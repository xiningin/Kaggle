{"cell_type":{"64e72afe":"code","690803d0":"code","8287f258":"code","1048aecb":"code","f0d3edbd":"code","02532239":"code","5c99e130":"code","2240803b":"code","e75051ce":"code","85b6570b":"code","ee86ac17":"code","2adeb7d6":"code","a202421f":"code","ecd0a4d9":"code","fda899da":"code","e9e54a2b":"code","168424ee":"code","5b06a3b7":"code","228d3de5":"code","8b0f7ba5":"code","4461d631":"code","113b0837":"code","7d21f586":"code","d63dcd93":"code","547f07f2":"code","16f3a0c7":"code","29f4b75e":"code","c3582925":"markdown","9356ac79":"markdown","97bb6dfb":"markdown","832fa0c7":"markdown","103595eb":"markdown","5c40a45e":"markdown","e79800dc":"markdown","47716195":"markdown","96234a08":"markdown"},"source":{"64e72afe":"import os\nimport pickle\nimport random\nimport glob\nimport datetime\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport pydicom\nfrom tqdm import tqdm\nfrom joblib import delayed, Parallel\nimport zipfile\nfrom pydicom.filebase import DicomBytesIO\nimport sys\nfrom PIL import Image\nimport cv2\n#from focal_loss import sparse_categorical_focal_loss\nimport keras\n#import tensorflow_addons as tfa\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import model_from_json\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, GlobalAveragePooling2D, Dropout\nfrom keras.applications.inception_v3 import InceptionV3\n\n# importing pyplot and image from matplotlib \nimport matplotlib.pyplot as plt \nimport matplotlib.image as mpimg \nfrom keras.optimizers import SGD\nfrom keras import backend\nfrom keras.models import load_model\n\nfrom keras.preprocessing import image\nimport albumentations as A\n\n\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\nimport tensorflow as tf","690803d0":"from tensorflow.keras.losses import Reduction\n\nfrom tensorflow_addons.losses import SigmoidFocalCrossEntropy","8287f258":"base_url = '\/home\/ubuntu\/kaggle\/rsna-intracranial-hemorrhage-detection\/'\nTRAIN_DIR = '\/home\/ubuntu\/kaggle\/rsna-intracranial-hemorrhage-detection\/stage_2_train\/'\nTEST_DIR = '\/home\/ubuntu\/kaggle\/rsna-intracranial-hemorrhage-detection\/stage_2_test\/'\nimage_dir = '\/home\/ubuntu\/kaggle\/rsna-intracranial-hemorrhage-detection\/png\/train\/adjacent-brain-cropped\/'\nsave_dir = 'home\/ubuntu\/kaggle\/models\/'\nos.listdir(base_url)\n\ndef png(image): \n    return image + '.png'","1048aecb":"initial_learning_rate = 1e-2\nfirst_decay_steps = 1000\nlr_decayed_fn = (\n  tf.keras.experimental.CosineDecayRestarts(\n      initial_learning_rate,\n      first_decay_steps))\nopt = tf.keras.optimizers.SGD(learning_rate=lr_decayed_fn, nesterov=True)","f0d3edbd":"train_idg = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        shear_range=0.05,\n        rotation_range=50, # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,\n        rescale=1.\/255)\nvalid_idg = ImageDataGenerator(rescale=1.\/255)\ntraining_data = pd.read_csv(f'train_0.csv') \ntraining_data['Image'] = training_data['Image'].apply(png)\n\nvalidation_data = pd.read_csv(f'valid_0.csv')\nvalidation_data['Image'] = validation_data['Image'].apply(png)\n\ncolumns=['any','epidural','intraparenchymal','intraventricular', 'subarachnoid','subdural']\n\n#train_data_generator = train_idg.flow_from_dataframe(training_data, directory = image_dir,\n#                           x_col = \"Image\", y_col = columns,batch_size=64,\n#                           class_mode=\"raw\", target_size=(224,224), shuffle = True)\n#valid_data_generator  = valid_idg.flow_from_dataframe(validation_data, directory = image_dir,\n#                        x_col = \"Image\", y_col = columns,batch_size=64,\n#                        class_mode = \"raw\",target_size=(224,224), shuffle = False)","02532239":"train_under_generator = train_idg.flow_from_dataframe(l, directory = image_dir,\n                           x_col = \"Image\", y_col = columns,batch_size=64,\n                           class_mode=\"raw\", target_size=(224,224), shuffle = True)\nvalid_under_generator  = valid_idg.flow_from_dataframe(m, directory = image_dir,\n                        x_col = \"Image\", y_col = columns,batch_size=64,\n                        class_mode = \"raw\",target_size=(224,224), shuffle = False)","5c99e130":"def undersample(dataframe,steps,batch_size):\n        part = np.int(steps\/3 * batch_size)\n        zero_ids = np.random.choice(dataframe.loc[dataframe[\"any\"] == 0].index.values, size=2*part, replace=False)\n        hot_ids = np.random.choice(dataframe.loc[dataframe[\"any\"] == 1].index.values, size=1*part, replace=False)\n        data_ids = list(set(zero_ids).union(hot_ids))\n        np.random.shuffle(data_ids)\n        return data_ids\n        ","2240803b":"train_indices = undersample(training_data, 8050,32)\nprint(len(train_indices))","e75051ce":"valid_indices = undersample(validation_data, 2010,32)\nprint(len(valid_indices))","85b6570b":"l = training_data[training_data.index.isin(train_indices)]\nm = validation_data[validation_data.index.isin(valid_indices)]","ee86ac17":"from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n\n\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3))\n\nfor layer in base_model.layers[:28]:\n    layer.trainable = False","2adeb7d6":"from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n\nMETRICS = [\n      tf.keras.metrics.TruePositives(name='tp'),\n      tf.keras.metrics.FalsePositives(name='fp'),\n      tf.keras.metrics.TrueNegatives(name='tn'),\n      tf.keras.metrics.FalseNegatives(name='fn'), \n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),\n      tf.keras.metrics.AUC(name='auc')\n      \n]\n\n\n# create the base pre-trained model\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3))\nprint('Model loaded.')\n\n\n\n# add a global spatial average pooling layer\nx = base_model.output\n\nx = GlobalAveragePooling2D()(x)\nnet = Dense(256, activation='elu')(x)\nnet = Dense(6, activation='sigmoid')(net)\n\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=net)\n\n\n\n# first: train only the top layers (which were randomly initialized)\n# i.e. freeze all convolutional InceptionV3 layers\n#for layer in base_model.layers:\n#    layer.trainable = False\nfor layer in base_model.layers[:28]:\n    layer.trainable = False\n\n\n# compile the model (should be done *after* setting layers to non-trainable)\nmodel.compile(opt, loss='binary_crossentropy', metrics=METRICS)\n\n\n\n\nmodel.summary()","a202421f":"from keras import backend as K\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\n\ncheckpoint = tf.keras.callbacks.ModelCheckpoint('\/kaggle\/models\/mobilenetv2_{epoch:08d}.h5', period=1,mode= 'auto',save_best_only=True) \n\nlearning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\ncallback_list = [checkpoint]\n","ecd0a4d9":"tf.config.experimental_run_functions_eagerly(True)","fda899da":"class_weight = {0:1.0,1:2.0}\nclass_weight","e9e54a2b":"\n\n\nnum_epochs = 20\n\nbatch_size = 512\ntraining_steps = len(training_data) \/\/ batch_size\nvalidation_step = len(validation_data) \/\/ batch_size\n\n\n\n\n\n# FIT THE MODEL\nhistory = model.fit(train_under_generator,\n            epochs=num_epochs,\n            steps_per_epoch=training_steps,\n            callbacks=callback_list,\n            class_weight=class_weight,\n            validation_data=valid_under_generator,\n            validation_steps= validation_step\n                   ) \n\n\n\n\n\ntf.keras.backend.clear_session()\n","168424ee":"valid_predict =  model.evaluate_generator(valid_under_generator)\nprint(valid_predict)","5b06a3b7":"model.metrics_names","228d3de5":"print('\\n---------------\\n')\nprint('validation data **loss** value =', valid_predict[0])\nprint('\\n---------------\\n')\nprint('validation data **true positive** value = ', valid_predict[1])\nprint('\\n---------------\\n')\nprint('validation data **false positive** value =', valid_predict[2])\nprint('\\n---------------\\n')\nprint('validation data **true negative** value =', valid_predict[3])\nprint('\\n---------------\\n')\nprint('validation data **false negative** value =', valid_predict[4])\nprint('\\n---------------\\n')\nprint('validation data **accuracy** value = ', valid_predict[5])\nprint('\\n---------------\\n')\nprint('validation data **precision** value =', valid_predict[6])\nprint('\\n---------------\\n')\nprint('validation data **recall* value =', valid_predict[7])\nprint('\\n---------------\\n')\nprint('validation data **AUC* value =', valid_predict[8])\nprint('\\n---------------\\n')","8b0f7ba5":"y_true = m[['any','epidural','intraparenchymal','intraventricular', 'subarachnoid','subdural']].reset_index(drop=True)\n\nY_pred = model.predict_generator(valid_under_generator)\npreds = np.where(Y_pred < 0.25, 0, 1)\n\n\n\n#val = 0.25\n\n#Y_pred[Y_pred>=val]=1\n#Y_pred[Y_pred<val]=0","4461d631":"print('Classification Report')\ntarget_names = ['any','epidural','intraparenchymal','intraventricular', 'subarachnoid','subdural']\nprint(classification_report(y_true, preds, target_names=target_names))","113b0837":"import seaborn as sns\nfrom sklearn.metrics import multilabel_confusion_matrix\n# Creating multilabel confusion matrix\nconfusion = multilabel_confusion_matrix(y_true, preds)\nmlb= ['any','epidural','intraparenchymal','intraventricular', 'subarachnoid','subdural']\n# Plot confusion matrix \nfig = plt.figure(figsize = (14, 8))\nfor i, (label, matrix) in enumerate(zip(mlb, confusion)):\n    plt.subplot(f'23{i+1}')\n    labels = [f'not_{label}', label]\n    sns.heatmap(matrix, annot = True, square = True, fmt = 'd', cbar = False, cmap = 'Blues', \n                xticklabels = labels, yticklabels = labels, linecolor = 'black', linewidth = 1)\n    plt.title(labels[0])\n\nplt.tight_layout()\nplt.show()","7d21f586":"auc = roc_auc_score(y_true, preds)\nprint(auc)","d63dcd93":"def plot_training(H):\n    # construct a plot that plots and saves the training history\n    with plt.xkcd():\n        plt.figure(figsize = (10,10))\n        plt.plot(H.epoch,H.history[\"accuracy\"], label=\"train_acc\")\n        plt.plot(H.epoch,H.history[\"val_accuracy\"], label=\"val_acc\")\n        plt.title(\"Training Accuracy\")\n        plt.xlabel(\"Epoch #\")\n        plt.ylabel(\"Accuracy\")\n        plt.legend(loc=\"lower left\")\n        plt.show()","547f07f2":"plot_training(history)","16f3a0c7":"def plot_training(H):\n    # construct a plot that plots and saves the training history\n    with plt.xkcd():\n        plt.figure(figsize = (10,10))\n        plt.plot(H.epoch,H.history[\"loss\"], label=\"train_loss\")\n        plt.plot(H.epoch,H.history[\"val_loss\"], label=\"val_loss\")\n        plt.title(\"Training Loss\")\n        plt.xlabel(\"Epoch #\")\n        plt.ylabel(\"Loss\")\n        plt.legend(loc=\"lower left\")\n        plt.show()","29f4b75e":"plot_training(history)","c3582925":"# Classifcation Report","9356ac79":"# Generator","97bb6dfb":"# Undersamping","832fa0c7":"# learning rate","103595eb":"# Evalution","5c40a45e":"# AUC_ROC_SCORE","e79800dc":"# ACCURACY AND LOSS PLOT","47716195":"# Callback","96234a08":"# Model"}}