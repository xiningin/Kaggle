{"cell_type":{"d1c384fe":"code","c8626ab5":"code","0602b8a7":"code","294f8364":"code","b3dc2ff3":"code","6cb6a344":"code","a0a20336":"code","9028143b":"code","4055dc42":"code","03f1f7c2":"code","0489b050":"code","190d7ae9":"code","ae27c56b":"code","236121ed":"code","ac27e3a3":"code","a48f1f8c":"code","af00fb54":"code","5fae5e94":"code","1a20d974":"code","1c3b4c2b":"code","27756507":"markdown","51a262ae":"markdown","f679cd6a":"markdown","7e1afe02":"markdown","604a915f":"markdown","e21f780d":"markdown","9c1e36b3":"markdown","ffa04395":"markdown","d0715279":"markdown","c4c9519f":"markdown","6d0c6e6f":"markdown"},"source":{"d1c384fe":"import math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","c8626ab5":"df = pd.read_csv('..\/input\/training\/training.csv')\ndf.dropna(inplace=True)\ndf.shape","0602b8a7":"from joblib import Parallel, delayed\n\ndef format_img(x):\n    return np.asarray([int(e) for e in x.split(' ')], dtype=np.uint8).reshape(96,96)\n\nwith Parallel(n_jobs=10, verbose=1, prefer='threads') as ex:\n    x = ex(delayed(format_img)(e) for e in df.Image)\n    \nx = np.stack(x)[..., None]\nx.shape","294f8364":"y = df.iloc[:, :-1].values\ny.shape","b3dc2ff3":"def show(x, y=None):\n    plt.imshow(x[..., 0], 'gray')\n    if y is not None:\n        points = np.vstack(np.split(y, 15)).T\n        plt.plot(points[0], points[1], 'o', color='red')\n        \n    plt.axis('off')\n\nsample_idx = np.random.choice(len(x))    \nshow(x[sample_idx], y[sample_idx])","6cb6a344":"from sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\nx_train.shape, x_val.shape","a0a20336":"# Observamos las dimensiones de \"y\"\ny_train.shape, y_val.shape","9028143b":"# Normalizar las im\u00e1genes (1pt)\n\n# Opto por normalizar utilizando la media y las desviaci\u00f3n est\u00e1ndar\n# Estiramos las im\u00e1genes:\nx_train_norm=x_train[:,:,:,:]\nx_val_norm=x_val[:,:,:,:]\nx_train_norm=x_train_norm.reshape([1712,96*96,1])\nx_val_norm=x_val_norm.reshape([428,96*96,1])\n\n# Normalizaci\u00f3n:\nmu=x_train_norm.mean()\nsigma=x_train_norm.std()\n\nx_train_norm=(x_train_norm - mu)\/sigma\nx_val_norm=(x_val_norm - mu)\/sigma # Se normaliza siempre con el mu y sigma de los datos de entrenamiento\n\nx_train_norm.shape, x_val_norm.shape, x_train_norm.mean(), x_train_norm.std(), x_val_norm.mean(), x_val_norm.std()\n\n","4055dc42":"# Observamos arriba que efectivamente est\u00e1n normalizados. Ahora retornamos a las dimensiones de matriz de imagen:\nx_train_norm=x_train_norm.reshape([1712,96,96,1])\nx_val_norm=x_val_norm.reshape([428,96,96,1])\n\nx_train_norm.shape, x_val_norm.shape","03f1f7c2":"# Observamos una imagen para ver si est\u00e1 todo en orden:\nshow(x_train_norm[15], y_train[15])","0489b050":"# Definir correctamente la red neuronal (5 pts)\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, AvgPool2D, BatchNormalization, Dropout\nfrom keras.optimizers import Adam\nfrom keras import regularizers\n\nmodel=Sequential([\n    Conv2D(72,4,input_shape=(96,96,1),activation='relu',kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(0.01)),\n    AvgPool2D(pool_size=(2,2)),\n    Conv2D(48,2,activation='relu',use_bias=False,kernel_initializer='he_normal' ,kernel_regularizer=regularizers.l2(0.01)), #Seg\u00fan clase, no se debe inicializar bias antes de un batchnorm\n    BatchNormalization(),\n    Flatten(),\n    Dropout(0.5), #Act\u00faa como regularizador\n    Dense(48,activation='relu', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)), #Importante utilizar he initialization para relu\n#     Dropout(0.2), #Act\u00faa como regularizador\n#     Dense(40,activation='relu', kernel_initializer='he_normal'), #Importante utilizar he initialization para relu\n    Dense(30, kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(0.01)) # No hay activaci\u00f3n ac\u00e1 por ser un problema de regresi\u00f3n\n])\n\nmodel.compile(optimizer=Adam(0.01),loss='mse',metrics=['mae']) # Settings seg\u00fan indicaciones","190d7ae9":"# Resumen de las capas del modelo:\nmodel.summary(), model.input, model.output","ae27c56b":"# Entrenar la red neuronal (2 pts)\nlog=model.fit(x_train_norm, y_train, epochs=150, batch_size=256, validation_data=[x_val_norm,y_val])","236121ed":"# Resultado del entrenamiento\n# - mae entre 10 y 15 (3 pts)\n# - mae entre 8 y 11 (5 pts)\n# - mae entre 5 y 8 (7 pts)\n# - mae menor o igual a 4.0 (9 pts)\n\nprint(f'MAE final: {model.evaluate(x_val, y_val)[1]}')\nprint(f'MAE final: {model.evaluate((x_val-mu)\/sigma, y_val)[1]}')\nprint(f'MAE final: {model.evaluate(x_val_norm, y_val)[1]}')","ac27e3a3":"# Ver la perdida en el entrenamiento\ndef show_results(*logs):\n    trn_loss, val_loss, trn_acc, val_acc = [], [], [], []\n    \n    for log in logs:\n        trn_loss += log.history['loss']\n        val_loss += log.history['val_loss']\n    \n    fig, ax = plt.subplots(figsize=(8,4))\n    ax.plot(trn_loss, label='train')\n    ax.plot(val_loss, label='validation')\n    ax.set_xlabel('epoch'); ax.set_ylabel('loss')\n    ax.legend()\n    \nshow_results(log)","a48f1f8c":"# Funci\u00f3n para visualizar un resultado\ndef show_pred(x, y_real, y_pred):\n    fig, axes = plt.subplots(1, 2, figsize=(10,5))\n    for ax in axes:\n        ax.imshow(x[0, ..., 0], 'gray')\n        ax.axis('off')\n        \n    points_real = np.vstack(np.split(y_real[0], 15)).T\n    points_pred = np.vstack(np.split(y_pred[0], 15)).T\n    axes[0].plot(points_pred[0], points_pred[1], 'o', color='red')\n    axes[0].set_title('Predictions', size=16)\n    axes[1].plot(points_real[0], points_real[1], 'o', color='green')\n    axes[1].plot(points_pred[0], points_pred[1], 'o', color='red', alpha=0.5)\n    axes[1].set_title('Real', size=16)","af00fb54":"# Ordenamos el set de validaci\u00f3n seg\u00fan el ranking de errores obtenidos al predecir el set de validaci\u00f3n:\npredicciones_val=model.predict(x_val_norm)\nresiduales_val=np.abs(predicciones_val - y_val)\nmad_val=np.sum(residuales_val, axis=1)\/30\n\nindices=mad_val.argsort()\nindices.shape","5fae5e94":"# Mostrar 5 resultados aleatorios del set de validaci\u00f3n (1 pt)\nfor _ in range(5):\n    index = np.random.choice(x_val_norm.shape[0])\n    sample_x = x_val_norm[index, None]\n    sample_y = y_val[index, None]\n    pred = model.predict(sample_x)\n    show_pred(sample_x, sample_y, pred)","1a20d974":"# Mostrar las 5 mejores predicciones del set de validaci\u00f3n (1 pt)\nfor i in range(5):\n    sample_x = x_val_norm[indices[i], None]\n    sample_y = y_val[indices[i], None]\n    pred = model.predict(sample_x)\n    show_pred(sample_x, sample_y, pred)","1c3b4c2b":"# Mostrar las 5 peores predicciones del set de validaci\u00f3n (1 pt)\nfor i in [-1,-2,-3,-4,-5]:\n    sample_x = x_val_norm[indices[i], None]\n    sample_y = y_val[indices[i], None]\n    pred = model.predict(sample_x)\n    show_pred(sample_x, sample_y, pred)","27756507":"# Train validation split","51a262ae":"Ej:\n``` python\nsample_x = x_val[0, None]\nsample_y = y_val[0, None]\npred = model.predict(sample_x)\nshow_pred(sample_x, sample_y, pred)\n```","f679cd6a":"Se observa entonces que se logra obtener un MAE menor a 4 (3.5462).","7e1afe02":"# Examen Parcial:\n\nPara ejecutar el c\u00f3digo: crear un kernel en la competencia de kaggle (https:\/\/www.kaggle.com\/c\/facial-keypoints-detection) y partir de este notebook. Una vez terminado, se debe descargar el notebook final y subirlo en paideia.\n\n\n## Descripcion de la tarea\n\nEl objetivo de esta tarea es predecir las posiciones de los puntos clave en im\u00e1genes de rostros.\n\nLas im\u00e1genes de entrada son de 96x96 p\u00edxeles y en escala de grises (descritas con n\u00fameros enteros entre 0 y 255).\n\nCada punto clave se especifica mediante un par de valores reales (x, y) en el espacio de los \u00edndices de p\u00edxeles. Hay 15 puntos clave, que representan los siguientes elementos de la cara:\n\n    left_eye_center, right_eye_center, left_eye_inner_corner, left_eye_outer_corner, right_eye_inner_corner, right_eye_outer_corner, left_eyebrow_inner_end, left_eyebrow_outer_end, right_eyebrow_inner_end, right_eyebrow_outer_end, nose_tip, mouth_left_corner, mouth_right_corner, mouth_center_top_lip, mouth_center_bottom_lip\n\nDe modo que se debe entrenar una red neuronal que tome como input la imagen en escala de grises y de como output 30 n\u00fameros (las coordenadas x,y de los 15 puntos claves).\n\nAl compilar el modelo, especificar como funci\u00f3n de p\u00e9rdida el mean squared error **(mse)** y como m\u00e9trica el mean absolute error **(mae)**. Por ejemplo:\n``` python\nmodel.compile(Adam(lr), loss='mse', metrics=['mae'])\n```\n\n## Calificaci\u00f3n\n\n- Normalizar las im\u00e1genes (1 pt)\n- Definir correctamente la red neuronal (4 pts)\n- Entrenar la red neuronal (2 pts)\n  - mae entre 10 y 15 (3 pts)\n  - mae entre 8 y 11 (5 pts)\n  - mae entre 5 y 8 (7 pts)\n  - mae menor o igual a 4.0 (9 pts)\n- Mostrar 5 resultados aleatorios del set de validaci\u00f3n (1 pt)\n- Mostrar las 5 mejores predicciones del set de validaci\u00f3n (1 pt)\n- Mostrar las 5 peores predicciones del set de validaci\u00f3n (1 pt)\n\n## Recomendaciones\n\nActivar el uso de GPU en el kernel de kaggle.\n\nDentro del kernel de kaggle, los botones para bajar y subir kernels, se encuentran en la parte superior de la pagina, a la izquierda del boton commit.\n\n![](https:\/\/i.imgur.com\/m4inkg3.png)","604a915f":"# Lectura de datos","e21f780d":"Nota para el profesor: Ojo que el modelo est\u00e1 entrenado para procesar adecuadamente datos normalizados, as\u00ed que tambi\u00e9n normalizo el **x_val** para imprimir el error adecuado.","9c1e36b3":"# Normalizaci\u00f3n de im\u00e1genes\nPara ello se utiliza reshape de numpy para estirar las imagenes, normalizarlas y volver a dimensionarla como imagen","ffa04395":"# Informaci\u00f3n de alumno\n- Nombre: Alessandro Oscar Huam\u00e1n Molina\n- C\u00f3digo: 20141131\n- Correo: alessandro.huaman@pucp.pe","d0715279":"# Model\nNotamos que se trata de un problema de regresi\u00f3n dado que los puntos faciales clave que debemos predecir tienen coordenadas X y Y (continuas). Entonces, la l\u00f3gica de la red a construir ser\u00e1: convertir la imagen facial a las 30 coordenadas (output), compar\u00e1ndolas con el valor real mediante la p\u00e9rdida MSE.","c4c9519f":"Todo bien hasta ahora.","6d0c6e6f":"# Resultados"}}