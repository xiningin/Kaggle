{"cell_type":{"f06d9442":"code","a8cb1ee0":"code","dedebd86":"code","a667bc83":"markdown","28cf4017":"markdown","0efff1e3":"markdown"},"source":{"f06d9442":"!pip install facenet_pytorch\n!pip install opencv-contrib-python\n","a8cb1ee0":"from functools import wraps\n\nfrom functools import wraps\n\nimport cv2\nimport numpy as np\nfrom facenet_pytorch.models.mtcnn import MTCNN\n\n\ndef roi_supported_detector(dict_of_id_to_bbs, bbs_width):\n    def mydecorator(detector_function):\n        @wraps(detector_function)\n        def wrapper(*args, **kwargs):\n            person_id = kwargs['person_id']\n            image = kwargs['img']\n            if person_id in dict_of_id_to_bbs.keys():\n                bb = dict_of_id_to_bbs[person_id][0]\n                margin = 0.5\n                width = abs(bb[0] - bb[2])\n                roi_coords = np.asarray([max(bb[0] - width * margin, 0),\n                                         max(bb[1] - width * margin, 0),\n                                         min(bb[2] + width * margin, image.shape[1]),\n                                         min(bb[3] + width * margin, image.shape[0])]).astype(int)\n                roi = image[roi_coords[1]:roi_coords[3], roi_coords[0]:roi_coords[2], :]\n                kwargs['img'] = roi\n                cv2.imshow(\"img_roi\", roi)\n                result = detector_function(*args, **kwargs)\n                result = list(result)\n                if result[0] is not None:\n                    result[0] = (result[0].reshape(-1, 2) + np.asarray(roi_coords)[:2]).reshape(1, -1)\n                    if len(result) > 2:\n                        result[2] = result[2] + np.asarray(roi_coords)[:2]\n                    new_bb = result[0]\n                    dict_of_id_to_bbs[person_id] = new_bb\n                    bbs_width[person_id] = width\n\n                result = tuple(result)\n            else:\n                result = detector_function(*args, **kwargs)\n                if result[0] is not None:\n                    new_bb = result[0]\n                    dict_of_id_to_bbs[person_id] = new_bb\n                    bb = dict_of_id_to_bbs[person_id][0]\n                    width = abs(bb[0] - bb[2])\n                    bbs_width[person_id] = width\n\n            return result\n\n        return wrapper\n\n    return mydecorator\n\n\nclass Extended_MTCNN(MTCNN):\n    dict_of_id_to_bbs = {}\n    bbs_width = {}\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(args, kwargs)\n\n    @roi_supported_detector(dict_of_id_to_bbs, bbs_width)\n    def detect_with_roi(self, person_id=1, *args, **kwargs):\n        return self.detect(*args, **kwargs)\n","dedebd86":"mtcnn = Extended_MTCNN(device=device,min_face_size=20)\ncap = cv2.VideoCapture(\"path_to_video\")\nwhile ret:\n\n    ret, frame = cap.read()\n    person_id = 1\n    \n    if person_id in mtcnn.dict_of_id_to_bbs.keys():\n        mtcnn.min_face_size = int(mtcnn.bbs_width[person_id] * 0.8)\n        print(mtcnn.min_face_size)\n    boxes, probs, landmarks = mtcnn.detect_with_roi(person_id=person_id,\n                                                    img=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), landmarks=True)","a667bc83":"This script contains tool to detect faces using MTCNN  based on ROI, that were driven from previous MTCNN detection.","28cf4017":"##### Note , that you should know person id in order to select roi correctly","0efff1e3":"## And then use this like:"}}