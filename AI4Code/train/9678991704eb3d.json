{"cell_type":{"00d146a7":"code","8811a026":"code","705ac1c2":"code","b0df1e05":"code","9efa3087":"code","48b181c4":"code","9034a10a":"code","24e3035c":"code","bc800c4e":"code","48072ceb":"code","50fbe808":"code","ed5da58c":"code","868b49a0":"code","7c16f192":"code","d0ad308c":"code","b3effaf4":"code","673051bc":"markdown","c4389ab0":"markdown","a0ec2e33":"markdown","80728732":"markdown","44b00ec2":"markdown","847da401":"markdown","c1bf50c3":"markdown"},"source":{"00d146a7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","8811a026":"import pandas as pd\ndf1 = pd.read_csv (\"\/kaggle\/input\/june15.csv\")\ndf2 = pd.read_csv (\"\/kaggle\/input\/july15.csv\")\ndf3 = pd.read_csv (\"\/kaggle\/input\/aug15.csv\")\ndf4 = pd.read_csv (\"\/kaggle\/input\/sep15.csv\")\ndf5 = pd.read_csv (\"\/kaggle\/input\/oct15.csv\")\n# df1=pd.read_csv(\"june15.csv\")\n# \/kaggle\/input\/june15.csv\n# df = pd.read_csv (r'Path where the CSV file is stored\\File name.csv')\n# print (df)","705ac1c2":"df1['timestamp'] = pd.to_datetime(df1['timestamp'])  # Makes sure your timestamp is in datetime format\ndf1=df1.groupby(pd.Grouper(key='timestamp', freq='60Min')).sum()","b0df1e05":"df1.reset_index(level=0, inplace=True)","9efa3087":"import plotly.express as px\n\nfig = px.line(df1, x='timestamp', y='mb')\nfig.show()","48b181c4":"df2['timestamp'] = pd.to_datetime(df2['timestamp'])  # Makes sure your timestamp is in datetime format\ndf2=df2.groupby(pd.Grouper(key='timestamp', freq='60Min')).sum()","9034a10a":"df2.reset_index(level=0, inplace=True)\nimport plotly.express as px\n\nfig = px.line(df2, x='timestamp', y='mb')\nfig.show()","24e3035c":"df3['timestamp'] = pd.to_datetime(df3['timestamp'])  # Makes sure your timestamp is in datetime format\ndf3=df3.groupby(pd.Grouper(key='timestamp', freq='60Min')).sum()","bc800c4e":"df3.reset_index(level=0, inplace=True)\nimport plotly.express as px\n\nfig = px.line(df3, x='timestamp', y='mb')\nfig.show()","48072ceb":"df4['timestamp'] = pd.to_datetime(df4['timestamp'])  # Makes sure your timestamp is in datetime format\ndf4=df4.groupby(pd.Grouper(key='timestamp', freq='60Min')).sum()","50fbe808":"df4.reset_index(level=0, inplace=True)\nimport plotly.express as px\n\nfig = px.line(df4, x='timestamp', y='mb')\nfig.show()","ed5da58c":"df5['timestamp'] = pd.to_datetime(df5['timestamp'])  # Makes sure your timestamp is in datetime format\ndf5=df5.groupby(pd.Grouper(key='timestamp', freq='60Min')).sum()","868b49a0":"df5.reset_index(level=0, inplace=True)\nimport plotly.express as px\n\nfig = px.line(df5, x='timestamp', y='mb')\nfig.show()","7c16f192":"df=[df1,df2,df3,df4,df5]\ndf=pd.concat(df,join='outer',axis=0,ignore_index=False)","d0ad308c":"df['timestamp'] = pd.to_datetime(df['timestamp'])  # Makes sure your timestamp is in datetime format\ndf=df.groupby(pd.Grouper(key='timestamp', freq='60Min')).sum()","b3effaf4":"df.reset_index(level=0, inplace=True)\nimport plotly.express as px\n\nfig = px.line(df, x='timestamp', y='mb')\nfig.show()","673051bc":"hourly dat for full data set","c4389ab0":"**sep hourly data**","a0ec2e33":"july hourly data****","80728732":"#*june hourly data*","44b00ec2":"oct hourly data****","847da401":"**Aug hourly data**","c1bf50c3":"**full data**"}}