{"cell_type":{"42fd2bca":"code","b89b1a6c":"code","9d598987":"code","f84d6f02":"code","5fa61b59":"code","ae52cefa":"code","5aa25019":"code","236512ad":"code","9e1a8084":"code","064cc257":"code","c46f90f7":"code","37b23388":"code","9d0d6666":"code","da6ff59f":"code","d0af21ec":"code","251cc78f":"code","3fb60b98":"code","0dbcac97":"code","daa88e79":"code","1950c256":"markdown","46c8949c":"markdown","12f273c1":"markdown","88009ed2":"markdown","d78ee73c":"markdown","22f0bca5":"markdown","213ad09d":"markdown","d930fe9d":"markdown"},"source":{"42fd2bca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b89b1a6c":"import matplotlib.pyplot as plt\nimport imageio\n\nTEST_FOLDER_PATH=\"..\/input\/test\/\"\nTRAIN_FOLDER_PATH=\"..\/input\/train\/\"\nTARGET_NUM=28\nlabel_columns=['Nucleoplasm','Nuclear membrane','Nucleoli',\n               'Nucleoli fibrillar center','Nuclear speckles'  ,\n               'Nuclear bodies','Endoplasmic reticulum',\n               'Golgi apparatus','Peroxisomes'  ,'Endosomes'  ,\n               'Lysosomes'  ,'Intermediate filaments'  ,'Actin filaments'  ,\n               'Focal adhesion sites'  ,'Microtubules'  ,'Microtubule ends'  ,\n               'Cytokinetic bridge'  ,'  Mitotic spindle'  ,\n               'Microtubule organizing center'  ,'Centrosome'  ,\n               'Lipid droplets'  ,'Plasma membrane'  ,'Cell junctions'  ,\n               'Mitochondria'  ,'Aggresome'  ,'Cytosol'  ,'Cytoplasmic bodies'  ,\n               'Rods & rings']\nlabel_columns_chinese=['\u6838\u8d28','\u6838\u819c','\u6838\u4ec1','\u6838\u4ec1\u7ea4\u7ef4\u4e2d\u5fc3','\u6838\u6563\u6591','\u6838\u673a\u6784','\u5185\u8d28\u7f51',\n                       '\u9ad8\u5c14\u57fa\u4f53','\u8fc7\u6c27\u5316\u7269\u9176\u4f53','\u5185\u4f53','\u6eb6\u9176\u4f53','\u4e2d\u95f4\u957f\u4e1d','\u808c\u52a8\u86cb\u767d\u4e1d',\n                       '\u7c98\u7740\u4f4d\u70b9','\u5fae\u7ba1','\u5fae\u7ba1\u672b\u7aef','\u7ec6\u80de\u52a8\u529b\u5b66\u6865','\u6709\u4e1d\u5206\u88c2\u7eba\u9524','\u5fae\u7ba1\u7ec4\u7ec7\u4e2d\u5fc3',\n                       '\u4e2d\u5fc3\u4f53','\u8102\u6ef4','\u8d28\u819c','\u7ec6\u80de\u8fde\u63a5','\u7ebf\u7c92\u4f53','\u805a\u96c6\u5c0f','\u7ec6\u80de\u8d28','\u7ec6\u80de\u8d28\u4f53',\n                       '\u6746\u548c\u73af']","9d598987":"label=pd.read_csv('..\/input\/train.csv')\ntrain_file_names=os.listdir(TRAIN_FOLDER_PATH)\ntest_file_names=os.listdir(TEST_FOLDER_PATH)\n","f84d6f02":"TRAIN_SAMPLE_SIZE=label.shape[0]","5fa61b59":"train_file_names.sort()\ntest_file_names.sort()","ae52cefa":"def generate_label_cube(label,label_columns):\n    cube=np.zeros((label.shape[0],TARGET_NUM),dtype=int)\n    target=label['Target'].values\n    for x in range(label.shape[0]):\n        for y in target[x].split():\n            cube[x][int(y)]=1\n    cube=pd.DataFrame(cube,columns=label_columns)\n    \n    return pd.concat([label,cube],axis=1)","5aa25019":"label_new=generate_label_cube(label,label_columns)","236512ad":"tf=imageio.imread(\"..\/input\/train\/\"+label[0:1]['Id'].values[0]+'_green.png')\ntf.shape","9e1a8084":"def showFourPic(names):\n    fig, axes = plt.subplots(4, 4,figsize=(25,25))\n    color=['Blues','Reds','YlOrBr','Greens']\n    apex=['_blue','_red','_yellow','_green']\n    for x in range(4):\n        for y in range(4):\n            axes[x,y].imshow(imageio.imread(TRAIN_FOLDER_PATH+names[x]+apex[y]+'.png'),cmap=plt.get_cmap(color[y]))\n            axes[x,y].set_title(names[x]+apex[y])\n    plt.show()","064cc257":"showFourPic(label_new[label_new['Microtubules']==1]['Id'][0:4].values)","c46f90f7":"showFourPic(label_new[label_new['Endoplasmic reticulum']==1]['Id'][0:4].values)","37b23388":"from keras.layers import Input\nfrom keras.layers import Dense\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Activation\nfrom keras.layers import AveragePooling2D\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras import layers\n\n\n","9d0d6666":"def conv2d_bn(x,\n              filters,\n              num_row,\n              num_col,\n              padding='same',\n              strides=(1, 1),\n              name=None):\n    bn_axis = 3\n    x = Conv2D(\n        filters, (num_row, num_col),\n        strides=strides,\n        padding=padding,\n        use_bias=False,\n        name=name)(x)\n    x = BatchNormalization(axis=bn_axis, scale=False, name=name)(x)\n    x = Activation('relu', name=name)(x)\n    return x","da6ff59f":"def InceptionV3():\n\n    channel_axis = 3\n    classes = 28\n    inputs=Input(shape=(512,512,1))\n\n    x = conv2d_bn(inputs,3,3,3,strides=(2,2),padding='valid')\n    x = conv2d_bn(x, 32, 3, 3, strides=(2, 2), padding='valid')\n    x = conv2d_bn(x, 32, 3, 3, padding='valid')\n    x = conv2d_bn(x, 64, 3, 3)\n    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n\n    x = conv2d_bn(x, 80, 1, 1, padding='valid')\n    x = conv2d_bn(x, 192, 3, 3, padding='valid')\n    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n\n    # mixed 0, 1, 2: 35 x 35 x 256\n    branch1x1 = conv2d_bn(x, 64, 1, 1)\n\n    branch5x5 = conv2d_bn(x, 48, 1, 1)\n    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n\n    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n\n    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n    branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n    x = layers.concatenate(\n        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n        axis=channel_axis,\n        name='mixed0')\n\n    # mixed 1: 35 x 35 x 256\n    branch1x1 = conv2d_bn(x, 64, 1, 1)\n\n    branch5x5 = conv2d_bn(x, 48, 1, 1)\n    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n\n    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n\n    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n    x = layers.concatenate(\n        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n        axis=channel_axis,\n        name='mixed1')\n\n    # mixed 2: 35 x 35 x 256\n    branch1x1 = conv2d_bn(x, 64, 1, 1)\n\n    branch5x5 = conv2d_bn(x, 48, 1, 1)\n    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n\n    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n\n    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n    x = layers.concatenate(\n        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n        axis=channel_axis,\n        name='mixed2')\n\n    # mixed 3: 17 x 17 x 768\n    branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n\n    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n    branch3x3dbl = conv2d_bn(\n        branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n\n    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n    x = layers.concatenate(\n        [branch3x3, branch3x3dbl, branch_pool], axis=channel_axis, name='mixed3')\n\n    # mixed 4: 17 x 17 x 768\n    branch1x1 = conv2d_bn(x, 192, 1, 1)\n\n    branch7x7 = conv2d_bn(x, 128, 1, 1)\n    branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n\n    branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n\n    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n    x = layers.concatenate(\n        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n        axis=channel_axis,\n        name='mixed4')\n\n    # mixed 5, 6: 17 x 17 x 768\n    for i in range(2):\n        branch1x1 = conv2d_bn(x, 192, 1, 1)\n\n        branch7x7 = conv2d_bn(x, 160, 1, 1)\n        branch7x7 = conv2d_bn(branch7x7, 160, 1, 7)\n        branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n\n        branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 1, 7)\n        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n\n        branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n        x = layers.concatenate(\n            [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n            axis=channel_axis,\n            name='mixed' + str(5 + i))\n\n    # mixed 7: 17 x 17 x 768\n    branch1x1 = conv2d_bn(x, 192, 1, 1)\n\n    branch7x7 = conv2d_bn(x, 192, 1, 1)\n    branch7x7 = conv2d_bn(branch7x7, 192, 1, 7)\n    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n\n    branch7x7dbl = conv2d_bn(x, 192, 1, 1)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n\n    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n    x = layers.concatenate(\n        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n        axis=channel_axis,\n        name='mixed7')\n\n    # mixed 8: 8 x 8 x 1280\n    branch3x3 = conv2d_bn(x, 192, 1, 1)\n    branch3x3 = conv2d_bn(branch3x3, 320, 3, 3, strides=(2, 2), padding='valid')\n\n    branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n    branch7x7x3 = conv2d_bn(\n        branch7x7x3, 192, 3, 3, strides=(2, 2), padding='valid')\n\n    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n    x = layers.concatenate(\n        [branch3x3, branch7x7x3, branch_pool], axis=channel_axis, name='mixed8')\n\n    # mixed 9: 8 x 8 x 2048\n    for i in range(2):\n        branch1x1 = conv2d_bn(x, 320, 1, 1)\n\n        branch3x3 = conv2d_bn(x, 384, 1, 1)\n        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n        branch3x3 = layers.concatenate(\n            [branch3x3_1, branch3x3_2], axis=channel_axis, name='mixed9_' + str(i))\n\n        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n        branch3x3dbl = layers.concatenate(\n            [branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)\n\n        branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n        x = layers.concatenate(\n            [branch1x1, branch3x3, branch3x3dbl, branch_pool],\n            axis=channel_axis,\n            name='mixed' + str(9 + i))\n    \n    # Classification block\n    x = GlobalAveragePooling2D(name='avg_pool')(x)\n    x = Dense(classes, activation='softmax', name='predictions')(x)\n\n\n    # Create model.\n    model = Model(inputs, x, name='inception_v3')\n\n    return model","d0af21ec":"model = InceptionV3()\n\nmodel.summary()","251cc78f":"def generate_label(target):\n    label=np.zeros(TARGET_NUM,dtype=float)\n    for x in target.split():\n        label[int(x)]=1\n    return label","3fb60b98":"\ndef image_generator(label,batch_size):\n    while True:\n        try:\n            #make batch size data a generator\n            batch=label.loc[np.random.randint(TRAIN_SAMPLE_SIZE, size=batch_size)]\n            img_list=[]\n            img_gen=iter(batch['Id'])\n            tar_list=[]\n            tar_gen=iter(batch['Target'])\n            \n            #create train and target batch\n            for x in range(batch_size):\n                file=next(img_gen)\n                target=next(tar_gen)\n                img=imageio.imread(TRAIN_FOLDER_PATH+file+'_green.png')\n                img_list.append(img)\n                tar=generate_label(target)   \n                tar_list.append(tar)\n                \n            #do pre-process and transform\n            img_out=np.array(img_list,dtype='float')\n            img_out\/=255\n            img_out=img_out.reshape(batch_size,512,512,1)\n            tar_out=np.array(tar_list,dtype='float')\n\n            yield (img_out,tar_out)\n        except StopIteration:\n            break","0dbcac97":"predics=model.predict_generator(test_file_generator(test_files),steps=len(test_files))","daa88e79":"predics[0]","1950c256":"model.save_weights('my_model_weights.h5')\nmodel.save('my_model.h5')","46c8949c":"InceptionV3 is heavy load for getting ideal accuracy. It took more than 4 hours to get accuracy over 0.60. One reason is that the InceptionV3 is 42 more layers which takes more time to update weights. The other reason is that the image size a little bit large. So I am going to resize the image to check if it works better on speeding up.","12f273c1":"test_files=[x for x in test_file_names if 'blue' in x]\ndef test_file_generator(test_files):\n    test_gen=iter(test_file_names)\n    while True:\n        try:\n            file = next(test_gen)\n            img=imageio.imread(TEST_FOLDER_PATH+file)\n            img=img.astype('float32')\n            img\/=255\n            img=img.reshape(1,512,512,1)\n            yield img\n        except StopIteration:\n            break\n    ","88009ed2":"\nmodel.fit_generator(image_generator(label,100),steps_per_epoch=100,epochs=50)  # starts training","d78ee73c":"model = InceptionV3()\nmodel.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","22f0bca5":"First, let's solve a puzzle that if red,yellow and green pictures are of some special types of protein organelle, because **endoplasmic reticulum (yellow)** and  **microtubules (red)** are also types showed in target list. If they are, they will look similar to green pictures. ","213ad09d":"518x518 size of pictures are large for cnn models, it needs more weights and conputing time. In order to reduce the volume of weights and computing time, GoogLeNet is a better choice in my mind. It uses inception construct which has 1\/4 numbers of weighs of an VGG. I will first go with GoogLeNet with V2.","d930fe9d":"I can see similar betweet green pictures with 'endoplasmic reticulum' and yellow pictures, and so do 'microtubules' labels and  red pictures. But I have not figure out the connection between them, I leave the part for later."}}