{"cell_type":{"fbef23ce":"code","3c0ab7fb":"code","713befa6":"code","23028b5c":"code","6d7788e8":"code","17b8952f":"code","9ed50e0b":"code","110cb032":"code","80a75f81":"code","f0df741a":"code","e859028d":"code","0debeb76":"code","f88bbb57":"code","db295465":"code","f1976c65":"code","5d58f4ed":"code","35e6beca":"code","6a626a2e":"code","07eebd40":"code","afdeffd7":"code","dedc55ab":"code","9f5f0a99":"code","143cec4e":"code","3e2454bc":"code","39bfe59f":"code","ea74e32e":"code","2baefe30":"code","24913322":"code","cf13ff53":"code","fd547914":"code","c05ebaa3":"code","b601bc84":"code","ed724eb8":"code","cde6a2b5":"code","21c22385":"code","d8310fda":"code","427156bb":"code","1600fb5d":"code","10916745":"code","5c520935":"code","750d5c46":"code","47c21773":"code","744870cc":"code","d38dbf00":"code","f7f6cf14":"code","856b3ab5":"code","2d5187ee":"code","217759d3":"markdown","5f7f3091":"markdown","0f115f21":"markdown","98d9dd92":"markdown","2fba1607":"markdown","3fdb0041":"markdown","a1c1c1b8":"markdown","d7262cda":"markdown","8410a358":"markdown","9e0e6304":"markdown"},"source":{"fbef23ce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score, classification_report, confusion_matrix\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","3c0ab7fb":"train_df = pd.read_csv('..\/input\/data-science-bowl-2019\/train.csv')\ntest_df = pd.read_csv('..\/input\/data-science-bowl-2019\/test.csv')\ntrain_labels_df = pd.read_csv('..\/input\/data-science-bowl-2019\/train_labels.csv')\nspecs_df = pd.read_csv('..\/input\/data-science-bowl-2019\/specs.csv')","713befa6":"train_df.shape","23028b5c":"train_df.head()","6d7788e8":"test_df.shape","17b8952f":"test_df.head()","9ed50e0b":"train_labels_df.shape","110cb032":"train_labels_df.head()","80a75f81":"specs_df.shape","f0df741a":"specs_df.head()","e859028d":"train_df.dtypes","0debeb76":"#Lets check null values\ntrain_df.isnull().sum()","f88bbb57":"#plt.figure(figsize=(20,29)) \nsns.countplot(\"event_id\", data = train_df)","db295465":"train_df['event_id'].value_counts()","f1976c65":"training_data_with_label = pd.merge(train_df, train_labels_df, how='inner')","5d58f4ed":"training_data_with_label.head()","35e6beca":"training_data_with_label.shape","6a626a2e":"def prepare_agg_and_date_features(input_df, input_columns):\n    for column in input_columns:\n        input_df[column+\"_total\"]= input_df.groupby(column)[column].transform('count')\n        input_df['timestamp'] = pd.to_datetime(input_df['timestamp'])\n        input_df['year'] = input_df['timestamp'].dt.year\n        input_df['quarter_of_year'] = input_df['timestamp'].dt.quarter\n        input_df['month_of_year'] = input_df['timestamp'].dt.month\n        input_df['day_of_month'] = input_df['timestamp'].dt.day\n        input_df['hour_of_day'] = input_df['timestamp'].dt.hour\n        input_df['minute_of_hour '] = input_df['timestamp'].dt.minute \n    return input_df","07eebd40":"input_agg_columns = ['event_id', 'game_session', 'installation_id','title','type','world']","afdeffd7":"#Derive features from training dataset\ntraining_features = prepare_agg_and_date_features(training_data_with_label, input_agg_columns)","dedc55ab":"training_features.shape","9f5f0a99":"training_features.head()","143cec4e":"#Derive features from test dataset\ntest_features = prepare_agg_and_date_features(test_df, input_agg_columns)","3e2454bc":"test_features.head()","39bfe59f":"test_features.shape","ea74e32e":"# remove Object type feaures\nrequired_training_features = training_features.select_dtypes(exclude  = object)","2baefe30":"X = required_training_features.drop([\"timestamp\",\"accuracy\",\"accuracy_group\",\"num_correct\", \"num_incorrect\"], axis=1)","24913322":"y = required_training_features['accuracy_group']","cf13ff53":"X.shape","fd547914":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)","c05ebaa3":"#training the model\nlr_clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)","b601bc84":"#get prediction \nlr_prediction = lr_clf.predict(X_test)","ed724eb8":"confusion_matrix(y_test, lr_prediction)","cde6a2b5":"display(classification_report(y_test, lr_prediction))","21c22385":"cohen_kappa_score(y_test, lr_prediction)","d8310fda":"exclude_columns = [\"event_id\",\"game_session\",\"event_data\",\"title\",\"type\",\"world\",\"timestamp\"]","427156bb":"required_testing_features = test_df.drop(exclude_columns,axis=1)","1600fb5d":"required_testing_features.head()","10916745":"required_testing_features.shape","5c520935":"lr_test_data_prediction = lr_clf.predict(required_testing_features.drop('installation_id',axis=1))","750d5c46":"required_testing_features['accuracy_group'] = lr_test_data_prediction","47c21773":"submission_df = required_testing_features[['installation_id','accuracy_group']]","744870cc":"submission_df.head()","d38dbf00":"submission_df_group_by = pd.DataFrame(submission_df.groupby(['installation_id'])['accuracy_group'].mean())\nsubmission_df_group_by = submission_df_group_by.round().astype(int)\nsubmission_df_group_by.head(10)","f7f6cf14":"submission_df_group_by = submission_df_group_by.reset_index()","856b3ab5":"submission_df_group_by.head()","2d5187ee":"submission_df_group_by.to_csv(\"submission.csv\",index=False)","217759d3":"Get the prediction on the test dataset","5f7f3091":"### imports","0f115f21":"Prepare dataset for modeling","98d9dd92":"Take mean aggregate prediction of each installation_id","2fba1607":"![](http:\/\/)Lets prepare few aggerated and date features ","3fdb0041":"### My Goals for this notebook is to build a simple baseline model for \"2019 Data Science Bowl\" Kaggle competition:\n\nDetailed descripton of the problem and data can be found here https:\/\/www.kaggle.com\/c\/data-science-bowl-2019","a1c1c1b8":"![](http:\/\/)<a href=\".\/ladle_submission.csv\"> Download File <\/a>","d7262cda":"> ### Preparing submission file**","8410a358":"#### Load the data","9e0e6304":"* > Join Training dataset with labels dataset"}}