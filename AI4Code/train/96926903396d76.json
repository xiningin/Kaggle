{"cell_type":{"4f35e6c4":"code","f80ea51d":"code","05878151":"code","1beee2d5":"code","642e464a":"code","0a1bbb40":"code","fafe95a9":"code","97349cda":"code","e7fb8273":"code","feba96de":"code","0ecb414f":"code","af9ce4ac":"code","0f02122d":"code","12aa2a86":"code","f0d4e745":"code","9e706c29":"code","6283b241":"code","35bd993d":"code","25abc93f":"code","8a6b2611":"code","6206c953":"code","6e652345":"code","96256ecb":"code","61fdeb70":"code","958a6b2b":"code","ecd79d64":"code","0df59a39":"code","78deabc8":"code","b4d416db":"code","0dc8c548":"code","0ddbb823":"code","43c432a4":"code","e74301bf":"code","490c6592":"code","e754503d":"code","36c47cce":"code","edd02052":"code","dd97491a":"code","8f28d9fe":"code","73d1478a":"code","ae272abe":"code","d0045916":"code","9fe63c10":"code","45e91149":"code","5c764055":"code","0bb09550":"code","e8ef9ab2":"code","5418a4dd":"code","77c0ee75":"code","c9e1fd45":"code","d2f6b951":"code","3623af0f":"code","e2fa822c":"code","8e5afdaf":"code","aef457c2":"code","bd4fcaac":"code","8801fa66":"code","42db90e8":"code","bea90ad7":"code","a8a1c76e":"code","20853278":"code","de01869c":"code","8db06493":"code","18eee563":"code","7e6d0670":"code","43d200f1":"code","2de39726":"code","4748a981":"code","2acb122b":"code","2d3a0595":"markdown","4b1afc5b":"markdown","190a402d":"markdown","d4ce16eb":"markdown","96ace472":"markdown","29ca0d19":"markdown","1f713909":"markdown","01f9a7a5":"markdown"},"source":{"4f35e6c4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f80ea51d":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")","05878151":"train_data.head()","1beee2d5":"train_data.info()","642e464a":"#about categorical attributes\ntrain_data[\"Sex\"].value_counts()","0a1bbb40":"#about categorical attributes\ntrain_data[\"Embarked\"].value_counts()","fafe95a9":"#showing a summary of the numerical attributes\ntrain_data.describe()","97349cda":"#visualizing numerical atrributes\nimport matplotlib.pyplot as plt\ntrain_data[\"Survived\"].hist()","e7fb8273":"train_data[\"Age\"].hist()","feba96de":"train_data[\"Pclass\"].hist()","0ecb414f":"corr_matrix = train_data.corr()\ncorr_matrix[\"Survived\"].sort_values(ascending=False)","af9ce4ac":"#another way to look for correlations is to use pandas scatter_matrix() function\nfrom pandas.plotting import scatter_matrix\n\nattributes = [\"Survived\", \"Fare\", \"Pclass\"]\nscatter_matrix(train_data[attributes], figsize=(12, 8))","0f02122d":"titanic = train_data.drop(\"Survived\", axis=1)\ntitanic_labels = train_data[\"Survived\"].copy()","12aa2a86":"#data cleaning\n#Age, Cabin and Embarked have missing values\n#For Age, let's fill in the misssing values with the median age value\nmedian_age = titanic[\"Age\"].median()\ntitanic[\"Age\"].fillna(median_age, inplace=True)","f0d4e745":"#For Cabin, let's remove the entire column\ntitanic.drop('Cabin', axis=1, inplace=True)","9e706c29":"#For Embarked, let's drop the rows with missing values\ntitanic.dropna(inplace=True)","6283b241":"titanic.info()","35bd993d":"titanic.isnull().sum()","25abc93f":"#handling Text and Categorical Attributes\ntitanic['Sex'].value_counts() #sex is a categorical attribute","8a6b2611":"#let's convert these categorie from text to numbers\nfrom sklearn.preprocessing import OrdinalEncoder\nordinal_encoder = OrdinalEncoder()\ntitanic_sex = titanic[[\"Sex\"]]\ntitanic['Sex'] = ordinal_encoder.fit_transform(titanic_sex)\nprint(titanic['Sex'].head())\nprint(ordinal_encoder.categories_)","6206c953":"titanic['Embarked'].value_counts() #Embarked is a categorical attribute","6e652345":"titanic_embarked = titanic[[\"Embarked\"]]\ntitanic['Embarked'] = ordinal_encoder.fit_transform(titanic_embarked)\nprint(titanic['Embarked'].head())\nprint(ordinal_encoder.categories_)","96256ecb":"#Assuming PassengerId, Name and Ticket are not relevant to predicting a passenger's survival\n#We can drop them\npassangerId = titanic['PassengerId'].copy()\ntitanic.drop('PassengerId', axis=1, inplace=True)\ntitanic.drop('Name', axis=1, inplace=True)\ntitanic.drop('Ticket', axis=1, inplace=True)","61fdeb70":"#we can create custom transformers for custom cleanup operations such as the one we did on the train set\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass missingValuesTransformer(BaseEstimator, TransformerMixin):\n    def fit(self, trainData):\n        self.median_age = trainData[\"Age\"].median()\n        self.most_embarked = 'S'\n        self.median_fare = trainData[\"Fare\"].median()\n        return self\n    \n    def transform(self, data):\n        new_data = data.copy()\n        new_data[\"Age\"].fillna(self.median_age, inplace=True)\n        new_data.drop('Cabin', axis=1, inplace=True)\n        new_data[\"Embarked\"].fillna(self.most_embarked, inplace=True)\n        new_data[\"Fare\"].fillna(self.median_fare, inplace=True)\n        return(new_data)\n    \n    def fit_transform(self, trainData):\n        self.fit(trainData)\n        return self.transform(trainData)","958a6b2b":"class categoricalTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self.ordinal_encoder_sex = OrdinalEncoder()\n        self.ordinal_encoder_embarked = OrdinalEncoder()\n        \n    def fit(self, trainData):\n        self.train_data_sex = trainData[[\"Sex\"]]\n        self.ordinal_encoder_sex.fit(self.train_data_sex)\n        \n        self.train_data_embarked = trainData[[\"Embarked\"]]\n        self.ordinal_encoder_embarked.fit(self.train_data_embarked)\n        \n        return self\n    \n    def transform(self, data):\n        new_data = data.copy()\n        \n        new_data_sex = new_data[[\"Sex\"]]\n        new_data['Sex'] =  self.ordinal_encoder_sex.transform(new_data_sex)\n        \n        new_data_embarked = new_data[[\"Embarked\"]]\n        new_data['Embarked'] = self.ordinal_encoder_embarked.transform(new_data_embarked)\n        \n        return(new_data)\n    \n    def fit_transform(self, trainData):\n        self.fit(trainData)\n        return self.transform(trainData)","ecd79d64":"class customTransformer(BaseEstimator, TransformerMixin):\n    def fit(self, trainData):\n            return self\n    \n    def transform(self, data):\n        new_data = data.copy()\n        \n        passangerIds = new_data['PassengerId'].copy()\n        new_data.drop('PassengerId', axis=1, inplace=True)\n        new_data.drop('Name', axis=1, inplace=True)\n        new_data.drop('Ticket', axis=1, inplace=True)\n        \n        #labels = new_data[\"Survived\"].copy()\n        #new_data.drop(\"Survived\", axis=1, inplace=True)\n    \n        return(new_data, passangerIds)\n    \n    def fit_transform(self, trainData):\n        self.fit(trainData)\n        return self.transform(trainData)\n    ","0df59a39":"class Transformer(BaseEstimator, TransformerMixin):\n        def __init__(self):\n            self.missing_transformer = missingValuesTransformer()\n            self.categorical_transformer = categoricalTransformer()\n            self.custom_transformer = customTransformer()\n            \n        def fit(self, trainData):\n            self.custom_transformer.fit(\n                self.categorical_transformer.fit_transform(\n                    self.missing_transformer.fit_transform(trainData)))\n            return self\n        \n        def transform(self, data):\n            return self.custom_transformer.transform(\n                    self.categorical_transformer.transform(\n                        self.missing_transformer.transform(data)))\n        \n        def fit_transform(self, trainData):\n            self.fit(trainData)\n            return self.transform(trainData)","78deabc8":"transformer = Transformer()\ntitanic, train_passangerIds = transformer.fit_transform(train_data)\ntitanic_labels = titanic[\"Survived\"].copy()\ntitanic.drop(\"Survived\", axis=1, inplace=True)","b4d416db":"titanic.head(10)","0dc8c548":"titanic.info()","0ddbb823":"titanic.isnull().sum()","43c432a4":"print(titanic_labels.head())\nprint(len(titanic_labels))\n","e74301bf":"print(train_passangerIds.head())\nprint(len(train_passangerIds))","490c6592":"#from sklearn.preprocessing import MinMaxScaler\n#scaler = MinMaxScaler()\n#titanic = scaler.fit_transform(titanic)\n#print(titanic)","e754503d":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ntitanic = scaler.fit_transform(titanic)\nprint(titanic)","36c47cce":"#Decision Tree Model\nfrom sklearn.tree import DecisionTreeClassifier\ntree_cls = DecisionTreeClassifier(random_state=42)\ntree_cls.fit(titanic, titanic_labels)","edd02052":"#Some predictions\nsome_predictions = tree_cls.predict(titanic[:5])\nprint(\"Predictions\", some_predictions)","dd97491a":"print(\"Labels\", titanic_labels[:5])","8f28d9fe":"#Measuring the Accuracy on the training set\n\ntitanic_predictions = tree_cls.predict(titanic)\n(titanic_predictions == titanic_labels).value_counts()\/len(titanic_labels)","73d1478a":"#Measuring the Accuracy on the training set\nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(titanic_predictions, titanic_labels)*100\nprint(accuracy)","ae272abe":"#Evaluating using Cross-Validation\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(tree_cls, titanic, titanic_labels, scoring=\"accuracy\",\n                        cv=10)","d0045916":"def display(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std() )\n    ","9fe63c10":"display(scores)","45e91149":"#We can see that the Decision Tree Model didn't perform as well as it did on the whole training set","5c764055":"#Random Forest Model\nfrom sklearn.ensemble import RandomForestClassifier\nforest_clf = RandomForestClassifier(random_state=1)\nforest_clf.fit(titanic, titanic_labels)","0bb09550":"titanic_predictions = forest_clf.predict(titanic)\n(titanic_predictions == titanic_labels).value_counts()\/len(titanic_labels)","e8ef9ab2":"scores = cross_val_score(forest_clf, titanic, titanic_labels, scoring=\"accuracy\",\n                        cv=10)","5418a4dd":"display(scores)","77c0ee75":"#Support Vector Machine Model\nfrom sklearn import svm\nsvm_clf = svm.SVC()\nsvm_clf.fit(titanic, titanic_labels)\n","c9e1fd45":"#Some predictions\nsome_predictions = svm_clf.predict(titanic[:5])\nprint(\"Predictions\", some_predictions)\nprint(\"Labels\", titanic_labels[:5])","d2f6b951":"#Measuring the Accuracy on the whole training set\ntitanic_predictions = svm_clf.predict(titanic)\n(titanic_predictions == titanic_labels).value_counts()\/len(titanic_labels)\n","3623af0f":"scores = cross_val_score(svm_clf, titanic, titanic_labels, scoring=\"accuracy\",\n                        cv=10)\ndisplay(scores)","e2fa822c":"#Let's fine tune the two best performing models, which were Random Forest Model and SVM Model","8e5afdaf":"from sklearn.model_selection import GridSearchCV\nforest_param_grid =[\n    {\n        'n_estimators': [10,50,100, 150, 200, 500],\n    \n    },\n    {\n        'n_estimators': [10,50,100, 150, 200, 500],\n        'bootstrap': [False]\n    }\n]","aef457c2":"forest_clf = RandomForestClassifier(random_state=1)\ngrid_search = GridSearchCV(forest_clf, \n                           forest_param_grid, \n                           cv=10, \n                           scoring='accuracy',\n                           return_train_score=True\n                          )\ngrid_search.fit(titanic, titanic_labels)","bd4fcaac":"grid_search.best_params_","8801fa66":"grid_search.best_estimator_","42db90e8":"grid_search.best_score_","bea90ad7":"svm_param_grid =[\n    {'kernel':('linear', 'rbf'), 'C':[1, 10]},\n]\n\nsvm_clf = svm.SVC()\n\ngrid_search = GridSearchCV(svm_clf, \n                           svm_param_grid, \n                           cv=10, \n                           scoring='accuracy',\n                           return_train_score=True\n                          )\ngrid_search.fit(titanic, titanic_labels)\ngrid_search.best_params_","a8a1c76e":"grid_search.best_score_ ","20853278":"model = grid_search.best_estimator_\nmodel","de01869c":"model.fit(titanic, titanic_labels)","8db06493":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","18eee563":"test_data.info()","7e6d0670":"X_test, test_passangerIds = transformer.transform(test_data)\nX_test.info()","43d200f1":"X_test['Embarked'].value_counts()","2de39726":"X_test_prepared = scaler.transform(X_test)\nX_test_prepared","4748a981":"predictions = model.predict(X_test_prepared)\nprint(predictions[:5])","2acb122b":"output = pd.DataFrame({'PassengerId': test_passangerIds, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","2d3a0595":"# Select and Train a Model","4b1afc5b":"# Creating a submission file","190a402d":"# Custom transformers","d4ce16eb":"# Taking a quick look at the data structure ","96ace472":"# feature scaling","29ca0d19":"# Fine-Tune the model","1f713909":"# Prepare the data form Machine Learning Algorithms","01f9a7a5":"# Seeking for correlations"}}