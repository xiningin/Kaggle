{"cell_type":{"2f46b532":"code","3d53b3cf":"code","deeca48b":"code","1cfb5d77":"code","fb93795e":"code","0650c6c9":"code","392f884e":"code","955d2244":"code","0235d64f":"markdown","3e5c22a8":"markdown","68788ce5":"markdown","aa91a2f6":"markdown","bee71005":"markdown","4d64a288":"markdown","240df1ad":"markdown","fe930927":"markdown","2ac51384":"markdown","718cebe1":"markdown","85c2f32f":"markdown"},"source":{"2f46b532":"# Generic\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os, warnings, gc\nwarnings.filterwarnings(\"ignore\")\n\n# SKLearn\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, brier_score_loss, log_loss\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.calibration import CalibratedClassifierCV, calibration_curve\n\n# Plot\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.express as px\nimport plotly.graph_objects as go","3d53b3cf":"# Data Load\nurl = '..\/input\/all-datasets-for-practicing-ml\/Class\/Class_Ionosphere.csv'\ndata = pd.read_csv(url, header='infer')\n\n# Total Classes\nprint(\"Total Classes: \", data.Class.nunique())\n\n''' Prep '''\nencoder = LabelEncoder()\ndata['Class']= encoder.fit_transform(data['Class']) \n\n''' Split '''\ncolumns = data.columns\ntarget = ['Class']   \nfeatures = columns [:-1]\n\nX = data[features]\ny = data[target]\n\n# Training = 90% & Validation = 10% \nsample_weight = np.random.RandomState(42).rand(y.shape[0])\ntest_size = 0.1\nX_train, X_val, y_train, y_val,sw_train, sw_test  = train_test_split(X, y, sample_weight, test_size=test_size, random_state=0, shuffle=True) \n\n\n''' Feature Scaling '''\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_val = sc.transform(X_val)","deeca48b":"'''Gaussian Naive-Bayes (no calibration)'''\ngnb = GaussianNB()\ngnb.fit(X_train,y_train)  # GaussianNB itself does not support sample-weights\nprob_pos_gnb = gnb.predict_proba(X_val)[:, 1]\n\n'''Gaussian Naive-Bayes (isotonic calibration)'''\ngnb_isotonic = CalibratedClassifierCV(gnb, cv='prefit', method=\"isotonic\")\ngnb_isotonic.fit(X_train, y_train, sample_weight=sw_train)\nprob_pos_gnbiso = gnb_isotonic.predict_proba(X_val)[:, 1]\n\n'''Gaussian Naive-Bayes (sigmoid  calibration)'''\ngnb_sigmoid = CalibratedClassifierCV(gnb, cv='prefit', method=\"sigmoid\")\ngnb_sigmoid.fit(X_train, y_train, sample_weight=sw_train)\nprob_pos_gnbsig = gnb_sigmoid.predict_proba(X_val)[:, 1]\n\nprint(\"Brier scores: (should be low)\\n\")\n\ngnb_score = brier_score_loss(y_val, prob_pos_gnb, sample_weight=sw_test)\nprint(\"GaussianNB Brier Score (no calibration) : %1.3f\" % gnb_score)\n\ngnb_iso_score = brier_score_loss(y_val, prob_pos_gnbiso, sample_weight=sw_test)\nprint(\"GaussianNB Brier Score (with isotonic) : %1.3f\" % gnb_iso_score)\n\ngnb_sig_score = brier_score_loss(y_val, prob_pos_gnbsig, sample_weight=sw_test)\nprint(\"GaussianNB Brier Score (with sigmoid) : %1.3f\" % gnb_sig_score)","1cfb5d77":"plt.figure(figsize=(15,10))\norder = np.lexsort((prob_pos_gnb, ))\n\nplt.plot(prob_pos_gnb[order], 'r', label='No calibration (%1.3f)' % gnb_score)\nplt.plot(prob_pos_gnbiso[order], 'g', linewidth=3, label='Isotonic calibration (%1.3f)' % gnb_iso_score)\nplt.plot(prob_pos_gnbsig[order], 'b', linewidth=3, label='Sigmoid calibration (%1.3f)' % gnb_sig_score)\n\nplt.ylim([-0.05, 1.05])\n\nplt.xlabel(\"Instances Sorted according to Predicted Probability \" \"(uncalibrated GNB)\")\nplt.ylabel(\"P(y=1)\")\nplt.legend(loc=\"upper left\")\nplt.title(\"Gaussian naive Bayes Probabilities\", fontsize=20)\n\nplt.show()","fb93795e":"fig = plt.figure(figsize=(15, 10))\nax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\nax2 = plt.subplot2grid((3, 1), (2, 0))\n\nax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n\nfrac_of_pos, mean_pred_val = calibration_curve(y_val, prob_pos_gnb, n_bins=10)\nfrac_of_pos_iso, mean_pred_val_iso = calibration_curve(y_val, prob_pos_gnbiso, n_bins=10)\nfrac_of_pos_sig, mean_pred_val_sig = calibration_curve(y_val, prob_pos_gnbsig, n_bins=10)\n\nax1.plot(mean_pred_val, frac_of_pos, \"s-\", label='No calibration (%1.3f)' % gnb_score)\nax1.plot(mean_pred_val_iso, frac_of_pos_iso, \"s-\", label='Isotonic calibration (%1.3f)' % gnb_iso_score)\nax1.plot(mean_pred_val_sig, frac_of_pos_sig, \"s-\", label='Sigmoid calibration (%1.3f)' % gnb_sig_score)\n\nax2.hist(prob_pos_gnb, range=(0, 1), bins=10, label='No calibration', histtype=\"step\", lw=2)\nax2.hist(prob_pos_gnbiso, range=(0, 1), bins=10, label='Isotonic calibration', histtype=\"step\", lw=2)\nax2.hist(prob_pos_gnbsig, range=(0, 1), bins=10, label='Sigmoid calibration', histtype=\"step\", lw=2)\n\n\nax1.set_ylabel(\"Fraction of positives\")\nax1.set_ylim([-0.05, 1.05])\nax1.legend(loc=\"lower right\")\nax1.set_title('GaussianNB Calibration plots  (reliability curve)', fontsize=20)\n\nax2.set_xlabel(\"Mean predicted value\")\nax2.set_ylabel(\"Count\")\nax2.legend(loc=\"upper center\", ncol=2)\n\nplt.tight_layout()\n","0650c6c9":"# Create classifiers\nlr = LogisticRegression()\nknn = KNeighborsClassifier()\ndtc = DecisionTreeClassifier(random_state=42)\nrfc = RandomForestClassifier(random_state=42, verbose=0)\n\n'''Plot calibration plots'''\n\nplt.figure(figsize=(15, 10))\nax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\nax2 = plt.subplot2grid((3, 1), (2, 0))\n\nax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n\nfor clf, name in [(lr, 'Logistic'), (knn, 'KNN'), (gnb, 'NaiveBayes'),                   \n                  (dtc, 'DecisionTree'), (rfc, 'RandomForest')]:\n    \n    clf.fit(X_train,y_train)\n    prob_pos = clf.predict_proba(X_val)[:, 1]\n    fraction_of_positives, mean_predicted_value = calibration_curve(y_val, prob_pos, n_bins=10)\n\n    ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"%s\" % (name, ))\n    ax2.hist(prob_pos, range=(0, 1), bins=10, label=name, histtype=\"step\", lw=2)\n    \n\nax1.set_ylabel(\"Fraction of positives\")\nax1.set_ylim([-0.05, 1.05])\nax1.legend(loc=\"lower right\")\nax1.set_title('Classifier Calibration plots  (reliability curve)', fontsize=20)\n\nax2.set_xlabel(\"Mean predicted value\")\nax2.set_ylabel(\"Count\")\nax2.legend(loc=\"upper center\", ncol=2)\n\nplt.tight_layout()\nplt.show()\n    ","392f884e":"# Data Load\nurl = '..\/input\/all-datasets-for-practicing-ml\/Class\/Class_Abalone.csv'\ndf = pd.read_csv(url, header='infer')\n\n# Total Classes\nprint(\"Total Classes: \", df.Sex.nunique())\n\n''' Prep '''\nencoder = LabelEncoder()\ndf['Sex']= encoder.fit_transform(df['Sex']) \n\n''' Split '''\ncolumns = df.columns\ntarget = ['Sex']   \nfeatures = columns [1:]\n\nX = df[features]\ny = df[target]\n\n# Training = 90% & Validation = 10% \n#test_size = 0.1\n#X_train, X_val, y_train, y_val  = train_test_split(X, y, test_size=test_size, random_state=0, shuffle=True) \n\n\n\n''' Feature Scaling '''\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_val = sc.transform(X_val)","955d2244":"# Classifier\nknn = KNeighborsClassifier()\n\n# Train\nknn.fit(X_train,y_train)\n\n#Calc Probability\nknn_probs = knn.predict_proba(X_val)\nknn_score = log_loss(y_val,knn_probs)\n\n# Probability Calibration (sigmoid method)\nsig_knn = CalibratedClassifierCV(knn, method=\"sigmoid\", cv=\"prefit\")\nsig_knn.fit(X_train, y_train)\nsig_knn_probs = sig_knn.predict_proba(X_val)\nsig_knn_score = log_loss(y_val, sig_knn_probs)\n\n# Probability Calibration (sigmoid method)\niso_knn = CalibratedClassifierCV(knn, method=\"isotonic\", cv=\"prefit\")\niso_knn.fit(X_train, y_train)\niso_knn_probs = iso_knn.predict_proba(X_val)\niso_knn_score = log_loss(y_val, iso_knn_probs)\n\n\nprint(\"KNN Log Loss (no calibration) : %1.3f\" % knn_score)\nprint(\"KNN Log Loss (sigmoid) : %1.3f\" % sig_knn_score)\nprint(\"KNN Log Loss (isotonic) : %1.3f\" % iso_knn_score)\n\n","0235d64f":"#### We can observe that only the isotonic calibration is able to provide a good probability calibration with low Brier Loss score.","3e5c22a8":"# ** Bonus - Probability Calibration for multi-class classification **\n\nWe just saw how to calibrate the probability for GaussianNB and then compared it with other classifier models. The dataset had a binary classification, however in real world we'll not always get a dataset that has binary classification. Therefore we shall a quick look at performing Probability Calibration on multi-class dataset.\n\nFor this, we shall be using the [Abalone](https:\/\/archive.ics.uci.edu\/ml\/datasets\/abalone) dataset with KNN Classifier.","68788ce5":"#### GaussianNaiveBayes tends to push probabilities to 0 or 1. This is probably because it makes the assumption that features are conditionally independent given the class.\n\n#### RandomForest shows probability peaks approx between 0 & 0.2 and 0.8 & 1. The probabilities close to 0 or 1 are very rare.\n\n#### DecisionTree also tends to push probabilities to 0 or 1\n\n#### KNN tends to show peak at 0 , then at 0.4 and at 1.\n\n#### LogisticRegression shows probabilities between 0 & 0.2 and  0.8 & 1, not reaching the probability = 1","aa91a2f6":"# Probability Calibration using CalibratedClassifierCV (GaussianNB)","bee71005":"Here we can observe that the KNN Classifier trained on 4177 datapoints without any calibration incurs a huge log_loss, whereas the same classifier with sigmoid calibration method trained on 4177 datapoints has less log_loss.\n\nNote: In this case the Isotonic Calibration method is useless as it incurs huge log_loss","4d64a288":"# Probability Calibration\n\nIn this notebook, we're going to learn about **Probability Calibration** & how it is done using SKLearn modules. \n\n\n**Premise:** While performing a classification we need to know 2 things, \n\n1. Class Label (obviously!)\n2. Probablity with which the class label was predicted \n\nThis is because, the **probability** gives us a confidence about the prediction that has been made. Having said that, there are certain models that can give you the class probabilities but they're rather poor estimates, while other models do not even support the probability. \n\n**Solution:** This is where the SKLearn's **calibration module** comes into picture. This module allows us to better calibrate the probabilities of a given model, or to add support for probability prediction. A well calibrated classifiers are probabilistic classifiers for which the output of the **predict_proba** method can be directly interpreted as a **confidence level**. \n\nExample, a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a **predict_proba** value close to 0.8, approximately 80% actually belong to the positive class.\n\nSKLearn achieves the Probability Calibration through:\n\n1. CalibratedClassifierCV class [regressor to calibrate a classifier]\n2. calibration_curve [plot the calibrated classifier]\n\n\n#### In this tutorial we'll use the [Ionosphere dataset (binary)](https:\/\/archive.ics.uci.edu\/ml\/datasets\/Ionosphere) & then \n\n* Calibrate the **GaussianNB** Classifier with the help of **CalibratedClassifierCV** using **Sigmoid** & **Isotonic** methods of calibration &\n* Plot the curve using **calibration_curve**.\n\n\n#### After that we'll\n\n* Compare & plot the calibration of **GaussianNB**, **KNN**, **Support Vector Machine** & **Random Forest** \n\n\n\n### As always, I'll keep the notebook fairely organized & well commented for easy reading. Please do consider it to **UPVOTE** if you think it is helpful :-).","240df1ad":"# Plot Predicted Probabilities (without calibration_curve)","fe930927":"# Data Load, Prep & Split","2ac51384":"# Libraries","718cebe1":"# Calibration Comparison (GaussianNB, KNN, DecisionTree & Random Forest)","85c2f32f":"# Plot Predicted Probabilities (with calibration_curve)"}}