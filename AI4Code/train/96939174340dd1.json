{"cell_type":{"7d4838f9":"code","37a7f5aa":"code","867f0d76":"code","09a87643":"code","68e00b51":"code","5c7e53db":"code","b97393e1":"code","e58cb20b":"code","d9bb9e7a":"code","5ecd45ac":"code","7397953e":"code","88265711":"code","6fa99b07":"code","df410665":"code","e1f61c84":"code","af3fb004":"code","82860e0a":"code","134a4534":"code","bc08eac2":"code","34dd6127":"code","eb8f1172":"code","297eba83":"code","6255d1dc":"code","fc984b5c":"code","d02eae86":"code","42183a57":"code","c2b832be":"code","68c241e2":"code","1047b999":"code","b4f7e9fb":"code","8b4fa748":"code","9868094d":"code","1dfb11ca":"code","4a39e1ef":"code","caf44630":"code","47ac512a":"code","6f47808b":"code","776cd501":"code","e162f699":"code","54130c10":"code","b2b93a07":"code","4f227bc9":"code","34f91b46":"code","2aa4bb18":"code","f270ea37":"code","a966ea6b":"code","ac8dcfae":"code","fde2e471":"code","6b839f22":"code","b817d00e":"code","9bbc094f":"code","181e44c7":"code","66507a79":"code","16599ba7":"code","e34afde6":"code","077690a5":"code","6caf3167":"code","98eceb46":"code","83f1bd16":"code","dc0b0d8a":"code","3cb74a07":"code","abb5b54f":"code","70aead1e":"code","1ef66d55":"code","7064dbda":"code","06da4605":"code","23c76ee3":"code","3395e136":"code","665be22b":"code","5fc2a188":"code","21931f3b":"code","b2581c41":"code","ab635fc7":"code","128b17b5":"code","19f39777":"code","9afc41e2":"markdown","2c204b21":"markdown","c621be86":"markdown","ddbb1e21":"markdown","77ab0cbb":"markdown","10c32807":"markdown","5027b704":"markdown","192f0fd8":"markdown","a6d9764d":"markdown","f87a9a54":"markdown","69bcf512":"markdown","32df0eea":"markdown","7442cc5f":"markdown","eaa3687d":"markdown","8f32abb1":"markdown","9b1e3862":"markdown","1f01538d":"markdown","10405487":"markdown","8e9e0fda":"markdown","7bbc9602":"markdown","32398c17":"markdown","8b0ac988":"markdown","952b3128":"markdown","a24e0709":"markdown","1ac36a0d":"markdown","12fabcce":"markdown","de64ae22":"markdown","9641c5d3":"markdown","de94a0da":"markdown","a6ff59ac":"markdown","19d651f7":"markdown","7f3ad5de":"markdown","062a3af8":"markdown","e7334e5a":"markdown","5da33b5c":"markdown","d13ee684":"markdown","c4af5004":"markdown","c2887ccd":"markdown","beda20b5":"markdown","811215d5":"markdown","03a0f988":"markdown","f0992eb8":"markdown","a5c86e31":"markdown"},"source":{"7d4838f9":"# packages\n\n# standard\nimport numpy as np\nimport pandas as pd\nimport time\n\n# plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Statistics\nimport scipy.stats as stats\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# ML tools\nimport h2o\nfrom h2o.estimators import H2ORandomForestEstimator\nfrom h2o.estimators import H2OGradientBoostingEstimator","37a7f5aa":"# load data\ndf = pd.read_csv('..\/input\/cern-electron-collision-data\/dielectron.csv')\ndf.head()","867f0d76":"# dimension of table\ndf.shape","09a87643":"# structure of data frame\ndf.info()","68e00b51":"# clean column names\ndf.rename(columns = {'px1 ':'px1'}, inplace = True)","5c7e53db":"# frequencies of run\ndf.Run.value_counts().plot(kind='bar')\nplt.grid()\nplt.title('Run')\nplt.show()","b97393e1":"# events: a few of them occur more than once!\nmultis = df.Event.value_counts() # get counts\nmultis = multis[multis.values>1] # filter by frequency > 1\nmultis","e58cb20b":"# extract ids\nmultis_ids = multis.index.to_list()\nprint(multis_ids)\n# and show corresponding rows\ndf[df.Event.isin(multis_ids)].sort_values('Event')","d9bb9e7a":"df[df.Event==418006834]","5ecd45ac":"# we fix the situation by changing the Event for the second row\ndf.loc[79612,'Event'] = 418006835 # use a number that is not yet in use!\n# and adjust our duplicate list\nmultis_ids.remove(418006834)\n# check:\ndf[df.Event==418006834]","7397953e":"# remove duplicates\ndf = df.drop_duplicates(subset='Event')","88265711":"# check for missing values in the target\ndf.M.isna().sum()","6fa99b07":"# remove the rows having missing targets for the following as it's only a very small fraction\ndf = df[~df.M.isna()]\ndf.shape","df410665":"# plot target\nplt.figure(figsize=(10,6))\ndf.M.plot(kind='hist', bins=100)\nplt.title('Distribution of M - The invariant mass of two electrons (GeV).')\nplt.grid()\nplt.show()","e1f61c84":"# stats for target; adding a few more percentiles compared to standard output\ndf.M.describe(percentiles=[0.01,0.1,0.25,0.5,0.75,0.9,0.99])","af3fb004":"df.Q1.value_counts().plot(kind='bar')\nplt.title('Q1 - Charge of electron 1')\nplt.grid()\nplt.show()\n\ndf.Q2.value_counts().plot(kind='bar')\nplt.title('Q2 - Charge of electron 2')\nplt.grid()\nplt.show()","82860e0a":"# define numeric features\nfeatures_num = ['E1', 'px1', 'py1', 'pz1', 'pt1', 'eta1', 'phi1', \n                'E2', 'px2', 'py2', 'pz2', 'pt2', 'eta2', 'phi2']","134a4534":"# summary stats, adding a few more percentiles compared to standard output\ndf[features_num].describe(percentiles=[0.01,0.1,0.25,0.5,0.75,0.9,0.99])","bc08eac2":"# combo plot hist \/ boxplot\nfor f in features_num:\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,8))\n    ax1.hist(df[f], bins=100)\n    ax1.grid()\n    ax1.set_title(f)\n    ax2.boxplot(df[f], vert=False)\n    ax2.grid()   \n    ax2.set_title(f + '- boxplot')\n    plt.show()","34dd6127":"# Pearson correlation\ncorr_pearson = df[features_num].corr(method='pearson')\n\nfig = plt.figure(figsize = (14,8))\nsns.heatmap(corr_pearson, annot=True, cmap='RdYlGn',\n            vmin=-1, vmax=1)\nplt.title('Pearson Correlation')\nplt.show()","eb8f1172":"# Spearman (Rank) correlation\ncorr_spearman = df[features_num].corr(method='spearman')\n\nfig = plt.figure(figsize = (14,8))\nsns.heatmap(corr_spearman, annot=True, cmap='RdYlGn',\n            vmin=-1, vmax=1)\nplt.title('Spearman Correlation')\nplt.show()","297eba83":"plt.scatter(df.E1, df.pt1, alpha=0.1)\nplt.xlabel('E1')\nplt.ylabel('pt1')\nplt.grid()\nplt.show()","6255d1dc":"plt.scatter(df.E2, df.pt2, alpha=0.1)\nplt.xlabel('E2')\nplt.ylabel('pt2')\nplt.grid()\nplt.show()","fc984b5c":"plt.scatter(df.py1, df.phi1, alpha=0.1)\nplt.xlabel('py1')\nplt.ylabel('phi1')\nplt.grid()\nplt.show()","d02eae86":"plt.scatter(df.py2, df.phi2, alpha=0.1)\nplt.xlabel('py2')\nplt.ylabel('phi2')\nplt.grid()\nplt.show()","42183a57":"plt.scatter(df.pz1, df.eta1, alpha=0.1)\nplt.xlabel('pz1')\nplt.ylabel('eta1')\nplt.grid()\nplt.show()","c2b832be":"plt.scatter(df.pz2, df.eta2, alpha=0.1)\nplt.xlabel('pz2')\nplt.ylabel('eta2')\nplt.grid()\nplt.show()","68c241e2":"# cross table for electron charges\npd.crosstab(df.Q1, df.Q2)","1047b999":"df['Q12'] = df.Q1 * df.Q2\ndf['Q12'].value_counts().plot(kind='bar')\nplt.title('Q1 = Q1*Q2')\nplt.grid()\nplt.show()","b4f7e9fb":"# scatter plot including correlation figure\nfor f in features_num:\n    c = np.round(df[f].corr(df.M, method='spearman'),4) # correlation\n    plt.scatter(df[f], df.M, alpha=0.1)\n    plt.title('Target vs '+f+' - corr_sp='+str(c))\n    plt.grid()\n    plt.show()","8b4fa748":"for f in ['Q1','Q2','Q12']:\n    sns.violinplot(data=df, x=f, y='M')\n    plt.title('Target vs '+f)\n    plt.grid()\n    plt.show()","9868094d":"corr_method='spearman'","1dfb11ca":"df['px12'] = df.px1 * df.px2\n# calc correlation with target and visualize\nfor f in ['px1','px2','px12']:\n    c = np.round(df[f].corr(df.M, method='spearman'),4) # correlation\n    plt.scatter(df[f], df.M, alpha=0.1)\n    plt.title('Target vs '+f+' - corr_sp='+str(c))\n    plt.grid()\n    plt.show()","4a39e1ef":"df['py12'] = df.py1 * df.py2\n# calc correlation with target and visualize\nfor f in ['py1','py2','py12']:\n    c = np.round(df[f].corr(df.M, method='spearman'),4) # correlation\n    plt.scatter(df[f], df.M, alpha=0.1)\n    plt.title('Target vs '+f+' - corr_sp='+str(c))\n    plt.grid()\n    plt.show()","caf44630":"df['pz12'] = df.pz1 * df.pz2\n# calc correlation with target and visualize\nfor f in ['pz1','pz2','pz12']:\n    c = np.round(df[f].corr(df.M, method='spearman'),4) # correlation\n    plt.scatter(df[f], df.M, alpha=0.1)\n    plt.title('Target vs '+f+' - corr_sp='+str(c))\n    plt.grid()\n    plt.show()","47ac512a":"df['phi12'] = df.phi1 * df.phi2\n# calc correlation with target and visualize\nfor f in ['phi1','phi2','phi12']:\n    c = np.round(df[f].corr(df.M, method='spearman'),4) # correlation\n    plt.scatter(df[f], df.M, alpha=0.1)\n    plt.title('Target vs '+f+' - corr_sp='+str(c))\n    plt.grid()\n    plt.show()","6f47808b":"df['eta12'] = df.eta1 * df.eta2\n# calc correlation with target and visualize\nfor f in ['eta1','eta2','eta12']:\n    c = np.round(df[f].corr(df.M, method='spearman'),4) # correlation\n    plt.scatter(df[f], df.M, alpha=0.1)\n    plt.title('Target vs '+f+' - corr_sp='+str(c))\n    plt.grid()\n    plt.show()","776cd501":"df['pt12'] = df.pt1 * df.pt2\n# calc correlation with target and visualize\nfor f in ['pt1','pt2','pt12']:\n    c = np.round(df[f].corr(df.M, method='spearman'),4) # correlation\n    plt.scatter(df[f], df.M, alpha=0.1)\n    plt.title('Target vs '+f+' - corr_sp='+str(c))\n    plt.grid()\n    plt.show()","e162f699":"df['E12'] = df.E1 * df.E2\n# calc correlation with target and visualize\nfor f in ['E1','E2','E12']:\n    c = np.round(df[f].corr(df.M, method='spearman'),4) # correlation\n    plt.scatter(df[f], df.M, alpha=0.1)\n    plt.title('Target vs '+f+' - corr_sp='+str(c))\n    plt.grid()\n    plt.show()","54130c10":"# select predictors\npredictors = features_num + ['Q1','Q2']\nprint('Number of predictors: ', len(predictors))\nprint(predictors)\n\n# define target\ntarget='M'","b2b93a07":"# start H2O\nh2o.init(max_mem_size='12G', nthreads=4) # Use maximum of 12 GB RAM and 4 cores","4f227bc9":"# upload data frame in H2O environment\ndf_hex = h2o.H2OFrame(df)\n\n# train \/ test split (80\/20)\ntrain_perc = 0.8\ntrain_hex, test_hex = df_hex.split_frame(ratios=[train_perc], seed=999)","34f91b46":"# export train\/test for external processing\ndf_train = train_hex.as_data_frame()\ndf_test = test_hex.as_data_frame()\n\ndf_train.to_csv('df_train.csv')\ndf_test.to_csv('df_test.csv')","2aa4bb18":"# # define (distributed) Random Forest model\n# fit_1 = H2ORandomForestEstimator(ntrees=100,\n#                                    max_depth=15,\n#                                    min_rows=1,\n#                                    nfolds=5,\n#                                    seed=999)","f270ea37":"# define Gradient Boosting model\nfit_1 = H2OGradientBoostingEstimator(ntrees = 801,\n                                     max_depth=4,\n                                     min_rows=15,\n                                     sample_rate=0.9,\n                                     col_sample_rate=0.7,\n                                     nfolds=5,\n                                     seed=999)","a966ea6b":"# train model - this takes a few minutes...\nt1 = time.time()\nfit_1.train(x=predictors,\n            y=target,\n            training_frame=train_hex)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","ac8dcfae":"# show training scoring history\nplt.rcParams['figure.figsize']=(7,4)\nfit_1.plot()","fde2e471":"# show cross validation metrics\nfit_1.cross_validation_metrics_summary()","6b839f22":"# show scoring history - training vs cross validations\nfor i in range(5):\n    cv_model_temp = fit_1.cross_validation_models()[i]\n    df_cv_score_history = cv_model_temp.score_history()\n    my_title = 'CV ' + str(1+i) + ' - Scoring History [RMSE]'\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.training_rmse, \n                c='blue', label='training')\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.validation_rmse, \n                c='darkorange', label='validation')\n    plt.title(my_title)\n    plt.xlabel('Number of Trees')\n    plt.legend()\n    plt.grid()\n    plt.show()","b817d00e":"# variable importance using shap values => see direction as well as severity of feature impact\nt1 = time.time()\nfit_1.shap_summary_plot(train_hex);\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","9bbc094f":"# predict on training data\npred_train = fit_1.predict(train_hex)\ny_train_act = train_hex.as_data_frame()[target].values # actuals\ny_train_pred = pred_train.as_data_frame().predict.values # predictions","181e44c7":"# plot predictions vs actual\np=sns.jointplot(y_train_act, y_train_pred,\n              joint_kws={'alpha' : 0.1})\np.fig.suptitle('Prediction vs Actual - Training Data')\nplt.xlabel('Actual')\nplt.ylabel('Prediction')\nplt.show()","66507a79":"print('Correlations - Training Data')\nprint('Correlation Pearson:', stats.pearsonr(y_train_act, y_train_pred))\nprint('Correlation Spearman:', stats.spearmanr(y_train_act, y_train_pred))","16599ba7":"# metrics on training data\nprint('MAE (train): ', np.round(mean_absolute_error(y_train_act, y_train_pred),2))\nprint('RMSE(train): ', np.round(np.sqrt(mean_squared_error(y_train_act, y_train_pred)),2))","e34afde6":"# predict on test data\npred_test = fit_1.predict(test_hex)\ny_test_act = test_hex.as_data_frame()[target].values # actual values\ny_test_pred = pred_test.as_data_frame().predict.values # predictions","077690a5":"# plot predictions vs actuals\np=sns.jointplot(y_test_act, y_test_pred,\n              joint_kws={'alpha' : 0.1})\np.fig.suptitle('Prediction vs Actual - Test Data')\nplt.xlabel('Actual')\nplt.ylabel('Prediction')\nplt.show()","6caf3167":"print('Correlations - Test Set')\nprint('Correlation Pearson:', stats.pearsonr(y_test_act, y_test_pred))\nprint('Correlation Spearman:', stats.spearmanr(y_test_act, y_test_pred))","98eceb46":"# metrics on test data\nprint('MAE (test): ', np.round(mean_absolute_error(y_test_act, y_test_pred),2))\nprint('RMSE(test): ', np.round(np.sqrt(mean_squared_error(y_test_act, y_test_pred)),2))","83f1bd16":"# update predictors\npredictors = features_num + ['Q1','Q2'] + ['Q12', 'px12', 'py12', 'pz12', 'pt12', 'phi12', 'eta12', 'E12']\nprint('Number of predictors: ', len(predictors))\nprint(predictors)","dc0b0d8a":"# define Gradient Boosting model\nfit_2 = H2OGradientBoostingEstimator(ntrees = 801,\n                                     max_depth=4,\n                                     min_rows=15,\n                                     sample_rate=0.9,\n                                     col_sample_rate=0.7,\n                                     nfolds=5,\n                                     seed=999)","3cb74a07":"# train model - this takes a few minutes...\nt1 = time.time()\nfit_2.train(x=predictors,\n            y=target,\n            training_frame=train_hex)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","abb5b54f":"# show training scoring history\nplt.rcParams['figure.figsize']=(7,4)\nfit_2.plot()","70aead1e":"# show cross validation metrics\nfit_2.cross_validation_metrics_summary()","1ef66d55":"# show scoring history - training vs cross validations\nfor i in range(5):\n    cv_model_temp = fit_2.cross_validation_models()[i]\n    df_cv_score_history = cv_model_temp.score_history()\n    my_title = 'CV ' + str(1+i) + ' - Scoring History [RMSE]'\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.training_rmse, \n                c='blue', label='training')\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.validation_rmse, \n                c='darkorange', label='validation')\n    plt.title(my_title)\n    plt.xlabel('Number of Trees')\n    plt.legend()\n    plt.grid()\n    plt.show()","7064dbda":"# variable importance using shap values => see direction as well as severity of feature impact\nt1 = time.time()\nfit_2.shap_summary_plot(train_hex);\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","06da4605":"# predict on training data\npred_train = fit_2.predict(train_hex)\ny_train_act = train_hex.as_data_frame()[target].values # actuals\ny_train_pred = pred_train.as_data_frame().predict.values # predictions","23c76ee3":"# plot predictions vs actuals\np=sns.jointplot(y_train_act, y_train_pred,\n              joint_kws={'alpha' : 0.1})\np.fig.suptitle('Prediction vs Actual - Training Data')\nplt.xlabel('Actual')\nplt.ylabel('Prediction')\nplt.show()","3395e136":"print('Correlations - Training Data')\nprint('Correlation Pearson:', stats.pearsonr(y_train_act, y_train_pred))\nprint('Correlation Spearman:', stats.spearmanr(y_train_act, y_train_pred))","665be22b":"# metrics on training data\nprint('MAE (train): ', np.round(mean_absolute_error(y_train_act, y_train_pred),2))\nprint('RMSE(train): ', np.round(np.sqrt(mean_squared_error(y_train_act, y_train_pred)),2))","5fc2a188":"# predict on test data\npred_test = fit_2.predict(test_hex)\ny_test_act = test_hex.as_data_frame()[target].values # actual values\ny_test_pred = pred_test.as_data_frame().predict.values # predictions","21931f3b":"# plot predictions vs actuals\np=sns.jointplot(y_test_act, y_test_pred,\n              joint_kws={'alpha' : 0.1})\np.fig.suptitle('Prediction vs Actual - Test Data')\nplt.xlabel('Actual')\nplt.ylabel('Prediction')\nplt.show()","b2581c41":"print('Correlations - Test Set')\nprint('Correlation Pearson:', stats.pearsonr(y_test_act, y_test_pred))\nprint('Correlation Spearman:', stats.spearmanr(y_test_act, y_test_pred))","ab635fc7":"# metrics on test data\nprint('MAE (test): ', np.round(mean_absolute_error(y_test_act, y_test_pred),2))\nprint('RMSE(test): ', np.round(np.sqrt(mean_squared_error(y_test_act, y_test_pred)),2))","128b17b5":"# select individual row from training data\nmy_row = 1\ntrain_hex[my_row,:]","19f39777":"# show detailed explanations for this prediction\nfit_2.explain_row(frame=train_hex, row_index=my_row);","9afc41e2":"### Predict and evaluate performance on training data:","2c204b21":"# Predict invariant mass of two electrons in particle collision events using Gradient Boosting and the power of Feature Engineering\n\n## Table of Contents\n* [Admin Columns](#1)\n* [Target Distribution](#2)\n* [Feature Distributions](#3)\n* [Feature Correlations](#4)\n* [Target vs Features](#5)\n* [Feature Engineering](#6)\n* [Gradient Boosting Model w\/o Feature Engineering](#7)\n* [Gradient Boosting Model using Feature Engineering](#8)\n* [Local Explanations](#9)\n\n### The features are not self-explanatory, so here is a copy of the data description:\n\nRun: The run number of the event.\n\nEvent: The event number.\n\nE1, E2: The total energy of the electron (GeV) for electrons 1 and 2.\n\npx1, py1, pz1, px2, py2, pz2: The components of the momemtum of the electron 1 and 2 (GeV).\n\npt1, pt2: The transverse momentum of the electron 1 and 2 (GeV).\n\neta1, eta2: The pseudorapidity of the electron 1 and 2.\n\nphi1, phi2: The phi angle of the electron 1 and 2 (rad).\n\nQ1, Q2: The charge of the electron 1 and 2.\n\nM: The invariant mass of two electrons (GeV) <= OUR TARGET","c621be86":"### Wow, this is an unreal improvement! Our RMSE (on CV) is now less then half compared to the first model!!!","ddbb1e21":"### Charges of electron 1 and 2","77ab0cbb":"<a id='1'><\/a>\n# Admin Columns","10c32807":"### Numerical Features","5027b704":"### The improved performance is also clearly visible in our scatter plot.","192f0fd8":"#### The plot confirms that neither Q1 nor Q2 have relevant predictive power.","a6d9764d":"#### We have 13 runs of varying size.","f87a9a54":"### Predict and evaluate performance on test set:","69bcf512":"#### Again, almost symmetric. However, combinations with different signs are more frequent than those having same signs. Let's try to add the product of the two charges (+1 if both have same sign, -1 if they have different signs) to our features:","32df0eea":"### Predict and evaluate performance on test set:","7442cc5f":"### Feature distributions","eaa3687d":"#### Interestingly the two rows are even from different runs... maybe a bug?","8f32abb1":"<a id='5'><\/a>\n# Target vs Features","9b1e3862":"### We cannot really see a significant impact of each Q1 and Q2 on the target.\n### But the product Q12 = Q1*Q2 seems to make a difference!","1f01538d":"## Let's check if our feature engineering (products feature_1 * feature_2) can improve our model:","10405487":"### Events","8e9e0fda":"<a id='4'><\/a>\n# Feature Correlations","7bbc9602":"#### Multiple event occurrences are duplicates, only exception being Event=418006834:","32398c17":"#### A few interesting scatter plots (we pick the ones having the highest correlation):","8b0ac988":"### Ok, this is somewhat surprising. None of the features px1\/2, py1\/2, pz1\/2, phi1\/2 and eta1\/2 shows a significant correlation with the target, but all the products do!!!","952b3128":"<a id='6'><\/a>\n# Feature Engineering","a24e0709":"### Also the more predictive features show the effect that the product seems more predictive than each of the factors!","1ac36a0d":"## Let's first build a model using just the original features:","12fabcce":"### Predict and evaluate performance on training data","de64ae22":"### Let's check if this \"product trick\" works also with other features:","9641c5d3":"<a id='8'><\/a>\n# Gradient Boosting Model using Feature Engineering\n","de94a0da":"<a id='3'><\/a>\n# Feature Distributions","a6ff59ac":"### Also the performance on the test set is more than twice as good!","19d651f7":"### Electron charges","7f3ad5de":"### Interesting shape, we have a concentration on the minimum value of 2 and two further peaks.","062a3af8":"### We keep the same hyper-parameters for the sake of simplicity:","e7334e5a":"### Runs","5da33b5c":"#### Nicely balanced!","d13ee684":"### Electron Charges","c4af5004":"<a id='7'><\/a>\n# Gradient Boosting Model w\/o Feature Engineering","c2887ccd":"<a id='9'><\/a>\n# Local Explanations","beda20b5":"### Not bad, but let's see what we can achieve with our feature engineering...","811215d5":"#### Finally, remove remaining duplicates:","03a0f988":"### Numerical Features","f0992eb8":"#### We have 85 rows without a target value.","a5c86e31":"<a id='2'><\/a>\n# Target Distribution"}}