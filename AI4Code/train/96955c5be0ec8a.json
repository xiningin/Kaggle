{"cell_type":{"0ee5032d":"code","ae32a786":"code","4cb9d817":"code","c84f88b8":"code","a199ea8c":"code","7f4f75de":"code","116923bb":"code","ad683cb2":"code","30036989":"code","072e0b3e":"code","b1dd7127":"code","ddc8ec3b":"code","a402a865":"code","43e88c95":"code","6519b66b":"code","fae94b65":"code","9a5895cc":"markdown","9a71eb15":"markdown","abc21053":"markdown","4161beba":"markdown","f3b1665c":"markdown","29b74bd8":"markdown","fcba5377":"markdown","16db5882":"markdown","448191f2":"markdown","0154bf7b":"markdown","c3251449":"markdown","6c453dc1":"markdown"},"source":{"0ee5032d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout, Flatten, Activation, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf","ae32a786":"test_data = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntrain_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')","4cb9d817":"test_data.head()","c84f88b8":"train_data.head()","a199ea8c":"X_train = train_data.drop(labels=[\"label\"], axis=1)\ny_train = train_data[\"label\"]\n\nX_test = test_data","7f4f75de":"X_train = X_train \/ 255.\nX_test = X_test \/ 255.","116923bb":"print(\"Original X_train: \", X_train.shape)\nprint(\"Original X_test: \", X_test.shape)\n\nX_train = X_train.values.reshape(-1, 28, 28, 1)\nX_test = X_test.values.reshape(-1, 28, 28, 1)\n\nprint(\"Reshaped X_train: \", X_train.shape)\nprint(\"Reshaped X_test: \", X_test.shape)","ad683cb2":"y_train = to_categorical(y_train, num_classes=10)","30036989":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=144)","072e0b3e":"model = Sequential()\n\nmodel.add(Conv2D(filters = 64,\n                   kernel_size = (5, 5),\n                   padding = 'same',\n                   activation = 'relu',\n                   input_shape = (28, 28, 1)))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters = 64,\n               kernel_size = (3, 3),\n               padding = 'same',\n               activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters = 128,\n               kernel_size = (5, 5),\n               padding = 'same',\n               activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters = 128,\n               kernel_size = (3, 3),\n               padding = 'same',\n               activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(Dropout(0.4))\n\nmodel.add(Dense(10, activation = 'softmax'))\n\nmodel.summary()","b1dd7127":"model.compile(loss = 'categorical_crossentropy',\n                optimizer = Adam(),\n                metrics = ['accuracy'])","ddc8ec3b":"datagen = ImageDataGenerator(\n    rotation_range = 10,\n    horizontal_flip = False,\n    vertical_flip = False)\n\ndatagen.fit(X_train)","a402a865":"epochs = 30\nbatch_len = 64\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\nhistory = model.fit(datagen.flow(X_train, y_train, batch_size=batch_len),\n                   steps_per_epoch = len(X_train) \/\/ batch_len,\n                   epochs = epochs,\n                   validation_data = (X_val, y_val),\n                   callbacks = [learning_rate_reduction])","43e88c95":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'val'])\nplt.show()\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'val'])\nplt.show()","6519b66b":"res = model.predict(X_test)\nres = np.argmax(res, axis = 1)\nres = pd.Series(res, name=\"Label\")","fae94b65":"result = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),res],axis = 1)\n\nresult.to_csv(\"result.csv\",index=False)","9a5895cc":"# One-hot-encode\n* Since we want to classify our data into ten classes (for digits 0-9) we can one hot encode our y_train with 10 values.","9a71eb15":"# Normalize Data\n* The given images contain pixels with values in the range of 0-255\n* We want to normalize these values into a value between 0.0 and 1.0 in order to make calculations easier and allow our model to learn at a faster rate","abc21053":"# Predict Test Data\n* Using our model, we can predit which digit each of the images given in our test set is\n* Store our model's predictions in a csv file","4161beba":"# Train our Model\n* Fit the model over 30 epochs\n* Found that a batch size of 64 worked well\n* We use ReduceLROnPlateau in order to half the learning rate when the validation accuracy flattens out over 3 epochs, helping our model better locate a minimum during optimization","f3b1665c":"# Data Augmentation\n* Generate augmented data from our training training data using the ImageDataGenerator\n* We don't want to have generated data that is vertically or horizontally flipped, for the case of 9 and 6","29b74bd8":"# Create Validation Set\n* From our training data, we will extract a validation set to use when training our model\n* We will use a 90%-10% training-validation split","fcba5377":"# Preprocess Data\n* Split train data into X_train and y_train.\n    * X_train will consist of all columns except 'label' column\n    * y_train will consist of only the 'label' column\n* The given test data does not have a 'label' column, so no need for preprocessing","16db5882":"# Plot Loss and Accuracy","448191f2":"# Reshape Data\n* The data provided is formatted as 784 pixels, but we want to reshape our data to represent 28x28 pixel images","0154bf7b":"# Fetch data from CSV files\n* Provided with test.csv and train.csv\n* Read data in using Pandas\n* Inspect the data sets\n","c3251449":"# Create Model\n* Initialize a convolutional neural network\n* Utilize dropout layers in order to deal with the model overfitting\n* Compile the model using the Adam optimizer","6c453dc1":"# Imports\n* Import all modules used in this notebook"}}