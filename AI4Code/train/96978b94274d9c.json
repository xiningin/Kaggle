{"cell_type":{"c83d3957":"code","4b3c49ed":"code","6c084d7c":"code","71e92c56":"code","97206573":"code","71a97cfb":"code","0b15d66d":"code","74306aba":"code","5bf5d44f":"code","a82f0e75":"code","a91ee442":"code","93391c1b":"code","aba73129":"code","3f0a48ba":"code","88891386":"code","5fbdcf6c":"code","07519852":"code","4b886d68":"code","3a8bd671":"code","d51e57d2":"code","6e406024":"code","1aeab3ab":"code","6974d021":"code","76ab13b3":"code","d82947d3":"code","fa8fa934":"code","c33f8596":"code","5e4a128c":"code","a9f9cddc":"code","0e848f00":"code","ea81d175":"code","e18a6fcb":"code","b2d31f71":"code","f4a7a3f9":"code","db6de638":"code","8f678d22":"code","85df43cf":"code","73781fa9":"code","df64ec1e":"code","b41b6e90":"code","e6907f1e":"code","784a2dbd":"code","191e9b50":"code","f2505f30":"code","767882c0":"code","f9b4a13c":"code","085b81c5":"code","7bd19ba3":"code","cbd24268":"code","445599c6":"code","6328b75a":"code","04f09dfc":"code","79d841c7":"code","d42d7a48":"markdown","a3010b25":"markdown","9d59517a":"markdown","81665689":"markdown","260f10e5":"markdown","5ea0d4bc":"markdown","1aa08791":"markdown","dbb0920a":"markdown","b17552be":"markdown","f60b1af0":"markdown","1fa1bf1e":"markdown","ee5dab19":"markdown","ac3ddea3":"markdown","b365505a":"markdown","9aa23b58":"markdown","32c4fc60":"markdown","bad2184a":"markdown","174f41b5":"markdown","d8212c6b":"markdown"},"source":{"c83d3957":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4b3c49ed":"data = pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')","6c084d7c":"data.head(10)","71e92c56":"data.shape","97206573":"data.index","71a97cfb":"data.columns","0b15d66d":"data.describe()","74306aba":"data.info()","5bf5d44f":"pd.unique(data['Id'])","a82f0e75":"pd.unique(data['SepalLengthCm'])","a91ee442":"pd.value_counts(data['SepalLengthCm'])","93391c1b":"pd.unique(data['SepalWidthCm'])","aba73129":"pd.unique(data['PetalLengthCm'])","3f0a48ba":"pd.unique(data['PetalWidthCm'])","88891386":"pd.unique(data['Species'])","5fbdcf6c":"data.dtypes","07519852":"data.isnull().sum()","4b886d68":"data","3a8bd671":"data_encode = data.select_dtypes(include=['object']).copy()\ndata_encode.head()","d51e57d2":"pd.get_dummies(data_encode, columns=['Species']).head()","6e406024":"import matplotlib.pyplot as plt","1aeab3ab":"plt.hist(data['SepalLengthCm'], color = 'steelblue')\nplt.title('Frequency of SepalLengthCm')\nplt.xlabel('SepalLengthCm')\nplt.ylabel('Frequency')\nplt.show()","6974d021":"plt.hist(data['SepalLengthCm'],bins = 50, color = 'steelblue')","76ab13b3":"data2 = data.loc[12, :]\ndata2","d82947d3":"new_data = {'Id':  [151],\n        'SepalLengthMm': [48],\n         'SepalWidthMm' : [3],\n         'PetalLengthMm' : [14],\n         'PetalWidthMm' : [1],\n         'Species' : ['Iris-setosa']\n        }\n\ndata3 = pd.DataFrame(new_data)","fa8fa934":"data3","c33f8596":"data3.rename(columns = {'SepalLengthMm':'SepalLengthCm', 'SepalWidthMm':'SepalWidthCm', 'PetalLengthMm':'PetalLengthCm',\n                       'PetalWidthMm':'PetalWidthCm'}, inplace = True) ","5e4a128c":"data3","a9f9cddc":"data3.iloc[:, 1:5] = data3.iloc[:, 1:5] \/ 10","0e848f00":"data3","ea81d175":"data.append(data3, ignore_index=True)","e18a6fcb":"import seaborn as sns","b2d31f71":"pearsoncorr = data.corr(method='pearson')\npearsoncorr","f4a7a3f9":"sns.heatmap(pearsoncorr, \n            xticklabels=pearsoncorr.columns,\n            yticklabels=pearsoncorr.columns,\n            annot=True,\n            linewidth=0.5)","db6de638":"kendallcorr = data.corr(method='kendall')\nkendallcorr","8f678d22":"sns.heatmap(kendallcorr, \n            xticklabels=kendallcorr.columns,\n            yticklabels=kendallcorr.columns,\n            annot=True,\n            linewidth=0.5)","85df43cf":"spearmancorr = data.corr(method='spearman')\nspearmancorr","73781fa9":"sns.heatmap(kendallcorr, \n            xticklabels=spearmancorr.columns,\n            yticklabels=spearmancorr.columns,\n            annot=True,\n            linewidth=0.5)","df64ec1e":"from sklearn import preprocessing\n\nx = data.iloc[:, 1:5].values\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\ndata_min_max = pd.DataFrame(x_scaled)","b41b6e90":"data_min_max","e6907f1e":"data_min_max['Species'] = data['Species']","784a2dbd":"data_min_max","191e9b50":"from scipy.stats import zscore\ndata_z_score = data.iloc[:, 1:5]\nnumeric_cols = data_z_score.select_dtypes(include=[np.number]).columns\ndata_z_score[numeric_cols].apply(zscore)","f2505f30":"z_score = data_z_score[numeric_cols].apply(zscore)","767882c0":"plt.hist(data['SepalLengthCm'], color = 'steelblue')\nplt.title('Frequency of SepalLengthCm (Original)')\nplt.xlabel('SepalLengthCm')\nplt.ylabel('Frequency')\nplt.show()","f9b4a13c":"plt.hist(data_min_max[0], color = 'steelblue')\nplt.title('Frequency of SepalLengthCm (Min-Max normalization)')\nplt.xlabel('SepalLengthCm')\nplt.ylabel('Frequency')\nplt.show()","085b81c5":"plt.hist(z_score['SepalLengthCm'], color = 'steelblue')\nplt.title('Frequency of SepalLengthCm (Z-score normalization)')\nplt.xlabel('SepalLengthCm')\nplt.ylabel('Frequency')\nplt.show()","7bd19ba3":"from sklearn.decomposition import PCA\npca = PCA(n_components=2)\nprincipalComponents = pca.fit_transform(z_score)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component 1', 'principal component 2'])\nprincipalDf","cbd24268":"finalDf = pd.concat([principalDf, data_min_max[['Species']]], axis = 1)\nfinalDf","445599c6":"fig = plt.figure(figsize = (8,8))\nax = fig.add_subplot(1,1,1) \nax.set_xlabel('Principal Component 1', fontsize = 15)\nax.set_ylabel('Principal Component 2', fontsize = 15)\nax.set_title('2 component PCA', fontsize = 20)\ntargets = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\ncolors = ['r', 'g', 'b']\nfor target, color in zip(targets,colors):\n    indicesToKeep = finalDf['Species'] == target\n    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n               , finalDf.loc[indicesToKeep, 'principal component 2']\n               , c = color\n               , s = 50)\nax.legend(targets)\nax.grid()","6328b75a":"import random","04f09dfc":"data_sample_w = data\nsampled_list_w = data_sample_w.sample(n=3, replace=True, random_state=1)\nsampled_list_w","79d841c7":"data_sample_wo = data\nsampled_list_wo = data_sample_wo.sample(n=3, replace=False, random_state=1)\nsampled_list_wo","d42d7a48":"Equal Width Binning (In-built feature in the matplotlib)","a3010b25":"# **Data Transformation**","9d59517a":"# **Sampling**","81665689":"Sampling without replacement","260f10e5":"# **Data Reduction : PCA**","5ea0d4bc":"As there is no missing data, there no need for handling for missing data by removing rows, or filling missing values with mean, median, most_frequent\nBut if there is vavlues missing in the dataset, one can tackle it by these methods:\n - Drop Row: \n > DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n - Replace missing value with mean, meadian or most frequent of that column:\n > DataFrame.replace(to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')\n","1aa08791":"Creating a new dataset for data integration","dbb0920a":"# **Binning**","b17552be":"Data Encoding using One Hot Encoder","f60b1af0":"Sampling with replacement","1fa1bf1e":"**Inserting Data and Inspecting**","ee5dab19":"Pearson Correlation\n![image.png](attachment:image.png)","ac3ddea3":"# **Correlations**","b365505a":"Spearman Correlation\n![image.png](attachment:image.png)\nd(i) = difference between the two ranks of each observation","9aa23b58":"Kendall Correlation\n![image.png](attachment:image.png)","32c4fc60":"The first array represents the no. of elements in the particular,\nwhile the second array represents the boundaries of the bins","bad2184a":"Check for missing data","174f41b5":"![image.png](attachment:image.png)","d8212c6b":"# **Data Integration**"}}