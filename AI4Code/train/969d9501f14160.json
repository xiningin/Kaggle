{"cell_type":{"d3d37a5a":"code","3575cda6":"code","d591e8fa":"code","21e5509b":"code","d493d673":"markdown","ff93068e":"markdown","011d91b4":"markdown","a937b441":"markdown"},"source":{"d3d37a5a":"import tensorflow as tf\nimport keras\nfrom keras.datasets import cifar10\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, BatchNormalization\nfrom keras.optimizers import SGD\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nstyle.use('bmh')","3575cda6":"# load dataset\n(train_X, train_y), (test_X, test_y) = cifar10.load_data()\n\n# summarize loaded dataset\nprint('Train: X=%s, y=%s' % (train_X.shape, train_y.shape))\nprint('Test: X=%s, y=%s' % (test_X.shape, test_y.shape))\n\n# plot first few images\nfor i in range(9):\n    plt.subplot(330 + 1 + i)\n    plt.imshow(train_X[i])\n\nplt.show()","d591e8fa":"# load train and test dataset\ndef load_dataset():\n    # load dataset\n    (train_X, train_y), (test_X, test_y) = cifar10.load_data()\n    # one hot encode target values\n    train_y = to_categorical(train_y)\n    test_y = to_categorical(test_y)\n    return train_X, train_y, test_X, test_y\n \n    \n# scale pixels\ndef preprocess_data(train, test):\n    # convert from integers to floats\n    train_norm = train.astype('float32')\n    test_norm = test.astype('float32')\n    # normalize to range 0-1\n    train_norm = train_norm \/ 255.0\n    test_norm = test_norm \/ 255.0\n    # return normalized images\n    return train_norm, test_norm\n \n    \n# plot diagnostic learning curves\ndef plot_diagnostics(history):\n    plt.figure(figsize=(10,10))\n    # plot loss\n    plt.subplot(211)\n    plt.title('Cross Entropy Loss')\n    plt.plot(history.history['loss'], color='blue', label='train')\n    plt.plot(history.history['val_loss'], color='orange', label='test')\n    plt.legend(loc='best')\n    # plot accuracy\n    plt.subplot(212)\n    plt.title('Classification Accuracy')\n    plt.plot(history.history['accuracy'], color='blue', label='train')\n    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n    plt.legend(loc='best')\n\n\n# Run the test harness for evaluating a model\ndef run_test_harness(model, batch_size, epochs, model_id):\n    # load dataset\n    train_X, train_y, test_X, test_y = load_dataset()\n    # prepare pixel data\n    train_X, test_X = preprocess_data(train_X, test_X)\n    # create data generator\n    data_gen = ImageDataGenerator(width_shift_range=0.1, \n                                  height_shift_range=0.1, \n                                  horizontal_flip=True)\n    # prepare iterator\n    train_iterator = data_gen.flow(train_X, train_y, batch_size=batch_size)\n    # fit model\n    steps = int(train_X.shape[0] \/ batch_size)\n    history = model.fit_generator(train_iterator, \n                                  steps_per_epoch=steps, \n                                  epochs=epochs, \n                                  validation_data=(test_X, test_y), \n                                  verbose=0)\n    # evaluate model\n    _, acc = model.evaluate(test_X, test_y, verbose=0)\n    print('\\nModel accuracy: %.3f' % (acc * 100.0))\n    # plot learning curves\n    plot_diagnostics(history)\n    # save model\n    model.save('model_{}.h5'.format(model_id))","21e5509b":"# define CNN model\ndef define_model():    \n    model = Sequential()\n    \n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32,32,3)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.2))\n    \n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.3))\n    \n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.4))\n    \n    model.add(Flatten())\n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(10, activation='softmax'))\n    # compile model\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    print(model.summary())\n    return model\n\n\n# create CNN model\ncnn_model_01 = define_model()\n\n# entry point, run the test harness\nrun_test_harness(cnn_model_01, batch_size=64, epochs=400, model_id='2020-08-06-1')","d493d673":"# Load and check dataset","ff93068e":"# Run CNN model","011d91b4":"# Define general functions","a937b441":"## Model accuracy: 90.41"}}