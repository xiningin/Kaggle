{"cell_type":{"3667affc":"code","fe8f5755":"code","ded46ef2":"code","7f659efa":"code","17b18075":"code","d7f39456":"code","d2f62a0a":"code","23ad6f1c":"code","62f5c808":"code","2afc1777":"code","e40b2b09":"code","d7b58f77":"code","e7092b0d":"code","43e86a2f":"code","3d72e05c":"code","55cd3c7d":"code","6736fdad":"code","eb379605":"code","b553e607":"code","bee6c81b":"code","8d3a6ad7":"code","47ff9c04":"code","68b343dd":"code","8b6c1862":"code","76fe6357":"code","e4c07193":"markdown","63afebc0":"markdown","1aee0b7e":"markdown","dd614095":"markdown","b14acfb3":"markdown","d4b61dc9":"markdown","936bac02":"markdown","a73671a7":"markdown","40aa2a43":"markdown","f60ddbb4":"markdown","52b45680":"markdown","68877f73":"markdown","aa0aafe6":"markdown","fc63b008":"markdown","8bdf8e57":"markdown","bde06de7":"markdown"},"source":{"3667affc":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n \n%matplotlib inline","fe8f5755":"df = pd.read_csv('..\/input\/mobile-health\/mhealth_raw_data.csv')\ndf","ded46ef2":"df.info()","7f659efa":"df.Activity.value_counts()","17b18075":"from sklearn.utils import resample\n \ndf_majority = df[df.Activity==0]\ndf_minorities = df[df.Activity!=0]\n \ndf_majority_downsampled = resample(df_majority,n_samples=30000, random_state=42)\ndf = pd.concat([df_majority_downsampled, df_minorities])\ndf.Activity.value_counts()","d7f39456":"df.isnull().sum()","d2f62a0a":"#Dropping duplicates\ndf = df.drop(df[df.duplicated(keep = 'first')].index, axis=0)","23ad6f1c":"df.Activity.value_counts()","62f5c808":"label_map = {\n    0: 'Nothing',\n    1: 'Standing still',  \n    2: 'Sitting and relaxing', \n    3: 'Lying down',  \n    4: 'Walking',  \n    5: 'Climbing stairs',  \n    6: 'Waist bends forward',\n    7: 'Frontal elevation of arms', \n    8: 'Knees bending (crouching)', \n    9: 'Cycling', \n    10: 'Jogging', \n    11: 'Running', \n    12: 'Jump front & back' \n}","2afc1777":"#Defining functions to visualize comparisons.\ndef plot_comparison(data, metric = 'acceleration'):\n \n  metric = metric[0].lower()\n  data = data\n \n  for i in range(0,13):\n    plt.figure(figsize=(16,4))\n \n    plt.subplot(1,2,1)\n    plt.plot(data[ data['Activity']==i ].reset_index(drop=True)[metric+'lx'], alpha=.7, label=metric+'lx')\n    plt.plot(data[ data['Activity']==i ].reset_index(drop=True)[metric+'ly'],color='red', alpha=.7, label=metric+'ly')\n    plt.plot(data[ data['Activity']==i ].reset_index(drop=True)[metric+'lz'],color='green', alpha=.7, label=metric+'lz')\n    plt.title(f'{label_map[i]} - left-ankle')\n    plt.legend()  \n \n    plt.subplot(1,2,2)\n    plt.plot(data[ data['Activity']==i ].reset_index(drop=True)[metric+'rx'], alpha=.7, label=metric+'rx')\n    plt.plot(data[ data['Activity']==i ].reset_index(drop=True)[metric+'ry'],color='red', alpha=.7, label=metric+'ry')\n    plt.plot(data[ data['Activity']==i ].reset_index(drop=True)[metric+'rz'],color='green', alpha=.7, label=metric+'rz')\n    plt.title(f'{label_map[i]} - right-lower-arm')\n    plt.legend() \n \n    plt.show()\n    print()\n \ndef plot_category(data,cat):\n  array = (data[cat].value_counts().sort_values(ascending=False)\/len(data))*100\n  plt.barh(array.index, width = array.values)\n  for index, value in enumerate(array.values):\n      plt.text(value + .5 , index, s= '{:.1f}%'.format(value))\n  plt.show()","e40b2b09":"plot_category(df,'Activity')\nplt.show()","d7b58f77":"plot_category(df,'subject')","e7092b0d":"subject1 = df[df['subject']=='subject1']\nsubject1.Activity.value_counts()","43e86a2f":"plot_category(subject1,'Activity')","3d72e05c":"plot_comparison(subject1,'acceleration')","55cd3c7d":"plot_comparison(subject1,'gyroscope')","6736fdad":"plt.plot(subject1[subject1.Activity == 8].reset_index(drop=True).head(500)['alx'])\nplt.plot(subject1[subject1.Activity == 8].reset_index(drop=True).head(500)['aly'], color='red')\nplt.plot(subject1[subject1.Activity == 8].reset_index(drop=True).head(500)['alz'], color='green')","eb379605":"plot_comparison(df)","b553e607":"plot_comparison(df,'gyroscope')","bee6c81b":"plt.figure(figsize=(8,6))\nfacetgrid = sns.FacetGrid(subject1, hue='Activity', height=6, aspect=2)\nfacetgrid.map(sns.distplot,'gly', hist=False).add_legend()\nplt.show()","8d3a6ad7":"plt.figure(figsize=(8,6))\nsns.boxplot(data=df)\nplt.show()","47ff9c04":"df.describe().T","68b343dd":"df1 = df.copy()","8b6c1862":"#Dropping feature have data outside 98% confidence interval\nfor feature in df1.columns[:-2]:\n  lower_range = np.quantile(df[feature],0.01)\n  upper_range = np.quantile(df[feature],0.99)\n  print(feature,'range:',lower_range,'to',upper_range)\n\n  df1 = df1.drop(df1[(df1[feature]>upper_range) | (df1[feature]<lower_range)].index, axis=0)\n  print('shape',df1.shape)","76fe6357":"plt.figure(figsize=(8,6))\nsns.boxplot(data=df1)\nplt.show()","e4c07193":"Clearly visible that static activites like sitting and lying down can be seperated from dynamic like cyclic and jumping. ","63afebc0":"# EDA of 1 subject data\nchecking data for 1 subject only","1aee0b7e":"Some activities are clearly seperated out from others.","dd614095":"Gyroscope data is much more clear,stable and follows a particular frequency cycle.","b14acfb3":"Again Static activites are more stable and  can be seperated from dynamic activities easily.","d4b61dc9":"All subjects contributes almost equally.","936bac02":"There are lots of outliers.","a73671a7":"Activity 12 has very less data points compare to rest of all as we have seen in full dataset.","40aa2a43":"Follow this ****[notebook](https:\/\/www.kaggle.com\/gaurav2022\/cnn-lstm-95)**** for Deep Learning modeling and predictions.","f60ddbb4":"If you have learn something new, Kindly upvote to help community :)\n\nYou can follow this ****[github repo](https:\/\/github.com\/G0rav\/Human_Activity_Recognition)**** for future advancments. ","52b45680":"Activity 12 has very less data points compare to rest of all.","68877f73":"# Importing data","aa0aafe6":"No null values.","fc63b008":"The data is highly inbalanced so resampling it.","8bdf8e57":"# EDA of Full Dataset","bde06de7":"# Data Cleaning"}}