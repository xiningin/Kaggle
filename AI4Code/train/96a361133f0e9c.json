{"cell_type":{"f372dd24":"code","0cd70c39":"code","769a52f9":"code","7a1e3a0f":"code","1f1b55f3":"code","7c07f133":"code","934d480c":"code","29a54c79":"code","ef18cfe0":"code","913528fa":"code","ca931d37":"markdown","96bdc602":"markdown","a0072dbf":"markdown","c0b6245a":"markdown","adc22c9c":"markdown","f27a4530":"markdown","e9d98b30":"markdown"},"source":{"f372dd24":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0cd70c39":"pip install git+https:\/\/github.com\/BindsNET\/bindsnet.git","769a52f9":"import os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport gc\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nimport torchvision\nfrom tqdm.notebook import tqdm\n\nfrom bindsnet.analysis.plotting import (\n    plot_assignments,\n    plot_input,\n    plot_performance,\n    plot_spikes,\n    plot_voltages,\n    plot_weights,\n)\nfrom bindsnet.datasets import MNIST\nfrom bindsnet.encoding import PoissonEncoder\nfrom bindsnet.evaluation import all_activity, assign_labels, proportion_weighting\nfrom bindsnet.models import DiehlAndCook2015\nfrom bindsnet.network.monitors import Monitor\nfrom bindsnet.utils import get_square_assignments, get_square_weights\n\nfrom sklearn.model_selection import train_test_split","7a1e3a0f":"train = pd.read_csv(r\"..\/input\/digit-recognizer\/train.csv\", dtype=np.float32)\ntest = pd.read_csv(r\"..\/input\/digit-recognizer\/test.csv\", dtype=np.float32)\nsubmission = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\n\ndata_train = (train.loc[:, train.columns != \"label\"].values\/255.).reshape(-1, 28, 28)\nlabel_train = train.label.values\nX_test = (test.values\/255.).reshape(-1, 28, 28)\n\nX_train, X_valid, y_train, y_valid = train_test_split(\n                                                      data_train,\n                                                      label_train,\n                                                      test_size=0.2,\n                                                      shuffle=True,\n                                                      random_state=2021\n                                                     ) \nX_train = torch.from_numpy(X_train)\ny_train = torch.from_numpy(y_train).type(torch.LongTensor)\n\nX_valid = torch.from_numpy(X_valid)\ny_valid = torch.from_numpy(y_valid).type(torch.LongTensor)\n\nX_test = torch.from_numpy(X_test)\n\ndel train, data_train, label_train","1f1b55f3":"n_train = len(y_train)\nn_test = 100\ntime = 250\ndt = 1.0\nintensity = 32\n\ntransform=transforms.Compose([transforms.Lambda(lambda x: x * intensity)])\n\ntrain_dataset = []\nfor i in range(n_train):\n    train_dataset.append({\"image\":X_train[i], \"encoded_image\": PoissonEncoder(time=time, dt=dt)(transform((X_train[i]).reshape(-1, 28, 28))), \"label\": y_train[i]})\n\nvalid_dataset = []\nfor i in range(n_test):\n    valid_dataset.append({\"image\":X_valid[i], \"encoded_image\": PoissonEncoder(time=time, dt=dt)(transform((X_valid[i]).reshape(-1, 28, 28))), \"label\": y_valid[i]})\n\ntest_dataset = []\nfor i in range(len(X_test)):\n    test_dataset.append({\"image\":X_test[i], \"encoded_image\": PoissonEncoder(time=time, dt=dt)(transform((X_test[i]).reshape(-1, 28, 28)))})","7c07f133":"print(\"Train data shape: \", train_dataset[0][\"encoded_image\"].numpy().shape)\nprint(\"Test data shape: \", test_dataset[0][\"encoded_image\"].numpy().shape)","934d480c":"gc.collect()\n\nseed = 0\nn_neurons = 100\nn_clamp = 1\nexc = 22.5\ninh = 120\ntheta_plus = 0.05\nprogress_interval = 10\nupdate_interval = 500\ntrain = True\nplot = True\ngpu = True\ndevice_id = 0\n\n# Sets up Gpu use\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nif gpu and torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed)\nelse:\n    torch.manual_seed(seed)\n    device = \"cpu\"\n    if gpu:\n        gpu = False\n\ntorch.set_num_threads(os.cpu_count() - 1)\nprint(\"Running on Device = \", device)\n\nif not train:\n    update_interval = n_test\n\nn_classes = 10\nn_sqrt = int(np.ceil(np.sqrt(n_neurons)))\nstart_intensity = intensity\nper_class = int(n_neurons \/ n_classes)\n\n# Build Diehl & Cook 2015 network.\nnetwork = DiehlAndCook2015(\n    n_inpt=784,\n    n_neurons=n_neurons,\n    exc=exc,\n    inh=inh,\n    dt=dt,\n    nu=[1e-10, 1e-3],  # 0.711\n    norm=78.4,\n    theta_plus=theta_plus,\n    inpt_shape=(1, 28, 28),\n)\n\n# Directs network to GPU\nif gpu:\n    network.to(\"cuda\")\n\n# Voltage recording for excitatory and inhibitory layers.\nexc_voltage_monitor = Monitor(network.layers[\"Ae\"], [\"v\"], time=time, device=device)\ninh_voltage_monitor = Monitor(network.layers[\"Ai\"], [\"v\"], time=time, device=device)\nnetwork.add_monitor(exc_voltage_monitor, name=\"exc_voltage\")\nnetwork.add_monitor(inh_voltage_monitor, name=\"inh_voltage\")\n\n# Load MNIST data.\n\"\"\"\ndataset = MNIST(\n    PoissonEncoder(time=time, dt=dt),\n    None,\n    root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\n    download=True,\n    transform=transforms.Compose(\n        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n    ),\n)\n\"\"\"\n\n# Create a dataloader to iterate and batch data\ndataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n\n# Record spikes during the simulation.\nspike_record = torch.zeros(update_interval, time, n_neurons, device=device)\n\n# Neuron assignments and spike proportions.\nassignments = -torch.ones_like(torch.Tensor(n_neurons), device=device)\nproportions = torch.zeros_like(torch.Tensor(n_neurons, n_classes), device=device)\nrates = torch.zeros_like(torch.Tensor(n_neurons, n_classes), device=device)\n\n# Sequence of accuracy estimates.\naccuracy = {\"all\": [], \"proportion\": []}\n\n# Labels to determine neuron assignments and spike proportions and estimate accuracy\nlabels = torch.empty(update_interval, device=device)\n\nspikes = {}\nfor layer in set(network.layers):\n    spikes[layer] = Monitor(network.layers[layer], state_vars=[\"s\"], time=time)\n    network.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)\n\n# Train the network.\nprint(\"Begin training.\\n\")\n\ninpt_axes = None\ninpt_ims = None\nspike_axes = None\nspike_ims = None\nweights_im = None\nassigns_im = None\nperf_ax = None\nvoltage_axes = None\nvoltage_ims = None\n\npbar = tqdm(total=n_train)\nfor (i, datum) in enumerate(dataloader):\n    if i > n_train:\n        break\n\n    image = datum[\"encoded_image\"]\n    label = datum[\"label\"]\n\n    if i % update_interval == 0 and i > 0:\n        # Get network predictions.\n        all_activity_pred = all_activity(spike_record, assignments, n_classes)\n        proportion_pred = proportion_weighting(\n            spike_record, assignments, proportions, n_classes\n        )\n\n        # Compute network accuracy according to available classification strategies.\n        accuracy[\"all\"].append(\n            100 * torch.sum(labels.long() == all_activity_pred).item() \/ update_interval\n        )\n        accuracy[\"proportion\"].append(\n            100 * torch.sum(labels.long() == proportion_pred).item() \/ update_interval\n        )\n\n        print(\n            \"\\nAll activity accuracy: %.2f (last), %.2f (average), %.2f (best)\"\n            % (accuracy[\"all\"][-1], np.mean(accuracy[\"all\"]), np.max(accuracy[\"all\"]))\n        )\n        print(\n            \"Proportion weighting accuracy: %.2f (last), %.2f (average), %.2f (best)\\n\"\n            % (\n                accuracy[\"proportion\"][-1],\n                np.mean(accuracy[\"proportion\"]),\n                np.max(accuracy[\"proportion\"]),\n            )\n        )\n\n        # Assign labels to excitatory layer neurons.\n        assignments, proportions, rates = assign_labels(\n            spike_record, labels, n_classes, rates\n        )\n\n    # Add the current label to the list of labels for this update_interval\n    labels[i % update_interval] = label[0]\n\n    # Run the network on the input.\n    choice = np.random.choice(int(n_neurons \/ n_classes), size=n_clamp, replace=False)\n    clamp = {\"Ae\": per_class * label.long() + torch.Tensor(choice).long()}\n    if gpu:\n        inputs = {\"X\": image.cuda().view(time, 1, 1, 28, 28)}\n    else:\n        inputs = {\"X\": image.view(time, 1, 1, 28, 28)}\n    network.run(inputs=inputs, time=time, clamp=clamp)\n\n    # Get voltage recording.\n    exc_voltages = exc_voltage_monitor.get(\"v\")\n    inh_voltages = inh_voltage_monitor.get(\"v\")\n\n    # Add to spikes recording.\n    spike_record[i % update_interval] = spikes[\"Ae\"].get(\"s\").view(time, n_neurons)\n\n    # Optionally plot various simulation information.    \n    if plot and i == 0:\n        inpt = inputs[\"X\"].view(time, 784).sum(0).view(28, 28)\n        input_exc_weights = network.connections[(\"X\", \"Ae\")].w\n        square_weights = get_square_weights(\n            input_exc_weights.view(784, n_neurons), n_sqrt, 28\n        )\n        square_assignments = get_square_assignments(assignments, n_sqrt)\n        voltages = {\"Ae\": exc_voltages, \"Ai\": inh_voltages}\n\n        inpt_axes, inpt_ims = plot_input(\n            image.sum(1).view(28, 28), inpt, label=label, axes=inpt_axes, ims=inpt_ims\n        )\n        spike_ims, spike_axes = plot_spikes(\n            {layer: spikes[layer].get(\"s\").view(time, 1, -1) for layer in spikes},\n            ims=spike_ims,\n            axes=spike_axes,\n        )\n        weights_im = plot_weights(square_weights, im=weights_im)\n        assigns_im = plot_assignments(square_assignments, im=assigns_im)\n        perf_ax = plot_performance(accuracy, x_scale=update_interval, ax=perf_ax)\n        voltage_ims, voltage_axes = plot_voltages(\n            voltages, ims=voltage_ims, axes=voltage_axes\n        )\n        plt.pause(1e-8)\n\n    network.reset_state_variables()  # Reset state variables.\n    pbar.set_description_str(\"Train progress: \")\n    pbar.update()\n\nprint(\"Progress: %d \/ %d \\n\" % (n_train, n_train))\nprint(\"Training complete.\\n\")\n\nprint(\"Testing....\\n\")\n\n# Load MNIST data.\n\"\"\"\ntest_dataset = MNIST(\n    PoissonEncoder(time=time, dt=dt),\n    None,\n    root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\n    download=True,\n    train=False,\n    transform=transforms.Compose(\n        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n    ),\n)\n\"\"\"\n\n# Sequence of accuracy estimates.\naccuracy = {\"all\": 0, \"proportion\": 0}\n\n# Record spikes during the simulation.\nspike_record = torch.zeros(1, int(time \/ dt), n_neurons, device=device)\n\n# Train the network.\nprint(\"\\nBegin testing\\n\")\nnetwork.train(mode=False)\n\npbar = tqdm(total=n_test)\nfor step, batch in enumerate(valid_dataset):\n    if step > n_test:\n        break\n    # Get next input sample.\n    inputs = {\"X\": batch[\"encoded_image\"].view(int(time \/ dt), 1, 1, 28, 28)}\n    if gpu:\n        inputs = {k: v.cuda() for k, v in inputs.items()}\n\n    # Run the network on the input.\n    network.run(inputs=inputs, time=time, input_time_dim=1)\n\n    # Add to spikes recording.\n    spike_record[0] = spikes[\"Ae\"].get(\"s\").squeeze()\n\n    # Convert the array of labels into a tensor\n    label_tensor = torch.tensor(batch[\"label\"], device=device)\n\n    # Get network predictions.\n    all_activity_pred = all_activity(\n        spikes=spike_record, assignments=assignments, n_labels=n_classes\n    )\n    proportion_pred = proportion_weighting(\n        spikes=spike_record,\n        assignments=assignments,\n        proportions=proportions,\n        n_labels=n_classes,\n    )\n\n    # Compute network accuracy according to available classification strategies.\n    #print(\"label: \", torch.sum(label_tensor.long()).item(), \"pred: \", all_activity_pred.item())\n    accuracy[\"all\"] += float(torch.sum(label_tensor.long() == all_activity_pred).item())\n    accuracy[\"proportion\"] += float(\n        torch.sum(label_tensor.long() == proportion_pred).item()\n    )\n\n    network.reset_state_variables()  # Reset state variables.\n\n    pbar.set_description_str(\n        f\"Accuracy: {(max(accuracy['all'] ,accuracy['proportion'] ) \/ (step+1)):.3}\"\n    )\n    pbar.update()\n\nprint(\"\\nAll activity accuracy: %.2f\" % (accuracy[\"all\"] \/ n_test))\nprint(\"Proportion weighting accuracy: %.2f \\n\" % (accuracy[\"proportion\"] \/ n_test))\n\nprint(\"Testing complete.\\n\")\n","29a54c79":"test_size = 15 #size of sampling\nncols = 5\nif test_size%ncols == 0:\n    nrows = test_size\/\/ncols\nelse:\n    nrows = test_size\/\/ncols+1\nheight = nrows * 3\nfig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, height))\nax = ax.ravel()\n\nfor step, batch in enumerate(valid_dataset):\n    if step >= test_size:\n        break\n    # Get next input sample.\n    inputs = {\"X\": batch[\"encoded_image\"].view(int(time \/ dt), 1, 1, 28, 28)}\n    if gpu:\n        inputs = {k: v.cuda() for k, v in inputs.items()}\n\n    # Run the network on the input.\n    network.run(inputs=inputs, time=time, input_time_dim=1)\n\n    # Add to spikes recording.\n    spike_record[0] = spikes[\"Ae\"].get(\"s\").squeeze()\n\n    # Convert the array of labels into a tensor\n    label_tensor = torch.tensor(batch[\"label\"], device=device)\n\n    # Get network predictions.\n    all_activity_pred = all_activity(\n        spikes=spike_record, assignments=assignments, n_labels=n_classes\n    )\n    proportion_pred = proportion_weighting(\n        spikes=spike_record,\n        assignments=assignments,\n        proportions=proportions,\n        n_labels=n_classes,\n    )\n    \n    #print(\"label: \", torch.sum(label_tensor.long()).item(), \"pred: \", all_activity_pred.item())\n    \n    ax[step].imshow(torch.tensor(batch[\"image\"]).to(\"cpu\").detach().numpy().squeeze())\n    ax[step].axis(\"off\")\n    title = (\"Label: {}  Prediction: {}\".format(torch.sum(label_tensor.long()).item(), all_activity_pred.item()))\n    ax[step].set_title(title)\n    network.reset_state_variables()  # Reset state variables.","ef18cfe0":"model_preds_all_activity = []\nmodel_preds_proportion = []\n\npbar = tqdm(total=len(X_test))\nfor step, batch in enumerate(test_dataset):\n    # Get next input sample.\n    inputs = {\"X\": batch[\"encoded_image\"].view(int(time \/ dt), 1, 1, 28, 28)}\n    if gpu:\n        inputs = {k: v.cuda() for k, v in inputs.items()}\n\n    # Run the network on the input.\n    network.run(inputs=inputs, time=time, input_time_dim=1)\n\n    # Add to spikes recording.\n    spike_record[0] = spikes[\"Ae\"].get(\"s\").squeeze()\n\n    # Convert the array of labels into a tensor\n    #label_tensor = torch.tensor(batch[\"label\"], device=device)\n\n    # Get network predictions.\n    all_activity_pred = all_activity(\n        spikes=spike_record, assignments=assignments, n_labels=n_classes\n    )\n    proportion_pred = proportion_weighting(\n        spikes=spike_record,\n        assignments=assignments,\n        proportions=proportions,\n        n_labels=n_classes,\n    )\n    model_preds_all_activity.append(all_activity_pred.item())\n    model_preds_proportion.append(proportion_pred.item())\n\n    network.reset_state_variables()  # Reset state variables.\n    \n    pbar.set_description_str(\"Test progress: \")\n    pbar.update()","913528fa":"submission[\"Label\"] = model_preds_all_activity\nsubmission.to_csv(\"submission.csv\", index=False)","ca931d37":"# SNN with BindsNet\nThis notebook is based on bindsnet example script \"Supervised_mnist.py\"\nand modified to use kaggle MNIST dataset.\n\nSee [https:\/\/github.com\/BindsNET\/bindsnet\/tree\/master\/examples\/mnist](https:\/\/github.com\/BindsNET\/bindsnet\/tree\/master\/examples\/mnist)","96bdc602":"# Modeling and Training","a0072dbf":"# Prediction of test dataset and making submission file","c0b6245a":"train\u30c7\u30fc\u30bf\u306eshape 1, 250, 1, 28, 28,  test\u30c7\u30fc\u30bf\u306eshape 250, 1, 28, 28","adc22c9c":"# Preprocessing and encoding of dataset for SNN input","f27a4530":"# Load train and test data","e9d98b30":"# See label and prediction of validation dataset"}}