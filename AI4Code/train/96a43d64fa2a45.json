{"cell_type":{"ed9ce17f":"code","d4426f85":"code","018a5171":"code","d42b9b7f":"code","75b6b44c":"code","e16d60aa":"code","efbfc5be":"code","89f7cb21":"code","67bf5d75":"code","034b296b":"code","5dbe2bc9":"code","d6214ae7":"code","6aeafb5e":"code","9ad5b9e9":"code","d6d5d541":"code","75c1999b":"code","0ac5a351":"code","00ccc017":"code","f247deda":"code","09fa7cf4":"code","2dbf3a35":"code","60dc3608":"code","aced95ec":"code","63022f2f":"code","e9101f41":"code","eea5f49a":"code","9d535c05":"code","0c8f5100":"code","f2629348":"code","0189809a":"code","3b6ab1fd":"code","5f0e9d4c":"code","160827ad":"code","4ac1f522":"code","27e591f6":"code","419f8319":"markdown","45cf4202":"markdown","d7a2ce6d":"markdown","a065ad91":"markdown","9f158568":"markdown","c77a0399":"markdown","634d139c":"markdown","37795ba6":"markdown","6fe66e17":"markdown","47ee754f":"markdown","a6578248":"markdown","6640ef39":"markdown","4df96921":"markdown","90fe52b5":"markdown","fb5bd8b7":"markdown"},"source":{"ed9ce17f":"import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score","d4426f85":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nfull_data = [train,test]","018a5171":"# we delete \"Cabin\" and \"Ticket\" features because not relevant\ndel train['Cabin']\ndel train['Ticket']\ndel test['Cabin']\ndel test['Ticket']","d42b9b7f":"train.isnull().sum()","75b6b44c":"test.isnull().sum()","e16d60aa":"# we add a \"Title\" feature with \"Name\" feature\nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","efbfc5be":"# let's check that all \"Name\" features had a \"Title\"\ntrain.isnull().sum()\ntest.isnull().sum()","89f7cb21":"# we realize some \"Title\" have few elements, so non relevant\npd.crosstab(train['Title'], train['Sex'])\npd.crosstab(test['Title'], test['Sex'])","67bf5d75":"# we regroup some \"Title\"\nfor dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Capt','Col','Countess','Don','Dona','Dr','Jonkheer','Lady','Major','Rev','Sir'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace(['Mlle','Ms'], 'Miss')\n    dataset['Title'] = dataset['Title'].replace(['Mme'], 'Mrs')","034b296b":"# we study \"Title\" impact on \"Survived\"\nprint(train[['Title','Survived']].groupby(['Title'], as_index=False).mean())","5dbe2bc9":"# we can now erase \"Name\"\ndel train['Name']\ndel test['Name']","d6214ae7":"# we deal with \"age\" missing values with \"sex\" and \"pclass\" median\ntrain['Age'] = train.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\ntest['Age'] = test.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))","6aeafb5e":"train.isnull().sum()\ntest.isnull().sum()","9ad5b9e9":"# we regroup \"age\"\ntrain['AgeBand'] = pd.qcut(train['Age'], 5)    \n\nfor dataset in full_data:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4","d6d5d541":"# we realize there is an issue on \"Master\" because they are not all classed as \"0\" and it is not  \npd.crosstab(train['Title'], train['Age'])","75c1999b":"# so we do it manually\ni = 0\nwhile i < len(train):\n    if train['Title'][i] == 'Master':\n        train['Age'][i] = 0\n    i = i + 1\n    \ni = 0\nwhile i < len(test):\n    if test['Title'][i] == 'Master':\n        test['Age'][i] = 0\n    i = i + 1\n\npd.crosstab(train['Title'], train['Age'])\npd.crosstab(test['Title'], test['Age'])\ndel train['AgeBand']","0ac5a351":"# We now need to deal with \"Embarked\" and \"Fare\" features\ntrain.isnull().sum()\ntest.isnull().sum()","00ccc017":"# There is 2 \"Embarked\" values missing in the train set. We will replace them by the most frequent value\n\n# most of the passengers come from Southampton\nmode_embarked = train['Embarked'].mode()[0]\n\nprint(mode_embarked)","f247deda":"# we fill the missing values with \"S\" for Southampton\ntrain['Embarked'] = train['Embarked'].fillna(mode_embarked)","09fa7cf4":"# there is no more \"Embarked\" missing values\ntrain.isnull().sum()","2dbf3a35":"# Note: by googling the name of missing embarked person, we would have seen that they embarked at Southampton","60dc3608":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in full_data:\n    dataset['Title'] = dataset['Title'].map(title_mapping)","aced95ec":"for dataset in full_data:\n    dataset['Fare'] = dataset['Fare'].fillna(dataset['Fare'].median())","63022f2f":"# no missing \"Fare\" values in the test set\ntrain.isnull().sum()\ntest.isnull().sum()\n# il n'y a plus de valeurs manquantes dans le test set","e9101f41":"# we regroup the \"Fare\" values in 4 groups\ntrain['FareBand'] = pd.qcut(train['Fare'], 4)\nprint(train[['FareBand','Survived']].groupby(['FareBand'], as_index=False).mean())\n\nfor dataset in full_data:\n    dataset.loc[ dataset['Fare'] <= 7.91, ['Fare'] ] = 0    \n    dataset.loc[ (dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), ['Fare'] ] = 1\n    dataset.loc[ (dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31.0), ['Fare'] ] = 2\n    dataset.loc[ (dataset['Fare'] > 31.0), ['Fare'] ] = 3\n\ndel train['FareBand']","eea5f49a":"for dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n    \ndel train['SibSp']\ndel train['Parch']    \ndel test['SibSp']\ndel test['Parch']","9d535c05":"X_train = train.iloc[:, 2:].values\nX_test = test.iloc[:, 1:].values\ny_train = train.iloc[:, 1].values","0c8f5100":"label = LabelEncoder()\nX_train[:, 1] = label.fit_transform(X_train[:, 1])\nX_test[:, 1] = label.fit_transform(X_test[:, 1])","f2629348":"label_e = LabelEncoder()\nX_train[:, 4] = label_e.fit_transform(X_train[:, 4])\nX_test[:, 4] = label_e.fit_transform(X_test[:, 4])","0189809a":"classifier = SVC(kernel='rbf')\nclassifier.fit(X_train, y_train)\n\ny_prediction = classifier.predict(X_test)","3b6ab1fd":"accuracies = cross_val_score(estimator = classifier,X=X_train, y=y_train, cv=10)","5f0e9d4c":"# mean() gives a good idea of our model accuracy (bias)\naccuracies.mean() # 82,4%","160827ad":"# std() gives us an idea of the standard deviation (variance)\naccuracies.std() # 3.3%","4ac1f522":"# submission\nresults = pd.Series(y_prediction,name=\"Survived\")\nsubmission = pd.concat([pd.Series(range(892,1310),name = \"PassengerID\"),results],axis = 1)\nsubmission.to_csv(\"submission.csv\", index=False)","27e591f6":"submission","419f8319":"\n# \"Embarked\" feature (missing + mapping)","45cf4202":"# Import dataset","d7a2ce6d":"# Matrices creation","a065ad91":"A huge thanks to the following notebooks from which I learnt a lot:\n\n- https:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial\n- https:\/\/www.kaggle.com\/sinakhorami\/titanic-best-working-classifier\n- https:\/\/www.kaggle.com\/yassineghouzam\/titanic-top-4-with-ensemble-modeling\n- https:\/\/www.kaggle.com\/wikaiqi\/titaniclearningqi\n- https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions\n\nGo check them out !","9f158568":"# \"FamilySize\" feature creation","c77a0399":"# Classifier creation + prediction","634d139c":"# Results","37795ba6":"# \"Fare\" feature (missing + mapping)","6fe66e17":"# Import libraries","47ee754f":"# Apply k-fold cross validation","a6578248":"# \"Title\" feature mapping","6640ef39":"# Features mapping","4df96921":"# Feature engineering","90fe52b5":"# Check for missing values","fb5bd8b7":"# \"Age\" feature (missing + mapping)"}}