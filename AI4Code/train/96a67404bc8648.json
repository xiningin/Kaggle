{"cell_type":{"33e16591":"code","bce2a0b5":"code","776c25e6":"code","d066295f":"code","2ae65030":"code","37712380":"code","1b112c8a":"code","a569fc44":"code","558ec3d6":"code","e4308512":"code","7330f0d8":"code","7f54edb1":"code","9c06b067":"code","dd0c7f0d":"code","99ed9f49":"code","28c1a6cf":"code","15a05a90":"code","2bf7d848":"code","a118779c":"code","fbfeace6":"code","6f16d295":"code","3e5dc151":"code","c30023f0":"code","1bd88191":"code","e0324f1f":"code","ea8739eb":"code","3c479d09":"code","ee38b028":"code","0e8856c8":"code","5acce47a":"code","307b5869":"code","fbf6a714":"code","1540c7e3":"code","32842895":"code","fb6f119d":"code","2dd37706":"code","54f25cae":"code","f837a969":"code","dd956aeb":"code","037023b0":"code","39443251":"code","4ba980cc":"code","22ca40db":"code","9b5ac7c1":"code","a4df2061":"code","5e7ffc88":"code","e7f29806":"code","97d1f388":"code","dee7fe7a":"code","ab423b2c":"code","08e17af2":"code","42873c4b":"markdown","3b96c82a":"markdown","9c5c775a":"markdown","d7dbd587":"markdown","60fb1c86":"markdown","d613f5d8":"markdown","eef3a963":"markdown","2dc37349":"markdown","5619af6a":"markdown","4d66046a":"markdown","7199d1ff":"markdown","6fee43db":"markdown","69f30119":"markdown","f3b28958":"markdown","fec2fe89":"markdown","a261ed15":"markdown","c3933adf":"markdown","17dab36b":"markdown","46d7233a":"markdown","48d0e431":"markdown","7aed2377":"markdown","3fc995fc":"markdown","ee199281":"markdown","5c475241":"markdown","4c75d331":"markdown","fa5565e7":"markdown","5acf6ce1":"markdown","9e7407a6":"markdown","ee9efffe":"markdown","b20a5959":"markdown","8d4a0d8c":"markdown"},"source":{"33e16591":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bce2a0b5":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","776c25e6":"%matplotlib inline\nsns.set_style(\"whitegrid\")\nplt.style.use(\"fivethirtyeight\")","d066295f":"df = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')\ndf.head()","2ae65030":"pd.set_option(\"display.float\", \"{:.2f}\".format)\ndf.describe()","37712380":"df.shape","1b112c8a":"df.info()","a569fc44":"df.target.value_counts().plot(kind=\"bar\", color=[\"red\", \"green\"])","558ec3d6":"df.exang.value_counts().plot(kind=\"bar\", color=[\"blue\", \"orange\"])","e4308512":"missing_values_count = df.isnull().sum()\n\ntotal_cells = np.product(df.shape)\n\ntotal_missing = missing_values_count.sum()\n\npercentage_missing = (total_missing\/total_cells)*100\nprint(percentage_missing)","7330f0d8":"NAN = [(c, df[c].isnull().mean()*100) for c in df]\nNAN = pd.DataFrame(NAN, columns=['column_name', 'percentage'])\nNAN","7f54edb1":"for i in df.columns:\n    print(df[i].unique())","9c06b067":"categorical_val = []\ncontinous_val = []\nfor column in df.columns:\n    \n    print(f\"{column} : {df[column].unique()}\")\n    if len(df[column].unique()) <= 10:\n        categorical_val.append(column)\n    else:\n        continous_val.append(column)","dd0c7f0d":"def draw_histograms(dataframe, features, rows, cols):\n    fig=plt.figure(figsize=(20,20))\n    for i, feature in enumerate(features):\n        ax=fig.add_subplot(rows,cols,i+1)\n        dataframe[feature].hist(bins=20,ax=ax,facecolor='blue')\n        ax.set_title(feature+\" Distribution\",color='Red')\n        \n    fig.tight_layout()  \n    plt.show()\ndraw_histograms(df,df.columns,6,3)","99ed9f49":"plt.figure(figsize=(15, 15))\n\nfor i, column in enumerate(categorical_val, 1):\n    plt.subplot(3, 3, i)\n    df[df[\"target\"] == 0][column].hist(bins=40, color='blue', label='Heart Disease = NO', alpha=1,width=0.2)\n    df[df[\"target\"] == 1][column].hist(bins=40, color='red', label='Heart Disease = YES', alpha=1,width=0.2)\n    plt.legend()\n    plt.xlabel(column)","28c1a6cf":"plt.figure(figsize=(15, 15))\n\nfor i, column in enumerate(continous_val, 1):\n    plt.subplot(3, 2, i)\n    df[df[\"target\"] == 0][column].hist(bins=35, color='blue', label='Have Heart Disease = NO', alpha=1)\n    df[df[\"target\"] == 1][column].hist(bins=35, color='red', label='Have Heart Disease = YES', alpha=1)\n    plt.legend()\n    plt.xlabel(column)","15a05a90":"y = df[\"target\"]\n\nsns.countplot(y)\n\n\ntarget_temp = df.target.value_counts()\n\nprint(target_temp)","2bf7d848":"print(\"Percentage of patience with heart problems: \"+str(y.where(y==1).count()*100\/303))\nprint(\"Percentage of patience with heart problems: \"+str(y.where(y==0).count()*100\/303))","a118779c":"ax=plt.subplots(1,1,figsize=(10,8))\ndf['target'].value_counts().plot.pie(autopct='%1.1f%%',shadow=True,figsize=(10,8))\nplt.title(\"Heart Diseases %\")\nplt.show()","fbfeace6":"print(df[\"sex\"].unique())\n\nsns.barplot(df[\"sex\"],y)","6f16d295":"print(df[\"cp\"].unique())\nsns.barplot(df[\"cp\"],y)","3e5dc151":"print(df[\"fbs\"].describe())\nprint(df[\"fbs\"].unique())\nsns.barplot(df[\"fbs\"],y)","c30023f0":"print(df[\"restecg\"].unique())\nsns.barplot(df[\"restecg\"],y)","1bd88191":"print(df[\"exang\"].unique())\nsns.barplot(df[\"exang\"],y)","e0324f1f":"print(df[\"slope\"].unique())\nsns.barplot(df[\"slope\"],y)","ea8739eb":"df[\"ca\"].unique()","3c479d09":"sns.countplot(df[\"ca\"])  ","ee38b028":"sns.barplot(df[\"ca\"],y) ","0e8856c8":"print(df[\"thal\"].unique())","5acce47a":"sns.barplot(df[\"thal\"],y)","307b5869":"sns.distplot(df[\"thal\"])","fbf6a714":"sns.histplot(data=df, x=\"chol\", hue=\"target\",multiple=\"stack\")","1540c7e3":"sns.histplot(data=df, x=\"chol\", hue='target',kde = True)","32842895":"plt.figure(figsize=(10, 8))\nsns.relplot(x='trestbps', y='chol',hue='target', data=df)","fb6f119d":"plt.figure(figsize=(10, 8))\nplt.scatter(df.age[df.target==1],df.thalach[df.target==1],color=\"red\")\nplt.scatter(df.age[df.target==0],\n            df.thalach[df.target==0],\n            c=\"blue\")\nplt.title(\"Heart Disease in function of Age and Max Heart Rate\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Max Heart Rate\")\nplt.legend([\"Disease\", \"No Disease\"]);","2dd37706":"corr_matrix = df.corr()\nfig, ax = plt.subplots(figsize=(15, 15))\nax = sns.heatmap(corr_matrix,\n                 annot=True,\n                 linewidths=0.5,\n                 fmt=\".2f\",\n                 cmap=\"YlGnBu\");\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)","54f25cae":"df.drop('target', axis=1).corrwith(df.target).plot(kind='bar',\n                                                   grid=True, figsize=(10, 8), \n                                                   title=\"Correlation with target\",color=\"red\")","f837a969":"categorical_val.remove('target')\ndataset = pd.get_dummies(df, columns = categorical_val)\n\nfrom sklearn.preprocessing import StandardScaler\n\ns_sc = StandardScaler()\ncol_to_scale = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\ndataset[col_to_scale] = s_sc.fit_transform(dataset[col_to_scale])","dd956aeb":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report","037023b0":"\ndef print_score(clf, X_train, y_train, X_test, y_test, train=True):\n    if train:\n        pred = clf.predict(X_train)\n        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n        print(\"Train Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n        \n    elif train==False:\n        pred = clf.predict(X_test)\n        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n        print(\"Test Result:\\n================================================\")        \n        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")","39443251":"from sklearn.model_selection import train_test_split","4ba980cc":"X = dataset.drop('target', axis=1)\ny = dataset.target","22ca40db":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nfrom sklearn.linear_model import LogisticRegression","9b5ac7c1":"model = LogisticRegression(solver='liblinear')\nmodel.fit(X_train, y_train)","a4df2061":"print_score(model, X_train, y_train, X_test, y_test, train=True)\nprint_score(model, X_train, y_train, X_test, y_test, train=False)","5e7ffc88":"test_score = accuracy_score(y_test, model.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, model.predict(X_train)) * 100\n\nresults_df = pd.DataFrame(data=[[\"Logistic Regression\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\nresults_df","e7f29806":"y_pred1 = model.predict(X_test)\nprint(classification_report(y_test, y_pred1))","97d1f388":"model.predict(X_train[:10])","dee7fe7a":"model.predict(X_test[:10])","ab423b2c":"import joblib","08e17af2":"heart_pred = 'final_model.sav'\njoblib.dump(model, heart_pred)","42873c4b":"## 'ca' feature","3b96c82a":"## First, analyse the target variable","9c5c775a":"## FBS feature","d7dbd587":"## Gathering information about the data","60fb1c86":"## Unique Values in our datasets","d613f5d8":"## Slope feature","eef3a963":"### Bar Plot of Target Values","2dc37349":"## We'll analyse 'sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca' and 'thal' features","5619af6a":"### Total percentage of data is missing","4d66046a":"## Train Test split","7199d1ff":"#### People with exang=1 i.e. Exercise induced angina are much less likely to have heart problem","6fee43db":"## Describing the data","69f30119":"# Data Visualisation","f3b28958":"#### We analyse that females are more likely to have heart problems than males","fec2fe89":"#### We analyse from above bargraph that chest pain of '0', i.e. the ones with typical angina are much less likely to have heart problems","a261ed15":"### Bar Plot of exercise induced angina","c3933adf":"#### Nothing to analyse from this graph","17dab36b":"## restecg feature","46d7233a":"## 'Chest Pain Type' feature","48d0e431":"### 'Sex' feature","7aed2377":"#### We analyse that people with restecg '1' and '0' are much more likely to have a heart disease than with restecg '2'","3fc995fc":"## Save the model","ee199281":"## Shape of data","5c475241":"## Import Dataset","4c75d331":"## 'exang' feature","fa5565e7":"## 'thal' feature","5acf6ce1":"# Import Important Libraries","9e7407a6":"#### We observe, that Slope '2' causes heart pain much more than Slope '0' and '1'","ee9efffe":"# Data Cleaning","b20a5959":"# Machine Learning Model","8d4a0d8c":"# Thank You "}}