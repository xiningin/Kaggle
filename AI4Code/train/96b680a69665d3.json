{"cell_type":{"ec66b623":"code","bf09651e":"code","56e56540":"code","58b3a371":"code","2932dd34":"code","3b63b0be":"code","69137b4d":"code","1c51904f":"code","306b45d1":"code","54983082":"code","7abb1b7f":"markdown","234d55b7":"markdown","968436ba":"markdown","f3a789d0":"markdown","840679ef":"markdown","ff8e18ff":"markdown","ecbfc2b6":"markdown","107cceff":"markdown","0c11b1d9":"markdown"},"source":{"ec66b623":"#importing packages and reading the data\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nfrom sklearn import preprocessing\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.feature_selection import RFE\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","bf09651e":"db = pd.read_csv('\/kaggle\/input\/paris-housing-price-prediction\/ParisHousing.csv')\ndb.head()","56e56540":"db.info()","58b3a371":"corr_matrix = db.corr(method = 'pearson')\ncorr_matrix['price'].sort_values(ascending = False)","2932dd34":"#train\/test split\ntrain_set, test_set = train_test_split(db, test_size=0.2, random_state=42)\n\n#isolate our target variable\nlabel_train = train_set[\"price\"].copy()\nlabels_test = test_set[\"price\"].copy()\n\ntrain_set = train_set.drop(['price'], axis = 1)\ntest_set = test_set.drop(['price'], axis = 1)","3b63b0be":"lin_reg = LinearRegression()","69137b4d":"#testing RFE on TRAIN\nfor i in range(1,17):\n    rfe_i = RFE(lin_reg, i)\n    rfe_i = rfe_i.fit(train_set, label_train)\n    predictions_rfe_i = rfe_i.predict(train_set)\n    lin_mse_rfe_i = mean_squared_error(label_train, predictions_rfe_i)\n    lin_rmse_rfe_i = np.sqrt(lin_mse_rfe_i)\n    print(i,\" \",lin_rmse_rfe_i)\n    ","1c51904f":"round(db['price'].describe()) #with a mean of 4993448 and standard deviation of 2877424 an error of 1890 is quite good","306b45d1":"#train set\nrfe = RFE(lin_reg, 8)\nrfe = rfe.fit(train_set, label_train)\npredictions_rfe = rfe.predict(train_set)\nlin_mse_rfe = mean_squared_error(label_train, predictions_rfe)\nlin_rmse_rfe = np.sqrt(lin_mse_rfe)\nlin_rmse_rfe ","54983082":"#test set\nrfe_test = rfe.fit(test_set, labels_test)\npredictions_test_rfe = rfe_test.predict(test_set)\nlin_mse_test_rfe = mean_squared_error(labels_test, predictions_test_rfe)\nlin_rmse_test_rfe = np.sqrt(lin_mse_test_rfe)\nlin_rmse_test_rfe","7abb1b7f":"So, I managed to reduce the number of features from 16 to 8 and have an error close to the one corresponding to a regression with all 16 features.","234d55b7":"Define the linear regression:","968436ba":"So we see that keeping between 1 and 3 features gives a huge error, so we cannot keep only 3 of them. However, between 8 and 16 the error is almost constant, and around 1890.\nLet's check the target variable, to see what this means compared to it: ","f3a789d0":"This notebook tests a linear regression to determine houses' price considering different sets of features. To select features I have used Regressive Feature Elimination and tested what number of features gives the lowest RMSE.","840679ef":"Let's have a look at the data:","ff8e18ff":"OK, so we have a clean database, with no missings and no categorical data.\nLet's check what features are the most correlated with our target variable, price:","ecbfc2b6":"Now let's split the data into train and test data, and then apply our feature selection:","107cceff":"We have 16 features; now let's go through all of them and see what number of features offers the best, lowest RMSE on the training set:","0c11b1d9":"Now let's keep only 8 features and apply it on the train set, and then try it on the test set:"}}