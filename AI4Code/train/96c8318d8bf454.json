{"cell_type":{"782e062f":"code","9f2833d0":"code","428bff4e":"code","fd1a81bb":"code","37f2b38b":"code","6add3bdb":"code","06bc272b":"code","bff16eb0":"code","4d9b08b9":"code","691d60cd":"code","2f203047":"code","723e1ed6":"code","bedaa545":"code","cc2dd398":"code","437d951b":"code","35d0ca59":"code","742869bb":"code","cf8ba04e":"code","aebad2c9":"code","f14c20f6":"code","f3b28863":"code","cfa795c1":"markdown","763b49ed":"markdown","2e626732":"markdown","77148339":"markdown","7d9de0cd":"markdown","f6d747b3":"markdown","7987fdac":"markdown","a4e460ea":"markdown","fd073dea":"markdown","84c1a320":"markdown","d6692d79":"markdown"},"source":{"782e062f":"!conda install -y gdown","9f2833d0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport zipfile\nfrom matplotlib.gridspec import GridSpec\nimport matplotlib.pyplot as plt\nimport os \n\nimport torchvision\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nimport torch.nn.functional as F\n\nimport PIL\n\nfrom sklearn.metrics import confusion_matrix\n\nfrom collections import OrderedDict\n\nimport time\nimport gc\n\ngc.enable()\ntorch.__version__","428bff4e":"!gdown --id 1fpu2IATXJBoCD0adJDVjGYZ0qwDnQ4e8","fd1a81bb":"os.path.exists(\"\/kaggle\/working\/vgg_cat_vs_dog.h5\")","37f2b38b":"plt.rcParams[\"figure.figsize\"] = (10, 10)","6add3bdb":"with zipfile.ZipFile(\"..\/input\/dogs-vs-cats-redux-kernels-edition\/\" + \"train.zip\",\"r\") as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats-redux-kernels-edition\/\" + \"test.zip\",\"r\") as z:\n    z.extractall(\".\")","06bc272b":"def loadFileNames(trainTestFlag=True, start=0, end=12500, root=os.getcwd()):\n    fileNames = []\n    for ind in range(start, end):\n        fileName = []\n        if trainTestFlag:\n            fileName = [\"cat.\" + str(ind) + \".jpg\", \"dog.\" + str(ind) + \".jpg\"]\n        else:\n            fileName = [str(ind) + \".jpg\"]\n        \n        for ind, p in enumerate(fileName):\n            if trainTestFlag:\n                path = \"\/kaggle\/working\/train\/\" + p\n                if os.path.exists(path):\n                    if ind == 0:\n                        fileNames.append((path, 0))\n                    else:\n                        fileNames.append((path, 1))\n            else:\n                path = \"\/kaggle\/working\/test\/\" + p\n                if os.path.exists(path):\n                    fileNames.append((path, -1))\n    return fileNames","bff16eb0":"fileNames = np.array(loadFileNames())\nindeces = np.random.choice(len(fileNames), len(fileNames), replace=False)\ntrainTestRatio = 0.8\ntrainIndeces, validationIndeces = indeces[:int(0.8 * len(indeces))], indeces[int(0.8 * len(indeces)):] \nfileNamesTest = loadFileNames(False, 1, 12501)\n","4d9b08b9":"class DataAugmentation(Dataset):\n\n    def __init__(self, imgSize, fileNames, *args, **kwargs):\n        super(DataAugmentation, self).__init__(*args, **kwargs)\n        self.files = fileNames\n        self.tensorTransform = torchvision.transforms.ToTensor()\n        self.resize = torchvision.transforms.Resize((imgSize, imgSize))\n        self.tranlationTransform = torchvision.transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))\n        self.rotationalTransformation = torchvision.transforms.RandomRotation(45, center=(imgSize\/2, imgSize\/2) )\n        self.imgSize = imgSize\n    \n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, index):\n        img = PIL.Image.open(self.files[index][0])\n        label = self.files[index][1]\n        img = self.resize(img)\n        img = self.tranlationTransform(img)\n        img = self.rotationalTransformation(img)\n        #img = np.array(img, dtype=np.float32)\n        img = self.tensorTransform(img)#Will read it into 3xheightxwidth\n        #Standard normalize images\n        ravel = img.view(3, -1)\n        means = torch.mean(ravel, dim=1)\n        ravel -= torch.transpose(means.repeat(ravel.shape[1]).reshape(-1, 3), 0, 1)\n        std = torch.std(ravel, dim=1)\n        ravel \/= torch.transpose(std.repeat(ravel.shape[1]).reshape(-1, 3), 0, 1)\n        \n        img = ravel.view(3, self.imgSize, self.imgSize)\n\n        return img, label\n\nclass OriginalImages(Dataset):\n\n    def __init__(self, imgSize, fileNames, *args, **kwargs):\n        super(OriginalImages).__init__(*args, **kwargs)\n        self.files = fileNames\n        self.tensorTransform = torchvision.transforms.ToTensor()\n        self.resize = torchvision.transforms.Resize((imgSize, imgSize))\n        self.imgSize = imgSize\n    \n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, index):\n        img = PIL.Image.open(self.files[index][0])\n        label = self.files[index][1]\n        img = self.resize(img)\n        img = self.tensorTransform(img)\n        \n        #Standard normalize images\n        ravel = img.view(3, -1)\n        means = torch.mean(ravel, dim=1)\n        ravel -= torch.transpose(means.repeat(ravel.shape[1]).reshape(-1, 3), 0, 1)\n        std = torch.std(ravel, dim=1)\n        ravel \/= torch.transpose(std.repeat(ravel.shape[1]).reshape(-1, 3), 0, 1)\n        \n        img = ravel.view(3, self.imgSize, self.imgSize)\n        return img, label","691d60cd":"augmentedDataTrain = DataAugmentation(224, fileNames[trainIndeces])\noriginalDataTrain = OriginalImages(224, fileNames[trainIndeces])\noriginalDataValidation = OriginalImages(224, fileNames[validationIndeces])\noriginalDataTest =  OriginalImages(224, fileNamesTest)\n\ndataLoaderTrain = DataLoader(ConcatDataset([originalDataTrain, augmentedDataTrain]), batch_size=256, shuffle=True)\ndataLoaderValid = DataLoader(originalDataValidation, batch_size=256, shuffle=True)\ndataLoaderTest = DataLoader(originalDataTest, batch_size=256)","2f203047":"class VGG13(torch.nn.Module):\n\n    def __init__(self, *args, **kwargs):\n        super(VGG13, self).__init__(*args, **kwargs)\n        self.conv1 = torch.nn.Conv2d(3, 64, (3, 3), 1)\n        self.conv2 = torch.nn.Conv2d(64, 64, (3, 3), 1)\n        self.pool1 = torch.nn.MaxPool2d((2, 2), 2)#non-overlapping\n        self.conv3 = torch.nn.Conv2d(128, 128, (3, 3), 1)\n        self.conv4 = torch.nn.Conv2d(128, 128, (3, 3), 1)\n        self.pool2 = torch.nn.MaxPool2d((2, 2), 2)#non-overlapping\n        self.conv5 = torch.nn.Conv2d(256, 256, (3, 3), 1)\n        self.conv6 = torch.nn.Conv2d(256, 256, (3, 3), 1)\n        self.pool3 = torch.nn.MaxPool2d((2, 2), 2)#non-overlapping\n        self.conv7 = torch.nn.Conv2d(512, 512, (3, 3), 1)\n        self.conv8 = torch.nn.Conv2d(512, 512, (3, 3), 1)\n        self.pool4 = torch.nn.MaxPool2d((2, 2), 2)#non-overlapping\n        self.conv9 = torch.nn.Conv2d(512, 512, (3, 3), 1)\n        self.conv10 = torch.nn.Conv2d(512, 512, (3, 3), 1)\n        self.pool5 = torch.nn.MaxPool2d((2, 2), 2)#non-overlapping\n\n        self.fc1 = torch.nn.Linear(512 * 7 * 7, 4096)\n        self.fc2 = torch.nn.Linear(4096, 4096)\n        self.fc3 = torch.nn.Linear(4096, 2)\n\n\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.conv2(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.pool1(x)\n        #print(x.shape)\n        x = self.conv3(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.conv4(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.pool2(x)\n        #print(x.shape)\n\n        x = self.conv5(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.conv6(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.pool3(x)\n        #print(x.shape)\n\n        x = self.conv7(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.conv8(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.pool4(x)\n        #print(x.shape)\n\n        x = self.conv9(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.conv10(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.pool5(x)\n        #print(x.shape)\n\n        x = x.view(-1, 512 * 7 * 7)\n        #print(x.shape)\n\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = self.fc3(x)\n\n        x = F.softmax(x, dim=2)\n\n        return x\n    \n    @staticmethod\n    def init_param(layer):\n        if type(layer) == torch.nn.Conv2d:\n            torch.nn.init.xavier_normal_(layer.weight)\n        if type(layer) == torch.nn.Linear:\n            torch.nn.init.xavier_uniform_(layer.weight)\n    \n    def initialize_parameters(self, verbose=False):\n        self.apply(self.init_param)\n        numberParameters = 0\n        for p in self.parameters():\n            numberParameters += p.numel() if p.requires_grad else 0\n        if verbose:\n            counter = 0\n            for param in self.parameters():\n                print(f\"Layer {counter}\")\n                print(param)\n                counter += 1\n        print(\"Number of parameters is {:,}\".format(numberParameters))","723e1ed6":"class VggWithCustomLayers(torch.nn.Module):\n\n    def __init__(self, *args, **kwargs):\n        super(VggWithCustomLayers, self).__init__(*args, **kwargs)\n        self.vgg = torchvision.models.vgg16(pretrained=True)\n        for param in self.vgg.parameters():\n            param.requires_grad = False\n        in_features = self.vgg.classifier[-1].in_features\n        block = torch.nn.Sequential(OrderedDict([\n            (\"conv_1\", torch.nn.Linear(in_features, 2)),\n            #(\"non-linear-1\", torch.nn.ReLU()),\n            #(\"last\", torch.nn.Linear(128, 1)),\n            (\"softmax\", torch.nn.Softmax(dim=1))\n        ]))\n        self.vgg.classifier[-1] = block\n\n    def forward(self, x):\n        x = self.vgg(x)\n        return x\n\ndef predict(loader, model, y_pred, y_true, images):\n    counter = 0\n    for batch, labels in loader:\n        gc.collect()\n        y_p = model(batch)\n        y = list(np.array(labels, dtype=np.int8))\n        _, y_p_max = torch.max(y_p, dim=1)\n        y_pred.extend(y_p_max.tolist())\n        y_true.extend(y)\n        print(f\"batch#{counter}\")\n        if counter < 10:\n            images.append(batch[0]) \n        del batch\n        del y_p\n        del y\n        del y_p_max\n        del _\n        counter += 1","bedaa545":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Assuming that we are on a CUDA machine, this should print a CUDA device:\n\nprint(device)\n\nmodel = VggWithCustomLayers()\nmodel.load_state_dict(torch.load(\"\/kaggle\/working\/vgg_cat_vs_dog.h5\"))\nprint(model)\n\n#model.initialize_parameters(False)\noptimizer = torch.optim.SGD(params=model.parameters(), lr=0.001, momentum=0.9)\nloss_fn = torch.nn.CrossEntropyLoss()\nvalidation_errors = []\ntraining_errors = []\nprint(model)\nmodel =model.to(device)\nfor name, param in model.named_parameters():\n    print(f\"{name} {param.requires_grad}\")","cc2dd398":"epochs = 1\ndef train_model(epochs, model, dataLoaderTrain, dataLoaderValid):\n    y_pred_train = []\n    y_pred_valid = []\n    y_true_train = []\n    y_true_valid = []\n    for epoch in range(0, epochs):\n        batchNum = 0\n        begin = time.time()\n        trainingErrorBatches = []\n        validationErrorBatches = []\n\n        for batch, labels in dataLoaderTrain:\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            y_pred = model(batch)\n            y = torch.tensor(np.array(labels, dtype=np.int8)).type(torch.LongTensor)\n            y = y.to(device)\n            loss = loss_fn(y_pred, y)\n            loss.backward()\n            optimizer.step()\n            if epoch + 1 == epochs:\n                y_pred_train.extend(list(np.argmax(y_pred.detach().numpy(), axis=1)))\n                y_true_train.extend(y.tolist())\n            trainingErrorBatches.append(loss.item())\n            print(f\"{epoch}:{batchNum}, -log-likelihood {np.round(loss.item(), 3)}\")\n            cnf = confusion_matrix(y, np.argmax(y_pred.detach().numpy(), axis=1))\n            print(f\"Accuracy: {np.round(np.sum(np.diag(cnf))\/np.sum(cnf), 3)*100}, \\n {cnf}\")\n            batchNum += 1\n\n        for batch, labels in dataLoaderValid:\n            optimizer.zero_grad()\n            y = torch.tensor(np.array(labels, dtype=np.int8)).type(torch.LongTensor)\n            y_pred = model(batch)\n            y = y.to(device)\n            loss = loss_fn(y_pred, y)\n            if epoch + 1 == epochs:\n                y_pred_valid.extend(list(np.argmax(y_pred.detach().numpy(), axis=1)))\n                y_true_valid.extend(y.tolist())\n            validationErrorBatches.append(loss.item())\n        training_errors.append(np.mean(trainingErrorBatches))\n        validation_errors.append(np.mean(validationErrorBatches))\n\n        end = time.time()\n        print(f\"{epoch} the avg -log-likelihood for training is {np.round(training_errors[-1], 2)} and it took {(end - begin)\/60} min\")\n        print(f\"{epoch} the avg -log-likelihood for validation is {np.round(validation_errors[-1], 2)} and it took {(end - begin)\/60} min\")\n    return y_pred_train, y_true_train, y_pred_valid, y_true_valid","437d951b":"# Training Performance\ny_pred = []\ny_true = [] \nimages = [] \n#predict(dataLoaderTrain, model, y_pred, y_true, images)\n#cnf = confusion_matrix(y_pred, y_true)\n#cnf = confusion_matrix(y_pred_train, y_true_train)\n#print(f\"Accuracy on training set {np.round(np.sum(np.diag(cnf))\/np.sum(cnf), 3) * 100} \\n {cnf}\")","35d0ca59":"# gs = GridSpec(2, 5)\n# gs.update(left=0.12, bottom=0.08, right=2, top=0.92, wspace=0.2, hspace=0.5)\n# lab = [\"cat\", \"dog\"]\n# colors = [\"red\", \"green\"]\n# for i in range(0, 2):\n#     for j in range(0, 5):\n#         ax = plt.subplot(gs[i, j])\n#         ax.imshow(images[i*2 + j].transpose(0, 2)[:, :, 0], cmap=\"gray\")\n#         ax.set_xticks([])\n#         ax.set_yticks([])\n#         ax.set_title(f\"y_true: {lab[y_true[i* 2 + j]]} and y_pred: {lab[y_pred[i*2 +j]]}\", color=colors[(y_true[i* 2 + j] == y_pred[i*2 +j])*1] )\n        \n# plt.show()","742869bb":"# del y_pred\n# del y_true\n# del images \n# del dataLoaderTrain\n# del cnf\n\n# Validation Performance\ny_pred = []\ny_true = [] \nimages = [] \npredict(dataLoaderValid, model, y_pred, y_true, images)\n#cnf = confusion_matrix(y_pred_valid, y_true_valid)\ncnf = confusion_matrix(y_pred, y_true)\nprint(f\"Accuracy on validation set {np.round(np.sum(np.diag(cnf))\/np.sum(cnf), 3) * 100} \\n {cnf}\")","cf8ba04e":"gs = GridSpec(2, 5)\ngs.update(left=0.12, bottom=0.08, right=2, top=0.92, wspace=0.2, hspace=0.5)\nlab = [\"cat\", \"dog\"]\ncolors = [\"red\", \"green\"]\nfor i in range(0, 2):\n    for j in range(0, 5):\n        ax = plt.subplot(gs[i, j])\n        ax.imshow(images[i*2 + j].transpose(0, 2)[:, :, 0], cmap=\"gray\")\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(f\"y_true: {lab[y_true[i* 2 + j]]} and y_pred: {lab[y_pred[i*2 +j]]}\", color=colors[(y_true[i* 2 + j] == y_pred[i*2 +j])*1] )\n        \nplt.show()","aebad2c9":"del dataLoaderValid\n#del cnf\n# Test Performance\ny_pred = []\ny_true = [] \nimages = [] \npredict(dataLoaderTest, model, y_pred, y_true, images)\ndf = pd.DataFrame(np.c_[np.arange(1, len(y_pred) + 1), y_pred], columns=[\"id\", \"label\"])\ndf.to_csv(\"submission.csv\", header=True, index=False)","f14c20f6":"gs = GridSpec(2, 5)\ngs.update(left=0.12, bottom=0.08, right=2, top=0.92, wspace=0.2, hspace=0.5)\nlab = [\"cat\", \"dog\"]\nfor i in range(0, 2):\n    for j in range(0, 5):\n        ax = plt.subplot(gs[i, j])\n        ax.imshow(images[i*2 + j].transpose(0, 2)[:, :, 0], cmap=\"gray\")\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(f\"y_pred: {lab[y_pred[i*2 +j]]}\")\n        \nplt.show()","f3b28863":"# To download file, from https:\/\/www.kaggle.com\/rtatman\/download-a-csv-file-from-a-kernel\n#from IPython.display import HTML\n# import base64\n#html = '<a  href=\"{filename}\" target=\"_blank\">{title}<\/a>'\n#html = html.format(title=\"file\",filename=\"submission.csv\")\n#HTML(html)","cfa795c1":"# Model Performance on the Test Set","763b49ed":"# Model Performance on the Training Set","2e626732":"# Instantiation of the Model","77148339":"# Extracting the training and test set","7d9de0cd":"# Creating VGG13 from Scratch and Using Custom model with the pretrained model of the VGG16","f6d747b3":"# Model Performance on the Validation Set","7987fdac":"# Validation and Training Split","a4e460ea":"# Training of the Model","fd073dea":"# Data Augmentation and Data Loading","84c1a320":"# References \n* https:\/\/arxiv.org\/abs\/1409.1556","d6692d79":"# Loading Packages and Weights for My Custom model"}}