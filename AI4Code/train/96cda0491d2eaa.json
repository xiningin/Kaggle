{"cell_type":{"fd5094bd":"code","83fa02c4":"code","387ad0d7":"code","310a005e":"code","d1814020":"code","22a9c7a4":"code","3cac62b2":"code","78c2b186":"code","5d59978b":"code","eb3bb42a":"code","9d42c73f":"code","38f639a4":"code","996bd2d7":"code","1d82abf4":"code","faeddba8":"code","fa0ebe8e":"code","82c8d5d8":"code","f52bec19":"code","152bcb42":"code","7e225d51":"code","ed88bda8":"code","78a33351":"code","53bfff3c":"code","082309f6":"code","9ac81dda":"code","f37bd80a":"code","d5c5715c":"code","3503fac9":"code","58db6b8b":"code","52a130f0":"code","5b8290da":"code","b7106459":"code","6d19f47d":"markdown","e9a95be2":"markdown","4a95cf48":"markdown","18479103":"markdown","fac670b8":"markdown","4490eedc":"markdown"},"source":{"fd5094bd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","83fa02c4":"# Import Pandas\nimport pandas as pd\n\n# Loading Data sets\nfull_url='\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_credits.csv'\n\nfull_url1='\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_movies.csv'\n\ncredits = pd.read_csv(full_url)\nmovies=pd.read_csv(full_url1)","387ad0d7":"# Printing 1st 5 elements of credits dataset\ncredits.head()","310a005e":"# Printing 1st 5 elements of movies dataset\nmovies.head(2)","d1814020":"# Printing the shapes of both the datasets\nprint(\"Credits:\",credits.shape)\nprint(\"Movies:\",movies.shape)","22a9c7a4":"# Renaming the column of credits data set\ncredits_renamed=credits.rename(index=str,columns={'movie_id':'id'})\ncredits_renamed.head()","3cac62b2":"# Merging both data sets\nmerge=movies.merge(credits_renamed,on='id')\nmerge.head()","78c2b186":"# Dropping unnecessary columns \ncleaned=merge.drop(columns=['homepage','title_x','title_y','status','production_countries'])\ncleaned.head()","5d59978b":"cleaned['overview'].head(2)","eb3bb42a":"#Import TfIdfVectorizer from scikit-learn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\ntfidf = TfidfVectorizer(stop_words='english',ngram_range=(1,3),min_df=3,analyzer='word')\n\n#Replace NaN with an empty string\ncleaned['overview'] = cleaned['overview'].fillna('')\n\n#Construct the required TF-IDF matrix by fitting and transforming the data\ntfidf_matrix = tfidf.fit_transform(cleaned['overview'])\n\n#Output the shape of tfidf_matrix\ntfidf_matrix.shape","9d42c73f":"from sklearn.metrics.pairwise import linear_kernel\n\n# Compute the cosine similarity matrix\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)","38f639a4":"print(cosine_sim.shape)\nprint(cosine_sim[1])","996bd2d7":"#Construct a reverse map of indices and movie titles\nindices = pd.Series(cleaned.index, index=cleaned['original_title']).drop_duplicates()\n","1d82abf4":"def get_recommendations(title, cosine_sim=cosine_sim):\n    # Get the index of the movie that matches the title\n    idx = indices[title]\n\n    # Get the pairwsie similarity scores of all movies with that movie\n    sim_scores = list(enumerate(cosine_sim[idx]))\n\n    # Sort the movies based on the similarity scores\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n\n    # Get the scores of the 10 most similar movies\n    sim_scores = sim_scores[1:11]\n\n    # Get the movie indices\n    movie_indices = [i[0] for i in sim_scores]\n\n    # Return the top 10 most similar movies\n    return cleaned['original_title'].iloc[movie_indices]","faeddba8":"# Getting the recommendation\nget_recommendations('Avatar')","fa0ebe8e":"get_recommendations('Spectre')","82c8d5d8":"cleaned.columns","f52bec19":"cleaned['crew'].values[0]","152bcb42":"\n# Parse the stringified features into their corresponding python objects\nfrom ast import literal_eval\n\nfeatures = ['cast', 'crew', 'keywords', 'genres']\n\nfor feature in features:\n    cleaned[feature] = cleaned[feature].apply(literal_eval)\n    \n## about literal_eval()    \n## https:\/\/stackoverflow.com\/questions\/15197673\/                                            ","7e225d51":"## a function that will return the top 3 elements or the entire list, whichever is more. \n## Here the list refers to the cast, keywords, and genres.\ndef get_list(x):\n    if isinstance(x, list):\n        names = [i['name'] for i in x]\n    \n    #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.\n        if len(names) > 3:\n            names = names[ : 3]\n        return names\n\n    #Return empty list in case of missing\/malformed data\n    return []","ed88bda8":"# Define new director, cast, genres and keywords features \n## that are in a suitable form.\ncleaned['director'] = cleaned['crew'].apply(get_director)\n\nfeatures = ['cast', 'keywords', 'genres']\n\nfor feature in features:\n    cleaned[feature] = cleaned[feature].apply(get_list)","78a33351":"## function to get the director's name\ndef get_director(x):\n    for i in x:\n        if i['job'] == 'Director':\n            return i['name']\n    return np.nan","53bfff3c":"## lets see the data stored for the 0th movie.  \ncleaned['crew'].values[0]\n\n## Notice : its an list of dict objects.","082309f6":"# Print the new features of the first 3 films\ncleaned[['original_title', 'cast', 'director', 'keywords', 'genres']].head(3)","9ac81dda":"# Function to convert all strings to lower case and strip names of spaces\ndef clean_data(x):\n    if isinstance(x, list):\n        return [str.lower(i.replace(\" \", \"\")) for i in x]\n    else:\n        if isinstance(x, str):\n            return str.lower(x.replace(\" \", \"\"))\n        else:\n            return ''","f37bd80a":"# Apply clean_data function to your features.\nfeatures = ['cast', 'keywords', 'director', 'genres']\n\nfor feature in features:\n    cleaned[feature] = cleaned[feature].apply(clean_data)","d5c5715c":"def create_metadata(x):\n    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])\n# Create a new metadata feature\ncleaned['metadata'] = cleaned.apply(create_metadata, axis=1)","3503fac9":"cleaned[['metadata']].head(2)","58db6b8b":"# Import CountVectorizer and create the count matrix\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ncount = CountVectorizer(stop_words='english')\n\ncount_matrix = count.fit_transform(cleaned['metadata'])","52a130f0":"# Compute the Cosine Similarity matrix based on the count_matrix\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ncosine_sim2 = cosine_similarity(count_matrix, count_matrix)","5b8290da":"# Reset index of your main DataFrame and construct reverse mapping as before\n\n## cleaned = cleaned.reset_index()\nindices = pd.Series(cleaned.index, index = cleaned['original_title'])\nindices[:2]","b7106459":"## You can now reuse your get_recommendations() function \n## by passing in the new cosine_sim2 matrix as your second argument.\n\nget_recommendations('The Dark Knight Rises', cosine_sim2)","6d19f47d":"Recommender systems can be classified into Two types:\n\n> **Content-based recommenders**: suggest similar items based on a particular item. This system uses item metadata, such as genre, director, description, actors, etc. for movies, to make these recommendations. The general idea behind these recommender systems is that if a person likes a particular item, he or she will also like an item that is similar to it. And to recommend that, it will make use of the user's past item metadata. A good example could be YouTube, where based on your history, it suggests you new videos that you could potentially watch.\n\n> **Collaborative filtering engines**: these systems are widely used, and they try to predict the rating or preference that a user would give an item-based on past ratings and preferences of other users. Collaborative filters do not require item metadata like its content-based counterparts.","e9a95be2":" Myslef [A V S V Tejaswini](https:\/\/www.linkedin.com\/in\/tejaswini-a-v-s-v-4b648319a) is creating an ML based Recommendation Engine in collaboration with [Mr. Rocky Jagtiani](https:\/\/www.linkedin.com\/today\/author\/rocky-jagtiani-3b390649\/)\n> This is a simple Data Science project on Movies Recommendation System which recommends you the movie based on the Review of previous movie.\n\n> Dataset: tmdb_5000_credits.csv,tmdb_5000_movies.csv from kaggle itself\n\n> Tech Stack used: pandas, Scikit-learn,Python\n\n> Recommended links : \n\n> https:\/\/datascience.suvenconsultants.com  ( For DS \/ AI \/ ML )\n\n> https:\/\/monster.suvenconsultants.com  ( For Web development )","4a95cf48":"# Enchancements","18479103":"Here we are going to implement **Content Based Filtering**","fac670b8":"I would like to humbly and sincerely thank my mentor [Rocky Jagtiani](https:\/\/www.linkedin.com\/today\/author\/rocky-jagtiani-3b390649\/). He is more of a friend to me then mentor. The Machine Learning course taught by him and various projects we did and are still doing is the best way to learn and skill in Data Science field. See https:\/\/datascience.suvenconsultants.com once for more.","4490eedc":"Recommender systems are among the most popular applications of data science today. They are used to predict the \"rating\" or \"preference\" that a user would give to an item. Almost every major tech company has applied them in some form. Amazon uses it to suggest products to customers, YouTube uses it to decide which video to play next on autoplay, and Facebook uses it to recommend pages to like and people to follow.\n\nRecommender systems have also been developed to explore research articles and experts, collaborators, and financial services. "}}