{"cell_type":{"91c9a3d8":"code","b2488e9f":"code","884d6c7a":"code","ee229dae":"markdown"},"source":{"91c9a3d8":"!ln -sf ..\/input\/optiverdataset\/optiver-features\/features .\/features\n!ln -sf ..\/input\/optiverdataset\/optiver-models\/models .\/models\n!ln -sf ..\/input\/optiverdataset\/optiver-scalers\/scalers .\/scalers\n!cp ..\/input\/optiverdataset\/optiver-src\/*.py .\/\n!mkdir -p predictions","b2488e9f":"!python nn_feature_stat.py -j2 -n2\n!python lgbm_feature_stat.py -j2\n\nfrom utils import *\n\ntest_df = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/test.csv')\ntest_df['target'] = np.load('.\/predictions\/nn_feature_stat_2_2.npy') * .6 + np.load('.\/predictions\/lgbm_feature_stat_2.npy') * .4\ntest_df[['row_id', 'target']].to_csv('submission.csv', index=False)","884d6c7a":"test_df","ee229dae":"Hello Kaggler,\n\nI would like to share how projects are organized in a manageable fashion. Most of the code in this kernel comed from other notebooks already shared.\n\nHere are some sources:\n1. https:\/\/www.kaggle.com\/alexioslyon\/lgbm-baseline\n2. https:\/\/www.kaggle.com\/c\/optiver-realized-volatility-prediction\/discussion\/267096\n3. https:\/\/www.kaggle.com\/denisvodchyts\/lgbm-slightly-different-features\n\nIdeas:\n\n1. All the feature scripts are named `{feature_name}.py`. All features can be loaded by calling Loader method. like this:\n\n```python\nimport feature_stat_2\ntrain_df, test_df = feature_stat_2.Loader()\n```\n\n2. All the models are name {model_name}.py. Each model can be trained separately by calling `python nn_feature_stat.py -t -j2`, which will save all the trained model in `.\/models`, preproprocessing scalers in `.\/scalers` and OOF predictions in `.\/oof`. Inferencing by `python nn_feature_stat.py -j2`, which will produce `.\/predictions\/nn_feature_stat_2_1.npy` as prediction output.\n\nBelow is an example for prediction using nn model with feature_stat_2_1 as input."}}