{"cell_type":{"564021ec":"code","d36701f3":"code","812c5427":"code","21468679":"code","edbccc86":"code","1453e04d":"code","c317e976":"code","c8066a27":"code","b89d70f9":"code","a6c377cf":"code","5a8212b5":"code","4f5aa494":"code","51647b8b":"code","00a63394":"code","3c8265d3":"code","61b60ed3":"code","32dbbd95":"code","3737c25e":"code","b789a8a8":"code","eca9f10d":"code","49732e26":"code","392dec5f":"code","88eadfe0":"code","fa3bde6b":"code","747a10c7":"code","f5a5bd32":"code","a5eebb47":"code","ffede6c7":"code","7f8e87ba":"code","d9d48477":"code","28aa3ab5":"code","f784dbe2":"code","8e69ac94":"code","f4e72230":"code","04e0a0e5":"code","edbd6cb3":"code","4b7d8b29":"code","c5b7c3d9":"code","e01df156":"code","22e8e920":"code","58248514":"code","08922263":"code","c25a71d2":"code","0e290f0f":"code","37575e1e":"code","50032a84":"code","daddd048":"code","b68961b2":"code","0ba47e5a":"code","f7ae0a53":"code","147adf0b":"code","a2016125":"code","0a01fc17":"code","63208bc8":"code","4f07c23c":"code","efb8937e":"code","37b4abc3":"code","fdbd3007":"code","f160f67e":"code","7fc03345":"code","bce3c172":"markdown","78c336fd":"markdown","805f90af":"markdown","7b9e7de6":"markdown","d8047876":"markdown","ba6c4bfe":"markdown","98dcda2b":"markdown","24e4f349":"markdown","ad467072":"markdown"},"source":{"564021ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom sklearn.metrics import plot_confusion_matrix, classification_report, f1_score\nfrom sklearn.model_selection import train_test_split ,GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d36701f3":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nprint(\"Training Data :\",train_df.shape)\nprint(\"Testing Data :\",test_df.shape)\n","812c5427":"train_df.head(5)","21468679":"train_df.info()","edbccc86":"train_df.describe().T","1453e04d":"train_df.columns.values","c317e976":"train_df.isnull().sum().sort_values(ascending=False)","c8066a27":"train_df.shape","b89d70f9":"def missing_percent(df):\n    nan_percent= 100*(df.isnull().sum()\/len(df)).sort_values(ascending = False)\n    nan_percent= nan_percent[nan_percent>0]\n    return nan_percent\nmissing_percent(train_df)\n","a6c377cf":"train_df.nunique().sort_values(ascending = False)","5a8212b5":"# train_df.head()","4f5aa494":"print(train_df[\"Survived\"].value_counts())\nprint(train_df[\"Sex\"].value_counts())","51647b8b":"#survial statistics group by sex\ntrain_df.groupby([\"Sex\", \"Survived\"])[\"Survived\"].count()","00a63394":"plt.hist(train_df[\"Sex\"])","3c8265d3":"plt.hist(train_df[\"Pclass\"])","61b60ed3":"plt.bar(train_df[\"Survived\"] , train_df[\"SibSp\"])","32dbbd95":"train_df.isna().sum()","3737c25e":"train_df.groupby([\"Embarked\", \"Survived\"])[\"Survived\"].count()","b789a8a8":"train_df.Embarked.value_counts()","eca9f10d":"train_df['Embarked'] =train_df['Embarked'].fillna('S')\ntrain_df.Embarked.isna().sum()","49732e26":"train_df['Age'].value_counts().sort_values(ascending = False)","392dec5f":"(train_df['Age']<1).value_counts()","88eadfe0":"train_df['Age'] = train_df['Age'].fillna(train_df['Age'].mean())\ntrain_df.loc[train_df['Age']<1,['Age']]= 1\ntrain_df['Age'].isna().sum()\nprint(train_df['Age'].shape)\nprint(\"Training Data Age Less than 1 :\",(train_df['Age']<1).value_counts())\n\ntest_df['Age'] = test_df['Age'].fillna(train_df['Age'].mean())\ntest_df.loc[test_df['Age']<1,['Age']]= 1\ntest_df['Age'].isna().sum()\nprint(test_df['Age'].shape)\nprint(\"Testing Data Age Less than 1 :\",(test_df['Age']<1).value_counts())","fa3bde6b":"plt.hist(train_df['Age'])\nplt.hist(test_df['Age'])","747a10c7":"sns.boxplot(train_df['Age'])","f5a5bd32":"# train_df.head()","a5eebb47":"train_df.isna().value_counts()","ffede6c7":"train_df['Cabin'].isna().value_counts()","7f8e87ba":"train_df.drop(columns=[\"Name\", \"Ticket\", \"Cabin\"],errors = 'raise' , inplace = True)\ntest_df.drop(columns=[\"Name\", \"Ticket\", \"Cabin\"],errors = 'raise' , inplace = True)","d9d48477":"train_df.head(5)","28aa3ab5":"print(train_df.shape)","f784dbe2":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\ntrain_df['Sex'] = le.fit_transform(train_df['Sex'])\ntrain_df['Embarked'] = le.fit_transform(train_df['Embarked'])\n\ntest_df['Sex'] = le.fit_transform(test_df['Sex'])\ntest_df['Embarked'] = le.fit_transform(test_df['Embarked'])","8e69ac94":"train_df","f4e72230":"train_df = train_df.astype({\"Age\": int})\ntrain_df.info()","04e0a0e5":"print((train_df[\"Age\"]<1).value_counts())\nprint((train_df[\"Age\"]<1).sum())","edbd6cb3":"(train_df['Fare']).value_counts()","4b7d8b29":"plt.boxplot(train_df['Fare'])","c5b7c3d9":"sns.distplot(train_df.Fare)","e01df156":"train_df.info()","22e8e920":"# train_data = train_df.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"])\n# train_data","58248514":"train_df.isna().sum()","08922263":"train_df[\"Fare\"]","c25a71d2":"plt.hist(train_df[\"Fare\"])","0e290f0f":"# train_df = train_df.astype({\"Fare\": int})\ntrain_df.head(10)\n","37575e1e":"corrmatrix = train_df.corr()\nfig,ax = plt.subplots(figsize=(12,12))\nsns.heatmap(corrmatrix,annot=True, square=True,ax=ax)\nplt.xticks(rotation=90)\nplt.title('Correlation Matrix')","50032a84":"# split training and testing \n\nX = train_df.drop(['Survived'], axis=1)\ny = train_df['Survived']\n# X_train, X_val, y_train, y_val = train_test_split(X,y,test_size = 0.2 ,stratify = y,random_state=42)\n\nX_train, X_val, y_train, y_val = train_test_split(X,y,test_size = 0.2,stratify = y,random_state=0)\n","daddd048":"test_df.isna().sum()\nmissing_percent(test_df)","b68961b2":"test_df.head(10)\ntest_df = test_df.astype({\"Age\": int})\ntest_df.info()","0ba47e5a":"test_df['Fare'] = test_df['Fare'].fillna(test_df['Fare'].mean())\ntest_df.Fare.isna().sum()\n","f7ae0a53":"test_df.isna().sum()","147adf0b":"# Importing Classifier Modules\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report, f1_score , confusion_matrix ,accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\n\nfrom sklearn.model_selection import cross_val_score ,cross_val_predict ,KFold\n\n","a2016125":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","0a01fc17":"clf = KNeighborsClassifier(n_neighbors = 13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_df, y, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","63208bc8":"from sklearn.neighbors import KNeighborsClassifier\nmodel = KNeighborsClassifier(n_neighbors=3)\nmodel.fit(X_train, y_train)\n# print metric to get performance\nprint(\"Accuracy: \",model.score(X_val, y_val) * 100)\ny_pred = model.predict(X_val)\nf1 = f1_score(y_val, y_pred, average='micro')\nprint(\"f1_score: \",f1)","4f07c23c":"print(\"  Validation set Classification Report:\")\nprint(classification_report(y_val, y_pred, digits=4))","efb8937e":"clf = RandomForestClassifier(random_state=121, criterion='entropy', max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=30)\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_val)\n\nprint(classification_report(y_val,y_pred))","37b4abc3":"Bclf = BaggingClassifier(\n    DecisionTreeClassifier(), n_estimators=100,\n    max_samples=100, bootstrap=True, random_state=42)\nBclf.fit(X_train, y_train)\ny_pred = clf.predict(X_val)\nprint(\"Accuracy: \",accuracy_score(y_val, y_pred)*100)\nf1 = f1_score(y_val, y_pred, average='micro')\nprint(\"f1_score: \",f1)\nprint(classification_report(y_val,y_pred))","fdbd3007":"pred = cross_val_predict(Bclf, X_train, y_train, cv=3)\nconfusion_matrix(y_train, pred)","f160f67e":"y_pred = Bclf.predict(test_df)\nprint(\"Done\")","7fc03345":"test_df['Survived'] = y_pred\ntest_df[['PassengerId','Survived']].to_csv('\/kaggle\/working\/gender_submission.csv', index=False)\nprint(\"Done\")","bce3c172":"## fill missing values in Age","78c336fd":"# Model","805f90af":"# Cross Validation:","7b9e7de6":"# Correlation Matrix\n","d8047876":"# Preprocessing\n","ba6c4bfe":"## missing data in feature","98dcda2b":"# Load Data","24e4f349":"## fill missing values in Embarked","ad467072":"# Confusion Matrix:"}}