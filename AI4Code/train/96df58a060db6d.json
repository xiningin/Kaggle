{"cell_type":{"42325bba":"code","ab675627":"code","f2d9e846":"code","dae6337a":"code","a9ea02de":"code","93c04f80":"code","25bb8e30":"code","c2d7bee9":"code","9f305c69":"code","3d5873e7":"code","0a0ac30b":"code","340d026e":"code","152b0f29":"code","8781aa91":"code","bcf5bce7":"code","d51b7367":"code","e0b06fbb":"markdown","f5325982":"markdown","6614ffeb":"markdown","65a0cd7e":"markdown","a0c03132":"markdown","b89c7968":"markdown","ef8a444f":"markdown","670cbb3f":"markdown","0e4a5cb1":"markdown","ce95382f":"markdown"},"source":{"42325bba":"import numpy as np\nimport pandas as pd \nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Flatten, Dense,GlobalAveragePooling2D\nfrom keras import applications\nfrom pathlib import Path\nfrom keras.models import model_from_json\nfrom keras.callbacks import ModelCheckpoint, History\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nimport matplotlib.pyplot as plt\nimport random\nimport os","ab675627":"filenames = os.listdir(\"..\/input\/dogs-vs-cats\/train\/train\")\nsample = random.choice(filenames)\nprint(sample)\nimage = load_img(\"..\/input\/dogs-vs-cats\/train\/train\/\"+sample)\nplt.imshow(image)","f2d9e846":"filenames = os.listdir(\"..\/input\/dogs-vs-cats\/train\/train\")\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        categories.append(1)\n    else:\n        categories.append(0)\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})\ndf.head()","dae6337a":"df.tail()","a9ea02de":"#See Total In count\ndf['category'].value_counts().plot.bar()","93c04f80":"from sklearn.model_selection import train_test_split\n#dimensions of our images.\nimg_width, img_height = 150, 150\nIMG_SHAPE = (img_width, img_height, 3)\n\n#IMAGE_FOLDER_PATH=\"..\/input\/dogs-vs-cats\/train\"\n\ntrain_data_dir = '..\/input\/dogs-vs-cats\/train\/train'\nvalidation_data_dir = '..\/input\/dogs-vs-cats\/train\/train'\ndataset = df\ndf[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'}) \ntrain_df, validate_df=train_test_split(df,\n                                       test_size=0.2,\n                                       random_state=42)\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)\n\nnb_train_samples = train_df.shape[0]\nnb_validation_samples = validate_df.shape[0]\n\n#nb_train_samples = 4000\n#nb_validation_samples = 800\nepochs = 50\nbatch_size = 40","25bb8e30":"datagen = ImageDataGenerator(rescale=1. \/ 255)\n\n# build the VGG16 network\nmodel = applications.VGG16(include_top=False, weights='imagenet')\n\n#Traning Generator\ntrain_generator = datagen.flow_from_dataframe(\n    train_df,\n    \"..\/input\/dogs-vs-cats\/train\/train\/\", \n    x_col='filename',\n    y_col='category',\n    class_mode='binary',\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    shuffle=True)\nbottleneck_features_train = model.predict_generator(\n    train_generator, nb_train_samples \/\/ batch_size)\n#np.save('bottleneck_features_train.npy', bottleneck_features_train)","c2d7bee9":"#Validation Generator\nvalidation_generator = datagen.flow_from_dataframe(\n    validate_df,\n    \"..\/input\/dogs-vs-cats\/train\/train\/\", \n    x_col='filename',\n    y_col='category',\n    class_mode='binary',\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    shuffle=False)\nbottleneck_features_validation = model.predict_generator(\n    validation_generator, nb_validation_samples \/\/ batch_size)\n#np.save('bottleneck_features_validation.npy', bottleneck_features_validation)","9f305c69":"os.makedirs(\"model\")\n#train_data = np.load('bottleneck_features_train.npy')\ntrain_data =bottleneck_features_train\ntrain_labels = np.array( \n    [0] * int(nb_train_samples \/ 2) + [1] * int(nb_train_samples \/ 2))\n\n#validation_data = np.load('bottleneck_features_validation.npy')\nvalidation_data = bottleneck_features_validation\n\nvalidation_labels = np.array(\n    [0] * int(nb_validation_samples \/ 2) + [1] * int(nb_validation_samples \/ 2))\n\nmodel = Sequential()\nmodel.add(Flatten(input_shape=train_data.shape[1:])) #shape (4, 4, 512) \nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(#optimizer='rmsprop',\n              optimizer=optimizers.RMSprop(lr=1e-4),\n              loss='binary_crossentropy', metrics=['accuracy'])\n\ncheckpointer = ModelCheckpoint(filepath = \"model\/model.weights.best.hdf5\", \n            verbose=1,  save_best_only=True)\nhist=model.fit(train_data, train_labels,\n          epochs=epochs,\n          batch_size=batch_size,\n          validation_data=(validation_data, validation_labels),\n          callbacks=[checkpointer] )","3d5873e7":"# Save neural network structure\nmodel_structure = model.to_json()\nf = Path(\"model\/model_structure_AM.json\")\nf.write_text(model_structure)\n\n# Save neural network's trained weights\nmodel.save_weights(\"model\/bottleneck_model_AM.h5\")","0a0ac30b":"def Polt_history(hist):\n    acc = hist.history['accuracy']\n    val_acc = hist.history['val_accuracy']\n\n    loss = hist.history['loss']\n    val_loss = hist.history['val_loss']\n\n    plt.figure(figsize=(8, 8))\n    plt.subplot(2, 1, 1)\n    plt.plot(acc, label='Training Accuracy')\n    plt.plot(val_acc, label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.ylabel('Accuracy')\n    plt.ylim([min(plt.ylim()),1])\n    plt.title('Training and Validation Accuracy')\n\n    plt.subplot(2, 1, 2)\n    plt.plot(loss, label='Training Loss')\n    plt.plot(val_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.ylabel('Cross Entropy')\n    plt.ylim([0,1.0])\n    plt.title('Training and Validation Loss')\n    plt.xlabel('epoch')\n    plt.show()\n\nPolt_history(hist)\nplt.savefig('model\/hist.png')","340d026e":"# build the VGG16 network\nbase_model = applications.VGG16(include_top=False, weights='imagenet', input_shape=IMG_SHAPE )\nprint(\"base_model.layers\", len(base_model.layers)) #19\n\n#Feature extraction\n#Freeze the convolutional base\nfor layer in base_model.layers[:15]:\n    layer.trainable = False\n    \n# build a top model to put on top of the convolutional model\ntop_model = Sequential()\n#top_model.add(GlobalAveragePooling2D())\ntop_model.add(Flatten(input_shape=base_model.output_shape[1:]))\ntop_model.add(Dense(256, activation='relu'))\ntop_model.add(Dropout(0.5))\ntop_model.add(Dense(1, activation='sigmoid'))\n\ntop_model_weights_path='model\/bottleneck_model_AM.h5'\ntop_model.load_weights(top_model_weights_path)\n\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(top_model)\nmodel.summary()","152b0f29":"epochs = 5\nbatch_size = 16\n\n# prepare data augmentation configuration\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/ 255,\n    rotation_range=15,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    \"..\/input\/dogs-vs-cats\/train\/train\/\", \n    x_col='filename',\n    y_col='category',\n    class_mode='binary',\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    shuffle=False)\n\n#Validation Generator\ntest_datagen = ImageDataGenerator(rescale=1.\/ 255)\nvalidation_generator = test_datagen.flow_from_dataframe(\n    validate_df,\n    \"..\/input\/dogs-vs-cats\/train\/train\/\", \n    x_col='filename',\n    y_col='category',\n    class_mode='binary',\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    shuffle=False)\n\n\n#Early Stop\n#To prevent over fitting we will stop the learning after 10 epochs and val_loss value not decreased\n#earlystop = EarlyStopping(patience=10)\n\n\ncheckpointer = ModelCheckpoint(filepath='model\/model.weights.best_2.hdf5', \n                               verbose=1, save_best_only=True)\n\n# compile the model with a SGD\/momentum optimizer and a very slow learning rate.\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n\n# fine-tune the model\nhist=model.fit_generator(\n    train_generator,\n    samples_per_epoch=nb_train_samples,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=nb_validation_samples \/\/ batch_size,\n    #nb_val_samples=nb_validation_samples)\n    callbacks=[checkpointer])","8781aa91":"# Save neural network structure and weights\n''''''\nmodel_structure = model.to_json()\nf = Path(\"model\/model_structure2_AM.json\")\nf.write_text(model_structure)\n\nmodel.save_weights(\"model\/model_weights2_AM.h5\")","bcf5bce7":"Polt_history(hist)\nplt.savefig('model\/hist_AM.png')","d51b7367":"import cv2\nimport glob\nfrom tqdm import tqdm\nimport pandas as pd\nfrom PIL import Image as img\n\nx_test = []\ndef model_predict(itr,start,end,x_test):\n\tresult = []\n\t#image_path = 'test1\/'+\"*[\"+rang+\"].jpg\"\n\t#image_path  ='\/home\/abdallah\/datasets\/dogs-vs-cats\/train\/cat*.jpg'\n\t#print (image_path)\n\timage_path  ='..\/input\/dogs-vs-cats\/test1\/test1\/*.jpg'\n\ttest_list = glob.glob(image_path)[start:end]\n\tprint(\"test_list\",test_list[1])\n\tfor i in tqdm(test_list):\n\t    temp = cv2.imread(i)\n\t    temp = cv2.resize(temp, (150, 150))\n\t    temp = temp.reshape(1, 150, 150, 3)\n\t    #out= model.predict_classes(temp)\n\t    #result.append(out[0][0])\n\t    result.append(model.predict_classes(temp)[0][0])\n\t    #if out == 1:    errors +=1\n\n\t#print(\"errors= \",errors, \"from total of\", i)\n\tidx = []\n\tfor i in test_list:\n\t    name = Path(i).stem  #get the filename without the extension \n\t    idx.append(name)\n\t#print(result)\n\tdata = {\"id\": idx, \"label\": result}\n\tsubmission = pd.DataFrame(data)\n\t#print(submission)\n\t#submission.index += 1 \n\t#submission.to_csv('submission_AAA22.csv')  #, index_label='Event_id'\n\n\tplt.figure(figsize=(12, 24))\n\tcount=0\n\tfor row in test_list:\n\t    img = load_img(row, target_size=(150,150))\n\t    plt.subplot(6, 3, count+1)\n\t    plt.imshow(img)\n\t    plt.xlabel(row + '(' + \"{}\".format(result[count]) + ')' )\n\t    count +=1\n\tplt.tight_layout()\n\tplt.show()\n\tplt.savefig('model\/predicted.png')\n\nmodel_predict(1, 20,    38 , x_test)","e0b06fbb":"# See sample image","f5325982":"# Fine-tuning a pre-trained model:","6614ffeb":"# Train top model","65a0cd7e":"* **Define Constants**","a0c03132":"# Import Library","b89c7968":"# Save Model","ef8a444f":"\n# Prepare Traning Data","670cbb3f":"# Learning curves","0e4a5cb1":"# See predicted result","ce95382f":"# Extract features"}}