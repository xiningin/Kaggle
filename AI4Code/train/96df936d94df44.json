{"cell_type":{"d384b555":"code","36ac9ead":"code","61e7f916":"code","c2db414c":"code","06169234":"code","40122682":"code","2259e548":"code","d45623c3":"code","fbd15ac8":"code","6ccaebc3":"code","ee24c3c5":"code","c96b8f4e":"code","b35dae36":"code","15ab3c29":"code","0abcc2cd":"code","0b674aa6":"code","b9e9cf92":"markdown","fef9f957":"markdown","0d4ead10":"markdown","5ba8ad20":"markdown"},"source":{"d384b555":"!pip install -U stanza","36ac9ead":"import os\nimport json\nimport stanza\nimport hashlib\nimport numpy as np\nimport pandas as pd","61e7f916":"stanza.download('en')","c2db414c":"nlp = stanza.Pipeline(processors='tokenize', lang='en', use_gpu=True)","06169234":"!git clone https:\/\/github.com\/COVIEWED\/coviewed_web_scraping","40122682":"!pip install -r coviewed_web_scraping\/requirements.txt","2259e548":"EXAMPLE_URL = 'https:\/\/www.euronews.com\/2020\/04\/01\/the-best-way-prevent-future-pandemics-like-coronavirus-stop-eating-meat-and-go-vegan-view'\nprint(EXAMPLE_URL)","d45623c3":"!cd coviewed_web_scraping\/ && python3 src\/scrape.py -u={EXAMPLE_URL}","fbd15ac8":"data_path = 'coviewed_web_scraping\/data\/'\nfname = [f for f in os.listdir(data_path) if f.endswith('.txt')][0]\nprint(fname)\nwith open(os.path.join(data_path, fname), 'r') as my_file:\n    txt_data = my_file.readlines()\ntxt_data = [line.strip() for line in txt_data if line.strip()]\nlen(txt_data)","6ccaebc3":"article_url = txt_data[0]\nprint(article_url)\narticle_published_datetime = txt_data[1]\nprint(article_published_datetime)","ee24c3c5":"article_title = txt_data[2]\nprint(article_title)","c96b8f4e":"article_text = \"\\n\\n\".join(txt_data[3:])\nprint(article_text)","b35dae36":"ALL_SENTENCES = []\ntxt = [p.strip() for p in article_text.split('\\n') if p.strip()]\nfile_id = fname.split('.')[0]\nprint(file_id)\nprint()\nfor i, paragraph in enumerate(txt):\n    doc = nlp(paragraph)\n    for sent in doc.sentences:\n        S = ' '.join([w.text for w in sent.words])\n        sH = hashlib.md5(S.encode('utf-8')).hexdigest()\n        print(sH)\n        print(S)\n        print()\n        ALL_SENTENCES.append([file_id, sH, S])\n","15ab3c29":"fname = file_id+'_sentences.tsv'\nprint(fname)\nAS = pd.DataFrame(ALL_SENTENCES, columns=['file_id','sentenceHash','sentence'])\nlen(AS)","0abcc2cd":"AS.sample(n=min(len(AS),3))","0b674aa6":"AS.to_csv(fname, sep='\\t', index=False, index_label=False)","b9e9cf92":"# Overview\n\n### What is the goal of Project [COVIEWED](https:\/\/www.coviewed.org\/)?\n\nProject [COVIEWED](https:\/\/www.coviewed.org\/)'s aim is to fight against misinformation on the web regarding the recent coronavirus pandemic \/ covid-19 outbreak. \n\nTo achieve this, we collect different types of claims from web sources with supporting or attacking evidence. \n\nThis information is used to train a machine learning classifier. \n\nOnce trained, we plan to release a browser extension that highlights potential true\/false claims on a web page to assist users in their information gathering process.\n\n### Organization\n\nWe have a public [Trello Board](https:\/\/trello.com\/invite\/b\/jk00CW3u\/9985740815b585156aaa22978a3067df\/project-coviewed) and our project is completely open source and available on [Github](https:\/\/github.com\/COVIEWED).","fef9f957":"---","0d4ead10":"# Load a News Article","5ba8ad20":"# Sentence Segmentation"}}