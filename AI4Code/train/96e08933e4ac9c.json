{"cell_type":{"79942b31":"code","200a4dfc":"code","0050f422":"code","9aa7dcd2":"code","8c8cdef0":"code","70880903":"code","9dadf13f":"code","bcdde2d8":"code","035a512d":"code","7b75f689":"markdown","86215e2b":"markdown","88349f65":"markdown","b53afea6":"markdown","3aabbbd3":"markdown"},"source":{"79942b31":"pip install impyute","200a4dfc":"import pandas as pd\nfrom impyute.imputation.cs import mice\ngender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ndata = pd.read_csv(\"..\/input\/titanic\/train.csv\")","0050f422":"data","9aa7dcd2":"def process_name (data):\n    data['Title'] = data['Name'].apply(lambda name: name.split(',')[1].split(' ')[1])\n    data['Title'] = [float(1) if name in ['Mr.'] else float(2) if name in ['Miss.', 'Ms.'] else float(3) if name in ['Mrs.'] else float(4) if name in ['Master.'] else float(5) for name in data['Title']]\n    data = data.drop(['Name'], axis = 1)\n    return data\n\n\ndef process_sex (data):\n    data['Sex'] = [float(0) if sex == 'male' else float(1) for sex in data['Sex']]    \n    return data\n\n\ndef process_cabin (data):\n    data['Cabin'] = data['Cabin'].isnull().astype(float)\n    return data\n\n\ndef process_embarked (data):\n#     data['Embarked'] = [float(1) if embarked == 'S' else float(2) if embarked == 'C' else float(3) for embarked in data['Embarked']]\n    data['newEmbarkedS'] = [float(1) if embarked == 'S' else float(0) for embarked in data['Embarked']]\n    data['newEmbarkedC'] = [float(1) if embarked == 'C' else float(0) for embarked in data['Embarked']]\n    data = data.drop(['Embarked'], axis = 1)\n    return data\n\n\ndef process_fare (data):\n    data['Fare'] = [float(0) if fare <= 7.91 else float(1) if fare > 7.91 and fare <= 14.454 else float(2) if fare > 14.454 and fare <= 31 else float(3) for fare in data['Fare']]\n    return data\n\n\ndef add_isAlone (data):\n    data['isAlone'] = float(0)\n    \n    for index, df in data.iterrows():\n        if df.SibSp + df.Parch == 0:\n            data.at[index, 'isAlone'] = float(1)\n    return data\n\n\ndef add_companion (data):\n    data['companion'] = float(0)\n\n    for index, df in data.iterrows():\n        companion = df.SibSp + df.Parch\n        data.at[index, 'companion'] = companion\n\n    return data\n\n\ndef impute (data):\n    if 'Survived' in data.columns:\n        impute_data = data.drop(['Survived'], axis = 1)\n    else:\n        impute_data = data\n    imputed = mice(impute_data.values)\n    imputed_value = imputed[:, data.columns.get_loc('Age')-1]\n    imputed_value = [0 if age < 0 else age for age in imputed_value]\n    data['Age'] = imputed_value\n    return data\n\n\ndef convert_to_float(data):\n    data['Pclass'] = data['Pclass'].astype(float)\n    data['SibSp'] = data['SibSp'].astype(float)\n    data['Parch'] = data['Parch'].astype(float)\n    return data\n\n\ndef process_features (data):\n    data = data.drop(['Ticket', 'PassengerId'], axis = 1)  # drop 'Ticket' and 'PassengerId' column\n    data = process_name(data)\n    data = process_sex (data)\n    data = process_cabin (data)\n    data = process_embarked (data)\n#     data = process_fare (data)\n    data = add_isAlone(data)\n    data = add_companion(data)\n    data = convert_to_float(data) # converts int columns to float for MICE imputation\n    data = impute(data)\n    return data\n\nfeatures = process_features(data)","8c8cdef0":"# Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\n\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorrelation_heatmap(features)\nlabel = features['Survived']\nfeatures = features.drop(['Survived'], axis=1)","70880903":"from sklearn.ensemble import RandomForestClassifier\nimport eli5\nimport numpy as np\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(RandomForestClassifier(n_estimators=300), cv=50, random_state=0).fit(features.values, label.values)\neli5.show_weights(perm, feature_names = features.columns.tolist())","9dadf13f":"drop_list = ['Parch', 'SibSp', 'Cabin', 'isAlone', 'companion']\nfeatures = features.drop(drop_list, axis = 1)","bcdde2d8":"import pandas as pd\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\ndef randomForestClassifier(X_train, y_train, n_fold):\n\tparameter_RandomForest = {\n\t\t'n_estimators': (10, 30, 50, 100, 200, 300, 400, 500, 700, 800, 1000),\n\t\t'max_features': ('auto', 'sqrt', 'log2', None),\n\t\t'criterion': ('gini', 'entropy')\n\t}\n\tgs_RandomForest = GridSearchCV(RandomForestClassifier(), parameter_RandomForest, verbose=1, cv=n_fold, n_jobs=-1)\n\tmodel = gs_RandomForest.fit(X_train, y_train)\n\treturn model\n\ndef kNeighborsClassifier(X_train, y_train, n_fold):\n\tparameter_KNeighbors = {\n\t\t'n_neighbors': (3, 5, 7, 9, 11, 13, 15),\n\t\t'weights': ('uniform', 'distance'),\n\t\t'algorithm': ('ball_tree', 'kd_tree', 'brute', 'auto')\n\t}\n\tgs_KNeighbors = GridSearchCV(KNeighborsClassifier(), parameter_KNeighbors, verbose=1, cv=n_fold, n_jobs=-1)\n\tmodel = gs_KNeighbors.fit(X_train, y_train)\n\treturn model\n\n\nn = 15\n\nmodel1 = randomForestClassifier(features, label, n)\n\nmodel2 = kNeighborsClassifier(features, label, n)\n\n\nprint('\\nFor Random Forest:\\n')\nprint(model1.best_score_)\nprint(model1.best_estimator_)\nprint(model1.best_params_)\nprint('\\n')\n\nprint('\\nFor KNeighbors:\\n')\nprint(model2.best_score_)\nprint(model2.best_estimator_)\nprint(model2.best_params_)","035a512d":"# Create submission\n\ndef create_submission_csv(model, features, filename):\n    pred = model.predict(features)\n    passenger_id = np.array(test[\"PassengerId\"]).astype(int)\n    my_solution = pd.DataFrame(pred, passenger_id, columns = [\"Survived\"])\n    my_solution.to_csv(filename, index_label = [\"PassengerId\"])\n    \ntest_x = test\ntest_x = process_features(test_x)\ntest_x = test_x.drop(drop_list, axis = 1)\ntest_x['Fare'] = test_x['Fare'].fillna(test_x['Fare'].mean())\n\ncreate_submission_csv(model1, test_x, 'result.csv')","7b75f689":"**FEATURE ENGINEERING**\n\n*      Separate titles into category: \n                                 1 if [Mr]\n                                 2 if [Miss, Ms]\n                                 3 if [Mrs]\n                                 4 if [Master]\n                                 5 if miscellaneous e.g. Rev., Dr., etc.\n    * Convert sex: 1 - female, 0 - male\n    * Group 'Cabin' column into two groups: 0 - if known, 1 - if 'NaN'\n    * Separate'Embarked' column into 2 columns (drop 1 in any of the 3 to avoid collinearity)\n    * Add 'isAlone' feature if passenger is alone: 1 - if alone, 0 - if not\n    * add 'companion' feature containing no. of companions the passenger is aboard with ('Parch'+'SibSp')\n    * impute missing 'Age' data by MICE (Multiple Imputation by Chained Equations) ref: https:\/\/towardsdatascience.com\/stop-using-mean-to-fill-missing-data-678c0d396e22","86215e2b":"**MODELS**\n\n* Random Forest and KNeighbors Clasifier\n* Cross validate through GridSearchCV","88349f65":"*drop selected parameters*","b53afea6":"**Permutation Importance**\n\n* Check the feature importances","3aabbbd3":"****DATA PREPROCESSING****"}}