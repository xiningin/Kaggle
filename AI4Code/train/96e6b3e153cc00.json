{"cell_type":{"1797ad01":"code","bce83b12":"code","75dbdaa1":"code","95df8d80":"code","f74107f0":"code","057d1974":"code","d298a684":"code","3dcef608":"code","2c246472":"code","8ba52c9e":"code","7724b2e1":"code","f320bec0":"code","76145fce":"code","a1de0e9f":"code","93a6a228":"code","83b526af":"code","f45bff37":"code","d5cb20f2":"code","68d52fdc":"code","27ce74df":"code","89daa379":"code","bbff53c5":"code","1a0866f2":"code","37e08f66":"code","eecc5da2":"code","04d5005a":"code","6e6098a2":"code","6872a907":"code","33d4d228":"code","93507972":"code","55ab48ba":"code","0980aca8":"code","b0509415":"code","1d0775a7":"code","f4f23563":"code","fc3fa487":"code","5d29e4dd":"code","4a63bc8e":"code","a63c5a51":"code","0481cfac":"code","0932fca6":"code","3458ddbf":"code","e321c56d":"code","6a6e6ece":"code","b26e13bf":"code","2e5bc5c8":"code","54ad4de2":"code","8ffcd1dd":"code","95c74448":"code","52b90ebf":"code","a9d9cb5a":"code","8568e5f5":"code","184348bd":"code","d52c8c2d":"code","5167d99b":"code","544f5e98":"code","c2e245d5":"code","e6889c75":"code","d56f6455":"code","cce4c6d1":"code","f8a905e5":"code","66ba14d9":"code","5e6a25f3":"code","3653548a":"code","ea4e95c9":"code","13581431":"code","bbc5e853":"code","7befdd81":"markdown","cb243887":"markdown","508a1760":"markdown","bb6e988a":"markdown","fd347bc5":"markdown","389163d4":"markdown","244d2ccd":"markdown","63d12d48":"markdown","1abd09e6":"markdown","8e170fcd":"markdown","5773cb7c":"markdown","526124dd":"markdown","4bd573be":"markdown"},"source":{"1797ad01":"#Importing the necessary libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","bce83b12":"#Reading the excel file\n\ndata=pd.read_excel(r\"..\/input\/anz-synthesised-transaction-dataset\/ANZ synthesised transaction dataset.xlsx\")","75dbdaa1":"#First five rows of the dataset\n\ndata.head()","95df8d80":"#Number of rows and columns in the dataset\n\ndata.shape","f74107f0":"#Columns present and their datatypes\n\ndata.dtypes","057d1974":"#Converting the extraction column to datetime and days of the date of transactions in a seperate column\n\ndata['extraction']=pd.to_datetime(data['extraction'])\ndata['day_name'] = data['date'].dt.day_name()","d298a684":"#Viewing the column after conversion to datetime format\n\ndata.head()","3dcef608":"#Summarizing the distribution of the dataset \n\ndata.describe()","2c246472":"#Counting the number of categories in the country column\ndata['country'].value_counts()","8ba52c9e":"#Counting the categories and their occurences in status column\nprint(data['status'].value_counts())\ndata['status'].value_counts(normalize=True)\n","7724b2e1":"data['currency'].value_counts()","f320bec0":"data['card_present_flag'].value_counts()","76145fce":"data['txn_description'].value_counts()","a1de0e9f":"data['merchant_id'].value_counts()","93a6a228":"data['merchant_suburb'].value_counts()","83b526af":"data['merchant_state'].value_counts()\n","f45bff37":"data['merchant_long_lat'].value_counts()","d5cb20f2":"data['movement'].value_counts()","68d52fdc":"#Checking the number of missing values in each column\n\ndata.isnull().sum()","27ce74df":"data.drop(['bpay_biller_code','merchant_code'],axis=1,inplace=True)\n#Dropping the two columns with more than 11158 missing values out of 12063 total data present","89daa379":"#Imputing the missing values feature-wise\n#Dropping merchant_id, merchant_suburb and merchant_long_lat columns having 4326 missing values each and 5725,1609 and 2703 categories respectively.\n#Imputing card_present_flag column with its median and merchant_state column with its mode\n\ndata.drop(['merchant_id','merchant_suburb','merchant_long_lat'],axis=1,inplace=True)\ndata['card_present_flag']=data['card_present_flag'].fillna(data['card_present_flag'].median())\ndata['merchant_state']=data['merchant_state'].fillna(data['merchant_state'].mode()[0])","bbff53c5":"#Checking the shape of the dataset after imputing the missing values\n\ndata.shape","1a0866f2":"#Dropping the duplicate values from customer_id column and printing its range\nx=data['customer_id'].drop_duplicates()\nprint(\"Total number of customers:\",len(x))\nfc=data['customer_id'].min()\nlc=data['customer_id'].max()\nprint(\"Customer id ranges from {} to {}\".format(fc,lc))","37e08f66":"#Grouping the data by customer_id and displaying the sum of amount and balance alongwith the number of transactions done by them\ndata_cus=data.groupby('customer_id').agg({'amount': lambda x: x.sum(),'balance': lambda x:x.sum(),'account':lambda x:len(x)})\ndata_cus.head()","eecc5da2":"#Customer_id of The customer who has the maximum transaction amount in 3 months\ndata_cus['amount'].max()\nmax_purchased_cus=data_cus[data_cus['amount']==45409.16]\nprint(max_purchased_cus)\ndata[data['customer_id']=='CUS-2738291516'].head(1)","04d5005a":"#Details of the customer who has the maximum single transaction amount\nmax_spent_cus=data[data['amount']==8835.98]\nmax_spent_cus.head(1)","6e6098a2":"#Details of 5 different customers who have the least transaction amount\nmin_spent_cus=data[data['amount']==0.1]\nmin_spent_cus.head()","6872a907":"#Plotting the transaction amount half monthly\ndata['amount'].plot(grid=True)\nplt.title(\"Transaction amount half-monthly\")","33d4d228":"#Setting the datetime as index column and plotting the average amount of every month\n\ndata.set_index('date',inplace=True)\ndata['amount'].resample(rule='M').mean().plot(kind='bar')\nplt.title(\"Average transaction amount every month\")","93507972":"#Plotting the maximum transaction amount of every week\ndata['amount'].resample(rule='W').max().plot(kind='bar')\nplt.title(\"Maximum transaction amount every week\")","55ab48ba":"#Calculating and plotting the monthly total transaction amount\ntotal_tran_monthly=data['amount'].resample(rule='M').sum().sort_values()\nprint(total_tran_monthly)\ntotal_tran_monthly.plot()\nplt.title(\"Monthly total transaction amount\")","0980aca8":"#Counting the number of transactions done on day basis\n\nsns.countplot(x='day_name',data=data)","b0509415":"#Plotting the average balance of every month in increasing order\n\ndata['balance'].resample(rule='M').mean().plot(kind='bar')","1d0775a7":"#Grouping the data by datetime and aggregating with the number of transactions done at that particular time\n\ndata_time=data.groupby('extraction').agg({'account': lambda x:len(x)})","f4f23563":"#Viewing the first 15 rows \n\ndata_time.head(15)","fc3fa487":"#Plotting the number of transactions made by customers every month\n\nnum_of_mon_tran=data_time['account'].resample(rule='M').sum()\nprint(num_of_mon_tran)\nprint(\"\\n On an average, Number of transactions customers make each month:\",num_of_mon_tran.mean())\nnum_of_mon_tran.plot(kind='line')\nplt.title(\"Number of transactions each month\")","5d29e4dd":"#First five customers with the maximum number of transactions\n\nmax_num_trans_cus=data['first_name'].value_counts()\nprint(max_num_trans_cus.head(5))\nmax_num_trans_cus.head(5).plot(kind='bar')\nplt.title(\"Number of transactions of Top Five Customers\")","4a63bc8e":"#Details of the customer with the maximum number of transactions\n\ndata[data['first_name']=='Michael'].head(1)","a63c5a51":"#Univariate analysis - Box plot\ndata['amount'].plot.box()","0481cfac":"data['balance'].plot.box()","0932fca6":"data['age'].plot.box()","3458ddbf":"#Bivariate Analysis - scatter plot\ndata.plot(x='age',y='amount',kind='scatter')","e321c56d":"data.plot(x='age',y='balance',kind='scatter')","6a6e6ece":"#Plotting the pairwise relationship of numerical features\n\nsns.pairplot(data)","b26e13bf":"data['balance'].plot.box()","2e5bc5c8":"#Outlier Treatment \n#Datapoints from age and amount column were removed whereas balance above 50000 i.e. 647 customers' balance was replaced by their mean.\n\n#age=data[data['age']>60]\n#print(len(age))\n#amo=data[data['amount']>6000]\n#print(len(amo))\n#len(data[data['balance']>50000])\n\ndata=data[data['age']<60] \ndata=data[data['amount']<6000]\ndata.loc[data['balance']>50000,'balance']=np.mean(data['balance'])","54ad4de2":"#Dropping the day_name column from the dataset after analysis\n\ndata=data.drop('day_name',axis=1)","8ffcd1dd":"#Viewing the shape of the dataset after outlier treatment and removal of the extra column created\n\ndata.shape","95c74448":"data_salary=data[data['txn_description']=='PAY\/SALARY']","52b90ebf":"data_salary.shape\n","a9d9cb5a":"#Creating a new column with the amount credited as salary and dropping the amount column \ndata_salary['annual_salary']=data_salary['amount']\ndata_salary=data_salary.drop(['amount'],axis=1)","8568e5f5":"#Removing the columns having only id details and other columns having only one category - which will return 1's in all the rows.\n\ncols=['account','long_lat','txn_description','first_name','extraction','transaction_id','country','customer_id','card_present_flag','currency','merchant_state','movement','status']","184348bd":"data_salary=data_salary.drop(cols,axis=1)","d52c8c2d":"data_salary.dtypes","5167d99b":"from sklearn.preprocessing import StandardScaler\n\ndata_salary=pd.get_dummies(data_salary)\nscalar=StandardScaler()\nsc_cols=['balance','age','annual_salary']\nscalar.fit_transform(data_salary[sc_cols])\nprint(data_salary.shape)","544f5e98":"#Plotting a heatmap of the correlation between the features\ncorr=data_salary.corr()\ncorr.sort_values(['annual_salary'],ascending=True,inplace=True)\nprint(corr['annual_salary'])\nsns.heatmap(corr,annot=True)","c2e245d5":"X=data_salary.drop('annual_salary',axis=1)\nY=data_salary['annual_salary']","e6889c75":"from sklearn.model_selection import train_test_split\nX_train,x_test,Y_train,y_test=train_test_split(X,Y,test_size=0.25)\n","d56f6455":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nLRmodel=LinearRegression()\nLRmodel.fit(X_train,Y_train)\ny_pred=LRmodel.predict(x_test)\nLinReg=LRmodel.score(x_test,y_test)\nprint(\"Score using Linear Regression\",LinReg)\nprint(\"RMSE\",np.sqrt(mean_squared_error(y_pred,y_test)))","cce4c6d1":"from sklearn.linear_model import Ridge\n\nRmodel=Ridge()\nRmodel.fit(X_train,Y_train)\ny_pred=Rmodel.predict(x_test)\nRidge=Rmodel.score(x_test,y_test)\nprint(\"Score using Ridge:\",Ridge)\nprint(\"RMSE on test data:\",np.sqrt(mean_squared_error(y_test,y_pred)))\n","f8a905e5":"from sklearn.linear_model import ElasticNet\n\nENmodel=ElasticNet()\nENmodel.fit(X_train,Y_train)\ny_pred=ENmodel.predict(x_test)\nElasticnet=ENmodel.score(x_test,y_test)\nprint(\"Score using Elastic Net:\",Elasticnet)\nprint(\"RMSE on test data:\",np.sqrt(mean_squared_error(y_test,y_pred)))","66ba14d9":"from sklearn.tree import DecisionTreeRegressor\n\nDTmodel=DecisionTreeRegressor()\nDTmodel.fit(X_train,Y_train)\ny_pred=DTmodel.predict(x_test)\nDTReg=DTmodel.score(x_test,y_test)\nprint(\"Score using Decision Tree Regressor:\",DTReg)\nprint(\"RMSE on test data:\",np.sqrt(mean_squared_error(y_test,y_pred)))\n","5e6a25f3":"from sklearn.ensemble import RandomForestRegressor\n\nRFmodel=RandomForestRegressor()\nRFmodel.fit(X_train,Y_train)\ny_pred=RFmodel.predict(x_test)\nRFReg=RFmodel.score(x_test,y_test)\nprint(\"Score using Random Forest Regressor:\",RFReg)\nprint(\"RMSE on test data\",np.sqrt(mean_squared_error(y_test,y_pred)))","3653548a":"from xgboost import XGBRegressor\n\nXGmodel=XGBRegressor()\nXGmodel.fit(X_train,Y_train)\ny_pred=XGmodel.predict(x_test)\nXGReg=XGmodel.score(x_test,y_test)\nprint(\"Score using XGBoost:\",XGReg)\nprint(\"RMSE on test data\",np.sqrt(mean_squared_error(y_test,y_pred)))","ea4e95c9":"from sklearn.model_selection import RandomizedSearchCV\n\nbooster=['gblinear','gbtree']\nlearning_rate=[0.001,0.01,0.1,0.2,0.5]\nn_estimators=[50,100,150,200,250]\nmax_depth=[2,4,6,8,10]\nparam_grid=dict(max_depth=max_depth,n_estimators=n_estimators,booster=booster,learning_rate=learning_rate)\n\nrandom_search=RandomizedSearchCV(XGmodel,param_grid,scoring='neg_mean_squared_error',cv=5,n_jobs=-1)\nresult=random_search.fit(X_train,Y_train)\nprint(\"Best: %f using %s\"%(result.best_score_,result.best_params_))","13581431":"print(result.best_estimator_)","bbc5e853":"final_model=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n             importance_type='gain', interaction_constraints='',\n             learning_rate=0.2, max_delta_step=0, max_depth=6,\n             min_child_weight=1, monotone_constraints='()',\n             n_estimators=150, n_jobs=0, num_parallel_tree=1, random_state=0,\n             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n             tree_method='exact', validate_parameters=1, verbosity=None)\n             \nfinal_model.fit(X_train,Y_train)\ny_final_pred=final_model.predict(x_test)\nprint(\"Score after hyperparameter tuning using XGBoost:\",final_model.score(x_test,y_test))\nprint(\"RMSE on test data:\", np.sqrt(mean_squared_error(y_test,y_final_pred)))","7befdd81":"# Exploratory Data Analysis","cb243887":"Observations:\n\n1)224 customers are above the age group of 60.\n2)Only 9 customers have a transaction amount of more than 6000.\n3)657 customers have balance above 50000.\n3)After preprocessing and cleaning the dataset, there are 11810 rows and 17 columns.","508a1760":"Observations:\n\n1)All the customers are from Australia.\n2)The transaction amount is in terms of Australian Dollars.\n3)64.07% i.e 7717 of the customers have a status of \"Authorized\" whereas 35.92% i.e 4326 customers have the status of \"Posted\".\n4)80.26% of customers used card and 19.74% did not use card for transactions.\n5)The merchants belong to 8 different states.\n6)NSW state has the most number of transactions.\n7)11160 customers fall under the category of debit transactions and 883 customers' accounts were credited.","bb6e988a":"# Hyper parameter tuning of XGBoost \n\nSince XGBoost regressor has the highest score, hyperparameter tuning is done to further minimize the loss function 'Root Mean Squared Error' on the test data, used as performance metrics for better performance of the model. We will use RandomizedSearchCV as it will take less computational time than GridSearchCV because XGboost has many parameters.","fd347bc5":"# Predictive Modelling\n","389163d4":"Observations:\n\n1)The dataset contains 12043 rows and 23 columns.\n2)The maximum transaction amount is 8835.98 whereas 75 percentile of data have a value of less than 53.65. \n3)The mean transaction amount is 187.93.\n4)The standard deviation i.e the average spread from mean is 592.59. \n5)Average age of customers is 30 and 75% of customers are below the age of 38.\n6)Maximum balance is 267128.52 whereas the mean is only 14704.19. \n7)The percentiles along with the standard deviation of amount and balance suggests a large spread and presence of outliers in the data.\n8)Most of the transactions were done through card.\n9)A new column having the days of the transactions is added to the dataset.","244d2ccd":"Observations:\n\n1)One hot encoding is done to the categorical feature \"gender\" and standardization to other numerical features.\n2)Annual Salary has positive correlation with male gender and balance of customers. Whereas, a negative correlation with female gender and very low negative with customers' age.\n3)Scores using different regression techniques show that XGBoost Regressor has the highest score and least RMSE on the test dataset.\n4)After hyperparameter tuning, RMSE is reduced to 747.45 with 0.52 R^2 score.","63d12d48":"# Comparison\n\n1)Analysis and visualisation of latitude and longitude needs to be done for gaining more information about the customers' locations.\n\n2)More features need to be engineered and fetched for increasing the efficiency of the business model.\n","1abd09e6":"# Virtual Internship - ANZ Transactions Dataset\n\nThis dataset contains 3 months of transactions history for 100 hypothetical customers provided by Data ANZ company .\nhttps:\/\/www.theforage.com\/modules\/ZLJCsrpkHo9pZBJNY\/BiJPfqmGY2QwgN6gA","8e170fcd":"# Objectives:\n\n1)To perform exploratory data analysis on the above dataset and draw insights from the information provided in it.\n2)Building a regression and a decision-tree prediction model to predict the annual salary of the customers whose salaries were credited to their accounts.","5773cb7c":"# Features:\n\n1)status : the status of the transaction i.e posted or authorized for each transaction.\n2)card_present_flag : whether the transaction was done by card or not (1= Yes and 0 = No).\n3)bpay_biller_code : unique code of the BPay Transaction done by the customers.\n4)account : account number of the customers.\n5)currency : currency type (Australian Dollars).\n6)long_lat : Longitude and Latitude location of the customers.\n7)txn_description : the mode of transaction the customers have done.\n8)merchant_id : the merchant id where the customers had done their transactions.\n9)merhant_code : unique merchant code of the merchants.\n10)first_name : first name of the customers.\n11)balance : balance of the customers during each transaction.\n12)date : date on which the transaction took place.\n13)gender : gender of the customers (Male or Female).\n14)age : age of the customers.\n15)merchant_suburb : the area where the merchants' business stores are located.\n16)merchant_state : the state where the merchants' stores are located.\n17)extraction : date and time of each transaction.\n18)amount : the amount transacted by the customers.\n19)transaction_id : unique transaction id given by the merchant when the customer makes a transaction.\n20)country : country where the customers belong to.\n21)customer_id = unique id of each customer.\n22)merchant_long_lat : the latitude and longitude location of the merchants.\n23)movement : how the transaction is made (credit or debit).","526124dd":"Observations:\n    \n1)Total number of customers are 100.\n2)Customer id ranges from CUS-1005756958 to CUS-883482547.\n3)The customer named \"Kenneth\" with Id: CUS-2738291516 did the maximum transaction of worth 45409.16 in 3 months.\n4)CUS-1816693151 named \"Tim\" did the maximum single transaction of 8835.98.\n5)Transaction amount is relatively more after the first half of every month.\n6)The monthly total and the monthly average transaction amount are highest in the month of October.\n7)The number of transactions are increasing with each month. \n8)In the first week of every month, the sale is comparatively low.\n9)Wednesday and Friday have the most number of transactions.\n10)The average balance of customers also increase with each month.\n11)Top five customers with the maximum number of transactions done over the period of 3 months are -       \n   \"Michael,Diana,Jessica,Joseph and Jeffrey\"\n12)Michael with customer id: CUS-2142601169\thas done the maximum number of transactions in the course of 3 months.","4bd573be":"Observations:\n\n1)There are 7 columns with missing values out of which 5 columns are dropped having the maximum number of missing values with unique id and location details alongwith wide variety of categories.\n2)After imputing the missing values, the dataset contains 12043 rows and 19 columns."}}