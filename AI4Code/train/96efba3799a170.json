{"cell_type":{"682a6a05":"code","473e37c2":"code","63fd6a69":"code","40acc60a":"code","a04402a2":"code","ec1be713":"code","680a5e74":"code","4b61c80e":"code","38cfe4ac":"code","2d0d9b05":"code","9d5f3427":"code","a76b974f":"code","ab1f7528":"code","d483ac13":"code","dbadbb0a":"code","4af99aa1":"code","c0e2d7ed":"code","a9242b81":"code","0fc4aad7":"code","85a796ed":"code","0e304517":"code","2f23f726":"code","f2b276f7":"code","22e098bf":"code","19876499":"code","b4188696":"code","26031ac0":"code","d6a8a26f":"code","6369297e":"code","07c4ec44":"code","9d6609f4":"code","2222c8d4":"code","f2f43fcd":"code","dccd555d":"code","f325e5f8":"code","02bc0bc1":"markdown","cbeb4d89":"markdown","5c1dfd58":"markdown","89b3dbec":"markdown","e8c14adf":"markdown","63fab373":"markdown","9662968f":"markdown","4a39eed1":"markdown","7e8ae0ec":"markdown","2e6f82eb":"markdown","1c3419c0":"markdown","40c42b7f":"markdown","fd28c47f":"markdown","fa90c87e":"markdown","2a3b08d0":"markdown","98d10976":"markdown","36dbd15d":"markdown","7ca32b4d":"markdown","fb7e5fb7":"markdown","1c3c197e":"markdown","816b0ed9":"markdown","b01a2bcb":"markdown","e6955098":"markdown","eb744248":"markdown","b1acc7d7":"markdown","2065ff6a":"markdown","1d967c92":"markdown","d0813d3c":"markdown","107e0506":"markdown","bf834d1b":"markdown","c12548e8":"markdown","fcf8d677":"markdown","ab836ce3":"markdown","433aa301":"markdown","bf7fb817":"markdown","82c7fa2b":"markdown","06c7fdd7":"markdown","be4ca386":"markdown","e4d804f3":"markdown","7bbed49b":"markdown","9bef5221":"markdown","b3380aae":"markdown","06733ec3":"markdown","57f70d2a":"markdown","b17297e4":"markdown","d41dfda2":"markdown","8fa83d4a":"markdown","b21e626f":"markdown","edec39ef":"markdown","7478c921":"markdown","f0bab086":"markdown","ef98e3d9":"markdown","fc3a6a6e":"markdown","3f3f807d":"markdown","9fe4736f":"markdown","439ee345":"markdown","571c52ca":"markdown","b851357b":"markdown","fbdb340d":"markdown","702bdf01":"markdown","eb0285d3":"markdown","d25b9619":"markdown","356da9c0":"markdown"},"source":{"682a6a05":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('ggplot')\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot, download_plotlyjs\nimport cufflinks as cf\ninit_notebook_mode(connected=True)\ncf.go_offline()\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nprint(os.listdir(\"..\/input\"))\nprint()\nprint(\"The files in the dataset is:-- \")\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","473e37c2":"# Importing the dataset\ndf = pd.read_csv('..\/input\/BlackFriday.csv')","63fd6a69":"# Let us check the Top 5 entries in the dataset.\ndf.head()","40acc60a":"# Basic information \ndf.info()","a04402a2":"# Let us check the Number of Null values and it's Percentage .\ntemp_df = df.isnull().sum().reset_index()\ntemp_df['Percentage of Null Values'] = temp_df[0]\/len(df)*100\ntemp_df.columns = ['Column Name', 'Number of Null Values','Percentage of Null Values']\ntemp_df","ec1be713":"# Removing Product_Category_3 column\ndf.drop(labels='Product_Category_3', axis=1, inplace=True)","680a5e74":"# Let us fill the Null values in Product_Categorical_2 column\n# First let us check the product which come maximum number of times in this column.\nnew_df = df['Product_Category_2'].value_counts().reset_index()\n\nnew_df.iplot(kind='bar', x='index',y='Product_Category_2', title='Frequency of values in Product_Category_2 Column',\n            xTitle='Product Category', yTitle='Frequency', color='deepskyblue')\n","4b61c80e":"# Filling Null values.\ndf['Product_Category_2'].fillna(value=8, inplace=True)\ndf['Product_Category_2'].unique()","38cfe4ac":"gender = df['Gender'].value_counts().reset_index()\ngender.columns = ['Gender', 'Count']\ngender.iplot(kind='pie', labels='Gender', values='Count', hole=0.2, pull=0.2, title='Ratio of Male and Female')\n# Interactive plot with plotly.","2d0d9b05":"age = df['Age'].value_counts().reset_index()\nage.columns = ['Age Group', 'Count']\nage.iplot(kind='bar', x='Age Group', y='Count', title='Number of people belongs to different age group',\n         xTitle='Age Group', yTitle='Quantity', color='deepskyblue')","9d5f3427":"try:\n    df.drop(labels=['User_ID', 'Product_ID'], inplace=True, axis=1,)\nexcept Exception as e: \n    print(\"Run from start again.\")\ndf.head()","a76b974f":"city = df['City_Category'].value_counts().reset_index()\ncity.iplot(kind='pie', labels='index', values='City_Category', hole=0.2, pull=0.2,\n          title='Percentage of People belongs to different City Category')","ab1f7528":"temp_df = df.groupby('Gender', axis=0)['Purchase'].sum().reset_index()\ntemp_df.iplot(kind='bar', x='Gender', y='Purchase', title='Total Purchase amount of Male and Female',\n             xTitle='Gender', yTitle='Total Purchase Amount', color='orange')\n","d483ac13":"status = df['Marital_Status'].value_counts().reset_index()\n# Converting 0 and 1 into Married and Non Married in status DataFrame\nstatus['index'] = status['index'].apply(lambda x: 'Non Married' if x==0 else 'Married')\n\nstatus.iplot(kind='pie', labels='index', values='Marital_Status', hole=0.2, pull=0.2,\n          title='Ratio of Married people and Non Married people')\nstatus.T","dbadbb0a":"temp_df = df.groupby('Marital_Status', axis=0)['Purchase'].sum().reset_index()\ntemp_df['Marital_Status'] = temp_df['Marital_Status'].apply(lambda x: 'Non Married' if x==0 else 'Married')\n\ntemp_df.iplot(kind='bar', x='Marital_Status', y='Purchase', title='Total Purchase amount of Male and Female',\n             xTitle='Marital_Status', yTitle='Total Purchase Amount', color='red')\n","4af99aa1":"pro1 = df['Product_Category_1'].reset_index()\npro1.columns = ['index', 'product']\n\npro2 = df['Product_Category_2'].reset_index()\npro2.columns = ['index', 'product']\nproduct = pd.concat([pro1, pro2] )\n\nproduct = product['product'].value_counts().reset_index()[:10]\nproduct.iplot(kind='bar', x='index', y='product', title='Top 10 product number which purchase maximum number of times',\n             xTitle='Product number', yTitle='Frequency', color='deepskyblue')","c0e2d7ed":"rich = df.groupby('City_Category')['Purchase'].sum().reset_index()\nrich.sort_values('Purchase',ascending=False, inplace=True)\nrich.iplot(kind='pie', labels='City_Category' ,values='Purchase', hole=0.2, pull=0.2,\n           title='Richest among A,B,C', )\n","a9242b81":"df.corr().iplot(kind='heatmap', title='HeatMap on Correlation of features ')","0fc4aad7":"# IMporting the useful Machine Learning libraries.\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import cross_val_score\n","85a796ed":"# Let us create a feature matrix and target vector.\nx_train = df.iloc[:,:-1].values      # Feature matrix\ny_train = df.iloc[:,-1].values     # Target vector","0e304517":"# Apply LabelEncoder to convert categorical values into 0,1 and so on format.\nlabel_x = LabelEncoder()\nx_train[:,0] = label_x.fit_transform(x_train[:,0])\nx_train[:,1] = label_x.fit_transform(x_train[:,1])\nx_train[:,3] = label_x.fit_transform(x_train[:,3])\nx_train[:,4] = label_x.fit_transform(x_train[:,4])\n\n# Apply OneHotEncoder to split the columns which have more than 2 categories.\none_hot = OneHotEncoder(categorical_features=[1,2,3,4,6,7])\nx_train = one_hot.fit_transform(x_train).toarray()\nprint(f\"\"\"Now let us see the shape of our x_train matrix.\nShape of x_train matrix =\\t {x_train.shape}.\nSo now we have 73 columns.\nNow we will apply Dimensionalty Reduction to reduce the number of features\/columns with the help of PCA algorithm. \"\"\")","2f23f726":"# Scaling the feature matrix.\nsc_x = StandardScaler()\nx_train = sc_x.fit_transform(x_train)\n\n# Scaling the Target Vector.\nsc_y = StandardScaler()\ny_train = y_train.reshape(-1,1)    # Converting the 1-D array into 2-array.\ny_train = sc_x.fit_transform(y_train)","f2b276f7":"pca = PCA(n_components=None)\nx_train = pca.fit_transform(x_train)\npca.explained_variance_ratio_","22e098bf":"pca = PCA(n_components=50)   # Fitting PCA with 50 features.\nx_train = pca.fit_transform(x_train)","19876499":"# Multi-linear regression Model. \nregressor_multi = LinearRegression()\nregressor_multi.fit(x_train,y_train)\n# Let us check the accuray\naccuracy = cross_val_score(estimator=regressor_multi, X=x_train, y=y_train,cv=10)\nprint(f\"The accuracy of the Multi-linear Regressor Model is \\t {accuracy.mean()}\")\nprint(f\"The deviation in the accuracy is \\t {accuracy.std()}\")\nprint()","b4188696":"\"\"\"\n# SVR \nregressor_svr = SVR(kernel='rbf')\nregressor_svr.fit(x_train, y_train)\n# Let us check the accuracy\naccuracy = cross_val_score(estimator=regressor_svr, X=x_train, y=y_train,cv=10)\nprint(f\"The accuracy of the SVR Model is \\t {accuracy.mean()}\")\nprint(f\"The deviation in the accuracy is \\t {accuracy.std()}\")\nprint()\n\"\"\"\nprint(\"Apply this model, if accuracy is good then use this model\")\nprint(\"This model takes too much time. \")","26031ac0":"df.head()","d6a8a26f":"# Creating Feature matrix and Target vector.\nx_train = df.drop(labels='Marital_Status',axis=1).values\ny_train = df['Marital_Status'].values","6369297e":"# Apply LabelEncoder to convert categorical values into 0,1 and so on format.\nlabel_x = LabelEncoder()\nx_train[:,0] = label_x.fit_transform(x_train[:,0])\nx_train[:,1] = label_x.fit_transform(x_train[:,1])\nx_train[:,3] = label_x.fit_transform(x_train[:,3])\nx_train[:,4] = label_x.fit_transform(x_train[:,4])\n\n# Apply OneHotEncoder to split the columns which have more than 2 categories.\none_hot = OneHotEncoder(categorical_features=[1,2,3,4,5,6])\nx_train = one_hot.fit_transform(x_train).toarray()\nprint(f\"\"\"Now let us see the shape of our x_train matrix.\nShape of x_train matrix =\\t {x_train.shape}.\nSo now we have 73 columns.\nNow we will apply Dimensionalty Reduction to reduce the number of features\/columns with the help of PCA algorithm. \"\"\")","07c4ec44":"sc_x = StandardScaler()\nx_train = sc_x.fit_transform(x_train)","9d6609f4":"pca = PCA(n_components=None)\nx_train = pca.fit_transform(x_train)\npca.explained_variance_ratio_","2222c8d4":"pca = PCA(n_components=50)   # Fitting PCA with 50 features.\nx_train = pca.fit_transform(x_train)","f2f43fcd":"# Apply Logistic regression\n# First step is to train our model .\n\nclassifier_logi = LogisticRegression()\nclassifier_logi.fit(x_train,y_train)\n\n# Let us check the accuracy of the model\naccuracy = cross_val_score(estimator=classifier_logi, X=x_train, y=y_train, cv=10)\nprint(f\"The accuracy of the Logistic Regressor Model is \\t {accuracy.mean()}\")\nprint(f\"The deviation in the accuracy is \\t {accuracy.std()}\")","dccd555d":"\"\"\"\n\n# Apply SVM with Gaussian kernel\nclassifier_svm2 = SVC(kernel='rbf', )\nclassifier_svm2.fit(x_train,y_train)\naccuracy = cross_val_score(estimator=classifier_svm2, X=x_train, y=y_train, cv=10)\nprint(f\"The accuracy of the SVM Gaussian kernel Model is \\t {accuracy.mean()}\")\nprint(f\"The deviation in the accuracy is \\t {accuracy.std()}\")\n\"\"\"\nprint(\"SVC Model\")","f325e5f8":"\"\"\"\n\n# Apply Naive Bayes Model.\n# Train Model\nclassifier_bayes = GaussianNB()\nclassifier_bayes.fit(x_train,y_train)\n# Check the accuracy and deviation in the accuracy\naccuracy = cross_val_score(estimator=classifier_bayes, X=x_train, y=y_train, cv=10)\nprint(f\"The accuracy of the Naive Bayes Model is \\t {accuracy.mean()}\") \nprint(f\"The deviation in the accuracy is \\t {accuracy.std()}\")\n\"\"\"\nprint(\"Navie-Bayes Model\")","02bc0bc1":"### =======================================================================","cbeb4d89":"#### b). SVR Model","5c1dfd58":"* So product number 8 is purchased maximum number of times.","89b3dbec":"### 5). Ratio of City Category.","e8c14adf":"# BASIC EDA","63fab373":"### ========================================================================","9662968f":"\n### =========================================================================","4a39eed1":"#### NOTE\n* When we are dealing with regression problem then we also need to do feature scaling on Target Vector.\n* In case of classification problem we do not need to do feature scaling on Target vector.\n* In both type of problem we will apply feature scaling on our Feature matrix.","7e8ae0ec":"### 1). Dealing with Null values\/ missing data.","2e6f82eb":"### ================================================================\n","1c3419c0":"### 6). Naiye-Bayes Model.","40c42b7f":"### 8). Total purchase amount of Married and Non Married people.","fd28c47f":"* As one can B is the richest city among A,B,C with 41% followed by C and then followed by A.\n* If mall owner knows that a particular person is from which city then worker there can show them products according to it, which lead to the benefit of the company.\n","fa90c87e":"### 5). Apply Support Vector Classifier (SVC).","2a3b08d0":"* As there are 70% Null values in coulmn name Product_Category_3.\n* So we will remove this column from our dataset.\n* And Null values in column Product_Category_2, we will replaced it by mode of the column.","98d10976":"### 6). Let us see the total purchase amount of Male and Female.","36dbd15d":"### 4). Apply Multi-linear Regression and Support vector regressor Model.","7ca32b4d":"* As expected, as Non Married people are more in number than Married people, so thier total purchase amount is also large.","fb7e5fb7":"### 7). Ratio of married and non married poplutions.","1c3c197e":"* Here On the basis of data we will classify whether a person is married or not.","816b0ed9":"### 4). Apply Logistic Regression Model.","b01a2bcb":"### 2). Ratio of Male and Female.","e6955098":"### ======================================================================","eb744248":"* Now we will fill  the Null values with 8.\n* One can also try not to fill the missing values.","b1acc7d7":"<img src='' width=1000 >","2065ff6a":"### 10). Rich city from city category A,B,C.","1d967c92":"#### a). Mutli-linear Regression Model.","d0813d3c":"### 2). Scaling the feature matrix, so that we can compare them on the same scale.","107e0506":"# REGRESSION","bf834d1b":"### Observation:-\n* Here we are getting accuracy of 50% with deviation of only 0.02%.\n* In my view this is good accuracy with this deviation.\n* Here we are getting low accuracy, it may indicates that our model may be not linear, so by applying the other non-linear algothim we may get more accuracy.","c12548e8":"### 3). Dimensionality Reduction with Principle Component Analysis (PCA).","fcf8d677":"#### Observations:-\n* Non Married people come to maximum number of times to shoping.\n* Non Married people are 59% and Married people are 41%.\n* By this mall owner can increse the products which belongs to Non Married people.\n* In this way owner can increase his\/her profit.\n* And the products which belongs to Non Married people, owner can place them near to entry gate or at a hot place of mall.","ab836ce3":"* Approximately equal number of people are there from city A,B and C.\n* But from these all B city contains the maximum number of people.","433aa301":"### 2). Scaling the feature matric.","bf7fb817":"### Observations:-\n* Accuracy of 65% with only 0.2% deviation.\n* Our model is good.\n* Now we can also apply other model, to check the accuray of other models.\n* But other models will take so much time to train.\n* I am here providing the code of SVC Model and Navie-Bayes Model, but I am not ruuning them right now.\n* Feel free to use code of these models to train your model","82c7fa2b":"# EDA + REGRESSION + CLASSIFICATION FROM SCRATCH WITH BLACK FRIDAY DATASET","06c7fdd7":"### ======================================================================","be4ca386":"### ==========================================================================","e4d804f3":"### 11). Correlation between features on heatmap.","7bbed49b":"### =============================================================================","9bef5221":"* 75% are Male as compare to 25% Female.\n* Some Interesting Fact.\n* It indicates that maximum number of products are releted to male or male are under pressure from thier wife to go to shopping :p .","b3380aae":"### 9). Which Product Category Purchased maximum number of times.","06733ec3":"### ======================================================================","57f70d2a":"### 4). Let us first remove the unwanted columns.\n","b17297e4":"### ==============================================================","d41dfda2":"### 1). Dealing with categorical values.","8fa83d4a":"* So now we will take 50 features (taking number of features with e-02). ","b21e626f":"### 3). Dimensionalty Reduction with the help of PCA algorithm.","edec39ef":"### ==========================================================================","7478c921":"#### Observation:-\n* Maximum Number of people are from the Age group of 26-35.\n* Young population is maximum.\n* Children are in less number (0-17 age group).\n* Old people are also there (55+ age group).","f0bab086":"# IF THIS KERNEL IS USEFUL, THEN PLEASE UPVOTE.\n<img src='https:\/\/drive.google.com\/uc?id=1qihsaxx33SiVo5dIw-djeIa5SrU_oSML' width=500 >","ef98e3d9":"### ===========================================================================","fc3a6a6e":"### =============================================================================","3f3f807d":"# CLASSIFICATION","9fe4736f":"* Likewise one can also predict the Gender of a person.","439ee345":"### ========================================================================","571c52ca":"* As expected male have more total purchase amount than female due to large number of male as compare to female.\n* Color orange indicates gender equality.","b851357b":"### ===========================================================================","fbdb340d":"### 3). From which age group people belongs maximum.","702bdf01":"### =======================================================================","eb0285d3":"<img src='https:\/\/drive.google.com\/uc?id=1ptXTg9tJspLaf6G3N7-rdUDMLeu7srM6' width=1000 >","d25b9619":"### ===========================================================================","356da9c0":"### 1). Dealing with categorical values."}}