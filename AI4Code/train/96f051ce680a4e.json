{"cell_type":{"041d914f":"code","bb5c30b8":"code","872c69da":"code","4b99f7dd":"code","87497d59":"code","bfeeff09":"code","98a0cd42":"code","f21ca81b":"code","c52a8682":"code","6edc79d2":"code","edc9929f":"markdown","b1e4f9e8":"markdown","e867e183":"markdown","63774dbf":"markdown","bceda3ac":"markdown","2ed2c16e":"markdown","bba2462c":"markdown","e74bb7e8":"markdown","861c1ab4":"markdown","6322d98b":"markdown"},"source":{"041d914f":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","bb5c30b8":"import numpy as np\nimport pandas as pd\nimport os\n\nfrom sklearn import preprocessing\nfrom sklearn.decomposition import PCA","872c69da":"os.listdir('..\/input\/lish-moa')","4b99f7dd":"train_features = pd.read_csv('..\/input\/lish-moa\/train_features.csv')\ntrain_targets_scored = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv('..\/input\/lish-moa\/train_targets_nonscored.csv')\ntest_features = pd.read_csv('..\/input\/lish-moa\/test_features.csv')","87497d59":"train_features.info()","bfeeff09":"train_features.head()","98a0cd42":"GENES = [col for col in train_features.columns if col.startswith('g-')]\nCELLS = [col for col in train_features.columns if col.startswith('c-')]\nlen(GENES+CELLS)","f21ca81b":"from sklearn.preprocessing import QuantileTransformer","c52a8682":"for col in (GENES + CELLS):\n    transformer = QuantileTransformer(random_state=0, output_distribution=\"normal\")\n    vec_len = len(train_features[col].values)\n    vec_len_test = len(test_features[col].values)\n    raw_vec = train_features[col].values.reshape(vec_len, 1)\n    transformer.fit(raw_vec)\n\n    train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]\n    \ndata = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])","6edc79d2":"pca = PCA().fit(data)\n\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (12,6)\n\nfig, ax = plt.subplots()\nxi = np.arange(1, 773, step=1)\ny = np.cumsum(pca.explained_variance_ratio_)\n\nplt.ylim(0.0,1.1)\nplt.plot(xi, y, marker='o', linestyle='--', color='b')\n\nplt.xlabel('Number of Components')\nplt.xticks(np.arange(0, 750, step=50)) #change from 0-based array index to 1-based human-readable label\nplt.ylabel('Cumulative variance (%)')\nplt.title('The number of components needed to explain variance')\n\nplt.axhline(y=0.95, color='r', linestyle='-')\nplt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)\n\nax.grid(axis='x')\nplt.show()","edc9929f":"### Now we have standardized our Data","b1e4f9e8":"## Choosing PCA on Genes columns ","e867e183":"### Remember to scale the data to the range between 0 and 1 before using PCA!\nTypically, we want the explained variance to be between 95\u201399%. ","63774dbf":"# If you like it, Do Upvote :)","bceda3ac":"In this short kernel, I am going to show you how to choose the `number of principal components` when using principal component analysis for dimensionality reduction as in MoA Competition ","2ed2c16e":"Full Post for detailed Explanation :- https:\/\/www.mikulskibartosz.name\/pca-how-to-choose-the-number-of-components\/","bba2462c":"Don\u2019t do it. Don\u2019t choose the number of components manually.Instead of that, use the option that allows you to set the variance of the input that is supposed to be explained by the generated components.","e74bb7e8":"## In this case, to get 95% of variance explained I need 600 principal components.","861c1ab4":"From the Scikit-learn implementation, we can get the information about the explained variance and plot the cumulative variance.","6322d98b":"On the plotted chart, we see what number of principal components we need."}}