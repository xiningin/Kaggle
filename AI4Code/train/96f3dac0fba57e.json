{"cell_type":{"86bfa868":"code","c468d74e":"code","c41708cf":"code","d075123d":"code","314bb3f7":"code","13ed9592":"code","b1248187":"code","507b8035":"code","97b0ec34":"code","17975942":"code","667c5632":"code","59d763ff":"code","151ec9b8":"code","45e6c533":"code","f7714ff9":"code","2de34d30":"code","b06e9606":"code","0f30b45d":"code","7cba2f3a":"code","74c557a4":"code","2aea66b6":"code","5a570514":"code","cf134662":"code","1c1ef477":"markdown","9ac6f762":"markdown","8d8d26e5":"markdown","30fc397b":"markdown","afbcf54e":"markdown","96f3a7af":"markdown","73a1d3d8":"markdown","0cac3528":"markdown","21f3558c":"markdown","830e04d9":"markdown","ebe1f5e7":"markdown","6d3dcafb":"markdown"},"source":{"86bfa868":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport pandas as pd\nimport pickle\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport zipfile ","c468d74e":"train = pd.read_csv(\"..\/input\/histopathologic-cancer-detection\/train_labels.csv\", dtype=str)\nprint(train.shape)","c41708cf":"train.head(10)","d075123d":"y_train = train.label\n\n(train.label.value_counts() \/ len(train)).to_frame().T","314bb3f7":"# Sample 16 images from the training set and display these along with their labels.\n\nplt.figure(figsize=(10,10)) # specifying the overall grid size\n\nfor i in range(16):\n    plt.subplot(4,4,i+1)    # the number of images in the grid is 6*6 (16)\n    img = mpimg.imread(f'..\/input\/histopathologic-cancer-detection\/train\/{train[\"id\"][i]}.tif')\n    plt.imshow(img)\n    plt.text(0, -5, f'Label {train[\"label\"][i]}')\n    plt.axis('off')\n    \nplt.tight_layout()\nplt.show()","13ed9592":"train_neg = train[train['label']=='0'].sample(4000,random_state=1)\ntrain_pos = train[train['label']=='1'].sample(4000,random_state=1)\n\ntrain_data = pd.concat([train_neg, train_pos], axis=0).reset_index(drop=True)\n\ntrain = shuffle(train_data)","b1248187":"train['label'].value_counts()","507b8035":"# function to apply the .tif extension\ndef append_ext(fn):\n    return fn+\".tif\"\n\n\ntrain['id'] = train['id'].apply(append_ext)\ntrain.head()","97b0ec34":"# Split the dataframe train into two DataFrames named train_df and valid_df. \n# Use 20% of the data for the validation set. \n# Use stratified sampling so that the label proportions are preserved.\n# Set a random seed for the split. \n\ntrain_df, valid_df = train_test_split(train, test_size=0.2, random_state=1, stratify=train.label)\n\nprint(train_df.shape)\nprint(valid_df.shape)","17975942":"# Create image data generators for both the training set and the validation set. \n# Use the data generators to scale the pixel values by a factor of 1\/255. \ntrain_datagen = ImageDataGenerator(rescale=1\/255)\nvalid_datagen = ImageDataGenerator(rescale=1\/255)","667c5632":"# Complete the code for the data loaders below. \n\nBATCH_SIZE = 64\n\ntrain_loader = train_datagen.flow_from_dataframe(\n    dataframe = train_df,\n    directory = '..\/input\/histopathologic-cancer-detection\/train\/',\n    x_col = 'id',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (32,32)\n)\n\nvalid_loader = train_datagen.flow_from_dataframe(\n    dataframe = valid_df,\n    directory = '..\/input\/histopathologic-cancer-detection\/train\/',\n    x_col = 'id',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (32,32)\n)","59d763ff":"# Run this cell to determine the number of training and validation batches. \n\nTR_STEPS = len(train_loader)\nVA_STEPS = len(valid_loader)\n\nprint(TR_STEPS)\nprint(VA_STEPS)","151ec9b8":"# Use this cell to construct a convolutional neural network model. \n# Your model should make use of each of the following layer types:\n#    Conv2D, MaxPooling2D, Dropout, BatchNormalization, Flatten, Dense\n# You can start by mimicking the architecture used in the \n# Aerial Cactus competetition, but you should explore different architectures\n# by adding more layers and\/or adding more nodes in individual layers\n\nnp.random.seed(1)\ntf.random.set_seed(1)\n\ncnn1 = Sequential([\n    Conv2D(32, (3,3), activation = 'relu', padding = 'same', input_shape=(32,32,3)),\n    Conv2D(32, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.25),\n    BatchNormalization(),\n\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.5),\n    BatchNormalization(),\n    \n    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.5),\n    BatchNormalization(),\n\n    Flatten(),\n    \n    Dense(32, activation='relu'),\n    Dropout(0.5),\n    Dense(16, activation='relu'),\n    Dropout(0.25),\n    BatchNormalization(),\n    # we have 2 here because we have 2 classes\n    Dense(2, activation='softmax')\n])\n\ncnn1.summary()","45e6c533":"opt = tf.keras.optimizers.Adam(0.001)\ncnn1.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.AUC()])","f7714ff9":"%%time \n\nh1 = cnn1.fit(\n    x = train_loader, \n    steps_per_epoch = TR_STEPS, \n    epochs = 30,\n    validation_data = valid_loader, \n    validation_steps = VA_STEPS, \n    verbose = 1\n)","2de34d30":"history = h1.history\nprint(history.keys())","b06e9606":"# Graph the result\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\n\nplt.subplot(1,3,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\n\nplt.subplot(1,3,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\n\nplt.subplot(1,3,3)\nplt.plot(epoch_range, history['auc'], label='Training')\nplt.plot(epoch_range, history['val_auc'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","0f30b45d":"# Use this cell to construct a convolutional neural network model. \n# Your model should make use of each of the following layer types:\n#    Conv2D, MaxPooling2D, Dropout, BatchNormalization, Flatten, Dense\n# You can start by mimicking the architecture used in the \n# Aerial Cactus competetition, but you should explore different architectures\n# by adding more layers and\/or adding more nodes in individual layers\n\nnp.random.seed(1)\ntf.random.set_seed(1)\n\ncnn2 = Sequential([\n    Conv2D(32, (3,3), activation = 'relu', padding = 'same', input_shape=(32,32,3)),\n    Conv2D(32, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.20),\n    BatchNormalization(),\n\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.6),\n    BatchNormalization(),\n    \n    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.6),\n    BatchNormalization(),\n\n    Flatten(),\n    \n    Dense(32, activation='relu'),\n    Dropout(0.6),\n    Dense(16, activation='relu'),\n    Dropout(0.20),\n    BatchNormalization(),\n    # we have 2 here because we have 2 classes\n    Dense(2, activation='softmax')\n])\n\ncnn2.summary()","7cba2f3a":"opt = tf.keras.optimizers.Adam(0.001)\ncnn2.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.AUC()])","74c557a4":"%%time \n\nh2 = cnn2.fit(\n    x = train_loader, \n    steps_per_epoch = TR_STEPS, \n    epochs = 50,\n    validation_data = valid_loader, \n    validation_steps = VA_STEPS, \n    verbose = 1\n)","2aea66b6":"history = h2.history\nprint(history.keys())","5a570514":"# Graph the result\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\n\nplt.subplot(1,3,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\n\nplt.subplot(1,3,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\n\nplt.subplot(1,3,3)\nplt.plot(epoch_range, history['auc_1'], label='Training')\nplt.plot(epoch_range, history['val_auc_1'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","cf134662":"\ncnn2.save('cancer_model.h5')\npickle.dump(history, open(f'cancer_history.pkl', 'wb'))","1c1ef477":"# Build Network","9ac6f762":"# Load Packages\n\n","8d8d26e5":"### Train Network","30fc397b":"# Save Model and History","afbcf54e":"# Split & Sample Data","96f3a7af":"# Training Run 1","73a1d3d8":"# Load DataFrame","0cac3528":"# View Sample of Images","21f3558c":"### Build Network","830e04d9":"# Model 2","ebe1f5e7":"# Train Network","6d3dcafb":"# Label Distribution"}}