{"cell_type":{"70f79b5e":"code","2b3da9a9":"code","319524c3":"code","16414b4d":"code","e8483dc8":"code","8f60bbc7":"code","b4c78467":"code","6b0be5d0":"code","edb3da0d":"code","af5b8885":"code","3a078db8":"code","87c2a834":"code","8dd18fbb":"code","483ca5d1":"code","d9e3d050":"code","4c4490df":"code","f9bc1bca":"code","27eb9a22":"code","92fd7f85":"code","25b7ce58":"code","2cfde696":"code","c769cb80":"code","4f771718":"code","2d4ae6db":"markdown","873259fb":"markdown","427e90df":"markdown","4113165e":"markdown","8e0e186d":"markdown","42fed870":"markdown","b428959e":"markdown","5cf0e73e":"markdown","fa07638f":"markdown","f3e29b9c":"markdown","510b234c":"markdown"},"source":{"70f79b5e":"import numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2b3da9a9":"!pip install imutils","319524c3":"from imutils import paths\nimport matplotlib.pyplot as plt\nimport argparse\nimport os\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split","16414b4d":"dataset = \"..\/input\/covid19-chest-xray-image-dataset\/dataset\"","e8483dc8":"args={}\nargs[\"dataset\"]=dataset","8f60bbc7":"import numpy as np\nimport cv2\niPaths = list(paths.list_images(args[\"dataset\"]))  #image paths\ndata = []\nlabels = []\nfor iPath in iPaths:\n    label = iPath.split(os.path.sep)[-2]   #split the image paths\n    image = cv2.imread(iPath)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #Convert images into RGB Channel\n    image = cv2.resize(image, (224, 224))  #Resizing the images\n    data.append(image)\n    labels.append(label)\ndata = np.array(data) \/ 255.0\nlabels = np.array(labels)","b4c78467":"import os\nData_Dir = \"..\/input\/covid19-chest-xray-image-dataset\/dataset\/\/\"","6b0be5d0":"Cimages = os.listdir(Data_Dir+\"covid\")\nNimages = os.listdir(Data_Dir+\"normal\")","edb3da0d":"import matplotlib.pyplot as plt\nimport cv2\nimport skimage\nfrom skimage.transform import resize\nimport numpy as np\ndef plotter(i):\n    normal = cv2.imread(Data_Dir+\"normal\/\/\"+Nimages[i])\n    normal = skimage.transform.resize(normal, (150, 150, 3))\n    coronavirus = cv2.imread(Data_Dir+\"covid\/\/\"+Cimages[i])\n    coronavirus = skimage.transform.resize(coronavirus, (150, 150, 3) , mode = 'reflect')\n    pair = np.concatenate((normal, coronavirus), axis=1)\n    print(\"Normal Chest X-ray Vs Covid-19 Chest X-ray\")\n    plt.figure(figsize=(10,5))\n    plt.imshow(pair)\n    plt.show()\nfor i in range(0,5):\n    plotter(i)","af5b8885":"LB = LabelBinarizer()\nlabels = LB.fit_transform(labels)\nlabels = to_categorical(labels); print(labels)\n(X_train, X_test, Y_train, Y_test) = train_test_split(data, labels,\n    test_size=0.20, stratify=labels, random_state=42)\ntrainAug = ImageDataGenerator(\n    rotation_range=15,\n    fill_mode=\"nearest\")","3a078db8":"model = VGG16(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=(224, 224, 3)))\nModel = model.output #head_Model\nModel = AveragePooling2D(pool_size=(4, 4))(Model)\nModel = Flatten(name=\"flatten\")(Model)\nModel = Dense(64, activation=\"relu\")(Model)\nModel = Dropout(0.5)(Model)\nModel = Dense(2, activation=\"softmax\")(Model)\nmodel = Model(inputs=model.input, outputs=Model)\nfor layer in model.layers:\n    layer.trainable = False","87c2a834":"X_train.shape,X_test.shape,Y_train.shape,Y_test.shape","8dd18fbb":"W_grid = 4 #width\nL_grid = 4 #lenth\nfig, axes = plt.subplots(L_grid, W_grid, figsize = (25, 25)) #subplots\naxes = axes.ravel()\nn_training = len(X_train)\nfor i in np.arange(0, L_grid * W_grid):\n    index = np.random.randint(0, n_training) # pick a random number\n    axes[i].imshow(X_train[index])\n    axes[i].set_title(Y_train[index])\n    axes[i].axis('off')\n    \nplt.subplots_adjust(hspace = 0.4)","483ca5d1":"INIT_LR = 1e-3\nEPOCHS = 30\nBS = 8","d9e3d050":"opt = Adam(lr=INIT_LR, decay=INIT_LR \/ EPOCHS)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\nprint(\"Compiling Starts\")\nR = model.fit_generator(\n    trainAug.flow(X_train, Y_train, batch_size=BS),\n    steps_per_epoch=len(X_train) \/\/ BS,\n    validation_data=(X_test, Y_test),\n    validation_steps=len(X_test) \/\/ BS,\n    epochs=EPOCHS)","4c4490df":"L = 5\nW = 3\nfig, axes = plt.subplots(L, W, figsize = (12, 12))\naxes = axes.ravel()\ny_pred = model.predict(X_test, batch_size=BS)\nfor i in np.arange(0,L*W):\n    axes[i].imshow(X_test[i])\n    axes[i].set_title('Prediction = {}\\n True = {}'.format(y_pred.argmax(axis=1)[i],\n                                                           Y_test.argmax(axis=1)[i]))\n    axes[i].axis('off')\n\nplt.subplots_adjust(wspace = 1, hspace=1)","f9bc1bca":"from sklearn.metrics import classification_report\ny_pred = model.predict(X_test, batch_size=BS)\ny_pred = np.argmax(y_pred, axis=1)\nprint(classification_report(Y_test.argmax(axis=1), y_pred,target_names=LB.classes_))","27eb9a22":"from sklearn.metrics import accuracy_score\naccuracy_score(Y_test.argmax(axis=1),y_pred)","92fd7f85":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(Y_test.argmax(axis=1), y_pred)\ntotal = sum(sum(cm))\nacc = (cm[0, 0] + cm[1, 1]) \/ total\nsensitivity = cm[0, 0] \/ (cm[0, 0] + cm[0, 1])\nspecificity = cm[1, 1] \/ (cm[1, 0] + cm[1, 1])\nprint(cm)\nprint(\"acc: {:.4f}\".format(acc))\nprint(\"sensitivity: {:.4f}\".format(sensitivity))\nprint(\"specificity: {:.4f}\".format(specificity))","25b7ce58":"# plot the loss\nplt.plot(R.history['loss'], label='train loss')\nplt.plot(R.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\nplt.savefig('LossVal_loss')\n\n# plot the accuracy\nplt.plot(R.history['accuracy'], label='train acc')\nplt.plot(R.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","2cfde696":"model.save('Covid_model.h5')","c769cb80":"import tensorflow as tf \nfrom keras.preprocessing import image\n#from keras.models import load_model\nmodel = tf.keras.models.load_model('Covid_model.h5')\nfrom keras.applications.vgg16 import preprocess_input\nimg = image.load_img('..\/input\/covid19-chest-xray-image-dataset\/dataset\/covid\/1-s2.0-S0929664620300449-gr2_lrg-b.jpg', target_size=(224, 224)) #insert a random covid-19 x-ray image\nimgplot = plt.imshow(img)\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nimg_data = preprocess_input(x)\nclasses = model.predict(img_data)\nNew_pred = np.argmax(classes, axis=1)\nif New_pred==[1]:\n  print('Prediction: Normal')\nelse:\n  print('Prediction: Corona')","4f771718":"img = image.load_img('..\/input\/covid19-chest-xray-image-dataset\/dataset\/normal\/NORMAL2-IM-0397-0001.jpeg', target_size=(224, 224)) #insert a random normal x-ray image\nimgplot = plt.imshow(img)\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nimg_data = preprocess_input(x)\nclasses = model.predict(img_data)\nNew_pred = np.argmax(classes, axis=1)\nif New_pred==[1]:\n  print('Prediction: Normal')\nelse:\n  print('Prediction: Corona')","2d4ae6db":"**Building the model and updating the weights of the base model using VGG16 network**","873259fb":"# Saving the model","427e90df":"# Initialize label binarizer","4113165e":"**Credits and learnings of this notebook for me is from this tutorial by Ashish https:\/\/www.youtube.com\/watch?v=RQxb_qroW00**","8e0e186d":"# Plotting the training and validation plot with respect to accuracy and loss","42fed870":"# Comapring the predictions","b428959e":"# Compiling the model","5cf0e73e":"# Thank you","fa07638f":"**Initialising learning rate as 1e-3 , epochs as 30 and batch size as 8**","f3e29b9c":"**The accuracy we got is 100% predicting all classes correctly may be it is due to less number of images.**","510b234c":"#  Result"}}