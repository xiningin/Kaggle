{"cell_type":{"67c5c901":"code","1362efc7":"code","89236190":"code","099d20f3":"code","62e5282b":"code","81b990b3":"code","0e7ce950":"code","2523e122":"code","3930e3af":"code","24399f41":"code","67d6dedb":"code","083c6422":"code","e2c571a9":"code","221ea939":"code","962bc923":"code","737b178f":"code","395998be":"code","064a4746":"code","43edd94b":"code","d8d138bc":"code","dba06092":"code","7a62eb12":"code","5fca31f1":"code","a0bc42c4":"code","0ef33b0a":"markdown"},"source":{"67c5c901":"import numpy as np \nimport pandas as pd\nfrom PIL import Image\nimport os\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader","1362efc7":"BATCH = 16\nEPOCHS = 2\n\nLR = 0.01\nIM_SIZE = 32\n\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\npath = '..\/input\/hotel-id-2021-fgvc8\/'\nTRAIN_DIR = path + 'train_images\/'\nTEST_DIR = path + 'test_images\/'","89236190":"train_df = pd.read_csv('..\/input\/hotel-id-2021-fgvc8\/train.csv')\ntrain_df","099d20f3":"train_df['hotel_id'].value_counts()","62e5282b":"train_df[train_df['chain']==8]","81b990b3":"NUM_CL = len(train_df['hotel_id'].value_counts())\nNUM_CL\n# 7770","0e7ce950":"from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\nle.fit(train_df['hotel_id'])\ntrain_df['label'] = le.transform(train_df['hotel_id'])\ntrain_df","2523e122":"# for Inference\n\nclass_map = dict(sorted(train_df[['label', 'hotel_id']].values.tolist()))","3930e3af":"# checking\ntrain_df[train_df['label'] == 6754]","24399f41":"train_df['chain_image'] = train_df['chain'].astype(str) + '\/' + train_df['image']\ntrain_df","67d6dedb":"# !!! Just for speed up training\ntr_df = train_df[:1000]\nprint(len(tr_df))\nX_Train, Y_Train = tr_df['chain_image'].values, tr_df['label'].values\n\n# X_Train = train_df['chain_image'].values\n# Y_Train = train_df['label'].values","083c6422":"Transform = transforms.Compose(\n    [transforms.ToTensor(),\n    transforms.Resize((IM_SIZE, IM_SIZE)),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])","e2c571a9":"class GetData(Dataset):\n    def __init__(self, Dir, FNames, Labels, Transform):\n        self.dir = Dir\n        self.fnames = FNames\n        self.transform = Transform\n        self.labels = Labels         \n        \n    def __len__(self):\n        return len(self.fnames)\n\n    def __getitem__(self, index):       \n        x = Image.open(os.path.join(self.dir, self.fnames[index]))\n    \n        if \"train\" in self.dir:             \n            return self.transform(x), self.labels[index]\n        elif \"test\" in self.dir:            \n            return self.transform(x), self.fnames[index]","221ea939":"trainset = GetData(TRAIN_DIR, X_Train, Y_Train, Transform)\ntrainloader = DataLoader(trainset, batch_size=BATCH, shuffle=True)","962bc923":"next(iter(trainloader))[0].shape","737b178f":"model = torchvision.models.resnet34()\nmodel.fc = nn.Linear(512, NUM_CL, bias=True)\nmodel = model.to(DEVICE)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)","395998be":"%%time\n\nfor epoch in range(EPOCHS):\n    tr_loss = 0.0\n\n    model = model.train()\n\n    for i, (images, labels) in enumerate(trainloader):        \n        images = images.to(DEVICE)\n        labels = labels.to(DEVICE)       \n        logits = model(images.float())       \n        loss = criterion(logits, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        tr_loss += loss.detach().item()\n    \n    model.eval()\n    print('Epoch: %d | Loss: %.4f'%(epoch, tr_loss \/ i))","064a4746":"X_Test = [name for name in (os.listdir(TEST_DIR))]\n# X_Test","43edd94b":"testset = GetData(TEST_DIR, X_Test, None, Transform)\ntestloader = DataLoader(testset, batch_size=1, shuffle=False)","d8d138bc":"%%time\n\ns_ls = []\n\nwith torch.no_grad():\n    model.eval()\n    for image, fname in testloader: \n        image = image.to(DEVICE)\n        \n        logits = model(image)        \n        ps = torch.exp(logits)        \n        _, top_class = ps.topk(1, dim=1)\n        \n        for pred in top_class:\n            s_ls.append([fname[0], pred.item()])","dba06092":"pred_df = pd.DataFrame.from_records(s_ls, columns=['image', 'label'])\npred_df","7a62eb12":"pred_df['hotel_id'] = pred_df['label'].map(class_map)\npred_df","5fca31f1":"sub = pred_df[['image', 'hotel_id']]\nsub.head()","a0bc42c4":"sub.to_csv(\"submission.csv\", index=False)","0ef33b0a":"## Inference"}}