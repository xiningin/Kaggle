{"cell_type":{"4897a748":"code","8670e4e0":"code","00f7ae98":"code","071eeff3":"code","90d86343":"code","bd854509":"code","3faa713b":"code","ed909c60":"code","6a63a2a4":"code","2865740d":"code","de7cabc6":"code","0fbd2e4f":"code","3e273ded":"code","b0afd8c1":"code","84de2dea":"code","898fba6f":"code","0994611c":"code","97dbcfa2":"code","51fba099":"code","fbf7776c":"code","3ca76c69":"markdown","34e6b493":"markdown"},"source":{"4897a748":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8670e4e0":"credits = pd.read_csv(\"\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_credits.csv\")\nmovies = pd.read_csv(\"\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_movies.csv\")\n\ncredits.head()","00f7ae98":"movies.head()","071eeff3":"print(credits.shape)\nprint(movies.shape)","90d86343":"credits = credits.rename(index=str, columns={\"movie_id\": \"id\"})\ncredits.head()","bd854509":"df_merge = movies.merge(credits, on=\"id\")\ndf_merge.head()","3faa713b":"df_cleaned = df_merge.drop(columns=[\"homepage\", \"title_x\", \"title_y\", \"status\", \"production_countries\"])\ndf_cleaned.head()","ed909c60":"df_cleaned.describe()","6a63a2a4":"df_cleaned.info()","2865740d":"df_cleaned['overview'].head()","de7cabc6":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfv = TfidfVectorizer(\n    min_df = 3,\n    max_features = None,\n    strip_accents = \"unicode\",\n    analyzer = \"word\",\n    token_pattern = r'\\w{1,}',\n    ngram_range = (1, 3),         # Taking combinations of 1-3 different kind of words\n    stop_words = \"english\"        # Remove the unnecessary stopword characters\n)\n\ndf_cleaned['overview'] = df_cleaned['overview'].fillna('')   # Removing NaN values\n\ntfv_matrix = tfv.fit_transform(df_cleaned['overview'])   # => Sparse Matrix(vectors) => most of the values in matrix = 0\ntfv_matrix","0fbd2e4f":"tfv_matrix.shape\n# 4803 records  and 10417 => features(based on the combinations of words(ngram=(1, 3)))","3e273ded":"from sklearn.metrics.pairwise import sigmoid_kernel\n# Sigmoid => Responsible for transforming input between 0 to 1\n# Passing the summary vectors in the sigmoid function => Will get values between 0 and 1\n\nsig = sigmoid_kernel(tfv_matrix, tfv_matrix)    # Combination of the same matrix\nsig[0]\n# Overview 1 related to overview 1, overview 1 related to overview 2, overview 1 related to overview 3, and so on","b0afd8c1":"# Mapping of Indices and Corresponding Movie Titles in the dataset\nindices = pd.Series(df_cleaned.index, index=df_cleaned['original_title']).drop_duplicates()\nindices","84de2dea":"# Movie Index for the movie \"Shanghai Calling\"\nprint(indices['Shanghai Calling'])\nprint(sig[4801])","898fba6f":"# Converting the range of the sigmoid values to a list along with respective indices using the enumerate function\n# [(Index, Score)]\nlist(enumerate(sig[indices['Shanghai Calling']]))","0994611c":"# Sorting according to the scores in the list\nsorted(list(enumerate(sig[indices['Shanghai Calling']])), key=lambda x: x[1], reverse=True)","97dbcfa2":"# Give movie title as input and based on the movie title we apply the object created in the sigmoid kernal\n# Doing the same thing as above but putting it in the fuction\ndef give_recommendation(title, sig=sig):\n    idx = indices[title]\n    sig_scores = list(enumerate(sig[idx]))\n    sig_scores = sorted(sig_scores, key=lambda x: x[1], reverse=True)\n    \n    # Getting Top 10 scores(index, scores)\n    sig_scores = sig_scores[1:11]\n    movie_indices = [i[0] for i in sig_scores]\n    return df_cleaned['original_title'].iloc[movie_indices]","51fba099":"give_recommendation('Shanghai Calling')","fbf7776c":"give_recommendation('Avatar')","3ca76c69":"## Creating Content Based Recommendations based on movie plot summary in \"overview\" column\n\n### Recommend movies that have similar plot summaries\n> For each and every movie - we create a vector of matrix<br>\n> Applying a recommendation system => Usually based on pair-wise similarity<br>\n> To find this similarity => we need to represent each and every movie summary as a vector<br>\n> We will used NLP Concept of TFidf Vectorizer which will help us creating a document matrix.<br>","34e6b493":"### Creating a Function to get recommendations for a movie based on the summaries\n> Step 1 - get corresponding index of the movie title<br>\n> Step 2 - get pairwise similarity scores<br>\n> Step 3 - Sort the movies<br>\n> Step 4 - Find the scores of 10 most similar movies<br>\n> Step 5 - get the movie indices of those top 10 movies<br>\n> Step 6 - Return the top 10 most similar movies<br>"}}