{"cell_type":{"abd96adc":"code","5773da8b":"code","b131ba33":"code","bd6f5302":"code","279ea758":"code","3812b62a":"code","b898cdd6":"code","f1b1baf6":"code","0687d076":"code","3f5ad980":"code","9e5a5239":"code","0986f673":"code","d3aeab78":"code","459f6970":"code","c8a5dcfb":"code","ecf4a0a3":"code","8a9a0b17":"code","75d0d48e":"code","76cf7c99":"code","bad6ffa8":"code","51d61f76":"code","7bfe8397":"code","b97f3068":"code","1b4a5383":"code","79cd1f6b":"code","515f873f":"code","ab34e370":"code","cb6294be":"code","9e22bf9a":"code","6c7c2f1e":"code","6601da3a":"code","95950a64":"code","83fd6b78":"code","4ca0d820":"code","346d1ba7":"code","523278dd":"code","e24b868e":"code","c776400e":"code","316dc6f6":"code","d7fb2b34":"code","b09ce1ed":"code","242887b4":"code","96c03a75":"markdown","4193f1d3":"markdown","a9b5454f":"markdown","b62e7d2a":"markdown","c4ed257b":"markdown","5dbcd1f9":"markdown","bd262ecd":"markdown","27d197b1":"markdown","1015ff2f":"markdown"},"source":{"abd96adc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom xgboost import plot_importance\nfrom matplotlib import pyplot\nimport shap\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nfrom time import time\nfrom tqdm import tqdm_notebook as tqdm\nfrom collections import Counter\nfrom scipy import stats\nimport lightgbm as lgb\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\nimport gc\nimport json\npd.set_option('display.max_columns', 1000)","5773da8b":"def eval_qwk_lgb_regr(y_true, y_pred):\n    \"\"\"\n    Fast cappa eval function for lgb.\n    \"\"\"\n    dist = Counter(reduce_train['accuracy_group'])\n    for k in dist:\n        dist[k] \/= len(reduce_train)\n    reduce_train['accuracy_group'].hist()\n    \n    acum = 0\n    bound = {}\n    for i in range(3):\n        acum += dist[i]\n        bound[i] = np.percentile(y_pred, acum * 100)\n\n    def classify(x):\n        if x <= bound[0]:\n            return 0\n        elif x <= bound[1]:\n            return 1\n        elif x <= bound[2]:\n            return 2\n        else:\n            return 3\n\n    y_pred = np.array(list(map(classify, y_pred))).reshape(y_true.shape)\n\n    return 'cappa', cohen_kappa_score(y_true, y_pred, weights='quadratic'), True","b131ba33":"def cohenkappa(ypred, y):\n    y = y.get_label().astype(\"int\")\n    ypred = ypred.reshape((4, -1)).argmax(axis = 0)\n    loss = cohenkappascore(y, y_pred, weights = 'quadratic')\n    return \"cappa\", loss, True","bd6f5302":"def read_data():\n    print('Reading train.csv file....')\n    train = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/train.csv')\n    print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n\n    print('Reading test.csv file....')\n    test = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/test.csv')\n    print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n\n    print('Reading train_labels.csv file....')\n    train_labels = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/train_labels.csv')\n    print('Train_labels.csv file have {} rows and {} columns'.format(train_labels.shape[0], train_labels.shape[1]))\n\n    print('Reading specs.csv file....')\n    specs = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/specs.csv')\n    print('Specs.csv file have {} rows and {} columns'.format(specs.shape[0], specs.shape[1]))\n\n    print('Reading sample_submission.csv file....')\n    sample_submission = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/sample_submission.csv')\n    print('Sample_submission.csv file have {} rows and {} columns'.format(sample_submission.shape[0], sample_submission.shape[1]))\n    return train, test, train_labels, specs, sample_submission","279ea758":"def encode_title(train, test, train_labels):\n    # encode title\n    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n    all_title_event_code = sorted(list(set(train[\"title_event_code\"].unique()).union(test[\"title_event_code\"].unique())))\n    # make a list with all the unique 'titles' from the train and test set\n    list_of_user_activities = sorted(list(set(train['title'].unique()).union(set(test['title'].unique()))))\n    # make a list with all the unique 'event_code' from the train and test set\n    list_of_event_code = sorted(list(set(train['event_code'].unique()).union(set(test['event_code'].unique()))))\n    list_of_event_id = sorted(list(set(train['event_id'].unique()).union(set(test['event_id'].unique()))))\n    # make a list with all the unique worlds from the train and test set\n    list_of_worlds = sorted(list(set(train['world'].unique()).union(set(test['world'].unique()))))\n    # create a dictionary numerating the titles\n    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n    assess_titles = sorted(list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(\n        set(test[test['type'] == 'Assessment']['title'].value_counts().index))))\n    # replace the text titles with the number titles from the dict\n    train['title'] = train['title'].map(activities_map)\n    test['title'] = test['title'].map(activities_map)\n    train['world'] = train['world'].map(activities_world)\n    test['world'] = test['world'].map(activities_world)\n    train_labels['title'] = train_labels['title'].map(activities_map)\n    win_code = dict(zip(activities_map.values(), (4100 * np.ones(len(activities_map))).astype('int')))\n    # then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\n    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n    # convert text into datetime\n    train['timestamp'] = pd.to_datetime(train['timestamp'])\n    test['timestamp'] = pd.to_datetime(test['timestamp'])\n\n    return train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code","3812b62a":"# this is the function that convert the raw data into processed features\ndef get_data(user_sample, test_set=False):\n    '''\n    The user_sample is a DataFrame from train or test where the only one \n    installation_id is filtered\n    And the test_set parameter is related with the labels processing, that is only requered\n    if test_set=False\n    '''\n    # Constants and parameters declaration\n    last_activity = 0\n    \n    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n    \n    # new features: time spent in each activity\n    last_session_time_sec = 0\n    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n    all_assessments = []\n    accumulated_accuracy_group = 0\n    accumulated_accuracy = 0\n    accumulated_correct_attempts = 0 \n    accumulated_uncorrect_attempts = 0\n    accumulated_actions = 0\n    counter = 0\n    time_first_activity = float(user_sample['timestamp'].values[0])\n    durations = []\n    last_accuracy_title = {'acc_' + title: -1 for title in assess_titles}\n    event_code_count: Dict[str, int] = {ev: 0 for ev in list_of_event_code}\n    event_id_count: Dict[str, int] = {eve: 0 for eve in list_of_event_id}\n    title_count: Dict[str, int] = {eve: 0 for eve in activities_labels.values()} \n    title_event_code_count: Dict[str, int] = {t_eve: 0 for t_eve in all_title_event_code}\n        \n    # last features\n    sessions_count = 0\n    \n    # itarates through each session of one instalation_id\n    for i, session in user_sample.groupby('game_session', sort=False):\n        # i = game_session_id\n        # session is a DataFrame that contain only one game_session\n        \n        # get some sessions information\n        session_type = session['type'].iloc[0]\n        session_title = session['title'].iloc[0]\n        session_title_text = activities_labels[session_title]\n                    \n            \n        # for each assessment, and only this kind off session, the features below are processed\n        # and a register are generated\n        if (session_type == 'Assessment') & (test_set or len(session)>1):\n            # search for event_code 4100, that represents the assessments trial\n            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n            # then, check the numbers of wins and the number of losses\n            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n            # copy a dict to use as feature template, it's initialized with some itens: \n            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n            features = user_activities_count.copy()\n            features.update(last_accuracy_title.copy())\n            features.update(event_code_count.copy())\n            features.update(event_id_count.copy())\n            features.update(title_count.copy())\n            features.update(title_event_code_count.copy())\n            features.update(last_accuracy_title.copy())\n            features['installation_session_count'] = sessions_count\n            \n            # get installation_id for aggregated features\n            features['installation_id'] = session['installation_id'].iloc[-1]\n            # add title as feature, remembering that title represents the name of the game\n            features['session_title'] = session['title'].iloc[0]\n            # the 4 lines below add the feature of the history of the trials of this player\n            # this is based on the all time attempts so far, at the moment of this assessment\n            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n            accumulated_correct_attempts += true_attempts \n            accumulated_uncorrect_attempts += false_attempts\n            # the time spent in the app so far\n            if durations == []:\n                features['duration_mean'] = 0\n                features['duration_std'] = 0\n            else:\n                features['duration_mean'] = np.mean(durations)\n                features['duration_std'] = np.std(durations)\n            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n            # the accurace is the all time wins divided by the all time attempts\n            features['accumulated_accuracy'] = accumulated_accuracy\/counter if counter > 0 else 0\n            accuracy = true_attempts\/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n            accumulated_accuracy += accuracy\n            last_accuracy_title['acc_' + session_title_text] = accuracy\n            # a feature of the current accuracy categorized\n            # it is a counter of how many times this player was in each accuracy group\n            if accuracy == 0:\n                features['accuracy_group'] = 0\n            elif accuracy == 1:\n                features['accuracy_group'] = 3\n            elif accuracy == 0.5:\n                features['accuracy_group'] = 2\n            else:\n                features['accuracy_group'] = 1\n            features.update(accuracy_groups)\n            accuracy_groups[features['accuracy_group']] += 1\n            # mean of the all accuracy groups of this player\n            features['accumulated_accuracy_group'] = accumulated_accuracy_group\/counter if counter > 0 else 0\n            accumulated_accuracy_group += features['accuracy_group']\n            # how many actions the player has done so far, it is initialized as 0 and updated some lines below\n            features['accumulated_actions'] = accumulated_actions\n            \n            # there are some conditions to allow this features to be inserted in the datasets\n            # if it's a test set, all sessions belong to the final dataset\n            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n            # that means, must exist an event_code 4100 or 4110\n            if test_set:\n                all_assessments.append(features)\n            elif true_attempts+false_attempts > 0:\n                all_assessments.append(features)\n                \n            counter += 1\n        \n        sessions_count += 1\n        # this piece counts how many actions was made in each event_code so far\n        def update_counters(counter: dict, col: str):\n                num_of_session_count = Counter(session[col])\n                for k in num_of_session_count.keys():\n                    x = k\n                    if col == 'title':\n                        x = activities_labels[k]\n                    counter[x] += num_of_session_count[k]\n                return counter\n            \n        event_code_count = update_counters(event_code_count, \"event_code\")\n        event_id_count = update_counters(event_id_count, \"event_id\")\n        title_count = update_counters(title_count, 'title')\n        title_event_code_count = update_counters(title_event_code_count, 'title_event_code')\n\n        # counts how many actions the player has done so far, used in the feature of the same name\n        accumulated_actions += len(session)\n        if last_activity != session_type:\n            user_activities_count[session_type] += 1\n            last_activitiy = session_type \n                        \n    # if it't the test_set, only the last assessment must be predicted, the previous are scraped\n    if test_set:\n        return all_assessments[-1]\n    # in the train_set, all assessments goes to the dataset\n    return all_assessments","b898cdd6":"def seed_everything(seed=0):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)","f1b1baf6":"def get_train_and_test(train, test):\n    compiled_train = []\n    compiled_test = []\n    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort = False)), total = 17000):\n        compiled_train += get_data(user_sample)\n    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort = False), total = 1000):\n        test_data = get_data(user_sample, test_set = True)\n        compiled_test.append(test_data)\n    reduce_train = pd.DataFrame(compiled_train)\n    reduce_test = pd.DataFrame(compiled_test)\n    categoricals = ['session_title']\n    return reduce_train, reduce_test, categoricals","0687d076":"def preprocess(reduce_train, reduce_test):\n    for df in [reduce_train, reduce_test]:\n        df['installation_session_count'] = df.groupby(['installation_id'])['Clip'].transform('count')\n        df['installation_duration_mean'] = df.groupby(['installation_id'])['duration_mean'].transform('mean')\n        df['installation_title_nunique'] = df.groupby(['installation_id'])['session_title'].transform('nunique')\n        \n        df['sum_event_code_count'] = df[[2050, 4100, 4230, 5000, 4235, 2060, 4110, 5010, 2070, 2075, 2080, 2081, 2083, 3110, 4010, 3120, 3121, 4020, 4021, \n                                        4022, 4025, 4030, 4031, 3010, 4035, 4040, 3020, 3021, 4045, 2000, 4050, 2010, 2020, 4070, 2025, 2030, 4080, 2035, \n                                        2040, 4090, 4220, 4095]].sum(axis = 1)\n        \n        df['installation_event_code_count_mean'] = df.groupby(['installation_id'])['sum_event_code_count'].transform('mean')\n        \n    return reduce_train, reduce_test","3f5ad980":"def Model1_LgbStratified(reduce_train, reduce_test, usefull_features, n_splits, bags=1):\n    for seed in range(bags):\n        kf = StratifiedKFold(n_splits=n_splits, shuffle = True, random_state = seed)\n        target = 'accuracy_group'\n        oof_pred = np.zeros((len(reduce_train), ))\n        y_pred = np.zeros((len(reduce_test), ))\n        oof_pred_val= np.zeros((len(reduce_train), ))\n        feature_importance_df_1 = pd.DataFrame()\n        for fold, (tr_ind, val_ind) in enumerate(kf.split(reduce_train, reduce_train[target])):\n            print('Fold {}'.format(fold + 1))\n            x_train, x_val = reduce_train[usefull_features].iloc[tr_ind], reduce_train[usefull_features].iloc[val_ind]\n            y_train, y_val = reduce_train[target][tr_ind], reduce_train[target][val_ind]\n            train_set = lgb.Dataset(x_train, y_train, categorical_feature=categoricals)\n            val_set = lgb.Dataset(x_val, y_val, categorical_feature=categoricals)\n\n            params = {'n_estimators':5000,\n                      'boosting_type': 'gbdt',\n                      'objective': 'regression',\n                      'metric': 'rmse',\n                      'subsample': 0.75,\n                      'subsample_freq': 1,\n                      'learning_rate': 0.01,\n                      'feature_fraction': 0.9,\n                      'max_depth': 15,\n                      'lambda_l1': 1,  \n                      'lambda_l2': 1,\n                      'verbose': 100,\n                      'early_stopping_rounds': 100,\n                      'seed': seed\n                        }\n\n            model = lgb.train(params, train_set, num_boost_round = 1000000, early_stopping_rounds = 300, \n                              valid_sets=[train_set, val_set], verbose_eval = 100)\n            oof_pred[val_ind] = model.predict(x_val)\n            fold_importance_df = pd.DataFrame()\n            fold_importance_df[\"feature\"] = features\n            fold_importance_df[\"importance\"] = model.feature_importance()\n            fold_importance_df[\"fold\"] = fold + 1\n            feature_importance_df_1 = pd.concat([feature_importance_df_1, fold_importance_df], axis=0)\n            oof_pred_val[val_ind]+= model.predict(x_val)\/ n_splits \/ bags\n            y_pred += model.predict(reduce_test[usefull_features]) \/ n_splits \/ bags\n        _, loss_score, _ = eval_qwk_lgb_regr(reduce_train[target], oof_pred)\n    print('Our oof cohen kappa score is: ', loss_score)\n\n    return y_pred,oof_pred_val, feature_importance_df_1","9e5a5239":"def Model2_GroupKFold(reduce_train, reduce_test, usefull_features, n_splits, bags=1):\n    for seed in range(bags):\n        kf = GroupKFold(n_splits=n_splits)\n        target = 'accuracy_group'\n        oof_pred = np.zeros((len(reduce_train), ))\n        y_pred = np.zeros((len(reduce_test), ))\n        oof_pred_val= np.zeros((len(reduce_train), ))\n        feature_importance_df_1 = pd.DataFrame()\n        for fold, (tr_ind, val_ind) in enumerate(kf.split(reduce_train, groups = reduce_train['installation_id'])):\n            print('Fold {}'.format(fold + 1))\n            x_train, x_val = reduce_train[usefull_features].iloc[tr_ind], reduce_train[usefull_features].iloc[val_ind]\n            y_train, y_val = reduce_train[target][tr_ind], reduce_train[target][val_ind]\n            train_set = lgb.Dataset(x_train, y_train, categorical_feature=categoricals)\n            val_set = lgb.Dataset(x_val, y_val, categorical_feature=categoricals)\n\n            params = {'n_estimators':5000,\n                      'boosting_type': 'gbdt',\n                      'objective': 'regression',\n                      'metric': 'rmse',\n                      'subsample': 0.75,\n                      'subsample_freq': 1,\n                      'learning_rate': 0.01,\n                      'feature_fraction': 0.9,\n                      'max_depth': 15,\n                      'lambda_l1': 1,  \n                      'lambda_l2': 1,\n                      'verbose': 100,\n                      'early_stopping_rounds': 100,\n                      'seed': seed\n                        }\n\n            model = lgb.train(params, train_set, num_boost_round = 1000000, early_stopping_rounds = 300, \n                              valid_sets=[train_set, val_set], verbose_eval = 100)\n            oof_pred[val_ind] = model.predict(x_val)\n            fold_importance_df = pd.DataFrame()\n            fold_importance_df[\"feature\"] = features\n            fold_importance_df[\"importance\"] = model.feature_importance()\n            fold_importance_df[\"fold\"] = fold + 1\n            feature_importance_df_1 = pd.concat([feature_importance_df_1, fold_importance_df], axis=0)\n            oof_pred_val[val_ind]+= model.predict(x_val)\/ n_splits \/ bags\n            y_pred += model.predict(reduce_test[usefull_features]) \/ n_splits \/ bags\n        _, loss_score, _ = eval_qwk_lgb_regr(reduce_train[target], oof_pred)\n    print('Our oof cohen kappa score is: ', loss_score)\n\n    return y_pred,oof_pred_val, feature_importance_df_1","0986f673":"# read data\ntrain, test, train_labels, specs, sample_submission = read_data()\n# get usefull dict with maping encode\ntrain, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code = encode_title(train, test, train_labels)\n# tranform function to get the train and test set\nreduce_train, reduce_test, categoricals = get_train_and_test(train, test)","d3aeab78":"#Preprocess the reduced train and test\nreduce_train, reduce_test = preprocess(reduce_train, reduce_test)","459f6970":"def plot_train_test_comp(feature):\n    BINS = 50\n    #data = reduce_train[reduce_train['accuracy_group'] == 3][feature]\n    data = reduce_train[feature]\n    train_mean = data.mean()\n    perc_90 = np.percentile(data, 95)\n    plt.hist(np.clip(data, 0, perc_90), bins=BINS, color='blue', alpha=0.5, weights=np.ones(len(data)) \/ len(data))\n    data = reduce_test[feature] \n    test_mean = data.mean()\n    ajust_factor = train_mean \/ test_mean\n    plt.hist(np.clip(data * ajust_factor, 0, perc_90), bins=BINS, color='red', alpha=0.5, weights=np.ones(len(data)) \/ len(data))\n    plt.show()\n\nplot_train_test_comp('Clip')","c8a5dcfb":"total_features = reduce_train.loc[(reduce_train.sum(axis=1) != 0), (reduce_train.sum(axis=0) != 0)].columns # delete useless columns\nfeatures = [x for x in total_features if x not in ['accuracy_group', 'installation_id']]","ecf4a0a3":"added_features = [col for col in total_features if col in ['accuracy_group', 'installation_id','installation_session_count', \n                                                  'installation_duration_mean', 'installation_title_nunique', \n                                                  'installation_event_code_count_mean','session_title']]\nadd_train = reduce_train[added_features]\nadd_test = reduce_test[added_features]","8a9a0b17":"to_exclude = []\najusted_test = reduce_test.copy()\nfor feature in ajusted_test.columns:\n    if feature not in ['accuracy_group', 'installation_id', 'accuracy_group', 'session_title']:\n        data = reduce_train[feature]\n        train_mean = data.mean()\n        data = ajusted_test[feature] \n        test_mean = data.mean()\n        try:\n            ajust_factor = train_mean \/ test_mean\n            if ajust_factor > 10 or ajust_factor < 0.1:\n                to_exclude.append(feature)\n                print(feature, train_mean, test_mean)\n            else:\n                ajusted_test[feature] *= ajust_factor\n        except:\n            to_exclude.append(feature)\n            print(feature, train_mean, test_mean)","75d0d48e":"features = [x for x in features if x not in to_exclude]\nreduce_train[features].shape","76cf7c99":"import warnings\nwarnings.filterwarnings(\"ignore\")\ny_lgb_pred_1,val_lgb_pred_1,feature_importance_1 =  Model1_LgbStratified(reduce_train, ajusted_test, features, 5)","bad6ffa8":"import seaborn as sns\ncols = (feature_importance_1[[\"feature\", \"importance\"]]\n        .groupby(\"feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:300].index)\nbest_features_stratified = feature_importance_1.loc[feature_importance_1.feature.isin(cols)]\n\nplt.figure(figsize=(14,10))\nsns.barplot(x=\"importance\", y=\"feature\", data=best_features_stratified[-50:].sort_values(by=\"importance\",ascending=False))\nplt.title('LightGBM Features (averaged over Stratified folds)')\nplt.tight_layout()","51d61f76":"warnings.filterwarnings(\"ignore\")\ny_lgb_pred_2,val_lgb_pred_2,feature_importance_2 =  Model2_GroupKFold(reduce_train, ajusted_test, features, 5)","7bfe8397":"import seaborn as sns\ncols = (feature_importance_2[[\"feature\", \"importance\"]]\n        .groupby(\"feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:300].index)\nbest_features_groupkfold = feature_importance_2.loc[feature_importance_2.feature.isin(cols)]\n\nplt.figure(figsize=(14,10))\nsns.barplot(x=\"importance\", y=\"feature\", data=best_features_groupkfold[-50:].sort_values(by=\"importance\",ascending=False))\nplt.title('LightGBM Features (averaged over GroupK folds)')\nplt.tight_layout()","b97f3068":"useful_features_group_K = best_features_groupkfold['feature'].tolist()\nfrom sklearn import metrics","1b4a5383":"av_features = [col for col in useful_features_group_K if col not in ['installation_session_count', \n                                                  'installation_duration_mean', 'installation_title_nunique', \n                                                  'installation_event_code_count_mean','session_title']]","79cd1f6b":"def run_av_groupk(reduce_train, reduce_test, usefull_features):\n    \n    tr_data = reduce_train.copy()\n    tst_data = reduce_test.copy()\n    tr_data['target'] = 0 \n    tst_data['target'] = 1\n    av_data = pd.concat([tr_data[[col for col in tr_data.columns if col not in ['accuracy_group']]], tst_data[[col for col in tst_data.columns if col not in ['accuracy_group']]]], axis = 0)\n    \n    # undersample majority class\n    positive = av_data[av_data['target']==1]\n    negative = av_data[av_data['target']==0]\n    negative = negative.sample(int(negative.shape[0] * 0.5), random_state = 42)\n    av_data = pd.concat([negative, positive], axis = 0)\n    \n    # reset index and shuffle\n    av_data.reset_index(drop = True)\n    from sklearn.utils import shuffle\n    av_data = shuffle(av_data)\n        \n    params = {\n            'learning_rate': 0.01, \n            'n_jobs': -1,\n            'seed': 42,\n            'objective':'binary',\n            'boosting_type':'gbdt',\n            'is_unbalance': True,\n            'metric': 'auc',\n        }\n    \n    # define a KFold strategy\n    kf = GroupKFold(n_splits = 5)\n    target = 'target'\n    oof_pred = np.zeros(len(av_data))\n    important_features = pd.DataFrame()\n    fold_auc = []\n    \n    \n    for fold, (tr_ind, val_ind) in enumerate(kf.split(av_data, groups = av_data['installation_id'])):\n        print('Fold {}'.format(fold + 1))\n        x_train, x_val = av_data[usefull_features].iloc[tr_ind], av_data[usefull_features].iloc[val_ind]\n        y_train, y_val = av_data[target].iloc[tr_ind], av_data[target].iloc[val_ind]\n        train_set = lgb.Dataset(x_train, y_train)\n        val_set = lgb.Dataset(x_val, y_val)\n        \n        model = lgb.train(params, train_set, num_boost_round = 100000, early_stopping_rounds = 20, \n                         valid_sets = [train_set, val_set], verbose_eval = 100)\n        \n        fold_importance = pd.DataFrame()\n        fold_importance['features'] = usefull_features\n        fold_importance['importance'] = model.feature_importance()\n        important_features = pd.concat([important_features, fold_importance], axis = 0)\n        \n        oof_pred[val_ind] = model.predict(x_val)\n        fold_auc.append(metrics.roc_auc_score(y_train, model.predict(x_train)))\n        \n    print('Our mean train roc auc score is :', np.mean(fold_auc))\n    print('Our oof roc auc score is :', metrics.roc_auc_score(av_data[target], oof_pred))\n    return important_features\n\nimportant_features = run_av_groupk(reduce_train, reduce_test, av_features)","515f873f":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize = (12,15))\nimportant_features = important_features.groupby('features')['importance'].mean().reset_index().sort_values('importance')\nsns.barplot(important_features['importance'][-80:], important_features['features'][-80:])","ab34e370":"def run_av_groupk_stage_2(reduce_train, reduce_test, usefull_features):\n    \n    tr_data = reduce_train.copy()\n    tst_data = reduce_test.copy()\n    tr_data['target'] = 0 \n    tst_data['target'] = 1\n    av_data = pd.concat([tr_data[[col for col in tr_data.columns if col not in ['accuracy_group']]], tst_data[[col for col in tst_data.columns if col not in ['accuracy_group']]]], axis = 0)\n    \n     # undersample majority class\n    positive = av_data[av_data['target']==1]\n    negative = av_data[av_data['target']==0]\n    negative = negative.sample(int(negative.shape[0] * 0.5), random_state = 42)\n    av_data = pd.concat([negative, positive], axis = 0)\n    \n    # reset index and shuffle\n    av_data.reset_index(drop = True)\n    from sklearn.utils import shuffle\n    av_data = shuffle(av_data)\n        \n        \n    params = {\n            'learning_rate': 0.01, \n            'n_jobs': -1,\n            'seed': 42,\n            'objective':'binary',\n            'boosting_type':'gbdt',\n            'is_unbalance': True,\n            'metric': 'auc'\n        }\n    \n    # define a KFold strategy\n    kf = GroupKFold(n_splits = 5)\n    target = 'target'\n    \n    oof_pred = np.zeros(len(av_data))\n    for fold, (tr_ind, val_ind) in enumerate(kf.split(av_data, groups = av_data['installation_id'])):\n        print('Fold {}'.format(fold + 1))\n        x_train, x_val = av_data[usefull_features].iloc[tr_ind], av_data[usefull_features].iloc[val_ind]\n        y_train, y_val = av_data[target].iloc[tr_ind], av_data[target].iloc[val_ind]\n        train_set = lgb.Dataset(x_train, y_train)\n        val_set = lgb.Dataset(x_val, y_val)\n        \n        model = lgb.train(params, train_set, num_boost_round = 100000, early_stopping_rounds = 20, \n                         valid_sets = [train_set, val_set], verbose_eval = 100)\n    \n        \n        oof_pred[val_ind] = model.predict(x_val)\n    \n    score = metrics.roc_auc_score(av_data[target], oof_pred)\n    \n    iter_features = usefull_features[::-1].copy()\n    drop_features = []\n    for i in iter_features:\n        oof_pred = np.zeros(len(av_data))\n        check_features = [col for col in iter_features if col not in drop_features + [i]]\n        print('Checking feature:', i)\n        for fold, (tr_ind, val_ind) in enumerate(kf.split(av_data, groups = av_data['installation_id'])):\n            x_train, x_val = av_data[check_features].iloc[tr_ind], av_data[check_features].iloc[val_ind]\n            y_train, y_val = av_data[target].iloc[tr_ind], av_data[target].iloc[val_ind]\n            train_set = lgb.Dataset(x_train, y_train)\n            val_set = lgb.Dataset(x_val, y_val)\n\n            model = lgb.train(params, train_set, num_boost_round = 100000, early_stopping_rounds = 20, \n                             valid_sets = [train_set, val_set], verbose_eval = False)\n\n\n            oof_pred[val_ind] = model.predict(x_val)\n            \n        rauc = metrics.roc_auc_score(av_data[target], oof_pred)\n            \n        if rauc < score:\n            print('Dropping feature: ', i)\n            score = rauc\n            drop_features.append(i)\n        else:\n            print('Feature {} is usefull'.format(i))\n            \n        print('Out best roc auc score is :', score)\n            \n        print('-'*50)\n        print('_'*50)\n            \n    usefull_features = [col for col in usefull_features if col not in drop_features]\n    return usefull_features\n\nusefull_features_groupk = run_av_groupk_stage_2(reduce_train, reduce_test, list(important_features['features']))","cb6294be":"reduce_train[usefull_features_groupk].shape","9e22bf9a":"reduce_test[usefull_features_groupk].shape","6c7c2f1e":"useful_features_Stratified = best_features_stratified['feature'].tolist()\nfrom sklearn import metrics","6601da3a":"av_features = [col for col in useful_features_Stratified if col not in ['installation_session_count', \n                                                  'installation_duration_mean', 'installation_title_nunique', \n                                                  'installation_event_code_count_mean','session_title']]","95950a64":"def run_av_Stratified(reduce_train, reduce_test, usefull_features):\n    \n    tr_data = reduce_train.copy()\n    tst_data = reduce_test.copy()\n    tr_data['target'] = 0 \n    tst_data['target'] = 1\n    av_data = pd.concat([tr_data[[col for col in tr_data.columns if col not in ['accuracy_group']]], tst_data[[col for col in tst_data.columns if col not in ['accuracy_group']]]], axis = 0)\n    \n    # undersample majority class\n    positive = av_data[av_data['target']==1]\n    negative = av_data[av_data['target']==0]\n    negative = negative.sample(int(negative.shape[0] * 0.5), random_state = 42)\n    av_data = pd.concat([negative, positive], axis = 0)\n    \n    # reset index and shuffle\n    av_data.reset_index(drop = True)\n    from sklearn.utils import shuffle\n    av_data = shuffle(av_data)\n        \n    params = {\n            'learning_rate': 0.01, \n            'n_jobs': -1,\n            'seed': 42,\n            'objective':'binary',\n            'boosting_type':'gbdt',\n            'is_unbalance': True,\n            'metric': 'auc',\n        }\n    \n    # define a KFold strategy\n    kf = StratifiedKFold(n_splits = 5)\n    target = 'target'\n    oof_pred = np.zeros(len(av_data))\n    important_features = pd.DataFrame()\n    fold_auc = []\n    \n    \n    for fold, (tr_ind, val_ind) in enumerate(kf.split(av_data,av_data[target])):\n        print('Fold {}'.format(fold + 1))\n        x_train, x_val = av_data[usefull_features].iloc[tr_ind], av_data[usefull_features].iloc[val_ind]\n        y_train, y_val = av_data[target].iloc[tr_ind], av_data[target].iloc[val_ind]\n        train_set = lgb.Dataset(x_train, y_train)\n        val_set = lgb.Dataset(x_val, y_val)\n        \n        model = lgb.train(params, train_set, num_boost_round = 100000, early_stopping_rounds = 20, \n                         valid_sets = [train_set, val_set], verbose_eval = 100)\n        \n        fold_importance = pd.DataFrame()\n        fold_importance['features'] = usefull_features\n        fold_importance['importance'] = model.feature_importance()\n        important_features = pd.concat([important_features, fold_importance], axis = 0)\n        \n        oof_pred[val_ind] = model.predict(x_val)\n        fold_auc.append(metrics.roc_auc_score(y_train, model.predict(x_train)))\n        \n    print('Our mean train roc auc score is :', np.mean(fold_auc))\n    print('Our oof roc auc score is :', metrics.roc_auc_score(av_data[target], oof_pred))\n    return important_features\n\nimportant_features_2 = run_av_Stratified(reduce_train, reduce_test, av_features)","83fd6b78":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize = (12,15))\nimportant_features_2 = important_features_2.groupby('features')['importance'].mean().reset_index().sort_values('importance')\nsns.barplot(important_features_2['importance'][-80:], important_features_2['features'][-80:])","4ca0d820":"def run_av_stratify_stage_2(reduce_train, reduce_test, usefull_features):\n    \n    tr_data = reduce_train.copy()\n    tst_data = reduce_test.copy()\n    tr_data['target'] = 0 \n    tst_data['target'] = 1\n    av_data = pd.concat([tr_data[[col for col in tr_data.columns if col not in ['accuracy_group']]], tst_data[[col for col in tst_data.columns if col not in ['accuracy_group']]]], axis = 0)\n    \n     # undersample majority class\n    positive = av_data[av_data['target']==1]\n    negative = av_data[av_data['target']==0]\n    negative = negative.sample(int(negative.shape[0] * 0.5), random_state = 42)\n    av_data = pd.concat([negative, positive], axis = 0)\n    \n    # reset index and shuffle\n    av_data.reset_index(drop = True)\n    from sklearn.utils import shuffle\n    av_data = shuffle(av_data)\n        \n        \n    params = {\n            'learning_rate': 0.01, \n            'n_jobs': -1,\n            'seed': 42,\n            'objective':'binary',\n            'boosting_type':'gbdt',\n            'is_unbalance': True,\n            'metric': 'auc'\n        }\n    \n    # define a KFold strategy\n    kf = StratifiedKFold(n_splits = 5)\n    target = 'target'\n    \n    oof_pred = np.zeros(len(av_data))\n    for fold, (tr_ind, val_ind) in enumerate(kf.split(av_data,av_data['target'])):\n        print('Fold {}'.format(fold + 1))\n        x_train, x_val = av_data[usefull_features].iloc[tr_ind], av_data[usefull_features].iloc[val_ind]\n        y_train, y_val = av_data[target].iloc[tr_ind], av_data[target].iloc[val_ind]\n        train_set = lgb.Dataset(x_train, y_train)\n        val_set = lgb.Dataset(x_val, y_val)\n        \n        model = lgb.train(params, train_set, num_boost_round = 100000, early_stopping_rounds = 20, \n                         valid_sets = [train_set, val_set], verbose_eval = 100)\n    \n        \n        oof_pred[val_ind] = model.predict(x_val)\n    \n    score = metrics.roc_auc_score(av_data[target], oof_pred)\n    \n    iter_features = usefull_features[::-1].copy()\n    drop_features = []\n    for i in iter_features:\n        oof_pred = np.zeros(len(av_data))\n        check_features = [col for col in iter_features if col not in drop_features + [i]]\n        print('Checking feature:', i)\n        for fold, (tr_ind, val_ind) in enumerate(kf.split(av_data,av_data['target'])):\n            x_train, x_val = av_data[check_features].iloc[tr_ind], av_data[check_features].iloc[val_ind]\n            y_train, y_val = av_data[target].iloc[tr_ind], av_data[target].iloc[val_ind]\n            train_set = lgb.Dataset(x_train, y_train)\n            val_set = lgb.Dataset(x_val, y_val)\n\n            model = lgb.train(params, train_set, num_boost_round = 100000, early_stopping_rounds = 20, \n                             valid_sets = [train_set, val_set], verbose_eval = False)\n\n\n            oof_pred[val_ind] = model.predict(x_val)\n            \n        rauc = metrics.roc_auc_score(av_data[target], oof_pred)\n            \n        if rauc < score:\n            print('Dropping feature: ', i)\n            score = rauc\n            drop_features.append(i)\n        else:\n            print('Feature {} is usefull'.format(i))\n            \n        print('Out best roc auc score is :', score)\n            \n        print('-'*50)\n        print('_'*50)\n            \n    usefull_features = [col for col in usefull_features if col not in drop_features]\n    return usefull_features\n\nusefull_features_stratify = run_av_stratify_stage_2(reduce_train, reduce_test, list(important_features_2['features']))","346d1ba7":"reduce_train[usefull_features_stratify].shape","523278dd":"reduce_test[usefull_features_stratify].shape","e24b868e":"Strat_train_X = pd.concat([reduce_train[usefull_features_stratify],add_train],axis=1)\nStrat_test_X = pd.concat([reduce_test[usefull_features_stratify],add_test], axis=1)\nGroupk_train_X = pd.concat([reduce_train[usefull_features_groupk],add_train], axis=1)\nGroupk_test_X = pd.concat([reduce_test[usefull_features_groupk],add_test], axis=1)","c776400e":"Strat_train_X.to_csv('Strat_train_X.csv', index=False)\nStrat_test_X.to_csv('Strat_test_X.csv', index=False)\nGroupk_train_X.to_csv('Groupk_train_X.csv', index=False)\nGroupk_test_X.to_csv('Groupk_test_X.csv', index=False)\n\nprint (\"The Data is Exported Successfully\")","316dc6f6":"Strat_train_X.shape","d7fb2b34":"Groupk_train_X.shape","b09ce1ed":"Strat_test_X.shape","242887b4":"Groupk_test_X.shape","96c03a75":"Concatenate the Features","4193f1d3":"Run Adverserial Validation on Group kfold","a9b5454f":"Much better, our model can still detect train and test. Nevertheless want to try and check the results.\n\nLet's build a function that drop one feature and check if the oof validation falls, if it falls we drop it.","b62e7d2a":"Run Adverserial Validation on Stratified kfold","c4ed257b":"Inspired by Ragnar's Kernel, https:\/\/www.kaggle.com\/ragnar123\/adversarial-validation-and-model <br\/>\nLets Minify the DSB data for building ML Models using Adversarial Feature Selection Technique","5dbcd1f9":"![](https:\/\/datasciencebowl.com\/wp-content\/uploads\/2019\/03\/dsb-logo-400.png)\n\nData Science Bowl is the world\u2019s largest data science competition focused on social good. Each year, this competition gives Kagglers a chance to use their passion to change the world. Over the last four years, more than 50,000+ Kagglers have submitted over 114,000+ submissions, to improve everything from lung cancer and heart disease detection to ocean health.","bd262ecd":"Let's make another filter and use adversarial validation to eliminate features. The main idea of adversarial validations is to train a ml model and check if the model can figure out if the data is from the train or test set.\n\nIf it can, this means that the data comes from another distribution and that's not a good thing.","27d197b1":"Since We already know the good features, lets filter them out before applying Adversarial technique","1015ff2f":"Export to CSV"}}