{"cell_type":{"490ce200":"code","14b74b8f":"code","fb8fbca7":"code","693fb413":"code","a767c491":"code","344e4cea":"code","501fe36c":"code","90f50284":"code","22703ad2":"code","cc7c5367":"code","c4379496":"code","a078b800":"code","4b556d1f":"code","2d2d6105":"code","14b5ddff":"code","159b1df4":"code","aefd5de3":"code","48612f64":"code","3d8941e1":"code","a6c94171":"code","01fddcfd":"code","0f0d7d4e":"code","10fd7b12":"code","9067fc68":"code","4e2fc632":"code","01b03051":"code","cc9478b5":"code","9b46f60a":"code","17cde9f4":"code","9f88b54a":"code","db8d4f13":"code","e7586631":"code","32e5844e":"code","ee318b68":"code","3eccea76":"code","0432b10b":"markdown","b2c3e83e":"markdown","fd2cda28":"markdown","c7d05aa0":"markdown","63e7e6ac":"markdown","d0851110":"markdown","fd97318c":"markdown","5558fa3c":"markdown","d5cfd708":"markdown","41aaffe9":"markdown","98b31929":"markdown","451d5406":"markdown","08a70caa":"markdown","a54c1f4e":"markdown","674265f1":"markdown","3a244e4e":"markdown","52b072ed":"markdown","90a251c6":"markdown","a89cbfa3":"markdown","ef6bb455":"markdown"},"source":{"490ce200":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","14b74b8f":"df = pd.read_csv('..\/input\/kuc-hackathon-winter-2018\/drugsComTrain_raw.csv', parse_dates=[\"date\"])\ndf_test = pd.read_csv('..\/input\/kuc-hackathon-winter-2018\/drugsComTest_raw.csv', parse_dates=[\"date\"])","fb8fbca7":"print(df.shape)\nprint(df_test.shape)","693fb413":"df['month'] = df.date.apply(lambda i: i.month)\ndf['day'] = df.date.apply(lambda i: i.day)\ndf['year'] = df.date.apply(lambda i: i.year)\n\ndf_test['month'] = df_test.date.apply(lambda i: i.month)\ndf_test['day'] = df_test.date.apply(lambda i: i.day)\ndf_test['year'] = df_test.date.apply(lambda i: i.year)\n\ndf['reviewLength'] = df.review.apply(lambda x: len(x.split()))\ndf_test['reviewLength'] = df_test.review.apply(lambda x: len(x.split()))","a767c491":"df.dtypes","344e4cea":"fig, ax = plt.subplots(3,1, figsize=(15,15))\n\nplt.style.use('seaborn')\n\n# Score by year\nax[0].plot(df.groupby('year').rating.mean())\nax[0].set_ylabel('Average Rating')\nax[0].set_xlabel('Year')\nax[0].set_title('Average Rating vs. Year')\n# plt.show()\n\nax[1].plot(df.groupby('month').rating.mean())\nax[1].set_ylabel('Average Rating')\nax[1].set_xlabel('Month')\nax[1].set_xticks(range(1,13))\nax[1].set_title('Average Rating vs. Month')\n\nax[2].plot(df.groupby('day').rating.mean())\nax[2].set_ylabel('Average Rating')\nax[2].set_xlabel('Day')\nax[2].set_xticks(range(1,32))\nax[2].set_title('Average Rating vs. Month')\n\nplt.show()","501fe36c":"# Create some mock data\n\n# plt.figure(figsize=(12,8))\nplt.style.use('fivethirtyeight')\n\nfig, ax1 = plt.subplots(figsize=(9,6))\nt = range(1,11)\n\ncolor = 'tab:red'\nax1.set_xlabel('Rating')\nax1.set_ylabel('Average usefulCount', color=color)\nax1.plot(t, df.groupby('rating').usefulCount.mean(), color=color, alpha=0.8)\nax1.set_xticks(range(1,11))\nax1.tick_params(axis='y', labelcolor=color)\nax1.set_title('Average usefulCount vs. Rating\\n Average Review Length vs. Rating')\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n\ncolor = 'tab:blue'\nax2.set_ylabel('Average Review Length', color=color)  # we already handled the x-label with ax1\nax2.plot(t, df.groupby('rating').reviewLength.mean(), color=color, alpha=0.8)\nax2.tick_params(axis='y', labelcolor=color)\n\nfig.tight_layout()  # otherwise the right y-label is slightly clipped\nplt.show()","90f50284":"# Make side-by-side barplot\nplt.figure(figsize=(9,6))\nplt.style.use('fivethirtyeight')\n\n\ndef make_hist(data1, data2, density=True) -> None:\n    \"\"\"make hist plot of useful counts given data, plot fraction if density is True\"\"\"\n#     print(data.shape)\n    total_counts1 = data1.usefulCount.sum()\n    total_counts2 = data2.usefulCount.sum()\n#     print(total_counts)\n    \n    sum_counts1 = data1.groupby('rating').usefulCount.sum()\n    frac_counts1 = sum_counts1\/total_counts1\n    frac1_6_10 = data1.groupby('rating').usefulCount.sum()[5:].sum()\/total_counts1\n    sum_counts2 = data2.groupby('rating').usefulCount.sum()\n    frac_counts2 = sum_counts2\/total_counts2\n    frac2_6_10 = data2.groupby('rating').usefulCount.sum()[5:].sum()\/total_counts2\n#     print(sum_counts)\n#     print(sum_counts.sum())\n\n    plt.bar([i-0.2 for i in range(1,11)],frac_counts1,width=0.4,  label='Total Average', color = 'tab:red', alpha=0.85)\n    plt.bar([i+0.2 for i in range(1,11)],frac_counts2,width=0.4,  label='Depression Average', color = 'tab:blue', alpha=0.85)\n    \n    plt.annotate(str(int(frac2_6_10*100))+'%',\n            xy=(9, 0.43), xycoords='data',\n            xytext=(5.75, 0.1), textcoords='data',\n            size=20, va=\"center\", ha=\"center\",\n            arrowprops=dict(arrowstyle=\"simple\",\n                            connectionstyle=\"arc3,rad=0.2\",\n                            color='tab:blue', alpha=0.85),\n            )\n    plt.annotate(str(int(frac1_6_10*100))+'%',\n            xy=(8, 0.43), xycoords='data',\n            xytext=(5.75, 0.17), textcoords='data',\n            size=20, va=\"center\", ha=\"center\",\n            arrowprops=dict(arrowstyle=\"simple\",\n                            connectionstyle=\"arc3,rad=0.2\",\n                            color='tab:red', alpha=0.85),\n            )\n    \n    \n    plt.xticks(range(1,11))\n    plt.xlabel('Rating')\n    plt.legend(['All Drugs','Depression Drugs'])\n    plt.ylabel('Fraction of usefulCounts')\n    plt.title('Distribution of usefulCounts\\n Total vs. Depression')\n    plt.tight_layout() \n    plt.show()\n\nmake_hist(df, df.loc[df.condition=='Depression',:])","22703ad2":"# Before\nprint(df.review[5])","cc7c5367":"##### Step 1. deal with html special symbols\n# https:\/\/stackoverflow.com\/questions\/753052\/strip-html-from-strings-in-python\n\nfrom html.parser import HTMLParser\n\nclass MLStripper(HTMLParser):\n    def __init__(self):\n        self.reset()\n        self.strict = False\n        self.convert_charrefs= True\n        self.fed = []\n    def handle_data(self, d):\n        self.fed.append(d)\n    def get_data(self):\n        return ''.join(self.fed)\n\ndef strip_tags(html):\n    s = MLStripper()\n    s.feed(html)\n    return s.get_data()\n\ndf['review'] = df.review.apply(lambda x: strip_tags(x))\ndf_test['review'] = df_test.review.apply(lambda x: strip_tags(x))","c4379496":"# After\nprint(df.review[5])","a078b800":"# Step 2. Remove contractions\n\n!pip install textsearch\n!pip install contractions\n\nimport contractions # need textsearch as well\n\ndf['review'] = df['review'].map(lambda x: contractions.fix(x))\ndf_test['review'] = df_test['review'].map(lambda x: contractions.fix(x))\n\nprint(df.review[5])","4b556d1f":"# Step 3. Convert to lowercase\n\ndf['review'] = df['review'].map(lambda x: x.lower())\ndf_test['review'] = df_test['review'].map(lambda x: x.lower())\n\n# Step 4. Remove numbers\nimport re\n\ndf['review'] = df['review'].map(lambda x: re.sub(r'\\d+', '', x))\ndf_test['review'] = df_test['review'].map(lambda x: re.sub(r'\\d+', '', x))\n\n# Step 5. Remove punctuation\ndf['review'] = df['review'].map(lambda x: re.sub('[!\u201d#$%&\u2019()*+,-.\/:;<=>?@[\\]^_`{|}~]', '', x))\ndf_test['review'] = df_test['review'].map(lambda x: re.sub('[!\u201d#$%&\u2019()*+,-.\/:;<=>?@[\\]^_`{|}~]', '', x))\n\ndf['review'] = df['review'].map(lambda x: x.split('\"')[1])\ndf_test['review'] = df_test['review'].map(lambda x: x.split('\"')[1])\n\n\nprint(df.review[5])","2d2d6105":"# Step 6. Lemmatize\n## This step is time-consuming\n\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nlemmatizer=WordNetLemmatizer()\n\ndf['review'] = df['review'].map(lambda x: ' '.join(lemmatizer.lemmatize(word, pos=\"v\") for word in word_tokenize(x)))\ndf_test['review'] = df_test['review'].map(lambda x: ' '.join(lemmatizer.lemmatize(word, pos=\"v\") for word in word_tokenize(x)))\n\ndf['review'] = df['review'].map(lambda x: ' '.join(lemmatizer.lemmatize(word, pos=\"n\") for word in word_tokenize(x)))\ndf_test['review'] = df_test['review'].map(lambda x: ' '.join(lemmatizer.lemmatize(word, pos=\"n\") for word in word_tokenize(x)))\n\nprint(df.review[5])","14b5ddff":"# Step 8. Removing stop words\nfrom nltk.corpus import stopwords\nstopword = stopwords.words('english')\n\n# text = \u201cThis is a Demo Text for NLP using NLTK. Full form of NLTK is Natural Language Toolkit\u201d\n# word_tokens = word_tokenize(text)\n# removing_stopwords = [word for word in word_tokens if word not in stopword]\n# print (removing_stopwords)\n\ndf['review'] = df['review'].map(lambda x: ' '.join(word for word in word_tokenize(x) if word not in stopword))\ndf_test['review'] = df_test['review'].map(lambda x: ' '.join(word for word in word_tokenize(x) if word not in stopword))\n\nprint(df.review[5])","159b1df4":"# Convert rating to 1-5\ndf.rating = (df.rating.values+1)\/\/2\ndf_test.rating = (df_test.rating.values+1)\/\/2","aefd5de3":"from sklearn.metrics import log_loss\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import classification_report\n\nlog_losses = []\ny_test = pd.get_dummies(df_test.rating)\ny_pred = y_test.copy()","48612f64":"# Random guessing\ny_pred.iloc[:,:] = 0.2\nlog_losses.append(log_loss(y_test, y_pred))","3d8941e1":"clf = OneVsRestClassifier(LogisticRegression(solver = 'liblinear'))\nX_train = df.loc[:,['year','month','reviewLength']]\ny_train = df.rating\nX_test = df_test.loc[:,['year','month','reviewLength']]\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict_proba(X_test)\nlog_losses.append(log_loss(y_test, y_pred))","a6c94171":"X_train = df.review\ny_train = df.rating\n\n# create the pipeline object\npl1 = Pipeline([\n        ('vectorizer', CountVectorizer()),\n        ('clf', OneVsRestClassifier(LogisticRegression(solver='liblinear')))])\n\n\n# fit the pipeline to our training data\n%time pl1.fit(X_train, y_train)","01fddcfd":"y_pred = pl1.predict_proba(df_test.review)\nlog_losses.append(log_loss(y_test, y_pred))","0f0d7d4e":"from sklearn.metrics import classification_report","10fd7b12":"# set a reasonable number of features before adding interactions\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer\n# create the pipeline object\npl2 = Pipeline([\n        ('vectorizer', CountVectorizer(ngram_range=(1, 2))),\n        ('clf', OneVsRestClassifier(LogisticRegression(solver='liblinear')))])\n\n# fit the pipeline to our training data\n%time pl2.fit(X_train, y_train)\n\ny_pred = pl2.predict_proba(df_test.review)\nlog_losses.append((log_loss(y_test, y_pred)))\nprint(log_losses)","9067fc68":"# create the pipeline object\npl3 = Pipeline([\n        ('vectorizer', CountVectorizer(ngram_range=(2, 4))),\n        ('clf', OneVsRestClassifier(LogisticRegression(solver='liblinear', class_weight='balanced')))])\n\n%time pl3.fit(X_train, y_train)\n\ny_pred = pl3.predict_proba(df_test.review)\nlog_losses.append((log_loss(y_test, y_pred)))\nprint(log_losses)","4e2fc632":"print(classification_report(pl3.predict(df_test.review), df_test.rating))","01b03051":"labels = ['Random Guess', 'LogisticRegression \\nwith numeric variables', \n          'LogisticRegression \\nwith text', 'LogisticRegression \\nwith text(ngram=(1,2))', 'LogisticRegression \\nwith text(ngram=(2,4))' ]","cc9478b5":"plt.style.use('fivethirtyeight')\n# plt.figure()\nfig, ax = plt.subplots(figsize=(10,10))\nind = np.arange(len(labels))\nwidth = 0.75\n\nax.barh(ind,log_losses[::-1], width)\nax.set_yticks(ind)\nax.set_yticklabels(labels[::-1])\nplt.xlabel('Log loss values')\n\nplt.annotate('-65%',\n            xy=(0.7, 0.3), xycoords='data',\n            xytext=(1.6, 3.2), textcoords='data',\n            size=20, va=\"center\", ha=\"center\",\n            arrowprops=dict(arrowstyle=\"simple\",\n                            connectionstyle=\"arc3,rad=-0.2\",\n                            color='tab:blue', alpha=0.85),\n            )\n\n# plt.ylabel('Methods')\nplt.title('Log loss values under different methods')\n# plt.tight_layout() \nplt.show()","9b46f60a":"import numpy as np\nimport pandas as pd\nfrom os import path\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\nall = pd.concat([df.iloc[:,0:11], df_test])","17cde9f4":"text = \" \".join(review for review in all.review)\n\nprint (\"There are {} words in the combination of all review.\".format(len(text)))\n\n# Create and generate a word cloud image:\nwordcloud = WordCloud(width=800, height=300,background_color=\"white\").generate(text)\n\nplt.figure(figsize=(20,5))\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","9f88b54a":"# Birth Control reviews\n\ntext = \" \".join(review for review in all[all.condition=='Birth Control'].review)\n\nprint (\"There are {} words in the combination of all review.\".format(len(text)))\n\nwordcloud = WordCloud(width=800, height=300,background_color=\"white\").generate(text)\n\nplt.figure(figsize=(20,5))\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","db8d4f13":"# Birth Control reviews\n\ntext = \" \".join(review for review in all[all.condition=='Depression'].review)\n\nprint (\"There are {} words in the combination of all review.\".format(len(text)))\n\nwordcloud = WordCloud(width=800, height=300,background_color=\"white\").generate(text)\n\nplt.figure(figsize=(20, 5))\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","e7586631":"verbs = ['take', 'get', 'go', 'work', 'start', 'day', 'days', 'feel', 'time', 'year', 'month', 'years', 'months', 'mg', 'like', 'would', 'use',\\\n         'first', 'try', 'doctor', 'pill', 'week', 'dose', 'lb', 'hour', 'one', 'never']\n\n# remove drug names\nnew_set = set(all.drugName.tolist())\nnew_set = {i.lower() for i in new_set}\n\nnew_list=[]\nfor i in new_set:\n    good = i.split()\n    new_list.extend(good)\nnew_set=set(new_list)\n\nall = all.copy()\nall['review'] = all.review.map(lambda x: ' '.join(word for word in word_tokenize(x) if word not in verbs))\nall['review'] = all.review.map(lambda x: ' '.join(word for word in word_tokenize(x) if word not in new_set))","32e5844e":"%%time\n\n# import warnings\n# warnings.simplefilter(\"ignore\", DeprecationWarning)\n\n# Load the LDA model from sk-learn\nfrom sklearn.decomposition import LatentDirichletAllocation as LDA\n \n# Helper function\ndef print_topics(model, count_vectorizer, n_top_words):\n    words = count_vectorizer.get_feature_names()\n    for topic_idx, topic in enumerate(model.components_):\n        print(\"\\nTopic #%d:\" % topic_idx)\n        print(\" \".join([words[i]\n                        for i in topic.argsort()[:-n_top_words - 1:-1]]))","ee318b68":"count_vectorizer = CountVectorizer()\ncount_data = count_vectorizer.fit_transform(all[all.condition=='Birth Control'].review)\n\nnumber_topics = 3\nnumber_words = 8\n\nlda = LDA(n_components=number_topics, n_jobs=-1, random_state=1)\nlda.fit(count_data)\n\n# Print the topics found by the LDA model\nprint(\"Topics found via LDA:\")\nprint_topics(lda, count_vectorizer, number_words)","3eccea76":"count_data = count_vectorizer.fit_transform(all[all.condition=='Depression'].review)\n\nnumber_topics = 3\nnumber_words = 8\n\nlda = LDA(n_components=number_topics, n_jobs=-1, random_state=55566)\nlda.fit(count_data)\n\n# Print the topics found by the LDA model\nprint(\"Topics found via LDA:\")\nprint_topics(lda, count_vectorizer, number_words)","0432b10b":"1. Word cloud based on all drug reviews","b2c3e83e":"## 2.5 Removing stop words","fd2cda28":"## 3.3 Logistic regression with reviews","c7d05aa0":"## 3.4 use `countVectorizer` with `ngram_range=(1,2)`","63e7e6ac":"This \u2018bias\u2019 pattern is more extreme on Depression drug reviews. As shown in following figure. For all drugs, the reviews giving a rating higher than 6 get 82% of all useful counts, and the percentage rise to 86% for depression drug reviews. ","d0851110":"## 2.2 Remove contractions","fd97318c":"# 2. Preprocessing Text\n## 2.1 Deal with html symbols\nSince the data was collected by crowling the pharmacy website, it contains some special symbols like \"&#039\" and \"&amp;\" whick represent \"'\" and \"&\". So, first let's deal with these symbols.","5558fa3c":"## 2.3 Convert to lowercase, remove numbers and punctuations","d5cfd708":"## 3.2 Logistic regression with numeric variables (year, month, review length)","41aaffe9":"## 3.1 Random Guessing\nFirst, let's set random guessing as our benchmark.","98b31929":"Hi, everyone, I'm new to kaggle and this is my first kaggle kernel. Let me know if you have any questions.","451d5406":"# 1. EDA \n","08a70caa":"## 4.2 Topic Modeling\nLet's remove more stop words first.","a54c1f4e":"Here are some fun facts about the data.The first one is about review length: as shown in the blue line in the following figure. Review length is shortest for best and worst ratings. \nNow let\u2019s look at the red line, it seems the higher the rating, the more people would find the review helpful. ","674265f1":"# 3. Classification\nI was hoping to adding other review data to this project. So I convert the rating from 1-10 to 1-5, since other reivew data like yelp and amazon only have 1-5 ratings.****","3a244e4e":"# 4 Topic Modeling\n## 4.1 Word Cloud","52b072ed":"## 2.4 Lemmatization","90a251c6":"2. Word cloud based on 'Depression' drugs reviews","a89cbfa3":"2. Word cloud based on 'Birth Control' drugs reviews","ef6bb455":"## 3.5 use `countVectorizer` with `ngram_range=(2,4)`"}}