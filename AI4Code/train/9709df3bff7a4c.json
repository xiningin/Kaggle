{"cell_type":{"76596320":"code","a1ea554f":"code","ed9aa030":"code","1448eed3":"code","2e21ae27":"code","2f5e1efd":"code","4da088d7":"code","2ee71549":"code","ef6ef40a":"code","eaafa6f4":"code","c9eb4ae1":"code","4c3f06ee":"code","06cbb993":"code","e49e446e":"code","04a77821":"code","1292b098":"code","8e24f7d5":"code","90fc76bb":"code","0e89b84e":"code","1b838043":"code","692dc70d":"code","293bc123":"code","f95099f6":"code","042c2707":"code","77e2c86d":"code","4520c0a2":"code","01c750c7":"code","69811d52":"code","0161d71b":"code","cfa00f68":"code","c2b7fc29":"code","8464b555":"code","829ca247":"code","1b10a398":"code","2e4664d8":"code","544dd9b1":"code","108f3c21":"code","14e65fd8":"code","3d64145c":"code","3552deb7":"code","fae99b5e":"code","23fc6e10":"code","61ce783b":"code","2d9ed593":"code","232d2820":"code","1ae1550e":"code","73790529":"code","f43c0870":"code","62e2a4a0":"code","b36c3d0b":"code","cf4c6c1c":"code","f2427d8a":"code","38fc7276":"code","475dbd5e":"code","227055c7":"code","ab8f44a8":"code","cb8b1146":"code","993d3c08":"code","d47f93f7":"code","52e2342a":"code","fde0fa14":"code","99e2be62":"code","665e8c68":"code","2b89ef10":"code","c463eccb":"code","16fef8fb":"code","789aeee4":"code","3530da75":"code","39f05201":"code","dbef8748":"code","243f5d35":"code","ad46f289":"code","b8882b3e":"code","922ce46d":"code","7fb9d4cd":"code","18c85278":"code","1fea6420":"code","9dc9d237":"markdown","57cf804b":"markdown","3f97d541":"markdown","14ec424e":"markdown","df87c341":"markdown","404a83eb":"markdown","6f06cb82":"markdown","55e1c5f2":"markdown","927f82af":"markdown","a4af6049":"markdown","3590183d":"markdown","8c37d1a4":"markdown","cf3a2961":"markdown","199ac189":"markdown","ff8e6534":"markdown","b9f423af":"markdown","6928168c":"markdown","634ec028":"markdown","ff7082e7":"markdown","b4cddd25":"markdown","a3e4a525":"markdown","84eb8cf7":"markdown","4fa1ab14":"markdown","6d7495a0":"markdown"},"source":{"76596320":"#import relevant modules for assignment\n\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport IPython.display\nimport PIL.Image\nimport tensorflow_datasets as tfds\nfrom tensorflow import keras\nfrom keras.datasets import fashion_mnist","a1ea554f":"#import fashion mnist, split into train\/test\/validation dataset & split into test\/train sets\n(train_images,train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\n#Creating validation dataset to go with training and test dataset imported\n\ntrain_images = train_images[6000:]\ntrain_labels = train_labels[6000:]\nval_images = train_images[:6000]\nval_labels = train_labels[:6000]\n\n#Print the shape of our image datasets\n\nprint(train_images.shape)\nprint(val_images.shape)\nprint(test_images.shape)\nprint()\n\n#Print the shape of our label datasets\nprint(train_labels.shape)\nprint(val_labels.shape)\nprint(test_labels.shape)","ed9aa030":"#Converting labels to categorical data\n\nfrom tensorflow.keras.utils import to_categorical\n\ntrain_labels = to_categorical(train_labels)\ntest_labels = to_categorical(test_labels)\nval_labels = to_categorical(val_labels)","1448eed3":"#pre-processing - batching completed in model.fit step 'batch_size'\n\n#Defining function to scale image pixels to have values between 0 and 1 - normalization pipeline\n\ndef normalize(example):\n    image = example\n    image = tf.math.divide(tf.math.subtract(image,tf.reduce_min(image)), tf.math.subtract(tf.reduce_max(image), tf.reduce_min(image)))\n    return image\n\n#Defining function to re-shape images to 784 pixels\n\ndef reshape(example):\n    image = example\n    image = tf.reshape(example, (len(image), 28 * 28))\n    return image\n\ntrain_images = reshape(train_images)\ntest_images = reshape(test_images)\nval_images = reshape(val_images)\n\ntrain_norm = normalize(train_images)\ntest_norm = normalize(test_images)\nval_norm = normalize(val_images)\n\nprint(train_norm.shape)\nprint(test_norm.shape)\nprint(val_norm.shape)\n","2e21ae27":"from tensorflow.keras import models, layers\n\n#build dense neural network\nmodel = models.Sequential([\n        layers.Dense(512, activation='relu', input_shape=(28 * 28,)),\n        layers.Dense(256, activation='relu'),\n        layers.Dropout(.2),\n        layers.Dense(128, activation='relu'),\n        layers.Dense(10, activation='softmax')])\n\nmodel.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(train_norm,\n                    train_labels,\n                    batch_size=100, \n                    epochs=500,\n                    validation_data = (val_norm, val_labels))\n\ntest_loss, test_acc = model.evaluate(test_norm, test_labels)","2f5e1efd":"#plotting accuracy vs loss accros training and validation sets, via TFDOCS - import modules\n!pip install git+https:\/\/github.com\/tensorflow\/docs\n\nimport tensorflow_docs as tfdocs\nimport tensorflow_docs.plots\nimport matplotlib.pyplot as plt","4da088d7":"accuracy = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\n\n#Plot 1 - Training vs Validation Loss\n\nepochs = range(1, len(loss) + 1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs, loss, 'g*', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n#Plot 2 - Training vs Validation Accuracy\n\nepochs1 = range(1, len(accuracy) +1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs1, accuracy, 'g*', label='Training Accuracy')\nplt.plot(epochs1, val_acc, 'b', label='Validation Accuracy')\nplt.title('Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n#printing test loss & accuracy\nprint(\"Our Dense Model Test Loss is: {}\".format(round(test_loss,3)))\nprint(\"Our Dense Model Test Accuracy is: {}\".format(round(test_acc,3)))","2ee71549":"#new reshaping function, to fit with CNN\ndef reshape2(example):\n    image = example\n    image = tf.reshape(example, (len(image), 28, 28, 1))\n    return image\n\ntrain_conv = reshape2(train_images)\nval_conv = reshape2(val_images)\ntest_conv = reshape2(test_images)\n\ndef normalize(example):\n    image = example\n    image = tf.math.divide(tf.math.subtract(image,tf.reduce_min(image)), tf.math.subtract(tf.reduce_max(image), tf.reduce_min(image)))\n    return image\n\ntrain_normc = normalize(train_conv)\ntest_normc = normalize(test_conv)\nval_normc = normalize(val_conv)\n\nprint(train_normc.shape)\nprint(test_normc.shape)\nprint(val_normc.shape)","ef6ef40a":"#defining model function for CNN\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import models, layers\n\ndef make_model():\n  modelconv = models.Sequential()\n  modelconv.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n  modelconv.add(layers.MaxPooling2D((2, 2)))\n  modelconv.add(layers.Conv2D(64, (3, 3), activation='relu'))\n  modelconv.add(layers.MaxPooling2D((2, 2)))\n  modelconv.add(layers.Conv2D(128, (2, 2), activation='relu'))\n  modelconv.add(layers.MaxPooling2D((2, 2)))\n  modelconv.add(layers.Conv2D(128, (1, 1), activation='relu'))\n  modelconv.add(layers.MaxPooling2D((2, 2)))\n  modelconv.add(layers.Flatten())\n  modelconv.add(layers.Dense(512, activation='relu'))\n  modelconv.add(layers.Dense(10, activation='softmax'))\n\n  modelconv.compile(loss='categorical_crossentropy',\n                optimizer=optimizers.RMSprop(lr=1e-4),\n                metrics=['accuracy'])\n  \n  return modelconv\n\nmodelconv = make_model()\nmodelconv.summary()","eaafa6f4":"#history for our convnet, including batching\n\nhistoryconv = modelconv.fit(\n      train_normc,\n      train_labels,\n      batch_size=100,\n      steps_per_epoch=100,\n      epochs=500,\n      validation_data=(val_normc, val_labels),\n      validation_steps=50)\n\ntest_lossc, test_accc = modelconv.evaluate(test_normc, test_labels)","c9eb4ae1":"accuracyc = historyconv.history['accuracy']\nval_accc = historyconv.history['val_accuracy']\nlossc = historyconv.history['loss']\nval_lossc = historyconv.history['val_loss']\n\n#Plot 1 - Training vs Validation Loss\n\nepochsc = range(1, len(lossc) + 1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochsc, lossc, 'g*', label='Training Loss')\nplt.plot(epochsc, val_lossc, 'r', label='Validation Loss')\nplt.title('CNN - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n#Plot 2 - Training vs Validation Accuracy\n\nepochs1c = range(1, len(accuracyc) +1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs1c, accuracyc, 'g*', label='Training Accuracy')\nplt.plot(epochs1c, val_accc, 'b', label='Validation Accuracy')\nplt.title('CNN - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n#printing test loss & accuracy\nprint(\"Our CNN Model Test Loss is: {}\".format(round(test_lossc,3)))\nprint(\"Our CNN Model Test Accuracy is: {}\".format(round(test_accc,3)))\nprint()","4c3f06ee":"#creating augmented dataframe for our fashion_mnist training set\n#performing random flips & cropping\n\ntrain_aug = tf.image.random_flip_left_right(train_normc)\ntrain_aug = tf.image.random_flip_up_down(train_aug)\ntrain_aug = tf.image.random_crop(train_aug, (54000, 28, 28, 1))\n","06cbb993":"#training new CNN model on augmented data\n\nhistoryaug = modelconv.fit(\n      train_aug,\n      train_labels,\n      batch_size=100,\n      steps_per_epoch=100,\n      epochs=500,\n      validation_data=(val_normc, val_labels),\n      validation_steps=50)\n\ntest_loss_aug, test_acc_aug = modelconv.evaluate(test_normc, test_labels)","e49e446e":"accuracy_aug = historyaug.history['accuracy']\nval_acc_aug = historyaug.history['val_accuracy']\nloss_aug = historyaug.history['loss']\nval_loss_aug = historyaug.history['val_loss']\n\n#Plot 1 - Training vs Validation Loss\n\nepochs_aug = range(1, len(loss_aug) + 1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs_aug, loss_aug, 'g*', label='Training Loss')\nplt.plot(epochs_aug, val_loss_aug, 'r', label='Validation Loss')\nplt.title('CNN - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n#Plot 2 - Training vs Validation Accuracy\n\nepochs1_aug = range(1, len(accuracy_aug) +1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs1_aug, accuracy_aug, 'g*', label='Training Accuracy')\nplt.plot(epochs1_aug, val_acc_aug, 'b', label='Validation Accuracy')\nplt.title('CNN - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n#printing test loss & accuracy\nprint(\"Our CNN Model Test Loss is: {}\".format(round(test_loss_aug,3)))\nprint(\"Our CNN Model Test Accuracy is: {}\".format(round(test_acc_aug,3)))\nprint()","04a77821":"import keras\nfrom keras.applications import VGG19\nfrom keras.applications.vgg19 import preprocess_input\nfrom keras.layers import Dense, Dropout\nfrom keras.models import Model\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers","1292b098":"vgg19_base = VGG19(weights='imagenet', include_top=False, input_shape = (48, 48, 3))","8e24f7d5":"vgg19_base.trainable = False","90fc76bb":"# Preprocessing the input \nX_train = preprocess_input(np.array(train_images))\nX_val = preprocess_input(np.array(val_images))\nX_test = preprocess_input(np.array(test_images))\n\nprint(X_train.shape)","0e89b84e":"def reshape3(example):\n    image = example\n    image = tf.reshape(example, (len(image), 28, 28, 1))\n    return image\n\nX_train = reshape3(X_train)\nX_val = reshape3(X_val)\nX_test = reshape3(X_test)\n\nprint(X_train.shape)","1b838043":"def transform_input_vgg(x):\n    x_vgg = np.array(x).reshape(-1,28,28)\n    x_vgg = np.repeat(x_vgg[:, :, :, np.newaxis], 3, axis=3)\n#    x_vgg = preprocess_input(x_vgg)\n    return x_vgg\n\nX_train = transform_input_vgg(X_train)\nX_val = transform_input_vgg(X_val)\nX_test = transform_input_vgg(X_test)\n\nprint(X_train.shape)\nprint(X_val.shape)\nprint(X_test.shape)","692dc70d":"IMAGE_SIZE = 48\ndef pre_process_image(image):\n    image = tf.image.convert_image_dtype(image, tf.float32) #replacement for manual scaling as per A1\n    image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n    return image\n\nX_train_f = pre_process_image(X_train)\nX_val_f = pre_process_image(X_val)\nX_test_f = pre_process_image(X_test)\n\nprint(X_train_f.shape)\nprint(X_val_f.shape)\nprint(X_test_f.shape)","293bc123":"def make_model():\n  model = models.Sequential()\n  model.add(vgg19_base)\n  model.add(layers.Flatten())\n  model.add(layers.Dense(256, activation='relu'))\n  model.add(layers.Dropout(0.7))\n  model.add(layers.Dense(10, activation='softmax'))\n\n  model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])\n\n  return model\n\nmodel_tf = make_model()\nmodel_tf.summary()","f95099f6":"#VGG16 model without fine tuning\nhistory_tl= model_tf.fit(\n      X_train_f,\n      train_labels,\n      batch_size=100,\n      steps_per_epoch=100,\n      epochs=500,\n      validation_data=(X_val_f, val_labels),\n      validation_steps=50)\n\ntest_loss_vgg, test_acc_vgg = model_tf.evaluate(X_test_f, test_labels)","042c2707":"#evalutate & plot vgg model without tuning\n\naccuracy_vgg = history_tl.history['accuracy']\nval_acc_vgg = history_tl.history['val_accuracy']\nloss_vgg = history_tl.history['loss']\nval_loss_vgg = history_tl.history['val_loss']\n\n#Plot 1 - Training vs Validation Loss\n\nepochs_vgg = range(1, len(loss_vgg) + 1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs_vgg, loss_vgg, 'g*', label='Training Loss')\nplt.plot(epochs_vgg, val_loss_vgg, 'r', label='Validation Loss')\nplt.title('VGG No Tuning - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n#Plot 2 - Training vs Validation Accuracy\n\nepochs1_vgg = range(1, len(accuracy_vgg) +1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs1_vgg, accuracy_vgg, 'g*', label='Training Accuracy')\nplt.plot(epochs1_vgg, val_acc_vgg, 'b', label='Validation Accuracy')\nplt.title('VGG No Tuning - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n#printing test loss & accuracy\nprint(\"Our VGG No Tuning Model Test Loss is: {}\".format(round(test_loss_vgg,3)))\nprint(\"Our VGG No Tuning Model Test Accuracy is: {}\".format(round(test_acc_vgg,3)))\nprint()","77e2c86d":"vgg19_base.trainable = True\nvgg19_base.summary()","4520c0a2":"#fine tuning for VGG19 model, enabling training on 'block5'\n\nset_trainable = False\nfor layer in vgg19_base.layers:\n    if layer.name == 'block5_conv1':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False","01c750c7":"#VGG19 model with fine tuning\nmodel_tf2 = make_model()\n\nmodel_tf2.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])\n\nhistory_tl2= model_tf2.fit(\n      X_train_f,\n      train_labels,\n      batch_size=100,\n      steps_per_epoch=100,\n      epochs=500,\n      validation_data=(X_val_f, val_labels),\n      validation_steps=50)\n\ntest_loss_vgg2, test_acc_vgg2 = model_tf2.evaluate(X_test_f, test_labels)","69811d52":"#plotting fine tuning model performance\n\naccuracy_vgg2 = history_tl2.history['accuracy']\nval_acc_vgg2 = history_tl2.history['val_accuracy']\nloss_vgg2 = history_tl2.history['loss']\nval_loss_vgg2 = history_tl2.history['val_loss']\n\n#Plot 1 - Training vs Validation Loss\n\nepochs_vgg2 = range(1, len(loss_vgg2) + 1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs_vgg2, loss_vgg2, 'g*', label='Training Loss')\nplt.plot(epochs_vgg2, val_loss_vgg2, 'r', label='Validation Loss')\nplt.title('VGG w Tuning - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n#Plot 2 - Training vs Validation Accuracy\n\nepochs1_vgg2 = range(1, len(accuracy_vgg2) +1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs1_vgg2, accuracy_vgg2, 'g*', label='Training Accuracy')\nplt.plot(epochs1_vgg2, val_acc_vgg2, 'b', label='Validation Accuracy')\nplt.title('VGG w Tuning - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n#printing test loss & accuracy\nprint(\"Our VGG w Tuning Model Test Loss is: {}\".format(round(test_loss_vgg2,4)))\nprint(\"Our VGG w Tuning Model Test Accuracy is: {}\".format(round(test_acc_vgg2,4)))\nprint()","0161d71b":"#load data for CIFAR10 and print data shape\n\nimport matplotlib.pyplot as plt\nfrom keras.datasets import cifar10\n\n(trainc_images, trainc_labels), (testc_images, testc_labels) = cifar10.load_data()\n\ntrainc_images = trainc_images[6000:]\ntrainc_labels = trainc_labels[6000:]\nvalc_images = trainc_images[:6000]\nvalc_labels = trainc_labels[:6000]\n\n#Print the shape of our image datasets\n\nprint(trainc_images.shape)\nprint(valc_images.shape)\nprint(testc_images.shape)\nprint()\n\n#Print the shape of our label datasets\nprint(trainc_labels.shape)\nprint(valc_labels.shape)\nprint(testc_labels.shape)\n","cfa00f68":"#Converting labels to categorical data\n\nfrom tensorflow.keras.utils import to_categorical\n\ntrainc_labels = to_categorical(trainc_labels)\ntestc_labels = to_categorical(testc_labels)\nvalc_labels = to_categorical(valc_labels)","c2b7fc29":"def normalize(example):\n    image = example\n    image = tf.math.divide(tf.math.subtract(image,tf.reduce_min(image)), tf.math.subtract(tf.reduce_max(image), tf.reduce_min(image)))\n    return image\n\ntrainc_norm = normalize(trainc_images)\nvalc_norm = normalize(valc_images)\ntestc_norm = normalize(testc_images)","8464b555":"#CPU\n! lscpu","829ca247":"#GPU\n! nvidia-smi","1b10a398":"#defining model function for Cifar10 CNN, 9 layers\n\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import models, layers\n\ndef make_model_cifar():\n  modelconv = models.Sequential()\n  modelconv.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=(32, 32, 3)))\n  modelconv.add(layers.MaxPooling2D((2, 2)))\n  modelconv.add(layers.Conv2D(64, (3, 3), activation='relu'))\n  modelconv.add(layers.MaxPooling2D((2, 2)))\n  modelconv.add(layers.Conv2D(128, (2, 2), activation='relu'))\n  modelconv.add(layers.MaxPooling2D((2, 2)))\n  modelconv.add(layers.Flatten())\n  modelconv.add(layers.Dense(512, activation='relu'))\n  modelconv.add(layers.Dense(10, activation='softmax'))\n\n  modelconv.compile(loss='categorical_crossentropy',\n                optimizer=optimizers.RMSprop(lr=1e-4),\n                metrics=['accuracy'])\n  \n  return modelconv\n\nmodel_cif = make_model_cifar()\nmodel_cif.summary()","2e4664d8":"model_cif.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])\n\nhistory_cif= model_cif.fit(\n      trainc_norm,\n      trainc_labels,\n      batch_size=100,\n      steps_per_epoch=100,\n      epochs=500,\n      validation_data=(valc_norm, valc_labels),\n      validation_steps=50)\n\ntest_loss_cif, test_acc_cif = model_cif.evaluate(testc_norm, testc_labels)","544dd9b1":"#plotting fine tuning model performance\n\naccuracy_cif = history_cif.history['accuracy']\nval_acc_cif = history_cif.history['val_accuracy']\nloss_cif = history_cif.history['loss']\nval_loss_cif = history_cif.history['val_loss']\n\n#Plot 1 - Training vs Validation Loss\n\nepochs_cif = range(1, len(loss_cif) + 1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs_cif, loss_cif, 'g*', label='Training Loss')\nplt.plot(epochs_cif, val_loss_cif, 'r', label='Validation Loss')\nplt.title('Cifar10 - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n#Plot 2 - Training vs Validation Accuracy\n\nepochs1_cif = range(1, len(accuracy_cif) +1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs1_cif, accuracy_cif, 'g*', label='Training Accuracy')\nplt.plot(epochs1_cif, val_acc_cif, 'b', label='Validation Accuracy')\nplt.title('Cifar10 - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n#printing test loss & accuracy\nprint(\"Our Shallow Cifar10 Test Loss is: {}\".format(round(test_loss_cif,3)))\nprint(\"Our Shallow Cifar10 Test Accuracy is: {}\".format(round(test_acc_cif,3)))\nprint()","108f3c21":"#importing ResNet50 via keras\n\nfrom keras.applications import ResNet50\nfrom keras.applications.resnet50 import preprocess_input","14e65fd8":"res_base = ResNet50(weights=None, include_top=False, input_shape = (32, 32, 3))\nres_base.summary()\n\n#not using normalized data or augmentation, both yielded slightly worse results when using ResNet50 as the preprocessing function is already defined\ntrainc_images = preprocess_input(trainc_images)\nvalc_images = preprocess_input(valc_images)\ntestc_images = preprocess_input(testc_images)","3d64145c":"from tensorflow.keras import models, layers, optimizers\n#model has all layers as trainable, this yielded the best results compared to a combination of ResNet50 blocks being activated\/not activated\n\ndef make_model():\n  model = models.Sequential()\n  model.add(res_base)\n  model.add(layers.Flatten())\n  model.add(layers.Dense(512, activation='relu'))\n  model.add(layers.Dropout(0.3))\n  model.add(layers.Dense(256, activation='relu'))\n  model.add(layers.Dense(10, activation='softmax'))\n\n  model.compile(optimizer='adam',\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])\n\n  return model\n\nmodel_res = make_model()\nmodel_res.summary()","3552deb7":"%%time \nhistory_res= model_res.fit(\n      trainc_images,\n      trainc_labels,\n      batch_size=100,\n      steps_per_epoch=100,\n      epochs=500,\n      validation_data=(valc_images, valc_labels),\n      validation_steps=50)\n\ntest_loss_res, test_acc_res = model_res.evaluate(testc_images, testc_labels)","fae99b5e":"print('Model Run Time = 30min 40s')\n","23fc6e10":"#plotting fine tuning model performance\n\naccuracy_res = history_res.history['accuracy']\nval_acc_res = history_res.history['val_accuracy']\nloss_res = history_res.history['loss']\nval_loss_res = history_res.history['val_loss']\n\n#Plot 1 - Training vs Validation Loss\n\nepochs_res = range(1, len(loss_res) + 1)\n\nplt.figure(figsize= (8,8))\nplt.ylim(0,5)\nplt.plot(epochs_res, loss_res, 'g*', label='Training Loss')\nplt.plot(epochs_res, val_loss_res, 'r', label='Validation Loss')\nplt.title('Cifar10 ResNet50 - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n#Plot 2 - Training vs Validation Accuracy\n\nepochs1_res = range(1, len(accuracy_res) +1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs1_res, accuracy_res, 'g*', label='Training Accuracy')\nplt.plot(epochs1_res, val_acc_res, 'b', label='Validation Accuracy')\nplt.title('Cifar10 ResNet50 - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n#printing test loss & accuracy\nprint(\"Our ResNet Test Loss is: {}\".format(round(test_loss_res,3)))\nprint(\"Our ResNet Cifar10 Test Accuracy is: {}\".format(round(test_acc_res,3)))","61ce783b":"#Option 1 - Learning Rate Schedule\nfrom tensorflow.keras import models, layers, optimizers\n\ninitial_learning_rate = 0.001\n\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=5000, decay_rate=0.96)\n\noptimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n\ndef make_model2():\n  model = models.Sequential()\n  model.add(res_base)\n  model.add(layers.Flatten())\n  model.add(layers.Dense(512, activation='relu'))\n  model.add(layers.Dropout(0.3))\n  model.add(layers.Dense(256, activation='relu'))\n  model.add(layers.Dense(10, activation='softmax'))\n\n  model.compile(optimizer=optimizer,\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])\n\n  return model\n\n\n\nmodel_res2 = make_model2()\nmodel_res2.summary()","2d9ed593":"%%time\n\nhistory_res2= model_res2.fit(\n      trainc_images,\n      trainc_labels,\n      batch_size=100,\n      steps_per_epoch=100,\n      epochs=500,\n      validation_data=(valc_images, valc_labels),\n      validation_steps=50)\n\ntest_loss_res2, test_acc_res2 = model_res2.evaluate(testc_images, testc_labels)","232d2820":"print('Learning Rate Schedule Model Run Time: 30min 16s')","1ae1550e":"#plotting  model performance\n\naccuracy_res2 = history_res2.history['accuracy']\nval_acc_res2 = history_res2.history['val_accuracy']\nloss_res2 = history_res2.history['loss']\nval_loss_res2 = history_res2.history['val_loss']\n\n#Plot 1 - Training vs Validation Loss\n\nepochs_res2 = range(1, len(loss_res2) + 1)\n\nplt.figure(figsize= (8,8))\nplt.ylim(0,5)\nplt.plot(epochs_res2, loss_res2, 'g*', label='Training Loss')\nplt.plot(epochs_res2, val_loss_res2, 'r', label='Validation Loss')\nplt.title('Cifar10 ResNet50 w LR Schedule - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n#Plot 2 - Training vs Validation Accuracy\n\nepochs1_res2 = range(1, len(accuracy_res2) +1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs1_res2, accuracy_res2, 'g*', label='Training Accuracy')\nplt.plot(epochs1_res2, val_acc_res2, 'b', label='Validation Accuracy')\nplt.title('Cifar10 ResNet50 w LR Schedule - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n#printing test loss & accuracy\nprint(\"Our ResNet50 w LR Schedule Test Loss is: {}\".format(round(test_loss_res2,3)))\nprint(\"Our ResNet50 w LR Schedule Test Accuracy is: {}\".format(round(test_acc_res2,3)))","73790529":"from tensorflow.keras import models, layers, optimizers\ninitial_learning_rate = 0.001\n\nlr_schedule = keras.optimizers.schedules.InverseTimeDecay(initial_learning_rate, decay_steps=5000, decay_rate=0.96, staircase=True)\n\noptimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n\ndef make_model21():\n  model = models.Sequential()\n  model.add(res_base)\n  model.add(layers.Flatten())\n  model.add(layers.Dense(512, activation='relu'))\n  model.add(layers.Dropout(0.3))\n  model.add(layers.Dense(256, activation='relu'))\n  model.add(layers.Dense(10, activation='softmax'))\n\n  model.compile(optimizer=optimizer,\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])\n\n  return model","f43c0870":"%%time\n\nmodel_res21 = make_model21()\n\nhistory_res21= model_res21.fit(\n      trainc_images,\n      trainc_labels,\n      batch_size=100,\n      steps_per_epoch=100,\n      epochs=500,\n      validation_data=(valc_images, valc_labels),\n      validation_steps=50)\n\ntest_loss_res21, test_acc_res21 = model_res21.evaluate(testc_images, testc_labels)","62e2a4a0":"print('Learning Rate Schedule Model (Inv Decay) Epochs Run Time: 30min 8s ')  ","b36c3d0b":"#plotting  model performance\n\naccuracy_res21 = history_res21.history['accuracy']\nval_acc_res21 = history_res21.history['val_accuracy']\nloss_res21 = history_res21.history['loss']\nval_loss_res21 = history_res21.history['val_loss']\n\n#Plot 1 - Training vs Validation Loss\n\nepochs_res21 = range(1, len(loss_res21) + 1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs_res21, loss_res21, 'g*', label='Training Loss')\nplt.plot(epochs_res21, val_loss_res21, 'r', label='Validation Loss')\nplt.title('Cifar10 ResNet50 w Inv Decay - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n#Plot 2 - Training vs Validation Accuracy\n\nepochs1_res21 = range(1, len(accuracy_res21) +1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs1_res21, accuracy_res21, 'g*', label='Training Accuracy')\nplt.plot(epochs1_res21, val_acc_res21, 'b', label='Validation Accuracy')\nplt.title('Cifar10 ResNet50 w Inv Decy - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n#printing test loss & accuracy\nprint(\"Our ResNet50 w LR Schedule Test Loss is: {}\".format(round(test_loss_res21,3)))\nprint(\"Our ResNet50 w LR Schedule Test Accuracy is: {}\".format(round(test_acc_res21,3)))","cf4c6c1c":"from tensorflow.keras import models, layers, optimizers\ninitial_learning_rate = 0.001\n\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=5000, decay_rate=0.96, staircase=True)\n\noptimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n\ndef make_model22():\n  model = models.Sequential()\n  model.add(res_base)\n  model.add(layers.Flatten())\n  model.add(layers.Dense(512, activation='relu'))\n  model.add(layers.Dropout(0.2))\n  model.add(layers.Dense(256, activation='relu'))\n  model.add(layers.Dense(10, activation='softmax'))\n\n  model.compile(optimizer=optimizer,\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])\n\n  return model","f2427d8a":"%%time\n\nmodel_res22 = make_model22()\n\nhistory_res22= model_res22.fit(\n      trainc_images,\n      trainc_labels,\n      batch_size=100,\n      steps_per_epoch=100,\n      epochs=250,\n      validation_data=(valc_images, valc_labels),\n      validation_steps=50)\n\ntest_loss_res22, test_acc_res22 = model_res22.evaluate(testc_images, testc_labels)","38fc7276":"print('Learning Rate Schedule Model (Exp Decay) @ 250 Epochs Run Time: 15min 25s ')  ","475dbd5e":"#plotting  model performance\n\naccuracy_res22 = history_res22.history['accuracy']\nval_acc_res22 = history_res22.history['val_accuracy']\nloss_res22 = history_res22.history['loss']\nval_loss_res22 = history_res22.history['val_loss']\n\n#Plot 1 - Training vs Validation Loss\n\nepochs_res22 = range(1, len(loss_res22) + 1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs_res22, loss_res22, 'g*', label='Training Loss')\nplt.plot(epochs_res22, val_loss_res22, 'r', label='Validation Loss')\nplt.title('Cifar10 ResNet50 w Exp Decy @ 250 Epochs - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n#Plot 2 - Training vs Validation Accuracy\n\nepochs1_res22 = range(1, len(accuracy_res22) +1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs1_res22, accuracy_res22, 'g*', label='Training Accuracy')\nplt.plot(epochs1_res22, val_acc_res22, 'b', label='Validation Accuracy')\nplt.title('Cifar10 ResNet50 w Exp Decy @ 250 Epochs - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n#printing test loss & accuracy\nprint(\"Our ResNet50 w Exp Decay @250 Epochs Test Loss is: {}\".format(round(test_loss_res22,3)))\nprint(\"Our ResNet50 w Exp Decay @250 Epochs Test Accuracy is: {}\".format(round(test_acc_res22,3)))","227055c7":"from tensorflow.keras import models, layers, optimizers\ninitial_learning_rate = 0.001\n\nlr_schedule = keras.optimizers.schedules.InverseTimeDecay(initial_learning_rate, decay_steps=5000, decay_rate=0.96, staircase=True)\n\noptimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n\ndef make_model23():\n  model = models.Sequential()\n  model.add(res_base)\n  model.add(layers.Flatten())\n  model.add(layers.Dense(512, activation='relu'))\n  model.add(layers.Dropout(0.2))\n  model.add(layers.Dense(256, activation='relu'))\n  model.add(layers.Dense(10, activation='softmax'))\n\n  model.compile(optimizer=optimizer,\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])\n\n  return model","ab8f44a8":"%%time\n\nmodel_res23 = make_model23()\n\nhistory_res23= model_res23.fit(\n      trainc_images,\n      trainc_labels,\n      batch_size=100,\n      steps_per_epoch=100,\n      epochs=250,\n      validation_data=(valc_images, valc_labels),\n      validation_steps=50)\n\ntest_loss_res23, test_acc_res23 = model_res23.evaluate(testc_images, testc_labels)","cb8b1146":"print('Learning Rate Schedule Model (Inv Decay) @ 250 Epochs Run Time: 15 min 29s ')  ","993d3c08":"#plotting  model performance\n\naccuracy_res23 = history_res23.history['accuracy']\nval_acc_res23 = history_res23.history['val_accuracy']\nloss_res23 = history_res23.history['loss']\nval_loss_res23 = history_res23.history['val_loss']\n\n#Plot 1 - Training vs Validation Loss\n\nepochs_res23 = range(1, len(loss_res23) + 1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs_res23, loss_res23, 'g*', label='Training Loss')\nplt.plot(epochs_res23, val_loss_res23, 'r', label='Validation Loss')\nplt.title('Cifar10 ResNet50 w Inv Decay @ 250 Epochs - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n#Plot 2 - Training vs Validation Accuracy\n\nepochs1_res23 = range(1, len(accuracy_res23) +1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs1_res23, accuracy_res23, 'g*', label='Training Accuracy')\nplt.plot(epochs1_res23, val_acc_res23, 'b', label='Validation Accuracy')\nplt.title('Cifar10 ResNet50 w Inv Decay @ 250 Epochs - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n#printing test loss & accuracy\nprint(\"Our ResNet50 w LR Schedule Test Loss is: {}\".format(round(test_loss_res23,3)))\nprint(\"Our ResNet50 w LR Schedule Test Accuracy is: {}\".format(round(test_acc_res23,3)))","d47f93f7":"from tensorflow.keras import models, layers, optimizers\ninitial_learning_rate = 0.001\n\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=5000, decay_rate=0.96, staircase=True)\n\noptimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n\ndef make_model24():\n  model = models.Sequential()\n  model.add(res_base)\n  model.add(layers.Flatten())\n  model.add(layers.Dense(512, activation='relu'))\n  model.add(layers.Dropout(0.2))\n  model.add(layers.Dense(256, activation='relu'))\n  model.add(layers.Dense(10, activation='softmax'))\n\n  model.compile(optimizer=optimizer,\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])\n\n  return model","52e2342a":"%%time\n\nmodel_res24 = make_model24()\n\nhistory_res24= model_res24.fit(\n      trainc_images,\n      trainc_labels,\n      batch_size=100,\n      steps_per_epoch=100,\n      epochs=100,\n      validation_data=(valc_images, valc_labels),\n      validation_steps=50)\n\ntest_loss_res24, test_acc_res24 = model_res24.evaluate(testc_images, testc_labels)","fde0fa14":"print('Learning Rate Schedule Model (Exp Decay) @ 100 Epochs Run Time: 6 min 18 s ')  ","99e2be62":"#plotting  model performance\n\naccuracy_res24 = history_res24.history['accuracy']\nval_acc_res24 = history_res24.history['val_accuracy']\nloss_res24 = history_res24.history['loss']\nval_loss_res24 = history_res24.history['val_loss']\n\n#Plot 1 - Training vs Validation Loss\n\nepochs_res24 = range(1, len(loss_res24) + 1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs_res24, loss_res24, 'g*', label='Training Loss')\nplt.plot(epochs_res24, val_loss_res24, 'r', label='Validation Loss')\nplt.title('Cifar10 ResNet50 w Exp Decay @ 100 Epochs - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n#Plot 2 - Training vs Validation Accuracy\n\nepochs1_res24 = range(1, len(accuracy_res24) +1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs1_res24, accuracy_res24, 'g*', label='Training Accuracy')\nplt.plot(epochs1_res24, val_acc_res24, 'b', label='Validation Accuracy')\nplt.title('Cifar10 ResNet50 w Exp Decay @ 100 Epochs - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n#printing test loss & accuracy\nprint(\"Our ResNet50 w LR Schedule Test Loss is: {}\".format(round(test_loss_res24,3)))\nprint(\"Our ResNet50 w LR Schedule Test Accuracy is: {}\".format(round(test_acc_res24,3)))","665e8c68":"from tensorflow.keras import models, layers, optimizers\n\n#Option 2 - Lookahead Optimizer       \nimport tensorflow_addons as tfa\n\nlearning_rate = 0.001\n\nopt = tf.keras.optimizers.Adam(learning_rate)\nopt = tfa.optimizers.Lookahead(opt)\n\ndef make_model3():\n  model = models.Sequential()\n  model.add(res_base)\n  model.add(layers.Flatten())\n  model.add(layers.Dense(512, activation='relu'))\n  model.add(layers.Dropout(0.2))\n  model.add(layers.Dense(256, activation='relu'))\n  model.add(layers.Dense(10, activation='softmax'))\n\n  model.compile(optimizer=opt,\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])\n\n  return model\n\nmodel_res3 = make_model3()\nmodel_res3.summary()                               ","2b89ef10":"%%time\n\nhistory_res3= model_res3.fit(\n      trainc_images,\n      trainc_labels,\n      batch_size=100,\n      steps_per_epoch=100,\n      epochs=500,\n      validation_data=(valc_images, valc_labels),\n      validation_steps=50, shuffle=True)\n\ntest_loss_res3, test_acc_res3 = model_res3.evaluate(testc_images, testc_labels)","c463eccb":"print('Lookahead Optimer Model Run Time: 49min 45s ')","16fef8fb":"#plotting  model performance\n\naccuracy_res3 = history_res3.history['accuracy']\nval_acc_res3 = history_res3.history['val_accuracy']\nloss_res3 = history_res3.history['loss']\nval_loss_res3 = history_res3.history['val_loss']\n\n#Plot 1 - Training vs Validation Loss\n\nepochs_res3 = range(1, len(loss_res3) + 1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs_res3, loss_res3, 'g*', label='Training Loss')\nplt.plot(epochs_res3, val_loss_res3, 'r', label='Validation Loss')\nplt.title('Cifar10 ResNet50 w Lookahead - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n#Plot 2 - Training vs Validation Accuracy\n\nepochs1_res3 = range(1, len(accuracy_res3) +1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs1_res3, accuracy_res3, 'g*', label='Training Accuracy')\nplt.plot(epochs1_res3, val_acc_res3, 'b', label='Validation Accuracy')\nplt.title('Cifar10 ResNet50 w Lookahead - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n#printing test loss & accuracy\nprint(\"Our ResNet50 w Lookahead Test Loss is: {}\".format(round(test_loss_res3,3)))\nprint(\"Our ResNet50 w Lookahead Test Accuracy is: {}\".format(round(test_acc_res3,3)))","789aeee4":"%%time\n\nhistory_res31= model_res3.fit(\n      trainc_images,\n      trainc_labels,\n      batch_size=100,\n      steps_per_epoch=100,\n      epochs=250,\n      validation_data=(valc_images, valc_labels),\n      validation_steps=50, shuffle=True)\n\ntest_loss_res31, test_acc_res31 = model_res3.evaluate(testc_images, testc_labels)","3530da75":"print('Lookahead Optimizer Model @ 250 Epochs Run Time: 25 min 15s ')","39f05201":"#plotting  model performance\n\naccuracy_res31 = history_res31.history['accuracy']\nval_acc_res31 = history_res31.history['val_accuracy']\nloss_res31 = history_res31.history['loss']\nval_loss_res31 = history_res31.history['val_loss']\n\n#Plot 1 - Training vs Validation Loss\n\nepochs_res31 = range(1, len(loss_res31) + 1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs_res31, loss_res31, 'g*', label='Training Loss')\nplt.plot(epochs_res31, val_loss_res31, 'r', label='Validation Loss')\nplt.title('Cifar10 ResNet50 w Lookahead @ 250 Epochs - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n#Plot 2 - Training vs Validation Accuracy\n\nepochs1_res31 = range(1, len(accuracy_res31) +1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs1_res31, accuracy_res31, 'g*', label='Training Accuracy')\nplt.plot(epochs1_res31, val_acc_res31, 'b', label='Validation Accuracy')\nplt.title('Cifar10 ResNet50 w Lookahead @ 250 Epochs - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n#printing test loss & accuracy\nprint(\"Our ResNet50 w Lookahead Test Loss is: {}\".format(round(test_loss_res31,3)))\nprint(\"Our ResNet50 w Lookahead Test Accuracy is: {}\".format(round(test_acc_res31,3)))","dbef8748":"%%time\n\nhistory_res32= model_res3.fit(\n      trainc_norm,\n      trainc_labels,\n      batch_size=100,\n      steps_per_epoch=100,\n      epochs=100,\n      validation_data=(valc_norm, valc_labels),\n      validation_steps=50, shuffle=True)\n\ntest_loss_res32, test_acc_res32 = model_res3.evaluate(testc_norm, testc_labels)","243f5d35":"print('Lookahead Optimizer Model @ 100 Epochs Run Time: 13min 50s ')","ad46f289":"#plotting  model performance\n\naccuracy_res32 = history_res32.history['accuracy']\nval_acc_res32 = history_res32.history['val_accuracy']\nloss_res32 = history_res32.history['loss']\nval_loss_res32 = history_res32.history['val_loss']\n\n#Plot 1 - Training vs Validation Loss\n\nepochs_res32 = range(1, len(loss_res32) + 1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs_res32, loss_res32, 'g*', label='Training Loss')\nplt.plot(epochs_res32, val_loss_res32, 'r', label='Validation Loss')\nplt.title('Cifar10 ResNet50 w Lookahead @ 100 Epochs - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n#Plot 2 - Training vs Validation Accuracy\n\nepochs1_res32 = range(1, len(accuracy_res32) +1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs1_res32, accuracy_res32, 'g*', label='Training Accuracy')\nplt.plot(epochs1_res32, val_acc_res32, 'b', label='Validation Accuracy')\nplt.title('Cifar10 ResNet50 w Lookahead @ 100 Epochs - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n#printing test loss & accuracy\nprint(\"Our ResNet50 w Lookahead Test Loss is: {}\".format(round(test_loss_res32,3)))\nprint(\"Our ResNet50 w Lookahead Test Accuracy is: {}\".format(round(test_acc_res32,3)))","b8882b3e":"#importing necessary modules for deep learning\n\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport IPython.display\nimport PIL.Image\nimport tensorflow_datasets as tfds\nfrom tensorflow import keras\nfrom tensorflow.keras import models, layers, optimizers\n","922ce46d":"initial_learning_rate = 0.001\n\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=5000, decay_rate=0.96, staircase=True)\n\noptimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.MaxPooling2D(1, 1))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.MaxPooling2D(1, 1))\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu'))\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu'))\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu'))\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.MaxPooling2D(1, 1))\nmodel.add(layers.Conv2D(1024, (3, 3), activation='relu'))\nmodel.add(layers.Conv2D(1024, (3, 3), activation='relu'))\nmodel.add(layers.Conv2D(2048, (3, 3), activation='relu'))\nmodel.add(layers.Conv2D(2048, (3, 3), activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.MaxPooling2D(1, 1))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(1024, activation='relu'))\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(10, activation='softmax'))\n\nmodel.compile(optimizer=optimizer,\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])\n    \n\nmodel.summary()","7fb9d4cd":"%%time\nhistory_novel = model.fit(\n                trainc_norm,\n                trainc_labels,\n                batch_size=100,\n                epochs=300,\n                steps_per_epoch=100,\n                validation_data= (valc_norm, valc_labels),\n                validation_steps=50)\n\ntest_loss_nov, test_acc_nov = model.evaluate(testc_norm, testc_labels)","18c85278":"print('Novel Model Run Time: 1h 27min 56s ')","1fea6420":"#plotting  model performance\n\naccuracy_nov = history_novel.history['accuracy']\nval_acc_nov = history_novel.history['val_accuracy']\nloss_nov = history_novel.history['loss']\nval_loss_nov = history_novel.history['val_loss']\n\n#Plot 1 - Training vs Validation Loss\n\nepochs_nov = range(1, len(loss_nov) + 1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs_nov, loss_nov, 'g*', label='Training Loss')\nplt.plot(epochs_nov, val_loss_nov, 'r', label='Validation Loss')\nplt.title('Novel Model - CIFAR10 - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n#Plot 2 - Training vs Validation Accuracy\n\nepochs1_nov = range(1, len(accuracy_nov) +1)\n\nplt.figure(figsize= (8,8))\nplt.plot(epochs1_nov, accuracy_nov, 'g*', label='Training Accuracy')\nplt.plot(epochs1_nov, val_acc_nov, 'b', label='Validation Accuracy')\nplt.title('Novel Model - CIFAR10 - Training vs Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n#printing test loss & accuracy\nprint(\"Our Novel Model Test Loss is: {}\".format(round(test_loss_nov,3)))\nprint(\"Our Novel Model Test Accuracy is: {}\".format(round(test_acc_nov,3)))","9dc9d237":"## Task 3 Design a novel deep neural network model (Challenge Task for Targeting HD Grades)\n\n*(weight ~11%)*\nHere, you have to show your critical idea to design a new neural network model. We will evaluate your results based on the novelty of the model and performance of the model. ","57cf804b":"**Experiment Results**\n\n **all training times using Google Colab Pro\n\n|Dropout (rate)   |  Optimiser   | Learning Rate  | Number of Epochs  | Run Time  |  Test Accuracy |\n|---|---|---|---|---  |---|\n| 30%   | Exponential Decay |0.001  | 500 | 30 m 16s  | 75.82%\n| 30% | Inverse Time Decay | 0.001   | 500 | 30 m 8s | 75.15%\n| 20%   | Exponential Decay  | 0.001 | 250 |  15 m 25s |76.25%\n| 20% | Inverse Time Decay | 0.001 | 250 | 15m 29s |  75.42%\n| 20% | Exponential Decay | 0.001 | 100 | 6m 18s | 54.5%\n| 20% | Lookahead | 0.001| 500 | 49m 45s | 73.64%\n| 20%| Lookahead | 0.001| 250 | 25m 15s | 72.88%\n| 20%| Lookahead | 0.001| 100| 13 m 50s | 64.2%","3f97d541":"---\n**END OF ASSIGNMENT TWO**","14ec424e":"### Task 1.4 Fashion-MNIST with transfer learning\n\n*(weight ~6%)*\n\nUse a pretrained model as the convolutional base to improve the classification performance. (Hint: You may use models in Keras Applications or those in the TensorFlow Hub.)\n\n- Try both with fine-tuning and without fine-tuning.\n- Report the model performance as before.\n\n","df87c341":"###### Task 2.1 Train a highly accurate network for CIFAR10\n\n*(weight ~6%, each subquestion worths ~2%)*\n\nIn this task, you will train deep neural networks on the [CIFAR10 dataset](https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html). Compared with the datasets that you have worked on so far, CIFAR10 represents a relatively larger multi-class classification problem and presents a great opportunity for you to solve a \"harder\" problem.\n\n","404a83eb":"#### Task 2.1.3 Train a ResNet\n\nTrain a residual neural network (ResNet) on the CIFAR10 training data and report the test accuracy and the training time.\n\nThe ResNet is a popular network architecture for image classification. You may find more information about how ResNet works by reading this [paper](https:\/\/arxiv.org\/abs\/1512.03385).\n\n\n*(You may implement a resnet model or use an existing implementation. In either case, you should not use pretrained network weights.)*","6f06cb82":"**GPU**\n\nModel: NVIDIA-SMI 450.66 Driver Version 418.67 CUDA Version:10.1\n\nNumber of GPUs: 1\n\nMemory: Total Memory 16,280 MB or 16.28 GB","55e1c5f2":"## Task 1 Solving Fashion-MNIST with Convolutional Neural Networks\n\n*(weight ~18%)*\n\nIn Assignment 1, you tackled the image classification problem in Fashion-MNIST. There, you used a Densely Connected Neural Network. You should now know that is not an optimal model architecture for the problem. In Assignment 2, you will apply the best practices of deep-learning computer vision to improve the image classification performance.","927f82af":"\n### Task 1.3 Build an input pipeline for data augmentation\n\n*(weight ~4%)*\n\nBuild a data preprocessing pipeline to perform data augmentation. (You may use Keras ImageDataGenerator or write your own transformations.)\n\n- Report the new classification accuracy. Make sure that you use the same number of training epochs as in Task 1.2.\n\n- (Optional) Profile your input pipeline to identify the most time-consuming operation. What actions have you taken to address that slow operation? (*Hint: You may use the [TensorFlow Profiler](https:\/\/github.com\/tensorflow\/profiler).*)","a4af6049":"### Task 1.2 Train a ConvNet from scratch\n\n*(weight ~2%)*\n\nBuild a ConvNet to replace the densely connected network in Task 1.1. Report the classification accuracy on the test set. Aim to achieve higher accuracy. \n\n","3590183d":"\n\n* Experiment - Examining the Effect of Learning Rate Schedule vs Lookahead Optimizers on Training Time & Test Accuracy \n\nFor this experiment, a learning rate schedule will be introduced into our model - with the primary experiement looking at how our model performance, particularly our test accuracy, is affected when running the model over varying periods of time (epochs), adjusting drop out rates, and using two different learning rate schedules\n\n\n","8c37d1a4":"**CPU**\n\nModel: Intel(R) Xeon(R) CPU @ 2.30GHz, Model 63\n\nNumber of CPUs: 4\n\nClock Speed: 2299.998 MHz","cf3a2961":"#### Task 2.1.2 Train a \"shallow\" ConvNet\n\nBuild a ConvNet with fewer than 10 layers. Train the network until it converges. You will use this network as a baseline for the later experiments. \n\n- Plot the training and validation history. \n- Report the testing accuracy. ","199ac189":"#### Task 2.1.1 Document the hardware used\n\nBefore you start, write down your hardware specifications, including \n\n- the GPU model, the number of GPUs, and the GPU memory\n- the CPU model, the number of CPUs, and the CPU clock speed\n\n(Hint: you may find commands like `nvidia-smi`, `lscpu` or `psutil` useful.)","ff8e6534":"### Task 3.1: The key idea to design a novel deep neural networks for CIFAR10\n\n*(weight ~5%)*\n\nIn this task, you will design a novel deep neural networks on the [CIFAR10 dataset](https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html). CIFAR10 represents a relatively larger multi-class classification problem and presents a great opportunity for you to solve a \"harder\" problem. Different from Task 2, in this task you are required to design a novel neural network and optimize the performance in classification. In your answer, you have to clearly present what the key difference between your model and the classic ones, what the benefits in your design model.","b9f423af":"### Task 2.2 Fast training of ResNet\n\n*(weight ~5%)*\n\nIn this task, you will experiment with different ways to reduce the time for training your ResNet on CIFAR10. There are different ways to speed up neural network training; below are two ideas. Please select at least one idea to implement. Explain the experiment steps and report the final performance and training time.\n\n#### Option 1. Learning rate schedule\n\nUse a learning rate schedule for the training. Some popular learning rate schedules include \n\n- the Step Decay learning rate (e.g., see [here](https:\/\/github.com\/kuangliu\/pytorch-cifar))\n- [Cyclical learning rates](https:\/\/arxiv.org\/abs\/1506.01186)\n- [The exponential learning rate](https:\/\/openreview.net\/forum?id=rJg8TeSFDH) \n\nAlso Keras provides [some convenient functions](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/optimizers\/schedules) that you can use.\n\n\n#### Option 2. Look ahead optimiser\n\nRead [this paper](https:\/\/arxiv.org\/abs\/1907.08610) and implement the Lookahead optimiser.","6928168c":"**ANSWER:**\n\nThe design of my novel neural network for the CIFAR-10 dataset is based loosely on the VGG19 model architecture, with a number of modifications to the number and contents of the layers.\n\nThe design of my model, is as follows:\n\n\n\n*   Convolutional Input Layer w Relu Activation\n\nBlock 1\n\n\n*   2x Convolutional Layers w Relu Activation\n*   1x Dropout Layer @ 10% dropout\n*   1x Max Pooling 2D Layer\n\nBlock 2\n\n* 2x Convolutional Layers w Relu Activation\n* 1x Dropout Layer @ 10% dropout\n* 1x Max Pooling 2D Layer\n\nBlock 3\n* 4x Convolutional Layers w Relu Activation\n* 1x Batch Normalization Layer\n* 1x Relu Activation Layer\n* 1x Dropout Layer @ 10% dropout\n* 1x Max Pooling 2D Layer\n\nBlock 4\n* 4x Convolutional Layers w Relu Activation\n* 1x Batch Normalization Layer\n* 1x Relu Activation Layer\n* 1x Dropout Layer @ 10% dropout\n* 1x Max Pooling 2D Layer\n\nBlock 5\/Output Block\n* 1x Flatten Layer\n* 2x Dense Layers w Relu Activation\n* 1x Dense Output Layer w 10 classes and Softmax Activation\n\nThe differences in my model, compared to the classical models for CNN and DNN training, is the additional of dropout layers after the convolutional layer in Blocks 1 & 2 and the addition of dropout layers after the batch normalization\/activation layers in Blocks 3 & 4.\n\nThe use of dropout layers is not uncommon in the classical architectures, however the use of dropouts after convolutional or batch normalization layers is not common.\n\nWhilst not conventional, this article points to studies that have had some success with training neural networks using dropout after convolutional layers.\n\nhttps:\/\/towardsdatascience.com\/dropout-on-convolutional-layers-is-weird-5c6ab14f19b2 \n\nThis article equates the use of dropout to injecting noise into the model, and whilst it is experimental it will be interesting to see the results of this different modelling architecture.\n\n\n\n","634ec028":"### Task 3.2: The implementation of the novel deep neural networks for CIFAR10\n\n*(weight ~6%)*\n\nIn this task, it requires you to write the codes for model implementation and report the performance. In your results, you have to demonstrate the compared performance of your new model and the state-of-the-art models.","ff7082e7":"**Performance Comparison**\n\nAs we can see, the novel model I designed has not performed as well as the models we have utilized previously in this assignment.\n\nOur VGG19 model, admittedly used on a less complex dataset in the Fashion-MNIST dataset, performed to a higher level, with an 84% accuracy for a non-fine tuned model and a 90% accuracy for a fine tuned model.\n\nOn the CIFAR-10 dataset, we used the ResNet50 model, which outperformed my novel model modestly in terms of test accuracy, but significantly in terms of model run time.\n\nFor example, my model ran for just over 1 hour and 27 minutes, finishing with a test accuracy of 69.5%.\n\nThe state of the art ResNet50 model achieved a training accuracy of 75.83% in 30 minutes and 16 seconds and an even more impressive training accuracy of 76.25% in 15 minutes and 25 seconds, using an Exponential Decay Learning Rate.\n\nWhilst my model certainly can't challenge some of the classic and state of the art CNN architectures, it was a model designed to be fundamentally different in it's design.","b4cddd25":"### Task 2.3 Performance comparison\n\n*(weight ~5%)*\n\nBased on the above experiments, which method or which combination of methods result in the best accuracy with the same training time.\n\n**ANSWER:**\n\nBased on our experiments above, our optimal models in terms of training time and test accuracy are our 'Decay' or 'Learning Rate' optimized models - specifically the models with the below optimization techniques:\n\nIt is important to note that I did not apply data augmentation to our ResNet model as the performance of the pre-trained ResNet50 model suffered by 0-5% when augmentation was applied.\n\n\n*   Exponential Decay Learning Schedule\n*   Inverse Decay Learning Schedule\n\nWhilst we achieved comparable accuracy with our Lookahead optimization, the run time (when compared by running for the same number of Epochs) is significantly longer for no gain.\n\nIn additional, from the experiment above it is clear that there is no tangible benefit in running either of the designed Learning Schedule Models (Exponential Decay or Inverse Decay), for more than 250 Epochs on the CIFAR-10 dataset.\n\nIndeed, our Learning Schedule models running for 250 Epochs outperformed our Lookahead model at both the 250 and 500 Epoch mark.\n\nAll of our models clearly outperformed the 'Shallow' Convolution Network we trained in Tast 2.1.2, wich had a test accuracy of 59%.\n\nOur best performing model, was an Exponential Decay Learning Schedule model trained for 250 Epochs, with a learning rate of 0.001 and a Dropout rate of 20% - with a final test accuracy of 76.25%\n\n\n","a3e4a525":"# SIT744 Assignment 2: Efficient Training of Convolutional Neural Network \n\nThis is an assignment which was completed in Google Colab, the output cells have not yet been re-run in a Kaggle environemnt.","84eb8cf7":"### Task 1.1 Revisit Fashion-MNIST classification with DNN\n\n*(weight ~2%)*\n\nReview your Assignment 1 solution, and reproduce the experiment here. Try to improve the model without changing the model architecture.\n","4fa1ab14":"## Task 2 Fast training of deep networks\n\n*(weight ~16%)*","6d7495a0":"### Task 1.5 Performance comparison\n\n*(weight ~4%)*\n\nRecord the test accuracy achieved at different training configurations above. Which method achieved the highest accuracy? Why did it work better for this problem?\n\n\n|Model Type| Test Accuracy|\n|----------|--------------|\n|   Dense Neural Network       |      89.44%        |\n|   Convolutional Neural Network       |     89.31%         |\n|   Augmented CNN      |      89.32%        |\n|   Transfer Learning (VGG19)                  |      84.10%         |\n|   Tuned Transfer Learning (VGG19) |  90.23%           |\n\n**ANSWER:**\n\nThe test accuracies garned above, show that all of the models designed for the Fashion-MNIST dataset are operating at a high level and have high test accuracy - with all being above 84%.\n\nWe can see that there is no significant difference between the implementations of DNN vs various CNN, likely due to the fact that this is a less complex set of images - confined to 'grayscale' features.\n\nThe optimal model was our transfer learned VGG19 model, with fine tuning on the 5th block, at 90.23%. Transfer learning a CNN with fine tuning worked best for this problem as it draws upon previous modelling work that has been completed to a high level, and tunes the model to improve the performance further again.\n\nIn addition, it is no surprise that a CNN model has outperformed a DNN model (even if only slightly) as CNN models generally perform to a higher level for image classification.\n"}}