{"cell_type":{"a9f1238b":"code","d5729cb5":"code","c4707dca":"code","4cb5db51":"code","510e87fa":"code","fc449751":"code","65c8161f":"code","54ba96fa":"code","7218b44b":"code","a63e8717":"code","e49ecfcf":"code","6664c4c7":"code","6d2e8479":"code","c6cd7188":"code","3d09107a":"code","27dbb5f3":"code","c34f9082":"code","fa4422cd":"code","b95ae4dc":"code","52133b29":"code","2037fbfa":"code","a0196104":"markdown","672e376a":"markdown","f7f175bb":"markdown","f123875e":"markdown","d334f239":"markdown","bd1d6c98":"markdown","79ccc8be":"markdown","980aa34a":"markdown","31edd57a":"markdown","30069862":"markdown","129e3d45":"markdown","74f7d108":"markdown"},"source":{"a9f1238b":"# Add your PRIVATE credentials\n# Do not use \"!export KAGGLE_USERNAME= ...\" OR \"\" around your credential\n%env KAGGLE_USERNAME=''\n%env KAGGLE_KEY=''\n\n# Verify\n!export -p | grep KAGGLE_USERNAME\n!export -p | grep KAGGLE_KEY","d5729cb5":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c4707dca":"## Cargar archivos de la competencia","4cb5db51":"import pandas as pd\nimport numpy as np\n\ndf = pd.read_csv('\/kaggle\/input\/tp-n2-aprendizaje-profundo-2021-by-datitos-v2\/fifa2021_training.csv')\ndf_infer = pd.read_csv('\/kaggle\/input\/tp-n2-aprendizaje-profundo-2021-by-datitos-v2\/fifa2021_test.csv')","510e87fa":"df.iloc[0]","fc449751":"from sklearn.model_selection import train_test_split\n\ndf_train, df_valid = train_test_split(df, stratify=df.Position, train_size=0.9, random_state=42)","65c8161f":"from sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import make_column_transformer\n\nvariables_descartar = [\n   'Position', # variable objetivo\n    'ID',\n    'Name',\n    'Natinality',\n    'Potential',\n    'BirthDate',\n    'Value',\n    'Wage',\n    'Club',\n    'Club_KitNumber',\n    'Club_JoinedClub',\n    'Club_ContractLength',\n]\n\nvariables_categ\u00f3ricas = df.drop(columns=variables_descartar).select_dtypes(include=np.object).columns\nvariables_num\u00e9ricas   = df.drop(columns=variables_descartar).select_dtypes(include=np.number).columns\n\ntransformador = make_column_transformer(\n    (OneHotEncoder(handle_unknown='ignore'),  variables_categ\u00f3ricas), # PreferredFoot, PlayerWorkRate, Sex resolver nacionalidad con handle_unknown='ignore' Eso trae otro probl despues, asi q por ahora vamos con eliminar los dos paises q me joden\n    (StandardScaler(), variables_num\u00e9ricas),   # Overal, Potential, Height, etc.\n    remainder='drop' # descarta las columnas no mencionadas en las transformaciones\n)","54ba96fa":"transformador.fit(df_train)","7218b44b":"# Se agrega la columna a predecir en el dataset para que tenga las mismas columnas que df_train :\/  \ndf_infer['Position'] = None\n\n\nX_train = transformador.transform(df_train)\nX_valid = transformador.transform(df_valid)\nX_infer = transformador.transform(df_infer)","a63e8717":"from sklearn.preprocessing import LabelEncoder\n\ntransformador_etiquetas = LabelEncoder()\n\ntransformador_etiquetas.fit(df_train.Position)\n\ny_train = transformador_etiquetas.transform(df_train.Position)\ny_valid = transformador_etiquetas.transform(df_valid.Position)","e49ecfcf":"from torch.utils.data import Dataset\n\nclass Tabular(Dataset):\n    def __init__(self, X, y=None):\n        self.X = X.astype(np.float32) # soluciona \"Expected object of scalar type Float but got scalar type Double\"\n        self.y = y \n\n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, item):\n        if self.y is None:\n            return self.X[item]\n        else:\n            return self.X[item], self.y[item]\n\n        \nds_train = Tabular(X_train, y_train)","6664c4c7":"ds_train[10]","6d2e8479":"from torch.utils.data import DataLoader\n\ndl_train = DataLoader(ds_train, batch_size=32, shuffle=False)","c6cd7188":"import torch\nX_valid = torch.tensor(X_valid).float()\nX_infer = torch.tensor(X_infer).float()\ny_valid = torch.tensor(y_valid)","3d09107a":"import torch\nimport torch.nn as nn","27dbb5f3":"IN  = X_train.shape[1]\nOUT = len(transformador_etiquetas.classes_)\n\nmodelo = nn.Sequential(\n    nn.Linear(IN,  8),\n    nn.Linear( 8, 64), nn.ReLU(),\n    nn.Linear(64, 32), nn.ReLU(), \n    nn.Linear(32, OUT)\n)","c34f9082":"weights = torch.tensor([0.2,0.2,0.2,0.2], dtype=torch.float)\n\ncriterio = nn.CrossEntropyLoss(weight=weights) #weight=weights \noptimizador = torch.optim.Adam(modelo.parameters(), lr=0.01)","fa4422cd":"from sklearn.metrics import balanced_accuracy_score\n\n\u00c9POCAS = 10\n\nfor \u00e9poca in range(\u00c9POCAS):\n    # activa capas Dropout, BatchNorm si las hubiese\n    modelo.train()\n\n    p\u00e9rdidas_train = []\n    \n    for X_lote, y_lote in dl_train:\n        optimizador.zero_grad()\n\n        predicciones = modelo(X_lote)\n        p\u00e9rdida = criterio(predicciones, y_lote)\n\n        p\u00e9rdida.backward()\n        optimizador.step()\n        \n        p\u00e9rdidas_train.append(p\u00e9rdida.item())\n    \n    # desactiva capas Dropout, BatchNorm si las hubiese\n    modelo.eval()\n    \n    with torch.no_grad():\n        predicciones = modelo(X_valid)\n        p\u00e9rdida = criterio(predicciones, y_valid)\n        \n        y_pred = predicciones.argmax(dim=1) # selecciona la clase con mayor probabilidad\n        \n        efectividad = balanced_accuracy_score(y_valid, y_pred)\n    \n    \n    print(f'{\u00e9poca:3d}  |  Train loss: {np.mean(p\u00e9rdidas_train):.3f}    Valid loss: {p\u00e9rdida:.3f}    Valid accuracy: {efectividad:.2f}')\ncriterio = nn.CrossEntropyLoss(weight=weights) \noptimizador = torch.optim.Adam(modelo.parameters(), lr=0.0001)","b95ae4dc":"with torch.no_grad():\n    y_infer = modelo(X_infer).argmax(dim=1)\n\ndf_infer['Position'] = transformador_etiquetas.inverse_transform(y_infer)\n\n(\n    df_infer[['ID', 'Position']]\n    .rename(columns={'ID':'Id', 'Position':'Category'})\n    .to_csv('submit.csv', index=False)\n)","52133b29":"#!pip install kaggle","2037fbfa":"#!kaggle competitions submit -c tp-n2-aprendizaje-profundo-2021-by-datitos-v2 -f submit.csv -m \"Ultimo submit!\"","a0196104":"Transformar variable objetivo\n\nComo la variable objetivo es del tipo string, hay que llevarla a un tipo num\u00e9rico para que PyTorch pueda procesarla.\n\nEste transformador mapea posiciones DEF, FWD, GK, MID a enteros y viceversa \u2014 la transformaci\u00f3n inversa ser\u00e1 \u00fatil para convertir las predicciones (enteros) en posiciones otra vez.","672e376a":"Transformar datasets","f7f175bb":"An\u00e1lisis exploratorio del dataset","f123875e":"\nEntrenar transformador\n\nEsencialmente, calculamos los promedios y las desviaciones est\u00e1ndares que usaremos para la estandarizaci\u00f3n.\n\n SOLO PARA EL DATASET DEtransformador.fit(df_train) ENTRENAMIENTO.","d334f239":"Definir transformaciones y columnas a utilizar","bd1d6c98":"### Entrenar Modelo","79ccc8be":"Instanciar Datasets de PyTorch\n\nEl aprendizaje profundo es especialmente efectivo para im\u00e1genes y texto; para datos tabulares (como un DataFrame) el aprendizaje de m\u00e1quinas cl\u00e1sico suele funcionar bastante bien, de ah\u00ed que PyTorch no cuente con facilidades para tratar este tipo de problemas.","980aa34a":"Instanciar DataLoaders de PyTorch","31edd57a":"### Inferir datos de prueba","30069862":"Obtener la ruta de los datasets","129e3d45":"Instanciar modelo","74f7d108":"Particionar datasets"}}