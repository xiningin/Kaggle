{"cell_type":{"180681b0":"code","35e3eda3":"code","adbd8a12":"code","33f856a2":"code","7b1885cd":"code","0649b441":"code","c2fd5162":"code","69c1dfa9":"code","7bc3ad5c":"code","2dea9d08":"code","e83200b8":"markdown","ff81e1d2":"markdown","e65da848":"markdown","b2d96648":"markdown","0514c955":"markdown","36cd1e36":"markdown","5df35ce0":"markdown"},"source":{"180681b0":"# !pip download finta -d .\/finta\/\n\n# import os\n# from zipfile import ZipFile\n\n# dirName = \".\/finta\/\"\n# zipName = \"finta.zip\"\n\n# # Create a ZipFile Object\n# with ZipFile(zipName, 'w') as zipObj:\n#     # Iterate over all the files in directory\n#     for folderName, subfolders, filenames in os.walk(dirName):\n#         for filename in filenames:\n#             if (filename != zipName):\n#                 # create complete filepath of file in directory\n#                 filePath = os.path.join(folderName, filename)\n#                 # Add file to zip\n#                 zipObj.write(filePath)","35e3eda3":"!pip install finta --no-index --find-links=file:\/\/\/kaggle\/input\/fin-ta\/finta","adbd8a12":"# Import packages \nimport os \nimport glob\nimport gc \nimport yaml\nimport math\nimport warnings\nfrom tqdm import tqdm\nfrom functools import reduce\n\nimport pandas as pd\nfrom finta import TA\nfrom numba import jit  \nimport numpy as np \nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nfrom joblib import Parallel, delayed\n\n# Configuration \nwarnings.simplefilter('ignore')\npd.set_option('max_column', 300)","33f856a2":"# Variable definitions\nDATA_PATH = \"..\/input\/optiver-realized-volatility-prediction\"\n__DATA_DIRS__ = ['book_train.parquet', \n                 'trade_tarin.parquet', \n                 'book_test.parquet', \n                 'trade_test.parquet']\nFILE_LIST_MAP = {\n    'book_train': glob.glob(os.path.join(DATA_PATH, \"book_train.parquet\/*\")),\n    'trade_train': glob.glob(os.path.join(DATA_PATH, \"trade_train.parquet\/*\")), \n    'book_test': glob.glob(os.path.join(DATA_PATH, \"book_test.parquet\/*\")), \n    'trade_test': glob.glob(os.path.join(DATA_PATH, \"trade_test.parquet\/*\"))\n}\nORDER_PRICE = ['bid_price1', 'bid_price2', 'ask_price1', 'ask_price2']\nORDER_VOLUME = ['bid_size1', 'bid_size2', 'ask_size1', 'ask_size2']\nTI_NAMES = [func for func in dir(TA) if callable(getattr(TA, func)) and not func.startswith(\"_\")]","7b1885cd":"# Utility functions \ndef get_wap(df_book):\n    '''Compute estimated price series.\n    \n    Parameters:\n        df_book: pd.DataFrame, raw information of book data\n    \n    Return: \n        wap: pd.DataFrame, estimated price series with time identifiers\n    '''\n    df_book_ = df_book.copy()\n    df_book_['wap1'] = ((df_book_['bid_price1']*df_book_['ask_size1'] + \n                        df_book_['ask_price1']*df_book_['bid_size1']) \/\n                        (df_book_['bid_size1'] + df_book_['ask_size1']))\n    wap = df_book_.loc[:, ['time_id', 'seconds_in_bucket', 'wap1']]\n    return wap\n\ndef get_ohlcv(prices, volumes, scale=10):\n    '''Return OHLCV of stock price based on the Kline scale (sec).\n    \n    Parameters:\n        prices: pd.Series, the estimated price series\n        volumes: pd.Series, the trading volume series\n        scale: int, the scale of the Kline (sec), default=10\n        \n    Return:\n        OHLCV: pd.DataFrame, four prices and trading volumes of the stock based on the Kline scale \n    '''\n    if 600%scale != 0:\n        raise ValueError(\"Choose scale divisible by 600 seconds...\")\n    \n    OHLCV = pd.DataFrame(columns=['open', 'high', 'low', 'close', 'volume'])\n    for i in range(0, 600, scale):\n        p_window = prices[i:i+scale]\n        v_window = volumes[i:i+scale]\n        p_stick = {\n            'open': p_window.iloc[0],\n            'high': np.max(p_window),\n            'low': np.min(p_window),\n            'close': p_window.iloc[-1],\n            'volume': np.sum(v_window),\n        }\n        OHLCV = OHLCV.append(p_stick, ignore_index=True)\n    OHLCV.insert(0, column='sec', value=[scale*(i+1) for i in range(0, 600\/\/scale)])\n    \n    return OHLCV\n\ndef ffill(df):\n    '''Forward fill information in order book data, followed by bfill to avoid bug in filler data.\n    '''\n    df_ = df.copy()\n    df_.set_index(['time_id', 'seconds_in_bucket'], inplace=True)\n    df_ = df_.reindex(pd.MultiIndex.from_product([df_.index.levels[0], np.arange(0,600)], names = ['time_id', 'seconds_in_bucket']), method='ffill')\n    df_ = df_.reindex(pd.MultiIndex.from_product([df_.index.levels[0], np.arange(0,600)], names = ['time_id', 'seconds_in_bucket']), method='bfill')\n    df_.reset_index(inplace=True)\n    \n    return df_","0649b441":"df_order = pd.read_parquet(os.path.join(DATA_PATH, \"book_train.parquet\/stock_id=0\/\"))\ndf_trade = pd.read_parquet(os.path.join(DATA_PATH, \"trade_train.parquet\/stock_id=0\/\"))\ndf_order = df_order[df_order['time_id'] == 5]\ndf_order = ffill(df_order)\ndf_trade = df_trade[df_trade['time_id'] == 5]\ndf_order.head()","c2fd5162":"wap = get_wap(df_order)\ndf = wap.merge(df_trade.loc[:, ['seconds_in_bucket', 'size']], on=['seconds_in_bucket'], how='outer')\ndf.fillna(0, inplace=True)\nohlcv = get_ohlcv(df['wap1'], df['size'], scale=10)\n\nfig = make_subplots(rows=2, cols=1, shared_xaxes=True)\nfig.add_trace(go.Candlestick(\n    x=ohlcv['sec'],\n    open=ohlcv['open'], \n    high=ohlcv['high'],\n    low=ohlcv['low'], \n    close=ohlcv['close']),\n    row=1, col=1\n)\nfig.add_trace(go.Bar(\n    x=ohlcv['sec'], \n    y=ohlcv['volume']),\n    row=2, col=1\n)\n\nfig.update(layout_xaxis_rangeslider_visible=False)\nfig.show()","69c1dfa9":"def get_dataset(datatype, n_jobs, scale):\n    '''Return processed dataset after running parallel dataset generation.\n    \n    Parameters:\n        datatype: str, dataset type, the choices are as follows:\n            {'train', 'test'}\n        n_jobs: int, num of processors to work\n        scale: int, the scale of the Kline (sec)\n    \n    Return:\n        df_proc: pd.DataFrame, dataset containing derived technical indicators\n    '''\n    df_proc = Parallel(n_jobs=n_jobs)(\n        delayed(gen_dataset)(book_file, \n                             trade_file,  \n                             scale) \n        for book_file, trade_file in tqdm(\n            zip(sorted(FILE_LIST_MAP[f'book_{datatype}']), sorted(FILE_LIST_MAP[f'trade_{datatype}']))\n        )\n    )    \n\n    df_proc = pd.concat(df_proc, ignore_index=True)\n\n    return df_proc\n\ndef gen_dataset(book_file, trade_file, scale):\n    '''Generate dataset for one stock.\n    \n    Parameters:\n        book_file: str, file path of the book data \n        trade_file: str, file path of the trade data\n        scale: int, the scale of the Kline (sec)\n    '''\n    assert book_file.split('=')[1] == trade_file.split('=')[1]\n    stock_id = book_file.split('=')[1]\n    df_book = pd.read_parquet(book_file)   # Order book dataframe for a single stock\n    df_book = ffill(df_book)\n    df_trade = pd.read_parquet(trade_file)   # Trade dataframe for a single stock \n\n    df = get_wap(df_book)\n    df = df.merge(df_trade.loc[:, ['time_id', 'seconds_in_bucket', 'size']], on=['time_id', 'seconds_in_bucket'], how='outer')\n    df.fillna(0, inplace=True)\n    \n    del df_book, df_trade\n    _ = gc.collect()\n    \n    tis = get_tis(df, scale)\n    stats = {col: ['mean', 'median', 'min', 'max', 'std'] for col in tis.columns if col != 'time_id'}\n    df_stats = cal_stats(tis, stats)\n    df_stats['row_id'] = df_stats['time_id'].apply(lambda t: f'{stock_id}-{t}')\n    df_stats['stock_id'] = int(stock_id)\n    print(f\"stock{stock_id} completes~\")\n    \n    return df_stats\n\ndef get_tis(df, scale):\n    '''Compute all technical indicators provided by finta.\n    \n    Parameters:\n        df: pd.DataFrame, book data merged with trade data\n        scale: int, the scale of the Kline (sec) \n    '''\n    tis = pd.DataFrame()\n    for time_id, gp in df.groupby('time_id'):\n        ohlcv_ = get_ohlcv(gp['wap1'], gp['size'], scale=scale)\n        ohlcv_.set_index(pd.DatetimeIndex(ohlcv_['sec']), inplace=True)\n        ohlcv_.drop('sec', axis=1, inplace=True)\n        for ti_name, ti in TIS.items():\n            result = ti(ohlcv_)\n            if type(result) == pd.core.series.Series:\n                result.name = ti_name\n            else:\n                result.columns = [f'{ti_name}_{col}' for col in result.columns]\n            ohlcv_ = ohlcv_.merge(result, right_index=True, left_index=True)\n        ohlcv_['time_id'] = int(time_id)\n        tis = pd.concat([tis, ohlcv_], ignore_index=True)\n    return tis \n\ndef cal_stats(df, ft_stats):\n    '''Calculate specified stats for given dataframe.\n    \n    Parameters:\n        df: pd.DataFrame, dataframe containing raw features\n        ft_stats: dict[str, list], mapping relationship between features and the stats (e.g., mean, median, min, max, std)\n        \n    Return:\n        df_stats: pd.DataFrame, dataframe containing derived stats\n    '''\n    df_ = df.groupby(by=['time_id'])   # Group samples based on time_id\n    df_stats = df_.agg(ft_stats)   # Use numba engine to accelerate stats computation\n    df_stats.columns = ['_'.join(sub_str) for sub_str in df_stats.columns]\n    df_stats.reset_index(inplace=True)\n    \n    return df_stats","7bc3ad5c":"# List all technical indicators, excluding the ones raising errors\n# TIS = {ti: getattr(TA, ti) for ti in TI_NAMES if ti not in ['LWMA', 'VIDYA', 'ALMA', 'MAMA', 'SWI', 'TMF']}\nTIS = {'ADL': getattr(TA, 'ADL')}\nTIS","2dea9d08":"# Try to compute one of the technical indicators\ndf_ti = get_dataset('train', -1, 10)","e83200b8":"### Simple Illustration of Candlestick Chart\n> Following is a simple illustration of OHLCV using `Candlestick` provided by `plotly`.","ff81e1d2":"### Package - `finta`\n#### 1. Download package files\n> In this work, I use a package named `finta` to help me quickly compute the **technical indicators**. In order to use the package in the notebook, I download it first and add the data to the corresponding notebook. Following provides the steps to download the package files:","e65da848":"### TI DataFrame Generation \n> Next, we're going to generate complete dataframe containing **technical indicators** for all (`stock_id`, `time_id`) pairs.","b2d96648":"#### 2. Install the package\n> After adding the data and refreshing, you can use the following command to install the package. Then, we can play around with it.","0514c955":"# OHLCV with Technical Indicators \n> Inspired by the informative [work](https:\/\/www.kaggle.com\/takemi\/ohlc-charts-candlestick-charts), I wrote this notebook to introduce the basic method to get the OHLCV data and derived **technical indicators**, which might be used as new features! Hope this notebook would help!","36cd1e36":"### Issue and Summary\n> The problem I encounter is that the computational time is too long. There are many techniques to speed up the computation, but I don't have much time to optimize the process. Finally, I still hope this notebook could give you some inspiration and help you use these **technical indicators** to get better performance!","5df35ce0":"### Technical Indicator Computation\n> Finally, we can use the built-in functions to compute the **technical indicators**. "}}