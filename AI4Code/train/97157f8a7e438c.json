{"cell_type":{"aec4460e":"code","52ab416d":"code","e78f9767":"code","586a5834":"code","81540b9a":"code","f12010e5":"code","37d01995":"code","0457727d":"code","d3a33bf0":"code","8bebe998":"code","8b4e3d13":"code","388560c8":"code","f439b7ac":"code","7404ee2f":"code","54ce7d6b":"markdown","bde6a0c7":"markdown","ca3497c5":"markdown","3dc565c7":"markdown"},"source":{"aec4460e":"! pip install segmentation_models_pytorch albumentations\n! pip install -U git+https:\/\/github.com\/albu\/albumentations --no-cache-dir\n","52ab416d":"\nimport os\nimport csv\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport itertools\n\nimport cv2\nfrom tqdm.notebook import tqdm\nfrom glob import glob\nfrom PIL import Image\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split, KFold\n\nimport shutil\n\nimport torch\nfrom torch.utils.data import DataLoader,Dataset\nimport torch.nn as nn\nimport albumentations\nimport torchvision \nfrom torchvision import transforms, models\n\nimport random\n\nimport segmentation_models_pytorch as smp\nfrom PIL import Image","e78f9767":"!ls","586a5834":"ROOT = \"\/kaggle\/input\/ultrasound-nerve-segmentation\/\"\ntrainpath = \"\/kaggle\/input\/ultrasound-nerve-segmentation\/train\/\"\ntestpath = \"\/kaggle\/input\/ultrasound-nerve-segmentation\/test\/\"\n\nmasks = [os.path.join(trainpath,i) for i in os.listdir(trainpath) if \"mask\" in i]\nimgs = [i.replace(\"_mask\",\"\") for i in masks]\n\ndf = pd.DataFrame({\"image\":imgs,\"mask\":masks})\n\ndf_train, df_val = train_test_split(df,test_size = 0.15)\nprint(df_train.values.shape)\nprint(df_val.values.shape)","81540b9a":"rows,cols=3,3\nfig=plt.figure(figsize=(10,10))\nfor i in range(1,rows*cols+1):\n    ii = random.randint(0, len(df))\n    fig.add_subplot(rows,cols,i)\n    img_path=df['image'][ii]\n    msk_path=df['mask'][ii]\n    plt.imshow(np.array(Image.open(img_path)), cmap = 'gray')\n    plt.imshow(np.array(Image.open(msk_path)),alpha=0.4, cmap = 'gray')\nplt.show()","f12010e5":"def rle_encoding(x):\n    dots = np.where(x.T.flatten()==1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b+1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\ndef convert_to_tensor(x,**kwargs):\n    return x.transpose(2,0,1).astype(\"float32\")\n\ndef func_for_preprocessing(preprocessing_fn=None):\n    transform = []\n    if preprocessing_fn:\n        transform.append(albumentations.Lambda(image=preprocessing_fn))\n    transform.append(albumentations.Lambda(image=convert_to_tensor))\n    return albumentations.Compose(transform)\n\ndef trainaugs():\n    transform =  [\n                albumentations.Resize(height=224,width=224,interpolation=Image.BILINEAR),\n                albumentations.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0),\n                albumentations.ShiftScaleRotate(rotate_limit=15, shift_limit=0.15, scale_limit=0.2),\n                albumentations.HorizontalFlip(),\n            ]\n    return albumentations.Compose(transform)\n\ndef valaugs():\n    transform = [\n                albumentations.Resize(height=224,width=224,interpolation=Image.BILINEAR),\n            ]\n    return albumentations.Compose(transform)\n\n\nclass GetDataset(Dataset):\n    def __init__(self,imagespath,maskspath,augment=None,preprocess=None):\n        self.imagespath = imagespath\n        self.maskspath = maskspath\n        self.augment = augment\n        self.preprocess = preprocess\n        \n    def __len__(self):\n        return len(self.imagespath)\n    \n    def __getitem__(self,idx):\n        image = cv2.cvtColor(cv2.imread(self.imagespath[idx]),cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(self.maskspath[idx], cv2.IMREAD_GRAYSCALE)\n\n        if self.augment:\n            sample = self.augment(image=image, mask=mask)\n            image,mask = sample['image'],sample['mask']\n        if self.preprocess:\n            sample = self.preprocess(image=image,mask=mask)\n            image,mask = sample['image'],sample['mask']\n\n        mask = (mask \/ 255).astype(np.float32)\n        mask = np.expand_dims(mask, axis=0)\n\n        return image,mask","37d01995":"encoder = \"resnet34\"\nencoder_wts = \"imagenet\"\nactivation = \"sigmoid\"\n\n\nmodel = smp.Unet(encoder_name=encoder,activation=activation,encoder_weights=encoder_wts)\npreprocess_func = smp.encoders.get_preprocessing_fn(encoder,encoder_wts)\n\n\ntraindata = GetDataset(imagespath = df_train['image'].tolist(),\n                            maskspath = df_train['mask'].tolist(),\n                            augment = trainaugs(),\n                            preprocess = func_for_preprocessing(preprocess_func))\n\nvalidationdata = GetDataset(imagespath = df_val['image'].tolist(),\n                            maskspath = df_val['mask'].tolist(),\n                            augment = valaugs(),\n                           preprocess = func_for_preprocessing(preprocess_func))\n\nbatch_size = 16\ntrainloader = DataLoader(traindata,batch_size = batch_size,shuffle=True)\nvalloader = DataLoader(validationdata,batch_size=batch_size,shuffle=False)\n","0457727d":"trainmodel = True\nepochs = 20\ndevice = \"cuda\"\nloss = smp.utils.losses.DiceLoss()\nmetrics = [ smp.utils.metrics.IoU(threshold=0.5) ]\noptimizer = torch.optim.Adam([dict(params=model.parameters(), lr=0.001)])\nlr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n\ntrainepoch = smp.utils.train.TrainEpoch(model,loss=loss,optimizer=optimizer,metrics=metrics,device=device,verbose=True)\nvalidepoch = smp.utils.train.ValidEpoch(model,loss=loss,metrics=metrics,device=device,verbose=True)\n","d3a33bf0":"best_iou_score = 0.0 \ntrain_logs_list, valid_logs_list = [], []\nfor i in range(0,epochs):\n    print('\\nEpoch: {}'.format(i))\n    trainlogs = trainepoch.run(trainloader)\n    validlogs = validepoch.run(valloader)\n    lr_scheduler.step()\n\n    train_logs_list.append(trainlogs)\n    valid_logs_list.append(validlogs)\n    if best_iou_score < validlogs['iou_score']:\n        best_iou_score = validlogs['iou_score']\n        torch.save(model, '.\/best_model.pth')","8bebe998":"train_logs_df = pd.DataFrame(train_logs_list)\nvalid_logs_df = pd.DataFrame(valid_logs_list)\ntrain_logs_df.T","8b4e3d13":"plt.figure(figsize=(10,4))\nplt.plot(train_logs_df.index.tolist(), train_logs_df.iou_score.tolist(),'g-',lw=3, label = 'Train')\nplt.plot(valid_logs_df.index.tolist(), valid_logs_df.iou_score.tolist(),'r-' ,lw=3, label = 'Valid')\nplt.xlabel('Epochs', fontsize=20)\nplt.ylabel('IoU Score', fontsize=20)\nplt.title('IoU Score Plot', fontsize=20)\nplt.legend(loc='best', fontsize=16)\nplt.grid()\nplt.show()\n\nplt.figure(figsize=(10,4))\nplt.plot(train_logs_df.index.tolist(), train_logs_df.dice_loss.tolist(),'g-',lw=3, label = 'Train')\nplt.plot(valid_logs_df.index.tolist(), valid_logs_df.dice_loss.tolist(),'r-' ,lw=3, label = 'Valid')\nplt.xlabel('Epochs', fontsize=20)\nplt.ylabel('Dice Loss', fontsize=20)\nplt.title('Dice Loss', fontsize=20)\nplt.legend(loc='best', fontsize=16)\nplt.grid()\nplt.show()","388560c8":"best_model = torch.load('.\/best_model.pth')\n\ntest_dataset = GetDataset(imagespath = df_val['image'].tolist(),\n                            maskspath = df_val['mask'].tolist(),\n                            augment = valaugs(),\n                           preprocess = func_for_preprocessing(preprocess_func))\n\n\ntest_dataset_vis = GetDataset(imagespath = df_val['image'].tolist(),\n                            maskspath = df_val['mask'].tolist())\n\n\ndef visualize(**images):\n    n = len(images)\n    plt.figure(figsize=(16, 5))\n    for i, (name, image) in enumerate(images.items()):\n        plt.subplot(1, n, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(' '.join(name.split('_')).title())\n        if image.shape[0] == 3:\n            image = image.transpose([1, 2, 0])\n        plt.imshow(image)\n    plt.show()\n\nfor i in range(25):\n    n = np.random.choice(len(test_dataset))\n    \n    image_vis = test_dataset_vis[n][0].astype('uint8')\n    mask_vis = test_dataset_vis[n][1].astype('uint8')\n    image, gt_mask = test_dataset[n]\n    \n    gt_mask = gt_mask.squeeze()\n    \n    x_tensor = torch.from_numpy(image).to(device).unsqueeze(0)\n    pr_mask = best_model.predict(x_tensor)\n    pr_mask = pr_mask.squeeze().cpu().numpy().round()\n\n    kernel = np.ones((5,5),np.uint8)\n    pr_mask_er = cv2.erode(pr_mask,kernel,iterations = 4)\n    pr_mask_er = cv2.dilate(pr_mask_er,kernel,iterations = 4)\n\n    pr_mask = cv2.resize(pr_mask, (580, 420))\n    pr_mask_er = cv2.resize(pr_mask_er, (580, 420))\n\n    mask_vis = mask_vis.squeeze()\n\n    visualize(\n        image=image_vis, \n        ground_truth_mask=mask_vis, \n        predicted_mask=pr_mask,\n        predicted_mask_erosion_with_dilation=pr_mask_er\n    )","f439b7ac":"imgs = [f for f in os.listdir(testpath)]\nimgs = sorted(imgs, key=lambda s: int(s.split('.')[0]))\n\nencodings = []\n\nfor m in tqdm(imgs):\n    x = cv2.imread(os.path.join(testpath, m))\n\n    x = valaugs()(image=x)['image']\n    x = func_for_preprocessing(preprocess_func)(image=x)['image']\n\n    x_tensor = torch.from_numpy(x).to(device).unsqueeze(0)\n    pr_mask = best_model.predict(x_tensor)\n\n    pr_mask = pr_mask.squeeze().cpu().numpy().round().astype(np.uint8)\n    pr_mask = albumentations.Resize(height=420,width=580,interpolation=Image.NEAREST)(image=pr_mask)['image']\n\n    encodings.append(rle_encoding(pr_mask))","7404ee2f":"df_submission = pd.DataFrame(columns=[\"img\", \"pixels\"])\nfor i, encoding in enumerate(encodings):\n    pixels = ' '.join(map(str, encoding))\n    df_submission.loc[i] = [str(i+1), pixels]\n\ndf_submission.to_csv('submission.csv', index=False)","54ce7d6b":"## Test evaluation","bde6a0c7":"## Main","ca3497c5":"## Init","3dc565c7":"## Test best saved model"}}