{"cell_type":{"e811d174":"code","48dcb60c":"code","8637af6a":"code","d6085cd4":"code","c2ff097b":"code","5d469022":"code","39536d21":"code","fd7cc367":"code","ecae29ba":"code","ad283c7b":"code","c85d0d85":"code","525ad8f0":"code","495e2862":"markdown","a2099906":"markdown"},"source":{"e811d174":"!pip3 install beautifulsoup4","48dcb60c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport requests\nimport pprint\nfrom bs4 import BeautifulSoup\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8637af6a":"ndtv = requests.get('https:\/\/www.ndtv.com\/world-news?pfrom=home-ndtv_mainnavgation')","d6085cd4":"#pp = pprint.PrettyPrinter(indent=4)\n#pp.pprint(yahoo.content)","c2ff097b":"page_content = BeautifulSoup(ndtv.content, 'html.parser')","5d469022":"results = page_content.find(id='trending')\nprint(results)","39536d21":"print(results.prettify())","fd7cc367":"#main_content = page_content.find(id='Main')\nheadline = page_content.find_all('p', class_ ='newsCont')","ecae29ba":"print(headline)","ad283c7b":"type(headline)","c85d0d85":"for element in headline:\n    print(element, end=\"\\n\"*2)","525ad8f0":"for element in headline:\n    print(element.text, end=\"\\n\\n\")","495e2862":"## Web Scraping ?\nUsing web scraping we could collect data from other website. We could extract the useful information through data.","a2099906":"#### Using tag Id extract data"}}