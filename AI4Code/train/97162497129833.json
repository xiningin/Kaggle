{"cell_type":{"8ed7ed5d":"code","77ba8429":"code","d9348923":"code","136d9e28":"code","e888b346":"code","acd5edbd":"code","a0741b01":"code","420786ed":"code","8a13d365":"code","fcbeaa79":"code","4ca4225e":"code","b69e6722":"code","262c9525":"code","40cc4636":"code","66403b91":"code","98e40b5f":"code","1259a814":"code","b3f9fd45":"code","2de98ef7":"code","7e7d2f6e":"code","d17bc797":"code","4093fab9":"code","aeba8d8b":"code","1fbafab8":"code","dccbd2cb":"code","2543032a":"code","e942ccb8":"code","c683fb0f":"code","aa32a486":"markdown","602fc837":"markdown","f22c0d84":"markdown","4d8c7aff":"markdown","631493c4":"markdown","ce4e17e4":"markdown","a75fd7e4":"markdown","0dc646de":"markdown","cb0fef63":"markdown"},"source":{"8ed7ed5d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","77ba8429":"# Notebook\u306e\u8868\u793a\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\n# \u4fbf\u5229\u306a\u3082\u306e\nimport tqdm\nimport warnings\nwarnings.simplefilter('ignore')\n\n# \u30c7\u30fc\u30bf\u64cd\u4f5c\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', None)\n\n# \u30c7\u30fc\u30bf\u53ef\u8996\u5316\nimport pandas_profiling as pdp\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\n\n# \u524d\u51e6\u7406\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\n# \u4ea4\u5dee\u691c\u8a3c\nfrom sklearn.model_selection import StratifiedKFold\n\n# \u5b9a\u6570\u306e\u5b9a\u7fa9\nSEED = 2019\nN_FOLDS = 10\n\n# input\u3068\u3057\u3066\u4e0e\u3048\u3089\u308c\u305f\u30d5\u30a1\u30a4\u30eb\u540d\u306e\u4e00\u89a7\u3092\u51fa\u529b\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        ","d9348923":"import numpy as np\nimport pandas as pd\npd.options.display.max_columns = 200\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\nfrom sklearn.model_selection import train_test_split#\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30e2\u30c7\u30eb\u8a55\u4fa1\u7528\u30c7\u30fc\u30bf\u306b\u5206\u3051\u308b\u30e9\u30a4\u30d6\u30e9\u30ea\n\nfrom tqdm import tqdm_notebook as tqdm\n\n#\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u81ea\u52d5\u5316\u30e9\u30a4\u30d6\u30e9\u30ea\nimport optuna\n \n#\u95a2\u6570\u306e\u51e6\u7406\u3067\u5fc5\u8981\u306a\u30e9\u30a4\u30d6\u30e9\u30ea\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score","136d9e28":"#\u5404\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\ntrain = pd.read_csv('..\/input\/machine-learning-homework\/train.csv')\ncity_info = pd.read_csv('..\/input\/machine-learning-homework\/city_info.csv')\ndata_dictionary = pd.read_csv('..\/input\/machine-learning-homework\/data_dictionary.csv')\nstation_info = pd.read_csv('..\/input\/machine-learning-homework\/station_info.csv')\ntest = pd.read_csv('..\/input\/machine-learning-homework\/test.csv')\n","e888b346":"#\u30c7\u30fc\u30bf\u306e\u884c\u5217\u6570\u3092\u8868\u793a\nprint(train.shape)\nprint(test.shape)\nprint(city_info.shape)\nprint(station_info.shape)","acd5edbd":"#train\u3068test\u3092concat\u3067\u7d50\u5408\u3057\u3066data\u3092\u4f5c\u308b\ndata = pd.concat([train, test], sort = False)\nprint(data.shape)","a0741b01":"#data\u306bcity_info\u306e\u7d4c\u7def\u306e\u5217\u3092\u8ffd\u52a0\u3059\u308b\ncity_info =city_info.drop(['Prefecture'], axis =1)\ncity_info.columns = ['Municipality', 'Municipality_Latitude', 'Municipality_Longitude'] \ndata = pd.merge(data, city_info, how = 'left', on = 'Municipality' )\nprint(data.shape)","420786ed":"#data\u306bStation\u306e\u7d4c\u7def\u3092\u8ffd\u52a0\nstation_info.columns = ['NearestStation', 'Station_Latitude', 'Station_Longitude']\ndata = pd.merge(data, station_info, how = 'left', on = 'NearestStation')\nprint(data.shape)","8a13d365":"#\u6771\u4eac\u99c5\u304b\u3089\u306e\u99c5\u306e\u8ddd\u96e2(km)\u306e\u5217\u3092\u8ffd\u52a0\nTokyo_Station = [35.68124, 139.7671]\ndata['station_dist_from_Tokyo'] = ((data['Station_Latitude']-Tokyo_Station[0])**2 + (data['Station_Longitude']-Tokyo_Station[1])**2)**0.5*111\ndata.shape","fcbeaa79":"#\u6771\u4eac\u99c5\u304b\u3089\u306e\u753a\u306e\u8ddd\u96e2(km)\u306e\u5217\u3092\u8ffd\u52a0\nTokyo_Station = [35.68124, 139.7671]\ndata['city_dist_from_Tokyo'] = ((data['Municipality_Latitude']-Tokyo_Station[0])**2 + (data['Municipality_Longitude']-Tokyo_Station[1])**2)**0.5*111\ndata.shape","4ca4225e":"#TimeToNearestStation\u3092\u6570\u5024\u306b\u5909\u66f4\n\nreplace_dict = {\n    '30-60minutes':30, '1H-1H30':60, '2H-':120, '1H30-2H':90}\ndata.TimeToNearestStation.replace(replace_dict, inplace=True)\ndata.TimeToNearestStation.replace(replace_dict, inplace=True)\n\ndata.TimeToNearestStation = data.TimeToNearestStation.astype(float)","b69e6722":"#\u30d6\u30fc\u30eb\u578b\u3092\u542b\u3080\u5217\u3092\u6570\u5024\uff080\u30011\uff09\u306b\u7f6e\u304d\u63db\u3048\n\ndata['Renovation'].replace(['Not yet','Done'], [0, 1], inplace = True)\ndata['FrontageIsGreaterFlag'].replace([True,False], [1, 0], inplace = True)","262c9525":"#\u7bc9\u5e74\u6570\u306e\u5217\u3092\u8ffd\u52a0\nthis_year = 2020\ndata['Build_year'] = this_year - data['BuildingYear']\ndata.shape","40cc4636":"#\u7bc9\u5e74\u6570\u306e\u9006\u6570\u5217\u3092\u8ffd\u52a0\ndata['1\/Build_year'] = 1\/data['Build_year'] \ndata.shape","66403b91":"#\u30ab\u30c6\u30b4\u30ea\u5909\u6570\u3092\u542b\u3080\u5217\u3092\u6570\u5024\u306b\u7f6e\u304d\u63db\u3048_count_Encoding\ncats = []\n\nfor col in data.columns:\n    if data[col].dtype == 'object': #dtype\u304cobject\u306e\u30e2\u30ce\u3092\u5bfe\u8c61\u306b\u3057\u3066\u3044\u308b\n        cats.append(col) #append\u306f\u30ea\u30b9\u30c8\u3078\u306e\u8ffd\u52a0\n        \ncats\n","98e40b5f":"for i in cats:\n    data[i] = data[i].map(data[i].value_counts())\n\ndata","1259a814":"#\u30ab\u30c6\u30b4\u30ea\u5909\u6570\u304c\u6b8b\u3063\u3066\u3044\u306a\u3044\u304b\u3092\u30c1\u30a7\u30c3\u30af\ncats_check=[]\n\nfor col in data.columns:\n    if data[col].dtype == 'object': #dtype\u304cobject\u306e\u30e2\u30ce\u3092\u5bfe\u8c61\u306b\u3057\u3066\u3044\u308b\n        cats.append(col) #append\u306f\u30ea\u30b9\u30c8\u3078\u306e\u8ffd\u52a0\n        \ncats_check","b3f9fd45":"#\u6b20\u640d\u304c\u6b8b\u3063\u3066\u3044\u306a\u3044\u304b\u30c1\u30a7\u30c3\u30af\ndata.isnull().sum()","2de98ef7":"#\u884c\u65b9\u5411\u306b\u7d50\u5408\u3057\u3066\u3044\u305ftrain\u3068test\u3092\u5206\u96e2\ntrain2 = data[:len(train)]\ntest2 = data[len(train):]","7e7d2f6e":"groups = train2.Prefecture.values\nnp.count_nonzero(groups)\ntrain2.drop(['Prefecture'], axis=1, inplace=True)\ntest2.drop(['Prefecture'], axis=1, inplace=True)","d17bc797":"#\u5206\u96e2\u3057\u305f\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u8aac\u660e\u5909\u6570\u3068\u76ee\u7684\u5909\u6570\u3092\u5206\u96e2\u3000\ny_train = train2['TradePrice']\nX_train = train2.drop('TradePrice', axis = 1)\nX_test = test2.drop('TradePrice', axis = 1)\n\nprint(data.shape)\nprint(y_train.shape)\nprint(X_train.shape)\nprint(X_test.shape)","4093fab9":"n_fold = 6\n#Fold\u30922\u3064\u306b\u5206\u3051\u308b\u3002\n\ncv = GroupKFold(n_splits=n_fold)\n#GroupKFold\u3092cv\u3068\u3044\u3046\u5909\u6570\u306b\u7f6e\u304d\u63db\u3048\u308b\n\nfor i, (train_index, val_index) in enumerate(tqdm(cv.split(X_train, y_train, groups))):\n    X_train_, y_train_ = X_train.iloc[train_index], y_train.iloc[train_index]\n    X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]","aeba8d8b":"print(X_train_.shape)\nprint(y_train_.shape)\nprint(X_val.shape)\nprint(y_val.shape)","1fbafab8":"#LightGBM\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u683c\u7d0d\n\nlgb_train = lgb.Dataset(X_train_, np.log1p(y_train_))\nlgb_eval = lgb.Dataset(X_val, np.log1p(y_val))\n","dccbd2cb":"# \u90fd\u9053\u5e9c\u770c\u3067\u533a\u5207\u3063\u3066\u4ea4\u5dee\u691c\u5b9a\u3092\u884c\u3044\u3001\u4e88\u6e2c\u7cbe\u5ea6\u3092\u898b\u7a4d\u3082\u308b\u3002\n# \u540c\u6642\u306b\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066cv averaging\u3092\u884c\u3044\u3001\u4e88\u6e2c\u5024\u3092\u5f97\u308b\u3002\nn_fold = 6\n#Fold\u30926\u3064\u306b\u5206\u3051\u308b\u3002\u4e00\u3064\u306eFold\u306b\u4e00\u3064\u306e\u770c\u304c\u5165\u308b\u3088\u3046\u306b\u306a\u308b\u3002\n\ncv = GroupKFold(n_splits=n_fold)\n#GroupKFold\u3092cv\u3068\u3044\u3046\u5909\u6570\u306b\u7f6e\u304d\u63db\u3048\u308b\n\ny_pred_train = np.zeros(len(train))\n#\u2460y_pred_train(y_train\u306e\u4e88\u6e2c\u5024)\u3092\u5165\u308c\u308b\u7bb1\u3092numpy\u306ezeros\u3067train\u306e\u9577\u3055\u5206\u306e\u30bc\u30ed\u306e\u914d\u5217\u3092\u4f5c\u6210\n\ny_pred_test = np.zeros(len(test))\n#\u2461y_pred_test(y_test\u306e\u4e88\u6e2c\u5024)\u3092\u5165\u308c\u308b\u7bb1\u3092numpy\u306ezeros\u3067train\u306e\u9577\u3055\u5206\u306e\u30bc\u30ed\u306e\u914d\u5217\u3092\u4f5c\u6210\n\nscores = []\n#\u691c\u5b9a\u30b9\u30b3\u30a2\u3092\u5165\u308c\u308b\u305f\u3081\u306e\u7a7a\u306e\u30ea\u30b9\u30c8\u3092\u4f5c\u6210\n\n\nfor i, (train_index, val_index) in enumerate(tqdm(cv.split(X_train, y_train, groups))):\n    X_train_, y_train_ = X_train.iloc[train_index], y_train.iloc[train_index]\n    X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n    \n    #for\u6587\u3092\u4f7f\u3063\u3066enumerate\u95a2\u6570\u3067\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u30ca\u30f3\u30d0\u30fc(i)\u3068train\u7528\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\uff08train_ix\uff09\u3068\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u7528\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\uff08val_ix\uff09\u3092\u751f\u6210\n    # \u2462X_train_  \u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u6bce\u306b\u5206\u985e\u3055\u308c\u305f\u8aac\u660e\u5909\u6570\uff08\u5b66\u7fd2\u30c7\u30fc\u30bf\uff09\n    # \u2463y_train_\u3000\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u6bce\u306b\u5206\u985e\u3055\u308c\u305f\u76ee\u7684\u5909\u6570\uff08\u5b66\u7fd2\u30c7\u30fc\u30bf\uff09\n    # \u2464X_val\u3000\u3000\u3000\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3054\u3068\u306b\u5206\u985e\u3055\u308c\u305f\u691c\u8a3c\u7528\u8aac\u660e\u5909\u6570\uff08\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\uff09\n    # \u2465y_val\u3000\u3000\u3000\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3054\u3068\u306b\u5206\u985e\u3055\u308c\u305f\u691c\u8a3c\u7528\u76ee\u7684\u5909\u6570\uff08\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\uff09\n    \n    params = {'metric': 'rmse','max_depth' : 9, 'max_bin':300, 'learning_rate':0.05, 'num_leaves':40}\n    lgb_train = lgb.Dataset(X_train_, np.log1p(y_train_))\n    lgb_eval = lgb.Dataset(X_val, np.log1p(y_val))\n\n    model = lgb.train(params,\n                lgb_train,\n                valid_sets=lgb_eval,\n                num_boost_round=10000,\n                early_stopping_rounds=100,\n                verbose_eval=50)\n\n        \n    y_pred_val = np.expm1(model.predict(X_val))\n    #\u2466\u3053\u3053\u3067\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u76ee\u7684\u5909\u6570\uff08\u2464X_val\uff09\u3092\u4f7f\u3063\u3066\u3001\u4e0a\u3067\u51fa\u6765\u305f\u30e2\u30c7\u30eb\u304b\u3089\u4e88\u6e2c\u5024\u3092\u51fa\u3057\u3066\u3044\u308b\u3002\u7d50\u679c\u306f\u5bfe\u6570\u8868\u8a18\u306b\u306a\u308b\u305f\u3081\u3001np.expm1\u3092\u4f7f\u3063\u3066\u5143\u306e\u6570\u5024\u306b\u623b\u3057\u3066\u3044\u308b\u3002\n    \n    y_pred_test += np.expm1(model.predict(X_test))\/n_fold\n    #\u2461\u3053\u308c\u304c\u63d0\u51fa\u7528\u30c7\u30fc\u30bf\u306b\u306a\u3063\u3066\u3044\u308b\u3002\u305f\u3060\u3057Fold\u6570\u5206\u306e1\u306b\u306a\u3063\u3066\u3044\u308b\u3002np.zeros\u3067\u4f5c\u3063\u305f0\u306e\u914d\u5217\u306b\u30a4\u30f3\u30af\u30ea\u30e1\u30f3\u30c8\u3057\u3066\u3044\u3063\u3066\u3044\u308b\u3002for\u6587\u3067Fold\u306e\u56de\u6570\u5206\u30c7\u30fc\u30bf\u304c\u7a4d\u307f\u3042\u304c\u3063\u3066\u3044\u304f\u3002\n    \n    y_pred_train[val_index] = y_pred_val\n    #\u2460\u4f55\u306e\u305f\u3081\u306b\u4f5c\u3063\u3066\u3044\u308b\uff1f\u3000\u521d\u3081\u306b\u4f5c\u3063\u305f\u30bc\u30ed\u306e\u914d\u5217\u306b\u2464X_val\u3092\u4f7f\u3063\u3066\u4e88\u6e2c\u3057\u305f\u2466y_pred_val\u306e\u914d\u5217\u3092\u5165\u308c\u8fbc\u3093\u3067\u3044\u304f\u3002np\u306e\u4f55\u756a\u76ee\u306b\u5024\uff08\u2466y_pred_val\uff09\u3092\u5165\u308c\u308b\u304b\u3092[val_index]\u3067\u6307\u5b9a\u3057\u3066\u3044\u308b\u3002\n    \n    score = mean_squared_log_error(y_val, y_pred_val)**0.5\n    #\u3053\u3053\u3067Fold\u4e00\u56de\u5206\u306eRMSLE\u3092\u7b97\u51fa\u3002\u691c\u8a3c\u7528\u76ee\u7684\u5909\u6570\uff08\u2465y_val\uff09\u3068\u2466\u63d0\u51fa\u7528\u306e\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306eRMSLE\u3092\u7b97\u51fa\u3002\n    \n    scores.append(score)\n    #\u521d\u3081\u306b\u4f5c\u3063\u305f\u7a7a\u306e\u30ea\u30b9\u30c8\u306bfor\u6587\u3067Fold\u306e\u56de\u6570\u5206\u30b9\u30b3\u30a2\u3092\u8ffd\u52a0\u3057\u3066\u3044\u304f\u3002\n    \n    \n    print(\"Fold%d RMSLE: %f\"%(i, score))\n    #\u4f55\u756a\u76ee\u306eFold\u304b\uff08i\uff09\u3001\u305d\u306e\u6642\u306e\u30b9\u30b3\u30a2RMSLE\u306f\u3044\u304f\u3064\u306b\u306a\u308b\u306e\u304b\u3092\u8868\u793a\u3055\u305b\u308b\u6307\u793a\u3002\n    \nprint(\"Overall RMSLE: %f\u00b1%f\"%(np.mean(scores), np.std(scores)))\n#For\u6587\u7d42\u4e86\u307e\u3067\u306b\u305f\u307e\u3063\u305fscore\u306e\u5e73\u5747\uff08mean\uff09\u3068\u6a19\u6e96\u504f\u5dee(std)\u3092\u8868\u793a\u3055\u305b\u308b\u3088\u3046\u306b\u6307\u793a\u3002for\u6587\u306e\u5916\u306b\u3042\u308b\u306e\u3067\u3001For\u6587\u304c\u7d42\u308f\u3063\u305f\u3089\u3001\u5225\u306e\u306f\u3053\u3067\u8868\u793a\u3055\u305b\u308b\u3053\u3068\u306b\u306a\u308b","2543032a":"## Submission\u7528\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210\ndf_sub = pd.read_csv('..\/input\/machine-learning-homework\/sample_submission.csv', index_col=0)\ndf_sub.TradePrice = y_pred_test\ndf_sub.to_csv('submission_0_lgb.csv')","e942ccb8":"# \u90fd\u9053\u5e9c\u770c\u3067\u533a\u5207\u3063\u3066\u4ea4\u5dee\u691c\u5b9a\u3092\u884c\u3044\u3001\u4e88\u6e2c\u7cbe\u5ea6\u3092\u898b\u7a4d\u3082\u308b\u3002\n# \u540c\u6642\u306b\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066cv averaging\u3092\u884c\u3044\u3001\u4e88\u6e2c\u5024\u3092\u5f97\u308b\u3002\nn_fold = 6\n#Fold\u30926\u3064\u306b\u5206\u3051\u308b\u3002\u4e00\u3064\u306eFold\u306b\u4e00\u3064\u306e\u770c\u304c\u5165\u308b\u3088\u3046\u306b\u306a\u308b\u3002\n\ncv = GroupKFold(n_splits=n_fold)\n#GroupKFold\u3092cv\u3068\u3044\u3046\u5909\u6570\u306b\u7f6e\u304d\u63db\u3048\u308b\n\ny_pred_train = np.zeros(len(train))\n#\u2460y_pred_train(y_train\u306e\u4e88\u6e2c\u5024)\u3092\u5165\u308c\u308b\u7bb1\u3092numpy\u306ezeros\u3067train\u306e\u9577\u3055\u5206\u306e\u30bc\u30ed\u306e\u914d\u5217\u3092\u4f5c\u6210\n\ny_pred_test = np.zeros(len(test))\n#\u2461y_pred_test(y_test\u306e\u4e88\u6e2c\u5024)\u3092\u5165\u308c\u308b\u7bb1\u3092numpy\u306ezeros\u3067train\u306e\u9577\u3055\u5206\u306e\u30bc\u30ed\u306e\u914d\u5217\u3092\u4f5c\u6210\n\nscores = []\n#\u691c\u5b9a\u30b9\u30b3\u30a2\u3092\u5165\u308c\u308b\u305f\u3081\u306e\u7a7a\u306e\u30ea\u30b9\u30c8\u3092\u4f5c\u6210\n\n\nfor i, (train_index, val_index) in enumerate(tqdm(cv.split(X_train, y_train, groups))):\n    X_train_, y_train_ = X_train.iloc[train_index], y_train.iloc[train_index]\n    X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n    \n    #for\u6587\u3092\u4f7f\u3063\u3066enumerate\u95a2\u6570\u3067\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u30ca\u30f3\u30d0\u30fc(i)\u3068train\u7528\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\uff08train_ix\uff09\u3068\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u7528\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\uff08val_ix\uff09\u3092\u751f\u6210\n    # \u2462X_train_  \u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u6bce\u306b\u5206\u985e\u3055\u308c\u305f\u8aac\u660e\u5909\u6570\uff08\u5b66\u7fd2\u30c7\u30fc\u30bf\uff09\n    # \u2463y_train_\u3000\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u6bce\u306b\u5206\u985e\u3055\u308c\u305f\u76ee\u7684\u5909\u6570\uff08\u5b66\u7fd2\u30c7\u30fc\u30bf\uff09\n    # \u2464X_val\u3000\u3000\u3000\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3054\u3068\u306b\u5206\u985e\u3055\u308c\u305f\u691c\u8a3c\u7528\u8aac\u660e\u5909\u6570\uff08\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\uff09\n    # \u2465y_val\u3000\u3000\u3000\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3054\u3068\u306b\u5206\u985e\u3055\u308c\u305f\u691c\u8a3c\u7528\u76ee\u7684\u5909\u6570\uff08\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\uff09\n    \n    params = {\"metric\": {'rmse'},'max_depth': 5, 'subsumple': 0.8283266765660044, 'subsample_freq': 1, 'leaning_rate': 1.0105141214298505e-05, 'feature_fraction': 0.43816080387938106, 'lambda_l1': 0.8362681889809804, 'lambda_l2': 0.34327027378780084}\n    lgb_train = lgb.Dataset(X_train_, np.log1p(y_train_))\n    lgb_eval = lgb.Dataset(X_val, np.log1p(y_val))\n\n    model = lgb.train(params,\n                lgb_train,\n                valid_sets=lgb_eval,\n                num_boost_round=10000,\n                early_stopping_rounds=100,\n                verbose_eval=50)\n\n        \n    y_pred_val = np.expm1(model.predict(X_val))\n    #\u2466\u3053\u3053\u3067\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u76ee\u7684\u5909\u6570\uff08\u2464X_val\uff09\u3092\u4f7f\u3063\u3066\u3001\u4e0a\u3067\u51fa\u6765\u305f\u30e2\u30c7\u30eb\u304b\u3089\u4e88\u6e2c\u5024\u3092\u51fa\u3057\u3066\u3044\u308b\u3002\u7d50\u679c\u306f\u5bfe\u6570\u8868\u8a18\u306b\u306a\u308b\u305f\u3081\u3001np.expm1\u3092\u4f7f\u3063\u3066\u5143\u306e\u6570\u5024\u306b\u623b\u3057\u3066\u3044\u308b\u3002\n    \n    y_pred_test += np.expm1(model.predict(X_test))\/n_fold\n    #\u2461\u3053\u308c\u304c\u63d0\u51fa\u7528\u30c7\u30fc\u30bf\u306b\u306a\u3063\u3066\u3044\u308b\u3002\u305f\u3060\u3057Fold\u6570\u5206\u306e1\u306b\u306a\u3063\u3066\u3044\u308b\u3002np.zeros\u3067\u4f5c\u3063\u305f0\u306e\u914d\u5217\u306b\u30a4\u30f3\u30af\u30ea\u30e1\u30f3\u30c8\u3057\u3066\u3044\u3063\u3066\u3044\u308b\u3002for\u6587\u3067Fold\u306e\u56de\u6570\u5206\u30c7\u30fc\u30bf\u304c\u7a4d\u307f\u3042\u304c\u3063\u3066\u3044\u304f\u3002\n    \n    y_pred_train[val_index] = y_pred_val\n    #\u2460\u4f55\u306e\u305f\u3081\u306b\u4f5c\u3063\u3066\u3044\u308b\uff1f\u3000\u521d\u3081\u306b\u4f5c\u3063\u305f\u30bc\u30ed\u306e\u914d\u5217\u306b\u2464X_val\u3092\u4f7f\u3063\u3066\u4e88\u6e2c\u3057\u305f\u2466y_pred_val\u306e\u914d\u5217\u3092\u5165\u308c\u8fbc\u3093\u3067\u3044\u304f\u3002np\u306e\u4f55\u756a\u76ee\u306b\u5024\uff08\u2466y_pred_val\uff09\u3092\u5165\u308c\u308b\u304b\u3092[val_index]\u3067\u6307\u5b9a\u3057\u3066\u3044\u308b\u3002\n    \n    score = mean_squared_log_error(y_val, y_pred_val)**0.5\n    #\u3053\u3053\u3067Fold\u4e00\u56de\u5206\u306eRMSLE\u3092\u7b97\u51fa\u3002\u691c\u8a3c\u7528\u76ee\u7684\u5909\u6570\uff08\u2465y_val\uff09\u3068\u2466\u63d0\u51fa\u7528\u306e\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306eRMSLE\u3092\u7b97\u51fa\u3002\n    \n    scores.append(score)\n    #\u521d\u3081\u306b\u4f5c\u3063\u305f\u7a7a\u306e\u30ea\u30b9\u30c8\u306bfor\u6587\u3067Fold\u306e\u56de\u6570\u5206\u30b9\u30b3\u30a2\u3092\u8ffd\u52a0\u3057\u3066\u3044\u304f\u3002\n    \n    \n    print(\"Fold%d RMSLE: %f\"%(i, score))\n    #\u4f55\u756a\u76ee\u306eFold\u304b\uff08i\uff09\u3001\u305d\u306e\u6642\u306e\u30b9\u30b3\u30a2RMSLE\u306f\u3044\u304f\u3064\u306b\u306a\u308b\u306e\u304b\u3092\u8868\u793a\u3055\u305b\u308b\u6307\u793a\u3002\n    \nprint(\"Overall RMSLE: %f\u00b1%f\"%(np.mean(scores), np.std(scores)))\n#For\u6587\u7d42\u4e86\u307e\u3067\u306b\u305f\u307e\u3063\u305fscore\u306e\u5e73\u5747\uff08mean\uff09\u3068\u6a19\u6e96\u504f\u5dee(std)\u3092\u8868\u793a\u3055\u305b\u308b\u3088\u3046\u306b\u6307\u793a\u3002for\u6587\u306e\u5916\u306b\u3042\u308b\u306e\u3067\u3001For\u6587\u304c\u7d42\u308f\u3063\u305f\u3089\u3001\u5225\u306e\u306f\u3053\u3067\u8868\u793a\u3055\u305b\u308b\u3053\u3068\u306b\u306a\u308b","c683fb0f":"## Submission\u7528\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210\ndf_sub = pd.read_csv('..\/input\/machine-learning-homework\/sample_submission.csv', index_col=0)\ndf_sub.TradePrice = y_pred_test\ndf_sub.to_csv('submission_1_lgb_op7200.csv')","aa32a486":"## Optuna\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u5f8c","602fc837":"## \u3053\u3053\u304b\u3089\u30c7\u30fc\u30bf\u306e\u524d\u51e6\u7406","f22c0d84":"\n#\u76ee\u7684\u95a2\u6570\u306e\u8a2d\u5b9a\n\n\ndef objective(trial):\n    params = {'metric': {'rmse'},\n              'max_depth' : trial.suggest_int('max_depth', 1, 10),\n              'subsumple' : trial.suggest_uniform('subsumple', 0.0, 1.0),\n              'subsample_freq' : trial.suggest_int('subsample_freq', 0, 1),\n              'leaning_rate' : trial.suggest_loguniform('leaning_rate', 1e-5, 1),\n              'feature_fraction' : trial.suggest_uniform('feature_fraction', 0.0, 1.0),\n              'lambda_l1' : trial.suggest_uniform('lambda_l1' , 0.0, 1.0),\n              'lambda_l2' : trial.suggest_uniform('lambda_l2' , 0.0, 1.0)}\n\n    gbm = lgb.train(params,\n                    lgb_train,\n                    valid_sets=(lgb_train, lgb_eval),\n                    num_boost_round=10000,\n                    early_stopping_rounds=100,\n                    verbose_eval=50)\n    predicted = gbm.predict(X_val)\n    RMSE = np.sqrt(mean_squared_error(y_val, np.expm1(predicted)))\n    \n    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'rmse')\n    return RMSE","4d8c7aff":"#data\u306e\u6b20\u640d\u5024\u3092-99999\u3067\u7f6e\u304d\u63db\u3048\u308b\ndata = data.fillna(-99999)\ndata.head()","631493c4":"## GroupKFold\u30676\u5206\u5272\u3057\u3066LightGBM\u30676\u56de\u5206\u306e\u4e88\u6e2c\u3068\u691c\u8a3c\u3092\u3057\u3066\u307f\u308b","ce4e17e4":"## Oputuna\u3067\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3092\u3057\u3066\u307f\u308b","a75fd7e4":"## \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u524d","0dc646de":"#Oputuna\u306e\u8d77\u52d5\nstudy = optuna.create_study()\nstudy.optimize(objective, timeout=7200)","cb0fef63":"## \u3053\u3053\u304b\u3089\u6a5f\u68b0\u5b66\u7fd2\u30d1\u30fc\u30c8"}}