{"cell_type":{"e8aa1702":"code","7c821861":"code","02691b29":"code","9b5809b4":"code","0a6e972c":"code","49fca97c":"code","f47c4637":"code","1183d4e8":"code","3a27985c":"code","a7979e7d":"code","71f2477d":"code","6dc7318a":"code","3738efab":"code","d989b973":"code","d711d963":"markdown","3806cb17":"markdown","3acb6b6d":"markdown","8735b0ca":"markdown","d3268b44":"markdown","f1a21dca":"markdown","96949f17":"markdown","dc1743d0":"markdown"},"source":{"e8aa1702":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7c821861":"nRowsRead = 1000 # specify 'None' if want to read whole file\ndf = pd.read_csv('..\/input\/cusersmarildownloadsgermancsv\/german.csv', delimiter=';', encoding = \"ISO-8859-2\", nrows = nRowsRead)\ndf.dataframeName = 'german.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\ndf.head()","02691b29":"import tensorflow as tf\nimport datetime\n\nfrom tensorflow import keras\nfrom keras.layers import GaussianNoise\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport pathlib\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom keras import optimizers\nimport tensorflow as tf\nimport tensorflow.keras \n\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras import backend as K\nfrom keras.layers.normalization import BatchNormalization","9b5809b4":"#Code by Volkan \u00d6zdemir https:\/\/www.kaggle.com\/volkandl\/what-if-the-data-was-an-image-cnn-usage\/notebook\n\n#df=df.iloc[:,1:]\n#test=test.iloc[:,1:]\nprint('df shape is: ',df.shape)\n#print('test shape is: ',test.shape)\ny = df[\"Creditability\"]\nX = df.iloc[:,:-1]\nprint(type(X), type(y))\nprint( X.shape, y.shape)","0a6e972c":"#Code by Volkan \u00d6zdemir https:\/\/www.kaggle.com\/volkandl\/what-if-the-data-was-an-image-cnn-usage\/notebook\n\nlabel=y\ntrain = X\nprint(\"train shape: \",train.shape),print(\"label shape: \",label.shape)","49fca97c":"#Code by Volkan \u00d6zdemir https:\/\/www.kaggle.com\/volkandl\/what-if-the-data-was-an-image-cnn-usage\/notebook\n\nx_train, x_test, y_train, y_test = train_test_split(train, label, test_size=0.30, random_state=42 )\nprint(\"x_train shape: \", x_train.shape)\nprint(\"y_train shape: \", y_train.shape)\nprint(\"x_test shape: \", x_test.shape)\nprint(\"y_test shape: \", y_test.shape)","f47c4637":"#Code by Volkan \u00d6zdemir https:\/\/www.kaggle.com\/volkandl\/what-if-the-data-was-an-image-cnn-usage\/notebook\n\nfrom sklearn.preprocessing import  StandardScaler\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)\n#test = scaler.transform(test)","1183d4e8":"#Code by Volkan \u00d6zdemir https:\/\/www.kaggle.com\/volkandl\/what-if-the-data-was-an-image-cnn-usage\/notebook\n\n#reshape images\nx_train = x_train.reshape(-1,10,10,1)\nx_test = x_test.reshape(-1,10,10,1)\n#test = test.reshape(-1,10,10,1)\n\nprint(\"x_train shape: \", x_train.shape)\nprint(\"y_train shape: \", y_train.shape)\nprint(\"x_test shape: \", x_test.shape)\nprint(\"y_test shape: \", y_test.shape)\n#print(\"test shape: \", test.shape)","3a27985c":"#Code by Volkan \u00d6zdemir https:\/\/www.kaggle.com\/volkandl\/what-if-the-data-was-an-image-cnn-usage\/notebook\n\nfig = plt.figure(figsize = (21, 22))\nlabel_index=y_train[:25].to_list()\nfor i in range(25):\n    plt.subplot(5,5,1 + i)\n    plt.title(\"Image Belongs to the label: \" + \" \" + str(label_index[i]), fontname=\"Times New Roman\",fontweight=\"bold\")\n    plt.imshow(x_train[i,:,:,0], cmap=plt.get_cmap('gray'))\nplt.show()","a7979e7d":"#Code by Volkan \u00d6zdemir https:\/\/www.kaggle.com\/volkandl\/what-if-the-data-was-an-image-cnn-usage\/notebook\n\n#Hyper Parameters\nbatch_size = 128\nepochs = 8\nlearning_rate=0.01\nactivation = 'relu'\nFully_connected_layer_nodes=86\ninput_shape = (10, 10, 1)","71f2477d":"#Code by Volkan \u00d6zdemir https:\/\/www.kaggle.com\/volkandl\/what-if-the-data-was-an-image-cnn-usage\/notebook\n\n#Rehape the images for AlexNet input such: (28,28,1) --> Giri\u015fleri AlexNet'e g\u00f6re ayarl\u0131yoruz.\nimg_rows = 10\nimg_cols = 10\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)","6dc7318a":"#Code by Volkan \u00d6zdemir https:\/\/www.kaggle.com\/volkandl\/what-if-the-data-was-an-image-cnn-usage\/notebook\n\nprint(\"x_train shape: \", x_train.shape)\nprint(\"y_train shape: \", y_train.shape)\nprint(\"x_test shape: \", x_test.shape)\nprint(\"y_test shape: \", y_test.shape)\nprint(\"input_shape: \", input_shape )","3738efab":"#ALEXNET STRUCTURE\nmodel = Sequential()\n\nmodel.add(Conv2D(8, kernel_size=(1, 1), activation= activation, padding=\"SAME\",input_shape=input_shape ) )\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(1, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(36, (3, 3), activation=activation,padding=\"SAME\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dense(Fully_connected_layer_nodes, activation=activation))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(Fully_connected_layer_nodes, activation=activation))\nmodel.add(BatchNormalization())\n\nmodel.add(Dense(1, activation='linear'))\n\n\nadam=tensorflow.keras.optimizers.Adam(lr=learning_rate)\ncallback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)      \n      \nmodel.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\nmodel.summary()","d989b973":"#Code by Volkan \u00d6zdemir https:\/\/www.kaggle.com\/volkandl\/what-if-the-data-was-an-image-cnn-usage\/notebook\n\nhistory=model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=[callback], verbose=1, validation_data=(x_test, y_test), shuffle=False)\nval_loss, val_acc=model.evaluate(x_test, y_test )\nprint(\"validation loss: \", val_loss)\nprint( \"<3 \")\nprint(\"validation accuracy: \", val_acc)\nprint(\"learn rate: \",learning_rate, \"epochs: \", epochs, \"activation: \",activation, \"Fully Connected Layer's Node Number :\", Fully_connected_layer_nodes)","d711d963":"#Create X ( train ) and y (label) out of train dataset and get rid of the first feature \"id\"","3806cb17":"#See our magical images :D I wonder if there will be some logical outcomes..","3acb6b6d":"#Create 10x10 matrices from 100x1 feature","8735b0ca":"#Standard scale for the scaling the features, it is nothing but substracting the mean and dividing the standard deviation of the corresponding feature","d3268b44":"Since we have Regression Problem, we changed the last activation neuron from softmax to linear. \n\nOur loss is 'mean_squared_error', optimizer is 'adam'and metric is 'mse' again.\n\nWe have callbacks as early stopping with patience of 5\n\nI use small filter sizes in convolutions since the data is small 10x10, even 7 times smaller than MNIST data which is 28x28!\n\nUse batch normalization since i have a huge batch size\n\nUse dropout to avoid overfitting\n\nActivation layers are \"ReLu\"\n\nPadding is \"Same\"","f1a21dca":"#Test - Train split as %30 of the data for test","96949f17":"We don't have test to be reshaped So we got that error below.","dc1743d0":"#We don't have test and that won't allow to perform the last snippet."}}