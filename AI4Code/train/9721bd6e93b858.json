{"cell_type":{"af26c3f5":"code","59fa3068":"code","066e95fc":"code","3e5a6a7c":"code","715e2f6a":"code","96fd1aa3":"code","c99f4830":"code","aa1ba7b1":"code","94a75784":"code","6e2e1f62":"code","15d98d78":"code","a81af976":"code","f565f746":"code","902283c0":"code","c2e3c8c0":"code","fd76be84":"code","5e42fe9f":"code","9004230d":"markdown","5f54b725":"markdown","f51e4b64":"markdown","55aa57d4":"markdown","0daab93f":"markdown","8aee2961":"markdown","c69379e7":"markdown","1ef52074":"markdown","71d7a8eb":"markdown","5e1a5b9e":"markdown","063358c6":"markdown","7feb7e6e":"markdown","49464f16":"markdown","9b20066a":"markdown","4a3466a1":"markdown"},"source":{"af26c3f5":"import numpy as np\nimport pandas as pd\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# Any results you write to the current directory are saved as output.","59fa3068":"def preprocess(df,eightbit=False):\n    #data.replace('na',np.NaN,True)\n    if(eightbit==True):\n        df = df.apply(round)\n        df.replace({-1:0},True)\n        return df\n    else:\n        df['class'].replace('neg',0,True)\n        df['class'].replace('pos',1,True)\n        return df","066e95fc":"eightBit=False\nlogging=True\n\nif(eightBit):\n    X_test = pd.read_csv(\"..\/input\/aps-failure-at-scania-trucks-data-set\/aps_failure_test_set_processed_8bit.csv\",na_values=0)\n    X_train = pd.read_csv(\"..\/input\/aps-failure-at-scania-trucks-data-set\/aps_failure_training_set_processed_8bit.csv\",na_values=0)\nelse:\n    X_test = pd.read_csv(\"..\/input\/aps-failure-at-scania-trucks-data-set\/aps_failure_test_set.csv\",na_values='na')\n    X_train = pd.read_csv(\"..\/input\/aps-failure-at-scania-trucks-data-set\/aps_failure_training_set.csv\",na_values='na')\n\n\n#X_train=preprocess(X_train,eightBit)\n#X_test=preprocess(X_test,eightBit)\n\nX_train['class'] = pd.Categorical(X_train['class']).codes\nX_test['class'] = pd.Categorical(X_test['class']).codes\n\n#print(X_train.head())\n\ny_train = X_train['class']            \nX_train.drop(['class'], axis=1, inplace=True)\n\n#X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, train_size=0.8, test_size=0.2, stratify=y_train)\n\ny_test = X_test['class']            \nX_test.drop(['class'], axis=1, inplace=True)","3e5a6a7c":"from sklearn.metrics.scorer import make_scorer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve, roc_auc_score,recall_score,precision_score\n\n\ndef scania_scorer(y_true,y_pred):\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()  \n    total_cost = 10*fp + 500*fn\n    return total_cost\n    \ndef scania_score_tensor(y_true,y_pred):\n    tf.print(y_true)\n    tf.print(y_pred)\n    mat = tf.math.confusion_matrix(labels=y_true, predictions=y_pred)\n    print(mat)\n    total_cost = 10*mat[0][1] + 500*mat[1][0]\n    return total_cost\n    \ndef print_all_scores(y_true, y_pred):\n    global logging\n    if(logging):\n        accuracy = accuracy_score(y_true, y_pred)\n        print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n\n        score = f1_score(y_true, y_pred, average='binary')\n        print('F-Measure: %.3f' % score)\n\n        valid_score = roc_auc_score(y_true, y_pred)\n        print(f\"Validation AUC score: {valid_score:.4f}\")\n\n        conf_mat = confusion_matrix(y_true, y_pred)\n        print('Confusion matrix:\\n', conf_mat)\n\n        print(scania_scorer(y_true, y_pred))\n\nmy_scania_scorer = make_scorer(scania_scorer, greater_is_better=False)\n\n","715e2f6a":"from sklearn.preprocessing import MinMaxScaler\n\ndef normalize(df):\n    scaler = MinMaxScaler(random_state=1)\n    scaler.fit(df)\n    return pd.DataFrame(scaler.transform(df), columns=df.columns)\n\n#X_train=normalize(X_train)\n    ","96fd1aa3":"import collections\nimport re\n#inspired by https:\/\/www.kaggle.com\/percevalve\/scania-dataset-eda-for-histograms\n\ndef getHistograms(df):\n    stripedNameList=[col_name.split(\"_\")[0] for col_name in df.columns if \"_\" in col_name]\n    histStripedNameList=[item for item, count in collections.Counter(stripedNameList).items() if count > 1]\n    histDict={k:[col for col in df.columns if k in col if re.match('^\\w{2}_\\d{3}$',col)] for k in histStripedNameList }\n    return histDict\n\ndef addSystemAge(df):\n    histDict=getHistograms(df)\n    hists=histDict.keys();\n    for hist in hists:\n        df[f\"{hist}_total\"] = sum(df[col] for col in histDict[hist])\n    df[\"system_age\"] = df[[f\"{hist}_total\" for hist in hists]].min(axis=1)\n    df.drop([f\"{hist}_total\" for hist in hists],axis=1,inplace=True)\n\ndef addAvg(df,replace=False,filterList=None):\n    histDict=getHistograms(df)\n    hists=histDict.keys();\n    if(filterList is not None):\n        hists=filterList\n    for hist in hists:\n        df[f\"{hist}_avg\"] = 0\n        df[f\"{hist}_total\"] = sum(df[col] for col in histDict[hist])\n        for col in histDict[hist]:\n            df[f\"{col}_density\"] = df[col]\/df[f\"{hist}_total\"]\n            df.loc[df[f\"{hist}_total\"] == -10, f\"{col}_density\"] = -1\n            df.loc[df[f\"{hist}_total\"] == 0, f\"{col}_density\"] = 0\n            df[f\"{hist}_avg\"] += int(col[3:])*df[col]\n        df[f\"{hist}_avg\"] = df[f\"{hist}_avg\"]\/df.system_age\n        df.loc[df[f\"{hist}_total\"] == 0, f\"{hist}_avg\"] = 0\n        df.loc[df[f\"{hist}_total\"] == -1, f\"{hist}_avg\"] = 0\n\n    df.drop([f\"{hist}_total\" for hist in hists],axis=1,inplace=True)\n    df.drop([col for col in df.columns if \"density\" in col],axis=1,inplace=True)\n    if(replace==True):\n        deleteHistCols(df,filterList)\n    \ndef deleteHistCols(df,colNames=None):\n    columns=df.columns\n    if(colNames is not None):\n        columns=colNames\n    for col in columns:\n        if re.match('^\\w{2}_\\d{3}$',col):\n            df.drop(col,axis=1,inplace=True)\n            \ndef addBins(df):\n    _, bins_for_total_feature = pd.qcut(df.system_age,3,retbins=True)\n    bins_for_total_feature[3] = np.max(df.system_age)\n    df[\"total_cat\"] = pd.cut(df.system_age.replace(np.nan,-1),[-10.1] + list(bins_for_total_feature),labels=[-0.10,10.0,20.0, 30.0])\n    df.total_cat= pd.to_numeric(df.total_cat)\n    \n#addSystemAge(X_train)\n#addSystemAge(X_test)\n#addAvg(X_train)\n#addAvg(X_test)\n#print(X_train.describe())\n#print(X_train.columns)","c99f4830":"def display_missing_values_table_chart(df,axis=1):\n    df_null_pct = df.isna().mean(axis=axis).round(4) * 100\n    df_null_pct.plot(kind='hist')\n    plt.show()\n\ndef delete_missing_values_table(dataf,dataf2=None,nanThreshold=55,axis=0):\n    global logging\n    if(axis==1):\n        indexListPosClass=dataf2.index[dataf2==1].tolist()\n        rowsByMissingValue=dataf.isnull().sum(axis=1)\n        rowsByMissingValue=rowsByMissingValue.drop(indexListPosClass)\n        rowsByMissingValue=rowsByMissingValue.index[rowsByMissingValue>60].tolist()\n        #print(rowsByMissingValue.value_counts().sort_index().to_string())\n        dataf.drop(rowsByMissingValue,axis=0,inplace=True)\n        dataf2.drop(rowsByMissingValue,axis=0,inplace=True)\n        dataf.drop(['class'], axis=1, inplace=True)\n        \n        if(logging):\n            #Display Missing Values per row with the nr of rows \n            print(X_train.isnull().sum(axis=1).value_counts().sort_index().to_string())\n            print(dataf.shape)\n    else:\n        cols_with_nan = [cname for cname in dataf.columns if 100 * dataf[cname].isnull().sum()\/ len(dataf[cname]) > nanThreshold]\n        dataf.drop(cols_with_nan,axis='columns', inplace=True)\n        if (len(cols_with_nan)>0 and logging):\n            print('Deleted Columns: ',cols_with_nan,'because it\/they had more than',nanThreshold,'% of null values')\n        if(dataf2 is not None):\n            dataf2.drop(cols_with_nan,axis='columns', inplace=True)\n\nif(logging):\n    display_missing_values_table_chart(X_train,1)\n#delete_missing_values_table(X_train,X_test)","aa1ba7b1":"def dropConstantFeatures(df,df2=None,nanThreshold=98):\n    global logging\n    #constantFeatures=df.std()[(df.std() == 0)].index.to_list()\n    constantFeatures = [cname for cname in df.columns if 100 * df[cname].value_counts().iloc[0]\/len(df.index) > nanThreshold]\n    df.drop(constantFeatures, axis=1, inplace=True)\n    if(logging):\n        if (len(constantFeatures)>0):\n            print('Deleted Columns: ',constantFeatures,'because it\/they where constant')\n        else:\n            print('No constant feature found!')\n    if(df2 is not None):\n        df2.drop(constantFeatures,axis='columns', inplace=True)\n        \n#dropConstantFeatures(X_train,X_test)","94a75784":"#did make the result worse the first tine I tried\n# https:\/\/towardsdatascience.com\/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779\n#idea use k-NN\n# idea use linear regression for imputation?\n\nfrom sklearn.impute import SimpleImputer\n#from fancyimpute import KNN\n#from fancyimpute import IterativeImputer\nfrom sklearn.neighbors import KNeighborsRegressor\nimport missingno as msno\n\ndef display_missingness(df):\n    missingdata_df = df.columns[df.isnull().any()].tolist()\n    print('Count of Null\\'s in the dataframe: ',len(missingdata_df))\n    #msno.matrix(df[missingdata_df])\n    #msno.heatmap(df[missingdata_df])\n\ndef impute(df,algo=None,method='mean'):\n    my_imputer= None\n#    if(algo=='knn'):\n#        my_imputer = KNN()\n#    if(algo=='mice'):\n#        my_imputer = IterativeImputer(verbose=True,initial_strategy=method,estimator=KNeighborsRegressor(n_neighbors=5,weights='uniform',algorithm='ball_tree'))\n#    else:\n    my_imputer = SimpleImputer(strategy=method)\n    df_imputed = pd.DataFrame(my_imputer.fit_transform(df))\n    # Imputation removed column names; put them back\n    df_imputed.columns = df.columns\n    if(logging):\n        print('Count of Null\\'s in the dataframe after impution:',df_imputed.isna().sum().sum())\n    return df_imputed\n\ndisplay_missingness(X_train)\n#X_train=impute(X_train)","6e2e1f62":"from imblearn.combine import SMOTETomek\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler,EditedNearestNeighbours,TomekLinks\n\ndef printClassCount(df,comment=''):\n    count_classes=pd.value_counts(df,sort=True)\n    print(comment,count_classes)\n\ndef showBalanced(df,eightBit=False):\n    count_classes=pd.value_counts(df,sort=True)\n    printClassCount(df)\n    if(logging):\n        if(eightBit):\n            print('1 :',count_classes[-1]\/count_classes[1])\n        else:\n            print('1 :',count_classes[0]\/count_classes[1])\n    count_classes.plot.bar(rot=0)\n    \ndef resample(X,y,strategy='auto',algo=None,random_state=1):\n    my_resampler= None\n    if(algo=='SMOTETomek'):\n        my_resampler = SMOTETomek(random_state=random_state)\n    elif(algo=='Tomek'):\n        my_resampler = TomekLinks(random_state=random_state)\n    elif(algo=='ENN'):\n        my_resampler = EditedNearestNeighbours(random_state=random_state)\n    elif(algo=='SMOTE'):\n        my_resampler = SMOTE(random_state=random_state,sampling_strategy = strategy)\n    elif(algo=='Cluster'):\n        my_resampler = ClusterCentroids(random_state=random_state,sampling_strategy = strategy)\n    #elif(algo=='RUS'):\n    #    my_imputer = \n    else:\n        my_resampler = RandomUnderSampler(random_state=random_state,sampling_strategy = strategy,)\n    \n    X_resampled, y_resampled = my_resampler.fit_resample(X, y)\n    X_resampled = pd.DataFrame(X_resampled)\n    X_resampled.columns = X.columns\n    y_resampled = pd.Series(y_resampled)\n    if(logging):\n        printClassCount(y_resampled,'resampled by '+ (algo or 'RUS')+'\\n')\n    return X_resampled,y_resampled\n    \nshowBalanced(y_train,eightBit)\n#X_train,y_train = resample(X_train,y_train,strategy=1)\n","15d98d78":"from sklearn.feature_selection import SelectKBest, chi2\nfrom matplotlib.ticker import ScalarFormatter, FormatStrFormatter\nfrom sklearn.decomposition import PCA, FastICA\n\n    \ndef showKmostImportant():\n    selector = SelectKBest(score_func=chi2,k='all')\n    fit = selector.fit(X_train, y_train)\n    dfscores = pd.DataFrame(fit.scores_)\n    dfcolumns = pd.DataFrame(X_train.columns)\n    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n    featureScores.columns = ['Name','Score'] \n    \n    ax=featureScores.plot(kind='hist')\n    ax.xaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n    plt.xticks(rotation=45)\n    plt.show()\n    \ndef doSelection(X,y,X2,take=84,random_state=1):\n    global logging\n    my_selector= SelectKBest(score_func=chi2)\n    \n    fit = my_selector.fit(X, y)\n    dfscores = pd.DataFrame(fit.scores_)\n    dfscores.set_index(X.columns,inplace=True)\n    dfscores.sort_values(by=0,ascending=False,inplace=True);\n    #dfscores[0].le()\n    \n    #keeptFeaturesList=dfscores[dfscores>=5000000000].dropna().index\n    keeptFeaturesList=X.iloc[:,:take]\n    X_reduced=X.filter(keeptFeaturesList)\n    if(logging):\n        print(X_reduced.shape)\n    if(X2 is not None):\n        X2_reduced=X2.filter(keeptFeaturesList)\n        return X_reduced,X2_reduced\n    return X_reduced\n\ndef doPCA(df,df2=None):\n    global logging\n    pca = PCA(84)\n    pca.fit(df)\n    df_reduced = pca.transform(df)\n    df_reduced = pd.DataFrame(df_reduced)\n    if(logging):\n        print(df_reduced.shape)\n    if(df2 is not None):\n        df2_reduced=pd.DataFrame(pca.transform(np.nan_to_num(df2)))\n        return df_reduced,df2_reduced\n    return df_reduced\n\ndef selectCorrelated(df,df2=None):\n    corr_matrix = X_train.corr(method = \"spearman\").abs()\n    # Select upper triangle of matrix\n    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(np.bool))\n    # Find index of feature columns with correlation greater than 0.95\n    to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n    df.drop(to_drop, axis = 1, inplace= True)\n    if(df2 is not None):\n        df2.drop(to_drop, axis = 1, inplace= True)\n\ndef selectFeatures(X,X2,algo=None,y=None):\n    if(algo=='corr'):\n        selectCorrelated(X,X2)\n    elif(algo=='pca'):\n        doPCA(X,X2)\n    else:\n        doSelection(X,y,X2)\n        \n#selectCorrelated(X_train,X_test)\n#X_train,X_test=doPCA(X_train,X_test)\n#showKmostImportant()\n#X_train,X_test=doSelection(X_train,y_train,X_test,84)\n","a81af976":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn import svm\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom time import time\n\n\nseed = 1\nimport random\nrandom.seed(seed)\nnp.random.seed(seed)\nimport tensorflow as tf\ntf.random.set_seed(seed)\nimport os\nos.environ['PYTHONHASHSEED'] = str(seed)\n\ndef makeNnModel():\n    global X_train\n    print(X_train.shape[1])\n    model = Sequential()\n    model.add(Dense(X_train.shape[1]*5, input_dim=X_train.shape[1], activation='relu'))\n    #model.add(Dense(30, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    # Compile model\n    #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.FalseNegatives(),tf.keras.metrics.FalsePositives()])\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[scania_score_tensor])\n    \n    return model\n        \n        \ndef selectAndFitModel(X,y,model_type=None):\n    print(model_type)\n    myModel=None\n    if(model_type=='svm'):\n        params = [{'kernel': ['rbf'], 'gamma': [0.01], 'C': [0.001, 0.01, 0.1, 1, 10]}]\n        grid_search = GridSearchCV(svm.SVC(C=1), params, cv=2, scoring=my_scania_scorer, verbose=10, n_jobs=-1)\n        start = time()\n        grid_search.fit(X, y)\n        print(grid_search.best_params_)\n        myModel = svm.SVC(**grid_search.best_params_,probability=True)\n    elif(model_type=='nn'):\n        myModel=KerasClassifier(makeNnModel, epochs=500, batch_size=50, verbose=1)\n    elif(model_type=='randomForest'):\n        myModel = RandomForestClassifier(criterion='entropy', max_depth=16, max_features=37, n_estimators=295,random_state=1)\n    elif(model_type=='randomForestReg'):\n        myModel = RandomForestRegressor(n_estimators=250, random_state=1, n_jobs=-1)\n    else:\n        myModel = XGBClassifier(learning_rate = 0.05, n_estimators=200, max_depth=4, random_state=1)\n    myModel.fit(X, y)\n    return myModel","f565f746":"from sklearn.feature_selection import SelectFromModel\nfrom numpy import sort\n\ndef predict(model,X_train,X_test,y_train,y_test,regression=False):\n    global logging\n    if(logging):\n        print(X_train.shape)\n    y_pred = model.predict(X_test)\n    if(regression):\n        y_pred = np.round(y_pred)\n    print_all_scores(y_test, y_pred)\n    score=scania_scorer(y_test, y_pred)\n    return score\n\n#model=predict(X_train,X_test)","902283c0":"def trainWithFSelect(model,threshold,X_train,y_train,X_test,y_test):\n    global logging\n\n    \n    selection = SelectFromModel(model, threshold=threshold, prefit=True)\n    select_X_train = selection.transform(X_train)\n    select_X_test = selection.transform(X_test)\n    \n    selection_model = model\n    selection_model.fit(select_X_train, y_train)\n    # eval model\n    \n    #select_X_test = selection.transform(np.nan_to_num(X_test,True))\n    #select_X_test = X_test.loc[:,selection.get_support()].to_numpy()\n    #select_X_test.columns=select_X_train.columns\n    \n    y_pred = selection_model.predict(select_X_test)\n    #print(select_X_test.shape)\n    predictions = [round(value) for value in y_pred]\n    \n    score=scania_scorer(y_test, y_pred)\n    if(logging):\n        print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred))\n        print(\">>>\",score,\"<<<\")\n    \n    return selection_model,select_X_test,score\n    #print_all_scores(y_test, y_pred)\n#    print(\"Thresh=%.7f, n=%d, Score: %d\" % (threshold, select_X_train.shape[1], scania_scorer(y_test, predictions)))\n    \n    \ndef showFeatureSelectionWithModelSelect(model,X_train,y_train,X_test,y_test):\n    thresholds = sort(model.feature_importances_)\n    for thresh in thresholds:\n        trainWithFSelect(model,thresh,X_train,y_train,X_test,y_test)\n\n\n#reduced_X_Model,reduced_X_test = trainWithFSelect(model,0.00141,X_train,y_train,X_test,y_test)\n##print(X_train.columns)","c2e3c8c0":"from tqdm.notebook import tqdm\n\n#https:\/\/www.kaggle.com\/amirz79\/random-forest-8390-vs-catboost-xgboost\n#X&y test\ndef findBestProbabilties(trainedModel,X,y):\n    global logging\n    scores = trainedModel.predict_proba(X)[:,1]\n    fpr, tpr, thresholds = roc_curve(y, scores)\n    min_cost = np.inf\n    best_threshold = 0.5\n    costs = []\n    innerThresholds=tqdm(thresholds)\n    if(not logging):\n        innerThresholds=thresholds\n    for threshold in innerThresholds:\n        y_pred_threshold = scores > threshold\n        tn, fp, fn, tp = confusion_matrix(y, y_pred_threshold).ravel()\n        cost = 10*fp + 500*fn\n        costs.append(cost)\n        if cost < min_cost:\n            min_cost = cost\n            best_threshold = threshold\n    if(logging):\n        print(\"Best threshold: {:.4f}\".format(best_threshold))\n        print(\"Min cost: {:.2f}\".format(min_cost))\n    else:\n        return min_cost","fd76be84":"#findBestProbabilties(reduced_X_Model,reduced_X_test)","5e42fe9f":"from hyperopt import fmin, tpe, hp, anneal, Trials\n\ndef solve(doNormalize=False,\n            histogramBasedFSelect=False,\n            deleteMissingValCols=True,\n            dropConstant=True,\n            doImpute=True,\n            doImputeTest=False,\n            doResample=True,\n            doFselection=False,\n            doFselectWithModel=True,\n            doThresholdMagic=True,\n            model_type=None,\n            regression_round_pred=False):\n    global X_train,X_test,y_train,y_test\n    result=float('inf')\n    if(histogramBasedFSelect):\n        addSystemAge(X_train)\n        addSystemAge(X_test)\n        addAvg(X_train)\n        addAvg(X_test)\n    if(deleteMissingValCols):\n        delete_missing_values_table(X_train,X_test)\n    if(dropConstant):\n        dropConstantFeatures(X_train,X_test)\n    if(doNormalize):\n        X_train=normalize(X_train)\n        X_test=normalize(X_test)\n    if(doImpute):\n        X_train=impute(X_train)\n    if(doImputeTest):\n        X_test=impute(X_test)\n    else:\n        X_test=pd.DataFrame(np.nan_to_num(X_test), columns=X_test.columns)\n    if(doResample):\n        X_train,y_train = resample(X_train,y_train,strategy=1)\n    if(doFselection):\n        selectFeatures(X_train,X_test,y=y_train)\n    model=selectAndFitModel(X_train,y_train,model_type=model_type)\n    result = predict(model,X_train,X_test,y_train,y_test,regression_round_pred)\n    if(doFselectWithModel):\n        reduced_X_Model,reduced_X_test,result = trainWithFSelect(model,0.00141,X_train,y_train,X_test,y_test)\n    if(doThresholdMagic):\n        if(doFselectWithModel):\n            result =findBestProbabilties(reduced_X_Model,reduced_X_test,y_test)\n        else:\n            result =findBestProbabilties(model,X_test,y_test)\n    return result\n\ndoNormalize=False\nhistogramBasedFSelect=False\ndeleteMissingValCols=True\ndropConstant=True\ndoImpute=True\ndoImputeTest=False\ndoResample=True\ndoFselection=False\ndoFselectWithModel=True\ndoThresholdMagic=True\nmodel_type='xgb'\nregression_round_pred=False\n\nlogging=True\n\n#X_train.replace('na','-1', inplace=True)\n#X_test.replace('na','-1', inplace=True)\n#X_train=pd.DataFrame(np.nan_to_num(X_train), columns=X_train.columns)\n#X_test=pd.DataFrame(np.nan_to_num(X_test), columns=X_test.columns)\n    \nsolve(doNormalize,\n    histogramBasedFSelect,\n    deleteMissingValCols,\n    dropConstant,\n    doImpute,\n    doImputeTest,\n    doResample,\n    doFselection,\n    doFselectWithModel,\n    doThresholdMagic,\n    model_type,\n    regression_round_pred) ","9004230d":"tweak probability thresholds","5f54b725":"# Select and Train Model","f51e4b64":"# Select Features with ModelSelect","55aa57d4":"# Balance\n\nfor pipeline: https:\/\/imbalanced-learn.readthedocs.io\/en\/stable\/auto_examples\/plot_outlier_rejections.html#sphx-glr-auto-examples-plot-outlier-rejections-py\n","0daab93f":"# Null values","8aee2961":"# Impute","c69379e7":"# Scoring function","1ef52074":"# Feature Selection using deeper Understanding of the Data","71d7a8eb":"Learnings:\nacuracy_score is not good for an unbalanced dataset\nBetter use Confusion Matrix\n![image.png](attachment:image.png)\nOr MCC or F1\n\nCompetition score:\nCost_1 = False Positives\nCost_2 = False Negatives\nTotal Cost = FP*10 + 500 FN","5e1a5b9e":"# Feature selection\n\n","063358c6":"### Selection using SelectK best or PCA","7feb7e6e":"# Normalize","49464f16":"# Constant features","9b20066a":"# Prediction","4a3466a1":"# Hyperparameter Optimisation with HyperOpt"}}