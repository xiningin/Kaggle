{"cell_type":{"f5ed2733":"code","3ee04282":"code","3f980e2f":"code","32122c22":"code","55dcddd8":"code","7d89ac66":"code","c4592ee0":"code","bca10c8e":"code","217c9855":"code","93fd7fd9":"code","8b77f0cb":"code","f1fa557c":"code","d7d9c8f0":"code","c072a1c4":"code","95822627":"code","30c172c5":"code","88fb6201":"code","b8ef3538":"code","0e92aeca":"code","da3bfc4c":"code","2815f01f":"code","a5169754":"code","cee18bfc":"code","13370988":"code","04d28492":"code","2e800d1e":"code","83725347":"code","f7120d20":"code","fe817646":"code","4020cbc1":"code","bc40e58f":"code","0b950255":"code","66bf468f":"code","d53f3f5a":"code","815818d7":"code","e632b9b6":"code","15ed8218":"code","fdaeaa86":"code","74c22b8d":"code","22e32724":"code","0807c26f":"code","a3113c00":"code","5efd3c2c":"code","80c5cc3d":"code","27e2329d":"code","b57ce7d3":"code","85c866d3":"code","6a1aae37":"code","ce6e037e":"code","2a4f9d10":"code","7838aebb":"code","52471bfb":"code","44a03bc1":"code","ddfd6c52":"code","07b178cf":"code","7e260fcc":"markdown","260e5d5b":"markdown","54df9e9c":"markdown","19de8f6c":"markdown","45d60340":"markdown","ddbe7e11":"markdown","df1b8c89":"markdown","5be15550":"markdown","7085de63":"markdown","3a492473":"markdown","28840202":"markdown","ceb6e262":"markdown","a719739b":"markdown","42bcee61":"markdown","2bbe2ea7":"markdown","7ad4d841":"markdown","28755172":"markdown","9b2b4b8c":"markdown","f0eea54e":"markdown","f4ae3cf7":"markdown","eef6e83b":"markdown","b8a4a85a":"markdown","7fabb4da":"markdown","0cb1f0f3":"markdown","f4d262c7":"markdown","38043358":"markdown","c66f43bc":"markdown","352f07f4":"markdown","dfca6b02":"markdown","69c41165":"markdown","e0bbbae2":"markdown","107d83e8":"markdown","491d6231":"markdown","21f637a9":"markdown","e27a8dd3":"markdown","07dd6bfa":"markdown","9cdc5e62":"markdown","3eafeded":"markdown","ec98a2d0":"markdown"},"source":{"f5ed2733":"import warnings\nwarnings.filterwarnings('ignore')","3ee04282":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","3f980e2f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sn\n\n%matplotlib inline","32122c22":"data = pd.read_csv('..\/input\/heart.csv')\ndata.head(2)","55dcddd8":"data.info()","7d89ac66":"print('Number of rows in the dataset: ',data.shape[0])\nprint('Number of columns in the dataset: ',data.shape[1])","c4592ee0":"data.isnull().sum()","bca10c8e":"data.describe()","217c9855":"male = len(data[data.sex == 1])\nfemale = len(data[data.sex == 0])\nplt.pie(x=[male, female], explode=(0, 0), labels=['Male', 'Female'], autopct='%1.2f%%', shadow=True, startangle=90)\nplt.show()","93fd7fd9":"sn.countplot('sex',hue='target', data=data, palette='mako_r')\nplt.title('Heart Disease Frequency for Sex')\nplt.xlabel('Sex (0 = Female, 1 = Male)')\nplt.xticks(rotation=0)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.ylabel('Frequency')\nplt.show()","8b77f0cb":"x = [len(data[data['cp'] == 0]),len(data[data['cp'] == 1]), len(data[data['cp'] == 2]), len(data[data['cp'] == 3])]\nplt.pie(x, data=data, labels=['CP(1) typical angina', 'CP(2) atypical angina', 'CP(3) non-anginal pain', 'CP(4) asymptomatic'], autopct='%1.2f%%', shadow=True,startangle=90)\nplt.show()","f1fa557c":"sn.countplot('cp',hue='target', data=data, palette='mako_r')\nplt.title('Heart Disease Frequency for chest pain type')\nplt.xlabel('Chest pain type')\nplt.xticks(np.arange(4), [1, 2, 3, 4], rotation=0)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.ylabel('Frequency')\nplt.show()","d7d9c8f0":"sizes = [len(data[data.fbs == 0]), len(data[data.fbs==1])]\nlabels = ['No', 'Yes']\nplt.pie(x=sizes, labels=labels, explode=(0.1, 0), autopct=\"%1.2f%%\", startangle=90,shadow=True)\nplt.show()","c072a1c4":"sn.countplot('fbs', hue='target', data=data, palette='mako_r')\nplt.title('Heart Disease Frequency for fbs')\nplt.xticks(rotation=0)\nplt.xlabel('fbs > 120 mg\/dl (1 = true; 0 = false)')\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.ylabel('Frequency')\nplt.show()","95822627":"sizes = [len(data[data.restecg == 0]), len(data[data.restecg==1]), len(data[data.restecg==2])]\nlabels = ['Normal', 'ST-T wave abnormality', 'definite left ventricular hypertrophy by Estes criteria']\nplt.pie(x=sizes, labels=labels, explode=(0, 0, 0), autopct=\"%1.2f%%\", startangle=90,shadow=True)\nplt.show()","30c172c5":"sn.countplot('restecg', hue='target', data=data, palette='mako_r')\nplt.title('Heart Disease Frequency for restecg')\nplt.xlabel('Resting electrocardiographic measurement')\nplt.xticks(rotation=0)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.ylabel('Frequency')\nplt.show()","88fb6201":"sizes = [len(data[data.exang == 0]), len(data[data.exang==1])]\nlabels = ['No', 'Yes']\nplt.pie(x=sizes, labels=labels, explode=(0.1, 0), autopct=\"%1.2f%%\", startangle=90,shadow=True)\nplt.show()","b8ef3538":"sn.countplot('exang', hue='target', data=data, palette='mako_r')\nplt.title('Heart Disease Frequency for exang')\nplt.xlabel('exercise induced angina (1=Yes: 0=No)')\nplt.xticks(rotation=0)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.ylabel('Frequency')\nplt.show()","0e92aeca":"sizes = [len(data[data.slope == 0]), len(data[data.slope==1]), len(data[data.slope==2])]\nlabels = ['Upsloping', 'Flat', 'Downssloping']\nplt.pie(x=sizes, labels=labels, explode=(0, 0, 0), autopct=\"%1.2f%%\", startangle=90,shadow=True)\nplt.show()","da3bfc4c":"sn.countplot('slope', hue='target', data=data, palette='mako_r')\nplt.title('Heart Disease Frequency for slope')\nplt.xlabel('The Slope of The Peak Exercise ST Segment')\nplt.xticks(rotation=0)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.ylabel('Frequency')\nplt.show()","2815f01f":"sn.countplot('thal', data=data)\nplt.title('Frequency for thal')\nplt.ylabel('Frequency')\nplt.show()","a5169754":"sn.countplot('thal', hue='target', data=data, palette='mako_r')\nplt.title('Heart Disease Frequency for thal')\nplt.xticks(rotation=0)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.ylabel('Frequency')\nplt.show()","cee18bfc":"data.age.hist(bins=30)\nplt.show()","13370988":"plt.figure(figsize=(20, 6))\nsn.countplot('age', hue='target', data=data)\nplt.title('Heart Disease Frequency for Age')\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.ylabel('Frequency')\nplt.show()","04d28492":"plt.hist([data.chol[data.target==0], data.chol[data.target==1]], bins=20,color=['green', 'orange'], stacked=True)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.title('Heart Disease Frequency for cholestoral ')\nplt.ylabel('Frequency')\nplt.plot()","2e800d1e":"plt.hist([data.thalach[data.target==0], data.thalach[data.target==1]], bins=20,color=['green', 'orange'], stacked=True)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.title('Heart Disease Frequency for maximum heart rate achieved')\nplt.ylabel('Frequency')\nplt.plot()","83725347":"plt.figure(figsize=(12, 12))\nsn.heatmap(data.corr(), annot=True, fmt='.1f')\nplt.show()","f7120d20":"cp = pd.get_dummies(data['cp'], prefix = \"cp\", drop_first=True)\nthal = pd.get_dummies(data['thal'], prefix = \"thal\" , drop_first=True)\nslope = pd.get_dummies(data['slope'], prefix = \"slope\", drop_first=True)","fe817646":"new_data = pd.concat([data, cp, thal, slope], axis=1)\nnew_data.head()","4020cbc1":"new_data.drop(['cp', 'thal', 'slope'], axis=1, inplace=True)\nnew_data.head()","bc40e58f":"# removing target columns from dataset\nX = new_data.drop(['target'], axis=1)\ny = new_data.target","0b950255":"print(X.shape)","66bf468f":"X = (X - X.min())\/(X.max()-X.min())\nX.head()","d53f3f5a":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)","815818d7":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\n# checking the score at test data\nlr.score(X_test, y_test)","e632b9b6":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, lr.predict(X_test))\nsn.heatmap(cm, annot=True)\nplt.plot()","15ed8218":"from sklearn.model_selection import GridSearchCV","fdaeaa86":"# Setting parameters for GridSearchCV\nparams = {'penalty':['l1','l2'],\n         'C':[0.01,0.1,1,10,100],\n         'class_weight':['balanced',None]}\nlr_model = GridSearchCV(lr,param_grid=params,cv=10)","74c22b8d":"lr_model.fit(X_train,y_train)\nlr_model.best_params_","22e32724":"lr = LogisticRegression(C=1, penalty='l2')\nlr.fit(X_train, y_train)\nlr.score(X_test, y_test)","0807c26f":"# measure the quality of predictions\nfrom sklearn.metrics import auc, classification_report\nprint(classification_report(y_test, lr.predict(X_test)))","a3113c00":"from sklearn.svm import SVC\nsvc = SVC(kernel='linear')\nsvc.fit(X_train, y_train)\nsvc.score(X_test, y_test)","5efd3c2c":"cm = confusion_matrix(y_test, svc.predict(X_test))\nsn.heatmap(cm, annot=True)\nplt.plot()","80c5cc3d":"from sklearn.ensemble import RandomForestClassifier\nparams = {'n_estimators':list(range(10,30)),\n         'max_depth':list(range(1,7))}\nrf_model = GridSearchCV(RandomForestClassifier(),param_grid=params,cv=10)\nrf_model.fit(X_train,y_train)\nrf_model.best_params_ ","27e2329d":"rfc = RandomForestClassifier(max_depth= 3, n_estimators= 17, random_state=2)\nrfc.fit(X_train, y_train)\nrfc.score(X_test, y_test)","b57ce7d3":"cm = confusion_matrix(y_test, rfc.predict(X_test))\nsn.heatmap(cm, annot=True)\nplt.plot()","85c866d3":"# measure the quality of predictions\nprint(classification_report(y_test, rfc.predict(X_test)))","6a1aae37":"from sklearn.ensemble import GradientBoostingClassifier\ngbc = GradientBoostingClassifier()\ngbc.fit(X_train, y_train)\ngbc.score(X_test, y_test)","ce6e037e":"cm = confusion_matrix(y_test, gbc.predict(X_test))\nsn.heatmap(cm, annot=True)\nplt.plot()","2a4f9d10":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(X_train, y_train)\nnb.score(X_test, y_test)","7838aebb":"cm = confusion_matrix(y_test, nb.predict(X_test))\nsn.heatmap(cm, annot=True)\nplt.plot()","52471bfb":"# measure the quality of predictions\nprint(classification_report(y_test, nb.predict(X_test)))","44a03bc1":"# Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores\nfrom sklearn.metrics import roc_auc_score\nprint(roc_auc_score(y_test, nb.predict(X_test)))","ddfd6c52":"algo = ['LogisticRegression', 'SVC', 'RandomForest', 'GaussianNB', 'GradientBoosting']\nscore = [al.score(X_test, y_test) for al in [lr, svc,rfc, nb, gbc]] ","07b178cf":"plt.grid()\nplt.bar(x=algo, height=score, color=['red','green','b','pink','orange'])\nplt.xticks(rotation=90)\nplt.ylim((0,1))\nplt.yticks(np.arange(0,1.1,0.1))\nplt.show()","7e260fcc":"**7. Age :**\n","260e5d5b":"<font color='green'>There are no null values in the dataset<\/font>","54df9e9c":"## Support Vector Machine","19de8f6c":"We don't need cp, thal, slope columns so we will drop them","45d60340":"**1. Sex**","ddbe7e11":"Our model is giving good result.","df1b8c89":"<br>\n\n<font size=4px>Dataset Columns (Features)<\/font>","5be15550":"# Random Forest Classifier","7085de63":"**3. fbs (asting blood sugar)**\n<p>(fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)<\/p>","3a492473":"# Data Preprocessing \nDatasets contains Categorical Data so we have to create dummy variables.<br>\n'cp', 'thal' and 'slope' are categorical variables","28840202":"**Normalize the data**\n<img src=\"https:\/\/beyondbacktesting.files.wordpress.com\/2017\/07\/normalization.png?w=863\" \/>","ceb6e262":"**9. thalach :**\nmaximum heart rate achieved\n","a719739b":"**Descriptive statistics Generation.**","42bcee61":"**Confusion Matrix**","2bbe2ea7":"**6. thal :**\nA blood disorder called thalassemia","7ad4d841":"We will split our data. 80% of our data will be train data and 20% of it will be test data.","28755172":"<br>\n**Dimensions of the data : **","9b2b4b8c":"* Age (age in years)\n* Sex (1 = male; 0 = female)\n* CP (chest pain type)\n* TRESTBPS (resting blood pressure (in mm Hg on admission to the hospital))\n* CHOL (serum cholestoral in mg\/dl)\n* FPS (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n* RESTECH (resting electrocardiographic results)\n* THALACH (maximum heart rate achieved)\n* EXANG (exercise induced angina (1 = yes; 0 = no))\n* OLDPEAK (ST depression induced by exercise relative to rest)\n* SLOPE (the slope of the peak exercise ST segment)\n* CA (number of major vessels (0-3) colored by flourosopy)\n* THAL (3 = normal; 6 = fixed defect; 7 = reversable defect)\n* TARGET (1 or 0)","f0eea54e":"If you find this kernel helpful, Please <font color=\"red\"><b>UPVOTES<\/b><\/font>.","f4ae3cf7":"**2. CP (chest pain type)**","eef6e83b":"<br>\n\n<font size=4px>Importing some useful libraries<\/font>","b8a4a85a":"**Concise summary of a Data**","7fabb4da":"**5. Slope :**\nThe slope of the peak exercise ST segment\n","0cb1f0f3":"<br>\n**Missing values detection :**","f4d262c7":"**3.restecg**\n(resting electrocardiographic results)","38043358":"# Train the Models","c66f43bc":"<font color=red>We use drop_first to get k-1 dummies out of k categorical levels by removing the first level.<\/font>","352f07f4":"**4. exang**\n(exercise induced angina)","dfca6b02":"**8. Chol :**\nserum cholestoral in mg\/dl\n\n<font color='red'>Here we ca see, how Disease depends on cholestoral.","69c41165":"Confusion Matrix","e0bbbae2":"# INTRODUCTION","107d83e8":"<br>\n\n<font color='skyblue' size=3xp>**Checking how the target values depend on various features.**<font>","491d6231":"# Gradient Boosting Classifies","21f637a9":"### Logistic Regression","e27a8dd3":"<br>\n\n<font size=4px>Loading the data<\/font>","07dd6bfa":"# All Algo's Score","9cdc5e62":"<br>\n\n# Data Exploration","3eafeded":"We have a data which classified if patients have heart disease or not according to features in it. In particular, the Cleveland database is the only one that has been used by ML researchers to this date. The \"goal\" field refers to the presence of heart disease in the patient. In addition, we will analyze for this dataset. We will use a wide range of tools for this part. If there's value in there, we'il do it there. Finally, machine learning algorithms are estimated.","ec98a2d0":"# Gaussian NB"}}