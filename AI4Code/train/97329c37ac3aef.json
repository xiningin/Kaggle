{"cell_type":{"f482750c":"code","46ec5e80":"code","46b01da2":"code","d20c8b6b":"code","3b6329e1":"code","8ffb2024":"code","b403eed3":"code","f88c2ded":"code","76e54aea":"code","60396e22":"code","f5a48fb6":"code","cfe66119":"code","9386a1b5":"code","2ea465da":"code","57526d92":"code","9372e3ef":"code","f9e31530":"code","878082c3":"code","cd1e9a7d":"code","b7e19931":"code","3c11b21b":"code","5ad9be18":"code","21cd99db":"code","21e6a22e":"code","c682475e":"markdown","a957e9e7":"markdown","416b7a64":"markdown","20af742e":"markdown","026c1ac1":"markdown","3dc53d70":"markdown","16f47739":"markdown","4300c27a":"markdown","ae454355":"markdown","3f69ceb2":"markdown","5c6867da":"markdown","ad56332b":"markdown","9700bfe1":"markdown","1203fadc":"markdown","b08893c5":"markdown","02050d37":"markdown","3435f992":"markdown","df8548fd":"markdown","664393b2":"markdown","267efa4a":"markdown"},"source":{"f482750c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport re\nimport gensim\nfrom nltk.tokenize import word_tokenize\nimport string\n\nfrom tqdm import tqdm\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, LSTM,Dense, SpatialDropout1D, Dropout\nfrom keras.initializers import Constant\nfrom keras.optimizers import Adam\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow_hub as hub\n\nimport torch\n\nimport warnings\nwarnings.simplefilter('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","46ec5e80":"# import nltk\n# nltk.download('wordnet')\n!wget https:\/\/raw.githubusercontent.com\/tensorflow\/models\/master\/official\/nlp\/bert\/tokenization.py","46b01da2":"import tokenization","d20c8b6b":"def remove_URL(text):\n    url = re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    return url.sub(r'',text)\n\ndef remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\n\n# Reference : https:\/\/gist.github.com\/slowkow\/7a7f61f495e3dbb7e3d767f97bd7304b\ndef remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\ndef remove_punct(text):\n    table=str.maketrans('','',string.punctuation)\n    return text.translate(table)\n\ndef remove_numbers(text):\n    text = ''.join([i for i in text if not i.isdigit()])         \n    return text","3b6329e1":"# Thanks to https:\/\/www.kaggle.com\/rftexas\/text-only-kfold-bert\nabbreviations = {\n    \"$\" : \" dollar \",\n    \"\u20ac\" : \" euro \",\n    \"4ao\" : \"for adults only\",\n    \"a.m\" : \"before midday\",\n    \"a3\" : \"anytime anywhere anyplace\",\n    \"aamof\" : \"as a matter of fact\",\n    \"acct\" : \"account\",\n    \"adih\" : \"another day in hell\",\n    \"afaic\" : \"as far as i am concerned\",\n    \"afaict\" : \"as far as i can tell\",\n    \"afaik\" : \"as far as i know\",\n    \"afair\" : \"as far as i remember\",\n    \"afk\" : \"away from keyboard\",\n    \"app\" : \"application\",\n    \"approx\" : \"approximately\",\n    \"apps\" : \"applications\",\n    \"asap\" : \"as soon as possible\",\n    \"asl\" : \"age, sex, location\",\n    \"atk\" : \"at the keyboard\",\n    \"ave.\" : \"avenue\",\n    \"aymm\" : \"are you my mother\",\n    \"ayor\" : \"at your own risk\", \n    \"b&b\" : \"bed and breakfast\",\n    \"b+b\" : \"bed and breakfast\",\n    \"b.c\" : \"before christ\",\n    \"b2b\" : \"business to business\",\n    \"b2c\" : \"business to customer\",\n    \"b4\" : \"before\",\n    \"b4n\" : \"bye for now\",\n    \"b@u\" : \"back at you\",\n    \"bae\" : \"before anyone else\",\n    \"bak\" : \"back at keyboard\",\n    \"bbbg\" : \"bye bye be good\",\n    \"bbc\" : \"british broadcasting corporation\",\n    \"bbias\" : \"be back in a second\",\n    \"bbl\" : \"be back later\",\n    \"bbs\" : \"be back soon\",\n    \"be4\" : \"before\",\n    \"bfn\" : \"bye for now\",\n    \"blvd\" : \"boulevard\",\n    \"bout\" : \"about\",\n    \"brb\" : \"be right back\",\n    \"bros\" : \"brothers\",\n    \"brt\" : \"be right there\",\n    \"bsaaw\" : \"big smile and a wink\",\n    \"btw\" : \"by the way\",\n    \"bwl\" : \"bursting with laughter\",\n    \"c\/o\" : \"care of\",\n    \"cet\" : \"central european time\",\n    \"cf\" : \"compare\",\n    \"cia\" : \"central intelligence agency\",\n    \"csl\" : \"can not stop laughing\",\n    \"cu\" : \"see you\",\n    \"cul8r\" : \"see you later\",\n    \"cv\" : \"curriculum vitae\",\n    \"cwot\" : \"complete waste of time\",\n    \"cya\" : \"see you\",\n    \"cyt\" : \"see you tomorrow\",\n    \"dae\" : \"does anyone else\",\n    \"dbmib\" : \"do not bother me i am busy\",\n    \"diy\" : \"do it yourself\",\n    \"dm\" : \"direct message\",\n    \"dwh\" : \"during work hours\",\n    \"e123\" : \"easy as one two three\",\n    \"eet\" : \"eastern european time\",\n    \"eg\" : \"example\",\n    \"embm\" : \"early morning business meeting\",\n    \"encl\" : \"enclosed\",\n    \"encl.\" : \"enclosed\",\n    \"etc\" : \"and so on\",\n    \"faq\" : \"frequently asked questions\",\n    \"fawc\" : \"for anyone who cares\",\n    \"fb\" : \"facebook\",\n    \"fc\" : \"fingers crossed\",\n    \"fig\" : \"figure\",\n    \"fimh\" : \"forever in my heart\", \n    \"ft.\" : \"feet\",\n    \"ft\" : \"featuring\",\n    \"ftl\" : \"for the loss\",\n    \"ftw\" : \"for the win\",\n    \"fwiw\" : \"for what it is worth\",\n    \"fyi\" : \"for your information\",\n    \"g9\" : \"genius\",\n    \"gahoy\" : \"get a hold of yourself\",\n    \"gal\" : \"get a life\",\n    \"gcse\" : \"general certificate of secondary education\",\n    \"gfn\" : \"gone for now\",\n    \"gg\" : \"good game\",\n    \"gl\" : \"good luck\",\n    \"glhf\" : \"good luck have fun\",\n    \"gmt\" : \"greenwich mean time\",\n    \"gmta\" : \"great minds think alike\",\n    \"gn\" : \"good night\",\n    \"g.o.a.t\" : \"greatest of all time\",\n    \"goat\" : \"greatest of all time\",\n    \"goi\" : \"get over it\",\n    \"gps\" : \"global positioning system\",\n    \"gr8\" : \"great\",\n    \"gratz\" : \"congratulations\",\n    \"gyal\" : \"girl\",\n    \"h&c\" : \"hot and cold\",\n    \"hp\" : \"horsepower\",\n    \"hr\" : \"hour\",\n    \"hrh\" : \"his royal highness\",\n    \"ht\" : \"height\",\n    \"ibrb\" : \"i will be right back\",\n    \"ic\" : \"i see\",\n    \"icq\" : \"i seek you\",\n    \"icymi\" : \"in case you missed it\",\n    \"idc\" : \"i do not care\",\n    \"idgadf\" : \"i do not give a damn fuck\",\n    \"idgaf\" : \"i do not give a fuck\",\n    \"idk\" : \"i do not know\",\n    \"ie\" : \"that is\",\n    \"i.e\" : \"that is\",\n    \"ifyp\" : \"i feel your pain\",\n    \"IG\" : \"instagram\",\n    \"iirc\" : \"if i remember correctly\",\n    \"ilu\" : \"i love you\",\n    \"ily\" : \"i love you\",\n    \"imho\" : \"in my humble opinion\",\n    \"imo\" : \"in my opinion\",\n    \"imu\" : \"i miss you\",\n    \"iow\" : \"in other words\",\n    \"irl\" : \"in real life\",\n    \"j4f\" : \"just for fun\",\n    \"jic\" : \"just in case\",\n    \"jk\" : \"just kidding\",\n    \"jsyk\" : \"just so you know\",\n    \"l8r\" : \"later\",\n    \"lb\" : \"pound\",\n    \"lbs\" : \"pounds\",\n    \"ldr\" : \"long distance relationship\",\n    \"lmao\" : \"laugh my ass off\",\n    \"lmfao\" : \"laugh my fucking ass off\",\n    \"lol\" : \"laughing out loud\",\n    \"ltd\" : \"limited\",\n    \"ltns\" : \"long time no see\",\n    \"m8\" : \"mate\",\n    \"mf\" : \"motherfucker\",\n    \"mfs\" : \"motherfuckers\",\n    \"mfw\" : \"my face when\",\n    \"mofo\" : \"motherfucker\",\n    \"mph\" : \"miles per hour\",\n    \"mr\" : \"mister\",\n    \"mrw\" : \"my reaction when\",\n    \"ms\" : \"miss\",\n    \"mte\" : \"my thoughts exactly\",\n    \"nagi\" : \"not a good idea\",\n    \"nbc\" : \"national broadcasting company\",\n    \"nbd\" : \"not big deal\",\n    \"nfs\" : \"not for sale\",\n    \"ngl\" : \"not going to lie\",\n    \"nhs\" : \"national health service\",\n    \"nrn\" : \"no reply necessary\",\n    \"nsfl\" : \"not safe for life\",\n    \"nsfw\" : \"not safe for work\",\n    \"nth\" : \"nice to have\",\n    \"nvr\" : \"never\",\n    \"nyc\" : \"new york city\",\n    \"oc\" : \"original content\",\n    \"og\" : \"original\",\n    \"ohp\" : \"overhead projector\",\n    \"oic\" : \"oh i see\",\n    \"omdb\" : \"over my dead body\",\n    \"omg\" : \"oh my god\",\n    \"omw\" : \"on my way\",\n    \"p.a\" : \"per annum\",\n    \"p.m\" : \"after midday\",\n    \"pm\" : \"prime minister\",\n    \"poc\" : \"people of color\",\n    \"pov\" : \"point of view\",\n    \"pp\" : \"pages\",\n    \"ppl\" : \"people\",\n    \"prw\" : \"parents are watching\",\n    \"ps\" : \"postscript\",\n    \"pt\" : \"point\",\n    \"ptb\" : \"please text back\",\n    \"pto\" : \"please turn over\",\n    \"qpsa\" : \"what happens\", #\"que pasa\",\n    \"ratchet\" : \"rude\",\n    \"rbtl\" : \"read between the lines\",\n    \"rlrt\" : \"real life retweet\", \n    \"rofl\" : \"rolling on the floor laughing\",\n    \"roflol\" : \"rolling on the floor laughing out loud\",\n    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n    \"rt\" : \"retweet\",\n    \"ruok\" : \"are you ok\",\n    \"sfw\" : \"safe for work\",\n    \"sk8\" : \"skate\",\n    \"smh\" : \"shake my head\",\n    \"sq\" : \"square\",\n    \"srsly\" : \"seriously\", \n    \"ssdd\" : \"same stuff different day\",\n    \"tbh\" : \"to be honest\",\n    \"tbs\" : \"tablespooful\",\n    \"tbsp\" : \"tablespooful\",\n    \"tfw\" : \"that feeling when\",\n    \"thks\" : \"thank you\",\n    \"tho\" : \"though\",\n    \"thx\" : \"thank you\",\n    \"tia\" : \"thanks in advance\",\n    \"til\" : \"today i learned\",\n    \"tl;dr\" : \"too long i did not read\",\n    \"tldr\" : \"too long i did not read\",\n    \"tmb\" : \"tweet me back\",\n    \"tntl\" : \"trying not to laugh\",\n    \"ttyl\" : \"talk to you later\",\n    \"u\" : \"you\",\n    \"u2\" : \"you too\",\n    \"u4e\" : \"yours for ever\",\n    \"utc\" : \"coordinated universal time\",\n    \"w\/\" : \"with\",\n    \"w\/o\" : \"without\",\n    \"w8\" : \"wait\",\n    \"wassup\" : \"what is up\",\n    \"wb\" : \"welcome back\",\n    \"wtf\" : \"what the fuck\",\n    \"wtg\" : \"way to go\",\n    \"wtpa\" : \"where the party at\",\n    \"wuf\" : \"where are you from\",\n    \"wuzup\" : \"what is up\",\n    \"wywh\" : \"wish you were here\",\n    \"yd\" : \"yard\",\n    \"ygtr\" : \"you got that right\",\n    \"ynk\" : \"you never know\",\n    \"zzz\" : \"sleeping bored and tired\"\n}","8ffb2024":"# Thanks to https:\/\/www.kaggle.com\/rftexas\/text-only-kfold-bert\ndef convert_abbrev(word):\n    return abbreviations[word.lower()] if word.lower() in abbreviations.keys() else word\n\ndef convert_abbrev_in_text(text):\n    tokens = word_tokenize(text)\n    tokens = [convert_abbrev(word) for word in tokens]\n    text = ' '.join(tokens)\n    return text","b403eed3":"train = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntest = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')\nsubmission = pd.read_csv(\"..\/input\/nlp-getting-started\/sample_submission.csv\")","f88c2ded":"train.head()","76e54aea":"test.head()","60396e22":"train['text']=train['text'].apply(lambda x : remove_URL(x))\ntrain['text']=train['text'].apply(lambda x : remove_html(x))\ntrain['text']=train['text'].apply(lambda x : remove_emoji(x))\ntrain['text']=train['text'].apply(lambda x : remove_punct(x))\ntrain['text']=train['text'].apply(lambda x : remove_numbers(x))\ntrain['text']=train['text'].apply(lambda x : convert_abbrev_in_text(x))","f5a48fb6":"test['text']=test['text'].apply(lambda x : remove_URL(x))\ntest['text']=test['text'].apply(lambda x : remove_html(x))\ntest['text']=test['text'].apply(lambda x : remove_emoji(x))\ntest['text']=test['text'].apply(lambda x : remove_punct(x))\ntest['text']=test['text'].apply(lambda x : remove_numbers(x))\ntest['text']=test['text'].apply(lambda x : convert_abbrev_in_text(x))","cfe66119":"train.head()\n# test.head()","9386a1b5":"random_state_split = 2\nDropout_num = 0\nlearning_rate = 6e-6\nvalid = 0.2\nepochs_num = 3\nbatch_size_num = 16","2ea465da":"# Thanks to https:\/\/www.kaggle.com\/xhlulu\/disaster-nlp-keras-bert-using-tfhub\ndef bert_encode(texts, tokenizer, max_len=512):\n    all_tokens = []\n    all_masks = []\n    all_segments = []\n    \n    for text in texts:\n        text = tokenizer.tokenize(text)\n            \n        text = text[:max_len-2]\n        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n        pad_len = max_len - len(input_sequence)\n        \n        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n        tokens += [0] * pad_len\n        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n        segment_ids = [0] * max_len\n        \n        all_tokens.append(tokens)\n        all_masks.append(pad_masks)\n        all_segments.append(segment_ids)\n    \n    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)","57526d92":"# Thanks to https:\/\/www.kaggle.com\/xhlulu\/disaster-nlp-keras-bert-using-tfhub\ndef build_model(bert_layer, max_len=512):\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n\n    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n    clf_output = sequence_output[:, 0, :]\n    \n    if Dropout_num == 0:\n        # Without Dropout\n        out = Dense(1, activation='sigmoid')(clf_output)\n    else:\n        # With Dropout(Dropout_num), Dropout_num > 0\n        x = Dropout(Dropout_num)(clf_output)\n        out = Dense(1, activation='sigmoid')(x)\n\n    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n    model.compile(Adam(lr=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model","9372e3ef":"# Load BERT from the Tensorflow Hub\nmodule_url = \"https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_L-24_H-1024_A-16\/1\"\nbert_layer = hub.KerasLayer(module_url, trainable=True)","f9e31530":"vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\ndo_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\ntokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)","878082c3":"train_input = bert_encode(train.text.values, tokenizer, max_len=160)\ntest_input = bert_encode(test.text.values, tokenizer, max_len=160)\ntrain_labels = train.target.values","cd1e9a7d":"# Thanks to https:\/\/www.kaggle.com\/xhlulu\/disaster-nlp-keras-bert-using-tfhub\nmodel_BERT = build_model(bert_layer, max_len=160)\nmodel_BERT.summary()","b7e19931":"# Thanks to https:\/\/www.kaggle.com\/xhlulu\/disaster-nlp-keras-bert-using-tfhub\n# Train BERT model with my tuning\ncheckpoint = ModelCheckpoint('model_BERT.h5', monitor='val_loss', save_best_only=True)\n\ntrain_history = model_BERT.fit(\n    train_input, train_labels,\n    validation_split = valid,\n    epochs = epochs_num, # recomended 3-5 epochs\n    callbacks=[checkpoint],\n    batch_size = batch_size_num\n)","3c11b21b":"# Thanks to https:\/\/www.kaggle.com\/xhlulu\/disaster-nlp-keras-bert-using-tfhub\n# Prediction by BERT model with my tuning\nmodel_BERT.load_weights('model_BERT.h5')\ntest_pred_BERT = model_BERT.predict(test_input)\ntest_pred_BERT_int = test_pred_BERT.round().astype('int')","5ad9be18":"# # Prediction by BERT model with my tuning for the training data - for the Confusion Matrix\n# train_pred_BERT = model_BERT.predict(train_input)\n# train_pred_BERT_int = train_pred_BERT.round().astype('int')","21cd99db":"submission['target'] = test_pred_BERT_int\nsubmission.head(10)","21e6a22e":"submission.to_csv(\"submission_BERT_Clean_DONE.csv\", index=False, header=True)","c682475e":"# **6. \u0e2a\u0e23\u0e49\u0e32\u0e07\u0e15\u0e31\u0e27\u0e41\u0e1b\u0e23 tokenizer \u0e41\u0e25\u0e30\u0e19\u0e33\u0e44\u0e1b\u0e43\u0e0a\u0e49\u0e43\u0e19\u0e1f\u0e31\u0e07\u0e01\u0e4c\u0e0a\u0e31\u0e19 bert_encode**\n* train_input \u0e17\u0e33\u0e01\u0e32\u0e23\u0e41\u0e1b\u0e25\u0e07\u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e43\u0e19\u0e0a\u0e38\u0e14\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25 train \u0e40\u0e1b\u0e47\u0e19\u0e40\u0e27\u0e01\u0e40\u0e15\u0e2d\u0e23\u0e4c\u0e02\u0e2d\u0e07\u0e15\u0e31\u0e27\u0e40\u0e25\u0e02 (\u0e04\u0e33\u0e17\u0e35\u0e48\u0e16\u0e39\u0e01\u0e41\u0e17\u0e19\u0e14\u0e49\u0e27\u0e22\u0e04\u0e48\u0e32\u0e15\u0e31\u0e27\u0e40\u0e25\u0e02) \u0e14\u0e49\u0e27\u0e22\u0e1f\u0e31\u0e07\u0e01\u0e4c\u0e0a\u0e31\u0e19 bert_encode<br>\u0e42\u0e14\u0e22\u0e01\u0e33\u0e2b\u0e19\u0e14\u0e08\u0e33\u0e19\u0e27\u0e19 token \u0e43\u0e19\u0e41\u0e15\u0e48\u0e25\u0e30\u0e40\u0e27\u0e01\u0e40\u0e15\u0e2d\u0e23\u0e4c\u0e44\u0e27\u0e49\u0e2a\u0e39\u0e07\u0e2a\u0e38\u0e14\u0e17\u0e35\u0e48 160\n* test_input \u0e17\u0e33\u0e01\u0e32\u0e23\u0e41\u0e1b\u0e25\u0e07\u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e43\u0e19\u0e0a\u0e38\u0e14\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25 test \u0e40\u0e1b\u0e47\u0e19\u0e40\u0e27\u0e01\u0e40\u0e15\u0e2d\u0e23\u0e4c\u0e02\u0e2d\u0e07\u0e15\u0e31\u0e27\u0e40\u0e25\u0e02 (\u0e04\u0e33\u0e17\u0e35\u0e48\u0e16\u0e39\u0e01\u0e41\u0e17\u0e19\u0e14\u0e49\u0e27\u0e22\u0e04\u0e48\u0e32\u0e15\u0e31\u0e27\u0e40\u0e25\u0e02) \u0e14\u0e49\u0e27\u0e22\u0e1f\u0e31\u0e07\u0e01\u0e4c\u0e0a\u0e31\u0e19 bert_encode<br>\u0e42\u0e14\u0e22\u0e01\u0e33\u0e2b\u0e19\u0e14\u0e08\u0e33\u0e19\u0e27\u0e19 token \u0e43\u0e19\u0e41\u0e15\u0e48\u0e25\u0e30\u0e40\u0e27\u0e01\u0e40\u0e15\u0e2d\u0e23\u0e4c\u0e44\u0e27\u0e49\u0e2a\u0e39\u0e07\u0e2a\u0e38\u0e14\u0e17\u0e35\u0e48 160","a957e9e7":"# **5. Download BERT Large \u0e15\u0e32\u0e21\u0e17\u0e35\u0e48\u0e01\u0e25\u0e48\u0e32\u0e27\u0e44\u0e27\u0e49\u0e02\u0e49\u0e32\u0e07\u0e15\u0e49\u0e19**","416b7a64":"# **4. \u0e01\u0e32\u0e23\u0e01\u0e33\u0e2b\u0e19\u0e14\u0e04\u0e48\u0e32\u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e42\u0e21\u0e40\u0e14\u0e25\u0e41\u0e25\u0e30\u0e2b\u0e25\u0e31\u0e01\u0e01\u0e32\u0e23\u0e17\u0e33\u0e07\u0e32\u0e19\u0e02\u0e2d\u0e07 BERT**","20af742e":"### 4.3 \u0e2a\u0e23\u0e49\u0e32\u0e07\u0e1f\u0e31\u0e07\u0e01\u0e4c\u0e0a\u0e31\u0e19\u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a BERT Model\n* \u0e01\u0e33\u0e2b\u0e19\u0e14\u0e04\u0e48\u0e32 input \u0e43\u0e2b\u0e49\u0e01\u0e31\u0e1a\u0e42\u0e21\u0e40\u0e14\u0e25 \u0e43\u0e19\u0e17\u0e35\u0e48\u0e19\u0e35\u0e49\u0e44\u0e14\u0e49\u0e41\u0e01\u0e48 Token, Mask \u0e41\u0e25\u0e30 Segment \u0e15\u0e32\u0e21\u0e1f\u0e31\u0e07\u0e01\u0e4c\u0e0a\u0e31\u0e19 <code>bert_encode<\/code>\n* Optimize \u0e42\u0e21\u0e40\u0e14\u0e25\u0e14\u0e49\u0e27\u0e22\u0e01\u0e32\u0e23\u0e43\u0e0a\u0e49 Adam \u0e43\u0e19\u0e01\u0e32\u0e23\u0e1b\u0e23\u0e31\u0e1a Learning rate \u0e43\u0e2b\u0e49\u0e40\u0e2b\u0e21\u0e32\u0e30\u0e2a\u0e21\u0e43\u0e19\u0e01\u0e32\u0e23\u0e40\u0e17\u0e23\u0e19\u0e41\u0e15\u0e48\u0e25\u0e30\u0e23\u0e2d\u0e1a","026c1ac1":"# \u0e1b\u0e23\u0e30\u0e40\u0e20\u0e17\u0e41\u0e25\u0e30\u0e02\u0e31\u0e49\u0e19\u0e15\u0e2d\u0e19\u0e01\u0e32\u0e23\u0e40\u0e23\u0e35\u0e22\u0e19\u0e23\u0e39\u0e49\u0e02\u0e2d\u0e07 BERT\nBERT \u0e2a\u0e32\u0e21\u0e32\u0e23\u0e16\u0e08\u0e33\u0e41\u0e19\u0e01\u0e2d\u0e2d\u0e01\u0e40\u0e1b\u0e47\u0e19 2 \u0e2a\u0e48\u0e27\u0e19\u0e43\u0e2b\u0e0d\u0e48 \u0e46 \u0e44\u0e14\u0e49\u0e41\u0e01\u0e48\n1. BERT-Base \u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e2a\u0e23\u0e49\u0e32\u0e07\u0e42\u0e21\u0e40\u0e14\u0e25\u0e15\u0e32\u0e21\u0e2b\u0e25\u0e31\u0e01\u0e01\u0e32\u0e23\u0e17\u0e33\u0e07\u0e32\u0e19\u0e02\u0e2d\u0e07 BERT \u0e15\u0e32\u0e21\u0e1b\u0e01\u0e15\u0e34\u0e0b\u0e36\u0e48\u0e07\u0e40\u0e1e\u0e35\u0e22\u0e07\u0e1e\u0e2d\u0e01\u0e31\u0e1a\u0e01\u0e32\u0e23\u0e17\u0e33\u0e07\u0e32\u0e19\u0e41\u0e25\u0e49\u0e27\n2. BERT-Large \u0e08\u0e30\u0e41\u0e15\u0e01\u0e15\u0e48\u0e32\u0e07\u0e01\u0e31\u0e1a\u0e41\u0e1a\u0e1a\u0e41\u0e23\u0e01\u0e15\u0e23\u0e07\u0e17\u0e35\u0e48 Bert Large \u0e19\u0e35\u0e49\u0e08\u0e30\u0e21\u0e35\u0e04\u0e27\u0e32\u0e21\u0e2a\u0e32\u0e21\u0e32\u0e23\u0e16\u0e43\u0e19\u0e01\u0e32\u0e23\u0e1b\u0e23\u0e30\u0e21\u0e27\u0e25\u0e1c\u0e25\u0e17\u0e35\u0e48\u0e2a\u0e39\u0e07\u0e01\u0e27\u0e48\u0e32\u0e40\u0e1b\u0e47\u0e19\u0e40\u0e17\u0e48\u0e32\u0e15\u0e31\u0e27\u0e40\u0e2b\u0e21\u0e32\u0e30\u0e01\u0e31\u0e1a\u0e01\u0e32\u0e23\u0e40\u0e23\u0e35\u0e22\u0e19\u0e23\u0e39\u0e49\u0e01\u0e31\u0e1a\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e17\u0e35\u0e48\u0e21\u0e35\u0e02\u0e19\u0e32\u0e14\u0e43\u0e2b\u0e0d\u0e48\u0e21\u0e32\u0e01\n\n\u0e01\u0e32\u0e23\u0e40\u0e23\u0e35\u0e22\u0e19\u0e23\u0e39\u0e49\u0e02\u0e2d\u0e07 BERT \u0e08\u0e30\u0e41\u0e1a\u0e48\u0e07\u0e2d\u0e2d\u0e01\u0e40\u0e1b\u0e47\u0e19 2 \u0e0a\u0e48\u0e27\u0e07\u0e2a\u0e33\u0e04\u0e31\u0e0d\u0e14\u0e31\u0e07\u0e19\u0e35\u0e49\n<br>1. Pre-training \u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e43\u0e2b\u0e49 BERT \u0e40\u0e23\u0e35\u0e22\u0e19\u0e23\u0e39\u0e49\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e04\u0e43\u0e19\u0e0a\u0e38\u0e14\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e41\u0e25\u0e30\u0e2a\u0e23\u0e49\u0e32\u0e07 Language Model \u0e02\u0e2d\u0e07\u0e21\u0e31\u0e19\u0e02\u0e36\u0e49\u0e19\u0e21\u0e32\u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e17\u0e33\u0e04\u0e27\u0e32\u0e21\u0e40\u0e02\u0e49\u0e32\u0e43\u0e08\u0e42\u0e04\u0e23\u0e07\u0e2a\u0e23\u0e49\u0e32\u0e07\u0e02\u0e2d\u0e07\u0e20\u0e32\u0e29\u0e32\u0e19\u0e31\u0e49\u0e19 \u0e46 \u0e43\u0e19\u0e20\u0e32\u0e1e\u0e23\u0e27\u0e21\n<br>2. Fine-tuning \u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e01\u0e32\u0e23\u0e2a\u0e2d\u0e19\u0e42\u0e21\u0e40\u0e14\u0e25\u0e2d\u0e35\u0e01\u0e04\u0e23\u0e31\u0e49\u0e07\u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e43\u0e2b\u0e49\u0e40\u0e2b\u0e21\u0e32\u0e30\u0e01\u0e31\u0e1a\u0e1b\u0e31\u0e0d\u0e2b\u0e32\u0e17\u0e35\u0e48\u0e1c\u0e39\u0e49\u0e17\u0e33\u0e42\u0e21\u0e40\u0e14\u0e25\u0e15\u0e49\u0e2d\u0e07\u0e01\u0e32\u0e23\u0e41\u0e01\u0e49\u0e1b\u0e31\u0e0d\u0e2b\u0e32","3dc53d70":"# **2. \u0e2a\u0e23\u0e49\u0e32\u0e07\u0e1f\u0e31\u0e07\u0e01\u0e4c\u0e0a\u0e31\u0e19\u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a Clean Data \u0e43\u0e19 Tweets**\n* <code>remove_URL<\/code> \u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e25\u0e1a\u0e25\u0e34\u0e07\u0e01\u0e4c\u0e15\u0e48\u0e32\u0e07 \u0e46 \u0e17\u0e35\u0e48\u0e42\u0e1e\u0e2a\u0e15\u0e4c\u0e21\u0e32\u0e43\u0e19\u0e17\u0e27\u0e35\u0e15\u0e19\u0e31\u0e49\u0e19 \u0e46 \u0e40\u0e0a\u0e48\u0e19 https:\/\/kaggle.com\n* <code>remove_html<\/code> \u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e25\u0e1a html tags \u0e17\u0e35\u0e48\u0e2d\u0e32\u0e08\u0e15\u0e34\u0e14\u0e21\u0e32\u0e01\u0e31\u0e1a\u0e17\u0e27\u0e35\u0e15\n* <code>remove_emoji<\/code> \u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e25\u0e1a\u0e2d\u0e35\u0e42\u0e21\u0e15\u0e34\u0e04\u0e2d\u0e19\u0e41\u0e2a\u0e14\u0e07\u0e2d\u0e32\u0e23\u0e21\u0e13\u0e4c\u0e15\u0e48\u0e32\u0e07 \u0e46, \u0e2a\u0e31\u0e0d\u0e25\u0e31\u0e01\u0e29\u0e13\u0e4c \u0e23\u0e39\u0e1b\u0e41\u0e17\u0e19\u0e04\u0e27\u0e32\u0e21\u0e2b\u0e21\u0e32\u0e22, \u0e2a\u0e31\u0e0d\u0e25\u0e31\u0e01\u0e29\u0e13\u0e4c\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e01\u0e31\u0e1a\u0e08\u0e23\u0e32\u0e08\u0e23\u0e01\u0e31\u0e1a\u0e41\u0e1c\u0e19\u0e17\u0e35\u0e48 \u0e41\u0e25\u0e30 \u0e18\u0e07\u0e15\u0e48\u0e32\u0e07 \u0e46\n* <code>remove_punct<\/code> \u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e25\u0e1a\u0e2d\u0e31\u0e01\u0e02\u0e23\u0e30\u0e1e\u0e34\u0e40\u0e28\u0e29\u0e43\u0e19\u0e17\u0e27\u0e35\u0e15\n* <code>remove_number<\/code> \u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e25\u0e1a\u0e15\u0e31\u0e27\u0e40\u0e25\u0e02\u0e43\u0e19\u0e17\u0e27\u0e35\u0e15\n* <code>convert_abbrev_in_text<\/code> \u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e41\u0e1b\u0e25\u0e07\u0e04\u0e33\u0e17\u0e35\u0e48\u0e40\u0e02\u0e35\u0e22\u0e19\u0e41\u0e1a\u0e1a\u0e15\u0e31\u0e27\u0e22\u0e48\u0e2d\u0e40\u0e1b\u0e47\u0e19\u0e04\u0e33\u0e40\u0e15\u0e47\u0e21","16f47739":"# **7. \u0e40\u0e23\u0e35\u0e22\u0e01\u0e43\u0e0a\u0e49 Model BERT**\n* \u0e14\u0e39 model summary \u0e27\u0e48\u0e32\u0e21\u0e35\u0e04\u0e48\u0e32\u0e15\u0e48\u0e32\u0e07 \u0e46 \u0e41\u0e25\u0e30\u0e21\u0e35\u0e08\u0e33\u0e19\u0e27\u0e19\u0e1e\u0e32\u0e23\u0e32\u0e21\u0e34\u0e40\u0e15\u0e2d\u0e23\u0e4c\u0e15\u0e32\u0e21 BERT Large \u0e02\u0e49\u0e32\u0e07\u0e15\u0e49\u0e19\u0e2b\u0e23\u0e37\u0e2d\u0e44\u0e21\u0e48\n* \u0e40\u0e23\u0e34\u0e48\u0e21\u0e01\u0e23\u0e30\u0e1a\u0e27\u0e19\u0e01\u0e32\u0e23\u0e43\u0e2b\u0e49 BERT \u0e40\u0e23\u0e35\u0e22\u0e19\u0e23\u0e39\u0e49 \u0e14\u0e49\u0e27\u0e22\u0e04\u0e48\u0e32\u0e15\u0e31\u0e27\u0e41\u0e1b\u0e23\u0e17\u0e35\u0e48\u0e01\u0e33\u0e2b\u0e19\u0e14\u0e44\u0e27\u0e49\u0e43\u0e19\u0e2b\u0e31\u0e27\u0e02\u0e49\u0e2d 4.1\n* \u0e14\u0e39\u0e04\u0e48\u0e32 accuracy \u0e02\u0e2d\u0e07\u0e42\u0e21\u0e40\u0e14\u0e25\u0e17\u0e35\u0e48\u0e17\u0e33\u0e01\u0e32\u0e23\u0e40\u0e23\u0e35\u0e22\u0e19\u0e23\u0e39\u0e49\u0e08\u0e19\u0e40\u0e2a\u0e23\u0e47\u0e08\u0e2a\u0e34\u0e49\u0e19\u0e41\u0e25\u0e30\u0e15\u0e31\u0e14\u0e2a\u0e34\u0e19\u0e43\u0e08\u0e27\u0e48\u0e32\u0e08\u0e30\u0e40\u0e25\u0e37\u0e2d\u0e01\u0e43\u0e0a\u0e49\u0e42\u0e21\u0e40\u0e14\u0e25\u0e19\u0e35\u0e49\u0e2b\u0e23\u0e37\u0e2d\u0e01\u0e25\u0e31\u0e1a\u0e44\u0e1b\u0e40\u0e23\u0e35\u0e22\u0e19\u0e23\u0e39\u0e49\u0e43\u0e2b\u0e21\u0e48\u0e42\u0e14\u0e22\u0e01\u0e32\u0e23\u0e1b\u0e23\u0e31\u0e1a\u0e04\u0e48\u0e32\u0e43\u0e19\u0e15\u0e31\u0e27\u0e41\u0e1b\u0e23","4300c27a":"# **1. Import Libraries**\n**\u0e21\u0e35 Library \u0e17\u0e35\u0e48\u0e2a\u0e33\u0e04\u0e31\u0e0d\u0e14\u0e31\u0e07\u0e19\u0e35\u0e49**\n* numpy \u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e04\u0e33\u0e19\u0e27\u0e13\u0e04\u0e13\u0e34\u0e15\u0e28\u0e32\u0e2a\u0e15\u0e23\u0e4c\u0e41\u0e25\u0e30\u0e40\u0e21\u0e17\u0e23\u0e34\u0e01\u0e0b\u0e4c\u0e40\u0e1a\u0e37\u0e49\u0e2d\u0e07\u0e15\u0e49\u0e19\n* pandas \u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e2d\u0e48\u0e32\u0e19\u0e44\u0e1f\u0e25\u0e4c\u0e41\u0e25\u0e30\u0e08\u0e31\u0e14\u0e01\u0e32\u0e23 DataFrame\n* Tokenizer \u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e2a\u0e23\u0e49\u0e32\u0e07 token\n* pad_sequence \u0e43\u0e19\u0e01\u0e32\u0e23\u0e17\u0e33\u0e43\u0e2b\u0e49 vector \u0e02\u0e2d\u0e07\u0e41\u0e15\u0e48\u0e25\u0e30\u0e17\u0e27\u0e35\u0e15\u0e21\u0e35\u0e02\u0e19\u0e32\u0e14\u0e40\u0e17\u0e48\u0e32\u0e01\u0e31\u0e19\n* Embedding, LSTM,Dense, SpatialDropout1D, Dropout \u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e08\u0e31\u0e14\u0e01\u0e32\u0e23\u0e42\u0e21\u0e40\u0e14\u0e25\n* Adam \u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e17\u0e33 Optimization \u0e43\u0e2b\u0e49\u0e42\u0e21\u0e40\u0e14\u0e25","ae454355":"# <center><b><font size= 6>Real or Not? NLP with Disaster Tweets <\/font><\/b><\/center>\n# \u0e23\u0e32\u0e22\u0e0a\u0e37\u0e48\u0e2d\u0e2a\u0e21\u0e32\u0e0a\u0e34\u0e01\n1. \u0e19\u0e32\u0e07\u0e2a\u0e32\u0e27\u0e18\u0e31\u0e0d\u0e1e\u0e34\u0e0a\u0e0a\u0e32 \u0e40\u0e2a\u0e37\u0e2d\u0e40\u0e1b\u0e25\u0e35\u0e48\u0e22\u0e27 \u0e23\u0e2b\u0e31\u0e2a\u0e19\u0e31\u0e01\u0e28\u0e36\u0e01\u0e29\u0e32 6209656047\n2. \u0e19\u0e32\u0e22\u0e2a\u0e2b\u0e31\u0e2a\u0e27\u0e23\u0e23\u0e29   \u0e28\u0e23\u0e35\u0e1e\u0e25 \u0e23\u0e2b\u0e31\u0e2a\u0e19\u0e31\u0e01\u0e28\u0e36\u0e01\u0e29\u0e32 6209656062\n3. \u0e19\u0e32\u0e07\u0e2a\u0e32\u0e27\u0e01\u0e38\u0e0d\u0e0a\u0e4c\u0e20\u0e31\u0e2a\u0e2a\u0e4c \u0e21\u0e13\u0e35\u0e42\u0e0a\u0e15\u0e34\u0e23\u0e31\u0e15\u0e19\u0e4c \u0e23\u0e2b\u0e31\u0e2a\u0e19\u0e31\u0e01\u0e28\u0e36\u0e01\u0e29\u0e32 6209656252\n\n<h1>\u0e40\u0e2a\u0e19\u0e2d<\/h1>\n\u0e2d\u0e32\u0e08\u0e32\u0e23\u0e22\u0e4c\u0e28\u0e23\u0e31\u0e13\u0e22\u0e4c \u0e01\u0e38\u0e25\u0e22\u0e32\u0e19\u0e19\u0e17\u0e4c","3f69ceb2":"# \u0e17\u0e33\u0e44\u0e21\u0e16\u0e36\u0e07\u0e43\u0e0a\u0e49 BERT-Large\nBERT \u0e1b\u0e23\u0e30\u0e40\u0e20\u0e17\u0e19\u0e35\u0e49\u0e16\u0e39\u0e01\u0e2d\u0e2d\u0e01\u0e41\u0e1a\u0e1a\u0e21\u0e32\u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e27\u0e31\u0e14\u0e02\u0e35\u0e14\u0e04\u0e27\u0e32\u0e21\u0e2a\u0e32\u0e21\u0e32\u0e23\u0e16\u0e43\u0e19\u0e01\u0e32\u0e23\u0e2a\u0e23\u0e49\u0e32\u0e07 Language Model \u0e42\u0e14\u0e22\u0e08\u0e30\u0e21\u0e35 Attention Head (\u0e01\u0e32\u0e23\u0e1a\u0e2d\u0e01\u0e04\u0e27\u0e32\u0e21\u0e2a\u0e31\u0e21\u0e1e\u0e31\u0e19\u0e18\u0e4c\u0e02\u0e2d\u0e07\u0e04\u0e33) \u0e17\u0e35\u0e48\u0e21\u0e35\u0e08\u0e33\u0e19\u0e27\u0e19\u0e21\u0e32\u0e01\u0e02\u0e36\u0e49\u0e19,\nLayer \u0e43\u0e19\u0e01\u0e32\u0e23\u0e1b\u0e23\u0e30\u0e21\u0e27\u0e25\u0e1c\u0e25\u0e17\u0e35\u0e48\u0e40\u0e1e\u0e34\u0e48\u0e21\u0e02\u0e36\u0e49\u0e19 \u0e41\u0e25\u0e30 \u0e21\u0e35 Embedding Vector (\u0e41\u0e1b\u0e25\u0e07\u0e04\u0e33\u0e40\u0e1b\u0e47\u0e19\u0e40\u0e27\u0e01\u0e40\u0e15\u0e2d\u0e23\u0e4c\u0e02\u0e2d\u0e07\u0e15\u0e31\u0e27\u0e40\u0e25\u0e02) \u0e17\u0e35\u0e48\u0e02\u0e19\u0e32\u0e14\u0e43\u0e2b\u0e0d\u0e48\u0e02\u0e36\u0e49\u0e19\u0e0b\u0e36\u0e48\u0e07\u0e40\u0e2b\u0e21\u0e32\u0e30\u0e01\u0e31\u0e1a\u0e0a\u0e38\u0e14\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e17\u0e35\u0e48\u0e21\u0e35\u0e02\u0e19\u0e32\u0e14\u0e43\u0e2b\u0e0d\u0e48\u0e21\u0e32\u0e01 \u0e41\u0e25\u0e30\u0e40\u0e2b\u0e15\u0e38\u0e1c\u0e25\u0e17\u0e35\u0e48\u0e43\u0e0a\u0e49\u0e01\u0e31\u0e1a\u0e42\u0e1b\u0e23\u0e40\u0e08\u0e04\u0e19\u0e35\u0e49\u0e40\u0e1e\u0e23\u0e32\u0e30\u0e15\u0e49\u0e2d\u0e07\u0e01\u0e32\u0e23\u0e14\u0e39\u0e27\u0e48\u0e32 BERT \u0e1b\u0e23\u0e30\u0e40\u0e20\u0e17\u0e19\u0e35\u0e49\u0e08\u0e30\u0e19\u0e33\u0e21\u0e32\u0e1b\u0e23\u0e30\u0e21\u0e27\u0e25\u0e1c\u0e25\u0e01\u0e31\u0e1a\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e17\u0e35\u0e48\u0e44\u0e21\u0e48\u0e43\u0e2b\u0e0d\u0e48\u0e21\u0e32\u0e01\u0e44\u0e14\u0e49\u0e2b\u0e23\u0e37\u0e2d\u0e44\u0e21\u0e48 \u0e2b\u0e23\u0e37\u0e2d\u0e25\u0e14 Bacth \u0e43\u0e19\u0e01\u0e32\u0e23\u0e19\u0e33\u0e40\u0e02\u0e49\u0e32\u0e42\u0e21\u0e40\u0e14\u0e25\u0e44\u0e14\u0e49\u0e2b\u0e23\u0e37\u0e2d\u0e44\u0e21\u0e48\n\n# \u0e23\u0e32\u0e22\u0e25\u0e30\u0e40\u0e2d\u0e35\u0e22\u0e14\u0e40\u0e1a\u0e37\u0e49\u0e2d\u0e07\u0e15\u0e49\u0e19\u0e02\u0e2d\u0e07 BERT-Large \u0e17\u0e35\u0e48\u0e43\u0e0a\u0e49\n* 24 Layers\n* 1024 hidden units\n* 16 head (Attention)\n* Parameters \u0e1b\u0e23\u0e30\u0e21\u0e32\u0e13 340 \u0e25\u0e49\u0e32\u0e19\u0e15\u0e31\u0e27","5c6867da":"![](https:\/\/firebasestorage.googleapis.com\/v0\/b\/second-try-cb-pirwud.appspot.com\/o\/BERT_RUN.jpg?alt=media&token=f318d2e9-68e7-4928-9ee3-bce4ea580610)\n<br>\u0e23\u0e39\u0e1b\u0e17\u0e35\u0e48 1: \u0e1c\u0e25\u0e25\u0e31\u0e1e\u0e18\u0e4c\u0e02\u0e2d\u0e07\u0e01\u0e32\u0e23\u0e40\u0e17\u0e23\u0e19 BERT Model \u0e43\u0e19\u0e23\u0e2d\u0e1a\u0e17\u0e35\u0e48\u0e2a\u0e48\u0e07 kaggle \u0e14\u0e49\u0e27\u0e22\u0e04\u0e30\u0e41\u0e19\u0e19 0.83144 (\u0e04\u0e48\u0e32\u0e17\u0e35\u0e48\u0e1b\u0e23\u0e31\u0e1a Leanring_rate = 0.00005, Dropout_num = 0.05, epoch = 4)","ad56332b":"# **8. \u0e17\u0e33\u0e19\u0e32\u0e22\u0e1c\u0e25 \u0e41\u0e25\u0e30 \u0e2a\u0e48\u0e07\u0e04\u0e33\u0e15\u0e2d\u0e1a**\n* \u0e19\u0e33 BERT Model \u0e17\u0e35\u0e48\u0e1c\u0e48\u0e32\u0e19\u0e01\u0e32\u0e23\u0e40\u0e17\u0e23\u0e19\u0e41\u0e25\u0e49\u0e27\u0e21\u0e32\u0e17\u0e33\u0e19\u0e32\u0e22\u0e27\u0e48\u0e32\u0e17\u0e27\u0e35\u0e15\u0e19\u0e31\u0e49\u0e19 \u0e46 \u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e01\u0e31\u0e1a\u0e01\u0e32\u0e23\u0e40\u0e01\u0e34\u0e14\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34\u0e02\u0e36\u0e49\u0e19\u0e08\u0e23\u0e34\u0e07\u0e2b\u0e23\u0e37\u0e2d\u0e44\u0e21\u0e48 (\u0e19\u0e33\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e43\u0e19\u0e2a\u0e48\u0e27\u0e19\u0e02\u0e2d\u0e07 test.csv \u0e21\u0e32\u0e17\u0e33\u0e19\u0e32\u0e22\u0e1c\u0e25\u0e25\u0e31\u0e1e\u0e18\u0e4c)\n* \u0e1a\u0e31\u0e19\u0e17\u0e36\u0e01\u0e1c\u0e25\u0e25\u0e31\u0e1e\u0e18\u0e4c\u0e17\u0e35\u0e48\u0e17\u0e33\u0e19\u0e32\u0e22\u0e44\u0e14\u0e49\u0e25\u0e07\u0e43\u0e19 submission.csv \u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e2a\u0e48\u0e07\u0e04\u0e33\u0e15\u0e2d\u0e1a\u0e43\u0e19 kaggle (\u0e04\u0e33\u0e15\u0e2d\u0e1a\u0e17\u0e35\u0e48\u0e17\u0e33\u0e19\u0e32\u0e22\u0e44\u0e14\u0e49\u0e04\u0e37\u0e2d 0 \u0e41\u0e17\u0e19\u0e44\u0e21\u0e48\u0e40\u0e01\u0e34\u0e14\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34, 1 \u0e41\u0e17\u0e19\u0e01\u0e32\u0e23\u0e40\u0e01\u0e34\u0e14\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34)","9700bfe1":"# **\u0e1a\u0e17\u0e19\u0e33**\n<font size= 3>\u0e42\u0e1b\u0e23\u0e40\u0e08\u0e04\u0e19\u0e35\u0e49\u0e40\u0e1b\u0e47\u0e19\u0e01\u0e32\u0e23\u0e17\u0e33\u0e19\u0e32\u0e22\u0e27\u0e48\u0e32\u0e17\u0e27\u0e35\u0e15\u0e19\u0e31\u0e49\u0e19 \u0e46 \u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e01\u0e31\u0e1a\u0e01\u0e32\u0e23\u0e40\u0e01\u0e34\u0e14\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34\u0e08\u0e23\u0e34\u0e07\u0e2b\u0e23\u0e37\u0e2d\u0e44\u0e21\u0e48 \u0e42\u0e14\u0e22 0 \u0e41\u0e17\u0e19 \"\u0e44\u0e21\u0e48\u0e40\u0e01\u0e34\u0e14\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34\" 1 \u0e41\u0e17\u0e19 \"\u0e40\u0e01\u0e34\u0e14\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34\"\n<br>\u0e42\u0e14\u0e22 Notebook \u0e19\u0e35\u0e49\u0e43\u0e0a\u0e49 BERT \u0e43\u0e19\u0e01\u0e32\u0e23\u0e17\u0e33\u0e19\u0e32\u0e22\u0e27\u0e48\u0e32\u0e17\u0e27\u0e35\u0e15\u0e19\u0e31\u0e49\u0e19\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e01\u0e31\u0e1a\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34\u0e2b\u0e23\u0e37\u0e2d\u0e44\u0e21\u0e48<\/font>","1203fadc":"### 4.1 \u0e01\u0e33\u0e2b\u0e19\u0e14\u0e04\u0e48\u0e32\u0e15\u0e31\u0e27\u0e41\u0e1b\u0e23\u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a Optimize \u0e42\u0e21\u0e40\u0e14\u0e25\n* <code>random_state_split<\/code>: \u0e40\u0e23\u0e34\u0e48\u0e21\u0e15\u0e49\u0e19\u0e2a\u0e38\u0e48\u0e21\u0e04\u0e48\u0e32\u0e17\u0e35\u0e25\u0e30 2 \u0e04\u0e48\u0e32\n* <code>Dropout_num<\/code>: \u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e1b\u0e49\u0e2d\u0e07\u0e01\u0e31\u0e19\u0e01\u0e32\u0e23\u0e40\u0e01\u0e34\u0e14 Overfitting \u0e43\u0e19\u0e42\u0e21\u0e40\u0e14\u0e25\n* <code>learning_rate<\/code>: \u0e01\u0e33\u0e2b\u0e19\u0e14\u0e04\u0e27\u0e32\u0e21\u0e40\u0e23\u0e47\u0e27\u0e43\u0e19\u0e01\u0e32\u0e23\u0e40\u0e23\u0e35\u0e22\u0e19\u0e23\u0e39\u0e49\u0e02\u0e2d\u0e07\u0e42\u0e21\u0e40\u0e14\u0e25\n* <code>valid<\/code>: \u0e40\u0e01\u0e13\u0e11\u0e4c\u0e01\u0e32\u0e23\u0e40\u0e25\u0e37\u0e2d\u0e01\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e43\u0e19\u0e01\u0e32\u0e23\u0e2a\u0e2d\u0e19\u0e42\u0e21\u0e40\u0e14\u0e25\n* <code>epochs_num<\/code>: \u0e08\u0e33\u0e19\u0e27\u0e19\u0e23\u0e2d\u0e1a\u0e01\u0e32\u0e23\u0e40\u0e23\u0e35\u0e22\u0e19\u0e23\u0e39\u0e49\u0e02\u0e2d\u0e07\u0e42\u0e21\u0e40\u0e14\u0e25 (\u0e1b\u0e23\u0e30\u0e21\u0e27\u0e25\u0e1c\u0e25\u0e04\u0e23\u0e1a\u0e08\u0e33\u0e19\u0e27\u0e19 Mini Batch \u0e04\u0e37\u0e2d\u0e40\u0e2a\u0e23\u0e47\u0e08 1 epoch)\n* <code>batch_size_num<\/code>: \u0e40\u0e1b\u0e47\u0e19\u0e01\u0e32\u0e23\u0e41\u0e1a\u0e48\u0e07\u0e0a\u0e38\u0e14\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e2d\u0e2d\u0e01\u0e40\u0e1b\u0e47\u0e19\u0e2a\u0e48\u0e27\u0e19\u0e40\u0e25\u0e47\u0e01 \u0e46 \u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e25\u0e14\u0e20\u0e32\u0e23\u0e30\u0e01\u0e32\u0e23\u0e1b\u0e23\u0e30\u0e21\u0e27\u0e25\u0e1c\u0e25\u0e02\u0e2d\u0e07\u0e04\u0e2d\u0e21\u0e1e\u0e34\u0e27\u0e40\u0e15\u0e2d\u0e23\u0e4c","b08893c5":"## 1.1 Download tokenization.py \u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e2a\u0e23\u0e49\u0e32\u0e07 token \u0e43\u0e19 BERT","02050d37":"### 4.2 \u0e01\u0e32\u0e23\u0e17\u0e33\u0e07\u0e32\u0e19\u0e02\u0e2d\u0e07 BERT Encode\n\u0e2a\u0e48\u0e27\u0e19\u0e19\u0e35\u0e49\u0e08\u0e30\u0e40\u0e1b\u0e47\u0e19\u0e01\u0e32\u0e23\u0e41\u0e1b\u0e25\u0e07\u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e43\u0e19\u0e17\u0e27\u0e35\u0e15\u0e43\u0e2b\u0e49\u0e2d\u0e22\u0e39\u0e48\u0e43\u0e19\u0e23\u0e39\u0e1b\u0e41\u0e1a\u0e1a\u0e17\u0e35\u0e48\u0e2a\u0e32\u0e21\u0e32\u0e23\u0e16\u0e19\u0e33\u0e40\u0e02\u0e49\u0e32 BERT \u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e1b\u0e23\u0e30\u0e21\u0e27\u0e25\u0e1c\u0e25\u0e15\u0e48\u0e2d\u0e44\u0e1b\n* \u0e41\u0e1b\u0e25\u0e07\u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e40\u0e1b\u0e47\u0e19\u0e40\u0e27\u0e01\u0e40\u0e15\u0e2d\u0e23\u0e4c\u0e02\u0e2d\u0e07\u0e15\u0e31\u0e27\u0e40\u0e25\u0e02\u0e14\u0e49\u0e27\u0e22 tokenizer \u0e42\u0e14\u0e22\u0e2a\u0e34\u0e48\u0e07\u0e19\u0e35\u0e49\u0e08\u0e30\u0e17\u0e33\u0e01\u0e32\u0e23\u0e41\u0e1a\u0e48\u0e07\u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e2d\u0e2d\u0e01\u0e40\u0e1b\u0e47\u0e19\u0e04\u0e33 \u0e46 \u0e0b\u0e36\u0e48\u0e07\u0e41\u0e15\u0e48\u0e25\u0e30\u0e04\u0e33\u0e19\u0e31\u0e49\u0e19\u0e08\u0e30\u0e16\u0e39\u0e01\u0e21\u0e35\u0e04\u0e48\u0e32\u0e17\u0e35\u0e48\u0e41\u0e15\u0e01\u0e15\u0e48\u0e32\u0e07\u0e01\u0e31\u0e19\u0e2d\u0e2d\u0e01\u0e44\u0e1b\n* \u0e01\u0e33\u0e2b\u0e19\u0e14 <code>\\[CLS\\]<\/code> \u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e1a\u0e2d\u0e01\u0e27\u0e48\u0e32\u0e04\u0e33\u0e44\u0e2b\u0e19\u0e40\u0e1b\u0e47\u0e19\u0e04\u0e33\u0e40\u0e23\u0e34\u0e48\u0e21\u0e15\u0e49\u0e19\u0e02\u0e2d\u0e07\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e04 \u0e41\u0e25\u0e30\u0e01\u0e33\u0e2b\u0e19\u0e14 <code>\\[SEP\\]<\/code> \u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e1a\u0e2d\u0e01\u0e15\u0e33\u0e41\u0e2b\u0e19\u0e48\u0e07\u0e43\u0e19\u0e01\u0e32\u0e23\u0e41\u0e1a\u0e48\u0e07\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e04\n* \u0e17\u0e33\u0e01\u0e32\u0e23 pad \u0e43\u0e2b\u0e49\u0e40\u0e27\u0e01\u0e40\u0e15\u0e2d\u0e23\u0e4c\u0e21\u0e35\u0e02\u0e19\u0e32\u0e14\u0e40\u0e17\u0e48\u0e32\u0e01\u0e31\u0e19\u0e17\u0e38\u0e01\u0e40\u0e27\u0e01\u0e40\u0e15\u0e2d\u0e23\u0e4c\n* \u0e43\u0e2a\u0e48 Mask \u0e43\u0e2b\u0e49\u0e01\u0e31\u0e1a\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e17\u0e35\u0e48\u0e08\u0e30\u0e19\u0e33\u0e44\u0e1b\u0e40\u0e17\u0e23\u0e19\u0e43\u0e19 BERT \u0e42\u0e14\u0e22\u0e27\u0e34\u0e18\u0e35\u0e19\u0e35\u0e49\u0e08\u0e30\u0e1b\u0e34\u0e14\u0e04\u0e48\u0e32\u0e44\u0e27\u0e49\u0e1a\u0e32\u0e07\u0e2a\u0e48\u0e27\u0e19\u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e43\u0e2b\u0e49\u0e42\u0e21\u0e40\u0e14\u0e25\u0e44\u0e14\u0e49\u0e17\u0e33\u0e01\u0e32\u0e23\u0e40\u0e23\u0e35\u0e22\u0e19\u0e23\u0e39\u0e49\u0e08\u0e32\u0e01\u0e01\u0e32\u0e23\u0e17\u0e33\u0e19\u0e32\u0e22\u0e2a\u0e48\u0e27\u0e19\u0e17\u0e35\u0e48\u0e16\u0e39\u0e01\u0e1b\u0e34\u0e14\u0e44\u0e27\u0e49<br>(\u0e40\u0e23\u0e32\u0e04\u0e32\u0e14\u0e2b\u0e27\u0e31\u0e07\u0e27\u0e48\u0e32\u0e08\u0e30 BERT \u0e08\u0e30\u0e40\u0e15\u0e34\u0e21\u0e04\u0e33\u0e17\u0e35\u0e48\u0e16\u0e39\u0e01 Mask \u0e44\u0e27\u0e49\u0e44\u0e14\u0e49\u0e40\u0e2b\u0e21\u0e37\u0e2d\u0e19\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e04\u0e14\u0e31\u0e49\u0e07\u0e40\u0e14\u0e34\u0e21)","3435f992":"# BERT \u0e04\u0e37\u0e2d\u0e2d\u0e30\u0e44\u0e23 ?\nBidirectional Encoder Representations from Transformers \u0e21\u0e35\u0e1e\u0e37\u0e49\u0e19\u0e10\u0e32\u0e19\u0e08\u0e32\u0e01 Transformer \u0e42\u0e14\u0e22 Bert \u0e21\u0e35\u0e2b\u0e19\u0e49\u0e32\u0e17\u0e35\u0e48 Encoder \u0e04\u0e33\u0e43\u0e19\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e04\u0e43\u0e2b\u0e49\u0e40\u0e1b\u0e47\u0e19\u0e40\u0e27\u0e01\u0e40\u0e15\u0e2d\u0e23\u0e4c\u0e02\u0e2d\u0e07\u0e15\u0e31\u0e27\u0e40\u0e25\u0e02\u0e17\u0e35\u0e48\u0e41\u0e17\u0e19\u0e04\u0e48\u0e32\u0e04\u0e33\u0e15\u0e48\u0e32\u0e07 \u0e46 \u0e43\u0e19\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e04 \u0e41\u0e25\u0e30\u0e21\u0e35\u0e42\u0e21\u0e40\u0e14\u0e25 Classifier \u0e43\u0e19\u0e01\u0e32\u0e23\u0e08\u0e33\u0e41\u0e19\u0e01\u0e1b\u0e23\u0e30\u0e40\u0e20\u0e17\u0e02\u0e2d\u0e07\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e04 \u0e0b\u0e36\u0e48\u0e07\u0e01\u0e32\u0e23\u0e17\u0e33\u0e07\u0e32\u0e19\u0e02\u0e2d\u0e07 BERT \u0e08\u0e30\u0e43\u0e0a\u0e49\u0e2b\u0e25\u0e31\u0e01\u0e01\u0e32\u0e23\u0e17\u0e35\u0e48\u0e40\u0e23\u0e35\u0e22\u0e01\u0e27\u0e48\u0e32 Self Attention \u0e0b\u0e36\u0e48\u0e07\u0e40\u0e1b\u0e47\u0e19\u0e01\u0e32\u0e23\u0e40\u0e25\u0e37\u0e2d\u0e01\u0e2a\u0e19\u0e43\u0e08\u0e40\u0e09\u0e1e\u0e32\u0e30\u0e04\u0e33\u0e17\u0e35\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07 \u0e41\u0e25\u0e30\u0e21\u0e35\u0e04\u0e27\u0e32\u0e21\u0e2a\u0e33\u0e04\u0e31\u0e0d\u0e21\u0e32\u0e43\u0e0a\u0e49\u0e17\u0e33\u0e04\u0e27\u0e32\u0e21\u0e40\u0e02\u0e49\u0e32\u0e43\u0e08\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e04\u0e19\u0e31\u0e49\u0e19 \u0e46 \u0e42\u0e14\u0e22\u0e01\u0e32\u0e23\u0e2b\u0e32\u0e04\u0e33\u0e17\u0e35\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e2b\u0e23\u0e37\u0e2d\u0e21\u0e35\u0e04\u0e27\u0e32\u0e21\u0e2a\u0e33\u0e04\u0e31\u0e0d\u0e19\u0e31\u0e49\u0e19\u0e42\u0e21\u0e40\u0e14\u0e25\u0e08\u0e33\u0e40\u0e1b\u0e47\u0e19\u0e15\u0e49\u0e2d\u0e07\u0e1b\u0e23\u0e30\u0e21\u0e27\u0e25\u0e1c\u0e25\u0e04\u0e33\u0e17\u0e35\u0e48\u0e2a\u0e19\u0e43\u0e08\u0e44\u0e1b\u0e1e\u0e23\u0e49\u0e2d\u0e21\u0e01\u0e31\u0e1a\u0e41\u0e15\u0e48\u0e25\u0e30\u0e04\u0e33\u0e43\u0e19\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e04\u0e17\u0e31\u0e49\u0e07\u0e19\u0e35\u0e49 BERT \u0e08\u0e30\u0e17\u0e33\u0e2b\u0e19\u0e49\u0e32\u0e17\u0e35\u0e48\u0e2a\u0e23\u0e49\u0e32\u0e07 Language Model \u0e17\u0e35\u0e48\u0e2a\u0e32\u0e21\u0e32\u0e23\u0e16\u0e40\u0e02\u0e49\u0e32\u0e43\u0e08\u0e1a\u0e23\u0e34\u0e1a\u0e17\u0e42\u0e14\u0e22\u0e23\u0e2d\u0e1a\u0e02\u0e2d\u0e07\u0e04\u0e33\u0e43\u0e19\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e04\u0e14\u0e49\u0e27\u0e22\u0e2b\u0e25\u0e31\u0e01\u0e01\u0e32\u0e23 Self Attention \u0e17\u0e31\u0e49\u0e07\u0e19\u0e35\u0e49\u0e22\u0e31\u0e07\u0e44\u0e14\u0e49\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e0a\u0e19\u0e4c\u0e08\u0e32\u0e01\u0e01\u0e32\u0e23\u0e43\u0e0a\u0e49 Attention \u0e43\u0e19\u0e01\u0e32\u0e23\u0e0a\u0e48\u0e27\u0e22\u0e43\u0e2b\u0e49\u0e42\u0e21\u0e40\u0e14\u0e25\u0e44\u0e21\u0e48\u0e25\u0e37\u0e21\u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e01\u0e48\u0e2d\u0e19\u0e2b\u0e19\u0e49\u0e32\u0e17\u0e35\u0e48\u0e44\u0e14\u0e49\u0e17\u0e33\u0e01\u0e32\u0e23\u0e40\u0e23\u0e35\u0e22\u0e19\u0e23\u0e39\u0e49\u0e44\u0e1b\u0e41\u0e25\u0e49\u0e27\u0e41\u0e25\u0e30\u0e22\u0e31\u0e07\u0e0a\u0e48\u0e27\u0e22\u0e43\u0e2b\u0e49\u0e40\u0e23\u0e35\u0e22\u0e19\u0e23\u0e39\u0e49\u0e04\u0e33\u0e44\u0e1b\u0e1e\u0e23\u0e49\u0e2d\u0e21 \u0e46  \u0e01\u0e31\u0e19\u0e2b\u0e25\u0e32\u0e22\u0e04\u0e33\u0e44\u0e14\u0e49\u0e2d\u0e35\u0e01\u0e14\u0e49\u0e27\u0e22","df8548fd":"# **3. Import \u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e41\u0e25\u0e30\u0e40\u0e23\u0e35\u0e22\u0e01\u0e43\u0e0a\u0e49\u0e1f\u0e31\u0e07\u0e01\u0e4c\u0e0a\u0e31\u0e19 Cleaning**\n\u0e0a\u0e38\u0e14\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e17\u0e35\u0e48\u0e19\u0e33\u0e40\u0e02\u0e49\u0e32\u0e21\u0e32\u0e21\u0e35\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e21\u0e14 3 \u0e44\u0e1f\u0e25\u0e4c\u0e14\u0e49\u0e27\u0e22\u0e01\u0e31\u0e19\u0e44\u0e14\u0e49\u0e41\u0e01\u0e48\n1. train.csv\n2. test.csv\n3. sample_submission.csv (\u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e43\u0e2a\u0e48\u0e04\u0e33\u0e15\u0e2d\u0e1a\u0e17\u0e35\u0e48\u0e17\u0e33\u0e19\u0e32\u0e22\u0e44\u0e14\u0e49\u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e40\u0e2d\u0e32\u0e44\u0e1b\u0e2a\u0e48\u0e07\u0e43\u0e19 kaggle)\n\n\u0e08\u0e32\u0e01\u0e19\u0e31\u0e49\u0e19\u0e14\u0e39\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e04\u0e23\u0e48\u0e32\u0e27 \u0e46 \u0e14\u0e49\u0e27\u0e22 <code>train.head()<\/code>, <code>test.head()<\/code> \u0e41\u0e25\u0e49\u0e27\u0e08\u0e36\u0e07\u0e40\u0e23\u0e35\u0e22\u0e01\u0e43\u0e0a\u0e49\u0e1f\u0e31\u0e07\u0e01\u0e4c\u0e0a\u0e31\u0e19\u0e43\u0e19\u0e01\u0e32\u0e23 Cleaning \u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e43\u0e19\u0e17\u0e27\u0e35\u0e15\u0e43\u0e2b\u0e49\u0e2d\u0e22\u0e39\u0e48\u0e43\u0e19\u0e23\u0e39\u0e1b\u0e41\u0e1a\u0e1a\u0e40\u0e14\u0e35\u0e22\u0e27\u0e01\u0e31\u0e19\u0e17\u0e31\u0e49\u0e07 train \u0e41\u0e25\u0e30 test \u0e14\u0e49\u0e27\u0e22\u0e27\u0e34\u0e18\u0e35\u0e01\u0e32\u0e23\u0e02\u0e2d\u0e07 Regular Expression","664393b2":"1. BERT \u0e04\u0e37\u0e2d\u0e2d\u0e30\u0e44\u0e23 https:\/\/medium.com\/@chameleontk\/\u0e17\u0e33\u0e04\u0e27\u0e32\u0e21\u0e40\u0e02\u0e49\u0e32\u0e43\u0e08-bert-98589715545\n2. BERT \u0e04\u0e37\u0e2d\u0e2d\u0e30\u0e44\u0e23 https:\/\/medium.com\/@chameleontk\/\u0e17\u0e33\u0e04\u0e27\u0e32\u0e21\u0e40\u0e02\u0e49\u0e32\u0e43\u0e08-transformer-part-i-a50dcf06579b\n3. BERT \u0e04\u0e37\u0e2d\u0e2d\u0e30\u0e44\u0e23 https:\/\/medium.com\/@chameleontk\/\u0e17\u0e33\u0e04\u0e27\u0e32\u0e21\u0e40\u0e02\u0e49\u0e32\u0e43\u0e08-transformer-part-ii-e2b467a70a45\n4. BERT \u0e04\u0e37\u0e2d\u0e2d\u0e30\u0e44\u0e23 https:\/\/medium.com\/@chameleontk\/\u0e17\u0e33\u0e04\u0e27\u0e32\u0e21\u0e40\u0e02\u0e49\u0e32\u0e43\u0e08-transformer-part-iii-2f36fb256f0c\n5. how bert works https:\/\/towardsdatascience.com\/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270\n5. regex using python https:\/\/www.w3schools.com\/python\/python_regex.asp\n6. BERT max length https:\/\/stackoverflow.com\/questions\/58636587\/how-to-use-bert-for-long-text-classification\n7. validation in ML https:\/\/machinelearningmastery.com\/difference-test-validation-datasets\/\n8. Writing markdowns in kaggle https:\/\/www.kaggle.com\/shubhamksingh\/create-beautiful-notebooks-formatting-tutorial","267efa4a":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#120078;\n           font-size: 200%;\n           font-family:Kanit;\n           letter-spacing:0.5px\">\n<h1><center>References<\/center><h1>"}}