{"cell_type":{"bb95ed2d":"code","d5e40420":"code","07195fbd":"code","6c17ee51":"code","b5b910cb":"code","1440277e":"code","5083bc02":"code","fd353dae":"code","8bd38b0e":"code","6fde04e7":"code","120203e3":"markdown","37551867":"markdown","358fbbec":"markdown","9e584fdb":"markdown","bd1d8dca":"markdown","5239ab95":"markdown","7aac24b6":"markdown","9beb1247":"markdown","ad0035d8":"markdown","0340d570":"markdown"},"source":{"bb95ed2d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","d5e40420":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\nY_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"],axis = 1)","07195fbd":"X_train = X_train \/ 255.0\ntest = test \/ 255.0","6c17ee51":"X_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","b5b910cb":"from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nY_train = to_categorical(Y_train, num_classes = 10)","1440277e":"from sklearn.model_selection import train_test_split\n\nrandom_seed = 2\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)","5083bc02":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","fd353dae":"from keras.optimizers import RMSprop\n\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n","8bd38b0e":"epochs = 30 \nbatch_size = 86\nmyFittedModel = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, validation_data = (X_val, Y_val), verbose = 2)","6fde04e7":"import matplotlib.pyplot as plt\n\n# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(myFittedModel.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(myFittedModel.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(myFittedModel.history['acc'], color='b', label=\"Training accuracy\")\nax[1].plot(myFittedModel.history['val_acc'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","120203e3":"**6.Define the model:**\nUsing the Keras Sequential API (adding one layer at a time)\n\n1-The convolution Conv2D layer: 32 filters for the two firsts conv2D layers and 64 filters for the two last ones. Each filter transforms a part of the image (defined by the kernel size) using the kernel filter. \n\n2-The pooling (MaxPool2D) layer: used for downsampling.\n\n3- Dropout: a proportion of nodes in the layer are randomly ignored (setting their wieghts to zero) for each training sample.(To reduce overfitting)\n\n'relu' is the rectifier (activation function max(0,x) used to add non linearity to the network.\n\n4-The Flatten layer is used to convert the final feature maps into a one single 1D vector. (It is like un-reshaping the result back)","37551867":"**4.One hot encoding:**\nsince the digits are limited (from 0 to 9), it is more efficient to use the one hot representation for labels","358fbbec":"**1.Load Data**","9e584fdb":"**7.Optimization:**\n\n1-The loss function: the error rate between the oberved labels and the predicted ones.  (I used categorical_crossentropy)\n\n2-The optimizer: iteratively improve parameters (filters kernel values, weights and bias of neurons ...) in order to minimise the loss. (I used RMSprop)\n\n3-Accuracy:  to evaluate the performance our model. It is similar to the loss function, except that the results from the metric evaluation are not used when training the model (only for evaluation).","bd1d8dca":"**8.Fit the model:**","5239ab95":"**Digit Recognizer**","7aac24b6":"**8.Evaluate the model:**","9beb1247":"**3.Reshape:**\nfrom 1D vectors of 784 values (in panda.Dtaframe) to 28x28x1 3D matrices.","ad0035d8":"**5.Split training and valdiation set:**\nI chose only 10% for the validation set","0340d570":"**2.Normalization:**\ngrayscale normalization"}}