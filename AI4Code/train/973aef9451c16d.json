{"cell_type":{"14399c26":"code","e6b62da8":"code","dca8cd6c":"code","e5c0faaa":"code","f65ef56f":"code","f861b450":"code","8c2c6496":"code","4d453e07":"code","f77d34ca":"code","ff4308ad":"code","5379bf97":"code","a4832313":"markdown","7acf3c01":"markdown","b41e9e39":"markdown","1ffe743d":"markdown","cb1bed37":"markdown","4ecfac17":"markdown","48bd5b83":"markdown","e32b1fd6":"markdown","712f4b3a":"markdown"},"source":{"14399c26":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2 as cv\nfrom tqdm import tqdm\nimport random\nimport os\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, Activation\nfrom keras import optimizers\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.models import load_model","e6b62da8":"img = cv.imread(\"..\/input\/english-handwritten-characters-dataset\/Img\/img011-053.png\")\nplt.imshow(img)","dca8cd6c":"df = pd.read_csv(r'..\/input\/english-handwritten-characters-dataset\/english.csv')\ndf.head()","e5c0faaa":"classes = df['label'].unique()\nprint(f'\\nThe Classes:\\n {classes} ')","f65ef56f":"# Define the data path\nDATADIR = \"..\/input\/english-handwritten-characters-dataset\"         \n\n# Read the csv file\ndataset = pd.read_csv(DATADIR + '\/english.csv')\n# Get a 500 random values\/rows\nrand = random.sample(range(len(dataset)), 500)\n# Make the random 500 as a validation data\nvalidation_set = pd.DataFrame(dataset.iloc[rand, :].values, columns=['image', 'label'])\n# Drop the 500 from the orignal data set\ndataset.drop(rand, inplace=True)\n# Get a 5 random rows\/values from the validation set\nrand = random.sample(range(len(validation_set)), 5)\n# from the 5 random Create the test set \ntest_set = pd.DataFrame(validation_set.iloc[rand, :].values, columns=['image', 'label'])\n# Drop the 5 from the validation set\nvalidation_set.drop(rand, inplace=True)\n# Show the validation set as a example\nvalidation_set","f861b450":"train_data_generator = ImageDataGenerator(rescale=1\/255, shear_range=0.2, zoom_range=0.2)\ndata_generator = ImageDataGenerator(rescale=1\/255)\ntraining_data_frame = train_data_generator.flow_from_dataframe(dataframe=dataset, directory=DATADIR, x_col='image', y_col='label', \n                                                               target_size=(64, 64), class_mode='categorical')\nvalidation_data_frame = data_generator.flow_from_dataframe(dataframe=validation_set, directory=DATADIR, x_col='image', y_col='label', \n                                                           target_size=(64, 64), class_mode='categorical')\ntest_data_frame = data_generator.flow_from_dataframe(dataframe=test_set, directory=DATADIR, x_col='image', y_col='label', \n                                                     target_size=(64, 64), class_mode='categorical', shuffle=False)","8c2c6496":"# Define the model\nmodel = Sequential()\n\n# Add first Convolutional Layer\nmodel.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=(64,64,3)))\n# Add a relu Activation \nmodel.add(Activation('relu'))\n# Add a second Convolutional Layer\nmodel.add(Conv2D(32, (3, 3)))\n# Add a relu Activation \nmodel.add(Activation('relu'))\n# Add a Max pooling layer\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n# Add a Dropout layer\nmodel.add(Dropout(0.25))\n\n# Add third Convolutional Layer\nmodel.add(Conv2D(64, (3, 3), padding='same'))\n# Add a relu Activation \nmodel.add(Activation('relu'))\n# Add Fourth Convolutional Layer\nmodel.add(Conv2D(64, (3, 3)))\n# Add a relu Activation \nmodel.add(Activation('relu'))\n# Add a Max pooling layer\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n# Add a Dropout Layer\nmodel.add(Dropout(0.25))\n\n# Add Fifth Convolutional Layer\nmodel.add(Conv2D(64, (3, 3), padding='same'))\n# Add a Activation Layer\nmodel.add(Activation('relu'))\n# Add a sixth Convolutional Layer\nmodel.add(Conv2D(64, (3, 3)))\n# Add a Activation Layer\nmodel.add(Activation('relu'))\n# Add a Max Pooling Layer\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n# Add a Dropout Layer\nmodel.add(Dropout(0.25))\n\n# Add a Flatten Layer\nmodel.add(Flatten())\n# Add a Dense layer Layer\nmodel.add(Dense(512))\n# Add a Activation Layer\nmodel.add(Activation('relu'))\n# Add a Dropout Layer\nmodel.add(Dropout(0.5))\n# Add the Output Dense Layer\nmodel.add(Dense(62, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizers.RMSprop(lr=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","4d453e07":"# Train the model for 50 epochs\nhistory = model.fit(training_data_frame, validation_data=validation_data_frame, epochs=50)","f77d34ca":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(50)\n\nplt.figure(figsize=(15, 15))\nplt.subplot(2, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","ff4308ad":"# Save the model as model.h5\nmodel.save('model.h5')\n# Load the model\nmodel = load_model('model.h5')\n","5379bf97":"# Print the class indices \nprint(\"Prediction Dict: \", training_data_frame.class_indices)\n# Predict on the test data \npred = model.predict(test_data_frame)\n# Create a class\/labels dictionary\nclassDict = {\n            0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\", 5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\", 10: \"A\",\n            11: \"B\", 12: \"C\", 13: \"D\", 14: \"E\", 15: \"F\", 16: \"G\", 17: \"H\", 18: \"I\", 19: \"J\", 20: \"K\",\n            21: \"L\", 22: \"M\", 23: \"N\", 24: \"O\", 25: \"P\", 26: \"Q\", 27: \"R\", 28: \"S\", 29: \"T\", 30: \"U\",\n            31: \"V\", 32: \"W\", 33: \"X\", 34: \"Y\", 35: \"Z\", 36: \"a\", 37: \"b\", 38: \"c\", 39: \"d\", 40: \"e\",\n            41: \"f\", 42: \"g\", 43: \"h\", 44: \"i\", 45: \"j\", 46: \"k\", 47: \"l\", 48: \"m\", 49: \"n\", 50: \"o\",\n            51: \"p\", 52: \"q\", 53: \"r\", 54: \"s\", 55: \"t\", 56: \"u\", 57: \"v\", 58: \"w\", 59: \"x\", 60: \"y\",\n            61: \"z\"}\n\n# Make a data frame that contains the probability for each class\noutputDf = pd.DataFrame(pred)\n# Get the index of the max probability from the output Data frame\nmaxIndex = list(outputDf.idxmax(axis=1))\n# Print the max index\nprint(\"Max index: \", maxIndex)\n# Make a loop in range the length of the test data (5)\nfor i in range(len(test_set)):\n    # Read the image \n    image = cv.imread(DATADIR + '\/' + test_set.at[i, 'image'])\n    # The title of the plot which is the predicted label\n    plt.title(classDict.get(maxIndex[i], \"error\"))\n    # Show the actual image\n    plt.imshow(image)\n    plt.show()","a4832313":"## Train\/Fit the model","7acf3c01":"## Import the libraries","b41e9e39":"## Read the csv file, Print the first 5 rows","1ffe743d":"## Save the model","cb1bed37":"## Show a example of the data","4ecfac17":"## Plot the result","48bd5b83":"## Build the model","e32b1fd6":"## Explore the classes","712f4b3a":"## Read the images"}}