{"cell_type":{"4b715169":"code","dd9248d9":"code","8ef7d356":"code","1fce412c":"code","41db6e2e":"code","5f496937":"code","11ac0687":"code","350c8485":"code","c607a8a2":"code","d5d52cec":"code","faca179c":"code","86d486cd":"code","dbd80fae":"code","369bc6c3":"code","be069ba6":"code","0c3e4199":"code","705ce876":"code","2152b277":"code","df0355c4":"code","067eba4c":"code","20fc72da":"code","6f497b26":"code","ba5cfce5":"code","81826de6":"code","20805942":"code","ac831a51":"markdown","4801c8c8":"markdown","04ee94b6":"markdown","9d35d13a":"markdown"},"source":{"4b715169":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dd9248d9":"#Checking Train datasets\nTrain_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\nTrain_data.head(10)","8ef7d356":"#Checking Test Datasets\nTest_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nTest_data.head(10)","1fce412c":"#Knowing Datasets\nprint (Train_data.shape)\nprint (Test_data.shape)","41db6e2e":"#from Aleix notebook\nwomen = Train_data.loc[Train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","5f496937":"#from Aleix notebook\nmen = Train_data.loc[Train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","11ac0687":"Train_data.info()  #for Categorical Information in Train dataset","350c8485":"Test_data.info() #for Categorical Information in Test dataset","c607a8a2":"Train_data.describe() #for Numerical Information in Train dataset","d5d52cec":"Train_data.isnull().sum() #Checking Null Values in Train datasets.","faca179c":"Test_data.isnull().sum() ##Checking Null Values in Test datasets.","86d486cd":"count_plt = sns.countplot(Train_data[\"Survived\"])\nplt.show(count_plt)","dbd80fae":"sns.barplot(data=Train_data, x=\"Survived\", y=\"Parch\")","369bc6c3":"sns.barplot(data=Train_data, x=\"Pclass\", y=\"Survived\")","be069ba6":"sns.barplot(data=Train_data, x=\"Survived\", y=\"Sex\")","0c3e4199":"Train_data['Age'].fillna(Train_data['Age'].mean(), inplace = True)\nTest_data['Age'].fillna(Train_data['Age'].mean(), inplace = True)\nTest_data['Fare'].fillna(Train_data['Fare'].mean(), inplace = True)\nTrain_data['Embarked'].fillna('S', inplace = True)","705ce876":"Train_data.isnull().sum()","2152b277":"#We will drop unwanted columns\nTrain_data.drop(columns=[\"Cabin\", \"Name\", \"Ticket\"], axis=1, inplace=True)\nTest_data.drop(columns=[\"Cabin\", \"Name\", \"Ticket\"], axis=1, inplace=True)\n\n# We will drop passengerid\nTrain_data = Train_data.drop(['PassengerId'],axis=1)","df0355c4":"# Now we will change gender to numeric\nTrain_data.loc[Train_data.Sex=='female','Sex']=1\nTrain_data.loc[Train_data.Sex=='male','Sex']=0\nTrain_data[\"Sex\"] = Train_data[\"Sex\"].astype(str).astype(float)\n\n# changing strings to numeric\nTrain_data.loc[Train_data.Embarked =='S','Embarked']= 3\nTrain_data.loc[Train_data.Embarked =='C','Embarked']=2\nTrain_data.loc[Train_data.Embarked =='Q','Embarked']=1\nTrain_data[\"Embarked\"] = Train_data[\"Embarked\"].astype(str).astype(float)","067eba4c":"# Same for test data\nTest_data['Age'] = Test_data['Age'].fillna(Test_data['Age'].mean())\nTest_data['Fare'] = Test_data['Fare'].fillna(Test_data['Fare'].mean())\nTest_data.loc[Test_data.Sex=='female','Sex']=1\nTest_data.loc[Test_data.Sex=='male','Sex']=0\nTest_data[\"Sex\"] = Test_data[\"Sex\"].astype(str).astype(float)\nTest_data.loc[Test_data.Embarked =='S','Embarked']= 3\nTest_data.loc[Test_data.Embarked =='C','Embarked']=2\nTest_data.loc[Test_data.Embarked =='Q','Embarked']=1\nTest_data[\"Embarked\"] = Test_data[\"Embarked\"].astype(str).astype(float)\nTest_data.isnull().sum()","20fc72da":"# checking data\nprint(Train_data.head())\nprint(Test_data.head())\nprint(Train_data.corr())","6f497b26":"train_x= Train_data.drop(columns=[\"Survived\"], axis=1)\ntrain_y= Train_data[\"Survived\"]\n\ntest_x= Test_data.drop(\"PassengerId\",axis=1)\n\n\n# Random forest classifier\n\nmodel_RF = RandomForestClassifier(n_estimators=100, max_depth=4, min_samples_split=2, min_samples_leaf=2, random_state=2)\nmodel_RF.fit(train_x, train_y)\npredictions_RF = model_RF.predict(test_x)\n\nprint(model_RF.score(train_x, train_y))\npp = model_RF.predict(test_x)\nprint(\"Survived\", sum(pp!=0))\nprint(\"NOT Survived\", sum(pp==0))","ba5cfce5":"#Knn classifier\nKNN_classifier = KNeighborsClassifier(n_neighbors=3)\nKNN_classifier.fit(train_x, train_y)\npredictions_KNN = KNN_classifier.predict(test_x)\n\nprint(KNN_classifier.score(train_x, train_y))\npp = KNN_classifier.predict(test_x)\nprint(\"Survived\", sum(pp!=0))\nprint(\"NOT Survived\", sum(pp==0))","81826de6":"#Final Submission\noutput = pd.DataFrame({'PassengerId': Test_data.PassengerId, 'Survived': predictions_RF})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","20805942":"Train_data.head()","ac831a51":"# Let's Look for some patterns or similarity between Features by ploting graphs.","4801c8c8":"# Exploring and Analysing Datasets","04ee94b6":"# Predicting using Algorithms","9d35d13a":"# Titanic Survivors Predictions Using Various Algorithms\nThis is my First ever kaggle Challange.\nHere i will try to predict who survived in the RMS Titanic on 15 April 1912.\nOn this RMS Titanic it is estimated 2,224 passengers and crew aboard."}}