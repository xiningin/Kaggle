{"cell_type":{"9d40f80a":"code","52921ba6":"code","bf99c95c":"code","51081259":"code","dda78cf0":"code","e3c84c19":"code","cd9ce816":"code","b35b8897":"code","d2386a04":"code","fc391300":"code","08269f1d":"code","a3d27e8c":"code","2858c6c1":"code","fd6f5c43":"code","22949238":"code","93771aa2":"code","2e20ead4":"code","c26800cc":"code","bd1ca7a9":"code","478fcd3e":"code","9719cc83":"code","f7b4d1f9":"code","3ff38a4e":"code","369c8cec":"code","e582eeec":"code","8b595a1e":"code","3d3174e1":"code","cdceb1c7":"code","b6c06605":"code","2044c05c":"code","65f956b1":"code","8269eb42":"code","9a6804fa":"markdown","767e44c3":"markdown","0f67d4d6":"markdown","fc5ce49a":"markdown","8d8b55b5":"markdown","8fcdb6a8":"markdown","707eb5e1":"markdown","b707fb9b":"markdown","029e41e7":"markdown","6fc8f6cf":"markdown","981b199a":"markdown","2be33440":"markdown","6e1a53e3":"markdown","699f750a":"markdown","cf17dba3":"markdown","3dfa2395":"markdown","a33214f7":"markdown","4e64ac57":"markdown","bf44e19d":"markdown","78e31e69":"markdown","9241866a":"markdown","40d83be6":"markdown","334f1543":"markdown","9b36cd40":"markdown","c4c72b99":"markdown","7dc9035e":"markdown","df7dcf31":"markdown","e5d033ad":"markdown","93f13bd2":"markdown","ca9b90ac":"markdown","450c05b9":"markdown","1949363f":"markdown","68548777":"markdown","5c9d00c9":"markdown","06fcdc27":"markdown","c60b7697":"markdown","3bd3da43":"markdown","7e7e05b2":"markdown","f6dbb7d7":"markdown"},"source":{"9d40f80a":"with open('..\/input\/creditapprovaldataset\/crx.txt', 'r') as file:\n    print(file.read())","52921ba6":"import pandas as pd\n\nprint('Environment ready!')","bf99c95c":"col_names = [('A'+str(i)) for i in range(1,17)]\ndf = pd.read_csv('..\/input\/creditapprovaldataset\/crx.data', names=col_names, header=None)\n\nprint(f'Dataset Shape: {df.shape}')\ndf","51081259":"print(f'Number of Columns: {len(df.columns)}')\ndf.columns","dda78cf0":"df.info()","e3c84c19":"df.columns","cd9ce816":"missing_df = pd.DataFrame()\n\nfor idx in range(len(df)):\n    if df.iloc[idx].isin(['?']).any():\n        missing_df = missing_df.append(df.iloc[idx], ignore_index=False)\n        \nprint(f'Number of records with missing values: {missing_df.shape}')\nmissing_df.head()","b35b8897":"for col in missing_df.columns:\n    tally = df[col].isin(['?']).sum()\n    if tally != 0:\n        print(f'{col}: {tally}')","d2386a04":"import numpy as np\ndf = df.replace(to_replace='?', value=np.nan)\n\nprint(f'Shape: {df.shape}')\nprint(f'Missing values: {df.isna().sum()}')\ndf.head()","fc391300":"df.info()","08269f1d":"df.head()","a3d27e8c":"df[['A2', 'A14']] = df[['A2', 'A14']].astype('float64')\ndf.dtypes","2858c6c1":"df.describe()","fd6f5c43":"df = df.replace({'+':1, '-':0})\nprint(df.shape)\ndf.head()","22949238":"cols_one_unique = [col for col in df.columns if df[col].nunique() <= 1 ]\n\nprint(f'These are the features with only one unique value: {cols_one_unique}')","93771aa2":"for col in df.columns:\n    print(col, ': ', df[col].nunique())","2e20ead4":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.pairplot(data=df, vars=df.columns)\nplt.show()","c26800cc":"import math\nnumerical_vars = [feat for feat in df.select_dtypes(exclude='object').columns.to_list()]\n\nn_cols=3\nn_rows = math.ceil(len(numerical_vars)\/n_cols)\ni=0\n\nfig,ax=plt.subplots(n_rows, n_cols, figsize=(20,20))\n\nfor var in numerical_vars:\n    i += 1\n    plt.subplot(n_rows, n_cols, i)\n    plt.title(var)\n    sns.boxplot(x=df.A16, y=df[var])\n\nplt.show()","bd1ca7a9":"n_cols = 3\nn_rows = math.ceil(len(numerical_vars)\/n_cols)\ni=0\n\nfig,ax = plt.subplots(n_rows, n_cols, figsize=(20,20))\n\nfor var in numerical_vars:\n    i+=1\n    plt.subplot(n_rows, n_cols, i)\n    plt.title(var)\n    sns.swarmplot(x=df.A16, y=df[var])\n\nplt.show()","478fcd3e":"denied_df = df.loc[df.A16 == 0]\napproved_df = df.loc[df.A16 == 1]\n\nn_cols = 3\nn_rows = math.ceil(len(numerical_vars)\/n_cols)\ni=0\n\nfig,ax = plt.subplots(n_rows, n_cols, figsize=(20,10))\n\nfor var in numerical_vars:\n    i+=1\n    plt.subplot(n_rows, n_cols, i)\n    plt.title(var)\n    sns.distplot(a = denied_df[var], hist=False, label='denied', kde_kws={'bw':1.5}, color=\"#5982C5\")\n    sns.distplot(a = approved_df[var], hist=False, label='approved', kde_kws={'bw':1.5}, color=\"#FB3523\")\n\nplt.show()","9719cc83":"!pip install yellowbrick","f7b4d1f9":"from yellowbrick.target import FeatureCorrelation\nfrom yellowbrick.classifier import ClassBalance, ClassificationReport, ConfusionMatrix, DiscriminationThreshold\nfrom yellowbrick.features import JointPlotVisualizer, PCADecomposition, RadViz, Rank1D, Rank2D\n\nprint('Visual EDA ready!')","3ff38a4e":"# I usually implement copy() to preserver the original dataframe with which I can always revert back to when\n# there's a mistake in cleaning.\n\n# I need to drop the rows with None as the visualizers used below can't handle NA\ndf = df.dropna()\nX = df.drop('A16', axis=1, inplace=False)\ny = df[['A16']].astype('int')\n\nprint(f'Feature Variables: {X.shape}')\nprint(f'Target Variable: {y.shape}')\n\nX.head()","369c8cec":"feat_matrix = X.values\ntarget_vector = y.values.flatten()\n\nprint(f'Features: {feat_matrix.shape}')\nprint(f'Target\/Response: {target_vector.shape}')\n\nfeat_vars = X.columns.to_list()\ntarget_var = y.columns.to_list()\nprint(f'Feature Variables: {feat_vars}')\nprint(f'Target Variable: {target_var}')\n\ntarget_balance = ClassBalance(labels=['denied', 'approved'])\ntarget_balance.fit(target_vector)\ntarget_balance.show()","e582eeec":"numerical_vars = [feat for feat in X.select_dtypes(exclude='object').columns.to_list()]\n\nfeature_correlation = FeatureCorrelation(method='mutual_info-classification',\n                                        feature_names=numerical_vars,\n                                        sort=True)\n\nfeature_correlation.fit(X[numerical_vars], y[target_var].values.flatten())\nfeature_correlation.show()","8b595a1e":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndesign_matrix = X[numerical_vars].values\ntarget_vector = y.values.flatten()\n\nrad_viz = RadViz(classes=['denied', 'approved'], features=numerical_vars, colormap='winter')\n\nplt.figure(figsize=(10,10))\nrad_viz.fit(design_matrix, target_vector)\nrad_viz.show()","3d3174e1":"rank_1D = Rank1D(algorithm='shapiro', features=numerical_vars, color='goldenrod')\nrank_1D.fit_transform_show(design_matrix, target_vector)","cdceb1c7":"rand_2D = Rank2D(algorithm='pearson', features=numerical_vars, colormap='bwr')\nplt.figure(figsize=(10,10))\nrand_2D.fit_transform_show(design_matrix, target_vector)","b6c06605":"import seaborn as sns\n\nplt.figure(figsize=(10,10))\nax = sns.heatmap(abs(df.drop('A16', axis=1).corr()),\n                 vmin=0, vmax=1, center=0.5,\n                 cmap='RdYlGn_r',\n                 square=True,\n                 annot=True,\n                 annot_kws={\"size\": 12})\n\nax.set_xticklabels(ax.get_xticklabels(),\n                  rotation=45,\n                  horizontalalignment='right')","2044c05c":"colors = np.array(['red' if yi else 'blue' for yi in target_vector])\n\nplt.figure(figsize=(10,7))\npca = PCADecomposition(scale=True, proj_features=True)\npca.fit_transform_show(design_matrix, target_vector, colors=colors)","65f956b1":"categorical_vars = [feat for feat in X.select_dtypes(include='object').columns.to_list()]\ncategorical_vars","8269eb42":"n_cols = 4\nn_rows = math.ceil(len(categorical_vars)\/n_cols)\ni = 0\n\nfig,axs = plt.subplots(n_rows, n_cols, figsize=(20,10))\n\nfor var in categorical_vars:\n    i += 1\n    plt.subplot(n_rows,n_cols,i)\n    plt.title(var)\n    sns.barplot(x=df[var].value_counts().index, y=df[var].value_counts().values)\n\nplt.show()","9a6804fa":"These are the modules inside ```yellowbrick``` that I need to install.","767e44c3":"# **3. Visual EDA: Numerical Variables**","0f67d4d6":"## **2.3. Investigating Unique Values**","fc5ce49a":"## **3.3. Multivariate Target-Feature Correlation**\n\nThis is very powerful to perform an **initial check to detect separability of the classes**. This can be used as either an alternative or an augmentation to Principal Component Analysis which I will demonstrate later in this notebook.","8d8b55b5":"# **OBJECTIVE:**\n\nCreate a model that predicts whether given credit card application attributes, an application will be approved or not.\n\n## **Notebook Goal:**\n\nIn this particular notebook, we will implement the Exploratory Data Analysis (EDA) Phase of a Machine Learning Project. **Note that highlighted implementation here is the VISUAL EDA which I personally prefer as it allows easier inspection of the data!** It helps me better in understanding correlation, distribution, balance, etc.\n\nFuture notebooks will investigate the other parts of the CRISP-DM Stack for Machine Learning.\n\n## **WARNING!**\n\nAs you read through this very long notebook, you'll see that there are analysis that are **repetitive or redundant**. I simply showed several ways to extract the same form of analysis (sometimes using different visualization libraries). In the real-world workflow, you can adopt either method and you're good to go.","8fcdb6a8":"## **3.0. Basic Bivariate Analysis**","707eb5e1":"## **3.4. Feature Ranking**\n\nThis MAY or MAY NOT yield the same results as the previous analysis on correlation to target using ```feature_correlation```.","b707fb9b":"Note that **there are some columns which appear as OBJECT data type when they should be either float or integer.** These columns include\n* A2\n* A14\n\nSo let's convert these data types as ```float64```.","029e41e7":"Another analysis that can be performed is the correlation between the numeric and categorical variables. In particular, that towards the classes or the categorical target variable. We can use seaborn's boxplots for this.","6fc8f6cf":"This is probaly the worst way to do it. Take note that pairplots are useful to perform a preliminary analysis on numerical variables (sometimes even categorical ones may also provide insight). In the case of a dataset with large features, the pairplot can come out this messy. The way to deal with this is to either\n* extract only intuitive variables to analyze\n* split the features in small batches and investigate each batch\n* perform pairplots after performing feature importance analysis.","981b199a":"Let's verify with the following:\n    A1:  12\n    A2:  12\n    A4:   6\n    A5:   6\n    A6:   9\n    A7:   9\n    A14: 13","2be33440":"An alternative to the above visualization is to get the correlation matrix and visualize as a heatmap using seaborne and show the coefficient of correlation for a more objective investigation.","6e1a53e3":"# **2. Basic EDA**","699f750a":"# **MORE ADVANCED EDAs**","cf17dba3":"Looks like there are no missing values in the dataset. The original dataset defined in https:\/\/archive.ics.uci.edu\/ml\/datasets\/Credit+Approval however indicated that SUPPOSEDLY there are missing values. This was also indicated in the DESCRIPTION parsed above:\n\n37 cases (5%) have one or more missing values.  The missing values from particular attributes are:\n\n    A1:  12\n    A2:  12\n    A4:   6\n    A5:   6\n    A6:   9\n    A7:   9\n    A14: 13\n    \nNot sure if it has been imputed already?","3dfa2395":"Based on this, **there's no features that are multicollinear**. Hence, no need to drop any of these numerical features.","a33214f7":"## **3.1. Class Balance Check**\n\nNote that this is a Classification Problem. Thus, to avoid \"underfitting\" of model, it MAY BE important to check the balance between the datasets. \n* If one class is under-represented, model may risk simply memorizing the over-represented class and use it as a default prediction. This may result to **high false positives or false negatives*.\n* If both class are represented well, there's a better chance for the model to catch the real patterns or correlations between the feature variables and the target variable.","4e64ac57":"In all of my EDA workflows, I have an easier time understanding **statistics** visually. So I either create my own visualizing functions or use libraries that can aid in visual EDA. For the Visual EDA, I will be heavily using the ```yellowbrick``` library which I need to install.","bf44e19d":"## **3.2. Correlations to Target Variable**\n\nThis is very important to determine which amongst the numerical variables exhibit promising predictive power.","78e31e69":"**What can be said of the distributions of the numerical variables as seen above?**\n\nWell, for the most part, they have a lot of records in the lower values of the feature variables. It's very hard to deduce whether there's an anomaly here or not since the feature variables' true nature are hidden from us. But this is a usual scenario when dealing with datasets that are needed to be protected. You can either\n* assume that the data engineer or data analyst did a pre-cleaning of the dataset before it was handed over to you, a data scientist\n* or implement your best tuning of a predictive model without worrying too much about the intuitive background of the feature variables (which is very tricky when it comes to understanding the business value that can be derived from your model, or explaining the business implication behind how your model worked or did not work)","9241866a":"Other ways to implement bivariate analyses would be:\n* jointplot or a 2D KDE plot\n* a simple KDE plot\n* or a distplot\n\nAll of these are implementable with ```seaborn```.","40d83be6":"# **1. Load the Dataset**","334f1543":"**You can also create the side-by-side comparison of the distribution for EACH of the feature variables for each category in the other categorical variables, instead of the classification approved\/denied.** I opted not to illustrate it here as it will be too tedious!","9b36cd40":"What I did here is\n* get the absolute value of the correlation matrices since I am not interested in checking the direction of the correlation but more on the degree of correlation\n* I reversed the colormap to make the HIGH COLLINEARITIES as red! (It's more of something that I get accustomed to: red is danger!)","c4c72b99":"## **3.5. Pairwise Feature Correlation**","7dc9035e":"## **2.2. Investigating Missing Values**","df7dcf31":"Let's replace these \"?\" with ```None``` type instead.","e5d033ad":"Finally, let's conver the target variable ```A16``` into a binary classification label such that\n* ```+``` = 1 - approved credit application\n* ```-``` = 0 - approved credit application","93f13bd2":"Roughly, the information held by the 4 numerical variables regarding the target is well below 10 %. Arranged, it looks like A11 holds the most information (i.e. mostly highly predictive power) regarding the target variable A16.","ca9b90ac":"**What's very interesting however is the difference between the distribution for each class!**\n\n* For the most part, the majority of the distribution occurs at the same values of the feature variable.\n* However, there is more \"variance\" in distribution for the \"approved\" records in ALL of the feature variables compared to that of the \"denied\" records. This is interesting as it begs the question, \"Is there really a pattern of what a person's say net worth, total savings, past credit transactions, etc. to getting approved?\" That is of course, if these numerical variables are talking about this \"inferred\" variables. (There is a very large chance it's not because of the behaviour we are seeing here!)","450c05b9":"## **3.6. Principal Component Analysis (PCA)**","1949363f":"What we can analyze here are things such as\n* Compare the IQR between the classes for each numerical variable.\n* Determine whether there are outliers or maybe only outliers exist for a certain class.\n* Are the medians of the two classes the same or spread apart?\n* How \"intense\" is the amount of outliers? Are they significant enough to impact the model building?\n\n> 1. As you can see, **the IQR for approved credit card applications are on the higher end** for most of the numerical variables, **except for A15** where the comparison is too vague. **What does this entail about these specific numerical variables?** These are foretelling of the nature of approval of applications. However, we don't know what these variables are exactly as they are not disclosed from the dataset. We can only infer. Things such as ```monthly_income```, ```years_of_experience```, ```credit_score```, ```total_assets```, and what not could be these variables. Intuitively, the higher your records are for this, it can give you a better chance of getting approved. **Caveat however, this is only inference.**\n\n> 2. As you can see, in most of the variables **there are more outliers for denied applications** compared to approved applications. We are not sure why this is the case. We need to be careful when dealing with presence of large outliers **especially when it's an imbalanced classification dataset**. A pre-processing approach called **[Novel Pattern Synthesis (NPS)](shorturl.at\/jtwAD)** can be done to work around this. **Thankfully, as you'll see later, this dataset in particular is not imbalanced.**\n\n> 3. The medians for each class are not exactly far apart. In case they are, I am not sure if there's a study yet on how difference in class median affects the classification model. What's more important is the scale of the values for each class, then each variable. Check if there's a need to scale or normalize.\n\n> 4. The boxplots above demonstrate the substantial presence of outliers per class. This also aligns with the ```df.describe()``` implementation before where the min is VERY FAR from the mean of the dataset. **In most cases, dealing with outliers simply implies scaling the variables** which allows attributes to be in a common scale. This can be implemented with ```sklearn```.\n\n```\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n```\n\n**CAVEAT**:\nYou may want to CHECK whether removing or including the outliers improve your model or not.\n\nAlternatively, you can use a **swarmplot** instead of a boxplot to understand further your datasets in terms of the classes they are classified into.","68548777":"### **RESOLUTION:**\n\nUpon a much closer inspection, apparently, the original .data file used \"?\" to indicate missing values. Hence, technically it still contained a value, a string \"?\" at that. Let's inspect this further.\n\n**CAVEAT**\nNote that since the null values are indicated as the string \"?\", we can't simply use the usual ```.isnull().any()```. Instead, we can loop through all the records and return all records whose Series of values contain \"?\". This is saved into a new DataFrame as seen below:","5c9d00c9":"# **5. Conclusion**\n\nIn this notebook, there's no feature that was removed just yet since there was no sign of multi-collinearity. The columns with missing values are also not dropped yet (nor were the records). In the next notebook for data preprocessing, we can talk about how to\n* handle missing values\n* handle outliers\n* and feature engineering or feature selection\n\n**CAVEAT**\n\nNote that in this implementation, I demonstrated the techniques using the **entire training dataset**. In a more rigorous investigation, you can split the data into training and test first before implementing some of the EDAs. Examples would be distributions. This would allow you to check for representations, especially when there's an imbalance in the dataset.","06fcdc27":"The visualization above shows immediately that the classes are balanced. There's no drastic difference in terms of over or under-representation. As such, there's **no need to handle imbalanced dataset** in this notebook. I will try to look for a dataset with largely imbalanced dataset to illustrate handling of such dataset.","c60b7697":"## **2.1. Basic Summary Statistics**","3bd3da43":"# **4. Visual EDA: Categorical Variables**\n\nI separated this simply because it does not concern much abou","7e7e05b2":"Well, this looks like there's no clear separability of the two classes based on the 4 numerical variables visualized here. This is quite aligned with the analysis on the ```feature_correlation``` as well! In fact, if you can perform an ```r-squared``` analysis, it might show the same conclusion. This means that solely relying on the numerical variables to separate the approved vs. denied credit card applications is (OBVIOUSLY) not enough! Duh!\n\n**This might be a reach**, but based on the visualization above, **it looks like A2 and A3 tend to have a stronger effect**. This can be supported by the following feature ranking analysis using Shapiro algorithm.","f6dbb7d7":"Again, this would've made sense as well for use of checking anomaly. For example, you can check the min-max values of each category and check whether that would've made sense intuitively. For now, let's consider it cleaned!\n\nAnother approach to understanding categorical data is the use of ```crosstabs```."}}