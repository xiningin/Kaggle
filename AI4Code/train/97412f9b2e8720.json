{"cell_type":{"19c161af":"code","8d2042a2":"code","11dbd4a3":"code","5f4cfb3f":"code","aee83525":"code","e75f59fe":"code","86aea07c":"code","d1ca937a":"code","e5fc7cfd":"code","c8eda2a5":"code","6dd3fd27":"code","368b4517":"code","8f48743c":"code","c5c07017":"code","e731f1ff":"code","45cc6c1b":"code","14f18e52":"code","3f547cc8":"code","d533aa0d":"code","bd74ee00":"code","bb46b285":"code","aa6ac463":"code","33a5bafb":"code","fc9cf723":"code","3877a27e":"code","b6f8bb80":"code","0e695626":"code","e0e1de57":"code","d3a1584e":"code","25913c62":"code","fe3996ac":"code","1c7cab12":"code","ae4b9084":"code","cddf0d43":"code","5bc6a312":"code","2ddf018e":"code","b472032e":"code","f7053e4a":"code","c7529b2b":"code","31afa024":"code","69f2a8a6":"code","e2c8d19e":"code","d23ece46":"code","4c0f2b98":"code","5ab8f74b":"code","47aa0f59":"code","c81b6a0b":"code","596dde3b":"code","9a055be9":"code","bcc27876":"code","736730c6":"code","d1f54eba":"code","4c5fbcc4":"code","d53cdf38":"code","0805082a":"code","1b356b30":"code","48a38e3e":"code","c4f92f6f":"code","a9090bef":"code","97ec28dc":"code","a9ca7ee3":"code","3f74a8d9":"code","c076d5f5":"code","9979fd7d":"code","67adba1a":"code","ddbbaa44":"code","49195fcd":"code","b5c1b2f1":"code","f3bcd4a1":"code","09cb5c6c":"code","14f709cc":"code","60e567ae":"code","23bf00e4":"code","580cdca8":"code","c4dcfe28":"code","7ac83138":"code","61ece634":"code","d8997f9f":"code","6258291c":"code","6a0fff91":"code","b5585828":"code","58b9ef3d":"code","415b9f93":"code","c01ad5ef":"code","53396441":"code","5022746f":"code","b45f927b":"code","f2613fe2":"code","599d76a4":"code","61f7be06":"code","1aeb3a45":"code","d9d5ac0a":"code","ee9e4cdf":"code","e65dc3c1":"code","f2421d20":"code","17dffa66":"code","d10ac275":"code","0b2dff64":"code","d7af4e53":"markdown","68611923":"markdown","dd23031e":"markdown","e7e24757":"markdown","08c61a63":"markdown","fa6a5efd":"markdown","867a8f7f":"markdown","5edbcf30":"markdown","c21f234d":"markdown","838278a2":"markdown","51f90db9":"markdown","d3e169b1":"markdown","45095ff9":"markdown","339d3b99":"markdown","a9176444":"markdown","cb56aa07":"markdown","761eea73":"markdown","9e44adb1":"markdown","57b85b71":"markdown","f77aecca":"markdown","8eb35d3e":"markdown","96a7c13f":"markdown","ec10b1c5":"markdown","31a0284c":"markdown","840c02be":"markdown","6be71a7d":"markdown","b63248cb":"markdown","9c72aa03":"markdown","f39e595d":"markdown","51fd59f5":"markdown","5b52db09":"markdown","14891419":"markdown","cfe36f90":"markdown","212b86ff":"markdown","2affbaa5":"markdown","c449cd07":"markdown","93375ad3":"markdown","60b56aee":"markdown","73b298fe":"markdown","76c91897":"markdown","9ffde61c":"markdown","ebf015b5":"markdown","4c3b32cc":"markdown"},"source":{"19c161af":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.style.use(\"fivethirtyeight\")\nsns.set_style('whitegrid')\n%matplotlib inline\n\npd.set_option('display.float', '{:.2f}'.format)\npd.set_option('display.max_columns', 50)\npd.set_option('display.max_rows', 50)","8d2042a2":"data = pd.read_csv(\"\/kaggle\/input\/lending-club-dataset\/lending_club_loan_two.csv\")\ndata.head()","11dbd4a3":"data.describe()","5f4cfb3f":"data.info()","aee83525":"sns.countplot(data.loan_status)","e75f59fe":"plt.figure(figsize=(12, 8))\nsns.heatmap(data.corr(), annot=True, cmap='viridis')","86aea07c":"plt.figure(figsize=(12, 20))\n\nplt.subplot(4, 2, 1)\ndata[data[\"loan_status\"] == \"Fully Paid\"][\"installment\"].hist(bins=35, color='blue', label='loan_status = Fully Paid', alpha=0.8)\ndata[data[\"loan_status\"] == \"Charged Off\"][\"installment\"].hist(bins=35, color='red', label='loan_status = Charged Off', alpha=0.8)\nplt.legend()\nplt.xlabel(\"installment\")\n\nplt.subplot(4, 2, 2)\ndata[data[\"loan_status\"] == \"Fully Paid\"][\"loan_amnt\"].hist(bins=35, color='blue', label='loan_status = Fully Paid', alpha=0.8)\ndata[data[\"loan_status\"] == \"Charged Off\"][\"loan_amnt\"].hist(bins=35, color='red', label='loan_status = Charged Off', alpha=0.8)\nplt.legend()\nplt.xlabel(\"loan_amnt\")\n\nplt.subplot(4, 2, 3)\nsns.scatterplot(x='installment', y='loan_amnt', data=data)\n\nplt.subplot(4, 2, 4)\nsns.boxplot(x='loan_status', y='loan_amnt', data=data)","d1ca937a":"data.groupby(by='loan_status')['loan_amnt'].describe()","e5fc7cfd":"print(f\"GRADE unique: {data.grade.unique()}\")\nprint(f\"SUB_GRADE unique: {data.sub_grade.unique()}\")","c8eda2a5":"plt.figure(figsize=(15, 10))\n\nplt.subplot(2, 2, 1)\ngrade = sorted(data.grade.unique().tolist())\nsns.countplot(x='grade', data=data, hue='loan_status', order=grade)\n\nplt.subplot(2, 2, 2)\nsub_grade = sorted(data.sub_grade.unique().tolist())\ng = sns.countplot(x='sub_grade', data=data, hue='loan_status', order=sub_grade)\ng.set_xticklabels(g.get_xticklabels(), rotation=90);","6dd3fd27":"df = data[(data.grade == 'F') | (data.grade == 'G')]\n\nplt.figure(figsize=(15, 10))\n\nplt.subplot(2, 2, 1)\ngrade = sorted(df.grade.unique().tolist())\nsns.countplot(x='grade', data=df, hue='loan_status', order=grade)\n\nplt.subplot(2, 2, 2)\nsub_grade = sorted(df.sub_grade.unique().tolist())\nsns.countplot(x='sub_grade', data=df, hue='loan_status', order=sub_grade)","368b4517":"data.home_ownership.value_counts()","8f48743c":"data.loc[(data.home_ownership == 'ANY') | (data.home_ownership == 'NONE'), 'home_ownership'] = 'OTHER'  \ndata.home_ownership.value_counts()","c5c07017":"plt.figure(figsize=(15, 20))\n\nplt.subplot(4, 2, 1)\nsns.countplot(x='term', data=data, hue='loan_status')\n\nplt.subplot(4, 2, 2)\nsns.countplot(x='home_ownership', data=data, hue='loan_status')\n\nplt.subplot(4, 2, 3)\nsns.countplot(x='verification_status', data=data, hue='loan_status')\n\nplt.subplot(4, 2, 4)\ng = sns.countplot(x='purpose', data=data, hue='loan_status')\ng.set_xticklabels(g.get_xticklabels(), rotation=90);","e731f1ff":"plt.figure(figsize=(15, 10))\n\nplt.subplot(2, 2, 1)\ndata[data[\"loan_status\"] == \"Fully Paid\"][\"int_rate\"].hist(bins=35, color='blue', label='loan_status = Fully Paid', alpha=0.6)\ndata[data[\"loan_status\"] == \"Charged Off\"][\"int_rate\"].hist(bins=35, color='red', label='loan_status = Charged Off', alpha=0.6)\nplt.legend()\nplt.xlabel(\"int_rate\")\n\nplt.subplot(2, 2, 2)\ndata[data[\"loan_status\"] == \"Fully Paid\"][\"annual_inc\"].hist(bins=8, color='blue', label='loan_status = Fully Paid', alpha=0.6)\ndata[data[\"loan_status\"] == \"Charged Off\"][\"annual_inc\"].hist(bins=8, color='red', label='loan_status = Charged Off', alpha=0.6)\nplt.legend()\nplt.xlabel(\"annual_inc\")\n\ndf[\"annual_inc\"].head()","45cc6c1b":"# Extract more info from the annual_inc hist by limiting the range and increasing the bins\n\nplt.figure(figsize=(15, 10))\n\nplt.subplot(2, 2, 2)\ndata[data[\"loan_status\"] == \"Fully Paid\"][\"annual_inc\"].hist(bins=100, color='blue', label='loan_status = Fully Paid', alpha=0.6)\ndata[data[\"loan_status\"] == \"Charged Off\"][\"annual_inc\"].hist(bins=100, color='red', label='loan_status = Charged Off', alpha=0.6)\nplt.legend()\nplt.xlabel(\"annual_inc\")\nplt.xlim([0, 500000])","14f18e52":"data[data.annual_inc >= 1000000].shape","3f547cc8":"data.emp_title.isna().sum()","d533aa0d":"data['emp_title'] = data.emp_title.str.lower()","bd74ee00":"def manager(string):\n    if type(string) is str:\n        return 'manager' if 'manager' in string else string\n\ndef president(string):\n    if type(string) is str:\n        return 'president' if 'president' in string else string\n    \ndef nurse(string):\n    if type(string) is str:\n        return 'nurse' if 'nurse' in string else string\n    \ndef driver(string):\n    if type(string) is str:\n        return 'driver' if 'driver' in string else string\n    \ndef assistant(string):\n    if type(string) is str:\n        return 'assistant' if 'assistant' in string else string\n\ndef engineer(string):\n    if type(string) is str:\n        return 'engineer' if 'engineer' in string else string    \n\nfunctions = [manager, president, nurse, driver, assistant, engineer]\nfor func in functions:\n    data['emp_title'] = data.emp_title.apply(func)","bb46b285":"data.emp_title.value_counts()[:30]","aa6ac463":"plt.figure(figsize=(15, 12))\n\nplt.subplot(2, 2, 1)\norder = ['< 1 year', '1 year', '2 years', '3 years', '4 years', '5 years', \n          '6 years', '7 years', '8 years', '9 years', '10+ years',]\nsns.countplot(x='emp_length', data=data, hue='loan_status', order=order)\n\nplt.subplot(2, 2, 2)\nplt.barh(data.emp_title.value_counts()[:30].index, data.emp_title.value_counts()[:30])\nplt.title(\"The most 30 jobs title afforded a loan\")","33a5bafb":"plt.figure(figsize=(15, 12))\n\nplt.subplot(2, 2, 1)\ndata.issue_d.value_counts().sort_index().plot()\n\nplt.subplot(2, 2, 2)\ndata.earliest_cr_line.value_counts().sort_index().plot()","fc9cf723":"data.title.isna().sum()","3877a27e":"data['title'] = data.title.str.lower()","b6f8bb80":"data.title.value_counts()[:30]","0e695626":"data.dti.value_counts()","e0e1de57":"data[data.open_acc > 40].shape","d3a1584e":"data[data.total_acc > 80].shape","25913c62":"data[data.revol_bal < 10000].shape","fe3996ac":"data[data.revol_util > 200]","1c7cab12":"plt.figure(figsize=(15, 30))\n\nplt.subplot(6, 2, 1)\ndata[data[\"loan_status\"] == \"Fully Paid\"][\"dti\"].value_counts().hist(bins=35, color='blue', \n                                                                     label='loan_status = Fully Paid', alpha=0.6)\ndata[data[\"loan_status\"] == \"Charged Off\"][\"dti\"].value_counts().hist(bins=35, color='red', \n                                                                      label='loan_status = Charged Off', alpha=0.6)\nplt.legend()\nplt.xlabel(\"dti\")\n\nplt.subplot(6, 2, 2)\ndata[data[\"loan_status\"] == \"Fully Paid\"][\"open_acc\"].hist(bins=35, color='blue', label='loan_status = Fully Paid', alpha=0.6)\ndata[data[\"loan_status\"] == \"Charged Off\"][\"open_acc\"].hist(bins=35, color='red', label='loan_status = Charged Off', alpha=0.6)\nplt.legend()\nplt.xlabel(\"open_acc\")\n\nplt.subplot(6, 2, 3)\ndf = data[(data.revol_bal <= 10000)]\ndf[df[\"loan_status\"] == \"Fully Paid\"][\"revol_bal\"].hist(bins=35, color='blue', label='loan_status = Fully Paid', alpha=0.6)\ndf[df[\"loan_status\"] == \"Charged Off\"][\"revol_bal\"].hist(bins=35, color='red', label='loan_status = Charged Off', alpha=0.6)\nplt.legend()\nplt.xlabel(\"revol_bal\")\n\nplt.subplot(6, 2, 4)\ndata[data[\"loan_status\"] == \"Fully Paid\"][\"revol_util\"].hist(bins=35, color='blue', label='loan_status = Fully Paid', alpha=0.6)\ndata[data[\"loan_status\"] == \"Charged Off\"][\"revol_util\"].hist(bins=35, color='red', label='loan_status = Charged Off', alpha=0.6)\nplt.legend()\nplt.xlabel(\"revol_util\")\n\nplt.subplot(6, 2, 5)\ndf = data[(data.revol_bal <= 10000)]\ndf[df[\"loan_status\"] == \"Fully Paid\"][\"total_acc\"].hist(bins=35, color='blue', label='loan_status = Fully Paid', alpha=0.6)\ndf[df[\"loan_status\"] == \"Charged Off\"][\"total_acc\"].hist(bins=35, color='red', label='loan_status = Charged Off', alpha=0.6)\nplt.legend()\nplt.xlabel(\"total_acc\")\n","ae4b9084":"data.pub_rec.value_counts()","cddf0d43":"data.initial_list_status.value_counts()","5bc6a312":"data.application_type.value_counts()","2ddf018e":"data.mort_acc.value_counts()","b472032e":"data.pub_rec_bankruptcies.value_counts()","f7053e4a":"def pub_rec(number):\n    if number == 0.0:\n        return 0\n    else:\n        return 1\n    \ndef mort_acc(number):\n    if number == 0.0:\n        return 0\n    elif number >= 1.0:\n        return 1\n    else:\n        return number\n    \ndef pub_rec_bankruptcies(number):\n    if number == 0.0:\n        return 0\n    elif number >= 1.0:\n        return 1\n    else:\n        return number","c7529b2b":"data['pub_rec'] = data.pub_rec.apply(pub_rec)\ndata['mort_acc'] = data.mort_acc.apply(mort_acc)\ndata['pub_rec_bankruptcies'] = data.pub_rec_bankruptcies.apply(pub_rec_bankruptcies)","31afa024":"plt.figure(figsize=(12, 30))\n\nplt.subplot(6, 2, 1)\nsns.countplot(x='pub_rec', data=data, hue='loan_status')\n\nplt.subplot(6, 2, 2)\nsns.countplot(x='initial_list_status', data=data, hue='loan_status')\n\nplt.subplot(6, 2, 3)\nsns.countplot(x='application_type', data=data, hue='loan_status')\n\nplt.subplot(6, 2, 4)\nsns.countplot(x='mort_acc', data=data, hue='loan_status')\n\nplt.subplot(6, 2, 5)\nsns.countplot(x='pub_rec_bankruptcies', data=data, hue='loan_status')","69f2a8a6":"data['loan_status'] = data.loan_status.map({'Fully Paid':0, 'Charged Off':1})","e2c8d19e":"plt.figure(figsize=(8, 5))\ndata.corr()['loan_status'].drop('loan_status').sort_values().plot(kind='barh')","d23ece46":"# The length of the data\nprint(f\"The Length of the data: {data.shape}\")","4c0f2b98":"# Missing values\nfor column in data.columns:\n    if data[column].isna().sum() != 0:\n        missing = data[column].isna().sum()\n        portion = (missing \/ data.shape[0]) * 100\n        print(f\"'{column}': number of missing values '{missing}' ==> '{portion:.3f}%'\")","5ab8f74b":"data.emp_title.nunique()","47aa0f59":"data.drop('emp_title', axis=1, inplace=True)","c81b6a0b":"data.emp_length.unique()","596dde3b":"for year in data.emp_length.unique():\n    print(f\"{year} years in this position:\")\n    print(f\"{data[data.emp_length == year].loan_status.value_counts(normalize=True)}\")\n    print('==========================================')","9a055be9":"data.drop('emp_length', axis=1, inplace=True)","bcc27876":"data.title.value_counts().head()","736730c6":"data.purpose.value_counts().head()","d1f54eba":"data.drop('title', axis=1, inplace=True)","4c5fbcc4":"data.mort_acc.value_counts()","d53cdf38":"data.mort_acc.isna().sum()","0805082a":"plt.figure(figsize=(8, 5))\ndata.corr()['mort_acc'].drop('mort_acc').sort_values().plot(kind='barh')","1b356b30":"total_acc_avg = data.groupby(by='total_acc').mean().mort_acc","48a38e3e":"def fill_mort_acc(total_acc, mort_acc):\n    if np.isnan(mort_acc):\n        return total_acc_avg[total_acc].round()\n    else:\n        return mort_acc","c4f92f6f":"data['mort_acc'] = data.apply(lambda x: fill_mort_acc(x['total_acc'], x['mort_acc']), axis=1)","a9090bef":"for column in data.columns:\n    if data[column].isna().sum() != 0:\n        missing = data[column].isna().sum()\n        portion = (missing \/ data.shape[0]) * 100\n        print(f\"'{column}': number of missing values '{missing}' ==> '{portion:.3f}%'\")","97ec28dc":"data.dropna(inplace=True)","a9ca7ee3":"data.shape","3f74a8d9":"print([column for column in data.columns if data[column].dtype == object])","c076d5f5":"data.term.unique()","9979fd7d":"term_values = {' 36 months': 36, ' 60 months': 60}\ndata['term'] = data.term.map(term_values)","67adba1a":"data.term.unique()","ddbbaa44":"data.drop('grade', axis=1, inplace=True)","49195fcd":"dummies = ['sub_grade', 'verification_status', 'purpose', 'initial_list_status', \n           'application_type', 'home_ownership']\ndata = pd.get_dummies(data, columns=dummies, drop_first=True)","b5c1b2f1":"data.head()","f3bcd4a1":"data.address.head()","09cb5c6c":"data['zip_code'] = data.address.apply(lambda x: x[-5:])","14f709cc":"data.zip_code.value_counts()","60e567ae":"data = pd.get_dummies(data, columns=['zip_code'], drop_first=True)","23bf00e4":"data.drop('address', axis=1, inplace=True)","580cdca8":"data.head()","c4dcfe28":"data.drop('issue_d', axis=1, inplace=True)","7ac83138":"data['earliest_cr_line'] = data.earliest_cr_line.str.split('-', expand=True)[1]","61ece634":"data.earliest_cr_line.nunique()","d8997f9f":"# print(f\"Data shape: {data.shape}\")\n\n# # Remove duplicate Features\n# data = data.T.drop_duplicates()\n# data = data.T\n\n# # Remove Duplicate Rows\n# data.drop_duplicates(inplace=True)\n\n# print(f\"Data shape: {data.shape}\")","6258291c":"w_p = data.loan_status.value_counts()[0] \/ data.shape[0]\nw_n = data.loan_status.value_counts()[1] \/ data.shape[0]\n\nprint(f\"Weight of positive values {w_p}\")\nprint(f\"Weight of negative values {w_n}\")","6a0fff91":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nX = data.drop('loan_status', axis=1)\ny = data.loan_status\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","b5585828":"scaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","58b9ef3d":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\n\ndef print_score(true, pred, train=True):\n    if train:\n        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n        print(\"Train Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")\n        \n    elif train==False:\n        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n        print(\"Test Result:\\n================================================\")        \n        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")","415b9f93":"X_train = np.array(X_train).astype(np.float32)\nX_test = np.array(X_test).astype(np.float32)\ny_train = np.array(y_train).astype(np.float32)\ny_test = np.array(y_test).astype(np.float32)","c01ad5ef":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import AUC","53396441":"def evaluate_nn(true, pred, train=True):\n    if train:\n        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n        print(\"Train Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")\n        \n    elif train==False:\n        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n        print(\"Test Result:\\n================================================\")        \n        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")\n        \ndef plot_learning_evolution(r):\n    plt.figure(figsize=(12, 8))\n    \n    plt.subplot(2, 2, 1)\n    plt.plot(r.history['loss'], label='Loss')\n    plt.plot(r.history['val_loss'], label='val_Loss')\n    plt.title('Loss evolution during trainig')\n    plt.legend()\n\n    plt.subplot(2, 2, 2)\n    plt.plot(r.history['AUC'], label='AUC')\n    plt.plot(r.history['val_AUC'], label='val_AUC')\n    plt.title('AUC score evolution during trainig')\n    plt.legend();\n\ndef nn_model(num_columns, num_labels, hidden_units, dropout_rates, learning_rate):\n    inp = tf.keras.layers.Input(shape=(num_columns, ))\n    x = BatchNormalization()(inp)\n    x = Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)):\n        x = Dense(hidden_units[i], activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(dropout_rates[i + 1])(x)\n    x = Dense(num_labels, activation='sigmoid')(x)\n  \n    model = Model(inputs=inp, outputs=x)\n    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=[AUC(name='AUC')])\n    return model","5022746f":"num_columns = X_train.shape[1]\nnum_labels = 1\nhidden_units = [150, 150, 150]\ndropout_rates = [0.1, 0, 0.1, 0]\nlearning_rate = 1e-3\n\n\nmodel = nn_model(\n    num_columns=num_columns, \n    num_labels=num_labels,\n    hidden_units=hidden_units,\n    dropout_rates=dropout_rates,\n    learning_rate=learning_rate\n)\nr = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=150,\n    batch_size=32\n)","b45f927b":"plot_learning_evolution(r)","f2613fe2":"y_train_pred = model.predict(X_train)\nevaluate_nn(y_train, y_train_pred.round(), train=True)","599d76a4":"y_test_pred = model.predict(X_test)\nevaluate_nn(y_test, y_test_pred.round(), train=False)","61f7be06":"scores_dict = {\n    'ANNs': {\n        'Train': roc_auc_score(y_train, model.predict(X_train)),\n        'Test': roc_auc_score(y_test, model.predict(X_test)),\n    },\n}","1aeb3a45":"from xgboost import XGBClassifier\n\nn_estimators = [50, 100, 200]\nlearning_rate = [0.05, 0.01, 0.5, 0.1, 1]\ntree_method = ['gpu_hist']\n\nparams_grid = {\n    'n_estimators': n_estimators,\n#     'learning_rate': learning_rate,\n}\n\nxgb_clf = XGBClassifier()\nxgb_cv = GridSearchCV(xgb_clf, params_grid, cv=3, scoring='roc_auc', n_jobs=-1, verbose=1)\n# xgb_cv.fit(X_train, y_train)\n# best_params = xgb_cv.best_params_\n# best_params['tree_method'] = 'gpu_hist'\nbest_params = {'n_estimators': 50, 'tree_method': 'gpu_hist'}\nprint(f\"Best Parameters: {best_params}\")\n\nxgb_clf = XGBClassifier(**best_params)\nxgb_clf.fit(X_train, y_train)\n\ny_train_pred = xgb_clf.predict(X_train)\ny_test_pred = xgb_clf.predict(X_test)\n\nprint_score(y_train, y_train_pred, train=True)\nprint_score(y_test, y_test_pred, train=False)","d9d5ac0a":"from sklearn.metrics import plot_confusion_matrix, plot_roc_curve\n\ndisp = plot_confusion_matrix(xgb_clf, X_test, y_test, \n                             cmap='Blues', values_format='d', \n                             display_labels=['Fully-Paid', 'Default'])\n\ndisp = plot_roc_curve(xgb_clf, X_test, y_test)","ee9e4cdf":"scores_dict['XGBoost'] = {\n        'Train': roc_auc_score(y_train, xgb_clf.predict(X_train)),\n        'Test': roc_auc_score(y_test, xgb_clf.predict(X_test)),\n    }","e65dc3c1":"from sklearn.ensemble import RandomForestClassifier\n\nrf_clf = RandomForestClassifier(n_estimators=100)\nrf_clf.fit(X_train, y_train)\n\ny_train_pred = rf_clf.predict(X_train)\ny_test_pred = rf_clf.predict(X_test)\n\nprint_score(y_train, y_train_pred, train=True)\nprint_score(y_test, y_test_pred, train=False)","f2421d20":"disp = plot_confusion_matrix(rf_clf, X_test, y_test, \n                             cmap='Blues', values_format='d', \n                             display_labels=['Fully-Paid', 'Default'])\n\ndisp = plot_roc_curve(xgb_clf, X_test, y_test)\nplot_roc_curve(rf_clf, X_test, y_test, ax=disp.ax_)","17dffa66":"scores_dict['Random Forest'] = {\n        'Train': roc_auc_score(y_train, rf_clf.predict(X_train)),\n        'Test': roc_auc_score(y_test, rf_clf.predict(X_test)),\n    }","d10ac275":"ml_models = {\n    'Random Forest': rf_clf, \n    'XGBoost': xgb_clf, \n    'ANNs': model\n}\n\nfor model in ml_models:\n    print(f\"{model.upper():{30}} roc_auc_score: {roc_auc_score(y_test, ml_models[model].predict(X_test)):.3f}\")","0b2dff64":"scores_df = pd.DataFrame(scores_dict)\nscores_df.plot(kind='barh', figsize=(15, 8))","d7af4e53":"We noticed almost perfect correlation between \"`loan_amnt`\" the \"`installment`\" feature. We'll explore this features further. Print out their descriptions and perform a scatterplot between them. \n\n- Does this relationship make sense to you? \n- Do we think there is duplicate information here?","68611923":"- It seems that loans with high intersest rate are more likely to be unpaid.\n- Only 75 borrowers have an annual income more than 1 million.","dd23031e":"## How numeric features correlate with the target variable?","e7e24757":"### `grade` & `sub_grade`\nLet's explore the Grade and SubGrade columns that LendingClub attributes to the loans. \n\nWhat are the unique possible `grade` & `sub_grade`?","08c61a63":"The title column is simply a string subcategory\/description of the purpose column. So we are going to drop the title column.","fa6a5efd":"### `dti`, `open_acc`, `revol_bal`, `revol_util`, & `total_acc`","867a8f7f":"Charge off rates are extremely similar across all employment lengths. So we are going to drop the `emp_length` column.","5edbcf30":"### `issue_d`, `earliest_cr_line`","c21f234d":"# 7. 1. Artificial Neural Networks (ANNs)","838278a2":"### `loan_amnt` & `installment`","51f90db9":"### `grade` & `sub_grade`\n\nWe know that `grade` is just a sub feature of `sub_grade`, So we are goinig to drop it.","d3e169b1":"### `loan_status`","45095ff9":"It looks like `F` and `G` subgrades don't get paid back that often. Isloate those and recreate the countplot just for those subgrades.","339d3b99":"# 7. 3. Random Forest Classifier","a9176444":"# 8. Comparing Models Prerformance","cb56aa07":"## Train Test Split","761eea73":"### `term`","9e44adb1":"### `title`","57b85b71":"### `earliest_cr_line`\nThis appears to be a historical time stamp feature. Extract the year from this feature using a `.apply()` function, then convert it to a numeric feature.","f77aecca":"## Check for duplicates columns & features","8eb35d3e":"Looks like the total_acc feature correlates with the mort_acc , this makes sense! Let's try this fillna() approach. We will group the dataframe by the total_acc and calculate the mean value for the mort_acc per total_acc entry. To get the result below:","96a7c13f":"### `emp_title` & `emp_length`","ec10b1c5":"### `pub_rec`, `initial_list_status`, `application_type`, `mort_acc`, & `pub_rec_bankruptcies`","31a0284c":"### `emp_length`","840c02be":"### `mort_acc`\n\nThere are many ways we could deal with this missing data. We could attempt to build a simple model to fill it in, such as a linear model, we could just fill it in based on the mean of the other columns, or you could even bin the columns into categories and then set NaN as its own category. There is no 100% correct approach! \n\nLet's review the other columsn to see which most highly correlates to mort_acc","6be71a7d":"- It seems that the smaller the `dti` the more likely that the loan will not be paid.\n- Only `217` borrower have more than `40` open credit lines.\n- Only `266` borrower have more than `80` credit line in the borrower credit file.","b63248cb":"### `issue_d` \n\nThis would be data leakage, we wouldn't know beforehand whether or not a loan would be issued when using our model, so in theory we wouldn't have an issue_date, drop this feature.","9c72aa03":"### `term`, `home_ownership`, `verification_status` & `purpose`","f39e595d":"## Normalizing the data","51fd59f5":"### `address`\nWe are going to feature engineer a zip code column from the address in the data set. Create a column called 'zip_code' that extracts the zip code from the address column.","5b52db09":"# 5. Exploratory Data Analysis\n\n**OVERALL GOAL:** \n- Get an understanding for which variables are important, view summary statistics, and visualize the data","14891419":"# 6. Data PreProcessing\n\n**Section Goals:** \n- Remove or fill any missing data. \n- Remove unnecessary or repetitive features. \n- Convert categorical string features to dummy variables.","cfe36f90":"# Loan Analysis Problem Statement\n\n# 1. Introduction\n\n## What is`LendingClub`? \nA  peer-to-peer lending company, headquartered in San Francisco, California. It was the first peer-to-peer lender to register its offerings as securities with the Securities and Exchange Commission (SEC), and to offer loan trading on a secondary market. `LendingClub` is the world's largest peer-to-peer lending platform.\n\n## How will this case study help you?\n\nSolving this case study can help you in the following ways:\n- Give you an idea about how real business problems are solved using Machine Learning\n- Develop a basic understanding of risk analytics in banking and financial services and understand how data is used to minimise the risk of losing money while lending to customers.\n\n# 2. Business Understanding\n\nYou work for the `LendingClub` company which specialises in lending various types of loans to urban customers. When the company receives a loan application, the company has to make a decision for loan approval based on the applicant\u2019s profile. Two types of risks are associated with the bank\u2019s decision:\n\n- If the applicant is likely to repay the loan, then not approving the loan results in a loss of business to the company\n- If the applicant is not likely to repay the loan, i.e. he\/she is likely to default, then approving the loan may lead to a financial loss for the company\n\nThe data given contains the information about past loan applicants and whether they \u2018defaulted\u2019 or not. The aim is to identify patterns which indicate if a person is likely to default, which may be used for taking\nactions such as denying the loan, reducing the amount of loan, lending (to risky applicants) at a higher interest rate, etc.\n\nWhen a person applies for a loan, there are two types of decisions that could be taken by the company:\n1. `Loan accepted`: If the company approves the loan, there are 3 possible scenarios described below:\n    - `Fully paid`: Applicant has fully paid the loan (the principal and the interest rate)\n    - `Current`: Applicant is in the process of paying the instalments, i.e. the tenure of the loan is not yet completed. These candidates are not labelled as 'defaulted'.\n    - `Charged-off`: Applicant has not paid the instalments in due time for a long period of time, i.e. he\/she has defaulted on the loan\n2. `Loan rejected`: The company had rejected the loan (because the candidate does not meet their requirements etc.). Since the loan was rejected, there is no transactional history of those applicants with the company and so this data is not available with the company (and thus in this dataset)\n\n# 3. Business Objectives\n- `LendingClub` is the largest online loan marketplace, facilitating personal loans, business loans, and financing of medical procedures. Borrowers can easily access lower interest rate loans through a fast online interface. \n- Like most other lending companies, lending loans to \u2018`risky`\u2019 applicants is the largest source of financial loss (called `credit loss`). The credit loss is the amount of money lost by the lender when the borrower refuses to pay or runs away with the money owed. In other words, borrowers who defaultcause the largest amount of loss to the lenders. In this case, the customers labelled as '`charged-off`' are the '`defaulters`'. \n- If one is able to identify these risky loan applicants, then such loans can be reduced thereby cutting down the amount of credit loss. Identification of such applicants using EDA and machine learning is the aim of this case study. \n- In other words, the company wants to understand the driving factors (or driver variables) behind loan default, i.e. the variables which are strong indicators of default. The company can utilise this knowledge for its portfolio and risk assessment. \n- To develop your understanding of the domain, you are advised to independently research a little about risk analytics (understanding the types of variables and their significance should be enough).\n\n# 4. Data Description\n\n----\n-----\nHere is the information on this particular data set:\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>LoanStatNew<\/th>\n      <th>Description<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>loan_amnt<\/td>\n      <td>The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>term<\/td>\n      <td>The number of payments on the loan. Values are in months and can be either 36 or 60.<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>int_rate<\/td>\n      <td>Interest Rate on the loan<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>installment<\/td>\n      <td>The monthly payment owed by the borrower if the loan originates.<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>grade<\/td>\n      <td>LC assigned loan grade<\/td>\n    <\/tr>\n    <tr>\n      <th>5<\/th>\n      <td>sub_grade<\/td>\n      <td>LC assigned loan subgrade<\/td>\n    <\/tr>\n    <tr>\n      <th>6<\/th>\n      <td>emp_title<\/td>\n      <td>The job title supplied by the Borrower when applying for the loan.*<\/td>\n    <\/tr>\n    <tr>\n      <th>7<\/th>\n      <td>emp_length<\/td>\n      <td>Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years.<\/td>\n    <\/tr>\n    <tr>\n      <th>8<\/th>\n      <td>home_ownership<\/td>\n      <td>The home ownership status provided by the borrower during registration\u00a0or obtained from the credit report.\u00a0Our values are: RENT, OWN, MORTGAGE, OTHER<\/td>\n    <\/tr>\n    <tr>\n      <th>9<\/th>\n      <td>annual_inc<\/td>\n      <td>The self-reported annual income provided by the borrower during registration.<\/td>\n    <\/tr>\n    <tr>\n      <th>10<\/th>\n      <td>verification_status<\/td>\n      <td>Indicates if income was verified by LC, not verified, or if the income source was verified<\/td>\n    <\/tr>\n    <tr>\n      <th>11<\/th>\n      <td>issue_d<\/td>\n      <td>The month which the loan was funded<\/td>\n    <\/tr>\n    <tr>\n      <th>12<\/th>\n      <td>loan_status<\/td>\n      <td>Current status of the loan<\/td>\n    <\/tr>\n    <tr>\n      <th>13<\/th>\n      <td>purpose<\/td>\n      <td>A category provided by the borrower for the loan request.<\/td>\n    <\/tr>\n    <tr>\n      <th>14<\/th>\n      <td>title<\/td>\n      <td>The loan title provided by the borrower<\/td>\n    <\/tr>\n    <tr>\n      <th>15<\/th>\n      <td>zip_code<\/td>\n      <td>The first 3 numbers of the zip code provided by the borrower in the loan application.<\/td>\n    <\/tr>\n    <tr>\n      <th>16<\/th>\n      <td>addr_state<\/td>\n      <td>The state provided by the borrower in the loan application<\/td>\n    <\/tr>\n    <tr>\n      <th>17<\/th>\n      <td>dti<\/td>\n      <td>A ratio calculated using the borrower\u2019s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower\u2019s self-reported monthly income.<\/td>\n    <\/tr>\n    <tr>\n      <th>18<\/th>\n      <td>earliest_cr_line<\/td>\n      <td>The month the borrower's earliest reported credit line was opened<\/td>\n    <\/tr>\n    <tr>\n      <th>19<\/th>\n      <td>open_acc<\/td>\n      <td>The number of open credit lines in the borrower's credit file.<\/td>\n    <\/tr>\n    <tr>\n      <th>20<\/th>\n      <td>pub_rec<\/td>\n      <td>Number of derogatory public records<\/td>\n    <\/tr>\n    <tr>\n      <th>21<\/th>\n      <td>revol_bal<\/td>\n      <td>Total credit revolving balance<\/td>\n    <\/tr>\n    <tr>\n      <th>22<\/th>\n      <td>revol_util<\/td>\n      <td>Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.<\/td>\n    <\/tr>\n    <tr>\n      <th>23<\/th>\n      <td>total_acc<\/td>\n      <td>The total number of credit lines currently in the borrower's credit file<\/td>\n    <\/tr>\n    <tr>\n      <th>24<\/th>\n      <td>initial_list_status<\/td>\n      <td>The initial listing status of the loan. Possible values are \u2013 W, F<\/td>\n    <\/tr>\n    <tr>\n      <th>25<\/th>\n      <td>application_type<\/td>\n      <td>Indicates whether the loan is an individual application or a joint application with two co-borrowers<\/td>\n    <\/tr>\n    <tr>\n      <th>26<\/th>\n      <td>mort_acc<\/td>\n      <td>Number of mortgage accounts.<\/td>\n    <\/tr>\n    <tr>\n      <th>27<\/th>\n      <td>pub_rec_bankruptcies<\/td>\n      <td>Number of public record bankruptcies<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n\n---\n----","212b86ff":"### `int_rate` & `annual_inc`","2affbaa5":"### `title`","c449cd07":"`title` will be removed because we have the `purpose` column with is generated from it.","93375ad3":"Realistically there are too many unique job titles to try to convert this to a dummy variable feature. Let's remove that emp_title column.","60b56aee":"## Categorical Variables and Dummy Variables","73b298fe":"### `revol_util` & `pub_rec_bankruptcies`\nThese two features have missing data points, but they account for less than 0.5% of the total data. So we are going to remove the rows that are missing those values in those columns with dropna().","76c91897":"### `emp_title`","9ffde61c":"# 7. Models Building","ebf015b5":"****\n## Conclusion:\n\nWe notice that, there are broadly three types of features: \n- 1. Features related to the applicant (demographic variables such as occupation, employment details etc.), \n- 2. Features related to loan characteristics (amount of loan, interest rate, purpose of loan etc.) \n****","4c3b32cc":"# 7. 2. XGBoost Classifier"}}