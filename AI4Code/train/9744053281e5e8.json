{"cell_type":{"82a653dd":"code","81ee56fc":"code","3285559a":"code","82771008":"code","f1178f29":"code","b3721d74":"code","cff4f8c3":"code","39e97057":"code","46c067cc":"code","38c38a83":"code","38383ef5":"code","b6e228e0":"code","3e0d8447":"code","98bba6e8":"code","7ed61808":"code","840137c4":"code","ba32327b":"markdown","118bc40a":"markdown","17b2a008":"markdown","0e04d3c5":"markdown","105b11c5":"markdown","4ace4c75":"markdown","50551d94":"markdown","54689b98":"markdown","e5feb8b1":"markdown","bc3f7839":"markdown","9fd279c9":"markdown","091e2675":"markdown","ce6ff430":"markdown","d3d505bc":"markdown","df5d41cb":"markdown","eda6a78a":"markdown","b7f99367":"markdown","27e909db":"markdown","0c948693":"markdown","e465ddf4":"markdown","5153d28c":"markdown","0557b925":"markdown","73015225":"markdown","badbc560":"markdown","2384bd92":"markdown","1bc94703":"markdown","8fb7cb58":"markdown"},"source":{"82a653dd":"# Importing the Keras libraries and packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop , Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\ntrain = pd.read_csv(\"..\/input\/train.csv\")\n\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\n\n\nY_train = train[\"label\"]\n\n# Drop 'label' column\nX_train = train.drop(labels = [\"label\"],axis = 1) \n\n","81ee56fc":"sns.countplot(Y_train)  ","3285559a":"Y_train.value_counts()","82771008":"# Check the data\nX_train.isnull().any().describe()","f1178f29":"# Normalize the data                   \nX_train = X_train \/ 255.0         \ntest = test \/ 255.0\n\n\n# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\n","b3721d74":"# Encode labels to one hot vectors\nY_train = to_categorical(Y_train, num_classes = 10)","cff4f8c3":"# Set the random seed\nrandom_seed = 42\n\n# Split the train and the validation set for the fitting\nX_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size = 0.1,\n                                                  random_state=42)\n","39e97057":"# Show an image\nplt.imshow(X_train[2][:,:,0])","46c067cc":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  \n        vertical_flip=False)  \n\n\ndatagen.fit(X_train)","38c38a83":"# Set the CNN model \n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',  \n                 activation ='relu', input_shape = (28,28,1)))\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Dropout(0.25))\n\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\n\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n\nmodel.add(Dropout(0.25))\n\n\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation = \"relu\"))\n\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(10, activation = \"softmax\"))\n","38383ef5":"# Define the optimizer\n\noptimizer = RMSprop(lr=0.001, rho=0.9, decay=0.0)  ","b6e228e0":"# Compile the model\n\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","3e0d8447":"# Set a learning rate annealer - in model.fitgenerator callbacks\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\nepochs = 2            \nbatch_size = 64\n","98bba6e8":"# Fit the model with augmentation\nmodel.fit_generator(datagen.flow(X_train,Y_train,\n                                 batch_size=batch_size),\n                                 epochs = epochs,\n                                 validation_data = (X_test,Y_test),\n                                 verbose = 2,\n                                 steps_per_epoch=X_train.shape[0] \/\/ batch_size,\n                                 callbacks=[learning_rate_reduction])\n","7ed61808":"results = model.predict(X_test)","840137c4":"# select the indix with the maximum probability\n\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\n\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"CNN Results- .csv\",index=False)\n","ba32327b":"### Split dataset","118bc40a":"# CNN - Keras\n\n\n- Import images\n- Image Reshaping\n- Data Augmentation\n- Build the CNN\n- Optimizer\n- Compile the Model\n- Learning Rate - Epoch - Batch_size\n- Fit the model\n- Make Predictions","17b2a008":"# Image Reshaping","0e04d3c5":"# Build the CNN","105b11c5":"## ANN\n\nArtificial Neural Network model to classify images.\n\n\n<img style=\"float: left;\" src=\"https:\/\/groupfuturista.com\/blog\/wp-content\/uploads\/2019\/03\/Artificial-Neural-Networks-Man-vs-Machine.jpeg\" width=\"650px\"\/>","4ace4c75":"### Predict results","50551d94":"# Import libraries and load the dataset","54689b98":"### Results Submission","e5feb8b1":"# Fit the Model","bc3f7839":"# Optimizer","9fd279c9":"# CCN - Multilabel Image Classification","091e2675":"# Build a CNN Multilabel Image Classifier\n\n\n## CNN Workflow\n\n- Convolution operation\n- ReLU\n- Pooling\n- Flattening\n- ANN","ce6ff430":"### Check if dataset is balanced","d3d505bc":"## Pooling\n\nPooling layers are used to downsample the image.\nPooling layers help in reducing the number of parameters required and hence, this reduces the computation required. Pooling also helps in avoiding overfitting. There are two types of pooling operation that could be done:\n\n- Max Pooling\u200a\u2014\u200aSelecting the maximum value\n- Average Pooling\u200a\u2014\u200aSum all of the values and dividing it by the total number of values\n\nIn this case we use Max Pooling\n\n<img style=\"float: left;\" src=\"https:\/\/cdn-images-1.medium.com\/max\/1600\/1*GksqN5XY8HPpIddm5wzm7A.jpeg\" width=\"750px\"\/>\n","df5d41cb":"## Flattening\n\nFlattening is converting the data into a 1-dimensional array for inputting it to the next layer. We flatten the output of the convolutional layers to create a single long feature vector. And it is connected to the final classification model, which is called a fully-connected layer.\n\n<img style=\"float: left;\" src=\"https:\/\/sds-platform-private.s3-us-east-2.amazonaws.com\/uploads\/73_blog_image_1.png\" width=\"650px\"\/>\n\n\n<img style=\"float: left;\" src=\"https:\/\/sds-platform-private.s3-us-east-2.amazonaws.com\/uploads\/73_blog_image_2.png\" width=\"650px\"\/>","eda6a78a":"<img style=\"float: left;\" src=\"https:\/\/cdn-images-1.medium.com\/max\/1600\/1*uAeANQIOQPqWZnnuH-VEyw.jpeg\" width=\"650px\"\/>","b7f99367":"<img style=\"float: left;\" src=\"\" width=\"850px\"\/>","27e909db":"# Must see\n\n- CNN Visualization\n\nVisualization of a Convolutional Neural Network\n  http:\/\/scs.ryerson.ca\/~aharley\/vis\/\n\n\n\n2D Visualization of a Convolutional Neural Network\n  http:\/\/scs.ryerson.ca\/~aharley\/vis\/conv\/flat.html\n\n\n\n2D Visualization of a Fully-Connected Neural Network\n  http:\/\/scs.ryerson.ca\/~aharley\/vis\/fc\/flat.html\n\n\n\n3D Visualization of a Convolutional Neural Network\n  http:\/\/scs.ryerson.ca\/~aharley\/vis\/conv\/\n\n\n\n3D Visualization of a Fully-Connected Neural Network\n  http:\/\/scs.ryerson.ca\/~aharley\/vis\/fc\/\n\n\nThanks to -->  Adam Harley  http:\/\/www.cs.cmu.edu\/~aharley\/\n\n\n\n- ANN Visualization\n\nhttps:\/\/playground.tensorflow.org\/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.87664&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false","0c948693":"\n### *https:\/\/www.kaggle.com\/giovanninig\/kernels*","e465ddf4":"<img style=\"float: left;\" src=\"https:\/\/wallpaperaccess.com\/full\/684045.jpg\" width=\"850px\"\/>","5153d28c":"### Show an image example","0557b925":"# Data Augmentation","73015225":"## Convolution Operation\n\nIn each convolution layer, we take a filter of a small size and move that filter across the image and perform convolution operations. Convolution operations are nothing but element-wise matrix multiplication between the filter values and the pixels in the image and the resultant values are summed.\nConvo layer is sometimes called feature extractor layer because features of the image are get extracted within this layer.  \n\n\n## ReLU\nReLU is used to to make all negative value to zero and increase non-linearity within images. \n\n\n<img style=\"float: left;\" src=\"https:\/\/sds-platform-private.s3-us-east-2.amazonaws.com\/uploads\/71_blog_image_1.png\" width=\"750px\"\/>","badbc560":"<img style=\"float: left;\" src=\"https:\/\/cdn-images-1.medium.com\/max\/1600\/1*uAeANQIOQPqWZnnuH-VEyw.jpeg\" width=\"800px\"\/>","2384bd92":"### Encode labels to one hot vectors (ex : 3 -> [0,0,0,1,0,0,0,0,0,0])","1bc94703":"# Compile the model","8fb7cb58":"# Learning Rate - Epoch - Batch_size"}}