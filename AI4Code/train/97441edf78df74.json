{"cell_type":{"2f5b4b75":"code","e4257537":"code","f1756701":"code","35108ca6":"code","5ef14ad4":"code","09b21aae":"code","71f8a144":"code","d624a52f":"code","473a216e":"code","459c7d5d":"code","28b921ea":"code","1f35c72c":"code","aa235a45":"code","b2a5c723":"code","a0731c23":"code","c68a93b8":"code","132aaf92":"code","f1010408":"code","acf33fd4":"code","687bdfb5":"code","30698029":"code","b4309c5e":"code","2f07d73a":"code","ffcc2bbc":"code","86273532":"code","5d8a6648":"code","d1f367c4":"code","03259a03":"code","a11852b4":"code","9504a7ee":"code","774c1930":"code","de6ec23e":"code","e3cf9565":"code","2b4668ba":"code","2db28f91":"code","0848a4d9":"code","4e7e1722":"code","aa95b844":"code","103a68ba":"code","fbcdfc04":"code","3e673e92":"code","6b74bfae":"code","88ebe6d6":"code","06fafa07":"code","cea7f5ea":"code","092f4125":"code","eedbff71":"code","0a399515":"code","8a228161":"code","babada87":"code","4c4de74e":"code","bedb53b5":"code","29915364":"code","9272f68f":"code","4df3650e":"code","2e4edde4":"code","751f1792":"markdown","62d9df53":"markdown","0bb380c5":"markdown","1dfe2475":"markdown","797188ec":"markdown","03e62b72":"markdown","6a3b4b90":"markdown","531067e1":"markdown","5d41446d":"markdown","6d544a63":"markdown","c491ad49":"markdown"},"source":{"2f5b4b75":"# Loading some of the required libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib notebook\nimport os\nfor dirname, _, filenames in os.walk('kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e4257537":"# Loading the datasets used here\ntrain_data = pd.read_csv('\/kaggle\/input\/train-testtt\/train_titanic.txt')\ntest_data = pd.read_csv('\/kaggle\/input\/train-testtt\/test_titanic.txt')\ny = train_data['Survived']","f1756701":"# Reading the above data\nprint(y, train_data, test_data)","35108ca6":"# Size of the datasets\n\n\ntrain_data.shape, test_data.shape","5ef14ad4":"# Data description\ntrain_data.describe(), test_data.describe()","09b21aae":"# Percentage number of those who survived by their sex\nsexes = train_data.groupby('Sex').mean()\nsexes['Survived']*100","71f8a144":"# Percentage number of those who survived by their class\nsexes = train_data.groupby('Pclass').mean()\nsexes['Survived']*100","d624a52f":"# Total number of people who survived and those who didn't make it labelled by 1 and 0 respectively \ntrain_data.Survived.value_counts()","473a216e":"# Percentage number of those who survived by SibSp and Unique SibSp_counts\nKK = train_data.groupby('SibSp').mean()\nKKK = KK['Survived']*100\nSibSp_counts = train_data['SibSp'].value_counts()\nprint(KKK, SibSp_counts)","459c7d5d":"# Percentage number of those who survived by Parch and Unique Parch_counts\nPP = train_data.groupby('Parch').mean()\nPPP = PP['Survived']*100\nParch_counts = train_data['Parch'].value_counts()\nprint(PPP, Parch_counts)","28b921ea":"\nplt.figure(figsize=(5,4))\nplt.style.use('seaborn-notebook')\nsns.countplot(x='Survived', hue='Sex', data=train_data)\nplt.title('Countplot showing Survivors by their sex')\nplt.show()","1f35c72c":"plt.figure()\nplt.style.use('seaborn-dark')\nsns.distplot(train_data['Age'], bins=50, kde=True, color='b')\nplt.title('Age distribution amongst the train_dataset')\nplt.show()\n\nplt.style.use('seaborn-deep')\nfacet = sns.FacetGrid(data=train_data, col='Survived', height=3, aspect=4)\nfacet.map(sns.distplot, 'Age', kde=True, bins=50)\nplt.title('Plots displaying age distribution among Survivors')\nplt.show()","aa235a45":"Relationship = train_data.corr()\nplt.figure()\nsns.heatmap(data=Relationship, annot=True, cmap='Blues')\nplt.title('Relationship between different varaiables in our train_data')\nplt.show()","b2a5c723":"def family(data):\n    data['family_tog'] = data['Parch'] + data['SibSp']\n    data = data.drop(['SibSp', 'Parch'], axis=1)\n    return data\ntrain_data = family(train_data)\ntest_data = family(test_data)","a0731c23":"means = train_data.groupby('family_tog')\nmeans.Survived.mean()*100","c68a93b8":"train_data['family_tog'] = train_data['family_tog'].apply(lambda x: 'Travelled alone' if x==0 else x)\ntrain_data['family_tog'] = train_data['family_tog'].apply(lambda x: 'Travelled with small family' if (x==1 or x==2 or x==3) else x)\ntrain_data['family_tog'] = train_data['family_tog'].apply(lambda x: 'Travelled with slightly big family' if (x==4 or x==5 or x==6) else x)\ntrain_data['family_tog'] = train_data['family_tog'].apply(lambda x: 'Travelled with big family' if (x==7 or x==10) else x)\n","132aaf92":"test_data['family_tog'] = test_data['family_tog'].apply(lambda x: 'Travelled alone' if x==0 else x)\ntest_data['family_tog'] = test_data['family_tog'].apply(lambda x: 'Travelled with small family' if (x==1 or x==2 or x==3) else x)\ntest_data['family_tog'] = test_data['family_tog'].apply(lambda x: 'Travelled with slightly big family' if (x==4 or x==5 or x==6) else x)\ntest_data['family_tog'] = test_data['family_tog'].apply(lambda x: 'Travelled with big family' if (x==7 or x==10) else x)\n","f1010408":"print(train_data['family_tog'].value_counts(), test_data['family_tog'].value_counts())","acf33fd4":"# Pie_Chart \n# More visualizations on the data\nplt.figure()\nplt.style.use('seaborn-muted')\nplt.pie(train_data.Sex.value_counts(), explode=[0.02, 0.02], labels= ['Male', 'Female'], autopct='%1.1f%%', colors=['b','g'])\nplt.title('Pie Chart showing distribution of men and women in the train_data')\nplt.show()\n\nplt.figure()\nplt.style.use('seaborn-paper')\nsexes = train_data.groupby('Sex').mean()\nplt.pie(sexes.Survived, labels= ['Male', 'Female'], autopct='%1.1f%%', colors=['red','purple'])\nplt.title('Pie Chart showing distribution of men and women who survived')\nplt.show()\n\nplt.figure()\nplt.style.use('Solarize_Light2')\nsexes = train_data.groupby('Embarked').mean()\nplt.pie(sexes.Survived, labels= ['C', 'Q', 'S'], autopct='%1.1f%%', colors=['orange','blue', 'magenta'])\nplt.title('Pie Chart showing passenger distribution at different Ports of embarkation')\nplt.show()\n\nplt.figure()\nplt.style.use('seaborn-paper')\nplt.pie(train_data['family_tog'].value_counts(), labels= ['Travelled alone', 'Travelled with small family', 'Travelled with slightly big family', 'Travelled with big family'], autopct='%1.1f%%', colors=['b','g', 'brown', 'grey'])\nplt.title('Pie Chart showing distribution of men and women in the train_data')\nplt.show()","687bdfb5":"train_data['Fare'].nunique()","30698029":"train_data['Fare'].value_counts()","b4309c5e":"# Price variations at the different ports of embarkation\nplt.style.use('seaborn-paper')\nfig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10,8))\nax1.hist(train_data.Fare[train_data.Embarked == 'C'], bins=50, alpha=0.5)\nax1.set_yscale('log')\nax1.set_title('Price variations for those who embarked at Cherbourg')\nplt.show()\nplt.xlabel('FARE', color='black')\nplt.tight_layout(pad=1.50)\n\nplt.style.use('seaborn-paper')\nax2.hist(train_data.Fare[train_data.Embarked == 'Q'], bins=50, alpha=0.5, color='g')\nax2.set_yscale('log')\nax2.set_title('Price variations for those who embarked at Queensland')\nplt.show()\nplt.tight_layout(pad=1.50)\n\nplt.style.use('seaborn-paper')\nax3.hist(train_data.Fare[train_data.Embarked == 'S'], bins=50, alpha=0.5, color='r')\nax3.set_yscale('log')\nax3.set_title('Price variations for those who embarked at Southampton')\nplt.show()","2f07d73a":"train_data['Name'] = train_data['Name'].apply(lambda x: x.split('.')[0].split(',')[1])\ntest_data['Name'] = test_data['Name'].apply(lambda x: x.split('.')[0].split(',')[1])","ffcc2bbc":"train_data['Name'].value_counts(), test_data['Name'].value_counts()","86273532":"plt.figure()\nplt.style.use('seaborn-dark')\nsns.countplot(x='Name', hue='Survived', data=train_data, palette='colorblind')\nplt.xticks(rotation=60)\nplt.title('A countplot showing name titles and their survival counts', color='g')\nplt.show()\nplt.legend(loc='upper right')\nplt.tight_layout(pad=1.50)","5d8a6648":"title = pd.DataFrame(train_data.groupby('Name')['Survived'].agg('count').sort_values(ascending=False))\nplt.figure()\nplt.style.use('seaborn-dark')\nplt.rcParams['figure.figsize'] = (8,6)\nsns.barplot(x=title.Survived, y=title.index, data=title, palette='colorblind')\nplt.gca().set_title('Bar plot showing Name title counts', fontsize=(10))\nplt.show()","d1f367c4":"train_data['Cabin'].value_counts()","03259a03":"train_data['Ticket'].value_counts()","a11852b4":"train_data['Cabin'].isnull().sum(), test_data['Cabin'].isnull().sum()","9504a7ee":"train_data['Cabin'].fillna('Reserved', inplace=True), test_data['Cabin'].fillna('Reserved', inplace=True)","774c1930":"train_data","de6ec23e":"train_data['Cabin'].value_counts()","e3cf9565":"train_data['deck'] = train_data['Cabin'].str.replace('([0-9\\s])+', '')\ntest_data['deck'] = test_data['Cabin'].str.replace('([0-9\\s])+', '')","2b4668ba":"test_data['deck'].value_counts(), train_data['deck'].value_counts()","2db28f91":"def number_of_cabins(row):\n    if len(row.deck) > 1:\n       row['Cabin'] = len(row.deck)\n    elif row.deck == 'Reserved':\n        row['Cabin'] = 0\n    else:\n        row['Cabin'] = 1\n    return row\ntrain_data = train_data.apply(number_of_cabins, axis=1)\ntest_data = test_data.apply(number_of_cabins, axis=1)","0848a4d9":"train_data['Cabin'].value_counts(), test_data['Cabin'].value_counts()","4e7e1722":"train_data['deck'] = train_data['deck'].apply(lambda x: x[0] if x != 'Reserved' else x)\ntest_data['deck'] = test_data['deck'].apply(lambda x: x[0] if x != 'Reserved' else x)","aa95b844":"train_data['deck'].value_counts(), test_data['deck'].value_counts()","103a68ba":"for title in train_data[train_data.Age.isna()].Name.value_counts().index:\n    mean_age = train_data.groupby('Name').mean().T[title].Age\n    mean_age_list = train_data[train_data.Name == title].Age.fillna(mean_age)\n    train_data.update(mean_age_list)\ntrain_data.isnull().sum()","fbcdfc04":"for title in test_data[test_data.Age.isnull()].Name.value_counts().index:\n    mean_age = test_data.groupby('Name').mean().T[title].Age\n    mean_age_list = test_data[test_data.Name == title].Age.fillna(mean_age)\n    test_data.update(mean_age_list)\ntest_data.Age.isna().sum()","3e673e92":"test_data['Age'] = test_data.Age.fillna(test_data.Age.mean())","6b74bfae":"test_data.Age.isnull().sum()","88ebe6d6":"most_paid_fare = test_data.Fare.value_counts()\ntest_data.Fare = test_data.Fare.fillna(most_paid_fare.index[0])","06fafa07":"most_frequent_port_of_embarkation = train_data.Embarked.value_counts()\nport = most_frequent_port_of_embarkation\nport","cea7f5ea":"train_data.Embarked = train_data.Embarked.fillna(port.index[0])","092f4125":"train_data.drop(['PassengerId','Survived', 'Ticket', 'Cabin'], axis=1, inplace=True)\ntest_data.drop(['PassengerId','Ticket', 'Cabin'], axis=1, inplace=True)","eedbff71":"train_data","0a399515":"# Using OneHotEncoder to deal with categorical features to create dummies\nfrom sklearn.preprocessing import OneHotEncoder\nEnc = OneHotEncoder(handle_unknown='ignore', sparse=False)\nfeatures = ['Pclass', 'Name', 'Sex', 'Age', 'Fare', 'Embarked', 'family_tog', 'deck']\nEnc_train_cols = pd.DataFrame(Enc.fit_transform(train_data[features]))\nEnc_test_cols = pd.DataFrame(Enc.transform(test_data[features]))\n\nEnc_train_cols.index = train_data.index\nEnc_test_cols.index = test_data.index\n\nTrn = train_data.drop(features, axis=1)\nTen = test_data.drop(features, axis=1)\n\ntrain_data = pd.concat([Trn, Enc_train_cols], axis=1)\ntest_data = pd.concat([Ten, Enc_test_cols], axis=1)","8a228161":"train_data.shape, test_data.shape","babada87":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV","4c4de74e":"steps = [('scaler', StandardScaler())]\npipe = Pipeline([('scaler', StandardScaler()), ('classifier', RandomForestClassifier())])\nparam_grid={'classifier': [RandomForestClassifier()], 'classifier__n_estimators':[500], 'classifier__max_features':[0.25], 'classifier__max_depth':[8], 'classifier__criterion':['entropy']}\nclf = GridSearchCV(pipe, param_grid=param_grid, cv=10, verbose=True, n_jobs=-1)\nbest_clf = clf.fit(train_data, y)","bedb53b5":"score = clf.best_score_\nparams = clf.best_params_\nprint('Best score : {}'.format(score))\nprint('Best parameters : {}'.format(params))","29915364":"final_results = clf.predict(test_data)\nfinal_results","9272f68f":"test_data = pd.read_csv('\/kaggle\/input\/train-testtt\/test_titanic.txt')","4df3650e":"Final_solution = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': final_results})\nFinal_solution","2e4edde4":"Final_solution.to_csv('Submission.csv', index=False)","751f1792":"Since i will need to use the passengerId for the test_data, i will have to load the dataset again to help me come up with my final prediction","62d9df53":"There is a defined function to help us show survival of people who were in families and it shows that those with larger families had a higher chance to survive","0bb380c5":"Looking at the 'Fare' feature, it can also come in handy with predictions depending on how much one had to pay to be on the titanic","1dfe2475":"DATA ANALYSIS AND DATA VISUALIZATION","797188ec":"Looking at the 'Name' feature, it's important to note that different names have different titles.. i beleive this can also be utilized in our predictions","03e62b72":"Ideally this is a new column called 'family_tog' which shows how people were travelling while on the titanic i.e; those who were in small numbers, big or small families and so on... From this feature we can find out who amongst these had a higher chance of survival","6a3b4b90":"# Beginners Machine Learning with the titanic dataset","531067e1":"Missing 'Fare' feature values are replaced with the average fare paid for the travellers on the titanic","5d41446d":"Missing 'Embarked' feature values replaced with the port of embarkation at which most people boarded the titanic","6d544a63":"Since the 'Age' feature will be utilized, missing values are replaced with mean age of the other travellers with whom they have the same name title.\nI believe that makes more sense.","c491ad49":"The 'Cabin' feature has very many missing values much as it would be good for our predictions since someone's position on the titanic can also help with our predictions.\nSo i will call the missing values 'Reserved', assuming those are reserved spots"}}