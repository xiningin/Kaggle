{"cell_type":{"759ed6e0":"code","2169d8b5":"code","7acbe1e0":"code","ea664e8f":"code","c31c6b7f":"code","e5df79f2":"code","8b560b1a":"code","0d378a87":"code","2ee94ab6":"code","26dab8eb":"code","ce361876":"code","c3d4f4c1":"code","05dbd764":"code","9753906f":"markdown","09f9274a":"markdown","fbfd5cd8":"markdown","849eda90":"markdown","5e41b25a":"markdown","83ddb3a1":"markdown","0015dfab":"markdown","8b43ef62":"markdown","7d2d9b87":"markdown"},"source":{"759ed6e0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"..\/input\"))","2169d8b5":"import matplotlib.pyplot as plt\nimport numpy as np\n\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\n#from torch.autograd import Variable\nimport torch.optim as optim\n\nimport torchvision.utils as vutils\nfrom torchvision import datasets, transforms\nfrom torchvision.utils import save_image","7acbe1e0":"batch_size = 32\nimage_size = 64\n\n# Learning rate for optimizers\nlr = 0.0002\n\n# Number of channels \nchannels = 3\n\n# Number of training epochs\nepochs = 100\n\n# Latent vector (i.e Size of generator input)\nlatentVec = 100\n\n# Beta1 hyperparam for Adam optimizers\nbeta1 = 0.5\n\n# Number of GPUs available. 0 for cuda mode.\nngpu = 1\n\n# Size of feature maps in generator\nFeaGen = 64\n\n# Size of feature maps in discriminator\nFeaDis = 64","ea664e8f":"# Decide which device we want to run\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Crop 64x64 image\ntransform = transforms.Compose([transforms.Resize(image_size),\n                                transforms.CenterCrop(image_size),\n                                transforms.ToTensor(),\n                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\n# Dataloader\ntrain_data = datasets.ImageFolder(\"..\/input\/all-dogs\/\", transform = transform)\ntrain_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n\nimgs, label = next(iter(train_loader))\nimgs = imgs.numpy().transpose(0, 2, 3, 1)","c31c6b7f":"TrainingImages = next(iter(train_loader))\nplt.figure(figsize=(12, 10))\nplt.axis(\"off\")\nplt.title(\"Training images\")\nplt.imshow(np.transpose(vutils.make_grid(TrainingImages[0].to(device)[:64], padding=2, \n                                         normalize=True).cpu(),(1,2,0)))","e5df79f2":"def weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0.0)","8b560b1a":"## Generator\n\nclass Generator(nn.Module):\n    \n    def __init__(self, ngpu):\n        super(Generator, self).__init__()\n        \n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            nn.ConvTranspose2d(latentVec, FeaGen * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(FeaGen * 8),\n            nn.ReLU(True),\n            # State size. (FeaGen x 8) x 4 x 4 \n            nn.ConvTranspose2d(FeaGen * 8, FeaGen * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(FeaGen * 4),\n            nn.ReLU(True),\n            # State size. (FeaGen x 4) x 8 x 8 \n            nn.ConvTranspose2d(FeaGen * 4, FeaGen * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(FeaGen * 2),\n            nn.ReLU(True),\n            # State size. (FeaGen x 2) x 16 x 16\n            nn.ConvTranspose2d(FeaGen * 2, FeaGen, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(FeaGen),\n            nn.ReLU(True),\n            # State size. FeaGen x 32 x 32\n            nn.ConvTranspose2d(FeaGen, channels, 4, 2, 1, bias=False),\n            nn.Tanh()\n            # State size. (channels) x 64 x 64\n        )\n        \n    def forward(self, input):\n        return self.main(input)\n    \n    \n# Create the generator\nnetG = Generator(ngpu).to(device)\n\n# Apply the weights_init function to randomly initialize all weights\n#  to mean=0, stdev=0.2.\nnetG.apply(weights_init)\n\n# Print the model\nprint(netG)","0d378a87":"## Discriminator\n\nclass Discriminator(nn.Module):\n    \n    def __init__(self, ngpu):\n        super(Discriminator, self).__init__()\n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            # input is channels x 64 x 64\n            nn.Conv2d(channels, FeaDis, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            # State size. (FeaDis) x 32 x 32\n            nn.Conv2d(FeaDis, FeaDis * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(FeaDis * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # State size. (FeaDis * 2) x 16 x 16\n            nn.Conv2d(FeaDis * 2, FeaDis * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(FeaDis * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            # State size. (FeaDis * 4) x 8 x 8\n            nn.Conv2d(FeaDis * 4, FeaDis * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(FeaDis * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            # State size. (FeaDis * 8) x 4 x 4\n            nn.Conv2d(FeaDis * 8, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, input):\n        return self.main(input)\n    \n    \n# Create the discriminator\nnetD = Discriminator(ngpu).to(device)\n\n# Apply the weights_init function to randomly initialize all weights\n#  to mean=0, stdev=0.2.\nnetD.apply(weights_init)\n\n# Print the model\nprint(netD)","2ee94ab6":"# Initialize BCELoss function\ncriterion = nn.BCELoss()\n\n# Create batch of latent vectors that we will use to visualize\n# the progression of the generator\nfixed_noise = torch.randn(64, latentVec, 1, 1, device=device)\n\n# Establish convention for real and fake labels during training\nreal_label = 1\nfake_label = 0\n\n# Setup Adam optimizers for both G and D\noptimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\noptimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))","26dab8eb":"# Lists to keep track of progress\nGlosses = []\nDlosses = []\niters = 0\nnum_epochs = 15\n\n# For each epoch\nfor epoch in range(num_epochs):\n    # For each batch in dataloader\n    for i, data in enumerate(train_loader, 0):\n        \n        # Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        ## Train with real batch\n        netD.zero_grad()\n        realImg = data[0].to(device)\n        batch_size = realImg.size(0)\n        labels = torch.full((batch_size,), real_label, device=device)\n        \n        output = netD(realImg).view(-1)\n        Real_Loss = criterion(output, labels)   # Calculate loss\n        Real_Loss.backward()                    # Calculate Gradient\n        Dx = output.mean().item()\n        \n        ## Train with fake batch\n        # Generate batch of latent vectors\n        noise = torch.randn(batch_size, latentVec, 1, 1, device = device)\n        fake = netG(noise)\n        labels.fill_(fake_label)\n        output = netD(fake.detach())\n        Fake_Loss = criterion(output, labels)\n        Fake_Loss.backward()\n        D_G1= output.mean().item()\n        # Add the gradients from the all-real and all-fake batches\n        DisLoss = Real_Loss + Fake_Loss\n        optimizerD.step()\n        \n        # Update G network: maximize log(D(G(z)))\n        netG.zero_grad()\n        labels.fill_(real_label)                # fake labels are real for generator cost\n        output = netD(fake)\n        GLoss = criterion(output, labels)\n        GLoss.backward()\n        D_G2 = output.mean().item()\n        optimizerG.step()\n        \n        # Output training stats\n        if iters % 60 == 0:\n            print('[Epoch %d\/%d] [Batch %d\/%d] [D Loss: %.4f] [G Loss: %.4f] [D(x): %.4f] [D(G(z)): %.4f\/%.4f]' \n                  % (epoch, num_epochs, i, len(train_loader), DisLoss.item(), GLoss.item(), Dx, D_G1, D_G2))\n            \n            ValidImage = netG(fixed_noise)\n        \n        iters += 1\n            \n        # Save Losses\n        Glosses.append(GLoss.item())\n        Dlosses.append(DisLoss.item())\n        ","ce361876":"plt.figure(figsize=(10,5))\nplt.title(\"Generator and Discriminator Loss\")\nplt.plot(Glosses,label=\"G\")\nplt.plot(Dlosses,label=\"D\")\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","c3d4f4c1":"if not os.path.exists('..\/output_images'):\n    os.mkdir('..\/output_images')\nim_batch_size = 50\nn_images=10000\nfor i_batch in range(0, n_images, im_batch_size):\n    gen_z = torch.randn(im_batch_size, 100, 1, 1, device=device)\n    gen_images = netG(gen_z)\n    images = gen_images.to(\"cpu\").clone().detach()\n    images = images.numpy().transpose(0, 2, 3, 1)\n    for i_image in range(gen_images.size(0)):\n        save_image(gen_images[i_image, :, :, :], os.path.join('..\/output_images', f'image_{i_batch+i_image:05d}.png'))\n\n\nimport shutil\nshutil.make_archive('images', 'zip', '..\/output_images')","05dbd764":"for i in range(10):\n    plt.imshow(images[i])\n    plt.show()\n","9753906f":"Kindly **upvote** this kernel if you find it helpful.","09f9274a":"#### Model training","fbfd5cd8":"Let's see the training images in the dataset","849eda90":"These are some of the images in our training dataset.\n\nIn the [DCGAN paper](http:\/\/arxiv.org\/pdf\/1511.06434.pdf) it is stated that all model weights should be randomly initialized from a Normal distribution with mean=0, stdev=0.02. ","5e41b25a":"#### Setting parameters","83ddb3a1":"#### Loss functions and Optimizers","0015dfab":"#### DCGAN Architecture\n\nReferred from PyTorch official documentation: https:\/\/pytorch.org\/tutorials\/beginner\/dcgan_faces_tutorial.html","8b43ef62":"### DCGAN (Deep Convolutional Generative Adversarial Networks)\n\nGANs biggest problem is that they are unstable to train (note the oscillations of the loss). This is due to the fact that we train two networks from the same backpropagation. Also, we already know that we have better tools when it comes to image processing and deep learning \u2013 Convolutional Neural Networks (CNN). By combining main CNN concepts with GAN ideas, we can improve in this task and generate better images. That is how Deep Convolutional Generative Adversarial Network (DCGAN) were created. \n\nIn order to stabilize GANs training, authors of DCGAN proposed several improvements:\n\n* Utilizing the convolution layer instead pooling function in the Discriminator model for reducing dimensionality. In the Generator Model, we use deconvolution to upsample dimensions of feature maps.\n* Adding in the batch normalization. This is used to increase the stability of a neural network. In an essence, batch normalization normalizes the output of a previous layer by subtracting the batch mean and dividing by the batch standard deviation.\n* Remove fully connected layers from Convolutional Neural Network.\n* Use Relu and Leaky Relu activation functions.\n\nIt was first described by Radford et. al. in the paper [Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks.](http:\/\/arxiv.org\/pdf\/1511.06434.pdf)\n\nThose who want to know about the basics of GAN, go through [GAN Brief Introduction](http:\/\/medium.com\/@shwetagoyal41\/gans-a-brief-introduction-to-generative-adversarial-networks-f06216c7200e) article.","7d2d9b87":"#### Data preparation"}}