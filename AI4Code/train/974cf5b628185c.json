{"cell_type":{"98a4fe4f":"code","c2591a9a":"code","c7532d4b":"code","f0902e71":"code","48cbc994":"code","365d918f":"code","32f98da6":"code","0a099740":"code","8c23f371":"code","009831f4":"code","969997c3":"code","19267ad5":"code","59bec3f3":"code","6b842563":"code","4ff1dd05":"code","50d8591f":"code","bda11b0e":"code","b68f775c":"code","00551a49":"code","294d588f":"code","d7577687":"code","37874559":"code","01a1d950":"code","83eafde3":"code","7399317a":"code","5c88a43d":"code","9014292d":"code","a63b607f":"code","42ca478b":"code","d5cce5c8":"markdown","0c17783c":"markdown","6aa30817":"markdown","20f75ff3":"markdown","59730a0f":"markdown","c4024f40":"markdown","2c892789":"markdown","8f44b9ee":"markdown","3d8ccaae":"markdown","77c26ef3":"markdown","adee3038":"markdown","56b31ebc":"markdown","d531ddd5":"markdown","bf1fb9d2":"markdown","96bd8cb0":"markdown","6f402fd0":"markdown"},"source":{"98a4fe4f":"import numpy as np \nimport pandas as pd\nimport pandas_profiling as pp\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nimport sklearn\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.decomposition import PCA as PCA\nfrom sklearn.metrics import silhouette_samples, mean_squared_error, mean_absolute_error\nplt.style.use('seaborn-whitegrid')","c2591a9a":"pjme = pd.read_csv('..\/input\/PJME_hourly.csv', index_col=[0], parse_dates=[0])","c7532d4b":"pp.ProfileReport(pjme)","f0902e71":"print('shape = ', pjme.shape)\nprint(pjme.columns)","48cbc994":"pjme.head(10)\npjme.info()","365d918f":"pca = PCA(n_components=1)\npca.fit(pjme)\nXpca = pca.transform(pjme)\nsns.set()\nplt.figure(figsize=(6,3))\nplt.scatter(Xpca[0],Xpca[3], c='Blue')\nplt.show()","32f98da6":"color_pal = [\"#8DA0CB\", \"#D39200\", \"#93AA00\", \"#00BA38\", \"#00C19F\", \"#00B9E3\", \"#619CFF\", \"#DB72FB\"]\n_ = pjme.plot(style='.', figsize=(15,5), color=color_pal[0], title='PJM East')","0a099740":"split_date = '01-Jan-2015'\npjme_train = pjme.loc[pjme.index <= split_date].copy()\npjme_test = pjme.loc[pjme.index > split_date].copy()","8c23f371":"_ = pjme_test \\\n    .rename(columns={'PJME_MW': 'TEST SET'}) \\\n    .join(pjme_train.rename(columns={'PJME_MW': 'TRAINING SET'}), how='outer') \\\n    .plot(figsize=(15,5), title='PJM East', style='.')","009831f4":"def create_features(df, label=None):\n    \"\"\"\n    Creates time series features from datetime index\n    \"\"\"\n    df['date'] = df.index\n    df['hour'] = df['date'].dt.hour\n    df['dayofweek'] = df['date'].dt.dayofweek\n    df['quarter'] = df['date'].dt.quarter\n    df['month'] = df['date'].dt.month\n    df['year'] = df['date'].dt.year\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df['dayofmonth'] = df['date'].dt.day\n    df['weekofyear'] = df['date'].dt.weekofyear\n    \n    X = df[['hour','dayofweek','quarter','month','year',\n           'dayofyear','dayofmonth','weekofyear']]\n    if label:\n        y = df[label]\n        return X, y\n    return X","969997c3":"X_train, y_train = create_features(pjme_train, label='PJME_MW')\nX_test, y_test = create_features(pjme_test, label='PJME_MW')","19267ad5":"reg = xgb.XGBRegressor(n_estimators=999)\nreg.fit(X_train, y_train,\n        eval_set=[(X_train, y_train), (X_test, y_test)],\n        early_stopping_rounds=51,\n       verbose=False) # Change verbose to True if you want to see it train","59bec3f3":"_ = plot_importance(reg, height=0.87)","6b842563":"pjme_test['MW_Prediction'] = reg.predict(X_test)\npjme_all = pd.concat([pjme_test, pjme_train], sort=False)","4ff1dd05":"_ = pjme_all[['PJME_MW','MW_Prediction']].plot(figsize=(15, 5))","50d8591f":"# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\n_ = pjme_all[['MW_Prediction','PJME_MW']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_xbound(lower='01-01-2015', upper='02-01-2015')\nax.set_ylim(0, 60000)\nplot = plt.suptitle('January 2015 Forecast vs Actuals')","bda11b0e":"# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(6)\nf.set_figwidth(18)\n_ = pjme_all[['MW_Prediction','PJME_MW']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_xbound(lower='01-01-2015', upper='01-08-2015')\nax.set_ylim(0, 60000)\nplot = plt.suptitle('First Week of January Forecast vs Actuals')","b68f775c":"f, ax = plt.subplots(1)\nf.set_figheight(6)\nf.set_figwidth(18)\n_ = pjme_all[['MW_Prediction','PJME_MW']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_ylim(0, 60000)\nax.set_xbound(lower='07-01-2015', upper='07-08-2015')\nplot = plt.suptitle('First Week of July Forecast vs Actuals')","00551a49":"mean_squared_error(y_true=pjme_test['PJME_MW'],\n                   y_pred=pjme_test['MW_Prediction'])","294d588f":"mean_absolute_error(y_true=pjme_test['PJME_MW'],\n                   y_pred=pjme_test['MW_Prediction'])","d7577687":"def mean_absolute_percentage_error(y_true, y_pred): \n    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100","37874559":"mean_absolute_percentage_error(y_true=pjme_test['PJME_MW'],\n                   y_pred=pjme_test['MW_Prediction'])","01a1d950":"pjme_test['error'] = pjme_test['PJME_MW'] - pjme_test['MW_Prediction']\npjme_test['abs_error'] = pjme_test['error'].apply(np.abs)\nerror_by_day = pjme_test.groupby(['year','month','dayofmonth']) \\\n    .mean()[['PJME_MW','MW_Prediction','error','abs_error']]","83eafde3":"# Over forecasted days\nerror_by_day.sort_values('error', ascending=True).head(10)","7399317a":"# Worst absolute predicted days\nerror_by_day.sort_values('abs_error', ascending=False).head(10)","5c88a43d":"# Best predicted days\nerror_by_day.sort_values('abs_error', ascending=True).head(10)","9014292d":"f, ax = plt.subplots(1)\nf.set_figheight(6)\nf.set_figwidth(9)\n_ = pjme_all[['MW_Prediction','PJME_MW']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_ylim(0, 60000)\nax.set_xbound(lower='08-13-2016', upper='08-14-2016')\nplot = plt.suptitle('Aug 13, 2016 - Worst Predicted Day')","a63b607f":"f, ax = plt.subplots(1)\nf.set_figheight(6)\nf.set_figwidth(10)\n_ = pjme_all[['MW_Prediction','PJME_MW']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_ylim(0, 60000)\nax.set_xbound(lower='10-03-2016', upper='10-04-2016')\nplot = plt.suptitle('Oct 3, 2016 - Best Predicted Day')","42ca478b":"f, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(10)\n_ = pjme_all[['MW_Prediction','PJME_MW']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_ylim(0, 60000)\nax.set_xbound(lower='08-13-2016', upper='08-14-2016')\nplot = plt.suptitle('Aug 13, 2016 - Worst Predicted Day')","d5cce5c8":"# Plotting some best\/worst predicted days","0c17783c":"Thanks to:\n* [Vitalii Mokin](https:\/\/www.kaggle.com\/vbmokin) \u2013  https:\/\/www.kaggle.com\/vbmokin\/convert-to-regression-with-tuning\n* [Rob Mulla](https:\/\/www.kaggle.com\/robikscube) \u2013 https:\/\/www.kaggle.com\/robikscube\/tutorial-time-series-forecasting-with-xgboost\n\nhttps:\/\/towardsdatascience.com\/machine-learning-algorithms-part-12-hierarchical-agglomerative-clustering-example-in-python-1e18e0075019\n","6aa30817":"Notice anything about the over forecasted days? \n- #1 worst day - July 4th, 2016 - is a holiday. \n- #3 worst day - December 25, 2015 - Christmas\n- #5 worst day - July 4th, 2016 - is a holiday.   \nLooks like our model may benefit from adding a holiday indicator.","20f75ff3":"# Error Metrics On Test Set\nOur RMSE error is 13780445  \nOur MAE error is 2848.89  \nOur MAPE error is 8.94%","59730a0f":"# Train\/Test Split\nCut off the data after 2015 to use as our Test set.","c4024f40":"# Data\nThe data we will be using is hourly power consumption data from PJM. Energy consumtion has some unique charachteristics. It will be interesting to see how prophet picks them up.\n\nPulling the `PJM East` which has data from 2002-2018 for the entire east region.","2c892789":"The best predicted days seem to be a lot of october (not many holidays and mild weather) Also early may","8f44b9ee":"This one is pretty impressive. SPOT ON","3d8ccaae":"# Create XGBoost Model","77c26ef3":"MAPE isn't included in sklearn so we need to use a custom function.","adee3038":"# Look at Worst and Best Predicted Days","56b31ebc":"# Look at first month of predictions","d531ddd5":"We can see that the day of year was most commonly used to split trees, while hour and year came in next. Quarter has low importance due to the fact that it could be created by different dayofyear splits.","bf1fb9d2":"# Create Time Series Features","96bd8cb0":"# Forecast on Test Set","6f402fd0":"## Feature Importances\nFeature importance is a great way to get a general idea about which features the model is relying on most to make the prediction. This is a metric that simply sums up how many times each feature is split on."}}