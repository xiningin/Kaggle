{"cell_type":{"9de4735d":"code","d4886ae8":"code","8f6ff285":"code","3ea87c16":"code","b4365443":"code","20028914":"code","dede0203":"code","9b04c502":"code","dc36a1ab":"code","a33f010b":"code","599e860c":"code","b779f88f":"code","c3366349":"code","b76dc5eb":"code","3422020c":"code","3ef7061d":"code","14062fc9":"code","19efc33f":"code","46710335":"code","e247ebb8":"code","ca31cd67":"code","940d51b7":"code","0abd8dd9":"code","5bcd32ae":"markdown","16ed5bde":"markdown","553cedb1":"markdown","20d65fd5":"markdown","0dff4e95":"markdown","d52c2744":"markdown","273acec9":"markdown","cb7fd517":"markdown","b42adfd7":"markdown","90b1a7c2":"markdown","412d803b":"markdown","7cb26df2":"markdown","aa2a0561":"markdown","4b210925":"markdown"},"source":{"9de4735d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d4886ae8":"import pandas as pd\ndf1 = pd.read_csv('\/kaggle\/input\/fashion-mnist_train.csv',sep=',')\ndf2 = pd.read_csv('\/kaggle\/input\/fashion-mnist_test.csv', sep = ',')","8f6ff285":"## Display dataframes\ndf1.head()","3ea87c16":"df2.head()","b4365443":"x_train = df1.iloc[:,1:]\ny_train = df1.iloc[:,0]\nx_test= df2.iloc[:,1:]\ny_test=df2.iloc[:,0]\n","20028914":"import numpy as np\nx_train = np.array(x_train, dtype = 'float32')\nx_test = np.array(x_test, dtype ='float32')\ny_train = np.array(y_train, dtype = 'float32')\ny_test = np.array(y_test, dtype ='float32')","dede0203":"x_train.max()","9b04c502":"x_train.min()","dc36a1ab":"x_train = x_train[:,:]\/255","a33f010b":"x_train","599e860c":"x_test = x_test[:,:]\/255","b779f88f":"x_test","c3366349":"from sklearn.cross_validation import train_test_split\nx_train,x_validate,y_train,y_validate = train_test_split(x_train,y_train,test_size = 0.2,random_state = 12345)","b76dc5eb":"import matplotlib.pyplot as plt\n%matplotlib inline\nimage1 = x_train[10,:].reshape((28,28))\nplt.imshow(image1)\nplt.show()","3422020c":"image2 = x_train[100,:].reshape((28,28))\nplt.imshow(image2)\nplt.show()","3ef7061d":"image_rows = 28\nimage_cols = 28\nbatch_size = 512\nimage_shape = (image_rows,image_cols,1)","14062fc9":"x_train = x_train.reshape(x_train.shape[0],*image_shape)\nx_test = x_test.reshape(x_test.shape[0],*image_shape)\nx_validate = x_validate.reshape(x_validate.shape[0],*image_shape)","19efc33f":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import SGD,Adam\n#### Define the model\ncnn_model = Sequential([\n    Conv2D(filters=32,kernel_size=3,activation='relu',input_shape = image_shape),\n    MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n    Dropout(0.2),\n    Flatten(), # flatten out the layers\n    Dense(32,activation='relu'),\n    Dense(10,activation = 'softmax')\n    \n])\n\n","46710335":"cnn_model.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001),metrics =['accuracy'])","e247ebb8":"history = cnn_model.fit(\n    x_train,\n    y_train,\n    batch_size=batch_size,\n    epochs=100,\n    verbose=1,\n    validation_data=(x_validate,y_validate),\n)","ca31cd67":"score = cnn_model.evaluate(x_test,y_test,verbose=0)\nprint('Test Loss :',score[0])\nprint('Test Accuracy : ',score[1])","940d51b7":"#get the predictions for the test data\npredicted = cnn_model.predict_classes(x_test)","0abd8dd9":"predicted","5bcd32ae":"Now we need to do more formating on the x_train,x_test and x_validate sets.","16ed5bde":"### Intro to Convolutional Neural Networks\nConvolutional neural networks (CNNs) are the current state-of-the-art model architecture for image classification tasks. CNNs apply a series of filters to the raw pixel data of an image to extract and learn higher-level features, which the model can then use for classification. CNNs contains three components:\n\n*    ** Convolutional layers**, which apply a specified number of convolution filters to the image. For each subregion, the layer performs a set of mathematical operations to produce a single value in the output feature map. Convolutional layers then typically apply a ReLU activation function to the output to introduce nonlinearities into the model.\n\n*     **Pooling layers**, which downsample the image data extracted by the convolutional layers to reduce the dimensionality of the feature map in order to decrease processing time. A commonly used pooling algorithm is max pooling, which extracts subregions of the feature map (e.g., 2x2-pixel tiles), keeps their maximum value, and discards all other values.\n\n*    ** Dense (fully connected) layers**, which perform classification on the features extracted by the convolutional layers and downsampled by the pooling layers. In a dense layer, every node in the layer is connected to every node in the preceding layer.\n\nTypically, a CNN is composed of a stack of convolutional modules that perform feature extraction. Each module consists of a convolutional layer followed by a pooling layer. The last convolutional module is followed by one or more dense layers that perform classification. The final dense layer in a CNN contains a single node for each target class in the model (all the possible classes the model may predict), with a softmax activation function to generate a value between 0\u20131 for each node (the sum of all these softmax values is equal to 1). We can interpret the softmax values for a given image as relative measurements of how likely it is that the image falls into each target class.","553cedb1":"## I am going to use CNN(Convolutional Neural Network) Model. Let's Understand CNN model","20d65fd5":"### Labels\n\nEach training and test example is assigned to one of the following labels:\n\n    0 T-shirt\/top\n    1 Trouser\n    2 Pullover\n    3 Dress\n    4 Coat\n    5 Sandal\n    6 Shirt\n    7 Sneaker\n    8 Bag\n    9 Ankle boot\n\n### TL;DR\n\n    Each row is a separate image\n    Column 1 is the class label.\n    Remaining columns are pixel numbers (784 total).\n    Each value is the darkness of the pixel (1 to 255)\n","0dff4e95":"### please upvote to show your support\n## Solution Fashion MNIST","d52c2744":"## Please upvote if you like the kernal\n## comment if you have a any doubt \n## We can have discussion on any topic ","273acec9":"### Let's start solving Fashion MNIST Dataset\n### Read train and test csv file as Dataframe","cb7fd517":"### Now visualise the sample image how it looks like in 28 * 28 pixel size\n","b42adfd7":"Now we can see that first column is of \"label\" which contain values 0 to 9.\nOther columns are pixel1,pixel2,pixel3.....upto pixel784 that contain pixels.\nHere each row is a different image representation in the form pixel data.\n### Now split data into train and test datasets","90b1a7c2":"### Description of problem","412d803b":"### Content\n\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n\n*  To locate a pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27. The pixel is located on row i and column j of a 28 x 28 matrix.\n*  For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below. ","7cb26df2":" ### Important note\n **we need to convert the dataframes into numpy arrays of float32 type which is the acceptable form for tensorflow and keras.**","aa2a0561":"### Context \nFashion-MNIST is a dataset of Zalando's article images\u2014consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n\nThe original MNIST dataset contains a lot of handwritten digits. Members of the AI\/ML\/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset researchers try. \"If it doesn't work on MNIST, it won't work at all\", they said. \"Well, if it does work on MNIST, it may still fail on others.\"\n\nZalando seeks to replace the original MNIST dataset","4b210925":"### important Note : Since the image data in x_train and x_test is from 0 to 255 , we need to rescale this from 0 to 1.To do this we need to divide the x_train and x_test by 255"}}