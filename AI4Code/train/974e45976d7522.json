{"cell_type":{"24cc716b":"code","ffef5aab":"code","75d8ee25":"code","2dc54167":"code","40af1c75":"code","dee64480":"code","7368b9ac":"code","b2887f1e":"code","8c05b9a6":"code","30411d62":"code","9d4d1c47":"code","feea2e7b":"code","bd85af03":"code","93101bb6":"code","71ff112f":"code","958557b3":"code","0667f47a":"code","a687fce8":"markdown","a7ee565e":"markdown","fc467e6b":"markdown","3d4c2b4e":"markdown","8c433c57":"markdown","a69ffd9c":"markdown","14dbfb6e":"markdown","938d8515":"markdown"},"source":{"24cc716b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n\nimport pandas as pd\nimport numpy as np\nfrom skimage.io import imread_collection,imread,imsave\nimport matplotlib.pyplot as plt\nfrom skimage.transform import resize\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom tensorboard import summary as summary_lib\nimport warnings \nwarnings.filterwarnings('ignore')\n# Any results you write to the current directory are saved as output.","ffef5aab":"height=50\nwidth =50\ndef Resize_Images(images,h=height,w=width):\n    new_images = []\n    for image in images:\n        new_images.append(resize(image, (h, w),anti_aliasing=True))\n    return np.array(new_images)","75d8ee25":"images_dir = '..\/input\/data\/natural_images\/'\nairplanes = Resize_Images(imread_collection(images_dir+'airplane\/*.jpg'))\nplt.imshow(airplanes[0])\nn_of_obj1 = np.shape(airplanes)[0]","2dc54167":"cars = Resize_Images(imread_collection(images_dir+'car\/*.jpg'))\nn_of_obj2 = np.shape(cars)[0]\nplt.imshow(cars[0])\nfinal_data = np.concatenate([airplanes,cars],axis=0)\ndel airplanes,cars","40af1c75":"dogs = Resize_Images(imread_collection(images_dir+'dog\/*.jpg'))\nn_of_obj3 = np.shape(dogs)[0]\nplt.imshow(dogs[0])\nfinal_data = np.concatenate([final_data,dogs],axis=0)\ndel dogs","dee64480":"fruits = Resize_Images(imread_collection(images_dir+'fruit\/*.jpg'))\nn_of_obj4 = np.shape(fruits)[0]\nplt.imshow(fruits[0])\nfinal_data = np.concatenate([final_data,fruits],axis=0)\ndel fruits","7368b9ac":"people = Resize_Images(imread_collection(images_dir+'person\/*.jpg'))\nn_of_obj5 = np.shape(people)[0]\nplt.imshow(people[0])\nfinal_data = np.concatenate([final_data,people],axis=0)\nfinal_data = np.array(final_data,np.float32)\ndel people","b2887f1e":"N = final_data.shape[0]","8c05b9a6":"def create_sprite_image(data,per_data=32):\n    test_array = []\n    test_label = []\n    for i in range(6): #Concatenation of images horizontally then vertically\n        airplane = data[i*per_data:(i+1)*per_data]\n        now = n_of_obj1\n        test_array.extend(airplane)\n        test_label.extend([1 for i in range(per_data)])\n        \n        cars = data[now+(i*per_data):now+(i+1)*per_data]\n        now += n_of_obj2\n        test_array.extend(cars)\n        test_label.extend([2 for i in range(per_data)])\n        \n        dogs = data[now+(i*per_data):now+(i+1)*per_data]\n        now += n_of_obj3\n        test_array.extend(dogs)\n        test_label.extend([3 for i in range(per_data)])\n        \n        fruits = data[now+(i*per_data):now+(i+1)*per_data]\n        now += n_of_obj4\n        test_array.extend(fruits)\n        test_label.extend([4 for i in range(per_data)])\n        \n        people = data[now+(i*per_data):now+(i+1)*per_data]\n        test_array.extend(people)\n        test_label.extend([5 for i in range(per_data)])\n        \n        airplane = np.reshape(airplane,(per_data*50,50,3))\n        cars = np.reshape(cars,(per_data*50,50,3))\n        dogs = np.reshape(dogs,(per_data*50,50,3))\n        fruits = np.reshape(fruits,(per_data*50,50,3))\n        people = np.reshape(people,(per_data*50,50,3))\n        \n        \n        if(i == 0): \n            final_array =  np.concatenate([airplane,cars,people],axis=1)\n            continue\n        final_array =  np.concatenate([final_array,airplane,cars,people],axis=1)\n        if(i == 5):\n            airplane = data[i*per_data:(i+1)*per_data]\n            now = n_of_obj1\n            test_array.extend(airplane)\n            test_label.extend([1 for i in range(per_data)])\n            \n            cars = data[now+(i*per_data):now+(i+1)*per_data]\n            now += n_of_obj2\n            test_array.extend(cars)\n            test_label.extend([2 for i in range(per_data)])\n            airplane = np.reshape(airplane,(per_data*50,50,3))\n            cars = np.reshape(cars,(per_data*50,50,3))\n            final_array = np.concatenate([final_array,airplane,cars],axis=1)\n\n    \n    tsv_file = []\n    #Creating the metadata label\n    options = ['Airplane','Car','Dog','Fruit','People']\n    for row in range(per_data):\n        for i in range(6):\n            tsv_file.extend(options)\n        tsv_file.extend(['Airplane','Car'])\n    tsv_file = np.reshape(tsv_file,(-1,1))\n    tsv_file = pd.DataFrame(tsv_file)\n    tsv_file.to_csv('label.tsv',header=False, index=False) #The tensorboard metadata parser considers headers as one of its contents\n\n    return np.array(test_array),np.reshape(test_label,(-1,1)),resize(final_array,(32*50,32*50),anti_aliasing=True)\n\n#####\ntest_array,test_label,sprite_image = create_sprite_image(final_data)    \nprint(test_array.shape,test_label.shape,sprite_image.shape)\nimsave('sprite.png',sprite_image)\nfig, ax = plt.subplots(figsize=(50, 50))\nplt.imshow(imread('sprite.png'))","30411d62":"#Creating the label to be OneHot Encoded\nlabels = [1 for i in range(n_of_obj1)]\nlabels.extend([2 for i in range(n_of_obj2)])\nlabels.extend([3 for i in range(n_of_obj3)])\nlabels.extend([4 for i in range(n_of_obj4)])\nlabels.extend([5 for i in range(n_of_obj5)])\nlabels = np.array(labels)\nlabels = np.reshape(labels,(labels.shape[0],1),np.float32)","9d4d1c47":"oh_model = OneHotEncoder(sparse=False)\nlabels = oh_model.fit_transform(labels)\ntest_label = oh_model.transform(test_label)","feea2e7b":"category_numbers = 5\nbatch_size = N","bd85af03":"tf.reset_default_graph()\nsess = tf.Session()\n\nwith tf.name_scope('INPUT'):\n    X = tf.placeholder(tf.float32,[None,height,width,3])\n    Y = tf.placeholder(tf.float32,[None,category_numbers])\n    tf.summary.image('image_test',X,10)\n\nwith tf.name_scope('LAYER_1'):\n    conv1 = tf.keras.layers.Conv2D(32,kernel_size=[3,3],padding='same',activation='relu')(X)\n    conv1 = tf.keras.layers.Conv2D(32,kernel_size=[3,3],padding='same',activation='relu')(conv1)\n    conv1 = tf.keras.layers.MaxPooling2D((2,2))(conv1)\n    tf.summary.histogram('layer_conv1',conv1)\n\nwith tf.name_scope('LAYER_2'):\n    conv2 = tf.keras.layers.Conv2D(64,kernel_size=[3,3],padding='same',activation='relu')(conv1)\n    conv2 = tf.keras.layers.Conv2D(64,kernel_size=[3,3],padding='same',activation='relu')(conv2)\n    conv2 = tf.keras.layers.MaxPooling2D((2,2))(conv2)\n    tf.summary.histogram('layer_conv2',conv2)\n    \nwith tf.name_scope('FINAL_LAYER'):\n    flat = tf.keras.layers.Flatten()(conv2)\n    dense = tf.keras.layers.Dense(16,activation='relu')(flat)\n    embed_input = dense #We take this as the embedding vector for our Tensorboard projection\n    embedding_input_size = 16\n    logits = tf.keras.layers.Dense(category_numbers,activation='softmax')(dense)\n    tf.summary.histogram('final_layer_logits',logits)\n\nwith tf.name_scope('LOSS'):\n    loss = tf.losses.softmax_cross_entropy(onehot_labels=Y,logits=logits)\n    tf.summary.scalar('loss',loss)\n    lab = tf.reshape(Y,[1,-1])\n    lab = tf.dtypes.cast(lab,tf.bool)\n    pred = tf.reshape(logits,[1,-1])\n    \nwith tf.name_scope('TRAIN'):\n    opt = tf.train.AdamOptimizer(10E-4)\n    train = opt.minimize(loss)\n\n#We assemble all the summaries together else we would have to call it indivisually in the training step    \nsummary = tf.summary.merge_all()\nembedding = tf.Variable(tf.zeros([1024, embedding_input_size]), name=\"Embedding\")\nassignment = embedding.assign(embed_input)\nsaver = tf.train.Saver()\n\nsess.run(tf.global_variables_initializer())\nwriter = tf.summary.FileWriter('tb_folder\/log\/',sess.graph)\n\nconfig = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\nembedding_config = config.embeddings.add(tensor_name=embedding.name)\n# embedding_config.tensor_name = embedding.name\nembedding_config.sprite.image_path = 'sprite.png'\nembedding_config.metadata_path = 'label.tsv'\n\nembedding_config.sprite.single_image_dim.extend([height, width])\ntf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)","93101bb6":"#We move the sprite and the metadat to the working directory\n!cp sprite.png tb_folder\/log\n!cp label.tsv tb_folder\/log","71ff112f":"epochs = 300\n\nfor i in range(epochs):    \n    L,_,S = sess.run([loss,train,summary],feed_dict={X:final_data,Y:labels})\n    if i%50 == 0:\n        sess.run([assignment],feed_dict={X:test_array,Y:test_label})\n        saver.save(sess, \"tb_folder\/log\/model.ckpt\", i)\n    writer.add_summary(S,0) #Updating summary\n    print('Loss:%0.5f '%L,\"Epoch: \",i)","958557b3":"!wget https:\/\/bin.equinox.io\/c\/4VmDzA7iaHb\/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\n\nLOG_DIR = 'tb_folder\/log\/' \nget_ipython().system_raw(\n    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n    .format(LOG_DIR)\n)\nget_ipython().system_raw('.\/ngrok http 6006 &')\n! curl -s http:\/\/localhost:4040\/api\/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","0667f47a":"sess.close()","a687fce8":"ngrok provides us with a port (a web server). The Beholder plugin doesn't work very well with the server, hence I have not implemented it but if you want to try beholder add this to your code\n>>from tensorboard.plugins.beholder import Beholder\n\n>>beholder = Beholder(\"tb_folder\/log\/\")\n\n>**Add the next line to your training step**\n\n>>beholder.update(session=sess)","a7ee565e":"**OneHotEncoding Step:**","fc467e6b":"Note that we are deleting the data to free up the RAM because if comes close to its threshold, the kernel crashes.","3d4c2b4e":"> We will resize the images to the same resolution of 50x50.\nIt is done batch-wise.","8c433c57":"**TENSORBOARD USAGE:**\n\nThis kernel is mainly to showcase how tensorboard can be used in a kaggle kernel. We take a CNN to showcase it. The dataset we will be using is 'Natural Images' dataset.\n\n**Tensorboard:** It is tool used to visualise your TF models, it is mainly used for debugging model performances.\n\n**WORKFLOW OF TENSORBOARD:** \n\n1. We compute what needs to summarized using tf.summary.\n1. We combine all the summary record using tf.summary.merge_all().\n1. We create a directory to store the logs i.e is done by tf.summary.FileWriter(log_dir).\n1. Finally we keep updating the summary in the disk by calling tf.summary.merge_all() in different instances of the training step.\n\nPlease make sure the internet is connected.","a69ffd9c":"1. We will be creating sprite image im the next cell.\n1. There will be 7x32 images imported in case of 'airplanes' and 'cars' and 6x32 images in case of the rest.\n1. This is mainly to fulfill the criterea of having equal AxA shaped image, as the tensorboard projecter only accepts square images.\n1. Else it keeps copying the contents of the first square formed in the rectangular image.\n1. We create a 'label.tsv' file to create the metadata label.\n1. We also create a test_array to input into the model to create its embeddings, which will be masked by its sprite image in the tensorboard projection\n","14dbfb6e":"**THE TRAINING STEP**\nWe need to keep updating the summary, here we are updating it after every epoch and we are updating the embeddings after every 50 epochs, as the weights changes as the epochs increases.","938d8515":" **The Model Details:**\n> LAYER 1 : \n* Convulution Layer \n* Convulution Layer\n* Max-pooling layer\n\n>LAYER 2:\n* Convulution Layer \n* Convulution Layer\n* Max-pooling Layer\n\n>FINAL-LAYER:\n* [](http:\/\/)Flatten the output from Max-pooling Layer\n* Dense layer with 16 neurons\n* Softmax-layer\n"}}