{"cell_type":{"3c74b73b":"code","647460a3":"code","3f85b6b8":"code","bb790104":"code","91147cd1":"code","55a12316":"code","25d8bf6f":"code","5d45f120":"code","db5d48e1":"code","d2e5c85e":"code","11db561f":"code","58bf2815":"code","7a623df2":"code","1918f719":"markdown","18993b50":"markdown","c123b1d2":"markdown","a7faff5d":"markdown","d963871d":"markdown","9f62d726":"markdown","ff5f967a":"markdown","d979d37e":"markdown","96cbc4d0":"markdown","4eb3687f":"markdown"},"source":{"3c74b73b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","647460a3":"df_wine_offers = pd.read_excel(\"..\/input\/WineKMC.xlsx\", sheetname=0)\ndf_wine_offers.columns = [\"offer_id\", \"campaign\", \"varietal\", \"min_qty\", \"discount\", \"origin\", \"past_peak\"]\ndf_wine_offers.head()","3f85b6b8":"df_wine_transactions = pd.read_excel(\"..\/input\/WineKMC.xlsx\", sheetname=1)\ndf_wine_transactions.columns = [\"customer_name\", \"offer_id\"]\ndf_wine_transactions['n'] = 1\ndf_wine_transactions.head()","bb790104":"# merge the two dataframes\nmy_df = pd.merge(df_wine_offers, df_wine_transactions)\nmy_df.head()","91147cd1":"# create a matrix \nmatrix = my_df.pivot_table(index=['customer_name'], columns=['offer_id'], values='n',fill_value=0)\nmatrix.head(5)","55a12316":"# run a first KMeans clustering algorithm as required in the exercise\nfrom sklearn.cluster import KMeans\ncluster = KMeans(n_clusters=5)\nmatrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[2:]])\nmatrix.cluster.value_counts()","25d8bf6f":"# the sum of squared error \nssd = []\nK = range(2,11)\nfor cluster_i in K:\n    kmeans = KMeans(n_clusters=cluster_i)\n    kmodel = kmeans.fit(matrix[matrix.columns[2:]])\n    ssd.append(kmodel.inertia_)","5d45f120":"import sklearn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","db5d48e1":"plt.plot(K, ssd, 'bx-')\nplt.xlabel('nr_clusters')\nplt.ylabel('ssd')\nplt.title('Elbow method for chosing the best number of clusters')\nplt.show()","d2e5c85e":"# prepare the x_cols first.\nx_cols = matrix.columns[:-1]\nx_cols","11db561f":"#run PCA\n\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\nmatrix['x'] = pca.fit_transform(matrix[x_cols])[:,0]\nmatrix['y'] = pca.fit_transform(matrix[x_cols])[:,1]\nmatrix = matrix.reset_index()","58bf2815":"matrix.head(5)","7a623df2":"customer_clusters = matrix[['customer_name', 'cluster', 'x', 'y']]\ncustomer_clusters.head()\n# Get current size of figure \nfig_size = plt.rcParams[\"figure.figsize\"]\nprint(fig_size)\n\n# And reset figure width to 12 and height to 9\nfig_size[0] = 12\nfig_size[1] = 9\nplt.rcParams[\"figure.figsize\"] = fig_size\n\nplt.scatter(customer_clusters['x'], customer_clusters['y'], c = customer_clusters['cluster'])","1918f719":"## Visualizing Clusters using PCA\n\nBut how can we visualize clusters when each data point has 32 dimensions? Principal Component Analysis (PCA) will help us reduce the dimensionality of our data from 32 to only two dimensions. This way we can visualize the clusters.","18993b50":"### Now we have two columns x, y gnerated from PCA that we can use to visualize the clusyters.","c123b1d2":"In order to learn more about how our customers behave, so we can use their behavior (whether or not they purchased something based on an offer) as a way to group similar minded customers together. We can then study those groups to look for patterns and trends which can help us formulate future offers.So we need a way to compare customers. To do this, we're going to create a matrix that contains each customer and a 0\/1 indicator for whether or not they responded to a given offer.\n","a7faff5d":"As the graphics above shows, in the x axis we have the number of clusters and in the y-axis we have sum-of-squares error. So in this graphics we see an elbow between four and six clusters (x-axis) which suggests that the optimal number of clusters is K = 5 ","d963871d":"### K-Means Clustering\n\nFor how does K-Means Clustering work. we need to maximize the distance between centroids and minimize the distance between data points and the respective centroid for the cluster they are in. A very intuitive way for deciding the optimal number of clusters for our dataset is the Elbow method... which works as follows.\n","9f62d726":"### Here we go!\n#### More than \"five clusters\" there seem to be only three (well defined) clusters of customers! The green, the black and the yellow-darkgreen.magenta.","ff5f967a":"### The transcations","d979d37e":"Plot graphics that will help the decision process. ","96cbc4d0":"### The offers ","4eb3687f":"The dataset contains records on offers sent to customers and transaction level data. The transactions data shows which offer customers responded to, and what the customer ended up buying. The data is contained in an Excel workbook containing two worksheets. Each worksheet contains a different dataset."}}