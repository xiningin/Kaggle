{"cell_type":{"0adead94":"code","57914de0":"code","a09c958e":"code","59b10ac6":"code","a6ee6b01":"code","65d0678b":"code","6276c1dd":"code","661cee2c":"code","cd9b4f28":"code","f26618e9":"code","4ada8ce6":"code","9dd32bb6":"code","33faf174":"code","2794a3aa":"code","eb18b7d8":"code","13b3e394":"code","8aed241a":"code","0053d332":"code","41de8f02":"code","f94b99c8":"code","95343563":"code","7c78b6f0":"code","3fc4f4d0":"code","c4d481b0":"code","b31018c8":"code","98306535":"code","bfa44214":"code","9994f562":"code","26a86978":"code","bddb5ccd":"code","7acfe440":"code","69fb1283":"code","3ad0f277":"code","13d0fc1f":"code","5e449acd":"code","830ef100":"code","b176c6bc":"code","0389883e":"code","d3935184":"code","7ca2ede3":"code","0044ad88":"code","28b4d436":"code","c7227fd3":"code","ff12acfe":"code","bab21d83":"code","61aaf391":"code","671b3129":"markdown","62c74d04":"markdown","5f2a7ff6":"markdown","10b52100":"markdown","f15be512":"markdown","ec5c1834":"markdown","7fb14940":"markdown","d2599ff2":"markdown","74470933":"markdown","7a34c355":"markdown","56c60b28":"markdown","9cea2e3b":"markdown","b653d692":"markdown","7237894e":"markdown","7fa1d32f":"markdown","f6e559dc":"markdown","967970d9":"markdown","e2575cf6":"markdown","5a658afe":"markdown","dd7009cc":"markdown","5706a2a7":"markdown","5da6d221":"markdown","31898d9a":"markdown","a145352b":"markdown","5112a846":"markdown","58bd8b60":"markdown","b819eec9":"markdown","e96ce1bb":"markdown","e7069f3a":"markdown","829752d9":"markdown","f19fc530":"markdown","21431652":"markdown","8fdf0317":"markdown","237eb7dc":"markdown","2c7e0f96":"markdown","337cf4d2":"markdown","155bf916":"markdown","c59a3488":"markdown","4a47b134":"markdown","a0486156":"markdown","be645213":"markdown","090c5449":"markdown","78be193a":"markdown","6dd47aa9":"markdown","7d1e44dc":"markdown","aa72fd39":"markdown","11da6ef8":"markdown","1e7fe2e5":"markdown","3f000ee0":"markdown","27cb5dba":"markdown","3c1f9705":"markdown","6a02f664":"markdown","d3ddf36e":"markdown","0e8e152c":"markdown","55571ae0":"markdown","6d040e9a":"markdown"},"source":{"0adead94":"# Directive pour afficher les graphiques dans Jupyter\n%matplotlib inline","57914de0":"# Pandas : librairie de manipulation de donn\u00e9es\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\n# SeaBorn : librairie de graphiques avanc\u00e9s\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","a09c958e":"df = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')","59b10ac6":"df.head(10)","a6ee6b01":"df.columns","65d0678b":"from IPython.core.display import HTML # permet d'afficher du code html dans jupyter\ndisplay(HTML(df.head(10).to_html()))","6276c1dd":"df.shape","661cee2c":"df.describe()","cd9b4f28":"df.columns","f26618e9":"df = df.drop(['Unnamed: 32'], axis=1)","4ada8ce6":"df.diagnosis.value_counts()","9dd32bb6":"malin = df.diagnosis=='M'\nbenin = df.diagnosis=='B'","33faf174":"sns.jointplot(\"perimeter_worst\", \"area_worst\", df, kind='kde');","2794a3aa":"plt.figure(figsize=(12,12))\nsns.kdeplot(df.perimeter_worst, df.area_worst,  shade=True)","eb18b7d8":"plt.figure(figsize=(12,12))\nsns.kdeplot(df[malin].perimeter_worst, df[malin].area_worst, cmap=\"Reds\",  shade=True, alpha=0.3, shade_lowest=False)\nsns.kdeplot(df[benin].perimeter_worst, df[benin].area_worst, cmap=\"Greens\", shade=True, alpha=0.3, shade_lowest=False)","13b3e394":"sns.boxplot(x=\"diagnosis\", y=\"perimeter_worst\", data=df)","8aed241a":"sns.violinplot(x=\"diagnosis\", y=\"perimeter_worst\", data=df)","0053d332":"fig = sns.FacetGrid(df, hue=\"diagnosis\", aspect=3, palette=\"Set2\") # aspect=3 permet d'allonger le graphique\nfig.map(sns.kdeplot, \"perimeter_worst\", shade=True)\nfig.add_legend()","41de8f02":"sns.lmplot(x=\"radius_mean\", y=\"texture_mean\", data=df, fit_reg=False, hue='diagnosis')","f94b99c8":"#sns.pairplot(df, hue=\"diagnosis\")","95343563":"data_train = df.sample(frac=0.8, random_state=1)          # 80% des donn\u00e9es avec frac=0.8\ndata_test = df.drop(data_train.index)     # le reste des donn\u00e9es pour le test","7c78b6f0":"X_train = data_train.drop(['diagnosis'], axis=1)\ny_train = data_train['diagnosis']\nX_test = data_test.drop(['diagnosis'], axis=1)\ny_test = data_test['diagnosis']","3fc4f4d0":"plt.figure(figsize=(9,9))\n\nlogistique = lambda x: np.exp(x)\/(1+np.exp(x))   \n\nx_range = np.linspace(-10,10,50)       \ny_values = logistique(x_range)\n\nplt.plot(x_range, y_values, color=\"red\")","c4d481b0":"from sklearn.linear_model import LogisticRegression","b31018c8":"lr = LogisticRegression()\nlr.fit(X_train,y_train)","98306535":"y_lr = lr.predict(X_test)","bfa44214":"from sklearn.metrics import accuracy_score, confusion_matrix","9994f562":"lr_score = accuracy_score(y_test, y_lr)\nprint(lr_score)","26a86978":"# Matrice de confusion\ncm = confusion_matrix(y_test, y_lr)\nprint(cm)","bddb5ccd":"pd.crosstab(y_test, y_lr, rownames=['Reel'], colnames=['Prediction'], margins=True)","7acfe440":"fig = sns.FacetGrid(df, hue=\"diagnosis\", aspect=3) # aspect=3 permet d'allonger le graphique\nfig.map(sns.kdeplot, \"perimeter_worst\", shade=True)\nfig.add_legend()","69fb1283":"fig = sns.FacetGrid(df[df.perimeter_worst>110], hue=\"diagnosis\", aspect=3) # aspect=3 permet d'allonger le graphique\nfig.map(sns.kdeplot, \"texture_mean\", shade=True)\nfig.add_legend()","3ad0f277":"fig = sns.FacetGrid(df[(df.perimeter_worst>110) & (df.texture_mean>17)], hue=\"diagnosis\", aspect=3) # aspect=3 permet d'allonger le graphique\nfig.map(sns.kdeplot, \"concave points_mean\", shade=True)\nfig.add_legend()","13d0fc1f":"from sklearn import tree\ndtc = tree.DecisionTreeClassifier()\ndtc.fit(X_train,y_train)\ny_dtc = dtc.predict(X_test)\nprint(accuracy_score(y_test, y_dtc))","5e449acd":"plt.figure(figsize=(30,30))\ntree.plot_tree(dtc, feature_names=X_train.columns, class_names=['benin','malin'], fontsize=14, filled=True)  ","830ef100":"dtc1 = tree.DecisionTreeClassifier(max_depth = 3, min_samples_leaf = 20)\ndtc1.fit(X_train,y_train)","b176c6bc":"plt.figure(figsize=(30,30))\ntree.plot_tree(dtc1, feature_names=X_train.columns, class_names=['benin','malin'], fontsize=14, filled=True)  ","0389883e":"y_dtc1 = dtc1.predict(X_test)\nprint(accuracy_score(y_test, y_dtc1))","d3935184":"from sklearn import ensemble\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","7ca2ede3":"rf_score = accuracy_score(y_test, y_rf)\nprint(rf_score)","0044ad88":"pd.crosstab(y_test, y_rf, rownames=['Reel'], colnames=['Prediction'], margins=True)","28b4d436":"importances = rf.feature_importances_\nindices = np.argsort(importances)","c7227fd3":"plt.figure(figsize=(12,8))\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), df.columns[indices])\nplt.title('Importance des caracteristiques')","ff12acfe":"df = sns.load_dataset(\"iris\")","bab21d83":"df.head()","61aaf391":"sns.pairplot(df, hue=\"species\")","671b3129":"La fonction logistique $\\frac{e^{x}}{1+e^{x}}$ varie entre $-\\infty$ et $+\\infty$ pour $x$ variant entre $0$ et $1$.  \nElle est souvent utilis\u00e9e pour \"mapper\" une probabilit\u00e9 et un espace r\u00e9el","62c74d04":"Pour avoir l'ensemble du tableau, on peut utiliser un affichage au format HTML :","5f2a7ff6":"On a les informations suivantes :\n- longueur du s\u00e9pale (en cm)\n- largeur du s\u00e9pale\n- longueur du p\u00e9tale\n- largeur du p\u00e9tale\n- esp\u00e8ce : Virginica, Setosa ou Versicolor","10b52100":"cf par exemple :  \nhttps:\/\/fr.wikipedia.org\/wiki\/For%C3%AAt_d%27arbres_d%C3%A9cisionnels  \nhttps:\/\/www.biostars.org\/p\/86981\/  \nhttps:\/\/infinitescript.com\/2016\/08\/random-forest\/","f15be512":"Les **diagrammes en bo\u00eete** (ou **bo\u00eetes \u00e0 moustaches** ou **box plot**) r\u00e9sument quelques caract\u00e9ristiques de position du caract\u00e8re \u00e9tudi\u00e9 (m\u00e9diane, quartiles, minimum, maximum ou d\u00e9ciles). Ce diagramme est utilis\u00e9 principalement pour comparer un m\u00eame caract\u00e8re dans deux populations de tailles diff\u00e9rentes. Il s'agit de tracer un rectangle allant du premier quartile au troisi\u00e8me quartile et coup\u00e9 par la m\u00e9diane. On ajoute alors des segments aux extr\u00e9mit\u00e9s menant jusqu'aux valeurs extr\u00eames.  \nPar exemple pour la r\u00e9partion des esp\u00e8ces selon la longueur du s\u00e9pale :","ec5c1834":"Pour plus de d\u00e9tails sur les arbres de d\u00e9cision :  \nhttps:\/\/zestedesavoir.com\/tutoriels\/962\/les-arbres-de-decisions\/comprendre-le-concept\/#1-les-origines  \nhttp:\/\/cedric.cnam.fr\/vertigo\/Cours\/ml2\/tpArbresDecision.html  \nhttp:\/\/perso.mines-paristech.fr\/fabien.moutarde\/ES_MachineLearning\/Slides\/coursFM_AD-RF.pdf  ","7fb14940":"### Exercice  \nLe r\u00e9sultat est-il satisfaisant ?  \nQuel pourrait \u00eatre le probl\u00e8me ?","d2599ff2":"# Breast cancer Wisconsin","74470933":"## Arbres de d\u00e9cision","7a34c355":"Pour plus de d\u00e9tails, cf par exemple :  \nhttp:\/\/eric.univ-lyon2.fr\/~ricco\/cours\/cours\/pratique_regression_logistique.pdf","56c60b28":"## Donn\u00e9es","9cea2e3b":"On peut tracer la courbe de r\u00e9gression logistique pour pr\u00e9dire l'esp\u00e8ce Virginica \u00e0 partir de la longueur du s\u00e9pale avec la fonction *lmplot* :","b653d692":"Les **violins plots** sont similaires aux box plots, except\u00e9 qu\u2019ils permettent de montrer la courbe de densit\u00e9 de probabilit\u00e9 des diff\u00e9rentes valeurs. Typiquement, les violins plots pr\u00e9sentent un marqueur pour la m\u00e9diane des donn\u00e9es et l\u2019\u00e9cart interquartile, comme dans un box plot standard.","7237894e":"L'attribut *feature_importances_* renvoie un tableau du poids de chaque caract\u00e9ristique dans la d\u00e9cision :","7fa1d32f":"On peut visualiser ces degr\u00e9s d'importance avec un graphique \u00e0 barres par exemple :","f6e559dc":"La colonne **'Unnamed: 32'** est vide : on va la supprimer ","967970d9":"On a un *faux positif* et deux *faux n\u00e9gatifs*","e2575cf6":"## Librairies utiles","5a658afe":"*FacetGrid* permet de superposer des graphiques selon une ou plusieurs caract\u00e9ristiques. On cr\u00e9e une structure avec *FacetGrid*, et on trace ensuite les graphiques avec *map*","dd7009cc":"### Exercice : les iris","5706a2a7":"## Le dataset Breast Cancer Wisconsin","5da6d221":"On peut pr\u00e9dire les valeurs sur l'ensemble de test avec le mod\u00e8le entra\u00een\u00e9 :","31898d9a":"## Random forests","a145352b":"Et la matrice de confusion :","5112a846":"L'indice *GINI* mesure avec quelle fr\u00e9quence un \u00e9l\u00e9ment al\u00e9atoire de l'ensemble serait mal class\u00e9 si son \u00e9tiquette \u00e9tait s\u00e9lectionn\u00e9e al\u00e9atoirement depuis la distribution des \u00e9tiquettes dans le sous-ensemble.","58bd8b60":"<img src=\"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcQM3aH4Q3AplfE1MR3ROAp9Ok35fafmNT59ddXkdEvNdMkT8X6E\">","b819eec9":"On entra\u00eene le mod\u00e8le de r\u00e9gression logistique avec *fit* :","e96ce1bb":"## Visualisations","e7069f3a":"On peut afficher les 10 premi\u00e8res lignes du dataset :","829752d9":"On obtient un arbre un peu diff\u00e9rent :","f19fc530":"On s\u00e9pare les donn\u00e9es d'apprentissage (*X_train*) et la cible (*y_train*, la colonnes des donn\u00e9es *classe*)","21431652":"Une mesure plus fine consiste \u00e0 compter le nombre de **faux positif** (valeur pr\u00e9dite 1 et r\u00e9elle 0) et de **vrai n\u00e9gatif** (valeur pr\u00e9dite 0 et r\u00e9elle 1). On utilise une **matrice de confusion** :","8fdf0317":"Autrement dit, cela revient \u00e0 trouver une s\u00e9paration lin\u00e9aire des caract\u00e9ristiques qui minimise un crit\u00e8re d'erreur.","237eb7dc":"*pairplot* affiche les nuages de points associ\u00e9s \u00e0 tous les couples de param\u00e8tres :","2c7e0f96":"Pour construire un arbre de d\u00e9cision \u00e0 partir d'un ensemble d'apprentissage, on va choisir une variable qui s\u00e9pare l'ensemble en deux parties les plus distinctes en fonction d'un crit\u00e8re. Sur les iris par exemple, on peut utiliser la largeur du p\u00e9tale pour s\u00e9parer l'esp\u00e8ce Setosa des autres.","337cf4d2":"## Machine learning","155bf916":"On veut pr\u00e9dire une variable al\u00e9atoire $Y$ \u00e0 partir d'un vecteur de variables explicatives $X=(X_1,...,X_n)$\nOn \n","c59a3488":"On s\u00e9pare le dataset en deux parties :\n- un ensemble d'apprentissage (entre 70% et 90% des donn\u00e9es), qui va permettre d'entra\u00eener le mod\u00e8le\n- un ensemble de test (entre 10% et 30% des donn\u00e9es), qui va permettre d'estimer la pertinence de la pr\u00e9diction","4a47b134":"La mesure de pertinence compte le nombre de fois o\u00f9 l'algorithme a fait une bonne pr\u00e9diction (en pourcentage) :","a0486156":"Un arbre de d\u00e9cision permet de faire \u00e0 chaque \u00e9tape un choix entre deux possibilit\u00e9s, pour arriver \u00e0 une r\u00e9ponse sur les feuilles (cf. Akinator)  \n<img src=\"https:\/\/fr.akinator.com\/bundles\/elokencesite\/images\/akitudes_670x1096\/defi.png?v95\">","be645213":"## R\u00e9gression logistique","090c5449":"La r\u00e9gression logistique consiste \u00e0 trouver une fonction lin\u00e9aire C(X) qui permette d'estimer la probabilit\u00e9 de $Y=1$ connaissant $X$ :\n$$p(Y=1|X) = \\frac{e^{C(X)}}{1+e^{C(X)}}$$","78be193a":"On veut tracer un nuage de points selon le rayon et la texture de la tumeur, en diff\u00e9renciant la couleur des points selon le diagnostic :","6dd47aa9":"Le dataset des iris est pr\u00e9d\u00e9fini dans seaborn :","7d1e44dc":"Le dataset est accessible sur :  \nhttps:\/\/www.kaggle.com\/uciml\/breast-cancer-wisconsin-data  \nhttp:\/\/archive.ics.uci.edu\/ml\/datasets\/breast+cancer+wisconsin+%28diagnostic%29  \n(on peut utiliser pd.read_table pour lire un fichier .dat)","aa72fd39":"On peut tracer ce type de graphique avec des couleurs :","11da6ef8":"Appliquer les m\u00e9thodes de visualisation et de machine learning vues pr\u00e9c\u00e9demment sur ce dataset","1e7fe2e5":"On peut aussi utiliser la m\u00e9thode **crosstab** de **Pandas** (plut\u00f4t que la m\u00e9thode confusion_matrix de sklearn) pour afficher la matrice de confusion :","3f000ee0":"On veut maintenant pr\u00e9dire l'esp\u00e8ce \u00e0 partir de toutes les caract\u00e9ristiques, et \u00e9valuer la qualit\u00e9 de cette pr\u00e9diction en utilisant la r\u00e9gression logistique d\u00e9finie dans la librairie *sklearn* :","27cb5dba":"<img src=\"https:\/\/i.stack.imgur.com\/gKyb9.png\">","3c1f9705":"### Importance des caract\u00e9ristiques","6a02f664":"On a les informations suivantes :\n1) ID number 2) Diagnosis (M = malignant, B = benign) 3-32)\n\nTen real-valued features are computed for each cell nucleus:\n\na) radius (mean of distances from center to points on the perimeter)  \nb) texture (standard deviation of gray-scale values)  \nc) perimeter  \nd) area  \ne) smoothness (local variation in radius lengths)  \nf) compactness (perimeter^2 \/ area - 1.0)  \ng) concavity (severity of concave portions of the contour)  \nh) concave points (number of concave portions of the contour)  \ni) symmetry  \nj) fractal dimension (\"coastline approximation\" - 1)  \n  \nThe mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.  \n  \nAll feature values are recoded with four significant digits.","d3ddf36e":"<img src=\"https:\/\/infinitescript.com\/wordpress\/wp-content\/uploads\/2016\/08\/Random-Forest-Example.jpg\">","0e8e152c":"*jointplot* permet de visualiser dans un plan les distributions d'un couple de param\u00e8tres :","55571ae0":"On peut modifier certains param\u00e8tres :  Le param\u00e8tre *max_depth* est un seuil sur la profondeur maximale de l\u2019arbre. Le param\u00e8tre *min_samples_leaf* donne le nombre minimal d\u2019\u00e9chantillons dans un noeud feuille.","6d040e9a":"## Score et matrice de confusion"}}