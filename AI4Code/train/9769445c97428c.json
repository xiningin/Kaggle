{"cell_type":{"23b98aaf":"code","51501418":"code","eb4cdef9":"code","296f1b49":"code","538acbc3":"code","8f453723":"code","c1c98e72":"code","74ea0033":"code","ce288851":"code","2731a4b9":"code","53bbf0c2":"code","cb1213ff":"code","82ca3502":"code","8a27a5d7":"code","3cce07ab":"code","0b20e22b":"code","3bab3a77":"code","b47cdb17":"markdown","cfb3e722":"markdown","532aeed3":"markdown","8ba212e5":"markdown","efaa5495":"markdown","052aba2d":"markdown","f6fbf1fc":"markdown","c590878d":"markdown","790db285":"markdown","f20158f8":"markdown","de64dd8a":"markdown","8f8a757d":"markdown"},"source":{"23b98aaf":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler","51501418":"df=pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\ndf.head(5)","eb4cdef9":"df.info()","296f1b49":"df.describe()","538acbc3":"df.drop(['density'],inplace=True, axis =1)\ndf.isnull().sum()","8f453723":"df.hist(bins=10,figsize=(15,12))\nplt.show()","c1c98e72":"plt.figure(figsize=(15,10))\ncorr = df.corr()\nsns.heatmap(corr,annot=True,cmap='viridis')","74ea0033":"corr_cols=[]\nfor i in range(len(df.columns)-1):\n    for j in range(i):\n        val=corr.iloc[i,j]\n        if abs(val)>=.7:\n            corr_cols.append(corr.columns[i])\nprint(corr_cols)","ce288851":"def quality(x):\n    if x<5:\n        return 0 #bad\n    elif x==5 or x==6:\n        return 1 #average\n    else:\n        return 2 #good\ndf['quality']=df['quality'].apply(quality)","2731a4b9":"x=df.iloc[:,:-1]\ny=df.iloc[:,-1]\nxTrain,xTest,yTrain,yTest=train_test_split(x,y,test_size=.2,random_state=1)","53bbf0c2":"sc=MinMaxScaler()\nxTrain=sc.fit_transform(xTrain)\nxTest=sc.transform(xTest)","cb1213ff":"acc = 0\nk=0\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(xTrain,yTrain)\n    pred = knn.predict(xTest)\n    score=accuracy_score(yTest,pred)\n    if score>acc:\n        acc=score\n        k=i\nprint(acc,k)","82ca3502":"knn = KNeighborsClassifier(n_neighbors=k)\nknn.fit(xTrain,yTrain)\npred = knn.predict(xTest)\nprint(accuracy_score(yTest,pred))","8a27a5d7":"classifier=RandomForestClassifier()\nclassifier.fit(xTrain,yTrain)\nyPred = classifier.predict(xTest)\nprint(accuracy_score(yTest,yPred))","3cce07ab":"model=xgb.XGBClassifier() \nmodel.fit(xTrain, yTrain) \nyPred=model.predict(xTest) \nprint(accuracy_score(yTest, yPred)) ","0b20e22b":"mod_nb=GaussianNB()\nmod_nb.fit(xTrain,yTrain)\nyPred=mod_nb.predict(xTest) \nprint(accuracy_score(yTest, yPred))","3bab3a77":"mod=SVC(kernel='rbf')\nmod.fit(xTrain,yTrain)\nyPred=mod.predict(xTest) \nprint(accuracy_score(yTest, yPred))","b47cdb17":"# Random Forest","cfb3e722":"# KNN Classifier","532aeed3":"The MEAN, STD, 75%, max value are all ~~ 1 for density. So let's drop 'Density column.","8ba212e5":"# Scale the Data","efaa5495":"# XGBOOST","052aba2d":"No columns have strong correlation with other columns in the data. So we are keeping all columns here.","f6fbf1fc":"Let's categorise the wine quality into 3 as Bad, Average and Good. From the histogram plotted above, It s clear that quality is more of distributed normally with majority falling in between 5 and 6. So let's take values between 5&6 as average quality.","c590878d":"Random Forest classifier had the highest accuracy. Upvote if you like the kernel.","790db285":"# Naive Bayes","f20158f8":"# Multivariate analysis\n\nLet's plot a heat map to find the correlated data columns","de64dd8a":"# Support Vector Classifier","8f8a757d":"# Univariate analysis"}}