{"cell_type":{"b0c811ba":"code","ecc760c8":"code","cba910a1":"code","4fc08e27":"code","c450727c":"code","debc7a15":"code","d84e0b4e":"code","18200b8b":"code","2e54c065":"code","5307a844":"code","fabd9e6d":"code","d2a31dbf":"code","3b1a9d2f":"code","dc6aabfd":"code","bb38ef73":"code","890844d4":"code","4025d500":"code","e5a97ca9":"code","57e8525e":"code","1734d826":"code","1504f849":"code","76d80fc6":"code","e898016d":"code","347e58ae":"code","e36067e5":"code","558498d0":"code","641f391b":"code","28c09566":"code","e1179025":"code","6aaee499":"code","ca9ffe15":"code","cc4de32e":"code","892c470b":"code","fe7fa9aa":"code","0227f1c2":"code","75358b5d":"code","265d310f":"code","5b1d2dae":"code","60c66daa":"code","406d3707":"code","a21655a1":"code","f89f49bd":"code","c18b158c":"code","560fb99f":"code","cbce46cd":"code","2d057704":"code","d5c6e43b":"code","3f027cd4":"code","62ec3a5f":"code","72a14b07":"code","6d3ba906":"code","8cf41edd":"code","b59bf12f":"code","338461e6":"code","fecd54bb":"code","4177529c":"code","2858a310":"code","7f3b6eff":"code","9119f859":"code","8fe68201":"code","76035ef4":"markdown","39d094fb":"markdown","f54b2204":"markdown","32123713":"markdown","92fbd8cc":"markdown","c3723d0f":"markdown","b0e9718a":"markdown","76dab535":"markdown","de4158bc":"markdown","ee927edc":"markdown","252fae63":"markdown","16deef4f":"markdown","67cb7142":"markdown","502d5bf4":"markdown","d1e8ede4":"markdown","08b78f74":"markdown","d6434ba3":"markdown","adf1534a":"markdown","8301614f":"markdown","f82b6a14":"markdown","8c6dbef0":"markdown","be25fb2e":"markdown","10758c02":"markdown","60f1a94f":"markdown","3b52c33d":"markdown","fe49bce2":"markdown","b793a589":"markdown","91ee1396":"markdown"},"source":{"b0c811ba":"import pandas as pd\nimport numpy as np\nimport gc\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\n# Plots look better and clearer in svg format\n%config InlineBackend.figure_format = 'svg' \n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\n# Some aesthetic settings\nplt.style.use('bmh')\nsns.set(style = 'whitegrid', font_scale = 0.8, rc={\"grid.linewidth\": 0.5, \"lines.linewidth\": 1})","ecc760c8":"# Loading datasets\nid_train = pd.read_csv('..\/input\/train_identity.csv', index_col = 'TransactionID')\ntr_train = pd.read_csv('..\/input\/train_transaction.csv', index_col = 'TransactionID')\n\nid_test = pd.read_csv('..\/input\/test_identity.csv', index_col = 'TransactionID')\ntr_test = pd.read_csv('..\/input\/test_transaction.csv', index_col = 'TransactionID')","cba910a1":"# Join train and test datasets\ntrain_df = tr_train.join(id_train)\ntest_df = tr_test.join(id_test)\n\n# Removing datasets that we don't need anymore\ndel id_train\ndel tr_train\ndel id_test\ndel tr_test\n\ngc.collect()","4fc08e27":"# Shape of datasets\nprint('Train dataset shape: ',  train_df.shape)\nprint('Test dataset shape: ',  test_df.shape)","c450727c":"train_df.head()\n\n#     TransactionDT: timedelta from a given reference datetime (not an actual timestamp)\n#     TransactionAMT: transaction payment amount in USD\n#     ProductCD: product code, the product for each transaction\n#     card1 - card6: payment card information, such as card type, card category, issue bank, country, etc.\n#     addr: address\n#     dist: distance\n#     P_ and (R__) emaildomain: purchaser and recipient email domain\n#     C1-C14: counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked.\n#     D1-D15: timedelta, such as days between previous transaction, etc.\n#     M1-M9: match, such as names on card and address, etc.\n#     Vxxx: Vesta engineered rich features, including ranking, counting, and other entity relations.","debc7a15":"# Function block\ndef null_table(dataset):\n    \n    '''Create table with ammount of null values for dataset'''\n    \n    return pd.DataFrame({'Null values': dataset.isnull().sum(), \n                         '% of nulls': round((dataset.isnull().sum() \/ dataset.shape[0]) * 100, 2)}).T\n\ndef plot_hist(col, hist=True, kde = True, bins = 50, log = False, fillna = np.nan):\n    \n    '''Creates distribution plot for train\/test datasets and fraud\n        col - column name\n        hist - Whether to plot a histogram (True\/False)\n        kde - Whether to plot a gaussian kernel density estimate (True\/False)\n        bins - number of bins\n        log - apply np.log1p transform to values (True\/False)\n        fillna - fill nulls with specified value'''\n    \n    if log:\n        sns.distplot(np.log1p(train_df[col].fillna(fillna)), label = 'Train', hist = hist, bins = bins, kde = kde)\n        sns.distplot(np.log1p(test_df[col].fillna(fillna)), label = 'Test', hist = hist, bins = bins, kde = kde)\n        sns.distplot(np.log1p(train_df[train_df['isFraud'] == 1][col].fillna(fillna)), label = 'Fraud', hist = hist, bins = bins, kde = kde)\n        plt.title(f'Distribution of {col} feature with log transform')\n        \n    else:\n        sns.distplot(train_df[col].fillna(fillna), label = 'Train', hist = hist, bins = bins, kde = kde)\n        sns.distplot(test_df[col].fillna(fillna), label = 'Test', hist = hist, bins = bins, kde = kde)\n        sns.distplot(train_df[train_df['isFraud'] == 1][col].fillna(fillna), label = 'Fraud', hist = hist, bins = bins, kde = kde, color = 'black')\n        plt.title(f'Distribution of {col} feature')\n        \n    plt.legend()\n\ndef plot_cat(col, test = True, rot = 0, n = False, fillna = np.nan, annot = False, title = True):\n    \n    '''Creates countplot for train\/test datasets and fraud\n       col - column name\n       test - makes 2 plots if True - countplot for train and test values, second - countplot fraud and non fraud in train dataset\n       rot - rotation of xticks\n       n - plot only n top values\n       fillna - fill nulls with specified values\n       annot - whether to plot % of transactions\n       '''\n    \n    if n:\n        order = train_df[col].fillna(fillna).value_counts().sort_values(ascending = False).iloc[:n].index\n    else:\n        order = train_df[col].fillna(fillna).value_counts().sort_values(ascending = False).index\n    \n    if test:\n        t = pd.DataFrame({col: train_df[col], 'Label': 'Train'})\n        tst = pd.DataFrame({col: test_df[col], 'Label': 'Test'})\n        t_tr = pd.concat([t, tst])        \n               \n        plt.subplot('211')        \n        sns.countplot(t_tr[col].fillna(fillna), hue = t_tr['Label'], \n                      order = order).set_title('Train\/Test countplot')\n        plt.xticks(rotation = rot)\n        \n        plt.subplot('212')        \n        g = sns.countplot(train_df[col].fillna(fillna), hue = train_df['isFraud'],\n                     order = order)\n        if annot:\n            for p in g.patches:\n                g.annotate('{:.1f}%'.format((p.get_height() \/ train_df.shape[0]) * 100, 2), \n                           (p.get_x() + 0.1, p.get_height()+5000))\n        plt.title('Fraud\/non fraud countplot')\n        plt.xticks(rotation = rot)\n        plt.tight_layout()\n        \n    else:\n        g = sns.countplot(train_df[col].fillna(fillna), hue = train_df['isFraud'], \n                      order = order)\n        if annot:\n            for p in g.patches:\n                g.annotate('{:.1f}%'.format((p.get_height() \/ train_df.shape[0]) * 100, 2), \n                           (p.get_x() + 0.1, p.get_height()+5000))\n        if title:\n            plt.title('Fraud\/non fraud countplot')\n        plt.xticks(rotation = rot)\n        \ndef plot_rate(col, figsize = (8, 4), head = False, n = 10, df = False):\n    \n    ''' Plot fraud rate for categorical features'''\n    \n    if df:\n        if head:\n            return pd.DataFrame(train_df[train_df['isFraud'] == 1][col].value_counts() \/\n                                  train_df[col].value_counts()).sort_values(by = col, ascending = False).head(n)\n        else:\n            return pd.DataFrame(train_df[train_df['isFraud'] == 1][col].value_counts() \/\n                                  train_df[col].value_counts()).sort_values(by = col, ascending = False)\n    else:\n        \n        if head:\n            fraud_rate = pd.DataFrame(train_df[train_df['isFraud'] == 1][col].value_counts() \/\n                                      train_df[col].value_counts()).sort_values(by = col, ascending = False).head(n)\n        else:\n            fraud_rate = pd.DataFrame(train_df[train_df['isFraud'] == 1][col].value_counts() \/ \n                                      train_df[col].value_counts()).sort_values(by = col, ascending = False)\n\n        fraud_rate.plot(kind = 'bar', figsize = figsize)\n        \ndef plot_grid(cols_list, rows, cols, start = 0, end = -1, figsize = (11, 10), rot = 45):\n    fig = plt.figure(figsize = figsize)\n    for i, col in enumerate(cols_list[start:end]):\n        plt.subplot(rows, cols, i+1)\n        if train_df[col].dtype == 'O':\n            plot_cat(col, test = False, n = 15, rot = rot)\n\n        else:\n            plot_hist(col, hist = False)\n    plt.tight_layout()","d84e0b4e":"train_null = null_table(train_df)\ntest_null = null_table(test_df)\n\ntrain_null","18200b8b":"test_null","2e54c065":"print('Number of train_df features with more than 50% null values: ', train_null.T[train_null.T['% of nulls'] > 50].shape[0])\nprint('Number of test_df features with more than 50% null values: ', test_null.T[test_null.T['% of nulls'] > 50].shape[0])","5307a844":"# isFraud feature\nfig = plt.figure(figsize = (5, 4))\ng = sns.countplot('isFraud', data = train_df)\nfor p in g.patches:\n    g.annotate('{} ({:.2f})%'.format(p.get_height(), (p.get_height() \/ train_df.shape[0]) * 100, 2), (p.get_x() + 0.1, p.get_height()+5000))","fabd9e6d":"# TransactionDT: timedelta from a given reference datetime (not an actual timestamp)\nfig = plt.figure(figsize = (13, 6))\nplot_hist('TransactionDT')","d2a31dbf":"train_df['Tr_day'] = np.floor((train_df['TransactionDT'] \/ (3600 * 24) - 1) % 7)\ntrain_df['Tr_hour'] = np.floor(train_df['TransactionDT'] \/ 3600) % 24","3b1a9d2f":"# Day of transaction plots\nfig, ax = plt.subplots(1, 2, figsize = (13, 4))\nsns.barplot(x = 'Tr_day', y = 'TransactionAmt', data = train_df, hue = 'isFraud', ax = ax[0])\nsns.countplot(x = 'Tr_day', data = train_df, hue = 'isFraud', ax = ax[1])","dc6aabfd":"# Hour of transaction plots\nfig, ax = plt.subplots(2, 1, figsize = (13, 6))\nsns.barplot(x = 'Tr_hour', y = 'TransactionAmt', data = train_df, hue = 'isFraud', ax = ax[0])\nsns.countplot(x = 'Tr_hour', data = train_df, hue = 'isFraud', ax = ax[1])","bb38ef73":"#     TransactionAMT: transaction payment amount in USD\nfor i, j in enumerate([False, True]):\n    fig = plt.figure(figsize = (13, 7))\n    plt.subplot(f'21{i+1}')\n    plot_hist('TransactionAmt', hist = False, log = j)","890844d4":"train_df['TransactionAmt'].describe()","4025d500":"# ProductCD: product code, the product for each transaction\nfig, ax = plt.subplots(2, 1, figsize = (11, 7))\nplot_cat('ProductCD')","e5a97ca9":"plot_rate('ProductCD')","57e8525e":"# card1 - card6: payment card information, such as card type, card category, issue bank, country, etc.\ncols = ['card{}'.format(i) for i in range(1, 7)]\nfig = plt.figure(figsize = (11, 7))\nfor i, col in enumerate(cols):\n    plt.subplot('23{}'.format(i + 1))\n    \n    if col not in ['card4', 'card6']:    \n        plot_hist(col, hist = False)\n        \n    else:\n        plot_cat(col, test = False, rot = 90, annot = False)\n        \nplt.tight_layout()","1734d826":"plot_rate('card4')","1504f849":"#   addr: address\n#   dist: distance\nfig = plt.figure(figsize = (11, 7))\nfor i, col in enumerate(['addr1', 'addr2', 'dist1', 'dist2']):    \n    plt.subplot(f'22{i+1}')\n    plot_hist(col, hist = False)\nplt.tight_layout()","76d80fc6":"fig = plt.figure(figsize = (11, 7))\nfor i, col in enumerate(['addr1', 'addr2', 'dist1', 'dist2']):    \n    plt.subplot(f'22{i+1}')\n    plot_cat(col, test = False, annot = False, n = 10, title = False)\nplt.tight_layout()","e898016d":"fig, ax = plt.subplots(1, 2, figsize = (13, 4))\nfor i, col in enumerate(['addr1', 'addr2']):\n    fraud_rate = pd.DataFrame(train_df[train_df['isFraud'] == 1][col].value_counts() \/\n                              train_df[col].value_counts()).sort_values(by = col, ascending = False).head(20)\n    fraud_rate.plot(kind = 'bar', ax = ax[i])\n    ","347e58ae":"train_df[train_df['addr1'].isin(plot_rate('addr1', df = True, head = True, n = 6).index.values)]['addr1'].value_counts()","e36067e5":"train_df[train_df['addr2'].isin(plot_rate('addr2', df = True, head = True, n = 6).index.values)]['addr2'].value_counts()","558498d0":"fig, ax = plt.subplots(2, 1, figsize = (11, 7))\nfor i, col in enumerate(['dist1', 'dist2']):\n    fraud_rate = pd.DataFrame(train_df[train_df['isFraud'] == 1][col].value_counts() \/\n                              train_df[col].value_counts()).sort_values(by = col, ascending = False).head(40)\n    fraud_rate.plot(kind = 'bar', ax = ax[i])\nplt.tight_layout()","641f391b":"train_df[train_df['dist1'].isin(plot_rate('dist1', df = True, head = True, n = 16).index.values)]['dist1'].value_counts()","28c09566":"train_df[train_df['dist2'].isin(plot_rate('dist2', df = True, head = True, n = 28).index.values)]['dist2'].value_counts()","e1179025":"#     P_ and (R__) emaildomain: purchaser and recipient email domain\n# P_emaildomain feature\nfig = plt.figure(figsize = (11, 8))\nplot_cat('P_emaildomain', rot = 90, fillna = 'Null', n = 20, annot = False)","6aaee499":"# R_emaildomain feature\nfig = plt.figure(figsize = (11, 8))\nplot_cat('R_emaildomain', rot = 90, n = 20, annot = False)","ca9ffe15":"fig, ax = plt.subplots(2, 1, figsize = (11, 7))\nfor i, col in enumerate(['P_emaildomain', 'R_emaildomain']):\n    fraud_rate = pd.DataFrame(train_df[train_df['isFraud'] == 1][col].value_counts() \/\n                              train_df[col].value_counts()).sort_values(by = col, ascending = False).head(40)\n    fraud_rate.plot(kind = 'bar', ax = ax[i])\nplt.tight_layout()","cc4de32e":"print(train_df[train_df['P_emaildomain'] == 'protonmail.com']['P_emaildomain'].value_counts())\nprint(train_df[train_df['R_emaildomain'] == 'protonmail.com']['R_emaildomain'].value_counts())","892c470b":"#     C1-C14: counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked.\nc_cols = [f'C{i}' for i in range(1, 15)]\ntrain_df[c_cols].describe()","fe7fa9aa":"# C1-C6 features\ncols = [f'C{i}' for i in range(1, 7)]\nfig = plt.figure(figsize = (11, 18))\nfor i, col in enumerate(cols):    \n    plt.subplot(f'72{i+1}')\n    plot_hist(col, hist = False)\nplt.tight_layout()","0227f1c2":"fig = plt.figure(figsize = (11, 7))\nfor i, col in enumerate(cols):    \n    plt.subplot(f'32{i+1}')\n    plot_cat(col, test = False, annot = False, n = 10, title = False)\nplt.tight_layout()","75358b5d":"fig, ax = plt.subplots(6, 1, figsize = (11, 10))\nfor i, col in enumerate(cols):\n    fraud_rate = pd.DataFrame(train_df[train_df['isFraud'] == 1][col].value_counts() \/\n                              train_df[col].value_counts()).sort_values(by = col, ascending = False).head(60)\n    fraud_rate.plot(kind = 'bar', ax = ax[i])\nplt.tight_layout()","265d310f":"# C7-C14 features\ncols = [f'C{i}' for i in range(7, 15)]\nfig = plt.figure(figsize = (11, 20))\nfor i, col in enumerate(cols):    \n    plt.subplot(f'72{i+1}')\n    plot_hist(col, hist = False)\nplt.tight_layout()","5b1d2dae":"fig = plt.figure(figsize = (11, 8))\nfor i, col in enumerate(cols):    \n    plt.subplot(f'24{i+1}')\n    plot_cat(col, test = False, annot = False, n = 10, title = False, rot = 90)\nplt.tight_layout()","60c66daa":"fig, ax = plt.subplots(8, 1, figsize = (11, 12))\nfor i, col in enumerate(cols):\n    fraud_rate = pd.DataFrame(train_df[train_df['isFraud'] == 1][col].value_counts() \/\n                              train_df[col].value_counts()).sort_values(by = col, ascending = False).head(60)\n    fraud_rate.plot(kind = 'bar', ax = ax[i])\nplt.tight_layout()","406d3707":"#     D1-D15: timedelta, such as days between previous transaction, etc.\nd_cols = [f'D{i}' for i in range(1, 16)]\ntrain_df[d_cols].describe()","a21655a1":"cols = [f'D{i}' for i in range(1, 9)]\nfig = plt.figure(figsize = (11, 20))\nfor i, col in enumerate(cols):    \n    plt.subplot(f'72{i+1}')\n    plot_hist(col, hist = False)\nplt.tight_layout()","f89f49bd":"fig = plt.figure(figsize = (11, 8))\nfor i, col in enumerate(cols):    \n    plt.subplot(f'24{i+1}')\n    plot_cat(col, test = False, annot = False, n = 10, title = False, rot = 90)\nplt.tight_layout()","c18b158c":"fig, ax = plt.subplots(8, 1, figsize = (11, 12))\nfor i, col in enumerate(cols):\n    fraud_rate = pd.DataFrame(train_df[train_df['isFraud'] == 1][col].value_counts() \/\n                              train_df[col].value_counts()).sort_values(by = col, ascending = False).head(60)\n    fraud_rate.plot(kind = 'bar', ax = ax[i])\nplt.tight_layout()","560fb99f":"cols = [f'D{i}' for i in range(9, 16)]\nfig = plt.figure(figsize = (11, 20))\nfor i, col in enumerate(cols):    \n    plt.subplot(f'72{i+1}')\n    plot_hist(col, hist = False)\nplt.tight_layout()","cbce46cd":"fig = plt.figure(figsize = (11, 8))\nfor i, col in enumerate(cols):    \n    plt.subplot(f'24{i+1}')\n    plot_cat(col, test = False, annot = False, n = 10, title = False, rot = 90)\nplt.tight_layout()","2d057704":"fig, ax = plt.subplots(7, 1, figsize = (11, 20))\nfor i, col in enumerate(cols):\n    fraud_rate = pd.DataFrame(train_df[train_df['isFraud'] == 1][col].value_counts() \/\n                              train_df[col].value_counts()).sort_values(by = col, ascending = False).head(60)\n    fraud_rate.plot(kind = 'bar', ax = ax[i])\nplt.tight_layout()","d5c6e43b":"#     M1-M9: match, such as names on card and address, etc.\nm_cols = [f'M{i}' for i in range(1, 10)]\ntrain_df[m_cols].describe()","3f027cd4":"fig = plt.figure(figsize = (11, 10))\nfor i, col in enumerate(m_cols):    \n    plt.subplot(f'33{i+1}')\n    plot_cat(col, test = False, fillna = 'Null')\nplt.tight_layout()","62ec3a5f":"fig, ax = plt.subplots(1, 9, figsize = (15, 3))\nfor i, col in enumerate(m_cols):\n    fraud_rate = pd.DataFrame(train_df[train_df['isFraud'] == 1][col].value_counts() \/\n                              train_df[col].value_counts()).sort_values(by = col, ascending = False)\n    fraud_rate.plot(kind = 'bar', ax = ax[i])\nplt.tight_layout()","72a14b07":"# DeviceType\nfig = plt.figure(figsize = (8, 8))\nplot_cat('DeviceType', rot = 90, fillna = 'null')","6d3ba906":"plot_rate('DeviceType')","8cf41edd":"# DeviceInfo\nfig = plt.figure(figsize = (12, 4))\nplot_cat('DeviceInfo', rot = 90, test = False, n = 20, annot = False)","b59bf12f":"plot_rate('DeviceInfo', head = True, figsize = (13, 4), n = 60)","338461e6":"train_df[train_df['DeviceInfo'].isin(plot_rate('DeviceInfo', df = True, head = True, n = 46).index.values)]['DeviceInfo'].value_counts()","fecd54bb":"# id features\nid_cols = [f'id_0{i}' for i in range(1, 10)] + [f'id_{i}' for i in range(10, 39)]\ntrain_df[id_cols].describe(include = 'all')","4177529c":"plot_grid(id_cols, 3, 3, 0, 9)","2858a310":"plot_grid(id_cols, 3, 3, 9, 18)","7f3b6eff":"plot_grid(id_cols, 3, 3, 18, 27)","9119f859":"plot_grid(id_cols, 3, 3, 27, 36)","8fe68201":"plot_grid(id_cols, 1, 2, 36, 39, figsize = (8, 3))","76035ef4":"Next - we need to join our identity and transaction datasets, it can be easily done with pd.DataFrame.join function:","39d094fb":"C1, C2, C4 and C6 features have high fraud rate on high values\n\nC3 feature have relatively high fraud rate on low values\n\nC5 have a peak of fraudent rate on 331 value","f54b2204":"**Loading datasets:**","32123713":"Similar picture - high values have high fraud rates.","92fbd8cc":"Create a dataframe with null values for train and test datasets:","c3723d0f":"D1-D15 features:","b0e9718a":"We have a lot of null values in our datasets:","76dab535":"These addresses have 19 transactions and all of them is fraudent.\n\nLet's look ad dist feature","de4158bc":"50% of transactions has small values from 43 to 125 dollars, and most part of fraudint transactions concentrated in this interval, but also we can see 2 fraudent transactions peaks - on approximately 1100 and 5000 dollars.\n\n","ee927edc":"To save time I'll create a couple of functions for data plotting.","252fae63":"Devices with 100% fraud rate","16deef4f":"We can see that for every given day of week fraudent transactions have higher mean value and higher standard deviation.\n\nAlso we can see that 0.0 day have more fraudent transactions than other days.","67cb7142":"We see that protonmail.com have very high fraud rate - more than 40 percent for P_emaildomain feature, and near 100 percent for R_emaildomain feature.","502d5bf4":"We can see that gmail.com takes a vast part of all fraud transactions, but let's take a look at fraud rate:","d1e8ede4":"**Import all necessary modules:**","08b78f74":"M1-M9 features","d6434ba3":"M1 - F value contains no fraud transactions\nM4 - M2 value is a peak of fraudent transactions","adf1534a":"In this kernel I'll try to make a first look on the data.\n\nThis kernel contains all features except Vxxx. You can see my Vxxx features EDA in [this](https:\/\/www.kaggle.com\/trolukovich\/vxxx-features-eda) kernel.\n\nThe data divided into train and test datasets each of which is represented by x_transaction.csv and x_identity.csv\n\nData description provided in [this](https:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/discussion\/101203#latest-595301) topic, but for convinience, I'll copy it here:\n\n\n    **Transaction Table**\n\n    TransactionDT: timedelta from a given reference datetime (not an actual timestamp)\n    TransactionAMT: transaction payment amount in USD\n    ProductCD: product code, the product for each transaction\n    card1 - card6: payment card information, such as card type, card category, issue bank, country, etc.\n    addr: address\n    dist: distance\n    P_ and (R__) emaildomain: purchaser and recipient email domain\n    C1-C14: counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked.\n    D1-D15: timedelta, such as days between previous transaction, etc.\n    M1-M9: match, such as names on card and address, etc.\n    Vxxx: Vesta engineered rich features, including ranking, counting, and other entity relations.\n\n    *Categorical Features:*\n    ProductCD\n    card1 - card6\n    addr1, addr2\n    Pemaildomain Remaildomain\n    M1 - M9\n\n    **Identity Table**\n\nVariables in this table are identity information \u2013 network connection information (IP, ISP, Proxy, etc) and digital signature (UA\/browser\/os\/version, etc) associated with transactions.\nThey're collected by Vesta\u2019s fraud protection system and digital security partners.\n(The field names are masked and pairwise dictionary will not be provided for privacy protection and contract agreement)\n\n    *Categorical Features:*\n    DeviceType\n    DeviceInfo\n    id12 - id38","8301614f":"Let's start plotting.\nWe have very imballanced data - only 3.5% of data is fraudent.","f82b6a14":"We can see that 75 percent of these features have very smal values - 0, 1, 2 or 3, and very high maximum values.","8c6dbef0":"We can see that the data represented in two time intervals, and the test dataset is presented by earlier observations than the training dataset. Also we can see a couple of fraudent transactions peaks on 0.5 an 1 value.\n\nLet's make 2 new features with day and hour of transaction:","be25fb2e":"Let's look at fraud rate:","10758c02":"All of these transactions are fraudent.\n\nLet's look at P\/R_emaildomain features:","60f1a94f":"card1 - a big fraud peak on 10000 value\n\ncard4 - discover is most fraudent card, it has twice more fraudent transactions than other cards.\n\ncard6 - credit cards have more fraudent transactions than other cards.","3b52c33d":"We can see a lot of distances with 100 percent fraud rate.","fe49bce2":"We have 74.4% of transactions in W product, and it takes almost half of fraudent transactions, but looking on fraud rate plot we see, that W product have smallest fraud rate, and C product have highest.","b793a589":"Next: C1-C14 features.","91ee1396":"We can see something interesting here:\n- very high fraud rate for some addresses in addr1 feature\n- fraud rate equal to 1 for some addresses in addr2 feature\n\nLet's take a closer look"}}