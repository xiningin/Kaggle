{"cell_type":{"b18f42b5":"code","658493ed":"code","d3885747":"code","0bd55305":"code","3c61d74e":"code","ed0d4d38":"code","d803b12b":"code","09c49b6d":"code","598ec1b4":"code","bdcf114f":"code","f20588dd":"code","7ee4463a":"code","65eef8cb":"code","945f1367":"code","46daff8c":"code","b8f2c5b8":"code","d10498c7":"code","ef762183":"code","f3164792":"code","c7bba3e4":"code","d2dcfac9":"code","293d7350":"code","88923542":"code","d1b9175d":"code","f1c2baae":"code","afeda1be":"code","005b5206":"code","9378559b":"code","47c1e17c":"code","08255019":"code","e79c8e53":"code","d28f4b62":"code","1eaf32f4":"code","6257e205":"code","eea1911b":"code","de103f7b":"code","8fe7f617":"code","3ea0b312":"code","e4e6ecad":"code","6c69b69d":"code","7de64a18":"code","3eca3469":"code","2749be43":"code","5e6d70ef":"code","2e558e8f":"code","3b297043":"code","5496088a":"code","37974e07":"code","6bbc2b62":"code","3dc1e0aa":"markdown","f8ac8a45":"markdown","cba15943":"markdown","d9bd8618":"markdown","137b5c35":"markdown","75c6978b":"markdown","21541cbd":"markdown","5a996bef":"markdown","7f76bee1":"markdown","48578e47":"markdown","bb7c4581":"markdown","acb5ffac":"markdown","9f4b66d6":"markdown"},"source":{"b18f42b5":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# importing the necessary libraries\nimport pandas as pd\nimport numpy as np\n\nimport random\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error","658493ed":"data = pd.read_csv(\"\/kaggle\/input\/cristiano-ronaldos-goals\/yds_data.csv\") # reading data from the CSV file","d3885747":"data.shape # checking how many rows and columns are in the data","0bd55305":"data.head() # seeing how the data looks like","3c61d74e":"# A. Using descriptive Statistics to find some insights\ndata.describe()","ed0d4d38":"# B. Finding the dtypes of Columns to get some Insights\ndata.info()","d803b12b":"# Percentage and Sum of Missing values in each Columns\nmissing_data = pd.DataFrame({'total_missing': data.isnull().sum(), 'perc_missing': (data.isnull().sum()\/data.shape[0])*100})\nmissing_data","09c49b6d":"# Exploring The Target Variable 'is_goal'\ndata.is_goal.value_counts()","598ec1b4":"#1. Droping Unnecessary Columns\ndata.drop([\"Unnamed: 0\",  'remaining_min.1', 'power_of_shot.1','knockout_match.1', 'remaining_sec.1', 'distance_of_shot.1'], axis=1, inplace=True)","bdcf114f":"data.head() # looking at the dataset after transformation","f20588dd":"data.columns # to see if the columns are dropped succesfully","7ee4463a":"#2. Changing dtypes to datetime\ndata.date_of_game = pd.to_datetime(data.date_of_game, errors='coerce')\ndata['game_season'] = data['game_season'].astype('object')\ndata['game_season']","65eef8cb":"# Labelencoding the 'game_season' ","945f1367":"l_unique = data['game_season'].unique() # fteching out the unique values from game_season\/\nl_unique","46daff8c":"v_unique = np.arange(len(l_unique)) # obtaining values in the range of the length of I_unique\nv_unique","b8f2c5b8":"data['game_season'].replace(to_replace=l_unique, value=v_unique, inplace=True) # replacing categorical data with numerical values\ndata['game_season'].head()","d10498c7":"data['game_season'] = data['game_season'].astype('int') # converting the datatype of the column from int64 to int32\ndata['game_season'].head()","ef762183":"# Filling NaN values in Column \"remaining_sec\" with MEAN\ndata['power_of_shot'].fillna(value=data['power_of_shot'].mean(), inplace=True)\ndata.isnull().sum() # number of missing values for power_of_shot column should be zero\n","f3164792":"# Filling NaN values in Column \"type_of_combined_shot\" with MODE\nmode_com  = data.type_of_combined_shot.value_counts().keys()[0]\nprint('moded is: ',mode_com)\ndata.type_of_combined_shot.fillna(value=mode_com, inplace=True)\ndata.isnull().sum() # number of missing values for type_of_combined_shot column should be zero","c7bba3e4":"# Filling NaN values in Column \"remaining_sec\" with MEDIAN\ndata.remaining_sec.fillna(value=data.remaining_sec.median(), inplace=True)\ndata.isnull().sum() # number of missing values for remaining_sec column should be zero","d2dcfac9":"# Shot_id_no.\ndata.shot_id_number = pd.Series(np.arange(1,data.shot_id_number.shape[0]+1))\ndata.isnull().sum() # number of missing values for shot_id_number column should be zero","293d7350":"# Filling NaN values in Columns \"location_x\" and \"location_y\" with 0\ndata['location_x'].fillna(value=0, inplace=True)\ndata['location_y'].fillna(value=0, inplace=True)\ndata.isnull().sum() # number of missing values for location_x and location_y columns should be zero","88923542":"# Using Forward Filling method in appropriate Columns\nprint('Null values in column home\/away before forward fill =',data['home\/away'].isnull().sum())\ncol = ['home\/away','lat\/lng', 'team_name','match_id','match_event_id', 'team_id', 'remaining_min', 'knockout_match',  'game_season' ]\ndata.loc[:,col] = data.loc[:,col].ffill()\nprint('Null values in column home\/away after the forward fill =',data['home\/away'].isnull().sum())","d1b9175d":"# Filling Missing Values In \"shot_basics\" based on \"range_of_short\" column!\n# if the range of the shot is 16-24 ft it's a mid range shot\ndata.loc[(data.range_of_shot == '16-24 ft.'), 'shot_basics'] = data[data.range_of_shot == '16-24 ft.'].shot_basics.fillna(value='Mid Range')\n\n# if the range of the shot is less than 8 ft then randomly assign goal line or goal area value to the shot \ndata.loc[(data.range_of_shot == 'Less Than 8 ft.')&(data.shot_basics.isnull()), 'shot_basics']   =  pd.Series(data[(data.range_of_shot == 'Less Than 8 ft.')&(data.shot_basics.isnull())].shot_basics.apply(lambda x: x if type(x)==str else np.random.choice(['Goal Area', 'Goal Line'],1,p=[0.7590347263095939, 0.24096527369040613])[0]))\n# if the range of the shot is  8-16 ft then randomly assign goal line or mid range value to the shot\ndata.loc[(data.range_of_shot == '8-16 ft.')&(data.shot_basics.isnull()), 'shot_basics']          =  pd.Series(data[(data.range_of_shot == '8-16 ft.')&(data.shot_basics.isnull())].shot_basics.apply(lambda x: x if type(x)==str else np.random.choice(['Mid Range', 'Goal Line'],1,p=[0.6488754615642833, 0.35112453843571667])[0]))\n# if the range of the shot is more than 24 ft then randomly assign one of the values from'Penalty Spot', 'Right Corner', 'Left Corner' to shot_basic field\ndata.loc[(data.range_of_shot == '24+ ft.')&(data.shot_basics.isnull()), 'shot_basics']            =  pd.Series(data[(data.range_of_shot == '24+ ft.')&(data.shot_basics.isnull())].shot_basics.apply(lambda x: x if type(x)==str else np.random.choice(['Penalty Spot', 'Right Corner', 'Left Corner'],1,p=[0.8932384341637011, 0.06192170818505338, 0.044839857651245554])[0]))\n# if the shot is a back court shot then randomly assign one of the values from''Mid Ground Line', 'Penalty Spot' to shot_basic field\ndata.loc[(data.range_of_shot == 'Back Court Shot')&(data.shot_basics.isnull()), 'shot_basics']    =  pd.Series(data[(data.range_of_shot == 'Back Court Shot')&(data.shot_basics.isnull())].shot_basics.apply(lambda x: x if type(x)==str else np.random.choice(['Mid Ground Line', 'Penalty Spot'],1,p=[0.8441558441558441, 0.15584415584415584])[0]))\ndata.isna().sum()","f1c2baae":"data['shot_basics'].unique() # now we have populated the shot types and reduced the number of missing values. Earlier we had 1575 missing values for this column, now we have only 66.","afeda1be":"# Filling Missing Values In \"range_of_short\" based on \"short_basics\" column!\n\n# if shot_basics is Goal Area, then range of shot is Less Than 8 ft\ndata.loc[(data.shot_basics == 'Goal Area'), 'range_of_shot']       = data[data.shot_basics == 'Goal Area'].range_of_shot.fillna(value='Less Than 8 ft.')\n# if shot_basics is Penalty Spot, then range of shot is  24+ ft.\ndata.loc[(data.shot_basics == 'Penalty Spot'), 'range_of_shot']    = data[data.shot_basics == 'Penalty Spot'].range_of_shot.fillna(value= '24+ ft.')\n# if shot_basics is Right Corner, then range of shot is  24+ ft.\ndata.loc[(data.shot_basics == 'Right Corner'), 'range_of_shot']    = data[data.shot_basics == 'Right Corner'].range_of_shot.fillna(value='24+ ft.')\n# if shot_basics is Left Corner, then range of shot is  24+ ft.\ndata.loc[(data.shot_basics == 'Left Corner'), 'range_of_shot']     = data[data.shot_basics == 'Left Corner'].range_of_shot.fillna(value='24+ ft.')\n# if shot_basics is Mid Ground Line , then range of shot is  Back Court Shot\ndata.loc[(data.shot_basics == 'Mid Ground Line'), 'range_of_shot'] = data[data.shot_basics == 'Mid Ground Line'].range_of_shot.fillna(value='Back Court Shot')\n# if shot_basics is Mid Range then randomly assign '16-24 ft.' or  '8-16 ft.' to range of shot\ndata.loc[(data.shot_basics == 'Mid Range')&(data.range_of_shot.isnull()), 'range_of_shot']       = pd.Series(data[(data.shot_basics == 'Mid Range')&(data.range_of_shot.isnull())].range_of_shot.apply(lambda x: x if type(x)==str else np.random.choice(['16-24 ft.', '8-16 ft.'],1,p=[0.6527708850289495, 0.34722911497105047])[0]))\n# if shot_basics is Goal Line then randomly assign ''8-16 ft.' or  'Less Than 8 ft.' to range of shot\ndata.loc[(data.shot_basics == 'Goal Line')&(data.range_of_shot.isnull()), 'range_of_shot']       = pd.Series(data[(data.shot_basics == 'Goal Line')&(data.range_of_shot.isnull())].range_of_shot.apply(lambda x: x if type(x)==str else np.random.choice(['8-16 ft.', 'Less Than 8 ft.'],1,p=[0.5054360956752839, 0.49456390432471614])[0]))\n\ndata.isnull().sum() # number of missing values for range_of_shot column should have been reduced","005b5206":"data['range_of_shot'].unique() # the number of missing values has fallen from 1564 to 66","9378559b":"# Filling the remaining missing values incase they both have NaN values using the forward fill method\ndata.shot_basics.fillna(method='ffill', inplace=True)\ndata.range_of_shot.fillna(method='ffill', inplace=True)\ndata.isnull().sum() # number of missing values for shot_basics and range_of_shot columns should be zero","47c1e17c":"# Filling the missing value in \"\u00e4rea_of_short\" Column\ndata.area_of_shot.fillna(value='Center(C)', inplace=True) # all the missing values get filled by  'Centre(C)'\ndata.isnull().sum() # number of missing values for area_of_shot column should be zero","08255019":"data['distance_of_shot'].unique()","e79c8e53":"#Filling the Missing values in \"distance_of_shot\"\n# if distance_of_shot isnull randomly assign a value from 20,45,44,37\ndata.loc[data['distance_of_shot'].isnull(), 'distance_of_shot'] = pd.Series(data.loc[data['distance_of_shot'].isnull(), 'distance_of_shot'].apply(lambda x: x if type(x)==str else np.random.choice([20,45,44,37],1,p=[0.5278056615137523,0.18630797028709095,0.14384661714515157,0.1420397510540052])[0])) \ndata.isnull().sum() # number of missing values for distance_of_shot column should be zero","d28f4b62":"\n# Making the train Dataset\ntrain = data[data.is_goal.notnull()]\nprint('the Shape of Train Dataset',train.shape)\ntrain.set_index(np.arange(train.shape[0]),inplace=True)\ntrain.head()\n","1eaf32f4":"# Making the Test Dataset\ntest = data[data.is_goal.isnull()]\nprint('The Shape of Test Dataset',test.shape)\ntest.set_index(np.arange(test.shape[0]), inplace=True)\ntest.head()","6257e205":"l_goal   = train[train.is_goal == 1].type_of_shot.value_counts().head(6).keys()     # Top six shots when it was goal\nl_goal","eea1911b":"p_g_sum  = train[train.is_goal == 1].type_of_shot.value_counts().head(6).sum() # Top six shots when it was goal\np_goal   = (train[train.is_goal == 1].type_of_shot.value_counts().head(6) \/ p_g_sum ).tolist()  # There respective probablities\np_goal","de103f7b":"# if is_goal is 1, if type of shot is a string value, fill with the same or else fill with randomly choosing value from l_goal\ng = pd.Series(train[train.is_goal == 1].type_of_shot.apply(lambda x: x if type(x)==str else np.random.choice(l_goal,1,p=p_goal)[0]))\ng","8fe7f617":"# # if is_goal is 1, if type of shot is null then type of shot becomes equal to the value of g based on the index\ntrain.loc[(train.is_goal == 1)&(train.type_of_shot.isnull()), 'type_of_shot'] = g","3ea0b312":"train['type_of_shot'].isna().sum() # number of missing values got reduced from more than 15k to 6723","e4e6ecad":"l_no_goal   = train[train.is_goal == 0].type_of_shot.value_counts().head(5).keys()     # Top five shots when it was not a goal\np_no_sum  = train[train.is_goal == 0].type_of_shot.value_counts().head(5).sum()\np_no_goal   = (train[train.is_goal == 0].type_of_shot.value_counts().head(5) \/ p_no_sum ).tolist() # There respective probablities \nng = pd.Series(train[train.is_goal == 0].type_of_shot.apply(lambda x: x if type(x)==str else np.random.choice(l_no_goal,1,p=p_no_goal)[0]))\ntrain.loc[(train.is_goal == 0)&(train.type_of_shot.isnull()), 'type_of_shot'] = ng \ntrain['type_of_shot'].isna().sum() # number of missing values got reduced to zero","6c69b69d":"#Handeling the remaing values in test dataset with a smilira approach\ntest.loc[test['type_of_shot'].isnull(), 'type_of_shot'] = pd.Series(test.loc[test['type_of_shot'].isnull(), 'type_of_shot'].apply(lambda x: x if type(x)==str else np.random.choice(['shot - 39', 'shot - 36', 'shot - 4'],1,p=[0.37377133988618727, 0.33419555095706155, 0.2920331091567512])[0])) \n","7de64a18":"test['type_of_shot'].isna().sum() # we have removed the missing values from test set as well","3eca3469":"%%time\n# Labeling the catagories with integers\nfor col in train.columns:\n    if train[col].dtypes == object: # if the column has categorical values\n        l_unique = train[col].unique() # find the unique values\n        v_unique = np.arange(len(l_unique)) # create a list of number from zero to the length of the I_unique values\n        train[col].replace(to_replace=l_unique, value=v_unique, inplace=True) # replace the categorical values with numerical values\n        train[col] = train[col].astype('int') # change the type from int64 to int32\n        \n        # same has been done for test data as well\n        test[col].replace(to_replace=l_unique, value=v_unique, inplace=True)\n        test[col] = test[col].astype('int')\n        ","2749be43":"# Dropping the unnecessary Columns\ntrain.drop(['date_of_game'], axis=1, inplace=True)\ntrain.head()","5e6d70ef":"test.drop(['date_of_game'], axis=1, inplace=True)\ntest.head()","2e558e8f":"# Splliting the Target Column from the Dataset\ny = train.is_goal\ny.head()","3b297043":"train.drop(['is_goal'], axis=1, inplace=True)\ntrain.head()\n","5496088a":"test.drop(['is_goal'], axis=1, inplace=True)\ntest.head()","37974e07":"train.info() # we have converted all the categorical columns to numeric ones","6bbc2b62":"train.isna().sum() ## we have don't have any missing values as well. Our data is ready to be fed to a machine learning model.","3dc1e0aa":"\n\n# B.      Exploratory Data Analysis","f8ac8a45":"#### 3. Handeling Missing Values\n","cba15943":"##### Handeling Missing Values in train and Test Dataset","d9bd8618":"#### Filling the Nan value with a random choice from given list with there appropriate probablities\n","137b5c35":"##### # train and test data are divided based on the vaue of is goal column","75c6978b":"##### \" It's a binary classification problem as there are only two values for the target ''is_goal\" column","21541cbd":"#### and we have applied similar concept for the scenarios when there was no goal","5a996bef":"## Making the Train and Test Dataset","7f76bee1":"#### 2. Checking for Missing Values","48578e47":"###  Label Encoding the Object type Columns","bb7c4581":"#### 1. Exploring the Columns of Dataset","acb5ffac":"# A. Data Preprocessing","9f4b66d6":"#### 1. Dropping unnessary Columns\n"}}