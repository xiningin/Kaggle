{"cell_type":{"a85c8b9e":"code","781007ed":"code","b27d7847":"code","0763d8da":"code","eae55436":"code","657baf2f":"code","ccfec4f2":"code","e33d8d84":"code","69db1bd3":"code","1f41da30":"code","963c4c9f":"code","89f0ddf5":"code","25a0c36e":"code","b59984e3":"code","57901c18":"markdown","cc1afaeb":"markdown","d7d03b37":"markdown","3e7dda8f":"markdown","974cc6f6":"markdown","dd26cebc":"markdown","9c0d7ad6":"markdown","44f5a868":"markdown","56f32851":"markdown","85aed3cb":"markdown","431256fa":"markdown","c18e166a":"markdown"},"source":{"a85c8b9e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import SelectKBest, chi2 # For feature selection\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","781007ed":"!pwd","b27d7847":"print(\"Loading data set......\")\ntrain = pd.read_csv(\"..\/input\/learn-together\/train.csv\")\ntest = pd.read_csv(\"..\/input\/learn-together\/test.csv\")\nprint(\"Done...\")","0763d8da":"print(\"train data size:\", train.shape)\ntrain.head()","eae55436":"print(\"test data size:\", test.shape)\ntest.head()","657baf2f":"train.info()","ccfec4f2":"train.describe().T","e33d8d84":"# Declare target and predictors\nprint(\"Selecting features and target columns for model\")\ntarget = train['Cover_Type']\ntrain_df = train.drop([\"Cover_Type\", \"Id\", \"Vertical_Distance_To_Hydrology\"], axis=1)\ntest_df = test.drop([\"Id\", \"Vertical_Distance_To_Hydrology\"], axis=1)\n","69db1bd3":"train_df.shape, test_df.shape","1f41da30":"# Feature  selection\n\nbest = SelectKBest(chi2, k=25).fit(train_df, target)\ntrain_best = best.transform(train_df)\ntest_best = best.transform(test_df)","963c4c9f":"# Create Model\nprint(\"Creating model\")\nrf = RandomForestClassifier(n_estimators=100)\nprint(\"Model created\")\n","89f0ddf5":"print(\"Cross vaidation Score\")\nprint(cross_val_score(rf,train_best, target, cv=3, scoring=\"accuracy\" ))\n","25a0c36e":"print(\"Fitting Model on training data set.....\")\n# Fit Model to traing data\nrf.fit(train_best, target)\nprint(\"Predict on test data set....\")\ntest_pred = rf.predict(test_best)\n\n","b59984e3":"# Save test predictions to file\nprint(\"Creating submission file\")\noutput = pd.DataFrame({'Id': test.Id,'Cover_Type': test_pred})\noutput.to_csv('submission_rf_1.csv', index=False)\n","57901c18":"### Load Data Set","cc1afaeb":"To select best features for our model, we wil use \"SelectKBest\" module from sklearn feature selection.\nSince our target column is categorical, we will use \"chi2\" as parameter for \"SelectKbest\".","d7d03b37":"### Exploratory Data Analysis","3e7dda8f":"### Import Required Libraries","974cc6f6":"### Create Model","dd26cebc":"### Create Submission File","9c0d7ad6":"We are using RandomForestClassifier algorithm for our model","44f5a868":"### Cross validation of the model","56f32851":"### Feature Selection\n\nIn this model, we are not going to make much feature engineering. We will make model by using the available features. There are some negative values in \"Vertical_Distance_To_Hydrology\" column. SO we will drop this column along with \"Id\" column. \"Id\"column is not required for our model.","85aed3cb":"### Further work\n* More accurate model can be created using features engineering.\n* For better performance of this model, Parameter tuning is advised.\n","431256fa":"## Basic Random Forets Classifier\n**The challenge:**\n\nIn this competition you\u2019ll predict what types of trees there are in an area based on various geographic features.\n\nThe competition datasets comes from a study conducted in four wilderness areas within the beautiful Roosevelt National Forest of northern Colorado. These areas represent forests with very little human disturbances \u2013 the existing forest cover types there are more a result of ecological processes rather than forest management practices.\nThe data is in raw form and contains categorical data such as wilderness areas and soil type.","c18e166a":"### Fit Model and Predict"}}