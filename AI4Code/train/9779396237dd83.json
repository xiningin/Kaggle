{"cell_type":{"043ae2da":"code","96027715":"code","ee5aaa4f":"code","fd65dd4f":"code","f0297753":"code","0d6bbc4c":"code","55fd7714":"code","770df192":"code","1ee34480":"code","61e1c75a":"code","59eead69":"code","7269fbab":"code","b2053f0a":"code","e390b84f":"code","e5539ee4":"code","8e099932":"code","c66ec8e4":"code","0f84cf17":"code","116bca83":"code","bbc04cfa":"code","898d2f6d":"markdown","fb073f1d":"markdown","cdde3c92":"markdown","a35f9da7":"markdown"},"source":{"043ae2da":"pip install imutils","96027715":"\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom imutils import paths\nimport argparse\nimport imutils\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ee5aaa4f":"def image_to_feature_vector(image, size=(32, 32)):\n    # resize the image to a fixed size, then flatten the image into\n    # a list of raw pixel intensities\n    return cv2.resize(image, size).flatten()","fd65dd4f":"def extract_color_histogram(image, bins=(8, 8, 8)):\n    # extract a 3D color histogram from the HSV color space using\n    # the supplied number of `bins` per channel\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins,[0, 180, 0, 256, 0, 256])\n    \n    if imutils.is_cv2():\n        hist = cv2.normalize(hist)\n    \n    else:\n        cv2.normalize(hist, hist)\n    # return the flattened histogram as the feature vector\n    return hist.flatten()","f0297753":"imagePaths = []\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/'):\n    for filename in filenames:\n        if (filename[-3:] == 'png'):\n            imagePaths.append(os.path.join(dirname, filename))","0d6bbc4c":"image = cv2.imread(imagePaths[0])\nprint(image.shape)\nplt.imshow(image)\nplt.show()","55fd7714":"rawImages = []\nfeatures = []\nlabels = []\nimg=[]\n\nfor imagePath in imagePaths:\n    label = imagePath.split(os.path.sep)[-2]\n    image = cv2.imread(imagePath)\n    # extract raw pixel intensity \"features\", followed by a color\n    # histogram to characterize the color distribution of the pixels\n    # in the image\n    pixels = image_to_feature_vector(image)\n    hist = extract_color_histogram(image)\n    rawImages.append(pixels)\n    features.append(hist)\n    labels.append(label)\n    img.append(image)\n   \nprint(labels[0])","770df192":"rawImages = np.array(rawImages)\nfeatures = np.array(features)\nlabels = np.array(labels)\nprint(\"[INFO] pixels matrix: {:.2f}MB\".format(rawImages.nbytes \/ (1024 * 1000.0)))\nprint(\"[INFO] features matrix: {:.2f}MB\".format(features.nbytes \/ (1024 * 1000.0)))","1ee34480":"# splitting the data into training and testing splits, 75% for train and 25% for test\n(trainRI, testRI, trainRL, testRL) = train_test_split(rawImages, labels, test_size=0.25)\n(trainFeat, testFeat, trainLabels, testLabels) = train_test_split(features, labels, test_size=0.25)\n","61e1c75a":"print(trainRI.shape)\nprint(trainRL.shape)\nprint(testRI.shape)\nprint(testRL.shape)","59eead69":"from sklearn.model_selection import StratifiedKFold\nfrom statistics import mean\nfrom sklearn.metrics import *\nfrom sklearn import metrics\naccavg=[]\nrecavg=[]\nstratifiedcv= StratifiedKFold()\nstratifiedcv.get_n_splits(rawImages, labels)\nneighborsmatrix=[1,3,5,10,25]\nfor n in neighborsmatrix:\n    accraw2=[]\n    recraw2=[]\n    for train_ix, test_ix in stratifiedcv.split(rawImages, labels):\n        trainRI2, testRI2 = rawImages[train_ix], rawImages[test_ix]\n        trainRL2, testRL2 = labels[train_ix], labels[test_ix]\n       \n        model2 = KNeighborsClassifier(n_neighbors=n)\n        model2.fit(trainRI2, trainRL2)\n        acc = model2.score(testRI2, testRL2)\n        yhat=model2.predict(testRI2)\n        accround=round(acc,2)\n        \n        #print(\"Raw pixel accuracy is: {:.2f}%\".format(acc * 100))\n        #print(accraw2)\n        accuracy=accuracy_score(testRL2, yhat)\n        recall= recall_score(testRL2, yhat, average='macro')\n        recraw2.append(recall*100)\n        accraw2.append(accuracy*100)\n        #precision=precision_score(testRL2, yhat)\n        #recall=recall_score(testRL2, yhat)\n        #f1=f1_score(testRL2, yhat)\n        #print(\"for neighbours = \", n)\n        #print(\"accuracy = \", accuracy, \"precision = \", precision, \"recall = \", recall, \"f1-measure = \", f1)\n        #print(metrics.classification_report(testRL2, yhat, digits=3))\n    avg=mean(accraw2)\n    accavg.append(avg)\n    recavg.append(mean(recraw2))\nprint(accavg)\nprint(recavg)\n","7269fbab":"figx = plt.figure(figsize =(9, 6))\nplt.plot(neighborsmatrix,accavg)\nplt.xlabel('neighbors')\nplt.ylabel('average accuracies')\nplt.title('Raw pixel accuracy wrt different K values ')\nplt.show()","b2053f0a":"figx2 = plt.figure(figsize =(9, 6))\nplt.plot(neighborsmatrix,recavg)\nplt.xlabel('neighbors')\nplt.ylabel('average recall in %')\nplt.title('Raw pixel recall wrt different K values ')\nplt.show()","e390b84f":"accraw=[]\nneighborsmatrix=[1,3,5,10,25]\nfor n in neighborsmatrix:\n    model = KNeighborsClassifier(n_neighbors=n)\n    model.fit(trainRI, trainRL)\n    acc = model.score(testRI, testRL)\n    accround=round(acc,2)\n    accraw.append(accround)\n    print(\"Raw pixel accuracy is: {:.2f}%\".format(acc * 100))","e5539ee4":"fig1 = plt.figure(figsize =(9, 6))\nplt.plot(neighborsmatrix,accraw)\nplt.xlabel('neighbors')\nplt.ylabel('accuracies')\nplt.title('Raw pixel accuracy wrt different K values ')\nplt.show()\n#plt.plot(neighborsmatrix,accraw)","8e099932":"accavg2=[]\nrecavg2=[]\nstratifiedcv= StratifiedKFold()\nstratifiedcv.get_n_splits(features, labels)\nfor n in neighborsmatrix:\n    acchist2=[]\n    rechist2=[]\n    for train_ix, test_ix in stratifiedcv.split(features, labels):\n        trainFeat2, testFeat2 = features[train_ix], features[test_ix]\n        trainLabels2, testLabels2 = labels[train_ix], labels[test_ix]\n        model3 = KNeighborsClassifier(n_neighbors=n)\n        model3.fit(trainFeat2, trainLabels2)\n        acc = model3.score(testFeat2, testLabels2)\n        yhat=model3.predict(testFeat2)\n        accuracy=accuracy_score(testLabels2, yhat)\n        recall= recall_score(testLabels2, yhat, average='macro')\n        rechist2.append(recall*100)\n        acchist2.append(accuracy*100)\n        \n    avg=mean(acchist2)\n    accavg2.append(avg)\n    recavg2.append(mean(rechist2))\nprint(accavg2)\nprint(recavg2)","c66ec8e4":"figy = plt.figure(figsize =(9, 6))\nplt.plot(neighborsmatrix,accavg2)\nplt.xlabel('neighbors')\nplt.ylabel('average accuracies')\nplt.title('Histogram accuracy wrt different K values ')\nplt.show()","0f84cf17":"figy2 = plt.figure(figsize =(9, 6))\nplt.plot(neighborsmatrix,recavg2)\nplt.xlabel('neighbors')\nplt.ylabel('average recall in %')\nplt.title('Histogram recall wrt different K values ')\nplt.show()","116bca83":"acchist=[]\nneighborsmatrix=[1,3,5,10,25]\nfor n in neighborsmatrix:\n    model = KNeighborsClassifier(n_neighbors=n)\n    model.fit(trainFeat, trainLabels)\n    acc = model.score(testFeat, testLabels)\n    accround=round(acc,2)\n    acchist.append(accround)\n    print(\"Histogram accuracy is : {:.2f}%\".format(acc * 100))","bbc04cfa":"fig2 = plt.figure(figsize =(9, 6))\nplt.plot(neighborsmatrix,acchist)\nplt.xlabel('neighbors')\nplt.ylabel('accuracies')\nplt.title('Histogram accuracy wrt different K values ')\nplt.show()","898d2f6d":"**Raw pixel accuracies without 5 fold cross validation**","fb073f1d":"**KNN Approach**","cdde3c92":"The following part of processing the images where the images are flattened and converted to color histograms are referred from the document \"https:\/\/www.pyimagesearch.com\/2016\/08\/08\/k-nn-classifier-for-image-classification\/\". This link has been pu in the references of our paper.","a35f9da7":"Histogram accuracies without using 5-fold cross validation"}}