{"cell_type":{"d6ea2d39":"code","ab2bed07":"code","7df88783":"code","6ec12db0":"code","f156bb06":"code","11ac3a18":"code","88a07f1a":"code","cdb16ecb":"code","e258b35a":"code","c4b0b7fb":"code","a7e99df5":"code","05b6460d":"code","dc3f2de6":"code","0d95442b":"code","44368066":"code","b3218703":"code","cd2d961f":"code","39f4a068":"code","5ae78388":"code","99796230":"code","6318515b":"code","b125c390":"code","258885bc":"markdown"},"source":{"d6ea2d39":"from fastai.vision import *\nimport os\n\npath = Path(\"..\/input\/samples\/samples\")\nprint(os.listdir(path)[:10])","ab2bed07":"def plot_lr(learn):\n    lr_find(learn)\n    learn.recorder.plot()","7df88783":"def char_from_path(path, position):\n    return path.name[position]","6ec12db0":"data = (ImageList.from_folder(path) #Where to find the data? -> in path and its subfolders\n        .split_by_rand_pct(0.2)              #How to split in train\/valid? -> use the folders\n        .label_from_func(partial(char_from_path, position=0))            #How to label? -> depending on the folder of the filenames\n        .transform(get_transforms(do_flip=False))       #Data augmentation? -> use tfms with a size of 64\n        .databunch())                   #Finally? -> use the defaults for conversion to ImageDataBunch","f156bb06":"data.show_batch(3, figsize=(10,10))","11ac3a18":"learn = cnn_learner(data, models.resnet34, metrics=accuracy, model_dir='\/tmp', ps=0.)","88a07f1a":"plot_lr(learn)","cdb16ecb":"lr = 5e-2\nlearn.fit_one_cycle(5, lr)","e258b35a":"learn.save('pretrained')","c4b0b7fb":"learn.load('pretrained')\nlearn.unfreeze()","a7e99df5":"plot_lr(learn)","05b6460d":"learn.fit_one_cycle(15, slice(5e-4, lr\/5))","dc3f2de6":"interp = ClassificationInterpretation.from_learner(learn)","0d95442b":"interp.plot_confusion_matrix(figsize=(7,7))","44368066":"interp.plot_top_losses(4, heatmap_thresh=14, largest=False)","b3218703":"def data_from_position(position):\n    data = (ImageList.from_folder(path) #Where to find the data? -> in path and its subfolders\n        .split_by_rand_pct(0.2)              #How to split in train\/valid? -> use the folders\n        .label_from_func(partial(char_from_path, position=position))            #How to label? -> depending on the folder of the filenames\n        .transform(get_transforms(do_flip=False))       #Data augmentation? -> use tfms with a size of 64\n        .databunch())                   #Finally? -> use the defaults for conversion to ImageDataBunch\n    return data","cd2d961f":"learners = []\nfor i in range(5):\n    data = data_from_position(i)\n    \n    learn = cnn_learner(data, models.resnet34, metrics=accuracy, model_dir='\/tmp', ps=0.)\n    \n    lr = 5e-2\n    learn.fit_one_cycle(5, lr)\n    \n    learn.unfreeze()\n    learn.fit_one_cycle(15, slice(5e-4, lr\/5))\n    \n    learners.append(learn)","39f4a068":"figures = []\nfor learner in learners:\n    figures.append(learner.interpret().plot_top_losses(4, heatmap_thresh=14, figsize=(8,8), largest=False, return_fig=True))","5ae78388":"for e,f in enumerate(figures):\n    f.suptitle('')\n    for a in f.axes: a.set_title(f'Position: {e+1}')\n    f.savefig(f'{e}_heatmap.png', bbox_inches='tight')","99796230":"def predict_captcha(img, learners):\n    return ''.join([str(learner.predict(img)[0]) for learner in learners])","6318515b":"fig, ax = plt.subplots(ncols=5, figsize=(20,10))\nfor a, (img, lbl) in zip(ax.flatten(), learners[0].data.valid_ds):\n    show_image(img, a)\n    a.set_title(f'predicted: {predict_captcha(img, learners)}')\nplt.show()","b125c390":"img_paths = learners[0].data.valid_ds.items\ncount = 0\ncorrect = 0\n\nfor img_path in img_paths:\n    lbl = img_path.name[:-4]\n    img = open_image(img_path)\n    predicted = predict_captcha(img, learners)\n    if lbl==predicted: correct +=1\n    count += 1\ncorrect\/count","258885bc":"[This](https:\/\/medium.com\/@oneironaut.oml\/solving-captchas-with-deeplearning-part-2-single-character-classification-ac0b2d102c96) blog post explains what's going in in this kernel."}}