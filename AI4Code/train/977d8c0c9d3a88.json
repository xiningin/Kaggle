{"cell_type":{"2042b132":"code","6f8fef97":"code","37374ca1":"code","5f4e218d":"code","10f7b0a9":"code","69e9a4ce":"code","72e9c7a5":"code","3e1f0fa5":"code","8595cabb":"code","a7db6932":"code","bc385b0f":"code","d9243372":"code","90fa9651":"code","9af6ab72":"code","d3bbd52d":"code","efae8101":"code","61fc1fa2":"code","efe07856":"code","32c5d9ae":"code","88a3fb09":"code","c939697e":"code","2ebb2a3a":"code","30b90a7f":"markdown","7f4ce8ce":"markdown","252a7077":"markdown","7aac92ed":"markdown","9588460d":"markdown","b76bf273":"markdown","b8764fda":"markdown","9f479ec6":"markdown"},"source":{"2042b132":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6f8fef97":"import matplotlib.pyplot as plt\nimport scipy\nimport sys\nimport os\nimport pickle\nimport librosa\nimport librosa.display\nfrom IPython.display import Audio\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","37374ca1":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers\nimport keras\nfrom keras.models import Sequential","5f4e218d":"audio_data = '..\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\/classical\/classical.00026.wav'\ndata , sr = librosa.load(audio_data)\nprint(type(data), type(sr))","10f7b0a9":"librosa.load(audio_data, sr=45600)","69e9a4ce":"import IPython\nIPython.display.Audio(data,rate=sr)","72e9c7a5":"plt.figure(figsize=(14,6))\nlibrosa.display.waveplot(data)\nplt.show()","3e1f0fa5":"X = librosa.stft(data)\namp = librosa.amplitude_to_db(abs(X))\nplt.figure(figsize=(14,6))\nlibrosa.display.specshow(amp,sr=sr,x_axis='time',y_axis='hz')\nplt.colorbar()","8595cabb":"plt.figure(figsize=(14, 6))\nlibrosa.display.specshow(amp, sr=sr, x_axis='time', y_axis='log')\nplt.colorbar()","a7db6932":"from sklearn.preprocessing import normalize\n\nspectral_rolloff = librosa.feature.spectral_rolloff(data+0.01, sr=sr)[0]\nplt.figure(figsize=(14, 6))\nlibrosa.display.waveplot(data, sr=sr, alpha=0.4)","bc385b0f":"plt.figure(figsize=(14, 6))\nlibrosa.display.waveplot(data, sr=sr)","d9243372":"n_0 = 9000\nn_1 = 9100\n\nzc = librosa.zero_crossings(data[n_0:n_1], pad=False)\nprint(\"The number of zero-crossings is :\",sum(zc))\n\nplt.figure(figsize=(14,6))\nplt.plot(data[n_0:n_1])\nplt.grid()","90fa9651":"df1 = pd.read_csv('..\/input\/gtzan-dataset-music-genre-classification\/Data\/features_3_sec.csv')\ndf1.head()","9af6ab72":"print(df1.shape)\nprint(df1.dtypes)","d3bbd52d":"df1 = df1.drop(labels='filename',axis=1)","efae8101":"genre_list = df1.iloc[:, -1]\nencoder = LabelEncoder()\ny = encoder.fit_transform(genre_list)\nprint(y)","61fc1fa2":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX = scaler.fit_transform(np.array(df1.iloc[:, :-1], dtype = float))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)","efe07856":"m = Sequential()\nm.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\nm.add(layers.Dense(128, activation='relu'))\nm.add(layers.Dense(64, activation='relu'))\nm.add(layers.Dense(10, activation='softmax'))\nm.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","32c5d9ae":"classifier = m.fit(X_train,y_train,epochs=100,batch_size=128)","88a3fb09":"loss, acc  = m.evaluate(X_test, y_test, batch_size=128)\nprint('Loss = ',loss,'Accuracy = ',acc)\n","c939697e":"history = m.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=50,batch_size=32)","2ebb2a3a":"fig,axs = plt.subplots(2)\naxs[0].plot(history.history[\"accuracy\"],label=\"train accuracy\")\naxs[0].plot(history.history[\"val_accuracy\"],label=\"test accuracy\")\naxs[0].set_ylabel(\"Accuracy\")\naxs[0].legend(loc='lower right')\naxs[0].set_title(\"Accuracy eval\")\n    \naxs[1].plot(history.history[\"loss\"],label=\"train error\")\naxs[1].plot(history.history[\"val_loss\"],label=\"test error\")\naxs[1].set_ylabel(\"Error\")\naxs[1].set_xlabel(\"Epoch\")\naxs[1].legend(loc='upper right')\nplt.show()","30b90a7f":"Playing audio","7f4ce8ce":"### Using validation set","252a7077":"### Accuracy","7aac92ed":"## Neural networks","9588460d":"## Visualization","b76bf273":"### Zero crossing","b8764fda":"## CNN","9f479ec6":"### Classification"}}