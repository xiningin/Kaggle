{"cell_type":{"3686a57e":"code","74819e59":"code","dd7afcc8":"code","5a21e2f1":"code","db5622a0":"code","f010720b":"code","8435c763":"code","5c8ffb27":"code","fa0010e6":"code","8d58cfb0":"code","f7a69e2a":"code","19dfe59b":"code","3687ba52":"code","028302f7":"code","4a10483e":"code","5420762c":"markdown"},"source":{"3686a57e":"#Importing Libraries \n\nimport pandas as pd\nimport numpy as np\nimport re          #regular expression\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter(\"ignore\")","74819e59":"data = pd.read_csv(\"..\/input\/language-detection\/Language Detection.csv\")\ndata.head(10)","dd7afcc8":"data[\"Language\"].value_counts() #value_counts() is used to get a Series containing counts of unique values. ","5a21e2f1":"#Separating Independent and Dependent features\nX = data[\"Text\"]\ny = data[\"Language\"]\n\n#Label Encoding to convert it into a numerical form\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)","db5622a0":"data_list = []\n\n# iterating through all the text\nfor text in X:         \n    text = re.sub(r'[!@#$(),n\"%^*?:;~`0-9]', ' ', text)      # removing the symbols and numbers\n    text = re.sub(r'[[]]', ' ', text)   \n    text = text.lower()          # converting the text to lower case\n    data_list.append(text)       # appending to data_list","f010720b":"#Bag of Words [ converting text into numerical form by creating a Bag of Words model using CountVectorizer.]\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer() # tokenize a collection of text documents\nX = cv.fit_transform(data_list).toarray()\nX.shape # (10337, 39419)","8435c763":"#train-test split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=42)","5c8ffb27":"# Model Training\nfrom sklearn.naive_bayes import MultinomialNB  #classifier is suitable for classification with discrete features\nmodel = MultinomialNB()\nmodel.fit(x_train, y_train)","fa0010e6":"#predict output for test dataset\ny_pred = model.predict(x_test)","8d58cfb0":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nac = accuracy_score(y_test, y_pred)\ncm = confusion_matrix(y_test, y_pred)","f7a69e2a":"print(\"Accuracy is :\",ac)","19dfe59b":"plt.figure(figsize=(15,10))\nsns.heatmap(cm, annot = True)\nplt.show()","3687ba52":"#Predicting with some more data\n\ndef predict(text):\n     x = cv.transform([text]).toarray() # converting text to bag of words model (Vector)\n     lang = model.predict(x) # predicting the language\n     lang = le.inverse_transform(lang) # finding the language corresponding the the predicted value\n     print(\"The langauge is in\",lang[0]) # printing the language","028302f7":"predict('People are awesome')","4a10483e":"predict('\u0d28\u0d7d\u0d15\u0d41\u0d28\u0d4d\u0d28\u0d41')","5420762c":"TEXT PREPROCESSING"}}