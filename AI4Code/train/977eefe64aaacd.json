{"cell_type":{"f6e5b94b":"code","37c008e4":"code","9e5cd40c":"code","10ecf7d3":"code","4dcb4c76":"code","7f88a613":"code","52cc620d":"code","658a2d59":"code","13831b9a":"code","e8e299fa":"code","fddb918a":"code","26d1481b":"code","313c05ba":"code","ced1e790":"code","0662f039":"code","15e28e35":"code","a4940334":"code","ab42e254":"code","b4a8f705":"code","800c4826":"code","59440ce3":"code","b6f0ec12":"code","341edbce":"code","d00d2d1c":"code","174d5468":"code","a4b7abf5":"code","23a6544f":"code","42362f20":"code","3f4b2437":"code","af99357c":"code","7a3bf4e1":"code","2d0a67b0":"code","1fddff9a":"code","26253fea":"code","d95e68c5":"code","62356e5e":"code","aa9afcd8":"code","c56143bd":"code","ea26eb8a":"code","2c575723":"code","246ec481":"code","de9c8912":"code","e0374ce5":"markdown","b447b8b8":"markdown","0201e433":"markdown","d73bb2f2":"markdown","9f3b54a8":"markdown","aaf38008":"markdown","ecf39e89":"markdown","6cf13747":"markdown","8e80c65c":"markdown","f95caf33":"markdown"},"source":{"f6e5b94b":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import KFold\nfrom matplotlib import pyplot as plt\nimport xgboost as xgb\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport shap\nimport math\n%matplotlib inline\n\n","37c008e4":"#data import \ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ntrain=pd.DataFrame(train)\ntest=pd.DataFrame(test)\ndata_test=pd.read_csv('..\/input\/titanic\/test.csv')\n\nprint(\"Shape of the train set is\", train.shape, \" and the shape of the test is \",test.shape)","9e5cd40c":"train.head(10)","10ecf7d3":"test.head(10)","4dcb4c76":"train.info()\n","7f88a613":"#correlation matrix traces how variables are related to each other\n#This will give an idea how to empute missing variable without dropping col\nsns.heatmap(train.corr(), annot=True, cmap=\"coolwarm\")\nplt.show()","52cc620d":"#drop PassengerId ,Ticket columns\ntrain.drop(['PassengerId', 'Ticket','Name'], axis=1, inplace=True)\ntest.drop(['PassengerId', 'Ticket', 'Name'], axis=1, inplace=True)\ntrain.shape, test.shape","658a2d59":"train.info()","13831b9a":"train.describe()","e8e299fa":"#Missing columns\ncols_with_missing_train = train.isnull().sum()\nprint(\"Training set columns with missing values are :\\n\", cols_with_missing_train[cols_with_missing_train>0])\n\ncols_with_missing_test = test.isnull().sum()\nprint(\"\\n\\n Test set columns with missing values are :\\n\", cols_with_missing_test[cols_with_missing_test>0])\n\nprint(\"\\n\\n Mean of survived passengers:\\n\",train[\"Survived\"].mean())","fddb918a":"#Suvived by Age \nax = sns.boxplot(x=\"Survived\", y=\"Age\", \n                data=train)\nax = sns.stripplot(x=\"Survived\", y=\"Age\",\n                   data=train, jitter=True,\n                   edgecolor=\"gray\")\nplt.title(\"Suvived by Age in training data\")","26d1481b":"sns.countplot('Pclass',hue='Survived',data=train)\nplt.show()","313c05ba":"#Corelation between Age and Parch\nsns.boxplot(x='Parch',y='Age', data=train, palette='hls')\nplt.title(\"Age % Parch in training data\")","ced1e790":"sns.boxplot(x='Parch',y='Age', data=test, palette='hls')\nplt.title(\"Age % Parch in test data\")\n#Mean age % parch is due to the correlation between Age and Parch\nprint(\"Correlation between Age and Parch \\n\",train.corr()[\"Age\"].sort_values(ascending = False))\n\nmean_age_train=train.groupby(['Parch'])['Age'].mean()\nmean_age_test= test.groupby(['Parch'])['Age'].mean()      ","0662f039":"#Imputer function to fill age using mean  on Parch\ndef fill_age(data,mean_age):\n    for i in data['Age'].index:\n        if (math.isnan(data['Age'][i])):\n            if (data['Parch'][i]==0): \n                data['Age'][i]=mean_age[0]\n            if (data['Parch'][i]==1): \n                data['Age'][i]=mean_age[1]\n            if (data['Parch'][i]==2): \n                data['Age'][i]=mean_age[2]\n            if (data['Parch'][i]==3): \n                data['Age'][i]=mean_age[3]\n            if (data['Parch'][i]==4): \n                data['Age'][i]=mean_age[4]\n            if (data['Parch'][i]==5): \n                data['Age'][i]=mean_age[5]\n            if (data['Parch'][i]==6): \n                data['Age'][i]=mean_age[6]\n            data['Age'][i]=mean_age[6]\n    return data","15e28e35":"fill_age(train,mean_age_train)\nfill_age(test,mean_age_test)","a4940334":"#Embarked has missing values lets observe how it moves?\ntrain[train['Embarked'].isnull()]","ab42e254":"sns.boxplot(x=\"Embarked\", y=\"Fare\", hue=\"Pclass\", data=train)","b4a8f705":"#Fill Embarked with C\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna('C')","800c4826":"#Categorical to numerical Embarked in train\/test\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nEnc=LabelEncoder()\ntrain[\"Embarked\"]=Enc.fit_transform(train[\"Embarked\"])\ntest[\"Embarked\"]=Enc.fit_transform(test[\"Embarked\"])\ntrain.head()","59440ce3":"test.head()","b6f0ec12":"#Cabin feature are missing a lot of values in both training and test datasets\ntrain[\"Cabin\"].isnull().sum(),test[\"Cabin\"].isnull().sum()\ntrain[\"Cabin\"].unique()","341edbce":"train['Part']=train['Cabin'].str[0]\ntest['Part']=test['Cabin'].str[0]\ntrain.drop(['Cabin'],axis=1, inplace=True)\ntest.drop(['Cabin'],axis=1, inplace=True)\ntrain.head()","d00d2d1c":"sns.boxplot(x=\"Part\", y=\"Fare\",  data=train)","174d5468":"train.isnull().sum()","a4b7abf5":"train['Part'].unique()\n","23a6544f":"#Fill Part with random choices\ntrain[\"Part\"] = train['Part'].fillna((pd.Series(np.random.choice(['C', 'E', 'G', 'D', 'A', 'B', 'F', 'T'], size=len(train.index)))))\n","42362f20":"test['Part'].unique()","3f4b2437":"#Fill Part with random choices\ntest[\"Part\"] = test['Part'].fillna((pd.Series(np.random.choice([ 'B', 'E', 'A', 'C', 'D', 'F', 'G'], size=len(test.index)))))\n#Categorical to numerical Part\ntrain[\"Part\"]=Enc.fit_transform(train[\"Part\"])\ntest[\"Part\"]=Enc.fit_transform(test[\"Part\"])","af99357c":"#convert Sex from categorical to numeric\ntrain['Sex'].replace(['male','female'],[0,1],inplace=True)\ntest['Sex'].replace(['male','female'],[0,1],inplace=True)","7a3bf4e1":"#Test Fare missing value \ntest[test['Fare'].isnull()]","2d0a67b0":"#We can replace missing value in Fare by taking median of all fares of those passengers who share 3rd Passenger class\nmedian_fare=test[(train['Pclass'] == 3)]['Fare'].median()\nmedian_fare\ntest[\"Fare\"] = test[\"Fare\"].fillna(median_fare)","1fddff9a":"from sklearn import preprocessing\n\n\n#convert Age from float to Int\ntrain['Age'] = train['Age'].astype(int)\ntest['Age']    = test['Age'].astype(int)\n\n\nstd_scale = preprocessing.StandardScaler().fit(train[['Age', 'Fare']])\ntrain[['Age', 'Fare']] = std_scale.transform(train[['Age', 'Fare']])\n\n\nstd_scale = preprocessing.StandardScaler().fit(test[['Age', 'Fare']])\ntest[['Age', 'Fare']] = std_scale.transform(test[['Age', 'Fare']])","26253fea":"#train.drop(['Part'], axis=1, inplace=True)\n#test.drop(['Part'], axis=1, inplace=True)\ntrain.head()\n","d95e68c5":"\ntest.head()\n","62356e5e":"y_train = train[\"Survived\"]\nX_train = train.drop(\"Survived\",axis=1)\nX_test=test","aa9afcd8":"X_train.shape , y_train.shape, X_test.shape","c56143bd":"X_train.head()","ea26eb8a":"from sklearn.linear_model import LogisticRegression\nLinaer_reg = LogisticRegression()\nLinaer_reg.fit(X_train,y_train)\npredictions = Linaer_reg.predict(X_test)\nLR_score= Linaer_reg.score(X_train, y_train)\n","2c575723":"predictions\n","246ec481":"data_test","de9c8912":"\noutput = pd.DataFrame({'PassengerId': data_test['PassengerId'], 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)","e0374ce5":"Observation:\n\n1-Most survived have median age 28 (young are more lucky to survive)!!!","b447b8b8":"* #Data analysis & cleansing\n\n","0201e433":"Feature engineering: create a new feature that contain only the cabine partition (C23 is in the C partition)\n","d73bb2f2":"#After data exploring and analysing we have to split the data into train and validation\n","9f3b54a8":"Features are as follows:\n\nPassengerId  :  numerical: does not correlate with the rest of data and can be removed\/ not useful\n\nSurvived   :   can serve as label Y_train\n\nPclass     :    numerical: Passenger class \n\nName      :     categorical: Passenger's name\n\nSex       :     categorical: Passenger's sex\n\nAge        :   numerical:   Passenger's age\n\nSibSp      :    numerical: Number of siblings ans spouses Sibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nParch      :    numerical: Number of children\n\nTicket     :    categorical: The ticket id.\n\nFare      :    numerical: The ticket cost.\n\nCabin      :    categorical: the cabin number\n\nEmbarked    :   categorical: port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)' \n\n\nAccording to this description some feature seem to be unusful for such as PassengerId ,Ticket. These two variables does not correlate with the rest of variables. It is important to drop them.\n","aaf38008":"**Introduction**\n\n\n\nPredictive analysis: the main objective is predict the survival passengers from the Well-Known Titanic shipwreck.\nTwo datasets include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\nTrain.csv file contains the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the \u201cground truth\u201d.\n\nThe `test.csv` dataset contains similar information but does not disclose the \u201cground truth\u201d for each passenger. It\u2019s your job to predict these outcomes.\n\n","ecf39e89":"It can be observed that When  Pclass=1 and MEDIAN passes through fare=80 ====>>  Embarked tends to be  ~ C","6cf13747":"#Both passengers have Embarked missing values while having Pclass=1 and fare=80, lets observe Embarked according to these values\n","8e80c65c":"#Logistic regression \n","f95caf33":"Only 38% of passengers survived."}}