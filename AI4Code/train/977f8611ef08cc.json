{"cell_type":{"0b26e075":"code","f87c8d1e":"code","6bb4cc20":"code","46c2136d":"code","f6419c25":"code","a441de1b":"code","5a9f5368":"code","2564763f":"code","83829538":"code","bddeb851":"code","90557da4":"code","2a31c2d2":"code","b7bd22e2":"code","4db8b88d":"code","a8b0e5fb":"code","ab09d344":"code","a3b6cf04":"code","6a55ae40":"markdown","9e54f844":"markdown","6111f3cc":"markdown","0703ce57":"markdown","4cb5a6c5":"markdown","51159658":"markdown","ed40e9c5":"markdown"},"source":{"0b26e075":"package_paths = [\n    '..\/input\/pytorch-image-library\/pytorch-image-models-master\/pytorch-image-models-master',\n]\nimport sys;\n\nfor pth in package_paths:\n    sys.path.append(pth)\n\nimport timm","f87c8d1e":"import pandas as pd\nimport numpy as np\nimport cv2\nimport torch\nimport torch.nn as nn\nimport albumentations as A\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom albumentations.core.composition import Compose, OneOf\nfrom albumentations.augmentations.transforms import CLAHE, GaussNoise, ISONoise\nfrom albumentations.pytorch import ToTensorV2\n\nfrom pytorch_lightning import Trainer, seed_everything\nfrom pytorch_lightning import Callback\nfrom pytorch_lightning.loggers import CSVLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n\nfrom sklearn.model_selection import StratifiedKFold","6bb4cc20":"class CFG:\n    seed = 42\n    model_name = 'resnet50'\n    pretrained = False\n    img_size = 512\n    num_classes = 12\n    batch_size = 32\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","46c2136d":"PATH = \"..\/input\/plant-pathology-2021-fgvc8\/\"\nTEST_DIR = PATH + 'test_images\/'","f6419c25":"seed_everything(CFG.seed)","a441de1b":"df_all = pd.read_csv(PATH + \"train.csv\")\nlabels = list(df_all['labels'].value_counts().keys())\nlabels_dict = dict(zip(labels, range(12)))","5a9f5368":"sub = pd.read_csv(PATH + \"sample_submission.csv\")\nsub.head()","2564763f":"class PlantDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.image_id = df['image'].values\n        self.labels = df['labels'].values\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        image_id = self.image_id[idx]\n        label = self.labels[idx]\n        \n        image_path = TEST_DIR + image_id\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        augmented = self.transform(image=image)\n        image = augmented['image']\n        return {'image':image, 'target': label}","83829538":"def get_transform(phase: str):\n    if phase == 'train':\n        return Compose([\n            A.RandomResizedCrop(height=CFG.img_size, width=CFG.img_size),\n            A.HorizontalFlip(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n            A.RandomBrightnessContrast(p=0.5),\n            A.Normalize(),\n            ToTensorV2(),\n        ])\n    else:\n        return Compose([\n            A.Resize(height=CFG.img_size, width=CFG.img_size),\n            A.Normalize(),\n            ToTensorV2(),\n        ])","bddeb851":"test_dataset = PlantDataset(sub, get_transform('valid'))\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=2)","90557da4":"class CustomResNet(nn.Module):\n    def __init__(self, model_name='resnet18', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        in_features = self.model.get_classifier().in_features\n        self.model.fc = nn.Linear(in_features, CFG.num_classes)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","2a31c2d2":"from collections import OrderedDict\n\ndef fix_model_state_dict(state_dict):\n    new_state_dict = OrderedDict()\n    for k, v in state_dict.items():\n        name = k\n        if name.startswith('model.'):\n            name = name[6:]  # remove 'model.' of dataparallel\n        new_state_dict[name] = v\n    return new_state_dict","b7bd22e2":"model = CustomResNet(model_name=CFG.model_name, pretrained=CFG.pretrained)","4db8b88d":"checkpoint = \"..\/input\/plat2021-resnet50\/last.ckpt\"\n\nweight = torch.load(checkpoint)['state_dict']\nmodel.load_state_dict(fix_model_state_dict(weight))","a8b0e5fb":"model.cuda()\nmodel.eval()\n\npredictions = []\nfor batch in test_loader:\n    image = batch['image'].cuda()\n    with torch.no_grad():\n        outputs = model(image)\n        preds = outputs.argmax(1).detach().cpu().numpy()\n        predictions.append(preds)","ab09d344":"inv_labels_dict = {v: k for k, v in labels_dict.items()}\ninv_labels_dict","a3b6cf04":"sub['labels'] = np.concatenate(predictions)\nsub = sub.replace({\"labels\": inv_labels_dict})\nsub.to_csv('submission.csv', index=False)\nsub.head()","6a55ae40":"# Define Model","9e54f844":"# Inference","6111f3cc":"### Load images that have been pre-resized by AnkurSingh to speed up the learning process. https:\/\/www.kaggle.com\/c\/plant-pathology-2021-fgvc8\/discussion\/227032","0703ce57":"# Config","4cb5a6c5":"# Plant 2021 with PyTorch Lightning\nThis notebook uses the models learned in the following notebooks for inference.\n[Training notebook](https:\/\/www.kaggle.com\/pegasos\/plant2021-pytorch-lightning-starter-training)","51159658":"# Import","ed40e9c5":"# Define Dataset"}}