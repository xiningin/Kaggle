{"cell_type":{"5fd38db1":"code","0be92ee6":"code","89e4f9f7":"code","6332a449":"code","7046ecd6":"code","28968830":"code","ccec2f1d":"code","0a5c009d":"code","4662cb66":"code","43b57520":"code","9cdd54de":"code","438b2083":"code","62445127":"code","ea7c6999":"code","c5b3d4e7":"code","37109339":"code","902cb214":"code","4a08e430":"code","35fbe3d0":"code","5fe56c78":"code","4aa4dc6a":"code","589c628c":"code","8d86148c":"code","bea10918":"code","a167d361":"code","c416e513":"code","0a3b968c":"markdown","a1818406":"markdown","dc9e61f1":"markdown","594efcb3":"markdown","877c4741":"markdown","54363dfb":"markdown","5bf07401":"markdown","dca36502":"markdown","7c4a23ed":"markdown","787fd5ca":"markdown","ee120006":"markdown","f96006a1":"markdown","71459cca":"markdown","989fef20":"markdown","4b084d78":"markdown","4363719c":"markdown","5e858101":"markdown","1f4f5dfe":"markdown","8dedadda":"markdown","b5681be7":"markdown","fc73ef9f":"markdown"},"source":{"5fd38db1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\n\nfrom tqdm import tqdm\nsns.set_style(\"darkgrid\")\n\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, SimpleRNN, LSTM, GRU, Input\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0be92ee6":"df= pd.read_csv('\/kaggle\/input\/nyse\/prices-split-adjusted.csv')\ndf.head()","89e4f9f7":"amz= df[df.symbol == 'AMZN']\namz.shape","6332a449":"print('Select region of interest for deeper understanding ')\npx.line(amz, x=\"date\", y=[\"open\", \"close\",\"low\", \"high\"], title='Opening stock prices of Amazon.com, Inc.')","7046ecd6":"fig = make_subplots(rows=1, cols=2, column_widths=[0.6, 0.4])\n\nfig.add_trace(go.Scatter(x= amz.date, y=amz.open.diff(), name='l1'),\n              row=1, col=1)\n\nfig.add_trace(go.Histogram(x=amz['open'].diff(), name='h1', histnorm='probability density'),\n              row=1, col=2)\nfig.update_layout( height=550, width=1130, title_text=\"Consecutive difference between opening stock price of AMAZON shares\")\n\nfig.update_xaxes(title_text=\"Time\", row=1, col=1);   fig.update_xaxes(title_text=\"Value\", row=1, col=2)\nfig.update_yaxes(title_text=\"Value\", row=1, col=1);   fig.update_yaxes(title_text=\"Prob. Density\", row=1, col=2)\n\nfig.show()","28968830":"f, axes= plt.subplots(2,2, figsize=(20,14))\nsns.regplot(x=amz.open, y=amz.close, color=\"g\", ax=axes[0][0])\nsns.regplot(x=amz.open, y=amz.volume, ax=axes[0][1])\nsns.regplot(x=amz.low, y=amz.high, color=\"b\", ax=axes[1][0])\nsns.regplot(x=amz.volume, y=amz.close, color=\"g\", ax=axes[1][1])","ccec2f1d":"f, axes= plt.subplots(1,2, figsize=(20,6))\nsns.regplot(x=amz.open.diff(), y=amz.close.diff(), color=\"g\", ax=axes[0])\nsns.regplot(x=amz.low.diff(), y=amz.high.diff(), color=\"b\", ax=axes[1])\nplt.suptitle('Consecutive variation correlations', size=16)","0a5c009d":"corr= amz.corr()\nplt.figure(figsize=(8,5))\nsns.heatmap(corr, annot=True, cmap=\"Greens_r\",linewidth = 3, linecolor = \"white\")","4662cb66":"def split_data(X,Y):\n    return X[:-40], Y[:-40], X[-40:], Y[-40:]","43b57520":"def data_for_linear(df, timesteps= 40):\n    x=amz.open.values\n    x=x.reshape(-1,1)\n    #Normalization\n    \n    scaler = MinMaxScaler()\n    x_noml=scaler.fit_transform(x)\n    X=[]; Y=[]\n    for i in tqdm(range(x.shape[0]- timesteps)):\n        X.append(x_noml[i:i+timesteps])\n        Y.append(x_noml[i+timesteps])\n    X=np.array(X); Y= np.array(Y)\n    X= np.reshape(X, (-1,timesteps))\n    print('Input shape:{}, Output shape:{}'.format(X.shape, Y.shape))\n    return X,Y, scaler","9cdd54de":"#Loading & data splitting\n# 2D Input \nx_linear, ylinear, lin_scaler= data_for_linear(amz)\nxtrain, ytrain, xtest, ytest= split_data(x_linear, ylinear)","438b2083":"liner_model= Sequential()\nliner_model.add(Dense(128, activation=None, input_shape=(40,)))\nliner_model.add(Dense(228, activation=None))\nliner_model.add(Dense(64, activation=None))\nliner_model.add(Dense(1, activation=None))\n\nliner_model.compile(optimizer='adam', loss='mse')\nliner_model.summary()","62445127":"his= liner_model.fit(xtrain, ytrain, epochs=40)","ea7c6999":"fig = make_subplots(rows=1, cols=2, column_widths=[0.5, 0.5])\n\nfig.add_trace(go.Scatter(x= amz.date[40:1682].values, y= lin_scaler.inverse_transform(ytrain).reshape(-1), name='Traning data'),\n              row=1, col=1)\n\nfig.add_trace(go.Scatter(x= amz.date[40:1682].values, y= lin_scaler.inverse_transform(liner_model.predict(xtrain)).reshape(-1), name='Prediction'),\n              row=1, col=1)\n\nfig.add_trace(go.Scatter(x= amz.date[1682+40:].values, y= lin_scaler.inverse_transform(ytest).reshape(-1), name='Testing data'),\n              row=1, col=2)\n\nfig.add_trace(go.Scatter(x= amz.date[1682+40:].values, y= lin_scaler.inverse_transform(liner_model.predict(xtest)).reshape(-1), name='Test prediction'),\n              row=1, col=2)\n\nfig.update_layout( height=550, width=1200, title_text=\"Linear Model performance\")\n\nfig.update_xaxes(title_text=\"Date\", row=1, col=1);   fig.update_xaxes(title_text=\"Date\", row=1, col=2)\nfig.update_yaxes(title_text=\"Opening stock price\", row=1, col=1);   fig.update_yaxes(title_text=\"Opening stock price\", row=1, col=2)\n\nfig.show()","c5b3d4e7":"#-------------- True Forecasting\/predicting future sales--------------------#\nypred=[]\nfor i in range(xtest.shape[0]-1):\n    p= liner_model.predict(xtest[i].reshape(1,40))\n    ypred.append(p)\n    xtest[i+1, -1]= p\nypred.append(liner_model.predict(xtest[i+1].reshape(1,40)))\n#-------------- Note it!------------------------------------------------------#\n    \n\nf, ax= plt.subplots(1, 2, figsize=(30,8))\nax[0].plot(lin_scaler.inverse_transform(ytrain))\nax[0].plot(lin_scaler.inverse_transform(liner_model.predict(xtrain)))\nax[0].set_title('Traning set, mse:{}'.format(mean_absolute_error(ytrain, liner_model.predict(xtrain))*100))\nax[0].set_ylabel('Open-stock-price')\nax[0].set_xlabel('Time')\n\nax[1].plot(lin_scaler.inverse_transform(ytest))\nax[1].plot(lin_scaler.inverse_transform(np.array(ypred).reshape(-1,1)))\nax[1].set_title('Testing-set, mse:{}'.format(mean_absolute_error(ytest, np.array(ypred).reshape(-1,1))*100))\nax[1].set_ylabel('Open-stock-price')\nax[1].set_xlabel('Time')\nplt.show()","37109339":"def data_for_RNNs(df, timesteps= 40):\n    x=amz.open.values\n    x=x.reshape(-1,1)\n    \n    #Normalization\n    scaler = MinMaxScaler()\n    x_noml=scaler.fit_transform(x)\n    \n    X=[]; Y=[]\n    for i in tqdm(range(x.shape[0]- timesteps)):\n        X.append(x_noml[i:i+timesteps])\n        Y.append(x_noml[i+timesteps])\n    X=np.array(X); Y= np.array(Y)\n    print('Input shape:{}, Output shape:{}'.format(X.shape, Y.shape))\n    return X,Y, scaler","902cb214":"# 3D Input \nx_rnn, y_rnn, rnn_scaler= data_for_RNNs(amz)\nxtrain, ytrain, xtest, ytest= split_data(x_rnn, y_rnn)","4a08e430":"rnn_model= Sequential()\nrnn_model.add(SimpleRNN(128, activation='tanh', input_shape=(40,1), return_sequences=True))\nrnn_model.add(SimpleRNN(228,activation='tanh', return_sequences=True))\nrnn_model.add(Dropout(0.3))\nrnn_model.add(SimpleRNN(64, activation='tanh', return_sequences=False))\nrnn_model.add(Dense(1, activation=None))\n\nrnn_model.compile(optimizer='adam', loss='mse')\nrnn_model.summary()","35fbe3d0":"his= rnn_model.fit(xtrain, ytrain, epochs=40)","5fe56c78":"fig = make_subplots(rows=1, cols=2, column_widths=[0.5, 0.5])\n\nfig.add_trace(go.Scatter(x= amz.date[40:1682].values, y= rnn_scaler.inverse_transform(ytrain).reshape(-1), name='Traning data'),\n              row=1, col=1)\n\nfig.add_trace(go.Scatter(x= amz.date[40:1682].values, y= rnn_scaler.inverse_transform(rnn_model.predict(xtrain)).reshape(-1), name='Prediction'),\n              row=1, col=1)\n\nfig.add_trace(go.Scatter(x= amz.date[1682+40:].values, y= rnn_scaler.inverse_transform(ytest).reshape(-1), name='Testing data'),\n              row=1, col=2)\n\nfig.add_trace(go.Scatter(x= amz.date[1682+40:].values, y= rnn_scaler.inverse_transform(rnn_model.predict(xtest)).reshape(-1), name='Test prediction'),\n              row=1, col=2)\n\nfig.update_layout( height=550, width=1200, title_text=\"Simple RNN Model performance\")\n\nfig.update_xaxes(title_text=\"Date\", row=1, col=1);   fig.update_xaxes(title_text=\"Date\", row=1, col=2)\nfig.update_yaxes(title_text=\"Opening stock price\", row=1, col=1);   fig.update_yaxes(title_text=\"Opening stock price\", row=1, col=2)\n\nfig.show()","4aa4dc6a":"#-------------- True Forecasting\/predicting of future data--------------------#\n\n# Grab value predicted by model on 1st sample of test data.\n# Replace last(timestep) value from 2nd sample with predicted value.\n# Predict.....Grab.....Replace....Predict.... \n\n\nypred=[]\nfor i in range(xtest.shape[0]-1):\n    p= rnn_model.predict(xtest[i].reshape(1,40, 1))\n    ypred.append(p)\n    xtest[i+1, -1]= p\nypred.append(rnn_model.predict(xtest[i+1].reshape(1,40, 1)))\n#-------------- Note it!------------------------------------------------------#\n    \n\nf, ax= plt.subplots(1, 2, figsize=(30,8))\nax[0].plot(rnn_scaler.inverse_transform(ytrain))\nax[0].plot(rnn_scaler.inverse_transform(rnn_model.predict(xtrain)))\nax[0].set_title('Traning set, mse:{}'.format(mean_absolute_error(ytrain, rnn_model.predict(xtrain))*100))\nax[0].set_ylabel('Open-stock-price')\nax[0].set_xlabel('Time')\n\nax[1].plot(rnn_scaler.inverse_transform(ytest))\nax[1].plot(rnn_scaler.inverse_transform(np.array(ypred).reshape(-1,1)))\nax[1].set_title('Testing-set, mse:{}'.format(mean_absolute_error(ytest, np.array(ypred).reshape(-1,1))*100))\nax[1].set_ylabel('Open-stock-price')\nax[1].set_xlabel('Time')\nplt.show()","589c628c":"# 3D Input \nx_lstm, y_lstm, lstm_scaler= data_for_RNNs(amz)\nxtrain, ytrain, xtest, ytest= split_data(x_lstm, y_lstm)","8d86148c":"lstm_model= Sequential()\nlstm_model.add(LSTM(128, activation='tanh', input_shape=(40,1), return_sequences=True))\nlstm_model.add(LSTM(228,activation='tanh', return_sequences=True))\nlstm_model.add(Dropout(0.3))\nlstm_model.add(LSTM(64, activation='tanh', return_sequences=False))\nlstm_model.add(Dense(1, activation=None))\n\nlstm_model.compile(optimizer='adam', loss='mse')\nlstm_model.summary()","bea10918":"his= lstm_model.fit(xtrain, ytrain, epochs=40)","a167d361":"fig = make_subplots(rows=1, cols=2, column_widths=[0.5, 0.5])\n\nfig.add_trace(go.Scatter(x= amz.date[40:1682].values, y= lstm_scaler.inverse_transform(ytrain).reshape(-1), name='Traning data'),\n              row=1, col=1)\n\nfig.add_trace(go.Scatter(x= amz.date[40:1682].values, y= lstm_scaler.inverse_transform(lstm_model.predict(xtrain)).reshape(-1), name='Prediction'),\n              row=1, col=1)\n\nfig.add_trace(go.Scatter(x= amz.date[1682+40:].values, y= lstm_scaler.inverse_transform(ytest).reshape(-1), name='Testing data'),\n              row=1, col=2)\n\nfig.add_trace(go.Scatter(x= amz.date[1682+40:].values, y= lstm_scaler.inverse_transform(lstm_model.predict(xtest)).reshape(-1), name='Test prediction'),\n              row=1, col=2)\n\nfig.update_layout( height=550, width=1200, title_text=\"LSTM RNN Model performance\")\n\nfig.update_xaxes(title_text=\"Date\", row=1, col=1);   fig.update_xaxes(title_text=\"Date\", row=1, col=2)\nfig.update_yaxes(title_text=\"Opening stock price\", row=1, col=1);   fig.update_yaxes(title_text=\"Opening stock price\", row=1, col=2)\n\nfig.show()","c416e513":"#-------------- True Forecasting\/predicting of future data--------------------#\n\n# Grab value predicted by model on 1st sample of test data.\n# Replace last(timestep) value from 2nd sample with predicted value.\n# Predict.....Grab.....Replace....Predict.... \n\nypred=[]\nfor i in range(xtest.shape[0]-1):\n    p= lstm_model.predict(xtest[i].reshape(1,40, 1))\n    ypred.append(p)\n    xtest[i+1, -1]= p\nypred.append(lstm_model.predict(xtest[i+1].reshape(1,40, 1)))\n#-------------- Note it!------------------------------------------------------#\n    \n\nf, ax= plt.subplots(1, 2, figsize=(30,8))\nax[0].plot(lstm_scaler.inverse_transform(ytrain))\nax[0].plot(lstm_scaler.inverse_transform(lstm_model.predict(xtrain)))\nax[0].set_title('Traning set, mse:{}'.format(mean_absolute_error(ytrain, lstm_model.predict(xtrain))*100))\nax[0].set_ylabel('Open-stock-price')\nax[0].set_xlabel('Time')\n\nax[1].plot(lstm_scaler.inverse_transform(ytest))\nax[1].plot(lstm_scaler.inverse_transform(np.array(ypred).reshape(-1,1)))\nax[1].set_title('Testing-set, mse:{}'.format(mean_absolute_error(ytest, np.array(ypred).reshape(-1,1))*100))\nax[1].set_ylabel('Open-stock-price')\nax[1].set_xlabel('Time')\nplt.show()","0a3b968c":"> ### Model(Linear model(ANN)) traning\n\n![](https:\/\/miro.medium.com\/proxy\/1*mTTmfdMcFlPtyu8__vRHOQ.gif)","a1818406":"> ### Model(Simple rnn) traning\n![](https:\/\/miro.medium.com\/max\/1900\/1*gFC2bTg3uihp1klknWU0qg.gif)","dc9e61f1":"<hr>","594efcb3":"# Exploratory Data Analysis","877c4741":"> ### Model(LSTM rnn) traning\n\n![](https:\/\/miro.medium.com\/max\/1900\/1*cmv5EOAd6iWMzWvHrZbl-w.gif)","54363dfb":"![](https:\/\/i.gifer.com\/7ImI.gif)                                                                                                                                                  \n### ---------------------------HOPE YOU HAVE ENJOYED THIS NOTEBOOK-------------------------","5bf07401":"# Linear regression for fitting the data ","dca36502":"![](data:image\/png;base64,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)","7c4a23ed":"> ### Model performance visualization & Forecasting\n## <span style=\"color:Tomato;\"> WRONG<\/span> Forecasting !!","787fd5ca":"<hr>","ee120006":"<hr>","f96006a1":"# **Simple RNN for fitting the data**\n> ### Data per-processing for model feeding\n\n![](https:\/\/jrmerwin.github.io\/deeplearning4j-docs\/img\/rnn_data.png)","71459cca":"## <span style=\"color:green;\"> RIGHT<\/span> way to Forecast !!","989fef20":"> ### Model performance visualization & Forecasting\n## <span style=\"color:Tomato;\"> WRONG<\/span> Forecasting !!","4b084d78":"> ### Model performance visualization & Forecasting\n## <span style=\"color:Tomato;\"> WRONG<\/span> Forecasting !!","4363719c":"> ### Data per-processing for model feeding","5e858101":"### We can conclude from above visualization....\n1. We got **large error values for the unknown data**. This means that the network has failed to predict the close price. Perhaps, we can improve the result by changing the network architecture on train it for more epochs.\n2.  I don\u2019t think we can get more data since we have already used all of the data available. It is possible to train a network using data for different companies, but since these companies may have different properties, their stock prices may change according to different laws, which will only confuse the network.\n3. Here the model **fails to capture the trend** quickly on real multi-timestep data.\n\n### Some general facts....\n* **Random walk theory suggests that changes in stock prices have the same distribution and are independent of each other. Therefore, it assumes the past movement or trend of a stock price or market cannot be used to predict its future movement.**\n* If anyone could predict future stock price even for a single time, they would already be the richest man on the planet. (They could simply borrow a lot of money at risk-free rate (say 812%) and leverage it even more using options to make the trade)","1f4f5dfe":"# LSTM(rnn) for fitting the data\n> ### Data per-processing for model feeding","8dedadda":"## <span style=\"color:green;\"> RIGHT<\/span> way to Forecast !!","b5681be7":"#  A *GAME-CHANGER* Question\n\n## Can Data Scientists leverage the power of RNN's to make **<span style=\"color:MediumSeaGreen;\">MONEY<\/span> from stock market** ?\n\n![](https:\/\/mir-s3-cdn-cf.behance.net\/project_modules\/max_1200\/699e4762225981.5a89af14d87a9.gif)\n    \n## Notebook contents\n\n\n\n\n### Exploratory Data Analysis.     \n### Exercising concept of '<span style=\"color:blue;\">ALL DATA IS SAME<\/span>' for **ML** algorithms.\n\n\n\n\n1. Practise **Linear Regression** to fit data.\n2. Practise **Simple RNN** to fit same data.\n3. Practise **LSTM's** to do same.\n\n\n\n\n\n### Right way to **Forecast Future Predictions !!**.\n\n   \n\n1. More than **85% beginners FAILS(Do things in wrong way)** in this section.\n2. More info. is in \"<a href=\"https:\/\/www.kaggle.com\/akhileshdkapse\/get-smarter-in-eda-ml-modelling-stock-prediction#Linear-regression-for-fitting-the-data\">RIGHT way to Forecast !!<\/a>\" sections below.\n\n\n\n\n### <p style=\"color:DodgerBlue;\"> <span style=\"color:red;\">UPVOTE<\/span>, if you find this kernel JUSTIFIABLE............. :-)<\/p>","fc73ef9f":"## <span style=\"color:green;\"> RIGHT<\/span> way to Forecast !!\n\n### Let's choose smart strategy for forecasting\n* Grab value predicted by model on 1st sample of test data.\n* Replace last(timestep) value from 2nd sample with predicted value.\n* Predict.....Grab.....Replace....Predict.... \n"}}