{"cell_type":{"302f8187":"code","06302740":"code","c6998c9a":"code","867972a8":"code","dea8ffa9":"code","18cbad0b":"code","10a19a78":"code","7fcdcd62":"code","f8252f94":"code","8aedb3d4":"code","f6f5e9c4":"code","c07e9cd4":"code","7d529cf1":"code","26e8aa68":"code","6b1d26f6":"code","300e231f":"code","9f1f4acf":"markdown","41c0f3b8":"markdown","7fe3976c":"markdown","40ed470d":"markdown","3ec99bfd":"markdown","61ec3137":"markdown","67cc97fa":"markdown","93c5f05b":"markdown","9524289d":"markdown"},"source":{"302f8187":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","06302740":"from math import log2, ceil\nfrom pathlib import Path\nfrom matplotlib import pyplot as plt \nimport cv2\n%matplotlib inline\nfrom skimage.measure import compare_ssim\nfrom matplotlib.patches import Rectangle\nfrom keras.preprocessing.image import load_img\nfrom math import sin, cos\nfrom PIL import ImageDraw, Image","c6998c9a":"with open('..\/input\/micropcb-images\/train_bboxes.csv') as f: data = f.read().split('\\n')[:-1]\nlen(data) # Number of rows in the dataset","867972a8":"for line in data[:5]: print(line)","dea8ffa9":"def bboxes_pcb(path, img_id, debug=False):\n    # You need to input the path (train or test) and the car_id (img_id)\n    bboxes = []\n    # Let's iterate over all the angles\n    for num in range(1, 17):\n        # Here we read images i and i+1. \n        # If i==16, we will read the first image\n        # To speed up the things, we can scale the images 5 times\n        fname1 = os.path.join(path, img_id+ '_{:0>2}.jpg'.format(num))\n        fname2 = os.path.join(path, img_id+ '_{:0>2}.jpg'.format((num) % 16+1))\n        img_1_orig = cv2.imread(fname1)\n        h, w = img_1_orig.shape[0],img_1_orig.shape[1],\n        img_1_scaled = cv2.resize(img_1_orig, (w\/\/5, h\/\/5))\n\n        img_2_orig = cv2.imread(fname2)\n        h, w = img_2_orig.shape[0],img_2_orig.shape[1],\n        img_2_scaled = cv2.resize(img_2_orig, (w\/\/5, h\/\/5))\n\n        if debug:\n            plt.figure()\n            plt.subplot(121)\n            plt.title('Current image [{}]'.format(num))\n            plt.imshow(img_1_scaled)\n            plt.subplot(122)\n            plt.title('Next image [{}]'.format((num) % 16+1))\n            plt.imshow(img_2_scaled)\n            plt.show()\n        \n        # As the images differ from each other just a by a small angle of rotation,\n        # We can find their difference and draw a boundign box around the obtained image\n        img1 = cv2.cvtColor(img_1_scaled, cv2.COLOR_BGR2GRAY)\n        img2 = cv2.cvtColor(img_2_scaled, cv2.COLOR_BGR2GRAY)\n\n        # Instead of plain difference, we look for structural similarity\n        score, dimg = compare_ssim(img1, img2, full=True)\n        dimg = (dimg * 255).astype(\"uint8\")\n\n\n        thresh = cv2.threshold(dimg, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n        if debug:\n            plt.figure()\n            plt.title('Difference image')\n            plt.imshow(dimg>thresh)\n            plt.show()        \n        \n        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        \n        ROIS = []\n        for c in cnts[1]:\n            (x, y, w, h) = cv2.boundingRect(c)\n            # We dont want to use too small bounding boxes\n            if w*h > img1.shape[0]*img1.shape[1]\/\/9:\n                ROIS.append([x, y, x+w, y+h])\n\n        ROIS = np.array(ROIS)\n\n        # Now we will draw a boundig box \n        # around all the bounding boxes (there are outliers)\n        x1 = ROIS[:,0].min()\n        y1 = ROIS[:,1].min()\n\n        x2 = ROIS[:,2].max()\n        y2 = ROIS[:,3].max()\n\n        if debug:\n            plt.figure()\n            plt.imshow(img_1_orig)\n            rect = Rectangle((x1*5, y1*5), (x2-x1)*5, (y2-y1)*5, fill=False, color='red')\n            plt.axes().add_patch(rect)\n            plt.show()      \n        bboxes.append([fname1, x1*5, y1*5, x2*5, y2*5])\n    return bboxes","18cbad0b":"train = pd.read_csv('..\/input\/micropcb-images\/train_bboxes.csv')\n# k is camera instrinsic matrix\nk = np.array([[2304.5479, 0,  1686.2379],\n           [0, 2305.8757, 1354.9849],\n           [0, 0, 1]], dtype=np.float32)","10a19a78":"plt.rcParams[\"axes.grid\"] = False\nimg_name = train.loc[10]['Image']\npred_string = train.loc[10]['Top']\nfig, ax = plt.subplots(figsize=(15, 15))\nimg = load_img('..\/input\/micropcb-images\/train_coded\/train_coded\/' + img_name)\nplt.imshow(img)\nplt.show()","7fcdcd62":"items = pred_string.split(' ')\nmodel_types, yaws, pitches, rolls, xs, ys, zs = [items[i::7] for i in range(7)]","f8252f94":"# convert euler angle to rotation matrix\ndef euler_to_Rot(yaw, pitch, roll):\n    Y = np.array([[cos(yaw), 0, sin(yaw)],\n                  [0, 1, 0],\n                  [-sin(yaw), 0, cos(yaw)]])\n    P = np.array([[1, 0, 0],\n                  [0, cos(pitch), -sin(pitch)],\n                  [0, sin(pitch), cos(pitch)]])\n    R = np.array([[cos(roll), -sin(roll), 0],\n                  [sin(roll), cos(roll), 0],\n                  [0, 0, 1]])\n    return np.dot(Y, np.dot(P, R))","8aedb3d4":"def draw_line(image, points):\n    color = (255, 0, 0)\n    cv2.line(image, tuple(points[1][:2]), tuple(points[2][:2]), color, 16)\n    cv2.line(image, tuple(points[1][:2]), tuple(points[4][:2]), color, 16)\n\n    cv2.line(image, tuple(points[1][:2]), tuple(points[5][:2]), color, 16)\n    cv2.line(image, tuple(points[2][:2]), tuple(points[3][:2]), color, 16)\n    cv2.line(image, tuple(points[2][:2]), tuple(points[6][:2]), color, 16)\n    cv2.line(image, tuple(points[3][:2]), tuple(points[4][:2]), color, 16)\n    cv2.line(image, tuple(points[3][:2]), tuple(points[7][:2]), color, 16)\n\n    cv2.line(image, tuple(points[4][:2]), tuple(points[8][:2]), color, 16)\n    cv2.line(image, tuple(points[5][:2]), tuple(points[8][:2]), color, 16)\n\n    cv2.line(image, tuple(points[5][:2]), tuple(points[6][:2]), color, 16)\n    cv2.line(image, tuple(points[6][:2]), tuple(points[7][:2]), color, 16)\n    cv2.line(image, tuple(points[7][:2]), tuple(points[8][:2]), color, 16)\n    return image\n\n\ndef draw_points(image, points):\n    image = np.array(image)\n    for (p_x, p_y, p_z) in points:\n        # print(\"p_x, p_y\", p_x, p_y)\n        cv2.circle(image, (p_x, p_y), 5, (255, 0, 0), -1)\n    return image","f6f5e9c4":"# image coordinate to world coordinate\ndef img_cor_2_world_cor():\n    x_img, y_img, z_img = img_cor_points[0]\n    xc, yc, zc = x_img*z_img, y_img*z_img, z_img\n    p_cam = np.array([xc, yc, zc])\n    xw, yw, zw = np.dot(np.linalg.inv(k), p_cam)\n    print(xw, yw, zw)\n    print(x, y, z)","c07e9cd4":"x_l = 1.02\ny_l = 0.80\nz_l = 2.31\nfor yaw, pitch, roll, x, y, z in zip(yaws, pitches, rolls, xs, ys, zs):\n    yaw, pitch, roll, x, y, z = [float(x) for x in [yaw, pitch, roll, x, y, z]]\n    # I think the pitch and yaw should be exchanged\n    yaw, pitch, roll = -pitch, -yaw, -roll\n    Rt = np.eye(4)\n    t = np.array([x, y, z])\n    Rt[:3, 3] = t\n    Rt[:3, :3] = euler_to_Rot(yaw, pitch, roll).T\n    Rt = Rt[:3, :]\n    P = np.array([[0, 0, 0, 1],\n                  [x_l, y_l, -z_l, 1],\n                  [x_l, y_l, z_l, 1],\n                  [-x_l, y_l, z_l, 1],\n                  [-x_l, y_l, -z_l, 1],\n                  [x_l, -y_l, -z_l, 1],\n                  [x_l, -y_l, z_l, 1],\n                  [-x_l, -y_l, z_l, 1],\n                  [-x_l, -y_l, -z_l, 1]]).T\n    img_cor_points = np.dot(k, np.dot(Rt, P))\n    img_cor_points = img_cor_points.T\n    img_cor_points[:, 0] \/= img_cor_points[:, 2]\n    img_cor_points[:, 1] \/= img_cor_points[:, 2]\n    # call this function before chage the dtype\n    img_cor_2_world_cor()\n    img_cor_points = img_cor_points.astype(int)\n    img = draw_points(img, img_cor_points)\n    img = draw_line(img, img_cor_points)\n    \nimg = Image.fromarray(img)\nplt.imshow(img)\nplt.show()","7d529cf1":"df = pd.read_csv('..\/input\/micropcb-images\/train_bboxes.csv', encoding='utf8')\npd.set_option('display.max_columns', None)\ndf.head()","26e8aa68":"df_train = pd.read_csv('..\/input\/micropcb-images\/train_angles.csv', encoding='utf8')\npd.set_option('display.max_columns', None)\ndf_train.head()","6b1d26f6":"df1 = pd.read_csv('..\/input\/micropcb-images\/train_ratio_top_to_bottom.csv', encoding='utf8')\npd.set_option('display.max_columns', None)\ndf1.head()","300e231f":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#4251f5','#42a7f5','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Be patient. Mar\u00edlia Prata, @mpwolke was Here.' )","9f1f4acf":"NameError: name 'yaws' is not defined.  Because numpy.int64' object has no attribute 'split'\nTherefore, I have NO Image at all.","41c0f3b8":"#Codes by Aleksei Tiulpin https:\/\/www.kaggle.com\/alekseit\/simple-bounding-boxes","7fe3976c":"#Codes by Martin Piotte https:\/\/www.kaggle.com\/martinpiotte\/bounding-box-data-for-the-whale-flukes","40ed470d":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcQjGLDZg4tSY1VBfT44mLOP1i2bi9oa6zWq0w&usqp=CAU)nts.com","3ec99bfd":"#Codes by Linye Li https:\/\/www.kaggle.com\/zstusnoopy\/visualize-the-location-and-3d-bounding-box-of-car","61ec3137":"#AttributeError: 'numpy.int64' object has no attribute 'split'","67cc97fa":"#Here I just opened the files to read them","93c5f05b":"The function didn't work on the next snippet since I got: AttributeError: 'NoneType' object has no attribute 'shape'.","9524289d":"PRINTED CIRCUIT BOARD (PCB)\n\nA printed circuit board (PCB) mechanically supports and electrically connects electrical or electronic components using conductive tracks, pads and other features etched from one or more sheet layers of copper laminated onto and\/or between sheet layers of a non-conductive substrate. Components are generally soldered onto the PCB to both electrically connect and mechanically fasten them to it.\nhttps:\/\/en.wikipedia.org\/wiki\/Printed_circuit_board"}}