{"cell_type":{"1a4fd2b6":"code","a0b513a5":"code","b000aa02":"code","e4acb133":"code","2b446a82":"code","daa08c01":"code","900b7e61":"code","74bd17df":"code","25e6eca3":"code","f40bdcec":"code","3f3b3727":"code","1edfaca5":"code","ee3db93b":"code","b0765fd5":"code","74823ba4":"code","a5d54e7b":"code","041786c9":"code","cfcedf03":"code","dd23782d":"code","be1bb008":"code","d792a7bf":"code","326ab572":"code","0d542af9":"code","3ff0e136":"code","405d0a8d":"code","4465f59e":"code","e9307d5c":"code","495f15cd":"code","85b5d8a8":"code","1fe1bece":"code","29853e19":"code","390a3ea2":"code","e29c6f31":"code","875c108e":"code","8f2a15ae":"code","da4d02a0":"code","77b36270":"code","56d4ee89":"code","2e2237c3":"code","f8bd4af3":"code","bdd1ff16":"code","29995e71":"code","3861cade":"code","fa321223":"code","21171c37":"code","956ebe44":"code","0ec633a4":"code","59f17fce":"code","7d6410d9":"code","14cdfd31":"code","6a9cd8a0":"code","d85d4eaa":"code","d3bfd88e":"code","165215d0":"code","53e0e69e":"code","ecc1281f":"code","f5372a3e":"code","7f1064e2":"code","5a0ae6f2":"code","a9b81b18":"code","959491f4":"code","c6ef639b":"code","cfcc7a9c":"code","2c490afa":"code","2c035cdc":"code","9a9d712f":"code","ecb16652":"code","ea2a9737":"code","639e0047":"code","930c1ce4":"code","2f5d3b6d":"code","8216847a":"code","1b21ba3b":"code","4ed75a47":"code","b4cdf892":"code","d9b054c8":"code","0c7733aa":"code","b89ce05e":"code","0306f550":"code","e9a7c71e":"code","1a2db2b1":"code","62afc15b":"code","064e74a0":"code","97aebf39":"code","3211a322":"code","7aa6b0f8":"code","d8527b67":"code","e24e88db":"code","7e5dda9a":"markdown","01d20bff":"markdown","c4f91a9f":"markdown","deb351db":"markdown","a0f39a98":"markdown","8f3da684":"markdown","aaf39404":"markdown","07bdc0e8":"markdown","2ee06737":"markdown","a7edcd07":"markdown","39cb89bd":"markdown","0a2adebf":"markdown","7ca23674":"markdown","94646cd3":"markdown","6128eac3":"markdown","d86942d3":"markdown","b5dd59f2":"markdown"},"source":{"1a4fd2b6":"# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\n\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a0b513a5":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_PassengerId = test_df[\"PassengerId\"]","b000aa02":"train_df.columns","e4acb133":"\ntrain_df.head()","2b446a82":"train_df.describe()","daa08c01":"train_df.info()","900b7e61":"train_df.info()","74bd17df":"def bar_plot(variable):\n    \"\"\"\n        input: variable ex: \"Sex\"\n        output: bar plot & value count\n    \"\"\"\n    # get feature\n    var = train_df[variable]\n    # count number of categorical variable(value\/sample)\n    varValue = var.value_counts()\n    \n    # visualize\n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}\".format(variable,varValue))","25e6eca3":"\ncategory1 = [\"Survived\",\"Sex\",\"Pclass\",\"Embarked\",\"SibSp\", \"Parch\"]\nfor c in category1:\n    bar_plot(c)","f40bdcec":"\ncategory2 = [\"Cabin\", \"Name\", \"Ticket\"]\nfor c in category2:\n    print(\"{} \\n\".format(train_df[c].value_counts()))","3f3b3727":"train_df.head()","1edfaca5":"\ndef plot_hist(variable):\n    plt.figure(figsize = (9,3))\n    plt.hist(train_df[variable], bins = 50)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distribution with hist\".format(variable))\n    plt.show()","ee3db93b":"numericVar = [\"Fare\", \"Age\",\"PassengerId\"]\nfor n in numericVar:\n    plot_hist(n)","b0765fd5":"train_df[[\"Pclass\",\"Survived\"]].groupby([\"Pclass\"], as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","74823ba4":"train_df[[\"Sex\",\"Survived\"]].groupby([\"Sex\"], as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","a5d54e7b":"train_df[[\"SibSp\",\"Survived\"]].groupby([\"SibSp\"], as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","041786c9":"\ntrain_df[[\"Parch\",\"Survived\"]].groupby([\"Parch\"], as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","cfcedf03":"def detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(df[c],25)\n        # 3rd quartile\n        Q3 = np.percentile(df[c],75)\n        # IQR\n        IQR = Q3 - Q1\n        # Outlier step\n        outlier_step = IQR * 1.5\n        # detect outlier and their indeces\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        # store indeces\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","dd23782d":"\ntrain_df.loc[detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])]","be1bb008":"train_df = train_df.drop(detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]),axis = 0).reset_index(drop = True)","d792a7bf":"train_df.shape","326ab572":"\ntrain_df_len = len(train_df)\ntrain_df = pd.concat([train_df,test_df],axis = 0).reset_index(drop = True)","0d542af9":"\ntrain_df.head()","3ff0e136":"train_df.columns[train_df.isnull().any()]","405d0a8d":"\ntrain_df.isnull().sum()","4465f59e":"train_df[train_df[\"Embarked\"].isnull()]","e9307d5c":"train_df.boxplot(column=\"Fare\",by = \"Embarked\")\nplt.show()","495f15cd":"\ntrain_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"C\")\ntrain_df[train_df[\"Embarked\"].isnull()]","85b5d8a8":"train_df[train_df[\"Fare\"].isnull()]","1fe1bece":"train_df[\"Fare\"] = train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"] == 3][\"Fare\"]))","29853e19":"\ntrain_df[train_df[\"Fare\"].isnull()]","390a3ea2":"list1 = [\"SibSp\", \"Parch\", \"Age\", \"Fare\", \"Survived\"]\nsns.heatmap(train_df[list1].corr(), annot = True, fmt = \".2f\")\nplt.show()","e29c6f31":"g = sns.factorplot(x = \"SibSp\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","875c108e":"g = sns.factorplot(x = \"Parch\", y = \"Survived\", kind = \"bar\", data = train_df, size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","8f2a15ae":"g = sns.factorplot(x = \"Pclass\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","da4d02a0":"g = sns.FacetGrid(train_df, col = \"Survived\")\ng.map(sns.distplot, \"Age\", bins = 25)\nplt.show()","77b36270":"g = sns.FacetGrid(train_df, col = \"Survived\", row = \"Pclass\", size = 2)\ng.map(plt.hist, \"Age\", bins = 25)\ng.add_legend()\nplt.show()","56d4ee89":"g = sns.FacetGrid(train_df, row = \"Embarked\", size = 2)\ng.map(sns.pointplot, \"Pclass\",\"Survived\",\"Sex\")\ng.add_legend()\nplt.show()","2e2237c3":"g = sns.FacetGrid(train_df, row = \"Embarked\", col = \"Survived\", size = 2.3)\ng.map(sns.barplot, \"Sex\", \"Fare\")\ng.add_legend()\nplt.show()","f8bd4af3":"train_df[train_df[\"Age\"].isnull()]","bdd1ff16":"sns.factorplot(x = \"Sex\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","29995e71":"sns.factorplot(x = \"Sex\", y = \"Age\", hue = \"Pclass\",data = train_df, kind = \"box\")\nplt.show()","3861cade":"\nsns.factorplot(x = \"Parch\", y = \"Age\", data = train_df, kind = \"box\")\nsns.factorplot(x = \"SibSp\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","fa321223":"sns.heatmap(train_df[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(), annot = True)\nplt.show()","21171c37":"index_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nfor i in index_nan_age:\n    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) &(train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"])& (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n    age_med = train_df[\"Age\"].median()\n    if not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred\n    else:\n        train_df[\"Age\"].iloc[i] = age_med","956ebe44":"train_df[train_df[\"Age\"].isnull()]","0ec633a4":"train_df[\"Name\"].head(10)","59f17fce":"\nname = train_df[\"Name\"]\ntrain_df[\"Title\"] = [i.split(\".\")[0].split(\",\")[-1].strip() for i in name]","7d6410d9":"\nsns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","14cdfd31":"# convert to categorical\ntrain_df[\"Title\"] = train_df[\"Title\"].replace([\"Lady\",\"the Countess\",\"Capt\",\"Col\",\"Don\",\"Dr\",\"Major\",\"Rev\",\"Sir\",\"Jonkheer\",\"Dona\"],\"other\")\ntrain_df[\"Title\"] = [0 if i == \"Master\" else 1 if i == \"Miss\" or i == \"Ms\" or i == \"Mlle\" or i == \"Mrs\" else 2 if i == \"Mr\" else 3 for i in train_df[\"Title\"]]\ntrain_df[\"Title\"].head(20)","6a9cd8a0":"\nsns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","d85d4eaa":"g = sns.factorplot(x = \"Title\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_xticklabels([\"Master\",\"Mrs\",\"Mr\",\"Other\"])\ng.set_ylabels(\"Survival Probability\")\nplt.show()","d3bfd88e":"train_df.drop(labels = [\"Name\"], axis = 1, inplace = True)","165215d0":"train_df.head()","53e0e69e":"train_df = pd.get_dummies(train_df,columns=[\"Title\"])\ntrain_df.head()","ecc1281f":"train_df.head()","f5372a3e":"train_df[\"Fsize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1","7f1064e2":"\ng = sns.factorplot(x = \"Fsize\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","5a0ae6f2":"train_df[\"family_size\"] = [1 if i < 5 else 0 for i in train_df[\"Fsize\"]]","a9b81b18":"train_df.head(10)","959491f4":"sns.countplot(x = \"family_size\", data = train_df)\nplt.show()","c6ef639b":"\ng = sns.factorplot(x = \"family_size\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","cfcc7a9c":"train_df = pd.get_dummies(train_df, columns= [\"family_size\"])\ntrain_df.head()","2c490afa":"train_df[\"Embarked\"].head()","2c035cdc":"sns.countplot(x = \"Embarked\", data = train_df)\nplt.show()","9a9d712f":"train_df = pd.get_dummies(train_df, columns=[\"Embarked\"])\ntrain_df.head()","ecb16652":"train_df[\"Ticket\"].head(20)","ea2a9737":"\na = \"A\/5. 2151\"\na.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0]","639e0047":"tickets = []\nfor i in list(train_df.Ticket):\n    if not i.isdigit():\n        tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n        tickets.append(\"x\")\ntrain_df[\"Ticket\"] = tickets","930c1ce4":"train_df[\"Ticket\"].head(20)","2f5d3b6d":"train_df.head()","8216847a":"train_df = pd.get_dummies(train_df, columns= [\"Ticket\"], prefix = \"T\")\ntrain_df.head(10)","1b21ba3b":"sns.countplot(x = \"Pclass\", data = train_df)\nplt.show()","4ed75a47":"\ntrain_df[\"Pclass\"] = train_df[\"Pclass\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns= [\"Pclass\"])\ntrain_df.head()","b4cdf892":"train_df[\"Sex\"] = train_df[\"Sex\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns=[\"Sex\"])\ntrain_df.head()","d9b054c8":"\ntrain_df.drop(labels = [\"PassengerId\", \"Cabin\"], axis = 1, inplace = True)","0c7733aa":"train_df.columns","b89ce05e":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","0306f550":"\ntrain_df_len","e9a7c71e":"test = train_df[train_df_len:]\ntest.drop(labels = [\"Survived\"],axis = 1, inplace = True)","1a2db2b1":"test.head()","62afc15b":"train = train_df[:train_df_len]\nX_train = train.drop(labels = \"Survived\", axis = 1)\ny_train = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)\nprint(\"X_train\",len(X_train))\nprint(\"X_test\",len(X_test))\nprint(\"y_train\",len(y_train))\nprint(\"y_test\",len(y_test))\nprint(\"test\",len(test))","064e74a0":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nacc_log_train = round(logreg.score(X_train, y_train)*100,2) \nacc_log_test = round(logreg.score(X_test,y_test)*100,2)\nprint(\"Training Accuracy: % {}\".format(acc_log_train))\nprint(\"Testing Accuracy: % {}\".format(acc_log_test))","97aebf39":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","3211a322":"\ncv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","7aa6b0f8":"cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"DecisionTreeClassifier\", \"SVM\",\"RandomForestClassifier\",\n             \"LogisticRegression\",\n             \"KNeighborsClassifier\"]})\n\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")","d8527b67":"votingC = VotingClassifier(estimators = [(\"dt\",best_estimators[0]),\n                                        (\"rfc\",best_estimators[2]),\n                                        (\"lr\",best_estimators[3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))","e24e88db":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_PassengerId, test_survived],axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)","7e5dda9a":"* Pclass - Survived\n* Sex - Survived\n* SibSp - Survived\n* Parch - Survived","01d20bff":"## Feature Engineering","c4f91a9f":"* Categorical Variable: Survived, Sex, Pclass, Embarked, Cabin, Name, Ticket, Sibsp and Parch\n* Numerical Variable: Fare, age and passengerId","deb351db":"# Visualization","a0f39a98":"# **Load and Check Data**","8f3da684":"## Simple Logistic Regression","aaf39404":"# Basic Data Analysis","07bdc0e8":"# Missing Value","2ee06737":"# Categorical Variable","a7edcd07":"## Correlation Between Sibsp -- Parch -- Age -- Fare -- Survived","39cb89bd":"# Outlier Detection","0a2adebf":"# Modeling","7ca23674":"* Find Missing Value\n* Fill Missing Value","94646cd3":"# Numerical Variable","6128eac3":"# **Variable Description**","d86942d3":"# Ensemble Modeling","b5dd59f2":"## Hyperparameter Tuning -- Grid Search -- Cross Validation"}}