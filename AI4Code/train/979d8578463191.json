{"cell_type":{"55342928":"code","c277598f":"code","ad3b9ea9":"code","da4c2223":"code","fe77be89":"code","45636758":"code","be62eacc":"code","c49d388a":"code","01ac11e1":"code","48836eac":"markdown","b21708d8":"markdown","d90e5b60":"markdown","51d744f1":"markdown","0fa24f13":"markdown","40324d0e":"markdown","f5837d85":"markdown","28be421b":"markdown","cdd3f52e":"markdown","a7d1b06a":"markdown","97d17b2b":"markdown","abdb6a48":"markdown"},"source":{"55342928":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c277598f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport joblib\nfrom matplotlib.colors import ListedColormap\nplt.style.use(\"fivethirtyeight\") # THIS IS STYLE OF GRAPHS\n\n\nclass Perceptron:\n    def __init__(self,eta,epochs):\n        self.weights = np.random.randn(3) * 1e-4\n        print(f'weights assigned are : \\n{self.weights}')\n        self.eta = eta\n        self.epochs = epochs\n        \n    def activation_function(self,inputs,weights):\n        z = np.dot(inputs , weights)\n        return np.where(z > 0, 1, 0)\n    \n    def fit(self,X,y):\n        self.X = X\n        self.y = y\n        \n        X_with_bias = np.c_[self.X , -np.ones((len(self.X),1))]\n        print(f'X with bias : \\n{X_with_bias}')\n        \n        for epoch in range(self.epochs):\n            print(\"--\"*10)\n            print(f\"for epoch: {epoch}\")\n            print(\"--\"*10)\n            \n        \n            y_hat = self.activation_function(X_with_bias , self.weights)\n            print(f'predicted values by  single Neuron is : {y_hat}')\n        \n            self.error = self.y - y_hat\n            print(f'Error is : \\n{self.error}')\n        \n            #back propagation (weights updation)\n            self.weights = self.weights + self.eta * np.dot(X_with_bias.T , self.error)\n            print(f\"updated weights after epoch:\\n{epoch}\/{self.epochs} : \\n{self.weights}\")\n            \n            \n            \n    def predict(self,X):\n        X_with_bias = np.c_[X , -np.ones((len(X),1))]\n        return self.activation_function(X_with_bias , self.weights)\n    \n    \n    def total_loss(self):\n        total_loss = np.sum(self.error)\n        print(f'total error : {total_loss}')\n        return total_loss\n\n\n    \n        ","ad3b9ea9":"AND ={\n    'x1' : [0,0,1,1],\n    'x2' : [0,1,0,1],\n    'y'  : [0,0,0,1]\n}\n\ndf = pd.DataFrame(AND)\ndf","da4c2223":"def data_prepare(df):\n    X = df.drop('y',axis=1)\n    y = df['y']\n    \n    return X,y","fe77be89":"X , y = data_prepare(df)\n\nETA = 0.3\nEPOCHS=10\n\nmodel = Perceptron(eta = ETA , epochs = EPOCHS)\nmodel.fit(X , y)\n\n_ = model.total_loss()","45636758":"OR ={\n    'x1' : [0,0,1,1],\n    'x2' : [0,1,0,1],\n    'y'  : [0,1,1,1]\n}\n\ndf = pd.DataFrame(OR)\ndf","be62eacc":"X , y = data_prepare(df)\n\nETA = 0.3\nEPOCHS=10\n\nmodel = Perceptron(eta = ETA , epochs = EPOCHS)\nmodel.fit(X , y)\n\n_ = model.total_loss()","c49d388a":"XOR ={\n    'x1' : [0,0,1,1],\n    'x2' : [0,1,0,1],\n    'y'  : [0,1,1,0]\n}\n\ndf = pd.DataFrame(XOR)\ndf","01ac11e1":"X , y = data_prepare(df)\n\nETA = 0.3\nEPOCHS=10\n\nmodel = Perceptron(eta = ETA , epochs = EPOCHS)\nmodel.fit(X , y)\n\n_ = model.total_loss()","48836eac":"> **Please do upvote if you like the efforts and it's useful for you**","b21708d8":"> **As we can even after 10 epochs we aren't getting our expected result hense single neuron cannot work for XOR gate we need more number of neurons in order to get our expected result**","d90e5b60":"> **Implemetation on OR gate**","51d744f1":"# **Step by Step Working of a Single Neuron**\n\n**Let\u2019s** walk through this diagram step-by-step.\n\nAs you can see, neurons in a deep learning model are capable of having synapses that connect to more than one neuron in the preceding layer. Each synapse has an associated weight, which impacts the preceding neuron\u2019s importance in the overall neural network.\n\nWeights are a very important topic in the field of deep learning because adjusting a model\u2019s weights is the primary way through which deep learning models are trained. You\u2019ll see this in practice later on when we build our first neural networks from scratch.\n\nOnce a neuron receives its inputs from the neurons in the preceding layer of the model, it adds up each signal multiplied by its corresponding weight and passes them on to an activation function, like this:\n\nA neuron's activation function\n\n![image.png](attachment:ef26df73-3fa6-409c-977d-db315895f7de.png)","0fa24f13":"> **Implementing on AND gate**","40324d0e":"# **Let's start with what is Deep Learning**\n\n\nDeep learning is a type of machine learning and artificial intelligence (AI) that imitates the way humans gain certain types of knowledge. ... While traditional machine learning algorithms are linear, deep learning algorithms are stacked in a hierarchy of increasing complexity and abstraction.","f5837d85":"> **Implementing on XOR gate**","28be421b":"> **Implemetation of Single Neuron from Scratch**","cdd3f52e":"# **What is a Neuron in Deep Learning?**\n\n***Neurons*** in deep learning models are nodes through which data and computations flow.\n\nNeurons work like this:\n\nThey receive one or more input signals. These input signals can come from either the raw data set or from neurons positioned at a previous layer of the neural net.\nThey perform some calculations.\n\nThey send some output signals to neurons deeper in the neural net through a synapse.\nHere is a diagram of the functionality of a neuron in a deep learning neural net:\n\nThe function of a neuron in a deep learning model\n![image.png](attachment:78990070-334a-4482-b3f9-672ac5580690.png)","a7d1b06a":"> while running for 10 epochs we are getting our expected result at 3rd epoch so we can stop at the nearest epoch where we are getting our value","97d17b2b":"> after running for 3 epochs we are getting our result ","abdb6a48":"# > **This is how one single neuron works**"}}