{"cell_type":{"4325f3ec":"code","273ddef6":"code","ded51524":"code","5d56618c":"code","00c819fe":"code","9bd1971c":"code","dfcb0482":"code","8b8b75ba":"code","f4fe4bf4":"code","dec6e996":"code","7b75ff70":"code","d59979e9":"code","a7a8cb8b":"code","13129de0":"code","aaea3c9a":"code","714f1934":"code","689a0fbb":"code","d242bf01":"code","d886336c":"code","8aeaec86":"code","150e9137":"code","879b01db":"code","9afa5506":"code","5e4f2cfc":"code","f3e1cf39":"code","0fc6e9ee":"code","b42e73f6":"code","7e9bc856":"code","5981ba1c":"code","63cd31e1":"code","48197579":"code","9e5c0074":"code","b4e5b629":"code","5f779cc4":"code","cf979061":"code","8ba189eb":"code","abae0ced":"code","d0d540b3":"code","ea2600ac":"code","816e530b":"code","ec7dbadf":"code","7917ac4a":"code","d3037556":"code","d03a9088":"code","3a6d812b":"code","a138e63c":"code","197c9cf7":"code","2423025e":"code","3dc364fd":"code","6ed1247b":"code","3b83b6c2":"code","3918fdad":"code","82268f37":"code","bc652005":"code","35a6e27c":"code","9ead9033":"code","f6ffcc58":"code","c6a889b9":"code","bc7f6b9e":"code","9864a843":"code","d50b4307":"code","2b953416":"code","fc4f8769":"code","7f236e49":"code","f6f4d2b5":"code","682129fa":"code","4522391b":"code","cbd5ebdb":"code","97e997b5":"code","d05a9860":"code","b38cf84b":"code","7b638042":"code","961e27b5":"code","e9121616":"code","0ce59916":"code","c46bcceb":"code","3c3df7f3":"code","ec9516d5":"code","024e60b6":"code","c2901722":"code","38bcb925":"code","a571606d":"code","99617d5f":"code","37e8bc11":"code","281242b5":"code","3d3e117f":"code","ee9f8fef":"code","79a3b6ad":"code","04a1d747":"markdown","c69ff5cd":"markdown","51c92599":"markdown","ee0bb0e2":"markdown","fe1dd682":"markdown","01735843":"markdown","a8a2c34d":"markdown","04a1d871":"markdown","87751045":"markdown","4dd2d1e8":"markdown","81bef8c2":"markdown","586f0aa2":"markdown","5fa9b176":"markdown","8c275221":"markdown","3049aeca":"markdown","55a02a19":"markdown","fa942085":"markdown","f8b0d5ae":"markdown","443dc631":"markdown","72f62a76":"markdown","51cbca37":"markdown","e6f1d092":"markdown","9a4b7fe0":"markdown","ebfe05a7":"markdown","ec15c29f":"markdown","7c2175a7":"markdown","d61b917e":"markdown","0594b0f0":"markdown","b6ab6a4c":"markdown","96d239ad":"markdown","0aa11db4":"markdown","50c64d15":"markdown","9373034a":"markdown","3341074e":"markdown","ead2ae8d":"markdown","5658c6e6":"markdown","27c66cbf":"markdown","68c77c0e":"markdown","d5bf6193":"markdown","c9d09942":"markdown","d918a012":"markdown","db25c1c0":"markdown","5cff14cb":"markdown","444b158b":"markdown","a3e939d6":"markdown","39090167":"markdown","c189a5be":"markdown","cc2702a9":"markdown","d4e97a3e":"markdown","a0298062":"markdown","3ef3d43a":"markdown","e90fab7a":"markdown","91ac35d6":"markdown","667ebdcc":"markdown","93626583":"markdown","b873c850":"markdown","b9bca3aa":"markdown","2d20a075":"markdown","b9d363b1":"markdown","13b08931":"markdown","59b3a592":"markdown","1e8aa504":"markdown","1e0a4ed0":"markdown","16100528":"markdown","e21ac9af":"markdown","578c17a9":"markdown","aca6be2c":"markdown"},"source":{"4325f3ec":"import re\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport seaborn as sns\nfrom tensorflow import keras\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom collections import Counter\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\n!pip install visualkeras #https:\/\/github.com\/paulgavrikov\/visualkeras\nimport visualkeras\n\ntry: #Part of original notebook to set TPU\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n    \nprint(tf.__version__)","273ddef6":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync #GPU:1 num_replicas\nIMAGE_SIZE = [100, 100]\nEPOCHS = 100 #early stops in model.fit-->need to save best weights","ded51524":"train_folder= '..\/input\/chest-xray-pneumonia\/chest_xray\/train\/'\nval_folder = '..\/input\/chest-xray-pneumonia\/chest_xray\/val\/'\ntest_folder = '..\/input\/chest-xray-pneumonia\/chest_xray\/test\/'","5d56618c":"filepath = [] #list of paths of images of train & validation\ncategories = [] #label","00c819fe":"filenames = os.listdir(os.path.join(train_folder,'NORMAL'))\nfor filename in filenames:\n        filepath.append(os.path.join(train_folder,'NORMAL',filename))\n        categories.append(\"NORMAL\") #0: Normal\n\nfilenames = os.listdir(os.path.join(train_folder,'PNEUMONIA'))\nfor filename in filenames:\n        filepath.append(os.path.join(train_folder,'PNEUMONIA',filename))\n        categories.append(\"PNEUMONIA\") #1: Pneumonia","9bd1971c":"filenames = os.listdir(os.path.join(val_folder,'NORMAL'))\nfor filename in filenames:\n        filepath.append(os.path.join(val_folder,'NORMAL',filename))\n        categories.append(\"NORMAL\") #0: Normal\n        \nfilenames = os.listdir(os.path.join(val_folder,'PNEUMONIA'))\nfor filename in filenames:\n        filepath.append(os.path.join(val_folder,'PNEUMONIA',filename))\n        categories.append(\"PNEUMONIA\") #1: Pneumonia","dfcb0482":"df = pd.DataFrame({'filepath':filepath,'label':categories})\ndf.info\nplot = sns.countplot(x ='label', data = df).set_title('Train+Validation')\nprint(\"Df Train-Vali: \",df.head())\nprint(\"\")\nprint(df['label'].value_counts())","8b8b75ba":"train, vali = train_test_split(df, test_size=0.2,stratify=df['label'],random_state=6) #stratify to keep distribution","f4fe4bf4":"plot_train = sns.countplot(x ='label', data = train).set_title('Train 80%')\nprint('Train 80%: ')\nprint(train['label'].value_counts())","dec6e996":"plot_vali = sns.countplot(x ='label', data = vali).set_title('Validation 20%')\nprint('Validation 20%: ')\nprint(vali['label'].value_counts())","7b75ff70":"load = ImageDataGenerator() #To load images","d59979e9":"#Load images [0 255] and resize images\n\ntrain_set = load.flow_from_dataframe(train,\n                                        x_col = 'filepath',\n                                        y_col = 'label',\n                                        target_size = IMAGE_SIZE,\n                                        batch_size = BATCH_SIZE,\n                                        class_mode = 'binary')\n\nvali_set = load.flow_from_dataframe(vali,\n                                        x_col = 'filepath',\n                                        y_col = 'label',\n                                        target_size = IMAGE_SIZE,\n                                        batch_size = BATCH_SIZE,\n                                        class_mode = 'binary')\n\ntest_set = load.flow_from_directory(test_folder,\n                                        target_size = IMAGE_SIZE,\n                                        batch_size = BATCH_SIZE,\n                                        shuffle = False, #for confusionMatrix\n                                        class_mode = 'binary')\n\n#Check classes in output\nprint(\"train: \",train_set.class_indices)\nprint(\"vali: \",vali_set.class_indices)\nprint(\"test: \",test_set.class_indices)\n#it returns a DataFrameIterator yielding tuples of (x, y) where x is a numpy array containing a batch of images with shape (batch_size, *target_size, channels) and y is a numpy array of corresponding labels.","a7a8cb8b":"VAL_IMG_COUNT = vali_set.samples\nTEST_IMG_COUNT = test_set.samples","13129de0":"print('Train: ',Counter(train_set.classes))\nprint('Validation: ',Counter(vali_set.classes))\nprint('Test: ',Counter(test_set.classes))","aaea3c9a":"#Meaning of output of ImageDataGenerator\n\n#print(len(train_set)) #number of batch in training set (from 0)\n#print(train_set[0][0][1]) #list of images of first batch\n#print((train_set[0][1])) #list of labels of first batch\n#print(train_set[0][0][1].shape) #shape of one image\n#train_set[0][0][1] #float32","714f1934":"plt.figure(figsize=(10,10))\nplt.suptitle('Original training set')\nfor n in range(16):\n    ax = plt.subplot(4,4,n+1)\n    plt.imshow(train_set[0][0][n].astype(np.uint8))  #uint8 to plot\n    if train_set[0][1][n]:\n        plt.title(\"PNEUMONIA\")\n    else:\n        plt.title(\"NORMAL\")\n    plt.axis(\"off\")","689a0fbb":"augment_gen = ImageDataGenerator(zoom_range = 0.2,\n                                   rotation_range=0.2,\n                                   width_shift_range=0.1,\n                                   height_shift_range=0.1,\n                                   ) #to perform augmentation on training set","d242bf01":"aug_train_set =  augment_gen.flow_from_dataframe(train,\n                                        x_col = 'filepath',\n                                        y_col = 'label',\n                                        target_size = IMAGE_SIZE,\n                                        batch_size = BATCH_SIZE,\n                                        class_mode = 'binary')\nprint(\"\\n Aug_train: \",train_set.class_indices)","d886336c":"plt.figure(figsize=(10,10))\nplt.suptitle('Augmented training set')\nfor n in range(16):\n    ax = plt.subplot(4,4,n+1)\n    plt.imshow(aug_train_set[0][0][n].astype(np.uint8))\n    if train_set[0][1][n]:\n        plt.title(\"PNEUMONIA\")\n    else:\n        plt.title(\"NORMAL\")\n    plt.axis(\"off\")","8aeaec86":"counter = Counter(aug_train_set.classes)\n#print(counter.items()) #0: Normal, 1: Pneumonia\n\ncounter['NORMAL'] = counter.pop(0)\ncounter['PNEUMONIA'] = counter.pop(1) #change name for visualization dictionary\n\nprint('Aug_train_set')\nfor i in counter:\n    print(i,': ',counter[i])\n\nplt.bar(counter.keys(),counter.values())\nplt.title('Aug_Train_set')\nplt.show()","150e9137":"COUNT_PNEUMONIA=counter['PNEUMONIA']\nCOUNT_NORMAL=counter['NORMAL']\nTRAIN_IMG_COUNT=aug_train_set.samples\n\nweight_for_0 = (1 \/ COUNT_NORMAL)*(TRAIN_IMG_COUNT)\/2.0 \nweight_for_1 = (1 \/ COUNT_PNEUMONIA)*(TRAIN_IMG_COUNT)\/2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","879b01db":"keras.backend.clear_session() #clear any model","9afa5506":"def conv_block(filters):\n    block = tf.keras.Sequential([\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPool2D()\n    ]\n    )\n    \n    return block","5e4f2cfc":"def dense_block(units, dropout_rate):\n    block = tf.keras.Sequential([\n        tf.keras.layers.Dense(units, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(dropout_rate)\n    ])\n    \n    return block","f3e1cf39":"def build_model():\n    model = tf.keras.Sequential([\n        tf.keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n        \n        tf.keras.layers.Rescaling(scale=1.\/255), #Scaling images between [0 1]\n        \n        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n        tf.keras.layers.MaxPool2D(),\n        \n        conv_block(32),\n        conv_block(64),\n        \n        conv_block(128),\n        tf.keras.layers.Dropout(0.2), #Dropout layers to reduce overfitting\n        \n        conv_block(256),\n        tf.keras.layers.Dropout(0.2),\n        \n        tf.keras.layers.Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        \n        tf.keras.layers.Dense(1, activation='sigmoid') #sigmoid activation function for the last layer, because it's a binary classification\n    ])\n\n    return model","0fc6e9ee":"with strategy.scope():\n    model = build_model()\n\n    METRICS = [\n        'accuracy',\n        tf.keras.metrics.Precision(name='precision'),\n        tf.keras.metrics.Recall(name='recall')\n    ]\n    \n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(),\n        loss='binary_crossentropy',\n        metrics=METRICS\n    )\n    \nmodel.summary()","b42e73f6":"visualkeras.layered_view(model, legend=True)","7e9bc856":"print(\"steps_per_epoch : \",TRAIN_IMG_COUNT \/\/ BATCH_SIZE)\nprint(\"validation_steps : \",VAL_IMG_COUNT \/\/ BATCH_SIZE)","5981ba1c":"checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"CNN_xray_model.h5\",\n                                                    save_best_only=True,verbose=1)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=8,\n                                                     restore_best_weights=True,verbose=1)#check val_loss\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=5, min_lr=0.00001,verbose=1) #if val_loss not improved for patience_epochs-->reduce the learning rate","63cd31e1":"history = model.fit(\n    aug_train_set,\n    steps_per_epoch=TRAIN_IMG_COUNT \/\/ BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=vali_set,\n    validation_steps=VAL_IMG_COUNT \/\/ BATCH_SIZE,\n    class_weight=class_weight,\n    callbacks=[checkpoint_cb,early_stopping_cb,reduce_lr]\n)","48197579":"fig, ax = plt.subplots(1, 4, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","9e5c0074":"#Load model for interactive session\n#keras.backend.clear_session()\n#model = keras.models.load_model('..\/input\/models\/CNN_xray_model.h5')","b4e5b629":"loss, acc, prec, rec = model.evaluate(test_set)","5f779cc4":"#Predicted labels\npredictions = model.predict(test_set)\npredictions = predictions > 0.5\n\n#True labels\norig = test_set.labels","cf979061":"cm = confusion_matrix(orig, predictions)\nprint('Confusion matrix:')\nprint(cm)\nprint('')\n\ncr = classification_report(orig, predictions)\nprint('Classification report:')\nprint(cr)\nprint('')","8ba189eb":"disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['NORMAL','PNEUMONIA'])\ndisp.plot()","abae0ced":"err=[i for i, (x, y) in enumerate(zip(predictions, orig)) if x != y] #check where orig and predictions don't match (wrong classification)\n#print(err)\nprint('errori commessi: ',len(err))\n\nplt.figure(figsize=(10,10))\nplt.suptitle(\"WRONG PREDICTIONS\")\nfor n in range(16): #plot max 16 wrong predictions\n    bn=err[n]\/\/BATCH_SIZE #number of batch of wrong prediction train_set[bn][0][image]\n    ib=err[n]-BATCH_SIZE*bn #number of the image in the batch size train_set[bn][0][ib]\n    #print('id_err:',err[n],' batch:',bn,' diff:',err[n]-BATCH_SIZE*bn)\n    ax = plt.subplot(4,4,n+1)\n    plt.imshow(test_set[bn][0][ib].astype(np.uint8))  #uint8 to plot\n    \n    if test_set[bn][1][ib]: #real value\n        plt.title(\"Real: PNEUMONIA\")\n    else:\n        plt.title(\"Real: NORMAL\")\n    plt.axis(\"off\")","d0d540b3":"keras.backend.clear_session() #delete the previous model (clear model variable)","ea2600ac":"base_model = keras.applications.VGG16(\n    weights='imagenet',  # Load weights pre-trained on ImageNet\n    input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3),\n    include_top=False)  # Do not include the ImageNet classifier at the top","816e530b":"base_model.trainable = False #freeze the base model","ec7dbadf":"inputs = keras.layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n\n#Preprocess for VGG16\nx = tf.keras.applications.vgg16.preprocess_input(inputs)\n\n# We make sure that the base_model is running in inference mode here, passing `training=False`\nx = base_model(x, training=False) #-->not updating weights of this part of the model\n\n# Convert features of shape `base_model.output_shape[1:]` to vectors\nx = keras.layers.GlobalAveragePooling2D()(x)\n\nx = keras.layers.Dense(128, activation='relu')(x)\nx = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n\n# A Dense classifier with a single unit (binary classification)\noutputs = keras.layers.Dense(1, activation='sigmoid')(x)\nmodel = keras.Model(inputs, outputs)\n\nmodel.summary()","7917ac4a":"early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=6,\n                                                     restore_best_weights=True,verbose=1) #check val_loss\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=3, min_lr=1e-5 ,verbose=1) #min_lr as input for fine tuning next","d3037556":"model.compile(\n    optimizer=keras.optimizers.Adam(),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\n\nhistory = model.fit(\n    aug_train_set,\n    steps_per_epoch=TRAIN_IMG_COUNT \/\/ BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=vali_set,\n    validation_steps=VAL_IMG_COUNT \/\/ BATCH_SIZE,\n    class_weight=class_weight,\n    callbacks=[early_stopping_cb, reduce_lr]\n)","d03a9088":"fig, ax = plt.subplots(1, 2, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","3a6d812b":"# Unfreeze the base model\nbase_model.trainable = True\n\nmodel.summary()\n\nmodel.compile(optimizer=keras.optimizers.Adam(1e-5), #Very low learning rate\n              loss='binary_crossentropy',\n              metrics='accuracy')","a138e63c":"checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"VGG16_xray_model.h5\",\n                                                    save_best_only=True,verbose=1)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5,\n                                                     restore_best_weights=True,verbose=1) #check val_loss by default for the early stop (check if improve)","197c9cf7":"#Be careful to stop before overfitting (check the validation_loss)\nhistory = model.fit(\n    aug_train_set,\n    steps_per_epoch=TRAIN_IMG_COUNT \/\/ BATCH_SIZE,\n    epochs=100,\n    validation_data=vali_set,\n    validation_steps=VAL_IMG_COUNT \/\/ BATCH_SIZE,\n    class_weight=class_weight,\n    callbacks=[checkpoint_cb,early_stopping_cb]\n)","2423025e":"fig, ax = plt.subplots(1, 2, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","3dc364fd":"#Load model for interactive session\n#keras.backend.clear_session()\n#model = keras.models.load_model('..\/input\/models\/VGG16_xray_model.h5')","6ed1247b":"loss, acc = model.evaluate(test_set)","3b83b6c2":"#Predicted labels\npredictions = model.predict(test_set)\npredictions = predictions > 0.5\n\n#True labels\norig = test_set.labels","3918fdad":"cm = confusion_matrix(orig, predictions)\nprint('Confusion matrix:')\nprint(cm)\nprint('')\n\ncr = classification_report(orig, predictions)\nprint('Classification report:')\nprint(cr)\nprint('')","82268f37":"disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['NORMAL','PNEUMONIA'])\ndisp.plot()","bc652005":"err=[i for i, (x, y) in enumerate(zip(predictions, orig)) if x != y] #check where orig and predictions don't match (wrong classification)\n#print(err)\nprint('errori commessi: ',len(err))\n\nplt.figure(figsize=(10,10))\nplt.suptitle(\"WRONG PREDICTIONS\")\nfor n in range(16): #plot max 16 wrong predictions\n    bn=err[n]\/\/BATCH_SIZE #number of batch of wrong prediction train_set[bn][0][image]\n    ib=err[n]-BATCH_SIZE*bn #number of the image in the batch size train_set[bn][0][ib]\n    #print('id_err:',err[n],' batch:',bn,' diff:',err[n]-BATCH_SIZE*bn)\n    ax = plt.subplot(4,4,n+1)\n    plt.imshow(test_set[bn][0][ib].astype(np.uint8))  #uint8 to plot\n    \n    if test_set[bn][1][ib]: #real value\n        plt.title(\"Real: PNEUMONIA\")\n    else:\n        plt.title(\"Real: NORMAL\")\n    plt.axis(\"off\")","35a6e27c":"keras.backend.clear_session()","9ead9033":"base_model = keras.applications.Xception(\n    weights='imagenet',  # Load weights pre-trained on ImageNet\n    input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3),\n    include_top=False)  # Do not include the ImageNet classifier at the top","f6ffcc58":"base_model.trainable = False #freeze the base model","c6a889b9":"inputs = keras.layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n\n#Preprocess for Xception\nx = tf.keras.applications.xception.preprocess_input(inputs)\n\n# We make sure that the base_model is running in inference mode here passing `training=False`\nx = base_model(x, training=False)\n\n# Convert features of shape `base_model.output_shape[1:]` to vectors\nx = keras.layers.GlobalAveragePooling2D()(x)\n\nx = keras.layers.Dense(128, activation='relu')(x)\nx = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n\n# A Dense classifier with a single unit (binary classification)\noutputs = keras.layers.Dense(1, activation='sigmoid')(x)\nmodel = keras.Model(inputs, outputs)\n\nmodel.summary()","bc7f6b9e":"early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=6,\n                                                     restore_best_weights=True,verbose=1)#check val_loss\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=3, min_lr=1e-5 ,verbose=1) #min_lr as input for fine tuning next","9864a843":"model.compile(\n    optimizer=keras.optimizers.Adam(),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\n\nhistory = model.fit(\n    aug_train_set,\n    steps_per_epoch=TRAIN_IMG_COUNT \/\/ BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=vali_set,\n    validation_steps=VAL_IMG_COUNT \/\/ BATCH_SIZE,\n    class_weight=class_weight,\n    callbacks=[early_stopping_cb, reduce_lr]\n)","d50b4307":"fig, ax = plt.subplots(1, 2, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","2b953416":"# Unfreeze the base model\nbase_model.trainable = True\n\nmodel.summary()\n\nmodel.compile(optimizer=keras.optimizers.Adam(1e-5), #Very low learning rate\n              loss='binary_crossentropy',\n              metrics='accuracy')","fc4f8769":"checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"Xception_xray_model.h5\",\n                                                    save_best_only=True,verbose=1)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5,\n                                                     restore_best_weights=True,verbose=1) #check val_loss","7f236e49":"history = model.fit(\n    aug_train_set,\n    steps_per_epoch=TRAIN_IMG_COUNT \/\/ BATCH_SIZE,\n    epochs=100,\n    validation_data=vali_set,\n    validation_steps=VAL_IMG_COUNT \/\/ BATCH_SIZE,\n    class_weight=class_weight,\n    callbacks=[checkpoint_cb,early_stopping_cb]\n)","f6f4d2b5":"fig, ax = plt.subplots(1, 2, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","682129fa":"#Load model for interactive session\n#keras.backend.clear_session()\n#model = keras.models.load_model('..\/input\/models\/Xception_xray_model.h5')","4522391b":"loss, acc = model.evaluate(test_set)","cbd5ebdb":"#Predicted labels\npredictions = model.predict(test_set)\npredictions = predictions > 0.5\n\n#True labels\norig = test_set.labels","97e997b5":"cm = confusion_matrix(orig, predictions)\nprint('Confusion matrix:')\nprint(cm)\nprint('')\n\ncr = classification_report(orig, predictions)\nprint('Classification report:')\nprint(cr)\nprint('')","d05a9860":"disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['NORMAL','PNEUMONIA'])\ndisp.plot()","b38cf84b":"err=[i for i, (x, y) in enumerate(zip(predictions, orig)) if x != y] #check where orig and predictions don't match (wrong classification)\n#print(err)\nprint('errori commessi: ',len(err))\n\nplt.figure(figsize=(10,10))\nplt.suptitle(\"WRONG PREDICTIONS\")\nfor n in range(16): #plot max 16 wrong predictions\n    bn=err[n]\/\/BATCH_SIZE #number of batch of wrong prediction train_set[bn][0][image]\n    ib=err[n]-BATCH_SIZE*bn #number of the image in the batch size train_set[bn][0][ib]\n    #print('id_err:',err[n],' batch:',bn,' diff:',err[n]-BATCH_SIZE*bn)\n    ax = plt.subplot(4,4,n+1)\n    plt.imshow(test_set[bn][0][ib].astype(np.uint8))  #uint8 to plot\n    \n    if test_set[bn][1][ib]: #real value\n        plt.title(\"Real: PNEUMONIA\")\n    else:\n        plt.title(\"Real: NORMAL\")\n    plt.axis(\"off\")","7b638042":"keras.backend.clear_session()","961e27b5":"base_model = keras.applications.ResNet152V2(\n    weights='imagenet',  # Load weights pre-trained on ImageNet\n    input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3),\n    include_top=False)  # Do not include the ImageNet classifier at the top","e9121616":"base_model.trainable = False #freeze the base model","0ce59916":"inputs = keras.layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n\n#Preprocess for ResNet152V2\nx = tf.keras.applications.resnet_v2.preprocess_input(inputs)\n\n# We make sure that the base_model is running in inference mode here, passing `training=False`\nx = base_model(x, training=False)\n\n# Convert features of shape `base_model.output_shape[1:]` to vectors\nx = keras.layers.GlobalAveragePooling2D()(x)\n\nx = keras.layers.Dense(128, activation='relu')(x)\nx = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n\n# A Dense classifier with a single unit (binary classification)\noutputs = keras.layers.Dense(1, activation='sigmoid')(x)\nmodel = keras.Model(inputs, outputs)\n\nmodel.summary()","c46bcceb":"early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=6,\n                                                     restore_best_weights=True,verbose=1)#check val_loss\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=3, min_lr=1e-5 ,verbose=1) #min_lr as input for fine tuning next","3c3df7f3":"model.compile(\n    optimizer=keras.optimizers.Adam(),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\n\nhistory = model.fit(\n    aug_train_set,\n    steps_per_epoch=TRAIN_IMG_COUNT \/\/ BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=vali_set,\n    validation_steps=VAL_IMG_COUNT \/\/ BATCH_SIZE,\n    class_weight=class_weight,\n    callbacks=[early_stopping_cb, reduce_lr]\n)","ec9516d5":"fig, ax = plt.subplots(1, 2, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","024e60b6":"# Unfreeze the base model\nbase_model.trainable = True\n\nmodel.summary()\n\nmodel.compile(optimizer=keras.optimizers.Adam(1e-5),  # Very low learning rate\n              loss='binary_crossentropy',\n              metrics='accuracy')","c2901722":"checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"ResNet152V2_xray_model.h5\",\n                                                    save_best_only=True,verbose=1)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5,\n                                                     restore_best_weights=True,verbose=1)#check val_loss","38bcb925":"history = model.fit(\n    aug_train_set,\n    steps_per_epoch=TRAIN_IMG_COUNT \/\/ BATCH_SIZE,\n    epochs=100,\n    validation_data=vali_set,\n    validation_steps=VAL_IMG_COUNT \/\/ BATCH_SIZE,\n    class_weight=class_weight,\n    callbacks=[checkpoint_cb,early_stopping_cb]\n)","a571606d":"fig, ax = plt.subplots(1, 2, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","99617d5f":"#Load model for interactive session\n#keras.backend.clear_session()\n#model = keras.models.load_model('..\/input\/models\/Xception_xray_model.h5')","37e8bc11":"loss, acc = model.evaluate(test_set)","281242b5":"#Predicted labels\npredictions = model.predict(test_set)\npredictions = predictions > 0.5\n\n#True labels\norig = test_set.labels","3d3e117f":"cm = confusion_matrix(orig, predictions)\nprint('Confusion matrix:')\nprint(cm)\nprint('')\n\ncr = classification_report(orig, predictions)\nprint('Classification report:')\nprint(cr)\nprint('')","ee9f8fef":"disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['NORMAL','PNEUMONIA'])\ndisp.plot()","79a3b6ad":"err=[i for i, (x, y) in enumerate(zip(predictions, orig)) if x != y] #check where orig and predictions don't match (wrong classification)\n#print(err)\nprint('errori commessi: ',len(err))\n\nplt.figure(figsize=(10,10))\nplt.suptitle(\"WRONG PREDICTIONS\")\nfor n in range(16): #plot max 16 wrong predictions\n    bn=err[n]\/\/BATCH_SIZE #number of batch of wrong prediction train_set[bn][0][image]\n    ib=err[n]-BATCH_SIZE*bn #number of the image in the batch size train_set[bn][0][ib]\n    #print('id_err:',err[n],' batch:',bn,' diff:',err[n]-BATCH_SIZE*bn)\n    ax = plt.subplot(4,4,n+1)\n    plt.imshow(test_set[bn][0][ib].astype(np.uint8))  #uint8 to plot\n    \n    if test_set[bn][1][ib]==1: #real value\n        plt.title(\"Real: PNEUMONIA\")\n    else:\n        plt.title(\"Real: NORMAL\")\n    plt.axis(\"off\")","04a1d747":"First of all, load the images of the sets (use *ImageDataGenerator* without specifying any transformation)","c69ff5cd":"Crate new model on top and include preprocessing step for the input mages in the model","51c92599":"# 8 Transfer Learning Xception + Fine Tuning","ee0bb0e2":"Train the model reducing the learning rate and saving the best model","fe1dd682":"Crate new model on top and include preprocessing step for the input mages in the model","01735843":"**Confusion Matrix**\n\nCreate the confusion matrix and the report of the performance","a8a2c34d":"Now we will recreate the validation set and the training set from the dataframe that we have created. Let's perform a **Split training set 80% - validation set 20%**. To do this let's use the *train_test_split* function and care to set *stratify*: it's important so the training set and validation set that we crate will have the same distribution","04a1d871":"The images are imported with pixel value between [0 255] and then are resized with the IMAGE_SIZE, specified before. Be careful to set Shuffle=False for the test set, this is important in order to avoid any possible wrong classifications after the execution of the confusion matrix. These images will be imported in batches, whose size is BATCH_SIZE. ","87751045":"Plot some images of first batch of training set after data augmentation","4dd2d1e8":"Crate new model on top and include preprocessing step for the input mages in the model","81bef8c2":"\n\nPneumonia is an inflammation of the lung tissue caused by an infection that can lead to serious health problems and even death. To help doctors analyze X-ray images to diagnose pneumonia, Deep Learning has become increasingly important. However, the accuracy of neural networks is a crucial aspect. In our work, we took an existing project on pneumonia detection using Deep Learning and applied various methods to improve the performance of the model.\n\nThe [original project](https:\/\/www.kaggle.com\/amyjang\/tensorflow-pneumonia-classification-on-x-rays) used a database with a total of 5856 X-ray images, which were first downsized to [180 180] pixels and pixel values rescaled to [0 1]. 624 of these images were reserved for testing and the remaining images were split into training and validation sets in a ratio of 80%\/20%. Since the dataset contains more images of pneumonia than healthy radiographs, the data must be balanced for training. The weights of the pneumonia images and the normal images were adjusted so that a normal image has a higher impact on the neural network. A new convolutional neural network was built from scratch, consisting mainly of convolutional blocks and dense layers. The training was performed in two steps: the first with 25 epochs with a fixed learning rate and then a further training with 100 epochs, with early stopping and exponential decay of the learning rate. The TPU accelerator was used to run the code.\n\nIn our project, we tried to solve some of the problems and improve the performance. First, overfitting was reduced through data augmentation. Starting with the given images, new images were created for every epoch using transformers to zoom, rotate and shift. The ImageDataGenerator function was used to apply the transforms, which unfortunately required a switch to the GPU for training and significantly increased the training time. With the data extension alone, we were already able to increase the performance of the model by roughly 10%. The next step was to implement transfer learning using three different models: VGG16, Xception and ResNet are 3 CNN models that have been trained on the ImageNet database and the trained models were made available on Keras. To implement these models in our project, we only took the base of the imported models and froze them first. We built new blocks on top of the base and trained the model to fit the new weights. In the end we unfreezed the base again and finetuned the entire model. For all three models, we were again able to improve performance by a few percent, resulting in both accuracy and precision of about 0.93.\n\nIn this project, we have shown the importance of having a large dataset for training to achieve more independent learning and avoid overfitting, and that data augmentation can be a useful source of unseen images when there is not enough original material. Neural networks trained for similar tasks can be adapted to a new task with great performance, compensating for the lack of data and significantly reducing training time. Overall, Deep Learning has proven to be a useful option to quickly analyse X-ray images and assist doctors in diagnosis.\n","586f0aa2":"Let's plot some images of first batch of training set","5fa9b176":"Define and early stop to avoid overfitting and using a decreasing learning rate","8c275221":"# 5 train & test CNN model (original notebook)","3049aeca":"# 6 Transfer Learning\nLet's try to perform [transfer learning](https:\/\/keras.io\/guides\/transfer_learning\/) to create an adapt model for our situation.\nWe will try to use the base of the different CNN models: VGG16, Xcpetion and ResNet152V2","55a02a19":"**Freeze** the base of the model","fa942085":"Define and early stop to avoid overfitting and using a decreasing learning rate","f8b0d5ae":"# 9 Transfer Learning ResNet + Fine Tuning","443dc631":"Since the images labelled as Normal are less than those one labelled as Pneumonia, each image labelled as Normal will be weighted more to balance the data, so the CNN model will work better due to balanced training data.","72f62a76":"**Confusion Matrix**","51cbca37":"# 4 Build CNN of the [original notebook](https:\/\/www.kaggle.com\/amyjang\/tensorflow-pneumonia-classification-on-x-rays?scriptVersionId=39162263&cellId=33)","e6f1d092":"Load the images path and label of the training set","9a4b7fe0":"Evaluate the test set","ebfe05a7":"Save the best model","ec15c29f":"Evaluate the test set","7c2175a7":"Here we import the necessary libraries.\n\nIn this notebook we\u2019re using GPUs instead of TPUs in order to implement the data augmentation performing *ImageDataGenerator* function. Therefore, the implementation time of the code will also be much longer than the original notebook.\n","d61b917e":"Let's create a **dataframe containing all images of test and validation set**. \nIt's composed by 3883 images labelled as \"Pneumonia\" and 1349 images labelled as \"Normal\"","0594b0f0":"**Plot some wrong classified images**","b6ab6a4c":"Get the directory path for the training, validation and test set","96d239ad":"We define only geometrical random transformations that can be relevant for our images","0aa11db4":"Evaluate the test set","50c64d15":"Let's perform [data augmentation](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator) on the training set, trying to reduce overfitting that affected the previous notebook. To augment our images let's use the function *ImageDataGenerator*: this function will modify our entire training set of images with random transformations at each epoch (so the model during the training phase will be trained on new images at each epoch)","9373034a":"**Plot some wrong classified images**","3341074e":"We set some hyperparameters such as the image size, the batch size and the number of epochs used to train the following models. \n\nImages will be rescaled to the defined IMAGE_SIZE: the size is set to [100,100] and we get performances similar to models trained with larger images (so with images of higher quality), but with a shorter computational time. \n\nThe number of EPOCHS is set to a high number: to avoid the risk of overfitting, we add some \u2018\u2019early stops\u2019\u2019 in the training part. Moreover, it is helpful from the computational point of view. \n\nThe BATCH_SIZE using GPU is set to 16 (*strategy.num_replicas_in_sync*=1 for GPU): we have to increase\/decrease the batch size according to computational resources and model\u2019s performances. Size of 16 seems quite good for our models: the train part is slower, but we have not hardware problems and the models converge faster.","ead2ae8d":"Evaluate the test set","5658c6e6":"Define and early stop to avoid overfitting and using a decreasing learning rate","27c66cbf":"As we can see the new validation set is composed by 1047 images and the new training set is composed by 4185 images, and they have the same distribution between the two classes","68c77c0e":"The chest X-ray images that we are using come from this [dataset](https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia): the dataset is organized into 3 folders (train, val, test) and each one contains two subfolders: one for \"PNEUMONIA\" and the other for \"NORMAL\" cases. There's a total of 5863 images, saved in JPEG type and there are two classes (Pneumonia\/Normal), so our models will perform a binary classification. The validation set is composed only by 16 images, while the training set is composed by 5216 images, so we will create a new validation set to get a 80:20 standard division for the training set and the validation set. The test set contains 624 images (234 Normal and 390 Pneumonia) and we decide to keep it in order to compare the performance between our model and the original notebook on the same test set.  \n","d5bf6193":"# 3 Data Augmentation","c9d09942":"**Fine Tuning**\n\nUnfreeze the base model","d918a012":"Train the model. Since there are only two possible labels for the image, we will use the *binary_crossentropy* loss","db25c1c0":"**Confusion Matrix**\n\nCreate the confusion matrix and the report of the performance","5cff14cb":"Using **[VGG16](https:\/\/keras.io\/api\/applications\/vgg\/)**","444b158b":"Create a convolution block and a dense layer block","a3e939d6":"**Plot some wrong classified images**","39090167":"Load the images path and label of the validation set","c189a5be":"# 2. Loading data","cc2702a9":"**Confusion Matrix**\n\nCreate the confusion matrix and the report of the performance","d4e97a3e":"**Freeze** the base of the model","a0298062":"Save the best model","3ef3d43a":"# 7 Transfer Learning VGG16 + Fine Tuning\n","e90fab7a":"Create an empty list to save images file path and the label (Pneumonia\/Normal), for the images of training and validation set","91ac35d6":"**Plot some wrong classified images**","667ebdcc":"Now we have to **correct data imbalancing** for the training set, because we have more images classified as pneumonia than normal.","93626583":"Now let's perform the **Data augmentation** only on the training set. To do this we need to specify the random transformations that we want to do and reload all the images of the training set","b873c850":"# 1. Setup","b9bca3aa":"**Fine Tuning**\n\nUnfreeze the base model","2d20a075":"But there's a problem in our dataset: the class imbalance, that may lead problems to the performance of our models. So **check the class imbalance in the training set**","b9d363b1":"Using **[ResNet152V2](https:\/\/keras.io\/api\/applications\/resnet\/#resnet152v2-function)**","13b08931":"# Abstract","59b3a592":"Save the best model","1e8aa504":"# Introduction\n\nDeep neural networks are now the state-of-the-art machine learning models across a variety of areas. Regarding the medical domain, it can be a huge potential for medical imaging technology, medical data analysis, medical diagnostics and healthcare in general.\n\nThe implementation of clinical-decision support algorithms for medical imaging aid in expediting the diagnosis of these treatable conditions, thereby facilitating earlier treatment, resulting in improved clinical outcomes. \n\nThis notebook will show how using GPU, in order to build and train convolution neural networks that are able to predict if an X-ray scans shows presence of pneumonia, it\u2019s possible to get results with higher accuracy with data augmentation and transfer learning as additional tools. \n","1e0a4ed0":"Using **[Xception](https:\/\/keras.io\/api\/applications\/xception\/)**","16100528":"Perform **FINE TUNING : UNFREEZE ALL LAYERS**\n\nOnce your model has converged on the new data, unfreeze all or part of the base model and retrain the whole model end-to-end with a very low learning rate.","e21ac9af":"**Freeze** the base of the model","578c17a9":"Let's build the model in a Sequential way, adding every layer we prefer. We include a rescaling layer to scale pixel values between [0 1], cause CNN works better with small numbers. The last layer is a Dense layer, whose output is one: Pneumonia or Normal case (binary classification). ","aca6be2c":"Let's use the CNN model defined in the original notebook and try to improve the performance. Our aim is trying to reduce overfitting of the original model"}}