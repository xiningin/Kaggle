{"cell_type":{"18973ba9":"code","f6bbceae":"code","66937a37":"code","fb84d487":"code","481e4232":"code","92d2c02d":"code","6f9d6623":"code","9ab55fa2":"code","49368d04":"code","aa37bc1b":"code","4da21e9b":"code","4fa29912":"code","cc0a3206":"code","70afa7d4":"code","5947c6fe":"code","09bed1fe":"code","8089624c":"code","70a5f23c":"code","2e179bad":"code","f38e0d7a":"code","9a6e308f":"code","3d948e99":"code","cdc21cc5":"code","b6602d22":"code","d30fd66f":"code","459ffd31":"code","97452949":"markdown","d4fbe2a4":"markdown","810c0db4":"markdown","341c1f19":"markdown","30fd97b8":"markdown","efdc8dad":"markdown"},"source":{"18973ba9":"import keras\nfrom keras.layers import Dense, Conv2D, BatchNormalization, Activation\nfrom keras.layers import AveragePooling2D, Input, Flatten\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.datasets import cifar10\nfrom keras.utils import to_categorical\nimport numpy as np\nimport os","f6bbceae":"# Training parameters\nbatch_size = 32\nepochs = 100\nnum_classes = 10","66937a37":"# Load the CIFAR10 data.\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()","fb84d487":"# Input image dimensions.\ninput_shape = x_train.shape[1:]\ninput_shape","481e4232":"# Normalize data.\nx_train = x_train.astype('float32') \/ 255\nx_test = x_test.astype('float32') \/ 255","92d2c02d":"# Subtracting pixel mean improves accuracy\nx_train_mean = np.mean(x_train, axis=0)\nx_train -= x_train_mean\nx_test -= x_train_mean","6f9d6623":"print('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\nprint('y_train shape:', y_train.shape)","9ab55fa2":"# Convert class vectors to binary class matrices.\ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)","49368d04":"def resnet_layer(inputs,\n                 num_filters=16,\n                 kernel_size=3,\n                 strides=1,\n                 activation='relu',\n                 batch_normalization=True,\n                 conv_first=True):\n    \n    conv = Conv2D(num_filters,\n                  kernel_size=kernel_size,\n                  strides=strides,\n                  padding='same',\n                  kernel_initializer='he_normal',\n                  kernel_regularizer=l2(1e-4))\n\n    x = inputs\n    if conv_first:\n        x = conv(x)\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n    else:\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n        x = conv(x)\n    return x","aa37bc1b":"n = 3\ndepth = n * 6 + 2","4da21e9b":"def resnet(input_shape, depth, num_classes=10):\n    # Start model definition.\n    num_filters = 16\n    num_res_blocks = int((depth - 2) \/ 6)\n\n    inputs = Input(shape=input_shape)\n    x = resnet_layer(inputs=inputs)\n    # Instantiate the stack of residual units\n    for stack in range(3):\n        for res_block in range(num_res_blocks):\n            strides = 1\n            if stack > 0 and res_block == 0:  # first layer but not first stack\n                strides = 2  # downsample\n            y = resnet_layer(inputs=x,\n                             num_filters=num_filters,\n                             strides=strides)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters,\n                             activation=None)\n            if stack > 0 and res_block == 0:  # first layer but not first stack\n                # linear projection residual shortcut connection to match\n                # changed dims\n                x = resnet_layer(inputs=x,\n                                 num_filters=num_filters,\n                                 kernel_size=1,\n                                 strides=strides,\n                                 activation=None,\n                                 batch_normalization=False)\n            x = keras.layers.add([x, y])\n            x = Activation('relu')(x)\n        num_filters *= 2\n\n    # Add classifier on top.\n    # v1 does not use BN after last shortcut connection-ReLU\n    x = AveragePooling2D(pool_size=8)(x)\n    y = Flatten()(x)\n    outputs = Dense(num_classes,\n                    activation='softmax',\n                    kernel_initializer='he_normal')(y)\n\n    # Instantiate model.\n    model = Model(inputs=inputs, outputs=outputs)\n    return model","4fa29912":"def lr_schedule(epoch):\n    lr = 1e-3\n    if epoch > 80:\n        lr *= 1e-1\n    return lr","cc0a3206":"model = resnet(input_shape=input_shape, depth=depth)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(lr_schedule(0)),\n              metrics=['accuracy'])","70afa7d4":"model.summary()","5947c6fe":"# Prepare model model saving directory.\nsave_dir = os.path.join(os.getcwd(), 'saved_models')\nmodel_name = 'ResNet'\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nfilepath = os.path.join(save_dir, model_name)","09bed1fe":"# Prepare callbacks for model saving and for learning rate adjustment.\ncheckpoint = ModelCheckpoint(filepath=filepath,\n                             monitor='val_acc',\n                             verbose=1,\n                             save_best_only=True)\n\nlr_scheduler = LearningRateScheduler(lr_schedule)\n\nlr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n                               cooldown=0,\n                               patience=5,\n                               min_lr=0.5e-6)\n\ncallbacks = [checkpoint, lr_reducer, lr_scheduler]","8089624c":"h=model.fit(x_train, y_train,\n            batch_size=batch_size,\n            epochs=epochs,\n            validation_data=(x_test, y_test),\n            shuffle=True,\n            callbacks=callbacks)","70a5f23c":"model.save('resnet.h5')","2e179bad":"model.save_weights('resnet_w.hdf5')","f38e0d7a":"import pickle\n\nf=open('resnet_h.pckl','wb')\npickle.dump(h.history,f)\nf.close()","9a6e308f":"import matplotlib.pyplot as plt\nepoch_nums = range(1, epochs+1)\ntraining_loss = h.history[\"loss\"]\nvalidation_loss = h.history[\"val_loss\"]\nplt.plot(epoch_nums , training_loss)\nplt.plot(epoch_nums , validation_loss)\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['training','validation'], loc='upper right')\nplt.show()","3d948e99":"scores = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","cdc21cc5":"def testImage(result):\n    print(result) \n    if result[0][0]==1: \n        print(\"Aeroplane\") \n    elif result[0][1]==1: \n        print('Automobile') \n    elif result[0][2]==1: \n        print('Bird') \n    elif result[0][3]==1: \n        print('Cat') \n    elif result[0][4]==1: \n        print('Deer') \n    elif result[0][5]==1: \n        print('Dog') \n    elif result[0][6]==1: \n        print('Frog') \n    elif result[0][7]==1: \n        print('Horse') \n    elif result[0][8]==1: \n        print('Ship') \n    elif result[0][9]==1: \n        print('Truck') \n    else:\n        print('Error')","b6602d22":"from keras.preprocessing import image\n\ntest_image1 =image.load_img(\"..\/input\/imagetest\/Image\/horse1.jpg\",target_size =(32,32,3))\ntest_image =image.img_to_array(test_image1) \ntest_image =np.expand_dims(test_image, axis =0) \nresult = model.predict(test_image)\nplt.imshow(test_image1)\ntestImage(result)","d30fd66f":"y_pred_test = model.predict(x_test)\ny_test_classes = np.argmax(y_pred_test, axis=1)\ny_pred_test_classes = np.argmax(y_pred_test, axis=1)\ny_pred_test_max_probas = np.max(y_pred_test, axis=1)","459ffd31":"cols = 8\nrows = 2\nNUM_CLASSES = 10\ncifar10_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \n                   \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\nfig = plt.figure(figsize=(2 * cols - 1, 3 * rows - 1))\nfor i in range(cols):\n    for j in range(rows):\n        y_test = y_test.astype(int)\n        random_index = np.random.randint(0, len(y_test))\n        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n        ax.grid('off')\n        ax.axis('off')\n        ax.imshow(x_test[random_index, :])\n        pred_label =  cifar10_classes[y_pred_test_classes[random_index]]\n        pred_proba = y_pred_test_max_probas[random_index]\n        true_label = cifar10_classes[y_test_classes[random_index]]\n        ax.set_title(\"pred: {}\\nscore: {:.3}\\ntrue: {}\".format(\n               pred_label, pred_proba, true_label\n        ))\nplt.show()","97452949":"# Trained Model Test","d4fbe2a4":"# Compile the Model","810c0db4":"# Trained Model Score","341c1f19":"# Train the Model","30fd97b8":"# Test by Dataset","efdc8dad":"# Loss"}}