{"cell_type":{"87b49c53":"code","6c93528b":"code","1e075f4c":"code","0fe578d4":"code","b77e2f1e":"code","60644384":"code","896d23ad":"code","21efd0f2":"code","f1724a81":"code","fbf16ae0":"code","3fc723d2":"code","0c92264c":"code","b91f4b85":"code","14b992ae":"code","0580c7bb":"code","9c286839":"code","00097978":"code","bd0b9f6c":"code","e7cbc0cf":"code","257c4434":"code","7e5f2cfa":"code","5f94ed44":"code","c4544a81":"code","bb97b59b":"code","1068d538":"code","be7230e8":"code","93f9679c":"code","12e8331d":"code","a4cbde89":"code","3ced6ff9":"code","3db1a3cf":"code","892d3dce":"code","2076aaeb":"code","e9089c84":"markdown","fbf9e09f":"markdown","4817d1b3":"markdown","dbfad85e":"markdown","3f323e88":"markdown","8f2b0bbe":"markdown","1a4b61d4":"markdown","1090f7ab":"markdown","9d1db661":"markdown","7c1599bd":"markdown","f91ea44e":"markdown","80ffe6fc":"markdown","cb153293":"markdown","999af6dc":"markdown","51c35327":"markdown","c7d46e6c":"markdown"},"source":{"87b49c53":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","6c93528b":"def reduce_memory_usage(df):\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != 'object':\n            c_min = df[col].min()\n            c_max = df[col].max()\n            \n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    pass\n        else:\n            df[col] = df[col].astype('category')\n    \n    return df","1e075f4c":"df=pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/train.csv\")\nreduce_memory_usage(df)\ntest=pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/test.csv\")\nreduce_memory_usage(test)","0fe578d4":"df.head()","b77e2f1e":"df.describe().T","60644384":"df.isnull().sum()","896d23ad":"df.info()","21efd0f2":"for col in df.columns:\n    print(f\"The total unique values in {col} are {len(df[col].unique())}\")","f1724a81":"df.drop([\"Soil_Type7\",\"Soil_Type15\"],axis=1,inplace=True)","fbf16ae0":"import matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('ggplot')","3fc723d2":"plt.figure(figsize=(15,10))\nsns.countplot(df.Cover_Type)\nplt.plot()","0c92264c":"df['Cover_Type'].value_counts(ascending=False)","b91f4b85":"try:\n    fig, axes=plt.subplots(2,5,figsize=(30,15))\n    j=0\n    i=0\n    for k in range(1,11):\n        if j==5:\n            i+=1\n            j=0\n        sns.kdeplot(df.loc[:,df.columns[k]],ax=axes[i,j])\n        plt.gca().set_title(f\"{df.columns[k]}\")\n        j+=1\nexcept:\n    print(\"Got all the columns\")","14b992ae":"def outlier_function(df, col_name):\n    first_quartile = np.percentile(np.array(df[col_name].tolist()), 25)\n    third_quartile = np.percentile(np.array(df[col_name].tolist()), 75)\n    IQR = third_quartile - first_quartile\n    \n    upper_limit = third_quartile+(3*IQR)\n    lower_limit = first_quartile-(3*IQR)\n    outlier_count = 0\n    \n    for value in df[col_name].tolist():\n        if (value < lower_limit) | (value > upper_limit):\n            outlier_count += 1\n    return lower_limit, upper_limit, outlier_count","0580c7bb":"for col in  df.columns[:10]:\n    out=outlier_function(df,col)\n    if out[2]>0:\n        print(f\"There are {out[2]} outliers in {col}\")","9c286839":"try:\n    fig_out, axes_out=plt.subplots(2,5,figsize=(30,15))\n    j=0\n    i=0\n    for k in range(1,11):\n        if j==5:\n            i+=1\n            j=0\n        sns.boxplot(y=df.columns[k],x=df.columns[-1],data=df,ax=axes_out[i,j])\n        plt.gca().set_title(f\"{df.columns[k]}\")\n        j+=1\nexcept:\n    print(\"Got all the columns\")","00097978":"sns.heatmap(df.corr())","bd0b9f6c":"cb_params = {'iterations': 10000,\n             'learning_rate': 0.218904169525507,\n             'loss_function': 'MultiClass',\n             'eval_metric': 'Accuracy',\n             'l2_leaf_reg': 1.6163189485316596,\n             'bagging_temperature': 0.14353551008899088,\n             'random_strength': 1.29,\n             'depth': 10,\n             'grow_policy': 'SymmetricTree',\n             'leaf_estimation_method': 'Gradient',\n             'od_type': 'Iter',\n             'early_stopping_rounds': 300,\n             'border_count': 254,\n             'use_best_model': True,\n             'min_data_in_leaf': 150,\n             'task_type': 'GPU',\n             'random_seed': 42}","e7cbc0cf":"from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,roc_auc_score\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\nimport pickle\nfrom sklearn import model_selection\nfrom catboost import CatBoostClassifier","257c4434":"df=pd.concat([df,\n              df[df[\"Cover_Type\"]==5],\n              df[df[\"Cover_Type\"]==5],\n              df[df[\"Cover_Type\"]==5],\n              df[df[\"Cover_Type\"]==5],\n              df[df[\"Cover_Type\"]==5],\n              df[df[\"Cover_Type\"]==5],\n              df[df[\"Cover_Type\"]==4],\n              df[df[\"Cover_Type\"]==4],\n              df[df[\"Cover_Type\"]==4],\n              df[df[\"Cover_Type\"]==4],\n              df[df[\"Cover_Type\"]==4],\n              df[df[\"Cover_Type\"]==4]],ignore_index=True)","7e5f2cfa":"test.drop([\"Soil_Type7\",\"Soil_Type15\"],axis=1,inplace=True)","5f94ed44":"df[\"Aspect\"][df[\"Aspect\"] < 0] += 360\ndf[\"Aspect\"][df[\"Aspect\"] > 359] -= 360\n\ntest[\"Aspect\"][test[\"Aspect\"] < 0] += 360\ntest[\"Aspect\"][test[\"Aspect\"] > 359] -= 360","c4544a81":"df.loc[df[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\ntest.loc[test[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\n\ndf.loc[df[\"Hillshade_Noon\"] < 0, \"Hillshade_Noon\"] = 0\ntest.loc[test[\"Hillshade_Noon\"] < 0, \"Hillshade_Noon\"] = 0\n\ndf.loc[df[\"Hillshade_3pm\"] < 0, \"Hillshade_3pm\"] = 0\ntest.loc[test[\"Hillshade_3pm\"] < 0, \"Hillshade_3pm\"] = 0\n\ndf.loc[df[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\ntest.loc[test[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\n\ndf.loc[df[\"Hillshade_Noon\"] > 255, \"Hillshade_Noon\"] = 255\ntest.loc[test[\"Hillshade_Noon\"] > 255, \"Hillshade_Noon\"] = 255\n\ndf.loc[df[\"Hillshade_3pm\"] > 255, \"Hillshade_3pm\"] = 255\ntest.loc[test[\"Hillshade_3pm\"] > 255, \"Hillshade_3pm\"] = 255","bb97b59b":"feature_col=df.columns[1:-1]\nX=df[feature_col]\ny=df[\"Cover_Type\"]","1068d538":"X_test=test[feature_col]","be7230e8":"%%time\n# Setting up fold parameters\nsplits = 5\nskf = model_selection.StratifiedKFold(n_splits=splits, shuffle=True, random_state=42)\n\n# Creating an array of zeros for storing \"out of fold\" predictions\noof_preds = np.zeros((X.shape[0],))\npreds = np.zeros((X_test.shape[0],len(np.unique(y))))\nmodel_fi = 0\ntotal_mean_acc = 0\n\n# Generating folds and making training and prediction for each of 10 folds\nfor num, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n    X_train, X_valid = X.loc[train_idx], X.loc[valid_idx]\n    y_train, y_valid = y.loc[train_idx], y.loc[valid_idx]\n    \n    model = CatBoostClassifier(**cb_params)\n    model.fit(X_train, y_train,\n              verbose=False,\n              eval_set=(X_valid, y_valid),\n              )\n    \n    # Getting mean test data predictions (i.e. devided by number of splits)\n    preds += model.predict_proba(X_test) \/ splits\n    \n    # Getting mean feature importances (i.e. devided by number of splits)\n    model_fi += model.feature_importances_ \/ splits\n    \n    # Getting validation data predictions. Each fold model makes predictions on an unseen data.\n    # So in the end it will be completely filled with unseen data predictions.\n    # It will be used to evaluate hyperparameters performance only.\n    \n    oof_preds[valid_idx] = model.predict(X_valid).flatten()\n    \n    # Getting score for a fold model\n    fold_acc = accuracy_score(y_valid, oof_preds[valid_idx])\n    \n    print(f\"Fold {num} accuracy: {fold_acc}\")\n    print(classification_report(y_valid,oof_preds[valid_idx]))\n    \n    # Getting mean score of all fold models (i.e. devided by number of splits)\n    total_mean_acc += fold_acc \/ splits\n    \nprint(f\"\\nOverall ROC AUC: {total_mean_acc}\")","93f9679c":"plt.figure(figsize=(45,30))\nplt.rcParams.update({'font.size': 30})\nidxs = np.argsort(model_fi)\nplt.title(\"Feature Importance\")\nplt.barh(range(len(idxs)),model_fi[idxs],align=\"center\")\nplt.yticks(range(len(idxs)),[feature_col[i] for i in idxs])\nplt.xlabel(\"Random Forest Feature Importance\")\nplt.tight_layout()\nplt.show()","12e8331d":"test.shape","a4cbde89":"result=pd.DataFrame(model.predict(X_test))","3ced6ff9":"submit=pd.concat([pd.DataFrame(test[\"Id\"]),result],axis=1)","3db1a3cf":"submit.columns=[\"Id\",\"Cover_Type\"]","892d3dce":"submit.head()","2076aaeb":"submit.to_csv(\"submission.csv\",index=False)","e9089c84":"# Getting Outliers\n\n<img src=\"https:\/\/media.giphy.com\/media\/OSUuEuaz0imBy\/giphy.gif\">","fbf9e09f":"# Creating Data for Minority Classes","4817d1b3":"# EDA","dbfad85e":"As **Soil_Type7** and **Soil_Type15** are  having only 1 type of data need to be removed from the data frame","3f323e88":"<img src=\"https:\/\/media.giphy.com\/media\/PAqjdPkJLDsmBRSYUp\/giphy.gif\" width=80%>","8f2b0bbe":"<img src=\"https:\/\/media.giphy.com\/media\/XfnuZsoKN5VCjyynHn\/giphy.gif\">","1a4b61d4":"<img src=\"https:\/\/media.giphy.com\/media\/4LM3elgbccSje\/giphy.gif\">","1090f7ab":"# Please Upvote if you Liked what you saw!! Helps a lot\ud83d\ude01","9d1db661":"# \ud83d\udc4d Building the CatBoost Model\n\n\n<img src=\"https:\/\/media.giphy.com\/media\/lJNoBCvQYp7nq\/giphy.gif\">","7c1599bd":"# Model Training","f91ea44e":"## Thanks for the [Discussion](https:\/\/www.kaggle.com\/c\/tabular-playground-series-dec-2021\/discussion\/293373) , Providing such usefull insites of the data ","80ffe6fc":"As we can see there is imbalance in the dataset","cb153293":"<img src=\"https:\/\/media.giphy.com\/media\/l4RKhOL0xiBdbgglFi\/giphy.gif\" width=50%>","999af6dc":"# Data Description\n- Elevation - Elevation in meters\n- Aspect - Aspect in degrees azimuth\n- Slope - Slope in degrees\n- Horizontal_Distance_To_Hydrology - Horz Dist to nearest surface water features\n- Vertical_Distance_To_Hydrology - Vert Dist to nearest surface water features\n- Horizontal_Distance_To_Roadways - Horz Dist to nearest roadway\n- Hillshade_9am (0 to 255 index) - Hillshade index at 9am, summer solstice\n- Hillshade_Noon (0 to 255 index) - Hillshade index at noon, summer solstice\n- Hillshade_3pm (0 to 255 index) - Hillshade index at 3pm, summer solstice\n- Horizontal_Distance_To_Fire_Points - Horz Dist to nearest wildfire ignition points\n- Wilderness_Area (4 binary columns, 0 = absence or 1 = presence) - Wilderness area designation\n- Soil_Type (40 binary columns, 0 = absence or 1 = presence) - Soil Type designation\n- Cover_Type (7 types, integers 1 to 7) - Forest Cover Type designation","51c35327":"# Checking for NULLs in the data","c7d46e6c":"# Checking for data types in the DataFrame"}}