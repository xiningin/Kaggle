{"cell_type":{"20d56ee0":"code","cbef64d6":"code","335c611f":"code","0bc7f16e":"code","8303df85":"code","e6148281":"code","4229d80f":"code","71dba531":"code","973ca2c6":"code","b0a1f5d3":"code","620b8b03":"code","38b5b548":"code","ab146dee":"code","8d3ed1a1":"code","5f475372":"code","d2511464":"code","14ce7d6b":"code","8f05a184":"code","39f88e43":"code","0afc7284":"code","ee3ff030":"code","7e6a3997":"code","ecc6c0d2":"code","6560d412":"code","86c9db63":"code","0142093e":"code","08c0fa72":"code","a538ae90":"code","4fe49ebe":"code","35e121a8":"code","91c8c504":"code","6af7785e":"code","cda59d61":"code","0e7f2d01":"markdown","12699364":"markdown","79b26d6c":"markdown","c5ee4a3f":"markdown","f20cefbc":"markdown","3dfe3810":"markdown"},"source":{"20d56ee0":"import sklearn\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport pandas\nfrom sklearn.model_selection import train_test_split\nimport numpy","cbef64d6":"Tweet= pandas.read_csv(\"..\/input\/Tweets.csv\")\nTweet.head()","335c611f":"(len(Tweet)-Tweet.count())\/len(Tweet)","0bc7f16e":"del Tweet['tweet_coord']\ndel Tweet['airline_sentiment_gold']\ndel Tweet['negativereason_gold']","8303df85":"Mood_count=Tweet['airline_sentiment'].value_counts()","e6148281":"Index = [1,2,3]\nplt.bar(Index,Mood_count)\nplt.xticks(Index,['negative','neutral','positive'],rotation=45)\nplt.ylabel('Mood Count')\nplt.xlabel('Mood')\nplt.title('Count of Moods')","4229d80f":"Tweet['airline'].value_counts()","71dba531":"def plot_sub_sentiment(Airline):\n    df=Tweet[Tweet['airline']==Airline]\n    count=df['airline_sentiment'].value_counts()\n    Index = [1,2,3]\n    plt.bar(Index,count)\n    plt.xticks(Index,['negative','neutral','positive'])\n    plt.ylabel('Mood Count')\n    plt.xlabel('Mood')\n    plt.title('Count of Moods of '+Airline)\nplt.figure(1,figsize=(12, 12))\nplt.subplot(231)\nplot_sub_sentiment('US Airways')\nplt.subplot(232)\nplot_sub_sentiment('United')\nplt.subplot(233)\nplot_sub_sentiment('American')\nplt.subplot(234)\nplot_sub_sentiment('Southwest')\nplt.subplot(235)\nplot_sub_sentiment('Delta')\nplt.subplot(236)\nplot_sub_sentiment('Virgin America')","973ca2c6":"NR_Count=dict(Tweet['negativereason'].value_counts(sort=False))","b0a1f5d3":"def NR_Count(Airline):\n    if Airline=='All':\n        df=Tweet\n    else:\n        df=Tweet[Tweet['airline']==Airline]\n    count=dict(df['negativereason'].value_counts())\n    Unique_reason=list(Tweet['negativereason'].unique())\n    Unique_reason=[x for x in Unique_reason if str(x) != 'nan']\n    Reason_frame=pandas.DataFrame({'Reasons':Unique_reason})\n    Reason_frame['count']=Reason_frame['Reasons'].apply(lambda x: count[x])\n    return Reason_frame","620b8b03":"def plot_reason(Airline):\n    df=NR_Count(Airline)\n    count=df['count']\n    Index = range(1,(len(df)+1))\n    plt.bar(Index,count)\n    plt.xticks(Index,df['Reasons'],rotation=90)\n    plt.ylabel('Count')\n    plt.xlabel('Reason')\n    plt.title('Count of Reasons for '+Airline)","38b5b548":"plot_reason('All')","ab146dee":"plot_reason('US Airways')","8d3ed1a1":"plot_reason('United')","5f475372":"plot_reason('American')","d2511464":"plot_reason('Southwest')","14ce7d6b":"plot_reason('Delta')","8f05a184":"plot_reason('Virgin America')","39f88e43":"from wordcloud import WordCloud,STOPWORDS","0afc7284":"df=Tweet[Tweet['airline_sentiment']=='negative']\nwords = ' '.join(df['text'])\ncleaned_word = \" \".join([word for word in words.split()\n                            if 'http' not in word\n                                and not word.startswith('@')\n                                and word != 'RT'\n                            ])","ee3ff030":"wordcloud = WordCloud(stopwords=STOPWORDS,\n                      background_color='black',\n                      width=3000,\n                      height=2500\n                     ).generate(cleaned_word)","7e6a3997":"plt.figure(1,figsize=(12, 12))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","ecc6c0d2":"import re\nimport nltk\nfrom nltk.corpus import stopwords","6560d412":"def tweet_to_words(raw_tweet):\n    letters_only = re.sub(\"[^a-zA-Z]\", \" \",raw_tweet) \n    words = letters_only.lower().split()                             \n    stops = set(stopwords.words(\"english\"))                  \n    meaningful_words = [w for w in words if not w in stops] \n    return( \" \".join( meaningful_words )) ","86c9db63":"def clean_tweet_length(raw_tweet):\n    letters_only = re.sub(\"[^a-zA-Z]\", \" \",raw_tweet) \n    words = letters_only.lower().split()                             \n    stops = set(stopwords.words(\"english\"))                  \n    meaningful_words = [w for w in words if not w in stops] \n    return(len(meaningful_words)) ","0142093e":"Tweet['sentiment']=Tweet['airline_sentiment'].apply(lambda x: 0 if x=='negative' else 1)","08c0fa72":"Tweet['clean_tweet']=Tweet['text'].apply(lambda x: tweet_to_words(x))\nTweet['Tweet_length']=Tweet['text'].apply(lambda x: clean_tweet_length(x))\ntrain,test = train_test_split(Tweet,test_size=0.2,random_state=42)","a538ae90":"train_clean_tweet=[]\nfor tweet in train['clean_tweet']:\n    train_clean_tweet.append(tweet)\ntest_clean_tweet=[]\nfor tweet in test['clean_tweet']:\n    test_clean_tweet.append(tweet)","4fe49ebe":"from sklearn.feature_extraction.text import CountVectorizer\nv = CountVectorizer(analyzer = \"word\")\ntrain_features= v.fit_transform(train_clean_tweet)\ntest_features=v.transform(test_clean_tweet)","35e121a8":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import accuracy_score","91c8c504":"Classifiers = [\n    LogisticRegression(C=0.000000001,solver='liblinear',max_iter=200),\n    KNeighborsClassifier(3),\n    SVC(kernel=\"rbf\", C=0.025, probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(n_estimators=200),\n    AdaBoostClassifier(),\n    GaussianNB()]","6af7785e":"dense_features=train_features.toarray()\ndense_test= test_features.toarray()\nAccuracy=[]\nModel=[]\nfor classifier in Classifiers:\n    try:\n        fit = classifier.fit(train_features,train['sentiment'])\n        pred = fit.predict(test_features)\n    except Exception:\n        fit = classifier.fit(dense_features,train['sentiment'])\n        pred = fit.predict(dense_test)\n    accuracy = accuracy_score(pred,test['sentiment'])\n    Accuracy.append(accuracy)\n    Model.append(classifier.__class__.__name__)\n    print('Accuracy of '+classifier.__class__.__name__+'is '+str(accuracy))    ","cda59d61":"Index = [1,2,3,4,5,6,7]\nplt.bar(Index,Accuracy)\nplt.xticks(Index, Model,rotation=45)\nplt.ylabel('Accuracy')\nplt.xlabel('Model')\nplt.title('Accuracies of Models')","0e7f2d01":"### E: Preprocess data for classification","12699364":"**Our data exploration ends up at here. The next step will be preprocess the data in order to make the learning process more smooth.**","79b26d6c":"**We can find that the Tweets with negative moods are frequently involved some words like cancelled, flight ,customer or hour. People might guess that customer tends to complain when they are waiting for the delayed flights.**","c5ee4a3f":"From the above plots one can find that the distribution of moods for the first three airlines are always skewed toward negative moods. On contrary, the moods are distributed more balanced with the later three airline companies. ","f20cefbc":"## Compare the model performances","3dfe3810":"### D: Word Cloud for the negative Tweets"}}