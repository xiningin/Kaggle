{"cell_type":{"144089ed":"code","11a8d7df":"code","726aecd6":"code","29327b30":"code","be7f9439":"code","7dad73df":"code","db3943c8":"code","d695a0c0":"code","367aff78":"code","ae9d7e15":"code","f1a1a02a":"code","cec71465":"code","c35f0f07":"code","e10bd7b4":"code","9abeb93e":"code","b00f33dc":"code","c7de0869":"code","4264830d":"code","3e65a005":"markdown","8ba1283e":"markdown","a59abd62":"markdown","f572c460":"markdown","f0e3769a":"markdown","3faa2f1e":"markdown","3bf032cb":"markdown","75c6afc2":"markdown","0c052da1":"markdown","5568f2b9":"markdown","9cee0a43":"markdown","a8b55fee":"markdown","7bf54a0a":"markdown","178e1cc9":"markdown","35eb5800":"markdown"},"source":{"144089ed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","11a8d7df":"import lime\nfrom lime import lime_tabular\nimport lightgbm as lgb\nfrom xgboost import XGBClassifier, XGBRFRegressor\nfrom sklearn.model_selection import KFold, train_test_split","726aecd6":"df_train = pd.read_csv(\"..\/input\/song-popularity-prediction\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/song-popularity-prediction\/test.csv\")\nsubmission = pd.read_csv(\"..\/input\/song-popularity-prediction\/sample_submission.csv\")","29327b30":"df_train.drop('id', axis=1,inplace=True)\ndf_test.drop('id', axis=1,inplace=True)","be7f9439":"df_train.dropna(inplace=True)\ndf_train.reset_index(drop=True, inplace=True)\n\ndf_test.dropna(inplace=True)\ndf_test.reset_index(drop=True, inplace=True)","7dad73df":"df_train.head()","db3943c8":"FEATURES = [\n    \"song_duration_ms\",\n    \"acousticness\",\n    \"danceability\",\n    \"energy\",\n    \"instrumentalness\",\n    \"key\",\n    \"liveness\",\n    \"loudness\",\n    \"audio_mode\",\n    \"speechiness\",\n    \"tempo\",\n    \"time_signature\",\n    \"audio_valence\",\n]","d695a0c0":"len(FEATURES)","367aff78":"dep_var = 'song_popularity'","ae9d7e15":"X = df_train[FEATURES]\ny = df_train[dep_var]","f1a1a02a":"X.shape,y.shape","cec71465":"#param_lgb are taken from https:\/\/www.kaggle.com\/venkatkumar001\/spp2-lgbm , with some modification\n\nparams_lgb = {\n    \"task\": \"train\",\n    \"boosting_type\": \"gbdt\",\n    \"objective\": \"binary\",\n    'subsample': 0.95312,\n    'learning_rate': 0.001635,\n    \"max_depth\": 5,\n    \"feature_fraction\": 0.2256038826485174,\n    \"bagging_fraction\": 0.7705303688019942,\n    \"min_child_samples\": 290,\n    \"reg_alpha\": 14.68267919457715,\n    \"reg_lambda\": 66.156,\n    \"max_bin\": 772,\n    \"min_data_per_group\": 177,\n    \"bagging_freq\": 1,\n    \"cat_smooth\": 96,\n    \"cat_l2\": 17,\n    \"verbosity\": -1,\n    'random_state':42,\n    'n_estimators':8000,\n    'colsample_bytree':0.1107\n    }","c35f0f07":"lgb_train = lgb.Dataset(X, y)\n\nmodel = lgb.train(params=params_lgb,\n                      train_set=lgb_train,\n                      verbose_eval=False)","e10bd7b4":"# this is required as LIME requires class probabilities in case of classification example\n# LightGBM directly returns probability for class 1 by default \ndef prob(data):\n    return np.array(list(zip(1-model.predict(data),model.predict(data))))","9abeb93e":"explainer = lime.lime_tabular.LimeTabularExplainer(\n    X[model.feature_name()].astype(int).values, \n    feature_names=model.feature_name(),\n    training_labels=df_train[dep_var],\n    mode='classification')","b00f33dc":"# asking for explanation for LIME model\ni = 3\nexp = explainer.explain_instance(X.loc[i,FEATURES].astype(int).values, prob)\nexp.show_in_notebook(show_table=True)","c7de0869":"# asking for explanation for LIME model\ni = 0\nexp = explainer.explain_instance(X.loc[i,FEATURES].astype(int).values, prob)\nexp.show_in_notebook(show_table=True)","4264830d":"# asking for explanation for LIME model\ni = 15000\nexp = explainer.explain_instance(X.loc[i,FEATURES].astype(int).values, prob)\nexp.show_in_notebook(show_table=True)","3e65a005":"# Model interpretation","8ba1283e":"# Happy Learning !!!","a59abd62":"***The interpretation of machine learning models has become of prime importance nowadays. The lime stands for local interpretable model agnostic explanations takes any machine learning models as input and generates explanations about feature contributions in making a prediction. It assumes that is a black box model which means that it does not know the inner workings of models and generates explanation based on this assumption. ***","f572c460":"**References:** \n* https:\/\/www.youtube.com\/watch?v=CY3t11vuuOM\n* https:\/\/coderzcolumn.com\/tutorials\/machine-learning\/how-to-use-lime-to-understand-sklearn-models-predictions\n* https:\/\/towardsdatascience.com\/decrypting-your-machine-learning-model-using-lime-5adc035109b5\n* https:\/\/towardsdatascience.com\/lime-how-to-interpret-machine-learning-models-with-python-94b0e7e4432e\n* https:\/\/coderzcolumn.com\/tutorials\/machine-learning\/how-to-use-lime-to-understand-sklearn-models-predictions","f0e3769a":"**Interpreting machine learning models is simple using LIME. It provides you with a great way of explaining what\u2019s going on . You don\u2019t have to worry about data visualization, as the LIME library handles that for you.**","3faa2f1e":"# Model Train","3bf032cb":"![](https:\/\/miro.medium.com\/max\/2000\/1*Lo4tT2xLY7cEnTzTSb27Qg.jpeg)","75c6afc2":"Nou we call the explain_instance function of the explainer object to, well, explain the prediction. The following parameters are required:\n* **data_row** \u2013 a single observation from the dataset\n* **predict_fn** \u2013 a function used to make predictions. The predict_proba from the model is a great option because it shows probabilities","0c052da1":"**Goal of this notebook is to share the basic working example of LIME on the data  and show the interpretations and visualizations.**","5568f2b9":"# Continue with the more examples !!!! Have fun . Upvote will be appreciated :)","9cee0a43":"The **show_in_notebook** function shows the prediction interpretation in the notebook environment\n\nThis is how the explanations look for some of the training data","a8b55fee":"**Lets drop na values as LIME has some issues handling NA values**","7bf54a0a":"# Conclusion","178e1cc9":"# LIME - Local Interpretable Model-Agnostic Explanations ","35eb5800":"To start explaining the model, you first need to import the LIME library and create a tabular explainer object. It expects the following parameters:\n* **training_data** \u2013 our training data generated with train\/test split. It must be in a Numpy array format.\n* **feature_names** \u2013 column names from the training set\n* **class_names** \u2013 distinct classes from the target variable\n* **mode** \u2013 type of problem you\u2019re solving (classification in this case)"}}