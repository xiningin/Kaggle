{"cell_type":{"1d2c6371":"code","5a0f33ed":"code","3fe15055":"code","459048cd":"code","db76e1e2":"code","2db18567":"code","084e1c8a":"code","7c9fb9d7":"code","7efd8a18":"code","4b190898":"code","974291ec":"code","4cdae6bf":"code","326acbda":"code","1ed275a4":"code","fcd2e0c6":"code","a41b0d88":"code","f69a948b":"code","a1bb6fb5":"code","9857191c":"code","0a169099":"code","10707d95":"code","29ae8e12":"code","a33e0f5c":"code","cf718178":"code","cb4f07b9":"code","c412f315":"markdown","954115c6":"markdown","a8d6d538":"markdown","3fcc1874":"markdown","eab38ac9":"markdown","1f228f54":"markdown","fc4651b9":"markdown","30e8b272":"markdown","8d6f2b6c":"markdown","6b513bc3":"markdown","9a91d95b":"markdown","28c5e3c1":"markdown","3ebc6bcb":"markdown","a35f676b":"markdown","bc22ad54":"markdown","a76b36d5":"markdown","f891a92a":"markdown","0f7558eb":"markdown","4d473aba":"markdown","4f831530":"markdown","529b5178":"markdown"},"source":{"1d2c6371":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,MaxPooling2D,Dropout,Activation,BatchNormalization,Flatten\nfrom tensorflow.keras.models import Sequential\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau\nfrom keras.utils import to_categorical\nfrom keras_preprocessing.image import ImageDataGenerator,load_img\nfrom sklearn.model_selection import train_test_split \nimport random\nimport os\nfrom PIL import Image","5a0f33ed":"data_dir = '..\/input\/gtsrb-german-traffic-sign\/'\ntrain_path = '..\/input\/gtsrb-german-traffic-sign\/Train'\ndata = pd.read_csv('..\/input\/gtsrb-german-traffic-sign\/Train.csv')\ndata1 = pd.read_csv('..\/input\/gtsrblabel-names\/label_names.csv')\n\n# Resizing the images to 30x30x3\n\nheight = 30\nwidth = 30\nchannels = 1","3fe15055":"num_categories = len(os.listdir(train_path))#length of the path \nnum_categories\n","459048cd":"m= data.drop(['Width','Height','Roi.X1','Roi.Y1','Roi.X2','Roi.Y2'],1)\nm\n","db76e1e2":"data = pd.merge(data1, m, on='ClassId', how='outer')\ndata","2db18567":"plt.figure(figsize=(21,10))  \nplt.bar(data['ClassId'], data['SignName'])\nplt.xticks(data['ClassId'],rotation='horizontal')\nplt.show()\n","084e1c8a":"data = []\nlabels = []\nfor i in range(num_categories):                          #1\n    path = os.path.join(train_path,str(i))               #2\n    images = os.listdir(path)                            #3\n    \n    for a in images:\n       \n            image = Image.open(path + '\/' + a)          #4\n            image = image.resize((height,width))        #5\n            image = np.array(image)                     #6\n            data.append(image)                          #7\n            labels.append(i)\n        \n            \n        \n            \n\ndata = np.array(data)      \nlabels = np.array(labels)    ","7c9fb9d7":"data.shape,labels.shape","7efd8a18":"\n#Split arrays or matrices into random train and test subsets\n\nX_train, X_test, Y_train, Y_test = train_test_split(data,labels,test_size=0.2,random_state=42, shuffle=True)\n\nX_train = X_train\/255   #The final preprocessing step for the input data is to convert our data  and normalize our data values to the range [0, 1].\n\n\nX_test = X_test\/255\n\nprint(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)\n","4b190898":"#one hot encoding\nY_train=to_categorical(Y_train)  #Converts a class vector (integers) to binary class matrix.\nY_test= to_categorical(Y_test)\n\nprint(Y_train.shape)\nprint(Y_test.shape)","974291ec":"\n'''A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor'''\nmodel = Sequential()\n'''1'st layer convolutional  using 32 filter's with 3*3 filter size  and input shape is 30*30*3 where 30*30 height& width and 3 is RGB channel''' \nmodel.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(height,width,3)))\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n'''A pooling operation that calculates the maximum, or largest, value in each patch of each feature map . we use 2*2 pool size'''\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n'''Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is\ntemporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.'''\nmodel.add(Dropout(rate=0.25))\n\n'''2'nd layer convolutional  using 64 filter's with 3*3 filter size  and input shape is 30*30*3 where 30*30 height& width and 3 is RGB channel '''\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n'''A pooling operation that calculates the maximum, or largest, value in each patch of each feature map . we use 2*2 pool size'''\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(rate=0.25))\n'''Flattening is converting the data into a 1-dimensional array for inputting it to the next layer. \nWe flatten the output of the convolutional layers to create a single long feature vector.\nAnd it is connected to the final classification model, which is called a fully-connected layer'''\nmodel.add(Flatten())\n'''The dense layer is a fully connected layer, meaning all the neurons in a layer are connected to those in the next layer.'''\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(rate=0.5))\nmodel.add(Dense(num_categories, activation='softmax'))\n\n\n\n\n\n","4cdae6bf":"\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\n","326acbda":"from keras.callbacks import EarlyStopping,ReduceLROnPlateau\nearlyStop = EarlyStopping(patience=2)\nlearining_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',patience=2,verbose=1,factor= 0.5,min_lr=0.00001)\ncallbacks = [earlyStop,learining_rate_reduction]","1ed275a4":"\n\ntrain_datagen = ImageDataGenerator(rotation_range=10,\n                                   zoom_range=0.15,\n                                   width_shift_range=0.1,\n                                   height_shift_range=0.1,\n                                   shear_range=0.15,\n                                   horizontal_flip=False,\n                                   vertical_flip=False,\n                                   fill_mode=\"nearest\")","fcd2e0c6":"batch_size = 32\nepochs = 15\n\nhistory = model.fit(train_datagen.flow(X_train,Y_train,\n                                       batch_size=batch_size),\n                    \n                    epochs=epochs,                       \n                    callbacks=callbacks,\n                    validation_data=(X_test, Y_test) )  \n","a41b0d88":"#model.save(\"gtsrb-german-traffic-sign p1.h5\")","f69a948b":"#from keras.models import load_model\n#model = load_model('gtsrb-german-traffic-sign p1.h5')","a1bb6fb5":"# plotting graphs for accuracy \n\nplt.figure(0)\nplt.plot(history.history['accuracy'], label='training accuracy')\nplt.plot(history.history['val_accuracy'], label='val accuracy')\nplt.title('Accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()\n\nplt.figure(1)\nplt.plot(history.history['loss'], label='training loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.title('Loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","9857191c":"\n\ntest = pd.read_csv(data_dir + '\/Test.csv')\n\nlabels = test[\"ClassId\"].values\nimages = test[\"Path\"].values\n\ndata=[]\n\nfor a in images:\n        \n            image = Image.open(data_dir + '\/' + a)\n            image = image.resize((height,width))\n            image = np.array(image)\n            data.append(image)\n            \nX_pred = np.array(data)\nX_pred = X_pred\/255","0a169099":"pred = model.predict_classes(X_pred)","10707d95":"from sklearn.metrics import accuracy_score\n\nprint('Test Data accuracy: ',accuracy_score(labels, pred)*100)","29ae8e12":"test_pred= test.drop(['Width','Height','Roi.X1','Roi.Y1','Roi.X2','Roi.Y2'],1)\ntest_pred.head()","a33e0f5c":"test_pred['Predict']=pred\ntest_pred.head()","cf718178":"plt.figure(figsize=(16,16))\nplt.tight_layout()\nclass_id=test_pred['ClassId'].iloc[0:6]\npred=test_pred['Predict'].iloc[0:6]\nfor i,j in enumerate(class_id):\n    img=Image.open('..\/input\/gtsrb-german-traffic-sign\/Meta\/'+str(j)+'.png')\n    plt.subplot(6,2,2*i+1)\n    plt.axis('off')\n    plt.title('Actual Sign')\n    plt.imshow(img)\nfor i,j in enumerate(pred):\n    img=Image.open('..\/input\/gtsrb-german-traffic-sign\/Meta\/'+str(j)+'.png')\n    plt.subplot(6,2,2*i+2)\n    plt.axis('off')\n    plt.title('Predicted Sign ')\n    plt.imshow(img)   ","cb4f07b9":"Image_Height = 30\nImage_Width = 30\nchannels = 3\nImage_Size =(Image_Width,Image_Height)\nresults = { 0:'Speed limit (20km\/h)',\n            1:'Speed limit (30km\/h)', \n            2:'Speed limit (50km\/h)', \n            3:'Speed limit (60km\/h)', \n            4:'Speed limit (70km\/h)', \n            5:'Speed limit (80km\/h)', \n            6:'End of speed limit (80km\/h)', \n            7:'Speed limit (100km\/h)', \n            8:'Speed limit (120km\/h)', \n            9:'No passing', \n            10:'No passing for vehicles over 3.5 metric tons', \n            11:'Right-of-way at intersection', \n            12:'Priority road', \n            13:'Yield', \n            14:'Stop', \n            15:'No vehicles', \n            16:'Vehicles over 3.5 metric tons prohibited', \n            17:'No entry', \n            18:'General caution', \n            19:'Dangerous curve left', \n            20:'Dangerous curve right', \n            21:'Double curve', \n            22:'Bumpy road', \n            23:'Slippery road', \n            24:'Road narrows on the right', \n            25:'Road work', \n            26:'Traffic signals', \n            27:'Pedestrians', \n            28:'Children crossing', \n            29:'Bicycles crossing', \n            30:'Beware of ice\/snow',\n            31:'Wild animals crossing', \n            32:'End speed + passing limits', \n            33:'Turn right ahead', \n            34:'Turn left ahead', \n            35:'Ahead only', \n            36:'Go straight or right', \n            37:'Go straight or left', \n            38:'Keep right', \n            39:'Keep left', \n            40:'Roundabout mandatory', \n            41:'End of no passing', \n            42:'End of no passing by vehicles over 3.5 metric tons' }\nfrom PIL import Image\nimport numpy as np\nim=Image.open('..\/input\/gtsrb-german-traffic-sign\/Test\/00023.png')\nplt.imshow(im)\nim=im.resize(Image_Size)\nim=np.expand_dims(im,axis=0)\nim=np.array(im)\nim=im\/255\npred=model.predict_classes([im])[0]\nresult=(print(pred,results[pred]))\nresult\n","c412f315":"# Preprocess input data for Keras.","954115c6":"# Prepairng data & labels creating nested loop ","a8d6d538":"* **Here we are first feeding the training data(Xtrain) and training labels(Ytrain). We then use Keras to allow our model to train for 15 epochs on a batch_size of 32**\n* **A callback is a set of functions to be applied at given stages of the training procedure.This includes stopping training when you reach a certain accuracy\/loss score,saving your model as a checkpoint after each successful epoch,adjusting the learning rates over time,and more.**\n* **validation_data. Data on which to evaluate the loss and any model metrics at the end of each epoch.**","3fcc1874":"# Prepairng Test data","eab38ac9":"# Importing Libraries","1f228f54":"# Prediction ","fc4651b9":"# Data Augmentation to get high accuracy","30e8b272":"![](http:\/\/miro.medium.com\/max\/2000\/1*lXdNveKOPqjTfnRXfQlNRA.png)","8d6f2b6c":"#  Test a Model on New Images","6b513bc3":"# Model Training","9a91d95b":"# **Building Model**","28c5e3c1":"# Data Preprocessing","3ebc6bcb":"# Collecting data","a35f676b":"1. **creating for loop with range of 43 no of diffrent catergories it will iterate one bye one**\n2. **os.path.join() method in Python join one or more path components. This method concatenates various path components with exactly one directory separator (\u2018\/\u2019) following each non-empty part except the last path component.**\n3. **creating that for loop it will itrate the string value to get diffrent no of categories** \n4. **Image.open() Opens and identifies the given image file**\n5. **resize() Returns a resized copy of this image. Parameters: size \u2013 The requested size in pixels, as a 2-tuple: (width, height)**\n6. **I would like to take an image and change the scale of the image, while it is a numpy array.**\n7. **Append created image file in formdata (key value)**","bc22ad54":"# Accuracy classification Score","a76b36d5":"# Compiling Model","f891a92a":"![](http:\/\/miro.medium.com\/max\/3840\/1*NcqhsFhED_W9OnyI0ZO3jA.jpeg)","0f7558eb":"# Plotting Graphs for accuracy ","4d473aba":"# Joining DataFrames\n**Full Outer Join The FULL OUTER JOIN combines the results of both the left and the right outer joins. The joined DataFrame will contain all records from both the DataFrames and fill in NaNs for missing matches on either side. You can perform a full outer join by specifying the how argument as outer in the merge() function:**","4f831530":"# Plotting the number of images in each class","529b5178":"# Save & Load Keras models"}}