{"cell_type":{"4f2a23d5":"code","5c9fe117":"code","c3c414e8":"code","ee4a9a64":"code","b54d2610":"code","f17c9c24":"code","a12efac1":"code","3968942c":"code","556d8abd":"code","ab86b388":"code","882d6bfc":"code","e2cd63af":"code","070c2e9d":"markdown","ec1ee273":"markdown","62439df4":"markdown","9ab478cd":"markdown","cb49f547":"markdown","464fa570":"markdown","eadcd333":"markdown","305657c0":"markdown"},"source":{"4f2a23d5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5c9fe117":"df = pd.read_csv('..\/input\/usa-housing\/USA_Housing.csv')\ndf.head()\n","c3c414e8":"df.describe()","ee4a9a64":"sns.pairplot(df)","b54d2610":"x = df[['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms',\n               'Avg. Area Number of Bedrooms', 'Area Population']]\ny = df['Price']","f17c9c24":"from sklearn.model_selection import train_test_split\n\nxtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.25, random_state=101) ","a12efac1":"from sklearn.linear_model import LinearRegression \n\nlr = LinearRegression() \n\nlr.fit(xtrain,ytrain) ","3968942c":"print(lr.intercept_)","556d8abd":"coef = pd.DataFrame(lr.coef_,x.columns,columns=['Coefficient']) \ncoef","ab86b388":"predictions = lr.predict(xtest)","882d6bfc":"plt.scatter(ytest,predictions)","e2cd63af":"sns.distplot((y_test-predictions),bins=50); ","070c2e9d":"What we have here are coefficients for our columns. This means that if our \"Avg. Area Number of Rooms\" increased by one unit, then we'd see the price increase by around $121,297.153133","ec1ee273":"The describe function makes it easier to see basic statistical details about our data, such as the average, median, max value, etc, for all the applicable columns. ","62439df4":"We can again plot some datapoints to see how the data is clustered, and if any noticeable patterns pop out. ","9ab478cd":"We created a new variable called **df** which holds all our data from the CSV file. Using the head() function, we can print out the first few rows to make sure our data has imported properly, and that we have the columns we need. ","cb49f547":"We start to see our data have a distinct positive pattern. ","464fa570":"We create two variables, one variable to train on, and another as our target variable. Next we are going to split our x and y variables into a training set, and a testing set. This is so that we have enough data to also test our model at the end to account for any randomness in our accuracy. ","eadcd333":"We have imported all the libraries we need, including additionals such as **seaborn**, and **matplotlib**. Next we are going to load our data to use. ","305657c0":"To summarize, if any item in column were to increase by a unit, then the price would increase by coefficient."}}