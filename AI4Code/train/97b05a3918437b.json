{"cell_type":{"94bd78a6":"code","c597ef95":"code","b012ff64":"code","6de52968":"code","daeea6b5":"code","909d01c3":"code","da568506":"code","066381bf":"code","adc3eefe":"code","dc2977e7":"code","7cf25809":"code","82dd683b":"code","51dd082c":"code","61977f8a":"code","552e2ba1":"code","6e2a18af":"code","239fc17b":"code","166871d2":"code","2977f9f3":"code","09db2426":"code","6eb23ab7":"code","0675aecf":"code","1363d199":"code","c585166d":"code","2c79935c":"code","d472d1a4":"code","688ed217":"code","ae8822fa":"code","3936fff8":"code","6a0b174d":"code","acd9e28d":"code","ac19e767":"code","5aed4684":"code","a6f9e61e":"code","b657f445":"code","95ce5452":"code","960ca0d2":"code","ff558752":"code","5360788c":"code","9151e35c":"code","03a88b14":"code","9945392c":"code","8878ed1c":"code","dbf7b71e":"code","ecdf6456":"code","7a1a742b":"code","cd895323":"code","f6f13ab9":"code","8ef08417":"markdown","242a733c":"markdown","bf72a4f2":"markdown","92759c38":"markdown","6d63eb15":"markdown","30a4f7e1":"markdown","23367a9d":"markdown","514daae1":"markdown","68ecec13":"markdown","5cf8ae62":"markdown"},"source":{"94bd78a6":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n%matplotlib inline\nimport torch\nfrom catboost import CatBoostClassifier, Pool\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import StratifiedKFold # For creating folds\nfrom sklearn.metrics import log_loss # Evaluation metrics\nimport random","c597ef95":"train_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jun-2021\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jun-2021\/test.csv\")\nss = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jun-2021\/sample_submission.csv\")","b012ff64":"feature_cols = [f\"feature_{i}\" for i in range(75)]","6de52968":"num_cols = 5\nplt.figure(figsize = (10, 8))\nf, axes = plt.subplots(nrows=15, ncols=5, figsize=(20, 30))\nfor index, col in enumerate(feature_cols):\n    i,j = (index \/\/ num_cols, index % num_cols)\n    sns.kdeplot(train_df.loc[train_df['target'] == 'Class_1', col] , color=\"gray\",ax=axes[i,j])\n    sns.kdeplot(train_df.loc[train_df['target'] == 'Class_2', col] , color=\"red\",ax=axes[i,j])\n    sns.kdeplot(train_df.loc[train_df['target'] == 'Class_3', col] , color=\"black\",ax=axes[i,j])\n    sns.kdeplot(train_df.loc[train_df['target'] == 'Class_4', col] , color=\"maroon\",ax=axes[i,j])\n    sns.kdeplot(train_df.loc[train_df['target'] == 'Class_5', col] , color=\"brown\",ax=axes[i,j])\n    sns.kdeplot(train_df.loc[train_df['target'] == 'Class_6', col] , color=\"blue\",ax=axes[i,j])\n    sns.kdeplot(train_df.loc[train_df['target'] == 'Class_7', col] , color=\"black\",ax=axes[i,j])\n    sns.kdeplot(train_df.loc[train_df['target'] == 'Class_8', col] , color=\"red\",ax=axes[i,j])\n    sns.kdeplot(train_df.loc[train_df['target'] == 'Class_9', col] , color=\"maroon\",ax=axes[i,j])\n    \nplt.title('Distribution of Target');\nplt.tight_layout()\nplt.show()","daeea6b5":"train_df.shape,test_df.shape","909d01c3":"train_df['target'].value_counts().plot(kind = 'barh',color=\"gray\")","da568506":"from fastai.tabular.all import *","066381bf":"cat_vars = []\ncont_vars = []\n\nfor cols in feature_cols:\n    if len(train_df[cols].value_counts()) < 22:\n        cat_vars.append(cols)\n    else:\n        cont_vars.append(cols)\n    \nlen(cat_vars)","adc3eefe":"# https:\/\/www.kaggle.com\/soerendip\/fastai\n\nsplits = RandomSplitter(valid_pct=0.2)(range_of(train_df))\n\nto = TabularPandas(\n    train_df,\n    y_names=\"target\",\n    cat_names = cat_vars,\n    cont_names = cont_vars,\n    procs = [Categorify, FillMissing, Normalize],\n    splits=splits\n)\n\n# and convert it do dataloader with batch size of ...\nbatch_size = 4096\ndls = to.dataloaders(bs=batch_size)","dc2977e7":"categories = train_df[cat_vars].nunique().keys().to_list()\ncardinalities = train_df[cat_vars].nunique().values\nemb_szs = {cat: min(100, card\/\/2) for cat, card in zip(categories, cardinalities)}\nemb_szs","7cf25809":"config = tabular_config(ps=[0.001,0.01])\nlearn = tabular_learner(dls, emb_szs=emb_szs,  wd=5e-1, layers=[250,100],\n                        config=config, metrics=accuracy)","82dd683b":"learn.lr_find()","51dd082c":"learn.fit_one_cycle(5, 0.02089296132326126)","61977f8a":"dl = learn.dls.test_dl(test_df)\npred = learn.get_preds(dl=dl)\nss.loc[:,1:] = pred[0].numpy()\nss.to_csv('submission_fastai.csv',index = False)","552e2ba1":"X_train = pd.DataFrame(dls.train_ds[feature_cols])\ny_train = dls.train_ds['target']\n\nX_valid = pd.DataFrame(dls.valid_ds[feature_cols])\ny_valid = dls.valid_ds['target']","6e2a18af":"X_train.shape,X_valid.shape","239fc17b":"target = pd.concat([y_train, y_valid])","166871d2":"X_test = pd.DataFrame(dl.dataset[:])[feature_cols]\nX_test.shape","2977f9f3":"from xgboost import XGBClassifier\nclf = XGBClassifier(objective = 'multi:softmax', booster = 'gbtree', \n                     nrounds = 'min.error.idx', num_class = 3, \n                     maximize = False, eval_metric = 'logloss', eta = .1,\n                     max_depth = 14, colsample_bytree = .4, n_jobs=-1)","09db2426":"clf.fit(X_train, y_train)","6eb23ab7":"from sklearn.metrics import accuracy_score\nacc = accuracy_score(y_valid, clf.predict(X_valid))\nacc","0675aecf":"pred = clf.predict_proba(X_test)\nss.loc[:,1:] = pred\nss.to_csv('submission_XGBoost.csv',index=False) #1.78111","1363d199":"categorical_features_indices = []\nfor col in cat_vars:\n    categorical_features_indices.append(np.where(train_df.columns == col)[0][0])\n    print(train_df[col].dtype)\ncategorical_features_indices","c585166d":"train_embed = pd.concat([X_train, X_valid])\ndf_train = train_embed\ndf_test = X_test\ntrain_data = Pool(df_train[feature_cols],  target)","2c79935c":"from sklearn.metrics import accuracy_score\nfrom catboost import cv\nimport optuna\n\ndef objective(trial, model, train_df, y):\n    #train_set = Dataset(df_train[feature_cols], label = target)\n    train_data = Pool(train_df[feature_cols], label = y)\n    hparams = {\n        'loss_function': 'MultiClass',\n        #'eval_metric': 'Logloss',        \n        #'verbosity': -1,\n        'grow_policy': 'Lossguide',\n        'bootstrap_type': 'Poisson',\n        \n        'learning_rate': trial.suggest_float('learning_rate', 0.005, 1),\n        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.001, 3.0),\n        'max_bin': trial.suggest_int('max_bin', 150, 250),\n        \"bootstrap_type\": trial.suggest_categorical(\n            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n        ),\n        'max_depth': trial.suggest_int('max_depth', 5, 12),\n        'leaf_estimation_method': 'Gradient',\n        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 50, 500),\n        'iterations':10000,\n        'random_state':2021,\n        'task_type': 'GPU',\n    }\n    \n    if hparams[\"bootstrap_type\"] == \"Bayesian\":\n        hparams[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 60)\n    elif hparams[\"bootstrap_type\"] == \"Bernoulli\":\n        hparams[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n    \n    k = 5\n    cv_results = cv(\n            params = hparams,            \n            dtrain = train_data,\n            num_boost_round = 2500,\n            nfold = k,\n            stratified = True,\n            early_stopping_rounds = 100,\n            verbose_eval = False,\n        )\n\n    return cv_results.mean()\n","d472d1a4":"study_catboost = optuna.create_study(direction = 'minimize')\nstudy_catboost.optimize(lambda trial: objective(trial, 'catboost',\n                                                df_train[feature_cols], target),\n                        n_trials = 100, timeout = 600)","688ed217":"study_catboost.best_params","ae8822fa":"param_cb ={\n    'max_depth': 8, \n    'l2_leaf_reg': 2.9203995625107293, \n    'bagging_temperature': 32.30584785106606, \n    'loss_function': 'MultiClass',\n    #'eval_metric': 'AUC',    \n    'grow_policy': 'Lossguide',\n    'bootstrap_type': 'Bayesian', \n    'learning_rate': 0.27478567078925825, \n    'max_bin': 227, \n    'min_data_in_leaf': 333,\n    'task_type':'GPU',\n    'iterations':10000,\n    'random_state':2021,\n    #'subsample': 0.13534551086578891\n}","3936fff8":"%%time\nfrom sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score\nfrom catboost import CatBoostClassifier\n\n\n\noofcat         = np.zeros((df_train.shape[0],9))\npredictionscat = np.zeros((df_test.shape[0],9))\n\n\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfold=StratifiedKFold(n_splits=5,shuffle=True,random_state=2021)\ni=1\n\nfor dev_index, val_index in fold.split(df_train[feature_cols],target):    \n    dev_X, val_X = df_train[feature_cols].loc[dev_index,:], df_train[feature_cols].loc[val_index,:]\n    dev_y, val_y = target[dev_index], target[val_index]\n\n    m=CatBoostClassifier(**param_cb)\n    m.fit(dev_X,dev_y,eval_set=[(val_X, val_y)], early_stopping_rounds=100,verbose=100)\n  \n    oofcat[val_index]  = m.predict_proba(val_X.values)\n    pred_test = m.predict_proba(df_test[feature_cols].values)\n    predictionscat += pred_test\n\npredictionscat = predictionscat\/5 ","6a0b174d":"oofcat.shape,predictionscat.shape,df_train[feature_cols].shape,target.shape,df_test[feature_cols].shape","acd9e28d":"ss[\"Class_1\"] = pd.DataFrame(predictionscat)[0]\nss[\"Class_2\"] = pd.DataFrame(predictionscat)[1]\nss[\"Class_3\"] = pd.DataFrame(predictionscat)[2]\nss[\"Class_4\"] = pd.DataFrame(predictionscat)[3]\nss[\"Class_5\"] = pd.DataFrame(predictionscat)[4]\nss[\"Class_6\"] = pd.DataFrame(predictionscat)[5]\nss[\"Class_7\"] = pd.DataFrame(predictionscat)[6]\nss[\"Class_8\"] = pd.DataFrame(predictionscat)[7]\nss[\"Class_9\"] = pd.DataFrame(predictionscat)[8]\nss.to_csv(\"submission.csv\", index=False) #1.75322","ac19e767":"train_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jun-2021\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jun-2021\/test.csv\")\nss = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jun-2021\/sample_submission.csv\")","5aed4684":"y = train_df['target']","a6f9e61e":"%%time\nfrom sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score\nfrom catboost import CatBoostClassifier\n\n\n# categorical_features_indices = np.where(train_df.dtypes =='category')[0]\n# categorical_features_indices\noofcat         = np.zeros((train_df.shape[0],9))\npredictionscat_p = np.zeros((test_df.shape[0],9))\n\n\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfold=StratifiedKFold(n_splits=5,shuffle=True,random_state=2021)\ni=1\n\nfor dev_index, val_index in fold.split(train_df[feature_cols],y):    \n    dev_X, val_X = train_df[feature_cols].loc[dev_index,:], train_df[feature_cols].loc[val_index,:]\n    dev_y, val_y = y[dev_index], y[val_index]\n\n    m=CatBoostClassifier(**param_cb)\n    m.fit(dev_X,dev_y,eval_set=[(val_X, val_y)], early_stopping_rounds=100,verbose=100)\n  \n    oofcat[val_index]  = m.predict_proba(val_X.values)\n    pred_test = m.predict_proba(test_df[feature_cols].values)\n    predictionscat_p += pred_test\n\npredictionscat_p = predictionscat_p\/5 ","b657f445":"ss[\"Class_1\"] = pd.DataFrame(predictionscat_p)[0]\nss[\"Class_2\"] = pd.DataFrame(predictionscat_p)[1]\nss[\"Class_3\"] = pd.DataFrame(predictionscat_p)[2]\nss[\"Class_4\"] = pd.DataFrame(predictionscat_p)[3]\nss[\"Class_5\"] = pd.DataFrame(predictionscat_p)[4]\nss[\"Class_6\"] = pd.DataFrame(predictionscat_p)[5]\nss[\"Class_7\"] = pd.DataFrame(predictionscat_p)[6]\nss[\"Class_8\"] = pd.DataFrame(predictionscat_p)[7]\nss[\"Class_9\"] = pd.DataFrame(predictionscat_p)[8]\nss.to_csv(\"submission_p.csv\", index=False)","95ce5452":"\ncol1 = (pd.DataFrame(predictionscat)[0] * 0.40 + pd.DataFrame(predictionscat_p)[0] * 0.60) \ncol2 = (pd.DataFrame(predictionscat)[1] * 0.40 + pd.DataFrame(predictionscat_p)[1] * 0.60)\ncol3 = (pd.DataFrame(predictionscat)[2] * 0.40 + pd.DataFrame(predictionscat_p)[2] * 0.60)\ncol4 = (pd.DataFrame(predictionscat)[3] * 0.40 + pd.DataFrame(predictionscat_p)[3] * 0.60)\ncol5 = (pd.DataFrame(predictionscat)[4] * 0.40 + pd.DataFrame(predictionscat_p)[4] * 0.60)\ncol6 = (pd.DataFrame(predictionscat)[5] * 0.40 + pd.DataFrame(predictionscat_p)[5] * 0.60)\ncol7 = (pd.DataFrame(predictionscat)[6] * 0.40 + pd.DataFrame(predictionscat_p)[6] * 0.60)\ncol8 = (pd.DataFrame(predictionscat)[7] * 0.40 + pd.DataFrame(predictionscat_p)[7] * 0.60)\ncol9 = (pd.DataFrame(predictionscat)[8] * 0.40 + pd.DataFrame(predictionscat_p)[8] * 0.60)\n\nss['Class_1'] =  col1\nss['Class_2'] =  col2\nss['Class_3'] =  col3\nss['Class_4'] =  col4\nss['Class_5'] =  col5\nss['Class_6'] =  col6\nss['Class_7'] =  col7\nss['Class_8'] =  col8\nss['Class_9'] =  col9\nss.to_csv('submission1.csv', index=False)","960ca0d2":"### finish","ff558752":"# train_df = df\n# test_df = test \n# feature_cols = cat_features\n# y = train_df.target","5360788c":"# y = pd.DataFrame(train_df['target'])\n# y = y['target'].map({\n#       'Class_1':'0',\n#       'Class_2':'1',\n#       'Class_3':'2',\n#       'Class_4':'3',\n#       'Class_5':'4',\n#       'Class_6':'5',\n#       'Class_7':'6',\n#       'Class_8':'7',\n#       'Class_9':'8'})\n# y = np.array(y).astype(int)\n# y = y.ravel()","9151e35c":"# !pip install -q \/kaggle\/input\/pytorchtabnet\/pytorch_tabnet-2.0.1-py3-none-any.whl","03a88b14":"# from sklearn.model_selection import train_test_split, KFold\n# from pytorch_tabnet.tab_model import TabNetClassifier","9945392c":"# df = pd.concat([train_df,test_df],axis=0)","8878ed1c":"# from sklearn.preprocessing import LabelEncoder\n# categorical_columns = []\n# categorical_dims =  {}\n# for col in df.columns[df.dtypes == int]:\n#     #print(col, train_df[col].nunique())\n#     l_enc = LabelEncoder()    \n#     df[col] = l_enc.fit_transform(df[col].values)\n#     categorical_columns.append(col)\n#     categorical_dims[col] = len(l_enc.classes_)","dbf7b71e":"# train_df.shape,test_df.shape,df.shape","ecdf6456":"# train_df = df.loc[df.target.isnull() == False]\n# test_df = df.loc[df.target.isnull() == False][feature_cols]","7a1a742b":"# cat_idxs = [ i for i, f in enumerate(feature_cols) if f in categorical_columns]\n\n# cat_dims = [ categorical_dims[f] for i, f in enumerate(feature_cols) if f in categorical_columns]","cd895323":"# %%time\n# from sklearn.metrics import accuracy_score\n# scores = []\n# ooftabnet = np.zeros((train_df.shape[0],9))\n# predictionstabnet= np.zeros((test_df.shape[0],9))\n\n# fold=StratifiedKFold(n_splits=5,shuffle=True,random_state=2021)\n# i=1\n# n_d = n_a = 50\n\n# tabnet_params = dict(verbose=40)\n\n# for dev_index, val_index in fold.split(train_df[feature_cols],y): \n#     #print(dev_index)\n#     dev_X, val_X = train_df[feature_cols].loc[dev_index,:], train_df[feature_cols].loc[val_index,:]\n#     dev_y, val_y = y[dev_index], y[val_index]\n    \n#     model = TabNetClassifier(\n#     n_d=n_d,n_a=n_a, n_steps=5,\n#     gamma=1.5, n_independent=2, n_shared=2,\n#     cat_idxs=cat_idxs,\n#     cat_dims=cat_dims,\n#     cat_emb_dim=1,\n#     lambda_sparse=1e-2, momentum=0.3, clip_value=2.,\n#     optimizer_fn=torch.optim.Adam,\n#     optimizer_params=dict(lr=2e-2),\n#     scheduler_params = {\"gamma\": 0.95,\n#                      \"step_size\": 10},\n#     scheduler_fn=torch.optim.lr_scheduler.StepLR, epsilon=1e-15)\n    \n#     model.fit(\n#       dev_X.values, dev_y,\n#       eval_set=[(val_X.values, val_y)],\n#       patience=100,\n#       max_epochs=300,\n#     )\n#     scores.append(accuracy_score(val_y, model.predict(val_X.values)))\n#     print(\"IN 1\")\n#     pred_val  = model.predict_proba(val_X.values)\n#     print(\"IN 2\")\n#     pred_test = model.predict_proba(test_df[feature_cols].values)\n      \n#     ooftabnet[val_index] = pred_val\n#     predictionstabnet += pred_test\n    \n# predictionstabnet \/= 5.","f6f13ab9":"# ss[\"Class_1\"] = pd.DataFrame(predictionstabnet)[0]\n# ss[\"Class_2\"] = pd.DataFrame(predictionstabnet)[1]\n# ss[\"Class_3\"] = pd.DataFrame(predictionstabnet)[2]\n# ss[\"Class_4\"] = pd.DataFrame(predictionstabnet)[3]\n# ss[\"Class_5\"] = pd.DataFrame(predictionstabnet)[4]\n# ss[\"Class_6\"] = pd.DataFrame(predictionstabnet)[5]\n# ss[\"Class_7\"] = pd.DataFrame(predictionstabnet)[6]\n# ss[\"Class_8\"] = pd.DataFrame(predictionstabnet)[7]\n# ss[\"Class_9\"] = pd.DataFrame(predictionstabnet)[8]\n# ss.to_csv(\"submission.csv\", index=False)","8ef08417":"### Cat Boost 2","242a733c":"### Data Visualization","bf72a4f2":"### Blend","92759c38":"### XG Boost","6d63eb15":"1. ANALYZE DATA\n2. FAST AI\n3. EXTRACT EMBEDDINGS\n4. TRAIN XG BOOST\n5. TRAIN CAT BOOST - with FAST AI Embeddings\n6. TRAIN CAT BOOST - without embeddings\n7. ENSEMBLE","30a4f7e1":"# Tabular Playground Series - Jun 2021","23367a9d":"### FAST AI","514daae1":"### Tab Net","68ecec13":"### Cat Boost 1","5cf8ae62":"### Extract Embeddings"}}