{"cell_type":{"ae2d0882":"code","8826bbb3":"code","351274da":"code","56d4b849":"code","90e99315":"code","470f7111":"code","3958bf2d":"code","f829eb47":"code","ea1300ff":"code","ada7e696":"code","507721d0":"code","e2ecfe53":"code","475fb55e":"code","69e7698f":"code","9a807d18":"markdown","4dc7e243":"markdown","798ab138":"markdown","14296221":"markdown","8ae37570":"markdown","b71a3fb1":"markdown","90da6e53":"markdown","7bc27c0b":"markdown","9632ee90":"markdown","32b28f26":"markdown","5997fe53":"markdown","85feb596":"markdown","d1bd9bd9":"markdown"},"source":{"ae2d0882":"%matplotlib notebook\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","8826bbb3":"train_data = pd.read_csv(\"..\/input\/train.csv\")\ntrain_data.head(10)","351274da":"def CleanData(data):\n    # Delete useless columns\n    data = data.drop(columns= [\"Name\", \"Ticket\", \"Cabin\"])\n    \n    # Assign categorical values to Gender\n    data = data.replace(\"male\", 0)\n    data = data.replace(\"female\", 1)\n    \n    # Assign categorical values to Port of Embarking\n    data = data.replace(\"C\", 0)\n    data = data.replace(\"Q\", 1)\n    data = data.replace(\"S\", 2)\n    \n    data[\"Age\"].fillna(-1, inplace=True)\n    data[\"Embarked\"].fillna(-1, inplace=True)\n    \n    return data\n\ntrain_data = CleanData(train_data)\ntrain_data.head(20)","56d4b849":"pick_columns = np.arange(2,9)\nfeature_names = train_data.columns[pick_columns]\n\nx_train = train_data.iloc[:, pick_columns].values.astype(\"float32\")\ny_train = train_data.iloc[:, 1].values.astype(\"int32\")\nid_train = train_data.iloc[:, 0].values.astype(\"int32\")","90e99315":"\nx_mean = np.mean(x_train, axis = 0)\nx_std = np.std(x_train, axis = 0)\nx_train = (x_train - x_mean) \/ x_std\n","470f7111":"x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size = 0.2)","3958bf2d":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout","f829eb47":"model = Sequential()\nmodel.add(Dense(128, activation=\"relu\", input_shape = (x_train.shape[1],))) # Hidden Layer 1 that receives the Input from the Input Layer\n\nmodel.add(Dense(64, activation=\"relu\")) # Hidden Layer 2\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(32, activation=\"relu\")) # Hidden Layer 3\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(16, activation=\"relu\")) # Hidden Layer 4\nmodel.add(Dropout(0.2))\n\n\nmodel.add(Dense(1, activation=\"sigmoid\")) # Outout Layer\n\nmodel.summary()","ea1300ff":"model.compile(optimizer='adam', loss = \"binary_crossentropy\", metrics = ['accuracy'])","ada7e696":"model.fit(x_train, y_train, batch_size = 64, epochs = 20)","507721d0":"validation_loss, validation_accuracy = model.evaluate(x_validation, y_validation, batch_size=32)\nprint(\"Loss: \"+ str(np.round(validation_loss, 3)))\nprint(\"Accuracy: \"+ str(np.round(validation_accuracy, 3)))","e2ecfe53":"import eli5\nfrom eli5.permutation_importance import get_score_importances\n\ndef Score(x, y):\n    loss, accuracy = model.evaluate(x, y, batch_size=32, verbose=0)\n    return accuracy\n\nbase_score, score_decreases = get_score_importances(Score, x_validation, y_validation, n_iter= 100)\nfeature_importances = np.mean(score_decreases, axis=0)\nfeature_std = np.std(score_decreases, axis=0)\n\nsort_index = np.argsort(feature_importances)[::-1]\nprint(\"Feature Importances:\")\nfor i in range(feature_names.size):\n    \n    j = sort_index[i]\n    print(feature_names[j] +\":  \"+ str(np.round(feature_importances[j],3)) + \" +- \" + str(np.round(feature_std[j],3)))\n","475fb55e":"import seaborn as sns\nplt.figure()\nsns.barplot(x = \"Sex\", y = \"Survived\", data = train_data)\nplt.ylabel(\"Survival Rate\")\nplt.xlabel(\"Sex\")\nplt.xticks([0,1], [\"male\", \"female\"]) \n\n\nplt.figure()\nsns.barplot(x = \"Pclass\", y = \"Survived\", data = train_data)\nplt.ylabel(\"Survival Rate\")\nplt.xlabel(\"Passenger Class\")","69e7698f":"import shap  # package used to calculate Shap values\n\npassenger_to_study = 40\npassenger_data = np.array([x_validation[passenger_to_study]])\npassenger_survival = model.predict(passenger_data)[0][0]\n\nprint(\"Survival change of passenger X: \" + str(np.round(passenger_survival,3)))\n\nexplainer = shap.DeepExplainer(model, data= x_validation)\n\nshap_values = explainer.shap_values(passenger_data)\n\nprint(\"How much each feature contributed:\")\nfor i in range(feature_names.size):\n\n    j = sort_index[i]\n\n\n    print(feature_names[j] +\" = \"+ str(np.round(passenger_data[0][j]*x_std[j] + x_mean[j],3)) + \" -> \" + str(np.round(shap_values[0][0][j],3)))\n\nshap.initjs()\nshap.force_plot(explainer.expected_value[0], shap_values[0][0], passenger_data[0]*x_std + x_mean, feature_names= feature_names)\n","9a807d18":"## Split the data into a training and validation set","4dc7e243":"## Compile the model.\n## You need to provide: \n### - Optimizer (to update the network)\n### - Loss function (that you want to minimize)\n### - Metric (For the user to know how the model is performing)","798ab138":"## Fit the model.\n### Provide batch size (how many training examples to use at a single time).\n### Provide epoch number (how many iterations to perform for each batch).","14296221":"## Now we can use the shap values to study how each variable affected the final outcome","8ae37570":"## Construct the Sequential model","b71a3fb1":"## From the permutation importance we learn that the Sex is the most important feature when predicting the results by far. Followed by the Passenger class, the age , and the number of Silbings\/Spouse. The Number of Parents\/Children, Ticket Fare and port of embarked do not affect the prediction.","90da6e53":"## Start with Permutation Importance.\n### Shuffle each column and evaluate the model.\n### The most important features will lead to a loss in accuracy when shuffled.","7bc27c0b":"## Before starting lets clean the data.\n### Lets assume that the Name does not matter.\n### The ticket number also does not matter\n### The cabin row has a lot of nans and it is not clear how to treat it so just remove it.\n### Assign gender \"Male = 0\", \"Female = 1\"\n### Assignt Embarked Port \"C = 0\", \"Q = 1\", \"S = 2\"\n### Fill the nans in age with \"-1\"\n### Fill the nans in Embarked  with \"-1\"","9632ee90":"## Preprocess the data. Normalize the columns in the training set.","32b28f26":"## Now we are ready to train our neural network.\n## First we start by importing the Keras library","5997fe53":" # Apply the Machine Learning Explainability Microcourse to extract further information from the data.\n ### https:\/\/www.kaggle.com\/learn\/machine-learning-explainability","85feb596":"### Extract the ID and survival outcome from the train data.","d1bd9bd9":"## Read the training and test data"}}