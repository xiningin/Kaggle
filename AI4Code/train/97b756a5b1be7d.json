{"cell_type":{"a1ea9164":"code","8ab1798a":"code","52cc853f":"code","2cf1db86":"code","f8b2981a":"code","b9b3a955":"code","1667647d":"code","208087c4":"code","a4971467":"code","6379ea49":"code","875ab022":"code","3dd86e3d":"code","d62aa5a7":"code","46e75ce5":"code","f6aa38c0":"code","102310eb":"code","2713b306":"code","2d4b25c2":"code","4752b13d":"code","cc4853c1":"code","3806856b":"code","1c9024c4":"code","d0401db9":"code","979f54d4":"code","1b2b7b9d":"code","5ff33e99":"code","f67e5bce":"code","e7498d5d":"code","2a46c118":"code","be846abb":"code","750bc6da":"code","655e6ddc":"code","5a95a2ab":"code","2d7d1512":"code","4e3d1120":"code","c26da3a4":"markdown","bd3e5e1c":"markdown","5c068967":"markdown","081ef57a":"markdown","0f2eedb3":"markdown","72fbe354":"markdown","d9b9d6a9":"markdown","0c3ea7ff":"markdown","feba30d7":"markdown","7ab62eed":"markdown","db45b68f":"markdown","def432ec":"markdown","058e9ee1":"markdown","12b910be":"markdown","44c6dd19":"markdown","1cb4febb":"markdown","99c4db79":"markdown","ff488e73":"markdown","97a2b9b3":"markdown","a56df288":"markdown","55df34ae":"markdown","e4df4abd":"markdown","0ab35c97":"markdown","6542c2fe":"markdown"},"source":{"a1ea9164":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport csv\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport statistics","8ab1798a":"# defining directory paths\ntrain_dir = \"..\/input\/train.csv\"\ntest_dir = \"..\/input\/test.csv\"","52cc853f":"df = pd.read_csv(train_dir)\ntest_df = pd.read_csv(test_dir)\n#checking for missing and na values\nprint(\"Total number of instance : \",len(df))\ndf.isna().sum()","2cf1db86":"df.head(3)","f8b2981a":"df.fillna(-1, inplace = True) #filling in missing values with -1\ntest_df.fillna(-1, inplace = True)\ndf[\"Cabin\"].unique()","b9b3a955":"df.drop([\"Cabin\"], axis = 1, inplace = True)\ntest_df.drop([\"Cabin\"], axis = 1, inplace = True)\ndf.drop([\"Ticket\"], axis = 1, inplace = True)\ntest_df.drop([\"Ticket\"], axis = 1, inplace = True)\ndf.info()\ndf.head(10)","1667647d":"# checking class distribution\ndf[\"Survived\"].value_counts().plot(kind = \"bar\")","208087c4":"f,ax = plt.subplots(figsize=(15, 13))\nsns.heatmap(df.corr(), annot=True, cmap = \"Blues\", linewidths=.5, fmt= '.2f',ax = ax)\nplt.show()","a4971467":"df_survived = df[df[\"Survived\"]==1]\ndf_notsurvived = df[df[\"Survived\"]==0]\ngb_pclass_surv = df_survived.groupby(\"Pclass\")[\"Survived\"].sum()\n#a = gb_pclass_surv.plot(kind= \"bar\")\ngb_pclass_notsurv = df_notsurvived.groupby(\"Pclass\")[\"Survived\"].count()\n#b = gb_pclass_notsurv.plot(kind= \"bar\")\n\nfig = plt.figure(figsize = (10,4))\nf1 = fig.add_subplot(1, 2, 1)\nf1.set_ylim([0,400])\nf2 = fig.add_subplot(1,2,2)\nf2.set_ylim([0,400])\ngb_pclass_surv.plot(kind= \"bar\", title = \"Survived\", ax = f1)\ngb_pclass_notsurv.plot(kind= \"bar\", title = \"Not Survived\", ax = f2)","6379ea49":"df.drop(\"PassengerId\", axis = 1, inplace = True)\ntest_df.drop(\"PassengerId\", axis = 1, inplace = True)","875ab022":"print(\"SibSp unqiue value counts :\\n\" + str(df[\"SibSp\"].value_counts()))\n\nfig = plt.figure(figsize = (15,5))\nf1 = fig.add_subplot(1, 3, 1)\nf1.set_ylim([0,700])\nf2 = fig.add_subplot(1,3,2)\nf2.set_ylim([0,700])\nf3 = fig.add_subplot(1,3, 3)\nf3.set_ylim([0,700])\ndf[\"SibSp\"].value_counts().plot(kind= \"bar\", title = \"(SibSp) Total\", ax = f1)\ndf_survived[\"SibSp\"].value_counts().plot(kind= \"bar\", title = \"(SibSp) Survived\", ax = f2)\ndf_notsurvived[\"SibSp\"].value_counts().plot(kind= \"bar\", title =  \"(SibSp) Not Survived\", ax = f3)\nplt.show()","3dd86e3d":"print(\"Parch unique value counts : \\n\" + str(df[\"Parch\"].value_counts()))\n\nfig = plt.figure(figsize = (15,5))\nf1 = fig.add_subplot(1, 3, 1)\nf1.set_ylim([0,700])\nf2 = fig.add_subplot(1,3,2)\nf2.set_ylim([0,700])\nf3 = fig.add_subplot(1,3, 3)\nf3.set_ylim([0,700])\ndf[\"Parch\"].value_counts().plot(kind= \"bar\", title = \"(Parch) Total\", ax = f1)\ndf_survived[\"Parch\"].value_counts().plot(kind= \"bar\", title = \"(Parch) Survived\", ax = f2)\ndf_notsurvived[\"Parch\"].value_counts().plot(kind= \"bar\", title =  \"(Parch) Not Survived\", ax = f3)\nplt.show()","d62aa5a7":"df[\"Sex\"].replace(\"male\", 0, inplace = True)\ntest_df[\"Sex\"].replace(\"male\", 0, inplace = True)\ndf[\"Sex\"].replace(\"female\", 1, inplace = True)\ntest_df[\"Sex\"].replace(\"female\", 1, inplace = True)\n\ndf[\"Embarked\"].replace([\"S\",\"C\",\"Q\"],[0,1,2], inplace = True)\ntest_df[\"Embarked\"].replace([\"S\",\"C\",\"Q\"],[0,1,2], inplace = True)","46e75ce5":"df[\"n_fam_mem\"] = df[\"SibSp\"] + df[\"Parch\"]\ntest_df[\"n_fam_mem\"] = df[\"SibSp\"] + df[\"Parch\"]\ndf_survived[\"n_fam_mem\"] = df_survived[\"SibSp\"] + df_survived[\"Parch\"]\ndf_notsurvived[\"n_fam_mem\"] = df_notsurvived[\"SibSp\"] + df_notsurvived[\"Parch\"]\n\nfig = plt.figure(figsize = (15,5))\nf1 = fig.add_subplot(1, 3, 1)\nf1.set_ylim([0,600])\nf2 = fig.add_subplot(1,3,2)\nf2.set_ylim([0,600])\nf3 = fig.add_subplot(1,3, 3)\nf3.set_ylim([0,600])\n\ndf[\"n_fam_mem\"].value_counts().plot(kind = \"bar\", title = \"all\", ax = f1)\ndf_survived[\"n_fam_mem\"].value_counts().plot(kind = \"bar\", title = \"Survived\", ax = f2)\ndf_notsurvived[\"n_fam_mem\"].value_counts().plot(kind = \"bar\", ax = f3)","f6aa38c0":"def create_family_ranges(df):\n    familysize = []\n    for members in df[\"n_fam_mem\"]:\n        if members == 0:\n            familysize.append(0)\n        elif members > 0 and members <=4:\n            familysize.append(1)\n        elif members > 4:\n            familysize.append(2)\n    return familysize\n\nfamsize = create_family_ranges(df)\ndf[\"familysize\"] = famsize\n\ntest_famsize = create_family_ranges(test_df)\ntest_df[\"familysize\"] = test_famsize","102310eb":"df[\"Age\"].where(df[\"Age\"]!=-1).mean()","2713b306":"def age_to_int(df):\n    agelist = df[\"Age\"].values.tolist()\n    for i in range(len(agelist)):\n        if agelist[i] < 18 and agelist[i] >= 0:\n            agelist[i] = 0\n        elif agelist[i] >= 18 and agelist[i] < 60:\n            agelist[i] = 1\n        elif agelist[i]>=60 and agelist[i]<200:\n            agelist[i] = 2\n        else:\n            agelist[i] = -1\n    ageint = pd.DataFrame(agelist)\n    return ageint","2d4b25c2":"ageint = age_to_int(df)\ndf[\"Ageint\"] = ageint\ndf.drop(\"Age\", axis = 1, inplace = True)\n\ntest_ageint = age_to_int(test_df)\ntest_df[\"Ageint\"] = test_ageint\ntest_df.drop(\"Age\", axis = 1, inplace = True)\n","4752b13d":"df[\"actual_fare\"] = df[\"Fare\"]\/(df[\"n_fam_mem\"]+1)\n\ntest_df[\"actual_fare\"] = test_df[\"Fare\"]\/(test_df[\"n_fam_mem\"]+1)\n\ndf[\"actual_fare\"].plot()\ndf[\"actual_fare\"].describe()","cc4853c1":"def conv_fare_ranges(df): \n    fare_ranges = []\n    for fare in df.actual_fare:\n        if fare < 7:\n            fare_ranges.append(0)\n        elif fare >=7 and fare < 14:\n            fare_ranges.append(1)\n        elif fare >=14 and fare < 30:\n            fare_ranges.append(2)\n        elif fare >=30 and fare < 50:\n            fare_ranges.append(3)\n        elif fare >=50:\n            fare_ranges.append(4)\n    return fare_ranges\n        \nfare_ranges = conv_fare_ranges(df)\ndf[\"fare_ranges\"] = fare_ranges\n\ntest_fare_ranges = conv_fare_ranges(test_df)\ntest_df[\"fare_ranges\"] = test_fare_ranges","3806856b":"df_nonsurv_fare = df[df[\"Survived\"]==0]\ndf_surv_fare = df[df[\"Survived\"]==1]\n\nfig = plt.figure(figsize = (15,5))\nf1 = fig.add_subplot(1, 3, 1)\nf1.set_ylim([0,500])\nf2 = fig.add_subplot(1,3,2)\nf2.set_ylim([0,500])\nf3 = fig.add_subplot(1,3, 3)\nf3.set_ylim([0,500])\n\ndf[\"fare_ranges\"].value_counts().plot(kind=\"bar\", title = \"Fare Ranges all\", ax = f1)\ndf_surv_fare[\"fare_ranges\"].value_counts().plot(kind=\"bar\", title =  \"Survived\", ax = f2)\ndf_nonsurv_fare[\"fare_ranges\"].value_counts().plot(kind=\"bar\", title = \"Not Survived\", ax = f3)","1c9024c4":"def name_to_int(df):\n    name = df[\"Name\"].values.tolist()\n    namelist = []\n    for i in name:\n        index = 1\n        inew = i.split()\n        if inew[0].endswith(\",\"):\n            index = 1\n        elif inew[1].endswith(\",\"):\n            index = 2\n        elif inew[2].endswith(\",\"):\n            index = 3\n        namelist.append(inew[index])\n    print(set(namelist))\n    \n    titlelist = []\n    \n    for i in range(len(namelist)): \n        if namelist[i] == \"Lady.\":\n            titlelist.append(\"Lady.\")\n        elif namelist[i] == \"Ms.\":\n            titlelist.append(\"Ms.\")\n        elif namelist[i] == \"Miss.\":\n            titlelist.append(\"Miss.\")\n        elif namelist[i] == \"Dr.\":\n            titlelist.append(\"Dr.\")\n        elif namelist[i] == \"Mr.\":\n            titlelist.append(\"Mr.\")\n        elif namelist[i] == \"Jonkheer.\":\n            titlelist.append(\"Jonkheer.\")\n        elif namelist[i] == \"Col.\":\n            titlelist.append(\"Col.\")\n        elif namelist[i] == \"Mrs.\":\n            titlelist.append(\"Mrs\")\n        elif namelist[i] == \"Sir.\":\n            titlelist.append(\"Sir.\")\n        elif namelist[i] == \"Mlle.\":\n            titlelist.append(\"Mlle.\")\n        elif namelist[i] == \"Capt.\":\n            titlelist.append(\"Capt.\")\n        elif namelist[i] == \"the\":\n            titlelist.append(\"the\")\n        elif namelist[i] == \"Don.\":\n            titlelist.append(\"Don.\")\n        elif namelist[i] == \"Master.\":\n            titlelist.append(\"Master.\")\n        elif namelist[i] == \"Rev.\":\n            titlelist.append(\"Rev.\")\n        elif namelist[i] == \"Mme.\":\n            titlelist.append(\"Mme.\")\n        elif namelist[i] == \"Major.\":\n            titlelist.append(\"Major.\")\n        else:\n            titlelist.append(\"sometitle\")\n    print(set(namelist))\n    return titlelist","d0401db9":"titlelist = name_to_int(df)\ndf[\"titles\"] = titlelist\ndf[\"titles\"].value_counts()\n\ntesttitlelist = name_to_int(test_df)\ntest_df[\"titles\"] = testtitlelist","979f54d4":"df[\"titles\"].replace([\"Ms.\",\"Jonkheer.\",\"the\",\"Don.\",\"Capt.\",\"Sir.\",\"Lady.\",\"Mme.\",\"Col.\",\"Major.\"],\"sometitle\", inplace = True)\ntest_df[\"titles\"].replace([\"Ms.\",\"Jonkheer.\",\"the\",\"Don.\",\"Capt.\",\"Sir.\",\"Lady.\",\"Mme.\",\"Col.\",\"Major.\"],\"sometitle\", inplace = True)\n\ndf[\"titles\"].replace(\"Mlle.\",\"Miss.\", inplace = True)\ntest_df[\"titles\"].replace(\"Mlle.\",\"Miss.\", inplace = True)\n\ntest_df[\"titles\"].value_counts()","1b2b7b9d":"df[\"titles\"].replace([\"Mr.\", \"Miss.\", \"Mrs\", \"Master.\", \"Dr.\", \"Rev.\", \"sometitle\"],[0,1,2,3,4,5,6], inplace = True)\ndf[\"titles\"].astype(\"int64\")\n\ntest_df[\"titles\"].replace([\"Mr.\", \"Miss.\", \"Mrs\", \"Master.\", \"Dr.\", \"Rev.\", \"sometitle\"],[0,1,2,3,4,5,6], inplace = True)\ntest_df[\"titles\"].astype(\"int64\")\n\ndf.drop([\"Name\"], axis = 1, inplace = True)\ntest_df.drop([\"Name\"], axis = 1, inplace = True)","5ff33e99":"df.drop([\"SibSp\",\"Parch\",\"Fare\",\"n_fam_mem\",\"actual_fare\"], axis = 1, inplace = True)\ntest_df.drop([\"SibSp\",\"Parch\",\"Fare\",\"n_fam_mem\",\"actual_fare\"], axis = 1, inplace = True)","f67e5bce":"df.info()\nf,ax = plt.subplots(figsize=(15, 13))\nsns.heatmap(df.corr(), annot=True,cmap = \"Blues\", linewidths=.5, fmt= '.2f',ax = ax)\nplt.show()","e7498d5d":"labels = df[\"Survived\"]\ndata = df.drop(\"Survived\", axis = 1)\n\nX_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size = 0.1)","2a46c118":"final_clf = None\nclf_names = [\"Logistic Regression\", \"KNN(3)\", \"KNN(5)\", \"Random forest classifier\", \"Decision Tree Classifier\",\n            \"Gradient Boosting Classifier\", \"Support Vector Machine\"]\nclassifiers = []\nscores = []","be846abb":"bestknn5 = None\nbestknn3 = None\nbestrf = None\nbestgb = None\nbestcvm = None\nbestlr = None\nbestdt = None\nfor i in range(10):\n    \n    X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size = 0.1)\n    tempscores = []\n    \n    # logistic Regression\n    lr_clf = LogisticRegression()\n    lr_clf.fit(X_train, Y_train)\n    tempscores.append((lr_clf.score(X_test, Y_test))*100)\n    if lr_clf.score(X_test, Y_test)*100 > 85:\n        bestlr = lr_clf\n    \n    # KNN n_neighbors = 3\n    knn3_clf = KNeighborsClassifier()\n    knn3_clf.fit(X_train, Y_train)\n    tempscores.append((knn3_clf.score(X_test, Y_test))*100)\n    if knn3_clf.score(X_test, Y_test)*100 > 85:\n        bestknn3 = knn3_clf\n\n    # KNN n_neighbors = 5\n    knn5_clf = KNeighborsClassifier()\n    knn5_clf.fit(X_train, Y_train)\n    tempscores.append((knn5_clf.score(X_test, Y_test))*100)\n    if knn5_clf.score(X_test, Y_test)*100 > 85:\n        bestknn5 = knn5_clf\n\n    # Random Forest\n    rf_clf = RandomForestClassifier(n_estimators = 100)\n    rf_clf.fit(X_train, Y_train)\n    tempscores.append((rf_clf.score(X_test, Y_test))*100)\n    if rf_clf.score(X_test, Y_test)*100 > 85:\n        bestrf = rf_clf\n\n    # Decision Tree\n    dt_clf = DecisionTreeClassifier()\n    dt_clf.fit(X_train, Y_train)\n    tempscores.append((dt_clf.score(X_test, Y_test))*100)\n    if dt_clf.score(X_test, Y_test)*100 > 85:\n        bestdt = dt_clf\n\n    # Gradient Boosting \n    gb_clf = GradientBoostingClassifier()\n    gb_clf.fit(X_train, Y_train)\n    tempscores.append((gb_clf.score(X_test, Y_test))*100)\n    if gb_clf.score(X_test, Y_test)*100 > 85:\n        bestgb = lr_clf\n\n    #SVM\n    svm_clf = SVC(gamma = \"scale\")\n    svm_clf.fit(X_train, Y_train)\n    tempscores.append((svm_clf.score(X_test, Y_test))*100)\n    if svm_clf.score(X_test, Y_test)*100 > 85:\n        bestsvm = svm_clf\n    \n    scores.append(tempscores)","750bc6da":"scores = np.array(scores)\nclfs = pd.DataFrame({\"Classifier\":clf_names})\nclfs[\"iteration0\"] = scores[0].T\nclfs[\"iteration1\"] = scores[1].T\nclfs[\"iteration2\"] = scores[2].T\nclfs[\"iteration3\"] = scores[3].T\nclfs[\"iteration4\"] = scores[4].T\nclfs[\"iteration5\"] = scores[5].T\nclfs[\"iteration6\"] = scores[6].T\nclfs[\"iteration7\"] = scores[7].T\nclfs[\"iteration8\"] = scores[8].T\nclfs[\"iteration9\"] = scores[9].T\n\nmeans = clfs.mean(axis = 1)\nmeans = means.values.tolist()\n\nclfs[\"Average\"] = means","655e6ddc":"clfs.head(10)","5a95a2ab":"final_clf = bestsvm","2d7d1512":"test_data = test_df\npredictions = final_clf.predict(test_data)\nprint(len(predictions))","4e3d1120":"final_csv = []\ncsv_title = ['PassengerId', 'Survived']\nfinal_csv.append(csv_title)\nfor i in range(len(predictions)):\n    passengerid = i + 892\n    survived = predictions[i]\n    temp = [passengerid, survived]\n    final_csv.append(temp)\n\nprint(len(final_csv))\n\nwith open('submission_csv.csv', 'w') as file:\n    writer = csv.writer(file)\n    writer.writerows(final_csv)\nfile.close()","c26da3a4":"**Defining and choosing the best from one of the classifiers given below : **\n1. Logistic Regression\n2. K-nearest Neighbors with n_neighbors = 3\n3. K-nearest Neighbors with n_neighbors = 5\n4. Random Forest Classifier\n5. Decision Tree Classifier\n6. Gradient Boosting Classifier\n7. Support Vector Machine","bd3e5e1c":"Now Choosing the classifier accordingly,\nhere we have used SVM.","5c068967":"There is no object type data left. You can check this by df.info()","081ef57a":"**Fare Ranges = less than 7 , 7-14 , 14-30 , 30-50 , more than 50 **","0f2eedb3":"Now checking class distribution of **pclass**, i.e., how many people from each class survived.","72fbe354":"* Now, the columns **Sex** and **Embarked** are object type columns, thus we need to change them to numeric type.","d9b9d6a9":"Below is a dictionary that maps to the title of a person to a label, this includes all the title present in the dataframe.","0c3ea7ff":"Using the **parch** and **sibsp** column we can make a new column named no. of family members onboard **(n_fam_mem)**. \nAnd visualizing results.","feba30d7":"Now we will divide the n_fam_mem into specific ranges or type, say single person (0), small family (1) or big family (2), ","7ab62eed":"Checking data in sibsp (sibling\/spouse) and parch(parent\/children), basically these columns gives information about how many family members the person is travelling with.","db45b68f":"Dividing the actual fare into 5 different ranges.","def432ec":"Now the **name** column has unique data item in every row, but each name has a title with it. We can use the title and check if it relates to something.","058e9ee1":"As we can see a lot of titles occur only one thus we will replace this by \"sometitle\"","12b910be":"Saving final resutls into the csv file for submission.","44c6dd19":"New we use the trained classifier to make predictions on the testing data.\n","1cb4febb":"Now the data in **Fare** seems like it is the total of what the passenger paid including the fare of the other family members, so we create a new column named actual_fare i.e., the fare divided by n_fam_mem + 1.","99c4db79":"Next step is to dividing data into Training data and training labels, where labels is \"Survived\" column, and then splitting training data into train and test sets.","ff488e73":"**Correlation map :**","97a2b9b3":"**Cabin** column has a lot of unique values, we can still use the alphabetical cabin type but it wont improve our model much thus dropping it would be the best.","a56df288":"The above figure shows that most of the people from class 3 did'nt survive while nearly equal no. of people from the 2nd class did and did not survive, while more people of the 1st class survived as compared to non survival rate, thus pclass is an important data for training the classifier.","55df34ae":"The column **Age** contains continuous data, thus dividing it into particular ranges.","e4df4abd":"The data contains a lot of missing values in columns **Age** and **Cabin**.\nto fill missing values we will fill those missing values in **Age** column with \"-1\".\n\n**Cabin** Column contains 687 missing values out of a total of 891 values, we'll check what type of values cabin col has.","0ab35c97":"Also, the PassengerId column only tells about the id of the passenger travelling on the ship thus it is useless for training purpose thus dropping PassengerId. ","6542c2fe":"We have cleaned and processed the data, we only need to get rid of a few original columns which we used to derive new columns. we need to drop :\n(Fare, n_fam_mem, actual_fare)"}}