{"cell_type":{"c5d5b9b4":"code","b5907742":"code","71c17e9c":"code","096aa547":"code","589f0bc9":"code","c6022beb":"code","53faac3a":"code","ef2db83e":"code","7bdbe8d2":"code","7edf6640":"code","3a2f6d6f":"code","b75549a5":"code","6258dd79":"code","44515004":"code","184c87a4":"markdown","04620b61":"markdown","59e19803":"markdown","baf75d99":"markdown","9aa11abc":"markdown","2b2e8721":"markdown","62e63609":"markdown","df97e4c8":"markdown","edfdd0f8":"markdown","1f60ef9a":"markdown","28c5314c":"markdown","58bffd3a":"markdown","e0d46a1a":"markdown","5a679ed1":"markdown"},"source":{"c5d5b9b4":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\n\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n)\n\n# ao usar o Kaggle, o root deve apontar para '..\/input\/cifar10_pytorch\/data'\n\ntrainset = torchvision.datasets.CIFAR10(root='..\/input\/cifar10-pytorch\/cifar10_pytorch\/data', train=True,\n                                        download=False, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='..\/input\/cifar10-pytorch\/cifar10_pytorch\/data', train=False,\n                                       download=False, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=4,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","b5907742":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image\ndef imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n\n# print labels\nprint(' '.join('%5s' % classes[labels[j]] for j in range(4)))","71c17e9c":"import torch.nn as nn\nimport torch.nn.functional as F\n\n#aumentando o kernelSize\nclass NetFirst(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(10, 20, 5)\n        self.conv2_bn = nn.BatchNorm2d(20)\n        self.fc1 = nn.Linear(20 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = self.conv2_bn(x)\n        x = x.view(-1, 20 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\nnet = NetFirst()\n\n\n#Accuracy First: [58%, 57%, 64%, 56%, 59%]\n#M\u00e9dia accuracy first: 58.8%\n\n\n\n#Executando convolu\u00e7\u00e3o, pooling e normaliza\u00e7\u00e3o para conv1 e conv2. E depois 4 Lineares.\n\nclass NetSecond(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 5)\n        self.conv1_bn = nn.BatchNorm2d(10)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(10, 20, 5)\n        self.conv2_bn = nn.BatchNorm2d(20)\n        self.fc1 = nn.Linear(20 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 42)\n        self.fc4 = nn.Linear(42, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = self.conv1_bn(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = self.conv2_bn(x)\n        x = x.view(-1, 20 * 5 * 5) \n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        return x\n\n\nnet = NetSecond()\n\n\n#Accuracy Second: [57%, 63%, 56%, 60%, 64%]\n#M\u00e9dia accuracy Second: 60%\n\n\n\n\n\n#Executando convolu\u00e7\u00e3o, normaliza\u00e7\u00e3o e pooling para conv1 e conv2. E 2 vezes Lineares com valores 10x maior do que NetSecond.\n\n\nclass NetThird(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 5)\n        self.conv1_bn = nn.BatchNorm2d(10)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(10, 20, 5)\n        self.conv2_bn = nn.BatchNorm2d(20)\n        self.fc1 = nn.Linear(20 * 5 * 5, 1200)\n        self.fc2 = nn.Linear(1200, 840)\n\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.conv1_bn(x)\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.conv2_bn(x)\n        x = self.pool(x)\n        x = x.view(-1, 20 * 5 * 5) \n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n\n        return x\n\n\nnet = NetThird()\n\n\n\n\n\n#Accuracy Third: [62%, 65%, 67%, 59%, 61%]\n#M\u00e9dia accuracy third: 62.8%\n","096aa547":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)","589f0bc9":"for epoch in range(2):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss \/ 2000))\n            running_loss = 0.0\n\nprint('Finished Training')","c6022beb":"dataiter = iter(testloader)\nimages, labels = dataiter.next()\n\n# print images\nimshow(torchvision.utils.make_grid(images))\nprint('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))","53faac3a":"outputs = net(images)","ef2db83e":"_, predicted = torch.max(outputs, 1)\n\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                              for j in range(4)))","7bdbe8d2":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct \/ total))","7edf6640":"class_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n        for i in range(4):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(10):\n    print('Accuracy of %5s : %2d %%' % (\n        classes[i], 100 * class_correct[i] \/ class_total[i]))","3a2f6d6f":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nnet = Net()\nnet.to(device)\n\ncriterion = nn.CrossEntropyLoss().to(device)\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n\nfor epoch in range(2):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss \/ 2000))\n            running_loss = 0.0\n\nprint('Finished Training')","b75549a5":"correct = 0\ntotal = 0\n\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data[0].to(device), data[1].to(device)\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct \/ total))","6258dd79":"print(net)","44515004":"import numpy as np\n\n# precisa colocar os prints na defini\u00e7\u00e3o da rede\nx = torch.Tensor(np.ones((1,3,32,32)))\nnet.forward(x)","184c87a4":"### Configurando a rede ","04620b61":"### Utilizando a predi\u00e7\u00e3o da rede (feed-forward)","59e19803":"### Movendo os dados para GPU e executando novamente o treinamento","baf75d99":"### Exibindo a acur\u00e1cia por classe","9aa11abc":"### PyTorch e o m\u00f3dulo TorchVision para vis\u00e3o computacional","2b2e8721":"### Mostrando como fica o modelo depois de compilado","62e63609":"### Verificando a acur\u00e1cia do conjunto de teste","df97e4c8":"### Mostrando a acur\u00e1cia nas amostras de teste","edfdd0f8":"## Redes Neurais Convolucionais (CNN, \"Convolutional Neural Networks\")\n\nO objetivo desse notebook \u00e9 trazer a implementa\u00e7\u00e3o e os principais componentes de uma rede neural convolucional utilizando o framework PyTorch. A seguir tamb\u00e9m est\u00e3o alguns links com mais informa\u00e7\u00f5es que pode ajudar a compreender melhor esse tipo de rede al\u00e9m do conte\u00fado visto em aula.\n\nAs redes neurais convolucionais dependem basicamente de 3 camadas para funcionarem: convolu\u00e7\u00e3o, sumariza\u00e7\u00e3o (pooling) e, mais recentemente, normaliza\u00e7\u00e3o. Pode-se dizer que essas redes foram definidas, quase que em toda sua completude, em 1980 por Kunihiko Fukushima, e era chamada de \"neocognitron\".\n\nO material a seguir \u00e9 baseado no tutorial do PyTorch e algumas especificidades foram inclu\u00eddas, como a camada de normaliza\u00e7\u00e3o, e a correta migra\u00e7\u00e3o do c\u00f3digo para GPU. O link original do tutorial e outros materiais est\u00e3o dispon\u00edveis a seguir, bem como o restante da implementa\u00e7\u00e3o e da aula.\n\n---\n\nLinks \u00dateis:\n\n*  \"Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position\", de Kunihiko Fukushima:\n\n> http:\/\/www.cs.princeton.edu\/courses\/archive\/spr08\/cos598B\/Readings\/Fukushima1980.pdf\n\n* Post sobre a camada de normaliza\u00e7\u00e3o em batelada nas redes neurais convolucionais:\n\n> http:\/\/mlexplained.com\/2018\/01\/10\/an-intuitive-explanation-of-why-batch-normalization-really-works-normalization-in-deep-learning-part-1\/\n\n* Reposit\u00f3rio que mant\u00e9m algumas bases de imagens e um ranking dos melhores m\u00e9todos e o desempenho deles:\n\n> http:\/\/rodrigob.github.io\/are_we_there_yet\/build\/classification_datasets_results.html\n\n* Como s\u00e3o calculados o tamanho das camadas numa rede neural convolucional?\n\n> https:\/\/medium.com\/@iamvarman\/how-to-calculate-the-number-of-parameters-in-the-cnn-5bd55364d7ca\n\n> https:\/\/pytorch.org\/docs\/stable\/nn.html#convolution-layers\n\n* Um kernel no Kaggle sobre vis\u00e3o computacional em imagens de gatos e cachorros:\n\n> https:\/\/www.kaggle.com\/hung96ad\/dogs-vs-cats-pytorch-cnn-without-transfer-learning\n\n* Este material \u00e9 baseado no tutorial de PyTorch dispon\u00edvel no site dos mantenedores:\n\n> https:\/\/pytorch.org\/tutorials\/beginner\/blitz\/cifar10_tutorial.html","1f60ef9a":"### Visualizando algumas imagens do dataset","28c5314c":"### Disparando o treinamento da rede","58bffd3a":"### Visualizando as amostras de ground truth","e0d46a1a":"### Configurando a fun\u00e7\u00e3o de custo e o otimizador","5a679ed1":"### Mostrando como o vetor de uma imagem se altera entre as camadas"}}