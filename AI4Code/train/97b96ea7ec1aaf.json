{"cell_type":{"fd15b938":"code","dca6b59a":"code","bc905b86":"code","b1087a5b":"code","4c8027cf":"code","07fbd4d6":"code","8b57d5b8":"code","c4ba31e9":"code","3d69fd6e":"code","e05f7116":"code","db5337ae":"code","a5582e17":"code","2dda1200":"code","259e6260":"code","00cb2bd8":"code","83783bc5":"code","425eba2a":"code","1bb05a71":"code","4fe8203f":"code","7a90cc64":"markdown","eb8c9e89":"markdown","acad570e":"markdown","a6952317":"markdown","1991452c":"markdown","c3d89609":"markdown","add059ea":"markdown","7b195102":"markdown","c99674a7":"markdown"},"source":{"fd15b938":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","dca6b59a":"df = pd.read_json(\"..\/input\/Sarcasm_Headlines_Dataset.json\",lines=True)","bc905b86":"df.sample(2)","b1087a5b":"print(\"size : \",df.shape)\nprint(\"checking null value:\\n\",df.isna().sum())","4c8027cf":"#dropping article link\ndf.drop(columns=[\"article_link\"], inplace=True)","07fbd4d6":"words = \" \"\nfor item in df.headline:\n    for inner_item in item.lower().split():\n        words+=inner_item+\" \"\n        \nfrom wordcloud import WordCloud, STOPWORDS \nstopwords = set(STOPWORDS) \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() ","8b57d5b8":"from sklearn.model_selection import train_test_split\ntrain_x,test_x,train_y,test_y = train_test_split(df.headline,df.is_sarcastic,test_size = 0.1)","c4ba31e9":"from sklearn.feature_extraction.text import TfidfVectorizer\nvect = TfidfVectorizer()\ntrain_X = vect.fit_transform(train_x)","3d69fd6e":"train_X.shape","e05f7116":"from xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nscores = []\nfor i in range(6,14):\n    model = XGBClassifier(max_depth = i)\n    model.fit(train_X,train_y)\n    target = model.predict(vect.transform(test_x))\n    score = accuracy_score(target,test_y)\n    scores.append(accuracy_score(target,test_y))\n    print (\"accuracy score: \",score,\" Depth: \",i)\nprint (scores)\nprint(\"best score: \",max(scores))","db5337ae":"#first 5 features\nvect.get_feature_names()[:5]","a5582e17":"import nltk\nimport nltk.corpus\nfrom nltk.stem import WordNetLemmatizer\nwordnet_lemmatizer = WordNetLemmatizer()\nwordnet_lemmatizer.lemmatize(\"beautifully\")","2dda1200":"import string\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')\nprint (\"punctuations that gonna be removed, : \",string.punctuation)\n\"\"\"\nPunctuation,\nremoving stop words\nwords with minimum length 3\nlemmatizing words\n\n\"\"\"\nheadlines = []\nfor item in df.headline:\n    word_data = \" \"\n    for item2 in item.split():\n        if item2.lower() not in stop_words:\n            word_data +=wordnet_lemmatizer.lemmatize(item2.lower())+\" \"\n    headlines.append(word_data)\ndf['refined'] = headlines\ndef process(text):\n    nopunc = ''.join([char for char in text if char not in string.punctuation])\n    clean_words = [word for word in nopunc.split() ]\n    clean_words = \" \".join(clean_words)\n    return clean_words\ndf['refined'] = df['refined'].apply(process)","259e6260":"df.sample()","00cb2bd8":"words = \" \"\nis_sarcasm = df[df.is_sarcastic==1].refined\nfor item in is_sarcasm:\n    for inner_item in item.lower().split():\n        words+=inner_item+\" \"\n        \nfrom wordcloud import WordCloud, STOPWORDS \nimport matplotlib.pyplot as plt\nstopwords = set(STOPWORDS) \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.title(\"Sarcasm\")\nplt.show() \n","83783bc5":"words = \" \"\nis_not_sarcasm = df[df.is_sarcastic==0].refined\nfor item in is_not_sarcasm:\n    for inner_item in item.lower().split():\n        words+=inner_item+\" \"\n        \nfrom wordcloud import WordCloud, STOPWORDS \nimport matplotlib.pyplot as plt\nstopwords = set(STOPWORDS) \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.title(\"NOT Sarcasm\")\nplt.show() \n","425eba2a":"from sklearn.model_selection import train_test_split\ntrain_x,test_x,train_y,test_y = train_test_split(df.refined,df.is_sarcastic,test_size = 0.1)\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvect = TfidfVectorizer(token_pattern = \"[a-zA-Z]{2,}\",max_features=2000,ngram_range=(1,2))\ntrain_X = vect.fit_transform(train_x)\n","1bb05a71":"from sklearn.metrics import accuracy_score\nscores = []\nfor i in range(6,14):\n    model = XGBClassifier(max_depth = i)\n    model.fit(train_X,train_y)\n    target = model.predict(vect.transform(test_x))\n    score = accuracy_score(target,test_y)\n    scores.append(score)\n    print (\"accuracy score: \",score,\" Depth: \",i)\nprint (scores)\nprint(\"best score: \",max(scores))","4fe8203f":"vect.get_feature_names()[:5]","7a90cc64":"* So now, we start cleaning the data \n* 1. removing punctuations\n* 2. removing numbers \n* 3. removing stopwords(that occur frequently like them,our,your)\n* 4. Lemmatization(ex : \"dogs\" ,\"dog\" either of them will be converted to \"dog\")\n* 5. (further if any..)","eb8c9e89":"Let's see word cloud based on sarcasm and not sacrcasm ","acad570e":"let's build and test the model","a6952317":"Let's see some data","1991452c":"I would like to know, \n* On what parameters I can improve my accuracy score?\n* Using which model can I increase accuracy?\n* Why model isn't functioning better after refining?","c3d89609":"Let's check the words of **headline** column using WORDCLOUD","add059ea":"seems like man, new, report, trump, are common in headlines.","7b195102":"Let's build and run the model ","c99674a7":"Hello friends, let's get started"}}