{"cell_type":{"2d9b6232":"code","1da7d973":"code","ea639cc2":"code","15b5b675":"code","3d72087e":"code","d270be98":"code","965dd97c":"code","f3ed8b6a":"code","bc527837":"code","c296b727":"code","2d93e582":"code","1e82bf74":"code","47e5e8a6":"code","45a41394":"code","49168938":"code","99c718bc":"code","802f5a76":"markdown","32163f52":"markdown","9ea80e79":"markdown","d6080bb8":"markdown"},"source":{"2d9b6232":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1da7d973":"# import libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt","ea639cc2":"print(tf.__version__)","15b5b675":"train_data = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest_data = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')","3d72087e":"x = train_data.drop(['label'], axis = 1)\ny = train_data['label']","d270be98":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state =1)","965dd97c":"# feature scaling\nx_train = x_train \/ 255.0\nx_test = x_test \/ 255.0","f3ed8b6a":"# initializng the ANN\nann = keras.models.Sequential()","bc527837":"# Adding the input layer and the hidden layers\nann.add(keras.layers.Flatten(input_shape=(28, 28)))","c296b727":"# Adding the second hidden layer\nann.add(keras.layers.Dense(128, activation='relu'))","2d93e582":"# Adding the output layer\nann.add(keras.layers.Dense(10))","1e82bf74":"# compiling the ANN\nann.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","47e5e8a6":"# Training the ANN on the Training set\nann.fit(x_train, y_train, epochs=10)","45a41394":"# evaluate accuracy\ntest_loss, test_acc = ann.evaluate(x_test,  y_test, verbose=2)\nprint('\\nTest accuracy:', test_acc)","49168938":"# make predictions\nprobability_model = tf.keras.Sequential([ann, \n                                         tf.keras.layers.Softmax()])","99c718bc":"predictions = probability_model.predict(x_test)","802f5a76":"# Part 3: Training the ANN","32163f52":"# Part 2: Building ANN","9ea80e79":"# Part 4: Making predictions","d6080bb8":"# Part 1: Data preprocessing"}}