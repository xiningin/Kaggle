{"cell_type":{"29de6e53":"code","31bab68e":"code","2873cb9e":"code","955e7372":"code","b4bd141d":"code","889b8876":"code","1b805d9b":"code","fc46ae28":"code","a20faca7":"code","dbdd2d82":"code","10232274":"code","08cbfeca":"code","6b1cdb88":"code","d8cbbc32":"code","591e74f6":"code","cdfd4aa1":"code","5b1b9984":"code","b4aed70e":"code","3629a34c":"code","7ef13313":"code","b675cc93":"code","ac4a2fb8":"code","787e6ee0":"code","d9c5bbd6":"code","c5170c8e":"code","59ad5550":"markdown","e18b5b18":"markdown","8881ab78":"markdown","553abb16":"markdown","21547e21":"markdown","0d5fcc2c":"markdown","9b914504":"markdown","e64809fb":"markdown","9a422531":"markdown","32820a03":"markdown","bda4c28c":"markdown","611f5206":"markdown","38a453f4":"markdown","000aef7c":"markdown","23f52803":"markdown","4f970d63":"markdown","3e3b352d":"markdown","65635c16":"markdown","1fd083d7":"markdown","ddbeaa01":"markdown","b17598bc":"markdown","a0eb616d":"markdown"},"source":{"29de6e53":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import Ridge\npd.set_option('display.max_columns', None)\n%matplotlib inline","31bab68e":"train_data = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","2873cb9e":"train_data.head()","955e7372":"train_data.shape","b4bd141d":"# unimportant features - known from data description\nunwanted_features = [\n    'Neighborhood', 'Condition1', 'Condition2', 'RoofStyle', 'RoofMatl',\n    'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'TotalBsmtSF', 'Heating', 'MiscFeature',\n    'Electrical', 'Functional', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'SaleCondition',\n    'LandSlope', # known from LandContour\n    'HouseStyle', # related to BldgType\n    'GarageCars', # related to GarageArea\n    # related to OverallQual, OverallCond\n    'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation'\n]\nnew_data = train_data.drop(unwanted_features, axis=1)","889b8876":"new_data.shape","1b805d9b":"# get columns with nan values\nnan_per = new_data.isna().sum() \/ new_data.isna().count()\nnan_features = new_data.loc[:,nan_per > 0].columns\nnan_features","fc46ae28":"# get coulumns with nan percent >= threshold to delete them\nthreshold = 0.6\nnan_drop = new_data.loc[:,nan_per >= threshold].columns\nnew_data.drop(nan_drop, axis=1, inplace=True)\nnan_features = nan_features.drop(nan_drop) # remainder nan features","a20faca7":"new_data.shape","dbdd2d82":"# explore nan_features\nnew_data[nan_features].dtypes","10232274":"# fill categorical features nan values with 0 if nan has meaning\nnan_meaning_features = ['BsmtQual', 'BsmtCond', 'FireplaceQu']\nfor col in nan_meaning_features:\n    new_data[col].fillna(0, inplace=True)\nnan_features = nan_features.drop(nan_meaning_features)","08cbfeca":"# fill nan values with most frequency value\nfor col in nan_features:\n    new_data[col].fillna(new_data[col].mode().iat[0], inplace=True)","6b1cdb88":"new_data.isna().any().sum()","d8cbbc32":"# get categorical features\ncat_cols = new_data.select_dtypes('object').columns\ncat_cols","591e74f6":"# get unique values of categorical features\nfor col in cat_cols:\n    uv = new_data[col].unique()\n    print(f'{col} ({len(uv)}) ==> {uv}')","cdfd4aa1":"# map categorical values\nnew_data['MSZoning'] = new_data['MSZoning'].map({'C (all)': 1, 'FV': 2, 'RL': 3, 'RM': 4, 'RH': 5})\nnew_data['Street'] = new_data['Street'].map({'Pave': 1, 'Grvl': 2})\nnew_data['LotShape'] = new_data['LotShape'].map({'Reg': 1, 'IR1': 2, 'IR2': 3, 'IR3': 4})\nnew_data['LandContour'] = new_data['LandContour'].map({'Lvl': 1, 'Bnk': 2, 'HLS': 3, 'Low': 4})\nnew_data['Utilities'] = new_data['Utilities'].map({'AllPub': 1, 'NoSeWa': 2})\nnew_data['LotConfig'] = new_data['LotConfig'].map({'Inside': 1, 'Corner': 2, 'CulDSac': 4, 'FR2': 5, 'FR3': 6})\nnew_data['BldgType'] = new_data['BldgType'].map({'1Fam': 1, '2fmCon': 2, 'Duplex': 3, 'TwnhsE': 4, 'Twnhs': 5})\nnew_data['BsmtQual'] = new_data['BsmtQual'].map({0: 0, 'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\nnew_data['BsmtCond'] = new_data['BsmtCond'].map({0: 0, 'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\nnew_data['HeatingQC'] = new_data['HeatingQC'].map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\nnew_data['CentralAir'] = new_data['CentralAir'].map({'Y': 1, 'N': 2})\nnew_data['KitchenQual'] = new_data['KitchenQual'].map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\nnew_data['FireplaceQu'] = new_data['FireplaceQu'].map({0: 0, 'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\nnew_data['SaleType'] = new_data['SaleType'].map({'WD': 1, 'CWD': 2, 'VWD': 3, 'New': 4, 'COD': 5, 'Con': 6, 'ConLw': 7, 'ConLI': 8, 'ConLD': 9, 'Oth': 10})","5b1b9984":"new_data.head()","b4aed70e":"correlations = new_data.corr()\nplt.figure(figsize = (16,16))\nsns.heatmap(correlations)","3629a34c":"uncorr_features = correlations['SalePrice'][correlations['SalePrice'] > -0.05]\nuncorr_features = uncorr_features[uncorr_features < 0.05]\nuncorr_features.index","7ef13313":"new_data.drop(uncorr_features.index[1:], axis=1, inplace=True)","b675cc93":"new_data.shape","ac4a2fb8":"def process_data(data):\n    # All unimportant features\n    unwanted_features = [\n        'Neighborhood', 'Condition1', 'Condition2', 'RoofStyle', 'RoofMatl',\n        'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'TotalBsmtSF', 'Heating', 'MiscFeature',\n        'Electrical', 'Functional', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'SaleCondition',\n        'LandSlope', 'HouseStyle', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n        'Alley', 'PoolQC', 'Fence',\n        'Street', 'Utilities', 'BldgType', 'BsmtFinSF2', 'LowQualFinSF',\n       'BsmtHalfBath', '3SsnPorch', 'MiscVal', 'MoSold', 'YrSold'\n    ]\n    new_data = data.drop(unwanted_features, axis=1)\n    # fill categorical features nan values with 0 if nan has meaning\n    nan_meaning_features = ['BsmtQual', 'BsmtCond', 'FireplaceQu']\n    for col in nan_meaning_features:\n        new_data[col].fillna(0, inplace=True)\n    # fill nan values with most frequency value\n    nan_features = ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n    for col in nan_features:\n        new_data[col].fillna(new_data[col].mode().iat[0], inplace=True)\n    # map categorical values\n    new_data['MSZoning'] = new_data['MSZoning'].map({'C (all)': 1, 'FV': 2, 'RL': 3, 'RM': 4, 'RH': 5})\n    new_data['LotShape'] = new_data['LotShape'].map({'Reg': 1, 'IR1': 2, 'IR2': 3, 'IR3': 4})\n    new_data['LandContour'] = new_data['LandContour'].map({'Lvl': 1, 'Bnk': 2, 'HLS': 3, 'Low': 4})\n    new_data['LotConfig'] = new_data['LotConfig'].map({'Inside': 1, 'Corner': 2, 'CulDSac': 4, 'FR2': 5, 'FR3': 6})\n    new_data['BsmtQual'] = new_data['BsmtQual'].map({0: 0, 'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\n    new_data['BsmtCond'] = new_data['BsmtCond'].map({0: 0, 'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\n    new_data['HeatingQC'] = new_data['HeatingQC'].map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\n    new_data['CentralAir'] = new_data['CentralAir'].map({'Y': 1, 'N': 2})\n    new_data['KitchenQual'] = new_data['KitchenQual'].map({'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\n    new_data['FireplaceQu'] = new_data['FireplaceQu'].map({0: 0, 'Ex': 1, 'Gd': 2, 'TA': 3, 'Fa': 4, 'Po': 5})\n    new_data['SaleType'] = new_data['SaleType'].map({'WD': 1, 'CWD': 2, 'VWD': 3, 'New': 4, 'COD': 5, 'Con': 6, 'ConLw': 7, 'ConLI': 8, 'ConLD': 9, 'Oth': 10})\n    return new_data","787e6ee0":"new_data = process_data(train_data)\nrows, cols = new_data.shape\nX_train = new_data.iloc[:, 1: cols-1]\ny_train = new_data.iloc[:, cols-1:]\nr = Ridge(alpha=100).fit(X_train, y_train)","d9c5bbd6":"test_data = process_data(pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv'))\ntr, tc = test_data.shape\nX_test = test_data.iloc[:, 1: cols-1]\nX_test.fillna(0, inplace=True)\ny_pred = r.predict(X_test)","c5170c8e":"ids = test_data.iloc[:,:1]\ny_pred_df = pd.DataFrame(y_pred, columns=['SalePrice'])\nresult = pd.concat([ids, y_pred_df], axis=1)\nresult.to_csv('submit.csv', index=False)","59ad5550":"Categorical values can be either nominal or ordinal, so,I decided to look at unique values and try to recognise what kind are there","e18b5b18":"# 6- Train Model","8881ab78":"now we have features with missing values and its percentage","553abb16":"finally, I can see numbers only","21547e21":"now I need to ask fewer questions","0d5fcc2c":"# 5- Build Pipeline\nPipelines are good friends in Data Processing. Since we need to process training data and test data, we can build a function that takes our dataset and process it","9b914504":"### 2.2.1- Nan is not Nan\nAccording to data description, Nan can mean that this feature is absent which means 0","e64809fb":"### 2.2.2- Fill missing values","9a422531":"we find that some features are numerical and some features are categorical, so we can handle each of them separately, but, I decided to use Mode method (fill missing values with the most frequently value) which works fine with both numerical and categorical values","32820a03":"It seems that there are many questions to ask when I want to buy a new house","bda4c28c":"# 2- Holes in Data!\nWhen it comes to missing values, we can drop the whole feature or fill the missing values with some arbitrary value","611f5206":"and here,we avoided all holes","38a453f4":"# 8- Submission","000aef7c":"In this notebook, I am trying to practise some basics of Feature Engineering to make Ridge Regression model (and I got score 0.16675)","23f52803":"According to data description and unique values, they are ordinal, so, we can map them with simple numbers","4f970d63":"# 3- Numbers only\nComputer can deal with numbers only, so, we need to map any other data types to numbers","3e3b352d":"# 1- Recognize our Data\nfirst, I go throw data description and try to identify some of unimportant features (features I may not be interested in when buying new house and features can beknown from other features)","65635c16":"Now, we need to set a threshold for our relations","1fd083d7":"# 4- SalePrice Best Friends\nWe need to know that features are really have a strong relationship with our SalePrice, we can plot heatmap to see that","ddbeaa01":"## 2.2- Fill missing values\nnow we come to fill the missing values in feature with small missing values","b17598bc":"## 2.1- Delete features with big holes\nI decided to delete features which has missing value percentage >= 60%","a0eb616d":"# 7- Test Model"}}