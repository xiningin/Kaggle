{"cell_type":{"76850608":"code","db37c038":"code","7159fd57":"code","bd20810e":"code","70329362":"code","1ef28d33":"code","cd44b190":"code","f733bc68":"code","7c12f3a3":"code","05d966d7":"code","c257385b":"code","eda709e7":"code","c27fa3a2":"code","2eced3ec":"code","3fdb0bd2":"code","06d037d9":"code","f1012d5f":"code","048aae5f":"code","d758634e":"code","af94748a":"code","57e70e21":"code","2304ce56":"code","f9003ab9":"code","1cad156d":"code","fe79699a":"code","38de48ac":"code","9b976844":"code","c4400844":"code","5b244153":"code","a759cbf4":"code","375d808c":"code","b85abb76":"code","0ee1f424":"code","e90d300f":"code","34e6788d":"code","9623f7e1":"code","39f1dc5c":"code","785cd6a6":"code","c05f0f94":"code","9e2b9df4":"code","7ab1d343":"markdown","4105156d":"markdown","147e4402":"markdown","6a1c353b":"markdown","8f1f5ece":"markdown","03412f3f":"markdown","b28fa31c":"markdown","693422dc":"markdown","3dde76d9":"markdown","542bbf26":"markdown","80e0b2d2":"markdown","e2a2e76c":"markdown"},"source":{"76850608":"%config Completer.use_jedi = False","db37c038":"#  Installing ktrain\n!pip install ktrain","7159fd57":"# Standard imports\nimport os\nimport pprint\nimport json\nimport pandas as pd\nimport numpy as np\nfrom IPython.display import display\n\n# For plotting\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# For Evaluation and model selection \nfrom sklearn.model_selection import *\nfrom sklearn.metrics import *\n\n# For model building\nimport tensorflow as tf\nimport ktrain\nfrom ktrain import text","bd20810e":"params = {}\nparams['train_csv'] = \"..\/input\/commonlitreadabilityprize\/train.csv\"\nparams['test_csv'] = \"..\/input\/commonlitreadabilityprize\/test.csv\"\nparams['sample_sub'] = \"..\/input\/commonlitreadabilityprize\/sample_submission.csv\"","70329362":"train_df = pd.read_csv(params['train_csv'])\ntest_df = pd.read_csv(params['test_csv'])","1ef28d33":"train_df.isnull().sum()","cd44b190":"test_df.isnull().sum()","f733bc68":"train_df.head()","7c12f3a3":"test_df","05d966d7":"# Checking whether we have any duplicates in test and train\nprint(f\"Number of ids in train : {len(train_df)}\")\nprint(f\"Number of unique ids in train : {len(train_df['id'].unique())}\")\n\nprint(f\"Number of ids in test : {len(test_df)}\")\nprint(f\"Number of unique ids in test : {len(test_df['id'].unique())}\")","c257385b":"train_ids = set(train_df['id'].values)\ntest_ids = set(test_df['id'].values)\n\nif len(train_ids.intersection(test_ids)) > 0:\n    print(f\"Common ids in train and test : {train_ids.intersection(test_ids)}\")\nelse:\n    print(\"No intersection\")","eda709e7":"fig = px.histogram(train_df, x = 'target')\nfig.update_layout(\n        title_text = \"Distribution of targets\",\n        title_x = 0.5,\n)\nfig.show()","c27fa3a2":"print(f\"Mean of my labels : {np.mean(train_df['target'])}\")\nprint(f\"Std of my labels : {np.std(train_df['target'])}\")","2eced3ec":"max_ = 0; min_ = 1e9\nfor i in train_df.excerpt.values:\n    max_ = max(max_, len(i))\n    min_ = min(min_, len(i))\n\nmax_, min_","3fdb0bd2":"def create_folds(data, target=\"target\", num_splits = 5): \n    data[\"kfold\"] = -1 \n    data = data.sample(frac=1).reset_index(drop=True)\n    \n    # Applying Sturg's rule to calculate the no. of bins for target\n    num_bins = int(1 + np.log2(len(data))) \n\n    data.loc[:, \"bins\"] = pd.cut(data[target], bins=num_bins, labels=False) \n    kf = StratifiedKFold(n_splits=num_splits) \n    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)): \n        data.loc[v_, 'kfold'] = f\n        \n    data = data.drop([\"bins\"], axis = 1)         \n    return data \n\ntrain_df = create_folds(train_df, target = 'target', num_splits = 4)\ntrain_df.kfold.value_counts()","06d037d9":"# Splitting into train and val\n\ntrain_set = train_df.loc[train_df.kfold != 3]\nval_set = train_df.loc[train_df.kfold == 3]\n\nlen(train_set), len(val_set)","f1012d5f":"X_train = train_set.excerpt.values\nX_val = val_set.excerpt.values\n\ny_train = train_set.target.values\ny_val = val_set.target.values","048aae5f":"y_train","d758634e":"trn, val, preproc = text.texts_from_array(\n                        x_train=X_train, y_train=y_train,                                          \n                        x_test=X_val, y_test=y_val,                                          \n                        ngram_range=3,                                          \n                        maxlen=512,                                           \n                        max_features=35000,\n                        preprocess_mode='bert'\n                    )","af94748a":"text.print_text_regression_models()","57e70e21":"model = text.text_regression_model('bert',\n                                  train_data = trn,\n                                  preproc = preproc)\n# Setting our learner\nlearner = ktrain.get_learner(\n    model, \n    train_data = trn,\n    val_data = val,\n    batch_size = 6\n)","2304ce56":"# Estimating the optimizer Learning rate\n\nlearner.lr_find()","f9003ab9":"learner.lr_plot()","1cad156d":"learner.fit_onecycle(1e-4, 10)","fe79699a":"learner.view_top_losses(n=3, preproc = preproc)","38de48ac":"hist = learner.history.history\ntrain_loss = hist['loss']\nval_loss = hist['val_loss']\n\ntrain_mae = hist['mean_absolute_error']\nval_mae = hist['val_mean_absolute_error']\n\nepochs = [d for d in range(1, len(train_loss)+1)]\n\nlr = hist['lr']\niters = hist['iterations']\n","9b976844":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=epochs, y=train_loss,\n                    mode='lines+markers',\n                    name='train_loss'))\nfig.add_trace(go.Scatter(x=epochs, y=val_loss,\n                    mode='lines+markers',\n                    name='val_loss'))\nfig.add_trace(go.Scatter(x=epochs, y=train_mae,\n                    mode='lines+markers', name='train_mae'))\nfig.add_trace(go.Scatter(x=epochs, y=val_mae,\n                    mode='lines+markers', name='val_mae'))\n\nfig.update_layout(\n    title_text = \"Training Results\",\n    title_x = .5,\n    xaxis_title = \"EPOCHS\",\n    yaxis_title = \"Values\"\n)\nfig.show()","c4400844":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=iters, y=lr,\n                    mode='markers',\n                    name='Learning Rate'))\n\nfig.update_layout(\n    title_text = \"Learning rate\",\n    title_x = .5,\n    xaxis_title = \"Iterations\",\n    yaxis_title = \"Learning rates\"\n)\nfig.show()","5b244153":"predictor = ktrain.get_predictor(learner.model, preproc)","a759cbf4":"val_preds = []\nfor txt in X_val:\n    val_preds.append(predictor.predict(txt))","375d808c":"# Model performance\nrmse = mean_squared_error(val_preds, y_val, squared = False)\nprint(f\"Model Score : {round(rmse,3)}\")","b85abb76":"!mkdir .\/model_BERT_token_BERT_CLRP\npredictor.save(\".\/model_BERT_token_BERT_CLRP\/model\")","0ee1f424":"!pip install kaggle","e90d300f":"!cp ..\/input\/kaggle-token\/kaggle_token.json .\/\n!mv .\/kaggle_token.json .\/kaggle.json","34e6788d":"!ls -l ..\/..\/root\n!cp .\/kaggle.json ..\/..\/root\/\n!ls ..\/..\/root","9623f7e1":"!mkdir ..\/..\/root\/.kaggle\n!mv ..\/..\/root\/kaggle.json ..\/..\/root\/.kaggle\/kaggle.json\n\n!chmod 600 \/root\/.kaggle\/kaggle.json\n!kaggle datasets init -p .\/model_BERT_token_BERT_CLRP","39f1dc5c":"!cat .\/model_BERT_token_BERT_CLRP\/dataset-metadata.json","785cd6a6":"import json\nwith open(\".\/model_BERT_token_BERT_CLRP\/dataset-metadata.json\", 'r+') as file_:\n    meta_data = json.load(file_)\n    meta_data['title'] = 'model_BERT_token_BERT_CLRP'\n    meta_data['id'] = 'hotsonhonet\/ModelsCLRP'\n    file_.seek(0)        \n    json.dump(meta_data, file_, indent=4)\n    file_.truncate()\n    \nprint(meta_data['title'], meta_data['id'])\n\n!cat .\/model_BERT_token_BERT_CLRP\/dataset-metadata.json","c05f0f94":"!mv .\/model_BERT_token_BERT_CLRP\/model\/* .\/model_BERT_token_BERT_CLRP","9e2b9df4":"!kaggle datasets create -p .\/model_BERT_token_BERT_CLRP ","7ab1d343":"# Creating training and validation datasets","4105156d":"# Config\n","147e4402":"# Lets Build our predictor and evaluate our model","6a1c353b":"## Splitting into features","8f1f5ece":"# Training and Inspecting Model","03412f3f":"# Loading dataset","b28fa31c":"Lets start with the infamous BERT model","693422dc":"# Visualizing results","3dde76d9":"# Distribution of labels","542bbf26":"# Importing Modules","80e0b2d2":"# Lets see what all regression models we have !!","e2a2e76c":"# Saving model"}}