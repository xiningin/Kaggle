{"cell_type":{"2e8d477a":"code","8783eec2":"code","1cdd3fd3":"code","b3768c34":"code","7ce5805c":"code","dcdf4923":"code","5e381a20":"code","d3adbbc4":"code","bb3f91e4":"code","45bcea95":"code","f067b7e9":"code","f1b3ef4a":"code","1006c331":"code","48e30a63":"code","5137804e":"code","794d0954":"code","3472cb1e":"code","69b54acf":"code","c8f9d916":"code","6dfa1625":"code","27a9eb93":"code","e2f175a9":"code","00fb99d3":"code","c1f27e92":"code","cbc39257":"code","9b46f7f8":"code","92af52b0":"code","4e40c154":"code","6a65d191":"code","9d937a1b":"code","40450d2f":"code","ee339a04":"code","bbfa5ac1":"code","8c7c38ab":"code","1835ae40":"code","b8aedea0":"code","1c140348":"code","7d1e684f":"markdown","b386b0eb":"markdown","844c7b21":"markdown","7a20f6bb":"markdown","299643a1":"markdown","5f933e2c":"markdown","738a571e":"markdown","eb41d076":"markdown","b2c79829":"markdown","616d44d2":"markdown","16bc6d7b":"markdown","75fe9149":"markdown","7294d418":"markdown","fd9c27db":"markdown","9b1cc517":"markdown","59eb6d60":"markdown","108ce230":"markdown","0463a096":"markdown","fbfb0e9f":"markdown","8b6e7eda":"markdown","74d0f0c8":"markdown","66600cc1":"markdown","0d82ea99":"markdown","4e6e3659":"markdown","fc0c5e8b":"markdown","c0e949ad":"markdown","abfba2a4":"markdown","2860d305":"markdown","489ac8e2":"markdown","f2b134a0":"markdown","3552060d":"markdown","e8ead7da":"markdown","b7520588":"markdown","2a27edbd":"markdown","130998ea":"markdown","5586aabc":"markdown","395aa458":"markdown","67bc6f2e":"markdown","23809be9":"markdown","d25f5c35":"markdown","20d33c80":"markdown","1fb138d3":"markdown","dcf878a2":"markdown","72100864":"markdown","d1081e8e":"markdown","16f35496":"markdown","945933dc":"markdown","74979d81":"markdown","877e9a2a":"markdown","60bd0b52":"markdown","614cd37c":"markdown","fd4938e6":"markdown","999fa6ff":"markdown","4116f3e3":"markdown","4414e1a4":"markdown","1f9d92f9":"markdown","6aef2b92":"markdown","c58f4a5c":"markdown"},"source":{"2e8d477a":"import numpy as np                                                 # Implemennts milti-dimensional array and matrices\nimport pandas as pd                                                # For data manipulation and analysis\nimport pandas_profiling\nimport matplotlib.pyplot as plt                                    # Plotting library for Python programming language and it's numerical mathematics extension NumPy\nimport seaborn as sns                                              # Provides a high level interface for drawing attractive and informative statistical graphics\n%matplotlib inline\nsns.set()\n\nfrom subprocess import check_output\n\n","8783eec2":"#If you get UnicodeDecodeError - 'utf8' codec can't decode, invalid continuation byte error, either use engine='python'\n#or encoding='latin-1' options\ncarsale = pd.read_csv(\"..\/input\/car-sale-advertisements\/car_ad.csv\",engine=\"python\")     # Importing car_sale dataset using pd.read_csv","1cdd3fd3":"carsale.shape    # This will print the number of rows and comlumns of the Data Frame","b3768c34":"carsale.columns  # This will print the names of all columns.","7ce5805c":"carsale.head()   # Will give you first 5 records","dcdf4923":"carsale.tail()   # This will print the last n rows of the Data Frame","5e381a20":"carsale.info() # This will give Index, Datatype and Memory information","d3adbbc4":"# Use include='all' option to generate descriptive statistics for all columns\n# You can get idea about which column has missing values using this\ncarsale.describe() ","bb3f91e4":"carsale.isnull().sum() # Will show you null count for each column, but will not count Zeros(0) as null","45bcea95":"profile = pandas_profiling.ProfileReport(carsale)\nprofile.to_file(outputfile=\"carsale_before_preprocessing_1.html\")","f067b7e9":"carsale.replace({'engType': 'Other', 'price': 0, 'mileage': 0}, np.nan, inplace=True)","f1b3ef4a":"profile = pandas_profiling.ProfileReport(carsale)\nprofile.to_file(outputfile=\"carsale_before_preprocessing_2.html\")","1006c331":"carsale.drop_duplicates(inplace=True) #inplace used to modify the dataset with applied command\ncarsale.shape","48e30a63":"def get_median_price(x):\n    brand = x.name[0]\n    if x.count() > 0:\n        return x.median() # Return median for a brand\/model if the median exists.\n    elif carsale.groupby(['car'])['price'].count()[brand] > 0:\n        brand_median = carsale.groupby(['car'])['price'].apply(lambda x: x.median())[brand]\n        return brand_median # Return median of brand if particular brand\/model combo has no median,\n    else:                 # but brand itself has a median for the 'price' feature. \n        return carsale['price'].median() # Otherwise return dataset's median for the 'price' feature.\n    \nprice_median = carsale.groupby(['car','model'])['price'].apply(get_median_price).reset_index()\nprice_median.rename(columns={'price': 'price_med'}, inplace=True)\nprice_median.head()","5137804e":"def fill_with_median(x):\n    if pd.isnull(x['price']):\n        return price_median[(price_median['car'] == x['car']) & (price_median['model'] == x['model'])]['price_med'].values[0]\n    else:\n        return x['price']\n    \ncarsale['price'] = carsale.apply(fill_with_median, axis=1)\ncarsale.head()","794d0954":"def get_median_engV(x):\n    brand = x.name[0]\n    if x.count() > 0:\n        return x.median() # Return median for a brand\/model if the median exists.\n    elif carsale.groupby(['car'])['engV'].count()[brand] > 0:\n        brand_median = carsale.groupby(['car'])['engV'].apply(lambda x: x.median())[brand]\n        return brand_median # Return median of brand if particular brand\/model combo has no median,\n    else:                 # but brand itself has a median for the 'engV' feature. \n        return carsale['engV'].median() # Otherwise return dataset's median for the 'engV' feature.\n    \nengV_median = carsale.groupby(['car','model'])['engV'].apply(get_median_engV).reset_index()\nengV_median.rename(columns={'engV': 'engV_med'}, inplace=True)\nengV_median.head()","3472cb1e":"def fill_with_median(x):\n    if pd.isnull(x['engV']):\n        return engV_median[(engV_median['car'] == x['car']) & (engV_median['model'] == x['model'])]['engV_med'].values[0]\n    else:\n        return x['engV']\n    \ncarsale['engV'] = carsale.apply(fill_with_median, axis=1)\ncarsale.head()","69b54acf":"def get_median_mileage(x):\n    brand = x.name[0]\n    if x.count() > 0:\n        return x.median() # Return median for a brand\/model if the median exists.\n    elif carsale.groupby(['car'])['mileage'].count()[brand] > 0:\n        brand_median = carsale.groupby(['car'])['mileage'].apply(lambda x: x.median())[brand]\n        return brand_median # Return median of brand if particular brand\/model combo has no median,\n    else:                 # but brand itself has a median for the 'mileage' feature. \n        return carsale['mileage'].median() # Otherwise return dataset's median for the 'mileage' feature.\n    \nmileage_median = carsale.groupby(['car','model'])['mileage'].apply(get_median_mileage).reset_index()\nmileage_median.rename(columns={'mileage': 'mileage_med'}, inplace=True)\nmileage_median.head()","c8f9d916":"def fill_with_median(x):\n    if pd.isnull(x['mileage']):\n        return mileage_median[(mileage_median['car'] == x['car']) & (mileage_median['model'] == x['model'])]['mileage_med'].values[0]\n    else:\n        return x['mileage']\n    \ncarsale['mileage'] = carsale.apply(fill_with_median, axis=1)\ncarsale.head()","6dfa1625":"def get_drive_mode(x):\n    brand = x.name[0]\n    if x.count() > 0:\n        return x.mode() # Return mode for a brand\/model if the mode exists.\n    elif carsale.groupby(['car'])['drive'].count()[brand] > 0:\n        brand_mode = carsale.groupby(['car'])['drive'].apply(lambda x: x.mode())[brand]\n        return brand_mode # Return mode of brand if particular brand\/model combo has no mode,\n    else:                 # but brand itself has a mode for the 'drive' feature. \n        return carsale['drive'].mode() # Otherwise return dataset's mode for the 'drive' feature.\n    \ndrive_modes = carsale.groupby(['car','model'])['drive'].apply(get_drive_mode).reset_index().drop('level_2', axis=1)\ndrive_modes.rename(columns={'drive': 'drive_mode'}, inplace=True)\ndrive_modes.head()","27a9eb93":"def fill_with_mode(x):\n    if pd.isnull(x['drive']):\n        return drive_modes[(drive_modes['car'] == x['car']) & (drive_modes['model'] == x['model'])]['drive_mode'].values[0]\n    else:\n        return x['drive']\n    \ncarsale['drive'] = carsale.apply(fill_with_mode, axis=1)\ncarsale.head()","e2f175a9":"def get_engType_mode(x):\n    brand = x.name[0]\n    if x.count() > 0:\n        return x.mode() # Return mode for a brand\/model if the mode exists.\n    elif carsale.groupby(['car'])['engType'].count()[brand] > 0:\n        brand_mode = carsale.groupby(['car'])['engType'].apply(lambda x: x.mode())[brand]\n        return brand_mode # Return mode of brand if particular brand\/model combo has no mode,\n    else:                 # but brand itself has a mode for the 'engType' feature. \n        return carsale['engType'].mode() # Otherwise return dataset's mode for the 'engType' feature.\n    \nengType_modes = carsale.groupby(['car','model'])['engType'].apply(get_engType_mode).reset_index().drop('level_2', axis=1)\nengType_modes.rename(columns={'engType': 'engType_mode'}, inplace=True)\nengType_modes.head()","00fb99d3":"def fill_with_mode(x):\n    if pd.isnull(x['engType']):\n        return engType_modes[(engType_modes['car'] == x['car']) & (engType_modes['model'] == x['model'])]['engType_mode'].values[0]\n    else:\n        return x['engType']\n    \ncarsale['engType'] = carsale.apply(fill_with_mode, axis=1)\ncarsale.head()","c1f27e92":"carsale.isnull().sum()","cbc39257":"import pandas_profiling\nprofile = pandas_profiling.ProfileReport(carsale)\nprofile.to_file(outputfile=\"carsale_after_preprocessing.html\")","9b46f7f8":"carsale.car.value_counts().head(10).plot.bar()\nplt.title(\"Top 10 car brands on sale\")","92af52b0":"carsale[carsale.price.isin(carsale.price.nlargest())].sort_values(['car','model','body','mileage','price'])","4e40c154":"carsale[carsale.price.isin(carsale.price.nsmallest())].sort_values(['car','model','body','mileage','price'])","6a65d191":"sns.countplot(y='body', data=carsale, orient='h', hue='registration')\nplt.title(\"Most preferred body type used in 1953-2016\")","9d937a1b":"sns.countplot(x='engType', data=carsale, orient='h')\nplt.title(\"Most preferred engType used over the years\")","40450d2f":"carsale.sort_values(['car','model','body','mileage','year'])\n\ndf = carsale.groupby('year')['registration'].value_counts().sort_values(ascending=False)\ndf = pd.DataFrame(df)\ndf.rename(columns={'registration': 'RegCounts'}, inplace=True)\ndf.reset_index(inplace=True)\ndisplay(df.head())\nsns.lineplot(data=df, x='year', y='RegCounts', hue='registration')\n#sns.scatterplot(data=df, x='year', y='RegCounts', hue='registration')\nplt.title(\"Years group having max sale\/registration\")\n","ee339a04":"sns.lineplot(data=carsale, y='price', x='year', hue='drive')\nplt.title(\"year - price lineplot (1950 - 2010)\")","bbfa5ac1":"sns.lineplot(data=carsale[carsale.year >= 2010], y='price', x='year', hue='drive')\nplt.title(\"year - price lineplot (2010 - 2016)\")","8c7c38ab":"sns.lineplot(x='mileage',y='price',data=carsale, hue='engType')\nplt.title(\"mileage - price line Plot\")","1835ae40":"sns.heatmap(carsale.corr(),annot=True, linewidths=.5)\nplt.title(\"Heatmap for Highest correlated features for Carsale datset\")","b8aedea0":"sns.lmplot('year','price', carsale, fit_reg=False, hue='engType')\nplt.title(\"Price distribution over the year w.r.t to engType\")","1c140348":"sns.pairplot(carsale, hue='engType', palette=\"viridis\", height=3)","7d1e684f":"<a id=section3><\/a>","b386b0eb":"### * Profiling_2","844c7b21":"<a id=section1><\/a>","7a20f6bb":"- I have done Pandas Profiling before preprocessing dataset, so we can get initial observations from the dataset in better visual aspects, to find correlation matrix and sample data. File was saved as html file __carsale_before_preprocessing_1.html__.\n\n- Will take a look at the file and see what useful insight you can develop from it. <br\/>\n","299643a1":" - This shows the __car brands having \"sedan\" type of body having maximum registration\/sale__ over the years. This shows People prefers __sedan__ type of body mostly and hence this information can be use for achieving max sale and to figure out production of units.","5f933e2c":"- Initial observation as a result from profiling of __Carsale Dataset__ can be seen in  __carsale_before_preprocessing_1.html__","738a571e":"- Let's look into feature available in __carsale dataset__ in detail an __Visualize them__","eb41d076":" - The above graphs shows the __Price__ distribution over the years (1953-2016). As the years increase, we cannot comment on the price increase, but in general, __there has been an increase in price in recent years.__","b2c79829":"#### Some Background Information\n - This data was collected from private car sale advertisements in Ukraine and provided by INSAID team to perform Exploratory Data Analysis.\n - This dataset has real raw data which has all inconvenient moments (as NA\u2019s for example).\n - This dataset contains data for more than 9.5K cars sale in Ukraine. Most of them are used cars so it opens the possibility to analyze features related to car operation.","616d44d2":" - This graph shows in which Year was the highest registrations, and hence shows max sale was done in the Year __2008__. \n    <br>This info can be use to start working\/research why sale was max in this year.\n - What was the factors affected this sale\/registrations","16bc6d7b":"### *  Handling categorical data\n- __drive__: Replacing missing values now for __drive__ column based on __[car,model]__ group product and __mode__ value of __drive__ based on this group. ","75fe9149":"<a id=section301><\/a>","7294d418":"Now I have preprocessed the data, now the dataset does not contain missing values. So, the pandas profiling report which I have generated after preprocessing will give more beneficial insights. You can compare the two reports, i.e __carsale_before_preprocessing_2.html__ and __carsale_after_preprocessing.html__.<br\/>\n\nIn __carsale_after_preprocessing.html__ report, observations:\n- In the Dataset info, Total __Missing(%)__ = __0.0%__ \n- Number of __variables__ = __11__ \n- Observe the updated details, Click on Toggle details to get more detailed information about each feature.","fd9c27db":"- We can see that __engV__ and __drive__ columns contains __maximum null values__. But it didn't consider __0__ as missing value, so we have to figure out how to deal with this as mentioned above too.","9b1cc517":"<a id=section303><\/a>","59eb6d60":" - The above graph shows line plot\/relation between __mileage__ and __price__. We can't comment on the price increase\/decrease over the mileage but this shows, price changing accordingly based on mileage value. So __price is varying based on mileage__ too and this should be consider as a factor for the calculation.","108ce230":"<a id=section304><\/a>","0463a096":"- __engType__: Replacing missing values now for __engType__ column based on __[car,model]__ group product and __mode__ value of __engType__ based on this group. ","fbfb0e9f":"<a id=section2><\/a>","8b6e7eda":"- __engV__: Replacing missing values now for __engV__ column based on __[car,model]__ group product and __median__ value of __engV__ based on this group. \n","74d0f0c8":" - We can see there are no missing data exist in our dataset, let's go with finding observations\/pattern using plotting\/charting, but first we'll save this in our post profiling (which is the data states after preprocessing)","66600cc1":" - This shows __top 5 highest price selling car and their models details__ and hence __can be used for email marketing for high profile income group peoples__ to achieve sales goals","0d82ea99":"### 3.1 Understanding the Carsale Dataset","4e6e3659":"- The dataset consists information collected from car sale advertisements for study\/practice purpose where most of them're used cars.\n- The dataset comprises of __9576 observations of 10 columns__. Below is a table showing names of all the columns and their description.","fc0c5e8b":"<a id=section4><\/a>","c0e949ad":"- __mileage__: Replacing missing values now for __mileage__ column based on __[car,model,year]__ group product and __median__ value of __mileage__ based on this group. Year has been included here as per data observations year to year mileage is getting down for the same Car\/Brand combination.","abfba2a4":"- __engType__ column has __\"Other\"__ values as well, So as mentioned above in data description, we should treat them as NA. So we'll be replacing those to __NaN__\n- __price__ has __267__ zeros which should be treated as missing values. So we'll be replacing those to __NaN__\n- __mileage__ has __348__ zeros which should be treated as missing values. So we'll be replacing those to __NaN__","2860d305":"\n<table>\n<thead>\n    <style>\ntd {\n  text-align: center;\n}\n<\/style>\n<tr>\n<th>Column Name<\/th>\n<th>Description<\/th>\n<\/tr>\n<\/thead>\n<tbody><tr>\n<td>car<\/td>\n<td>Manufacturer brand<\/td>\n<\/tr>\n<tr>\n<td>price<\/td>\n<td>Seller\u2019s price in advertisement (in USD)<\/td>\n<\/tr>\n<tr>\n<td>body<\/td>\n<td>Car body type<\/td>\n<\/tr>\n<tr>\n<td>mileage<\/td>\n<td>as mentioned in advertisement (\u2018000 Km)<\/td>\n<\/tr>\n<tr>\n<td>engV<\/td>\n<td>rounded engine volume (\u2018000 cubic cm)<\/td>\n<\/tr>\n<tr>\n<td>engType<\/td>\n<td>type of fuel (\u201cOther\u201d in this case should be treated as NA)<\/td>\n<\/tr>\n<tr>\n<td>registration<\/td>\n<td>whether car registered in Ukraine or not<\/td>\n<\/tr>\n<tr>\n<td>year<\/td>\n<td>year of production<\/td>\n<\/tr>\n<tr>\n<td>model<\/td>\n<td>specific model name<\/td>\n<\/tr>\n<tr>\n<td>drive<\/td>\n<td>drive type<\/td>\n<\/tr>\n<\/tbody><\/table>","489ac8e2":"# Exploratory Data Analysis Carsale Advetisement Dataset","f2b134a0":"- Initial observation as a result from profiling of Carsale Dataset can be seen in __carsale_before_preprocessing_2.html__","3552060d":"- Let see what are the changes after __Preprocessing_1__ in initial observations from profiling","e8ead7da":" - This shows __top 5 lowest price selling car and their models details__ and hence __can be used for email marketing for low to middle profile income group peoples__ to achieve sales goals","b7520588":"#### Importing packages                                          ","2a27edbd":"## * Post Pandas Profiling","130998ea":"<a id=section201><\/a>","5586aabc":"The notebooks explores the basic use of __Pandas__ and will cover the basic commands of __Exploratory Data Analysis(EDA)__ which includes __cleaning__, __munging__, __combining__, __reshaping__, __slicing__, __dicing__, and __transforming data__ for analysis purpose.\n\n* __Exploratory Data Analysis__ <br\/>\nUnderstand the data by EDA and derive simple models with Pandas as baseline.\nEDA ia a critical and first step in analyzing the data and we do this for below reasons :\n    - Finding patterns in Data\n    - Determining relationships in Data\n    - Checking of assumptions\n    - Preliminary selection of appropriate models\n    - Detection of mistakes \n","395aa458":"## Table of Contents\n\n1. [Problem Statement](#section1)<br>\n2. [Data Loading and Description](#section2)\n3. [Data Profiling](#section3)\n    - * [Understanding the Dataset](#section301)<br\/>\n    - * [Profiling_1](#section302)<br\/>\n    - * [Preprocessing_1](#section303)<br\/>\n    - * [Profiling_2](#section304)<br\/>\n    - * [Preprocessing_2](#section305)<br\/>\n    - * [Post Profiling](#section306)<br\/>\n4. [Conclusions](#section4)<br\/>  ","67bc6f2e":"### *  Handling numerical data\n- __price__: Replacing missing values now for __price__ column based on __[car,model]__ group product and __median__ value of __price__ based on this group. \n","23809be9":" - This pairplot gives the observations which already have been referred from other graphs above : those are\n - - Price varying based on __Year__ and __Mileage__\n - - As __Year__ increases there is increase in __Petrol__ engine type vehicles's prices which also depending on __mileage__ too.","d25f5c35":"### * Profiling_1","20d33c80":" -  The above __multivariate graphs__ shows the __Price__ distribution over the years w.r.t __engType__. As the years increase, this shows there is __significant increase in prices of cars models having engine tyep = \"Petrol\"__ as compared to __\"Gas\" and \"Diesel\"__.","1fb138d3":"<a id=section302><\/a>","dcf878a2":"- Now we'll see if still we have missing data in dataset. If not, then we are good to go with plotting","72100864":"<a id=section302><\/a>","d1081e8e":"#### Importing the Dataset","16f35496":"- __duplicates__: As there are __113__ duplicate rows in dataset, we have to remove those first.","945933dc":"### 1. Problem Statement","74979d81":"__Carsale Dataset__  has __9576 rows__ and __10 columns.__","877e9a2a":" - This shows __Volkswagen__ and __Mercedes-Benz__ are top most brands on sale and hence these would be preferred choices for high profile people","60bd0b52":"## 3. Data Profiling","614cd37c":"<a id=section306><\/a>","fd4938e6":"- We can see all numeric columns having count __9576__ except __engV__. Looks like this column has some missing values\n- __price__ and __mileage__ has __min__ value as __Zero__ which is not possible. We need to look into to replace them as __NaN__ to make them null values","999fa6ff":"### * Preprocessing_2\n<br>\nNow we will deal with handling duplicates and missing values","4116f3e3":"### 2. Data Loading and Description","4414e1a4":" - Above graph shows the __which features are most relative\/correlated and dependent on each other__. Hence it looks __price__ and __year__ are higly correlated to each other and price may change (increase\/decrease over the period of time)","1f9d92f9":"<a id=section305><\/a>","6aef2b92":"### * Preprocessing_1","c58f4a5c":"## 5. Conclusion \n\n- With the help of notebook I learnt how exploratory data analysis can be carried out using Pandas plotting.\n- Also I have seen making use of packages like __matplotlib and seaborn__ to develop better insights about the data.<br\/>\n- I have also seen how __preproceesing__ helps in dealing with _missing_ values and irregualities present in the data. I also learnt how to _create new features_ which will in turn help us to better predict the survival. \n- I also make use of __pandas profiling__ feature to generate an html report containing all the information of the various features present in the dataset.\n- I have seen the impact of columns like __mileage, year and engType on the Price increase\/decrease rate__.\n- The most important inference drawn from all this analysis is, I get to know what are the __features on which price is highly positively and negatively coorelated with.__ \n- This analysis will help me to choose which __machine learning model__ we can apply to predict price of test dataset in later terms and projects. "}}