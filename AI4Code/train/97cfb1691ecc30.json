{"cell_type":{"f1b9ec6d":"code","874a79dc":"code","f40e2901":"code","5356b17e":"code","719227aa":"code","11e07aa5":"code","fcd00564":"code","f299e4c8":"code","f0b5bfee":"code","9fb04286":"code","27d48a15":"code","e04ed961":"code","293dabd1":"code","c2bf4218":"code","5fd49b0d":"code","ae903175":"code","79f15fdf":"code","cbcd5a95":"code","342e1aa6":"code","a0650e28":"code","af2ca2cf":"code","71cb2bad":"code","d37f7b23":"markdown","523d5528":"markdown","93e6bfd5":"markdown","5aeb99fa":"markdown","d4da8eac":"markdown","3e640d9a":"markdown","e88de969":"markdown","b7275900":"markdown","977f7651":"markdown","4ace4b58":"markdown","018ccb92":"markdown"},"source":{"f1b9ec6d":"import numpy as np, pandas as pd, gc\nimport cv2, matplotlib.pyplot as plt\nimport cudf, cuml, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom cuml.neighbors import NearestNeighbors\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0, EfficientNetB1, EfficientNetB2\nprint('RAPIDS',cuml.__version__)\nprint('TF',tf.__version__)","874a79dc":"# RESTRICT TENSORFLOW TO 1GB OF GPU RAM\n# SO THAT WE HAVE 15GB RAM FOR RAPIDS\nLIMIT = 1\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    tf.config.experimental.set_virtual_device_configuration(\n        gpus[0],\n        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    print(e)\nprint('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\nprint('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))","f40e2901":"COMPUTE_CV = True\n\ntest = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\nif len(test)>3: COMPUTE_CV = False\nelse: print('this submission notebook will compute CV score, but commit notebook will not')","5356b17e":"train = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\ntmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\ntrain['target'] = train.label_group.map(tmp)\nprint('train shape is', train.shape )\ntrain.head()","719227aa":"tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain['oof'] = train.image_phash.map(tmp)","11e07aa5":"def getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n \/ (len(row.target)+len(row[col]))\n    return f1score","fcd00564":"train['f1'] = train.apply(getMetric('oof'),axis=1)\nprint('CV score for baseline =',train.f1.mean())","f299e4c8":"if COMPUTE_CV:\n    test = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\n    test_gf = cudf.DataFrame(test)\n    print('Using train as test to compute CV (since commit notebook). Shape is', test_gf.shape )\nelse:\n    test = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\n    test_gf = cudf.read_csv('..\/input\/shopee-product-matching\/test.csv')\n    print('Test shape is', test_gf.shape )\ntest_gf.head()","f0b5bfee":"class DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, df, img_size=256, batch_size=32, path=''): \n        self.df = df\n        self.img_size = img_size\n        self.batch_size = batch_size\n        self.path = path\n        self.indexes = np.arange(len(self.df))\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        ct = len(self.df) \/\/ self.batch_size\n        ct += int(( (len(self.df)) % self.batch_size)!=0)\n        return ct\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        X = self.__data_generation(indexes)\n        return X\n            \n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples' \n        X = np.zeros((len(indexes),self.img_size,self.img_size,3),dtype='float32')\n        df = self.df.iloc[indexes]\n        for i,(index,row) in enumerate(df.iterrows()):\n            img = cv2.imread(self.path+row.image)\n            X[i,] = cv2.resize(img,(self.img_size,self.img_size)) #\/128.0 - 1.0\n        return X","9fb04286":"BASE = '..\/input\/shopee-product-matching\/test_images\/'\nif COMPUTE_CV: BASE = '..\/input\/shopee-product-matching\/train_images\/'\n\nWGT = '..\/input\/tfkerasefficientnetimagenetnotop\/efficientnetb0_notop.h5'\nmodel = EfficientNetB0(weights=WGT,include_top=False, pooling='avg', input_shape=None)\n\nembeds = []\nCHUNK = 1024*4\n\nprint('Computing image embeddings...')\nCTS = len(test)\/\/CHUNK\nif len(test)%CHUNK!=0: CTS += 1\nfor i,j in enumerate( range( CTS ) ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(test))\n    print('chunk',a,'to',b)\n    \n    test_gen = DataGenerator(test.iloc[a:b], img_size=380, batch_size=16, path=BASE)\n    image_embeddings = model.predict(test_gen,verbose=1,use_multiprocessing=True, workers=4)\n    embeds.append(image_embeddings)\n\n    #if i>=1: break\n    \ndel model\n_ = gc.collect()\nimage_embeddings = np.concatenate(embeds)\nprint('image embeddings shape',image_embeddings.shape)","27d48a15":"KNN = 50\nif len(test)==3: KNN = 2\nmodel = NearestNeighbors(n_neighbors=KNN)\nmodel.fit(image_embeddings)","e04ed961":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar images...')\nCTS = len(image_embeddings)\/\/CHUNK\nif len(image_embeddings)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(image_embeddings))\n    print('chunk',a,'to',b)\n    distances, indices = model.kneighbors(image_embeddings[a:b,])\n    \n    for k in range(b-a):\n        IDX = np.where(distances[k,]<6.0)[0]\n        IDS = indices[k,IDX]\n        o = test.iloc[IDS].posting_id.values\n        preds.append(o)\n        \ndel model, distances, indices, image_embeddings, embeds\n_ = gc.collect()","293dabd1":"test['preds2'] = preds\ntest.head()","c2bf4218":"import string\n\ndef removePunctuation(text):\n    punc_translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n    return text.translate(punc_translator)\n\ntest['title_clean'] = test['title'].apply(removePunctuation)\ntitle_to_use = cudf.DataFrame(test).title_clean","5fd49b0d":"print('Computing text embeddings...')\ntfidf_vec = TfidfVectorizer(stop_words='english', \n                            binary=True, \n#                             max_df = 0.5,\n#                             min_df = 2,\n                            max_features=30000)\ntext_embeddings = tfidf_vec.fit_transform(title_to_use).toarray().astype(np.float32)\nprint('text embeddings shape',text_embeddings.shape)","ae903175":"preds = []\nCHUNK = 1024\n\nprint('Finding similar titles...')\nCTS = len(test)\/\/CHUNK\nif len(test)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(test))\n    print('chunk',a,'to',b)\n    \n    # COSINE SIMILARITY DISTANCE\n    cts = cupy.matmul(text_embeddings, text_embeddings[a:b].T).T\n    \n    for k in range(b-a):\n        IDX = cupy.where(cts[k,]>0.7)[0]\n        o = test.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)\n        \ndel tfidf_vec, text_embeddings\n_ = gc.collect()","79f15fdf":"test['preds'] = preds\ntest.head()","cbcd5a95":"tmp = test.groupby('image_phash').posting_id.agg('unique').to_dict()\ntest['preds3'] = test.image_phash.map(tmp)\ntest.head()","342e1aa6":"def combine_for_sub(row):\n    x = np.concatenate([row.preds, row.preds2, row.preds3])\n    return ' '.join( np.unique(x) )\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.preds, row.preds2, row.preds3])\n    return np.unique(x)","a0650e28":"if COMPUTE_CV:\n    tmp = test.groupby('label_group').posting_id.agg('unique').to_dict()\n    test['target'] = test.label_group.map(tmp)\n    test['oof'] = test.apply(combine_for_cv,axis=1)\n    test['f1'] = test.apply(getMetric('oof'),axis=1)\n    print('CV Score =', round(test.f1.mean(), 3) )\n\ntest['matches'] = test.apply(combine_for_sub,axis=1)","af2ca2cf":"print(\"CV for image :\", round(test.apply(getMetric('preds2'),axis=1).mean(), 3))\nprint(\"CV for text  :\", round(test.apply(getMetric('preds'),axis=1).mean(), 3))\nprint(\"CV for phash :\", round(test.apply(getMetric('preds3'),axis=1).mean(), 3))","71cb2bad":"test[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head()","d37f7b23":"# Compute Baseline CV Score\nA baseline is to predict all items with the same `image_phash` as being duplicate. Let's calcuate the CV score for this submission.","523d5528":"# Load Train Data\nFirst we load the train data and create a target column of ground truths to help us compute CV score. Note how the variable `COMPUTE_CV` will change to `False` when we **submit** this notebook but it is `True` now because you are reading a **commit** notebook.","93e6bfd5":"# Write Submission CSV\nIn this notebook, the submission file below looks funny containing train information. But when we submit this notebook, the size of `test.csv` dataframe will be longer than 3 rows and the variable `COMPUTE_CV` will subsequently set to `False`. Then our submission notebook will compute the correct matches using the real test dataset and our submission csv for LB will be ok.","5aeb99fa":"# Compute RAPIDS Model CV and Infer Submission\nWe will now use image embeddings, text embeddings, and phash to create a better model with better CV. We will also infer submission csv.\n\nNote how the variable `COMPUTE_CV` is only `True` when we **commit** this notebook. Right now you are reading a **commit** notebook, so we see test replaced with train and computed CV score. When we **submit** this notebook, the variable `COMPUTE_CV` will be `False` and the **submit** notebook will **not** compute CV. Instead it will load the real test dataset with 70,000 rows and find duplicates in the real test dataset.","d4da8eac":"# Load Libraries","3e640d9a":"Main experimentals :\n- V8 (CV 0.721) :\n    1. increase img_size to 380\n- V6 (CV 0.732) :\n    1. remove punctuations\n- V3 (CV 0.730 to 0.734) : \n    1. changed text similarity threshold 0.7 to 0.6\n- V2 (CV 0.725 to 0.730) : \n    1. changed EfficientNetB0 to EfficientNetB2. Because B2's resolution is 260 which is closer to img_size 256.\n    2. changed parameters in TfidfVectorizer to remove useless features.\n    \nThings didn't work :\n- change K, distance in KNN\n\nUpdate : my CV is not stable enough","e88de969":"# Compute CV Score","b7275900":"# Use Image Embeddings\nTo prevent memory errors, we will compute image embeddings in chunks. And we will find similar images with RAPIDS cuML KNN in chunks.","977f7651":"# Use Phash Feature\nWe will predict all items with the same phash as duplicates","4ace4b58":"# Use Text Embeddings\nTo prevent memory errors, we will find similar titles in chunks. To faciliate this, we will use cosine similarity between text embeddings instead of KNN.","018ccb92":"Credits :\n- [[PART 2] - RAPIDS TfidfVectorizer - [CV 0.700]](https:\/\/www.kaggle.com\/cdeotte\/part-2-rapids-tfidfvectorizer-cv-0-700)"}}