{"cell_type":{"2ab6f0c6":"code","2da0bcd3":"code","20e1a2e2":"code","b961c9b6":"code","af6faca3":"code","6e91f85a":"code","f31d629a":"code","0fe2a6bb":"code","fbe9c879":"code","13ecc7ef":"code","22213e68":"code","dfce4922":"code","fc41636e":"code","e09e8088":"code","553e0776":"code","7b096dc5":"code","8e7157ac":"code","ad3e68b2":"markdown","f2ecd051":"markdown","c3e4f6d3":"markdown","bdd65c59":"markdown","8757f8b8":"markdown","ef22d45e":"markdown","e6542de4":"markdown","f87e9bc3":"markdown","1d6851e0":"markdown","fe13df39":"markdown","1d3c0a15":"markdown","c5f3883f":"markdown","b03fe94d":"markdown","eb3e8c31":"markdown","21e7adc7":"markdown","9b86aac9":"markdown","99458710":"markdown"},"source":{"2ab6f0c6":"import numpy as np \nimport pandas as pd\n\n#For data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#For text preprocessing\nimport re\nimport nltk\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.tokenize import TweetTokenizer\nfrom nltk.tokenize import word_tokenize \nfrom nltk.corpus import stopwords\n\n#For creating the neural network model\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport tensorflow.keras.layers as L\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras.optimizers import Adam","2da0bcd3":"train = pd.read_csv('..\/input\/covid-19-nlp-text-classification\/Corona_NLP_train.csv',encoding='latin1')\ntest = pd.read_csv('..\/input\/covid-19-nlp-text-classification\/Corona_NLP_test.csv',encoding='latin1')\n\ntrain.head()","20e1a2e2":"print('Shape of Train datatset:',train.shape)\nprint('Shape of Test dataset:',test.shape)","b961c9b6":"train.isnull().sum()","af6faca3":"test.isnull().sum()","6e91f85a":"#Defining variables to count the appearances of each sentiments in the dataset\ndist_train = train['Sentiment'].value_counts()\ndist_test = test['Sentiment'].value_counts()","f31d629a":"#Create plot\nsns.barplot(x= dist_train.index, y= dist_train.values, palette = 'magma')\n\n#Set the size of plot\nsns.set(rc = {'figure.figsize':(10,7)})\n\n#Set the title for plot\nplt.title('Train Dataset: Sentiment Class Distibution')\n\n#Label the X axis of the plot\nplt.xlabel('Sentiments')\n\n#Label the Y axis of the plot\nplt.ylabel('Count')","0fe2a6bb":"#Create plot\nsns.barplot(x= dist_test.index, y= dist_test.values, palette = 'magma')\n\n#Set the size of plot\nsns.set(rc = {'figure.figsize':(10,7)})\n\n#Set the title for plot\nplt.title('Test Dataset: Sentiment Class Distibution')\n\n#Label the X axis of the plot\nplt.xlabel('Sentiments')\n\n#Label the Y axis of the plot\nplt.ylabel('Count')","fbe9c879":"X = train['OriginalTweet'].copy()\ny = train['Sentiment'].copy()","13ecc7ef":"def data_cleaner(tweet):\n    \n    # remove urls\n    tweet = re.sub(r'http\\S+', ' ', tweet)\n    \n    # remove html tags\n    tweet = re.sub(r'<.*?>',' ', tweet)\n    \n    # remove digits\n    tweet = re.sub(r'\\d+',' ', tweet)\n    \n    # remove hashtags\n    tweet = re.sub(r'#\\w+',' ', tweet)\n    \n    # remove mentions\n    tweet = re.sub(r'@\\w+',' ', tweet)\n    \n    #removing stop words\n    tweet = tweet.split()\n    tweet = \" \".join([word for word in tweet if not word in stop_words])\n    \n    return tweet\n\n#Defining a variable for stopwords\nstop_words = stopwords.words('english')\n\n#Apply the above defined function to train dataset\nX_cleaned = X.apply(data_cleaner)\nX_cleaned.head()","22213e68":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(X_cleaned)\n\nX = tokenizer.texts_to_sequences(X_cleaned)\n\nvocab_size = len(tokenizer.word_index)+1\n\nprint(\"Vocabulary size: {}\".format(vocab_size))\nprint(\"\\nFor Example:\\n\")\nprint(\"Sentence:\\n{}\".format(X_cleaned[1]))\nprint(\"\\nAfter tokenizing :\\n{}\".format(X[1]))\n\nX = pad_sequences(X, padding='post')\nprint(\"\\nAfter padding :\\n{}\".format(X[1]))","dfce4922":"encoding = {'Extremely Negative': 0,'Negative': 0,'Neutral': 1,'Positive':2,'Extremely Positive': 2}\n\nlabels = ['Negative', 'Neutral', 'Positive']\n           \ny.replace(encoding, inplace=True)","fc41636e":"tf.keras.backend.clear_session()\n\n# Initialize hyper parameters\nEPOCHS = 2\nBATCH_SIZE = 32\nembedding_dim = 16\nunits = 256\n\n#Create a Sequential Model\nmodel = tf.keras.Sequential([\n    L.Embedding(vocab_size, embedding_dim, input_length=X.shape[1]),\n    L.Bidirectional(L.LSTM(units,return_sequences=True)),\n    L.GlobalMaxPool1D(),\n    L.Dropout(0.4),\n    L.Dense(64, activation=\"relu\"),\n    L.Dropout(0.4),\n    L.Dense(3)\n])\n\n#Compile the model\nmodel.compile(loss=SparseCategoricalCrossentropy(from_logits=True),\n              optimizer='adam',metrics=['accuracy']\n             )\n\n#Show the final model summary\nmodel.summary()","e09e8088":"history = model.fit(X, y, epochs=EPOCHS, validation_split=0.12, batch_size=BATCH_SIZE)","553e0776":"X_test = test['OriginalTweet'].copy()\ny_test = test['Sentiment'].copy()\n\n#Apply the tweets preprocessing functions to test dataset\nX_test = X_test.apply(data_cleaner)\n\nX_test = tokenizer.texts_to_sequences(X_test)\n\nX_test = pad_sequences(X_test, padding='post')\n\ny_test.replace(encoding, inplace=True)","7b096dc5":"pred = model.predict(X_test)","8e7157ac":"loss, acc = model.evaluate(X_test,y_test,verbose=0)\nprint('Test loss: {}'.format(loss))\nprint('Test Accuracy: {}'.format(acc))","ad3e68b2":"### Text preprocessing the test dataset for prediction","f2ecd051":"### Text preprocessing: Remove Stopwords and Tokenize","c3e4f6d3":"### Evaluate the model","bdd65c59":"### Check shape of train and test dataset","8757f8b8":"### Predict the sentiments using model","ef22d45e":"### Check for null values in test dataset","e6542de4":"### Define features and target variables","f87e9bc3":"### Encode sentiments for ease","1d6851e0":"### Define a neural network model","fe13df39":"#### There are five types of sentiments initially in the dataset. We can club *Extremely Negative and Negative* tweets together for ease and the same for *Extremely Positive and Positive* tweets.","1d3c0a15":"### Check for null values in train dataset","c5f3883f":"# **COVID-19 Tweets Classification using Neural Networks**","b03fe94d":"### Import Libraries","eb3e8c31":"### Import and Read data","21e7adc7":"### Fit the model with train dataset","9b86aac9":"##### We don't need any other columns except Tweets and Sentiment. We will predict the sentiments only on the basis of tweets irrespective of their location or any other features.","99458710":"### Data Visualization of different *sentiments* classes"}}