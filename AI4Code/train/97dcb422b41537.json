{"cell_type":{"55986ae9":"code","0e081dfc":"code","d86ff5cc":"code","5ae5cf1c":"code","66b50a18":"code","aee79eea":"code","50038439":"code","bc5558ea":"code","39f3874b":"code","e1fbd57d":"code","053b577a":"code","b5902c5f":"code","64eddd01":"code","ae0ec690":"code","73390194":"code","e3cbc021":"code","ea702a11":"code","d28102e1":"code","38bf3246":"code","9f88d88b":"code","e893435b":"code","4cd60ddd":"code","d5d9a3da":"code","25a9ba7b":"code","ea3355cc":"markdown","18ef2501":"markdown","bfa68142":"markdown","5814d6a0":"markdown","20abac3b":"markdown"},"source":{"55986ae9":"# matplotlib\u3067\u65e5\u672c\u8a9e\u3092\u6271\u3048\u308b\u3088\u3046\u306b\n!pip install japanize_matplotlib -Uq\n\n# \u30d9\u30f3\u56f3\u3092\u4f5c\u6210\n!pip install matplotlib-venn -Uq\n\n# Warnings\u3092\u9664\u53bb\n!pip install shutup -Uq","0e081dfc":"import shutup; shutup.please()\n\nimport os\nimport gc\ngc.enable()\nimport sys\nimport glob\nimport math\nimport time\nimport random\nimport string\nimport psutil\nimport pathlib\nfrom pathlib import Path\nfrom contextlib import contextmanager\n\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', 200)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport japanize_matplotlib\nfrom matplotlib_venn import venn2\n\nfrom tqdm.auto import tqdm as tqdmp\nfrom tqdm.autonotebook import tqdm as tqdm\ntqdmp.pandas()\n\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n\n## Model\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import datasets, models, transforms","d86ff5cc":"# \u5b9f\u9a13\u3067\u4f7f\u3046\u30d1\u30e9\u30e1\u30fc\u30bf\u306fConfig\u3067\u7ba1\u7406\u3057\u3066\u3044\u307e\u3059\u3002\n# \u3053\u306e\u5b9f\u9a13\u4f55\u3084\u3063\u305f\u304b\u306a\u3068\u5f8c\u3067\u632f\u308a\u8fd4\u308a\u3084\u3059\u3044\u3088\u3046\u306b\u3001\u306a\u308b\u3079\u304fConfig\u3060\u3051\u898b\u308c\u3070\u308f\u304b\u308b\u3088\u3046\u306b\u3057\u3066\u3044\u307e\u3059\n\nclass CFG:\n    \n    def __init__(self):\n        \n        self.seed=42\n        self.n_fold = 5\n        self.environment='Kaggle'\n        self.project='Shiggle_2nd'\n        self.exp_name = '003_transformer'\n        self.debug=True\n        \n        # model\n        self.epoch = 10\n        self.lr = 2e-4\n        self.weight_decay = 5e-5\n        \nCONFIG = CFG()","5ae5cf1c":"## \u518d\u73fe\u6027\u78ba\u4fdd\u306e\u305f\u3081\u306eSeed\u56fa\u5b9a\ndef seed_everything(seed:int==42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(CONFIG.seed)","66b50a18":"## \u51e6\u7406\u306b\u304b\u304b\u3063\u305f\u6642\u9593\u3068\u4f7f\u7528\u3057\u305f\u30e1\u30e2\u30ea\u3092\u8a08\u6e2c\n@contextmanager\ndef timer(name:str, slack:bool=False):\n    t0 = time.time()\n    p = psutil.Process(os.getpid())\n    m0 = p.memory_info()[0] \/ 2. ** 30\n    print(f'<< {name} >> Start')\n    yield\n    \n    m1 = p.memory_info()[0] \/ 2. ** 30\n    delta = m1 - m0\n    sign = '+' if delta >= 0 else '-'\n    delta = math.fabs(delta)\n    \n    print(f\"<< {name} >> {m1:.1f}GB({sign}{delta:.1f}GB):{time.time() - t0:.1f}sec\", file=sys.stderr)","aee79eea":"## Directory\u8a2d\u5b9a\nINPUT_DIR = Path('..\/input\/shigglecup-2nd')\nMODEL_DIR = Path('.\/')\nOUTPUT_DIR = Path('.\/')\nprint(f\"INPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\")","50038439":"## Data Check\nfor dirnames, _, filenames in os.walk(INPUT_DIR):\n    for filename in filenames:\n        print(f'{dirnames}\/{filename}')","bc5558ea":"with timer('Data Load'):\n    pokemon_df = pd.read_csv(INPUT_DIR \/ 'pokemon.csv')\n    team_id_df = pd.read_csv(INPUT_DIR \/ 'team_id.csv')\n    type_df = pd.read_csv(INPUT_DIR \/ 'typetable.csv')\n    type_df = type_df.set_index(\"atck\")\n    \n    train_df = pd.read_csv(INPUT_DIR \/ 'train.csv')\n    test_df = pd.read_csv(INPUT_DIR \/ 'test.csv')\n    \n    sub_df = pd.read_csv(INPUT_DIR \/ 'sample_submission.csv')\n    \n    print(f'pokemon_df: {pokemon_df.shape} | team_id_df: {team_id_df.shape} | type_df: {type_df.shape}')\n    print(f'train_df: {train_df.shape} | test_df: {test_df.shape} | sub_df: {sub_df.shape}')","39f3874b":"def attack_stats(row):\n    if row[\"Attack_Type\"] == 0:\n        return row[\"Attack\"] + row[\"Speed\"]\n    \n    else:\n        return row[\"Sp_Atk\"] + row[\"Speed\"]\n    \ndef defense_stats(row):\n    if row[\"Defense_Type\"] == 0:\n        return row[\"Defense\"] + row[\"HP\"]\n    \n    else:\n        return row[\"Sp_Def\"] + row[\"HP\"]\n\ndef FE_pokemon(df:pd.DataFrame) -> (pd.DataFrame, list):\n    \n    \"\"\"pokemon\u5358\u4f53\u306e\u7279\u5fb4\u4f5c\u6210\n    \"\"\"\n    \n    feature_cols = [\"pokemon_id\"]\n    \n    # \u5408\u8a08\u7a2e\u65cf\u5024\n    stats_cols = [\"HP\", \"Attack\", \"Defense\", \"Sp_Atk\", \"Sp_Def\", \"Speed\"]\n    for col in stats_cols:\n        df[col] \/= 100. # \u6b63\u898f\u5316\u3082\u304b\u306d\u3066100\u3067\u5272\u3063\u3066\u307e\u3059\n        \n    feature_cols += stats_cols\n    \n    df[\"Attack__Sp_Atk_Diff\"] = df[\"Attack\"] - df[\"Sp_Atk\"]\n    df[\"Attack_Type\"] = df[\"Attack__Sp_Atk_Diff\"].apply(lambda x:0 if x > 0 else 1) # Attack > Sp_Atk\u3067\u3042\u308c\u30700, Sp_Atk > Attack\u3067\u3042\u308c\u30701\n    \n    df[\"Defense__Sp_Def_Diff\"] = df[\"Defense\"] - df[\"Sp_Def\"]\n    df[\"Defense_Type\"] = df[\"Defense__Sp_Def_Diff\"].apply(lambda x:0 if x > 0 else 1) # Defense > Sp_Def\u3000\u3067\u3042\u308c\u30700, Sp_Def > Defense\u3000\u3067\u3042\u308c\u30701\n    \n    \n    df[\"total_stats\"] = df[stats_cols].sum(axis=1)\/6.# \u6b63\u898f\u5316\u3082\u304b\u306d\u30666\u3067\u5272\u3063\u3066\u307e\u3059\n    df[\"Attack_stats\"] = df.apply(attack_stats, axis=1)\/2.# \u6b63\u898f\u5316\u3082\u304b\u306d\u30662\u3067\u5272\u3063\u3066\u307e\u3059\n    df[\"Defense_stats\"] = df.apply(defense_stats, axis=1)\/2.# \u6b63\u898f\u5316\u3082\u304b\u306d\u30662\u3067\u5272\u3063\u3066\u307e\u3059\n    \n    feature_cols.append(\"total_stats\")\n    feature_cols.append(\"Attack_stats\")\n    feature_cols.append(\"Defense_stats\")\n    \n    return df, feature_cols","e1fbd57d":"with timer(\"FE_pokemon_df\"):\n    pokemon_df, feature_list = FE_pokemon(pokemon_df)\n    display(pokemon_df[feature_list].head())","053b577a":"team_id = 1\nteam_num = team_id_df[team_id_df['team_id']==team_id].reset_index(drop=True)\n\nfeats = []\npokemon_id_cols = [f'pokemon_id_{i+1}' for i in range(6)]\n\nfor pokemon_id in pokemon_id_cols:\n    tmp_feats = pokemon_df.loc[team_num[pokemon_id], feature_list[1:]]\n    feats.append(tmp_feats)\n    \nnp.concatenate(feats).shape","b5902c5f":"def get_feat(team_id_df: pd.DataFrame, pokemon_df:pd.DataFrame, feature_list:list, team_id:int) -> np.array:\n    \n    \"\"\"\n    team_id\u306b\u5fdc\u3058\u305f\u30dd\u30b1\u30e2\u30f3\u306e\u7279\u5fb4\u3092\u62bd\u51fa\n    \"\"\"\n    \n    team_num = team_id_df[team_id_df['team_id']==team_id].reset_index(drop=True)\n\n    feats = []\n    pokemon_id_cols = [f'pokemon_id_{i+1}' for i in range(6)]\n\n    for pokemon_id in pokemon_id_cols:\n        tmp_feats = pokemon_df.loc[team_num[pokemon_id], feature_list[1:]] # pokemon_id\u4ee5\u5916\u306e\u7279\u5fb4\n        feats.append(tmp_feats)\n        \n    return np.concatenate(feats)","64eddd01":"from torchvision import transforms\n\n\ndef shuffle(x):\n    \"\"\"Input\u306eindex\u3092shuffle. \u4f8b.[0, 1, 2, 3, 4, 5] -> [2, 1, 4, 5, 3]\n    \"\"\"\n    \n    tmp = [i for i in range(6)]\n    random.shuffle(tmp)\n\n    return x[tmp, :]","ae0ec690":"class PokemonDataset:\n    \n    \"\"\"\n    first\u3068second\u3067\u305d\u308c\u305e\u308c6x9\u306e\u7279\u5fb4\u3092\u4f5c\u6210\n    first\u306e\u307f\u9806\u756a\u3092shuffle\u3059\u308b\u3088\u3046\u306aaugmentation\u3092\u9069\u7528\n    \"\"\"\n    \n    def __init__(self, df, transforms, is_train):\n        \n        self.df = df # DataFrame\n        self.transforms = transforms # Augmentation\u3059\u308b\u304b\u3069\u3046\u304b\n        self.is_train = is_train # \u5b66\u7fd2 or \u4e88\u6e2c\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx:int):\n        \n        first_team_id = self.df.loc[idx, \"first\"]\n        second_team_id = self.df.loc[idx, \"second\"]\n                        \n        first_feat = get_feat(team_id_df, pokemon_df, feature_list, team_id=first_team_id)\n        second_feat = get_feat(team_id_df, pokemon_df, feature_list,team_id=second_team_id)\n        \n        if self.transforms: # Shuffle Augmentation\n            transform = transforms.Lambda(shuffle)\n            first_feat = transform(first_feat)\n        \n        if self.is_train:\n            target = self.df.loc[idx, \"target\"]\n            return {\n                \"first_features\":torch.tensor(first_feat, dtype=torch.float).unsqueeze(-1).permute(2,0,1),  # (Batch size, ch, \u30dd\u30b1\u30e2\u30f3\u306e\u6570, \u7279\u5fb4\u91cf\u6570)\n                \"second_features\":torch.tensor(second_feat, dtype=torch.float).unsqueeze(-1).permute(2,0,1), # (Batch size, ch, \u30dd\u30b1\u30e2\u30f3\u306e\u6570, \u7279\u5fb4\u91cf\u6570)\n                \"target\":torch.tensor(target, dtype=torch.float).unsqueeze(-1),\n            }\n        \n        else:\n            return {\n                \"first_features\":torch.tensor(first_feat, dtype=torch.float).unsqueeze(-1).permute(2,0,1), # (Batch size, ch, \u30dd\u30b1\u30e2\u30f3\u306e\u6570, \u7279\u5fb4\u91cf\u6570)\n                \"second_features\":torch.tensor(second_feat, dtype=torch.float).unsqueeze(-1).permute(2,0,1), # (Batch size, ch, \u30dd\u30b1\u30e2\u30f3\u306e\u6570, \u7279\u5fb4\u91cf\u6570)\n            }","73390194":"# \u78ba\u8a8d\ntrain_dataset = PokemonDataset(\n    df=train_df,\n    transforms=True,\n    is_train=True\n)\n\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset,\n    batch_size=4,\n    shuffle=False,\n)\n\nfor data in train_loader:\n    break","e3cbc021":"data[\"first_features\"].size(), data[\"second_features\"].size(), data[\"target\"].size()","ea702a11":"class CombatModel(nn.Module):\n    \n    \"\"\"\n    6\u4f53x\uff19\u7279\u5fb4\u91cf\u30921\u679a\u306e\u753b\u50cf\u3068\u898b\u7acb\u3066\u3066\u3001Conv2D\u3067\u4e88\u6e2c\n    \"\"\"\n    \n    def __init__(self, in_chans=2, num_class=1):\n        super(CombatModel, self).__init__()\n        self.in_chans = in_chans\n        self.num_class = num_class\n        \n        self.conv1 = nn.Conv2d(self.in_chans, 32, kernel_size=(6, 9), padding=(1, 1))\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=(3, 3))\n        self.head = nn.Linear(in_features=64, out_features=self.num_class)\n        \n    def forward(self, x):\n        x = self.conv1(x)        \n        x = self.conv2(x)        \n        x = self.pool(x)\n        x = x.view(x.size(0), -1)\n        \n        output = self.head(x)\n        \n        return output","d28102e1":"model = CombatModel()\nmodel(torch.cat([data[\"first_features\"], data[\"second_features\"]], dim=1)).size()","38bf3246":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count","9f88d88b":"def train_func(model, optimizer, scheduler, loss_fn, dataloader, device, epoch):\n    \n    losses = AverageMeter()\n\n    model.train()\n    tq = tqdm(dataloader, total=len(dataloader))\n\n    for step, data in enumerate(tq):\n\n        s_t = time.time()\n        optimizer.zero_grad()\n        \n        first = data[\"first_features\"].to(device)\n        second = data[\"second_features\"].to(device)\n        target = data[\"target\"].to(device)\n\n        bsz = target.shape[0] # Batch Size\n        preds = model(torch.cat([first, second], dim=1))\n        \n        loss = loss_fn(preds, target)\n        loss.backward()\n        optimizer.step()\n\n        scheduler.step()\n        losses.update(loss.item(), bsz)\n\n        e_t = time.time() - s_t\n            \n        tq.set_description(f\"Train Epoch: {epoch+1:2d} | Loss{losses.avg:.5f}\")\n\n    tq.close()\n    _ = gc.collect()\n    \n    return losses.avg","e893435b":"def valid_func(model, loss_fn, dataloader, device, epoch):\n    \n    losses = AverageMeter()\n\n    model.eval()\n    tq = tqdm(dataloader, total=len(dataloader))\n    valid_preds = []\n\n    for step, data in enumerate(tq):\n\n        s_t = time.time()\n        optimizer.zero_grad()\n        \n        first = data[\"first_features\"].to(device)\n        second = data[\"second_features\"].to(device)\n        target = data[\"target\"].to(device)\n\n        bsz = target.shape[0] # Batch Size\n        preds = model(torch.cat([first, second], dim=1))\n        \n        loss = loss_fn(preds, target)\n        losses.update(loss.item(), bsz)\n        \n        valid_preds.append(preds[:, 0].sigmoid().detach().cpu().numpy())\n\n        e_t = time.time() - s_t\n\n        if CONFIG.debug==False:\n            wandb.log({'epoch': epoch+1, 'fold': fold+1, \"step_loss\": loss})\n            wandb.log({'epoch': epoch+1, 'fold': fold+1, \"Learning Rate\": optimizer.param_groups[0][\"lr\"]})\n            \n        tq.set_description(f\"Valid Epoch: {epoch+1:2d} | Loss{losses.avg:.5f}\")\n\n    tq.close()\n    valid_preds = np.concatenate(valid_preds)\n    _ = gc.collect()\n    \n    return losses.avg, valid_preds","4cd60ddd":"def test_func(model, dataloader, device):\n    \n    model.eval()\n    test_preds = []\n\n    for step, data in enumerate(dataloader):\n\n        optimizer.zero_grad()\n        \n        first = data[\"first_features\"].to(device)\n        second = data[\"second_features\"].to(device)\n\n        bsz = target.shape[0] # Batch Size\n        preds = model(torch.cat([first, second], dim=1))        \n        test_preds.append(preds[:, 0].sigmoid().detach().cpu().numpy())\n\n    tq.close()\n    test_preds = np.concatenate(test_preds)\n    _ = gc.collect()\n    \n    return test_preds","d5d9a3da":"oof = np.zeros(len(train_df))\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nCV = GroupKFold(n_splits=CONFIG.n_fold)\n\nfor fold, (tr, te) in enumerate(CV.split(train_df, train_df[\"target\"], groups=train_df[\"first\"])):\n\n    print(f'######################### Fold: {fold+1} #############################')\n    train_dataset = PokemonDataset(\n        df=train_df.loc[tr, :].reset_index(drop=True),\n        transforms=True,\n        is_train=True\n    )\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=32,\n        shuffle=False,\n    )\n\n    valid_dataset = PokemonDataset(\n        df=train_df.loc[te, :].reset_index(drop=True),\n        transforms=False,\n        is_train=True\n    )\n\n    valid_loader = torch.utils.data.DataLoader(\n        valid_dataset,\n        batch_size=32,\n        shuffle=False,\n    )\n    \n    model = CombatModel()\n    model.to(device)\n\n    optimizer = torch.optim.AdamW(model.parameters(),\n                                  lr=1e-3,\n                                  weight_decay=CONFIG.weight_decay)\n\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n        optimizer,\n        T_max=CONFIG.epoch * len(train_loader),\n        eta_min=0,\n        last_epoch=-1\n    )\n    \n    loss_fn = nn.BCEWithLogitsLoss()\n    best_score = 0\n    \n    for epoch in range(CONFIG.epoch):\n\n        start_time = time.time()\n        train_loss = train_func(\n            model, \n            optimizer, \n            scheduler,\n            loss_fn,\n            train_loader, \n            device,\n            epoch\n        )\n        \n        valid_loss, valid_preds = valid_func(\n            model, \n            loss_fn,\n            valid_loader, \n            device,\n            epoch\n        )\n        \n        valid_score = roc_auc_score(train_df.loc[te, \"target\"], valid_preds)\n\n        end_time = time.time()\n\n        if valid_score > best_score:\n            best_score = valid_score\n            oof[te] = valid_preds\n            \n            print(f\"|\u2605| FOLD: {fold+1} | EPOCH:{epoch+1:02d} | train_loss:{train_loss:.6f} | valid_score:{valid_score:.6f} | Best Score:{best_score:.5f} | time:{end_time-start_time:.1f}s \")\n\n        else:\n            print(f\"| | FOLD: {fold+1} | EPOCH:{epoch+1:02d} | train_loss:{train_loss:.6f} | valid_score:{valid_score:.6f} | Best Score:{best_score:.5f} | time:{end_time-start_time:.1f}s \")\n\ntotal_auc = roc_auc_score(train_df[target_col], oof)\nprint(\"\u2605\"*50)\nprint(f\"total auc: {total_auc:.5f}\")","25a9ba7b":"total_auc = roc_auc_score(train_df[\"target\"], oof)\nprint(\"\u2605\"*50)\nprint(f\"total auc: {total_auc:.5f}\")","ea3355cc":"# Settings","18ef2501":"# Dataset","bfa68142":"- \u4f59\u308a\u306b\u3082\u3046\u307e\u304f\u3044\u304b\u306a\u3059\u304e\u3066\u3001\u30c6\u30b9\u30c8\u306e\u4e88\u6e2c\u3059\u3089\u3057\u3066\u3044\u306a\u3044\u3001\u3001\u3001\u3001\n- \u3053\u308c\u307e\u3067\u306eLightGBM\u3067\u306e\u7d50\u679c\u304b\u3089\u3001CV\u3068LB\u306f\u3042\u308b\u7a0b\u5ea6\u76f8\u95a2\u304c\u3042\u308a\u305d\u3046\u306a\u3053\u3068\u3082\u308f\u304b\u3063\u3066\u3044\u308b\u306e\u3067\u3001\u3053\u306e\u7d50\u679c\u306a\u3089LB\u3067\u3082\u307e\u3063\u305f\u304f\u3046\u307e\u304f\u3044\u3063\u3066\u306a\u3044\u3053\u3068\u306f\u60f3\u50cf\u306b\u5bb9\u6613\u3044\u3001\u3001\u3001\n- (\u9762\u767d\u305d\u3046\u306a\u30a2\u30a4\u30c7\u30a2\u3060\u3068\u601d\u3063\u305f\u3093\u3060\u3051\u3069\u306a...)","5814d6a0":"<div class = 'alert alert-block alert-info'\n     style = 'background-color:#b48bbd;\n              color:#4a294a;\n              border-width:5px;\n              border-color:#5a4a9c;\n              font-family:Comic Sans MS'>\n    <p style = 'font-size:24px'>Exp 003<\/p>\n<\/div>   \n<p style = 'font-size:24px'>\n    Conv2D Model\n<\/p>\n<li style = 'font-size:12px'>\n    \u307e\u3063\u305f\u304f\u3046\u307e\u304f\u3044\u304b\u306a\u304b\u3063\u305f\u306e\u3067\u3001\u3053\u3053\u3067\u6210\u4ecf\u3055\u305b\u3066\u304f\u3060\u3055\u3044\n<\/li>\n<li style = 'font-size:12px'>\n    \u8003\u3048\u65b9\u3068\u3057\u3066\u306f\u3001\u753b\u50cf\u306e\u3088\u3046\u306bpokemon\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8868\u3059\u3088\u3046\u306b\u5909\u5f62\u3057\u307e\u3059\u3002\n<\/li>\n<li style = 'font-size:12px'>\n    1ch\u76ee: first\u306e\u30dd\u30b1\u30e2\u30f36\u4f53x9\u7279\u5fb4\u91cf, 2ch\u76ee: second\u306e\u30dd\u30b1\u30e2\u30f36\u4f53x9\u7279\u5fb4\u91cf\n<\/li>\n<li style = 'font-size:12px'>\n    \u904e\u5b66\u7fd2\u5bfe\u7b56\u306b\u3001first\u306e6\u4f53\u306f\u9806\u756a\u3092shuffle\u3059\u308baugmentation\u3042\u308a\n<\/li>\n<li style = 'font-size:12px'>\n    \u6c17\u6301\u3061\u3068\u3057\u3066\u306f\u30016\u4f53\u305a\u3064\u306e\u7279\u5fb4\u306e\u5dee\u5206\u3092\u898b\u308b\u3088\u3046\u306b\u5b66\u7fd2\u3057\u3066\u304f\u308c\u306a\u3044\u304b\u306a\u3068\u8003\u3048\u3066\u307e\u3057\u305f\u304c\u7518\u304b\u3063\u305f\u3067\u3059\u3002\n<\/li>\n","20abac3b":"<img src=\"https:\/\/pbs.twimg.com\/media\/B9TQPzMCMAE9duX?format=png&name=large\" width=400%>"}}