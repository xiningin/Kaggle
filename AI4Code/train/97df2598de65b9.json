{"cell_type":{"22afe433":"code","c35aead4":"code","5615dbcb":"code","b4c9a93f":"code","39909975":"code","6d951d1a":"code","717608dd":"code","643fe843":"code","85ba09b9":"code","50dc4f2e":"code","ef797918":"code","c5ca7f99":"code","20a47dcb":"code","ed549493":"code","3a51b54b":"code","7116243f":"code","fb99f633":"markdown","1fc56762":"markdown","c9ba50f5":"markdown","43b12f0e":"markdown","556d7cd6":"markdown","c8add630":"markdown","4241ab9e":"markdown","b8d9e43c":"markdown","020d81b0":"markdown","56672aad":"markdown","61594bee":"markdown","2e9d6a6d":"markdown","ec56b07c":"markdown"},"source":{"22afe433":"import pandas as pd\n\nlabels = pd.read_csv(\"..\/input\/cassava-leaf-disease-classification\/train.csv\")\nlabels.head()","c35aead4":"train_dir = '..\/input\/cassava-leaf-disease-classification\/train_images'\ntest_dir = '..\/input\/cassava-leaf-disease-classification\/test_images'\n\nbatch_size = 32\nimg_height = 256\nimg_width = 256\n\nfrom keras import preprocessing\n\n\ntrain_datagen = preprocessing.image.ImageDataGenerator(rescale=1.\/225,\n                                                       rotation_range=40,\n                                                       width_shift_range=0.2,\n                                                       height_shift_range=0.2,\n                                                       shear_range=0.2,\n                                                       zoom_range=0.2,\n                                                       validation_split=0.3,\n                                                       horizontal_flip=True,)\n\ntest_datagen = preprocessing.image.ImageDataGenerator(rescale=1.\/255)\n\ntrain_ds = train_datagen.flow_from_dataframe(dataframe=labels.astype(str),\n                                             directory=train_dir,\n                                             subset='training',\n                                             x_col=\"image_id\",\n                                             validation_split=0.2,\n                                             y_col=\"label\",\n                                             shuffle=True,\n                                             target_size=(img_height,img_width),\n                                             batch_size=batch_size,\n                                             class_mode='categorical')\n\nval_ds = train_datagen.flow_from_dataframe(dataframe=labels.astype(str),\n                                             directory=train_dir,\n                                             subset='validation',\n                                             x_col=\"image_id\",\n                                             validation_split=0.2,\n                                             y_col=\"label\",\n                                             shuffle=True,\n                                             target_size=(img_height,img_width),\n                                             batch_size=batch_size,\n                                             class_mode='categorical')","5615dbcb":"# import numpy as np\n# np.unique(train_ds.labels)","b4c9a93f":"num_classes = 5\n\nfrom keras import models, layers, optimizers\n\nmodel = models.Sequential()\n\nmodel.add(layers.Conv2D(16,(3,3), activation='relu', input_shape=(img_height,img_width,3)))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=(img_height,img_width,3)))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Conv2D(64,(3,3), activation='relu', input_shape=(img_height,img_width,3)))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dense(num_classes, activation='softmax'))\n\nmodel.compile(optimizer=optimizers.Adam(),\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])\n\nmodel.summary()\n","39909975":"# try:\n#     import visualkeras\n# except:\n#     !pip install visualkeras\n#     import visualkeras\n\n# visualkeras.layered_view(model, draw_volume=False)","6d951d1a":"# # input_size = X_train.shape[1:]\n# input_size = 32\n# # class_num = y_test.shape[1]\n# class_num = 5\n\n# from keras.models import Sequential\n# from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n# from keras.layers.convolutional import Conv2D, MaxPooling2D \n\n# model = Sequential()\n\n# model.add(Conv2D(32, (3, 3), input_shape=input_size, padding='same'))\n# model.add(Activation('relu'))\n\n# model.add(Conv2D(32, (3, 3), input_shape=(3, 32, 32), activation='relu', padding='same'))\n# model.add(Dropout(0.2))\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(64, (3, 3), padding='same'))\n# model.add(Activation('relu'))\n\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.2))\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(64, (3, 3), padding='same'))\n# model.add(Activation('relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.2))\n# model.add(BatchNormalization())\n    \n# model.add(Conv2D(128, (3, 3), padding='same'))\n# model.add(Activation('relu'))\n# model.add(Dropout(0.2))\n# model.add(BatchNormalization())\n\n# model.add(Flatten())\n# model.add(Dropout(0.2))\n\n# model.add(Dense(256, kernel_constraint=maxnorm(3)))\n# model.add(Activation('relu'))\n# model.add(Dropout(0.2))\n# model.add(BatchNormalization())\n    \n# model.add(Dense(128, kernel_constraint=maxnorm(3)))\n# model.add(Activation('relu'))\n# model.add(Dropout(0.2))\n# model.add(BatchNormalization())\n\n# model.add(Dense(class_num))\n# model.add(Activation('softmax'))","717608dd":"# gpu_info = !nvidia-smi\n# gpu_info = '\\n'.join(gpu_info)\n# print(gpu_info)","643fe843":"# ENABLE GPU\n\n# device = torch.device('cuda')","85ba09b9":"epochs=100\nsteps_per_epoch = 150\n\nhistory = model.fit(\n    train_ds,steps_per_epoch=steps_per_epoch,\n    validation_data=val_ds,validation_steps=steps_per_epoch,\n    epochs=epochs,\n)","50dc4f2e":"import matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","ef797918":"# def generate_number():\n\n# def generate_layer_type():\n\n# def generate_layer_params(layer_type):\n\n# def generate_layer(layer_type,layer_params):\n\n# def create_model(layers):\n\n# def train_and_eval_model(model):\n\n# def log_score(score):\n\n# def print_score(score):","c5ca7f99":"\n\n# best_score = 0\n# while True:\n#     N_layers = generate_number()\n#     layers = []\n#     for i in range(N):\n#         layer_type = generate_layer_type()\n#         layer_params = generate_layer_params(layer_type)\n#         layer = generate_layer(layer_type,layer_params)\n#         layers.append(layer)\n        \n#     model = create_model(layers)\n#     score = train_and_eval_model(model)\n#     log_score(score)\n#     if score>best_score:\n#         print_score(score)\n#         best_score = score\n    \n    ","20a47dcb":"# epochs = 25\n# optimizer = 'adam'\n\n# model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\n\n# print(model.summary())\n\n# numpy.random.seed(seed)\n# model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64)\n\n# # Model evaluation\n# scores = model.evaluate(X_test, y_test, verbose=0)\n# print(\"Accuracy: %.2f%%\" % (scores[1]*100))","ed549493":"test_dir = '..\/input\/cassava-leaf-disease-classification\/test_images'\n\nfrom keras import preprocessing\n\n\ntest_datagen = preprocessing.image.ImageDataGenerator(rescale=1.\/255)\n\n\n\n","3a51b54b":"from PIL import Image\nimport numpy as np\nimport pandas as pd\nimport os\n\nss = pd.read_csv(\"..\/input\/cassava-leaf-disease-classification\/sample_submission.csv\")\npreds = []\n\nfor image_id in ss.image_id:\n    image = Image.open(os.path.join(test_dir, image_id))\n    image = image.resize((img_height, img_width))\n    image = np.expand_dims(image, axis = 0)\n    preds.append(np.argmax(model.predict(image)))\n\nss['label'] = preds","7116243f":"ss.to_csv('submission.csv', index = False)","fb99f633":"### 1.0 import labels","1fc56762":"# Image Recognition with a CNN","c9ba50f5":"# 7. submission\n## 7.1 create test set","43b12f0e":"## 1.1 importing folder directly into dataset","556d7cd6":"## 3.1 visualizing the model - network architecture","c8add630":"## 4. training model","4241ab9e":"### 5.1 function declerations","b8d9e43c":"## 5. evaluating the model","020d81b0":"## 3. creating the model","56672aad":"## 3. (again) create the model - yarden's version","61594bee":"## start random hparams generation","2e9d6a6d":"## 1. prepping the Data","ec56b07c":"## 6. improving hparams\nlet's now generate random hparams and test each one\nWe'll start by first declaring functions for each purpose"}}