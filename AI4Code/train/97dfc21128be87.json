{"cell_type":{"b5368b22":"code","12f280dd":"code","9d988a82":"code","0e5da248":"code","d31a073f":"code","59dcfdcc":"code","8fdc14e3":"code","fab5f806":"code","98e61849":"code","7c7671af":"code","f4c74fab":"code","b7927f0c":"code","b1755fbc":"code","a89418e7":"code","3d437620":"code","73059fc1":"code","dc3d2102":"markdown","39336fef":"markdown","616f80de":"markdown","c84131db":"markdown","362bbcaf":"markdown","461024bc":"markdown","72795055":"markdown","2afdda1c":"markdown","c30e1403":"markdown","ddd7669f":"markdown","d830dda0":"markdown","0bd57eb3":"markdown","f1ca2839":"markdown","ccb085dc":"markdown","aebcf02f":"markdown","1686285c":"markdown","baacf0c1":"markdown"},"source":{"b5368b22":"# Pr\u00e1ctica: Regrsi\u00f3n log\u00edstica\n# Fernando Bordignon - http:\/\/saberesdigitales.unipe.edu.ar\n\n# Carga de librer\u00edas\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn import linear_model\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport seaborn as sb\n%matplotlib inline","12f280dd":"# carga del juego de datos\n\ndataframe = pd.read_csv(r\"..\/input\/winlinmac\/usuarios_win_mac_lin.csv\")\ndataframe.head()","9d988a82":"dataframe.describe()","0e5da248":"print(dataframe.groupby('clase').size())","d31a073f":"dataframe.drop(['clase'],1).hist()\nplt.show()","59dcfdcc":"sb.pairplot(dataframe.dropna(), hue='clase',size=4,vars=[\"duracion\", \"paginas\",\"acciones\",\"valor\"],kind='reg')","8fdc14e3":"X = np.array(dataframe.drop(['clase'],1))\ny = np.array(dataframe['clase'])\nX.shape","fab5f806":"model = linear_model.LogisticRegression(solver='liblinear')\nmodel.fit(X,y)","98e61849":"predictions = model.predict(X)\nprint(predictions)[0:5]","7c7671af":"model.score(X,y)","f4c74fab":"validation_size = 0.20\nseed = 7\nX_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, y, test_size=validation_size, random_state=seed)","b7927f0c":"name='Logistic Regression'\nkfold = model_selection.KFold(n_splits=10, random_state=seed)\ncv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\nmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\nprint(msg)","b1755fbc":"predictions = model.predict(X_validation)\nprint(accuracy_score(Y_validation, predictions))","a89418e7":"print(confusion_matrix(Y_validation, predictions))","3d437620":"print(classification_report(Y_validation, predictions))","73059fc1":"X_new = pd.DataFrame({'duracion': [10], 'paginas': [3], 'acciones': [5], 'valor': [9]})\nmodel.predict(X_new)","dc3d2102":"Tambi\u00e9n podemos ver el reporte de clasificaci\u00f3n con nuestro conjunto de Validaci\u00f3n. En nuestro caso vemos que se utilizaron como \u201csoporte\u201d 18 registros windows, 6 de mac y 10 de Linux (total de 34 registros). Podemos ver la precisi\u00f3n con que se acertaron cada una de las clases y vemos que por ejemplo de Macintosh tuvo 3 aciertos y 3 fallos (0.5 recall). La valoraci\u00f3n que de aqui nos conviene tener en cuenta es la de F1-score, que tiene en cuenta la precisi\u00f3n y recall. El promedio de F1 es de 84% lo cual no est\u00e1 nada mal.","39336fef":"Volvemos a compilar nuestro modelo de Regresi\u00f3n Log\u00edstica pero esta vez s\u00f3lo con 80% de los datos de entrada y calculamos el nuevo scoring que ahora nos da 74%.","616f80de":"Y creamos nuestro modelo y hacemos que se ajuste (fit) a nuestro conjunto de entradas X y salidas \u2018y\u2019.\n","c84131db":"# Regresi\u00f3n Log\u00edstica \n\n(original en https:\/\/www.aprendemachinelearning.com\/regresion-logistica-con-python-paso-a-paso\/)\n\n**Breve Introducci\u00f3n a la Regresi\u00f3n Log\u00edstica**\n\nUtilizaremos algoritmos de Machine Learning en Python para resolver un problema de Regresi\u00f3n Log\u00edstica. A partir de un conjunto de datos de entrada (caracter\u00edsticas), nuestra salida ser\u00e1 discreta (y no continua) por eso utilizamos Regresi\u00f3n Log\u00edstica (y no Regresi\u00f3n Lineal). La Regresi\u00f3n Log\u00edstica es un Algoritmo Supervisado y se utiliza para clasificaci\u00f3n.\n\nVamos a clasificar problemas con dos posibles estados \u201cSI\/NO\u201d: binario o un n\u00famero finito de \u201cetiquetas\u201d o \u201cclases\u201d: m\u00faltiple. Algunos Ejemplos de Regresi\u00f3n Log\u00edstica son:\n\n* Clasificar si el correo que llega es Spam o No es Spam\n* Dados unos resultados cl\u00ednicos de un tumor clasificar en \u201cBenigno\u201d o \u201cMaligno\u201d.\n* El texto de un art\u00edculo a analizar es: Entretenimiento, Deportes, Pol\u00edtica \u00f3 Ciencia\n* A partir de historial bancario conceder un cr\u00e9dito o no\n\nConfiaremos en la implementaci\u00f3n del paquete sklearn en Python para ponerlo en pr\u00e1ctica.\n\n**Ejercicio de Regresi\u00f3n Log\u00edstica en Python**\n\nPara nuestro ejercicio he creado un archivo csv con datos de entrada a modo de ejemplo para clasificar si el usuario que visita un sitio web usa como sistema operativo Windows, Macintosh o Linux.\n\nNuestra informaci\u00f3n de entrada son 4 caracter\u00edsticas que tom\u00e9 de una web que utiliza Google Analytics y son:\n\n* Duraci\u00f3n de la visita en Segundos\n* Cantidad de P\u00e1ginas Vistas durante la Sesi\u00f3n\n* Cantidad de Acciones del usuario (click, scroll, uso de checkbox, sliders,etc)\n* Suma del Valor de las acciones (cada acci\u00f3n lleva asociada una valoraci\u00f3n de importancia)\n\nComo la salida es discreta, asignaremos los siguientes valores a las etiquetas:\n\n* 0 \u2013 Windows\n* 1 \u2013 Macintosh\n* 2 -Linux\n\nLa muestra es peque\u00f1a: son 170 registros para poder comprender el ejercicio, pero recordemos que para conseguir buenos resultados siempre es mejor contar con un n\u00famero abundante de datos que dar\u00e1n mayor exactitud a las predicciones y evitar\u00e1n problemas de overfitting u underfitting. (Por decir algo, de mil a 5 mil registros no estar\u00eda mal).\n","362bbcaf":"**Visualizaci\u00f3n de Datos**\n\nAntes de empezar a procesar el conjunto de datos, vamos a hacer unas visualizaciones que muchas veces nos pueden ayudar a comprender mejor las caracter\u00edsticas de la informaci\u00f3n con la que trabajamos y su correlaci\u00f3n.\n\nPrimero visualizamos en formato de historial los cuatro Features de entrada con nombres \u201cduraci\u00f3n\u201d, \u201cp\u00e1ginas\u201d,\u201dacciones\u201d y \u201cvalor\u201d podemos ver gr\u00e1ficamente entre qu\u00e9 valores se comprenden sus m\u00ednimos y m\u00e1ximos y en qu\u00e9 intervalos concentran la mayor densidad de registros.","461024bc":"Luego analizaremos cuantos resultados tenemos de cada tipo usando la funci\u00f3n groupby y vemos que tenemos 86 usuarios \u201cClase 0\u201d, es decir Windows, 40 usuarios Mac y 44 de Linux.","72795055":"Leemos el archivo csv (por sencillez, se considera que estar\u00e1 en el mismo directorio que el archivo de notebook .ipynb) y lo asignamos mediante Pandas a la variable dataframe. Mediante el m\u00e9todo dataframe.head() vemos en pantalla los 5 primeros registros.","2afdda1c":"A continuaci\u00f3n llamamos al m\u00e9todo dataframe.describe() que nos dar\u00e1 algo de informaci\u00f3n estad\u00edstica b\u00e1sica de nuestro set de datos. La Media, el desv\u00edo est\u00e1ndar, valores m\u00ednimo y m\u00e1ximo de cada caracter\u00edstica.","c30e1403":"Y tambi\u00e9n podemos interrelacionar las entradas de a pares, para ver como se concentran linealmente las salidas de usuarios por colores: Sistema Operativo Windows en azul, Macintosh en verde y Linux en rojo.","ddd7669f":"**Creamos el Modelo de Regresi\u00f3n Log\u00edstica**\n\nAhora cargamos las variables de las 4 columnas de entrada en X excluyendo la columna \u201cclase\u201d con el m\u00e9todo drop(). En cambio agregamos la columna \u201cclase\u201d en la variable y. Ejecutamos X.shape para comprobar la dimensi\u00f3n de nuestra matriz con datos de entrada de 170 registros por 4 columnas.","d830dda0":"**Validaci\u00f3n de nuestro modelo**\n\nUna buena pr\u00e1ctica en Machine Learning es la de subdividir nuestro conjunto de datos de entrada en un set de entrenamiento y otro para validar el modelo (que no se utiliza durante el entrenamiento y por lo tanto la m\u00e1quina desconoce). Esto evitar\u00e1 problemas en los que nuestro algoritmo pueda fallar por \u201csobregeneralizar\u201d el conocimiento.\n\nPara ello, subdividimos nuestros datos de entrada en forma aleatoria (mezclados) utilizando 80% de registros para entrenamiento y 20% para validar.","0bd57eb3":"Y confirmamos cuan bueno fue nuestro modelo utilizando model.score() que nos devuelve la precisi\u00f3n media de las predicciones, en nuestro caso del 77%.","f1ca2839":"Y ahora hacemos las predicciones -en realidad clasificaci\u00f3n- utilizando nuestro \u201ccross validation set\u201d, es decir del subconjunto que hab\u00edamos apartado. En este caso vemos que los aciertos fueron del 85% pero hay que tener en cuenta que el tama\u00f1o de datos era peque\u00f1o.","ccb085dc":"**Clasificaci\u00f3n (o predicci\u00f3n) de nuevos valores**\n\nComo \u00faltimo ejercicio, vamos a inventar los datos de entrada de  navegaci\u00f3n de un usuario ficticio que tiene estos valores:\n\n* Tiempo Duraci\u00f3n: 10\n* Paginas visitadas: 3\n* Acciones al navegar: 5\n* Valoraci\u00f3n: 9\n\nLo probamos en nuestro modelo y vemos que lo clasifica como un usuario tipo 2, es decir, de Linux.","aebcf02f":"Una vez compilado nuestro modelo, le hacemos clasificar todo nuestro conjunto de entradas X utilizando el m\u00e9todo \u201cpredict(X)\u201d y revisamos algunas de sus salidas y vemos que coincide con las salidas reales de nuestro archivo csv.","1686285c":"Finalmente vemos en pantalla la \u201cmatriz de confusi\u00f3n\u201d donde muestra cuantos resultados equivocados tuvo de cada clase (los que no est\u00e1n en la diagonal), por ejemplo predijo 3 usuarios que eran Mac como usuarios de Windows y predijo a 2 usuarios Linux que realmente eran de Windows.\n\n**Reporte de Resultados del Modelo**","baacf0c1":"En este ejercicio las 3 clases est\u00e1n equilibradas, pero \u00bfQu\u00e9 pasa si tengo desbalanceo de datos? \n\n**Conclusiones**\n\nDurante este art\u00edculo vimos c\u00f3mo crear un modelo de Regresi\u00f3n Log\u00edstica en Python para poder clasificar el Sistema Operativo de usuarios a partir de sus caracter\u00edsticas de navegaci\u00f3n en un sitio web. A partir de este ejemplo, se podr\u00e1 extender a otro tipos de tareas que pueden surgir durante nuestro trabajo en el que deberemos clasificar resultados en valores discretos. Si tuvi\u00e9ramos que predecir valores continuos, deberemos aplicar Regresi\u00f3n Lineal.\n\n*Addio, ci vediamo nel prossimo notebook!*"}}