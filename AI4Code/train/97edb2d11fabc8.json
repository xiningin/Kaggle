{"cell_type":{"7b0477ec":"code","ed35ae68":"code","8c5a835f":"code","5c41a31e":"code","e968f0cf":"code","74fefa81":"code","e9a17408":"code","c7117a0f":"code","9bf3e567":"code","1b1bca64":"code","06a71399":"code","c93a1247":"code","c0dbd742":"code","785f0495":"code","c49f59e2":"code","97fba227":"code","1fa4c7a1":"code","3bf77fe0":"code","acf2d4ea":"code","f3e30870":"code","45b9fb37":"code","019f0b57":"code","da51cb8e":"code","cfb08fbb":"code","274ce09d":"code","bacac693":"code","4f650b06":"code","eb578e40":"code","87e4aa07":"code","71803c58":"code","9664a00b":"code","04f73927":"code","1d2d57ff":"code","5479480e":"code","063adc9b":"code","c55dd08b":"code","d442221d":"code","c944e7cf":"code","d2261e83":"code","352edb95":"markdown","0edfe089":"markdown","edf8a620":"markdown","45a8ed02":"markdown","50aeff01":"markdown","fbaee1a5":"markdown","19894d86":"markdown","9d28b37f":"markdown","4dda19bd":"markdown","5334ee9e":"markdown","19d86c1d":"markdown","977878da":"markdown","10353601":"markdown","162128c2":"markdown","96a8efb6":"markdown","e91a8392":"markdown","2f198804":"markdown","421b195f":"markdown","98f77b02":"markdown","66d56f35":"markdown","ef48b53c":"markdown","a1092963":"markdown","75c0551d":"markdown","a37b87c2":"markdown","fe8852f9":"markdown","29d3008f":"markdown","f09bfbf7":"markdown","25b59cdc":"markdown","b7a63fa0":"markdown","31648cb5":"markdown","d2ee3d8e":"markdown"},"source":{"7b0477ec":"import os \nimport torch  \nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score \nfrom PIL import Image\n\nfrom torch.utils.data import DataLoader, Dataset, random_split\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torchvision.utils import make_grid\n\ntorch.manual_seed(5)\nnp.random.seed(5)\n\n%matplotlib inline","ed35ae68":"!pip install torchsummary","8c5a835f":"train_img_parent = \"..\/input\/intel-image-classification\/seg_train\/seg_train\" # train directory address\ntest_img_parent = \"..\/input\/intel-image-classification\/seg_test\/seg_test\" # test directory address\n\nclassLabels = {'buildings':0, 'mountain':1, 'street':2, 'forest':3, 'sea':4, 'glacier':5}","5c41a31e":"def csv_maker(parent_dir, class_label, csv_name):\n    \"\"\"Converts unstructured data stored in subdirectories into dataframe and csv file\n    \n    Args-\n        parent_dir- String containing address of parent directory(test data or training data)\n        class_label- Class label dictionary object\n        csv_name- Name you want to give to your returned csv file (string) \n        \n    Returns-\n        dataframe- A pandas.DataFrame object\n    \"\"\"\n    labelled_arr = np.array([]) # creates an empty array\n    \n    for subdir, label in class_label.items():\n        img_dir = os.path.join(parent_dir, subdir) # gets the path of each subdirectory in the parent data directory\n        files = np.array(os.listdir(img_dir)).reshape(-1,1) # gets the list of names of each image\n        labels = np.array([label for i in range(files.shape[0])]).reshape(-1,1) #creates a label column for the images\n        data = np.concatenate((files, labels), axis = 1) # concatenates file name and label arrays into a single array\n        labelled_arr = np.append(labelled_arr, data)\n    \n    labelled_arr = labelled_arr.reshape(-1,2)\n    \n    np.random.seed(5)\n    np.random.shuffle(labelled_arr) # shuffles the dataset\n    \n    dataframe = pd.DataFrame(labelled_arr)\n    dataframe.columns = ['image', 'label']\n    dataframe['label'] = dataframe['label'].astype('int') \n    \n    dataframe.to_csv(csv_name, index = False) # creates the csv file for the dataframe\n    \n    return dataframe","e968f0cf":"train_df = csv_maker(train_img_parent, classLabels, csv_name = \"train.csv\")\n\ntest_df = csv_maker(test_img_parent, classLabels, csv_name = \"test.csv\")\n\ntrain_csv = \".\/train.csv\"\ntest_csv = \".\/test.csv\"","74fefa81":"print(\"\\nTraining DF-\\n\")\nprint(train_df.head())\nprint(\"\\nTesting DF-\\n\")\nprint(test_df.head())","e9a17408":"# creating custom pytorch dataset\n\nclass ImageDataset(Dataset):\n    def __init__(self, dataframe, data_dir, label_dict, transform = None):\n        self.df = dataframe\n        self.data_dir = data_dir\n        self.label_dict = label_dict\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        img_name, label = self.df.loc[idx]\n        class_labels = list(self.label_dict.keys())\n        img_path = self.data_dir + '\/' + class_labels[label] + '\/' + img_name\n        img = img = Image.open(img_path)\n        \n        if self.transform:\n            img = self.transform(img)\n        \n        return img, label        ","c7117a0f":"# R_sum = 0\n# G_sum = 0\n# B_sum = 0\n\n# for i in range(len(train_dataset)):\n#     R_sum += train_dataset[i][0][0].sum()\n#     G_sum += train_dataset[i][0][1].sum()\n#     B_sum += train_dataset[i][0][2].sum()\n\n# R_mean = R_sum \/ (256*256*len(train_dataset))\n# G_mean = G_sum \/ (256*256*len(train_dataset))\n# B_mean = B_sum \/ (256*256*len(train_dataset))","9bf3e567":"# mean = (R_mean, G_mean, B_mean)\nmean = (0.4302, 0.4575, 0.4539)","1b1bca64":"# R2_sum = 0\n# G2_sum = 0\n# B2_sum = 0\n\n# for i in range(len(train_dataset)):\n#     R2_sum += ((train_dataset[i][0][0] - mean[0])**2).sum()\n#     G2_sum += ((train_dataset[i][0][1] - mean[1])**2).sum()\n#     B2_sum += ((train_dataset[i][0][2] - mean[2])**2).sum()\n\n# R_std = (R2_sum \/ (256*256*len(train_dataset)))**0.5\n# G_std = (G2_sum \/ (256*256*len(train_dataset)))**0.5\n# B_std = (B2_sum \/ (256*256*len(train_dataset)))**0.5","06a71399":"# std = (R_std, G_std, B_std)\nstd = (0.2606, 0.2588, 0.2907)","c93a1247":"# We will try different transforms on our training data and compare the results. For now, let us stick to the training transforms given below\n\nextra_transforms = (transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.3), transforms.RandomPerspective(distortion_scale=0.2, p=0.5, interpolation=3, fill=0))\n\n\ntransformTrain1 = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.Resize([256, 256]),\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std),\n    transforms.RandomErasing(),\n])\n\ntransformTrain2 = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomApply(extra_transforms, p=0.2),\n    transforms.Resize([256, 256]),\n    transforms.ToTensor(),\n    transforms.RandomErasing(scale=(0.02, 0.2)),\n])\n\n# Transforms for test data\ntransformTest = transforms.Compose([\n    transforms.Resize([256, 256]),\n    transforms.ToTensor(),\n])\n    ","c0dbd742":"# creating training dataset\ntrain_dataset = ImageDataset(train_df, train_img_parent, classLabels, transform = transformTrain2)\n\n# creating testing dataset\ntest_dataset = ImageDataset(test_df, test_img_parent, classLabels, transform = transformTest)","785f0495":"print(\"Total images in the dataset:\", len(train_dataset))\nimg, label = train_dataset[0]\nprint(img[:,:5,:5]) # printing a small 3 x 5 x 5 slice of the 3 x 256 x 256 tensor\nprint(\"Image label:\", list(classLabels.keys())[label])\nplt.imshow(img.permute(1,2,0))\n","c49f59e2":"batch_size = 32\n                                                                                \ntrain_dl = DataLoader(\n    dataset = train_dataset, \n    batch_size = batch_size, \n    shuffle = True, \n    num_workers = 2, \n    pin_memory = True)\n\ntest_dl = DataLoader(\n    dataset = test_dataset, \n    batch_size = batch_size, \n    shuffle = False, \n    num_workers = 2, \n    pin_memory = True)","97fba227":"train_dl","1fa4c7a1":"def batch_viewer(dataloader):\n    \"\"\"Shows the images in a batch returned by the PyTorch dataloader object.\n    \n    Args-\n        dataloader- PyTorch dataloader object\n    \n    Returns-\n        None\n    \"\"\"\n    for images, labels in dataloader:\n        fig, ax = plt.subplots(figsize = (16,16))\n        ax.imshow(make_grid(images, nrow = 8).permute(1, 2, 0))\n        break    ","3bf77fe0":"batch_viewer(train_dl)","acf2d4ea":"def accuracy(output, labels):\n    \"\"\"Calculates the accuracy for the predicted output and the actual label values.\n    \n    Agrs-\n        output- Output tensor generated by the model\n        labels- Actual labels for the given batch of data\n    \n    Returns-\n        accuracy- Accuracy percentage for the predictions\n    \"\"\"\n    softmax = nn.Softmax(dim=1)\n    output = softmax(output) # converts output values to probability values for each class\n    preds = torch.argmax(output, axis = 1) # sets class with max probability as prediction \n    accuracy = torch.sum(preds==labels).item() \/ len(labels) # accuracy = correct_prediction \/ total_predictions\n    return torch.Tensor([accuracy])\n\nclass SceneClassificationBase(nn.Module):\n    def training_step(self, batch):\n        \"\"\"Calculates the cross entropy loss for a given batch of data.\n        \n        Args-\n            batch- One batch of data as generated by the data loader\n        \n        Returns-\n            batch_loss- Total cross entropy loss for the batch\n        \"\"\"\n        images, labels = batch \n        output = self(images)                  # generates predictions for the batch of images\n        batch_loss = F.cross_entropy(output, labels) # calculates loss for the predictions and actual labels\n        return batch_loss\n    \n    def validation_step(self, batch):\n        \"\"\"Calculates total validation loss and validation accuracy for a given batch data during a validation step.\n        \n        Args-\n            batch- One batch of data as generated by the data loader\n            \n        Returns-\n            A dictionary object containing validation loss and validation accuracy for the given batch\n        \"\"\"\n        images, labels = batch \n        output = self(images)                    # generate predictions for given batch\n        batch_loss = F.cross_entropy(output, labels)   # calculates batch loss\n        batch_acc = accuracy(output, labels)           # calculate batch accuracy\n        return {'val_loss': batch_loss.detach(), 'val_acc': batch_acc}\n        \n    def validation_epoch_end(self, outputs):\n        \"\"\"Calculates mean validation loss and mean validation accuracy for a one validation epoch.\n        \n        Args-\n            outputs- A list of dictionary objects containing validation accuracy and validation loss for each batch of data in one epoch\n            \n        Returns-\n            A dictionary object containing validation loss and validation accuracy for the given batch\n        \"\"\"\n        batch_losses = [batch_val_dict['val_loss'] for batch_val_dict in outputs] # creates a list of batch losses for all the batches in one validation epoch\n        epoch_loss = torch.stack(batch_losses).mean()   # calculates mean validation loss for the epoch\n        batch_accs = [batch_val_dict['val_acc'] for batch_val_dict in outputs]   # creates a list of batch accuracies for all the batches in one validation epoch \n        epoch_acc = torch.stack(batch_accs).mean()      # calculates mean validation accuracy for the epoch\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, \n            result['lrs'][-1], \n            result['train_loss'], \n            result['val_loss'], \n            result['val_acc']))","f3e30870":"class Model_ResNeXt(SceneClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Sequential(    # 3 x 256 x 256\n            nn.Conv2d(3, 64, kernel_size = 3, padding = 1),    # 64 x 256 x 256\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace = True),\n        )    \n        self.conv2 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size = 3, padding = 1),    # 128 x 256 x 256\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace = True),\n            nn.MaxPool2d(2, 2),    # 128 x 128 x 128 \n        )\n        self.resnxt1 = nn.Sequential(\n            nn.Conv2d(128, 128, kernel_size = 3, padding = 1), # 128 x 128 x 128\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace = True),\n            nn.Conv2d(128, 128, kernel_size = 3, padding = 1), # 128 x 128 x 128\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace = True),\n        )\n        self.conv3 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size = 3, padding = 1),    # 256 x 128 x 128\n            nn.BatchNorm2d(256),\n            nn.MaxPool2d(2, 2),   # 256 x 64 x 64\n            nn.ReLU(inplace = True), \n        )\n        self.conv4 = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size = 3, padding = 1),    # 512 x 64 x 64\n            nn.BatchNorm2d(512),\n            nn.MaxPool2d(2, 2),    # 512 x 32 x 32\n            nn.ReLU(inplace = True), \n        )\n        self.resnxt2 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size = 3, padding = 1), # 512 x 32 x 32\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace = True),\n            nn.Conv2d(512, 512, kernel_size = 3, padding = 1), # 512 x 32 x 32\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace = True),\n        )\n        self.classifier = nn.Sequential(nn.AvgPool2d(2, 2), # 512 x 16 x 16\n                                        nn.Flatten(), \n                                        nn.Linear(512 * 16 * 16, 6),\n        )\n        \n    def forward(self, x):\n        output = self.conv1(x)\n        output = self.conv2(output)\n        output = self.resnxt1(output) + self.resnxt1(output) + self.resnxt1(output) + self.resnxt1(output) + output\n        output = self.conv3(output)\n        output = self.conv4(output)\n        output = self.resnxt2(output) + self.resnxt2(output) + self.resnxt2(output) + self.resnxt2(output) + output\n        output = self.classifier(output)\n        return output\n        ","45b9fb37":"model = Model_ResNeXt()\nmodel","019f0b57":"from torchsummary import summary\n\nsummary(model, input_size=(3, 256, 256))","da51cb8e":"def get_default_device():\n    \"\"\"Picks the trainig device-- GPU if available, else CPU.\n    \"\"\"\n    if torch.cuda.is_available():   # checks if a cuda device is available\n        return torch.device('cuda') # sets the default device as the available CUDA device\n    else:\n        return torch.device('cpu')  # if no CUDA device found, sets CPU as the default device\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\n    \"\"\"\n    if isinstance(data, (list,tuple)): # asserts if the data is a list\/tuple \n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to the default device.\n    \"\"\"\n    def __init__(self, dataloader, device):\n        self.dl = dataloader\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device.\n        \"\"\"\n        for batch in self.dl: \n            yield to_device(batch, self.device)\n\n    def __len__(self):\n        \"\"\"Prints the total number of batches.\n        \"\"\"\n        return len(self.dl)","cfb08fbb":"device = get_default_device()\ndevice","274ce09d":"train_dl = DeviceDataLoader(train_dl, device)\ntest_dl = DeviceDataLoader(test_dl, device)\nto_device(model, device)","bacac693":"def try_batch(dataloader):\n    for images, labels in dataloader:\n        print('images.shape:', images.shape)\n        out = model(images)\n        print('out.shape:', out.shape)\n        print('out[0]:', out[0])\n        break\n\ntry_batch(train_dl)","4f650b06":"from tqdm.notebook import tqdm\n\n@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()    # sets the model to evaluation mode\n    outputs = [model.validation_step(batch) for batch in val_loader] # performs validation for each batch and stores it in a list\n    return model.validation_epoch_end(outputs) # returns mean validation accuracy and validation loss for one complete epoch\n\ndef get_lr(optimizer):\n    \"\"\"Gets the learning rate of the optimizer.\n    \"\"\"\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n                  weight_decay = 0, grad_clip = None, opt_func = torch.optim.SGD):\n    \n    torch.cuda.empty_cache()    # clears cache in CUDA device\n    history = []    # declares an empty list to store result for each epoch\n    \n    # sets up custom optimizer with weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay = weight_decay)\n    \n    # sets up one-cycle learning rate scheduler\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs = epochs, steps_per_epoch = len(train_loader))\n    \n    for epoch in range(epochs): \n        model.train()    # initiate training phase\n        train_losses = []\n        lrs = []\n        for batch in tqdm(train_loader):    # cycles through each batch of the training data\n            loss = model.training_step(batch)    \n            train_losses.append(loss)\n            loss.backward()\n            \n            # perfomrs gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step() # updates parameters based on gradients obtained via optimizer.backwards()\n            optimizer.zero_grad() # resets gradient values\n            \n            # records & updates learning rate\n            lrs.append(get_lr(optimizer))\n            scheduler.step()\n        \n        # initaites validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","eb578e40":"initial_acc_loss = evaluate(model, test_dl)\nprint(initial_acc_loss)","87e4aa07":"epochs = 10\nmax_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","71803c58":"%%time\nhistory = fit_one_cycle(epochs, max_lr, model, train_dl, test_dl, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)","9664a00b":"epochs = 5\nmax_lr = 0.001\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam\n\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, test_dl, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)","04f73927":"trainingComplete = True","1d2d57ff":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title('Accuracy vs. No. of Epochs')\n    \nplot_accuracies(history)","5479480e":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of Epochs')\n    \nplot_losses(history)","063adc9b":"def predict_single_image(image_data):\n    image, label = image_data\n    label = list(classLabels.keys())[label]\n    # displaying the image\n    plt.imshow(image.permute(1,2,0))\n    print(\"Actual label: \", label)\n    # using model to predict image label\n    xb = image.unsqueeze(0)\n    xb = to_device(xb, device)\n    preds = model(xb)\n    prediction = preds[0]\n    prediction = list(classLabels.keys())[torch.argmax(prediction).item()]\n    print(\"Prediction: \", prediction)","c55dd08b":"predict_single_image(test_dataset[69])","d442221d":"predict_single_image(test_dataset[420])","c944e7cf":"predict_single_image(test_dataset[100])","d2261e83":"torch.save(model.state_dict(), 'sceneClassification_ResNeXt.pth')","352edb95":"Now, the next challege. We need a method that allows us to feed data to our deep learning model for training as well as testing. Luckily, for this, we have the PyTorch's built-in DataLoader class. Let us create our dataloader objects.","0edfe089":"With this, we come to an end of one part of our project where we used a ResNeXt9 CNN model to train and test a multi-class scene classification model.","edf8a620":"The initial model accuracy that we got is around 16%. Let us now train the model.","45a8ed02":"### Creating the CSV files and dataframe objects-","50aeff01":"One thing to be noted is that we set **shuffle = False** for test data loader as we aren't training the model on the test data. We are just using it to make predictions, for which there's no need to shuffle the data.","fbaee1a5":"The model made a wrong prediction on this image. And to be honest, this one is quite complex for even a human eye. One can see mountains in the image, so it can be classified as a 'mountain' scene. The white region below the mountains looks like waves. So it can be classified as a 'sea', which is exactly what our model did. But unfortunately, the white region is the frozen ice of a glacier.","19894d86":"One of the advantages of working with Deep Learning frameworks like PyTorch is that they allow us to train our models on GPU. This can significantly speed up the training process as compared to training on CPUs, especially when we have huge datasets. [This](https:\/\/medium.com\/@shachishah.ce\/do-we-really-need-gpu-for-deep-learning-47042c02efe2#:~:text=The%20High%20bandwidth%2C%20hiding%20the,lot%20faster%20than%20a%20CPU.&text=CPU%20can%20train%20a%20deep,Learning%20Model%20efficiently%20and%20effectively.) article explains why GPUs are a better choice for Deep Learning as compared to CPUs.\n\nNow, we need to define a method that allows us to push our model as well as the dataset onto the GPU during the training\/testing process.","9d28b37f":"---\n## Importing Project Dependencies\n---\n\nFirst, we will import all the necessary Python PyData modules.\u00a0\n\n*One thing to be noted is that we are implementing the model using PyTorch.*","4dda19bd":"Now, let us have a look at the initial model accuracy and loss on the test dataset. One thing to be noted here is that we haven't done any training yet. So whatever the results will be are goinf to be based on entirely randomized model parameters. In order to improve the model's performance, we will need to optimize it, which will be done during the training phase.","5334ee9e":"Let us now save our model in case we would like to use it in the future for making classifications.","19d86c1d":"This was an easy classification. An as we can see, our model did a good job on this one.","977878da":"What's the point of making a scene classification model if we can't use it, right? So let us use our model and try to make predictions from it on individual images from the test set and see how our model is performing.","10353601":"---\n## Model & Training\n---\n\nNow, let us move on to the next step. In this section, we will define our model class along with the loss function, scoring function and the various helper functions that will come handy while training and evaluating our model.\n\nFirst, let us create a base class where we will define all the helper functions as well as our loss and accuracy functions. Then we will simply inherit the base class to another class where we will define our actual model.\n\nThis will allow us to keep our code clean and modular. Instead of redefining different model functions again and again from scratch, we can simply define a new model while our helper functions will remain the same.","162128c2":"---\n\nLet us now have a look at our training and testing datasets.\n\n---","96a8efb6":"### Defining Data Loaders","e91a8392":"---\n## Preparing the Dataset\n---\nNow comes the first tricky part. If you look at the dataset directory, you will observe that we don't have any CSV file or a directly labelled data to work with. Rather, the training and testing data directories are further divided into subdirectories for each possible outcome class. So, in order to be able to work with this data, we need to restructure the data into a format that we can work on; a format that we are used to working with, basically CSV files and pandas.DataFrame objects. Also, since we will be implementing our Deep Learning model using PyTorch, we need to convert the images into tensor objects.\n\nFrom a programmer's problem solving perspective, let us break down these problems-\n\n1. \n    * Formatting the unstructured dataset into structured CSV and dataframe objects \n    * Adding label to the data\n2. \n    * Converting the images into tensor objects \n    * Converting the dataframe into a PyTorch dataset\n    \n3. Creating a method to view the images from their tensor form ","2f198804":"---\n## Understanding the Problem Statement\n---\n\nFor this project, we will be working on the [Intel Image Classification](https:\/\/www.kaggle.com\/puneet6060\/intel-image-classification) dataset.\u00a0\n\n\nThis is a multi-class classification problem where, given a picture, we want our model to classify it as one of the six possible scenes\u200a-\u200abuildings (0), forest (1), glacier (2), mountain (3), sea (4) or street (5).\n\nAs per the data source, each image is a 150 \u00d7 150 pixel, 3-channeled (RGB) image, with around 14k images in the training set and 3k images in the testing set.","421b195f":"Now, one of the transformations we will be performing on our images is normalizing them. Normalization is a key step in Deep Learning. By restraining the range in which the values are spread into a small range, you can really speed up the training speed. \n\n---\n\\***NOTE**- Since the process of calculation of the normalization parameters (mean and standard deviation can be really a CPU-resource-intensive task, I'll just run the code once then comment it out while storing the values to speed up the process next time we run the notebook.)","98f77b02":"As we can see here, everything worked just fine. Let us now define the 'fit' function for our model. ","66d56f35":"With the model and the dataloader moved to the GPU, we will now test the model on a batch of data to make sure everything is working fine before we actually move on to train\/test on the entire training\/testing dataset. This is like a precautionary step to make sure that we don't run into any major problem while the actual training\/testing phase.\n\nWe will feed our model with a batch of data from the training dataloader. \n\n* The dimension of the input will be- batch_size x 3 x img_width x img_height\n* The output dimension we expect is- batch_size x num_classes(6)\n\nIf everything works as expected, we will move on to the final step of our project-- training and evaluating our model.","ef48b53c":"Now that we have our dataloaders created, let us create a method to visualize the images in a batch.","a1092963":"Now, let us have a look at the summary for our model. The summary function of the torchsummary package gives us a very well defined structural summary for our model, along with the total number of trainable parameters at each layer and the complete model in total. ","75c0551d":"With this done, we have successfully defined the method that allows batches of data generated by the dataloader to the CUDA device (our Nvidia GPU).\n\nNow, let us check the default device we have available for the runtime.","a37b87c2":"Now that we have defined our model, let us create a model object and test if everything is working properly.","fe8852f9":"---\nNow that we have created the dataframe objects and CSV files for the testing and training dataset, let's create the PyTorch dataset objects that will allow us to use the image data with our PyTorch model. \n\n---","29d3008f":"As we can see, the default device is CUDA. This means our GPU is working just fine and we are ready to train\/test the model. Now, let us move our device and dataloaders onto the default device. ","f09bfbf7":"With this, we have successfully created both our training and testing datasets, and we are ready to work with them. \n\nBut before we go on to the next step, let us first test our dataset and make sure it is working properly.","25b59cdc":"The model made a correct prediction. This was a pretty easy problem from a human point of view. One can clearly see this image is showing a huge water body.","b7a63fa0":"With this, we have completed the model training. It took around 1hr 30 minutes for the entire training process, and our model can now predict the scene in an image with upto 81% accuracy, which is considerably high. Of course, the model's performance can be further improved by playing around with the hypermeters or using with a different CNN architecture.\n\nLet us now plot the model's accuracy and loss.","31648cb5":"Let us train for 5 more epochs.","d2ee3d8e":"# Deep Learning Project Walkthrough- Image Classification using CNN\n\n---\n***\n<h3>Your Complete Guide on How to Make a Complete Deep Learning Project<\/h3>\n\nDeep learning is a fancy word nowadays that you, as an aspiring Data Scientist might hear all the time. Whether it be the futuristic [Tesla Autopilot](http:\/\/www.tesla.com\/autopilot) or your iOS or Android device's smart photo gallery that automatically segments your pictures using facial recognition and object detection, deep learning is everywhere. \n\nThe sheer power that deep learning unlocks for you in terms of what you can achieve via it, that rapid advancements in the fields of AI due to deep learning; this never fails to amaze me.\n\nThe aim of this article here is to introduce you to the magic of Deep Learning. We will see how to train a Deep Learning model (that uses the CNN algorithm) capable of recognizing the scene in an image."}}