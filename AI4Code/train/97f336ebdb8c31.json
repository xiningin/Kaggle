{"cell_type":{"6251de55":"code","4cf306ee":"code","214e4f39":"code","75bd02f4":"code","08c920b0":"code","c6bd8d9a":"code","ca4bd9b3":"code","efe4b5ec":"code","aebd2c3e":"code","94b81006":"code","4d72d77b":"code","13f3f027":"code","bad726e1":"markdown","689a6118":"markdown","fc41da5b":"markdown","8433bc62":"markdown","877291b7":"markdown","34ba7505":"markdown","a91280c2":"markdown","6c9bb646":"markdown"},"source":{"6251de55":"import torch\nimport torchvision # vision operations\nimport torch.optim as optim # optimizer\nimport torch.nn.functional as F # functions\nimport numpy as np # linear algebra\nimport torch.nn as nn # Convolutionals layers and other operations \nfrom torchvision import transforms # transform image\nfrom  torchvision.datasets import MNIST # dataset\nimport matplotlib.pyplot as plt # vizualization\nimport os \nimport cv2\nfrom torchvision.utils import save_image # save image from  output\nfrom warnings import filterwarnings \nfilterwarnings(\"ignore\")","4cf306ee":"NUM_EPOCHS = 20\nLEARNING_RATE = 1e-3\nBATCH_SIZE = 16\nNOISE_FACTOR = 0.5","214e4f39":"train_loader = torch.utils.data.DataLoader(\n    MNIST(root = \".\/dataset\", train=True, download = True, \n    transform  = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\n    ),batch_size = BATCH_SIZE, shuffle = True\n)\ntest_loader = torch.utils.data.DataLoader(\n    MNIST(root = \".\/dataset\", train=False, download = True, \n    transform  = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\n    ),batch_size = BATCH_SIZE, shuffle = True\n)","75bd02f4":"i = 0\nplt.figure(figsize=(10,10))\nfor data  in train_loader:\n    images, _ = data\n    plt.subplot(3,3,i+1)\n    plt.imshow(images[i,0,:,:],cmap = plt.cm.gray)\n    plt.xticks([])\n    plt.yticks([])\n    i += 1 \n    if i == 9:\n        break\nplt.show()","08c920b0":"def get_device():\n    if torch.cuda.is_available():\n        device = 'cuda'\n    else:\n        device = 'cpu'\n    return device\n# create folder\ndef make_dir():\n    image_dir = 'Saved_Images'\n    if not os.path.exists(image_dir):\n        os.makedirs(image_dir)\n# save output and input images\ndef save_decoded_image(img, name):\n    img = img.view(img.size(0), 1, 28, 28)\n    save_image(img, name)","c6bd8d9a":"class Autoencoder(nn.Module):\n    def __init__(self):\n        super(Autoencoder, self).__init__()\n        # encoder layers\n        self.enc1 = nn.Conv2d(1, 128, kernel_size=3, padding=1)\n        self.enc2 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n        self.enc3 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n        self.enc4 = nn.Conv2d(32, 8, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        # decoder layers\n        self.dec1 = nn.ConvTranspose2d(8, 8, kernel_size=3, stride=2)  \n        self.dec2 = nn.ConvTranspose2d(8, 32, kernel_size=3, stride=2)\n        self.dec3 = nn.ConvTranspose2d(32, 64, kernel_size=2, stride=2)\n        self.dec4 = nn.ConvTranspose2d(64, 128, kernel_size=2, stride=2)\n        self.out = nn.Conv2d(128, 1, kernel_size=3, padding=1)\n    def forward(self, x):\n        # encode\n        x = F.relu(self.enc1(x))\n        x = self.pool(x)\n        x = F.relu(self.enc2(x))\n        x = self.pool(x)\n        x = F.relu(self.enc3(x))\n        x = self.pool(x)\n        x = F.relu(self.enc4(x))\n        x = self.pool(x) # the latent space representation\n        \n        # decode\n        x = F.relu(self.dec1(x))\n        x = F.relu(self.dec2(x))\n        x = F.relu(self.dec3(x))\n        x = F.relu(self.dec4(x))\n        x = F.sigmoid(self.out(x))\n        return x\nnet = Autoencoder()\nprint(net)","ca4bd9b3":"criterion = nn.MSELoss()\n# the optimizer\noptimizer = optim.Adam(net.parameters(), LEARNING_RATE)","efe4b5ec":"def train(net, trainloader, NUM_EPOCHS):\n    train_loss = []\n    for epoch in range(NUM_EPOCHS):\n        running_loss = 0.0\n        for data in trainloader:\n            img, _ = data \n            # we do not need the image labels\n            # add noise to the image data\n            img_noisy = img + NOISE_FACTOR * torch.randn(img.shape)\n            # clip to make the values fall between 0 and 1\n            img_noisy = np.clip(img_noisy, 0., 1.)\n            img_noisy = img_noisy.to(device)\n            optimizer.zero_grad()\n            outputs = net(img_noisy)\n            loss = criterion(outputs, img_noisy)\n            # backpropagation\n            loss.backward()\n            # update the parameters\n            optimizer.step()\n            running_loss += loss.item()\n        loss = running_loss \/ len(trainloader)\n        train_loss.append(loss)\n        print('Epoch {} of {}, Train Loss: {:.3f}'.format(\n            epoch+1, NUM_EPOCHS, loss))\n    return train_loss","aebd2c3e":"device = get_device()\nnet.to(device)\nmake_dir()\ntrain_loss = train(net, train_loader, NUM_EPOCHS)\nplt.figure()\nplt.plot(train_loss)\nplt.title('Train Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.savefig('.\/Saved_Images\/loss.png')\nplt.show()","94b81006":"def test(net, testloader):\n     for batch in testloader:\n        img, _ = batch\n        img_noisy = img + NOISE_FACTOR * torch.randn(img.shape)\n        img_noisy = np.clip(img_noisy, 0., 1.)\n        img_noisy = img_noisy.to(device)\n        outputs = net(img_noisy)\n        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n        save_image(img_noisy, 'noisy_test_input.png')\n        save_image(outputs, 'denoised_test.png')\n        break","4d72d77b":"test(net, test_loader)","13f3f027":"noisy_test_image = cv2.imread(\".\/noisy_test_input.png\")\ndenoised_test_image = cv2.imread(\".\/denoised_test.png\")\nplt.figure(figsize = (12,12))\nplt.subplot(1,2,1)\nplt.imshow(noisy_test_image)\nplt.title(\"noisy image\")\nplt.subplot(1,2,2)\nplt.imshow(denoised_test_image)\nplt.title(\"denoised image\")\nplt.show()","bad726e1":"# Autoencoder Model","689a6118":"# Look data","fc41da5b":"# Test","8433bc62":"# Constants","877291b7":"# Get data","34ba7505":"# Train","a91280c2":"# import necessary libraries","6c9bb646":"<p style=\"font-size:18px;font-weight:bold\">Please if you have any questions or suggestions, write comments. See you again \ud83d\udc4b<\/p>"}}