{"cell_type":{"3e19bfa2":"code","ce6082c5":"code","bb793512":"code","957dee8c":"code","8d55c707":"code","b84807b6":"code","0914efed":"code","1801ec6d":"code","c7261c97":"code","16ee380b":"code","9d22bc99":"code","69d3bd2e":"code","ca222251":"code","fab164b5":"code","3f719abe":"code","6cf7b3df":"markdown","5aab3639":"markdown","92135dd1":"markdown","0d993d8e":"markdown","1b8f70f4":"markdown","b377a911":"markdown","5f0b4a7e":"markdown","46fca1be":"markdown","f2df16a9":"markdown","61c5a982":"markdown","7f42e3da":"markdown","48afa963":"markdown","2f911c87":"markdown","92116728":"markdown","00e95bc6":"markdown","93023f77":"markdown","827c5ac3":"markdown"},"source":{"3e19bfa2":"from keras.applications import inception_v3\nfrom keras import backend as K\nimport numpy as np\nimport scipy\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing import image\nfrom IPython.display import Image\n%matplotlib inline","ce6082c5":"K.set_learning_phase(0) # disable all training of the model weights\nmodel = inception_v3.InceptionV3(weights='imagenet', include_top=False)","bb793512":"# you can run this cell to see all the names of the layers\nmodel.summary()","957dee8c":"#######################################################################################\n# UTILITY FUNCTIONS\n# mostly image manipulation\n# nothing interesting here to understant the Deep Dream algorithm\n######################################################################################\n\ndef resize_img(img, size):\n    img = np.copy(img)\n    factors = (1,\n    float(size[0]) \/ img.shape[1],\n    float(size[1]) \/ img.shape[2],\n    1)\n    return scipy.ndimage.zoom(img, factors, order=1)\n   \ndef save_img(img, fname):\n    pil_img = deprocess_image(np.copy(img))\n    scipy.misc.imsave(fname, pil_img)\n    return\n   \ndef preprocess_image(image_path):\n    img = image.load_img(image_path)\n    img = image.img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    img = inception_v3.preprocess_input(img)\n    return img\n   \ndef deprocess_image(x):\n    if K.image_data_format() == 'channels_first':\n        x = x.reshape((3, x.shape[2], x.shape[3]))\n        x = x.transpose((1, 2, 0))\n    else:\n        x = x.reshape((x.shape[1], x.shape[2], 3))\n    x \/= 2.\n    x += 0.5\n    x *= 255.\n    x = np.clip(x, 0, 255).astype('uint8')\n    return x\n   \n###################################################################################","8d55c707":"# four layer will be involve in calculation of the loss\n# each layer will have a specific weight in the loss.\nlayer_contributions = {\n    'mixed2': 0.2,\n    'mixed3': 3.,\n    'mixed4': 2.,\n    'mixed5': 1.5,\n    }","b84807b6":"# We will define the loss as a weighted sum of L2 norm of all filters in several layers\nlayer_dict = dict([(layer.name, layer) for layer in model.layers])\n\nloss = K.variable(0.) # initialize loss to 0\nfor layer_name in layer_contributions:\n    coeff = layer_contributions[layer_name]\n    activation = layer_dict[layer_name].output  # get the activations corresponding to a layer\n    scaling = K.prod(K.cast(K.shape(activation), 'float32')) # number of activation in a layer\n    # avoid border effect by selecting 2:-2 \n    loss += coeff * K.sum(K.square(activation[:,2:-2, 2:-2, :])) \/ scaling   # \"average\" the activations","0914efed":"# Gradient ascent\ndream = model.input\ngrads = K.gradients(loss, dream)[0]  # gradient of the input with regard to the loss.\ngrads \/= K.maximum(K.mean(K.abs(grads)), 1e-7) # normalize gradient (like clipping)\n\noutputs = [loss, grads]\n# keras syntax use a K.function to interact with the backend, in a computational graph.\nfetch_loss_and_grads = K.function([dream], outputs)  \n\ndef eval_loss_and_grads(x):\n    outs = fetch_loss_and_grads([x])\n    loss_value = outs[0]\n    grad_values = outs[1]\n    return loss_value, grad_values\n   \n# main function of the gradient ascent   \n# the max_loss parameter \"cap\" the value of the loss we want to reach\ndef gradient_ascent(picture, iterations, learning_rate, max_loss=None):\n    for i in range(iterations):\n        loss_value, gradient_values = eval_loss_and_grads(picture)\n        if (max_loss!=None) and (loss_value>max_loss):\n            # Stop the algorithm after a Maximum loss threshold \n            break\n        print('...Loss value at', i, ':', loss_value)\n        # gradient ascent add the gradient instead of substracting it\n        picture = picture + learning_rate*gradient_values\n    return picture","1801ec6d":"# running gradient ascent of different scales of image\ndef main(base_image_path):\n    learning_rate = 0.01\n    iterations = 20\n    max_loss = 10\n    \n    # all the part below concern the rescaling of the image\n    num_octave = 3 \n    octave_scale = 1.4\n    img = preprocess_image(base_image_path)\n    original_shape = img.shape[1:3]\n    successive_shapes = [original_shape]\n    for i in range(1, num_octave):\n        shape = tuple([int(dim \/ (octave_scale ** i)) for dim in original_shape])\n        successive_shapes.append(shape)\n    successive_shapes = successive_shapes[::-1]\n    original_img = np.copy(img)\n    shrunk_original_img = resize_img(img, successive_shapes[0]) # srunk to first scale\n\n    # we run the algorithm for each size of the image\n    for shape in successive_shapes:\n        print('Processing image shape', shape)\n        img = resize_img(img, shape)\n        # the most interesting call to the gradient ascent fucntion\n        img = gradient_ascent(img,\n                              iterations=iterations,\n                              learning_rate=learning_rate,\n                              max_loss=max_loss)\n        # below is the upsizing of the image\n        upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n        same_size_original = resize_img(original_img, shape)\n        lost_detail = same_size_original - upscaled_shrunk_original_img\n        img += lost_detail\n        shrunk_original_img = resize_img(original_img, shape)\n        save_img(img, fname='dream_at_scale.png')\n    save_img(img, fname='final_dream.png')","c7261c97":"# Run the generative model\nmain('..\/input\/rome.jpg')","16ee380b":"# Now our Dreamed Image is:\nImage(filename='final_dream.png')","9d22bc99":"##############################\n# Edit the contibuting layers\n\nlayer_contributions = {\n    'conv2d_52': 25.,\n    }","69d3bd2e":"####################################\n# RUN THIS CELL TO UPDATE THE GRAPH\n# NO NEED TO CHANGE THIS CODE\n\n\nlayer_dict = dict([(layer.name, layer) for layer in model.layers]) # map layer_name -> instance\n\nloss = K.variable(0.) # initialize loss to 0\nfor layer_name in layer_contributions:\n    coeff = layer_contributions[layer_name]\n    activation = layer_dict[layer_name].output\n    scaling = K.prod(K.cast(K.shape(activation), 'float32')) # number of activation in a layer\n    # avoid border effect by selecting 2:-2 \n    loss += coeff * K.sum(K.square(activation[:,2:-2, 2:-2, :])) \/ scaling\n    # Gradient ascent\n    \ndream = model.input\ngrads = K.gradients(loss, dream)[0]  # gradient of the input with regard to the loss.\ngrads \/= K.maximum(K.mean(K.abs(grads)), 1e-7) # normalize gradient (like clipping)\n\noutputs = [loss, grads]\nfetch_loss_and_grads = K.function([dream], outputs)\n\ndef eval_loss_and_grads(x):\n    outs = fetch_loss_and_grads([x])\n    loss_value = outs[0]\n    grad_values = outs[1]\n    return loss_value, grad_values\n   \ndef gradient_ascent(picture, iterations, learning_rate, max_loss=None):\n    for i in range(iterations):\n        loss_value, gradient_values = eval_loss_and_grads(picture)\n        if (max_loss!=None) and (loss_value>max_loss):\n            # Stop the algorithm after a Maximum loss threshold \n            break\n        print('...Loss value at', i, ':', loss_value)\n        picture = picture + learning_rate*gradient_values\n    return picture","ca222251":"############################################################\n# Edit the learning rate to speed up the modification\n# Edit the max_loss to increase the modification of the image\n\n\ndef main(base_image_path):\n    learning_rate = 0.01\n    num_octave = 3\n    octave_scale = 1.4\n    iterations = 20\n    max_loss = 100\n\n    img = preprocess_image(base_image_path)\n    original_shape = img.shape[1:3]\n    successive_shapes = [original_shape]\n    for i in range(1, num_octave):\n        shape = tuple([int(dim \/ (octave_scale ** i)) for dim in original_shape])\n        successive_shapes.append(shape)\n    successive_shapes = successive_shapes[::-1]\n    original_img = np.copy(img)\n    shrunk_original_img = resize_img(img, successive_shapes[0]) # srunk to first scale\n\n    for shape in successive_shapes:\n        print('Processing image shape', shape)\n        img = resize_img(img, shape)\n        img = gradient_ascent(img,\n                              iterations=iterations,\n                              learning_rate=learning_rate,\n                              max_loss=max_loss)\n        upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n        same_size_original = resize_img(original_img, shape)\n        lost_detail = same_size_original - upscaled_shrunk_original_img\n        img += lost_detail\n        shrunk_original_img = resize_img(original_img, shape)\n        save_img(img, fname='dream_at_scale.png')\n    save_img(img, fname='final_dream2.png')","fab164b5":"main('..\/input\/sky.JPG')","3f719abe":"# Now our Dreamed Image is:\nImage(filename='final_dream2.png')","6cf7b3df":"For the Deep Dream algorithm we are going to hack this NN to achieve our goal: Modify the input picture!\n1. First we remove the \"top\" of the network, the part of fully connected layers that compute the last activations.\n2. Then we create a new LOSS function that average the values of several activations layers.\n3. The gradients are computed with this LOSS function and regarding the input, not the parameters as it is usually the case.\n4. The input values (our picture) are updated with the <b>gradients ascent<\/b> and another iteration begins with these new input.\n\nThe intuition here is that the input picture will be modify at every iteration and input again for the next iteration.\nThe modification of the input try to increase the activations, by gradient ascent (we want to maximize the loss).\nBy maximizing the LOSS it means that we increase the activations values, if we increase the activations it means that there is a lot of patterns matching the  filters of the layers.\n\nIn other words if there is filters that recognize eyes in the layers that we selected to calculate the LOSS function, the gradient ascent will try to add eyes to the input picture to maximize the loss, hence these weird pattern appear on our input.\n\ni.e:\n\nGradient descent: w = w - lr * grad_w\n\nGradient ascent: w = w + lr * grad_w\n\n<img src=\"https:\/\/raw.githubusercontent.com\/flacout\/deep-dream-demo\/master\/image\/deep-dream-network.png\">","5aab3639":"## Define the loss function\n","92135dd1":"Deep Dream is a computer vision algorithm developed at google in 2014.\nIt modify an image with some dream-like shapes.\n\nDeepDream is a Generative model, as opposed to the classical predictive models.\nGenerative models generate \"something new\" on their own. \n\n\n<img src=\"https:\/\/raw.githubusercontent.com\/flacout\/deep-dream-demo\/master\/image\/deep-dream.jpg\" style=\"width:700px;height:400px;\">","0d993d8e":"For the sake of explaination I show below a simplification of the Neural Network architecture during training:\n\n<img src=\"https:\/\/raw.githubusercontent.com\/flacout\/deep-dream-demo\/master\/image\/neural-network.png\">","1b8f70f4":"You should observe that at each iteration the loss increase.\n\nAlthough every time the image is rescaled the process is reset again and the loss restart from zero (but the image is already modified)\n\nBelow is our input image:\n<img src=\"https:\/\/raw.githubusercontent.com\/flacout\/deep-dream-demo\/master\/dream\/rome.jpg\">","b377a911":"## Load the inception model\nWe load the inception network trained with imagenet, and without the top of fully connected layers","5f0b4a7e":"## Generate the new images\nBelow is the main function that essentialy run several iterations of gradient ascent on our input\n\nTraditionnaly the iterations are run first on a smaller version of the image then on a bigger scaling until we reach the original size of the image. This way allow apparently to conserve the most details of the image. I'm not explaining this part as this is not essential to understand Deep Dream, but you can leave a comment if you want more information.","46fca1be":"You can see that the loss take higher values now, making more dramatic changes to the input\/\n\nBelow is our input image:\n<img src=\"https:\/\/raw.githubusercontent.com\/flacout\/deep-dream-demo\/master\/dream\/sky.JPG\">","f2df16a9":"## Define our gradient ascent","61c5a982":"For our Implementation we will use an existing Neural Network, called Inception.\n\nInception was trained on imagenet, a famous dataset of picture labeled with classes. 1000 classes exist in the dataset: cat, elephant, phone, house... but it is mostly cats and dogs...\n\nBelow a picture of the architecture of the model:\n\n\n<img src=\"https:\/\/raw.githubusercontent.com\/flacout\/deep-dream-demo\/master\/image\/inception.png\" style=\"width:800px;height:350px;\">","7f42e3da":"## Acknowledgement","48afa963":"## Choose layers to compute the loss\nIt is better result to mix several layers in the algorithm\n\nYou can also modify the coefficient (weight) of each layer in the calculation of the Loss fucntion.\n\nIf you want to try it yourself the most interesting layers are the one named \"conv\" or \"mixed\"\n","2f911c87":"# Deep Dream in Practice","92116728":"# Deep Dream in Theory","00e95bc6":"Now we can start seing some animal shapes forming in the clouds.\n\nChange with your own settings to obtain different images modifications!!","93023f77":"Another important consideration is that, each layer of a NN contains fitlers, and each filter capture a shape, a texture, a color... of an image.\n\nEarly layers in a NN capture simple shapes: vertical edges, simple texture... whereas later layers in a NN capture more complex shapes: ears, faces, fish...\n\nThis is important for our algorithm as we will leverage this property to modify our images.\n\n<img src=\"https:\/\/raw.githubusercontent.com\/flacout\/deep-dream-demo\/master\/image\/layers-observation.png\">","827c5ac3":"# Changing parameters\nIf you want to play around with the algorithm here is a few advices:\n\n- Pictures of homogenous view (sky, grass land, desert) are actually easier for the neural network to modify, has there is not much patterns already in place.\n- Number of iteration, max_loss and learning rate are interesting parameters to modify to observe how they influence the loss values and consequently the output\n- The contributing layers, and their coefficients are interesting to change to observe different patterns modifications of the image.\n\nRemenber after each modification to re-run the previous cells to update the computational graph."}}