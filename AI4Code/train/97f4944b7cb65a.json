{"cell_type":{"989667a4":"code","0a7b6e24":"code","1383fa09":"code","32933711":"code","1366bb55":"code","fee6f071":"code","7020ec8b":"code","c41059f7":"code","c7084b61":"code","a7c08343":"code","ba4777e2":"code","7e19afb3":"code","13dc2dd3":"code","5a0cf27f":"code","6215b990":"code","c6d8590d":"code","2ca6497b":"code","e584fb67":"code","2c9dfee7":"code","dd3661a7":"code","56d73cf3":"code","a7f207ac":"code","e8fa4ddb":"code","7303e822":"code","dfd426de":"code","25ff5b83":"code","1ebe848f":"code","fff5c101":"code","7704f559":"code","5492cd4e":"code","2fc312e1":"code","3e8e0501":"code","6d5cccf7":"code","0d5d9065":"code","1949134b":"markdown","ae90c09d":"markdown","4b45aca5":"markdown"},"source":{"989667a4":"# Load some required libraries\nimport pandas as pd\nimport numpy as np\nimport tensorflow.compat.v1 as tf\nimport keras\nimport matplotlib.pyplot as plt\nimport math\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('fivethirtyeight')\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM, GRU, Bidirectional\nfrom keras.optimizers import SGD\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom plotly import __version__\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport cufflinks as cf\nimport plotly.offline as pyo\ncf.go_offline()\npyo.init_notebook_mode()\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nprint(__version__)\nimport os\nfor dirname, _, filenames in os.walk('kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0a7b6e24":"#Load data\ndata = pd.read_csv('\/kaggle\/input\/nyse\/prices-split-adjusted.csv', parse_dates=['date'], index_col='date')\ndata.head(3)","1383fa09":"#data['Month'] = data.index.month\n#months = {1:'January', 2:'February', 3:'March', 4:'April', 5:'May', 6:'June', 7:'July', 8:'August', 9:'September', 10:'October', 11:'November', 12:'December'}\n#data['Month'] = data['Month'].map(months)\n#data","32933711":"#Check for duplicated values\ndata.duplicated().sum()","1366bb55":"data.drop_duplicates(inplace=True)","fee6f071":"#Check for null values\ndata.isna().sum()","7020ec8b":"data.symbol.value_counts()","c41059f7":"plt.figure(figsize=(8,6))\nplt.subplot(1,1,1)\nplt.plot(data[data.symbol=='MUR'].open.values, label='open', color='cyan', linewidth=0.8)\nplt.plot(data[data.symbol=='MUR'].close.values, label='close', color='blue', linewidth=0.8)\nplt.plot(data[data.symbol=='MUR'].high.values, label='high', color='darkred', linewidth=0.8)\nplt.plot(data[data.symbol=='MUR'].low.values, label='low', color='brown', linewidth=0.8)\nplt.legend(loc='best')\nplt.xlabel('time[days]')\nplt.ylabel('Prices')\nplt.title('Stock price')\n\n\nadrian = pd.DataFrame(data[data.symbol=='MUR'].volume.values)\nadrian.iplot(kind='line', title='Volumes', yTitle='Prices', xTitle='time[days]', color='black')","c7084b61":"ad = pd.DataFrame(data[data.symbol=='MUR'].close)\nad","a7c08343":"training_set = ad[:'2016'].values\ntest_set = ad['2016':].values","ba4777e2":"training_set.shape","7e19afb3":"test_set.shape","13dc2dd3":"# Scaling the data\nscaler = MinMaxScaler()\nscaled_data = scaler.fit_transform(training_set.reshape(-1,1))\nscaled_test = scaler.transform(test_set.reshape(-1,1))","5a0cf27f":"scaled_data.shape","6215b990":"scaled_data","c6d8590d":"X_train = []\ny_train = []\nfor i in range(60,1762):\n    X_train.append(scaled_data[i-60:i,0])\n    y_train.append(scaled_data[i,0])\nX_train, y_train = np.array(X_train), np.array(y_train)","2ca6497b":"#Reshape for effecient modelling\nX_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))","e584fb67":"X_train.shape","2c9dfee7":"#LSTM architecture\nmodel = Sequential()\n# First LSTM layer with Dropout regularisation\nmodel.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1)))\nmodel.add(Dropout(0.2))\n# Second LSTM layer\nmodel.add(LSTM(units=50,return_sequences=True))\nmodel.add(Dropout(0.2))\n# Third LSTM layer\nmodel.add(LSTM(units=50, return_sequences=True))\nmodel.add(Dropout(0.2))\n# Fourth LSTM layer\nmodel.add(LSTM(units=50))\nmodel.add(Dropout(0.5))\n# The output layer\nmodel.add(Dense(units=50, kernel_initializer='uniform', activation='tanh'))\nmodel.add(Dense(units=1, kernel_initializer='uniform', activation='linear'))\n\n# Compiling the RNN\nmodel.compile(optimizer='adam',loss='mean_squared_error')\n# Fitting to the training set\nstart = time.time()\nmodel.fit(X_train,y_train,epochs=200,batch_size=35, validation_split=0.05, verbose=1)\nprint ('compilation time : ', time.time() - start)","dd3661a7":"model.summary()","56d73cf3":"dataset_total = pd.concat((ad[\"close\"][:'2016'],ad[\"close\"]['2016':]),axis=0)\ninputs = dataset_total[len(dataset_total)-len(test_set)-60 :].values\ninputs = inputs.reshape(-1,1)\ninputs  = scaler.transform(inputs)","a7f207ac":"X_test = []\ny_test = []\nfor i in range(60,312):\n    X_test.append(inputs[i-60:i,0])\n    y_test.append(inputs[i,0])\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\npredicted_stock_price = model.predict(X_test)\n# Inverse transform is to denormalize the predicted_stock_price\npredicted_stock_price = scaler.inverse_transform(predicted_stock_price)\npredicted_stock_price, test_set\n","e8fa4ddb":"predicted_stock_price.shape","7303e822":"plt.figure(figsize=(8,6))\nplt.subplot(1,1,1)\nplt.plot(predicted_stock_price, linewidth=1.2, color='green', label='Predicted [MUR] Stock price')\nplt.plot(test_set, linewidth=1.2, color='darkred', label='Real [MUR] Stock price')\nplt.xlabel('Time', fontsize=8)\nplt.ylabel('IBM Stock Price', fontsize=8)\nplt.legend(loc='best', fontsize=10)\nplt.show()\n","dfd426de":"predicted_stock_price.shape","25ff5b83":"rmse = math.sqrt(mean_squared_error(test_set, predicted_stock_price))\nrmse","1ebe848f":"# R2_score for the LSTM\nr2_score(test_set, predicted_stock_price)","fff5c101":"GRU_model = Sequential()\n# First GRU layer with Dropout regularisation\nGRU_model.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\nGRU_model.add(Dropout(0.2))\n# Second GRU layer\nGRU_model.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\nGRU_model.add(Dropout(0.2))\n# Third GRU layer\nGRU_model.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\nGRU_model.add(Dropout(0.2))\n# Fourth GRU layer\nGRU_model.add(GRU(units=50, activation='tanh'))\nGRU_model.add(Dropout(0.5))\n# The output layer\n#GRU_model.add(Dense(units=50, kernel_initializer='uniform', activation='tanh'))\nGRU_model.add(Dense(units=1, kernel_initializer='uniform', activation='linear'))\n# Compiling the RNN\nGRU_model.compile(optimizer=SGD(learning_rate=0.01, decay=1e-7, momentum=0.9, nesterov=True),loss='mean_squared_error')\n# Fitting to the training set\nstart = time.time()\nGRU_model.fit(X_train,y_train,epochs=200,batch_size=35, validation_split=0.05, verbose=1)\nprint ('compilation time : ', time.time() - start)","7704f559":"GRU_model.summary()","5492cd4e":"X_test = []\nfor i in range(60,312):\n    X_test.append(inputs[i-60:i,0])\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\nGRU_predicted_stock_price = GRU_model.predict(X_test)\n# Denormalizing the predicted_stock_price\nGRU_predicted_stock_price = scaler.inverse_transform(GRU_predicted_stock_price)","2fc312e1":"GRU_predicted_stock_price.shape","3e8e0501":"plt.figure(figsize=(8,6))\nplt.subplot(1,1,1)\nplt.plot(GRU_predicted_stock_price, linewidth=1.2, color='green', label='Predicted [MUR] Stock price')\nplt.plot(test_set, linewidth=1.2, color='black', label='Real [MUR] Stock price')\nplt.xlabel('Time', fontsize=8)\nplt.ylabel(' stock Price', fontsize=8)\nplt.legend(loc='best', fontsize=10)\nplt.show()","6d5cccf7":"Rmse = math.sqrt(mean_squared_error(test_set, GRU_predicted_stock_price))\nRmse","0d5d9065":"# R2_score for the GRU\nr2_score(test_set, GRU_predicted_stock_price)","1949134b":"# New York Stock Exchange","ae90c09d":"Extracting prices for \"MUR\" symbol in the dataset","4b45aca5":"Now that there are no null values and duplicated values in the data, this simplifies our work"}}