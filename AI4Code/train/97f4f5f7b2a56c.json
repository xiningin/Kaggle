{"cell_type":{"2e697f17":"code","0a2d560a":"code","3ff2193c":"code","29884226":"code","7fb390db":"code","5ee4374f":"code","c7f6c0c8":"code","a70b2c63":"code","3ce5062c":"code","6a77ebce":"code","6b72cece":"code","c4431a6c":"code","a1433c0d":"code","3e01a96a":"code","d8747aac":"code","da28b362":"code","81c58055":"code","1ffef2b0":"code","64a3a0d9":"code","813604ac":"code","8f7e98c7":"code","3ae25b13":"code","207ee69f":"code","52c40a48":"code","f2b079e0":"code","a87a164b":"code","c4478804":"code","74402e45":"code","f3921963":"code","ca47df97":"code","6a61b5cb":"code","d7fb7cda":"code","96b80118":"code","8f2d0ecb":"code","831ecb79":"code","8de9c40e":"code","82b35fa1":"code","23ac1076":"code","d148bb90":"code","72148b8b":"code","83bb5b88":"code","aed56b01":"code","39e5e178":"code","e7358177":"code","bc091783":"code","2d8e49c7":"code","55b001e7":"code","d7b1404b":"code","92187cfb":"code","14837fb3":"code","493c05e0":"code","bcc873c2":"code","4a08e158":"code","ca4a338f":"code","2706e6c7":"code","618dd741":"code","6f9dd6cc":"markdown","8d854923":"markdown","d4779c29":"markdown","da480fad":"markdown","50de0a29":"markdown","170f04db":"markdown","cb50e344":"markdown"},"source":{"2e697f17":"import pandas as pd\nimport numpy as np\nimport seaborn as sns","0a2d560a":"trainData=pd.read_csv(\"..\/input\/restaurant-revenue-prediction\/train.csv.zip\")","3ff2193c":"df=pd.read_csv(\"..\/input\/restaurant-revenue-prediction\/test.csv.zip\")","29884226":"column_names = [\"id\",\"Prediction\"]\nsample=pd.DataFrame(columns=column_names)\nsample[\"id\"]=df[\"Id\"]","7fb390db":"trainData","5ee4374f":"trainData['Open Date'] = pd.to_datetime(trainData['Open Date'], format='%m\/%d\/%Y')\ndf['Open Date'] = pd.to_datetime(df['Open Date'], format='%m\/%d\/%Y')","c7f6c0c8":"trainData['OpenDays']=\"\"\ndf['OpenDays']=\"\"","a70b2c63":"dateLastTrain = pd.DataFrame({'Date':np.repeat(['01\/01\/2015'],[len(trainData)]) })\ndateLastTest = pd.DataFrame({'Date':np.repeat(['01\/01\/2015'],[len(df)]) })","3ce5062c":"dateLastTrain['Date'] = pd.to_datetime(dateLastTrain['Date'], format='%m\/%d\/%Y') \ndateLastTest['Date'] = pd.to_datetime(dateLastTest['Date'], format='%m\/%d\/%Y') ","6a77ebce":"df.head()","6b72cece":"trainData['OpenDays'] = dateLastTrain['Date'] - trainData['Open Date']\ndf['OpenDays'] = dateLastTest['Date'] - df['Open Date']","c4431a6c":"trainData['OpenDays'] = trainData['OpenDays'].astype('timedelta64[D]').astype(int)\ndf['OpenDays'] = df['OpenDays'].astype('timedelta64[D]').astype(int)","a1433c0d":"cityPerc = trainData[[\"City Group\", \"revenue\"]].groupby(['City Group'],as_index=False).mean()","3e01a96a":"sns.barplot(x='City Group', y='revenue', data=cityPerc)","d8747aac":"citygroupDummy = pd.get_dummies(trainData['City Group'])\ncitygroupD = pd.get_dummies(df['City Group'])\ncitygroupDummy","da28b362":"trainData = trainData.join(citygroupDummy)\ndf = df.join(citygroupD)","81c58055":"trainData = trainData.drop('City Group', axis=1)\ndf = df.drop('City Group', axis=1)","1ffef2b0":"trainData = trainData.drop('Open Date', axis=1)\ndf = df.drop('Open Date', axis=1)","64a3a0d9":"trainData[[\"City\",\"revenue\"]].groupby([\"City\"]).mean().plot(kind=\"bar\")","813604ac":"mean_revenue_per_city = trainData[['City', 'revenue']].groupby('City', as_index=False).mean()\nmean_revenue_per_city['revenue'] = mean_revenue_per_city['revenue'].apply(lambda x: int(x\/1e6)) ","8f7e98c7":"mean_revenue_per_city","3ae25b13":"mean_dict = dict(zip(mean_revenue_per_city.City, mean_revenue_per_city.revenue))","207ee69f":"mean_dict","52c40a48":"trainData.replace({\"City\":mean_dict}, inplace=True)","f2b079e0":"trainData.City.unique()","a87a164b":"trainData.City.mean()","c4478804":"df.City.unique()","74402e45":"df.replace({\"City\":mean_dict}, inplace=True)","f3921963":"#adding 4 as it was the mean in traindata column","ca47df97":"df['City'] = df['City'].apply(lambda x: 4 if isinstance(x,str) else x)","6a61b5cb":"trainData.Type.unique()","d7fb7cda":"from sklearn.preprocessing import LabelEncoder","96b80118":"lr = LabelEncoder()\nlr2=LabelEncoder()","8f2d0ecb":"trainData[\"Type\"]=lr.fit_transform(trainData[\"Type\"])\ndf[\"Type\"]=lr2.fit_transform(df[\"Type\"])","831ecb79":"X = trainData.drop(['revenue', 'Id'],axis=1)","8de9c40e":"X","82b35fa1":"df = df.drop(['Id'],axis=1)","23ac1076":"Y=trainData[\"revenue\"]","d148bb90":"from sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import KFold\n\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor","72148b8b":"from math import sqrt","83bb5b88":"cv = KFold(n_splits=10, shuffle=True, random_state=108)\nmodel = LGBMRegressor(n_estimators=200, learning_rate=0.01, subsample=0.7, colsample_bytree=0.8)\n\nscores = []\nfor train_idx, test_idx in cv.split(X):\n    X_train = X.iloc[train_idx]\n    X_val = X.iloc[test_idx]\n    y_train = Y.iloc[train_idx]\n    y_val = Y.iloc[test_idx]\n    \n    model.fit(X_train,y_train)\n    preds = model.predict(X_val)\n    \n    rmse = sqrt(mean_squared_error(y_val, preds))\n    print(rmse)\n    scores.append(rmse)\n\nprint(\"\\nMean score %d\"%np.mean(scores))","aed56b01":"predictions = model.predict(df)\npredictions","39e5e178":"sns.distplot(predictions, bins=20)","e7358177":"import eli5\nfrom eli5.sklearn import PermutationImportance","bc091783":"X = trainData.drop(['revenue', 'Id'],axis=1)\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=1)\n\nfrom xgboost import XGBRegressor\nxgb=XGBRegressor()\nxgb.fit(X_train,Y_train)","2d8e49c7":"perm = PermutationImportance(xgb, random_state=1).fit(X_train,Y_train)\neli5.show_weights(perm, feature_names = X_train.columns.to_list())","55b001e7":"trainData['P29_to_City_mean'] = trainData.groupby('City')['P29'].transform('mean')\ntrainData['P17_to_City_mean'] = trainData.groupby('City')['P17'].transform('mean')\ntrainData['P28_to_City_mean'] = trainData.groupby('City')['P28'].transform('mean')\ntrainData['P1_to_City_mean'] = trainData.groupby('City')['P1'].transform('mean')\ntrainData['P27_to_City_mean'] = trainData.groupby('City')['P27'].transform('mean')\ntrainData['P20_to_City_mean'] = trainData.groupby('City')['P20'].transform('mean')","d7b1404b":"df['P29_to_City_mean'] = df.groupby('City')['P29'].transform('mean')\ndf['P17_to_City_mean'] = df.groupby('City')['P17'].transform('mean')\ndf['P28_to_City_mean'] = df.groupby('City')['P28'].transform('mean')\ndf['P1_to_City_mean'] = df.groupby('City')['P1'].transform('mean')\ndf['P27_to_City_mean'] = df.groupby('City')['P27'].transform('mean')\ndf['P20_to_City_mean'] = df.groupby('City')['P20'].transform('mean')","92187cfb":"X = trainData.drop(['revenue', 'Id'],axis=1)","14837fb3":"X","493c05e0":"cv = KFold(n_splits=10, shuffle=True, random_state=108)\nmodel = LGBMRegressor(n_estimators=200, learning_rate=0.01, subsample=0.7, colsample_bytree=0.8)\n\nscores = []\nfor train_idx, test_idx in cv.split(X):\n    X_train = X.iloc[train_idx]\n    X_val = X.iloc[test_idx]\n    y_train = Y.iloc[train_idx]\n    y_val = Y.iloc[test_idx]\n    \n    model.fit(X_train,y_train)\n    preds = model.predict(X_val)\n    \n    rmse = sqrt(mean_squared_error(y_val, preds))\n    print(rmse)\n    scores.append(rmse)\n\nprint(\"\\nMean score %d\"%np.mean(scores))","bcc873c2":"predictions = model.predict(df)\nsample['Prediction'] = predictions","4a08e158":"sample","ca4a338f":"sample['Prediction']=sample['Prediction'].apply(lambda x: round((float(x\/1e6)*1000000),1))","2706e6c7":"sample['Prediction']","618dd741":"sample.to_csv('submission.csv', index=False)","6f9dd6cc":"#now looking the Type Column ","8d854923":"#Applying model once again so that we can get our new Model with more accuracy","d4779c29":"#we have to label encode the city column but we can't do directly\n#so we create a new column of city mean revenue\n","da480fad":"# first modifying The OpenDate column ","50de0a29":"#checking the weightage of all the column","170f04db":"# now looking at the City group column","cb50e344":"#adding new columns accordingly"}}