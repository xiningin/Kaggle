{"cell_type":{"3ced1add":"code","266987b2":"code","d13208c6":"code","3efe7329":"code","4b715e6a":"code","277eb2bd":"code","8c869c81":"code","36c8051f":"code","6370b1c0":"code","acb7b510":"code","ce4cb2f0":"code","6c832d4f":"code","5daa726d":"code","9a1d666d":"code","29495805":"code","2ef60aa8":"code","10299602":"code","33f9112b":"code","7c9c6a92":"code","1b7dd50d":"code","5a3c5ed5":"code","6acd90b0":"code","2481e29a":"code","03988829":"markdown","283a678e":"markdown","dd3c657b":"markdown","86d4e3da":"markdown","120b1b3d":"markdown","a051a18e":"markdown","254e9473":"markdown","1d9393d0":"markdown","e0b885f6":"markdown","498230ac":"markdown","ae729c3c":"markdown","e90bb6b5":"markdown","1d037d93":"markdown","0f180c0a":"markdown","88b9f38f":"markdown","fc356819":"markdown","76ee8d5f":"markdown","57f3c303":"markdown","6670c439":"markdown","12f94222":"markdown","e1308892":"markdown","de7a2872":"markdown","b17144d4":"markdown"},"source":{"3ced1add":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn import linear_model\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.linear_model import RidgeCV\n\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","266987b2":"l = pd.read_csv('..\/input\/seattle\/listings.csv')","d13208c6":"l['neighbourhood_group_cleansed'].value_counts()","3efe7329":"fontsize = 10\n\ndf_temp = l[['neighbourhood_group_cleansed', 'review_scores_rating']]\ndf_temp['n'] = np.where(\n    df_temp['neighbourhood_group_cleansed'] == 'University District', \n    'University District', 'Other neighbourhoods'\n)\n\nfig, axes = plt.subplots(figsize=(14, 8))\nsns.violinplot('n','review_scores_rating', data=df_temp, ax = axes)\naxes.set_title('Review scores by neighbourhood group')\n\naxes.yaxis.grid(True)\naxes.set_xlabel('Neighbourhood group')\naxes.set_ylabel('Review score')\n\nplt.show()","4b715e6a":"fontsize = 10\n\ndf_temp = l[['neighbourhood_group_cleansed', 'reviews_per_month']]\ndf_temp['n'] = np.where(\n    df_temp['neighbourhood_group_cleansed'] == 'University District', \n    'University District', 'Other neighbourhoods'\n)\n\nfig, axes = plt.subplots(figsize=(14, 8))\nsns.violinplot('n','reviews_per_month', data=df_temp, ax = axes)\naxes.set_title('Reviews per month by neighbourhood group')\n\naxes.yaxis.grid(True)\naxes.set_xlabel('Neighbourhood group')\naxes.set_ylabel('Reviews per month')\n\nplt.show()","277eb2bd":"fontsize = 10\n\ndf_temp = l[['neighbourhood_group_cleansed', 'review_scores_rating', 'reviews_per_month']].copy()\ndf_temp['cx_score'] = df_temp['review_scores_rating'] \/ 100 * df_temp['reviews_per_month']\ndf_temp['n'] = np.where(\n    df_temp['neighbourhood_group_cleansed'] == 'University District', \n    'University District', 'Other neighbourhoods'\n)\n\nfig, axes = plt.subplots(figsize=(14, 8))\nsns.violinplot('n','cx_score', data=df_temp, ax = axes)\naxes.set_title('CX score by neighbourhood group')\n\naxes.yaxis.grid(True)\naxes.set_xlabel('Neighbourhood group')\naxes.set_ylabel('CX score')\n\nplt.show()","8c869c81":"df = l.copy()\ndf = df.loc[df['neighbourhood_group_cleansed'] == 'University District']","36c8051f":"def convert_host_since(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['days_as_host'] = (pd.to_datetime(df['last_scraped']) - pd.to_datetime(df['host_since'])) \/ np.timedelta64(1, 'D')\n    \n    df = df.drop(['last_scraped', 'host_since'], axis=1)\n    \n    return df\n\ndef convert_host_location(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n\n    df['host_in_seattle'] = df['host_location'].str.contains('Seattle')\n    \n    df = df.drop(['host_location'], axis=1)\n    \n    return df\n\ndef convert_host_about(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['has_host_about'] = ~df['host_about'].isnull()\n    \n    df = df.drop(['host_about'], axis=1)\n    \n    return df\n\ndef convert_host_response_time(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['host_response_time'] = np.where(\n        df['host_response_time'].eq('within an hour'), 1,\n        np.where(\n            df['host_response_time'].eq('within a few hours'), 2,\n            np.where(\n                df['host_response_time'].eq('within a day'), 3, 4\n            )\n        )\n    )\n    \n    return df\n\ndef convert_host_response_rate(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['host_response_rate'] = df['host_response_rate'].str.replace(r'%', r'.0').astype('float') \/ 100.0\n    \n    return df\n\ndef convert_host_neighbourhood(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['host_in_neighbourhood'] = np.where(\n        df['host_neighbourhood'] == df['neighbourhood'], True, \n        np.where(\n            df['host_neighbourhood'] == df['neighbourhood_cleansed'], True,\n            np.where(\n                df['host_neighbourhood'] == df['neighbourhood_group_cleansed'], True, False\n            )\n        )\n    )\n    \n    df = df.drop(['host_neighbourhood', 'neighbourhood', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed'], axis=1)\n    \n    return df\n\ndef convert_host_verifications(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['host_verif_email'] = df['host_verifications'].str.contains('email')\n    df['host_verif_kba'] = df['host_verifications'].str.contains('kba')\n    df['host_verif_phone'] = df['host_verifications'].str.contains('phone')\n    df['host_verif_reviews'] = df['host_verifications'].str.contains('reviews')\n    df['host_verif_jumio'] = df['host_verifications'].str.contains('jumio')\n    df['host_verif_facebook'] = df['host_verifications'].str.contains('facebook')\n    df['host_verif_linkedin'] = df['host_verifications'].str.contains('linkedin')\n    df['host_verif_google'] = df['host_verifications'].str.contains('google')\n    df['host_verif_manual_online'] = df['host_verifications'].str.contains('manual_online')\n    df['host_verif_manual_offline'] = df['host_verifications'].str.contains('manual_offline')\n    df['host_verif_sent_id'] = df['host_verifications'].str.contains('sent_id')\n    df['host_verif_amex'] = df['host_verifications'].str.contains('amex')\n    df['host_verif_weibo'] = df['host_verifications'].str.contains('weibo')\n    df['host_verif_photographer'] = df['host_verifications'].str.contains('photographer')\n    \n    df = df.drop(['host_verifications'], axis=1)\n    \n    return df\n\ndef convert_host_has_profile_pic(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['host_has_profile_pic'] = np.where(df['host_has_profile_pic'] == 't', True, False)\n    \n    return df\n\ndef convert_host_identity_verified(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['host_identity_verified'] = np.where(df['host_identity_verified'] == 't', True, False)\n    \n    return df\n\ndef convert_bed_type(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['real_bed'] = np.where(\n        df['bed_type'] == 'Real Bed', True, False\n    )\n    \n    df = df.drop(['bed_type'], axis=1)\n    \n    return df\n\ndef convert_amenities(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['amenities_tv'] = df['amenities'].str.contains('TV')\n    df['amenities_internet'] = df['amenities'].str.contains('Internet')\n    df['amenities_wireless_internet'] = df['amenities'].str.contains('Wireless Internet')\n    df['amenities_cable_tv'] = df['amenities'].str.contains('Cable TV')\n    df['amenities_kitchen'] = df['amenities'].str.contains('Kitchen')\n    df['amenities_elevator_in_building'] = df['amenities'].str.contains('Elevator in Building')\n    df['amenities_wheelchair_accessible'] = df['amenities'].str.contains('Wheelchair Accessible')\n    df['amenities_smoke_detector'] = df['amenities'].str.contains('Smoke Detector')\n    df['amenities_pool'] = df['amenities'].str.contains('Pool')\n    df['amenities_free_parking_on_premises'] = df['amenities'].str.contains('Free Parking on Premises')\n    df['amenities_air_conditioning'] = df['amenities'].str.contains('Air Conditioning')\n    df['amenities_heating'] = df['amenities'].str.contains('Heating')\n    df['amenities_pets_live_on_this_property'] = df['amenities'].str.contains('Pets live on this property')\n    df['amenities_washer'] = df['amenities'].str.contains('Washer')\n    df['amenities_breakfast'] = df['amenities'].str.contains('Breakfast')\n    df['amenities_buzzer_wireless_intercom'] = df['amenities'].str.contains('Buzzer\/Wireless Intercom')\n    df['amenities_pets_allowed'] = df['amenities'].str.contains('Pets Allowed')\n    df['amenities_carbon_monoxide_detector'] = df['amenities'].str.contains('Carbon Monoxide Detector')\n    df['amenities_gym'] = df['amenities'].str.contains('Gym')\n    df['amenities_dryer'] = df['amenities'].str.contains('Dryer')\n    df['amenities_indoor_fireplace'] = df['amenities'].str.contains('Indoor Fireplace')\n    df['amenities_family_kid_friendly'] = df['amenities'].str.contains('Family\/Kid Friendly')\n    df['amenities_dogs'] = df['amenities'].str.contains('Dog(s)')\n    df['amenities_essentials'] = df['amenities'].str.contains('Essentials')\n    df['amenities_cats'] = df['amenities'].str.contains('Cat(s)')\n    df['amenities_hot_tub'] = df['amenities'].str.contains('Hot Tub')\n    df['amenities_shampoo'] = df['amenities'].str.contains('Shampoo')\n    df['amenities_first_aid_kit'] = df['amenities'].str.contains('First Aid Kit')\n    df['amenities_smoking_allowed'] = df['amenities'].str.contains('Smoking Allowed')\n    df['amenities_fire_extinguisher'] = df['amenities'].str.contains('Fire Extinguisher')\n    df['amenities_doorman'] = df['amenities'].str.contains('Doorman')\n    df['amenities_washer_dryer'] = df['amenities'].str.contains('Washer \/ Dryer')\n    df['amenities_safety_card'] = df['amenities'].str.contains('Safety Card')\n    df['amenities_suitable_for_events'] = df['amenities'].str.contains('Suitable for Events')\n    df['amenities_other_pets'] = df['amenities'].str.contains('Other pet(s)')\n    df['amenities_24_hour_check_in'] = df['amenities'].str.contains('24-Hour Check-in')\n    df['amenities_hangers'] = df['amenities'].str.contains('Hangers')\n    df['amenities_laptop_friendly_workspace'] = df['amenities'].str.contains('Laptop Friendly Workspace')\n    df['amenities_iron'] = df['amenities'].str.contains('Iron')\n    df['amenities_hair_dryer'] = df['amenities'].str.contains('Hair Dryer')\n    df['amenities_lock_on_bedroom_door'] = df['amenities'].str.contains('Lock on Bedroom Door')\n    \n    df = df.drop(['amenities'], axis=1)\n    \n    return df\n\ndef convert_weekly_price(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['weekly_price_ratio'] = df['weekly_price'].replace('[\\$,]', '', regex=True).astype(float) \/ \\\n        df['price'].replace('[\\$,]', '', regex=True).astype(float)\n        \n    df['has_weekly_price'] = ~df['weekly_price'].isnull()\n    \n    df['weekly_price'] = df['weekly_price'].replace('[\\$,]', '', regex=True).astype(float)\n    \n    return df\n\ndef convert_monthly_price(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['monthly_price_ratio'] = df['monthly_price'].replace('[\\$,]', '', regex=True).astype(float) \/ \\\n        df['price'].replace('[\\$,]', '', regex=True).astype(float)\n        \n    df['has_monthly_price'] = ~df['monthly_price'].isnull()\n    \n    df['monthly_price'] = df['monthly_price'].replace('[\\$,]', '', regex=True).astype(float)\n    \n    return df\n\ndef convert_security_deposit(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['security_deposit_ratio'] = df['security_deposit'].replace('[\\$,]', '', regex=True).astype(float) \/ \\\n        df['price'].replace('[\\$,]', '', regex=True).astype(float)\n        \n    df['has_security_deposit'] = ~df['security_deposit'].isnull()\n    \n    df['security_deposit'] = df['security_deposit'].replace('[\\$,]', '', regex=True).astype(float)\n    \n    return df\n\ndef convert_cleaning_fee(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['cleaning_fee_ratio'] = df['cleaning_fee'].replace('[\\$,]', '', regex=True).astype(float) \/ \\\n        df['price'].replace('[\\$,]', '', regex=True).astype(float)\n        \n    df['has_cleaning_fee'] = ~df['cleaning_fee'].isnull()\n    \n    df['cleaning_fee'] = df['cleaning_fee'].replace('[\\$,]', '', regex=True).astype(float)\n    \n    return df\n\ndef convert_extra_people(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['extra_people_ratio'] = df['extra_people'].replace('[\\$,]', '', regex=True).astype(float) \/ \\\n        df['price'].replace('[\\$,]', '', regex=True).astype(float)\n    \n    df['extra_people'] = df['extra_people'].replace('[\\$,]', '', regex=True).astype(float)\n    \n    return df\n\ndef convert_instant_bookable(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['instant_bookable'] = np.where(df['instant_bookable'] == 't', True, False)\n    \n    return df\n\ndef convert_cancellation_policy(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    new_data = pd.get_dummies(df[['cancellation_policy']])\n    df[new_data.columns] = new_data\n    \n    df = df.drop(['cancellation_policy'], axis=1)\n    \n    return df, new_data.columns\n\ndef convert_require_guest_profile_picture(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['require_guest_profile_picture'] = np.where(df['require_guest_profile_picture'] == 't', True, False)\n    \n    return df\n\ndef convert_require_guest_phone_verification(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['require_guest_phone_verification'] = np.where(df['require_guest_phone_verification'] == 't', True, False)\n    \n    return df\n\ndef convert_price(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['price'] = df['price'].replace('[\\$,]', '', regex=True).astype(float)\n    \n    return df\n\ndef convert_host_is_superhost(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['host_is_superhost'] = np.where(df['host_is_superhost'] == 't', True, False)\n    \n    return df\n\ndef convert_is_location_exact(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['is_location_exact'] = np.where(df['is_location_exact'] == 't', True, False)\n    \n    return df\n\ndef convert_neighbourhood_cleansed(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    new_data = pd.get_dummies(df[['neighbourhood_cleansed']])\n    df[new_data.columns] = new_data\n    \n    return df, new_data.columns\n\ndef convert_neighbourhood_group_cleansed(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    new_data = pd.get_dummies(df[['neighbourhood_group_cleansed']])\n    df[new_data.columns] = new_data\n    \n    return df, new_data.columns\n\ndef convert_property_type(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['property_type'] = np.where(\n        df['property_type'] == 'House', 'House',\n        np.where(\n            df['property_type'] == 'Apartment', 'Apartment',\n            np.where(\n                df['property_type'] == 'Townhouse', 'Townhouse',\n                'Other'\n            )\n        )\n    )\n    \n    new_data = pd.get_dummies(df[['property_type']])\n    df[new_data.columns] = new_data\n    \n    df = df.drop(['property_type'], axis=1)\n    \n    return df, new_data.columns\n\ndef convert_minimum_nights(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['has_minimum_nights'] = np.where(df['minimum_nights'] > 0, True, False)\n    \n    return df\n\ndef convert_maximum_nights(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the modified dataset containing the transformed features\n    \"\"\"\n    \n    df['has_maximum_nights'] = np.where(df['maximum_nights'] > 0, True, False)\n    \n    return df","6370b1c0":"def convert_df(df):\n    \"\"\"\n    Input: df - a dataset containing the unprocessed column's data\n    Output: df - the fully pre-processed dataset\n    \"\"\"\n    \n    # dummies\n    df, cols_neighbourhood_cleansed = convert_neighbourhood_cleansed(df)\n    df, cols_neighbourhood_group_cleansed = convert_neighbourhood_group_cleansed(df)\n    df, cols_property_type = convert_property_type(df)\n    df, cols_cancellation_policy = convert_cancellation_policy(df)\n    \n    cols_dummies = []\n    cols_dummies.extend(cols_neighbourhood_cleansed)\n    cols_dummies.extend(cols_neighbourhood_group_cleansed)\n    cols_dummies.extend(cols_property_type)\n    cols_dummies.extend(cols_cancellation_policy)\n    \n    # map columns to new variables\n    df = convert_host_since(df)\n    df = convert_host_location(df)\n    df = convert_host_about(df)\n    df = convert_host_response_time(df)\n    df = convert_host_response_rate(df)\n    df = convert_host_neighbourhood(df)\n    df = convert_host_verifications(df)\n    df = convert_host_has_profile_pic(df)\n    df = convert_host_identity_verified(df)\n    df = convert_bed_type(df)\n    df = convert_amenities(df)\n    df = convert_weekly_price(df)\n    df = convert_monthly_price(df)\n    df = convert_security_deposit(df)\n    df = convert_cleaning_fee(df)\n    df = convert_extra_people(df)\n    df = convert_instant_bookable(df)\n    df = convert_require_guest_profile_picture(df)\n    df = convert_require_guest_phone_verification(df)\n    df = convert_price(df)\n    df = convert_host_is_superhost(df)\n    df = convert_is_location_exact(df)\n    df = convert_minimum_nights(df)\n    df = convert_maximum_nights(df)\n    \n    # fill NaN values with reasonable values\n    df['days_as_host'] = df['days_as_host'].fillna(df['days_as_host'].median())\n    df['host_in_seattle'] = df['host_in_seattle'].fillna(df['host_in_seattle'].median())\n    df['host_response_rate'] = df['host_response_rate'].fillna(1.0)\n    df['weekly_price'] = df['weekly_price'].fillna(0.0)\n    df['monthly_price'] = df['monthly_price'].fillna(0.0)\n    df['security_deposit'] = df['security_deposit'].fillna(0.0)\n    df['cleaning_fee'] = df['cleaning_fee'].fillna(0.0)\n    df['extra_people'] = df['extra_people'].fillna(0.0)\n    df['weekly_price_ratio'] = df['weekly_price_ratio'].fillna(0.0)\n    df['monthly_price_ratio'] = df['monthly_price_ratio'].fillna(0.0)\n    df['security_deposit_ratio'] = df['security_deposit_ratio'].fillna(0.0)\n    df['cleaning_fee_ratio'] = df['cleaning_fee_ratio'].fillna(0.0)\n    \n    df['accommodates'] = df['accommodates'].fillna(df['accommodates'].median())\n    df['bathrooms'] = df['bathrooms'].fillna(0)\n    df['bedrooms'] = df['bedrooms'].fillna(0)\n    df['beds'] = df['beds'].fillna(0)\n    \n    cols = ['review_scores_rating', 'number_of_reviews', 'reviews_per_month',\n          'host_id', 'days_as_host', 'host_in_seattle', 'has_host_about', 'host_response_time',\n          'host_response_rate', 'host_in_neighbourhood', 'host_verif_email', 'host_verif_kba',\n          'host_verif_phone', 'host_verif_reviews', 'host_verif_jumio', 'host_verif_facebook',\n          'host_verif_linkedin', 'host_verif_google', 'host_verif_manual_online',\n          'host_verif_manual_offline', 'host_verif_sent_id', 'host_verif_amex',\n          'host_verif_weibo', 'host_verif_photographer', 'host_has_profile_pic',\n          'host_identity_verified', 'real_bed', 'amenities_tv', 'amenities_internet',\n          'amenities_wireless_internet', 'amenities_cable_tv', 'amenities_kitchen',\n          'amenities_elevator_in_building', 'amenities_wheelchair_accessible',\n          'amenities_smoke_detector', 'amenities_pool', 'amenities_free_parking_on_premises',\n          'amenities_air_conditioning', 'amenities_heating', 'amenities_pets_live_on_this_property',\n          'amenities_washer', 'amenities_breakfast', 'amenities_buzzer_wireless_intercom',\n          'amenities_pets_allowed', 'amenities_carbon_monoxide_detector', 'amenities_gym',\n          'amenities_dryer', 'amenities_indoor_fireplace', 'amenities_family_kid_friendly',\n          'amenities_dogs', 'amenities_essentials', 'amenities_cats', 'amenities_hot_tub',\n          'amenities_shampoo', 'amenities_first_aid_kit', 'amenities_smoking_allowed',\n          'amenities_fire_extinguisher', 'amenities_doorman', 'amenities_washer_dryer',\n          'amenities_safety_card', 'amenities_suitable_for_events', 'amenities_other_pets',\n          'amenities_24_hour_check_in', 'amenities_hangers', 'amenities_laptop_friendly_workspace',\n          'amenities_iron', 'amenities_hair_dryer', 'amenities_lock_on_bedroom_door',\n          'weekly_price_ratio', 'has_weekly_price', 'monthly_price_ratio', 'has_monthly_price',\n          'security_deposit_ratio', 'has_security_deposit', 'cleaning_fee_ratio',\n          'has_cleaning_fee', 'extra_people_ratio', 'instant_bookable',\n          'require_guest_profile_picture', 'require_guest_phone_verification',\n          'minimum_nights', 'maximum_nights', 'price', 'host_is_superhost', 'is_location_exact',\n          'accommodates', 'bathrooms', 'bedrooms', 'beds',\n           'weekly_price', 'monthly_price', 'security_deposit', 'cleaning_fee', 'extra_people',\n           'has_minimum_nights', 'has_maximum_nights']\n    \n    cols.extend(cols_dummies)\n                        \n    # Select only columns needed for analysis\n    df = df.loc[:, cols]\n    \n    # Remove rows with null values for response variable\n    df = df.dropna(subset=['review_scores_rating'])\n    \n    # Convert the review scores to a decimal\n    df['review_scores_rating'] = df['review_scores_rating'] \/ 100\n    \n    # The given calculation for the customer experience score\n    df['cx_score'] = df['review_scores_rating'] * df['reviews_per_month']\n    \n    return df, cols_dummies","acb7b510":"df, cols_dummies = convert_df(df)","ce4cb2f0":"df['cx_score'].hist()","6c832d4f":"df3 = df.copy()\ntry:\n    df3 = df3.drop(['reviews_per_month'], axis=1)\nexcept:\n    pass\ntry:\n    df3 = df3.drop(['number_of_reviews'], axis=1)\nexcept:\n    pass\ntry:\n    df3 = df3.drop(['review_scores_rating'], axis=1)\nexcept:\n    pass\ntry:\n    df3 = df3.drop(['host_id'], axis=1)\nexcept:\n    pass","5daa726d":"corr = df3.corr()\ncorr_y = corr['cx_score']\nfontsize = 10\nplt.figure(figsize=(15,10))\ncorr_y[np.abs(corr_y) > 0.4].sort_values(ascending=False).plot.barh()","9a1d666d":"df3 = df3[corr_y[np.abs(corr_y) > 0.2].index.values]","29495805":"train, test = train_test_split(df3, test_size=0.3, random_state=0)\n\nX_train = train.drop(['cx_score'], axis=1)\ny_train = train['cx_score']\n\nX_test = test.drop(['cx_score'], axis=1)\ny_test = test['cx_score']\n\nols = linear_model.LinearRegression()\nols.fit(X_train, y_train)\ny_train_preds = ols.predict(X_train)\nr2_score(y_train, y_train_preds)","2ef60aa8":"np.sqrt(mean_squared_error(y_train, y_train_preds))","10299602":"y_test_preds = ols.predict(X_test)\nr2_score(y_test, y_test_preds)","33f9112b":"np.sqrt(mean_squared_error(y_test, y_test_preds))","7c9c6a92":"reg = RidgeCV(cv=6)\nreg.fit(X_train, y_train)\nreg.score(X_train, y_train)","1b7dd50d":"reg.score(X_test, y_test)","5a3c5ed5":"y_test_preds = reg.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_test_preds))","6acd90b0":"coefs = pd.DataFrame(reg.coef_, index=X_train.columns)\ncoefs.columns = ['Coefficient']\ncoefs.sort_values(by=['Coefficient'], ascending=False).head(5)","2481e29a":"coefs.sort_values(by=['Coefficient'], ascending=True).head(5)","03988829":"# Predicting AirBnb Review Scores\n\nIn this document we will be:\n* Creating violin plots of variables in order to ascertain a reasonable response variable\n* Preparing the data for a prediction model on the response variable\n* Assessing model performance and looking at feature importance\n\nFirstly, we will import all the relevant libraries.","283a678e":"The test RMSE is much better than before. Now let's have a look at the coefficients of the model to understand feature importance. Firstly, we list the top 5 features with positive coefficients.","dd3c657b":"A histogram of the response variable is given below.","86d4e3da":"We will now apply the preprocessing function to the data.","120b1b3d":"We will see how the University District reviews scores compare against the other listings using the violin plot.","a051a18e":"Now let's see how well the OLS model performs on the test data.","254e9473":"This is a very good score. Let's see also the RMSE.","1d9393d0":"We will be using the listings dataset only.","e0b885f6":"Finally, we decide on the combination of review score and reviews per month for the CX score and inspect its distribution.","498230ac":"The R2 score on the training data is not as good as before, but let's check how it performs on the test data.","ae729c3c":"Let's plot the most correlated features with the response variable.","e90bb6b5":"The RMSE score is also bad. Let's try another model, such as ridge regression. We will use cross-validation with 6 folds.","1d037d93":"Next we show the 5 features with the most negative coefficients","0f180c0a":"Various functions for preprocessing each variable are given below.","88b9f38f":"Next, we have a violin plot of the reviews per month.","fc356819":"Now let's create the train test split of the data, and separate the response variable from the other features. We then fit an OLS regression on the data and print the R2 score of the training data.","76ee8d5f":"We will drop the unnecessary columns from the data for modelling.","57f3c303":"Let's see the value counts of the various neighbourhoods.","6670c439":"The preprocessing functions for the data are combined together in the following overall dataset preprocessing function.","12f94222":"We will just filter the data to the University District for more accurate results.","e1308892":"This R2 score is very bad.","de7a2872":"The R2 score is reasonable, so we can accept this model.","b17144d4":"Let's take only the features which have at least magnitude 0.2 correlation with the response variable."}}