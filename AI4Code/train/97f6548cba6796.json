{"cell_type":{"33708300":"code","5bff5cd0":"code","3d8e6acc":"code","a65568bb":"code","80a4890b":"code","76beb2c0":"code","4c52f0a0":"code","dd033c23":"code","117abe23":"code","07c09566":"code","c623f0d4":"code","3da2bbb7":"code","a13099ff":"code","60b519ea":"code","5a997b4a":"code","9e95216a":"code","d10ae5a2":"code","c4b89d9e":"code","281edd59":"code","17a4f2fb":"code","bf241aa5":"code","7354924b":"code","0745fa3d":"code","2f08c6f3":"code","deeeb5c6":"code","9483a98d":"code","02d03acc":"code","a49d46d2":"code","9f96fbf3":"code","5acc61c4":"code","7406b4d0":"markdown","f24527ab":"markdown","b6e5c036":"markdown","d8dc1ec7":"markdown","89380bb2":"markdown","b45f42e4":"markdown","a6222b1d":"markdown","4d941de8":"markdown","8cc130f1":"markdown","13589718":"markdown","c9e4b61e":"markdown","75a6154a":"markdown","19f7d5b3":"markdown","75ab7f18":"markdown","c12a8c5e":"markdown","f0e008b6":"markdown","b7f54fcf":"markdown","00e86512":"markdown","7c5da847":"markdown","f1cfcc16":"markdown","7e83de32":"markdown","f4060e56":"markdown","e017bdbc":"markdown","2b382025":"markdown","9320c2a2":"markdown","3886b5c0":"markdown","1c8e90ae":"markdown","e7545b8c":"markdown","6e2ae3a9":"markdown","c5450b5b":"markdown","2a984241":"markdown","580d99b0":"markdown","940c33f1":"markdown","40226713":"markdown","2569a2f5":"markdown","41826b02":"markdown"},"source":{"33708300":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode, plot\nfrom scipy.interpolate import make_interp_spline, BSpline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport folium\nimport os\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport plotly.graph_objects as go\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport datetime\nfrom datetime import date as datefun\nfrom datetime import timedelta\nimport requests\n\n","5bff5cd0":"data_raw=requests.get('https:\/\/api.covid19india.org\/raw_data.json').json()  # read API\nhead=list(data_raw['raw_data'][0].keys())\n","3d8e6acc":"head # Keys","a65568bb":"\ntemp = pd.DataFrame([]) \nfor i in range(0,len(data_raw['raw_data'])):\n    data1=pd.DataFrame([data_raw['raw_data'][i].values()], columns=head)\n    temp=temp.append(data1,ignore_index = True)\n\n#------------  Remove No data rows ------------------------------------\ntemp1= list(temp.loc[0:len(data_raw['raw_data']),'currentstatus'])\nvalid_data=[i for i, item in enumerate(temp1) if item != '']\ndata_raw=temp[0:len(valid_data)]","80a4890b":"data_raw \nfor index, row in data_raw.iterrows():\n    if row['detectedstate'] in 'Delhi':\n            data_raw.at[index,'detecteddistrict'] = 'Delhi'\n","76beb2c0":"def get_state_df_from_api(data_temp,start_date,end_date):\n    tot_days=(datefun.today()-datetime.datetime.strptime(start_date, '%Y-%m-%d').date()).days\n\n    temp_data=data_raw.copy()\n    temp1= list(data_raw.loc[:,'dateannounced'])\n    DATE = [datetime.datetime.strptime(x,'%d\/%m\/%Y') for x in temp1]\n    temp_data.loc[:,'dateannounced'] = DATE\n\n    temp2= pd.to_datetime(temp_data.dateannounced,format='%Y-%m-%d')\n    temp_data.loc[:,'dateannounced'] = temp2.dt.strftime('%Y-%m-%d')\n\n\n    # #---------Set till-date as the Last date available in data_raw-------\n    yesterday = datefun.today() - timedelta(days=1)\n    date_yesterday=yesterday.strftime('%Y-%m-%d')\n    date_yesterday=end_date\n\n    data_temp = temp_data[(temp_data['dateannounced'] <= date_yesterday)]\n    data=data_temp\n    data.loc[:,'Confirmed']=np.ones((data_temp['dateannounced'].size),dtype='int')\n    data.loc[:,'Recovered'] = np.zeros((data_temp['dateannounced'].size),dtype='int')\n    temp=data[data['currentstatus']=='Recovered']\n    data.loc[list(temp.index),'Recovered']=1\n    data.loc[:,'Fatalities'] = np.zeros((data_temp['dateannounced'].size),dtype='int')\n    temp=data[data['currentstatus']=='Fatalities']\n    data.loc[list(temp.index),'Fatalities']=1\n\n    data=data.rename({'detectedstate': 'State'}, axis='columns')\n    data=data.rename({'dateannounced': 'Date'}, axis='columns')\n\n    temp_data=data.copy()\n    temp2= pd.to_datetime(temp_data.Date,format='%Y-%m-%d')\n    data.loc[:,'Date'] = temp2.dt.strftime('%Y-%m-%d')\n\n\n    ''' Prepare State Data '''\n    States=list(data.State.unique())\n    final_data=pd.DataFrame([])\n    for j in range (0,len(States)):\n        st= data.query('State == '+ '\"'+States[j]+'\"')\n        #a=st['Confirmed'].cumsum()\n        date=list(st.Date.unique())\n        a=list(pd.date_range(start=start_date, end=end_date).date)#date[len(date)-1]).date)\n        dat1=dict()\n        dat2=dict()\n        for i in a:\n            dt=st[\"Date\"] == str(i)\n            aa=st.loc[dt].Confirmed.sum()\n            bb=st.loc[dt].Fatalities.sum()\n            dat1[i]=aa\n            dat2[i]=bb\n        datc=np.array(list(dat1.values())).cumsum()\n        datf=np.array(list(dat2.values())).cumsum()\n        nam=pd.Series([States[j]])\n        name=nam.repeat(len(a))\n        days=np.arange(len(a))\n        tempdata={'State':name,'Date': pd.to_datetime(a,format='%Y-%m-%d'),'Day':days,'ConfirmedCases': datc.T,'Fatalities': datf.T,}\n        dd=pd.DataFrame.from_dict(tempdata)\n        final_data=final_data.append(dd,ignore_index = True)\n\n    temp1= pd.to_datetime(final_data.Date)\n    final_data['Date'] = temp1.dt.strftime('%Y-%m-%d')\n    return final_data\n\ndef get_district_df_from_api(data_temp,start_date,end_date):\n    tot_days=(datefun.today()-datetime.datetime.strptime(start_date, '%Y-%m-%d').date()).days\n\n    temp_data=data_raw.copy()\n    temp1= list(data_raw.loc[:,'dateannounced'])\n    DATE = [datetime.datetime.strptime(x,'%d\/%m\/%Y') for x in temp1]\n    temp_data.loc[:,'dateannounced'] = DATE\n\n    temp2= pd.to_datetime(temp_data.dateannounced,format='%Y-%m-%d')\n    temp_data.loc[:,'dateannounced'] = temp2.dt.strftime('%Y-%m-%d')\n\n\n    # #---------Set till-date as the Last date available in data_raw-------\n    yesterday = datefun.today() - timedelta(days=1)\n    date_yesterday=yesterday.strftime('%Y-%m-%d')\n    date_yesterday=end_date\n    \n    data_temp = temp_data[(temp_data['dateannounced'] <= date_yesterday)]\n    datad=data_temp\n    datad.loc[:,'Confirmed']=np.ones((data_temp['dateannounced'].size),dtype='int')\n    datad.loc[:,'Recovered'] = np.zeros((data_temp['dateannounced'].size),dtype='int')\n    temp=datad[datad['currentstatus']=='Recovered']\n    datad.loc[list(temp.index),'Recovered']=1\n    datad.loc[:,'Fatalities'] = np.zeros((data_temp['dateannounced'].size),dtype='int')\n    temp=datad[datad['currentstatus']=='Fatalities']\n    datad.loc[list(temp.index),'Fatalities']=1\n\n    datad=datad.rename({'detecteddistrict': 'District'}, axis='columns')\n    datad=datad.rename({'dateannounced': 'Date'}, axis='columns')\n   \n    #datad['Date']= pd.to_datetime(datad['Date'],format='%Y-%m-%d')\n    \n    temp_data=datad.copy()\n    temp2= pd.to_datetime(temp_data.Date,format='%Y-%m-%d')\n    datad.loc[:,'Date'] = temp2.dt.strftime('%Y-%m-%d')\n\n    ''' Prepare District Data '''\n    Districts=list(datad.District.unique())\n    final_datad=pd.DataFrame([])\n    for j in range (0,len(Districts)):\n        st= datad.query('District == '+ '\"'+Districts[j]+'\"')\n        #a=st['Confirmed'].cumsum()\n        date=list(st.Date.unique())\n        a=list(pd.date_range(start=start_date, end=end_date).date)\n        dat1=dict()\n        dat2=dict()\n        for i in a:\n            dt=st[\"Date\"] == str(i)\n            aa=st.loc[dt].Confirmed.sum()\n            bb=st.loc[dt].Fatalities.sum()\n            dat1[i]=aa\n            dat2[i]=bb\n        datc=np.array(list(dat1.values())).cumsum()\n        datf=np.array(list(dat2.values())).cumsum()\n        nam=pd.Series([Districts[j]])\n        name=nam.repeat(len(a))\n        days=np.arange(len(a))\n        tempdata={'District':name,'Date': pd.to_datetime(a,format='%Y-%m-%d'),'Day':days,'ConfirmedCases': datc.T,'Fatalities': datf.T,}\n        dd=pd.DataFrame.from_dict(tempdata)\n        final_datad=final_datad.append(dd,ignore_index = True)\n\n    temp1= pd.to_datetime(final_datad.Date)\n    final_datad['Date'] = temp1.dt.strftime('%Y-%m-%d')\n    return final_datad","4c52f0a0":"\nstart_date='2020-03-01'; end_date='2020-04-27'\ndf_state = get_state_df_from_api(data_raw,start_date,end_date)\n\n#df_district = get_district_df_from_api(data_raw,start_date,end_date)\n#df_district","dd033c23":"latest_date=df_state['Date'].max()\ndf_state_latest = df_state[df_state['Date'] == latest_date].sort_values(by='ConfirmedCases',ascending=False)\n#df_state_= df_latest.groupby(['District']).sum().reset_index() # get sum of cases for each province\ndf_state_latest.style.background_gradient(cmap='Reds')","117abe23":"df_k= pd.read_csv('..\/input\/covid19-in-india\/covid_19_india.csv')\n\ndf_k['Date']  = pd.to_datetime(df_k['Date'],format=\"%d\/%m\/%y\") # new clean date columnn\ndf_k_latest = df_k[(df_k['Date'] == end_date)].sort_values(by='Confirmed',ascending=False)\n#df_temp=df[df['Sno']==latest_index]\n#latest_date=df_temp['Date'].max()\n#df_latest = df[df['Date'] == latest_date]\ndf_k","07c09566":"print(\"Total number of Cases According to Kaggle Data base as on \",end_date, \"is = \",df_k_latest['Confirmed'].sum())\nprint(\"Total number of Cases According to Covid19India.org as on \",end_date, \"is = \",df_state_latest['ConfirmedCases'].sum())","c623f0d4":"def plot_trend_rowdf(df,threshold,Days,First_n,highlight,Label_X,Label_Y,Title):\n# modified from the awesome by Tarun Kumar work at https:\/\/www.kaggle.com\/tarunkr\/covid-19-case-study-analysis-viz-comparisons and modified for use\n\n    temp_I = df#.sort_values(df.columns[-1], ascending= True)\n    temp_I_sum = temp_I.sum(axis=1)\n   # print(temp_I_sum)\n    last_row=temp_I.tail(1)\n    last_row1 = last_row.sort_values(by=last_row.last_valid_index(),ascending=False, axis=1)\n\n #   threshold = 50\n #   Days=51\n    f = plt.figure(figsize=(10,12))\n    ax = f.add_subplot(111)\n    x = Days\n    t1_I = temp_I_sum.to_numpy()\n    t2_I = t1_I[t1_I>threshold][:x]\n    date = np.arange(0,len(t2_I[:x]))\n    xnew = np.linspace(date.min(), date.max(), Days)\n    spl = make_interp_spline(date, t2_I, k=1)  # type: BSpline\n    power_smooth = spl(xnew)\n    marker_style = dict(linewidth=4, linestyle='-', marker='o',markersize=6, markerfacecolor='#ffffff')\n    plt.plot(xnew,power_smooth,\"-.\",label = 'All The Cases',**marker_style)\n          \n    for i,col in enumerate(last_row1.columns[:15]):\n        if col not in  ['Date','date']:\n            x = Days\n            t1_I = temp_I[col].to_numpy()\n            t2_I = t1_I[t1_I>threshold][:x]\n            if t2_I.size>0 :\n                date = np.arange(0,len(t2_I[:x]))\n                xnew = np.linspace(date.min(), date.max(), Days)\n                spl = make_interp_spline(date, t2_I, k=1)  # type: BSpline\n                power_smooth = spl(xnew)\n                if col in highlight:\n                    marker_style = dict(linewidth=4, linestyle='-', marker='o',markersize=6, markerfacecolor='#000000')\n                    plt.plot(xnew,power_smooth,\"-.\",label = col,**marker_style)\n                else:  \n                    plt.plot(xnew,power_smooth,'-o',label = col,linewidth =3, markevery=[-1])\n             #   else:\n              #  \n\n    plt.tick_params(labelsize = 14)        \n    plt.xticks(np.arange(0,Days,7),[ \"Day \"+str(i) for i in range(Days)][::7])     \n\n    # Reference lines \n    x = np.arange(0,Days\/3)\n    y = 2**(x+np.log(threshold))\n    plt.plot(x,y,\"--\",linewidth =2,color = \"gray\")\n    plt.annotate(\"No. of cases doubles every day\",(x[-2],y[-1]),xycoords=\"data\",fontsize=14,alpha = 0.5)\n\n    x = np.arange(0,Days\/2)\n    y = 2**(x\/2+np.log2(threshold))\n    plt.plot(x,y,\"--\",linewidth =2,color = \"gray\")\n    plt.annotate(\".. every socend day\",(x[-3],y[-1]),xycoords=\"data\",fontsize=14,alpha = 0.5)\n\n    x = np.arange(0,Days-4)\n    y = 2**(x\/7+np.log2(threshold))\n    plt.plot(x,y,\"--\",linewidth =2,color = \"gray\")\n    plt.annotate(\".. every week\",(x[-3],y[-1]),xycoords=\"data\",fontsize=14,alpha = 0.5)\n\n    x = np.arange(0,Days-4)\n    y = 2**(x\/30+np.log2(threshold))\n    plt.plot(x,y,\"--\",linewidth =2,color = \"gray\")\n    plt.annotate(\".. every month\",(x[-3],y[-1]),xycoords=\"data\",fontsize=14,alpha = 0.5)\n\n    x = np.arange(0,Days-4)\n    y = 2**(x\/4+np.log2(threshold))\n    plt.plot(x,y,\"--\",linewidth =2,color = \"Red\")\n    plt.annotate(\".. every 4 days\",(x[-3],y[-1]),color=\"Red\",xycoords=\"data\",fontsize=14,alpha = 0.8)\n\n    # plot Params\n    plt.xlabel(Label_X,fontsize=17)\n    plt.ylabel(Label_Y,fontsize=17)\n    plt.title(Title,fontsize=22)\n    plt.legend(loc = \"upper left\")\n    plt.yscale(\"log\")\n    plt.grid(which=\"both\")\n    plt.show()","3da2bbb7":"df_state=df_state.sort_values(by='Date',ascending=True)\n#gb_state_time = df_state.groupby(['Date']).sum().reset_index()\ngb_state_time = df_state.pivot_table(index=['Date'], \n            columns=['State'], values='ConfirmedCases').fillna(0)\ngb_state_time['Date']=gb_state_time.index\ngb_state_time.index.name = None\ngb_state_time = gb_state_time.sort_values(by='Date',ascending=True)\ngb_state_time['Date'] = pd.to_datetime(gb_state_time['Date'],format=\"%Y-%m-%d\")\ngb_state_time.index = pd.to_datetime(gb_state_time['Date'],format=\"%Y-%m-%d\")\ngb_state_time=gb_state_time.drop(['Date'],axis = 1) \ngb_state_time.tail(3)","a13099ff":"\nstart_date='2020-03-01'; end_date='2020-04-23'\ndf_district = get_district_df_from_api(data_raw,start_date,end_date)\n\ndf_district.tail(10)","60b519ea":"df_district=df_district.sort_values(by='Date',ascending=True)\n#gb_district_time = df_district.groupby(['Date']).sum().reset_index()\ngb_district_time = df_district.pivot_table(index=['Date'], \n            columns=['District'], values='ConfirmedCases').fillna(0)\ngb_district_time['Date']=gb_district_time.index\ngb_district_time.index.name = None\ngb_district_time = gb_district_time.sort_values(by='Date',ascending=True)\ngb_district_time['Date'] = pd.to_datetime(gb_district_time['Date'],format=\"%Y-%m-%d\")\ngb_district_time.index = pd.to_datetime(gb_district_time['Date'],format=\"%Y-%m-%d\")\ngb_district_time=gb_district_time.drop(['Date'],axis = 1) \ngb_district_time.rename(columns = {list(gb_district_time)[0]:'Unkown'}, inplace=True)\ngb_district_time.tail(10)","5a997b4a":"highlight=[\"Mumbai\",\"Pune\",\"Indore\",\"Delhi\",\"Kasaragod\"]\nFirst_n=15\nDays=50\nThreshold=50\nLabel_X=\"Days( Referenced to Threshold )\"\nLabel_Y=\"Number of Confirmed Cases (Log Scale)\"\nTitle=\"Trend Comparison of Different District (confirmed)\\n Top 15 Cities in terms of COVID-19 Cases\"\nplot_trend_rowdf(gb_district_time,Threshold,Days,First_n,highlight,Label_X,Label_Y,Title)","9e95216a":"latest_date=df_district['Date'].max()\ndf_latest = df_district[df_district['Date'] == latest_date]\ndf_district_m = df_latest.groupby(['District']).sum().reset_index()\n#df_district_m1=df_district_m[df_district_m.District != []]\n#df_district_m  = df_district_m['District'].str.replace(\" \",\"\")\ndf_district_m.at[0,'District']=\"Unknown\"\ndf_district_m.head(10)","d10ae5a2":"from geopy.extra.rate_limiter import RateLimiter\nfrom geopy.exc import GeocoderServiceError, GeocoderTimedOut, GeocoderUnavailable\nimport time\nfrom  geopy.geocoders import Nominatim\n\ndef get_lat_lon(geolocator, city):\n    location = None\n    country=\"India\"\n    try:\n        location = geolocator.geocode(city+','+ country)\n    except (GeocoderTimedOut, GeocoderServiceError, GeocoderUnavailable):\n        time.sleep(1)\n        try:\n            location = geolocator.geocode(city+','+ country)\n        except (\n                GeocoderTimedOut, GeocoderServiceError,\n                GeocoderUnavailable):\n            return None, None\n    if location:\n        return location\n    else:\n        return None","c4b89d9e":"\ngeolocator = Nominatim()\n\ncity =\"una\"\nlocation=get_lat_lon(geolocator,city)\ncountry =\"India\"\nloc = geolocator.geocode(city+','+ country)\nprint(\"latitude is :-\" ,loc.latitude,\"\\nlongtitude is:-\" ,loc.longitude)\nprint(location)","281edd59":"df_lat_lon= pd.read_csv('..\/input\/district-lat-lon-covid\/India_District_Lat_Long')\ndf_lat_lon\ndf_lat = df_lat_lon.pivot_table(columns=['District'],values='lat').fillna(0)\ndf_lon = df_lat_lon.pivot_table(columns=['District'],values='long').fillna(0)\n\ndf_district_m['lat']=\"\"\ndf_district_m['long']=\"\"\nmissing_list = [\"Unknown\"]\nfor index, row in df_district_m.iterrows():\n    if row['District'] in df_lat.columns:\n        df_district_m.at[index,'lat'] = df_lat[row['District']]['lat']\n        df_district_m.at[index,'long'] = df_lon[row['District']]['long']\n        #print(df_lat[row['District']])\n    else :\n        df_district_m.at[index,'lat'] = \"0\"\n        df_district_m.at[index,'long'] = \"0\"\n        if row['District'] not in missing_list :\n            city=row['District']\n            #loc = geolocator.geocode(city+','+ 'India')\n            loc=get_lat_lon(geolocator,city)\n            print(loc)\n            if not loc:\n                print(city)\n                missing_list.append(row['District'])\n            else :\n                df_district_m.at[index,'lat'] = loc.latitude\n                df_district_m.at[index,'long'] = loc.longitude\n                ","17a4f2fb":"df1 =df_district_m[df_district_m['lat'].notna()]\ndf1.head(10)\n# Cases which are not linked to any district is shown as Unkown District\n","bf241aa5":"#Wirintg data to csv file to avoid api calls for getting lat long\n#df1.to_csv(\"India_District_Lat_lon\", mode='w', columns=['District','lat','long'], index=False)\n","7354924b":"scalar=0.8\nmap = folium.Map(location=[20, 80], zoom_start=4.5,tiles='cartodbpositron')\n\ndf1['color']=df1['ConfirmedCases'].apply(lambda count:\"red\" if count>=400 else\n                                         \"green\" if count>=200 and count<400 else\n                                         \"darkblue\" if count>=100 and count<200 else\n                                         \"brown\" if count>=50 and count<100 else\n                                         \"grey\" if count>=10 and count<50 else\n                                         \"black\")\n\ndf1['size']=df1['ConfirmedCases'].apply(lambda count:12 if count>=400 else\n                                         8 if count>=200 and count<400 else\n                                         6 if count>=100 and count<200 else\n                                         3 if count>=50 and count<100 else\n                                         1 if count>=10 and count<50 else\n                                         0.1)\n\nfor lat, lon, value, name, color1,size in zip(df1['lat'], df1['long'], df1['ConfirmedCases'], df1['District'],df1['color'],df1['size']):\n    folium.CircleMarker([lat, lon],\n                        radius=size*3*scalar,\n                        popup = ('<strong>District<\/strong>: ' + str(name).capitalize() + '<br>'\n                                '<strong>Active Cases<\/strong>: ' + str(value) + '<br>'),\n                        color=color1,\n                        \n                        fill_color=color1,\n                        fill_opacity=0.7 ).add_to(map)\nmap","0745fa3d":"stationArr = df1[['lat', 'long','Day']].as_matrix()\nfrom folium import plugins\nmap.add_children(plugins.HeatMap(stationArr, radius=25))\nmap","2f08c6f3":"map_small = folium.Map(location=[20, 80], zoom_start=4,tiles='cartodbpositron')\nscalar=0.5\nfor lat, lon, value, name, color1,size in zip(df1['lat'], df1['long'], df1['ConfirmedCases'], df1['District'],df1['color'],df1['size']):\n    folium.CircleMarker([lat, lon],\n                        radius=size*3*scalar,\n                        popup = ('<strong>District<\/strong>: ' + str(name).capitalize() + '<br>'\n                                '<strong>Active Cases<\/strong>: ' + str(value) + '<br>'),\n                        color=color1,\n                        \n                        fill_color=color1,\n                        fill_opacity=0.7 ).add_to(map_small)\nmap_small","deeeb5c6":"map_small.add_children(plugins.HeatMap(stationArr, radius=20))\nmap_small","9483a98d":"data_raw.head(10)","02d03acc":"backupnotes=data_raw['backupnotes']\nnotes = data_raw['notes']\nbackupnotes=backupnotes.dropna()\nnotes = notes.dropna()\ntransmission=data_raw['typeoftransmission']\ntransmission=transmission.dropna()","a49d46d2":"from wordcloud import WordCloud,STOPWORDS,ImageColorGenerator\nfrom matplotlib.colors import LinearSegmentedColormap\nfrom PIL import Image\n\ncolors = [\"#BF0A30\", \"#002868\"]\ncmap = LinearSegmentedColormap.from_list(\"mycmap\", colors)\nmask = np.array(Image.open(\"..\/input\/circle\/circle.png\"))\n\ntext = \" \".join(str(each) for each in notes)\nstopwords = set(STOPWORDS)\nstopwords.update([\"Details\", \"awaited\"])\nwordcloud = WordCloud(stopwords=stopwords,max_words=100,colormap=cmap, background_color=\"white\",mask=mask).generate(text)\nplt.figure(figsize=(10,6))\nplt.figure(figsize=(15,10))\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.figure(1,figsize=(12, 12))\nplt.show()","9f96fbf3":"from wordcloud import WordCloud,STOPWORDS,ImageColorGenerator\ntext = \" \".join(str(each) for each in backupnotes)\nstopwords = set(STOPWORDS)\nstopwords.update([\"Details\", \"awaited\"])\ncolors = [\"#BF0A30\", \"#002868\"]\ncmap = LinearSegmentedColormap.from_list(\"mycmap\", colors)\nwordcloud = WordCloud(stopwords=stopwords,max_words=200,colormap=cmap, background_color=\"white\",mask=mask).generate(text)\nplt.figure(figsize=(10,6))\nplt.figure(figsize=(15,10))\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.figure(1,figsize=(12, 12))\nplt.show()","5acc61c4":"from wordcloud import WordCloud,STOPWORDS,ImageColorGenerator\ntext = \" \".join(str(each) for each in transmission)\nstopwords = set(STOPWORDS)\nstopwords.update([ \"Details\", \"awaited\"])\ncolors = [\"#BF0A30\", \"#002868\"]\ncmap = LinearSegmentedColormap.from_list(\"mycmap\", colors)\nwordcloud = WordCloud(stopwords=stopwords,max_words=200,colormap=cmap, background_color=\"white\",mask=mask).generate(text)\nplt.figure(figsize=(10,6))\nplt.figure(figsize=(15,10))\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.figure(1,figsize=(12, 12))\nplt.show()","7406b4d0":"## Observation : There is a slight differenc between the two cases which may be due to reporting of foreing nationals","f24527ab":"# Prediction of Cases for India","b6e5c036":"## To analyze the spread of COVID-19 at various district folium is used, with circle as marker size represents the number of cases. Cities for which location could not be obtained plotted at (0,0) location","d8dc1ec7":"## Comparing the data-set from Data-set available in Kaggle","89380bb2":"### TO Visualize better let us reduce the size of markers and zoom level","b45f42e4":"1. Getting the dataset as per the latest date and current cases and Fatalities","a6222b1d":"## Utiliity function as per [github](https:\/\/github.com\/anandsahadevan\/COVID19india_visualize) repository to convert the raw data in dataframes","4d941de8":"As the number of rows are getting increased a pre-fetched lat long data already saved is first searched and if lat long is not present in the file, then it get fetched through geopy, and all the cities for which location could not be obtained is put in the missing_list","8cc130f1":"## will update soon ","13589718":"### work is in progress will update soon","c9e4b61e":"### 1.1 Getting the data-set to dataframe : \n### To convert the data to dataframe work done in this [github](https:\/\/github.com\/anandsahadevan\/COVID19india_visualize) repository is utilized. Author has created very good work to get the data in dataframe","75a6154a":"Wordcloud for the notes coloumn","19f7d5b3":"# Plotting the Trend of various states over time","75ab7f18":"### For further analysis we will be using the data-set from covid19India.org","c12a8c5e":"### Plotting functions are taken from work done by [Traun Kumar](https:\/\/www.kaggle.com\/tarunkr\/covid-19-case-study-analysis-viz-comparisons) and modified for better visualization and more control","f0e008b6":"worldcloud from transmission coloumn","b7f54fcf":"# District Wise Analysis of Covid19 Spread","00e86512":"## Group and Arrange the data as state-wise ","7c5da847":"# Comparison of Indian Covid19 Spread with Italy, USA and China","f1cfcc16":"Observation : \"Delhi\" with \"Travelled\" can be seen higher font size which indicates that from the available infrmation of infected cases most of the people has connection to Delhi.\n\"Travelled Dubai\" is also anothe key word which looks to be more common.. \"Local and Contact Transmission \" can also be seen along with \"Travel History\"","7e83de32":"## Getting the state wise data and analyzing it by providing the range of dates","f4060e56":"## Observations on India's trend\n#### India is still in intital stage of infections and trends for each state shows varying pattern. India has initially shown very slow increase in rate of infection. but now it's trend is very close to increase in cases to twice every fourth day. \n#### Maharashtra State with most of the cases is also following the trend of cases get doubled every fourth day. Kerala state seems to stabilized. \n#### Tamilnadu and Delhi is showing very high increase in cases, and may surpass number of Maharashtra in terms of cases. Trends from Madhya Pradesh and Andhra Pradesh is also have higher trends as compared to other states.\n\n### Trend for India goes to 30 Days while for states it's still in 7-10 days, which shows that new cases are getting identified in different states","e017bdbc":"### The API provides various information related to infected personlike detected city, district, gender etc.","2b382025":"Observation : The transmission coloumn mostly indicates local transmission and we can notice that the size of Local is more than Imported.\n","9320c2a2":"Test cell to cofirm that function is returning propoer locations ","3886b5c0":"Coronavirus disease (COVID-19) is an infectious disease caused by a new virus.\nThe disease causes respiratory illness (like the flu) with symptoms such as a cough, fever, and in more severe cases, difficulty breathing. You can protect yourself by washing your hands frequently, avoiding touching your face, and avoiding close contact (1 meter or 3 feet) with people who are unwell.\nfor more details please visit [WHO webpage](https:\/\/www.who.int\/emergencies\/diseases\/novel-coronavirus-2019)","1c8e90ae":"COCID-19 has seend more than 27000 positive cases as on 27th April 2020 and it's spreading at various locations in India. The overall spread in increasing at the rate of cases getting doubled every fourth week.\nThis notebook aims to analyze the crowd source data from [covid19india](www.covid19india.org) and look the details at distric level to understand which are the cities getting more effected by the disease.\n### If you like, or have suggestions or found some errors in analysis please like or comment.. \n### working on prediction and comparison with COVID-19 spread in other countries and will be updating it soon..","e7545b8c":"#### Observation on District Wise Analysis : \n#### Mumbai and Delhi are showing very high rate of increase in infection as compared to country level, with this rate both the cities may have double the cases in next three days (as on 11\/04\/20). \n#### Kasaragod which initially has more number of cases as comparedto other cities now looks to be stabliized.\n#### Pune, Indore, Thane, Jaipur, Ahmedabad are also few cities which may see high number of cases in coming days\n","6e2ae3a9":"### API from covid19india.org provide various other informations also like, notes which describe the travel or cotnact history and a backup level note as well. It also has a coloumn fot transmission type.\n### To analyze this coloumns wordcloud is used \n","c5450b5b":"# District wise Spatial Analysis ","2a984241":"## Observations : Most of the cities in India has cases of Covid19 and some cities like Mumbai,Delhi,Pune and Indore are at major risk.","580d99b0":"Observations : In the backup notes coloumn the \"Travel History\", \"Dubai\" along with various other kerywords can be seen.\nSome patient ID can be seen here like P44, P45, P182, P4 etc. which indicates that this pateints may have virus to various people","940c33f1":"![](https:\/\/media.springernature.com\/w580h326\/nature-cms\/uploads\/collections\/2AP1TD2-b598c7937e0cb7c3ddb3d98f6d897d82.jpg)","40226713":"# 1. Getting the date-set :\n## Read data from [covid19india.org](http:\/\/covid19india.org) : A crowd source inititative to track the spread of virus in India \nThe Data-set is fetched by the API provided at [api.covid19india.org](http:\/\/api.covid19india.org)","2569a2f5":"To perform spatial analysis we need to have latitude and logitude for each city. to get the Lat, Long following function is used which try to get location lat, long from geopy","41826b02":"Analyzing the raw data "}}