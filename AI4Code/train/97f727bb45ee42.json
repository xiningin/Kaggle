{"cell_type":{"32d7a0aa":"code","2ac252d3":"code","02d8f4b1":"code","6e7093f9":"code","6e81a511":"code","e5e8ce24":"code","291a30ba":"code","babee543":"code","ec5e89f9":"code","1ba2f234":"code","f66e8949":"code","99fe6af1":"code","eae8baff":"code","f577e119":"code","b26afb84":"code","62d921c2":"code","e354112b":"code","5d6c9b02":"code","e163a7e1":"code","ad82451f":"code","05de55d0":"code","312c6e37":"code","b20d9086":"code","db67b7bc":"code","5e959693":"code","0187ef40":"code","f30c9ce9":"code","89f185fc":"code","a9a39b8f":"code","f9154a5f":"code","9a8ce2f6":"code","ac932b7a":"code","93a9844e":"code","79e3a42a":"markdown","f013bd70":"markdown","ec3ea8cf":"markdown","417cc9b4":"markdown","f95d30dd":"markdown","d656c132":"markdown","180dead2":"markdown","35e2ceaf":"markdown","c047c927":"markdown","2287b41a":"markdown","6f0cf58e":"markdown"},"source":{"32d7a0aa":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport json\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\n\nsns.set_style('darkgrid')","2ac252d3":"# train = pd.read_csv('..\/input\/bigquery-geotab-intersection-congestion\/train.csv',nrows=22345) # read in sample of data for fast experimentation\n\ntrain = pd.read_csv('..\/input\/bigquery-geotab-intersection-congestion\/train.csv')","02d8f4b1":"test = pd.read_csv('..\/input\/bigquery-geotab-intersection-congestion\/test.csv')\nsample = pd.read_csv('..\/input\/bigquery-geotab-intersection-congestion\/sample_submission.csv')\nwith open('..\/input\/bigquery-geotab-intersection-congestion\/submission_metric_map.json') as f:\n    submission_metric_map = json.load(f)","6e7093f9":"train.head()","6e81a511":"test.head()","e5e8ce24":"train.info()","291a30ba":"test.info()","babee543":"street_features = ['EntryStreetName', 'ExitStreetName', 'EntryHeading', 'ExitHeading', 'Path']\ntrain[street_features].head()","ec5e89f9":"train.drop('Path', axis=1, inplace=True)\ntest.drop('Path', axis=1, inplace=True)","1ba2f234":"directions = {\n    'N': 0,\n    'NE': 1\/4,\n    'E': 1\/2,\n    'SE': 3\/4,\n    'S': 1,\n    'SW': 5\/4,\n    'W': 3\/2,\n    'NW': 7\/4\n}","f66e8949":"train['EntryHeading'] = train['EntryHeading'].map(directions)\ntrain['ExitHeading'] = train['ExitHeading'].map(directions)\n\ntest['EntryHeading'] = test['EntryHeading'].map(directions)\ntest['ExitHeading'] = test['ExitHeading'].map(directions)","99fe6af1":"train['diffHeading'] = train['EntryHeading']-train['ExitHeading']  # TODO - check if this is right. For now, it's a silly approximation without the angles being taken into consideration\n\ntest['diffHeading'] = test['EntryHeading']-test['ExitHeading']  # TODO - check if this is right. For now, it's a silly approximation without the angles being taken into consideration\n\ntrain[['ExitHeading','EntryHeading','diffHeading']].drop_duplicates().head(10)","eae8baff":"new_train_columns = ['IntersectionId', 'Latitude', 'Longitude', 'EntryStreetName',\n       'ExitStreetName', 'EntryHeading', 'ExitHeading', 'Hour', 'Weekend', 'DistanceToFirstStop',\n       'Month', 'TotalTimeStopped', 'Percentile', 'City'\n                    ,'diffHeading'\n                    ]","f577e119":"new_test_columns = ['IntersectionId', 'Latitude', 'Longitude', 'EntryStreetName',\n       'ExitStreetName', 'EntryHeading', 'ExitHeading', 'Hour', 'Weekend',\n       'Month', 'Percentile', 'City'\n                   ,'diffHeading'\n                   ]","b26afb84":"new_train = pd.DataFrame(columns=new_train_columns)","62d921c2":"new_test = pd.DataFrame(columns=new_test_columns)","e354112b":"for per in [20, 40, 50, 60, 80]:\n    new_df = train.copy()\n    new_df['TotalTimeStopped'] = new_df['TotalTimeStopped_p'+str(per)]\n    new_df['DistanceToFirstStop'] = new_df['DistanceToFirstStop_p'+str(per)]\n    new_df['Percentile'] = pd.Series([per for _ in range(len(new_df))])\n    new_df.drop(['TotalTimeStopped_p20', 'TotalTimeStopped_p40',\n       'TotalTimeStopped_p50', 'TotalTimeStopped_p60', 'TotalTimeStopped_p80',\n       'TimeFromFirstStop_p20', 'TimeFromFirstStop_p40',\n       'TimeFromFirstStop_p50', 'TimeFromFirstStop_p60',\n       'TimeFromFirstStop_p80', 'DistanceToFirstStop_p20',\n       'DistanceToFirstStop_p40', 'DistanceToFirstStop_p50',\n       'DistanceToFirstStop_p60', 'DistanceToFirstStop_p80', 'RowId'], axis=1,inplace=True)\n    new_train = pd.concat([new_train, new_df], sort=True)","5d6c9b02":"for per in [20, 50, 80]:\n    new_df = test.copy()\n    new_df['Percentile'] = pd.Series([per for _ in range(len(new_df))])\n    new_test = pd.concat([new_test, new_df], sort=True)","e163a7e1":"new_train = pd.concat([new_train.drop('City', axis=1), pd.get_dummies(new_train['City'])], axis=1)","ad82451f":"new_test = pd.concat([new_test.drop('City', axis=1), pd.get_dummies(new_test['City'])], axis=1)","05de55d0":"new_train = new_train.reindex(sorted(new_train.columns), axis=1)\nnew_test = new_test.reindex(sorted(new_test.columns), axis=1)","312c6e37":"new_test = new_test.sort_values(by=['RowId', 'Percentile'])","b20d9086":"X_train = np.array(new_train.drop(['EntryStreetName', 'ExitStreetName', 'IntersectionId', 'TotalTimeStopped', 'DistanceToFirstStop'], axis=1))\nX_test = np.array(new_test.drop(['EntryStreetName', 'ExitStreetName', 'IntersectionId', 'RowId'], axis=1))","db67b7bc":"y_train = np.array(new_train[['TotalTimeStopped', 'DistanceToFirstStop']])","5e959693":"X_train.shape","0187ef40":"X_test.shape","f30c9ce9":"clf = RandomForestRegressor(n_jobs=4, n_estimators=12)\n\nclf.fit(X_train, y_train)","89f185fc":"y_pred = clf.predict(X_test)","a9a39b8f":"sample['Target'] = y_pred.reshape(-1)","f9154a5f":"l = []\nfor i in range(1920335):\n    for j in [0,3,1,4,2,5]:\n        l.append(str(i)+'_'+str(j))","9a8ce2f6":"sample['TargetId'] = l","ac932b7a":"sample = sample.sort_values(by='TargetId')","93a9844e":"sample.to_csv('sample_submission.csv', index=False)","79e3a42a":"Let's create a new dataframe with the new following features: TotaTimeStopped, DistanceToFirstStop and Percentile.\n\nCreating a dataframe in the following way can enable us to use the percentile as a feature and can help us boost the model.\n\n* This step seems very klunky and could be improved. TODO. ","f013bd70":"# Table of contents\n- [Imports and initial exploration](#imports)\n- [Exploratory Data Analysis](#eda)\n    - [Exploring street features](#streetfeatures)\n- [Preprocessing](#prepro)\n\n- [Baseline model](#baseline)","ec3ea8cf":"## Exploratory Data Analysis\n<a id='eda'><\/a>","417cc9b4":"## Imports and initial exploration\n<a id='imports'><\/a>","f95d30dd":"### Exploring street features\n<a id='streetfeatures'><\/a>","d656c132":"The cardinal directions can be expressed using the equation: $$ \\frac{\\theta}{\\pi} $$\n\nWhere $\\theta$ is the angle between the direction we want to encode and the north compass direction, measured clockwise.\n\n* This is an **important** feature, as shown by janlauge here : https:\/\/www.kaggle.com\/janlauge\/intersection-congestion-eda\n\n* We can fill in this code in python (e.g. based on: https:\/\/www.analytics-link.com\/single-post\/2018\/08\/21\/Calculating-the-compass-direction-between-two-points-in-Python , https:\/\/rosettacode.org\/wiki\/Angle_difference_between_two_bearings#Python , https:\/\/gist.github.com\/RobertSudwarts\/acf8df23a16afdb5837f ) \n\n* TODO: circularize \/ use angles","180dead2":"# BigQuery-Geotab Intersection Congestion","35e2ceaf":"We can see path is just a concatenation of the other features, so we could drop it","c047c927":"## Baseline model\n<a id='baseline'><\/a>","2287b41a":"* Forked from : https:\/\/www.kaggle.com\/bgmello\/how-one-percentile-affect-the-others\n\n* Todo: submission code is very klunky.\n* Todo: intersection ID is non unique, it's only unique per coty. make a new one and (if not using LGBM\/embedders), OHE it. ","6f0cf58e":"## Preprocessing\n<a id='prepro'><\/a>"}}