{"cell_type":{"145cb167":"code","2ff4010c":"code","b4dc8f2b":"code","84950d14":"code","84079f61":"code","a381b625":"code","1ad48ed8":"code","f9d684af":"code","06f647a7":"code","4cb368f8":"code","53fbd8a6":"code","45edaea8":"code","42024555":"code","87292905":"code","8aeda770":"code","102491da":"code","814523b3":"code","9ec2fd70":"code","abf1171c":"code","984f23dd":"code","c4cf9155":"code","d134e34d":"code","e0af8c4a":"code","b289fdf1":"code","33173b0d":"code","dfe62c8a":"code","f7984d22":"code","6dcf2e13":"code","d0e1e4c6":"code","3c66ea09":"code","04f1e7f2":"code","2ae2ce67":"code","8c380954":"code","677032f3":"code","63331325":"markdown","d9e90f10":"markdown","419417ff":"markdown","24b171ea":"markdown","b45482fb":"markdown","ccb28f20":"markdown","217e1c65":"markdown","9be1f68e":"markdown"},"source":{"145cb167":"#Import Libs\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as plt\n\nimport seaborn as sns","2ff4010c":"df = pd.read_csv('train.csv')","b4dc8f2b":"df['Credit_History'] = df['Credit_History'].fillna( df['Credit_History'].dropna().mode().values[0] )\ndf['Self_Employed'] = df['Self_Employed'].fillna( df['Self_Employed'].dropna().mode().values[0] )\ndf['LoanAmount'] = df['LoanAmount'].fillna( df['LoanAmount'].dropna().mean())\ndf['Dependents'] = df['Dependents'].fillna( df['Dependents'].dropna().mode().values[0] )\ndf['Loan_Amount_Term'] = df['Loan_Amount_Term'].fillna( df['Loan_Amount_Term'].dropna().mode().values[0] )\ndf['Gender'] = df['Gender'].fillna( df['Gender'].dropna().mode().values[0] )\ndf['Married'] = df['Married'].fillna( df['Married'].dropna().mode().values[0] )\ndf['Self_Employed'] = df['Self_Employed'].fillna( df['Self_Employed'].dropna().mode().values[0] )\ndf['Gender'] = df['Gender'].map({'Female':0,'Male':1}).astype(np.int)\ndf['Married'] = df['Married'].map({'No':0,'Yes':1}).astype(np.int)\ndf['Education'] = df['Education'].map({'Not Graduate':0,'Graduate':1}).astype(np.int)\ndf['Self_Employed'] = df['Self_Employed'].map({'No':0, 'Yes':1}).astype(np.int)\ndf['Loan_Status'] = df['Loan_Status'].map({'N':0, 'Y':1}).astype(np.int)\ndf['Dependents'] = df['Dependents'].str.rstrip('+')\ndf['Loan_Amount_Term'] = df['Loan_Amount_Term'].fillna( df['Loan_Amount_Term'].dropna().mode().values[0] )\ndf['Credit_History'] = df['Credit_History'].fillna( df['Credit_History'].dropna().mode().values[0] )\ncolumn_names =['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome',\n       'Loan_Amount_Term', 'Credit_History', 'Property_Area','LoanAmount','Loan_Status'] \ndf = df.reindex(columns = column_names)\ndf.head()","84950d14":"# log transformation\n# df['LoanAmount_log']=np.log(df['LoanAmount'])\n# df['LoanAmount'].hist(bins=20)\n# df['LoanAmount_log']=np.log(df['LoanAmount'])\n# df.drop('LoanAmount',1, inplace = True)","84079f61":"X = df.drop(['Loan_ID','Loan_Status'],1)\ny = df['Loan_Status']","a381b625":"X = pd.get_dummies(X)\nX.head()","1ad48ed8":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)","f9d684af":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","06f647a7":"# scaling\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nnums = ['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term']\nX_train[nums] = scaler.fit_transform(X_train[nums])","4cb368f8":"nums = ['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term']\nX_test[nums] = scaler.fit_transform(X_test[nums])","53fbd8a6":"import warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nmodel=LogisticRegression()\nmodel.fit(X_train,y_train)\n","45edaea8":"y_pred = model.predict(X_test)\naccuracy_score(y_test,y_pred)","42024555":"from sklearn.metrics import confusion_matrix","87292905":"confusion_matrix(y_test, y_pred)","8aeda770":"test = pd.read_csv('test.csv')","102491da":"test['Credit_History'] = test['Credit_History'].fillna( test['Credit_History'].dropna().mode().values[0] )\ntest['Self_Employed'] = test['Self_Employed'].fillna( test['Self_Employed'].dropna().mode().values[0] )\ntest['LoanAmount'] = test['LoanAmount'].fillna( test['LoanAmount'].dropna().mean())\ntest['Dependents'] = test['Dependents'].fillna( test['Dependents'].dropna().mode().values[0] )\ntest['Loan_Amount_Term'] = test['Loan_Amount_Term'].fillna( test['Loan_Amount_Term'].dropna().mode().values[0] )\ntest['Gender'] = test['Gender'].fillna( test['Gender'].dropna().mode().values[0] )\ntest['Married'] = test['Married'].fillna( test['Married'].dropna().mode().values[0] )\ntest['Self_Employed'] = test['Self_Employed'].fillna( test['Self_Employed'].dropna().mode().values[0] )\ntest['Gender'] = test['Gender'].map({'Female':0,'Male':1}).astype(np.int)\ntest['Married'] = test['Married'].map({'No':0,'Yes':1}).astype(np.int)\ntest['Education'] = test['Education'].map({'Not Graduate':0,'Graduate':1}).astype(np.int)\ntest['Self_Employed'] = test['Self_Employed'].map({'No':0, 'Yes':1}).astype(np.int)\n# test['Loan_Status'] = test['Loan_Status'].map({'N':0, 'Y':1}).astype(np.int)\ntest['Dependents'] = test['Dependents'].str.rstrip('+')\n# test['Loan_Amount_Term'] = test['Loan_Amount_Term'].fillna( test['Loan_Amount_Term'].dropna().mode().values[0] )\ntest['Credit_History'] = test['Credit_History'].fillna( test['Credit_History'].dropna().mode().values[0] )\ncolumn_names =['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome',\n       'Loan_Amount_Term', 'Credit_History', 'Property_Area','LoanAmount'] \ntest = test.reindex(columns = column_names)\ntest.head()","814523b3":"test.drop('Loan_ID',1,inplace=True)\n","9ec2fd70":"test = pd.get_dummies(test)\ntest.shape","abf1171c":"#test[nums] = scaler.fit(test[nums])","984f23dd":"pred_test = model.predict(test)","c4cf9155":"submission = pd.read_csv('submission.csv')","d134e34d":"submission['Loan_Status'] = pred_test\nsubmission['Loan_Status']= submission['Loan_Status'].map({1:'Y',0:'N'})\nsubmission.head()","e0af8c4a":"pd.DataFrame(submission, columns=['Loan_ID','Loan_Status']).to_csv('Final_Submission.csv')","b289fdf1":"def scaling(data,nums):\n    from sklearn.preprocessing import StandardScaler\n    scaler = StandardScaler()\n    data[nums] = scaler.fit_transform(data[nums]) ","33173b0d":"df.head()\ntrain = df.copy()\ntrain.drop('Loan_ID',1,inplace=True)\ncols = ['ApplicantIncome','CoapplicantIncome','Loan_Amount_Term','LoanAmount']\nscaling(train,cols)\ntrain = pd.get_dummies(train)\ntrain.head()","dfe62c8a":"outcome_var = 'Loan_Status'\nmodel = LogisticRegression()\npredictor_var = train.columns\nclassification_model(model, train,predictor_var,outcome_var)\n","f7984d22":"from sklearn.model_selection import StratifiedKFold","6dcf2e13":"i=1\nmean = 0\nkf = StratifiedKFold(n_splits=5,random_state=1)\nfor train_index,test_index in kf.split(X,y):\n    print ('\\n{} of kfold {} '.format(i,kf.n_splits))\n    xtr,xvl = X.loc[train_index],X.loc[test_index]\n    ytr,yvl = y[train_index],y[test_index]\n    model = LogisticRegression(random_state=1)\n    model.fit(xtr,ytr)\n    pred_test=model.predict(xvl)\n    score=accuracy_score(yvl,pred_test)\n    mean += score\n    print ('accuracy_score',score)\n    i+=1\n    pred_test = model.predict(test)\n    pred = model.predict_proba(xvl)[:,1]\n    print ('\\n Mean Validation Accuracy',mean\/(i-1))","d0e1e4c6":"from sklearn import tree\ni=1\nmean = 0\nkf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(X,y):\n    print ('\\n{} of kfold {} '.format(i,kf.n_splits))\n    xtr,xvl = X.loc[train_index],X.loc[test_index]\n    ytr,yvl = y[train_index],y[test_index]\n    model = tree.DecisionTreeClassifier(random_state=1)\n    model.fit(xtr,ytr)\n    pred_test=model.predict(xvl)\n    score=accuracy_score(yvl,pred_test)\n    mean += score\n    print ('accuracy_score',score)\n    i+=1\n    pred_test = model.predict(test)\n    pred = model.predict_proba(xvl)[:,1]\nprint ('\\n Mean Validation Accuracy',mean\/(i-1))","3c66ea09":"from sklearn.ensemble import RandomForestClassifier\ni=1\nmean = 0\nkf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(X,y):\n print ('\\n{} of kfold {} '.format(i,kf.n_splits))\n xtr,xvl = X.loc[train_index],X.loc[test_index]\n ytr,yvl = y[train_index],y[test_index]\n model = RandomForestClassifier(random_state=1, max_depth=10)\n model.fit(xtr,ytr)\n pred_test=model.predict(xvl)\n score=accuracy_score(yvl,pred_test)\n mean += score\n print ('accuracy_score',score)\n i+=1\n pred_test = model.predict(test)\n pred = model.predict_proba(xvl)[:,1]\nprint ('\\n Mean Validation Accuracy',mean\/(i-1))","04f1e7f2":"from sklearn.model_selection import GridSearchCV\n\nparamgrid = {'max_depth': list(range(1,20,2)), 'n_estimators': list(range(1,200,20))}\n\ngrid_search=GridSearchCV(RandomForestClassifier(random_state=1),paramgrid)\n\ngrid_search.fit(X_train,y_train)\nGridSearchCV(estimator=RandomForestClassifier(random_state=1),\n             param_grid={'max_depth': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19],\n                         'n_estimators': [1, 21, 41, 61, 81, 101, 121, 141, 161,\n                                          181]})\ngrid_search.best_estimator_\nRandomForestClassifier(max_depth=5, n_estimators=41, random_state=1)\ni=1\nmean = 0\nkf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(X,y):\n    print ('\\n{} of kfold {} '.format(i,kf.n_splits))\n    xtr,xvl = X.loc[train_index],X.loc[test_index]\n    ytr,yvl = y[train_index],y[test_index]\n    model = RandomForestClassifier(random_state=1, max_depth=3, n_estimators=41)\n    model.fit(xtr,ytr)\n    pred_test = model.predict(xvl)\n    score = accuracy_score(yvl,pred_test)\n    mean += score\n    print ('accuracy_score',score)\n    i+=1\n    pred_test = model.predict(test)\n    pred = model.predict_proba(xvl)[:,1]\nprint ('\\n Mean Validation Accuracy',mean\/(i-1))","2ae2ce67":"importances=pd.Series(model.feature_importances_, index=X.columns)\nimportances.plot(kind='barh', figsize=(12,8))","8c380954":"from xgboost import XGBClassifier\ni=1 \nmean = 0\nkf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True) \nfor train_index,test_index in kf.split(X,y): \n print('\\n{} of kfold {}'.format(i,kf.n_splits)) \n xtr,xvl = X.loc[train_index],X.loc[test_index] \n ytr,yvl = y[train_index],y[test_index] \n model = XGBClassifier(n_estimators=50, max_depth=4) \n model.fit(xtr, ytr) \n pred_test = model.predict(xvl) \n score = accuracy_score(yvl,pred_test) \n mean += score\n print ('accuracy_score',score)\n i+=1\n pred_test = model.predict(test)\n pred = model.predict_proba(xvl)[:,1]\nprint ('\\n Mean Validation Accuracy',mean\/(i-1))","677032f3":"submission['Loan_Status']=pred_test\nsubmission['Loan_Status'].replace(0, 'N', inplace=True)\nsubmission['Loan_Status'].replace(1, 'Y', inplace=True)\npd.DataFrame(submission, columns=['Loan_ID','Loan_Status']).to_csv('XGBoostresults.csv')","63331325":"### 3. Random Forest","d9e90f10":"### 4.Grid Search CV","419417ff":"### 5. Feature Importance","24b171ea":"### 1.Logistic Regression","b45482fb":"#### above is the sign of overfitting, we need to perform cross validation and learn the algorithm well.","ccb28f20":"### 2. Decision Tress","217e1c65":"### 6. XGBoosting","9be1f68e":"### 1.1 Predictions on test data"}}