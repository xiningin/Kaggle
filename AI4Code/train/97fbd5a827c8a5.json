{"cell_type":{"e3fa17a3":"code","741be0b2":"code","6b3bb2dd":"code","4b1edfc4":"code","08f87924":"code","2a167cf5":"code","ac57b2aa":"code","86a142fb":"code","6c331e52":"code","a62f1df1":"code","86ca2f25":"code","10bf9828":"code","2b8eca1f":"code","5f677c54":"code","7bbe9dc6":"code","e7ad22ef":"code","ae06a048":"code","c6388b71":"code","9cce773f":"code","3f9a7d83":"code","99de4884":"code","aa50a156":"code","0c0cd78d":"code","993d8bd6":"code","ddccd585":"code","0b84ebec":"code","d0e314f4":"code","c6fda97d":"code","96c0de81":"code","63dd2637":"code","b8f6be8b":"code","ac7a06b7":"code","12a0d645":"code","a6544e4e":"code","173678b2":"code","8ca49216":"code","f0bc3fac":"code","6ee36347":"code","f027f840":"code","6fe8f1f0":"code","552269bf":"code","83f83494":"code","97f234d8":"code","2d1e608e":"code","8ea5f4f4":"code","e92bb661":"code","a370aa5e":"code","50445bf1":"code","3e6602f7":"code","c43b872c":"code","b755643a":"code","06afafe0":"code","37b08466":"code","d8b0d37a":"code","1b19e2f2":"code","76be3b79":"code","619bfd19":"code","752fa1a3":"code","52023ac4":"code","abf35b03":"code","bfe3a304":"code","6c3ee5ef":"code","619a8c58":"code","05f83fce":"code","455af927":"code","db0d279a":"code","2af3657b":"code","3bcd08f4":"markdown","34f0f9d0":"markdown","df38a390":"markdown","db5a99a3":"markdown","5d0a837d":"markdown","fbb3c83c":"markdown","9b920575":"markdown","b2d2a7ee":"markdown","c850ce9a":"markdown","34a7db69":"markdown","1d4534b3":"markdown","7632bb30":"markdown","47ac7171":"markdown","30497eaa":"markdown","d65ea427":"markdown","6f4679ec":"markdown","c74bac4a":"markdown","71d5ff0b":"markdown","5d08e258":"markdown","472d1af5":"markdown","3d9705bf":"markdown","999e6fe1":"markdown","920ef30d":"markdown","8bf6f2f9":"markdown","43ead5d5":"markdown","ff8698c7":"markdown","f7083e82":"markdown","cf828ef1":"markdown","eba12418":"markdown","94c5e8f5":"markdown","783f6d1b":"markdown","f7ddd870":"markdown","6487ebcf":"markdown","005d626b":"markdown","e71ab797":"markdown","940a0729":"markdown","c904b402":"markdown","34f1cc16":"markdown","ee0b5aea":"markdown","30c85d83":"markdown","7bf25e40":"markdown","697d8b2a":"markdown","893e4e52":"markdown","6404f784":"markdown","f4e6761d":"markdown","b291b757":"markdown","71f8565c":"markdown","45974b54":"markdown","d9377240":"markdown","b3765bb0":"markdown","4f7c08ca":"markdown","1e09c83c":"markdown","d0f4a6b8":"markdown","d4d82476":"markdown","4aa340e2":"markdown","e0d24a21":"markdown","306d9787":"markdown","cfa9ced7":"markdown","e3edbc19":"markdown","580fceeb":"markdown"},"source":{"e3fa17a3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","741be0b2":"import warnings\nwarnings.filterwarnings('ignore')","6b3bb2dd":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\npd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)","4b1edfc4":"bikes = pd.read_csv(\"\/kaggle\/input\/bike-sharing-analysis-post-covid19\/day.csv\")\nbikes.head()","08f87924":"bikes.info()","2a167cf5":"print(\"shape of dataset is\" ,bikes.shape)","ac57b2aa":"bikes.describe()","86a142fb":"bikes.dtypes","6c331e52":"round(100*(bikes.isnull().sum()\/len(bikes)),2)","a62f1df1":"bikes.columns","86ca2f25":"drop_list = ['instant','dteday']\nbikes_new = bikes.drop(drop_list, axis=1)","10bf9828":"bikes_new.head()","2b8eca1f":"bikes_new.info()","5f677c54":"bikes_new['season']=bikes_new['season'].map({1:\"spring\", 2:\"summer\", 3:\"fall\", 4:\"winter\"})\nbikes_new['season'].value_counts()","7bbe9dc6":"bikes_new['weathersit']=bikes_new['weathersit'].map({1:\"clear\", 2:\"mist+cloudy\", 3:\"light_rain\/snow\", 4:\"heavy_rain\/snow\"})\nbikes_new['weathersit'].value_counts()","e7ad22ef":"bikes_new['weekday']=bikes_new['weekday'].map({0:\"Sunday\", 1:\"Monday\", 2:\"Tuesday\", 3:\"Wednesday\",4:\"Thursday\", 5:\"Friday\", 6:\"Saturday\"})\nbikes_new['weekday'].value_counts()","ae06a048":"bikes_new['mnth']=bikes_new['mnth'].map({1:\"Jan\", 2:\"Feb\", 3:\"Mar\",4:\"Apr\", 5:\"May\", 6:\"Jun\",7:\"Jul\", 8:\"Aug\", 9:\"Sep\",10:\"Oct\", 11:\"Nov\", 12:\"Dec\"})\nbikes_new['mnth'].value_counts()","c6388b71":"bikes_new.info()","9cce773f":"bikes_num=bikes_new[['temp','atemp', 'hum', 'windspeed','casual','registered','cnt']]\nsns.pairplot(bikes_num, diag_kind='kde')\nplt.show()","3f9a7d83":"plt.figure(figsize=(25, 15))\nplt.subplot(2,3,1)\nsns.boxplot(x = 'season', y = 'cnt', data = bikes_new)\nplt.subplot(2,3,2)\nsns.boxplot(x = 'mnth', y = 'cnt', data = bikes_new)\nplt.subplot(2,3,3)\nsns.boxplot(x = 'weathersit', y = 'cnt', data = bikes_new)\nplt.subplot(2,3,4)\nsns.boxplot(x = 'holiday', y = 'cnt', data = bikes_new)\nplt.subplot(2,3,5)\nsns.boxplot(x = 'weekday', y = 'cnt', data = bikes_new)\nplt.subplot(2,3,6)\nsns.boxplot(x = 'workingday', y = 'cnt', data = bikes_new)\nplt.show()","99de4884":"plt.figure(figsize = (25,15))\nax = sns.heatmap(bikes_new.corr(),square = True,annot=True, cmap=\"Reds\")\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5);","aa50a156":"bikes_new = bikes_new.drop([\"casual\",\"registered\"], axis=1)\nbikes_new.head()","0c0cd78d":"bikes_new = pd.get_dummies(bikes_new, drop_first=True)\nbikes_new.head()","993d8bd6":"from sklearn.model_selection import train_test_split\n\ndf_train, df_test = train_test_split(bikes_new, train_size = 0.7, test_size = 0.3, random_state = 14)","ddccd585":"print(\"Shape of bike dataset:\",bikes_new.shape)\nprint(\"Shape of training dataset :\",df_train.shape)","0b84ebec":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","d0e314f4":"num_vars = ['temp','atemp','hum','windspeed','cnt']\ndf_train[num_vars] = scaler.fit_transform(df_train[num_vars])\ndf_train.head()","c6fda97d":"df_train.describe()","96c0de81":"y_train = df_train.pop('cnt')\nX_train = df_train","63dd2637":"from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","b8f6be8b":"lm = LinearRegression()\nlm.fit(X_train, y_train)\n\nrfe = RFE(lm, 15)             \nrfe = rfe.fit(X_train, y_train)","ac7a06b7":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","12a0d645":"col = X_train.columns[rfe.support_]\ncol","a6544e4e":"X_train.columns[~rfe.support_]","173678b2":"X_train_rfe = X_train[col]\nX_train_rfe.head()","8ca49216":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nvif['Features'] = X_train_rfe.columns\nvif['VIF'] = [variance_inflation_factor(X_train_rfe.values, i) for i in range(X_train_rfe.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","f0bc3fac":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_train_rfe = sm.add_constant(X_train_rfe)","6ee36347":"lm = sm.OLS(y_train,X_train_rfe).fit()   # Running the linear model\nprint(lm.summary())","f027f840":"#Removing the const from the dataframe and creating a new dataframe as \"X_train_new\"\n\nX_train_new = X_train_rfe.drop([\"const\",], axis = 1)","6fe8f1f0":"X_train_new = X_train_new.drop([\"atemp\",], axis = 1)","552269bf":"vif = pd.DataFrame()\nvif['Features'] = X_train_new.columns\nvif['VIF'] = [variance_inflation_factor(X_train_new.values, i) for i in range(X_train_new.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","83f83494":"# Add a constant\nX_train_lm2 = sm.add_constant(X_train_new)\n\n# Creating and running the linear model\nlr2 = sm.OLS(y_train, X_train_lm2).fit()\nprint(lr2.summary())","97f234d8":"X_train_new = X_train_new.drop([\"windspeed\"], axis = 1)","2d1e608e":"vif = pd.DataFrame()\nvif['Features'] = X_train_new.columns\nvif['VIF'] = [variance_inflation_factor(X_train_new.values, i) for i in range(X_train_new.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","8ea5f4f4":"# Add a constant\nX_train_lm3 = sm.add_constant(X_train_new)\n\n# Creating and running the linear model\nlr3 = sm.OLS(y_train, X_train_lm3).fit()\nprint(lr3.summary())","e92bb661":"X_train_new = X_train_new.drop([\"mnth_Feb\"], axis = 1)","a370aa5e":"vif = pd.DataFrame()\nvif['Features'] = X_train_new.columns\nvif['VIF'] = [variance_inflation_factor(X_train_new.values, i) for i in range(X_train_new.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","50445bf1":"# Add a constant\nX_train_lm4 = sm.add_constant(X_train_new)\n\n# Creating and running the linear model\nlr4 = sm.OLS(y_train, X_train_lm4).fit()\nprint(lr4.summary())","3e6602f7":"X_train_new = X_train_new.drop([\"mnth_Jan\"], axis = 1)","c43b872c":"vif = pd.DataFrame()\nvif['Features'] = X_train_new.columns\nvif['VIF'] = [variance_inflation_factor(X_train_new.values, i) for i in range(X_train_new.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","b755643a":"# Add a constant\nX_train_lm5 = sm.add_constant(X_train_new)\n\n# Creating and running the linear model\nlr5 = sm.OLS(y_train, X_train_lm5).fit()\nprint(lr5.summary())","06afafe0":"X_train_new = X_train_new.drop([\"hum\"], axis = 1)","37b08466":"vif = pd.DataFrame()\nvif['Features'] = X_train_new.columns\nvif['VIF'] = [variance_inflation_factor(X_train_new.values, i) for i in range(X_train_new.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","d8b0d37a":"# Add a constant\nX_train_lm6 = sm.add_constant(X_train_new)\n\n# Creating and running the linear model\nlr6 = sm.OLS(y_train, X_train_lm6).fit()\nprint(lr6.summary())","1b19e2f2":"lr6.params","76be3b79":"y_train_pred = lr6.predict(X_train_lm6)","619bfd19":"res = y_train-y_train_pred\n# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((res), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18) ","752fa1a3":"vif = pd.DataFrame()\nvif['Features'] = X_train_new.columns\nvif['VIF'] = [variance_inflation_factor(X_train_new.values, i) for i in range(X_train_new.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","52023ac4":"num_vars = ['temp', 'atemp', 'hum', 'windspeed','cnt']\n\ndf_test[num_vars] = scaler.transform(df_test[num_vars])","abf35b03":"df_test.describe()","bfe3a304":"y_test = df_test.pop('cnt')\nX_test = df_test\nX_test.info()","6c3ee5ef":"#Selecting the variables that were part of final model.\ncol1=X_train_new.columns\nX_test=X_test[col1]\n# Adding constant variable to test dataframe\nX_test_lm6 = sm.add_constant(X_test)\nX_test_lm6.info()","619a8c58":"# Making predictions using the final model (lr6)\ny_pred = lr6.predict(X_test_lm6)","05f83fce":"# Plotting y_test and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y_test, y_pred, alpha=.5)\nfig.suptitle('y_test vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y_test', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16) \nplt.show()","455af927":"from sklearn.metrics import r2_score\nr2_score(y_test, y_pred)","db0d279a":"r2=0.8199435928434153","2af3657b":"# n is number of rows in X\nn = X_test.shape[0]\n\n# Number of features (predictors, p) is the shape along axis 1\np = X_test.shape[1]\n\n# We find the Adjusted R-squared using the formula\nadjusted_r2 = 1-(1-r2)*(n-1)\/(n-p-1)\nadjusted_r2","3bcd08f4":"### Visualising numerical variables through pairplot","34f0f9d0":"### Visualising categorical variable w.r.t target variable \"cnt\" via boxplot","df38a390":"# Reading and understanding the Data","db5a99a3":"### Due to low Multicollinearity between the predictors and significant p-values, considering the linear model 6 as our final model.","5d0a837d":"### Creating dummy for all the categorical variable","fbb3c83c":"#### Inferences\n\n - temp and atemp shows a exact linear relationship in between them and has a linear relationship with the target variable. Further, we'll keep one of these for further analysis.\n \n - casual and registered shows a linear realtionship with target variable cnt as sum of casual and registered booking is equal to the target variable cnt. Further, we'll drop both these variables to make our model unbiased.\n    \n - windspeed and hum shows a very low negative linear relationship with target variable cnt. ","9b920575":"### Checking for assumptions","b2d2a7ee":"# Data Modelling and Evaluation","c850ce9a":"Removing the \"hum\" feature due to high VIF","34a7db69":"#### Inferences\n - Variables \"casual\" and \"registered\" are highly correlated with our target variable \"cnt\". The realtionship between them is CNT = Casual + Registered . Hence, dropping the casual and registered variable.\n \n - Also, the variable \"temp\" and \"atemp\" also show a very high correlation, but we'll decide which feature should be kept further in analysis via RFE and VIF","1d4534b3":"# Problem Statement\n\nA bike-sharing system is a service in which bikes are made available for shared use to individuals on a short term basis for a price or free. Many bike share systems allow people to borrow a bike from a \"dock\" which is usually computer-controlled wherein the user enters the payment information, and the system unlocks it. This bike can then be returned to another dock belonging to the same system.\n\n\nA US bike-sharing provider RapidBikes has recently suffered considerable dips in their revenues due to the ongoing Corona pandemic. The company is finding it very difficult to sustain in the current market scenario. So, it has decided to come up with a mindful business plan to be able to accelerate its revenue as soon as the ongoing lockdown comes to an end, and the economy restores to a healthy state. \n\n\nIn such an attempt, RapidBikes aspires to understand the demand for shared bikes among the people after this ongoing quarantine situation ends across the nation due to Covid-19. They have planned this to prepare themselves to cater to the people's needs once the situation gets better all around and stand out from other service providers and make huge profits.\n\n\nThey have contracted a consulting company to understand the factors on which the demand for these shared bikes depends. Specifically, they want to understand the factors affecting the demand for these shared bikes in the American market. The company wants to know:\n\n    Which variables are significant in predicting the demand for shared bikes.\n    How well those variables describe the bike demands\n\nBased on various meteorological surveys and people's styles, the service provider firm has gathered a large dataset on daily bike demands across the American market based on some factors. \n\n\n## Business Goal:\nYou are required to model the demand for shared bikes with the available independent variables. It will be used by the management to understand how exactly the demands vary with different features. They can accordingly manipulate the business strategy to meet the demand levels and meet the customer's expectations. Further, the model will be a good way for management to understand the demand dynamics of a new market. ","7632bb30":"There are no null values in the dataset","47ac7171":"Checking VIF","30497eaa":"### Scaling for all the numerical variables","d65ea427":"Below mentioned variables are continous in nature\n - temp\n - atemp\n - hum\n - windspeed\n - casual\n - registered\n - cnt","6f4679ec":"\nDropping the below mentioned columns: \n- instant : It's only an index value\n- dteday : This has the date, Since we already have seperate columns for 'year' & 'month', removing this column\n\nSaving the new dataframe as \"bikes_new\" in order to preserve the orginal dataframe","c74bac4a":"## Final Results\n\n    Train R^2 :0.818\n    Train Adjusted R^2 :0.815\n    Test R^2 :0.819\n    Test Adjusted R^2 :0.811\n\n### This model seems to be really good as this fits the train and test set without much variance","71d5ff0b":"## Linear Model 5","5d08e258":"### Visualising the correaltion between the variables via heatmap","472d1af5":"### Selecting the variables via RFE","3d9705bf":"## Linear Model 2","999e6fe1":"Importing tha library and diving the dataset such that 70% is allocated to train set and 30% is for test set\n\nChoosing the random_state=14 as this will always perform the same split whenever the command is executed","920ef30d":"#### Inferences\nThere are 6 categorical variables in the dataset.\n\n - season: Almost 32% of the bike booking were happening in faal season with a median of approox 5000 booking. This was followed by Summer & Winter with 27% & 25% of total booking. Season can be a good predictor for the target variable.\n\n - mnth: Almost 10% of the bike booking were happening in the between May to September with a median of over 4000 booking per month. Mnth has some trend for bookings and can be a good predictor for the target variable.\n    \n - weathersit: Almost 65% of the bike booking happened during Clear weather situation with a median of close to 5000 booking. This was followed by Misty+Cloudy weather situation with 30% of total booking. Weathersit does show some interesting trend towards the bike bookings can be a good predictor for the target variable.\n    \n - holiday: Almost 97.6% of the bike booking were happening when it is not a holiday .Holiday may not be a good predictor for the target variable.\n    \n - weekday: weekday variable shows very close trend (between 13% to 15% of total booking on all days of the week) having their independent medians between 4000 to 5000 bookings. This variable can have some or no influence towards the target variable which shall be decided further.\n    \n - workingday: Almost 70% of the bike booking were happening in \u2018workingday\u2019 with a median of close to 5000 booking. workingday is an important variable but might have high correaltion with other independent variables which shall be analysed further  ","8bf6f2f9":"We conclude that this model satifies the assumptions of linerar regression as all the features have VIF > 5 denoting weak relationship in between the independent variables and error terms are normally distributed with mean zero.","43ead5d5":"Removing the \"atemp\" feature due to high VIF and high p-value","ff8698c7":"Removing the \"mnth_Feb\" feature due to high p-value","f7083e82":" #### Looking at the data, there seems to be some fields that are categorical in nature, but is integer\/float type.\n \n Converting the below mentioned categorical variables to object datatype by mapping\n - season\n - weathersit\n - weekday\n - mnth","cf828ef1":"Below steps will be followed\n - Create Dummy variable\n - Drop original variable for which the dummy was created\n - Drop first dummy variable for each set of dummies created.","eba12418":"Running RFE with the output number of the variable equal to 15","94c5e8f5":"### Checking the VIF\n\nThis will create a dataframe containing names of all the feature variables and their respective VIFs","783f6d1b":"# Data Preperation I","f7ddd870":"### Checking and removing the redundant columns","6487ebcf":"### MAKING PREDICTION USING FINAL MODEL \nNow that we have fitted the model and checked the assumptions, it's time to go ahead and make predictions using the final model (lr7)\n\nApplying the scaling on the test set","005d626b":"### Diving dataset into test and train","e71ab797":"Checking VIF","940a0729":"## The equation of best fitted line based on our final 6:\n\n - cnt = 0.225493 + (yr \u00d7 0.237066) + (temp \u00d7 0.420134) - (season_spring \u00d7 0.124774) + (season_winter \u00d70.074333) -  (mnth_Dec \u00d7 0.047587) \u2212 (mnth_Jul \u00d7 0.078552) \u2212 (mnth_Nov \u00d7 0.058535) + (mnth_Sep x 0.057056) - (weathersit_light_rain\/snow x 0.264492) - (weathersit_mist+cloudy x 0.073738) ","c904b402":"# Data Preperation II","34f1cc16":"### Checking the sturcture of data","ee0b5aea":"### Checking for null values is the data","30c85d83":"### Identification of variables\n\n Below mentioned variables are binary in nature:\n - yr\n - holiday","7bf25e40":"## Linear Model 4","697d8b2a":"# Importing Important Libraries","893e4e52":"# Data Visualisation","6404f784":"Removing the \"mnth_Jan\" feature due to high p-value","f4e6761d":"## As per our final Model, the top 3 predictor variables that influences the bike booking are:\n\n - Temperature (temp) : The coefficient value of \u20180.420134\u2019 indicates that a unit increase in temp variable increases the bike renting numbers by 0.420134 units.\n - Weather Situation (weathersit_light_rain\/snow): The coefficient value of \u2018-0.264492\u2019 indicates that if there is light rain or snow,bike renting numbers decreases by 0.264492 units.\n - Year (yr): A coefficient value of \u20180.2308\u2019 indicates that the total bike renting has gone up by 23% from year 2018 to year 2019.\n \n### The next important predictor features are:\n  - Season : The renting goes up by 0.074333 units in the winter season whereas the renting rate falls by 0.124774 in the spring season\n  - Month (mnth) : The renting goes up in the month of September by 0.057056 units whereas the renting falls in the month of July, November and December by 0.078552 , 0.058535 and 0.047587 respecitively","b291b757":"#### Inference :\n   - Dataset has 730 rows and 16 columns.\n   - Except one dteday column, all other are either float or integer type.\n   - We will analyse the categorical variables and onvert them to as required.","71f8565c":"Checking VIF","45974b54":"Removing the \"windspeed\" due to high VIF","d9377240":"Checking VIF","b3765bb0":"All Categorical variables are now converted to object data type in order to convert them into dummy variables later","4f7c08ca":"Checking VIF","1e09c83c":" - Multicollinearity ","d0f4a6b8":"# Final Model Interpretation\nHypothesis Testing:\n\nHypothesis testing states that:\n\n    H0:B1=B2=...=Bn=0\n    H1: at least one Bi!=0\n\nlr6 model coefficient values\n\n    const                         0.225493\n    yr                            0.237066\n    temp                          0.420134\n    season_spring                -0.124774\n    season_winter                 0.074333\n    mnth_Dec                     -0.047587\n    mnth_Jul                     -0.078552\n    mnth_Nov                     -0.058535\n    mnth_Sep                      0.057056\n    weathersit_light_rain\/snow   -0.264492\n    weathersit_mist+cloudy       -0.073738\n    \n#### Inference\nFrom the lr6 model summary, it is evident that all our coefficients are not equal to zero which means We REJECT the NULL HYPOTHESIS","d4d82476":"## Linear Model 6","4aa340e2":"Creating a dataframe with the columns selected via RFE","e0d24a21":"### Dividing the dataset into X and y","306d9787":"# Final Report","cfa9ced7":"## Linear Model 3","e3edbc19":"## Creating linear Model using Stats Model\n\n## Linear model 1","580fceeb":" - Distribution of Error Terms"}}