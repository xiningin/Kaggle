{"cell_type":{"d7a57cd7":"code","f80b4ecc":"code","06dca534":"code","87da9e02":"code","00395c16":"code","f0e876ae":"code","08be770d":"code","36abcbba":"code","49d634f6":"code","24b72aa3":"code","511c7497":"code","c884f431":"code","f3c0abe2":"code","d2a5a401":"code","4213c3b5":"code","b91d1e9c":"markdown"},"source":{"d7a57cd7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense,Activation,Dropout\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\nfrom xgboost import XGBClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\n\n\nfrom keras.callbacks import EarlyStopping\nimport math\n","f80b4ecc":"df=pd.read_csv('..\/input\/heart.csv',delimiter=',')\ndf.head(3)","06dca534":"df.corr()","87da9e02":"fig, ax = plt.subplots(figsize=(15,15))\nsns.heatmap(df.corr(),annot=True, linewidths=.5,ax=ax)","00395c16":"label=df['target']\ndf.shape\ndel df['target']\ndf.shape","f0e876ae":"sns.countplot(label)","08be770d":"X_train,Y_train,X_test,Y_test=train_test_split(df,label,test_size=0.3,random_state=0)\nprint(X_train.shape)\nprint(Y_train.shape)\nprint(X_test.shape)\nprint(Y_test.shape)\n","36abcbba":"X_valid,X_rftest,Y_valid,Y_rftest=train_test_split(Y_train,Y_test,test_size=0.5,random_state=0)","49d634f6":"#Hyperparameter tuning\nmaxi=0\nl=np.arange(1,5000,25)\nfor x in range(len(l)):\n    model=RandomForestClassifier(random_state=l[x],verbose=1)\n    model.fit(X_train,X_test)\n    a=model.predict(X_valid)\n    if(maxi<round(accuracy_score(a,Y_valid)*100,2)):\n        maxi=round(accuracy_score(a,Y_valid)*100,2)\n        c1=l[x]\nprint(c1)\n\n    \n","24b72aa3":"maxi=0\nfor i in range(c1-25,c1+25):\n    model=RandomForestClassifier(random_state=i,verbose=1)\n    model.fit(X_train,X_test)\n    a=model.predict(X_valid)\n    if(maxi<round(accuracy_score(a,Y_valid)*100,2)):\n        maxi=round(accuracy_score(a,Y_valid)*100,2)\n        c1=i\nmodel=RandomForestClassifier(random_state=c1)\nmodel.fit(X_train,X_test)\npredict1=model.predict(Y_train)\nweight1=round(accuracy_score(predict1,Y_test)*100,2)\nprint('Random forest accuracy score:',round(accuracy_score(predict1,Y_test)*100,2))\nc1=round(accuracy_score(predict1,Y_test)*100,2)\n","511c7497":"model=svm.SVC(kernel='linear',verbose=1,gamma='scale', decision_function_shape='ovo')\nmodel.fit(X_train,X_test)\npredict2=model.predict(Y_train)\nc=0\nfor i in range(len(predict2)):\n    if(predict2[i]==Y_test.iloc[i]):\n        c+=1\nc2=(c\/len(predict2))*100\nprint('Linear Svm Accuracy Score is',c2)\nweight2=c2\n\n","c884f431":"model = XGBClassifier(objective=\"binary:logistic\")\nmodel.fit(X_train, X_test)\npredict3=model.predict(Y_train)\nc=0\nfor i in range(len(predict3)):\n    if(predict3[i]==Y_test.iloc[i]):\n        c+=1\nc3=(c\/len(predict3))*100\nprint('XGBoost Accuracy Score is',c3)\nweight3=c3\n","f3c0abe2":"X_train=np.expand_dims(X_train, axis=2) \nY_train=np.expand_dims(Y_train, axis=2)\nes=EarlyStopping(patience=7)\nmodel=Sequential()\nmodel.add(LSTM(13,input_shape=(13,1)))\nmodel.add(Dense(output_dim=1))\nmodel.add(Activation('sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\nmodel.fit(X_train,X_test,epochs=100,batch_size=1,verbose=1,callbacks=[es])\npredict4=model.predict(Y_train)\nc4=model.evaluate(Y_train,Y_test)\nweight4=c4[1]\n","d2a5a401":"print('SVM Accuracy Score:',c2)\nprint('XGBoost Accuracy Score:',c3)\nprint('LSTM accuracy Score:',c4[1]*100)\nprint('Random Forest Classifier:',c1)","4213c3b5":"l=[]\nfor i in range(len(Y_train)):\n    c1,c2=0,0\n    if(predict1[i]==0):\n        c1+=weight1\n    else:\n        c2+=weight1\n    if(predict2[i]==0):\n        c1+=weight2\n    else:\n        c2+=weight2\n    if(predict3[i]==0):\n        c1+=weight3\n    else:\n        c2+=weight3\n    if(predict4[i]==0):\n        c1+=weight4\n    else:\n        c2+=weight4\n    if(c1>c2):\n        l.append(0)\n    else:\n        l.append(1)\nc=0\n\nfor i in range(len(Y_train)):\n    if(l[i]==Y_test.iloc[i]):\n        c+=1\nprint('Accuracy of Voting Based Model',c\/len(Y_train))\n    \n        \n        \n","b91d1e9c":"**Voting-based-Model**"}}