{"cell_type":{"af544c40":"code","814be718":"code","a4f23a36":"code","195e979c":"code","35b7e439":"code","716b7310":"code","5988a29a":"code","38d63820":"code","70192548":"code","d0ce4b4f":"code","0f8b5d7a":"code","53bf9fa4":"code","9aeacf01":"code","99a7e3c0":"code","de2893d3":"code","9a8f521d":"code","47acc17b":"code","07fdefed":"code","07d659ef":"code","796ebadf":"code","9e7e958b":"code","f90eb334":"code","8ab1b6c1":"code","321ee4d6":"code","36e97a1b":"code","76d99700":"code","37e7c31c":"code","e9c8c302":"code","6168d47f":"code","ab171e1e":"code","d202e7de":"code","4f219738":"code","2bae1375":"code","4b54386c":"code","5145eb51":"code","e82a2764":"code","4f7c02a0":"code","396bd81e":"code","053a0e87":"code","2d87a186":"code","788efb96":"code","64ae485c":"code","6c546234":"code","df6de999":"code","e58251d2":"code","4d18e202":"code","d28f1eb6":"code","754c7652":"code","4a8f3f27":"code","8a43d9f1":"markdown","15a5f5e7":"markdown","60cb8f01":"markdown","4949fd5e":"markdown","6457beae":"markdown","f5effe17":"markdown","56f449a2":"markdown","706c9326":"markdown"},"source":{"af544c40":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","814be718":"insurance_df=pd.read_csv(\"..\/input\/insurance.csv\")","a4f23a36":"insurance_df.shape","195e979c":"insurance_df.isna().sum()","35b7e439":"insurance_df.index","716b7310":"insurance_df.head(10)","5988a29a":"import matplotlib.pyplot as plt\n\n%matplotlib inline\nimport seaborn as sns","38d63820":"insurance_df.describe()","70192548":"insur_corr=insurance_df.corr()\ninsur_corr","d0ce4b4f":"insur_cov=insurance_df.cov()\ninsur_cov","0f8b5d7a":"sns.heatmap(insur_corr,vmin=-1,vmax=1,center=0,annot=True)","53bf9fa4":"#sns.pairplot(data=insurance_df,hue='children')","9aeacf01":"plt.figure(figsize=(14, 7))\nsns.scatterplot(x=insurance_df['age'], y=insurance_df['expenses'],hue=insurance_df['children'],size=insurance_df['bmi'])","99a7e3c0":"plt.figure(figsize=(14, 7))\nsns.scatterplot(x=insurance_df['bmi'], y=insurance_df['expenses'],hue=insurance_df['children'],size=insurance_df['age'])","de2893d3":"sns.pairplot(data=insurance_df,hue='region')","9a8f521d":"plt.figure(figsize=(14, 7))\nsns.scatterplot(x=insurance_df['age'], y=insurance_df['expenses'],hue=insurance_df['region'],size=insurance_df['bmi'])","47acc17b":"plt.figure(figsize=(14, 7))\nsns.scatterplot(x=insurance_df['bmi'], y=insurance_df['expenses'],hue=insurance_df['region'],size=insurance_df['age'])","07fdefed":"sns.pairplot(data=insurance_df,hue='smoker')","07d659ef":"plt.figure(figsize=(14, 7))\nsns.scatterplot(x=insurance_df['age'], y=insurance_df['expenses'],hue=insurance_df['smoker'],size=insurance_df['bmi'])","796ebadf":"plt.figure(figsize=(14, 7))\nsns.scatterplot(x=insurance_df['bmi'], y=insurance_df['expenses'],hue=insurance_df['smoker'],size=insurance_df['age'])","9e7e958b":"sns.pairplot(data=insurance_df,hue='sex')","f90eb334":"plt.figure(figsize=(14, 7))\nsns.scatterplot(x=insurance_df['age'], y=insurance_df['expenses'],hue=insurance_df['sex'],size=insurance_df['bmi'])","8ab1b6c1":"plt.figure(figsize=(14, 7))\nsns.scatterplot(x=insurance_df['bmi'], y=insurance_df['expenses'],hue=insurance_df['sex'],size=insurance_df['age'])","321ee4d6":"# Importing necessary package for creating model\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n","36e97a1b":"cat_col=['smoker','region','sex']\nnum_col=[i for i in insurance_df.columns if i not in cat_col]\nnum_col","76d99700":"# one-hot encoding\none_hot=pd.get_dummies(insurance_df[cat_col])\ninsur_procsd_df=pd.concat([insurance_df[num_col],one_hot],axis=1)\ninsur_procsd_df.head(10)","37e7c31c":"#label encoding\ninsr_procsd_df_label=insurance_df\nfrom sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\nfor i in cat_col:\n    insr_procsd_df_label[i] = label_encoder.fit_transform(insr_procsd_df_label[i])\ninsr_procsd_df_label.head(10)","e9c8c302":"#using one hot encoding\nX=insur_procsd_df.drop(columns='expenses')\ny=insurance_df[['expenses']]","6168d47f":"train_X, test_X, train_y, test_y = train_test_split(X,y,test_size=0.3,random_state=1234)","ab171e1e":"model = LinearRegression()\n\nmodel.fit(train_X,train_y)","d202e7de":"# Print Model intercept and co-efficent\nprint(\"Model intercept\",model.intercept_,\"Model co-efficent\",model.coef_)","4f219738":"cdf = pd.DataFrame(data=model.coef_.T, index=X.columns, columns=[\"Coefficients\"])\ncdf","2bae1375":"# Print various metrics\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n\nprint(\"Predicting the train data\")\ntrain_predict = model.predict(train_X)\nprint(\"Predicting the test data\")\ntest_predict = model.predict(test_X)\nprint(\"MAE\")\nprint(\"Train : \",mean_absolute_error(train_y,train_predict))\nprint(\"Test  : \",mean_absolute_error(test_y,test_predict))\nprint(\"====================================\")\nprint(\"MSE\")\nprint(\"Train : \",mean_squared_error(train_y,train_predict))\nprint(\"Test  : \",mean_squared_error(test_y,test_predict))\nprint(\"====================================\")\nimport numpy as np\nprint(\"RMSE\")\nprint(\"Train : \",np.sqrt(mean_squared_error(train_y,train_predict)))\nprint(\"Test  : \",np.sqrt(mean_squared_error(test_y,test_predict)))\nprint(\"====================================\")\nprint(\"R^2\")\nprint(\"Train : \",r2_score(train_y,train_predict))\nprint(\"Test  : \",r2_score(test_y,test_predict))\nprint(\"MAPE\")\nprint(\"Train : \",np.mean(np.abs((train_y - train_predict) \/ train_y)) * 100)\nprint(\"Test  : \",np.mean(np.abs((test_y - test_predict) \/ test_y)) * 100)\n","4b54386c":"#Plot actual vs predicted value\nplt.figure(figsize=(10,7))\nplt.title(\"Actual vs. predicted expenses\",fontsize=25)\nplt.xlabel(\"Actual expenses\",fontsize=18)\nplt.ylabel(\"Predicted expenses\", fontsize=18)\nplt.scatter(x=test_y,y=test_predict)","5145eb51":"#using label encoding\nX=insur_procsd_df.drop(columns='expenses')\ny=insr_procsd_df_label[['expenses']]","e82a2764":"# split data into train and test\ntrain_X, test_X, train_y, test_y = train_test_split(X,y,test_size=0.3,random_state=2000)","4f7c02a0":"# Create Linear regression model with train and test data\nmodel = LinearRegression()\n\nmodel.fit(train_X,train_y)","396bd81e":"# Print Model intercept and co-efficent\nprint(\"Model intercept\",model.intercept_,\"Model co-efficent\",model.coef_)","053a0e87":"cdf = pd.DataFrame(data=model.coef_.T, index=X.columns, columns=[\"Coefficients\"])\ncdf","2d87a186":"# Print various metrics\n\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n\nprint(\"Predicting the train data\")\ntrain_predict = model.predict(train_X)\nprint(\"Predicting the test data\")\ntest_predict = model.predict(test_X)\nprint(\"MAE\")\nprint(\"Train : \",mean_absolute_error(train_y,train_predict))\nprint(\"Test  : \",mean_absolute_error(test_y,test_predict))\nprint(\"====================================\")\nprint(\"MSE\")\nprint(\"Train : \",mean_squared_error(train_y,train_predict))\nprint(\"Test  : \",mean_squared_error(test_y,test_predict))\nprint(\"====================================\")\nimport numpy as np\nprint(\"RMSE\")\nprint(\"Train : \",np.sqrt(mean_squared_error(train_y,train_predict)))\nprint(\"Test  : \",np.sqrt(mean_squared_error(test_y,test_predict)))\nprint(\"====================================\")\nprint(\"R^2\")\nprint(\"Train : \",r2_score(train_y,train_predict))\nprint(\"Test  : \",r2_score(test_y,test_predict))\nprint(\"MAPE\")\nprint(\"Train : \",np.mean(np.abs((train_y - train_predict) \/ train_y)) * 100)\nprint(\"Test  : \",np.mean(np.abs((test_y - test_predict) \/ test_y)) * 100)","788efb96":"#Plot actual vs predicted value\nplt.figure(figsize=(10,7))\nplt.title(\"Actual vs. predicted expenses\",fontsize=25)\nplt.xlabel(\"Actual expenses\",fontsize=18)\nplt.ylabel(\"Predicted expenses\", fontsize=18)\nplt.scatter(x=test_y,y=test_predict)","64ae485c":"print(\"MAPE\")\nprint(\"Train : \",np.mean(np.abs((train_y - train_predict) \/ train_y)) * 100)\nprint(\"Test  : \",np.mean(np.abs((test_y - test_predict) \/ test_y)) * 100)","6c546234":"from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import accuracy_score\nfrom math import sqrt","df6de999":"X_train, X_test, y_train, y_test = train_test_split(\nX, y, test_size = 0.3, random_state = 100)\ny_train=np.ravel(y_train)\ny_test=np.ravel(y_test)","e58251d2":"rmse_train_dict={}\nrmse_test_dict={}\ndf_len=round(sqrt(len(insur_procsd_df)))\n#Train Model and Predict  \nfor k in range(3,df_len):\n    neigh = KNeighborsRegressor(n_neighbors = k).fit(X_train,y_train)\n    yhat_train = neigh.predict(X_train)\n    yhat = neigh.predict(X_test)\n    test_rmse=sqrt(mean_squared_error(y_test,yhat))\n    train_rmse=sqrt(mean_squared_error(y_train,yhat_train))\n    rmse_train_dict.update(({k:train_rmse}))\n    rmse_test_dict.update(({k:test_rmse}))\n    print(\"RMSE for train : \",train_rmse,\" test : \",test_rmse,\" difference between train and test :\",abs(train_rmse-test_rmse),\" with k =\",k)","4d18e202":"elbow_curve_train = pd.Series(rmse_train_dict,index=rmse_train_dict.keys())\nelbow_curve_test = pd.Series(rmse_test_dict,index=rmse_test_dict.keys())\nelbow_curve_train.head(10)","d28f1eb6":"ax=elbow_curve_train.plot(title=\"RMSE of train VS Value of K \")\nax.set_xlabel(\"K\")\nax.set_ylabel(\"RMSE of train\")\n","754c7652":"ax=elbow_curve_test.plot(title=\"RMSE of test VS Value of K \")\nax.set_xlabel(\"K\")\nax.set_ylabel(\"RMSE of test\")\n","4a8f3f27":"#for K in range(25):\n    #K_value = K+1\n    #neigh = KNeighborsRegressor(n_neighbors = K_value, weights='uniform', algorithm='auto')\n    #neigh.fit(X_train, y_train) \n    #y_pred = neigh.predict(X_test)\n    #print(\"MAPE\")\n    #print(\"Train : \",np.mean(np.abs((train_y - train_predict) \/ train_y)) * 100)\n    #print(\"Test  : \",np.mean(np.abs((test_y - test_predict) \/ test_y)) * 100)","8a43d9f1":"**With respect to categorical variable \"sex\" from above visualizations , we see slight relationship between gender and expense.female member tends to have high expense than male member particularly when you see lower part of graph between age and expense**","15a5f5e7":"**With respect to categorical variable \"children\" from above visualization , we  see slight relation between children and expenses particularly in lower part of age vs expense graph**","60cb8f01":"**Above correlation and covariance value inform that there exist strong relationship between expenses and {age(0.3) ,bmi(0.2)} for numerical variables**","4949fd5e":"****I dont see much difference between using label encoding and one-hot encoding. Also my predicted expenses value not following linear pattern with actual expenses****","6457beae":"**From the above output we see RMSE value remains low for train and test with k=23**","f5effe17":"**With respect to categorical variable \"smoker\" from above visualizations , it clearly says smoker have high expenses comparted to non-smoker**","56f449a2":"**With respect to categorical variable \"region\" from above visualizations , we  see slight dependency between region and expenses.south east people have more expenses followed by southwest,northwest and northeast**","706c9326":"**We will try to implement knn for this Linear regression to see how accuracy calculated**"}}