{"cell_type":{"f76265ed":"code","a87f0420":"code","b78bd1c8":"code","43e9c88e":"code","03e69742":"code","dbd844fc":"code","ff8d320b":"code","f6b2786d":"code","9f3b5cd5":"code","241dd212":"code","03c052e7":"code","8589376f":"code","51507137":"code","3d73cad4":"code","769cbd53":"code","3104e161":"code","7e6107f0":"code","dd8a1499":"markdown"},"source":{"f76265ed":"import numpy as np\nimport pandas as pd\nimport datetime\nimport os\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n\ndef display_all(df):\n    with pd.option_context(\"display.max_rows\", 1000): \n        with pd.option_context(\"display.max_columns\", 1000): \n            display(df.tail().transpose())\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a87f0420":"train_raw = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-1\/train.csv\")\ntest_raw = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-1\/test.csv\")\nsub =  pd.read_csv(\"..\/input\/covid19-global-forecasting-week-1\/submission.csv\")\ncountry_data_raw = pd.read_csv(\"..\/input\/countries-of-the-world\/countries of the world.csv\")\npop_data_raw = pd.read_csv(\"..\/input\/population-by-country-2020\/population_by_country_2020.csv\")\npollution_raw = pd.read_csv(\"..\/input\/pollution-by-country-for-covid19-analysis\/region_pollution.csv\")\noverweight_raw = pd.read_csv(\"..\/input\/who-overweight-by-country-2016\/WHO_overweightByCountry_2016.csv\")\nobese_raw = pd.read_csv(\"..\/input\/who-obesity-by-country-2016\/WHO_obesityByCountry_2016.csv\")\necon_raw = pd.read_csv(\"..\/input\/the-economic-freedom-index\/economic_freedom_index2019_data.csv\", encoding= \"ISO-8859-1\")\ncountryinfo_raw = pd.read_csv(\"..\/input\/countryinfo\/covid19countryinfo.csv\")\nweather_raw = pd.read_csv(\"..\/input\/weather-data\/training_data_with_weather_info.csv\")\nhappiness_raw = pd.read_csv(\"..\/input\/world-happiness-report-2020\/WHR20_DataForFigure2.1.csv\")","b78bd1c8":"# Data on country response\ndef clean_response(df_raw):\n    df = df_raw.copy().drop(['pop', 'density', 'medianage', 'urbanpop'], axis=1)\n    print('The following countries are missing or have different names to those in train_raw:\\n', list(set(list(train_raw['Country\/Region'])) - set(list(df['country']))))\n    for col in ['quarantine', 'schools', 'restrictions']:\n        df[col] = pd.to_datetime(df[col])\n    return df.dropna(axis=1, how='all').rename(columns={'country': 'Country'})\n\nresponse = clean_response(countryinfo_raw)\ndisplay_all(response)","43e9c88e":"# Air pollution data\npollution = pollution_raw.copy().rename(columns={'Region': 'Country'})\nprint('The following countries are missing or have different names to those in train_raw:\\n', list(set(list(train_raw['Country\/Region'])) - set(list(pollution['Country']))))\ndisplay_all(pollution)","03e69742":"# Overweight data\ndef clean_overweight(df_raw):\n    df = df_raw.copy()\n    df.columns = ['Country', 'CombinedOverweight', 'MaleOverweight', 'FemaleOverweight']\n    \n    try_me = df['Country'] == 'Congo'\n    df_try = df.copy()[try_me]\n    df_try['Country'] = 'Republic of the Congo'\n    df = df.append([df_try], ignore_index=True)\n    \n    try_me = df['Country'] == 'Gambia'\n    df_try = df.copy()[try_me]\n    df_try['Country'] = 'The Gambia'\n    df = df.append([df_try], ignore_index=True)\n    \n    df.loc[df['Country']=='C\u00f4te d\\'Ivoire','Country'] = 'Cote d\\'Ivoire'\n    df.loc[df['Country']=='United States of America','Country'] = 'US'\n    df.loc[df['Country']=='United Kingdom of Great Britain and Northern Ireland','Country'] = 'United Kingdom'\n    df.loc[df['Country']=='Republic of North Macedonia','Country'] = 'North Macedonia'\n    df.loc[df['Country']=='Taiwan','Country'] = 'Taiwan*'\n    df.loc[df['Country']=='Republic of Korea','Country'] = 'Korea, South'\n    df.loc[df['Country']=='Gambia','Country'] = 'Gambia, The'\n    df.loc[df['Country']=='Congo','Country'] = 'Congo (Brazzaville)'\n    df.loc[df['Country']=='Democratic Republic of the Congo','Country'] = 'Congo (Kinshasa)'\n    df.loc[df['Country']=='Bahamas','Country'] = 'The Bahamas'\n    df.loc[df['Country']=='United Republic of Tanzania','Country'] = 'Tanzania'\n    df.loc[df['Country']=='Viet Nam','Country'] = 'Vietnam'\n    df.loc[df['Country']=='Republic of Moldova','Country'] = 'Moldova'\n    df.loc[df['Country']=='Iran (Islamic Republic of)','Country'] = 'Iran'\n    df.loc[df['Country']=='Brunei Darussalam','Country'] = 'Brunei'\n    df.loc[df['Country']=='Russian Federation','Country'] = 'Russia'\n    df.loc[df['Country']=='Venezuela (Bolivarian Republic of)','Country'] = 'Venezuela'\n    df.loc[df['Country']=='Bolivia (Plurinational State of)','Country'] = 'Bolivia'\n    \n    print('The following countries are missing or have different names to those in train_raw:\\n', list(set(list(train_raw['Country\/Region'])) - set(list(df['Country']))))\n    print('Impute missing values later')\n    \n    return df\n    \noverweight = clean_overweight(overweight_raw)\ndisplay_all(overweight)","dbd844fc":"# Obesity data\ndef clean_obesity(df_raw):\n    df = df_raw.copy()\n    df.columns = ['Country', 'CombinedObesity', 'MaleObesity', 'FemaleObesity']\n    \n    try_me = df['Country'] == 'Congo'\n    df_try = df.copy()[try_me]\n    df_try['Country'] = 'Republic of the Congo'\n    df = df.append([df_try], ignore_index=True)\n    \n    try_me = df['Country'] == 'Gambia'\n    df_try = df.copy()[try_me]\n    df_try['Country'] = 'The Gambia'\n    df = df.append([df_try], ignore_index=True)\n    \n    df.loc[df['Country']=='C\u00f4te d\\'Ivoire','Country'] = 'Cote d\\'Ivoire'\n    df.loc[df['Country']=='United States of America','Country'] = 'US'\n    df.loc[df['Country']=='United Kingdom of Great Britain and Northern Ireland','Country'] = 'United Kingdom'\n    df.loc[df['Country']=='Republic of North Macedonia','Country'] = 'North Macedonia'\n    df.loc[df['Country']=='Taiwan','Country'] = 'Taiwan*'\n    df.loc[df['Country']=='Republic of Korea','Country'] = 'Korea, South'\n    df.loc[df['Country']=='Gambia','Country'] = 'Gambia, The'\n    df.loc[df['Country']=='Congo','Country'] = 'Congo (Brazzaville)'\n    df.loc[df['Country']=='Democratic Republic of the Congo','Country'] = 'Congo (Kinshasa)'\n    df.loc[df['Country']=='Bahamas','Country'] = 'The Bahamas'\n    df.loc[df['Country']=='United Republic of Tanzania','Country'] = 'Tanzania'\n    df.loc[df['Country']=='Viet Nam','Country'] = 'Vietnam'\n    df.loc[df['Country']=='Republic of Moldova','Country'] = 'Moldova'\n    df.loc[df['Country']=='Iran (Islamic Republic of)','Country'] = 'Iran'\n    df.loc[df['Country']=='Brunei Darussalam','Country'] = 'Brunei'\n    df.loc[df['Country']=='Russian Federation','Country'] = 'Russia'\n    df.loc[df['Country']=='Venezuela (Bolivarian Republic of)','Country'] = 'Venezuela'\n    df.loc[df['Country']=='Bolivia (Plurinational State of)','Country'] = 'Bolivia'\n    \n    print('The following countries are missing or have different names to those in train_raw:\\n', list(set(list(train_raw['Country\/Region'])) - set(list(df['Country']))))\n    print('Impute missing values later')\n    \n    return df\n    \nobesity = clean_obesity(obese_raw)\ndisplay_all(obesity)","ff8d320b":"# Economy data\ndef clean_econ(df_raw):\n    df = df_raw.copy()\n    \n    try_me = df['Country'] == 'Congo, Republic of'\n    df_try = df.copy()[try_me]\n    df_try['Country'] = 'Republic of the Congo'\n    df = df.append([df_try], ignore_index=True)\n    \n    try_me = df['Country'] == 'Gambia'\n    df_try = df.copy()[try_me]\n    df_try['Country'] = 'The Gambia'\n    df = df.append([df_try], ignore_index=True)\n    \n    df.loc[df['Country']=='C\u00f4te d\\'Ivoire','Country'] = 'Cote d\\'Ivoire'\n    df.loc[df['Country']=='United States','Country'] = 'US'\n    #df.loc[df['Country']=='Czech Republic'] = 'Czechia'\n    df.loc[df['Country']=='Republic of North Macedonia','Country'] = 'North Macedonia'\n    df.loc[df['Country']=='Taiwan ','Country'] = 'Taiwan*'\n    df.loc[df['Country']=='Gambia','Country'] = 'Gambia, The'\n    df.loc[df['Country']=='Congo, Republic of','Country'] = 'Congo (Brazzaville)'\n    df.loc[df['Country']=='Congo, Democratic Republic of the Congo','Country'] = 'Congo (Kinshasa)'\n    df.loc[df['Country']=='Bahamas','Country'] = 'The Bahamas'\n    df.loc[df['Country']=='Slovak Republic','Country'] = 'Slovakia'\n    df.loc[df['Country']=='Kyrgyz Republic','Country'] = 'Kyrgyzstan'\n    df.loc[df['Country']=='Brunei Darussalam','Country'] = 'Brunei'\n    df.loc[df['Country']=='Macedonia','Country'] = 'North Macedonia'\n    \n    df1 = pd.DataFrame({'Country':['Guernsey','Andorra','Greenland','Aruba','Cruise Ship','San Marino','Jersey','Antigua and Barbuda','French Guiana',\n                                   'Puerto Rico','Mayotte','Holy See','Reunion','Guam','Martinique','Guadeloupe','Monaco','Czechia'],\n                        'Region':['Europe','Europe','Americas','Americas','Asia-Pacific','Europe','Europe','Americas','Americas',\n                                   'Americas','Sub-Saharan Africa','Europe','Sub-Saharan Africa','Asia-Pacific','Americas','Americas','Europe','Europe']})\n    \n    df = df.append(df1, sort=True)\n    \n    print('The following countries are missing or have different names to those in train_raw:\\n', list(set(list(train_raw['Country\/Region'])) - set(list(df['Country']))))\n    \n    df = df.drop(['CountryID', 'Country Name', 'WEBNAME', 'Population (Millions)'], axis=1)\n    \n    df['GDP (Billions, PPP)'] = df['GDP (Billions, PPP)'].str.strip('$').str.split(' ').str.get(0).str.replace(',', '').astype(float)\n    df['GDP per Capita (PPP)'] = df['GDP per Capita (PPP)'].str.strip('$').str.split(' ').str.get(0).str.replace(',', '').astype(float)\n    df['Unemployment (%)'] = df['Unemployment (%)'].str.split(' ').str.get(0).astype(float)\n    df['FDI Inflow (Millions)'] = df['FDI Inflow (Millions)'].str.replace(',', '').astype(float)\n    \n    for col in df.columns[df.isna().any()].tolist():\n        df[col] = df[col].fillna(df.groupby('Region')[col].transform('median')) # fill missing values with region medians\n    \n    return df.rename(columns={'Region': 'EconRegion'})\n    \necon = clean_econ(econ_raw)\ndisplay_all(econ)","f6b2786d":"# Population data\ndef clean_pop_data(df):\n    df.columns = ['Country', 'Pop', 'YearlyPopChange', 'NetPopChange', 'PopDensity', 'LandArea', \n                  'NetMigrants', 'FertilityRate', 'MedianAge', 'UrbanPop', 'WorldShare']\n    \n    try_me = df['Country'] == 'Congo'\n    df_try = df.copy()[try_me]\n    df_try['Country'] = 'Republic of the Congo'\n    df = df.append([df_try], ignore_index=True)\n    \n    try_me = df['Country'] == 'Gambia'\n    df_try = df.copy()[try_me]\n    df_try['Country'] = 'The Gambia'\n    df = df.append([df_try], ignore_index=True)\n    \n    df.loc[df['Country']=='C\u00f4te d\\'Ivoire','Country'] = 'Cote d\\'Ivoire'\n    df.loc[df['Country']=='Channel Islands','Country'] = 'Guernsey'\n    df.loc[df['Country']=='United States','Country'] = 'US'\n    df.loc[df['Country']=='R\u00e9union','Country'] = 'Reunion'\n    df.loc[df['Country']=='Taiwan','Country'] = 'Taiwan*'\n    df.loc[df['Country']=='South Korea','Country'] = 'Korea, South'\n    df.loc[df['Country']=='Gambia','Country'] = 'Gambia, The'\n    df.loc[df['Country']=='Congo','Country'] = 'Congo (Brazzaville)'\n    df.loc[df['Country']=='DR Congo','Country'] = 'Congo (Kinshasa)'\n    df.loc[df['Country']=='Bahamas','Country'] = 'The Bahamas'\n    df.loc[df['Country']=='Czech Republic (Czechia)','Country'] = 'Czechia'\n    df.loc[df['Country']=='St. Vincent & Grenadines','Country'] = 'Saint Vincent and the Grenadines'\n    \n    try_me = df['Country'] == 'Guernsey'\n    df_try = df.copy()[try_me]\n    df_try['Country'] = 'Jersey'\n    df = df.append([df_try], ignore_index=True)\n    \n    for col in ['YearlyPopChange', 'UrbanPop', 'WorldShare']:\n        df[col] = df[col].str.rstrip('%')\n    \n    # Add Kosovo and Cruise Ship manually\n    # https:\/\/en.wikipedia.org\/wiki\/Demographics_of_Kosovo\n    # https:\/\/www.indexmundi.com\/kosovo\/#Demographics\n    # https:\/\/en.wikipedia.org\/wiki\/Diamond_Princess_(ship)\n    df1 = pd.DataFrame({'Country':['Kosovo','Cruise Ship'],\n                        'Pop':[1793000,3711],\n                        'YearlyPopChange':[0.64,0],\n                        'NetPopChange':[1147,0],\n                        'PopDensity':[165,26],\n                        'LandArea':[10887,141],\n                        'NetMigrants':[-7340,0],\n                        'FertilityRate':[2.09,0],\n                        'MedianAge':[30,62],\n                        'UrbanPop':[65,100],\n                        'WorldShare':[0.02,0.00]})\n    \n    df = df.append(df1)\n    \n    print('The following countries are missing or have different names to those in train_raw:\\n', list(set(list(train_raw['Country\/Region'])) - set(list(df['Country']))))\n    \n    return df\n\npop_data = clean_pop_data(pop_data_raw)\ndisplay_all(pop_data)","9f3b5cd5":"# Additional country data\ndef clean_country_data(df):\n    country_data = df.copy()\n    country_data['Country'] = country_data['Country'].str.strip()\n    country_data['Region'] = country_data['Region'].str.strip()\n    for col in list(set(list(country_data))-set(['Country', 'Region'])):\n        if is_string_dtype(country_data[col]):\n            country_data[col] = country_data[col].str.replace(',','.').astype(float)\n            \n    df1 = pd.DataFrame({'Country':['Cruise Ship', 'Holy See', 'Kosovo', 'Montenegro'],\n                        'Region':['ASIA (EX. NEAR EAST)', 'WESTERN EUROPE', 'EASTERN EUROPE', 'EASTERN EUROPE']})\n    \n    country_data = country_data.append(df1, sort=True)\n    \n    for col in country_data.columns[country_data.isna().any()].tolist():\n        country_data[col] = country_data[col].fillna(country_data.groupby('Region')[col].transform('median')) # fill missing values with region medians\n        \n    try_me = country_data['Country'] == 'Congo, Repub. of the'\n    df_try = country_data.copy()[try_me]\n    df_try['Country'] = 'Republic of the Congo'\n    country_data = country_data.append([df_try], ignore_index=True)\n    \n    try_me = country_data['Country'] == 'Gambia, The'\n    df_try = country_data.copy()[try_me]\n    df_try['Country'] = 'The Gambia'\n    country_data = country_data.append([df_try], ignore_index=True)\n\n    country_data.loc[country_data['Country']=='United States','Country'] = 'US'\n    country_data.loc[country_data['Country']=='Mainland China','Country'] = 'China'\n    country_data.loc[country_data['Country']=='Viet Nam','Country'] = 'Vietnam'\n    country_data.loc[country_data['Country']=='UK','Country'] = 'United Kingdom'\n    country_data.loc[country_data['Country']=='Taiwan','Country'] = 'Taiwan*'\n    country_data.loc[country_data['Country']=='Hong Kong SAR, China','Country'] = 'Hong Kong'\n    country_data.loc[country_data['Country']=='Bosnia & Herzegovina','Country'] = 'Bosnia and Herzegovina'\n    country_data.loc[country_data['Country']=='Antigua & Barbuda','Country'] = 'Antigua and Barbuda'\n    country_data.loc[country_data['Country']=='Central African Rep.','Country'] = 'Central African Republic'\n    country_data.loc[country_data['Country']=='Czech Republic','Country'] = 'Czechia'\n    country_data.loc[country_data['Country']=='Swaziland','Country'] = 'Eswatini'\n    country_data.loc[country_data['Country']=='Macedonia','Country'] = 'North Macedonia'\n    country_data.loc[country_data['Country']=='Congo, Repub. of the','Country'] = 'Congo (Brazzaville)'\n    country_data.loc[country_data['Country']=='Congo, Dem. Rep.','Country'] = 'Congo (Kinshasa)'\n    country_data.loc[country_data['Country']=='Bahamas, The','Country'] = 'The Bahamas'\n    country_data.loc[country_data['Country']=='Trinidad & Tobago','Country'] = 'Trinidad and Tobago'\n\n    print('The following countries are missing or have different names to those in train_raw:\\n', list(set(list(train_raw['Country\/Region'])) - set(list(country_data['Country']))))\n    \n    country_data['Climate'] = country_data['Climate'].astype(str)\n    \n    return country_data.drop(['GDP ($ per capita)'], axis=1)\n\ncountry_data = clean_country_data(country_data_raw)\ndisplay_all(country_data)","241dd212":"# Weather data\n# https:\/\/www.kaggle.com\/davidbnn92\/weather-data\/\ndef clean_weather(df_raw):\n    df = df_raw.copy()[['Id', 'temp', 'min', 'max', 'stp', 'wdsp', 'prcp', 'fog']]\n    # Note: we will handle missing values later, so convert to nan to make things easier\n    for col in ['temp', 'min', 'max', 'stp']:\n        df[col] = df[col].replace(9999.9, np.nan)\n    df['wdsp'] = df['wdsp'].replace(999.9, np.nan)\n    df['prcp'] = df['prcp'].replace(99.99, np.nan)\n    #df['Date'] = pd.to_datetime(df['Date'])\n    \n    return df.rename(columns={'min': 'min_temp', 'max': 'max_temp'})\n\nweather = clean_weather(weather_raw)\ndisplay_all(weather)","03c052e7":"# Happiness report 2020 data\ndef clean_happiness_data(df):\n    df = df.rename(columns={'Country name': 'Country'}).drop('Regional indicator', axis=1)\n   \n    try_me = df['Country'] == 'Congo (Brazzaville)'\n    df_try = df.copy()[try_me]\n    df_try['Country'] = 'Republic of the Congo'\n    df = df.append([df_try], ignore_index=True)\n    \n    try_me = df['Country'] == 'Gambia'\n    df_try = df.copy()[try_me]\n    df_try['Country'] = 'The Gambia'\n    df = df.append([df_try], ignore_index=True)\n    \n    df.loc[df['Country']=='Ivory Coast','Country'] = 'Cote d\\'Ivoire'\n    df.loc[df['Country']=='United States','Country'] = 'US'\n    df.loc[df['Country']=='Macedonia','Country'] = 'North Macedonia'\n    df.loc[df['Country']=='Taiwan Province of China','Country'] = 'Taiwan*'\n    df.loc[df['Country']=='South Korea','Country'] = 'Korea, South'\n    df.loc[df['Country']=='Gambia','Country'] = 'Gambia, The'\n    df.loc[df['Country']=='Bahamas','Country'] = 'The Bahamas'\n    df.loc[df['Country']=='Czech Republic','Country'] = 'Czechia'\n    df.loc[df['Country']=='Swaziland','Country'] = 'Eswatini'\n       \n    print('The following countries are missing or have different names to those in train_raw:\\n', list(set(list(train_raw['Country\/Region'])) - set(list(df['Country']))))\n    print('Impute missing values later')\n    \n    return df\n\nhappiness = clean_happiness_data(happiness_raw)\ndisplay_all(happiness)","8589376f":"list(happiness)","51507137":"# Cleaning and feature engineering\ncombined_raw = train_raw.append(test_raw, sort=True)\n\ndef clean_covid19_data(df):\n    # Basic cleaning\n    df['Date'] = pd.to_datetime(df['Date'])\n    df['Province\/State'] = df['Province\/State'].fillna('None')\n    df = df.sort_values(['Country\/Region', 'Province\/State', 'Date'])\n    df['Id'].fillna(-1, inplace=True)\n    df['ForecastId'].fillna(-1, inplace=True)\n    df['ConfirmedCases'].fillna(0, inplace=True)\n    df['Fatalities'].fillna(0, inplace=True)\n\n    # Add some extra features from the date column\n    def make_date(df, date_field):\n        \"Make sure `df[date_field]` is of the right date type.\"\n        field_dtype = df[date_field].dtype\n        if isinstance(field_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n            field_dtype = np.datetime64\n        if not np.issubdtype(field_dtype, np.datetime64):\n            df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True)\n\n    def add_datepart(df, field_name, drop=True, time=False):\n        \"Helper function that adds columns relevant to a date in the column `field_name` of `df`.\"\n        make_date(df, field_name)\n        field = df[field_name]\n        attr = ['Year', 'Month', 'Week', 'Day', 'DayOfWeek', 'DayOfYear']\n        if time: attr = attr + ['Hour', 'Minute', 'Second']\n        for n in attr: df[n] = getattr(field.dt, n.lower())\n        df['Elapsed'] = field.astype(np.int64) \/\/ 10 ** 9\n        if drop: df.drop(field_name, axis=1, inplace=True)\n        return df\n\n    df = add_datepart(df, 'Date', drop=False)\n    \n    # Add additional data sources\n    df = pd.merge(df.rename(columns={'Country\/Region':'Country'}), country_data, on=['Country'], how='left')\n    df = pd.merge(df, pop_data, on=['Country'], how='left')\n    df = pd.merge(df, pollution, on=['Country'], how='left')\n    df = pd.merge(df, overweight, on=['Country'], how='left')\n    df = pd.merge(df, obesity, on=['Country'], how='left')\n    df = pd.merge(df, econ, on=['Country'], how='left')\n    df = pd.merge(df, response, on=['Country'], how='left')\n    df = pd.merge(df, weather, on=['Id'], how='left')\n    df = pd.merge(df, happiness, on=['Country'], how='left')\n    df = df.drop_duplicates()\n    \n    # Fix missing (typically fill missing values with region medians)\n    df['NetMigrants'].fillna((df['Net migration']\/100)*df['Pop'], inplace=True)\n    df['Net migration'] = (df['NetMigrants'] \/ df['Pop']) * 100\n    for col in ['FertilityRate', 'MedianAge', 'UrbanPop']:\n        df[col] = df[col].str.replace('N.A.', '99000')\n        df[col] = df[col].astype(float)\n        df[col] = df[col].replace(99000, (df.groupby('Region')[col].transform('median')))\n        df[col] = df[col].fillna(df.groupby('Region')[col].transform('median'))\n        \n    for col in ['temp', 'min_temp', 'max_temp', 'stp', 'wdsp', 'prcp', 'fog']:\n        df[col] = df[col].fillna(df.groupby(['Country', 'Month', 'Week'])[col].transform('median'))\n        df[col] = df[col].fillna(df.groupby(['Region', 'Month', 'Week'])[col].transform('median'))\n        df[col] = df[col].fillna(df.groupby(['Country', 'Month'])[col].transform('median'))\n        df[col] = df[col].fillna(df.groupby(['Region', 'Month'])[col].transform('median'))\n        df[col] = df[col].fillna(df.groupby(['Country'])[col].transform('median'))\n        df[col] = df[col].fillna(df.groupby(['Region'])[col].transform('median'))\n        \n    for col in ['CombinedOverweight', 'MaleOverweight', 'FemaleOverweight', 'CombinedObesity', 'MaleObesity', 'FemaleObesity', 'hospibed', 'smokers', \n                'sex0', 'sex14', 'sex25', 'sex54', 'sex64', 'sex65plus', 'sexratio', 'lung', 'femalelung', 'malelung', 'tests', 'testpop',\n                'Ladder score', 'Standard error of ladder score', 'upperwhisker', 'lowerwhisker', 'Logged GDP per capita', 'Social support', 'Healthy life expectancy',\n                'Freedom to make life choices', 'Generosity', 'Perceptions of corruption', 'Ladder score in Dystopia', 'Explained by: Log GDP per capita',\n                'Explained by: Social support', 'Explained by: Healthy life expectancy', 'Explained by: Freedom to make life choices', 'Explained by: Generosity',\n                'Explained by: Perceptions of corruption', 'Dystopia + residual']:\n        df[col] = df[col].fillna(df.groupby('Region')[col].transform('median'))\n        \n    df['pct_tested'] = df['tests'] \/ df['Pop']\n    df['tests'] = df['tests'].fillna(df['pct_tested'].median()*df['Pop'])\n    df['testpop'] = df['Pop'] \/ df['tests']\n    \n    # Fix channel island population metrics\n    guer_pop = df[df['Country']=='Guernsey']['Population'].mean() \/ (df[df['Country']=='Guernsey']['Population'].mean() + df[df['Country']=='Jersey']['Population'].mean())\n    guer_la = df[df['Country']=='Guernsey']['Area (sq. mi.)'].mean() \/ (df[df['Country']=='Guernsey']['Area (sq. mi.)'].mean() + df[df['Country']=='Jersey']['Area (sq. mi.)'].mean())\n    guer_pop_den = df[df['Country']=='Guernsey']['Pop. Density (per sq. mi.)'].mean() \/ (df[df['Country']=='Guernsey']['Pop. Density (per sq. mi.)'].mean() + df[df['Country']=='Jersey']['Pop. Density (per sq. mi.)'].mean())\n    df['Pop'] = np.where(df['Country']=='Guernsey', guer_pop*df['Pop'], \n                             np.where(df['Country']=='Jersey', (1-guer_pop)*df['Pop'], df['Pop']))\n    df['LandArea'] = np.where(df['Country']=='Guernsey', guer_la*df['LandArea'], \n                             np.where(df['Country']=='Jersey', (1-guer_la)*df['LandArea'], df['LandArea']))\n    df['PopDensity'] = np.where(df['Country']=='Guernsey', guer_pop_den*df['PopDensity'], \n                             np.where(df['Country']=='Jersey', (1-guer_pop_den)*df['PopDensity'], df['PopDensity']))\n    \n    # Add features to further explain country response to the outbreak\n    df['HasQuarantine'] = np.where(df['quarantine']<=df['Date'], 1, 0)\n    df['HasSchoolClosure'] = np.where(df['schools']<=df['Date'], 1, 0)\n    df['HasRestrictions'] = np.where(df['restrictions']<=df['Date'], 1, 0)\n    df.loc[df['quarantine'].notnull(), 'DaysSinceQuarantine'] = (df['Date'] - df['quarantine']).dt.days\n    df.loc[df['schools'].notnull(), 'DaysSinceSchoolClosure'] = (df['Date'] - df['schools']).dt.days\n    df.loc[df['restrictions'].notnull(), 'DaysSinceRestrictions'] = (df['Date'] - df['restrictions']).dt.days\n\n    for col in ['DaysSinceQuarantine', 'DaysSinceSchoolClosure', 'DaysSinceRestrictions']:\n        df[col] = df[col].fillna(0)\n        df[col] = np.where(df[col]<0, 0, df[col])\n    \n    def add_cases_fatalities_feats(df):\n        # Add features to explain days since first case and fatality for different groups\n        df1 = df.copy()[df['ConfirmedCases']>0].groupby('Country')['Date'].min().reset_index().rename(columns={'Date':'FirstCase'})\n        df = pd.merge(df, df1, on='Country', how='left')\n        df.loc[df['FirstCase'].notnull(), 'DaysSinceFirstCaseCountry'] = (df['Date'] - df['FirstCase']).dt.days\n        df1 = df.copy()[df['Fatalities']>0].groupby('Country')['Date'].min().reset_index().rename(columns={'Date':'FirstFatality'})\n        df = pd.merge(df, df1, on='Country', how='left')\n        df.loc[df['FirstFatality'].notnull(), 'DaysSinceFirstFatalityCountry'] = (df['Date'] - df['FirstFatality']).dt.days\n        df = df.drop(['FirstCase', 'FirstFatality'], axis=1)\n\n        df1 = df.copy()[df['ConfirmedCases']>0].groupby('Region')['Date'].min().reset_index().rename(columns={'Date':'FirstCase'})\n        df = pd.merge(df, df1, on='Region', how='left')\n        df.loc[df['FirstCase'].notnull(), 'DaysSinceFirstCaseRegion'] = (df['Date'] - df['FirstCase']).dt.days\n        df1 = df.copy()[df['Fatalities']>0].groupby('Region')['Date'].min().reset_index().rename(columns={'Date':'FirstFatality'})\n        df = pd.merge(df, df1, on='Region', how='left')\n        df.loc[df['FirstFatality'].notnull(), 'DaysSinceFirstFatalityRegion'] = (df['Date'] - df['FirstFatality']).dt.days\n        df = df.drop(['FirstCase', 'FirstFatality'], axis=1)\n\n        df1 = df.copy()[(df['ConfirmedCases']>0)&(df['Province\/State']!='None')].groupby('Province\/State')['Date'].min().reset_index().rename(columns={'Date':'FirstCase'})\n        df = pd.merge(df, df1, on='Province\/State', how='left')\n        df.loc[df['FirstCase'].notnull(), 'DaysSinceFirstCaseProvince'] = (df['Date'] - df['FirstCase']).dt.days\n        df1 = df.copy()[(df['Fatalities']>0)&(df['Province\/State']!='None')].groupby('Province\/State')['Date'].min().reset_index().rename(columns={'Date':'FirstFatality'})\n        df = pd.merge(df, df1, on='Province\/State', how='left')\n        df.loc[df['FirstFatality'].notnull(), 'DaysSinceFirstFatalityProvince'] = (df['Date'] - df['FirstFatality']).dt.days\n        df = df.drop(['FirstCase', 'FirstFatality'], axis=1)\n\n        df = df.fillna(0)\n        return df\n    \n    df = add_cases_fatalities_feats(df)\n    \n    def add_cases_fatalities_100(df):\n        # Add features to explain days since 100th case and fatality for different groups\n        df1 = df.copy()[df['ConfirmedCases']>100].groupby('Country')['Date'].min().reset_index().rename(columns={'Date':'Case100'})\n        df = pd.merge(df, df1, on='Country', how='left')\n        df.loc[df['Case100'].notnull(), 'DaysSinceCase100Country'] = (df['Date'] - df['Case100']).dt.days\n        df1 = df.copy()[df['Fatalities']>100].groupby('Country')['Date'].min().reset_index().rename(columns={'Date':'Fatality100'})\n        df = pd.merge(df, df1, on='Country', how='left')\n        df.loc[df['Fatality100'].notnull(), 'DaysSinceFatality100Country'] = (df['Date'] - df['Fatality100']).dt.days\n        df = df.drop(['Case100', 'Fatality100'], axis=1)\n\n        df1 = df.copy()[df['ConfirmedCases']>100].groupby('Region')['Date'].min().reset_index().rename(columns={'Date':'Case100'})\n        df = pd.merge(df, df1, on='Region', how='left')\n        df.loc[df['Case100'].notnull(), 'DaysSinceCase100Region'] = (df['Date'] - df['Case100']).dt.days\n        df1 = df.copy()[df['Fatalities']>100].groupby('Region')['Date'].min().reset_index().rename(columns={'Date':'Fatality100'})\n        df = pd.merge(df, df1, on='Region', how='left')\n        df.loc[df['Fatality100'].notnull(), 'DaysSinceFatality100Region'] = (df['Date'] - df['Fatality100']).dt.days\n        df = df.drop(['Case100', 'Fatality100'], axis=1)\n\n        df1 = df.copy()[(df['ConfirmedCases']>100)&(df['Province\/State']!='None')].groupby('Province\/State')['Date'].min().reset_index().rename(columns={'Date':'Case100'})\n        df = pd.merge(df, df1, on='Province\/State', how='left')\n        df.loc[df['Case100'].notnull(), 'DaysSinceCase100Province'] = (df['Date'] - df['Case100']).dt.days\n        df1 = df.copy()[(df['Fatalities']>100)&(df['Province\/State']!='None')].groupby('Province\/State')['Date'].min().reset_index().rename(columns={'Date':'Fatality100'})\n        df = pd.merge(df, df1, on='Province\/State', how='left')\n        df.loc[df['Fatality100'].notnull(), 'DaysSinceFatality100Province'] = (df['Date'] - df['Fatality100']).dt.days\n        df = df.drop(['Case100', 'Fatality100'], axis=1)\n\n        df['DaysSinceFirstCaseGlobal'] = (df['Date'] - df[df['ConfirmedCases']>0]['Date'].min()).dt.days\n        df['DaysSinceFirstFatalityGlobal'] = (df['Date'] - df[df['Fatalities']>0]['Date'].min()).dt.days\n        df['DaysSinceCase100Global'] = (df['Date'] - df[df['ConfirmedCases']>100]['Date'].min()).dt.days\n        df['DaysSinceFatality100Global'] = (df['Date'] - df[df['Fatalities']>100]['Date'].min()).dt.days\n\n        df = df.fillna(0)\n        return df\n    \n    df = add_cases_fatalities_100(df)\n    \n    # Remove surplus columns\n    df = df.drop(['Population', 'Area (sq. mi.)', 'Pop. Density (per sq. mi.)', 'pct_tested', 'quarantine', 'schools', 'restrictions', 'EconRegion'], axis=1)\n    \n    # Convert remaining string cols to floats\n    for col in ['YearlyPopChange', 'WorldShare']:\n        df[col] = df[col].astype(float)\n    \n    return df.drop_duplicates()\n\ncombined = clean_covid19_data(combined_raw)\ncombined.columns[combined.isna().any()].tolist()","3d73cad4":"# https:\/\/www.kaggle.com\/saga21\/covid-global-forecast-sir-model-ml-regressions\ndef calculate_trend(df, lag_list, column):\n    for lag in lag_list:\n        trend_column_lag = \"Trend_\" + column + \"_\" + str(lag)\n        df[trend_column_lag] = (df[column]-df[column].shift(lag, fill_value=-999))\/df[column].shift(lag, fill_value=0)\n    return df\n\n\ndef calculate_lag(df, lag_list, column):\n    for lag in lag_list:\n        column_lag = column + \"_\" + str(lag)\n        df[column_lag] = df[column].shift(lag, fill_value=0)\n    return df\n\ncombined = calculate_lag(combined, range(1,7), 'ConfirmedCases')\ncombined = calculate_lag(combined, range(1,7), 'Fatalities')\ncombined = calculate_trend(combined, [1], 'ConfirmedCases')\ncombined = calculate_trend(combined, [1], 'Fatalities')\ncombined.replace([np.inf, -np.inf], 0, inplace=True)\ncombined.fillna(0, inplace=True)","769cbd53":"def add_extra_trends(df):\n    master = pd.DataFrame()\n    for country in df['Country'].unique():\n        df1 = df.copy()[df['Country']==country].sort_values(by='Date')\n\n        df1['NewConfirmed'] = df1['ConfirmedCases'] - df1['ConfirmedCases'].shift(1)\n        df1['NewConfirmed'] = df1['NewConfirmed'].fillna(df1['ConfirmedCases'])\n        df1['PreviousDayNewConfirmed'] = df1['NewConfirmed']\n        df1['PreviousDayNewConfirmed'] = df1['PreviousDayNewConfirmed'].fillna(0)\n        df1['GrowthFactor'] = df1['NewConfirmed'] \/ df1['PreviousDayNewConfirmed'] # https:\/\/www.youtube.com\/watch?v=Kas0tIxDvrg\n        df1['GrowthFactor'] = df1['GrowthFactor'].rolling(3).median() # add smoothing\n        \n\n        df1['NewFatalities'] = df1['Fatalities'] - df1['Fatalities'].shift(1)\n        df1['NewFatalities'] = df1['NewFatalities'].fillna(df1['Fatalities'])\n        df1['PreviousDayNewFatalities'] = df1['Fatalities'].shift(1) - df1['Fatalities'].shift(2)\n        df1['PreviousDayNewFatalities'] = df1['PreviousDayNewFatalities'].fillna(0)\n        df1['MortalityFactor'] = df1['NewFatalities'] \/ df1['PreviousDayNewFatalities']\n        df1['MortalityFactor'] = df1['MortalityFactor'].rolling(3).median() # add smoothing\n        \n        df1['CaseFatalityRate'] = df1['Fatalities'] \/ df1['ConfirmedCases']\n        df1['InfectionRate'] = df1['ConfirmedCases'] \/ df1['Pop']\n        df1['MortalityRate'] = df1['Fatalities'] \/ df1['Pop']\n        \n        df1 = df1.replace([np.inf, -np.inf], np.nan)\n        df1['GrowthFactor'] = np.where(df1['ConfirmedCases']==0, 0, df1['GrowthFactor'].fillna(1.25)) # assumed\n        df1['MortalityFactor'] = np.where(df1['Fatalities']==0, 0, df1['MortalityFactor'].fillna(1.25)) # assumed\n        df1['CaseFatalityRate'] = df1['CaseFatalityRate'].fillna(0)\n        df1['InfectionRate'] = df1['InfectionRate'].fillna(0)\n        df1['MortalityRate'] = df1['MortalityRate'].fillna(0)\n        \n        master = master.append(df1)\n        \n    return master.drop(['NewConfirmed', 'PreviousDayNewConfirmed', 'NewFatalities', 'PreviousDayNewFatalities'], axis=1)\n\ncombined = add_extra_trends(combined)\ndisplay_all(combined)","3104e161":"# Label encode categorical features\ncat = combined.copy()[['Province\/State', 'Region', 'Climate', 'Country']]\ncont = combined.drop(['Province\/State', 'Region', 'Climate', 'Country'], axis=1)\n\n# Use label encoding to convert categorical features to numeric\n# https:\/\/stackoverflow.com\/a\/37038257\ndef label_encode(df):\n    # Convert df to label encoded\n    df_le = pd.DataFrame({col: df[col].astype('category').cat.codes for col in df}, index=df.index)\n    # Save mappings as a dict\n    mappings = {col: {n: cat for n, cat in enumerate(df[col].astype('category').cat.categories)} \n     for col in df}\n    return df_le, mappings\n\ncat_le, mappings = label_encode(cat)\ncombined = pd.merge(cat_le, cont, left_index=True, right_index=True)\ndisplay_all(combined)","7e6107f0":"# Apply log transformations\ncols = [x for x in list(combined) if 'ConfirmedCases' in x and 'Trend' not in x or 'Fatalities' in x and 'Trend' not in x]\ncombined[cols] = combined[cols].astype('float64').apply(lambda x: np.log(x))\ncombined.replace([np.inf, -np.inf], 0, inplace=True)\n\n# Split into train, test and validation sets\ntrain = combined[combined['ForecastId']==-1]\ntest = combined[combined['ForecastId']!=-1]\nvalid = train.copy()[train['Date']>=test['Date'].min()]\ntrain = train.copy()[train['Date']<test['Date'].min()]","dd8a1499":"This is a notebook to create an enriched dataset using some of the additional data described [here](https:\/\/www.kaggle.com\/c\/covid19-global-forecasting-week-1\/discussion\/137078).\nI hope you find it useful!"}}