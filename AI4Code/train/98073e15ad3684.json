{"cell_type":{"c72df8e3":"code","0b6382da":"code","b7bb1783":"code","67596d1f":"code","a051798e":"code","432e1b46":"code","ea7da571":"code","ee8145b6":"code","bfb31eb3":"code","97d66731":"markdown","19294092":"markdown","3bd86f8e":"markdown","69a95bb8":"markdown","9a931a8f":"markdown","8b9d4024":"markdown","9c2e26a9":"markdown"},"source":{"c72df8e3":"from tensorflow.keras.datasets import cifar100\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\nfrom tensorflow.keras.losses import categorical_crossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport numpy as np","0b6382da":"(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n\n# Parse numbers as floats\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\n# Normalize data\nX_train = (X_train) \/ 255.\nX_test = (X_test) \/ 255.\n\n# number of classes\nnb_classes = len(np.unique(y_train))\n\n# Image size\nimg_width, img_height, img_num_channels = 32, 32, 3\ninput_shape = (img_width, img_height, img_num_channels)\n\n# convert class vectors to binary class matrices\ny_train = to_categorical(y_train, nb_classes)\ny_test = to_categorical(y_test, nb_classes)","b7bb1783":"plt.figure(figsize=(10, 10))\n\nfor i in range (4*4):\n  plt.subplot(4, 4, i+1)\n  plt.imshow(X_train[i])\n  plt.axis('off')\n\nplt.show()","67596d1f":"model = Sequential()\n# 128 and not only 32 filters because there are 100 classes. 32 filters gave bad results.\nmodel.add(Conv2D(128, (3, 3), padding='same', input_shape=X_train.shape[1:]))\nmodel.add(Activation('elu'))\n\nmodel.add(Conv2D(128, (3, 3)))\nmodel.add(Activation('elu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(256, (3, 3), padding='same'))\nmodel.add(Activation('elu'))\n\nmodel.add(Conv2D(256, (3, 3)))\nmodel.add(Activation('elu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(512, (3, 3), padding='same'))\nmodel.add(Activation('elu'))\n\nmodel.add(Conv2D(512, (3, 3)))\nmodel.add(Activation('elu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation('elu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(nb_classes))\nmodel.add(Activation('softmax'))\n\nmodel.summary()","a051798e":"# Compile the model\nmodel.compile(loss=categorical_crossentropy, optimizer=Adam(learning_rate = 0.0001, decay = 1e-6), metrics=['accuracy'])","432e1b46":"datagen = ImageDataGenerator(\n            featurewise_center=False,  # set input mean to 0 over the dataset\n            samplewise_center=False,  # set each sample mean to 0\n            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n            samplewise_std_normalization=False,  # divide each input by its std\n            zca_whitening=False,  # apply ZCA whitening\n            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n            horizontal_flip=True,  # randomly flip images\n            vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","ea7da571":"early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=8, restore_best_weights = True)\n\n# Fit data to model\nhistory = model.fit(datagen.flow(X_train, y_train, batch_size=50), \n                   steps_per_epoch=X_train.shape[0] \/\/ 50,\n                   epochs=600,\n                   validation_data=(X_test, y_test),\n                   verbose=1,\n                   callbacks=[early_stop])","ee8145b6":"# Generate generalization metrics\nscore = model.evaluate(X_test, y_test, verbose=0)\nprint(f'Test loss: {score[0]} \/ Test accuracy: {score[1]}')\n\n# Visualize history\n# Plot history: Loss\nplt.plot(history.history['val_loss'])\nplt.title('Validation loss history')\nplt.ylabel('Loss value')\nplt.xlabel('No. epoch')\nplt.show()\n\n# Plot history: Accuracy\nplt.plot(history.history['val_accuracy'])\nplt.title('Validation accuracy history')\nplt.ylabel('Accuracy value (%)')\nplt.xlabel('No. epoch')\nplt.show()","bfb31eb3":"evaluation = model.evaluate(datagen.flow(X_test, y_test, batch_size=50),\n                                      steps=X_test.shape[0] \/\/ 50)\n\nprint('Model Accuracy = %.2f' % (evaluation[1]))","97d66731":"**Accuracy of the model**","19294092":"**Plot some images**","3bd86f8e":"# DATA","69a95bb8":"# Evaluate the model","9a931a8f":"**Data augmentation**\n","8b9d4024":"# Create the model","9c2e26a9":"**LOAD DATA**"}}