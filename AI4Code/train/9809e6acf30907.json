{"cell_type":{"244c7c15":"code","f7764b36":"code","cc814167":"code","bfe31488":"code","68cdd0ef":"code","630d285d":"code","cea6dc2f":"code","518e55d5":"code","dcc20a40":"code","a10de1c6":"code","8ca4da38":"code","6e13ec3b":"code","6a38e7f0":"code","5dc25807":"code","3d8ccfd5":"code","67b4d4e1":"code","ed35f1b7":"code","a85401c6":"code","13c94359":"code","51f590fe":"code","c9532930":"code","8bb20eac":"code","015f09dd":"code","bd720608":"code","4b49f58d":"code","c45edaa0":"code","9096a10f":"code","15c5516e":"code","6f128094":"code","8cd57cba":"code","ccae5874":"code","f28c68a1":"code","92cb250a":"code","130fade3":"code","e8ecc931":"code","3f10f374":"code","118b1677":"code","2d2a3cd8":"code","dcc55310":"markdown","861a2c2b":"markdown","c59b9dd3":"markdown","9daefcd3":"markdown","8cb0b27d":"markdown","8df1546e":"markdown","4c93c0ba":"markdown","2ea036fd":"markdown","d09ae4cf":"markdown","fb43c1d1":"markdown","340413a0":"markdown","0eb3be4e":"markdown","336e5cc2":"markdown","7b32fc4c":"markdown","9bf1a5b3":"markdown","ebb3ff66":"markdown","6f99584f":"markdown","adbb43ad":"markdown"},"source":{"244c7c15":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f7764b36":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nimport re\nfrom statistics import mode\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder","cc814167":"# Reading data\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\n\n# Storing Passenger Id for submission\nId = test.PassengerId","bfe31488":"train.head()","68cdd0ef":"test.head()","630d285d":"train.hist(figsize=(14,14), color='green', bins=20)\nplt.show()","cea6dc2f":"fig = plt.figure(figsize=(10,10))\n\nsns.barplot(x=\"Sex\", y=\"Survived\", data=train)\n\n#print percentages of females vs. males that survive\nprint(\"Percentage of females who survived:\", train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of males who survived:\", train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts(normalize = True)[1]*100)","518e55d5":"fig = plt.figure(figsize=(10,10))\n\n\n#draw a bar plot of survival by Pclass\nsns.barplot(x=\"Pclass\", y=\"Survived\", data=train)\n\n#print percentage of people by Pclass that survived\nprint(\"Percentage of Pclass = 1 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 1].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of Pclass = 2 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 2].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of Pclass = 3 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 3].value_counts(normalize = True)[1]*100)","dcc20a40":"fig = plt.figure(figsize=(10,10))\n\n\n#draw a bar plot for SibSp vs. survival\nsns.barplot(x=\"SibSp\", y=\"Survived\", data=train)\n\n#I won't be printing individual percent values for all of these.\nprint(\"Percentage of SibSp = 0 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 0].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of SibSp = 1 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 1].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of SibSp = 2 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 2].value_counts(normalize = True)[1]*100)","a10de1c6":"fig = plt.figure(figsize=(10,10))\n\n\nsns.barplot(x=\"Parch\", y=\"Survived\", data=train)\nplt.show()","8ca4da38":"# Combining Data\n\ndataset = pd.concat([train, test], sort=False, ignore_index=True)\n\n# Visualizing missing values\ndataset.isnull().mean().sort_values(ascending=False)","6e13ec3b":"# Checking correlations with Heatmap\n\nfig, axs = plt.subplots(nrows=1, figsize=(13, 13))\nsns.heatmap(dataset.corr(), annot=True, square=True, cmap='YlGnBu', linewidths=2, linecolor='black', annot_kws={'size':12})","6a38e7f0":"# Filling in the missing value in `Fare` with its median\ndataset['Fare'].fillna(dataset['Fare'].median(), inplace=True)\n\n\n# Filling in the missing value in 'Embarked' with its mode (Value: 'S')\ndataset['Embarked'] = dataset['Embarked'].fillna('S')","5dc25807":"# Creating 'Title' column\ndataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand = False)\ndataset['Title'].unique().tolist()","3d8ccfd5":"# This shows the percentage of occurrences for each title. 'Mr' occurs the most often.\n\ndataset['Title'].value_counts(normalize=True)*100","67b4d4e1":"# Replacing less familiar names with more familiar names\ndataset['Title'] = dataset['Title'].replace(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer')\ndataset['Title'] = dataset['Title'].replace(['Jonkheer', 'Master'], 'Master')\ndataset['Title'] = dataset['Title'].replace(['Don', 'Sir', 'the Countess', 'Lady', 'Dona'], 'Royalty')\ndataset['Title'] = dataset['Title'].replace(['Mme', 'Ms', 'Mrs'], 'Mrs')\ndataset['Title'] = dataset['Title'].replace(['Mlle', 'Miss'], 'Miss')\n  \n\n# Imputing missing values with 0\ndataset['Title'] = dataset['Title'].fillna(0)\n\ndataset['Title'].value_counts()","ed35f1b7":"# Filling the missing values in Age with its median\ndataset['Age'].fillna(dataset['Age'].median(), inplace=True)","a85401c6":"g  = sns.factorplot(x=\"Parch\",y=\"Survived\",data=dataset, size = 8)\ng = g.set_ylabels(\"Survival Percentage\")","13c94359":"g  = sns.factorplot(x=\"SibSp\",y=\"Survived\",data=dataset, size = 8)\ng = g.set_ylabels(\"Survival Percentage\")","51f590fe":"# Family Size = # of Siblings + # of Parents + You\ndataset['FamSize'] = dataset['SibSp'] + dataset['Parch'] + 1","c9532930":"g  = sns.factorplot(x=\"FamSize\",y=\"Survived\",data=dataset, size = 8)\ng = g.set_ylabels(\"Survival Percentage\")","8bb20eac":"def family_label(s):\n    if (s >= 2) & (s <= 4):\n        return 2\n    elif ((s > 4) & (s <= 7)) | (s == 1):\n        return 1\n    elif (s > 7):\n        return 0\n    \ndataset['FamLabel']=dataset['FamSize'].apply(family_label)\ndataset.head()","015f09dd":"plt.figure(figsize=(8, 8))\nsns.barplot(x=\"FamLabel\", y=\"Survived\", data=dataset, palette='Blues_d')\nplt.show()","bd720608":"dataset['Cabin'] = dataset['Cabin'].fillna('Unknown')\ndataset['Deck']=dataset['Cabin'].str.get(0)","4b49f58d":"plt.figure(figsize=(8, 8))\nsns.barplot(x='Deck', y='Survived', data=dataset, palette='ocean')\nplt.show()","c45edaa0":"dataset.drop(['Name', 'Ticket', 'SibSp', 'Parch', 'FamSize', 'Cabin'], axis=1, inplace=True)","9096a10f":"dataset.dtypes","15c5516e":"label = LabelEncoder()\n\nfor col in ['Sex', 'Embarked', 'Deck', 'Title']:\n    dataset[col] = label.fit_transform(dataset[col])","6f128094":"# Splitting dataset into train\ntrain = dataset[:len(train)]\n\n# Splitting dataset into test\ntest = dataset[len(train):]\n\n# Drop labels 'Survived' because there shouldn't be a Survived column in the test data\ntest.drop(labels=['Survived'], axis=1, inplace=True)","8cd57cba":"train.head()","ccae5874":"test.head()","f28c68a1":"train['Survived'] = train['Survived'].astype(int)","92cb250a":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_validate\n\n# Setting up variables for modelling\ny = train.Survived\n\nX = train.drop('Survived', axis=1)","130fade3":"# Logistic Regression\nprint(\"Logistic Regression:\", cross_val_score(LogisticRegression(), X, y).mean())\n\n# SVC\nprint(\"SVC:\", cross_val_score(SVC(), X, y).mean())\n\n# Random Forest\nprint(\"Random Forest:\", cross_val_score(RandomForestClassifier(), X, y).mean())\n\n# GaussianNB\nprint(\"GaussianNB:\", cross_val_score(GaussianNB(), X, y).mean())\n\n# Decision Tree\nprint(\"Decision Tree:\", cross_val_score(DecisionTreeClassifier(), X, y).mean())","e8ecc931":"select = SelectKBest(k = 'all')\nfinal_model = RandomForestClassifier(random_state = 10, warm_start = True, \n                                  n_estimators = 26,\n                                  max_depth = 6, \n                                  max_features = 'sqrt')\n\npipeline = make_pipeline(select, final_model)\n\ncv_result = cross_validate(pipeline, X, y, cv= 10)\n\nprint(\"CV Test Score : Mean - %.7g | Std - %.7g \" % (np.mean(cv_result['test_score']), \\\n                                                     np.std(cv_result['test_score'])))","3f10f374":"pipeline.fit(X, y)\n\nfinal_predictions = pipeline.predict(test)","118b1677":"output = pd.DataFrame({'PassengerId': Id, 'Survived': final_predictions})\noutput.to_csv('submission.csv', index=False)","2d2a3cd8":"output.head()","dcc55310":"Females have a much higher chance of Survival than Men.","861a2c2b":"**Data Visualizations**","c59b9dd3":"Again, no clear correlation but people with no parents were less likely to survive than those with 1-3 parents\/children.","9daefcd3":"# **Feature Engineering**","8cb0b27d":"Creating Title feature from Name feature.","8df1546e":"There isn't a clear correlation but in general people with more siblings\/spouses were less likely survive. Also people with no siblings\/spouses were less likely to survive than people with one or two siblings\/spouses.","4c93c0ba":"Let's visualize our new Deck feature","2ea036fd":"Columns SibSp and Parch are very similar to each other in meaning and in correlation.","d09ae4cf":"Create a new feature called FamLabel which categorizes the family size.","fb43c1d1":"Create a new feature called FamSize which combines Parch and SibSp.","340413a0":"We find correlations between features and impute missing values using the correlations. Using feature engineering we create new features that are beneficial to our dataset FamLabel, Deck, and Title.","0eb3be4e":"We still have some categorical features which we must change to numerical so we use a Label Encoder.","336e5cc2":"Change Survived to an integer.","7b32fc4c":"Dropping Name, Ticket, SibSp, Parch, FamSize, and Cabin because they were already used for feature engineering or may be useless.","9bf1a5b3":"Passengers of PClass 1 class were more likely to Survive","ebb3ff66":"Split dataset back into train and test variables.","6f99584f":"**ML Predictions**","adbb43ad":"Although our Cabin feature has many missing values. We can still create a new feature called Deck which is the first letter of the Cabin name. We do this because the first letter of the cabin name represents the location of the cabin."}}