{"cell_type":{"9283e84c":"code","e1061f95":"code","13afd718":"code","37dbf72e":"code","1239a06b":"code","eff0b663":"code","1bbfc99f":"code","47ac6739":"code","69a2707c":"code","02ef3648":"code","232ea6fc":"code","3ade16f8":"code","ff979858":"code","f584ecb1":"code","98e37865":"code","3c9feeaf":"code","a91411b6":"code","58c920fa":"code","30d5f9c7":"code","0f4459fe":"code","ba948c84":"code","e1c98fba":"code","a8e30d9f":"code","7605e5a7":"code","c541c008":"code","67539393":"code","5c901a09":"code","16c72183":"markdown","b512bd90":"markdown","6ef649fa":"markdown","76718141":"markdown","549fefb1":"markdown","764bd84b":"markdown"},"source":{"9283e84c":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom collections import Counter\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import applications\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras import optimizers\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\nos.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'","e1061f95":"train_data_dir = r\"..\/input\/covid19-image-dataset\/Covid19-dataset\/train\"\ntest_data_dir = r\"..\/input\/covid19-image-dataset\/Covid19-dataset\/test\"","13afd718":"covid_images = [os.path.join(train_data_dir, 'Covid', path) for path in os.listdir(train_data_dir + '\/Covid')]\nnormal_images = [os.path.join(train_data_dir, 'Normal', path) for path in os.listdir(train_data_dir + '\/Normal')]\nviral_pneumonia_images = [os.path.join(train_data_dir, 'Viral Pneumonia', path) for path in os.listdir(train_data_dir + '\/Viral Pneumonia')]","37dbf72e":"image = Image.open(covid_images[0])","1239a06b":"plt.imshow(np.array(image))\nplt.show()","eff0b663":"#now we normalize the data\ntrain_datagen = ImageDataGenerator(rescale=1. \/ 255)\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)","1bbfc99f":"#first generating images without augmentation for a baseline model\nimg_width, img_height = 224, 224\nbatch_size = 8\n\ntrain_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical')\ntest_generator = test_datagen.flow_from_directory(test_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical')","47ac6739":"#checking the class counts\nfrom collections import Counter\nprint(\"The individual class count in train set is \", Counter(train_generator.classes))\nprint(\"The individual class count in test set is \", Counter(test_generator.classes))","69a2707c":"#now we will build a base model\nbase_model = tf.keras.applications.resnet.ResNet50(weights='imagenet', include_top=False)\nglobal_avg_pooling = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\noutput = tf.keras.layers.Dense(3, activation='softmax')(global_avg_pooling)\nmodel = tf.keras.Model(inputs=base_model.input, outputs=output)\noptimizer = tf.keras.optimizers.SGD(lr=1e-3, momentum=0.9, decay=0.01)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])","02ef3648":"history = model.fit(train_generator, epochs=10, validation_data=test_generator, verbose=1)","232ea6fc":"#now lets plot epoch vs loss\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(range(10), history.history['loss'], label='train loss')\nplt.plot(range(10), history.history['val_loss'], label='val loss')\nplt.title('Baseline model: Epoch vs loss')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend()\nplt.subplot(1, 2, 2)\nplt.plot(range(10), history.history['accuracy'], label='train accuracy')\nplt.plot(range(10), history.history['val_accuracy'], label='val accuracy')\nplt.title('Baseline model: Epoch vs accuracy')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","3ade16f8":"#alright now let us try to add dropout layer for regularization\nbase_model = tf.keras.applications.resnet.ResNet50(weights='imagenet', include_top=False)\nglobal_avg_pooling = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\ndropout = tf.keras.layers.Dropout(rate=0.5)(global_avg_pooling) #added dropout\noutput = tf.keras.layers.Dense(3, activation='softmax')(dropout)\nmodel = tf.keras.Model(inputs=base_model.input, outputs=output)\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])","ff979858":"history = model.fit(train_generator, epochs=10, validation_data=test_generator, verbose=1)","f584ecb1":"#plotting epoch vs loss and accuracy again\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(range(10), history.history['loss'], label='train loss')\nplt.plot(range(10), history.history['val_loss'], label='val loss')\nplt.title('Baseline model with dropout: Epoch vs loss')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend()\nplt.subplot(1, 2, 2)\nplt.plot(range(10), history.history['accuracy'], label='train accuracy')\nplt.plot(range(10), history.history['val_accuracy'], label='val accuracy')\nplt.title('Baseline model with dropout: Epoch vs accuracy')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","98e37865":"#performing data augmentation\ntrain_datagen = ImageDataGenerator(rescale=1. \/ 255, \n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   horizontal_flip=True)\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)","3c9feeaf":"#generating images with augmentation for the model\nimg_width, img_height = 224, 224\nbatch_size = 8\n\ntrain_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical')\ntest_generator = test_datagen.flow_from_directory(test_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical')","a91411b6":"x, y = next(train_generator)","58c920fa":"x.shape","30d5f9c7":"for i, j in zip(range(1,9), range(0,8)):\n    plt.subplot(2, 4, i)\n    plt.imshow(x[j])","0f4459fe":"base_model = tf.keras.applications.resnet.ResNet50(weights='imagenet', include_top=False)\nglobal_avg_pooling = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\ndropout = tf.keras.layers.Dropout(rate=0.5)(global_avg_pooling) #added dropout\noutput = tf.keras.layers.Dense(3, activation='softmax')(dropout)\nmodel = tf.keras.Model(inputs=base_model.input, outputs=output)\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])","ba948c84":"history = model.fit(train_generator, epochs=60, validation_data=test_generator, verbose=1)","e1c98fba":"plt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(range(60), history.history['loss'], label='train loss')\nplt.plot(range(60), history.history['val_loss'], label='val loss')\nplt.title('Model with Augmentation: Epoch vs loss')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend()\nplt.subplot(1, 2, 2)\nplt.plot(range(60), history.history['accuracy'], label='train accuracy')\nplt.plot(range(60), history.history['val_accuracy'], label='val accuracy')\nplt.title('Model with Augmentation: Epoch vs accuracy')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","a8e30d9f":"all_batches = []\ncount = 1\nfor batch in tqdm(test_generator):\n    all_batches.append(batch)\n    count = count + 1\n    if count == 33:\n        break","7605e5a7":"len(all_batches)","c541c008":"all_y_hats = []\nall_y = []\nfor X, y in all_batches:\n    y_hat = model.predict(X)\n    y_hat = np.argmax(y_hat, 1)\n    all_y_hats.extend(list(y_hat))\n    all_y.extend(list(np.argmax(y, 1)))","67539393":"print(classification_report(all_y, all_y_hats))","5c901a09":"sns.heatmap(confusion_matrix(all_y, all_y_hats), annot=True, cmap='mako')\nplt.title('Confusion Matrix on Test Set')\nplt.show()","16c72183":"Ovservations:\n\nAlright, since we added dropout we see a slight improvement compared to the previous model, but still not upto the mark. To further fix overfitting we need to perform data augmentation so our train data size is increased.","b512bd90":"Observations:\n\nWe see that our baseline model gives us an overfit model. The val_accuracy is very low compared to the train accuracy.","6ef649fa":"<h1> COVID-19 Classification Using Chest X-Rays","76718141":"<h3>The dataset consists of chest X-ray images and the task is to classify them into 3 classes i.e., COVID-19, Normal, Viral Pneumonia. The dataset is split into train and test directories, each with 3 folders containing images of the 3 classes.","549fefb1":"# Conclusion\nTrained a convolutional neural network with ResNet-50 weights on Imagenet through transfer learning. The accuracy score achieved on validation set is 96.97%. Also, by looking at the confusion matrix, we see that principal diagnoal elements are very high and others are zero. Therefore, all of the data points in the test set are being classified correctly.","764bd84b":"After running the model for 60 epochs, we get an excellent accuracy score of 100% on validation data. Further, we are going to check other metrics like confucion matrix and F1 score\n"}}