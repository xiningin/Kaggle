{"cell_type":{"f9e1e07a":"code","eb510510":"code","2a12a8f2":"code","cdd72b64":"code","c7cc8338":"code","955a4430":"code","ec236af7":"code","38ea2c02":"code","f3682bdc":"code","dba933df":"code","07ce2e64":"code","98eb80b3":"code","6126eb27":"code","9389daac":"code","3f5901cd":"code","c1fffa2a":"code","591dc462":"code","a67ce0d5":"code","dfe7b194":"code","bcdd7459":"code","237962e5":"code","b3a28bb6":"code","313a1027":"code","5c0cc43b":"code","add79992":"code","7a52cb27":"code","ecf383b9":"code","2c00cba4":"code","308ff9c3":"code","15d33421":"code","b83b34a9":"code","35c9dc0c":"code","44600f24":"code","13dcb609":"code","55baf328":"code","47a610e2":"markdown","46d9b06b":"markdown","d82299b3":"markdown","10dfd22f":"markdown","321dbd13":"markdown","39deaed5":"markdown","35ff80f9":"markdown","d30d8c62":"markdown","b0fab136":"markdown","005af123":"markdown","b2e45838":"markdown","2ded6176":"markdown","8bdacad0":"markdown","ca31669d":"markdown","c6da812b":"markdown","6596ac15":"markdown","ce6fa500":"markdown"},"source":{"f9e1e07a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom collections import Counter\nimport string\nfrom nltk.corpus import stopwords\nimport spacy\nfrom wordcloud import WordCloud","eb510510":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss,f1_score,confusion_matrix,plot_confusion_matrix\nfrom scipy.sparse import hstack,csr_matrix\nfrom tqdm import tqdm\nimport operator","2a12a8f2":"#data=pd.read_csv('..\/data\/tripadvisor_hotel_reviews.csv')\ndata=pd.read_csv('..\/input\/trip-advisor-hotel-reviews\/tripadvisor_hotel_reviews.csv')","cdd72b64":"data.head()","c7cc8338":"data.shape","955a4430":"data.isna().sum()","ec236af7":"plt.figure(figsize=(8,8))\nsns.countplot(data['Rating'])\nplt.title('Ratings Count in the dataset',fontsize=15)\nplt.xlabel('Rating',fontsize=8)\nplt.ylabel('Count',fontsize=8)","38ea2c02":"(data['Rating'].value_counts()\/data.shape[0])*100","f3682bdc":"list(data['Review'])[:3]","dba933df":"stopwrds=set(stopwords.words(\"english\"))","07ce2e64":"#https:\/\/www.kaggle.com\/ruchi798\/how-do-you-recognize-fake-news\ndef get_bigram(df,n):\n   \n    vec=CountVectorizer(ngram_range=(2,2),stop_words=stopwrds).fit(df)\n    bag_of_words=vec.transform(df)\n    sum_words=bag_of_words.sum(0)\n    word_freq=[(word,sum_words[0,idx]) for word,idx in vec.vocabulary_.items()]\n    word_freq=sorted(word_freq,key=lambda x:x[1],reverse=True)\n    return word_freq[:n]","98eb80b3":"bigram_rat1=get_bigram(data.loc[data['Rating']==1,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does'])),10)\nbigram_rat1","6126eb27":"bigram_rat2=get_bigram(data.loc[data['Rating']==2,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does'])),10)\nbigram_rat2","9389daac":"bigram_rat3=get_bigram(data.loc[data['Rating']==3,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does'])),10)\nbigram_rat3","3f5901cd":"bigram_rat4=get_bigram(data.loc[data['Rating']==4,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does'])),10)\nbigram_rat4","c1fffa2a":"bigram_rat5=get_bigram(data.loc[data['Rating']==5,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does'])),10)\nbigram_rat5","591dc462":"## Check for common words in highest rated reviews\nset([x[0] for x in bigram_rat3])\\\n&set([x[0] for x in bigram_rat4])\\\n&set([x[0] for x in bigram_rat5])","a67ce0d5":"#Check for common words in least rated reviews\nset([x[0] for x in bigram_rat1])&set([x[0] for x in bigram_rat2])&set([x[0] for x in bigram_rat3])\n","dfe7b194":"def get_trigram(df,n):\n   \n    vec=CountVectorizer(ngram_range=(3,3),stop_words=stopwrds).fit(df)\n    bag_of_words=vec.transform(df)\n    sum_words=bag_of_words.sum(0)\n    word_freq=[(word,sum_words[0,idx]) for word,idx in vec.vocabulary_.items()]\n    word_freq=sorted(word_freq,key=lambda x:x[1],reverse=True)\n    return word_freq[:n]","bcdd7459":"trigram_rat1=get_trigram(data.loc[data['Rating']==1,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does','san','juan','punta','cana'])),10)\ntrigram_rat1","237962e5":"trigram_rat2=get_trigram(data.loc[data['Rating']==2,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does','san','juan','punta','cana'])),10)\ntrigram_rat2","b3a28bb6":"trigram_rat3=get_trigram(data.loc[data['Rating']==3,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does','san','juan','punta','cana'])),10)\ntrigram_rat3","313a1027":"trigram_rat4=get_trigram(data.loc[data['Rating']==4,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does','san','juan','punta','cana'])),10)\ntrigram_rat4","5c0cc43b":"trigram_rat5=get_trigram(data.loc[data['Rating']==5,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does','san','juan','punta','cana'])),10)\ntrigram_rat5","add79992":"## Check for common words in highest rated reviews\nset([x[0] for x in trigram_rat3])\\\n&set([x[0] for x in trigram_rat4])\\\n&set([x[0] for x in trigram_rat5])","7a52cb27":"## Check for common words in least rated reviews\nset([x[0] for x in trigram_rat1])\\\n&set([x[0] for x in trigram_rat2])\\\n&set([x[0] for x in trigram_rat3])","ecf383b9":"data['length']=data['Review'].apply(lambda x:len(x.split()))\ndata['num_chars']=data['Review'].apply(lambda x:len(str(x)))\ndata['num_punctuations']=data['Review'].apply(lambda x:len([c for c in x if x in string.punctuation]))\ndata['num_stopwords']=data['Review'].apply(lambda x:len([c for c in str(x).lower().split() if c in stopwrds]))","2c00cba4":"plt.figure(figsize=(15,10))\nplt.subplot(2,2,1)\nsns.boxplot(x='Rating',y='length',data=data,palette=sns.color_palette('colorblind'))\nplt.title('Distribution of Length by Rating',fontsize=15)\nplt.xlabel('Rating',fontsize=8)\nplt.ylabel('Length',fontsize=8)\nplt.subplot(2,2,2)\nsns.boxplot(x='Rating',y='num_chars',data=data,palette=sns.color_palette('colorblind'))\nplt.title('Distribution of Number of Characters by Rating',fontsize=15)\nplt.xlabel('Rating',fontsize=8)\nplt.ylabel('Num Chars',fontsize=8)\nplt.subplot(2,2,3)\nsns.boxplot(x='Rating',y='num_punctuations',data=data,palette=sns.color_palette('colorblind'))\nplt.title('Distribution of Num Punctuations by Rating',fontsize=15)\nplt.xlabel('Rating',fontsize=8)\nplt.ylabel('Num Punctuations',fontsize=8)\nplt.subplot(2,2,4)\nsns.boxplot(x='Rating',y='num_stopwords',data=data,palette=sns.color_palette('colorblind'))\nplt.title('Distribution of Stopwords by Rating',fontsize=15)\nplt.xlabel('Rating',fontsize=8)\nplt.ylabel('Num Stopwords',fontsize=8)","308ff9c3":"kf=StratifiedKFold(n_splits=5,random_state=42,shuffle=True)","15d33421":"feat=['length', 'num_chars', 'num_punctuations', 'num_stopwords']","b83b34a9":"encoding_dict={1:0,\n              2:1,\n              3:2,\n              4:3,\n              5:4}\ndata['Rating']=data['Rating'].map(encoding_dict)","35c9dc0c":"data['Rating'].value_counts()","44600f24":"nlp=spacy.load('en_core_web_sm',disable=['ner','parser','tagger'])\n\ndef spacy_tokenizer(text):\n    tokens=[x.text for x in nlp(text)]\n    tokens=[tok.strip() for tok in tokens]\n    ## remove most common terms identified from n-gram analysis,\n    tokens=[tok for tok in tokens if tok!='' and tok not in ['did','not','hotel','room','does','san','juan','punta','cana']]\n    return tokens","13dcb609":"oof_preds_tfidf=np.zeros((len(data),1))\nfor i,(trn_idx,val_idx) in enumerate(kf.split(data['Review'],data['Rating'])):\n    print(f'Fold {i+1} Training ...')\n    train_x=data.iloc[trn_idx,].reset_index(drop=True)\n    valid_x=data.iloc[val_idx,].reset_index(drop=True)\n    train_y=data.iloc[trn_idx,1].values\n    valid_y=data.iloc[val_idx,1].values\n    \n    word_vectorizer=TfidfVectorizer(analyzer='word',tokenizer=spacy_tokenizer,\n                       token_pattern=r'\\w{1,}',\n                       stop_words=stopwrds,\n                      ngram_range=(1,3),max_features=8000)\n    \n    word_vectorizer.fit(list(train_x['Review'].values))\n    train_word_vec=word_vectorizer.transform(list(train_x['Review']))\n    valid_word_vec=word_vectorizer.transform(list(valid_x['Review']))\n    train_x_sparse=hstack((csr_matrix(train_x[feat]),train_word_vec))\n    valid_x_sparse=hstack((csr_matrix(valid_x[feat]),valid_word_vec))\n    rf=RandomForestClassifier(n_estimators=500,\n                             max_depth=20,\n                             max_features='auto',\n                             min_samples_split=5,\n                             bootstrap=True,\n                             n_jobs=-1,\n                             random_state=42,\n                             verbose=False)\n    rf.fit(train_x_sparse,train_y)\n    preds=rf.predict(valid_x_sparse)\n    score=f1_score(valid_y,preds,average='macro')\n    print(f'Fold {i+1} f1 score {score}')\n    oof_preds_tfidf[val_idx]=preds.reshape(-1,1)\noof_score_tfidf=f1_score(data['Rating'],oof_preds_tfidf.astype('int'),average='macro')\nprint(f'Overall OOF f1 score {oof_score_tfidf}')","55baf328":"oof_preds_cv=np.zeros((len(data),1))\nfor i,(trn_idx,val_idx) in enumerate(kf.split(data['Review'],data['Rating'])):\n    print(f'Fold {i+1} Training ...')\n    train_x=data.iloc[trn_idx,].reset_index(drop=True)\n    valid_x=data.iloc[val_idx,].reset_index(drop=True)\n    train_y=data.iloc[trn_idx,1].values\n    valid_y=data.iloc[val_idx,1].values\n    \n    count_vectorizer=CountVectorizer(analyzer='word',tokenizer=spacy_tokenizer,\n                       token_pattern=r'\\w{1,}',\n                       stop_words=stopwrds,\n                      ngram_range=(1,3),max_features=8000)\n    \n    count_vectorizer.fit(list(train_x['Review'].values))\n    train_word_vec=count_vectorizer.transform(list(train_x['Review']))\n    valid_word_vec=count_vectorizer.transform(list(valid_x['Review']))\n    train_x_sparse=hstack((csr_matrix(train_x[feat]),train_word_vec))\n    valid_x_sparse=hstack((csr_matrix(valid_x[feat]),valid_word_vec))\n    rf=RandomForestClassifier(n_estimators=500,\n                             max_depth=20,\n                             max_features='auto',\n                             min_samples_split=5,\n                             bootstrap=True,\n                             n_jobs=-1,\n                             random_state=42,\n                             verbose=False)\n    rf.fit(train_x_sparse,train_y)\n    preds=rf.predict(valid_x_sparse)\n    score=f1_score(valid_y,preds,average='macro')\n    print(f'Fold {i+1} f1 score {score}')\n    oof_preds_cv[val_idx]=preds.reshape(-1,1)\noof_score_cv=f1_score(data['Rating'],oof_preds_cv.astype('int'),average='macro')\nprint(f'Overall OOF f1 score {oof_score_cv}')","47a610e2":"### Using Count Vectorizer and Random Forest","46d9b06b":"## n-gram Analysis","d82299b3":"## Using TF-IDF and Random Forest Model","10dfd22f":"1.https:\/\/www.kaggle.com\/ruchi798\/how-do-you-recognize-fake-news\n\n2.https:\/\/www.kaggle.com\/anokas\/data-analysis-xgboost-starter-0-35460-lb","321dbd13":"From the n-gram analysis of words,it is seen that there are many words which appear across the reviews and this is a challenge since it might make our model difficult to distinguish between the ratings.\n\nLets see if we can find any difference in the length,number of words etc across the rating.","39deaed5":"### Feature Engineering","35ff80f9":"### References:","d30d8c62":"In this kernel,I am going to do an analysis on the hotel reviews from Trip advisor dataset.The ratings scale is from 1-5 and there are 20491 reviews provided.\n\n#### Approach:\n\nI plan to do an n-gram and word cloud analysis to find out if the reviews could be easily differentiated with respect to their ratings.Then I plan to build basic models -TFIDF,Count vectorizer with either Logit or RandomForest.This is a multi-class classification problem.","b0fab136":"Analysis of the bigrams for the ratings provides us the following insight:\n\n1.There are bigrams which are more common in all the reviews.\n\n2.great location,staff friendly,staff helpful,stayed nights,walking nights were more pronunced as the rating moves from 3 to 5 whereas stay away,customer service,make sure were few bigrams which were seen in reviews with rating 1-3.\n\n4.Punta cana and San Juan are names of places which were found in almost all of the reviews irrespective of the rating.\n\nFor trigram analysis,Lets remove these common location names and check the corpus.","005af123":"### Loading the data","b2e45838":"* There is a slight difference in the median length of the reviews with respect to each rating.But the difference is not pronunced much.Rating 5 has lesser median value compared to other ratings.\n\n* Similarly when the number of characters is considered,rating 5 has a smaller median value compared to other.But the difference is not easily distinguishable.\n\n* An empty plot for the punctuation indicates that there are no reviews having punctuations !!! Strange ..\n\n* The number of stopwords with respect to each rating is also dominated by lot of outliers.Those providing ratings of 5 are using more stopwords compared to other ratings.","2ded6176":"## Trip Advisor Hotel Review Prediction","8bdacad0":"Similar to bigram analysis,trigram analysis presents us imporant insights:\n\n1.There are common words in highest rated reviews among the top 10 most common words. - 10 minute walk,flat screen tv,staff friendly helpful are a few.\n\n2.King size bed is the common trigram which appears in all the reviews across the rating.","ca31669d":"### Data Cleaning and handling missing values (if any)","c6da812b":"There are no null values in either of the columns.","6596ac15":"## Basic Modelling","ce6fa500":"44 % of the dataset has reviews with rating 5 while 29 % of the datset has reviews with rating 4."}}