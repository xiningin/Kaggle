{"cell_type":{"1035ee1e":"code","abfd039a":"code","51ec0d59":"code","79ccd847":"code","c1b33904":"code","da8dba65":"code","81a18c94":"code","d3983843":"code","fe21f81f":"code","26049355":"code","7ebfa50e":"code","3661cd8c":"code","47f50121":"code","4d0136b4":"code","1291568d":"code","bad085f2":"code","b45ff2aa":"code","1535a178":"code","8e54c54d":"code","1038eecd":"code","95e40df7":"code","a4db29e9":"code","9d100e65":"code","d4a234bb":"code","5f2aa308":"code","58f54dff":"code","b8aa21ec":"code","0510cef6":"code","cc4b964e":"code","ee561287":"code","61f0e432":"code","7ef02e69":"code","507f2544":"code","15799f5b":"code","fd291aa9":"code","933f9987":"code","fc34cf0a":"code","a9cc85e4":"code","798424cc":"code","9436bf17":"code","4c4e3fa9":"code","211d6d3b":"code","09de4f63":"code","5935c257":"code","f8bfb1f8":"code","9a3ed571":"code","fde9372c":"code","c3a65bf2":"code","9bf41b48":"code","47b30c7b":"code","255ca22d":"code","246eb9ba":"code","0ec4113c":"markdown","ce548e77":"markdown","0c79b758":"markdown","80aadde2":"markdown","25249b9d":"markdown","28eeee9e":"markdown","538de5bc":"markdown","b8cfcd98":"markdown","70ae16ef":"markdown","63716788":"markdown","18263287":"markdown","99a70a85":"markdown","3145635b":"markdown","cc2cb9c6":"markdown","5ba2016e":"markdown","34b0833a":"markdown","2d53a51c":"markdown","866e2e7f":"markdown","9cb8f5d5":"markdown","3e72a2b5":"markdown","1add3594":"markdown","c4b4a389":"markdown","cfd12612":"markdown","d0e103a4":"markdown"},"source":{"1035ee1e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","abfd039a":"#import relevant libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","51ec0d59":"#load the data\nsurvey_data=pd.read_csv(\"..\/input\/maggisurvey\/Maggi-Survey .csv\")\nsurvey_data","79ccd847":"#Copy the data into a new variable\nmaggi_data=survey_data.copy()\n","c1b33904":"#Display the column names\nmaggi_data.columns.values","da8dba65":"#Drop the \"Timestamp\" column\nmaggi_data=maggi_data.drop('Timestamp', axis=1)","81a18c94":"#Create a list object containing the modified names for columns\ncolumn_names=['age','number_of_times','consumption(in pkt)','competitors','add_ingredients','ingredients','go_to_meal','effect_of_lead','nutritive_value','rs15pack','masala_magic','inc_masala']","d3983843":"#Create the list with keys as old column names and values as corresponding new names.\nnames=dict()\nfor i in range(len(column_names)):\n    names[maggi_data.columns.values[i]]=column_names[i]","fe21f81f":"#Rename the column\nmaggi_data=maggi_data.rename(columns=names)","26049355":"#Mapping the values of \"number of times\" column from 1-5 accordingly going from lower conumption to higher consumption\nmaggi_data[\"number_of_times\"]=maggi_data[\"number_of_times\"].map({\"Less often\":1,\"Once in a month\":2,\"Once in two weeks\":3,\"Once in a week\":4,\"More than once in a week\":5})","7ebfa50e":"#Removing PKT from the values and mapping \"More than 2 PKTS\" with \"3\" in the \"consumption(in pkt)\" column\nmaggi_data[\"consumption(in pkt)\"]=maggi_data[\"consumption(in pkt)\"].map({\"1 PKT\":1,\"2 PKTS\":2,\"More than 2 PKTS\":3})","3661cd8c":"# Bar chart showing the distrinution of age groups.\nplt.bar(maggi_data['age'].value_counts().index ,maggi_data['age'].value_counts().values, color=['#ffed00',\"#ed232a\",'#023047'])\nplt.xlabel('Age group', fontsize=13)\nplt.ylabel('Frequency', fontsize=13)\nplt.title('Age group of respondents', fontsize=16, fontweight=\"bold\")\nplt.show()","47f50121":"#Bar chart showing top compettors of Maggi \nplt.barh(maggi_data['competitors'].value_counts().index, maggi_data['competitors'].value_counts().values, color=['#e85d04','#023047','#370617','#008641','#d00000'])\nplt.xlabel('No. of people who prefer this brand', fontsize=13)\nplt.ylabel('Brand name', fontsize=13)\nplt.title('Close competitors of Maggi', fontsize=16, fontweight=\"bold\")\nplt.show()","4d0136b4":"#Bar chart showing the no of people who consider\/dont't consider maggi as complete meal\nsns.countplot(x=maggi_data['add_ingredients'], data= maggi_data ,palette=[\"#ffc922\",'#ed232a']).set_title('Is Maggi prefered with added ingredients ?', fontdict={'fontsize':16,'fontweight': 'bold'})","1291568d":"#Top 2 ingredients that people prefer with maggi noodles\ningredients=[]\nfor i in range(maggi_data[\"ingredients\"].shape[0]):\n    a=str(maggi_data[\"ingredients\"][i]).split(\";\")\n    ingredients+=a\ningredients_series=pd.Series(ingredients)\nprint(ingredients_series.value_counts().head(2))","bad085f2":"#Bar chart showing the the no. of people whose consumption declined\/didn't decline after 2015 lead controversy. \nsns.countplot(x=maggi_data['effect_of_lead'], data= maggi_data ,palette=[\"#ffc922\",'#ed232a']).set_title('Has consumption declined after the Lead Controversy with Maggi?',fontdict= { 'fontsize': 16, 'fontweight':'bold'})","b45ff2aa":"#create a dataframe for stacked area chart\nnutritive_value=pd.DataFrame()\n#create a column containing possible values for 'no_of_times' column\nnutritive_value['How_Often']=np.sort(maggi_data['number_of_times'].unique())","1535a178":"#create a list containing the no. of people who finds nutritive value in maggi noodles and consumes it different no. of times.\nyes_value=[]\nfor i in np.sort(maggi_data['number_of_times'].unique()):\n    yes_value.append(np.argwhere((maggi_data['number_of_times'].to_numpy()==i) & (maggi_data['nutritive_value'].to_numpy()=='Yes')).shape[0])","8e54c54d":"#create a list containing the no. of people who doesn't find nutritive value in maggi noodles and consumes it different no. of times.\nno_value=[]\nfor i in np.sort(maggi_data['number_of_times'].unique()):\n    no_value.append(np.argwhere((maggi_data['number_of_times'].to_numpy()==i) & (maggi_data['nutritive_value'].to_numpy()=='No')).shape[0])","1038eecd":"#Add the above two list as separate columns in \"nutritive value\" dataframe.\nnutritive_value['Yes']= yes_value\nnutritive_value['No']= no_value","95e40df7":"nutritive_value","a4db29e9":"#Stacked Area Chart showing the frequency of people who consumes maggi noodles different no. of times stacked by whether they\n#nutritive_value in it.\nplt.stackplot(nutritive_value['How_Often'],nutritive_value['Yes'],nutritive_value['No'], colors =[\"#e5383b\",\"#FFB703\"])\nplt.legend(labels=['Yes','No'], loc=\"upper left\")\nplt.xlim((1,5))\nplt.title(\"Do people find Nutritive value in Maggi ?\",fontsize=15, fontweight='bold')\nplt.xlabel(\"How often does a person consume Maggi\", fontsize=13)\nplt.ylabel(\"Frequency\", fontsize=13)\nplt.show()","9d100e65":"#Doughnut Chart showing the percentage of people who consider maggi as their go to meal.\n\ncolors=[\"#ffed00\",\"#ed232a\"]\nplt.pie(maggi_data['go_to_meal'].value_counts().values,colors=colors,autopct='%1.1f%%',labels=maggi_data['go_to_meal'].value_counts().index)\ncentre_circle=plt.Circle((0,0),0.50,fc=\"white\")\nfig=plt.gcf()\nfig.gca().add_artist(centre_circle)\nplt.title(\"PERCENTAGE OF PEOPLE WHO CONSIDER MAGGI AS THEIR GO TO MEAL\",fontsize=\"15\",fontweight=\"bold\")\nplt.show()","d4a234bb":"#create a contingency table for 'inc_masala' and 'masala_magic'\ndata_crosstab = pd.crosstab(maggi_data['inc_masala'], maggi_data['masala_magic'], \n                               margins = False)\nprint(data_crosstab)","5f2aa308":"#Performing chi square test to test the independence of attributes\nfrom scipy.stats import chi2_contingency\nfrom scipy.stats import chi2\nstat, p, dof, expected = chi2_contingency(data_crosstab)\nprint('dof=%d' % dof)\nprint(expected)\n# interpret test-statistic\nprob = 0.95\ncritical = chi2.ppf(prob, dof)\nprint('probability=%.3f, critical=%.3f, stat=%.3f' % (prob, critical, stat))\n# interpret p-value\nalpha = 1.0 - prob\nprint('significance=%.3f, p=%.3f' % (alpha, p))\n","58f54dff":"#Bar chart showiwng the frequency of people who want\/doesn't want Maggi to increase its taste maker size.\nsns.countplot(x=maggi_data['inc_masala'], data= maggi_data ,palette=[\"#ffed00\",'#ed232a']).set_title('Do people want Maggi to increase it''s tastemaker size at the cost of increased prices?',fontdict= { 'fontsize': 16, 'fontweight':'bold'})","b8aa21ec":"#Import the KMeans module so we can perform k-means clustering with sklearn\nfrom sklearn.cluster import KMeans","0510cef6":"maggi_data","cc4b964e":"#Create a dataframe that contains 'ExpenseRating' and 'FieldRating' columns\ncluster_df = pd.DataFrame({'consumption(in pkt)':maggi_data['consumption(in pkt)'], 'number_of_times':maggi_data['number_of_times']})\ncluster_df","ee561287":"#Plotting the data using scatter plot\nplt.scatter(cluster_df['number_of_times'],cluster_df['consumption(in pkt)']) \n\nplt.xlabel('number_of_times')\nplt.ylabel('consumption(in pkt)')\nplt.show()","61f0e432":"# Create an empty list\nwcss=[]\n\n# Create all possible cluster solutions with a loop\nfor i in range(1,7):\n    # Cluster solution with i clusters\n    kmeans = KMeans(i)\n    # Fit the data\n    kmeans.fit(cluster_df)\n    # Find WCSS for the current iteration\n    wcss_iter = kmeans.inertia_\n    # Append the value to the WCSS list\n    wcss.append(wcss_iter)\nwcss","7ef02e69":"# Create a variable containing the numbers from 1 to 6, so we can use it as X axis of the future plot\nnumber_clusters = range(1,7)\n# Plot the number of clusters vs WCSS\nplt.plot(number_clusters,wcss)\n# Name the graph\nplt.title('The Elbow Method')\n# Name the x-axis\nplt.xlabel('Number of clusters')\n# Name the y-axis\nplt.ylabel('Within-cluster Sum of Squares')\nplt.show()","507f2544":"# Create an object (which we would call kmeans)\nkmeans = KMeans(3)\n#  Fit the input data, i.e. cluster the data in cluster_df in 3 clusters\nkmeans.fit(cluster_df)","15799f5b":"#Create a copy of 'cluster_df' dataframe \nclusters = cluster_df.copy() \n#Create a new column, containing the predicted clusters for each observation.\nclusters['cluster_pred']=kmeans.fit_predict(cluster_df)\n## Plot the data using the 'number_of_times' and 'consumption(in pkt)'\n# c (color) is an argument which could be coded with a variable \n# The variable in this case has values 0,1,2, indicating to plt.scatter, that there are three colors (0,1,2)\n# All points in cluster 0 will be the same colour, all points in cluster 1 - another one, etc.\n# cmap is the color map\nplt.scatter(clusters['number_of_times'],clusters['consumption(in pkt)'],c=clusters['cluster_pred'],cmap='rainbow', alpha=0.5)\nplt.xlabel('number_of_times',fontsize=13)\nplt.ylim(0,4)\nplt.ylabel('consumption(in pkt)',fontsize=13)\nplt.title(\"Consumption Analysis\", fontsize=16)\n","fd291aa9":"#Create a dataframe of records included in 1st cluster i.e. cluster of lower consumption.\nlow_consumption=clusters[clusters['cluster_pred']==1]","933f9987":"#Create a list object  that contains nutritive_value response of the people whose consumption is low.\na=[]\nfor i in low_consumption.index:\n    a.append(maggi_data['nutritive_value'][i])","fc34cf0a":"#Create a list object  that contains effect_of_lead response of the people whose consumption is low.\nb=[]\nfor i in low_consumption.index:\n    b.append(maggi_data['effect_of_lead'][i])","a9cc85e4":"#Adding the above created lists as columns in the \"low_consumption\" column \nlow_consumption['nutritive_value']=a\nlow_consumption['effect_of_lead']=b\nlow_consumption","798424cc":"#probability that the person's consumption decreased after lead controversy given his\/her consumption is low\nP_a= (np.argwhere(low_consumption['effect_of_lead'].to_numpy()=='Yes, It did').shape[0])\/low_consumption.shape[0]\nP_a","9436bf17":"#probability that the person doesn't find any nutritive value in maggi given his\/her consumption is low\nP_b= (np.argwhere(low_consumption['nutritive_value'].to_numpy()=='No').shape[0])\/low_consumption.shape[0]\nP_b","4c4e3fa9":"#probability that the person's consumption decreased after lead controversy and the person doesn't find any nutritive value in maggi given his\/her consumption is low\nP_ab= (np.argwhere((low_consumption['nutritive_value'].to_numpy()=='No') & (low_consumption['effect_of_lead'].to_numpy()=='Yes, It did')).shape[0])\/low_consumption.shape[0]\nP_ab","211d6d3b":"#probability that the person's consumption decreased after lead controversy or the person doesn't find any nutritive value in maggi given his\/her consumption is low\nP_a_union_b= P_a + P_b - P_ab\nP_a_union_b","09de4f63":"#Assign value 3 to the people who consume maggi noodles more than once or once in a week or once in two weeks. \nnaive_df=pd.DataFrame()\nnaive_df['number_of_times']=np.where(np.isin(maggi_data[\"number_of_times\"],[3,4,5]),3,maggi_data[\"number_of_times\"])","5935c257":"#Add 'consumption(in pkt)' column in the newly_created dataframe. \nnaive_df[\"consumption(in pkt)\"]=maggi_data['consumption(in pkt)']","f8bfb1f8":"naive_df","9a3ed571":"# store the feature matrix (X) and response vector (y)\nX = naive_df\ny = pd.DataFrame({\"rs15pack\":maggi_data[\"rs15pack\"]})\n  \n# splitting X and y into training and testing sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n  \n# training the model on training set\nfrom sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)\n  \n# making predictions on the testing set\ny_pred = gnb.predict(X_test)\n  \n# comparing actual response values (y_test) with predicted response values (y_pred)\nfrom sklearn import metrics\nprint('Gaussian Naive Bayes model accuracy(in %):', metrics.accuracy_score(y_test,y_pred)*100)\n      ","fde9372c":"'''\nMake prediction whether a peron would prefer Rs.15 pack of maggi noodles given he\/she consumes 1 pack of maggi noodles at a \ntime and consumes it quite oftenly. using the naive bayes classifier\n'''\nx=pd.DataFrame({\"number_times\":[3],\"consumption(in pkt)\":[1]})\nprint(gnb.predict(x))","c3a65bf2":"#profit or loss calculations(monthly)\n#Assigning 0,1,2,4,8 to the persons who consume maggi noodles given no. times in a month respectively\nmonthly_consumption= np.array(maggi_data[\"number_of_times\"].map({1:0,2:1,3:2,4:4,5:8}))\n#profit or loss maggi would bear is it introduced Rs.15 pack from each category of consumers.\nprofit_loss=np.array(maggi_data['consumption(in pkt)'].map({1:3,2:-9,3:-6}))","9bf41b48":"#Calculating the sum of product of corresponding values of above two columns would give us monthly profit\/loss\nsum(monthly_consumption*profit_loss)\n","47b30c7b":"#monthly revenue earned by maggi by Rs.12 pack of noodles\nrs12=np.array(maggi_data['consumption(in pkt)'].map({1:12,2:24,3:36}))\nsum(monthly_consumption*rs12)","255ca22d":"#monthly revenue earned by maggi by Rs.15 pack of noodles\nrs15=np.array(maggi_data['consumption(in pkt)'].map({1:15,2:15,3:30}))\nsum(monthly_consumption*rs15)","246eb9ba":"#percentage loss\n(sum(monthly_consumption*profit_loss)\/sum(monthly_consumption*rs12))*100","0ec4113c":"We want WCSS to be as low as possible while we can still have small no. of clusters so we could interpret them.<br>\nIn the above graph, we are getting two elbow points i.e. at 2 and 3<br>\n3 is the biggest no. of cluster for which we are still getting the significant decrease in WCSS. Thereafter there is almost no improvement.<p>\nSo we will go with 3 cluster solution. ","ce548e77":"The consumption has remained same for majority of people as it was before the lead controversy with Maggi in 2015.","0c79b758":"Out of all the people who consume Maggi very rarely, around 90% of the people either do not find any nutritive value in Maggi or their consumption decreased after the lead controversy.\nIt suggests that these people are quite health conscious. Maggi might want to work on making this cluster of people believe that Maggi is safe to eat.","80aadde2":"Yippee seems to be the closest competitor of Maggi among other brands with around 45% of the people preferring Yippee after Maggi.","25249b9d":"The graph compares how often a person consumes Maggi and whether or not they find any nutritive value in Maggi. It suggests that people who don't find any nutritive value in Maggi either don't consume it or have it very rarely. But at the same time we see that the people who consumes Maggi quite often, also don't find any nutritive value in Maggi. Although there are some people who find it nutritious but their propotion is almost imperceptible.","28eeee9e":"Maggi would have to bear a monthly loss of approximately 5% if it introduced Rs.15 pack of maggi noodles. ","538de5bc":"The problem is to test that the two attributes under consideration i.e. \"inc_masala\" and 'masala_magic' are independent or not.<br>\nTherefore Test of Independence of Attributes need to be used.","b8cfcd98":"Spices like oregano & chili flakes, and Veggies comes out to be the top 2 ingredients prefered by people along with their Maggi. This suggests Maggi can come up with flavors similar to these, to make their cutomers more happy.","70ae16ef":"Null Hypotheses(H_0): Attributes are independent<br>\nAlternative Hypotheses(H_1): Attributes are not independent<p>\nLevel of Significance(alpha)=0.05\n","63716788":"The Naive Bayes Classifier has been deployed to predict whether a person would prefer Rs 15 pack of maggi noodles given he\/she consumes 1 pack of maggi noodles at a time and consumes it quite oftenly.<br>\nThe person who consumes 1 pack of maggi noodles would be profitable if he\/she would shift to Rs 15 pack and if he\/she consumes it quit oftenly.","18263287":"## Exploartory Data Analysis","99a70a85":"According to the Naive Bayes Classifier a person would prefer Rs.15 pack of maggi noodles given he\/she consumes 1 pack of maggi noodles at a time and consumes it quite oftenly. ","3145635b":"## Naive Bayes Classifier","cc2cb9c6":"Yayyy!! Maggi has become the Go-To-Meal for around 60% of the people consuming it.","5ba2016e":"The above 2 graphs suggested how people prioritise Taste over Health. Even though they find the product less healthy and safe, their consumption level didn't decline much.","34b0833a":"**1st cluster** (People who consume maggi noodles less often and consume not more than 2 packs at a time): *Dissatisfied Customers* <br>\n**2nd cluster** (People who consume maggi noodles once in two weeks and consume not more than 2 packs at a time): *Stable Customers*<br>\n**3rd cluster** (People who consume maggi noodles quite often): *Best Customers*","2d53a51c":"Since p value(0.135) is greater than level of significance(0.05), null hyopotheses may be accepted.<br>\nThere is not enough statistical evidence to conclude that Attributes are dependent.<p>\nTherefore there is no relation between whether a person wants tastemaker size to be increased and if he\/she buys maggi masala-ae-magic with maggi noodles.","866e2e7f":"More than 90% of the respondents belong to the age group of 18-26 which are mostly college going students.","9cb8f5d5":"## About Respondents","3e72a2b5":"## Cluster Analysis","1add3594":"Yes, people want Maggi to increase its Tastemaker size. These people are also willing to pay extra price.\nHowever there are around 38% of people who might or might not want Maggi to increase the size of its tastemaker but they defenitely don't want Maggi to increase cost.","c4b4a389":"More than 70% of the people prefer adding additional ingredients in their Maggi, this shows people experimenting with and cutomizing Maggi according to their own taste.","cfd12612":"## Preprocessing ","d0e103a4":"## Hypotheses Testing"}}