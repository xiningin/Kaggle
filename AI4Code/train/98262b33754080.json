{"cell_type":{"bfad7292":"code","b2355991":"code","9eee3c78":"code","65ec6585":"code","928a96f2":"code","3d486435":"code","20050b5f":"code","bb38860d":"code","21b881cf":"code","16fd781e":"code","fec18d64":"code","f52240b0":"code","4750f9e2":"code","73cb7ffc":"code","c8da542b":"code","797893d1":"code","cc7a7ca2":"code","1c556aed":"code","e7d95a0a":"code","84b93574":"code","d742f9e5":"code","05732454":"code","4e1bcef8":"code","c8d601d5":"code","1bbfdfcb":"code","0bb1a316":"code","5b7e8ae9":"code","17850a89":"code","7e7dcc9a":"code","fb29f54a":"code","3bf99238":"code","89fc423f":"code","87e9499e":"code","fa1c4704":"code","c0f6d68d":"code","1025d4bb":"code","eaed9341":"code","9abf0984":"markdown","37eab350":"markdown","dbf60a59":"markdown","34077884":"markdown","7f0661ab":"markdown","c46ebe59":"markdown","a81f5047":"markdown","c9cda082":"markdown","2d49ebaf":"markdown","1a7dad28":"markdown","b02e5414":"markdown","a2407d3d":"markdown","af892e19":"markdown","3d310b05":"markdown","911b0e29":"markdown","fb171a13":"markdown","0d4c7e99":"markdown","999ae628":"markdown","1473af13":"markdown","4b2250bf":"markdown","cf60c839":"markdown","95bacd68":"markdown","247db1fe":"markdown","12c7528c":"markdown","9fc3e7e9":"markdown"},"source":{"bfad7292":"#Loading Libraries\n\n#text analysis\nimport re \nimport nltk \nimport string\n\n#data processing\nimport pandas as pd\nimport numpy as np\n\n#visualisation\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n\n\n%matplotlib inline","b2355991":"pd.set_option(\"display.max_colwidth\", 300)\n#This helps us see the dataframes in a more visually pleasing manner","9eee3c78":"train=pd.read_csv(\"..\/input\/train.csv\")\ntest=pd.read_csv(\"..\/input\/test.csv\")\ntrain.head()","65ec6585":"#Typical non-negative tweets\n\ntrain[train['label'] == 0].head(10)","928a96f2":"#Typical negative tweets\ntrain[train['label'] == 1].head(10)","3d486435":"#Dataset shape\ntrain.shape, test.shape","20050b5f":"#Dataset Distribution\n\ntrain[\"label\"].value_counts()","bb38860d":"#Visualising\n%matplotlib inline\n\nlabels=['Negative', 'Positive']\ncolors = ['mistyrose','lightcyan']\nsizes=[train['label'].value_counts()[1],\n     train['label'].value_counts()[0]]\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, colors=colors,autopct='%1.0f%%')\nax1.axis('equal')\nplt.show()","21b881cf":"#Checking the distribution of length of tweets in training and test set\n\nlength_train = train['tweet'].str.len()\nlength_test = test['tweet'].str.len()\n\nplt.hist(length_train, bins=20, label=\"train_tweets\", color='mistyrose')\nplt.hist(length_test, bins=20, label=\"test_tweets\", color='darksalmon')\nplt.legend()\nplt.show()","16fd781e":"#combine test and train set\ncombine= train.append(test,ignore_index=True, sort=True)","fec18d64":"#function that removes a specific user-defined pattern from text, which we can use later\ndef remove_pattern(input_txt, pattern):\n    r=re.findall(pattern,input_txt)\n    for i in r:\n        input_txt=re.sub(i,'',input_txt)\n    return input_txt\n","f52240b0":"#create a new column \"tidy_tweet\" which has our processed, tidy treat without redundancies\n#removes '@user'; regular expression \"@[\\w]*\" returns anything starting with @\n\ncombine['tidy_tweet'] = np.vectorize(remove_pattern)(combine['tweet'], \"@[\\w]*\")","4750f9e2":"#remove special characters, except #\ncombine['tidy_tweet'] = combine['tidy_tweet'].str.replace(\"[^a-zA-Z#]\", \" \")","73cb7ffc":"#remove short words\ncombine['tidy_tweet']=combine['tidy_tweet'].apply(lambda x:' '.join([w for w in x.split() if len(w)>3]))","c8da542b":"combine.head()","797893d1":"#tokenising\ntokenised_tweet= combine['tidy_tweet'].apply(lambda x: x.split())\ntokenised_tweet.head()","cc7a7ca2":"#stemming\nfrom nltk.stem.porter import *\nstemmer = PorterStemmer()\n\ntokenised_tweet = tokenised_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\ntokenised_tweet.head()","1c556aed":"#put all tokens back as the tidy_tweet\nfor i in range(len(tokenised_tweet)):\n    tokenised_tweet[i] = ' '.join(tokenised_tweet[i])\ncombine['tidy_tweet']=tokenised_tweet\n\n\ncombine.head()","e7d95a0a":"#wordcloud generation for all tweets\n\nall_words=' '.join([text for text in combine['tidy_tweet']])\nfrom wordcloud import WordCloud\nword_cloud=WordCloud(width=800, height=500, random_state=21,max_font_size=110,colormap='tab20').generate(all_words)\n\nplt.figure(figsize=(10, 7))\nplt.imshow(word_cloud)\nplt.axis('off')\nplt.show()","84b93574":"#wordcloud for positive (non-racist) tweets\nnon_negative_words=' '.join([text for text in combine['tidy_tweet'][combine['label']==0]])\nfrom wordcloud import WordCloud\nword_cloud=WordCloud(width=800, height=500, random_state=21,max_font_size=110,colormap='tab20').generate(non_negative_words)\n\nplt.figure(figsize=(10, 7))\nplt.imshow(word_cloud)\nplt.axis('off')\nplt.show()","d742f9e5":"#wordcloud for negative (racist) tweets\nnegative_words=' '.join([text for text in combine['tidy_tweet'][combine['label']==1]])\nfrom wordcloud import WordCloud\nword_cloud=WordCloud(width=800, height=500, random_state=21,max_font_size=110,colormap='tab20').generate(negative_words)\n\nplt.figure(figsize=(10, 7))\nplt.imshow(word_cloud)\nplt.axis('off')\nplt.show()","05732454":"# function to collect hashtags\ndef hashtag_extract(x):\n    hashtags = []\n    for i in x:\n        ht = re.findall(r\"#(\\w+)\", i)\n        hashtags.append(ht)\n\n    return hashtags","4e1bcef8":"#hashtag list for non negative tweets\nHT_non_negative = hashtag_extract(combine['tidy_tweet'][combine['label'] == 0])\n\n#hashtag list for negative tweets\nHT_negative = hashtag_extract(combine['tidy_tweet'][combine['label'] == 1])\n\n#unnest list\nHT_non_negative = sum(HT_non_negative,[])\nHT_negative = sum(HT_negative,[])","c8d601d5":"#most used hashtag for non negative tweets\n\na = nltk.FreqDist(HT_non_negative)\nd = pd.DataFrame({'Hashtag': list(a.keys()),\n                  'Count': list(a.values())})\n# selecting top 10 most frequent hashtags     \nd = d.nlargest(columns=\"Count\", n = 10) \n\nplt.figure(figsize=(10,8))\nax = sns.barplot(data=d, x= \"Hashtag\", y = \"Count\",palette=\"cubehelix\")\nax.set(ylabel = 'Count')\nplt.show()","1bbfdfcb":"#most negative hashtags\nb = nltk.FreqDist(HT_negative)\nd = pd.DataFrame({'Hashtag': list(b.keys()),\n                  'Count': list(b.values())})\n# selecting top 10 most frequent hashtags     \nd = d.nlargest(columns=\"Count\", n = 10) \n\nplt.figure(figsize=(10,8))\nax = sns.barplot(data=d, x= \"Hashtag\", y = \"Count\",palette=\"cubehelix\")\nax.set(ylabel = 'Count')\nplt.show()","0bb1a316":"#bag of word features\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nbow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\nbow=bow_vectorizer.fit_transform(combine['tidy_tweet'])\n\nbow.shape","5b7e8ae9":"#TF-IDF features\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\ntfidf=tfidf_vectorizer.fit_transform(combine['tidy_tweet'])\n\ntfidf.shape","17850a89":"import gensim\ntokenized_tweet = combine['tidy_tweet'].apply(lambda x: x.split()) # tokenizing\n\nmodel_w2v = gensim.models.Word2Vec(\n            tokenized_tweet,\n            size=200, # desired no. of features\/independent variables \n            window=5, # context window size\n            min_count=2,\n            sg = 1, # 1 for skip-gram model\n            hs = 0,\n            negative = 10, # for negative sampling\n            workers= 2, # no.of cores\n            seed = 34)\n\nmodel_w2v.train(tokenized_tweet, total_examples= len(combine['tidy_tweet']), epochs=20)","7e7dcc9a":"#Find most similar words in the corpus for a given word\n\nmodel_w2v.wv.most_similar(positive=\"trump\")","fb29f54a":"def word_vector(tokens, size):\n    vec = np.zeros(size).reshape((1, size))\n    count = 0.\n    for word in tokens:\n        try:\n            vec += model_w2v[word].reshape((1, size))\n            count += 1.\n        except KeyError: # handling the case where the token is not in vocabulary\n                         \n            continue\n    if count != 0:\n        vec \/= count\n    return vec","3bf99238":"wordvec_arrays = np.zeros((len(tokenized_tweet), 200))\n\nfor i in range(len(tokenized_tweet)):\n    wordvec_arrays[i,:] = word_vector(tokenized_tweet[i], 200)\n    \nwordvec_df = pd.DataFrame(wordvec_arrays)\n\nwordvec_df.shape","89fc423f":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score","87e9499e":"#BOG feature model\n\ntrain_bow = bow[:31962,:]\ntest_bow = bow[31962:,:]\n\nxtrain_bow, xval_bow,ytrain,yval=train_test_split(train_bow,train['label'],random_state=42,test_size=0.3)\n\nlr=LogisticRegression()\nlr.fit(xtrain_bow,ytrain)\n\nprediction=lr.predict_proba(xval_bow)\nprediction_int = prediction[:,1] >= 0.3\nprediction_int = prediction_int.astype(np.int)\n\nf1_score(yval,prediction_int)","fa1c4704":"test_pred = lr.predict_proba(test_bow)\ntest_pred_int = test_pred[:,1] >= 0.3\ntest_pred_int = test_pred_int.astype(np.int)\ntest['label'] = test_pred_int\n\nsubmission = test[['id','label']]\n\n#submission.to_csv('sub_lreg_bow.csv', index=False) # writing data to a CSV file","c0f6d68d":"#TF-IDF\ntrain_tfidf = tfidf[:31962,:]\ntest_tfidf = tfidf[31962:,:]\n\nxtrain_tfidf = train_tfidf[ytrain.index]\nxvalid_tfidf = train_tfidf[yval.index]\n\nlr.fit(xtrain_tfidf, ytrain)\n\nprediction = lr.predict_proba(xvalid_tfidf)\nprediction_int = prediction[:,1] >= 0.3\nprediction_int = prediction_int.astype(np.int)\n\nf1_score(yval, prediction_int)","1025d4bb":"train_w2v = wordvec_df.iloc[:31962,:]\ntest_w2v = wordvec_df.iloc[31962:,:]\n\nxtrain_w2v = train_w2v.iloc[ytrain.index,:]\nxvalid_w2v = train_w2v.iloc[yval.index,:]","eaed9341":"lr.fit(xtrain_w2v, ytrain)\n\nprediction = lr.predict_proba(xvalid_w2v)\nprediction_int = prediction[:,1] >= 0.3\nprediction_int = prediction_int.astype(np.int)\nf1_score(yval, prediction_int)","9abf0984":"### Bag of Words Features","37eab350":"### Hashtag Analysis","dbf60a59":"Creating vectors for tweets","34077884":"The distribution of the tweet length is pretty much the same.","7f0661ab":"Word2Vec has 200 features, as opposed to the 1000 features in BOW and TFIDF. What does this do? Save space and time.","c46ebe59":"## Building the Model\n\nWe will use a Logistic Regression model to test the performance using our three different feature sets.","a81f5047":"### Word2Vec Embeddings","c9cda082":"Right off the bat we can see that usernames, numerics and special characters are not necesarry to classify the sentiment of the tweet. What is essential, however, is the hashtag. \n\nA good rule of thumb while dealing with twitter (or social media) data is to keep the hashtags, as they can explicitly denote the emotion, tone, or subject of the tweet.","2d49ebaf":"As can be seen, Word2Vec embeddings outperform TFIDF and BOW.","1a7dad28":"## Data Exploration\n\nUnderstanding the labelled dataset.","b02e5414":"### Tokenising the Tweets\n\nHere, tokens are the individual words of the tweet, so we just split it.","a2407d3d":"As we see, hashtags are quite important in our dataset, as they have explicit negative\/non-negative associations.","af892e19":"### Word Cloud Generation","3d310b05":"### TFIDF Features","911b0e29":"### Removing Redundant Characters and Words","fb171a13":"### TF-IDF Features","0d4c7e99":"## Preprocessing and Cleaning the Data\n\nFor cleaning the data, we will do the following:\n\n1. Combine both test and training set so we can preprocess both together\n2. Remove redundant characters- numerics, special characters (not hashtags), short words, usernames(@user)\n3. Tokenise the processed tweet\n4. Stemming- strip suffixes to get the root word","999ae628":"### Normalizing the Text\n\nUsing the Porter Stemmer to normalise the tweets. This reduces the vocabulary size, while more or less preserving the sentiment and semantics.","1473af13":"# Feature Extraction Twitter Sentiment Analysis\n\nIn sentiment analysis, we detect tweets that have negative sentiment, i.e, racist, sexist or general hate speech. Here, tweets with a label '1' denotes a negative tweet, while '0' denotes the absence of hate speech in the tweet.\n\nFor textual data, we need to perform feature extraction in order to train a supervised machine learning model. In this notebook, our main goal is to **explore the different feature extraction methods**, and not to optimise the performance of the model.\n\nWe extract features using the following:\n1. Bag of Words Features\n2. TF-IDF features\n3. Word Embeddings\n\nThe details for the same will be discussed alongside their implementation.","4b2250bf":"## Data Analysis and Visualisation\n\nWe will analyse the text of the tweet and its relation to the sentiment with the following:\n\n1. Wordcloud: Most used words (have bigger fonts), for positive and negative tweets. [Reference](https:\/\/amueller.github.io\/word_cloud\/).\n2. Hashtags: Analyse the effect of hashtags on the tweet sentiment.\n","cf60c839":"## Feature Extration\n\n**Extracting Features from Text**\n\n1. Bag Of Words Features: creates a matrix of the unique tokens (in all documents in a corpus) and their respective frequencies. This will not see the context of the words, merely the presence of the word. [Reference](https:\/\/machinelearningmastery.com\/gentle-introduction-bag-words-model\/)\n\n2. TF-IDF Features: like BOW, but gives more weight to rare words. That is, words that occur frequently in only a few tweets are given more importance than words that occur in all tweets. [Reference](https:\/\/medium.com\/acing-ai\/what-is-tf-idf-in-feature-engineering-7f1ba81982bd) \n\n3. Word Embeddings (Word2Vec): these are representations of texts that preserve the semantics (in a way). Here, words with similar meaning will be mapped to a similar representation. Word2Vec gives a numerical representation of a word,that preserve the relationship between words (such as synonyms or antonyms). [Reference](http:\/\/https:\/\/towardsdatascience.com\/introduction-to-word-embedding-and-word2vec-652d0c2060fa) ","95bacd68":"### Bag of Words Features","247db1fe":"### Combining the Train and Test Sets","12c7528c":"As we can see, 93% of the training data is classified as non-racist\/sexist. Thus, the dataset is imbalanced. \n\nTypically, a good way to deal with this is to resample the data (either oversampling the under-represented class, or undersampling the over-represented class), but we will avoid making changes to the dataset here. \n\nInstead, we will just be wary of using Accuracy as our evaluation metric, and instead use the F1-Score. While this doesnt particularly solve the problem of having an unbalanced dataset, it will reduce the chances of misinterpretting our results.\n\nA good explanation of how you can deal with imbalanced data can be found [here](https:\/\/towardsdatascience.com\/methods-for-dealing-with-imbalanced-data-5b761be45a18).","9fc3e7e9":"### Word2Vec Features"}}