{"cell_type":{"bf3e26fc":"code","abf63ebb":"code","796ef1ad":"code","78d477ca":"code","f81a29dd":"code","e9919124":"code","0d29ecc0":"code","5ba94f9a":"code","09ee0f1d":"code","eabe4087":"code","e8291ccc":"code","356e6bb9":"code","b0225632":"code","597507db":"code","ca4809da":"code","af085059":"code","c441c63a":"code","e0c67316":"code","eefbbdab":"code","edf0643f":"code","8105a909":"code","5c6ec448":"code","63883f38":"code","133aa61f":"code","d7127b83":"code","609c9aff":"code","d3c397c8":"code","69a2b46c":"code","5bdc4ad2":"code","f64d7e47":"code","b191622a":"code","d69e06fc":"code","17717af7":"code","3f32ac41":"code","2301fd7c":"markdown","552969b6":"markdown","7f9cafb6":"markdown","416ed69d":"markdown","79880412":"markdown","804a7cbc":"markdown","9fc1db34":"markdown","6d55f79e":"markdown","ab52af5d":"markdown","2ad54c3c":"markdown","164f5b22":"markdown","5dbfe9e2":"markdown","7dc4bea0":"markdown"},"source":{"bf3e26fc":"# libraries\nimport os\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nmatplotlib.rcParams['figure.facecolor'] = '#ffffff'\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as T\nfrom torch.utils.data import random_split\nfrom torchvision.utils import make_grid\nfrom tqdm.notebook import tqdm\n\nimport time\nimport pandas as pd\n\nfrom sklearn.metrics import classification_report,confusion_matrix","abf63ebb":"DATA_DIR = \"..\/input\/butterfly-images40-species\/butterflies\"\n\ntrain_dir = os.path.join(DATA_DIR,\"train\")\nvalid_dir = os.path.join(DATA_DIR,\"valid\")\ntest_dir = os.path.join(DATA_DIR,\"test\")\n\nos.listdir(test_dir)[:4]","796ef1ad":"os.listdir(DATA_DIR + \"\/train\")[:10]","78d477ca":"# defining transforms\n\nimagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\nimage_size = 224\nbatch_size = 32\n\ntrain_transforms = T.Compose([\n    T.Resize(image_size),\n    T.RandomHorizontalFlip(),\n    T.RandomRotation(20),\n    T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n    T.ToTensor(),\n    T.Normalize(*imagenet_stats)\n])\n\nval_test_transforms = T.Compose([\n    T.Resize(image_size),\n    T.ToTensor(),\n    T.Normalize(*imagenet_stats)\n])\n","f81a29dd":"# datastes\ntrain_ds = ImageFolder(train_dir,train_transforms)\nval_ds = ImageFolder(valid_dir, val_test_transforms)\ntest_ds = ImageFolder(test_dir, val_test_transforms)","e9919124":"classes = train_ds.classes\nlen_classes = len(classes)","0d29ecc0":"# classes and indexes belonging to them\ntrain_ds.class_to_idx","5ba94f9a":"# No of images in train\/test and valid sets\nprint(f\"Train : {len(train_ds)} \\nValidation : {len(val_ds)} \\nTest : {len(test_ds)}\")","09ee0f1d":"# Data Loaders\ntrain_dl = DataLoader(train_ds, batch_size = batch_size, shuffle = True, num_workers = 3, pin_memory = True)\nval_dl = DataLoader(val_ds, batch_size = batch_size, shuffle = False, num_workers = 3, pin_memory = True)\ntest_dl = DataLoader(test_ds, batch_size = batch_size, shuffle = False, num_workers = 3, pin_memory = True)","eabe4087":"# function to denormalize\ndef denormalize(images, means, stds):\n    means = torch.tensor(means).reshape(1, 3, 1, 1)\n    stds = torch.tensor(stds).reshape(1, 3, 1, 1)\n    return images * stds + means\n\n# to show the images\ndef show_images(img,label):\n    plt.figure(figsize = [20,14])\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        img[i] = denormalize(img[i], *imagenet_stats)\n        plt.imshow(img[i].permute(1,2,0))\n        plt.title(classes[label[i]])\n        plt.axis(\"off\")\n    plt.show()","e8291ccc":"# one batch \nimages,labels = iter(train_dl).next()\n\nprint(images.shape)","356e6bb9":"# show the images\nshow_images(images,labels)","b0225632":"# A class we can extend to use in our model.\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}],{} train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch+1, \"last_lr: {:.5f},\".format(result['lrs'][-1]) if 'lrs' in result else '', \n            result['train_loss'], result['val_loss'], result['val_acc']))\n\n        \n        \ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))","597507db":"# build the model using a pre-trained model and changing the last layer\n\nfrom torchvision import models\n\nclass ButterFlyModel(ImageClassificationBase):\n    def __init__(self, num_classes, pretrained=True):\n        super().__init__()\n        # Use a pretrained model\n        self.network = models.googlenet(pretrained=True)\n        # Replace last layer\n        self.network.fc = nn.Linear(self.network.fc.in_features, num_classes)\n\n    def forward(self, xb):\n        return self.network(xb)","ca4809da":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","af085059":"device = get_default_device()\ndevice","c441c63a":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\ntest_dl = DeviceDataLoader(test_dl,device)","e0c67316":"import torch\nfrom tqdm.notebook import tqdm\n\n# for evaluation\n@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\n# training\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase\n        model.train()\n        train_losses = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history\n\n# get the learning rate\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\n# releasing resources after one epoch\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader,\n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n\n    # Set up custom optimizer with weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # Set up one-cycle learning rate scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs,\n                                                steps_per_epoch=len(train_loader))\n\n    for epoch in range(epochs):\n        # Training Phase\n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n\n            # Gradient clipping\n            if grad_clip:\n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n\n            optimizer.step()\n            optimizer.zero_grad()\n\n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n            sched.step()\n\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","eefbbdab":"model = ButterFlyModel(len(train_ds.classes))\nto_device(model,device)\nprint(\"Model Built..\")","edf0643f":"# score of the model before the training process\n\nhistory = [evaluate(model, val_dl)]\nhistory","8105a909":"# defining parameters for the model\nepochs = 15\nmax_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\n\nopt_func = torch.optim.Adam","5c6ec448":"print(\"Starting Training .. ..\")\nstart = time.time()\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, \n                         grad_clip=grad_clip, \n                         weight_decay=weight_decay, \n                         opt_func=opt_func)\nend = time.time()\nprint(f\"Finished training in {end-start} seconds..\")","63883f38":"evaluate(model,test_dl)","133aa61f":"accuracies = [x[\"val_acc\"] for x in history]\nval_loss = [x[\"val_loss\"] for x in history]","d7127b83":"train_loss = [x.get(\"train_loss\") for x in history]","609c9aff":"# accuracies\n\nplt.plot(accuracies,marker = \"*\",c = \"green\")\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.title('Accuracy vs. No. of epochs');","d3c397c8":"# losses\n\nplt.plot(train_loss, '-bx')\nplt.plot(val_loss, '-rx')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['Training', 'Validation'])\nplt.title('Loss vs. No. of epochs');","69a2b46c":"# learning rates\n\nlrs = np.concatenate([x.get('lrs', []) for x in history])\nplt.plot(lrs)\nplt.xlabel('Batch no.')\nplt.ylabel('Learning rate')\nplt.title('Learning Rate vs. Batch no.');","5bdc4ad2":"# function to get prediction and labels\ndef makePrediction(dataset, num_images = 25):\n    predicted = []\n    actual = []\n    for i in range(num_images):\n        # getting label and image\n        img, label = dataset[i]\n        actual.append(label)\n        \n        # making prediction\n        img_batched = to_device(img.unsqueeze(0),device)\n        \n        _,pred = torch.max(model(img_batched), dim = 1)\n        pred = pred[0].item()\n        predicted.append(pred)\n        \n    return predicted,actual\n\n# function to denormalize and permute\ndef denPermute_test(images, means, stds):\n    means = torch.tensor(means).reshape(3, 1, 1)\n    stds = torch.tensor(stds).reshape(3, 1, 1)\n    images = images * stds + means\n    return images.permute(1,2,0)","f64d7e47":"pred,actual = makePrediction(test_ds,len(test_ds))","b191622a":"def plotPredictions(testData, num=25):\n    plt.figure(figsize=[22,14])\n    for i in range(num):\n        plt.subplot(5,5,i+1)\n        image,_ = testData[i]\n        image = denPermute_test(image, *imagenet_stats)\n        plt.imshow(image)\n        plt.xlabel(f\"Actual : {classes[actual[i]]}\")\n        plt.ylabel(f\"Pred : {classes[pred[i]]}\")\n        plt.xticks([])\n        plt.yticks([])\n    plt.show()","d69e06fc":"plotPredictions(test_ds)","17717af7":"plt.figure(figsize=[25,14])\nsns.heatmap(confusion_matrix(pred,actual),annot=True, fmt = \"d\" ,cmap = \"Blues\");","3f32ac41":"print(classification_report(pred,actual))","2301fd7c":"# **Butterfly species clssification using Pytorch**\n\n![Image](https:\/\/www.thefactsite.com\/wp-content\/uploads\/2016\/12\/butterfly-facts-702x347.jpg)\n\n### Dataset\n\n- Train, Test. Validation data set for 50 butterfly species. All images are 224 X 224 X 3 in jpg format .\n- Train set consists of 4955 images partitioned into 50 sub directories one for each species.\n- Test set consists of 250 images partitioned into 50 sub directories with 5 test images per species.\n- Valid set consists of 250 images partitioned into 50 sub directories with 5 validation images per species.","552969b6":"# **MODEL**","7f9cafb6":"## **Testing**","416ed69d":"### To use a GPU","79880412":"### **Classification Report**","804a7cbc":"### Take a look at some of the images from train batch","9fc1db34":"## Dataset Preparation","6d55f79e":"## Imports\n- Importing the necessay PyTorch libraries for the model and data.\n- Matplotlib and seaborn for visualizations.\n- Scikit-Learn for some performance metrics.","ab52af5d":"## Confusion matrix","2ad54c3c":"## **Training the Model**","164f5b22":"## **SUMMARY**\n- A classification task on a dataste containing images of different species of butterflies.\n- Prepare data into train,test and validation part using pytorch's built in modules.\n- Performinng data augmentation to potentially improve the performance of our model.\n- Defining classes and functions for ease of visulaizing the model imporovemnts.\n- Using a pre-trained model for better scores after trying CNNs and Simple Neural Nets.\n- Testing and visuakizing the results.\n- Dataset at : https:\/\/www.kaggle.com\/gpiosenka\/butterfly-images40-species\n- Helper functions from : https:\/\/jovian.ai\/learn\/deep-learning-with-pytorch-zero-to-gans","5dbfe9e2":"**Training**","7dc4bea0":"## Predictions v\/s labels"}}