{"cell_type":{"c0afea21":"code","73a95713":"code","1536edcd":"code","31eb8950":"code","b536d810":"code","90dbd379":"code","e009b026":"code","4e37b468":"code","907cea48":"code","6cc874ec":"code","a6eb20c1":"code","ab42dd3d":"code","094eb136":"code","ac2f19f8":"code","5fce08b7":"code","a5dd1e14":"code","e39a7943":"code","836a15be":"code","01a48ef1":"code","63d55960":"code","3216b9db":"code","c58ed471":"code","56dc810c":"code","fe5b7357":"code","1da68d81":"code","0e649c35":"code","e99be318":"code","1041f637":"code","36a8b572":"code","1d043de2":"code","f80b85b8":"code","db44172f":"code","4d186e24":"code","53082478":"code","8b80cb44":"code","abf1fee4":"code","2458032f":"code","d501148a":"code","59fdb9d9":"code","f7dfcaaf":"code","fa5798ff":"code","78fd5ccb":"code","bca26b8e":"code","acdb5bca":"code","2b09fdb8":"code","de075096":"code","10eadc26":"code","ecdde36b":"code","a3a59ec5":"code","d7fc0189":"code","fa151399":"code","d8372883":"code","39cb897a":"code","79331228":"code","ab248bd0":"code","3ba69a18":"code","6118a2e0":"code","a833970d":"code","99dd8f03":"code","0bac8d54":"code","a3a9994a":"code","484ab2d6":"code","bdce9773":"code","5620e13f":"code","7b06e226":"markdown","38e941cb":"markdown","17a84ec8":"markdown","76634b41":"markdown","a6498de5":"markdown","62334481":"markdown","84f595a3":"markdown","f5376dc1":"markdown","ee2a6268":"markdown","0bb279c8":"markdown","f7c393cd":"markdown","3c4a7576":"markdown"},"source":{"c0afea21":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # data visualization\nimport seaborn as sns\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","73a95713":"train = pd.read_csv('..\/input\/a2-data\/train.csv')","1536edcd":"train.head()","31eb8950":"eval = pd.read_csv('..\/input\/a2-data\/eval.csv')","b536d810":"eval.head()","90dbd379":"train.columns","e009b026":"eval.columns","4e37b468":"train.describe()","907cea48":"train.info()","6cc874ec":"reference = train.drop(['id','title','console'],axis=1)","a6eb20c1":"for x in reference.columns:\n    print(reference[x].value_counts())","ab42dd3d":"#for x in train.columns:\n    #sns.countplot(x='esrb_rating',hue=x,data=train)","094eb136":"#sns.countplot(x='esrb_rating',hue='Survived',data=train)","ac2f19f8":"for x in reference.columns:\n    #print(reference[x].value_counts())\n    sns.countplot(data=reference,x=reference[x])\n","5fce08b7":"g = sns.FacetGrid(reference, col=\"esrb_rating\",row='violence')\ng.map(sns.countplot, x=reference['violence'])","a5dd1e14":"#for label, _ in counter.items():\n#    row_ix = where(y == label)[0]\n#    pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n#pyplot.legend()\n#pyplot.show()","e39a7943":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.compose import ColumnTransformer","836a15be":"#label_enc = LabelEncoder()\n#train['esrb_rating'] = label_enc.fit_transform(train['esrb_rating'])\ny = train['esrb_rating']\nX_train = train.drop(['id','title','esrb_rating','console'], axis=1)\nX_test = eval.drop(['id','console'], axis=1)","01a48ef1":"X_train.head()","63d55960":"y.head()","3216b9db":"len(y)","c58ed471":"lr = LogisticRegression()","56dc810c":"svc = SVC()","fe5b7357":"dt = DecisionTreeClassifier()","1da68d81":"rf = RandomForestClassifier()","0e649c35":"KNN = KNeighborsClassifier()","e99be318":"def display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())","1041f637":"#lr_pipeline = make_pipeline(column_trans, lr)\nlr_cv = cross_val_score(lr,X_train,y,cv=3)\nprint('Logistic Regression statistics: ')\ndisplay_scores(lr_cv)","36a8b572":"#svc_pipeline = make_pipeline(column_trans, svc)\nsvc_cv = cross_val_score(svc,X_train,y,cv=3)\nprint('SVC Regression statistics: ')\ndisplay_scores(svc_cv)","1d043de2":"#dt_pipeline = make_pipeline(column_trans, dt)\ndt_cv = cross_val_score(dt,X_train,y,cv=3)\nprint('Decision tree statistics: ')\ndisplay_scores(dt_cv)","f80b85b8":"#rf_pipeline = make_pipeline(column_trans, rf)\nrf_cv = cross_val_score(rf,X_train,y,cv=3)\nprint('Random Forest statistics: ')\ndisplay_scores(rf_cv)","db44172f":"#KNN_pipeline = make_pipeline(column_trans, KNN)\nKNN_cv = cross_val_score(KNN,X_train,y,cv=3)\nprint('KNN statistics: ')\ndisplay_scores(KNN_cv)","4d186e24":"from sklearn.model_selection import GridSearchCV\n\n #Use grid search to tune the parameters:\n # C and gamma using exponentially growing sequences for gridsearch\n # C = 2^-5, 2^-3, 2^-1, 2^1, 2^3, 2^5, 2^7\n # gamma = 2^-15, 2^-13, 2^-1\nsvc_params_grid = {'C': 2**np.arange(-5,15,dtype=float),\n                  'kernel':['linear','poly','rbf','sigmoid'],\n                   'gamma': 2**np.arange(-15,3,dtype=float)}\n\nsvc_grid = GridSearchCV(svc, svc_params_grid, scoring='accuracy', cv=3, return_train_score=True)\nsvc_grid.fit(X_train, y)\nprint(svc_grid)","53082478":"svc_grid.best_params_","8b80cb44":"svc_grid.best_score_","abf1fee4":"svc_grid_pred = svc_grid.predict(X_test)\nprint(svc_grid_pred)","2458032f":"svc_results = pd.DataFrame.from_dict(svc_grid.cv_results_)\nsns.histplot(data=svc_results,x='mean_test_score',stat='count')","d501148a":"svc_results.describe()","59fdb9d9":"#Use grid search to tune the parameters:\n # C is a set of numbers evenly space on a log scale\n # Penalty is parameter set that includes l1 and l2 penalty, elastic, and none\n # We use the set of solvers as per sklearn documentation to see which one is best\nlr_params_grid = {'C': np.logspace(-4, 4, 20),\n                  'penalty': ['l1','l2','elasticnet','none'],\n                   'solver': ['newton-cg', 'lbfgs', 'liblinear','saga']}\n\nlr_grid = GridSearchCV(lr, lr_params_grid, scoring='accuracy', cv=3, return_train_score=True)\nlr_grid.fit(X_train, y)\nprint(lr_grid)","f7dfcaaf":"lr_grid.best_params_","fa5798ff":"lr_grid.best_score_","78fd5ccb":"lr_grid_pred = lr_grid.predict(X_test)\nprint(lr_grid_pred)","bca26b8e":"lr_results = pd.DataFrame.from_dict(lr_grid.cv_results_)\nsns.histplot(data=lr_results,x='mean_test_score',stat='count')","acdb5bca":"lr_results.describe()","2b09fdb8":"dt_params_grid = {'criterion': ['gini','entropy'],\n                  'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None]}\n\ndt_grid = GridSearchCV(dt, dt_params_grid, scoring='accuracy', cv=3, return_train_score=True)\ndt_grid.fit(X_train, y)\nprint(dt_grid)","de075096":"dt_grid.best_params_","10eadc26":"dt_grid.best_score_","ecdde36b":"dt_grid_pred = dt_grid.predict(X_test)\nprint(dt_grid_pred)","a3a59ec5":"dt_results = pd.DataFrame.from_dict(dt_grid.cv_results_)\nsns.histplot(data=dt_results,x='mean_test_score',stat='count')","d7fc0189":"dt_results.describe()","fa151399":"rf_params_grid= {'bootstrap': [True, False],\n                 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n                 'max_features': ['auto', 'sqrt'],\n                 'min_samples_leaf': [1, 2, 4],\n                 'min_samples_split': [2, 5, 10],\n                 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n\nrf_grid = GridSearchCV(rf, rf_params_grid, scoring='accuracy', cv=3, return_train_score=True)\nrf_grid.fit(X_train, y)\nprint(rf_grid)","d8372883":"rf_grid.best_params_","39cb897a":"rf_grid.best_score_","79331228":"rf_grid_pred = rf_grid.predict(X_test)\nprint(rf_grid_pred)","ab248bd0":"rf_results = pd.DataFrame.from_dict(rf_grid.cv_results_)\nsns.histplot(data=rf_results,x='mean_test_score',stat='count')","3ba69a18":"rf_results.describe()","6118a2e0":"# Here first param is number of nearest neighbors with a min number of neighbors being 2 and max 15,\n# We use choose a different algorithm type for each instance\n# We choose our p value to be 1 for manhattan_distance (l1), and euclidean_distance (l2) for 2, 3 represents some arbritary value which will be set to minkowski_distance\n\nknn_params_grid = {'n_neighbors': np.arange(2,15),\n                  'weights': ['uniform','distance'],\n                   'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n                   'p': [1,2]}\n\nknn_grid = GridSearchCV(KNN, knn_params_grid, scoring='accuracy', cv=3, return_train_score=True)\nknn_grid.fit(X_train, y)\nprint(knn_grid)","a833970d":"knn_grid.best_params_","99dd8f03":"knn_grid.best_score_","0bac8d54":"knn_results = pd.DataFrame.from_dict(knn_grid.cv_results_)\nsns.histplot(data=knn_results,x='mean_test_score',stat='count')","a3a9994a":"knn_results.describe()","484ab2d6":"knn_grid_pred = knn_grid.predict(X_test)\nprint(knn_grid_pred)","bdce9773":"#results = pd.DataFrame({'lr': lr_grid_pred,'dt': dt_grid_pred, ''})","5620e13f":"output = pd.DataFrame({'id': eval.id, 'esrb_rating': rf_grid_pred})\nprint(output.to_string())\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n","7b06e226":"**Logistic Regression grid**","38e941cb":"# **Building Models**","17a84ec8":"**Decision Tree grid**","76634b41":"**Gridsearch**","a6498de5":"> Dropping console and title from feature as it is irrelevant to actual esrb rating","62334481":"**SVC grid**","84f595a3":"cross validation, gridsearch for hpt and see which features contribute less to predictions","f5376dc1":"***There are no outliers in this data set as it consist of only binary classifiers for each feature***","ee2a6268":"**Random Forest grid**","0bb279c8":"***No missing values***","f7c393cd":"# **Hyperparameter Tuning**","3c4a7576":"**Nearest Neighbors Grid**"}}