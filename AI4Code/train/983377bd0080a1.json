{"cell_type":{"4e47ec8c":"code","37ad37f6":"code","2dc6bc10":"code","349cdd16":"code","54f2cd08":"code","d5017750":"code","f2a8b4ec":"code","4edf7ce1":"code","979ca807":"code","dae90c39":"code","70592250":"code","4904474c":"code","850c26b4":"code","f2688956":"code","24f7b303":"code","4e30a552":"code","06dce13c":"code","b66324dc":"code","c7f749c4":"code","a8d87eeb":"code","63d40b5b":"code","a3476100":"code","89364cc5":"code","ce21241a":"code","31367335":"code","1557048b":"code","1f719c70":"code","29c21d83":"code","d0672d65":"code","bbd3b4db":"code","b152ef7d":"code","3e9012fd":"code","465d0eaf":"code","f8023412":"code","8bbc3e23":"code","7f76f287":"markdown","4ff069dd":"markdown","fbdf4338":"markdown","0ebc9262":"markdown","91a75dc1":"markdown","426f0fd2":"markdown","7d95e496":"markdown","7314815e":"markdown","e3b19df7":"markdown","309848d9":"markdown","0325231f":"markdown","b26256f7":"markdown","ce9b8b94":"markdown","9744ee96":"markdown","9454534b":"markdown","2c10d524":"markdown","ba92d731":"markdown","09fef195":"markdown","5a86a720":"markdown","377fd4a0":"markdown","3340bb06":"markdown","851f2887":"markdown","da478d7e":"markdown","8bf7833f":"markdown","4335a678":"markdown","55ca3bd2":"markdown","3f349858":"markdown","3ebb3fcd":"markdown"},"source":{"4e47ec8c":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.applications import MobileNetV2\nimport os\n\nfrom tqdm import tqdm","37ad37f6":"dir_root = '..\/input\/lyme-clean-and-dirty\/Lyme_ver03\/'\ndir_original = dir_root + 'data\/'\ndir_augmented = dir_root + 'augmented_dataset\/'\ntest_df = pd.read_csv(dir_root + 'test_data.csv')\ntrain_df = pd.read_csv(dir_root + 'training_data.csv')\naugmented_df = pd.read_csv(dir_root + 'data_augmented.csv')","2dc6bc10":"%%time\n\ndata = {}\n\ntarget_size = (224, 224)\n\n\nfor i in range(len(test_df['image'])):\n    image_name = dir_original + test_df['image'][i]\n    image=tf.keras.preprocessing.image.load_img(image_name, color_mode='rgb', target_size = target_size)\n    image=np.array(image)\n    data.update({test_df['image'][i]: image})\n    \n\nfor i in range(len(train_df['image'])):\n    image_name = dir_original + train_df['image'][i]\n    image=tf.keras.preprocessing.image.load_img(image_name, color_mode='rgb', target_size = target_size)\n    image=np.array(image)\n    data.update({train_df['image'][i]: image})\n\n\nfor i in range(len(augmented_df['image'])):\n    image_name = dir_augmented + augmented_df['image'][i]\n    image=tf.keras.preprocessing.image.load_img(image_name, color_mode='rgb', target_size = target_size)\n    image=np.array(image)\n    data.update({augmented_df['image'][i]: image})\n\n\n","349cdd16":"print('train_df size: ',len(train_df))\nprint('test_df size: ',len(test_df))\ndata_df = pd.concat([test_df, train_df])\n\ndata_df.reset_index(drop=True, inplace=True)\ndata_df = data_df.sample(frac=1, random_state=123)\ndata_df.reset_index(drop=True, inplace=True)\n\nprint('data_original_df size: ',len(data_df))","54f2cd08":"def show_model_results(acc_per_fold, loss_per_fold, auc_per_fold):\n    # == Provide average scores ==\n    print('------------------------------------------------------------------------')\n    print('Score per fold')\n    for i in range(0, len(acc_per_fold)):\n      print('------------------------------------------------------------------------')\n      print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - AUC: {auc_per_fold[i]}')\n    print('------------------------------------------------------------------------')\n    print('Average scores for all folds:')\n    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n    print(f'> AUC: {np.mean(auc_per_fold)} (+- {np.std(auc_per_fold)})')\n    print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')","d5017750":"def plot_mean_std(label, line_color, fill_color, epoch_list, mean_list, std_list, ax):\n  \n  ax.plot(\n    epoch_list,\n    mean_list,\n    color=line_color,\n    label=label, \n    lw=2,\n    alpha=0.8,\n  )\n\n  upper = (mean_list + std_list)\n  lower = (mean_list - std_list)\n\n  ax.fill_between(\n    epoch_list,\n    lower,\n    upper,\n    color=fill_color,\n    alpha=0.5,\n    label=r\"$\\pm$ 1 std. dev.\",\n  )\n\n\ndef plot_train_val_mean_std(metric_label, legend_location, metric_ylim, history_train_list_means, history_train_list_stds, history_val_list_means, history_val_list_stds, ax):\n\n\n  epochs_list = range(EPOCHS)\n\n  plot_mean_std('train', 'r', \"lightcoral\", epochs_list, history_train_list_means, history_train_list_stds, ax)\n  plot_mean_std('val', 'b', \"lightsteelblue\", epochs_list, history_val_list_means, history_val_list_stds, ax)\n\n  ax.set(\n    xlim = [0, EPOCHS-1],\n    ylim = metric_ylim,\n    title = metric_label + \" - History\",\n  )\n\n  ax.legend(loc=legend_location, ncol=2)\n\n  fig_filename = model_name + '_' + metric_label + '_history_' + add_title + '.png'\n  fig_file_path = os.path.join(figures_dir, fig_filename)\n  plt.savefig(fig_file_path, dpi=300)\n\n  plt.show()  \n","f2a8b4ec":"class Base_Model(tf.keras.Model):\n\n  def __init__(self, target_size):\n    super().__init__()\n    self.target_size = target_size\n    self.base_model = MobileNetV2(\n    include_top=False,\n    pooling='max', weights=WEIGHTS, input_shape = self.target_size)\n    print(target_size)\n\n    # make the weights and biases of the base model non-trainable\n    # by \"freezing\" each layer of the BASE network\n    for layer in self.layers:\n        print(layer.name)\n        layer.trainable = TRAINABLE    \n    \n    self.flat_layer = tf.keras.layers.Flatten()\n    self.dense1_layer = tf.keras.layers.Dense(512, activation='relu')\n    self.dense2_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n\n  def call(self, inputs, training=False):\n    x = self.base_model(inputs)\n    x = self.flat_layer(x)\n    x = self.dense1_layer(x)\n\n\n    return self.dense2_layer(x)\n    ","4edf7ce1":"class Complex_Model():\n\n  def __init__(self, result_data, result_label, save_dir, epoch_num, \n               target_size = (224, 224, 3), num_folds = 5):\n    \n    self.X = result_data\n    self.Y = result_label\n    self.target_size = target_size\n    self.save_dir = save_dir\n    self.epoch_num = epoch_num\n    self.num_folds = num_folds\n\n    self.acc_per_fold = []\n    self.loss_per_fold = []\n    self.auc_per_fold = []\n\n    self.history_acc_list = []\n    self.history_loss_list = []\n    self.history_auc_list = []\n    self.history_val_acc_list = []\n    self.history_val_loss_list = []\n    self.history_val_auc_list = []\n\n\n\n  def run(self):\n\n    kfold = StratifiedKFold(n_splits = self.num_folds)\n  \n\n    from tqdm import tqdm\n    for train, test in tqdm(kfold.split(self.X, self.Y)):\n\n      model = Base_Model(self.target_size)\n\n      #model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001), \n      model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001), \n                  loss = 'binary_crossentropy', \n                  metrics = [tf.keras.metrics.AUC(name='auc'),'acc'])\n\n\n      if DA == True:  \n        train_data_aug = ImageDataGenerator(\n          rescale=1.\/255,\n          featurewise_center=True, \n          samplewise_center=True, featurewise_std_normalization=True, samplewise_std_normalization=True,\n          zca_whitening=True, zca_epsilon=1e-06, rotation_range=90, \n          width_shift_range=1.0, height_shift_range=1.0, brightness_range=[0.5, 1.5], \n          shear_range=90.0, zoom_range=1.0, channel_shift_range=0.0, \n          fill_mode='nearest', horizontal_flip=False, vertical_flip=False\n        ).flow(self.X[train], self.Y[train])\n      else:\n        train_data_aug = ImageDataGenerator(rescale=1.\/255).flow(self.X[train], self.Y[train])\n    \n      test_data_aug = ImageDataGenerator(rescale=1.\/255).flow(self.X[test], self.Y[test])\n\n      checkpoint_AUC = ModelCheckpoint(save_dir, monitor='val_auc', verbose=2, save_best_only=True, \n                                      mode='max', save_weights_only=True)\n\n      history = model.fit(\n        train_data_aug,               \n        epochs=self.epoch_num,\n        verbose=2,\n        callbacks = [checkpoint_AUC],\n        validation_data=test_data_aug)\n        \n      model.summary()        \n      \n      model.load_weights(save_dir)\n      \n      scores = model.evaluate(test_data_aug, verbose=0)\n\n      self.loss_per_fold.append(scores[0])\n      self.auc_per_fold.append(scores[1])\n      self.acc_per_fold.append(scores[2])\n\n      \n      self.history_acc_list.append(history.history['acc'])\n      self.history_loss_list.append(history.history['loss'])\n      self.history_auc_list.append(history.history['auc'])\n      self.history_val_acc_list.append(history.history['val_acc'])\n      self.history_val_loss_list.append(history.history['val_loss'])\n      self.history_val_auc_list.append(history.history['val_auc'])\n\n\n  def show_results(self):\n    show_model_results(self.acc_per_fold, self.loss_per_fold, self.auc_per_fold)\n\n\n  def history_stat_metrics(self, history_list):\n    history_list_means = np.mean(np.asarray(history_list),axis=0)\n    history_list_stds = np.std(np.asarray(history_list),axis=0)\n    return(history_list_means, history_list_stds)\n\n\n  def plot_accuracy(self):\n\n    train_acc_list_means, train_acc_list_stds = self.history_stat_metrics(self.history_acc_list)\n    val_acc_list_means, val_acc_list_stds = self.history_stat_metrics(self.history_val_acc_list)\n\n    fig, ax = plt.subplots()\n\n    plot_train_val_mean_std('Accuracy', \"lower center\", [0.01, 1.05], train_acc_list_means, \n                        train_acc_list_stds, val_acc_list_means, val_acc_list_stds, ax)\n    \n   \n  def plot_auc(self):\n\n    train_auc_list_means, train_auc_list_stds = self.history_stat_metrics(self.history_auc_list)\n    val_auc_list_means, val_auc_list_stds = self.history_stat_metrics(self.history_val_auc_list)\n\n    fig, ax = plt.subplots()\n\n    plot_train_val_mean_std('AUC', \"lower center\", [0.01, 1.05], train_auc_list_means, train_auc_list_stds, \n                        val_auc_list_means, val_auc_list_stds, ax)\n\n\n\n  def plot_loss(self):\n\n    train_loss_list_means, train_loss_list_stds = self.history_stat_metrics(self.history_loss_list)\n    val_loss_list_means, val_loss_list_stds = self.history_stat_metrics(self.history_val_loss_list)\n\n    fig, ax = plt.subplots()\n\n    plot_train_val_mean_std('Loss', \"upper center\", [0.01, 6], train_loss_list_means, train_loss_list_stds, \n                        val_loss_list_means, val_loss_list_stds, ax) \n\n\n  def folds_mean_max_auc(self):\n    return np.mean(self.acc_per_fold), np.std(self.acc_per_fold), np.mean(self.auc_per_fold), np.std(self.auc_per_fold), np.mean(self.loss_per_fold), np.std(self.loss_per_fold)  ","979ca807":"def prepare_data_growing(noisy_part, limit):\n    result_label = []\n    result_data = []\n\n    pos_lyme_count = 0\n    no_lyme_count = 0\n    \n    for i in range(len(data_df['image'])):\n\n#      if (data_df['clean'][i] == 1) and (data_df['lyme_positive'][i] == 1) and (clean_pos_lyme_count < clean_limit):\n      if (data_df['clean'][i] == 1) and (data_df['lyme_positive'][i] == 1) and (pos_lyme_count < limit*(1-noisy_part)):\n          result_label.append(data_df['lyme_positive'][i])\n          result_data.append(data[data_df['image'][i]])\n          pos_lyme_count += 1\n      \n      if (data_df['clean'][i] == 1) and (data_df['lyme_positive'][i] == 0) and (no_lyme_count < pos_lyme_count):\n          result_label.append(data_df['lyme_positive'][i])\n          result_data.append(data[data_df['image'][i]])\n          no_lyme_count += 1\n\n        \n\n      if noisy_part > 0:\n\n          if (data_df['clean'][i] == 0) and (data_df['lyme_positive'][i] == 1) and (pos_lyme_count < limit):\n              result_label.append(data_df['lyme_positive'][i])\n              result_data.append(data[data_df['image'][i]])\n              pos_lyme_count += 1\n\n          if (data_df['clean'][i] == 0) and (data_df['lyme_positive'][i] == 0) and (no_lyme_count < pos_lyme_count):\n              result_label.append(data_df['lyme_positive'][i])\n              result_data.append(data[data_df['image'][i]])\n              no_lyme_count += 1        \n\n                \n  \n    result_data = np.asarray(result_data).astype(np.float32)\n    result_label = np.asarray(result_label).astype(np.float32)\n\n    print('pos_lyme_count:', pos_lyme_count)\n    print('no_lyme_count:', no_lyme_count)\n    print('Growing dataset size: ',len(result_data))\n    print('Growing dataset (label) size: ',len(result_label))\n\n    return result_data, result_label","dae90c39":"def plot_noise_vs(x, y, x_label, y_label, plot_title):\n  plt.plot(x, y)\n  #plt.xticks(x)\n  plt.xlabel(x_label)\n  plt.ylabel(y_label)\n  plt.title(plot_title)\n\n  fig_filename = model_name + '_' + plot_title + '.png'\n  fig_file_path = os.path.join(figures_dir, fig_filename)\n  plt.savefig(fig_file_path, dpi=300)\n\n  plt.show()","70592250":"def plot_noise_mean_std(metric_label, legend_location, metric_ylim, list_noise, list_means, list_stds, ax):\n\n    plot_mean_std('Mean', 'b', \"lightsteelblue\", list_noise, list_means, list_stds, ax)\n\n    ax.set(\n        xlim = [0, 70],\n        ylim = metric_ylim,\n        title = metric_label + \" vs \" + x_label,\n        xlabel = x_label,\n        ylabel = metric_label\n    )\n\n    ax.legend(loc=legend_location, ncol=2)\n\n    fig_filename = model_name + '_' + metric_label + \"_vs_\" + x_label_filename + '_FILL.png'\n    fig_file_path = os.path.join(figures_dir, fig_filename)\n    plt.savefig(fig_file_path, dpi=300)\n\n    plt.show()  ","4904474c":"def run_regime():  \n    #num_list = [15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65]\n    num_list = list(range(5,66,1))\n\n    metrics_list = []\n    for n in tqdm(num_list):\n        result_data, result_label = prepare_data_growing(NOISE_PART, n)\n        add_title = 'noise' + str(NOISE_PART) + '_num' + str(n)\n        model = Complex_Model(result_data=result_data, result_label=result_label, save_dir=save_dir, epoch_num = EPOCHS)\n    \n        model.run()\n        model.show_results()\n        model.plot_accuracy()\n        model.plot_loss()\n        model.plot_auc()\n    \n        metrics = model.folds_mean_max_auc()\n        metrics_list.append(metrics)   \n\n    acc_mean_list = []\n    acc_std_list = []\n    auc_mean_list = []\n    auc_std_list = []\n    loss_mean_list = []\n    loss_std_list = []\n    for n in range(len(num_list)):\n        acc_mean_list.append(metrics_list[n][0])\n        acc_std_list.append(metrics_list[n][1])\n        auc_mean_list.append(metrics_list[n][2])\n        auc_std_list.append(metrics_list[n][3])\n        loss_mean_list.append(metrics_list[n][4])\n        loss_std_list.append(metrics_list[n][5])    \n        \n    # Summary\n    summary = np.column_stack((np.array(num_list),acc_mean_list,acc_std_list,auc_mean_list,auc_std_list,loss_mean_list,loss_std_list))\n    summary_df = pd.DataFrame(summary)\n    summary_df.columns = ['num', 'acc_mean', 'acc_std', 'auc_mean', 'auc_std', 'loss_mean', 'loss_std']\n    summary_df.head()\n    summary_filename = model_name + '_summary.txt'\n    summary_file_path = os.path.join(figures_dir, summary_filename)\n    summary_df.to_csv(summary_file_path, index=False)\n        \n    plot_noise_vs(num_list, acc_mean_list, x_label, 'Accuracy (mean)', 'Accuracy_mean_vs_' + x_label_filename)\n    plot_noise_vs(num_list, acc_std_list, x_label, 'Accuracy (std)', 'Accuracy_std_vs_' + x_label_filename)\n    plot_noise_vs(num_list, auc_mean_list, x_label, 'AUC (mean)', 'AUC_mean_vs_' + x_label_filename)\n    plot_noise_vs(num_list, auc_std_list, x_label, 'AUC (std)', 'AUC_std_vs_' + x_label_filename)\n    plot_noise_vs(num_list, loss_mean_list, x_label, 'Loss (mean)', 'Loss_mean_vs_' + x_label_filename)\n    plot_noise_vs(num_list, loss_std_list, x_label, 'Loss (std)', 'Loss_std_vs_' + x_label_filename)\n    \n    fig, ax = plt.subplots()\n    plot_noise_mean_std('Accuracy', \"lower center\", [0.3, 0.9], num_list, np.array(acc_mean_list), np.array(acc_std_list), ax)   \n    fig, ax = plt.subplots()\n    plot_noise_mean_std('AUC', \"upper center\", [0.5, 1.1], num_list, np.array(auc_mean_list), np.array(auc_std_list), ax)    \n    fig, ax = plt.subplots()\n    plot_noise_mean_std('Loss', \"upper center\", [-0.2, 3.6], num_list, np.array(loss_mean_list), np.array(loss_std_list), ax)    ","850c26b4":"EPOCHS = 30\n\n# Train from ImageNet-trainable Weights\nWEIGHTS = 'imagenet'\nWEIGHTS_name = 'imagenet'\n# Train from scratch\n#WEIGHTS = None\n#WEIGHTS_name = 'Scratch'\n\nadd_title = ''\nx_label = 'Number of images'\nx_label_filename = 'Num'    ","f2688956":"# Clean dataset \nNOISE_PART = 0.0\ndata_quality = 'CLEAN'\n\n# Dirty dataset \n#NOISE_PART = 1.0\n#data_quality = 'DIRTY'\n\n# Dirty & Clean dataset \n#NOISE_PART = 0.5\n#data_quality = 'DIRTY_CLEAN'","24f7b303":"# Train from ImageNet-trainable Weights Learning (IWL) -> True\n#TRAINABLE = True\n#TL_name = 'NOTL'\n# Transfer Learning (TL) -> False\nTRAINABLE = False\nTL_name = 'TL'","4e30a552":"# With Data Augmentation -> True\n#DA = True\n#DA_name = 'DA' \n# Without Data Augmentation -> False\nDA = False\nDA_name = 'NODA' \n\nsave_dir = '.\/MODELS\/'\nmodel_name = 'MobileNetV2_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name\nfigures_dir = '.\/OUTPUT\/' + model_name + '\/'\nos.makedirs(figures_dir, exist_ok=True)\n\nrun_regime()","06dce13c":"# With Data Augmentation -> True\nDA = True\nDA_name = 'DA' \n# Without Data Augmentation -> False\n#DA = False\n#DA_name = 'NODA' \n\nsave_dir = '.\/MODELS\/'\nmodel_name = 'MobileNetV2_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name\nfigures_dir = '.\/OUTPUT\/' + model_name + '\/'\nos.makedirs(figures_dir, exist_ok=True)\n\nrun_regime()","b66324dc":"# Train from ImageNet-trainable Weights Learning (IWL) -> True\nTRAINABLE = True\nTL_name = 'NOTL'\n# Transfer Learning (TL) -> False\n#TRAINABLE = False\n#TL_name = 'TL'","c7f749c4":"# With Data Augmentation -> True\n#DA = True\n#DA_name = 'DA' \n# Without Data Augmentation -> False\nDA = False\nDA_name = 'NODA' \n\nsave_dir = '.\/MODELS\/'\nmodel_name = 'MobileNetV2_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name\nfigures_dir = '.\/OUTPUT\/' + model_name + '\/'\nos.makedirs(figures_dir, exist_ok=True)\n\nrun_regime()","a8d87eeb":"# With Data Augmentation -> True\nDA = True\nDA_name = 'DA' \n# Without Data Augmentation -> False\n#DA = False\n#DA_name = 'NODA' \n\nsave_dir = '.\/MODELS\/'\nmodel_name = 'MobileNetV2_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name\nfigures_dir = '.\/OUTPUT\/' + model_name + '\/'\nos.makedirs(figures_dir, exist_ok=True)\n\nrun_regime()","63d40b5b":"# Clean dataset \n#NOISE_PART = 0.0\n#data_quality = 'CLEAN'\n\n# Dirty dataset \nNOISE_PART = 1.0\ndata_quality = 'DIRTY'\n\n# Dirty & Clean dataset \n#NOISE_PART = 0.5\n#data_quality = 'DIRTY_CLEAN'","a3476100":"# Train from ImageNet-trainable Weights Learning (IWL) -> True\n#TRAINABLE = True\n#TL_name = 'NOTL'\n# Transfer Learning (TL) -> False\nTRAINABLE = False\nTL_name = 'TL'","89364cc5":"# With Data Augmentation -> True\n#DA = True\n#DA_name = 'DA' \n# Without Data Augmentation -> False\nDA = False\nDA_name = 'NODA' \n\nsave_dir = '.\/MODELS\/'\nmodel_name = 'MobileNetV2_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name\nfigures_dir = '.\/OUTPUT\/' + model_name + '\/'\nos.makedirs(figures_dir, exist_ok=True)\n\nrun_regime()","ce21241a":"# With Data Augmentation -> True\nDA = True\nDA_name = 'DA' \n# Without Data Augmentation -> False\n#DA = False\n#DA_name = 'NODA' \n\nsave_dir = '.\/MODELS\/'\nmodel_name = 'MobileNetV2_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name\nfigures_dir = '.\/OUTPUT\/' + model_name + '\/'\nos.makedirs(figures_dir, exist_ok=True)\n\nrun_regime()","31367335":"# Train from ImageNet-trainable Weights Learning (IWL) -> True\nTRAINABLE = True\nTL_name = 'NOTL'\n# Transfer Learning (TL) -> False\n#TRAINABLE = False\n#TL_name = 'TL'","1557048b":"# With Data Augmentation -> True\n#DA = True\n#DA_name = 'DA' \n# Without Data Augmentation -> False\nDA = False\nDA_name = 'NODA' \n\nsave_dir = '.\/MODELS\/'\nmodel_name = 'MobileNetV2_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name\nfigures_dir = '.\/OUTPUT\/' + model_name + '\/'\nos.makedirs(figures_dir, exist_ok=True)\n\nrun_regime()","1f719c70":"# With Data Augmentation -> True\nDA = True\nDA_name = 'DA' \n# Without Data Augmentation -> False\n#DA = False\n#DA_name = 'NODA' \n\nsave_dir = '.\/MODELS\/'\nmodel_name = 'MobileNetV2_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name\nfigures_dir = '.\/OUTPUT\/' + model_name + '\/'\nos.makedirs(figures_dir, exist_ok=True)\n\nrun_regime()","29c21d83":"# Clean dataset \n#NOISE_PART = 0.0\n#data_quality = 'CLEAN'\n\n# Dirty dataset \n#NOISE_PART = 1.0\n#data_quality = 'DIRTY'\n\n# Dirty & Clean dataset \nNOISE_PART = 0.5\ndata_quality = 'DIRTY_CLEAN'","d0672d65":"# Train from ImageNet-trainable Weights Learning (IWL) -> True\n#TRAINABLE = True\n#TL_name = 'NOTL'\n# Transfer Learning (TL) -> False\nTRAINABLE = False\nTL_name = 'TL'","bbd3b4db":"# With Data Augmentation -> True\n#DA = True\n#DA_name = 'DA' \n# Without Data Augmentation -> False\nDA = False\nDA_name = 'NODA' \n\nsave_dir = '.\/MODELS\/'\nmodel_name = 'MobileNetV2_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name\nfigures_dir = '.\/OUTPUT\/' + model_name + '\/'\nos.makedirs(figures_dir, exist_ok=True)\n\nrun_regime()","b152ef7d":"# With Data Augmentation -> True\nDA = True\nDA_name = 'DA' \n# Without Data Augmentation -> False\n#DA = False\n#DA_name = 'NODA' \n\nsave_dir = '.\/MODELS\/'\nmodel_name = 'MobileNetV2_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name\nfigures_dir = '.\/OUTPUT\/' + model_name + '\/'\nos.makedirs(figures_dir, exist_ok=True)\n\nrun_regime()","3e9012fd":"# Train from ImageNet-trainable Weights Learning (IWL) -> True\nTRAINABLE = True\nTL_name = 'NOTL'\n# Transfer Learning (TL) -> False\n#TRAINABLE = False\n#TL_name = 'TL'","465d0eaf":"# With Data Augmentation -> True\n#DA = True\n#DA_name = 'DA' \n# Without Data Augmentation -> False\nDA = False\nDA_name = 'NODA' \n\nsave_dir = '.\/MODELS\/'\nmodel_name = 'MobileNetV2_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name\nfigures_dir = '.\/OUTPUT\/' + model_name + '\/'\nos.makedirs(figures_dir, exist_ok=True)\n\nrun_regime()","f8023412":"# With Data Augmentation -> True\nDA = True\nDA_name = 'DA' \n# Without Data Augmentation -> False\n#DA = False\n#DA_name = 'NODA' \n\nsave_dir = '.\/MODELS\/'\nmodel_name = 'MobileNetV2_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name\nfigures_dir = '.\/OUTPUT\/' + model_name + '\/'\nos.makedirs(figures_dir, exist_ok=True)\n\nrun_regime()","8bbc3e23":"! ls -all .\/OUTPUT","7f76f287":"# Different number of images","4ff069dd":"# Model_class","fbdf4338":"## Regime = DIRTY","0ebc9262":"#### Regime = CLEAN + NOTL + DA","91a75dc1":"### Regime = DIRTY + CLEAN + TL","426f0fd2":"#### Regime = CLEAN + TL + NODA","7d95e496":"## Data PreProcessing ","7314815e":"#### Regime = DIRTY + CLEAN + NOTL + NODA","e3b19df7":"### Regime = DIRTY + CLEAN + NOTL","309848d9":"## Regime = CLEAN","0325231f":"## Load from Kaggle","b26256f7":"#### Regime = DIRTY + CLEAN + TL + DA","ce9b8b94":"# Regimes","9744ee96":"#### Regime = DIRTY + TL + DA","9454534b":"#### Regime = DIRTY + NOTL + DA","2c10d524":"## Regime = DIRTY + CLEAN","ba92d731":"#### Regime = CLEAN + NOTL + NODA","09fef195":"### Regime = DIRTY + TL","5a86a720":"### Regime = CLEAN + TL","377fd4a0":"#### Regime = CLEAN + TL + DA","3340bb06":"# Prepare data","851f2887":"#### Regime = DIRTY + NOTL + NODA","da478d7e":"#### Regime = DIRTY + TL + NODA","8bf7833f":"#### Regime = DIRTY + CLEAN + NOTL + DA","4335a678":"# Plot functions","55ca3bd2":"#### Regime = DIRTY + CLEAN + TL + NODA","3f349858":"### Regime = CLEAN + NOTL","3ebb3fcd":"### Regime = DIRTY + NOTL"}}