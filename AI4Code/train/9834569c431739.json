{"cell_type":{"a7cc9a1c":"code","d320040a":"code","b9316135":"code","77348d3e":"code","b30404f0":"code","049cfc60":"code","2bbbf4d9":"code","b757670b":"code","9563c93f":"code","83b7cb79":"code","6457aa7b":"code","cb169463":"code","3c58f16c":"code","0f56f3d6":"markdown","1e57ec53":"markdown","ed758936":"markdown","0f0208a4":"markdown","17fadad8":"markdown","5cdcabcf":"markdown","c0b0aad5":"markdown","dcfde0df":"markdown","39961d13":"markdown","082b6f7c":"markdown","fbafc716":"markdown","7966bc98":"markdown","abb9d09a":"markdown","1a91b1fe":"markdown","477a9c97":"markdown","82249f4c":"markdown"},"source":{"a7cc9a1c":"import os\n# Data agg\nimport pandas as pd\nimport numpy as np\n\n# Viz\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nplt.style.use('seaborn')\n\n# Torch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\ntorch.backends.cudnn.deterministic = True  \n\n# metrics\nfrom sklearn import metrics\n\n# Data processing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","d320040a":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","b9316135":"full_data = pd.concat([train,test],ignore_index=False)\nmissing_age_map = full_data.groupby(['Sex','Pclass','Parch','Embarked'],as_index=False).agg({'Age':'mean'})\n\ntrain_age_merge = train.loc[train.Age.isnull(),:].drop(['Age'],axis=1).merge(missing_age_map,on=['Sex','Pclass','Parch','Embarked'],how='inner')\ntrain_age_merge.index = train.loc[train.Age.isnull(),:].index\ntrain.loc[train.Age.isnull(),'Age'] = train_age_merge['Age']\n\ntest_age_merge = test.loc[test.Age.isnull(),:].drop(['Age'],axis=1).merge(missing_age_map,on=['Sex','Pclass','Parch','Embarked'],how='inner')\ntest_age_merge.index = test.loc[test.Age.isnull(),:].index\ntest.loc[test.Age.isnull(),'Age'] = test_age_merge['Age']\n\ntrain.Age.fillna(full_data.Age.mean(),inplace=True)\ntest.Age.fillna(full_data.Age.mean(),inplace=True)\n\ntrain['Embarked'].fillna('S',inplace=True)\ntest['Embarked'].fillna('S',inplace=True)","77348d3e":"train.columns = train.columns.str.lower().str.replace('\/','_').str.replace(' ','_')\ntest.columns = test.columns.str.lower().str.replace('\/','_').str.replace(' ','_')\n\n# to drop columns\nto_drop = ['name','ticket','cabin']\ntrain = train.drop(to_drop + ['passengerid'],axis=1)\ntest = test.drop(to_drop,axis=1)\n\ntrain.embarked = train.embarked.replace({'S': 0, 'C': 1, 'Q': 2})\ntest.embarked = test.embarked.replace({'S': 0, 'C': 1, 'Q': 2})\n\n\ntrain.sex = train.sex.replace({'male':1,'female':0})\ntest.sex = test.sex.replace({'male':1,'female':0})","b30404f0":"scaler = StandardScaler()","049cfc60":"target = 'survived'\n\nfeatures = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare','embarked']","2bbbf4d9":"train[features] = scaler.fit_transform(train[features])\ntest[features] = scaler.transform(test[features])","b757670b":"train_,test_ = train_test_split(train,test_size=0.33,random_state=42,stratify=train[target])","9563c93f":"x_train = torch.from_numpy(train_[features].values).type(torch.FloatTensor)\ny_train = torch.from_numpy(train_[target].values).type(torch.LongTensor)\n\nx_test = torch.from_numpy(test_[features].values).type(torch.FloatTensor)\ny_test = torch.from_numpy(test_[target].values).type(torch.LongTensor)","83b7cb79":"### Here is our neural network\nclass Net(nn.Module):\n\n    def __init__(self):\n        super(Net,self).__init__()\n        # takes an imput of 6 features, and spits out a vector of size 256\n        self.lin1 = nn.Linear(in_features=7,out_features=256,bias=True)\n        # the second layer takes the 256 vector and process it into a vector of size 64\n        self.lin2 = nn.Linear(in_features=256,out_features=64,bias=True)\n        # the last layer takes the 64 size vector and returns the output vector which 2 == number of classes\n        self.lin3 = nn.Linear(in_features=64,out_features=2,bias=True)\n    \n    # here we take the input data and pass it through the chain of layers\n    def forward(self,input):\n        x = self.lin1(input)\n        x = self.lin2(x)\n        x = self.lin3(x)\n        return x\n\n# instance our model\nmodel = Net()\n# set the number of epochs\nepochs = 100\n# criterion aka loss function -> find more on pytorch docs\ncriterion = nn.CrossEntropyLoss()\n\n# optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\n# create 3 lists to store the losses and accuracy at each epoch\ntrain_losses, test_losses, accuracy = [0]*epochs, [0]*epochs,[0]*epochs\n\n\n# in this current case we don't use batches for training and we pass the whole data at each epoch\nfor e in range(epochs):\n    optimizer.zero_grad()\n\n    # Comput train loss\n    y_pred = model(x_train)\n    loss = criterion(y_pred, y_train)\n    \n    loss.backward()\n\n    optimizer.step()\n\n    # store train loss\n    train_losses[e] = loss.item()\n    \n    # Compute the test stats\n    with torch.no_grad():\n        # Turn on all the nodes\n        model.eval()\n        \n        # Comput test loss\n        ps = model(x_test)\n        loss = criterion(ps, y_test)\n\n        # store test loss\n        test_losses[e] = loss.item()\n        \n        # Compute accuracy\n        top_p, top_class = ps.topk(1, dim=1)\n    \n        equals = (top_class == y_test.view(*top_class.shape))\n        \n        # store accuracy\n        accuracy[e] = torch.mean(equals.type(torch.FloatTensor))\n\n# Print the final information\nprint(f'Accuracy  : {100*accuracy[-1].item():0.2f}%')\nprint(f'Train loss: {train_losses[-1]}')\nprint(f'Test loss : {test_losses[-1]}')\n    \n# Plot the results\nfig,ax = plt.subplots(1,2,figsize=(20,5))\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epochs')\nax[0].set_title('Model Accuracy')\nax[0].plot(accuracy)\n\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epochs')\nax[1].set_title('Train\/Test Losses')\nax[1].plot(train_losses, label='train')\nax[1].plot(test_losses, label='test')\nax[1].legend()   \n\nplt.tight_layout()","6457aa7b":"print(metrics.classification_report(test_[target],top_class.numpy().ravel()))","cb169463":"sns.heatmap(metrics.confusion_matrix(test_[target],top_class.numpy().ravel()),fmt='d',annot=True);","3c58f16c":"# predict test data\nsub = model(torch.from_numpy(test[features].values).type(torch.FloatTensor))\n# extract the predicted class\nsub_p, sub_class = sub.topk(1, dim=1)\n\n# copy test data frame\ns = test.copy()\n# new columnns with prediction\ns[target] = sub_class.numpy().ravel()\n\n# rename the columns for submission\ns = s.rename(columns={\n    target:'Survived',\n    'passengerid':'PassengerId'\n})\n\n# save the submission file\ns[['Survived','PassengerId']].to_csv('submission.csv',index=False)","0f56f3d6":"**Drop useless columns and encode values from sex and embarked columns**","1e57ec53":"**Split train data into train\/test**","ed758936":"**Classificaiton Report**","0f0208a4":"## Imports","17fadad8":"**Confusion Matrix**","5cdcabcf":"**Set the target and features**\n","c0b0aad5":"This notebook aims to solve the titanic classification problem using `pytorch`","dcfde0df":"**From pandas\/numpy to Tensors (types are important)**","39961d13":"**Submission**","082b6f7c":"**Apply scaler on features**","fbafc716":"**Keep this part into one cell, it willl make the model development and testing easier**","7966bc98":"**Fill Missing Values**","abb9d09a":"## Data","1a91b1fe":"# Titanic Torch \ud83d\udd25\n\n![https:\/\/www.maritimecyprus.com\/wp-content\/uploads\/2015\/10\/titanic-infographic-1536x951.jpg](https:\/\/www.maritimecyprus.com\/wp-content\/uploads\/2015\/10\/titanic-infographic-1536x951.jpg)","477a9c97":"**Load Data**","82249f4c":"## Modelling"}}