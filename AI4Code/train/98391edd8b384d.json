{"cell_type":{"54a754ef":"code","320070a9":"code","13ecb528":"code","e4d98435":"code","35775132":"code","f106e76c":"code","1ea8c0dc":"code","f35c0c6d":"code","7289fdf1":"code","0687bf62":"code","85f1b78f":"code","3652565f":"code","6dc9d4ac":"code","dad1c2c1":"code","0dcd454e":"code","c7f09203":"markdown","c8a6c18d":"markdown","835ff581":"markdown","26ed5720":"markdown","adab03f5":"markdown","0e3f0ce4":"markdown","2ada2ee5":"markdown","14f6a34f":"markdown","0b690dac":"markdown","e0b1d1ef":"markdown","fb5cc83c":"markdown","d6ec21b5":"markdown","72707473":"markdown","f47b4fe5":"markdown"},"source":{"54a754ef":"import os\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nimport random\nseed = 10\nnp.random.seed(seed)\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)","320070a9":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","13ecb528":"%%time\ntrain_transaction = pd.read_csv('..\/input\/ieee-fraud-detection\/train_transaction.csv', index_col='TransactionID')\ntest_transaction = pd.read_csv('..\/input\/ieee-fraud-detection\/test_transaction.csv', index_col='TransactionID')\nsample_submission = pd.read_csv('..\/input\/ieee-fraud-detection\/sample_submission.csv', index_col='TransactionID')\ntrain_identity = pd.read_csv('..\/input\/ieee-fraud-detection\/train_identity.csv', index_col='TransactionID')\ntest_identity = pd.read_csv('..\/input\/ieee-fraud-detection\/test_identity.csv', index_col='TransactionID')","e4d98435":"train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ntest = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n\nprint(train.shape)\nprint(test.shape)\n\ny_train = train['isFraud'].copy()\n\n# Drop target, fill in NaNs\nX_train = train.drop('isFraud', axis=1)\nX_test = test.copy()\n\ndel train, test\n\n# Label Encoding\nfor f in X_train.columns:\n    if X_train[f].dtype=='object' or X_test[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(X_train[f].values) + list(X_test[f].values))\n        X_train[f] = lbl.transform(list(X_train[f].values))\n        X_test[f] = lbl.transform(list(X_test[f].values)) ","35775132":"col_del = []\nfor i in range(339):\n    col = \"V\" + str(i+1)\n    s = train_transaction[col].fillna(0).map(lambda x:0 if x%1 == 0 else 1).sum()\n    if s > 300000:\n        print(col,s)\n        col_del.append(col)\n","f106e76c":"features = [x for x in X_train.columns if x not in col_del]","1ea8c0dc":"train_transaction['hour'] = train_transaction['TransactionDT'].map(lambda x:(x\/\/3600)%24)\ntest_transaction['hour'] = test_transaction['TransactionDT'].map(lambda x:(x\/\/3600)%24)\ntrain_transaction['weekday'] = train_transaction['TransactionDT'].map(lambda x:(x\/\/(3600 * 24))%7)\ntest_transaction['weekday'] = test_transaction['TransactionDT'].map(lambda x:(x\/\/(3600 * 24))%7)\n\ndel train_transaction, train_identity, test_transaction, test_identity","f35c0c6d":"from sklearn.impute import SimpleImputer\nimp = SimpleImputer(missing_values=np.nan, strategy='mean')\nimp.fit(X_train[features])\nX_train[features] = imp.transform(X_train[features])","7289fdf1":"imp.fit(X_test[features])\nX_test[features] = imp.transform(X_test[features])\ndel imp","0687bf62":"print(X_train[features])","85f1b78f":"%%time\n# WARNING! THIS CAN DAMAGE THE DATA \n\nX_train = reduce_mem_usage(X_train)\nX_test = reduce_mem_usage(X_test)","3652565f":"import gc\ngc.collect()","6dc9d4ac":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\ncate = [x for x in X_train.columns if (x == 'ProductCD' or  x.startswith(\"addr\") or x.startswith(\"card\") or \n                                       x.endswith(\"domain\") or x.startswith(\"Device\")) and not x.endswith(\"count\") ]\nprint(cate)\nparams = {'application': 'binary',\n          'boosting': 'gbdt',\n          'metric': 'auc',\n          'max_depth': 16,\n          'learning_rate': 0.03,\n          'bagging_fraction': 0.9,\n          'feature_fraction': 0.9,\n          'verbose': -1,\n          'lambda_l1': 0.1,\n          'lambda_l2': 0.01,\n          'num_leaves': 500,\n          'min_child_weight': 3,\n          'data_random_seed': 17,\n          'nthreads':4}\n\nearly_stop = 500\nverbose_eval = 30\nnum_rounds = 600\n# \nfolds = 3\nkf = KFold(n_splits = folds, shuffle = True, random_state=seed)\ny_preds = np.zeros(X_test.shape[0])\nfeature_importance_df = pd.DataFrame()\ni = 0\nfor tr_idx, val_idx in kf.split(X_train[features], y_train):\n\n    \n    X_tr = X_train.iloc[tr_idx, :]\n    y_tr = y_train.iloc[tr_idx]\n    d_train = lgb.Dataset(X_tr, label=y_tr,categorical_feature = cate)\n    watchlist = []\n    \n    \n    model = lgb.train(params,\n                      train_set=d_train,\n                      num_boost_round=num_rounds,\n                      valid_sets=watchlist,\n                      verbose_eval=verbose_eval)\n        \n    \n    y_preds+= model.predict(X_test[features]) \/ folds\n    \n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = X_tr.columns\n    fold_importance_df[\"importance\"] = model.feature_importance()\n    fold_importance_df[\"fold\"] = i + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    i+=1\n    del X_tr,d_train","dad1c2c1":"print(y_preds)","0dcd454e":"sample_submission['isFraud'] = y_preds\nsample_submission.to_csv('LightGBM.csv')","c7f09203":"**Imputations**","c8a6c18d":"**We deal with the numeric features now. We choose for deletion the features with more than 300000 NAs.**","835ff581":"**Merge, class feature 'y', and categorical features codification**","26ed5720":"# LightGBM + FE + Imputations + Mem Optimization + 3 Folds | Execution Time in 34 mins aprox. | Score 0.938","adab03f5":"# Loading data","0e3f0ce4":"**Memory optimization**","2ada2ee5":"# Training model and Predictions","14f6a34f":"### Some modifications from the public kernel https:\/\/www.kaggle.com\/whitebird\/a-method-to-valid-offline-lb-9506","0b690dac":"**LightGBM**","e0b1d1ef":"# Writing results","fb5cc83c":"# Preprocessing","d6ec21b5":"## Features Election","72707473":"**Data Mapping. Seconds in Hour of Day and Day of Week**","f47b4fe5":"**Garbage Collector**"}}