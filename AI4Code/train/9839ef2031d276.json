{"cell_type":{"834fb6b2":"code","00426617":"code","6496d438":"code","bbae4d18":"code","a8ad7386":"code","d6ae2bca":"code","738be98c":"code","78443292":"code","d4d86eb6":"code","541830a3":"code","4b232c97":"code","43acbe68":"code","6fadde79":"code","f9659a45":"code","0d4662fa":"code","0ec1faaf":"code","a0bb7d46":"code","0063f3b5":"markdown","6c2ec0e9":"markdown","08eee7bb":"markdown","c17f24c5":"markdown","02c3c36b":"markdown","5c423b6f":"markdown","33344e3a":"markdown","96114f9e":"markdown","304c92ae":"markdown","d413b0d7":"markdown","4d63dba1":"markdown","a9015aff":"markdown","a2396537":"markdown"},"source":{"834fb6b2":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","00426617":"df=pd.read_csv('..\/input\/customersegmentation\/Online Retail.csv')\ndf.head()","6496d438":"df.info()","bbae4d18":"df=df.dropna(axis=0)\ndf=df.drop_duplicates()","a8ad7386":"df['InvoiceDate']=pd.to_datetime(df['InvoiceDate'])\n#to convert the columns to days ,we need to get the last day cheaked in data\nlast_date=df['InvoiceDate'].max()  \ndf['InvoiceDate']=last_date-df['InvoiceDate']\ndf['InvoiceDate']=df['InvoiceDate'].dt.days","d6ae2bca":"\ndf['the amount']=df['Quantity']*df['UnitPrice'] ","738be98c":"r_df=df.groupby('CustomerID')['InvoiceDate'].min()\nf_df=df.groupby(df['CustomerID'])['InvoiceNo'].count()\nm_df=df.groupby(df['CustomerID'])['the amount'].sum()","78443292":"rf_data=pd.merge(r_df,f_df,on='CustomerID', how='inner')\nrfm_data=pd.merge(rf_data,m_df,on='CustomerID', how='inner')\nrfm_data.head()","d4d86eb6":"country_data=df.groupby(df['Country'])['CustomerID'].count()\ncountry_data","541830a3":"id_coun=df[['Country','CustomerID']] \nrfmc_data=pd.merge(rfm_data,id_coun,on='CustomerID', how='left')\nrfmc_data=rfmc_data.drop_duplicates()\nrfmc_data=rfmc_data.set_index('CustomerID')\nrfmc_data=rfmc_data.rename(columns={'InvoiceDate':'recency',\n                                    'InvoiceNo':'frequency',\n                                    'the amount':'monetary'})\n\nrfmc_data.groupby(rfmc_data['Country']).count()\nUK_rfmc_data=rfmc_data[rfmc_data['Country']=='United Kingdom']\nUK_rfmc_data.head()","4b232c97":"sns.boxplot(UK_rfmc_data['recency'])","43acbe68":"sns.boxplot(UK_rfmc_data['frequency'])\n","6fadde79":"sns.boxplot(UK_rfmc_data['monetary'])","f9659a45":"UK_rfmc_data.describe()","0d4662fa":"def remove_outlier(df, col_name):\n    q1 = df[col_name].quantile(0.25)\n    q3 = df[col_name].quantile(0.75)\n    iqr = q3-q1\n    fence_low  = q1-1.5*iqr\n    fence_high = q3+1.5*iqr\n    df = df[(df[col_name] > fence_low) & (df[col_name] < fence_high)]\n    return df\nL=0\nwhile L<=3: \n    select_col=UK_rfmc_data.columns[L]\n    remove_data=remove_outlier(UK_rfmc_data,select_col)\n    UK_rfmc_data=remove_data\n    print('turn num ',L+1)\n    print(UK_rfmc_data.shape)\n    L+=1\n    if L==3:\n        break \n    \nUK_rfmc_data.head()","0ec1faaf":"#rfm score \nquantiles = UK_rfmc_data.quantile(q=[0.25,0.5,0.75])\nquantiles = quantiles.to_dict()\n\ndef RScoring(x,p,d):\n    if x <= d[p][0.25]:\n        return 1\n    elif x <= d[p][0.50]:\n        return 2\n    elif x <= d[p][0.75]: \n        return 3\n    else:\n        return 4\n    \ndef FnMScoring(x,p,d):\n    if x <= d[p][0.25]:\n        return 4\n    elif x <= d[p][0.50]:\n        return 3\n    elif x <= d[p][0.75]: \n        return 2\n    else:\n        return 1\n \nUK_rfmc_data['R'] =UK_rfmc_data['recency'].apply(RScoring,\n                                            args=('recency',quantiles,))\nUK_rfmc_data['F'] = UK_rfmc_data['frequency'].apply(FnMScoring,\n                                              args=('frequency',quantiles,))\nUK_rfmc_data['M'] =UK_rfmc_data['monetary'].apply(FnMScoring,\n                                             args=('monetary',quantiles,))    \n\n\nUK_rfmc_data['RFM SCORE']=UK_rfmc_data[['R','F','M']].sum(axis=1)\nUK_rfmc_data.head()","a0bb7d46":"S_customer=UK_rfmc_data[UK_rfmc_data['RFM SCORE']==3]\nS_customer['RFM_Loyalty_Leve']='S'\n\nUK_rfmc_data=UK_rfmc_data[UK_rfmc_data['RFM SCORE']!=3]\n\nLoyalty_Level = ['A','B','C']\nScore_cuts = pd.qcut(UK_rfmc_data['RFM SCORE'], q = 3, labels = Loyalty_Level)\nUK_rfmc_data['RFM_Loyalty_Level'] = Score_cuts.values\n\nA_customer=UK_rfmc_data[UK_rfmc_data['RFM_Loyalty_Level']=='A']\nB_customer=UK_rfmc_data[UK_rfmc_data['RFM_Loyalty_Level']=='B']\nC_customer=UK_rfmc_data[UK_rfmc_data['RFM_Loyalty_Level']=='C']\n","0063f3b5":"United kingdom is most freq country ,so let's use it to make analysis","6c2ec0e9":"'InvoiceDate'is an object columns ,let's convert it to datetime and get days ","08eee7bb":"now I will delete it ","c17f24c5":"in each columns, thier are outliers data","02c3c36b":"in 'recency' column their are 0 value ,in 'monetary' column thier are negative value,so handle it by log tranformation is not possible","5c423b6f":"now ,I will make Loyalty Level columns ,then i will split data to 4 dataframe to make handle it more easy ","33344e3a":"**RFM analysis**","96114f9e":"load data \n","304c92ae":"let's cheak data and missing value and handle it ","d413b0d7":" we have missing value in 'CustomerID'and 'Description'\n drop it is a good option to handle it\n also I will handle duplicates rows \n ","4d63dba1":"recency,frequency,monetary","a9015aff":"**it possible to make analysis to each country ,but in this notebook UK is a good choice to make analysis**","a2396537":"now I will handle outliers data\n"}}