{"cell_type":{"3416ecfd":"code","e7a31035":"code","71b236fa":"code","62d3f190":"code","5bb6096f":"code","71300414":"code","bf19dd11":"code","22062054":"code","478881e3":"code","29f01d77":"code","c6bf8bc0":"code","48ef521c":"code","871fdc13":"code","7e8ed46c":"code","45dbd7e6":"code","36284971":"code","bfc9306b":"code","49157abc":"code","28a59cd7":"code","a13b39e8":"code","ab2e459a":"code","34b73bcc":"code","dd83c9af":"code","b6f4bdc0":"code","25ce5ef8":"code","54b85f9c":"code","54612045":"code","f3089cbd":"code","62d1a355":"code","80d9f4bc":"code","efdafc0d":"code","213f2e0f":"code","023992f6":"code","d626164b":"code","006e34d2":"code","df58abe7":"code","40d1c34e":"code","973f84d7":"code","353dd68f":"code","cd2ea3b3":"code","05af1b4d":"code","ef4a0938":"code","53a4ec41":"code","29d5ffe4":"code","cb84f47a":"code","eec5355c":"code","7ce439ad":"code","37720e8a":"code","19c78ea0":"code","4e414d20":"code","23f9f461":"code","e185e795":"code","0555c8e7":"code","ad91066a":"code","4c4fb565":"code","f9fde000":"code","52bf2861":"code","f87b33cb":"code","66588802":"code","910b0f4b":"code","83b67102":"code","f0a58c63":"markdown","e6dfed03":"markdown","bf0d032b":"markdown","bfaba8d5":"markdown","61458d5a":"markdown","ba294cbb":"markdown","52a9fac5":"markdown","c6c10396":"markdown","07649d5b":"markdown","67603bf4":"markdown","e034e980":"markdown","fa9f2056":"markdown","677b3820":"markdown","e44e032c":"markdown","4f8c11aa":"markdown","aa01ebb2":"markdown","c7d909f7":"markdown","5ee79964":"markdown","20b6a1d1":"markdown","52311e16":"markdown","da170c21":"markdown","1f2cc528":"markdown","3d45561b":"markdown","02382f2a":"markdown","97d10d50":"markdown","b2415c7d":"markdown","55078432":"markdown","9defb508":"markdown","a6347a2c":"markdown","b8af094c":"markdown","dd8fe9d9":"markdown","404c9d1a":"markdown","0c34c935":"markdown","89010a2e":"markdown","7b025482":"markdown"},"source":{"3416ecfd":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport datetime\n\nimport warnings\nwarnings.filterwarnings('ignore')","e7a31035":"books = pd.read_csv('..\/input\/goodbooks-10k\/\/books.csv')\nratings = pd.read_csv('..\/input\/goodbooks-10k\/\/ratings.csv')\nbook_tags = pd.read_csv('..\/input\/goodbooks-10k\/\/book_tags.csv')\ntags = pd.read_csv('..\/input\/goodbooks-10k\/\/tags.csv')","71b236fa":"books['original_publication_year'] = books['original_publication_year'].fillna(-1).apply(lambda x: int(x) if x != -1 else -1)","62d3f190":"ratings_rmv_duplicates = ratings.drop_duplicates()\nunwanted_users = ratings_rmv_duplicates.groupby('user_id')['user_id'].count()\nunwanted_users = unwanted_users[unwanted_users < 3]\nunwanted_ratings = ratings_rmv_duplicates[ratings_rmv_duplicates.user_id.isin(unwanted_users.index)]\nnew_ratings = ratings_rmv_duplicates.drop(unwanted_ratings.index)","5bb6096f":"new_ratings['title'] = books.set_index('id').title.loc[new_ratings.book_id].values","71300414":"new_ratings.head(10)","bf19dd11":"v = books['ratings_count']\nm = books['ratings_count'].quantile(0.95)\nR = books['average_rating']\nC = books['average_rating'].mean()\nW = (R*v + C*m) \/ (v + m)","22062054":"books['weighted_rating'] = W","478881e3":"qualified  = books.sort_values('weighted_rating', ascending=False).head(250)","29f01d77":"qualified[['title', 'authors', 'average_rating', 'weighted_rating']].head(15)","c6bf8bc0":"book_tags.head()","48ef521c":"tags.head()","871fdc13":"genres = [\"Art\", \"Biography\", \"Business\", \"Chick Lit\", \"Children's\", \"Christian\", \"Classics\",\n          \"Comics\", \"Contemporary\", \"Cookbooks\", \"Crime\", \"Ebooks\", \"Fantasy\", \"Fiction\",\n          \"Gay and Lesbian\", \"Graphic Novels\", \"Historical Fiction\", \"History\", \"Horror\",\n          \"Humor and Comedy\", \"Manga\", \"Memoir\", \"Music\", \"Mystery\", \"Nonfiction\", \"Paranormal\",\n          \"Philosophy\", \"Poetry\", \"Psychology\", \"Religion\", \"Romance\", \"Science\", \"Science Fiction\", \n          \"Self Help\", \"Suspense\", \"Spirituality\", \"Sports\", \"Thriller\", \"Travel\", \"Young Adult\"]","7e8ed46c":"genres = list(map(str.lower, genres))\ngenres[:4]","45dbd7e6":"available_genres = tags.loc[tags.tag_name.str.lower().isin(genres)]","36284971":"available_genres.head()","bfc9306b":"available_genres_books = book_tags[book_tags.tag_id.isin(available_genres.tag_id)]","49157abc":"print('There are {} books that are tagged with above genres'.format(available_genres_books.shape[0]))","28a59cd7":"available_genres_books.head()","a13b39e8":"available_genres_books['genre'] = available_genres.tag_name.loc[available_genres_books.tag_id].values\navailable_genres_books.head()","ab2e459a":"def build_chart(genre, percentile=0.85):\n    df = available_genres_books[available_genres_books['genre'] == genre.lower()]\n    qualified = books.set_index('book_id').loc[df.goodreads_book_id]\n\n    v = qualified['ratings_count']\n    m = qualified['ratings_count'].quantile(percentile)\n    R = qualified['average_rating']\n    C = qualified['average_rating'].mean()\n    qualified['weighted_rating'] = (R*v + C*m) \/ (v + m)\n\n    qualified.sort_values('weighted_rating', ascending=False, inplace=True)\n    return qualified","34b73bcc":"cols = ['title','authors','original_publication_year','average_rating','ratings_count','work_text_reviews_count','weighted_rating']","dd83c9af":"genre = 'Fiction'\nbuild_chart(genre)[cols].head(15)","b6f4bdc0":"list(enumerate(available_genres.tag_name))","25ce5ef8":"idx = 24  # romance\nbuild_chart(list(available_genres.tag_name)[idx])[cols].head(15)","54b85f9c":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel, cosine_similarity","54612045":"books['authors'] = books['authors'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x.split(', ')])","f3089cbd":"def get_genres(x):\n    t = book_tags[book_tags.goodreads_book_id==x]\n    return [i.lower().replace(\" \", \"\") for i in tags.tag_name.loc[t.tag_id].values]","62d1a355":"books['genres'] = books.book_id.apply(get_genres)","80d9f4bc":"books['soup'] = books.apply(lambda x: ' '.join([x['title']] + x['authors'] + x['genres']), axis=1)","efdafc0d":"books.soup.head()","213f2e0f":"count = CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\ncount_matrix = count.fit_transform(books['soup'])","023992f6":"cosine_sim = cosine_similarity(count_matrix, count_matrix)","d626164b":"indices = pd.Series(books.index, index=books['title'])\ntitles = books['title']","006e34d2":"def get_recommendations(title, n=10):\n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:31]\n    book_indices = [i[0] for i in sim_scores]\n    return list(titles.iloc[book_indices].values)[:n]","df58abe7":"get_recommendations(\"The One Minute Manager\")","40d1c34e":"def get_name_from_partial(title):\n    return list(books.title[books.title.str.lower().str.contains(title) == True].values)","973f84d7":"title = \"business\"\nl = get_name_from_partial(title)\nlist(enumerate(l))","353dd68f":"get_recommendations(l[1])","cd2ea3b3":"def improved_recommendations(title, n=10):\n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:31]\n    book_indices = [i[0] for i in sim_scores]\n    df = books.iloc[book_indices][['title', 'ratings_count', 'average_rating', 'weighted_rating']]\n\n    v = df['ratings_count']\n    m = df['ratings_count'].quantile(0.60)\n    R = df['average_rating']\n    C = df['average_rating'].mean()\n    df['weighted_rating'] = (R*v + C*m) \/ (v + m)\n    \n    qualified = df[df['ratings_count'] >= m]\n    qualified = qualified.sort_values('weighted_rating', ascending=False)\n    return qualified.head(n)","05af1b4d":"improved_recommendations(\"The One Minute Manager\")","ef4a0938":"improved_recommendations(l[1])","53a4ec41":"# ! pip install surprise","29d5ffe4":"from surprise import Reader, Dataset, SVD\nfrom surprise.model_selection import cross_validate","cb84f47a":"reader = Reader()\ndata = Dataset.load_from_df(new_ratings[['user_id', 'book_id', 'rating']], reader)","eec5355c":"svd = SVD()\ncross_validate(svd, data, measures=['RMSE', 'MAE'])","7ce439ad":"trainset = data.build_full_trainset()\nsvd.fit(trainset);","37720e8a":"new_ratings[new_ratings['user_id'] == 10]","19c78ea0":"svd.predict(10, 1506)","4e414d20":"# bookmat = new_ratings.groupby(['user_id', 'title'])['rating'].mean().unstack()\nbookmat = new_ratings.pivot_table(index='user_id', columns='title', values='rating')\nbookmat.head()","23f9f461":"def get_similar(title, mat):\n    title_user_ratings = mat[title]\n    similar_to_title = mat.corrwith(title_user_ratings)\n    corr_title = pd.DataFrame(similar_to_title, columns=['correlation'])\n    corr_title.dropna(inplace=True)\n    corr_title.sort_values('correlation', ascending=False, inplace=True)\n    return corr_title","e185e795":"title = \"Twilight (Twilight, #1)\"\nsmlr = get_similar(title, bookmat)","0555c8e7":"smlr.head(10)","ad91066a":"smlr = smlr.join(books.set_index('title')['ratings_count'])\nsmlr.head()","4c4fb565":"smlr[smlr.ratings_count > 5e5].sort_values('correlation', ascending=False).head(10)","f9fde000":"def hybrid(user_id, title, n=10):\n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:51]\n    book_indices = [i[0] for i in sim_scores]\n    \n    df = books.iloc[book_indices][['book_id', 'title', 'original_publication_year', 'ratings_count', 'average_rating']]\n    df['est'] = df['book_id'].apply(lambda x: svd.predict(user_id, x).est)\n    df = df.sort_values('est', ascending=False)\n    return df.head(n)","52bf2861":"hybrid(4, 'Eat, Pray, Love')","f87b33cb":"hybrid(10, 'Eat, Pray, Love')","66588802":"def improved_hybrid(user_id, title, n=10):\n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:51]\n    book_indices = [i[0] for i in sim_scores]\n    \n    df = books.iloc[book_indices][['book_id', 'title', 'ratings_count', 'average_rating', 'original_publication_year']]\n    v = df['ratings_count']\n    m = df['ratings_count'].quantile(0.60)\n    R = df['average_rating']\n    C = df['average_rating'].mean()\n    df['weighted_rating'] = (R*v + C*m) \/ (v + m)\n    \n    df['est'] = df['book_id'].apply(lambda x: svd.predict(user_id, x).est)\n    \n    df['score'] = (df['est'] + df['weighted_rating']) \/ 2\n    df = df.sort_values('score', ascending=False)\n    return df[['book_id', 'title', 'original_publication_year', 'ratings_count', 'average_rating', 'score']].head(n)","910b0f4b":"improved_hybrid(4, 'Eat, Pray, Love')","83b67102":"improved_hybrid(10, 'Eat, Pray, Love')","f0a58c63":"## Top \"Genres\" Books <a id=\"5\"><\/a> <br>","e6dfed03":"# Simple Recommender <a id=\"3\"><\/a> <br>\n\nThe Simple Recommender offers generalized recommnendations to every user based on book popularity and (sometimes) genre. The basic idea behind this recommender is that books that are more popular and more critically acclaimed will have a higher probability of being liked by the average audience. This model does not give personalized recommendations based on the user.\n\nThe implementation of this model is extremely trivial. All we have to do is sort our books based on ratings and popularity and display the top books of our list. As an added step, we can pass in a genre argument to get the top books of a particular genre.\n","bf0d032b":"# Conclusion <a id=\"13\"><\/a> <br>\n\nIn this notebook, I have built 4 different recommendation engines based on different ideas and algorithms. They are as follows:\n\n1. **Simple Recommender:** This system used overall Goodreads Ratings Count and Rating Averages to build Top Books Charts, in general and for a specific genre. The IMDB Weighted Rating System was used to calculate ratings on which the sorting was finally performed.\n2. **Content Based Recommender:** We built content based engines that took book title, authors and genres as input to come up with predictions. We also deviced a simple filter to give greater preference to books with more votes and higher ratings.\n3. **Collaborative Filtering:** We built two Collaborative Filters; \n  - one that uses the powerful Surprise Library to build an **user-based** filter based on single value decomposition, since the RMSE obtained was less than 1, and the engine gave estimated ratings for a given user and book.\n  - And the other (**item-based**) which built a pivot table for users ratings corresponding to each book, and the engine gave similar books for a given book.\n4. **Hybrid Engine:** We brought together ideas from content and collaborative filterting to build an engine that gave book suggestions to a particular user based on the estimated ratings that it had internally calculated for that user.\n\nPrevious -> [The Story of Book](https:\/\/www.kaggle.com\/omarzaghlol\/goodreads-1-the-story-of-book\/)","bfaba8d5":"Ok, we got similar books, but we need to filter them by their *ratings_count*.","61458d5a":"Ok, we see that the new results make more sense, besides to, the recommendations are more personalized and tailored towards particular users.","ba294cbb":"Get similar books with at least 500k ratings.","52a9fac5":"Let us pick users 10 and check the ratings s\/he has given.","c6c10396":"# Clean the dataset <a id=\"2\"><\/a> <br>\n\nAs with nearly any real-life dataset, we need to do some cleaning first. When exploring the data I noticed that for some combinations of user and book there are multiple ratings, while in theory there should only be one (unless users can rate a book several times). Furthermore, for the collaborative filtering it is better to have more ratings per user. So I decided to remove users who have rated fewer than 3 books.","07649d5b":"## Cosine Similarity <a id=\"7\"><\/a> <br>\n\nI will be using the Cosine Similarity to calculate a numeric quantity that denotes the similarity between two books. Mathematically, it is defined as follows:\n\n$cosine(x,y) = \\frac{x. y^\\intercal}{||x||.||y||} $\n\n","67603bf4":"- [Importing Libraries and Loading Our Data](#1)\n- [Clean the dataset](#2)\n- [Simple Recommender](#3)\n    - [Top Books](#4)\n    - [Top \"Genres\" Books](#5)\n- [Content Based Recommender](#6)\n    - [Cosine Similarity](#7)\n    - [Popularity and Ratings](#8)\n- [Collaborative Filtering](#9)\n    - [User Based](#10)\n    - [Item Based](#11)\n- [Hybrid Recommender](#12)\n- [Conclusion](#13)\n- [Save Model](#14)","e034e980":"There are two classes of Collaborative Filtering:\n![](https:\/\/miro.medium.com\/max\/1280\/1*QvhetbRjCr1vryTch_2HZQ.jpeg)\n- **User-based**, which measures the similarity between target users and other users.\n- **Item-based**, which measures the similarity between the items that target users rate or interact with and other items.","fa9f2056":"For simplicity, you can just pass the index of the wanted genre from below. ","677b3820":"My approach to building the recommender is going to be extremely *hacky*. These are steps I plan to do:\n1. **Strip Spaces and Convert to Lowercase** from authors. This way, our engine will not confuse between **Stephen Covey** and **Stephen King**.\n2. Combining books with their corresponding **genres** .\n2. I then use a **Count Vectorizer** to create our count matrix.\n\nFinally, we calculate the cosine similarities and return books that are most similar.","e44e032c":"I think the sorting of similar is more better now than before.\nTherefore, we will conclude our Content Based Recommender section here and come back to it when we build a hybrid engine.\n","4f8c11aa":"Let us see our method in action by displaying the Top 15 Fiction Books (Fiction almost didn't feature at all in our Generic Top Chart despite being one of the most popular movie genres).","aa01ebb2":"For book with ID 1506, we get an estimated prediction of **3.393**. One startling feature of this recommender system is that it doesn't care what the book is (or what it contains). It works purely on the basis of an assigned book ID and tries to predict ratings based on how the other users have predicted the book.","c7d909f7":"We get a mean **Root Mean Sqaure Error** of about 0.8419 which is more than good enough for our case. Let us now train on our dataset and arrive at predictions.","5ee79964":"We see that for our hybrid recommender, we get (almost) different recommendations for different users although the book is the same. But maybe we can make it better through following steps:\n1. Use our *improved_recommendations* technique , that we used in the **Content Based** seciton above\n2. Combine it with the user *estimations*, by dividing their summation by 2\n3. Finally, put the result into a new feature ***score***","20b6a1d1":"# Books Recommender System","52311e16":"What if I want a specific book but I can't remember it's full name!!\n\nSo I created the following *method* to get book titles from a **partial** title.","da170c21":"# What's in this kernel?","1f2cc528":"![](http:\/\/labs.criteo.com\/wp-content\/uploads\/2017\/08\/CustomersWhoBought3.jpg)","3d45561b":"This is the second part of my project on Book Data Analysis and Recommendation Systems. \n\nIn my first notebook ([The Story of Book](https:\/\/www.kaggle.com\/omarzaghlol\/goodreads-1-the-story-of-book\/)), I attempted at narrating the story of book by performing an extensive exploratory data analysis on Books Metadata collected from Goodreads.\n\nIn this notebook, I will attempt at implementing a few recommendation algorithms (Basic Recommender, Content-based and Collaborative Filtering) and try to build an ensemble of these models to come up with our final recommendation system.","02382f2a":"# Content Based Recommender <a id=\"6\"><\/a> <br>\n\n![](https:\/\/miro.medium.com\/max\/828\/1*1b-yMSGZ1HfxvHiJCiPV7Q.png)\n\nThe recommender we built in the previous section suffers some severe limitations. For one, it gives the same recommendation to everyone, regardless of the user's personal taste. If a person who loves business books (and hates fiction) were to look at our Top 15 Chart, s\/he wouldn't probably like most of the books. If s\/he were to go one step further and look at our charts by genre, s\/he wouldn't still be getting the best recommendations.\n\nFor instance, consider a person who loves *The Fault in Our Stars*, *Twilight*. One inference we can obtain is that the person loves the romaintic books. Even if s\/he were to access the romance chart, s\/he wouldn't find these as the top recommendations.\n\nTo personalise our recommendations more, I am going to build an engine that computes similarity between movies based on certain metrics and suggests books that are most similar to a particular book that a user liked. Since we will be using book metadata (or content) to build this engine, this also known as **Content Based Filtering.**\n\nI will build this recommender based on book's *Title*, *Authors* and *Genres*.","97d10d50":"## Popularity and Ratings <a id=\"8\"><\/a> <br>\n\nOne thing that we notice about our recommendation system is that it recommends books regardless of ratings and popularity. It is true that ***Across the River and Into the Trees*** and ***The Old Man and the Sea*** were written by **Ernest Hemingway**, but the former one was cnosidered a bad (not the worst) book that shouldn't be recommended to anyone, since that most people hated the book for it's static plot and overwrought emotion.\n\nTherefore, we will add a mechanism to remove bad books and return books which are popular and have had a good critical response.\n\nI will take the top 30 movies based on similarity scores and calculate the vote of the 60th percentile book. Then, using this as the value of $m$, we will calculate the weighted rating of each book using IMDB's formula like we did in the Simple Recommender section.","b2415c7d":"We see that J.K. Rowling's **Harry Potter** Books occur at the very top of our chart. The chart also indicates a strong bias of Goodreads Users towards particular genres and authors. \n\nLet us now construct our function that builds charts for particular genres. For this, we will use relax our default conditions to the **85th** percentile instead of 95. ","55078432":"# Collaborative Filtering <a id=\"9\"><\/a> <br>\n\n![](https:\/\/miro.medium.com\/max\/706\/1*DYJ-HQnOVvmm5suNtqV3Jw.png)\n\nOur content based engine suffers from some severe limitations. It is only capable of suggesting books which are *close* to a certain book. That is, it is not capable of capturing tastes and providing recommendations across genres.\n\nAlso, the engine that we built is not really personal in that it doesn't capture the personal tastes and biases of a user. Anyone querying our engine for recommendations based on a book will receive the same recommendations for that book, regardless of who s\/he is.\n\nTherefore, in this section, we will use a technique called **Collaborative Filtering** to make recommendations to Book Readers. Collaborative Filtering is based on the idea that users similar to a me can be used to predict how much I will like a particular product or service those users have used\/experienced but I have not.\n\nI will not be implementing Collaborative Filtering from scratch. Instead, I will use the **Surprise** library that used extremely powerful algorithms like **Singular Value Decomposition (SVD)** to minimise RMSE (Root Mean Square Error) and give great recommendations.","9defb508":"# Importing Libraries and Loading Our Data <a id=\"1\"><\/a> <br>","a6347a2c":"## - Item Based <a id=\"11\"><\/a> <br>","b8af094c":"Here we will build a table for users with their corresponding ratings for each book. ","dd8fe9d9":"I will use IMDB's *weighted rating* formula to construct my chart. Mathematically, it is represented as follows:\n\nWeighted Rating (WR) = $(\\frac{v}{v + m} . R) + (\\frac{m}{v + m} . C)$\n\nwhere,\n* *v* is the number of ratings for the book\n* *m* is the minimum ratings required to be listed in the chart\n* *R* is the average rating of the book\n* *C* is the mean rating across the whole report\n\nThe next step is to determine an appropriate value for *m*, the minimum ratings required to be listed in the chart. We will use **95th percentile** as our cutoff. In other words, for a book to feature in the charts, it must have more ratings than at least 95% of the books in the list.\n\nI will build our overall Top 250 Chart and will define a function to build charts for a particular genre. Let's begin!","404c9d1a":"That's more interesting and reasonable result, since we could get *Twilight* book series in our top results. ","0c34c935":"## Top Books <a id=\"4\"><\/a> <br>","89010a2e":"# Hybrid Recommender <a id=\"12\"><\/a> <br>\n\n![](https:\/\/www.toonpool.com\/user\/250\/files\/hybrid_20095.jpg)\n\nIn this section, I will try to build a simple hybrid recommender that brings together techniques we have implemented in the content based and collaborative filter based engines. This is how it will work:\n\n* **Input:** User ID and the Title of a Book\n* **Output:** Similar books sorted on the basis of expected ratings by that particular user.","7b025482":"## - User Based <a id=\"10\"><\/a> <br>"}}