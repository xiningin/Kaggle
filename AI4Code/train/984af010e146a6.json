{"cell_type":{"b33f42a8":"code","b06a94f2":"code","32234fa0":"code","b867addf":"code","55e0bcc6":"code","a5f65b9d":"code","89e7789b":"code","3b49e605":"code","a09c12da":"code","7e31e83e":"code","27e94963":"code","c554106a":"code","6f765b30":"code","fc3ab0ed":"code","f031e17b":"code","3bc1bca1":"code","47a3118c":"code","4cbd574d":"code","32eef2e3":"code","cb488ce1":"code","2d253910":"code","57b33777":"code","4d7dc39a":"code","fba8e3c0":"code","5a073764":"code","57e8b275":"code","309f89d4":"code","88125191":"markdown","0e614766":"markdown","568db627":"markdown","5145d9e3":"markdown","b87d1daf":"markdown","b87806ab":"markdown","1dab4092":"markdown","89b928f4":"markdown","50a9ec08":"markdown"},"source":{"b33f42a8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b06a94f2":"df_sub = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\ndf_sub.head()","32234fa0":"df_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","b867addf":"df_train.head()","55e0bcc6":"df_test.head()","a5f65b9d":"df_train.describe(include='all')","89e7789b":"100 * df_train.Survived.value_counts(normalize=True).round(4)","3b49e605":"100 * df_train.Pclass.value_counts(normalize=True).round(4)","a09c12da":"100 * df_train.Sex.value_counts(normalize=True).round(4)","7e31e83e":"100 * df_train.SibSp.value_counts(normalize=True).round(4)","27e94963":"100 * df_train.Parch.value_counts(normalize=True).round(4)","c554106a":"100 * df_train.Embarked.value_counts(normalize=True).round(4)","6f765b30":"df_train.head()","fc3ab0ed":"from sklearn.model_selection import StratifiedKFold","f031e17b":"# Add new column for fold information\ndf_train['kfold'] = -1\n\n# Randomize the training data\ndf_train = df_train.sample(frac=1).reset_index(drop=True)\n\n# Initialize the StratifiedKFold\nskf = StratifiedKFold(n_splits = 5)\n\n# Get X and y from training dataset\nX = df_train.drop('Survived', axis=1).values\ny = df_train.Survived.values\n\n# Assign fold for validation dataset\nfor fold_, (trn_, val_) in enumerate(skf.split(X, y)):\n    df_train.loc[val_, 'kfold'] = fold_\n","3bc1bca1":"from sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression","47a3118c":"def transform_df(df, is_train = True, fold=None):\n    # list of numerical columns\n    num_cols = ['Age', 'Fare']\n    # list of unused columns\n    unused_cols = ['PassengerId', 'Name', 'Ticket']\n    if is_train:\n        unused_cols.append('Survived')\n        unused_cols.append('kfold')\n    \n    # all columns are features except PassengerId, Name, Ticket, Survived and kfold\n    features = [f for f in df.columns if f not in unused_cols]\n    \n    # Fill all NaN values with NONE\n    for col in features:\n        if col not in num_cols:\n            df.loc[:, col] = df[col].astype(str).fillna('NONE')\n        else:\n            df.loc[:, col] = df[col].fillna(-1)\n    \n    if is_train:\n        df_train = df[df['kfold'] != fold].reset_index(drop=True)\n        df_val = df[df['kfold'] == fold].reset_index(drop=True)\n    \n    features_cat = [f for f in features if f not in num_cols]\n    \n    if is_train:\n        data_cat = pd.concat([df_train[features_cat], df_val[features_cat]], axis=0)\n        \n    for f_ in features_cat:\n        # Initialize OneHotEncoder\n        lbl = LabelEncoder()\n        \n        if is_train:\n            lbl.fit(data_cat[f_])\n            df_train.loc[:, f_] = lbl.transform(df_train[f_])\n            df_val.loc[:, f_] = lbl.transform(df_val[f_])\n        else:\n            df.loc[:, f_] = lbl.fit_transform(df[f_])\n    \n    \n    \n    # Initialize MinMaxScaler required to normalize num_cols\n    scaler = MinMaxScaler()\n    \n    # Merge full training data (train + validation) for num features\n    if is_train:\n        data_num = pd.concat([df_train[num_cols], df_val[num_cols]], axis=0)\n    else:\n        data_num = df[num_cols]\n    \n    \n    # Fit Ohe on full_data\n    scaler.fit(data_num)\n    \n    if is_train:\n        # Transform dataset\n        df_train.loc[:, num_cols] = scaler.transform(df_train[num_cols])\n        df_val.loc[:, num_cols] = scaler.transform(df_val[num_cols])\n    else:\n        df.loc[:, num_cols] = scaler.transform(df[num_cols])\n    \n    if is_train:\n        return df_train[features], df_val[features], df_train.Survived.values, df_val.Survived.values\n    return df.PassengerId.values, df[features]","4cbd574d":"def run(df_train, fold, model):\n        \n    # Get training and validation dataset\n    x_train, x_val, y_train, y_val = transform_df(df_train, is_train=True, fold=fold)\n    \n    # Fit the model on training data\n    model.fit(x_train, y_train)\n    \n    # Predict from validation data\n    # We need the probability values as we are using AUC, we will use the probability of 1s\n    valid_preds = model.predict_proba(x_val)[:, 1]\n    \n    # Get roc auc score\n    auc = roc_auc_score(y_val, valid_preds)\n    \n    # Display AUC\n    print(f'Fold={fold}, AUC={auc}')\n    \n    return auc","32eef2e3":"# Logistic regression\nbest_model = None\nbest_auc = None\nfor fold_ in range(5):\n    model = LogisticRegression()\n    auc = run(df_train, fold=fold_, model=model)\n    if best_auc is None or best_auc < auc:\n        best_model = model\n        best_auc = auc\nprint ('Best AUC={}'.format(best_auc))","cb488ce1":"df_test_PassengerId, df_test_transformed = transform_df(df_test, is_train=False)","2d253910":"def submission(X, passengerId, model, submission_index):\n    preds = model.predict(X)\n    \n    sub_df = pd.DataFrame(list(zip(passengerId, preds)), columns=['PassengerId', 'Survived'])\n    sub_df.to_csv(f'Submission_{submission_index}.csv', index=False)","57b33777":"submission(df_test_transformed, df_test_PassengerId, best_model, submission_index=1)","4d7dc39a":"from sklearn.tree import DecisionTreeClassifier","fba8e3c0":"# Decision Tree\nbest_model = None\nbest_auc = None\nfor fold_ in range(5):\n    model = DecisionTreeClassifier(random_state=42)\n    auc = run(df_train, fold=fold_, model=model)\n    if best_auc is None or best_auc < auc:\n        best_model = model\n        best_auc = auc\nprint ('Best AUC={}'.format(best_auc))","5a073764":"from sklearn.ensemble import RandomForestClassifier","57e8b275":"# Random Forest\nbest_model = None\nbest_auc = None\nfor fold_ in range(5):\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\n    auc = run(df_train, fold=fold_, model=model)\n    if best_auc is None or best_auc < auc:\n        best_model = model\n        best_auc = auc\nprint ('Best AUC={}'.format(best_auc))","309f89d4":"# Submission 2\nsubmission(df_test_transformed, df_test_PassengerId, best_model, submission_index=2)\n# Didn't improve score in Overall competition","88125191":"## View submission file to know what to submit","0e614766":"# Cross validation\nCreate folds for train data","568db627":"DecisionTree didn't improve much compared to LogisticRegression","5145d9e3":"# Check counts of each category in train dataset for categorical columns","b87d1daf":"# Load the data into dataframes","b87806ab":"RandomForest has improved much on AUC score compared to LogisticRegression, DecisionTree","1dab4092":"## Load train and test files","89b928f4":"Define a function to run for each fold and make predictions on each fold","50a9ec08":"In above counts, we can see that our target column is skewed. So, it gives us hint to use 'AUC score' as metric for the model evaluation."}}