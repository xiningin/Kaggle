{"cell_type":{"c2eda1c9":"code","a08b6b5f":"code","3e9a0d88":"code","2927db3c":"code","74be26f8":"code","4bb2400c":"code","4066bffc":"code","5d90aa43":"code","3338db10":"code","29b7e301":"code","f80e7ef2":"code","ee714f62":"code","0d161505":"code","cb26a448":"code","b7f2d83b":"code","b6ada056":"code","d27bb85a":"code","ac5837c7":"code","2d35ce01":"code","dc86f533":"code","98327840":"markdown","45fede91":"markdown"},"source":{"c2eda1c9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nidir = os.path.join('..', 'input')\n# Any results you write to the current directory are saved as output.\ndf_aisles = pd.read_csv(os.path.join(idir, 'aisles.csv'))\nprint(df_aisles.head())","a08b6b5f":"df_department = pd.read_csv(os.path.join(idir, 'departments.csv'))\ndf_opp = pd.read_csv(os.path.join(idir, 'order_products__prior.csv'))\ndf_opt = pd.read_csv(os.path.join(idir, 'order_products__train.csv'))\ndf_orders = pd.read_csv(os.path.join(idir, 'orders.csv'))\ndf_products = pd.read_csv(os.path.join(idir, 'products.csv'))\n","3e9a0d88":"for df in [df_aisles, df_department, df_opp, df_opt, df_orders, df_products]:\n    print(df.head())","2927db3c":"for df in [df_aisles, df_department, df_opp, df_opt, df_orders, df_products]:\n    print(df.columns)","74be26f8":"df_orders.describe()","4bb2400c":"df_orders.head()","4066bffc":"df_orders['eval_set'].value_counts()","5d90aa43":"df = pd.merge(\n    left = df_products,\n    right = df_department,\n    on = 'department_id',\n    left_index = False,\n    right_index = False\n)\n\ndf = pd.merge(\n    left = df,\n    right = df_aisles,\n    on = 'aisle_id',\n    left_index = False,\n    right_index = False\n)\n\ndf_prior = pd.merge(\n    left = df,\n    right = df_opp,\n    on = 'product_id',\n    left_index = False,\n    right_index = False\n)\n\ndf_prior = pd.merge(\n    left = df_prior,\n    right = df_orders[df_orders['eval_set'] == 'prior'],\n    on = 'order_id',\n    left_index = False,\n    right_index = False\n)\n\ndf_train = pd.merge(\n    left = df,\n    right = df_opt,\n    on = 'product_id',\n    left_index = False,\n    right_index = False\n)\n\ndf_train = pd.merge(\n    left = df_train,\n    right = df_orders[df_orders['eval_set'] == 'train'],\n    on = 'order_id',\n    left_index = False,\n    right_index = False\n)\n\ndf_test = df_orders.loc[df_orders['eval_set'] == 'test', :]\n    ","3338db10":"df_train.head()","29b7e301":"df_prior['reordered'].value_counts()","f80e7ef2":"df_prior.groupby('product_name')['reordered'].sum().sort_values(ascending=False)","ee714f62":"# sum reorder by dept\n# days since last order\ndf_prior.groupby('department')['reordered'].sum().sort_values(ascending=False)\n","0d161505":"import seaborn as sns\n\ndf_prior['order_dow'].value_counts().sort_index().plot.bar()","cb26a448":"df_user_order_cnts = df_prior.groupby(['user_id', 'order_id'])[['product_id']].count()\ndf_order_agg = df_user_order_cnts.reset_index().groupby(['user_id'])['product_id'].agg({'Avg Items Per Order':'mean', 'Number of Orders':'count'})\ndf_order_agg.sort_values(by='Number of Orders', ascending=False)","b7f2d83b":"df_prior[df_prior['user_id'] == 152340].groupby(['product_id', 'product_name'])['aisle'].count().sort_values(ascending=False)","b6ada056":"mask = (df_prior['user_id'] == 152340) & (df_prior['product_id'] == 35461)\ndf_prior.loc[mask, :].groupby('order_dow').count()['product_id'].plot.bar()","d27bb85a":"df_prior.loc[mask, :].groupby('days_since_prior_order').count()['product_id'].plot.bar()","ac5837c7":"sns.heatmap(df_prior.isnull(), cbar=False)","2d35ce01":"sns.heatmap(df_train.isnull(), cbar=False)","dc86f533":"sns.heatmap(df_test.isnull(), cbar=False)","98327840":"Ideas to pursue:\n- Look at a single customer first (highest 5 customers - total number of orders, average number of items per order)\n- Graph the number of days since last order\n","45fede91":"TODO:\n- When training our model keep each customer separate\n- Cluster customers\n"}}