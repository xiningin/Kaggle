{"cell_type":{"68c2ecc7":"code","00996c0c":"code","97017b16":"code","a4e6d66c":"code","fce3301f":"code","54495b7a":"code","c20a8ad5":"code","f23ed2b9":"code","0120944c":"code","22485322":"code","2442872a":"code","86493905":"code","872bcba2":"code","666602dc":"code","95329f9b":"markdown"},"source":{"68c2ecc7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom itertools import combinations\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","00996c0c":"df= pd.read_csv('..\/input\/another-fiat-500-dataset-1538-rows\/automobile_dot_it_used_fiat_500_in_Italy_dataset_filtered.csv')\ndf.head()","97017b16":"#from https:\/\/it.wikipedia.org\/wiki\/Fiat_500_(2007)#Versioni_e_allestimenti\n# we can check the power values for 500's engines\n# we have 4 possible values in kw 62,5 - 77,2 - 51 - 73,5\n\ndef replace_power(power):\n    if power == 73 or power == 74:\n        return 73\n    elif power == 62 or power == 63:\n        return 62\n    else:\n        return power\n    \n# fix power values\ndf['engine_power'] = df['engine_power'].apply(lambda power: replace_power(power))\n#since 58 Kw does not correspond at any sold engine and we have only one element: remove those rows\ndf = df[df['engine_power'] != 58]","a4e6d66c":"# encode and standardize\n\ndef replace_model(model):\n    if model == 'sport':\n        return 2\n    if model == 'lounge':\n        return 1\n    if model == 'pop':\n        return 0\n    \n# fix power values\ndf['model'] = df['model'].apply(lambda model: replace_model(model))","fce3301f":"df.head()","54495b7a":"sns.pairplot(df)","c20a8ad5":"figure, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(nrows=3, ncols=2)\nfigure.set_size_inches(16,28)\n_ = sns.regplot(df['engine_power'], df['price'], ax=ax1)\n_ = sns.regplot(df['age_in_days'], df['price'], ax=ax2)\n_ = sns.regplot(df['km'], df['price'], ax=ax3)\n_ = sns.regplot(df['previous_owners'], df['price'], ax=ax4)\n_ = sns.regplot(df['lat'], df['price'], ax=ax5)\n_ = sns.regplot(df['lon'], df['price'], ax=ax6)\n","f23ed2b9":"# correlation map\ndf.corr()","0120944c":"features = ['model', 'engine_power', 'age_in_days', 'km', 'previous_owners', 'lat','lon', 'price']\n\nselected_features = ['model', 'engine_power', 'age_in_days', 'km', 'previous_owners', 'lat','lon']\n\n#df.drop(drop_features, axis=1, inplace=True)","22485322":"# try all combinations to get the best results\n\nfor i in range(1, len(selected_features)+1):\n    combs = combinations(selected_features,i)\n    for comb in combs:\n        df2 = df[list(comb)]\n        X = df2.values\n        Y = df.price.values\n\n        X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=0, shuffle=True)\n\n        print(list(comb))\n        for deg in range(1,5):\n            poly = PolynomialFeatures(degree=deg)\n            X_train_poly = poly.fit_transform(X_train)\n            X_test_poly = poly.transform(X_test)\n            regressor = LinearRegression()\n            regressor.fit(X_train_poly,y_train)\n            y_test_pred = regressor.predict(X_test_poly)\n            print('deg=%d, train score= %.4f, test score= %.4f' %(deg,regressor.score(X_train_poly, y_train),regressor.score(X_test_poly, y_test)))\n    ","2442872a":"# Use best feature list and train the model again\n\nbest_feature_list = ['model', 'age_in_days', 'km', 'previous_owners', 'lat', 'lon']\n\nX = df[best_feature_list].values\nY = df.price.values\n\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=0, shuffle=True)\n\npoly = PolynomialFeatures(degree=2)\nX_train_poly = poly.fit_transform(X_train)\nX_test_poly = poly.transform(X_test)\nregressor = LinearRegression()\nregressor.fit(X_train_poly,y_train)\ny_train_pred = regressor.predict(X_train_poly)\ny_test_pred = regressor.predict(X_test_poly)\nprint('deg=%d, train score= %.4f, test score= %.4f' %(deg,regressor.score(X_train_poly, y_train),regressor.score(X_test_poly, y_test)))\n    ","86493905":"# predict the first 20 values of test set and compare with the real value\nfor i in range(0, len(y_test[:20])):\n    print(str(y_test[i]) + \",  \" +  str(y_test_pred[i]))","872bcba2":"# plot difference between y_train and y_train_pred\nplt.scatter(y_train, y_train_pred)\nplt.scatter(y_train, y_train);","666602dc":"# plot difference between y_test and y_test_pred\nplt.scatter(y_test, y_test_pred)\nplt.scatter(y_test, y_test);","95329f9b":"Best results:\n    \nbest feature list: ['model', 'age_in_days', 'km', 'previous_owners', 'lat', 'lon']\nwith deg=2: train score= 0.8577, test score= 0.8465\n\nConsiderations:\nIt looks like the car outfit (model) does not matter that much for the used car's price"}}