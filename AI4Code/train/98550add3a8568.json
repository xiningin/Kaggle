{"cell_type":{"93c4b190":"code","1139ebb0":"code","3307a048":"code","c6f4e49f":"code","e5b144b2":"code","c820b7a7":"code","824a2fd9":"code","af02d2d1":"code","ef99432b":"code","aaf46f17":"code","589bab9c":"code","ec19c524":"code","beca03da":"code","49515e44":"code","35f74e05":"code","36023e14":"code","37569f71":"code","2dce1655":"code","06698b01":"code","9bd829dd":"code","e10d8278":"code","0e26c4c4":"code","56518a21":"code","e2d7abbd":"code","ea9e9529":"code","ce3759b9":"code","a49ec976":"code","b263b746":"code","10a0878c":"code","19a9d137":"code","58c2f328":"markdown","d15dfcec":"markdown","6bb277a7":"markdown","64f8a973":"markdown"},"source":{"93c4b190":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tensorflow import keras\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1139ebb0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nfrom tkinter import filedialog,Text\nfrom PIL import Image, ImageOps\nimport tkinter as tk\nimport io\n\n","3307a048":"import tensorflow as tf\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten\nimport tensorflow_hub as hub\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dot, Lambda, Input\nfrom tensorflow.keras.models import Sequential,Model\nimport keras\nfrom tensorflow.keras import datasets, layers, models","c6f4e49f":"fashion_mnist=keras.datasets.fashion_mnist\n(train_images,train_label),(test_images,test_label)=fashion_mnist.load_data()","e5b144b2":"print(len(train_images),len(train_label))\nprint(len(test_images),len(test_label))","c820b7a7":"pt_x_train=[]\npt_y_train=[]   \nfor i in range(len(train_images)):\n    if(train_label[i] in [0,1,2,3,4]):\n                pt_x_train.append(train_images[i])\n                pt_y_train.append(train_label[i])\n\npt_x_train=np.array(pt_x_train)\n\npt_y_train = pd.get_dummies(pt_y_train)\npt_y_train=np.array(pt_y_train)","824a2fd9":"print(np.shape(pt_x_train))\nprint(np.shape(pt_y_train))","af02d2d1":"pt_x_test=[]\npt_y_test=[]   \nfor i in range(len(test_images)):\n    if(test_label[i] in [0,1,2,3,4]):\n                pt_x_test.append(test_images[i])\n                pt_y_test.append(test_label[i])\n\npt_x_test=np.array(pt_x_test)\n\npt_y_test = pd.get_dummies(pt_y_test)\npt_y_test=np.array(pt_y_test)","ef99432b":"print(np.shape(pt_x_test))\nprint(np.shape(pt_y_test))","aaf46f17":"from sklearn.model_selection import train_test_split\nX_train=pt_x_train.reshape((len(pt_x_train),28,28,1))\nY_train=pt_y_train\n\nX_test=pt_x_test.reshape((len(pt_x_test),28,28,1))\nY_test=pt_y_test","589bab9c":"len(pt_x_train)","ec19c524":"print(X_train.shape,Y_train.shape)","beca03da":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\ntrain_datagen.fit(X_train)\n\ntrain_generator = train_datagen.flow(X_train,Y_train,batch_size = 32)","49515e44":"\nmodel_transfer = Sequential()\nmodel_transfer.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28,28, 1)))\nmodel_transfer.add(layers.MaxPooling2D((2, 2)))\nmodel_transfer.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel_transfer.add(layers.MaxPooling2D((2, 2)))\nmodel_transfer.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel_transfer.add(layers.MaxPooling2D((2, 2)))\nmodel_transfer.add(layers.Flatten())\n\nmodel_transfer.summary()","35f74e05":"final_layer_model = Sequential()\nfinal_layer_model.add(layers.Input(64))\nfinal_layer_model.add(layers.Dense(5, activation=\"softmax\"))\n\nmodel = tf.keras.Sequential([\n        model_transfer,\n        final_layer_model\n        \n])","36023e14":"model.summary()","37569f71":"model.compile(optimizer='adam',\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])","2dce1655":"model.fit(train_generator,\n         validation_data=(X_test, Y_test),\n         epochs=5,\n         verbose=2)\n","06698b01":"tl_x_train=[]\ntl_y_train=[]   \nfor i in range(len(train_images)):\n    if(train_label[i] in [5,6,7,8,9]):\n                tl_x_train.append(train_images[i])\n                tl_y_train.append(train_label[i])\n\ntl_x_train=np.array(tl_x_train)\n\ntl_y_train = pd.get_dummies(tl_y_train)\ntl_y_train=np.array(tl_y_train)","9bd829dd":"print(np.shape(tl_x_train))\nprint(np.shape(tl_y_train))","e10d8278":"tl_x_test=[]\ntl_y_test=[]   \nfor i in range(len(test_images)):\n    if(test_label[i] in [0,1,2,3,4]):\n                tl_x_test.append(test_images[i])\n                tl_y_test.append(test_label[i])\n\ntl_x_test=np.array(pt_x_test)\n\ntl_y_test = pd.get_dummies(tl_y_test)\ntl_y_test=np.array(tl_y_test)","0e26c4c4":"print(np.shape(tl_x_test))\nprint(np.shape(tl_y_test))","56518a21":"X_train=pt_x_train.reshape((len(pt_x_train),28,28,1))\nY_train=pt_y_train\n\nX_test=pt_x_test.reshape((len(pt_x_test),28,28,1))\nY_test=pt_y_test","e2d7abbd":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\ntrain_datagen.fit(X_train)\n\ntrain_generator = train_datagen.flow(X_train,Y_train,batch_size = 32)","ea9e9529":"for l in  model_transfer.layers:\n    l.trainable=False","ce3759b9":"for l in model_transfer.layers:\n    print(l.name, l.trainable)","a49ec976":"\n\n\n\nfinal_layer_Transferlearning_model = Sequential()\nfinal_layer_Transferlearning_model.add(layers.Input(64))\nfinal_layer_Transferlearning_model.add(layers.Dense(5, activation=\"softmax\"))\n\nmodel2 = tf.keras.Sequential([\n        model_transfer,\n        final_layer_model\n        \n])","b263b746":"model2.summary()","10a0878c":"model2.compile(optimizer='adam',\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])","19a9d137":"model2.fit(train_generator,\n         validation_data=(X_test, Y_test),\n         epochs=5,\n         verbose=2)","58c2f328":"-------------------------From Here The Transfer Learning part Starts--------------------------","d15dfcec":"---------- freezing weights of trained earlier model----------------","6bb277a7":"After Creating pt_x_train, tl_x_train, pt_x_test,tl_x_test\n* Shape of pt_x_train=(30000,28,28)\n* Shape of tl_x_train=(30000,28,28)\n* Shape of pt_x_test=(5000,28,28)\n* Shape of tl_x_test=(5000,28,28)","64f8a973":"**Loading Dataset**"}}