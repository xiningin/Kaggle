{"cell_type":{"c3a79200":"code","698223eb":"code","5a4b33e8":"code","0e93754d":"code","ae9a3e82":"code","9274f743":"code","c0e5e5fa":"code","2f2ff3da":"code","eb99ebb7":"code","58291ec9":"code","ba5aefbf":"code","49c75a20":"code","93f9fe1a":"code","bcf7d159":"code","ba23622c":"code","19e86255":"code","1478c6ad":"code","b6bf653e":"code","2ca03b3f":"code","827a6fe9":"code","fd0bafb4":"code","bc6f3996":"code","19880a99":"code","4f99e2ec":"code","5204dc18":"code","837fb3be":"code","069f70e1":"code","f88559df":"code","a49302ac":"code","8c087c6f":"code","e4b05558":"code","671b5721":"code","61b0a3d0":"code","fe9c8b2e":"code","f3d6a11b":"code","6bce35e4":"code","0d2b208f":"code","c885fb65":"code","20a53e8e":"code","a8cc4afe":"code","8aab5086":"code","fc5cf7b5":"code","f02fa14e":"code","1feeb3b7":"code","fba20f96":"code","8a377ee2":"code","1502bfdd":"code","d6623227":"code","2e2e8735":"code","703a5029":"code","3d0c27c3":"code","f5e89eb4":"code","ca1f0b90":"code","5a643901":"code","59055f51":"code","75244a9c":"code","a2e0c280":"code","3f78adfc":"code","06a41779":"code","c1a24eab":"code","6ef7be98":"code","5bc75b7e":"code","97fa854a":"code","e87e8427":"code","e89b9565":"code","04d1c8e1":"code","6343015f":"code","4834e44a":"code","db7e300f":"code","7a3765db":"code","35c03df2":"code","1626bc80":"code","d35b2697":"markdown","fe8fa802":"markdown","47b1a7dc":"markdown","2575dff3":"markdown","ac768fd1":"markdown","ccfacf3f":"markdown","5b6ae269":"markdown","e1fcada9":"markdown","e94b9179":"markdown","65dfa5f3":"markdown","2433460e":"markdown","a6238864":"markdown","2ec7fa8b":"markdown","e66c0c85":"markdown","9ff391bb":"markdown","67c55223":"markdown","5ad46a93":"markdown","f94c5264":"markdown","60d37a3f":"markdown","4aa4320a":"markdown","769f1b34":"markdown","eb366bd5":"markdown","a34ed290":"markdown","3780bdfd":"markdown","068165c0":"markdown","455d3b92":"markdown","71b1c9fb":"markdown","1ff8ba66":"markdown","7d6b91a1":"markdown"},"source":{"c3a79200":"!pip install requests","698223eb":"pip install ruptures","5a4b33e8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nimport scipy.fftpack\nfrom scipy.fft import fft, fftfreq\nimport ruptures as rpt\n\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.tree import export_graphviz\nfrom sklearn.utils import shuffle\n\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nimport matplotlib.cm as cm\n\nfrom subprocess import call\nfrom IPython.display import Image\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers.normalization import BatchNormalization\nfrom keras import backend\n\nimport tensorflow as tf","0e93754d":"#S6 Edge\ns6blue1=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/S6edge - Blue0.csv')\ns6blue2=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/S6edge - Blue1.csv')\ns6blue3=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/S6edge - Blue2.csv')\ns6blue4=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/S6edge - Blue3.csv')\ns6blue5=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/S6edge - Blue4.csv')\ns6blue6=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/S6edge - Blue5.csv')\ns6blue7=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/S6edge - Blue6.csv')\ns6blue8=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/S6edge - Blue7.csv')\ns6blue9=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/S6edge - Blue8.csv')\ns6blue10=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/S6edge - Blue9.csv')\nframes=[s6blue1,s6blue2,s6blue3,s6blue4,s6blue5,s6blue6,s6blue7,s6blue8,s6blue9,s6blue10]\nbukitPanjangToExpo_s6edge=pd.concat(frames)\n\n#iPhone\niphoneblue1=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/iphoneblue1.csv')\niphoneblue2=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/iphoneblue2.csv')\niphoneblue3=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/iphoneblue3.csv')\niphoneblue4=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/iphoneblue4.csv')\niphoneblue5=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/iphoneblue5.csv')\niphoneblue6=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/iphoneblue6.csv')\niphoneblue7=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/iphoneblue7.csv')\nframes=[iphoneblue1,iphoneblue2,iphoneblue3,iphoneblue4,iphoneblue5,iphoneblue6,iphoneblue7]\nbukitPanjangToExpo_iphone12pro=pd.concat(frames)","ae9a3e82":"#S6 Edge\nwoodlandNorthToWoodlandSouth_s6edge=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/S6edge - Brown1.csv')\n\n#iPhone 12 Pro\nwoodlandNorthToWoodlandSouth_iphone12pro=pd.read_csv('..\/input\/singapore-underground-mobility-sensing-data\/iphone12_brown.csv')","9274f743":"#Import all functions from github\nimport requests\nurl='https:\/\/raw.githubusercontent.com\/kaiyang7766\/ExploratoryDataAnalysis\/main\/Load_Data\/LoadFunctions_old.py'\nr=requests.get(url)\nwith open('LoadFunctions_old.py','w') as f:\n    f.write(r.text)\n\nfrom LoadFunctions_old import *","c0e5e5fa":"#All underground station names\nDT_Stations = ['DT1_Bukit_Panjang', 'DT2_Cashew', 'DT3_Hillview','DT5_Beauty_World', 'DT6_King_Albert_Park', 'DT7_Sixth_Avenue', 'DT8_Tan_Kah_Kee', 'DT9_Botanic_Gardens', 'DT10_Stevens','DT11_Newton','DT12_Little_India','DT13_Rochor','DT14_Bugis', 'DT15_Promenade','DT16_Bayfront','DT17_Downtown','DT18_Telok Ayer','DT19_Chinatown','DT20_Fort_Canning','DT21_Bencoolen','DT22_Jalan_Besar','DT23_Bendemeer','DT24_Geylang_Bahru','DT25_Mattar','DT26_MacPherson','DT27_Ubi','DT28_Kaki_Bukit','DT29_Bedok_North','DT30_Bedok_Reservoir','DT31_Tampines_West','DT32_Tampines','DT33_Tempines_East','DT34_Upper_Changi','DT35_Expo']\nTE_Stations=['TE1_Woodlands_North','TE2_Woodlands','TE3_Woodlands_South']","2f2ff3da":"bukitPanjangToExpo_s6edge=datapreparation(bukitPanjangToExpo_s6edge, '2020-12-25 09:17:00.000','2020-12-25 10:23:51.000', resize=15, neednormalizepressure = True)\nbukitPanjangToExpo_iphone12pro=datapreparation(bukitPanjangToExpo_iphone12pro,'2020-12-25 09:16:50.000','2020-12-25 10:26:19.000',resize=1, neednormalizepressure = False)\nwoodlandNorthToWoodlandSouth_s6edge=datapreparation(woodlandNorthToWoodlandSouth_s6edge, '2020-12-25 08:23:27.000','2020-12-25 08:30:00.000', resize=9, neednormalizepressure = True)\nwoodlandNorthToWoodlandSouth_iphone12pro=datapreparation(woodlandNorthToWoodlandSouth_iphone12pro, '2020-12-25 08:23:01.000','2020-12-25 08:30:00.000',resize=1, neednormalizepressure = False)","eb99ebb7":"bukitPanjangToExpo_s6edge","58291ec9":"bukitPanjangToExpo_iphone12pro","ba5aefbf":"woodlandNorthToWoodlandSouth_s6edge","49c75a20":"woodlandNorthToWoodlandSouth_iphone12pro","93f9fe1a":"bukitPanjangToExpo_s6edge.info()","bcf7d159":"bukitPanjangToExpo_iphone12pro.describe()","ba23622c":"woodlandNorthToWoodlandSouth_s6edge.describe()","19e86255":"woodlandNorthToWoodlandSouth_iphone12pro.describe()","1478c6ad":"visualisation(bukitPanjangToExpo_s6edge,bukitPanjangToExpo_iphone12pro,'Downtown line on S6 Edge and iPhone 12 Pro')","b6bf653e":"visualisation(woodlandNorthToWoodlandSouth_s6edge,woodlandNorthToWoodlandSouth_iphone12pro,'Thomsom-East Coast Line (Brown) on S6 Edge and iPhone 12 Pro')","2ca03b3f":"def totalvisualization(data):\n    data_idle=data[~data.Mode.str.contains('MRT')]\n    data_mrt=data[~data.Mode.str.contains('Idle')]\n    plt.figure(figsize=(20,72))\n    for i, col in enumerate(['Acc_Lin_X', 'Acc_Lin_Y', 'Acc_Lin_Z', 'Acc_X', 'Acc_Y','Acc_Z', 'Bar_Pressure', 'Gyr_X', 'Gyr_Y', 'Gyr_Z','Loc_Altitude', 'Loc_Latitude', 'Loc_Longitude', 'Mag_X', 'Mag_Y','Mag_Z'],start=1):\n        plt.subplot(8,2,i)\n        plt.plot(data_mrt['Cleaned_Time'],data_mrt[col],'.y',label='MRT')\n        plt.plot(data_idle['Cleaned_Time'],data_idle[col],'.b',label='Idle')\n        plt.legend()\n        plt.xlabel('Time (s)')\n        plt.title(col)\n        #plt.show()","827a6fe9":"totalvisualization(bukitPanjangToExpo_s6edge)","fd0bafb4":"totalvisualization(bukitPanjangToExpo_iphone12pro)","bc6f3996":"totalvisualization(woodlandNorthToWoodlandSouth_s6edge)","19880a99":"totalvisualization(woodlandNorthToWoodlandSouth_iphone12pro)","4f99e2ec":"DT_iphone12pro=bukitPanjangToExpo_iphone12pro\nDT_s6edge=bukitPanjangToExpo_s6edge","5204dc18":"DT_iphone12pro_temp = errorRemovingPipeline(DT_iphone12pro)\nDT_iphone12pro_keyvalues = appendStation(DT_iphone12pro_temp,DT_Stations)\nDT_iphone12pro = modifyColumnStation(DT_iphone12pro,DT_iphone12pro_keyvalues)","837fb3be":"dropmoving=DT_iphone12pro.loc[DT_iphone12pro['Station']=='Moving']\nDT_iphone12pro.drop(DT_iphone12pro.index[list(dropmoving.index)],inplace=True)","069f70e1":"DT_iphone12pro['Station'].value_counts()","f88559df":"features = ['Mode', 'Acc_Lin_X', 'Acc_Lin_Y', 'Acc_Lin_Z', \n            'Acc_X', 'Acc_Y', 'Acc_Z', 'Bar_Pressure', \n            'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Mag_X', 'Mag_Y', 'Mag_Z','Station']\n\nMRT_data_iphone = [DT_iphone12pro[features]]\n\nmrt_data_iphone = pd.concat(MRT_data_iphone)\nmrt_data_iphone.reset_index(inplace=True)\nmrt_data_iphone = mrt_data_iphone.drop('index', axis=1)\n\n# Fill in 0 for all Null values EXCEPT locations columns (Loc_Altitude, Loc_Latitude, Loc_Longitude)\nfor i in features:\n    mrt_data_iphone[i].fillna(0, inplace=True)\n\nprint(mrt_data_iphone['Mode'].unique())","a49302ac":"# Omit the 'Mode' column\nmrt_data_features_iphone = mrt_data_iphone[[ 'Acc_Z', 'Bar_Pressure','Mag_X', 'Acc_Y', 'Mag_Z']]\n\n# The ground truth\nmrt_data_mode_iphone = mrt_data_iphone['Station']\n\n# Normalize the feature values\nmrt_data_features_normalized_iphone=(mrt_data_features_iphone-mrt_data_features_iphone.mean())\/mrt_data_features_iphone.std()","8c087c6f":"X_train_iphone, X_test_iphone, y_train_iphone, y_test_iphone = train_test_split(mrt_data_features_normalized_iphone, mrt_data_mode_iphone, test_size=0.3)","e4b05558":"DT_s6edge_temp = errorRemovingPipeline(DT_s6edge)\nDT_s6edge_keyvalues = appendStation(DT_s6edge_temp,DT_Stations)\nDT_s6edge = modifyColumnStation(DT_s6edge,DT_s6edge_keyvalues)","671b5721":"dropmoving=DT_s6edge.loc[DT_s6edge['Station']=='Moving']\nDT_s6edge.drop(DT_s6edge.index[list(dropmoving.index)],inplace=True)","61b0a3d0":"DT_s6edge['Station'].value_counts()","fe9c8b2e":"features = ['Mode', 'Acc_Lin_X', 'Acc_Lin_Y', 'Acc_Lin_Z', \n            'Acc_X', 'Acc_Y', 'Acc_Z', 'Bar_Pressure', \n            'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Mag_X', 'Mag_Y', 'Mag_Z','Station']\n\nMRT_data = [DT_s6edge[features]]\n\nmrt_data = pd.concat(MRT_data)\nmrt_data.reset_index(inplace=True)\nmrt_data = mrt_data.drop('index', axis=1)\n\n# Fill in 0 for all Null values EXCEPT locations columns (Loc_Altitude, Loc_Latitude, Loc_Longitude)\nfor i in features:\n    mrt_data[i].fillna(0, inplace=True)\n\n# Find out the null values inside the dataframe\n#to_drop_walking = mrt_data.loc[mrt_data['Mode'] == 'Walking']\n#to_drop_pmd = mrt_data.loc[mrt_data['Mode'] == 'PMD']\n#mrt_data.drop(mrt_data.index[list(to_drop_walking.index)], inplace = True)\n#mrt_data.drop(mrt_data.index[list(to_drop_pmd.index)], inplace = True)\n\nprint(mrt_data['Mode'].unique())","f3d6a11b":"mrt_data_features = mrt_data[[ 'Acc_Z', 'Bar_Pressure','Mag_X', 'Acc_Y', 'Mag_Z']]\n\n# The ground truth\nmrt_data_mode = mrt_data['Station']\n\n# Normalize the feature values\nmrt_data_features_normalized=(mrt_data_features-mrt_data_features.mean())\/mrt_data_features.std()","6bce35e4":"X_train_s6edge, X_test_s6edge, y_train_s6edge, y_test_s6edge = train_test_split(mrt_data_features_normalized, mrt_data_mode, test_size=0.3)","0d2b208f":"# Omit the 'Mode' column\nmrt_data_features = mrt_data_iphone[[ 'Acc_X', 'Acc_Y', 'Acc_Z', 'Bar_Pressure', \n                              'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Mag_X', 'Mag_Y', 'Mag_Z']]\n\n# The ground truth\nmrt_data_mode = mrt_data_iphone['Mode']\n\n# Normalize the feature values\nmrt_data_features_normalized=(mrt_data_features-mrt_data_features.mean())\/mrt_data_features.std()\n\n# Split the data to train and test sets\nX_train, X_test, y_train, y_test = train_test_split(mrt_data_features_normalized, mrt_data_mode, test_size=0.3)\n\nRFC    = RandomForestClassifier(n_estimators=10, max_depth=50)\n\nRFC.fit(X_train, y_train)\n\nrfc_predict  = RFC.predict(X_test)\n\n# Confusion matrix\nprint(\"=== Confusion Matrix ===\")\nprint(confusion_matrix(y_test, rfc_predict))\nprint('\\n')\n\n# Classification Report\nprint(\"=== Classification Report ===\")\nprint(classification_report(y_test, rfc_predict))\nprint('\\n')","c885fb65":"# Plots the Feature Importance Tree #\n\nestimator = RFC.estimators_[1]\n\nexport_graphviz(estimator, out_file='tree.dot', \n                feature_names = list(mrt_data_features.columns),\n                class_names = mrt_data['Mode'].unique(),\n                rounded = True, proportion = False, \n                precision = 2, filled = True)\n\nfrom subprocess import call\ncall(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n\n# Display in jupyter notebook\nfrom IPython.display import Image\nImage(filename = 'tree.png')","20a53e8e":"#Correlation Matrix#\n\ncorr_data = mrt_data_features.corr()\nf, ax = plt.subplots(figsize=(10, 10))\nax = sb.heatmap(corr_data, square=True, annot=True)","a8cc4afe":"from sklearn.inspection import permutation_importance\nresult = permutation_importance(RFC, X_train, y_train, n_repeats=10,\n                                random_state=42)\nperm_sorted_idx = result.importances_mean.argsort()\n\ntree_importance_sorted_idx = np.argsort(RFC.feature_importances_)\ntree_indices = np.arange(0, len(RFC.feature_importances_)) + 0.5\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n\nax1.barh(tree_indices,\n         RFC.feature_importances_[tree_importance_sorted_idx], height=0.7)\nax1.set_yticklabels(np.array(mrt_data_features.columns)[tree_importance_sorted_idx])\nax1.set_yticks(tree_indices)\nax1.set_ylim((0, len(RFC.feature_importances_)))\nax2.boxplot(result.importances[perm_sorted_idx].T, vert=False,\n            labels=np.array(mrt_data_features.columns)[perm_sorted_idx])\nfig.tight_layout()\nplt.show()","8aab5086":"# Dendrogram to denote feature importance through permutation matrix\n\nfrom scipy.stats import spearmanr\nfrom scipy.cluster import hierarchy\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\ncorr = spearmanr(mrt_data_features).correlation\ncorr_linkage = hierarchy.ward(corr)\ndendro = hierarchy.dendrogram(\n    corr_linkage, labels=mrt_data_features.columns, ax=ax1, leaf_rotation=90\n)\ndendro_idx = np.arange(0, len(dendro['ivl']))\n\nax2.imshow(corr[dendro['leaves'], :][:, dendro['leaves']])\nax2.set_xticks(dendro_idx)\nax2.set_yticks(dendro_idx)\nax2.set_xticklabels(dendro['ivl'], rotation='vertical')\nax2.set_yticklabels(dendro['ivl'])\nfig.tight_layout()\nplt.show()","fc5cf7b5":"from collections import defaultdict\n\ncluster_ids = hierarchy.fcluster(corr_linkage, 1, criterion='distance')\ncluster_id_to_feature_ids = defaultdict(list)\nfor idx, cluster_id in enumerate(cluster_ids):\n    cluster_id_to_feature_ids[cluster_id].append(idx)\nselected_features = [v[0] for v in cluster_id_to_feature_ids.values()]\n\nX_train_sel = X_train.iloc[:, selected_features]\nX_test_sel = X_test.iloc[:, selected_features]\n\nclf_sel = RandomForestClassifier(n_estimators=100, random_state=42)\nclf_sel.fit(X_train_sel, y_train)\nprint(\"Accuracy on test data with features removed: {:.2f}\".format(\n      clf_sel.score(X_test_sel, y_test)))","f02fa14e":"print(selected_features)\nprint(mrt_data_features.columns[selected_features])\nprint(mrt_data_features[mrt_data_features.columns[selected_features]])","1feeb3b7":"from sklearn.model_selection import KFold\nkf = KFold(shuffle=True, n_splits=5)\n\naccuracy_kfold = cross_val_score(RFC, mrt_data_features[mrt_data_features.columns[selected_features]], mrt_data_mode, cv=kf, scoring='accuracy')\nmacro_avg_kfold = cross_val_score(RFC, mrt_data_features[mrt_data_features.columns[selected_features]], mrt_data_mode, cv=kf, scoring='f1_macro')\nweight_avg_kfold = cross_val_score(RFC, mrt_data_features[mrt_data_features.columns[selected_features]], mrt_data_mode, cv=kf, scoring='f1_weighted')","fba20f96":"print(\"The Accuracy of the 5-fold cross validation are            :\" + str(accuracy_kfold))\nprint(\"The F1 Macro Average of the 5-fold cross validation are    :\" + str(macro_avg_kfold))\nprint(\"The F1 Weighted Average of the 5-fold cross validation are :\" + str(weight_avg_kfold))","8a377ee2":"param_grid = {\n    'max_depth': [20, 30, 40, 50],\n    'n_estimators': [10, 20, 30, 40, 50]\n}\n\nrf = RandomForestClassifier()\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                          cv = 5, verbose = 2)\n\n# Fit the grid search to the data\ngrid_search.fit(X_train_sel, y_train)\n","1502bfdd":"best_grid = grid_search.best_estimator_\nbest_score = grid_search.best_score_\nprint(best_grid)\nprint()\nprint(best_score)","d6623227":"# We create a function that automatically trains the data using the input as the selected features\ndef random_forest(features):\n    features_list = features.split(', ')\n\n    global mrt_data\n    mrt_data_features = mrt_data[features_list]\n    mrt_data_mode = mrt_data['Mode']\n    mrt_data_features_normalized=(mrt_data_features-mrt_data_features.mean())\/mrt_data_features.std()\n\n    # Split the data to train and test sets, 57846 for train, 14462 for test\n    X_train, X_test, y_train, y_test = train_test_split(mrt_data_features_normalized, mrt_data_mode, test_size=0.3)\n\n    RFC    = RandomForestClassifier()\n    RFC.fit(X_train, y_train)\n\n    rfc_predict  = RFC.predict(X_test)\n\n    # Confusion matrix\n    print(\"=== Confusion Matrix of \" + str(features) + \" ===\")\n    print(confusion_matrix(y_test, rfc_predict))\n    print('\\n')\n\n    # Classification Report\n    print(\"=== Classification Report of \" + str(features) + \" ===\")\n    print(classification_report(y_test, rfc_predict))\n    print('\\n')\n    print('\\n')","2e2e8735":"random_forest('Bar_Pressure')\nrandom_forest('Acc_Z')\nrandom_forest('Gyr_Z')\nrandom_forest('Mag_Z')","703a5029":"RFC    = RandomForestClassifier(n_estimators=10, max_depth=50)","3d0c27c3":"RFC.fit(X_train_iphone, y_train_iphone)\n\nrfc_predict  = RFC.predict(X_test_iphone)\n\n# Confusion matrix\nprint(\"=== Confusion Matrix ===\")\nprint(confusion_matrix(y_test_iphone, rfc_predict))\nprint('\\n')\n\n# Classification Report\nprint(\"=== Classification Report ===\")\nprint(classification_report(y_test_iphone, rfc_predict))\nprint('\\n')","f5e89eb4":"rfc_predict  = RFC.predict(X_test_s6edge)\n\n# Confusion matrix\nprint(\"=== Confusion Matrix ===\")\nprint(confusion_matrix(y_test_s6edge, rfc_predict))\nprint('\\n')\n\n# Classification Report\nprint(\"=== Classification Report ===\")\nprint(classification_report(y_test_s6edge, rfc_predict))\nprint('\\n')","ca1f0b90":"RFC.fit(X_train_s6edge, y_train_s6edge)\n\nrfc_predict  = RFC.predict(X_test_s6edge)\n\n# Confusion matrix\nprint(\"=== Confusion Matrix ===\")\nprint(confusion_matrix(y_test_s6edge, rfc_predict))\nprint('\\n')\n\n# Classification Report\nprint(\"=== Classification Report ===\")\nprint(classification_report(y_test_s6edge, rfc_predict))\nprint('\\n')","5a643901":"rfc_predict  = RFC.predict(X_test_iphone)\n\n# Confusion matrix\nprint(\"=== Confusion Matrix ===\")\nprint(confusion_matrix(y_test_iphone, rfc_predict))\nprint('\\n')\n\n# Classification Report\nprint(\"=== Classification Report ===\")\nprint(classification_report(y_test_iphone, rfc_predict))\nprint('\\n')","59055f51":"features = ['Mode', 'Acc_Lin_X', 'Acc_Lin_Y', 'Acc_Lin_Z', \n            'Acc_X', 'Acc_Y', 'Acc_Z', 'Bar_Pressure', \n            'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Mag_X', 'Mag_Y', 'Mag_Z','Station']\n\nMRT_data_iphone = [DT_iphone12pro[features]]\n\nmrt_data_iphone = pd.concat(MRT_data_iphone)\nmrt_data_iphone.reset_index(inplace=True)\nmrt_data_iphone = mrt_data_iphone.drop('index', axis=1)\n\nMRT_data_s6edge = [DT_s6edge[features]]\n\nmrt_data_s6edge = pd.concat(MRT_data_s6edge)\nmrt_data_s6edge.reset_index(inplace=True)\nmrt_data_s6edge = mrt_data_s6edge.drop('index', axis=1)\nfor i in features:\n    mrt_data_iphone[i].fillna(0, inplace=True) #can try fill with mean?\n    mrt_data_s6edge[i].fillna(0, inplace=True)\n\nmrt_data_features_iphone = mrt_data_iphone[[ 'Acc_Lin_X', 'Acc_Lin_Y', 'Acc_Lin_Z', \n            'Acc_X', 'Acc_Y', 'Acc_Z', 'Bar_Pressure', \n            'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Mag_X', 'Mag_Y', 'Mag_Z']]\nmrt_data_features_s6edge = mrt_data_s6edge[[ 'Acc_Lin_X', 'Acc_Lin_Y', 'Acc_Lin_Z', \n            'Acc_X', 'Acc_Y', 'Acc_Z', 'Bar_Pressure', \n            'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Mag_X', 'Mag_Y', 'Mag_Z']]\ncombined_data=pd.concat([mrt_data_features_iphone,mrt_data_features_s6edge])\nmrt_data_combined=pd.concat([DT_iphone12pro,DT_s6edge])","75244a9c":"from sklearn.preprocessing import StandardScaler\n# standardizing the data\nscaler = StandardScaler()\ndata_scaled = scaler.fit_transform(combined_data)\n\n# statistics of scaled data\npd.DataFrame(data_scaled).describe()","a2e0c280":"from sklearn.metrics import silhouette_samples, silhouette_score\nimport matplotlib.cm as cm\nfrom sklearn.cluster import KMeans","3f78adfc":"def silhouetteAnalysis(data):\n  '''get silhouette scores to know the number of clusters to be used'''\n  '''used only the dataset with numerical variables as input parameter'''\n  range_n_clusters = [2, 3, 4, 5, 6]\n  for n_clusters in range_n_clusters:\n      # Create a subplot with 1 row and 2 columns\n      fig, (ax1, ax2) = plt.subplots(1, 2)\n      fig.set_size_inches(18, 7)\n\n      # The 1st subplot is the silhouette plot\n      # The silhouette coefficient can range from -1, 1 but in this example all\n      # lie within [-0.1, 1]\n      ax1.set_xlim([-0.1, 1])\n      # The (n_clusters+1)*10 is for inserting blank space between silhouette\n      # plots of individual clusters, to demarcate them clearly.\n      ax1.set_ylim([0, len(data) + (n_clusters + 1) * 10])\n\n      # Initialize the clusterer with n_clusters value and a random generator\n      # seed of 10 for reproducibility.\n      clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n      cluster_labels = clusterer.fit_predict(data)\n\n      # The silhouette_score gives the average value for all the samples.\n      # This gives a perspective into the density and separation of the formed\n      # clusters\n      silhouette_avg = silhouette_score(data, cluster_labels)\n      print(\"For n_clusters =\", n_clusters,\n            \"The average silhouette_score is :\", silhouette_avg)\n\n      # Compute the silhouette scores for each sample\n      sample_silhouette_values = silhouette_samples(data, cluster_labels)\n\n      y_lower = 10\n      for i in range(n_clusters):\n          # Aggregate the silhouette scores for samples belonging to\n          # cluster i, and sort them\n          ith_cluster_silhouette_values = \\\n              sample_silhouette_values[cluster_labels == i]\n\n          ith_cluster_silhouette_values.sort()\n\n          size_cluster_i = ith_cluster_silhouette_values.shape[0]\n          y_upper = y_lower + size_cluster_i\n\n          color = cm.nipy_spectral(float(i) \/ n_clusters)\n          ax1.fill_betweenx(np.arange(y_lower, y_upper),\n                            0, ith_cluster_silhouette_values,\n                            facecolor=color, edgecolor=color, alpha=0.7)\n\n          # Label the silhouette plots with their cluster numbers at the middle\n          ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n\n          # Compute the new y_lower for next plot\n          y_lower = y_upper + 10  # 10 for the 0 samples\n\n      ax1.set_title(\"The silhouette plot for the various clusters.\")\n      ax1.set_xlabel(\"The silhouette coefficient values\")\n      ax1.set_ylabel(\"Cluster label\")\n\n      # The vertical line for average silhouette score of all the values\n      ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n\n      ax1.set_yticks([])  # Clear the yaxis labels \/ ticks\n      ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n\n      # 2nd Plot showing the actual clusters formed\n      colors = cm.nipy_spectral(cluster_labels.astype(float) \/ n_clusters)\n      ax2.scatter(data[:, 0], data[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n                  c=colors, edgecolor='k')\n\n      # Labeling the clusters\n      centers = clusterer.cluster_centers_\n      # Draw white circles at cluster centers\n      ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n                  c=\"white\", alpha=1, s=200, edgecolor='k')\n\n      for i, c in enumerate(centers):\n          ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n                      s=50, edgecolor='k')\n\n      ax2.set_title(\"The visualization of the clustered data.\")\n      ax2.set_xlabel(\"Feature space for the 1st feature\")\n      ax2.set_ylabel(\"Feature space for the 2nd feature\")\n\n      plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n                    \"with n_clusters = %d\" % n_clusters),\n                  fontsize=14, fontweight='bold')\n\n  plt.show()","06a41779":"mrt_data_combined_features = mrt_data_combined[[ 'Acc_X', 'Acc_Y', 'Acc_Z', 'Bar_Pressure', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Mag_X', 'Mag_Y', 'Mag_Z']]\nmrt_data_combined_features\n\nfeatures2 = ['Acc_X', 'Acc_Y', 'Acc_Z', 'Bar_Pressure', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Mag_X', 'Mag_Y', 'Mag_Z']\n\nfor i in features2:\n    mrt_data_combined_features[i].fillna(0, inplace=True)\n\nmrt_data_combined_features\n\n#next step has to be array and no NaN","c1a24eab":"silhouetteAnalysis(mrt_data_combined_features.values)","6ef7be98":"# defining the kmeans function with initialization as k-means++\nkmeans = KMeans(n_clusters=2, init='k-means++')\n\n# fitting the k means algorithm on scaled data\nkmeans.fit(data_scaled)","5bc75b7e":"# k means using 5 clusters and k-means++ initialization\nkmeans = KMeans(n_jobs = -1, n_clusters = 3, init='k-means++')\nkmeans.fit(data_scaled)\npred = kmeans.predict(data_scaled)","97fa854a":"frame = pd.DataFrame(data_scaled)\nframe['cluster'] = pred\nframe['cluster'].value_counts()","e87e8427":"mrt_data_combined['category'] = pred","e89b9565":"group = mrt_data_combined.groupby('category')\n\noutput = group.apply(lambda x: x['Station'].unique())\n\nfor i in output:\n    print(i)","04d1c8e1":"group0_combined = mrt_data_combined[mrt_data_combined['category'] == 0]\ngroup1_combined = mrt_data_combined[mrt_data_combined['category'] == 1]\ngroup2_combined = mrt_data_combined[mrt_data_combined['category'] == 2]\n#group3_combined = mrt_data_combined[mrt_data_combined['category'] == 3]\nfor i in features:\n    group0_combined[i].fillna(0, inplace=True) #can try fill with mean?\n    group1_combined[i].fillna(0, inplace=True)\n    group2_combined[i].fillna(0, inplace=True)\n    #group3_combined[i].fillna(0, inplace=True)","6343015f":"def visualizationAfterClustering(data1, data2, data3, data4, data5, data6):\n  '''visualise the data for each numerical variables after clustering using different colours'''\n  '''if less than 6 clusters, put 'None' as parameter'''\n  plt.figure(figsize=(20,72))\n  for i, col in enumerate(['Acc_Lin_X', 'Acc_Lin_Y', 'Acc_Lin_Z', 'Acc_X', 'Acc_Y','Acc_Z', 'Bar_Pressure', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Mag_X', 'Mag_Y','Mag_Z'],start=1):\n    plt.subplot(8,2,i)\n    plt.plot(data1[col],'.y',label='Cluster 1')\n    if data2 is not None:\n      plt.plot(data2[col],'.r',label='Cluster 2')\n    if data3 is not None:\n      plt.plot(data3[col],'.g',label='Cluster 3')\n    if data4 is not None:\n      plt.plot(data4[col],'.b',label='Cluster 4')\n    if data5 is not None:\n      plt.plot(data5[col],'.c',label='Cluster 5')\n    if data6 is not None:\n      plt.plot(data6[col],'.m',label='Cluster 6')\n    plt.title(col)\n  plt.legend()\n  plt.xlabel('Time') #actually is the index count\n  plt.title(col)","4834e44a":"visualizationAfterClustering(group0_combined,group1_combined,group2_combined,None,None,None)","db7e300f":"RFC    = RandomForestClassifier(n_estimators=10, max_depth=50)\ndef randomforest_stationprediction_cluster(group):\n    cfeatures = group[[ 'Acc_Z', 'Bar_Pressure','Mag_X', 'Acc_Y', 'Mag_Z']]\n\n    # The ground truth\n    cmode = group['Station']\n\n    # Normalize the feature values\n    cfeatures_normalized=(cfeatures-cfeatures.mean())\/cfeatures.std()\n    \n    x_train, x_test, y_train, y_test = train_test_split(cfeatures_normalized, cmode, test_size=0.3)\n    \n    RFC.fit(x_train, y_train)\n\n    rfc_predict  = RFC.predict(x_test)\n\n    # Confusion matrix\n    print(\"=== Confusion Matrix ===\")\n    print(confusion_matrix(y_test, rfc_predict))\n    print('\\n')\n\n    # Classification Report\n    print(\"=== Classification Report ===\")\n    print(classification_report(y_test, rfc_predict))\n    print('\\n')","7a3765db":"randomforest_stationprediction_cluster(group0_combined)","35c03df2":"randomforest_stationprediction_cluster(group1_combined)","1626bc80":"randomforest_stationprediction_cluster(group2_combined)","d35b2697":"## Use s6edge to train the model, test on s6edge","fe8fa802":"## Thomson-East Coast Line","47b1a7dc":"## Use iphone to train the model, test on iphone","2575dff3":"## Downtown Line","ac768fd1":"# Clustering","ccfacf3f":"# Silhouette Scores\nThe silhouette ranges from \u22121 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. If most objects have a high value, then the clustering configuration is appropriate. If many points have a low or negative value, then the clustering configuration may have too many or too few clusters.","5b6ae269":"## Load Thomson-East Line from S6 Edge and iPhone 12 Pro","e1fcada9":"# Packages","e94b9179":"## Group 2","65dfa5f3":"# Exploratory Data Analysis","2433460e":"# Preparing data to build the model (Downtown line) + Appending stations","a6238864":"## Group 0","2ec7fa8b":"#### Permutation Matrix and Feature Selection\n","e66c0c85":"#### Feature Importance Ranking","9ff391bb":"# Visualisation of all variables","67c55223":"## Use iphone to train model, test on s6edge","5ad46a93":"# Data Visualisation","f94c5264":"## Use s6edge to train the model, test on iphone","60d37a3f":"#### Model Running ####","4aa4320a":"# Travel Mode Prediction","769f1b34":"## Load all Downtown data from S6 Edge and iPhone 12 Pro","eb366bd5":"### Random Forest ###","a34ed290":"## S6 Edge data","3780bdfd":"## iPhone data","068165c0":"# Direct Prediction","455d3b92":"# Prediction based on clusters","71b1c9fb":"## Group 1","1ff8ba66":"# Summary Statistics","7d6b91a1":"#### K-Fold Cross Validation & GridSearchCV ####"}}