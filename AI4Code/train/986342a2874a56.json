{"cell_type":{"c926e795":"code","6a5e10d4":"code","31ddc18f":"code","7d5ad10e":"code","50364baf":"code","4c22123f":"code","e076f1ab":"code","5e94bc71":"code","3b9e45c7":"code","55e08cdc":"code","c3af7cd4":"code","064abb81":"code","cb47e4b7":"code","91ce95c6":"code","41d8ba15":"code","04b026d4":"code","27bd7569":"code","6ce27b4f":"code","249dd562":"markdown","7e0e520b":"markdown","3e0f5453":"markdown","75e12599":"markdown","d019a6cd":"markdown","95c45391":"markdown","d2c5dd0b":"markdown","21af6899":"markdown","e2df1857":"markdown","a8d15281":"markdown","393438d5":"markdown","6bc41c74":"markdown","587e1328":"markdown","54c3ae52":"markdown","0ca7df7a":"markdown","7280247e":"markdown","aca543b0":"markdown","99fb4222":"markdown","f60a86fe":"markdown","25545556":"markdown","ce5bba57":"markdown","d6e96772":"markdown"},"source":{"c926e795":"# pandas and numpy\nimport pandas as pd\nimport numpy as np\nimport re\n\n# tokenizer and vectorizer\nfrom nltk.tokenize import TweetTokenizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer # for TFIDF vectorizer\n\n# sklearn utility\nfrom sklearn.model_selection import cross_val_score, train_test_split, KFold, GridSearchCV # calculate cross validation\n\n# models\nfrom sklearn.linear_model import LogisticRegression, Perceptron\nfrom sklearn.svm import LinearSVC\n\n# tokens filter\nfrom emoji import UNICODE_EMOJI\nfrom string import punctuation\n\npunctuation += ' \u30fb\u2018\u2019\u201c\u201d\u2026'\n\n# visualization\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\n%matplotlib inline","6a5e10d4":"import os\n\ndata_folder = '\/kaggle\/input\/fit5149-2020-s1\/data\/'\ntweet_xml = []\nfor dirname, _, filenames in os.walk(data_folder):\n    for filename in filenames:\n        if ('.xml' in filename) and ('MACOSX' not in filename):\n            tweet_xml.append(data_folder+filename)\n        \nlen(tweet_xml)","31ddc18f":"all_tweets = []\nall_user = []\nfor filename in tweet_xml:\n    # extract user id\n    pattern_id = \"(?<=data\/)(.+?)(?=.xml)\"\n    id_user = str(re.findall(pattern_id, filename, re.DOTALL)[0])\n    # extract tweets\n    input_xml = str(open(filename).read())\n    pattern = \"(?<=<document><!\\[CDATA\\[)(.+?)(?=]]><\/document>)\"\n    # append to list\n    content = re.findall(pattern, input_xml, re.DOTALL)\n    all_content = \" \".join(content)\n    #content.insert(0, id_user) \n    all_tweets.append((id_user,all_content))\n\ntweet_DF = pd.DataFrame(all_tweets) \ntweet_DF.rename(columns={ tweet_DF.columns[0]: \"id\" }, inplace = True) # rename first column\ntweet_DF.rename(columns={ tweet_DF.columns[1]: \"tweets\" }, inplace = True) # rename first column\ntweet_DF.head()","7d5ad10e":"#Class for Tokenization and tokens filtering\nclass CleanToken(object):\n    def __call__(self,doc):\n        token = []\n        for t in TweetTokenizer().tokenize(doc): # Tokenization\n            \n            # filter out unused tokens\n              #keep unichar emoji     take out punctuation and unichar and whitespace and all tokens containing http\n            if t in UNICODE_EMOJI or (t not in punctuation and len(t)>1 and t != '' and not('http' in t)):\n                token.append(t)\n        return token\n\n# vectorizer to generate TF-IDF features\nvectorizer = TfidfVectorizer(analyzer='word',input='content',\n                             lowercase=True, #lowercase the input\n                             min_df=3, # assign minimal document frequency\n                             ngram_range=(1,2), # allows unigram, bigram, trigram\n                             tokenizer=CleanToken(), # call defined tokenizer\n                             sublinear_tf=True # change TF calculation method\n                             ).fit(tweet_DF['tweets'])\n\nprint('number of tokens:')\nlen(vectorizer.get_feature_names())","50364baf":"train_raw = pd.read_csv(\"..\/input\/author-profiling-train-test\/train_labels.csv\")\ntrain_raw.gender = train_raw.gender.map({'male':1,'female':0}) # encode label variable\n\n# merge tweets from whole dataset\ntrain_raw = pd.merge(train_raw, tweet_DF, on='id', how='left')\ntrain_raw.head()","4c22123f":"submit_raw = pd.read_csv(\"..\/input\/author-profiling-train-test\/test.csv\")\nsubmit_raw.drop(columns=['language'], inplace = True) # drop unused language column\n\n# merge tweets from whole dataset\nsubmit_raw = pd.merge(submit_raw, tweet_DF, on='id', how='left')\nsubmit_raw.head()","e076f1ab":"# Prepare the predictor and target variables\nX = vectorizer.transform(train_raw.tweets)\nY = train_raw.gender.tolist()\n\n# testing predictors\nsubmit_x = vectorizer.transform(submit_raw.tweets)","5e94bc71":"# plot train label distribution\ntrain_raw.groupby('gender').tweets.count().plot.bar(ylim=0)\nplt.show()","3b9e45c7":"# sum each tokens' tfidf value grouped by gender\ngrouped = {gender:X[usersindex,:].sum(axis=0).tolist()[0] for gender, usersindex in train_raw.groupby('gender').groups.items()}\n\n# convert grouped dictionary to pandas dataframe using vectorizer tokens as index\ngrouped = pd.DataFrame(grouped, index=vectorizer.get_feature_names())\ngrouped['col'] = grouped.apply(lambda row: row[1] - row[0], axis = 1)\n\n# plot tfidf features\nfig, ax = plt.subplots(figsize=(20, 8)) # resize the figure\nccmap = LinearSegmentedColormap.from_list(\"\", [\"magenta\",\"violet\",\"blue\"]) # define color gradient\n\n# prepare tokens that will be added in the plot (gender representation tokens) \ntexts = grouped.loc[abs(grouped.col) > 4.5].reset_index()\n\n# plot texts and scatter plot\ntexts.apply(lambda row: ax.text(row[0],row[1],row['index']),axis = 1)\nax.scatter(grouped[0],grouped[1], c=grouped.col, s=5, cmap=ccmap)\nax.set_xlabel('Tokens Usage Frequency by Female')\nax.set_ylabel('Tokens Usage Frequency by Male')\n\nplt.show()","55e08cdc":"# Cross validation function \ndef model_CV(x_train, y_train, model, CV=10):\n    name = model.__class__.__name__\n    # splitting the folds\n    kfold = KFold(n_splits=CV, random_state=42, shuffle = True)\n    # get CV score\n    cv_results = cross_val_score(model, x_train, y_train, cv=CV, scoring='accuracy', verbose=1, n_jobs=-1)\n    accuracy = round(cv_results.mean(),5) # take the mean of all folds' score\n    std = round(cv_results.std(),5) # take the std of all folds' score\n    msg = \"%s: %f (%f)\" % (name, accuracy, std)\n    print(msg) # print model name, mean and std accuracy\n    return(accuracy,std) # return only the cv mean accuracy","c3af7cd4":"# Grid search function\ndef grid_hyper(model, train_x, train_y, param_grid, CV=10):\n    name = model.__class__.__name__\n    # prepare gridsearch model by given param grid\n    model_grid = GridSearchCV(model, param_grid, cv = CV, scoring='accuracy', verbose=1, n_jobs=-1)\n    # fit the gridseach model\n    model_grid.fit(train_x, train_y)\n    # calculate the score\n    score = round(model_grid.best_score_,5)\n    std = round(model_grid.cv_results_['std_test_score'][model_grid.best_index_],5)\n    msg = \"%s: %f (%f)\" % (name, score, std)\n    print(msg) # print base model name with gridsearch best score\n    return (model_grid, score, std) # return the model and score","064abb81":"validation_size = 0.10 # the percentage of validation set\nseed = 123 # seed for reproducibility\n\n# spliting training raw dataset to training and validation set\nX_train, X_val, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size, random_state=seed)","cb47e4b7":"# put all base model and its tuning parameter in one dataframe\nmodels = {'name':['LR',\n                  'LSVM',\n                  'PCR'\n                 ],\n          'base':[LogisticRegression(max_iter=5000),\n                  LinearSVC(max_iter=5000),\n                  Perceptron(max_iter=5000),\n                 ],\n          # all regularizations values are set to make model as linear as possible (minimized regularization)\n          'param':[{\"C\": [10**i for i in range(0,5)]},\n                   {\"C\": [10**i for i in range(0,5)]},\n                   {'alpha':[10**i for i in range(-4,1)]},\n                  ]\n         }\nmodels=pd.DataFrame(models)\nmodels.head()","91ce95c6":"# using pandas dataframe apply method, try all base models\nmodels['cv_score'] = models.apply(lambda model: model_CV(X_train,Y_train,model['base']),axis=1)\nmodels.head()","41d8ba15":"# using pandas apply method, call gridSearch function for every model\ngrid_result = models.apply(lambda model: grid_hyper(model['base'],X_train,Y_train,model['param']), axis=1)\n\n# save grid score and grid model to models dictionary\nmodels['grid_score'] = grid_result.apply(lambda grid: (grid[1], grid[2]))\nmodels['grid_best_params'] = grid_result.apply(lambda grid: grid[0].best_params_)\nmodels","04b026d4":"# fit all models with 90% training dataset and calculate model's score using 10% validation set\nmodels.apply(lambda model: model['base'].set_params(**model['grid_best_params']), axis=1) \\\n                             .apply(lambda model: model.fit(X_train, Y_train)) \\\n                             .apply(lambda model: model.score(X_val, Y_validation))","27bd7569":"# create final model using all training dataset to be used for exporting prediction\nmodels['finalModel'] = models.apply(lambda model: model['base'].set_params(**model['grid_best_params']), axis=1) \\\n                             .apply(lambda model: model.fit(X, Y))","6ce27b4f":"# reading the test label file (answer dataset)\nanswer_DF = pd.read_csv(\"..\/input\/author-profiling-train-test\/test_labels.csv\")\nanswer_DF.gender = answer_DF.gender.apply(lambda gender: 1 if gender == 'male' else 0)\n\n# scoring all final models by predicting submit_raw tfidf and comparing the prediction with answer dataset\nmodels['finalModel'].apply(lambda model: model.score(submit_x, answer_DF.gender.tolist()))","249dd562":"# Part 1:  Introduction and Data Preparation\n\nNowadays with the increasing social media usage, more and more people are establishing their online presence or persona by creating and uploading digital contents which mostly are images and texts. This means that we can consider everyone is an author of their own online content, so that we can use online contents to reveal its author characteristics like age, location, personality, hobby or gender. For example, we can profile someone using their twitter posting which showing their authorship style choices. The authorship profiling analysis is one of classification problem in machine learning which trains classification model (classifier) to examines style of each individual author and predict the corresponding author characteristic as its target variable.\n\nThis competition\/assignment allows us to carry our author analysis to predict gender of twitter users based on their set of tweets. For author profiling, Rangel, et al proved that classifier models using tf-idf weighted n-gram features have shown a remarkable result to classify authors\u2019 profile especially for gender prediction. In this paper, we try to report our analysis on datasets given in the competition\/assignment and show how we build and choose our final submitted classifier using tf-idf weighted n-gram features.","7e0e520b":"On predicting validation dataset, all models show an increasing performance with perceptron as the best performing model. All those increases are still in their 95% confident estimation range (1.96 * std) which means that all models can generalized well on unseen data and we can expect to get a similar accoracy score when we predicting test dataset.","3e0f5453":"# Part 2 : Exploratory Data Analysis\n## 2.1 Distribution of Target Variable","75e12599":"Construct dataframe","d019a6cd":"## 2.2 Distribution of Features Generated (TF-IDF) ","95c45391":"### 1.4 Read Training and Testing (Submission) Datasets\nread both datasets and merge them with each user's tfidf features","d2c5dd0b":"### Check All Tuned Model using Validation Dataset","21af6899":"# Part 3: Model Development\n## 3.1 Auxilliary Functions for Model Development","e2df1857":"from cv score, we can see that LSVM is the best scored model with the lowest variance of CV scores.\n\n### Tuning each model hyper parameter (defined in model's params)","a8d15281":"### Cross validate each base model","393438d5":"## 1.2 Read tweets files\n\nRead the train and test tweets files into dataframe.","6bc41c74":"## 3.3 Model Development","587e1328":"The target variable has a balance distribution on each class, so no need to do over or under sampling method to make it balance. ","54c3ae52":"### Calculate All Final Models' Accuracy with Testing Dataset (answer dataset)","0ca7df7a":"### Fit Final Models with all train dataset","7280247e":"As we predicted, we get a similar level of accuracy score. All models' performance is still inside their confident interval range with LR model as the best performing model.","aca543b0":"The tokens plotting shows a linear kind of scatted data, so we will try linear model as our classifiers","99fb4222":"## 3.2 Train-Val split\nuse 10% of training dataset as validation data","f60a86fe":"# FIT5149 S1 2020 Assessment 2: Authorship Profiling\n## Group 19 - eidmubarak\n\n### Member:\n\n##### Ade Satya Wahana - 30350832\nawah0002@student.monash.edu\n\n##### Anita Rohmawati- 29641292\naroh0002@student.monash.edu\n\n##### Arya Lintang Sakethi - 30303109\nasak0007@student.monash.edu\n\n=======================================================","25545556":"## 1.1 Import Required Packages","ce5bba57":"## 1.3 Features Engineering\nTokenization and TF-IDF Vectorization ","d6e96772":"LSVM is still the best model out of three linear models. Changing hyperparameter using grid search successfully increases LR and LSVM CV score but makes their performance more varied (bias-variance trade off)"}}