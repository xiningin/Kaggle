{"cell_type":{"a4edebde":"code","f124b3fe":"code","636a7039":"code","c3c1acb6":"code","5ea8bdf1":"code","1b554153":"code","9888649a":"code","64e05fd0":"code","92450e57":"code","6c3ac9fb":"code","feff9e47":"code","f4b665b8":"code","876e646b":"code","155b9318":"code","f059fa93":"code","f1d7f64b":"code","b1b40a8e":"code","b0e170bc":"code","29ee7299":"code","950b5019":"code","d2f4efe9":"code","1025d6fc":"code","714170d5":"code","e90fae76":"code","340726f8":"code","2a778771":"markdown"},"source":{"a4edebde":"# Importing the necessary libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sbn\nimport matplotlib.pyplot as plt\n","f124b3fe":"# Read the data\npharma_data = pd.read_csv('https:\/\/raw.githubusercontent.com\/dphi-official\/Datasets\/master\/pharma_data\/Training_set_begs.csv')","636a7039":"# Observing the first 5 rows of the dataframe\npharma_data.head()","c3c1acb6":"# Heatmap of Correlation matrix consisting of correlation coefficients between the predictors\nplt.figure(figsize=(16,10))\nsbn.set(font_scale=1.1)\nsbn.heatmap(pharma_data.corr(),annot=True,cmap=\"RdYlGn\")\nplt.show()","5ea8bdf1":"# Information on different columns of the dataset\npharma_data.info()","1b554153":"# Preprocessing for nominal categorical data (one hot encoding)\npharma_data_cat_conv=pd.get_dummies(pharma_data, columns=[\"Treated_with_drugs\",\"Patient_Smoker\",\"Patient_Rural_Urban\",\"Patient_mental_condition\"])\npharma_data_cat_conv.info()","9888649a":"# Preprocessing for categorical data which are already 1 hot coded (replacing missing values by the most frequent value)\npharma_data_cat_conv['A'].fillna(pharma_data_cat_conv['A'].mode()[0],inplace=True)\npharma_data_cat_conv['B'].fillna(pharma_data_cat_conv['B'].mode()[0],inplace=True)\npharma_data_cat_conv['C'].fillna(pharma_data_cat_conv['C'].mode()[0],inplace=True)\npharma_data_cat_conv['D'].fillna(pharma_data_cat_conv['D'].mode()[0],inplace=True)\npharma_data_cat_conv['E'].fillna(pharma_data_cat_conv['E'].mode()[0],inplace=True)\npharma_data_cat_conv['F'].fillna(pharma_data_cat_conv['F'].mode()[0],inplace=True)\npharma_data_cat_conv['Z'].fillna(pharma_data_cat_conv['Z'].mode()[0],inplace=True)\n\n\n","64e05fd0":"# Check whether any NaN exists \npharma_data_cat_conv.isna().sum()","92450e57":"# Separate targets from predictors\ny = pharma_data_cat_conv[['Survived_1_year']]  # target variable \nX = pharma_data_cat_conv.drop(['Survived_1_year'], axis=1)  # input variables","6c3ac9fb":"# Dropping the ids from the list of predictors as they don't have any impact on the target variable\nX=X.drop(['Patient_ID','ID_Patient_Care_Situation'], axis=1)\n","feff9e47":"# Dropping 'Number_of_prev_cond' from the list of predictors as this predictor is the sum of the values in A, B, C, D, E, F, Z. \nX=X.drop(['Number_of_prev_cond'], axis=1)\nX.head()","f4b665b8":"# Normalizing the predictors\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Fit scaler on the input variables\nnorm = MinMaxScaler().fit(X)\n\n# Transform the input variables\nX_norm = pd.DataFrame(norm.transform(X))\n\nX_norm.columns=X.columns","876e646b":"# Break off validation data from training data\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val =train_test_split(X_norm, y, \n                                                    test_size=0.2, \n                                                    random_state=1)","155b9318":"X_train.head()","f059fa93":"\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Define initial model. Specify a number for seed to ensure same results each run\nclf_lr = XGBClassifier(learning_rate =0.1,\nn_estimators=500,\nmax_depth=5,\nmin_child_weight=1,\ngamma=0,\nsubsample=0.8,\ncolsample_bytree=0.8,\nobjective= 'binary:logistic',\nnthread=4,\nscale_pos_weight=1,\nseed=1)\n\n# Define range of the parameters for optimization using RandomizedSearchCV\noptimization_dict = {\"boosting_type\": ['gbdt','dart'],\n\"n_estimators\"     : [200,500,800,1100,1400,1700,2000],\n\"learning_rate\"    : list(np.logspace(np.log10(0.005), np.log10(0.5), base = 10, num = 1000)) ,\n\"max_depth\"        : [3,5,7,9,11,13,15,17,19,21,23],\n'silent': [False],\n'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n'gamma': [0, 0.25, 0.5, 1.0],\n'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],\n'reg_alpha': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0]}\n\n\n# Define RandomizedSearchCV\nmodel = RandomizedSearchCV(clf_lr, optimization_dict, \n                     scoring='roc_auc', n_iter=10, verbose=1,n_jobs=4,iid=False, cv=2)\n\n# Fit RandomizedSearchCV model to training data\nlr_baseline_model = model.fit(X_train,y_train)\n\n","f1d7f64b":"lr_baseline_model.best_params_, lr_baseline_model.best_score_","b1b40a8e":"# Define model with optimized parameters\nmodel = XGBClassifier(**lr_baseline_model.best_params_,\n objective= 'binary:logistic',\n nthread=4,\n scale_pos_weight=1,\n random_state=1)\n\n# Fit optimized model\nlr_baseline_model_op = model.fit(X_train,y_train)\n\n# Predict validation set targets\ny_val_pred = lr_baseline_model_op.predict(X_val)\n\n# Predict training set targets\ny_train_pred=lr_baseline_model_op.predict(X_train)\n\n# Calculating evaluation metrics for train data and validation data\nfrom sklearn.metrics import accuracy_score,f1_score\nac_score = accuracy_score(y_val, y_val_pred)\nf_score = f1_score(y_val, y_val_pred)\nac_score_train = accuracy_score(y_train,y_train_pred)\nf_score_train = f1_score(y_train,y_train_pred)\n\n\nprint(\"Validation accuracy score:\", ac_score)\nprint(\"Validation F1 Score:\", f_score)\nprint(\"Train accuracy score:\", ac_score_train)\nprint(\"Train F1 Score:\", f_score_train)","b0e170bc":"# Read test data\ntest_new = pd.read_csv('https:\/\/raw.githubusercontent.com\/dphi-official\/Datasets\/master\/pharma_data\/Testing_set_begs.csv')\n","29ee7299":"# Check NaN values in Test data\ntest_new.isna().sum()","950b5019":"# Preprocessing for nominal categorical data (one hot encoding)\ntest_new=pd.get_dummies(test_new, columns=[\"Treated_with_drugs\",\"Patient_Smoker\",\"Patient_Rural_Urban\",\"Patient_mental_condition\"])\ntest_new.info()","d2f4efe9":"# test data does not have 'Cannot say' in 'Patient_Smoker' column. Therefore, during the one hot encoding of this column for test data, 'Patient_Smoker_Cannot say' column is not created while it exists for train data. Hence, this column is created for test data with all values as 0\ntest_new.loc[:,'Patient_Smoker_Cannot say']=0","1025d6fc":"# Re-aaranging the test data columns to match with train data columns\ntest_new = test_new[['Diagnosed_Condition', 'Patient_Age', 'Patient_Body_Mass_Index', 'A',\n       'B', 'C', 'D', 'E', 'F', 'Z', 'Number_of_prev_cond',\n       'Treated_with_drugs_DX1 ', 'Treated_with_drugs_DX1 DX2 ',\n       'Treated_with_drugs_DX1 DX2 DX3 ',\n       'Treated_with_drugs_DX1 DX2 DX3 DX4 ',\n       'Treated_with_drugs_DX1 DX2 DX3 DX4 DX5 ',\n       'Treated_with_drugs_DX1 DX2 DX3 DX5 ',\n       'Treated_with_drugs_DX1 DX2 DX4 ',\n       'Treated_with_drugs_DX1 DX2 DX4 DX5 ',\n       'Treated_with_drugs_DX1 DX2 DX5 ', 'Treated_with_drugs_DX1 DX3 ',\n       'Treated_with_drugs_DX1 DX3 DX4 ',\n       'Treated_with_drugs_DX1 DX3 DX4 DX5 ',\n       'Treated_with_drugs_DX1 DX3 DX5 ', 'Treated_with_drugs_DX1 DX4 ',\n       'Treated_with_drugs_DX1 DX4 DX5 ', 'Treated_with_drugs_DX1 DX5 ',\n       'Treated_with_drugs_DX2 ', 'Treated_with_drugs_DX2 DX3 ',\n       'Treated_with_drugs_DX2 DX3 DX4 ',\n       'Treated_with_drugs_DX2 DX3 DX4 DX5 ',\n       'Treated_with_drugs_DX2 DX3 DX5 ', 'Treated_with_drugs_DX2 DX4 ',\n       'Treated_with_drugs_DX2 DX4 DX5 ', 'Treated_with_drugs_DX2 DX5 ',\n       'Treated_with_drugs_DX3 ', 'Treated_with_drugs_DX3 DX4 ',\n       'Treated_with_drugs_DX3 DX4 DX5 ', 'Treated_with_drugs_DX3 DX5 ',\n       'Treated_with_drugs_DX4 ', 'Treated_with_drugs_DX4 DX5 ',\n       'Treated_with_drugs_DX5 ', 'Treated_with_drugs_DX6','Patient_Smoker_Cannot say',\n       'Patient_Smoker_NO', 'Patient_Smoker_YES', 'Patient_Rural_Urban_RURAL',\n       'Patient_Rural_Urban_URBAN', 'Patient_mental_condition_Stable',\n       ]]","714170d5":"# Dropping 'Number_of_prev_cond' from the list of predictors in test data as this predictor is the sum of the values in A, B, C, D, E, F, Z and therefore not needed\ntest_new.drop('Number_of_prev_cond',axis=1,inplace=True)","e90fae76":"# Normalize the predictors in test data \ntest_new_norm = pd.DataFrame(norm.transform(test_new),columns=test_new.columns)","340726f8":"\n# Predicting the targets for test data\npreds_test= lr_baseline_model_op.predict(test_new_norm)\n\n\noutput = pd.DataFrame({'Id':test_new_norm.index,\n                       'Survived_1_year': preds_test})\noutput.to_csv('submission.csv', index=False)\n\n","2a778771":"**Objective**\n\nA hospital in the province of Greenland has been trying to improve its care conditions by looking at historic survival of the patients. They tried looking at their data but could not identify the main factors leading to high survivals.\n\nYou are the best data scientist in Greenland and they've hired you to solve this problem. Now you are responsible for developing a model that will predict the chances of survival of a patient after 1 year of treatment (Survived_1_year).\n\n**Target Data**\n\nThe dataset contains the patient records collected from a hospital in Greenland. The \"Survived_1_year\" column is a target variable which has binary entries (0 or 1).\n\n    Survived_1_year == 0, implies that the patient did not survive after 1 year of treatment\n    Survived_1_year == 1, implies that the patient survived after 1 year of treatment\n\n**Input Data:**\n\n    ID_Patient_Care_Situation: Care situation of a patient during treatment\n    Diagnosed_Condition: The diagnosed condition of the patient\n    ID_Patient: Patient identifier number\n    Treatment_with_drugs: Class of drugs used during treatment\n    Survived_1_year: If the patient survived after one year (0 means did not survive; 1 means survived)\n    Patient_Age: Age of the patient\n    Patient_Body_Mass_Index: A calculated value based on the patient\u2019s weight, height, etc.\n    Patient_Smoker: If the patient was a smoker or not\n    Patient_Rural_Urban: If the patient stayed in Rural or Urban part of the country\n    Previous_Condition: Condition of the patient before the start of the treatment ( This variable is splitted into 8 columns - A, B, C, D, E, F, Z and Number_of_prev_cond. A, B, C, D, E, F and Z are the previous conditions of the patient. Suppose for one patient, if the entry in column A is 1, it means that the previous condition of the patient was A. If the patient didn't have that condition, it is 0 and same for other conditions. If a patient has previous condition as A and C , columns A and C will have entries as 1 and 1 respectively while the other column B, D, E, F, Z will have entries 0, 0, 0, 0, 0 respectively. The column Number_of_prev_cond will have entry as 2 i.e. 1 + 0 + 1 + 0 + 0 + 0 + 0 + 0 = 2 in this case. )\n"}}