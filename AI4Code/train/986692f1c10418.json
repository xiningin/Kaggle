{"cell_type":{"0d753f1b":"code","c7e83abc":"code","3bd2b756":"code","64fcdb9e":"code","cb12f337":"code","41b210c6":"code","54bdc485":"code","bd14d4b1":"code","b1bc086b":"code","c8ba8c06":"code","8b117434":"code","fbbf1e39":"code","3b47b1ed":"code","2fed0389":"code","efc0e485":"code","5cf1b14d":"code","5e5eb0ff":"code","7a1786ca":"code","63d98fdf":"code","54f8ae8a":"code","726bab83":"code","3e3287d0":"code","b8b5e4c8":"code","027827fb":"code","fbdf6324":"code","7256e86a":"code","871a984e":"code","39e5a455":"markdown"},"source":{"0d753f1b":"import numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom scipy import stats\nimport glob\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nfrom glob import glob\nimport gc\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image,display\nimport seaborn as sns\nimport matplotlib.image as mpimg\nimport scipy.spatial.distance as dist\nfrom sklearn.model_selection import train_test_split\nimport os\nwarnings.filterwarnings('ignore')","c7e83abc":"train = pd.read_csv(\"..\/input\/happy-whale-and-dolphin\/train.csv\")\ntrain.head()","3bd2b756":"# Check for Duplicates\ntrain.duplicated().sum()","64fcdb9e":"print(\"Training data size\",train.shape)\nsubmission = pd.read_csv(\"..\/input\/happy-whale-and-dolphin\/sample_submission.csv\")\nsubmission.head()","cb12f337":"train['individual_id'].value_counts().hist()","41b210c6":"# missing data in training data \ntotal = train.isnull().sum().sort_values(ascending = False)\npercent = (train.isnull().sum()\/train.isnull().count()).sort_values(ascending = False)\nmissing_train_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_train_data.head()","54bdc485":"# Occurance of individual_id in decreasing order(Top categories)\ntemp = pd.DataFrame(train.individual_id.value_counts().head(8))\ntemp.reset_index(inplace=True)\ntemp.columns = ['individual_id','count']\ntemp","bd14d4b1":"wd = pd.DataFrame(train.groupby(['individual_id'])['individual_id'].count())\nwd.rename(columns={'individual_id': 'Count_Images'}, inplace=True)\nwd.reset_index(inplace=True)\nwd.sort_values(by=['Count_Images'],ascending=False, inplace=True)\nwd['Cummulative_Count'] = wd['Count_Images'].cumsum()\nwd['Cummulative_Pctg']= wd['Cummulative_Count']\/wd['Count_Images'].sum()\nwd['Row_id'] = np.arange(len(wd))\nfig = plt.figure()\nax = plt.axes()\nax.plot(wd['Row_id'], wd['Cummulative_Pctg']);\nax.set(xlabel='Count of Classes', ylabel='Cummulative %',\n       title='Cummulative distribution of images by class count');","b1bc086b":"print(\"Number of classes that contribute 95% of total images is: \"+ str(len(wd[wd['Cummulative_Pctg']<=0.95])))\nprint(\"Number of classes that contribute 99% of total images is: \"+ str(len(wd[wd['Cummulative_Pctg']<=0.99])))\nprint(str(train['individual_id'].nunique()- len(wd[wd['Cummulative_Pctg']<=0.99]))+ \" Classes contribute just about remaining 1% of images\")\nprint(\"Number of classes with just two images is:\"+ str(len(wd[wd['Count_Images']<=2])))","c8ba8c06":"# Plot the most frequent landmark_ids\nplt.figure(figsize = (9, 8))\nplt.title('Most frequent individual_id')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"individual_id\", y=\"count\", data=temp,\n            label=\"Count\")\nplt.show()","8b117434":"# Occurance of landmark_id in increasing order\ntemp = pd.DataFrame(train.individual_id.value_counts().tail(8))\ntemp.reset_index(inplace=True)\ntemp.columns = ['individual_id','count']\ntemp","fbbf1e39":"# Plot the least frequent landmark_ids\nplt.figure(figsize = (9, 8))\nplt.title('Least frequent individual_id')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"individual_id\", y=\"count\", data=temp,\n            label=\"Count\")\nplt.show()","3b47b1ed":"train.nunique()","2fed0389":"from collections import Counter\na = train['individual_id'].tolist()\nletter_counts = Counter(a)\ndf = pd.DataFrame.from_dict(letter_counts, orient='index')\ndf.plot(kind='bar')","efc0e485":"print(\"Number of classes under 20 occurences\",(train['individual_id'].value_counts() <= 20).sum(),'out of total number of categories',len(train['individual_id'].unique()))","5cf1b14d":"sns.set()\nplt.title('Training set: number of images per class(line plot)')\nsns.set_color_codes(\"pastel\")\nindividual_id = pd.DataFrame(train['individual_id'].value_counts())\nindividual_id.reset_index(inplace=True)\nindividual_id.columns = ['individual_id','count']\nax = individual_id['count'].plot(logy=True, grid=True)\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=30)\nax.set(xlabel=\"individual_id\", ylabel=\"Number of images\")","5e5eb0ff":"# Visualize outliers, min\/max or quantiles of the landmarks count\nsns.set()\nax = individual_id.boxplot(column='count')\nax.set_yscale('log')","7a1786ca":"mainPath = '..\/input\/happy-whale-and-dolphin\/train_images\/'\nall_img_paths = [y for x in os.walk(mainPath) for y in glob(os.path.join(x[0], '*.jpg'))]\nall_filenames = []\nfor filepath in all_img_paths:\n    FileName = os.path.basename(filepath)\n    all_filenames.append(FileName)\npath_dict = dict(zip(all_filenames,all_img_paths))","63d98fdf":"wd","54f8ae8a":"##Getting the list of ids where top 5 and bottom 5 categories\ntop5_cats = wd[wd['Row_id']<=4].individual_id.tolist()\nbottom5_cats = wd[wd['Row_id']>=(wd['Row_id'].max()-4)].individual_id.tolist()","726bab83":"print(\"Top 5 image categories are : \" + str(top5_cats))\nprint(\"Bottom 5 image categories are : \" + str(bottom5_cats))","3e3287d0":"train['image']=train['individual_id']+str(\".jpg\")","b8b5e4c8":"train","027827fb":"img0 = cv2.imread('..\/input\/happy-whale-and-dolphin\/train_images\/00021adfb725ed.jpg')\n\ntrain_hist = plt.hist(img0.ravel(), bins = 256, color = 'orange', )\ntrain_hist = plt.hist(img0[:, :, 0].ravel(), bins = 256, color = 'red', alpha = 0.5)\ntrain_hist = plt.hist(img0[:, :, 1].ravel(), bins = 256, color = 'Green', alpha = 0.5)\ntrain_hist = plt.hist(img0[:, :, 2].ravel(), bins = 256, color = 'Blue', alpha = 0.5)\ntrain_hist = plt.xlabel('Intensity Value')\ntrain_hist = plt.ylabel('Count')\ntrain_hist = plt.legend(['Total', 'Red Channel', 'Green Channel', 'Blue Channel'])\nprint('Intensity Histogram of Train Image')\nplt.show()","fbdf6324":"img1 = cv2.imread('..\/input\/happy-whale-and-dolphin\/test_images\/000110707af0ba.jpg')\n\ntest_hist = plt.hist(img1.ravel(), bins = 256, color = 'orange', )\ntest_hist = plt.hist(img1[:, :, 0].ravel(), bins = 256, color = 'red', alpha = 0.5)\ntest_hist = plt.hist(img1[:, :, 1].ravel(), bins = 256, color = 'Green', alpha = 0.5)\ntest_hist = plt.hist(img1[:, :, 2].ravel(), bins = 256, color = 'Blue', alpha = 0.5)\ntest_hist = plt.xlabel('Intensity Value')\ntest_hist = plt.ylabel('Count')\ntest_hist = plt.legend(['Total', 'Red Channel', 'Green Channel', 'Blue Channel'])\nprint('Intensity Histogram of Test Image')\nplt.show()","7256e86a":"train_list = glob('..\/input\/happy-whale-and-dolphin\/train_images\/*')","871a984e":"plt.rcParams[\"axes.grid\"] = False\nf, axarr = plt.subplots(4, 3, figsize=(24, 22))\n\ncurr_row = 0\nfor i in range(12):\n    example = cv2.imread(train_list[i])\n    example = example[:,:,::-1]\n    \n    col = i%4\n    axarr[col, curr_row].imshow(example)\n    if col == 3:\n        curr_row += 1","39e5a455":"![](https:\/\/blogger.googleusercontent.com\/img\/a\/AVvXsEjVBFVJg4z5YeCrBaFoTfJ7wcZxlFt9WrepKwOADEBtZe96pJI1KKryhjQupntMedLQgwOTdMTEHkyZm-LAHCrU7JD_1UNjoQdTGzvVe1-XVfA1rocSbCCmLfLqS7sm-_wKIsYwm5hW35RDF0wAhHYkL7MoWLM4QsowyQsNRAzb8xMaKhvgDVoMwH-b=s782)"}}