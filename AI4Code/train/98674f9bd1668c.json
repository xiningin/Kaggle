{"cell_type":{"471ec0ac":"code","1ce6cf01":"code","6bd3e1bb":"code","6a3a9f84":"code","620d4219":"code","8757f82a":"code","7ecda5cc":"code","ef51e080":"code","318bc8b0":"code","8f667d73":"code","7d91ddd2":"code","73352093":"code","c2ed732a":"code","17973a57":"code","9caf34c6":"code","840e4934":"code","7a79f46a":"code","0f75215a":"code","d2144eb2":"code","73dcebc1":"code","86029aa1":"code","75286bfc":"code","fa41fc83":"code","e20a3bfb":"code","856dfa0a":"code","2a3b767d":"code","f032fe6d":"code","a8eca024":"code","42cc1ba1":"code","d5183fe5":"code","0a0ab959":"code","14af2936":"markdown","187af3b9":"markdown","9a814142":"markdown","5d022305":"markdown","d958b9b5":"markdown","b25d5d8e":"markdown","c8287153":"markdown","fd19b050":"markdown","1cd6d7d4":"markdown"},"source":{"471ec0ac":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1ce6cf01":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow import keras\n\nimport os\nimport cv2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator #\nfrom tensorflow.keras.preprocessing import image\nimport matplotlib.pyplot as plt","6bd3e1bb":"train_data_path = \"..\/input\/car-scratch-dataset\/car_dent_coco\/car_dent_coco\/train\/\"\ntest_data_path = \"..\/input\/car-scratch-dataset\/car_dent_coco\/car_dent_coco\/test\/\"\nvalid_data_path = \"..\/input\/car-scratch-dataset\/car_dent_coco\/car_dent_coco\/valid\/\"","6a3a9f84":"import glob\n# print(glob.glob(str(train_data_path)+'\/*.jpg'))\n#back_light-1---83-_jpg.rf.829f6df0f7e1032fac163a84da29a75e.jpg\n#sign_light--19-_jpg.rf.9170ffdd1abc3028910d4592a6aa9984.jpg","620d4219":"# looking into the the data\nimg = plt.imread(os.path.join(train_data_path, \"back_light-1---83-_jpg.rf.829f6df0f7e1032fac163a84da29a75e.jpg\"))\nplt.imshow(img)\nheight, width, dim = img.shape\nprint(\"size of image (h x w)\",height,width)","8757f82a":"# looking into the the data\nimg = plt.imread(os.path.join(train_data_path, \"sign_light--19-_jpg.rf.9170ffdd1abc3028910d4592a6aa9984.jpg\"))\nplt.imshow(img)\nheight, width, dim = img.shape\nprint(\"size of image (h x w)\",height,width)","7ecda5cc":"train_data_path","ef51e080":"\ntrain = ImageDataGenerator(rescale=1\/255)\ntest = ImageDataGenerator(rescale=1\/255)\nvalid = ImageDataGenerator(rescale=1\/255)\n\nimg_width, img_height = 640, 640\n\nnb_train_samples = 2000\nnb_validation_samples = 800\nnb_epoch = 50\n\ntrain_dataset = train.flow_from_directory(directory = '..\/input\/car-scratch-dataset\/car_dent_coco\/car_dent_coco\/',classes = ['train']\n                                         ,\n        target_size=(img_width, img_height),\n        batch_size=32,\n        class_mode='binary')\n                                         \ntest_dataset = test.flow_from_directory(directory = '..\/input\/car-scratch-dataset\/car_dent_coco\/car_dent_coco\/',classes = ['test']\n                                       ,\n        target_size=(img_width, img_height),\n        batch_size=16,\n        class_mode='binary')\n\nvalid_dataset = test.flow_from_directory(directory = '..\/input\/car-scratch-dataset\/car_dent_coco\/car_dent_coco\/',classes = ['valid']\n                                        ,\n        target_size=(img_width, img_height),\n        batch_size=16,\n        class_mode='binary',\n        shuffle=True)","318bc8b0":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense","8f667d73":"# dimensions of our images.\nimg_width, img_height = 640, 640\n\n\n\nmodel = Sequential()\nmodel.add(Convolution2D(32, (3, 3),padding='same',input_shape=(img_width, img_height,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(32,(3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\nmodel.summary()\n","7d91ddd2":"from keras.layers import Dense,Activation,Dropout, Conv2D, MaxPool2D\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nearlystop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=1, min_delta=0.001)\nmodelcheck = ModelCheckpoint('best_model.hdf5', monitor='val_accuracy',verbose=1,save_best_only=True,mode='max')","73352093":"history = model.fit(train_dataset, \n                    validation_data=test_dataset,\n                    epochs=64,\n                    callbacks=[earlystop,modelcheck],\n                    batch_size=32)\n\n","c2ed732a":"model.save('car_model.hdf5')","17973a57":"# Saving the model for Future Inferences\n\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")","9caf34c6":"# imports\n\n\n# opening and store file in a variable\n\njson_file = open('model.json','r')\nloaded_model_json = json_file.read()\njson_file.close()\n\n# use Keras model_from_json to make a loaded model\n\nloaded_model = tf.keras.models.model_from_json(loaded_model_json)\n\n# load weights into new model\n\nloaded_model.load_weights(\"model.h5\")\nprint(\"Loaded Model from disk\")\n\n# compile and evaluate loaded model\n\nloaded_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","840e4934":"# from flask import Flask, render_template, request\n\n# @app.route('\/')\n# def index_view():\n#     return render_template('index.html')\n\n\n# @app.route('\/predict\/',methods=['GET','POST'])\n# def predict():\n#     response = \"For ML Prediction\"\n#     return response\n\n# if __name__ == '__main__':\n#     app.run(debug=True, port=8000)\n\n","7a79f46a":"def get_model():\n    global model\n    model = load_model('car_model')\n    print(\"Model loaded!\")","0f75215a":"def load_image(img_path):\n\n    img = image.load_img(img_path)\n    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n    img_tensor \/= 255.                                      # imshow expects values in the range [0, 1]\n\n    return img_tensor\n\ndef prediction(img_path):\n    new_image = load_image(img_path)\n    \n    pred = model.predict(new_image)\n    \n    print(pred)\n    \n    labels=np.array(pred)\n    labels[labels>=0.6]=1\n    labels[labels<0.6]=0\n    \n    print(labels)\n    final=np.array(labels)\n    \n    if final[0][0]==1:\n        return \"Bad\"\n    else:\n        return \"Good\"","d2144eb2":"plt.plot(history.history['loss'], label='train') \nplt.plot(history.history['val_loss'], label='test') \nplt.legend()\nplt.show()","73dcebc1":"print('Test accuracy achieved', history.history['val_accuracy'][-2])","86029aa1":"model.evaluate_generator(generator=valid_dataset,\nsteps=32)","75286bfc":"test_dataset.reset()\npred=model.predict_generator(test_dataset,\nsteps=128,\nverbose=1)\npredicted_class_indices=np.argmax(pred,axis=1)\n","fa41fc83":"predicted_class_indices\n\n# 0 = car damage","e20a3bfb":"labels = (train_dataset.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]","856dfa0a":"filenames=test_dataset.filenames\nresults=pd.DataFrame({\"Filename\":filenames,\n                      \"Predictions\":predictions})\nresults.to_csv(\"results.csv\",index=False)","2a3b767d":"#Check data in validation dataset\nimport glob\n# print(glob.glob(str(valid_data_path)+'\/*.jpg'))","f032fe6d":"# Our predict function\ndef predictImage(filename):\n    \n    img = image.load_img(filename)\n    plt.imshow(img)\n    \n    Y = image.img_to_array(img)\n    X = np.expand_dims(Y,axis=0)\n    val = model.predict(X)\n    print(val)\n    if val < 0.5:\n        plt.xlabel(\"Car Damage\",fontsize=30)\n    elif val >= 0.5:\n        plt.xlabel(\"Car Not Damage\",fontsize=30)\n        \n        \nu = '..\/input\/car-scratch-dataset\/car_dent_coco\/car_dent_coco\/valid\/rear_bumper-sep23---60-_jpg.rf.f20c9aeb3fa88e632b275bfccd7fdf4c.jpg'\npredictImage(u)","a8eca024":"!pip install fastapi uvicorn\n","42cc1ba1":"from pydantic import BaseModel\nfrom fastapi import FastAPI\nimport uvicorn\n\napp = FastAPI()\n \n\nclass request_body(BaseModel):\n    f_name: str\n\n# Creating an Endpoint to receive the data\n# to make prediction on.\n@app.post('\/predict')\ndef predict(data : request_body):\n    # Making the data in a form suitable for prediction\n        \n    img = image.load_img(filename)\n    plt.imshow(img)\n    \n    Y = image.img_to_array(img)\n    X = np.expand_dims(Y,axis=0)\n    val = model.predict(X)\n    print(val)\n    if val < 0.5:\n        plt.xlabel(\"Car Damage\",fontsize=30)\n    elif val >= 0.5:\n        plt.xlabel(\"Car Not Damage\",fontsize=30)\n    return { 'class' : iris.target_names[class_idx]}\n    \n\n     \n    # Return the Result\n#     return { 'class' : iris.target_names[class_idx]}","d5183fe5":"!pip install --upgrade streamlit","0a0ab959":"import numpy as np\nimport streamlit as st\nimport tensorflow as tf\nfrom PIL import Image, ImageOps\ndef import_and_predict(image_data, model):\n    \n        size = (150,150) \n        image = ImageOps.fit(image_data)\n#         image = ImageOps.fit(image_data, size, Image.ANTIALIAS)\n        image = np.asarray(image)\n        image = (image.astype(np.float32) \/ 255.0)\n\n        img_reshape = image[np.newaxis,...]\n#         img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n#         img_resize = (cv2.resize(img, dsize=(75, 75),    interpolation=cv2.INTER_CUBIC))\/255.\n        \n#         img_reshape = img_resize[np.newaxis,...]\n    \n        prediction = model.predict(img_reshape)\n        \n        return prediction\n    \nmodel = tf.keras.models.load_model('car_model.hdf5')\n\nimport streamlit as st\nst.write(\"\"\"\n         # Car Damage Detection\n         \"\"\"\n         )\nst.write(\"This is a simple image classification web app to predict damage\")\nfile = st.file_uploader(\"Please upload an image file\", type=[\"jpg\", \"png\"])    \nif file is None:\n    st.text(\"Please upload an image file\")\nelse:\n    image = Image.open(file)\n    st.image(image, use_column_width=True)\n    prediction = import_and_predict(image, model)\n    \n    if np.argmax(prediction) < 0.5:\n        st.write(\"Car Damage!\")\n    elif np.argmax(prediction) >= 0.5:\n        st.write(\"Car Not Damage!\")\n    \n    \n    st.text(\"Probability (0: Car_Damage, 1: Car_Not_Damage\")\n    st.write(prediction)","14af2936":"# Load images data","187af3b9":"# Train model","9a814142":"# Read data path and check files","5d022305":"# References\n\n*    [Tutorial-image-classification-with-keras-flow-from-directory-and-generators](https:\/\/vijayabhaskar96.medium.com\/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720)","d958b9b5":"# Deploy the model","b25d5d8e":"# Predict the output","c8287153":"# StreamLit Web app","fd19b050":"# Evaluate the model","1cd6d7d4":"# Validate Model Output"}}