{"cell_type":{"b10cae14":"code","46aa62a3":"code","472597a1":"code","6142435f":"code","1f35e5e5":"code","04acb7e7":"code","ea8ea39d":"code","99951e30":"code","bff5d691":"code","79194f9f":"code","e95d23a1":"code","2678f2ce":"code","ee7152a4":"code","dd369cb2":"code","f456bcfa":"code","03ee5c3c":"code","549d8803":"code","cd7dc3bf":"code","63661605":"code","0ca0afa4":"code","2132d0ea":"code","af91daeb":"code","9ca7284a":"code","59172711":"code","54aea3b0":"code","2a315b95":"code","93a08af5":"code","6556f040":"code","86d4a76d":"code","f77527c3":"code","cf20632e":"code","d9984ec0":"code","d50ff0f8":"code","b51fab2e":"code","05002e63":"code","de56d779":"code","a110cb42":"code","3488a92b":"code","ca3fdacf":"code","bfcbf855":"code","d6d142fe":"code","bf6e8589":"code","da8424c1":"code","adddb9f9":"code","4d4664b8":"code","e21e0eb7":"code","5285223a":"code","a2a1cf9a":"code","4bfaf6a7":"code","dc0184df":"code","c31a299e":"code","dd851e5f":"markdown","51b855cd":"markdown","cbbdd3a5":"markdown","95a14a89":"markdown","51140928":"markdown","fc4ccb9e":"markdown","c9fd6976":"markdown","ac6b0b62":"markdown","0ef78bad":"markdown","ff0f5cc7":"markdown","c213e706":"markdown","1cf45ed1":"markdown","1a6bc324":"markdown","79300f90":"markdown","5378fa9d":"markdown","66bfa930":"markdown","dc5e20dd":"markdown","1248acc8":"markdown","4c83d2ac":"markdown","58154f0e":"markdown","705fbc74":"markdown","fb742848":"markdown","bbb37bfb":"markdown","12bfa8b3":"markdown","e2c90dc3":"markdown","b8421ae2":"markdown","9df40669":"markdown","fb5d5085":"markdown","97e352d1":"markdown","c8bd83a9":"markdown","7c87b311":"markdown"},"source":{"b10cae14":"#Data manipulation libraries\n\nimport pandas as pd # reading and writing CSV etc \nimport numpy as np # handling mathematical functions\n\n#Data Viz libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\n\n#Scientific Learning libraries\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score","46aa62a3":"df=pd.read_csv('..\/input\/fish-market\/Fish.csv')","472597a1":"print(str('Is there any NaN value in the dataset: '), df.isnull().values.any()) ## checking for null values","6142435f":"df.head()","1f35e5e5":"df.info()","04acb7e7":"df.describe()","ea8ea39d":"sns.countplot(x=df['Species']) ","99951e30":"sns.barplot(y=df['Height'],x=df['Species']) #Bream has the greatest height","bff5d691":"sns.barplot(y=df['Width'],x=df['Species']) #whitefish has maximum width along side bream","79194f9f":"sns.barplot(y=df['Weight'],x=df['Species']) #Pike has maximum weight","e95d23a1":"sns.heatmap(df.corr(),annot=True) ## To check all the correlations present ","2678f2ce":"sns.pairplot(df) ","ee7152a4":"plt.figure(figsize=(5,8))\nsns.boxplot(y=df['Weight']) ","dd369cb2":"z = np.abs(stats.zscore(df.drop('Species',axis=1)))\nthreshold=3\nprint(np.where(z>3))\nprint('\\n')\nprint(np.where(z<-3)) ## caught some outliers, here i have their indexes  ","f456bcfa":"df_= df.drop('Species',axis=1)\nQ1 =df_.quantile(0.25)\nQ3 = df_.quantile(0.75)\nIQR = Q3 - Q1\nprint(IQR)","03ee5c3c":"df_ = df_[(z < 3).all(axis=1)]","549d8803":"df_out = df_[~((df_ < (Q1 - 1.5 * IQR)) |(df_ > (Q3 + 1.5 * IQR))).any(axis=1)]\ndf_out.shape","cd7dc3bf":"plt.figure(figsize=(5,8))\nsns.boxplot(y=df_out['Weight']) ## fair enough ","63661605":"df_s=df\ndf['Species'].unique()","0ca0afa4":"df_bream=df[df['Species']=='Bream']\ndf_roach=df[df['Species']=='Roach']\ndf_whitefish=df[df['Species']=='Whitefish']\ndf_parkki=df[df['Species']=='Parkki']\ndf_perch=df[df['Species']=='Perch']\ndf_pike=df[df['Species']=='Pike']\ndf_smelt=df[df['Species']=='Smelt']","2132d0ea":"sns.pairplot(df_s,hue='Species')","af91daeb":"plt.figure(figsize=(10,8))\nsns.boxplot(y=df['Weight'],x=df['Species'])","9ca7284a":"    z = np.abs(stats.zscore(df_roach.drop('Species',axis=1)))\n    df_q= df_roach.drop('Species',axis=1)\n    Q1 =df_q.quantile(0.25)\n    Q3 = df_q.quantile(0.75)\n    IQR = Q3 - Q1\n    df_roach = df_roach[(z < 3).all(axis=1)]\n    df_roach = df_roach[~((df_roach < (Q1 - 1.5 * IQR)) |(df_roach > (Q3 + 1.5 * IQR))).any(axis=1)]\n    \n    \n    z = np.abs(stats.zscore(df_smelt.drop('Species',axis=1)))\n    df_q= df_smelt.drop('Species',axis=1)\n    Q1 =df_q.quantile(0.25)\n    Q3 = df_q.quantile(0.75)\n    IQR = Q3 - Q1\n    df_smelt = df_smelt[(z < 3).all(axis=1)]\n    df_smelt = df_smelt[~((df_smelt < (Q1 - 1.5 * IQR)) |(df_smelt > (Q3 + 1.5 * IQR))).any(axis=1)]\n    ","59172711":"d=[df_bream,df_roach,df_whitefish,df_parkki, df_perch,df_pike,df_smelt]\nresult=pd.concat(d)","54aea3b0":"plt.figure(figsize=(10,8))\nsns.boxplot(y=result['Weight'],x=result['Species'])","2a315b95":"X=df_out.drop(['Weight'],axis=1)\ny=df_out['Weight']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)","93a08af5":"lr=LinearRegression() #creating a LinearRegression model instance","6556f040":"lr.fit(X_train,y_train) #now we'll directly fit the model and predict the outcome","86d4a76d":"pre=lr.predict(X_test)","f77527c3":"print('R2_score:')\nprint(metrics.explained_variance_score(y_test,pre)) ","cf20632e":"sns.distplot((y_test-pre))","d9984ec0":"plt.scatter(y_test,pre)","d50ff0f8":"pf=PolynomialFeatures() #Creating a PolynomialFeatures instance","b51fab2e":"quad=pf.fit_transform(X) #Creating a transformed data ","05002e63":" X_train, X_test, y_train, y_test = train_test_split(quad, y, test_size=0.20, random_state=42)","de56d779":"lr.fit(X_train,y_train)  #Now go with the basic Linear Regression Steps fit and predict","a110cb42":"pred=lr.predict(X_test)","3488a92b":"print('R2_score:',metrics.explained_variance_score(y_test,pred))\nprint('MAE:',metrics.mean_absolute_error(y_test,pred))\nprint('MSE:',metrics.mean_squared_error(y_test,pred))\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_test,pred)))\n","ca3fdacf":"cross_val_score_train = cross_val_score(lr, X_train, y_train, cv=10, scoring='r2')\nprint(cross_val_score_train)","bfcbf855":"print(np.mean(cross_val_score_train))","d6d142fe":"# bit of graphical plotting just to make sure that i have not overfitted the data in any case\nsns.distplot((y_test-pred))","bf6e8589":"plt.scatter(y_test,pred,marker='o')\n","da8424c1":"# Model Seems to be pretty good","adddb9f9":"X=result.drop(['Species'],axis=1)\ny=result['Species']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","4d4664b8":"logr=LogisticRegression()  #creating an LogisticRegression instance\n","e21e0eb7":"logr.fit(X_train,y_train)  #now will fit and predict","5285223a":"pre=logr.predict(X_test)","a2a1cf9a":"logr.score(X_test,y_test)","4bfaf6a7":"data={'Actual':y_test.array,'Predicted':pre}","dc0184df":"res=pd.DataFrame(data)","c31a299e":"res","dd851e5f":"This data set contains the following features:\n\n* 'Species': Name of the species \n* 'Weight': Weight of individual fish in grams\n* 'Length 1': Vertical length in cm\n* 'Length 2': Diagonal length in cm\n* 'Length 3': Cross length in cm\n* 'Height': Height in cm\n* 'Width': Width in cm\n\nOur dependent variable is 'Weight'. Independent variables are 'species', different lengths, 'height' and 'width'.\n\nI will use independent variables (measurements of the fish) to estimate dependent variable (weight of the fish).\n\n","51b855cd":"### Seems like we have taken them out and are ready with our final dataset for predicting the species. But first let's make sure that they are really gone.","cbbdd3a5":"### Seems like only Roach and Smelt have outliers, so we'll remove them on the basis Z-score and IQR score","95a14a89":"## Now we are talking results \n### So this was my best trained model for estimating the weight of individual fish based on given data set","51140928":"### Let's seperate out dependent and independent values first ","fc4ccb9e":"## Well looking at the size of data this seems like a fine result ","c9fd6976":"### Since there are very less number of outliers ill be removing them","ac6b0b62":"### Now that i have my data clean for estimating the weight ,ill start with same thing again for the predicting of species","0ef78bad":"# Machine Learning Model Prep Start's here: \n## Here i've selected linear Regression model for estimation of weight(dependent variable) with the help of width , length, height etc(independent variable). ","ff0f5cc7":"### Z-score analysis ","c213e706":"### Let's seperate out the dependent and independent variable from the later created final dataset 'result'","1cf45ed1":"### IQR analysis","1a6bc324":"### The purpose of study of this data is to estimate the weight of individual fish with the help of a multiple linear regression model which considers features such as height ,width,length etc of the fish, as well as prediction of a any particular specie with the help of a logistical regression model \n\n","79300f90":"### Let's start with catching outliers ","5378fa9d":"## Now let's perform some preprocessing with 2nd degree polynomial featuring ","66bfa930":"# MULTIPLE LINEAR REGRESSION MODEL FOR WEIGHT ESTIMATION FROM MEASUREMENTS OF THE FISH AND LOGISTICAL MODEL FOR SPECIE'S  PREDICTION","dc5e20dd":"### Now let's see if we have done enough to get rid of them","1248acc8":"### Surveying data with the help of .info(),.head(),.describe() ","4c83d2ac":"## Now let's start with predicting species(Dependent feature), based upon rest of the independent features.\n### Here i've selected Logistical Regression algorithm because of the small size of data and catagorical target feature","58154f0e":"### This score seems to be pretty good, but if we change random_state our train and test samples will be different and our model's score will be different. In order to eliminate this change I will use cross validation:\n","705fbc74":"# So this was all from my side, feel free to post any query or issues related to it.","fb742848":"### Well it seems like i was wrong after all about the outliers, we'll try and reduce them with the help of Z-score and IQR ","bbb37bfb":"## Now let's move to our Exploratory Data Analysis\n### We'll be using seaborn for plotting the graphs ","12bfa8b3":"### The dataset seems to be fairly consistent ,but still we'll quickly rush through some basic techniques to detect any sorts of outliers ","e2c90dc3":"### Not a bad score for such a lazy model xD","b8421ae2":"#### I'll seperate out each species so that later on i can see the outliers if individually if any are there ","9df40669":"### The mean of all the above values would give me a almost perfect conclusion about my R2 score","fb5d5085":"### Let's checkout the results by comparing actual and predicted values","97e352d1":"### Now let's read the data from our project directory ","c8bd83a9":"\n    Positive outcomes: \n                       - Improvment in studies of fishes in any water body .\n                       - Estimation of individual fish speices population in the selected water mass.\n                       - Obtaining more info on fishes without any physical contact that might harm\n                         them.\n                  \n         Environment:  \n                       -python 3 \n                  ","7c87b311":"### Let's start with importing all our required libraries "}}