{"cell_type":{"40e492f6":"code","10915417":"code","d1198cce":"code","0ae9f8d1":"code","b75863b5":"code","d9de4623":"code","94f9ea85":"code","0e0fd465":"code","e61a7288":"code","f959465b":"code","1935ab52":"code","0eb4e4a7":"code","bc9929f2":"code","7e4091c0":"code","bb31f340":"code","2794ce68":"code","9b9a71b3":"code","f6ea02f7":"code","5bf505c5":"code","738acb04":"code","e99a7540":"code","ff663cfc":"code","d5a73d6d":"code","32c0034c":"code","a48020bb":"code","069ef50e":"code","824d17dc":"code","74408bfc":"code","7d5ae78b":"code","be68c2a5":"code","a394a861":"code","33add782":"code","3625cee6":"code","0b021ad6":"code","3ac56e80":"code","efa77e12":"code","c7ecac3a":"code","2db86402":"code","08091be3":"code","cfaf859d":"code","eee04a38":"code","beaeccd6":"code","2fc21556":"code","9d9f8043":"code","3a01c4b7":"code","efb9cc59":"code","cbd06c61":"code","f4bb9cdc":"code","4eb66dbe":"code","e15e96f7":"code","f35acbf8":"code","99cfb72b":"code","58bcf5a4":"code","c6f9ef9a":"code","300a18d8":"code","e5a1faaa":"code","e7779335":"code","ecc771a2":"code","90922a79":"code","d6d47098":"code","2ba0b56f":"code","0e4a81b0":"code","2575f1f3":"code","8307765e":"code","080a4355":"code","eca09c46":"code","d6fdf2f8":"code","b81b1957":"code","28afd832":"code","7aca8787":"code","bb96495c":"code","d14ebfca":"code","348587ec":"code","6cf647a3":"code","19a79b02":"code","89012931":"code","81874007":"code","2be98fde":"code","1337a39e":"code","f609b2f3":"code","7f74235c":"code","b44fa742":"code","17e4a0a8":"code","849dfd50":"markdown","1c3eeb22":"markdown","7a147110":"markdown","bea03a8d":"markdown","15c5c106":"markdown","588f02ed":"markdown","d69257cd":"markdown","9bc7f782":"markdown","29e294d5":"markdown","1be85c7b":"markdown","f0247670":"markdown","a0dfe566":"markdown","124bf8c9":"markdown","7e1441b2":"markdown","487a2c9a":"markdown","7e88b037":"markdown","018f240f":"markdown","3b93a4ce":"markdown","2e504a13":"markdown","093e7938":"markdown","f7d2a228":"markdown","e228238f":"markdown","a67b4132":"markdown","9c33b1b0":"markdown","aa5899d9":"markdown","45bd6c6e":"markdown","fee8099a":"markdown","1c63d5af":"markdown","887e4c09":"markdown","01610d4b":"markdown","0746dd52":"markdown","587d8785":"markdown"},"source":{"40e492f6":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","10915417":"dados = pd.read_csv('..\/input\/ckdisease\/kidney_disease.csv')","d1198cce":"dados.head()","0ae9f8d1":"dados = dados.drop('id',axis=1)","b75863b5":"dados.head()","d9de4623":"dados.info()","94f9ea85":"dados.isna().sum()","0e0fd465":"dados = dados.dropna()","e61a7288":"dados.isna().sum()","f959465b":"dados.head()","1935ab52":"dados = dados.reset_index().drop('index',axis=1)","0eb4e4a7":"sns.countplot(dados['classification'])","bc9929f2":"fig, ax = plt.subplots(2,5,figsize=(12,7))\nsns.countplot(dados['ane'],ax=ax[0][0],hue=dados['classification'])\nsns.countplot(dados['pe'],ax=ax[0][1],hue=dados['classification'])\nsns.countplot(dados['appet'],ax=ax[0][2],hue=dados['classification'])\nsns.countplot(dados['cad'],ax=ax[0][3],hue=dados['classification'])\nsns.countplot(dados['dm'],ax=ax[0][4],hue=dados['classification'])\nsns.countplot(dados['htn'],ax=ax[1][0],hue=dados['classification'])\nsns.countplot(dados['rbc'],ax=ax[1][1],hue=dados['classification'])\nsns.countplot(dados['pc'],ax=ax[1][2],hue=dados['classification'])\nsns.countplot(dados['pcc'],ax=ax[1][3],hue=dados['classification'])\nsns.countplot(dados['ba'],ax=ax[1][4],hue=dados['classification'])\nplt.tight_layout()","7e4091c0":"dados['pcv'] = dados['pcv'].astype(int)\ndados['wc'] = dados['wc'].astype(int)\ndados['rc'] = dados['rc'].astype(float)","bb31f340":"fig, ax = plt.subplots(4,3,figsize=(12,7))\nax[0][0].hist(dados['bgr'])\nax[0][0].set_title('bgr')\nax[0][1].hist(dados['bu'])\nax[0][1].set_title('bu')\nax[0][2].hist(dados['sc'])\nax[0][2].set_title('sc')\n\nax[1][0].hist(dados['sod'])\nax[1][0].set_title('sod')\nax[1][1].hist(dados['pot'])\nax[1][1].set_title('pot')\nax[1][2].hist(dados['hemo'])\nax[1][2].set_title('hemo')\n\nax[2][0].hist(dados['pcv'])\nax[2][0].set_title('pcv')\nax[2][1].hist(dados['wc'])\nax[2][1].set_title('wc')\nax[2][2].hist(dados['rc'])\nax[2][2].set_title('rc')\n\nax[3][0].hist(dados['age'])\nax[3][0].set_title('age')\nax[3][1].hist(dados['sg'])\nax[3][1].set_title('sg')\nax[3][2].hist(dados['bp'])\nax[3][2].set_title('bp')\nplt.tight_layout()","2794ce68":"colunas_normalizar = ['bgr','bu','sc','sod','pot','hemo','pcv','wc','rc','age','bp']","9b9a71b3":"from sklearn.preprocessing import MinMaxScaler","f6ea02f7":"for col in colunas_normalizar:\n    scaler = MinMaxScaler(feature_range=(0,1))\n    dados[col] = scaler.fit_transform(dados[col].values.reshape(-1,1))","5bf505c5":"dados.head()","738acb04":"colunas_onehot = ['rbc','pc','ba','pcc','pe','appet','cad','dm','htn','ane']","e99a7540":"from sklearn.preprocessing import OneHotEncoder, LabelEncoder","ff663cfc":"for col in colunas_onehot:\n    enc = OneHotEncoder()\n    dados[col] = enc.fit_transform(dados[col].values.reshape(-1,1)).toarray()","d5a73d6d":"enc = LabelEncoder()\ndados['classification'] = enc.fit_transform(dados['classification'])","32c0034c":"dados.head()","a48020bb":"corr = dados.corr()","069ef50e":"fig,ax = plt.subplots(figsize=(10,8))\nsns.heatmap(corr,ax=ax)\nplt.tight_layout()","824d17dc":"from sklearn.model_selection import train_test_split, cross_val_score,KFold,StratifiedKFold, GridSearchCV\nfrom sklearn.metrics import confusion_matrix,accuracy_score,f1_score,average_precision_score,recall_score,roc_auc_score","74408bfc":"colunas_X = dados.columns.drop('classification')","7d5ae78b":"X = dados.drop('classification',axis=1).values\nY = dados['classification'].values","be68c2a5":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30,random_state=42,stratify=Y)","a394a861":"accuracy = []\nprecision =[]\nrecall = []\nf1 = []\nroc = []","33add782":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier","3625cee6":"print(\"Logistic Regression\")\nlog_reg_params = {\"penalty\": ['None','l1', 'l2','elasticnet'], 'C': [1, 10, 100], \n                  'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\ngrid_log_reg = GridSearchCV(LogisticRegression(max_iter=10000), log_reg_params,n_jobs=8,cv=10,scoring='roc_auc_ovo')\ngrid_log_reg.fit(X_train, y_train)\nlogreg = grid_log_reg.best_estimator_\nlog_reg_score = cross_val_score(logreg, X_train, y_train, cv=10,scoring='roc_auc_ovo')\nlog_reg_score_teste = cross_val_score(logreg, X_test, y_test, cv=10,scoring='roc_auc_ovo')\nprint(\"Best Estimator\")\nprint(logreg)\nprint('Score Regressao Logistica Train: ', round(log_reg_score.mean() * 100, 2).astype(str) + '%')\nprint('Score Regressao Logistica Test: ', round(log_reg_score_teste.mean() * 100, 2).astype(str) + '%')","0b021ad6":"logreg.fit(X_train,y_train)","3ac56e80":"Y_pred_logreg = logreg.predict(X_test)","efa77e12":"cm_logreg = confusion_matrix(y_test,Y_pred_logreg)","c7ecac3a":"acc_score_logreg = accuracy_score(y_test,Y_pred_logreg)\nf1_score_logreg = f1_score(y_test,Y_pred_logreg)\nprecisao_logreg = average_precision_score(y_test,Y_pred_logreg)\nrecall_logreg = recall_score(y_test,Y_pred_logreg)\nroc_logreg = roc_auc_score(y_test,Y_pred_logreg,multi_class='ovo')\nprint('Accuracy Logistic Regression ',round(acc_score_logreg*100,2).astype(str)+'%')\nprint('Precision Logistic Regression ',round(precisao_logreg*100,2).astype(str)+'%')\nprint('F1 Logistic Regression ',round(f1_score_logreg*100,2).astype(str)+'%')\nprint('Recall Logistic Regression ',round(recall_logreg*100,2).astype(str)+'%')\nprint('ROC Logistic Regression ',round(roc_logreg*100,2).astype(str)+'%')","2db86402":"accuracy.append(acc_score_logreg)\nprecision.append(precisao_logreg)\nrecall.append(recall_logreg)\nf1.append(f1_score_logreg)\nroc.append(roc_logreg)","08091be3":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_logreg, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Logistic Regression \\n Confusion Matrix\", fontsize=14)\nax.set_xticklabels(['ckd', 'notckd'], fontsize=14, rotation=0)\nax.set_yticklabels(['ckd', 'notckd'], fontsize=14, rotation=360)","cfaf859d":"importance_logreg = logreg.coef_[0]\nfeature_series_logreg = pd.Series(data=importance_logreg,index=colunas_X)\nfeature_series_logreg.plot.bar()\nplt.title('Feature Importance Logistic Regression')\nplt.xlabel('Features')\nplt.ylabel('Importance')\nplt.tight_layout()","eee04a38":"print(\"KNN\")\nknears_params = {\"n_neighbors\": list(range(5,30,1)),'leaf_size' : list(range(3,11,1)), 'weights': ['uniform', 'distance']}\ngrid_knears = GridSearchCV(KNeighborsClassifier(), knears_params,n_jobs=8,cv=10,scoring='roc_auc_ovo')\ngrid_knears.fit(X_train, y_train)\nknn = grid_knears.best_estimator_\nknears_score = cross_val_score(knn, X_train, y_train, cv=10,scoring='roc_auc_ovo')\nknears_score_teste = cross_val_score(knn, X_test, y_test, cv=10,scoring='roc_auc_ovo')\nprint(\"Best Estimator\")\nprint(knn)\nprint('Score KNN Train: ', round(knears_score.mean() * 100, 2).astype(str) + '%')\nprint('Score KNN Test: ', round(knears_score_teste.mean() * 100, 2).astype(str) + '%')","beaeccd6":"knn.fit(X_train,y_train)","2fc21556":"Y_pred_knn = knn.predict(X_test)","9d9f8043":"cm_knn = confusion_matrix(y_test,Y_pred_knn)","3a01c4b7":"acc_score_knn = accuracy_score(y_test,Y_pred_knn)\nf1_score_knn = f1_score(y_test,Y_pred_knn)\nprecisao_knn = average_precision_score(y_test,Y_pred_knn)\nrecall_knn = recall_score(y_test,Y_pred_knn)\nroc_knn = roc_auc_score(y_test,Y_pred_knn,multi_class='ovo')\nprint('Accuracy KNN ',round(acc_score_knn*100,2).astype(str)+'%')\nprint('Precision KNN ',round(precisao_knn*100,2).astype(str)+'%')\nprint('F1 KNN ',round(f1_score_knn*100,2).astype(str)+'%')\nprint('Recall KNN ',round(recall_knn*100,2).astype(str)+'%')\nprint('ROC KNN ',round(roc_knn*100,2).astype(str)+'%')","efb9cc59":"accuracy.append(acc_score_knn)\nprecision.append(precisao_knn)\nrecall.append(recall_knn)\nf1.append(f1_score_knn)\nroc.append(roc_knn)","cbd06c61":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_knn, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"KNN \\n Confusion Matrix\", fontsize=14)\nax.set_xticklabels(['ckd', 'notckd'], fontsize=14, rotation=0)\nax.set_yticklabels(['ckd', 'notckd'], fontsize=14, rotation=360)","f4bb9cdc":"print(\"Ada Boost Classifier\")\nada_params = {'n_estimators' : list(range(5,200))}\ngrid_ada = GridSearchCV(AdaBoostClassifier(), ada_params,n_jobs=8,cv=10,scoring='roc_auc_ovo')\ngrid_ada.fit(X_train, y_train)\nada = grid_ada.best_estimator_\nprint(\"Best Estimator\")\nprint(ada)\nada_score = cross_val_score(ada, X_train, y_train, cv=10,scoring='roc_auc_ovo')\nada_score_teste = cross_val_score(ada, X_test, y_test, cv=10,scoring='roc_auc_ovo')\nprint('Score AdaBoost Train: ', round(ada_score.mean() * 100, 2).astype(str) + '%')\nprint('Score AdaBoost Test: ', round(ada_score_teste.mean() * 100, 2).astype(str) + '%')","4eb66dbe":"ada.fit(X_train,y_train)","e15e96f7":"Y_pred_ada = ada.predict(X_test)","f35acbf8":"cm_ada = confusion_matrix(y_test,Y_pred_ada)","99cfb72b":"acc_score_ada = accuracy_score(y_test,Y_pred_ada)\nf1_score_ada = f1_score(y_test,Y_pred_ada)\nprecisao_ada = average_precision_score(y_test,Y_pred_ada)\nrecall_ada = recall_score(y_test,Y_pred_ada)\nroc_ada = roc_auc_score(y_test,Y_pred_ada,multi_class='ovo')\nprint('Accuracy ADA Boost ',round(acc_score_ada*100,2).astype(str)+'%')\nprint('Precision Ada Boost ',round(precisao_ada*100,2).astype(str)+'%')\nprint('F1 Ada Boost ',round(f1_score_ada*100,2).astype(str)+'%')\nprint('Recall Ada Boost ',round(recall_ada*100,2).astype(str)+'%')\nprint('ROC Ada Boost ',round(roc_ada*100,2).astype(str)+'%')","58bcf5a4":"accuracy.append(acc_score_ada)\nprecision.append(precisao_ada)\nrecall.append(recall_ada)\nf1.append(f1_score_ada)\nroc.append(roc_ada)","c6f9ef9a":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_ada, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Ada Boost \\n Confusion matrix\", fontsize=14)\nax.set_xticklabels(['ckd', 'notckd'], fontsize=14, rotation=0)\nax.set_yticklabels(['ckd', 'notckd'], fontsize=14, rotation=360)","300a18d8":"importance_ada = ada.feature_importances_\nfeature_series_ada = pd.Series(data=importance_ada,index=colunas_X)\nfeature_series_ada.plot.bar()\nplt.title('Feature Importance Ada Boost')\nplt.xlabel('Features')\nplt.ylabel('Importance')\nplt.tight_layout()","e5a1faaa":"print(\"Random Forest Classifier\")\nforest_params = {\"max_depth\": list(range(5,10,1)),\"n_estimators\" : list(range(5,10,1))}\nforest = GridSearchCV(RandomForestClassifier(), forest_params,n_jobs=8,cv=10,scoring='roc_auc_ovo')\nforest.fit(X_train, y_train)\nrandom_forest = forest.best_estimator_\nprint(\"Best Estimator\")\nprint(random_forest)\nforest_score = cross_val_score(random_forest, X_train, y_train, cv=10,scoring='roc_auc_ovo')\nforest_score_teste = cross_val_score(random_forest, X_test, y_test, cv=10,scoring='roc_auc_ovo')\nprint('Score RFC Train: ', round(forest_score.mean() * 100, 2).astype(str) + '%')\nprint('Score RFC Test: ', round(forest_score_teste.mean() * 100, 2).astype(str) + '%')","e7779335":"random_forest.fit(X_train,y_train)","ecc771a2":"Y_pred_rf = random_forest.predict(X_test)","90922a79":"cm_rf = confusion_matrix(y_test,Y_pred_rf)","d6d47098":"acc_score_rf = accuracy_score(y_test,Y_pred_rf)\nf1_score_rf = f1_score(y_test,Y_pred_rf)\nprecisao_rf = average_precision_score(y_test,Y_pred_rf)\nrecall_rf = recall_score(y_test,Y_pred_rf)\nroc_rf = roc_auc_score(y_test,Y_pred_rf,multi_class='ovo')\nprint('Accuracy Random Forest ',round(acc_score_rf*100,2).astype(str)+'%')\nprint('Precision Random Forest ',round(precisao_rf*100,2).astype(str)+'%')\nprint('F1 Random Forest ',round(f1_score_rf*100,2).astype(str)+'%')\nprint('Recall Random Forest ',round(recall_rf*100,2).astype(str)+'%')\nprint('ROC Random Forest ',round(roc_rf*100,2).astype(str)+'%')","2ba0b56f":"accuracy.append(acc_score_rf)\nprecision.append(precisao_rf)\nrecall.append(recall_rf)\nf1.append(f1_score_rf)\nroc.append(roc_rf)","0e4a81b0":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_rf, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Random Forest \\n Confusion matrix\", fontsize=14)\nax.set_xticklabels(['ckd', 'notckd'], fontsize=14, rotation=0)\nax.set_yticklabels(['ckd', 'notckd'], fontsize=14, rotation=360)","2575f1f3":"importance_rfc = random_forest.feature_importances_\nfeature_series_rfc = pd.Series(data=importance_rfc,index=colunas_X)\nfeature_series_rfc.plot.bar()\nplt.title('Feature Importance Random Forest')\nplt.xlabel('Features')\nplt.ylabel('Importance')\nplt.tight_layout()","8307765e":"print(\"Gradient Boost Classifier\")\ngrad_params = {'n_estimators' : list(range(4,21,1)),'max_depth' : list(range(5,21,1))}\ngrad = GridSearchCV(GradientBoostingClassifier(), grad_params,n_jobs=8,cv=10,scoring='roc_auc_ovo')\ngrad.fit(X_train, y_train)\ngrad_boost = grad.best_estimator_\nprint(\"Best Estimator\")\nprint(grad_boost)\ngrad_score = cross_val_score(grad_boost, X_train, y_train, cv=10,scoring='roc_auc_ovo')\ngrad_score_teste = cross_val_score(grad_boost, X_test, y_test, cv=10,scoring='roc_auc_ovo')\nprint('Score GradBoost Train: ', round(grad_score.mean() * 100, 2).astype(str) + '%')\nprint('Score GradBoost Test: ', round(grad_score_teste.mean() * 100, 2).astype(str) + '%')","080a4355":"grad_boost.fit(X_train, y_train)","eca09c46":"Y_pred_gb = grad_boost.predict(X_test)","d6fdf2f8":"cm_gb = confusion_matrix(y_test,Y_pred_gb)","b81b1957":"acc_score_gb = accuracy_score(y_test,Y_pred_gb)\nf1_score_gb = f1_score(y_test,Y_pred_gb)\nprecisao_gb = average_precision_score(y_test,Y_pred_gb)\nrecall_gb = recall_score(y_test,Y_pred_gb)\nroc_gb = roc_auc_score(y_test,Y_pred_gb,multi_class='ovo')\nprint('Accuracy Gradient Boosting ',round(acc_score_gb*100,2).astype(str)+'%')\nprint('Precision Gradient Boosting  ',round(precisao_gb*100,2).astype(str)+'%')\nprint('F1 Gradient Boosting  ',round(f1_score_gb*100,2).astype(str)+'%')\nprint('Recall Gradient Boosting  ',round(recall_gb*100,2).astype(str)+'%')\nprint('ROC Gradient Boosting ',round(roc_gb*100,2).astype(str)+'%')","28afd832":"accuracy.append(acc_score_gb)\nprecision.append(precisao_gb)\nrecall.append(recall_gb)\nf1.append(f1_score_gb)\nroc.append(roc_gb)","7aca8787":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_gb, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Gradient Boosting  \\n Confusion matrix\", fontsize=14)\nax.set_xticklabels(['ckd', 'notckd'], fontsize=14, rotation=0)\nax.set_yticklabels(['ckd', 'notckd'], fontsize=14, rotation=360)","bb96495c":"importance_gradboost = grad_boost.feature_importances_\nfeature_series_gradboost = pd.Series(data=importance_gradboost,index=colunas_X)\nfeature_series_gradboost.plot.bar()\nplt.title('Feature Importance Gradient Boosting')\nplt.xlabel('Features')\nplt.ylabel('Importance')\nplt.tight_layout()","d14ebfca":"n_inputs = X_train.shape[1]","348587ec":"from keras.models import Sequential\nfrom keras.layers import Activation,BatchNormalization\nfrom keras.layers.core import Dense,Dropout\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.callbacks import ReduceLROnPlateau,EarlyStopping","6cf647a3":"modelo = Sequential()\nmodelo.add(Dense(128, input_shape=(n_inputs, ), activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo.add(BatchNormalization())\nmodelo.add(Dense(256, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo.add(BatchNormalization())\nmodelo.add(Dropout(0.5))\nmodelo.add(Dense(512, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo.add(BatchNormalization())\nmodelo.add(Dense(512, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo.add(BatchNormalization())\nmodelo.add(Dropout(0.5))\nmodelo.add(Dense(256, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo.add(BatchNormalization())\nmodelo.add(Dense(128, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo.add(BatchNormalization())\nmodelo.add(Dropout(0.5))\nmodelo.add(Dense(2, activation='softmax', kernel_initializer='glorot_uniform',bias_initializer='zeros'))","19a79b02":"reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, mode='auto', min_delta=0.0001)\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\ncallbacks_list = [reduce_lr,es]\nbsize = 50","89012931":"modelo.compile(Adam(lr=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodelo.fit(X_train, y_train, batch_size=bsize, epochs=200, verbose=2, validation_data=(X_test,y_test),callbacks=callbacks_list)","81874007":"Y_pred_keras = modelo.predict_classes(X_test, batch_size=bsize, verbose=0)","2be98fde":"cm_keras = confusion_matrix(y_test,Y_pred_keras)\nacc_score_keras = accuracy_score(y_test,Y_pred_keras)\nf1_score_keras = f1_score(y_test,Y_pred_keras)\nprecisao_keras = average_precision_score(y_test,Y_pred_keras)\nrecall_keras = recall_score(y_test,Y_pred_keras)\nroc_keras = roc_auc_score(y_test,Y_pred_keras,multi_class='ovo')\nprint('Accuracy Keras ',round(acc_score_keras*100,2).astype(str)+'%')\nprint('Precision Keras  ',round(precisao_keras*100,2).astype(str)+'%')\nprint('F1 Keras  ',round(f1_score_keras*100,2).astype(str)+'%')\nprint('Recall Keras  ',round(recall_keras*100,2).astype(str)+'%')\nprint('ROC Keras ',round(roc_keras*100,2).astype(str)+'%')","1337a39e":"accuracy.append(acc_score_keras)\nprecision.append(precisao_keras)\nrecall.append(recall_keras)\nf1.append(f1_score_keras)\nroc.append(roc_keras)","f609b2f3":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_keras, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Keras  \\n Matriz de Confus\u00e3o\", fontsize=14)\nax.set_xticklabels(['ckd', 'notckd'], fontsize=14, rotation=0)\nax.set_yticklabels(['ckd', 'notckd'], fontsize=14, rotation=360)","7f74235c":"nome_modelo = [\"Logistic Regression\",\"KNN\",\"AdaBoost\",\"RFC\",\"GradBoost\",\"Keras\"]\ndic_metrics = {'Model' : nome_modelo, 'Accuracy' : accuracy, 'Precision' : precision, 'Recall' : recall, 'F1' : f1, 'ROC' : roc}\ndataframe = pd.DataFrame(dic_metrics)","b44fa742":"dataframe_sorted =  dataframe.sort_values(by=['ROC','Accuracy','Recall','F1','Precision'],ascending=False).reset_index().drop('index',axis=1)","17e4a0a8":"dataframe_sorted","849dfd50":"These distributions tell us that all of these continuous variables must be normalized in order to get the maximum accuracies","1c3eeb22":"Removing id column","7a147110":"Keras was able to find the right solution for all test sample","bea03a8d":"The feature importance plot shows that only the columns al, htn, dm and appet are important for the problem","15c5c106":"Showing initial statistcs from the data","588f02ed":"Random forest had a very similiar result compared to Logistic regression","d69257cd":"In order to find the best solution for each model, GridSearchCV will be used with a cross-validation of 10 samples","9bc7f782":"Compared to logistic regression KNN had a worse performance","29e294d5":"For Gradient Boosting only the column al is important","1be85c7b":"Ada Boost had a very similar performance compared to Logistic Regression","f0247670":"Importing fundamental libraries","a0dfe566":"Logistic regression has only made one mistake with demonstrate that it is an excellent model for predicting kidney disease","124bf8c9":"Build a deep learning model with Keras. I will use Batch Normalization since this has a very imporant effect in the model","7e1441b2":"Spliting into train and test samples using 30% for test size","487a2c9a":"Gradient boost also had a very similar performance compared to the logistic regression and ada boost models","7e88b037":"Checking the distribution of each class","018f240f":"Features with strong correlation have a negative correlation","3b93a4ce":"Checking the distributions of the continuous variables","2e504a13":"For random forest classifier only the columns al, ba, sod, hemo, rc and dm are important where the column rc is the most important","093e7938":"The deep learning model has proven to be the best one compared to the machine learning models used here","f7d2a228":"Continuous features will be normalized with MinMaxScaler","e228238f":"Showing the first five lines","a67b4132":"Checking how each categorical variable affects the diagnostic","9c33b1b0":"Accoring to Ada Boost only the column al is important for the problem","aa5899d9":"The output feature (classification) will be converted to numerical using Label Enconder","45bd6c6e":"For patients without the disease the categorical variables have a very specific behavior","fee8099a":"Defining the X and Y variables\n","1c63d5af":"Categorical features will be converted to numerical values using OneHot Enconder","887e4c09":"It looks like there are lines with NaNs","01610d4b":"Reading the dataset","0746dd52":"There are several NaNs in the columns rbc, wc, rc for example. I will drop them all since most of them are categorical columns","587d8785":"Checking the correlation of each variable\n"}}