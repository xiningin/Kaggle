{"cell_type":{"86b84f97":"code","1b0af805":"code","f8531b74":"code","b2809546":"code","2ee6cfcd":"code","5d9c3448":"code","01b457be":"code","9c546fbe":"code","0f51550a":"code","f11a3b35":"code","2638d0cf":"code","84ff9287":"code","39b0d902":"code","afb98bb5":"code","45dc4e5c":"code","23a4a8c8":"code","f9fbb2ff":"code","7a21e6ad":"code","9cb7cfa4":"code","1ae5bf98":"code","2cc42cfc":"code","60f5790d":"code","4e5230cc":"code","35f3834e":"code","dbbb8729":"code","b1916818":"code","10be4edc":"code","de3e36cf":"code","e8349032":"code","a1bebad6":"code","c3b07b09":"code","ef02b317":"code","b2174949":"code","6ae332fa":"code","3c7466d2":"code","667a3aa6":"code","6ec32256":"code","897357cb":"code","e3af1c9b":"code","99ac467b":"code","9a27db24":"code","43184d41":"code","5fe96949":"code","6ec78bbf":"code","f3c843e7":"code","ad3bdd35":"markdown","0b77c529":"markdown","375ac1df":"markdown","732f7b7b":"markdown","0352336d":"markdown","c662c268":"markdown","d4801faa":"markdown","4f34ecc1":"markdown","a4badb1f":"markdown","c9617dae":"markdown","e6b4fde0":"markdown","15372fd6":"markdown","30694ef1":"markdown","43b6adb5":"markdown","451234b0":"markdown","b48469b0":"markdown","d001390c":"markdown","c766c14c":"markdown","be68c877":"markdown","f9c05e97":"markdown","6b1171c2":"markdown","a35d36f6":"markdown","14fc3288":"markdown","a4a02155":"markdown","8773e17f":"markdown","b1467974":"markdown","d047fc39":"markdown"},"source":{"86b84f97":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1b0af805":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","f8531b74":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain","b2809546":"train.columns\n","2ee6cfcd":"train = train.drop([\"Name\", \"Ticket\", \"Fare\", \"Embarked\", \"Cabin\"], axis=1)\ntrain","5d9c3448":"train.isnull().sum()","01b457be":"female = (train[\"Sex\"] == \"female\")\nfemale.sum()\navg_age_female = (train[female][\"Age\"].mean())\nround(avg_age_female,1) \ntrain_female = (train[female][\"Age\"]).fillna(value=avg_age_female)\ntrain_female.astype('int')","9c546fbe":"male = (train[\"Sex\"] == \"male\")\nmale.sum()\navg_age_male = (train[male][\"Age\"].mean())\nround(avg_age_male,1) \ntrain_male = (train[male][\"Age\"]).fillna(value=avg_age_male)\ntrain_male.astype('int')","0f51550a":"train[\"Age\"] = pd.concat([train_female, train_male])\ntrain[\"Age\"] = train[\"Age\"].astype('int')\ntrain","f11a3b35":"train.isnull().sum()","2638d0cf":"sns.pairplot(train, hue = \"Survived\", palette = 'husl')","84ff9287":"sns.histplot(data=train, x=\"Survived\", hue = \"Survived\", palette = 'husl')","39b0d902":"sns.histplot(data=train, y=\"Age\", x=\"Survived\", hue = \"Survived\", cbar=True, palette = 'husl')","afb98bb5":"sns.histplot(data=train, y=\"Sex\", x=\"Survived\", hue = \"Survived\", cbar=True, palette = 'husl')","45dc4e5c":"sns.histplot(data=train, y=\"SibSp\", x=\"Survived\", hue = \"Survived\", cbar=True, palette = 'husl')","23a4a8c8":"sns.histplot(data=train, x=\"Pclass\", y=\"Survived\", hue = \"Survived\", cbar=True, palette = 'husl')","f9fbb2ff":"train_encoded = pd.get_dummies(train)\ntrain = train_encoded\ntrain","7a21e6ad":"X = train.drop([\"Survived\"], axis = 1)\nX","9cb7cfa4":"y = train[\"Survived\"]\ny","1ae5bf98":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nX.shape","2cc42cfc":"from sklearn.model_selection import train_test_split \nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","60f5790d":"from sklearn.svm import SVC \nsvc = SVC()\nfrom sklearn.model_selection import GridSearchCV\nparam_grid = {\n    'C': [0.1,1, 10], \n    'gamma': [1,0.1,0.01],\n   }\ngrid = GridSearchCV(svc,param_grid,refit=True)\ngrid.fit(X_train, y_train)","4e5230cc":"grid.best_estimator_","35f3834e":"grid.best_score_","dbbb8729":"pd.DataFrame(grid.cv_results_)","b1916818":"f,ax = plt.subplots(figsize = (10,6))\nsns.barplot(data = grid.cv_results_, x = 'param_gamma', y = 'mean_test_score', ax=ax, palette = 'rocket_r')\nax.set(ylim=(0.7, 0.9))\nax.set(title=\"Grid Search SVM score\")\nax.set(xlabel=\"gamma\", ylabel=\"Mean Test Score\")","10be4edc":"model = grid.best_estimator_","de3e36cf":"from sklearn.metrics import classification_report, confusion_matrix\ny_pred = model.predict(X_val)\nprint(classification_report(y_val, y_pred))","e8349032":"cn_matrix = confusion_matrix(y_val, y_pred, labels = [0,1])\ncn_matrix","a1bebad6":"f, ax = plt.subplots(figsize = (10,8))\nax = sns.heatmap(cn_matrix, annot=True)\nax.set_xlabel(\"Predicted\")\nax.set_ylabel(\"True\")\nax.set_title(\"Confusion Matrix\")\n","c3b07b09":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(y_val, y_pred)\nroc_auc = auc(fpr, tpr)","ef02b317":"plt.figure(figsize = (10,8))\nplt.plot(fpr, tpr, color = 'magenta', lw = 2, label = 'ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([1,0], [1,0], color = 'navy', lw = 2, linestyle = '--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title(\"Receiver Operating Characteristic curve\")\nplt.legend(loc = 'lower right')","b2174949":"test= pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest","6ae332fa":"test = test.drop([\"Name\", \"Ticket\", \"Fare\", \"Embarked\", \"Cabin\"], axis=1)\ntest\n","3c7466d2":"test.isnull().sum()","667a3aa6":"female = (test[\"Sex\"] == \"female\")\nfemale.sum()\navg_age_female = (test[female][\"Age\"].mean())\nround(avg_age_female,1) \ntest_female = (test[female][\"Age\"]).fillna(value=avg_age_female)\ntest_female.astype('int')","6ec32256":"male = (test[\"Sex\"] == \"male\")\nmale.sum()\navg_age_male = (test[male][\"Age\"].mean())\nround(avg_age_male,1) \ntest_male = (test[male][\"Age\"]).fillna(value=avg_age_male)\ntest_male.astype('int')","897357cb":"test[\"Age\"] = pd.concat([test_female, test_male])\ntest[\"Age\"] = test[\"Age\"].astype('int')\ntest","e3af1c9b":"test_encoded = pd.get_dummies(test)\ntest_encoded\n","99ac467b":"test = scaler.transform(test_encoded)\ntest.shape","9a27db24":"model.fit(X, y)\ntarget = model.predict(test)\ntarget","43184d41":"df = pd.DataFrame(np.array(target), columns=[\"Survived\"])\ndf","5fe96949":"gendersubmission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")","6ec78bbf":"df[[\"PassengerId\"]] = gendersubmission.PassengerId\noutput = df[[\"PassengerId\", \"Survived\", ]]\noutput","f3c843e7":"output.to_csv('Submission.csv', index=False)\n","ad3bdd35":"##### *The train set is Cross validated on various classification models like LogisticRegression, Kneighbors classifier, Support Vector Machines, DecisionTree Classifier, Random Forest Classifier, Naive Bayes Classifier & Gradient Boosting Classifier*","0b77c529":"# Model Evaluation","375ac1df":"##### *Tuning the 'C' and 'gamma' parameters using Gridsearch, 'C' reduces error & 'gamma' decides the decision boundry* ","732f7b7b":"# Target prediction","0352336d":"# Train data cleaning & preprocessing","c662c268":"### Our Features and Target \n##### *X is the feature data set, y is the target variable*","d4801faa":"### drop duplicate\/unimportant features. \n##### *Columns \"Ticket\" & \"Fare\" duplicate the information of \"Pclass\", so we can drop those 2 features*\n##### *Column \"Embarked\" does not provide any vital information to our target, Column \"Cabin\" has mostly missing values, so we can drop them too!*","4f34ecc1":"### Area under the ROC Curve is 0.80, it shows that our model gives a good performance","a4badb1f":"# Model Validation","c9617dae":"# Classification Report & Confusion Matrix","e6b4fde0":"##### *Selecting Support Vector Machine model based on the best performance on our training set, other good performers are Naive Bayes and Gradient Boosting Classifier models!*","15372fd6":"##### *Basic library imports*","30694ef1":"# Evaluate test data","43b6adb5":"##### *Pairwise relationships in train data*","451234b0":"### fill null values in Age \n##### *calc avg age of men, women and fill in the null values*","b48469b0":"### Test Data\n","d001390c":"# Exploratory Data Analysis","c766c14c":"### Preprocessing Standardisation\n##### *Standardising the features*","be68c877":"# Test Data cleaning & preprocessing","f9c05e97":"### Our final tuned model to fit our test data!","6b1171c2":"### Train Data\n","a35d36f6":"# Train and Validation sets\n##### *Splitting train set into train set and validation set for testing performance within train data*","14fc3288":"# Hyperparameter Tuning","a4a02155":"##### *concat male, female in Age column*","8773e17f":"### Encoding categorical features on train data","b1467974":"# Feature Extraction","d047fc39":"### check for Null values"}}