{"cell_type":{"b294e2db":"code","2ebf45ee":"code","0f44eda5":"code","5ac9ba10":"code","7d491aa4":"code","30175693":"markdown","b2f6a58b":"markdown","58d7129a":"markdown","6d93f53c":"markdown","6406979c":"markdown","f3165930":"markdown"},"source":{"b294e2db":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor\nfrom sklearn.linear_model import PassiveAggressiveRegressor, ARDRegression, RidgeCV\nfrom sklearn.linear_model import TheilSenRegressor, RANSACRegressor, HuberRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.svm import SVR, LinearSVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor, VotingRegressor, StackingRegressor\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.cross_decomposition import PLSRegression","2ebf45ee":"reg_dict = {\"LinearRegression\": LinearRegression(),\n            \"Ridge\": Ridge(),\n            \"Lasso\": Lasso(),\n            \"ElasticNet\": ElasticNet(), \n            \"Polynomial_deg2\": Pipeline([('poly', PolynomialFeatures(degree=2)),('linear', LinearRegression())]),\n            \"Polynomial_deg3\": Pipeline([('poly', PolynomialFeatures(degree=3)),('linear', LinearRegression())]),\n            \"Polynomial_deg4\": Pipeline([('poly', PolynomialFeatures(degree=4)),('linear', LinearRegression())]),\n            \"Polynomial_deg5\": Pipeline([('poly', PolynomialFeatures(degree=5)),('linear', LinearRegression())]),\n            \"KNeighborsRegressor\": KNeighborsRegressor(n_neighbors=3),\n            \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n            \"RandomForestRegressor\": RandomForestRegressor(),\n            \"SVR_rbf\": SVR(kernel='rbf', C=1e3, gamma=0.1, epsilon=0.1, degree=3),\n            \"SVR_linear\": SVR(kernel='linear', C=1e3, gamma=0.1, epsilon=0.1, degree=3),\n            \"GaussianProcessRegressor\": GaussianProcessRegressor(),\n            \"SGDRegressor\": SGDRegressor(),\n            \"MLPRegressor\": MLPRegressor(hidden_layer_sizes=(10,10), max_iter=100, early_stopping=True, n_iter_no_change=5),\n            \"ExtraTreesRegressor\": ExtraTreesRegressor(n_estimators=100), \n            \"PassiveAggressiveRegressor\": PassiveAggressiveRegressor(max_iter=100, tol=1e-3),\n            \"TheilSenRegressor\": TheilSenRegressor(random_state=0),\n            \"RANSACRegressor\": RANSACRegressor(random_state=0),\n            \"HistGradientBoostingRegressor\": HistGradientBoostingRegressor(),\n            \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0, n_estimators=100),\n            \"BaggingRegressor\": BaggingRegressor(base_estimator=SVR(), n_estimators=10),\n            \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n            \"VotingRegressor\": VotingRegressor([('lr', LinearRegression()), ('rf', RandomForestRegressor(n_estimators=10))]),\n            \"StackingRegressor\": StackingRegressor(estimators=[('lr', RidgeCV()), ('svr', LinearSVR())], final_estimator=RandomForestRegressor(n_estimators=10)),\n            \"ARDRegression\": ARDRegression(),\n            \"HuberRegressor\": HuberRegressor(),\n            }","0f44eda5":"def make_future_dates(last_date, period):\n    prediction_dates=pd.date_range(last_date, periods=period+1, freq='B')\n    return prediction_dates[1:]\n\ndef prepare_data(data2, forecast_out):\n    label = np.roll(data2, -forecast_out).reshape((-1))\n    X = data2; \n    X_lately = X[-forecast_out:]\n    X = X[:-forecast_out] \n    y = label[:-forecast_out] \n    return [X, y, X_lately];\n\n# load data\ndata = pd.read_csv('..\/input\/ntt-data-global-ai-challenge-06-2020\/COVID-19_and_Price_dataset.csv',header=0,parse_dates=[0])\ndata=data[[\"Date\",\"Price\"]].tail(100)\ndata=data.set_index('Date',drop=True)\n\n# prepare data\nforecast_out = 34\nx_train, y_train, X_lately = prepare_data(data,forecast_out)\n\n# feature Scaling\nstdsc = StandardScaler()\nx_train_std = stdsc.fit_transform(x_train)\ny_train_std = stdsc.transform(y_train.reshape(-1, 1))\nX_lately_std = stdsc.transform(X_lately)\n\n# prediction\nfuture_dates = make_future_dates(data.index[-1],forecast_out)\ndf_preds=pd.DataFrame({\"Date\":future_dates})\ndf_preds=df_preds.set_index('Date',drop=True)\nfor reg_name, reg in reg_dict.items():\n    reg.fit(x_train_std, y_train_std)\n    prediction = reg.predict(X_lately_std)\n    prediction = stdsc.inverse_transform(prediction.reshape((-1)))\n    df_preds[reg_name] = pd.DataFrame({'Price':prediction},index=future_dates)","5ac9ba10":"def disp_all(mode='entire'):\n    plt.figure(figsize=(16, 8))\n    for col in df_preds.columns:\n        plt.plot(df_preds.index[-len(df_preds):], df_preds[col][-len(df_preds):],label=col)\n\n    if mode is 'entire':\n        plt.plot(data.index[-100:], data['Price'].tail(100),label=\"Actual\")\n        plt.vlines([data.index[-1]], 0, 60, \"red\", linestyles='dashed')\n        plt.text([data.index[-1]], 60, 'Today', backgroundcolor='white', ha='center', va='center')\n        plt.vlines([data.index[-1-75]], 0, 60, \"red\", linestyles='dashed')\n        plt.text([data.index[-1-75]], 60, '75 days before', backgroundcolor='white', ha='center', va='center')\n        plt.vlines([df_preds.index[-1]], 0, 60, \"red\", linestyles='dashed')\n        plt.text([df_preds.index[-1]], 60, '34 days after', backgroundcolor='white', ha='center', va='center')\n    plt.ylim(0, 80)\n    plt.title('Predictions ('+mode+')')\n    plt.xlabel('Date')\n    plt.ylabel('Price')\n    plt.legend(loc='best',ncol=2)\n    plt.grid(True)\n    plt.show()\n    \ndisp_all('entire')\ndisp_all('zoom')","7d491aa4":"template = pd.read_csv('..\/input\/ntt-data-global-ai-challenge-06-2020\/sampleSubmission0710_updated.csv',header=0,parse_dates=[0])\ntemplate.drop(\"Price\",axis=1,inplace=True)\n\ndf2 = data.copy() \nfor col in df_preds.columns:\n    df2[col] = data['Price'].copy() \ndf2 = pd.concat([df2, df_preds])\ndf2.drop(\"Price\",axis=1,inplace=True)\n\nfor col in df2.columns:\n    submission = pd.merge(template, df2[col], on='Date', how='left')\n    submission.rename(columns={col: 'Price'},inplace=True)\n    if submission[\"Price\"].isnull().any():\n        submission[\"Price\"].fillna(submission[\"Price\"].mean(),inplace=True)\n    submission[\"Price\"] = submission[\"Price\"].round(9)\n    submission.to_csv(\"submission_\" + col + \".csv\", index=False)","30175693":"# Define regression models","b2f6a58b":"Good luck!","58d7129a":"# Creating submission file","6d93f53c":"# Importing the libraries","6406979c":"# Display all result","f3165930":"# Prediction"}}