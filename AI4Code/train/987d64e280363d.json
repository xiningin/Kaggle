{"cell_type":{"5cc43062":"code","fa6ee126":"code","5f4120ab":"code","dda17ae5":"code","8ac4bb2f":"code","30732a21":"code","feab7e2e":"code","627eb198":"code","eb8bc15f":"code","a7bb33f5":"code","765ca6f6":"code","2c2f724f":"code","fdc50e6b":"code","d471b58f":"code","3f5df910":"code","8435ee7a":"code","b72c696e":"code","9bcf5074":"code","1b0e58ff":"code","94d5f46e":"code","39a00e8d":"code","02d5480b":"code","fa59f465":"code","10920100":"code","c2d30ca1":"code","d43a42fb":"code","e0ebcd1d":"code","77494878":"code","bd54f8e5":"code","bcad4b3b":"code","a2f0819a":"code","4e6a272e":"code","7a4dcd3c":"code","777f6a3a":"code","2c2344aa":"code","72f2b455":"code","efcdb628":"code","60db705e":"code","dd9c9741":"markdown","350c177b":"markdown","280f9f5f":"markdown","cfca3bf2":"markdown","0bd95230":"markdown","0e1f399a":"markdown","1e747bfc":"markdown","3b630df5":"markdown","5c736a22":"markdown","c89d308b":"markdown","4020203b":"markdown","0e64a369":"markdown","8048ff22":"markdown","0326f04a":"markdown","853d3091":"markdown","237bf38c":"markdown","86581478":"markdown","1688a6fd":"markdown","a027e5d0":"markdown"},"source":{"5cc43062":"import numpy as np\nimport os\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn; sn.set(font_scale=1.4)\nfrom sklearn.utils import shuffle           \nimport matplotlib.pyplot as plt             \nimport cv2                                 \nimport tensorflow as tf                \nfrom tqdm import tqdm\nfrom keras.preprocessing import image\nfrom keras import applications\n#import efficientnet\nfrom keras import callbacks\nfrom keras.models import Sequential\n","fa6ee126":"!pip install -U efficientnet","5f4120ab":"class_names = ['mountain', 'street', 'glacier', 'buildings', 'sea', 'forest']\nclass_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n\nnb_classes = len(class_names)\n\nIMAGE_SIZE = (150, 150)","dda17ae5":"class_names_label","8ac4bb2f":"def load_data():\n    \"\"\"\n        Load the data:\n            - 14,034 images to train the network.\n            - 3,000 images to evaluate how accurately the network learned to classify images.\n    \"\"\"\n    \n    datasets = ['..\/input\/intel-image-classification\/seg_train\/seg_train', '..\/input\/intel-image-classification\/seg_test\/seg_test']\n    output = []\n    \n    # Iterate through training and test sets\n    for dataset in datasets:\n        \n        images = []\n        labels = []\n        \n        print(\"Loading {}\".format(dataset))\n        \n        # Iterate through each folder corresponding to a category\n        for folder in os.listdir(dataset):\n            label = class_names_label[folder]\n            \n            # Iterate through each image in our folder\n            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n                \n                # Get the path name of the image\n                img_path = os.path.join(os.path.join(dataset, folder), file)\n                \n                # Open and resize the img\n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, IMAGE_SIZE) \n                \n                # Append the image and its corresponding label to the output\n                images.append(image)\n                labels.append(label)\n                \n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')   \n        \n        output.append((images, labels))\n\n    return output","30732a21":"(train_images, train_labels), (test_images, test_labels) = load_data()","feab7e2e":"train_images[0].shape","627eb198":"train_images, train_labels = shuffle(train_images, train_labels, random_state=7)","eb8bc15f":"train_labels_unique, train_counts = np.unique(train_labels, return_counts=True)\ntest_labels_unique, test_counts = np.unique(test_labels, return_counts=True)\npd.DataFrame({'train': train_counts,\n                    'test': test_counts}, \n             index=class_names\n            ).plot.bar()\nplt.show()","a7bb33f5":"n_train = train_labels.shape[0]\nn_test = test_labels.shape[0]\n\nprint (\"Number of training examples: {}\".format(n_train))\nprint (\"Number of testing examples: {}\".format(n_test))\nprint (\"Each image -RGB  shape is: {}\".format(IMAGE_SIZE))","765ca6f6":"plt.pie(train_counts,\n        explode=(0, 0, 0, 0, 0, 0) , \n        labels=class_names,\n        autopct='%1.1f%%')\nplt.axis('equal')\nplt.title('Proportion of each observed category')\nplt.show()","2c2f724f":"train_images = train_images \/ 255.0 \ntest_images = test_images \/ 255.0","fdc50e6b":"def display_random_image(class_names, images, labels):\n    \"\"\"\n        Display a random image from the images array and its correspond label from the labels array.\n    \"\"\"\n    \n    index = np.random.randint(images.shape[0])\n    plt.figure()\n    plt.imshow(images[index])\n    plt.xticks([])\n    plt.yticks([])\n    #plt.grid(False)\n    plt.title('Image #{} : '.format(index) + class_names[labels[index]])\n    plt.show()","d471b58f":"display_random_image(class_names, train_images, train_labels)","3f5df910":"def display_examples(class_names, images, labels):\n    \"\"\"\n        Display 25 images from the images array with its corresponding labels\n    \"\"\"\n    \n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(images[i], cmap=plt.cm.binary)\n        plt.xlabel(class_names[labels[i]])\n    plt.show()","8435ee7a":"display_examples(class_names, train_images, train_labels)","b72c696e":"#model.summary()","9bcf5074":"def plot_accuracy_loss(history,model_name):\n    \"\"\"\n        Plot the accuracy and the loss during the training of the nn.\n    \"\"\"\n    fig = plt.figure(figsize=(10,5))\n\n    # Plot accuracy\n    plt.subplot(221)\n    plt.plot(history.history['acc'],'bo--', label = \"acc\")\n    plt.plot(history.history['val_acc'], 'ro--', label = \"val_acc\")\n    plt.title(\"train_acc vs val_acc\" + model_name)\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epochs\")\n    plt.legend()\n\n    # Plot loss function\n    plt.subplot(222)\n    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n    plt.title(\"train_loss vs val_loss\"  + model_name)\n    plt.ylabel(\"loss\")\n    plt.xlabel(\"epochs\")\n\n    plt.legend()\n    plt.show()","1b0e58ff":"model = applications.VGG19(weights='imagenet', include_top=False)\n\ntrain_features = model.predict(train_images)\ntest_features = model.predict(test_images)","94d5f46e":"n_train, x, y, z = train_features.shape\nn_test, x, y, z = test_features.shape\nnumFeatures = x * y * z","39a00e8d":"model2 = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape = (x, y, z)),\n    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n])\n\nmodel2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n\nhistory2 = model2.fit(train_features, train_labels, batch_size=512, epochs=25, validation_split = 0.25)","02d5480b":"plot_accuracy_loss(history2,\"VGG19\")","fa59f465":"test_loss = model2.evaluate(test_features, test_labels)\ndel model\ndel model2","10920100":"model = applications.InceptionV3(weights='imagenet', include_top=False)","c2d30ca1":"train_features = model.predict(train_images)\ntest_features = model.predict(test_images)\nn_train, x, y, z = train_features.shape\nn_test, x, y, z = test_features.shape\nnumFeatures = x * y * z\n\nmodel2 = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape = (x, y, z)),\n    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n])","d43a42fb":"model2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n\nhistory2 = model2.fit(train_features, train_labels, batch_size=128, epochs=15, validation_split = 0.2)\nplot_accuracy_loss(history2,\"InceptionV3\")","e0ebcd1d":"test_loss = model2.evaluate(test_features, test_labels)\ndel model\ndel model2","77494878":"model = applications.InceptionResNetV2(weights='imagenet', include_top=False)","bd54f8e5":"train_features = model.predict(train_images)\ntest_features = model.predict(test_images)\nn_train, x, y, z = train_features.shape\nn_test, x, y, z = test_features.shape\nnumFeatures = x * y * z\n\nmodel2 = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape = (x, y, z)),\n    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n])","bcad4b3b":"model2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n\nhistory2 = model2.fit(train_features, train_labels, batch_size=256, epochs=25, validation_split = 0.25)\nplot_accuracy_loss(history2,\"InceptionResNetV2\")","a2f0819a":"test_loss = model2.evaluate(test_features, test_labels)\ndel model\ndel model2","4e6a272e":"model_DenseNet201 = applications.DenseNet201(weights='imagenet', include_top=False)\ntrain_features_DenseNet201 = model_DenseNet201.predict(train_images)\ntest_features_DenseNet201 = model_DenseNet201.predict(test_images)\nn_train, x, y, z = train_features_DenseNet201.shape\nn_test, x, y, z = test_features_DenseNet201.shape\n\nmodel2_DenseNet201 = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape = (x, y, z)),\n    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n])","7a4dcd3c":"model2_DenseNet201.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n\nhistory2_DenseNet201 = model2_DenseNet201.fit(train_features_DenseNet201, train_labels, batch_size=1024, epochs=30, validation_split = 0.15)\nplot_accuracy_loss(history2_DenseNet201,\"DenseNet201\")","777f6a3a":"test_loss = model2_DenseNet201.evaluate(test_features_DenseNet201, test_labels)\ndel model_DenseNet201\ndel model2_DenseNet201","2c2344aa":"from efficientnet.keras import EfficientNetB7","72f2b455":"if 0 :\n    model = EfficientNetB7(weights='imagenet', include_top=False)\n    train_features = model.predict(train_images)\n    test_features = model.predict(test_images)\n    n_train, x, y, z = train_features.shape\n    n_test, x, y, z = test_features.shape\n\n    model2 = tf.keras.Sequential([\n        tf.keras.layers.Flatten(input_shape = (x, y, z)),\n        tf.keras.layers.Dense(100, activation=tf.nn.relu),\n        tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n    ])","efcdb628":"if 0 :   \n    model2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n\n    history2 = model2.fit(train_features, train_labels, batch_size=1024, epochs=30, validation_split = 0.15)\n    plot_accuracy_loss(history2,\"EfficientNetB7\")","60db705e":"if 0 :   \ntest_loss = model2.evaluate(test_features, test_labels)","dd9c9741":"We fit the model to the data from the training set. The neural network will learn by itself the pattern in order to distinguish each category.","350c177b":"# InceptionResNetV2","280f9f5f":"![image.png](attachment:image.png)","cfca3bf2":"# Loading the Data\nWe have to write a load_data function that load the images and the labels from the folder.","0bd95230":"## Scal image dataset","0e1f399a":"![image.png](attachment:image.png)","1e747bfc":"# Import Packages","3b630df5":"# InceptionV3","5c736a22":"# EfficientNet","c89d308b":"We can also display the first 25 images from the training set directly with a loop to get a better view","4020203b":"# DenseNet201","0e64a369":"![image.png](attachment:image.png)","8048ff22":"# Intel image multi label classification using transfer learning\n\nmulti label CNN Classification for: \n\nmountain, street, glacier, buildings, sea,forest\n\nI'll try different type of networks while using transfer learning\n\nhttps:\/\/towardsdatascience.com\/illustrated-10-cnn-architectures-95d78ace614d","0326f04a":"# explore the dataset\n","853d3091":"![image.png](attachment:image.png)","237bf38c":"Model is allocating too much memory - need to run standalone ","86581478":"## Visualize the data\nWe can display a random image from the training set.","1688a6fd":"# VGG19","a027e5d0":"## Huge thanks for Vincent Liu :) "}}