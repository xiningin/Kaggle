{"cell_type":{"73b05fb2":"code","749d8f5a":"code","ac891411":"markdown"},"source":{"73b05fb2":"import numpy as np\nimport pandas as pd\nimport os\nimport pathlib\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom keras.preprocessing import image\n\ndata_dir = pathlib.Path(os.path.join('\/kaggle\/input\/dandelionimages','Images'))\n\nbatch_size = 16\nimg_height = 180\nimg_width = 180\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=212,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)\n\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=212,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)\n\nclass_names = train_ds.class_names\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n\nnum_classes = 2\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255,input_shape=(img_height, img_width, 3)),\n    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n    tf.keras.layers.Conv2D(16, 3, padding='same'),\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(rate=0.5),\n    tf.keras.layers.Dense(4),\n    tf.keras.layers.Dense(num_classes)\n    \n])\n\nmodel.summary()\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nepochs=60\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)\n\nmodel.save('Model1\/my_model',overwrite=True)","749d8f5a":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        random_num = np.random.randint(0, len(images))\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[random_num].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[random_num]])\n        plt.axis(\"off\")\n\n\n\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\n\nplt.show()\n","ac891411":"The training and validation accuracy are similar, and the loss function also. This means we do not have overfitting.\nData augmentation in the form of Randomflip and Randomrotation along with a dropout layer were added to achieve this.\nIt was noticed that having an activation function like relu or sigmoid in the dense layer before the final output layer,\ncaused convergence problems where the loss function would often get stuck in a local minimum."}}