{"cell_type":{"46f97ea1":"code","7b2ebf99":"code","fa21cfd7":"code","714c5b45":"code","c7ef118d":"code","fd5c92a9":"code","8c5d4dcd":"code","cc9e8d38":"code","616a63a2":"code","1e500890":"code","e0b4da1b":"code","b4733990":"code","c57120c7":"code","6fc22a50":"code","fede825d":"code","3dd4b3e9":"code","b05eec7c":"code","399d38a8":"code","a96973c1":"code","314c36d6":"code","a739be85":"code","eef82d24":"code","8aed3b73":"code","d97f3f3a":"code","9f0e2f35":"code","3e9a29a6":"code","75ca07b7":"code","1bae4824":"code","49aaba75":"code","12f7015c":"code","1a97eaa8":"code","2e4ca859":"code","b62fb1c1":"code","913effa2":"code","45c8b6af":"code","abd46188":"code","ce24ec55":"code","186d623e":"code","d5b36654":"code","16994dae":"markdown","6e3a9da0":"markdown","13bc16de":"markdown","01995b52":"markdown"},"source":{"46f97ea1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7b2ebf99":"df = pd.read_csv('..\/input\/water-potability\/water_potability.csv')","fa21cfd7":"df.head()","714c5b45":"df.isnull().sum()","c7ef118d":"print(\"number of rows: \", df.shape[0])\nprint(\"number of column: \", df.shape[1])\ndf.Potability.value_counts()","fd5c92a9":"#df = df.dropna() # dropping all row with null values\ndf_notpotable  = df[df['Potability']==0]\ndf_potable = df[df['Potability']==1] ","8c5d4dcd":"df_notpotable.isnull().sum()","cc9e8d38":"df_potable.isnull().sum()","616a63a2":"from sklearn.impute import SimpleImputer\n\nimpute = SimpleImputer(missing_values=np.nan, strategy = 'mean')\n\n#for df_notpotable\nimpute.fit(df_notpotable[['ph']])\nimpute.fit(df_notpotable[['Sulfate']])\nimpute.fit(df_notpotable[['Trihalomethanes']])\n\ndf_notpotable['ph'] = impute.transform(df_notpotable[['ph']])\ndf_notpotable['Sulfate'] = impute.transform(df_notpotable[['Sulfate']])\ndf_notpotable['Trihalomethanes'] = impute.transform(df_notpotable[['Trihalomethanes']])\n\n#for df_potable\nimpute.fit(df_potable[['ph']])\nimpute.fit(df_potable[['Sulfate']])\nimpute.fit(df_potable[['Trihalomethanes']])\n\ndf_potable['ph'] = impute.transform(df_potable[['ph']])\ndf_potable['Sulfate'] = impute.transform(df_potable[['Sulfate']])\ndf_potable['Trihalomethanes'] = impute.transform(df_potable[['Trihalomethanes']])","1e500890":"df_notpotable.isnull().sum()","e0b4da1b":"df.Potability.value_counts()","b4733990":"df_potable.isnull().sum()","c57120c7":"df = pd.concat([df_notpotable, df_potable])","6fc22a50":"df.head()","fede825d":"df = df.sample(frac = 1) # shuffling the rows","3dd4b3e9":"df.head()","b05eec7c":"x = df.drop('Potability', axis = 1) #getting x\ny = df['Potability'] #getting y ","399d38a8":"from sklearn.preprocessing import MinMaxScaler\n#Now, lets scale all the value in x within 0 to 1...\nscaler = MinMaxScaler() # creating object of MinMaxScaler\nscaler.fit(x)\n\nx = scaler.transform(x)\n\nx = pd.DataFrame(x)\nx","a96973c1":"df.hist(bins=10, figsize=(20,15), color = 'teal')","314c36d6":"import matplotlib.pyplot as plt\nfig = plt.figure(figsize=(25,10))\n \np1 = fig.add_subplot(2,2,1)\np1.hist(df.ph[df.Potability == 0], bins=20, alpha = .4)\np1.hist(df.ph[df.Potability == 1], bins=20, alpha = .4)\nplt.title('pH')\nplt.xlabel('pH')\nplt.ylabel('Count')\nlabels = [\"0\", \"1\"]\nplt.legend(labels)\n\np1 = fig.add_subplot(2,2,2)\np1.hist(df.Hardness[df.Potability == 0], bins=20, alpha = .4)\np1.hist(df.Hardness[df.Potability == 1], bins=20, alpha = .4)\nplt.title('Hardness')\nplt.xlabel('Hardness')\nplt.ylabel('Count')\nlabels = [\"0\", \"1\"]\nplt.legend(labels)\n\np1 = fig.add_subplot(2,2,3)\np1.hist(df.Solids[df.Potability == 0], bins=20, alpha = .4)\np1.hist(df.Solids[df.Potability == 1], bins=20, alpha = .4)\nplt.title('Solids')\nplt.xlabel('Solids')\nplt.ylabel('Count')\nlabels = [\"0\", \"1\"]\nplt.legend(labels)\n\np1 = fig.add_subplot(2,2,4)\np1.hist(df.Chloramines[df.Potability == 0], bins=20, alpha = .4)\np1.hist(df.Chloramines[df.Potability == 1], bins=20, alpha = .4)\nplt.title('Chloramines')\nplt.xlabel('Chloramines')\nplt.ylabel('Count')\nlabels = [\"0\", \"1\"]\nplt.legend(labels)\n \nplt.subplots_adjust(wspace=.1, hspace=.3)\nplt.show()","a739be85":"count_classes = pd.value_counts(y,sort=True)\ncount_classes.plot(kind = 'bar', rot = 0)\nplt.title(\"Potability Class Distribution\")\nplt.xticks(range(2))\nplt.xlabel(\"Potability\")\nplt.ylabel(\"Frequency\")","eef82d24":"zero = df[df['Potability']==0]\none = df[df['Potability']==1]","8aed3b73":"print(zero.shape,one.shape)","d97f3f3a":"from imblearn.over_sampling import SMOTE\noversample = SMOTE()\nx_res, y_res = oversample.fit_resample(x, y)","9f0e2f35":"x_res.shape,y_res.shape","3e9a29a6":"count_classes = pd.value_counts(y_res,sort=True)\ncount_classes.plot(kind = 'bar', rot = 0)\nplt.title(\"Potability Class Distribution\")\nplt.xticks(range(2))\nplt.xlabel(\"Potability\")\nplt.ylabel(\"Frequency\")","75ca07b7":"from numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\n\n# prepare the cross-validation procedure\ncv = KFold(n_splits=10, random_state=1, shuffle=True)\n\nrandomForestClassifier = RandomForestClassifier(n_estimators = 1000)\n\nscores = cross_val_score(randomForestClassifier, x_res, y_res, scoring='accuracy', cv=cv, n_jobs=-1)\n\nprint('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))","1bae4824":"#to plot accuracy bar\naccuracy_list ={}\naccuracy_list[\"K fold with RF\"] = (mean(scores)*100)","49aaba75":"# fit model no training data\n\nfrom xgboost import XGBClassifier\n\nxgbClassifier = XGBClassifier()\nscores = cross_val_score(xgbClassifier, x_res, y_res, scoring='accuracy', cv=cv, n_jobs=-1)\nprint('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))","12f7015c":"accuracy_list[\"K fold with XG Boost\"] = (mean(scores)*100)\nprint(accuracy_list)","1a97eaa8":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, stratify = y)\ny_train = pd.Series(y_train)","2e4ca859":"from sklearn.metrics import accuracy_score\n#Random Forest\nrandomForestClassifier = RandomForestClassifier(n_estimators = 1000)\nrandomForestClassifier.fit(x_train, y_train.values.ravel())\npredictionsRandomForestClassifier = randomForestClassifier.predict(x_test)\naccuracyRandomForestClassifier = accuracy_score(predictionsRandomForestClassifier, y_test)\nprint(accuracyRandomForestClassifier)","b62fb1c1":"accuracy_list[\"Random Forest\"] = accuracyRandomForestClassifier*100\nprint(accuracy_list)","913effa2":"# fit model no training data\nmodel = XGBClassifier(use_label_encoder = False)\nmodel.fit(x_train, y_train,verbose=True)\nprint(model)","45c8b6af":"\n# make predictions for test data\ny_pred = model.predict(x_test)\npredictions = [round(value) for value in y_pred]","abd46188":"# evaluate predictions\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","ce24ec55":"\naccuracy_list[\"XG Boost\"] = accuracy*100\nprint(accuracy_list)","186d623e":"import matplotlib.pyplot as plt\nprint(accuracy_list)","d5b36654":"names = list(accuracy_list.keys())\nvalues = list(accuracy_list.values())\n\nfig, axs = plt.subplots(3,1, figsize=(15, 15), sharey=True)\naxs[0].bar(names, values)\naxs[1].scatter(names, values)\naxs[2].plot(names, values)\nfig.suptitle('Categorical Plotting')","16994dae":"# Handling Null Values with Means","6e3a9da0":"# Classifiers","13bc16de":"# Normalizing the dataset","01995b52":"# OverSampling"}}