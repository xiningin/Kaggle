{"cell_type":{"ad3dceaf":"code","36e6f725":"code","6b2583cf":"code","c61aa464":"code","19081b63":"code","dd39226e":"code","8fcd7302":"code","fa79f924":"code","9e274e79":"code","bcf00ac2":"code","244eccc7":"code","db631f8f":"code","b32da4c1":"code","5a94aa67":"code","0d871f61":"code","5602e585":"code","504ec86c":"code","279b482b":"code","04beccf2":"code","50c1dbb9":"markdown","134e0b0a":"markdown","67398085":"markdown","f744729a":"markdown","8f5cf5a7":"markdown","9cbea5bc":"markdown","1e16f7d8":"markdown","6a3c7d0b":"markdown","f663208e":"markdown","d070034a":"markdown","cd88a652":"markdown","e0a402a0":"markdown","3f10496f":"markdown","a8ea83bd":"markdown"},"source":{"ad3dceaf":"import numpy as np\nimport pickle\nimport gzip\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport h5py\nimport sklearn\nimport sklearn.datasets\nimport scipy\n\nfrom PIL import Image\nfrom scipy import ndimage\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization, Activation\nfrom keras import regularizers\n\nnp.random.seed(7)\n\n\n%matplotlib inline","36e6f725":"import pickle\ndef load_data():\n    f = open('\/kaggle\/input\/mnist-handwriting\/mnist.pkl', 'rb')\n    f.seek(0)\n    training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n    f.close()\n    return (training_data, validation_data, test_data)","6b2583cf":"training_data, validation_data, test_data = load_data()","c61aa464":"training_data","19081b63":"print(\"The feature dataset is:\" + str(training_data[0]))\nprint(\"The target dataset is:\" + str(training_data[1]))\nprint(\"The number of examples in the training dataset is:\" + str(len(training_data[0])))\nprint(\"The number of points in a single input is:\" + str(len(training_data[0][1])))","dd39226e":"def one_hot(j):\n    # input is the target dataset of shape (1, m) where m is the number of data points\n    # returns a 2 dimensional array of shape (10, m) where each target value is converted to a one hot encoding\n    # Look at the next block of code for a better understanding of one hot encoding\n    n = j.shape[0]\n    new_array = np.zeros((10, n))\n    index = 0\n    for res in j:\n        new_array[res][index] = 1.0\n        index = index + 1\n    return new_array","8fcd7302":"data = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\none_hot(data)","fa79f924":"def data_wrapper():\n    tr_d, va_d, te_d = load_data()\n    \n    training_inputs = np.array(tr_d[0][:]).T\n    training_results = np.array(tr_d[1][:])\n    train_set_y = one_hot(training_results)\n    \n    validation_inputs = np.array(va_d[0][:]).T\n    validation_results = np.array(va_d[1][:])\n    validation_set_y = one_hot(validation_results)\n    \n    test_inputs = np.array(te_d[0][:]).T\n    test_results = np.array(te_d[1][:])\n    test_set_y = one_hot(test_results)\n    \n    return (training_inputs, train_set_y, validation_inputs, validation_set_y)","9e274e79":"train_set_x, train_set_y, test_set_x, test_set_y = data_wrapper()","bcf00ac2":"train_set_x = train_set_x.T\ntrain_set_y = train_set_y.T\ntest_set_x = test_set_x.T\ntest_set_y = test_set_y.T","244eccc7":"print (\"train_set_x shape: \" + str(train_set_x.shape))\nprint (\"train_set_y shape: \" + str(train_set_y.shape))\nprint (\"test_set_x shape: \" + str(test_set_x.shape))\nprint (\"test_set_y shape: \" + str(test_set_y.shape))","db631f8f":"index  = 13\nk = train_set_x[index,:]\nk = k.reshape((28, 28))\nplt.title('Label is {label}'.format(label= training_data[1][index]))\nplt.imshow(k, cmap='gray')\nplt.show()","b32da4c1":"# create model\nnn_model = Sequential()\nnn_model.add(Dense(35, input_dim=784, activation='relu'))\nnn_model.add(Dropout(0.3))\nnn_model.add(Dense(21, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nnn_model.add(Dense(10, activation='softmax'))","5a94aa67":"nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","0d871f61":"nn_model.fit(train_set_x, train_set_y, epochs=100, batch_size=50)","5602e585":"scores_train = nn_model.evaluate(train_set_x, train_set_y)\nprint(\"\\n%s: %.2f%%\" % (nn_model.metrics_names[1], scores_train[1]*100))","504ec86c":"predictions = nn_model.predict(test_set_x)\npredictions = np.argmax(predictions, axis = 1)\npredictions","279b482b":"scores_test = nn_model.evaluate(test_set_x, test_set_y)\nprint(\"\\n%s: %.2f%%\" % (nn_model.metrics_names[1], scores_test[1]*100))","04beccf2":"index  = 999\nk = test_set_x[index, :]\nk = k.reshape((28, 28))\nplt.title('Label is {label}'.format(label=(predictions[index], np.argmax(test_set_y, axis = 1)[index])))\nplt.imshow(k, cmap='gray')\nplt.show()","50c1dbb9":"Before we run the model on the training datasets, we compile the model in which we define various things like the loss function, the optimizer and the evaluation metric.","134e0b0a":"Now, let's see if the datasets are in the desired shape:","67398085":"In this assignment, you'll implement a L-layer deep model on MNIST dataset using Keras. The MNIST dataset contains tens of thousands of scanned images of handwritten digits, together with their correct classifications. MNIST's name comes from the fact that it is a modified subset of two data sets collected by NIST, the United States' National Institute of Standards and Technology.<br>\n","f744729a":"We can see that the model has ~ 99% accuracy on the training dataset.","8f5cf5a7":"The MNIST dataset we use here is 'mnist.pkl.gz' which is divided into training, validation and test data. The following function <i> load_data() <\/i> unpacks the file and extracts the training, validation and test data.","9cbea5bc":"Keras is a framework. So, to implement a neural network model in Keras, we first create an instance of Sequential(). <br>\nThe Sequential model is a linear stack of layers. We then keep adding Dense layers that are fully connected layers as we desire.<br><br>\nWe have included Dropout using <i> nn_model.add(Dropout(0.3)) <\/i> <br><br>\nWe can also include regularization using the command <br> <i> nn_model.add(Dense(21, activation='relu', kernel_regularizer=regularizers.l2(0.01))) <\/i> <br>instead of <br> <i> nn_model.add(Dense(21, activation='relu')) <\/i>","1e16f7d8":"For implementing in Keras, the input training and input target dataset are supposed to have shape (m, n) where m is the number of training samples and n is the number of parts in a single input.\n<br> Hence, let create the desired dataset shapes by taking transpose.","6a3c7d0b":"Try and look at the different test cases and check which all have gone wrong. Feel free to change the index numbers.","f663208e":"Now, let's make predictions on the test dataset.","d070034a":"Now, as discussed earlier in the lectures, the target variable is converted to a one hot matrix. We use the function <i> one_hot <\/i> to convert the target dataset to one hot encoding.","cd88a652":"Let's see how the data looks:","e0a402a0":"Now let us visualise the dataset. Feel free to change the index to see if the training data has been correctly tagged.","3f10496f":"Now, to fit the model on the training input and training target dataset, we run the following command using a minibatch of size 50 and 100 epochs.","a8ea83bd":"We can see that the model has ~97% accuracy on the training dataset."}}