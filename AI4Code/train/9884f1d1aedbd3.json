{"cell_type":{"b4f5a8f4":"code","2bd2c364":"code","81ae8abc":"code","a3fd2553":"code","6cff3637":"code","2b7985d6":"code","54fc4f7c":"code","e962ff17":"code","6c7ea053":"code","2673b2d1":"markdown","e107b61e":"markdown","17b1d336":"markdown","90552437":"markdown"},"source":{"b4f5a8f4":"import pandas as pd\nimport numpy as np\nfrom functools import partial\nimport os\nimport random\nimport joblib\nimport json\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score\nfrom scipy.optimize import differential_evolution\nimport tensorflow as tf\nfrom tensorflow import keras \nimport gc\nfrom functools import reduce\nfrom itertools import combinations, chain\nfrom tqdm import tqdm\nfrom sklearn.model_selection import KFold\nfrom itertools import chain\nimport warnings\nwarnings.filterwarnings(\"ignore\")","2bd2c364":"oof_predictions_v3 = joblib.load(\"..\/input\/cassava-leaf-disease-ensemble-tests\/oof_v04 (1).pkl\")","81ae8abc":"oof_predictions_v3.head(3)","a3fd2553":"# Build some promising stacks for evaluation\noof_predictions_v3.loc[:,\"vits\"] = oof_predictions_v3.apply(lambda x: [np.mean(v) for v in zip(x[\"vit2019\"],x[\"vit2020\"])], axis=1)\noof_predictions_v3.loc[:,\"vit_resnext\"] = oof_predictions_v3.apply(lambda x: [np.mean(v) for v in zip(x[\"vit2020\"],x[\"resnext\"])], axis=1)\n\ncolumns = oof_predictions_v3.columns[2:].tolist()","6cff3637":"combined = []\nfor i in range(len(columns)):\n    combined.append(list(combinations(columns, i+1)))\n\ndef evaluate_ensemble(df, columns):\n    return df[[*columns]].apply(lambda x: np.argmax([np.sum(v) for v in zip(*[x[c] for c in columns])]), axis=1).values\n\nresults = dict()\nwith tqdm(total=len(list(chain(*combined)))) as process_bar:\n    for c in list(chain(*combined)):\n        process_bar.update(1)  \n        results[c] = accuracy_score(oof_predictions_v3.label.values, evaluate_ensemble(oof_predictions_v3, c))","2b7985d6":"# Get top-50 combinations\n{k: results[k] for k in sorted(results, key=results.get, reverse=True)[0:50]}","54fc4f7c":"considered_models = oof_predictions_v3[[\"image_id\",\"label\",\"b4\",\"vit2020\",\"resnext\",\"mobilenet\"]]","e962ff17":"kfold = KFold(n_splits=4)\n\nyhats = considered_models.iloc[:,2:].values\ny = considered_models.label.values\nn_models = yhats.shape[1]\n\naccuracy = []\nfor fold, (train_idx, test_idx) in enumerate(kfold.split(yhats, y)):\n    \n    print(f\"Iteration {fold+1}\")\n    \n    weights = np.array([1.0\/n_models for _ in range(n_models)])\n    bounds = [(0.0, 1.0) for _ in range(n_models)]\n    minimizeargs = (np.take(yhats, train_idx, axis=0), np.take(y, train_idx, axis=0))\n    \n    def calculate_accuracy(y_true, y_pred):\n        return np.average(y_true == y_pred)\n\n    def loss_func(weights, Yhat, Y):\n        w = np.mean(weights * Yhat, axis=1)\n        return 1 - calculate_accuracy(Y, list(map(lambda x: np.argmax(x), w)))\n\n    sol = differential_evolution(loss_func, bounds, minimizeargs, maxiter=20, tol=1e-5, disp=True, seed=8)\n    \n    \n    # Calculate oof accuracy of optimized weights\n    oof_accuracy = calculate_accuracy(np.take(y, test_idx, axis=0),\n                                      list(map(lambda x: np.argmax(x), np.mean(\n                                          np.take(yhats, test_idx, axis=0) * sol.x, axis=1))))\n    \n    print(f\"{oof_accuracy}\")\n    \n    accuracy.append((sol.x, oof_accuracy))","6c7ea053":"#weights for ensembles of four different models\naccuracy","2673b2d1":"# Mean and Stacked Mean combinations\nWe used itertools.combinations to check all possible combinations for mean ensembles. In addition to the individual models, we also combined some models in advance. This was an easy way to try out the different combinations including diverse levels. In most cases, the calculated cross-validation scores were quite close to the public leaderboard results. Even after the final submission, the combinations proved to be very stable.","e107b61e":"# Differential Evolution\nAnother technique that we also used to obtain good and stable results in the rankings was a prior optimization of the weights of the softmax logits of each model. For optimization we used the [Scipy differential_evolution](https:\/\/docs.scipy.org\/doc\/scipy\/reference\/generated\/scipy.optimize.differential_evolution.html) method .","17b1d336":"# Loading Out-of-Fold Predictions for some of our tested models","90552437":"# Finding good ensembles to submit in competition\nWe tried different types of ensembles (e.g., means and meta learners). Our best submissions used a stacked mean approach and weights found via an optimization. These submissions scored around 91.3% on the public and also private leaderboard."}}