{"cell_type":{"e3c81b1c":"code","df9d0bf1":"code","63a3dde2":"code","58fdc9d0":"code","4591270b":"code","f2f60009":"code","869c2c19":"code","8c40bc54":"code","3cdacbbb":"code","ceab8895":"code","eb35b32b":"code","e67bee92":"code","6497c176":"code","65ebcbac":"code","939f57e3":"code","47bc1251":"code","497fd99b":"code","beecf6f0":"code","60a75552":"code","a2310b52":"code","66712b0d":"code","fc0995b0":"code","20036302":"code","3c5e9ac5":"code","e158310e":"code","cbed47f4":"code","eab9fcf9":"code","e3bb2c8b":"code","8c4a84a0":"code","25b6ff6d":"code","7ede00d1":"code","3f9d9b68":"code","b9cab321":"code","a4972053":"code","5990bb79":"code","dab4d560":"code","27dd8434":"code","91db12af":"code","bb9ebf96":"code","d0f44926":"code","33ce632f":"code","38e95ab2":"code","8050c99f":"code","2767c378":"code","c2ded834":"code","914e509d":"code","8ac4e522":"code","afc1bb15":"code","bd1ebe7d":"code","1029f1cd":"code","224921be":"code","3bf2fcca":"code","5789d09f":"code","ebf82b60":"code","5d730cc7":"code","bb2ba6c7":"code","e24af7d8":"code","110d6c75":"code","c01830b0":"markdown","5ed06236":"markdown","999ba127":"markdown","22639cee":"markdown","831780fc":"markdown","607ea9ef":"markdown","db688333":"markdown","6f9e13c9":"markdown","5c20cbe0":"markdown","3245ea79":"markdown","1572ece5":"markdown","e18472ed":"markdown","abc64f81":"markdown","435d9dce":"markdown","e3aa9eb8":"markdown","b0ed6b51":"markdown","9358ebbe":"markdown","32166821":"markdown","f3fb737a":"markdown","dbd29c74":"markdown","b5fbf816":"markdown","35940352":"markdown","31848494":"markdown","9ebebd77":"markdown","8e120cf1":"markdown","4ec827f9":"markdown","59dd25d5":"markdown","5686a871":"markdown","9f8e9d6e":"markdown","2d06dca2":"markdown","47c64b6a":"markdown","bdfca108":"markdown","a8c4098e":"markdown","01f85512":"markdown","c8d41a48":"markdown","78fa6930":"markdown","d8578d2e":"markdown","7610084f":"markdown","2d50f855":"markdown","5417af6f":"markdown","cc7c8de1":"markdown","9e49ae24":"markdown","57988f32":"markdown","d57c9ba4":"markdown","cd552ac4":"markdown","11733d89":"markdown","f132b077":"markdown","c49192fd":"markdown","1017bfc7":"markdown","05465f92":"markdown","ef95cf75":"markdown","c9a55133":"markdown"},"source":{"e3c81b1c":"# General Packages\nimport numpy as np\nimport pandas as pd\n\n# Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Machine Learning Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.neural_network import MLPClassifier\n\n# others\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# constant\nRANDOM_STATE = 10","df9d0bf1":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","63a3dde2":"train.head()","58fdc9d0":"train.info()","4591270b":"train.describe()","f2f60009":"test.head()","869c2c19":"test.info()","8c40bc54":"test.describe()","3cdacbbb":"drop_train = train.drop(['PassengerId','Name','Ticket','Cabin'], axis=1)\ndrop_train.head()","ceab8895":"drop_test = test.drop(['PassengerId','Name','Ticket','Cabin'], axis=1)\ndrop_test.head()","eb35b32b":"fig, ax = plt.subplots(figsize=(8,8))\nsns.heatmap(drop_train.corr(), annot=True, ax=ax)","e67bee92":"meanAgePclass1 = drop_train.loc[drop_train.Pclass == 1,'Age'].mean()\nmeanAgePclass2 = drop_train.loc[drop_train.Pclass == 2,'Age'].mean()\nmeanAgePclass3 = drop_train.loc[drop_train.Pclass == 3,'Age'].mean()\n\nprint('meanAgePclass1: {}'.format(meanAgePclass1))\nprint('meanAgePclass2: {}'.format(meanAgePclass2))\nprint('meanAgePclass3: {}'.format(meanAgePclass3))","6497c176":"modeEmbarked = drop_train.Embarked.mode().iloc[0]\nprint(type(modeEmbarked))\nprint('modeEmbarked: {}'.format(modeEmbarked))","65ebcbac":"meanFarePclass1 = drop_train.loc[drop_train.Pclass == 1,'Fare'].mean()\nmeanFarePclass2 = drop_train.loc[drop_train.Pclass == 2,'Fare'].mean()\nmeanFarePclass3 = drop_train.loc[drop_train.Pclass == 3,'Fare'].mean()\n\nprint('meanFarePclass1: {}'.format(meanFarePclass1))\nprint('meanFarePclass2: {}'.format(meanFarePclass2))\nprint('meanFarePclass3: {}'.format(meanFarePclass3))\n\nprint('row of missing Fare: \\n{}'.format(drop_test.loc[drop_test.Fare.isnull()]))","939f57e3":"imputer_train = drop_train\nimputer_train.loc[(imputer_train['Pclass'] == 1) & (imputer_train['Age'].isnull()), 'Age'] = meanAgePclass1\nimputer_train.loc[(imputer_train['Pclass'] == 2) & (imputer_train['Age'].isnull()), 'Age'] = meanAgePclass2\nimputer_train.loc[(imputer_train['Pclass'] == 3) & (imputer_train['Age'].isnull()), 'Age'] = meanAgePclass3\nimputer_train.loc[imputer_train['Embarked'].isnull(), 'Embarked'] = modeEmbarked\n\nimputer_train.info()                                                   ","47bc1251":"fig, ax = plt.subplots(figsize=(8,8))\nsns.heatmap(imputer_train.corr(), annot=True, ax=ax)","497fd99b":"imputer_test = drop_test\nimputer_test.loc[(imputer_test['Pclass'] == 1) & (imputer_test['Age'].isnull()), 'Age'] = meanAgePclass1\nimputer_test.loc[(imputer_test['Pclass'] == 2) & (imputer_test['Age'].isnull()), 'Age'] = meanAgePclass2\nimputer_test.loc[(imputer_test['Pclass'] == 3) & (imputer_test['Age'].isnull()), 'Age'] = meanAgePclass3\nimputer_test.loc[imputer_test['Fare'].isnull(), 'Fare'] = meanFarePclass3\n\nimputer_test.info()","beecf6f0":"imputer_train['Pclass'] = imputer_train['Pclass'].astype('str')\nimputer_train.info()","60a75552":"imputer_test['Pclass'] = imputer_test['Pclass'].astype('str')\nimputer_test.info()","a2310b52":"oneHot_train = pd.get_dummies(imputer_train)\noneHot_train.head()","66712b0d":"oneHot_test = pd.get_dummies(imputer_test)\noneHot_test.head()","fc0995b0":"X = oneHot_train.drop(['Survived'], axis=1)\nX.head()","20036302":"y = oneHot_train['Survived']\ny.head()","3c5e9ac5":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=RANDOM_STATE)\n\nprint('X_train: \\n{}'.format(X_train.head()))\nprint()\nprint('X_valid: \\n{}'.format(X_valid.head()))\nprint()\nprint('y_train: \\n{}'.format(y_train.head()))\nprint()\nprint('y_valid: \\n{}'.format(y_valid.head()))     ","e158310e":"# MinMaxScaler\nminmaxScaler = MinMaxScaler()\n\n# X_train, X_valid\nminmaxScaler.fit(X_train)\nX_train_minmaxScaled = minmaxScaler.transform(X_train)\nX_valid_minmaxScaled = minmaxScaler.transform(X_valid)\nprint('X_train_minmaxScaled:\\n{}'.format(X_train_minmaxScaled[:5,:]))\nprint()\nprint('X_train_minmaxScaled:\\n{}'.format(X_valid_minmaxScaled[:5,:]))\nprint()\n\n# X, test\nminmaxScaler.fit(X)\nX_minmaxScaled = minmaxScaler.transform(X)\ntest_minmaxScaled = minmaxScaler.transform(oneHot_test)\nprint('X_minmaxScaled:\\n{}'.format(X_minmaxScaled[:5,:]))\nprint()\nprint('test_minmaxScaled:\\n{}'.format(test_minmaxScaled[:5,:]))","cbed47f4":"# StandardScaler\n\n# X_train, X_valid\nstdScaler = StandardScaler()\nstdScaler.fit(X_train)\nX_train_stdScaled = stdScaler.transform(X_train)\nX_valid_stdScaled = stdScaler.transform(X_valid)\nprint('X_train_stdScaled:\\n{}'.format(X_train_stdScaled[:5,:]))\nprint()\nprint('X_valid_stdScaled:\\n{}'.format(X_valid_stdScaled[:5,:]))\nprint()\n\n# X, test\nstdScaler = StandardScaler()\nstdScaler.fit(X)\nX_stdScaled = stdScaler.transform(X)\ntest_stdScaled = stdScaler.transform(oneHot_test)\nprint('X_stdScaled:\\n{}'.format(X_stdScaled[:5,:]))\nprint()\nprint('test_stdScaled:\\n{}'.format(test_stdScaled[:5,:]))","eab9fcf9":"cv = StratifiedKFold(shuffle=True, random_state=RANDOM_STATE)","e3bb2c8b":"# LogisticRegression\nclf = LogisticRegression(random_state = RANDOM_STATE)\n\n#defult NotScaled\nclf.fit(X_train,y_train)\ndefLrTrainScore = cross_val_score(clf, X_train, y_train, cv=cv).mean()\ndefLrValidScore = cross_val_score(clf, X_valid, y_valid, cv=cv).mean()\nprint('LogisticRegression NotScaled train score: {:.3f}'.format(defLrTrainScore))\nprint('LogisticRegression NotScaled valid score: {:.3f}'.format(defLrValidScore))\n\n#defult minmaxScaled\nclf.fit(X_train_minmaxScaled,y_train)\ndefMinMaxLrTrainScore = cross_val_score(clf, X_train_minmaxScaled, y_train, cv=cv).mean()\ndefMinMaxLrValidScore = cross_val_score(clf, X_valid_minmaxScaled, y_valid, cv=cv).mean()\nprint('LogisticRegression MinMaxScaled train score: {:.3f}'.format(defMinMaxLrTrainScore))\nprint('LogisticRegression MinMaxScaled valid score: {:.3f}'.format(defMinMaxLrValidScore))\n\n#defult StandardScaled\nclf.fit(X_train_stdScaled,y_train)\ndefStdLrTrainScore = cross_val_score(clf, X_train_stdScaled, y_train, cv=cv).mean()\ndefStdLrValidScore = cross_val_score(clf, X_valid_stdScaled, y_valid, cv=cv).mean()\nprint('LogisticRegression StandardScaled train score: {:.3f}'.format(defStdLrTrainScore))\nprint('LogisticRegression StandardScaled valid score: {:.3f}'.format(defStdLrValidScore))","8c4a84a0":"# GaussianNB\nclf = GaussianNB()\n\n#defult NotScaled\nclf.fit(X_train,y_train)\ndefGaussianTrainScore = cross_val_score(clf, X_train, y_train, cv=cv).mean()\ndefGaussianValidScore = cross_val_score(clf, X_valid, y_valid, cv=cv).mean()\nprint('Gaussian NotScaled train score: {:.3f}'.format(defGaussianTrainScore))\nprint('Gaussian NotScaled valid score: {:.3f}'.format(defGaussianValidScore))\n\n#defult minmaxScaled\nclf.fit(X_train_minmaxScaled,y_train)\ndefMinMaxGaussianTrainScore = cross_val_score(clf, X_train_minmaxScaled, y_train, cv=cv).mean()\ndefMinMaxGaussianValidScore = cross_val_score(clf, X_valid_minmaxScaled, y_valid, cv=cv).mean()\nprint('Gaussian MinMaxScaled train score: {:.3f}'.format(defMinMaxGaussianTrainScore))\nprint('Gaussian MinMaxScaled valid score: {:.3f}'.format(defMinMaxGaussianValidScore))\n\n#defult StandardScaled\nclf.fit(X_train_stdScaled,y_train)\ndefStdGaussianTrainScore = cross_val_score(clf, X_train_stdScaled, y_train, cv=cv).mean()\ndefStdGaussianValidScore = cross_val_score(clf, X_valid_stdScaled, y_valid, cv=cv).mean()\nprint('Gaussian StandardScaled train score: {:.3f}'.format(defStdGaussianTrainScore))\nprint('Gaussian StandardScaled valid score: {:.3f}'.format(defStdGaussianValidScore))","25b6ff6d":"# SVC\nclf = SVC(random_state = RANDOM_STATE)\n\n#defult NotScaled\nclf.fit(X_train,y_train)\ndefSvcTrainScore = cross_val_score(clf, X_train, y_train, cv=cv).mean()\ndefSvcValidScore = cross_val_score(clf, X_valid, y_valid, cv=cv).mean()\nprint('SVC train NotScaled score: {:.3f}'.format(defSvcTrainScore))\nprint('SVC valid NotScaled score: {:.3f}'.format(defSvcValidScore))\n\n#defult minmaxScaled\nclf.fit(X_train_minmaxScaled,y_train)\ndefMinMaxSvcTrainScore = cross_val_score(clf, X_train_minmaxScaled, y_train, cv=cv).mean()\ndefMinMaxSvcValidScore = cross_val_score(clf, X_valid_minmaxScaled, y_valid, cv=cv).mean()\nprint('SVC MinMaxScaled train score: {:.3f}'.format(defMinMaxSvcTrainScore))\nprint('SVC MinMaxScaled valid score: {:.3f}'.format(defMinMaxSvcValidScore))\n\n#defult StandardScaled\nclf.fit(X_train_stdScaled,y_train)\ndefStdSvcTrainScore = cross_val_score(clf, X_train_stdScaled, y_train, cv=cv).mean()\ndefStdSvcValidScore = cross_val_score(clf, X_valid_stdScaled, y_valid, cv=cv).mean()\nprint('SVC StandardScaled train score: {:.3f}'.format(defStdSvcTrainScore))\nprint('SVC StandardScaled valid score: {:.3f}'.format(defStdSvcValidScore))","7ede00d1":"# LinearSVC\nclf = LinearSVC(random_state = RANDOM_STATE)\n\n#defult NotScaled\nclf.fit(X_train,y_train)\ndefLinearSvcTrainScore = cross_val_score(clf, X_train, y_train, cv=cv).mean()\ndefLinearSvcValidScore = cross_val_score(clf, X_valid, y_valid, cv=cv).mean()\nprint('LinearSVC NotScaled train score: {:.3f}'.format(defLinearSvcTrainScore))\nprint('LinearSVC NotScaled valid score: {:.3f}'.format(defLinearSvcValidScore))\n\n#defult minmaxScaled\nclf.fit(X_train_minmaxScaled,y_train)\ndefMinMaxLinearSvcTrainScore = cross_val_score(clf, X_train_minmaxScaled, y_train, cv=cv).mean()\ndefMinMaxLinearSvcValidScore = cross_val_score(clf, X_valid_minmaxScaled, y_valid, cv=cv).mean()\nprint('LinearSVC MinMaxScaled train score: {:.3f}'.format(defMinMaxLinearSvcTrainScore))\nprint('LinearSVC MinMaxScaled valid score: {:.3f}'.format(defMinMaxLinearSvcValidScore))\n\n#defult StandardScaled\nclf.fit(X_train_stdScaled,y_train)\ndefStdLinearSvcTrainScore = cross_val_score(clf, X_train_stdScaled, y_train, cv=cv).mean()\ndefStdLinearSvcValidScore = cross_val_score(clf, X_valid_stdScaled, y_valid, cv=cv).mean()\nprint('LinearSVC StandardScaled train score: {:.3f}'.format(defStdLinearSvcTrainScore))\nprint('LinearSVC StandardScaled valid score: {:.3f}'.format(defStdLinearSvcValidScore))","3f9d9b68":"# RandomForestClassifier\nclf = RandomForestClassifier(random_state = RANDOM_STATE)\n\n#defult NotScaled\nclf.fit(X_train,y_train)\ndefRfTrainScore = cross_val_score(clf, X_train, y_train, cv=cv).mean()\ndefRfValidScore = cross_val_score(clf, X_valid, y_valid, cv=cv).mean()\nprint('RandomForestClassifier NotScaled train score: {:.3f}'.format(defRfTrainScore))\nprint('RandomForestClassifier NotScaled valid score: {:.3f}'.format(defRfValidScore))\n\n#defult minmaxScaled\nclf.fit(X_train_minmaxScaled,y_train)\ndefMinMaxRfTrainScore = cross_val_score(clf, X_train_minmaxScaled, y_train, cv=cv).mean()\ndefMinMaxRfValidScore = cross_val_score(clf, X_valid_minmaxScaled, y_valid, cv=cv).mean()\nprint('RandomForestClassifier MinMaxScaled train score: {:.3f}'.format(defMinMaxRfTrainScore))\nprint('RandomForestClassifier MinMaxScaled valid score: {:.3f}'.format(defMinMaxRfValidScore))\n\n#defult StandardScaled\nclf.fit(X_train_stdScaled,y_train)\ndefStdRfTrainScore = cross_val_score(clf, X_train_stdScaled, y_train, cv=cv).mean()\ndefStdRfValidScore = cross_val_score(clf, X_valid_stdScaled, y_valid, cv=cv).mean()\nprint('RandomForestClassifier StandardScaled train score: {:.3f}'.format(defStdRfTrainScore))\nprint('RandomForestClassifier StandardScaled valid score: {:.3f}'.format(defStdRfValidScore))","b9cab321":"# DecisionTreeClassifier\nclf = DecisionTreeClassifier(random_state = RANDOM_STATE)\n\n#defult NotScaled\nclf.fit(X_train,y_train)\ndefDtTrainScore = cross_val_score(clf, X_train, y_train, cv=cv).mean()\ndefDtValidScore = cross_val_score(clf, X_valid, y_valid, cv=cv).mean()\nprint('DecisionTreeClassifier NotScaled train score: {:.3f}'.format(defDtTrainScore))\nprint('DecisionTreeClassifier NotScaled valid score: {:.3f}'.format(defDtValidScore))\n\n#defult minmaxScaled\nclf.fit(X_train_minmaxScaled,y_train)\ndefMinMaxDtTrainScore = cross_val_score(clf, X_train_minmaxScaled, y_train, cv=cv).mean()\ndefMinMaxDtValidScore = cross_val_score(clf, X_valid_minmaxScaled, y_valid, cv=cv).mean()\nprint('DecisionTreeClassifier MinMaxScaled train score: {:.3f}'.format(defMinMaxDtTrainScore))\nprint('DecisionTreeClassifier MinMaxScaled valid score: {:.3f}'.format(defMinMaxDtValidScore))\n\n#defult StandardScaled\nclf.fit(X_train_stdScaled,y_train)\ndefStdDtTrainScore = cross_val_score(clf, X_train_stdScaled, y_train, cv=cv).mean()\ndefStdDtValidScore = cross_val_score(clf, X_valid_stdScaled, y_valid, cv=cv).mean()\nprint('DecisionTreeClassifier StandardScaled train score: {:.3f}'.format(defStdDtTrainScore))\nprint('DecisionTreeClassifier StandardScaled valid score: {:.3f}'.format(defStdDtValidScore))","a4972053":"# KNeighborsClassifier\nclf = KNeighborsClassifier()\n\n#defult NotScaled\nclf.fit(X_train,y_train)\ndefKnnTrainScore = cross_val_score(clf, X_train, y_train, cv=cv).mean()\ndefKnnValidScore = cross_val_score(clf, X_valid, y_valid, cv=cv).mean()\nprint('KNeighborsClassifier NotScaled train score: {:.3f}'.format(defKnnTrainScore))\nprint('KNeighborsClassifier NotScaled valid score: {:.3f}'.format(defKnnValidScore))\n\n#defult minmaxScaled\nclf.fit(X_train_minmaxScaled,y_train)\ndefMinMaxKnnTrainScore = cross_val_score(clf, X_train_minmaxScaled, y_train, cv=cv).mean()\ndefMinMaxKnnValidScore = cross_val_score(clf, X_valid_minmaxScaled, y_valid, cv=cv).mean()\nprint('KNeighborsClassifier MinMaxScaled train score: {:.3f}'.format(defMinMaxKnnTrainScore))\nprint('KNeighborsClassifier MinMaxScaled valid score: {:.3f}'.format(defMinMaxKnnValidScore))\n\n#defult StandardScaled\nclf.fit(X_train_stdScaled,y_train)\ndefStdKnnTrainScore = cross_val_score(clf, X_train_stdScaled, y_train, cv=cv).mean()\ndefStdKnnValidScore = cross_val_score(clf, X_valid_stdScaled, y_valid, cv=cv).mean()\nprint('KNeighborsClassifier StandardScaled train score: {:.3f}'.format(defStdKnnTrainScore))\nprint('KNeighborsClassifier StandardScaled valid score: {:.3f}'.format(defStdKnnValidScore))","5990bb79":"# Perceptron\nclf = Perceptron(random_state = RANDOM_STATE)\n\n#defult NotScaled\nclf.fit(X_train,y_train)\ndefPerceptronTrainScore = cross_val_score(clf, X_train, y_train, cv=cv).mean()\ndefPerceptronValidScore = cross_val_score(clf, X_valid, y_valid, cv=cv).mean()\nprint('Perceptron NotScaled train score: {:.3f}'.format(defPerceptronTrainScore))\nprint('Perceptron NotScaled valid score: {:.3f}'.format(defPerceptronValidScore))\n\n#defult minmaxScaled\nclf.fit(X_train_minmaxScaled,y_train)\ndefMinMaxPerceptronTrainScore = cross_val_score(clf, X_train_minmaxScaled, y_train, cv=cv).mean()\ndefMinMaxPerceptronValidScore = cross_val_score(clf, X_valid_minmaxScaled, y_valid, cv=cv).mean()\nprint('Perceptron MinMaxScaled train score: {:.3f}'.format(defMinMaxPerceptronTrainScore))\nprint('Perceptron MinMaxScaled valid score: {:.3f}'.format(defMinMaxPerceptronValidScore))\n\n#defult StandardScaled\nclf.fit(X_train_stdScaled,y_train)\ndefStdPerceptronTrainScore = cross_val_score(clf, X_train_stdScaled, y_train, cv=cv).mean()\ndefStdPerceptronValidScore = cross_val_score(clf, X_valid_stdScaled, y_valid, cv=cv).mean()\nprint('Perceptron StandardScaled train score: {:.3f}'.format(defStdPerceptronTrainScore))\nprint('Perceptron StandardScaled valid score: {:.3f}'.format(defStdPerceptronValidScore))","dab4d560":"# MLPClassifier\nclf = MLPClassifier(random_state = RANDOM_STATE)\n\n#defult NotScaled\nclf.fit(X_train,y_train)\ndefMlpTrainScore = cross_val_score(clf, X_train, y_train, cv=cv).mean()\ndefMlpValidScore = cross_val_score(clf, X_valid, y_valid, cv=cv).mean()\nprint('MLPClassifier NotScaled train score: {:.3f}'.format(defMlpTrainScore))\nprint('MLPClassifier NotScaled valid score: {:.3f}'.format(defMlpValidScore))\n\n#defult minmaxScaled\nclf.fit(X_train_minmaxScaled,y_train)\ndefMinMaxMlpTrainScore = cross_val_score(clf, X_train_minmaxScaled, y_train, cv=cv).mean()\ndefMinMaxMlpValidScore = cross_val_score(clf, X_valid_minmaxScaled, y_valid, cv=cv).mean()\nprint('MLPClassifier MinMaxScaled train score: {:.3f}'.format(defMinMaxMlpTrainScore))\nprint('MLPClassifier MinMaxScaled valid score: {:.3f}'.format(defMinMaxMlpValidScore))\n\n#defult StandardScaled\nclf.fit(X_train_stdScaled,y_train)\ndefStdMlpTrainScore = cross_val_score(clf, X_train_stdScaled, y_train, cv=cv).mean()\ndefStdMlpValidScore = cross_val_score(clf, X_valid_stdScaled, y_valid, cv=cv).mean()\nprint('MLPClassifier StandardScaler train score: {:.3f}'.format(defStdMlpTrainScore))\nprint('MLPClassifier StandardScaler valid score: {:.3f}'.format(defStdMlpValidScore))","27dd8434":"# Define function plotting heatmap results from gridsearchCV\ndef plot_heatmap_from_grid(clf,i, name):\n    # Pick up tuning Parameters\n    params = [k for k in clf.cv_results_.keys() if k.startswith('param_')]\n    if len(params) != 2: raise Exception('grid has to have exact 2 parameters.') \n\n    # Define heatmap's index, columns, values\n    index = params[0]\n    columns = params[1]\n    values = 'mean_test_score'\n\n    # Extract Keys from grid\n    df_dict = {k: clf.cv_results_[k] for k in clf.cv_results_.keys() & {index, columns, values}}\n\n    # Transform to pd.DataFrame and plot heatmap\n    df = pd.DataFrame(df_dict)\n    data = df.pivot(index=index, columns=columns, values=values)    \n    sns.heatmap(data, annot=True, fmt='.3f',ax=axarr[i]).set_title(name, fontsize=18)","91db12af":"# LogisticRegression\nlr = LogisticRegression(random_state=RANDOM_STATE)\ngrid_param = {'solver': ['newton-cg','lbfgs','liblinear','sag','saga'], 'C': [0.001,0.01,0.1,1,10,100]}\nclf = GridSearchCV(lr, grid_param, cv=cv, scoring='accuracy')\nfig, axarr = plt.subplots(1, 3, figsize=(28,8))\n\n#GridSearched NotScaled\nclf.fit(X_train, y_train)\ngridLrTrainScore = clf.best_score_\ngridLrValidScore = cross_val_score(clf, X_valid, y_valid, cv=cv).mean()\nprint('LogisticRegression GridSearchCV NotScaled best params: {}'.format(clf.best_params_))\nprint('LogisticRegression GridSearchCV NotScaled train score: {:.3f}'.format(gridLrTrainScore))\nprint('LogisticRegression GridSearchCV NotScaled valid score: {:.3f}'.format(gridLrValidScore))\nplot_heatmap_from_grid(clf,0, 'LogisticRegression NotScaled')\n\n#GridSearched minmaxScaled\nclf.fit(X_train_minmaxScaled, y_train)\ngridMinMaxLrTrainScore = clf.best_score_\ngridMinMaxLrValidScore = cross_val_score(clf, X_valid_minmaxScaled, y_valid, cv=cv).mean()\nprint('LogisticRegression GridSearchCV MinMaxScaled best params: {}'.format(clf.best_params_))\nprint('LogisticRegression GridSearchCV MinMaxScaled train score: {:.3f}'.format(gridMinMaxLrTrainScore))\nprint('LogisticRegression GridSearchCV MinMaxScaled valid score: {:.3f}'.format(gridMinMaxLrValidScore))\nplot_heatmap_from_grid(clf,1, 'LogisticRegression MinMaxScaled')\n\n#GridSearched StandardScaled\nclf.fit(X_train_stdScaled, y_train)\ngridStdLrTrainScore = clf.best_score_\ngridStdLrValidScore = cross_val_score(clf, X_valid_stdScaled, y_valid, cv=cv).mean()\nprint('LogisticRegression GridSearchCV StandardScaled best params: {}'.format(clf.best_params_))\nprint('LogisticRegression GridSearchCV StandardScaled train score: {:.3f}'.format(gridStdLrTrainScore))\nprint('LogisticRegression GridSearchCV StandardScaled valid score: {:.3f}'.format(gridStdLrValidScore))\nplot_heatmap_from_grid(clf,2, 'LogisticRegression StandardScaled')","bb9ebf96":"# GaussianNB\ngridGaussianTrainScore = 0\ngridMinMaxGaussianTrainScore = 0\ngridStdGaussianTrainScore = 0\ngridGaussianValidScore = 0\ngridMinMaxGaussianValidScore = 0\ngridStdGaussianValidScore = 0","d0f44926":"# SVC\nsvc = SVC(random_state=RANDOM_STATE)\ngrid_param = {'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': ['auto', 0.0001, 0.001, 0.01, 0.1, 1, 10]}\nclf = GridSearchCV(svc, grid_param, cv=cv, scoring='accuracy', )\nfig, axarr = plt.subplots(1, 3, figsize=(28,8))\n\n#GridSearched NotScaled\nclf.fit(X_train, y_train)\ngridSvcTrainScore = clf.best_score_\ngridSvcValidScore = cross_val_score(clf, X_valid, y_valid, cv=cv).mean()\nprint('SVC GridSearchCV NotScaled best params: {}'.format(clf.best_params_))\nprint('SVC GridSearchCV NotScaled train score: {:.3f}'.format(gridSvcTrainScore))\nprint('SVC GridSearchCV NotScaled valid score: {:.3f}'.format(gridSvcValidScore))\nplot_heatmap_from_grid(clf,0,'SVC NotScaled')\n\n#GridSearched minmaxScaled\nclf.fit(X_train_minmaxScaled, y_train)\ngridMinMaxSvcTrainScore = clf.best_score_\ngridMinMaxSvcValidScore = cross_val_score(clf, X_valid_minmaxScaled, y_valid, cv=cv).mean()\nprint('SVC GridSearchCV MinMaxScaled best params: {}'.format(clf.best_params_))\nprint('SVC GridSearchCV MinMaxScaled train score: {:.3f}'.format(gridMinMaxSvcTrainScore))\nprint('SVC GridSearchCV MinMaxScaled valid score: {:.3f}'.format(gridMinMaxSvcValidScore))\nplot_heatmap_from_grid(clf,1,'SVC MinMaxScaled')\n\n#GridSearched StandardScaled\nclf.fit(X_train_stdScaled, y_train)\ngridStdSvcTrainScore = clf.best_score_\ngridStdSvcValidScore = cross_val_score(clf, X_valid_stdScaled, y_valid, cv=cv).mean()\nprint('SVC GridSearchCV StandardScaled best params: {}'.format(clf.best_params_))\nprint('SVC GridSearchCV StandardScaled train score: {:.3f}'.format(gridStdSvcTrainScore))\nprint('SVC GridSearchCV StandardScaled valid score: {:.3f}'.format(gridStdSvcValidScore))\nplot_heatmap_from_grid(clf,2,'SVC StandardScaled')","33ce632f":"# LinearSVC\nlinear_svc = LinearSVC(random_state=RANDOM_STATE)\ngrid_param = { 'C':[0.001, 0.01, 0.1, 1, 3, 5], 'max_iter': [1000, 10000, 50000, 100000]}\nclf = GridSearchCV(linear_svc, grid_param, cv=cv, scoring='accuracy')\nfig, axarr = plt.subplots(1, 3, figsize=(28,8))\n\n#GridSearched NotScaled\nclf.fit(X_train, y_train)\ngridLinearSvcTrainScore = clf.best_score_\ngridLinearSvcValidScore = cross_val_score(clf, X_valid, y_valid, cv=cv).mean()\nprint('LinearSVC GridSearchCV NotScaled best params: {}'.format(clf.best_params_))\nprint('LinearSVC GridSearchCV NotScaled train score: {:.3f}'.format(gridLinearSvcTrainScore))\nprint('LinearSVC GridSearchCV NotScaled valid score: {:.3f}'.format(gridLinearSvcValidScore))\nplot_heatmap_from_grid(clf,0,'LinearSVC NotScaled')\n\n#GridSearched minmaxScaled\nclf.fit(X_train_minmaxScaled, y_train)\ngridMinMaxLinearSvcTrainScore = clf.best_score_\ngridMinMaxLinearSvcValidScore = cross_val_score(clf, X_valid_minmaxScaled, y_valid, cv=cv).mean()\nprint('LinearSVC GridSearchCV MinMaxScaled best params: {}'.format(clf.best_params_))\nprint('LinearSVC GridSearchCV MinMaxScaled train score: {:.3f}'.format(gridMinMaxLinearSvcTrainScore))\nprint('LinearSVC GridSearchCV MinMaxScaled valid score: {:.3f}'.format(gridMinMaxLinearSvcValidScore))\nplot_heatmap_from_grid(clf,1,'LinearSVC MinMaxScaled')\n\n#GridSearched StandardScaled\nclf.fit(X_train_stdScaled, y_train)\ngridStdLinearSvcTrainScore = clf.best_score_\ngridStdLinearSvcValidScore = cross_val_score(clf, X_valid_stdScaled, y_valid, cv=cv).mean()\nprint('LinearSVC GridSearchCV StandardScaled best params: {}'.format(clf.best_params_))\nprint('LinearSVC GridSearchCV StandardScaled train score: {:.3f}'.format(gridStdLinearSvcTrainScore))\nprint('LinearSVC GridSearchCV StandardScaled valid score: {:.3f}'.format(gridStdLinearSvcValidScore))\nplot_heatmap_from_grid(clf,2,'LinearSVC StandardScaled')","38e95ab2":"# RandomForestClassifier\nrf = RandomForestClassifier(random_state=RANDOM_STATE)\ngrid_param = {'n_estimators': [10, 100, 300, 500], 'max_depth': [None, 1, 3, 5, 7, 9]}\nclf = GridSearchCV(rf, grid_param, cv=cv, scoring='accuracy')\nfig, axarr = plt.subplots(1, 3, figsize=(28,8))\n\n#GridSearched NotScaled\nclf.fit(X_train, y_train)\ngridRfTrainScore = clf.best_score_\ngridRfValidScore = cross_val_score(clf, X_valid, y_valid, cv=cv).mean()\nprint('RandomForestClassifier GridSearchCV NotScaled best params: {}'.format(clf.best_params_))\nprint('RandomForestClassifier GridSearchCV NotScaled train score: {:.3f}'.format(gridRfTrainScore))\nprint('RandomForestClassifier GridSearchCV NotScaled valid score: {:.3f}'.format(gridRfValidScore))\nplot_heatmap_from_grid(clf,0,'RandomForestClassifier NotScaled')\n\n#GridSearched minmaxScaled\nclf.fit(X_train_minmaxScaled, y_train)\ngridMinMaxRfTrainScore = clf.best_score_\ngridMinMaxRfValidScore = cross_val_score(clf, X_valid_minmaxScaled, y_valid, cv=cv).mean()\nprint('RandomForestClassifier GridSearchCV MinMaxScaled best params: {}'.format(clf.best_params_))\nprint('RandomForestClassifier GridSearchCV MinMaxScaled train score: {:.3f}'.format(gridMinMaxRfTrainScore))\nprint('RandomForestClassifier GridSearchCV MinMaxScaled valid score: {:.3f}'.format(gridMinMaxRfValidScore))\nplot_heatmap_from_grid(clf,1,'RandomForestClassifier MinMaxScaled')\n\n#GridSearched StandardScaled\nclf.fit(X_train_stdScaled, y_train)\ngridStdRfTrainScore = clf.best_score_\ngridStdRfValidScore = cross_val_score(clf, X_valid_stdScaled, y_valid, cv=cv).mean()\nprint('RandomForestClassifier GridSearchCV StandardScaled best params: {}'.format(clf.best_params_))\nprint('RandomForestClassifier GridSearchCV StandardScaled train score: {:.3f}'.format(gridStdRfTrainScore))\nprint('RandomForestClassifier GridSearchCV StandardScaled valid score: {:.3f}'.format(gridStdRfValidScore))\nplot_heatmap_from_grid(clf,2,'RandomForestClassifier StandardScaled')","8050c99f":"# DecisionTreeClassifier\ndt = DecisionTreeClassifier(random_state=RANDOM_STATE)\ngrid_param = {'max_depth': [None, 1, 3, 5, 7, 9, 11], 'max_features': [None, 1, 3, 5, 7, 9, 11]}\nclf = GridSearchCV(dt, grid_param, cv=cv, scoring='accuracy')\nfig, axarr = plt.subplots(1, 3, figsize=(28,8))\n\n#GridSearched NotScaled\nclf.fit(X_train, y_train)\ngridDtTrainScore = clf.best_score_\ngridDtValidScore = cross_val_score(clf, X_valid, y_valid, cv=cv).mean()\nprint('DecisionTreeClassifier GridSearchCV NotScaled best params: {}'.format(clf.best_params_))\nprint('DecisionTreeClassifier GridSearchCV NotScaled train score: {:.3f}'.format(gridDtTrainScore))\nprint('DecisionTreeClassifier GridSearchCV NotScaled valid score: {:.3f}'.format(gridDtValidScore))\nplot_heatmap_from_grid(clf,0,'DecisionTreeClassifier NotScaled')\n\n#GridSearched minmaxScaled\nclf.fit(X_train_minmaxScaled, y_train)\ngridMinMaxDtTrainScore = clf.best_score_\ngridMinMaxDtValidScore = cross_val_score(clf, X_valid_minmaxScaled, y_valid, cv=cv).mean()\nprint('DecisionTreeClassifier GridSearchCV MinMaxScaled best params: {}'.format(clf.best_params_))\nprint('DecisionTreeClassifier GridSearchCV MinMaxScaled train score: {:.3f}'.format(gridMinMaxDtTrainScore))\nprint('DecisionTreeClassifier GridSearchCV MinMaxScaled valid score: {:.3f}'.format(gridMinMaxDtValidScore))\nplot_heatmap_from_grid(clf,1,'DecisionTreeClassifier MinMaxScaled')\n\n#GridSearched StandardScaled\nclf.fit(X_train_stdScaled, y_train)\ngridStdDtTrainScore = clf.best_score_\ngridStdDtValidScore = cross_val_score(clf, X_valid_stdScaled, y_valid, cv=cv).mean()\nprint('DecisionTreeClassifier GridSearchCV StandardScaled best params: {}'.format(clf.best_params_))\nprint('DecisionTreeClassifier GridSearchCV StandardScaled train score: {:.3f}'.format(gridStdDtTrainScore))\nprint('DecisionTreeClassifier GridSearchCV StandardScaled valid score: {:.3f}'.format(gridStdDtValidScore))\nplot_heatmap_from_grid(clf,2,'DecisionTreeClassifier StandardScaled')","2767c378":"# KNeighborsClassifier\nknn = KNeighborsClassifier()\ngrid_param = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 'weights': ['uniform', 'distance']}\nclf = GridSearchCV(knn, grid_param, cv=cv, scoring='accuracy')\nfig, axarr = plt.subplots(1, 3, figsize=(28,8))\n\n#GridSearched NotScaled\nclf.fit(X_train, y_train)\ngridKnnTrainScore = clf.best_score_\ngridKnnValidScore = cross_val_score(clf, X_valid, y_valid, cv=cv).mean()\nprint('KNeighborsClassifier GridSearchCV NotScaled best params: {}'.format(clf.best_params_))\nprint('KNeighborsClassifier GridSearchCV NotScaled train score: {:.3f}'.format(gridKnnTrainScore))\nprint('KNeighborsClassifier GridSearchCV NotScaled valid score: {:.3f}'.format(gridKnnValidScore))\nplot_heatmap_from_grid(clf,0,'KNeighborsClassifier NotScaled')\n\n#GridSearched minmaxScaled\nclf.fit(X_train_minmaxScaled, y_train)\ngridMinMaxKnnTrainScore = clf.best_score_\ngridMinMaxKnnValidScore = cross_val_score(clf, X_valid_minmaxScaled, y_valid, cv=cv).mean()\nprint('KNeighborsClassifier GridSearchCV MinMaxScaled best params: {}'.format(clf.best_params_))\nprint('KNeighborsClassifier GridSearchCV MinMaxScaled train score: {:.3f}'.format(gridMinMaxKnnTrainScore))\nprint('KNeighborsClassifier GridSearchCV MinMaxScaled valid score: {:.3f}'.format(gridMinMaxKnnValidScore))\nplot_heatmap_from_grid(clf,1,'KNeighborsClassifier MinMaxScaled')\n\n#GridSearched StandardScaled\nclf.fit(X_train_stdScaled, y_train)\ngridStdKnnTrainScore = clf.best_score_\ngridStdKnnValidScore = cross_val_score(clf, X_valid_stdScaled, y_valid, cv=cv).mean()\nprint('KNeighborsClassifier GridSearchCV StandardScaled best params: {}'.format(clf.best_params_))\nprint('KNeighborsClassifier GridSearchCV StandardScaled train score: {:.3f}'.format(gridStdKnnTrainScore))\nprint('KNeighborsClassifier GridSearchCV StandardScaled valid score: {:.3f}'.format(gridStdKnnValidScore))\nplot_heatmap_from_grid(clf,2,'KNeighborsClassifier StandardScaled')","c2ded834":"# Perceptron\nperceptron = Perceptron(random_state=RANDOM_STATE)\ngrid_param = {'penalty': [None,'l2', 'l1','elasticnet'],'max_iter': [5, 10, 50, 100, 500, 1000, 5000]}\nclf = GridSearchCV(perceptron, grid_param, cv=cv, scoring='accuracy')\nfig, axarr = plt.subplots(1, 3, figsize=(28,8))\n\n#GridSearched NotScaled\nclf.fit(X_train, y_train)\ngridPerceptronTrainScore = clf.best_score_\ngridPerceptronValidScore = cross_val_score(clf, X_valid, y_valid, cv=cv).mean()\nprint('Perceptron GridSearchCV NotScaled best params: {}'.format(clf.best_params_))\nprint('Perceptron GridSearchCV NotScaled train score: {:.3f}'.format(gridPerceptronTrainScore))\nprint('Perceptron GridSearchCV NotScaled valid score: {:.3f}'.format(gridPerceptronValidScore))\nplot_heatmap_from_grid(clf,0,'Perceptron NotScaled')\n\n#GridSearched minmaxScaled\nclf.fit(X_train_minmaxScaled, y_train)\ngridMinMaxPerceptronTrainScore = clf.best_score_\ngridMinMaxPerceptronValidScore = cross_val_score(clf, X_valid_minmaxScaled, y_valid, cv=cv).mean()\nprint('Perceptron GridSearchCV MinMaxScaled best params: {}'.format(clf.best_params_))\nprint('Perceptron GridSearchCV MinMaxScaled train score: {:.3f}'.format(gridMinMaxPerceptronTrainScore))\nprint('Perceptron GridSearchCV MinMaxScaled valid score: {:.3f}'.format(gridMinMaxPerceptronValidScore))\nplot_heatmap_from_grid(clf,1,'Perceptron MinMaxScaled')\n\n#GridSearched StandardScaled\nclf.fit(X_train_stdScaled, y_train)\ngridStdPerceptronTrainScore = clf.best_score_\ngridStdPerceptronValidScore = cross_val_score(clf, X_valid_stdScaled, y_valid, cv=cv).mean()\nprint('Perceptron GridSearchCV StandardScaled best params: {}'.format(clf.best_params_))\nprint('Perceptron GridSearchCV StandardScaled train score: {:.3f}'.format(gridStdPerceptronTrainScore))\nprint('Perceptron GridSearchCV StandardScaled valid score: {:.3f}'.format(gridStdPerceptronValidScore))\nplot_heatmap_from_grid(clf,2,'Perceptron StandardScaled')","914e509d":"# MLPClassifier\nmlp = MLPClassifier(random_state=RANDOM_STATE)\ngrid_param = parameters={'hidden_layer_sizes': [(10,), (100,), (100,100,)],'alpha': [0.0001, 0.001, 0.01]}\nclf = GridSearchCV(mlp, grid_param, cv=cv, scoring='accuracy')\nfig, axarr = plt.subplots(1, 3, figsize=(28,8))\n\n#GridSearched NotScaled\nclf.fit(X_train, y_train)\ngridMlpTrainScore = clf.best_score_\ngridMlpValidScore = cross_val_score(clf, X_valid, y_valid, cv=cv).mean()\nprint('MLPClassifier GridSearchCV NotScaled best params: {}'.format(clf.best_params_))\nprint('MLPClassifier GridSearchCV NotScaled train score: {:.3f}'.format(gridMlpTrainScore))\nprint('MLPClassifier GridSearchCV NotScaled valid score: {:.3f}'.format(gridMlpValidScore))\nplot_heatmap_from_grid(clf,0,'MLPClassifier NotScaled')\n\n#GridSearched minmaxScaled\nclf.fit(X_train_minmaxScaled, y_train)\ngridMinMaxMlpTrainScore = clf.best_score_\ngridMinMaxMlpValidScore = cross_val_score(clf, X_valid_minmaxScaled, y_valid, cv=cv).mean()\nprint('MLPClassifier GridSearchCV MinMaxScaled best params: {}'.format(clf.best_params_))\nprint('MLPClassifier GridSearchCV MinMaxScaled train score: {:.3f}'.format(gridMinMaxMlpTrainScore))\nprint('MLPClassifier GridSearchCV MinMaxScaled valid score: {:.3f}'.format(gridMinMaxMlpValidScore))\nplot_heatmap_from_grid(clf,1,'MLPClassifier MinMaxScaled')\n\n#GridSearched StandardScaled\nclf.fit(X_train_stdScaled, y_train)\ngridStdMlpTrainScore = clf.best_score_\ngridStdMlpValidScore = cross_val_score(clf, X_valid_stdScaled, y_valid, cv=cv).mean()\nprint('MLPClassifier GridSearchCV StandardScaled best params: {}'.format(clf.best_params_))\nprint('MLPClassifier GridSearchCV StandardScaled train score: {:.3f}'.format(gridStdMlpTrainScore))\nprint('MLPClassifier GridSearchCV StandardScaled valid score: {:.3f}'.format(gridStdMlpValidScore))\nplot_heatmap_from_grid(clf,2,'MLPClassifier StandardScaled')","8ac4e522":"pd.options.display.float_format = '{:,.3f}'.format\n\ntrainScores = pd.DataFrame({\n    'Model': ['LogisticRegression', 'GaussianNB', 'SVC', 'LinearSVC', \n              'RandomForestClassifier', 'DecisionTreeClassifier',\n              'KNeighborsClassifier', 'Perceptron', \n              'MLPClassifier'],\n    'NoScaleTrain': [defLrTrainScore, defGaussianTrainScore,\n                         defSvcTrainScore, defLinearSvcTrainScore, \n                         defRfTrainScore, defDtTrainScore, \n                         defKnnTrainScore, defPerceptronTrainScore,\n                        defMlpTrainScore],\n    'MinMaxTrain': [defMinMaxLrTrainScore, defMinMaxGaussianTrainScore,\n                         defMinMaxSvcTrainScore, defMinMaxLinearSvcTrainScore, \n                         defMinMaxRfTrainScore, defMinMaxDtTrainScore, \n                         defMinMaxKnnTrainScore, defMinMaxPerceptronTrainScore,\n                        defMinMaxMlpTrainScore],\n    'StdTrain': [defStdLrTrainScore, defStdGaussianTrainScore,\n                         defStdSvcTrainScore, defStdLinearSvcTrainScore, \n                         defStdRfTrainScore, defStdDtTrainScore, \n                         defStdKnnTrainScore, defStdPerceptronTrainScore,\n                        defStdMlpTrainScore],\n    'gridNoScaleTrain': [gridLrTrainScore, gridGaussianTrainScore,\n                         gridSvcTrainScore, gridLinearSvcTrainScore, \n                         gridRfTrainScore, gridDtTrainScore, \n                         gridKnnTrainScore, gridPerceptronTrainScore,\n                        gridMlpTrainScore],\n    'gridMinMaxTrain': [gridMinMaxLrTrainScore, gridMinMaxGaussianTrainScore,\n                         gridMinMaxSvcTrainScore, gridMinMaxLinearSvcTrainScore, \n                         gridMinMaxRfTrainScore, gridMinMaxDtTrainScore, \n                         gridMinMaxKnnTrainScore, gridMinMaxPerceptronTrainScore,\n                        gridMinMaxMlpTrainScore],\n    'gridStdTrain': [gridStdLrTrainScore, gridStdGaussianTrainScore,\n                         gridStdSvcTrainScore, gridStdLinearSvcTrainScore, \n                         gridStdRfTrainScore, gridStdDtTrainScore, \n                         gridStdKnnTrainScore, gridStdPerceptronTrainScore,\n                        gridStdMlpTrainScore],\n}).set_index('Model')\n\nvalidScores = pd.DataFrame({\n    'Model': ['LogisticRegression', 'GaussianNB', 'SVC', 'LinearSVC', \n              'RandomForestClassifier', 'DecisionTreeClassifier',\n              'KNeighborsClassifier', 'Perceptron', \n              'MLPClassifier'],\n    'NoScaleValid': [defLrValidScore, defGaussianValidScore,\n                         defSvcValidScore, defLinearSvcValidScore, \n                         defRfValidScore, defDtValidScore, \n                         defKnnValidScore, defPerceptronValidScore,\n                        defMlpValidScore],\n    'MinMaxValid': [defMinMaxLrValidScore, defMinMaxGaussianValidScore,\n                         defMinMaxSvcValidScore, defMinMaxLinearSvcValidScore, \n                         defMinMaxRfValidScore, defMinMaxDtValidScore, \n                         defMinMaxKnnValidScore, defMinMaxPerceptronValidScore,\n                        defMinMaxMlpValidScore],\n    'StdValid': [defStdLrValidScore, defStdGaussianValidScore,\n                         defStdSvcValidScore, defStdLinearSvcValidScore, \n                         defStdRfValidScore, defStdDtValidScore, \n                         defStdKnnValidScore, defStdPerceptronValidScore,\n                        defStdMlpValidScore],\n    'gridNoScaleValid': [gridLrValidScore, gridGaussianValidScore,\n                         gridSvcValidScore, gridLinearSvcValidScore, \n                         gridRfValidScore, gridDtValidScore, \n                         gridKnnValidScore, gridPerceptronValidScore,\n                        gridMlpValidScore],\n    'gridMinMaxValid': [gridMinMaxLrValidScore, gridMinMaxGaussianValidScore,\n                         gridMinMaxSvcValidScore, gridMinMaxLinearSvcValidScore, \n                         gridMinMaxRfValidScore, gridMinMaxDtValidScore, \n                         gridMinMaxKnnValidScore, gridMinMaxPerceptronValidScore,\n                        gridMinMaxMlpValidScore],\n    'gridStdValid': [gridStdLrValidScore, gridStdGaussianValidScore,\n                         gridStdSvcValidScore, gridStdLinearSvcValidScore, \n                         gridStdRfValidScore, gridStdDtValidScore, \n                         gridStdKnnValidScore, gridStdPerceptronValidScore,\n                        gridStdMlpValidScore]\n}).set_index('Model')","afc1bb15":"fig, axarr = plt.subplots(1, 2, figsize=(22, 8))\nsns.heatmap(trainScores, annot=True, vmin=0.6, fmt='.3f',ax=axarr[0]).set_title(\"Train Scores\", fontsize=18)\nsns.heatmap(validScores, annot=True, vmin=0.6, fmt='.3f',ax=axarr[1]).set_title(\"Valid Scores\", fontsize=18)","bd1ebe7d":"# LogisticRegression\nlr = LogisticRegression(random_state=RANDOM_STATE)\ngrid_param = {'solver': ['newton-cg','lbfgs','liblinear','sag','saga'], 'C': [0.001,0.01,0.1,1,10,100]}\nclf = GridSearchCV(lr, grid_param, cv=cv, scoring='accuracy')\n\n#GridSearched StandardScaled\nclf.fit(X_stdScaled, y)\nlrStdScaledPred = clf.predict(test_stdScaled)\nprint('LogisticRegression StandardScaled train score: {:.3f}'.format(clf.best_score_))","1029f1cd":"# SVC\nsvc = SVC(random_state=RANDOM_STATE)\ngrid_param = {'C': [0.01, 0.1, 1, 10, 100, 1000], 'gamma': ['auto', 0.0001, 0.001, 0.01, 0.1, 1, 10]}\nclf = GridSearchCV(svc, grid_param, cv=cv, scoring='accuracy', )\n\n#GridSearched minmaxScaled\nclf.fit(X_minmaxScaled, y)\nsvcMinmaxScaledPred = clf.predict(test_minmaxScaled)\nprint('SVC minmaxScaled train score: {:.3f}'.format(clf.best_score_))","224921be":"# LinearSVC\nlinear_svc = LinearSVC(random_state=RANDOM_STATE)\ngrid_param = { 'C':[0.001, 0.01, 0.1, 1, 3, 5], 'max_iter': [1000, 10000, 50000, 100000]}\nlinear_svcClf = GridSearchCV(linear_svc, grid_param, cv=cv, scoring='accuracy')\n\n#GridSearched StandardScaled\nclf.fit(X_stdScaled, y)\nlinear_svcStdScaledPred = clf.predict(test_stdScaled)\nprint('LinearSVC StandardScaled train score: {:.3f}'.format(clf.best_score_))","3bf2fcca":"# RandomForestClassifier\nrf = RandomForestClassifier(random_state=RANDOM_STATE)\ngrid_param = {'n_estimators': [10, 100, 300, 500], 'max_depth': [None, 1, 3, 5, 7, 9]}\nclf = GridSearchCV(rf, grid_param, cv=cv, scoring='accuracy')\n\n# GridSearched NotScaled)\nclf.fit(X, y)\nrfNotScaledPred = clf.predict(oneHot_test)\nprint('RandomForestClassifier NotScaled train score: {:.3f}'.format(clf.best_score_))","5789d09f":"# DecisionTreeClassifier\ndt = DecisionTreeClassifier(random_state=RANDOM_STATE)\ngrid_param = {'max_depth': [None, 1, 3, 5, 7, 9, 11], 'max_features': [None, 1, 3, 5, 7, 9, 11]}\nclf = GridSearchCV(dt, grid_param, cv=cv, scoring='accuracy')\n\n# GridSearched NotScaled)\nclf.fit(X, y)\ndtNotScaledPred = clf.predict(oneHot_test)\nprint('DecisionTreeClassifier NotScaled train score: {:.3f}'.format(clf.best_score_))","ebf82b60":"# KNeighborsClassifier\nknn = KNeighborsClassifier()\ngrid_param = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 'weights': ['uniform', 'distance']}\nclf = GridSearchCV(knn, grid_param, cv=cv, scoring='accuracy')\n\n#GridSearched minmaxScaled\nclf.fit(X_minmaxScaled, y)\nknnMinmaxScaledPred = clf.predict(test_minmaxScaled)\nprint('KNeighborsClassifier minmaxScaled train score: {:.3f}'.format(clf.best_score_))","5d730cc7":"# MLPClassifier\nmlp = MLPClassifier(random_state=RANDOM_STATE)\ngrid_param = parameters={'hidden_layer_sizes': [(10,), (100,), (100,100,)],'alpha': [0.0001, 0.001, 0.01]}\nclf = GridSearchCV(mlp, grid_param, cv=cv, scoring='accuracy')\n\n#GridSearched StandardScaled\nclf.fit(X_stdScaled, y)\nmlpStdScaledPred = clf.predict(test_stdScaled)\nprint('MLPClassifier StandardScaled train score: {:.3f}'.format(clf.best_score_))","bb2ba6c7":"ensembleDf = pd.DataFrame({\n    'lrStdScaledPred': lrStdScaledPred,\n    'svcMinmaxScaledPred': svcMinmaxScaledPred,\n    'linear_svcStdScaledPred': linear_svcStdScaledPred,\n    'rfNotScaledPred': rfNotScaledPred,\n    'dtNotScaledPred': dtNotScaledPred,\n    'knnMinmaxScaledPred': knnMinmaxScaledPred,\n    'mlpStdScaledPred': mlpStdScaledPred,\n})\n\nensembleDf['mode'] = ensembleDf.mode(axis=1)\n\nensembleDf.head()","e24af7d8":"submission = pd.DataFrame({\n    'PassengerId': test['PassengerId'],\n    'Survived': ensembleDf.loc[:,'mode']\n})\n\nsubmission.head()","110d6c75":"submission.to_csv('submission.csv', index=False)","c01830b0":"<a id=\"ch5\"><\/a>\n# 5 Comparing models\n\nLet's fit various ML models and get scores.\n\nThen compare these scores and obtain some knowledge about models.\n\nFinally decide which models use to predict.","5ed06236":"Change datatype from int64 to string with test data, too.","999ba127":"Show heatmap table of correlation again. The absolute value of correlation between Pclass and Age is higher than one before imputing, -0.37 to -0.4.\n\nnote: I expected that the absolute value of correlation between Survived and Age will rise, but it is falled,-0.077 to -0.051. I guess the reason why is the absolute value of correlation between Survived and Pclass is not so high -0.34 and imputing missing Age data with the value related to Pclass is not contribute to rase it.","22639cee":"<a id=\"ch5-2-5\"><\/a>\n### 5-2-5 RandomForestClassifier","831780fc":"For the purposes of the following, define cross-validation strategy.\n* To obtain more accurate score of train data.\n* To compare with a score of gridsearchCV, use same scoring method. \n* To ensure the repeability, pass RANDOM_STATE to model.","607ea9ef":"To impute missing Embarked data, acquire the mode of that column.","db688333":"<a id=\"ch4-3\"><\/a>\n## 4-3 Train Validation sprit\n\nThe scores of train data which is used for learning is not suitable for judging the model good or bad. Although a score of train data is very high, if overfitting occurred, a score of new (unseen) data is quite low. \n\n(By means of using kfold cross validation, reliability of train data's score will be improved. But, it is same that the score is calucrated by a dataset which is used for learning. So it is not inadequate anyway.)\n\nFrom the point of veiw of a demand that predict accurately a new data's classification, it is necessary judging the model with a score of a new data(generalization capability).\n\nThen split train data into X_train and X_valid, y_train, y_valid. To check generalization capability of each model.","6f9e13c9":"<a id=\"ch9\"><\/a>\n# 9 Conclusion\n\nI am glad that I could deepen the understanding of each model.\n\nThe score is 0.79425, which is my best score.\n\nThis time I used only scikit learn, I would like to challenge other libraries, XGBoosting and tensor flow.","5c20cbe0":"<a id=\"ch8\"><\/a>\n# 8 Submit","3245ea79":"<a id=\"ch5-1-9\"><\/a>\n### 5-1-9 MLPClassifier","1572ece5":"<a id=\"ch5-1-3\"><\/a>\n### 5-1-3 SVC","e18472ed":"To impute missing Fare data, calculate the mean of Fare of each Pclass, Because above table shows high the absolute value of correlation -0.55 between Pclass and Fare.\n\nAnd identify the row of missing Fare data, to aquire Pclass.","abc64f81":"Drop columns that is not used learnig from traindata.","435d9dce":"Desplayed with heatmap.\nVarious things can be read from the table below.\n\n### train vs valid\n\nBecause it uses CV, train data and valid data have not made such a big difference.\n\uff08When comparing train scores not using CV and valid scores, train scores tended to be higher and valid scores tended to be lower.\uff09\n\uff08DecisionTree is remarkable. Train scores were quite high, and valid scores tended to be rather low. Obviously overfitting had occurred.\uff09\n\n### not Scaled vs MinMaxScaled, StandardScaled\n\nRandomForest and DecisionTree do not change almost for each scale, but the results change with scales in other models. Although the score of StandardScaled is often good as a trend, the scores of not scaled may be the best.\n\n### default parameters vs grid parameters\n\nAlthough gridsearchCV tends to be higher in score, conversely default may be higher. It seems to be due to a random number.\n\n### Comparison by model\n\nIn terms of valid data, the score of gridsearchCV of MLPClassifier is the best. Perceptron is the worst score.\n\n\n\nIn response to the result, do predict.\nFor each model, compare with the best score of gridsearchCV of valid data, omit the lower 2 models.\nThe remaining models use the scale that gave the best results respectively.","e3aa9eb8":"<a id=\"ch4-1\"><\/a>\n## 4-1 Impute\n\nTo impute more acculate value to missing age data, identify column the biggest absolute value of correlation.\n\nFrom heatmap table of correlation, Pclass -0.37 is the the biggest absolute value of correlation of Age.","b0ed6b51":"train data has 891 rows. Age and Cabin, Embarked columun has missing data.","9358ebbe":"Calculate the mean of Age each Pclass.","32166821":"<a id=\"ch4-5\"><\/a>\n## 4-5 Standard Scaling\n\nFit Standard Scaling too.","f3fb737a":"<a id=\"ch5-3\"><\/a>\n## 5-3 Comparing models and decide models\n\nTo display the score of each model with heatmap, store it in `dataframe`.","dbd29c74":"<a id=\"ch1\"><\/a>\n# 1  Introduction\n**This notebook purpose is like this.**\n* Using visualization(heatmap) to preproccecing, proccecing data a little bit intricately.\n* Scoring some models with changing data or parameters, comparing scores with visualization(heatmap) in terms of train data vs. validation data, Not Scaled vs. MinMaxScaled or StandardScaled, default parameters vs. best parameters(GridSearchCV). From this comparison, obtaining some knowledge about models.\n* Selecting models and Ensenbling results.","b5fbf816":"<a id=\"ch5-2-2\"><\/a>\n### 5-2-2 GaussianNB\n\nnote: GaussianNB has no parameter to change with GridSearchCV. Assign zero to the variable for later comparison.","35940352":"<a id=\"ch4-4\"><\/a>\n## 4-4 MinMax Scaling\n\nFit MinMaxScaler. It is used for comparing with another scales later. ","31848494":"<a id=\"ch5-2-4\"><\/a>\n### 5-2-4 LinearSVC","9ebebd77":"Drop columns that is not used learnig from test data.","8e120cf1":"<a id=\"ch5-1-8\"><\/a>\n### 5-1-8 Perceptron","4ec827f9":"<a id=\"ch5-1\"><\/a>\n## 5-1 Default Parametars\n\nFit each model with default parametars and get scores.\nGet scores of not scaled and minmaxScaled, standardScaled and train data, valid data.\n\nCompare the scores with scores that getten with gridsearchCV.","59dd25d5":"Applying `pd.get_dummies` to test data, too.","5686a871":"<a id=\"ch5-1-1\"><\/a>\n### 5-1-1 LogisticRegression","9f8e9d6e":"<a id=\"ch5-1-4\"><\/a>\n### 5-1-4 LinearSVC","2d06dca2":"Impute value of Age and Embarked to train data and confirm that missing data is nothing.","47c64b6a":"To fit MLmodels, drop and Extract columns and make X, y from train data.","bdfca108":"<a id=\"ch7\"><\/a>\n# 7  Ensenble results","a8c4098e":"<a id=\"ch5-1-5\"><\/a>\n### 5-1-5 RandomForestClassifier","01f85512":"# This is my best practice - Titanic\n**2018\/07\/13**\n\n* [1  Introduction](#ch1)\n* [2  Import libraries](#ch2)\n* [3  EDA(Explanatory Data Analysis)](#ch3)\n* [4  Preproccecing](#ch4)\n    * [4-1  Impute](#ch4-1)\n    * [4-2  OneHot Encoding](#ch4-2)\n    * [4-3  Train Validation sprit](#ch4-3)\n    * [4-4  MinMax Scaling](#ch4-4)\n    * [4-5  Standard Scaling](#ch4-5)\n* [5  Comparing models](#ch5)\n    * [5-1  Default Parametars](#ch5-1)\n        * [5-1-1  LogisticRegression](#ch5-1-1)\n        * [5-1-2  GaussianNB](#ch5-1-2)\n        * [5-1-3  SVC](#ch5-1-3)\n        * [5-1-4  LinearSVC](#ch5-1-4)\n        * [5-1-5  RandomForestClassifier](#ch5-1-5)\n        * [5-1-6  DecisionTreeClassifier](#ch5-1-6)\n        * [5-1-7  KNeighborsClassifier](#ch5-1-7)\n        * [5-1-8  Perceptron](#ch5-1-8)\n        * [5-1-9  MLPClassifier](#ch5-1-9)\n    * [5-2  GridSearchCV](#ch5-2)\n        * [5-2-1  LogisticRegression](#ch5-2-1)\n        * [5-2-2  GaussianNB](#ch5-2-2)\n        * [5-2-3  SVC](#ch5-2-3)\n        * [5-2-4  LinearSVC](#ch5-2-4)\n        * [5-2-5  RandomForestClassifier](#ch5-2-5)\n        * [5-2-6  DecisionTreeClassifier](#ch5-2-6)\n        * [5-2-7  KNeighborsClassifier](#ch5-2-7)\n        * [5-2-8  Perceptron](#ch5-2-8)\n        * [5-2-9  MLPClassifier](#ch5-2-9)\n    * [5-3  Comparing models and decide models](#ch5-3)\n* [6  Predict each models](#ch6)\n* [7  Ensenble results](#ch7)\n* [8  Submit](#ch8)\n* [9  Conclusion](#ch9)","c8d41a48":"<a id=\"ch5-2-8\"><\/a>\n### 5-2-8 Perceptron","78fa6930":"Impute value of Age and Fare to test data and confirm that missing data is nothing too.","d8578d2e":"<a id=\"ch4\"><\/a>\n# 4 Preproccecing\n\nTo fit and predict with ML models, preprcess data.\n\nFirst, impute missingdata. Aming to more accurate imputing, use visualization(heatmap) and calculate setting values.\n\nSecond, transform from categorical variables into One-Hot with OneHotEncoder. \n\nThird, split train data into X_train and X_valid. To check generalization capability of each model.\n\nThen, fit MinMaxScaler and StandardScaler. To check variations of scores by changing data not scaled or MinMaxScaled, StandardScaled.","7610084f":"<a id=\"ch5-2-6\"><\/a>\n### 5-2-6 DecisionTreeClassifier","2d50f855":"Applying `pd.get_dummies`(OneHotEncoding) to train data.\n\nPclass is transformed to One-Hot.","5417af6f":"<a id=\"ch5-2-1\"><\/a>\n### 5-2-1 LogisticRegression","cc7c8de1":"<a id=\"ch6\"><\/a>\n# 6 Predict each models","9e49ae24":"test data has 418 rows. Age and Fare, Cabin columun has missing data.","57988f32":"<a id=\"ch5-2-9\"><\/a>\n### 5-2-9 MLPClassifier\n\nnote: The reason why the parameter is set roughly compared with other models is that MLPClassifier has a large amount of calculation, so setting it in detail makes the processing time too long.","d57c9ba4":"<a id=\"ch5-2\"><\/a>\n## 5-2 GridSearchCV\n\nGet scores with gridsearchCV same as default parameters and compare them.\n\nBy the way, default parameters are included in parameters calculated by gridsearchCV.\nAs a result, theoretically, the score will not be lower than the default parameter in gridsearchCV.\n(Since random numbers are used for calculation, gridsearchCV may be lower than the default parameter depending on them.)\n\nIn order to visualize the score of each parameter of gridsearchCV with heatmap, define function.","cd552ac4":"<a id=\"ch3\"><\/a>\n# 3  EDA(Explanatory Data Analysis)\n","11733d89":"<a id=\"ch5-2-7\"><\/a>\n### 5-2-7 KNeighborsClassifier","f132b077":"<a id=\"ch5-2-3\"><\/a>\n### 5-2-3 SVC","c49192fd":"<a id=\"ch5-1-2\"><\/a>\n### 5-1-2 GaussianNB","1017bfc7":"<a id=\"ch4-2\"><\/a>\n## 4-2 OneHot Encoding\n\nPclass is categorical variables but datatype is int64. So change datatype from int64 to string with train data.","05465f92":"<a id=\"ch2\"><\/a>\n# 2  Import libraries\nnote: Difine RANDOM_STATE to ensure the repeability.","ef95cf75":"<a id=\"ch5-1-6\"><\/a>\n### 5-1-6 DecisionTreeClassifier","c9a55133":"<a id=\"ch5-1-7\"><\/a>\n### 5-1-7 KNeighborsClassifier"}}