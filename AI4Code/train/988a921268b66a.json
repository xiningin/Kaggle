{"cell_type":{"9b91d4f2":"code","44a3dfab":"code","ec020d42":"code","c1e30760":"code","3548b2fa":"code","ad7a87ee":"code","d52a339d":"code","55fbdd92":"code","23bb9537":"code","cc9090c8":"code","ab3b0ec2":"code","cdbc56e5":"code","257918b8":"code","8740c4a3":"code","9ec6bf22":"code","989ecd00":"code","2dee841a":"code","1025e272":"code","a656e030":"code","3cdae3b8":"code","2f7572b8":"code","40025179":"code","3e28227d":"code","55ea5cf0":"code","33c1138c":"code","c37a9b79":"code","3a79bc0e":"code","cec46db9":"markdown","72a8d172":"markdown","4c8c5473":"markdown","aefdc6db":"markdown","3bff5f8c":"markdown","d01df9b6":"markdown"},"source":{"9b91d4f2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport datatable as dt\n%whos","44a3dfab":"%%time\ndata = pd.read_csv('..\/input\/tabular-playground-series-jan-2021\/train.csv')\nsubmission = dt.fread('..\/input\/tabular-playground-series-jan-2021\/test.csv').to_pandas()","ec020d42":"display(data.head())","c1e30760":"y = data.target.values\nX = data.drop(['id','target'], axis=1).values\nX.shape, y.shape","3548b2fa":"import seaborn as sns\nimport plotly.express as px\nfrom sklearn.preprocessing import scale","ad7a87ee":"print(f'Number of NA values in features: {pd.isnull(X).sum()}')","d52a339d":"plt.figure(figsize=(12,8))\nplt.title('Distribution of target variable')\nsns.distplot(y)\nplt.axis('off')","55fbdd92":"%%time\nplt.figure(figsize=(12,6))\nsns.pairplot(data.drop(['id'], axis=1))","23bb9537":"plt.figure(figsize=(12,6))\nplt.subplot(121)\nplt.title('Features Corr Matrix')\ncorr_mat=np.corrcoef(X.T)\nsns.heatmap(abs(corr_mat), cmap='rocket_r')\n\nplt.subplot(122)\nplt.title('Target vs Features')\nsns.heatmap(abs(np.corrcoef(y,X.T)[1:,0].reshape(-1,1)), cmap='rocket_r')","cc9090c8":"EPOCHS = 100\nDROP_Z_SCORE = 2.3","ab3b0ec2":"import tensorflow as tf\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler, FunctionTransformer, PowerTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom scipy import stats\nimport kerastuner as kt\n","cdbc56e5":"def _drop_outlier(df):\n    z_scores = stats.zscore(df)\n\n    abs_z_scores = np.abs(z_scores)\n    filtered_entries = (abs_z_scores < DROP_Z_SCORE).all(axis=1)\n    return df[filtered_entries]\n\ndef _custom_eng(x):\n    return x.drop(['id'],axis=1).values","257918b8":"feature_pipeline=Pipeline(steps=[\n    ('feature_eng', FunctionTransformer(_custom_eng, check_inverse=False)),\n#    ('outlier_dropper', FunctionTransformer(_drop_outlier, check_inverse=False)),\n    ('trnsfrmer', PowerTransformer(method='yeo-johnson')),\n    ('scaler', StandardScaler()),\n    ('pca', PCA())\n])","8740c4a3":"y_bins=pd.qcut(data.target, q=10)\ntrain,test = train_test_split(data, test_size=.2, random_state=42, stratify=y_bins)","9ec6bf22":"train,test=map(_drop_outlier,[train,test])","989ecd00":"train.shape, test.shape","2dee841a":"train_pipe_before = train.drop('target',axis=1)\ntest_pipe_before = test.drop('target',axis=1)\ntrainc = feature_pipeline.fit_transform(train_pipe_before)\ntestc = feature_pipeline.transform(test_pipe_before)\n\nX_train, y_train = trainc, train.target.values\nX_test, y_test = testc, test.target.values\n\nlist(map(lambda x: x.shape,[X_train, y_train, X_test, y_test]))","1025e272":"SHAPE = X_train.shape","a656e030":"def build_model(hp):\n    model = tf.keras.models.Sequential()\n    \n    # Layer 1\n    model.add(tf.keras.layers.Dense(hp.Int('units',min_value=10, max_value=100, step=32), activation='relu', input_shape=SHAPE))\n    model.add(tf.keras.layers.Dropout(hp.Float('rate', min_value=.05,max_value=.7,step=10)))\n    \n    # Layer 2\n    model.add(tf.keras.layers.Dense(hp.Int('units',min_value=10, max_value=100, step=32), activation='relu'))\n    model.add(tf.keras.layers.Dropout(hp.Float('rate', min_value=.05,max_value=.7,step=10)))\n    \n    # Layer 3\n    model.add(tf.keras.layers.Dense(hp.Int('units',min_value=10, max_value=100, step=32), activation='relu'))\n    model.add(tf.keras.layers.Dropout(hp.Float('rate', min_value=.05,max_value=.7,step=10)))\n    \n    # Last\n    model.add(tf.keras.layers.Dense(1, activation='linear'))\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n        loss='mse',\n        metrics=[tf.keras.metrics.RootMeanSquaredError()]\n    )\n    return model\n\ntuner = kt.tuners.RandomSearch(\n    build_model,\n    objective=kt.Objective(\"val_root_mean_squared_error\", direction=\"min\"),\n    max_trials=5,\n    executions_per_trial=3,\n    directory='fine_tune_results',\n    project_name='playground')\n\ntuner.search_space_summary()","3cdae3b8":"%%time \ntuner.search(X_train, y_train,\n             epochs=5,\n             validation_data=(X_test, y_test))\n\nmodel = tuner.get_best_models(num_models=1)[0]","2f7572b8":"import lightgbm as lgb\n\nlgb.__version__","40025179":"lgb_train = lgb.Dataset(\n    X_train, y_train,\n    feature_name = ['cont'+str(i) for i in range(14)],\n)\n\nparams = {\n    'boosting':'gbdt',\n    'objective': 'regression',\n    'metric': 'rmsle'\n}","3e28227d":"lgb_model=lgb.train(params, lgb_train,\n                   )","55ea5cf0":"id_col=submission.id\nprint(submission.shape)\n\nsub_ready=feature_pipeline.transform(submission)\nprint(sub_ready.shape)\nsub_ready","33c1138c":"predictions=(lgb_model.predict(sub_ready).reshape(-1,1)+model.predict(sub_ready))\/2","c37a9b79":"subm=id_col.to_frame()\nsubm['target'] = predictions\nsubm.set_index('id',inplace=True)\ndisplay(subm)","3a79bc0e":"subm.to_csv('.\/submission.csv')","cec46db9":"# EDA","72a8d172":"# Machine learning\n\n## Pipeline","4c8c5473":"## Fit several models\n### KERAS Feed Forward NN","aefdc6db":"# Submission","3bff5f8c":"### Lightgbm","d01df9b6":"# Read Files"}}