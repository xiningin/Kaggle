{"cell_type":{"87eba76c":"code","ef8f8cc7":"code","e5d66a4c":"code","14f42ef6":"code","95db5892":"code","6919ec30":"code","c0fe295b":"code","0d057240":"code","1f16d329":"code","ecac9812":"code","844f5352":"code","9fe1f9df":"code","93d96452":"code","42442cdd":"code","a77a6bde":"code","c53e3984":"code","e11d3a4c":"code","32fd5890":"code","7551b847":"code","82b38fff":"code","45f79bbb":"code","8f9989c8":"code","444be37b":"code","ec039e75":"code","794505ea":"code","c12c25b1":"code","8804adad":"code","f6510d99":"code","df85fe24":"code","58de3cce":"code","5f979830":"code","183fc5ef":"code","0ef65b75":"code","9dff98f9":"code","8e3401b8":"code","1d76f1ba":"code","5b90d90d":"code","feef1ad4":"code","b1d92e21":"code","69b67cd6":"code","e59a515c":"code","8523bbd8":"code","4d99d6c0":"code","5fc4839b":"code","00ed0f43":"code","b693bfec":"code","12f457da":"code","f24cea0e":"code","72202b67":"code","1919df9a":"code","fb59b9a0":"code","fe5ff60b":"code","e1c33f78":"markdown","c16facb2":"markdown","4d9f3baf":"markdown","fcf11441":"markdown","6cb9ac1a":"markdown","b1337a98":"markdown","46027c01":"markdown","7192d027":"markdown","aa0bc297":"markdown","8da50ba4":"markdown","0f8c967c":"markdown","d0cb562f":"markdown","4ea66967":"markdown"},"source":{"87eba76c":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix, \\\n                            classification_report, f1_score, roc_curve, auc\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom keras.models import Model\nfrom keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.callbacks import EarlyStopping\nfrom wordcloud import WordCloud\nfrom collections import Counter, defaultdict\nimport nltk\nimport nltk as nlp\nimport string\nimport re\n","ef8f8cc7":"true = pd.read_csv(\"..\/input\/fake-news-training-and-testing\/FakeNews-training.csv\")\nfake = pd.read_csv(\"..\/input\/fake-news-training-and-testing\/FakeNews-testing.csv\")","e5d66a4c":"fake['target'] = 'fake'\ntrue['target'] = 'true'\nnewstot = pd.concat([fake, true]).reset_index(drop = True)\nnewstot.head()","14f42ef6":"for key,count in fake.subject.value_counts().iteritems():\n    print(f\"{key}:\\t{count}\")\n\nprint(f\"Total Records:\\t{fake.shape[0]}\")","95db5892":"for key,count in true.subject.value_counts().iteritems():\n    print(f\"{key}:\\t{count}\")\n\n    print(f\"Total Records:\\t{true.shape[0]}\")","6919ec30":"fake['fake'] = 1\ntrue['fake'] = 0\n\ndata_df = pd.concat([fake, true], ignore_index=True)\n\nplt.figure(figsize=(6,6))\nsns.countplot(\"subject\", data=fake)\nplt.xticks(rotation=90)\nplt.xlabel('Subject-Fake')\nplt.show()\n\nplt.figure(figsize=(4,6))\nsns.countplot(\"subject\", data=true)\nplt.xticks(rotation=90)\nplt.xlabel('Subject-True')\nplt.show()\n\nplt.figure(figsize=(4,6))\nax = sns.countplot(x=\"fake\", data=data_df)\nax.set_xticklabels(['Real', 'Fake'])\nplt.xlabel('Classification')\nplt.xticks(rotation=90)\nplt.show()","c0fe295b":"data_df['title_length'] = data_df['title'].apply(lambda x : len(x.strip().split()))\ndata_df['text_length'] = data_df['text'].apply(lambda x : len(x.strip().split()))\n\nplt.figure(figsize=(12,6))\nsns.distplot(data_df[data_df['fake'] == 1]['title_length'], \n             kde=False, label='Fake', bins=20)\nsns.distplot(data_df[data_df['fake'] == 0]['title_length'], \n             kde=False, label='True', bins=20)\nplt.xlabel('Title Length', weight='bold')\nplt.title('Length of title comparison', weight='bold')\nplt.legend()\nplt.show()","0d057240":"fig = plt.figure(figsize=(10, 6))\nplt.title(\"Word counts of article titles\", fontsize=16, weight='bold')\nax = sns.boxplot(x=\"fake\", y=\"title_length\", data=data_df)\nax.set_xticklabels(['Real', 'Fake'])\nax.set_xlabel(\"Article Classification\", fontsize=14, weight='bold') \nax.set_ylabel(\"Length of Entry (Words)\", fontsize=14, weight='bold')\nplt.show()","1f16d329":"plt.figure(figsize=(12,6))\nsns.distplot(data_df[data_df['fake'] == 1]['text_length'], \n             kde=False, label='Fake', bins=20)\nsns.distplot(data_df[data_df['fake'] == 0]['text_length'], \n             kde=False, label='True', bins=20)\nplt.xlabel('Text Length', weight='bold')\nplt.title('Length of title comparison', weight='bold')\nplt.xlim(0.0, 4500)\nplt.legend()\nplt.show()","ecac9812":"fig = plt.figure(figsize=(10, 6))\nplt.title(\"Word counts of article text\", fontsize=16, weight='bold')\nax = sns.boxplot(x=\"fake\", y=\"text_length\", data=data_df)\nax.set_xticklabels(['Real', 'Fake'])\nax.set_xlabel(\"Article Classification\", fontsize=14, weight='bold') \nax.set_ylabel(\"Length of Entry (Words)\", fontsize=14, weight='bold')\nplt.ylim(0.0, 3000.0)\nplt.show()","844f5352":"def create_corpus(text_data):\n    corpus = []\n    for sentence in text_data:\n        for word in sentence.split():\n            corpus.append(word)\n    return corpus\n            \ndef top_words(text_corpus, top_n=25, return_dict=False):\n    def_dict = defaultdict(int)\n    for word in text_corpus:\n        def_dict[word] += 1\n    most_common = sorted(def_dict.items(), key=lambda x : x[1], reverse=True)[:top_n]\n    if return_dict:\n        return most_common, def_dict\n    else:    \n        return most_common\n    \ntop_n = 100\ntext_field = \"title\"\n\nfake_corpus = create_corpus(fake[text_field].values)\nfake_top_n_words, fake_symptom_dict = top_words(fake_corpus, top_n=top_n, return_dict=True)\nfake_words, fake_word_counts = zip(*fake_top_n_words)\n\ndef plot_words(word_list, word_counts, n, text_description, figsize=(30,5)):\n    plt.figure(figsize=figsize)\n    plt.xticks(rotation=90)\n    plt.bar(word_list, word_counts)\n    plt.title(f\"Top {n} words in {text_description}\", weight='bold')\n    plt.ylabel(\"Word Count\", weight='bold')\n    plt.show()\n\nplot_words(fake_words, fake_word_counts, 100, \"Fake Article Titles\")\nprint(f\"Total unique words in {text_field}: {len(fake_symptom_dict)}\")\n\ntop_n = 50\ntext_field = \"title\"\n\ntrue_corpus = create_corpus(true[text_field].values)\ntrue_top_n_words, true_symptom_dict = top_words(true_corpus, top_n=top_n, return_dict=True)\ntrue_words, true_word_counts = zip(*true_top_n_words)\n\nplot_words(true_words, true_word_counts, 50, \"True Article Titles\")\nprint(f\"Total unique words in {text_field}: {len(true_symptom_dict)}\")\n","9fe1f9df":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(true_y, pred_y, title='Confusion Matrix', figsize=(8,6)):\n\n    conf_matrix = confusion_matrix(true_y, pred_y)\n    conf_df = pd.DataFrame(conf_matrix, columns=np.unique(true_y), index = np.unique(true_y))\n    conf_df.index.name = 'Actual'\n    conf_df.columns.name = 'Predicted'\n    plt.figure(figsize = figsize)\n    plt.title(title)\n    sns.set(font_scale=1.4)\n    sns.heatmap(conf_df, cmap=\"Blues\", annot=True, \n                annot_kws={\"size\": 16}, fmt='g')\n    plt.show()","93d96452":"x_train,x_test,y_train,y_test = train_test_split(newstot['text'], newstot.target, test_size=0.2, random_state=2020)\n\npipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', LogisticRegression())])\n\nmodel_log = pipe.fit(x_train, y_train)\nprediction = model_log.predict(x_test)\nacc_LG = round(model_log.score(x_train, y_train)*80,20)\nacc_LG","42442cdd":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"Logistic Regression classifier accuracy: {0:.2f}%\".format(model_log.score(x_train, y_train)*80,20))\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"Logistic Regression Confusion Matrix\", figsize=(5,5))\n\nprint(classification_report(y_test, prediction))","a77a6bde":"from sklearn.metrics import f1_score\nf1_LG = f1_score(y_test, prediction, average='weighted')\nprint('F1 score: %f' % f1_LG)","c53e3984":"x_train,x_test,y_train,y_test = train_test_split(newstot['text'], newstot.target, test_size=0.2, random_state=2020)\n\npipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', LinearSVC())])\n\nmodel_SVC = pipe.fit(x_train, y_train)\nprediction = model_SVC.predict(x_test)\nacc_SVC = round(model_SVC.score(x_train, y_train)*80,20)\nacc_SVC","e11d3a4c":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"SVC classifier accuracy: {0:.2f}%\".format(model_log.score(x_train, y_train)*80,20))\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"SVC Confusion Matrix\", figsize=(5,5))\n\nprint(classification_report(y_test, prediction))","32fd5890":"from sklearn.metrics import f1_score\nf1_SVC = f1_score(y_test, prediction, average='weighted')\nprint('F1 score: %f' % f1_SVC)","7551b847":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', MultinomialNB())])\n\nmodel_MNB = pipe.fit(x_train, y_train)\nprediction = model_MNB.predict(x_test)\nacc_MNB = round(model_MNB.score(x_train, y_train)*80,20)\nacc_MNB","82b38fff":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"Multinomial Naive Bayes classifier accuracy: {0:.2f}%\".format(model_log.score(x_train, y_train)*80,20))\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"Multinomial Naive Bayes Classifier Confusion Matrix\", figsize=(5,5))\n\nprint(classification_report(y_test, prediction))","45f79bbb":"from sklearn.metrics import f1_score\nf1_MNB = f1_score(y_test, prediction, average='weighted')\nprint('F1 score: %f' % f1_MNB)","8f9989c8":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', BernoulliNB())])\n\nmodel_BNB = pipe.fit(x_train, y_train)\nprediction = model_BNB.predict(x_test)\nacc_BNB = round(model_BNB.score(x_train, y_train)*80,20)\nacc_BNB","444be37b":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"Barnoulli Naive Bayes classifier accuracy: {0:.2f}%\".format(model_log.score(x_train, y_train)*80,20))\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"Barnoulli Naive Bayes Confusion Matrix\", figsize=(5,5))\n\nprint(classification_report(y_test, prediction))","ec039e75":"from sklearn.metrics import f1_score\nf1_BNB = f1_score(y_test, prediction, average='weighted')\nprint('F1 score: %f' % f1_BNB)","794505ea":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', GradientBoostingClassifier(loss = 'deviance',\n                                                   learning_rate = 0.01,\n                                                   n_estimators = 10,\n                                                   max_depth = 5,\n                                                   random_state=55))])\n\nmodel_GB = pipe.fit(x_train, y_train)\nprediction = model_GB.predict(x_test)\nacc_GB = round(model_GB.score(x_train, y_train)*80,20)\nacc_GB","c12c25b1":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"Gradient Boost classifier accuracy: {0:.2f}%\".format(model_log.score(x_train, y_train)*80,20))\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"Gradient Boost Confusion Matrix\", figsize=(5,5))\n\nprint(classification_report(y_test, prediction))","8804adad":"from sklearn.metrics import f1_score\nf1_GB = f1_score(y_test, prediction, average='weighted')\nprint('F1 score: %f' % f1_GB)","f6510d99":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', XGBClassifier(loss = 'deviance',\n                                                   learning_rate = 0.01,\n                                                   n_estimators = 10,\n                                                   max_depth = 5,\n                                                   random_state=2020))])\n\nmodel_XGB = pipe.fit(x_train, y_train)\nprediction = model_XGB.predict(x_test)\nacc_XGB = round(model_XGB.score(x_train, y_train)*80,20)\nacc_XGB","df85fe24":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"XGBoost classifier accuracy: {0:.2f}%\".format(model_log.score(x_train, y_train)*80,20))\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"XGBoost Confusion Matrix\", figsize=(5,5))\n\nprint(classification_report(y_test, prediction))","58de3cce":"from sklearn.metrics import f1_score\nf1_XGB = f1_score(y_test, prediction, average='weighted')\nprint('F1 score: %f' % f1_XGB)","5f979830":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', SGDClassifier())])\n\nmodel_SGD = pipe.fit(x_train, y_train)\nprediction = model_SGD.predict(x_test)\nacc_SGD = round(model_SGD.score(x_train, y_train)*80,20)\nacc_SGD","183fc5ef":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"Stochastic Gradient Descent classifier accuracy: {0:.2f}%\".format(model_log.score(x_train, y_train)*80,20))\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"Stochastic Gradient Descent Confusion Matrix\", figsize=(5,5))\n\nprint(classification_report(y_test, prediction))","0ef65b75":"from sklearn.metrics import f1_score\nf1_SGD = f1_score(y_test, prediction, average='weighted')\nprint('F1 score: %f' % f1_SGD)","9dff98f9":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', DecisionTreeClassifier(criterion= 'entropy',\n                                           max_depth = 10, \n                                           splitter='best', \n                                           random_state=2020))])\n\nmodel_DT = pipe.fit(x_train, y_train)\nprediction = model_DT.predict(x_test)\nacc_DT = round(model_DT.score(x_train, y_train)*80,20)\nacc_DT","8e3401b8":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"Decision Tree classifier accuracy: {0:.2f}%\".format(model_log.score(x_train, y_train)*80,20))\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"Decision Tree Confusion Matrix\", figsize=(5,5))\n\nprint(classification_report(y_test, prediction))","1d76f1ba":"from sklearn.metrics import f1_score\nf1_DT = f1_score(y_test, prediction, average='weighted')\nprint('F1 score: %f' % f1_DT)","5b90d90d":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', RandomForestClassifier(n_estimators=100))])\n\nmodel_RF = pipe.fit(x_train, y_train)\nprediction = model_RF.predict(x_test)\nacc_RF = round(model_RF.score(x_train, y_train)*80,20)\nacc_RF","feef1ad4":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"Random Forest classifier accuracy: {0:.2f}%\".format(model_log.score(x_train, y_train)*80,20))\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"Random Forest Confusion Matrix\", figsize=(5,5))\nprint(classification_report(y_test, prediction))","b1d92e21":"from sklearn.metrics import f1_score\nf1_RF = f1_score(y_test, prediction, average='weighted')\nprint('F1 score: %f' % f1_RF)","69b67cd6":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', KNeighborsClassifier(n_neighbors = 10,weights = 'distance',algorithm = 'brute'))])\n\nmodel_KNN = pipe.fit(x_train, y_train)\nprediction = model_KNN.predict(x_test)\nacc_KNN = round(model_KNN.score(x_train, y_train)*80,20)\nacc_KNN","e59a515c":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"KNN classifier accuracy: {0:.2f}%\".format(model_log.score(x_train, y_train)*80,20))\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"KNN Confusion Matrix\", figsize=(5,5))\n\nprint(classification_report(y_test, prediction))","8523bbd8":"from sklearn.metrics import f1_score\nf1_KNN = f1_score(y_test, prediction, average='weighted')\nprint('F1 score: %f' % f1_KNN)","4d99d6c0":"from sklearn.metrics import accuracy_score\nacc = (accuracy_score(y_test,prediction))\nprint('Accuracy score: %f' % acc)","5fc4839b":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test, prediction))","00ed0f43":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,prediction))","b693bfec":"X = newstot.text\nY = newstot.target\nle = LabelEncoder()\nY = le.fit_transform(Y)\nY = Y.reshape(-1,1)","12f457da":"X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)\nmax_words = 500\nmax_len = 75\ntok = Tokenizer(num_words=max_words)\ntok.fit_on_texts(X_train)\nsequences = tok.texts_to_sequences(X_train)\nsequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\ndef RNN():\n    inputs = Input(name='inputs',shape=[max_len])\n    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n    layer = LSTM(64)(layer)\n    layer = Dense(256,name='FC1')(layer)\n    layer = Activation('relu')(layer)\n    layer = Dropout(0.5)(layer)\n    layer = Dense(1,name='out_layer')(layer)\n    layer = Activation('sigmoid')(layer)\n    model = Model(inputs=inputs,outputs=layer)\n    return model\nmodel = RNN()","f24cea0e":"from tensorflow.keras.utils import plot_model \nplot_model(model, to_file='model1.png')\nmodel.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])","72202b67":"model.fit(sequences_matrix,Y_train,batch_size=32,epochs=5,\n          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])","1919df9a":"test_sequences = tok.texts_to_sequences(X_test)\ntest_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\naccr = model.evaluate(test_sequences_matrix,Y_test)\nprint('Accuracy: {:0.2f}%'.format(accr[1]*100))","fb59b9a0":"labels = ['Logistic Regression','SVC','Multinomial Naive Bayes','Bernoulli Naive Bayes','Gradient Boost','XGBoost','Stochastic Gradient Descent','Decision Tree', 'Random Forest', 'KNN']\nfscores= [f1_LG, f1_SVC ,f1_MNB, f1_BNB ,f1_GB,f1_XGB, f1_SGD,f1_DT, f1_RF, f1_KNN]\n\nx = np.arange(len(labels))  \nwidth = 0.2 \n\nfig, ax = plt.subplots(figsize=(30, 30))\nrects1 = ax.bar(x - width\/2, fscores, width, label='F1-Scores')\n\nax.set_ylabel('F1-Score Value')\nax.set_title('F1-Score by Specific Algorithm')\nax.set_xticks(x)\nax.set_xticklabels(labels, rotation='vertical')\nax.legend()\n\ndef autolabel(rects):\n    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() \/ 2, height),\n                    xytext=(0, 0.5), \n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\n\n\nautolabel(rects1)\nplt.show()","fe5ff60b":"labels = ['Logistic Regression','SVC','Multinomial Naive Bayes','Bernoulli Naive Bayes','Gradient Boost','XGBoost','Stochastic Gradient Descent','Decision Tree', 'Random Forest', 'KNN']\nfscores= [acc_LG, acc_SVC, acc_MNB, acc_BNB, acc_GB, acc_XGB, acc_SGD, acc_DT, acc_RF, acc_KNN]\n\nx = np.arange(len(labels))  \nwidth = 0.4 \n\nfig, ax = plt.subplots(figsize=(30, 30))\nrects1 = ax.bar(x - width\/2, fscores, width, label='Accuracies')\n\nax.set_ylabel('Accuracy Value')\nax.set_title('Accuracy by Specific Algorithm')\nax.set_xticks(x)\nax.set_xticklabels(labels, rotation='vertical')\nax.legend()\n\ndef autolabel(rects):\n    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() \/ 2, height),\n                    xytext=(0, 0.5),\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\n\n\nautolabel(rects1)\nplt.show()","e1c33f78":"# Library and Data","c16facb2":"# Reading Data","4d9f3baf":"# Random Forest Classifier","fcf11441":"# Gradient Boost Classifier","6cb9ac1a":"# Support Vector Classifier","b1337a98":"# KNN Classifier","46027c01":"# LSTM","7192d027":"# Decision Tree","aa0bc297":"# Bernoulli Naive Bayes Classifier","8da50ba4":"# Logistic Regression Classifier","0f8c967c":"# XGBoost Classifier","d0cb562f":"# Multinomial Naive Bayes Classifier","4ea66967":"# Stochastic Gradient Descent"}}