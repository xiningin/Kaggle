{"cell_type":{"a8052709":"code","566eb85a":"code","909128bb":"code","fabc6038":"code","b76943c5":"code","60796db4":"code","e6004cad":"code","3b5c51cb":"code","70ed0701":"code","405f1962":"code","a5974731":"code","3a54a5b5":"code","c1ca8880":"code","05fcc887":"code","847f734c":"code","62551461":"code","5fa048fa":"code","5f3c4efa":"code","40425425":"code","08dd584c":"code","4b2fef8a":"code","0f70a92c":"code","56e426ef":"code","2bd6d8bf":"code","884714c3":"code","f086e01f":"code","a068b2af":"code","f61dc95b":"code","f30fb682":"code","960a77a4":"code","59b837d2":"code","08601da1":"code","d5074904":"code","98af32ef":"code","fed1c048":"code","e4837f3b":"code","d194516d":"code","5dc21e79":"code","fa119dc2":"code","10c40dca":"code","12dacb8f":"code","d43d5d3e":"code","138e10d3":"code","18df1ce1":"code","6ea4d4ef":"code","4e7d60fd":"code","df27e308":"code","1f70d737":"code","ebf38443":"code","ed6556d2":"code","73126813":"code","99a39106":"code","ee6e03c7":"code","9d9aeea2":"code","87fb81f5":"code","ce3f78f4":"code","4a7026ff":"code","af127945":"code","e1dff9d3":"code","e632667d":"code","7c56d6ec":"code","5cab4375":"code","aeb7c202":"code","2b250ead":"code","6c1bdc80":"markdown","943edb2f":"markdown","e4e3e524":"markdown","6bd3bacb":"markdown","830c6605":"markdown","f0dcf714":"markdown","ce501e47":"markdown","87340777":"markdown","14d2ea00":"markdown","731f1342":"markdown","74ee02fc":"markdown","1514a0dd":"markdown","8ce26029":"markdown","d691f9fb":"markdown","53a175cd":"markdown","6dd539af":"markdown","33a9dad2":"markdown","43122679":"markdown","fc66beff":"markdown","da53692b":"markdown","c0584410":"markdown","29a5a26d":"markdown","7997b28a":"markdown","241de245":"markdown","ea52a39a":"markdown","10ff3997":"markdown","969ff8b2":"markdown","2a407098":"markdown","faff3698":"markdown","174bbb54":"markdown","e8a46465":"markdown","15721345":"markdown","07b31f37":"markdown","85fa54c8":"markdown","81998698":"markdown","8d70767f":"markdown","31ea1b94":"markdown","f3701f48":"markdown","c60dbe16":"markdown","e4b89788":"markdown","3c79fbd9":"markdown","dfc3299a":"markdown","4a9115c2":"markdown"},"source":{"a8052709":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.mlab as mlab\n%matplotlib inline","566eb85a":"\ndf = pd.read_csv(\"..\/input\/indian-liver-patient-records\/indian_liver_patient.csv\")\ndf.head()\n","909128bb":"# dataframe dimensions\nprint(\"This dataframe has {} rows and {} columns\".format(*df.shape))","fabc6038":"df.info()","b76943c5":"numerical_cols = df.select_dtypes(include=\"number\").columns\nprint('There are',len(numerical_cols),'numeric columns')","60796db4":"categorical_cols = df.select_dtypes(include=\"object\").columns\n\nprint('There are',len(categorical_cols),'categorical columns')","e6004cad":"df.rename(columns={'Dataset':'target'},inplace=True)\ndf.head()","3b5c51cb":"target_counts=df['target'].value_counts().values\ngender_counts=df['Gender'].value_counts().values\n\nfig1, axes=plt.subplots(nrows=1, ncols=2,figsize=(10,5))\n\n\ntarget_sizes=df.groupby('target').size()\naxes[0].pie(\n    x=target_counts,\n    labels=['patient({})'.format(target_sizes[1]),'not patient({})'.format(target_sizes[2])],\n    autopct='%1.1f%%'\n)\naxes[0].set_title(\"Percentage of liver patient\")\n\ngender_sizes=df.groupby('Gender').size()\naxes[1].pie(\n    x=gender_counts, \n    labels=['male({})'.format(gender_sizes['Male']), 'female({})'.format(gender_sizes['Female'])], \n    autopct=\"%1.1f%%\"\n)\naxes[1].set_title(\"Age wise liver patient\")","70ed0701":"df['Gender'].value_counts().plot.bar(color='peachpuff')","405f1962":"df.describe().T","a5974731":"df.dtypes.value_counts()","3a54a5b5":"cat_col = ['Gender','target']\nprint('Categorical columns in the dataset are :',cat_col)\nprint('No of values in each categories   ')\nfor i in cat_col:\n   print('Column = ',i)\n   print(df[i].value_counts())","c1ca8880":"print('Percentage of categories in each variable')\nfor i in cat_col:\n   print('Column = ',i)\n   print(df[i].value_counts()\/len(df[i]))    ","05fcc887":"df.isnull().sum()     ","847f734c":"df['Albumin_and_Globulin_Ratio'].fillna(df['Albumin_and_Globulin_Ratio'].mean(), inplace=True)\ndf.info()","62551461":"cols = df.select_dtypes(exclude='object')\nq=1\nplt.figure(figsize=(15,20))\nfor col in cols:\n   plt.subplot(5,5,q)\n   ax = sns.boxplot(df[col],color='red')\n   plt.xlabel(col)\n   q+=1\nplt.show()","5fa048fa":"plt.subplot(1,2,1)\nax = sns.countplot(data=df, x='target')\nplt.title('Liver patient', fontsize=15)\nfor i in ax.patches:\n    \n    ax.text(i.get_x()+0.3, i.get_height(), str(round(i.get_height(), 2)), fontsize=15, color='red')\n\n","5f3c4efa":"print('We will be using smote when we will splitting the dataset in train and test')\n","40425425":"plt.figure(figsize=(20, 10))\nsns.heatmap(df.corr(), cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 15},\n           cmap= 'coolwarm')\nplt.title('Correlation between features');","08dd584c":"g = sns.FacetGrid(df, col=\"Gender\", row=\"target\", margin_titles=True)\ng.map(plt.scatter,\"Direct_Bilirubin\", \"Total_Bilirubin\", edgecolor=\"w\")\nplt.subplots_adjust(top=0.9)","4b2fef8a":"# plotting all the dependent variables with target variable\n# plotting scatter plot of continous variable with target variable\nnum_cols=['Age', 'Total_Bilirubin', 'Direct_Bilirubin',\n     'Alkaline_Phosphotase', 'Alamine_Aminotransferase', 'Aspartate_Aminotransferase', 'Total_Protiens',\n     'Albumin', 'Albumin_and_Globulin_Ratio']\nq=1\nplt.figure(figsize=(15,25))\n\nfor i in num_cols:\n   plt.subplot(4,3,q)\n   plt.title(i)\n   plt.scatter(df[i],df[\"target\"])\n   plt.xlabel(i)\n   plt.ylabel(\"target\")\n   q+=1\nplt.show()","0f70a92c":"g = sns.FacetGrid(df, col=\"Gender\", row=\"target\", margin_titles=True)\ng.map(plt.scatter,\"Albumin_and_Globulin_Ratio\", \"Total_Protiens\",  edgecolor=\"w\")\nplt.subplots_adjust(top=0.9)","56e426ef":"sns.jointplot(\"Albumin_and_Globulin_Ratio\", \"Albumin\", data=df, kind=\"reg\")","2bd6d8bf":"# Converting gender into dummies\ndf = pd.get_dummies(df,columns = ['Gender'],drop_first = True)","884714c3":"df.head()","f086e01f":"import scipy.stats as st","a068b2af":"X=df.drop('target', axis=1)\nY= df['target']","f61dc95b":"from sklearn.model_selection import train_test_split\nX_train ,X_test, Y_train , Y_test = train_test_split(X , Y , test_size = 0.30 , random_state =42)\nX_train.shape , Y_train.shape","f30fb682":"st.f_oneway(Y_train,Y_test,Y)","960a77a4":"from sklearn.metrics import accuracy_score\n\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression","59b837d2":" ## using Logistic Regression\n# Create logistic regression object\nlogreg = LogisticRegression()\n# Train the model using the training sets and check score\nlogreg.fit(X_train, Y_train)\n#Predict Output\nlog_predicted= logreg.predict(X_test)\n\nlogreg_score = round(logreg.score(X_train, Y_train) * 100, 2)\nlogreg_score_test = round(logreg.score(X_test, Y_test) * 100, 2)\n#Equation coefficient and Intercept\nprint('Logistic Regression Training Score: \\n', logreg_score)\nprint('Logistic Regression Test Score: \\n', logreg_score_test)\nprint('Coefficient: \\n', logreg.coef_)\nprint('Intercept: \\n', logreg.intercept_)\nprint('Accuracy: \\n', accuracy_score(Y_test,log_predicted))\nprint('Confusion Matrix: \\n', confusion_matrix(Y_test,log_predicted))\nprint('Classification Report: \\n', classification_report(Y_test,log_predicted))\n\nsns.heatmap(confusion_matrix(Y_test,log_predicted),annot=True,fmt=\"d\")","08601da1":"# reading the coefficient parameters\npd.DataFrame(zip(list(X_train.columns),list(logreg.coef_[0])), columns=[\"Variable\",\"Coefficient\"])\\\n.sort_values('Coefficient').style.background_gradient(cmap='viridis', low=0.2, high=0.2)\n","d5074904":"from sklearn.metrics import cohen_kappa_score","98af32ef":"print('Cohen Kappa Score on this model',cohen_kappa_score(Y_test,log_predicted))","fed1c048":"\nprint(f'Coefficients: {logreg.coef_}')\nprint(f'Intercept: {logreg.intercept_}')\nprint(f'R^2 score: {logreg.score(X, Y)}')","e4837f3b":"# Hyper parameter tuning for logistic regression","d194516d":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, binarize\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n","5dc21e79":"# creating parameter grid\ndict_params = {\"penalty\" : [\"l1\", \"l2\"],\n               \"C\" : [0.001, 0.01, 0.1, 1, 10, 100]}\n\n# hyperparameter tuning\nbase_model = LogisticRegression()\nmodel_tuning = GridSearchCV(base_model, param_grid=dict_params, scoring=\"roc_auc\", cv=4, return_train_score=True)\nmodel_tuning.fit(X,Y)\n\n# model results\ncv_results = pd.DataFrame(model_tuning.cv_results_)\ncv_results['train_test_diff'] = cv_results['mean_train_score'] - cv_results['mean_test_score']\ncv_results.sort_values('train_test_diff')[[\"param_C\",\"param_penalty\",\"mean_train_score\",\"mean_test_score\",'train_test_diff']]","fa119dc2":"# visualizing training and testing accuracy\nplt.plot(cv_results.index+1, cv_results[\"mean_test_score\"], label=\"test score\")\nplt.plot(cv_results.index+1, cv_results[\"mean_train_score\"], label=\"train score\")\nplt.title(\"Training vs. Test score\")\nplt.ylabel(\"ROC AUC Score\")\nplt.xlabel(\"Iteration\")\nplt.legend()\nplt.grid()\nplt.show()","10c40dca":"# fitting model with best params\nmodel_logit = LogisticRegression(penalty='l1', C=100)\nmodel_logit.fit(X_train, Y_train)\ny_pred = model_logit.predict(X_test)","12dacb8f":"# confusion matrix\ncm = pd.DataFrame(confusion_matrix(Y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n\n# plotting test results confusion matrix\nplt.figure(figsize=(5,5))\nsns.heatmap(cm, cmap=\"RdYlGn\", annot=True, cbar=False, square=True)\nplt.xlabel(\"Predicted values\", fontsize=12)\nplt.ylabel(\"Actual values\", fontsize=12)\nplt.title(\"Test results\", fontsize=20)\nplt.show()\n\ncm_reference = pd.DataFrame(np.array([\"TN\",\"FP\",\"FN\",\"TP\"]).reshape(2,2), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\nprint(cm_reference)","d43d5d3e":"# calculating TP,TN,FP,FN\nTN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n\n# print values\nprint(\"True positives:\", TP)\nprint(\"True negatives:\", TN)\nprint(\"False positives (Type I error):\", FP)\nprint(\"False negatives (Type II error):\", FN)","138e10d3":"df_results = pd.DataFrame(columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy','F1-score','ROC AUC'])","18df1ce1":"# itereation results\ndescription = \"Logit with hyperparamter tuning\"\nmisclassifications = FP + FN\ntype1 = FP\ntype2 = FN\nprecision = round(precision_score(Y_test,y_pred),2)\nrecall = round(recall_score(Y_test,y_pred),2)\naccuracy = round(accuracy_score(Y_test,y_pred),2)\nf1 = round(f1_score(Y_test,y_pred),2)\nauc = round(roc_auc_score(Y_test,y_pred),2)\n\ndf_results = pd.concat([df_results,\n                        pd.DataFrame(np.array([description,\n                                     misclassifications,\n                                     type1,\n                                     type2,\n                                     precision,\n                                     recall,\n                                     accuracy,\n                                     f1,\n                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy','F1-score','ROC AUC'])\n                                  ], axis=0)\n\ndf_results","6ea4d4ef":"from sklearn.neighbors import KNeighborsClassifier\n\n# fitting base model with default params\nmodel_knn = KNeighborsClassifier()\nmodel_knn.fit(X_train, Y_train)","4e7d60fd":"# predicting X_test\ny_pred = model_knn.predict(X_test)\n\n# checking for model overfit\nprint(\"Training accuracy:\", accuracy_score(Y_train,model_knn.predict(X_train)))\nprint(\"Test accuracy:\", accuracy_score(Y_test,y_pred))","df27e308":"# confusion matrix\ncm = pd.DataFrame(confusion_matrix(Y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n\n# plotting test results confusion matrix\nplt.figure(figsize=(5,5))\nsns.heatmap(cm, cmap=\"RdYlGn\", annot=True, cbar=False, square=True)\nplt.xlabel(\"Predicted values\", fontsize=12)\nplt.ylabel(\"Actual values\", fontsize=12)\nplt.title(\"Test results\", fontsize=20)\nplt.show()\n\ncm_reference = pd.DataFrame(np.array([\"TN\",\"FP\",\"FN\",\"TP\"]).reshape(2,2), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\nprint(cm_reference)","1f70d737":"# calculating TP,TN,FP,FN\nTN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n\n# print values\nprint(\"True positives:\", TP)\nprint(\"True negatives:\", TN)\nprint(\"False positives (Type I error):\", FP)\nprint(\"False negatives (Type II error):\", FN)","ebf38443":"# itereation results\ndescription = \"Base kNN model\"\nmisclassifications = FP + FN\ntype1 = FP\ntype2 = FN\nprecision = round(precision_score(Y_test,y_pred),2)\nrecall = round(recall_score(Y_test,y_pred),2)\naccuracy = round(accuracy_score(Y_test,y_pred),2)\nf1 = round(f1_score(Y_test,y_pred),2)\nauc = round(roc_auc_score(Y_test,y_pred),2)\n\ndf_results = pd.concat([df_results,\n                        pd.DataFrame(np.array([description,\n                                     misclassifications,\n                                     type1,\n                                     type2,\n                                     precision,\n                                     recall,\n                                     accuracy,\n                                     f1,\n                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy','F1-score','ROC AUC'])\n                                  ], axis=0)\n\ndf_results","ed6556d2":"## Optimizing for optimal k value.","73126813":"# k values for model complexity\nneig = np.arange(1, 25)\ntrain_accuracy, test_accuracy = [], []\n\n# loop over different values of k\nfor k in neig:\n    # k from 1 to 25(exclude)\n    knn = KNeighborsClassifier(n_neighbors=k)\n    # Fit with knn\n    knn.fit(X_train,Y_train)\n    #train accuracy\n    train_accuracy.append(knn.score(X_train, Y_train))\n    # test accuracy\n    test_accuracy.append(knn.score(X_test, Y_test))\n\n# Plot\nplt.figure(figsize=[12,8])\nplt.plot(neig, test_accuracy, label = 'Testing Accuracy')\nplt.plot(neig, train_accuracy, label = 'Training Accuracy')\nplt.legend()\nplt.title('Value VS Accuracy',fontsize=20)\nplt.xlabel('Number of Neighbors',fontsize=20)\nplt.ylabel('Accuracy',fontsize=20)\nplt.xticks(neig)\nplt.grid()\nplt.show()\nprint(\"Best accuracy is {} with k = {}\".format(np.max(test_accuracy),1+test_accuracy.index(np.max(test_accuracy))))","99a39106":"# fitting base model with k=6\nmodel_knn = KNeighborsClassifier(n_neighbors=6)\nmodel_knn.fit(X_train, Y_train)","ee6e03c7":"# predicting X_test\ny_pred = model_knn.predict(X_test)\n\n# checking for model overfit\nprint(\"Training accuracy:\", accuracy_score(Y_train,model_knn.predict(X_train)))\nprint(\"Test accuracy:\", accuracy_score(Y_test,y_pred))","9d9aeea2":"# confusion matrix\ncm = pd.DataFrame(confusion_matrix(Y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n\n# plotting test results confusion matrix\nplt.figure(figsize=(5,5))\nsns.heatmap(cm, cmap=\"RdYlGn\", annot=True, cbar=False, square=True)\nplt.xlabel(\"Predicted values\", fontsize=12)\nplt.ylabel(\"Actual values\", fontsize=12)\nplt.title(\"Test results\", fontsize=20)\nplt.show()\n\ncm_reference = pd.DataFrame(np.array([\"TN\",\"FP\",\"FN\",\"TP\"]).reshape(2,2), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\nprint(cm_reference)","87fb81f5":"# calculating TP,TN,FP,FN\nTN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n\n# print values\nprint(\"True positives:\", TP)\nprint(\"True negatives:\", TN)\nprint(\"False positives (Type I error):\", FP)\nprint(\"False negatives (Type II error):\", FN)","ce3f78f4":"# itereation results\ndescription = \"kNN with optimal k (6)\"\nmisclassifications = FP + FN\ntype1 = FP\ntype2 = FN\nprecision = round(precision_score(Y_test,y_pred),2)\nrecall = round(recall_score(Y_test,y_pred),2)\naccuracy = round(accuracy_score(Y_test,y_pred),2)\nf1 = round(f1_score(Y_test,y_pred),2)\nauc = round(roc_auc_score(Y_test,y_pred),2)\n\ndf_results = pd.concat([df_results,\n                        pd.DataFrame(np.array([description,\n                                     misclassifications,\n                                     type1,\n                                     type2,\n                                     precision,\n                                     recall,\n                                     accuracy,\n                                     f1,\n                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy','F1-score','ROC AUC'])\n                                  ], axis=0)\n\ndf_results","4a7026ff":"# Random Forest","af127945":"from sklearn.ensemble import RandomForestClassifier ","e1dff9d3":"model_rfc = RandomForestClassifier()\nmodel_rfc.fit(X_train, Y_train)","e632667d":"# predicting X_test\ny_pred = model_rfc.predict(X_test)\n\n# checking for model overfit\nprint(\"Training accuracy:\", accuracy_score(Y_train,model_knn.predict(X_train)))\nprint(\"Test accuracy:\", accuracy_score(Y_test,y_pred))","7c56d6ec":"# confusion matrix\ncm = pd.DataFrame(confusion_matrix(Y_test,y_pred), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\n\n# plotting test results confusion matrix\nplt.figure(figsize=(5,5))\nsns.heatmap(cm, cmap=\"RdYlGn\", annot=True, cbar=False, square=True)\nplt.xlabel(\"Predicted values\", fontsize=12)\nplt.ylabel(\"Actual values\", fontsize=12)\nplt.title(\"Test results\", fontsize=20)\nplt.show()\n\ncm_reference = pd.DataFrame(np.array([\"TN\",\"FP\",\"FN\",\"TP\"]).reshape(2,2), columns=['Predicted:0','Predicted:1'], index=['Actual:0','Actual:1'])\nprint(cm_reference)","5cab4375":"# calculating TP,TN,FP,FN\nTN, FP, FN, TP = cm.iloc[0,0], cm.iloc[0,1], cm.iloc[1,0], cm.iloc[1,1]\n\n# print values\nprint(\"True positives:\", TP)\nprint(\"True negatives:\", TN)\nprint(\"False positives (Type I error):\", FP)\nprint(\"False negatives (Type II error):\", FN)","aeb7c202":"# itereation results\ndescription = \"Base random forest\"\nmisclassifications = FP + FN\ntype1 = FP\ntype2 = FN\nprecision = round(precision_score(Y_test,y_pred),2)\nrecall = round(recall_score(Y_test,y_pred),2)\naccuracy = round(accuracy_score(Y_test,y_pred),2)\nf1 = round(f1_score(Y_test,y_pred),2)\nauc = round(roc_auc_score(Y_test,y_pred),2)\n\ndf_results = pd.concat([df_results,\n                        pd.DataFrame(np.array([description,\n                                     misclassifications,\n                                     type1,\n                                     type2,\n                                     precision,\n                                     recall,\n                                     accuracy,\n                                     f1,\n                                     auc]).reshape(1,-1), columns=['Description','Misclassifications','Type I errors','Type II errors','Precision','Recall','Accuracy','F1-score','ROC AUC'])\n                                  ], axis=0)\n\ndf_results","2b250ead":"print('Correlation of selector with all independent variables')\ndf.corr()['target'].plot.barh()\nplt.show()","6c1bdc80":"P value is greater than 0.05 so we are fai to reject null hypothesis.so mean are same of all.","943edb2f":"**Recall (Sensitivity) - Recall is the ratio of correctly predicted positive observations to the all observations in actual class.**\n\nRecall = TP\/TP+FN","e4e3e524":"- Mitigating Risk of Machine Learning\n- Data Difficulties.\n- Technology Troubles.\n- Security Snags.\n- Models Misbehaving.\n- Interaction Issues.","6bd3bacb":"There seems to be direct relationship between Total_Bilirubin and Direct_Bilirubin. We have the possibility of removing one of this feature.","830c6605":"#### The above correlation also indicates the following correlation\n##### Total_Protiens & Albumin\n##### Alamine_Aminotransferase & Aspartate_Aminotransferase\n##### Direct_Bilirubin & Total_Bilirubin\n##### There is some correlation between Albumin_and_Globulin_Ratio and Albumin. But its not as high as Total_Protiens & Albumin","f0dcf714":"1.","ce501e47":"### 2.Summarize important observations from the data set ","87340777":"We are changing value of k by doing hyper parameter tuning. We get optimum k value 6 for the model.it increases the accuracy compared to base model.","14d2ea00":"### b.\tPlot all independent variables with the target & find out the relationship? Perform the Relevant Tests to find out if the Independent variables are associated with the Target Variable.","731f1342":"## Iteration 1","74ee02fc":"Cohen's kappa coefficient is a statistic that is used to measure inter-rater reliability for qualitative items. It is generally thought to be a more robust measure than simple percent agreement calculation, as \u03ba takes into account the possibility of the agreement occurring by chance. ","1514a0dd":"2.","8ce26029":"#### a.\tPlot relevant categorical plots. Find out which are the variables most correlated or appear to be in causation with Target? Do you want to exclude some variables from the model based on this analysis? What other actions will you take?","d691f9fb":"### 4.Summarize relationships among variables (10 marks)               ","53a175cd":"#### Some pointers which would help you, but don\u2019t be limited by these\n#### a.\tDo variables have missing\/null values?\n","6dd539af":"3.","33a9dad2":"### 8. Summarize as follows \n#### 1.\tSummarize the overall fit of the model and list down the measures to prove that it is a good model\n#### 2.\tWrite down a business interpretation\/explanation of the model \u2013 which variables are affecting the target the most and explain the relationship. Feel free to use charts or graphs to explain.\n#### 3.\tWhat changes from the base model had the most effect on model performance?\n#### 4.\tWhat are the key risks to your results and interpretation?\n","43122679":"H0:mu of Y_train=mu of Y_test =mu of Y\nH1:any one of them differs","fc66beff":"**As we can see that logistic regression and KNN with k=6 is the best model for us as it gives best accuracy.**","da53692b":"#### Some pointers which would help you, but don\u2019t be limited by these\n#### a.\tFind out number of rows; no. & types of variables (continuous, categorical etc.)\n","c0584410":"### 5.Split dataset into train and test (70:30) \n#### a.\tAre both train and test representative of the overall data? How would you ascertain this statistically?\n\n","29a5a26d":"#### c.\tSummarize observations for categorical variables \u2013 no. of categories, % observations in each category","7997b28a":"#### c.\tIs the Target distributed evenly? Is it a defect? If Yes, what steps are being taken to rectify the problem","241de245":"From the above jointplots and scatterplots, we find direct relationship between the following features:\nDirect_Bilirubin & Total_Bilirubin\nAspartate_Aminotransferase & Alamine_Aminotransferase\nTotal_Protiens & Albumin\nAlbumin_and_Globulin_Ratio & Albumin","ea52a39a":"#### b.\tCalculate five-point summary for numerical variables","10ff3997":"**F1 score - F1 Score is the weighted average of Precision and Recall.**\nF1 Score = 2*(Recall * Precision) \/ (Recall + Precision)","969ff8b2":"As we can see the relationship of target variables with each variables in the dataset.","2a407098":"Albumin and Albumin_and_Globulin ratio,Total_Protiens are the variables which are afftecting target variable most","faff3698":"There are outliers in our dataset but we are not removing off as of now.","174bbb54":"### 7. How do you improve the accuracy of the model? Write clearly the changes that you will make before re-fitting the model. Fit the final model. \n#### Please feel free to have any number of iterations to get to the final answer. Marks are awarded based on the quality of final model you are able to achieve. \n\n","e8a46465":"**Precision - Precision is the ratio of correctly predicted positive observations to the total predicted positive observations. The question that this metric answer is of all passengers that labeled as survived, how many actually survived? High precision relates to the low false positive rate. We have got 0.788 precision which is pretty good.**\n\nPrecision = TP\/TP+FP","15721345":"### 3.Check for defects in the data. Perform necessary actions to \u2018fix\u2019 these defects (5 Marks)","07b31f37":"### 1.Read the dataset (tab, csv, xls, txt, inbuilt dataset)","85fa54c8":"#### b.\tDo variables have outliers? ","81998698":"## Iteration 2","8d70767f":"### Fit a base model and explain the reason of selecting that model. Please write your key observations.\n#### a.\tWhat is the overall Accuracy? Please comment on whether it is good or not. \n#### b.\tWhat is Precision, Recall and F1 Score and what will be the optimization objective keeping in mind the problem statement.\n#### c.\tWhich variables are significant?\n#### d.\tWhat is Cohen\u2019s Kappa Value and what inference do you make from the model\n#### e.\tWhich other key model output parameters do you want to look at? \n\n","31ea1b94":"4.","f3701f48":"**Overall accuracy is the probability that an individual will be correctly classified by a test; that is, the sum of the true positives plus true negatives divided by the total number of individuals tested.**","c60dbe16":"No.of male is more than female.","e4b89788":"There are four missing values in Albumin_and_Globulin_Ratio.Filling missing values with mean.","3c79fbd9":"### Using base model Logistic Regression ","dfc3299a":"As we can observe that data is not balanced so we will balance it by smote or nearmiss.","4a9115c2":"As we can see that KNN with k=6 is the best model for us as it gives best accuracy.We use optimum k value 6 by hyper parameter tuning.It gives 74% accuracy. Logistic regression is also giving almost same accuracy."}}