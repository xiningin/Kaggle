{"cell_type":{"973294ec":"code","c76aa23e":"code","8a84acf4":"code","01172482":"code","26846e25":"code","a82d4fa1":"code","d942bbd0":"code","3c759f21":"code","67849aea":"code","cb79a3fc":"code","b5d0fc57":"code","edc4d37c":"code","b5be1c1f":"code","86d04d84":"markdown","92f4c5a4":"markdown"},"source":{"973294ec":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os, gc\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import GroupKFold\nimport matplotlib.pyplot as plt\n\n\nfrom typing import List\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import mstats\nfrom scipy.spatial.distance import cdist ","c76aa23e":"!pip install seaborn --upgrade --quiet","8a84acf4":"import seaborn as sns","01172482":"train = pd.read_csv('\/kaggle\/input\/jane-street-market-prediction\/train.csv')","26846e25":"features = [c for c in train.columns if 'feature' in c]\nf_mean = train[features[1:]].mean()\ntrain = train.query('weight > 0').reset_index(drop = True)\ntrain['action'] = (train['resp'] > 0).astype('int')\ntrain[features[1:]] = train[features[1:]].fillna(f_mean)\ntime_features = ['feature_60', 'feature_61', 'feature_62', 'feature_63' ,'feature_65', 'feature_66', 'feature_67', 'feature_68']\nnew_time_features = []","a82d4fa1":"def utility_score(date, weight, resp, action):\n    count_i = len(np.unique(date))\n    Pi = np.bincount(date, weight * resp * action)\n    t = np.sum(Pi) \/ np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 \/ count_i)\n    u = np.clip(t, 0, 6) * np.sum(Pi)\n    return u","d942bbd0":"# https:\/\/www.geeksforgeeks.org\/elbow-method-for-optimal-value-of-k-in-kmeans\/\ndistortions = []\ninertias = []\n\n\nK = range(2,10)\n\ntrain_0 = train.query('feature_0==-1')\n\nfor i in K:\n    gc.collect()\n    kmeans_ = KMeans(n_clusters=i, random_state=0).fit(train_0[time_features])\n    distortions.append(sum(np.min(cdist(train_0[time_features], kmeans_.cluster_centers_, \n                      'euclidean'),axis=1)) \/ train_0[time_features].shape[0]) \n    inertias.append(kmeans_.inertia_)  \n    print(f'# clusters, cluster eval, score')\n    for j in range(i):\n        score = utility_score(date=train_0['date'], weight=train_0['weight'], resp=train_0['resp'], action=(kmeans_.labels_==j))\n        score = round(score,2)    \n        print(f'{i}, {j}, {score}')","3c759f21":"plt.plot(K, distortions[:9], 'bx-') \nplt.xlabel('Values of K') \nplt.ylabel('Distortion') \nplt.title('The Elbow Method using Distortion') \nplt.show() ","67849aea":"plt.plot(K, inertias[:9], 'bx-') \nplt.xlabel('Values of K') \nplt.ylabel('Inertia') \nplt.title('The Elbow Method using Inertia') \nplt.show() ","cb79a3fc":"k=5\n\ntrain_0['clusters'] = KMeans(n_clusters=k, random_state=0).fit(train_0[time_features]).labels_","b5d0fc57":"def plotFeatureSplits(df: pd.DataFrame, feature_list: List[int]) -> None:\n    for i in feature_list:\n        if i != 64:\n\n            # Create a plot with original timeseries, and split by feature 0\n            _, axes = plt.subplots(1, figsize=(10, 5))\n\n            # Original timeseries\n            \n            axes.scatter(df['feature_64'], df[f'feature_{i}'], s=.2)\n            axes.set_title(f'Feature {i}')\n            axes.set_ylabel(f'Feature {i}')\n            axes.set_xlabel(f'Time of Day')\n            \n            sns.displot(data=df,x=\"feature_64\",y=f'feature_{i}', kind='kde', hue='clusters')\n            \n            plt.show()\n\n# Show features 60-68 and their relationship\nnew = train_0.query('date==0')\n","edc4d37c":"plotFeatureSplits(new, np.arange(60, 65))","b5be1c1f":"plotFeatureSplits(new, np.arange(65, 69))","86d04d84":"5 clusters were chosen, as that retains human-readible segmentation while reducing distortion and maintaining the large reductions in inertia.\n\nClusters 0 and 1 have a utility of 900 and 300 respectively when only looking at feature_0==-1. We see these possible trades are in the morning (between -5 and 1). \n\nCould this clusters provide their own signal?","92f4c5a4":"## KMeans Clustering, Visualization of Time Data\n\nIn this notebook, you will see how to cluster the time related features. "}}