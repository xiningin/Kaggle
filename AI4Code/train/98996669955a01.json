{"cell_type":{"a8aaf38e":"code","412ea653":"code","f36c9890":"code","54c15e99":"code","b5f963bb":"code","8a071ffe":"code","f2a63e6f":"code","d4d2d761":"code","3dd32f4d":"code","f3ad787a":"code","cb97d7a2":"code","9ef5cc7e":"markdown","7902a867":"markdown","e1bbc676":"markdown","4d7d0791":"markdown","0ec2de25":"markdown","644f4363":"markdown"},"source":{"a8aaf38e":"import os\nimport pandas as pd\nprint(os.listdir(\"..\/input\/data\"))\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 13, 13","412ea653":"import matplotlib.pyplot as plt\nimport numpy as np\nimport random\n\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.utils import to_categorical, plot_model\nfrom tensorflow import keras as K\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator ","f36c9890":"train_datagen = ImageDataGenerator(\n        rescale=1.\/255, # This rescales the pixel brightnesses from 0-255 to 0-1\n        validation_split = 0.1) \n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# Now we set our training generator to read images from the training directory\ntrain_generator = train_datagen.flow_from_directory(\n        '..\/input\/data\/train', # Az el\u00e9r\u00e9si \u00fat\n        batch_size=32, # Images are not read and sent to the network individually, but in batches\n        class_mode='categorical', # We spacify that we wish to use each subfolder in the training directory a s a separate class\n        subset=\"training\")\n\n# The validation generator is constructed from the same object, with the same arguments, only this time from the set apart 10 percent from the files \nvalid_generator = train_datagen.flow_from_directory(\n        '..\/input\/data\/train',\n        batch_size=32,\n        class_mode='categorical',\n        subset=\"validation\") # Here we request these files to come from the validation set\n\n# The test generator will stream form the test directory, so formally there is only one class, \"test\"\ntest_generator = test_datagen.flow_from_directory(\n        '..\/input\/data\/',\n        shuffle=False, # Now we do not want to shuffle the examples. Not at all\n        classes=['test'],\n        batch_size=32)","54c15e99":"im = train_generator.next()\nprint(im[0].shape) # 32 Images as a batch\nprint(im[1].shape) # The labels are already one-hot encoded for us!\nplt.imshow(im[0][0])","b5f963bb":"a = \"relu\"\nmodel = Sequential()\nmodel.add(Conv2D(8, (3, 3), activation=a, input_shape = ( 256, 256, 3)))\nmodel.add(MaxPool2D(2, 2))\nmodel.add(Conv2D(16, (3, 3), activation=a))\nmodel.add(MaxPool2D(2, 2))\nmodel.add(Conv2D(32, (3, 3), activation=a))\nmodel.add(MaxPool2D(2, 2))\nmodel.add(Conv2D(32, (3, 3), activation=a))\nmodel.add(Dropout(0.4))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation=a))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(10, activation=\"softmax\"))\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\nmodel.summary()","8a071ffe":"history = model.fit_generator(train_generator, epochs = 10, validation_data=valid_generator)","f2a63e6f":"plt.plot(history.epoch, history.history[\"acc\"])\nplt.plot(history.epoch, history.history[\"val_acc\"])","d4d2d761":"predictions = model.predict_generator(test_generator) # And this is how you predict","3dd32f4d":"print(predictions)\nprint()\nprint(np.argmax(predictions, axis=1)) # Argmax grabs the most probable sport for each image","f3ad787a":"sample = pd.read_csv(\"..\/input\/data\/sample_submission.csv\")\nprint(sample.head())\n","cb97d7a2":"print(valid_generator.class_indices) #The class names are returned as a name-index mapping. We have to invert it\ninv_map = {v: k for k, v in valid_generator.class_indices.items()}\nprint(inv_map)\nsubmission = pd.DataFrame(data= {'ID': test_generator.filenames , 'sport' : np.argmax(predictions, axis=1)} )\nsubmission = submission.replace(inv_map)\nprint(submission.head())\nfilename = 'Sports.csv'\n\nsubmission.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)","9ef5cc7e":"Whenever we call the .next() method on a generator, it returns a batch of images, and the corresponding labels. These batches are product of random shuffling of the dataset the generator drwas on, but it is hopefully intelligent enough to use all of them","7902a867":"**Before we could start real work, we must load our dataset. For a directory of images, this can be a painstanking process to perform manually. (And, at least for large image datasetes, it also means allocating numpy arrays of terrfic size). Luckily, Keras comes with a preprocessing subpackage, offering out-of-the-box solutions for the meanial work of streaming images from disc and applying basic transformations**","e1bbc676":"**We instantiate an ImageDataGenerator object for each dataset (the training and the test). Its arguments denote operations that we wish to apply on the images**","4d7d0791":"This is the basic way to do it, though a  ot of tweaking is possible. Most importantly, DataGenerators are capable of **data augmentation** That is, they can apply random transformations (zooming, croping, rotations, flips, channel swaps, etc...) on the data, producing \"not so new\" examples for free, and hopefully allowing improved generalization","0ec2de25":"We now take a peek on the expected submission format. Notice that image filename is required, but they are in increasing order","644f4363":"**Now we define a very basic convolutional network, mainly just to demonstarte how one uses the DataGenerators**"}}