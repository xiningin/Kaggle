{"cell_type":{"8e175d10":"code","1e5e23ea":"code","7d78d1dd":"code","5c1c2d01":"code","f99de2f0":"code","4a378d2f":"code","2acebf96":"code","e3fed841":"code","d16718cd":"code","8a0fef24":"code","086308e7":"code","7e554dcf":"code","af573709":"code","9b91f8dd":"code","1e490ad8":"code","b2879aed":"code","3906bbcb":"code","cc857318":"code","bf347558":"code","e53c4d2c":"code","b44ecb6f":"code","32490825":"code","d2c736df":"code","45a4eaf3":"code","2880d757":"code","69906bea":"code","5b61c92d":"code","99be6294":"code","823aaf43":"code","86e5baec":"code","a50ef0e2":"code","af924d98":"code","78f6d04f":"code","aefcfee9":"code","f398d608":"code","af93f9d9":"code","caedbef6":"code","6a5e5b9d":"code","23bff2e2":"code","ee7d08e8":"code","4776241c":"code","10077dea":"code","9a74955b":"code","cde6df56":"code","fc7c8126":"code","bc36547b":"code","d2e19882":"code","ff5aa090":"code","b84d71f8":"code","9245fc0e":"code","b05ef2ea":"code","516541ce":"code","596f0552":"code","5fc6bddd":"code","942fe032":"code","9535620b":"code","40e69541":"code","fc498a87":"code","c9dc9c49":"code","0ccaa553":"code","14bd7ec9":"code","b6932b19":"code","aeb70d18":"code","9dec4c57":"code","f3c5c5b6":"code","218b8b3b":"code","8057638b":"code","265a8ae2":"code","828fa6d8":"code","a8418aa3":"code","d8756a08":"code","879a32de":"code","e4bce4cf":"code","a43acb78":"code","beeff3b6":"markdown","d16969c0":"markdown","200d0345":"markdown","5733d3bc":"markdown","f4bd7853":"markdown","c85c354d":"markdown"},"source":{"8e175d10":"#Importing Neccessary Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","1e5e23ea":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7d78d1dd":"train=pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")","5c1c2d01":"train.head(5)","f99de2f0":"#Missing Values\ntrain.isnull().sum()","4a378d2f":"#shape of the Training Set\ntrain.shape","2acebf96":"train.keyword.value_counts()","e3fed841":"train.location.value_counts()","d16718cd":"#In this Project We Only Want to Study the Tweets so We can Drop LOCATION And Keyword\ntrain.drop('keyword',axis=1,inplace=True)\ntrain.drop('location',axis=1,inplace=True)","8a0fef24":"train.head()","086308e7":"#Visualisation of target\nsns.countplot(train.target);","7e554dcf":"#Cleaning the Tweets by Removing Panctuation marks,Symbols,URLS,Stopwords,\nimport nltk\nfrom nltk.tokenize import sent_tokenize,word_tokenize\nnltk.download('punkt')","af573709":"x=train.text","9b91f8dd":"word_tokenize(x[1])","1e490ad8":"import re","b2879aed":"x=[re.sub('http[s]?:\/\/\\S+#.','',sent)for sent in x]","3906bbcb":"from nltk.corpus import stopwords\n#nltk.download('stopwords')","cc857318":"stop_word=stopwords.words('english')","bf347558":"import string","e53c4d2c":"from string import punctuation","b44ecb6f":"print(list(punctuation))","32490825":"final_stop=stop_word+list(punctuation)+[\"...\",\"''\",\"===\",\"^^\",\"#\",\"http\"]","d2c736df":"#Normalising the case\nx=[word.lower() for word in x]","45a4eaf3":"x=[word_tokenize(sent) for sent in x]","2880d757":"def stop(sent):\n    return [word for word in sent if word not in final_stop]","69906bea":"stop(x[0])","5b61c92d":"x=[stop(sent) for sent in x]","99be6294":"x=[\" \".join(word) for word in x]","823aaf43":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split","86e5baec":"tfidfv=TfidfVectorizer()","a50ef0e2":"X=x\ny=train.target","af924d98":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)","78f6d04f":"X_train=tfidfv.fit_transform(X_train)","aefcfee9":"X_test=tfidfv.transform(X_test)","f398d608":"from sklearn.linear_model import LogisticRegression","af93f9d9":"Log_reg=LogisticRegression()","caedbef6":"Log_reg.fit(X_train,y_train)","6a5e5b9d":"pred=Log_reg.predict(X_test)","23bff2e2":"from sklearn.metrics import accuracy_score,classification_report,f1_score,confusion_matrix","ee7d08e8":"print(f\"{'Model'}\\n\")\nprint(f\"Classication Report\\n \\n{classification_report(pred,y_test)}\")\nprint(f\"Accuracy Score using Model {accuracy_score(pred,y_test)}\\n\")\nprint(f\"Confusion Matrix \\n {confusion_matrix(pred,y_test)}\")","4776241c":"def Results(pred,y_test):\n    #print(f\"{a}\\n\")\n    print(f\"Classication Report\\n \\n{classification_report(pred,y_test)}\")\n    print(f\"Accuracy Score using Model {accuracy_score(pred,y_test)}\\n\")\n    print(f\"Confusion Matrix \\n {confusion_matrix(pred,y_test)}\")","10077dea":"#2.\nfrom sklearn.naive_bayes import MultinomialNB","9a74955b":"naive_bayes=MultinomialNB()","cde6df56":"naive_bayes.fit(X_train,y_train)","fc7c8126":"pred=naive_bayes.predict(X_test)","bc36547b":"Results(pred,y_test)","d2e19882":"#3.SVM\nfrom sklearn.svm import LinearSVC","ff5aa090":"SVC=LinearSVC()","b84d71f8":"SVC.fit(X_train,y_train)","9245fc0e":"pred=SVC.predict(X_test)","b05ef2ea":"Results(pred,y_test)","516541ce":"#4.Stocastic Gradient Decent\nfrom sklearn.linear_model import SGDClassifier\nclf = SGDClassifier(loss=\"log\", penalty=\"elasticnet\",max_iter=10000)\nclf.fit(X_train,y_train)","596f0552":"pred=clf.predict(X_test)","5fc6bddd":"print(\"Stocastic Gradient Decent \\n\")\nResults(pred,y_test)","942fe032":"#5.k-Nearest-Neighbors (kNN)\nfrom sklearn.neighbors import KNeighborsClassifier","9535620b":"knn=KNeighborsClassifier()","40e69541":"knn.fit(X_train,y_train)","fc498a87":"pred=knn.predict(X_test)","c9dc9c49":"print(\"5.k-Nearest-Neighbors (kNN)\")\nResults(pred,y_test)","0ccaa553":"#6.RandomForest (RF)\nfrom sklearn.ensemble import RandomForestClassifier","14bd7ec9":"Classifier=RandomForestClassifier(n_estimators=500,class_weight='balanced')","b6932b19":"Classifier.fit(X_train,y_train)","aeb70d18":"pred=Classifier.predict(X_test)","9dec4c57":"Results(pred,y_test)","f3c5c5b6":"#Now We will do some hyperparameter tuning\n#From Above it is clear that by using simple model without hyperparameter tuning\n#We Can Not get accuracy more than 79% \nfrom sklearn.model_selection import GridSearchCV","218b8b3b":"n_estimators = [100, 300, 500]\nmax_depth = [5, 8]\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 5] ","8057638b":"hyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n              min_samples_split = min_samples_split, \n             min_samples_leaf = min_samples_leaf)","265a8ae2":"gridF = GridSearchCV(Classifier, hyperF, cv = 3, verbose = 1, \n                      n_jobs = -1)","828fa6d8":"bestF=gridF.fit(X_train,y_train)","a8418aa3":"bestF.best_estimator_\n","d8756a08":"classifier=RandomForestClassifier(class_weight='balanced', max_depth=8, min_samples_leaf=2,\n                       min_samples_split=5, n_estimators=300)","879a32de":"classifier.fit(X_train,y_train)","e4bce4cf":"pred=classifier.predict(X_test)","a43acb78":"Results(pred,y_test)","beeff3b6":"Machine Learning Models\n\n1.Multinomial Na\u00efve Bayes (NB)\n\n2.Logistic Regression (LR)\n\n3.SVM (SVM)\n\n4.Stochastic Gradient Descent (SGD)\n\n5.k-Nearest-Neighbors (kNN)\n\n6.RandomForest (RF)\n\n7.Gradient Boosting (GB)\n\n8.XGBoost (the famous) (XGB)\n\n9.Adaboost\n\n10.Catboost\n\n11.LigthGBM\n\n12.ExtraTreesClassifier","d16969c0":"#### Natural Language Processing with Disaster Tweets","200d0345":"From Above we can see that our Accuracy is Very good and confustion matrix results Also better than Previos models","5733d3bc":"Twitter has become an important communication channel in times of emergency.\nThe ubiquitousness of smartphones enables people to announce an emergency\nthey\u2019re observing in real-time. Because of this, more agencies are interested \nin programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).","f4bd7853":"##### Step 1: Problem Defination and Moto Behind This Project","c85c354d":"From Above we can see that our Accuracy is Very good but we can improve it by using Advanced Algorithms"}}