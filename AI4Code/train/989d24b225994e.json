{"cell_type":{"d0511ee8":"code","2341d205":"code","6de04d9f":"code","159891cf":"code","5099bdb7":"code","eee11c76":"code","0992cb32":"code","4d423eee":"code","d3fa6bbd":"code","ec43a9d1":"code","f9aa783f":"code","90186633":"code","5d18dcbc":"code","bf208686":"code","ab78a665":"code","95d5278c":"markdown","6689532b":"markdown","53156cad":"markdown","bc4ca17e":"markdown","b955e2a4":"markdown","9b232f34":"markdown","31ad8e39":"markdown","31f07b52":"markdown","31a121f5":"markdown","34146bcc":"markdown","9d5ad7c6":"markdown","5db08e08":"markdown","007e396f":"markdown","ceb2920d":"markdown","e4f4928d":"markdown","c436397c":"markdown","6ebd6062":"markdown","61462a03":"markdown","5b23e249":"markdown"},"source":{"d0511ee8":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf","2341d205":"tf.__version__","6de04d9f":"dataset = pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')\nX = dataset.iloc[:, 3:-1].values\ny = dataset.iloc[:, -1].values","159891cf":"import pandas_profiling as pp\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","5099bdb7":"pp.ProfileReport(dataset, title = 'Pandas Profiling report of \"dataset\"', html = {'style':{'full_width': True}})","eee11c76":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","0992cb32":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","4d423eee":"ann = tf.keras.models.Sequential()","d3fa6bbd":"ann.add(tf.keras.layers.Dense(units=8, activation='relu'))","ec43a9d1":"ann.add(tf.keras.layers.Dense(units=8, activation='relu'))","f9aa783f":"ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))","90186633":"ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","5d18dcbc":"ann.fit(X_train, y_train, batch_size = 32, epochs = 75)","bf208686":"y_pred = ann.predict(X_test)\ny_pred = (y_pred > 0.5)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","ab78a665":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nprint(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred)*100))","95d5278c":"### Adding the input layer and the first hidden layer","6689532b":"### Splitting the dataset into the Training set and Test set","53156cad":"## Part 1 - Data Preprocessing","bc4ca17e":"### Importing the dataset","b955e2a4":"## Part 3 - Training the ANN","9b232f34":"### Adding the output layer","31ad8e39":"### Training the ANN on the Training set","31f07b52":"### Initializing the ANN","31a121f5":"### Feature Scaling","34146bcc":"### Adding the second hidden layer","9d5ad7c6":"### Predicting the Test set results","5db08e08":"### Making the Confusion Matrix","007e396f":"# Heart Disease Prediction with <font color = 'blue'>Artificial Neural Networks<\/font>\n    \n* **Part 1 - Data Preprocessing**   \n  * Importing libraries\n  * Importing the dataset\n  * Dataset information (Pandas Profiling)    \n  * Spliting the Train & Test datasets\n  * Feature Scaling\n* **Part 2 - Building the ANN**    \n  * Initializing the ANN    \n  * Adding the input layer and the first hidden layer    \n  * Adding the second hidden layer    \n  * Adding the output layer    \n* **Part 3 - Training the ANN**    \n  * Compiling the ANN\n  * Training the ANN on the Training set   \n* **Part 4 - Making the predictions and evaluating the model**    \n  * Predicting the Test set results    \n  * Making the Confusion Matrix    \n    ","ceb2920d":"### Importing the libraries","e4f4928d":"### Dataset information (Pandas Profiling)","c436397c":"## Part 4 - Making the predictions and evaluating the model","6ebd6062":"## Part 2 - Building the ANN","61462a03":"### Compiling the ANN","5b23e249":"# If you liked my work then please upvote, Thank you."}}