{"cell_type":{"77857c6f":"code","7727bf74":"code","7a901a9d":"code","4d080071":"code","105e0ca2":"code","4ede032f":"code","cccd2bd0":"code","2bdcf722":"code","92e66907":"code","62b0b146":"code","609959f0":"code","43e6abee":"code","3deccc0a":"code","5d4a6059":"code","31f001e8":"code","f21148eb":"code","8f8d2681":"code","2cf44049":"code","f2952c8c":"code","fb5c9c64":"code","4924baf6":"code","ee832631":"code","af6050e3":"code","4a594d16":"code","42797b0b":"code","a3ea788b":"code","af0aa74f":"code","67f05ca6":"code","b5593655":"code","f199422f":"code","cff5718c":"code","9ede594d":"markdown","8bd6f4bd":"markdown","7aaab6c2":"markdown","c68cee9e":"markdown","21953e09":"markdown","3d01275f":"markdown","a51a65b8":"markdown","5665686d":"markdown","82877f93":"markdown","b3658647":"markdown","15488d36":"markdown","4031486b":"markdown","9e99bdc8":"markdown","084e2540":"markdown","f6fd9a1e":"markdown","7672962b":"markdown","c61c27ae":"markdown","50cc7be5":"markdown","e828d053":"markdown","765a56d3":"markdown","7e2a9896":"markdown","1d051203":"markdown","8385c503":"markdown","b786ffdd":"markdown","2ed557cf":"markdown","99d84cbe":"markdown","1ee37fac":"markdown","083e90b2":"markdown","105d3049":"markdown","051304d0":"markdown","e303b670":"markdown","8f17ce02":"markdown","22967212":"markdown","5e29b0a4":"markdown","daac8b99":"markdown","5ee6ba78":"markdown","02263a73":"markdown","a958965a":"markdown","93adcee3":"markdown","1d9449fb":"markdown","1dd97a57":"markdown","4ffefa6a":"markdown","f39ecbff":"markdown","878e594e":"markdown"},"source":{"77857c6f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import accuracy_score\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport pylab as plot","7727bf74":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","7a901a9d":"train_data.head()","4d080071":"test_data.head()","105e0ca2":"train_data.describe()","4ede032f":"test_data.describe()","cccd2bd0":"params = {\n    'axes.labelsize': \"large\",\n    'xtick.labelsize': 'medium',\n    'legend.fontsize': 'medium',\n    'legend.loc': \"best\",\n\n}\nplot.rcParams.update(params)\n\ntrain_data['Died'] = 1 - train_data['Survived']","2bdcf722":"train_data.groupby('Sex').agg('mean')[['Survived', 'Died']].plot(kind='bar', stacked=True)\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\nplt.show()","92e66907":"train_data.groupby('Pclass').agg('mean')[['Survived', 'Died']].plot(kind='bar', stacked=True)\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\nplt.show()","62b0b146":"train_data.groupby('SibSp').agg('mean')[['Survived', 'Died']].plot(kind='bar', stacked=True)\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\nplt.show()","609959f0":"train_data.groupby('Parch').agg('mean')[['Survived', 'Died']].plot(kind='bar', stacked=True)\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\nplt.show()","43e6abee":"plt.hist([train_data[train_data['Survived'] == 1]['Fare'], train_data[train_data['Survived'] == 0]['Fare']], bins = 30, label = ['Survived','Dead'])\nplt.xlabel('Fare')\nplt.ylabel('Number of passengers')\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\nplt.show()","3deccc0a":"plt.hist([train_data[train_data['Survived'] == 1]['Age'], train_data[train_data['Survived'] == 0]['Age']], bins = 8, label = ['Survived','Dead'])\nplt.xlabel('Age')\nplt.ylabel('Number of passengers')\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\nplt.show()","5d4a6059":"sing_titles = list()\nfor name in train_data[\"Name\"]:\n    title = name.split(',')[1].split('.')[0].strip()\n    if title not in sing_titles: sing_titles.append(title)\nprint(sing_titles)\nsing_test = list()\nfor name in test_data[\"Name\"]:\n    title = name.split(',')[1].split('.')[0].strip()\n    if title not in sing_test: sing_test.append(title)\nprint(sing_test)","31f001e8":"# Function that, given a title string, checks it and replaces it with the correct title\ndef title_corr(t):\n    newt = t\n    if t == 'Mrs' or t == 'Mr' or t == 'Miss':\n        return newt\n    elif t == 'Capt' or t == 'Col' or t == 'Major' or t == 'Dr' or t == 'Rev':\n        newt = 'Crew'\n    elif t == 'Jonkheer' or t == 'Sir' or t == 'the Countess' or t == 'Lady' or t == 'Master':\n        newt = 'Noble'\n    elif t == 'Don':\n        newt = 'Mr'\n    elif t == 'Dona' or t == 'Ms' or t == 'Mme':\n        newt = 'Mrs'\n    elif t == 'Mlle':\n        newt = 'Miss'\n    else: print(\"Title not included:\", t)\n    return newt\n\n# Extract the titles from the name and put them in a list, then correct them\n# Train data\ntitles = list()\nfor name in train_data[\"Name\"]:\n    titles.append(name.split(',')[1].split('.')[0].strip())\nfor i in range(len(titles)):\n    titles[i] = title_corr(titles[i])\ntrain_data[\"Titles\"] = titles\n\n# Plotting\nplt.hist([train_data[train_data['Survived'] == 1]['Titles'], train_data[train_data['Survived'] == 0]['Titles']], label = ['Survived','Dead'])\nplt.xlabel('Title')\nplt.ylabel('Number of passengers')\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\nplt.show()\n\n# Test data\ntest_titles = list()\nfor name in test_data[\"Name\"]:\n    test_titles.append(name.split(',')[1].split('.')[0].strip())\nfor i in range(len(test_titles)):\n    test_titles[i] = title_corr(test_titles[i])\ntest_data[\"Titles\"] = test_titles","f21148eb":"title_mapping = {\"Mrs\": 4, \"Miss\": 3, \"Mr\": 0, \"Noble\": 2,\"Crew\": 1}\ntrain_data['Title Map'] = train_data['Titles'].map(title_mapping)\ntest_data['Title Map'] = test_data['Titles'].map(title_mapping)","8f8d2681":"train_data[\"Fare\"] = train_data[\"Fare\"].fillna(train_data[\"Fare\"].median())\ntest_data[\"Fare\"] = test_data[\"Fare\"].fillna(test_data[\"Fare\"].median())","2cf44049":"train_data['FareGroup'] = pd.cut(train_data['Fare'],3)\nprint(train_data[['FareGroup', 'Survived']].groupby('FareGroup', as_index=False).mean().sort_values('Survived', ascending=False))","f2952c8c":"def group_fare(fare):\n    if fare <= 170: return 0\n    if fare > 170 and fare <= 340: return 1\n    if fare > 340: return 2\n    \n# Loops over the df and fill the Fare Group column\nfor i, row in train_data.iterrows():\n    train_data.at[i,'Fare Group'] = group_fare(row[\"Fare\"])\n# Same for test data\nfor i, row in test_data.iterrows():\n    test_data.at[i,'Fare Group'] = group_fare(row[\"Fare\"])","fb5c9c64":"# Function that returns the median age for passengers from a certain class, sex and title\ndef calc_age(df, cl, sx, tl):\n    a = df.groupby([\"Pclass\", \"Sex\", \"Titles\"])[\"Age\"].median()\n    return a[cl][sx][tl]\n\n# Getting the full dataset (more accurate for median calculation)\nage_train = train_data.copy()\nage_train.drop('PassengerId', axis=1, inplace=True)\nage_train.drop('Survived',axis=1, inplace=True)\nage_test = test_data.copy()\nage_test.drop('PassengerId', axis=1, inplace=True)\ndf = pd.concat([age_train, age_test], sort=False).reset_index(drop=True)\n\n# Fill up missing ages\nfor i, row in train_data.iterrows():\n    if pd.isna(row['Age']) :\n        newage = (calc_age(df, row[\"Pclass\"], row[\"Sex\"], row[\"Titles\"]))\n        train_data.at[i,'Age'] = newage\n    else: continue\n# Same for test data\nfor i, row in test_data.iterrows():\n    if pd.isna(row['Age']) :\n        newage = (calc_age(df, row[\"Pclass\"], row[\"Sex\"], row[\"Titles\"]))\n        test_data.at[i,'Age'] = newage\n    else: continue","4924baf6":"train_data['AgeGroup'] = pd.cut(train_data['Age'],5)\nprint(train_data[['AgeGroup', 'Survived']].groupby('AgeGroup', as_index=False).mean().sort_values('Survived', ascending=False))","ee832631":"def group_age(age):\n    if age <= 16: return 4\n    if age > 16 and age <= 32: return 1\n    if age > 32 and age <= 48: return 2\n    if age > 48 and age <= 64: return 3\n    if age > 64: return 0\n\n# Loops over the df and fill the Age Group column\nfor i, row in train_data.iterrows():\n    train_data.at[i,'Age Group'] = group_age(row[\"Age\"])\n    # Same for test data\nfor i, row in test_data.iterrows():\n    test_data.at[i,'Age Group'] = group_age(row[\"Age\"])","af6050e3":"train_data[\"Family\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\ntest_data[\"Family\"] = test_data[\"SibSp\"] + test_data[\"Parch\"]","4a594d16":"train_data[\"Embarked\"] = train_data[\"Embarked\"].fillna('S')","42797b0b":"print(train_data[['Embarked', 'Survived']].groupby('Embarked', as_index=False).mean().sort_values('Survived', ascending=False))","a3ea788b":"def embarked_rate(embarked_port):\n    if embarked_port == 'C': return 2\n    if embarked_port == 'Q': return 1\n    if embarked_port == 'S': return 0\n\nfor i, row in train_data.iterrows():\n    train_data.at[i,'Emb Rate'] = embarked_rate(row[\"Embarked\"])\nfor i, row in test_data.iterrows():\n    test_data.at[i,'Emb Rate'] = embarked_rate(row[\"Embarked\"])","af0aa74f":"sex_mapping = {\"male\": 0, \"female\": 1}\ntrain_data['Sex Map'] = train_data['Sex'].map(sex_mapping)\ntest_data['Sex Map'] = test_data['Sex'].map(sex_mapping)","67f05ca6":"# Drops some columns\ncols_to_drop = [\"SibSp\", \"Parch\", \"Name\", \"Age\", \"Fare\",  \"Embarked\", \"Cabin\", \"Ticket\", \"Sex\", \"Titles\"]\nnew_train = train_data.drop(cols_to_drop, axis=1)\nnew_test = test_data.drop(cols_to_drop, axis=1)\n\ny = train_data[\"Survived\"]\nfeatures = [\"Pclass\", \"Sex Map\", \"Family\", \"Title Map\", \"Age Group\", \"Fare Group\", \"Emb Rate\"]\nX = pd.get_dummies(new_train[features])\nX_test = pd.get_dummies(new_test[features])\n# X = new_train.drop(\"Survived\", axis=1)\n# X_test = new_test","b5593655":"model1 = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel1.fit(X, y)\ny1_test = model1.predict(X_test)\n\nmodel2 = XGBClassifier(max_depth=3, n_estimators=1000, learning_rate=0.05)\nmodel2.fit(X, y)\ny2_test = model2.predict(X_test)\n\nmodel3 = SVC(random_state=1)\nmodel3.fit(X,y)\ny3_test = model3.predict(X_test)\n\nmodel4 = GradientBoostingClassifier(random_state=42)\nmodel4.fit(X, y)\ny4_test = model4.predict(X_test)","f199422f":"model1_preds = cross_val_predict(model1, X, y, cv=10)\nmodel1_acc = accuracy_score(y, model1_preds)\nmodel2_preds = cross_val_predict(model2, X, y, cv=10)\nmodel2_acc = accuracy_score(y, model2_preds)\nmodel3_preds = cross_val_predict(model3, X, y, cv=10)\nmodel3_acc = accuracy_score(y, model3_preds)\nmodel4_preds = cross_val_predict(model4, X, y, cv=10)\nmodel4_acc = accuracy_score(y, model4_preds)\n\nprint(\"Random Forest Accuracy:\", model1_acc)\nprint(\"XGBoost Accuracy:\", model2_acc)\nprint(\"SVC Accuracy:\", model3_acc)\nprint(\"GB Accuracy:\", model4_acc)","cff5718c":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': y2_test})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","9ede594d":"Importing the packages that I need:","8bd6f4bd":"Loading the csv files:","7aaab6c2":"# *3d. ParCh*","c68cee9e":"First, checking how the data looks like in both files.","21953e09":"1. Load and Import\n2. Data Description\n3. Data Visualisation\n4. Feature Engineering\n5. Model, Fit and Predict","3d01275f":"# *3f. Age*","a51a65b8":"# *4e. Embarked*","5665686d":"Calculate accuracy of each model:","82877f93":"# *3c. SibSp*","b3658647":"We also have missing information in the \"age\" column, as well as in the \"fare\" one.","15488d36":"This notebook will be divided into the following sections:","4031486b":"Use different models to predict y:","9e99bdc8":"Group fares into 3 categories, weighed according to the survival rate:","084e2540":"Choose the features that will be used:","f6fd9a1e":"Then, we want to group the ages:","7672962b":"# *4f. Sex Mapping*","c61c27ae":"# *4c. Age Groups*\n\nFirst, let's fill the missing ages using a median for a specific sex, title and class for the whole dataset:","50cc7be5":"We will group the ages in 5 groups, weighed according to the survival rate:","e828d053":"As you can see, women had almost 3 times more chances to survive the Titanic than men. This correlation is so strong that if you just use this parameter to predict who dies and who survives in your test sample, you would be 76.55% correct!","765a56d3":"# 2. Data Description","7e2a9896":"Each row represents a passenger, for which we have various information:\n\n* PassengerId: the ID number given for each passenger in this dataset. You can see it as the row number.\n* Survived: 0 if they died, 1 if they survived.\n* Pclass: whether they were in 1st, 2nd or 3rd class.\n* Name: full name including title and sometimes maiden name.\n* Sex: male or female\n* Age: in years\n* Sibsp: number of siblings and\/or spouses aboard the Titanic\n* Parch: number of parents and\/or children aboard the Titanic\n* Ticket: the ticket number\n* Fare: how much they paid for their ticket\n* Cabin: the cabin number\n* Embarked: which port they embarked from. C = Cherbourg, Q = Queenstown, S = Southampton.\n\nThe testing data\u2019s layout is exactly the same, without the \u201cSurvived\u201d column.\n\nThere are 891 rows in the training data, meaning 891 passengers. With a very quick describe() function, I can get some statistical information about this data:","1d051203":"# *3a. Sex*\n\nLet's plot the survival rate for men and women:","8385c503":"We want to use both SibSp and ParCh into one variable:","b786ffdd":"Mapping the titles depending on survival rate:","2ed557cf":"This is the second version of this notebook, that includes visualisation and feature engineering, as well as testing different models. So far, I have achieved an accuracy of 79.425%.","99d84cbe":"# *4b. Fare Groups*","1ee37fac":"Weigh the embarked feature with the survival rate into a new column:","083e90b2":"As fare is a continuous parameters, we will benefit from grouping it:","105d3049":"Check out the survival rate for each port:","051304d0":"Fill the missing fares with the median:","e303b670":"# 3. Data Visualisation","8f17ce02":"You can find more information and how I slowly improved my accuracy to arrive at this code by reading my blog: https:\/\/celineterranova.com\/blog\/","22967212":"# *4d. Family*","5e29b0a4":"# *4a. Titles*\n\nFrom the name field in the dataset, I can extract the title of the person. Let's first check what titles I have in both the training and the testing data:","daac8b99":"# 1. Load and Import","5ee6ba78":"I decided to divide these into 5 categories: Miss, Mrs, Mr, Noble, Crew.","02263a73":"# 5. Model, Fit and Predict","a958965a":"Immediately we notice something interesting in the \u201ccount\u201d row: the number for Age is lower, which means that, for some passengers, no age is present in the table. Note that this information only took in account the column that had numbers in them, not strings (which makes sense), so we have blanks in other columns too (especially in the \u201ccabin\u201d column).\n\nIf we do the same work for the test data:","93adcee3":"# 4. Feature Engineering","1d9449fb":"In this section, I will plot some of the parameters that have an influence on the outcome (for the training data). For each feature, I will plot those who survived vs those who died.\n\nFirst I'm choosing some parameters that will be used in the plots below (optional) and I'm adding a column \"Died\" to my dataset to make life easier.","1dd97a57":"Create output:","4ffefa6a":"Fill missing data for embarked feature:","f39ecbff":"# *3b. Pclass*\n\nClass also plays a role: people in first class had more chances to survive than those in second and third class. Plotted (relatively to the number of passengers in each class):","878e594e":"# *3e. Fare*"}}