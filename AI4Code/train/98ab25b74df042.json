{"cell_type":{"d141b784":"code","557462db":"code","69f23f1d":"code","cacbd88d":"code","8dc5add8":"code","c5aa73d1":"code","c606d8d4":"code","804ed36f":"code","8b80bf46":"code","0424ea25":"code","18ed2494":"code","01581a28":"code","fd7569b6":"code","b5f0af69":"code","849003fb":"code","188e75f0":"code","ba68a39b":"code","bc9ff12c":"code","ab93aca5":"code","9e60aeb8":"code","ba07587a":"code","f6ff639e":"code","7e8654d1":"code","5d2d7e37":"code","a8b800cf":"code","4749bb68":"code","b7194bb7":"code","240b2cf3":"code","e8b89aa7":"code","156e223c":"code","6829d836":"code","fc42a7de":"code","5bf04289":"code","88e0c2da":"code","40605889":"code","e600eedb":"code","5c228a54":"code","4b4f3559":"code","74d140ae":"code","8c7ca710":"code","fb87e030":"code","a752c988":"code","afb932fa":"code","26c192ca":"code","d66b84cd":"code","edfcbfef":"code","9e3285f3":"code","fde9b96c":"code","341b7b4e":"code","fd69727f":"code","f5825d34":"code","9ab75ee8":"code","e547e3d0":"code","460ffba7":"code","5d9cdcaa":"code","86051012":"code","dac2f6e8":"code","f27ed388":"code","993ae0d6":"code","d5482354":"code","d6a75113":"code","792427d0":"code","c58c0c3d":"code","6c6b8cae":"code","9c393dc3":"code","c5254df8":"code","c24e23cf":"code","4eb6a8c9":"code","1e1842e7":"code","851ad36c":"code","958765d7":"code","c4c99010":"code","e4ec2170":"code","a7b402d5":"code","1bfd65ac":"code","c6de9ff4":"code","2c686373":"code","8a37f3af":"markdown","7f8d2625":"markdown","b7366dbb":"markdown","c7303949":"markdown","d8c5da83":"markdown","9a79778c":"markdown","de57c2e1":"markdown","7a803f04":"markdown","f664a348":"markdown","bda7c8ae":"markdown","6bb29ff5":"markdown","d805351b":"markdown","94e5c11f":"markdown","5825f029":"markdown","ac4974f8":"markdown","c2e22f3e":"markdown","3bea118b":"markdown","5e5ad6fa":"markdown","bdca0eeb":"markdown","b31d8fb0":"markdown","fc58d3c2":"markdown","7ea14fb0":"markdown","84af1ef8":"markdown","a0e340db":"markdown","bb9a7178":"markdown","22904d06":"markdown","5ad2534e":"markdown","9e5fa022":"markdown","0cbada48":"markdown","39c9c199":"markdown","a53c67b8":"markdown","77cbcdc8":"markdown"},"source":{"d141b784":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","557462db":"!pip install ycimpute","69f23f1d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom ycimpute.imputer import knnimput, MICE\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn import metrics\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBRegressor","cacbd88d":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","8dc5add8":"train.info()","c5aa73d1":"train_salePrice = train[\"SalePrice\"]\ntrain_salePrice","c606d8d4":"#konut fiyatlar\u0131n\u0131n istatiksel \u00f6zeti\n\nsalePrice_desc = train['SalePrice'].describe().T\nsalePrice_desc ","804ed36f":"sns.distplot(train['SalePrice'])\nplt.ylabel('Frekans')\nplt.title('SalePrice Da\u011f\u0131l\u0131m\u0131')","8b80bf46":"#\u00c7arp\u0131kl\u0131k ve bas\u0131kl\u0131k\n\nprint(\"\u00c7arp\u0131kl\u0131k: %f\" % train['SalePrice'].skew())\nprint(\"Bas\u0131kl\u0131k: %f\" % train['SalePrice'].kurt())","0424ea25":"# korelasyon matrisi\n\ncorrmat = train.corr()\ncorrmat","18ed2494":"# korelasyon matrisinin g\u00f6rselle\u015ftirilmesi\n\nplt.subplots(figsize=(15,12))\nsns.heatmap(corrmat, vmax=1, cmap=\"Blues\", square=True)","01581a28":"#\"SalePrice\" ve di\u011fer konut \u00f6zelliklerinin korelasyon matrisinin olu\u015fturulmas\u0131\n\nsalePrice = train[\"SalePrice\"]\ncorr_salePrice = train.corrwith(salePrice, axis=0)\ncorr_salePrice = pd.DataFrame(corr_salePrice)\ncorr_salePrice.rename (columns = {0: 'SalePrice'}, inplace = True)\n\n#Olu\u015fturulan korelasyon matrisinin g\u00f6rselle\u015ftirilmesi\nplt.subplots(figsize=(15,12))\nsns.set(font_scale=1.1)\nsns.heatmap(corr_salePrice, vmax=1, cmap=\"Blues\",fmt='.4f',annot=True);","fd7569b6":"k = 10 # heatmap i\u00e7in de\u011fi\u015fken say\u0131s\u0131\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(train[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values, cmap=\"Blues\")\nplt.show()","b5f0af69":"#box plot overallqual\/saleprice\ndata = pd.concat([train['SalePrice'], train['OverallQual']], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x='OverallQual', y=\"SalePrice\", data=data);\nfig.axis(ymin=0, ymax=800000);","849003fb":"# YearBuild ve SalePrice boxlot\nplt.figure(figsize=(40,20))\nsns.set(font_scale=1.5)\nsns.boxplot(x='YearBuilt', y=\"SalePrice\", data=train);\nsns.swarmplot(x='YearBuilt', y=\"SalePrice\", data=train, color=\".25\");\nplt.xticks(weight='bold',rotation=90);","188e75f0":"# TotalBsmtSF\/salePrice Da\u011f\u0131l\u0131m Grafi\u011fi \n\ndata = pd.concat([train['SalePrice'], train['TotalBsmtSF']], axis=1)\ndata.plot.scatter(x='TotalBsmtSF', y='SalePrice', ylim=(0,800000));","ba68a39b":"#1stFlrSF\/salePrice Da\u011f\u0131l\u0131m Grafi\u011fi \n\ndata = pd.concat([train['SalePrice'], train['1stFlrSF']], axis=1)\ndata.plot.scatter(x='1stFlrSF', y='SalePrice', ylim=(0,800000));","bc9ff12c":"#GrLivArea\/salePrice Da\u011f\u0131l\u0131m Grafi\u011fi \n\ndata = pd.concat([train['SalePrice'], train['GrLivArea']], axis=1)\ndata.plot.scatter(x='GrLivArea', y='SalePrice', ylim=(0,800000));","ab93aca5":"#FullBath\/salePrice Da\u011f\u0131l\u0131m Grafi\u011fi \n\ndata = pd.concat([train['SalePrice'], train['FullBath']], axis=1)\ndata.plot.scatter(x='FullBath', y='SalePrice', ylim=(0,800000));","9e60aeb8":"#TotRmsAbvGrd\/salePrice Da\u011f\u0131l\u0131m Grafi\u011fi \n\ndata = pd.concat([train['SalePrice'], train['TotRmsAbvGrd']], axis=1)\ndata.plot.scatter(x='TotRmsAbvGrd', y='SalePrice', ylim=(0,800000));","ba07587a":"#GarageCars\/salePrice Da\u011f\u0131l\u0131m Grafi\u011fi \n\ndata = pd.concat([train['SalePrice'], train['GarageCars']], axis=1)\ndata.plot.scatter(x='GarageCars', y='SalePrice', ylim=(0,800000));","f6ff639e":"#GarageArea\/salePrice Da\u011f\u0131l\u0131m Grafi\u011fi \n\ndata = pd.concat([train['SalePrice'], train['GarageArea']], axis=1)\ndata.plot.scatter(x='GarageArea', y='SalePrice', ylim=(0,800000));","7e8654d1":"train = train.drop(\"SalePrice\", axis='columns')\ntrain.shape","5d2d7e37":"all_data = pd.concat([train,test])\nall_data.head()","a8b800cf":"all_data = all_data.reset_index(drop=True)","4749bb68":"total = all_data.isnull().sum().sort_values(ascending=False)\npercent = (all_data.isnull().sum()\/train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Toplam', 'Y\u00fczde'])\nmissing_data = missing_data\nmissing_data.head(34)\nmissing_data","b7194bb7":"# Eksik verilerin g\u00f6rselle\u015ftirilmesi\n\nf,ax = plt.subplots(figsize=(15, 10))\nmissing = round(all_data.isnull().mean(),5)\nmissing = missing[missing > 0]\nmissing.sort_values(inplace=True)\nmissing.plot.bar(color=\"b\")\n\nax.set(ylabel=\"Eksik de\u011ferlerin y\u00fczdesi\")\nax.set(xlabel=\"\u00d6zellikler\")\nax.set(title= \"\u00d6zelli\u011fe g\u00f6re eksik veri y\u00fczdesi\")\nsns.despine(trim=True, left=True)","240b2cf3":"missing_categorical_cols = [\"BsmtFinType2\",\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\n                            \"BsmtFinType2\",\"GarageCond\", \"GarageQual\", \"GarageFinish\",\n                            \"GarageType\",\"FireplaceQu\",\"Fence\",\n                            \"Alley\", \"MiscFeature\", \"PoolQC\"]\n\nfor col in missing_categorical_cols:\n    col = all_data[col]\n    for index in range(col.size):\n        if col[index] is np.nan:\n           col[index]= \"NA\"\n        else:\n            continue","e8b89aa7":"garageYrBlt = all_data[\"GarageYrBlt\"]\nfor index in range(garageYrBlt.size):\n    if np.isnan(garageYrBlt[index]):\n        garageYrBlt[index] = 0.0\n    else:\n        continue","156e223c":"mean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['BsmtFinType1'] = mean_f.fit_transform(all_data[['BsmtFinType1']])\n\nmean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['Electrical'] = mean_f.fit_transform(all_data[['Electrical']])\n\nmean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['MSZoning'] = mean_f.fit_transform(all_data[['MSZoning']])\n\nmean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['Functional'] = mean_f.fit_transform(all_data[['Functional']])\n\nmean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['Utilities'] = mean_f.fit_transform(all_data[['Utilities']])\n\nmean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['BsmtHalfBath'] = mean_f.fit_transform(all_data[['BsmtHalfBath']])\n\nmean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['BsmtFullBath'] = mean_f.fit_transform(all_data[['BsmtFullBath']])\n\nmean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['KitchenQual'] = mean_f.fit_transform(all_data[['KitchenQual']])\n\nmean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['Exterior2nd'] = mean_f.fit_transform(all_data[['Exterior2nd']])\n\nmean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['Exterior1st'] = mean_f.fit_transform(all_data[['Exterior1st']])\n\nmean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['BsmtFinSF1'] = mean_f.fit_transform(all_data[['BsmtFinSF1']])\n\nmean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['SaleType'] = mean_f.fit_transform(all_data[['SaleType']])\n\nmean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['TotalBsmtSF'] = mean_f.fit_transform(all_data[['TotalBsmtSF']])\n\nmean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['BsmtUnfSF'] = mean_f.fit_transform(all_data[['BsmtUnfSF']])\n\nmean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['BsmtFinSF2'] = mean_f.fit_transform(all_data[['BsmtFinSF2']])\n\nmean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['GarageCars'] = mean_f.fit_transform(all_data[['GarageCars']])\n\nmean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['GarageArea'] = mean_f.fit_transform(all_data[['GarageArea']])\n\nmean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['MasVnrType'] = mean_f.fit_transform(all_data[['MasVnrType']])\n\nmean_f = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nall_data['MasVnrArea'] = mean_f.fit_transform(all_data[['MasVnrArea']])\n","6829d836":"masVnrType = all_data['MasVnrType']\n\nfor index in range(masVnrType.size):\n    if masVnrType[index] == 'None':\n        masVnrType[index] = 'NA'\n    else:\n        continue\n\nall_data['MasVnrType'] = masVnrType\n\nall_data['MasVnrType']","fc42a7de":"total = all_data.isnull().sum().sort_values(ascending=False)\npercent = (all_data.isnull().sum()\/all_data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Toplam', 'Y\u00fczde'])\n\nmissing_data[:20]","5bf04289":"centralAir = train[\"CentralAir\"]\n\nfor index in range(centralAir.size):\n    if centralAir[index] is \"N\":\n        centralAir[index] = 0\n    else:\n        centralAir[index] = 1\n\n    \ntrain[\"CentralAir\"] = centralAir","88e0c2da":"alley = all_data['Alley']\nHasAlley = []\nAlleyGrvl = []\nAlleyPave = []\n\nfor index in range(alley.size):\n    if alley[index] == 'NA':\n        HasAlley.append(0)\n    else:\n        HasAlley.append(1)   \n    if alley[index] == \"Grvl\":\n        AlleyGrvl.append(1)\n    else:\n        AlleyGrvl.append(0)   \n    if alley[index] == \"Pave\":\n        AlleyPave.append(1)\n    else:\n        AlleyPave.append(0)\n\nall_data[\"HasAlley\"] = HasAlley\nall_data[\"AlleyGrvl\"] = AlleyGrvl\nall_data[\"AlleyPave\"] = AlleyPave\n\nall_data = all_data.drop(\"Alley\", axis='columns')\nall_data.head()","40605889":"BsmtQual_ = all_data[\"BsmtQual\"]\nBsmtQual = []\nHasBsmt = []\n\nfor index in range(BsmtQual_.size):\n    if BsmtQual_[index] == \"NA\":\n        BsmtQual.append(0)\n        HasBsmt.append(0)\n    else:\n        HasBsmt.append(1)\n    if BsmtQual_[index] == \"Ex\":\n        BsmtQual.append(105)   \n    if BsmtQual_[index] == \"Gd\":\n        BsmtQual.append(95)   \n    if BsmtQual_[index] == \"TA\":\n        BsmtQual.append(85)     \n    if BsmtQual_[index] == \"Fa\":\n        BsmtQual.append(75)\n    if BsmtQual_[index] == \"Po\":\n        BsmtQual.append(65)\n\nall_data[\"HasBsmt\"] = HasBsmt\nall_data[\"BsmtQual\"] = BsmtQual","e600eedb":"BsmtCond_ = all_data[\"BsmtCond\"]\nBsmtCond = []\n\nfor index in range(BsmtCond_.size):\n    if BsmtCond_[index] == \"NA\":\n        BsmtCond.append(0)\n    if BsmtCond_[index] == \"Ex\":\n        BsmtCond.append(5)     \n    if BsmtCond_[index] == \"Gd\":\n        BsmtCond.append(4)    \n    if BsmtCond_[index] == \"TA\":\n        BsmtCond.append(3)    \n    if BsmtCond_[index] == \"Fa\":\n        BsmtCond.append(2)\n    if BsmtCond_[index] == \"Po\":\n        BsmtCond.append(1)\n\nall_data[\"BsmtCond\"] = BsmtCond","5c228a54":"GarageQual_ = all_data[\"GarageQual\"]\nHasGarage = []\nGarageQual = []\n\nfor index in range(GarageQual_.size):\n    if GarageQual_[index] == \"NA\":\n        HasGarage.append(0)\n        GarageQual.append(0)\n    else:\n        HasGarage.append(1) \n    if GarageQual_[index] == \"Ex\":\n        GarageQual.append(5)     \n    if GarageQual_[index] == \"Gd\":\n        GarageQual.append(4)     \n    if GarageQual_[index] == \"TA\":\n        GarageQual.append(3)    \n    if GarageQual_[index] == \"Fa\":\n        GarageQual.append(2)\n    if GarageQual_[index] == \"Po\":\n        GarageQual.append(1)\n\nall_data[\"GarageQual\"] = GarageQual\nall_data[\"HasGarage\"] = HasGarage","4b4f3559":"GarageCond_ = all_data[\"GarageCond\"]\nGarageCond = []\n\nfor index in range(GarageCond_.size):\n    if GarageCond_[index] == \"NA\":\n        GarageCond.append(0)\n    if GarageCond_[index] == \"Ex\":\n        GarageCond.append(5)  \n    if GarageCond_[index] == \"Gd\":\n        GarageCond.append(4)     \n    if GarageCond_[index] == \"TA\":\n        GarageCond.append(3)     \n    if GarageCond_[index] == \"Fa\":\n        GarageCond.append(2)\n    if GarageCond_[index] == \"Po\":\n        GarageCond.append(1)\n\nall_data[\"GarageCond\"] = GarageCond","74d140ae":"PoolQC_ = all_data[\"PoolQC\"]\nHasPool = []\nPoolQC = []\n\n\nfor index in range(PoolQC_.size):\n    if PoolQC_[index] == \"NA\":\n        HasPool.append(0)\n        PoolQC.append(0)\n    else:\n        HasPool.append(1)\n    if PoolQC_[index] == \"Ex\":\n        PoolQC.append(4)    \n    if PoolQC_[index] == \"Gd\":\n        PoolQC.append(3)    \n    if PoolQC_[index] == \"TA\":\n        PoolQC.append(2)     \n    if PoolQC_[index] == \"Fa\":\n        PoolQC.append(1)\n\nall_data[\"PoolQC\"] = PoolQC\nall_data[\"HasPool\"] = HasPool","8c7ca710":"FireplaceQu_ = all_data[\"FireplaceQu\"]\nHasFireplace = []\nFireplaceQu = []\n\nfor index in range(FireplaceQu_.size):\n    if FireplaceQu_[index] == \"NA\":\n        HasFireplace.append(0)\n        FireplaceQu.append(0)\n    else:\n        HasFireplace.append(1)\n    if FireplaceQu_[index] == \"Ex\":\n        FireplaceQu.append(5)     \n    if FireplaceQu_[index] == \"Gd\":\n        FireplaceQu.append(4)        \n    if FireplaceQu_[index] == \"TA\":\n        FireplaceQu.append(3)       \n    if FireplaceQu_[index] == \"Fa\":\n        FireplaceQu.append(2)   \n    if FireplaceQu_[index] == \"Po\":\n        FireplaceQu.append(1)\n\nall_data[\"FireplaceQu\"] = FireplaceQu\nall_data[\"HasFireplace\"] = HasFireplace","fb87e030":"Fence_ = all_data[\"Fence\"]\nHasFence = []\nFence = []\n\nfor index in range(Fence_.size):\n    if Fence_[index] == \"NA\":\n        HasFence.append(0)\n        Fence.append(0)\n    else:\n        HasFence.append(1)\n    if Fence_[index] == \"GdPrv\":\n        Fence.append(4)      \n    if Fence_[index] == \"MnPrv\":\n        Fence.append(3)   \n    if Fence_[index] == \"GdWo\":\n        Fence.append(2)\n    if Fence_[index] == \"MnWw\":\n        Fence.append(1)\n\nall_data[\"Fence\"] = Fence\nall_data[\"HasFence\"] = HasFence","a752c988":"ExterQual_ = all_data[\"ExterQual\"]\nExterQual = []\n\nfor index in range(ExterQual_.size):\n    if ExterQual_[index] == \"NA\":    \n        ExterQual.append(0)\n    if ExterQual_[index] == \"Ex\":\n        ExterQual.append(5)   \n    if ExterQual_[index] == \"Gd\":\n        ExterQual.append(4)    \n    if ExterQual_[index] == \"TA\":\n        ExterQual.append(3)\n    if ExterQual_[index] == \"Fa\":\n        ExterQual.append(1)\n    if ExterQual_[index] == \"Po\":\n        ExterQual.append(0)\n\nall_data[\"ExterQual\"] = ExterQual","afb932fa":"ExterCond_ = all_data[\"ExterCond\"]\nExterCond = []\n\nfor index in range(ExterCond_.size):\n    if ExterCond_[index] == \"NA\":    \n        ExterCond.append(0)\n    if ExterCond_[index] == \"Ex\":\n        ExterCond.append(5)  \n    if ExterCond_[index] == \"Gd\":\n        ExterCond.append(4) \n    if ExterCond_[index] == \"TA\":\n        ExterCond.append(3)\n    if ExterCond_[index] == \"Fa\":\n        ExterCond.append(2)\n    if ExterCond_[index] == \"Po\":\n        ExterCond.append(1)\n\nall_data[\"ExterCond\"] = ExterCond","26c192ca":"HeatingQC_ = all_data[\"HeatingQC\"]\nHeatingQC = []\n\nfor index in range(HeatingQC_.size):\n    if HeatingQC_[index] == \"NA\": \n        HeatingQC.append(0)  \n    if HeatingQC_[index] == \"Ex\":\n        HeatingQC.append(5)      \n    if HeatingQC_[index] == \"Gd\":\n        HeatingQC.append(4)     \n    if HeatingQC_[index] == \"TA\":\n        HeatingQC.append(3)\n    if HeatingQC_[index] == \"Fa\":\n        HeatingQC.append(2)\n    if HeatingQC_[index] == \"Po\":\n        HeatingQC.append(1)\n\nall_data[\"ExterCond\"] = ExterCond","d66b84cd":"KitchenQual_ = all_data[\"KitchenQual\"]\nKitchenQual = []\n\nfor index in range(KitchenQual_.size):\n    if KitchenQual_[index] == \"NA\": \n        KitchenQual.append(0)\n    if KitchenQual_[index] == \"Ex\":\n        KitchenQual.append(5)    \n    if KitchenQual_[index] == \"Gd\":\n        KitchenQual.append(4)  \n    if KitchenQual_[index] == \"TA\":\n        KitchenQual.append(3)\n    if KitchenQual_[index] == \"Fa\":\n        KitchenQual.append(2)\n    if KitchenQual_[index] == \"Po\":\n        KitchenQual.append(1)\n\nall_data[\"KitchenQual\"] = KitchenQual\n","edfcbfef":"all_data.head()","9e3285f3":"#all_data'n\u0131n dummy edilmesi.\nall_data_copy = all_data.copy()\nall_data_copy = all_data.drop(\"Id\", axis='columns')\n\nnumeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ncategorial_cols = []\n\nfor col in all_data_copy.columns:\n    if all_data_copy[col].dtype not in numeric_dtypes:\n        categorial_cols.append(col)\n    else:\n        continue\n\nall_data_dummy = pd.get_dummies(all_data_copy[categorial_cols])\nall_data_copy = all_data.drop(categorial_cols, axis='columns')\nall_data_dummy  = pd.concat([all_data_copy,all_data_dummy], axis=1)\n\nall_data_dummy.head()","fde9b96c":"all_data_dummy.info()","341b7b4e":"#LotFrontage kolonunun KNN ile doldurulmas\u0131\nvar_names = list(all_data_dummy)\narray_all_data = np.array(all_data_dummy)\nall_data_knn_dummy = knnimput.KNN(k = 4).complete(array_all_data)\nall_data_knn_dummy = pd.DataFrame(all_data_knn_dummy, columns = var_names)","fd69727f":"total = all_data_knn_dummy.isnull().sum().sort_values(ascending=False)\npercent = (all_data_knn_dummy.isnull().sum()\/all_data_knn_dummy.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Toplam', 'Y\u00fczde'])\n\nmissing_data","f5825d34":"all_data_knn_dummy.head(20)","9ab75ee8":"all_data_knn = all_data.copy()\nall_data_knn[\"LotFrontage\"] = all_data_knn_dummy[\"LotFrontage\"]\nall_data_knn.head(20)","e547e3d0":"#Multiple Imputation(MICE) ile tamamlanmas\u0131\nvar_names = list(all_data_dummy)\narray_all_data = np.array(all_data_dummy)\nall_data_mice_dummy = MICE().complete(array_all_data)\nall_data_mice_dummy = pd.DataFrame(all_data_mice_dummy, columns = var_names)\nall_data_mice_dummy.head(20)","460ffba7":"all_data_mice = all_data.copy()\nall_data_mice[\"LotFrontage\"] = all_data_mice_dummy[\"LotFrontage\"]\nall_data_mice.head(20)","5d9cdcaa":"#Varyansa g\u00f6re \u00f6zellik se\u00e7imi\n\nfrom sklearn.feature_selection import VarianceThreshold\n\n\nselector = VarianceThreshold()\nselected_knn_dummy_vt = selector.fit_transform(all_data_knn_dummy)\nselected_knn_dummy_vt = pd.DataFrame(selected_knn_dummy_vt)\nselected_knn_dummy_vt","86051012":"#korelasyonlara g\u00f6re \u00f6zellik se\u00e7imi\n\ntrain_knn = all_data_knn_dummy.copy()\ntrain_knn = train_knn[:1460]\ntrain_knn[\"SalePrice\"] = train_salePrice\n\ncor_knn = train_knn.corr()\n\n#Hedef de\u011fi\u015fken ile olan korelasyon\ncor_target_knn = abs(cor_knn[\"SalePrice\"])\n\nselected_knn_corr = cor_target_knn[cor_target_knn > 0.5]\n\nselected_knn_corr","dac2f6e8":"train_mice = all_data_mice_dummy.copy()\ntrain_mice = train_mice[:1460]\ntrain_mice[\"SalePrice\"] = train_salePrice\n\ncor_mice = train_mice.corr()#korelasonu y\u00f6n\u00fc \u00f6nemli olmad\u0131\u011f\u0131 \u015fiddeti bizim i\u00e7in \u00f6nemli o y\u00fczden mutlak de\u011ferini al\u0131yoruz.\ncor_target_mice = abs(cor_mice[\"SalePrice\"])\n\nselected_mice_corr = cor_target_mice[cor_target_mice > 0.5]#Y\u00fcksek korelasyonlu olanlar\u0131 se\u00e7me\n\nselected_mice_corr","f27ed388":"#Agac tabanl\u0131 \u00f6zellik se\u00e7imi\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\n\nsalePrice = []\nfor i in range(1459):\n    salePrice.append(0)\n    \nX_knn = all_data_knn_dummy\ny = list(train_salePrice) + salePrice\ny = pd.Series(y)\n\nclf = ExtraTreesClassifier(n_estimators=10)\nclf = clf.fit(X_knn, y)\nclf.feature_importances_  \n\nmodel = SelectFromModel(clf, prefit=True)\nselected_knn_etc = model.transform(X_knn)\nselected_knn_etc = pd.DataFrame(selected_knn_etc)\nselected_knn_etc","993ae0d6":"\nimport mlxtend\nfrom mlxtend.feature_selection import SequentialFeatureSelector as SFS\nfrom mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\nfrom sklearn.linear_model import LogisticRegression\n\nX_SFS = all_data_knn_dummy\ny = list(train_salePrice) + salePrice\ny = pd.Series(y)\n\n# Sequential Forward Selection(sfs)\nsfs = SFS(LogisticRegression(),\n           k_features=30,\n           forward=True,\n           floating=False,\n           scoring = 'accuracy',\n           cv = 0)\nsfs1=sfs.fit(X_SFS, y)\nfig1 = plot_sfs(sfs1.get_metric_dict(), kind='std_dev')\nresult_LR = pd.DataFrame.from_dict(sfs1.get_metric_dict(confidence_interval=0.90)).T\nresult_LR.sort_values('avg_score', ascending=0, inplace=True)\nresult_LR.head()\n\nbest_features_LR = result_LR.feature_idx.head(1).tolist()\nselect_features_LR = can.columns[best_features_LR]\nselect_features_LR","d5482354":"X_train = all_data_knn_dummy[:1460].drop(\"Id\", axis='columns')\ny_train = train_salePrice\nX_test = all_data_knn_dummy[1460:].drop(\"Id\", axis='columns')\n\n\nrf_model = RandomForestRegressor(n_estimators=10, max_depth=20)\ntuned = rf_model.fit(X_train,y_train)\ny_pred = tuned.predict(X_test)","d6a75113":"my_submission = pd.DataFrame({'Id': range(1461,2920), 'SalePrice': y_pred })\nmy_submission.to_csv('submission_rf.csv', index=False)\nmy_submission.info()","792427d0":"print(x)","c58c0c3d":"X_train = all_data_knn_dummy[:1460].drop(\"Id\", axis='columns')\ny_train = train_salePrice\nX_test = all_data_knn_dummy[1460:].drop(\"Id\", axis='columns')\n\n\nrf_model = RandomForestRegressor()\n\nrf_params = { \"max_depth\" : [2,4,5,8,10],\n              \"max_features\" : [1,2,5,8,10,17],\n              \"n_estimators\" : [100,200,500,1000,1500,1800,2000],\n              \"min_samples_split\": [2,10,75,60,100,80] }\n\nrf_cv_model = GridSearchCV(rf_model, rf_params, cv=10, n_jobs=-1, verbose=2).fit(X_train,y_train)\n\nrf_best_params = rf_cv_model.best_params_\n\nmd = rf_best_params[\"max_depth\"]\nmf = rf_best_params[\"max_features\"]\nmss = rf_best_params[\"min_samples_split\"]\nn = rf_best_params[\"n_estimators\"]\n\nrf_model = RandomForestRegressor(max_depth = md, max_features = mf, min_samples_split = mss, n_estimators = n)\nrf_tuned = rf_model.fit(X_train,y_train)\n\ny_pred = rf_tuned.predict(X_test)\ny_pred \n","6c6b8cae":"rf_Importance = pd.DataFrame({\"Importance\":rf_tuned.feature_importances_*100},index = X_train.columns)\n\ns = rf_Importance.sort_values(by = \"Importance\", axis=0, ascending = False)\nfig_dims = (50, 50)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.barplot(x = \"Importance\", y =  rf_Importance[\"Importance\"].index, ax=ax, data=s);\n\n","9c393dc3":"new_train_columns = []\n\nfor index, row in rf_Importance.iterrows():\n    if(row[\"Importance\"] >= 0.1):\n        new_train_columns.append(index)\n    \nnew_train = X_train[new_train_columns]\n\nX_train = new_train\nX_test = X_test[new_train_columns]\nrf_model = RandomForestRegressor(max_depth = md, max_features = mf, min_samples_split = mss, n_estimators = n)\nrf_tuned = rf_model.fit(X_train,y_train)\n\ny_pred = rf_tuned.predict(X_test)","c5254df8":"# MICE ile eksik verilerin tamamlanana veri k\u00fcmesinin e\u011fitilmesi \n\nX_train = all_data_mice_dummy[:1460].drop(\"Id\", axis='columns')\ny_train = train_salePrice\nX_test = all_data_mice_dummy[1460:].drop(\"Id\", axis='columns')","c24e23cf":"# KNN y\u00f6ntemi ile eksik verilerin tamamlanana veri k\u00fcmesinin e\u011fitilmesi \n\nX_train = all_data_knn_dummy[:1460].drop(\"Id\", axis='columns')\ny_train = train_salePrice\nX_test = all_data_knn_dummy[1460:].drop(\"Id\", axis='columns')","4eb6a8c9":"# Korelasyon tabanl\u0131 \u00f6zellik se\u00e7imi ile olu\u015fturulan veri k\u00fcmesinin e\u011fitilmesi \n\ntrain_columns = [\"OverallQual\",\"YearBuilt\",\"YearRemodAdd\", \"ExterQual\", \"TotalBsmtSF\" ,    \n                 \"1stFlrSF\", \"GrLivArea\", \"FullBath\", \"KitchenQual\", \"TotRmsAbvGrd\",\"GarageCars\", \"GarageArea\"]\n\nX_train = all_data_knn_dummy[:1460].drop(\"Id\", axis='columns')\nX_train = X_train[train_columns]\ny_train = train_salePrice\nX_test = all_data_knn_dummy[1460:].drop(\"Id\", axis='columns')\nX_test = X_test[train_columns]","1e1842e7":"# A\u011fa\u00e7 tabanl\u0131 \u00f6zellik se\u00e7imi ile olu\u015fturulan veri k\u00fcmesinin e\u011fitilmesi \n\nX_train = selected_knn_etc[:1460]\ny_train = train_salePrice\nX_test = selected_knn_etc[1460:]\n\nscaler = StandardScaler()\n\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\n\nscaler.fit(X_test)\nX_test_scaled = scaler.transform(X_test)\n\nxgb_model = XGBRegressor()\n\nxgb_params = { \"learning_rate\" : [0.1,0.01,0.001],\n               \"max_depth\" : [3, 5, 8, 10],\n               \"n_estimators\" : [100,200,500,1000,1500,1800,2000],\n               \"colsample_bytree\": [0.4, 0.7, 1] }\n\nxgb_cv_model = GridSearchCV(xgb_model, xgb_params, cv=10, n_jobs=-1, verbose=2).fit(X_train,y_train)\n\n\nxgb_model = xgb_cv_model.best_estimator_\nxgb_tuned = xgb_model.fit(X_train,y_train)\n\ny_pred_xgb = xgb_tuned.predict(X_test)  ","851ad36c":"xgb_model","958765d7":"xgb_Importance = pd.DataFrame({\"Importance\":xgb_tuned.feature_importances_*100},index = X_train.columns)\n\ns = xgb_Importance.sort_values(by = \"Importance\", axis=0, ascending = False)\nfig_dims = (50, 50)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.barplot(x = \"Importance\", y =  xgb_Importance[\"Importance\"].index, ax=ax, data=s)\n","c4c99010":"new_train_columns = []\n\nfor index, row in xgb_Importance.iterrows():\n    if(row[\"Importance\"] >= 0.1):\n        new_train_columns.append(index)\n    \nnew_train = X_train[new_train_columns]\n\nX_train = new_train\nX_test = X_test[new_train_columns]\n\nscaler = StandardScaler()\n\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\n\nscaler.fit(X_test)\nX_test_scaled = scaler.transform(X_test)\n\nxgb_model = xgb_cv_model.best_estimator_\nxgb_tuned = xgb_model.fit(X_train,y_train)\n\ny_pred_xgb = xgb_tuned.predict(X_test)\ny_pred_xgb","e4ec2170":"my_submission = pd.DataFrame({'Id': range(1461,2920), 'SalePrice': y_pred_xgb })\nmy_submission.to_csv('submission_xgb.csv', index=False)\nmy_submission.info()","a7b402d5":"# KNN ile eksik verileri tamamlanarak a\u011fa\u00e7 tabanl\u0131 \u00f6zellik se\u00e7imi ile olu\u015fturulan veri k\u00fcmesinin e\u011fitilmesi \n\nX_train = selected_knn_etc[:1460].drop(0, axis='columns')\ny_train = train_salePrice\nX_test = selected_knn_etc[1460:].drop(0, axis='columns')\n\nscaler = StandardScaler()\n\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\n\nscaler.fit(X_test)\nX_test_scaled = scaler.transform(X_test)\n\nmlp_model = MLPRegressor()\n\nmlp_params = {\"alpha\": [0.1, 0.01, 0.02, 0.001],\n               \"hidden_layer_sizes\": [(50,50), (10,10), (150,100),(20,10), (250,250), (300,100),(100,100)],\n               \"solver\" : [\"lbfgs\",\"adam\",\"sgd\"],\n               \"activation\": [\"relu\",\"logistic\",\"tanh\"]}\n\nmlp_cv_model = GridSearchCV(mlp_model, mlp_params, cv=10, n_jobs=-1, verbose=2).fit(X_train_scaled,y_train)\n\nmlp_model = mlp_cv_model.best_estimator_\nmlp_model\n\nmlp_tuned = mlp_model.fit(X_train_scaled,y_train)\n\ny_pred_mlp = mlp_tuned.predict(X_test_scaled)\ny_pred_mlp\n","1bfd65ac":"# KNN ile eksik verileri tamamlanan b\u00fct\u00fcn veri k\u00fcmesinin e\u011fitilmesi \n\nX_train = all_data_knn_dummy[:1460].drop(\"Id\", axis='columns')\ny_train = train_salePrice\nX_test = all_data_knn_dummy[1460:].drop(\"Id\", axis='columns')\n\n\nscaler = StandardScaler()\n\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\n\nscaler.fit(X_test)\nX_test_scaled = scaler.transform(X_test)\n\n\nmlp_model = MLPRegressor()\n\nmlp_params = {\"alpha\": [0.1, 0.01, 0.02, 0.001],\n               \"hidden_layer_sizes\": [(50,50), (10,10), (150,100),(200,100), (250,250), (300,100),(100,100)],\n               \"solver\" : [\"lbfgs\",\"adam\",\"sgd\"],\n               \"activation\": [\"relu\",\"logistic\",\"tanh\"]}\n\nmlp_cv_model = GridSearchCV(mlp_model, mlp_params, cv=10, n_jobs=-1, verbose=2).fit(X_train_scaled,y_train)\n\nmlp_model = mlp_cv_model.best_estimator_\nmlp_tuned = mlp_model.fit(X_train_scaled,y_train)\n\ny_pred_mlp = mlp_tuned.predict(X_test_scaled)\ny_pred_mlp","c6de9ff4":"my_submission = pd.DataFrame({'Id': range(1461,2920), 'SalePrice': y_pred_mlp })\nmy_submission.to_csv('submission_mlp.csv', index=False)\nmy_submission.info()","2c686373":"print(\"done\")","8a37f3af":"Sat\u0131\u015f fiyat\u0131 ve konutun garaj\u0131n\u0131n metrekaresi (GarageArea) aras\u0131ndaki ili\u015fki;","7f8d2625":"Konutun b\u00fcnyesinde bar\u0131nd\u0131rd\u0131\u011f\u0131 baz\u0131 \u00f6zelliklerin kalitesi ile ilgili \u00f6zellikler kategorik de\u011fi\u015fken olarak yer almaktad\u0131r. \u00d6ncelikle bu \u00f6zellikleri say\u0131sal de\u011ferlere d\u00f6n\u00fc\u015ft\u00fcrelim.","b7366dbb":" **2. XGBOOST ALGOR\u0130TMASI**\n\nXGBOOST algoritmas\u0131 da a\u011faca dayal\u0131 makine \u00f6\u011frenme algoritmalar\u0131ndan biridir. Gradient Boosting algoritmas\u0131n\u0131n \u00e7e\u015fitli d\u00fczenlemeler ile optimize edilmi\u015f y\u00fcksek performansl\u0131 halidir. ","c7303949":"# KONUT F\u0130YATLARININ TAHM\u0130N\u0130\n\nKonut fiyat tahmini olduk\u00e7a karma\u015f\u0131k ve \u00e7ok say\u0131da parametrenin dikkate al\u0131nmas\u0131n\u0131 gerektiren bir tahmin i\u015flemidir.\n\nVeri k\u00fcmesinde 1460 konutun 81 adet kolon bulunmaktad\u0131r. Bu kolonlar\u0131n 79 tanesi konut \u00f6zelliklerini temsil etmektedir. Konut \u00f6zelliklerini temsil eden 79 kolonun 43 tanesi kategorik, 36 tanesi say\u0131sal de\u011fer almaktad\u0131r. Konut \u00f6zelliklerini temsil eden kolonlarda eksik veriler bulunmaktad\u0131r.\n\nBu \u00e7al\u0131\u015fman\u0131n amac\u0131 bu \u00f6zellikler dikkate al\u0131narak konut sat\u0131\u015f fiyat\u0131n\u0131n(SalePrice) tahmin edilmesidir.","d8c5da83":"info( ) metodu ile \u00e7al\u0131\u015f\u0131lan veri k\u00fcmesi i\u00e7erisindeki dtype olarak bilinen veri tipleri ve kullan\u0131lan bellek hakk\u0131nda bize bilgi vermektedir. B\u00f6ylece veri k\u00fcmesinin kolon say\u0131s\u0131n\u0131 ve veri tiplerini \u00f6\u011frenebiliriz.","9a79778c":"Bu \u00e7al\u0131\u015fmada \u00f6nemli olan nokta konutlar\u0131n sat\u0131\u015f fiyat\u0131(SalePrice) oldu\u011fu i\u00e7in bir de sat\u0131\u015f fiyat\u0131n\u0131n di\u011fer \u00f6zelliklerle olan korelasyonuna bakal\u0131m.","de57c2e1":"Eksik verinin 10 taneden az oldu\u011fu \u00f6zellikleri Scikit-learn k\u00fct\u00fcphanesinin SimpleImputer mod\u00fcl\u00fcn\u00fc kullanarak en s\u0131k kullan\u0131lan de\u011fer ile tamamlayal\u0131m.\n\nScikit-learn, Python programlama dilinde yaz\u0131lm\u0131\u015f bir makine \u00f6\u011frenme k\u00fct\u00fcphanesidir. SimpleImputer eksik de\u011ferlerin d\u00f6n\u00fc\u015ft\u00fcr\u00fclmesini sa\u011flayan sklearn k\u00fct\u00fcphanesinden kulland\u0131\u011f\u0131m\u0131z bir d\u00f6n\u00fc\u015ft\u00fcr\u00fcc\u00fc mod\u00fcld\u00fcr.\n\nmissing_values parametresi ile d\u00f6n\u00fc\u015ft\u00fcr\u00fclmek istenen veriler belirlenmektedir.Daha sonraki parametre olan strategy parametresi s\u0131ras\u0131nda ise 4 adet yer alan strateji t\u00fcr\u00fcnden birisini se\u00e7erek hangi y\u00f6nteme g\u00f6re d\u00f6n\u00fc\u015ft\u00fcr\u00fclece\u011fine karar verilmektedir. A\u015fa\u011f\u0131da bu stratejilere yer verilmektedir:\n\n\u201cmean\u201d stratejisi, her s\u00fctun boyunca ortalama kullan\u0131larak eksik de\u011ferlerin de\u011fi\u015ftirilmesini sa\u011flar. Yaln\u0131zca say\u0131sal verilerle kullan\u0131labilir.\n\n\u201cmedian\u201d stratejisi, her s\u00fctun boyunca medyan kullan\u0131larak eksik de\u011ferlerin de\u011fi\u015ftirilmesini sa\u011flar. Yaln\u0131zca say\u0131sal verilerle kullan\u0131labilir.\n\n\u201cmost_frequent\u201d stratejisi , her s\u00fctun boyunca en s\u0131k kullan\u0131lan de\u011feri kullan\u0131larak eksik de\u011ferlerin de\u011fi\u015ftirilmesini sa\u011flar. String veya say\u0131sal verilerle kullan\u0131labilir.\n\n\u201cconstant\u201d stratejisi, eksik de\u011ferleri fill_value ile de\u011fi\u015ftirin. String veya say\u0131sal verilerle kullan\u0131labilir.","7a803f04":"Sat\u0131\u015f fiyat\u0131 ve konutta yer alan toplam oda say\u0131s\u0131 (TotRmsAbvGrd) aras\u0131ndaki ili\u015fki;","f664a348":"Da\u011f\u0131l\u0131m (scatter) diyagram\u0131, iki farkl\u0131 de\u011fi\u015fkenin aras\u0131ndaki ili\u015fkiyi belirlemek i\u00e7in kullan\u0131lan grafiklerden biridir. \n\nSat\u0131\u015f fiyat\u0131 ve giri\u015f kat\u0131n\u0131n toplam metrekaresi(TotalBsmtSF) aras\u0131ndaki ili\u015fki \u015fu \u015fekildedir;","bda7c8ae":"\u0130lk ad\u0131m olarak projede kullanaca\u011f\u0131m\u0131z Python\u2019a ait olan k\u00fct\u00fcphanelerini import edelim.","6bb29ff5":"Veri k\u00fcmelerindeki baz\u0131 \u00f6zelliklerdeki eksiklikler ba\u015fka bir de\u011fi\u015fkenle ba\u011flant\u0131l\u0131 olup yap\u0131sal bir durumdan dolay\u0131 eksik olabilmektedir.\n\nKonutun garaj\u0131n\u0131n yap\u0131m y\u0131l\u0131(GarageYrBlt) \u00f6zelli\u011findeki eksik veriler de yap\u0131sal durumdan dolay\u0131 ortaya \u00e7\u0131km\u0131\u015ft\u0131r. Bu \u00f6zellik \u2018NA\u2019 ifadesi ile doldurulan eksik verilerde ba\u011flant\u0131l\u0131 olup garaj\u0131 olmayan konutlar\u0131n garaj yap\u0131m y\u0131l\u0131 da bulunmamaktad\u0131r.","d805351b":"**3. A\u011eA\u00c7 TABANLI \u00d6ZELL\u0130K SE\u00c7\u0130M\u0130**\n\nEkstra a\u011fa\u00e7 s\u0131n\u0131fland\u0131r\u0131c\u0131s\u0131, s\u0131n\u0131fland\u0131rma sonucunu \u00e7\u0131karmak i\u00e7in bir \"ormanda\" toplanan birden fazla ili\u015fkisiz karar a\u011fac\u0131n\u0131n sonu\u00e7lar\u0131n\u0131 bir araya getiren bir toplu \u00f6\u011frenme tekni\u011fidir. Her a\u011fac\u0131n tahmini dikkate al\u0131narak nihai karar\u0131n al\u0131nd\u0131\u011f\u0131 \u00e7ok say\u0131da karar a\u011fac\u0131ndan olu\u015fmaktad\u0131r","94e5c11f":"Yap\u0131lan eksik veri tamamlama i\u015flemlerinden sonra sadece konuta ba\u011fl\u0131 caddenin uzunlu\u011fu (LotFrontage) \u00f6zelli\u011finde eksik veriler bulunmaktad\u0131r. Bu \u00f6zellikteki eksik verilerin say\u0131s\u0131 fazla oldu\u011fu i\u00e7in tahmine dayal\u0131 de\u011fer atama y\u00f6ntemi kullanal\u0131m.\n\nDe\u011fer atama i\u015flemi i\u00e7in uygulamas\u0131 kolay g\u00f6zetimli \u00f6\u011frenme algoritmalar\u0131ndan K-En Yak\u0131n Kom\u015fu (KNN) algoritmas\u0131ndan ve \u00e7oklu de\u011fer atama (multiple imputation) y\u00f6ntemlerinden faydalanaca\u011f\u0131z ancak bundan \u00f6nce kategorik \u00f6zelliklerimizi say\u0131sal \u00f6zelliklere d\u00f6n\u00fc\u015ft\u00fcrmemiz gerekmekte. Bunun i\u00e7in get_dummies() metodunu kullanaca\u011f\u0131z.","5825f029":"corr() metodu veri k\u00fcmesinde yer alan \u00f6zeliklerin korelasyon matrisini olu\u015fturur(Sadece say\u0131lsal de\u011fer alan \u00f6zellikler i\u00e7in). Korelasyon iki rassal de\u011fi\u015fken aras\u0131ndaki do\u011frusal ili\u015fkinin y\u00f6n\u00fcn\u00fc ve g\u00fcc\u00fcn\u00fc belirtir.","ac4974f8":"Sat\u0131\u015f fiyat\u0131 ve konutun garaj\u0131n\u0131n ara\u00e7 kapasitesi(GarageCars) aras\u0131ndaki ili\u015fki;","c2e22f3e":"Pandas k\u00fct\u00fcphanesini import ederken pd k\u0131saltmas\u0131 ile tan\u0131mlad\u0131\u011f\u0131m\u0131z i\u00e7in kodun her alan\u0131nda art\u0131k pd ile \u00e7a\u011f\u0131rabilmemiz m\u00fcmk\u00fcnd\u00fcr. \u00dczerinde \u00e7al\u0131\u015faca\u011f\u0131m veri k\u00fcmesi bir CSV dosyas\u0131 oldu\u011fu i\u00e7in read_csv( ) metodu ile verilerimizi okuyal\u0131m.","3bea118b":"# SATI\u015e F\u0130YATININ \u0130NCELENMES\u0130\n\nBu \u00e7al\u0131\u015fmadaki as\u0131l \u00f6nemli nokta konutlar\u0131n sat\u0131\u015f fiyat\u0131 yani \"SalePrice\" kolonudur. Sat\u0131\u015f fiyat\u0131n\u0131n ve di\u011fer konut \u00f6zelliklerinin birbiri ile olan korelasyonlar\u0131n\u0131 yani birbirleriyle olan ba\u011fl\u0131l\u0131klar\u0131n\u0131 incelemek bize \u00f6zellik se\u00e7iminde yard\u0131mc\u0131 olacakt\u0131r.\n\n\"SalePrice\" kolonunu biraz inceleyelim.","5e5ad6fa":"Yukar\u0131da yer alan korelasyon grafi\u011finde sat\u0131\u015f fiyat\u0131n\u0131n ve di\u011fer konut \u00f6zelliklerinin korelasyonu g\u00f6r\u00fclmektedir. Buradan yola \u00e7\u0131karak bir konutun sat\u0131\u015f fiyat\u0131n\u0131 0.5'ten b\u00fcy\u00fck bir korelasyonu olan \u00f6zelliklerin \u2018OverallQual\u2019, 'YearBuilt', \u2018TotalBsmtSF\u2019, \u20181stFlrSF\u2019, 'GrLiArea', 'FullBath','TotRmsAbvGrd', \u2018GarageCars\u2019 ve \u2018GarageArea\u2019 oldu\u011fu g\u00f6r\u00fclmektedir.\n\nBu \u00f6zelliklerin korelasyonuna bakacak olursak;","bdca0eeb":"# **MODEL OLU\u015eTURULMASI**\n\n\u00d6rneklem \u00fczerinden elde edilen tahmin fonksiyonu;\n\nY' =b0 + b1x1 + b2x2 +...+bjxj+...+ pxp   \nY' : Konut fiyat\u0131\nbi  : Konutun fiyat\u0131n\u0131 etkileyen \u00f6zelliklerin a\u011f\u0131rl\u0131klar\u0131\nxi  : Konut fiyat\u0131n\u0131 etkileyen \u00f6zellikler\n\n\nProbleme, veri k\u00fcmesine g\u00f6re de\u011fi\u015fiklik g\u00f6steren makine \u00f6\u011frenmesi modellerinin parametrelerini hiper parametre (hyperparameters) olarak adland\u0131r\u0131lmaktad\u0131r.  Bu hiper parametreler probleme,  veri k\u00fcmesine g\u00f6re farkl\u0131l\u0131k g\u00f6sterdi\u011fi i\u00e7in hiper parametre se\u00e7imi modeli olu\u015fturan tasar\u0131mc\u0131 taraf\u0131ndan yap\u0131lmaktad\u0131r.\n\nScikit-learn k\u00fct\u00fcphanesinde yer alan GridSearchCV mod\u00fcl\u00fc de hiper parametre se\u00e7iminde kullan\u0131lmaktad\u0131r.\nGridSearchCV, modelde denenmesi istenen hiper parametreler ve de\u011ferleri i\u00e7in b\u00fct\u00fcn kombinasyonlar ile ayr\u0131 ayr\u0131 model kurarak ve belirtilen metri\u011fe g\u00f6re en ba\u015far\u0131l\u0131 hiper parametre seti belirlemektedir.\n\n**1. RASTGELE ORMAN ALGOR\u0130TMASI (RANDOM FOREST)**\n\nTopluluk \u00f6\u011frenme y\u00f6ntemi olan rastgele orman algoritmas\u0131, s\u0131n\u0131fland\u0131rma i\u015flemi esnas\u0131nda birden fazla karar a\u011fac\u0131 \u00fcreterek s\u0131n\u0131fland\u0131rma de\u011ferini y\u00fckseltmeyi hedefleyen bir algoritmad\u0131r.\n","b31d8fb0":"# EKS\u0130K VER\u0130LER\u0130N \u0130NCELENMES\u0130\n\nEksik veri incelenen veri k\u00fcmesindeki g\u00f6zlemlerde eksiklik olmas\u0131 durumunu ifade etmektedir. Veri \u00f6n i\u015fleme i\u015flemlerinde kar\u015f\u0131m\u0131za \u00e7\u0131kan ciddi problemlerden biridir.\n\n\u00d6ncelikle konut \u00f6zelliklerini temsil eden kolonlar\u0131n hangisinde, ne kadar eksik veri oldu\u011funu inceleyelim. Toplamda her s\u00fctun (\u00f6zellik) i\u00e7in ne kadar NaN de\u011fer yer ald\u0131\u011f\u0131n\u0131 g\u00f6rmek istiyor iseniz sum() metodu ile sonucu ekranda g\u00f6rebilmeniz m\u00fcmk\u00fcnd\u00fcr.","fc58d3c2":"Veri k\u00fcmesinin \u00f6zellikleri incelendi\u011fi zaman, veri k\u00fcmesinde yer alan kategorik de\u011ferler alan \u00f6zelliklerde bulunan NaN de\u011ferler asl\u0131nda eksik veri olmad\u0131\u011f\u0131 ve bir anlam ifade etti\u011fi,'NA' yani yok anlam\u0131na geldi\u011fi g\u00f6r\u00fclmektedir.\n\n\u00d6ncelikle veri k\u00fcmesinde bu duruma sahip olan \u00f6zelliklerideki eksik de\u011ferleri \u2018NA\u2019 ifadesi ile tamamlamaya ba\u015flayal\u0131m.","7ea14fb0":"Sat\u0131\u015f fiyat\u0131 ve konutun zemin \u00fczerindeki toplam ya\u015fam alan\u0131(GrLivArea) aras\u0131ndaki ili\u015fki;","84af1ef8":"Sat\u0131\u015f fiyat\u0131 ve konutun 1. kat\u0131n\u0131n metrekasi(1stFlrSF) aras\u0131ndaki ili\u015fki;","a0e340db":"Sat\u0131\u015f fiyat\u0131 ile giri\u015f kat\u0131n\u0131n toplam metrekaresi(TotalBsmtSF), konutun 1. kat\u0131n\u0131n metrekasi(1stFlrSF) ve konutun zemin \u00fczerindeki toplam ya\u015fam alan\u0131(GrLivArea) aras\u0131nda do\u011frusal bir ili\u015fki bulundu\u011fu da\u011f\u0131l\u0131m grafiklerinde g\u00f6r\u00fclmektedir.\n\n\nSat\u0131\u015f fiyat\u0131 ve konutun tamamlanm\u0131\u015f banyo say\u0131s\u0131 (FullBath) aras\u0131ndaki ili\u015fki;","bb9a7178":"Veri k\u00fcmemizdeki kategorik \u00f6zelliklerimizi say\u0131sal \u00f6zelliklere d\u00f6n\u00fc\u015ft\u00fcrd\u00fck. \u015eimdi kalan eksik verilerimizi de tamamlayal\u0131m. Bunun i\u00e7in Ycimpute k\u00fct\u00fcphanesinin Knnimpute mod\u00fcl\u00fcn\u00fc kullanaca\u011f\u0131m. Ama bu mod\u00fcl\u00fc kullanabilmek i\u00e7in \u00f6nce install edip sonra import etmemiz gerekmekte.\n\nknnimput() metodu bizden bir Numpy array'i bekledi\u011fi i\u00e7in veri k\u00fcmemizdeki \u00f6zellikleri bir yerde saklay\u0131p veri k\u00fcmemizi bir Numpy array'e d\u00f6n\u00fc\u015ft\u00fcr\u00fcp eksik de\u011ferleri tamamlad\u0131ktan sonra tekrar isimlendirme i\u015fleminin ger\u00e7ekle\u015ftirece\u011fiz;","22904d06":"Kutu grafikleri, ara\u015ft\u0131rmac\u0131lar\u0131n ortalama de\u011ferleri, veri k\u00fcmesinin da\u011f\u0131l\u0131m\u0131n\u0131 ve de\u011fi\u015fkenlik belirtilerini h\u0131zl\u0131 bir \u015fekilde tan\u0131mlamas\u0131n\u0131, verilerin g\u00f6rsel bir \u00f6zeti sa\u011flayan grafiklerdir. Yukar\u0131daki grafikte ayk\u0131r\u0131 de\u011ferler var gibi g\u00f6r\u00fcnse de bu ak\u0131r\u0131l\u0131k konutun sahip oldu\u011fu di\u011fer \u00f6zellikler ile ba\u011flant\u0131l\u0131d\u0131r.\n\nBir di\u011fer \u00f6nemli \u00f6zelli\u011fimiz de 'YearBuilt' yani konutun yap\u0131m y\u0131l\u0131. Bu \u00f6zelli\u011fin kutu grafi\u011fi ise \u015fu \u015fekilde;","5ad2534e":"\u00c7oklu de\u011fer atama y\u00f6nteminde mevcut veri k\u00fcmesi \u00fczerinden bir istatistiksel da\u011f\u0131l\u0131m elde edilir (\u00f6rne\u011fin ilkelleme (regression)) ard\u0131ndan bu da\u011f\u0131l\u0131m sayesinde eksik verileri dolduran bir ba\u011flant\u0131 kullan\u0131l\u0131r, bu i\u015flem birden fazla yap\u0131larak her bir veri k\u00fcmesi daha sonra kullan\u0131lmak \u00fczere saklan\u0131r.","9e5fa022":"**\u00c7OK KATMANLI YAPAY S\u0130N\u0130R A\u011eLARI**\n\n\u0130nsan beyninin bilgi i\u015fleme \u015feklini referans alan s\u0131n\u0131fland\u0131rma ve regresyon problemleri i\u00e7in kullan\u0131labilen kuvvetli makine  \u00f6\u011frenmesi algoritmalar\u0131ndan biridir.","0cbada48":"# \u00d6ZELL\u0130K SE\u00c7\u0130M\u0130\n\n\u00c7ok fazla \u00f6zellik kullanmak modelin performans\u0131n\u0131 d\u00fc\u015f\u00fcrebilir. En iyi performans sonucu elde etmek i\u00e7in, en optimum de\u011fi\u015fkenler belirlenip bu \u00f6zellikler ile model kurmak gerekmektedir. Se\u00e7ilen \u00f6zellikler ile karma\u015f\u0131k olmayan daha kolay anla\u015f\u0131l\u0131r  ve h\u0131zl\u0131 \u00e7al\u0131\u015fan bir model elde edilmi\u015f olunur.\n\n**1. VARYANSA G\u00d6RE \u00d6ZELL\u0130K SE\u00c7\u0130M\u0130**\n\nVaryansa g\u00f6re \u00f6zellik se\u00e7imi d\u00fc\u015f\u00fck varyansl\u0131 \u00f6zelliklerin veri k\u00fcmesinden \u00e7\u0131kar\u0131lmas\u0131d\u0131r. Varyans, verilerin aritmetik ortalamadan sapmalar\u0131n\u0131n karelerinin toplam\u0131d\u0131r. E\u011fer b\u00fct\u00fcn de\u011ferler ayn\u0131 ise varyans = 0 olacakt\u0131r. Bu a\u015fama t\u00fcm de\u011ferleri ayn\u0131 olan kategorik \u00f6zelliklerin veri k\u00fcmesinden \u00e7\u0131karma i\u015fleminin say\u0131sal \u00f6zellikler i\u00e7in olan a\u015famas\u0131d\u0131r. ","39c9c199":"\u015eimdi gelin konut fiyatlar\u0131n\u0131n belirlenmesinde \u00f6nemli olan bu \u00f6zellikleri biraz yak\u0131ndan inceleyelim.\n\nOverallQual kolonu konutun malzeme kalitesini ifade etmektedir. 1-10 aras\u0131nda say\u0131sal de\u011fer almaktad\u0131r.","a53c67b8":"Varyansa g\u00f6re \u00f6zellik se\u00e7imi yap\u0131ld\u0131\u011f\u0131nda alt k\u00fcme olarak b\u00fct\u00fcn \u00f6zelliklerin yer ald\u0131\u011f\u0131 bir veri k\u00fcmesi elde edilmi\u015ftir, bu durumda veri k\u00fcmesindeki \u00f6zelliklerde y\u00fcksek oranda ayn\u0131 de\u011feri ta\u015f\u0131yan bir \u00f6zellik bulunmad\u0131\u011f\u0131n\u0131 g\u00f6stermektedir.\n\n\n**2. KORELASYONA G\u00d6RE \u00d6ZELL\u0130K SE\u00c7\u0130M\u0130**\n\nVeri k\u00fcmesindeki \u00f6zelliklerin sat\u0131\u015f fiyat\u0131yla do\u011frusal ili\u015fkinin y\u00f6n\u00fcn\u00fc ve g\u00fcc\u00fcn\u00fcn\u00fc  Pearson   korelasyonu ile g\u00f6zlemlemi\u015ftik. Pearson korelasyonu say\u0131sal de\u011fi\u015fkenler i\u00e7in kullan\u0131lmaktad\u0131r. Pearson korelasyonu ile \u00f6zellik se\u00e7imi yapmak da m\u00fcmk\u00fcnd\u00fcr. ","77cbcdc8":"skew() metodu veri k\u00fcmesinin \u00e7arp\u0131kl\u0131\u011f\u0131n\u0131 hesaplamaktad\u0131r. \u00c7arp\u0131kl\u0131k; \n\n![](http:\/\/media.geeksforgeeks.org\/wp-content\/uploads\/skewness.jpg)\n\nformul\u00fc ile hesaplan\u0131r. \n\n* \u00e7arp\u0131kl\u0131k = 0: normal da\u011f\u0131l\u0131m\n* \u00e7arp\u0131kl\u0131k > 0: da\u011f\u0131l\u0131m\u0131n sol kuyru\u011funda daha fazla a\u011f\u0131rl\u0131k\n* \u00e7arp\u0131kl\u0131k < 0: da\u011f\u0131l\u0131m\u0131n sa\u011f kuyru\u011funda daha fazla a\u011f\u0131rl\u0131k \n\nBas\u0131kl\u0131k kavram\u0131 bir reel de\u011ferli rassal de\u011fi\u015fken i\u00e7in olas\u0131l\u0131k da\u011f\u0131l\u0131m\u0131n\u0131n, grafik g\u00f6steriminden tan\u0131mlanarak ortaya \u00e7\u0131kar\u0131lan bir kavram olan, sivrili\u011fi veya bas\u0131kl\u0131\u011f\u0131 \u00f6zelli\u011finin \u00f6l\u00e7\u00fcm\u00fcd\u00fcr.\n\n"}}