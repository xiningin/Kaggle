{"cell_type":{"3f963f6f":"code","274409d6":"code","0d15a172":"code","42eafa71":"code","5f9515b8":"code","af728d74":"code","5427ea3c":"code","ca71455b":"code","23848d5c":"code","6ff68130":"code","b082af47":"code","99ad6c4f":"code","1cdf517a":"code","88d7a238":"code","8c085f4d":"code","1370982e":"code","ec269c65":"code","2a4bf408":"code","f2a2e07b":"code","6edc299a":"code","92cbec49":"code","63c164ce":"code","8fed7eb6":"code","cc88a7e7":"code","312e7813":"code","b4347c97":"code","560c62a1":"code","c6761070":"code","49b0ba85":"code","86fdc450":"code","87b0ba51":"code","425bf6a2":"code","53800f23":"code","8f2ee291":"code","37818748":"code","a2ddfa51":"code","72e8bb6c":"markdown"},"source":{"3f963f6f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport pandas as pd\nimport numpy as np\nimport string\nimport re\nimport json\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport nltk\nfrom wordcloud import WordCloud\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n\nfrom nltk.corpus import stopwords\nnltk_stopwords = stopwords.words('english')\n\nremove_punctuation = '!\"$%&\\'()*+,-.\/:;<=>?@[\\\\]\u201c\u201d^_`{|}~\u2019'\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.utils import np_utils\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","274409d6":"import pandas as pd\nenglish_text = pd.read_csv(\"..\/input\/english_text.csv\")\nhinglish_text = pd.read_csv(\"..\/input\/hinglish_text.csv\")","0d15a172":"english_text.head()","42eafa71":"hinglish_text.head()","5f9515b8":"print(english_text.shape)\nprint(hinglish_text.shape)","af728d74":"hinglish_text.isna().sum()","5427ea3c":"def clean_column(dataframe, column_to_clean, new_col):\n    df_copy = dataframe.copy()\n    df_copy['copied_column'] = df_copy[column_to_clean]\n    df_copy['copied_column'] = df_copy['copied_column'].str.lower()\n    cleaned_column = []\n    for label in df_copy.index:\n        row = df_copy.loc[label, :]['copied_column']\n        clean = [x for x in row.split() if x not in string.punctuation]\n        clean = [x for x in clean if x not in nltk_stopwords]\n        clean = [x for x in clean if x not in string.digits]\n        clean = [x for x in clean if x not in remove_punctuation]\n        clean = [x for x in clean if len(x) != 1]\n        clean = \" \".join(clean)\n        clean = clean.strip()\n        cleaned_column.append(clean)\n    df_copy[new_col] = cleaned_column\n    del df_copy['copied_column']\n    return df_copy","ca71455b":"english_text_copy = clean_column(english_text, 'text', 'clean_text')\nenglish_text_copy.drop(['text'], axis=1, inplace = True)","23848d5c":"english_text_copy","6ff68130":"hinglish_text_copy = clean_column(hinglish_text, 'text', 'clean_text')\nhinglish_text_copy.drop(['text'], axis=1, inplace = True)","b082af47":"hinglish_text_copy","99ad6c4f":"english_text_labels = np.zeros((english_text.shape[0],1), dtype=np.int16)\nhinglish_text_labels = np.ones((hinglish_text.shape[0],1), dtype=np.int16)","1cdf517a":"english_text_copy['labels'] = english_text_labels\nhinglish_text_copy['labels'] = hinglish_text_labels","88d7a238":"english_text_copy = english_text_copy.take(np.random.permutation(len(english_text_copy))[:4470])","8c085f4d":"english_text_copy.shape","1370982e":"copy_df = english_text_copy.append(hinglish_text_copy)","ec269c65":"copy_df","2a4bf408":"copy_df.drop(['ID'], axis=1, inplace=True)","f2a2e07b":"copy_df","6edc299a":"X_train, X_test, y_train, y_test = train_test_split(copy_df['clean_text'], copy_df['labels'], test_size=0.33, random_state=6001)","92cbec49":"y_train","63c164ce":"from sklearn.feature_extraction.text import TfidfVectorizer","8fed7eb6":"vectorizer = TfidfVectorizer(min_df=2, ngram_range=(1, 2), max_features= 10000,strip_accents='unicode', norm='l2')","cc88a7e7":"x_train = vectorizer.fit_transform(X_train).todense()\nx_test = vectorizer.transform(X_test).todense()","312e7813":"np.random.seed(1337)\nbatch_size = 64\nnb_epochs = 20","b4347c97":"y_test","560c62a1":"Y_train = np_utils.to_categorical(y_train, 2)\nY_test = np_utils.to_categorical(y_test, 2)","c6761070":"Y_test","49b0ba85":"import gensim \nfrom gensim.models import Word2Vec ","86fdc450":"model = Sequential()\nmodel.add(Dense(1000,input_shape= (10000,)))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(500))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(50))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2))\nmodel.add(Activation('sigmoid'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\nprint (model.summary())","87b0ba51":"y_train.shape","425bf6a2":"model.fit(x_train, Y_train, batch_size=batch_size, epochs=20,verbose=1)","53800f23":"y_train_pred = model.predict_classes(x_train,batch_size=batch_size)\ny_test_pred = model.predict_classes(x_test,batch_size=batch_size)","8f2ee291":"y_train_pred","37818748":"# Validation accuracy\naccuracy_score(y_train, y_train_pred)*100","a2ddfa51":"# Testing accuracy\naccuracy_score(y_test, y_test_pred)*100","72e8bb6c":"**Taking equal rows as hinglish Datasets So that the data will be same for both the classes**"}}