{"cell_type":{"b02aa13a":"code","8b778b3f":"code","ef00d6b4":"code","3b8aecb3":"code","192040ee":"code","3e15659d":"code","8d6ad7c7":"code","af372924":"code","2580716c":"code","2678d965":"code","f1cccb4f":"code","7d363c72":"code","ca59e09b":"code","a620cb87":"code","5d9bdfe1":"markdown","b9fd68a4":"markdown","1d95e5d3":"markdown","db2f7c3a":"markdown","4429987e":"markdown","ffb60b77":"markdown","2fc34e78":"markdown","96c2c3b0":"markdown","f517837f":"markdown","2c6e5925":"markdown","a41f3da4":"markdown","555ffa53":"markdown","e060bc54":"markdown","85e4f548":"markdown","10438100":"markdown","6dc5350b":"markdown"},"source":{"b02aa13a":"import numpy as np \nimport pandas as pd \nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.image as mpimg\nimport plotly.express as px\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator \nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2","8b778b3f":"INPUT_SHAPE = (150,150,3)\nBATCH_SIZE = 60\ntest_path='..\/input\/intel-image-classification\/seg_test\/seg_test\/'\ntrain_path='..\/input\/intel-image-classification\/seg_train\/seg_train\/'","ef00d6b4":"def visualize_data(folder):\n    c=1\n    directory=os.listdir(folder)\n    plt.figure(figsize=(28,20))\n    for each in directory:\n        currentFolder=folder+ \"\/\" +each\n        for i, file in enumerate(os.listdir(currentFolder)[0:4]):\n            full_path=currentFolder+\"\/\"+file\n            plt.subplot(3, 8, c)\n            img = mpimg.imread(full_path)\n            plt.imshow(img)\n            plt.title(each)\n            c+=1\n    plt.subplots_adjust(wspace=0.3, hspace=-0.1)\n    plt.show()\n    \nvisualize_data(test_path)","3b8aecb3":"def get_generator(_training_dir, _test_dir):\n    train_datagen = ImageDataGenerator(\n        rescale=1\/255.0, \n        featurewise_center=True,\n        featurewise_std_normalization=True, \n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        horizontal_flip=True,\n        shear_range=0.2,\n        fill_mode='nearest'\n    )\n    test_datagen = ImageDataGenerator(\n        rescale=1\/255.0\n    )\n    train_generator = train_datagen.flow_from_directory(\n        _training_dir,\n        shuffle=True,\n        target_size=(150,150),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical'\n    )\n    test_generator = test_datagen.flow_from_directory(\n        _test_dir,\n        shuffle=True,\n        target_size=(150,150),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical'\n    )\n    \n    return train_generator, test_generator","192040ee":"def plotter(history):\n    #summarize history for accuracy\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","3e15659d":"def get_defined_label(x):\n    label_dict = {0:'building', 1:'forest', 2:'glacier', 3:'mountain', 4:'sea', 5:'street'}\n    for key, value in label_dict:\n        if key == x:\n            return value","8d6ad7c7":"def get_initialized_model(INPUT_SHAPE):\n    base_model = InceptionResNetV2(\n        input_shape=INPUT_SHAPE,\n        weights='imagenet',\n        include_top=False,\n        pooling='avg'\n    )\n    base_model.trainable = False\n    \n    print('Base Model Ouput Shape = {}'.format(base_model.output_shape))\n    last_output = base_model.output\n    x = tf.keras.layers.Dropout(0.2)(last_output)\n    x = tf.keras.layers.Dense(units=128, activation='relu')(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    x = tf.keras.layers.Dense(units=128, activation='relu')(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    x = tf.keras.layers.Dense(units = 6, activation='softmax')(x)\n    \n    model = tf.keras.Model( base_model.input, x) \n\n    model.compile(\n        optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001, momentum=0.9, centered=True), \n        loss = ['categorical_crossentropy'], \n        metrics = ['accuracy']\n    )\n\n    model_callback = [tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss', \n        min_delta=0.001, \n        patience=5, \n        verbose=1,\n        mode='auto', \n        baseline=None, \n        restore_best_weights=True\n    ), tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.1,\n        patience=1,\n        min_delta=0.0000001,\n        verbose=1 \n    )]\n    \n    return model, model_callback","af372924":"train_generator, test_generator = get_generator(train_path, test_path)\nmodel, model_callbacks = get_initialized_model(INPUT_SHAPE)","2580716c":"history = model.fit_generator(train_generator, epochs=30, validation_data=test_generator, callbacks=[model_callbacks])","2678d965":"score = model.evaluate_generator(test_generator)\nplotter(history)\nprint('\\nScore [ {} ] '.format(dict(zip(model.metrics_names, score))))","f1cccb4f":"for layer in model.layers[-100:]:\n    layer.trainable=True\n\nfor i, layer in enumerate(model.layers):\n    print(i, layer.name, layer.trainable)","7d363c72":"model.compile(\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5), \n    loss = ['categorical_crossentropy'], \n    metrics = ['accuracy']\n)    \n\nmodel_callback_new = [tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', \n    min_delta=0.001, \n    patience=3, \n    verbose=1,\n    mode='auto', \n    baseline=None, \n    restore_best_weights=True\n), tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.1,\n    patience=1,\n    min_delta=0.00000001,\n    verbose=1 \n)]","ca59e09b":"#resetting the generators\ntrain_generator.reset()\ntest_generator.reset()\n\nhistory = model.fit_generator(\n    train_generator,\n    epochs=25,\n    steps_per_epoch=14034\/\/BATCH_SIZE,\n    validation_data=test_generator,\n    validation_steps=3000\/\/BATCH_SIZE,\n    callbacks=[model_callback_new]\n)","a620cb87":"score = model.evaluate_generator(test_generator)\nplotter(history)\nprint('\\nScore [ {} ] '.format(dict(zip(model.metrics_names, score))))","5d9bdfe1":"## *Fine-tuning the model to further improve the Accuracy* \n* The layers made non-trainable previously are now being altered. This alteration is limited to the last 100 layers, that are made **Trainable**. Furthermore, the layers made trainable are also enumerated specifically and displayed (select to un-hide the output).","b9fd68a4":"* Re-evaluating the score and plotting the accuracies and losses.","1d95e5d3":"## *Loading Data*","db2f7c3a":"## *Plot History*","4429987e":"* Recompiling with **Adam** optimizer on a relatively low learning rate of 0.00001, and adjusting the callbacks. ","ffb60b77":"*Score is displayed along with appropriate metrics*","2fc34e78":"# **Intel Image Classification - (InceptionResNetV2)**","96c2c3b0":"## *Image Augmentation*","f517837f":"*Callbacks and Generators are returned*","2c6e5925":"## *Assign Image Labels*","a41f3da4":"## *Importing Libraries*","555ffa53":"*Model is fitted and trained for a total of 65 epochs*","e060bc54":"* Resetting the generators and training for 25 epochs with the latest callbacks.","85e4f548":"------------------------------------------------------------------------------------------------------------------------------------","10438100":"## *Visualize Data*","6dc5350b":"## *Initialize Model*\n* **InceptionResNetV2** is used as a base-model and Feature Extractor, the output is passed through an average pooling layer onto the fully connected network. Initially the base-model parameters are kept **non-trainable**. Furthermore, Early-stopping and Learning-rate-reduction callbacks are added."}}