{"cell_type":{"6f78ee71":"code","e358f4a7":"code","d39ebec3":"code","ead54ddf":"code","5128d1e3":"code","d92b971c":"code","95953cbb":"code","c13caee0":"code","bc0e4b15":"code","cf1d8d81":"code","1a4064de":"code","78a19157":"code","d5eaf722":"code","69217168":"code","26f9b6cd":"code","387750b2":"markdown","a57a1c92":"markdown","aed2c007":"markdown"},"source":{"6f78ee71":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e358f4a7":"df=pd.read_csv('\/kaggle\/input\/flights-data\/flights.csv')\ndf.isnull().sum() # observe all nans \ndf.nunique() #unique values per col\ndf.drop('Unnamed: 0',axis=1, inplace=True)\ncols=df.columns\nprint(\"Time period:\", df.year.min(),\" to \",df.year.max(),\"\\n\", \n      df.head())","d39ebec3":"from sklearn.preprocessing import LabelEncoder\ncat_cols = [col for col in df.columns if df[col].dtype == \"object\"]\nlabel_encoder = LabelEncoder()\nfor col in set(cat_cols):\n    df[col]=df[col].astype('str')\n    df[col] = label_encoder.fit_transform(df[col])\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer()\nimputed = pd.DataFrame(imputer.fit_transform(df))\nimputed.columns=cols\nprint(imputed.head())","ead54ddf":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(imputed, test_size=0.2) ","5128d1e3":"y_train=train['arr_delay']\nX_train=train.drop(['arr_delay'], axis=1)\ny_test=test['arr_delay']\nX_test=test.drop(['arr_delay'], axis=1)","d92b971c":"from xgboost import XGBRegressor\nfrom sklearn.model_selection import cross_val_score\nmy_model = XGBRegressor(n_estimators=300,learning_rate=0.05, n_jobs=4)\nmy_model.fit(X_train, y_train, \n             early_stopping_rounds=5, \n             eval_set=[(X_test, y_test)],\n             verbose=False)\ncv_scores=cross_val_score(my_model, X_train, y_train,cv=5)\npr_arr_delay=my_model.predict(X_test)\nprint('mean cross-validation score:', cv_scores.mean())","95953cbb":"y_train_2=train['dep_delay']\nX_train_2=train.drop(['dep_delay'], axis=1)\ny_test_2=test['dep_delay']\nX_test_2=test.drop(['dep_delay'], axis=1)","c13caee0":"my_model.fit(X_train_2, y_train_2, \n             early_stopping_rounds=5, \n             eval_set=[(X_test_2, y_test_2)],\n             verbose=False)\ncv_scores_2 = cross_val_score(my_model, X_train_2, y_train_2,cv=5)\npr_dep_delay=my_model.predict(X_test_2)\nprint('mean cross-validation score:', cv_scores_2.mean())","bc0e4b15":"arr_delay=pd.DataFrame({\"Prediction\":pr_arr_delay, \"Test data\":y_test})\narr_delay.plot.kde(bw_method=3,figsize=(10,5))","cf1d8d81":"dep_delay=pd.DataFrame({\"Prediction\":pr_dep_delay, \"Test data\":y_test_2})\ndep_delay.plot.kde(bw_method=3,figsize=(10,5))","1a4064de":"a=[]\nb=[]\nfor i in range(len(imputed)):\n    if imputed.dep_delay[i]<0:\n        imputed.dep_delay[i]=imputed.dep_delay[i]%1\n        a.append(1)\n    else: \n        a.append(0)\nfor e in range(len(imputed)):\n    if imputed.arr_delay[e]<0:\n        imputed.arr_delay[e]=imputed.arr_delay[e]%1\n        b.append(1)\n    else: \n        b.append(0)\nimputed['negative value dep?']=a\nimputed['negative value arr?']=b","78a19157":"train_new, test_new = train_test_split(imputed, test_size=0.2) ","d5eaf722":"y_train_new=train_new['arr_delay']\nX_train_new=train_new.drop(['arr_delay'], axis=1)\ny_test_new=test_new['arr_delay']\nX_test_new=test_new.drop(['arr_delay'], axis=1)","69217168":"my_model.fit(X_train_new, y_train_new, \n             early_stopping_rounds=5, \n             eval_set=[(X_test_new, y_test_new)],\n             verbose=False)\ncv_scores_2 = cross_val_score(my_model, X_train_new, y_train_new,cv=5)\npr_arr_delay_new=my_model.predict(X_test_new)\nprint('mean cross-validation score:', cv_scores_2.mean())","26f9b6cd":"arr_delay=pd.DataFrame({\"Prediction\":pr_arr_delay_new, \"Test data\":y_test_new})\narr_delay.plot.kde(bw_method=3,figsize=(10,5))","387750b2":"# Since predictions tend to 0 more than test data I decide to get mod of arrival and departures delays and mention sign (\"-\" or \"+\") of their values in additional columns ","a57a1c92":"# In this kernel I would like to share my predictions of arrivals and departures delays","aed2c007":"# There are couple KDE plots"}}