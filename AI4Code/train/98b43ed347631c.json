{"cell_type":{"fc35ca0d":"code","7c5968f8":"code","f75ac330":"code","31b69c24":"code","43cddf95":"code","2b180600":"code","8bd93282":"code","15fd758c":"code","a2b5aee0":"code","15bb1e41":"code","92f68729":"code","c9b68ee1":"code","aeda43e2":"code","dc6a9b4b":"code","34263535":"code","d6766d10":"code","1fca417c":"code","338e654c":"code","172b3de6":"markdown","28ceb5f7":"markdown","560bf29c":"markdown","ba46dcec":"markdown","abc8dcb5":"markdown","6557d1ae":"markdown","459afb2c":"markdown","66782632":"markdown","fc0dd533":"markdown","3f3f81cc":"markdown","6533a1f0":"markdown"},"source":{"fc35ca0d":"Participant_name = 'test' # inside the apostrophes e.g. Zel","7c5968f8":"label_pathway1 = '..\/input\/testing\/train1_label.tif'  # after the slash e.g. ..\/awesome\/your_work1.tif","f75ac330":"label_pathway2 = '..\/input\/testing\/train2_label.tif'  # after the slash e.g. ..\/awesome\/your_work2.tif","31b69c24":"hyperparameters = {\n    # network structural parameters\n    'number_convolution_per_layer': 64,  \n    'convolution_kernel_size': 3,\n    'number_layer': 3,\n    'dropout': 0.1,\n    # experimental parameters\n    'batch_size': 200,\n    'number_epoch': 1, \n    'stride': 80,  # gap of sampling\n    'width_sampling': 80,  #for window of sampling\n}","43cddf95":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport multiprocessing as mp\nimport cv2\nfrom skimage.filters import hessian\nfrom itertools import product, repeat\nfrom sklearn.ensemble import RandomForestClassifier\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Conv2D, Conv2DTranspose, concatenate, UpSampling2D, \\\n    MaxPooling2D, BatchNormalization, Dropout, Input, Reshape, Flatten, Softmax","2b180600":"def shuffle(X, y):\n    idx = np.random.permutation(X.shape[0])\n    return X[idx], y[idx]\n\ndef patching(X, patch_size=256, stride=5):\n    p_h = (X.shape[0] - patch_size) \/\/ stride + 1\n    p_w = (X.shape[1] - patch_size) \/\/ stride + 1\n\n    # stride the tensor\n    _strides = tuple([i * stride for i in X.strides]) + tuple(X.strides)\n    X = np.lib.stride_tricks.as_strided(X, shape=(p_h, p_w, patch_size, patch_size), strides=_strides)\\\n        .reshape((-1, patch_size, patch_size, 1))\n    return X\n\ndef reconstruct_cnn(y_pred, image_size=None, stride=None):\n    i_h, i_w = image_size[:2]  #e.g. (a, b)\n    p_h, p_w = y_pred.shape[1:3]  #e.g. (x, h, w, 1)\n    img = np.zeros((i_h, i_w))\n\n    # compute the dimensions of the patches array\n    n_h = (i_h - p_h) \/\/ stride + 1\n    n_w = (i_w - p_w) \/\/ stride + 1\n\n    for p, (i, j) in zip(y_pred, product(range(n_h), range(n_w))):\n        img[i * stride:i * stride + p_h, j * stride:j * stride + p_w] += p\n\n    for i in range(i_h):\n        for j in range(i_w):\n            img[i, j] \/= float(min(i + stride, p_h, i_h - i) *\n                               min(j + stride, p_w, i_w - j))\n    return img\n\n\ndef _minmaxscalar(ndarray, dtype=np.float32):\n    scaled = np.array((ndarray - np.min(ndarray)) \/ (np.max(ndarray) - np.min(ndarray)), dtype=dtype)\n    return scaled\n\n\ndef submit(y_pred, idx, out_path):\n    assert isinstance(y_pred, np.ndarray), 'y_pred should be a numpy array'\n    assert isinstance(out_path, str), 'out_path should be a string'\n    csv = {\n        'id': idx,\n        'prediction': y_pred.flatten().astype(int),\n    }\n    pd.DataFrame(csv).to_csv(out_path, index=False, header=True)","8bd93282":"def convolutionalNeuralNetwork(params):\n    inputs = Input((params['width_sampling'], params['width_sampling'], 1))\n    pools = []\n    \n    # encoder\n    for i in range(params['number_layer']):\n        if i == 0:\n            x = inputs\n        x = Conv2D(params['number_convolution_per_layer'],\n                   (params['convolution_kernel_size'], params['convolution_kernel_size']),\n                   activation='relu', padding='same')(x)\n        x = BatchNormalization()(x)\n        x = Conv2D(params['number_convolution_per_layer'], \n                   (params['convolution_kernel_size'], params['convolution_kernel_size']), \n                   activation='relu', padding='same')(x)\n        x = BatchNormalization()(x)\n        pools.append(x)\n        x = MaxPooling2D(pool_size=(2, 2))(x)\n        \n    x = Conv2D(params['number_convolution_per_layer'] * 4, \n               (params['convolution_kernel_size'], params['convolution_kernel_size']), \n               activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(params['number_convolution_per_layer'] * 4, \n               (params['convolution_kernel_size'], params['convolution_kernel_size']), \n               activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(1, \n               (params['convolution_kernel_size'], params['convolution_kernel_size']),\n               activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n\n    # bottom\n    x = Flatten()(x)\n    for i in range(3):\n        x = Dense(params['width_sampling'] * params['width_sampling'] \/\/ 64, activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(params['dropout'])(x)\n    x = Reshape((int(params['width_sampling'] \/\/ 8), int(params['width_sampling'] \/\/ 8), 1))(x)\n\n    # decoder\n    for i in range(params['number_layer']):\n        x = Conv2DTranspose(params['number_convolution_per_layer'], \n                            (params['convolution_kernel_size'], params['convolution_kernel_size']), \n                            activation='relu', padding='same')(x)\n        x = BatchNormalization()(x)\n        x = Conv2DTranspose(params['number_convolution_per_layer'], \n                            (params['convolution_kernel_size'], params['convolution_kernel_size']), \n                            activation='relu', padding='same')(x)\n        x = BatchNormalization()(x)\n        x = concatenate([UpSampling2D(size=(2, 2))(x), pools[-i-1]], axis=3)\n\n    x = Conv2DTranspose(params['number_convolution_per_layer'], \n                        (params['convolution_kernel_size'], params['convolution_kernel_size']), \n                        activation='relu', padding='same')(x)\n    x = Conv2DTranspose(params['number_convolution_per_layer'], \n                        (params['convolution_kernel_size'], params['convolution_kernel_size']), \n                        activation='relu', padding='same')(x)\n\n    x = Conv2DTranspose(1, (3, 3), activation='relu', padding='same')(x)\n\n    mdl = Model(inputs=inputs, outputs=x)\n    mdl.compile(loss='mse', optimizer='Adam')\n    return mdl","15fd758c":"raw1 = np.asarray(Image.open('..\/input\/nanoperando-amiens-2019\/train1.tif'))\nraw2 = np.asarray(Image.open('..\/input\/nanoperando-amiens-2019\/train2.tif'))\nto_predict1 = np.asarray(Image.open('..\/input\/nanoperando-amiens-2019\/test1.tif'))\nto_predict2 = np.asarray(Image.open('..\/input\/nanoperando-amiens-2019\/test2.tif'))\nlabel1 = np.asarray(Image.open(label_pathway1))\nlabel2 = np.asarray(Image.open(label_pathway2))\nidx = np.asarray(np.loadtxt('..\/input\/nanoperando-amiens-2019\/idx.csv')).astype(int)","a2b5aee0":"X_train = patching(raw1, hyperparameters['width_sampling'], hyperparameters['stride'])\nX_train = np.concatenate([X_train, patching(raw2, hyperparameters['width_sampling'], hyperparameters['stride'])], axis=0)\ny_train = patching(label1, hyperparameters['width_sampling'], hyperparameters['stride'])\ny_train = np.concatenate([y_train, patching(label2, hyperparameters['width_sampling'], hyperparameters['stride'])], axis=0)\nX_train, y_train = shuffle(X_train, y_train)","15bb1e41":"model = convolutionalNeuralNetwork(hyperparameters)","92f68729":"# train\nmodel.fit(X_train, y_train, epochs=hyperparameters['number_epoch'], batch_size=hyperparameters['batch_size'])\ndel X_train, y_train","c9b68ee1":"X_test1 = patching(to_predict1, hyperparameters['width_sampling'], hyperparameters['stride'])\nX_test2 = patching(to_predict2, hyperparameters['width_sampling'], hyperparameters['stride'])\ny_pred1 = model.predict(X_test1)\ny_pred1 = reconstruct_cnn(np.squeeze(y_pred1), image_size=to_predict1.shape, stride=hyperparameters['stride'])\ny_pred2 = model.predict(X_test2)\ny_pred2 = reconstruct_cnn(np.squeeze(y_pred2), image_size=to_predict2.shape, stride=hyperparameters['stride'])\ntotal = np.concatenate([y_pred1.flatten(), y_pred2.flatten()], axis=0)\nprint('pred1 shape:{}'.format(y_pred1.shape), '\\npred2 shape:{}'.format(y_pred2.shape),\n      '\\nidx shape:{}'.format(idx.shape))\nsubmit(total.flatten()[idx], idx, '{}.csv'.format(Participant_name))","aeda43e2":"from shutil import copyfile\ncopyfile(label_pathway1, '\/kaggle\/working\/{}1.tif'.format(Participant_name))\ncopyfile(label_pathway2, '\/kaggle\/working\/{}2.tif'.format(Participant_name))","dc6a9b4b":"import matplotlib.pyplot as plt\n%matplotlib inline","34263535":"plt.figure(figsize=(50, 50))\nplt.imshow(y_pred1)","d6766d10":"plt.figure(figsize=(50, 50))\nplt.imshow(y_pred2)","1fca417c":"## For the debug","338e654c":"print('test1.shape: {}'.format(to_predict1.shape))\nprint('test2.shape: {}'.format(to_predict2.shape))\nprint('y_pred1.shape: {}'.format(y_pred1.shape))\nprint('y_pred2.shape: {}'.format(y_pred2.shape))","172b3de6":"## Prediction","28ceb5f7":"## Define some useful functions for data preparation and this competition","560bf29c":"## Please enter your name or nick name here","ba46dcec":"## Import libraries and define tool functions","abc8dcb5":"## Play with some parameters","6557d1ae":" ## Prepare data","459afb2c":"## Enter your segmented file pathway here \n### (point them to input\/SOMETHING\/SOMETHING.tif)","66782632":"## Begin training","fc0dd533":"## Submit also other data\/labels","3f3f81cc":"## Plot the prediction","6533a1f0":"## Here to define the Convolutional Neural Network"}}