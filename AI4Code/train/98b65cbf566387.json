{"cell_type":{"4d6cd7b3":"code","b72fae70":"code","ecc084ed":"code","ddb3babf":"code","6085d07b":"code","70506852":"code","07cb153c":"code","94e325dc":"code","a996dd94":"code","5c7f9b93":"code","4a21c3da":"code","131c5951":"code","a3188ed1":"code","d3216346":"code","c2016b35":"code","84210166":"code","c5b84cf1":"code","be321ab6":"code","7b78d3b0":"code","fac2a3f7":"code","ccbad7c1":"code","ad3b3e58":"code","210391a1":"code","627d9dc0":"code","f9801013":"code","b60bffac":"code","a008e5cc":"code","022d38d3":"code","d9ffb646":"code","5c1cfc13":"code","23348956":"code","93cfdf02":"code","77dc7f1f":"markdown","256e45ab":"markdown","6fcfb7eb":"markdown","2fbd1485":"markdown"},"source":{"4d6cd7b3":"!pip install efficientnet_pytorch","b72fae70":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport torch\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nimport torch.nn as nn\nfrom torch.utils.tensorboard import SummaryWriter\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom torchvision import models, transforms\nfrom efficientnet_pytorch import EfficientNet\nimport copy\nimport tqdm\nimport PIL\nfrom PIL import Image\nimport zipfile\n\nfrom sklearn.metrics import confusion_matrix\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ecc084ed":"train_data_path = \"..\/input\/dogs-vs-cats-redux-kernels-edition\/train.zip\"\ntest_data_path = \"..\/input\/dogs-vs-cats-redux-kernels-edition\/test.zip\"\n\nwith zipfile.ZipFile(train_data_path, 'r') as zip_ref:\n    zip_ref.extractall(\".\")\n    \nwith zipfile.ZipFile(test_data_path, 'r') as zip_ref:\n    zip_ref.extractall(\".\")","ddb3babf":"import glob\n\ntrain_dir = \".\/train\"\ntest_dir = \".\/test\"\ntrain_list = glob.glob(os.path.join(train_dir,'*.jpg'))\ntest_list = glob.glob(os.path.join(test_dir, '*.jpg'))","6085d07b":"from sklearn.model_selection import train_test_split\ntrain_list, val_list = train_test_split(train_list, test_size=0.2)","70506852":"mean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\n\ntrain_transforms =  transforms.Compose([\n        transforms.Resize((448, 448)),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std),\n    ])\n\nval_transforms = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std),\n    ])\n\n\ntest_transforms = transforms.Compose([   \n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std),\n    ])","07cb153c":"class dataset(torch.utils.data.Dataset):\n    def __init__(self,file_list,transform=None):\n        self.file_list = file_list\n        self.transform = transform\n        \n    def __len__(self):\n        self.filelength = len(self.file_list)\n        return self.filelength\n    \n    #load an one of images\n    def __getitem__(self,idx):\n        img_path = self.file_list[idx]\n        img = Image.open(img_path)\n        img_transformed = self.transform(img)\n        \n        label = img_path.split('\/')[-1].split('.')[0]\n        if label == 'dog':\n            label=1\n        elif label == 'cat':\n            label=0\n            \n        return img_transformed,label","94e325dc":"train_data = dataset(train_list, transform=train_transforms)\ntest_data = dataset(test_list, transform=test_transforms)\nval_data = dataset(val_list, transform=test_transforms)","a996dd94":"train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=32, shuffle=True )\ntest_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size=32, shuffle=True)\nval_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size=32, shuffle=True)","5c7f9b93":"# samples, labels = iter(train_loader).next()\n# fig = plt.figure(figsize=(24, 16))\n# fig.tight_layout()\n# ad = {0:'cat', 1:'dog'}\n# for num, sample in enumerate(samples[:24]):\n#     plt.subplot(4,6,num+1)\n#     plt.title(ad[labels[num].item()])\n#     plt.axis('off')\n#     sample = sample.cpu().numpy()\n#     plt.imshow(np.transpose(sample, (1,2,0)))","4a21c3da":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\ntorch.manual_seed(42)\nif device =='cuda':\n    torch.cuda.manual_seed_all(42)","131c5951":"# class Cnn(nn.Module):\n#     def __init__(self):\n#         super(Cnn,self).__init__()\n        \n#         self.layer1 = nn.Sequential(\n#             nn.Conv2d(3,16,kernel_size=3, padding=0,stride=2),\n#             nn.BatchNorm2d(16),\n#             nn.ReLU(),\n#             nn.MaxPool2d(2)\n#         )\n        \n#         self.layer2 = nn.Sequential(\n#             nn.Conv2d(16,32, kernel_size=3, padding=0, stride=2),\n#             nn.BatchNorm2d(32),\n#             nn.ReLU(),\n#             nn.MaxPool2d(2)\n#             )\n        \n#         self.layer3 = nn.Sequential(\n#             nn.Conv2d(32,64, kernel_size=3, padding=0, stride=2),\n#             nn.BatchNorm2d(64),\n#             nn.ReLU(),\n#             nn.MaxPool2d(2)\n#         )\n        \n        \n#         self.fc1 = nn.Linear(3*3*64,10)\n#         self.dropout = nn.Dropout(0.5)\n#         self.fc2 = nn.Linear(10,2)\n#         self.relu = nn.ReLU()\n        \n        \n#     def forward(self,x):\n#         out = self.layer1(x)\n#         out = self.layer2(out)\n#         out = self.layer3(out)\n#         out = out.view(out.size(0),-1)\n#         out = self.relu(self.fc1(out))\n#         out = self.fc2(out)\n#         return out","a3188ed1":"# model = Cnn().to(device)\n# model.train()","d3216346":"# optimizer = optim.Adam(params = model.parameters(),lr=0.001)\n# criterion = nn.CrossEntropyLoss()","c2016b35":"model = models.vgg19(pretrained=True)\n# model","84210166":"model.classifier[6] = nn.Linear(in_features=4096, out_features=1)\n\nupdate_params = []\nparams_names = ['classifier.6.weight', 'classifier.6.bias']\n\nfor name, param in model.named_parameters():\n    if name in params_names:\n        param.requires_grad = True\n        update_params.append(param)\n    else:\n        param.requires_grad = False\n        \nmodel = model.to(device)\nsigmo = nn.Sigmoid()","c5b84cf1":"# criterion = nn.CrossEntropyLoss()\n# criterion = nn.BCEWithLogitsLoss(reduction = 'mean').to(device)\ncriterion = nn.BCELoss(reduction = 'mean').to(device)\noptimizer = optim.SGD(params=update_params, lr=0.001, momentum=0.9)","be321ab6":"# model = models.inception_v3(pretrained=True, aux_logits=False)\n# model","7b78d3b0":"# model = models.inception_v3(pretrained=True, aux_logits=False)\n# model.fc = nn.Linear(in_features=2048, out_features=2)\n\n# update_params = []\n# params_names = ['fc.weight', 'fc.bias']\n\n# for name, param in model.named_parameters():\n#     if name in params_names:\n#         param.requires_grad = True\n#         update_params.append(param)\n#     else:\n#         param.requires_grad = False\n        \n# model = model.to(device)","fac2a3f7":"# criterion = nn.CrossEntropyLoss()\n# optimizer = optim.SGD(params=update_params, lr=0.001, momentum=0.9)","ccbad7c1":"# model = EfficientNet.from_pretrained(\"efficientnet-b5\")\n# model","ad3b3e58":"# model._fc = nn.Linear(in_features=2048, out_features=2)\n# update_params = []\n# params_names = ['_fc.weight', '_fc.bias']\n\n# for name, param in model.named_parameters():\n#     if name in params_names:\n#         param.requires_grad = True\n#         update_params.append(param)\n#     else:\n#         param.requires_grad = False\n        \n# model = model.to(device)","210391a1":"# criterion = nn.CrossEntropyLoss()\n# optimizer = optim.SGD(params=update_params, lr=0.001, momentum=0.9)","627d9dc0":"epochs = 6\n\ntrain_loss_list = []\ntrain_acc_list = []\nval_loss_list = []\nval_acc_list = []\n\nbest_loss = 1e10\nweights_path = \".\"\n\nfor epoch in range(epochs):\n    epoch_loss = 0\n    epoch_accuracy = 0\n#     print(\"#batches \", len(train_loader))\n    for batch_idx, (data, label) in enumerate(train_loader):\n#         if (batch_idx+1) % 100 == 0:\n#             print(batch_idx+1)\n        data = data.to(device)\n        label = label.to(device)\n        \n        output = sigmo(model(data))\n        loss = criterion(output, label.view(-1, 1).float())\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n#         acc = ((output.argmax(dim=1) == label).float().mean())\n        acc = (((torch.flatten(output) > 0.5).int() == label).float().mean())\n        epoch_accuracy += acc\/len(train_loader)\n        epoch_loss += loss\/len(train_loader)\n        \n    print('Epoch : {}, train accuracy : {}, train loss : {}'.format(epoch+1, epoch_accuracy,epoch_loss))\n    train_loss_list.append(epoch_loss)\n    train_acc_list.append(epoch_accuracy)\n    \n    with torch.no_grad():\n        epoch_val_accuracy=0\n        epoch_val_loss =0\n        for data, label in val_loader:\n            data = data.to(device)\n            label = label.to(device)\n            \n            val_output = sigmo(model(data))\n            val_loss = criterion(val_output,label.view(-1, 1).float())\n            \n            \n#             acc = ((val_output.argmax(dim=1) == label).float().mean())\n            acc = (((torch.flatten(val_output) > 0.5).int() == label).float().mean())\n            epoch_val_accuracy += acc\/ len(val_loader)\n            epoch_val_loss += val_loss\/ len(val_loader)\n            \n        print('Epoch : {}, val_accuracy : {}, val_loss : {}'.format(epoch+1, epoch_val_accuracy,epoch_val_loss))\n        val_loss_list.append(epoch_val_loss)\n        val_acc_list.append(epoch_val_accuracy)\n        if epoch_val_loss < best_loss:\n            torch.save(model.state_dict(), os.path.join(weights_path, \"model.pt\"),)","f9801013":"plt.clf()\nx_axis = list(range(epochs))\nplt.plot(x_axis, train_loss_list, label=\"Train\")\nplt.plot(x_axis, val_loss_list, label=\"Validation\")\nplt.xlabel(\"#epoch\")\nplt.ylabel('loss')\nplt.title('Loss')\nplt.legend()\nplt.show()\n\nplt.clf()\nx_axis = list(range(epochs))\nplt.plot(x_axis, train_acc_list, label=\"Train\")\nplt.plot(x_axis, val_acc_list, label=\"Validation\")\nplt.xlabel(\"#epoch\")\nplt.ylabel('Accuracy')\nplt.title('accuracy')\nplt.legend()\nplt.show()","b60bffac":"predictions = []\ntrue_labels = []\nwrong_answers = []\nepoch_val_loss = 0\nepoch_val_accuracy = 0\nfor data, label in val_loader:\n    data = data.to(device)\n    label = label.to(device)\n\n    val_output = sigmo(model(data))\n    val_output = torch.flatten(val_output)\n    for i in range(len(val_output)):\n        predictions.append((val_output[i] > 0.5).int().item())\n        true_labels.append(label[i].item())\n        if predictions[-1] != true_labels[-1]:\n            wrong_answers.append((data[i], predictions[-1]))","a008e5cc":"class UnNormalize(object):\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n\n    def __call__(self, tensor):\n        for t, m, s in zip(tensor, self.mean, self.std):\n            t.mul_(s).add_(m)\n            # The normalize code -> t.sub_(m).div_(s)\n        return tensor","022d38d3":"print(true_labels[:20])\nprint(predictions[:20])\nunorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n\nfig = plt.figure(figsize=(24, 16))\nfig.tight_layout()\nad = {0:'cat', 1:'dog'}\nfor num, (sample, label) in enumerate(wrong_answers[:36]):\n    plt.subplot(6,6,num+1)\n    plt.title(ad[label])\n    plt.axis('off')\n    \n    sample = unorm(sample)\n    sample = sample.detach().cpu().numpy()\n    plt.imshow(np.transpose(sample, (1,2,0)))","d9ffb646":"conf_matrix = confusion_matrix(true_labels, predictions)\n\nfig, ax = plt.subplots(figsize=(7.5, 7.5))\nax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\nfor i in range(conf_matrix.shape[0]):\n    for j in range(conf_matrix.shape[1]):\n        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n \nplt.xlabel('Predictions', fontsize=18)\nplt.ylabel('Actuals', fontsize=18)\nplt.title('Confusion Matrix', fontsize=18)\nplt.show()","5c1cfc13":"model.load_state_dict(torch.load(weights_path + \"\/model.pt\", map_location=device))\ndog_probs = []\nmodel.eval()\nwith torch.no_grad():\n    for data, fileid in test_loader:\n        data = data.to(device)\n        preds = sigmo(model(data))\n#         preds_list = F.softmax(preds, dim=1)[:, 1].tolist()\n#         preds_list = (torch.flatten(preds) > 0.5).detach().float().cpu() * 0.97 + 0.01\n        preds_list = torch.flatten(preds).detach().cpu().numpy()\n        dog_probs += list(zip(list(fileid), preds_list))","23348956":"dog_probs.sort(key = lambda x : int(x[0]))\nidx = list(map(lambda x: x[0],dog_probs))\nprob = list(map(lambda x: x[1],dog_probs))\nsubmission = pd.DataFrame({'id':idx,'label':prob})\nsubmission","93cfdf02":"submission.to_csv('last.csv',index=False)","77dc7f1f":"# **InceptionV3**","256e45ab":"# **EffNet**","6fcfb7eb":"# **VGG16\/19**","2fbd1485":"# **CNN**"}}