{"cell_type":{"d1acb283":"code","22d12cc9":"code","ab5be364":"code","67052072":"code","f5ca0550":"code","72d37859":"code","fc515098":"code","9ce9c949":"code","2d32f1bd":"code","9a8d1e3c":"code","20a5e8b0":"code","d5a64201":"code","7ddb7b7f":"code","c0864754":"code","af183bd9":"code","b6978355":"code","8489a53f":"code","61a37157":"code","bb11d855":"markdown","fcce5cef":"markdown","2d66deab":"markdown","a04f951b":"markdown","95cf2ad4":"markdown","cb2880a0":"markdown"},"source":{"d1acb283":"import tensorflow as tf\nLIMIT = 1\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    tf.config.experimental.set_virtual_device_configuration(\n        gpus[0],\n        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 1024 * LIMIT)])\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\n    print('then RAPIDS can use %iGB GPU RAM'%(16 - LIMIT))\n  except RuntimeError as e:\n    print(e)\nelse:\n    print(\"GPU is not running\")","22d12cc9":"import numpy as np\nimport pandas as pd\ndf = pd.read_csv(\"..\/input\/shopee-product-matching\/train.csv\")\nprint(df.shape)\ndf.head()","ab5be364":"DEBUG = False\nif DEBUG:\n    df = df.sample(n = 2000).reset_index(drop = True)\nprint(df.shape)","67052072":"from sklearn.model_selection import GroupKFold\ngroups = df[\"label_group\"].values\ngkf = GroupKFold(n_splits = 5)\nfor train_idx, valid_idx in gkf.split(df, groups, groups):\n    train = df.iloc[train_idx, :].copy()\n    valid = df.iloc[valid_idx, :].copy()\nprint(train.shape, valid.shape)","f5ca0550":"train","72d37859":"import matplotlib.pyplot as plt\nplt.style.use(\"seaborn-white\")\nimport tensorflow as tf\n\ndef train_preprocess(path, _):\n    path = \"..\/input\/shopee-product-matching\/train_images\" + \"\/\" + path\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image, channels = 3)\n    image = tf.image.resize(image, [256, 256])\n    image = tf.cast(image, tf.float32) \/ 255.0\n    return image, image\n\ntrain_ds = tf.data.Dataset.from_tensor_slices((train[\"image\"].values, train[\"label_group\"].values))\nvalid_ds = tf.data.Dataset.from_tensor_slices((valid[\"image\"].values, valid[\"label_group\"].values))\ntrain_ds = train_ds.map(train_preprocess)\nvalid_ds = valid_ds.map(train_preprocess)","fc515098":"image, _ = next(iter(train_ds))\nplt.imshow(image)\nplt.show()\nprint(image.shape)","9ce9c949":"image, _ = next(iter(valid_ds))\nplt.imshow(image)\nplt.show()\nprint(image.shape)","2d32f1bd":"train_ds = train_ds.batch(64).prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\nvalid_ds = valid_ds.batch(64 * 2)","9a8d1e3c":"import tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\n\ndef autoencoder(input_shape):\n    inputs = L.Input(shape = input_shape)\n    encoded = L.Conv2D(filters = 16, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(inputs)\n    encoded = L.BatchNormalization()(encoded)\n    encoded = L.MaxPooling2D(pool_size = (2, 2), padding = \"same\")(encoded)\n    encoded = L.Conv2D(filters = 32, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(encoded)\n    encoded = L.BatchNormalization()(encoded)\n    encoded = L.MaxPooling2D(pool_size = (2, 2), padding = \"same\")(encoded)\n    encoded = L.Conv2D(filters = 64, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(encoded)\n    encoded = L.BatchNormalization()(encoded)\n    encoded = L.MaxPooling2D(pool_size = (2, 2), padding = \"same\")(encoded)\n    \"\"\"\n    encoded = L.Conv2D(filters = 64, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(encoded)\n    encoded = L.BatchNormalization()(encoded)\n    encoded = L.MaxPooling2D(pool_size = (2, 2), padding = \"same\")(encoded)\n    encoded = L.Conv2D(filters = 64, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(encoded)\n    encoded = L.BatchNormalization()(encoded)\n    encoded = L.MaxPooling2D(pool_size = (2, 2), padding = \"same\")(encoded)\n    encoded = L.Conv2D(filters = 128, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(encoded)\n    encoded = L.BatchNormalization()(encoded)\n    encoded = L.MaxPooling2D(pool_size = (2, 2), padding = \"same\")(encoded)\n    \"\"\"\n\n#    features = encoded\n    \n    \"\"\"\n    decoded = L.Conv2D(filters = 128, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(encoded)\n    decoded = L.UpSampling2D(size = (2, 2))(decoded)\n    decoded = L.Conv2D(filters = 64, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(decoded)\n    decoded = L.UpSampling2D(size = (2, 2))(decoded)\n    decoded = L.Conv2D(filters = 64, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(decoded)\n    decoded = L.UpSampling2D(size = (2, 2))(decoded)\n    \"\"\"\n    decoded = L.Conv2D(filters = 64, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(encoded)\n    decoded = L.UpSampling2D(size = (2, 2))(decoded)\n    decoded = L.Conv2D(filters = 32, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(decoded)\n    decoded = L.UpSampling2D(size = (2, 2))(decoded)\n    decoded = L.Conv2D(filters = 16, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(decoded)\n    decoded = L.UpSampling2D(size = (2, 2))(decoded)\n    decoded = L.Conv2D(filters = 3, kernel_size = (3, 3), padding = \"same\", activation = \"sigmoid\")(decoded)\n    \n    encoder = M.Model(inputs = inputs, outputs = encoded)\n    autoencoder = M.Model(inputs = inputs, outputs = decoded)\n    autoencoder.compile(optimizer = \"Adam\", loss = \"binary_crossentropy\")\n    return autoencoder, encoder\n\ntf.keras.backend.clear_session()\nautoencoder, encoder = autoencoder((256, 256, 3))\nautoencoder.summary()","20a5e8b0":"TRAINING = False\n\nif TRAINING:\n    history = autoencoder.fit(\n        train_ds, validation_data = valid_ds, epochs = 1,\n        callbacks = [\n            tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 3, mode = \"min\"),\n            tf.keras.callbacks.ModelCheckpoint(filepath = \"autoencoder.h5\", monitor = \"val_loss\", mode = \"min\", save_best_only = True, save_weights_only = True)\n        ]\n    )\nelse:\n    autoencoder.load_weights(\"..\/input\/shoppee-autoencoder0324\/autoencoder.h5\")","d5a64201":"image = next(iter(valid_ds))[0][0]\nplt.imshow(image)\nplt.show()","7ddb7b7f":"plt.imshow(autoencoder.predict(next(iter(valid_ds))[0])[0])\nplt.show()","c0864754":"from tqdm.notebook import tqdm, trange\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    import cuml\n    from cuml.neighbors import NearestNeighbors\nelse:\n    from sklearn.neighbors import NearestNeighbors\nimport gc","af183bd9":"CV = True\n\ntest = pd.read_csv(\"..\/input\/shopee-product-matching\/test.csv\")\nif test.shape[0] > 3:\n    CV = False\n\nif CV:\n    test = valid.copy()\n    DIR = \"..\/input\/shopee-product-matching\/train_images\"\nelse:\n    DIR = \"..\/input\/shopee-product-matching\/test_images\"\nprint(test.shape, DIR)","b6978355":"CHUNK = 1024\nCHUNK_SIZE = test.shape[0] \/\/ CHUNK\nif test.shape[0] % CHUNK != 0:\n    CHUNK_SIZE += 1","8489a53f":"def test_preprocess(path):\n    path = DIR + \"\/\" + path\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image, channels = 3)\n    image = tf.image.resize(image, [256, 256])\n    image = tf.cast(image, tf.float32) \/ 255.0\n    return image\n\ntest[\"image_preds\"] = \"\"\nKNN = 50\nknn = NearestNeighbors(n_neighbors = KNN)\n\nfor chunk in range(CHUNK_SIZE):\n    a = chunk * CHUNK\n    b = min((chunk + 1) * CHUNK, test.shape[0])\n    \n    test_ds = tf.data.Dataset.from_tensor_slices((test.iloc[a : b][\"image\"].values))\n    test_ds = test_ds.map(test_preprocess)\n    test_ds = test_ds.batch(64 * 2)\n\n    test_encoded = []\n    for image in tqdm(test_ds):\n        batch_size = image.shape[0]\n        encoded = encoder.predict(image)\n        test_encoded.append(encoded.reshape(batch_size, -1))\n    test_encoded = np.concatenate(test_encoded, axis = 0)\n    \n    knn.fit(test_encoded)\n    distances, indices = knn.kneighbors(test_encoded)\n    del test_encoded; gc.collect()\n\n    preds = []\n    for i in range(b - a):\n        idx = np.where(distances[i] < 5.0)[0]\n        ids = indices[i, idx]\n        preds.append(test.iloc[a: b].iloc[ids][\"posting_id\"].values)\n\n    del distances, indices; gc.collect()\n    test.iloc[a : b,][\"image_preds\"] = preds\ntest.head()","61a37157":"test[\"matches\"] = test.apply(lambda x: \" \".join(np.unique(x[\"image_preds\"])) , axis = 1)\nsubmit = test[[\"posting_id\", \"matches\"]].copy()\nsubmit.to_csv(\"submission.csv\", index = False)\nsubmit","bb11d855":"def metric(col):\n    def f1score(row):\n        n = len(np.intersect1d(row[\"target\"], row[col]))\n        return 2*n \/ (len(row[\"target\"]) + len(row[col]))\n    return f1score\n\nscore = valid.apply(metric(\"oof\"), axis = 1).mean()\nprint(f\"CV Score = {score}\")","fcce5cef":"# 3. Autoencoder","2d66deab":"# INFERENCE","a04f951b":"# 1. Loading","95cf2ad4":"tmp = valid.groupby(\"label_group\")[\"posting_id\"].agg(\"unique\").to_dict()\nvalid[\"target\"] = valid[\"label_group\"].map(tmp)\nvalid[\"oof\"] = valid.apply(lambda x: np.unique(x[\"image_preds\"]), axis = 1)\nvalid.head()","cb2880a0":"# 2. Images"}}