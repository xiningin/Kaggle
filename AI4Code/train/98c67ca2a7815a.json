{"cell_type":{"8f2c888a":"code","bc4b5155":"code","8d48e506":"code","510b3cc6":"code","bf86bffd":"code","3c86d580":"code","b378a96c":"code","1719f39d":"code","4f52af1b":"code","5e856b9a":"code","37272571":"code","7a134645":"code","c9e850f3":"code","0c6a78b0":"code","a96ab8ce":"code","59b5fc0d":"code","1f5da09c":"code","d8484626":"code","3b1641eb":"code","af031f35":"code","5baaf7c6":"code","5219ec23":"code","d2fe9862":"code","b390dc6e":"code","31fde0d3":"code","a55b18dc":"code","48622af2":"code","f43d1ebc":"code","64d55a34":"code","8fe6f9f3":"code","324ac0ca":"code","87fd2a58":"code","0f328bd5":"code","4e358e8d":"code","e69236e5":"code","260fea51":"code","8a902f85":"code","3af0d3af":"markdown","2ec25f77":"markdown","c62c3c12":"markdown","3638d3af":"markdown","7c5a396f":"markdown","44a575d4":"markdown","68365495":"markdown","a41a921c":"markdown","f8320f21":"markdown","1df1d0bd":"markdown","36d7c18f":"markdown","6e8155f7":"markdown","3ce89541":"markdown","1e918721":"markdown","4992341f":"markdown","2fec2f6b":"markdown","a36c8c4b":"markdown","c526b321":"markdown","6fe2d4bb":"markdown","54a8254d":"markdown","e5a1be17":"markdown","53c5bd06":"markdown","7c1c7dfc":"markdown","a45a881e":"markdown","2e0f8c97":"markdown","38b661ec":"markdown","d8539927":"markdown"},"source":{"8f2c888a":"#\u00a0The usual suspects\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pylab as plt\nfrom sklearn.cross_validation import cross_val_score, time\nfrom sklearn.model_selection import TimeSeriesSplit\n#\u00a0Ignore warnings (this isn't a good practice usually)\nimport warnings\nwarnings.filterwarnings(\"ignore\")","bc4b5155":"# Avocados are green. :) \nGREEN_COLORMAP = sns.color_palette(\"Greens\")","8d48e506":"DATA_PATH  = \"..\/input\/avocado.csv\"\ndf = pd.read_csv(DATA_PATH, parse_dates=['Date'])","510b3cc6":"fig, ax = plt.subplots(1, 1, figsize=(20, 8))\ndf.set_index('Date').plot(y='AveragePrice', ax=ax, color=GREEN_COLORMAP[2])","bf86bffd":"#\u00a0Get the number of years and create one plot per year.\n#\u00a0Notice that 2018 has less samples than the previous ones.\nyears = df.year.unique()\nnumber_years = len(years)\nfig, axes = plt.subplots(number_years, 1, figsize=(12, 8))\nfor i, year in enumerate(years):\n    #\u00a0One green shade per year :)\n    #\u00a0Also, no line connecting the points and marker set to a dot\n    #\u00a0for enhanced readability.\n    (df.set_index('Date')\n       .loc[lambda df: df.year == year]\n       .plot(y='AveragePrice', ax=axes[i], color=GREEN_COLORMAP[i],\n             marker=\"o\", linestyle=\"\"))\n    axes[i].legend_.remove()\n\nfig.set_tight_layout(\"tight\")","3c86d580":"fig, ax = plt.subplots(1, 1, figsize=(12, 8))\ndf.groupby('Date').size().plot(ax=ax)","b378a96c":"df.Date.diff().value_counts()","1719f39d":"fig, axes = plt.subplots(2, 1, figsize=(12, 8))\ndf.groupby('Date')['region'].nunique().plot(ax=axes[0])\ndf.groupby('Date')['type'].nunique().plot(ax=axes[1])","4f52af1b":"(\"Bingo, that's it: there are {} unique regions and {} unique\" \n\" types of Avocado ({})\").format(df['region'].nunique(),\n                                 df['type'].nunique(),\n                                ' and '.join(df['type'].unique())) ","5e856b9a":"fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n\ndf['region'].value_counts().plot(kind='bar', ax=axes[0], \n                                 color=GREEN_COLORMAP)\ndf['type'].value_counts().plot(kind='bar', ax=axes[1], color=GREEN_COLORMAP)\nfig.set_tight_layout(\"tight\")","37272571":"ts = df.groupby('Date')['AveragePrice'].mean().reset_index()","7a134645":"ts.sample(5)","c9e850f3":"fig, ax = plt.subplots(1, 1, figsize=(12, 8))\nts.set_index('Date').plot(ax=ax, marker=\"o\", linestyle=\"-\", color=GREEN_COLORMAP[2])","0c6a78b0":"fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n(ts.set_index('Date')\n   .resample('1M')\n   .mean()\n   .plot(ax=ax, marker=\"o\", linestyle=\"-\", color=GREEN_COLORMAP[2]))","a96ab8ce":"fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n(ts.set_index('Date')\n   .assign(month=lambda df: df.index.month)\n   .groupby('month')['AveragePrice'].agg([\"mean\", \"std\", \"median\", \"min\", \"max\"])\n   .plot(ax=ax, marker=\"o\"))\nax.set_xlabel('Month')","59b5fc0d":"# Renaming the ts DataFrame's columns (you will see why soon) before temporal split\nrenamed_ts = ts.rename(columns={\"Date\": \"ds\", \"AveragePrice\": \"y\"})\ntrain_ts = renamed_ts.loc[lambda df: df['ds'].dt.year < 2018, :]\ntest_ts = renamed_ts.loc[lambda df: df['ds'].dt.year == 2018, :]","1f5da09c":"train_ts.head()","d8484626":"train_ts.tail()","3b1641eb":"from fbprophet import Prophet\nfrom fbprophet.diagnostics import cross_validation, performance_metrics\n\n\n#\u00a0TODO: Add some comments\nHORIZON = \"90days\"\nPERIOD = \"7days\"\n\nprophet_model = Prophet()\nprophet_model.fit(train_ts)\nprophet_cv_df = cross_validation(prophet_model, horizon=HORIZON, \n                                 period=PERIOD)","af031f35":"prophet_cv_df.head()","5baaf7c6":"prophet_perf_df = performance_metrics(prophet_cv_df)","5219ec23":"prophet_perf_df.sample(5)","d2fe9862":"from fbprophet.plot import plot_cross_validation_metric\nplot_cross_validation_metric(prophet_cv_df, metric='mae');","b390dc6e":"fig ,ax = plt.subplots(1, 1, figsize=(12, 8))\n(prophet_perf_df.groupby('horizon')['mae']\n                .mean()\n                .plot(ax=ax, marker=\"o\", colors=GREEN_COLORMAP[2]))\nax.set_ylabel('MAE')","31fde0d3":"future_prophet_df = prophet_model.make_future_dataframe(periods=365)\npredicted_prophet_df = prophet_model.predict(future_prophet_df)\nprophet_model.plot(predicted_prophet_df);\nprophet_model.plot_components(predicted_prophet_df);","a55b18dc":"def add_calendar_features(df):\n    #\u00a0TODO: Add some comments\n    return (df.assign(month=lambda df: df['ds'].dt.month, \n                                     week=lambda df: df['ds'].dt.week,\n                                     year=lambda df: df['ds'].dt.year,\n                                     past_month_mean_y=lambda df: \n                                      (df['y'].rolling(window=4)\n                                              .mean()\n                                              .fillna(method='bfill')),\n                                     past_year_mean_y=lambda df: \n                                      (df['y'].rolling(window=52)\n                                              .mean())\n                                              .fillna(method='bfill'))\n                              )\n\n\n\naugmented_ts = add_calendar_features(renamed_ts)\naugmented_train_ts = augmented_ts.loc[lambda df: df['ds'].dt.year < 2018, :].drop('ds', axis=1)\naugmented_test_ts = augmented_ts.loc[lambda df: df['ds'].dt.year == 2018, :].drop('ds', axis=1)","48622af2":"augmented_train_ts.head()","f43d1ebc":"fig, ax = plt.subplots(1, 1, figsize=(12, 8))\naugmented_train_ts.plot(y='past_month_mean_y', ax=ax)\naugmented_train_ts.plot(y='past_year_mean_y', ax=ax)\naugmented_train_ts.plot(y='y', ax=ax)","64d55a34":"tscv = TimeSeriesSplit(n_splits=3)","8fe6f9f3":"from tpot import TPOTRegressor\n\n#\u00a0TODO: Try more generations and a bigger population size. \n#\u00a0Be careful not to run out of time!\n\ntpot_model = TPOTRegressor(generations=20, population_size=100, cv=tscv, \n                           scoring=\"neg_mean_absolute_error\", \n                           n_jobs=2, verbosity=2)","324ac0ca":"tpot_model.fit(augmented_train_ts.drop('y', axis=1), \n               augmented_train_ts['y'])","87fd2a58":"test_timestamps = test_ts.ds.values","0f328bd5":"predicted_prophet_s = predicted_prophet_df.loc[lambda df: df['ds']\n                                               .isin(test_timestamps), \"yhat\"]\npredicted_tpot_s = tpot_model.predict(augmented_test_ts.drop(\"y\", axis=1))","4e358e8d":"assert predicted_tpot_s.shape == predicted_prophet_s.shape\nassert predicted_tpot_s.shape == test_ts[\"y\"].shape","e69236e5":"predictions_df = pd.DataFrame({'tpot': predicted_tpot_s, \n                              'prophet': predicted_prophet_s,\n                              'true': test_ts['y'].values,\n                              'Date': test_ts['ds'].values})","260fea51":"print(\"MAE for tpot on the test dataset is: {}\".format(\n    (predictions_df['tpot'] - predictions_df['true']).abs().mean(axis=0)))\nprint(\"MAE for prophet on the test dataset is: {}\".format(\n    (predictions_df['prophet'] - predictions_df['true']).abs().mean(axis=0)))","8a902f85":"fig, ax = plt.subplots(1, 1, figsize=(12, 10))\npredictions_df.set_index('Date').plot(marker='o', ax=ax)","3af0d3af":"Some observations: \n    \n* There are seasonal variations: prices are higher from July to October (roughly) since demand is higher during these months.\n* There are also yearly variations: an upward trend probably due to a higher demand?\n* As mentionned earlier, 2018 data stops in March. \n\nTo finish this section, let's plot some simple statistics about the average monthly price: mean, standard deviation, median, min, and max values. ","2ec25f77":"Let's plot the predictions for each model (alongside the true values). For that, we need to prepare\nthe predictions DataFrame. Also, we will compute the MAE for each model.","c62c3c12":"##\u00a0ML models","3638d3af":"As in any ML task, will start by dividing the dataset into train and test data. \nWe won't look at the test dataset until the end. \nAlso, since this is a time-series ML problem, we will use a timestamp to perform the split (can't use the [`train_test_split`](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html) from sklearn): \ndata before 2018 belongs to the train dataset. After, it belongs to the test dataset. ","7c5a396f":"#\u00a0Test evaluation","44a575d4":"If you are unfamilar with CV for time-series, I highly recommend checking this blog post: https:\/\/robjhyndman.com\/hyndsight\/tscv\/. ","68365495":"We also notice that most observations are made once a week (thus the delta of -7  days). \nWhy are there 108 observations per week though? Hint: look at the `region` and `type` columns.","a41a921c":"First, let's plot the avocado's average price over time.","f8320f21":"As a model, let's try the tpot auto-ml tool and see what it gets. Notice that I use the negative MAE since sklearn needs a score (the higher the better) to optimize in the CV method.","1df1d0bd":"It appears there are multiple points per day. How many exactly?","36d7c18f":"Not bad for a first graph. However, things are a little bit packed. Possible solution: let's make \na time-series plot per year.","6e8155f7":"In this notebook, I predict the average price of avocado using time-series modeling \ntechniques","3ce89541":"#\u00a0Statistical models","1e918721":"Let's see how this time-series looks like when resampled to a monthly frequency.","4992341f":"To wrap this short EDA, let's check these regions and types.","2fec2f6b":"That's it for now. I hope you have enjoyed exploring this dataset and some of the time-series modeling techniques.\n\nTo be continued, stay tuned!\n\nOther ideas: \n\n*  Better explanation and investigation of CV for Prophet model.\n* Tuning hyperparamters for Prophet model.\n* RNN models. \n* More generation for TPOT\n\nAlso, since I am not in expert in time-series modeling, let me know if there is any mistake or data leakage.\nAs usual, enjoy!","a36c8c4b":"To assess the quality of the model's predictions, will be using a the [**mean absolute error**](https:\/\/en.wikipedia.org\/wiki\/Mean_absolute_error). The lower is this error, the better the model. \n\nAlright, time to kickstart the modeling! Let's begin with traditional models, i.e. statistical time-series models. ","c526b321":"ALright, now we need to define a time-series compatible CV. For that, we will \nuse `TimeSeriesSplit` from `sklearn`.","6fe2d4bb":"For that, let's use [`Prophet`](https:\/\/facebook.github.io\/prophet\/docs\/quick_start.html) (this is why we renamed the `Date`\u00a0and `AveragePrice` columns), an open-source time-series (unveiled a year and half ago) analysis library developed at Facebook. For more details, I recommend checking the [announcement](https:\/\/research.fb.com\/prophet-forecasting-at-scale\/) blog post.","54a8254d":"Based on the CV score, tpot is the winner!\nLet's see if this is true on the test dataset.","e5a1be17":"What is the CV MAPE evolution when varying the horizon (i.e. the number of days in the future to predict)? ","53c5bd06":"Let's start by loading the data and doing some time-series exploration.","7c1c7dfc":"#\u00a0Time-series processing","a45a881e":"Before starting this section, we will need to extract calendar features from the `ds`\u00a0column. \nWill also add average rolling mean prices (yearly and monthly). Notice that I approximate the last year using\nthe 52 previous points and the last months by using the 4 previous points. Finally, I backfill missing data. ","2e0f8c97":"Next, we will compute the \"real\" average avocado's price (over the different regions and types) and only keep\nthis column (in addition to the `Date` obviously). ","38b661ec":"#\u00a0Loading data and EDA","d8539927":"#\u00a0Temporal train\/test split"}}