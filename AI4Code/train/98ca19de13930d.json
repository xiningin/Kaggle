{"cell_type":{"8541a16d":"code","d3974e14":"code","750141ff":"code","593036a4":"code","b50c4c1f":"code","641681f3":"code","9c4948b8":"code","180e53a0":"code","1c14605b":"code","53cc0316":"code","f68a5520":"code","925e79ca":"code","3add5614":"code","485fb668":"code","489b6840":"code","9a21e9ae":"code","527cafe4":"markdown","1fd63c9e":"markdown","768d6796":"markdown","c923400a":"markdown","b4357297":"markdown","5258362e":"markdown","67ab10d6":"markdown","c6f4507d":"markdown","8bcbb995":"markdown","c4953774":"markdown","61d10e32":"markdown","5bce0bc8":"markdown","c44945e5":"markdown"},"source":{"8541a16d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d3974e14":"import os\nfrom functools import partial\n\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport PIL.Image as image\nimport PIL\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline","750141ff":"train_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","593036a4":"train_data_x = train_data.iloc[:,1:]\ntrain_data_y = train_data.iloc[:,0]\n\n# Take all the value for reshaping -1, dimension (28,28), colour 1\ntrain_data_x = train_data_x.values.reshape(-1,28,28)\ntest_data_x = test_data.values.reshape(-1,28,28)\n\n# Expected shape per image is 28,28 (width, height)\ntrain_data_x[0].shape","b50c4c1f":"plt.imshow(train_data_x[8], cmap='gray');","641681f3":"train_data_x = np.expand_dims(train_data_x, axis=-1)\/255.0\ntest_data_x = np.expand_dims(test_data_x, axis=-1)\/255.0","9c4948b8":"# Expected shape per image is 28,28,1 (width, height, colour)\ntest_data_x[0].shape","180e53a0":"def data_augumentation(x_data, y_data, batch_size):\n    \"\"\"\n    Data augmentation\n    \"\"\"\n#     datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n#         rotation_range=20, width_shift_range=0.1,height_shift_range=0.1, zoom_range=0.2)\n    datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=5, width_shift_range=0.1,height_shift_range=0.1, zoom_range=0.1)\n    datagen.fit(x_data)\n    train_data = datagen.flow(x_data, y_data, batch_size=batch_size, shuffle=True)\n    return train_data","1c14605b":"class MyCallback(tf.keras.callbacks.Callback):\n    \"\"\"\n    custom callback for epoch end\n    \"\"\"\n    \n    def on_epoch_end(self, epoch, logs={}):\n        \"\"\"\n        some function\n        \"\"\"\n        if logs['accuracy'] >= 0.999:\n            self.model.stop_training = True\ncall = MyCallback()","53cc0316":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (5,5), padding = 'same', activation='relu', input_shape=(28,28,1)),\n    tf.keras.layers.Conv2D(32, (5,5), padding = 'same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Conv2D(64, (3,3), padding = 'same', activation='relu'),\n    tf.keras.layers.Conv2D(64, (3,3), padding = 'same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax'),\n])\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.RMSprop(\n        learning_rate=0.001),\n    loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])","f68a5520":"TRAIN_SIZE=0.8\nBATCH_SIZE=64\nx_train, x_test, y_train, y_test = train_test_split(train_data_x, train_data_y, train_size=TRAIN_SIZE, random_state=10)","925e79ca":"aug_train_data = data_augumentation(x_train, y_train, BATCH_SIZE)","3add5614":"hist = model.fit(aug_train_data, epochs=30, steps_per_epoch=int(len(x_train)\/BATCH_SIZE), validation_data=(x_test, y_test), callbacks=[call])","485fb668":"plt.plot(hist.history['accuracy'][1:], label='train acc')\nplt.plot(hist.history['val_accuracy'][1:], label='validation acc')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')","489b6840":"aug_train_data = data_augumentation(train_data_x, train_data_y, BATCH_SIZE)\nhist = model.fit(aug_train_data, epochs=30, steps_per_epoch=int(len(train_data_x)\/BATCH_SIZE), callbacks=[call])","9a21e9ae":"pred_y = model.predict(test_data_x)\npred_y = np.argmax(pred_y, axis=1)\n# Generate Submission File \nout_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')\nout_df.Label = pred_y\nout_df.to_csv(\"output.csv\", index=False)","527cafe4":"## Plot to see accuracy","1fd63c9e":"# Import necessary libraries","768d6796":"# Data Collection","c923400a":"# Final Training","b4357297":"### 1 Convolution layer, 1 pooling layer\n### 1 hidden layer and 512 hidden units","5258362e":"# Data Augmentation","67ab10d6":"> # Training\/Evaluation","c6f4507d":"## Plot some sample images","8bcbb995":"## Read data from csv file","c4953774":"# Prediction","61d10e32":"# Create layers","5bce0bc8":"### Callback for stopping training on reaching 99% train accuracy","c44945e5":"## Convert data from excel to numpy array and reshape to 28x28"}}