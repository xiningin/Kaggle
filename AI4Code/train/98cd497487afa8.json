{"cell_type":{"37fb01f1":"code","ff829253":"code","bd4021a4":"code","12eefb3b":"code","1d286352":"code","f13ffe8b":"code","1cd2bbe4":"code","a1c96beb":"code","ce960c1d":"code","c6ef5f6f":"code","4c3a5b80":"code","bda1862f":"code","732c12c9":"code","be3c3473":"code","0cba6b31":"code","c22c4f37":"code","8257710c":"code","91e43356":"code","425ed7a2":"code","f5219064":"code","c6d0dbae":"code","ba1c949a":"code","1519ddc0":"markdown","58bbb50a":"markdown","a8248475":"markdown","12aa1cb7":"markdown","76d7512e":"markdown","4abe7e48":"markdown","585ce37d":"markdown","b042f349":"markdown","ddf3703d":"markdown"},"source":{"37fb01f1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport cv2\nimport os","ff829253":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch","bd4021a4":"DATADIR = '..\/input\/flowers-recognition\/flowers'\nCATEGORIES = [\"daisy\",\"dandelion\",\"rose\",\"sunflower\",\"tulip\"]\nIMG_SIZE = 28","12eefb3b":"def create_training_data():\n    training_data = []\n\n    for category in CATEGORIES:\n        path = os.path.join(DATADIR,category)\n        class_num = CATEGORIES.index(category)\n        for img in os.listdir(path):\n            try:\n                img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n                new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE)) \n                training_data.append([new_array,class_num])\n            except Exception as e:\n                pass\n\n    return np.asarray(training_data)","1d286352":"training_data = create_training_data()","f13ffe8b":"features = np.concatenate(training_data[:,0]).reshape(4323, 28, 28).astype(np.float32)\nlabels = training_data[:,1]","1cd2bbe4":"# normalize\nfeatures \/= 255.\n\n# one hot encoder\nlabels = np.eye(len(CATEGORIES))[list(labels)]","a1c96beb":"cuda = torch.device('cuda')","ce960c1d":"features = torch.from_numpy(features.astype(np.float32)).to(cuda)\nlabels = torch.from_numpy(labels.astype(np.float32)).to(cuda)","c6ef5f6f":"X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42, shuffle=True)","4c3a5b80":"np.random.seed(34243242)\nf = torch.tensor(np.random.randn(3, 3).astype(np.float32)).to(cuda) \/ 9\nw1 = torch.tensor(np.random.randn(169, 64).astype(np.float32)).to(cuda) \/ 9\nw2 = torch.tensor(np.random.randn(64, 32).astype(np.float32)).to(cuda) \/ 9\nw3 = torch.tensor(np.random.randn(32, 5).astype(np.float32)).to(cuda) \/ 9\n\ntheta = f, w1, w2, w3","bda1862f":"# Convolution and derivative functions","732c12c9":"def conv3x3(x, f):\n    conv = torch.tensor(np.zeros((26,26)).astype(np.float32)).to(cuda)\n    for i in range(x.shape[0] - 2):\n        for j in range(x.shape[1] - 2):\n            conv[i,j] = torch.sum(torch.mul(x[i:i+3,j:j+3], f))\n    return conv","be3c3473":"def dconv(x, f):\n    filter = torch.tensor(np.zeros((3,3)).astype(np.float32)).to(cuda)\n    for i in range(3):\n        for j in range(3):\n            filter[i,j] = torch.sum(torch.mul(x[i:i+26,j:j+26], f))\n    return filter","0cba6b31":"def maxpool2x2(x):\n    maxpool = torch.tensor(np.zeros((13,13)).astype(np.float32)).to(cuda)\n    all_indices = []\n    for i in range(0, x.shape[0], 2):\n        for j in range(0, x.shape[1], 2):\n            values, indices = torch.max(x[i:i+2,j:j+2], 0)\n            maxpool[i \/\/ 2,j \/\/ 2] = values[0]\n            indices[0], indices[1] = indices[0] + i, indices[1] + j\n            all_indices.append(indices)\n    return maxpool, all_indices","c22c4f37":"def softmax(x):\n    return torch.exp(x)\/torch.sum(torch.exp(x))","8257710c":"def dtanh(x):\n    return 1.0 - torch.tanh(x)**2","91e43356":"def forward(x, theta):\n    f, w1, w2, w3 = theta\n\n    conv = conv3x3(x, f)\n    maxpool, maxpool_indices = maxpool2x2(conv)\n\n    flat = maxpool.flatten()\n    flat = flat.reshape(1, flat.shape[0])\n\n    p = flat @ w1\n    q = torch.tanh(p)\n    r = q @ w2\n    s = torch.tanh(r)\n    t = s @ w3\n    u = softmax(t)\n\n    return conv, maxpool, maxpool_indices, flat, p, q, r, s, t, u","425ed7a2":"def backward(x, y, theta):\n    conv, maxpool, maxpool_indices, flat, p, q, r, s, t, u = forward(x, theta)\n\n    e = u - y\n    # cross entropy\n    # -log(argmax(y))\n    error = 1 - ( -torch.log(u[0][torch.argmax(y)]))\n\n    dt = e @ w3.T\n    ds = dtanh(r) * dt\n    dr = ds @ w2.T\n    dq = dtanh(p) * dr\n    dp = dq @ w1.T\n\n    dw3 = s.T @ e\n    dw2 = q.T @ ds\n    dw1 = flat.T @ dq\n\n    dmaxpool = torch.tensor(np.zeros((26,26)).astype(np.float32)).to(cuda)\n\n    for i, p in enumerate(dp.flatten()):\n        m, n = maxpool_indices[i]\n        dmaxpool[m, n] = p\n\n    # rotate 180\n    rot180 = dmaxpool.flip(1)\n\n    df = dconv(x, rot180)\n\n    grads = df, dw1, dw2, dw3\n\n    return grads, error","f5219064":"def update(grads, theta, batch_size, lr=0.05):\n    df, dw1, dw2, dw3 = grads\n    f, w1, w2, w3 = theta\n\n    f -= (df * lr) \/ batch_size\n    w1 -= (dw1 * lr) \/ batch_size\n    w2 -= (dw2 * lr) \/ batch_size\n    w3 -= (dw3 * lr) \/ batch_size\n\n    return f, w1, w2, w3","c6d0dbae":"batch_size = 128\ntorch.backends.cudnn.benchmark = True","ba1c949a":"for epoch in range(10):\n    for idx in np.array_split(np.arange(len(X_train)), len(X_train)\/batch_size):\n        for i in idx:\n            grads, accuracy = backward(X_train[i], y_train[i], theta)\n            theta = update(grads, theta, batch_size, lr=0.1)\n    print(\"Epoch:{0:2d}, Accuracy:{1:1.3f}\".format(epoch, accuracy))","1519ddc0":"# Training","58bbb50a":"# Pytorch from Scratch Flowers Recognition","a8248475":"# Activation functions","12aa1cb7":"# Maxpool function","76d7512e":"# Prepare Data","4abe7e48":"# Parameters","585ce37d":"# Update function","b042f349":"# Forward propagation","ddf3703d":"# Backward propagation"}}