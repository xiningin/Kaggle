{"cell_type":{"e66dbf51":"code","55c9cc5d":"code","5343dd23":"code","eb25b391":"code","fa7264ad":"code","1783ebac":"code","2ab0abda":"code","54b9b0b4":"code","f034aab6":"code","d9d0be6b":"code","8009cb4d":"code","980476aa":"code","67bd4384":"code","26ca0b0d":"code","5670cbd6":"code","8b5fe8d3":"code","e6a7a235":"code","d072a59c":"code","8cd41e68":"code","a982cec4":"code","eb76cf7b":"code","d14a3f0c":"code","e072063c":"code","551ad0e5":"code","da2c9806":"code","9ac8d903":"markdown","e5b1129f":"markdown","301849ff":"markdown","f5427795":"markdown"},"source":{"e66dbf51":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","55c9cc5d":"import pandas as pd\nimport numpy as np\nimport wordcloud\nimport seaborn as sns\nimport nltk\nfrom nltk.corpus import stopwords\nfrom textblob import Word\nfrom sklearn.preprocessing import LabelEncoder\nfrom collections import Counter\nimport wordcloud\nfrom keras.preprocessing.text import Tokenizer\nimport matplotlib.pyplot as plt\nimport re\nfrom keras.models import Sequential\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.optimizers import Adam","5343dd23":"#Try to merge 3 given files in 1 dataset Frame.\ndf1 = pd.read_csv(\"..\/input\/upi-payment-apps-review-google-play-store\/GooglePayIndia.csv\")\ndf2 = pd.read_csv(\"..\/input\/upi-payment-apps-review-google-play-store\/PaytmIndia.csv\")\ndf3 = pd.read_csv(\"..\/input\/upi-payment-apps-review-google-play-store\/PhonePayIndia.csv\")","eb25b391":"df1['app']='GooglePayIndia'\ndf2['app']='PaytmIndia'\ndf3['app']='PhonePayIndia'","fa7264ad":"#Merge all 3 files in final database\ndf= pd.concat([df1,df2,df3])","1783ebac":"#Initially take only few columns from dataset for model analysis and building.\ndata = df.drop(['Unnamed: 0','reviewId','userImage','reviewCreatedVersion','replyContent','repliedAt'],axis=1)","2ab0abda":"#Remove null values from dataset\ndata = data[data['content'].notnull()]\ndata = data[data['userName'].notnull()]\ndata.shape","54b9b0b4":"#Convert all text to smaller case and remove stopwords:\nstop_words = stopwords.words('english')\ndata.loc[:,'content']=data.loc[:,'content'].apply(lambda x:' '.join(x for x in x.split() if x not in stop_words))\ndata.loc[:,'content'] = data.loc[:,'content'].apply(lambda x:' '.join([Word(x).lemmatize() for x in x.split()]))\ndata.loc[:,'content'] = data.loc[:,'content'].apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))","f034aab6":"#Clean text punctuation marks and characters before analysis.\ndata.loc[:,'content'] = data.loc[:,'content'].str.replace('?','',regex=True)\ndata.loc[:,'content'] = data.loc[:,'content'].str.replace('!','',regex=True)\ndata.loc[:,'content'] = data.loc[:,'content'].str.replace('@','',regex=True)\ndata.loc[:,'content'] = data.loc[:,'content'].str.replace('*','',regex=True)\ndata.loc[:,'content'] = data.loc[:,'content'].str.replace('&','',regex=True)\ndata.loc[:,'content'] = data.loc[:,'content'].str.replace(':','',regex=True)\ndata.loc[:,'content'] = data.loc[:,'content'].str.replace('.','',regex=True)\ndata.loc[:,'content'] = data.loc[:,'content'].str.replace('-','',regex=True)\ndata.loc[:,'content'] = data.loc[:,'content'].str.replace('%','',regex=True)\ndata.loc[:,'content'] = data.loc[:,'content'].str.replace('$','',regex=True)\ndata.loc[:,'content'] = data.loc[:,'content'].str.replace(',','',regex=True)","d9d0be6b":"#some frequent words with no sentiment attached to them should be removed\ndata.loc[:,'content'] = data.loc[:,'content'].str.replace('app','',regex=True)\ndata.loc[:,'content'] = data.loc[:,'content'].str.replace('paytm','',regex=True)\ndata.loc[:,'content'] = data.loc[:,'content'].str.replace('google','',regex=True)","8009cb4d":"#Lets visualize frequent occuring words in review=5 and review = 1 along with its no. of occurences\ndata5 = data[data['score']==5]\ncorp = data5['content'].values\ntok = Tokenizer(num_words=250, split=' ')\ntok.fit_on_texts(data5['content'].values)\n#Lists for words and their count\nP = []\nCNT = []\nN = []\nCNT1 =[]","980476aa":"for i in range(1,15):\n    P.append(tok.index_word[i])","67bd4384":"for word in P:\n    CNT.append(tok.word_counts[word])","26ca0b0d":"plt.figure(figsize=(14,8))\nplt.bar(P,CNT,color='green')\nplt.title('Most Positive words')\nplt.xlabel('Positive word')\nplt.ylabel('Frequency')\nplt.show()","5670cbd6":"data1 = data[(data['score']==1)]\ncorp1 = data1['content'].values\ntokn = Tokenizer(num_words=250, split=' ')\ntokn.fit_on_texts(data1['content'].values)\nfor n in range(1,15):\n    N.append(tokn.index_word[n])","8b5fe8d3":"for word in N:\n    CNT1.append(tokn.word_counts[word])","e6a7a235":"plt.figure(figsize=(14,8))\nplt.bar(N,CNT1,color='red')\nplt.title('Most Negative words')\nplt.xlabel('Negative word')\nplt.ylabel('Frequency')\nplt.show()","d072a59c":"#Frequency of positive words is much more than frequency of Negative words.\n#Lets build word cloud on complete data for its verification.\n#Lets create word cloud of data to analyse most commonly used words.\ncommon_words=''\nfor i in data.content:\n    i = str(i)\n    tokens = i.split()\n    common_words += \" \".join(tokens)+\" \"\nA = wordcloud.WordCloud().generate(common_words)\nplt.figure(figsize=(15,12))\nplt.imshow(A, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","8cd41e68":"#convert date to datetime format for time based analysis\ndata['New_date'] = pd.to_datetime(data['at'],format = \"%Y-%m-%d %H:%M:%S\")","a982cec4":"data['Month'] = data['New_date'].dt.month_name()\ndata['Year'] = data['New_date'].dt.year\ndata['date'] = data['New_date'].dt.day\ndata['Hour'] = data['New_date'].dt.hour\ndata['Minutes'] = data['New_date'].dt.minute\ndata['Seconds'] = data['New_date'].dt.second","eb76cf7b":"#Data grouped by app and score to analyse each app and its score count\ndata.groupby(['app','score']).count()\nA = data.groupby(['app','score']).count().reset_index()\nA['count'] = A['Year']\nA = A.drop(['userName','content','thumbsUpCount','at','New_date','Month','Year','date','Hour','Minutes','Seconds'],axis=1)","d14a3f0c":"#Calculate Percentage of each app score compared to its overall count.\nGpay = A.iloc[0:5,2:3]['count'].sum()\nPaytm = A.iloc[5:10,2:3]['count'].sum()\nPhonepe=A.iloc[10:15,2:3]['count'].sum()\nA.loc[A['app'] == 'GooglePayIndia','Percentage']= (A['count']\/Gpay)*100\nA.loc[A['app'] == 'PaytmIndia','Percentage']= (A['count']\/Paytm)*100\nA.loc[A['app'] == 'PhonePayIndia','Percentage']= (A['count']\/Phonepe)*100\n","e072063c":"#Bar plot indicating each app scores and count\nplt.figure(figsize=(13,9))\nsns.barplot(x='app',y='count',data=A,hue='score')\nplt.title('Score 1-5 Reviews count ')\nplt.show()\n#Paytm India got highest positive reviews","551ad0e5":"#Lets compare % of each app\nplt.figure(figsize=(13,9))\nsns.barplot(x='app',y='Percentage',data=A,hue='score')\nplt.title('Percentage of reviews for scores 1-5')\nplt.show()","da2c9806":"#Basic LSTM model built using google Colab for review star rating prediction.It gives 78-79% accuracy.\n#This model hyperparameter tuning is ongoing. Code will be updated if further accuracy is achieved.\n#prepare dataset with content and score for model building\n#data_model = data[['content','score']]\n#token = Tokenizer(num_words=5000,split=' ')\n#token.fit_on_texts(data_model['content'].values)\n#X=token.texts_to_sequences(data_model['content'].values)\n#X = pad_sequences(X)\n#Y = pd.get_dummies(data_model['score'])\n#from sklearn.model_selection import train_test_split\n#x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state = 1)\n#modelf = Sequential()\n#modelf.add(Embedding(5000, 240, input_length = X.shape[1]))\n#modelf.add(SpatialDropout1D(0.2))\n#modelf.add(LSTM(176, dropout=0.2, recurrent_dropout=0.2))\n#modelf.add(Dense(5,activation='softmax'))\n#modelf.compile(loss = 'categorical_crossentropy', optimizer= Adam(learning_rate=0.1), metrics = ['accuracy'])\n#print(modelf.summary())\n#modelf.fit(x_train,y_train, epochs = 10, batch_size=1024, verbose = 'auto')\n#modelf.evaluate(x_test,y_test)","9ac8d903":"df= pd.concat([df1,df2,df3])","e5b1129f":"#Conclusions from above data:-\n> 1. For google Pay app , during Q1 2020,average rating is 4 which is continuously declining afterwards.\n> 2. In year 2021, Paytm app average rating is higher than google pay.\n> 3. In NOV 2021, Average rating of Paytm and phonepe apps is very high and Google pay is clearly lagging for positive rating.\n> 4. Thums up votes are given more to either extreme positive \/ extreme Neagtive reviews(5 and 1 star). For neutral reviews, thums up votes are less.\n","301849ff":"![](http:\/\/)![Dashboard_payment_apps.png](attachment:27405aa2-6853-471f-a5c4-3a94fc075892.png)","f5427795":"#Conclusion:- Paytm India app has highest Positive reviews and Google pay India got highest Negative reviews.\n#I have configured below Tableau dashboard for time-trend analysis of payment apps.\n"}}