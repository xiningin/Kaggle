{"cell_type":{"1b46a592":"code","18fc5d49":"code","6064a182":"code","d474cbef":"code","aac1dd6f":"code","17b43626":"code","32b8ffc8":"code","d787a384":"code","5d0c3bb2":"code","c863fd31":"code","6d577a02":"code","10d557d1":"code","ead1de41":"code","627a94ec":"code","ea5b2ff7":"code","fb164560":"code","238d4322":"code","0a212e7c":"code","c5bd245c":"code","7fff596c":"code","5624a1ba":"code","3a4477aa":"code","ee12105d":"code","c97a81a8":"code","7210882d":"code","8085a416":"code","c910e1bf":"code","d5a6d800":"code","e11caa6c":"code","701ed15e":"markdown","d125257a":"markdown","e620a353":"markdown","65e56d34":"markdown","9b634955":"markdown","603a3fa2":"markdown","f4a6a0e4":"markdown","14276567":"markdown","990b1acc":"markdown","1c3e810a":"markdown","7cf14f17":"markdown","71306d50":"markdown","b676e561":"markdown","b94eb8f5":"markdown","de0613f2":"markdown","2f631ae5":"markdown","8ee8a8af":"markdown"},"source":{"1b46a592":"!pip install tensorflow","18fc5d49":"import tensorflow as tf","6064a182":"tf.__version__","d474cbef":"# We install imageio to make GIFs\n!pip install imageio\n","aac1dd6f":"# The glob module finds all the pathnames matching a specified pattern according to the rules used\nimport glob\n# imageio is a Python library that provides an easy interface to read and write a wide range of image data,\nimport imageio\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nimport os\n\n# PIL is Python Imaging Library which is a free and open-source additional library for the Python programming language \n# that adds support for opening, manipulating, and saving many different image file formats.\nimport PIL\nfrom PIL import Image\nfrom tensorflow.keras import layers\nimport time\nimport random\n%load_ext tensorboard\nfrom IPython import display\n\n%matplotlib inline","17b43626":"# fashion mnist dataset is in Keras' sample data \nfrom keras.datasets.fashion_mnist import load_data","32b8ffc8":"(train_images, train_labels), (_, _) = tf.keras.datasets.fashion_mnist.load_data()","d787a384":"train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\ntrain_images = (train_images - 127.5) \/ 127.5 # Normalize the images to [-1, 1]\n","5d0c3bb2":"BUFFER_SIZE = 60000\nBATCH_SIZE = 256\n","c863fd31":"# Create batches of data and shuffle them.\ntrain_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)","6d577a02":"# Let's make gnerator model function\n\ndef make_generator_model():\n\n# The model is Keras sequentia model\n    model = tf.keras.Sequential()\n# And inoput is noise of 100 and output is 7*7*256\n    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n    model.add(layers.BatchNormalization())\n# Use ReLU, rectified linear activation function, that will output the input directly if it is positive, otherwise, it will output zero.\n    model.add(layers.ReLU())\n\n\n# Reshape and test it with assert function\n    model.add(layers.Reshape((7, 7, 256)))\n    assert model.output_shape == (None, 7, 7, 256) \n\n\n# Make the shape to 7*7*128\n    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n    assert model.output_shape == (None, 7, 7, 128) \n    model.add(layers.BatchNormalization())\n    model.add(layers.ReLU())\n\n\n# And make the size as 14*14*64 \n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 14, 14, 64)\n    model.add(layers.BatchNormalization())\n    model.add(layers.ReLU())\n\n# And we make the output, with the size of the original mnsit image size\n# Use tanh as activation\n    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', \n                                     use_bias=False, activation='tanh')) \n    assert model.output_shape == (None, 28, 28, 1) \n\n    return model\n\n   ","10d557d1":"generator = make_generator_model()\n\nnoise = tf.random.normal([1, 100])\ngenerated_image = generator(noise, training=False)\n\nplt.imshow(generated_image[0, :, :, 0], cmap='gray')","ead1de41":"#Make a new function to make the discriminator model\n# Input shape is 28*28*1 and we make it 64\ndef make_discriminator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n                                     input_shape=[28, 28, 1]))\n    model.add(layers.LeakyReLU())\n# Make the dropout rate of 0.3 so that we avoid any overfitting\n    model.add(layers.Dropout(0.3))\n\n# Make the size to 128\n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n#Flatten the layer\n    model.add(layers.Flatten())\n# And classify the model\n    model.add(layers.Dense(1))\n\n    return model\n\n   ","627a94ec":"discriminator = make_discriminator_model()\ndecision = discriminator(generated_image)\nprint (decision)","ea5b2ff7":"# This method returns a helper function to compute the cross entropy loss. (for Binary Classification)\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","fb164560":"def discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","238d4322":"def generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","0a212e7c":"# Use Adam as the Optimizer\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","c5bd245c":"checkpoint_dir = '.\/training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","7fff596c":"# Define the training loop\n\nEPOCHS = 1000\nnoise_dim = 100\nnum_examples_to_generate = 16\n\n# We will recycle this seed over time.\n# (Because it is easy to visualize progress in GIF animation.)\nseed = tf.random.normal([num_examples_to_generate, noise_dim])\n# The training loop starts with the Generator taking a random seed as input. \n# The seed value is used to generate the image. Use Discrimintor to classify real images \n# (taken from the training set) and fake images (generated by Generator).\n# Calculate the loss of each model, and update the Generator and Discrimintor using gradients.","5624a1ba":"# This decorator \"compiles\" the function.\n@tf.function\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n      generated_images = generator(noise, training=True)\n\n      real_output = discriminator(images, training=True)\n      fake_output = discriminator(generated_images, training=True)\n\n      gen_loss = generator_loss(fake_output)\n      disc_loss = discriminator_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))","3a4477aa":"# Create and save images\n\ndef generate_and_save_images(model, epoch, test_input):\n  # Notice that `training` is set to False.\n  # This will run all layers (including batch normalization) in inference mode.\n  predictions = model(test_input, training=False)\n\n  fig = plt.figure(figsize=(4,4))\n\n  for i in range(predictions.shape[0]):\n      plt.subplot(4, 4, i+1)\n      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n      plt.axis('off')\n\n  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n  plt.show()\n","ee12105d":"def train(dataset, epochs):\n  for epoch in range(epochs):\n    start = time.time()\n\n    for image_batch in dataset:\n      train_step(image_batch)\n\n# Instantly create images for GIF.\n    display.clear_output(wait=True)\n    generate_and_save_images(generator,\n                             epoch + 1,\n                             seed)\n\n\n# It saves the model every 15 epoch passes\n    if (epoch + 1) % 15 == 0:\n      checkpoint.save(file_prefix = checkpoint_prefix)\n    \n\n # print the report on how much time it takes for each epoch\n    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n# Generate after the last epoch is over.\n  display.clear_output(wait=True)\n  generate_and_save_images(generator,\n                           epochs,\n                           seed)\n","c97a81a8":"# # Model training\n# Call the train method defined above to train both Generator and Discrimintor at the same time. \n# Traning a generative adversarial neural network can be very tricky. \n# It is important that Generator and Discrimintor do not overpower each other. \n# (For example, if the learning rate is similar, one side will dominate.) \n# At the beginning of training, the generated image looks like random noise. As the training progresses, \n# the images generated will gradually look like real. After about 50 epochs, an image resembling the MNIST image is created. \n# If you run it with default settings in Colab, it will take about 1 minute per epoch.\n%%time\ntrain(train_dataset, EPOCHS)","7210882d":"# Restore the last checkpoint.\ncheckpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))","8085a416":"# Create GIF\n# Displays a single image using epoch numbers.\n\ndef display_image(epoch_no):\n  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))","c910e1bf":"display_image(EPOCHS)","d5a6d800":"# Create a GIF animation using images saved during training with imageio.\n\nanim_file = 'dcganwithfashionmnist.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n  filenames = glob.glob('image*.png')\n  filenames = sorted(filenames)\n  last = -1\n  for i,filename in enumerate(filenames):\n    frame = 2*(i**0.5)\n    if round(frame) > round(last):\n      last = frame\n    else:\n      continue\n    image = imageio.imread(filename)\n    writer.append_data(image)\n  image = imageio.imread(filename)\n  writer.append_data(image)\n\nimport IPython\nif IPython.version_info > (6,2,0,''):\n  display.Image(filename=anim_file)","e11caa6c":"# If you are working at Colab, you can download the animation from the code below:\n\ntry:\n  from google.colab import files\nexcept ImportError:\n  pass\nelse:\n  files.download(anim_file)","701ed15e":"## Loss function and optimizer\nDefine the loss function and optimizer for both models.","d125257a":"### Loading and preparing the dataset\nWe will use the Fashion MNIST dataset to train the Generator and Discriminator. \n\nThe Generator will generate numbers that resemble handwritten numeric data. ","e620a353":"* First install TensorFlow","65e56d34":"### Save checkpoint\nThis notebook shows you how to save and restore models that can be useful in cases where long-running training is disrupted.","9b634955":"# Please give an upvoe if you feel it is useful\n\n### plaese check other notebooks \n\n* [DCGAN with MNIST ](https:\/\/www.kaggle.com\/joshuajhchoi\/wgan-gp-with-mnist-for-absolute-beginners)\n\n* [DCGAN with Cifar10](https:\/\/www.kaggle.com\/joshuajhchoi\/dcgan-with-cifar10-for-absolute-beginners)\n\n* [DCGAN with parasitized cell images](https:\/\/www.kaggle.com\/joshuajhchoi\/dcgan-with-medical-images-for-absolute-beginners)\n\n* [CGAN with MNIST](https:\/\/www.kaggle.com\/joshuajhchoi\/cgan-with-mnist-for-absolute-beginners)\n\n* [WGAN with MNIST](https:\/\/www.kaggle.com\/joshuajhchoi\/wgan-with-fashion-mnist-for-absolute-beginners)\n\n* [WGAN-GP with MNIST](https:\/\/www.kaggle.com\/joshuajhchoi\/wgan-gp-with-mnist-for-absolute-beginners)","603a3fa2":"# DCGAN with Fashion MNIST (TensorFlow)","f4a6a0e4":"Buffer Size?\n\nHere, buffer_size refers to the size of the container to hold the data to be shuffled.\n\nIf there are 60,000 data and buffer_size=6,000 is set, only 6,000 data will be shuffled, and the rest of the data will remain in order.\n\nTherefore, buffer_size should be set larger than the data to be learned.","14276567":"Let's create an image using a generator that hasn't been trained yet.","990b1acc":"Like Generator, it uses a Discriminator (which has not yet been trained) to determine if the generated image is real or fake. \n\nThe model is trained to output positive values for real images and negative values for fake images.","1c3e810a":"So why 127.5?\n\nFor normalization, we are to bring the values in range [-1.0,1.0].\n\nValues for a pixel in grayscale are in range [0,255],\n\nSo (train images - 127.5) will make 0 to -127.5 and 255 to 127.5\n\nSo every pixel values will be between -127.5 to +127.5\n\nAnd then you divide them by 127.5\n\nIt will put them between -1.0 and +1.0","7cf14f17":"### Experiment utils (RUN ME!)","71306d50":"## Creating the model\nGenerator and Discriminator are defined using [Keras Sequential API] \n\n(https:\/\/www.tensorflow.org\/guide\/keras#sequential_model).","b676e561":"Generator loss function\n\nGenerator's loss function quantifies how well the Discriminator is tricked. \n\nIntuitively, if Generator is running smoothly, Discriminator will classify fake images as real (or 1). Here we will compare the Discriminator's decision on the generated image to a matrix of ones.","b94eb8f5":"#### Portions of this page are reproduced from work created and shared by Google and used according to terms described in the Creative Commons 4.0 Attribution License.","de0613f2":"### Discriminator\nDiscriminator is an image classifier based on Convolutional Neural Network (CNN).","2f631ae5":"### Discriminator Loss Function\n\nThis method quantifies how well the Discriminator determines real images from fake images. \n\nCompare the Discriminator's prediction of the real image with a matrix of 1s, and the Discriminator's prediction of the fake (generated) image with a matrix of 0s.","8ee8a8af":"### Model Traning"}}