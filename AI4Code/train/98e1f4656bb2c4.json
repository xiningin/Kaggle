{"cell_type":{"8988c0f9":"code","c4a53d53":"code","b7c7ae4c":"code","48f2a709":"code","c439847f":"code","f6b204fa":"code","026183b9":"code","66947774":"code","d11045e6":"code","ef4adfd4":"code","a671bafd":"code","7c3524ea":"code","516175d4":"code","e3aa5aad":"code","97e8989d":"code","6fccafc8":"code","522b528e":"code","55a4dbe4":"code","fb978a0e":"code","d726598b":"code","4d668b80":"code","b1652cac":"code","e9066fdd":"code","b71df398":"code","9b29b8c9":"code","178e88f9":"code","258f2f81":"code","242be6d7":"code","b052f894":"code","6be59f80":"code","73fd31b8":"code","088a7330":"code","024903d5":"code","ad67bb89":"code","0545c79a":"code","625b663d":"code","07fa6576":"code","51c03f51":"code","17dd662f":"code","52015c5d":"code","86430bc0":"code","d01162e2":"code","60f27d22":"code","6c96e9ab":"code","1f65eb33":"code","61ec9e67":"code","fc90ba7b":"code","a8a79cb2":"code","989b8c5e":"code","8ee014ac":"code","92c30b01":"code","1cd2aa06":"markdown","50fca5b3":"markdown","fe71ccc5":"markdown","60da7acb":"markdown","9a3e82fd":"markdown","800591cf":"markdown","cb37f182":"markdown","43330fc1":"markdown","c0faa148":"markdown","3620f2bd":"markdown","438dc7f5":"markdown","dd04ded7":"markdown","731ab7cf":"markdown","62fe345b":"markdown","e1338395":"markdown","4e3d64b6":"markdown","111284b3":"markdown","4bb44135":"markdown","66e03742":"markdown","91b491bf":"markdown","97272274":"markdown","be951910":"markdown","d6d9e33b":"markdown","b0d7f730":"markdown","23137733":"markdown","0c17063a":"markdown","6ea35fce":"markdown","e84d1a9b":"markdown","ca816601":"markdown","c4402896":"markdown","091219dc":"markdown","5c9872b5":"markdown","6cdb5cd1":"markdown","b9d30d53":"markdown","19e073be":"markdown","f74f332b":"markdown","3b401f9a":"markdown","3a0f00c8":"markdown","5ddd9f24":"markdown","cbe85e24":"markdown","3c967141":"markdown","1d50582a":"markdown","d1fffb6c":"markdown"},"source":{"8988c0f9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c4a53d53":"data=pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')","b7c7ae4c":"data.columns","48f2a709":"data.head(10)","c439847f":"data.describe()","f6b204fa":"import matplotlib.pyplot as plt","026183b9":"def bar_plot(variable):\n    var =data[variable]\n    varValue = var.value_counts()\n    plt.figure(figsize=(9,3))\n    plt.bar(varValue.index, varValue,color=[\"#C06C84\", \"#5E1742\", \"#005D8E\", \"#00ADB5\",\"#3E606F\",\"#EFAB1F\"])\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    \n    plt.show()\n    print(\"{}: \\n {}\".format(variable,varValue))","66947774":"category1 = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\",\"ca\",\"thal\",\"target\"]\nfor c in category1:\n    bar_plot(c)","d11045e6":"def plot_hist(variable):\n    plt.figure(figsize=(9,3))\n    plt.hist(data[variable], bins=40)\n    plt.xlabel(variable)\n    plt.ylabel(\"frequency\")\n    plt.title(\"{} distrubition with hist\".format(variable))\n    plt.show()","ef4adfd4":"numericVar = [\"age\",\"trestbps\",\"chol\",\"thalach\",\"oldpeak\"]\nfor n in numericVar:\n    plot_hist(n)","a671bafd":"from matplotlib import pyplot\na4_dims = (18, 8)\nfig, ax = pyplot.subplots(figsize=a4_dims)\nsns.countplot(x='age',hue='target',data=data, linewidth=1,ax=ax)","7c3524ea":"data['sex'].value_counts().plot(kind='pie',colors=[\"#EFAB1F\", \"#3E606F\"],autopct='%1.1f%%',figsize=(9,9))\nplt.show\nvarValue = data.sex.value_counts()\nprint(varValue)","516175d4":"a4_dims = (18, 8)\nfig, ax = pyplot.subplots(figsize=a4_dims)\nsns.countplot(x='sex',hue='target',data=data, linewidth=1,ax=ax)","e3aa5aad":"colors = {0:'#cd1076', 1:'#008080'}\nfig, ax = plt.subplots()\ngrouped = data.groupby('target')\nfor key, group in grouped:\n    group.plot(ax=ax, kind='scatter'\n               ,x='thalach', y='age', label=key\n               ,color=colors[key])\nplt.show()","97e8989d":"colors = {0:'#cd1076', 1:'#008080'}\nfig, ax = plt.subplots()\ngrouped = data.groupby('target')\nfor key, group in grouped:\n    group.plot(ax=ax, kind='scatter'\n               ,x='oldpeak', y='age', label=key\n               ,color=colors[key])\nplt.show()","6fccafc8":"colors = {0:'#cd1076', 1:'#008080'}\nfig, ax = plt.subplots()\ngrouped = data.groupby('target')\nfor key, group in grouped:\n    group.plot(ax=ax, kind='scatter'\n               ,x='chol', y='age', label=key\n               ,color=colors[key])\nplt.show()","522b528e":"colors = {0:'#cd1076', 1:'#008080'}\nfig, ax = plt.subplots()\ngrouped = data.groupby('target')\nfor key, group in grouped:\n    group.plot(ax=ax, kind='scatter'\n               ,x='trestbps', y='age', label=key\n               ,color=colors[key])\nplt.show()","55a4dbe4":"# cp vs target\ndata[[\"cp\",\"target\"]].groupby([\"cp\"], as_index = False).mean().sort_values(by=\"target\",ascending = False)","fb978a0e":"# sex vs target\ndata[[\"sex\",\"target\"]].groupby([\"sex\"], as_index = False).mean().sort_values(by=\"target\",ascending = False)","d726598b":"# restecg vs target\ndata[[\"restecg\",\"target\"]].groupby([\"restecg\"], as_index = False).mean().sort_values(by=\"target\",ascending = False)","4d668b80":"# exang vs target\ndata[[\"exang\",\"target\"]].groupby([\"exang\"], as_index = False).mean().sort_values(by=\"target\",ascending = False)","b1652cac":"def detect_outliers(data,features):\n    outlier_indices = []\n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(data[c],25)\n        # 3rd quartile\n        Q3 = np.percentile(data[c],75)\n        # IQR\n        IQR = Q3 - Q1\n        # Outlier step\n        outlier_step = IQR * 1.5\n        # detect outlier and their indeces\n        outlier_list_col = data[(data[c] < Q1 - outlier_step) | (data[c] > Q3 + outlier_step)].index\n        # store indeces\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","e9066fdd":"data.loc[detect_outliers(data,['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'])]","b71df398":"data.head(10)","9b29b8c9":"data_len = len(data)\ndata = pd.concat([data],axis = 0).reset_index(drop = True)","178e88f9":"data.head()","258f2f81":"data.columns[data.isnull().any()]","242be6d7":"data.isnull().sum()","b052f894":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n\ndata[\"target\"] = data.target\nX = data.drop(\"target\",1)\ny = data[\"target\"]\ndata.head()\nplt.figure(figsize=(25,25))\ncor = data.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()\n\ncor_target = abs(cor[\"target\"]) #absolute value\n#High Correlations\nrelevant_features = cor_target[cor_target>0.3]\nrelevant_features","6be59f80":"data.columns\n","73fd31b8":"data1=data[['cp','thalach','exang','oldpeak','slope','ca','thal','target']]\ndata=pd.DataFrame(data1)\n","088a7330":"from sklearn.preprocessing import StandardScaler\nX = data.iloc[:, 0:7]\nY = data.iloc[:, 7]\nnd = StandardScaler()\nnd.fit(X)\nX =nd.transform(X)\nprint(Y)","024903d5":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split,KFold,cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import f1_score\n                  \nX = data.iloc[:, 0:7]\nY = data.iloc[:, 7]\nX_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.2, random_state = 100)\naccuracies ={} \nmeans={}\nrandoms={}","ad67bb89":"#Manual Tuning\nfrom xgboost import XGBClassifier\naccuracy = []\nfor n in range(1,11):\n    xgb =XGBClassifier(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.78,\n                           colsample_bytree=1, max_depth=n)\n    xgb.fit(X_train,y_train)\n    prediction = xgb.predict(X_test)\n    accuracy.append(accuracy_score(y_test, prediction))\nprint(accuracy)    \nplt.plot(range(1,11), accuracy,color='#cd5555')\nplt.xlabel('Max_depth')\nplt.ylabel('Accuracy')\nplt.show()    ","0545c79a":"from sklearn.model_selection import RandomizedSearchCV\nxgb_params = {\n    'learning_rate' : [0.08, 0.06, 0.04, 0.09],      \n    'max_depth': range(1,40),\n    'n_estimators': [100, 200, 300,500,1000]}\nxgb =XGBClassifier()\nxgb_randomcv_model=RandomizedSearchCV(estimator=xgb, param_distributions=xgb_params, n_iter=100, cv=5, scoring='accuracy', n_jobs=-1, verbose=2).fit(X_train,y_train)\nprint(xgb_randomcv_model.best_params_)\nprint('xgb_randomcv_model accuracy = {}'.format(xgb_randomcv_model.best_score_))\nrandom=xgb_randomcv_model.best_score_*100\nrandoms['XGBoost']=random","625b663d":"from sklearn.model_selection import GridSearchCV\nxgb_params = { 'learning_rate' : [0.08, 0.06, 0.04, 0.09],      \n    'max_depth': range(1,40),\n    'n_estimators': [100, 200, 300,500,1000]}\nxgb =XGBClassifier()\nxgb_gridcv_model = GridSearchCV(estimator=xgb, param_grid=xgb_params, cv=5, scoring='accuracy', n_jobs=-1, verbose=2).fit(X_train,y_train)\nprint(xgb_gridcv_model.best_params_)\nprint('xgb gridcv model accuracy score = {}'.format(xgb_gridcv_model.best_score_))\nacc=xgb_gridcv_model.best_score_ *100\naccuracies[' XGBoost Gridsearch']=acc","07fa6576":"kfold=model_selection.KFold(n_splits=5)\nmodelL=XGBClassifier(n_estimators=100, max_depth=11,learning_rate=0.09)\nresults=model_selection.cross_val_score(modelL,X,Y,cv=kfold)\nprint(results)\nprint(results.mean()*100)\nmean=results.mean()*100\nmeans['XGBoost']=mean","51c03f51":"from sklearn.tree import DecisionTreeClassifier\ndt_params = {'min_weight_fraction_leaf' : [0.0 , 0.2 , 0.4 , 0.6 ,0.8],\n   'max_depth': range(1,40),\n    'max_features': range(1,40),\n    'min_samples_leaf': range(1,40),\n    'max_leaf_nodes' : range(1,40)\n    \n    }\ndt=DecisionTreeClassifier()\ndt_randomcv_model=RandomizedSearchCV(estimator=dt, param_distributions=dt_params, n_iter=100, cv=5, scoring='accuracy', n_jobs=-1, verbose=2).fit(X_train,y_train)\nprint(dt_randomcv_model.best_params_)\nprint('dt_randomcv_model accuracy score = {}'.format(dt_randomcv_model.best_score_))\nrandom=dt_randomcv_model.best_score_*100\nrandoms['Decision Tree']=random","17dd662f":"kfold=model_selection.KFold(n_splits=5)\nmodelL=DecisionTreeClassifier(min_weight_fraction_leaf=0.0,max_features=3, min_samples_leaf=15,max_depth=7,max_leaf_nodes=28)\nresults=model_selection.cross_val_score(modelL,X,Y,cv=kfold)\nprint(results)\nprint(results.mean()*100)\nmean=results.mean()*100\nmeans['Decision Tree']=mean","52015c5d":"rf_params = {\n   'max_depth': range(1,40),\n    'max_features': range(1,40),\n    'min_samples_leaf': range(1,20),\n    'min_samples_split': range(1,20),\n    'n_estimators': [100, 200, 300,500,1000]}\nrf=RandomForestClassifier()\nrf_randomcv_model=RandomizedSearchCV(estimator=rf, param_distributions=rf_params, n_iter=20, cv=5, scoring='accuracy', n_jobs=-1, verbose=2).fit(X_train,y_train)\nprint(rf_randomcv_model.best_params_)\nprint('rf_randomcv_model accuracy score = {}'.format(rf_randomcv_model.best_score_))\nrandom=rf_randomcv_model.best_score_*100\nrandoms['Random Forest']=random\n","86430bc0":"kfold=model_selection.KFold(n_splits=5)\nmodelL=RandomForestClassifier(n_estimators=100,min_samples_split=14, min_samples_leaf=4,max_depth=7)\nresults=model_selection.cross_val_score(modelL,X,Y,cv=kfold)\nprint(results)\nprint(results.mean()*100)\nmean=results.mean()*100\nmeans['Random Forest']=mean","d01162e2":"from sklearn.neighbors import KNeighborsClassifier\nknn_params = {'n_neighbors' : range(1,10)\n   }\nknn=KNeighborsClassifier()\nknn_randomcv_model=RandomizedSearchCV(estimator=knn, param_distributions=knn_params, n_iter=100, cv=5, scoring='accuracy', n_jobs=-1, verbose=2).fit(X_train,y_train)\nprint(knn_randomcv_model.best_params_)\nprint('knn_randomcv_model accuracy score = {}'.format(knn_randomcv_model.best_score_))\nrandom=knn_randomcv_model.best_score_*100\nrandoms['KNN']=random\n","60f27d22":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nknn_params = {'n_neighbors' : range(1,10),\n              'weights' : ['uniform', 'distance'],\n              'algorithm' : ['auto','ball_tree','kd_tree','brute'],\n              'p' : [1,2]\n   }\nknn=KNeighborsClassifier()\nknn_gridcv_model=GridSearchCV(estimator=knn, param_grid=knn_params, cv=5, scoring='accuracy', n_jobs=-1, verbose=2).fit(X_train,y_train)\nprint(knn_gridcv_model.best_params_)\nprint('knn_randomcv_model accuracy score = {}'.format(knn_gridcv_model.best_score_)) \nacc=knn_gridcv_model.best_score_ *100\naccuracies['KNN Gridsearch']=acc","6c96e9ab":"kfold=model_selection.KFold(n_splits=5)\nmodelL=KNeighborsClassifier(n_neighbors= 1)\nresults=model_selection.cross_val_score(modelL,X,Y,cv=kfold)\nprint(results)\nprint(results.mean()*100)\nmean=results.mean()*100\nmeans['KNN']=mean","1f65eb33":"from sklearn.svm import SVC\nsvc_params= {'C' : [0.1,0.2,0.3,0.001,0.003],\n             'kernel': ['linear','poly','rbf','sigmoid']}\nsvc=SVC()\nsvc_gridcv_model=GridSearchCV(estimator=svc, param_grid=svc_params, cv=5, scoring='accuracy', n_jobs=-1, verbose=2).fit(X_train,y_train)\nprint(svc_gridcv_model.best_params_)\nprint('rf_gridcv_model accuracy score = {}'.format(svc_gridcv_model.best_score_))\nacc=svc_gridcv_model.best_score_ *100\naccuracies['SVC Gridsearch']=acc","61ec9e67":"kfold=model_selection.KFold(n_splits=5)\nmodel=SVC(C=0.1,kernel='linear')\nresults=model_selection.cross_val_score(model,X,Y,cv=kfold)\nprint(results)\nprint(results.mean()*100)\nmean=results.mean()*100\nmeans['SVC']=mean","fc90ba7b":"from sklearn.linear_model import Perceptron\npr_params= {'penalty' : ['l2','l1','elasticnet','None'],\n             'alpha': [0.0001,0.001,0.0002,0.0004,0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3],\n           'max_iter': [50,100,250,1000]}\npr=Perceptron()\npr_gridcv_model=GridSearchCV(estimator=pr, param_grid=pr_params, cv=5, scoring='accuracy', n_jobs=-1, verbose=2).fit(X_train,y_train)\nprint(pr_gridcv_model.best_params_)\nprint('pr_gridcv_model accuracy score = {}'.format(pr_gridcv_model.best_score_)) \nacc=pr_gridcv_model.best_score_ *100\naccuracies['Perceptron Gridsearch']=acc","a8a79cb2":"kfold=model_selection.KFold(n_splits=5)\nmodel=Perceptron(alpha=0.0003,max_iter=50,penalty='l1')\nresults=model_selection.cross_val_score(model,X,Y,cv=kfold)\nprint(results)\nprint(results.mean()*100)\nmean=results.mean()*100\nmeans['Perceptron']=mean","989b8c5e":"colors = [\"#00008b\", \"#00e5ee\", \"#cd1076\", \"#008080\",\"#cd5555\"]\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(16,5))\nplt.yticks(np.arange(0,100,5))\nplt.ylabel(\"Accuracy %\")\nplt.xlabel(\"\\n\\n Algorithms\")\nsns.barplot(x=list(randoms.keys()), y=list(randoms.values()), palette=colors)\nplt.show()","8ee014ac":"colors = [\"#C06C84\", \"#5E1742\", \"#005D8E\"]\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(16,5))\nplt.yticks(np.arange(0,101,5))\nplt.ylabel(\"GridSearch Scores%\")\nplt.xlabel(\"\\n\\n Algorithms\")\nsns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()), palette=colors)\nplt.show()","92c30b01":"colors = [\"#C06C84\", \"#5E1742\", \"#005D8E\", \"#00ADB5\",\"#3E606F\",\"#EFAB1F\"]\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(16,5))\nplt.yticks(np.arange(0,101,5))\nplt.ylabel(\"Cross Validation Scores %\")\nplt.xlabel(\"\\n\\n Algorithms\")\nsns.barplot(x=list(means.keys()), y=list(means.values()), palette=colors)\nplt.show()","1cd2aa06":"## Cross Validation","50fca5b3":"<a id = \"23\"><\/a><br>\n# Let's look at the distribution of variables according to the target.","fe71ccc5":"![1_dEXTHHEDCPu9ZZORpECaXA.jpeg](attachment:1_dEXTHHEDCPu9ZZORpECaXA.jpeg)","60da7acb":" <a id = \"10\"><\/a><br>\n # Algorithms   \n   *          [Xgboost Classifier](#11)\n   *          [Decision Tree](#12)\n   *          [Random Forest](#13)\n   *          [KNN](#14) \n   *          [Support Vector Classifier](#15) \n   *          [Perceptron](#18)","9a3e82fd":"<a id = \"6\"><\/a><br>\n# Basic Data Analysis","800591cf":"## Randomized Search CV","cb37f182":"## Grid Search CV","43330fc1":"# Heart Disease","c0faa148":"<a id = \"3\"><\/a><br>\n# Univariate Variable Analysis\n* Categorical Variables: sex,cp, fbs,restecg,exang,slope,ca,thal,target\n* Numerical Variables: trestbps, chol,thalach, oldpeak","3620f2bd":"<a id = \"8\"><\/a><br>\n # Missing Value\n* Find Missing Value\n","438dc7f5":"<a id = \"5\"><\/a><br>\n## Numerical Variable","dd04ded7":"# Grid Search CV","731ab7cf":"<a id = \"4\"><\/b><br>\n## Categorical Variable ","62fe345b":"## Grid Search CV","e1338395":"## Cross Validation","4e3d64b6":"<a id = \"9\"><\/a><br>\n## Find Missing Value","111284b3":"<a id = \"22\"><\/a><br>\n    \n# Normalization","4bb44135":"<a id = \"7\"><\/a><br>\n# Outlier Detection","66e03742":"#  Comparison Grid Search CV Scores","91b491bf":"## 68.3 percent of our data are men.","97272274":"## Cross Validation","be951910":"## Randomized Search CV","d6d9e33b":"## Randomized Search CV","b0d7f730":"## The disease is intense between the ages of 41-45 and 51-58.","23137733":"# Comparison Cross Validation Scores","0c17063a":"![original.jpeg](attachment:original.jpeg)","6ea35fce":"<a id = \"14\"><\/a><br>\n # KNN","e84d1a9b":"## Grid Search CV","ca816601":"<a id = \"1\"><\/a><br>\n# Load and check data","c4402896":"<a id = \"13\"><\/a><br>\n # Random Forest","091219dc":"<a id = \"15\"><\/a><br>\n# Support Vector Classifier","5c9872b5":"<a id = \"12\"><\/a><br>\n # Decision Tree","6cdb5cd1":"## The disease is more common in those whose *thalach* value is less than 160.","b9d30d53":"## Randomized Search CV","19e073be":"<a id = \"11\"><\/a><br>\n# XGBoost Classifier","f74f332b":"<a id = \"16\"><\/a><br>\n# Comparison of Randomized Search CV Scores","3b401f9a":"## Cross Validation","3a0f00c8":"<font color = '#EFAB1F'>\nContent:\n    \n1. [Load and check data](#1)\n3. [Univariate Variable Analysis](#3)\n    *          [Categorical Variable ](#4)\n    *          [Numerical Variable ](#5)\n1. [Visualization of Variables](#23)    \n1. [Basic Data Analysis](#6)    \n1. [Outlier Detection](#7)    \n1. [Missing Value](#8)\n    *          [Find Missing Value](#9)\n1. [Pearson Correlation Coefficient](#20)   \n1. [Normalization](#22)    \n1. [Algorithms](#10) \n    *          [Xgboost Classifier](#11)\n    *          [Decision Tree](#12)\n    *          [Random Forest](#13)\n    *          [KNN](#14) \n    *          [Support Vector Classifier](#15) \n    *          [Perceptron](#18)\n1. [Comparison of Randomized Search CV Scores](#16)  \n1. [Comparison of Grid Search CV Scores](#17)  \n1. [Comparison of Cross Validation Scores](#18)  \n    \n    ","5ddd9f24":"1. age\n1. sex\n1. chest pain type (4 values)\n1. resting blood pressure\n1. serum cholestoral in mg\/dl\n1. fasting blood sugar > 120 mg\/dl\n1. resting electrocardiographic results (values 0,1,2)\n1. maximum heart rate achieved\n1. exercise induced angina\n1. oldpeak = ST depression induced by exercise relative to rest\n1. the slope of the peak exercise ST segment\n1. number of major vessels (0-3) colored by flourosopy\n1. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect","cbe85e24":"# Pearson Correlation Coefficient","3c967141":"<a id = \"18\"><\/a><br>\n# Neural Network(Perceptron)\n","1d50582a":"## Cross Validation","d1fffb6c":"* cp - target\n* sex - target\n* restecg - fbs\n* exang - target"}}