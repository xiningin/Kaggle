{"cell_type":{"330d2123":"code","96c14503":"code","1c04de40":"code","426fff5f":"code","2d0fe408":"code","32ebbfa9":"code","87f6d9ac":"code","3189d1a2":"code","c70d2039":"code","9f8f4135":"code","1dd7f223":"code","a6860a01":"code","23311b99":"code","d24db2f3":"code","09d8ea41":"code","78f21dfb":"code","2029b28e":"code","94fadb71":"markdown","53aa72a6":"markdown","82da6a32":"markdown","16c93562":"markdown","b8b25a3f":"markdown","7f0acc4f":"markdown","c0f1e2af":"markdown","7f950791":"markdown"},"source":{"330d2123":"import pandas as pd\n# *XGBoost** is the leading model for working with standard tabular data (the type of data you store in Pandas DataFrames)\nfrom xgboost import XGBRegressor\n# Mean absolute error regression loss\nfrom sklearn.metrics import mean_absolute_error\n# Split arrays or matrices into random train and test subsets\nfrom sklearn.model_selection import train_test_split\n# Imputation transformer for completing missing values.\nfrom sklearn.impute import SimpleImputer","96c14503":"# path to the file to read\niowa_file_path = '..\/input\/train.csv'\niowa_file_path_test ='..\/input\/test.csv'\n# read into a PD DataFrame\nhome_data = pd.read_csv(iowa_file_path)\nhome_data_test = pd.read_csv(iowa_file_path_test)\n\n#Save the 'Id' column\ntrain_ID = home_data['Id']\ntest_ID = home_data_test['Id']\n\n#droping ID column\nhome_data.drop(\"Id\", axis = 1, inplace = True)\nhome_data_test.drop(\"Id\", axis = 1, inplace = True)\n\n# keep original shape\nntrain = home_data.shape[0]\nntest = home_data_test.shape[0]\n\n# save target\nhome_target = home_data.SalePrice.values\n\n# Concat data to prepare for one_hot_encoding\nall_data = pd.concat((home_data, home_data_test)).reset_index(drop=True)\n\n#drop SalePrice column\nall_data.drop(['SalePrice'], axis=1, inplace=True)\nprint(\"all_data size is : {}\".format(all_data.shape))","1c04de40":"all_data_na = (all_data.isnull().sum() \/ len(all_data)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_data.head(20)","426fff5f":"all_data[\"PoolQC\"] = all_data[\"PoolQC\"].fillna(\"None\")\nall_data[\"MiscFeature\"] = all_data[\"MiscFeature\"].fillna(\"None\")\nall_data[\"Alley\"] = all_data[\"Alley\"].fillna(\"None\")\nall_data[\"Fence\"] = all_data[\"Fence\"].fillna(\"None\")\nall_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].fillna(\"None\")\n#Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\nall_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\nfor col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    all_data[col] = all_data[col].fillna('None')\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    all_data[col] = all_data[col].fillna(0)\nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    all_data[col] = all_data[col].fillna(0)\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    all_data[col] = all_data[col].fillna('None')\nall_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\nall_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\nall_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\nall_data = all_data.drop(['Utilities'], axis=1)\nall_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\nall_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\nall_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\nall_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\nall_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\nall_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\nall_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")","2d0fe408":"#Check remaining missing values if any \nall_data_na = (all_data.isnull().sum() \/ len(all_data)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_data.head()","32ebbfa9":"#MSSubClass=The building class\nall_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n\n\n#Changing OverallCond into a categorical variable\nall_data['OverallCond'] = all_data['OverallCond'].astype(str)\n\n\n#Year and month sold are transformed into categorical features.\nall_data['YrSold'] = all_data['YrSold'].astype(str)\nall_data['MoSold'] = all_data['MoSold'].astype(str)","87f6d9ac":"# \"cardinality\" means the number of unique values in a column.\n# We use it as our only way to select categorical columns here. \n\nlow_cardinality_cols = [cname for cname in all_data.columns if \n                                all_data[cname].nunique() < 10 and\n                                all_data[cname].dtype == \"object\"]\nnumeric_cols = [cname for cname in all_data.columns if \n                                all_data[cname].dtype in ['int64', 'float64']]\nmy_cols = low_cardinality_cols + numeric_cols\nall_data = all_data[my_cols]","3189d1a2":"all_data_encoded = pd.get_dummies(all_data)\nprint(all_data_encoded.shape)","c70d2039":"home_data = all_data_encoded[:ntrain]\nhome_data_test = all_data_encoded[ntrain:]","9f8f4135":"X_train, X_test, y_train, y_test = train_test_split(home_data, home_target, train_size=0.7, test_size=0.3, random_state=0) ","1dd7f223":"# Shape after droping categorical columns with nunique >= 10\nprint(X_train.shape)\nprint(X_test.shape)","a6860a01":"# check out the header after encoding\nX_train.head()","23311b99":"## use Imputer to fill in missing data\n#my_imputer = SimpleImputer()\n#imputed_X_train = my_imputer.fit_transform(X_train)\n#imputed_X_test = my_imputer.transform(X_test)","d24db2f3":"my_model = XGBRegressor(n_estimator=200)\nmy_model.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_test, y_test)],verbose=False)","09d8ea41":"predictions = my_model.predict(X_test)\nprint(\"Mean Absolute Error : \" + str(mean_absolute_error(predictions, y_test)))\n","78f21dfb":"# predict on test data and submit\npred_test = my_model.predict(home_data_test)\nprint(pred_test)","2029b28e":"#Submission:\nsub = pd.DataFrame()\nsub['Id'] = test_ID\nsub['SalePrice'] = pred_test\nsub.to_csv('submission.csv', index=False)","94fadb71":"### XGBoost and One Hot Encoding\nImprove model by using Gradient Boosting Decision and include Categorical features. Code and other documentation can be found at \n[Learn Machine Learning](https:\/\/www.kaggle.com\/dansbecker\/learn-machine-learning) series","53aa72a6":"### Getting the new train and test sets.","82da6a32":"### Initialize the model\n**n_estimators** specifies how many times to go through the modeling\n**early_stopping_rounds** offers a way to automatically find the ideal value. Early stopping causes the model to stop iterating when the validation score stops improving, even if we aren't at the hard stop for n_estimators.","16c93562":"### One-Hot Encoding\nOne hot encoding is the most widespread approach, and it works very well unless your categorical variable takes on a large number of values (i.e. you generally won't it for variables taking more than 15 different values. It'd be a poor choice in some cases with fewer values, though that varies.)\nOne hot encoding creates new (binary) columns, indicating the presence of each possible value from the original data","b8b25a3f":"**Object** indicates a column has text (there are other things it could be theoretically be, but that's unimportant for our purposes). It's most common to one-hot encode these \"object\" columns, since they can't be plugged directly into most models.  Pandas offers a convenient function called **get_dummies** to get one-hot encodings","7f0acc4f":"### Split train and test data","c0f1e2af":"### More Feature Engineering\nTransforming some numerical variables that are really categorical","7f950791":"### Fill in missing values\nPoolQC : data description says NA means \"No Pool\". That make sense, given the huge ratio of missing value (+99%) and majority of houses have no Pool at all in general.\n\nMiscFeature : data description says NA means \"no misc feature\"\n\nAlley : data description says NA means \"no alley access\"\n\nFence : data description says NA means \"no fence\"\n\nFireplaceQu : data description says NA means \"no fireplace\"\n\nLotFrontage : Since the area of each street connected to the house property most likely have a similar area to other houses in its neighborhood , we can fill in missing values by the median LotFrontage of the neighborhood.\n\nGarageType, GarageFinish, GarageQual and GarageCond : Replacing missing data with None\n\nGarageYrBlt, GarageArea and GarageCars : Replacing missing data with 0 (Since No garage = no cars in such garage.)\n\nBsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtFullBath and BsmtHalfBath : missing values are likely zero for having no basement\n\nBsmtQual, BsmtCond, BsmtExposure, BsmtFinType1 and BsmtFinType2 : For all these categorical basement-related features, NaN means that there is no basement.\n\nMasVnrArea and MasVnrType : NA most likely means no masonry veneer for these houses. We can fill 0 for the area and None for the type.\n\nMSZoning (The general zoning classification) : 'RL' is by far the most common value. So we can fill in missing values with 'RL'\n\nUtilities : For this categorical feature all records are \"AllPub\", except for one \"NoSeWa\" and 2 NA . Since the house with 'NoSewa' is in the training set, this feature won't help in predictive modelling. We can then safely remove it.\n\nFunctional : data description says NA means typical\n\nElectrical : It has one NA value. Since this feature has mostly 'SBrkr', we can set that for the missing value.\n\nKitchenQual: Only one NA value, and same as Electrical, we set 'TA' (which is the most frequent) for the missing value in KitchenQual.\n\nExterior1st and Exterior2nd : Again Both Exterior 1 & 2 have only one missing value. We will just substitute in the most common string\n\nSaleType : Fill in again with most frequent which is \"WD\"\n\nMSSubClass : Na most likely means No building class. We can replace missing values with None"}}