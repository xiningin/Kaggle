{"cell_type":{"fb447da7":"code","978e14ca":"code","a2b3ae34":"code","d0043e6c":"code","a3a80eb8":"code","61b51e14":"code","6e872f8e":"code","3666f66c":"code","d64aeaba":"code","381ed69b":"code","5dc691f6":"code","2ddd91a0":"code","72eef3e5":"code","0cae9047":"code","b8959da3":"code","ded7711d":"code","706e28d7":"code","e9cb3d07":"code","7a1c5ce7":"markdown"},"source":{"fb447da7":"!pip install tslearn","978e14ca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy\nfrom tslearn.clustering import TimeSeriesKMeans\nfrom tslearn.datasets import CachedDatasets\nfrom tslearn.preprocessing import TimeSeriesScalerMeanVariance, \\\n    TimeSeriesResampler\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.pyplot as plt \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nseed = 0\nnumpy.random.seed(seed)","a2b3ae34":"# read data\ndf = pd.read_csv('\/kaggle\/input\/electric-motor-temperature\/pmsm_temperature_data.csv')\ndf\n","d0043e6c":"X_train=df['ambient'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")\n","a3a80eb8":"X_train=df['coolant'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","61b51e14":"X_train=df['u_d'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","6e872f8e":"X_train=df['u_q'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","3666f66c":"X_train=df['motor_speed'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","d64aeaba":"X_train=df['torque'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","381ed69b":"X_train=df['i_d'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","5dc691f6":"X_train=df['i_q'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","2ddd91a0":"X_train=df['pm'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","72eef3e5":"X_train=df['stator_yoke'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","0cae9047":"X_train=df['stator_tooth'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","b8959da3":"X_train=df['stator_winding'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","ded7711d":"\nX_train=df['profile_id'].values\nX_train=X_train[:998000]\nX_train=np.reshape(X_train, (998, 1000))\nX_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\nX_train = TimeSeriesResampler(sz=1000).fit_transform(X_train)\nsz = X_train.shape[1]\n\n# Euclidean k-means\nprint(\"Euclidean k-means\")\nkm = TimeSeriesKMeans(n_clusters=36, verbose=True, random_state=seed)\ny_pred = km.fit_predict(X_train)\n\n#plt.figure()\nplt.figure(figsize=(50,25))\nfor yi in range(36):\n\n    plt.subplot(6, 6, yi + 1)\n    \n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Euclidean $k$-means\")","706e28d7":"\n# DBA-k-means\nprint(\"DBA k-means\")\ndba_km = TimeSeriesKMeans(n_clusters=3,\n                          n_init=2,\n                          metric=\"dtw\",\n                          verbose=True,\n                          max_iter_barycenter=10,\n                          random_state=seed)\ny_pred = dba_km.fit_predict(X_train)\n\nfor yi in range(3):\n    plt.subplot(3, 3, 4 + yi)\n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(dba_km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"DBA $k$-means\")","e9cb3d07":"# Soft-DTW-k-means\nprint(\"Soft-DTW k-means\")\nsdtw_km = TimeSeriesKMeans(n_clusters=3,\n                           metric=\"softdtw\",\n                           metric_params={\"gamma\": .01},\n                           verbose=True,\n                           random_state=seed)\ny_pred = sdtw_km.fit_predict(X_train)\n\nfor yi in range(3):\n    plt.subplot(3, 3, 7 + yi)\n    for xx in X_train[y_pred == yi]:\n        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n    plt.plot(sdtw_km.cluster_centers_[yi].ravel(), \"r-\")\n    plt.xlim(0, sz)\n    plt.ylim(-4, 4)\n    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n             transform=plt.gca().transAxes)\n    if yi == 1:\n        plt.title(\"Soft-DTW $k$-means\")\n\nplt.tight_layout()\nplt.show()","7a1c5ce7":"**Parametric Analysis based on behavior **\n\nResearch is available showing that Temperature has significant effect on the performance of motor.\n\nhttps:\/\/ieeexplore.ieee.org\/abstract\/document\/7732809\/\n\nFrom above research it has been concluded that\n\n* The torque produced by the motor decreases in inverse proportion to the increased magnet temperature.\n* Motor reaches steady state speed faster in lower magnetic temperature\n* It was observed that there was an increase in the phase currents that the motor drew along with the increased magnet temperature.\n\n"}}