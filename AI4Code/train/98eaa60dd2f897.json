{"cell_type":{"f6543ae7":"code","fa771715":"code","3a9b1d01":"code","3ef69d3d":"code","9d12796f":"code","b111660c":"code","78e97e5a":"code","9cbcc49e":"code","d72d825f":"code","ef1a5a5b":"code","b5db41bb":"code","9921ec06":"code","69d8458d":"code","db3fdc11":"markdown","fc81adaf":"markdown","c966847c":"markdown","882f5c83":"markdown","b72de065":"markdown","00c529de":"markdown","d10114b4":"markdown","60d3ad44":"markdown","fe88ab48":"markdown","a7a75722":"markdown","a7ce59b0":"markdown","5dab65a3":"markdown"},"source":{"f6543ae7":"import random\nimport glob\nimport gc\nfrom itertools import product\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom matplotlib import pyplot as plt\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('max_colwidth', None)","fa771715":"order_book_train_files = glob.glob('..\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/*')\nstock_ids = [stock.split('=')[1] for stock in order_book_train_files]\ndf_order_book_train_files = pd.DataFrame({'stock_id': stock_ids,'stock_path': order_book_train_files})\ndf_order_book_train_files.head()","3a9b1d01":"def calculate_wap(df):\n    a = df['bid_price1'] * df['ask_size1']\n    b = df['ask_price1'] * df['bid_size1']\n    c = df['bid_size1'] + df['ask_size1']\n    return (a + b) \/ c\n\ndef log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff()","3ef69d3d":"def abs_log_returns_topn(list_file, n_top):\n    '''Returns log returns for top n stocks from shuffled stock list'''\n    df_list = []\n    for stock_file in list_file[:n_top]:\n        df_book_data = pd.read_parquet(stock_file)\n        df_book_data['wap'] = calculate_wap(df_book_data) \n        df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n        df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n        df_book_data['log_return'] = df_book_data['log_return'].apply(abs)\n        df_book_data['stock_id'] = int(stock_file.split('=')[1])\n        df_list.append(df_book_data)\n    df = pd.concat(df_list, ignore_index=True)\n    return df","9d12796f":"# Randomly shuffle the stocks\nrandom.shuffle(order_book_train_files)\n\n# Get log returns for 5 stocks sample\ndf_log_returns = abs_log_returns_topn(order_book_train_files, 5)\n\nselected_stocks = df_log_returns['stock_id'].unique()\nprint('Stock Ids:', ', '.join(str(s) for s in selected_stocks))","b111660c":"df_log_returns['stock_id'].value_counts()","78e97e5a":"def plot_auto_correlation(series, lags=30, stock=''):\n    plt.rcParams[\"figure.figsize\"] = 20, 5\n    fig, axes = plt.subplots(1, 2)\n    acf = plot_acf(series, lags=lags, ax = axes[0])\n    pacf = plot_pacf(series, lags=lags, ax = axes[1])\n    acf.suptitle(f'Autocorrelation and Partial Autocorrelation - stock {stock}', fontsize=20)\n    plt.show()","9cbcc49e":"for stock_id in selected_stocks:\n    df_log_returns_stock = df_log_returns[df_log_returns['stock_id'] == stock_id]\n    random_time_id = random.choice(df_log_returns_stock['time_id'].unique())\n    df_time_slice = df_log_returns_stock[df_log_returns_stock['time_id'] == random_time_id]\n    plot_auto_correlation(df_time_slice['log_return'], stock=stock_id)","d72d825f":"arima_order = []\nfor stock_id in selected_stocks:\n    for order_seq in product((2, 1, 0), repeat=3):\n        if order_seq == (0, 0, 0):     #ARIMA(0,0,0) model is white noise \n            continue\n        try:\n            df_log_returns_stock = df_log_returns[df_log_returns['stock_id'] == stock_id]\n            # Slicing random time period to train ARIMA model\n            random_time_id = random.choice(df_log_returns_stock['time_id'].unique())\n            df_time_slice = df_log_returns_stock[df_log_returns_stock['time_id'] == random_time_id]\n            arima_model = ARIMA(df_time_slice['log_return'], order = order_seq)\n            results_ARIMA = arima_model.fit(disp=-1)\n            arima_order.append([stock_id, order_seq, results_ARIMA.aic])\n            # print(f'{order_seq} AIC: {results_ARIMA.aic}')\n        except:\n            pass\ndf_arima_order = pd.DataFrame(arima_order, columns=['stock_id', 'order', 'aic'])","ef1a5a5b":"df_arima_order_min = pd.merge(df_arima_order.groupby('stock_id')['aic'].min().reset_index(),\n                          df_arima_order, \n                          how='left', \n                          on=['stock_id','aic'])\ndf_arima_order_min","b5db41bb":"def plot_resid_sqr(series, stock_id='', time_id=''):\n    plt.rcParams[\"figure.figsize\"] = 20, 5\n    plt.plot(series.values)\n    plt.title(f'Squared Residial Plot - stock {stock_id} - time_id {time_id}', fontsize=14)\n    plt.ylabel('Squared Residial', fontsize=14)\n    plt.show()","9921ec06":"for idx, row in df_arima_order_min.iterrows():\n    stock_id = row['stock_id']\n    df_log_returns_stock = df_log_returns[df_log_returns['stock_id'] == stock_id]\n    # Slicing random time period to train ARIMA model\n    random_time_id = random.choice(df_log_returns_stock['time_id'].unique())\n    df_time_slice = df_log_returns_stock[df_log_returns_stock['time_id'] == random_time_id]\n    arima_model = ARIMA(df_time_slice['log_return'], order = row['order'])\n    results_ARIMA = arima_model.fit(disp=-1)\n    sqr_resid = np.power(results_ARIMA.resid, 2)\n    plot_resid_sqr(sqr_resid, stock_id, random_time_id)","69d8458d":"for idx, row in df_arima_order_min.iterrows():\n    stock_id = row['stock_id']\n    df_log_returns_stock = df_log_returns[df_log_returns['stock_id'] == stock_id]\n    # Slicing random time period to train ARIMA model\n    random_time_id = random.choice(df_log_returns_stock['time_id'].unique())\n    df_time_slice = df_log_returns_stock[df_log_returns_stock['time_id'] == random_time_id]\n    arima_model = ARIMA(df_time_slice['log_return'], order = row['order'])\n    results_ARIMA = arima_model.fit(disp=-1)\n    sqr_resid = np.power(results_ARIMA.resid, 2)\n    plot_auto_correlation(sqr_resid, stock=stock_id)","db3fdc11":"**Finding order sequence for ARIMA model**","fc81adaf":"Each record in the dataframe contains a parquet file path that has book data about that particular stock","c966847c":"Looking at the PACF plots for absolute log returns, there's a lag of either 1 or 2, meaning that all the higher-order autocorrelations can be explained by lag-1 & lag-2 autocorrelations. Let's have a look at ARIMA model and try to find if volatility clusters exist","882f5c83":"### ACF\/PACF Plots","b72de065":"# Volatility Clustering","00c529de":"### Train data","d10114b4":"### Volatility Clustering in Squared Residuals","60d3ad44":"**Looking at the squared residual plots, there definitely seems to be volatility clustering found in data, though the degree of clustering vary depending on stock and time_id. Let's have a look at the auto correlations for squared residuals**","fe88ab48":"### Input\n\nWe will be using **randomly sampled stocks** and a **random time span**(singe time_id) to look at the volatility clusters.","a7a75722":"### Log Return","a7ce59b0":"Different stocks seem to follow different ARIMA orders. Let's try plugging these order numbers in the model and see if there's volatility clustering in squared residuals","5dab65a3":"**ACF\/PACF of Squared residuals also show the lag-1 & lag-2 auto-correlation. Looks like we can use both to experiment with GARCH models.**"}}