{"cell_type":{"11314e6b":"code","1fd74b97":"code","cbb0670a":"code","a271526e":"code","a62a3b0c":"code","612b452b":"code","76f0eb50":"code","28f16f08":"code","85763275":"code","4d6f21bb":"code","d40e31ed":"code","cfdf827d":"code","01196d20":"code","d598b8b8":"code","fa615bc7":"code","251a7021":"code","34b1f2ce":"code","3ab29f0b":"code","9ec208fa":"code","1576e485":"code","6e808d58":"code","8cf8ffbe":"code","975d90a9":"code","785fab11":"code","28951327":"code","fde0bac7":"code","acc59739":"code","299b096d":"code","34bf713a":"code","f18b8b82":"code","e2d717f3":"code","1b9ebe82":"code","b288236d":"code","aa0bd89f":"code","4fbb9b05":"code","861ce7b7":"markdown","4107bf3e":"markdown","a0e4eb8b":"markdown","7b111554":"markdown","ce2ef1fd":"markdown","5200f9fa":"markdown","5a808f72":"markdown","df9a83c6":"markdown","c306c29c":"markdown"},"source":{"11314e6b":"#Importing required packages.\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n%matplotlib inline","1fd74b97":"#Loading dataset\nwine = pd.read_csv('..\/input\/winequality-red.csv')","cbb0670a":"#Let's check how the data is distributed\nwine.head()","a271526e":"#Information about the data columns\nwine.info()","a62a3b0c":"# #Here we see that fixed acidity does not give any specification to classify the quality.\n# fig = plt.figure(figsize = (10,6))\n# sns.barplot(x = 'quality', y = 'fixed acidity', data = wine)","612b452b":"# #Here we see that its quite a downing trend in the volatile acidity as we go higher the quality \n# fig = plt.figure(figsize = (10,6))\n# sns.barplot(x = 'quality', y = 'volatile acidity', data = wine)","76f0eb50":"# #Composition of citric acid go higher as we go higher in the quality of the wine\n# fig = plt.figure(figsize = (10,6))\n# sns.barplot(x = 'quality', y = 'citric acid', data = wine)","28f16f08":"# fig = plt.figure(figsize = (10,6))\n# sns.barplot(x = 'quality', y = 'residual sugar', data = wine)","85763275":"# #Composition of chloride also go down as we go higher in the quality of the wine\n# fig = plt.figure(figsize = (10,6))\n# sns.barplot(x = 'quality', y = 'chlorides', data = wine)","4d6f21bb":"# #Making binary classificaion for the response variable.\n# #Dividing wine as good and bad by giving the limit for the quality\n# bins = (2, 6.5, 8)\n# group_names = ['bad', 'good']\n# wine['quality'] = pd.cut(wine['quality'], bins = bins, labels = group_names)","d40e31ed":"# #Now lets assign a labels to our quality variable\n# label_quality = LabelEncoder()","cfdf827d":"# #Bad becomes 0 and good becomes 1 \n# wine['quality'] = label_quality.fit_transform(wine['quality'])","01196d20":"# wine['quality'].value_counts()","d598b8b8":"# sns.countplot(wine['quality'])","fa615bc7":"#Now seperate the dataset as response variable and feature variabes\nX = wine.drop('quality', axis = 1)\ny = wine['quality']","251a7021":"#Train and Test splitting of data \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","34b1f2ce":"#Applying Standard scaling to get optimized result\nsc = StandardScaler()","3ab29f0b":"# X_train","9ec208fa":"X_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)\n","1576e485":"rfc = RandomForestClassifier(n_estimators=200)\nrfc.fit(X_train, y_train)\npred_rfc = rfc.predict(X_test)","6e808d58":"pred_rfc","8cf8ffbe":"quality = []\n\nfor pr in pred_rfc:\n    if pr >6:\n        quality.append(\"good\")\n    elif pr==6:\n        quality.append(\"normal\")\n    else:\n        quality.append(\"bad\")","975d90a9":"id =[]\nfor i in range(len(pred_rfc)):\n    id.append(i+1)","785fab11":"submit = pd.DataFrame()","28951327":"submit['id'] = id \nsubmit['taste'] = quality","fde0bac7":"submit.to_csv(\"answer.csv\", index=False)","acc59739":"# sgd = SGDClassifier(penalty=None)\n# sgd.fit(X_train, y_train)\n# pred_sgd = sgd.predict(X_test)","299b096d":"# print(classification_report(y_test, pred_sgd))","34bf713a":"# print(confusion_matrix(y_test, pred_sgd))","f18b8b82":"# svc = SVC()\n# svc.fit(X_train, y_train)\n# pred_svc = svc.predict(X_test)","e2d717f3":"# print(classification_report(y_test, pred_svc))","1b9ebe82":"# #Finding best parameters for our SVC model\n# param = {\n#     'C': [0.1,0.8,0.9,1,1.1,1.2,1.3,1.4],\n#     'kernel':['linear', 'rbf'],\n#     'gamma' :[0.1,0.8,0.9,1,1.1,1.2,1.3,1.4]\n# }\n# grid_svc = GridSearchCV(svc, param_grid=param, scoring='accuracy', cv=10)","b288236d":"# grid_svc.fit(X_train, y_train)","aa0bd89f":"#Best parameters for our svc model\n# grid_svc.best_params_","4fbb9b05":"# #Let's run our SVC again with the best parameters.\n# svc2 = SVC(C = 1.2, gamma =  0.9, kernel= 'rbf')\n# svc2.fit(X_train, y_train)\n# pred_svc2 = svc2.predict(X_test)\n# print(classification_report(y_test, pred_svc2))","861ce7b7":"#### 84% accuracy using stochastic gradient descent classifier","4107bf3e":"## Support Vector Classifier","a0e4eb8b":"#### Support vector classifier gets 86%","7b111554":"## **Let's do some plotting to know how the data columns are distributed in the dataset**","ce2ef1fd":"## Let's try to increase our accuracy of models\n## Grid Search CV","5200f9fa":"## Preprocessing Data for performing Machine learning algorithms","5a808f72":"\n\n## Stochastic Gradient Decent Classifier","df9a83c6":"## Our training and testing data is ready now to perform machine learning algorithm","c306c29c":"### Random Forest Classifier"}}