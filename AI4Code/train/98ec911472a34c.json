{"cell_type":{"831ed2fd":"code","5e06f370":"code","2ddf4098":"code","7244df6d":"code","42a6325b":"code","aba85903":"code","d72fed2d":"code","76433a62":"markdown","b7d81ab6":"markdown","f6439bc3":"markdown","13ab8820":"markdown","00ff30ef":"markdown","0c82d39b":"markdown","8f583858":"markdown","2eb66f95":"markdown","7cce2372":"markdown","f135351c":"markdown"},"source":{"831ed2fd":"import sys\nimport matplotlib.pyplot as plt\nimport cv2\nimport time\nimport tensorflow as tf\nimport numpy as np","5e06f370":"import tensorflow as tf\ndetection_graph = tf.Graph()\nwith detection_graph.as_default():\n    od_graph_def = tf.compat.v1.GraphDef()\n    with tf.io.gfile.GFile('..\/input\/mobilenet-face\/frozen_inference_graph_face.pb', 'rb') as fid:\n        serialized_graph = fid.read()\n        od_graph_def.ParseFromString(serialized_graph)\n        tf.import_graph_def(od_graph_def, name='')\n        config = tf.compat.v1.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess=tf.compat.v1.Session(graph=detection_graph, config=config)\n    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n    boxes_tensor = detection_graph.get_tensor_by_name('detection_boxes:0')    \n    scores_tensor = detection_graph.get_tensor_by_name('detection_scores:0')\n    num_detections = detection_graph.get_tensor_by_name('num_detections:0')","2ddf4098":"def get_mobilenet_face(image):\n    global boxes,scores,num_detections\n    (im_height,im_width)=image.shape[:-1]\n    imgs=np.array([image])\n    (boxes, scores) = sess.run(\n        [boxes_tensor, scores_tensor],\n        feed_dict={image_tensor: imgs})\n    max_=np.where(scores==scores.max())[0][0]\n    box=boxes[0][max_]\n    ymin, xmin, ymax, xmax = box\n    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n                                ymin * im_height, ymax * im_height)\n    left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n    return (left, right, top, bottom)\ndef crop_image(frame,bbox):\n    left, right, top, bottom=bbox\n    return frame[top:bottom,left:right]\ndef get_img(frame):\n    return cv2.resize(crop_image(frame,get_mobilenet_face(frame)),(160,160))","7244df6d":"def detect_video(video):\n    capture = cv2.VideoCapture(video)\n    v_len = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n    frame_idxs = np.linspace(0,v_len,frame_count, endpoint=False, dtype=np.int)\n    imgs=[]\n    i=0\n    for frame_idx in range(int(v_len)):\n        ret = capture.grab()\n        if not ret: \n            pass\n        if frame_idx >= frame_idxs[i]:\n            ret, frame = capture.retrieve()\n            if not ret or frame is None:\n                pass\n            else:\n                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n                try:\n                    face=get_img(frame)\n                except Exception as err:\n                    print(err)\n                    continue\n                imgs.append(face)\n            i += 1\n            if i >= len(frame_idxs):\n                break\n    if len(imgs)<frame_count:\n        return None\n    return np.hstack(imgs)","42a6325b":"video='..\/input\/deepfake-detection-challenge\/train_sample_videos\/bdnaqemxmr.mp4'","aba85903":"frame_count=5\nplt.imshow(detect_video(video))","d72fed2d":"frame_count=10\nplt.imshow(detect_video(video))","76433a62":"# Helper Fuction","b7d81ab6":"# Initialize Mobilenet Face Extractor","f6439bc3":"I am going to introduce Mobilenet SSD face extractor. **It is better than MTCNN\/same with MTCNN in accuracy, but still have a competitive speed** I am aware of dual shot detector is better, but it takes too long.\n\nIt is recommended by @harshit_sheoran. FYI, it is used in our best score kernel(0.34LB).","13ab8820":"In this kernel, it will be a clean version of that extractor extracting faces from frames. I also included the helper function to go over video(with error catch).","00ff30ef":"Thanks for reading. Hope this notebook helps! Please upvote this notebook and the associated dataset if you find it helpful.","0c82d39b":"# Introduction","8f583858":"# Conclusion","2eb66f95":"**Here is the comparison to other face extractors[link](https:\/\/www.kaggle.com\/unkownhihi\/mobilenet-face-extractor-helper-code)**","7cce2372":"# Imports","f135351c":"# Detection\/Results"}}