{"cell_type":{"68d8ed35":"code","804c4d9f":"code","daeacc59":"code","9e893f9a":"code","36b19e7e":"code","37e7cbac":"code","cc80a49a":"code","f073c2b9":"code","67c7ea50":"code","ed3825ef":"code","4abfebff":"code","f4e4c584":"code","d88f501a":"code","88a95d23":"code","9b9b942c":"code","ff9820a7":"code","e762570d":"code","c85318ea":"code","69b58a13":"code","3792f2b0":"code","2badf356":"code","92136579":"code","9f2373ff":"code","7a5ac9d8":"code","0e1db00f":"code","bef243ad":"code","b087ff18":"code","2d92e9b6":"code","f4bac6f9":"code","6a467763":"code","2019c2d4":"code","e3767b62":"code","9f6cb509":"code","f68a808f":"code","e46eb3f3":"code","e84f9f24":"code","0bb55cf6":"code","d24a93d5":"code","70a417b7":"code","d37f249b":"code","babddaf5":"code","9fa5267c":"code","29c677a8":"code","1125700c":"code","b2f982f5":"code","9d412c84":"code","ae86efc9":"markdown","266251b3":"markdown","4ca8877f":"markdown","f6aa55e2":"markdown","f69f1303":"markdown","db086fd8":"markdown","fd30da6a":"markdown","1ff1f1f2":"markdown"},"source":{"68d8ed35":"# Importing  Libraries\nfrom numpy.random import seed\nseed(101)\n\nimport pandas as pd\nimport numpy as np\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\n\nimport os\nimport cv2\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport itertools\nimport shutil\nimport matplotlib.pyplot as plt\n%matplotlib inline\ntf.random.set_seed(101)","804c4d9f":"# Setting Some Pre-Requisites\nIMAGE_SIZE=96\nIMAGE_CHANNELS=3\nSAMPLE_SIZE=50000         # We will be training 50,000 samples from each label","daeacc59":"# So, what are the files which are available?\n\nos.listdir('..\/input\/histopathologic-cancer-detection')","9e893f9a":"# So, how many images are there in each of the folder in the training dataset?\n\nprint(len(os.listdir('..\/input\/histopathologic-cancer-detection\/train')))\nprint(len(os.listdir('..\/input\/histopathologic-cancer-detection\/test')))","36b19e7e":"# Creating a dataframe of all the training images\n\ndf_data = pd.read_csv('..\/input\/histopathologic-cancer-detection\/train_labels.csv')\n\n# removing this image because it caused a training error previously\ndf_data[df_data['id'] != 'dd6dfed324f9fcb6f93f46f32fc800f2ec196be2']\n\n# removing this image because it's black\ndf_data[df_data['id'] != '9369c7278ec8bcc6c880d99194de09fc2bd4efbe']\n\n\nprint(df_data.shape)","37e7cbac":"df_data['label'].value_counts()","cc80a49a":"labels_count = df_data.label.value_counts()\n\n%matplotlib inline\nplt.pie(labels_count, labels=['No Cancer', 'Cancer'], startangle=180, \n        autopct='%1.1f', colors=['#00ff99','#FF96A7'], shadow=True)\nplt.figure(figsize=(16,16))\nplt.show()","f073c2b9":"# source: https:\/\/www.kaggle.com\/gpreda\/honey-bee-subspecies-classification\n\ndef draw_category_images(col_name,figure_cols, df, IMAGE_PATH):\n    \n    \"\"\"\n    Give a column in a dataframe,\n    this function takes a sample of each class and displays that\n    sample on one row. The sample size is the same as figure_cols which\n    is the number of columns in the figure.\n    Because this function takes a random sample, each time the function is run it\n    displays different images.\n    \"\"\"\n    \n\n    categories = (df.groupby([col_name])[col_name].nunique()).index\n    f, ax = plt.subplots(nrows=len(categories),ncols=figure_cols, \n                         figsize=(4*figure_cols,4*len(categories))) # adjust size here\n    # draw a number of images for each location\n    for i, cat in enumerate(categories):\n        sample = df[df[col_name]==cat].sample(figure_cols) # figure_cols is also the sample size\n        for j in range(0,figure_cols):\n            file=IMAGE_PATH + sample.iloc[j]['id'] + '.tif'\n            im=cv2.imread(file)\n            ax[i, j].imshow(im, resample=True, cmap='gray')\n            ax[i, j].set_title(cat, fontsize=16)  \n    plt.tight_layout()\n    plt.show()","67c7ea50":"IMAGE_PATH = '..\/input\/histopathologic-cancer-detection\/train\/' \n\ndraw_category_images('label',4, df_data, IMAGE_PATH)","ed3825ef":"# Create the Train and Validation Sets\n\ndf_0=df_data[df_data['label']==0].sample(SAMPLE_SIZE,random_state=101)\ndf_1=df_data[df_data['label']==1].sample(SAMPLE_SIZE,random_state=101)\n\n# concat the dataframes\ndf_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n# shuffle\ndf_data = shuffle(df_data)\n\ndf_data['label'].value_counts()","4abfebff":"# Now, for the train-test split\n\n# stratify=y creates a balanced validation set.\ny = df_data['label']\n\ndf_train, df_val = train_test_split(df_data, test_size=0.10, random_state=101, stratify=y)\n\nprint(df_train.shape)\nprint(df_val.shape)","f4e4c584":"# Create a new directory so that we will be using the ImageDataGenerator\nbase_dir='base_dir'\nos.mkdir(base_dir)\n\n# now we create 2 folders inside 'base_dir':\n\n# train_dir\n    # a_no_tumor_tissue\n    # b_has_tumor_tissue\n\n# val_dir\n    # a_no_tumor_tissue\n    # b_has_tumor_tissue\n\n\n\n# create a path to 'base_dir' to which we will join the names of the new folders\n# train_dir\ntrain_dir = os.path.join(base_dir, 'train_dir')\nos.mkdir(train_dir)\n\n# val_dir\nval_dir = os.path.join(base_dir, 'val_dir')\nos.mkdir(val_dir)\n\n\n\n# [CREATE FOLDERS INSIDE THE TRAIN AND VALIDATION FOLDERS]\n# Inside each folder we create seperate folders for each class\n\n# create new folders inside train_dir\nno_tumor_tissue = os.path.join(train_dir, 'a_no_tumor_tissue')\nos.mkdir(no_tumor_tissue)\nhas_tumor_tissue = os.path.join(train_dir, 'b_has_tumor_tissue')\nos.mkdir(has_tumor_tissue)\n\n\n# create new folders inside val_dir\nno_tumor_tissue = os.path.join(val_dir, 'a_no_tumor_tissue')\nos.mkdir(no_tumor_tissue)\nhas_tumor_tissue = os.path.join(val_dir, 'b_has_tumor_tissue')\nos.mkdir(has_tumor_tissue)","d88f501a":"# check that the folders have been created\nos.listdir('base_dir\/train_dir')","88a95d23":"# Set the id as the index in df_data\ndf_data.set_index('id', inplace=True)","9b9b942c":"# Get a list of train and val images\ntrain_list = list(df_train['id'])\nval_list = list(df_val['id'])\n\n\n\n# Transfer the train images\n\nfor image in train_list:\n    \n    # the id in the csv file does not have the .tif extension therefore we add it here\n    fname = image + '.tif'\n    # get the label for a certain image\n    target = df_data.loc[image,'label']\n    \n    # these must match the folder names\n    if target == 0:\n        label = 'a_no_tumor_tissue'\n    if target == 1:\n        label = 'b_has_tumor_tissue'\n    \n    # source path to image\n    src = os.path.join('..\/input\/histopathologic-cancer-detection\/train', fname)\n    # destination path to image\n    dst = os.path.join(train_dir, label, fname)\n    # copy the image from the source to the destination\n    shutil.copyfile(src, dst)\n\n\n# Transfer the val images\n\nfor image in val_list:\n    \n    # the id in the csv file does not have the .tif extension therefore we add it here\n    fname = image + '.tif'\n    # get the label for a certain image\n    target = df_data.loc[image,'label']\n    \n    # these must match the folder names\n    if target == 0:\n        label = 'a_no_tumor_tissue'\n    if target == 1:\n        label = 'b_has_tumor_tissue'\n    \n\n    # source path to image\n    src = os.path.join('..\/input\/histopathologic-cancer-detection\/train', fname)\n    # destination path to image\n    dst = os.path.join(val_dir, label, fname)\n    # copy the image from the source to the destination\n    shutil.copyfile(src, dst)","ff9820a7":"# check how many train images we have in each folder\n\nprint(len(os.listdir('base_dir\/train_dir\/a_no_tumor_tissue')))\nprint(len(os.listdir('base_dir\/train_dir\/b_has_tumor_tissue')))","e762570d":"# check how many val images we have in each folder\n\nprint(len(os.listdir('base_dir\/val_dir\/a_no_tumor_tissue')))\nprint(len(os.listdir('base_dir\/val_dir\/b_has_tumor_tissue')))","c85318ea":"# Set up the generators\ntrain_path = 'base_dir\/train_dir'\nvalid_path = 'base_dir\/val_dir'\ntest_path = '..\/input\/histopathologic-cancer-detection\/test'\n\nnum_train_samples = len(df_train)\nnum_val_samples = len(df_val)\ntrain_batch_size = 10\nval_batch_size = 10\n\n\ntrain_steps = np.ceil(num_train_samples \/ train_batch_size)\nval_steps = np.ceil(num_val_samples \/ val_batch_size)\ndatagen = ImageDataGenerator(rescale=1.0\/255)\n\ntrain_gen = datagen.flow_from_directory(train_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=train_batch_size,\n                                        class_mode='categorical')\n\nval_gen = datagen.flow_from_directory(valid_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=val_batch_size,\n                                        class_mode='categorical')\n\n# Note: shuffle=False causes the test dataset to not be shuffled\ntest_gen = datagen.flow_from_directory(valid_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=1,\n                                        class_mode='categorical',\n                                        shuffle=False)","69b58a13":"kernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 32\nsecond_filters = 64\nthird_filters = 128\n\ndropout_conv = 0.3\ndropout_dense = 0.3\n\n\nmodel = Sequential()\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (96, 96, 3)))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(dropout_dense))\nmodel.add(Dense(2, activation = \"softmax\"))\n\nmodel.summary()","3792f2b0":"model.compile(Adam(lr=0.0001), loss='binary_crossentropy', \n              metrics=['accuracy'])","2badf356":"# Get the labels that are associated with each index\nprint(val_gen.class_indices)","92136579":"filepath = \"model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n                             save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n                                   verbose=1, mode='max', min_lr=0.00001)\n                              \n                              \ncallbacks_list = [checkpoint, reduce_lr]\n\nhistory = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n                    validation_data=val_gen,\n                    validation_steps=val_steps,\n                    epochs=20, verbose=1,\n                   callbacks=callbacks_list)","9f2373ff":"# get the metric names so we can use evaulate_generator\nmodel.metrics_names","7a5ac9d8":"# Here the best epoch will be used.\n\n\n\nval_loss, val_acc = \\\nmodel.evaluate_generator(test_gen, \n                        steps=len(df_val))\n\nprint('val_loss:', val_loss)\nprint('val_acc:', val_acc)","0e1db00f":"# display the loss and accuracy curves\n\nimport matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()","bef243ad":"# make a prediction\npredictions = model.predict_generator(test_gen, steps=len(df_val), verbose=1)","b087ff18":"predictions.shape","2d92e9b6":"# This is how to check what index keras has internally assigned to each class. \ntest_gen.class_indices","f4bac6f9":"# Put the predictions into a dataframe.\n# The columns need to be ordered to match the output of the previous cell\n\ndf_preds = pd.DataFrame(predictions, columns=['no_tumor_tissue', 'has_tumor_tissue'])\n\ndf_preds.head()","6a467763":"# Get the true labels\ny_true = test_gen.classes\n\n# Get the predicted labels as probabilities\ny_pred = df_preds['has_tumor_tissue']","2019c2d4":"from sklearn.metrics import roc_auc_score\n\nroc_auc_score(y_true, y_pred)","e3767b62":"# Get the labels of the test images.\n\ntest_labels = test_gen.classes\ntest_labels.shape","9f6cb509":"# argmax returns the index of the max value in a row\ncm = confusion_matrix(test_labels, predictions.argmax(axis=1))\n# Print the label associated with each class\ntest_gen.class_indices","f68a808f":"from sklearn.metrics import plot_confusion_matrix","e46eb3f3":"# Delete base_dir and it's sub folders to free up disk space.\n\nshutil.rmtree('base_dir')\n#[CREATE A TEST FOLDER DIRECTORY STRUCTURE]\n\n# We will be feeding test images from a folder into predict_generator().\n# Keras requires that the path should point to a folder containing images and not\n# to the images themselves. That is why we are creating a folder (test_images) \n# inside another folder (test_dir).\n\n# test_dir\n    # test_images\n\n# create test_dir\ntest_dir = 'test_dir'\nos.mkdir(test_dir)\n    \n# create test_images inside test_dir\ntest_images = os.path.join(test_dir, 'test_images')\nos.mkdir(test_images)\n# check that the directory we created exists\nos.listdir('test_dir')","e84f9f24":"# Transfer the test images into image_dir\n\ntest_list = os.listdir('..\/input\/histopathologic-cancer-detection\/test')\n\nfor image in test_list:\n    \n    fname = image\n    \n    # source path to image\n    src = os.path.join('..\/input\/histopathologic-cancer-detection\/test', fname)\n    # destination path to image\n    dst = os.path.join(test_images, fname)\n    # copy the image from the source to the destination\n    shutil.copyfile(src, dst)\n# check that the images are now in the test_images\n# Should now be 57458 images in the test_images folder\n\nlen(os.listdir('test_dir\/test_images'))","0bb55cf6":"test_path ='test_dir'\n\n\n# Here we change the path to point to the test_images folder.\n\ntest_gen = datagen.flow_from_directory(test_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=1,\n                                        class_mode='categorical',\n                                        shuffle=False)","d24a93d5":"num_test_images = 57458\n\n\n\npredictions = model.predict_generator(test_gen, steps=num_test_images, verbose=1)","70a417b7":"# Are the number of predictions correct?\n# Should be 57458.\n\nlen(predictions)","d37f249b":"# Put the predictions into a dataframe\n\ndf_preds = pd.DataFrame(predictions, columns=['no_tumor_tissue', 'has_tumor_tissue'])\n\ndf_preds.head()","babddaf5":"# This outputs the file names in the sequence in which \n# the generator processed the test images.\ntest_filenames = test_gen.filenames\n\n# add the filenames to the dataframe\ndf_preds['file_names'] = test_filenames\n\ndf_preds.head()","9fa5267c":"# Create an id column\n\n# A file name now has this format: \n# test_images\/00006537328c33e284c973d7b39d340809f7271b.tif\n\n# This function will extract the id:\n# 00006537328c33e284c973d7b39d340809f7271b\n\n\ndef extract_id(x):\n    \n    # split into a list\n    a = x.split('\/')\n    # split into a list\n    b = a[1].split('.')\n    extracted_id = b[0]\n    \n    return extracted_id\n\ndf_preds['id'] = df_preds['file_names'].apply(extract_id)\n\ndf_preds.head()","29c677a8":"# Get the predicted labels.\n# We were asked to predict a probability that the image has tumor tissue\ny_pred = df_preds['has_tumor_tissue']\n\n# get the id column\nimage_id = df_preds['id']","1125700c":"submission = pd.DataFrame({'id':image_id, \n                           'label':y_pred, \n                          }).set_index('id')\n\nsubmission.to_csv('patch_preds.csv', columns=['label']) \nsubmission.head()","b2f982f5":"# Delete the test_dir directory we created to prevent a Kaggle error.\n# Kaggle allows a max of 500 files to be saved.\n\nshutil.rmtree('test_dir')","9d412c84":"import seaborn as sns\nimport matplotlib.pyplot as plt     \n\nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); ","ae86efc9":"# I hope that you found my notebook useful. I did a great effort to complete the coding part. So, if you enjoyed the notebook, please leave an upvote. Thanks a lot for reading!!","266251b3":"\n1. Understanding the Problem:\n\nOur goal is to create an algorithm to identify metastatic cancer in small image patches taken from larger digital pathology scans.\n\n\n* Histopathology is the study of the signs of the disease using the microscopic examination of a biopsy or surgical specimen that is processed and fixed onto glass slides. To visualize different components of the tissue under a microscope, the sections are dyed with one or more stains.","4ca8877f":"# SUBMISSION","f6aa55e2":"# Introduction\nThis notebook provides solution to Histopathologic Cancer Detection challenge on Kaggle. This is a perfect Computer Vision problem where we are tasked with the detection of cancer by identifying metastatic tissue in histopathologic scans of lymph nodes using Deep Learning.","f69f1303":"\n# Understanding the Problem:\nOur goal is to create an algorithm to identify metastatic cancer in small image patches taken from larger digital pathology scans.\n\nObviously I don't know biology to understand this problem right away, here is what I found online about histopathology.\n\nHistopathology is the study of the signs of the disease using the microscopic examination of a biopsy or surgical specimen that is processed and fixed onto glass slides. To visualize different components of the tissue under a microscope, the sections are dyed with one or more stains.\n\n","db086fd8":"# Understanding the Data:\nThe train data we have here contains 220,025 images and the test set contains 57,468 images.\n\nIt is important to take into account that this data is only a subset of the original PCam dataset which in the end is derived from the Camelyon16 Challenge dataset, which contains 400 H&E stained whole slide images of sentinel lymph node sections that were acquired and digitized at 2 different centers using a 40x objective. The PCam's dataset including this one uses 10x undersampling to increase the field of view, which gives the resultant pixel resolution of 2.43 microns.\n\nHere's what Kaggle says,\n\nThe original PCam dataset contains duplicate images due to its probabilistic sampling, however, the version presented on Kaggle does not contain duplicates. We have otherwise maintained the same data and splits as the PCam benchmark.\n\nOur training data has a class distribution of 60:40 negative and positive samples which is not bad.","fd30da6a":"# Confusion Matrix","1ff1f1f2":"# Validation and Analysis\n### Metrics\n### Prediction and Activation Visualizations\n### ROC and AUC"}}