{"cell_type":{"761fdb72":"code","b26e00ee":"code","d71e8a14":"code","3a6d94af":"code","6f1540a8":"code","a3ffb4f6":"code","a6fd03da":"code","480f6055":"code","d7c5af28":"code","3cb2d50d":"code","db785299":"code","23eced1b":"code","d3f37765":"code","7a505ac2":"code","59237ce6":"code","615cd261":"code","b49f8c17":"code","475a1651":"code","6882d5a6":"code","25bfbd49":"code","33ce181b":"markdown","256708f5":"markdown","bc90f6df":"markdown","7feef9b2":"markdown","7f30f1a9":"markdown","bd571313":"markdown","fb288941":"markdown","087af77a":"markdown","70a99583":"markdown","61d82c78":"markdown","93fdcaa1":"markdown"},"source":{"761fdb72":"import torch\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b26e00ee":"mean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ntrain_transform = transforms.Compose([\n                                transforms.Resize(256),\n                                transforms.RandomResizedCrop(224),\n                                transforms.RandomHorizontalFlip(),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean, std)])\n\ntest_transform = transforms.Compose([\n                                transforms.Resize(256),\n                                transforms.CenterCrop(224),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean, std)])","d71e8a14":"data_dir = \"..\/input\/flowers_\/flowers_\/\"\n","3a6d94af":"img_datasets ={}","6f1540a8":"# That's how easily you can for images folders in Pytorch for further operations\nimg_datasets['train']= datasets.ImageFolder(data_dir + '\/train', train_transform)\nimg_datasets['test']= datasets.ImageFolder(data_dir + '\/test', test_transform)","a3ffb4f6":"# these gets extracted from the folder name\nclass_names = img_datasets['train'].classes\nclass_names","a6fd03da":"# these gets extracted from the folder name - class label mapping\nclass_idx = img_datasets['train'].class_to_idx\nclass_idx","480f6055":"train_loader = torch.utils.data.DataLoader(img_datasets['train'],\n                                                   batch_size=10,\n                                                   shuffle=True,\n                                                   num_workers=4)\n\ntest_loader = torch.utils.data.DataLoader(img_datasets['test'],\n                                                   batch_size=10,\n                                                   shuffle=True,\n                                                   num_workers=4)","d7c5af28":"images , labels = next(iter(train_loader))\nimages.shape","3cb2d50d":"# lets look at the labels\nlabels","db785299":"import torchvision.models as models\n\nmodel = models.vgg16(pretrained=True)","23eced1b":"for param in model.parameters():\n    param.required_grad = False","d3f37765":"# Now let's check the model archietecture\nmodel","7a505ac2":"num_of_inputs = model.classifier[0].in_features\nnum_of_inputs","59237ce6":"# restructaring the classifier\nimport torch.nn as nn\nmodel.classifier = nn.Sequential(\n                      nn.Linear(num_of_inputs, 5),\n                        nn.LogSoftmax(dim=1))","615cd261":"# Now let's check the model archietecture again to see the changes \nmodel","b49f8c17":"# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')\n# move tensors to GPU if CUDA is available\nif train_on_gpu:\n    model.cuda()","475a1651":"# loss function and optimizer\ncriterion = nn.NLLLoss()\noptimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001)","6882d5a6":"# number of epochs to train the model\nn_epochs = 10\n\n\nfor epoch in range(n_epochs):\n    # monitor training loss\n    train_loss = 0.0\n    train_accuracy = 0\n    \n    ###################\n    # train the model #\n    ###################\n    model.train() # prep model for training\n    for data, target in train_loader:\n        if train_on_gpu:\n            data, target = Variable(data.cuda()), Variable(target.cuda())\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update running training loss\n        train_loss += loss.item()*data.size(0)\n        #calculate accuracy\n        ps = torch.exp(output)\n        top_p, top_class = ps.topk(1, dim=1)\n        equals = top_class == target.view(*top_class.shape)\n        train_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n    \n# calculate average loss over an epoch\n    train_loss = train_loss\/len(train_loader.dataset)\n\n    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n            epoch+1, \n            train_loss\n            ))\n    print(f\"Train accuracy: {train_accuracy\/len(train_loader):.3f}\")\n","25bfbd49":"# Checking Test Performence\ntest_accuracy = 0\nmodel.eval() # prep model for evaluation\nfor data, target in test_loader:\n    if train_on_gpu:\n        data, target = Variable(data.cuda()), Variable(target.cuda())\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = model(data)\n    # calculate the loss\n    loss = criterion(output, target)\n    #calculate accuracy\n    ps = torch.exp(output)\n    top_p, top_class = ps.topk(1, dim=1)\n    equals = top_class == target.view(*top_class.shape)\n    test_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n\nprint(f\"Test accuracy: {test_accuracy\/len(test_loader):.3f}\")","33ce181b":"**Freezing model's layers:**\n\nWe will freeze all the layers in the network except the final layer.\nrequires_grad == False will freeze the parameters so that the gradients are not computed in backward() i.e. weights of these layers won't be trained","256708f5":"Let's examing a Batch of training Data","bc90f6df":"Accuracy can be improved by changing the classifer archietecture !! ","7feef9b2":"A call to ImageFolder(Path, Transform) applies our transformations to all the images in the specified directory.\nWe will create a dictorionary called img_dataset for train and test folder**","7f30f1a9":"If you remember we have five classes i.e. five class image classification , in the above print out if you look closely the (classifier)\nsection - this is doing something else. We need to change the classifier to make it a 5 class classifier.\n\nwe need to feed the no of input features to the linear layer (classifier[0]) to our newly created linear layer and output would be 5.","bd571313":"Creating Train & Test DataLoaders","fb288941":"All of the pretrained models are present inside torchvision , in this tutorial we will use vgg16 pretrained layer.\nPS: In Kaggle to download the pretrained model , you need to set Internet to On in settings.","087af77a":"- 10 - number of images in a single batch\n- 3 - number channels \n- 224 - width & height of the image","70a99583":"Classes Present","61d82c78":"Hope you can see the changes in the classifier layer","93fdcaa1":"**Image augmentation and normalization** \n\n- Transforms can be chained together using Compose\n- In image augmentation we randomly flip images, so that our model can detect wrongly oriented images too\n- All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. \n- Normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]\n- We first Resize the image to 256 then crop it to 224, so that it doesnt cut important features"}}