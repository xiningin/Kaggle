{"cell_type":{"9f10059b":"code","a6cab8c0":"code","07578965":"code","2c694a2f":"code","91d3e12b":"code","b663c682":"code","6b820095":"code","6d32b643":"code","12034104":"code","b123a16b":"code","5e9b1b56":"code","8cc5e418":"code","59a2a5d4":"code","73f84bae":"code","89977d0c":"code","b1511f52":"code","e23b9208":"code","deb0e3d0":"code","2b516266":"code","d16d4f18":"code","19d7c58d":"code","28557049":"code","66f16e96":"code","63a455b1":"markdown"},"source":{"9f10059b":"import os\nimport matplotlib.pyplot as plot\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom random import randint\nimport random\n\n# for creating validation set\nfrom sklearn.model_selection import train_test_split\n\n# for evaluating the model\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\n\n# PyTorch libraries and modules\nimport torch\nfrom torch.autograd import Variable\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\nfrom torch.optim import Adam, SGD\nfrom sklearn.utils import shuffle\n\n#Load libraries\nimport os  \nimport numpy as np\nimport torch\nimport glob\nimport torch.nn as nn\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nfrom torch.autograd import Variable\nimport torchvision\nimport pathlib\n\n\nimport numpy as np\nfrom torch.autograd import Variable\nfrom torchvision.models import squeezenet1_1\nimport torch.functional as F\nfrom io import open\nimport os\nfrom PIL import Image\nimport pathlib\nimport glob\nimport cv2","a6cab8c0":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","07578965":"#Transforms\ntransformer=transforms.Compose([\n    transforms.Resize((150,150)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)\/std\n                        [0.5,0.5,0.5])\n])","2c694a2f":"#Dataloader\n\n#Path for training and testing directory\ntrain_path=r'..\/input\/image-data\/train2\/train2'\ntest_path=r'..\/input\/image-data\/test2\/test2'\n\ntrain_loader=DataLoader(\n    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n    batch_size=64, shuffle=True\n)\ntest_loader=DataLoader(\n    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n    batch_size=32, shuffle=True\n)","91d3e12b":"#categories\nroot=pathlib.Path(train_path)\nclasses=sorted([j.name.split('\/')[-1] for j in root.iterdir()])","b663c682":"print(classes)","6b820095":"#CNN Network\n\n\nclass ConvNet(nn.Module):\n    def __init__(self,num_classes=6):\n        super(ConvNet,self).__init__()\n        \n        #Output size after convolution filter\n        #((w-f+2P)\/s) +1\n        \n        #Input shape= (256,3,150,150)\n        \n        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n        #Shape= (256,12,150,150)\n        self.bn1=nn.BatchNorm2d(num_features=12)\n        #Shape= (256,12,150,150)\n        self.relu1=nn.ReLU()\n        #Shape= (256,12,150,150)\n        self.pool=nn.MaxPool2d(kernel_size=2)\n        #Reduce the image size be factor 2\n        #Shape= (256,12,75,75)\n        \n        \n        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n        #Shape= (256,20,150,150)\n        self.bn2=nn.BatchNorm2d(num_features=20)\n        #Shape= (256,20,150,150)\n        self.relu2=nn.ReLU()\n        #Shape= (256,20,150,150)\n        \n        \n        \n        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n        #Shape= (256,32,75,75)\n        self.relu3=nn.ReLU()\n        #Shape= (256,32,75,75)\n        \n        \n        \n        self.conv4=nn.Conv2d(in_channels=32,out_channels=46,kernel_size=3,stride=1,padding=1)\n        #Shape= (256,46,75,75)\n        self.bn4=nn.BatchNorm2d(num_features=46)\n        #Shape= (256,46,75,75)\n        self.relu4=nn.ReLU()\n        #Shape= (256,46,75,75)\n        \n        self.conv5=nn.Conv2d(in_channels=46,out_channels=60,kernel_size=3,stride=1,padding=1)\n        #Shape= (256,60,75,75)\n        self.bn5=nn.BatchNorm2d(num_features=60)\n        #Shape= (256,60,75,75)\n        self.relu5=nn.ReLU()\n        #Shape= (256,60,75,75)\n        \n        \n        self.fc=nn.Linear(in_features=75 * 75 * 60,out_features=num_classes)\n        \n        \n        \n        #Feed forwad function\n        \n    def forward(self,input):\n        output=self.conv1(input)\n        output=self.bn1(output)\n        output=self.relu1(output)\n        output=self.pool(output)\n        \n        output=self.conv2(output)\n        output=self.bn2(output)\n        output=self.relu2(output)\n            \n        output=self.conv3(output)\n        output=self.relu3(output)\n            \n        output=self.conv4(output)\n        output=self.bn4(output)\n        output=self.relu4(output)\n        \n        output=self.conv5(output)\n        output=self.bn5(output)\n        output=self.relu5(output)\n            \n            \n            #Above output will be in matrix form, with shape (256,60,75,75)\n            \n        output=output.view(-1,60*75*75)\n            \n            \n        output=self.fc(output)\n            \n        return output","6d32b643":"model=ConvNet(num_classes=9).to(device)","12034104":"#Optmizer and loss function\noptimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\nloss_function=nn.CrossEntropyLoss()","b123a16b":"num_epochs=10","5e9b1b56":"#calculating the size of training and testing images\ntrain_count=len(glob.glob(train_path+'\/**\/*.png'))\ntest_count=len(glob.glob(test_path+'\/**\/*.png'))\n\nprint(train_count,test_count)","8cc5e418":"#Model training and saving best model\n\nbest_accuracy=0.0\n\nfor epoch in range(num_epochs):\n    \n    #Evaluation and training on training dataset\n    model.train()\n    train_accuracy=0.0\n    train_loss=0.0\n    \n    for i, (images,labels) in enumerate(train_loader):\n        if torch.cuda.is_available():\n            images=Variable(images.cuda())\n            labels=Variable(labels.cuda())\n            \n        optimizer.zero_grad()\n        \n        outputs=model(images)\n        loss=loss_function(outputs,labels)\n        loss.backward()\n        optimizer.step()\n        \n        \n        train_loss+= loss.cpu().data*images.size(0)\n        _,prediction=torch.max(outputs.data,1)\n        \n        train_accuracy+=int(torch.sum(prediction==labels.data))\n        \n    train_accuracy=train_accuracy\/train_count\n    train_loss=train_loss\/train_count\n    \n    \n    # Evaluation on testing dataset\n    model.eval()\n    \n    test_accuracy=0.0\n    for i, (images,labels) in enumerate(test_loader):\n        if torch.cuda.is_available():\n            images=Variable(images.cuda())\n            labels=Variable(labels.cuda())\n            \n        outputs=model(images)\n        _,prediction=torch.max(outputs.data,1)\n        test_accuracy+=int(torch.sum(prediction==labels.data))\n    \n    test_accuracy=test_accuracy\/test_count\n    \n    \n    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n    \n    #Save the best model\n    if test_accuracy>best_accuracy:\n        torch.save(model.state_dict(),'best_checkpoint.model')\n        best_accuracy=test_accuracy","59a2a5d4":"train_path=r'..\/input\/image-data\/train2\/train2'\npred_path=r'..\/input\/pred-data\/pred'","73f84bae":"#categories\nroot=pathlib.Path(train_path)\nclasses=sorted([j.name.split('\/')[-1] for j in root.iterdir()])","89977d0c":"checkpoint=torch.load('best_checkpoint.model')\nmodel=ConvNet(num_classes=9)\nmodel.load_state_dict(checkpoint)\nmodel.eval()","b1511f52":"#Transforms\ntransformer=transforms.Compose([\n    transforms.Resize((150,150)),\n    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)\/std\n                        [0.5,0.5,0.5])\n])","e23b9208":"#prediction function\ndef prediction(img_path,transformer):\n    \n    image=Image.open(img_path)\n    \n    image_tensor=transformer(image).float()\n    \n    \n    image_tensor=image_tensor.unsqueeze_(0)\n    \n    if torch.cuda.is_available():\n        image_tensor.cuda()\n        \n    input=Variable(image_tensor)\n    \n    \n    output=model(input)\n    \n    index=output.data.numpy().argmax()\n    \n    pred=classes[index]\n    \n    return pred","deb0e3d0":"images_path=glob.glob(pred_path+'\/*.png')","2b516266":"pred_dict={}\n\nfor i in images_path:\n    pred_dict[i[i.rfind('\/')+1:]]=prediction(i,transformer)","d16d4f18":"dict(list(pred_dict.items())[0:30])","19d7c58d":"f,ax = plot.subplots(5,5) \nf.subplots_adjust(0,0,3,3)\nfor i in range(0,5,1):\n    for j in range(0,5,1):\n        rnd_number = randint(0,852)\n        imgi =cv2.imread(pred_path + '\/' + str(rnd_number) + '.png')\n        ax[i,j].imshow(imgi)\n        ax[i,j].set_title(pred_dict[str(rnd_number) + '.png'])\n        ax[i,j].axis('off')","28557049":"v = {}\n\nfor key, value in sorted(pred_dict.items()):\n    v.setdefault(value, []).append(key)\nclasses = list(v.keys())\nclasses","66f16e96":"f,ax = plot.subplots(9,5) \nf.subplots_adjust(0,0,3,3)\nfor i in range(0,9,1):\n    for j in range(0,5,1):\n        imgi =cv2.imread(pred_path + '\/' + str(v[classes[i]][j+1]))\n        ax[i,j].imshow(imgi)\n        ax[i,j].set_title(classes[i])\n        ax[i,j].axis('off')","63a455b1":"# Inference"}}