{"cell_type":{"17227220":"code","bb92b6bf":"code","cc027b16":"code","92102324":"code","7eee5143":"code","be97e214":"code","5d1dca39":"code","14bcdd23":"code","a70a0e72":"code","9649c41e":"code","8e45fe3c":"code","996da214":"code","a6a0d1fb":"code","0f08d4b0":"code","8a8e54f9":"code","e78f6c7f":"code","d63b1742":"code","c839991f":"code","546547af":"code","057bd344":"code","3249fbb9":"code","5beff227":"code","01c8513f":"code","af2e4377":"code","26abf7e5":"code","d7840b9d":"code","8087b0d9":"code","5ccf3638":"code","b026ea5e":"code","af0a55f2":"code","190e2b25":"markdown","ad3c20dd":"markdown","465cb0c6":"markdown","701b847e":"markdown","8b679b46":"markdown","934305fd":"markdown","8ef6c5db":"markdown","f351c46c":"markdown","e42e81a3":"markdown","cf9440f3":"markdown","9968357b":"markdown","814c5182":"markdown","9aaa6dd2":"markdown","58c1b4ae":"markdown","4053f231":"markdown"},"source":{"17227220":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bb92b6bf":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nfrom scipy import stats\nimport scipy.stats as stats","cc027b16":"#read train set and test set\ntrain=pd.read_csv('..\/input\/titanic\/train.csv')\ntest=pd.read_csv('..\/input\/titanic\/test.csv')","92102324":"train.head()\n\n#ticker number and cabin number seems not important, we can delete it\uff1f","7eee5143":"train.isnull().sum()","be97e214":"#handling missing value age and embarked\n\n# Filling missing value in age, use mean\ntrain[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].mean())\n#Filling missing value in embarked, use mode\ntrain['Embarked']=train['Embarked'].fillna(train['Embarked'].mode()[0])\n","5d1dca39":"train=train.drop(['Cabin'],axis=1)","14bcdd23":"print(train.isnull().sum())\ntrain.head()\n\n#not missing value now","a70a0e72":"#handling categorical variables Sex and embarked.\n\ntrain['Sex_code']=train['Sex'].map({'female':1,\"male\":0}).astype('int')\ntrain['Embarked_code']=train['Embarked'].map({'S':0,\"C\":1,\"Q\":2}).astype('int')","9649c41e":"train.head()","8e45fe3c":"sns.countplot(train['Pclass'],hue=train['Survived'])\nplt.title('Pclass vs Survived')","996da214":"data=pd.concat([train['Age'], train['Survived']], axis=1)\nboxplot, ax = plt.subplots(figsize=(15,10))\nboxplot = sns.boxplot(x='Survived', y=\"Age\", data=data)\nplt.title('Age vs Survived')","a6a0d1fb":"sns.countplot(train['Sex'],hue=train['Survived'])","0f08d4b0":"sns.countplot(train['Embarked'],hue=train['Survived'])","8a8e54f9":"data=pd.concat([train['Fare'], train['Survived']], axis=1)\nboxplot, ax = plt.subplots(figsize=(15,10))\nboxplot = sns.boxplot(x='Survived', y=\"Fare\", data=data)\nplt.title('Fare vs Survived')","e78f6c7f":"X=train[['Pclass','Age','SibSp','Parch','Fare','Sex_code','Embarked_code']]\ny=train['Survived']","d63b1742":"# Import train_test_split function\nfrom sklearn.model_selection import train_test_split\n\n# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Create a Gaussian Classifier\nclf=RandomForestClassifier(n_estimators=100)\nclf.fit(X_train,y_train)\ny_pred=clf.predict(X_test)\n#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n\n\nimport pandas as pd\nfeature_importances = pd.DataFrame(clf.feature_importances_,\n                                   index = X_train.columns,\n                                    columns=['importance']).sort_values('importance',ascending=False)\nprint(feature_importances)","c839991f":"#removing some not important variables\uff08Parch and embarked\uff09\n\nX=train[['Pclass','Age','SibSp','Fare','Sex_code']]\ny=train['Survived']\n\n\n# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n\n#Create a Gaussian Classifier\nclf=RandomForestClassifier(n_estimators=100)\nclf.fit(X_train,y_train)\ny_pred=clf.predict(X_test)\n#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","546547af":"#removing some not important variables\uff08Pclass and SibSp\uff09\n\nX=train[['Age','Fare','Sex_code']]\ny=train['Survived']\n\n\n# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n\n#Create a Gaussian Classifier\nclf=RandomForestClassifier(n_estimators=100)\nclf.fit(X_train,y_train)\ny_pred=clf.predict(X_test)\n#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","057bd344":"X=train[['Age','Fare','Sex_code','Pclass']]\ny=train['Survived']\n\n\n# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n\n#Create a Gaussian Classifier\nclf=RandomForestClassifier(n_estimators=100)\nclf.fit(X_train,y_train)\ny_pred=clf.predict(X_test)\n#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","3249fbb9":"test.head()","5beff227":"#handling categorical variables Sex and embarked.\n\ntest['Sex_code']=test['Sex'].map({'female':1,\"male\":0}).astype('int')\ntest['Embarked_code']=test['Embarked'].map({'S':0,\"C\":1,\"Q\":2}).astype('int')\n","01c8513f":"test.isnull().sum()","af2e4377":"test['Age']=test['Age'].fillna(test['Age'].mean())","26abf7e5":"test['Fare']=test['Fare'].fillna(test['Fare'].mean())","d7840b9d":"X1=test[['Age','Fare','Sex_code','Pclass']]\nX=train[['Age','Fare','Sex_code','Pclass']]\ny=train['Survived']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n\n#Create a Gaussian Classifier\nclf=RandomForestClassifier(n_estimators=100)\nclf.fit(X_train,y_train)\ny_pred=clf.predict(X1)\n\nprint(len(y_pred))\nprint(len(test))\n\n","8087b0d9":"y_pred\n","5ccf3638":"#Import svm model\nfrom sklearn import svm\n\n#Create a svm Classifier\nclf = svm.SVC(kernel='linear') # Linear Kernel\n\n#Train the model using the training sets\nclf.fit(X_train, y_train)\n\n#Predict the response for test dataset\ny_pred1 = clf.predict(X1)\n\ny_pred1","b026ea5e":"from sklearn.neighbors import KNeighborsClassifier\nmodel = KNeighborsClassifier(n_neighbors=3)\n# Train the model using the training sets\nmodel.fit(X_train, y_train)\n\n#Predict Output\npredicted= model.predict(X1) \nprint(predicted)","af0a55f2":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived':predicted}) \noutput.to_csv('submission.csv', index=False) ","190e2b25":"## **Age vs Survived**","ad3c20dd":"## **Understanding data**","465cb0c6":"![image.png](attachment:9cd07db7-bf13-4fd2-82b5-cfe032cd3e5b.png)\n\n**Variable Notes**\n\npclass: A proxy for socio-economic status (SES)\n1st = Upper\n2nd = Middle\n3rd = Lower\n\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nsibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nparch: The dataset defines family relations in this way...\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.","701b847e":"## **STEPS**\n\n1. Understanding the data: look at independent variables X and dependent variable Y \uff08survived or not\uff09.\n2. Finding important independent variables:how X and Y relate.\n3. Data cleaning: Find missing value and outliner.(Train set and test set)\n4. Modeling (Random Forest model,Decision Tree,K-nearest neighbor\uff1f) \n*   1.Check Normality\/Homoscedasticity\/Linearity\/Absence of correlated errors\n*   2.If Y is not normally distributed, do some transformation.\n5. Model evaluation and improve the model\u00b6 \n","8b679b46":"## **K-nearest neighbor**","934305fd":"## **Fare vs Survived**","8ef6c5db":"## **Finding Important Features and Building Random Forest model**","f351c46c":"Train.csv will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the \u201cground truth\u201d.\n\nThe `test.csv` dataset contains similar information but does not disclose the \u201cground truth\u201d for each passenger. It\u2019s your job to predict these outcomes.\n\nUsing the patterns you find in the train.csv data, predict whether the other 418 passengers on board (found in test.csv) survived.","e42e81a3":"output1 = pd.DataFrame({'PassengerId': test.PassengerId,\n                       'Survived': y_pred})\noutput1.to_csv('submission1.csv', index=False)\n\n#reesult not good, try other model","cf9440f3":"## **Embarked vs Survived**","9968357b":"## **Evaluation**\n\n**Goal**\nIt is your job to predict if a passenger survived the sinking of the Titanic or not.\nFor each in the test set, you must predict a 0 or 1 value for the variable.\n\n**Metric**\nYour score is the percentage of passengers you correctly predict. This is known as accuracy.\n\n**Submission File Format**\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.\n\nThe file should have exactly 2 columns:\n\nPassengerId (sorted in any order)\nSurvived (contains your binary predictions: 1 for survived, 0 for deceased)","814c5182":"## **Pclass vs Survived**","9aaa6dd2":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': y_pred1}) \noutput.to_csv('submission.csv', index=False)","58c1b4ae":"## **Support Vector machine**","4053f231":"## **Gender vs Survived**"}}