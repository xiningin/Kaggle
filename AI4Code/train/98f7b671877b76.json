{"cell_type":{"c2d92c78":"code","628aa385":"code","dd8bfbf6":"code","ae3d6823":"code","086f3d55":"code","f375ac07":"code","1f9efeab":"code","129d83b3":"code","8610c520":"code","b52f363d":"code","82806686":"code","8d23e233":"code","6833d7b6":"code","08e40c50":"code","0e2b408c":"code","94a1e20a":"code","9d8947a7":"code","79030059":"markdown","e559818b":"markdown","dc07594c":"markdown","140fa2a5":"markdown","903e6484":"markdown","c4fbc773":"markdown","cea0dfae":"markdown","59679756":"markdown","c45493a4":"markdown","2d7eb955":"markdown","2f8c8522":"markdown","cf6170cf":"markdown","f5afac8b":"markdown","c86ec8e8":"markdown","6070d9e7":"markdown"},"source":{"c2d92c78":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","628aa385":"import tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nimport kerastuner as kt","dd8bfbf6":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\ntraining_set = train_datagen.flow_from_directory('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train',\n                                                  target_size = (64, 64),\n                                                  batch_size = 32,\n                                                  class_mode = 'binary')","ae3d6823":"test_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_set = test_datagen.flow_from_directory('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test',\n                                            target_size = (64, 64),\n                                            batch_size = 32,\n                                            class_mode = 'binary')","086f3d55":"cnn = tf.keras.models.Sequential()","f375ac07":"cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu', input_shape = [64, 64 , 3]))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n#\ncnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n#\ncnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","1f9efeab":"cnn.add(tf.keras.layers.Dropout(0.2))","129d83b3":"cnn.add(tf.keras.layers.Flatten())","8610c520":"cnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))","b52f363d":"cnn.add(tf.keras.layers.Dropout(0.2))","82806686":"cnn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n#print(cnn.summary())","8d23e233":"cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])","6833d7b6":"history = cnn.fit(x = training_set, validation_data = test_set, epochs = 10)","08e40c50":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nrec = history.history['recall']\nval_rec = history.history['val_recall']\n\nprec = history.history['precision']\nval_prec = history.history['val_precision']\n\n\nepochs_range = range(10)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.figure(figsize = (16,8))\nplt.subplot(1, 4, 1)\nplt.plot(epochs_range, acc, label = 'Training Accuracy')\nplt.plot(epochs_range, val_acc, label = 'Validation Accuracy')\nplt.legend(loc = 'lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 4, 2)\nplt.plot(epochs_range, loss, label = 'Training Loss')\nplt.plot(epochs_range, val_loss, label = 'Validation Loss')\nplt.legend(loc = 'upper right')\nplt.title('Training and Validation Loss')\n\nplt.subplot(1, 4, 3)\nplt.plot(epochs_range, rec, label = 'Training Recall')\nplt.plot(epochs_range, val_rec, label = 'Validation Recall')\nplt.legend(loc = 'lower right')\nplt.title('Training and Validation Recall')\n\nplt.subplot(1, 4, 4)\nplt.plot(epochs_range, prec, label = 'Training Precision')\nplt.plot(epochs_range, val_rec, label = 'Validation Precision')\nplt.legend(loc = 'lower right')\nplt.title('Training and Validation Precision')","0e2b408c":"import numpy as np\nfrom keras.preprocessing import image\ntest_image = image.load_img('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val\/PNEUMONIA\/person1954_bacteria_4886.jpeg', target_size = (64, 64))\ntest_image = image.img_to_array(test_image)\ntest_image = test_image\/255.0\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = cnn.predict(test_image)\ntraining_set.class_indices\nif result[0][0] > 0.5:\n    prediction = 'PNEUMONIA'\nelse:\n    prediction = 'NORMAL'\nprint(prediction)","94a1e20a":"def cnn_model_builder(hp):\n    \n    cnn_model = tf.keras.models.Sequential()\n    \n    cnn_model.add(tf.keras.layers.Conv2D(filters = hp.Int('conv_1_filter', min_value = 32, max_value = 128, step = 32),\n                                         kernel_size = hp.Choice('conv_1_kernel', values = [3, 5]),\n                                         activation = 'relu',\n                                         input_shape = [64, 64 ,3]))\n    \n    cnn_model.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n    \n    cnn_model.add(tf.keras.layers.Conv2D(filters = hp.Int('conv_2_filter', min_value = 32, max_value = 128, step = 32),\n                                         kernel_size = hp.Choice('conv_2_kernel', values = [3, 5]),\n                                         activation = 'relu'))\n    \n    cnn_model.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n    \n    \n    cnn_model.add(tf.keras.layers.Conv2D(filters = hp.Int('conv_3_filter', min_value = 32, max_value = 128, step = 32),\n                                         kernel_size = hp.Choice('conv_3_kernel', values = [3, 5]),\n                                         activation = 'relu'))\n    \n    cnn_model.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))    \n\n    cnn_model.add(tf.keras.layers.Dropout(hp.Float('dropout', 0.0, 0.5, step = 0.05, default = 0.5)))\n    \n    cnn_model.add(tf.keras.layers.Flatten())\n     \n    for z in range(hp.Int('num_layers', 2, 10)):\n        cnn_model.add(tf.keras.layers.Dense(units = hp.Int('units_' + str(z), min_value = 32, max_value = 512,step = 32), activation = 'relu'))\n    \n    \n    cnn_model.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n    \n    cnn_model.compile(optimizer = tf.keras.optimizers.Adam(hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4])),\n                      loss = 'binary_crossentropy',\n                      metrics = ['accuracy'])\n    \n    return cnn_model","9d8947a7":"import os\ntuner = kt.Hyperband(cnn_model_builder,\n                     objective = 'val_accuracy',\n                     max_epochs = 50,\n                     factor = 3,\n                     directory = os.path.normpath('\/kaggle\/output'))\n\ntuner.search(training_set,\n             validation_data = test_set,\n             epochs = 30)\n\n# Get the best hyperparameters #\nbest_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n\n# Compile the model with these parameters #\nmodel = tuner.hypermodel.build(best_hps)\nhistory_opt = model.fit(x = training_set, validation_data = test_set, epochs = 10)","79030059":"**Dropout layer**","e559818b":"**Importing the test set**","dc07594c":"**Output layer**","140fa2a5":"**Importing the training set - Data augmentation is also implemented in order to hep prevent or at least reduce overfitting**","903e6484":"**Compiling the CNN**","c4fbc773":"**ANN first hidden layer**","cea0dfae":"**Tuning the model's hyperparameters**","59679756":"**Convolution layers and pooling layers**","c45493a4":"# Building the CNN #","2d7eb955":"**Making a Single Prediction**","2f8c8522":"**Plotting training accuracy, recall and precision and validation accuracy, recall and precision**","cf6170cf":"**Importing the necessary libraries**","f5afac8b":"**Flattening layer**","c86ec8e8":"**Initialising the CNN**","6070d9e7":"**Dropout layer - Added to help prevent overfitting**"}}