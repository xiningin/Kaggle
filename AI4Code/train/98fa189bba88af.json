{"cell_type":{"0ad1e218":"code","b22ca5f8":"code","6373df21":"code","a760944d":"code","c1d373be":"code","43975112":"code","6b351c6d":"code","874d6340":"code","687af8c5":"code","774bf1b2":"code","f774a36b":"code","b621ad04":"code","aa57517c":"code","cf787a05":"code","8db86a3b":"code","f304bf63":"code","c31993c8":"code","2dd901d9":"code","3020d28f":"code","a9a8af80":"code","a2866420":"code","99e50f28":"code","e7f57b51":"code","a4312a1e":"code","e0701cdb":"code","d1b53605":"code","5b90daa3":"markdown","dd5378d7":"markdown","72bb8b06":"markdown","975275fa":"markdown","8d767c68":"markdown","0bf5ec68":"markdown","b38bbee5":"markdown","8c084770":"markdown","51c152de":"markdown","7d1e91ab":"markdown","7b14e6b8":"markdown","2c56a4f3":"markdown","ed9adae3":"markdown","48145b6f":"markdown","8af42b0b":"markdown","3b13bddf":"markdown","d701724b":"markdown","3709c2be":"markdown","fff3d3d1":"markdown"},"source":{"0ad1e218":"# import des biblioth\u00e8ques utilis\u00e9es\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, SGDRegressor, ElasticNet\nfrom sklearn.svm import SVR\nfrom sklearn.preprocessing import *\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.metrics import *\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom xgboost import XGBRegressor","b22ca5f8":"data = pd.read_csv(\"\/kaggle\/input\/refined-data\/data_hard_refined.csv\")\nprint(data.columns)\nprint(data.shape)\ndata.head()","6373df21":"data.describe()","a760944d":"print(data.ComplianceStatus.unique())\nprint(data.DefaultData.unique())","c1d373be":"data = data.drop(['SteamUse(kBtu)'], axis=1)","43975112":"data.info()","6b351c6d":"objectColumns = list(data.dtypes[data.dtypes == np.object].index)\nnumericColumns = list(data.dtypes[data.dtypes != np.object].index)\nprint(objectColumns)\nprint(numericColumns)","874d6340":"for column in objectColumns:\n    print('{}: {} uniques values'.format(column,len(data[column].unique())))","687af8c5":"data = data.drop(['PropertyName', 'Address'], axis=1)","774bf1b2":"data = data.drop(['OSEBuildingID', 'TaxParcelIdentificationNumber'], axis=1)","f774a36b":"# suite \u00e0 la suppression des outliers et \u00e0 nos nouvelles colonnes par surface on peut supprimer  les anciennes colonnes\n# data.drop(['SiteEnergyUse(kBtu)', 'TotalGHGEmissions'], axis=1, inplace=True)","b621ad04":"# on remet \u00e0 jour la liste des colonnes cat\u00e9gorielles\nobjectColumns = list(data.dtypes[data.dtypes == np.object].index)\nnumericColumns = list(data.dtypes[data.dtypes != np.object].index)\nprint(objectColumns)\nprint(numericColumns)","aa57517c":"#columns_to_drop=['SiteEnergyUse(kBtu)','Energy\/Surface', 'TotalGHGEmissions', 'GHG\/Surface']\n#y_columns=['Energy\/Surface', 'GHG\/Surface']\ny_columns = ['TotalGHGEmissions', 'SiteEnergyUse(kBtu)']\nX = data.drop(y_columns, axis=1)\n\nprint(X.shape)\ny = data[y_columns]\nprint(y.shape)\nprint(len(numericColumns))\nfor i in y_columns:\n    numericColumns.remove(i)\nprint(len(numericColumns))\n\n# X = data.drop(['TotalGHGEmissions', 'SiteEnergyUse(kBtu)'], axis=1)\n# y = data(['TotalGHGEmissions'])","cf787a05":"# standardiser les donn\u00e9es\npreprocessor = make_column_transformer((RobustScaler(),numericColumns),(OneHotEncoder(handle_unknown = 'ignore'),objectColumns))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","8db86a3b":"print(X.columns)\nprint(y.columns)","f304bf63":"model = make_pipeline(preprocessor,LinearRegression())\nmodel.fit(X_train,y_train)\nprint(\"score d'entrainement = \",model.score(X_train,y_train))\ny_pred = model.predict(X_test)\nprint(\"score de la pr\u00e9diction:\")#, accuracy_score(y_test, y_pred)), \nprint(\"MAE = \",mean_absolute_error(y_test,y_pred))\nprint(\"RMSE = \",np.sqrt(mean_squared_error(y_test,y_pred)))\nprint(\"median abs err = \",median_absolute_error(y_test,y_pred))","c31993c8":"for column in y_columns:\n    X_train, X_test, y_train, y_test = train_test_split(X, y[column], test_size=0.2)\n    model = make_pipeline(preprocessor,LinearRegression())\n    model.fit(X_train,y_train)\n    y_pred = model.predict(X_test)\n    print('M\u00e9thode: LinearRegression OneHotEncoder RobustScaler')\n    print('+ utilisation de pipelines')\n    print('Pr\u00e9diction de ',column)\n    print('score d\\'entrainement = ',model.score(X_train,y_train))\n    print(\"score de la pr\u00e9diction: \",  model.score(X_test, y_test)), \n    print(\"MAE = \",mean_absolute_error(y_test,y_pred))\n    print(\"RMSE = \",np.sqrt(mean_squared_error(y_test,y_pred)))\n    print(\"median abs err = \",median_absolute_error(y_test,y_pred))\n    print('')\n ","2dd901d9":"print(X.columns)\nprint(y.columns)","3020d28f":"\nX = data.drop(y_columns, axis=1)\ny = data[y_columns]\n\n# essais peu concluant avec les transformation appliqu\u00e9es avant.\nencoder=LabelEncoder()\nfor column in objectColumns:\n    X[column] = encoder.fit_transform(X[column])\n    \nencoder=StandardScaler()\nX_std = encoder.fit_transform(X)\n\nfor column in y_columns:\n    X_train, X_test, y_train, y_test = train_test_split(X_std, y[column], test_size=0.2)\n    model = LinearRegression()\n    model.fit(X_train,y_train)\n    y_pred = model.predict(X_test)\n    print('M\u00e9thode: LinearRegression LabelEncoder StandardScaler')\n    print('Pr\u00e9diction de ',column)\n    print('score d\\'entrainement = ',model.score(X_train,y_train))\n    print(\"score de la pr\u00e9diction:\"), \n    print(\"MAE = \",mean_absolute_error(y_test,y_pred))\n    print(\"RMSE = \",np.sqrt(mean_squared_error(y_test,y_pred)))\n    print(\"median abs err = \",median_absolute_error(y_test,y_pred))\n    print('')","a9a8af80":"# essais peu concluant avec les transformation appliqu\u00e9es avant.\nencoder= LabelBinarizer()\nfor column in objectColumns:\n    X[column] = encoder.fit_transform(X[column])\n    \nencoder=StandardScaler()\nX_std = encoder.fit_transform(X)\n\nfor column in y_columns:\n    X_train, X_test, y_train, y_test = train_test_split(X_std, y[column], test_size=0.2)\n    model = LinearRegression()\n    model.fit(X_train,y_train)\n    y_pred = model.predict(X_test)\n    print('M\u00e9thode: LinearRegression LabelBinarizer StandardScaler')\n    print('Pr\u00e9diction de ',column)\n    print('score d\\'entrainement = ',model.score(X_train,y_train))\n    print(\"score de la pr\u00e9diction:\"), \n    print(\"MAE = \",mean_absolute_error(y_test,y_pred))\n    print(\"RMSE = \",np.sqrt(mean_squared_error(y_test,y_pred)))\n    print(\"median abs err = \",median_absolute_error(y_test,y_pred))\n    print('')","a2866420":"n_bins = 20\nfig = plt.figure(figsize=(18,9))\nplt.hist(data['TotalGHGEmissions'],n_bins)\nplt.title('TotalGHGEmissions')\nplt.show()\nfig = plt.figure(figsize=(18,9))\nplt.hist(np.log(data['TotalGHGEmissions']),n_bins)\nplt.title('log TotalGHGEmissions')\nplt.show()","99e50f28":"results = []\nalgos = {\n    'LinearRegression' : LinearRegression(),\n    'Ridge' : Ridge(),\n    'Lasso' : Lasso(tol=0.5),\n    'ElasticNet' : ElasticNet(),\n    'SGDRegressor': SGDRegressor(),\n    'SVR': SVR(),\n    'RandomForestRegressor' : RandomForestRegressor(),\n    'XGBRegressor' : XGBRegressor()\n}\nX_train, X_test, y_train_all, y_test_all = train_test_split(X, y, test_size=0.2, random_state=1)","e7f57b51":"for algo_name, algo in algos.items():\n    print('Algorithme: ',algo_name)\n    for column in y_columns:\n        y_test = y_test_all[column]\n        y_train = y_train_all[column]\n        model = make_pipeline(preprocessor,algo)\n        model.fit(X_train,y_train)\n        y_pred = model.predict(X_test)\n        print('Pr\u00e9diction de ',column)\n        print('score d\\'entrainement = ',model.score(X_train,y_train))\n        print(\"score de la pr\u00e9diction: \",  model.score(X_test, y_test))\n        mae = mean_absolute_error(y_test,y_pred)\n        rmse = np.sqrt(mean_squared_error(y_test,y_pred))\n        med_abs_err = median_absolute_error(y_test,y_pred)\n        print(\"MAE = \", mae)        \n        print(\"RMSE = \",rmse)\n        print(\"median abs err = \", med_abs_err)\n        print('')\n        results.append([algo_name, column, model.score(X_test, y_test), mae, rmse, med_abs_err])\n    print('-'*100)","a4312a1e":"X_train = X_train.drop(['ENERGYSTARScore'], axis=1)\nX_test = X_test.drop(['ENERGYSTARScore'], axis=1)\nresults_without_energyStarScore = []\nnumericColumns.remove('ENERGYSTARScore')\nprint(numericColumns)\npreprocessor = make_column_transformer((RobustScaler(),numericColumns),(OneHotEncoder(handle_unknown = 'ignore'),objectColumns))","e0701cdb":"for algo_name, algo in algos.items():\n    print('Algorithme: ',algo_name)\n    for column in y_columns:\n        y_test = y_test_all[column]\n        y_train = y_train_all[column]\n        model = make_pipeline(preprocessor,algo)\n        model.fit(X_train,y_train)\n        y_pred = model.predict(X_test)\n        print('Pr\u00e9diction de ',column)\n        print('score d\\'entrainement = ',model.score(X_train,y_train))\n        print(\"score de la pr\u00e9diction: \",  model.score(X_test, y_test))\n        mae = mean_absolute_error(y_test,y_pred)\n        rmse = np.sqrt(mean_squared_error(y_test,y_pred))\n        med_abs_err = median_absolute_error(y_test,y_pred)\n        print(\"MAE = \", mae)        \n        print(\"RMSE = \",rmse)\n        print(\"median abs err = \", med_abs_err)\n        print('')\n        results_without_energyStarScore.append([algo_name, column, model.score(X_test, y_test), mae, rmse, med_abs_err])\n    print('-'*100)","d1b53605":"df_results = pd.DataFrame(results,columns=['algorithm', 'column','predict score', 'MAE', 'RMSE', 'median abs err'])\ndisplay(df_results.sort_values(by=['column','predict score'],ascending=False))\nprint(\"Sans le EnergyStarScore:\")\ndf_results_without_energyStarScore = pd.DataFrame(results_without_energyStarScore,columns=['algorithm', 'column','predict score', 'MAE', 'RMSE', 'median abs err'])\ndisplay(df_results_without_energyStarScore.sort_values(by=['column','predict score'],ascending=False))","5b90daa3":"On pourrait justifier un passage au log pour am\u00e9liorer la pr\u00e9cision des algorithme mais le RobustScaler nous permet de nous affranchir de cette transormation car il prend d\u00e9j\u00e0 en charge les changements d'\u00e9chelles et nivelle les diff\u00e9rences importantes et dans la pratique nous a donn\u00e9 de meilleurs r\u00e9sultats.","dd5378d7":"# <a id=\"conclude\">Conclusion<a\/>","72bb8b06":"Le score de pr\u00e9diction est assez correct, peut-il \u00eatre meilleur en utilisant un mod\u00e8le par variable \u00e0 pr\u00e9dire:","975275fa":"# <a id=\"preprocessing\">Pr\u00e9traitement<a\/> \n\n##  <a id=\"data-load-and-check\">Chargement et contr\u00f4le des donn\u00e9es<a\/>   ","8d767c68":"**Conclusion**\n\nLe choix des transformers utilis\u00e9s pour standardiser nos donn\u00e9es est tr\u00e8s impactant sur nos r\u00e9sultat. Un LabelEncoder ou un  LabelBinarizer associ\u00e9s avec des StandardScaler donne des r\u00e9sultats tr\u00e8s m\u00e9diocres. Un pipeline utilisant RobustScaler et OneHotEncoder donne des r\u00e9sultats bien meilleur et totalement admissible mais obligent par contre \u00e0 ignorer certaines lignes dont les cat\u00e9gories se retrouvent dans le jeu d'entrainement mais pas dans le jeu de test et ne sont par cons\u00e9quent pas connues du mod\u00e8le. On essaiera de gommer ces imperfections dans la suite avec une validation crois\u00e9e.\n\nessai rat\u00e9 avec le StratifiedShuffleSplit...","0bf5ec68":"# Sommaire\n\n1. [Pr\u00e9traitement](#preprcessing)  \n    1.1. [Chargement et contr\u00f4le des donn\u00e9es](#data-load-and-check)  \n    1.2. [Pr\u00e9paration des jeux de donn\u00e9es](#data-prepare)   \n    1.2. [Cas des outliers](#outliers)\n2. [R\u00e9gression lin\u00e9aire basique](#simple-linear-regression)  \n3. [Comparaison des mod\u00e8les](#model-compare)  \n4. [Comparaison des mod\u00e8les sans le EnergyStarScore](#model-compare-without-ESS)  \n5. [Conclusion](#conclude)","b38bbee5":"##  <a id=\"data-prepare\">Pr\u00e9paration des jeux de donn\u00e9es<a\/>   ","8c084770":"Idem pour 'OSEBuildingID', 'TaxParcelIdentificationNumber' dans les variables num\u00e9riques.","51c152de":"N'ayant pas fait d'analyse pouss\u00e9e sur les outliers je vais utiliser le RobustScaler (les statistiques de centrage et de mise \u00e0 l'\u00e9chelle de RobustScaler sont bas\u00e9es sur des centiles et ne sont donc pas influenc\u00e9es par un petit nombre de valeurs aberrantes marginales tr\u00e8s importantes) pour les valeurs num\u00e9riques et le OneHotEncoderpour les cat\u00e9gories","7d1e91ab":"Certaines colonnes sont li\u00e9es \u00e0 l'identification du batiment. C'est le cas de 'PropertyName', 'Address'. Nous allons donc les enlever car peu exploitable. De plus si on voulait utiliser une technique li\u00e9e \u00e0 la proximit\u00e9 entre les batiments, la longitude et la latitude serait plus facilement utilisable que l'adresse. Les autres sont des variables cat\u00e9gorielles. ","7b14e6b8":"# <a id=\"model-compare\">Comparaison des mod\u00e8les<a\/> ","2c56a4f3":"##  <a id=\"outliers\">Cas des outliers<a\/>   \n    \n    J'ai fait des tests avec le jeu de donn\u00e9es \u00e9pur\u00e9s des outliers mais les r\u00e9sultat \u00e9taient moins bon, j'ai donc d\u00e9cid\u00e9 de continuer \u00e0 travailler avec le jeu de donn\u00e9es initiales.","ed9adae3":"    Le XGBRegresson et le RandomForestRegressor sont nos deux algorithmes les plus performants. Ils obtiennent des r\u00e9sultats tr\u00e8s satisfaisants. Cependant une optimisation des param\u00e8tres des diff\u00e9rents algorithmes pourrait cr\u00e9er des diff\u00e9rences. On va donc chercher \u00e0 optimiser les param\u00e8tres de ces diff\u00e9rents algorithme par le biais d'une validation crois\u00e9e. Nous supprimerons n\u00e9anmoins le SGDRegressor qui est totalement contre-performant et le SVR qui a des r\u00e9sultats pas assez bon.","48145b6f":"On a fait certaines approximations avec ce mod\u00e8le: certraines cat\u00e9gories  (celles du jeu de test) n'ont malheureusement pas \u00e9t\u00e9 encod\u00e9es. Cela g\u00e9n\u00e9rait des erreurs qu'on a d\u00e9cid\u00e9 d'ignorer avec le param\u00e8tre handle_unknown = 'ignore' du OneHotEncoder. Il faudrait donc pour une telle  m\u00e9thode se passer de l'utilisation des p\u00eepeline ou il faudrait appliquer la modification avant au rique de cr\u00e9er une fuite des donn\u00e9es?","8af42b0b":"Pour r\u00e9pondre au consigne de l'\u00e9nonc\u00e9 nous devons supprimer les donn\u00e9es li\u00e9es \u00e0 la consommation \u00e9nerg\u00e9tique car les relev\u00e9s sont co\u00fbteux \u00e0 obtenir. Nous supprimons donc la colonne 'SteamUse(kBtu)'","3b13bddf":"<div style=\"width:100%;text-align: center;\">\n    <img src=\"https:\/\/user.oc-static.com\/upload\/2019\/02\/24\/15510245026714_Seattle_logo_landscape_blue-black.png\" \/>\n<\/div>\n\n# Introduction\n\nVous travaillez pour la ville de Seattle. Pour atteindre son objectif de ville neutre en \u00e9missions de carbone en 2050, votre \u00e9quipe s\u2019int\u00e9resse de pr\u00e8s aux \u00e9missions des b\u00e2timents non destin\u00e9s \u00e0 l\u2019habitation.\n\nDes relev\u00e9s minutieux ont \u00e9t\u00e9 effectu\u00e9s par vos agents en 2015 et en 2016. Cependant, ces relev\u00e9s sont co\u00fbteux \u00e0 obtenir, et \u00e0 partir de ceux d\u00e9j\u00e0 r\u00e9alis\u00e9s, vous voulez tenter de pr\u00e9dire les \u00e9missions de CO2 et la consommation totale d\u2019\u00e9nergie de b\u00e2timents pour lesquels elles n\u2019ont pas encore \u00e9t\u00e9 mesur\u00e9es.\n\nVotre pr\u00e9diction se basera sur les donn\u00e9es d\u00e9claratives du permis d'exploitation commerciale (taille et usage des b\u00e2timents, mention de travaux r\u00e9cents, date de construction..)\n\nVous cherchez \u00e9galement \u00e0 \u00e9valuer l\u2019int\u00e9r\u00eat de l\u2019\"ENERGY STAR Score\" pour la pr\u00e9diction d\u2019\u00e9missions, qui est fastidieux \u00e0 calculer avec l\u2019approche utilis\u00e9e actuellement par votre \u00e9quipe.\n","d701724b":"Certaines colonnes ne sont pas num\u00e9rique, il va falloir les modifier. Analysons plus en d\u00e9tail leur contenu:","3709c2be":"# <a id=\"simple-linear-regression\">R\u00e9gression lin\u00e9aire basique<a\/>","fff3d3d1":"# <a id=\"model-compare-without-ESS\">Comparaison des mod\u00e8les sans le EnergyStarScore<a\/> "}}