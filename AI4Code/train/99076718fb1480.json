{"cell_type":{"eb7b2016":"code","ab073850":"code","f62d2b55":"code","a59a7cfa":"code","3f5732d2":"code","10ea1a8d":"code","7e5b9f7a":"code","ee5375b7":"code","6297cdcc":"code","ac9ccffd":"code","a2c58d41":"code","869afd9a":"markdown","b8e2f66a":"markdown","b4dee4c5":"markdown","9c67467e":"markdown","357a3faf":"markdown","b1f36e82":"markdown","a92061c1":"markdown","1c58bc5f":"markdown","858a6fc7":"markdown"},"source":{"eb7b2016":"!pip install --quiet \/kaggle\/input\/kerasapplications\n!pip install --quiet \/kaggle\/input\/efficientnet-git","ab073850":"import math, os, re, warnings, random, glob\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import Sequential, Model\nimport efficientnet.tfkeras as efn\n\ndef seed_everything(seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nseed = 0\nseed_everything(seed)\nwarnings.filterwarnings('ignore')","f62d2b55":"# TPU or GPU detection\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(f'Running on TPU {tpu.master()}')\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nAUTO = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","a59a7cfa":"BATCH_SIZE = 16 * REPLICAS\nHEIGHT = 512\nWIDTH = 512 \nCHANNELS = 3\nN_CLASSES = 5\nTTA_STEPS = 0 # Do TTA if > 0 \nUSE_REGULAR = False\nUSE_SCL = True","3f5732d2":"def data_augment(image, label):\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n            \n    # Flips\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if p_spatial > .75:\n        image = tf.image.transpose(image)\n        \n    # Rotates\n    if p_rotate > .75:\n        image = tf.image.rot90(image, k=3) # rotate 270\u00ba\n    elif p_rotate > .5:\n        image = tf.image.rot90(image, k=2) # rotate 180\u00ba\n    elif p_rotate > .25:\n        image = tf.image.rot90(image, k=1) # rotate 90\u00ba\n        \n    # Pixel-level transforms\n    if p_pixel_1 >= .4:\n        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n    if p_pixel_2 >= .4:\n        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n    if p_pixel_3 >= .4:\n        image = tf.image.random_brightness(image, max_delta=.1)\n        \n    # Crops\n    if p_crop > .6:\n        if p_crop > .9:\n            image = tf.image.central_crop(image, central_fraction=.5)\n        elif p_crop > .8:\n            image = tf.image.central_crop(image, central_fraction=.6)\n        elif p_crop > .7:\n            image = tf.image.central_crop(image, central_fraction=.7)\n        else:\n            image = tf.image.central_crop(image, central_fraction=.8)\n    elif p_crop > .3:\n        crop_size = tf.random.uniform([], int(HEIGHT*.6), HEIGHT, dtype=tf.int32)\n        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n            \n    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\n        \n    return image, label","10ea1a8d":"# Datasets utility functions\ndef get_name(file_path):\n    parts = tf.strings.split(file_path, os.path.sep)\n    name = parts[-1]\n    return name\n\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    \n#     image = center_crop(image)\n    return image\n\ndef center_crop(image):\n    image = tf.reshape(image, [600, 800, CHANNELS]) # Original shape\n    \n    h, w = image.shape[0], image.shape[1]\n    if h > w:\n        image = tf.image.crop_to_bounding_box(image, (h - w) \/\/ 2, 0, w, w)\n    else:\n        image = tf.image.crop_to_bounding_box(image, 0, (w - h) \/\/ 2, h, h)\n        \n    image = tf.image.resize(image, [HEIGHT, WIDTH]) # Expected shape\n    return image\n\ndef resize_image(image, label):\n    image = tf.image.resize(image, [HEIGHT, WIDTH])\n    image = tf.reshape(image, [HEIGHT, WIDTH, CHANNELS])\n    return image, label\n\ndef process_path(file_path):\n    name = get_name(file_path)\n    img = tf.io.read_file(file_path)\n    img = decode_image(img)\n    return img, name\n\ndef get_dataset(files_path, shuffled=False, tta=False, extension='jpg'):\n    dataset = tf.data.Dataset.list_files(f'{files_path}*{extension}', shuffle=shuffled)\n    dataset = dataset.map(process_path, num_parallel_calls=AUTO)\n    if tta:\n        dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.map(resize_image, num_parallel_calls=AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)","7e5b9f7a":"database_base_path = '\/kaggle\/input\/cassava-leaf-disease-classification\/'\nsubmission = pd.read_csv(f'{database_base_path}sample_submission.csv')\ndisplay(submission.head())\n\nTEST_FILENAMES = tf.io.gfile.glob(f'{database_base_path}test_tfrecords\/ld_test*.tfrec')\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\nprint(f'GCS: test: {NUM_TEST_IMAGES}')","ee5375b7":"model_path_list = glob.glob('\/kaggle\/input\/cassava-leaf-supervised-contrastive-learning\/model_reg*.h5')\nmodel_path_list.sort()\n\nprint('Models to predict:')\nprint(*model_path_list, sep='\\n')\n\nmodel_path_list_scl = glob.glob('\/kaggle\/input\/cassava-leaf-supervised-contrastive-learning\/model_scl*.h5')\nmodel_path_list_scl.sort()\n\nprint('\\nModels to predict:')\nprint(*model_path_list_scl, sep='\\n')","6297cdcc":"def encoder_fn(input_shape):\n    inputs = L.Input(shape=input_shape, name='inputs')\n    base_model = efn.EfficientNetB3(input_tensor=inputs, \n                                    include_top=False, \n                                    weights=None, \n                                    pooling='avg')\n    \n    model = Model(inputs=inputs, outputs=base_model.outputs)\n\n    return model\n\n\ndef classifier_fn(input_shape, N_CLASSES, encoder, trainable=True):\n    for layer in encoder.layers:\n        layer.trainable = trainable\n        \n    inputs = L.Input(shape=input_shape, name='inputs')\n    \n    features = encoder(inputs)\n    features = L.Dropout(.5)(features)\n    features = L.Dense(1000, activation='relu')(features)\n    features = L.Dropout(.5)(features)\n    outputs = L.Dense(N_CLASSES, activation='softmax', name='outputs', dtype='float32')(features)\n\n    model = Model(inputs=inputs, outputs=outputs)\n\n    return model","ac9ccffd":"files_path = f'{database_base_path}test_images\/'\ntest_size = len(os.listdir(files_path))\ntest_preds = np.zeros((test_size, N_CLASSES))\n\n\nif USE_REGULAR:\n    print('Inference for regular trainining models')\n    with strategy.scope():\n        encoder = encoder_fn((None, None, CHANNELS))\n        model = classifier_fn((None, None, CHANNELS), N_CLASSES, encoder)\n\n    for model_path in model_path_list:\n        print(model_path)\n        K.clear_session()\n        model.load_weights(model_path)\n\n        if TTA_STEPS > 0:\n            test_ds = get_dataset(files_path, tta=True).repeat()\n            ct_steps = TTA_STEPS * ((test_size\/BATCH_SIZE) + 1)\n            preds = model.predict(test_ds, steps=ct_steps, verbose=1)[:(test_size * TTA_STEPS)]\n            preds = np.mean(preds.reshape(test_size, TTA_STEPS, N_CLASSES, order='F'), axis=1)\n            test_preds += preds \/ len(model_path_list)\n        else:\n            test_ds = get_dataset(files_path, tta=False)\n            x_test = test_ds.map(lambda image, image_name: image)\n            test_preds += model.predict(x_test) \/ len(model_path_list)\n        \n        \nif USE_SCL:\n    print('\\nInference for \"Supervised Contrastive Learning\" models')\n    with strategy.scope():\n        encoder = encoder_fn((None, None, CHANNELS))\n        model = classifier_fn((None, None, CHANNELS), N_CLASSES, encoder, trainable=False)\n\n    for model_path in model_path_list_scl:\n        print(model_path)\n        K.clear_session()\n        model.load_weights(model_path)\n\n        if TTA_STEPS > 0:\n            test_ds = get_dataset(files_path, tta=True).repeat()\n            ct_steps = TTA_STEPS * ((test_size\/BATCH_SIZE) + 1)\n            preds = model.predict(test_ds, steps=ct_steps, verbose=1)[:(test_size * TTA_STEPS)]\n            preds = np.mean(preds.reshape(test_size, TTA_STEPS, N_CLASSES, order='F'), axis=1)\n            test_preds += preds \/ len(model_path_list_scl)\n        else:\n            test_ds = get_dataset(files_path, tta=False)\n            x_test = test_ds.map(lambda image, image_name: image)\n            test_preds += model.predict(x_test) \/ len(model_path_list_scl)\n    \ntest_preds = np.argmax(test_preds, axis=-1)\ntest_names_ds = get_dataset(files_path)\nimage_names = [img_name.numpy().decode('utf-8') for img, img_name in iter(test_names_ds.unbatch())]","a2c58d41":"submission = pd.DataFrame({'image_id': image_names, 'label': test_preds})\nsubmission.to_csv('submission.csv', index=False)\ndisplay(submission.head())","869afd9a":"<center><img src=\"https:\/\/raw.githubusercontent.com\/dimitreOliveira\/MachineLearning\/master\/Kaggle\/Cassava%20Leaf%20Disease%20Classification\/banner.png\" width=\"1000\"><\/center>\n<br>\n<center><h1>Cassava Leaf Disease - Supervised Contrastive Learning - Inference<\/h1><\/center>\n<br>\n\n- This is the inference part of the work, the training notebook can be found here [Cassava Leaf - Supervised Contrastive Learning](https:\/\/www.kaggle.com\/dimitreoliveira\/cassava-leaf-supervised-contrastive-learning)\n- keras-applications GitHub repository can be found [here](https:\/\/www.kaggle.com\/dimitreoliveira\/kerasapplications)\n- efficientnet GitHub repository can be found [here](https:\/\/www.kaggle.com\/dimitreoliveira\/efficientnet-git)\n- Dataset source `center cropped` [512x512](https:\/\/www.kaggle.com\/dimitreoliveira\/cassava-leaf-disease-50-tfrecords-center-512x512)\n- Dataset source `external data` `center cropped` [512x512](https:\/\/www.kaggle.com\/dimitreoliveira\/cassava-leaf-disease-50-tfrecords-external-512x512)\n- Dataset source [discussion thread](https:\/\/www.kaggle.com\/c\/cassava-leaf-disease-classification\/discussion\/198744)\n- Dataset [creation source](https:\/\/www.kaggle.com\/dimitreoliveira\/cassava-leaf-disease-stratified-tfrecords-256x256)","b8e2f66a":"# Augmentation","b4dee4c5":"### Hardware configuration","9c67467e":"# Load data","357a3faf":"## Dependencies","b1f36e82":"## Auxiliary functions","a92061c1":"# Model","1c58bc5f":"# Model parameters","858a6fc7":"# Test set predictions"}}