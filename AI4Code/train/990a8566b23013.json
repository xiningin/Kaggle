{"cell_type":{"497ec184":"code","5076ed75":"code","f32a801b":"code","438d4f49":"code","dc73e5c6":"code","7638dc0c":"code","2616006f":"code","498bb6bb":"code","c6512876":"code","839df450":"code","59fddc21":"code","250bb9ce":"code","a84781f0":"code","4e7b3f94":"code","01772bcb":"code","0f7937a4":"code","d474e766":"code","672111a5":"code","a07bed85":"code","44bd66ff":"code","b5e1abe9":"code","aedf1a49":"code","6501cea5":"code","d976b941":"code","a3e6a408":"code","06667690":"code","05016c4c":"code","0fc20fee":"code","01fae419":"code","434bfa06":"code","2dc427cf":"code","2bdf44c1":"code","1d80276e":"markdown","893d44ad":"markdown","dee390b9":"markdown","9d70d360":"markdown","ab224e14":"markdown","e87969b5":"markdown","1a990fff":"markdown","0419d113":"markdown","8155a40d":"markdown"},"source":{"497ec184":"import numpy as np \nimport pandas as pd\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5076ed75":"for dirname, _, filenames in os.walk('\/kaggle\/input\/aptos2019-blindness-detection\/'):\n    print(dirname)","f32a801b":"BASE_PATH='\/kaggle\/input\/aptos2019-blindness-detection\/'\ntrain_dataset=pd.read_csv(os.path.join(BASE_PATH,'train.csv'))\ntest_dataset=pd.read_csv(os.path.join(BASE_PATH,'test.csv'))","438d4f49":"train_dataset.head(3)","dc73e5c6":"test_dataset.head(3)","7638dc0c":"from PIL import Image\nfrom matplotlib.pyplot import imshow\nimport matplotlib.pyplot as plt\nfig=plt.figure(figsize=(32, 32))\ncolumns = 3\nrows = 5\nfor i in range(1,rows*columns+1):\n    IMG_PATH=BASE_PATH+'train_images\/'\n    img=Image.open(os.path.join(IMG_PATH,train_dataset.iloc[i][0]+'.png'))\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\nplt.show()","2616006f":"!pip install --upgrade efficientnet-pytorch","498bb6bb":"!pip install torchsummary","c6512876":"import PIL\nimport torch\nfrom time import time\nimport torchvision\nfrom PIL import Image\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils import data\nfrom torchsummary import summary\nfrom torch.autograd import Variable\nimport torchvision.transforms as transforms\nfrom efficientnet_pytorch import EfficientNet","839df450":"class Dataset(data.Dataset):\n    def __init__(self,csv_path,images_path,transform=None):\n        self.train_set=pd.read_csv(csv_path)\n        self.train_path=images_path\n        self.transform=transform\n    def __len__(self):\n        return len(self.train_set)\n    \n    def __getitem__(self,idx):\n        file_name=self.train_set.iloc[idx][0]+'.png'\n        label=self.train_set.iloc[idx][1]\n        img=Image.open(os.path.join(self.train_path,file_name))\n        if self.transform is not None:\n            img=self.transform(img)\n        return img,label","59fddc21":"params = {'batch_size': 16,\n          'shuffle': True\n         }\nepochs = 100\nlearning_rate=1e-3","250bb9ce":"transform_train = transforms.Compose([transforms.Resize((224,224)),transforms.RandomApply([\n        torchvision.transforms.RandomRotation(10),\n        transforms.RandomHorizontalFlip()],0.7),\n\t\ttransforms.ToTensor()])","a84781f0":"training_set=Dataset(os.path.join(BASE_PATH,'train.csv'),os.path.join(BASE_PATH,'train_images\/'),transform=transform_train)\ntraining_generator=data.DataLoader(training_set,**params)","4e7b3f94":"use_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\nprint(device)","01772bcb":"model = EfficientNet.from_pretrained('efficientnet-b7', num_classes=5)","0f7937a4":"model.to(device)","d474e766":"print(summary(model, input_size=(3, 224, 224)))","672111a5":"PATH_SAVE='.\/Weights\/'\nif(not os.path.exists(PATH_SAVE)):\n    os.mkdir(PATH_SAVE)","a07bed85":"criterion = nn.CrossEntropyLoss()\nlr_decay=0.99\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","44bd66ff":"eye = torch.eye(5).to(device)\nclasses=[0,1,2,3,4]","b5e1abe9":"history_accuracy=[]\nhistory_loss=[]\nepochs = 25","aedf1a49":"\"\"\"for epoch in range(epochs):  \n    running_loss = 0.0\n    correct=0\n    total=0\n    class_correct = list(0. for _ in classes)\n    class_total = list(0. for _ in classes)\n    for i, data in enumerate(training_generator, 0):\n        inputs, labels = data\n        t0 = time()\n        inputs, labels = inputs.to(device), labels.to(device)\n        labels = eye[labels]\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, torch.max(labels, 1)[1])\n        _, predicted = torch.max(outputs, 1)\n        _, labels = torch.max(labels, 1)\n        c = (predicted == labels.data).squeeze()\n        correct += (predicted == labels).sum().item()\n        total += labels.size(0)\n        accuracy = float(correct) \/ float(total)\n        \n        history_accuracy.append(accuracy)\n        history_loss.append(loss)\n        \n        loss.backward()\n        optimizer.step()\n        \n        for j in range(labels.size(0)):\n            label = labels[j]\n            class_correct[label] += c[j].item()\n            class_total[label] += 1\n        \n        running_loss += loss.item()\n        \n        print( \"Epoch : \",epoch+1,\" Batch : \", i+1,\" Loss :  \",running_loss\/(i+1),\" Accuracy : \",accuracy,\"Time \",round(time()-t0, 2),\"s\" )\n    for k in range(len(classes)):\n        if(class_total[k]!=0):\n            print('Accuracy of %5s : %2d %%' % (classes[k], 100 * class_correct[k] \/ class_total[k]))\n        \n    print('[%d epoch] Accuracy of the network on the Training images: %d %%' % (epoch+1, 100 * correct \/ total))\n        \n    if epoch%10==0 or epoch==0:\n        torch.save(model.state_dict(), os.path.join(PATH_SAVE,str(epoch+1)+'_'+str(accuracy)+'.pth'))\n        \n\"\"\"","6501cea5":"plt.plot(history_accuracy)\nplt.plot(history_loss)","d976b941":"model.load_state_dict(torch.load('\/kaggle\/input\/efficient-net\/Weights\/21_0.9243582741671218.pth'))","a3e6a408":"model.eval()","06667690":"test_transforms = transforms.Compose([transforms.Resize(512),\n                                      transforms.ToTensor(),\n                                     ])","05016c4c":"def predict_image(image):\n    image_tensor = test_transforms(image)\n    image_tensor = image_tensor.unsqueeze_(0)\n    input = Variable(image_tensor)\n    input = input.to(device)\n    output = model(input)\n    index = output.data.cpu().numpy().argmax()\n    return index","0fc20fee":"submission=pd.read_csv(BASE_PATH+'sample_submission.csv')","01fae419":"submission.head(3)","434bfa06":"submission_csv=pd.DataFrame(columns=['id_code','diagnosis'])","2dc427cf":"IMG_TEST_PATH=os.path.join(BASE_PATH,'test_images\/')\nfor i in range(len(submission)):\n    img=Image.open(IMG_TEST_PATH+submission.iloc[i][0]+'.png')\n    prediction=predict_image(img)\n    submission_csv=submission_csv.append({'id_code': submission.iloc[i][0],'diagnosis': prediction},ignore_index=True)\n    if(i%10==0 or i==len(submission)-1):\n        print('[',32*'=','>] ',round((i+1)*100\/len(submission),2),' % Complete')","2bdf44c1":"submission_csv.to_csv('submission.csv',index=False)","1d80276e":"# **Visualizing Training Data**","893d44ad":"# **Inference**","dee390b9":"# **Directory**","9d70d360":"## **Defining Transforms and Parameters for Training**","ab224e14":"## **Importing the Model (Efficient Net)**","e87969b5":"## **Visualizing The Training Accuracy and losses**","1a990fff":"# **Training The Model**","0419d113":"## ****Importing and Installing Libraries****","8155a40d":"## **Data-Loader**"}}