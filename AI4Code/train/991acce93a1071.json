{"cell_type":{"e8319084":"code","1a0a550e":"code","d00477d8":"code","8850354b":"code","c3e6b857":"code","e5f93dec":"code","ea4367a4":"code","19cbfb32":"code","e766e026":"code","54eb0261":"code","720fd5d0":"code","dd081932":"code","99e5202a":"code","cfc10206":"code","65bab381":"code","42c65a7a":"code","05044876":"code","bbfc09ac":"code","07e40696":"code","1c675097":"code","9ca79a0a":"code","ebce6762":"code","05fd1051":"code","b6e48aab":"code","db313be1":"code","f6cd0b46":"code","c20f8c44":"code","a95ba618":"markdown","919ae779":"markdown","e7b299d7":"markdown","da54a100":"markdown","69388a97":"markdown","a7d6b444":"markdown","35a5df61":"markdown","67dc8da0":"markdown","122ece24":"markdown","2e5e2495":"markdown","b79d9044":"markdown","fab5f9b1":"markdown","2d1118eb":"markdown","6d796fd4":"markdown","57cbccdd":"markdown","7a6bb97d":"markdown","05d7c519":"markdown","438b90d1":"markdown","8284d4d3":"markdown","75fd0418":"markdown","3c4aea64":"markdown","cb362940":"markdown","28ceba67":"markdown","21093370":"markdown","69cd395c":"markdown","7edd1acb":"markdown","c6bf5715":"markdown","fd139588":"markdown","f01ad8d0":"markdown","b964c414":"markdown","02664965":"markdown","f53cace6":"markdown","7d959214":"markdown"},"source":{"e8319084":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom warnings import filterwarnings\nfrom lightgbm import LGBMClassifier\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_validate,KFold, GridSearchCV, cross_val_score\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nimport seaborn as sns\n## Setting RC param in MatplotLib for better Visulaziation\nplt.rc('xtick',labelsize=20)\nplt.rc('ytick',labelsize=20)\n\nfilterwarnings(\"ignore\")","1a0a550e":"heart_df = pd.read_csv('..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')\nheart_df","d00477d8":"# Getting to know your data\nheart_df.describe()","8850354b":"# No Missing Value is Present in Given Dataset\nheart_df.isna().sum()","c3e6b857":"# All Columns are either interger or floating number and no missing values.\nheart_df.info()","e5f93dec":"# Unique Value in all Columns of Datasets\nheart_df.nunique()","ea4367a4":"# We have sub classify our column into three Catergory\noridinal_col = ['sex', 'fbs','exng', 'cp', 'restecg', 'slp', 'caa', 'thall']\nnumerical_col = ['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']\noutput = ['output']","19cbfb32":"fig, ax = plt.subplots(nrows=5, ncols=2, figsize=(22, 40), gridspec_kw={\n                       'width_ratios': [1.3, 1], 'wspace': 0.3, 'hspace': 0.3})\nsns.set_style('whitegrid')\n\ncol = ['age', 'chol', 'trtbps', 'thalachh', 'oldpeak']\ntitle = ['Age', 'Cholesterol', 'Blood Pressure', 'Heart Rate', 'Previous Peak']\ncolors = [\"#5947ee\", \"#5f8de9\", \"#05548b\", \"#06a6b9\", \"#028f89\"]\nfor i in range(5):\n    label_density_plot = 'Skewness   ' + str(np.around(heart_df[col[i]].skew(), 3)) +\\\n        '\\nKurtosis       ' + str(np.round(heart_df[col[i]].kurtosis(), 3)) +\\\n        '\\nMean           ' + str(np.round(heart_df[col[i]].mean(), 3)) +\\\n        '\\nVariance       ' + str(np.round(heart_df[col[i]].var(), 3))\n\n    label_box_plot = 'Maximum  ' + str(heart_df[col[i]].max()) +\\\n        '\\nInter Quartile Range  ' + str(np.percentile(heart_df[col[i]], 75) - np.percentile(heart_df['age'], 25)) +\\\n        '\\nMedian   ' + str(heart_df[col[i]].median()) +\\\n        '\\nMinimum  ' + str(heart_df[col[i]].min())\n\n    sns.distplot(bins=60, kde=True,\n                 a=heart_df[col[i]], norm_hist=True, color=colors[i], ax=ax[i, 0])\n    ax[i, 0].legend([label_density_plot],\n                    loc='upper right', fontsize='x-large')\n    ax[i, 0].set_xlabel(title[i], fontdict={'size': 16})\n    ax[i, 0].set_title(title[i]+'[Density Plot]', fontdict={'size': 20})\n\n    sns.boxenplot(x=heart_df[col[i]], ax=ax[i, 1], orient='v', color=colors[i])\n    ax[i, 1].legend([label_box_plot], loc='upper right', fontsize='x-large')\n    ax[i, 1].set_title(title[i]+'[Box-Plot]', fontdict={'size': 20})\n    ax[i, 1].set_xlabel(title[i], fontdict={'size': 16})\n    ax[i, 1].set_ylabel('')\n\nplt.show()","e766e026":"col = ['sex', 'cp', 'fbs', 'restecg', 'exng', 'slp', 'caa', 'thall']\n\ntitle = ['Sex', 'Chest Pain', 'Fasting Blood Sugar', 'Resting Electrocardiographic',\n         'Exercise induced angina', 'Slope', 'Number of Major Vessel', 'Thalium Stress Test']\n\nlegend = [['Female', 'Male'], ['Typical Angina', 'Atypical Angina', 'Non-Anginal Pain', 'Asymptomatic'],\n          ['Less than 120 ', 'Greater than 120'], [\n              'Normal', 'St-T wave abnormality', 'Hypertrophy'],\n          ['No', 'Yes'], ['Downsloping', 'Flat', 'UpSloping'], [0, 1, 2, 3, 4],\n          ['No Defect', 'Fixed Defect', 'Normal', 'Reversable Defect']]\n\nsns.set_palette('Set2')\n\nfig, ax = plt.subplots(3, 3, figsize=(30, 28), gridspec_kw={'hspace': 0.21})\nk = 0\n\nfor i in range(3):\n    if i == 2:\n        for j in range(2):\n            sns.countplot(x=heart_df[col[k]], ax=ax[i, j])\n\n            ax[i, j].set_title(title[k], fontdict={'size': 30})\n            ax[i, j].set_xlabel('')\n            ax[i, j].set_ylabel('')\n            ax[i, j].set_xticklabels(legend[k], fontdict={'size': 23})\n            ax[i, j].legend('')\n\n            for z in ax[i, j].patches:\n                text = str(z.get_height()) + '(' + \\\n                    str(np.round(z.get_height()\/len(heart_df), 2)) + ')'\n                ax[i, j].annotate(\n                    text, (z.get_x()+0.09, z.get_height()+1), size=24)\n\n            k += 1\n\n    else:\n        for j in range(3):\n            sns.countplot(x=heart_df[col[k]], ax=ax[i, j])\n\n            ax[i, j].set_title(title[k], fontdict={'size': 30})\n            ax[i, j].set_xticklabels(legend[k], fontdict={'size': 23})\n            ax[i, j].set_xlabel('')\n            ax[i, j].set_ylabel('')\n            ax[i, j].legend('')\n\n            for z in ax[i, j].patches:\n                text = str(z.get_height()) + '(' + \\\n                    str(np.round(z.get_height()\/len(heart_df), 2)) + ')'\n                ax[i, j].annotate(\n                    text, (z.get_x()+0.09, z.get_height()+1), size=24)\n\n            k += 1\n\nax[0, 1].set_xticklabels(legend[1], fontdict={'size': 15})\nax[1, 0].set_xticklabels(legend[3], fontdict={'size': 20})\n\nax[2, 1].set_xticklabels(legend[7], fontdict={'size': 20})\ntext = \"Every Single Bar has a\\nNumber Which Show\\nCount of that paticular\\nValue and\\nCount \/ Total Count\"\nax[2, 2].annotate(text, (0.01, 0.4), size=40,\n                  family=\"MS Mincho\", color=\"#007696\")\nax[2, 2].axis('off')\nplt.show()","54eb0261":"fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n\nsns.set_style('whitegrid')\nsns.countplot(x=heart_df['output'], ax=ax, palette=\"RdBu\")\n\nax.set_title('Chance of Heart Attack', fontdict={'size': 20})\nax.set_xticklabels(['Less Chance of\\nHeart Attack',\n                    'High Chance of\\nHear Attack'], fontdict={'size': 15})\n\nfor i in ax.patches:\n    text = \"Count --> \" + str(i.get_height()) + '(' + \\\n        str(np.round(i.get_height()\/len(heart_df), 2)) + ')'\n    ax.annotate(text, (i.get_x()+0.1, i.get_height()+1.5), size=14)\n\nax.set_xlabel('')\nax.set_ylabel('')\n\nplt.show()","720fd5d0":"sns.set_style('darkgrid')\n\ncol = ['chol', 'thalachh', 'trtbps']\n\ntitle = ['Cholesterol', 'Heart Rate', 'Blood Pressure']\n\nfig, ax = plt.subplots(3, 1, figsize=(30, 30), gridspec_kw={\"hspace\": 0.25})\n\nfor i in range(3):\n    g = sns.lineplot(x=\"age\", data=heart_df, y=col[i], hue='output', ax=ax[i])\n    g.set_title(\"Age Variation with \" + title[i], fontdict={'size': 35})\n    g.legend(['Low Chance of Heart Attack',\n              'High Chance of Heart Attack'], fontsize=18)\n    g.set_xlabel(\"Age\", fontdict={'size': 25})\n    g.set_ylabel(title[i], fontdict={'size': 25})\n    \nplt.show()","dd081932":"fig, ax = plt.subplots(4, 1, figsize=(20, 28), gridspec_kw={'hspace': 0.35})\n\ncol = ['age', 'thalachh', 'chol', 'trtbps']\n\ntitle = ['Age', \"Heart Rate\", \"Cholesterol Level\", \"Blood Pressure\"]\n\nfor i in range(4):\n    sns.distplot(a=heart_df[heart_df['output'] == 1]\n                 [col[i]], bins=60, color='red', ax=ax[i])\n    sns.distplot(a=heart_df[heart_df['output'] == 0]\n                 [col[i]], bins=60, color='green', ax=ax[i])\n    \n    \n    ax[i].legend(['High Chance of Heart Attack',\n                  'Low Chance of Heart Attack'], fontsize=18)\n    ax[i].set_title(\n        title[i] + \" Distribution based on Heat Attack Chance\", fontdict={'size': 20})\n    \n    ax[i].set_xlabel(title[i], fontdict={'size': 18})\n\nplt.show()","99e5202a":"plt.figure(figsize=(30, 8))\nax = sns.distplot(a=heart_df[heart_df['output'] == 1]\n                  ['oldpeak'], bins=6, color='red', kde=False)\n\nax = sns.distplot(a=heart_df[heart_df['output'] == 0]\n                  ['oldpeak'], bins=6, color='green', kde=False)\n\nax.legend(['High Chance of Heart Attack',\n           'Low Chance of Heart Attack'], fontsize=18)\nax.set_title(\"OldPeak Distribution based on Heat Attack Chance\",\n             fontdict={'size': 20})\n\nax.set_xlabel(\"Oldpeak\", fontdict={'size': 18})\n\nplt.show()","cfc10206":"col = ['sex', 'cp', 'fbs', 'restecg', 'exng', 'slp', 'caa', 'thall']\n\ntitle = ['Sex', 'Chest Pain', 'Fasting Blood Sugar', 'Resting Electrocardiographic',\n         'Exercise induced angina', 'Slope', 'Number of Major Vessel', 'Thalium Stress Test']\n\nlegend = [['Female', 'Male'], ['Typical Angina', 'Atypical Angina', 'Non-Anginal Pain', 'Asymptomatic'],\n          ['Less than 120 ', 'Greater than 120'], [\n              'Normal', 'St-T wave abnormality', 'Hypertrophy'],\n          ['No', 'Yes'], ['Downsloping', 'Flat', 'UpSloping'], [0, 1, 2, 3, 4],\n          ['No Defect', 'Fixed Defect', 'Normal', 'Reversable Defect']]\n\nsns.set_palette('Set1')\nfig, ax = plt.subplots(3, 3, figsize=(38, 38), gridspec_kw={'hspace': 0.12})\nplt.suptitle(\"Red Mean Less Risk of Heart Attack\\nBlue Mean High Risk Of Heart Attack\", fontsize=30,\n             fontweight=\"bold\", )\n\nk = 0\nfor i in range(3):\n    if i == 2:\n        for j in range(2):\n            sns.countplot(x=heart_df[col[k]],\n                          ax=ax[i, j], hue=heart_df['output'])\n            \n            ax[i, j].set_title(title[k], fontdict={'size': 32})\n            ax[i, j].set_xlabel('')\n            ax[i, j].set_ylabel('')\n            ax[i, j].set_xticklabels(legend[k], fontdict={'size': 23})\n            ax[i, j].legend('')\n            \n            for z in ax[i, j].patches:\n                text = str(z.get_height()) + '(' + \\\n                    str(np.round(z.get_height()\/len(heart_df), 2)) + ')'\n                ax[i, j].annotate(\n                    text, (z.get_x()+0.01, z.get_height()+1), size=22, )\n                \n            k += 1\n    else:\n        for j in range(3):\n            sns.countplot(x=heart_df[col[k]],\n                          hue=heart_df['output'], ax=ax[i, j])\n            \n            ax[i, j].set_title(title[k], fontdict={'size': 32})\n            ax[i, j].set_xticklabels(legend[k], fontdict={'size': 23})\n            ax[i, j].set_xlabel('')\n            ax[i, j].set_ylabel('')\n            ax[i, j].legend('')\n            \n            for z in ax[i, j].patches:\n                text = str(z.get_height()) + '(' + \\\n                    str(np.round(z.get_height()\/len(heart_df), 2)) + ')'\n                ax[i, j].annotate(\n                    text, (z.get_x() + 0.01, z.get_height()+1), size=22)\n                \n            k += 1\nax[0, 1].set_xticklabels(legend[1], fontdict={'size': 15})\nax[2, 1].set_xticklabels(legend[7], fontdict={'size': 20})\nax[2, 2].remove()\n\nfig.tight_layout()\nfig.subplots_adjust(top=0.94)\n\nplt.show()","65bab381":"plt.figure(figsize=(20, 14))\nsns.set_style(\"whitegrid\")\ncorr = heart_df.corr(method='pearson')\nmask = np.triu(np.ones(corr.shape))\nsns.heatmap(data=corr, mask=mask, annot=True, cmap=\"YlGnBu\",\n            square=True, robust=True, linewidths=3)\nplt.show()","42c65a7a":"scaler = MinMaxScaler()\ndf_copy = heart_df.copy()\ncol = ['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']\nscaler_dataframe = pd.DataFrame(scaler.fit_transform(heart_df[col]), columns= col)\nfor i in col:\n    df_copy.loc[:, i] = scaler_dataframe.loc[:, i]\ndf_copy","05044876":"X_train, X_test, y_train, y_test = train_test_split(df_copy.drop('output', axis = 1), df_copy['output'],\n                                                   test_size= 0.2, random_state = 42)\nlinear_model = LogisticRegression()\nlinear_model.fit(X_train, y_train)\nprint(\"Train Accuracy of our Linear model is\", linear_model.score(X_train, y_train))\nprint(\"Test Accuracy of our Linear model is \",linear_model.score(X_test, y_test))","bbfc09ac":"knn_model = KNeighborsClassifier()\nknn_model.fit(X_train, y_train)\nprint(\"Train Accuracy of our K-Neighbors model is\", knn_model.score(X_train, y_train))\nprint(\"Test Accuracy of our K-Neighbors model is \",knn_model.score(X_test, y_test))","07e40696":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, y_train)\nprint(\"Train Accuracy of our Decision Tree model is\", decision_tree.score(X_train, y_train))\nprint(\"Test Accuracy of our  Decision Tree model is \",decision_tree.score(X_test, y_test))","1c675097":"svc =SVC()\nsvc.fit(X_train, y_train)\nprint(\"Train Accuracy of our Support Vector Classifier model is\", svc.score(X_train, y_train))\nprint(\"Test Accuracy of our Support Vector Classifier model is \",svc.score(X_test, y_test))","9ca79a0a":"lgbClassifier = LGBMClassifier()\nlgbClassifier.fit(X_train, y_train)\nprint(\"Train Accuracy of our LGBM-Classifier model is\", lgbClassifier.score(X_train, y_train))\nprint(\"Test Accuracy of our LGBM-Classifier model is \",lgbClassifier.score(X_test, y_test))","ebce6762":"bernouli_model = BernoulliNB()\nbernouli_model.fit(X_train, y_train)\nprint(\"Train Accuracy of our Bernoulli-NB model is\", bernouli_model.score(X_train, y_train))\nprint(\"Test Accuracy of our Bernoulli-NB model is \",bernouli_model.score(X_test, y_test))","05fd1051":"gaussian_model = GaussianNB()\ngaussian_model.fit(X_train, y_train)\nprint(\"Train Accuracy of our Gaussian-NB model is\", gaussian_model.score(X_train, y_train))\nprint(\"Test Accuracy of our Gaussian-NB model is \",gaussian_model.score(X_test, y_test))","b6e48aab":"nusvm = NuSVC()\nnusvm.fit(X_train, y_train)\nprint(\"Train Accuracy of our Nu-SVC model is\", nusvm.score(X_train, y_train))\nprint(\"Test Accuracy of our Nu-SVC model is \",nusvm.score(X_test, y_test))","db313be1":"param_grid = {'n_neighbors': np.arange(1,25, 1)}\ngrid_seach_K_Neighbors  = GridSearchCV(KNeighborsClassifier(),param_grid, scoring = 'accuracy', n_jobs = -1)\ngrid_seach_K_Neighbors.fit(X_train, y_train)\nprint(\"Best K-Values for K-Neighbors is\", grid_seach_K_Neighbors.best_params_['n_neighbors'])\nprint(\"Train Accuracy of our K-Neighbors model after Grid Search is\", grid_seach_K_Neighbors.score(X_train, y_train))\nprint(\"Test Accuracy of our K-Neighbors model after Grid Search is \",grid_seach_K_Neighbors.score(X_test, y_test))","f6cd0b46":"param_grid = {'C': np.arange(0.1, 1, 0.1), 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\ngrid_seach_svc = GridSearchCV(SVC(), param_grid, scoring= 'accuracy', n_jobs=-10)\ngrid_seach_svc.fit(X_train, y_train)\nprint(\"Best K-Values for Support Vector is\", grid_seach_svc.best_params_)\nprint(\"Train Accuracy of our  Support Vector model after Grid Search is\", grid_seach_svc.score(X_train, y_train))\nprint(\"Test Accuracy of our  Support Vectormodel after Grid Search is \",grid_seach_svc.score(X_test, y_test))","c20f8c44":"def get_result(model):\n    name = model.__class__.__name__\n    train_accuracy = model.score(X_train, y_train)\n    test_accracy = model.score(X_test,y_test)\n    return [[name,train_accuracy,test_accracy]]\n\nmodels = [linear_model, decision_tree, bernouli_model, gaussian_model, nusvm, lgbClassifier, knn_model]\nresult = pd.DataFrame(get_result(models[0]), columns= ['Name', 'Train Accuracy', 'Test Accuracy'])\nfor i in range(1, len(models)):\n    new_result = pd.DataFrame(get_result(models[i]), columns= ['Name', 'Train Accuracy', 'Test Accuracy'])\n    result = pd.concat([result, new_result])\nresult.reset_index(drop = True)","a95ba618":"## UniaVarient Analysis","919ae779":"### K-Neighbors \nTo Select the best K Value we can use also elbow method.","e7b299d7":"## Data Reading & Data PreProcessing","da54a100":"## Grid Seach and Cross Validation","69388a97":"![](https:\/\/www.cdc.gov\/heartdisease\/images\/HA-signs-symptoms-social2.png)\n## Importing Library","a7d6b444":"### Support Vector Classifier","35a5df61":"<b>Conclusion:<\/b>\n##### 1. There is no direct Relationship b\/w age & Change of Heart Attack but it was seen Most Heart Attack are occur in age [20-55].\n##### 2. As Cholesterol Increase Chances of Heart Attack also increase.\n##### 3. People Having High Heart Rate tend to have more chances of Heart Attack\n##### 4. Blood Pressure has no direct Relationship with Heart Attack as conclude by graph.","67dc8da0":"We have Plot two curve for each  numerical columns they are \n1. [Kernel Density Estimate](https:\/\/en.wikipedia.org\/wiki\/Kernel_density_estimation)\n2. [Box-Plot](https:\/\/en.wikipedia.org\/wiki\/Box_plot)\n\nAlso We Add some Stats of that paticular features in their plot Which are:-\n\n Kdeplot\n1. [Skewness](https:\/\/en.wikipedia.org\/wiki\/Skewness)\n2. [Kurtosis](https:\/\/en.wikipedia.org\/wiki\/Kurtosis)\n3. [Mean](https:\/\/en.wikipedia.org\/wiki\/Mean)\n4. [Variance](https:\/\/en.wikipedia.org\/wiki\/Variance)    \n\nBox-Plot\n1. [Maximum](https:\/\/en.wikipedia.org\/wiki\/Maxima_and_minima)\n2. [InterQuartile-Range](https:\/\/en.wikipedia.org\/wiki\/Interquartile_range)\n3. [Median](https:\/\/en.wikipedia.org\/wiki\/Median)\n4. [Minimum](https:\/\/en.wikipedia.org\/wiki\/Maxima_and_minima)","122ece24":"<b>Conclusion<\/b>\n#####  1. Female Has more chance of heart Attack as compare to Men\n#####  2. People having Non-Anginal Pain Must have a check as they are more vulnerable to heart attack.\n#####  3. People who do not have have angina include in their daily exercise are more likely to have heart attack than one who does.\n#####  4. The More Major Vessel you have less is chance of Heart attack","2e5e2495":"<b>Conclusion<\/b>\n#### 1. There are twice as men as female on our dataset.\n#### 2. Most People have Typical Angina Chest Pain as Compare to all other Chest Pain.\n#### 3. Generally Fasting Blood Sugar has Value smaller than 120.\n#### 4. There is 0.01% Chance you have Resting Electrocardiographc result as Hypertrophy.\n#### 5. Around 67% people do not have angina include to their Daily exercise.\n#### 6. 58% People have 0 Major Vessel in their body.","b79d9044":"### Risk of Heart Attack vs All columns ","fab5f9b1":"## If you Like Please UpVote & Comment.\n## Also if any Changes Please Mention.","2d1118eb":"![](https:\/\/www.nhlbi.nih.gov\/sites\/default\/files\/styles\/16x9_crop\/public\/2020-10\/Learn%20What%20a%20Heart%20Attack%20Feels%20Like_October%202020_Final%20thumbnail.jpg?itok=-cu0N5Ea)\n# Data Visualization","6d796fd4":"### Logistic Regression","57cbccdd":"### NuSVC","7a6bb97d":"### Categorical Plot","05d7c519":"![](https:\/\/www.heartfoundation.org.nz\/images\/heart-healthcare\/public\/other\/cholesterol-graphic.png)\n## Multivarient Analysis","438b90d1":"# Creating Model","8284d4d3":"### Output","75fd0418":"![](https:\/\/www.gethealthystayhealthy.com\/sites\/default\/files\/inline-images\/heart-health-and-women_2_0.png)\n## BiVarient Analysis","3c4aea64":"<b>Conclusion<\/b>\n#### The Data has around 46% of less chances of heart attack and 54% of high chance of Heart Attack","cb362940":"<b>Conclusion<\/b>\n#####  1. People Having Low Cholesterol and Age tends to be more vulnerable to heart attack. \n####   2.With Increase in Age The Heart Rate tends to Decrease\n####   3. There is no such relation b\/w Blood Pressure and Age as but people with low Blood Pressure has higher chance to attack.","28ceba67":"### LGBMClassifier","21093370":"### Support Vector Classifier","69cd395c":"<b>Discussion<\/b>\n#### 1. You can Also calculate Spearman Correlation if you think there is non-linear Relation b\/w features.\n#### 2. Our Output has high Positive Correlation with Chest Pain, Heart Rate, Major Vessel.\n#### 3. Out Output has high Negative Correlation with Exercise-Including-Angina, 'Old-Peak .\n#### 4. You can Use Feature Selection Method to remove some feature if you want.Some Feature Selection technique are given below.\n<ol>\n    <li>Forward Selection<\/li>\n    <li>Backward Selection<\/li>\n    <li>Recursive Selection<\/li>\n    <li>Select K Best<\/li>\n<\/ol>","7edd1acb":"### BernoulliNB \t","c6bf5715":"# Result","fd139588":"### GaussianNB \t","f01ad8d0":"### Decision Tree Classifier","b964c414":"We have 303 Row & 14 Columns)","02664965":"# What we can add or new?\n1. Use Different Parameter with Grid Search and search for optimal Solution.\n2. Find Relation b\/w Other Feature like Does Cholesterol Increase with increase in Heart Rate?\n3. Trying add New Columns Like Body Mass Index?\n4. Feature Adding and Removing.","f53cace6":"## <b>Conclusion<\/b>\n1. Decision Tree & LGBM-Classifier is over-fitting our dataset because their large difference b\/w train and test accuracy.\n2. K-Neighbors Classifier is working fine with our mode and having test accuracy of 83% which is good, but we can achieve more with help of cross validation and Grid Search.\n3. Logistic Regression is Simplest Classifier which show 83% Test Accuracy and less difference b\/w train and test accuracy.\n4. Support Vector Machine, NSVC, Gaussian-NB, Bernoulli-NB has approx same and also best train & test accuracy.","7d959214":"### KNeighborsClassifier"}}