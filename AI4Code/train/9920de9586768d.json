{"cell_type":{"c4e2d1ae":"code","6e784922":"code","1e738a9f":"code","612f4a60":"code","e19555a6":"code","7e422fdd":"code","4bd3ddec":"code","199197da":"code","cd85f33f":"code","c895de82":"code","0ba6971f":"code","557e4903":"code","eb949751":"code","6df122d0":"code","75fad4c6":"code","5acc9abe":"code","6a10b1d2":"code","67ab38bd":"code","45d22d97":"code","ac77cf72":"code","d700d97a":"code","e60f6690":"code","8c26beca":"code","26a7980c":"code","ad51f8fe":"code","db213f3a":"code","cadeb556":"code","729c61a4":"code","e9ff1457":"code","85ca49a1":"code","f2cf5e4b":"code","d0408d4f":"code","2c1f3a63":"code","2ff10380":"code","fa40f6c4":"code","cce108a2":"code","e809174a":"code","f3bcd2a9":"code","09b285a8":"code","be5ad60c":"code","a5d66418":"code","93d617dc":"code","3a0af226":"code","b7bdd844":"code","dbc17904":"code","78b5d45c":"code","7d69ec5c":"code","d54ef80f":"code","d04884b8":"code","2144d169":"markdown","e07ebb55":"markdown","5e469507":"markdown","9153a2ba":"markdown","705ab876":"markdown"},"source":{"c4e2d1ae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6e784922":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport shutil\nfrom collections import Counter \n%matplotlib inline","1e738a9f":"my_data_dir = '\/kaggle\/input\/intel-image-classification\/'","612f4a60":"# CONFIRM THAT THIS REPORTS BACK 'test', and 'train'\nos.listdir(my_data_dir) ","e19555a6":"test_path = my_data_dir+'\/seg_test\/seg_test'\ntrain_path = my_data_dir+'\/seg_train\/seg_train'\npred_path = my_data_dir+'\/seg_pred\/seg_pred'","7e422fdd":"train_size = 0\ntest_size = 0","4bd3ddec":"for root, dirs, files in os.walk(train_path):\n    train_size += len(files)\n\nfor root, dirs, files in os.walk(test_path):\n    test_size += len(files)","199197da":"print(\"The number of files in train path is \" + str(train_size))\nprint(\"The number of files in test path is \" + str(test_size))","cd85f33f":"os.listdir(test_path)","c895de82":"os.listdir(train_path)","0ba6971f":"os.listdir(train_path+'\/street')[0]","557e4903":"street_img = train_path+'\/street\/'+'5713.jpg'\nstreet_img","eb949751":"img = cv2.imread(street_img)\nimg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\nplt.imshow(img)","6df122d0":"img.shape","75fad4c6":"os.listdir(train_path+'\/forest')[0]","5acc9abe":"forest_img = train_path+'\/forest\/'+'11866.jpg'\nforest_img","6a10b1d2":"img = cv2.imread(forest_img)\nimg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\nplt.imshow(img)","67ab38bd":"img.shape","45d22d97":"from keras.preprocessing.image import ImageDataGenerator","ac77cf72":"dim1 = []\ndim2 = []\nfor image_filename in os.listdir(test_path+'\/street\/'):\n    \n    img = plt.imread(test_path+'\/street\/'+image_filename)\n    d1,d2,colors = img.shape\n    dim1.append(d1)\n    dim2.append(d2)","d700d97a":"sns.jointplot(dim1,dim2)","e60f6690":"np.mean(dim1)","8c26beca":"np.mean(dim2)","26a7980c":"image_shape = (150,150,3)","ad51f8fe":"import tensorflow as tf\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.applications import *\nfrom keras.models import Model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras import backend as k","db213f3a":"# fix seed for reproducible results (only works on CPU, not GPU)\nseed = 9\nnp.random.seed(seed=seed)\ntf.compat.v1.set_random_seed(seed)","cadeb556":"# hyper parameters for model\nnb_classes = 6  # number of classes\nbased_model_last_block_layer_number = 126  # value is based on based model selected.\nimg_width, img_height = 150, 150  # change based on the shape\/structure of your images\nbatch_size = 32  # try 4, 8, 16, 32, 64, 128, 256 dependent on CPU\/GPU memory capacity (powers of 2 values).\nnb_epoch = 50  # number of iteration the algorithm gets trained.\nlearn_rate = 1e-4  # sgd learning rate\nmomentum = .9  # sgd momentum to avoid local minimum\ntransformation_ratio = .05  # how aggressive will be the data augmentation\/transformation","729c61a4":"DEVICE = \"TPU\"\nif DEVICE == \"TPU\":\n    print(\"connecting to TPU...\")\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        print(\"Could not connect to TPU\")\n        tpu = None\n\n    if tpu:\n        try:\n            print(\"initializing  TPU ...\")\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"TPU initialized\")\n        except _:\n            print(\"failed to initialize TPU\")\n    else:\n        DEVICE = \"GPU\"\n\nif DEVICE != \"TPU\":\n    print(\"Using default strategy for CPU and single GPU\")\n    strategy = tf.distribute.get_strategy()\n\nif DEVICE == \"GPU\":\n    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n\nAUTO     = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')\n    ","e9ff1457":"EPOCHS = 50\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync # this is 8 on TPU v3-8, it is 1 on CPU and GPU\nLR_START = 0.00001\nLR_MAX = 0.00005 * strategy.num_replicas_in_sync\nLR_MIN = 0.00001\nLR_RAMPUP_EPOCHS = 5\nLR_SUSTAIN_EPOCHS = 0\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n    \nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n\nrng = [i for i in range(EPOCHS)]\ny = [lrfn(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","85ca49a1":"with strategy.scope():\n    # Pre-Trained CNN Model using imagenet dataset for pre-trained weights\n    base_model = Xception(input_shape=(img_width, img_height, 3), weights='imagenet', include_top=False)\n\nprint(base_model.summary())","f2cf5e4b":"from copy import copy, deepcopy\ndatagen = ImageDataGenerator(rescale=1.\/255)\n\ndef extract_features(directory, sample_count):\n    features = np.zeros(shape=(sample_count, 5, 5, 2048))  # Must be equal to the output of the convolutional base\n    labels = np.zeros(shape=(sample_count))\n    # Preprocess data\n    generator = datagen.flow_from_directory(directory,\n                                            target_size=(img_width,img_height),\n                                            batch_size = BATCH_SIZE,\n                                            class_mode='categorical')\n    # Pass data through convolutional base\n    i = 0\n    for inputs_batch, labels_batch in generator:\n        features_batch = base_model.predict(inputs_batch)\n        features[i * BATCH_SIZE: (i + 1) * BATCH_SIZE] = features_batch\n        labels[i * BATCH_SIZE: (i + 1) * BATCH_SIZE] = np.argmax(labels_batch,axis=1)\n        i += 1\n        if i * BATCH_SIZE >= sample_count:\n            break\n    return features, labels\n    \ntrain_features, train_labels = extract_features(train_path, train_size)  \ntest_features, test_labels = extract_features(test_path, test_size)","d0408d4f":"model = models.Sequential()\nmodel.add(layers.Flatten(input_shape=(5,5,2048)))\nmodel.add(layers.Dense(256, activation='relu', input_dim=(5*5*2048)))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(6, activation='softmax'))\nmodel.summary()","2c1f3a63":"# Compile model\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","2ff10380":"# first: train only the top layers (which were randomly initialized)\n# i.e. freeze all layers of the based model that is already pre-trained.\n#for layer in base_model.layers:\n    #layer.trainable = False","fa40f6c4":"import warnings\nwarnings.filterwarnings('ignore')","cce108a2":"early_stop = EarlyStopping(monitor='val_acc',patience=2)","e809174a":"# Train model\nhistory = model.fit(train_features, train_labels,\n                    epochs=EPOCHS,\n                    batch_size=BATCH_SIZE, \n                    validation_data=(train_features, train_labels),\n                    callbacks=[lr_callback,early_stop])","f3bcd2a9":"from tensorflow.keras.models import load_model\nmodel.save('intel_image_classifier_2.h5')\n#model = load_model(\"..\/input\/intelimageclassifiermodels\/intel_image_classifier_1.h5\")","09b285a8":"losses = pd.DataFrame(model.history.history)","be5ad60c":"losses[['loss','val_loss']].plot()","a5d66418":"losses[['accuracy','val_accuracy']].plot()","93d617dc":"model.metrics_names","3a0af226":"print(\"Evaluate on test data\")\nresults = model.evaluate(test_features,test_labels)\nprint(\"test loss, test acc:\", results)","b7bdd844":"pred_probabilities = model.predict(test_features)","dbc17904":"predictions = np.argmax(pred_probabilities, axis=1) ","78b5d45c":"from sklearn.metrics import classification_report,confusion_matrix","7d69ec5c":"print(classification_report(test_labels,predictions))","d54ef80f":"class_names = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\nCM = confusion_matrix(test_labels, predictions)\nax = plt.axes()\nsns.heatmap(CM, annot=True, \n           annot_kws={\"size\": 10}, \n           xticklabels=class_names, \n           yticklabels=class_names, ax = ax)\nax.set_title('Confusion matrix')\nplt.show()","d04884b8":"from tensorflow.keras.preprocessing import image\ncount = 0\n#cols = ['Image_id', 'buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n#df = pd.DataFrame(columns=cols)\nfor dirname, _, filenames in os.walk('..\/input\/intel-image-classification\/seg_pred\/seg_pred'):\n    for filename in filenames:\n        if count < 10:\n            list1 = []\n            path = os.path.join(dirname, filename)\n            my_image = image.load_img(path,target_size=(img_width, img_height))\n            img = my_image\n            my_image = image.img_to_array(my_image)\n            #my_image = np.expand_dims(my_image, axis=0)\n            my_image \/= 255.\n            # Extract features\n            features = base_model.predict(my_image.reshape(1,img_width, img_height, 3))\n            #list1 = [filename]\n            #list1.extend(model.predict(my_image).flatten())\n            #ser1 = pd.Series(list1,index=['Image_id', 'buildings','forest','glacier','mountain','sea','street'])\n            #df = df.append(ser1,ignore_index=True)\n            df = pd.DataFrame({'Image_id':filename, 'Types':['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street'], 'val':model.predict(features).flatten()})\n            \n            # Plot the Images\n            fig, ax = plt.subplots(1,2,figsize=(10,5))\n            df.plot.bar(x='Types', y='val', rot=0,ax=ax[0])\n            ax[0].set_title('Probablity Distribution')\n            \n            ax[1] = plt.imshow(img)\n            ax[1] = plt.title(filename)\n\n            count = count + 1\n        else:\n            break","2144d169":"# Creating the Model","e07ebb55":"# Predict on Unknown Images","5e469507":"# Evaluating the Model","9153a2ba":"# Determining Target Shape of Images","705ab876":"# Training the Model"}}