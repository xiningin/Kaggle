{"cell_type":{"cbf62d81":"code","2b873de1":"code","96d9fa46":"code","83b475f8":"code","68ad6508":"code","e3ba7b99":"code","ce0c6805":"code","cd600b24":"code","8a8f7870":"code","686ef417":"code","726b6e3e":"code","1037a01d":"code","b2c39010":"code","15876a04":"code","ea20e8cb":"code","5ee9a2b5":"code","94b2bf22":"code","69aa6df7":"markdown"},"source":{"cbf62d81":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport cv2 as cv\nfrom keras.layers import Conv2D, Input, LeakyReLU, Dense, Activation, Flatten, Dropout, MaxPool2D\nfrom keras import models\nfrom keras.optimizers import Adam,RMSprop \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nimport pickle\nfrom keras.datasets import mnist","2b873de1":"np.random.seed(1)\ndf_train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ndf_train = df_train.iloc[np.random.permutation(len(df_train))]","96d9fa46":"df_train.head(5)","83b475f8":"df_train.shape","68ad6508":"sample_size = df_train.shape[0] # Training set size\nvalidation_size = int(df_train.shape[0]*0.1) # Validation set size \n\n# train_x and train_y\ntrain_x = np.asarray(df_train.iloc[:sample_size-validation_size,1:]).reshape([sample_size-validation_size,28,28,1]) # taking all columns expect column 0\ntrain_y = np.asarray(df_train.iloc[:sample_size-validation_size,0]).reshape([sample_size-validation_size,1]) # taking column 0\n\n# val_x and val_y\nval_x = np.asarray(df_train.iloc[sample_size-validation_size:,1:]).reshape([validation_size,28,28,1])\nval_y = np.asarray(df_train.iloc[sample_size-validation_size:,0]).reshape([validation_size,1])","e3ba7b99":"train_x.shape,train_y.shape","ce0c6805":"df_test = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\ntest_x = np.asarray(df_test.iloc[:,:]).reshape([-1,28,28,1])","cd600b24":"train_x = train_x\/255\nval_x = val_x\/255\ntest_x = test_x\/255","8a8f7870":"counts = df_train.iloc[:sample_size-validation_size,:].groupby('label')['label'].count()\nf = plt.figure(figsize=(10,6))\nf.add_subplot(111)\n\nplt.bar(counts.index,counts.values,width = 0.8,color=\"orange\")\nfor i in counts.index:\n    plt.text(i,counts.values[i]+50,str(counts.values[i]),horizontalalignment='center',fontsize=14)\n\nplt.tick_params(labelsize = 14)\nplt.xticks(counts.index)\nplt.xlabel(\"Digits\",fontsize=16)\nplt.ylabel(\"Frequency\",fontsize=16)\nplt.title(\"Frequency Graph training set\",fontsize=20)\nplt.savefig('digit_frequency_train.png')  \nplt.show()","686ef417":"counts = df_train.iloc[sample_size-validation_size:,:].groupby('label')['label'].count()\nf = plt.figure(figsize=(10,6))\nf.add_subplot(111)\n\nplt.bar(counts.index,counts.values,width = 0.8,color=\"orange\")\nfor i in counts.index:\n    plt.text(i,counts.values[i]+5,str(counts.values[i]),horizontalalignment='center',fontsize=14)\n\nplt.tick_params(labelsize = 14)\nplt.xticks(counts.index)\nplt.xlabel(\"Digits\",fontsize=16)\nplt.ylabel(\"Frequency\",fontsize=16)\nplt.title(\"Frequency Graph Validation set\",fontsize=20)\nplt.savefig('digit_frequency_val.png')\nplt.show()","726b6e3e":"rows = 5 # defining no. of rows in figure\ncols = 6 # defining no. of colums in figure\n\nf = plt.figure(figsize=(2*cols,2*rows)) # defining a figure \n\nfor i in range(rows*cols): \n    f.add_subplot(rows,cols,i+1) # adding sub plot to figure on each iteration\n    plt.imshow(train_x[i].reshape([28,28]), cmap= \"Greys\") \n    plt.axis(\"off\")\n    plt.title(str(train_y[i]), y=-0.20,color=\"black\")","1037a01d":"model = models.Sequential()\n# Block 1\nmodel.add(Conv2D(32,3, padding  =\"same\",input_shape=(28,28,1)))\nmodel.add(LeakyReLU())\nmodel.add(Conv2D(32,3, padding  =\"same\"))\nmodel.add(LeakyReLU())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n# Block 2\nmodel.add(Conv2D(64,3, padding  =\"same\"))\nmodel.add(LeakyReLU())\nmodel.add(Conv2D(64,3, padding  =\"same\"))\nmodel.add(LeakyReLU())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dense(32,activation='relu'))\nmodel.add(Dense(10,activation=\"sigmoid\"))","b2c39010":"initial_lr = 0.001\nloss = \"sparse_categorical_crossentropy\"\nmodel.compile(Adam(lr=initial_lr), loss=loss ,metrics=['accuracy'])\nmodel.summary()","15876a04":"epochs = 20\nbatch_size = 256\nhistory_1 = model.fit(train_x,train_y,batch_size=batch_size,epochs=epochs,validation_data=(val_x,val_y))","ea20e8cb":"f = plt.figure(figsize=(20,7))\nf.add_subplot(121)\n\nplt.plot(history_1.epoch,history_1.history['accuracy'],label = \"accuracy\") # Accuracy curve for training set\nplt.plot(history_1.epoch,history_1.history['val_accuracy'],label = \"val_accuracy\") # Accuracy curve for validation set\n\nplt.title(\"Accuracy Curve\",fontsize=18)\nplt.xlabel(\"Epochs\",fontsize=15)\nplt.ylabel(\"Accuracy\",fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\n\nf.add_subplot(122)\n\nplt.plot(history_1.epoch,history_1.history['loss'],label=\"loss\") # Loss curve for training set\nplt.plot(history_1.epoch,history_1.history['val_loss'],label=\"val_loss\") # Loss curve for validation set\n\nplt.title(\"Loss Curve\",fontsize=18)\nplt.xlabel(\"Epochs\",fontsize=15)\nplt.ylabel(\"Loss\",fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\n\nplt.show()","5ee9a2b5":"val_p = np.argmax(model.predict(val_x),axis =1)\n\nerror = 0\nconfusion_matrix = np.zeros([10,10])\nfor i in range(val_x.shape[0]):\n    confusion_matrix[val_y[i],val_p[i]] += 1\n    if val_y[i]!=val_p[i]:\n        error +=1\n        \nprint(\"Confusion Matrix: \\n\\n\" ,confusion_matrix)\nprint(\"\\nErrors in validation set: \" ,error)\nprint(\"\\nError Persentage : \" ,(error*100)\/val_p.shape[0])\nprint(\"\\nAccuracy : \" ,100-(error*100)\/val_p.shape[0])\nprint(\"\\nValidation set Shape :\",val_p.shape[0])","94b2bf22":"f = plt.figure(figsize=(10,8.5))\nf.add_subplot(111)\n\nplt.imshow(np.log2(confusion_matrix+1),cmap=\"Reds\")\nplt.colorbar()\nplt.tick_params(size=5,color=\"white\")\nplt.xticks(np.arange(0,10),np.arange(0,10))\nplt.yticks(np.arange(0,10),np.arange(0,10))\n\nthreshold = confusion_matrix.max()\/2 \n\nfor i in range(10):\n    for j in range(10):\n        plt.text(j,i,int(confusion_matrix[i,j]),horizontalalignment=\"center\",color=\"white\" if confusion_matrix[i, j] > threshold else \"black\")\n        \nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.savefig(\"Confusion_matrix1.png\")\nplt.show()","69aa6df7":"Convolutional Neural Network Model "}}