{"cell_type":{"ce23cff3":"code","9345a70d":"code","fff4048c":"code","5d409e36":"code","948d85cc":"code","b598fa5b":"code","c0867175":"code","63a59a13":"code","c5ae8229":"code","2507588a":"code","c984989a":"code","bd264f23":"code","1533051b":"markdown","73504227":"markdown","30fd7feb":"markdown","33f40243":"markdown","607e966b":"markdown","cc0ba163":"markdown","28608d57":"markdown","c57f8667":"markdown","00491439":"markdown","941b5b35":"markdown"},"source":{"ce23cff3":"!git clone https:\/\/github.com\/switchablenorms\/DeepFashion_Try_On\n%cd DeepFashion_Try_On","9345a70d":"%cd ACGPN_inference","fff4048c":"!mkdir -p ..\/Data_preprocessing","5d409e36":"!cp -rf \/kaggle\/input\/viton-dataset\/ACGPN_TestData\/* ..\/Data_preprocessing","948d85cc":"!ls ..\/Data_preprocessing","b598fa5b":"# copy a pre-trained model (checkpoint)\n!cp -rf \/kaggle\/input\/acgpn-checkpoints\/label2city checkpoints","c0867175":"!python test.py","63a59a13":"!ls sample","c5ae8229":"from IPython.display import Image","2507588a":"Image('sample\/000001_0.jpg')","c984989a":"Image('sample\/000010_0.jpg')","bd264f23":"Image('sample\/003935_0.jpg')","1533051b":"## Paper: [Towards Photo-Realistic Virtual Try-On by Adaptively Generating, CVPR'20](https:\/\/arxiv.org\/abs\/2003.05863)","73504227":"#### License: The use of this software is RESTRICTED to non-commercial research and educational purposes.","30fd7feb":"## Test Model","33f40243":"## Download test data","607e966b":"![DeepFashionTryOn.jpg](attachment:DeepFashionTryOn.jpg)","cc0ba163":"## Repro [Github](https:\/\/github.com\/switchablenorms\/DeepFashion_Try_On)","28608d57":"### output: sample\/*.jpg","c57f8667":"## Dataset: VITON dataset \n    This dataset contains 16,253 image pairs, further splitting into a training set of 14,221 paris and a testing set of 2,032 pairs.<br>","00491439":"## copy a pre-trained model (checkpoint)","941b5b35":"## Display sample images"}}