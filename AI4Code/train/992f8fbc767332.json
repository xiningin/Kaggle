{"cell_type":{"81fe4b33":"code","8eca3c48":"code","1572321c":"code","62d9ea59":"code","5180f2e0":"code","14791bba":"code","e792248f":"code","43f6d009":"code","2f6eae39":"code","a9fae693":"code","d970027f":"code","f2df7a64":"code","e4dadee2":"code","8b5ff46d":"code","381214b7":"code","ef07b2e9":"code","e1abe063":"code","28670511":"code","194b2ebe":"code","704c3eaa":"code","fdec881c":"code","ee81000b":"code","f8004861":"code","66e08b72":"code","e5d37b47":"code","9311da4f":"code","0d59d07d":"code","ca5a81cd":"code","b3c3f062":"code","9a327876":"code","10a247f3":"code","79e39428":"code","c2340fea":"code","dac4369e":"code","31adb087":"markdown","14df9f7b":"markdown","2da7abc1":"markdown","2ac50fd8":"markdown","30f8ee1e":"markdown","742f7d6b":"markdown","8549111d":"markdown","80429582":"markdown","3aab7f49":"markdown","56c25f63":"markdown","011df98c":"markdown","b9098254":"markdown","1ab57195":"markdown","1a4b6445":"markdown","41c6bc13":"markdown","28f500ad":"markdown","5a863097":"markdown","c10210c9":"markdown","8c2776c4":"markdown","1fcdb07f":"markdown","a2b2e877":"markdown","60f5b554":"markdown","0ff463f9":"markdown","9739b956":"markdown","a5c891f3":"markdown","ac6e4aaa":"markdown"},"source":{"81fe4b33":"!ls \/kaggle\/input\/dog-image-dsg","8eca3c48":"!pip install timm","1572321c":"# \u57fa\u672c\u30d1\u30c3\u30b1\u30fc\u30b8\nimport pandas as pd\nimport numpy as np\nimport os\nimport json\nimport time\nimport random\nfrom tqdm.notebook import tqdm\n\n# \u53ef\u8996\u5316\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# \u753b\u50cf\u7cfb\nimport cv2\nimport albumentations as albu\nfrom albumentations.pytorch import ToTensorV2\n\n# \u6a5f\u68b0\u5b66\u7fd2\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n# \u30e2\u30c7\u30eb\nimport timm\n\n# pytorch\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as data\nfrom torch.cuda.amp import autocast, GradScaler","62d9ea59":"# \u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\ntrain_df = pd.read_csv('\/kaggle\/input\/dog-image-dsg\/train.csv')\ntrain_df.head()","5180f2e0":"# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\ntest_df = pd.read_csv('\/kaggle\/input\/dog-image-dsg\/test.csv')\ntest_df.head()","14791bba":"sample_submission = pd.read_csv('\/kaggle\/input\/dog-image-dsg\/sample_submission.csv')\nsample_submission.head()","e792248f":"# \u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u60c5\u5831\ntrain_df.info()","43f6d009":"# \u30e9\u30d9\u30eb\u78ba\u8a8d \ntrain_df['breed'].value_counts()","2f6eae39":"label_list = train_df['breed'].unique()\n\nmax_plot = 3 # \u5168\u72ac\u7a2e\u8868\u793a\u3059\u308b\u3068\u5927\u5909\u306a\u306e\u30673\u72ac\u7a2e\u306e\u307f\u8868\u793a\nfor count, label in enumerate(label_list):\n    print('\u3010', label, '\u3011')\n    \n    img_list = train_df.query(\"breed == @label\").head(max_plot)['id'].map(lambda x:'\/kaggle\/input\/dog-image-dsg\/photo\/photo\/' + x + '.jpg').values\n    width = 35\n    height = 35\n    plt.figure(figsize=(width, height))\n    for i in range(len(img_list)):\n        plt.subplot(5, 5, i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(plt.imread(img_list[i], 0))\n    plt.show()\n    \n    # \u6307\u5b9a\u3057\u305f\u72ac\u7a2e\u307e\u3067\u8868\u793a\n    if count >= max_plot-1:\n        break","a9fae693":"# \u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u5bfe\u5fdc\nbreed_list = list(train_df['breed'].unique())\n\ntarget_to_breed = {}\nbreed_to_target = {}\nfor i, breed_i in enumerate(breed_list):\n    target_to_breed[i] = breed_i\n    breed_to_target[breed_i] = i\n\nwith open('target_to_breed.json', 'w') as fp:\n    json.dump(target_to_breed, fp)\n\nwith open('breed_to_target.json', 'w') as fp:\n    json.dump(breed_to_target, fp)","d970027f":"# \u5b66\u7fd2\u30e9\u30d9\u30eb\u3092\u5909\u63db\u3059\u308b\ntrain_df.replace(breed_to_target, inplace=True)","f2df7a64":"# \u5909\u63db\u5f8c\u306e\u78ba\u8a8d\ntrain_df.head()","e4dadee2":"CFG = {\n    'fold_num': 5, # \u4ea4\u5dee\u691c\u8a3c\u3092\u884c\u3046\u969b\u306eFold\u306e\u6570\n    'seed': 0,  # \u4e71\u6570\u30b7\u30fc\u30c9\u306e\u56fa\u5b9a\n    'model_arch': 'tf_efficientnet_b4_ns',  # \u4e88\u6e2c\u306b\u7528\u3044\u308b\u30e2\u30c7\u30eb\u306e\u7a2e\u985e\n    'data_root': '\/kaggle\/input\/dog-image-dsg\/photo\/photo\/',  # \u5b66\u7fd2\u30fb\u63a8\u8ad6\u3057\u305f\u3044\u753b\u50cf\u306e\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\n    'model_path': '\/kaggle\/working',  # \u5b66\u7fd2\u3067\u4f5c\u6210\u3057\u305f\u30e2\u30c7\u30eb\u306e\u30d1\u30b9(\u4ed6\u306enotebook\u7b49\u3067\u5b66\u7fd2\u3055\u305b\u305f\u30e2\u30c7\u30eb\u3092\u7528\u3044\u308b\u5834\u5408\u306fKaggle\u306bdataset\u3092\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3057\u3001\u30d1\u30b9\u3092\u6307\u5b9a)\n    'target_col': 'breed',  # \u4e88\u6e2c\u3057\u305f\u3044\u5217\u540d\n    'size': 224,  # \u5b66\u7fd2\u30fb\u63a8\u8ad6\u6642\u306e\u753b\u50cf\u30b5\u30a4\u30ba\n    'mean': [0.485, 0.456, 0.406],  # \u753b\u50cf\u3092\u6a19\u6e96\u5316\u3059\u308b\u969b\u306e\u5e73\u5747\u5024(\u30c7\u30d5\u30a9\u30eb\u30c8\u3068\u3057\u3066Imagenet\u306e\u7d71\u8a08\u5024\u3092\u6307\u5b9a) \n    'std': [0.229, 0.224, 0.225],  # \u753b\u50cf\u3092\u6a19\u6e96\u5316\u3059\u308b\u969b\u306e\u6a19\u6e96\u504f\u5dee\u5024(\u30c7\u30d5\u30a9\u30eb\u30c8\u3068\u3057\u3066Imagenet\u306e\u7d71\u8a08\u5024\u3092\u6307\u5b9a) \n    'epochs': 5,  # Epcoch\u6570\n    'used_epochs':[], # \u63a8\u8ad6\u6642\u306b\u3069\u306eEpoch\u6570\u306e\u30e2\u30c7\u30eb\u3092\u4f7f\u3046\u304b(\u30ea\u30b9\u30c8\u6307\u5b9a\u306a\u306e\u3067\u3001[4,5,6]\u306e\u3088\u3046\u306b\u6307\u5b9a\u3059\u308b\u30683\u3064\u306eEpoch\u6642\u306e\u30e2\u30c7\u30eb\u3067\u305d\u308c\u305e\u308c\u63a8\u8ad6\u3057\u3066\u5e73\u5747\u306e\u7d50\u679c\u3092\u8fd4\u3059)\n    'train_bs': 16,  # \u5b66\u7fd2\u6642\u306e\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\n    'valid_bs': 16,  # \u63a8\u8ad6\u6642\u306e\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\n    'lr': 1e-4, # \u5b66\u7fd2\u7387\n    'step_size': 2, # \u30b9\u30b1\u30b8\u30e5\u30fc\u30e9\u3092\u306b\u3088\u3063\u3066\u5b66\u7fd2\u7387\u3092\u4f55\u30a8\u30dd\u30c3\u30af\u3054\u3068\u306b\u66f4\u65b0\u3059\u308b\u304b \n    'gamma': 0.9, # \u5b66\u7fd2\u7387\u306e\u66f4\u65b0\u7387\u3002\u66f4\u65b0\u30bf\u30a4\u30df\u30f3\u30b0\u3067\u5b66\u7fd2\u7387\u3092gamma\u500d\u306b\u3059\u308b\n    'weight_decay':1e-6,  # \u91cd\u307f\u6e1b\u8870\n    'num_workers': 4,  # \u4e26\u5217\u5316(CPU\u30b3\u30a2\u6570\u3092\u78ba\u8a8d\u3057\u3066\u6307\u5b9a)\n    'debug': False  # \u30c7\u30d0\u30c3\u30b0\u7528\u3067\u52d5\u4f5c\u3060\u3051\u78ba\u8a8d\u3057\u305f\u3044\u3068\u304d\u306fTrue(\u30c7\u30fc\u30bf\u91cf\u3092\u524a\u6e1b\u3057\u3066\u5b9f\u884c)\n}\n","8b5ff46d":"# \u5b9f\u9a13\u306e\u518d\u73fe\u6027\u3092\u78ba\u4fdd\u3059\u308b\u305f\u3081\u3001\u5404\u51e6\u7406\u3067\u306e\u4e71\u6570\u30b7\u30fc\u30c9\u3092\u56fa\u5b9a\u3059\u308b\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.benchmark = True\n    torch.backends.cudnn.deterministic = (torch.cuda.is_available() == 1)","381214b7":"# \u753b\u50cf\u306ePath\u3092\u53d7\u3051\u53d6\u3063\u3066opencv\u3067\u8aad\u307f\u8fbc\u3093\u3060\u753b\u50cf\u3092\u8fd4\u3059\ndef get_img(path):\n    im_bgr = cv2.imread(path)\n    im_rgb = im_bgr[:, :, ::-1]\n    return im_rgb","ef07b2e9":"# \u5b66\u7fd2\u7528\u306e\u30c7\u30fc\u30bf\u5909\u63db\ndef get_train_transforms():\n    return albu.Compose([\n            albu.Resize(CFG['size'], CFG['size']), # \u753b\u50cf\u30b5\u30a4\u30ba\u3092\u6307\u5b9a\u3057\u305f\u30b5\u30a4\u30ba\u306b\u63c3\u3048\u308b\n            albu.Transpose(p=0.5),  # 50%\u306e\u78ba\u7387\u3067\u884c\u3068\u5217\u3092\u5165\u308c\u66ff\u3048\u3066\u8ee2\u7f6e\n            albu.HorizontalFlip(p=0.5), # 50%\u306e\u78ba\u7387\u3067\u6c34\u5e73\u65b9\u5411\u306e\u30d5\u30ea\u30c3\u30d7\n            albu.VerticalFlip(p=0.5),  # 50%\u306e\u78ba\u7387\u3067\u5782\u76f4\u65b9\u5411\u306e\u30d5\u30ea\u30c3\u30d7\n            albu.ShiftScaleRotate(p=0.5),  # 50%\u306e\u78ba\u7387\u3067\u753b\u50cf\u306e\u56de\u8ee2\n            albu.Normalize(mean=CFG['mean'], std=CFG['std'], max_pixel_value=255.0, p=1.0),  # \u753b\u50cf\u306e\u6a19\u6e96\u5316\n            ToTensorV2(p=1.0),  # \u753b\u50cf\u3092tensor\u3078\u5909\u63db\n        ], p=1.)\n  \n# \u691c\u8a3c\u7528\u306e\u30c7\u30fc\u30bf\u5909\u63db\ndef get_valid_transforms():\n    return albu.Compose([\n            albu.Resize(CFG['size'], CFG['size']),\n            albu.Normalize(mean=CFG['mean'], std=CFG['std'], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)","e1abe063":"# \u8a13\u7df4\u6642\u306e\u753b\u50cf\u524d\u51e6\u7406\u306e\u52d5\u4f5c\u3092\u78ba\u8a8d\n# \u5b9f\u884c\u3059\u308b\u305f\u3073\u306b\u51e6\u7406\u7d50\u679c\u306e\u753b\u50cf\u304c\u5909\u308f\u308b\n\n# 1. \u753b\u50cf\u8aad\u307f\u8fbc\u307f\nimage_file_path = '\/kaggle\/input\/dog-image-dsg\/photo\/photo\/000bec180eb18c7604dcecc8fe0dba07.jpg'\nimg = get_img(image_file_path)   # [\u9ad8\u3055][\u5e45][\u8272RGB]\n\n# 2. \u5143\u306e\u753b\u50cf\u306e\u8868\u793a\nprint(\"***\u5909\u63db\u524d***\")\nplt.imshow(img)\nplt.show()\n\n# \u5b66\u7fd2\u7528\u306e\u753b\u50cf\u5909\u63db\ntransform = get_train_transforms()\nimg_transformed = transform(image=img)['image']\n\nprint(\"***\u5909\u63db\u5f8c***\")\n# (\u8272\u3001\u9ad8\u3055\u3001\u5e45)\u3092 (\u9ad8\u3055\u3001\u5e45\u3001\u8272)\u306b\u5909\u63db\u3057\u30010-1\u306b\u5024\u3092\u5236\u9650\u3057\u3066\u8868\u793a\nimg_transformed = img_transformed.numpy().transpose((1, 2, 0))\nimg_transformed = np.clip(img_transformed, 0, 1)\nplt.imshow(img_transformed)\nplt.show()","28670511":"class DogDataset(data.Dataset):\n    \"\"\"\n    \u72ac\u753b\u50cf\u306eDataset\u30af\u30e9\u30b9\u3002PyTorch\u306eDataset\u30af\u30e9\u30b9\u3092\u7d99\u627f\u3002\n\n    Attributes\n    ----------\n    df : DataFrame\n        \u6b63\u89e3\u30e9\u30d9\u30eb\u306e\u5165\u3063\u305f\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\n    data_root : str\n        \u753b\u50cf\u306e\u30d1\u30b9\n    transform : object\n        \u524d\u51e6\u7406\u30af\u30e9\u30b9\n    output_label : bool\n        \u6b63\u89e3\u30e9\u30d9\u30eb\u304c\u308f\u304b\u3063\u3066\u3044\u308b\u5834\u5408\u306fTrue\n    \"\"\"\n\n    def __init__(self,\n                 df,\n                 data_root, \n                 transforms=None, \n                 output_label=True):\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms = transforms\n        self.data_root = data_root\n        self.output_label=output_label\n        if output_label == True:\n            self.labels = self.df[CFG['target_col']].values\n\n    def __len__(self):\n        '''\u753b\u50cf\u306e\u679a\u6570\u3092\u8fd4\u3059'''\n        return self.df.shape[0]\n\n    def __getitem__(self, index):\n        '''\n        \u524d\u51e6\u7406\u3092\u3057\u305f\u753b\u50cf\u306eTensor\u5f62\u5f0f\u306e\u30c7\u30fc\u30bf\u3068\u30e9\u30d9\u30eb\u3092\u53d6\u5f97\n        '''\n        \n        # \u30e9\u30d9\u30eb\u306e\u53d6\u5f97\n        if self.output_label == True:\n            target = self.labels[index]\n          \n        # index\u756a\u76ee\u306e\u753b\u50cf\u3092\u30ed\u30fc\u30c9\n        img_path = self.data_root + self.df.loc[index]['id'] + '.jpg'\n        img = get_img(img_path)  # [\u9ad8\u3055][\u5e45][\u8272RGB]\n\n        # \u753b\u50cf\u306e\u524d\u51e6\u7406\u3092\u5b9f\u65bd\n        img_transformed = self.transforms(image=img)['image']\n\n        # \u6b63\u89e3\u30e9\u30d9\u30eb\u304c\u3042\u308b\u5834\u5408\u306f\u3001\u5909\u63db\u5f8c\u306e\u753b\u50cf\u3068\u30e9\u30d9\u30eb\u3092\u4e21\u65b9\u8fd4\u3059\n        if self.output_label == True:\n            return img_transformed, target\n        else:\n            return img_transformed","194b2ebe":"class DogImgClassifier(nn.Module):\n    def __init__(self, model_arch, n_class, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_arch, pretrained=pretrained) # timm\u304b\u3089\u30e2\u30c7\u30eb\u3092\u8aad\u307f\u8fbc\u3093\u3067\u8ee2\u79fb\u5b66\u7fd2\u3092\u884c\u3046\n        # pretrained\u306e\u30e2\u30c7\u30eb\u3068\u4eca\u56de\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u306f\u51fa\u529b\u3057\u305f\u3044\u30af\u30e9\u30b9\u6570\u304c\u7570\u306a\u308b\u305f\u3081\u30e2\u30c7\u30eb\u306e\u6700\u7d42\u5c64\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3092\u7d44\u307f\u66ff\u3048\u308b\n        n_features = self.model.classifier.in_features \n        self.model.classifier = nn.Linear(n_features, n_class)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","704c3eaa":"def prepare_dataloader(df,\n                       trn_idx,\n                       val_idx,\n                       data_root=CFG['data_root']):\n    \n    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n\n    # \u5b66\u7fd2\u7528\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u8aad\u307f\u8fbc\u3080\n    train_ds = DogDataset(train_, \n                              data_root, \n                              transforms=get_train_transforms(), \n                              output_label=True)\n    \n    # \u691c\u8a3c\u7528\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u8aad\u307f\u8fbc\u3080\n    valid_ds = DogDataset(valid_, \n                              data_root, \n                              transforms=get_valid_transforms(), \n                              output_label=True)\n    \n    train_loader = torch.utils.data.DataLoader(\n        train_ds,\n        batch_size=CFG['train_bs'],\n        pin_memory=False, # True\u306b\u3059\u308b\u3068CPU\u306e\u30e1\u30e2\u30ea\u9818\u57df\u304c\u30da\u30fc\u30b8\u30f3\u30b0\u3055\u308c\u306a\u3044\u3088\u3046\u306b\u306a\u308b\n        drop_last=False,  # True\u306b\u3059\u308b\u3068\u30c7\u30fc\u30bf\u6570\u304c\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u3067\u5272\u308a\u5207\u308c\u306a\u3044\u3068\u304d\u306e\u6700\u5f8c\u306e\u30df\u30cb\u30d0\u30c3\u30c1\u3092\u4f7f\u7528\u3057\u306a\u304f\u306a\u308b\n        shuffle=True,        \n        num_workers=CFG['num_workers'],\n    )\n    val_loader = torch.utils.data.DataLoader(\n        valid_ds, \n        batch_size=CFG['valid_bs'],\n        num_workers=CFG['num_workers'],\n        shuffle=False,\n        pin_memory=False,\n    )\n    return train_loader, val_loader","fdec881c":"def training(train):\n    \"\"\"\n    Attributes\n    ----------\n    train : DataFrame\n        \u5b66\u7fd2\u7528\u306e\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\n    \"\"\"\n\n    # \u958b\u59cb\u6642\u523b\n    start = time.time()\n\n    # \u30b7\u30fc\u30c9\u3092\u7d71\u4e00\n    seed_everything(CFG['seed'])\n    \n    # \u5206\u985e\u3059\u308b\u30af\u30e9\u30b9\u6570\u3092\u6307\u5b9a\n    class_values = train[CFG['target_col']].values\n    class_num = train[CFG['target_col']].nunique()\n    print(\"\u5206\u985e\u30af\u30e9\u30b9\u6570\uff1a\", class_num)\n    \n    # GPU\u304c\u4f7f\u3048\u308b\u304b\u3092\u78ba\u8a8d\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(\"\u4f7f\u7528\u30c7\u30d0\u30a4\u30b9\uff1a\", device)\n    \n    # \u4f55Epoch\u76ee\u304c\u30d9\u30b9\u30c8\u306eaccuracy\u3060\u3063\u305f\u304b\u3092\u8a18\u9332\n    best_epoch = -1 # \u6700\u3082\u3044\u3044\u6b63\u89e3\u7387\u3092\u51fa\u3057\u305fepoch\u6570\n    best_acc = 0.0 # \u6700\u3082\u3044\u3044\u6b63\u89e3\u7387\n        \n    # Fold\u3067\u5206\u5272\n    # \u5404\u30db\u30fc\u30eb\u30c9\u3067\u30e9\u30d9\u30eb\u306e\u7a2e\u985e\u304c\u5747\u4e00\u3068\u306a\u308b\u3088\u3046\u306b\u5c64\u5316\u62bd\u51fa\n    folds = StratifiedKFold(\n        n_splits=CFG['fold_num'],\n        shuffle=True,\n        random_state=CFG['seed']).split(np.arange(train.shape[0]),class_values)\n    \n    # Fold\u5206\u7e70\u308a\u8fd4\u3059\n    for fold, (trn_idx, val_idx) in enumerate(folds):\n\n        # \u30c7\u30d0\u30c3\u30b0\u7528\u306e\u3068\u304d\u306f1fold\u3060\u3051\u8a66\u3059\n        if CFG['debug'] and fold != 0:\n            break\n\n        print(\"-----------\")\n        print('Fold {} \u5b66\u7fd2\u958b\u59cb'.format(fold))\n        \n        # train, valid\u306e\u6570\n        print(\"train:\", len(trn_idx), \" valid:\", len(val_idx))\n        \n        # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u751f\u6210\n        model = DogImgClassifier(CFG['model_arch'],\n                                 class_num,\n                                 pretrained=True).to(device)\n\n        # \u8a13\u7df4\u30e2\u30fc\u30c9\u306b\u8a2d\u5b9a\n        model.train()\n\n        print('\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a2d\u5b9a\u5b8c\u4e86\uff1a\u5b66\u7fd2\u6e08\u307f\u306e\u91cd\u307f\u3092\u30ed\u30fc\u30c9\u3057\u3001\u8a13\u7df4\u30e2\u30fc\u30c9\u306b\u8a2d\u5b9a\u3057\u307e\u3057\u305f')\n\n        # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092GPU\u3078\n        model.to(device)\n\n        # \u640d\u5931\u95a2\u6570\u306e\u8a2d\u5b9a\n        # \u3053\u3053\u3067\u306f\u640d\u5931\u95a2\u6570\u3068\u3057\u3066\u30af\u30ed\u30b9\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u3092\u6307\u5b9a\n        criterion = nn.CrossEntropyLoss().to(device)\n\n        # \u6700\u9069\u5316\u624b\u6cd5\u306e\u8a2d\u5b9a\n        # \u3053\u3053\u3067\u306f\u6700\u9069\u5316\u624b\u6cd5\u3068\u3057\u3066Adam\u3092\u6307\u5b9a\n        optimizer = torch.optim.Adam(model.parameters(),\n                                     lr=CFG['lr'], \n                                     weight_decay=CFG['weight_decay'])\n        \n        # \u30b9\u30b1\u30b8\u30e5\u30fc\u30e9\u306e\u8a2d\u5b9a\n        # \u3053\u3053\u3067\u306fStepLR\u3092\u6307\u5b9a\n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=['step_size'], gamma=CFG['gamma'])\n        \n        # epoch\u306e\u30eb\u30fc\u30d7\n        for epoch in range(CFG['epochs']):\n            print('Epoch {}\/{}'.format(epoch+1, CFG['epochs'])) \n            end = time.time() # \u7d42\u4e86\u6642\u523b\n            print(end-start, \"\u79d2\")\n            print('-------------')\n            \n            # dataloader\u4f5c\u6210\n            train_dataloader, val_dataloader = prepare_dataloader(train,\n                                                                  trn_idx,\n                                                                  val_idx,\n                                                                  data_root=CFG['data_root'])\n            # train\u3068valid\u306edataloader\u3092\u7ba1\u7406\n            dataloaders_dict = {'train':train_dataloader, 'val':val_dataloader}\n            \n            # epoch\u3054\u3068\u306e\u5b66\u7fd2\u3068\u691c\u8a3c\u306e\u30eb\u30fc\u30d7\n            for phase in ['train', 'val']:\n                print(\"epoch\", epoch, \"---pahse\", phase)\n                if phase == 'train':\n                    model.train()  # \u30e2\u30c7\u30eb\u3092\u8a13\u7df4\u30e2\u30fc\u30c9\u306b\n                    \n                    scaler = GradScaler() # amp\u306e\u5229\u7528\n                    \n                else:\n                    model.eval()   # \u30e2\u30c7\u30eb\u3092\u691c\u8a3c\u30e2\u30fc\u30c9\u306b\n\n                epoch_loss = 0.0  # epoch\u306e\u640d\u5931\u548c\n                epoch_corrects = 0  # epoch\u306e\u6b63\u89e3\u6570\n\n                val_preds = []\n                val_true =[]\n                \n                # \u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\u304b\u3089\u30df\u30cb\u30d0\u30c3\u30c1\u3092\u53d6\u308a\u51fa\u3059\u30eb\u30fc\u30d7\n                for inputs, labels in tqdm(dataloaders_dict[phase]):\n\n                    # GPU\u304c\u4f7f\u3048\u308b\u306a\u3089GPU\u306b\u30c7\u30fc\u30bf\u3092\u9001\u308b\n                    inputs = inputs.to(device)\n                    labels = labels.to(device)\n\n                    # optimizer\u3092\u521d\u671f\u5316\n                    optimizer.zero_grad()\n\n                    # \u9806\u4f1d\u642c\uff08forward\uff09\u8a08\u7b97(Scaler\u306b\u3088\u308b\u9ad8\u901f\u5316)\n                    with torch.set_grad_enabled(phase == 'train'):\n                        with autocast():  # float32\u306e\u4fdd\u6301\u3084\u52fe\u914d\u306e\u5024\u306e\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u7b49\u3092\u81ea\u52d5\u7684\u306b\u884c\u3046\u3053\u3068\u3067TensorCore\u3092\u6709\u52b9\u6d3b\u7528\u3057\u3001GPU\u8a08\u7b97\u306e\u9ad8\u901f\u5316\u30fb\u7701\u30e1\u30e2\u30ea\u5316\n                            outputs = model(inputs)\n                            loss = criterion(outputs, labels)\n                        _, preds = torch.max(outputs, 1)  # \u30e9\u30d9\u30eb\u3092\u4e88\u6e2c\n\n                        # \u8a13\u7df4\u6642\u306f\u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\n                        if phase == 'train':\n                            scaler.scale(loss).backward()\n                            scaler.step(optimizer)\n                            scaler.update()\n\n                    # loss\u306e\u5408\u8a08\u3092\u66f4\u65b0\n                    epoch_loss += loss.item() * inputs.size(0)  \n                    \n                    # \u6b63\u89e3\u6570\u306e\u5408\u8a08\u3092\u66f4\u65b0\n                    epoch_corrects += torch.sum(preds == labels.data)\n\n                    val_preds = np.concatenate([val_preds, preds.to('cpu').numpy()], 0)\n                    val_true = np.concatenate([val_true, labels.data.to('cpu').numpy()], 0)\n\n                # epoch\u3054\u3068\u306eloss\u3068\u6b63\u89e3\u7387\u3092\u8868\u793a\n                epoch_loss = epoch_loss \/ len(dataloaders_dict[phase].dataset)\n                epoch_acc = epoch_corrects.double(\n                ) \/ len(dataloaders_dict[phase].dataset)\n\n                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                    phase, epoch_loss, epoch_acc))\n                \n                # \u691c\u8a3c\u30b9\u30b3\u30a2\u306e\u6b63\u89e3\u7387\u3092\u66f4\u65b0\u3057\u305f\u5834\u5408\u306f\u305d\u306e\u6642\u306eepoch\u3092\u8a18\u9332\n                if phase == 'val' and best_acc < float(epoch_acc.to('cpu').numpy()):\n                    best_acc = float(epoch_acc.to('cpu').numpy())\n                    best_epoch = epoch\n                    \n                # \u4f5c\u6210\u3057\u305f\u30e2\u30c7\u30eb\u306e\u8a18\u9332\n                torch.save(model.state_dict(),'{}_fold_{}_{}'.format(CFG['model_arch'], fold, epoch))\n                \n        # \u4e0d\u8981\u30d5\u30a1\u30a4\u30eb\u3092\u524a\u9664\u3057\u3001\u30e1\u30e2\u30ea\u958b\u653e\n        del model, optimizer, train_dataloader, val_dataloader, scaler\n        torch.cuda.empty_cache()\n    \n    # \u30d9\u30b9\u30c8\u306a\u691c\u8a3c\u30b9\u30b3\u30a2\u3068\u305d\u306e\u6642\u306e\u30a8\u30dd\u30c3\u30af\u6570\u306e\u30da\u30a2\u3092\u8fd4\u3059\n    return best_epoch, best_acc","ee81000b":"BEST_EPOCH = -1\n# \u30c7\u30d0\u30c3\u30b0\u7528\u306e\u3068\u304d\u306f\u30c7\u30fc\u30bf\u91cf\u3092\u6e1b\u3089\u3057\u3066\u5b9f\u884c\nif CFG['debug']:\n    BEST_EPOCH, BEST_ACC = training(train_df.iloc[:1000]) \nelse:\n    BEST_EPOCH, BEST_ACC = training(train_df) ","f8004861":"print(\"\u5168Fold\u3092\u901a\u3057\u3066\u6700\u3082\u826f\u304b\u3063\u305f\u691c\u8a3c\u30b9\u30b3\u30a2(\u6b63\u89e3\u7387)\uff1a\", BEST_ACC)\nprint(\"\u305d\u306e\u3068\u304d\u306eEpoch\u6570\uff1a\", BEST_EPOCH)\n\n#\u3000\u3082\u3057\u3082\u30d9\u30b9\u30c8Epoch\u3092\u7528\u3044\u3066\u63a8\u8ad6\u3059\u308b\u5834\u5408\u306f\u6307\u5b9a\u3059\u308b(\u8907\u6570Epoch\u306e\u30e2\u30c7\u30eb\u3092\u9078\u629e\u3057\u305f\u3044\u5834\u5408\u306f\u500b\u5225\u306b\u6307\u5b9a)\nCFG['used_epochs'] = [BEST_EPOCH]","66e08b72":"def inference_one_epoch(model, data_loader, device):\n    model.eval()\n\n    image_preds_all = []\n    \n    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n    for step, (imgs) in pbar:\n        imgs = imgs.to(device).float()\n        \n        # \u30e2\u30c7\u30eb\u3092\u4f7f\u3063\u305f\u63a8\u8ad6\u3092\u884c\u3046\n        image_preds = model(imgs)   #output = model(input)\n        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n        \n    # \u63a8\u8ad6\u7d50\u679c\u3092\u7d50\u5408\u3057\u3066\u8fd4\u3059\n    image_preds_all = np.concatenate(image_preds_all, axis=0)\n    return image_preds_all","e5d37b47":"# \u63a8\u8ad6\ndef inference(train, test):\n    \"\"\"\n    Attributes\n    ----------\n    train : DataFrame\n        \u5b66\u7fd2\u7528\u306e\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\n    test : DataFrame\n        \u30c6\u30b9\u30c8\u7528\u306e\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\n    \"\"\"\n    # \u958b\u59cb\u6642\u523b\n    start = time.time()\n    \n    # \u30b7\u30fc\u30c9\u3092\u7d71\u4e00\n    seed_everything(CFG['seed'])\n    \n    # \u30af\u30e9\u30b9\u6570\n    class_values = train[CFG['target_col']].values\n    class_num = train[CFG['target_col']].nunique()\n    print(\"\u5206\u985e\u30af\u30e9\u30b9\u6570\uff1a\", class_num)\n    \n    # GPU\u304c\u4f7f\u3048\u308b\u304b\u3092\u78ba\u8a8d\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(\"\u4f7f\u7528\u30c7\u30d0\u30a4\u30b9\uff1a\", device)\n\n    # \u7d50\u679c\u306e\u691c\u8a3c\u306b\u7528\u3044\u308bdf\n    valid_df = pd.DataFrame()\n    \n    # Fold\u3067\u5206\u5272\n    folds = StratifiedKFold(\n        n_splits=CFG['fold_num'],\n        shuffle=True,\n        random_state=CFG['seed']).split(np.arange(train.shape[0]),class_values)\n    \n    # Fold\u5206\u7e70\u308a\u8fd4\u3059\n    for fold, (trn_idx, val_idx) in enumerate(folds):\n        # \u30c7\u30d0\u30c3\u30b0\u7528\u306e\u3068\u304d\u306f1fold\u3060\u3051\u8a66\u3059\n        if CFG['debug'] and fold != 0:\n            break\n        print(\"-----------\")\n        print('Fold {} \u63a8\u8ad6\u958b\u59cb'.format(fold))\n        \n        # train, valid\u306e\u6570\n        print(\"valid:\", len(val_idx), \" test:\", test.shape[0])\n        \n        # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u751f\u6210\n        model = DogImgClassifier(CFG['model_arch'], class_num, pretrained=True).to(device)\n\n        # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092GPU\u3078\n        model.to(device)\n\n        # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304c\u3042\u308b\u7a0b\u5ea6\u56fa\u5b9a\u3067\u3042\u308c\u3070\u3001\u9ad8\u901f\u5316\u3055\u305b\u308b\n        torch.backends.cudnn.benchmark = True\n\n        # \u691c\u8a3c\u7528\u306e\u30c7\u30fc\u30bf\n        valid_ = train.loc[val_idx,:].reset_index(drop=True)\n        valid_ds = DogDataset(valid_,\n                              CFG['data_root'],\n                              transforms=get_valid_transforms(),\n                              output_label=False)\n        \n        # \u30c6\u30b9\u30c8\u7528\u306e\u30c7\u30fc\u30bf\n        test_ = test.copy()\n        test_ds = DogDataset(test_,\n                             CFG['data_root'],\n                             transforms=get_valid_transforms(),\n                             output_label=False)\n\n        # \u691c\u8a3c\u7528\u306e\u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\n        val_loader = torch.utils.data.DataLoader(\n            valid_ds, \n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            shuffle=False,\n            pin_memory=False,\n        )\n        \n        # \u30c6\u30b9\u30c8\u7528\u306e\u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\n        tst_loader = torch.utils.data.DataLoader(\n            test_ds, \n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            shuffle=False,\n            pin_memory=False,\n        )\n        \n        # \u7d50\u679c\u3092\u683c\u7d0d\u3059\u308b\n        val_preds = []\n        tst_preds = []\n        \n        # epoch\u306e\u30eb\u30fc\u30d7(\u5b66\u7fd2\u3067\u4f7f\u3063\u305f\u3082\u306e\u306e\u307f\u3092\u63a1\u7528)\n        for i, epoch in enumerate(CFG['used_epochs']):  \n            print('Epoch {}'.format(epoch))\n            end = time.time() # \u7d42\u4e86\u6642\u523b\n            print(end-start, \"\u79d2\")\n            print('-------------')\n            \n            # \u5b66\u7fd2\u6e08\u307f\u306e\u30e2\u30c7\u30eb\u3092\u30ed\u30fc\u30c9\n            print('{}\/{}_fold_{}_{}'.format(CFG['model_path'], CFG['model_arch'], fold, epoch))\n            model.load_state_dict(torch.load('{}\/{}_fold_{}_{}'.format(CFG['model_path'],CFG['model_arch'], fold, epoch)))\n            \n            # \u63a8\u8ad6\u3092\u5b9f\u65bd\n            with torch.no_grad():\n                val_preds += [inference_one_epoch(model, val_loader, device)]\n                tst_preds += [inference_one_epoch(model, tst_loader, device)]\n        \n        # \u63a8\u8ad6\u7d50\u679c\u306e\u5e73\u5747\u3092\u53d6\u308b\n        val_preds = np.mean(val_preds, axis=0) \n        tst_preds = np.mean(tst_preds, axis=0) \n\n        # logloss\u3068accuracy\u3092\u8a08\u7b97\n        print('fold {} validation loss = {:.5f}'.format(fold, log_loss(valid_[CFG['target_col']].values, val_preds)))\n        print('fold {} validation accuracy = {:.5f}'.format(fold, (valid_[CFG['target_col']].values==np.argmax(val_preds, axis=1)).mean()))\n\n        # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u95a2\u3059\u308b\u63a8\u8ad6\u7d50\u679c\u3092\u4fdd\u5b58\n        if fold == 0:\n            tst_preds_sum = tst_preds.copy()\n            \n        else:\n            tst_preds_sum += tst_preds\n            \n        temp_df = train.loc[val_idx,:].copy()\n        temp_df['pred'] = np.argmax(val_preds, axis=1)\n        valid_df = valid_df.append(temp_df)\n        \n        # \u4f7f\u7528\u3057\u305f\u30e2\u30c7\u30eb\u3092\u524a\u9664\u3057\u3066\u30e1\u30e2\u30ea\u958b\u653e\n        del model\n        torch.cuda.empty_cache()\n    \n    # \u63a8\u8ad6\u7d50\u679c\u3092\u8fd4\u3059\n    return  valid_df, tst_preds_sum \/ CFG['fold_num']","9311da4f":"# \u30c7\u30d0\u30c3\u30b0\u7528\u306e\u3068\u304d\u306f\u30c7\u30fc\u30bf\u91cf\u3092\u6e1b\u3089\u3057\u3066\u5b9f\u884c\nif CFG['debug']:\n    valid_df, tst_preds = inference(train_df.iloc[:1000], test_df) \nelse:\n    valid_df, tst_preds = inference(train_df, test_df)","0d59d07d":"cm = confusion_matrix(y_pred=valid_df['pred'].values, y_true=valid_df['breed'].values)\ncmp = ConfusionMatrixDisplay(cm)\nfig, ax= plt.subplots(figsize=(20,20))\ncmp.plot(cmap=plt.cm.Blues, ax=ax)","ca5a81cd":"def plot_true_pred_images(df, target_to_breed, true_type, pred_type, plot_max):\n    \n    print(\"true: \", true_type, target_to_breed[true_type])\n    print(\"pred: \", pred_type, target_to_breed[pred_type])\n    # \u8868\u793a\u3057\u305f\u3044\u753b\u50cf\u306e\u30ea\u30b9\u30c8\n    img_list = valid_df.query('breed == @true_type and pred == @pred_type')['id'].map(\n        lambda x:'\/kaggle\/input\/dog-image-dsg\/photo\/photo\/' + x + '.jpg').values\n    \n    img_list = img_list[:plot_max]\n    # \u753b\u50cf\u306e\u8868\u793a\n    width = 35\n    height = 35\n    plt.figure(figsize=(width, height))\n    for i in range(len(img_list)):\n        plt.subplot(5, 5, i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(plt.imread(img_list[i], 0))\n    plt.show()","b3c3f062":"# 21maltese_dog\u3060\u304c\u300122Ihasa\u3068\u4e88\u6e2c\u3057\u305f\u753b\u50cf\u3092\u898b\u3066\u307f\u308b\nplot_true_pred_images(valid_df, target_to_breed, true_type=22, pred_type=21, plot_max=10)","9a327876":"# 22Ihasa\u306e\u672c\u5f53\u306e\u753b\u50cf\u3092\u898b\u3066\u307f\u308b\nplot_true_pred_images(valid_df, target_to_breed, true_type=22, pred_type=22, plot_max=10)","10a247f3":"submission = test_df.copy()\nsubmission['breed'] = np.argmax(tst_preds, axis=1)  # \u30b9\u30b3\u30a2\u304c\u9ad8\u3044\u3082\u306e\u3092\nsubmission.replace(target_to_breed, inplace=True)","79e39428":"submission.shape","c2340fea":"submission.head()","dac4369e":"# \u63d0\u51fa\u30d5\u30a1\u30a4\u30eb\u3092\u8a18\u9332\nsubmission.to_csv(\"submission_XXXX.csv\", index=False, header=True)","31adb087":"# \u5fc5\u8981\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","14df9f7b":"# \u63a8\u8ad6\u304c\u5f53\u305f\u3063\u3066\u3044\u306a\u3044\u30c7\u30fc\u30bf\u306e\u78ba\u8a8d","2da7abc1":"# \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f","2ac50fd8":"# \u753b\u50cf\u524d\u51e6\u7406\nDataAugmentation\u306a\u3069\u3092\u5909\u3048\u308b\u5834\u5408\u306f\u3053\u3053\u3092\u5909\u66f4  \nalbumentation\u3067\u3067\u304d\u308b\u4ed6\u306e\u51e6\u7406\u306e\u53c2\u8003  \nhttps:\/\/qiita.com\/kurilab\/items\/b69e1be8d0224ae139ad\n\nhttps:\/\/albumentations-demo.herokuapp.com\/","30f8ee1e":"# \u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc","742f7d6b":"# \u63a8\u8ad6\u306e\u5b9f\u884c","8549111d":"# \u30c7\u30fc\u30bf\u306e\u78ba\u8a8d","80429582":"# 1\u30a8\u30dd\u30c3\u30af\u3054\u3068\u306e\u63a8\u8ad6","3aab7f49":"# \u3053\u306e\u30b3\u30fc\u30c9\u306f\u5b66\u7fd2\u7528\u306e\u30b9\u30bf\u30fc\u30bf\u30fc\u30b3\u30fc\u30c9\u3067\u3059\n","56c25f63":"## Contents\n1. \u5fc5\u8981\u30c7\u30fc\u30bf\u3084\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u8aad\u307f\u8fbc\u307f \n1. \u30c7\u30fc\u30bf\u306e\u78ba\u8a8d\n1. \u753b\u50cf\u306e\u8868\u793a\n1. \u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\n1. \u5b66\u7fd2\u30fb\u63a8\u8ad6\u306e\u8a2d\u5b9a\u5024\u3092\u6307\u5b9a\n1. \u5404\u7a2e\u95a2\u6570\u30fb\u30af\u30e9\u30b9\u306e\u4f5c\u6210\n    1. \u4e71\u6570\u30b7\u30fc\u30c9\u306e\u56fa\u5b9a\n    1. \u753b\u50cf\u306e\u53d6\u5f97\u95a2\u6570\n    1. DataAugumentaion\n    1. Dataset\u30ab\u30b9\u30bf\u30e0\u30af\u30e9\u30b9\u306e\u4f5c\u6210\n    1. Dataloader\u30af\u30e9\u30b9\u306e\u4f5c\u6210\n    1. model\u4f5c\u6210\n    1. 1\u30a8\u30dd\u30c3\u30af\u3054\u3068\u306e\u63a8\u8ad6\n1. \u5b66\u7fd2\n1. \u63a8\u8ad6\n1. \u7d50\u679c\u306e\u78ba\u8a8d\n1. \u63d0\u51fa\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210\n### ","011df98c":"# \u5b66\u7fd2\n\u3053\u3053\u307e\u3067\u306e\u5b9a\u7fa9\u3057\u305f\u30af\u30e9\u30b9\u3092\u7528\u3044\u3066\u5b66\u7fd2\u3092\u884c\u3044\u307e\u3059\u3002","b9098254":"# \u753b\u50cf\u306e\u8868\u793a\n\u5224\u5225\u3057\u305f\u753b\u50cf\u306f\u3069\u306e\u3088\u3046\u306a\u3082\u306e\u304b\u3092\u5b9f\u969b\u306b\u30d7\u30ed\u30c3\u30c8\u3057\u3066\u78ba\u8a8d\u3057\u3066\u307f\u307e\u3059\u3002","1ab57195":"# \u753b\u50cf\u306e\u53d6\u5f97\u95a2\u6570","1a4b6445":"# \u53c2\u8003URL\nPytorch\u306e\u9ad8\u901f\u5316\nhttps:\/\/qiita.com\/sugulu_Ogawa_ISID\/items\/62f5f7adee083d96a587\n\nalbumentaion\u306e\u30c7\u30e2\u30b5\u30a4\u30c8\nhttps:\/\/albumentations-demo.herokuapp.com\/","41c6bc13":"# \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u30af\u30e9\u30b9\n\u4eca\u56de\u5b66\u7fd2\u30fb\u63a8\u8ad6\u3057\u305f\u3044\u753b\u50cf\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u30ab\u30b9\u30bf\u30e0\u30af\u30e9\u30b9\u3092\u4f5c\u6210\u3059\u308b","28f500ad":"# \u4e71\u6570\u30b7\u30fc\u30c9\u306e\u56fa\u5b9a\u95a2\u6570","5a863097":"# \u63a8\u8ad6\n\u5b66\u7fd2\u306b\u3088\u3063\u3066\u3001\u4f5c\u6210\u3057\u305f\u30e2\u30c7\u30eb\u3092\u4f7f\u3063\u305f\u63a8\u8ad6\u3092\u884c\u3046\u30b3\u30fc\u30c9\u3067\u3059","c10210c9":"# \u30b9\u30bf\u30fc\u30bf\u30fc\u30b3\u30fc\u30c9\u3092\u7406\u89e3\u30fb\u52d5\u4f5c\u78ba\u8a8d\u3067\u304d\u305f\u4eba\u306f...\u2193\n1. \u5404\u7a2e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u5909\u66f4\u3057\u3066\u7cbe\u5ea6\u304c\u3069\u306e\u3088\u3046\u306b\u5909\u5316\u3059\u308b\u304b\u3092\u78ba\u8a8d\u3057\u3066\u307f\u308b\n     1. \u753b\u50cf\u30b5\u30a4\u30ba\u3092\u5909\u3048\u3066\u307f\u308b\n     1. \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u3092\u5909\u66f4\u3057\u3066\u307f\u308b\n     1. epoch\u6570\u3092\u5909\u66f4\u3057\u3066\u307f\u308b\n     1. \u5b66\u7fd2\u7387\u3092\u5909\u66f4\u3057\u3066\u307f\u308b  \n    \n1. \u5b9f\u88c5\u3092\u5909\u66f4\u3057\u3066\u307f\u308b\n    1. DataAugmentation\u306e\u51e6\u7406\u3092\u8ffd\u52a0\u3057\u3066\u307f\u308b  \n    https:\/\/qiita.com\/kurilab\/items\/b69e1be8d0224ae139ad  \n    1. model\u3092\u5909\u66f4\u3057\u3066\u307f\u308b  \n    https:\/\/github.com\/rwightman\/pytorch-image-models\/tree\/master\/timm\/models  \n    \u4e0a\u8a18\u3092\u53c2\u8003\u306btimm\u306e\"vit_base_patch16_224\"\u30e2\u30c7\u30eb\u306b\u5909\u66f4\u3057\u3066\u307f\u307e\u3057\u3087\u3046(\u6700\u7d42\u5c64\u306e\u5909\u66f4\u65b9\u6cd5\u306b\u6ce8\u610f)  \n    1. \u640d\u5931\u95a2\u6570\u3092\u5909\u66f4\u3057\u3066\u307f\u308b  \n    https:\/\/pytorch.org\/docs\/stable\/nn.html#loss-functions  \n    1. optimizer\u3092\u5909\u66f4\u3057\u3066\u307f\u308b  \n    https:\/\/pytorch.org\/docs\/stable\/optim.html  \n    1. \u30b9\u30b1\u30b8\u30e5\u30fc\u30e9\u3092\u5909\u66f4\u3057\u3066\u307f\u308b  \n    https:\/\/katsura-jp.hatenablog.com\/entry\/2019\/01\/30\/183501  \n\n1. \u5b9f\u88c5\u3092\u8ffd\u52a0\u3057\u3066\u307f\u308b\n    1. Test Time Augmentation (TTA)\u3092\u884c\u3063\u3066\u307f\u308b\n    1. pseudo labeling\u3092\u884c\u3063\u3066\u307f\u308b","8c2776c4":"# \u63d0\u51fa\u7528\u30d5\u30a1\u30a4\u30eb\u4f5c\u6210","1fcdb07f":"# \u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u5bfe\u5fdc\n\u30af\u30e9\u30b9\u5206\u985e\u3092\u884c\u3046\u969b\u306b\u30ab\u30c6\u30b4\u30ea\u306e\u6587\u5b57\u5217\u3067\u306f\u5b66\u7fd2\u3092\u884c\u3048\u306a\u3044\u305f\u3081\u3001\u30ab\u30c6\u30b4\u30ea\u756a\u53f7\u3068\u30ab\u30c6\u30b4\u30ea\u540d\u30921\u5bfe1\u5bfe\u5fdc\u3055\u305b\u308b\u5bfe\u5fdc\u8868\u3092\u4f5c\u6210\u3059\u308b","a2b2e877":"# ","60f5b554":"# \u5b66\u7fd2\u30fb\u63a8\u8ad6\u306e\u8a2d\u5b9a\n\u5b66\u7fd2\u6642\u30fb\u63a8\u8ad6\u6642\u306b\u7528\u3044\u308b\u8a2d\u5b9a\u3092\u6307\u5b9a\u3059\u308b","0ff463f9":"# \u5909\u66f4\u3057\u305f\u753b\u50cf\u306e\u78ba\u8a8d\n\u5b9a\u7fa9\u3057\u305fget_train_transform\u306e\u5909\u63db\u51e6\u7406\u306b\u3088\u3063\u3066\u753b\u50cf\u304c\u3069\u306e\u3088\u3046\u306b\u52a0\u5de5\u3055\u308c\u308b\u304b\u3092\u78ba\u8a8d\u3059\u308b","9739b956":"# \u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30a4\u30f3\u30dd\u30fc\u30c8","a5c891f3":"# \u30e2\u30c7\u30eb\n\u4f7f\u7528\u3059\u308b\u30e2\u30c7\u30eb\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3092\u5b9a\u7fa9\u3059\u308b\u3002  \npretrained=True\u3067\u3042\u308c\u3070\u3001\u4e8b\u524d\u5b66\u7fd2\u6e08\u307f\u91cd\u307f\u3092\u5229\u7528\u3057\u8ee2\u79fb\u5b66\u7fd2\u3092\u884c\u3046","ac6e4aaa":"# \u5b66\u7fd2\u306e\u5b9f\u884c"}}