{"cell_type":{"32342694":"code","278aaa5a":"code","8a1c112f":"code","8337e70e":"code","ced88aca":"code","428341d6":"code","84ded361":"code","25d04fd8":"code","534be2e1":"code","48fe4ba9":"code","e0ee328b":"code","d18ca549":"code","86106825":"code","11e7a368":"code","5f979136":"code","b585a254":"code","b4337e68":"code","c4d4451b":"code","3a45e41a":"code","e552c487":"code","1afe7147":"code","3fa3a147":"code","23b8da0f":"code","5222fdd8":"code","d5942a86":"code","ad03cae1":"code","47baf92c":"code","fbe493b8":"code","8d598377":"code","c20b3082":"code","93eb1896":"code","674ddfe6":"code","28a27ea1":"code","76c24a7c":"code","7d02410f":"code","f92d0b13":"code","46275b13":"code","6559c8d7":"code","5de67e0e":"code","49a57386":"code","7b24b0cd":"code","8f8bd344":"code","8a7b90ce":"code","4714d639":"code","22370c79":"code","8ff3ae0b":"code","f44d6b90":"code","84d48b9c":"code","9e4df19f":"code","1086bfd4":"code","42217f8f":"code","b05c1c0f":"markdown","c6380183":"markdown","82b9727c":"markdown","2490e25c":"markdown","84df0083":"markdown","96be1682":"markdown"},"source":{"32342694":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#sns.set(\n#    font_scale=1.5,\n#    style=\"whitegrid\",\n#    rc={'figure.figsize':(20,7)}\n#)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","278aaa5a":"train_data = pd.read_csv(\"..\/input\/learn-together\/train.csv\", index_col='Id')\ntrain_data.sample(5)","8a1c112f":"train_data.shape","8337e70e":"train_data.describe().T","ced88aca":"# Get names of columns with missing values\ncols_with_missing = [col for col in train_data.columns\n                     if train_data[col].isnull().any()]\nprint(cols_with_missing)","428341d6":"#All columns are numerical\n#train_data.dtypes\ntrain_data.info()","84ded361":"#I change type of categorical columns in order to display correlacion easily\ntrain_data.iloc[:,10:-1] = train_data.iloc[:,10:-1].astype(\"category\")","25d04fd8":"f,ax = plt.subplots(figsize=(8,6))\nsns.heatmap(train_data.corr(),annot=True, linewidths=.5, fmt='.1f', ax=ax)\nplt.show()","534be2e1":"train_data.iloc[:,:3].columns","48fe4ba9":"sns.pairplot(train_data[list(train_data.iloc[:,6:9].columns)+['Cover_Type']], hue=\"Cover_Type\");\n#ns.pairplot(train_data[list(train_data.iloc[:,:3].columns)+['Cover_Type']], hue=\"Cover_Type\", palette=\"colorblind\", diag_kind=\"kde\");","e0ee328b":"FG = sns.FacetGrid(train_data, hue=\"Cover_Type\", palette=\"Set2\", size=5) \n#                   hue_kws={\"marker\": [\"^\", \"v\", \"*\"]})\nFG.map(plt.scatter, \"Hillshade_9am\", \"Hillshade_3pm\", s=50, linewidth=.5, edgecolor=\"white\")\nFG.add_legend();\n","d18ca549":"plt.figure(figsize=(24,18))\n\nfor n, columns in enumerate(train_data.iloc[:,:10].columns,1):\n    plt.subplot(4,3,n)\n    for i in np.arange(1,8):\n        sns.kdeplot(train_data[columns][(train_data['Cover_Type']==i)], label=i, shade=True)\n        plt.xlabel(columns);\n\n","86106825":"plt.figure(figsize=(24,9))\n\nfor i in np.arange(1,8):\n    plt.subplot(2,4,i)\n    plt.hist(train_data.loc[train_data['Cover_Type']==i, 'Wilderness_Area3'], range = [0,1])\n    plt.xlabel(i)\n        \n   \n    ","11e7a368":"plt.figure(figsize=(18,8))\n\nfor i in np.arange(1,8):\n    plt.subplot(2,4,i)\n    sns.distplot(train_data['Hillshade_9am'][(train_data['Cover_Type']==i)])\n    plt.xlabel(i)","5f979136":"fig, axs = plt.subplots(2, 2, sharey=True, figsize = (20,15))\n\naxs[0, 0].scatter(train_data['Hillshade_9am'], train_data['Hillshade_Noon'], color='darkblue')\naxs[0, 0].set(title = 'Hillshade_9am And Hillshade_Noon', xlabel = \"Hillshade_9am\", ylabel = \"Hillshade_Noon\")\n\naxs[0, 1].scatter(train_data['Hillshade_Noon'], train_data['Hillshade_3pm'], color='darkblue')\naxs[0, 1].set(title = 'Hillshade_Noon And Hillshade_3pm', xlabel = \"Hillshade_Noon\", ylabel = \"Hillshade_3pm\")\n\naxs[1, 0].scatter(train_data['Slope'], train_data['Hillshade_3pm'], color='darkblue')\naxs[1, 0].set(title = 'Slope And Hillshade_3pm', xlabel = \"Slope\", ylabel = \"Hillshade_3pm\")\n\naxs[1, 1].scatter(train_data['Aspect'], train_data['Hillshade_3pm'], color='darkblue')\naxs[1, 1].set(title = 'Aspect And Hillshade_3pm', xlabel = \"Aspect\", ylabel = \"Hillshade_3pm\")\n","b585a254":"train_data.plot(kind='scatter', x='Slope', y='Elevation', alpha=0.5, color='maroon', figsize = (12,9))\nplt.title('Slope And Elevation')\nplt.xlabel(\"Slope\")\nplt.ylabel(\"Elevation\")\nplt.show()","b4337e68":"# import modules \nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn import linear_model\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import r2_score","c4d4451b":"# To prepare data\nHillshade_train_data = train_data[(train_data[\"Hillshade_3pm\"] != 0)]\nHillshade_test_data = train_data[(train_data[\"Hillshade_3pm\"] == 0)]\nprint(Hillshade_train_data.shape)\nprint(Hillshade_test_data.shape)\n","3a45e41a":"# linear regression\nlr = linear_model.LinearRegression()\n#lr = linear_model.LassoCV(normalize = True)\n#lr = linear_model.RidgeCV(normalize = True)\nscores=cross_val_score(lr,Hillshade_train_data[['Hillshade_9am', 'Hillshade_Noon', 'Aspect', 'Slope']],Hillshade_train_data[\"Hillshade_3pm\"],cv=5,scoring='r2')\nprint(scores)\nprint(scores.mean())","e552c487":"lr.fit(Hillshade_train_data[['Hillshade_9am', 'Hillshade_Noon', 'Aspect', 'Slope']],Hillshade_train_data[\"Hillshade_3pm\"])\nHillshade_test_data.loc[:,\"Hillshade_3pm\"] = lr.predict(Hillshade_test_data[['Hillshade_9am', 'Hillshade_Noon', 'Aspect', 'Slope']])","1afe7147":"fig, axs = plt.subplots(2, 2, sharey=True, figsize = (20,15))\n\naxs[0, 0].scatter(train_data['Hillshade_9am'], train_data['Hillshade_3pm'], color='darkblue')\naxs[0, 0].scatter(Hillshade_test_data['Hillshade_9am'], Hillshade_test_data['Hillshade_3pm'], color='maroon')\naxs[0, 0].set(title = 'Hillshade_9am And Hillshade_3pm', xlabel = \"Hillshade_9am\", ylabel = \"Hillshade_3pm\")\n\naxs[0, 1].scatter(train_data['Hillshade_Noon'], train_data['Hillshade_3pm'], color='darkblue')\naxs[0, 1].scatter(Hillshade_test_data['Hillshade_Noon'], Hillshade_test_data['Hillshade_3pm'], color='maroon')\naxs[0, 1].set(title = 'Hillshade_Noon And Hillshade_3pm', xlabel = \"Hillshade_Noon\", ylabel = \"Hillshade_3pm\")\n\naxs[1, 0].scatter(train_data['Aspect'], train_data['Hillshade_3pm'], color='darkblue')\naxs[1, 0].scatter(Hillshade_test_data['Aspect'], Hillshade_test_data['Hillshade_3pm'], color='maroon')\naxs[1, 0].set(title = 'Aspect And Hillshade_3pm', xlabel = \"Aspect\", ylabel = \"Hillshade_3pm\")\n\naxs[1, 1].scatter(train_data['Slope'], train_data['Hillshade_3pm'], color='darkblue')\naxs[1, 1].scatter(Hillshade_test_data['Slope'], Hillshade_test_data['Hillshade_3pm'], color='maroon')\naxs[1, 1].set(title = 'Slope And Hillshade_3pm', xlabel = \"Slope\", ylabel = \"Hillshade_3pm\")\n\nplt.show()","3fa3a147":"# Se reemplazan los zero de \"Hillshade_3pm\" en train_data \ntrain_data.loc[(train_data[\"Hillshade_3pm\"] == 0),\"Hillshade_3pm\"]=lr.predict(Hillshade_test_data[['Hillshade_9am', 'Hillshade_Noon', 'Aspect', 'Slope']])","23b8da0f":"fig, axs = plt.subplots(2, 2, sharey=True, figsize = (20,15))\n\naxs[0, 0].scatter(train_data['Hillshade_9am'], train_data['Hillshade_3pm'], color='darkblue')\naxs[0, 0].scatter(Hillshade_test_data['Hillshade_9am'], Hillshade_test_data['Hillshade_3pm'], color='maroon')\naxs[0, 0].set(title = 'Hillshade_9am And Hillshade_3pm', xlabel = \"Hillshade_9am\", ylabel = \"Hillshade_3pm\")\n\naxs[0, 1].scatter(train_data['Hillshade_Noon'], train_data['Hillshade_3pm'], color='darkblue')\naxs[0, 1].scatter(Hillshade_test_data['Hillshade_Noon'], Hillshade_test_data['Hillshade_3pm'], color='maroon')\naxs[0, 1].set(title = 'Hillshade_Noon And Hillshade_3pm', xlabel = \"Hillshade_Noon\", ylabel = \"Hillshade_3pm\")\n\naxs[1, 0].scatter(train_data['Aspect'], train_data['Hillshade_3pm'], color='darkblue')\naxs[1, 0].scatter(Hillshade_test_data['Aspect'], Hillshade_test_data['Hillshade_3pm'], color='maroon')\naxs[1, 0].set(title = 'Aspect And Hillshade_3pm', xlabel = \"Aspect\", ylabel = \"Hillshade_3pm\")\n\naxs[1, 1].scatter(train_data['Slope'], train_data['Hillshade_3pm'], color='darkblue')\naxs[1, 1].scatter(Hillshade_test_data['Slope'], Hillshade_test_data['Hillshade_3pm'], color='maroon')\naxs[1, 1].set(title = 'Slope And Hillshade_3pm', xlabel = \"Slope\", ylabel = \"Hillshade_3pm\")\n\nplt.show()","5222fdd8":"train_data.plot(kind='scatter', x='Aspect', y='Hillshade_9am', alpha=0.5, color='maroon', figsize = (12,9))\nplt.title('Aspect And Hillshade_9am')\nplt.xlabel(\"Aspect\")\nplt.ylabel(\"Hillshade_9am\")\nplt.show()","d5942a86":"train_data.plot(kind='scatter', y='Hillshade_Noon', x='Slope', alpha=0.5, color='darkblue', figsize = (12,9))\nplt.title('Hillshade_Noon And Slope')\nplt.ylabel(\"Hillshade_Noon\")\nplt.xlabel(\"Slope\")\nplt.show()","ad03cae1":"import plotly.graph_objs as go\nfrom plotly.offline import iplot\n\n\ntrace1 = go.Box(\n    y=train_data[\"Vertical_Distance_To_Hydrology\"],\n    name = 'Vertical Distance',\n    marker = dict(color = 'rgb(0,145,119)')\n)\ntrace2 = go.Box(\n    y=train_data[\"Horizontal_Distance_To_Hydrology\"],\n    name = 'Horizontal Distance',\n    marker = dict(color = 'rgb(5, 79, 174)')\n)\n\ndata = [trace1, trace2]\nlayout = dict(autosize=False, width=700,height=500, title='Distance To Hydrology', paper_bgcolor='rgb(243, 243, 243)', \n              plot_bgcolor='rgb(243, 243, 243)', margin=dict(l=40,r=30,b=80,t=100,))\nfig = dict(data=data, layout=layout)\niplot(fig)\n","47baf92c":"f,ax=plt.subplots(1,2,figsize=(15,7))\ntrain_data.Vertical_Distance_To_Hydrology.plot.hist(ax=ax[0],bins=30,edgecolor='black',color='crimson')\nax[0].set_title('Vertical Distance To Hydrology')\nx1=list(range(-150,350,50))\nax[0].set_xticks(x1)\ntrain_data.Horizontal_Distance_To_Hydrology.plot.hist(ax=ax[1],bins=30,edgecolor='black',color='darkmagenta')\nax[1].set_title('Horizontal Distance To Hydrology')\nx2=list(range(0,1000,100))\nax[1].set_xticks(x2)\nplt.show()","fbe493b8":"import plotly.graph_objs as go\nfrom plotly.offline import iplot\n\ntrace1 = go.Box(\n    y=train_data[\"Horizontal_Distance_To_Roadways\"],\n    name = 'Distance_To_Roadways',\n    marker = dict(color = 'rgb(0,145,119)')\n)\ntrace2 = go.Box(\n    y=train_data[\"Horizontal_Distance_To_Fire_Points\"],\n    name = 'Distance_To_Fire_Points',\n    marker = dict(color = 'rgb(5, 79, 174)')\n)\n\ndata = [trace1, trace2]\nlayout = dict(autosize=False, width=700,height=500, title='Other Distances', paper_bgcolor='rgb(243, 243, 243)', \n              plot_bgcolor='rgb(243, 243, 243)', margin=dict(l=40,r=30,b=80,t=100,))\nfig = dict(data=data, layout=layout)\niplot(fig)","8d598377":"f,ax=plt.subplots(1,2,figsize=(15,7))\ntrain_data.Horizontal_Distance_To_Roadways.plot.hist(ax=ax[0],bins=30,edgecolor='black',color='crimson')\nax[0].set_title('Horizontal_Distance_To_Roadways')\nx1=list(range(0,7000,500))\nax[0].set_xticks(x1)\n\ntrain_data.Horizontal_Distance_To_Fire_Points.plot.hist(ax=ax[1],bins=30,edgecolor='black',color='darkmagenta')\nax[1].set_title('Horizontal_Distance_To_Fire_Points')\nx2=list(range(0,7000,500))\nax[1].set_xticks(x2)\nplt.show()","c20b3082":"print(train_data.shape)\n# Suppression of outliers\n# values 0 in Hillshade_3pm and in \u00bfAspect?\n#Type 7 (0), Type 8 (1), Type 15 (0) and Type 25 (1) have either no or too few values.\n# Type 9 (10), type 28 (9), type 36 (10),\n# type 21 (16) type 27 (15), type 34 (22), type 37 (34)\n\n#reduce_train_data=train_data[(train_data[\"Horizontal_Distance_To_Hydrology\"]<750) \n#                             & (train_data[\"Vertical_Distance_To_Hydrology\"]<250)\n#                             & (train_data[\"Horizontal_Distance_To_Roadways\"] < 5500)\n#                             & (train_data[\"Horizontal_Distance_To_Fire_Points\"]<4500)\n#                             & (train_data['Hillshade_3pm']!=0)\n#                            ]\n\n#reduce_train_data=train_data[(train_data['Hillshade_3pm']!=0)\n#                            ]\n\n#print(reduce_train_data.shape)","93eb1896":"train_data.Soil_Type21.value_counts()","674ddfe6":"train_data[train_data[\"Soil_Type21\"]==1].Cover_Type.value_counts()","28a27ea1":"train_data.columns","76c24a7c":"# Create target object and call it y\ny = train_data.Cover_Type\n# Create X with all columns as a first asumption\n#X = train_data.drop(['Cover_Type'], axis=1)\n#dropped_columns=['Hillshade_3pm','Soil_Type7','Soil_Type8','Soil_Type9','Soil_Type15','Soil_Type21','Soil_Type25','Soil_Type27','Soil_Type28','Soil_Type34','Soil_Type36','Soil_Type37']\ndropped_columns=['Soil_Type7','Soil_Type8','Soil_Type9','Soil_Type15','Soil_Type25', 'Soil_Type28','Soil_Type36', 'Hillshade_9am', 'Hillshade_Noon','Hillshade_3pm', 'Vertical_Distance_To_Hydrology']\n#dropped_columns=['Soil_Type7','Soil_Type8','Soil_Type15','Soil_Type25']\nX = train_data.drop(dropped_columns+['Cover_Type'], axis=1)","7d02410f":"f,ax=plt.subplots(1,2,figsize=(15,7))\ntrain_data.Hillshade_3pm.plot.hist(ax=ax[0],bins=30,edgecolor='black',color='crimson')\nax[0].set_title('Hillshade_3pm')\nx1=list(range(0,300,20))\nax[0].set_xticks(x1)\ntrain_data.Aspect.plot.hist(ax=ax[1],bins=30,edgecolor='black',color='darkmagenta')\nax[1].set_title('Aspect')\nx2=list(range(0,100,20))\nax[1].set_xticks(x2)\nplt.show()","f92d0b13":"import plotly.express as px\ncover_type = train_data[\"Cover_Type\"].value_counts()\ndf_cover_type = pd.DataFrame({'CoverType': cover_type.index, 'Total':cover_type.values})\n\nfig = px.bar(df_cover_type, x='CoverType', y='Total', height=400, width=650)\nfig.show()","46275b13":"import pandas_profiling as pp\n#report = pp.ProfileReport(train_data)\n#report.to_file(\"report.html\")\n\n#report","6559c8d7":"from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold\nkf = KFold(n_splits=5, shuffle = True ,random_state=1)\n\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=2)","5de67e0e":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, roc_curve,confusion_matrix\n\n# First test with all features and random forest\n# Define the model. Set random_state to 1\nrf_scores={}\n#for n in [100]:\n#    rf_model = RandomForestClassifier(n_estimators=n, random_state=1)\n#    rf_model.fit(train_X, train_y)\n#    rf_val_predictions = rf_model.predict(val_X)\n#    rf_acc = accuracy_score(val_y, rf_val_predictions)\n    #print (rf_acc)\n#    rf_scores[n] = rf_acc\n\n#print(rf_scores)\n\n#rf_mat = confusion_matrix(val_y, rf_val_predictions)\n#print (rf_mat)\n\n\n#kf = KFold(n_splits=5, shuffle = True ,random_state=1)\n#precisions = cross_val_score(rf_model, train_X, train_y, cv=kf, n_jobs=1, scoring = 'precision',verbose = 0)\n#recalls = cross_val_score(rf_model, train_X, train_y, cv=kf, n_jobs=1, scoring = 'recall',verbose = 0)\n\n#print('recall = %f, precision = %f' %(recalls.mean(), precisions.mean()))\n","49a57386":"# second test with all features and Gradient Boosting\n# Define the model. Set random_state to 1\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n#for n in [800,1000,1200]:\n#    gb_model = XGBClassifier(n_estimators=n, random_state=1)\n#    gb_model.fit(train_X, train_y)\n#    gb_val_predictions = gb_model.predict(val_X)\n\n#    gb_acc = accuracy_score(val_y, gb_val_predictions)\n#    print (gb_acc)\n\n#gb_model.fit(train_X, train_y,\n#             early_stopping_rounds=5, \n#             eval_set=[(val_X, val_y)],\n#             verbose=False)\n\n\n#print('')\n\n#gb_mat = confusion_matrix(val_y, gb_val_predictions)\n#print (gb_mat)","7b24b0cd":"#third test\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n\ndef evaluar_rendimiento(modelo, nombre):\n    s = cross_val_score(modelo, X, y, cv=kf, n_jobs=-1)\n    print(\"Rendimiento de {}:\\t{:0.3} \u00b1 {:0.3}\".format( \\\n        nombre, s.mean().round(3), s.std().round(3)))\n    \n    \ndt = DecisionTreeClassifier(class_weight='balanced')\n\n#evaluar_rendimiento(dt,\"\u00c1rbol de decisi\u00f3n\")\n","8f8bd344":"bdt = BaggingClassifier(DecisionTreeClassifier())\nrf = RandomForestClassifier(class_weight='balanced')\net = ExtraTreesClassifier(class_weight='balanced')\n\n#evaluar_rendimiento(dt,  \"\u00c1rbol de decisi\u00f3n\")\n#evaluar_rendimiento(bdt, \"Bagging AD\")\n#evaluar_rendimiento(rf,  \"Random Forest\")\n#evaluar_rendimiento(et,  \"Extra Trees\")","8a7b90ce":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nparam_trees = {'n_estimators': [100, 150, 200, 250, 300], \n               #'max_features': ['auto', 'sqrt'], \n               'max_features': [32, 36, 40, 42],\n               'max_depth': [75, 100, 150, 200], \n               'min_samples_split' : [2],\n               'min_samples_leaf':[1]}\n\nrf = ExtraTreesClassifier(class_weight='balanced')\nkf = StratifiedKFold(n_splits=4, shuffle=True)\n\n#grid_search_rf = GridSearchCV(rf, param_grid=param_trees, cv=kf, verbose=1, n_jobs=-1)\n#grid_search_et = RandomizedSearchCV(estimator = rf, \n#                                    param_distributions = param_trees, \n#                                    n_iter = 10, \n#                                    cv = kf, \n#                                    verbose=1, \n#                                    random_state=2, \n#                                    n_jobs = -1, \n#                                    scoring = 'accuracy')\n\n#grid_search_rf.fit(X, y)\n","4714d639":"#grid_search_rf.best_estimator_","22370c79":"#grid_search_rf.best_score_","8ff3ae0b":"from sklearn.model_selection import cross_val_score\n\n#rf_model = ExtraTreesClassifier(n_estimators=100, max_features=48, max_depth=100, min_samples_leaf =1, random_state=2) # 0.8758597883597884 \/ \nrf_model = ExtraTreesClassifier(n_estimators=250, max_features=32, max_depth=150, min_samples_leaf =1, random_state=2) # 0.8766534391534392 ==> 0.78071\n#rf_model = ExtraTreesClassifier(n_estimators=300, max_features=40, max_depth=100, min_samples_leaf =1, random_state=2) # 0.875462962962963\n#rf_model = ExtraTreesClassifier(n_estimators=200, max_features=30, max_depth=200, min_samples_leaf =1, random_state=2) #0.8752645502645503\n#rf_model = ExtraTreesClassifier(n_estimators=100, max_features=44, max_depth=75, min_samples_leaf =1, random_state=2) # 0.8767195767195767 => 0.77934\n\n#rf_model = RandomForestClassifier(n_estimators = 719, max_features = 0.3, max_depth = 464, min_samples_split = 2,min_samples_leaf = 1,bootstrap = False, random_state=2) # 0.8712962962962962\n#rf_model = ExtraTreesClassifier(n_estimators = 719, max_features = 0.3, max_depth = 464, min_samples_split = 2,min_samples_leaf = 1,bootstrap = False, random_state=2) # 0.8732804232804232\n\n#rf_model.fit(train_X, train_y)\n#rf_val_predictions = rf_model.predict(val_X)\n#rf_acc = accuracy_score(val_y, rf_val_predictions)\n#print (rf_acc)\n\nscores = cross_val_score(rf_model, X, y, cv=kf,scoring='accuracy')\nprint (scores)\n\nprint(\"Average accuracy:\")\nprint(scores.mean())","f44d6b90":"model = ExtraTreesClassifier(n_estimators=250, max_features=32, max_depth=150, min_samples_leaf =1, random_state=2)\nmodel.fit(X, y)\n","84d48b9c":"test_data = pd.read_csv(\"..\/input\/learn-together\/test.csv\",index_col='Id')\ntest_data.sample(5)","9e4df19f":"print(test_data.loc[(test_data[\"Hillshade_3pm\"] == 0)].shape)\n# Se reemplazan los zero de \"Hillshade_3pm\" en test_data \ntest_data.loc[(test_data[\"Hillshade_3pm\"] == 0),\"Hillshade_3pm\"]=lr.predict(test_data.loc[(test_data[\"Hillshade_3pm\"] == 0),['Hillshade_9am', 'Hillshade_Noon', 'Aspect', 'Slope']])\n\nprint(test_data.loc[(test_data[\"Hillshade_3pm\"] == 0)].shape)","1086bfd4":"test_X = test_data.drop(dropped_columns, axis=1)\ntest_X.shape","42217f8f":"# make predictions which we will submit. \ntest_preds = model.predict(test_X)\n\nprint(test_preds[0:10])\n\noutput = pd.DataFrame({'ID': test_data.index,\n                       'Cover_Type': test_preds})\noutput.to_csv('submission.csv', index=False)\n\n#print(pd.read_csv('submission.csv'))","b05c1c0f":"Seems fair enough to replace data:\n- LinearRegression = 0.9971013929249446\n- LassoCV = 0.9971023521834418\n- RidgeCV = 0.9862335843760185","c6380183":"0 values for Hillshade_3pm seems not to be normal\nI want to calcul them again with Hillshade_9am + Hillshade_Noon + Aspect + Slope that seems more correlated\nLinear regresion should be enough","82b9727c":"Accuracy for Random Forest = 84% but 0.66804 with test data\n\nAccuracy for Random Forest (n_estimators=100)= 87% but 0.71640 with test data\n\nAccuracy 3 for RF = 87,46% but 0.72547\n\nAccuracy for for Gradient Boosting = 77% but 0.57182 with test data\n\nLast test with training without outlier + extratrees : 0.8796513803260984\n0.8804350600657148 => 0.74336\n\n0.8798692682989674 => 0.76282\n\n0.8810834899281861 => 0.76180","2490e25c":"0.8797619047619047\n0.8767195767195768","84df0083":"To perform EDA I've used very usefull notebook \"**Quick Visualization and Eda for Beginners\" from Fatih Bilgin**.","96be1682":"there is no missing values"}}