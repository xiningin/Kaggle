{"cell_type":{"aaff42c1":"code","2b61e110":"code","dc0f62c8":"code","f2a356e3":"code","d83f1d43":"code","5f3b9eb8":"code","b0151144":"code","c2f36b52":"code","349aa4e5":"code","1565bafb":"code","e5e7d564":"code","ef521a4a":"code","b5a4bb0e":"code","93e009a0":"code","d832659e":"code","0035485b":"code","38c439eb":"code","16c5c31e":"code","62bbedbe":"code","cc5dd439":"code","1e035242":"code","5f77da06":"code","35683b72":"code","25c2c845":"code","16c4a6fd":"code","1fd78953":"code","8f1a4bec":"code","a405ddb2":"code","d4d18fa4":"code","6e515c1c":"code","16bf9f52":"code","d085c9e8":"code","a61ccf83":"code","66ca8c44":"code","5b86be36":"code","a498f615":"code","971c5e7f":"code","3a95f8ed":"code","a6384418":"code","520b9895":"code","32042e99":"code","cd77fd4d":"code","2d00767f":"code","576e615d":"code","164bd2d7":"code","dba21f51":"code","cb647c51":"code","a95ae482":"code","6fe4ce1d":"code","a4af29c8":"code","ec6ce360":"code","2bf33f05":"markdown","435415be":"markdown","04ced9cd":"markdown","7b3d49df":"markdown","b24466d1":"markdown","80cea230":"markdown","8fb6450b":"markdown","c2eed39e":"markdown","28747668":"markdown","b00c99b1":"markdown","89b80a26":"markdown","4d2f122e":"markdown","d8fee4a1":"markdown","7ff57713":"markdown","39ed46c1":"markdown","998ec0e8":"markdown","e165475f":"markdown","bc15d7c1":"markdown","03563ed1":"markdown","27e090dc":"markdown","0886b816":"markdown","8ed5d263":"markdown","6a6116e2":"markdown","1ae8551c":"markdown","f34f71d3":"markdown","94bf9154":"markdown","a940e4a2":"markdown","43259c73":"markdown","eff5dbda":"markdown","2873bda9":"markdown","1a23a432":"markdown"},"source":{"aaff42c1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","2b61e110":"train_data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","dc0f62c8":"train_data","f2a356e3":"train_house_id = train_data['Id']\ntest_house_id = test_data['Id']\ntrain_data = train_data.drop(columns=['Id'])\ntest_data = test_data.drop(columns=['Id'])","d83f1d43":"non_numerical_features = ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n                          'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n                          'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd',\n                          'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n                          'BsmtExposure', 'BsmtFinType1', 'Heating', 'BsmtFinType2', 'HeatingQC',\n                          'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu',\n                          'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive',\n                          'PoolQC', 'Fence', 'SaleType', 'SaleCondition', 'MiscFeature']\n\ncontinuous_features = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1',\n                       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n                       'GrLivArea', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n                       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']","5f3b9eb8":"sns.distplot(train_data['SalePrice'])","b0151144":"correlation = train_data.corr()\nsns.heatmap(correlation)","c2f36b52":"sns.barplot(x=correlation['SalePrice'], y=correlation['SalePrice'].keys(), orient='h')","349aa4e5":"correlation['SalePrice']","1565bafb":"index = 0\nfor feature in non_numerical_features:\n    for key in train_data[feature].value_counts().keys():\n        train_data[feature] = train_data[feature].replace(key, index)\n        index += 1\n    index = 0\n\nfor feature in non_numerical_features:\n    for key in test_data[feature].value_counts().keys():\n        test_data[feature] = test_data[feature].replace(key, index)\n        index += 1\n    index = 0","e5e7d564":"train_data.info()","ef521a4a":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer","b5a4bb0e":"train_data","93e009a0":"train_data.loc[:, 'MSSubClass':'SaleCondition'] = IterativeImputer().fit_transform(train_data.loc[:, 'MSSubClass':'SaleCondition'])\ntest_data.loc[:, 'MSSubClass':'SaleCondition'] = IterativeImputer().fit_transform(test_data.loc[:, 'MSSubClass':'SaleCondition'])","d832659e":"train_data","0035485b":"from sklearn.preprocessing import MinMaxScaler","38c439eb":"normalizer = MinMaxScaler(feature_range=(0, 1))\ntrain_data[continuous_features] = normalizer.fit_transform(train_data[continuous_features])","16c5c31e":"train_data","62bbedbe":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score","cc5dd439":"X = train_data.loc[:, 'MSSubClass':'SaleCondition']\ny = train_data.loc[:, 'SalePrice']","1e035242":"linear = LinearRegression()\nlinear_predicted = cross_val_score(linear, X, y, cv=10, scoring='r2')\nprint(f'LinearRegression: {linear_predicted.mean()}')","5f77da06":"from sklearn.ensemble import GradientBoostingRegressor","35683b72":"gbr = GradientBoostingRegressor(n_estimators=500, alpha=0.9)\ngbr_predicted = cross_val_score(gbr, X, y, cv=10, scoring='r2')","25c2c845":"gbr_predicted.mean()","16c4a6fd":"from sklearn.tree import DecisionTreeRegressor","1fd78953":"dtr = DecisionTreeRegressor(max_depth=7)\ndtr_predicted = cross_val_score(dtr, X, y, cv=10, scoring='r2')","8f1a4bec":"dtr_predicted.mean()","a405ddb2":"from sklearn.ensemble import RandomForestRegressor","d4d18fa4":"rfr = RandomForestRegressor(n_estimators=700)\nrfr_predicted = cross_val_score(rfr, X, y, cv=10, scoring='r2')","6e515c1c":"rfr_predicted.mean()","16bf9f52":"from sklearn.linear_model import Lasso","d085c9e8":"lr = Lasso(max_iter=10000)\nlr_predicted = cross_val_score(lr, X, y, cv=10, scoring='r2')","a61ccf83":"lr_predicted.mean()","66ca8c44":"from sklearn.linear_model import Ridge","5b86be36":"rr = Ridge(max_iter=10000)\nrr_predicted = cross_val_score(rr, X, y, cv=10, scoring='r2')","a498f615":"rr_predicted.mean()","971c5e7f":"from sklearn.svm import SVR","3a95f8ed":"svr = SVR(kernel='linear', C=500)\nsvr_predicted = cross_val_score(svr, X, y, cv=10, scoring='r2')","a6384418":"svr_predicted.mean()","520b9895":"from sklearn.neural_network import MLPRegressor","32042e99":"mlp = MLPRegressor(hidden_layer_sizes=(500, 500), activation='relu', max_iter=3000)\nmlp_predicted = cross_val_score(mlp, X, y, cv=10, scoring='r2')","cd77fd4d":"mlp_predicted.mean()","2d00767f":"x = ['LR', 'GB', 'DT', 'RF', 'LASSO', 'Ridge', 'SVR', 'NN']\nheight = [linear_predicted.mean(), gbr_predicted.mean(), dtr_predicted.mean(), rfr_predicted.mean(), lr_predicted.mean(), rr_predicted.mean(), svr_predicted.mean(), mlp_predicted.mean()]\ncolor = ['black', 'red', 'blue', 'purple', 'orange', 'brown', 'green', 'pink']\n\nplt.xlabel('Techniques')\nplt.ylabel('Accuracy')\nplt.bar(x=x, height=height, color=color)\nplt.show()","576e615d":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score","164bd2d7":"X = train_data.loc[:, 'MSSubClass':'SaleCondition']\ny = train_data.loc[:, 'SalePrice']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)","dba21f51":"gbr = GradientBoostingRegressor(n_estimators=500, alpha=0.9)\ngbr.fit(X_train, y_train)\npredicted = gbr.predict(X_test)","cb647c51":"x = range(len(y_test))\nplt.scatter(x, y_test, color='red')\nplt.ylabel('SalePrice')\nplt.plot(x, predicted, 'k--')\nplt.legend(['Predicted', 'True'])\nplt.show()\nprint(f'R-Squared: {r2_score(y_test, predicted)}')","a95ae482":"X_for_test = train_data.loc[:, 'MSSubClass':'SaleCondition']\ny_for_test = train_data.loc[:, 'SalePrice']\n\ngbr = GradientBoostingRegressor(n_estimators=500, alpha=0.9)\ngbr.fit(X_for_test, y_for_test)\n\npredicted = gbr.predict(test_data)","6fe4ce1d":"plt.title('Unseen_Data')\nplt.xlabel('House_ID')\nplt.ylabel('SalePrice')\nplt.scatter(test_house_id, predicted, color='blue')\nplt.show()","a4af29c8":"sub = pd.DataFrame({\n    'Id':test_house_id,\n    'SalePrice':predicted\n})","ec6ce360":"sub.to_csv('sample_submission.csv', index=False)\nprint('File Saved!')","2bf33f05":"### Label-Encoding","435415be":"If you enjoy this notebook or that was useful, please up-vote me!\nThanks.","04ced9cd":"### NeuralNetwork","7b3d49df":"### Distribution\/Relationship","b24466d1":"In this implementation, I tried to explain everything for beginners and use the most of machine learning techniques, like:\nLinearRegression\nGradientBoosting\nNeuralNetwork\netc.","80cea230":"### Dealing with missing-values","8fb6450b":"### SVR","c2eed39e":"### Ridge","28747668":"feature 'Id' is unique, so we drop it...","b00c99b1":"### Unseen-Data prediction","89b80a26":"### Normalization","4d2f122e":"### Cross-Validation","d8fee4a1":"I tried to encode labels without functions like 'LabelEncoder'. Because I can control values easier...","7ff57713":"![](https:\/\/i.stack.imgur.com\/xb1VY.png)\n\nBest value: 1 (It can be negative)","39ed46c1":"I tried different neural networks. Finally I chosed 2 hiddenlayers + 500 neurons inside each of them...","998ec0e8":"### Implementation","e165475f":"### GradientBoosting","bc15d7c1":"At first, we import 'Pandas' library that we need to load data:","03563ed1":"### RandomForest","27e090dc":"Now you can see the correlation between 'SalePrice' and other features.","0886b816":"### LinearRegression","8ed5d263":"For importing 'IterativeImputer', we need to import 'enable_iterative_imputer' at first:","6a6116e2":"### Visualization","1ae8551c":"Now we're ready to use machine learning algorithms","f34f71d3":"'SalePrice' is like normal-distribution!","94bf9154":"At this step, we use cross_val_score to get R-Squared score.\n'cv' is 10, so 'K' is 10 in KFold Cross-Validation","a940e4a2":"### DecisionTree","43259c73":"### LASSO","eff5dbda":"As you can see, GradientBoosing have the highest accuracy (R-Squared score).","2873bda9":"As you can see, we have many features that aren't full, so we can't drop them.\nBecause if we try to drop them, our power of model will reduce.\n\nBut we have two solutions:\n1.Using Mean-Mode values\n2.Using 'IterativeImputer' to predict all of the features by others.\n\nWI tried solution 1, but accuracy score was low. So we'll use solution 2.","1a23a432":"### Introduction"}}