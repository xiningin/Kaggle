{"cell_type":{"8765693f":"code","3d264d4e":"code","a0f4841b":"code","8f744e41":"code","4c7636ca":"code","d0a24a13":"code","1f089851":"code","b4895460":"code","6f390103":"code","31c89df9":"code","df547820":"code","cef914c2":"code","1c9b96e8":"code","478f8c6d":"code","5204e656":"code","6b5312c8":"code","e660df21":"code","83e37cc7":"markdown","8c6dc982":"markdown","fa958d2d":"markdown","17c04497":"markdown","10558f2c":"markdown","34006a0d":"markdown","64315d9a":"markdown","47363235":"markdown","e854cecb":"markdown","404cd683":"markdown","06aca962":"markdown"},"source":{"8765693f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3d264d4e":"import warnings\nwarnings.simplefilter('ignore')\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nfrom pprint import pprint\nfrom datetime import datetime\nimport collections\nimport re\n\nimport nltk\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('wordnet')\nfrom nltk.corpus import wordnet, stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\n\nfrom wordcloud import WordCloud","a0f4841b":"file_name = '..\/input\/stock-markettweets-lexicon-data\/tweets_labelled_09042020_16072020.csv'\ndata = pd.read_csv(file_name, sep=';').set_index('id')\ndata.shape","8f744e41":"data.head()","4c7636ca":"for i in range(5):\n    pprint(data.iat[i,1])","d0a24a13":"ticker_pattern = re.compile(r'(^\\$[A-Z]+|^\\$ES_F)')\nht_pattern = re.compile(r'#\\w+')\n\nticker_dic = collections.defaultdict(int)\nht_dic = collections.defaultdict(int)\n\nfor text in data['text']:\n    for word in text.split():\n        if ticker_pattern.fullmatch(word) is not None:\n            ticker_dic[word[1:]] += 1\n        \n        word = word.lower()\n        if ht_pattern.fullmatch(word) is not None:\n            ht_dic[word] += 1","1f089851":"ticker_df = pd.DataFrame.from_dict(\n    ticker_dic, orient='index').rename(columns={0:'count'})\\\n    .sort_values('count', ascending=False).head(20)\n    \nht_df = pd.DataFrame.from_dict(\n    ht_dic, orient='index').rename(columns={0:'count'})\\\n    .sort_values('count', ascending=False).head(20)\n\nfig, ax = plt.subplots(1, 2, figsize=(12,8))\nplt.suptitle('Frequent Tickers and Hashtags', fontsize=16)\nplt.subplots_adjust(wspace=0.4)\n\nsns.barplot(x=ticker_df['count'], y=ticker_df.index, orient='h', ax=ax[0])\nax[0].set_title('Top 20 Tickers')\n\nsns.barplot(x=ht_df['count'], y=ht_df.index, orient='h', ax=ax[1])\nax[1].set_title('Top 20 HashTags')\n\nplt.show()","b4895460":"charonly = re.compile(r'[^a-zA-Z\\s]')\nhandle_pattern = re.compile(r'@\\w+')\nemoji_pattern = re.compile(\"[\"\n                        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                        u\"\\U00002702-\\U000027B0\"\n                        u\"\\U000024C2-\\U0001F251\"\n                        \"]+\", flags=re.UNICODE)\nurl_pattern = re.compile(\n    'http[s]?:\/\/(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\npic_pattern = re.compile('pic\\.twitter\\.com\/.{10}')\nspecial_code = re.compile(r'(&amp;|&gt;|&lt;)')\ntag_pattern = re.compile(r'<.*?>')\n\nSTOPWORDS = set(stopwords.words('english')).union(\n    {'rt', 'retweet', 'RT', 'Retweet', 'RETWEET'})\n\nlemmatizer = WordNetLemmatizer()\n\ndef hashtag(phrase):\n    return ht_pattern.sub(' ', phrase)\n\ndef remove_ticker(phrase):\n    return ticker_pattern.sub('', phrase)\n    \ndef specialcode(phrase):\n    return special_code.sub(' ', phrase)\n\ndef emoji(phrase):\n    return emoji_pattern.sub(' ', phrase)\n\ndef url(phrase):\n    return url_pattern.sub('', phrase)\n\ndef pic(phrase):\n    return pic_pattern.sub('', phrase)\n\ndef html_tag(phrase):\n    return tag_pattern.sub(' ', phrase)\n\ndef handle(phrase):\n    return handle_pattern.sub('', phrase)\n\ndef decontracted(phrase):\n    # specific\n    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n    \n    # DIS, ticker symbol of Disney, is interpreted as the plural of \"DI\" \n    # in WordCloud, so I converted it to Disney\n    phrase = re.sub('DIS', 'Disney', phrase)\n\n    # general\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"(he|He)\\'s\", \"he is\", phrase)\n    phrase = re.sub(r\"(she|She)\\'s\", \"she is\", phrase)\n    phrase = re.sub(r\"(it|It)\\'s\", \"it is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"(\\'ve|has)\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    return phrase\n\ndef onlychar(phrase):\n    return charonly.sub('', phrase)\n\ndef remove_stopwords(phrase):\n    return \" \".join([word for word in str(phrase).split()\\\n                     if word not in STOPWORDS])\n\ndef tokenize_stem(phrase):   \n    tokens = word_tokenize(phrase)\n    stem_words =[]\n    for token in tokens:\n        word = lemmatizer.lemmatize(token)\n        stem_words.append(word)        \n    buf = ' '.join(stem_words)    \n    return buf","6f390103":"def arrange_text(ds):\n    ds['text2'] = ds['text'].apply(emoji)\n    ds['text2'] = ds['text2'].apply(handle)\n    ds['text2'] = ds['text2'].apply(specialcode)\n    ds['text2'] = ds['text2'].apply(hashtag)\n    ds['text2'] = ds['text2'].apply(url)\n    ds['text2'] = ds['text2'].apply(pic)\n    ds['text2'] = ds['text2'].apply(html_tag)\n    ds['text2'] = ds['text2'].apply(onlychar)\n    ds['text2'] = ds['text2'].apply(decontracted)\n    ds['text2'] = ds['text2'].apply(onlychar)\n    ds['text2'] = ds['text2'].apply(tokenize_stem)\n    ds['text2'] = ds['text2'].apply(remove_stopwords)","31c89df9":"arrange_text(data)","df547820":"for i in range(5):\n    pprint(data.iat[i,3])","cef914c2":"words = ' '.join([text for text in data['text2']])\nwordcloud = WordCloud(\n    width=800, height=400, background_color='white', max_font_size=110)\\\n    .generate(words)\n\nplt.figure(figsize=(14, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.title('Words in all tweet\\n', fontsize=24)\nplt.axis('off')\nplt.show()","1c9b96e8":"not_ticker = [] # list of words except for Ticker\n\nfor text in data['text2']:\n    for word in text.split():\n        if word.upper() not in ticker_dic:\n            not_ticker.append(word)\n            \nwords = ' '.join([word for word in not_ticker])\nwordcloud = WordCloud(\n    width=800, height=400, background_color='white', max_font_size=110).\\\n    generate(words)\nplt.figure(figsize=(14, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.title('Words in all tweet without Ticker\\n', fontsize=24)\nplt.axis('off')\nplt.show()","478f8c6d":"def wordcloud_by_sentiment(sentiment):\n    not_ticker = []\n\n    for text in data[data['sentiment']==sentiment]['text2']:\n        for word in text.split():\n            if word.upper() not in ticker_dic:\n                not_ticker.append(word.lower())\n\n    words = ' '.join([word for word in not_ticker])\n    wordcloud = WordCloud(\n        width=800, height=400, background_color='white', max_font_size=110, max_words=100).\\\n        generate(words)\n    plt.figure(figsize=(14, 7))\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.title('Words in '+ sentiment.capitalize() + ' tweets\\n', fontsize=32)\n    plt.axis('off')\n    plt.show()","5204e656":"wordcloud_by_sentiment('positive')","6b5312c8":"wordcloud_by_sentiment('negative')","e660df21":"wordcloud_by_sentiment('neutral')","83e37cc7":"> \"DIS\", ticker of The Walt Disney Company, is interpreted as the plural of \"DI\" in WordCloud, so I converted it to \"Disney\"","8c6dc982":"### Too much Tickers!!  \n### So I created WordCloud without Ticker because the words that symbolize sentiment are not obvious.","fa958d2d":"\"buy\", \"bullish\", \"good\", \"higher\", \"rally\",...","17c04497":"## WordCloud","10558f2c":"## PreProccess for WordCloud  \n### * delete emoji, handle, URL,...\n### * lemmatize\n### * delete stop_word including 'RT'","34006a0d":"Updated 2021\/5\/11","64315d9a":"\"sell\", \"short\", \"loss\", \"lower\", \"bearish\", ...  \nParticularly noteworthy are the words in small fonts, such as \"volatility\", \"risk\", \"short interest\", \"covid\",...","47363235":"## Quick view of tweets","e854cecb":"Tweet texts contain some ticker symbols  \n> For exsample, $AMD in 5th row","404cd683":"### WordCloud by sentiment  \nTickers are excluded, hereafter.","06aca962":"## Quick view of preprocessed tweets"}}