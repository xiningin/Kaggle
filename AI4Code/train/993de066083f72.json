{"cell_type":{"44cc6174":"code","b1fa36ab":"code","1c7c9a9e":"code","6c34d4e4":"code","eed90e71":"code","1b21f0eb":"code","4f73dd9b":"code","a2f5b2c4":"code","9f36bb61":"code","b27d97aa":"code","ab326cc6":"code","b6feafc2":"code","3d8345f8":"code","5ad8e7c8":"code","724c229e":"code","dacf1bcf":"code","52eb8c75":"code","bc5715c1":"code","eead4f80":"markdown","70dc178e":"markdown","43ce927e":"markdown","ace5cc75":"markdown","d7aa9f22":"markdown","a6242832":"markdown","771ca17f":"markdown","6e63f86f":"markdown","6a9daa22":"markdown"},"source":{"44cc6174":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport altair as alt\nalt.renderers.enable('notebook')\nprint(os.listdir(\"..\/input\"))\nfrom IPython.display import HTML\n\n\n# The below is great for working but if you publish it, no charts show up.\n# The workaround in the next cell deals with this.\n#alt.renderers.enable('notebook')\n\nHTML(\"This code block contains import statements and setup.\")\n# Any results you write to the current directory are saved as output.","b1fa36ab":"## Dont worry about the code in this block. This is just the setup for showing Altair graphs in Kaggle Notebooks\n\n\nfrom  altair.vega import v3\nimport json\nfrom IPython.display import HTML\n\n\nvega_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega@' + v3.SCHEMA_VERSION\nvega_lib_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lib'\nvega_lite_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lite@' + alt.SCHEMA_VERSION\nvega_embed_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-embed@3'\nnoext = \"?noext\"\n\npaths = {\n    'vega': vega_url + noext,\n    'vega-lib': vega_lib_url + noext,\n    'vega-lite': vega_lite_url + noext,\n    'vega-embed': vega_embed_url + noext\n}\n\nworkaround = \"\"\"\nrequirejs.config({{\n    baseUrl: 'https:\/\/cdn.jsdelivr.net\/npm\/',\n    paths: {}\n}});\n\"\"\"\n\ndef add_autoincrement(render_func):\n    # Keep track of unique <div\/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n            \n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    chart_str = \"\"\"\n    <div id=\"{id}\"><\/div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"anything?\");\n    }});\n    console.log(\"really...anything?\");\n    <\/script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )\n\nHTML(\"\".join((\n    \"<script>\",\n    workaround.format(json.dumps(paths)),\n    \"<\/script>\",\n    \"This code block sets up embedded rendering in HTML output and<br\/>\",\n    \"provides the function `render(chart, id='vega-chart')` for use below.\"\n)))\n","1c7c9a9e":"#!pip install fbprophet","6c34d4e4":"from fbprophet import Prophet\n\n#!mkdir -p dataset\n#!wget -c -b http:\/\/www-personal.umich.edu\/~mejn\/cp\/data\/sunspots.txt -P dataset\ndata = pd.read_excel('..\/input\/wockhardt\/Pharma_orig Wockhardt.xlsx', header=0, index_col=0, parse_dates=True, squeeze=True)","eed90e71":"#!ls dataset\/","1b21f0eb":"# View the data as a table\ndata_as_frame = pd.DataFrame(data, columns=['Wockhardt', 'Day'])\ndata_as_frame.tail(10)","4f73dd9b":"data_as_frame['ds']=data_as_frame['Day'].astype(int)","a2f5b2c4":"data_as_frame.head()","9f36bb61":" data_as_frame['time_stamp']=data_as_frame.apply(lambda x:(pd.Timestamp('01-01-2008')+pd.DateOffset(days = int(x['ds']))),axis=1)","b27d97aa":"#Cleaning the df, we only need two columns date time and the data\nclean_df=data_as_frame.drop(['Day','ds'],axis=1)","ab326cc6":"clean_df.head()","b6feafc2":"render(alt.Chart(clean_df).mark_line(size=15, opacity=0.8, color = 'Orange').encode(\n        x='yearmonthdate(time_stamp):T',\n        y=alt.Y('Wockhardt', title='Wockhardt'),    \n        tooltip=['yearmonthdate(time_stamp)', 'Wockhardt']\n    ).interactive().properties(width=900, height=450,title='Wockhardt Stock Price')\\\n              .configure_title(fontSize=20))","3d8345f8":"## Prophet requires two columns, one is ds (the date time) and y (variable to be forecasted)\nclean_df.columns = ['y', 'ds']","5ad8e7c8":"def fit_predict_model(dataframe, interval_width = 0.99, changepoint_range = 0.99):\n    m = Prophet(daily_seasonality = False, yearly_seasonality = False, weekly_seasonality = False,\n                seasonality_mode = 'multiplicative', \n                interval_width = interval_width,\n                changepoint_range = changepoint_range)\n    m = m.fit(dataframe)\n    \n    forecast = m.predict(dataframe)\n    forecast['fact'] = dataframe['y'].reset_index(drop = True)\n    print('Displaying Prophet plot')\n    fig1 = m.plot(forecast)\n    return forecast\n    \npred = fit_predict_model(clean_df)\n","724c229e":"def detect_anomalies(forecast):\n    forecasted = forecast[['ds','trend', 'yhat', 'yhat_lower', 'yhat_upper', 'fact']].copy()\n    #forecast['fact'] = df['y']\n\n    forecasted['anomaly'] = 0\n    forecasted.loc[forecasted['fact'] > forecasted['yhat_upper'], 'anomaly'] = 1\n    forecasted.loc[forecasted['fact'] < forecasted['yhat_lower'], 'anomaly'] = -1\n\n    #anomaly importances\n    forecasted['importance'] = 0\n    forecasted.loc[forecasted['anomaly'] ==1, 'importance'] = \\\n        (forecasted['fact'] - forecasted['yhat_upper'])\/forecast['fact']\n    forecasted.loc[forecasted['anomaly'] ==-1, 'importance'] = \\\n        (forecasted['yhat_lower'] - forecasted['fact'])\/forecast['fact']\n    \n    return forecasted\n\npred = detect_anomalies(pred)","dacf1bcf":"pred.head()","52eb8c75":"pred[pred.anomaly == 1]","bc5715c1":"def plot_anomalies(forecasted):\n    interval = alt.Chart(forecasted).mark_area(interpolate=\"basis\", color = '#7FC97F').encode(\n    x=alt.X('ds:T',  title ='date'),\n    y='yhat_upper',\n    y2='yhat_lower',\n    tooltip=['yearmonthdate(ds)', 'fact', 'yhat_lower', 'yhat_upper']\n    ).interactive().properties(\n        title='Anomaly Detection'\n    )\n\n    fact = alt.Chart(forecasted[forecasted.anomaly==0]).mark_circle(size=15, opacity=0.7, color = 'Black').encode(\n        x='ds:T',\n        y=alt.Y('fact', title='Sunspots'),    \n        tooltip=['yearmonthdate(ds)', 'fact', 'yhat_lower', 'yhat_upper']\n    ).interactive()\n\n    anomalies = alt.Chart(forecasted[forecasted.anomaly!=0]).mark_circle(size=30, color = 'Red').encode(\n        x='ds:T',\n        y=alt.Y('fact', title='Sunspots'),    \n        tooltip=['yearmonthdate(ds)', 'fact', 'yhat_lower', 'yhat_upper'],\n        size = alt.Size( 'importance', legend=None)\n    ).interactive()\n\n    return render(alt.layer(interval, fact, anomalies)\\\n              .properties(width=870, height=450)\\\n              .configure_title(fontSize=20))\n              \nplot_anomalies(pred)","eead4f80":"## Lets Predict","70dc178e":"# Getting the data","43ce927e":"# Preparing data for modelling in Prophet","ace5cc75":"References:\n* http:\/\/www-personal.umich.edu\/~mejn\/cp\/programs.html\n* https:\/\/towardsdatascience.com\/anomaly-detection-time-series-4c661f6f165f\n* https:\/\/github.com\/altair-viz\/altair\/issues\/1270\n","d7aa9f22":"### Converting data to Pandas dataframe","a6242832":"## Lets view the data in graphical format","771ca17f":"# Detecting Anomalies:\n* The light blue boundaries in the above graph are yhat_upper and yhat_lower.\n* If y value is greater than yhat_upper and less than yhat lower then it is an anomaly.\n* Also getting the importance of that anomaly based on its distance from yhat_upper and yhat_lower.","6e63f86f":"# Plotting the anomalies for a better view","6a9daa22":"### Converting the months column in format acceptable for Prophet, starting from 1749 "}}