{"cell_type":{"dafb49f6":"code","1d5ddca0":"code","c8dea126":"code","ac69024a":"code","fd2ea63b":"code","6dd32d6c":"code","978b57d1":"code","885c6bae":"code","f17d0a3a":"code","6dd16a33":"code","64eefd63":"code","0514039e":"code","4cda4a8d":"code","3c603b61":"code","a0071445":"markdown","b11d384d":"markdown","cfad7b54":"markdown","08615881":"markdown"},"source":{"dafb49f6":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport matplotlib.gridspec as gridspec\nfrom matplotlib.patches import Rectangle\n\nimport os\nimport json\nimport time\nimport numpy as np\nfrom PIL import Image\nimport torch\nfrom tqdm import tqdm\nimport cv2\nimport sys\n\n# sys.path.append('\/kaggle\/input\/retinaface\/RetinaFace')\n# from retinaface import RetinaFace\n\n# sys.path.append('\/kaggle\/input\/yolov2face')\n# from yolov2 import load_mobilenetv2_224_075_detector, FaceDetector_yolo, get_boxes_points\n\n# sys.path.append('\/kaggle\/input\/s3fdface\/s3fd')\n# from detection.sfd import FaceDetector\n\nsys.path.append('\/kaggle\/input\/retinafacetorch')\nfrom retina import retinaface_model, detect_images","1d5ddca0":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nretinaface_model = retinaface_model(model_path='\/kaggle\/input\/retinafacetorch\/Resnet50_Final.pth',device=device)","c8dea126":"video_path = '\/kaggle\/input\/deepfake-detection-challenge\/train_sample_videos\/'","ac69024a":"# n_frames = 10\n# for vi in os.listdir(video_path):\n#     start = time.time()\n#     imgs = []\n    \n#     cap = cv2.VideoCapture(os.path.join(video_path, vi))\n#     v_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n#     video_length = 0\n#     for j in range(v_len):\n#         success = cap.grab()\n#         if success:\n#             video_length += 1\n#         else:\n#             break\n#     cap.release()\n\n#     sample = np.linspace(0, video_length-1, n_frames).astype(int)\n#     cap = cv2.VideoCapture(os.path.join(video_path, vi))\n#     for j in range(video_length):\n#         succ, image = cap.read()\n#         if j in sample and succ:\n#             # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n#             imgs.append(np.float32(image))\n#         if len(imgs) == n_frames:\n#             break\n#     if len(imgs) != 0:\n#         detect_images(imgs=imgs, net=retinaface_model, thresh=0.94, device=device)\n#         print(time.time()-start)","fd2ea63b":"def show_sequence(sequence, num_frames):\n    columns = 3\n    rows = (num_frames + 1) \/\/ (columns)\n    fig = plt.figure(figsize = (32,(16 \/\/ columns) * rows))\n    gs = gridspec.GridSpec(rows, columns)\n    for j in range(rows*columns):\n        plt.subplot(gs[j])\n        plt.axis(\"off\")\n        plt.imshow(sequence[j])\n\nsample_video = '\/kaggle\/input\/deepfake-detection-challenge\/train_sample_videos\/apatcsqejh.mp4'","6dd32d6c":"imgs = []\ncap = cv2.VideoCapture(sample_video)\nvideo_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\nsample = np.linspace(0, video_length-1, 9).astype(int)\nfor j in range(video_length):\n    success = cap.grab()\n    if j in sample:\n        success, image = cap.retrieve()\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if not success:\n            continue\n        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        imgs.append(image)\ncap.release()\nbboxes = detect_images(imgs=[np.float32(img) for img in imgs], net=retinaface_model, thresh=0.94, device=device)\npyretina_final_list = []\nred = (255,0,0)\nfor i in range(len(imgs)):\n    for b in bboxes[i]:\n        lx, ly, rx, ry = b[0], b[1], b[2], b[3]\n        cv2.rectangle(imgs[i], (int(round(lx)),int(round(ly))), (int(round(rx)), int(round(ry))), red, 2)\n    pyretina_final_list.append(imgs[i])\nshow_sequence(pyretina_final_list, 9)","978b57d1":"# retina_detector = RetinaFace('\/kaggle\/input\/retinaface\/RetinaFace\/models\/R50', 0, 0, 'net3')\n# for vi in os.listdir(video_path):\n#     start = time.time()\n#     imgs = []\n#     cap = cv2.VideoCapture(os.path.join(video_path, vi))\n#     video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n#     sample = np.linspace(0, video_length-1, 10).astype(int)\n#     for j in range(video_length):\n#         success = cap.grab()\n#         if j in sample:\n#             success, image = cap.retrieve()\n#             if not success:\n#                 continue\n#             # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n#             imgs.append(image)\n#     cap.release()\n#     thresh = 0.95\n#     scales = [1024, 1980]\n#     im_shape = imgs[0].shape\n#     target_size = scales[0]\n#     max_size = scales[1]\n#     im_size_min = np.min(im_shape[0:2])\n#     im_size_max = np.max(im_shape[0:2])\n#     #im_scale = 1.0\n#     #if im_size_min>target_size or im_size_max>max_size:\n#     im_scale = float(target_size) \/ float(im_size_min)\n#     # prevent bigger axis from being more than max_size:\n#     if np.round(im_scale * im_size_max) > max_size:\n#         im_scale = float(max_size) \/ float(im_size_max)\n#     scales = [im_scale]\n#     flip = False\n#     faces, _ = retina_detector.detect(imgs, thresh, scales=scales, do_flip=flip)\n#     print(len(faces))\n#     print(type(faces))\n#     print(faces)\n#     # print(faces)\n#     # print(time.time()-start)","885c6bae":"# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n# sfd_detector = FaceDetector(device=device, path_to_detector='\/kaggle\/input\/s3fdface\/s3fd\/s3fd-619a316812.pth', verbose=False)\n# for vi in os.listdir(video_path):\n#     start = time.time()\n#     imgs = []\n#     cap = cv2.VideoCapture(os.path.join(video_path, vi))\n#     video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n#     sample = np.linspace(0, video_length-1, 10).astype(int)\n#     for j in range(video_length):\n#         success = cap.grab()\n#         if j in sample:\n#             success, image = cap.retrieve()\n#             image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n#             if not success:\n#                 continue\n#             # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n#             imgs.append(image)\n#     cap.release()\n#     for im in imgs:\n#         detected_faces = sfd_detector.detect_from_image(im, rgb=True)\n#         # print(faces)\n#     print(time.time()-start)\n#     break","f17d0a3a":"# mobilenetv2 = load_mobilenetv2_224_075_detector(\"\/kaggle\/input\/yolov2face\/facedetection-mobilenetv2-size224-alpha0.75.h5\")\n# yolo_model = FaceDetector_yolo(mobilenetv2)\n# for vi in os.listdir(video_path):\n#     start = time.time()\n#     imgs = []\n#     cap = cv2.VideoCapture(os.path.join(video_path, vi))\n#     video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n#     sample = np.linspace(0, video_length-1, 10).astype(int)\n#     for j in range(video_length):\n#         success = cap.grab()\n#         if j in sample:\n#             success, image = cap.retrieve()\n#             image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n#             if not success:\n#                 continue\n#             # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n#             imgs.append(image)\n#     cap.release()\n#     for im in imgs:\n#         yolo_boxes = yolo_model.detect(im, 0.9)\n#         # print(faces)\n#     print(time.time()-start)\n#     break","6dd16a33":"# def show_sequence(sequence, num_frames):\n#     columns = 3\n#     rows = (num_frames + 1) \/\/ (columns)\n#     fig = plt.figure(figsize = (32,(16 \/\/ columns) * rows))\n#     gs = gridspec.GridSpec(rows, columns)\n#     for j in range(rows*columns):\n#         plt.subplot(gs[j])\n#         plt.axis(\"off\")\n#         plt.imshow(sequence[j])\n\n# sample_video = '\/kaggle\/input\/deepfake-detection-challenge\/train_sample_videos\/apatcsqejh.mp4'","64eefd63":"# imgs = []\n# cap = cv2.VideoCapture(sample_video)\n# video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n# sample = np.linspace(0, video_length-1, 9).astype(int)\n# for j in range(video_length):\n#     success = cap.grab()\n#     if j in sample:\n#         success, image = cap.retrieve()\n#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n#         if not success:\n#             continue\n#         # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n#         imgs.append(image)\n# cap.release()","0514039e":"# retina_detector = RetinaFace('\/kaggle\/input\/retinaface\/RetinaFace\/models\/R50', 0, -1, 'net3')\n# thresh = 0.94\n# scales = [1024, 1980]\n# im_shape = imgs[0].shape\n# target_size = scales[0]\n# max_size = scales[1]\n# im_size_min = np.min(im_shape[0:2])\n# im_size_max = np.max(im_shape[0:2])\n# #im_scale = 1.0\n# #if im_size_min>target_size or im_size_max>max_size:\n# im_scale = float(target_size) \/ float(im_size_min)\n# # prevent bigger axis from being more than max_size:\n# if np.round(im_scale * im_size_max) > max_size:\n#     im_scale = float(max_size) \/ float(im_size_max)\n# scales = [im_scale]\n# flip = False\n# retina_final_list = []\n# red = (255,0,0)\n# for im in imgs:\n#     faces, _ = retina_detector.detect(im, thresh, scales=scales, do_flip=flip)\n#     if faces is not None:\n#         for i in range(faces.shape[0]):\n#             box = faces[i].astype(np.int)\n#             lx, ly, rx, ry = box[0], box[1], box[2], box[3]\n#             cv2.rectangle(im, (int(round(lx)),int(round(ly))), (int(round(rx)), int(round(ry))), red, 2)\n#     retina_final_list.append(im)\n# show_sequence(retina_final_list, 9)","4cda4a8d":"# sfd_final_list = []\n# red = (255,0,0)\n# for im in imgs:\n#     detected_faces = sfd_detector.detect_from_image(im, rgb=True)\n#     for b in detected_faces:\n#         lx, ly, rx, ry, _ = b\n#         cv2.rectangle(im, (int(round(lx)),int(round(ly))), (int(round(rx)), int(round(ry))), red, 2)\n#     sfd_final_list.append(im)\n# show_sequence(sfd_final_list, 9)","3c603b61":"# mobilenetv2 = load_mobilenetv2_224_075_detector(\"\/kaggle\/input\/yolov2face\/facedetection-mobilenetv2-size224-alpha0.75.h5\")\n# yolo_model = FaceDetector_yolo(mobilenetv2)\n# yolo_final_list = []\n# red = (255,0,0)\n# for im in imgs:\n#     yolo_boxes = yolo_model.detect(im, 0.75)\n#     print(yolo_boxes)\n#     yb = get_boxes_points(yolo_boxes, im.shape) \n#     for b in yb:\n#         lx, ly, rx, ry = b\n#         cv2.rectangle(im, (int(round(lx)),int(round(ly))), (int(round(rx)), int(round(ry))), red, 2)\n#     yolo_final_list.append(im)\n# show_sequence(yolo_final_list, 9)","a0071445":"Visualization of the face detection results:","b11d384d":"RetinaFace speed test:","cfad7b54":"S3fdFace speed test:","08615881":"Yolo_v2 Face speed test:"}}