{"cell_type":{"851589c2":"code","53c76d60":"code","6d83288b":"code","a2cd5b40":"code","b30bbb6b":"code","655b7a00":"code","553144f6":"code","4955a099":"code","250e85de":"code","657d1350":"code","dea203e1":"code","27715d18":"code","0dc7deaf":"code","a9c434c6":"markdown","81604f6a":"markdown","4f382bae":"markdown","d7365b62":"markdown","398890de":"markdown","01a42222":"markdown","e3a6db1e":"markdown"},"source":{"851589c2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn, optim\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\n\nimport os\nprint(os.listdir(\"..\/input\/cell_images\/cell_images\/\"))","53c76d60":"# Define your transforms for the training, validation, and testing sets\ntrain_transforms = transforms.Compose([transforms.RandomRotation(30),\n                                       transforms.RandomResizedCrop(224),\n                                       transforms.RandomVerticalFlip(),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize([0.485, 0.456, 0.406], \n                                                            [0.229, 0.224, 0.225])])\n\ntest_transforms = transforms.Compose([transforms.Resize(256),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406], \n                                                           [0.229, 0.224, 0.225])])\n\nvalidation_transforms = transforms.Compose([transforms.Resize(256),\n                                            transforms.CenterCrop(224),\n                                            transforms.ToTensor(),\n                                            transforms.Normalize([0.485, 0.456, 0.406], \n                                                                 [0.229, 0.224, 0.225])])","6d83288b":"img_dir='..\/input\/cell_images\/cell_images\/'\ntrain_data = datasets.ImageFolder(img_dir,transform=train_transforms)","a2cd5b40":"# number of subprocesses to use for data loading\nnum_workers = 0\n# percentage of training set to use as validation\nvalid_size = 0.2\n\ntest_size = 0.1\n\n# convert data to a normalized torch.FloatTensor\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\n# obtain training indices that will be used for validation\nnum_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nvalid_split = int(np.floor((valid_size) * num_train))\ntest_split = int(np.floor((valid_size+test_size) * num_train))\nvalid_idx, test_idx, train_idx = indices[:valid_split], indices[valid_split:test_split], indices[test_split:]\n\nprint(len(valid_idx), len(test_idx), len(train_idx))\n\n# define samplers for obtaining training and validation batches\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\ntest_sampler = SubsetRandomSampler(test_idx)\n\n# prepare data loaders (combine dataset and sampler)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=64,\n    sampler=train_sampler, num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(train_data, batch_size=32, \n    sampler=valid_sampler, num_workers=num_workers)\ntest_loader = torch.utils.data.DataLoader(train_data, batch_size=20, \n    sampler=test_sampler, num_workers=num_workers)","b30bbb6b":"model = models.resnet50(pretrained=True)\n\nfor param in model.parameters():\n    param.requires_grad = False\n\nmodel.fc = nn.Linear(2048, 2, bias=True)\n\nfc_parameters = model.fc.parameters()\n\nfor param in fc_parameters:\n    param.requires_grad = True\n    \nmodel","655b7a00":"use_cuda = torch.cuda.is_available()\nif use_cuda:\n    model = model.cuda()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.fc.parameters(), lr=0.001 , momentum=0.9)","553144f6":"def train(n_epochs, model, optimizer, criterion, use_cuda, save_path):\n    \"\"\"returns trained model\"\"\"\n    # initialize tracker for minimum validation loss\n    valid_loss_min = np.Inf\n    \n    for epoch in range(1, n_epochs+1):\n        # initialize variables to monitor training and validation loss\n        train_loss = 0.0\n        valid_loss = 0.0\n        \n        ###################\n        # train the model #\n        ###################\n        model.train()\n        for batch_idx, (data, target) in enumerate(train_loader):\n            # move to GPU\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n\n            # initialize weights to zero\n            optimizer.zero_grad()\n            \n            output = model(data)\n            \n            # calculate loss\n            loss = criterion(output, target)\n            \n            # back prop\n            loss.backward()\n            \n            # grad\n            optimizer.step()\n            \n            train_loss = train_loss + ((1 \/ (batch_idx + 1)) * (loss.data - train_loss))\n            \n            if batch_idx % 100 == 0:\n                print('Epoch %d, Batch %d loss: %.6f' %\n                  (epoch, batch_idx + 1, train_loss))\n        \n        ######################    \n        # validate the model #\n        ######################\n        model.eval()\n        for batch_idx, (data, target) in enumerate(valid_loader):\n            # move to GPU\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            ## update the average validation loss\n            output = model(data)\n            loss = criterion(output, target)\n            valid_loss = valid_loss + ((1 \/ (batch_idx + 1)) * (loss.data - valid_loss))\n\n            \n        # print training\/validation statistics \n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n            epoch, \n            train_loss,\n            valid_loss\n            ))\n        \n        ## TODO: save the model if validation loss has decreased\n        if valid_loss < valid_loss_min:\n            torch.save(model.state_dict(), save_path)\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n            valid_loss_min,\n            valid_loss))\n            valid_loss_min = valid_loss\n            \n    # return trained model\n    return model","4955a099":"train(25, model, optimizer, criterion, use_cuda, 'malaria_detection.pt')","250e85de":"model.load_state_dict(torch.load('malaria_detection.pt'))","657d1350":"def test(model, criterion, use_cuda):\n\n    # monitor test loss and accuracy\n    test_loss = 0.\n    correct = 0.\n    total = 0.\n\n    for batch_idx, (data, target) in enumerate(test_loader):\n        # move to GPU\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the loss\n        loss = criterion(output, target)\n        # update average test loss \n        test_loss = test_loss + ((1 \/ (batch_idx + 1)) * (loss.data - test_loss))\n        # convert output probabilities to predicted class\n        pred = output.data.max(1, keepdim=True)[1]\n        # compare predictions to true label\n        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n        total += data.size(0)\n            \n    print('Test Loss: {:.6f}\\n'.format(test_loss))\n\n    print('\\nTest Accuracy: %2d%% (%2d\/%2d)' % (\n        100. * correct \/ total, correct, total))\ntest(model, criterion, use_cuda)","dea203e1":"def load_input_image(img_path):    \n    image = Image.open(img_path)\n    prediction_transform = transforms.Compose([transforms.Resize(size=(224, 224)),\n                                     transforms.ToTensor(), \n                                     transforms.Normalize([0.485, 0.456, 0.406], \n                                                          [0.229, 0.224, 0.225])])\n\n    # discard the transparent, alpha channel (that's the :3) and add the batch dimension\n    image = prediction_transform(image)[:3,:,:].unsqueeze(0)\n    return image","27715d18":"def predict_malaria(model, class_names, img_path):\n    # load the image and return the predicted breed\n    img = load_input_image(img_path)\n    model = model.cpu()\n    model.eval()\n    idx = torch.argmax(model(img))\n    return class_names[idx]","0dc7deaf":"from glob import glob\nfrom PIL import Image\nfrom termcolor import colored\n\nclass_names=['Parasitized','Uninfected']\ninf = np.array(glob(\"..\/input\/cell_images\/cell_images\/Parasitized\/*\"))\nuninf = np.array(glob(\"..\/input\/cell_images\/cell_images\/Uninfected\/*\"))\nfor i in range(3):\n    img_path=inf[i]\n    img = Image.open(img_path)\n    if predict_malaria(model, class_names, img_path) == 'Parasitized':\n        print(colored('Parasitized', 'green'))\n    else:\n        print(colored('Uninfected', 'red'))\n    plt.imshow(img)\n    plt.show()\nfor i in range(3):\n    img_path=uninf[i]\n    img = Image.open(img_path)\n    if predict_malaria(model, class_names, img_path) == 'Uninfected':\n        print(colored('Uninfected', 'green'))\n    else:\n        print(colored('Parasitized', 'red'))        \n    plt.imshow(img)\n    plt.show()","a9c434c6":"## Model ResNet50","81604f6a":"## Testing The Model","4f382bae":"# Malaria Detection\n\nMalaria is a life-threatening disease caused by parasites that are transmitted to people through the bites of infected female Anopheles mosquitoes. It is preventable and curable.\n* In 2017, there were an estimated 219 million cases of malaria in 90 countries.\n* Malaria deaths reached 435 000 in 2017.\n* The WHO African Region carries a disproportionately high share of the global malaria burden. In 2017, the region was home to 92% of malaria cases and 93% of malaria deaths.\n\nMalaria is caused by Plasmodium parasites. The parasites are spread to people through the bites of infected female Anopheles mosquitoes, called \"malaria vectors.\" There are 5 parasite species that cause malaria in humans, and 2 of these species \u2013 P. falciparum and P. vivax \u2013 pose the greatest threat.\n\n\n***Diagnosis of malaria can be difficult***:\n\n* Where malaria is not endemic any more (such as in the United States), health-care providers may not be familiar with the disease. Clinicians seeing a malaria patient may forget to consider malaria among the potential diagnoses and not order the needed diagnostic tests. Laboratorians may lack experience with malaria and fail to detect parasites when examining blood smears under the microscope.\n* Malaria is an acute febrile illness. In a non-immune individual, symptoms usually appear 10\u201315 days after the infective mosquito bite. The first symptoms \u2013 fever, headache, and chills \u2013 may be mild and difficult to recognize as malaria. If not treated within 24 hours, P. falciparum malaria can progress to severe illness, often leading to death.\n\n***Microscopic Diagnosis***\n\nMalaria parasites can be identified by examining under the microscope a drop of the patient\u2019s blood, spread out as a \u201cblood smear\u201d on a microscope slide. Prior to examination, the specimen is stained  to give the parasites a distinctive appearance. This technique remains the gold standard for laboratory confirmation of malaria. However, it depends on the quality of the reagents, of the microscope, and on the experience of the laboratorian.\n\n![malaria](https:\/\/cdn1.sph.harvard.edu\/wp-content\/uploads\/2015\/03\/Malaria-cells_CDC.jpg)\n\nreferences :\n* [1] https:\/\/www.who.int\/news-room\/fact-sheets\/detail\/malaria \n* [2] https:\/\/www.cdc.gov\/malaria\/diagnosis_treatment\/diagnosis.html \n","d7365b62":"## Dataset","398890de":"## Writing The Algorithm for Code Execution","01a42222":"## Training The Network","e3a6db1e":"## Loading Saved Model"}}