{"cell_type":{"25a8849c":"code","761c9300":"code","2a9de03a":"code","107b56f0":"code","8d7eeee9":"code","e43911b1":"code","96b52656":"code","466126ac":"code","63703f2d":"code","b5371315":"code","dd063730":"code","bf8c5d29":"code","39ddc658":"code","95cecfed":"code","69ba487f":"code","e06d7294":"code","9b4755a5":"code","b2285d94":"code","b65fe8cc":"code","0171f4c3":"code","d11b62f5":"code","283e949f":"code","ed1097c9":"code","ed162ec8":"code","4d4dd6da":"code","6788695f":"code","35d18c3c":"code","ddc17d3a":"code","51d7fb00":"code","84fb9da0":"markdown","3a6c8fad":"markdown","a2d5fda1":"markdown","484288e3":"markdown","066a5ead":"markdown","09474e52":"markdown","b5b5f16b":"markdown","2717e570":"markdown","60915a88":"markdown","265c3a1a":"markdown","6d4bd8e6":"markdown","cba3fe02":"markdown","3062f852":"markdown","ddac798a":"markdown","0ace50b8":"markdown"},"source":{"25a8849c":"# basics\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# preprocess\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import PowerTransformer\n\n# model\nfrom lightgbm import LGBMClassifier\n\n# imbalanced\nfrom imblearn.pipeline import Pipeline\n\n## hyperopt functions\nfrom hyperopt import fmin, hp, tpe, Trials, space_eval\nfrom hyperopt.pyll import scope as ho_scope\nfrom hyperopt.pyll.stochastic import sample as ho_sample\nfrom functools import partial\n\n# evalue\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix, average_precision_score, roc_auc_score, fbeta_score\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, auc, log_loss\nfrom sklearn.metrics import precision_recall_curve, plot_precision_recall_curve, roc_curve, plot_roc_curve\n\n# resample\nfrom imblearn.over_sampling import ADASYN, SMOTE\nfrom imblearn.under_sampling import OneSidedSelection, NeighbourhoodCleaningRule, TomekLinks\n\n# turn off warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")","761c9300":"# Set model\ndef instance_model(hyperparameters):\n    \n    # LightGBM classifier\n    if pd.DataFrame(hyperparameters.keys())[0][0] == 'lgbm':\n        model = LGBMClassifier(**hyperparameters['lgbm'], \n                            n_jobs = -1,\n                            random_state = 42,      \n                            objective = \"binary\", \n                            #categorical_feature = categorical_features_index,\n                            n_estimators = 9999999,\n                            bagging_freq = 1,       \n                            #is_unbalance = True,   \n                            learning_rate = 0.01)  \n       \n        # Resampling\n        # ADASYN: Adaptive synthetic sampling\n        if hyperparameters['lgbm']['sample'] == 'adasyn':\n            undersample = ADASYN(random_state=42)\n            if hyperparameters['lgbm']['power'] == True:\n                power = PowerTransformer(method='yeo-johnson', standardize=True)\n                model = Pipeline([('sampling', undersample), \n                                  ('power', power), ('lgbm', model) ])\n            else: \n                model = Pipeline([('sampling', undersample), ('lgbm', model) ])\n                \n        # SMOTE: Synthetic Minority Oversampling Technique\n        if hyperparameters['lgbm']['sample'] == 'smote':\n            undersample = SMOTE()\n            if hyperparameters['lgbm']['power'] == True:\n                power = PowerTransformer(method='yeo-johnson', standardize=True)\n                model = Pipeline([('sampling', undersample),\n                                  ('power', power), ('lgbm', model) ])\n            else: \n                model = Pipeline([('sampling', undersample), ('lgbm', model) ])\n                \n        # Tomek Links: remover exemplos ambiguos\n        elif hyperparameters['lgbm']['sample'] == 'tomek':\n            undersample = TomekLinks()\n            if hyperparameters['lgbm']['power'] == True:\n                power = PowerTransformer(method='yeo-johnson', standardize=True)\n                model = Pipeline([('sampling', undersample), \n                                  ('power', power), ('lgbm', model) ])\n            else:\n                model = Pipeline([('sampling', undersample), ('lgbm', model) ])\n                \n        # Neighborhood Cleaning Rule for Undersampling: \n        # Condensed Nearest Neighbor + Edited Nearest Neighbors\n        elif hyperparameters['lgbm']['sample'] == 'ncr': \n            undersample  = NeighbourhoodCleaningRule(n_neighbors=3,\n                                                     threshold_cleaning=0.5)\n            if hyperparameters['lgbm']['power'] == True:\n                power = PowerTransformer(method='yeo-johnson', standardize=True)\n                model = Pipeline([('sampling', undersample),\n                                  ('power', power), ('lgbm', model) ])\n            else:\n                model = Pipeline([('sampling', undersample), ('lgbm', model) ])\n                \n        # One-Sided Selection : \n        # Tomek Links + Condensed Nearest Neighbor \n        elif hyperparameters['lgbm']['sample'] == 'oss':\n            undersample = OneSidedSelection(n_neighbors=1, n_seeds_S=200)\n            if hyperparameters['lgbm']['power'] == True:\n                power = PowerTransformer(method='yeo-johnson', standardize=True)\n                model = Pipeline([('sampling', undersample), \n                                  ('power', power), ('lgbm', model) ])\n            else:\n                model = Pipeline([('sampling', undersample), \n                                  ('lgbm', model) ])\n        ## No resampling\n        else:\n            if hyperparameters['lgbm']['power'] == True:\n                power = PowerTransformer(method='yeo-johnson', standardize=True)\n                model = Pipeline([('sampling', None), \n                                  ('power', power), ('lgbm', model) ])\n            else:\n                model = Pipeline([('sampling', None), ('lgbm', model) ])\n     \n    return model\n\ndef to_minimize(hyperparameters, features, target, fit_params):\n    # create an instance of the model \n    model = instance_model(hyperparameters)\n    \n    # train with cross-validation\n    resultado = cross_val_score(estimator = model, \n                                X = features, \n                                y = target, \n                                scoring = \"average_precision\",\n                                cv = cv, \n                                fit_params = fit_params,\n                                n_jobs = -1,\n                                error_score='raise')\n    \n    return -resultado.mean()\n\n# function to get the optimization history\ndef extract_space_eval(hp_space, trial):\n    \n    ## get results\n    desempacota_trial = space_eval(space = hp_space, \n                                   hp_assignment = {k: v[0] for (k, v) in trial['misc']['vals'].items() if len(v) > 0})\n    \n    return desempacota_trial\n\ndef unpack_dictionary(dictionary):\n    unpacked = {}\n    for (key, value) in dictionary.items():\n        if isinstance(value, dict):\n            unpacked = {**unpacked, **unpack_dictionary(value)}\n        else:\n            unpacked[key] = value\n            \n    return unpacked\n\n# Metrics to evaluate model\ndef evalue_model(model, y_test, X_test, model_name):\n    # default cut off\n    threshold = 0.5\n    \n    # predict\n    pred_prob = model.predict_proba(X_test)\n    \n    # pr curve to best threshold\n    precision, recall, thresholds = precision_recall_curve(y_test, pred_prob[:, 1])\n\n    # calcule fscore\n    fscore_f2  = ((1+4)*precision*recall)\/(4*precision+recall) # f2\n    fscore_f1  = (2*precision*recall)\/(precision+recall) #f1\n    fscore_f05 = (1.25*precision*recall)\/(0.25*precision+recall) #f05\n    \n    # get max\n    threshold_f2  = thresholds[np.argmax(fscore_f2)]\n    threshold_f1  = thresholds[np.argmax(fscore_f1)]\n    threshold_f05 = thresholds[np.argmax(fscore_f05)]\n    \n    # prob true class\n    pred_prob = [predicao[1] for predicao in pred_prob]\n    \n    # apply threshold 05\n    pred_class = [instancia >= threshold_f05 for instancia in pred_prob]\n    \n    # confusion matrix\n    cm = confusion_matrix(y_true = y_test, y_pred = pred_class)\n    \n    # metrics\n    dictionary = {'accuracy': accuracy_score(y_true = y_test,y_pred=pred_class),\n                  'F05': fbeta_score(y_true=y_test,y_pred=pred_class,beta=0.5),\n                  'F1': fbeta_score(y_true=y_test,y_pred=pred_class,beta=1),\n                  'F2': fbeta_score(y_true=y_test,y_pred=pred_class,beta=2),\n                  'recall': recall_score(y_true = y_test, y_pred = pred_class),\n                  'precision': precision_score(y_true=y_test,y_pred=pred_class),\n                  'tn': cm[0][0],\n                  'fn': cm[1][0],\n                  'tp': cm[1][1],\n                  'fp': cm[0][1],\n                  'logloss': log_loss(y_test, pred_prob),\n                  'threshold_f2': threshold_f2,\n                  'threshold_f05': threshold_f05,\n                  'threshold_f1': threshold_f1,\n                  'auc': roc_auc_score(y_true = y_test, y_score = pred_prob),\n                  'average_precision':average_precision_score(y_true=y_test,y_score=pred_prob),\n                  'aucpr': auc(recall, precision),\n                  'model_name': model_name}\n    \n    return dictionary\n\ndef plot_auc_pr(name, labels, predictions,n=0.5, **kwargs):\n  p, r, _ = precision_recall_curve(labels, predictions)\n\n  plt.plot(100*r, 100*p, label=name, linewidth=2, **kwargs)\n  plt.xlabel('Recall [%]')\n  plt.ylabel('Precision [%]')\n  plt.xlim([-0.5,100])\n  plt.title('Precision-Recall Curve')\n  plt.ylim([20,100.5])\n  plt.grid(True)\n  ax = plt.gca()\n  ax.set_aspect('equal')","2a9de03a":"df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\nprint(\"Full dataset has\",df.shape[0], \"rows and\", df.shape[1], \"columns\")","107b56f0":"df.head()","8d7eeee9":"print(\"Missing data: \", df.isnull().sum().sum())","e43911b1":"# The classes are heavily skewed we need to solve this issue later.\nprint('No Frauds', round(df['Class'].value_counts()[0]\/len(df) * 100,2), '% of the dataset')\nprint('Fraud', round(df['Class'].value_counts()[1]\/len(df) * 100,2), '% of the dataset')\n\nsns.countplot('Class', data=df)\nplt.title('Class Distributions \\n 0: No Fraud 1: Fraud')","96b52656":"fig, ax = plt.subplots(1, 2, figsize=(18,4))\n\nsns.distplot(df['Amount'].values, ax=ax[0])\nax[0].set_title('Distribution of Transaction Amount')\nax[0].set_xlim([min(df['Amount'].values), max(df['Amount'].values)])\n\nsns.distplot(df['Time'].values, ax=ax[1])\nax[1].set_title('Distribution of Transaction Time')\nax[1].set_xlim([min(df['Time'].values), max(df['Time'].values)])","466126ac":"X = df.drop('Class', axis=1)\ny = df['Class']","63703f2d":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\nX_train = pd.DataFrame(X_train.values, columns=X.columns)\nX_test  = pd.DataFrame(X_test.values, columns=X.columns)\ny_train = y_train.values\ny_test  = y_test.values","b5371315":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n\nprint(\"Train: Fraud =\", sum(y_train), \"No Fraud =\", len(y_train) - sum(y_train))\nprint(\"Val:   Fraud =\", sum(y_val), \" No Fraud =\", len(y_val) - sum(y_val))\nprint(\"Test:  Fraud =\", sum(y_test), \" No Fraud =\", len(y_test) - sum(y_test))\n\neval_set = [(pd.DataFrame(X_val), pd.DataFrame(y_val))]","dd063730":"cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)","bf8c5d29":"%%time\n\nmodel_lgbm = LGBMClassifier(n_jobs = -1, random_state = 42, objective = \"binary\",\n                            #categorical_feature= categorical_features_index,\n                            n_estimators = 9999999,\n                            bagging_freq = 1,\n                            #boosting = \"dart\",\n                            learning_rate = 0.01,\n                            is_unbalance = True)\n\nfit_params={'lgbm__early_stopping_rounds': 100, \n            'lgbm__eval_metric': 'average_precision',\n            'lgbm__verbose': True,\n            'lgbm__eval_set': eval_set}\n\nundersample = None\n\nmodel_lgbm_baseline = Pipeline([('sample', undersample), \n                                ('lgbm', model_lgbm) ])\n\nmodel_lgbm_baseline_cv = cross_val_score(model_lgbm_baseline, X_train, y_train, \n                                        cv = cv, \n                                        scoring = \"average_precision\", \n                                        fit_params = fit_params, \n                                        n_jobs=-1, \n                                         error_score='raise')\n\nprint(\"cross-validation Average Precision:\",f\"{model_lgbm_baseline_cv.mean():.3f} STD:{model_lgbm_baseline_cv.std():.2f}\")","39ddc658":"scale_pos_weight_max = int((len(y_train) - sum(y_train)) \/ sum(y_train))\nscale_pos_weight_max","95cecfed":"# choices source: https:\/\/github.com\/microsoft\/LightGBM\/issues\/695#issuecomment-315591634\nhp_space_lgbm = {\n    'lgbm': {\n        # number of trees and learning rate -------------\n        #'n_estimators': ho_scope.int(hp.quniform('n_estimators',100,600,100)), # eval autotune\n        #'learning_rate': hp.loguniform('learning_rate',np.log(1e-5),np.log(0.05)), # eval autotune\n        # tree depth ------------------------------------\n        #'max_depth':  ho_scope.int(hp.quniform('max_depth',2,12,1)),\n        #'num_leaves': hp.choice(label = 'num_leaves', options = [15, 31, 63, 127, 255, 511, 1023, 2047, 4095]),\n        #'min_child_weight':  ho_scope.int(hp.quniform('min_child_weight',0,X_train.shape[0]\/100,1)),\n        # conservative update step ----------------------\n        ##'max_delta_step': ho_scope.int(hp.quniform('max_delta_step',1,10,1)),\n        # sampling --------------------------------------\n        'subsample': hp.uniform('subsample',0.4,1), \n        'colsample_bytree': hp.uniform('colsample_bytree',0.4,1),\n        #'feature_fraction': hp.uniform('feature_fraction',0.2,0.7),\n        # regularization --------------------------------\n        'reg_lambda': hp.loguniform('reg_lambda',np.log(1e-4),np.log(10)),\n        'reg_alpha': hp.loguniform('reg_alpha',np.log(1e-4),np.log(10)),\n        ##'min_gain_to_split': hp.loguniform('min_gain_to_split',np.log(1e-4),np.log(2)),\n        # specific lgbm ---------------------------------\n        #'min_child_samples': ho_scope.int(hp.quniform('min_child_samples',10,500,100)),\n        # set weights for balancing ---------------------\n        'scale_pos_weight' : ho_scope.int(hp.loguniform('scale_pos_weight',np.log(1),np.log(scale_pos_weight_max))),\n        # Dart Booster ----------------------------------\n        #'drop_rate': hp.uniform('drop_rate',0,1),\n        #'skip_drop': hp.uniform('skip_drop',0,1)\n        # Pipeline parameters ---------------------------\n        # Sampling\n        'sample':  hp.choice(label = 'sample', options = [None, 'tomek', 'ncr','oss', 'smote']),\n        # Boxcox\n        'power': hp.choice(label = 'power', options = [False, True])\n    }\n}","69ba487f":"## criando instancia do Trials\ninteractions_lgbm = Trials()","e06d7294":"fit_params={'lgbm__early_stopping_rounds': 100,\n            'lgbm__eval_metric': 'average_precision',\n            'lgbm__verbose': False,\n            'lgbm__eval_set': eval_set}","9b4755a5":"%%time\n\n## run optimization\noptimization = fmin(fn = partial(to_minimize, features = X_train, target = y_train, fit_params = fit_params),\n                  space = hp_space_lgbm, \n                  algo = tpe.suggest,\n                  trials = interactions_lgbm,\n                  max_evals = int(60), \n                  rstate = np.random.RandomState(42))","b2285d94":"## save history \nlgbm_history = pd.DataFrame([unpack_dictionary(extract_space_eval(hp_space_lgbm, x)) for x in interactions_lgbm.trials])","b65fe8cc":"## save results in new col\nlgbm_history['average_precision'] = pd.DataFrame(interactions_lgbm.results).loss * -1","0171f4c3":"sns.scatterplot(x = lgbm_history.index, y = 'average_precision', data = lgbm_history)\nplt.title('Optimization History')\nplt.xlabel(xlabel = 'Interaction')\nplt.ylabel(ylabel = 'Average Precision')","d11b62f5":"sns.countplot(x = 'sample', data = pd.DataFrame(lgbm_history['sample'].apply(lambda x: \"None\" if x == None else x)))\nplt.title('Times each criterion was selected')\nplt.xlabel(xlabel = 'sample')\nplt.ylabel(ylabel = 'Interactions')","283e949f":"sns.countplot(x = 'power', data = lgbm_history)\nplt.title('Times each criterion was selected')\nplt.xlabel(xlabel = 'YeoJhonson')\nplt.ylabel(ylabel = 'Interactions')","ed1097c9":"selected_hyperparameters = space_eval(space = hp_space_lgbm, hp_assignment = optimization)\nselected_hyperparameters","ed162ec8":"model_lgbm_bayeshp = instance_model(hyperparameters=selected_hyperparameters)","4d4dd6da":"print(\"Historical max Average Precision:\",f\"{lgbm_history.average_precision.max():.3f} STD:{lgbm_history.average_precision.std():.2f}\")","6788695f":"%%time\nclassifiers = {\n    \"LGBMBaseline\": model_lgbm_baseline,\n    \"LGBMBayesOpt\": model_lgbm_bayeshp\n}\n\n# df to store metrics \nresults_lgbm = pd.DataFrame(columns= ['metric', 'model_name', 'aucpr', 'average_precision', 'auc', 'accuracy', 'F05', 'F1', 'F2', 'recall', 'precision', 'tn', 'fn', 'tp', 'fp', 'logloss', 'threshold_f2', 'threshold_f05', 'threshold_f1'])\n\n# df to save predictions\npred_df = pd.DataFrame(y_test,index=None)\n\nfor key, classifier in classifiers.items():\n    print(\"Running\", key)\n    model          = classifier.fit(X_train, y_train, \n                                    lgbm__early_stopping_rounds= 100, \n                                    lgbm__eval_metric= 'average_precision',\n                                    lgbm__verbose = 0,\n                                    lgbm__eval_set= eval_set)\n    pred_df[key]   = model.predict_proba(X_test)[:,1]\n    training_score = evalue_model(model,y_test, X_test, key)\n    df             = pd.DataFrame(training_score.items(), columns = [\"metric\", \"value\"])\n    results_lgbm   = results_lgbm.append(df.set_index('metric').T)","35d18c3c":"results_lgbm.drop('metric', axis=1).reset_index().drop('index', axis=1).sort_values(\"aucpr\", ascending = False)","ddc17d3a":"colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n\nsns.set_style(\"whitegrid\")\nplot_auc_pr(\"LGBMBaseline\", y_test, pred_df[\"LGBMBaseline\"], color=colors[0])\nplot_auc_pr(\"LGBMBayesOpt\", y_test ,pred_df[\"LGBMBayesOpt\"], color=colors[1],linestyle='--')\nplt.legend(loc='lower left')","51d7fb00":"plt.rcdefaults()\nfig, ax = plt.subplots()\nax.barh(X.columns[np.argsort(model_lgbm_bayeshp.steps[1][1].feature_importances_)][::-1], \n        sorted(model_lgbm_bayeshp.steps[1][1].feature_importances_, reverse=True),\n        align='center')\nax.set_yticks(X.columns)\nax.invert_yaxis() \nax.set_xlabel('Importance')","84fb9da0":"Sources:\n\n- <https:\/\/github.com\/microsoft\/LightGBM\/issues\/695#issuecomment-315591634>\n- <https:\/\/machinelearningmastery.com\/framework-for-imbalanced-classification-projects\/>\n- <https:\/\/machinelearningmastery.com\/roc-curves-and-precision-recall-curves-for-classification-in-python\/>\n- <https:\/\/sites.google.com\/view\/lauraepp\/parameters>\n- <https:\/\/sanchom.wordpress.com\/tag\/average-precision\/>","3a6c8fad":"## Baseline model","a2d5fda1":"## Bayes Optimization ","484288e3":"# Problem definition","066a5ead":"# Modeling\n\nSeparate explanatory variables from the target","09474e52":"# Evalue","b5b5f16b":"#### Details:\n\nAs mentioned in the description of the data set: these are transactions made by credit cards in September 2013 by European cardholders for 2 days.\n\nImportant informations:\n\n- The data set is highly unbalanced, the positive class (fraud) is responsible for 0.172% of all transactions.\n- The input variables are all numeric and most were obtained by the PCA (common procedure due to confidentiality)\n- The `Time` feature contains the seconds that elapse between each transaction and a first transaction in the data set.\n- The `Amount` resource is the Transaction Amount\n- The `Class` resource is a response variable and assumes a value of 1 in case of fraud and 0 if not.\n\n#### Solution:\n\nA LightGBM model will be adjusted using Bayesian optimization with lib hyperopt (optimize hyperparameters and resampling methods) to classify whether the transition is fraud. The goal will be to maximize aucpr (or average precision)\n\nThe resampling methods tested will be:\n\n- SMOTE\n- ADASYN\n- OneSidedSelection\n- NeighbourhoodCleaningRule\n- TomekLinks\n","2717e570":"Check distribution of non-PCA features","60915a88":"# Import dependencies","265c3a1a":"Check data balance","6d4bd8e6":"Define cross-validation method as stratified (due to unbalanced database) and shuffle to avoid ordering bias","cba3fe02":"## Understand train results","3062f852":"Authors:\n\n  * [Fellipe Gomes](https:\/\/github.com\/gomesfellipe) (Statistician - UFF, Data Scientist - Accenture) \n  * [Nicholas Marino](https:\/\/github.com\/nacmarino) (Ecologist - UFJF, Data Scientist - Accenture)\n\n\n<p align=\"right\"><span style=\"color:firebrick\">Dont forget to upvote if you liked! \ud83e\udd18<\/span> <\/p>\n","ddac798a":"# Explore","0ace50b8":"AUCPR"}}