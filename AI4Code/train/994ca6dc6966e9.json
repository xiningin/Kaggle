{"cell_type":{"65be53b1":"code","d80db6d9":"code","03388b00":"code","b6812a36":"code","18dac6e6":"code","b09b8503":"code","936bc2f8":"code","5241d699":"code","ae661b62":"code","6e24b14a":"code","96a8e80b":"code","315feb50":"code","1f10532e":"code","d2b74a5b":"code","f6be5720":"code","d84e7a3e":"code","5a071976":"code","20ce88c7":"code","57a6d1d9":"code","51904280":"code","09d977a5":"code","78bbf79a":"code","af604e52":"code","59c91646":"code","968cc5de":"code","2a89a2af":"code","8788c752":"code","815b20fc":"code","3c3da332":"code","ff7331d5":"code","ae6084fb":"code","beafb381":"code","5b03656c":"code","9d3fcff5":"code","f09e38b2":"code","10243a17":"code","95ff0150":"code","d3911bbf":"code","960209fa":"code","e59d1cf9":"code","5e9cb493":"code","dbc5b3ff":"code","9206a95a":"code","daef21da":"code","64dda066":"code","276b9862":"code","e413cd66":"code","3f19bed4":"code","b67b20af":"code","04105e89":"code","78d566e8":"code","96450e6c":"code","ab8c61f6":"code","a105626d":"markdown","476c45fc":"markdown","56d2b897":"markdown","067967b1":"markdown","7a416771":"markdown","0df1f20f":"markdown","e30655bc":"markdown","722e2575":"markdown","9cbe619f":"markdown","7ffdd227":"markdown","ae7bf9e5":"markdown"},"source":{"65be53b1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import IsolationForest\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.impute import KNNImputer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Lasso, Ridge, ElasticNet\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.ensemble import VotingClassifier\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import RFE\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import roc_auc_score\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d80db6d9":"train = pd.read_csv('..\/input\/iba-ml1-mid-project\/train.csv')\ntest = pd.read_csv('..\/input\/iba-ml1-mid-project\/test.csv')","03388b00":"df = train.replace(',','.', regex=True).astype(float) #changed the type to float as data type one of the columns was object","b6812a36":"iso=IsolationForest(contamination=0.10)\nimp=SimpleImputer(strategy='mean')","18dac6e6":"X=df[['age','number_dependent_family_members', 'monthly_income', 'number_of_credit_lines', 'real_estate_loans', 'ratio_debt_payment_to_income','credit_line_utilization','number_of_previous_late_payments_up_to_59_days','number_of_previous_late_payments_up_to_89_days','number_of_previous_late_payments_90_days_or_more']]\ny=df[['defaulted_on_loan']]\n","b09b8503":"rus=RandomUnderSampler(random_state=42)\nros=RandomOverSampler(random_state=42)","936bc2f8":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8) \n","5241d699":"X_rus_train, y_rus_train = rus.fit_resample(X_train, y_train)\n","ae661b62":"sns.scatterplot(data=X_rus_train, x='age', y='monthly_income') #taking on pair plot to compair it to after outlier removal \n","6e24b14a":"outlier_predXtr = iso.fit_predict(imp.fit_transform(X_rus_train)) #checking outliers in X_train\nmask=outlier_predXtr != -1\nX_train2, y_train2 = X_rus_train.iloc[mask, :], y_rus_train.iloc[mask] #updating training dataset","96a8e80b":"sns.scatterplot(data=X_train2, x='age', y='monthly_income') \n","315feb50":"estimator=SVR(kernel='linear')","1f10532e":"numerics = ['age','number_dependent_family_members', 'monthly_income', 'number_of_credit_lines', 'real_estate_loans', 'ratio_debt_payment_to_income','credit_line_utilization','number_of_previous_late_payments_up_to_59_days','number_of_previous_late_payments_up_to_89_days','number_of_previous_late_payments_90_days_or_more']","d2b74a5b":"numeric_transformer = Pipeline(steps=[\n    ('impute', KNNImputer()),\n    ('scaler', MinMaxScaler())\n    ])\n\ncolumn_preprocessing = ColumnTransformer(transformers=[\n    ('numeric', numeric_transformer, numerics)\n    \n    ])\n\nmodel = Pipeline(steps=[\n    ('preprocessing', column_preprocessing),\n    ('feat_select', RFE(estimator)),\n    ('classification', VotingClassifier(estimators=[\n        ('dt', DecisionTreeClassifier()),\n        ('knn', KNeighborsClassifier()),\n        ('randomforest', RandomForestClassifier())\n    ], voting='soft'))\n    ])\n\n  \nparam_space = {\n    'preprocessing__numeric__impute__n_neighbors':[3,9],\n    'classification__knn__n_neighbors':[3,9],\n    'classification__dt__max_depth':[5,7],\n    'feat_select__n_features_to_select':[4,7]\n    }","f6be5720":"gs= GridSearchCV(model, param_space, cv= 15, scoring='roc_auc', refit='precision_score')\n","d84e7a3e":"gs.fit(X_train2, y_train2.values.ravel() )\n","5a071976":"y_predict=gs.predict(X_test) #find target values on test dataset\ny_predict","20ce88c7":"y_predict_probs = gs.predict_proba(X_test) #find probabilities of target values on test dataset\ny_predict_probs","57a6d1d9":"plot_confusion_matrix(gs, X_test, y_test) ","51904280":"positive_probs = y_predict_probs[:, 1]\n","09d977a5":"gs.best_estimator_","78bbf79a":"roc_auc_score(y_test, y_predict)","af604e52":"roc_auc_score(y_test, positive_probs)","59c91646":"newtest=test.drop(['Id'], axis=1).replace(',','.', regex=True).astype(float) #preparing test data","968cc5de":"resultsprob=gs.predict_proba(newtest) # .replace(',','.', regex=True).astype(float))\nresultsprob.shape #checking the size ","2a89a2af":"resultsdfprob=pd.DataFrame(resultsprob[:,1], columns = ['Predicted'])\nresultsdfprob.index.name = 'Id'\nresultsdfprob.index += 1 ","8788c752":"resultsdfprob.to_csv('submission proba Aghamir Aghazada.csv')\n","815b20fc":"from sklearn import metrics\nfrom sklearn.metrics import roc_curve\nfrom matplotlib import pyplot","3c3da332":"fpr, tpr, thresholds = roc_curve(y_test, positive_probs)\npyplot.plot(fpr, tpr, marker='.', label='model')\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill')\npyplot.legend()\npyplot.show()","ff7331d5":"imp2=KNNImputer(n_neighbors=9) # 9 is seelceted as GridSearch showed this to be better estimator\ndt= DecisionTreeClassifier(max_depth=7) # 7 is seelceted as GridSearch showed this to be better estimator\ndt.fit(imp2.fit_transform(X_train2), imp2.fit_transform(y_train2))","ae6084fb":"importance = dt.feature_importances_\nfor i,v in enumerate(importance):\n    print('Feature: %0d, Score: %.5f' % (i,v))\npyplot.bar([x for x in range(len(importance))], importance)\npyplot.show()","beafb381":"for col in X_train2.columns:\n    print(col)","5b03656c":"y_predict_probsdt=dt.predict_proba(imp2.fit_transform(X_test))\npositive_probsdt = y_predict_probsdt[:, 1]\nroc_auc_score(y_test, positive_probsdt)","9d3fcff5":"plot_confusion_matrix(dt, imp2.fit_transform(X_test), imp2.fit_transform(y_test)) ","f09e38b2":"fpr, tpr, thresholds = roc_curve(y_test, positive_probsdt)\npyplot.plot(fpr, tpr, marker='.', label='model')\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill')\npyplot.legend()\npyplot.show()","10243a17":"randomforest = RandomForestClassifier()\nrandomforest.fit(imp2.fit_transform(X_train2), imp2.fit_transform(y_train2))","95ff0150":"randomforest.feature_importances_","d3911bbf":"importance = randomforest.feature_importances_\nfor i,v in enumerate(importance):\n    print('Feature: %0d, Score: %.5f' % (i,v))\npyplot.bar([x for x in range(len(importance))], importance)\npyplot.show()","960209fa":"y_predict_probsrf=randomforest.predict_proba(imp2.fit_transform(X_test))\npositive_probsrf = y_predict_probsrf[:, 1]\nroc_auc_score(y_test, positive_probsrf)","e59d1cf9":"fpr, tpr, thresholds = roc_curve(y_test, positive_probsrf)\npyplot.plot(fpr, tpr, marker='.', label='model')\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill')\npyplot.legend()\npyplot.show()","5e9cb493":"plot_confusion_matrix(randomforest, imp2.fit_transform(X_test), imp2.fit_transform(y_test)) ","dbc5b3ff":"knn= KNeighborsClassifier(n_neighbors=9)\nknn.fit(imp2.fit_transform(X_train2), imp2.fit_transform(y_train2))","9206a95a":"y_predict_probsknn=knn.predict_proba(imp2.fit_transform(X_test))\npositive_probsknn = y_predict_probsknn[:, 1]\nroc_auc_score(y_test, positive_probsknn)","daef21da":"fpr, tpr, thresholds = roc_curve(y_test, positive_probsknn)\npyplot.plot(fpr, tpr, marker='.', label='model')\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill')\npyplot.legend()\npyplot.show()","64dda066":"plot_confusion_matrix(knn, imp2.fit_transform(X_test), imp2.fit_transform(y_test)) ","276b9862":"numeric_transformer = Pipeline(steps=[\n    ('impute', KNNImputer()),\n    ('scaler', MinMaxScaler())\n    ])\n\ncolumn_preprocessing = ColumnTransformer(transformers=[\n    ('numeric', numeric_transformer, numerics)\n    \n    ])\n\nmodel2 = Pipeline(steps=[\n    ('preprocessing', column_preprocessing),\n    ('feat_select', RFE(estimator)),\n    ('classification', VotingClassifier(estimators=[\n        ('dt', DecisionTreeClassifier()),\n        ('randomforest', RandomForestClassifier())\n    ], voting='soft'))\n    ])\n\n  \nparam_space = {\n    'preprocessing__numeric__impute__n_neighbors':[9],\n    'classification__dt__max_depth':[5],\n    'feat_select__n_features_to_select':[7]\n    }","e413cd66":"gs2= GridSearchCV(model2, param_space, cv= 15, scoring='roc_auc', refit='precision_score')\ngs2.fit(X_train2, y_train2.values.ravel() )\n","3f19bed4":"imp2.fit_transform(X_test)","b67b20af":"y_predict_probsgs2=gs2.predict_proba(X_test)\npositive_probsgs2 = y_predict_probsgs2[:, 1]\n","04105e89":"roc_auc_score(y_test, positive_probsgs2)","78d566e8":"fpr, tpr, thresholds = roc_curve(y_test, positive_probsgs2)\npyplot.plot(fpr, tpr, marker='.', label='model')\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill')\npyplot.legend()\npyplot.show()","96450e6c":"plot_confusion_matrix(gs2, X_test, imp2.fit_transform(y_test)) ","ab8c61f6":"resultsgs2=gs2.predict_proba(newtest) # .replace(',','.', regex=True).astype(float))\nresultsgs2=pd.DataFrame(resultsgs2[:,1], columns = ['Predicted'])\nresultsgs2.index.name = 'Id'\nresultsgs2.index += 1 \nresultsgs2.to_csv('submission gs2 Aghamir Aghazada.csv')\n","a105626d":"This model gives slightly better roc_auc_score and better predics true positives but it predicts false positives more than previous model.","476c45fc":"**Checking feature importance:**\n\nAs we used pipeline we will have too replicate all claculations separately for each model in order to calculate feature importances. Best estimators will be used in order to avoid long processing times.","56d2b897":"Any train_size ratio yielded same results.","067967b1":"\nThis model ensemble gives result similar to models that it consists of. In order to diverisy the decision making process we will keep both of this models in ensemble which will hopefully work better in predicting other data. Other different model were used and were later dropped in order to increase roc_auc_score. Different train test split ratios were tested but even dramatic changes to ratio did not affect the score much.","7a416771":"As we can see for Decision Tree model the most important feature is credit_line_utilization - about 50%. It is followed by number_of_previous_late_payments_up_to_59_days - 16%, number_of_previous_late_payments_90_days_or_more - 12%. Rest of the features play less importance( biggest impact has number_of_previous_late_payments_up_to_89_days and it is less than 7%). Even though I gave an option to choose between 4 and 7 features, it went with 7, while the biggest impact on this model have only 4 of them. Let's check feature importance for random model.","0df1f20f":"Even though features like 'number_of_previous_late_payments_up_to_59_days', 'number_of_previous_late_payments_up_to_89_days','number_of_previous_late_payments_90_days_or_more' have high correlation they were all used by model in prediction. I expected GridSearch model to drop highly correlated features. We will check the feature importance later. ","e30655bc":"\u0130n this model we can see that credit_line_utilization feature still plays largest role - about 25%, but overall all feature importance distribution is more balanced. This explains why GridSearch choose maximum available number of features that was allowed. GridSearch chose 7 features and we can see that 3 out of 10 features have less than 5% impact on calculation. We can assume that these features were dropped while GridSearch.  ","722e2575":"Initially I was calculating roc_auc_score by using gs.predict which would show 75% score. Later I realized that the task is to find probabilities of positive and negative cases, so I used gs.predict_proba which showed better results of ~82%","9cbe619f":"Decided to undersample the data since oversampling would take much more time to calculate.","7ffdd227":"We can see that number of outliers decreased previous operation","ae7bf9e5":"Since KNN model shows drastically lower roc_auc_score it is better to drop it from model ensemble and run GridSearch again with optimal hyperparameters"}}