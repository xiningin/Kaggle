{"cell_type":{"737697aa":"code","cec43414":"code","7b5ebe70":"code","dfc83d6d":"code","b04fb1aa":"code","bc7cf040":"code","a8c6f822":"code","cc350c07":"code","def4a8f4":"code","7681fe50":"code","706128f6":"code","d3d9686d":"code","befd7f11":"code","dee1be1a":"markdown","36d7ad82":"markdown","15a31a85":"markdown","71010d44":"markdown","05b5a18d":"markdown"},"source":{"737697aa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cec43414":"# Importing the required packages\nimport torch\nimport cv2\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset\nimport torch.nn as nn\nfrom sklearn.metrics import f1_score\nimport seaborn as sns","7b5ebe70":"# Read the csv file and print the first 10 rows\ncsv=pd.read_csv(\"\/kaggle\/input\/sign-language-mnist\/sign_mnist_train.csv\")\nprint(csv.head(10))\nlabels=csv['label']","dfc83d6d":"# Plotting the number of data in each label as a countplot.\nplt.figure(figsize=(10,10))\nsns.countplot(labels)","b04fb1aa":"# Split the label (1st Column) and Image Pixels (2nd-785th Column)\ntext=\"pixel\"\nimages=torch.zeros((csv.shape[0],1))\nfor i in range(1,785):\n    temp_text=text+str(i)\n    temp=csv[temp_text]\n    temp=torch.FloatTensor(temp).unsqueeze(1)\n    images=torch.cat((images,temp),1)\nimages_final=torch.FloatTensor(images[:,1:]).view(-1,28,28)","bc7cf040":"fig=plt.figure(figsize=(10,10))\ncolumns=3\nrows=4\nfor i in range(12):\n    img=images_final[i,:]\n    img=img.numpy()\n    img=cv2.resize(img,(224,224))\n    fig.add_subplot(columns, rows, i + 1)\n    plt.imshow(img)\nplt.show()","a8c6f822":"class GestureDataset(Dataset):\n    def __init__(self,csv,train=True):\n        self.csv=pd.read_csv(csv)\n        self.img_size=224\n        # print(self.csv['image_names'][:5])\n        self.train=train\n        text=\"pixel\"\n        self.images=torch.zeros((self.csv.shape[0],1))\n        for i in range(1,785):\n            temp_text=text+str(i)\n            temp=self.csv[temp_text]\n            temp=torch.FloatTensor(temp).unsqueeze(1)\n            self.images=torch.cat((self.images,temp),1)\n        self.labels=self.csv['label']\n        self.images=self.images[:,1:]\n        self.images=self.images.view(-1,28,28)\n        \n    def __getitem__(self,index):\n        img=self.images[index]\n        img=img.numpy()\n        img=cv2.resize(img,(self.img_size,self.img_size))\n        tensor_image=torch.FloatTensor(img)\n        tensor_image=tensor_image.unsqueeze(0)\n        tensor_image\/=255.\n        if self.train:\n            return tensor_image,self.labels[index]\n        else:\n            return tensor_image\n    def __len__(self):\n        return self.images.shape[0]","cc350c07":"# Using custom GestureDataset class to load train and test data respectively.\ndata=GestureDataset(\"\/kaggle\/input\/sign-language-mnist\/sign_mnist_train.csv\")\ndata_val=GestureDataset(\"\/kaggle\/input\/sign-language-mnist\/sign_mnist_test.csv\")","def4a8f4":"# Using the in-built DataLoader to create batches of images and labels for training validation respectively. \ntrain_loader=torch.utils.data.DataLoader(dataset=data,batch_size=128,num_workers=4,shuffle=True)\nval_loader=torch.utils.data.DataLoader(dataset=data_val,batch_size=64,num_workers=0,shuffle=True)","7681fe50":"class Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        self.Conv1 = nn.Sequential(\n        nn.Conv2d(1, 32, 5), # 220, 220\n        nn.MaxPool2d(2), # 110, 110\n        nn.ReLU(),\n        nn.BatchNorm2d(32)\n        )\n        self.Conv2 = nn.Sequential(\n        nn.Conv2d(32, 64, 5), # 106, 106\n        nn.MaxPool2d(2),  # 53,53\n        nn.ReLU(),\n        nn.BatchNorm2d(64)\n        )\n        self.Conv3 = nn.Sequential(\n        nn.Conv2d(64, 128, 3), # 51, 51\n        nn.MaxPool2d(2), # 25, 25\n        nn.ReLU(),\n        nn.BatchNorm2d(128)\n        )\n        self.Conv4 = nn.Sequential(\n        nn.Conv2d(128, 256, 3), # 23, 23\n        nn.MaxPool2d(2), # 11, 11\n        nn.ReLU(),            \n        nn.BatchNorm2d(256)\n        )\n        self.Conv5 = nn.Sequential(\n        nn.Conv2d(256, 512, 3), # 9, 9\n        nn.MaxPool2d(2), # 4, 4\n        nn.ReLU(),\n        nn.BatchNorm2d(512)\n        )\n        \n        self.Linear1 = nn.Linear(512 * 4 * 4, 256)\n        self.dropout=nn.Dropout(0.1)\n        self.Linear3 = nn.Linear(256, 25)\n    def forward(self, x):\n        x = self.Conv1(x)\n        x = self.Conv2(x)\n        x = self.Conv3(x)\n        x = self.Conv4(x)\n        x=self.dropout(x)\n        x = self.Conv5(x)\n        x = x.view(x.size(0), -1)\n        x = self.Linear1(x)\n        x = self.dropout(x)\n        x = self.Linear3(x)\n        return x","706128f6":"# Validating the model against the validation dataset and generate the accuracy and F1-Score.\ndef validate(val_loader,model):\n    model.eval()\n    test_labels=[0]\n    test_pred=[0]\n    for i, (images,labels) in enumerate(val_loader):\n        outputs=model(images.to(device))\n        predicted = torch.softmax(outputs,dim=1)\n        _,predicted=torch.max(predicted, 1)\n        test_pred.extend(list(predicted.data.cpu().numpy()))\n        test_labels.extend(list(labels.data.cpu().numpy()))\n\n    test_pred=np.array(test_pred[1:])\n    test_labels=np.array(test_labels[1:])\n    correct=(test_pred==test_labels).sum()\n    accuracy=correct\/len(test_labels)\n    f1_test=f1_score(test_labels,test_pred,average='weighted')\n    model.train()\n    return accuracy,f1_test ","d3d9686d":"model=Classifier()\nmodel=model.to(\"cuda\")\nmodel.train()\ncheckpoint=None\ndevice=\"cuda\"\nlearning_rate=1e-3\nstart_epoch=0\nend_epoch=20\ncriterion = nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.5, verbose= True, min_lr=1e-6)\nif checkpoint:\n    model.load_state_dict(torch.load(checkpoint)['state_dict'])\n    start_epoch=torch.load(checkpoint)['epoch']\nfor epoch in range(start_epoch,end_epoch+1):\n    for i, (images,labels) in enumerate(train_loader):\n        outputs=model(images.to(device))\n        loss=criterion(outputs.to(device),labels.to(device))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        predicted = torch.softmax(outputs,dim=1)\n        _,predicted=torch.max(predicted, 1)\n        f1=f1_score(labels.cpu().numpy(),predicted.cpu().numpy(),average='weighted')\n    val_accuracy, val_f1=validate(val_loader,model)\n    print(\"------------------------------------------------------------------------------------------------------\")\n    print(\"Epoch [{}\/{}], Training F1: {:.4f}, Validation Accuracy: {:.4f}, Validation F1: {:.4f}\".format(epoch,end_epoch,f1,val_accuracy,val_f1))\n    scheduler.step(val_accuracy)","befd7f11":"# Save the model for future use and optimization.\ntorch.save({\n'epoch': epoch,\n'state_dict': model.state_dict(),\n'optimizer' : optimizer.state_dict()},\n'checkpoint.epoch.1.{}.pth.tar'.format(epoch))","dee1be1a":"**Displaying Data:** <br><br>\nLoop through the first 12 images and display it using Matplotlib. <br><br>\nImages are arranged in 4 rows of three columns each. <br><br>\n***Images are resized to (224,224).*** <br><br>","36d7ad82":"<b>**GestureDataset class:**<\/b> <br><br>\nDefining GestureDataset class, which inherits ***Dataset class*** and overrides the two methods ***\\__getitem__*** and ***\\__len__***. <br><br>\nThe main purpose of this class is to process the images and labels into a format which can be directly used for training.<br><br>\n***\\__init__:*** \n*     Reads csv.<br>\n*     Splits Labels and Images.<br>\n*     Converts given 1-D vectors to 2-D images.<br><br>\n***\\__getitem__:*** <br><br>\n*     Reads each image and resizes them to the size (224,224).<br>\n*     The image is then converted to Tensor of type Float.<br>\n*     Finally, the tensor values are normalized to the range (0,1).<br><br>\n***\\__len__:***<br><br>\n*     Returns the number of images in the dataset.<br><br>","15a31a85":"# Training the model \n1. Define the Cross Entopy loss function. <br>\n2. Define the Adam Optimizer with a learning rate of 1e-3.<br>\n3. Finally, define the learning rate scheduler which reduces the learning rate by a factor of 0.5 (i.e. lr\\*0.5), if the validation accuracy does not reduce after 2 epochs.<br>\n4. Train the model for 20 epochs.<br>","71010d44":"# Defining the Model:\nDefining the Classifier class for Classification. <br><br>\nThe ***\\__init__*** method is used to initialize the network layers. <br><br>\nThe ***forward*** method is used to process the input through the initialized layers and return the final output. <br> <br>\n\n<b>Classifier:<\/b><br>\n1. The model contains 5 Convolutional modules. <br>\n    i) Each Convolutional module consists of a 2D -Convolutional layer, followed by MaxPooling, REctified Linear Unit and Batch Normalization layers.<br>\n    ii) The first convolutional layer takes the input image of size (224,224) and convolves using a 32 channeled kernel of size (5,5).<br> (224,224,1) * (5,5,32) --> (220,220,32) -->MaxPool--> (110,110,32).<br><br>\n    iii) The second convolutional layer takes the output of the first conv layer of size (110,110,32) and convolves using a 64 channeled kernel of size (5,5).<br> (110,110,32) * (5,5,64) --> (106,106,64) -->MaxPool--> (53,53,64).<br><br>\n    iv) The third convolutional layer takes the output of the second conv layer of size (53,53,64) and convolves using a 128 channeled kernel of size (3,3).<br> (53,53,64) * (3,3,128) --> (51,51,128) -->MaxPool--> (25,25,128).<br><br>\n    v) The fourth convolutional layer takes the output of the third conv layer of size (25,25,128) and convolves using a 256 channeled kernel of size (3,3).<br> (25,25,128) * (3,3,256) --> (23,23,256) -->MaxPool--> (11,11,256).<br><br>\n    iii) The fifth convolutional layer takes the output of the fourth conv layer of size (11,11,256) and convolves using a 512 channeled kernel of size (3,3).<br> (11,11,256) * (3,3,512) --> (9,9,512) -->MaxPool--> (4,4,512).<br><br>\n\n2. The model contains two fully connected layers for classification.<br><br>\n    i) The first FC layer takes the flattened output of the final Conv layer of size (512\\*4\\*4,1) reduces the dimension to 256. This layer is follwed by a dropout layer with a dropout probability of 10% <br><br>\n    ii) The second FC layer takes the output of the first and reduces the dimension to 25, which is the number of classes. <br><br>\n    ","05b5a18d":"# CNN Architecture Using PyTorch\nName: Vijay Vignesh P<br><br>\nLinkedIn: https:\/\/www.linkedin.com\/in\/vijay-vignesh-0002\/ <br><br>\nGitHub: https:\/\/github.com\/VijayVignesh1 <br><br>\nEmail: vijayvigneshp02@gmail.com <br><br>\n***Please Upvote if you like it*** <br><br>"}}