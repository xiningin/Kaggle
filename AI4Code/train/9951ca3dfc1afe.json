{"cell_type":{"80865019":"code","66c8a194":"code","4f2810ee":"code","5743f179":"code","acfd8f09":"code","b87cbde0":"code","c08dd53e":"code","f3ffc299":"code","71b4239f":"code","16072d6c":"code","c2245deb":"code","9785b544":"code","8d48174e":"code","5bfa5fc8":"code","a9a35e56":"code","c73acca0":"code","72662ae4":"code","ec4147a5":"code","eb8479e3":"code","676930a1":"code","7f707b36":"code","7b206d60":"code","433fb3b6":"code","6d5b05d7":"code","cf148cbb":"code","b6350a04":"code","0288f6c2":"code","b6571361":"code","0a58517b":"markdown","39a76c88":"markdown","5fdd5d60":"markdown","739bbfa3":"markdown","cf36e789":"markdown","d9a6770f":"markdown","5f865e8d":"markdown","17c193b5":"markdown","93973550":"markdown","1f944c12":"markdown","b47c13ce":"markdown","50623ea8":"markdown","83a326f1":"markdown","8ba97117":"markdown","3d0651bd":"markdown","1ea576f0":"markdown","84605fa9":"markdown","6147209a":"markdown","7862f85f":"markdown"},"source":{"80865019":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline","66c8a194":"%time train = pd.read_csv('..\/input\/train.csv')\ntrain.shape, train.columns","4f2810ee":"%time test = pd.read_csv('..\/input\/test.csv')\ntest.shape, test.columns","5743f179":"train.dtypes.value_counts()","acfd8f09":"features = train.drop(columns=['ID', 'target'])\nfeatures.min().min(), features.max().max(), features.isnull().any().any()","b87cbde0":"test_features = test.drop(columns='ID').sample(n=features.shape[0], random_state=123)\ntest_features.min().min(), test_features.max().max(), test_features.isnull().any().any()","c08dd53e":"plt.figure(figsize=(5,5))\nplt.spy((features > 0).values);","f3ffc299":"(features == 0).sum().sum() \/ features.size * 100","71b4239f":"plt.figure(figsize=(5,5))\nplt.spy((test_features > 0).values);","16072d6c":"(test_features == 0).sum().sum() \/ test_features.size * 100","c2245deb":"nunique = features.nunique()\nno_info = nunique == 1\nno_info.sum()","9785b544":"to_drop = nunique[no_info].index.values\ntrain.drop(columns=to_drop, inplace=True)\nfeatures.drop(columns=to_drop, inplace=True)\ntest.drop(columns=to_drop, inplace=True)\ntest_features.drop(columns=to_drop, inplace=True)","8d48174e":"train.loc[features.duplicated(keep=False), ['ID', 'target']]","5bfa5fc8":"trans = features.T\nall_duplicates = trans[trans.duplicated(keep=False)].index\nlast_duplicates = trans[trans.duplicated()].index\nall_duplicates, last_duplicates","a9a35e56":"test_sample = test_features.sample(n=features.shape[0], random_state=123)\ntrans_test = test_sample.T\ntrans_test[trans_test.duplicated(keep=False)].index","c73acca0":"for i in range(len(all_duplicates)):\n    for j in range(i + 1, len(all_duplicates)):\n        col1, col2 = all_duplicates[i], all_duplicates[j]\n        print(col1, col2, 'train:', sum(train[col1] != train[col2]), ' test:', sum(test_sample[col1] != test_sample[col2]))","72662ae4":"train.target.describe()","ec4147a5":"fig, ax = plt.subplots()\nplt.scatter(range(train.shape[0]), np.sort(train.target.values));\nax.set_yscale('log')","eb8479e3":"int_cols = features.columns[features.dtypes == np.int64].values\nint_train = features[int_cols]","676930a1":"plt.figure(figsize=(5,10))\nplt.spy((int_train > 0).values);","7f707b36":"(int_train == 0).sum().sum() \/ int_train.size * 100","7b206d60":"nunique_int = int_train.nunique()\nfig, ax = plt.subplots()\nnunique_int.hist(bins=300, bottom=0.1)\nax.set_xscale('log')","433fb3b6":"float_cols = features.columns[features.dtypes == np.float64].values\nfloat_train = features[float_cols]","6d5b05d7":"float_train = train[float_cols]\nplt.figure(figsize=(5,10))\nplt.spy((float_train > 0).values);","cf148cbb":"(float_train == 0).sum().sum() \/ float_train.size * 100","b6350a04":"nunique_float = float_train.nunique()\nfig, ax = plt.subplots()\nnunique_float.hist(bins=300, bottom=0.1)\nax.set_xscale('log')","0288f6c2":"train.target = np.log1p(train.target)\n%time train.to_feather('train.feather')\n%time train = pd.read_feather('train.feather')","b6571361":"# No space left in Kaggle, but can be done locally\n# %time test.to_feather('test.feather')\n# %time test = pd.read_feather('test.feather')","0a58517b":"### No missing values; all values are nonnegative","39a76c88":"## Integer columns","5fdd5d60":"## Overview","739bbfa3":"### Very sparse data","cf36e789":"### Number of unique values (could be lots of categorical data)","d9a6770f":"## Float columns","5f865e8d":"### No zeros: starts from 30,000.","17c193b5":"### Duplicate rows: only two and with different targets","93973550":"### Almost all entries are zeros (very sparse data)","1f944c12":"### Columns carrying no information: 256 => can remove them right away","b47c13ce":"### Slightly less sparse than int","50623ea8":"# Read the data","83a326f1":"### 3147 integer columns, 1845 float columns (including target) and 1 string column (ID)","8ba97117":"### Duplicate columns: in training, but not in test","3d0651bd":"### Approximately linear on a log scale","1ea576f0":"# Look at the data","84605fa9":"## Target","6147209a":"> # Save the data in the feather format","7862f85f":"### The distribution of unique counts is notably different between floats and ints"}}