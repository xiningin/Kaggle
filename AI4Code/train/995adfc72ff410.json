{"cell_type":{"d60fd700":"code","7782a376":"code","281dcbc8":"code","17093206":"code","7585b18a":"code","9b03545e":"code","e99af7c5":"code","68b5c4e1":"code","5f55ddda":"code","0de38208":"code","99753d1d":"code","d7ba19dc":"code","748c2b29":"code","a163022a":"code","bb31d2e4":"code","1cacfc53":"code","360e2fd8":"code","19c5e584":"code","59ea2401":"code","93ef8945":"code","060d9a6d":"code","d0d12a20":"code","651853e7":"code","28479209":"code","6116adeb":"code","5099149c":"markdown","93ca269a":"markdown","e3104cf5":"markdown","8476d280":"markdown","d900c20b":"markdown","b5b4cddc":"markdown","479e59bf":"markdown"},"source":{"d60fd700":"# %% === < Global Setting: Time and Seed > ===\nimport time\nimport numpy as np\nUTC_time = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime()) # Colab UTC time\nlocal_time = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime(time.time()+8*3600)) # Colab for UTC+8\nprint(\"UTC Time:\", UTC_time)\nprint(\"Local Time (UTC+8):\", local_time)\nseed = int(round(1000000*np.random.random()))\nseed = 2021\nprint(\"Seed:\", seed)\nnp.random.seed(seed)","7782a376":"# %% === < Importing the raw data > ===\nimport pandas as pd\ndata_raw = pd.read_csv('\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')\nprint(data_raw.shape)\ndata_raw.head()","281dcbc8":"# %% === < Droping out the null data and useless variables > ===\ndata_raw[data_raw.isnull().any(axis=1)]","17093206":"print(data_raw[\"gender\"].value_counts())","7585b18a":"data_raw[data_raw['gender']=='Other']","9b03545e":"data_dropna = data_raw.dropna()\nprint(data_dropna.shape)\ndata_dropna = data_dropna.drop([3116])\nprint(data_dropna[\"gender\"].value_counts())\nprint(data_dropna.shape)\ndata_dropna = data_dropna.drop(columns=['id']) # dropout non-using column\nprint(data_dropna.shape)\ndata_dropna.head()","e99af7c5":"data_dropna[\"work_type\"] = data_dropna[\"work_type\"].astype('category')\ndata_dropna[\"smoking_status\"] = data_dropna[\"smoking_status\"].astype('category')\ndata_dropna[\"Residence_type\"] = data_dropna[\"Residence_type\"].astype('object')\ndata_dropna[\"hypertension\"] = data_dropna[\"hypertension\"].astype('object')\ndata_dropna[\"heart_disease\"] = data_dropna[\"heart_disease\"].astype('object')\ndata_dropna[\"stroke\"] = data_dropna[\"stroke\"].astype('int8')\nprint(data_dropna.dtypes)","68b5c4e1":"# %% === < Showing correlations between variables > ===\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.rcParams['axes.titlesize'] = 16\nplt.rcParams['axes.labelsize'] = 14\nplt.rcParams['xtick.labelsize'] = 12\nplt.rcParams['ytick.labelsize'] = 12\nplt.rcParams['legend.fontsize'] = 12\n\nplt.figure(figsize=(8,6))\nsns.heatmap(data_dropna.corr(), cmap=\"coolwarm\", annot=True, vmin=-1, vmax=1, fmt='.2g')\nplt.title('Correlation of Continuous Variables')\n# plt.savefig(output_folder+'Correlation of Variables.png', dpi=300)","5f55ddda":"data_conti = data_dropna.select_dtypes(include=['float64']).copy()\ndata_conti.head()","0de38208":"# %% === < Drawing violinplots of continuous variables > ===\nfor idx,feature in enumerate(data_conti):\n  plt.figure(figsize=(8,6))\n  sns.violinplot(y = data_conti[feature], x = data_dropna['stroke'], palette=\"Set3\")\n  plt.title('Violinplot of %s'%feature)\n#   plt.savefig(output_folder+'Violinplot of %s.png'%feature, dpi=300)","99753d1d":"data_obj = data_dropna.select_dtypes(include=['object']).copy()\ndata_obj.head()","d7ba19dc":"# %% === < Drawing boxplots of catergorical variables > ===\nfor idx,feature in enumerate(data_obj):\n  plt.figure(figsize=(8,6))\n  sns.barplot(x = data_obj[feature], y = data_dropna['stroke'])\n  plt.title('Barplot of %s'%feature)\n#   plt.savefig(output_folder+'Barplot of %s.png'%feature, dpi=300)","748c2b29":"print(data_obj[\"ever_married\"].value_counts())\nprint()\nprint(data_obj[\"gender\"].value_counts())","a163022a":"cleanup_vars = {\"ever_married\": {\"No\":0,\"Yes\":1},\n         \"gender\": {\"Male\":0,\"Female\":1}}\ndata_obj = data_obj.replace(cleanup_vars).astype('object')\ndata_obj.head()","bb31d2e4":"from sklearn.preprocessing import LabelEncoder\nlabel_vars = [\"Residence_type\"]\ndata_obj[label_vars] = data_obj[label_vars].apply(LabelEncoder().fit_transform).astype('object')\ndata_obj.head()","1cacfc53":"data_catg = data_dropna.select_dtypes(include=['category']).copy()\ndata_catg.head()","360e2fd8":"# %% === < Drawing boxplots of catergorical variables > ===\nfor idx,feature in enumerate(data_catg):\n  plt.figure(figsize=(8,6))\n  sns.barplot(x = data_catg[feature], y = data_dropna['stroke'])\n  plt.title('Barplot of %s'%feature)\n#   plt.savefig(output_folder+'Barplot of %s.png'%feature, dpi=300)","19c5e584":"import pandas as pd\ndata_dummy = pd.get_dummies(data_catg)\ndata_dummy.head()","59ea2401":"import pandas as pd\ndata = pd.concat([data_conti,data_obj,data_dummy,data_dropna[\"stroke\"]], axis=1)\nprint(data.shape)\ndata.head()\n# data.to_excel(output_folder+'Data_StatisticsDummy.xlsx',sheet_name='dummy') ","93ef8945":"from sklearn.model_selection import train_test_split # Import train_test_split function\n\ndropout_cols = ['stroke']\nX = data.drop(columns=dropout_cols) # Predictors\ny = data['stroke'] # Target variable\nprint('Shape of original dummy coding data X and y: ',X.shape,y.shape)\nprint()\n\n# === Spliting dataset into training set and test set\nX_train_raw, X_test, y_train_raw, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\nprint('Shape of testing data X and y: ',X_test.shape,y_test.shape)\nprint('Testing data - No stroke: %d'%y_test[y==0].shape)\nprint('Testing data - Yes stroke: %d'%y_test[y==1].shape)\nprint()\nprint('Shape of training data X and y: ',X_train_raw.shape,y_train_raw.shape)\nprint('Before over sampling - No stroke: %d'%y_train_raw[y==0].shape)\nprint('Before over sampling - Yes stroke: %d'%y_train_raw[y==1].shape)\nprint()","060d9a6d":"# === Over sampling to balance the different labels of data\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import ADASYN\nfrom imblearn.over_sampling import BorderlineSMOTE\nfrom imblearn.over_sampling import SVMSMOTE\n# from imblearn.over_sampling import SMOTENC\n\nresampling_method = BorderlineSMOTE\nX_train, y_train = resampling_method(sampling_strategy='not majority').fit_resample(X_train_raw,y_train_raw)\nprint('Shape of random over sampling dummy coding data X and y: ',X_train.shape,y_train.shape)\nprint('After over sampling - No stroke: %d'%y_train[y_train==0].shape)\nprint('After over sampling - Yes stroke: %d'%y_train[y_train==1].shape)\nprint()","d0d12a20":"# %% === < Classifiers: Predicted Results and Confusion Matrices > ===\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n\nclassifiers = [\n  LogisticRegression(),\n  KNeighborsClassifier(),\n  GaussianNB(),\n  SVC(probability=True), \n  DecisionTreeClassifier(), \n  QuadraticDiscriminantAnalysis(),\n  RandomForestClassifier(), \n  AdaBoostClassifier(),\n  MLPClassifier()\n  ]\n\nresult_table = pd.DataFrame(columns=['Classifiers','Accuracy','F1','Precision','Recall','fpr','tpr','AUC'])\n\nfor classifier in classifiers:\n  classifier_name = classifier.__class__.__name__\n  model = classifier.fit(X_train, y_train)\n  y_pred = model.predict(X_test)\n  y_score = model.predict_proba(X_test)[::,1]\n  # === Confusion Matrix\n  plt.figure(figsize=(8,7))\n  sns.heatmap(confusion_matrix(y_test,y_pred,normalize=None), annot=True, cmap='YlGnBu')\n  plt.ylabel('True label', fontsize=14)\n  plt.xlabel('Predicted label', fontsize=14)\n  plt.title('Confusion Matrix (%s)'%classifier_name, fontsize=14)\n#   plt.savefig(output_folder+'Confusion Matrix (%s).png'%classifier_name, dpi=300)\n  plt.show()\n  # === Normalized Confusion Matrix\n  plt.figure(figsize=(8,7))\n  sns.heatmap(confusion_matrix(y_test,y_pred,normalize='true'), annot=True, cmap='Blues', vmin=0, vmax=1)\n  plt.ylabel('True label')\n  plt.xlabel('Predicted label')\n  plt.title('Normalized Confusion Matrix (%s)'%classifier_name)\n#   plt.savefig(output_folder+'Normalized Confusion Matrix (%s).png'%classifier_name, dpi=300)\n  plt.show()\n  # === Result\n  accuracy = accuracy_score(y_test,y_pred)\n  f1 = f1_score(y_test,y_pred)\n  precision = precision_score(y_test,y_pred)\n  recall = recall_score(y_test,y_pred)\n  fpr, tpr, _ = roc_curve(y_test, y_score)\n  auc = roc_auc_score(y_test, y_score)\n  # === Table of Result\n  result_table = result_table.append({\n      'Classifiers':classifier_name,\n      'Accuracy':accuracy,\n      'F1':f1,\n      'Precision':precision,\n      'Recall':recall,\n      'fpr':fpr,\n      'tpr':tpr,\n      'AUC':auc\n      },\n    ignore_index=True\n    )\nresult_table.set_index('Classifiers', inplace=True)","651853e7":"# %% === < Predicted Results Output > ===\ndf_result = result_table[['Accuracy','F1','Precision','Recall']]\ndf_result = df_result.round(4)\nprint(df_result)\n# df_result.to_excel(output_folder+'Result_%s.xlsx'%local_time,sheet_name='result') ","28479209":"# %% === < ROC Curves to compare different models > ===\nimport numpy as np\n\nfig = plt.figure(figsize=(10,9))\n\nfor idx in result_table.index:\n  plt.plot(\n    result_table.loc[idx]['fpr'], \n    result_table.loc[idx]['tpr'], \n    label=\"{}, AUC={:.4f}\".format(idx, result_table.loc[idx]['AUC'])\n    )\n    \nplt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\nplt.xticks(np.arange(0.0, 1.1, step=0.1))\nplt.yticks(np.arange(0.0, 1.1, step=0.1))\nplt.xlabel(\"Flase Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title('Comparison of ROC Curves')\nplt.legend(prop={'size':12}, loc='lower right')\n# plt.savefig(output_folder+'ROC Curves %s.png'%local_time, dpi=300)","6116adeb":"# %% === < Finish Time > ===\nimport time\nUTC_time = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime()) # Colab UTC time\nlocal_time = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime(time.time()+8*3600)) # Colab for UTC+8\nprint(\"UTC Time:\", UTC_time)\nprint(\"Local Time (UTC+8):\", local_time)","5099149c":"## Data Importing and Preprocessing\n\nUsing Pandas to import data and doing preprocessing","93ca269a":"## Model Establishment and Evaluation\n\nUsing some classification algorithms to classify\n\nApplying some evaluation indexes to check the fitting results and predicted results","e3104cf5":"## Data preprocessing and Visualization\n\nUsing Pandas, Matplolib, Seaborn to prepare date for analysis and visualize","8476d280":"## Rebuilding Data (concat)\n\nIf neccessary, droping out useless variables","d900c20b":"# Task Description\n\nDataset: Stroke Prediction Dataset\n\nKaggle: https:\/\/www.kaggle.com\/fedesoriano\/stroke-prediction-dataset","b5b4cddc":"## Data Balance\n\nUsing re-sampling method to balance different targets\n\nReference (Imbalanced-Learn):\n\n* https:\/\/imbalanced-learn.org\/stable\/index.html","479e59bf":"### One-Hot-Encoding \n\nUsing one-hot-encoding (dummy coding) to sparse data\n\nFor preparing to train models\n\nReference:\n\n* https:\/\/medium.com\/@PatHuang\/%E5%88%9D%E5%AD%B8python%E6%89%8B%E8%A8%98-3-%E8%B3%87%E6%96%99%E5%89%8D%E8%99%95%E7%90%86-label-encoding-one-hot-encoding-85c983d63f87\n\n* https:\/\/www.kaggle.com\/getting-started\/27270\n\n* https:\/\/pbpython.com\/categorical-encoding.html"}}