{"cell_type":{"3d1922c9":"code","e5343ad8":"code","1b69393e":"code","2e6175eb":"code","17a78adc":"code","5de2accd":"code","f797d1c0":"code","61cda922":"code","3fc3655a":"code","735daef0":"code","cd1ba95d":"code","0ebbc94d":"code","253cd3d0":"code","6e013cd4":"code","9d003408":"code","2cd2206e":"code","6b55ea01":"code","d4c87a05":"code","a620e37d":"code","a24d125c":"code","c31e5eec":"code","2633ce4a":"code","870404f7":"markdown","551007f2":"markdown","f9793ec3":"markdown","81023365":"markdown"},"source":{"3d1922c9":"import os\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import transforms\nimport torchvision\n\nimport torch\nfrom torch import nn as nn\nfrom torch.nn import functional as f\nfrom torch.optim import Adam, SGD\nfrom torch.optim.lr_scheduler import MultiStepLR, StepLR\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nfrom torch.utils.tensorboard import SummaryWriter\n\nfrom PIL import Image\nfrom cv2 import resize, imread, CascadeClassifier, rectangle, COLOR_BGR2GRAY\nfrom cv2.data import haarcascades\nimport cv2\nimport xml.etree.ElementTree as ET\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.neighbors import KNeighborsClassifier\n\nimport gc\n\nplt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'\n\n%matplotlib inline","e5343ad8":"root = \"\/kaggle\/input\/face-mask-detection\/\"\nSIZE = 64\ninitial_SIZE = (512, 366)","1b69393e":"def label_generator():\n    \n    for _, _, filename in os.walk(root + \"annotations\"):\n        \n        for file in filename:\n\n            tree = ET.parse(root + 'annotations\/' + file)\n            tree_root = tree.getroot()\n\n            title = tree_root.find(\"filename\").text\n            positions = []\n            \n            for obj in tree_root.findall(f\"object\"):\n                \n                name = obj.find(\"name\").text\n                positions.append({'name': name, 'coords': {}})\n                \n                for i, p in enumerate(obj.findall(\"bndbox\/\/*\")):\n                    if i % 4 == 0:\n                        positions[-1]['coords']['x_m'] = int(p.text)\n                    if i % 4 == 2:\n                        positions[-1]['coords']['x_M'] = int(p.text)\n                    if i % 4 == 1:\n                        positions[-1]['coords']['y_m'] = int(p.text)\n                    if i % 4 == 3:\n                        positions[-1]['coords']['y_M'] = int(p.text)\n            \n            yield title, positions\n\n\n\n\ndef generate_pairs(generator):\n    \n    codes = {\"with_mask\": 1, \"without_mask\": 0, \"mask_weared_incorrect\": 1}\n    \n    for i, data in enumerate(generator()):\n        \n        title, label_coords = data[0], data[1]\n        mask = np.asarray(Image.open(root + 'images\/' + title)).transpose(2, 1, 0)[:3, :, :]\n        \n        for pair in label_coords:\n            label, coords = pair['name'], pair['coords']                                                             \n            submask = mask[:, coords['x_m']: coords['x_M'], coords['y_m']: coords['y_M']] \/ 255\n            yield submask, torch.tensor(codes[label])\n\ndef detect_face_(path):\n    \n    face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n    image = imread(path)\n    #image = resize(image, (64, 64))\n    gray = cv2.cvtColor(image, COLOR_BGR2GRAY)\n    args = face_detector.detectMultiScale(gray, 1.1, 1)\n    print(args)\n    args = args[1]\n    x, y, w, h = args\n    face = image[200: 500, 400: 700]\n    face = resize(face, (SIZE, SIZE)) \/ 255\n    plt.imshow(face)\n    #assert 0 == 1\n    return face\n        \ndef load_data(p):\n    to_apply = [transforms.RandomRotation(90), transforms.RandomHorizontalFlip(1)]\n    X_mask, X_no_mask, Y_mask, Y_no_mask = [], [], [], []\n    \n    split_index = 0\n    size = int(len(list(generate_pairs(label_generator))) * (1 - p))\n    \n    for i, (face, label) in enumerate(generate_pairs(label_generator)):\n        \n        face = face.transpose(1, 2, 0)\n        face = resize(np.float32(face), (SIZE, SIZE))\n        face = face.transpose(2, 1, 0)\n        face = torch.Tensor(face)\n        split_index += 1\n\n        if label == 0:\n            for transform in to_apply:\n                Y_mask.append(label)\n                X_mask.append(transform(face))\n                split_index += 1\n\n            Y_mask.append(label)\n            X_mask.append(face)\n            \n        else:\n            X_no_mask.append(face)\n            Y_no_mask.append(label)\n    \n    \n    return torch.stack(X_mask), torch.stack(Y_mask), torch.stack(X_no_mask), torch.stack(Y_no_mask)","2e6175eb":"def generate_closest_faces_dataset(X, y):\n    \n    X_demasked = X[y == 0]\n    classifier = KNeighborsClassifier(n_neighbors=1)\n    X_closest = []\n    \n    for i, x in enumerate(X_demasked):\n        X_demasked_cleared = torch.cat((X_demasked[: i], X_demasked[i + 1: ]))\n        diff_x = ((X_demasked_cleared - x) ** 2).sum((1, 2, 3))\n        close_index = torch.argmin(diff_x, axis=0)\n        if i == 10:\n            return x, X_demasked_cleared[close_index]","17a78adc":"x, close = generate_closest_faces_dataset(X_val, Y_val)\nfig, axes = plt.subplots(1, 2)\naxes[0].imshow(x.resize(64, 64, 3))\naxes[1].imshow(close.resize(64, 64, 3))","5de2accd":"x.size(), close.size()","f797d1c0":"test_new(model, \"\/kaggle\/input\/masktest3\/mask-3.jpg\")","61cda922":"X_mask, Y_mask, X_no_mask, Y_no_mask = load_data(0.2)","3fc3655a":"len(X_mask), len(X_no_mask)","735daef0":"hparams = {\n    \n    \"lr_1\": 1e-3,\n    \"lr_2\": 1e-5,\n    \"momentum\": 0.9,\n    \"epochs\": 15,\n    \"batch_size\": 25,\n    \"p\": 0.5,\n    \"activation\": ['ReLU', 'LeakyReLU' ,'ELU', 'PReLU']\n    \n}","cd1ba95d":"len(X_mask), len(X_no_mask)\nsize_mask = 1500\nsize_no_mask = 2000\n\nindices_train = np.random.permutation(size_mask + size_no_mask)\nindices_val = np.random.permutation(len(X_mask) + len(X_no_mask) - size_mask - size_no_mask)\n\nX_train = torch.cat([X_mask[:size_mask], X_no_mask[:size_no_mask]])\nX_val = torch.cat([X_mask[size_mask:], X_no_mask[size_no_mask:]])\nY_train = torch.cat([Y_mask[:size_mask], Y_no_mask[:size_no_mask]])\nY_val = torch.cat([Y_mask[size_mask:], Y_no_mask[size_no_mask:]])\n\nX_train, Y_train = X_train[indices_train], Y_train[indices_train]\nX_val, Y_val = X_val[indices_val], Y_val[indices_val]","0ebbc94d":"batch_size = hparams['batch_size']\n\ndataset_train = TensorDataset(X_train, Y_train)\ndataset_val = TensorDataset(X_val, Y_val)\n\ndataloader_train = DataLoader(dataset_train, batch_size)\ndataloader_val = DataLoader(dataset_val, batch_size)\n\ndataloaders = {\"train\": dataloader_train, \"val\": dataloader_val}","253cd3d0":"for batch in dataloader_train:\n    print(batch[1])","6e013cd4":"class DeviceDataLoader():\n    \n    def __init__(self, dataloader, device):\n        \n        self.dataloader = dataloader\n        self.device = device\n        \n    def __iter__(self):\n        \n        for data in self.dataloader:\n            yield to_device(data, self.device)\n    \n    def __len__(self):\n        \n        return len(self.dataloader)\n    \ndef to_device(data, device):\n    \n    if isinstance(data, (list, tuple)):\n        return [to_device(x, device) for x in data]\n    \n    return data.to(device, non_blocking=True)\n    \n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")","9d003408":"def accuracy_segmentation(y_output_, y):\n    \n    y_output = torch.argmax(y_output_, 1)\n    y_masked = y[y > -2]\n    y_output_masked = y_output[y > -2]\n    qualyfying = y_masked[y_masked == y_output_masked]\n    accuracy = len(qualyfying) \/ len(y_masked)\n    \n    return accuracy\n\ndef accuracy(y_output_, y):\n    \n    y_output = torch.argmax(y_output_, 1)\n    qualyfying = y[y == y_output]\n    accuracy = len(qualyfying) \/ len(y)\n    \n    return accuracy\n\ndef recall(y_output_, y, label_forbid=0, threshold=0.5):\n    \n    y_output = torch.argmax(torch.where(y_output_ >= threshold, 1, 0), 1)\n    y_mask = (y != label_forbid)\n    mask_q = (y[y_mask] == y_output[y_mask])\n    qualyfying = y_output[y_mask][mask_q]\n    \n    return len(qualyfying) \/ len(y[y_mask]) if len(y[y_mask]) else 1\n\n\ndef precision(y_output_, y, label_forbid=0, threshold=0.5):\n    \n    y_output = torch.argmax(torch.where(y_output_ >= threshold, 1, 0), 1)\n    y_mask = (y_output != label_forbid)\n    mask_q = (y[y_mask] == y_output[y_mask])\n    qualyfying = y[y_mask][mask_q]\n    \n    return len(qualyfying) \/ len(y[y_mask]) if len(y[y_mask]) else 1\n\n\ndef f1_score(y_output, y, label_forbid=0):\n    \n    eps = 1e-9\n    rec = recall(y_output, y)\n    prec = precision(y_output, y)\n    \n    return (2 * rec * prec) \/ (rec + prec + eps)    ","2cd2206e":"def update_logs(arr, item, iteration):\n    \n    if iteration == 0:\n        arr.append(0)\n        \n    arr[-1] = ((iteration) \/ (iteration + 1) * arr[-1]) + (1) \/ (iteration + 1) * item\n    return arr\n\ndef validation_step(model, batch, criterion):\n    \n    with torch.no_grad():\n        \n        x, y = batch\n        x, y = x.to(device), y.to(device).long()\n        output = model(x)\n        \n        loss = criterion(output, y)\n        acc = accuracy(output, y)\n        tp = recall(output, y, label_forbid=0)\n        f1 = f1_score(output, y)\n        \n    return loss, acc, tp, f1\n        \n\ndef training_step(model, batch, criterion, optimizer):\n    \n    x, y = batch\n    x, y = x.to(device), y.to(device).long()\n\n    optimizer.zero_grad()\n\n    output = model(x)\n    y = y.long()\n    loss = criterion(output, y)\n    acc = accuracy(output, y)\n    tp = recall(output, y, 0.5)\n    f1 = f1_score(output, y)\n\n    loss.backward()\n    optimizer.step()\n    \n    return loss, acc, tp, f1\n\ndef train(model, hparams, dataloaders, patience, logs=None):\n    \n    current = 0\n    model.train()\n    dataloader_train, dataloader_val = dataloaders['train'], dataloaders['val']\n    \n    lr, momentum, epochs = hparams['lr_1'], hparams['momentum'], hparams['epochs']\n\n    if not logs:\n        running_train_accuracy = []\n        running_train_recall = []\n        running_train_fscore = []\n        running_train_loss = []\n\n        running_val_accuracy = []\n        running_val_recall = []\n        running_val_loss = []\n        running_val_fscore = []\n    else:\n        train_stats, val_stats = logs['train'], logs['validation']\n        running_train_accuracy = train_stats['accuracy']\n        running_train_recall = train_stats['recall']\n        running_train_fscore = train_stats['f1']\n        running_train_loss = train_stats['loss']\n        \n        running_val_accuracy = val_stats['accuracy']\n        running_val_recall = val_stats['recall']\n        running_val_fscore = val_stats['f1']\n        running_val_loss = val_stats['loss']\n     \n    criterion = nn.CrossEntropyLoss(ignore_index=-1, weight=torch.FloatTensor([1, 1]).to(device))\n    optimizer = Adam([{\"params\": model.encoder.parameters(), \"lr\": 1e-5,\n                      \"params\": model.decoder.parameters(), \"lr\": lr,\n                      \"params\": model.classifier.parameters(), \"lr\": 1e-5}], lr=lr)\n    #optimizer = Adam(params=model.parameters(), lr=lr)\n    scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n    \n    best_model = model\n    current_best_score = 0\n    \n    for epoch in range(epochs):\n        \n        current += 1\n        \n        for i, batch in enumerate(dataloader_train):\n            \n            loss, acc, tp, f1 = training_step(model, batch, criterion, optimizer)\n            running_train_accuracy = update_logs(running_train_accuracy, acc, i)\n            running_train_recall = update_logs(running_train_recall, tp, i)\n            running_train_loss = update_logs(running_train_loss, loss.detach().item(), i)\n            running_train_fscore = update_logs(running_train_fscore, f1, i)\n            \n        for i, batch in enumerate(dataloader_val):\n            \n            loss, acc, tp, f1 = validation_step(model, batch, criterion)\n            running_val_accuracy = update_logs(running_val_accuracy, acc, i)\n            running_val_recall = update_logs(running_val_recall, tp, i)\n            running_val_loss = update_logs(running_val_loss, loss.detach().item(), i)\n            running_val_fscore = update_logs(running_val_fscore, f1, i)\n            \n            \n        scheduler.step() \n        value = round(running_val_recall[-1], 5)\n        \n        if value > current_best_score:\n            current_best_score = value  \n            best_model = model\n            torch.save(model.state_dict(), f\"best_model_epoch_{epoch}\")\n            current = 0\n        else:\n            current += 1\n            \n        if current == patience:\n            break\n            \n        print(f\"epoch {epoch}| train loss: {round(running_train_loss[-1], 5)}, train accuracy: {round(running_train_accuracy[-1], 5)}, val loss: {round(running_val_loss[-1], 5)}, val accuracy: {round(running_val_accuracy[-1], 5)}\")\n        print(f\"train recall score: {round(running_train_recall[-1], 5)}, val recall score: {round(running_val_recall[-1], 5)}\")    \n        print(f\"train f1 score: {round(running_train_fscore[-1], 5)}, val f1 score: {round(running_val_fscore[-1], 5)}\")\n    \n    stats = {\"train\": {\"loss\": running_train_loss, \"accuracy\": running_train_accuracy, \n               \"recall\": running_train_recall, \"f1\": running_train_fscore},\n    \"validation\": {\"loss\": running_val_loss, \"accuracy\": running_val_accuracy, \n               \"recall\": running_val_recall, \"f1\": running_val_fscore}}\n    \n    return best_model, stats","6b55ea01":"#class Upsampling(nn.Module)\nclass SimpleLeNet(nn.Module):\n    \n    def __init__(self, haparams):\n        \n        super().__init__()\n        layers = []\n        \n        layers.append(nn.Conv2d(3, 3, 3, 2, 1))\n        layers.append(nn.BatchNorm2d(3))\n        layers.append(nn.ReLU())\n        \n        layers.append(nn.Conv2d(3, 16, 5, 1, 0))\n        layers.append(nn.BatchNorm2d(16))\n        layers.append(nn.ReLU())\n        layers.append(nn.AvgPool2d(3, 2, 1))\n        \n        layers.append(nn.Conv2d(16, 32, 3, 2, 1))\n        layers.append(nn.BatchNorm2d(32))\n        layers.append(nn.ReLU())\n        \n        layers.append(nn.Flatten())\n        layers.append(nn.Linear(1568, 100))\n        layers.append(nn.Linear(100, 2))\n        \n        layers.append(nn.Softmax())\n        \n        self.model = nn.Sequential(*layers)\n        \n    def forward(self, x):\n        \n        x = self.model(x)\n        return x\n\n\nclass ModelPretrainedEncoder(nn.Module):\n    \n    def __init__(self, hparams):\n        \n        p = hparams['p']\n        super().__init__()\n        layers = []\n    \n        layers.append(nn.ConvTranspose2d(512, 256, 4, 4, 0))\n        layers.append(nn.BatchNorm2d(256))\n        layers.append(nn.ReLU())\n        layers.append(nn.Dropout2d(p))\n        \n        layers.append(nn.ConvTranspose2d(256, 32, 4, 4, 0))\n        layers.append(nn.BatchNorm2d(32))\n        layers.append(nn.ReLU())\n        \n        layers.append(nn.Conv2d(32, 3, 1, 1, 0))\n        layers.append(nn.BatchNorm2d(3))\n        layers.append(nn.ReLU())\n        \n        flatten = nn.Flatten()\n        classifier_1 = nn.Linear(3 * 4096, 100)\n        act_1 = nn.ReLU()\n        dp_1 = nn.Dropout(p)\n        classifier_2 = nn.Linear(100, 2)\n        \n        pretrained = torchvision.models.vgg16(pretrained=True)\n        \n        self.classifier = nn.Sequential(flatten, classifier_1, act_1, classifier_2)\n        self.encoder = nn.Sequential(*list(pretrained.features)[:-1])\n        self.decoder = nn.Sequential(*layers)\n        \n    def forward(self, x):\n        \n        x = self.encoder(x)\n        x = self.decoder(x)\n\n        x = self.classifier(x)\n        x = f.softmax(x)\n\n        return x\n        ","d4c87a05":"model = ModelPretrainedEncoder(hparams)\nmodel = model.to(device)\nmodel, stats = train(model, hparams, dataloaders, 20)","a620e37d":"def plot_ROC(model, dataset, step=0.05):\n    \n    model.eval()\n    dataloader = DataLoader(dataset, shuffle=True, batch_size=1)\n    \n    y_outputs = []\n    ys = []\n    \n    fprs, tprs = [], []\n    \n    with torch.no_grad():\n        for batch in dataloader:\n            \n            x, y = batch\n            ys.append(y)\n            x, y = x.to(device), y.to(device)\n            \n            y_outputs.append(model(x).cpu().numpy())\n        \n        y_outputs, y = torch.Tensor(y_outputs), torch.Tensor(ys)\n        y_outputs = y_outputs.view((y_outputs.size()[0], 2))\n        args = np.arange(0, 1, step)\n\n        fprs = [precision(y_outputs, y, 1, arg) for i, arg in enumerate(args)]\n        tprs = [precision(y_outputs, y, 0, arg) for i, arg in enumerate(args)]\n            \n    plt.figure(figsize=(16, 16))\n    #plt.plot(np.arange(0, 1, step), np.arange(0, 1, step), linestyle=\"dashed\")\n    plt.plot(fprs, tprs)\n    \n\ndef plot_training_curves(stats):\n    \n    train_stats, val_stats = stats['train'], stats['validation']\n    \n    fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n    \n    axes[0, 0].plot(train_stats['loss'])\n    axes[0, 0].plot(val_stats['loss'])\n    axes[0, 0].set_title(\"loss\")\n    axes[0, 0].legend((\"train\", \"validation\"))\n    \n    axes[0, 1].plot(train_stats['accuracy'])\n    axes[0, 1].plot(val_stats['accuracy'])\n    axes[0, 1].set_title(\"Accuracy\")\n    axes[0, 1].legend((\"train\", \"validation\"))\n    \n    axes[1, 0].plot(train_stats['recall'])\n    axes[1, 0].plot(val_stats['recall'])\n    axes[1, 0].set_title(\"Recall\")\n    axes[1, 0].legend((\"train\", \"validation\"))\n    \n    axes[1, 1].plot(train_stats['f1'])\n    axes[1, 1].plot(val_stats['f1'])\n    axes[1, 1].set_title(\"F1\")\n    axes[1, 1].legend((\"train\", \"validation\"))\n\ndef visualize_results(model, dataset, count):\n    \n    model.eval()\n    dataloader = DataLoader(dataset, shuffle=True, batch_size=1)\n    with torch.no_grad():\n        fig, axes = plt.subplots(int(count \/\/ 2), 2, figsize=(12, 12))\n        for i, data in enumerate(dataloader):\n            \n            x, y = data\n            x, y = x.to(device), y.to(device)\n            output = model(x)\n\n            output = torch.argmax(output, 1)\n            codes = {1: \"with mask\", 0: \"without mask\"}\n            title = codes[output.item()]\n            \n            axes[int(i \/\/ 2), i % 2].imshow(x.cpu().numpy()[0].transpose(1, 2, 0))\n            axes[int(i \/\/ 2), i % 2].set_title(title)\n            axes[int(i \/\/ 2), i % 2].tick_params(    \n                axis='both',        \n                which='both',   \n                bottom=False,     \n                top=False,       \n                labelbottom=False)\n            plt.axis(\"off\")\n            \n            if i == count - 1:\n                break\n                \ndef test_new(model, path):\n\n    fig, axes = plt.subplots(1, 1, figsize=(12, 12))\n    codes = {1: \"with mask\", 0: \"without mask\"}\n    face = detect_face_(path)\n    output = model(torch.Tensor(face).view(1, face.shape[2], face.shape[0], face.shape[1]).to(device))\n    print(output)\n    output = torch.argmax(output, 1)\n    title = codes[output.item()]\n    axes.imshow(face)\n    axes.set_title(title)\n    axes.tick_params(    \n                axis='both',        \n                which='both',   \n                bottom=False,     \n                top=False,       \n                labelbottom=False)","a24d125c":"plot_training_curves(stats)","c31e5eec":"visualize_results(model, dataset_val, 10)","2633ce4a":"plot_ROC(model, dataset_val, step=0.05)","870404f7":"<h1>Metrics<\/h1>","551007f2":"<h1>Training\/Hypertuning<\/h1>","f9793ec3":"<h1>Loading data<\/h1>","81023365":"<h1>Visualizers<\/h1>"}}