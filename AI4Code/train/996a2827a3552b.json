{"cell_type":{"27717fb8":"code","40be16f1":"code","21de12fc":"code","7143b6aa":"code","04c11cda":"code","2e430aec":"code","dfa7332f":"code","2006e84b":"code","80563290":"code","1e6c36a1":"code","63c5eac4":"code","750c235b":"code","bf3c635b":"code","d42008dc":"code","3bff95f0":"code","e7da7758":"code","0ffa1e95":"code","2fc57fe5":"markdown","4bf384e5":"markdown","ea6b74fe":"markdown","ce5b8350":"markdown","515829bd":"markdown","0b4e390f":"markdown"},"source":{"27717fb8":"# Import the standard libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","40be16f1":"# Define the constance\n\nFOLDER_ = 'Casting CNN'\nBATCH_SIZE_ = 16\nCOLOR_SPECTRUM_ = (1)          # 1 if B&W, 3 if color\nIMG_SIZE_ = (300, 300)","21de12fc":"# import Keras Modules\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout","7143b6aa":"# Initialize the CNN\n\nclassifier = Sequential()","04c11cda":"# Adding the layers\ninput_shape_ = (300,300) + (COLOR_SPECTRUM_, )\nclassifier.add(Conv2D(BATCH_SIZE_, (3,3), input_shape=input_shape_, activation='relu'))\nclassifier.add(MaxPooling2D(pool_size=(2,2)))\n\n# Add a second layer\nclassifier.add(Conv2D(BATCH_SIZE_, (3,3), activation='relu'))\nclassifier.add(MaxPooling2D(pool_size=(2,2)))\n\n# Flattening\nclassifier.add(Flatten())","2e430aec":"# ANN Layer\n\n# Add a second hidden layer\nclassifier.add(Dense(units = 128, activation='relu'))\nclassifier.add(Dropout(rate=.2))\n\n# Add a second hidden layer\nclassifier.add(Dense(units = 128, activation='relu'))\nclassifier.add(Dropout(rate=.2))\n\n# Add a third hidden layer\nclassifier.add(Dense(units = 64, activation='relu'))\nclassifier.add(Dropout(rate=.2))\n\nclassifier.add(Dense(units = 1, activation='sigmoid'))","dfa7332f":"classifier.compile(optimizer= 'adam',\n                   loss='binary_crossentropy',\n                   metrics=['accuracy'])","2006e84b":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        vertical_flip=True,\n        rotation_range=25)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)","80563290":"from pathlib import Path\n\ndataset_folder =  Path('\/kaggle\/input\/real-life-industrial-dataset-of-casting-product\/casting_data')\n\nif dataset_folder.exists():\n    print(f'[-------]\\nConnect the dataset folder at \\n\\t{str(dataset_folder)}\\n[-------]')\nelse:\n    print(f'[*******]\\nConnecting the dataset folder failed \\n[*******]')\n","1e6c36a1":"training_files = dataset_folder \/ 'train\/'\ntest_files = dataset_folder \/ 'test\/'\n\ntraining_set= train_datagen.flow_from_directory(\n        training_files,\n        target_size=(300,300),\n        batch_size=BATCH_SIZE_,\n        class_mode='binary',\n        color_mode=\"grayscale\")\n\ntest_set = test_datagen.flow_from_directory(\n        test_files,\n        target_size= (300,300),\n        batch_size=BATCH_SIZE_,\n        class_mode='binary',\n        color_mode=\"grayscale\")","63c5eac4":"training_size = len(training_set)\ntest_size = len(test_set)\n\nprint(f'{training_size} * {BATCH_SIZE_} = {training_size * BATCH_SIZE_}')\nprint(f'{test_size} * {BATCH_SIZE_} = {test_size * BATCH_SIZE_}')","750c235b":"\n\n# get the number of CPU threads\n\nimport multiprocessing\nimport tensorflow as tf\n\ndef set_workers(local = False):\n    \n    catcha =''\n    workers = multiprocessing.cpu_count()\n    \n    if local:\n        workers -= 1 \n        catcha = 'locally '\n        \n    gpus = tf.config.experimental.list_physical_devices('GPU')\n\n    print(f\"Working with {workers} CPU threads {catcha}and with {len(gpus)} GPU\" )\n    \n    return workers\n\nworkers_ = set_workers()\n","bf3c635b":"classifier.fit_generator(\n        training_set,\n        steps_per_epoch=training_size,\n        epochs=25,\n        validation_data=test_set,\n        validation_steps=test_size,\n        use_multiprocessing=True,\n        workers=workers_)","d42008dc":"classifier.summary()","3bff95f0":"import seaborn as sns\n\nplt.rcParams[\"figure.figsize\"] = (16,9)\nsns.set(style=\"darkgrid\")\n\ndata = pd.DataFrame(classifier.history.history)\n\nplt.title('Visualisation of the training')\nplt.ylabel('Loss\/Accuracy')\nplt.xlabel('# Epochs')\nsns.lineplot(data=data, linewidth=3.5)","e7da7758":"from sklearn.metrics import classification_report, confusion_matrix\n\ntest_set.reset\ny_pred = classifier.predict_generator(generator = test_set, \n                                      steps = test_size,\n                                      use_multiprocessing=True,\n                                        workers=workers_)\n\ny_pred = y_pred >= 0.5\n\nprint(\"[------]\\nConfusion Matrix\")\nprint(confusion_matrix(test_set.classes[test_set.index_array], y_pred))\nprint(\"[------]\")","0ffa1e95":"target_names = ['Defective parts', 'Good parts']\n\nprint('[------]\\nClassification Report')\nprint(classification_report(test_set.classes[test_set.index_array], y_pred, target_names=target_names))\nprint(\"[------]\")","2fc57fe5":"## Performance review","4bf384e5":"## Importing images","ea6b74fe":"# Building the CNN","ce5b8350":"### Confusion Matrix","515829bd":"### Discussion: Image Size\nAs (i.) we are working with a GPU and (ii.) the image are quite small (300x300 px), we can use Input = Image size.","0b4e390f":"### Training performance"}}