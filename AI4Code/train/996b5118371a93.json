{"cell_type":{"1b0b9e6a":"code","133fbbdf":"code","bdd398ff":"code","5c5b34c2":"code","c7573d89":"code","527987d8":"code","ada6107e":"code","24ca4bf0":"code","253cbfba":"code","e96572cb":"code","40c6225b":"code","5ef17a2e":"code","0d628ba6":"code","6dda0158":"code","5892b0f1":"markdown"},"source":{"1b0b9e6a":"# Importing import modules\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom keras import optimizers\nimport matplotlib.pyplot as plt\nfrom skimage import io\nprint(os.listdir(\"..\/input\/data\/data\"))","133fbbdf":"# Train, test and validation directories\ntrain_dir = \"..\/input\/data\/data\/train\"\nval_dir = \"..\/input\/data\/data\/validation\"\ntest_dir = \"..\/input\/data\/data\/test\"","bdd398ff":"# Declaring variables\noutputSize = len(os.listdir(train_dir)) # number of different gestures. Will determine number of units in final dense layer\nepochs = 30 # Number of epochs","5c5b34c2":"# Train Data Generator to do data augmentation on training images\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)","c7573d89":"# Test Data Generator\ntest_datagen = ImageDataGenerator(rescale=1.\/255)","527987d8":"# Setting up the train generator to flow from the train directory\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size = (256,256),\n    batch_size = 32,\n    class_mode = 'categorical',\n    color_mode = 'grayscale'\n)\n\n# Doing the same as above for the validation directory\nval_generator = test_datagen.flow_from_directory(\n    val_dir,\n    target_size = (256,256),\n    batch_size = 32,\n    class_mode = 'categorical',\n    color_mode = 'grayscale'\n)","ada6107e":"# Function to create keras model for different number of gestures\ndef create_model(outputSize):\n    model = Sequential()\n    model.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', input_shape = (256,256,1)))\n    model.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = 2))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = 2))\n    model.add(Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'))\n    model.add(Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = 2))\n    model.add(Flatten())\n    model.add(Dropout(rate = 0.5))\n    model.add(Dense(512, activation = 'relu'))\n    model.add(Dense(units = outputSize, activation = 'softmax'))\n    model.compile(optimizer = optimizers.adam(lr=1e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n    return model","24ca4bf0":"# Creating the model\nmodel = create_model(outputSize)","253cbfba":"# Summary of model\nmodel.summary()","e96572cb":"# Fitting the model to the data based on a 32 batch size\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=outputSize*1000\/32,\n    epochs=epochs,\n    validation_data=val_generator,\n    validation_steps=outputSize*500\/32\n)","40c6225b":"# Plotting training acc\/loss and val acc\/loss\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nrange_ep = epochs +1\nepoch_x = range(1, range_ep)\n\nplt.plot(epoch_x,acc,'bo',label=\"Training Acc\")\nplt.plot(epoch_x,val_acc,'b',label='Validation Acc')\nplt.title('Training and Validation Acc')\nplt.legend()\nplt.figure()\n\nplt.plot(epoch_x,loss,'bo',label=\"Training Loss\")\nplt.plot(epoch_x,val_loss,'b',label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\nplt.figure()\n\nplt.show()","5ef17a2e":"# Setting up the test generator to flow from the test directory\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size = (256,256),\n    batch_size = 32,\n    class_mode = 'categorical',\n    color_mode = 'grayscale'\n)","0d628ba6":"# Test accuracy and test loss calc\ntest_loss, test_acc = model.evaluate_generator(test_generator,steps = outputSize*500\/32)\nprint(\"Test Acc:\",test_acc)\nprint(\"Test Loss:\",test_loss)","6dda0158":"# Model weights and model\nmodel.save_weights('my_model_weights.h5')\nmodel.save(\"my_model.h5\")","5892b0f1":"**GitHub Repo:** https:\/\/github.com\/mdylan2\/hand_gesture_recognition.git"}}