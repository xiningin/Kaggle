{"cell_type":{"9d7e4c27":"code","ddd5faca":"code","751682f4":"code","371209c5":"code","3e0a5cfd":"code","3b79515e":"code","e86ff542":"code","d3ad4be2":"code","25770be8":"code","c21d84b2":"code","f7fc67f0":"code","6c6b6934":"code","16be6c07":"code","e46bb9c6":"code","6f6c6112":"code","e726c43d":"code","d8e281e7":"code","5f67c471":"code","171e9c9b":"code","8f879365":"code","399fe8ba":"code","4e66242a":"code","e7c1686b":"code","48cc2d24":"code","ee35679e":"markdown","9f164684":"markdown","565fd7a8":"markdown","930a3390":"markdown","f3588e76":"markdown","9528f523":"markdown","c5bea282":"markdown","88ca45bb":"markdown"},"source":{"9d7e4c27":"import pathlib\nimport os\nimport numpy as np\nimport pandas as pb\nimport seaborn as sns\nimport tensorflow as tf\nimport keras\nimport IPython.display as display\nfrom PIL import Image\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline","ddd5faca":"data_dir = pathlib.Path(\"..\/input\/images_train\")\nimage_count = len(list(data_dir.glob('*\/*.jpg')))\nimage_count","751682f4":"CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \".DS_Store\"])\nCLASS_NAMES","371209c5":"cat = list(data_dir.glob('cat\/*'))\ncar = list(data_dir.glob('car\/*'))\nflower = list(data_dir.glob('flower\/*'))\n\nfor image_path in cat[:1]:\n    img = cv2.imread(str(image_path))","3e0a5cfd":"plt.imshow(img)","3b79515e":"BATCH_TRAIN_SIZE = 64\nIMG_HEIGHT = 224\nIMG_WIDTH = 224\nSTEPS_PER_EPOCH = np.ceil(image_count\/BATCH_TRAIN_SIZE)\nEPOCHS=12","e86ff542":"image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)\n\ntrain_data_gen = image_generator.flow_from_directory(directory=str(data_dir),\n                                                     batch_size=BATCH_TRAIN_SIZE,\n                                                     shuffle=True,\n                                                     target_size=(224, 224),\n                                                     class_mode=\"sparse\",\n                                                     classes = list(CLASS_NAMES))","d3ad4be2":"def show_batch(image_batch, label_batch):\n    plt.figure(figsize=(10,10))\n    for n in range(25):\n        ax = plt.subplot(5,5,n+1)\n        plt.imshow(image_batch[n])\n        plt.axis('off')","25770be8":"image_batch, label_batch = next(train_data_gen)\nshow_batch(image_batch, label_batch)","c21d84b2":"image_batch[2].shape","f7fc67f0":"AUTOTUNE = tf.data.experimental.AUTOTUNE","6c6b6934":"list_ds = tf.data.Dataset.list_files(str(data_dir\/'*\/*'))\n\nfor f in list_ds.take(5):\n    print(f.numpy())","16be6c07":"def get_label(file_path):\n    # convert the path to a list of path components\n    parts = tf.strings.split(file_path, os.path.sep)\n    # The second to last is the class-directory\n    return parts[-2] == CLASS_NAMES\n\ndef decode_img(img):\n    # convert the compressed string to a 3D uint8 tensor\n    img = tf.image.decode_jpeg(img, channels=3)\n    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    # resize the image to the desired size.\n    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n\ndef process_path(file_path):\n    label = get_label(file_path)\n    # load the raw data from the file as a string\n    img = tf.io.read_file(file_path)\n    img = decode_img(img)\n    return img, label","e46bb9c6":"# Set `num_parallel_calls` so multiple images are loaded\/processed in parallel.\nlabeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n\nfor image, label in labeled_ds.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())","6f6c6112":"train_ds = labeled_ds.take(np.ceil(1596*0.7)) \ntest_ds = labeled_ds.take(np.ceil(1596*0.7))","e726c43d":"def prepare_for_training(ds, cache=True, shuffle_buffer_size=300):\n    # This is a small dataset, only load it once, and keep it in memory.\n    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n    # fit in memory.\n    if cache:\n        if isinstance(cache, str):\n            ds = ds.cache(cache)\n        else:\n            ds = ds.cache()\n\n    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n\n    # Repeat forever\n    ds = ds.repeat()\n\n    ds = ds.batch(BATCH_TRAIN_SIZE)\n\n    # `prefetch` lets the dataset fetch batches in the background while the model\n    # is training.\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n\n    return ds","d8e281e7":"train_dsfinal = prepare_for_training(train_ds)\ntest_dsfinal = prepare_for_training(test_ds)","5f67c471":"image_batch, label_batch = next(iter(train_dsfinal))\n\nshow_batch(image_batch.numpy(), label_batch.numpy())","171e9c9b":"label_batch.shape","8f879365":"class CNNModel():\n    def __init__(self):\n        self.inputs = tf.keras.Input(shape=(224,224,3))\n        self.x1= tf.keras.layers.Conv2D(32 , 3, activation='relu')(self.inputs)\n        self.x1= tf.keras.layers.Conv2D(64, 3, activation='relu')(self.x1)\n        self.x1= tf.keras.layers.MaxPooling2D(2,2)(self.x1)\n        \n        self.x2= tf.keras.layers.Conv2D(32, 3, activation='relu')(self.x1)\n        self.x2= tf.keras.layers.Conv2D(64, 3, activation='relu')(self.x2)\n        self.x2= tf.keras.layers.MaxPooling2D(3,3)(self.x2)\n        \n        self.x3= tf.keras.layers.Conv2D(32, 3, activation='relu')(self.x2)\n        self.x3= tf.keras.layers.MaxPooling2D(2,2)(self.x3)\n        self.x = tf.keras.layers.Dropout(0.2)(self.x3)\n        \n        self.output = tf.keras.layers.Flatten()(self.x)\n        self.output = tf.keras.layers.Dense(224, activation='relu')(self.output)\n        self.output = tf.keras.layers.Dense(3, activation='softmax')(self.output) \n\n        self.model = tf.keras.Model(self.inputs, self.output)\n        \n        \"\"\"\n        X_input = Input((480, 480, 3))\n\n        X = Conv2D(6, (5, 5), kernel_initializer = glorot_uniform(seed=0))(X_input) #480 - 4 = 476\n        X = BatchNormalization(axis = 3)(X)\n        X = Activation('relu')(X)\n        X = MaxPooling2D((2, 2), strides=(2, 2))(X) # 476 \/ 2 = 238\n\n        X = Conv2D(16, (5, 5), kernel_initializer = glorot_uniform(seed=0))(X) #238 - 4 = 234\n        X = BatchNormalization(axis = 3)(X)\n        X = Activation('relu')(X)\n        X = MaxPooling2D((2, 2), strides=(2, 2))(X) # 234 \/ 2 = 117\n\n        X = Conv2D(32, (5, 5), kernel_initializer = glorot_uniform(seed=0))(X) #117 - 4 = 113\n        X = BatchNormalization(axis = 3)(X)\n        X = Activation('relu')(X)\n        X = MaxPooling2D((2, 2), strides=(2, 2))(X) # 113 \/ 2 = 56\n\n        X = Conv2D(16, (5, 5), kernel_initializer = glorot_uniform(seed=0))(X) #56 - 4 = 52\n        X = BatchNormalization(axis = 3)(X)\n        X = Activation('relu')(X)\n        X = MaxPooling2D((2, 2), strides=(2, 2))(X) # 52 \/ 2 = 26\n\n        X = Conv2D(5, (5, 5), kernel_initializer = glorot_uniform(seed=0))(X) #26 - 4 = 22\n        X = BatchNormalization(axis = 3)(X)\n        X = Activation('relu')(X)\n        X = MaxPooling2D((2, 2), strides=(2, 2))(X) # 22 \/ 2 = 11\n\n        model = Model(inputs = X_input, outputs = X, name='ResNet50')\n        \"\"\"\n\n\n    def compile_cnn(self):\n        self.model.summary()\n        self.model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.RMSprop(lr=0.001), metrics=['accuracy'])\n        \n    def fit(self, dataset, n_epochs):\n        self.model.fit(\n            dataset,\n            steps_per_epoch=STEPS_PER_EPOCH,\n            epochs=n_epochs,\n            validation_data=test_dsfinal,\n            validation_steps=200\n        )\n\n# Create an instance of the model\nmodel = CNNModel()","399fe8ba":"model.compile_cnn()","4e66242a":"history = model.fit(dataset = train_dsfinal, n_epochs = EPOCHS)","e7c1686b":"acc = model.model.history.history['accuracy']\nval_acc = model.model.history.history['val_accuracy']\n\nloss = model.model.history.history['loss']\nval_loss = model.model.history.history['val_loss']\n\nepochs_range = range(EPOCHS)\n\nplt.figure(figsize=(10, 6))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","48cc2d24":"model.model.evaluate(test_dsfinal, verbose=2, steps=64)","ee35679e":"# CNN on a 3 class problem on images\n\nConvolutionnal Neural Network on a 3 classes problem (cat, car, flower) that come from CIFAR-10 dataset.\n\n### Importing libs","9f164684":"### Using tf.data \nUsinf tf.data, with ability of .cache(), method is actually faster for big dataset.","565fd7a8":"To train a model with this dataset you will want the data:\n\nTo be well shuffled.\nTo be batched.\nBatches to be available as soon as possible.","930a3390":"## Initialisation variables","f3588e76":"### Loading data\n\n- Using keras.preprocessing","9528f523":"### CONCLUSION : Obtaining a 98.25% accuracy","c5bea282":"### Building model\n\nCNN model","88ca45bb":"## Dataset Generator\n\nLet's generate image to float32 in range [0,1].\n\nMoreover, as our dataset has images of different size, we will target size them as 448 px\n\n### Using ImageDataGenerator from keras"}}