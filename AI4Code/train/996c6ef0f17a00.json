{"cell_type":{"64657947":"code","ed1fd49f":"code","6ec16049":"code","8c7dd81c":"code","bf3704d3":"code","69117241":"code","4c0a2207":"code","bfd89e99":"code","57a7c154":"code","18eb8a6a":"code","57687588":"code","d5b69cea":"code","b4defe90":"code","de21d71e":"code","f882ec03":"code","a419c04e":"code","d3c428ac":"code","b76c8728":"code","24ec518d":"code","2bbc7f8e":"code","f0af57c8":"code","18d3fe98":"code","b6d815e2":"code","3aa71a1f":"code","cb7eb6df":"code","1723425b":"code","a4d65962":"code","a2d726e8":"code","3fb65f1e":"code","15868683":"code","0e1a1904":"code","f5e88d78":"code","e100798b":"code","b61320d4":"code","d1d5d9fb":"code","b3d11834":"code","104caa06":"code","b6989792":"code","dd54e4ef":"markdown","fb265320":"markdown","8a2f606d":"markdown","89246c5f":"markdown","c6880c86":"markdown","584791fa":"markdown","2aae3e21":"markdown","f1150a5f":"markdown","d0d959eb":"markdown","f0672f4c":"markdown","179836ae":"markdown","95cfe274":"markdown","bbc3e194":"markdown","b3a9ebc5":"markdown","65f0701f":"markdown","aa7d78c5":"markdown","c7ba17a2":"markdown","d574acb4":"markdown","fb8e0cba":"markdown","a669951d":"markdown","93b7d4c5":"markdown","30945ab9":"markdown","afdd0c90":"markdown","402774eb":"markdown","8b972c7c":"markdown"},"source":{"64657947":"import re\nimport string\nimport nltk\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom wordcloud import WordCloud\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import  CountVectorizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score","ed1fd49f":"#The data is indeed not encoded as UTF-8; everything is ASCII except for that single 0x92 byte:\ntrain = pd.read_csv('..\/input\/news-category-dataset\/Data_Train.csv',encoding='cp1252')\ntest = pd.read_csv('..\/input\/news-category-dataset\/Data_Test.csv',encoding='cp1252')","6ec16049":"train.head()","8c7dd81c":"train.info()","bf3704d3":"train.isnull().sum()","69117241":"train['Category'] = train['SECTION']","4c0a2207":"train.head()","bfd89e99":"rem = {\"Category\": {0: \"Politics\", 1: \"Technology\", 2:\"Entertainment\", 3:\"Business\"}}","57a7c154":"train = train.replace(rem)\ntrain.head()","18eb8a6a":"count = train.Category.value_counts()\nsns.barplot(x=count.index, y=count)\nplt.xlabel('Category')\nplt.ylabel('Count')","57687588":"train['Text_length'] = train['STORY'].apply(len)\ntrain.head()","d5b69cea":"len_text = sns.FacetGrid(data=train, col='Category')\nlen_text.map(plt.hist, 'Text_length', bins=20, color='r')","b4defe90":"def plot_(a):\n    x1 = train[train.SECTION == 0][a]\n    x2 = train[train.SECTION == 1][a]\n    x3 = train[train.SECTION == 2][a]\n    x4 = train[train.SECTION == 3][a]\n    plt.subplot(1,1,1)\n    _ = plt.hist(x1, alpha=0.8, color=\"red\", bins=50)\n    __= plt.hist(x2, alpha=0.5, color=\"grey\", bins=50)\n    ___ = plt.hist(x3, alpha=0.8, color=\"green\", bins=50)\n    ____= plt.hist(x4, alpha=0.5, color=\"black\", bins=50)\n    return ____","de21d71e":"plt_len_text = plot_('Text_length')","f882ec03":"train['words_counts']=train.STORY.str.split().map(lambda x: len(x))\ntrain.head()","a419c04e":"plot_words_counts = plot_(\"words_counts\")","d3c428ac":"import string\ntrain['punctuation_count'] = train['STORY'].map(lambda x: len([c for c in str(x) if c in string.punctuation]))","b76c8728":"train.head()","24ec518d":"_ =plot_('punctuation_count')","2bbc7f8e":"def clean_text(text):\n    text = text.lower()                                  # lower-case all characters\n    text =  re.sub(r'@\\S+', '',text)                     # remove twitter handles\n    text =  re.sub(r'http\\S+', '',text)                  # remove urls\n    text =  re.sub(r'pic.\\S+', '',text) \n    text =  re.sub(r\"[^a-zA-Z+']\", ' ',text)             # only keeps characters\n    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text+' ')      # keep words with length>1 only\n    text = \"\".join([i for i in text if i not in string.punctuation])\n    words = nltk.tokenize.word_tokenize(text)\n    stopwords = nltk.corpus.stopwords.words('english')   # remove stopwords\n    text = \" \".join([i for i in words if i not in stopwords and len(i)>2])\n    text= re.sub(\"\\s[\\s]+\", \" \",text).strip()            # remove repeated\/leading\/trailing spaces\n    return text","f0af57c8":"train['Text_cleaning'] = train.STORY.apply(clean_text)","18d3fe98":"train.head()","b6d815e2":"train['len_text_clean']=train.Text_cleaning.apply(len)\ntrain.head()","3aa71a1f":"vectorizer = CountVectorizer()\ndata_vectorizer = vectorizer.fit_transform(train['Text_cleaning'])","cb7eb6df":"label = train['SECTION']","1723425b":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data_vectorizer, label, test_size=0.2, random_state=42)","a4d65962":"my_Category =['Politics','Technology','Entertainment','Business']","a2d726e8":"def model(name_model):\n    a = name_model()\n    a.fit(X_train,y_train)\n    y_pred = a.predict(X_test)\n    Acc_train = a.score(X_train, y_train)\n    acc_test = a.score(X_test, y_test)\n    print('Train Accuracy : {:.2f}%'.format(Acc_train*100))\n    print('Test Accuracy  : {:.2f}%'.format(acc_test*100))\n    print('******** Classification Report ***************')\n    print(classification_report(y_test, y_pred,target_names=my_Category))\n    print('******** Predicting the Test set results ******')\n    cm = confusion_matrix(y_test, y_pred)\n    sns.heatmap(cm, annot=True)\n    return acc_test","3fb65f1e":"from sklearn.linear_model import LogisticRegression\nacc_LR = model(LogisticRegression)","15868683":"from sklearn.svm import SVC\nacc_SVC = model(SVC)","0e1a1904":"from sklearn.tree import DecisionTreeClassifier\nacc_DTC = model(DecisionTreeClassifier)","f5e88d78":"from sklearn.naive_bayes import MultinomialNB\nacc_MNB = model(MultinomialNB)","e100798b":"from sklearn.ensemble import RandomForestClassifier\nacc_RFC = model(RandomForestClassifier)","b61320d4":"from sklearn.neighbors import KNeighborsClassifier\nacc_KNC = model(KNeighborsClassifier)","d1d5d9fb":"from sklearn.ensemble import AdaBoostClassifier\nacc_ABC = model(AdaBoostClassifier)","b3d11834":"output = pd.DataFrame({\"Model\":['Logistic Regression','SVC','Decision Tree Classifier',\n                                'MultinomialNB','Random Forest Classifier',\n                               'KNeighborsClassifier','AdaBoost Classifier',],\n                      \"Accuracy\":[acc_LR, acc_SVC, acc_DTC, acc_MNB, acc_RFC, acc_KNC, acc_ABC]})","104caa06":"output","b6989792":"plt.figure(figsize=(10, 6))\nplots = sns.barplot(x='Model', y='Accuracy', data=output)\nfor bar in plots.patches:\n    plots.annotate(format(bar.get_height(), '.2f'),\n                   (bar.get_x() + bar.get_width() \/ 2,\n                    bar.get_height()), ha='center', va='center',\n                   size=15, xytext=(0, 8),\n                   textcoords='offset points')\n\nplt.xlabel(\"Models\", size=14)\nplt.xticks(rotation=70);\nplt.ylabel(\"Accuracy\", size=14)\nplt.show()","dd54e4ef":"# \u2714\ufe0f KNeighborsClassifier","fb265320":"# \u2714\ufe0f MultinomialNB","8a2f606d":"# \u2714\ufe0f Text length VS Category","89246c5f":"# \ud83d\udcca Final Report","c6880c86":"# \ud83d\udce5 Importing Libraries","584791fa":"# \u2714\ufe0f Text length of the story","2aae3e21":"# \u2714\ufe0f punctuation count of the story","f1150a5f":"# \u2728 Thanks","d0d959eb":"# \u2714\ufe0f plot Text length ","f0672f4c":"# \u2702\ufe0f Train test split","179836ae":"# \u2714\ufe0f Logistic Regression","95cfe274":"# \u2714\ufe0f Decision Tree Classifier","bbc3e194":"# \ud83e\uddf9 Cleaning Data","b3a9ebc5":"# \ud83d\udd0e Checking for NaN values","65f0701f":"# \ud83d\udcda Machine Learning Models","aa7d78c5":"# \ud83d\udd25 EDA & Visualization","c7ba17a2":"# \ud83d\udcdd Meta information of Dataframe","d574acb4":"# \u2714\ufe0f Random Forest Classifier","fb8e0cba":"# \ud83e\uddbe Function","a669951d":"# \u2714\ufe0f SVC","93b7d4c5":"# \u2714\ufe0f plot words counts","30945ab9":"* Feel free to download Notebook and do experiments on it.\n* Comments if you find something inappropriate and will improve accordingly.\n* Upvote if you find this notebook useful.","afdd0c90":"# \u2714\ufe0f AdaBoost Classifier","402774eb":"# \ud83d\udd22 The process of converting words into numbers","8b972c7c":"# \ud83d\uddc3\ufe0f Load Dataset"}}