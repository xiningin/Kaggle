{"cell_type":{"11e5d470":"code","85a3c329":"code","64b52b79":"code","957fadd5":"code","421a9b2f":"code","b1be1d64":"code","025a1857":"code","df918e4d":"code","1602699d":"code","1d4c22af":"code","756bf90a":"code","b24bebee":"code","77a15273":"code","07ae9f91":"markdown","cc5b3f4d":"markdown","50d64eb5":"markdown"},"source":{"11e5d470":"#Importing required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","85a3c329":"#Importing data\ndata = pd.read_csv('\/kaggle\/input\/ice-cream-revenue\/IceCreamData.csv')\nprint(data.head())\nprint('The size of the dataset', len(data))","64b52b79":"#Checking for missing values\ndata.info()","957fadd5":"#As we can conclude from above cell that the data doesn't have any missing values\n#We can plot a graph of these two columns, to clearly understand the trend.\n\nplt.scatter(data.Temperature, data.Revenue, marker='x')","421a9b2f":"#Let us split this data into train-test, for training and evaluating our model\ntrain = data.head(300)\ntest = data.tail(200)\nprint('Training Set : ', train.shape)\nprint('Testing Set : ', test.shape)","b1be1d64":"#Let us seperate the feature(x) and target(y) variable\nx = train.Temperature\ny = train.Revenue\nprint('Feature Variable : ', x.shape)\nprint('Target Variable : ', y.shape)","025a1857":"#Visualizing feature variable\nx","df918e4d":"#Adding ones to feature variable\nx = np.c_[np.ones((300,1)), x]\nx[:5]","1602699d":"#Calculating the value of theta\ntheta = np.linalg.inv(x.T.dot(x)).dot(x.T).dot(y)\ntheta","1d4c22af":"test.head(5)","756bf90a":"#Using theta value that we calculated earlier to predict data from test set\nx_new = np.array([[5.858454],[26.859723]]) #Here we used the first two elements from test set above\nx_new = np.c_[np.ones((2,1)), x_new]\nx_predict = x_new.dot(theta)\nx_predict","b24bebee":"#Making predictions for the entire test set\nx_new = np.array(test.Temperature)\nx_new = np.c_[np.ones((200,1)), x_new]\nx_predict = x_new.dot(theta)\npredict = pd.DataFrame(x_predict)\ntrue = pd.DataFrame(test.Revenue)","77a15273":"#Calculation r2 score using r2_score from sklearn\nfrom sklearn.metrics import r2_score\nscore = r2_score(true, predict)\nprint(\"R2 Score: \", score)","07ae9f91":"The data that we have used here is a simple dataset imported from [here](https:\/\/www.kaggle.com\/vinicius150987\/ice-cream-revenue), this dataset was created by [Vinicius Barbosa Paiva](https:\/\/www.kaggle.com\/vinicius150987). The data here is quite simple, it has two columns, temperature and revenue, and has 500 rows. \n\nFor obvious reasons, as the temperature increases, the revenue of the IceCream Vendor should also increase accordingly.\n\nThe model that we are going to predict should be able to do the same.","cc5b3f4d":"# Linear Regression using Normal Equation\n## Artificial Intelligence - The Better Way\nThis notebook would give an overview of low-level implementation of Linear Regression using Normal Equation.\n> The methods used in the notebook can't be considered efficient as it would be potratying how stuffs are cooked under the hood.","50d64eb5":"So here out model predicted with an accuracy of 97% on test data, the model is quite good.\n\n**Hooray!!**<br>\nWe have created first machine learning model from scratch with efficient accuracy.\n<hr>\n\n***Disclaimer***\n* For detailed explaination of the same, you can visit [here](https:\/\/rithurajnambiar.medium.com\/ml-algorithms-from-scratch-1214981efee). \n* GitHub Repo for the same notebook is included in my blog itself.\n* Upvote if you like the content, and stay tuned for developing other algorithms from scratch!\n\n<hr>\n\n***Connect***<br>\n[LinkedIn](https:\/\/linkedin.com\/in\/rithuraj-nambiar) &nbsp; [GitHub](https:\/\/github.com\/rithurajnambiar17) &nbsp;  [Kaggle](https:\/\/www.kaggle.com\/rithurajnambiar)"}}