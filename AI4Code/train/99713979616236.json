{"cell_type":{"9e0d82ce":"code","6d5dfda4":"code","56150cb3":"code","083c8e9f":"code","504743bb":"code","e3e21f48":"code","4d291949":"code","5d4e7223":"code","4a1699b4":"code","4c00b49c":"code","607bb9d5":"code","fc5541c4":"code","1629a5a4":"code","3ac35d33":"code","bd1ac55c":"markdown","19d25cdf":"markdown"},"source":{"9e0d82ce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","6d5dfda4":"#First we have to import all required Libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","56150cb3":"#reading the csv file using pandas \n\nData=pd.read_csv('\/kaggle\/input\/diabetes-dataset\/diabetes2.csv')\nData.head() #top 5 rows of data\n","083c8e9f":"Data.info()","504743bb":"#finding out null values\n#Data.isnull().sum().sum()\nData.isnull() # so there is no null values in our dataset","e3e21f48":"#finding the null values using heatmap \nsns.heatmap(Data.isnull(),cmap='viridis') #so there is null values or there is no shades","4d291949":"#graph using seaborn library \nsns.countplot('Outcome',data=Data) #here In this graph you see the count of Diabetes members ","5d4e7223":"#now we are creating X(independent features) & y(dependent values)\n\nX=Data.iloc[:,[0,1,2,3,4,5,6,7]].values # from column 0 to 7 \ny=Data.iloc[:,-1].values #last column","4a1699b4":"#splitting dataset into training and test set\n#here we are importing traintestsplit function from library sklearn\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.3, random_state=33) #iam giving a testsize value is 30% & random state is 30 value","4c00b49c":"X_train","607bb9d5":"#lets create a model using logistic regression algorithm\n\nfrom sklearn.linear_model import LogisticRegression\n\nclf=LogisticRegression(random_state=0) #creating a object called clf\nclf.fit(X_train,y_train) # fit the train datasets","fc5541c4":"#now predict the X_test\ny_pred=clf.predict(X_test)","1629a5a4":"#finding accuracy of model\nfrom sklearn.metrics import confusion_matrix,classification_report\n\nprint(confusion_matrix(y_pred,y_test))","3ac35d33":"#macro average (averaging the unweighted mean per label)\n#weighted average (averaging the support-weighted mean per label)(i.e. the number of correctly predicted instances in that class, divided by the total number of instances in that class)\nprint(classification_report(y_pred,y_test))","bd1ac55c":"**Using LOGISTIC REGRESSION we are predicting Diabetics**","19d25cdf":"Classification report is"}}