{"cell_type":{"022b21e9":"code","94ae2b01":"code","7170c1f5":"code","f664abb3":"code","e726a9db":"code","00f4a37e":"code","6d3cc724":"code","8244455d":"code","484d8485":"code","b9ac3635":"code","0dd1341f":"code","3aee9e46":"code","f1beb242":"code","bb42e360":"code","e98a570f":"code","a40e6db1":"code","ac87be25":"code","8a334819":"code","fe97e656":"code","36769112":"code","55b72b89":"code","ab7dfdba":"code","28794389":"code","0e7fa209":"markdown","a45210fd":"markdown","428fde9a":"markdown","92e3a463":"markdown","93f3479a":"markdown","5feb236d":"markdown","656d5efc":"markdown","c374e77a":"markdown","91d07f40":"markdown","c2ab0e3a":"markdown","afec6e6e":"markdown","3d06c190":"markdown","954f1778":"markdown","cbbb42d1":"markdown","32a938d2":"markdown"},"source":{"022b21e9":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random","94ae2b01":"df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ndf.head()","7170c1f5":"non_fraud = len(df[df.Class == 0])\nfraud = len(df[df.Class == 1])\nfraud_percent = (fraud \/ (fraud + non_fraud)) * 100\n\nprint(\"Number of Genuine transactions: \", non_fraud)\nprint(\"Number of Fraud transactions: \", fraud)\nprint(\"Percentage of Fraud transactions: {:.4f}\".format(fraud_percent))","f664abb3":"from sklearn.preprocessing import RobustScaler\nrs = RobustScaler()\ndf['scaled_amount'] = rs.fit_transform(df['Amount'].values.reshape(-1,1))\ndf['scaled_time'] = rs.fit_transform(df['Time'].values.reshape(-1,1))","e726a9db":"df.drop(['Time', 'Amount'], axis=1, inplace=True)\nscaled_amount = df['scaled_amount']\nscaled_time = df['scaled_time']\ndf.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\ndf.insert(0, 'scaled_amount', scaled_amount)\ndf.insert(0, 'scaled_time', scaled_time)\ndf.head()","00f4a37e":"x = df.drop([\"Class\"], axis= 1)\ny = df[\"Class\"]\nfrom sklearn.model_selection import train_test_split\n(x_train, x_test, y_train, y_test) = train_test_split(x, y, test_size= 0.3, random_state= 42)\nprint(\"Shape of x_train: \", x_train.shape)\nprint(\"Shape of x_test: \", x_test.shape)","6d3cc724":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nstrmodels=['RandomForestClassifier','DecisionTreeClassifier','KNeighborsClassifier']\nmodels=[RandomForestClassifier(),DecisionTreeClassifier(),KNeighborsClassifier()]\n\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n\ndef metrics(strmodel, model, actuals, predictions):    \n    accuracy=accuracy_score(actuals, predictions)\n    precision=precision_score(actuals, predictions)\n    recall=recall_score(actuals, predictions)\n    f1score=f1_score(actuals, predictions)\n    strmodel=strmodel\n    print(\"Model: {}\".format(strmodel))\n    print(\"Accuracy: {:.5f}\".format(accuracy))\n    print(\"Precision: {:.5f}\".format(precision))\n    print(\"Recall: {:.5f}\".format(recall))\n    print(\"F1-score: {:.5f}\".format(f1score))\n    print()\n    \n    return strmodel,accuracy,precision,recall,f1score","8244455d":"print(\"Shape of x_train: \", x_train.shape)\nprint(\"Shape of x_test: \", x_test.shape)\nprint()\nprint(\"without Oversampling, counts of label '1', %: {:.1f}\".format(sum(y_train==1)\/len(y_train)*100.0,2))\nprint(\"without Oversampling, counts of label '0', %: {:.1f}\".format(sum(y_train==0)\/len(y_train)*100.0,2))","484d8485":"woutos=[]\nfor i, strmodel in enumerate(strmodels):\n    model=models[i]\n    model.fit(x_train, y_train)\n    y_pred = model.predict(x_test)\n    woutos+=[tuple(['Without OverSampling'])+ metrics(strmodel, model, y_test, y_pred.round())]","b9ac3635":"from imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(random_state=2)\nx_train_ros, y_train_ros = ros.fit_resample(x_train, y_train)\n\nprint(\"Shape of x_train_ros: \", x_train_ros.shape)\nprint(\"Shape of x_test: \", x_test.shape)\nprint()\nprint(\"RandomOverSampler, counts of label '1', %: {:.1f}\".format(sum(y_train_ros==1)\/len(y_train_ros)*100.0,2))\nprint(\"RandomOverSampler, counts of label '0', %: {:.1f}\".format(sum(y_train_ros==0)\/len(y_train_ros)*100.0,2))","0dd1341f":"wros=[]\nfor i, strmodel in enumerate(strmodels):\n    model=models[i]\n    model.fit(x_train_ros, y_train_ros)\n    y_pred = model.predict(x_test)\n    wros+=[tuple(['RandomOverSampler'])+metrics(strmodel, model, y_test, y_pred.round())]","3aee9e46":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=2)\nx_train_sm, y_train_sm = sm.fit_resample(x_train, y_train)\n\nprint(\"Shape of x_train_sm: \", x_train_sm.shape)\nprint(\"Shape of x_test: \", x_test.shape)\nprint()\nprint(\"SMOTE, counts of label '1', %: {:.1f}\".format(sum(y_train_sm==1)\/len(y_train_sm)*100.0,2))\nprint(\"SMOTE, counts of label '0', %: {:.1f}\".format(sum(y_train_sm==0)\/len(y_train_sm)*100.0,2))","f1beb242":"wsm=[]\nfor i, strmodel in enumerate(strmodels):\n    model=models[i]\n    model.fit(x_train_sm, y_train_sm)\n    y_pred = model.predict(x_test)\n    wsm+=[tuple(['SMOTE'])+metrics(strmodel, model, y_test, y_pred.round())]","bb42e360":"from imblearn.over_sampling import ADASYN\nad = ADASYN(random_state=2)\nx_train_ad, y_train_ad = ad.fit_resample(x_train, y_train)\n\nprint(\"Shape of x_train_ad: \", x_train_ad.shape)\nprint(\"Shape of x_test: \", x_test.shape)\nprint()\nprint(\"ADASYN, counts of label '1', %: {:.1f}\".format(sum(y_train_ad==1)\/len(y_train_ad)*100.0,2))\nprint(\"ADASYN, counts of label '0', %: {:.1f}\".format(sum(y_train_ad==0)\/len(y_train_ad)*100.0,2))","e98a570f":"wad=[]\nfor i, strmodel in enumerate(strmodels):\n    model=models[i]\n    model.fit(x_train_ad, y_train_ad)\n    y_pred = model.predict(x_test)\n    wad+=[tuple(['ADASYN'])+metrics(strmodel, model, y_test, y_pred.round())]","a40e6db1":"from imblearn.combine import SMOTEENN\nsmteen = SMOTEENN(random_state=2)\nx_train_smteen, y_train_smteen = smteen.fit_resample(x_train, y_train)\n\nprint(\"Shape of x_train_ad: \", x_train_smteen.shape)\nprint(\"Shape of x_test: \", x_test.shape)\nprint()\nprint(\"SMOTEENN, counts of label '1', %: {:.1f}\".format(sum(y_train_smteen==1)\/len(y_train_smteen)*100.0,2))\nprint(\"SMOTEENN, counts of label '0', %: {:.1f}\".format(sum(y_train_smteen==0)\/len(y_train_smteen)*100.0,2))","ac87be25":"wsmteen=[]\nfor i, strmodel in enumerate(strmodels):\n    model=models[i]\n    model.fit(x_train_smteen, y_train_smteen)\n    y_pred = model.predict(x_test)\n    wsmteen+=[tuple(['SMTEENN'])+metrics(strmodel, model, y_test, y_pred.round())]","8a334819":"from imblearn.combine import SMOTETomek\nsmtom = SMOTETomek(random_state=2)\nx_train_smtom, y_train_smtom = smtom.fit_resample(x_train, y_train)\n\nprint(\"Shape of x_train_ad: \", x_train_smtom.shape)\nprint(\"Shape of x_test: \", x_test.shape)\nprint()\nprint(\"SMOTETomek, counts of label '1', %: {:.1f}\".format(sum(y_train_smtom==1)\/len(y_train_smtom)*100.0,2))\nprint(\"SMOTETomek, counts of label '0', %: {:.1f}\".format(sum(y_train_smtom==0)\/len(y_train_smtom)*100.0,2))","fe97e656":"wsmtom=[]\nfor i, strmodel in enumerate(strmodels):\n    model=models[i]\n    model.fit(x_train_smtom, y_train_smtom)\n    y_pred = model.predict(x_test)\n    wsmtom+=[tuple(['SMOTETomek'])+metrics(strmodel, models, y_test, y_pred.round())]","36769112":"n=len(x_train)\nN=list(range(n))\nrandom.seed(2021)\nrandom.shuffle(N)\nxy_train=pd.concat([x_train,y_train],axis=1)\n\nxy_train2=xy_train.iloc[N[0:n\/\/10]]\ny_train2=xy_train2['Class']\nx_train2=xy_train2.drop('Class',axis=1)\n\n#only class1 train data\nxy_train_c1=xy_train[xy_train['Class']==1]\ny_train_c1=xy_train_c1['Class']\nx_train_c1=xy_train_c1.drop('Class',axis=1)\n\nx_train_c2=pd.concat([x_train_c1,x_train2],axis=0)\ny_train_c2=pd.concat([y_train_c1,y_train2],axis=0)","55b72b89":"#from imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(random_state=2)\nx_train_c3, y_train_c3 = ros.fit_resample(x_train_c2, y_train_c2)\n\nx_train_rosnd=pd.concat([x_train_c3,x_train2],axis=0)\ny_train_rosnd=pd.concat([y_train_c3,y_train2],axis=0)\n\nprint(\"Shape of x_train_rosnd: \", x_train_rosnd.shape)\nprint(\"Shape of x_test: \", x_test.shape)\nprint()\nprint(\"Decreased RandomOverSampler, counts of label '1', %: {:.1f}\".format(sum(y_train_rosnd==1)\/len(y_train_rosnd)*100.0,2))\nprint(\"Decreased RandomOverSampler, counts of label '0', %: {:.1f}\".format(sum(y_train_rosnd==0)\/len(y_train_rosnd)*100.0,2))","ab7dfdba":"wrosnd=[]\nfor i, strmodel in enumerate(strmodels):\n    model=models[i]\n    model.fit(x_train_rosnd, y_train_rosnd)\n    y_pred = model.predict(x_test)\n    wrosnd+=[tuple(['DecreasedRandomOverSampler'])+metrics(strmodel, model, y_test, y_pred.round())]","28794389":"woutos=pd.DataFrame(woutos)\nwros=pd.DataFrame(wros)\nwsm=pd.DataFrame(wsm)\nwad=pd.DataFrame(wad)\nwsmteen=pd.DataFrame(wsmteen)\nwsmtom=pd.DataFrame(wsmtom)\nwrosnd=pd.DataFrame(wrosnd)\n\nresults=pd.concat([woutos, wros, wsm, wad, wsmteen, wsmtom, wrosnd],axis=0)\nresults.columns=['OSModel','Model','Accuracy','Precision','Recall','F1_score']\n\nresults.sort_values('F1_score',ascending=False).reset_index(drop=True)","0e7fa209":"## 4-2. Apply Model With RandomOverSampler:","a45210fd":"## 4-5. Apply Model With SMOTEENN:","428fde9a":"## 3. Models:","92e3a463":"## 4-7. Decrease Number and Apply Model With RandomOverSampler:\n* An experimet of decreasing ratio of 'Class'==1 in the train data after oversampling","93f3479a":"#### Combination of Over- and Under-sampling Method\n* SMOTEEN<br\/>\nhttps:\/\/imbalanced-learn.org\/stable\/references\/generated\/imblearn.combine.SMOTEENN.html\n* SMOTETomek<br\/>\nhttps:\/\/imbalanced-learn.org\/stable\/references\/generated\/imblearn.combine.SMOTETomek.html","5feb236d":"## 4-4. Apply Model With ADASYN:","656d5efc":"## 4-3. Apply Model With SMOTE:","c374e77a":"## 2. Scaling features","91d07f40":"#### Oversampling Method\n* RandomOverSampler<br\/>\nhttps:\/\/imbalanced-learn.org\/stable\/references\/generated\/imblearn.over_sampling.RandomOverSampler.html\n* SMOTE<br\/>\nhttps:\/\/imbalanced-learn.org\/stable\/references\/generated\/imblearn.over_sampling.SMOTE.html\n* ADASYN<br\/>\nhttps:\/\/imbalanced-learn.org\/stable\/references\/generated\/imblearn.over_sampling.ADASYN.html","c2ab0e3a":"## 6. Conclusion\n* When performed with RandomForestClassifier as a model, RandomOverSampler gave slightly better results than Without Oversampling. \n* When performed with DecisionTreeClassifier, there was no oversampling method which gave better result than Without Oversampling.\n* There is a difference in compatibility between oversampling method and classifier method.","afec6e6e":"# Fraud Detection: Over-\/Under-sampling (RandomOverSampler, SMOTE, ADASYN, SMOTEEN, SMOTETomek) Method Metrics Comparison\nThis notebook was created to check the effect of Over-\/Under-sampling, referring to the following notebook.<br\/>\nhttps:\/\/www.kaggle.com\/adamml\/fraud-detection-models-comparison\/notebook","3d06c190":"## 1. Load data","954f1778":"## 4-6. Apply Model With SMOTETomek:","cbbb42d1":"## 5. Metrics Comparison","32a938d2":"## 4-1. Apply Model without Oversampling"}}