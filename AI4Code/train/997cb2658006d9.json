{"cell_type":{"72cb2d01":"code","74b04ab4":"code","73e24ed9":"code","706006df":"code","dd9bb5dd":"code","8c3e6205":"code","57ec88ba":"code","b46c4e83":"code","1704689c":"code","2a1e8ce8":"code","82856f1d":"code","7072ec76":"code","53d95cfa":"code","c7d972ce":"code","4b206f70":"code","eb87bde6":"code","472478ce":"code","d37acb30":"code","0e819da9":"code","729973dc":"code","d07b5d59":"code","5ff57493":"code","6c0f91df":"code","a651ba3f":"code","6123b0b5":"code","d1fcd6c8":"code","96037981":"code","8bc2d808":"code","e41130b8":"code","817fd3ec":"code","a7e1a284":"code","d3e77ffc":"code","15314042":"code","fd857f23":"code","0873997e":"code","563f7229":"code","dbaeb83b":"code","8e1b276c":"code","62cf2781":"code","e26fb661":"code","b0ed0162":"code","a78ae8c5":"code","702e4a82":"code","408e161e":"code","f5e111dc":"code","39af4177":"code","057f76bd":"code","f77166d5":"code","1cbcc0f8":"code","2567a92c":"code","f694c9c0":"code","41989aaa":"code","523e2d10":"code","61d51fa0":"code","a29d1fc7":"code","3b399cfa":"code","8e1c66cc":"code","1067e6ad":"code","1fcf1b19":"code","8d418cb7":"code","520f9244":"code","8eac216c":"code","637ef6f4":"code","abbdc167":"code","8a70db7b":"code","ca7953d4":"code","2e9afde6":"code","f1656a8d":"code","29133c2c":"code","6629b84c":"code","285723ca":"code","effe4264":"code","29165a39":"code","3f205607":"markdown","ed85befc":"markdown","7b46e4e2":"markdown","7be017e9":"markdown","40e29065":"markdown","1247a87c":"markdown","369c8cfb":"markdown","88782d1a":"markdown","80a3ef3c":"markdown","6f01b738":"markdown","9e9e950e":"markdown","da39e7c1":"markdown","f5239a81":"markdown","b1650922":"markdown","6a646ba1":"markdown","ec2d8c02":"markdown","7b972381":"markdown","43ce15dc":"markdown","3b6ed850":"markdown","6f3f718a":"markdown","260f5411":"markdown","d9a3a6ee":"markdown","3a6c9b1d":"markdown","3b84acc5":"markdown","4fe78cb4":"markdown","bc97b0dd":"markdown","935752b1":"markdown","552752c0":"markdown","b27e7d34":"markdown","877f0f60":"markdown","5a6cec35":"markdown","943e718b":"markdown"},"source":{"72cb2d01":"# Thanks to https:\/\/www.kaggle.com\/awsaf49\/pydicom-conda-helper for pydicom files\n\n# !wget 'https:\/\/anaconda.org\/conda-forge\/libjpeg-turbo\/2.1.0\/download\/linux-64\/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -q\n# !wget 'https:\/\/anaconda.org\/conda-forge\/libgcc-ng\/9.3.0\/download\/linux-64\/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -q\n# !wget 'https:\/\/anaconda.org\/conda-forge\/gdcm\/2.8.9\/download\/linux-64\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -q\n# !wget 'https:\/\/anaconda.org\/conda-forge\/conda\/4.10.1\/download\/linux-64\/conda-4.10.1-py37h89c1867_0.tar.bz2' -q\n# !wget 'https:\/\/anaconda.org\/conda-forge\/certifi\/2020.12.5\/download\/linux-64\/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -q\n# !wget 'https:\/\/anaconda.org\/conda-forge\/openssl\/1.1.1k\/download\/linux-64\/openssl-1.1.1k-h7f98852_0.tar.bz2' -q\n\n!conda install 'libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install 'libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install 'gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install 'conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install 'certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install 'openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","74b04ab4":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport glob\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom skimage import exposure\nimport cv2\nimport warnings\nfrom fastai.vision.all import *\nwarnings.filterwarnings('ignore')","73e24ed9":"pd.options.display.max_columns = 500\npd.options.display.max_rows=1000","706006df":"from fastai.basics import *\nfrom fastai.callback.all import *\nfrom fastai.vision.all import *\nfrom fastai.medical.imaging import *\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut","dd9bb5dd":"dataset_path = Path('..\/input\/siim-covid19-detection')","8c3e6205":"dataset_path.ls()","57ec88ba":"train_study_df = pd.read_csv(dataset_path\/'train_study_level.csv')\ntrain_image_df = pd.read_csv(dataset_path\/'train_image_level.csv')","b46c4e83":"train_study_df.head()","1704689c":"train_image_df.head()","2a1e8ce8":"train_study_df.shape","82856f1d":"study_classes = ['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']\ntrain_study_df[study_classes].value_counts()","7072ec76":"plt.figure(figsize = (10,5))\nplt.bar([1,2,3,4], train_study_df[study_classes].values.sum(axis=0))\nplt.xticks([1,2,3,4],study_classes)\nplt.ylabel('Frequency')\nplt.show()","53d95cfa":"train_image_df['split_label'] = train_image_df.label.apply(lambda x: [x.split()[offs:offs+6] for offs in range(0, len(x.split()), 6) ]) # start, stop, step","c7d972ce":"train_image_df.head()","4b206f70":"# this is only the distribution of image level labels: opacity and none\nclasses_freq = []\nfor i in range(len(train_image_df)):\n    for j in train_image_df.iloc[i].split_label: classes_freq.append(j[0])\nplt.hist(classes_freq)\nplt.ylabel('Frequency')\n\nprint(classes_freq[:10])","eb87bde6":"train_image_df.head()","472478ce":"bbox_areas = []\nfor i in range(len(train_image_df)):\n    for j in train_image_df.iloc[i].split_label:\n        bbox_areas.append((float(j[4])-float(j[2]))*(float(j[5])-float(j[3])))\nplt.hist(bbox_areas)\nplt.ylabel('Frequency')\n\nprint(bbox_areas[:10])","d37acb30":"# https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    \ndef dicom2array(path, voi_lut=False, fix_monochrome=True):\n    dicom = pydicom.read_file(path)\n    # VOI LUT (if available by DICOM device) is used to\n    # transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n        \n    \ndef plot_img(img, size=(7, 7), is_rgb=True, title=\"\", cmap='gray'):\n    plt.figure(figsize=size)\n    plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()\n\n\ndef plot_imgs(imgs, cols=4, size=7, is_rgb=True, title=\"\", cmap='gray', img_size=(500,500)):\n    rows = len(imgs)\/\/cols + 1\n    fig = plt.figure(figsize=(cols*size, rows*size))\n    for i, img in enumerate(imgs):\n        if img_size is not None:\n            img = cv2.resize(img, img_size)\n        fig.add_subplot(rows, cols, i+1)\n        plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()","0e819da9":"dicom_paths = get_dicom_files(dataset_path\/'train')[:10]\nimgs = [dicom2array(path) for path in dicom_paths]\nplot_imgs(imgs)","729973dc":"num_images_per_study = []\nfor i in (dataset_path\/'train').ls():\n    num_images_per_study.append(len(get_dicom_files(i)))\n    if len(get_dicom_files(i)) > 2:\n        print(f'Study {i} had {len(get_dicom_files(i))} images')","d07b5d59":"plt.hist(num_images_per_study)","5ff57493":"def image_path(row):\n    study_path = dataset_path\/'train'\/row.StudyInstanceUID\n    for i in get_dicom_files(study_path):\n        if row.id.split('_')[0] == i.stem: return i \n        \ntrain_image_df['image_path'] = train_image_df.apply(image_path, axis=1)","6c0f91df":"train_image_df['image_path'].iloc[0].stem, train_image_df['image_path'].iloc[0]","a651ba3f":"train_image_df.head(1)","6123b0b5":"imgs = []\nimage_paths = train_image_df['image_path'].values\n\n# map label_id to specify color\nthickness = 10\nscale = 1\n\n\nfor i in range(8):\n    image_path = random.choice(image_paths)\n    print(image_path)\n    img = dicom2array(path=image_path)\n    img = cv2.resize(img, None, fx=1\/scale, fy=1\/scale)\n    img = np.stack([img, img, img], axis=-1)\n    for i in train_image_df.loc[train_image_df['image_path'] == image_path].split_label.values[0]:\n        if i[0] == 'opacity':\n            img = cv2.rectangle(img,\n                                (int(float(i[2])\/scale), int(float(i[3])\/scale)),\n                                (int(float(i[4])\/scale), int(float(i[5])\/scale)),\n                                [255,0,0], thickness)\n    \n    img = cv2.resize(img, (500,500))\n    imgs.append(img)\n    \nplot_imgs(imgs, cmap='gray')","d1fcd6c8":"train_image_df.head()","96037981":"def get_label(row):\n    for c in train_study_df.columns:\n        if row[c] == 1:\n            return str.lower(c.split(\" \")[0])\n\ntrain_study_df['study_label'] = train_study_df.apply(get_label, axis=1)","8bc2d808":"train_study_df['StudyInstanceUID'] = train_study_df['id'].apply(lambda x: x.split('_')[0])","e41130b8":"train_study_df = train_study_df.rename(columns={'id': 'study_id'})\ntrain_image_df = train_image_df.rename(columns={'id': 'image_id'})\ntrain_study_df.head()","817fd3ec":"train_image_df.shape, train_study_df.shape","a7e1a284":"train_image_df['ImageInstanceUID'] = train_image_df['image_id'].apply(lambda x: x.split('_')[0])\ntrain_image_df.head(2)","d3e77ffc":"def get_num_opacities(labels):\n    num_opacities = 0\n    for i in labels:\n        if i[0] == 'opacity':\n            num_opacities += 1\n    return num_opacities","15314042":"combined_df = train_image_df.merge(train_study_df, on='StudyInstanceUID')\ncombined_df['num_opacities'] = combined_df.split_label.apply(get_num_opacities)\ncombined_df.to_csv('study_image_combined_df.csv', index=False)\ncombined_df.head(2)","fd857f23":"train_study_df.shape, train_image_df.shape, combined_df.shape","0873997e":"# image_level_dicom_data = pd.DataFrame.from_dicoms(combined_df.image_path.values)\n# len(image_level_dicom_data)\n                          \n# train_image_dicom_df = pd.DataFrame(image_level_dicom_data)\n# train_image_dicom_df['ImageInstanceUID'] = train_image_dicom_df.fname.apply(lambda x: Path(x).stem)\n# train_image_dicom_df.to_csv('image_dicom_data.csv', index=False)","563f7229":"# train_image_dicom_df[train_image_dicom_df['StudyDate']=='284b97d038b7']\n\n# study_image_dicom_combined_df = combined_df.merge(train_image_dicom_df, on='ImageInstanceUID')\n# study_image_dicom_combined_df.drop('StudyInstanceUID_x', axis=1)\n# study_image_dicom_combined_df = study_image_dicom_combined_df.rename(columns={'StudyInstanceUID_x': 'StudyInstanceUID'})\n# study_image_dicom_combined_df['num_opacities'] = study_image_dicom_combined_df.split_label.apply(get_num_opacities)\n# study_image_dicom_combined_df.to_csv('study_image_dicom_combined_data.csv', index=False)","dbaeb83b":"# combined_df = pd.read_csv('..\/input\/siimcovidcsvfiles\/study_image_dicom_combined_data.csv')","8e1b276c":"combined_df.head(2)","62cf2781":"combined_df['study_label'].value_counts()","e26fb661":"combined_df['study_label'].count()","b0ed0162":"combined_df['ImageInstanceUID'].unique().shape, combined_df['StudyInstanceUID'].unique().shape ","a78ae8c5":"(combined_df[(combined_df['num_opacities']==0) &\n                              (combined_df['study_label']=='negative')]['study_label'].value_counts(), \n\n combined_df[(combined_df['num_opacities']==0) &\n                              (combined_df['study_label']=='negative')]['StudyInstanceUID'].unique().shape)","702e4a82":"combined_df['StudyInstanceUID'].value_counts()","408e161e":"studies_with_more_than_1_image = \\\ncombined_df[combined_df['StudyInstanceUID'].isin([s for s, i in combined_df['StudyInstanceUID'].value_counts().items() if i>1])]","f5e111dc":"(studies_with_more_than_1_image['StudyInstanceUID'].unique().shape, \nstudies_with_more_than_1_image.study_label.value_counts(), \nstudies_with_more_than_1_image.shape)","39af4177":"combined_df[(combined_df['num_opacities']==0) &\n                              (combined_df['study_label']!='negative')]['study_label'].value_counts()","057f76bd":"non_negative_no_bb_images = combined_df[(combined_df['num_opacities']==0) &\n                              (combined_df['study_label']!='negative')]\nnon_negative_no_bb_images.shape","f77166d5":"# separate the images which have proper labels and have co-ordinates if applicable vs the images under suspicion\ncombined_df_new = combined_df.drop(non_negative_no_bb_images.index)","1cbcc0f8":"combined_df.shape, combined_df_new.shape, non_negative_no_bb_images.shape","2567a92c":"non_negative_no_bb_images['StudyInstanceUID'].value_counts()[:25], non_negative_no_bb_images['StudyInstanceUID'].unique().shape, non_negative_no_bb_images.shape","f694c9c0":"# len((set(non_negative_no_bb_images['StudyInstanceUID']).union(set(studies_with_more_than_1_image['StudyInstanceUID'].unique()))).difference(\n# (set(non_negative_no_bb_images['StudyInstanceUID']).intersection(set(studies_with_more_than_1_image['StudyInstanceUID'].unique())))))\n\n\nprint(\"Number of unique non-negative studies with no BB: {}\".format(\n    len(set(non_negative_no_bb_images['StudyInstanceUID']).intersection(\n        set(studies_with_more_than_1_image['StudyInstanceUID'].unique())))))\n\nprint(\"Total unique studies with more than 1 image: {}\".format(\n    studies_with_more_than_1_image['StudyInstanceUID'].unique().shape))\n\nlen(\"Total negative studies with duplicate images: {}\".format(\n    (set(studies_with_more_than_1_image['StudyInstanceUID'].unique())).difference(\n    (set(non_negative_no_bb_images['StudyInstanceUID'].unique())).intersection(\n        set(studies_with_more_than_1_image['StudyInstanceUID'].unique())))))\n","41989aaa":"multi_image_negative_study_df = combined_df[combined_df['StudyInstanceUID'].isin((set(studies_with_more_than_1_image['StudyInstanceUID'].unique())).difference(\n    (set(non_negative_no_bb_images['StudyInstanceUID']).intersection(set(studies_with_more_than_1_image['StudyInstanceUID'].unique())))))]\n\nmulti_image_negative_study_df.study_label.value_counts(), multi_image_negative_study_df.StudyInstanceUID.unique().shape","523e2d10":"bad_images = []\nfor study_id in multi_image_negative_study_df.StudyInstanceUID.unique():\n    print(study_id)\n    rows = multi_image_negative_study_df[multi_image_negative_study_df['StudyInstanceUID']==study_id]\n    print(rows.ImageInstanceUID)\n    try:\n        rows = multi_image_negative_study_df[multi_image_negative_study_df['StudyInstanceUID']==study_id]\n        dcmimg = [pydicom.dcmread(i) for i in rows.image_path]\n        row_cols = [(item.Rows, item.Columns) for item in dcmimg]\n        imgs = [dicom2array(path) for path in rows.image_path]\n        print(row_cols)\n        img_avrages = [im.mean() for im in imgs]\n        print(img_avrages)\n        plot_imgs(imgs)\n        \n    except Exception as e:\n        bad_images.append((study_id, list(rows.ImageInstanceUID), list(rows.image_path)))\n        print(e)\n        print(f\"check {study_id} manually\")","61d51fa0":"# need help figuring out which images to remove and how to go about this\nduplicate_images_negative_label_images = ['0d4d6acc9ed3','93a881fb3292','cdd9e3aaf45a','68ad4b624a6d','cbf0a27f993e','b61f3493c551','0b020a7aff0a','3e7b2ffc97db','ace7a9702770','e96133d06736','9108cdfd43dc','e897ef5c203c','d180fed57716','f208dc529d16','ea2688741043','21518ca15050','bdd3115879aa','a1fa5f79671d','59bc532be971','b0866caa201a','ea516e218fe6','93301812b0e7','a2ee4b862182','d9456aadecbe']\nlen(duplicate_images_negative_label_images)","a29d1fc7":"print(combined_df_new.shape)\ncombined_df_new = combined_df_new.drop(\n    combined_df_new[combined_df_new.ImageInstanceUID.isin(duplicate_images_negative_label_images)].index)\nprint(combined_df_new.shape)","3b399cfa":"non_negative_no_bb_images.StudyInstanceUID.unique().shape, non_negative_no_bb_images.shape","8e1c66cc":"common_studies = non_negative_no_bb_images[non_negative_no_bb_images['StudyInstanceUID'].isin(combined_df_new['StudyInstanceUID'])]\n\nprint(\"Images with no BB which are a part of non-negative study which has more than 1 image: {}\".format(common_studies.shape))\nprint(\"NonNegative studie with more than 1 image: {}\".format(common_studies['StudyInstanceUID'].unique().shape))\nprint(\"TotalUnique images here: {}\".format(common_studies['ImageInstanceUID'].unique().shape))","1067e6ad":"common_studies.study_label.value_counts(), common_studies.StudyInstanceUID.unique().shape","1fcf1b19":"# in the original combined dataframe, we can see that there are 177 studies with more than 1 image. We capture the images for these 177 studies\n# which have atleast 1 bounding box. We can ignore the rest of the images for these studies since a study will have 1 label and all the images under\n# that study should have the same label\ncombined_df_new[combined_df_new['StudyInstanceUID'].isin(common_studies['StudyInstanceUID'])]['StudyInstanceUID'].shape","8d418cb7":"uncommon_studies = non_negative_no_bb_images[~non_negative_no_bb_images['StudyInstanceUID'].isin(common_studies['StudyInstanceUID'])]\nuncommon_studies.StudyInstanceUID.unique().shape, uncommon_studies.shape","520f9244":"uncommon_studies.study_label.value_counts()","8eac216c":"uncommon_studies[uncommon_studies['study_label']=='typical']","637ef6f4":"uncommon_studies = uncommon_studies.drop(1793)","abbdc167":"set(uncommon_studies.StudyInstanceUID).intersection(set(combined_df_new.StudyInstanceUID))","8a70db7b":"uncommon_studies.StudyInstanceUID.value_counts()[:5]","ca7953d4":"bad_images = []\nfor study_id in [\"0d9709b3af74\", \"784afbafee30\"]:\n    print(study_id)\n    rows = uncommon_studies[uncommon_studies['StudyInstanceUID']==study_id]\n    print(rows.ImageInstanceUID)\n    try:\n        rows = uncommon_studies[uncommon_studies['StudyInstanceUID']==study_id]\n        dcmimg = [pydicom.dcmread(i) for i in rows.image_path]\n        row_cols = [(item.Rows, item.Columns) for item in dcmimg]\n        imgs = [dicom2array(path) for path in rows.image_path]\n        print(row_cols)\n        print([im.mean() for im in imgs])\n        plot_imgs(imgs)\n    except Exception as e:\n        bad_images.append((study_id, list(rows.ImageInstanceUID), list(rows.image_path)))\n        print(e)\n        print(f\"check {study_id} manually\")","2e9afde6":"uncommon_studies = uncommon_studies.drop(\n    uncommon_studies[uncommon_studies['ImageInstanceUID'].isin([\"efc93a3917b6\", \"830063223a31\"])].index)","f1656a8d":"uncommon_studies.shape","29133c2c":"combined_df_new.shape","6629b84c":"final_df = pd.concat([combined_df_new, uncommon_studies])","285723ca":"final_df.shape, train_image_df.shape, studies_with_more_than_1_image.shape","effe4264":"final_df.to_csv('cleaned_data-v1.csv', index=False)","29165a39":"# let's see the remaining duplicate images available to us\n\nbad_images = []\nfor study_id, cont in final_df.StudyInstanceUID.value_counts()[:30].items():\n    print(study_id)\n    rows = final_df[final_df['StudyInstanceUID']==study_id]\n    print(rows.ImageInstanceUID)\n    try:\n        rows = final_df[final_df['StudyInstanceUID']==study_id]\n        imgs = [dicom2array(path) for path in rows.image_path]\n        plot_imgs(imgs)\n        dcmimg = [pydicom.dcmread(i) for i in rows.image_path]\n        row_cols = [(item.Rows, item.Columns) for item in dcmimg]\n        print(row_cols)\n    except Exception as e:\n        bad_images.append((study_id, list(rows.ImageInstanceUID), list(rows.image_path)))\n        print(e)\n        print(f\"check {study_id} manually\")","3f205607":"Let's also look at the distribution of the bounding box areas:","ed85befc":"we see more labels than the number of images because some images are tagged with more than 1 label because they have more than 1 nodes in them","7b46e4e2":"As you can see, at the study-level, we are predicting the following classes:\n* Negative for Pneumonia\n* Typical Appearance\n* Indeterminate Appearance\n* Atypical Appearance\n\nThis here is a standard multi-label classification problem. In the training set, interestingly they are not multi-label, but it is mentioned that:\n> Studies in the test set may contain more than one label.\n\nLet's look at the distribution:\n","7be017e9":"Here, we get common studies. These are studies which are labelled with a `non-negative` tag and have images in which some images have opacities marked and some don't.\n\nWe can see that out of the 261 studies with images with no bounding boxes, 177 of those studies have atleast 1 image with a bounding box and we've captured that image in our dataframe `combined_df_new` along with the study details.","40e29065":"Most of thse images are different enough for us to consider them.","1247a87c":"## Combined analysis","369c8cfb":"There are 113 negative labeled images which are repeated under 53 studies. We will need to manually select the image that we want to use in each of the studies","88782d1a":"There are studies with multiple images which have no bounding boxes and out of these studies some are captured in our new dataframe.","80a3ef3c":"The previous 60 duplicate images can be found here. We'll need to manually select the images we want to use for these studies","6f01b738":"# Image level analysis","9e9e950e":"# A look at the images\n\nOkay, let's now look at some example images:","da39e7c1":"**Okay, so now we have**\n- non_negative_no_bb_images: images which are part of studies which are non negative. But these images have no bounding boxes in them which is odd\n- combined_df: study and image combined data where we map all the study level labels to all the corresponding images","f5239a81":"We can see that the 177 unique studies that we have in common (which have some images with bounding boxes and some with no bounding boxes) are covered in the dataframe where we separated out the bad data.","b1650922":"We can see that we have:\n\n* `train_study_level.csv` - the train study-level metadata, with one row for each study, including correct labels.\n* `train_image_level.csv` - the train image-level metadata, with one row for each image, including both correct labels and any bounding boxes in a dictionary format. Some images in both test and train have multiple bounding boxes.\n* `sample_submission.csv` - a sample submission file containing all image- and study-level IDs.\n* `train` folder - comprises 6,334 chest scans in DICOM format, stored in paths with the form `study`\/`series`\/`image`\n* `test` folder \n\nThe hidden test dataset is of roughly the same scale as the training dataset.\n","6a646ba1":"## Analyzing negative labelled studies with duplicate images\nWe will need to separate duplicate images with negative labels","ec2d8c02":"There are 86 atypical images wth no opacity defined and 1 typical image with no opacity defined. the latter seems like an anomaly and we can probably remove that and use the other 86 atypical ones. Let's also make sure that these are not already accounted for","7b972381":"## Understandig images with no opacities but non negative label","43ce15dc":"There are 304 images which are a part of 261 studies which don't have bounding boxes","3b6ed850":"There are 232 unique studies with more than 1 image, and we can also see the division of duplicate images accross these studies.\n\nWe are dealing with 2 types of bad data\n- Duplicate images in studies which don't add much value\n- Images which are labelled as non-negative but don't have proper bounding boxes\n- Images which are both, i.e are duplicated in a study and have no bounding boxes s","6f3f718a":"Let's check what data is available to us:","260f5411":"Now, to get all the images that are useful, we need to select from the above data frames.","d9a3a6ee":"We have our bounding box labels provided in the `label` column. The format is as follows:\n\n`[class ID] [confidence score] [bounding box]`\n\n* class ID - either `opacity` or `none`\n* confidence score - confidence from your neural network model. If none, the confidence is `1`.\n* bounding box - typical `xmin ymin xmax ymax` format. If class ID is none, the bounding box is `1 0 0 1 1`.\n\nThe bounding boxes are also provided in easily readable dictionary format in column `boxes`, and the study that each image is a part of is provided in`StudyInstanceUID`.\n\nLet's quick look at the distribution of opacity vs none:","3a6c9b1d":"# A look at the provided data","3b84acc5":"Let's now look at `train_image_level.csv`:","4fe78cb4":"As expected, all the negative labelled images have no bounding boxes associated with them. On top of that, we have 60 duplicate images 1736 - 1676 = 60\n","bc97b0dd":"# A look at the CSVs\n\nLet's check the `train_study_level.csv` file:","935752b1":"# SIIM-FISABIO-RSNA COVID-19 Detection: A simple EDA \n\nIn this competition, we are provided with DICOM images of chest X-ray radiographs, and we are asked to identify and localize COVID-19 abnormalities. This is important because typical diagnosis of COVID-19 requires molecular testing (polymerase chain reaction) requires several hours, while chest radiographs can be obtained in minutes, but it is hard to distinguish between COVID-19 pneumonia and other other viral and bacterial pneumonias. Therefore, in this competition, be hope to develop AI that that eventually help radiologists diagnose the millions of COVID-19 patients more confidently and quickly.\n\nI'll provide a quick and simple EDA to help you get started with this very interesting competition!","552752c0":"# Bad and duplicate data\nLet's look at the images which have no bounding box but are labelled as not negative \n","b27e7d34":"Let's actually look at how many images are available per study:","877f0f60":"Now, we've separated the images with no bounding boxes and which are non negative with the images which have bounding boxes \n\nSo, we have 177 studies which have images with an opacity and images without an opacity. These 177 have multiple images attached to them and we've filtered out the images with no opacity out from the DF. Let's check how many images the remaining studies have in the DF","5a6cec35":"Let's look at the unique labels:","943e718b":"# Imports\nLet's start out by setting up our environment by importing the required modules:"}}