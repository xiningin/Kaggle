{"cell_type":{"1a714f73":"code","2376a16d":"code","e7c3ab2e":"code","39c60104":"code","ce5048a1":"code","0004878d":"code","262c5b46":"code","a254fec6":"code","e64aa84c":"code","137eea08":"code","c9165a0b":"code","9dfed5b9":"code","d7a4b08c":"code","c2e48831":"code","25924593":"code","33722234":"code","358fb51c":"code","750a0009":"code","5aa3b00f":"code","17af7956":"markdown","f2f639fa":"markdown","9dac21b7":"markdown","6dd10268":"markdown","65311ab2":"markdown","6195592f":"markdown","369bbb80":"markdown","37a7c03a":"markdown","288d1ea5":"markdown"},"source":{"1a714f73":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2376a16d":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.style.use('ggplot')\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nimport xgboost\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')","e7c3ab2e":"data = pd.read_csv('\/kaggle\/input\/heart-failure-prediction\/heart.csv')\ndata.head()","39c60104":"data.columns = data.columns.str.lower()","ce5048a1":"data.head()","0004878d":"data.shape","262c5b46":"data.info()","a254fec6":"data.isnull().sum()","e64aa84c":"heart_prob = data[data['heartdisease'] == 1]\nplt.figure(figsize=(12,8))\ns = sns.countplot(heart_prob.sex)\nfor p in s.patches:\n    s.annotate(format(p.get_height(), '.1f'), \n               (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                xytext = (0, 9), \n                textcoords = 'offset points'\n              )\nplt.show()","137eea08":"plt.figure(figsize=(12,8))\nplt.hist(heart_prob.age, histtype='step', color='black')\nplt.xlabel('age')\nplt.ylabel('count')\nplt.xticks(rotation=45)\nplt.show()","c9165a0b":"plt.figure(figsize=(12,8))\nsns.distplot(heart_prob.age)\nplt.show()","9dfed5b9":"data['sex'].replace({'M': 1, 'F': 0}, inplace=True)\ndata.chestpaintype.replace({'ASY': 0, 'NAP': 1, 'ATA': 2, 'TA': 3}, inplace=True)\ndata.restingecg.replace({'Normal': 0, 'LVH': 1, 'ST': 2}, inplace=True)\ndata['exerciseangina'].replace({'Y': 1, 'N': 0}, inplace=True)\ndata.st_slope.replace({'Flat': 0, 'Up': 1, 'Down': 2}, inplace=True)\ndata.head()","d7a4b08c":"plt.title('Distribution plots of all features')\nfor cols in data.columns:\n    sns.distplot(data[cols])\n    plt.show()","c2e48831":"X = data.drop('heartdisease', axis=1)\nY = data['heartdisease']","25924593":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=999, test_size=0.1)","33722234":"models = [(\"Logistic Regression\", LogisticRegression(random_state=0, max_iter=1000)),\n          (\"Support vectors\", SVC(random_state=0)),\n          (\"Random Forest\", RandomForestClassifier(random_state=0)),\n          (\"Decision Trees\", DecisionTreeClassifier(random_state=0)),\n          (\"XGBoost\", xgboost.XGBClassifier(random_state=0)),\n          ('Gradient Boosting', GradientBoostingClassifier(random_state=0))\n         ]","358fb51c":"results = []\nnames=[]\nfinalresults=[]\n\nfor name, model in models:\n    model.fit(X_train, Y_train)\n    model_results = model.predict(X_test)\n    score= accuracy_score(Y_test, model_results)\n    results.append(score)\n    names.append(name)\n    finalresults.append((name,score))","750a0009":"# Visualising the accuracy score of each classification model\nplt.rcParams['figure.figsize']=15,8 \nplt.style.use('dark_background')\nax = sns.barplot(x=names, y=results, palette = \"rocket\", saturation =1.0)\nplt.xlabel(\"Classifier Models\", fontsize = 20 )\nplt.ylabel(\"% of Accuracy\", fontsize = 20)\nplt.title(\"Accuracy of different Classifier Models\", fontsize = 20)\nplt.xticks(fontsize = 13, horizontalalignment = 'center', rotation = 0)\nplt.yticks(fontsize = 13)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{height:.2%}', (x + width\/2, y + height*1.02), ha='center', fontsize = 'x-large')\n#     print(width)\n#     print(height)\nplt.show()","5aa3b00f":"index = results.index(max(results))\nprint(f\"{names[index]} has the highest accuracy of {max(results)}\")","17af7956":"# Reading data","f2f639fa":"# EDA","9dac21b7":"Here we come to know that there are more number of males than the females who are prone to heart failures.","6dd10268":"All columns are asymptotically guassian","65311ab2":"Age feature is asymptotically gaussian.","6195592f":"# Data Preparation","369bbb80":"By above graph, we get to know that most of heart risk is in between the age 50 to 60","37a7c03a":"# Libraries required","288d1ea5":"# Model Training and validation"}}