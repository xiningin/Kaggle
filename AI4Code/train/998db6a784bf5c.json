{"cell_type":{"b86e6585":"code","8b28a179":"code","14f334f3":"code","5a2d19b6":"code","e04d8c87":"code","b60d5197":"code","cfa10e72":"code","3ca92f95":"code","dddb683a":"code","89a70ba1":"code","44faa48a":"code","32c9cfe2":"code","07cb2c95":"code","e130d01e":"code","e4141dc6":"code","03210f1e":"code","d23e9ae5":"code","f53ca610":"code","aa5de94f":"code","4c53d84a":"code","4d1387f4":"code","0645b76e":"code","bd7d93a0":"code","1f066562":"code","566bf304":"code","9ed8fca2":"code","8366e0d8":"code","3331937d":"markdown","7a4a6d8e":"markdown","e019a98f":"markdown","88d74aa3":"markdown","9b6fadfe":"markdown","1facc178":"markdown","63bc9cd7":"markdown","7c023511":"markdown","8386fa8b":"markdown"},"source":{"b86e6585":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8b28a179":"import re\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix","14f334f3":"#Read the dataset\ndata = pd.read_csv('..\/input\/sms-spam-collection-dataset\/spam.csv',encoding=\"ISO-8859-1\")\ndata.head()","5a2d19b6":"#Drop unwanted columns\ndata.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1,inplace=True)","e04d8c87":"#Rename columns\ndata.rename(columns={\"v1\": \"target\", \"v2\": \"sms\"},inplace=True)","b60d5197":"#Take a copy from original dataset\ndf=data.copy()\ndf.head()","cfa10e72":"#to check how many observations belongs to each class\ndf['target'].value_counts()","3ca92f95":"#check duplicates\ndf['sms'].duplicated().sum()","dddb683a":"#remove all duplicate rows\ndf.drop_duplicates(inplace=True)","89a70ba1":"#reset index\ndf.reset_index(inplace=True)","44faa48a":"#remove old index column\ndf.drop(\"index\",axis=1,inplace=True)","32c9cfe2":"#check missing values\ndf.isna().sum()","07cb2c95":"#0->ham (or good sms) 1->spam \nle=LabelEncoder()\ndf['target']=le.fit_transform(df['target'])\ndf.head()","e130d01e":"#cleaning text\n\ncorpus=[] #Empty list\n\nfor i in range(df.shape[0]):\n    review=re.sub('[^a-zA-Z]',' ',df['sms'][i]) #apart from a-z and A-Z, replace everything else with blank spaces\n    review=review.lower() #convert all the words into lower case\n    corpus.append(review) #append cleaned texts to above empty list","e4141dc6":"#add features column to df dataframe\ndf['features']=corpus\ndf.head()","03210f1e":"x=df['features']\ny=df['target']","d23e9ae5":"cvec=CountVectorizer()\ncvdf=cvec.fit_transform(x)","f53ca610":"cvdf.toarray()","aa5de94f":"#As aforementioned, this is unbalanced dataset. Therefore, we need to convert it into balanced way.  \nsm=SMOTE()\nx_sm,y_sm=sm.fit_resample(cvdf,y)","4c53d84a":"#Problem solved!!!\ny_sm.value_counts()","4d1387f4":"x_train,x_test,y_train,y_test=train_test_split(x_sm,y_sm,test_size=0.2,random_state=0)","0645b76e":"#I have used only support vector machine but you can use different techniques, which can be improved accuracy.\nsvm=SVC(kernel='linear')\nsvm.fit(x_train,y_train)\ny_pred=svm.predict(x_test)\naccuracy_score(y_test,y_pred)","bd7d93a0":"from mlxtend.plotting import plot_confusion_matrix\nmat=confusion_matrix(y_test, y_pred)\nplot_confusion_matrix(conf_mat=mat)","1f066562":"print(classification_report(y_test,y_pred))","566bf304":"sms=[\"Hey, you have won a car !!!!. Conrgratzz\",\n     \"Dear applicant, Your CV has been recieved. Best regards\",\n     \"YOU ARE CHOSEN TO RECEIVE A \u00e5\u00a3350 AWARD! Pls call claim to collect your award which you are selected to receive as a valued mobile customer.\"\n    ]","9ed8fca2":"#cleaning text\nunseen=[]\n\nfor i in range(len(sms)):\n    review=re.sub('[^a-zA-Z]',' ',sms[i])\n    review=review.lower()\n    unseen.append(review)","8366e0d8":"#0->ham (or good sms) 1->spam \nyp=svm.predict(cvec.transform(unseen))\nyp","3331937d":"**<h3>Checking the model with new sample sms<\/h3>**","7a4a6d8e":"<h3>Needful libraries<\/h3>","e019a98f":"**<h3>Split data into train and test<\/h3>**","88d74aa3":"**<h3>Separating independent and dependent data<\/h3>**","9b6fadfe":"**<h3>Apply SMOTE<\/h3>**","1facc178":"**<h3>Bag of Word<\/h3>**","63bc9cd7":"**<h3>Data Wrangling<\/h3>**","7c023511":"In lieu of Bag of Words, you can use Tf-idf, word2vec etc..","8386fa8b":"**<h3>Model building<\/h3>**"}}