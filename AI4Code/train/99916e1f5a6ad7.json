{"cell_type":{"20cb9212":"code","b2868627":"code","6192b4d2":"code","228a47ab":"code","ac02b41b":"code","1eb6d4b9":"code","12b2c552":"code","3f2d38f6":"code","bfef533d":"code","3862aa96":"code","542e8c51":"code","7434e255":"code","77ba8df1":"code","b4a5d29f":"code","6096f9c5":"code","ecddc6ac":"code","306cfa5a":"code","f3bedc45":"code","2dd25289":"code","47d5a5db":"code","ed22c60c":"code","9addd829":"code","3a51faff":"code","d9d0db1a":"code","2a0d5174":"code","7a0ee456":"code","e889f58f":"code","a6676fc3":"code","eca6c182":"code","949ab975":"code","95e4ec42":"code","c721bbcc":"code","a2ca0d9d":"code","b9ac01b5":"code","e31dca49":"code","f767819c":"code","146fff26":"code","eaf15c71":"code","05e9b840":"code","d2f03c92":"code","5f49b145":"code","20fecc5f":"code","7b192c15":"code","4620e1f7":"code","2115b273":"code","a7a6a051":"code","4e17a187":"code","3eefd352":"code","dcb7734b":"code","6d113bb6":"code","060895c9":"code","3e6dca04":"code","ea8d89d5":"code","f415462f":"markdown","813e4471":"markdown","5eff767c":"markdown","698e7aa4":"markdown","e877f342":"markdown","13247d87":"markdown","41ee6e50":"markdown","b924d8f3":"markdown","56fe1bdc":"markdown","6e1bc967":"markdown"},"source":{"20cb9212":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b2868627":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation,Dropout\n\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","6192b4d2":"#import datesets\ntrain = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')","228a47ab":"train.head()","ac02b41b":"plt.figure(figsize=(10,6))\nsns.set_style('whitegrid')\nsns.countplot(x='Survived',data=train,palette='coolwarm')","1eb6d4b9":"plt.figure(figsize=(10,6))\nsns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Sex',data=train,palette='coolwarm')","12b2c552":"plt.figure(figsize=(10,6))\nsns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Pclass',data=train,palette='rainbow')","3f2d38f6":"plt.figure(figsize=(10,6))\ntrain['Age'].hist(bins=30,color='blue')","bfef533d":"plt.figure(figsize=(10, 7))\nsns.boxplot(x='Pclass',y='Age',data=train,palette='rainbow')","3862aa96":"plt.figure(figsize=(10,6))\nsns.histplot(train['Fare'].dropna(),color='darkred',bins=30)","542e8c51":"#Missing data check\nplt.figure(figsize=(10,6))\nsns.heatmap(train.isnull(),cmap='viridis')","7434e255":"plt.figure(figsize=(10,6))\nsns.heatmap(test.isnull(),cmap='viridis')","77ba8df1":"print(f\"Average Age of Pclass 1 passengers {train[train['Pclass']==1]['Age'].mean():.2f}\")\n\nprint(f\"Average Age of Pclass 2 passengers {train[train['Pclass']==2]['Age'].mean():.2f}\")\n\nprint(f\"Average Age of Pclass 3 passengers {train[train['Pclass']==3]['Age'].mean():.2f}\")\n","b4a5d29f":"#filling missing values for Age based on the Pclass\ndef fill_age(c):\n    Age = c[0]\n    Pclass = c[1]\n    \n    if pd.isnull(Age):\n        if Pclass == 1:\n            return 44\n        elif Pclass == 2:\n            return 38\n        else:\n            return 33\n    else:\n        return Age\n\ntrain['Age'] = train[['Age','Pclass']].apply(fill_age,axis=1)\ntest['Age'] = train[['Age','Pclass']].apply(fill_age,axis=1)","6096f9c5":"train.drop(['Ticket','Cabin'],axis=1,inplace=True)\ntest.drop(['Ticket','Cabin'],axis=1,inplace=True)","ecddc6ac":"plt.figure(figsize=(10,6))\nsns.heatmap(train.isnull(),cmap='viridis')","306cfa5a":"plt.figure(figsize=(10,6))\nsns.heatmap(test.isnull(),cmap='viridis')","f3bedc45":"imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\ntrain[['Fare']] = imputer.fit_transform(train[['Fare']])\ntest[['Fare']] = imputer.fit_transform(test[['Fare']])","2dd25289":"imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\ntrain[['Embarked']] = imputer.fit_transform(train[['Embarked']])\ntest[['Embarked']] = imputer.fit_transform(test[['Embarked']])","47d5a5db":"sns.heatmap(test.isnull(),cmap='viridis')","ed22c60c":"sns.heatmap(test.isnull(),cmap='viridis')","9addd829":"print(train.info())\nprint(test.info())","3a51faff":"#train data\nS = pd.get_dummies(train['Sex'],drop_first=True)\nE = pd.get_dummies(train['Embarked'],drop_first=True)\ntrain = pd.concat([train,S,E],axis=1)\ntrain.drop(['Sex','Embarked','Name'],axis=1,inplace=True)","d9d0db1a":"#test data\nS = pd.get_dummies(test['Sex'],drop_first=True)\nE = pd.get_dummies(test['Embarked'],drop_first=True)\ntest = pd.concat([test,S,E],axis=1)\ntest.drop(['Sex','Embarked','Name'],axis=1,inplace=True)\n","2a0d5174":"train.head()","7a0ee456":"plt.figure(figsize=(10,6))\nsns.heatmap(train.corr(),cmap='rainbow')","e889f58f":"train.corr()['Survived']","a6676fc3":"test.head()","eca6c182":"print(train.shape)\nprint(test.shape)","949ab975":"X = train.drop(['PassengerId','Survived'],axis=1)\ny = train['Survived']","95e4ec42":"test","c721bbcc":"sc = StandardScaler()\nX = sc.fit_transform(X)\n#test data\nscaled_test = sc.transform(test.drop('PassengerId',axis=1))","a2ca0d9d":"X","b9ac01b5":"scaled_test","e31dca49":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30,random_state=100)","f767819c":"print(X_train.shape)\nprint(X_test.shape)","146fff26":"lr = LogisticRegression()\nlr.fit(X_train,y_train)\npredictions = lr.predict(X_test)","eaf15c71":"print(f'Classification Report\\n {classification_report(y_test,predictions)}')\nprint(f'Confusion Matrix \\n {confusion_matrix(y_test,predictions)}')\nprint(f'\\nAccuracy: {accuracy_score(y_test,predictions)*100:.2f}%')\n","05e9b840":"#fitting the whole train data and predciting results for test data\nlr.fit(X,y)\nlr_prediction = lr.predict(scaled_test)","d2f03c92":"submission = pd.DataFrame({'PassengerId': test['PassengerId'],'Survived':lr_prediction.flatten()}) \nsubmission.to_csv('submission.csv',index=False)","5f49b145":"rf = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = 0)\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)","20fecc5f":"print(f'Classification Report\\n {classification_report(y_test,y_pred)}')\nprint(f'Confusion Matrix \\n {confusion_matrix(y_test,y_pred)}')\nprint(f'\\nAccuracy: {accuracy_score(y_test,y_pred)*100:.2f}%')\n","7b192c15":"#fitting the whole train data and predciting results for test data\nrf.fit(X,y)\nrf_prediction = rf.predict(scaled_test)","4620e1f7":"submission = pd.DataFrame({'PassengerId': test['PassengerId'],'Survived':rf_prediction.flatten()}) \nsubmission.to_csv('submission.csv',index=False)","2115b273":"model = Sequential()\nmodel.add(Dense(units=30,activation='relu'))\nmodel.add(Dense(units=15,activation='relu'))\nmodel.add(Dense(units=1,activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam')","a7a6a051":"model.fit(x=X_train,y=y_train,epochs=100,validation_data=(X_test, y_test), verbose=1)","4e17a187":"model_loss = pd.DataFrame(model.history.history)\nmodel_loss.plot()","3eefd352":"tf_prediction = model.predict_classes(X_test)","dcb7734b":"print(f'Classification Report\\n {classification_report(y_test,tf_prediction)}')\nprint(f'Confusion Matrix \\n {confusion_matrix(y_test,tf_prediction)}')\nprint(f'\\nAccuracy: {accuracy_score(y_test,tf_prediction)*100:.2f}%')\n","6d113bb6":"#Whole train dataset\nmodel.fit(x=X,y=y,epochs=100,verbose=1)","060895c9":"tf_prediction = model.predict_classes(scaled_test)","3e6dca04":"submission = pd.DataFrame({'PassengerId': test['PassengerId'],'Survived':tf_prediction.flatten()}) \nsubmission.to_csv('submission.csv',index=False)","ea8d89d5":"submission","f415462f":"test.head()","813e4471":"**Data Scaling**","5eff767c":"# EDA","698e7aa4":"**Missing Values**","e877f342":"# Logistic Regression Model","13247d87":"**Splitting the train data for model building**","41ee6e50":"**Encoding Categroical Data**","b924d8f3":"# ANN","56fe1bdc":"# Random Forest Classifier","6e1bc967":"**Evaluation**"}}