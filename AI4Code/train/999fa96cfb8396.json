{"cell_type":{"f5a5fb34":"code","9697ca80":"code","2dd50aeb":"code","616e3174":"code","d9fc5976":"code","9017ad49":"code","bc48dc1e":"code","45b72828":"code","bb6fd4a0":"code","e9dbbdda":"code","af326f27":"code","e19b3f3a":"code","c4e3ba59":"code","4b54c077":"code","cc39c1d9":"code","71617d34":"code","8b97ccea":"code","329a794b":"code","6a859454":"code","52f69f30":"code","43062a0e":"code","caf02515":"code","06ea5bbb":"code","9f138a64":"code","6c23a4ae":"code","c2406e38":"code","4450c458":"code","13c11197":"code","70b590fc":"code","024983e6":"code","99c16075":"code","8e71ce9c":"code","a4f95972":"code","8c681723":"code","126d577a":"code","193b759a":"code","2f2ad2e8":"code","74c34d09":"code","926542d7":"code","95572469":"code","5cbf5bc7":"code","0386b39f":"code","17c547b4":"code","47cd3b17":"code","3ea6854f":"code","2eab0054":"code","a510a7f9":"code","59cc291b":"code","5536932e":"code","5c65d5fd":"code","7b7e3cce":"code","52e4e828":"code","9d11262d":"code","9f4275de":"code","15fe55fc":"code","e6e47c6a":"code","163fb8aa":"markdown","c6cfc33e":"markdown","bdb5db10":"markdown","4c4fe99b":"markdown","b68fd2c6":"markdown","99140369":"markdown","33935119":"markdown","e8d62f08":"markdown","bffe7ab6":"markdown","d643ce32":"markdown","09cf382c":"markdown","f87c63dd":"markdown","1f84110c":"markdown","bcf08fab":"markdown","5a3e682d":"markdown","08577c9f":"markdown","353f712e":"markdown","a481bdb7":"markdown","826dc208":"markdown","7326cab3":"markdown","0cda0252":"markdown","47ee4918":"markdown","44325b22":"markdown","b1780f09":"markdown","bc4e0e3e":"markdown","6eedadef":"markdown","63396075":"markdown","8684a805":"markdown","f0d9ab24":"markdown","67358d46":"markdown","af44d69d":"markdown","2c84c76b":"markdown","6ab0374d":"markdown","1f632064":"markdown","736aac39":"markdown","01cdcdeb":"markdown","85c6c451":"markdown","627a0f9a":"markdown","4d3d2ff7":"markdown","3f2e0486":"markdown","6efd3bd3":"markdown","0beeedb2":"markdown","40057091":"markdown","5a2c6598":"markdown","cb331107":"markdown","0ccece7a":"markdown","edbf3d04":"markdown","d316adda":"markdown","ba20b396":"markdown","646fbae9":"markdown","1f310ae7":"markdown","cbe4aa72":"markdown","0456cf26":"markdown","1c3bb64e":"markdown","4810c19b":"markdown","f76d9a60":"markdown","4d0206d9":"markdown","c33d149a":"markdown","20a24c7d":"markdown","083f7e6c":"markdown","5ece7bad":"markdown"},"source":{"f5a5fb34":"# Python libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport itertools\nfrom itertools import chain\nfrom sklearn.feature_selection import RFE\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, learning_curve, train_test_split\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score\nimport warnings\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\n\nwarnings.filterwarnings('ignore') #ignore warning messages ","9697ca80":"# Read data\ndata = pd.read_csv('..\/input\/data.csv')","2dd50aeb":"null_feat = pd.DataFrame(len(data['id']) - data.isnull().sum(), columns = ['Count'])\n\ntrace = go.Bar(x = null_feat.index, y = null_feat['Count'] ,opacity = 0.8, marker=dict(color = 'lightgrey',\n        line=dict(color='#000000',width=1.5)))\n\nlayout = dict(title =  \"Missing Values\")\n                    \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)","616e3174":"# Drop useless variables\ndata = data.drop(['Unnamed: 32','id'],axis = 1)\n\n# Reassign target\ndata.diagnosis.replace(to_replace = dict(M = 1, B = 0), inplace = True)","d9fc5976":"# Head\ndata.head()","9017ad49":"# describe\ndata.describe()","bc48dc1e":"# 2 datasets\nM = data[(data['diagnosis'] != 0)]\nB = data[(data['diagnosis'] == 0)]","45b72828":"#------------COUNT-----------------------\ntrace = go.Bar(x = (len(M), len(B)), y = ['malignant', 'benign'], orientation = 'h', opacity = 0.8, marker=dict(\n        color=[ 'gold', 'lightskyblue'],\n        line=dict(color='#000000',width=1.5)))\n\nlayout = dict(title =  'Count of diagnosis variable')\n                    \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)\n\n#------------PERCENTAGE-------------------\ntrace = go.Pie(labels = ['benign','malignant'], values = data['diagnosis'].value_counts(), \n               textfont=dict(size=15), opacity = 0.8,\n               marker=dict(colors=['lightskyblue', 'gold'], \n                           line=dict(color='#000000', width=1.5)))\n\n\nlayout = dict(title =  'Distribution of diagnosis variable')\n           \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)","bb6fd4a0":"def plot_distribution(data_select, size_bin) :  \n    tmp1 = M[data_select]\n    tmp2 = B[data_select]\n    hist_data = [tmp1, tmp2]\n    \n    group_labels = ['malignant', 'benign']\n    colors = ['#FFD700', '#7EC0EE']\n\n    fig = ff.create_distplot(hist_data, group_labels, colors = colors, show_hist = True, bin_size = size_bin, curve_type='kde')\n    \n    fig['layout'].update(title = data_select)\n\n    py.iplot(fig, filename = 'Density plot')","e9dbbdda":"#plot distribution 'mean'\nplot_distribution('radius_mean', .5)\nplot_distribution('texture_mean', .5)\nplot_distribution('perimeter_mean', 5)\nplot_distribution('area_mean', 10)\n#plot_distribution('smoothness_mean', .5)\n#plot_distribution('compactness_mean' .5)\n#plot_distribution('concavity_mean' .5)\n#plot_distribution('concave points_mean' .5)\n#plot_distribution('symmetry_mean' .5)\n#plot_distribution('fractal_dimension_mean' .5)","af326f27":"#plot distribution 'se'\nplot_distribution('radius_se', .1)\nplot_distribution('texture_se', .1)\nplot_distribution('perimeter_se', .5)\nplot_distribution('area_se', 5)\n#plot_distribution('smoothness_se', .5)\n#plot_distribution('compactness_se', .5)\n#plot_distribution('concavity_se', .5)\n#plot_distribution('concave points_se', .5)\n#plot_distribution('symmetry_se', .5)\n#plot_distribution('fractal_dimension_se', .5)","e19b3f3a":"#plot distribution 'worst'\nplot_distribution('radius_worst', .5)\nplot_distribution('texture_worst', .5)\nplot_distribution('perimeter_worst', 5)\nplot_distribution('area_worst', 10)\n#plot_distribution('smoothness_worst', .5)\n#plot_distribution('compactness_worst', .5)\n#plot_distribution('concavity_worst', .5)\n#plot_distribution('concave points_worst', .5)\n#plot_distribution('symmetry_worst', .5)\n#plot_distribution('fractal_dimension_worst', .5)","c4e3ba59":"#correlation\ncorrelation = data.corr()\n#tick labels\nmatrix_cols = correlation.columns.tolist()\n#convert to array\ncorr_array  = np.array(correlation)","4b54c077":"#Plotting\ntrace = go.Heatmap(z = corr_array,\n                   x = matrix_cols,\n                   y = matrix_cols,\n                   xgap = 2,\n                   ygap = 2,\n                   colorscale='Viridis',\n                   colorbar   = dict() ,\n                  )\nlayout = go.Layout(dict(title = 'Correlation Matrix for variables',\n                        autosize = False,\n                        height  = 720,\n                        width   = 800,\n                        margin  = dict(r = 0 ,l = 210,\n                                       t = 25,b = 210,\n                                     ),\n                        yaxis   = dict(tickfont = dict(size = 9)),\n                        xaxis   = dict(tickfont = dict(size = 9)),\n                       )\n                  )\nfig = go.Figure(data = [trace],layout = layout)\npy.iplot(fig)","cc39c1d9":"def plot_feat1_feat2(feat1, feat2) :  \n    trace0 = go.Scatter(\n        x = M[feat1],\n        y = M[feat2],\n        name = 'malignant',\n        mode = 'markers', \n        marker = dict(color = '#FFD700',\n            line = dict(\n                width = 1)))\n\n    trace1 = go.Scatter(\n        x = B[feat1],\n        y = B[feat2],\n        name = 'benign',\n        mode = 'markers',\n        marker = dict(color = '#7EC0EE',\n            line = dict(\n                width = 1)))\n\n    layout = dict(title = feat1 +\" \"+\"vs\"+\" \"+ feat2,\n                  yaxis = dict(title = feat2,zeroline = False),\n                  xaxis = dict(title = feat1, zeroline = False)\n                 )\n\n    plots = [trace0, trace1]\n\n    fig = dict(data = plots, layout=layout)\n    py.iplot(fig)","71617d34":"plot_feat1_feat2('perimeter_mean','radius_worst')\nplot_feat1_feat2('area_mean','radius_worst')\nplot_feat1_feat2('texture_mean','texture_worst')\nplot_feat1_feat2('area_worst','radius_worst')","8b97ccea":"#seaborn version : \n\npalette ={0 : 'lightblue', 1 : 'gold'}\nedgecolor = 'grey'\n\n# Plot +\nfig = plt.figure(figsize=(12,12))\n\nplt.subplot(221)\nax1 = sns.scatterplot(x = data['perimeter_mean'], y = data['radius_worst'], hue = \"diagnosis\",\n                    data = data, palette = palette, edgecolor=edgecolor)\nplt.title('perimeter mean vs radius worst')\nplt.subplot(222)\nax2 = sns.scatterplot(x = data['area_mean'], y = data['radius_worst'], hue = \"diagnosis\",\n                    data = data, palette =palette, edgecolor=edgecolor)\nplt.title('area mean vs radius worst')\nplt.subplot(223)\nax3 = sns.scatterplot(x = data['texture_mean'], y = data['texture_worst'], hue = \"diagnosis\",\n                    data = data, palette =palette, edgecolor=edgecolor)\nplt.title('texture mean vs texture worst')\nplt.subplot(224)\nax4 = sns.scatterplot(x = data['area_worst'], y = data['radius_worst'], hue = \"diagnosis\",\n                    data = data, palette =palette, edgecolor=edgecolor)\nplt.title('area mean vs radius worst')\n\nfig.suptitle('Positive correlated features', fontsize = 20)\nplt.savefig('1')\nplt.show()","329a794b":"plot_feat1_feat2('smoothness_mean','texture_mean')\nplot_feat1_feat2('radius_mean','fractal_dimension_worst')\nplot_feat1_feat2('texture_mean','symmetry_mean')\nplot_feat1_feat2('texture_mean','symmetry_se')","6a859454":"# seaborn version : \nfig = plt.figure(figsize=(12,12))\n\nplt.subplot(221)\nax1 = sns.scatterplot(x = data['smoothness_mean'], y = data['texture_mean'], hue = \"diagnosis\",\n                    data = data, palette =palette, edgecolor=edgecolor)\nplt.title('smoothness mean vs texture mean')\nplt.subplot(222)\nax2 = sns.scatterplot(x = data['radius_mean'], y = data['fractal_dimension_worst'], hue = \"diagnosis\",\n                    data = data, palette =palette, edgecolor=edgecolor)\nplt.title('radius mean vs fractal dimension_worst')\nplt.subplot(223)\nax3 = sns.scatterplot(x = data['texture_mean'], y = data['symmetry_mean'], hue = \"diagnosis\",\n                    data = data, palette =palette, edgecolor=edgecolor)\nplt.title('texture mean vs symmetry mean')\nplt.subplot(224)\nax4 = sns.scatterplot(x = data['texture_mean'], y = data['symmetry_se'], hue = \"diagnosis\",\n                    data = data, palette =palette, edgecolor=edgecolor)\nplt.title('texture mean vs symmetry se')\n\nfig.suptitle('Uncorrelated features', fontsize = 20)\nplt.savefig('2')\nplt.show()","52f69f30":"plot_feat1_feat2('area_mean','fractal_dimension_mean')\nplot_feat1_feat2('radius_mean','fractal_dimension_mean')\nplot_feat1_feat2('area_mean','smoothness_se')\nplot_feat1_feat2('smoothness_se','perimeter_mean')","43062a0e":"# seaborn version\nfig = plt.figure(figsize=(12,12))\n\nplt.subplot(221)\nax1 = sns.scatterplot(x = data['area_mean'], y = data['fractal_dimension_mean'], hue = \"diagnosis\",\n                    data = data, palette =palette, edgecolor=edgecolor)\nplt.title('smoothness mean vs fractal dimension mean')\nplt.subplot(222)\nax2 = sns.scatterplot(x = data['radius_mean'], y = data['fractal_dimension_mean'], hue = \"diagnosis\",\n                    data = data, palette =palette, edgecolor=edgecolor)\nplt.title('radius mean vs fractal dimension mean')\nplt.subplot(223)\nax2 = sns.scatterplot(x = data['area_mean'], y = data['smoothness_se'], hue = \"diagnosis\",\n                    data = data, palette =palette, edgecolor=edgecolor)\nplt.title('area mean vs fractal smoothness se')\nplt.subplot(224)\nax2 = sns.scatterplot(x = data['smoothness_se'], y = data['perimeter_mean'], hue = \"diagnosis\",\n                    data = data, palette =palette, edgecolor=edgecolor)\nplt.title('smoothness se vs perimeter mean')\n\nfig.suptitle('Negative correlated features', fontsize = 20)\nplt.savefig('3')\nplt.show()","caf02515":"target_pca = data['diagnosis']\ndata_pca = data.drop('diagnosis', axis=1)\n\ntarget_pca = pd.DataFrame(target_pca)\n\n#To make a PCA, normalize data is essential\nX_pca = data_pca.values\nX_std = StandardScaler().fit_transform(X_pca)\n\npca = PCA(svd_solver='full')\npca_std = pca.fit(X_std, target_pca).transform(X_std)\n\npca_std = pd.DataFrame(pca_std)\npca_std = pca_std.merge(target_pca, left_index = True, right_index = True, how = 'left')\npca_std['diagnosis'] = pca_std['diagnosis'].replace({1:'malignant',0:'benign'})","06ea5bbb":"#explained_variance \nvar_pca = pd.DataFrame(pca.explained_variance_ratio_)\nvar_pca = var_pca.T\n\n#----------SUM AND DROP COMP [7:30]\ncol_list = list(v for v in chain(pca_std.columns[6:30])) \nvar_pca['OTHERS_COMP'] = var_pca[col_list].sum(axis=1)\nvar_pca.drop(var_pca[col_list],axis=1,inplace=True)\nvar_pca = var_pca.T","9f138a64":"labels = ['COMP1','COMP2','COMP3','COMP4','COMP5','COMP6', 'COMP7 - 30']\ncolors = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue', 'lightgrey', 'orange', 'white']\n\ntrace = go.Pie(labels = labels, values = var_pca[0].values, opacity = 0.8,\n               textfont=dict(size=15),\n               marker=dict(colors=colors, \n                           line=dict(color='#000000', width=1.5)))\n\n\nlayout = dict(title =  'PCA : components and explained variance (6 comp = 88.8%)')\n \n                   \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)","6c23a4ae":"pca = PCA(n_components = 2)\n\npca_std = pca.fit(X_std, target_pca).transform(X_std)\npca_std = pd.DataFrame(pca_std,columns = ['COMP1','COMP2'])\npca_std = pca_std.merge(target_pca,left_index = True,right_index = True,how = 'left')\npca_std['diagnosis'] = pca_std['diagnosis'].replace({1:'malignant',0:'benign'})","c2406e38":"def pca_scatter(target,color) :\n    tracer = go.Scatter(x = pca_std[pca_std['diagnosis'] == target]['COMP1'] ,\n                        y = pca_std[pca_std['diagnosis'] == target]['COMP2'],\n                        name = target, mode = 'markers',\n                        marker = dict(color = color,line = dict(width = 1))\n                       )\n    return tracer\nlayout = go.Layout(dict(title = 'PCA Scatter plot (2 comp = 63.3%)',\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = 'COMP1 = 44.3%',\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = 'COMP2 = 19.0%',\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        height = 800\n                       ))\ntrace1 = pca_scatter('malignant','#FFD700')\ntrace2 = pca_scatter('benign','#7EC0EE')\nplots = [trace2,trace1]\nfig = go.Figure(data = plots,layout = layout)\npy.iplot(fig)","4450c458":"pca = PCA(n_components = 3)\npca_std = pca.fit(X_std, target_pca).transform(X_std)\n\npca_std = pd.DataFrame(pca_std,columns = ['COMP1','COMP2','COMP3'])\npca_std = pca_std.merge(target_pca, left_index = True, right_index = True,how = 'left')\npca_std['diagnosis'] = pca_std['diagnosis'].replace({1:'malignant',0:'benign'})","13c11197":"M_pca = pca_std[(pca_std['diagnosis'] == 'malignant')]\nB_pca = pca_std[(pca_std['diagnosis'] == 'benign')]","70b590fc":"trace1 = go.Scatter3d(x = M_pca['COMP1'],\n                      y = M_pca['COMP3'],\n                      z = M_pca['COMP2'],\n                      mode = \"markers\",\n                      name = \"malignant\",\n                      marker = dict(size = 4,color = '#FFD700',line = dict(width = 1))\n                     )\ntrace2 = go.Scatter3d(x = B_pca['COMP1'],\n                      y = B_pca['COMP3'],\n                      z = B_pca['COMP2'],\n                      name = 'benign',\n                      mode = 'markers',\n                      marker = dict(size = 4,color= '#7EC0EE',line = dict(width = 1))\n                     )\n\n\n\nlayout = go.Layout(dict(title = 'PCA Scatter plot (3 comp = 72.7%)',\n                        scene = dict(camera = dict(up=dict(x= 0 , y=0, z=0),\n                                                   center=dict(x=0, y=0, z=0),\n                                                   eye=dict(x=1.25, y=1.25, z=1.25)),\n                                     xaxis  = dict(title = 'COMP1',\n                                                   gridcolor='rgb(255, 255, 255)',\n                                                   zerolinecolor='rgb(255, 255, 255)',\n                                                   showbackground=True,\n                                                   backgroundcolor='rgb(230, 230,230)'),\n                                     yaxis  = dict(title = 'COMP3',\n                                                   gridcolor='rgb(255, 255, 255)',\n                                                   zerolinecolor='rgb(255, 255, 255)',\n                                                   showbackground=True,\n                                                   backgroundcolor='rgb(230, 230,230)'\n                                                  ),\n                                     zaxis  = dict(title = 'COMP2',\n                                                   gridcolor='rgb(255, 255, 255)',\n                                                   zerolinecolor='rgb(255, 255, 255)',\n                                                   showbackground=True,\n                                                   backgroundcolor='rgb(230, 230,230)'\n                                                  )),height = 700))\n                  \n\nplots = [trace1,trace2]\nfig  = go.Figure(data = plots,layout = layout)\npy.iplot(fig)","024983e6":"# Confusion matrix \ndef plot_confusion_matrix(cm, classes,\n                          normalize = False,\n                          title = 'Confusion matrix\"',\n                          cmap = plt.cm.Blues) :\n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation = 0)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])) :\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment = 'center',\n                 color = 'white' if cm[i, j] > thresh else 'black')\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n# Show metrics \ndef show_metrics():\n    tp = cm[1,1]\n    fn = cm[1,0]\n    fp = cm[0,1]\n    tn = cm[0,0]\n    print('Accuracy  =     {:.3f}'.format((tp+tn)\/(tp+tn+fp+fn)))\n    print('Precision =     {:.3f}'.format(tp\/(tp+fp)))\n    print('Recall    =     {:.3f}'.format(tp\/(tp+fn)))\n    print('F1_score  =     {:.3f}'.format(2*(((tp\/(tp+fp))*(tp\/(tp+fn)))\/\n                                                 ((tp\/(tp+fp))+(tp\/(tp+fn))))))","99c16075":"# Precision-recall curve\ndef plot_precision_recall():\n    plt.step(recall, precision, color = 'b', alpha = 0.2,\n             where = 'post')\n    plt.fill_between(recall, precision, step ='post', alpha = 0.2,\n                 color = 'b')\n\n    plt.plot(recall, precision, linewidth=2)\n    plt.xlim([0.0,1])\n    plt.ylim([0.0,1.05])\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision Recall Curve')\n    plt.show();","8e71ce9c":"# ROC curve\ndef plot_roc():\n    plt.plot(fpr, tpr, label = 'ROC curve', linewidth = 2)\n    plt.plot([0,1],[0,1], 'k--', linewidth = 2)\n   # plt.xlim([0.0,0.001])\n   # plt.ylim([0.0,1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.show();","a4f95972":"# Learning curve\ndef plot_learning_curve(estimator, title, X, y, ylim = None, cv = None,\n                        n_jobs = 1, train_sizes = np.linspace(.1, 1.0, 5)):\n    \"\"\"\n    Plots a learning curve. http:\/\/scikit-learn.org\/stable\/modules\/learning_curve.html\n    \"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel('Training examples')\n    plt.ylabel('Score')\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv = cv, n_jobs = n_jobs, train_sizes = train_sizes)\n    train_scores_mean = np.mean(train_scores, axis = 1)\n    train_scores_std = np.std(train_scores, axis = 1)\n    test_scores_mean = np.mean(test_scores, axis = 1)\n    test_scores_std = np.std(test_scores, axis = 1)\n    plt.grid()\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha = 0.1, color = \"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color = \"r\",\n             label = \"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color = \"g\",\n             label = \"Cross-validation score\")\n    plt.legend(loc = \"best\")\n    return plt","8c681723":"# Cross val metric\ndef cross_val_metrics(model) :\n    scores = ['accuracy', 'precision', 'recall']\n    for sc in scores:\n        scores = cross_val_score(model, X, y, cv = 5, scoring = sc)\n        print('[%s] : %0.5f (+\/- %0.5f)'%(sc, scores.mean(), scores.std()))","126d577a":"# Def X and Y\ny = np.array(data.diagnosis.tolist())\ndata = data.drop('diagnosis', 1)\nX = np.array(data.as_matrix())","193b759a":"# Normalization\nscaler = StandardScaler()\nX = scaler.fit_transform(X)","2f2ad2e8":"# Train_test split\nrandom_state = 42\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.12, random_state = random_state)","74c34d09":"# Find best hyperparameters (accuracy)\nlog_clf = LogisticRegression(random_state = random_state)\nparam_grid = {\n            'penalty' : ['l2','l1'],  \n            'C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n            }\n\nCV_log_clf = GridSearchCV(estimator = log_clf, param_grid = param_grid , scoring = 'accuracy', verbose = 1, n_jobs = -1)\nCV_log_clf.fit(X_train, y_train)\n\nbest_parameters = CV_log_clf.best_params_\nprint('The best parameters for using this model is', best_parameters)","926542d7":"#Log with best hyperparameters\nCV_log_clf = LogisticRegression(C = best_parameters['C'], \n                                penalty = best_parameters['penalty'], \n                                random_state = random_state)\n\nCV_log_clf.fit(X_train, y_train)\ny_pred = CV_log_clf.predict(X_test)\ny_score = CV_log_clf.decision_function(X_test)\n\n# Confusion maxtrix & metrics\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cm, \n                      classes=class_names, \n                      title='Logistic Confusion matrix')\nplt.savefig('6')\nplt.show()\n\nshow_metrics()\n\n# ROC curve\nfpr, tpr, t = roc_curve(y_test, y_score)\nplot_roc()","95572469":"#Logistic regression with RFE\nlog_clf = LogisticRegression(C = best_parameters['C'], \n                                 penalty = best_parameters['penalty'], \n                                 random_state = random_state)\n\nselector = RFE(log_clf)\nselector = selector.fit(X_train, y_train)\n\ny_pred = selector.predict(X_test)\ny_score = selector.predict_proba(X_test)[:,1]\n\n\n# Confusion maxtrix & metrics\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cm, \n                      classes=class_names, \n                      title='Logistic Confusion matrix')\nplt.show()\n\nshow_metrics()\n\n# ROC curve\nfpr, tpr, t = roc_curve(y_test, y_score)\nplot_roc()","5cbf5bc7":"# support and ranking RFE\nprint(selector.support_)\nprint(selector.ranking_)","0386b39f":"#Learning curve Log with best hyperpara\nplot_learning_curve(CV_log_clf, 'Learning Curve For Logistic Model', X, y, (0.85,1.05), 10)\nplt.savefig('7')\nplt.show()","17c547b4":"#Learning curve Log with RFE\nplot_learning_curve(selector, 'Learning Curve For Logistic Model with RFE', X, y, (0.85,1.05), 10)\nplt.show()","47cd3b17":"# Cross val Log \ncross_log = cross_val_metrics(CV_log_clf)","3ea6854f":"# Cross val Log with RFE\ncross_selector = cross_val_metrics(selector)","2eab0054":"# Threshold\nthresholds_adj = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n\nplt.figure(figsize = (15,15))\n\nj = 1\nfor i in thresholds_adj:\n    y_score = CV_log_clf.predict_proba(X_test)[:,1] > i\n    \n    \n    plt.subplot(3,3,j)\n    j += 1\n    \n    cm = confusion_matrix(y_test, y_score)\n    \n    tp = cm[1,1]\n    fn = cm[1,0]\n    fp = cm[0,1]\n    tn = cm[0,0]\n\n    print('Recall w\/ threshold = %s :'%i, (tp\/(tp+fn)))\n    \n    class_names = [0,1]\n    plot_confusion_matrix(cm, \n                          classes=class_names, \n                          title='Threshold = %s'%i) ","a510a7f9":"# Recall = 1.\ny_score = CV_log_clf.predict_proba(X_test)[:,1] > 0.1\ncm = confusion_matrix(y_test, y_score)\nclass_names = [0,1]\nshow_metrics()","59cc291b":"# Find the best parameters (recall)\nlog2_clf = LogisticRegression(random_state = random_state)\nparam_grid = {\n            'penalty' : ['l2','l1'],  \n            'C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n            }\n\nCV_log2_clf = GridSearchCV(estimator = log2_clf, param_grid = param_grid , scoring = 'recall', verbose = 1, n_jobs = -1)\nCV_log2_clf.fit(X_train, y_train)\n\nbest_parameters = CV_log2_clf.best_params_\nprint('The best parameters for using this model is', best_parameters)","5536932e":"# Log w best hyperparameters (recall)\nCV_log2_clf = LogisticRegression(C = best_parameters['C'], \n                                 penalty = best_parameters['penalty'], \n                                 random_state = random_state)\n\n\nCV_log2_clf.fit(X_train, y_train)\n\ny_pred = CV_log2_clf.predict(X_test)\ny_score = CV_log2_clf.decision_function(X_test)\n# Confusion maxtrix & metrics\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]","5c65d5fd":"# Cross val log2\ncross_val_metrics(CV_log2_clf)","7b7e3cce":"#Voting Classifier\nvoting_clf = VotingClassifier (\n        estimators = [('log1', CV_log_clf), ('log_2', CV_log2_clf)],\n                     voting='soft', weights = [1, 1])\n    \nvoting_clf.fit(X_train,y_train)\n\ny_pred = voting_clf.predict(X_test)\ny_score = voting_clf.predict_proba(X_test)[:,1]\n\n# Confusion maxtrix\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]\nshow_metrics()","52e4e828":"# Cross val score voting\ncross_voting = cross_val_metrics(voting_clf)","9d11262d":"#Learning curve Voting\nplot_learning_curve(voting_clf, 'Learning Curve For Voting clf', X, y, (0.85,1.05), 10)\nplt.savefig('9')\nplt.show()","9f4275de":"# Threshold\nthresholds_adj = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n\nplt.figure(figsize = (15,15))\n\nj = 1\nfor i in thresholds_adj:\n    y_score = voting_clf.predict_proba(X_test)[:,1] > i\n    \n    \n    plt.subplot(3,3,j)\n    j += 1\n    \n    cm = confusion_matrix(y_test, y_score)\n    \n    tp = cm[1,1]\n    fn = cm[1,0]\n    fp = cm[0,1]\n    tn = cm[0,0]\n\n    print('Recall w\/ threshold = %s :'%i, (tp\/(tp+fn)))\n    \n    class_names = [0,1]\n    plot_confusion_matrix(cm, \n                          classes=class_names, \n                          title='Threshold = %s'%i) ","15fe55fc":"# Ensemble, recall = 1.\ny_score = voting_clf.predict_proba(X_test)[:,1] > 0.23\ncm = confusion_matrix(y_test, y_score)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cm, \n                      classes = class_names, \n                      title = 'Ensemble Clf CM : recall = 100%')\nplt.savefig('8')\nplt.show()\n\nshow_metrics()\n\n# ROC curve\nfpr, tpr, t = roc_curve(y_test, y_score)\nplot_roc()\n\n# Precision-recall curve\nprecision, recall, thresholds = precision_recall_curve(y_test, y_score)\nplot_precision_recall()","e6e47c6a":"models_metrics = {'log_clf': [0.982, 0.990, 0.962], \n                 'selector': [0.974, 0.981, 0.948],\n                 'log2_clf' : [0.974,0.976,0.953],\n                 'voting_clf' : [0.979,0.985,0.958]\n                }\ndf = pd.DataFrame(data = models_metrics)\ndf.rename(index={0:'Accuracy',1:'Precision', 2: 'Recall'}, \n                 inplace=True)\nax = df.plot(kind='bar', figsize = (15,10), ylim = (0.94, 1), \n        color = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue'],\n        rot = 0, title ='Models performance (cross val mean)',\n        edgecolor = 'grey', alpha = 0.5)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01, p.get_height() * 1.0005))\nplt.show()","163fb8aa":"## <a id='7.2'>7.2. Voting classifier : log + log2<\/a> ","c6cfc33e":"## <a id='7.5'>7.5. Models performance plot (accuracy, precision, recall)<\/a>","bdb5db10":"## <a href='#3.1'>3.1. Compute PCA<\/a>","4c4fe99b":"## <a id='5.1'>5.1. Define (X,  y)<\/a>","b68fd2c6":"# <a id='3'>3. Principal Component Analysis<\/a>","99140369":"Why do you need to standardize your data ?  For example, a variable that ranges between 0 and 100 will outweigh a variable that ranges between 0 and 1. Using these variables without standardization in effect gives the variable with the larger range a bigger weight in the analysis","33935119":"## <a id='5.3'>5.3. Train test split<\/a>","e8d62f08":"* y = diagnosis (target)\n* X = features (radius_mean, area_se, ....) \n","bffe7ab6":"The confusion matrix, also known as the error matrix, allows visualization of the performance of an algorithm :\n* true positive (TP) : Malignant tumour correctly identified as malignant\n* true negative (TN) : Benign tumour correctly identified as benign\n* false positive (FP) : Benign tumour incorrectly identified as malignant \n* false negative (FN) : Malignant tumour incorrectly identified as benign\n\nMetrics : \n* Accuracy : (TP +TN) \/ (TP + TN + FP +FN)\n* Precision : TP \/ (TP + FP)\n* Recall : TP \/ (TP + FN)\n","d643ce32":"## <a id='#3.3'>3.4. PCA scatter plot with 3 components (72.7%)<\/a>","09cf382c":"## <a id='4.2'>4.2. Precision \u2013 Recall curve<\/a>","f87c63dd":"## <a id='6.3'>6.3. Compare learning curves and cross validation scores<\/a> ","1f84110c":"## <a id='2.6'>2.5. Positive correlated features<\/a> ","bcf08fab":"## <a id='7.1'>7.1. Logistic Regression  and GridSearch CV to optimise hyperparameters (recall)<\/a>","5a3e682d":"## <a id='1.4'>1.4. Reassign target and drop useless features<\/a>","08577c9f":"## <a id='6.1'>6.1. Logistic Regression  and GridSearch CV to optimise hyperparameters (accuracy)<\/a>","353f712e":"Bellow, you can remove the '#' to show all features distribution (except the first line)","a481bdb7":"- <a href='#1'>1. Load libraries and read the data<\/a>  \n    - <a href='#1.1'>1.1. Load libraries<\/a> \n    - <a href='#1.2'>1.2. Read the data<\/a> \n    - <a href='#1.3'>1.3. Missing values<\/a> \n    - <a href='#1.4'>1.4. Reassign target and drop useless features<\/a> \n- <a href='#2'>2. Exploratory Data Analysis (EDA)<\/a> \n    - <a href='#2.1'>2.1. Head and describe<\/a> \n    - <a href='#2.2'>2.2. Target distribution (number and %)<\/a> \n    - <a href='#2.3'>2.3. Features distribution (hue = diagnosis)<\/a> \n    - <a href='#2.4'>2.4. Correlation matrix<\/a> \n    - <a href='#2.6'>2.5. Positive correlated features<\/a> \n    - <a href='#2.7'>2.6. Uncorrelated features<\/a> \n    - <a href='#2.7'>2.7. Negative correlated features<\/a> \n- <a href='#3'>3. Principal Component Analysis<\/a>\n    - <a href='#3.1'>3.1. Compute PCA<\/a> \n    - <a href='#3.2'>3.2. PCA pie plot with 6 components (88.8%)<\/a> \n    - <a href='#3.2'>3.3. PCA scatter plot with 2 components (63.3%)<\/a> \n    - <a href='#3.3'>3.4. PCA scatter plot with 3 components (72.7%)<\/a>\n- <a href='#4'>4. Define functions<\/a>\n    - <a href='#4.1'>4.1. Confusion matrix and show metrics<\/a> \n    - <a href='#4.2'>4.2. Precision \u2013 Recall curve<\/a> \n    - <a href='#4.3'>4.3. ROC curve<\/a> \n    - <a href='#4.4'>4.4. Learning curve<\/a> \n    - <a href='#4.5'>4.5. Cross validation metrics<\/a> \n- <a href='#5'>5. Prepare dataset<\/a>\n    - <a href='#5.1'>5.1. Define (X,  y)<\/a> \n    - <a href='#5.2'>5.2. Standard scaler (X)<\/a> \n    - <a href='#5.3'>5.3. Train test split<\/a> \n- <a href='#6'>6. Predictive model : Logistic Regression<\/a> \n    - <a href='#6.1'>6.1. Logistic Regression  and GridSearch CV to optimise hyperparameters (accuracy)<\/a> \n    - <a href='#6.2'>6.2. RFE : Recursive features elimination (30 features => 15 features)<\/a> \n    - <a href='#6.3'>6.3. Compare learning curves and cross validation scores<\/a> \n    - <a href='#6.4'>6.4. Select threshold for a recall = 100% (all malignant tumors detected)<\/a> \n    - <a href='#6.5'>6.5. Predicting with recall = 100%<\/a> \n- <a href='#7'>7. Predictive model 2 : Ensemble Classifier to maximise precision and detect all malignant tumors<\/a>\n    - <a href='#7.1'>7.1. Logistic Regression  and GridSearch CV to optimise hyperparameters (recall)<\/a> \n    - <a href='#7.2'>7.2. Voting classifier : log + log2<\/a> \n    - <a href='#7.3'>7.3. Voting classifier : select threshold (recall = 100%)<\/a> \n    - <a href='#7.4'>7.4. Voting classifier : predicting with recall = 100% (precision = 92%)<\/a> \n    - <a href='#7.5'>7.5. Models performance plot (accuracy, precision, recall)<\/a> ","826dc208":"## <a id='7.4'>7.4. Voting classifier : predicting with recall = 100% (precision = 92%)<\/a>","7326cab3":"Cross-validation is a technique to evaluate predictive models by partitioning the original sample into a training set to train the model, and a test set to evaluate it. ","0cda0252":"**Thank you all ! Merci \u00e0 tous ! :)**","47ee4918":"# <a id='5'>5. Prepare dataset<\/a>","44325b22":" # <a id='6'>6. Predictive model : Logistic Regression<\/a>","b1780f09":"For this study, the most important is to detect all malignants tumours. ","bc4e0e3e":"## <a id='2.1'>2.1. Head and describe<\/a> ","6eedadef":"With only 15 features and 5 folds, we got an accuracy of 97.4 with a standard deviation of 0.78.\nTo follow, we don't use the selector, the log cfl is most performant but the code is here for you :)","63396075":"----------\n**Breast Cancer Analysis and Prediction**\n=====================================\n\n***Recall = 1. Precision = .92 Accuracy =  .971***\n\n***Vincent Lugat***\n\n*September 2018*\n\n----------","8684a805":" ## <a id='7.3'>7.3. Voting classifier : select threshold (recall = 100%)<\/a>","f0d9ab24":"* Grid search CV accuracy, penalty = l2\n* Grid search CV recall,  penalty = l1","67358d46":"## <a id='1.2'>1.2. Read the data<\/a>","af44d69d":" ## <a id='4.5'>4.5. Cross validation metrics<\/a>","2c84c76b":"## <a href='#6.5'>6.5. Predicting with recall = 100%<\/a>","6ab0374d":"## <a id='4.3'>4.3. ROC curve<\/a>","1f632064":"## <a id='3.2'>3.2. PCA pie plot with 6 components (88.8%)<\/a>","736aac39":"With 2 models we can increase the precision while keeping a recall = 100%","01cdcdeb":"## <a id='2.2'>2.2. Target distribution (number and %)<\/a> ","85c6c451":"All features are complete, only 'Unnamed: 32' is completely null, probably an error in the dataset, we drop it in below","627a0f9a":"**Information : [here](https:\/\/archive.ics.uci.edu\/ml\/datasets\/Breast+Cancer+Wisconsin+%28Diagnostic%29)**\n\nFeatures are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. \n* ID number \n* Diagnosis (M = malignant, B = benign)  \n\nTen real-valued features are computed for each cell nucleus: \n\n* radius (mean of distances from center to points on the perimeter) \n* texture (standard deviation of gray-scale values) \n* perimeter \n* area \n* smoothness (local variation in radius lengths) \n* compactness (perimeter^2 \/ area - 1.0) \n* concavity (severity of concave portions of the contour) \n* concave points (number of concave portions of the contour) \n* symmetry \n* fractal dimension (\"coastline approximation\" - 1)","4d3d2ff7":"The precision-recall curve shows the tradeoff between precision and recall for different threshold","3f2e0486":"## <a id='4.4'>4.4. Learning curve<\/a>","6efd3bd3":"The Learning curve determines cross-validated training and test scores.","0beeedb2":"# <a id='4'>4. Define functions<\/a>","40057091":"## <a href='#6.4'>6.4. Select threshold for a recall = 100% (all malignant tumors detected)<\/a>","5a2c6598":" # <a id='7'>7. Predictive model 2 : Ensemble Classifier to maximise precision and detect all malignant tumors<\/a>","cb331107":"## <a id='6.2'>6.2. RFE : Recursive features elimination (30 features => 15 features)<\/a>","0ccece7a":"## <a id='5.2'>5.2. Standard scaler (X)<\/a>","edbf3d04":"## <a id='2.7'>2.7. Negative correlated features<\/a>","d316adda":"## <a id='1.3'>1.3. Missing values<\/a>","ba20b396":"## <a id='4.1'>4.1. Confusion matrix and show metrics<\/a>","646fbae9":"* Special note : Thanks [Gabriel Preda](https:\/\/www.kaggle.com\/gpreda) for sharing his incredible knowledge :)\n* Special note 2 : Thanks [Pavan Raj](https:\/\/www.kaggle.com\/pavanraj159), the plotly master :)","1f310ae7":"## <a id='2.7'>2.6. Uncorrelated features<\/a>","cbe4aa72":"This part is essential to measure the performance of a model : roc, cross validation, learning curve ...","0456cf26":"# <a id='1'>1. Load libraries and read the data<\/a> ","1c3bb64e":"The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.","4810c19b":"## <a id='3.2'>3.3. PCA scatter plot with 2 components (63.3%)<\/a>","f76d9a60":"## <a id='2.3'>2.3. Features distribution (hue = diagnosis)<\/a> ","4d0206d9":"## <a id='1.1'>1.1. Load libraries<\/a> ","c33d149a":"# <a id='2'>2. Exploratory Data Analysis (EDA)<\/a>","20a24c7d":"Let's check the correlation between few features by pair","083f7e6c":"## <a id='2.4'>2.4. Correlation matrix<\/a>","5ece7bad":"Recursive feature elimination (RFE) is a feature selection method that fits a model and removes the weakest feature (or features) until the specified number of features is reached. Features are ranked by the model\u2019s coef_ or feature_importances_"}}