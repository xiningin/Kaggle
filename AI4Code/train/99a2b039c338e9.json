{"cell_type":{"62160e3d":"code","0e72f51e":"code","711f98ff":"code","7ba1d1c3":"code","852dac7a":"code","1dd64b12":"code","d2153d6d":"code","5fa6eedd":"code","e93e29e4":"code","21f5a1cc":"code","3c48c4f3":"code","520de138":"code","f9bad2c4":"code","5532b6d7":"code","42ab16ab":"code","f5707a6f":"code","d46727aa":"code","ae8b87d3":"code","c10a3398":"code","196c1d48":"code","e3f27d42":"code","a3bb62c1":"code","74207dcb":"code","7667d926":"code","ec2c994f":"code","d004d8e3":"code","a5cfcadb":"code","6bafa53c":"code","20f4f4b7":"code","8031cc65":"code","dd1f1ead":"code","9ca58cda":"code","eebf6fc4":"code","7bce5932":"code","ad491dad":"code","2ba6f7e2":"code","0f3b632b":"code","e13851f1":"code","9b3a152c":"code","18577444":"code","ee3e8b7a":"code","9922033c":"code","f5ed4498":"code","6ec47565":"code","93affefe":"code","1b705db0":"code","c8290d78":"code","a8230a37":"code","b8f8d60d":"code","56354498":"code","34e7cb45":"code","e53041cc":"code","f5aacad5":"code","4a70956b":"code","960b8f97":"code","e443d1dd":"code","30a1ba5d":"code","8738eaef":"code","882a65b3":"code","c0ccf1c1":"code","c8fb1aa2":"code","e585f793":"code","1a6cbdf4":"code","4cd489ed":"code","3f9588cd":"code","7b8142f1":"code","6a0c1486":"code","a3dad5e9":"code","164d1d6d":"markdown","09ecb40d":"markdown","a334b1af":"markdown","5a7eaac7":"markdown","870b0f06":"markdown","5a5f6a0f":"markdown","b2a428ee":"markdown","52b91d3e":"markdown","aa278f54":"markdown","564135f7":"markdown","b96e2d4b":"markdown","7920f557":"markdown","ea13de7c":"markdown","f39f28f4":"markdown","124cd584":"markdown","bb7edf4a":"markdown","62679c77":"markdown","3d035b0a":"markdown","0fd6520e":"markdown","3e5b08d5":"markdown","1556ac14":"markdown","730abc6b":"markdown","562f104b":"markdown","a48faf02":"markdown","577d30ad":"markdown","988e3542":"markdown","ba20fa00":"markdown","0388c958":"markdown","cef78aa7":"markdown","6ae87286":"markdown","260ff465":"markdown","c5e98018":"markdown","75a184e7":"markdown","379aea0f":"markdown","60fb70e4":"markdown","ec03cbcb":"markdown","1653b67c":"markdown","14825921":"markdown","f498df66":"markdown","23ff31ea":"markdown","25935f08":"markdown","1c7ff75a":"markdown","00ca282f":"markdown","56fe3b73":"markdown","c05b5a02":"markdown","4edeffe3":"markdown","56b1fe3e":"markdown","d9e7a62f":"markdown","69a39afb":"markdown","4806a382":"markdown","530d3255":"markdown","5c86de37":"markdown","56eea44c":"markdown","517048be":"markdown","c654e2c1":"markdown","2acb7275":"markdown","e78eedf4":"markdown","d114f760":"markdown","e73c0a96":"markdown","c3c85e08":"markdown","371a0362":"markdown","ce3d66a6":"markdown","750b962b":"markdown","13561c59":"markdown","ae74b4b8":"markdown","820e85a2":"markdown","d4935ce7":"markdown","d9a6d480":"markdown","cb4045ad":"markdown","4728db80":"markdown","dbcb07de":"markdown","6d31439d":"markdown","014a0aad":"markdown","81c08a4c":"markdown","e3409c30":"markdown","986bccc4":"markdown"},"source":{"62160e3d":"import numpy as np \nimport pandas as pd \nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import preprocessing\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","0e72f51e":"train_data = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/train.csv\")","711f98ff":"train_data.head()","7ba1d1c3":"train_data.tail()","852dac7a":"train_data.columns","1dd64b12":"print('lenght of data is', len(train_data))","d2153d6d":"train_data.shape","5fa6eedd":"train_data.info()","e93e29e4":"train_data.dtypes","21f5a1cc":"train_data[train_data.isnull().any(axis=1)].head()","3c48c4f3":"np.sum(train_data.isnull().any(axis=1))","520de138":"train_data.isnull().values.any()","f9bad2c4":"train_data.isnull().sum()","5532b6d7":"NANColumns=[]\ni=-1\nfor a in train_data.isnull().sum():\n    i+=1\n    if a!=0:\n        print(train_data.columns[i],a)\n        NANColumns.append(train_data.columns[i])","42ab16ab":"carrier_count = train_data[\"Pclass\"].value_counts()\nsns.set(style=\"darkgrid\")\nsns.barplot(carrier_count.index, carrier_count.values, alpha=0.9)\nplt.title('Frequency Distribution of pclass')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('pclass', fontsize=12)\nplt.show()","f5707a6f":"train_data[\"Pclass\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","d46727aa":"carrier_count = train_data[\"Survived\"].value_counts()\nsns.set(style=\"darkgrid\")\nsns.barplot(carrier_count.index, carrier_count.values, alpha=0.9)\nplt.title('Frequency Distribution of survived    ')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('survived    ', fontsize=12)\nplt.show()","ae8b87d3":"train_data[\"Survived\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","c10a3398":"train_data[\"Sex\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","196c1d48":"train_data[\"Age\"].value_counts().head(10).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","e3f27d42":"train_data[\"Embarked\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","a3bb62c1":"train_data.hist(figsize=(15,12),bins = 20, color=\"#107009AA\")\nplt.title(\"Features Distribution\")\nplt.show()","74207dcb":"test_data = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/test.csv\")\nids_test_data = test_data['PassengerId'].values","7667d926":"test_data.head()","ec2c994f":"test_data.tail()","d004d8e3":"test_data.columns","a5cfcadb":"print('lenght of data is', len(test_data))","6bafa53c":"test_data.shape","20f4f4b7":"test_data.info()","8031cc65":"test_data.dtypes","dd1f1ead":"test_data[test_data.isnull().any(axis=1)].head()","9ca58cda":"np.sum(test_data.isnull().any(axis=1))","eebf6fc4":"test_data.isnull().values.any()","7bce5932":"test_data.isnull().sum()","ad491dad":"NANColumns=[]\ni=-1\nfor a in test_data.isnull().sum():\n    i+=1\n    if a!=0:\n        print(test_data.columns[i],a)\n        NANColumns.append(test_data.columns[i])","2ba6f7e2":"carrier_count = test_data[\"Pclass\"].value_counts()\nsns.set(style=\"darkgrid\")\nsns.barplot(carrier_count.index, carrier_count.values, alpha=0.9)\nplt.title('Frequency Distribution of pclass')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('pclass', fontsize=12)\nplt.show()","0f3b632b":"test_data[\"Pclass\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","e13851f1":"test_data[\"Sex\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","9b3a152c":"test_data[\"Age\"].value_counts().head(10).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","18577444":"test_data[\"Embarked\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","ee3e8b7a":"test_data.hist(figsize=(15,12),bins = 20, color=\"#107009AA\")\nplt.title(\"Features Distribution\")\nplt.show()","9922033c":"colormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train_data.corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","f5ed4498":"train_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","6ec47565":"train_data[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","93affefe":"train_data[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","1b705db0":"train_data[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","c8290d78":"g = sns.FacetGrid(train_data, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","a8230a37":"grid = sns.FacetGrid(train_data, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","b8f8d60d":"grid = sns.FacetGrid(train_data, row='Embarked', col='Survived', size=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()","56354498":"y = train_data[\"Survived\"]","34e7cb45":"all_data = pd.concat([train_data,test_data],axis=0).reset_index(drop=True)","e53041cc":"all_data = all_data.drop([\"Survived\",\"PassengerId\"],axis=1)","f5aacad5":"def missing_value(df):\n    number = df.isnull().sum().sort_values(ascending=False)\n    number = number[number > 0]\n    percentage = df.isnull().sum() *100 \/ df.shape[0]\n    percentage = percentage[percentage > 0].sort_values(ascending=False)\n    return  pd.concat([number,percentage],keys=[\"Total\",\"Percentage\"],axis=1)\nmissing_value(all_data)","4a70956b":"## Imputing the missing values with the Mode because mode fill the values with the most accuring values and best for the categorical features\nall_data[\"Cabin\"] = all_data[\"Cabin\"].transform(lambda x: x.fillna(x.mode()[0]))","960b8f97":"## Imputing the missing values with the Mode because mode fill the values with the most accuring values and best for the categorical features\nall_data[\"Embarked\"] = all_data[\"Embarked\"].transform(lambda x: x.fillna(x.mode()[0]))","e443d1dd":"#Mapping the Age into 5 groups from 0 to 4\nall_data['Age']=all_data.loc[ all_data['Age'] <= 16, 'Age'] = 0\nall_data['Age']=all_data.loc[(all_data['Age'] > 16) & (all_data['Age'] <= 32), 'Age'] = 1\nall_data['Age']=all_data.loc[(all_data['Age'] > 32) & (all_data['Age'] <= 48), 'Age'] = 2\nall_data['Age']=all_data.loc[(all_data['Age'] > 48) & (all_data['Age'] <= 64), 'Age'] = 3\nall_data['Age']=all_data.loc[ all_data['Age'] > 64, 'Age'] = 4 ","30a1ba5d":"#Mapping the Fare into 5 groups from 0 to 4\nall_data['Fare']=all_data.loc[ all_data['Fare'] <= 7.91, 'Fare'] = 0\nall_data['Fare']=all_data.loc[(all_data['Fare'] > 7.91) & (all_data['Fare'] <= 14.454), 'Fare'] = 1\nall_data['Fare']=all_data.loc[(all_data['Fare'] > 14.454) & (all_data['Fare'] <= 31), 'Fare']   = 2\nall_data['Fare']=all_data.loc[ all_data['Fare'] > 31, 'Fare'] = 3\nall_data['Fare']=all_data['Fare'] = all_data['Fare'].astype(int)","8738eaef":"#Checking missing values now\nmissing_value(all_data)","882a65b3":"all_data.dtypes","c0ccf1c1":"pro= preprocessing.LabelEncoder()\nencpro=pro.fit_transform(all_data['Name'])\nall_data['Name'] = encpro\n\npro= preprocessing.LabelEncoder()\nencpro=pro.fit_transform(all_data['Sex'])\nall_data['Sex'] = encpro\n\npro= preprocessing.LabelEncoder()\nencpro=pro.fit_transform(all_data['Ticket'].astype(str))\nall_data['Ticket'] = encpro\n\npro= preprocessing.LabelEncoder()\nencpro=pro.fit_transform(all_data['Cabin'])\nall_data['Cabin'] = encpro\n\npro= preprocessing.LabelEncoder()\nencpro=pro.fit_transform(all_data['Embarked'].astype(str))\nall_data['Embarked'] = encpro","c8fb1aa2":"n = len(y)\ntrain_data = all_data[:n]\ntest_data = all_data[n:]","e585f793":"X = np.array(train_data)\ny = np.array(y)","1a6cbdf4":"rf = RandomForestClassifier(min_samples_leaf=1, min_samples_split=2)\nkf = KFold(n_splits=5)\noutcomes1 = []\nClassR=0\nConM=0\nfold = 0\ni=0\nconf_matrix_list_of_arrays = []\nfor train_index, test_index in kf.split(X,y):\n    i=i+1\n    print(\"KFold Split:\",i)\n    print('\\n')\n    fold += 1\n    Xtrain, Xtest = X[train_index], X[test_index]\n    ytrain, ytest = y[train_index], y[test_index]\n    print('Running time of algorithm')\n    %time rf.fit(Xtrain, ytrain)\n    predictions = rf.predict(Xtest)\n    accuracy = accuracy_score(ytest, predictions)\n    outcomes1.append(accuracy)\n    print(\"Accuracy of KFold \",i, \"is: \",accuracy)\n    print('\\n')\n    print(\"Classification Report of KFold \",i,\" is following:\")\n    print('\\n')\n    CR=classification_report(ytest, predictions)\n    print(CR)\n    print('\\n')\n    print(\"Confusion Matrix of KFold \",i,\" is following:\")\n    print('\\n')\n    CM=confusion_matrix(ytest, predictions)\n    conf_matrix_list_of_arrays.append(CM)\n    print(CM)\n    print('\\n')\n    print('\\n')\n\nprint('\\n')\nprint('Average Confusion Matrix')\naa = np.mean(conf_matrix_list_of_arrays, axis=0)\n\naaa = np.ceil(aa)\n\nb=pd.DataFrame(aaa)\nb=b.astype(int)\nlabels =['Not Survived','Survived']\n\nc=np.array(b)\n\nfig, ax = plot_confusion_matrix(conf_mat=c,figsize=(10, 10),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.show()\nprint('\\n')\nprint('\\n')\nmean_outcome1 = np.mean(outcomes1)\nprint(\"Total Average Accuracy of Random Forest Classifier is : {0}\".format(mean_outcome1)) ","4cd489ed":"rf = KNeighborsClassifier(n_neighbors=2)\nkf = KFold(n_splits=5)\noutcomes2 = []\nClassR=0\nConM=0\nfold = 0\ni=0\nconf_matrix_list_of_arrays = []\nfor train_index, test_index in kf.split(X,y):\n    i=i+1\n    print(\"KFold Split:\",i)\n    print('\\n')\n    fold += 1\n    Xtrain, Xtest = X[train_index], X[test_index]\n    ytrain, ytest = y[train_index], y[test_index]\n    print('Running time of algorithm')\n    %time rf.fit(Xtrain, ytrain)\n    predictions = rf.predict(Xtest)\n    accuracy = accuracy_score(ytest, predictions)\n    outcomes2.append(accuracy)\n    print(\"Accuracy of KFold \",i, \"is: \",accuracy)\n    print('\\n')\n    print(\"Classification Report of KFold \",i,\" is following:\")\n    print('\\n')\n    CR=classification_report(ytest, predictions)\n    print(CR)\n    print('\\n')\n    print(\"Confusion Matrix of KFold \",i,\" is following:\")\n    print('\\n')\n    CM=confusion_matrix(ytest, predictions)\n    conf_matrix_list_of_arrays.append(CM)\n    print(CM)\n    print('\\n')\n    print('\\n')\n\nprint('\\n')\nprint('Average Confusion Matrix')\naa = np.mean(conf_matrix_list_of_arrays, axis=0)\n\naaa = np.ceil(aa)\n\nb=pd.DataFrame(aaa)\nb=b.astype(int)\nlabels =['Not Survived','Survived']\n\nc=np.array(b)\n\nfig, ax = plot_confusion_matrix(conf_mat=c,figsize=(10, 10),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.show()\nprint('\\n')\nprint('\\n')\nmean_outcome2 = np.mean(outcomes2)\nprint(\"Total Average Accuracy of KNN Classifier is : {0}\".format(mean_outcome2)) ","3f9588cd":"rf = DecisionTreeClassifier(random_state=10)\nkf = KFold(n_splits=5)\noutcomes3 = []\nClassR=0\nConM=0\nfold = 0\ni=0\nconf_matrix_list_of_arrays = []\nfor train_index, test_index in kf.split(X,y):\n    i=i+1\n    print(\"KFold Split:\",i)\n    print('\\n')\n    fold += 1\n    Xtrain, Xtest = X[train_index], X[test_index]\n    ytrain, ytest = y[train_index], y[test_index]\n    print('Running time of algorithm')\n    %time rf.fit(Xtrain, ytrain)\n    predictions = rf.predict(Xtest)\n    accuracy = accuracy_score(ytest, predictions)\n    outcomes3.append(accuracy)\n    print(\"Accuracy of KFold \",i, \"is: \",accuracy)\n    print('\\n')\n    print(\"Classification Report of KFold \",i,\" is following:\")\n    print('\\n')\n    CR=classification_report(ytest, predictions)\n    print(CR)\n    print('\\n')\n    print(\"Confusion Matrix of KFold \",i,\" is following:\")\n    print('\\n')\n    CM=confusion_matrix(ytest, predictions)\n    conf_matrix_list_of_arrays.append(CM)\n    print(CM)\n    print('\\n')\n    print('\\n')\n\nprint('\\n')\nprint('Average Confusion Matrix')\naa = np.mean(conf_matrix_list_of_arrays, axis=0)\n\naaa = np.ceil(aa)\n\nb=pd.DataFrame(aaa)\nb=b.astype(int)\nlabels =['Not Survived','Survived']\n\nc=np.array(b)\n\nfig, ax = plot_confusion_matrix(conf_mat=c,figsize=(10, 10),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.show()\nprint('\\n')\nprint('\\n')\nmean_outcome3 = np.mean(outcomes3)\nprint(\"Total Average Accuracy of Decision Trees Classifier is : {0}\".format(mean_outcome3)) ","7b8142f1":"a=pd.DataFrame()\na['outcomes1']=outcomes1\na['outcomes2']=outcomes2\na['outcomes3']=outcomes3\n\nplt.figure(figsize=(25, 10))\nplt.subplot(1,1,1)\nplt.plot(a.outcomes1.values,color='blue',label='Random Forest')\nplt.plot(a.outcomes2.values,color='green',label='KNN')\nplt.plot(a.outcomes3.values,color='red',label='Decision Trees')\nplt.title('Algorithms Comparison')\nplt.xlabel('Number of time')\nplt.ylabel('Accuracy')\nplt.legend(bbox_to_anchor=(1, 1))\nplt.show()","6a0c1486":"a=a.rename(columns={'outcomes1':'Random Forest', 'outcomes2':'KNN','outcomes3':'Decision Tree'})\na.plot(kind='bar',figsize=(25, 10))","a3dad5e9":"a","164d1d6d":"## Extract the Survived out from the train data","09ecb40d":"# Correlation Survived with Parch","a334b1af":"# Coloumns\/features in data","5a7eaac7":"# Shape of data","870b0f06":"# Five top records of data","5a5f6a0f":"# Correlation Survived with SEX","b2a428ee":"# Frequency Distribution of survived","52b91d3e":"<div class=\"alert alert-block alert-danger\">  \n<h2><center><strong> Best Model is Random Forest as we can see that it performed well on cross validation<\/strong><\/center><\/h2>\n        \n<\/div>","aa278f54":"- Higher fare paying passengers had better survival.\n- Port of embarkation correlates with survival rates. ","564135f7":"- We can see that the correlation of pclass with survived is more than 0.5 among Pclass=1 so we are going to add this feature in training","b96e2d4b":"## Now splitting the data for training and testing with same index ID's","7920f557":"<div class=\"alert alert-block alert-danger\">  \n    <h1><strong>Loading testing data<\/strong><\/h1>\n    <i><\/i>\n<\/div>","ea13de7c":"# Frequency Distribution of sex","f39f28f4":"# Frequency Distribution of top 10 age","124cd584":"<div class=\"alert alert-block alert-danger\">  \n    <h1><strong>Loading training data<\/strong><\/h1>\n    <i><\/i>\n<\/div>","bb7edf4a":"# Length of data","62679c77":"# Data types of all coloumns","3d035b0a":"# Exploratory data analysis of test data","0fd6520e":"## Drop the Survived & PassengerId  columns","3e5b08d5":"# Five last records of data","1556ac14":"# Data types of all coloumns","730abc6b":"## A function for checking the missing values","562f104b":"# Frequency Distribution of pclass","a48faf02":"# Embarked plot","577d30ad":"# Comparison of all algorithms Results","988e3542":"# Comparison of all algorithms Results","ba20fa00":"# Coloumns\/features in data","0388c958":"- We can see that the Parch with 1 and 2 is high correlated with survival but others are lower and zero","cef78aa7":"# Frequency Distribution of embarked","6ae87286":"# All features of test data distrubution ","260ff465":"- We can see that the correlation of Sex with survived is more than 0.5 among Sex=female so we are going to add this feature in training","c5e98018":"# Shape of data","75a184e7":"# Counts of missing values in each column","379aea0f":"# Frequency Distribution of embarked","60fb70e4":"# Correlation Survived with SibSp","ec03cbcb":"1. # Importing Python Libraries \ud83d\udcd5 \ud83d\udcd7 \ud83d\udcd8 \ud83d\udcd9","1653b67c":"# Frequency Distribution of top 10 age","14825921":"# Looking at correlated features with Survived ","f498df66":"# Is there any missing values?","23ff31ea":"# Correlation Survived with Pclass","25935f08":"<div class=\"alert alert-block alert-danger\">  \n<h2><center><strong> Applying Cross Vaildation on each algorithm<\/strong><\/center><\/h2>\n        \n<\/div>","1c7ff75a":"# Frequency Distribution of sex","00ca282f":"# Length of data","56fe3b73":"# Random Forest Machine Algorithm","c05b5a02":"- As we can see that most of old age peoples not survived","4edeffe3":"# Count of missing values","56b1fe3e":"# Count of missing values","d9e7a62f":"# Counts of missing values in each column","69a39afb":"## Combining the train and test dataset","4806a382":"# Pclass plot","530d3255":"# Five top records of data","5c86de37":"### int = numrical features \n### object = categorical features ","56eea44c":"<div class=\"alert alert-block alert-info\">  \n<h1><center><strong> You can use my code and apply more robust techniques to get better results. <\/strong><\/center><\/h1>\n<h1><center><strong> I hope you like my efforts for Kaggle Community. Thanks \ud83d\ude0d<\/strong><\/center><\/h1>\n        \n<\/div>","517048be":"## Imputing the Missing Values of all data","c654e2c1":"# Frequency Distribution of pclass","2acb7275":"# Data information","e78eedf4":"## Coverting the categorical\/Object features into numeric form by applying the LabelEncoder function","d114f760":"# Getting Started with Tabular Playground Series - Apr 2021","e73c0a96":"# Exploratory data analysis of train data","c3c85e08":"# Data information","371a0362":"- We can see that the siblling with 1 is high correlated with survival but others are lower and zero","ce3d66a6":"# Looking at the test data missing values.","750b962b":"# Age plot","13561c59":"<div class=\"alert alert-block alert-danger\">  \n<h2><center><strong>As we can see from the graphs, features has good correlation with Pclass<\/strong><\/center><\/h2>\n        \n<\/div>","ae74b4b8":"# Checking missing Values","820e85a2":"<div class=\"alert alert-block alert-info\">  \n<h2><center><strong>Features engineering and preparation<\/strong><\/center><\/h2>\n        \n<\/div>","d4935ce7":"# Is there any missing values?","d9a6d480":"<div class=\"alert alert-block alert-info\">  \n<h2><center><strong> Building the models for training and testing<\/strong><\/center><\/h2>\n        \n<\/div>","cb4045ad":"# KNN Machine Algorithm","4728db80":"- Pclass=3 had most passengers, however most did not survive.\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. \n- Most passengers in Pclass=1 survived. \n- Pclass varies in terms of Age distribution of passengers.","dbcb07de":"# Checking missing Values","6d31439d":"# All features of train data distrubution ","014a0aad":"# <img src=\"https:\/\/thumbor.forbes.com\/thumbor\/960x0\/https%3A%2F%2Fspecials-images.forbesimg.com%2Fdam%2Fimageserve%2F877330410%2F960x0.jpg%3Ffit%3Dscale\">","81c08a4c":"# Looking at the train data missing values.","e3409c30":"# Five last records of data","986bccc4":"# Decision Trees Machine Algorithm"}}