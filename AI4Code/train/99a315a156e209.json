{"cell_type":{"2c849d6c":"code","3f9f8cc0":"code","2542b898":"code","824131c9":"code","3889cd67":"code","6753eae1":"code","4d6cd606":"code","b377c4d3":"code","b23e0ac8":"code","ab0ef65b":"markdown","892c17f1":"markdown","ab609651":"markdown","5456ae24":"markdown","5fb97054":"markdown","58ef40d5":"markdown","40d6f613":"markdown","7b8fd3de":"markdown","17383d94":"markdown","a01c0c25":"markdown","fe8ac698":"markdown","8fb1c810":"markdown","1edb85f8":"markdown"},"source":{"2c849d6c":"import pandas as pd\nimport os\nimport re\nimport numpy as np\n","3f9f8cc0":"\ndf_sales_train_validation = pd.read_csv(r'..\/input\/m5-forecasting-accuracy\/sales_train_validation.csv')\n","2542b898":"df_sales_train_validation.head(3)","824131c9":"cols = df_sales_train_validation.filter(regex='d_').columns\nmax = 0\nfor c in cols:\n    if df_sales_train_validation[c].max() > max:\n        max = df_sales_train_validation[c].max()\nprint('The maximum value for columns d_1 to d_1913 is: ', max)        ","3889cd67":"def ReduceSize(df_,  fl = 1):\n    intValues = ['int_', 'intc', 'intp', 'int8', 'int16', 'int32', 'int64', 'uint8', 'uint16', 'uint32', 'uint64']\n    floatValues = ['float_', 'float16', 'float32', 'float64']\n    minn, maxx = 0, 0 \n    stype = ''\n    for c in df_.columns:\n        try:\n            if df_[c].dtypes == 'object':\n                df_[c] = df_[c].astype('int64')\n                print('Successful conversion Object to Integer for COlumn: ', c)\n        except:\n            print('Not Possible Casting Object to INT64 for column: ', c)\n        stype = df_[c].dtypes\n        #Cast to INT\n        if stype in intValues:\n            minn , maxx = 1, -1\n            maxx = df_[c].max()\n            minn = df_[c].min()\n            if (minn >= -128) &  (maxx <= 128):\n                df_[c] = df_[c].astype('int8')                   \n            else:\n                if (minn >= -32767) &  (maxx <= 32767):\n                    df_[c] = df_[c].astype('int16')\n                else:\n                    if (minn >= -2147483647) &  (maxx <= 2147483647):\n                        df_[c] = df_[c].astype('int32')\n                    else:\n                        df_[c] = df_[c].astype('int64')\n            #Cast to UINT\n            if (fl == 2):\n                if (minn >= 0) &  (maxx <= 255):\n                    df_[c] = df_[c].astype('uint8')                   \n                else:\n                    if (minn >= 0) &  (maxx <= 65535):\n                        df_[c] = df_[c].astype('uint16')                   \n                    else:\n                        if (minn >= 0) &  (maxx <= 4294967295):\n                            df_[c] = df_[c].astype('uint32')                   \n                        else:\n                            if (minn >= 0) &  (maxx <= 18446744073709551615):\n                                df_[c] = df_[c].astype('uint64')                   \n        \n        if stype in floatValues:\n            try:\n                df_[c] = df_[c].astype('float16')\n            except:\n                try:\n                    df_[c] = df_[c].astype('float32')\n                except:\n                    df_[c] = df_[c].astype('float64')            \n        print(c)\n    \n    return df_","6753eae1":"df_sales_train_validation.memory_usage(index=False)","4d6cd606":"\nnp.sum(df_sales_train_validation.memory_usage(index=False))\n","b377c4d3":"ReduceSize(df_sales_train_validation)","b23e0ac8":"\nnp.sum(df_sales_train_validation.memory_usage(index=False))\n","ab0ef65b":"\nThe size before omptimization is 468082480 and after running function and getting optimized it become 98604660. With some simple calculations we will see that **the size of the data is decreased for almost 80 percent**.\n","892c17f1":"Thank you to @[ragnar123](https:\/\/www.kaggle.com\/ragnar123)","ab609651":"\nNow let's see the memory used after **OPTIMIZATION**:\n","5456ae24":"# **THIS FUNCTION COULD BE USED FOR ANY DATAFRAME FROM ANY COMPETIOTION OR CHALLENGE!** \n\n#  So keep it and USE it ...","5fb97054":"![](https:\/\/fmad.io\/images\/blog\/20160128_zip.png)","58ef40d5":"\nThis function gives information based on columns, therefor if we would to see the whole volume occupied, a SUM() is needed as follow:\n","40d6f613":"One of the challenges working with pandas dataframe is dimensions of the frames. Generally there are millions of records. Dataframes containing Time Series data are usually huge. Although some libraries or techniques has come to help the situation, still there is a lot to be done. Pandas.melt function is one of them in order to reduce the horizontal size of the frames and make it vertically.  This helps for better processing but it is not enough. \nAnother technique is reducing the size of dataframes. \n\nMost of the times the data type set for columns are initially set to the maximum size. Considering the number of columns with the same conditions makes the situation worse. For example in M5 dataset, the sales_train_validation.csv  conveys the amount of sold items in 1913 days. Simply the number of sold items per day would not be high. Here, the following code returns the maximum amount over all 1913 days.\n","7b8fd3de":"Before we do any operation on our data let's get some info about the dataset. The function ****memory_usage**** shows how much memory is occupied by the dataset. ","17383d94":"There are **TWO arguments** for this function. The **first** one is a Dataframe, and the **second** is a number that could be 1 or 2. Normally it would be set with 1 as default value but if you would like to include **Unsigned Integer** (\u201cuint8\u201d, \u201cuint16\u201d, \u201cuint32\u201d, or \u201cuint64\u201d) as your possible datatypes the second arument must set with 2.","a01c0c25":"I appreciate try the function with your existing dataset. In case you face error or inefficiency please let me know so as to improve it. \n","fe8ac698":"So, the maximum amount is 763! The interesting point is that all columns are set with int64 data type. For more information, int64 is defined to save numbers with almost 19 digits. However, in our case the maximum target is a 3 digits number which could be processed with int16 as well; so let\u2019s reduce the size of all of columns to int16. The following code helps to do so easily. \n\nThe point regarding this function is that it could be used for any dataframe and you will not have to care about the name of target columns or whether its data types are enumerated as integer or not. \n","8fb1c810":"\nThe dataset used for this tutorial is **df_sales_train_validation** from M5 competition.\n\n","1edb85f8":"The data originally is not big but after loading, joining as well as other operations then become huge and a big size RAM will be needed\n\n\n![](https:\/\/gdpr.report\/wp-content\/uploads\/2019\/05\/graph-3078539_1280-e1557991579520-635x360.png)\n"}}