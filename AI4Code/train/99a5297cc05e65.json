{"cell_type":{"9fc583d0":"code","2fc80da6":"code","d53a1844":"code","32dfee2f":"code","d943ea97":"code","75f7fbf6":"code","07ed0d20":"code","458099fd":"code","b370717c":"code","a5c1a4e5":"code","f9d99d6f":"code","aba17493":"code","aebcb259":"code","84396058":"code","0cd99021":"code","b906b534":"code","2a835f1a":"code","22897814":"code","00083cb1":"code","8cff48b5":"markdown","92c30808":"markdown","96781c38":"markdown","4bffbd3c":"markdown","b3cf98ca":"markdown","27b8e954":"markdown","93804866":"markdown","b039ac6d":"markdown","6a85101b":"markdown","67a90ad2":"markdown","5b866948":"markdown","ac3f7eeb":"markdown","56f78c7d":"markdown","9cbac21e":"markdown","1a5e62f7":"markdown","cb063fef":"markdown","1f1cfd6e":"markdown"},"source":{"9fc583d0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport cv2\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","2fc80da6":"os.listdir('..\/input\/tensorflow-great-barrier-reef\/')","d53a1844":"train = pd.read_csv('..\/input\/tensorflow-great-barrier-reef\/train.csv', index_col=0)\ntrain.head()","32dfee2f":"test = pd.read_csv('..\/input\/tensorflow-great-barrier-reef\/test.csv', index_col=0)\ntest.head()","d943ea97":"!pip install kornia","75f7fbf6":"import torch\nimport torchvision\nimport kornia as K","07ed0d20":"img_bgr: np.array = cv2.imread('..\/input\/tensorflow-great-barrier-reef\/train_images\/video_1\/10004.jpg')  # HxWxC \/ np.uint8\nimg_rgb: np.array = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n\nplt.imshow(img_rgb); plt.axis('off');","458099fd":"x_rgb: torch.tensor = torchvision.io.read_image('..\/input\/tensorflow-great-barrier-reef\/train_images\/video_1\/10004.jpg')  # CxHxW \/ torch.uint8\nx_rgb = x_rgb.unsqueeze(0)  # BxCxHxW\nprint(x_rgb.shape);","b370717c":"#Code by https:\/\/kornia-tutorials.readthedocs.io\/en\/latest\/hello_world_tutorial.html\n\nx_bgr: torch.tensor = K.image_to_tensor(img_bgr)  # CxHxW \/ torch.uint8\nx_bgr = x_bgr.unsqueeze(0)  # 1xCxHxW\nprint(f\"convert from '{img_bgr.shape}' to '{x_bgr.shape}'\")","a5c1a4e5":"x_rgb: torch.tensor = K.color.bgr_to_rgb(x_bgr)  # 1xCxHxW \/ torch.uint8","f9d99d6f":"img_bgr: np.array = K.tensor_to_image(x_bgr)\nimg_rgb: np.array = K.tensor_to_image(x_rgb)","aba17493":"#Code by https:\/\/kornia-tutorials.readthedocs.io\/en\/latest\/hello_world_tutorial.html\n\nfig, axs = plt.subplots(1, 2, figsize=(32, 16))\naxs = axs.ravel()\n\naxs[0].axis('off')\naxs[0].imshow(img_rgb)\n\naxs[1].axis('off')\naxs[1].imshow(img_bgr)\n\nplt.show()","aebcb259":"#Code by https:\/\/kornia-tutorials.readthedocs.io\/en\/latest\/data_augmentation_sequential.html?highlight=bbox\n\nfrom kornia import augmentation as K\nfrom kornia.augmentation import AugmentationSequential\n#from kornia.geometry import bbox_to_mask   #Deprecated??\nfrom kornia.utils import image_to_tensor, tensor_to_image\nfrom torchvision.transforms import transforms\nfrom kornia.geometry.bbox import bbox_to_mask as _bbox_to_mask\n\nto_tensor = transforms.ToTensor()\nto_pil = transforms.ToPILImage()\n\ndef plot_resulting_image(img, bbox, keypoints, mask):\n    img = img * mask\n    img_draw = cv2.polylines(np.array(to_pil(img)), bbox.numpy(), isClosed=True, color=(255, 0, 0))\n    for k in keypoints[0]:\n        img_draw = cv2.circle(img_draw, tuple(k.numpy()[:2]), radius=6, color=(255, 0, 0), thickness=-1)\n    return img_draw\n\nimg = cv2.imread(\"..\/input\/tensorflow-great-barrier-reef\/train_images\/video_1\/10004.jpg\", cv2.IMREAD_COLOR)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nh, w = img.shape[:2]\n\nimg_tensor = image_to_tensor(img).float() \/ 255.\nplt.imshow(img); plt.axis('off');","84396058":"#Code by https:\/\/kornia-tutorials.readthedocs.io\/en\/latest\/data_augmentation_sequential.html?highlight=bbox\n\naug_list = AugmentationSequential(\n    K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=1.0),\n    K.RandomAffine(360, [0.1, 0.1], [0.7, 1.2], [30., 50.], p=1.0),\n    K.RandomPerspective(0.5, p=1.0),\n    data_keys=[\"input\", \"bbox\", \"keypoints\", \"mask\"],\n    return_transform=False,\n    same_on_batch=False,\n)\n\nbbox = torch.tensor([[[355,10],[660,10],[660,250],[355,250]]])\nkeypoints = torch.tensor([[[465, 115], [545, 116]]])\nmask = bbox_to_mask(torch.tensor([[[155,0],[900,0],[900,400],[155,400]]]), w, h).float()\n\nimg_out = plot_resulting_image(img_tensor, bbox, keypoints, mask)\nplt.imshow(img_out); plt.axis('off');","0cd99021":"#Code by https:\/\/kornia-tutorials.readthedocs.io\/en\/latest\/data_augmentation_sequential.html?highlight=bbox\n\nout_tensor = aug_list(img_tensor, bbox.float(), keypoints.float(), mask)\nimg_out = plot_resulting_image(\n    out_tensor[0][0],\n    out_tensor[1].int(),\n    out_tensor[2].int(),\n    out_tensor[3][0],\n)\nplt.imshow(img_out); plt.axis('off');","b906b534":"#Code by https:\/\/kornia-tutorials.readthedocs.io\/en\/latest\/data_augmentation_sequential.html?highlight=bbox\n\nout_tensor_inv = aug_list.inverse(*out_tensor)\nimg_out = plot_resulting_image(\n    out_tensor_inv[0][0],\n    out_tensor_inv[1].int(),\n    out_tensor_inv[2].int(),\n    out_tensor_inv[3][0],\n)\nplt.imshow(img_out); plt.axis('off');","2a835f1a":"to_tensor = transforms.ToTensor()\nto_pil = transforms.ToPILImage()\n\n\ndef plot_resulting_image(img, bbox, keypoints, mask):\n    img = img * mask\n    img_draw = cv2.polylines(np.array(to_pil(img)), bbox.numpy(), isClosed=True, color=(255, 0, 0))\n    for k in keypoints[0]:\n        img_draw = cv2.circle(img_draw, tuple(k.numpy()[:2]), radius=6, color=(255, 0, 0), thickness=-1)\n    return img_draw\n\nimg = cv2.imread(\"..\/input\/tensorflow-great-barrier-reef\/train_images\/video_2\/100.jpg\", cv2.IMREAD_COLOR)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nh, w = img.shape[:2]\n\nimg_tensor = image_to_tensor(img).float() \/ 255.\nplt.imshow(img); plt.axis('off');","22897814":"#Code by https:\/\/kornia-tutorials.readthedocs.io\/en\/latest\/data_patch_sequential.html\n\nfrom kornia.augmentation import PatchSequential, ImageSequential\n\npseq = PatchSequential(\n    ImageSequential(\n        K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=0.5),\n        K.RandomPerspective(0.2, p=0.5),\n        K.RandomSolarize(0.1, 0.1, p=0.5),\n    ),\n    K.RandomAffine(15, [0.1, 0.1], [0.7, 1.2], [0., 20.], p=0.5),\n    K.RandomPerspective(0.2, p=0.5),\n    ImageSequential(\n        K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=0.5),\n        K.RandomPerspective(0.2, p=0.5),\n        K.RandomSolarize(0.1, 0.1, p=0.5),\n    ),\n    K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=0.5),\n    K.RandomAffine(15, [0.1, 0.1], [0.7, 1.2], [0., 20.], p=0.5),\n    K.RandomPerspective(0.2, p=0.5),\n    K.RandomSolarize(0.1, 0.1, p=0.5),\n    K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=0.5),\n    K.RandomAffine(15, [0.1, 0.1], [0.7, 1.2], [0., 20.], p=0.5),\n    ImageSequential(\n        K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=0.5),\n        K.RandomPerspective(0.2, p=0.5),\n        K.RandomSolarize(0.1, 0.1, p=0.5),\n    ),\n    K.RandomSolarize(0.1, 0.1, p=0.5),\n    K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=0.5),\n    K.RandomAffine(15, [0.1, 0.1], [0.7, 1.2], [0., 20.], p=0.5),\n    K.RandomPerspective(0.2, p=0.5),\n    K.RandomSolarize(0.1, 0.1, p=0.5),\n    patchwise_apply=True,\n    same_on_batch=True,\n)\nout_tensor = pseq(img_tensor[None].repeat(2, 1, 1, 1))\nto_pil(torch.cat([out_tensor[0], out_tensor[1]], dim=2))","00083cb1":"#Code by https:\/\/kornia-tutorials.readthedocs.io\/en\/latest\/data_patch_sequential.html\n\npseq = PatchSequential(\n    K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=0.75),\n    K.RandomElasticTransform(alpha=(4., 4.)),\n    patchwise_apply=False,\n    same_on_batch=False\n)\nout_tensor = pseq(img_tensor[None].repeat(2, 1, 1, 1))\nto_pil(torch.cat([out_tensor[0], out_tensor[1]], dim=2))","8cff48b5":"#Load an image with Torchvision\n\nIt returns the images in a torch.Tensor in the shape (C,H,W).","92c30808":"#It's a TensorFlow Competition.  My bad, I'm sorry.","96781c38":"#Visualize an image with Matplotib","4bffbd3c":"#Acknowledgement:\n\n@inproceedings{eriba2020kornia, author = {E. Riba, D. Mishkin, J. Shi, D. Ponsa, F. Moreno-Noguer and G. Bradski}, title = {A survey on Kornia: an Open Source Differentiable Computer Vision Library for PyTorch}, year = {2020}, }\n\n@inproceedings{eriba2019kornia, author = {E. Riba, D. Mishkin, D. Ponsa, E. Rublee and G. Bradski}, title = {Kornia: an Open Source Differentiable Computer Vision Library for PyTorch}, booktitle = {Winter Conference on Applications of Computer Vision}, year = {2020}, url = {https:\/\/arxiv.org\/pdf\/1910.02190.pdf} }\n\n@misc{Arraiy2018, author = {E. Riba, M. Fathollahi, W. Chaney, E. Rublee and G. Bradski}, title = {torchgeometry: when PyTorch meets geometry}, booktitle = {PyTorch Developer Conference}, year = {2018}, url = {https:\/\/drive.google.com\/file\/d\/1xiao1Xj9WzjJ08YY_nYwsthE-wxfyfhG\/view?usp=sharing} }","b3cf98ca":"#Load an image with Kornia\n\n\"The utility is kornia.image_to_tensor which casts a numpy.ndarray to a torch.Tensor and permutes the channels to leave the image ready for being used with any other PyTorch or Kornia component. The image is casted into a 4D torch.Tensor with zero-copy.\"\n\nhttps:\/\/kornia-tutorials.readthedocs.io\/en\/latest\/hello_world_tutorial.html","27b8e954":"<iframe width=\"956\" height=\"538\" src=\"https:\/\/www.youtube.com\/embed\/c9-QGMUUbbU\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>","93804866":"#Forward Computations","b039ac6d":"#Inverse Transformations","6a85101b":"#Patch Augmentation Sequential with patchwise_apply=True","67a90ad2":"I tried from kornia.geometry.bbox import bbox_to_mask as _bbox_to_mask  Though the warning above persists. ","5b866948":"#Define Augmentation Sequential and Different Labels","ac3f7eeb":"#Though it's TensorFlow Competition, I made a Kaggle Notebook with a library that uses PyTorch (awkward situation).","56f78c7d":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #4169E1;\"><b style=\"color:white;\">Control Crown-of-Thorns Starfish<\/b><\/h1><\/center>\n\n\nCrown-of-Thorns Starfish\n\n\"Since 1962, crown-of-thorns starfish outbreaks have had a major impact on the many reefs that make up the Great Barrier Reef. A fourth outbreak is currently underway in the World-Heritage Area.\"\n\n\"Crown-of-thorns starfish (also known as COTS) are marine invertebrates that feed on coral. They occur naturally on reefs throughout the Indo-Pacific region, and when conditions are right, they can reach plague proportions and devastate hard coral communities.\"\n\n\"Laboratory research at AIMS (Australian Institute of Marine Science) has shown that survival of crown-of-thorns starfish larvae increases dramatically when phytoplankton, their food source, becomes more abundant. Phytoplankton numbers are usually low in reef waters, but production can increase rapidly if early-season monsoonal and cyclonic floods carry fertilisers and other pollutants into the Great Barrier Reef lagoon.\"\n\n\"Once dense breeding populations of starfish develop on some reefs, the huge numbers of larvae that they produce can establish outbreaks on mid-shelf reefs in the central Reef, even though these reefs are hardly ever affected by runoff.\"\n\nhttps:\/\/www.aims.gov.au\/docs\/research\/biodiversity-ecology\/threats\/cots.html","9cbac21e":"#Patch Augmentation Sequential with patchwise_apply=False","1a5e62f7":"#Surviving corals eaten by Crown of Thorns Starfish | WWF-Australia\n\nhttps:\/\/www.youtube.com\/watch?v=c9-QGMUUbbU  - 10 de jan. de 2019\n\nScientists fear starfish could combine with bleaching in \u201cperfect storm\u201d of Reef destruction. \n\nA new WWF-Australia report urges a crackdown on the \u201cexcessive, and often illegal,\u201d use of industrial fertilisers that trigger outbreaks.\n\u2013\n\nMORE FROM WWF-AUSTRALIA\n\nSOCIAL:\nFacebook... \u25bahttps:\/\/www.facebook.com\/wwfaustralia\/\nInstagram.. \u25ba https:\/\/www.instagram.com\/wwf_australia\/\nTwitter........ \u25ba https:\/\/twitter.com\/WWF_Australia\/","cb063fef":"#Convert from BGR to RGB with a kornia.color component.","1f1cfd6e":"![](https:\/\/www.gbrmpa.gov.au\/__data\/assets\/image\/0010\/267229\/varieties\/max1300.jpg)gbrmpa.gov.au"}}