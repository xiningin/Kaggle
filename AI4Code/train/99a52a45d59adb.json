{"cell_type":{"91f00182":"code","600ab19a":"code","0df50552":"code","1e9910b5":"code","b5c9e805":"code","926d3de5":"code","b01470c2":"code","8f2a4c03":"code","6251370b":"code","0f840b6e":"code","a769f4b7":"code","6601736a":"code","9171b346":"code","be71db40":"code","7323f950":"code","01013dfc":"code","1246abdd":"code","741bacee":"code","a205cd75":"code","2fbac81c":"code","2af7c4a0":"code","315281a6":"code","9c8575c9":"code","071d0340":"code","de4976a3":"code","a2dd31c0":"code","aabe186a":"code","53984b0d":"markdown","65af1d5a":"markdown","a4cfb1dd":"markdown","81828431":"markdown","b11014e5":"markdown","af2d4676":"markdown","3ff3e384":"markdown","fa3f087b":"markdown","de8820ac":"markdown","583948e4":"markdown","628d5573":"markdown","ec61933b":"markdown","d9d36853":"markdown","e91537ff":"markdown","fac5a823":"markdown","981260de":"markdown","c4af204c":"markdown","314d39a1":"markdown"},"source":{"91f00182":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nfrom sklearn import preprocessing\nfrom sklearn import linear_model\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import make_scorer\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n\nfold_count=20","600ab19a":"def RMSLE(y_in,y_out):\n    return np.sqrt(np.mean((np.log(np.abs(y_out)+1) - np.log(np.abs(y_in)+1))**2))\n\nRMSLE_scorer = make_scorer(RMSLE, greater_is_better=False)\n","0df50552":"train_data = pd.read_csv(\"\/kaggle\/input\/atividade-regressao-PMR3508\/train.csv\",\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")\n\n\ntrain_data.describe() # checando se est\u00e1 tudo dentro do esperado","1e9910b5":"train_data.head()","b5c9e805":"train_data.shape","926d3de5":"plt.scatter(train_data['longitude'],train_data['latitude'],s=2)","b01470c2":"train_data.dropna()","8f2a4c03":"test_data = pd.read_csv(\"\/kaggle\/input\/atividade-regressao-PMR3508\/test.csv\",\n        sep=r'\\s*,\\s*',\n        engine='python',\n        index_col='Id',\n        na_values=\"?\")\n\n\ntest_data.describe() # checando se est\u00e1 tudo dentro do esperado","6251370b":"test_data.head()","0f840b6e":"fig, axs = plt.subplots(3, 2,figsize=(15,15))\ncounter=0\n\nfor i in range(3):\n    for j in range(2):\n\n        axs[i, j].hist(train_data[train_data.columns[3+counter]])\n        axs[i, j].set_title(str(train_data.columns[3+counter]))\n        counter+=1","a769f4b7":"figure(figsize=(7,5))\n\nplt.scatter(train_data['longitude'], train_data['latitude'], c=train_data['median_house_value'],s=3, cmap = 'jet')\nplt.title('Posi\u00e7\u00e3o geogr\u00e1fica - '+str(train_data.columns[9]))\nplt.xlabel('longitude')\nplt.ylabel('latitude')\nplt.colorbar()","6601736a":"fig, axs = plt.subplots(3, 2,figsize=(15,15))\ncounter=0\n\nfor i in range(3):\n    for j in range(2):\n\n        axs[i, j].scatter(train_data['longitude'], train_data['latitude'], c=train_data[train_data.columns[3+counter]],s=3, cmap = 'jet')\n        axs[i, j].set_title('Posi\u00e7\u00e3o geogr\u00e1fica - '+str(train_data.columns[3+counter]))\n        counter+=1\n\n\nfor ax in axs.flat:\n    ax.set(xlabel='longitude', ylabel='latitude')\n\n# Hide x labels and tick labels for top plots and y ticks for right plots.\nfor ax in axs.flat:\n    ax.label_outer()","9171b346":"clf = linear_model.LinearRegression()\n\nx=train_data.loc[:,:]\n\n# Create x, where x the 'scores' column's values as floats\nx = x.values.astype(float)\n\n# Create a minimum and maximum processor object\nscaler = preprocessing.StandardScaler()\n\n# Create an object to transform the data to fit minmax processor\nx_scaled = scaler.fit_transform(x)\n\n# Run the normalizer on the dataframe\nnormalized = pd.DataFrame(x_scaled)\n\n#y_train=np.log(train_data['median_house_value'])\ny_train=train_data['median_house_value']\n\nerror=[]\n\nindex_error=1\n\nerror.append(np.mean(abs(cross_val_score(clf, normalized[[1,2,3,8]], y_train ,cv=fold_count, scoring = RMSLE_scorer))))","be71db40":"print('RMSLE')\nprint(error[0])","7323f950":"print('RMSLE')\nfor i in range(4):\n    error.append(np.mean(abs(cross_val_score(clf, normalized[[1,2,3,8,i+4]], y_train ,cv=fold_count, scoring = RMSLE_scorer))))\n    print(np.round(error[index_error],5), end=' ')\n    print(np.round((error[0]-error[index_error])\/error[0]*100,3))\n    index_error+=1","01013dfc":"train_data['median_pop']=np.divide(train_data['population'],train_data['households'])\ntrain_data['median_bedrooms']=np.divide(train_data['total_bedrooms'],train_data['households'])\ntrain_data['median_rooms']=np.divide(train_data['total_rooms'],train_data['households'])\n\nx=train_data.loc[:,:]\n\n# Create x, where x the 'scores' column's values as floats\nx = x.values.astype(float)\n\n# Create a minimum and maximum processor object\nmin_max_scaler = preprocessing.MinMaxScaler()\n\n# Create an object to transform the data to fit minmax processor\nx_scaled = min_max_scaler.fit_transform(x)\n\n# Run the normalizer on the dataframe\nnormalized_2 = pd.DataFrame(x_scaled)","1246abdd":"figure(figsize=(7,5))\n\nplt.scatter(train_data['longitude'], train_data['latitude'], c=normalized_2[7],s=2, cmap = 'jet')\nplt.title('Posi\u00e7\u00e3o geogr\u00e1fica - '+str(train_data.columns[10]))\nplt.xlabel('longitude')\nplt.ylabel('latitude')\nplt.colorbar()","741bacee":"figure(figsize=(7,5))\n\nplt.scatter(train_data['longitude'], train_data['latitude'], c=normalized_2[8],s=2, cmap = 'jet')\nplt.title('Posi\u00e7\u00e3o geogr\u00e1fica - '+str(train_data.columns[11]))\nplt.xlabel('longitude')\nplt.ylabel('latitude')\nplt.colorbar()","a205cd75":"figure(figsize=(7,5))\n\nplt.scatter(train_data['longitude'], train_data['latitude'], c=normalized_2[9],s=2, cmap = 'jet')\nplt.title('Posi\u00e7\u00e3o geogr\u00e1fica - '+str(train_data.columns[12]))\nplt.xlabel('longitude')\nplt.ylabel('latitude')\nplt.colorbar()","2fbac81c":"print('RMSLE')\nfor i in range(3):\n    error.append(np.mean(abs(cross_val_score(clf, normalized_2[[1,2,3,8,i+10]], y_train ,cv=fold_count, scoring = RMSLE_scorer))))\n    print(np.round(error[index_error],5), end=' ')\n    print(np.round((error[0]-error[index_error])\/error[0]*100,3))\n    index_error+=1","2af7c4a0":"cross_scores=[]\nk_list=[]\n\n#testaremos K de 1 \u00e0 100\nfor i in range(1,100):\n    \n    k_list.append(i)\n    knn = KNeighborsRegressor(n_neighbors=i)\n    \n    cross_scores.append(np.mean(abs(cross_val_score(knn, normalized_2[[1,2,3,8]], y_train,cv=fold_count,scoring = RMSLE_scorer))))\n    #print(cross_scores)\nplt.plot(k_list,cross_scores)","315281a6":"k_num=cross_scores.index(min(cross_scores))\nk_num\n","9c8575c9":"knn = KNeighborsRegressor(n_neighbors=k_num)\n    \nerror.append(np.mean(abs(cross_val_score(knn, normalized_2[[1,2,3,8]], y_train,cv=fold_count,scoring = RMSLE_scorer))))\nprint('RMSLE')\nprint(error[index_error])\n\nindex_error+=1","071d0340":"error_zero_knn=index_error-1\n\nprint('RMSLE')\nfor i in [4,5,6,7,10,11,12]:\n    error.append(np.mean(abs(cross_val_score(knn, normalized_2[[1,2,3,8,i]], y_train ,cv=fold_count, scoring = RMSLE_scorer))))\n    print(np.round(error[index_error],5), end=' ')\n    print(np.round((error[error_zero_knn]-error[index_error])\/error[error_zero_knn]*100,3))\n    index_error+=1","de4976a3":"x=test_data.loc[:,['longitude','latitude','median_age','median_income']]\n\n# Create x, where x the 'scores' column's values as floats\nx = x.values.astype(float)\n\n# Create a minimum and maximum processor object\nmin_max_scaler = preprocessing.MinMaxScaler()\n\n# Create an object to transform the data to fit minmax processor\nx_scaled = min_max_scaler.fit_transform(x)\n\n# Run the normalizer on the dataframe\nnormalized_3 = pd.DataFrame(x_scaled)\n\nknn.fit(normalized[[1,2,3,8]],y_train)\ny_pred=knn.predict(normalized_3)\n\n\nsubmission=pd.DataFrame(index=test_data.index)\nsubmission[\"median_house_value\"]=y_pred\nsubmission.to_csv(\"submission.csv\", index = True, index_label = 'Id')\nsubmission","a2dd31c0":"submission.describe()","aabe186a":"angle=60\n\nrad=angle\/180*np.pi\n\nT=np.array([[np.cos(rad),-np.sin(rad)],[np.sin(rad), np.cos(rad)]])\nT_inv=np.linalg.inv(T)\n\n\nlong=train_data.loc[:,'longitude']\nlong=np.array(long.values)\nlong=np.transpose(long)\n\nlat=train_data.loc[:,'latitude']\nlat=np.array(lat.values)\nlat=np.transpose(lat)\n\nordinary_coord=np.concatenate([[long],[lat]])\n\ncoastal_coord=np.dot(T_inv,ordinary_coord)\n\nfig, axs = plt.subplots(3, 2,figsize=(15,15))\ncounter=3\n\nfor i in range(3):\n    for j in range(2):\n\n        axs[i, j].scatter(np.transpose(coastal_coord[0,:]),np.transpose(coastal_coord[1,:]), c=normalized_2[counter],s=3, cmap = 'jet')\n        axs[i, j].set_title('Posi\u00e7\u00e3o geogr\u00e1fica - '+str(train_data.columns[3+counter]))\n        counter+=1\n\n\nfor ax in axs.flat:\n    ax.set(xlabel='longitude', ylabel='latitude')\n\n# Hide x labels and tick labels for top plots and y ticks for right plots.\nfor ax in axs.flat:\n    ax.label_outer()","53984b0d":"# KNN\n\nVamos testar outro m\u00e9todo de regress\u00e3o para avaliar seu desempenho. Primeiramente com as quatro *features* j\u00e1 selecionadas.","65af1d5a":"# Explorando as *features*","a4cfb1dd":"O resultado m\u00e9dio para a m\u00e9trica RMSLE","81828431":"Aparentemente, *population*, *total_bedrooms* e *total_rooms* n\u00e3o s\u00e3o interessantes, pois a sua adi\u00e7\u00e3o \u00e0 regress\u00e3o contribuiu pouco para a diminui\u00e7\u00e3o do erro. Vamos analisar se a \"densidade populacional\", \"densidade de quartos\" e \"densidade de c\u00f4modos\" possam contribuir para a regress\u00e3o.","b11014e5":"Aparentemente, n\u00e3o h\u00e1 ganho significativo em adicionar essas *features* tamb\u00e9m.","af2d4676":"\u00c9 esperado que a posi\u00e7\u00e3o geogr\u00e1fica seja um fator de grande influ\u00eancia no pre\u00e7o de um im\u00f3vel. Vamos averiguar qualitativamente se esta hip\u00f3tese \u00e9 razo\u00e1vel. ","3ff3e384":"# \u00c2ngelo Bianco Yanagita - 6649978","fa3f087b":"Defini\u00e7\u00e3o do score RMSLE de acordo com o que fora implementado pelo aluno Rodrigo Gebara Reis.","de8820ac":"Inicialmente, vamos verificar a distribui\u00e7\u00e3o das *labels* no *dataset*.","583948e4":"Pode-se observar gradientes tanto no gr\u00e1fico referente \u00e0 *median_age* quanto \u00e0 *median_income* e por esse motivo, usaremos essas features juntamente com a posi\u00e7\u00e3o geogr\u00e1fico para a primeira vers\u00e3o da regress\u00e3o.","628d5573":"Onde o hiperpar\u00e2metro k com melhor desempenho segue:","ec61933b":"De modo an\u00e1logo \u00e0 regress\u00e3o linear, vamos analisar se a adi\u00e7\u00e3o de features contribui para o desempenho do KNN:","d9d36853":"Mais uma vez, n\u00e3o houve melhora significativa na adi\u00e7\u00e3o dessas *features*. Contudo, a regress\u00e3o com base no KNN com K=9 teve um desempenho muito superior \u00e0 abordagem com regress\u00e3o linear, portanto, usaremos o KNN como estimador para a submiss\u00e3o.","e91537ff":"# Tentativa de mudan\u00e7a de coordenadas","fac5a823":"Podemos perceber que \u00e9 razo\u00e1vel considerar que h\u00e1 correla\u00e7\u00e3o entre posi\u00e7\u00e3o geogr\u00e1fica e pre\u00e7o das casas. Partindo desse pressuposto, analisaremos se mais features est\u00e3o relacionadas \u00e0 posi\u00e7\u00e3o geogr\u00e1fica.","981260de":"# Importanto dados de teste","c4af204c":"# Import dos dados de treino","314d39a1":"Vamos analisar se adicionar uma das *features* restantes por vez, teremos um decr\u00e9scimo no erro."}}