{"cell_type":{"a2ff34de":"code","e2201b64":"code","a53d5952":"code","eb775204":"code","622b71b6":"code","ffa1ce2d":"code","ff596ddf":"code","958027e8":"code","9b7e93b7":"code","50a828e0":"code","b768c0d9":"code","8458fa42":"code","6c2d914e":"code","0084d342":"markdown","2b6f402e":"markdown","2641ce51":"markdown","5ee78e34":"markdown","54ad0dfe":"markdown","3c81103b":"markdown","e5a98170":"markdown","5f49f025":"markdown","9170c6a0":"markdown","18bd77fa":"markdown","07aefaf1":"markdown","84dc8a84":"markdown"},"source":{"a2ff34de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport math\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e2201b64":"data = pd.read_csv('\/kaggle\/input\/international-airline-passengers\/international-airline-passengers.csv', skipfooter = 5,engine='python')\ndata.head()","a53d5952":"dataset = data.iloc[:,1].values\nplt.plot(dataset)\nplt.xlabel('time')\nplt.ylabel('# of Passenger')\nplt.title('International Airline Passenger')\nplt.show()","eb775204":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error","622b71b6":"dataset = dataset.reshape(-1,1)\ndataset = dataset.astype(\"float32\")\ndataset.shape","ffa1ce2d":"scaler = MinMaxScaler(feature_range = (0,1))\ndataset = scaler.fit_transform(dataset)\ntrain_size = int(len(dataset) * 0.50)\ntest_size = len(dataset) - train_size\ntrain = dataset[0:train_size,:]\ntest = dataset[train_size:len(dataset),:]\nprint(\"Train size : {}\".format(len(train)))\nprint(\"Test size : {}\".format(len(test)))","ff596ddf":"time_stemp = 10\ndataX = []\ndataY = []\nfor i in range(len(train) - time_stemp - 1):\n    a = train[i:(i+time_stemp),0]\n    dataX.append(a)\n    dataY.append(train[i+time_stemp,0])\ntrainX = np.array(dataX)\ntrainY = np.array(dataY)","958027e8":"\ndataX = []\ndataY = []\nfor i in range(len(train) - time_stemp - 1):\n    a = test[i:(i+time_stemp),0]\n    dataX.append(a)\n    dataY.append(test[i+time_stemp,0])\ntestX = np.array(dataX)\ntestY = np.array(dataY)","9b7e93b7":"trainX = np.reshape(trainX, (trainX.shape[0],1,trainX.shape[1]))\ntestX = np.reshape(testX,(testX.shape[0],1,testX.shape[1]))","50a828e0":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\n","b768c0d9":"model = Sequential()\nmodel.add(LSTM(10,input_shape=(1,time_stemp))) #10LSTM neuron(block)\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error',optimizer='adam')\nmodel.fit(trainX,trainY,epochs = 50, batch_size = 1)","8458fa42":"train_predict = model.predict(trainX)\ntest_predict = model.predict(testX)\ntrain_predict = scaler.inverse_transform(train_predict)\ntrainY = scaler.inverse_transform([trainY])\ntest_predict = scaler.inverse_transform(test_predict)\ntestY= scaler.inverse_transform([testY])\ntrain_score = math.sqrt(mean_squared_error(trainY[0],train_predict[:,0]))\nprint('Train Score %.2f RMSE' %(train_score))\ntest_score = math.sqrt(mean_squared_error(testY[0],test_predict[:,0]))\nprint('Test Score %.2f RMSE' %(test_score))","6c2d914e":"train_predict_plot = np.empty_like(dataset)\ntrain_predict_plot[:,:] = np.nan\ntrain_predict_plot[time_stemp:len(train_predict) +time_stemp,:]=train_predict\ntest_predict_plot = np.empty_like(dataset)\ntest_predict_plot[:,:] = np.nan\ntest_predict_plot[len(train_predict)+(time_stemp*2)+1:len(dataset) -1,:] = test_predict\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(train_predict_plot)\nplt.plot(test_predict_plot)\nplt.show()\n","0084d342":"* **Model**","2b6f402e":"* **Reshape and Change Type**","2641ce51":"# Implementing RNN(Recurrent Neural Network with LSTM) with Keras\n","5ee78e34":"* **Needed Libraries**","54ad0dfe":"# Implementing LSTM Model","3c81103b":"# Preprocessing Data","e5a98170":"* **Create Dataset**","5f49f025":"# Loading and Visualizing Dataset","9170c6a0":"* **Scalling and Spliting Test-Train Dataset**","18bd77fa":"* **Needed Libraries**","07aefaf1":"# Predictions and Visualising RNN Model","84dc8a84":"* > In this part, data is preprocessed with different processes.\n* > I follow this order in preprocessing part :\n* 1. reshape\n* 2. change type\n* 3. scalling\n* 4. spliting train-test dataset\n* 5. create dataset"}}