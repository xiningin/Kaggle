{"cell_type":{"8604dac3":"code","b551f4d2":"code","cacb33cc":"code","c7de9ad3":"code","3ccda586":"code","212342e6":"code","8c98b4cb":"code","3394f63e":"code","b1a90379":"code","de439f11":"code","3e377bf3":"code","c8178fc2":"markdown","2a1738c2":"markdown","f30aa48d":"markdown","6595ec80":"markdown","ebfef83e":"markdown","ba4f0c16":"markdown","985717e5":"markdown","d242d118":"markdown","097a4404":"markdown"},"source":{"8604dac3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b551f4d2":"import numpy as np\ntime=1\nemr=100\nstego_method=\"xiao\"\ncover_file='..\/input\/amr-steg\/AMRNB_%ds_0_%s.npy'%(time,stego_method)\nstego_file='..\/input\/amr-steg\/AMRNB_%ds_%d_%s.npy'%(time,emr,stego_method)\ncover_data = np.array(np.load(cover_file), dtype='float')\nstego_data = np.array(np.load(stego_file), dtype='float')\nnp.random.shuffle(stego_data)\nnp.random.shuffle(cover_data)\nprint(stego_data.shape,cover_data.shape)","cacb33cc":"stego_data = stego_data[:,:,:5]\ncover_data = cover_data[:,:,:5]\nprint(stego_data.shape,cover_data.shape)","c7de9ad3":"ts=0.25 # \u5206\u5272\u6bd4\u4f8b\nts_num = int(len(stego_data) * float(ts))\nx_train = np.vstack((stego_data[ts_num:], cover_data[ts_num:]))\nx_test = np.vstack((stego_data[:ts_num], cover_data[:ts_num]))\ninput_dim = 5","3ccda586":"def shuffle(x, y):\n    datasets = list(zip(x, y))\n    np.random.shuffle(datasets)\n    x, y = zip(*datasets)\n    x, y = np.array(x), np.array(y)\n    return x, y","212342e6":"from keras.utils import np_utils\ny_test = np.hstack((np.ones(ts_num), np.zeros(ts_num)))\ny_train = np.hstack((np.ones((len(stego_data) - ts_num)), np.zeros((len(stego_data) - ts_num))))\nx_train, y_train = shuffle(x_train, y_train)\nx_test, y_test = shuffle(x_test, y_test)\ny_test = np_utils.to_categorical(y_test, num_classes=2)\ny_train = np_utils.to_categorical(y_train, num_classes=2)\nprint(y_train)\nprint(y_test)","8c98b4cb":"from keras.layers import Reshape, Dense, Dropout, LSTM, Bidirectional, AveragePooling1D, Flatten, Input, MaxPooling1D, Convolution1D, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, \\\n    BatchNormalization, Activation, GlobalAveragePooling2D\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Embedding, Dense, Flatten, Input","3394f63e":"input = Input(shape=(int(time * 50), input_dim))\nr1 = (LSTM(50, return_sequences=True))(input)\nr2 = LSTM(50, return_sequences=True)(r1)\nr_fla = Flatten()(r2)\noutput = Dense(2, activation=\"sigmoid\")(r_fla)\nmodel = Model(inputs=input, outputs=output)\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","b1a90379":"from keras.callbacks import EarlyStopping, ModelCheckpoint\n#mc = ModelCheckpoint('best_model.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nhistory=model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test,y_test))","de439f11":"from matplotlib import pyplot \npyplot.plot(history.history['accuracy'], label='train') \npyplot.plot(history.history['val_accuracy'], label='test') \npyplot.legend()\npyplot.show()","3e377bf3":"from sklearn.metrics import accuracy_score, confusion_matrix\nimport time\nstart_time=time.time()\ny_pred = np.argmax(model.predict(x_test), axis=1)\nend_time=time.time()\nprint(\"test_samples=\",len(x_test),\"test_time=\",start_time-end_time)\ny_test = np.argmax(y_test, axis=1)\naccuracy = accuracy_score(y_test, y_pred)\ntn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\nfpr = fp \/ (fp + tn)\nfnr = fn \/ (fn + tp)\nprint('test_acc={:.4f},fpr={:.4f},fnr={:.4f},tn={},fp={},fn={},tp={}'.format(accuracy, fpr, fnr, tn, fp, fn, tp))","c8178fc2":"@author: wu-junyan\n\n@file: keras-rnnsm\n\n@time: 2021\/2\/27 13:55\n\n@desc:","2a1738c2":"# Train","f30aa48d":"# Build Train\/Test Dataset","6595ec80":"# Select Coding Elements\n- xiao: [:, :, :5]\n- geiser: [:, :, 5:25]\n- huang: [:, :, 25:]","ebfef83e":"## Split","ba4f0c16":"## Shuffle","985717e5":"# Test","d242d118":"# Loading Dataset","097a4404":"# Build Model: RNN-SM"}}