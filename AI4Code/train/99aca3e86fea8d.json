{"cell_type":{"4cc6eb44":"code","128ca8ff":"code","5304a69f":"code","0b56d0a9":"code","e46f9d07":"code","2c900341":"code","370240a6":"code","c1d03b98":"code","dfdba8ff":"code","6a9cf3e5":"code","906600e3":"code","899220c9":"code","37481dfe":"code","b3454bfe":"code","a8dcf031":"code","fb90d280":"code","5e364f54":"code","f1572a73":"code","9714c36c":"code","7e94e51a":"code","390b8c48":"code","a0790d2a":"code","c551984b":"code","d6d8f13b":"code","b4e0fabd":"code","acf9a594":"code","c554ceb8":"code","49b26cd6":"code","7c94f7f6":"code","0d4379e6":"code","f6171a0c":"code","6e6cc777":"code","c661b5e4":"code","d7352e55":"code","40cd5976":"code","a116bdd3":"code","b679d62d":"markdown","bda630a0":"markdown"},"source":{"4cc6eb44":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport cv2\n# set the matplotlib backend so figures can be saved in the background\nimport matplotlib .pyplot as plt\n# import the necessary packages\nfrom sklearn import svm\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense\nfrom keras.optimizers import SGD\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras import backend as K\nfrom keras.utils import to_categorical\nfrom keras.models import model_from_json\nimport random\n\n# Any results you write to the current directory are saved as output.","128ca8ff":"data = []\nlabels = []\n\nfor paths, dirs,files in os.walk('..\/input\/owncollection'):\n    imagesPath = sorted([images for images in files])\n    #print(imagesPath)\n    #print(paths)\n    for imagePath in imagesPath:\n        image = cv2.imread('..\/input\/owncollection\/OwnCollection\/' + paths.split('\/')[4] + '\/' + paths.split('\/')[5] + '\/' + imagePath)\n        image = cv2.resize(image, (64,64)).flatten()\n        data.append(image)\n        labels.append(paths.split('\/')[4])\n\nprint(len(data))\nprint(len(labels))","5304a69f":"data = np.array(data, dtype='float32') \/ 255.0\nlabels = np.array(labels)","0b56d0a9":"data.shape","e46f9d07":"labels.shape","2c900341":"data[:100]","370240a6":"# partition the data into training and testing splits using 75% of\n# the data for training and the remaining 25% for testing\n(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.25, random_state=42)","c1d03b98":"trainY.shape","dfdba8ff":"testY.shape","6a9cf3e5":"lb = LabelBinarizer()\ntrainY = lb.fit_transform(trainY)\ntestY = lb.transform(testY)","906600e3":"trainY","899220c9":"print(trainY.shape)\nprint(testY.shape)","37481dfe":"clf = svm.SVC(kernel='rbf', gamma = 'auto',random_state=0)\nclf.fit(trainX, trainY)","b3454bfe":"image = cv2.imread('..\/input\/owncollection\/OwnCollection\/vehicles\/Right\/image0001.png')\nimage = cv2.resize(image, (64,64)).flatten()\nimage = image.astype('float') \/ 255\nimage = image.reshape((1, image.shape[0]))\nimage.shape","a8dcf031":"preds = clf.predict(image)\nprint(preds)\nlabel = lb.classes_[preds]\nprint(label)","fb90d280":"y_pred = clf.predict(testX)","5e364f54":"y_pred.shape","f1572a73":"y_pred[:10]","9714c36c":"cm = confusion_matrix(testY, y_pred)\nprint(cm)","7e94e51a":"score = accuracy_score(testY, y_pred)","390b8c48":"score","a0790d2a":"class SmallVGGNet:\n    @staticmethod\n    def build(width, height, depth, classes):\n        # initialize the model along with the input shape to be\n        # \"channels last\" and the channels dimension itself\n        model = Sequential()\n        inputShape = (height, width, depth)\n        chanDim = -1\n        \n        # If the we are using 'channels first', then we need to update the input shape\n        # and channels dimentions\n        if K.image_data_format() == 'channels_first':\n            inputShape = (depth, height, width)\n            chanDim = 1\n            \n        model.add(Conv2D(32, (3,3), padding = 'same' ,input_shape = inputShape))\n        model.add(Activation('relu'))\n        ## To normalize the data along the channel dimention, to reduce training time and stabilize\n        ## the network.\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(Dropout(0.25))\n        \n        # (CONV => RELU) * 2 => POOL layer set\n        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(Dropout(0.25))\n        \n        # (CONV => RELU) * 3 => POOL layer set\n        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(Dropout(0.25))\n        \n        # first (and only) set of FC => RELU layers\n        model.add(Flatten())\n        model.add(Dense(512))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n\n        # softmax classifier\n        model.add(Dense(classes))\n        model.add(Activation(\"softmax\"))\n\n        # return the constructed network architecture\n        return model","c551984b":"data = []\nlabels = []\n\nfor paths, dirs,files in os.walk('..\/input\/owncollection'):\n    imagesPath = sorted([images for images in files])\n    #print(imagesPath)\n    #print(paths)\n    for imagePath in imagesPath:\n        image = cv2.imread('..\/input\/owncollection\/OwnCollection\/' + paths.split('\/')[4] + '\/' + paths.split('\/')[5] + '\/' + imagePath)\n        image = cv2.resize(image, (64,64))\n        data.append(image)\n        labels.append(paths.split('\/')[4])\n\nprint(len(data))\nprint(len(labels))\n\n","d6d8f13b":"data[:3]","b4e0fabd":"data = np.array(data, dtype='float32') \/ 255.0\n# since the pixel intensities lies from 0 to 255, thus we normalized the data to 0 to 1\nlabels = np.array(labels)\nprint(data.shape)\nprint(labels.shape)","acf9a594":"# partition the data into training and testing splits using 75% of\n# the data for training and the remaining 25% for testing\n(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.25, random_state=42)","c554ceb8":"## Here We are just doing the one-hot encoding for the labels.\nlabelencoder_y_1 = LabelEncoder()\ntrainY = labelencoder_y_1.fit_transform(trainY)\ntestY = labelencoder_y_1.transform(testY)","49b26cd6":"print(trainY.shape, testY.shape)\n# construct the image generator for data augmentation\n# construct the image generator for data augmentation\naug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n                        height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n                        horizontal_flip=True, fill_mode=\"nearest\")\n \n\"\"\"\nImage augmentation allows us to construct \u201cadditional\u201d training data from our existing training data by randomly rotating, shifting, shearing, zooming, and flipping.\n\nData augmentation is often a critical step to:\n\n1) Avoiding overfitting\n2) Ensuring your model generalizes well\n\"\"\"\n    \n# initialize our VGG-like Convolutional Neural Network\nmodel = SmallVGGNet.build(width=64, height=64, depth=3,classes=len(labelencoder_y_1.classes_))","7c94f7f6":"# initialize our initial learning rate, # of epochs to train for,\n# and batch size\nINIT_LR = 0.01\nEPOCHS = 100\nBS = 32\n# initialize the model and optimizer \nprint(\"[INFO] training network...\")\nopt = SGD(lr=INIT_LR, decay=INIT_LR \/ EPOCHS)\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n\n# train the network\nh = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n                                validation_data=(testX, testY), \n                                steps_per_epoch=len(trainX) \/\/ BS,\n                                epochs=EPOCHS)","0d4379e6":"# evaluate the network\nprint(\"[INFO] evaluating network...\")\npredictions = model.predict(testX, batch_size=32)\nprint(classification_report(testY,\n                            predictions.argmax(axis=1), target_names=labelencoder_y_1.classes_))\n \n# plot the training loss and accuracy\nN = np.arange(0, EPOCHS)\nplt.figure()\nplt.plot(N, h.history[\"loss\"], label=\"train_loss\")\nplt.plot(N, h.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(N, h.history[\"acc\"], label=\"train_acc\")\nplt.plot(N, h.history[\"val_acc\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy (SmallVGGNet)\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend()","f6171a0c":"image = cv2.imread('..\/input\/owncollection\/OwnCollection\/non-vehicles\/Far\/image0000.png')\nimage = cv2.resize(image, (64,64))\nimage = image.astype('float') \/ 255.0\nimage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\nimage.shape","6e6cc777":"preds = model.predict(image)\ni = preds.argmax(axis=1)[0]\nlabel = labelencoder_y_1.classes_[i]\nprint(preds, label)","c661b5e4":"image = cv2.imread('..\/input\/owncollection\/OwnCollection\/vehicles\/Far\/image0000.png')\nimage = cv2.resize(image, (64,64))\nimage = image.astype('float') \/ 255.0\nimage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\nimage.shape","d7352e55":"preds = model.predict(image)\ni = preds.argmax(axis=1)[0]\nlabel = labelencoder_y_1.classes_[i]\nprint(preds, label)","40cd5976":"# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")\n ","a116bdd3":"# load json and create model\njson_file = open('model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model.load_weights(\"model.h5\")\nprint(\"Loaded model from disk\")\n ","b679d62d":"## So , as seen, we get a whopping 90% score on the model , which is pretty descent for a classifier\n\n---\n\n## Now , I'll be using a CNN for the same task, which is my simple version of the VGG - CNN architechture .","bda630a0":"## First making a SVM classifier to predict the classes, since the SVM classifiers generally do better with HOG features, and since I am making this model to for detection of cars in a video, I will be making use of a kernel SVM."}}