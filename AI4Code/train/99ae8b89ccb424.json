{"cell_type":{"0390b47e":"code","4f0634ca":"code","382e32e1":"code","40f6de5c":"code","e79c7a25":"code","52346d6c":"code","7366dcf1":"code","88c01277":"code","66c518ad":"code","c48ac793":"code","6bfde765":"markdown","d6510439":"markdown"},"source":{"0390b47e":"import os \nimport tensorflow as tf \nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n","4f0634ca":"print (os.getcwd())\ntrain,test,valid = os.listdir(\".\/\")\ntest,train,valid\n\n","382e32e1":"os.chdir('.\/train')\ntrain_man, train_woman=os.listdir('.\/')\ntrain_man, train_woman","40f6de5c":"#Getting the names of the files\n\ntrain_man_names = os.listdir(train_man)\nprint(train_man_names[:10])\n\n\ntrain_woman_names = os.listdir(train_woman)\nprint(train_man_names[:10])\n\n","e79c7a25":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# Parameters for our graph; we'll output images in a 4x4 configuration\nnrows = 4\nncols = 4\n\n# Index for iterating over images\npic_index = 0\n\n#Now, display a batch of 8 man and 8 woman pictures. You can rerun the cell to see a fresh batch each time:\n# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols * 4, nrows * 4)\n\npic_index += 8\nnext_man_pix = [os.path.join(train_man, fname) \n                for fname in train_man_names[pic_index-8:pic_index]]\nnext_woman_pix = [os.path.join(train_woman, fname) \n                for fname in train_woman_names[pic_index-8:pic_index]]\n\nfor i, img_path in enumerate(next_man_pix+next_woman_pix):\n  # Set up subplot; subplot indices start at 1\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off') # Don't show axes (or gridlines)\n\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n\nplt.show()\n","52346d6c":"import tensorflow as tf\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])","7366dcf1":"os.chdir('..\/') \nprint(os.listdir())\n","88c01277":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# All images will be rescaled by 1.\/255\ntrain_datagen = ImageDataGenerator(rescale=1\/255)\nvalidation_datagen = ImageDataGenerator(rescale=1\/255)\n\n# Flow training images in batches of 128 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        '.\/train',  # This is the source directory for training images \n        target_size=(150, 150),  # All images will be resized to 150x150\n        batch_size=128,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\n# Flow training images in batches of 128 using train_datagen generator\nvalidation_generator = validation_datagen.flow_from_directory(\n        '.\/valid',  # This is the source directory for validation images\n        target_size=(150, 150),  # All images will be resized to 150x150\n        batch_size=32,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\n\n\n\n","66c518ad":"history = model.fit(\n      train_generator,\n      steps_per_epoch=8,  \n      epochs=20,\n      verbose=1,\n      validation_data = validation_generator,\n      validation_steps=8)","c48ac793":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'g', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'g', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","6bfde765":"# Data Preprossecing and Generators","d6510439":"# Training"}}