{"cell_type":{"031927f2":"code","964a30da":"code","cf544d2a":"code","0d842041":"code","a1a88242":"code","85a32513":"code","5edb0873":"code","da2401f4":"code","daf13801":"code","a8c1cdf4":"code","325d1d15":"code","d53148ee":"code","bf99034f":"code","b0059eab":"code","e84f2865":"code","fe2c8aa4":"code","2cf42d06":"code","a7148b40":"code","f98039b8":"code","69341977":"code","ed8e6938":"markdown","d933297b":"markdown","a80648dc":"markdown","7a300820":"markdown","4704783c":"markdown","730556d8":"markdown"},"source":{"031927f2":"!pip install efficientnet_pytorch","964a30da":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport torch\nfrom torchvision import models\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn, optim\nfrom efficientnet_pytorch import EfficientNet\n\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm","cf544d2a":"train_path = '..\/input\/pokemonimagedataset\/dataset\/train\/'\ntest_path = '..\/input\/pokemonimagedataset\/dataset\/test\/'","0d842041":"def get_img_path(path):\n    img_path = []\n    for p in Path(train_path).glob('*\/*'):\n        img_path.append(p)\n        \n    return img_path","a1a88242":"def encode_target(path):\n    target = []\n    for p in Path(train_path).glob('*'):\n        if p.stem == 'NidoranF':\n          target.append(p.stem[:-1])\n        else:\n          target.append(p.stem)\n    \n    return target","85a32513":"class LoadData(Dataset):\n    def __init__(self, img_path, target, transform=None):\n        self.img_path = img_path\n        self.target = target\n        self.transform = transform\n        \n    def __len__(self): return len(img_path)\n    \n    def __getitem__(self, idx):\n        img = Image.open(self.img_path[idx]).convert('RGB')\n        target = self.target.index(Path(self.img_path[idx]).stem.split('.')[0])\n        \n        if self.transform:\n            img = self.transform(img)\n            \n            return img, target\n        else:\n            return img, target","5edb0873":"transform = transforms.Compose([\n    transforms.Resize((100, 100)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5),\n                          (0.5, 0.5, 0.5))\n])\n\nimg_path = get_img_path(train_path)\ntarget = encode_target(train_path)\n\nval_img_path = get_img_path(test_path)\nval_target = encode_target(test_path)","da2401f4":"ds = LoadData(img_path, target, transform=transform)\nds_val = LoadData(val_img_path, val_target, transform=transform)","daf13801":"for i, (x, y) in enumerate(ds):\n    print(x.shape, y, '------ training set')\n    if i ==6:\n      break\n    \nfor j, (q, w) in enumerate(ds_val):\n    print(q.shape, w, '------ valid set')\n    if j ==6:\n      break","a8c1cdf4":"bs = 16\n\ntrainloader = DataLoader(ds, batch_size=bs, shuffle=True)\ntestloader = DataLoader(ds_val, batch_size=bs, shuffle=True)","325d1d15":"for i, (x, y) in enumerate(trainloader):\n    print(x.shape, y.shape, '------ training set')\n    if i ==8:\n      break\n    \nfor j, (q, w) in enumerate(testloader):\n    print(q.shape, w.shape, '------ valid set')\n    if j ==8:\n      break","d53148ee":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = EfficientNet.from_pretrained(\"efficientnet-b2\")","bf99034f":"for param in model.parameters():\n    param.requires_grad = False\n    \nmodel._fc = nn.Linear(1408, len(target))\n\nfor param in model.parameters():\n    if param.requires_grad == True:\n        print(param.shape)","b0059eab":"model = model.to(device)","e84f2865":"opt = optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\nscheduler = optim.lr_scheduler.CyclicLR(opt, base_lr=1e-3, max_lr=0.01, cycle_momentum=False)","fe2c8aa4":"def validate(dataloader):\n  model.eval()\n  total, correct = 0, 0\n  for data in tqdm(dataloader, total=len(dataloader), leave=False):\n    inputs, labels = data\n    inputs, labels = inputs.to(device), labels.to(device)\n    outputs = model(inputs)\n    _, pred = torch.max(outputs, 1)\n\n    total += labels.size(0)\n    correct += (pred == labels).sum().item()\n\n  return criterion(outputs, labels), (correct\/total * 100)","2cf42d06":"epochs = 3\n\nfor epoch in range(epochs):\n    model.train()\n    for data, label in tqdm(trainloader, total=len(trainloader), leave=False):      \n        opt.zero_grad()\n        \n        out = model(data.to(device))\n        loss = criterion(out, label.to(device))\n        loss.backward()\n        \n        opt.step()\n        scheduler.step()\n    \n    validation = validate(testloader)\n    \n    print(f\"Epoch: {epoch+1}\/{epochs}\\ttrain_loss: {loss.item()}\\tval_loss: {validation[0].item()}\\tval_acc: {validation[1]}\")","a7148b40":"for params in model.parameters():\n    params.requires_grad = True","f98039b8":"opt1 = optim.Adam(model.parameters(), lr=1e-3)","69341977":"epochs = 20\nacc = 0.0\n\nfor epoch in range(epochs):\n    model.train()\n    for data, label in tqdm(trainloader, total=len(trainloader), leave=False):      \n        opt1.zero_grad()\n        \n        out = model(data.to(device))\n        loss = criterion(out, label.to(device))\n        loss.backward()\n        \n        opt1.step()\n    \n    validation = validate(testloader)\n    \n    if validation[1]>acc:\n        acc = validation[1]\n        torch.save(model.state_dict(), f'.\/model-{round(validation[1], 4)}.pt')\n    \n    print(f\"Epoch: {epoch+1}\/{epochs}\\ttrain_loss: {loss.item()}\\tval_loss: {validation[0].item()}\\tval_acc: {validation[1]}\")","ed8e6938":"## Train the freezed model","d933297b":"## Freeze the model","a80648dc":"## Train the unfreezed model","7a300820":"## Efficientnet","4704783c":"## Unfreeze the model","730556d8":"## End of model building"}}