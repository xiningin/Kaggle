{"cell_type":{"628c2bfd":"code","d7eed699":"code","ff5f53ac":"code","a851ef2e":"code","4b0f74e7":"code","99a79626":"code","0c8f92db":"code","82a8f9c2":"code","4d73c699":"code","ac41d257":"code","91484ac4":"markdown","24175240":"markdown","9cc1c561":"markdown","c928acde":"markdown","23df332e":"markdown","b573d04b":"markdown","2134b19d":"markdown","10a0afb6":"markdown","9d213916":"markdown"},"source":{"628c2bfd":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nimport numpy as np\nimport pandas as pd\n\ndata = pd.read_csv(\"..\/input\/netflix-shows-exploratory-analysis\/netflix_titles.csv\")","d7eed699":"vectorizer = TfidfVectorizer(stop_words='english')\nX = vectorizer.fit_transform(list(data.description))","ff5f53ac":"terms = vectorizer.get_feature_names()","a851ef2e":"from sklearn.metrics.pairwise import cosine_similarity\ndist = 1 - cosine_similarity(X[:100])","4b0f74e7":"true_k = 5\nmodel = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\nmodel.fit(X)\nclusters = model.labels_.tolist()\norder_centroids = model.cluster_centers_.argsort()[:, ::-1]","99a79626":"netflix = { 'title': list(data.title)[:100], 'type_show': list(data.type)[:100], 'description': list(data.description)[:100], 'cluster': clusters[:100] }\nframe = pd.DataFrame(netflix, index = [clusters[:100]] , columns = ['title', 'type_show', 'description', 'cluster'])","0c8f92db":"from __future__ import print_function\n\nprint(\"Top terms per cluster:\")\nprint()\n\nfor i in range(true_k):\n    print(\"Cluster %d:\" % i)\n    for ind in order_centroids[i, :5]:\n        print(terms[ind])\n    print() #add whitespace\n    print() #add whitespace\n    \n    print(\"Cluster %d titles:\" % i, end='')\n    for title in frame.loc[[i]]['title']:\n        print(' %s,' % title, end='')\n    print() #add whitespace\n    print() #add whitespace\n\n\nprint()\nprint()","82a8f9c2":"import os  # for os.path.basename\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\nfrom sklearn.manifold import MDS\n\nMDS()\n\n# convert two components as we're plotting points in a two-dimensional plane\n# \"precomputed\" because we provide a distance matrix\n# we will also specify `random_state` so the plot is reproducible.\nmds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n\npos = mds.fit_transform(dist)  # shape (n_components, n_samples)\nxs, ys = pos[:, 0], pos[:, 1]","4d73c699":"cluster_colors = {0: '#1b9e77', 1: '#d95f02', 2: '#7570b3', 3: '#e7298a', 4: '#45b6fe'}\n\ncluster_names = {0: 'New, life, family, world, friends', \n                 1: 'Save, fight, american, future, brothers', \n                 2: 'Drama, stories, set, writer, single', \n                 3: 'Yound, man, women, life, father', \n                 4: 'Documentary, follows, explores, series, world'}","ac41d257":"#some ipython magic to show the matplotlib plots inline\n%matplotlib inline \n\n#create data frame that has the result of the MDS plus the cluster numbers and titles\ndf = pd.DataFrame(dict(x=xs, y=ys, label=clusters[:100], title=list(data.title)[:100])) \n\n#group by cluster\ngroups = df.groupby('label')\n\n\n# set up plot\nfig, ax = plt.subplots(figsize=(17, 9)) # set size\nax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n\n#iterate through groups to layer the plot\n#note that I use the cluster_name and cluster_color dicts with the 'name' lookup to return the appropriate color\/label\nfor name, group in groups:\n    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, \n            label=cluster_names[name], color=cluster_colors[name], \n            mec='none')\n    ax.set_aspect('auto')\n    ax.tick_params(\\\n        axis= 'x',          # changes apply to the x-axis\n        which='both',      # both major and minor ticks are affected\n        bottom='off',      # ticks along the bottom edge are off\n        top='off',         # ticks along the top edge are off\n        labelbottom='off')\n    ax.tick_params(\\\n        axis= 'y',         # changes apply to the y-axis\n        which='both',      # both major and minor ticks are affected\n        left='off',      # ticks along the bottom edge are off\n        top='off',         # ticks along the top edge are off\n        labelleft='off')\n    \nax.legend(numpoints=1)  #show legend with only 1 point\n\n#add label in x,y position with the label as the film title\nfor i in range(len(df)):\n    ax.text(df.iloc[i]['x'], df.iloc[i]['y'], df.iloc[i]['title'], size=8)  \n\n    \n    \nplt.show() #show the plot\n\n#uncomment the below to save the plot if need be\n#plt.savefig('clusters_small_noaxes.png', dpi=200)","91484ac4":"Membuat dataframe yang terdiri dari title, type_show, description dan cluster. Hanya dibatasi 200 data.","24175240":"**Tf-idf and document similarity**\n\nKemudian mendefinisikan tf-idf vectorizer parameter dan meng-convert description menjadi matrix tf-idf. Vectorizer menggunakan stopwords untuk menghilangkan kata seperti 'a' atau 'the'.","9cc1c561":"**K-means clustering**\n\nDengan menggunakan matrix tf-idf, dapat dilakukan algoritma pengelompokkan untuk lebih memahami struktur tersembunyi di dalam description.","c928acde":"Import library dan load data yang akan dibutuhkan.","23df332e":"**Multidimensional scaling**\n\nMengubah matrix dist menjadi 2-dimensi array.","b573d04b":"**Visualizing document clusters**\n\nMemvisualisasikan output document cluster menggunakan matplotlib.","2134b19d":"dist didefinisikan sebagai 1 - persamaan cosinus dari setiap dokumen. Kesamaan cosine diukur terhadap matriks tf-idf dan dapat digunakan untuk menghasilkan ukuran kesamaan antara setiap dokumen dan dokumen lainnya dalam korpus (setiap description di antara description). Mengurangkannya dari 1 memberikan jarak kosinus yang akan saya gunakan untuk memplot pada bidang euclidean (2-dimensi).","10a0afb6":"Terms adalah vocabulary.","9d213916":"Contoh data yang sudah ter-cluster."}}