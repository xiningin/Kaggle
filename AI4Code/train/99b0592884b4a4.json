{"cell_type":{"9edb7fb6":"code","3779c3b8":"code","cf660eb0":"code","552c3ac9":"code","2cf60cfb":"code","2c2ca281":"code","2fb2cf88":"code","b5aa752e":"code","38bc3d8c":"code","72abf8ef":"code","87f2abf4":"code","b5371678":"code","74ae66c2":"code","c7a3a5f1":"markdown","f615a84d":"markdown","1c5bd5a4":"markdown","c2570850":"markdown","b5cb682d":"markdown","3d668f25":"markdown","73bc2483":"markdown"},"source":{"9edb7fb6":"#%% import\nimport os\nfrom glob import glob\nimport re\nimport ast\nimport numpy as np \nimport pandas as pd\nfrom PIL import Image, ImageDraw \nfrom tqdm import tqdm\nfrom dask import bag\nimport time\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.metrics import top_k_categorical_accuracy\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom keras.models import load_model","3779c3b8":"#%% set label dictionary and params\nclassfiles = os.listdir('..\/input\/train_simplified\/')\nnumstonames = {i: v[:-4].replace(\" \", \"_\") for i, v in enumerate(classfiles)} #adds underscores\n\nnum_classes = 340    #class \uac1c\uc218: 340\nimheight, imwidth = 64, 64  \nims_per_class = 100","cf660eb0":"# \uc810\ub4e4\uc744 \uc5f0\uacb0\ud558\uc5ec \uadf8\ub824\uc90c  \ndef draw_it(strokes):\n    image = Image.new(\"P\", (256,256), color=255) #\"P\": (8-bit pixels, mapped to any other mode using a color palette)\n    image_draw = ImageDraw.Draw(image)\n    for stroke in ast.literal_eval(strokes):\n        for i in range(len(stroke[0])-1):\n            image_draw.line([stroke[0][i], \n                             stroke[1][i],\n                             stroke[0][i+1], \n                             stroke[1][i+1]],\n                            fill=0, width=5)\n    image = image.resize((imheight, imwidth))\n    return np.array(image)\/255.\n\n","552c3ac9":"def data_load(ims_ind_st):\n    #%% get train arrays\n    train_grand = []\n    class_paths = glob('..\/input\/train_simplified\/*.csv')\n    for i,c in enumerate(class_paths[0: num_classes]):#enumerate(tqdm(class_paths[0: num_classes])):\n        train = pd.read_csv(c, usecols=['drawing', 'recognized'])\n        train = train[train.recognized == True][ims_ind_st:ims_ind_st+ims_per_class]\n        imagebag = bag.from_sequence(train.drawing.values).map(draw_it) \n        trainarray = np.array(imagebag.compute())  # PARALLELIZE\n        trainarray = np.reshape(trainarray, (ims_per_class, -1))    \n        labelarray = np.full((train.shape[0], 1), i)\n        trainarray = np.concatenate((labelarray, trainarray), axis=1)\n        train_grand.append(trainarray)\n        del trainarray\n        del train\n        time.sleep(0.1)\n    train_grand = np.array([train_grand.pop() for i in np.arange(num_classes)]) #less memory than np.concatenate\n    train_grand = train_grand.reshape((-1, (imheight*imwidth+1)))\n    return train_grand","2cf60cfb":"def train_val_split(train_grand):\n    # memory-friendly alternative to train_test_split?\n    valfrac = 0.05\n    cutpt = int(valfrac * train_grand.shape[0])\n    # shuffle \ud6c4 train data\/ validation data \ub098\ub220\uc90c \n    np.random.shuffle(train_grand)\n    y_train, X_train = train_grand[cutpt: , 0], train_grand[cutpt: , 1:]\n    y_val, X_val = train_grand[0:cutpt, 0], train_grand[0:cutpt, 1:] #validation set is recognized==True\n    del train_grand\n\n    y_train = keras.utils.to_categorical(y_train, num_classes)\n    X_train = X_train.reshape(X_train.shape[0], imheight, imwidth, 1)\n    y_val = keras.utils.to_categorical(y_val, num_classes)\n    X_val = X_val.reshape(X_val.shape[0], imheight, imwidth, 1)\n\n    print(y_train.shape, \"\\n\",\n          X_train.shape, \"\\n\",\n          y_val.shape, \"\\n\",\n          X_val.shape)\n    \n    return X_train, y_train, X_val, y_val","2c2ca281":"model = Sequential()\nmodel.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(imheight, imwidth, 1)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.summary()","2fb2cf88":"X_train,y_train,X_val,y_val = train_val_split(data_load(0))","b5aa752e":"def top_3_accuracy(x,y): \n    t3 = top_k_categorical_accuracy(x,y, 3)\n    return t3","38bc3d8c":"reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, \n                                   verbose=1, mode='auto', min_delta=0.005, cooldown=5, min_lr=0.0001)\nearlystop = EarlyStopping(monitor='val_top_3_accuracy', mode='max', patience=5) \ncallbacks = [reduceLROnPlat, earlystop]","72abf8ef":"model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy', top_3_accuracy])\n\nmodel.fit(x=X_train, y=y_train,\n          batch_size = 512,\n          epochs = 10,\n          validation_data = (X_val, y_val),\n          callbacks = callbacks,\n          verbose = 1)","87f2abf4":"for i in range(1, 10):\n    time.sleep(3)\n    X_train,y_train,X_val,y_val = train_val_split(data_load(i*ims_per_class))\n    \n    model.fit(x=X_train, y=y_train,\n          batch_size = 512,\n          epochs = 10,\n          validation_data = (X_val, y_val),\n          callbacks = callbacks,\n          verbose = 1)\n    \n    del X_train,y_train,X_val,y_val","b5371678":"#%% get test set\nttvlist = []\nreader = pd.read_csv('..\/input\/test_simplified.csv', index_col=['key_id'],\n    chunksize=2048)\nfor chunk in tqdm(reader, total=55):\n    imagebag = bag.from_sequence(chunk.drawing.values).map(draw_it) # \uc810 \uc5f0\uacb0 \n    testarray = np.array(imagebag.compute())\n    testarray = np.reshape(testarray, (testarray.shape[0], imheight, imwidth, 1))\n    testpreds = model.predict(testarray, verbose=0) #\ud559\uc2b5\ub41c \ubaa8\ub378\uc5d0 \uc801\uc6a9 \n    ttvs = np.argsort(-testpreds)[:, 0:3]  # top 3\n    ttvlist.append(ttvs)\n    \nttvarray = np.concatenate(ttvlist)","74ae66c2":"preds_df = pd.DataFrame({'first': ttvarray[:,0], 'second': ttvarray[:,1], 'third': ttvarray[:,2]})\npreds_df = preds_df.replace(numstonames)\npreds_df['words'] = preds_df['first'] + \" \" + preds_df['second'] + \" \" + preds_df['third']\n\nsub = pd.read_csv('..\/input\/sample_submission.csv', index_col=['key_id'])\nsub['word'] = preds_df.words.values\nsub.to_csv('cnn_3.csv')\nsub.head()","c7a3a5f1":"### hyperparameter","f615a84d":"#### data preprocessing","1c5bd5a4":"## Predicting on the Test data\nThe CNN does OK on the validation data, even with a basic model and limited training data. Let's generate predictions on the test set and submit.","c2570850":" A full version with 6000 images per class at 28x28 gets just under 0.60 on the public LB.  ","b5cb682d":"https:\/\/www.kaggle.com\/jpmiller\/image-based-cnn \ucc38\uace0\ud568.","3d668f25":"## Convolutional Neural Network (CNN)","73bc2483":"**data loading**"}}