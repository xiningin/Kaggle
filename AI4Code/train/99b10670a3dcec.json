{"cell_type":{"76b5e691":"code","372f18a8":"code","435b201f":"code","d7551f6f":"code","0991c6b4":"code","5204e06f":"code","79f0ac33":"code","d6445a17":"code","448e0417":"code","ab4d133c":"code","a9e0eccd":"code","1544cba3":"code","7ade497e":"code","e0753c25":"code","4eae21f7":"code","c0ec1be0":"code","96db9cf7":"code","d4d430fa":"code","a62eed58":"code","564379ea":"code","f05cfa15":"code","73ec1d4f":"code","305acdfe":"code","117937d5":"code","9d81db69":"code","2ff58872":"code","088e9564":"code","9e1e938f":"code","297ce0e6":"code","2f3aac87":"code","fcdd8be4":"code","ab0dd445":"code","50a53d5c":"code","59cc3cfa":"code","dfef4416":"code","7940a922":"code","cb22dff1":"code","d6a53f44":"code","ea376799":"code","76a3fca9":"code","f8f44246":"code","8abbe4c2":"code","2658533f":"code","18dbd4dc":"code","02af77e3":"code","c4bb5b80":"code","ddcc21e7":"code","9487e7f5":"markdown","66e59354":"markdown","bf5961aa":"markdown"},"source":{"76b5e691":"!pip uninstall fastai torch torchaudio fastcore torchvision -y ","372f18a8":"!pip install ..\/input\/packages\/packages\/packages\/colorednoise-1.1.1\/colorednoise-1.1.1 --find-links ..\/input\/packages\/packages --no-index --use-feature=2020-resolver","435b201f":"!pip install ..\/input\/packages\/fastaudio-0.0.post0.dev143gc7a2b85.dirty-py2.py3-none-any.whl --find-links ..\/input\/packages\/packages\/packages --no-index --verbose --upgrade --use-feature=2020-resolver","d7551f6f":"import fastaudio","0991c6b4":"import os\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.image as mpimg\nfrom matplotlib.offsetbox import AnnotationBbox, OffsetImage\n\n# Map 1 library\nimport plotly.express as px\n\n# Map 2 libraries\nimport descartes\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\n\n# Librosa Libraries\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\n\nimport sklearn\n\nimport warnings\nwarnings.filterwarnings('ignore')","5204e06f":"import soundfile as sf","79f0ac33":"#import ffmpy","d6445a17":"#new_path = Path(\"data\/train_audio_resample\")\n#old_path = Path(\"data\/train_audio\")","448e0417":"#new_path.mkdir()","ab4d133c":"#for subfolder in old_path.ls():\n#    Path(str(subfolder).replace(\"\/train_audio\/\", \"\/train_audio_resample\/\")).mkdir()","a9e0eccd":"#audio_files = get_files(old_path)","1544cba3":"#from fastprogress import progress_bar","7ade497e":"#for file in progress_bar(audio_files):\n#    new_file = Path(str(file).replace(\"\/train_audio\/\", \"\/train_audio_resample\/\").replace(\".mp3\", \".wav\"))\n#    new_file.parent.mkdir(exist_ok=True)\n#    ff = ffmpy.FFmpeg(inputs={str(file):None}, outputs={str(new_file): \"-ar 32000 -ac 1\"})\n#    ff.run()","e0753c25":"#resampled_audio_files = get_files(new_path)","4eae21f7":"#len(resampled_audio_files)","c0ec1be0":"#len(audio_files)","96db9cf7":"# Import data\ntrain_csv = pd.read_csv(\"..\/input\/birdsong-recognition\/train.csv\")\ntest_csv = pd.read_csv(\"..\/input\/birdsong-recognition\/test.csv\")\n\n# Create some time features\ntrain_csv['year'] = train_csv['date'].apply(lambda x: x.split('-')[0])\ntrain_csv['month'] = train_csv['date'].apply(lambda x: x.split('-')[1])\ntrain_csv['day_of_month'] = train_csv['date'].apply(lambda x: x.split('-')[2])\n\nprint(\"There are {:,} unique bird species in the dataset.\".format(len(train_csv['species'].unique())))","d4d430fa":"train_csv[\"file_path\"] = train_csv[[\"ebird_code\", \"filename\"]].agg(\"\/\".join, axis=1)\ntrain_csv[\"file_path\"] = train_csv[\"file_path\"]#.apply(lambda x: x.split(\".\")[0] + \".wav\")","a62eed58":"from fastai.vision.all import *\nfrom fastaudio.core.all import *\nfrom fastaudio.augment.all import *","564379ea":"cfg = AudioConfig.BasicMelSpectrogram(n_fft=512)\na2s = AudioToSpec.from_cfg(cfg)","f05cfa15":"path = Path(\"..\/input\/birdsong-recognition\")","73ec1d4f":"auds = DataBlock(blocks=(partial(AudioBlock, crop_signal_to=5000), MultiCategoryBlock),  \n                 get_x=ColReader(\"file_path\", pref=path\/\"train_audio\"), \n                 batch_tfms = [a2s],\n                 get_y=lambda x: [ColReader(\"ebird_code\")(x)])","305acdfe":"dbunch = auds.dataloaders(train_csv, bs=64)","117937d5":"x,y = dbunch.one_batch()","9d81db69":"x.shape","2ff58872":"dbunch.show_batch(figsize=(10, 5))","088e9564":"learn = cnn_learner(dbunch, \n            xresnet50, \n            config=cnn_config(n_in=1), #<- Only audio specific modification here\n            pretrained=True)","9e1e938f":"#learn.lr_find()","297ce0e6":"from fastai.callback.training import ShortEpochCallback","2f3aac87":"learn.fit_one_cycle(1, slice(1e-2), cbs=[ShortEpochCallback()])","fcdd8be4":"#learn.save(\"xresnet18-10epoch\") ","ab0dd445":"test_csv = pd.read_csv(\"..\/input\/birdcall-check\/test.csv\")","50a53d5c":"test_csv.head()","59cc3cfa":"out_dir = Path(\"test_audio_splitted\")\nout_dir.mkdir()","dfef4416":"row_ids_splitted = []\nfilenames_splitted = []\n\nfor audio_id in progress_bar(list(test_csv[\"audio_id\"].unique())):\n\n    audio, orig_sr = librosa.load(f\"..\/input\/birdcall-check\/test_audio\/{audio_id}.mp3\")\n    sr = 32_000\n    audio = librosa.resample(audio, orig_sr, sr)\n    duration = len(audio) \/ sr\n\n    segment_df = test_csv[test_csv[\"audio_id\"] == audio_id]\n    site = segment_df[\"site\"].iloc[0]\n    \n    \n    if (site == \"site_1\") or (site == \"site_2\"):\n        for row_id, end_second in zip(segment_df[\"row_id\"], segment_df[\"seconds\"]):\n            end_idx = math.floor(end_second * sr)\n            start_idx = math.floor(end_idx - (5 * sr))\n            audio_slice = audio[start_idx:end_idx]\n            filename = f\"{row_id}.wav\"\n            sf.write(out_dir\/f\"{filename}\", audio_slice, sr)\n            row_ids_splitted.append(row_id)\n            filenames_splitted.append(filename)\n\n    if site == \"site_3\":\n        row_id = segment_df[\"row_id\"].iloc[0]\n        end_second = 5\n        while end_second < duration:\n            end_idx = math.floor(end_second * sr)\n            start_idx = math.floor(end_idx - (5 * sr))\n            audio_slice = audio[start_idx:end_idx]\n            filename = f\"{row_id}_{end_second}.wav\"\n            sf.write(out_dir\/f\"{filename}\", audio_slice, sr)\n            row_ids_splitted.append(row_id)\n            filenames_splitted.append(filename)\n            end_second += 5\n\ntest_df_splitted = pd.DataFrame(data = {\"row_id\": row_ids_splitted, \"filename\": filenames_splitted})","7940a922":"test_df_splitted","cb22dff1":"test_datablock = DataBlock(blocks=(partial(AudioBlock, crop_signal_to=5000), MultiCategoryBlock),  \n                     get_x=ColReader(\"filename\", pref=out_dir), \n                     batch_tfms = [a2s],\n                     get_y=lambda x: [ColReader(\"row_id\")(x)])","d6a53f44":"fake_dls = test_datablock.dataloaders(test_df_splitted)","ea376799":"test_dl = fake_dls.test_dl(test_df_splitted)","76a3fca9":"sd = torch.load(\"..\/input\/birdstrainedmodels\/xresnet50-unfreeze-5.pth\")","f8f44246":"learn.model.load_state_dict(sd[\"model\"])","8abbe4c2":"preds = learn.get_preds(dl = test_dl, )","2658533f":"len(test_df_splitted)","18dbd4dc":"x= next(iter(test_dl))","02af77e3":"x[0]","c4bb5b80":"pred = learn.model(x[0])","ddcc21e7":"F.sigmoid(pred).max()","9487e7f5":"# inference code","66e59354":"### resample all audio files to 32 khz","bf5961aa":"## split files"}}