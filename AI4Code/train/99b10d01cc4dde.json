{"cell_type":{"02447599":"code","478df85b":"code","f052dd83":"code","8f2ae9eb":"code","ce57c42e":"code","2b85c114":"code","40a0709c":"code","a2646c23":"markdown","2de86199":"markdown","b415c488":"markdown","e0393b6d":"markdown","6c92f023":"markdown"},"source":{"02447599":"import numpy as np\nimport pandas as pd\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","478df85b":"def preprocess(df):\n    if 'Survived' in df.columns:\n        new_df = df.drop('Survived', 1)\n    else:\n        new_df = df.copy()\n    new_df = new_df.drop('Name', 1)\n    new_df = new_df.drop('Cabin', 1)\n    new_df = new_df.drop('PassengerId', 1)\n    ticket = new_df['Ticket']\n    new_df = new_df.drop('Ticket', 1)\n    # new_df['Ticket'] = list(map(len, ticket.values))\n    new_df['Embarked'] = new_df['Embarked'].astype('category').cat.codes\n    new_df['Sex'] = new_df['Sex'].astype('category').cat.codes\n    new_df = new_df.replace(np.nan, 0)\n    return new_df","f052dd83":"df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\n\ny_df = df['Survived']\ndf = preprocess(df)\nprint(df)","8f2ae9eb":"\nfrom sklearn.preprocessing import StandardScaler\n\n\nX = df.values\n\ny = y_df.values\nscaler = StandardScaler()\nscaler.fit(X)\nX = scaler.transform(X)\n# cv = fit_baseline(X, y)\n# print(cv.score(X_test, y_test))","ce57c42e":"import tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\ndef build_model():\n    model = Sequential()\n    model.add(Dense(72, input_shape=(7,), activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(48, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(16, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n# print(build_model().summary())\nmodel = KerasClassifier(build_fn=build_model, epochs=100, batch_size=10, verbose=0)\nkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nresults = cross_val_score(model, X, y, cv=kfold, verbose=1)\nprint(results)\nprint(results.mean())","2b85c114":"from sklearn.model_selection import cross_val_predict\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nID = test['PassengerId']\ntest = preprocess(test)\nmodel.fit(X, y)\npredictions = model.predict(scaler.transform(test.values))\ncleaned_predictions = np.array([prediction[0] for prediction in predictions])","40a0709c":"submission = pd.DataFrame({'PassengerId':ID, 'Survived':cleaned_predictions})\nprint(submission)\nsubmission.to_csv('submission.csv', index=False)","a2646c23":"Preprocess data.","2de86199":"Generate predictions on test data","b415c488":"Rescale data (significantly improves performance)","e0393b6d":"Build model and run crossvalidation","6c92f023":"Write predictions to output file"}}