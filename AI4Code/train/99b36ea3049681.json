{"cell_type":{"90139c57":"code","ffb2b730":"code","c4901fa7":"code","0d6d528f":"code","256fcc67":"code","d826e0b6":"code","f395971a":"code","ea2eb171":"code","4830ca9b":"code","bc1e63e5":"code","509089e4":"code","c4a876b7":"code","2a46ac41":"code","12d85cdc":"code","8afa45fc":"code","1b28cb6f":"code","ee6bb438":"code","959372c6":"code","08ac9ee3":"code","38ccf6b3":"code","5c235116":"code","bd435193":"code","d2f2e017":"code","22bad738":"code","164ea1b8":"code","1fae7462":"code","493f6a69":"code","9fba807a":"code","b3b07c7a":"code","ad3cf71a":"code","bb0734f6":"code","c356da59":"code","c6d37507":"code","704bb2f5":"code","597d567c":"code","1ba7a19a":"code","ed1b8208":"code","f519667b":"code","b806f20c":"code","8c86d836":"code","d733f00a":"code","5fbabaa3":"code","e7258626":"code","3c7d2d12":"code","9e4d64c4":"code","27d800af":"code","5e66b111":"code","a4bb7721":"code","5cf1f2b8":"markdown","bd344bef":"markdown","e18fd7c3":"markdown","9ab2dc1f":"markdown","dcc9cc1b":"markdown","50a51cae":"markdown","bf9f955f":"markdown","be9b4c08":"markdown","0b31f853":"markdown","a31ac248":"markdown","ca11f829":"markdown","f73ba408":"markdown","869c86bb":"markdown","97bd4bb0":"markdown","85691b8b":"markdown","88008f59":"markdown","da17a27a":"markdown","5059e68d":"markdown","fcda1ecf":"markdown","6ecd57d9":"markdown","bcca1550":"markdown","81b4b45a":"markdown","5be6e5fd":"markdown","520c7520":"markdown","e53b8d99":"markdown","bec41fd9":"markdown","7b2cf67d":"markdown","27f4ff54":"markdown","031d52db":"markdown","0d7d945d":"markdown","d193cddb":"markdown","6f9bb56f":"markdown","b5fc1e03":"markdown","f93e4d85":"markdown","f4d49465":"markdown","c22c6973":"markdown","f8953044":"markdown","fbcaa53b":"markdown","a95f4195":"markdown","bce20061":"markdown","f5a49f2e":"markdown","7ab1c341":"markdown","15af0bb6":"markdown","a106676c":"markdown","866e7a56":"markdown","93fd69fb":"markdown","feabfc94":"markdown"},"source":{"90139c57":"!pip install dabl;","ffb2b730":"!pip install missingno","c4901fa7":"!pip install ppscore","0d6d528f":"!pip install autoviz","256fcc67":"!pip install pycaret","d826e0b6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport dabl\nimport missingno as msno\nfrom autoviz.AutoViz_Class import AutoViz_Class\nimport ppscore as pps\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom pycaret import classification\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","f395971a":"df_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_train","ea2eb171":"dabl.plot(df_train, target_col=\"Survived\")","4830ca9b":"msno.matrix(df_train)","bc1e63e5":"msno.bar(df_train)","509089e4":"msno.heatmap(df_train)","c4a876b7":"AV = AutoViz_Class()\nAV.AutoViz('\/kaggle\/input\/titanic\/train.csv', depVar='Survived')\n","2a46ac41":"matrix = pps.matrix(df_train)\nmatrix[matrix['y'] == 'Survived']","12d85cdc":"def create_title_feat(df):\n    df['Title'] = df['Name']\n\n    # Cleaning name and extracting Title\n    for name_string in df['Name']:\n        df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n\n    # Replacing rare titles with more common ones\n    mapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr', 'Don': 'Mr', 'Mme': 'Miss',\n              'Jonkheer': 'Mr', 'Lady': 'Mrs', 'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\n    df.replace({'Title': mapping}, inplace=True)    \n\n\n    \ncreate_title_feat(df_train)\ndf_train","8afa45fc":"df_median_age = df_train.groupby(by=[ 'Title']).median().reset_index()\ndf_median_age = df_median_age[['Title', 'Age']]\ndf_median_age","1b28cb6f":"d = df_median_age.to_dict('list')\ntitle = d['Title']\nage = d['Age']\n\nfor t, a in zip(title, age):\n    mask = (df_train['Title'] == t)\n    df_train.loc[mask, 'Age'] = df_train.loc[mask, 'Age'].fillna(a)\n    \ndf_train  ","ee6bb438":"def create_family_size(df):\n    df['Family_Size'] = df['Parch'] + df['SibSp']\n    \ncreate_family_size(df_train)\ndf_train","959372c6":"def create_age_bins_feat(df):\n    df['AgeBin'] = pd.qcut(df['Age'], 4)\n\ncreate_age_bins_feat(df_train)\nlabel = LabelEncoder()\ndf_train['AgeBin'] = label.fit_transform(df_train['AgeBin'])\ndf_train","08ac9ee3":"clf = classification.setup(df_train, \n                           target = 'Survived', \n                           ignore_features = ['Ticket', 'Name', 'PassengerId'], \n                           silent = True,\n                           fix_imbalance = True,\n                           session_id = 786)","38ccf6b3":"# I'll use the _3_best_models in the future ...\n_3_best_models = classification.compare_models(n_select=3)","5c235116":"gbc = classification.create_model('gbc')","bd435193":"classification.plot_model(gbc, 'auc')","d2f2e017":"classification.plot_model(gbc, 'threshold')","22bad738":"classification.plot_model(gbc, 'pr')","164ea1b8":"classification.plot_model(gbc, 'confusion_matrix')","1fae7462":"classification.plot_model(gbc, 'error')","493f6a69":"classification.plot_model(gbc, 'class_report')","9fba807a":"classification.plot_model(gbc, 'boundary')","b3b07c7a":"classification.plot_model(gbc, 'learning')","ad3cf71a":"classification.plot_model(gbc, 'manifold')","bb0734f6":"classification.plot_model(gbc, 'calibration')","c356da59":"classification.plot_model(gbc, 'vc')","c6d37507":"classification.plot_model(gbc, 'feature')","704bb2f5":"classification.plot_model(gbc, 'parameter')","597d567c":"classification.plot_model(gbc, 'dimension')","1ba7a19a":"classification.interpret_model(gbc)","ed1b8208":"classification.interpret_model(gbc, plot = 'correlation')","f519667b":"classification.interpret_model(gbc, plot = 'reason', observation = 50)","b806f20c":"# train a votingclassifier on all models in library\nclf = classification.blend_models(estimator_list=_3_best_models, method = 'hard')","8c86d836":"classification.optimize_threshold(gbc, false_positive = -10, false_negative = -10, true_negative = 10, true_positive = 10)","d733f00a":"classification.predict_model(gbc, probability_threshold=0.42)","5fbabaa3":"df_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndf_test","e7258626":"create_title_feat(df_test)\ndf_test","3c7d2d12":"d = df_median_age.to_dict('list')\ntitle = d['Title']\nage = d['Age']\n\nfor t, a in zip(title, age):\n    mask = (df_test['Title'] == t)\n    df_test.loc[mask, 'Age'] = df_test.loc[mask, 'Age'].fillna(a)\n    \ndf_test  ","9e4d64c4":"create_family_size(df_test)\ndf_test","27d800af":"create_age_bins_feat(df_test)\nlabel = LabelEncoder()\ndf_test['AgeBin'] = label.fit_transform(df_test['AgeBin'])\ndf_test","5e66b111":"result = classification.predict_model(gbc, data=df_test)\nresult","a4bb7721":"result = result[['PassengerId', 'Label']]\nresult.rename(columns = {'Label': 'Survived'}, inplace = True)\nresult.to_csv('submission.csv', index=False, header=True)","5cf1f2b8":"# 5. Improve results\n## (I'll try at least ...)","bd344bef":"### Create age bins","e18fd7c3":"### Feature Importance","9ab2dc1f":"## 4.1 Compare models","dcc9cc1b":"### Area Under the Curve","50a51cae":"### Validation Curve","bf9f955f":"## Please: upvote if you liked this work...\n\n![Upvote](https:\/\/i.imgur.com\/cKIAXRw.jpg)","be9b4c08":"### Confusion Matrix","0b31f853":"### Calibration Curve","a31ac248":"### Create family size","ca11f829":"# 6. Finilize model (submit results)","f73ba408":"### Learning Curve","869c86bb":"### Create title feat.","97bd4bb0":"## 5.1 Blend models\n### I'll blend the 3 best models, as a way to improve the model's results (yeah... i'll use \"3_best_models\" variable now...)","85691b8b":"### Manifold Learning","88008f59":"# 3. Preprocess","da17a27a":"### Model Hyperparameter","5059e68d":"### Bar chart form","fcda1ecf":"### Classification Report","6ecd57d9":"### Decision Boundary","bcca1550":"## 3.1 Feature engineering\n","81b4b45a":"# 2. Exploratory Data Analysis (EDA)","5be6e5fd":"# 1. Problem definition","520c7520":"## 4.3 Interpret results","e53b8d99":"### 4.3.2 Correlation Plot\n#### I need more information about it... if you want to help me improve this result, I appreciate it!","bec41fd9":"## 5.2 Optimize threshold","7b2cf67d":"## 4.2 2nd best model metrics\n### I didn't understand the reason, but catboost did not allow all types of visualization, so I used the second best model to generate the graphics. If you know the reason and want to explain it to me, I appreciate it!","27f4ff54":"## 2.4 Using Predictive Power Score (PPS)\n\nref.: https:\/\/towardsdatascience.com\/rip-correlation-introducing-the-predictive-power-score-3d90808b9598","031d52db":"### 4.3.3 Plot at Observation Level","0d7d945d":"## 2.2 Missing values using MissingNo\n\n\nref.: https:\/\/towardsdatascience.com\/visualize-missing-values-with-missingno-ad4d938b00a1\n","d193cddb":"# This is a 'just for fun' jupyter notebook used to train data science skills and to experiment some new python libraries\n\n![Titanic](https:\/\/aventurasnahistoria.uol.com.br\/media\/_versions\/naufragio\/titaniammd_widexl.jpg)\n\n","6f9bb56f":"### Matrix form","b5fc1e03":"### Correlation between missing values features","f93e4d85":"## 5.3 New predict model","f4d49465":"## 2.1 Data visualization using dabl library (a library under construction, but with potential) \n\nmore inf.: https:\/\/towardsdatascience.com\/human-in-the-loop-auto-machine-learning-with-dabl-2fe9c9d1736f","c22c6973":"## Setting up of some libraries","f8953044":"### 4.2.1 Evaluate model","fbcaa53b":"![thats all folks](https:\/\/i.pinimg.com\/originals\/2c\/2e\/ef\/2c2eef8da1285d958914eef079f9b70c.jpg)","a95f4195":"### Class Prediction Error","bce20061":"## Need statement: Given a Titanic passenger database, create a predictive model capable of predicting which passengers survived or died (Spoiler alert: in the Titanic movie , Jack dies and Rose survives, although there is enough space for 2 people on the piece of wood on which Rose saved herself...).\n\n### Remember: this is a 'just for fun' notebook, I don't mean to be competitive, okay?\n\n![](https:\/\/i.insider.com\/5d2f85af36e03c05c5350e7d?width=1200&format=jpeg)\n\n### Special thanks to Parul Pandey (new libraries) :-)\nhttps:\/\/www.kaggle.com\/parulpandey\/useful-python-libraries-for-data-science\n\n### Special thanks to Konstantin (feature engineering) :-)\nhttps:\/\/www.kaggle.com\/konstantinmasich\/titanic-0-82-0-83\n\n### Special thanks to Pycare :-)\nhttps:\/\/www.kaggle.com\/teampycaret\/titanic-dataset-using-pycaret","f5a49f2e":"### Input missing age based on title","7ab1c341":"### Dimension Learning\n#### I don't know what that means, if you can explain it to me, I really appreciate it!","15af0bb6":"### Precision Recall Curve","a106676c":"### 4.3.1 Shap values","866e7a56":"## 2.3 Data visualization using AutoViz\n\nref.: https:\/\/towardsdatascience.com\/autoviz-automatically-visualize-any-dataset-ba2691a8b55a","93fd69fb":"### Discrimination Threshold","feabfc94":"# 4. Baseline algorithms"}}