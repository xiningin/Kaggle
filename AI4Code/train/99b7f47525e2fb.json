{"cell_type":{"63fd5a73":"code","ce85bba1":"code","4fc435ff":"code","0d4b06ea":"code","0ff797da":"code","c1b8a15e":"code","ac95b596":"code","680a2c54":"code","7bce2986":"code","0cbe317d":"code","091121ba":"code","0d7f36d7":"code","6fb060d2":"code","6d289b38":"code","d1ad786d":"code","c8cfb2e5":"code","88c8fcd6":"code","d2c0b2f4":"markdown","b4325a04":"markdown","87bd2944":"markdown","4a6f91e3":"markdown","699660fc":"markdown","8eb870fe":"markdown","313d5cab":"markdown","0d62d9a9":"markdown","e4030a75":"markdown","618e4a60":"markdown","7323b123":"markdown"},"source":{"63fd5a73":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n#load the libs\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport os\nprint(tf.__version__)\nprint(os.listdir(\"..\/input\"))","ce85bba1":"#import data and define the classes\ntrain_data = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\nclass_names = [0,1,2,3,4,5,6,7,8,9]\n\n#print out training data\nprint(train_data.shape)\nprint(train_data.head())","4fc435ff":"from sklearn.model_selection import train_test_split\n\n#split out the data into features (pixel values) and categorical labels (digit values 0-9)\ntrain_x = train_data.iloc[:,1:].values.astype('float32') # all pixel values\ntrain_y = train_data.iloc[:,0].values.astype('int32') # only labels i.e targets digits\n\ntest_x = test_data.iloc[:,].values.astype('float32') # all pixel values\n\n#reshape the features to be 28x28\ntrain_x = train_x.reshape(train_x.shape[:1] + (28, 28, 1))\ntest_x = test_x.reshape(test_x.shape[:1] + (28, 28, 1))\n\n#change the labels to be one-hot encoded\ntrain_y = keras.utils.to_categorical(train_y)\nnum_classes = train_y.shape[1]\n\n\n#normalize pixel values using minmax (values between 0 and 1 inclusive)\ntrain_x = train_x \/ 255\ntest_x = test_x \/ 255","0d4b06ea":"keras.callbacks.TensorBoard(log_dir='.\/logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=True, write_images=True)","0ff797da":"plt.figure()\nplt.imshow(train_x[0].reshape(28, 28))\nplt.colorbar()\nplt.grid(False)\nplt.show()\n\n#plot a group of features and labels to check data\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_x[i].reshape(28, 28), cmap=plt.cm.binary)\n    plt.xlabel(class_names[np.argmax(train_y[i])])\nplt.show()","c1b8a15e":"from keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\nfrom keras.layers.normalization import BatchNormalization\n\n#define the model and layers\n\n#first layer\nlayer1= tf.keras.layers.Conv2D(32,kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',\n                          input_shape=(28,28,1))\nlayer2= tf.keras.layers.Conv2D(32,kernel_size=(3,3), activation='relu',kernel_initializer='he_normal')\nlayer3= tf.keras.layers.MaxPooling2D(pool_size=(2,2))\nlayer4= tf.keras.layers.Dropout(0.20)\n\n#second layer\nlayer5= tf.keras.layers.Conv2D(64,(3, 3),activation='relu',padding='same')\nlayer6= tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='same')\nlayer7= tf.keras.layers.MaxPooling2D(pool_size=(2,2))\nlayer8= tf.keras.layers.Dropout(0.25)\n\n\n\n## third layer\nlayer9= tf.keras.layers.Conv2D(128,(3, 3),activation='relu',padding='same')\nlayer10= tf.keras.layers.Dropout(0.25)\n\n#output layer\nlayer11= tf.keras.layers.Flatten()\nlayer12= tf.keras.layers.Dense(128,activation='relu')\n# layer12 = tf.keras.layers.BatchNormalization()\nlayer13= tf.keras.layers.Dropout(0.3)\nlayer14= tf.keras.layers.Dense(10, activation=tf.nn.softmax)\nmodel = keras.models.Sequential()\nmodel.add(layer1)\nmodel.add(layer2)\nmodel.add(layer3)\nmodel.add(layer4)\nmodel.add(layer5)\nmodel.add(layer6)\nmodel.add(layer7)\nmodel.add(layer8)\nmodel.add(layer9)\nmodel.add(layer10)\nmodel.add(layer11)\n# model.add(layer12)\nmodel.add(layer13)\nmodel.add(layer14)","ac95b596":"model.summary()","680a2c54":"#compile the model\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n#print a summary of the model\n","7bce2986":"#train the model\nhist = model.fit(x=train_x, \n            y=train_y,\n            batch_size=128,\n            epochs=20,\n            verbose=1,\n            validation_split=0.15,\n            shuffle=True)\n","0cbe317d":"test = layer1.get_weights()\ntest[0].shape","091121ba":"plt.imshow(train_x[10][:,:,0])","0d7f36d7":"from numpy import array\nimport matplotlib.pyplot as plt\n\ndef plot_conv_weights():\n    W = layer1.get_weights()[0]\n    if len(W.shape) == 4:\n        W = np.squeeze(W)\n        for i in range(W.shape[0]):\n            print(i)\n            for j in range(W.shape[1]):\n                print(j)\n                a = array(W[i][j])\n                b = a.reshape(4,8)\n                plt.imshow(b, cmap='magma', interpolation='nearest')\n                name = str(i) + str(j) + \".png\"\n                plt.savefig(name)\n        \n\n            \nplot_conv_weights()","6fb060d2":"#make predictions on the test features\npredictions = model.predict(test_x)","6d289b38":"def plot_value_array(i, predictions_array):\n    predictions_array = predictions_array[i]\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n    plt.ylim([0, 1]) \n    predicted_label = np.argmax(predictions_array)\n    thisplot[predicted_label].set_color('red')\n\ndef plot_image(i, predictions_array, img):\n    img = img.reshape(img.shape[0] ,28, 28)\n    predictions_array, img = predictions_array[i], img[i]\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(img, cmap=plt.cm.binary)\n    predicted_label = np.argmax(predictions_array)\n    plt.xlabel(\"{} - prob:{:2.0f}%\".format(class_names[predicted_label], 100*np.max(predictions_array)), color='red')\n\n# Plot the first X test images, their predicted label, and the true label\n# Color correct predictions in blue, incorrect predictions in red\nnum_rows = 5\nnum_cols = 3\nnum_images = num_rows*num_cols\nplt.figure(figsize=(2*2*num_cols, 2*num_rows))\nfor i in range(num_images):\n    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n    plot_image(i, predictions, test_x)\n    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n    plot_value_array(i, predictions)\nplt.show()","d1ad786d":"print(hist.history['loss'])\nprint(hist.history['acc'])\nprint(hist.history['val_loss'])\nprint(hist.history['val_acc'])","c8cfb2e5":"\nimport matplotlib.pyplot as plt\n\nfig, loss_ax = plt.subplots()\nacc_ax = loss_ax.twinx()\n\nloss_ax.plot(hist.history['loss'], 'y', label='train loss')\nloss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\nloss_ax.set_xlabel('epoch')\nloss_ax.set_ylabel('loss')\nloss_ax.legend(loc='upper right')\n\nacc_ax.plot(hist.history['acc'], 'b', label='train acc')\nacc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\nacc_ax.set_ylabel('accuracy')\nacc_ax.legend(loc='upper left')\n\nplt.show()","88c8fcd6":"#submissions for Kaggle\n#cat_predictions = np.argmax(predictions, axis=1)\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": np.argmax(predictions, axis=1)})\nsubmissions.to_csv(\"my_submissions.csv\", index=False, header=True)","d2c0b2f4":"View an example of one feature","b4325a04":"Plot a table of test features (images) and the predicted targets (digits). Display the confidence via probability of the prediction under each image.","87bd2944":"Compile and summarize the model. Use adam optimizer and categorical cross entropy for loss (takes input of one-hot encoded targets)","4a6f91e3":"|Train the model using batch_size of 32 and up to 30 epochs (depending on improvement of validation accuracy).","699660fc":"Process the data by splitting training data into features and labels. Then apply preprocessing to the data to get it ready for input into the model.","8eb870fe":"Create submission file for Kaggle","313d5cab":"This is my first submission and notebook on Kaggle. I'm still learning and any comments would be appreciated. Hope some may find this useful.","0d62d9a9":"Import the MNIST data from input folder","e4030a75":"\n Make prediction on the test data","618e4a60":"|Create Keras callbacks for use during training","7323b123":"Define the model using Keras and TensorFlow backend (channels first)"}}