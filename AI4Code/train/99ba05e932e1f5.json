{"cell_type":{"81d1f128":"code","0114cc36":"code","cbe349be":"code","ef77753c":"code","b6c2867f":"code","ff86eaef":"code","313fbfd7":"code","44a1aafd":"code","f54cf2fa":"code","a40bdc36":"code","69afd057":"code","ada30fbf":"code","542cc95d":"code","9f8f0cea":"code","367f7dd9":"code","d8135ae6":"code","f2d88a72":"code","92192f36":"code","90fd4cd6":"code","5041f491":"code","1b71e909":"code","9b49ec75":"code","272ba069":"code","ae628328":"code","b4faf736":"code","a1b915c2":"code","b282a982":"code","7541ec9a":"code","ee863c8f":"code","74ef942c":"code","0dc56d60":"code","f6179f59":"code","05bf5893":"code","2de53646":"code","e1cce450":"code","b266b904":"code","e09c2ecd":"code","d7be8106":"code","cf5ff525":"code","3df51056":"code","6c10f50a":"code","0b53a2e0":"code","f97bf0d9":"code","5366e623":"code","8492475d":"code","b6f38f48":"code","58828261":"code","4cdcac4a":"code","6d6491bc":"code","c799c95d":"code","1863fca6":"code","baa3d240":"code","d895b989":"code","69f347a9":"code","a0c5e10c":"code","cda14d62":"code","245de432":"code","297b8699":"code","6e1cfeaa":"code","96945807":"code","13bbb93e":"code","ee4b03ae":"code","1f17c043":"code","d501381f":"code","e0bc8f9c":"code","b8f02a93":"code","843552ec":"code","bc697837":"code","25499002":"code","91a4a530":"code","5ba83713":"code","1c7350be":"code","2a8800b6":"code","44932a71":"code","870054af":"code","3ae100c6":"code","5b9144b9":"code","ba22b3be":"code","e9d4a97e":"code","a1888947":"code","4d3887b9":"code","a61eedfd":"code","73b6659e":"code","1bb4b0a2":"code","93a834d5":"code","af878818":"code","e6bf6628":"code","939c2f0b":"code","11ee4b17":"code","e39dfbab":"code","b5c76ba9":"code","f668c351":"code","14d9e0c7":"markdown","5aca9d31":"markdown","8f0f0aa3":"markdown","92f31e3b":"markdown","223e8655":"markdown","ccb5d578":"markdown","4224f1d4":"markdown","b25d3eb2":"markdown","fcd838ab":"markdown","2469346e":"markdown","61eadb54":"markdown","e7f0749b":"markdown","10b5ed70":"markdown","026bedaf":"markdown","7af3e253":"markdown","d40bbd6a":"markdown","6acfd8f3":"markdown","a0ebc6bf":"markdown","1011155d":"markdown","c97e6542":"markdown","334c1cbf":"markdown","85144acb":"markdown","8e17c396":"markdown","a13180cd":"markdown","61bfb58b":"markdown","83f530c8":"markdown","927deb59":"markdown","d8d5e163":"markdown","61acd572":"markdown","7a30850d":"markdown","61923ab8":"markdown","67ee7079":"markdown","9288c352":"markdown","b92b3c67":"markdown","d21c4b57":"markdown","c50b6b55":"markdown","0d92a0da":"markdown","b5d11176":"markdown","50229f82":"markdown","215a0270":"markdown","74457ee4":"markdown","9f4ce05e":"markdown","ce82c530":"markdown","b4583d6a":"markdown","dfdab0fb":"markdown","92cc6a40":"markdown","c24998ed":"markdown","6e4c6c35":"markdown","2d21dda4":"markdown","94f186c9":"markdown","0756dd15":"markdown","88ab6dee":"markdown","3b42b833":"markdown","e8bc8074":"markdown","a40ba675":"markdown","5d2741ba":"markdown","88659eca":"markdown","a8e46fc0":"markdown","fcf037b7":"markdown","595a2319":"markdown","a88fa305":"markdown","ef7353ad":"markdown","6237672a":"markdown","d8d41fa9":"markdown","4e0c65a3":"markdown","42a52911":"markdown","f151d8b8":"markdown","17bd092f":"markdown","cb5eeb2a":"markdown","b4a09ea9":"markdown","695a8f58":"markdown","a14bfbd8":"markdown","d5fc86fb":"markdown","a7ba1ae5":"markdown","2dc40798":"markdown","c9c282b2":"markdown","053f7a0e":"markdown","fbd361b4":"markdown","955050a6":"markdown","60f63bf7":"markdown"},"source":{"81d1f128":"# Importing Libraries\n\n# Standard libs\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom matplotlib.gridspec import GridSpec\npd.set_option('display.max_columns', 100)\nimport plotly.offline as py\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport json\nimport requests\nimport folium\n\nfrom datetime import datetime\nimport calendar\nfrom pandas.api.types import CategoricalDtype\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom PIL import Image\n\n# Utilities\nfrom viz_utils import *\n\n# DataPrep\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import RSLPStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nimport joblib\n\n# Modeling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nimport lightgbm as lgb","0114cc36":"#reading datas\nimport time\nstart = time.time()\ndata = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_customers_dataset.csv\")\ngeo_data = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_geolocation_dataset.csv\")\norder_itemdata = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_order_items_dataset.csv\")\npay_data = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_order_payments_dataset.csv\")\nrev_data = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_order_reviews_dataset.csv\")\norders = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_orders_dataset.csv\")\norder_prddata = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_products_dataset.csv\")\norder_selldata = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_sellers_dataset.csv\")\norder_prd_catdata = pd.read_csv(\"..\/input\/brazilian-ecommerce\/product_category_name_translation.csv\")\nend = time.time()\nprint(\"reading time: \",(end-start),\"sec\")","cbe349be":"#checking number of columns , column_names and no_of_rows\n\ndatasets = [data,geo_data,order_itemdata, pay_data, orders, order_prddata,rev_data,order_selldata, order_prd_catdata]\ntitles = [\"customers\",\"geolocations\",\"items\", \"payments\", \"orders\", \"products\",\"reviews\",\"sellers\",\"category_translation\"]\n\n\n\ninfo_df = pd.DataFrame({},)\ninfo_df['dataset']= titles\n\ninfo_df['no_of_columns']= [len(df.columns) for df in datasets ]\ninfo_df['columns_name']= [', '.join(list(df.columns)) for df in datasets] \ninfo_df['no_of_rows'] = [len(df) for df in datasets]\n\ninfo_df.style.background_gradient(cmap='Greys')","ef77753c":"#checking dtypes\ndatasets = [data,geo_data,order_itemdata, pay_data, orders, order_prddata,rev_data,order_selldata, order_prd_catdata]\ntitles = [\"customers\",\"geolocations\",\"items\", \"payments\", \"orders\", \"products\",\"reviews\",\"sellers\",\"category_translation\"]\n\nnumerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnew_df = pd.DataFrame({},)\nnew_df['dataset']= titles\n\nnew_df['numeric_features'] = [len((df.select_dtypes(include=numerics)).columns) for df in datasets]\nnew_df['num_features_name'] = [', '.join(list((df.select_dtypes(include=numerics)).columns)) for df in datasets]\nnew_df['object_features'] = [len((df.select_dtypes(include='object')).columns) for df in datasets]\nnew_df['objt_features_name'] = [', '.join(list((df.select_dtypes(include='object')).columns)) for df in datasets]\nnew_df['bool_features'] = [len((df.select_dtypes(include='bool')).columns) for df in datasets]\nnew_df.style.background_gradient(cmap='Greys')\n","b6c2867f":"#checking no of null values\n#code source-https:\/\/www.kaggle.com\/fayhosseini\/brazilian-e-commerce-eda-for-beginners\n\ndatasets = [data,geo_data,order_itemdata, pay_data, orders, order_prddata,rev_data,order_selldata, order_prd_catdata]\ntitles = [\"customers\",\"geolocations\",\"items\", \"payments\", \"orders\", \"products\",\"reviews\",\"sellers\",\"category_translation\"]\n\ninfo_df_n = pd.DataFrame({},)\n\ninfo_df_n['dataset']= titles\n\n#creating column of name of columns in the dataset \ninfo_df_n['cols'] = [', '.join([col for col, null in df.isnull().sum().items() ]) for df in datasets]\n\n#creating total number of columns in the dataset \ninfo_df_n['cols_no']= [df.shape[1] for df in datasets]\n\n#counting total null values\ninfo_df_n['null_no']= [df.isnull().sum().sum() for df in datasets]\n\n#creating total number of columns in the dataset with null-values \ninfo_df_n['null_cols_no']= [len([col for col, null in df.isnull().sum().items() if null > 0]) for df in datasets]\n\n#creating column of name of columns in the dataset with null-values \ninfo_df_n['null_cols'] = [', '.join([col for col, null in df.isnull().sum().items() if null > 0]) for df in datasets]\n\n\ninfo_df_n.style.background_gradient(cmap='Greys')","ff86eaef":"rev_new = rev_data.drop(['review_comment_title','review_creation_date','review_id','review_answer_timestamp'],axis=1)","313fbfd7":"df = pd.merge(orders,pay_data, on=\"order_id\")\ndf = df.merge(data, on=\"customer_id\")\ndf = df.merge(order_itemdata, on=\"order_id\")\ndf = df.merge(order_prddata, on=\"product_id\")\ndf = df.merge(order_prd_catdata, on=\"product_category_name\")\ndf = df.merge(rev_new, on=\"order_id\")\ndf.head()","44a1aafd":"print(\"Number of rows after merging:\",len(df))\nprint(\"Number of columns after merging:\",len(df.columns))","f54cf2fa":"df.isnull().sum()","a40bdc36":"#Handling missing values\nindex = (df[df['order_delivered_customer_date'].isnull() == True].index.values)\n\ndf[\"order_approved_at\"].fillna(df[\"order_purchase_timestamp\"], inplace=True)\ndf[\"order_delivered_customer_date\"].fillna(df[\"order_estimated_delivery_date\"], inplace=True)\n\n#dropping order delivery carrier date\ndf.drop(labels='order_delivered_carrier_date',axis=1,inplace=True)","69afd057":"#checking the replaced values\ndf.order_estimated_delivery_date[index[0]]","ada30fbf":"df.order_delivered_customer_date[index[0]]","542cc95d":"# Handling missing values of numerical features\ndf['product_weight_g'].fillna(df['product_weight_g'].median(),inplace=True)\ndf['product_length_cm'].fillna(df['product_length_cm'].median(),inplace=True)\ndf['product_height_cm'].fillna(df['product_height_cm'].median(),inplace=True)\ndf['product_width_cm'].fillna(df['product_width_cm'].median(),inplace=True)","9f8f0cea":"#Handling missing values of text column\nprint(\"Percentage of null reviews :\",(df.review_comment_message.isnull().sum()\/len(df))*100 ,\"%\")\n# filling null value of review comments with no_review\ndf['review_comment_message'].fillna('nao_reveja',inplace=True)","367f7dd9":"dup_rows = df[df.duplicated(['order_id','customer_id','order_purchase_timestamp','order_delivered_customer_date','customer_unique_id','review_comment_message'])]\ndup_rows.head()","d8135ae6":"#Deduplication of entries\ndf= df.drop_duplicates(subset={'order_id','customer_id','order_purchase_timestamp','order_delivered_customer_date'}, keep='first', inplace=False)\ndf=df.reindex()\ndf.head()","f2d88a72":"print(\"Number of rows after dedublication:\",len(df))\nprint(\"Number of columns after deduplication:\",len(df.columns))","92192f36":"# all time stamps are in object dtype as observed above converting it into dataetime \ndf[['order_purchase_timestamp','order_approved_at','order_delivered_customer_date','order_estimated_delivery_date',]]=df[['order_purchase_timestamp',\n       'order_approved_at','order_delivered_customer_date','order_estimated_delivery_date']].apply(pd.to_datetime)\n\n","90fd4cd6":"df.info()","5041f491":"df.describe()","1b71e909":"# checking the target variables i.e review score \ndf.review_score.value_counts()","9b49ec75":"def partition(x):\n    if x < 3:\n        return 0\n    return 1\ndf['review_score']=df['review_score'].map(lambda cw : partition(cw) ) \n    \n# checking the review score now\ndf.review_score.value_counts()","272ba069":"#counting the review score with 1 and 0\ny_value_counts = df.review_score.value_counts()\n\n#calculating the percentage of each review type\nprint(\"Total Positive Reviews :\", y_value_counts[1], \", (\", (y_value_counts[1]\/(y_value_counts[1]+y_value_counts[0]))*100,\"%)\")\nprint(\"Total Negative Reviews :\", y_value_counts[0], \", (\", (y_value_counts[0]\/(y_value_counts[1]+y_value_counts[0]))*100,\"%)\")\nprint('\\n')\n\n#plotting bar-plot and pie chart\n%matplotlib inline\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(14,5))\nplt.subplot(1,2,1)\nplt.ylabel('Total Reviews')\nplt.xlabel('Label')\nplt.title('Negative Vs Positive Reviews',color='dimgrey')\nplt.xticks([10,10.20],['0','1'])\n#creating bar plots\nplt.bar(10,14112, color = 'grey', width = 0.15,alpha=0.7,label='negative',edgecolor='black')\nplt.bar(10.20,83143,color = '#2e4884', width = 0.15,alpha=0.9,label='positive',edgecolor='black')\nplt.legend()\n\nplt.subplot(1,2,2)\nlabels = ['Positive','Negative']\nsizes = [83143,14112]\nexplode = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\ncolor={'#2e4884','grey'}\nplt.pie(sizes,explode=explode ,colors=color,labels=labels, autopct='%1.1f%%',shadow=False, startangle=0,radius=1.5,labeldistance=1.1,textprops={'fontsize': 14},frame=True, )\nplt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nplt.title('Pie Chart for review score',color='dimgrey')\nplt.show()\n","ae628328":"#Correlation matrix \ncorr_matrix = df.corr()","b4faf736":"#finding corr- values of the features with review_score\ncorr_matrix[\"review_score\"].sort_values(ascending=False)","a1b915c2":"#checking unique ids\nprint(\"Total number of unique seller_id:\",len((df.seller_id).unique()))\nprint(\"Total number of unique product_id:\",len((df.product_id).unique()))\nprint(\"Total number of unique customer_id:\",len((df.customer_unique_id).unique()))","b282a982":"%matplotlib inline\nplt.figure(figsize=(8,6))\nsns.set_style(\"whitegrid\")\nplt.ylabel('No of Unique_Ids')\nplt.xlabel('Different Unique_Ids')\nplt.title('Total Unique Ids',color='dimgrey')\nplt.xticks([10,10.25,10.50],['seller_id','product_id','customer_id'])\n#creating bar plots\nplt.bar(10,3022, color = 'grey', width = 0.25,alpha=0.7,label='seller_id',edgecolor='black')\nplt.bar(10.25,31053, color = 'white', width = 0.25,alpha=0.8,label='product_id',edgecolor='black')\nplt.bar(10.50,94087, color = '#2e4884', width = 0.25,alpha=0.9,label='customer_id',edgecolor='black')\nplt.legend()\nplt.show()","7541ec9a":"df.groupby('payment_type').size()","ee863c8f":"%matplotlib inline\nplt.figure(figsize=(14,5))\nplt.subplot(1,2,1)\nplt.ylabel('Total')\nplt.xlabel('payment_type')\nplt.title('Total payment_type',color='dimgrey')\nplt.xticks([10,10.25,10.50,10.75],['debit_card','voucher','boleto','credit_card'])\n#creating bar plots\nplt.bar(10.75,73816, color = '#2e4884', width = 0.25,alpha=0.8,label='credit_card',edgecolor='black')\nplt.bar(10.50,19345, color = '#d8d8d8', width = 0.25,label='boleto',edgecolor='black')\nplt.bar(10.25,2604, color = 'white', width = 0.25,alpha=0.5,label='voucher',edgecolor='black')\nplt.bar(10,1490, color = 'grey', width = 0.25,alpha=0.8,label='debit_card',edgecolor='black')\n\n\n\nplt.legend()\n\nplt.subplot(1,2,2)\ns= [ 73816,19345, 2604,1490]\nnew = ['credit_card','boleto','voucher','debit_card']\n\nexplode = (0, 0, 0,0)  \ncolours = {'credit_card': '#2e4884',\n           'boleto': '#d8d8d8',\n           'voucher': 'w',\n           'debit_card': 'grey'}\n\ncolor ={'#2e4884','grey','#d8d8d8','w'}\n\n\n\nplt.pie(s, explode=explode, labels=new,colors=[colours[key] for key in new] , autopct='%1.1f%%',shadow=False, startangle=70,radius=1.5,frame=True,textprops={'fontsize': 8})\nplt.axis('equal') \nplt.show()\n","74ef942c":"temp = pd.DataFrame(df.groupby('payment_type')['review_score'].agg(lambda x: x.eq(1).sum())).reset_index()\n\n# Pandas dataframe grouby count: https:\/\/stackoverflow.com\/a\/19385591\/4084039\ntemp['total'] = list(pd.DataFrame(df.groupby('payment_type')['review_score'].agg([('total','count'),('Avg','mean')]))['total'])\ntemp['Avg']   = list(pd.DataFrame(df.groupby('payment_type')['review_score'].agg([('total','count'),('Avg','mean')]))['Avg'])\n#sorting dataframe\ntemp = temp.sort_values(by=['total'], ascending=True)","0dc56d60":"#Simplifing the plots using pareto plots\ndef pareto_plot(df, x=None, y=None, title=None, show_pct_y=False, pct_format='{0:.0%}'):\n    xlabel = x\n    ylabel = y\n    tmp = df.sort_values(y, ascending=False)\n    x = tmp[x].values\n    y = tmp[y].values\n    weights = y \/ y.sum()\n    cumsum = weights.cumsum()\n\n    fig, ax1 = plt.subplots(figsize=(10,6))\n    ax1.bar(x, y,color='#2e4884',edgecolor='black',alpha=0.9)\n    ax1.set_xlabel(xlabel)\n    ax1.set_ylabel(ylabel)\n\n    ax2 = ax1.twinx()\n    ax2.plot(x, cumsum, '-ro', alpha=0.5,color='black')\n    ax2.set_ylabel('', color='r')\n    ax2.tick_params('y', colors='r')\n    \n    vals = ax2.get_yticks()\n    ax2.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n\n    # hide y-labels on right side\n    if not show_pct_y:\n        ax2.set_yticks([])\n    \n    formatted_weights = [pct_format.format(x) for x in cumsum]\n    for i, txt in enumerate(formatted_weights):\n        ax2.annotate(txt, (x[i], cumsum[i]),fontsize=15)    \n    \n    if title:\n        plt.title(title,color='dimgrey',fontsize=15)\n    \n    plt.tight_layout()\n    plt.show()","f6179f59":"pareto_plot(temp,x='payment_type',y='total',title=\"Pareto Plot of counts of each payment type\")","05bf5893":"#Let us see how this categorical feature related with our target variable\n#code source-https:\/\/matplotlib.org\/stable\/gallery\/lines_bars_and_markers\/barh.html\nplt.figure(figsize=(12,8))\np1=plt.barh(temp.payment_type,temp.total,color='grey',alpha=0.5)\np2=plt.barh(temp.payment_type,temp.review_score,color='#2e4884',alpha=0.9)\nplt.title('Payment Types and user_counts',fontsize=15,color='dimgrey')\nplt.ylabel('payment_types',fontsize=14)\nplt.xlabel('Total',fontsize=14)\nplt.legend((p1[0], p2[0]), ('total_reviews', 'positive_review by users'))\n\nplt.show()","2de53646":"# State with the consumers count\nplt.figure(figsize=(10,6))\nsns.set_style(\"whitegrid\")\nax = df.customer_state.value_counts().sort_values(ascending=False)[0:15].plot(kind='bar', color = 'grey', alpha=0.8)\nax.set_title(\"Top 15 consumer states of Brazil\")\nax.set_xlabel(\"States\")\nplt.xticks(rotation=35)\nax.set_ylabel(\"No of consumers\")\nplt.show()","e1cce450":"#stacked bar plots matplotlib: https:\/\/matplotlib.org\/gallery\/lines_bars_and_markers\/bar_stacked.html\ndef stack_plot(data, xtick, col2, col3='total'):\n    ind = np.arange(data.shape[0])\n    \n    plt.figure(figsize=(20,5))\n    p1 = plt.bar(ind, data[col3].values,color = 'grey',alpha=0.5)\n    p2 = plt.bar(ind, data[col2].values,color= '#2e4884',alpha=0.8)\n\n    plt.ylabel('Reviews')\n    plt.title('% of review_score  ')\n    plt.xticks(ind-0.1, list(data[xtick].values), rotation=0)\n    plt.legend((p1[0], p2[0]), ('total_reviews', 'positive_review'))\n    plt.show()","b266b904":"# Count number of zeros in dataframe python: https:\/\/stackoverflow.com\/a\/51540521\/4084039\ntemp_1 = pd.DataFrame(df.groupby('customer_state')['review_score'].agg(lambda x: x.eq(1).sum())).reset_index()\n\n# Pandas dataframe grouby count: https:\/\/stackoverflow.com\/a\/19385591\/4084039\n\n\ntemp_1['total'] = list(pd.DataFrame(df.groupby('customer_state')['review_score'].agg([('total','count'),('Avg','mean')]))['total'])\ntemp_1['Avg']   = list(pd.DataFrame(df.groupby('customer_state')['review_score'].agg([('total','count'),('Avg','mean')]))['Avg'])\ntemp_1= temp_1.rename(columns={'review_score':'positive_review'})\ntemp_1= temp_1.sort_values(by=['total'], ascending=False)","e09c2ecd":"temp_1","d7be8106":"stack_plot(temp_1,'customer_state',col2='positive_review', col3='total')","cf5ff525":"# State with the consumers count\nplt.figure(figsize=(10,6))\nsns.set_style(\"whitegrid\")\nax = df.product_category_name_english.value_counts().sort_values(ascending=False)[0:15].plot(kind='bar', color = 'grey', alpha=0.8)\nax.set_title(\"Top selling product categories\")\nax.set_xlabel(\"States\")\nplt.xticks(rotation=90)\nax.set_ylabel(\"No of Orders\")\nplt.show()","3df51056":"  temp_2 = pd.DataFrame(df.groupby('product_category_name_english')['review_score'].agg(lambda x: x.eq(1).sum())).reset_index()\n\n  # Pandas dataframe grouby count: https:\/\/stackoverflow.com\/a\/19385591\/4084039\n\n\n  temp_2['total'] = list(pd.DataFrame(df.groupby('product_category_name_english')['review_score'].agg([('total','count'),('Avg','mean')]))['total'])\n  temp_2['Avg']   = list(pd.DataFrame(df.groupby('product_category_name_english')['review_score'].agg([('total','count'),('Avg','mean')]))['Avg'])\n  temp_2 = temp_2.sort_values(by=['total'], ascending=True)\n  temp_2","6c10f50a":"#code source-https:\/\/matplotlib.org\/stable\/gallery\/lines_bars_and_markers\/barh.html\nplt.figure(figsize=(22,18))\nplt.barh(temp_2.product_category_name_english,temp_2.total,color='grey',alpha=0.4)\nplt.barh(temp_2.product_category_name_english,temp_2.review_score,color='#2e4884',alpha=0.7)\nplt.title('Top Selling Product Categories in Brazilian E-Commerce (2016-2018)',fontsize=22,color='dimgrey')\nplt.ylabel('product_category_name_english',fontsize=14)\nplt.xlabel('Total',fontsize=14)\nplt.savefig('plot14.png', dpi=480, bbox_inches='tight')\nplt.show()","0b53a2e0":"# plotting frequency orders vs  the number of consumers \nplt.figure(figsize=(14,8))\n\n#counting the consumers and converting it into percentage to visualize the distribution properly\nnum_orders=df['customer_unique_id'].value_counts().value_counts()\/df.shape[0]*100\nnum_orders=num_orders.reset_index()\n#renaming the columns\nnum_orders.rename(columns={'index':'number of orders', 'customer_unique_id':'log percentage of customers'},inplace=True)\n\n#plotting bar plot\nsns.barplot(data=num_orders,x='number of orders',y='log percentage of customers',palette='gray')\nplt.yscale('log') #log scale\nplt.title('Number of orders per customer',color='dimgrey')\n","f97bf0d9":"#by using custom countplots in (viz_utils)\nsns.set_style(\"whitegrid\")\nfig, ax = plt.subplots(figsize=(14, 6))\nsingle_countplot(df, x='order_status', ax=ax,palette=['grey'])\nplt.title('Order_status',color='dimgrey')\nplt.show()","5366e623":"#by using custom countplots in (viz_utils)\nsns.set_style(\"whitegrid\")\nfig, ax = plt.subplots(figsize=(14, 6))\nsingle_countplot(df, x='order_status', ax=ax,palette=['grey','#425a90'],hue='review_score')\nplt.title('Order_status with % of Reviews',color='dimgrey')\nplt.show()","8492475d":"#calulating number of days for the data is taken\nprint(df.order_approved_at.max() - df.order_approved_at.min(), ' from ', \n      df.order_approved_at.min(), ' to ', df.order_approved_at.max())","b6f38f48":"#code source-https:\/\/stackoverflow.com\/questions\/25146121\/extracting-just-month-and-year-separately-from-pandas-datetime-column\n\n# Extracting attributes for purchase date - Year and Month\ndf['order_purchase_year'] = df['order_purchase_timestamp'].apply(lambda x: x.year) #gives year Example :2016-10-04 09:43:32 ---->2016\ndf['order_purchase_month'] = df['order_purchase_timestamp'].apply(lambda x: x.month) #gives month Example :2016-10-04 09:43:32 ---->10\ndf['order_purchase_month_name'] = df['order_purchase_timestamp'].apply(lambda x: x.strftime('%b'))#gives month in short form Example :2016-10-04 09:43:32 ---->10--> Oct\ndf['order_purchase_year_month'] = df['order_purchase_timestamp'].apply(lambda x: x.strftime('%Y%m'))#gives month&year Example :2016-10-04 09:43:32 ---->201610\ndf['order_purchase_date'] = df['order_purchase_timestamp'].apply(lambda x: x.strftime('%Y%m%d'))#gives month,yr and date  Example :2016-10-04 09:43:32 ---->20161004\ndf['order_purchase_month_yr'] = df['order_purchase_timestamp'].apply(lambda x: x.strftime(\"%b-%y\"))\n\n# Extracting attributes for purchase date - Day and Day of Week\ndf['order_purchase_day'] = df['order_purchase_timestamp'].apply(lambda x: x.day)\ndf['order_purchase_dayofweek'] = df['order_purchase_timestamp'].apply(lambda x: x.dayofweek)\ndf['order_purchase_dayofweek_name'] = df['order_purchase_timestamp'].apply(lambda x: x.strftime('%a'))\n\n# Extracting attributes for purchase date - Hour and Time of the Day\ndf['order_purchase_hour'] = df['order_purchase_timestamp'].apply(lambda x: x.hour)\nhours_bins = [-0.1, 6, 12, 18, 23]\nhours_labels = ['Dawn', 'Morning', 'Afternoon', 'Night']\ndf['order_purchase_time_day'] = pd.cut(df['order_purchase_hour'], hours_bins, labels=hours_labels)\n\n# New DataFrame after transformations\ndf.head()","58828261":"sns.set_style(\"whitegrid\")\nplt.figure(figsize=(15,6))\nsns.lineplot(data=df['order_purchase_year_month'].value_counts().sort_index(), \n             color='black', linewidth=2)\nplt.title('Evolution of Total Orders in Brazilian E-Commerce', size=14, color='dimgrey')\nplt.xticks(rotation=90)\nplt.show()","4cdcac4a":"df_month = pd.DataFrame()\ndf_month['date'],df_month['review_score']= list(df.order_approved_at),list(df.review_score)\ndf_month=df_month.dropna()\ndf_month = df_month.sort_values(by=['date'])","6d6491bc":"df_month['monthcount'] = list(df_month.date.apply(lambda x: x.strftime(\"%b-%y\")))\n#plotting number of orders per month-year\nplt.figure(figsize=(18,6))\ng = sns.countplot(x=df_month.monthcount,data=df_month,color='grey',edgecolor='grey')\ng.set_xticklabels(g.get_xticklabels(), rotation=90)\ng.set_xlabel('Month-Year')\ng.set_ylabel('Orders Count')\nplt.title('Number of orders per month-year', size=14, color='dimgrey');","c799c95d":"#plotting number of positive and negative reviews per month-year\nplt.figure(figsize=(18,6))\ng = sns.countplot(x=df_month.monthcount,hue='review_score',data=df_month,palette=['grey','#425a90'],edgecolor='grey')\ng.set_xticklabels(g.get_xticklabels(), rotation=90)\ng.set_xlabel('Month-Year')\ng.set_ylabel('Orders Count')\nplt.title('Number of positive and negative reviews per month-year', size=14, color='dimgrey');","1863fca6":"#code source: https:\/\/www.kaggle.com\/thiagopanini\/e-commerce-sentiment-analysis-eda-viz-nlp\nfig = plt.figure(constrained_layout=True, figsize=(13, 10))\n\n# Axis definition\ngs = GridSpec(2, 2, figure=fig)\nax1 = fig.add_subplot(gs[1, 0])\nax2 = fig.add_subplot(gs[0, :])\nax3 = fig.add_subplot(gs[1, 1])\n\n# Barchart - Total Reviews by time of the day\nsingle_countplot(df, x='order_purchase_time_day', ax=ax1, order=False, palette=['grey','#2e4884'],hue='review_score')\nax1.set_title('Total Reviews by Time of the Day', size=14, color='dimgrey', pad=20)\n\n# Barchart - Total Reviews by month\nsingle_countplot(df, x='order_purchase_month_name', ax=ax2, order=False, palette=['grey','#2e4884'],hue='review_score')\n\nax2.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug','Sep','Oct','Nov','Dec'])\nax2.set_title('Total Reviews by Month', size=14, color='dimgrey', pad=20)\n\nsingle_countplot(df, x='order_purchase_dayofweek', ax=ax3, order=False, palette=['grey','#2e4884'],hue='review_score')\nweekday_label = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\nax3.set_xticklabels(weekday_label)\nax3.set_title('Total Reviews by Day of Week', size=14, color='dimgrey', pad=20)\n\nplt.savefig('plot14.png', dpi=300, bbox_inches='tight')\nplt.tight_layout()\n\nplt.show()","baa3d240":"#ploting plot for the Total Number orders based on the Total delivery Time(Days)\n#https:\/\/stackoverflow.com\/questions\/60229375\/solution-for-specificationerror-nested-renamer-is-not-supported-while-agg-alo\ndf['day_to_delivery']=((df['order_delivered_customer_date']-df['order_purchase_timestamp']).dt.days)\n","d895b989":"df_dev = pd.DataFrame()\ndf_dev['day_to_delivery'],df_dev['review_score']= list(df.day_to_delivery),list(df.review_score)\ndf_dev=df_dev.dropna()\n","69f347a9":"plt.figure(figsize=(22,6))\nplt.title('Order Counts Based on Total delivery Time(in Days)', color='dimgrey')\ng = sns.countplot(x=df_dev.day_to_delivery,data=df_dev,color='gray')\ng.set_xticklabels(g.get_xticklabels(), rotation=90)\ng.set_xlabel('Total Days')\ng.set_ylabel('Orders Count');","a0c5e10c":"import seaborn as sns\n\nplt.figure()\nsns.set_style(\"whitegrid\")\nax = sns.FacetGrid(df, hue=\"review_score\", height=5,aspect=2.0,palette=['#2e4884','black'])\nax = ax.map(sns.distplot, \"price\").add_legend();\nplt.title('Distribution of product price per class')\nplt.show()","cda14d62":"# plotting distributions of freight_value per class\nplt.figure()\n#sns.set_style(\"whitegrid\")\nax = sns.FacetGrid(df, hue=\"review_score\", height=5,aspect=2.0,palette=['#000080','black'])\nax = ax.map(sns.distplot, \"freight_value\").add_legend();\nplt.title('Distribution of freight_value per class')\nplt.show()","245de432":"# plotting distributions of product_height_cm per class\nsns.set_style(\"whitegrid\")\nax = sns.FacetGrid(df, hue=\"review_score\", height=5,aspect=2.0,palette=['#2e4884','black'])\nax = ax.map(sns.distplot, \"product_height_cm\").add_legend();\nplt.title('Distribution of product_height_cm per class')\nplt.show()","297b8699":"\n# distriution plot of product_weight_g\nplt.figure()\nsns.set_style(\"whitegrid\")\nax = sns.FacetGrid(df, hue=\"review_score\", height=5,aspect=2.0,palette=['#2e4884','black'])\nax = ax.map(sns.distplot, \"product_weight_g\").add_legend();\nplt.title('Distribution of product_weight_g per class')\nplt.show()","6e1cfeaa":"# distriution plot of payment_value\nplt.figure()\nsns.set_style(\"whitegrid\")\nax = sns.FacetGrid(df, hue=\"review_score\", height=5,aspect=2.0,palette=['#2e4884','black'])\nax = ax.map(sns.distplot, \"payment_value\").add_legend();\nplt.title('Distribution of payment_value per class')\nplt.show()","96945807":"import matplotlib.pyplot as plt\n \nplt.figure(figsize=(14,6))\n \nbox_plot_data=[df.product_length_cm,df.product_height_cm,df.product_width_cm]\nplt.boxplot(box_plot_data,labels=['product_length_cm','product_height_cm','product_width_cm'],vert=False)\nplt.title(\"Box Plots of Product Dimensions\")\nplt.savefig('plot24.png', dpi=400, bbox_inches='tight')\nplt.show()","13bbb93e":"import matplotlib.pyplot as plt\n \nplt.figure(figsize=(20,6))\n \nbox_plot_data=[df.payment_value,df.price]\nplt.boxplot(box_plot_data,labels=['payment_value','price'],vert=False)\nplt.title(\"Box Plots of Different Prices\")\nplt.savefig('plot25.png', dpi=400, bbox_inches='tight')\nplt.show()","ee4b03ae":"\n# Distribution of price vs freight_value per class\nplt.figure(figsize=(8,5))\nsns.set_style(\"whitegrid\")\nax = sns.scatterplot(x='price',y='freight_value', data = df, hue=\"review_score\",palette=['#2e4884','grey'])\nplt.title('Distribution of price vs freight_value per class')\nplt.show()","1f17c043":"\n# Distribution of price vs freight_value per class\nplt.figure(figsize=(8,5))\nsns.set_style(\"whitegrid\")\nax = sns.scatterplot(x='price',y='product_weight_g', data = df, hue=\"review_score\",palette=['#2e4884','grey'])\nplt.title('Distribution of price vs product_weight_g per class')\nplt.show()","d501381f":"# https:\/\/seaborn.pydata.org\/generated\/seaborn.pairplot.html\n# pair plot\nsns.set(style=\"ticks\", color_codes=True)\ng = sns.pairplot(df[['product_photos_qty','product_name_lenght','product_description_lenght','review_score']],hue='review_score',palette=['#2e4884','grey'])\ng.savefig(\"pairplot1.png\")","e0bc8f9c":"df_mm=df[['order_purchase_month_name','price']].groupby('order_purchase_month_name').sum()","b8f02a93":"pi = list(df_mm['price'])\nli = list(df_mm.index)\n#dict of months and price value\nres = {li[i]: pi[i] for i in range(len(li))}\n","843552ec":"from collections import OrderedDict\nmnths = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug','Sep','Oct','Nov','Dec']\nweeks=['Sun','Mon','Tue','Wed','Thu','Fri','Sat']\nres = dict(OrderedDict(sorted(res.items(),key =lambda x:mnths.index(x[0]))))#sorting by month\nprint(res)","bc697837":"temp_3= pd.DataFrame(df.groupby('order_purchase_month_name')['review_score'].agg(lambda x: x.eq(1).sum())).reset_index()\n\n# Pandas dataframe grouby count: https:\/\/stackoverflow.com\/a\/19385591\/4084039\n\n\ntemp_3['total'] = list(pd.DataFrame(df.groupby('order_purchase_month_name')['review_score'].agg([('total','count'),('Avg','mean')]))['total'])\ntemp_3['Avg']   = list(pd.DataFrame(df.groupby('order_purchase_month_name')['review_score'].agg([('total','count'),('Avg','mean')]))['Avg'])\ntemp_3= temp_3.sort_values(by=['total'], ascending=True)","25499002":"rem = {list(temp_3.order_purchase_month_name)[i]: list(temp_3.total)[i] for i in range(len(temp_3))}\nrem = dict(OrderedDict(sorted(rem.items(),key =lambda x:mnths.index(x[0]))))\nprint(rem)","91a4a530":"#https:\/\/matplotlib.org\/2.2.5\/gallery\/api\/two_scales.html\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nsns.set_style(\"whitegrid\")\n\n\nfig, ax1 = plt.subplots()\n\ncolor = 'grey'\nax1.set_xlabel('Month')\nax1.set_ylabel('price', color=color)\nax1.plot(list(res.keys()),list(res.values()), color=color)\nax1.plot(list(res.keys()),list(res.values()),'C0o', alpha=0.5,color='grey')\nax1.tick_params(axis='y', labelcolor=color)\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n\ncolor = '#2e4884'\nax2.set_ylabel('orders', color=color)  # we already handled the x-label with ax1\nax2.plot(list(res.keys()),list(rem.values()), color=color)\nax2.plot(list(res.keys()),list(rem.values()),'C0o', alpha=0.5,color='#2e4884')\nax2.tick_params(axis='y', labelcolor=color)\n#creating  points \n\n\nfig.tight_layout( )  # otherwise the right y-label is slightly clipped\nplt.show()","5ba83713":"# Reading in the reviews dataset\nreview_df = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_order_reviews_dataset.csv')\nreview_df.head()\nreview_df.shape","1c7350be":"review_data_title = review_df['review_comment_title']\nreview_data = review_df.drop(['review_comment_title'],axis=1)\n\n# Dropping NaN values\nreview_data  = review_data.dropna()\nreview_data_title = review_data_title.dropna()","2a8800b6":"# Resetting the reviews index and visualizing the data\nreview_data = review_data.reset_index(drop=True)\nreview_data.head(3)\nreview_data.shape","44932a71":"\n# Resetting the reviews titles index and visualizing the data\nreview_data_title = review_data_title.reset_index(drop=True)\nreview_data_title.head(3)\nreview_data_title.shape","870054af":"comments = []\nstop_words = set(stopwords.words('portuguese'))\n\n\nfor words in review_data['review_comment_message']:\n    only_letters = re.sub(\"[^a-zA-Z]\", \" \",words)\n    tokens = nltk.word_tokenize(only_letters) #tokenize the sentences\n    lower_case = [l.lower() for l in tokens] #convert all letters to lower case\n    filtered_result = list(filter(lambda l: l not in stop_words, lower_case)) #Remove stopwords from the comments\n    comments.append(' '.join(filtered_result))","3ae100c6":"\n#Using wordcloud to visualize the comments\nunique_string=(\" \").join(comments)\nwordcloud = WordCloud(width = 2000, height = 1000,background_color='white').generate(unique_string)\nplt.figure(figsize=(20,12))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.savefig('plot23.png', dpi=400, bbox_inches='tight')\nplt.show()","5b9144b9":"#further checking by Counting the words\nfrom collections import Counter\nwords = (\" \".join(review_data['review_comment_message'])).lower().split()\ncounts = Counter(words)","ba22b3be":"print(\"Most frequent words:\")\nsorted(counts.items(), key=lambda x: x[1], reverse=True)[:15]","e9d4a97e":"print(\"Least frequent words:\")\nsorted(counts.items(), key=lambda x: x[1], reverse=False)[:15]","a1888947":"\n#  google translate(from portuguese to english)\nfrom google_trans_new import google_translator\ntranslator = google_translator()\ntranslate_text = translator.translate('o,e,produto,a',lang_tgt='en',lang_src='pt' )\nprint(translate_text)","4d3887b9":"# Getting the number of words by splitting them by a space\nwords_per_review = df.review_comment_message.apply(lambda x: len(x.split(\" \")))\nplt.figure(figsize=(10,6))\nwords_per_review.hist(bins = 100)\nplt.xlabel('Review Length (words)')\nplt.ylabel('Frequency')\nplt.show()","a61eedfd":"# https:\/\/towardsdatascience.com\/recency-frequency-monetary-model-with-python-and-how-sephora-uses-it-to-optimize-their-google-d6a0707c5f17\nPRESENT = datetime(2018,9,3)\nrfm= df.groupby('customer_unique_id').agg({'order_purchase_timestamp': lambda date: (PRESENT - date.max()).days,\n                                        'order_id': lambda num: len(num),\n                                        'payment_value': lambda price: price.sum()})\nrfm.columns=['recency','frequency','monetary']\nrfm['recency'] = rfm['recency'].astype(int)\nrfm['frequency'] = rfm['frequency'].astype(int)\nrfm['monetary'] = rfm['monetary'].astype(float)\n","73b6659e":"rfm.head()","1bb4b0a2":"# Plot RFM distributions\nplt.figure(figsize=(12,10))\n# Plot distribution of R\nplt.subplot(3, 1, 1); sns.distplot(rfm['recency'],color='black')\n# Plot distribution of F\nplt.subplot(3, 1, 2); sns.distplot(rfm['frequency'],color='black')\n# Plot distribution of M\nplt.subplot(3, 1, 3); sns.distplot(rfm['monetary'],color='black')\n# Show the plot\nplt.show()","93a834d5":"# Create labels for Recency and Frequency\ndef partition(x):\n    if x < 10:\n      return 1\n    if 10<=x<=35:\n      return 2\n    if 35<x<=50:\n      return 3\n    if 50<x<=75:\n      return 4      \n\nrfm['f_quartile']=rfm['frequency'].map(lambda cw : partition(cw) ) \n    \n# checking the review score now\nrfm.f_quartile.value_counts()\nr_labels = range(4, 0, -1);m_labels= range(1,5)\n\nrfm['r_quartile'] = pd.qcut(rfm['recency'], 4, r_labels)\nrfm['m_quartile'] = pd.qcut(rfm['monetary'], 4, m_labels)","af878818":"rfm['RFM_Score'] = rfm.r_quartile.astype(str)+ rfm.f_quartile.astype(str) + rfm.m_quartile.astype(str)\nrfm.head()","e6bf6628":"rfm_count_unique = rfm.groupby('RFM_Score')['RFM_Score'].nunique()\nprint(rfm_count_unique.sum())\nrfm['RFM_Score_s'] = rfm[['r_quartile','f_quartile','m_quartile']].sum(axis=1)\nprint(rfm['RFM_Score_s'].head())","939c2f0b":"# Define rfm_level function\ndef rfm_level(df):\n    if df['RFM_Score_s'] >= 9:\n        return 'Can\\'t Loose Them'\n    elif ((df['RFM_Score_s'] >= 8) and (df['RFM_Score_s'] < 9)):\n        return 'Champions'\n    elif ((df['RFM_Score_s'] >= 7) and (df['RFM_Score_s'] < 8)):\n        return 'Loyal'\n    elif ((df['RFM_Score_s'] >= 6) and (df['RFM_Score_s'] < 7)):\n        return 'Potential'\n    elif ((df['RFM_Score_s'] >= 5) and (df['RFM_Score_s'] < 6)):\n        return 'Promising'\n    elif ((df['RFM_Score_s'] >= 4) and (df['RFM_Score_s'] < 5)):\n        return 'Needs Attention'\n    else:\n        return 'Require Activation'\n# Create a new variable RFM_Level\nrfm['RFM_Level'] = rfm.apply(rfm_level, axis=1)\n# Print the header with top 5 rows to the console\nrfm.head()","11ee4b17":"# Calculate average values for each RFM_Level, and return a size of each segment \nrfm_level_agg = rfm.groupby('RFM_Level').agg({\n    'recency': 'mean',\n    'frequency': 'mean',\n    'monetary': ['mean', 'count']\n}).round(1)\n# Print the aggregated dataset\nprint(rfm_level_agg)\nrfm_level_agg.columns = rfm_level_agg.columns.droplevel()","e39dfbab":"import squarify\n\nrfm_level_agg.columns = ['RecencyMean','FrequencyMean','MonetaryMean', 'Count']\n#Create our plot and resize it.\nfig = plt.gcf()\nax = fig.add_subplot()\nfig.set_size_inches(16, 9)\nsquarify.plot(sizes=rfm_level_agg['Count'], \n              label=['Can\\'t Loose Them',\n                     'Champions',\n                     'Loyal',\n                     'Needs Attention',\n                     'Potential', \n                     'Promising', \n                     'Require Activation'], alpha=.9,color=['#f0f0f0','#d2d2d2','#b4b4b4','#a5a5a5','#969696','#425a90','#2e4884'])\nplt.title(\"RFM Segments\",fontsize=18)\nplt.axis('off')\nplt.show()","b5c76ba9":"pip install squarify","f668c351":"rfm.head()","14d9e0c7":"* The  above box plots are showing the distribution of  the numerical features product_width_cm, product_height_cm and product_width_cm. These features are overlapping each other.\n\n* Now, let us go and do some bivariate analysis and see if we use more than one feature at time, can we come with something to classify these features.","5aca9d31":"# 3.2.3.Bivariate Analysis","8f0f0aa3":"* The above distribution plot shows the distribution of freight_value for both the postive and negative classes. We can observe that there is almost completely overlap of both the distribution for positive and negative class which suggests that it is not possible to classify them based only on freight_value feature.","92f31e3b":"# 3.2.5. Text Analysis","223e8655":"Obervation(s):\n\n* From the above two scatter plots titled `Distribution of price vs freight_value per class` and `Distribution of price vs freight_value per class` respectively, It is very hard to say anything about the reviews on the basis of these plot as data-points are not seperable based on reviews these are completely mixed data.\n","ccb5d578":"# 3.2.2 Univariate Analysis on Numerical Features\n* Price","4224f1d4":"# 3. Exploratory Data Analysis","b25d3eb2":"<h3>2.1.1. Data Overview<\/h3>","fcd838ab":"Observation(s):\n* The word cloud for the review_messages are shown above.The messages are in Portuguese language and the most frequent words are antes prazo,produto entregue,produto chegou e.t.c.\n\n* The most frequent word is ```'o'``` which means ```The``` , other frequent words are ``` e,produto,a``` which means ``` and, product,the``` respectively.","2469346e":"# Customer Satisfaction Prediction on Brazilian E-Commerce Public Dataset by Olist","61eadb54":"### 3.2.6. RFM -Analysis","e7f0749b":"<h1>2. Machine Learning Formulation<\/h1>\n\n","10b5ed70":"Observation(s):\n\n* From the avove stack plot of reviews per state we can conclude that most of consumers from each state has given positive reviews.In **SP** state from the total reviews of 40800 , 35791 reviews are positive reviews and for **RJ** state 9968 reviews are positive from the total reviews 12569.The consumer_state can be our important feature for the problem.\n\n\n","026bedaf":"* freight_value","7af3e253":"* payment_value","d40bbd6a":"### Observation(s):\n\n* The maximum number of null-values are present in reviews dataset and the name of the columns with the null-values are review_comment_title and review_comment_message.\n* products dataset contains least number of null- values but most of its columns has null-values.\n* we have to deal with these null-values in future.\n","6acfd8f3":"## Conclusions:\n\n* The target variable\/class-label is imbalanced.We should be carefull while choosing the performance metric of the models.\n* From the Correlation matrix we found that there is a strong positive correlation between: (payment_value and price), (product_weight_g and freight_value also with product_width_cm), (product_length_cm and product_width_cm), (product_height_cm and product_weight_g).But most of the features doesnot seems to be helpful  for the classification.\n\n* From the univariate analysis of payment_type we observed that 96 % of the user used credit card and boleto and concluded that this can be our important feature.\n\n* Also,from the univariate analysis of consumer_state we found that 42% of total consumers are from the SP(S\u00e3o Paulo), 12.9 % are from RJ(Rio de Janeiro) and 11.7 % are from MG(Minas Gerais).\n\n* After analysing the product_category feature we observed  that the most ordered products is from bed_bath_table category ,health beauty and sports_leisure between 2016 and 2018.The least ordered products are from security_and_services.\n\n* The different timestamps seems to be important features as many new features can be explorated from these.we observed within 2016-18 the total number of order received  is incresing till 2017-11 and after that there small decrement.from the month, day and time we observed the most number of orders are received in the month of feb , on monday and afternoon time.\n\n* The numerical features like price, payment_value, freight_value,product_height_cm,product_length_cm doesnot seems to be  helpful for this classification problem as observed from univariate and bivarate analysis.\n\n* As review_message can be important feature for this problem,basic analysis of the text is done and found that the most frequent words are 'o', 'e','produto','a' e.t.c.\n\n* RMF Analyis is also done to understand weather new features can be created from this or not and we found that one numerical feature or categorical feature can be extracted from this.\n","a0ebc6bf":"\n\n* For a given historical data of the customer predict the review score for the next order or purchase.\n\n* This problem statement can be further modified into *to* predict the customer satisfaction (positive or negative) for the purchase made from the brazilain e-commerce site Olist. \n","1011155d":"Olist is an e-commerce site of Brazil which provides a better platform to connect merchants and their product to the main marketplace of Brazil. Olist released this dataset on kaggle in Nov 2018. The data-set has information of 100k orders from 2016 to 2018 made at multiple marketplaces in Brazil. Its features allow viewing an order from multiple dimensions: from order status, price, payment and freight performance to customer location, product attributes and finally reviews written by customers. A Geo-location data-set that relates Brazilian zip codes to lat\/long coordinates has also been released.\n\nOlist is one of the largest department stores in Brazillian marketplaces. It provides good services for the merchants  to sell their products through the Olist Store and ship them directly to the customers using Olist logistics partners.Its business is based on interaction between consumer ,olist store and the seller.At first an order is made by the consumer on the olist site.This order is received by olist store ,based on the information of the order (like product category,geolocation,mode of payment e.t.c) a notification is forwarded to the sellers. After that product is received from the seller and delivered to the consumer within the estimated delivery time. Once the customer receives the product, or if the estimated delivery date is due, the customer gets a satisfaction survey by email where he can give a note for the purchase experience and write down some comments.\n","c97e6542":"##3.2.2 Univariate Analysis on different Timestamps","334c1cbf":"### Observation(s):\n\n* products dataset has maximum number of numerical features(i.e dtype :'int16', 'int32', 'int64', 'float16', 'float32', 'float64').\n* orders dataset has maximum number of features of object dtype \n* We can also observe that all the timestamps are in object datatypes.So, we have to convert it into datetime type to do  analysis on these features.","85144acb":"## 3.2.1. High level Statistics","8e17c396":"* product_height_cm","a13180cd":"Observation(s):\n* From the first plot titled  Top selling product categories we can conclude that most ordered products is from bed_bath_table category ,health beauty and sports_leisure between 2016 and 2018.The least ordered products are from security_and_services.\n\n* The second plot is stack plot which shows the total reviews and the reviews with positive sense.from this plot we can conclude that most of the reviews for the product category bed_bath_table are positive and it is same for the other product categories.This can be our important categorical feature for the problem.","61bfb58b":"Obsrervation(s):\n\nNote: **Baleto** ==> Boleto Banc\u00e1rio, simply referred to as Boleto (English: Ticket) is a payment method in Brazil regulated by FEBRABAN, short for Brazilian Federation of Banks.It can be paid at ATMs, branch facilities and internet banking of any Bank, Post Office, Lottery Agent and some supermarkets until its due date. \n* from the above plots we can observe that most of the orders are paid using credit card and the second most used payment method is boleto.\n\n* The percentage of each mode of payment is shown in pie chart which shows amonst the all payments made by the user the credit card is used by 75.9% of the users, baleto is used by 19.9% of the user and 3.2% of the user used voucher and debit card.\n\n","83f530c8":" Observation(s):\n\n* We can observe from the above stacked plot that most of the customer who used credit card have given positive reviews.Also, for the boleto, voucher and the debit card user it is same.From this we can conclude that this can be our important categorical feature for the problem.\n\n\n\n\n","927deb59":"Metric(s): \n* Macro f1-score \n* Binary Confusion Matrix","d8d5e163":"Observation(s):\n* Most of the consumer given order of any  products only for  one times and few consumers are also present who oredred products more than 35 times. From this we can say order frequecy can be used as important feature for the problem.","61acd572":"* we can observe from the above plots that 96 % of the user used credit card and boleto.With credit card , boleto and voucher it covers 98% of users. Now let us see,how it is related with the target variable i.e review score.Or we can say 98% chance that the customer will use credit_card or boleto or voucher.","7a30850d":"### 3.1 Data Cleaning and Preprocessing\n3.1.1. Reading datas \n\n\n\n\n\n","61923ab8":"Observation(s):\n* It can be observed that the maximum number of orders are delivered in 7 days few orders are also delivered in more than 30 days.The total deliver time can be a new feature to solve this problem.","67ee7079":"3.1.3. Handling missing values","9288c352":"Observation(s)\n* There are three density plots of recency, frequency and monetary are plotted.From the first plot  of recency we can observe that most of the users stayed with olist for long duration which is positive thing but order frequency is less.\n\n* from the second plot of frequency most number of transaction or order is less than 5. from the third plot of monetary the maximum amount spend over the given very period is seems to less than 1500 approx.","b92b3c67":"Handling Missing values in Timestamps\n\n* The order of different types of timestamps are shown below:\n\n\n    order_purchase_timestamp-->order_approved_at--> order_delivered_carrier_date-->order_delivered_customer_date-->order_estimated_delivery_dat\n    e     \n\n* Timestamps containg missing values are order_approved_at, order_delivered_carrier_date, order_delivered_customer_date.\n\n* null-values in order_approved_at can be replaced by order_purchase_timestamp and null-values in order_delivered_customer_date can be replaced by order_estimated_delivery_date \n* we can drop the column order_delivered_carrier_date.","d21c4b57":"* Evolution of price and the total orders per month","c50b6b55":"# 3.2.4 Multivariate Analysis","0d92a0da":"<h2>2.1.2. Data Description<\/h2>","b5d11176":"* Box Plot","50229f82":"\nEach feature or columns of different csv files are described below:\n\n* The  `olist_customers_dataset.csv` contain following features:\n\nFeature | Description \n----------|---------------\n**customer_id** | Id of the consumer who made the purchase.\n**customer_unique_id**    | Unique Id of the consumer.\n**customer_zip_code_prefix** | Zip Code of the location of the consumer.\n**customer_city** | Name of the City from where order is made.\n**customer_state** |  State Code from where order is made(Ex- sao paulo-SP).\n\n* The `olist_sellers_dataset.csv` contains following features:\n\nFeature | Description \n----------|---------------\n**seller_id** |   Unique Id of the seller registered in olist.\n**seller_zip_code_prefix** | Zip Code of the location of the seller.\n**seller_city** | Name of the City of the seller.\n**seller_state** | State Code (Ex- sao paulo-SP)\n\n\n* The `olist_order_items_dataset.csv`  contain following features:\n\nFeature | Description \n----------|---------------\n**order_id** | A unique id of order made by the consumers.\n**order_item_id** | A Unique id given to each item ordered in the order.\n**product_id** |A unique id given to each product available on the site.\n**seller_id** | Unique Id of the seller registered in olist.\n**shipping_limit_date** | The date before which shipping of the ordered    product must be completed.\n**price** | Actual price of the products ordered .\n**freight_value** | Price rate at which a product is delivered from one point to another. \n\n* The `olist_order_payments_dataset.csv` contain following features:\n\nFeature | Description \n----------|---------------\n**order_id** | A unique id of order made by the consumers.\n**payment_sequential** | sequences of the payments made in case of EMI.\n**payment_type** |  mode of payment used.(Ex-Credit Card)\n**payment_installments** | number of installments in case of EMI purchase.\n**payment_value** | Total amount paid for the purshase order.\n\n\n\n* The `olist_orders_dataset.csv`  contain following features:\n\nFeature | Description \n----------|---------------\n**order_id** | A unique id of order made by the consumers.\n**customer_id** | Id of the consumer who made the purchase.\n**order_status** | status of the order made i.e delivered, shipped etc.\n**order_purchase_timestamp** | Timestamp of the purchase.\n**order_approved_at** | Timestamp of the order approval.\n**order_delivered_carrier_date** | delivery date at which carrier made the delivery.\n**order_delivered_customer_date** | date at which customer got the product.\n**order_estimated_delivery_date** | estimated delivery date of the products.\n\n\n* The `olist_order_reviews_dataset.csv`  contain following features:\n\nFeature | Description \n----------|---------------\n**review_id** |Id of the review given on the product ordered by the order id.\n**order_id** |  A unique id of order made by the consumers.\n**review_score** | review score given by the customer for each order on the scale of 1\u20135. \n**review_comment_title** | Title of the review\n**review_comment_message** | Review comments posted by the consumer for each order.\n**review_creation_date** |Timestamp of the review when it is created.\n**review_answer_timestamp** | Timestamp of the review answered.\n\n\n* The `olist_products_dataset.csv` contain following features:\n\nFeature | Description \n----------|---------------\n**product_id** | A unique identifier for the proposed project.\n**product_category_name** | Name of the product category\n**product_name_lenght** | length of the string which specify the name given to the products ordered.\n**product_description_lenght** | length of the description written for each product ordered on the site.\n**product_photos_qty** | Number of photos of each product ordered available on the shopping portal.\n**product_weight_g** | Weight of the products ordered in grams.\n**product_length_cm** | Length of the products ordered in centimeters.\n**product_height_cm** | Height of the products ordered in centimeters.\n**product_width_cm** | width of the product ordered in centimeters.\n\n\n\n\n\n","215a0270":"<h2>1.4. Real-world\/Business objectives and constraints.<\/h2>","74457ee4":"Observation(s):\n* Based on the RFM_Score_s all customers are categorised into 7 categories :\n\n```\n'Can\\'t Loose Them' ====  RMF_Score_s  \u2265  9\n'Champions' ==== 8 \u2264 RMF_Score_s < 9\n'Loyal' ==== 7 \u2264 RMF_Score_s <8\n'Needs Attention' ==== 6 \u2264 RMF_Score_s <7\n'Potential' ==== 5 \u2264 RMF_Score_s < 6\n'Promising' ==== 4 \u2264 RMF_Score_s < 5 \n'Require Activation' RMF_Score_s <4\n```\n\n* From the above square plot the highest percentage of customers lie within area of category potential.Few areas also there with colored in blue scale which show the percentage of comsumers which requries more attention so that they can retain in olist.\n\n* We can use either RMF_Score_s or RMF_Level as feature to solve this problem.","9f4ce05e":"3.1.2. Checking datasets info()(Rows,columns,dtypes of columns ,missing Values (Null-values))","ce82c530":"Observation(s):\n\n* The first plot shows that 97.8% of the orders of status delivered and remaining precentage are with status shipped,canceled,invoiced,processing,unavailable and approved.\n\n* The second plot shows that for the order_status delivered most of the order are with positive reviews i.e 85% and only 12.8% are negative reviews.\n","b4583d6a":"Observation(s):\n* from the above plot we can observe that the number of purchase is increasing from 201609 to 201711(highest) and then decreases for a short sapn which means the either orders from the older customers are increasing or the number of consumers are increasing.","dfdab0fb":"### Observation(s):\n\n* Dataset with maximum number of columns is products.\n* Dataset with maximum number of rows is geolocations","92cc6a40":"### 2.2 Mapping the real world problem to an ML problem \n* Here, the objective is to predict the customer satisfaction score for a given order based on the given features like price, item description, on time delivery, delivery status etc.\n\n\n\n* The given problem can be solved as either by multiclass classification problem(predict score [1,2,3,4,5] ), binary classification problem(0 as negative of 1 as positive)  or Regression problem(for predicting scores)\n\n","c24998ed":"<h2> 1.2. Problem Statement <\/h2>","6e4c6c35":"<h1>1. Business\/Real-world Problem<\/h1>","2d21dda4":"* The above distribution plot shows the distribution of product_weight_g for both the postive and negative classes. We can observe that most of the product has weight less than 5000 gm .Also, there is almost completely overlap of both the distribution for positive and negative class which suggests that it is not possible to classify them based only on product_weight_g feature.","94f186c9":"#### 3.1.4 Data Dedublicate","0756dd15":"* from the above plots we can observe that there is same pattern of total sales and the total order per month between 016 and 2018.","88ab6dee":"Observation(s):\n* From the subplot titled Total Reviews by Month we can observe that the highest % of positive reviews amongst the total reviews between 2016 to 2018 are given on the month of feb i.e 9.8%.In the month of May and July amongst the total reviews there are more than 9.0% reviews are positive.\n\n* From the second subplot titled Total Reviews by Time of the day ,we can conclude that maximum number of orders are received in afternoon and the highest % of positive reviews are given on that time i.e 32.8%.\n\n* From the third subplot titled Total Reviews by day of the week  ,we can conclude that maximum number of orders are received on Monday and the highest % of positive reviews are given on that day  and Tuesday i.e 13.9%.\n\n","3b42b833":"\n* No latency-latency requirement.\n\n* Interpretability of the model can  be useful for understanding customer\u2019s behaviour.","e8bc8074":"## 3.2.2 Univariate Analysis: product_category_name_english\n","a40ba675":"##3.2.2 Univariate Analysis: Customer count based on State wise\n\n![alt text](https:\/\/st4.depositphotos.com\/1374738\/23094\/v\/950\/depositphotos_230940566-stock-illustration-map-brazil-divisions-states.jpg)\n\n[link text](https:\/\/)\n- Image Source : https:\/\/st4.depositphotos.com\/1374738\/23094\/v\/950\/depositphotos_230940566-stock-illustration-map-brazil-divisions-states.jpg","5d2741ba":"<h2>2.1. Data<\/h2>","88659eca":"## 3.2.2. Uivariate Analysis: payment_type","a8e46fc0":"#### 2.2.2 Performance Metric ","fcf037b7":"Observation(s):\n\n* 42% of total consumers are from the SP(S\u00e3o Paulo), 12.9 % are from RJ(Rio de Janeiro) and 11.7 % are from MG(Minas Gerais) which means most of consumers are from these states.Also from the above map we can observe these are neighbouring staes these staes are most active.Now, Let us see what type of reviews are given from the consumer of these states.\n\n\n\n","595a2319":"<h2>1.3 Source\/Useful Links <\/h2>","a88fa305":"\nObservation(s):\n\n* We can observe from the above plots 85.5% of the total reviews are positive i.e. 1 and only 14.5% reviews are negative i.e. which means that the given data set is imbalanced dataset.","ef7353ad":"**What is RFM?**\n\nBehavioral segmentation by 3 important features:\n\nRecency \u2014 number of days since the last purchase\n\nFrequency \u2014 number of transactions made over a given period\n\nMonetary \u2014 amount spent over a given period of time\n\nMore details - https:\/\/towardsdatascience.com\/recency-frequency-monetary-model-with-python-and-how-sephora-uses-it-to-optimize-their-google-d6a0707c5f17","6237672a":"## 3.2 Data Analysis\n\n\n\n\n\n\n","d8d41fa9":"3.1.3. Merging all *datasets*","4e0c65a3":"Source:- https:\/\/www.kaggle.com\/olistbr\/brazilian-ecommerce\n\nUploaded In the Year : 2018\n\nprovided by : Olist Store","42a52911":"Observation(s):\n* From the first plot titled Number of orders per month-year show the total number order received per month on each each between 2016 and 2018.It can be observeed that in the month of November in the year 2017 the highest number of orders are received which is more the 7000 approx. and the leat number of orders are received in the month of Dec in the year 2016.\n\n* The second plot shows the total number of positive and negative reviews given for each order  per month-year.It can observed that  most the orders have given positive reviews.From the above plot we observed that on NOV-17 the highest orders were received but from the second plot we can see the highest positive reviews were given on May-18","f151d8b8":"Observation:\n* After comparing different ids it can be observed that the highest number of unique id is of customers and least is from sellers","17bd092f":"* The above distribution plot shows the distribution of price for both the postive and negative classes. We can observe that there is almost completely overlap of both the distribution for positive and negative class which suggests that it is not possible to classify them based only on price feature.","cb5eeb2a":"Observation(s):\n\n* The pair plot shown above for the features product_photos_qty, product_name_length,product_description_length as these have negative correlation values with the review_score column.All the scatter plots between the features are completely mixed up not separable on the basis of reviews.We can say that none of these features are helpful for the classification.","b4a09ea9":"Observation(s):\n\n* We can observe from the above table except customer_zip_code_prefix, order_item_id and review_score features we have 12 numerical features in our final dataset.\n\n* Also,We can observe the statistics like percentile values , mean and standard deviation values, count , min and max of the numerical featues.For payment_value, the maximum payment value of an order is 13664 Brazilian real.\n\n* For the price and freight value of an order. The maximum price of an order is 6735 while max freight is  around 410 Brazilian real. The average price of an order is around 125 Brazilian real and frieght value is around 20 Brazilian real. The order with minimum price of 0.85 Brazilian real have been made. \n\n* Similarly, we can observe the other features further we will see the  distribution of these features and see how they are  helping  in classifying the class labels and find other insights. ","695a8f58":"Observation(s):\n* the final merged dataset has no null values.\n* total number of columns is 32.\n        dtype           |   number of columns\n        ----------------|-------------------\n        datetime64[ns]  |      4\n                        |\n        float64(10)     |      10\n                        |\n        int64           |      5\n                        |\n        object          |      13   ","a14bfbd8":"* The above distribution plot shows the distribution of product_height_cm for both the postive and negative classes. We can observe that most of the product has height less than 20 .Also, there is almost completely overlap of both the distribution for positive and negative class which suggests that it is not possible to classify them based only on product_height_cm feature.","d5fc86fb":"product_weight_g","a7ba1ae5":"### 3.2.2 Univariate Analysis: Order_status","2dc40798":"\nThe data is divided in multiple datasets for better understanding and organization. \n\n<img src=\"https:\/\/i.ibb.co\/RhqCYmR\/68747470733a2f2f692e696d6775722e636f6d2f485268643259302e706e67.png\" alt=\"68747470733a2f2f692e696d6775722e636f6d2f485268643259302e706e67\" border=\"0\">\n\n","c9c282b2":"Observation(s):\n\n* There is a strong positive correlation between: (payment_value and price), (product_weight_g and freight_value also with product_width_cm), (product_length_cm and product_width_cm), (product_height_cm and product_weight_g).\n","053f7a0e":"* The above distribution plot shows the distribution of payment_value for both the postive and negative classes. We can observe that there is almost completely overlap of both the distribution for positive and negative class which suggests that it is not possible to classify them based only on payment_value feature.","fbd361b4":"###3.2.2. Uivarite Analysis:frequency of orders Vs Number of Consumers","955050a6":"<h2>1.1 Description<\/h2>","60f63bf7":"#### 2.2.1 Type of Machine Leaning Problem\n* Here ,the problem is mapped to the Binary Classification Problem to solve it."}}