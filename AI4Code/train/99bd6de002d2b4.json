{"cell_type":{"40e2dc81":"code","27d117a5":"code","edfb22e9":"code","8648b6a8":"code","85f93a8c":"code","983adcab":"code","f54e8f6e":"code","39428d65":"code","80480dab":"code","0ab30165":"code","c9ef302d":"code","e7eb128b":"code","c4b8b13d":"code","59ff436b":"code","ad1d955f":"code","a13cf089":"code","532f5733":"code","f44355d5":"code","3a972429":"markdown","b9e3374c":"markdown","8424da3d":"markdown","21f348e8":"markdown","f3ebc927":"markdown","cea2237b":"markdown","628e25bb":"markdown","4819875e":"markdown","15d99405":"markdown","f7623878":"markdown","6f59bb41":"markdown","59d4d0b3":"markdown","d88ea27b":"markdown"},"source":{"40e2dc81":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import confusion_matrix\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","27d117a5":"# laod data from numpy file\nX = np.load('..\/input\/sign-language-digits-dataset\/X.npy')\ny = np.load('..\/input\/sign-language-digits-dataset\/Y.npy')\n","edfb22e9":"# reshape X\nX = X.reshape(-1,64,64,1)\n\nprint(\"X Shape:\",X.shape)\nprint(\"Y Shape:\",y.shape)","8648b6a8":"plt.figure(figsize=(20,6))\n\nfor i,j in enumerate([0,205,411,617,823,1030,1237,1444,1650,1858]):\n    plt.subplot(2,5,i+1)\n    plt.subplots_adjust(top = 2, bottom = 1)\n    plt.imshow(X[j].reshape(64,64))\n    plt.title(np.argmax(y[j]))\n    plt.axis('off')\n","85f93a8c":"list_y = []\nlist_y = [np.where(i == 1)[0][0] for i in y]\ncount = pd.Series(list_y).value_counts()\nprint(count)","983adcab":"plt.figure(figsize = (10,5))\nsns.countplot(np.array(list_y))\nplt.show()","f54e8f6e":"X_organized = np.concatenate((X[204:409,:],\n                              X[822:1028,:],\n                              X[1649:1855,:],\n                              X[1443:1649,:],\n                              X[1236:1443,:],\n                              X[1855:2062,:],\n                              X[615:822,:],\n                              X[409:615,:],\n                              X[1028:1236,:],\n                              X[0:204,:]),axis = 0)\n","39428d65":"plt.figure(figsize=(20,6))\n\nfor i,j in enumerate([0,205,411,617,823,1030,1237,1444,1650,1858]):\n    plt.subplot(2,5,i+1)\n    plt.subplots_adjust(top = 2, bottom = 1)\n    plt.imshow(X_organized[j].reshape(64,64))\n    plt.title(np.argmax(y[j]))\n    plt.axis('off')","80480dab":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test = train_test_split(X_organized,y,test_size = 0.2,random_state = 42)\n\nprint(\"x_train shape:\",x_train.shape)\nprint(\"x_test shape:\",x_test.shape)\nprint(\"y_train shape:\",y_train.shape)\nprint(\"y_test shape:\",y_test.shape)","0ab30165":"from keras.preprocessing.image import ImageDataGenerator","c9ef302d":"def show_new_samples(new_images):\n    plt.figure(figsize=(20,6))\n    for i in range(10):\n        plt.subplot(2,5,i+1)\n        image = new_images.next()\n        plt.imshow(image[0].reshape(64,64))\n        plt.axis('off')\n    \n    plt.show()","e7eb128b":"#Changin zoom level\ndatagen = ImageDataGenerator(zoom_range = 0.5)\nnew_images = datagen.flow(x_train,batch_size = 250)\nshow_new_samples(new_images)","c4b8b13d":"# Changing rotaion \ndatagen = ImageDataGenerator(rotation_range = 45)\nnew_images = datagen.flow(x_train,batch_size = 250)\nshow_new_samples(new_images)","59ff436b":"# Changing rotaion, zoom \ndatagen = ImageDataGenerator(zoom_range = 0.5,rotation_range = 45)\nnew_images = datagen.flow(x_train,batch_size = 1)\nshow_new_samples(new_images)","ad1d955f":"# load libraries\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, MaxPool2D, Conv2D, Flatten\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator","a13cf089":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (9,9),padding = 'Same', activation ='relu', input_shape = (64,64,1)))\nmodel.add(MaxPool2D(pool_size=(5,5)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (7,7),padding = 'Same', activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(4,4), strides=(3,3)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters = 128 , kernel_size = (5,5),padding = 'Same',activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dense(10, activation='softmax'))\n\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n\ndatagen = ImageDataGenerator(zoom_range = 0.5,rotation_range = 45)\ndatagen.fit(x_train)\n\nhistory = model.fit(datagen.flow(x_train,y_train, batch_size=250),epochs = 100, validation_data = (x_test,y_test))","532f5733":"plt.figure(figsize = (10,5))\nplt.plot(history.history['val_loss'], color='b', label=\"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","f44355d5":"y_predict = model.predict(x_test)\ny_predict_classes = np.argmax(y_predict,axis = 1) \ny_true = np.argmax(y_test,axis = 1) \nconfusion_mtx = confusion_matrix(y_true, y_predict_classes) \nplt.figure(figsize = (10,10))\nsns.heatmap(confusion_mtx, annot=True,fmt= '.1f')\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","3a972429":"<a id='5'><\/a>\n## Data Augmentation With Keras API\n\nData augmentation is a technique which generates new training samples without changing labels of images. To generate new samples, some features of images are changed like brightness, rotation or zoom level. To apply it, ImageDataGenerator class is used in KERAS API. This class refers parameters and changes images. After complete the changing process, it returns new samples. This is important! ImageDataGenerator returns only new images. It means that out training dataset consists of different from original dataset. It provides more generalizaton for model anf of course it is desirable.\n\nSo, in implementation of CNN part, I will use data augmentation and I will change rotation and zoom level of images. I chose these parameters with a simple logic. Think of test data that we might encounter in real life. We don't always hold our hand at 90 degrees. So it is quite possible that we have a rotational change when using sign language. Likewise, the zoom level of the photo to be taken may also change. So I thought I could train my model better by creating a more general data set with these two parameters.  Let's take a closer look at these parameters.\n\n* **rotation_range:** Rotation augmentation randomly rotates the image clockwise by a given number between 0 and 360.\n* **zoom_range:** The percentage of the zoom can be a single float or a range as an array or tuple. If a float is specified, then the range for the zoom will be [1-value, 1+value].\n\nI will apply data augmentation with this parameters.\n* rotation = 45\n* zoom_range = 0.5\n\nBefore continue to CNN implementation, let's look some samples to see effects of data augmentation on dataset.","b9e3374c":"I will re-organize data to match labels and images correctly.\n* 204-409   => 0\n* 822-1028  => 1\n* 1649-1855 => 2\n* 1443-1649 => 3\n* 1236-1443 => 4\n* 1855-2062 => 5\n* 615-822   => 6\n* 409-615   => 7\n* 1028-1236 => 8\n* 0-204     => 9","8424da3d":"<a id='1'><\/a>\n# Load Data and PreCheck","21f348e8":"# Introduction\n\nIn this kernel, sign language digits images will be classified with Convolutional Neural Network. CNN model will be like this;\n\nconv => maxpool => dropout <br\/>\nconv => maxpool => dropout <br\/>\nconv => maxpool => dropout <br\/> \nflatten => dropout => Dense(relu) => Dense (softmax)\n\nAlso I will use data augmentation to avoid overfitting. \n\n1. [Load Data and PreCheck](#1)\n1. [Preparing Data](#2)\n1. [Train Test Split](#3)\n1. [Implemantation of CNN](#4)\n    * [Data Augmentation with Keras API](#5)\n    * [Model Implementation](6)\n1. [Conclusion](#7)\n","f3ebc927":"* Now labels and images are matched correctly.","cea2237b":"<a id='2'><\/a>\n# Preparing Data","628e25bb":"<a id='6'><\/a>\n## Model Implementation","4819875e":"* We have a balanced dataset.","15d99405":"<a id='7'><\/a>\n# Conclusion","f7623878":"* Now our test and train datasets are ready. We can start to create CNN model.","6f59bb41":"<a id='4'><\/a>\n# Implementation of CNN","59d4d0b3":"* As you can see, labels and images don't match correctly. So first of all I will re-organize them.\n* Image size is 64x64\n* There are 2062 images in dataset.","d88ea27b":"<a id='3'><\/a>\n# Train Test Split"}}