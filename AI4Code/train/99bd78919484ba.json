{"cell_type":{"8ff0dbf8":"code","984a0221":"code","98632036":"code","c755b32b":"code","a6cc4b9f":"code","9f10a6fc":"code","923cdac0":"code","5cfa7b49":"code","fd7fa911":"code","91b29801":"code","f4ecf219":"code","44af9e5c":"code","81ebf185":"code","d2521ca6":"code","8d309164":"code","01db49d9":"code","9baef4b7":"code","0c87f6ea":"code","13eee377":"code","8b0e8099":"code","a31dfa12":"code","e30e56da":"code","f38714de":"code","83c1c74d":"code","ffdc18bf":"code","777ac41c":"code","f925a1bf":"code","81de5568":"code","4136886e":"code","412cb283":"code","1f9dbc28":"code","27404e57":"code","c76c2e0d":"code","9b061f4e":"markdown","8faa9e39":"markdown","242d88fa":"markdown","744dc7ab":"markdown","98b5017d":"markdown","647b224e":"markdown","3819509b":"markdown","ce894822":"markdown","5d912e6e":"markdown","90a6c0ff":"markdown","43b86844":"markdown"},"source":{"8ff0dbf8":"import os\nimport numpy as np \nimport pandas as pd \nimport scipy.sparse as sp\nfrom itertools import islice, cycle\nfrom more_itertools import pairwise\nfrom tqdm.auto import tqdm\nimport warnings\nfrom implicit.nearest_neighbours import BM25Recommender\n\nwarnings.filterwarnings('ignore')\nos.environ['OPENBLAS_NUM_THREADS'] = '1'\nos.environ['MKL_NUM_THREADS'] = '1'\n\nprint('Dataset:')\nfor dirname, _, filenames in os.walk('..\/input\/mts-ml-summer-school'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","984a0221":"class TimeRangeSplit():\n    \"\"\"\n        https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.date_range.html\n    \"\"\"\n    def __init__(self, \n                 start_date, \n                 end_date=None, \n                 freq='D', \n                 periods=None, \n                 tz=None, \n                 normalize=False, \n                 closed=None, \n                 train_min_date=None,\n                 filter_cold_users=True, \n                 filter_cold_items=True, \n                 filter_already_seen=True):\n        \n        self.start_date = start_date\n        if end_date is None and periods is None:\n            raise ValueError(\"Either 'end_date' or 'periods' must be non-zero, not both at the same time.\")\n\n        self.end_date = end_date\n        self.freq = freq\n        self.periods = periods\n        self.tz = tz\n        self.normalize = normalize\n        self.closed = closed\n        self.train_min_date = pd.to_datetime(train_min_date, errors='raise')\n        self.filter_cold_users = filter_cold_users\n        self.filter_cold_items = filter_cold_items\n        self.filter_already_seen = filter_already_seen\n\n        self.date_range = pd.date_range(\n            start=start_date, \n            end=end_date, \n            freq=freq, \n            periods=periods, \n            tz=tz, \n            normalize=normalize, \n            closed=closed)\n\n        self.max_n_splits = max(0, len(self.date_range) - 1)\n        if self.max_n_splits == 0:\n            raise ValueError(\"Provided parametrs set an empty date range.\") \n\n    def split(self, \n              df, \n              user_column='user_id',\n              item_column='item_id',\n              datetime_column='date',\n              fold_stats=False):\n        df_datetime = df[datetime_column]\n        if self.train_min_date is not None:\n            train_min_mask = df_datetime >= self.train_min_date\n        else:\n            train_min_mask = df_datetime.notnull()\n\n        date_range = self.date_range[(self.date_range >= df_datetime.min()) & \n                                     (self.date_range <= df_datetime.max())]\n\n        for start, end in pairwise(date_range):\n            fold_info = {\n                'Start date': start,\n                'End date': end\n            }\n            train_mask = train_min_mask & (df_datetime < start)\n            train_idx = df.index[train_mask]\n            if fold_stats:\n                fold_info['Train'] = len(train_idx)\n\n            test_mask = (df_datetime >= start) & (df_datetime < end)\n            test_idx = df.index[test_mask]\n            \n            if self.filter_cold_users:\n                new = np.setdiff1d(\n                    df.loc[test_idx, user_column].unique(), \n                    df.loc[train_idx, user_column].unique())\n                new_idx = df.index[test_mask & df[user_column].isin(new)]\n                test_idx = np.setdiff1d(test_idx, new_idx)\n                test_mask = df.index.isin(test_idx)\n                if fold_stats:\n                    fold_info['New users'] = len(new)\n                    fold_info['New users interactions'] = len(new_idx)\n\n            if self.filter_cold_items:\n                new = np.setdiff1d(\n                    df.loc[test_idx, item_column].unique(), \n                    df.loc[train_idx, item_column].unique())\n                new_idx = df.index[test_mask & df[item_column].isin(new)]\n                test_idx = np.setdiff1d(test_idx, new_idx)\n                test_mask = df.index.isin(test_idx)\n                if fold_stats:\n                    fold_info['New items'] = len(new)\n                    fold_info['New items interactions'] = len(new_idx)\n\n            if self.filter_already_seen:\n                user_item = [user_column, item_column]\n                train_pairs = df.loc[train_idx, user_item].set_index(user_item).index\n                test_pairs = df.loc[test_idx, user_item].set_index(user_item).index\n                intersection = train_pairs.intersection(test_pairs)\n                test_idx = test_idx[~test_pairs.isin(intersection)]\n                # test_mask = rd.df.index.isin(test_idx)\n                if fold_stats:\n                    fold_info['Known interactions'] = len(intersection)\n\n            if fold_stats:\n                fold_info['Test'] = len(test_idx)\n\n            yield (train_idx, test_idx, fold_info)\n\n    def get_n_splits(self, df, datetime_column='date'):\n        df_datetime = df[datetime_column]\n        if self.train_min_date is not None:\n            df_datetime = df_datetime[df_datetime >= self.train_min_date]\n\n        date_range = self.date_range[(self.date_range >= df_datetime.min()) & \n                                     (self.date_range <= df_datetime.max())]\n\n        return max(0, len(date_range) - 1)\n","98632036":"def metrics_map(val, recs):\n    users_count = val.user_id.nunique()\n\n    recs = recs.explode('item_id')\n    recs['rank'] = recs.groupby('user_id').cumcount() + 1\n\n    val_recs = val.set_index(['user_id', 'item_id']).join(recs.set_index(['user_id', 'item_id']))\n    val_recs = val_recs.sort_values(by=['user_id', 'rank'])\n    val_recs['users_item_count'] = val_recs.groupby(['user_id'], sort=False)['rank'].transform(np.size)\n\n    val_recs['cumulative_rank'] = val_recs.groupby(level='user_id').cumcount() + 1\n    val_recs['cumulative_rank'] = val_recs['cumulative_rank'] \/ val_recs['rank']\n\n    mapN = (val_recs[\"cumulative_rank\"] \/ val_recs[\"users_item_count\"]).sum() \/ users_count\n#     print(f\"MAP@{TOP_N} = {mapN}\")\n    return mapN","c755b32b":"items = pd.read_csv('..\/input\/mts-ml-summer-school\/items.csv')\nitems","a6cc4b9f":"items.info()","9f10a6fc":"for i in items.iloc[:, np.where(items.dtypes == 'object')[0]].columns:\n    items[i] = items[i].str.lower()\n    items[i] = items[i].astype('category')\nitems","923cdac0":"items.info()","5cfa7b49":"users = pd.read_csv('..\/input\/mts-ml-summer-school\/users.csv')\nusers","fd7fa911":"users.info()","91b29801":"for i in ['age', 'sex']:\n    users[i] = users[i].astype('string')\n    users[i] = users[i].str.lower()\n    users[i] = users[i].astype('category')\nusers","f4ecf219":"users[users.age.isna()]","44af9e5c":"users[users.sex.isna()]","81ebf185":"df = pd.read_csv('..\/input\/mts-ml-summer-school\/interactions.csv')\ndf['start_date'] = pd.to_datetime(df['start_date'])\ndf","d2521ca6":"users.head()","8d309164":"dupls = df[df.duplicated(['user_id', 'item_id'], keep=False)]\ndf = df.drop(dupls.index)\ndupls = dupls.groupby(['user_id', 'item_id']).agg({\n                                                    'progress': 'max',\n                                                    'rating': 'max',\n                                                    'start_date': 'min'\n                                                })\ndf = df.append(dupls.reset_index(), ignore_index=True)\ndf","01db49d9":"df.item_id.value_counts()","9baef4b7":"users_inv_mapping = dict(enumerate(df['user_id'].unique()))\nusers_mapping = {v: k for k, v in users_inv_mapping.items()}\nlen(users_mapping)","0c87f6ea":"items_inv_mapping = dict(enumerate(df['item_id'].unique()))\nitems_mapping = {v: k for k, v in items_inv_mapping.items()}\nlen(items_mapping)","13eee377":"last_date = df['start_date'].max().normalize()\nfolds = 7\nstart_date = last_date - pd.Timedelta(days=folds)\nstart_date, last_date","8b0e8099":"cv = TimeRangeSplit(start_date=start_date, periods=folds+1)\ncv.date_range","a31dfa12":"folds_with_stats = list(cv.split(\n    df, \n    user_column='user_id',\n    item_column='item_id',\n    datetime_column='start_date',\n    fold_stats=True\n))\n\nfolds_info_with_stats = pd.DataFrame([info for _, _, info in folds_with_stats])\nfolds_info_with_stats","e30e56da":"sample = pd.read_csv('..\/input\/mts-ml-summer-school\/sample_submission.csv')\nsample.head()","f38714de":"class PopularRecommender():\n    def __init__(self, max_K=100, days=30, user_column='user_id', item_column='item_id', dt_column='date',\n                groupby=None, fit_na_as_common=False):\n        self.max_K = max_K\n        self.days = days\n        self.user_column = user_column\n        self.item_column = item_column\n        self.dt_column = dt_column\n        self.groupby = groupby\n        self.fit_na_as_common = fit_na_as_common\n        self.recommendations = []\n        \n    def fit(self, df, df_users=None):\n        min_date = df[self.dt_column].max().normalize() - pd.DateOffset(days=self.days)\n        data = df[df[self.dt_column] > min_date]\n        recomm_common = data[self.item_column].value_counts().head(self.max_K).index.values\n        self.recomm_common = recomm_common\n        self.df_users = df_users\n        \n        if self.groupby is not None:\n            if df_users is None:\n                print('No df_users')\n                return None\n            \n            data = data.merge(df_users, on=self.user_column, how='left')\n            self.recommendations = data.groupby(self.groupby)[self.item_column]\\\n                                       .apply(lambda x: x.value_counts().head(self.max_K).index.values)\n            # \u0435\u0441\u043b\u0438 \u043d\u0435\u0442 \u0437\u0430\u043f\u0438\u0441\u0435\u0439 \u0434\u043b\u044f \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0438, \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u043e\u0432\u0430\u0442\u044c \u043e\u0431\u0449\u0435\u0435\n            na_mask = self.recommendations.isna()\n            self.recommendations[na_mask] = self.recommendations[na_mask].apply(lambda x: recomm_common)\n            # \u043d\u0430 \u0441\u043b\u0443\u0447\u0430\u0439, \u0435\u0441\u043b\u0438 \u0441\u043f\u0438\u0441\u043e\u043a \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0439 \u0431\u0443\u0434\u0435\u0442 \u043a\u043e\u0440\u043e\u0442\u043a\u0438\u043c (\u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 \u0442\u043e\u043b\u044c\u043a\u043e 2 \u043a\u043d\u0438\u0433\u0438)\n            # \u0434\u043e\u0431\u0430\u0432\u0438\u043c \u043e\u0431\u0449\u0443\u044e \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0430\u0446\u0438\u044e\n            self.recommendations = self.recommendations.apply(lambda x: np.concatenate((x, recomm_common)))\n            # na \u0432 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f\u0445\n            if self.fit_na_as_common:\n                na_mask = (self.recommendations.reset_index()[self.groupby]=='nan').sum(axis=1)!=0\n                self.recommendations[na_mask.values] = self.recommendations[na_mask.values].apply(lambda x: recomm_common)\n        else:\n            self.recommendations = recomm_common\n        \n    def recommend(self, users=None, N=10):\n        recs = self.recommendations[:N]\n        \n        if users is None:\n            if self.groupby is not None:\n                print('For recomendations based on groupby needs used_id')\n                return None\n            return recs\n        else:\n            if self.groupby is not None:  \n                if not isinstance(users, pd.Series):\n                    users = pd.Series([users], name=self.user_column)            \n                recoms = self.recommendations.apply(lambda x: x[:N]) # \u0442\u043e\u043b\u044c\u043a\u043e N \u043f\u0435\u0440\u0432\u044b\u0445 \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0439\n                recoms = recoms.reset_index()\n                recoms[self.groupby] = recoms[self.groupby].astype('category')\n                data = users.to_frame().merge(self.df_users, on=self.user_column, how='left') # \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e \u043f\u043e \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f\u043c \u0434\u043b\u044f \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f \u043d\u0430 \u0433\u0440\u0443\u043f\u043f\u044b\n                data = data.merge(recoms, on=self.groupby, how='left') # \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0438 \u0432 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0432\u0438\u0438 \u0441 \u0433\u0440\u0443\u043f\u043f\u043e\u0439\n                # \u0435\u0441\u043b\u0438 \u0432\u0441\u0442\u0440\u0435\u0447\u0430\u0435\u0442\u0441\u044f \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u0430\u044f \u0433\u0440\u0443\u043f\u043f\u0430, \u0442\u043e \u043f\u0440\u0435\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0431\u0443\u0434\u0443\u0442 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0430\u043c\u0438. \u0417\u0430\u043f\u043e\u043b\u043d\u0438\u0442\u044c \u0438\u0445 \u043e\u0431\u0449\u0438\u043c\u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\u043c\u0438 \u043f\u043e \u0432\u0441\u0435\u043c\u0443 \u043d\u0430\u0431\u043e\u0440\u0443\n#                 print(data.loc[0:1].T.apply(lambda x: list(set(x['item_id'].tolist()))))# - set(data[data.user_id == x.user_id].item_id)))\n                na_mask = data.iloc[:, -1].isna()\n                data.iloc[:, -1][na_mask] = data.iloc[:, -1][na_mask].apply(lambda x: self.recomm_common[:N])\n\n                return data.iloc[:, -1].values.tolist()\n            \n            else: # \u0435\u0441\u043b\u0438 \u043d\u0435 \u0431\u044b\u043b\u043e \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f \u043d\u0430 \u0433\u0440\u0443\u043f\u043f\u044b\n                return list(islice(cycle([recs]), len(users))) # \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u043c \u043e\u0431\u0449\u0435\u0435 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435","83c1c74d":"TOP_N = 10\n\ntrain_idx, test_idx, info = folds_with_stats[0]\ntest = df.loc[test_idx]\ntrain = df.loc[train_idx]\n\ntrain = train.set_index('item_id')[(train.item_id.value_counts() > 84)].reset_index()\n\npop_model = PopularRecommender(days=20, dt_column='start_date', groupby=['age'])\npop_model.fit(train, users)\n\nrecs = pd.DataFrame({'user_id': test['user_id'].unique()})\nrecs['item_id'] = pop_model.recommend(recs['user_id'], N=TOP_N)\n\nprint(metrics_map(test, recs))","ffdc18bf":"train_idx, test_idx, info = folds_with_stats[0]\ntest = sample.copy()\ntest.columns = ['user_id', 'item_id']\n\ntrain = df.set_index('item_id')[(df.item_id.value_counts() > 76)].reset_index()\n\npop_model = PopularRecommender(days=20, dt_column='start_date', groupby=['age'])\npop_model.fit(train, users)\n\nrecs = pd.DataFrame({'user_id': test['user_id'].unique()})\nrecs['item_id'] = pop_model.recommend(recs['user_id'], N=TOP_N)\n\nrecs","777ac41c":"def make_submission(df, id_col='user_id', predicted_col='item_id'):\n    df = df.explode('item_id').copy()\n    df['rank'] = df.groupby('user_id').cumcount() + 1\n\n    df_copy = df.copy()\n    df_copy.loc[:, id_col] = df_copy[id_col].astype(str)\n    df_copy.loc[:, predicted_col] = df_copy[predicted_col].astype(str)\n    df_copy = df_copy.groupby(id_col, as_index=False).agg({predicted_col: lambda x: ' '.join(list(x))})\n    df_copy.rename(columns={id_col: 'Id', predicted_col: 'Predicted'}, inplace=True)\n    \n    return df_copy[['Id', 'Predicted']]","f925a1bf":"make_submission(recs).to_csv('submission_pop.csv', index=None)","81de5568":"class Ensemble(BM25Recommender):\n    def __init__(self, df, K=20, K1=1.2, B=0.75, num_threads=0,\n                 max_K=100, days=30, user_column='user_id',\n                 item_column='item_id', dt_column='date',\n                 groupby=None, fit_na_as_common=False):\n\n        super().__init__(K, K1, B, num_threads)\n\n        self.max_K = max_K\n        self.days = days\n        self.user_column = user_column\n        self.item_column = item_column\n        self.dt_column = dt_column\n        self.groupby = groupby\n        self.fit_na_as_common = fit_na_as_common\n        self.recommendations = []\n        self.df = df.user_id.value_counts()\n        self.users = set(self.df.index)\n        \n    def fit(self, counts, df, df_users, show_progress=True):\n\n        super().fit(counts, show_progress)\n\n        min_date = df[self.dt_column].max().normalize() - pd.DateOffset(days=self.days)\n        data = df[df[self.dt_column] > min_date]\n        self.recomm_common = data[self.item_column].value_counts().head(self.max_K).index.values\n        self.df_users = df_users\n        self.users_ex = set(self.df_users.user_id)\n\n        if self.groupby is not None:\n\n            data = data.merge(df_users, on=self.user_column, how='left')\n            self.recommendations = data.groupby(self.groupby)[self.item_column]\\\n                                       .apply(lambda x: x.value_counts().head(self.max_K).index.values)\n            \n            # \u0435\u0441\u043b\u0438 \u043d\u0435\u0442 \u0437\u0430\u043f\u0438\u0441\u0435\u0439 \u0434\u043b\u044f \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0438, \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u043e\u0432\u0430\u0442\u044c \u043e\u0431\u0449\u0435\u0435\n            na_mask = self.recommendations.isna()\n            self.recommendations[na_mask] = self.recommendations[na_mask].apply(lambda x: self.recomm_common)\n            \n            # \u043d\u0430 \u0441\u043b\u0443\u0447\u0430\u0439, \u0435\u0441\u043b\u0438 \u0441\u043f\u0438\u0441\u043e\u043a \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0439 \u0431\u0443\u0434\u0435\u0442 \u043a\u043e\u0440\u043e\u0442\u043a\u0438\u043c (\u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 \u0442\u043e\u043b\u044c\u043a\u043e 2 \u043a\u043d\u0438\u0433\u0438)\n            # \u0434\u043e\u0431\u0430\u0432\u0438\u043c \u043e\u0431\u0449\u0443\u044e \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0430\u0446\u0438\u044e\n            self.recommendations = self.recommendations.apply(lambda x: np.concatenate((x, self.recomm_common)))\n            if self.fit_na_as_common:\n                na_mask = (self.recommendations.reset_index()[self.groupby]=='nan').sum(axis=1)!=0\n                self.recommendations[na_mask.values] = self.recommendations[na_mask.values].apply(lambda x: self.recomm_common)\n            self.df_users = self.df_users.set_index('user_id') \n   \n\n    def recommend(self, user, user_items, item_inv_mapping, user_mapping,\n                  N=10, filter_already_liked_items=True, interact_counts=10,\n                  filter_items=None, recalculate_user=False):\n        \n        if user not in self.users:\n            return self.recomm_common[:N].tolist() # \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u043c \u043e\u0431\u0449\u0435\u0435 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435\n\n        if self.df.loc[user] > interact_counts:\n            recs = super().recommend(user_mapping[user], user_items, N,\n                                     filter_already_liked_items,\n                                     filter_items, recalculate_user)\n            return [item_inv_mapping[item] for item, _ in recs]\n        \n        if self.groupby is not None and user in self.users_ex:  \n            data = tuple(self.df_users.loc[user][self.groupby])\n            \n            tmp = len(data) - 1\n            if any((data[tmp] != data[tmp], data[tmp - 1] != data[tmp - 1])):\n                return self.recomm_common[:N].tolist()\n\n            return self.recommendations.loc[data][:N].tolist()\n        \n        return self.recomm_common[:N].tolist() # \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u043c \u043e\u0431\u0449\u0435\u0435 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435","4136886e":"def generate_implicit_recs_mapper(model, train_matrix, N, user_mapping, item_inv_mapping,\n                                  users, number_of_inter):\n    def _recs_mapper(user):\n        recs = model.recommend(user=user,\n                               user_items=train_matrix,\n                               item_inv_mapping=item_inv_mapping,\n                               user_mapping=user_mapping,\n                               N=N, \n                               filter_already_liked_items=True,\n                               interact_counts=number_of_inter)\n        return recs        \n    return _recs_mapper\n","412cb283":"def get_coo_matrix(df, \n                   user_col='user_id', \n                   item_col='item_id', \n                   weight_col=None, \n                   users_mapping=users_mapping, \n                   items_mapping=items_mapping):\n    if weight_col is None:\n        weights = np.ones(len(df), dtype=np.float32)\n    else:\n        weights = df[weight_col].astype(np.float32)\n\n    interaction_matrix = sp.coo_matrix((\n        weights, \n        (\n            df[user_col].map(users_mapping.get), \n            df[item_col].map(items_mapping.get)\n        )\n    ))\n    return interaction_matrix","1f9dbc28":"res = []\nfor train_idx, test_idx, info in tqdm(folds_with_stats):\n    train = df.loc[train_idx]\n    test = df.loc[test_idx]\n\n    train_mat = get_coo_matrix(train).tocsr()\n\n    model = Ensemble(K=5, K1=1.2, B=0.75, days=20, dt_column='start_date', groupby=None, df=df)\n    model.fit(train_mat.T, train, users, show_progress=False)\n    mapper = generate_implicit_recs_mapper(model, train_mat, TOP_N, users_mapping, items_inv_mapping,\n                                           users, 10)\n    recs = pd.DataFrame({\n        'user_id': test['user_id'].unique()\n    })\n    recs['item_id'] = recs['user_id'].map(mapper)\n    res.append(metrics_map(test, recs))\nnp.mean(res) ","27404e57":"test = sample.copy()\ntest.columns = ['user_id', 'item_id']\ntrain_mat = get_coo_matrix(df).tocsr()\n\nmodel = Ensemble(K=5, K1=1.2, B=0.75, days=20, dt_column='start_date', groupby=None, df=df)\nmodel.fit(train_mat.T, df, users)\nmapper = generate_implicit_recs_mapper(model, train_mat, TOP_N, users_mapping, items_inv_mapping,\n                                       users, 10)\nrecs = pd.DataFrame({\n    'user_id': test['user_id'].unique()\n})\nrecs['item_id'] = recs['user_id'].map(mapper)\nrecs","c76c2e0d":"make_submission(recs).to_csv('submission_ens.csv', index=None)","9b061f4e":"# Ensembl","8faa9e39":"\u0418 \u0432\u043e\u0442 \u043d\u0430 \u044d\u0442\u043e\u043c \u043c\u043e\u043c\u0435\u043d\u0442\u0435 \u044f \u0437\u0430\u0433\u0440\u0443\u0441\u0442\u0438\u043b","242d88fa":"\u041d\u043e \u0442\u0443\u0442 \u043f\u0440\u0438\u0448\u0435\u043b \u0432 [discussions]( https:\/\/www.kaggle.com\/c\/mts-ml-summer-school\/discussion\/239136 '\u0433\u0435\u043d\u0438\u0439') \u0443\u043c\u043d\u044b\u0439 \u0438 \u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u043d\u044b\u0439 \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0438 \u043f\u043e\u0441\u043e\u0432\u0435\u0442\u043e\u0432\u0430\u043b \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0438\u0442\u044c PopularRecommender \u0438 \u0443\u043c\u043d\u044b\u0439 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c. \u041d\u0443 \u0447\u0442\u043e \u0436, \u0435\u0441\u043b\u0438 \u0447\u0443\u0432\u0430\u043a \u0438\u0437 \u0442\u043e\u043f\u0430 \u0433\u043e\u0432\u043e\u0440\u0438\u0442 - \u043d\u0430\u0434\u043e \u0434\u0435\u043b\u0430\u0442\u044c )","744dc7ab":"# Preprocessing\n### \u0412\u0441\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 - \u0431\u0430\u043d\u0430\u043b\u044c\u043d\u0430 \u0438 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0441\u043e\u0431\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u0437 \u0441\u0435\u0431\u044f \u043d\u0435 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442","98b5017d":"# Items ","647b224e":"\u041c\u0435\u0442\u043e\u0434\u043e\u043c \u043d\u0430\u0443\u0447\u043d\u043e\u0433\u043e \u0442\u044b\u043a\u0430 (\u0413\u0440\u0438\u0434\u0421\u0435\u0440\u0447) \u043f\u043e\u0434\u043e\u0431\u0440\u0430\u043b \u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0435 \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0435\u043d\u0442\u044b, \u0441\u043a\u043e\u0440 \u0432\u044b\u0448\u0435 0.01087 \u043f\u043e\u0434\u043d\u0438\u043c\u0430\u0442\u044c\u0441\u044f \u043d\u0438 \u0432 \u043a\u0430\u043a\u0443\u044e \u043d\u0435 \u0445\u043e\u0442\u0435\u043b","3819509b":"\u0412 \u0434\u0430\u043d\u043d\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435 \u0440\u0435\u0448\u0438\u043b \u043f\u043e\u0434\u0435\u043b\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c\u044e, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043f\u043e\u0437\u0432\u043e\u043b\u0438\u043b\u0430 \u0432\u043b\u0435\u0442\u0435\u0442\u044c \u0432 \u0442\u043e\u043f-10 \u043f\u0430\u0431\u043b\u0438\u043a\u0430 (\u043d\u0430 15 \u043c\u0430\u044f).\n\n\u042d\u0442\u0430 \u043c\u043e\u0434\u0435\u043b\u044c - \u0430\u043d\u0441\u0430\u043c\u0431\u043b\u044c \u0438\u0437 PopularRecommender \u0438 BM25Recommender, \u043a\u0430\u043a \u0438 \u0433\u043e\u0432\u043e\u0440\u0438\u043b \u0443\u043c\u043d\u044b\u0439 \u0447\u0435\u043b\u043e\u0432\u0435\u043a (\u043d\u0435 \u0441\u0442\u0430\u043b \u0432\u044b\u0434\u0443\u043c\u044b\u0432\u0430\u0442\u044c \u0432\u0435\u043b\u043e\u0441\u0438\u043f\u0435\u0434).\n\n\u041c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u043a\u043e\u0440, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043c\u043d\u0435 \u0443\u0434\u0430\u043b\u043e\u0441\u044c \u0432\u044b\u0431\u0438\u0442\u044c \u043d\u0430 \u043f\u0430\u0431\u043b\u0438\u043a\u0435 \u0441 \u044d\u0442\u0438\u043c \u043a\u043b\u0430\u0441\u0441\u043e\u043c - 0.01689. \u0414\u0435\u043b\u0438\u0442\u0435\u0441\u044c, \u0447\u0442\u043e \u0443 \u0432\u0430\u0441 \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u043e\u0441\u044c, 100% \u043c\u043e\u0436\u043d\u043e \u043b\u0443\u0447\u0448\u0435","ce894822":"# Users ","5d912e6e":"# Interactions","90a6c0ff":"# Baseline\n### \u043d\u0430\u0433\u043b\u043e \u0438 \u0431\u0435\u0437 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0439 \u0432\u0437\u044f\u0442\u043e [\u0442\u0443\u0442\u044c (\u0442\u044b\u043a)](https:\/\/www.kaggle.com\/declot\/mtc-baseline-models] '\u0413\u044b\u0433\u044b\u0433\u044b\u0433\u044b')","43b86844":"# \u0418\u0442\u043e\u0433\u043e\u0432\u043e\u0435 \u043c\u0435\u0441\u0442\u043e: 6, \u0438\u0442\u043e\u0433\u043e\u0432\u044b\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442: 0.01929\n# \u0414\u043e\u0431\u0440\u044b\u0439 \u0432\u0435\u0447\u0435\u0440, \u0434\u0430\u043c\u044b \u0438 \u0433\u043e\u0441\u043f\u043e\u0434\u0430, \u043b\u0435\u0434\u0438 \u0438 \u0434\u0436\u0435\u043d\u0442\u0435\u043b\u044c\u043c\u0435\u043d\u044b, \u0441\u044d\u0440\u044b \u0438 \u0441\u044d\u0440\u0438\u0445\u0438, \u043c\u0430\u043b\u044c\u0447\u0438\u043a\u0438 \u0438 \u0434\u0435\u0432\u043e\u0447\u043a\u0438, \u0437\u0434\u0440\u0430\u0432\u0441\u0442\u0432\u0443\u0439\u0442\u0435! \n\u0420\u0435\u0448\u0438\u043b \u043f\u043e\u0434\u0435\u043b\u0438\u0442\u044c\u0441\u044f \u0441\u0432\u043e\u0438\u043c\u0438 \u043d\u0430\u0440\u0430\u0431\u043e\u0442\u043a\u0430\u043c\u0438 \u0437\u0430 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0435 3 \u0434\u043d\u044f, \u0434\u0443\u043c\u0430\u044e, \u043a\u0442\u043e-\u0442\u043e \u0443\u0441\u043f\u0435\u0435\u0442 \u0438\u043c\u0438 \u0432\u043e\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c\u0441\u044f \u0434\u043b\u044f \u0441\u0432\u043e\u0438\u0445 \u043d\u0443\u0436\u0434. \u0414\u0435\u0440\u0437\u0430\u0439\u0442\u0435))"}}