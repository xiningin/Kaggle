{"cell_type":{"5931777f":"code","af5aa98b":"code","28c61c0e":"code","e03955c4":"code","8228ed28":"code","4298b7f4":"code","816ecb42":"code","4ecd6e3d":"code","419d0956":"code","21bc9732":"code","3696e526":"code","2ce6b3a1":"code","5688a7e1":"code","72f4486a":"code","8a7aa184":"code","85eb12dc":"code","7c88b1dd":"code","3f7d7e05":"code","d30935de":"code","5fed8fe1":"code","78431323":"code","bee4b7bc":"code","b03b5392":"code","c675c2a9":"code","2feb4bb0":"code","dc5aa8fb":"code","34be5123":"code","b7b9cc45":"code","efd3711f":"code","ca36bc82":"code","5385912c":"code","982894fe":"code","602471ef":"code","d2ad3be5":"code","bbe9b483":"code","d5dbfeb0":"code","1fd6d57a":"code","6a38889f":"code","a499c31d":"code","c98bfd9b":"code","94196f51":"code","cb4d02b6":"code","cdb8ffe3":"code","03d0799a":"code","5fdd19f5":"code","43f6311c":"code","818138fc":"code","4df05c33":"code","d578ecd6":"code","8a9de681":"code","a94bf250":"markdown","e50c30f4":"markdown","4925f34b":"markdown","1c262cad":"markdown","c4cb4a08":"markdown","f67327c5":"markdown","1c16d0ed":"markdown","4e6350e0":"markdown","64eadc4c":"markdown","6fa2ec3b":"markdown"},"source":{"5931777f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n        \n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af5aa98b":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom xgboost.sklearn import XGBClassifier","28c61c0e":"%matplotlib inline\nsns.set_style('darkgrid')","e03955c4":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ngs = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","8228ed28":"train.info()\nprint('='*40)\ntest.info()\nprint('='*40)\ngs.info()","4298b7f4":"def missing_summary(df):\n  null = df.isnull().sum()\n  not_null = df.notnull().sum()\n  return pd.DataFrame({'Total_missing':null,'missing %': round((null\/(null+not_null))*100,2),'Total_non_missing':not_null,'total_records':null+not_null})","816ecb42":"# Summary of test & train \nprint('training_data : \\n',missing_summary(train),'\\n','='*40,'\\n','test data : \\n',missing_summary(test))","4ecd6e3d":"train.corr()['Survived'].sort_values().plot(kind='bar')\nplt.show()","419d0956":"plt.figure(figsize=(10,5))\nsns.boxplot(x='Pclass' , y = 'Age', data=train)\nplt.show()","21bc9732":"plt.figure(figsize=(10,6))\nsns.swarmplot(y='Age', x='Survived',hue='Sex', data=train,palette='viridis')\nplt.show()","3696e526":"train.groupby(['Sex','Pclass'])['Survived'].mean().plot(figsize=(10,4))\nplt.ylabel('Avg Survival rate')\nplt.show()","2ce6b3a1":"train.groupby('Pclass')['Age'].mean()","5688a7e1":"for i in train['Pclass'].unique():\n  train[train['Pclass'] == i] = train[train['Pclass'] == i].fillna({'Age': train[train['Pclass'] == i]['Age'].dropna().median()})","72f4486a":"train.groupby('Pclass')['Age'].mean()","8a7aa184":"print('mean of age by :', test.groupby('Pclass')['Age'].mean(),'\\n\\n',\n      '='*40,'\\n\\n'\n      'mean of fare by :', test.groupby('Pclass')['Fare'].mean()\n      )","85eb12dc":"for i in test['Pclass'].unique():\n  test[test['Pclass'] == i] = test[test['Pclass'] == i].fillna({'Age': test[test['Pclass'] == i]['Age'].dropna().median()})\n  test[test['Pclass'] == i] = test[test['Pclass'] == i].fillna({'Fare': test[test['Pclass'] == i]['Fare'].mean()})","7c88b1dd":"print('mean of age by :', test.groupby('Pclass')['Age'].mean(),'\\n\\n',\n      '='*40,'\\n\\n'\n      'mean of fare by :', test.groupby('Pclass')['Fare'].mean()\n      )","3f7d7e05":"print('training_data : \\n',missing_summary(train),'\\n','='*40,'\\n','test data : \\n',missing_summary(test))","d30935de":"train['Title'] = train['Name'].str.split(',').str[1].str.split().str[0]\ntest['Title'] = test['Name'].str.split(',').str[1].str.split().str[0]","5fed8fe1":"train['Title'].value_counts()","78431323":"test['Title'].value_counts()","bee4b7bc":"title_mapping = {'Mr.':1,'Miss.':2,'Mrs.':3,'Master.':4,'Rev.':5,'Col.':6,'Ms.':7,'Dr.':8,'Dona.':9, 'Don.':9}","b03b5392":"train['Title'] = train['Title'].map(title_mapping)\ntest['Title'] = test['Title'].map(title_mapping)","c675c2a9":"train.isnull().sum()","2feb4bb0":"# Droping column which is not required\ntrain = train.drop('Cabin', axis=1)\ntest = test.drop('Cabin', axis=1)","dc5aa8fb":"train['Embarked'].describe()","34be5123":"#Deleting the records of training dataset where Embarked is missing\ntrain.dropna(axis=0,inplace=True)","b7b9cc45":"# correlation with respect to target variable\ntrain.corr()['Survived'].sort_values()","efd3711f":"# we already classified name and we are droping columns from both dataset\ntrain = train.drop(['Name','Ticket'],axis=1)\ntest = test.drop(['Name','Ticket'],axis=1)","ca36bc82":"print('test dataset:\\n',test.dtypes)\nprint('='*40)\nprint('train dataset:\\n',train.dtypes)","5385912c":"train['Title'] = train['Title'].astype('int64')","982894fe":"X = pd.get_dummies(data=train.drop('Survived',axis=1),columns=['Sex','Embarked','Pclass','Title'],drop_first=True)\ny = train['Survived'].values","602471ef":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","d2ad3be5":"X_train.head()","bbe9b483":"test_sample = pd.get_dummies(data=test,columns=['Sex','Embarked','Pclass','Title'],drop_first=True)","d5dbfeb0":"test_sample.head()","1fd6d57a":"def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n\n    if train == True:\n        '''\n        performance of training data\n        '''\n \n        print(\"Train Result:\")\n        print(\"=\"*60)\n        print(\"\\n\")\n        print(\"Accuracy score: {0:.4f}\\n\".format(accuracy_score(y_train, clf.predict(X_train))))\n        print(\"Classification Report: \\n {}\\n\".format(classification_report(y_train, clf.predict(X_train))))\n        print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_train, clf.predict(X_train))))\n\n        res = cross_val_score(clf, X_train, y_train.ravel(), cv=10, scoring='accuracy')\n        print(\"Average Accuracy: \\t {0:.4f}\".format(np.mean(res)))\n        print(\"Accuracy SD: \\t\\t {0:.4f}\".format(np.std(res)))\n        print(\"\\n\\n\")\n        \n    else:\n        '''\n         performance of test data\n        '''\n        print(\"Test Result:\") \n        print(\"=\"*60)\n        print(\"\\n\")\n        print(\"Accuracy score: {0:.4f}\\n\".format(accuracy_score(y_test, clf.predict(X_test))))\n        print(\"Classification Report: \\n {}\\n\".format(classification_report(y_test, clf.predict(X_test))))\n        print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_test, clf.predict(X_test))))    \n        ","6a38889f":"scale = StandardScaler()\n\nX_train = scale.fit_transform(X_train)\nX_test = scale.transform(X_test)","a499c31d":"model_classifiers = {'K-Nearest_Neighbors': KNeighborsClassifier(),\n                     'SVM'                : SVC(),\n                     'LogisticRegression' : LogisticRegression(),\n                     'Gaussian_Process'   : GaussianProcessClassifier(),\n                     'Gradient_Boosting'  : GradientBoostingClassifier(),\n                     'Decision_Tree'      : DecisionTreeClassifier(),\n                     'Extra_Trees'        : ExtraTreesClassifier(),\n                     'Random_Forest'      : RandomForestClassifier(),\n                     'Neural_Net'         : MLPClassifier(alpha=1, max_iter=1000),\n                     'AdaBoost'           : AdaBoostClassifier(),\n                     'XGBoost'            : XGBClassifier(random_state=42)}","c98bfd9b":"def model_compare(x_train_df,y_train_df,x_test_df,y_test_df,model_list):\n  return pd.DataFrame({'Model Name'    : [ i for i in model_list.keys()],\n                       'Training Score': [accuracy_score(y_train_df,i.fit(x_train_df,y_train_df).predict(x_train_df)) for i in model_list.values()],\n                       'Test Score'    : [accuracy_score(y_test_df,i.fit(x_train_df,y_train_df).predict(x_test_df)) for i in model_list.values()]\n                       }\n                      )","94196f51":"model_compare(X_train,y_train,X_test,y_test,model_classifiers)","cb4d02b6":"logreg = LogisticRegression()\nlogreg.fit(X_train,y_train)","cdb8ffe3":"print_score(logreg, X_train, y_train, X_test, y_test, train=True)\nprint_score(logreg, X_train, y_train, X_test, y_test, train=False)","03d0799a":"svm = SVC()\nsvm.fit(X_train,y_train)","5fdd19f5":"print_score(svm, X_train, y_train, X_test, y_test, train=True)\nprint_score(svm, X_train, y_train, X_test, y_test, train=False)","43f6311c":"test_sample = scale.transform(test_sample)","818138fc":"Survived = svm.predict(test_sample)","4df05c33":"predicted_test = pd.concat([test,pd.DataFrame({'Survived':Survived.tolist()})],axis=1)[['PassengerId','Survived']].sort_values('PassengerId')","d578ecd6":"print('Confusion Matrix:\\n\\n', confusion_matrix(gs.Survived,predicted_test.Survived),\n      '\\n\\n','='*40,'\\n'\n      'Accuracy Score:\\n\\n',accuracy_score(gs.Survived,predicted_test.Survived))","8a9de681":"predicted_test.to_csv('submission.csv', index=False)","a94bf250":"## Compare Models","e50c30f4":"## Apply Models\n\n***Applying Logistic Regression on train data***","4925f34b":"Applying SVM on train data","1c262cad":"***spliting train & test data into 70:30***","c4cb4a08":"***Missing value treatement - Training data***","f67327c5":"## Apply model on test data\n\n\n### gs = gender_submission.csv & predicted_test = predicted value of test.csv\n\n\n","1c16d0ed":"***Checking Missing values***","4e6350e0":"### Converting categorical variable into dummy\/indicator variables","64eadc4c":"***Missing value treatement - test data***","6fa2ec3b":"***Summary of test & train data***"}}