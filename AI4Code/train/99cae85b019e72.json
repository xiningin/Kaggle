{"cell_type":{"190b7891":"code","1e7d1d29":"code","5490db28":"code","6565b7f8":"code","933c2ed5":"code","96e78c32":"code","17ed3492":"code","b2e71c21":"code","5753632f":"code","7794d28d":"code","3cbc0f46":"code","08adfa51":"code","c33a34c7":"code","4038eafc":"code","1a8b4813":"code","ee1b603a":"code","96c63125":"code","b65b7c98":"code","0c9c5127":"code","925b6af1":"code","24748caf":"code","0f778f76":"code","8ce67063":"markdown","2e6c88f5":"markdown","0f3e804e":"markdown","f470c154":"markdown","385b22a1":"markdown","40d09426":"markdown","be66a297":"markdown","57e84464":"markdown","8dbf3c4c":"markdown","18e93fd1":"markdown","fcfe2ea7":"markdown","85557ba2":"markdown","4b067cb7":"markdown","307fff04":"markdown","0cdefd00":"markdown","80055bdc":"markdown","3a8c0363":"markdown","a64d0682":"markdown","eed4e96d":"markdown","6b94f9e9":"markdown"},"source":{"190b7891":"# Importing necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold\nsns.set()","1e7d1d29":"# Reading the Dataset\nclas_data = pd.read_csv('..\/input\/health-care-data-set-on-heart-attack-possibility\/heart.csv')","5490db28":"def data_info(data):\n    print('\\t\\t Data Info:')\n    print(clas_data.info())\n    print('\\n\\n\\t\\t Data Head:')\n    print(clas_data.head())\n    print('\\n\\n\\t\\t Data Describe:')\n    print(clas_data.describe())\n    print('\\n\\nData Shape: ',clas_data.shape)\n    print('\\n\\n\\t\\t Null Values')\n    print(clas_data.isna().sum())","6565b7f8":"data_info(clas_data)","933c2ed5":"var = 'target'\nsns.countplot(clas_data[var])","96e78c32":"var = 'sex'\nsns.countplot(clas_data[var])","17ed3492":"var = 'age'\nf, ax = plt.subplots(figsize=(15,8))\nsns.distplot(clas_data[var])\nplt.xlim([0,80])","b2e71c21":"var = 'chol'\nf, ax = plt.subplots(figsize=(15,8))\nsns.distplot(clas_data[var])\nplt.xlim([0,600])","5753632f":"var = 'trestbps'\nf, ax = plt.subplots(figsize=(15,8))\nsns.distplot(clas_data[var])\nplt.xlim([0,250])","7794d28d":"plt.figure(figsize=(18,18))\nsns.heatmap(clas_data.corr(),annot=True,cmap='RdYlGn')\n\nplt.show()","3cbc0f46":"clas_data.columns","08adfa51":"X = clas_data.iloc[:,:-1]\ny = clas_data.iloc[:,-1]\nprint(\"\\n\\n\\t\\tIndependent features of Dataset: \")\nprint(X.head())\nprint(\"\\n\\n\\t\\tDependent features of Dataset: \")\nprint(y.head())","c33a34c7":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 25)","4038eafc":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","1a8b4813":"log_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)\ny_pred = log_reg.predict(X_test)","ee1b603a":"from sklearn import metrics\nprint(\"Classification Model Accuracy is: \",metrics.accuracy_score(y_test, y_pred))","96c63125":"! pip install -q scikit-plot","b65b7c98":"import scikitplot as skplt\nskplt.metrics.plot_confusion_matrix(y_test,y_pred)","0c9c5127":"from sklearn.metrics import average_precision_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\naverage_precision = average_precision_score(y_test, y_pred)\nprint('Average precision-recall score: {0:0.2f}'.format(average_precision))\ndisp = plot_precision_recall_curve(log_reg, X_test, y_test)\ndisp.ax_.set_title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))","925b6af1":"from sklearn.metrics import f1_score\nprint(\"Macro F1 Score: \",f1_score(y_test, y_pred, average='macro'))\nprint(\"Micro F1 Score: \",f1_score(y_test, y_pred, average='micro'))\nprint(\"Weighted F1 Score: \",f1_score(y_test, y_pred, average='weighted'))","24748caf":"fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n\nplt.plot(fpr, tpr)\nplt.title('ROC curve for Heart Attack classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","0f778f76":"from sklearn.metrics import classification_report\ntarget_names = ['class 0', 'class 1']\nprint(classification_report(y_test, y_pred, target_names=target_names))","8ce67063":"## \ud83e\uddd1\ud83c\udffc\u200d\ud83c\udf73Evaluation of model\n\nFrom here we are followed by the different ways we could evaluate our classification model.","2e6c88f5":"# \ud83e\uddd0Evaluating Classification ML Models\n\nNeed to choose between different Models\n\n**OR**\n\nChoose between different features.\n\n**OR even**\n\nChoose between different Tuning Parameters\n\n**Then**\n\nWe need to <font color=\"blue\">***evaluate model***<\/font>\n\nSo, that we could find out that the model which we wanted to build is completed or it's need more work upon it.\n\nIn, this Kerne\/Notebook I have discussed few most popular tech. used to evaluate your model.\n\nSo, sit back and have a look over it and find out what you need to evaluate your's model.\n\nBefore going forward :\n<font color=\"Red\">Please Upvote ( It motivates me )<\/font>","0f3e804e":"And there are many more \n\nDo check out [https:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html](http:\/\/)","f470c154":"## Preprocesing and Ploting","385b22a1":"### ROC Curve\nROC can be broken down into sensitivity and specificity. Choosing the best model is sort of a balance between predicting 1's accurately or 0's accurately. In other words sensitivity and specificity.","40d09426":"### \ud83d\ude35F1 score\nThe F1 score is the harmonic mean of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall). The F1 score is also known as the S\u00f8rensen\u2013Dice coefficient or Dice similarity coefficient (DSC).[](http:\/\/)","be66a297":"Now, comes the **heat map**\n\n### \ud83d\udd25Heat Map\nA heat map (or heatmap) is a data visualization technique that shows magnitude of a phenomenon as color in two dimensions. The variation in color may be by hue or intensity, giving obvious visual cues to the reader about how the phenomenon is clustered or varies over space.","57e84464":"### Precision and Recall\nPrecision attempts to answer the following question:\n\n*What proportion of positive identifications was actually correct?*\n\nAnd,Recall attempts to answer the following question:\n\n*What proportion of actual positives was identified correctly?*","8dbf3c4c":"### \ud83e\udd2fConfusion Matrix\nMost used in classification model\n\nA confusion matrix is a summary of prediction results on a classification problem.\n\nThe number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix.\n\nThe confusion matrix shows the ways in which your classification model\nis confused when it makes predictions.\n\nIt gives you insight not only into the errors being made by your classifier but more importantly the types of errors that are being made.\n\nLet's now define the most basic terms, which are whole numbers (not rates):\n* true positives (TP): These are cases in which we predicted yes (they have the disease), and they do have the disease.\n* true negatives (TN): We predicted no, and they don't have the disease.\n* false positives (FP): We predicted yes, but they don't actually have the disease. (Also known as a \"Type I error.\")\n* false negatives (FN): We predicted no, but they actually do have the disease. (Also known as a \"Type II error.\")","18e93fd1":"### Model Accuracy\nIn multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true.","fcfe2ea7":"At here I have just divided the dataset first to X and y.\n\nFollowed by spliting for **test and train sets**","85557ba2":"So, Finally this NoteBook End here \ud83e\udd35\ud83c\udffb\n\nBefore going a humble request if you liked the notebook the \n\n<font color=\"Red\">Please Upvote ( It motivates me )<\/font>\n\n<font color=\"Green\">Do check my other notebooks: <\/font>\nhttps:\/\/www.kaggle.com\/iabhishekmaurya\/used-car-price-prediction\nhttps:\/\/www.kaggle.com\/iabhishekmaurya\/applied-machine-learning\/notebook\n\nAnd Stay Tuned... I WILL ALSO DO THE SAME FOR REGRESSION MODELS\n\nTill then Happy Coding\n# \ud83e\udd1d\ud83e\udd1d\ud83e\udd1d\ud83e\udd1d\ud83e\udd1d","4b067cb7":"## \ud83d\udc68\ud83c\udffc\u200d\ud83d\udcbb Model Training\n\nI used most basic Logistic Regression here (because our focus is on Evaluation rather than a well-trained model)","307fff04":"In this current Notebook I have discussed these following evaluation :\n<font color=\"Purple\">\n1. Classification Accuracy\n2. Confusion Matrix\n3. F1 Score\n4. Precision And Recall\n5. ROC Curve\n3. Classication Report <\/font>","0cdefd00":"### Classification Report \nAt the I am using classification Report by **sckit-learn** which basically report all important evaluation criteria.\n\nRef : [https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.classification_report.html](http:\/\/)\n\nI wouls suggest do read this documentation.","80055bdc":"Cleary most of dataset of person more than 40 year's of age. And it rises max in about 60.\n\nBelow, I ploted avout some more columns","3a8c0363":"As given in data description, these 14 features are mostly used in all model. ","a64d0682":"followed with **gender\/sex** column","eed4e96d":"### Let's first find out details of our dataset\n\nLooking it's description, info, a head look gives us a rough idea of our data.","6b94f9e9":"### Now, let's have some visual information of our dataset\n\nFirst, let us find out about our **target** column."}}