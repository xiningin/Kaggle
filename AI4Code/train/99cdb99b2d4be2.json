{"cell_type":{"9e96f9ac":"code","22053364":"code","a9047ca5":"code","64815f2f":"code","8f19eb8c":"code","1257cb8a":"code","2b573870":"code","a820453d":"code","9efd0ef2":"code","19ba0151":"code","267e3dc2":"code","953c924b":"code","4439f360":"code","26f59262":"code","f8d43958":"code","5b76cac2":"code","40567a5e":"code","cfda6809":"code","a9fb554b":"code","9870a936":"code","4185fc59":"code","d6b5bf4d":"code","99e50796":"code","ff9036a8":"code","18c17b57":"code","718f36a7":"code","f666110d":"code","46a71253":"code","a4a617a5":"code","6caec71c":"code","891895c2":"code","ade51503":"code","2c22869f":"code","5aef0341":"code","89659c23":"code","adc82f47":"code","ba90378b":"code","54543fd4":"code","8ae3901b":"code","84a6abcc":"code","daff42cf":"code","37d70a4f":"code","69131ad8":"code","76b6d950":"code","eaec4919":"code","563de367":"markdown","8d41b589":"markdown","37dea5bb":"markdown","fc5b175b":"markdown","7577c226":"markdown","b441ae5f":"markdown","1f5b0bc0":"markdown","e233338f":"markdown","712a6c87":"markdown","696be48a":"markdown"},"source":{"9e96f9ac":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.utils.class_weight import compute_class_weight\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.callbacks import LearningRateMonitor\nimport time\nimport gc\nimport torchmetrics\n\n\n# Pandas setting to display more dataset rows and columns\npd.set_option('display.max_rows', 150)\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', None)\npd.set_option('display.float_format', lambda x: '%.6f' % x)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","22053364":"train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-dec-2021\/train.csv\", low_memory=False)#, nrows=10000)\ntest = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-dec-2021\/test.csv\", low_memory=False)#, nrows=10000)","a9047ca5":"train.info(memory_usage=\"deep\")","64815f2f":"test.info(memory_usage=\"deep\")","8f19eb8c":"# Colors to be used for plots\ncolors = [\"lightcoral\", \"sandybrown\", \"darkorange\", \"mediumseagreen\",\n          \"lightseagreen\", \"cornflowerblue\", \"mediumpurple\", \"palevioletred\",\n          \"lightskyblue\", \"sandybrown\", \"yellowgreen\", \"indianred\",\n          \"lightsteelblue\", \"mediumorchid\", \"deepskyblue\"]","1257cb8a":"train.head()","2b573870":"target = \"Cover_Type\"\n\nfeatures = list(train.columns[1:55])","a820453d":"train[target].value_counts()","9efd0ef2":"fig, ax = plt.subplots(figsize=(5, 6))\npie = ax.pie([len(train), len(test)],\n             labels=[\"Train dataset\", \"Test dataset\"],\n             colors=[\"salmon\", \"teal\"],\n             textprops={\"fontsize\": 15},\n             autopct='%1.1f%%')\nax.axis(\"equal\")\nax.set_title(\"Dataset length comparison\", fontsize=18)\nfig.set_facecolor('white')\nplt.show();","19ba0151":"fig, ax = plt.subplots(figsize=(14, 8))\n\nbars = ax.bar(train[target].value_counts().sort_index().index,\n                  train[target].value_counts().sort_index().values,\n                  color=colors,\n                  edgecolor=\"black\")\nax.set_title(\"Target distribution\", fontsize=20, pad=15)\nax.set_ylabel(\"Count\", fontsize=14, labelpad=15)\nax.set_xlabel(\"Target label\", fontsize=14, labelpad=20)\nax.tick_params(axis=\"x\", pad=20)\nax.bar_label(bars, train[target].value_counts().sort_index().values,\n                 padding=3, fontsize=12)\nax.bar_label(bars, [f\"{x*100:2.1f}%\" for x in train[target].value_counts().sort_index().values\/len(train)],\n                 padding=-20, fontsize=12)\nax.margins(0.025, 0.06)\nax.grid(axis=\"y\")\n\nplt.show();","267e3dc2":"train[features].describe()","953c924b":"test[features].describe()","4439f360":"df = pd.concat([train[features], test[features]], axis=0)\ndf.reset_index(inplace=True, drop=True)\n\nunique_values = df[features].nunique() < 10\ncat_features = list(unique_values[unique_values==True].index)\nunique_values = df[features].nunique() >= 10\nnum_features = list(unique_values[unique_values==True].index)\n\nprint(f\"There are {len(cat_features)} categorical features: {cat_features}\")\nprint(f\"\\nThere are {len(num_features)} continuous features: {num_features}\")","26f59262":"train.isna().sum().sum(), test.isna().sum().sum()","f8d43958":"df = pd.concat([train[num_features], test[num_features]], axis=0)\ncolumns = df.columns.values\n\ncols = 3\nrows = len(columns) \/\/ cols + 1\n\nfig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(16,20), sharex=False)\n\nplt.subplots_adjust(hspace = 0.3)\ni=0\n\nfor r in np.arange(0, rows, 1):\n    for c in np.arange(0, cols, 1):\n        if i >= len(columns):\n            axs[r, c].set_visible(False)\n        else:\n            hist1 = axs[r, c].hist(train[columns[i]].values,\n                                   range=(df[columns[i]].min(),\n                                          df[columns[i]].max()),\n                                   bins=40,\n                                   color=\"deepskyblue\",\n                                   edgecolor=\"black\",\n                                   alpha=0.7,\n                                   label=\"Train Dataset\")\n            hist2 = axs[r, c].hist(test[columns[i]].values,\n                                   range=(df[columns[i]].min(),\n                                          df[columns[i]].max()),\n                                   bins=40,\n                                   color=\"palevioletred\",\n                                   edgecolor=\"black\",\n                                   alpha=0.7,\n                                   label=\"Test Dataset\")\n            axs[r, c].set_title(columns[i], fontsize=12, pad=5)\n            axs[r, c].set_yticks(axs[r, c].get_yticks())\n            axs[r, c].set_yticklabels([str(int(i\/1000))+\"k\" for i in axs[r, c].get_yticks()])\n            axs[r, c].tick_params(axis=\"y\", labelsize=10)\n            axs[r, c].tick_params(axis=\"x\", labelsize=10)\n            axs[r, c].grid(axis=\"y\")\n            if i == 0:\n                axs[r, c].legend(fontsize=10)\n                                  \n        i+=1\n#plt.suptitle(\"Numerical feature values distribution in both datasets\", y=0.99)\nplt.show();","5b76cac2":"df = pd.concat([train[cat_features], test[cat_features]], axis=0)\ncolumns = df.columns.values\n\ncols = 4\nrows = len(columns) \/\/ cols + 1\n\nfig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(16,40), sharex=False)\n\nplt.subplots_adjust(hspace = 0.3)\ni=0\n\nfor r in np.arange(0, rows, 1):\n    for c in np.arange(0, cols, 1):\n        if i >= len(columns):\n            axs[r, c].set_visible(False)\n        else:\n            hist1 = axs[r, c].hist(train[columns[i]].values,\n                                   range=(df[columns[i]].min(),\n                                          df[columns[i]].max()),\n                                   bins=40,\n                                   color=\"deepskyblue\",\n                                   edgecolor=\"black\",\n                                   alpha=0.7,\n                                   label=\"Train Dataset\")\n            hist2 = axs[r, c].hist(test[columns[i]].values,\n                                   range=(df[columns[i]].min(),\n                                          df[columns[i]].max()),\n                                   bins=40,\n                                   color=\"palevioletred\",\n                                   edgecolor=\"black\",\n                                   alpha=0.7,\n                                   label=\"Test Dataset\")\n            axs[r, c].set_title(columns[i], fontsize=12, pad=5)\n            axs[r, c].set_yticks(axs[r, c].get_yticks())\n            axs[r, c].set_yticklabels([str(int(i\/1000))+\"k\" for i in axs[r, c].get_yticks()])\n            axs[r, c].tick_params(axis=\"y\", labelsize=10)\n            axs[r, c].tick_params(axis=\"x\", labelsize=10)\n            axs[r, c].grid(axis=\"y\")\n            if i == 0:\n                axs[r, c].legend(fontsize=10)\n                                  \n        i+=1\n#plt.suptitle(\"Categorical feature values distribution in both datasets\", y=0.99)\nplt.show();","40567a5e":"print(f\"Rows with soil type 7: {(train['Soil_Type7'] == 1).sum() + (test['Soil_Type7'] == 1).sum()}\")\nprint(f\"Rows with soil type 15: {(train['Soil_Type15'] == 1).sum() + (test['Soil_Type15'] == 1).sum()}\")","cfda6809":"train.drop([\"Soil_Type7\", \"Soil_Type15\"], axis=1, inplace=True)\ntest.drop([\"Soil_Type7\", \"Soil_Type15\"], axis=1, inplace=True)\nfeatures.remove(\"Soil_Type7\")\nfeatures.remove(\"Soil_Type15\")\ncat_features.remove(\"Soil_Type7\")\ncat_features.remove(\"Soil_Type15\")","a9fb554b":"print(\"Numerical features with the least amount of unique values:\")\ntrain[num_features].nunique().sort_values().head(5)","9870a936":"display(train[['Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4']].sum(axis=1).value_counts().sort_index())\ndisplay(train[[x for x in train.columns if \"Soil_Type\" in x]].sum(axis=1).value_counts().sort_index())","4185fc59":"print(\"Target distribution per amount of wildernes area types\")\ndf = train[['Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4']].sum(axis=1)\ndf_2 = pd.DataFrame(columns=[str(x) + \" wild_types\" for x in df.value_counts().sort_index().index],\n                    index=list(train[target].value_counts().sort_index().index))\ndf_2.fillna(0, inplace=True)\nfor i in df.value_counts().index:\n    total_samples = len(train.loc[df==i, target]) \n    samples_per_class = train.loc[df==i, target].value_counts().sort_index()\n    for sample_index in samples_per_class.index:\n        df_2.loc[sample_index, str(i) + \" wild_types\"] = round((samples_per_class[sample_index] * 100 \/ total_samples), 4)\ndf_2","d6b5bf4d":"print(\"Target distribution per amount of soil types\")\ndf = train[[x for x in train.columns if \"Soil_Type\" in x]].sum(axis=1)\ndf_2 = pd.DataFrame(columns=[str(x) + \" soil_types\" for x in df.value_counts().sort_index().index],\n                    index=list(train[target].value_counts().sort_index().index))\ndf_2.fillna(0, inplace=True)\nfor i in df.value_counts().index:\n    total_samples = len(train.loc[df==i, target]) \n    samples_per_class = train.loc[df==i, target].value_counts().sort_index()\n    for sample_index in samples_per_class.index:\n        df_2.loc[sample_index, str(i) + \" soil_types\"] = round((samples_per_class[sample_index] * 100 \/ total_samples), 4)\ndf_2","99e50796":"# %%time\n# from sklearn.decomposition import PCA, SparsePCA, KernelPCA\n# pca = PCA(n_components=2)\n# data_2D = pca.fit_transform(MinMaxScaler().fit_transform(train[cat_features]))\n# pca = SparsePCA(n_components=2)\n# data_2D = pca.fit_transform(MinMaxScaler().fit_transform(train[cat_features]))\n# pca = KernelPCA(n_components=2, eigen_solver='randomized', kernel=\"poly\")\n# data_2D = pca.fit_transform(MinMaxScaler().fit_transform(train[cat_features]).astype(\"float32\"))","ff9036a8":"# fig, ax = plt.subplots(figsize=(16,16))\n# # fig_colors = train[target].copy()\n# # fig_colors = fig_colors.map({1:\"lightcoral\", 2:\"sandybrown\", 3:\"darkorange\", 4:\"mediumseagreen\", 5:\"cornflowerblue\", 6:\"mediumpurple\"})\n\n# # scatter = ax.scatter(data_2D[:10000, 0], data_2D[:10000, 1],\n# #                  c=train.loc[:9999,target], cmap=\"hsv\",\n# #                  s=4)\n\n# scatter = ax.scatter(data_2D[:, 0], data_2D[:, 1],\n#                  c=train.loc[:,target], cmap=\"hsv\",\n#                  s=4)\n\n# legend = ax.legend(*scatter.legend_elements(),\n#                     loc=\"upper right\", title=\"target\", fontsize=\"large\")\n# ax.add_artist(legend)","18c17b57":"# Dropping a row which is the only one example of 5th class\ntrain.drop(train[train[target]==5].index, axis=0, inplace=True)\ntrain.reset_index(drop=True, inplace=True)\nlabel_enc = LabelEncoder()\nNUM_CLASSES = train[target].nunique()","718f36a7":"# # Transforming Aspect feature to be in [0, 359] range \n# train.loc[train[\"Aspect\"]<0, \"Aspect\"] = train.loc[train[\"Aspect\"]<0, \"Aspect\"] + 360\n# train.loc[train[\"Aspect\"]>=360, \"Aspect\"] = train.loc[train[\"Aspect\"]>=360, \"Aspect\"] - 360\n\n# test.loc[test[\"Aspect\"]<0, \"Aspect\"] = test.loc[test[\"Aspect\"]<0, \"Aspect\"] + 360\n# test.loc[test[\"Aspect\"]>=360, \"Aspect\"] = test.loc[test[\"Aspect\"]>=360, \"Aspect\"] - 360\n\n# train[\"Aspect\"].min(), train[\"Aspect\"].max(), test[\"Aspect\"].min(), test[\"Aspect\"].max()","f666110d":"# # Clipping Hillshade features outliers to [0, 255] range \n\n# for df in [train, test]:\n#     df.loc[df[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\n#     df.loc[df[\"Hillshade_Noon\"] < 0, \"Hillshade_Noon\"] = 0\n#     df.loc[df[\"Hillshade_3pm\"] < 0, \"Hillshade_3pm\"] = 0\n#     df.loc[df[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\n#     df.loc[df[\"Hillshade_Noon\"] > 255, \"Hillshade_Noon\"] = 255\n#     df.loc[df[\"Hillshade_3pm\"] > 255, \"Hillshade_3pm\"] = 255\n    \n# train[[\"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\"]].min(), \\\n# train[[\"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\"]].max(), \\\n# test[[\"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\"]].min(), \\\n# test[[\"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\"]].max()","46a71253":"# # A new feature indicating that the patch is located lower than the closest water source\n# train[\"lower_than_water\"] = (train[\"Vertical_Distance_To_Hydrology\"] < 0).astype(\"int16\")\n# test[\"lower_than_water\"] = (test[\"Vertical_Distance_To_Hydrology\"] < 0).astype(\"int16\")\n# features.append(\"lower_than_water\")\n# cat_features.append(\"lower_than_water\")","a4a617a5":"# Adding two new features showing amount of different soil and wildernes area types\ntrain[\"wild_areas_sum\"] = train[['Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4']].sum(axis=1)\ntest[\"wild_areas_sum\"] = test[['Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4']].sum(axis=1)\n\ntrain[\"soil_types_sum\"] = train[[x for x in train.columns if \"Soil_Type\" in x]].sum(axis=1)\ntest[\"soil_types_sum\"] = test[[x for x in train.columns if \"Soil_Type\" in x]].sum(axis=1)\n\nfeatures.append(\"wild_areas_sum\")\nfeatures.append(\"soil_types_sum\")\ncat_features.append(\"wild_areas_sum\")\ncat_features.append(\"soil_types_sum\")","6caec71c":"# A new feature showing straight distance to a water source\ntrain[\"straight_dist_to_hydrology\"] = (train[\"Horizontal_Distance_To_Hydrology\"]**2 + train[\"Vertical_Distance_To_Hydrology\"]**2)**0.5\ntest[\"straight_dist_to_hydrology\"] = (test[\"Horizontal_Distance_To_Hydrology\"]**2 + test[\"Vertical_Distance_To_Hydrology\"]**2)**0.5\n\ntrain[\"sum_dist_to_hydrology\"] = train[\"Horizontal_Distance_To_Hydrology\"] + train[\"Vertical_Distance_To_Hydrology\"]\ntest[\"sum_dist_to_hydrology\"] = test[\"Horizontal_Distance_To_Hydrology\"] + test[\"Vertical_Distance_To_Hydrology\"]\n\nfeatures.append(\"straight_dist_to_hydrology\")\nfeatures.append(\"sum_dist_to_hydrology\")\nnum_features.append(\"straight_dist_to_hydrology\")\nnum_features.append(\"sum_dist_to_hydrology\")","891895c2":"# Standardizing and scaling features\ns_scaler = StandardScaler()\nfor col in num_features:\n    train[col] = s_scaler.fit_transform(np.array(train[col]).reshape(-1,1))\n    test[col] = s_scaler.transform(np.array(test[col]).reshape(-1,1))","ade51503":"# Reducing datasets memory size due to converting columns into lighter formats\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df\n\ntrain = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","2c22869f":"X_nn = train[features].copy()\nX_test_nn = test[features].copy()\ny = pd.Series(label_enc.fit_transform(train[target]))\n\n# # Generating OneHot encoded targets\n# ohe = OneHotEncoder(sparse=False)\n# y = ohe.fit_transform(np.array(train[target]).reshape(-1,1))\n# y[:5]","5aef0341":"X_nn.columns","89659c23":"mm_scaler = MinMaxScaler()\nfor col in X_nn.columns:\n    X_nn[col] = mm_scaler.fit_transform(np.array(X_nn[col]).reshape(-1,1))\n    X_test_nn[col] = mm_scaler.transform(np.array(X_test_nn[col]).reshape(-1,1))\n    \n# Transforming test data into tensors\nX_test_nn = torch.tensor(X_test_nn.to_numpy()).float()","adc82f47":"BATCH_SIZE = 4096","ba90378b":"def prepare_datasets(X_nn, X_valid_nn, y_nn, y_valid_nn, batch_size=BATCH_SIZE):\n    # Transforming data into tensors\n    X_nn = torch.tensor(X_nn.to_numpy(), dtype=torch.float32)\n    y_nn = torch.tensor(y_nn.to_numpy(), dtype=torch.long)\n    X_valid_nn = torch.tensor(X_valid_nn.to_numpy(), dtype=torch.float32)\n    y_valid_nn = torch.tensor(y_valid_nn.to_numpy(), dtype=torch.long)\n    \n    print(\"Using these datasets:\")\n    # Transforming tensors into tensor datasets\n    train_ds = TensorDataset(X_nn, y_nn)\n    valid_ds = TensorDataset(X_valid_nn, y_valid_nn)\n#     test_ds = TensorDataset(X_test_nn)\n    print(f\"Train_ds elements: {len(train_ds)}\")\n    print(f\"Valid_ds elements: {len(valid_ds)}\")\n#     print(f\"Test_ds elements: {len(test_ds)}\")\n\n    # Transforming into dataloader objects using batches\n    \n    train_ds = DataLoader(train_ds, batch_size, drop_last=False, num_workers=4)\n    valid_ds = DataLoader(valid_ds, batch_size, drop_last=False, num_workers=4)\n#     test_ds = DataLoader(test_ds, batch_size=BATCH_SIZE)\n\n    \n    for data, label in train_ds:\n        print(f\"Train_ds batch: {data.shape}, {label.shape}\")\n        break\n    for data, label in valid_ds:\n        print(f\"Valid_ds batch: {data.shape}, {label.shape}\")\n        break\n#     for data in test_ds:\n#         print(f\"Test_ds batch: {data[0].shape}\")\n#         break\n    return train_ds, valid_ds","54543fd4":"# Computing class weights to be used during training\nclass_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y), y=y)\n# Reduce weight of the smallest classes in order to not give\n# them too much attention\nclass_weights[3] = class_weights[0]\nclass_weights[4] = class_weights[0]\nclass_weights = torch.tensor(class_weights, dtype=torch.float32)\nclass_weights","8ae3901b":"# A function to initialize weights using Glorot normal initialization\ndef initialize_weights(m):\n    if isinstance(m, nn.Linear):\n        torch.nn.init.xavier_normal_(m.weight.data)","84a6abcc":"# A custom callback to log required parameters like metrics and learning rate\n# since TensorBoard is blocked on Kaggle.\nclass ParamsTracker(pl.callbacks.Callback):\n\n    def __init__(self, verbose=True):\n        self.verbose = verbose\n        # Defining empty lists for metric values\n        self.train_loss = []\n        self.train_acc = []\n        self.val_loss = []\n        self.val_acc = []\n        self.lr_epoch_start = []\n\n    \n    # Getting learning rate from an optimizer params at epoch start\n    def on_train_epoch_start(self, trainer, module):\n        current_learning_rate = trainer.optimizers[0].state_dict()[\"param_groups\"][0][\"lr\"]\n        self.lr_epoch_start.append(current_learning_rate)\n#         print(f\"Epoch start lr {current_learning_rate}\")\n        \n    def on_validation_epoch_end(self, trainer, module):\n        metrics_logs = trainer.logged_metrics\n        self.val_loss.append(metrics_logs[\"val_loss\"].item())\n        self.val_acc.append(metrics_logs[\"val_acc\"].item())\n    \n    # Getting last saved metrics from a trainer object and appending\n    # the required values to the corresponding lists\n    def on_train_epoch_end(self, trainer, module):\n        metrics_logs = trainer.logged_metrics\n        self.train_loss.append(metrics_logs[\"loss_epoch\"].item())\n        self.train_acc.append(metrics_logs[\"train_acc\"].item())\n        \n        # Print all metrics at the end of current epoch if verbose is set to True.\n        # It is done here because on_train_epoch_end event happens after on_validation_epoch_end event.\n        if self.verbose == True:\n            print(f\"Epoch {module.current_epoch} start learning rate: {self.lr_epoch_start[-1]:.6f}, \"\n                  f\"train_loss: {self.train_loss[-1]:.4f}, \"\n                  f\"train_acc: {self.train_acc[-1]:.4f}, \"\n                  f\"val_loss: {self.val_loss[-1]:.4f}, \"\n                  f\"val_acc: {self.val_acc[-1]:.4f}\")  ","daff42cf":"# Defining model parameters\nclass Model(pl.LightningModule):\n    def __init__(self, input_shape, class_weights):\n        super().__init__()\n        \n        # Input layer\n        self.input = nn.Linear(input_shape,128)\n        # Hidden layers\n        self.hidden1 = nn.Linear(128,64)\n        self.hidden2 = nn.Linear(64,32)\n#         self.hidden3 = nn.Linear(32,16)\n        # Output layer\n        self.output = nn.Linear(32,6)\n        \n        # Dropout rate\n        self.dr = 0.05\n        # Activation functions\n        self.activation = F.relu\n        self.softmax = nn.Softmax(dim=1)\n        # Metrics\n        self.train_acc_metric = torchmetrics.Accuracy(num_classes=6, average=\"micro\")\n        self.val_acc_metric = torchmetrics.Accuracy(num_classes=6, average=\"micro\")\n        self.loss = nn.CrossEntropyLoss()#weight=class_weights)\n        \n        self.flag = False\n    \n    def forward(self, x):\n        x = self.activation(self.input(x))\n        x = F.dropout(x,p=self.dr,training=self.training)\n        x = self.activation(self.hidden1(x))\n        x = F.dropout(x,p=self.dr,training=self.training)\n        x = self.activation(self.hidden2(x))\n        x = F.dropout(x,p=self.dr,training=self.training)\n#         x = self.swish(self.hidden3(x))\n#         x = F.dropout(x,p=self.dr,training=self.training)\n#         x = self.softmax(self.output(x))\n        x = self.output(x)\n        return x\n    \n    # Training loop with loss and metric computing for each train data batch\n    def training_step(self, batch, batch_idx):\n        X, y = batch\n        y_hat = self(X).squeeze(1)\n#         if self.flag == False:\n#             print(y_hat)\n#             self.flag = True\n        loss = self.loss(y_hat, y)\n        self.train_acc_metric(torch.argmax(y_hat, dim=1), y)\n        self.log('loss', loss, prog_bar=True, on_epoch=True, logger=True)\n#         self.log('accuracy', self.train_acc_metric, prog_bar=True, on_epoch=False, logger=True)\n        return {'loss': loss,}\n\n    # Uses batch loss and metric values to compute and print\n    # overall train data loss and metric \n    def training_epoch_end(self, outputs):\n        train_acc = self.train_acc_metric.compute()\n        self.log('train_acc', train_acc, prog_bar=True, on_epoch=True, on_step=False, logger=True)\n        self.train_acc_metric.reset()\n\n\n\n    # Computes loss and metric score for each valid data batch\n    def validation_step(self, batch, batch_idx):\n        X, y = batch\n        y_hat = self(X).squeeze(1)\n        val_loss = self.loss(y_hat, y)\n        self.val_acc_metric(torch.argmax(y_hat, dim=1), y)\n        self.log('val_loss',val_loss, prog_bar=True, on_epoch=True, logger=True)\n        return {'val_loss': val_loss}\n\n    # Uses batch loss and metric values to compute and print\n    # overall valid data loss and metric\n    def validation_epoch_end(self, outputs):\n        val_acc = self.val_acc_metric.compute()\n        self.log('val_acc', val_acc, prog_bar=True, on_epoch=True, on_step=False, logger=True)\n        self.val_acc_metric.reset()\n        return {'val_acc': val_acc}\n\n       \n    def predict_step(self, X, batch_idx, dataloader_idx = None):\n        return self.softmax(self(X[0]))\n    \n    # Setting optimizer and learning rate scheduler parameters if any\n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3, eps=1e-8, weight_decay=1e-2, amsgrad=False)\n#         optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        #lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9, last_epoch=-1, verbose=False)\n        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5,\n                                                                  patience=7, min_lr=1e-04, eps=1e-08,\n                                                                  verbose=False, threshold=0.002, threshold_mode=\"abs\")\n        return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler, \"monitor\": \"val_acc\"}","37d70a4f":"# Trains the model using given train and valid datasets\n# and returns filepath of the best saved model\ndef train_ann(train_ds, valid_ds, class_weights, Model=Model, input_shape=X_nn.shape[1]):\n    \n    model = Model(input_shape, class_weights)\n    model.apply(initialize_weights)\n\n    # A callback to save the best model\n    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n        dirpath=\"models\",\n        filename=f'model_' + '{val_acc:.4}',\n        monitor='val_acc',\n        mode='max',\n        save_weights_only=True)\n\n    # A callback to stop training when there is no improvement\n    early_stop_callback = EarlyStopping(\n        monitor='val_acc',\n        min_delta=0.0004,\n        patience=20,\n        verbose=False,\n        mode='max'\n    )\n\n#     # A callback to check learning rate if it is not constant\n#     lr_monitor = LearningRateMonitor(logging_interval='epoch')\n    \n    # A custom callback to print required parameters\n    params_tracker_callback = ParamsTracker(verbose=True)\n\n    # print(ModelSummary(model))\n\n    # Setting training parameters\n    trainer = pl.Trainer(\n        fast_dev_run=False,\n        max_epochs=60,\n    #         gpus=1,\n        precision=32,\n        limit_train_batches=1.0,\n        limit_val_batches=1.0, \n        num_sanity_val_steps=0,\n        check_val_every_n_epoch=1,\n        val_check_interval=1.0, \n        callbacks=[checkpoint_callback, early_stop_callback, params_tracker_callback],\n     )\n\n    # Training \n    trainer.fit(model, train_ds, valid_ds)\n\n    # Switching model to evaluation mode\n    model.eval()\n\n    # Getting path of the best saved model\n    best_model_path = checkpoint_callback.best_model_path\n    \n    return best_model_path, params_tracker_callback","69131ad8":"%%time\n# Fold splitting parameters\nsplits = 10\nskf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=42)\n\n# Two zero-filled arrays for out-of-fold and test predictions\nnn_oof_preds = np.zeros((X_nn.shape[0],))\nnn_test_preds = np.zeros((X_test_nn.shape[0],6))\ntotal_mean_acc = 0\n\n# Generating folds and making training and prediction for each of them\nfor num, (train_idx, valid_idx) in enumerate(skf.split(X_nn, y)):\n#     if num > 0:\n#         break\n    print(f\"\\n\\n===Training with fold {num}\")\n    X_train, X_valid = X_nn.loc[train_idx], X_nn.loc[valid_idx]\n    y_train, y_valid = y.loc[train_idx], y.loc[valid_idx]\n    \n    # Preparing datasets\n    train_ds, valid_ds = prepare_datasets(X_train, X_valid, y_train, y_valid)\n    \n    # Training model\n    best_model_path, tracked_values = train_ann(train_ds, valid_ds, class_weights, Model, X_nn.shape[1])\n    \n    # Loading weights of the best model\n    model = Model(X_nn.shape[1], class_weights)\n    model.load_state_dict(torch.load(best_model_path)['state_dict'])\n    model.eval()\n    \n    # Making valid data preds and plotting their histogram\n    preds = np.argmax(model(torch.tensor(X_valid.to_numpy()).float()).detach().numpy(), axis=1)\n#     display(pd.DataFrame(preds).hist(bins=50))\n    print(preds)\n    \n    # Calculating and printing this fold's model ROC AUC score\n    fold_score = accuracy_score(y_valid, preds)\n    print(f\"\\n===Fold {num} valid data accuracy score is {fold_score}\")\n    \n    # Making test data preds and plotting their histogram\n    test_preds = nn.Softmax(dim=1)(model(X_test_nn)).detach().numpy()\n#     display(pd.DataFrame(test_preds).hist(bins=50))\n    \n    # Saving preds in corresponding arrays\n    nn_oof_preds[valid_idx] = preds\n    nn_test_preds += test_preds \/ splits\n    \n    total_mean_acc += fold_score \/ splits\n    \nprint(f\"Average accuracy score of all models is {total_mean_acc}\")","76b6d950":"predictions = pd.DataFrame()\npredictions[\"Id\"] = test[\"Id\"]\npredictions[\"Cover_Type\"] = label_enc.inverse_transform(np.argmax(nn_test_preds, axis=1))\n\npredictions.to_csv('submission.csv', index=False, header=predictions.columns)\npredictions.head()","eaec4919":"fig, ax = plt.subplots(figsize=(14, 8))\n\nbars = ax.bar(predictions[\"Cover_Type\"].value_counts().sort_index().index,\n                  predictions[\"Cover_Type\"].value_counts().sort_index().values,\n                  color=colors,\n                  edgecolor=\"black\")\nax.set_title(\"Target distribution\", fontsize=20, pad=15)\nax.set_ylabel(\"Count\", fontsize=14, labelpad=15)\nax.set_xlabel(\"Target label\", fontsize=14, labelpad=20)\nax.tick_params(axis=\"x\", pad=20)\nax.bar_label(bars, predictions[\"Cover_Type\"].value_counts().sort_index().values,\n                 padding=3, fontsize=12)\nax.bar_label(bars, [f\"{x*100:2.1f}%\" for x in predictions[\"Cover_Type\"].value_counts().sort_index().values\/len(train)],\n                 padding=-20, fontsize=12)\nax.margins(0.025, 0.06)\nax.grid(axis=\"y\")\n\nplt.show();","563de367":"Let's check how target distribution differs for samples different amount of said types.","8d41b589":"As you can see proportion of some classes differs from the amount of wildernes area nad soil types. It's a good idea to add two new features showing the amount of said types per sample.","37dea5bb":"# **Data preprocessing**","fc5b175b":"# **Model training**","7577c226":"Some samples could have several wildernes area and soil types as you can see below.","b441ae5f":"# **Data import**","1f5b0bc0":"It looks like soil types 7 and 15 does not have any examples. Let's check it. If so, they could be dropped from the datasets.","e233338f":"To be continued...","712a6c87":"# **EDA**","696be48a":"There are no missing values in the both datasets.\n\nLet's check feature values distribution in the both datasets."}}