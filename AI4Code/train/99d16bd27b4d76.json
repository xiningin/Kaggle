{"cell_type":{"615d8879":"code","1b28bc32":"code","72835228":"code","c5f96eb1":"code","10dd056b":"code","2f0a2761":"code","ccacd560":"code","4989f4fc":"code","10c5506a":"code","9ecceb3a":"code","2854259e":"code","edbfcd1c":"code","e297a6b4":"code","8028f0db":"code","f1c82545":"code","4692dee2":"code","fdfef189":"code","9c9907bd":"code","2451c5f1":"code","120b8c38":"code","0404f8d2":"code","0e66d892":"code","4e31d584":"code","e548dc72":"code","2df4b18f":"code","680be5d3":"code","c4758cf7":"code","e849dc72":"code","70823b59":"code","7a56894f":"code","735c7894":"code","c725a44b":"code","e0d549ef":"code","8a90120e":"code","71a0a15d":"code","d1158874":"code","9a8d6c15":"code","4d0048d3":"code","6599c86c":"code","80735ff9":"code","609a57dd":"markdown","b2991669":"markdown","2ac38255":"markdown","d88b33d5":"markdown","ba5a579f":"markdown","9b5c72d7":"markdown","519953ee":"markdown","a93f68bb":"markdown","35ace91b":"markdown","5690f518":"markdown"},"source":{"615d8879":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","1b28bc32":"data=pd.read_csv('..\/input\/banking.csv')","72835228":"data.head()","c5f96eb1":"data.info()","10dd056b":"data.isnull().sum()","2f0a2761":"data.describe()","ccacd560":"data.corr()","4989f4fc":"\nsns.countplot(x=data['y'])\nplt.xlabel('Subscribed for Term deposit')\nlabels=[\"Didn't open term deposit\",\"Open term deposit\"]\n","10c5506a":"sns.pairplot(data=data,hue='y')","9ecceb3a":"plt.figure(figsize=(10,8))\nsns.countplot(x='education',hue='y',data=data)\nplt.tight_layout()","2854259e":"sns.countplot(x='marital',hue='y',data=data)","edbfcd1c":"sns.countplot(x='housing',hue='y',data=data)","e297a6b4":"sns.countplot(x='loan',hue='y',data=data)","8028f0db":"sns.countplot(x='poutcome',hue='y',data=data)","f1c82545":"pd.crosstab(data.marital,data.y).plot(kind='bar')\nplt.xlabel('Marital status')\nplt.ylabel('Proporation of customers')","4692dee2":"data.education[data.education=='basic.4y']='Basic'\ndata.education[data.education=='basic.6y']='Basic'\ndata.education[data.education=='basic.9y']='Basic'\ndata.education[data.education=='high.school']='High School'\ndata.education[data.education=='illiterate']='Illiterate'\ndata.education[data.education=='professional.course']='Professional Course'\ndata.education[data.education=='university.degree']='University Degree'\ndata.education[data.education=='unknown']='Unknown'","fdfef189":"numeric_dtype=data.select_dtypes(exclude='object')","9c9907bd":"sns.heatmap(numeric_dtype.corr(),annot=True)\nplt.title('Correlation Matrix')","2451c5f1":"cat_col=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']","120b8c38":"for col in cat_col:\n    data=pd.concat([data.drop(col,axis=1),pd.get_dummies(data[col],prefix=col,prefix_sep='-',drop_first=True)],axis=1)","0404f8d2":"data.columns","0e66d892":"X=data.drop('y',axis=1)\ny=data['y']","4e31d584":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=2)","e548dc72":"X_train.shape","2df4b18f":"X_test.shape","680be5d3":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,confusion_matrix,roc_curve,roc_auc_score,classification_report\n\nlr=LogisticRegression()\nlr.fit(X_train,y_train)\ny_predl=lr.predict(X_test)\nprobs=lr.predict_proba(X_test)\nprob=probs[:,1]\n\n\nauc=roc_auc_score(y_test,prob)\nprint('AUC score is',auc)","c4758cf7":"fpr,tpr,threshols=roc_curve(y_test,prob)\nplt.plot([0,1],[0,1],linestyle='-')\nplt.plot(fpr,tpr,marker='.')\n","e849dc72":"cm=confusion_matrix(y_test,y_predl)\nsns.heatmap(cm,annot=True)","70823b59":"print('Classification Report',classification_report(y_test,y_predl))","7a56894f":"from sklearn.model_selection import cross_val_score","735c7894":"score=cross_val_score(lr,X,y,scoring='accuracy',cv=10)","c725a44b":"print('After cross validation,Accuracy is',score.mean()*100)","e0d549ef":"from sklearn.feature_selection import RFE\n\nrfe=RFE(lr,12)\nfit=rfe.fit(X_train,y_train)\nselected_feature=fit.support_\nprint('No. of features %d',fit.n_features_)\nprint('Selected Features %d',fit.support_)\nprint('Ranking Features %d',fit.ranking_)","8a90120e":"col_to_drop=[]\nfor i in range(len(X.columns)-1):\n    if selected_feature[i] == False:\n        col_to_drop.append(i)\n        \nX_train.drop(X.iloc[:, col_to_drop], axis=1, inplace = True)\nX_test.drop(X.iloc[:, col_to_drop], axis=1, inplace = True)","71a0a15d":"X_train.columns","d1158874":"from sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier","9a8d6c15":"models=[SVC(class_weight='balanced'),\n        KNeighborsClassifier(),\n        LogisticRegression(class_weight='balanced'),\n        \n]\nscores=pd.DataFrame(columns=['Model','Accuracy','F1-score','Precision','Recall'])\nfor model in models:\n    classifier=model.fit(X_train,y_train)\n    name=str(classifier).rsplit('()',1)\n    accuracy = np.average(cross_val_score(classifier, X_test, y_test, scoring= \"accuracy\"))\n    \n    f1 = np.average(cross_val_score(classifier, X_test, y_test, scoring= \"f1_weighted\"))\n    \n    precision = np.average(cross_val_score(classifier, X_test, y_test, scoring='precision_weighted'))\n    \n    recall = np.average(cross_val_score(classifier, X_test, y_test, scoring='recall_weighted'))\n    \n    scores = scores.append({'Model': name,'Accuracy': accuracy,'F1-score': f1,\n                             'Precision': precision, 'Recall': recall}, ignore_index=True)\n\n\n\n\n\n\n","4d0048d3":"scores.set_index('Model')","6599c86c":"scores.plot(kind='bar',title='Scores')","80735ff9":"from sklearn.model_selection import GridSearchCV\nparam={'n_neighbors':[3,4,6,7,8,9,11,15],'weights':['uniform','distance'],'metric':['euclidean','manhattan']}\ngrid=GridSearchCV(KNeighborsClassifier(),param_grid=param,cv=8,n_jobs=-1)\ngs_results=grid.fit(X_train,y_train)\nprint('Best Score',gs_results.best_score_)\nprint('Best Estimator',gs_results.best_estimator_)\nprint('Best Param',gs_results.best_params_)","609a57dd":"Conclusion :- In this dataset I applied Logistic Regression algorithm with cross validation.And I found that there is a slight increase in accuracy.After that I did RFE feature selection method and tried modelling with SVC,KNN ,Logistic & KNN with grid search.Among these KNN performs well with an accuracy of 89%.","b2991669":"Splitting the data","2ac38255":"Logistic Regression","d88b33d5":"Suggest me to improve better classification accuracy","ba5a579f":"## Visualization","9b5c72d7":"Create dummy variables","519953ee":"Grid search with KNN","a93f68bb":"Feature Extraction with RFE","35ace91b":"Cross Validation","5690f518":"Select numeric and categorical dtypes"}}