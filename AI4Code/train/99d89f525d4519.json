{"cell_type":{"40624054":"code","f908187b":"code","9be69de2":"code","8bcf2900":"code","5ef00eff":"code","8c441797":"code","aff0e79c":"code","40163442":"code","a5e2ddaf":"code","2c98c3fc":"code","7f68174f":"code","adb13acb":"code","6a0dfade":"code","b77e23df":"code","dd2e4971":"code","fdf2bf25":"code","9bc782f7":"code","8b08810d":"code","c9a23342":"code","f375f0b0":"code","1368535f":"code","9facf0a2":"code","6752dc91":"code","4225346b":"code","48e752cf":"code","9c1729e7":"code","855c0c8f":"code","c8962881":"code","727d1b4c":"code","d7024923":"code","6d15258b":"code","e55aa58c":"code","6f0a2730":"code","efc82f57":"code","c1d0bf76":"code","3fc48a8c":"code","e5ecaf9c":"code","3aea703c":"code","73d8b629":"code","c3c9f33e":"code","d7ae5e1c":"code","db4f082c":"code","c93445ad":"code","7ef8fcfe":"code","3a416e4e":"code","15993fe8":"code","37f38c54":"code","31150fc3":"code","e6c31938":"code","4aedfbd1":"code","4d4aceca":"code","f04dfbdd":"code","97ee97cd":"code","d895c90c":"markdown","7889a21e":"markdown","34bd71b7":"markdown","a0c07afe":"markdown","e0fa1108":"markdown","d87298df":"markdown"},"source":{"40624054":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest, f_regression\nfrom sklearn import metrics\nimport math\nfrom scipy.stats import boxcox\nfrom scipy.special import inv_boxcox\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.preprocessing import (StandardScaler, \n                                   PolynomialFeatures)\n\nfrom scipy.stats import boxcox\nfrom scipy.special import inv_boxcox\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler\nimport xgboost\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n\n\nfrom sklearn.ensemble import GradientBoostingRegressor","f908187b":"df=pd.read_csv('..\/input\/seoul-bike-rental-ai-pro-iti\/train.csv')\ndf.head()","9be69de2":"Winter_df = df.loc[(df['Seasons'] == 'Winter')]\nSummer_df = df.loc[(df['Seasons'] == 'Summer')]\nAutumn_df = df.loc[(df['Seasons'] == 'Autumn')]\nSpring_df = df.loc[(df['Seasons'] == 'Spring')]\n################################","8bcf2900":"temp_winter = Winter_df.groupby('Hour').mean()\ntemp_summer = Summer_df.groupby('Hour').mean()\ntemp_autumn = Autumn_df.groupby('Hour').mean()\ntemp_spring = Spring_df.groupby('Hour').mean()\n#################################################\ny_Hour_winter = temp_winter['y']\ny_Hour_summer = temp_summer['y']\ny_Hour_autumn = temp_autumn['y']\ny_Hour_spring = temp_spring['y']\nHour = np.arange(0,24,step = 1)\n# ax = plt.subplots(2,2,1)\nfig, axs = plt.subplots(2, 2,figsize=(20,10))\naxs[0, 0].bar(Hour,y_Hour_winter,color = 'b')\naxs[0, 0].set_title('Winter')\naxs[0, 1].bar(Hour,y_Hour_summer,color = 'r')\naxs[0, 1].set_title('Summer')\naxs[1, 0].bar(Hour,y_Hour_autumn,color = 'g')\naxs[1, 0].set_title('Autumn')\naxs[1, 1].bar(Hour,y_Hour_spring,color='y')\naxs[1, 1].set_title('Spring')\nplt.show()\n","5ef00eff":"##############################################\ny_Hour_autumn_df = pd.DataFrame(Hour,columns = ['Hour'])\ny_Hour_autumn_df['Seasons'] = 'Autumn'\ny_Hour_autumn_df['y_avg_autumn_hour'] = y_Hour_autumn\n\ny_Hour_spring_df = pd.DataFrame(Hour,columns = ['Hour'])\ny_Hour_spring_df['Seasons'] = 'Spring'\ny_Hour_spring_df['y_avg_spring_hour'] = y_Hour_spring\n\ny_Hour_summer_df = pd.DataFrame(Hour,columns = ['Hour'])\ny_Hour_summer_df['Seasons'] = 'Summer'\ny_Hour_summer_df['y_avg_summer_hour'] = y_Hour_summer\n\ny_Hour_winter_df = pd.DataFrame(Hour,columns = ['Hour'])\ny_Hour_winter_df['Seasons'] = 'Winter'\ny_Hour_winter_df['y_avg_winter_hour'] = y_Hour_winter\n#######################################################\nmerged_df=pd.merge(df,y_Hour_autumn_df,on=['Seasons','Hour'],how='left')\nmerged_df=pd.merge(merged_df,y_Hour_spring_df,on=['Seasons','Hour'],how='left')\nmerged_df=pd.merge(merged_df,y_Hour_summer_df,on=['Seasons','Hour'],how='left')\nmerged_df=pd.merge(merged_df,y_Hour_winter_df,on=['Seasons','Hour'],how='left')\n########################################################\nmerged_df = merged_df.fillna(0)\n##################################\nmerged_df['y_avg_season_hour'] = merged_df['y_avg_autumn_hour']+ merged_df['y_avg_spring_hour'] +merged_df['y_avg_summer_hour'] +merged_df['y_avg_winter_hour']\ndf['y_avg_season_hour'] = merged_df['y_avg_season_hour']","8c441797":"cluster_list = ['Temperature(\ufffdC)','Humidity(%)','Wind speed (m\/s)','Visibility (10m)','Solar Radiation (MJ\/m2)','Rainfall(mm)','Snowfall (cm)']\nX = StandardScaler().fit_transform(df[cluster_list])\nkmeans = KMeans(n_clusters=14)\nmodel = kmeans.fit(X)\ndf['weathercluster'] = model.predict(StandardScaler().fit_transform(df[cluster_list]))","aff0e79c":"df.describe().T\n","40163442":"print(df['Functioning Day'].unique())\nprint(df['Seasons'].unique())\nprint(df['Holiday'].unique())","a5e2ddaf":"y=df[['y']]\nX=df.drop(['y','ID'], axis=1)\ny=np.ravel(y)\n","2c98c3fc":"X1=X.copy()\nfrom sklearn.preprocessing import LabelBinarizer\ndef Binarizer(column,data):\n    encoder = LabelBinarizer()\n    encoder.fit(data[column].astype(str))\n    transformed = encoder.transform(data[column].astype(str))\n    ohe_df = pd.DataFrame(transformed)\n    data = pd.concat([data, ohe_df], axis=1).drop([column], axis=1)\n    data=data.rename(columns={0:column})\n    data[column]=data[column].astype(np.int64)\n    return data\n#X1=Binarizer('Holiday',X1)\nX1=Binarizer('Functioning Day',X1)\n","7f68174f":"# defining Lag features\n\nfeatures=['Hour','Temperature(\ufffdC)','Visibility (10m)','Solar Radiation (MJ\/m2)','y_avg_season_hour'\\\n          ,'Humidity(%)','Wind speed (m\/s)','Snowfall (cm)','Rainfall(mm)','Dew point temperature(\ufffdC)','weathercluster']\n\ndef lag(data,features, shift):\n    for feature in features:\n        data['lag_'+str(shift)+'_'+feature] = data[feature].shift(shift)","adb13acb":"\n\n#Changing date object to datetime \nX1['Date']=pd.to_datetime(X1['Date'])\nX1['year']=pd.to_datetime(X1['Date'].dt.year).astype(np.int64)\nX1['day']=pd.to_datetime(X1['Date'].dt.day).astype(np.int64)\n\n#creating DayOfWeek feature\nX1['dayofweek'] = X1['Date'].dt.dayofweek\nX1['WeekOfYear'] = X1['Date'].dt.isocalendar().week.astype(np.int64)\nX1['DayofYear'] = X1['Date'].dt.dayofyear\n\nX1['hours_dt'] = pd.to_datetime(X1['Hour'], format='%H')\nhours_list = [7,8,9,17,18,19,20,21,22]\nX1['Travelling_time'] = np.where(X1['Hour'].isin(hours_list), 1, 0)\n\n\nlag(X1,features,-1)\nlag(X1,features,-3)\nlag(X1,features,-5)\nlag(X1,features,-7)\nlag(X1,features,-9)\nlag(X1,features,-11)\nlag(X1,features,3)\nlag(X1,features,1)\n\n\nX1.fillna(0,inplace=True)","6a0dfade":"X1.describe()\n","b77e23df":"# Testing the correlation between the features and the target value\ncorr_test=pd.concat([X1,pd.DataFrame(y)],axis=1)\ncorr_test.corr(method='pearson')[0].sort_values(ascending=False)","dd2e4971":"X1.isna().sum()","fdf2bf25":"num_cols=X1.select_dtypes('number').columns\nskew_limit=0.5\nskew_vals=X1[num_cols].skew()\n","9bc782f7":"#Showing the skew columns\nskew_cols=skew_vals[abs(skew_vals)>skew_limit].sort_values(ascending=False)\nskew_cols","8b08810d":"\n\n# Let's look at what happens to one of these features when we apply np.log1p visually\nfield='Wind speed (m\/s)'\n\n#Create two subplots and a figure using matplotlib\nfig,(ax_before,ax_after)=plt.subplots(1,2,figsize=(10,5))\n\n#Create a histogram of the ax_before subplot\nX1[field].hist(ax=ax_before)\n\n#Applying the transformation and create a histogram of the ax_after subplot\nX1[field].apply(np.log1p).hist(ax=ax_after)\n\n#Formating the titles for each subplot\nax_before.set(xlabel='value',ylabel='frequenct',title='Before the np.log1p transformation')\nax_after.set(xlabel='value',ylabel='frequenct',title='after the np.log1p transformation')\nfig.suptitle('field {}'.format(field));\n\n","c9a23342":"# #perform the skew transformations\n\nfor col in skew_cols.index.values:\n    if col=='Seasons_Spring'or col=='Seasons_Summer' or col=='Seasons_Winter' or col=='Visibility (10m)':\n        continue\n    X1[col]=X1[col].apply(np.log1p)\n    ","f375f0b0":"X1.skew().sort_values(ascending=False)\n\n#Skewness has dropped significantly after np.log1p transofrmation","1368535f":"#Now check for Null Values \nprint(X1.isnull().sum().sort_values())\nX2=X1.copy()\n","9facf0a2":"X2_pairplot=pd.concat([X2,pd.DataFrame(y)],axis=1)\n\n\n","6752dc91":"X2_pairplot.head()","4225346b":"ordinal_vals = {'Winter':1,'Spring':2,'Autumn':3,'Summer':4,'No Holiday':0,'Holiday':1}\n# ordinal_wof = {25:45,29:44,34:43,42:42,33:41,24:40,28:39,32:38,23:37,49:36,41:35,16:34,45:33,27:32,36:31,20:30,19:29,14:28,46:27,47:26,10:25,2:24,6:23,37:22,15:21,11:20,18:19,1:18,40:17,38:16,9:15,5:14,31:13,12:12,50:11,8:10,22:9,3:8,13:7,35:6,26:5,44:4,7:3,48:2,51:1}","48e752cf":"X2 = X2.replace(ordinal_vals)\n# X2['SortedWeekOfYear'] = X2['WeekOfYear'].replace(ordinal_wof)","9c1729e7":"X2['Humidity(%)'] = np.where(X2['Humidity(%)']==0, 57, X2['Humidity(%)'])","855c0c8f":"X2.info()","c8962881":"X2.drop(['Date','hours_dt','Dew point temperature(\ufffdC)','Snowfall (cm)'], axis=1,inplace=True)\n\ny_log=np.log1p(y)\nX_train, X_eval, y_train, y_eval=train_test_split(X2, y_log, test_size=0.3, random_state=42)\n\nX_train.info()","727d1b4c":"xgb_best = xgboost.XGBRegressor(colsample_bytree= 0.7,\n learning_rate=0.04,\n max_depth= 4,\n min_child_weight= 0.4,\n n_estimators= 2000,\n nthread= 4,\n objective= 'reg:linear',\n silent=1,\n subsample=0.7)\nxgb_best.fit(X2,y_log)\npred = xgb_best.predict(X_eval)\nprint(r2_score(y_eval,pred))\nprint(np.sqrt(metrics.mean_squared_error(y_eval,pred)))\n\n","d7024923":"df_test=pd.read_csv('..\/input\/seoul-bike-rental-ai-pro-iti\/test.csv')\ndf_test.head()\n","6d15258b":"df_test['weathercluster'] = model.predict(StandardScaler().fit_transform(df_test[cluster_list]))","e55aa58c":"merged_test_df=pd.merge(df_test,y_Hour_autumn_df,on=['Seasons','Hour'],how='left')\nmerged_test_df=pd.merge(merged_test_df,y_Hour_spring_df,on=['Seasons','Hour'],how='left')\nmerged_test_df=pd.merge(merged_test_df,y_Hour_summer_df,on=['Seasons','Hour'],how='left')\nmerged_test_df=pd.merge(merged_test_df,y_Hour_winter_df,on=['Seasons','Hour'],how='left')\n########################################################\nmerged_test_df = merged_test_df.fillna(0)\n##################################\nmerged_test_df['y_avg_season_hour'] = merged_test_df['y_avg_autumn_hour']+ merged_test_df['y_avg_spring_hour'] +merged_test_df['y_avg_summer_hour'] +merged_test_df['y_avg_winter_hour']\ndf_test['y_avg_season_hour'] = merged_test_df['y_avg_season_hour']","6f0a2730":"X_test=df_test.drop(['ID'], axis=1)\nX_test.info()","efc82f57":"def lag(data,features, shift):\n    for feature in features:\n        data['lag_'+str(shift)+'_'+feature] = data[feature].shift(shift)","c1d0bf76":"lag(X_test,features,-1)\nlag(X_test,features,-3)\nlag(X_test,features,-5)\nlag(X_test,features,-7)\nlag(X_test,features,-9)\nlag(X_test,features,-11)\nlag(X_test,features,3)\nlag(X_test,features,1)\n\n\n\n","3fc48a8c":"X1_test=X_test.copy()\n\n\nX1_test=Binarizer('Functioning Day',X1_test)","e5ecaf9c":"\n\n#Changing date object to datetime \nX1_test['Date']=pd.to_datetime(X1_test['Date'])\n","3aea703c":"num_cols=X1_test.select_dtypes('number').columns\nskew_limit=0.75\nskew_vals=X1_test[num_cols].skew()","73d8b629":"#Showing the skew columns\nskew_cols=skew_vals[abs(skew_vals)>skew_limit].sort_values(ascending=False)\nskew_cols","c3c9f33e":"#perform the skew transformations\n\nfor col in skew_cols.index.values:\n    if col=='Seasons_Spring'or col=='Seasons_Summer' or col=='Seasons_Winter' or col=='Visibility (10m)':\n        continue\n    X1_test[col]=X1_test[col].apply(np.log1p)\n    ","d7ae5e1c":"X2_test=X1_test.copy()","db4f082c":"# Tranforming Date to days,months and years\nX2_test['year']=pd.to_datetime(X2_test['Date'].dt.year)\nX2_test['day']=pd.to_datetime(X2_test['Date'].dt.day)\n\nX2_test['year']=pd.to_numeric(X2_test['year'])\nX2_test['day']=pd.to_numeric(X2_test['day'])\n\n\n\n","c93445ad":"X2_test['dayofweek'] = X2_test['Date'].dt.dayofweek\nX2_test['WeekOfYear'] = X2_test['Date'].dt.isocalendar().week.astype(np.int64)\nX2_test['DayofYear'] = X2_test['Date'].dt.dayofyear\nX2_test['hours_dt'] = pd.to_datetime(X2_test['Hour'], format='%H')\nX2_test['Travelling_time'] = np.where(X2_test['Hour'].isin(hours_list), 1, 0)\n\n\nX2_test.drop('Date',axis=1,inplace=True)\n\nX2_test.info()","7ef8fcfe":"X2_test = X2_test.replace(ordinal_vals)","3a416e4e":"X2_test['Humidity(%)'] = np.where(X2_test['Humidity(%)']==0, 57, X2_test['Humidity(%)'])","15993fe8":"cols_list = X2.columns.tolist()","37f38c54":"X2_test=X2_test[cols_list]\n\nX2_test.info()","31150fc3":"X2_test.fillna(0,inplace=True)","e6c31938":"y_test_predict_XGB=xgb_best.predict(X2_test)","4aedfbd1":"y_test_final_XGB=np.exp(y_test_predict_XGB)-1\ny_test_final_XGB = np.where(y_test_final_XGB<0.0,0,y_test_final_XGB)","4d4aceca":"df_testXGB=df_test.copy()","f04dfbdd":"df_testXGB['y']=y_test_final_XGB\n\n","97ee97cd":"df_testXGB[['ID','y']].to_csv('\/kaggle\/working\/submissiongbrXGBFinal.csv', index=False)","d895c90c":"# Adding Y_AVG_HOUR_SEASON FEATURE","7889a21e":"# Clustering Weather Data","34bd71b7":"# Handeling the Test Data","a0c07afe":"# Importing and Initially exploring the data","e0fa1108":"# Log Transformation of Skew Variables","d87298df":"## Encoding non numeric catagorical data  "}}