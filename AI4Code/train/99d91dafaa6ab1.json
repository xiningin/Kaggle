{"cell_type":{"e38e006c":"code","00abd0b6":"code","025f769f":"code","08e4918e":"code","473d40b3":"code","ed592465":"code","db2aefcc":"code","9e2964a3":"code","47eb1306":"code","f1cd6f1a":"code","1ee94200":"code","fd544610":"code","f52ab5f5":"code","a47db1a3":"code","49173ad0":"code","9c15c943":"code","30050419":"code","29ab6ffb":"code","f82fc886":"code","e324beb8":"code","c758edd9":"code","07f5cf8e":"code","1ada05f7":"code","515f765d":"code","5634e48a":"code","5eb74930":"code","d223883f":"code","8e2911cd":"code","99a2a435":"code","9ce1a0bb":"code","8530ce85":"code","bb0f9cf6":"code","5b38905d":"code","35f882c4":"code","cf8846d5":"code","101b298e":"code","8077b5f3":"code","8eba7e06":"code","2b987eac":"code","0be12859":"code","587b05ae":"markdown","937d122c":"markdown","d0692ad0":"markdown","11da5310":"markdown","a3f38be0":"markdown","003c30ec":"markdown","e181bedb":"markdown","ac3a61d2":"markdown","7e101047":"markdown","9761946d":"markdown","08c32a67":"markdown","e1ce7b08":"markdown","07d442e7":"markdown","9eabf5fc":"markdown","bc24e76a":"markdown","4ee9af34":"markdown","77a2c50c":"markdown","a3a8fae1":"markdown","6e366116":"markdown","6f1de72a":"markdown","ba15a24e":"markdown","b96d9f4b":"markdown","d1072a7f":"markdown"},"source":{"e38e006c":"import gc\nimport numpy  as np\nimport pandas as pd\nimport lightgbm  as lgb\nimport seaborn   as sns\nimport missingno as msno\nimport plotly.express as px\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics         import roc_auc_score, accuracy_score\nfrom sklearn.model_selection import train_test_split","00abd0b6":"# Read data\nfull_data = pd.read_excel('\/kaggle\/input\/covid19\/dataset.xlsx')\nfull_data.sample(5)","025f769f":"# Create dataframe counting NaN values per column\nnan_df = pd.DataFrame(full_data.isna().sum()).reset_index()\nnan_df.columns  = ['Column', 'NaN_Count']\nnan_df['NaN_Count'] = nan_df['NaN_Count'].astype('int')\nnan_df['NaN_%'] = round(nan_df['NaN_Count']\/5644 * 100,1)\nnan_df['Type']  = 'Missingness'\nnan_df.sort_values('NaN_%', inplace=True)","08e4918e":"# Add completeness\nfor i in range(nan_df.shape[0]):\n    complete_df = pd.DataFrame([nan_df.loc[i,'Column'],full_data.shape[0] - nan_df.loc[i,'NaN_Count'],100 - nan_df.loc[i,'NaN_%'], 'Completeness']).T\n    complete_df.columns  = ['Column','NaN_Count','NaN_%','Type']\n    complete_df['NaN_%'] = complete_df['NaN_%'].astype('int')\n    complete_df['NaN_Count'] = complete_df['NaN_Count'].astype('int')\n    nan_df = nan_df.append(complete_df, sort=True)","473d40b3":"# Missingness Plot\nfig = px.bar(nan_df,\n             x='Column',\n             y='NaN_%',\n             title='Missingness Plot',\n             color='Type',\n             template='plotly_dark',\n             opacity = 0.6,\n             height = 800,\n             color_discrete_sequence=['#dbdbdb','#38cae0']\n            )\nfig.show()","ed592465":"# Drop null columns\ndrop_list = ['D-Dimer','Prothrombin time (PT), Activity', 'Partial thromboplastin time\\xa0(PTT)\\xa0', 'Urine - Sugar', 'Fio2 (venous blood gas analysis)']\nfull_data = full_data.drop(drop_list, axis=1)\n\n# Fill NaNs with -10\nfull_data = full_data.fillna(-10, axis=1)\n\n# Binarize SARS-Cov-2 label\nfull_data['SARS-Cov-2 exam result'] = np.where(full_data['SARS-Cov-2 exam result'] == 'positive',1,0)\n\n# Compact care unit label\nfull_data['Care_unit'] = np.where(full_data['Patient addmited to intensive care unit (1=yes, 0=no)'] == 1,2,\n                                  np.where(full_data['Patient addmited to semi-intensive unit (1=yes, 0=no)'] == 1,1,0))\n\n# Drop care unit columns\ndrop_list = ['Patient addmited to regular ward (1=yes, 0=no)', 'Patient addmited to semi-intensive unit (1=yes, 0=no)', 'Patient addmited to intensive care unit (1=yes, 0=no)']\nfull_data = full_data.drop(drop_list, axis=1)","db2aefcc":"# Summarise data\ncount_df = pd.DataFrame(full_data['SARS-Cov-2 exam result'].value_counts()).reset_index()\ncount_df.columns = ['Label','Count']\ncount_df = count_df.iloc[::-1]\n\n# Create annotations\nannotations = [dict(\n            y=count_df.loc[i,'Label'],\n            x=count_df.loc[i,'Count'] + 150,\n            text=str(round(count_df.loc[i,'Count']\/5644*100,1))+'%',\n            font=dict(\n            size=14,\n            color=\"#000000\"\n            ),\n            bordercolor=\"#c7c7c7\",\n            borderwidth=1,\n            borderpad=4,\n            bgcolor=\"#ffffff\",\n            opacity=0.95,\n            showarrow=False,\n        ) for i in range(count_df.shape[0])]\n\n# Generate Plot\nfig = px.bar(count_df,\n             y='Label',\n             x='Count',\n             orientation='h',\n             title='Label Distribution of SARS-Cov-2',\n             template='plotly_dark'\n            )\nfig.update_layout(annotations = annotations)\nfig.update_traces(marker_color='#35bdcc',\n                  #marker_line_color='#ffffff',\n                  #marker_line_width=1,\n                  opacity=0.8)\n\nfig.show()","9e2964a3":"# Accuracy baseline\n5086 \/ (5086 + 558)","47eb1306":"# Separate `object` type variables into a different dataframe\ncolnames  = full_data.columns[(full_data.dtypes == 'O').tolist()].tolist()\nobject_df = full_data[colnames].copy()\nfull_data.drop(colnames, axis = 1, inplace = True)","f1cd6f1a":"# Analyze each variable....\nfor i,col in enumerate(object_df.columns):\n    if col == 'Patient ID':\n        continue\n    print('------------------[{}]------------------'.format(i))\n    print(object_df[col].value_counts()) ","1ee94200":"# Detected\/notdetected\ndetection_list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n\n# Positive\/negative exams\npositive_list = [18,19,20]\n\n# Presence\/absence exams\npresence_list = [21,24,25,26,29,32,33,34]\n\n# Apply corrections\nfor i in detection_list:\n    object_df[colnames[i]] = np.where(object_df[colnames[i]] == 'detected',1,np.where(object_df[colnames[i]] == -10,-10,0))\n    \nfor i in positive_list:\n    object_df[colnames[i]] = np.where(object_df[colnames[i]] == 'positive',1 , np.where(object_df[colnames[i]] == 'negative', 0, -10))\n    \nfor i in presence_list:\n    object_df[colnames[i]] = np.where(object_df[colnames[i]] == 'present',1 , np.where(object_df[colnames[i]] == 'absent', 0, -10))","fd544610":"# Special cases\nobject_df.loc[object_df[colnames[30]] == '<1000', colnames[30]] = 500\nobject_df[colnames[30]] = object_df[colnames[30]].astype('int64')\n\nobject_df.loc[object_df[colnames[23]] == 'N\u00e3o Realizado', colnames[23]] = -10\nobject_df[colnames[23]] = object_df[colnames[23]].astype('float32')\n\n\nobject_df[colnames[28]] = np.where(object_df[colnames[28]] == 'normal', 0, -10)\nobject_df[colnames[22]] = np.where(object_df[colnames[22]] == 'clear', 0, np.where(object_df[colnames[22]] == -10, -10, 1))\nobject_df[colnames[31]] = np.where(object_df[colnames[31]] == 'Ausentes', 0, np.where(object_df[colnames[31]] == -10, -10, 1))\nobject_df[colnames[35]] = np.where(object_df[colnames[35]] == 'yellow', 0, np.where(object_df[colnames[35]] == -10, -10, 1))\n\nobject_df = object_df.drop(colnames[27],axis=1)","f52ab5f5":"# Concat back both dataframes\nfull_data = pd.concat([full_data, object_df], axis=1)","a47db1a3":"keep_list = ['Patient age quantile',\n 'Hematocrit',\n 'Hemoglobin',\n 'Platelets',\n 'Mean platelet volume ',\n 'Red blood Cells',\n 'Lymphocytes',\n #'Mean corpuscular hemoglobin concentration\\xa0(MCHC)',\n 'Leukocytes',\n 'Monocytes',\n 'Basophils',\n #'Red blood cell distribution width (RDW)',\n #'Mean corpuscular volume (MCV)',\n 'Eosinophils',\n #'Mean corpuscular hemoglobin (MCH)',\n 'SARS-Cov-2 exam result'\n]","49173ad0":"parallel_df = full_data.copy()\nkeep_list = nan_df.query(\"NaN_Count == 5042 and Type == 'Missingness'\").Column.tolist()\nkeep_list = keep_list + ['SARS-Cov-2 exam result']","9c15c943":"fig = px.parallel_coordinates(parallel_df[keep_list],\n                              color=\"SARS-Cov-2 exam result\",\n                              template='plotly_dark',\n                              labels={\"Mean corpuscular hemoglobin concentration\\xa0(MCHC)\": \"MCHC\",\"Mean corpuscular hemoglobin (MCH)\": \"MCH\", \"Mean corpuscular volume (MCV)\": \"MCV\",\"Red blood cell distribution width (RDW)\": \"RDW\"},\n                              color_continuous_scale=['#dbdbdb','#38cae0'],\n                              title='Fluxo de Vari\u00e1veis de Hemograma'\n                             )\n\n\nfig.show()","30050419":"keep_list2 = nan_df.query(\"NaN_Count == 4292 and Type == 'Missingness'\").Column.tolist()\nkeep_list2.sort()\nkeep_list2 = ['SARS-Cov-2 exam result'] + keep_list2","29ab6ffb":"fig = px.parallel_categories(parallel_df[keep_list2].query('Adenovirus > -10'),\n                              color=\"SARS-Cov-2 exam result\",\n                              template='plotly_dark',\n                              labels={\"SARS-Cov-2 exam result\":\"COVID-19\",\"CoronavirusOC43\": \"C-OC43\",\"CoronavirusNL63\": \"C-NL63\",\n                                      \"Coronavirus HKU1\": \"C-HKU1\",\"Coronavirus229E\": \"C-229E\",\"Rhinovirus\/Enterovirus\": \"Rhino\/Enterovirus\",\n                                      \"Chlamydophila pneumoniae\": \"Chlamydophila\", \"Bordetella pertussis\": \"Bordetella\",\"Inf A H1N1 2009\": \"InfA H1N1\"},\n                              color_continuous_scale=['#dbdbdb','#38cae0'],\n                              title='Fluxo de Vari\u00e1veis de Hemograma'\n                             )\n\n\nfig.show()","f82fc886":"# Create training and testing splits\ntrain_df, test_df = train_test_split(full_data,\n                                     stratify     = full_data['SARS-Cov-2 exam result'],\n                                     test_size    = 0.3,\n                                     random_state = 451\n                                     )","e324beb8":"# Isolate labels\ntrain_label = train_df.pop('SARS-Cov-2 exam result')\ntest_label  = test_df.pop('SARS-Cov-2 exam result')","c758edd9":"# Isolate ids\ntrain_ids = train_df.pop('Patient ID')\ntest_ids  = test_df.pop('Patient ID')","07f5cf8e":"# Reset column names\ncols_list = train_df.columns.tolist()\ntrain_df.columns = list(range(train_df.shape[1]))\ntest_df.columns  = list(range(test_df.shape[1]))","1ada05f7":"# Create lgb dataset\nlgb_train = lgb.Dataset(train_df, label = train_label)\nlgb_test  = lgb.Dataset(test_df,  label = test_label)","515f765d":"params = {'num_leaves': 173,\n            'min_child_weight': 0.0,\n            'feature_fraction': 0.37030374041940073,\n            'bagging_fraction': 1.0,\n            'scale_pos_weight': 3.1711826966844865,\n            'reg_lambda': 40.72176285252339,\n            'reg_alpha': 10.0,\n            'min_data_in_leaf': 9,\n            'objective': 'binary',\n            'max_depth': -1,\n            'learning_rate': 0.006214136848886512,\n            'boosting_type': 'gbdt',\n            'bagging_seed': 42,\n            'metric': 'auc',\n            'verbosity': -1,\n            'random_state': 451,\n               }","5634e48a":"lgb_model = lgb.train(params,\n                      lgb_train,\n                      10000,\n                      valid_sets   = [lgb_train],\n                      verbose_eval = 1000\n                     )","5eb74930":"def evaluate_model(preds, eval_df = test_label):\n    '''\n    Evaluate Predictions Function\n    Returns accuracy and auc of the model\n    '''\n    auroc = roc_auc_score(eval_df.astype('uint8'), preds)\n    accur = accuracy_score(eval_df.astype('uint8'), preds >= 0.5)\n    print('Accuracy: ' + str(accur))\n    print('AUC: ' + str(auroc))","d223883f":"# Evaluate Model on testing set\nlgb_preds = lgb_model.predict(test_df)\nevaluate_model(lgb_preds)","8e2911cd":"# Create dataframe with feature importances\nfeature_importance_df = pd.DataFrame(lgb_model.feature_importance(), columns=['Feature Importance'])\nfeature_importance_df['Features'] = cols_list\nfeature_importance_df.sort_values('Feature Importance', inplace=True, ascending=True)","99a2a435":"px.bar(feature_importance_df.reset_index(drop=True)[102-25:102],\n       y='Features',\n       x='Feature Importance',\n       orientation='h',\n       template='plotly_dark',\n       color='Feature Importance',\n       opacity=0.8,\n       title='Top 25 Feature Importance',\n       color_continuous_scale=['#dbdbdb','#38cae0'],\n       height=700\n      )","9ce1a0bb":"px.box(full_data,\n       x = 'SARS-Cov-2 exam result',\n       y='Patient age quantile',\n       color='SARS-Cov-2 exam result',\n       title='Age Quantile vs COVID-19 Exam Result',\n       template='plotly_dark',\n       color_discrete_sequence=['#dbdbdb','#38cae0'],\n       width=800\n      )","8530ce85":"bloodwork_df = full_data.query(\"Leukocytes > -10 and Monocytes >-10\")\nbloodwork_df['SARS-Cov-2 exam result'] = bloodwork_df['SARS-Cov-2 exam result'].astype('str')","bb0f9cf6":"keep_list = ['Patient age quantile',\n 'SARS-Cov-2 exam result',\n 'Hematocrit',\n 'Hemoglobin',\n 'Platelets',\n 'Mean platelet volume ',\n 'Red blood Cells',\n 'Lymphocytes',\n 'Mean corpuscular hemoglobin concentration\\xa0(MCHC)',\n 'Leukocytes',\n 'Monocytes',\n 'Basophils',\n 'Red blood cell distribution width (RDW)',\n 'Mean corpuscular volume (MCV)',\n 'Eosinophils',\n 'Mean corpuscular hemoglobin (MCH)'\n]","5b38905d":"px.scatter_3d(bloodwork_df,\n              y=\"Patient age quantile\",\n              z=\"Leukocytes\",\n              x=\"Monocytes\",\n              color='SARS-Cov-2 exam result',\n              opacity=0.7,\n              color_discrete_map = {\"0\": \"#dbdbdb\", \"1\":\"#38cae0\"},\n              template='plotly_dark'\n             )","35f882c4":"def engineer_features(df):\n    df['volume']     = 1\/((df['Platelets']+10) * (df['Mean platelet volume ']+10))\n    df['blood_var1'] = (df['Hematocrit']+10)\/(df['Hemoglobin']+10)\n    df['blood_var2'] = (df['Lymphocytes']+10) \/ (df['volume']+10)\n    df['blood_var3'] = df['Leukocytes'] \/ df['volume']\n    return(df)","cf8846d5":"bloodwork_df = engineer_features(bloodwork_df)","101b298e":"# Create train and testing set for bloodwork dataset\nblood_train_df, blood_test_df = train_test_split(bloodwork_df.drop('Patient ID', axis=1),\n                                                 #bloodwork_df.loc[:,keep_list],\n                                                 test_size = 0.3,\n                                                 stratify  = bloodwork_df['SARS-Cov-2 exam result'],\n                                                 random_state = 451\n                                                )","8077b5f3":"# Isolate Labels\nblood_train_label = blood_train_df.pop('SARS-Cov-2 exam result').astype('int')\nblood_test_label  = blood_test_df.pop('SARS-Cov-2 exam result').astype('int')\n\n# Rename columns\nblood_train_df.columns = list(range(blood_train_df.shape[1]))\nblood_test_df.columns  = list(range(blood_test_df.shape[1]))\n\n# Create lgb dataset\nlgb_blood_train = lgb.Dataset(blood_train_df, label = blood_train_label)\nlgb_blood_test  = lgb.Dataset(blood_test_df,  label = blood_test_label)","8eba7e06":"best_params = {'num_leaves': 10,\n               'min_child_weight': 0.0,\n               'feature_fraction': 0.6944647141727874,\n               'bagging_fraction': 0.5674331535075892,\n               'scale_pos_weight': 0.1,\n               'reg_lambda': 7.263952208457604,\n               'reg_alpha': 0.0,\n               'min_data_in_leaf': 0,\n               'objective': 'binary',\n               'max_depth': -1,\n               'learning_rate': 0.01,\n               'boosting_type': 'gbdt',\n               'bagging_seed': 42,\n               'metric': 'auc',\n               'verbosity': -1,\n               'random_state': 451\n              }","2b987eac":"lgb_blood_model = lgb.train(best_params,\n                      lgb_blood_train,\n                      1000,\n                     )","0be12859":"# Evaluate Model on testing set\nblood_lgb_preds = lgb_blood_model.predict(blood_test_df)\nevaluate_model(blood_lgb_preds, eval_df=blood_test_label)","587b05ae":"# Model Parameters","937d122c":"In this dataset, there are a bunch of variables of type `object` that we have to do something about.\n\nWe'll first isolate them, inspect them and them choose an appropriate transformation.","d0692ad0":"Vou fazer um split padr\u00e3o 70\/30%.\n\nNesse split \u00e9 **essencial estratificar pela vari\u00e1vel de interesse**.\nCaso n\u00e3o seja estratificado, estamos expondo a distribui\u00e7\u00e3o do nosso testing set ao acaso, podendo gerar com um testing set com poucos casos positivos (e isso daria um resultado \u00f3timo, s\u00f3 que sem significado pr\u00e1tico nenhum) ou nosso set de treino pode ficar com poucos casos positivos e n\u00e3o ter dados suficientes para aprender.","11da5310":"Age does seem to be connected to COVID-19 diagnosis, but it is more plausible that the dataset has an inherent selection bias than age has that much power to predict COVID-19.\n\nFrom a causal standpoint, we know that imune systems become weaker with age, but this is by no means exclusive to COVID-19.\n\nAlso worth noting is that media can have an impact and potentially cause a selection bias as well - as groups of risk are targeted in the media, it can induce a disproportial amount of patients from those groups to come to the hospital, thus consolidating a selection bias within the dataset and any model built upon it.\n\nOther variables may certainly have a higher importance than age, though they are most likely offset by missingness.","a3f38be0":"# Bloodwork Model","003c30ec":"# Split Treino e Teste","e181bedb":"# Investigating Results","ac3a61d2":"# Data Preparation","7e101047":"There are many variables to be preapred, so first off we'll elimate the ones that are completely empty or don't vary at all.\n\nAs for the labels, we'll encode it as a numeric.","9761946d":"# Data Preprocessing","08c32a67":"# Exploratory Data Analysis","e1ce7b08":"We'll start by importing the data and checking for missingness prior to any analysis.","07d442e7":"A idade t\u00eam se mostrado muito importante para o diagn\u00f3stico...ao ponto de ser suspeito...\n","9eabf5fc":"We have a lot of class imbalance, making accuracy **inadequate** as a metric.\nOur 'brainless' model using only the most common occurence gives us `90.11%` accuracy","bc24e76a":"Most features here are binary with missingness, in a few special cases there are more classes, but they are often so small in number that I chose to group them.\n\nAs most variables are within the rante -5 ~ 5, I'll declare missingness as -10, as to note missigness without shifiting the distribution too much. ","4ee9af34":"Podemos ver que o COVID-19 est\u00e1 geralmente associado aos **demais testes virais serem negativos**, com excess\u00e3o de um caso que apontou Rhinovirus\/Enterovirus e COVID-19 simultaneamente.","77a2c50c":"Nosso modelo teve um ganho consider\u00e1vel em AUC e um ganho singelo em acur\u00e1cia.\n\nConsiderando que o modelo \u00e9 extremamente carente de dados (nossa \u00fanica vari\u00e1vel completa \u00e9 o quantil da idade), esse parece ser um bom resultado, e que se aplica \u00e0 base inteira.","a3a8fae1":"We can use a subset of this population with bloodwork variables and try to predict to all only them.\nThe caveat here is that such model is not specific, we expect to see great results as any infection would cause a surge into bloodwork behaviour.","6e366116":"Os par\u00e2metros a seguir foram obtidos atrav\u00e9s de sucessivas rodadas de cross-validation:","6f1de72a":"We can see that their considerable missingness: With the exception of the labels, IDS and Age there are often more 70% of data missing for every other feature.\nAt the same time, it appears that such missingness occurs in parallel, which is likely to be caused by the procedures that were done for that patient.","ba15a24e":"Agora \u00e9 a hora de ver como nosso modelo performou!\n\nLembrando que nosso baseline de Acur\u00e1cia \u00e9 `90.11%` e AUC baseline de `0.5`.","b96d9f4b":"# Evaluate Model","d1072a7f":"# Train LightGBM Model"}}