{"cell_type":{"48262c93":"code","c717d00d":"code","70a60513":"code","20e9549e":"code","887ab447":"code","d8b45720":"code","3bd5c44d":"code","d4173f50":"code","bc4f130d":"code","b01909c5":"code","00ed1c37":"code","7cbba073":"code","ae50ff63":"code","5ee11c8e":"code","0aa0adb7":"code","ae54e83d":"code","f9716769":"code","93f168b8":"code","43031e94":"code","ae03dea6":"code","3085aea1":"code","dd674731":"code","b9272a17":"code","ccb2401c":"code","80798e20":"code","0a5353f7":"code","aec03ce7":"code","a2aa496b":"code","8c2d5ffa":"code","21c7b1ec":"code","de93296f":"code","902775d4":"code","ef34e3f2":"code","dec1cc1a":"code","49cbe946":"code","da9089d8":"code","01a2d76d":"code","cce9a7a4":"code","35378992":"code","f9d97306":"markdown","eaf00e57":"markdown","2d2c4a8f":"markdown","58f2361a":"markdown","abab1b5a":"markdown","b6e00ec1":"markdown"},"source":{"48262c93":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\npd.set_option('display.max_columns', 1000)\nbase = \"\/kaggle\/input\/corruption-perceptions-index-for-10-years\"\n\n# Any results you write to the current directory are saved as output.","c717d00d":"files_by_year = {str(x):f\"CPI_{x}_final_dataset.csv\" for x in range(2010, 2020)}\ndfs = {k:pd.read_csv(f\"{base}\/{v}\") for k,v in files_by_year.items()}","70a60513":"final_cols = ['Year', 'Country', 'CPI Score', 'Rank', 'Number of Sources', 'Minimum score', 'Maximum score',\n              'Standard Error', '90% Confidence Interval (Higher bound)', '90% Confidence Interval (Lower bound)',\n              'ADB', 'AfDB', 'BF_SGI', 'BF_TI', 'EIU', 'FH', 'GI', 'IMD', 'PERC', 'PRS', 'TI', 'VDP', 'WB', 'WEF', 'WJP'\n]","20e9549e":"col_map = {'Country Rank': 'Rank', 'Country \/ Territory': 'Country', 'CPI 2010 Score': 'CPI Score', \n           'Surveys Used': 'Number of Sources', 'Standard Deviation': 'Standard Error', 'ADB 2009': 'ADB',\n           'AfDB 2009': 'AfDB', 'BF 2009': 'BF_TI', 'EIU 2010': 'EIU', 'FH 2010': 'FH', 'GI 2010': 'GI',\n           'IMD 2010': 'IMD', 'PERC2010': 'PERC', 'WB 2009': 'WB', 'WEF 2010': 'WEF'}\ndf_2010 = dfs['2010'].rename(columns=col_map)\ndf_2010","887ab447":"col_map.update({'CPI 2011 Score': 'CPI Score', 'AFDB' : 'AfDB', 'EIU_CRR': 'EIU', 'FH_NIT': 'FH', 'GI_CRR': 'GI', 'IMD2011': 'IMD', 'PERC2011': 'PERC', 'WEF2011': 'WEF', 'PERC2010': 'PERC2010', 'PRS_ICRG': 'PRS', 'TI_BPI': 'TI', 'WB_CPIA': 'WB', 'WJP_ROL': 'WJP'})\ndf_2011 = dfs['2011'].rename(columns=col_map)\ndf_2011","d8b45720":"def append(df1, df2, year1, year2):\n    if year1:\n        df1['Year'] = year1\n    if year2:\n        df2['Year'] = year2\n    return df1.loc[:, final_cols].append(df2.loc[:, final_cols], ignore_index=True)\nresult = append(df_2010, df_2011, 2010, 2011)\nresult","3bd5c44d":"def rename_and_append(df, result, year, col_map):\n    df = df.rename(columns=col_map)\n    return append(result, df, None, year)","d4173f50":"col_map.update({'CPI 2012 Score': 'CPI Score', '90% Confidence interval (Lower bound)': '90% Confidence Interval (Lower bound)',\n                '90% Confidence interval (Higher bound)': '90% Confidence Interval (Higher bound)',\n                'BF (SGI)' : 'BF_SGI', 'BF (BTI)': 'BF_TI', 'ICRG': 'PRS', 'PERC2011': 'PERC',\n                'WEF2011': 'WEF', 'PERC2010': 'PERC2010'})\nresult = rename_and_append(dfs['2012'], result, 2012, col_map)\nresult","bc4f130d":"col_map.update({'CPI 2013 Score': 'CPI Score'})\nresult = rename_and_append(dfs['2013'], result, 2013, col_map)\nresult","b01909c5":"col_map.update({'Country\/Territory': 'Country', 'CPI 2014': 'CPI Score', 'Number of Surveys Used': 'Number of Sources', 'Std Error': 'Standard Error', 'Min': 'Minimum score', 'Max': 'Maximum score', '90% Lower CI': '90% Confidence Interval (Lower bound)', '90% Upper CI': '90% Confidence Interval (Higher bound)'})\nresult = rename_and_append(dfs['2014'], result, 2014, col_map)\nresult","00ed1c37":"col_map.update({'CPI 2015 Score': 'CPI Score', 'Min': 'Minimum score', 'Max': 'Maximum score', '90%Upper CI': '90% Confidence Interval (Higher bound)', '90% Lower CI': '90% Confidence Interval (Lower bound)'})\ncol_map.update({'World Bank CPIA': 'WB', 'World  Economic Forum EOS': 'WEF', 'Bertelsmann  Foundation TI': 'BF_TI', 'Arican Development Bank': 'AfDB', 'IMD World Competitiveness Year Book': 'IMD', 'Bertelsmann Foundation SGI': 'BF_SGI', 'World Justice Project ROL': 'WJP', 'PRS Internationl Country Risk Guide': 'PRS', 'Economist Intelligence Unit': 'EIU', 'IHS Global Insight': 'GI', 'PERC Asia Risk Guide': 'PERC', 'Freedom House NIT': 'FH'})\nresult = rename_and_append(dfs['2015'], result, 2015, col_map)\nresult","7cbba073":"col_map.update({'CPI2016': 'CPI Score', 'World Economic Forum EOS': 'WEF', \n                'Global Insight Country Risk Ratings': 'GI', \n                'Bertelsmann Foundation Transformation Index': 'BF_TI', \n                'African Development Bank CPIA': 'AfDB', 'IMD World Competitiveness Yearbook': 'IMD', \n                'Bertelsmann Foundation Sustainable Governance Index': 'BF_SGI', \n                'World Justice Project Rule of Law Index': 'WJP', \n                'PRS International Country Risk Guide': 'PRS', 'Varities of Democracy Project': 'VDP', \n                'Economist Intelligence Unit Country Ratings': 'EIU', \n                'Freedom House Nations in Transit Ratings': 'FH', \n                'Std Error 2016': 'Standard Error', 'Lower CI': '90% Confidence Interval (Lower bound)',\n                'Upper CI': '90% Confidence Interval (Higher bound)'})\nresult = rename_and_append(dfs['2016'], result, 2016, col_map)\nresult","ae50ff63":"col_map.update({'CPI Score 2017': 'CPI Score', 'Rank 2017': 'Rank', 'Standard error 2017': 'Standard Error',\n                'Lower CI 2017': '90% Confidence Interval (Lower bound)', \n                'Upper CI 2017': '90% Confidence Interval (Higher bound)', 'Sources': 'Number of Sources',\n                'Varieties of Democracy Project': 'VDP'})\nresult = rename_and_append(dfs['2017'], result, 2017, col_map)\nresult","5ee11c8e":"col_map.update({'CPI Score 2018': 'CPI Score', 'Rank ': 'Rank', 'Standard error': 'Standard Error',\n                'Number of sources': 'Number of Sources', \n                'Lower CI ': '90% Confidence Interval (Lower bound)'})\nresult = rename_and_append(dfs['2018'], result, 2018, col_map)\nresult","0aa0adb7":"col_map.update({'CPI score 2019': 'CPI Score', 'standard error ': 'Standard Error'})\nresult = rename_and_append(dfs['2019'], result, 2019, col_map)\nresult","ae54e83d":"# No column has all nulls\nfor col in result.columns:\n    assert not all(result[col].isnull())","f9716769":"no_nulls_cols = ['Year', 'Country', 'CPI Score', 'Rank', '90% Confidence Interval (Lower bound)', \n                 '90% Confidence Interval (Higher bound)', 'Standard Error']\nfor col in no_nulls_cols:\n    assert not any(result[col].isnull())","93f168b8":"min_count = min([len(df) for df in dfs.values()])\nassert all([x >= min_count for x in result.groupby('Year')['Country'].count().values])","43031e94":"total_count = sum([len(df) for df in dfs.values()])\nassert total_count == len(result)","ae03dea6":"min_max_cols = ['Minimum score', 'Maximum score']\nfor col in min_max_cols:\n    assert set(result[result[col].isnull()]['Year'].drop_duplicates().values) == {2017, 2018, 2019}","3085aea1":"assert not any(result['Minimum score'] > result['Maximum score'])\nassert not any(result['90% Confidence Interval (Lower bound)'] > result['90% Confidence Interval (Higher bound)'])","dd674731":"result['Number of Sources'] = result['Number of Sources'].astype('int')\nresult","b9272a17":"# Scores for 2010 & 2011 are between 0 & 10 (rather than 0 & 100 for other years; hence multiplying them by 10)\nresult.loc[result['Year'] == 2010, 'CPI Score'] *= 10\nresult.loc[result['Year'] == 2011, 'CPI Score'] *= 10\n\nresult.loc[result['Year'] == 2010, 'Minimum score'] *= 10\nresult.loc[result['Year'] == 2011, 'Minimum score'] *= 10\nresult.loc[result['Year'] == 2010, 'Maximum score'] *= 10\nresult.loc[result['Year'] == 2011, 'Maximum score'] *= 10\n\nresult.loc[result['Year'] == 2010, 'Standard Error'] *= 10\nresult.loc[result['Year'] == 2011, 'Standard Error'] *= 10\n\nresult.loc[result['Year'] == 2010, '90% Confidence Interval (Higher bound)'] *= 10\nresult.loc[result['Year'] == 2011, '90% Confidence Interval (Higher bound)'] *= 10\nresult.loc[result['Year'] == 2010, '90% Confidence Interval (Lower bound)'] *= 10\nresult.loc[result['Year'] == 2011, '90% Confidence Interval (Lower bound)'] *= 10\nresult","ccb2401c":"# Standardize the country names so that joins are better\ncountry_renames = {}\ncountry_renames['Brunei'] = ['Brunei Darussalam']\ncountry_renames['Republic of the Congo'] = ['Congo  Republic', 'Congo Republic', 'Congo-Brazzaville', 'Republic of Congo']\ncountry_renames[\"C\u00f4te d'Ivoire\"] = [\"Cote d'Ivoire\", \"C\u00f4te D'Ivoire\", \"C\u00f4te d\u00b4Ivoire\", \"C\u00f4te d\u2019Ivoire\"]\ncountry_renames['Democratic Republic of the Congo'] = ['Democratic Republic of Congo', 'The Democratic Republic of Congo', 'Democratic Republic of the Congo ']\ncountry_renames['Guinea-Bissau'] = ['Guinea Bissau']\ncountry_renames['North Korea'] = ['Korea (North)', 'Korea, North']\ncountry_renames['South Korea'] = ['Korea (South)', 'Korea, South']\ncountry_renames['Saint Vincent and the Grenadines'] = ['Saint Vincent and The Grenadines']\ncountry_renames['Sao Tome & Principe'] = ['Sao Tome and Principe']\ncountry_renames['United States of America'] = ['The United States of America', 'United States']","80798e20":"def standardize_country_names(df, col='Country'):\n    df = df[df[col] != 'p']\n    for key, values in country_renames.items():\n        for value in values:\n            df.loc[df[col] == value, col] = key\n    return df\n","0a5353f7":"def merge_ref_data(df1, df2, cols_df1, cols_df2, idx_col1='Country', idx_col2='Country'):\n    df1 = df1[[idx_col1] + cols_df1] if cols_df1 else df1.reset_index()\n    df2 = df2[[idx_col2] + cols_df2] if cols_df2 else df2.reset_index()\n    ref_data1 = standardize_country_names(df1, idx_col1).set_index(idx_col1)\n    ref_data2 = standardize_country_names(df2, idx_col2).set_index(idx_col2)\n\n    merged = ref_data1.merge(ref_data2, left_index=True, right_index=True, how='outer', suffixes=('', '_y'))\n    second_cols = [x for x in merged.columns if x.endswith('_y')]\n    for col in second_cols:\n        first_col = col[:-2]\n        merged[first_col].fillna(merged[col], inplace=True)\n\n    cols = [x for x in merged.columns if not x.endswith('_y') and not (idx_col1 != idx_col2 and x == idx_col2)]\n    merged = merged[cols]\n    merged.index.name = idx_col1\n    return merged\n\nref_data = merge_ref_data(dfs['2019'], dfs['2018'], ['ISO3', 'Region'], ['ISO3', 'Region'])\nref_data","aec03ce7":"ref_data = merge_ref_data(ref_data, dfs['2017'], None, ['ISO3'])\nref_data","a2aa496b":"ref_data = merge_ref_data(ref_data, dfs['2016'], None, ['Region', 'WB Code', 'OECD', 'G20', 'BRICS', 'EU', 'Arab states'])\nref_data","8c2d5ffa":"ref_data = merge_ref_data(ref_data, dfs['2015'], None, ['Region'], idx_col2='Country\/Territory')\nref_data","21c7b1ec":"ref_data = merge_ref_data(ref_data, dfs['2014'], None, ['Region'], idx_col2='Country\/Territory')\nref_data","de93296f":"ref_data = merge_ref_data(ref_data, dfs['2013'], None, ['WB Code', 'Region', 'IFS Code'], idx_col2='Country \/ Territory')\nref_data","902775d4":"ref_data = merge_ref_data(ref_data, dfs['2012'], None, ['Region'], idx_col2='Country \/ Territory')\nref_data","ef34e3f2":"ref_data['Region'].value_counts()","dec1cc1a":"ref_data.loc[ref_data['Region'] == 'AM', 'Region'] = 'AME'\nref_data['Region'].value_counts()","49cbe946":"ref_data[ref_data['ISO3'].isnull()]","da9089d8":"ref_data[ref_data['Region'].isnull()]","01a2d76d":"result = standardize_country_names(result)\nresult","cce9a7a4":"result = result.merge(ref_data, left_on='Country', right_index=True, how='left')\nresult","35378992":"result.to_csv('merged_cpi_data.csv', index=False)","f9d97306":"## Merge the CPI dataset over 10 years\nBe careful of column name changes & missing columns","eaf00e57":"## Add Reference data like Region, etc. for all countries","2d2c4a8f":"### Merge merged result with reference data","58f2361a":"### Basic data cleanup","abab1b5a":"### Validate the data that was merged","b6e00ec1":"**2010 & 2011 don't have any reference data**"}}