{"cell_type":{"4ca7dadc":"code","4017c4c0":"code","43b34376":"code","e3888334":"code","c04c370b":"code","3f68139f":"code","43020d60":"code","648ef811":"code","658876d7":"code","9f452b3a":"code","36698d4b":"code","420b212d":"code","b483215d":"code","4ddad557":"code","dab67cdf":"code","d6222033":"code","01727504":"code","058c7e3e":"code","e637071c":"code","28093049":"code","75e563ac":"code","dfbc49ae":"code","a243d608":"code","3745da19":"code","090d1570":"code","c5e500ff":"code","8bbbb586":"code","f298b8f0":"code","815df8bd":"code","f6da55c1":"code","cabebbe6":"code","a6628702":"code","f7032439":"code","369b0ff6":"code","0aa82dd7":"code","7048dbdf":"code","f6f86a09":"code","0493b13b":"code","ab03f211":"code","e161fbdb":"code","e97d505e":"code","47fdda24":"code","150cd810":"code","d363954b":"code","a2e9cb36":"code","b9910396":"code","b6183891":"code","3d63e42c":"code","7fcb08e5":"code","7b38203e":"code","f7000e22":"code","78249c54":"code","17637d90":"code","770d674b":"code","f1221156":"code","e41cd35a":"code","baeddd07":"code","43efe4d2":"code","23cada5e":"code","d3101628":"code","6828d7a4":"code","9f25f3df":"code","a0b535d7":"code","de486a8b":"code","04968288":"code","2cf8d5aa":"markdown"},"source":{"4ca7dadc":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import Imputer, LabelEncoder, OneHotEncoder\nimport pandas_profiling as pf\n\nfrom scipy.stats import uniform, randint\nfrom sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\nfrom sklearn.model_selection import cross_val_score, cross_val_predict,GridSearchCV, StratifiedKFold, KFold, RandomizedSearchCV, train_test_split\n\nimport xgboost as xgb\nimport imblearn","4017c4c0":"data = pd.read_csv('https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/00492\/Metro_Interstate_Traffic_Volume.csv.gz')\ndata.head()","43b34376":"pf.ProfileReport(data)","e3888334":"data.holiday.unique()","c04c370b":"data.weather_main.unique()","3f68139f":"data.weather_description.unique()","43020d60":"data.info()","648ef811":"data.date_time = pd.to_datetime(data.date_time)","658876d7":"data['weekday'] = data.date_time.dt.dayofweek","9f452b3a":"data.weekday.unique()","36698d4b":"data['hour'] = data.date_time.dt.hour","420b212d":"data['month'] = data.date_time.dt.month","b483215d":"data.columns","4ddad557":"data.drop('date_time',1, inplace=True)","dab67cdf":"data.loc[data['holiday']=='None']","d6222033":"data.holiday.unique()","01727504":"data_holiday = data.holiday\ndata_holiday.value_counts()","058c7e3e":"data['holiday'] = data['holiday'].apply(lambda x: 'None' if x=='None' else 'Holiday')","e637071c":"data['holiday'] = data['holiday'].apply(lambda x: 0 if x=='None' else 1)","28093049":"data.holiday.value_counts()","75e563ac":"\nsns.distplot(data['holiday'])","dfbc49ae":"le1 = LabelEncoder()\ndata['weather_main'] = le1.fit_transform(data['weather_main'])","a243d608":"data.weather_description.value_counts()","3745da19":"le2 = LabelEncoder()\ndata['weather_description'] = le1.fit_transform(data['weather_description'])","090d1570":"data.head()","c5e500ff":"data[['holiday','weather_main','weather_description', 'weekday', 'hour','month']] = data[['holiday','weather_main','weather_description', 'weekday', 'hour','month']].astype('category')","8bbbb586":"data.columns","f298b8f0":"X = data.drop('traffic_volume',1)\ny = data.traffic_volume","815df8bd":"X = pd.get_dummies(X)\nX.head()","f6da55c1":"X.columns","cabebbe6":"data1 = data.drop('traffic_volume',1)\nfrom sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(random_state=1, max_depth=10)\nmodel.fit(data1,y)\n#Plot the feature importance to see the important features\nfeatures = data1.columns\nimportances = model.feature_importances_\nindices = np.argsort(importances)[-9:] #Top 10 features\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()","a6628702":"model = RandomForestRegressor(random_state=1, max_depth=10)\nmodel.fit(X,y)\n#Plot the feature importance to see the important features\nfeatures = X.columns\nimportances = model.feature_importances_\nindices = np.argsort(importances)[-15:] #Top 10 features\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()","f7032439":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX = sc_X.fit_transform(X)\nsc_y = StandardScaler()\ny = sc_y.fit_transform(y.values.reshape(-1,1))","369b0ff6":"from sklearn.decomposition import PCA\npca = PCA(n_components=4)\npca_result = pca.fit_transform(X)","0aa82dd7":"#visualize using the explained_variance_ratio_\n\nplt.plot(range(4),pca.explained_variance_ratio_)\nplt.plot(range(4), np.cumsum(pca.explained_variance_ratio_))\nplt.title('Component-wise and cumulative Explained variance')\nplt.legend()","7048dbdf":"pca_result.shape","f6f86a09":"from sklearn.decomposition import FastICA\nICA = FastICA(n_components=3, random_state=12)\nICA_data = ICA.fit_transform(X)\n\nplt.figure(figsize=(12,8))\nplt.title('ICA Components')\nplt.scatter(ICA_data[:,0], ICA_data[:,1])\nplt.scatter(ICA_data[:,1], ICA_data[:,2])\nplt.scatter(ICA_data[:,2], ICA_data[:,0])","0493b13b":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)","ab03f211":"from sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train,y_train)","e161fbdb":"y_pred = regressor.predict(X_test)","e97d505e":"from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score","47fdda24":"regressor.score(X_test,y_test)","150cd810":"np.sqrt(mean_squared_error(y_test,y_pred))","d363954b":"(sc_y.inverse_transform(y_test[:10]),sc_y.inverse_transform(y_pred[:10]))","a2e9cb36":"from sklearn.linear_model import Ridge\nregressor = Ridge()\nregressor.fit(X_train,y_train)\ny_pred = regressor.predict(X_test)\nregressor.score(X_test,y_test),mean_squared_error(y_test,y_pred)","b9910396":"sc_y.inverse_transform(y_test[:10]),sc_y.inverse_transform(y_pred[:10])","b6183891":"from sklearn import neighbors\nfor k in range(3,10):\n    n_neighbors=k\n    regressor=neighbors.KNeighborsRegressor(n_neighbors,weights='uniform',n_jobs=-1)\n    regressor.fit(X_train,y_train)\n    y_pred = regressor.predict(X_test)\n    print(regressor.score(X_test,y_test),mean_squared_error(y_test,y_pred))","3d63e42c":"from sklearn.tree import DecisionTreeRegressor\nregressor = DecisionTreeRegressor(max_depth=20)\nregressor.fit(X_train,y_train)\ny_pred = regressor.predict(X_test)\nregressor.score(X_test,y_test),mean_squared_error(y_test,y_pred)","7fcb08e5":"(sc_y.inverse_transform(y_test[:10]),sc_y.inverse_transform(y_pred[:10]))","7b38203e":"from sklearn.svm import SVR\nregressor=SVR()\nregressor.fit(X_train,y_train)\ny_pred = regressor.predict(X_test)\nregressor.score(X_test,y_test),mean_squared_error(y_test,y_pred)","f7000e22":"from sklearn.ensemble import RandomForestRegressor\nestim = np.arange(100,1000,100)\nfor k in estim:\n    regressor=RandomForestRegressor(n_estimators=k)\n    regressor.fit(X_train,y_train)\n    y_pred = regressor.predict(X_test)\n    print(f'{k} estimators - {regressor.score(X_test,y_test),mean_squared_error(y_test,y_pred)}')","78249c54":"regressor=RandomForestRegressor(n_estimators=500,n_jobs=-1)\nregressor.fit(X_train,y_train.ravel())\ny_pred = regressor.predict(X_test)\nregressor.score(X_test,y_test),mean_squared_error(y_test,y_pred)","17637d90":"(sc_y.inverse_transform(y_test[:10]),sc_y.inverse_transform(y_pred[:10]))","770d674b":"xgb_model = xgb.XGBRegressor(objective=\"reg:linear\",  n_estimators=1000, random_state=42,n_jobs=-1)\nxgb_model.fit(X_train,y_train,early_stopping_rounds=10,eval_set=[(X_test, y_test)])\n#xgb_model.fit(X_train,y_train,eval_set=[(X_test, y_test)])\ny_pred = xgb_model.predict(X_test)\nxgb_model.score(X_test,y_test), mean_squared_error(y_test, y_pred)","f1221156":"xgb.plot_importance(xgb_model,max_num_features=10)","e41cd35a":"# converts the target tree to a graphviz instance\nxgb.to_graphviz(xgb_model, num_trees=xgb_model.best_iteration)","baeddd07":"def display_scores(scores):\n    print(\"Scores: {0}\\nMean: {1:.3f}\\nStd: {2:.3f}\".format(scores, np.mean(scores), np.std(scores)))","43efe4d2":"def report_best_scores(results, n_top=3):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results['rank_test_score'] == i)\n        for candidate in candidates:\n            print(\"Model with rank: {0}\".format(i))\n            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n                  results['mean_test_score'][candidate],\n                  results['std_test_score'][candidate]))\n            print(\"Parameters: {0}\".format(results['params'][candidate]))\n            print(\"\")","23cada5e":"params = {\n    \"colsample_bytree\": uniform(0.7, 0.3),\n    \"gamma\": uniform(0, 0.5),\n    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n    \"max_depth\": randint(2, 6), # default 3\n    \"n_estimators\": randint(100, 150), # default 100\n    \"subsample\": uniform(0.6, 0.4)\n}\n\nsearch = RandomizedSearchCV(xgb_model, param_distributions=params, random_state=42, n_iter=200, cv=3, verbose=1, n_jobs=-1, return_train_score=True)\n\nsearch.fit(X_train,y_train)\n\nreport_best_scores(search.cv_results_, 1)","d3101628":"xgb_model = xgb.XGBRegressor(objective=\"reg:linear\",random_state=42,n_jobs=-1,colsample_bytree= 0.7467983561008608, gamma= 0.02904180608409973, learning_rate= 0.28985284373248055, max_depth= 5, n_estimators= 1000, subsample= 0.8832290311184181)\nxgb_model.fit(X_train,y_train,early_stopping_rounds=10,eval_set=[(X_test, y_test)])\n# xgb_model.fit(X_train,y_train,eval_set=[(X_test, y_test)])\ny_pred = xgb_model.predict(X_test)\nxgb_model.score(X_test,y_test), mean_squared_error(y_test, y_pred)","6828d7a4":"(sc_y.inverse_transform(y_test[:10]),sc_y.inverse_transform(y_pred[:10]))","9f25f3df":"print(\"best score: {0}, best iteration: {1}, best ntree limit {2}\".format(xgb_model.best_score, xgb_model.best_iteration, xgb_model.best_ntree_limit))","a0b535d7":"xgb_model = xgb.XGBRegressor(objective=\"reg:linear\", random_state=42,colsample_bytree= 0.9078671076075817, gamma= 0.17416830222659868, learning_rate=0.3109944455567122, max_depth= 5, subsample= 0.7671784126862315)\n\nscores = cross_val_score(xgb_model, X, y, scoring=\"neg_mean_squared_error\", cv=10,n_jobs=-1)\n\ndisplay_scores(np.sqrt(-scores))","de486a8b":"y_pred = cross_val_predict(xgb_model,X,y,cv=10,n_jobs=-1)","04968288":"sc_y.inverse_transform(y_pred[:10]),sc_y.inverse_transform(y[:10])","2cf8d5aa":"Model Bulding"}}