{"cell_type":{"a349a289":"code","c7b378ac":"code","89398c59":"code","511c315f":"code","996d9bd2":"code","91b799b1":"code","a0d3c516":"code","93a3b50f":"code","9e1d8e56":"code","aeeed594":"code","95a3dcf1":"code","ed81fdfe":"code","73962eae":"code","eaff098d":"code","748a62e8":"code","7fda710a":"code","3bc272a9":"code","817d4b52":"code","5c4b954e":"code","3efbd747":"code","ba946b61":"code","0ecfffcd":"code","0b75e9a9":"markdown"},"source":{"a349a289":"import pandas as pd\nimport numpy as np\n\n\nimport seaborn as sns\nsns.set_style(\"whitegrid\", {'axes.grid' : False})\nimport os\nfrom tqdm.notebook import tqdm\nimport gc\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns; sns.set()\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import ParameterGrid\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics","c7b378ac":"TARGET_COL = \"diabetes_mellitus\"\ndf = pd.read_csv(\"..\/input\/widsdatathon2021\/TrainingWiDS2021.csv\")\nprint(df.shape)\ntest = pd.read_csv(\"..\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv\")\nprint(test.shape)\ndf['label']='train'\ntest['label']='test'\nframes = [df,test]\njoin_df = pd.concat(frames, keys=['x', 'y'])\nassert len(join_df) == len(df) + len(test)\nlst = join_df.isna().sum()\/len(join_df)\np = pd.DataFrame(lst)\np.reset_index(inplace=True)\np.columns = ['a','b']\nlow_count = p[p['b']>0.8]\ntodelete=low_count['a'].values\ntest_id = test[\"encounter_id\"]\njoin_df.drop(todelete,axis=1,inplace=True)\njoin_df.head()","89398c59":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","511c315f":"join_df.drop(['Unnamed: 0','encounter_id'],inplace=True,axis=1)\nnumerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n\nnewdf = join_df.select_dtypes(include=numerics)\nnumeric_cols = newdf.columns\n\n# Need to do column by column due to memory constraints\ncategorical_cols =  ['elective_surgery','hospital_id','icu_id',\n 'ethnicity', 'gender', 'hospital_admit_source', 'icu_admit_source', 'icu_stay_type', 'icu_type','aids','cirrhosis','hepatic_failure','immunosuppression',\n 'leukemia','lymphoma','solid_tumor_with_metastasis','elective_surgery','apache_post_operative','arf_apache','fio2_apache','gcs_unable_apache','gcs_eyes_apache',\n 'gcs_motor_apache','gcs_verbal_apache','intubated_apache','ventilated_apache','solid_tumor_with_metastasis']\nfor i, v in tqdm(enumerate(categorical_cols)):\n    join_df[v] = join_df[v].fillna(join_df[v].value_counts().index[0])\nfor i, v in tqdm(enumerate([numeric_cols])):\n    join_df[v] =join_df.groupby(['ethnicity','gender'], sort=False)[v].apply(lambda x: x.fillna(x.mean()))\njoin_df[categorical_cols].isna().sum()","996d9bd2":"from sklearn.preprocessing import OrdinalEncoder\n\n# In loop to minimize memory use\nfor i, v in tqdm(enumerate(categorical_cols)):\n    join_df[v] = OrdinalEncoder(dtype=\"int\").fit_transform(join_df[[v]])\n    \n\ngc.collect()\n\ntrain = join_df[join_df['label']==\"train\"]\npredict = join_df[join_df['label']=='test']\n\ntrain.reset_index(inplace=True)\ntrain.drop(['level_0','level_1','label'],inplace=True,axis =1 )\n\npredict.reset_index(inplace=True)\npredict.drop(['level_0','level_1','diabetes_mellitus','label'],inplace=True,axis=1)\nfeatures = train.columns\nnum_feature = [col for col in features if col not in categorical_cols]\n","91b799b1":"num_feature = [col for col in features if col not in categorical_cols and train[col].dtype != 'object']\ndrop_columns=[]\ncorr = train[num_feature].corr()\n# Drop highly correlated features \ncolumns = np.full((corr.shape[0],), True, dtype=bool)\n\nfor i in range(corr.shape[0]):\n    for j in range(i+1, corr.shape[0]):\n        if corr.iloc[i,j] >=0.999 :\n            if columns[j]:\n                columns[j] = False\n                print('FEAT_A: {} FEAT_B: {} - Correlation: {}'.format(train[num_feature].columns[i] , train[num_feature].columns[j], corr.iloc[i,j]))\n        elif corr.iloc[i,j] <= -0.995:\n            if columns[j]:\n                columns[j] = False","a0d3c516":"drop_columns = train[num_feature].columns[columns == False].values\nprint('drop_columns',len(drop_columns),drop_columns)","93a3b50f":"train.drop(drop_columns,inplace=True,axis =1 )\npredict.drop(drop_columns,inplace=True,axis =1 )\ntrain[TARGET_COL].value_counts()\/len(train)","9e1d8e56":"from sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\ndf_majority = train[train['diabetes_mellitus']==0]\ndf_minority = train[train['diabetes_mellitus']==1]\n\ndf_minority_upsampled = resample(df_minority, \n                                 replace=True,     # sample with replacement\n                                 n_samples=83798,    # to match majority class\n                                 random_state= 303) # reproducible results\n \n# Combine majority class with upsampled minority class\ndf_upsampled = pd.concat([df_majority, df_minority_upsampled])\n \n# Display new class counts\ndf_upsampled.diabetes_mellitus.value_counts()\ntrain = df_upsampled","aeeed594":"X_train, X_test, y_train, y_test = train_test_split(\n     train[[c for c in train if TARGET_COL != c]], train[TARGET_COL], test_size=0.20, random_state=42)\nprint(X_train.shape,X_test.shape)","95a3dcf1":"X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.20, random_state=42)","ed81fdfe":"X_train.head()","73962eae":"import h2o\nh2o.init()\nfrom h2o.estimators.glm import H2OGeneralizedLinearEstimator\nfrom h2o.estimators.gbm import H2OGradientBoostingEstimator","eaff098d":"predictors = [c for c in train if TARGET_COL != c]\nresponse_col = TARGET_COL\ntrain=h2o.H2OFrame(train)","748a62e8":"train, test = train.split_frame(ratios = [0.8], seed = 1234)","7fda710a":"glm_model = H2OGradientBoostingEstimator(ntrees = 10,\n                                        max_depth = 5,\n                                        learn_rate = 0.1,\n                                        seed = 1234)\nglm_model.train(predictors, response_col, training_frame= train)\n\n# predict using the model and the testing dataset\npredict1 = glm_model.predict(test)","3bc272a9":"perf = glm_model.model_performance(test)\nperf","817d4b52":"# prediction=glm_model.staged_predict_proba( test)","5c4b954e":"predict","3efbd747":"pred = glm_model.staged_predict_proba(h2o.H2OFrame(predict))[:,1]\n\n","ba946b61":"test=h2o.import_file(\"..\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv\")\ntest[TARGET_COL] = pred","0ecfffcd":"h2o.export_file(test[[\"encounter_id\",\"diabetes_mellitus\"]], path = \".\/women1.csv\")","0b75e9a9":"# Fast AutoMl didnt worked"}}