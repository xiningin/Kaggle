{"cell_type":{"2f61c3b1":"code","d8a55b72":"code","029930fe":"code","5afce82c":"code","50e61eda":"code","71ef484d":"code","819b95da":"code","11868b2c":"code","64f5ad62":"code","e9b2a7d9":"code","2677ea51":"code","55cbb707":"code","6ded0274":"code","7c1192e3":"code","ac9f5ba5":"code","98a83475":"code","9d4744be":"code","312f4021":"code","26ca4019":"code","e07c0b90":"code","bd91364f":"code","d06416d2":"code","8f123da1":"code","7d986be9":"code","e42f7728":"code","a47e0930":"code","e2c529ef":"code","847c4014":"code","f13aca1a":"code","1c8918f6":"code","3517fb25":"code","25dd8b41":"code","aa631cea":"code","805b8381":"code","827724d7":"code","07a9a9ca":"markdown","3cd840b1":"markdown","5b37fbf9":"markdown","b82ca354":"markdown","cdb74299":"markdown","4636fbb7":"markdown","4d59d127":"markdown","4114aeb7":"markdown","a0fb7047":"markdown","59ed2110":"markdown","674f705a":"markdown","fc51dd10":"markdown","2a7b6248":"markdown","a02c9ecd":"markdown","cb0088f1":"markdown","51fa4704":"markdown","a1e03050":"markdown","1c304ae2":"markdown","79017239":"markdown","56eaed37":"markdown"},"source":{"2f61c3b1":"!pip install ..\/input\/timm-library\/timm-0.3.1-py3-none-any.whl","d8a55b72":"# Data Processing\nimport numpy as np \nimport pandas as pd\n\n# Model\nfrom fastai.vision.all import *\nimport torchvision.models as models \n\n# utils\nimport json","029930fe":"path = Path('..\/input\/cassava-leaf-disease-classification')\nos.listdir(path)","5afce82c":"# Lets take a look at the CSV.\ntrain = pd.read_csv(path\/\"train.csv\")\ntrain.head()","50e61eda":"len(train)","71ef484d":"train['label'].hist(figsize = (10, 5))","819b95da":"f = open (path\/'label_num_to_disease_map.json', \"r\") \n\ndata = json.loads(f.read()) \nprint(data)\nf.close()","11868b2c":"train['path'] = train['image_id'].map(lambda x:path\/'train_images'\/x)\ntrain = train.drop(columns=['image_id'])\ntrain = train.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ntrain.head(10)","64f5ad62":"item_tfms = RandomResizedCrop(460, min_scale=0.75, ratio=(1.,1.))\nbatch_tfms = [*aug_transforms(size=224, max_warp=0), Normalize.from_stats(*imagenet_stats)]\nbs=32","e9b2a7d9":"dls = ImageDataLoaders.from_df(train, #pass in train DataFrame\n                               valid_pct=0.2, #80-20 train-validation random split\n                               seed=999, #seed\n                               label_col=0, #label is in the first column of the DataFrame\n                               fn_col=1, #filename\/path is in the second column of the DataFrame\n                               bs=bs, #pass in batch size\n                               item_tfms=item_tfms, #pass in item_tfms\n                               batch_tfms=batch_tfms)","2677ea51":"dls.show_batch()","55cbb707":"if not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n        os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n\n!cp '..\/input\/..\/input\/efficientnet-b3\/tf_efficientnet_b3_ns-9d44bf68.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/tf_efficientnet_b3_ns-9d44bf68.pth'","6ded0274":"from timm import create_model\nfrom fastai.vision.learner import _update_first_layer\n\ndef create_timm_body(arch:str, pretrained=True, cut=None, n_in=3):\n    \"Creates a body from any model in the `timm` library.\"\n    model = create_model(arch, pretrained=pretrained, num_classes=0, global_pool='')\n    _update_first_layer(model, n_in, pretrained)\n    if cut is None:\n        ll = list(enumerate(model.children()))\n        cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n    if isinstance(cut, int): return nn.Sequential(*list(model.children())[:cut])\n    elif callable(cut): return cut(model)\n    else: raise NamedError(\"cut must be either integer or function\")","7c1192e3":"def create_timm_model(arch:str, n_out, cut=None, pretrained=True, n_in=3, init=nn.init.kaiming_normal_, custom_head=None,\n                     concat_pool=True, **kwargs):\n    \"Create custom architecture using `arch`, `n_in` and `n_out` from the `timm` library\"\n    body = create_timm_body(arch, pretrained, None, n_in)\n    if custom_head is None:\n        nf = num_features_model(nn.Sequential(*body.children())) * (2 if concat_pool else 1)\n        head = create_head(nf, n_out, concat_pool=concat_pool, **kwargs)\n    else: head = custom_head\n    model = nn.Sequential(body, head)\n    if init is not None: apply_init(model[1], init)\n    return model","ac9f5ba5":"def timm_learner(dls, arch:str, loss_func=None, pretrained=True, cut=None, splitter=None,\n                y_range=None, config=None, n_out=None, normalize=True, **kwargs):\n    \"Build a convnet style learner from `dls` and `arch` using the `timm` library\"\n    if config is None: config = {}\n    if n_out is None: n_out = get_c(dls)\n    assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n    if y_range is None and 'y_range' in config: y_range = config.pop('y_range')\n    model = create_timm_model(arch, n_out, default_split, pretrained, y_range=y_range, **config)\n    learn = Learner(dls, model, loss_func=loss_func, splitter=default_split, **kwargs)\n    if pretrained: learn.freeze()\n    return learn","98a83475":"learner = timm_learner(dls, \n                    'tf_efficientnet_b3_ns', \n                     opt_func = ranger,\n                     loss_func=LabelSmoothingCrossEntropy(),\n                     metrics = [accuracy]).to_native_fp16()","9d4744be":"learner.model_dir = '\/kaggle\/working\/models'","312f4021":"learner.lr_find()","26ca4019":"learner.freeze()\nlearner.fit_flat_cos(1,1e-1, wd=0.5, cbs=[MixUp()])","e07c0b90":"learner.save('stage-1')","bd91364f":"learner = learner.load('stage-1')","d06416d2":"learner.unfreeze()\nlearner.lr_find()","8f123da1":"learner.unfreeze()\nlearner.fit_flat_cos(10,5e-3,pct_start=0,cbs=[MixUp()])","7d986be9":"learner.recorder.plot_loss()","e42f7728":"learner = learner.to_native_fp32()","a47e0930":"learner.save('stage-2')","e2c529ef":"learner.export()","847c4014":"interp = ClassificationInterpretation.from_learner(learner)","f13aca1a":"interp.plot_confusion_matrix()","1c8918f6":"sample = pd.read_csv(path\/'sample_submission.csv')\nsample","3517fb25":"_sample = sample.copy()\n_sample['path'] = _sample['image_id'].map(lambda x:path\/'test_images'\/x)\n_sample = _sample.drop(columns=['image_id'])\ntest_dl = dls.test_dl(_sample)","25dd8b41":"test_dl.show_batch()","aa631cea":"preds, _ = learner.tta(dl=test_dl, n=8, beta=0)","805b8381":"sample['label'] = preds.argmax(dim=-1).numpy()","827724d7":"sample.to_csv('submission.csv',index=False)","07a9a9ca":"From above plot, we have 5 labels (4 diseases and 1 healthy):\n\n1. Cassava Bacterial Blight (CBB)\n2. Cassava Brown Streak Disease (CBSD)\n3. Cassava Green Mottle (CGM)\n4. Cassava Mosaic Disease (CMD)\n5. Healthy\n\nIn this case label 3, Cassava Mosaic Disease (CMD) is the most common label. This imbalance may have to be addressed with a weighted loss function or oversampling.","3cd840b1":"Let's make a submission with these predictions!","5b37fbf9":"Let us define classes as follows","b82ca354":"For fastai, the best way to train a model is to train the frozen pretrained model for a single epoch then train the whole pretrained model for several epochs.\n\nAs shown above, the optimal learning rate for training the frozen model is where the loss is decreasing quickly around ~1e-1. To be safe, we will use high weight decay to help prevent overfitting. We will also use another common state-of-the-art training technique: mixup.","cdb74299":"## Introduction\n\nMisdiagnosis of the many diseases impacting agricultural crops can lead to misuse of chemicals and more outbreaks with significant economic loss and environmental impacts. Current disease diagnosis based on human is time-consuming and expensive, and although computer-vision based models have the promise to increase efficiency.","4636fbb7":"### Finding the learning rate\n\nFastai provide functionality to find optimized learning rate. In order to find the optimized learning rate, the method ``lr_find()`` can be used. The method plot() defined on recorder can be used to plot a line plot between Loss vs. learning Rate. Fastai provide the suggestion also for optimize learning rate","4d59d127":"Okay let's check how many images are available in the training dataset:","4114aeb7":"### Model \n\nIn this competition we are going to use ``timm`` library by Ross Wightman. Let's add pretrained ``EfficientNet-B3`` model's weight. \n\nas we are going to use timm  we won't be using ``cnn_learner`` insted we will be using ``timm_learner`` because ``cnn_learner`` doesn't support the models from ``timm`` library. We could use ``resnet\/18\/34\/50`` pretrained model, and we'll be using the ``accuracy metric`` as this is how this competition will grade our results with. We can also use ``mixed precision`` very easily, along with ``Label Smoothing``","a0fb7047":"put the model back to fp32, and now we can export the model if we want to use later (i.e. for an inference).","59ed2110":"### DataBlock\n\nFirst let's define item and batch transforms and we'll come up with some basic data augmentations.\n\nOur ``item_tfms`` should ensure everything is ready to go into a batch, so we will use Resize.\n\nOur ``batch_tfms`` should apply any extra augmentations we may want. We'll use RandomResizedCropGPU, aug_transforms, and apply our Normalize:\n\nWe will normalize our data based on ImageNet, since that is what our pretrained model was trained with","674f705a":"### Inference\nIt's very simple to perform inference with fastai. The dls.test_dl function allows you to create test dataloader using the same pipeline defined earlier.","fc51dd10":"### Add complete path column to image_id of train.csv","2a7b6248":"Hopefully, we can develop a highly-predictive, robust, and generalizable model with this dataset.\n\nLet's check the distribution of the different classes:","a02c9ecd":"fastai also comes with some additional utilities like checking the confusion matrix:","cb0088f1":"Now let's pass the dataloader to the model and get predictions. We will use a common inference technique known as test-time augmentation (average predictions when passing in various augmented versions of the test image). This is also implemented in fastai. Let's do 8x TTA","51fa4704":"## Specific Objectives\n\nObjectives of \u2018Cassava Leaf Disease Classification Challenge\u2019 is to train a model using images of training dataset to 1) Accurately classify a given image from testing dataset into different diseased category or a healthy leaf;  2) Address depth perception\u2014angle, light, shade, physiological age of the leaf because as an added challenge, effective solutions for farmers must perform well under significant constraints, since African farmers may only have access to mobile-quality cameras with low-bandwidth; ","a1e03050":"## Importing required fastai modules and packages\n\npackage fastai.vision provides infinite number of functionalities to deal with computer vision problems like image classification, image segmentation etc...","1c304ae2":"### Files\n\n***train.csv***\n\n``image_id``: The id defined for each training image.\n\n``label``: Number defined for each disease.\n\n***test.csv***\n\n``image_id``: The id defined for each testing image.\n\n-------------------------------------------------------\n\n***train images***\n\nTraining images with name as image id and in jpg format.\n\n***test images***\n\nTesting images with name as image id and in jpg format.\n\n-------------------------------------------------------\n\n***label_num_to_disease_map.json***\n\nDisease name encoded as label number in train.csv ","79017239":"### And Done, let's submit our submission.csv file ","56eaed37":"## Data\n\n### Data Description\nGiven a photo of an Cassava leaf, can you accurately assess its health? This competition will challenge you to classify each cassava image into four disease categories or a fifth category indicating a healthy leaf. "}}