{"cell_type":{"698dad8e":"code","31d18b73":"code","2706890d":"code","929db8ce":"code","e9e4cd8e":"code","c267557e":"code","a648907d":"code","5338416b":"code","edba4d6d":"code","9527a64a":"code","b153748b":"code","e14cb284":"code","ee2c80a2":"code","31ebb785":"code","6eac3811":"code","f04ccfb9":"code","9b0c4ecf":"code","ee4e7a81":"code","b8acd0fd":"code","d5246d9a":"code","2c35a052":"code","3b7e7d17":"code","23fa8472":"code","a4492b95":"code","622a748f":"code","be2483ec":"code","931b85fe":"code","b9fa2597":"code","dc31cc15":"code","bd629187":"markdown","00e4833e":"markdown","7d7490fa":"markdown","13c9ce3e":"markdown","e2512bb6":"markdown","37cd1ee6":"markdown","72421d77":"markdown","fd3aff5d":"markdown","1ddef862":"markdown","180955c3":"markdown","715d552a":"markdown","56cc1b8d":"markdown","81ec9a7f":"markdown","37f4a781":"markdown","1a2258f8":"markdown","38e15b84":"markdown","ad8210f9":"markdown","e9f9b2fe":"markdown","b48ddb83":"markdown","cd399075":"markdown","f3462956":"markdown","f2d181ca":"markdown","e282d6b7":"markdown","b3051955":"markdown","7ba394de":"markdown","62c40842":"markdown","df569d1c":"markdown","eaa5c826":"markdown"},"source":{"698dad8e":"## Import Support libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport array\nimport math","31d18b73":"## Reading the CSV File Downloaded from the source\ndf = pd.read_csv(\"..\/input\/missing-values-pima-indians-diabetes-data\/pima_Missing_values.csv\")\nprint(df.head())","2706890d":"for i in range(0, 690):\n    if(df.Class[i] == 'tested_positive'):\n        df.Class[i] = 1\n    if(df.Class[i] == 'tested_negative'):\n        df.Class[i] = 0\ndf.Class = df.Class.astype(int)","929db8ce":"sum = [0] * 8\nfor i in range(0,8):\n    for j in range(0, 690):\n        if(df.iloc[j, i] == '<null>'):\n            df.iloc[j, i] = -999\n            sum[i] = sum[i] + 1","e9e4cd8e":"for i in range(0, 8):\n    df.iloc[:, i] = df.iloc[:, i].astype(float)","c267557e":"GlobConst = [3, 110, 105, 18, 20.0, 26.5, 0.5, 30]\n\nprint(\"Global Constants for given database is: \")\nfor i in range(0, 8):\n\tprint(df.columns[i], \" = \", GlobConst[i])","a648907d":"def useGlobalConstant():\n\tfor i in range(0, 8):\n\t\tfor j in range(0, 690):\n\t\t\tif df.iloc[j, i] == -999:\n\t\t\t\tdf.iloc[j, i] = GlobConst[i]\n\tfor i in range(0, 8):\n\t\tfor j in range(0, 690):\n\t\t\tif df.iloc[j, i] == -999:\n\t\t\t\tprint('Error')\n\tprint(df.head())","5338416b":"def useMean():\n\tfor i in range(0, 8):\n\t\tcount = 0\n\t\tsumm = 0\n\t\tfor j in range(0, 690):\n\t\t\tif df.iloc[j, i] != -999:\n\t\t\t\tsumm = summ + df.iloc[j, i]\n\t\t\t\tcount = count + 1\n\t\tavg = summ \/ count\n\t\tavg = round(avg, 3)\n\t\tprint(\"col \", i, \" Average = \", avg, \" total missing = \", (690-count))\n\t\tfor j in range(0, 690):\n\t\t\tif df.iloc[j, i] == -999:\n\t\t\t\tdf.iloc[j, i] = avg\n\tprint(df.head())","edba4d6d":"def useMedian():\n\tfor i in range(0, 8):\n\t\tcount = 0\n\t\tsr = df.iloc[:, i][df.iloc[:, i] != -999]\n\t\t# print(type(sr), \"  \", len(sr))\n\t\tmedian = sr.median()\n\t\tprint(\"col \", i, \" Median = \", median, \" total missing = \", (690 - len(sr)))\n\t\tfor j in range(0, 690):\n\t\t\tif df.iloc[j, i] == -999:\n\t\t\t\tdf.iloc[j, i] = median\n\tprint(df.head())","9527a64a":"print(\"\\n\\nFilling the missing values choice: \")\nprint(\"\\n 1. Use a Global Constant\\n 2. Use mean to fill the value\\n 3. Use Median to fill the value\\n\")\nc = input(\"Choice = \")\nprint(c)\nif c == '1':\n\tuseGlobalConstant()\nelif c == '2':\n    useMean()\nelif c == '3':\n    useMedian()\nelse:\n    print(\"Invalid Input.\")","b153748b":"df_copy = df.iloc[:, 0:8].copy()","e14cb284":"def binningByFreqency(sr):\n\tnoOfBins = (int)(math.sqrt(690))\n\tsr = sr.sort_values()\n\tsort_index = np.array(sr.index)\n\trang = 690\n\tbinwidth = (int)(rang \/ noOfBins)\n\tbins = [[0 for i in range(binwidth)] for j in range(noOfBins)]\n\treturn(bins, sort_index, noOfBins, binwidth)","ee2c80a2":"def smoothByBinMeans():\n\tfor i in range(0, 8):\n\t\tsr = df.iloc[:, i]\n\t\tsr1 = [0 for i in range(0, 690)]\n\t\t(bins, ind, noOfBins, binwidth) = binningByFreqency(sr)\n\t\tn=0\n\t\tfor m in range(0, noOfBins):\n\t\t\tbins[m] = sr[n : (n + binwidth)]\n\t\t\tif(i == 5):\n\t\t\t\tbinMean = round(bins[m].mean(), 1)\n\t\t\telif(i == 6):\n\t\t\t\tbinMean = round(bins[m].mean(), 3)\n\t\t\telse:\n\t\t\t\tbinMean = (int)(bins[m].mean())\n\t\t\tbins[m] = [binMean for k in range(binwidth)]\n\t\t\tn = n + binwidth\n\t\tbins = np.array(bins).flatten()\n\t\t# print(bins)\n\t\tfor j in range(0, len(bins)):\n\t\t\tsr1[ind[j]] = bins[j]\n\t\tdf_copy.iloc[:, i] = sr1\n\tprint(\"CSV named \\\"BinnedDataPimaIndianDiabetes.csv\\\" is generated after binning.\")\n\tdf_copy.to_csv('BinnedDataPimaIndianDiabetes.csv')","31ebb785":"def smoothByBinBoundaries():\n\tfor i in range(0, 8):\n\t\tsr = df.iloc[:, i]\n\t\tsr1 = [0 for i in range(0, 690)]\n\t\t(bins, ind, noOfBins, binwidth) = binningByFreqency(sr)\n\t\tn=0\n\t\tfor m in range(0, noOfBins):\n\t\t\tbins[m] = sr[n : (n + binwidth)]\n\t\t\tfro = bins[m][0]\n\t\t\tbck = bins[m][binwidth-1]\n\t\t\tk=0\n\t\t\tfor l in bins[m]:\n\t\t\t\tx1 = l - fro\n\t\t\t\tx2 = bck - l\n\t\t\t\tif(x1 < x2):\n\t\t\t\t\tbins[m][k] = fro\n\t\t\t\telse:\n\t\t\t\t\tbins[m][k] = bck\n\t\t\t\tk = k + 1\n\t\t\tn = n + binwidth\n\t\t\t# print(bins[m])\n\t\tbins = np.array(bins).flatten()\n\t\tfor j in range(0, len(bins)):\n\t\t\tsr1[ind[j]] = bins[j]\n\t\tdf_copy.iloc[:, i] = sr1\n\tprint(\"CSV named \\\"BinnedDataPimaIndianDiabetes.csv\\\" is generated after binning.\")\n\tdf_copy.to_csv('BinnedDataPimaIndianDiabetes.csv')","6eac3811":"print(\"\\n\\nSmoothing by Binning methods: \")\nprint(\"\\n1. Smooth by Bin Means\\n2. Smooth by Bin Boundaries\")\nc = input(\"Choice = \")\nprint(c)\nif c == '1':\n\tsmoothByBinMeans()\nelif c == '2':\n\tsmoothByBinBoundaries()\nelse:\n\tprint(\"Invalid Input.\")","f04ccfb9":"df_copy2 = df.iloc[:, 0:8].copy()","9b0c4ecf":"def MinMaxNorm():\n\tfor i in range(0, 8):\n\t\tsr = df.iloc[:, i]\n\t\tsr1 = []\n\t\tmina = min(sr)\n\t\tmaxa = max(sr)\n\t\tprint(\"New min value for \", df.columns[i])\n\t\tnew_mina = round((float)(input()), 2)\n\t\tprint(\"New max value for \", df.columns[i])\n\t\tnew_maxa = round((float)(input()), 2)\n\t\tfor j in sr:\n\t\t\tsr1 = sr1 + [((j - mina) \/ (maxa - mina)) * (new_maxa - new_mina) + new_mina]\n\t\tdf_copy2.iloc[:, i] = sr1\n\tprint(\"\\nCSV named \\\"NormalizedDataPimaIndianDiabetes.csv\\\" is generated with normalized values.\")\n\tdf_copy2.to_csv('NormalizedDataPimaIndianDiabetes.csv')","ee4e7a81":"def ZScoreNorm():\n\tfor i in range(0, 8):\n\t\tsr = df.iloc[:, i]\n\t\tsr1=[]\n\t\tmean_sr = sr.mean()\n\t\tstd_sr = sr.std()\n\t\tfor j in sr:\n\t\t\tsr1 = sr1 + [(j - mean_sr) \/ std_sr]\n\t\tdf_copy2.iloc[:, i] = sr1\n\tprint(\"\\nCSV named \\\"NormalizedDataPimaIndianDiabetes.csv\\\" is generated with normalized values.\")\n\tdf_copy2.to_csv('NormalizedDataPimaIndianDiabetes.csv')","b8acd0fd":"def DecimalScal():\t\n\tfor i in range(0, 8):\n\t\tsr = df.iloc[:, i]\n\t\tmaxa = max(sr)\n\t\td = 1\n\t\tsr1 = []\n\t\twhile(maxa > 0):\n\t\t\tmaxa = (int)(maxa \/ 10)\n\t\t\td = d * 10\n\t\tfor j in sr:\n\t\t\tsr1 = sr1 + [j \/ d]\n\t\tdf_copy2.iloc[:, i] = sr1\n\tprint(\"\\nCSV named \\\"NormalizedDataPimaIndianDiabetes.csv\\\" is generated with normalized values.\")\n\tdf_copy2.to_csv('NormalizedDataPimaIndianDiabetes.csv')","d5246d9a":"print(\"\\n\\nNormalization: \")\nprint(\"\\n1. Min-Max Normalization\\n2. Z-Score Normalization\\n3. Decimal Scaling\")\nc = input(\"Choice = \")\nprint(c)\nif c == '1':\n\tMinMaxNorm()\nelif c == '2':\n\tZScoreNorm()\nelif c == '3':\n\tDecimalScal()\nelse:\n\tprint(\"Invalid Input.\")","2c35a052":"df2 = pd.read_csv(\".\/NormalizedDataPimaIndianDiabetes.csv\")\nprint(df2.head())","3b7e7d17":"plt.figure(figsize=(10, 12))\nsns.set(rc={'figure.figsize':(12, 6)})\nsns.heatmap(df2.corr(), annot = True)","23fa8472":"df2['Class'] = df.iloc[:, 8]\nsns.countplot(x=\"Class\", data=df2)","a4492b95":"df2.head()","622a748f":"num_columns = df.select_dtypes(exclude='object').columns.tolist()\nnum_columns.remove('Class')\nprint(num_columns)\n\nplt.figure(figsize=(16,40))\nfor i,col in enumerate(num_columns,1):\n    plt.subplot(8,4,i)\n    sns.kdeplot(df[col],shade=True)\nplt.show()","be2483ec":"plt.figure(figsize=(16,40))\nfor i,col in enumerate(num_columns,1):\n    plt.subplot(8,4,i)\n    df[col].plot.box()\nplt.show()","931b85fe":"num_data = df[num_columns]\npd.DataFrame(data=[num_data.skew(),num_data.kurtosis()],index=['skewness','kurtosis'])","b9fa2597":"plt.figure(figsize=(20,40))\n\nfor i,col in enumerate(num_columns,1):\n    plt.subplot(10,1,i)\n    if col in ['X','Y']:\n        sns.swarmplot(data=df,x=col,y='Class')\n    else:\n        sns.scatterplot(data=df,x=col,y='Class')\nplt.show()","dc31cc15":"selected_features = df.columns\nprint(selected_features)\n\nsns.pairplot(df,hue='Class',vars=selected_features)\nplt.show()","bd629187":"### converting object datatype into float datatype ","00e4833e":"## --------------------Filling the missing values-------\n\n### Using column Global Constant","7d7490fa":"### decimal scaling","13c9ce3e":"### Using column Mean","e2512bb6":"## 3. Bivariate Analysis\n\n### With target variable","37cd1ee6":"#### The program can be divided into 4 parts:\n1. Reading the CSV file\n2. Find the missing values and replaces them. (by any one of following methods).\n        a. Fill the missing value manually\n        b. Use a Global Constant\n        c. Use mean to fill the value\n        d. Use Median to fill the value\n3. Divide key values into bins and smoothing them. (by any one of the following methods)\n        a. Smooth by Bin Means\n        b. Smooth by Bin Boundaries\n4. Apply the normalization process. (by any of the following methods)\n        a. Min-max Normalization\n        b. Z-score normalization\n        c. Decimal Scaling","72421d77":"### Data Cleaning from Scratch and Visualization of Cleanind Data\n\n # Data Cleaning Operation\n \n 1. Treatment Of Missing Values\n 2. Smoothing of noisy Data\n 3. Data Transformation","fd3aff5d":"#### Attribute information: \n1. Preg = Number of times pregnant \n2. Plas = Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n3. Pres = Diastolic blood pressure (mm Hg) \n4. Skin = Triceps skin fold thickness (mm) \n5. Insu = 2-Hour serum insulin (mu U\/ml) \n6. Mass = Body mass index (weight in kg\/(height in m)^2) \n7. Pedi = Diabetes pedigree function \n8. Age = Age (years)\n","1ddef862":"#### **Source of the database**: https:\/\/sci2s.ugr.es\/keel\/dataset\/data\/classification\/pima-10-fold.zip\n\n   From National Institute of Diabetes and Digestive and Kidney Diseases. Several constraints \nwere placed on the selection of these instances from a larger database. In particular, all patients \nhere are females at least 21 years old of Pima Indian heritage. \n\n   The class label represents if the person has not diabetes (tested_negative) or the person \nhas diabetes (tested_positive). ","180955c3":"## 2. Univariate Analysis\n\n#### Target variable -> \u201cClass\u201d (0 = non-diabetic, 1 = diabetic)","715d552a":"From the measures of below skewness and kurtosis value we can identify which column might have outliers.\n\nWe can see that \u201cBloodPressure\u201d and \u201cDiabetesPedigree\u201d has the kurtosis value >3,it means they have outlier values which can be normalized using some processing.","56cc1b8d":"#### By using boxplots, we can analyse the outliers and inter-quartile range of data.","81ec9a7f":"#### Missing Values: 50.65%","37f4a781":"### Binning by frequency","1a2258f8":"### z-score normalization","38e15b84":"### replacing \"< null >\" values as '-999' (to numeric)","ad8210f9":"### Using column Median","e9f9b2fe":"## --------------------Smooting data by binning------------","b48ddb83":"### min max normalization","cd399075":"## 1. Correlation Matrix:","f3462956":"#### All the columns are numerical, so we will plot the histograms of it. From it, we can view the distribution of the data.","f2d181ca":"## -------------------Normalization --------------------------","e282d6b7":"# Visualization of data:","b3051955":"### Smoothing by bin boundries","7ba394de":"## Global Constants ----","62c40842":"## 4. Multivariate Analysis","df569d1c":"## Data preprossessing ----\n### converting categorical column (output column) into nominal values","eaa5c826":"## Smoothing:\n\n### Smoothing by bin means"}}