{"cell_type":{"41c3dc7d":"code","57e86108":"code","508bb1ae":"code","2b49a56f":"code","fbd04eee":"code","73f8f554":"code","6c4a1486":"code","75749967":"code","be226c4e":"code","b46bd8f8":"code","c6a1c2e6":"code","77137510":"code","72f22610":"code","0b38d04c":"code","d3dce234":"code","34e9edf7":"code","f713845b":"code","bdce971d":"code","4e8d9045":"code","9f249e58":"code","26c51bc1":"code","e12c886d":"code","74ff23d6":"code","e7046b04":"code","fe624df3":"code","9d7666ab":"code","743cb400":"code","704e21e0":"code","8b8d4585":"code","e96426ea":"code","3542e02f":"code","69759c47":"code","2dad6096":"code","4df97b3f":"code","9d6708af":"code","e8a5aea9":"code","ce30b4a6":"code","413ef4f2":"code","e4a6d41e":"code","4042b252":"code","6382078c":"markdown","850029e5":"markdown","104339f0":"markdown","3e12cb72":"markdown","3b82cfb1":"markdown","040675cc":"markdown","34c50d80":"markdown","442bb56e":"markdown","dbadce36":"markdown","d07dd287":"markdown","b98bb0ef":"markdown","55e5e767":"markdown","c17954dd":"markdown"},"source":{"41c3dc7d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# plotly\nimport plotly.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\n#json\nimport json\n\n# word cloud library\nfrom wordcloud import WordCloud\n\n# seabron\nimport seaborn as sns\n\n# matplotlib\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","57e86108":"data_movies = pd.read_csv('..\/input\/tmdb_5000_movies.csv')\ndata_credits = pd.read_csv('..\/input\/tmdb_5000_credits.csv')","508bb1ae":"data_movies.info()","2b49a56f":"data_credits.info()","fbd04eee":"data_movies_average = data_movies .copy()\ndata_movies_average = data_movies_average.sort_values(['vote_average'],ascending = False)","73f8f554":"labelx = data_movies_average['original_title'].head(50)\nlabely = data_movies_average['vote_average'].head(50)\n\nlabelx = np.array(labelx)\nlabely = np.array(labely)\n\nplt.figure(figsize= (18,12))\nsns.barplot(x = labelx ,y = labely)\nplt.xticks(rotation = 90)\nplt.ylabel('Vote Average')\nplt.xlabel('Title')","6c4a1486":"C = data_movies.vote_average.mean()\nprint('the votes averages: ' ,C)","75749967":"m = data_movies.vote_count.quantile(.93)\nprint('the requred vote is : ',m)","be226c4e":"data_most_popular = data_movies.copy()\n","b46bd8f8":"data_most_popular = data_most_popular.loc[data_most_popular['vote_count']>=m]","c6a1c2e6":"V = data_most_popular.vote_count\nR = data_most_popular.vote_average","77137510":"result = (V\/(V+m)*R) + (m \/ (V+m)* C)","72f22610":"data_most_popular['pop'] = result","0b38d04c":"data_most_popular","d3dce234":"data_most_popular = data_most_popular.sort_values('pop',ascending = False)","34e9edf7":"data_most_popular[['title','vote_average']].head(10)","f713845b":"\ndata = [go.Bar(\n        x=data_most_popular.title.head(50),\n        y= data_most_popular['vote_average'].head(50),\n        marker = dict(color = 'rgba(110, 0,255, 0.6)',\n           line=dict(color='rgb(0,0,0)',width=1.5)),\n            text = data_most_popular.title.head(50)\n    )]\n\niplot(data, filename='basic-bar')","bdce971d":"data_movies = pd.read_csv('..\/input\/tmdb_5000_movies.csv')\ndata_credits = pd.read_csv('..\/input\/tmdb_5000_credits.csv')\ndata_movies['genres']=data_movies['genres'].apply(json.loads)\nfor index,i   in zip(data_movies.index,data_movies['genres']):\n    list1=[]    \n    for j in range(len(i)):       \n        list1.append((i[j]['name']))\n    data_movies.loc[index,'genres'] = str(list1) \n    \ndata_movies['keywords']=data_movies['keywords'].apply(json.loads)\nfor index,i in zip(data_movies.index,data_movies['keywords']):\n    list1=[]  \n    for j in range(len(i)):\n        list1.append((i[j]['name']))\n    data_movies.loc[index,'keywords'] = str(list1) \n    \ndata_movies['production_companies'] = data_movies['production_companies'].apply(json.loads)\nfor index,i in zip(data_movies.index,data_movies['production_companies']):\n    list1=[]\n    for j in range(len(i)):\n         list1.append((i[j]['name']))\n    data_movies.loc[index,'production_companies'] = str(list1)     \n    \ndata_movies['production_countries'] = data_movies['production_countries'].apply(json.loads)\nfor index,i in zip(data_movies.index,data_movies['production_countries']):\n    list1=[]\n    for j in range(len(i)):\n        list1.append((i[j]['name']))\n    data_movies.loc[index,'production_countries'] = str(list1)    \n    \ndata_credits['cast'] = data_credits['cast'].apply(json.loads)\nfor index,i in zip(data_credits.index,data_credits['cast']):\n    list1=[]\n    for j in range(len(i)):\n        list1.append((i[j]['name']))\n    data_credits.loc[index,'cast'] = str(list1)     \n    ","4e8d9045":"data_movies['genres'] = data_movies['genres'].str.strip('[]').str.replace(' ','').str.replace(\"''\",'')\ndata_movies['genres'] = data_movies['genres'].str.split(',')","9f249e58":"list1 = []\nfor i in data_movies['genres']:\n    list1.extend(i)","26c51bc1":"most_genres = pd.Series(list1).value_counts().sort_values(ascending = False )\ngenres = most_genres.index\nvalues = most_genres.values","e12c886d":"f,ax = plt.subplots(figsize = (12,12))\nsns.barplot(x = values,y = genres,color = 'blue', alpha = .6)","74ff23d6":"data_movies.release_date = data_movies.release_date.apply(lambda x: x.replace('-',' ') if '-' in str(x) else x)\ndata_movies_release = data_movies.copy()\ndata_movies_release.release_date = data_movies_release.release_date.apply(lambda x: x[0:4] if len(str(x))>4 else str(x))\ndata_movies_release.release_date = data_movies_release.release_date.apply(lambda x: x.strip('nan') if 'nan' in str(x) else x)    \ndata_movies_release.release_date = pd.to_numeric(data_movies_release.release_date)  \n","e7046b04":"data_inf = data_movies_release.release_date.value_counts()","fe624df3":"labelx = np.array(data_inf.index)\nlabely = np.array(data_inf.values)","9d7666ab":"plt.subplots(figsize = (18,15))\nsns.pointplot(x=labelx,y=labely,color='blue',alpha = 0.1)\nplt.xticks(rotation = 90)\nplt.title('movies for years',fontsize = 20,color='red')\nplt.xlabel('YEARS',fontsize = 20,color='green')\nplt.ylabel('MOV\u0130ES',fontsize = 20,color='green')\nplt.grid()","743cb400":"g=sns.jointplot(labelx,labely,kind='kde',siz=20)\nplt.savefig('graph.png')\nplt.show()\n","704e21e0":"g = sns.jointplot(labelx,labely,size=7,color= 'blue',ratio = 3)\nplt.show()","8b8d4585":"genre_list = []\nfor index,row in data_movies.iterrows():\n    genres = row['genres']\n    for i in genres:\n        genre_list.append(i)\n\n  \n    \n   \n","e96426ea":"index = pd.Series(genre_list).value_counts().index\nvalue = pd.Series(genre_list).value_counts().values","3542e02f":"list1=[]\nfor j in range(len(value)):\n    list1.append(0)\n   ","69759c47":"plt.subplots(figsize = (7,7))\ncolors = ['grey','blue','red','yellow','green','brown']\nplt.pie(value,explode = list1,labels=index,autopct='%1.1f%%')\nplt.show()","2dad6096":"df1=data_movies.copy()","4df97b3f":"df1 = df1.sort_values('budget',ascending = False)\n\ndf1[['budget','genres','title','revenue']].head(10)","9d6708af":"list_budget = df1.budget.head(10)\nlist_revanue = df1.revenue.head(10)","e8a5aea9":"import plotly.graph_objs as go\n\ntrace1 = go.Bar (\n                x = df1.title.head(10),\n                y = list_budget,\n                name = \"Budget\",\n                marker = dict(color= 'rgba(0,0,200,0.4)',\n                              line = dict(color = 'rgb(0,0,0)',width = 1)),\n                text = df1.genres\n              \n               )\n\n\ntrace2 = go.Bar(\n                x = df1.title.head(10),\n                y = list_revanue,\n                name = \"revanue\",\n                  marker = dict(color= 'rgba(200,100,10,0.7)',\n                                line= dict(color = 'rgb(0,0,0)',width = 1)),\n                   text = df1.genres\n)\n\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='group')\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename='grouped-bar')\n    ","ce30b4a6":"data_movies['production_countries'] = data_movies['production_countries'].str.strip('[]').str.replace(' ','').str.replace(\"''\",'')\ndata_movies['production_countries'] = data_movies['production_countries'].str.split(',')","413ef4f2":"list1 = []\nfor i in data_movies['production_countries']:\n    list1.extend(i)\n   \n","e4a6d41e":"df2 = pd.Series(list1).value_counts().dropna().head(10)\ncountries = df2.index\ncount = df2.values","4042b252":"fig = {\n    \"data\" : [\n        {\n            \"values\" : count,\n            \"labels\" : countries,\n            \"domain\" :{\"x\":[0,0.5]},\n            \"name\" : \"rate of product of countries\",\n            \"hoverinfo\": \"label+percent+name\",\n            \"hole\": .3,\n            \"type\": \"pie\"\n            \n            \n        } ,],\n    \"layout\":  {\n        \"title\": \"World rate of product of countries \",\n        \"annotations\" : [\n            {\n                \"font\": {\"size\":20},\n                \"showarrow\": False,\n                \"text\": \"rate of countries\",\n                \"x\": 0.20,\n                \"y\": 1\n            },\n        ]\n    }  \n}\niplot(fig)","6382078c":"We created new column in data and assigned to 'result' to the new column. After that we sorted the new column to the degree to 'result'.","850029e5":"Copying to data because of dont change everything in orginal data. After that make filter. We will choose high than m with use 'loc' method. Why we use loc method? Because m is not float which we found value.Thats wyh we cant comparison between m and the vote count. So we can select rows and columns based on labels with this method. The nice thing is that we can pass Boolean series instead of passing labels for a rows or columns selection and it will work.","104339f0":"# Coppying data \nBecause of dont effect the for real data. Use this way we can use the coppy data like real. So I shorted this data for averages","3e12cb72":"# Cleaning the data\nwehen we look see data we will see some strings.So this strings make complex to data. Thats why we need to clean this data.","3b82cfb1":"# Gettin data","040675cc":"# Cleaning data\nWe will see how many  movies made in each years. So thats why we need first cleaning to numerics data from than some strings. After that so many movies made same year but different month. Thats whay we need to first, cut up the months and days and counting againd the 'release_date'.","34c50d80":"# Comparison of budget and revenue all movies. \n\n\n\n","442bb56e":"# Finding the most productive countries and ratio, all over the world.\nThe firs step cleaning the data from strings and than we will create a list. ","dbadce36":"As you see the mean of vote oaverage is 6. and now we will find the minimum required votes. So firs we should determine a treshold. We will determined 93th percentile. Because for a movie be feature in the charts, it must have more votes than at least 90% of the movies in the list.But we will use higher than 90th percentile.","d07dd287":"# Glance over the both two data","b98bb0ef":"# Converting the data\nConverted the data from json to string. Because we can use string easer.","55e5e767":"# Find Most Popular Movies\n \nThe first we should know scale of IMDB. How works IMDB? The scoring is defined by the average rating of the members.\nHowever theese list are not baset on the average of votes of users. Because it is not healthy and fair result.For example, only two users voted for film A and average voted is 9 , 100 thousend users voted for film B and the average vote is 7,5 So if 100.000 people voted less then 2 people voted it would not be healthy.\n\nWell thats why we use Bayesian Calculation Method. This method works like this:\n\n (v \/ (v+m)) x R + (m \/ (v+m)) x C\n \n R = vote average\n\n v = vote counts\n\n m = minimum votes required to be list\n\n C = average score for the entire report.\n \n So we have known alread R and V. We can find m and C by use the R and V","c17954dd":"# Just trying\nits just my seaborn tryin. I just use seaborn lirary so this graphic is just for lesson.\nBut you can see real result under that."}}