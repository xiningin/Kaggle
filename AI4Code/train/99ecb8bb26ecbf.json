{"cell_type":{"e85b3c1c":"code","d2941f91":"code","b13c2d41":"code","7effcd21":"code","c432a62c":"code","40141a4b":"code","6690f2bc":"code","956d8c0e":"code","b7516777":"code","8720fc97":"code","bb27dad9":"code","520d4612":"code","96d458e9":"code","f3e639dc":"code","1bec97ed":"code","930c097b":"code","04ef160d":"code","83fa301e":"code","5ca9d6ed":"code","831d69fd":"code","e82a404d":"code","8b5048a7":"markdown","cbcbbd1b":"markdown","a48c668b":"markdown","86a3e3ef":"markdown","33103bf3":"markdown","6cd42895":"markdown","9ac77423":"markdown","364c0356":"markdown","26e37521":"markdown"},"source":{"e85b3c1c":"import numpy as np\nimport pandas as pd\nimport random\n\nfrom sklearn.decomposition import NMF\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d2941f91":"df = pd.read_csv('..\/input\/pokmon-index-database\/moves.csv')\ndf = df.head(20000)\ndf.dropna()","b13c2d41":"df.head()","7effcd21":"df['Effect'][350]","c432a62c":"count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\ndoc_term_matrix = count_vect.fit_transform(df['Effect'].values.astype('U'))","40141a4b":"doc_term_matrix","6690f2bc":"LDA = LatentDirichletAllocation(n_components=5, random_state=42)\nLDA.fit(doc_term_matrix)","956d8c0e":"for i in range(10):\n    random_id = random.randint(0,len(count_vect.get_feature_names()))\n    print(count_vect.get_feature_names()[random_id])","b7516777":"first_topic = LDA.components_[0]\ntop_topic_words = first_topic.argsort()[-10:]","8720fc97":"for i in top_topic_words:\n    print(count_vect.get_feature_names()[i])","bb27dad9":"for i,topic in enumerate(LDA.components_):\n    print(f'Top 10 words for topic #{i}:')\n    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n    print('\\n')","520d4612":"topic_values = LDA.transform(doc_term_matrix)\ntopic_values.shape","96d458e9":"df['Topic'] = topic_values.argmax(axis=1)","f3e639dc":"df.head()","1bec97ed":"tfidf_vect = TfidfVectorizer(max_df=0.8, min_df=2, stop_words='english')\ndoc_term_matrix = tfidf_vect.fit_transform(df['Effect'].values.astype('U'))","930c097b":"nmf = NMF(n_components=5, random_state=42)\nnmf.fit(doc_term_matrix )","04ef160d":"for i in range(10):\n    random_id = random.randint(0,len(tfidf_vect.get_feature_names()))\n    print(tfidf_vect.get_feature_names()[random_id])","83fa301e":"first_topic = nmf.components_[0]\ntop_topic_words = first_topic.argsort()[-10:]","5ca9d6ed":"for i in top_topic_words:\n    print(tfidf_vect.get_feature_names()[i])","831d69fd":"for i,topic in enumerate(nmf.components_):\n    print(f'Top 10 words for topic #{i}:')\n    print([tfidf_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n    print('\\n')","e82a404d":"topic_values = nmf.transform(doc_term_matrix)\ndf['Topic'] = topic_values.argmax(axis=1)\ndf.head()","8b5048a7":"# NMF for Topic Modeling in Python","cbcbbd1b":"# Topic Modeling","a48c668b":"# Importing Libraries","86a3e3ef":"Before we start, thanks to [LazyPanda](https:\/\/www.kaggle.com\/runesh) for introducing topic modeling to me, I thought it was really cool to learn. Also be sure to check out the [dataset](https:\/\/www.kaggle.com\/brendan45774\/pokmon-index-database) that I used which is [Pok\u00e9mon Index!](https:\/\/www.kaggle.com\/brendan45774\/pokmon-index-database)","33103bf3":"Non-Negative Matrix Factorization (NMF) a supervised learning technique that performs clustering and can do dimensionality reduction. It can be used in combination with TF-IDF scheme to perform topic modeling.","6cd42895":"# Inspecting data","9ac77423":"![image.png](attachment:b257024b-4ee3-462a-a9b1-97d4f1ef49f2.png)","364c0356":"Topic Modeling is a frequently used text-mining tool for discovery of hidden semantic structures in a text body. They are also referred to as probabilistic topic models, which refers to statistical algorithms for discovering the latent semantic structures of an extensive text body. Topic modeling is also an unsupervised technique that intends to analyze large volumes of text data by clustering the documents into groups.","26e37521":"# If you like this notebook, please give an Upvote! Don't forget to check out my other notebooks too!\n\n* [ConnectX Baseline](https:\/\/www.kaggle.com\/brendan45774\/connectx-baseline)\n* [Countries Life Expectancy Animation](https:\/\/www.kaggle.com\/brendan45774\/countries-life-expectancy-animation)\n* [Data Visuals - Matplotlib](http:\/\/www.kaggle.com\/brendan45774\/data-visuals-matplotlib)\n* [Digit Recognizer Solution](http:\/\/www.kaggle.com\/brendan45774\/digit-recognizer-solution)\n* [Dictionary and Pandas Cheat sheet](https:\/\/www.kaggle.com\/brendan45774\/dictionary-and-pandas-cheat-sheet)\n* [EDA Tutorial Hollywood Movies](https:\/\/www.kaggle.com\/brendan45774\/eda-tutorial-hollywood-movies)\n* [Getting started with Matplotlib](http:\/\/www.kaggle.com\/brendan45774\/getting-started-with-matplotlib)\n* [Guide to Matplotlib Image](https:\/\/www.kaggle.com\/brendan45774\/guide-to-matplotlib-image)\n* [HOG features - Histogram of Oriented Gradients](https:\/\/www.kaggle.com\/brendan45774\/hog-features-histogram-of-oriented-gradients)\n* [How to get the lowest score](https:\/\/www.kaggle.com\/brendan45774\/how-to-get-the-lowest-score)\n* [House predict solution](http:\/\/www.kaggle.com\/brendan45774\/house-predict-solution)\n* [K-Means Clustering (Image Compression)](https:\/\/www.kaggle.com\/brendan45774\/k-means-clustering-image-compression)\n* [Kuzushiji-MNIST Panda](http:\/\/www.kaggle.com\/brendan45774\/kuzushiji-mnist-panda)\n* [Plotly Coronavirus (Covid-19)](https:\/\/www.kaggle.com\/brendan45774\/plotly-coronavirus-covid-19)\n* [Titanic Top Solution](http:\/\/www.kaggle.com\/brendan45774\/titanic-top-solution)\n* [Titanic Data Solution](http:\/\/www.kaggle.com\/brendan45774\/titanic-data-solution)\n* [Topic Modeling (LDA)](https:\/\/www.kaggle.com\/brendan45774\/topic-modeling-lda)\n* [Word Cloud - Analyzing Names](https:\/\/www.kaggle.com\/brendan45774\/word-cloud-analyzing-names)"}}