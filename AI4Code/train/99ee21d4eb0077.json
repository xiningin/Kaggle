{"cell_type":{"9979af1a":"code","b058ddbf":"code","7c2bcd07":"code","14683fb1":"code","891fcabd":"code","af9a3292":"code","4a81c75f":"code","341a34d0":"code","ecff9c16":"code","1f75b323":"code","48b8b915":"code","2fdfbb3d":"code","e32573e9":"code","9f7aa607":"code","89886a6f":"code","14aeae8f":"code","395b3990":"code","0f26865f":"code","3bbd6ea9":"code","ed9b2e6b":"code","234248a3":"markdown","197d5314":"markdown","282b0f1b":"markdown"},"source":{"9979af1a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b058ddbf":"import warnings\nimport gc\nimport holidays\n\nfrom sklearn.model_selection import train_test_split\n\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\n\nwarnings.filterwarnings(\"ignore\")\nseed = 512","7c2bcd07":"df_train = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv')\ndf_train.head()","14683fb1":"# Define Model Evaluation functions\ndef smape(y_true, y_pred):\n    return np.mean(np.abs(y_true - y_pred) \/ (y_true + np.abs(y_pred)) * 200)\n\ndef evaluate_model(model, x, y):\n    y_pred = model.predict(x)\n    result = smape(y, y_pred)\n    return result","891fcabd":"#Define data pre-processing functions\ndef label_encoder(df):\n    country = {c : i for i, c in enumerate(df['country'].unique())}\n    store = {s : i for i, s in enumerate(df['store'].unique())}\n    product = {p : i for i, p in enumerate(df['product'].unique())}\n    df = df.copy()\n    df['country'] = df['country'].replace(country)\n    df['store'] = df['store'].replace(store)\n    df['product'] = df['product'].replace(product)\n    return df\n\ndef preprocess_dates(df):\n    df = df.copy()\n    df['date'] = pd.to_datetime(df['date'])\n    df['weekday'] = df['date'].dt.weekday\n    df['week']=df['date'].dt.isocalendar().week     \n    df['week'][df['week']>52]=52                    \n    df['week']=df['week'].astype('int')\n    df['month']=df['date'].dt.month\n    df['quarter'] = df['date'].dt.quarter\n    df['year']=df['date'].dt.year\n    df['day_of_year'] = df['date'].dt.day_of_year\n    df['day_of_month']=df['date'].dt.day\n    df['is_month_start'] = df['date'].dt.is_month_start\n    df['is_month_end'] = df['date'].dt.is_month_end\n    df['weekend']=(df['weekday']\/\/5 == 1)       \n    df['weekend']=df['weekend'].astype('int')   \n    return df\n\ndef preprocess_holidays(df):\n    holiday_finland = holidays.CountryHoliday(country='FI', years=[2015, 2016, 2017, 2018, 2019])\n    holiday_norway = holidays.CountryHoliday(country='NO', years=[2015, 2016, 2017, 2018, 2019])\n    holiday_sweden = holidays.CountryHoliday(country='SE', years=[2015, 2016, 2017, 2018, 2019])\n    holidays_fin_nor_swe = holiday_finland.copy()\n    holidays_fin_nor_swe.update(holiday_norway)\n    holidays_fin_nor_swe.update(holiday_sweden)\n    dates = list(holidays_fin_nor_swe.keys())\n    dates = sorted(pd.to_datetime(dates))\n    df = df.copy()\n    df['is_holiday'] = df['date'].apply(lambda x : 1 if x in dates else 0)\n    return df\n\ndef preprocess_timeseries(df):\n    df = df.copy()\n    # Sin of date values\n    df['sin_day_of_year'] = np.sin(df['day_of_year'])\n    df['sin_month'] = np.sin(df['month'])\n    df['sin_weekday'] = np.sin(df['weekday'])\n    df['sin_quarter'] = np.sin(df['quarter'])\n    # Cos of date values\n    df['cos_day_of_year'] = np.cos(df['day_of_year'])\n    df['cos_month'] = np.cos(df['month'])\n    df['cos_weekday'] = np.cos(df['weekday'])\n    df['cos_quarter'] = np.cos(df['quarter'])\n    return df","af9a3292":"train_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jan-2022\/train.csv\", sep=',')\ntrain_df","4a81c75f":"train_df = label_encoder(train_df)\ntrain_df = preprocess_dates(train_df)\ntrain_df = preprocess_holidays(train_df)\ntrain_df = preprocess_timeseries(train_df)\ntrain_df","341a34d0":"X_train = train_df.drop(['row_id', 'date', 'num_sold'], axis=1)\ny_train = train_df['num_sold']\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.25, random_state=seed, shuffle=False)","ecff9c16":"params = {'n_estimators': 1000, \n          'max_depth': 50, \n          'subsample': 1.0,\n          'eta': 0.3,\n          'colsample_bytree': 1.0,\n          'gamma': 0.0, \n          'min_child_weight': 1,\n          'reg_alpha': 1\n         }\n\nmodel =  XGBRegressor(**params,\n                      random_state=seed,\n                      early_stopping_rounds=300,\n                      verbosity=0)\n\nmodel.fit(X_train, y_train, verbose=True)\nscore = evaluate_model(model, X_test, y_test)\nprint(score)   # Public score = 7.36938","1f75b323":"plot_importance(model)","48b8b915":"import optuna","2fdfbb3d":"def objective(trial):\n   \n    n_estim = trial.suggest_int('n_estimators', 100, 1000)\n    max_d = trial.suggest_int('max_depth', 10, 80)\n    subsam = trial.suggest_float('subsample', 0.5, 1.0)    \n    eta = trial.suggest_float('eta', 0.01, 0.5)\n    colsample = trial.suggest_float('colsample_bytree', 0.7, 1.0)\n    gammma = trial.suggest_float('gammma', 0.0, 0.5)\n    min_child = trial.suggest_float('min_child_weight', 0.7, 1.0)\n    reg_a = trial.suggest_float('reg_alpha', 0.7, 1.0)\n    \n    params = {'n_estimators': n_estim, \n              'max_depth': max_d, \n              'subsample': subsam,\n              'eta': eta,\n              'colsample_bytree': colsample,\n              'gamma': gammma, \n              'min_child_weight': min_child,\n              'reg_alpha': reg_a\n             }\n    \n    model =  XGBRegressor(**params,\n                          random_state=seed,\n                          early_stopping_rounds=300,\n                          verbosity=0)\n    \n    model.fit(X_train, y_train, verbose=True)\n    score = evaluate_model(model, X_test, y_test)\n    \n    return score","e32573e9":"# Create Optuna Trial\nstudy = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(seed=seed))\n\n# Run trials\n#study.optimize(objective , n_trials = 500)\nstudy.optimize(objective, timeout = int(3600*9))    # an hour * X","9f7aa607":"# Best trial\nprint('Best trial score:', study.best_trial.value)\nstudy.best_trial.params","89886a6f":"# Create model with best trial parameters\nparams = {'n_estimators': study.best_trial.params['n_estimators'], \n          'max_depth': study.best_trial.params['max_depth'], \n          'subsample': study.best_trial.params['subsample'],\n          'eta': study.best_trial.params['eta'],\n          'colsample_bytree': study.best_trial.params['colsample_bytree'],\n          'gamma': study.best_trial.params['gammma'], \n          'min_child_weight': study.best_trial.params['min_child_weight'],\n          'reg_alpha': study.best_trial.params['reg_alpha']\n         }\n\nbest_model =  XGBRegressor(**params,\n                           random_state=seed,\n                           early_stopping_rounds=300,\n                           verbosity=0)\n\nbest_model.fit(X_train, y_train, verbose=True)\nscore = evaluate_model(best_model, X_test, y_test)\nprint(score)","14aeae8f":"# Train best model with all train data\nX_train = train_df.drop(['row_id', 'date', 'num_sold'], axis=1)\ny_train = train_df['num_sold']\n\nbest_model.fit(X_train, y_train, verbose=True)","395b3990":"real_test_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jan-2022\/test.csv\", sep=',')\nreal_test_df = label_encoder(real_test_df)\nreal_test_df = preprocess_dates(real_test_df)\nreal_test_df = preprocess_holidays(real_test_df)\nreal_test_df = preprocess_timeseries(real_test_df)\nX_real_test = real_test_df.drop(['row_id', 'date'], axis=1)","0f26865f":"target = best_model.predict(X_real_test).squeeze()\nrow_id =  real_test_df['row_id'].values\nsubmission = pd.DataFrame({'row_id' : row_id, 'num_sold' : target})","3bbd6ea9":"submission.head()","ed9b2e6b":"submission.to_csv('submission.csv', index=False)","234248a3":"## Model: XGBoost\nhttps:\/\/xgboost.readthedocs.io\/en\/latest\/python\/python_api.html#xgboost.XGBRegressor","197d5314":"## Submission","282b0f1b":"# Optuna Optimization"}}