{"cell_type":{"d1d5b7c9":"code","57938cc5":"code","078649e0":"code","8fdf8cee":"code","71b9432c":"code","75260c10":"code","3bfdbbcf":"code","1e29fa5d":"code","5a0e2d7e":"code","6c09dc50":"code","c2d1a1bc":"code","2e88caa8":"code","4078b666":"code","02714c84":"code","61b41013":"code","fb475679":"code","cfa2c840":"code","fced75d3":"code","8626f0e9":"code","dae220d3":"markdown"},"source":{"d1d5b7c9":"from __future__ import print_function, division\nimport os\nimport torch\nimport pandas as pd\nfrom skimage import io, transform\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nimport random","57938cc5":"# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport cv2","078649e0":"from tqdm import tqdm_notebook, tqdm","8fdf8cee":"! cat \/usr\/local\/cuda\/version.txt","71b9432c":"!ls \/kaggle\/input\/understanding_cloud_organization","75260c10":"DIR_TRAIN_IMAGES = \"\/kaggle\/input\/understanding_cloud_organization\/train_images\/\"","3bfdbbcf":"df_train = pd.read_csv(\"\/kaggle\/input\/understanding_cloud_organization\/train.csv\")\ndf_train[\"Label\"] = [i.split(\"_\")[1] for i in df_train.Image_Label.values.tolist()]","1e29fa5d":"df_train.head(20)","5a0e2d7e":"df_train_grp = df_train.dropna().groupby(\"Label\")","6c09dc50":"idx_fish = df_train_grp.get_group(\"Fish\").index.values.tolist()\nidx_flower = df_train_grp.get_group(\"Flower\").index.values.tolist()\nidx_gravel = df_train_grp.get_group(\"Gravel\").index.values.tolist()\nidx_sugar = df_train_grp.get_group(\"Sugar\").index.values.tolist()","c2d1a1bc":"def get_mask(idx:int):\n    n = idx\n    name_tuple = df_train.iloc[n, 0].split(\"_\")\n    img_name, img_label = name_tuple[0], name_tuple[1] \n    encoded_pixels = df_train.iloc[n,1]\n\n    enc_pix =  list(map(int,encoded_pixels.split(\" \")))\n    pix, pix_count = [], []\n    for i in tqdm(range(0, len(enc_pix))):\n        if i%2==0:\n            pix.append(enc_pix[i])\n        else:\n            pix_count.append(enc_pix[i])\n\n    rle_pixels = [list(range(pix[i],pix[i]+pix_count[i])) for i in range(0, len(pix))]\n    rle_mask_pixels = sum(rle_pixels,[]) \n\n    img_loc = DIR_TRAIN_IMAGES+img_name\n    img = cv2.imread(img_loc)\n    mask_img = np.zeros((img.shape[0]*img.shape[1],1), dtype=int)\n    mask_img[rle_mask_pixels] = 255\n    height,width=img.shape[0], img.shape[1]\n    mask = np.reshape(mask_img, (width, height)).T\n\n    return mask, img_name, img_label\n\n\n\n#plt.imshow(mask);","2e88caa8":"def disp_image(idx:int):\n    mask,img_name, img_label = get_mask(idx)\n    img_loc = DIR_TRAIN_IMAGES+img_name\n    img = cv2.imread(img_loc)\n    img_to_disp = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n    img_to_disp[mask==0,1] = 255\n    return img_to_disp, img_label","4078b666":"def disp_sample(category:str, ls_idx:list):\n    fig=plt.figure(figsize=(20, 10))\n    fig.subplots_adjust(hspace=0.9, wspace=0.4)\n    columns = 3\n    rows = 2\n    for i in range(1,7):\n        ax = fig.add_subplot(rows, columns, i)\n        img2disp, _ = disp_image(random.choice(ls_idx))\n        ax.set_title(category)\n        plt.imshow(img2disp)\n\n    plt.tight_layout()\n    plt.show()","02714c84":"disp_sample(\"fish\", idx_fish)","61b41013":"disp_sample(\"flower\", idx_flower)","fb475679":"disp_sample(\"sugar\", idx_sugar)","cfa2c840":"disp_sample(\"gravel\", idx_gravel)","fced75d3":"def disp_sample_assorted():\n    fig=plt.figure(figsize=(18, 12))\n    #fig.subplots_adjust(hspace=0.9, wspace=0.4)\n    columns = 3\n    rows = 3\n    for i in range(1,10):\n        ax = fig.add_subplot(rows, columns, i)\n        img2disp, img_label = disp_image(random.choice(idx_fish+idx_flower+idx_sugar+idx_gravel))\n        ax.set_title(img_label)\n        plt.imshow(img2disp)\n\n    plt.tight_layout()\n    plt.show()","8626f0e9":"disp_sample_assorted()","dae220d3":"## Generating Mask from Encoded Pixels\n\n- [Medium Blog](https:\/\/medium.com\/@sumanthmeenan\/generating-masks-from-encoded-pixels-semantic-segmentation-18635e834ad0)"}}