{"cell_type":{"32169121":"code","2f253cef":"code","7f097331":"code","d04e046b":"code","8518c8dd":"code","4f5bb46b":"code","8f0f39dd":"code","f787d406":"code","86840ec6":"code","86d4d1b2":"code","3a4da97b":"code","5ae8443f":"code","ba8cd6d6":"code","2366b943":"code","3a74b359":"code","e2f2b4bb":"code","788440f2":"code","050f3361":"code","cb47737c":"code","37bf6a16":"code","d5aa3dd0":"code","330b8091":"code","1c11b08a":"code","f47d2e57":"code","024e3407":"code","27405c06":"code","e88dac60":"code","e073d604":"code","bcc1d637":"markdown","916f8bc9":"markdown","fcf0a093":"markdown","d1a10651":"markdown","90710015":"markdown","fea84735":"markdown","57b441f3":"markdown","6023cbf4":"markdown","f7088e68":"markdown","b35e7d4a":"markdown","9fc157f2":"markdown","f2ce31bf":"markdown","2f645212":"markdown","564a52f5":"markdown","600219a0":"markdown","36667e8b":"markdown","42aed141":"markdown","762b744d":"markdown","ecc1842f":"markdown","3ec02edd":"markdown","74936808":"markdown","ba3ff0be":"markdown","9b5e873e":"markdown","a3c9e202":"markdown","36162e95":"markdown","c37ef13f":"markdown"},"source":{"32169121":"import tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport numpy as np","2f253cef":"(x_train,y_train),(x_test,y_test)=keras.datasets.mnist.load_data()","7f097331":"x_train","d04e046b":"x_train.shape # look at the shape of the data","8518c8dd":"len(x_train) #60,000 train images","4f5bb46b":"len(x_test) #10,000 test images","8f0f39dd":"x_train[0].shape","f787d406":"x_train[0]","86840ec6":"plt.matshow(x_train[5])","86d4d1b2":"y_train[5]","3a4da97b":"x_train=x_train\/255\nx_test=x_test\/255","5ae8443f":"x_train_flattened=x_train.reshape(len(x_train),28*28)\nx_test_flattened=x_test.reshape(len(x_test),28*28)","ba8cd6d6":"x_test_flattened.shape\n","2366b943":"x_train_flattened[0]","3a74b359":"model=keras.Sequential([\n    keras.layers.Dense(10,input_shape=(784,),activation=\"sigmoid\")\n]) \nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\nmodel.fit(x_train_flattened,y_train,epochs=5)\n\n#so sequential means I will have stack of layers in neural network\n# dense means every neuron in 1st layer will be connected to every other neuron in second layer","e2f2b4bb":"model.evaluate(x_test_flattened,y_test)","788440f2":"y_predict=model.predict(x_test_flattened)\ny_predict[3]","050f3361":"plt.matshow(x_test[3])","cb47737c":"np.argmax(y_predict[3])","37bf6a16":"y_predicted_labels=[np.argmax(i) for i in y_predict]\ny_predicted_labels[:5]","d5aa3dd0":"y_test[:5]","330b8091":"cm=tf.math.confusion_matrix(labels=y_test,predictions=y_predicted_labels)","1c11b08a":"cm","f47d2e57":"import seaborn as sns","024e3407":"plt.figure(figsize=(12,6))\nsns.heatmap(cm,annot=True,fmt=\"d\")\nplt.xlabel(\"predicted\")\nplt.ylabel(\"Truth\")","27405c06":"model=keras.Sequential([\n    keras.layers.Dense(100,input_shape=(784,),activation=\"relu\"),\n    keras.layers.Dense(10,activation=\"sigmoid\")\n])\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\nmodel.fit(x_train_flattened,y_train,epochs=5)\n\n# 100 means 100 neurons in hidden layer (this is just trial and error-No fix constant number)","e88dac60":"model.evaluate(x_test_flattened,y_test)","e073d604":"plt.figure(figsize=(12,6))\nsns.heatmap(cm,annot=True,fmt=\"d\")\nplt.xlabel(\"predicted\")\nplt.ylabel(\"Truth\")","bcc1d637":"So by looking at the above confusion matrix we can observe that\n1. 959 times the truth was 0 and model predicted it to be 0\n2. 1110 times the truth was 1 and model predicted it to be 1\nSimiliarly,\n3. 3 times the truth was 2 but model predicted it to be 0 and so on...","916f8bc9":"If you want to see what this image really looks like than for that we are using matplotlib","fcf0a093":"# Evaluate Accuracy on test dataset","d1a10651":"# Load MNIST hand_written Digits dataset from keras.datasets","90710015":"# CONFUSION MATRIX","fea84735":"We have to flatten the pixels to feed it to the neural network","57b441f3":"# SCALING","6023cbf4":"You can realize now that number of errors in these black box are now decreased ...","f7088e68":"# PREDICTION","b35e7d4a":"89% accuracy :D","9fc157f2":"## That`s it from my side....\n## Please Comment if you have any questions..\n## Upvote if you like it...\n","f2ce31bf":"let`s use seaborn to visualize confusion matrix","2f645212":"# Import Necessary Libraries","564a52f5":"# SIMPLE NEURAL NETWORK","600219a0":"# Evaluate Perfomance","36667e8b":"So our accuracy is 88% which is pretty good but if we want to improve our accuracy we can use scaling\n## scaling: scaling is a technique to improve the accuracy of our model","42aed141":"# Confusion Matrix ","762b744d":"Now let`s add an hidden layer to our simple neural network.\n> By adding hidden layer it tends to improves the performance of the model.\n> let us seeeeeeee","ecc1842f":"So now we are creating simple neural network with just 1 input layer and 1 output layer(No hidden layers)\n1.  input layer: input layer will have 784 (28*28) neurons- features in simple language\n2. output layer: output layer will have 10 neurons (0-9)","3ec02edd":"# **HAPPY KAGGLING","74936808":"In above shot the model is evaluating the accuracy on train dataset but now let`s evaluate it on test dataset","ba3ff0be":"It`s a good practice to scale the data before applying the model","9b5e873e":"# Flatten 28*28 Image","a3c9e202":"We can see we have 60,000 images of handwritten digits and each image is of 28 by 28 pixels","36162e95":"# Adding hidden layer ","c37ef13f":"So Now we can see that without hidden layer our performace was 92% and now it`s 97% almost :D"}}