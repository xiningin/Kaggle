{"cell_type":{"44586066":"code","f6c99a85":"code","71c02d2c":"code","bdbc9d2c":"code","93ba9c4b":"code","a0e55ccb":"code","811d875c":"code","1b68e76d":"code","9a82e0fd":"code","32e27fde":"code","e9d37a64":"code","68a77cf4":"code","cb1415f6":"code","70851c21":"code","7746b389":"code","a8a28463":"code","22e8d89e":"code","6cbb2c1f":"code","b8bacb2f":"code","ba10b041":"code","a5b029c4":"code","28817fc3":"code","9e618859":"code","d707ae77":"code","b7523a29":"markdown","effc8f0f":"markdown","827a34e2":"markdown","d73f25e3":"markdown","4feef9c1":"markdown","429d0097":"markdown","b9c0a1dc":"markdown","834708f9":"markdown","50773f3d":"markdown","3855fae3":"markdown","d383aaeb":"markdown"},"source":{"44586066":"import os\nimport sys\nimport shutil\n\nfrom pprint import pprint\nfrom tqdm import tqdm\ntqdm.pandas()\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nfrom PIL import Image\nfrom glob import glob\nimport cv2\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers.experimental.preprocessing import Rescaling\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.data import AUTOTUNE\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import load_model as tf_load_model, Model\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n\nfrom tensorflow.keras.layers import (\n    Input, \n    Dense, \n    Conv2D, \n    MaxPool2D, \n    Concatenate, \n    ZeroPadding2D, \n    Flatten,\n    BatchNormalization,\n    GlobalAveragePooling2D,\n    Dropout\n)\n\nfrom sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix","f6c99a85":"TRAIN_PATH = '..\/input\/if4074-praktikum-1-cnn-2021-01\/train\/seg_train'\nTEST_PATH = '..\/input\/if4074-praktikum-1-cnn-2021-01\/test\/test'","71c02d2c":"train_datagen = ImageDataGenerator(rescale=1.\/255, validation_split=0.2)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)","bdbc9d2c":"IMG_HEIGHT = IMG_WIDTH = 150\nBATCH_SIZE = 32\nCHANNEL = 3\nNUM_CLASSES = 6\nSEED = 42\n\ntrain_generator = train_datagen.flow_from_directory(\n    TRAIN_PATH,\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n    seed=SEED,\n    subset='training')\n\nvalidation_generator = train_datagen.flow_from_directory(\n    TRAIN_PATH,\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n    seed=SEED,\n    subset='validation')","93ba9c4b":"def improved_alexnet_2(input_shape, num_label):\n    \"\"\"\n      Input\n        |\n     Conv2D \n        | \n     Conv2D\n        |\n     Conv2D\n        |\n     Conv2D\n        |\n    MaxPool2D\n        | \n     Conv2D\n        |\n     Conv2D\n        |\n     Conv2D (3x1)\n        |\n     Conv2D (1x3)\n        |\n     Conv2D (3x1)\n        |\n     Conv2D (1x3)\n        |\n     Conv2D (3x1)\n        |\n     Conv2D (1x3)\n        |\n    MaxPool2D\n        |\n     Flatten\n        |\n      Dense\n        |\n      Dense\n        |\n     Out put\n    \"\"\"\n    inputs = Input(shape=input_shape, name=\"input_image\", dtype=\"float32\")\n    conv1 = Conv2D(96, (3, 3), strides=(2, 2), activation='relu', name='conv1-96')(inputs)\n    conv2 = Conv2D(96, (3, 3), strides=(1, 1), activation='relu', name='conv2-96')(conv1)\n    conv3 = Conv2D(96, (3, 3), strides=(1, 1), activation='relu', name='conv3-96')(conv2)\n    conv4 = Conv2D(96, (3, 3), strides=(1, 1), activation='relu', name='conv4-96')(conv3)\n\n    pool1 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), name='maxpool1')(conv4)\n    \n    conv5 = Conv2D(256, (5, 5), strides=(2, 2), activation='relu', name='conv5-256')(pool1)\n    conv6 = Conv2D(256, (3, 3), strides=(1, 1), activation='relu', name='conv6-256')(conv5)\n\n    conv7_3x1 = Conv2D(384, (3, 1), strides=(1, 1), activation='relu', name='conv7-384-3x1')(conv6)\n    conv7_1x3 = Conv2D(384, (1, 3), strides=(1, 1), activation='relu', name='conv7-384-1x3')(conv7_3x1)\n\n    conv8_3x1 = Conv2D(384, (3, 1), strides=(1, 1), activation='relu', name='conv8-384-3x1')(conv7_1x3)\n    conv8_1x3 = Conv2D(384, (1, 3), strides=(1, 1), activation='relu', name='conv8-384-1x3')(conv8_3x1)\n\n    conv9_3x1 = Conv2D(256, (3, 1), strides=(1, 1), activation='relu', name='conv9-256-3x1')(conv8_1x3)\n    conv9_1x3 = Conv2D(256, (1, 3), strides=(1, 1), activation='relu', name='conv9-256-1x3')(conv9_3x1)\n\n    pool2 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), name='maxpool2')(conv9_1x3)\n    flatten = Flatten(name='flatten')(pool2)\n\n    fc1 = Dense(512, activation='relu', name='dense1')(flatten)\n    fc2 = Dense(512, activation='relu', name='dense2')(fc1)\n    outputs = Dense(num_label, activation='softmax', name='output')(fc2)\n\n    return Model(inputs=inputs, outputs=outputs, name='improved-alexnet-2')","a0e55ccb":"def yoga_version(input_shape, num_label):\n    \"\"\"\n          Input\n            |\n         Conv2D \n            | \n         Conv2D\n            |\n         Conv2D\n            |\n         Conv2D\n            |\n        BatchNormalization\n            |\n        MaxPool2D\n            | \n         Conv 2D\n            |\n         Conv 2D\n      \/            \\\n    Conv2D(3x1)    Conv2D(1x3)\n     |              |\n    ZeroPadding2D  ZeroPadding2D\n     \\             \/\n        Merge (concatenation)\n            |            \n     BatchNormalization\n            |\n    GlobalAveragePooling2D\n            |\n         Dropout\n            |\n          Dense\n            |\n         Dropout\n            |\n          Dense\n            |\n         Out put\n    \"\"\"\n    inputs = Input(shape=input_shape, name=\"input_image\", dtype=\"float32\")\n    conv1 = Conv2D(96, (3, 3), strides=(2, 2), activation='relu', name='conv1-96')(inputs)\n    conv2 = Conv2D(96, (3, 3), strides=(1, 1), activation='relu', name='conv2-96')(conv1)\n    conv3 = Conv2D(96, (3, 3), strides=(1, 1), activation='relu', name='conv3-96')(conv2)\n    conv4 = Conv2D(96, (3, 3), strides=(1, 1), activation='relu', name='conv4-96')(conv3)\n    batchnorm1 = BatchNormalization(name='batchnorm1')(conv4)\n\n    pool1 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), name='maxpool1')(batchnorm1)\n    \n    conv5 = Conv2D(256, (5, 5), strides=(2, 2), activation='relu', name='conv5-256')(pool1)\n    conv6 = Conv2D(256, (3, 3), strides=(1, 1), activation='relu', name='conv6-256')(conv5)\n\n    conv7_3x1 = Conv2D(384, (3, 1), strides=(1, 1), activation='relu', name='conv7-384-3x1')(conv6)\n    conv7_1x3 = Conv2D(384, (1, 3), strides=(1, 1), activation='relu', name='conv7-384-1x3')(conv6)\n\n    pad1_3x1 = ZeroPadding2D(((0, 2), (0, 0)), name='pad1_3x1')(conv7_3x1)\n    pad1_1x3 = ZeroPadding2D(((0, 0), (0, 2)), name='pad1_1x3')(conv7_1x3)\n    merged1 = Concatenate(name='concatenate1')([pad1_3x1, pad1_1x3])\n\n    conv8_3x1 = Conv2D(384, (3, 1), strides=(1, 1), activation='relu', name='conv8-384-3x1')(merged1)\n    conv8_1x3 = Conv2D(384, (1, 3), strides=(1, 1), activation='relu', name='conv8-384-1x3')(merged1)\n\n    pad2_3x1 = ZeroPadding2D(((0, 2), (0, 0)), name='pad2_3x1')(conv8_3x1)\n    pad2_1x3 = ZeroPadding2D(((0, 0), (0, 2)), name='pad2_1x3')(conv8_1x3)\n    merged2 = Concatenate(name='concatenate2')([pad2_3x1, pad2_1x3])\n\n    conv9_3x1 = Conv2D(256, (3, 1), strides=(1, 1), activation='relu', name='conv9-256-3x1')(merged2)\n    conv9_1x3 = Conv2D(256, (1, 3), strides=(1, 1), activation='relu', name='conv9-256-1x3')(merged2)\n\n    pad3_3x1 = ZeroPadding2D(((0, 2), (0, 0)), name='pad3_3x1')(conv9_3x1)\n    pad3_1x3 = ZeroPadding2D(((0, 0), (0, 2)), name='pad3_1x3')(conv9_1x3)\n    merged3 = Concatenate(name='concatenate3')([pad3_3x1, pad3_1x3])\n    batchnorm2 = BatchNormalization(name='batchnorm2')(merged3)\n\n    pool2 = GlobalAveragePooling2D(name='globalaveragepooling')(batchnorm2)\n    \n    dropout1 = Dropout(0.3, name='dropout1')(pool2)\n    fc1 = Dense(512, activation='relu', name='dense1')(dropout1)\n    \n    dropout2 = Dropout(0.3, name='dropout2')(fc1)\n    fc2 = Dense(512, activation='relu', name='dense2')(dropout2)\n    \n    outputs = Dense(num_label, activation='softmax', name='output')(fc2)\n\n    return Model(inputs=inputs, outputs=outputs, name='yoga-net')","811d875c":"def willi_version(input_shape, num_label):\n    \"\"\"\n              Input\n                |\n             Conv2D \n                | \n             Conv2D\n                |\n             Conv2D\n                |\n             Conv2D\n                |\n            MaxPool2D\n                | \n             Conv2D\n                |\n             Conv2D\n         \/            \\\n    Conv2D(3x1)    Conv2D(1x3)\n         |              |\n    ZeroPadding2D  ZeroPadding2D\n         \\             \/\n        Merge (concatenation)\n                |\n        GlobalAveragePooling2D\n                |\n             Dropout\n                |\n              Dense\n                |\n             Dropout\n                |\n              Dense\n                |\n             Out put\n    \"\"\"\n    inputs = Input(shape=input_shape, name=\"input_image\", dtype=\"float32\")\n    conv1 = Conv2D(96, (3, 3), strides=(2, 2), activation='relu', name='conv1-96')(inputs)\n    conv2 = Conv2D(96, (3, 3), strides=(1, 1), activation='relu', name='conv2-96')(conv1)\n    conv3 = Conv2D(96, (3, 3), strides=(1, 1), activation='relu', name='conv3-96')(conv2)\n    conv4 = Conv2D(96, (3, 3), strides=(1, 1), activation='relu', name='conv4-96')(conv3)\n\n    pool1 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), name='maxpool1')(conv4)\n    \n    conv5 = Conv2D(256, (5, 5), strides=(2, 2), activation='relu', name='conv5-256')(pool1)\n    conv6 = Conv2D(256, (3, 3), strides=(1, 1), activation='relu', name='conv6-256')(conv5)\n\n    conv7_3x1 = Conv2D(384, (3, 1), strides=(1, 1), activation='relu', name='conv7-384-3x1')(conv6)\n    conv7_1x3 = Conv2D(384, (1, 3), strides=(1, 1), activation='relu', name='conv7-384-1x3')(conv6)\n\n    pad1_3x1 = ZeroPadding2D(((0, 2), (0, 0)), name='pad1_3x1')(conv7_3x1)\n    pad1_1x3 = ZeroPadding2D(((0, 0), (0, 2)), name='pad1_1x3')(conv7_1x3)\n    merged1 = Concatenate(name='concatenate1')([pad1_3x1, pad1_1x3])\n\n    conv8_3x1 = Conv2D(384, (3, 1), strides=(1, 1), activation='relu', name='conv8-384-3x1')(merged1)\n    conv8_1x3 = Conv2D(384, (1, 3), strides=(1, 1), activation='relu', name='conv8-384-1x3')(merged1)\n\n    pad2_3x1 = ZeroPadding2D(((0, 2), (0, 0)), name='pad2_3x1')(conv8_3x1)\n    pad2_1x3 = ZeroPadding2D(((0, 0), (0, 2)), name='pad2_1x3')(conv8_1x3)\n    merged2 = Concatenate(name='concatenate2')([pad2_3x1, pad2_1x3])\n\n    conv9_3x1 = Conv2D(256, (3, 1), strides=(1, 1), activation='relu', name='conv9-256-3x1')(merged2)\n    conv9_1x3 = Conv2D(256, (1, 3), strides=(1, 1), activation='relu', name='conv9-256-1x3')(merged2)\n\n    pad3_3x1 = ZeroPadding2D(((0, 2), (0, 0)), name='pad3_3x1')(conv9_3x1)\n    pad3_1x3 = ZeroPadding2D(((0, 0), (0, 2)), name='pad3_1x3')(conv9_1x3)\n    merged3 = Concatenate(name='concatenate3')([pad3_3x1, pad3_1x3])\n\n    pool2 = GlobalAveragePooling2D(name='globalaveragepooling')(merged3)\n    drop1 = Dropout(0.2)(pool2)\n    fc1 = Dense(512, activation='relu', name='dense1')(drop1)\n    drop2 = Dropout(0.2)(fc1)\n    fc2 = Dense(512, activation='relu', name='dense2')(drop2)\n    outputs = Dense(num_label, activation='softmax', name='output')(fc2)\n\n    return Model(inputs=inputs, outputs=outputs, name='willi-net')","1b68e76d":"input_shape = (IMG_HEIGHT, IMG_WIDTH, CHANNEL)\nalexnet2 = improved_alexnet_2(input_shape, NUM_CLASSES)\nyoga_model = yoga_version(input_shape, NUM_CLASSES)\nwilli_model = willi_version(input_shape, NUM_CLASSES)","9a82e0fd":"alexnet2.summary()","32e27fde":"yoga_model.summary()","e9d37a64":"willi_model.summary()","68a77cf4":"def scheduler(epoch, lr):\n    if epoch < 7: return lr\n    else: return lr * tf.math.exp(-0.1)\n\nlr_callback = LearningRateScheduler(scheduler)","cb1415f6":"def checkpoint(path, monitor, mode):\n    return ModelCheckpoint(\n        path,\n        save_best_only=True,\n        monitor=monitor,\n        mode=mode\n    )","70851c21":"LEARNING_RATE = 1e-4\nalexnet2.compile(\n    optimizer=Adam(learning_rate=LEARNING_RATE),\n    loss=CategoricalCrossentropy(),\n    metrics=['accuracy']\n)\nyoga_model.compile(\n    optimizer=Adam(learning_rate=LEARNING_RATE),\n    loss=CategoricalCrossentropy(),\n    metrics=['accuracy']\n)\nwilli_model.compile(\n    optimizer=Adam(learning_rate=LEARNING_RATE),\n    loss=CategoricalCrossentropy(),\n    metrics=['accuracy']\n)","7746b389":"# === Training!! ===\nhistory1 = alexnet2.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=20,\n    callbacks=[lr_callback, checkpoint('alexnet2.h5', 'val_loss', 'min')]\n)\nhistory2 = yoga_model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=30,\n    callbacks=[lr_callback, checkpoint('yoga.h5', 'val_accuracy', 'max')]\n)\nhistory3 = willi_model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=40,\n    callbacks=[lr_callback, checkpoint('willi.h5', 'val_loss', 'min')]\n)","a8a28463":"def plot_hist(history, epoch):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs_range = range(epoch)\n\n    plt.figure(figsize=(16, 8))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, acc, label='Training Accuracy')\n    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.title('Training and Validation Accuracy')\n\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, loss, label='Training Loss')\n    plt.plot(epochs_range, val_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.title('Training and Validation Loss')\n    plt.show()","22e8d89e":"plot_hist(history1, 20)","6cbb2c1f":"plot_hist(history2, 30)","b8bacb2f":"plot_hist(history3, 40)","ba10b041":"sample_submission_df = pd.read_csv(\"..\/input\/if4074-praktikum-1-cnn-2021-01\/sample_submission_.csv\")\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=sample_submission_df,\n    directory=TEST_PATH,\n    x_col=\"filename\",\n    y_col=None,\n    class_mode=None,\n    shuffle=False,\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n)","a5b029c4":"def mapper_output(mapper, pred):\n    out = []\n    for p in pred:\n        out.append(mapper[p])\n    return np.array(out)\n\ndef create_sub_df(y_pred):\n    y_pred = np.argmax(y_pred, axis=1)\n\n    mapper = {}\n    for key, val in train_generator.class_indices.items():\n        mapper[val] = key\n\n    # Create submission df\n    submission_df = pd.DataFrame({\n        'filename': filenames,\n        'labels': mapper_output(mapper,y_pred)\n    })\n    return submission_df","28817fc3":"alexnet2.load_weights('alexnet2.h5')\nyoga_model.load_weights('yoga.h5')\nwilli_model.load_weights('willi.h5')","9e618859":"filenames = test_generator.filenames\nnb_samples = len(filenames)\n\nalexnet2_prediction = alexnet2.predict(test_generator, verbose=1)\nyoga_prediction = yoga_model.predict(test_generator, verbose=1)\nwilli_prediction = willi_model.predict(test_generator, verbose=1)\n\n# Ensemble using SoftVote\ny_pred = np.array([yoga_prediction, willi_prediction]).mean(axis=0)\n\ndf_alexnet = create_sub_df(alexnet2_prediction)\ndf_yoga = create_sub_df(yoga_prediction)\ndf_willi = create_sub_df(willi_prediction)\ndf_ensemble = create_sub_df(y_pred)","d707ae77":"df_alexnet.to_csv('alexnet2.csv', index=False)\ndf_yoga.to_csv('yoga.csv', index=False)\ndf_willi.to_csv('willi.csv', index=False)\ndf_ensemble.to_csv('ensemble.csv', index=False)","b7523a29":"Metode ensemble yang digunakan di sini adalah dengan melakukan soft voting. Kami menggabungkan ketiga buah hasil prediksi (improved-alexnet+2, yoga-net, dan willi-net). Alasan dipilihnya kedua dari 3 model tersebut dikarenakan\n- improved-alexnet+2 merupakan baseline model\n- yoga-net memiliki kecenderungan memiliki probabilitas tinggi pada data yang benar, dan probabilitas menengah pada data yang salah\n- willi-net memiliki kecenderungan memiliki probabilitas yang menengah untuk kedua data yang benar maupun salah, tetapi untuk nilai dari validation loss willi-net lebih kecil dibandingkan yoga-net\n\nDengan menggunakan soft voting, diharapkan model dapat menghindari kesalahan dari willi-net dengan probabilitas tinggi yoga-net dan kesalahan yoga-net yang dicover oleh willi-net yang lebih general","effc8f0f":"<h3 id=\"basics\" style=\"font-family:verdana;\"> \n    <center>4. Evaluation \ud83d\udcdd\n    <\/center>\n<\/h3>","827a34e2":"<center>\n<img src=\"https:\/\/image.freepik.com\/free-vector\/set-weather-doodles-illustration_6997-2189.jpg\"\/>\n <\/center>","d73f25e3":"<h3 id=\"basics\" style=\"font-family:verdana;\"> \n    <center>5. Submission \ud83d\udce6\n    <\/center>\n<\/h3>","4feef9c1":"**Perbedaan willi-net dengan improved-alexnet + 2**\n- Merubah inferensi konvolusi 3x1 dan 1x3 dari sequential menjadi bercabang 2 yang hasilnya akan di-concatenate\n- Mengganti MaxPooling2D menjadi GlobalAveragePooling2D\n- Mengubah lokasi penggunaan Dropout pada setelah GlobalAveragePooling2D dan setelah Fully Connected (Dense) Layer 1 sebesar 0.2.\n\n**Kelebihan model**\n- Pemanfaatan inferensi konvolusi dengan ukuran kernel 3x1 dan 1x3 yang dipecah menjadi 2 yang kemudian di-concatenate dapat memberikan keluaran data yang lebih sesuai dengan konvolusi 3x3 karena input data 3x1 dan 1x3 sama (sedangkan apabila diletakkan sequential perlu penanganan lebih lanjut)\n- Model dapat melakukan generalisasi yang lebih baik ketimbang model baseline (improved-alexnet+2) karena dapat menggeneralisasi secara utuh dari (n x n x channels) menjadi sebanyak channels saja yang tentunya jauh lebih general ketimbang penggunaan flatten yang memakai seluruh fitur. Hal ini bermanfaat pada data dengan jumlah yang sedikit (seperti pada kasus ini, dimana masing - masing kelas umumnya sebanyak 2000 data)\n- Penggunaan dropout pada model dapat mengurangi efek overfitting yang terjadi saat inferensi. Dengan pengurangan kecepatan belajar dari bagian Fully Connected Layer, diharapkan layer secara menyeluruh dapat belajar pola - pola data dengan baik ","429d0097":"<h3 id=\"basics\" style=\"font-family:verdana;\"> \n    <center>1. Setup \u2699\ufe0f\n    <\/center>\n<\/h3>","b9c0a1dc":"<div style=\"font-size:15px; font-family:verdana;\">This notebook contains:\n\n<ol>\n    <li>How to load image data.<\/li>\n    <li>How to preprocess our data.<\/li>\n    <li>How to build model using tensorflow layers.<\/li>\n    <li>How to train our deep learning model.<\/li>\n    <li>How to evaluate our model results!.<\/li>\n<\/ol>\n\n<\/div>\n\n<p> Process! <\/p>\n\n<br>","834708f9":"<h3 id=\"basics\" style=\"font-family:verdana;\"> \n    <center>3. Modelling \ud83d\udcc8\n    <\/center>\n<\/h3>","50773f3d":"**Perbedaan yoga-net dengan Improved Alexnet+2**\n- Mengganti MaxPooling2D terakhir dengan GlobalAveragePooling2D\n- Merubah inferensi konvolusi 3x1 dan 1x3 dari sequential menjadi terpecah 2 yang kemudian akan diconcatenate\n- Menambahkan BatchNormalzation pada bagian setelah dilakukan concatenate terakhir dan 4 konvolusi pertama\n- Mengganti lokasi drop out ke setelah GlobalAveragePooling2D dan setelah dense1 layer\n\n**Kelebihan**\n- Model dapat melakukan generalisasi lebih baik dikarenakan GlobalAveragePooling2D melakukan generasi secara massal dari ukuran (n x n x channels) menjadi ukuran channels dibandingkan dengan Flatten yang memakai seluruh fitur\n- Inferensi konvolusi 3x1 dan 1x3 yang dipecah menjadi 2 yang kemudian diconcatenate dapat memberikan data yang lebih sesuai dengan konvolusi 3x3, dikarenakan input data 3x1 dan 1x3 sama\n- Dengan adanya padding dan pemecahan konvolusi 3x1 dan 1x3, gambar yang terproses menjadi lebih lengkap (tidak ada bagian yang terlupakan ataupun terpotong oleh padding)\n- Dengan adanya BatchNormalization, output yang dihasilkan dari layer konvolusi akan semakin seragam, sehingga untuk melakukan training, waktu yang dibutuhkan akan lebih sedikit (meskipun lebih rentan terhadap overfitting)\n- Dengan adanya drop drop out, model yang dibentuk dapat mengurangi overfitting karena proses randomize saat melakukan inferensi untuk meng-ignore beberapa nodes untuk ke layer selanjutnya, sehingga mengurangi kecepatan belajar dari suatu layer, sehingga layer yang lain dapat mengikuti kecepatan pembelajaran yang lebih sama\n\n","3855fae3":"<h3 id=\"basics\" style=\"font-family:verdana;\"> \n    <center>2. \u231b Load Image ... &amp; Preprocessing \ud83e\uddf9\n    <\/center>\n<\/h3>","d383aaeb":"<h1 style=\"font-family:verdana;\"> <center>\ud83d\udcda  Praktikum I: Convolutional Neural Network \ud83d\udcda<\/center> <\/h1>\n<p><center style=\"color:#159364; font-family:cursive;\">Scene classification with improved AlexNet model<\/center><\/p>\n\n***"}}