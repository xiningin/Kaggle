{"cell_type":{"d2f9c9b8":"code","c9aab107":"code","45102258":"code","d9e11825":"code","911db930":"code","2aec1d73":"code","5ec1c1c7":"code","91819181":"code","075f89ae":"code","2c29c4dc":"code","9f6c6f58":"code","f76272fc":"code","4ee16b7a":"code","866793a6":"code","e06e8746":"code","991a32fe":"markdown","5365041f":"markdown","72e58d0d":"markdown","cadb4266":"markdown","6cfb19c4":"markdown","70b5ddf4":"markdown","ebca66f6":"markdown","bae37b59":"markdown","853274b1":"markdown","cdbff1ba":"markdown","aef16489":"markdown","7511fa5b":"markdown","a156699d":"markdown"},"source":{"d2f9c9b8":"import pandas as pd\nfrom sklearn import model_selection","c9aab107":"train_path = \"..\/input\/tabular-playground-series-mar-2021\/train.csv\"\ntest_path = \"..\/input\/tabular-playground-series-mar-2021\/test.csv\"","45102258":"train = pd.read_csv(train_path)","d9e11825":"train.head()","911db930":"# Reference for this function: https:\/\/www.kaggle.com\/kirillklyukvin\/playground-series-february-21\/notebook\ndef eda(df):\n    \n    \"\"\"\n    This function helps us with simple data analysis.\n    We may explore the common information about the dataset, missing values, features distribution and duplicated rows\n    \"\"\"\n    \n    # applying info() method\n    print('---')\n    print('Common information')\n    print('---')\n    print()\n    print(df.info())\n    \n    # missing values\n    print()\n    print('---')\n    if df.isna().sum().sum() == 0:\n        print('There are no missing values')\n        print('---')\n    else:\n        print('Detected')\n        display(df.isna().sum())\n    \n    \n    # applying describe() method for categorical features\n    print()\n    print('---')\n    print('Categorical columns')\n    print('Total {}'.format(len(df.select_dtypes(include='object').columns)))\n    print('---')\n    display(df.describe(include = 'object'))\n    \n    # same describe() but for continious features\n    print('---')\n    print('Continuous columns')\n    print('Total {}'.format(len(df.select_dtypes(include=['int', 'float']).columns)))\n    print('---')\n    display(df.describe())\n    \n    #checking for duplicated rows\n    if df.duplicated().sum() == 0:\n        print('---')\n        print('There are no duplicates')\n        print('---')\n    else:\n        print('---')\n        print('Duplicates found')\n        print('---')\n        display(df[df.duplicated()])\n    \n    print()\n    print('---')\n    print('End of the report')","2aec1d73":"eda(train)","5ec1c1c7":"train.target.nunique()","91819181":"train.target.value_counts()","075f89ae":"train[\"kfold\"] = -1\ntrain = train.sample(frac=1).reset_index(drop=True)\ny = train.target.values\n\nskf = model_selection.StratifiedKFold(n_splits=5)\n\nfor f, (t_, v_) in enumerate(skf.split(X=train, y=y)):\n    train.loc[v_, 'kfold'] = f\n\ntrain.to_csv(\"train_folds.csv\", index=False)","2c29c4dc":"train_folds_path = \".\/train_folds.csv\"","9f6c6f58":"train_folds = pd.read_csv(train_folds_path)","f76272fc":"train_folds.head()","4ee16b7a":"# checking if all the folds are evenly split\ntrain_folds.kfold.value_counts()","866793a6":"train_folds.head()","e06e8746":"# checking the target distribution in each fold\nfor fold in range(5):\n    print(f\"====FOLD-{fold}====\")\n    df = train_folds[train_folds.kfold == fold]\n    print(df.target.value_counts())\n    print()","991a32fe":"### Target variable","5365041f":"#### Cool, the data seems to be evenly split","72e58d0d":"### Hurrayyy. We got the same distribution in each fold \ud83d\ude4c\ud83d\ude4c\ud83d\ude4c\ud83d\ude4c","cadb4266":"### You should trust your CV more instead of Public Leaderboard. \n### You will less likely overfit the data and will not experience major shakeups in the private leaderboard","6cfb19c4":"#### Data is highly skewed. So, we need to perform a good cross validation in order to decide which model and experiments performs better. You can never trust the public leaderboard :P","70b5ddf4":"Since the data is highly skewed we will perform a Stratified KFold cross validation, which preserves the target distribution in each fold (which helps to avoid overfitting)","ebca66f6":"#### Now, you can train and test your different models on `train_folds.csv` and validate your different experiments and model's performance","bae37b59":"So, we are dealing with a binary classification here","853274b1":"### Summary:\n- We have 19 categorical columns\n- We have 13 categorical columns\n- There are no missing values\n- There are no duplicates","cdbff1ba":"### Best luck for the competition\n### Please show your love by a upvote \ud83d\udc4d\n### Peace \u270c","aef16489":"You wanna make sure this split makes sense. We can do that by checking the stratification\n","7511fa5b":"### Sanity Check","a156699d":"## Stratified KFold Cross Validation"}}