{"cell_type":{"c259906c":"code","d31351bb":"code","9bba9313":"code","c34a0302":"code","218bffdd":"code","24c378ec":"code","2d63473f":"code","2e632541":"code","3619c4f4":"code","f451f5d0":"code","613b0372":"code","2e8077fd":"markdown"},"source":{"c259906c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d31351bb":"!pip install sister -q","9bba9313":"# import packages\nimport sister\nimport nltk\nfrom nltk import word_tokenize as tokenize\nfrom nltk.corpus import stopwords\nfrom scipy.spatial.distance import cosine as similar","c34a0302":"# Read data, drop index column\ndf = pd.read_csv('..\/input\/coding-problems-and-solution-python-code\/ProblemSolutionPythonV2.csv')\ndf = df.drop(columns=[\"Unnamed: 0\"])\n\n# Change column name for better convenient\ndf = df.rename(columns={\"Problem\": 'text', 'Python Code': 'code'})\ndf.head()","218bffdd":"df.info()","24c378ec":"# Function to process sentence: remove stopwords, lower text\ndef preprocess(sent):\n    return \" \".join([word.lower() for word in tokenize(sent) if word not in stopwords.words('english')])","2d63473f":"# preprocess text from data for later use\ndf['preprocess_text'] = df['text'].apply(lambda line: preprocess(line))\ncols = ['text', 'preprocess_text', 'code']\ndf = df[cols]\n\ndf.head()","2e632541":"# call model embedder\nembedder = sister.MeanEmbedding(lang=\"en\")","3619c4f4":"# calculate similarity and return code\ndef get_code(sent):\n    \"\"\"\n    input: sentence: describe what you want this bot to write\n    output: a tuple: \n    - the code\n    - the confident about your describe relate to the code\n    \"\"\"\n    results = [similar(embedder(preprocess(sent)), embedder(text)) for text in df['preprocess_text']]\n    similarity = min(results)\n    return df['code'][results.index(similarity)], round((1-similarity)*100, 2)","f451f5d0":"# print the pretty code :>\ndef print_code(code):\n    print(\"The code:\\n\")\n    for line in code.split('\\r'):\n        print(line)","613b0372":"# text = \"write a function to get a maximum value from an array\"\ntext = \"write a function to remove duplicates from a list\"\n\ncode, confident  = get_code(text)\n\nprint(f\"Confident: {confident}%\")\nprint_code(code)","2e8077fd":"This tool based on pre-coded from the dataset which is fixed (not generate code itself of course) \\\nIt'd be more correct if your description clear enough (and if it's in the dataset)"}}