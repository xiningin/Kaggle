{"cell_type":{"5dfeddfb":"code","3a430c5c":"code","770e14ca":"code","0cec8634":"code","f81500d5":"code","ee3536bd":"code","4f5f3c21":"code","62d15577":"code","fcb46ffb":"code","8dc4e226":"code","c423c3ff":"code","0382f4c4":"code","0d9a69c7":"code","1c56b1e9":"code","876f8333":"code","ef8df1a1":"code","6de98e88":"code","d5cd0d6a":"code","d348e0e2":"code","5d888e71":"code","c39f84b8":"code","7c24aff1":"code","8b817ae1":"code","2643aa96":"markdown","191672a1":"markdown","8a503420":"markdown","c51a67bb":"markdown","818a29c7":"markdown","74314d7f":"markdown","f413345a":"markdown","cf5ece16":"markdown","f0799ca9":"markdown"},"source":{"5dfeddfb":"# We always do this\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\n# Mainly for deep learning\nimport keras\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport tensorflow.keras.backend as K\n\n# Array powered-CUDA\nimport cudf, cuml, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import normalize\n\n# Python std. libraries\nimport os, threading, logging, gc, tqdm\nimport math","3a430c5c":"# Parameter\nBATCH = 64\nIMAGE_SIZE = (512, 512)\nN_CLASS = 11014\n\nDATA_PATH = \"..\/input\/shopee-product-matching\/\"\nTRAIN_PATH = DATA_PATH + \"train_images\/\"\nTEST_PATH = DATA_PATH + \"test_images\/\"\nSPLITS = 100 # for spliting dataset\n\n# True: for CV , False: for Commit\nGET_CV = False ","770e14ca":"# RESTRICT TENSORFLOW TO 2GB OF GPU RAM\n# SO THAT WE HAVE 14GB RAM FOR RAPIDS\nLIMIT = 2.0\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_virtual_device_configuration(\n            gpus[0],\n            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        print(e)\nprint('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\nprint('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))","0cec8634":"# Pandas dataframe\ntrain = pd.read_csv(DATA_PATH + \"train.csv\")\ntest = pd.read_csv(DATA_PATH + \"test.csv\")\n\n# RAPIDS dataframe\ntrain_cuda = cudf.read_csv(DATA_PATH + 'train.csv')\ntest_cuda = cudf.read_csv(DATA_PATH + 'test.csv')\n\nif GET_CV:\n    # Use train data\n    df = train\n    df_cuda = train_cuda\n    MAIN_PATH = TRAIN_PATH\n    \nelse:\n    # Use test data\n    df = test\n    df_cuda = test_cuda\n    MAIN_PATH = TEST_PATH\n\ntrain_cuda.head()","f81500d5":"train.info()","ee3536bd":"test.head()","4f5f3c21":"test.info()","62d15577":"# How many class in here\ntrain[\"label_group\"].nunique()","fcb46ffb":"if GET_CV:\n    target = df.groupby(\"label_group\").posting_id.agg(\"unique\").to_dict()\n    df[\"target\"] = df[\"label_group\"].map(target)\n\npred_phash = df.groupby(\"image_phash\").posting_id.agg(\"unique\").to_dict()\ndf[\"pred_phash\"] = df[\"image_phash\"].map(pred_phash)","8dc4e226":"if GET_CV:\n    # Metrics: F1 Score\n    def get_metric(col):\n        def f1_score(row):\n            n = len( np.intersect1d(row.target,row[col]) )\n            return 2*n \/ (len(row.target)+len(row[col]))\n        return f1_score\n\n    df[\"f1_phash\"] = df.apply(get_metric(\"pred_phash\"), axis=1) # axis=1 will return df row\n    print(\"F1 score with baseline model (phash) {}\".format(df[\"f1_phash\"].mean()))","c423c3ff":"# Build pretrained model and load its weights\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\nweight_path = \"..\/input\/keras-pretrained-models\/EfficientNetB0_NoTop_ImageNet.h5\"\npre_CNN = EfficientNetB0(include_top=False, \n                         weights=weight_path,\n                         pooling=\"avg\")\n\npre_CNN.trainable = False","0382f4c4":"# Read image in dataset\ndef read_im(path):\n    file = tf.io.read_file(path)\n    image = tf.io.decode_jpeg(file, channels=0)\n    image = tf.image.resize(image, (512, 512))\n    image = tf.cast(image, dtype=tf.float32) \/ 255.\n    \n    return image\n\n# Dataset pipeline from filenames --> image arrays\ndef get_image_dataset(filenames):\n    image_dataset = tf.data.Dataset.from_tensor_slices(filenames)\n    image_dataset = image_dataset.map(read_im, num_parallel_calls=tf.data.AUTOTUNE)\\\n                                 .prefetch(tf.data.AUTOTUNE)\n    return image_dataset\n    \n\ndef get_embedding(filenames):\n    embeds = []\n    # So, we split our array into N-splits and extract their features one by one.\n    splits = np.array_split(filenames, SPLITS)\n    for split in tqdm.tqdm( splits ):\n        \n        # when no data left, stop immediately (when test data len is still 3)\n        if not split.any(): \n            break\n        dataset = get_image_dataset(split)\n        features = pre_CNN.predict(dataset)\n        embeds.append(features)\n        \n    return tf.concat(embeds,axis=0)","0d9a69c7":"image_path = MAIN_PATH + df[\"image\"]\nimage_embedding = get_embedding(image_path)","1c56b1e9":"def im_preds(df, feature, splits):\n    feature_chunks = cupy.array_split(feature, splits)\n    preds = []\n\n    for fc in tqdm.tqdm(feature_chunks):\n\n        # Dot product of unit vector = Cosine Similarity\n        # When their dot product got higher, the closer they are\n        dp = cupy.matmul(feature, fc.T).T\n        \n        # This mask is consist of series of true-false value\n        # It is True when the dot product is above the limit\n        mask = cupy.where(dp > 1., True, False)\n        for m in mask:\n            preds.append( df.posting_id[m.get()].values ) # we use .get() to convert cupy to np\n\n    return preds","876f8333":"im_norm = normalize(image_embedding, axis=1)\nim_norm = cupy.array(im_norm)\nimage_preds = im_preds(df, im_norm, SPLITS)\n\n# Delete variable and perform garbage collection\n# RAM: You know, this CUDA-thing made me full. I feels relaxed, now.\ndel im_norm\ngc.collect()","ef8df1a1":"df[\"pred_images\"] = image_preds\n\nif GET_CV:\n    df[\"f1_images\"] = df.apply(get_metric(\"pred_images\"), axis=1)\n    df[\"f1_images\"].mean()","6de98e88":"# Ignore this, just tuning the threshold\n\n# z = normalize(image_embedding, axis=1)\n# z = (z @ z[:2].T).T\n# x = np.where(z > 0.9999999, True, False)\n# for y in x:\n#     print(df[y].posting_id)\n#     print()","d5cd0d6a":"# # Label for each distinct group\n# labels = train[\"label_group\"].unique()\n# labels_map = {label: index for index, label in enumerate(labels)}\n# train[\"label\"] = train[\"label_group\"].map(labels_map)\n# image_labels = train[\"label\"].values","d348e0e2":"tfidf = TfidfVectorizer(stop_words=None, binary=True, max_features=25000)\ntext_embed = tfidf.fit_transform(df_cuda.title).toarray()\ntext_embed = cupy.array(text_embed)","5d888e71":"splits = 100\n\ndef text_preds(df, feature, splits):\n    feature_chunks = cupy.array_split(feature, splits)\n    preds = []\n\n    for fc in tqdm.tqdm(feature_chunks):\n\n        # Dot product of unit vector = Cosine Similarity\n        # When their dot product got higher, the closer they are\n        dp = cupy.matmul(feature, fc.T).T\n        \n        # This mask is consist of series of true-false value\n        # It is True when the dot product is above the limit\n        mask = cupy.where(dp > 0.7, True, False)\n        for m in mask: \n            preds.append( df.posting_id[m.get()].values ) # we use .get() to convert cupy to np\n            \n    return preds\n\npreds = text_preds(df, text_embed, splits)\n\n# Delete variable and perform garbage collection\n# RAM: Okay, I'm taking my vacation, good luck !\ndel text_embed\ngc.collect()","c39f84b8":"# New column of text embed predictions\ndf[\"pred_text_embed\"] = preds\n\nif GET_CV:\n    # Compute f1 score\n    df[\"f1_text\"] = df.apply(get_metric(\"pred_text_embed\"), axis=1)\n    f1 = df[\"f1_text\"].mean()\n    print(\"f1_score with text embeddings: {}\".format(f1))","7c24aff1":"def concat_pred(row):\n    preds = np.concatenate([row.pred_phash, row.pred_images, row.pred_text_embed])\n    return np.unique(preds)\n\ndf[\"matches\"] = df.apply(concat_pred, axis=1)\n\nif GET_CV:\n    df[\"f1_match\"] = train.apply(get_metric(\"matches\"), axis=1)\n    df[\"f1_match\"].mean()","8b817ae1":"submission = pd.DataFrame({\"posting_id\": df.posting_id, \"matches\": df.matches})\nsubmission[\"matches\"] = submission[\"matches\"].map(lambda x: \" \".join(x))\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission","2643aa96":"# Import Your Trustwhorty Libraries","191672a1":"Image_phash LB score: 0.559","8a503420":"## Backbone model: EfficientNetB0","c51a67bb":"# Text Features","818a29c7":"# Image Features\n","74314d7f":"# Submission","f413345a":"# Combine Baseline, Images and Text features predictions","cf5ece16":"# Baseline Model","f0799ca9":"# A little sanity checks on dataframe"}}