{"cell_type":{"8c645fc0":"code","89ca0ba4":"code","eaea2d5c":"code","7336eeb7":"code","fdfa9374":"code","2ab4707c":"code","ebdc8ef8":"code","c46c0460":"code","00e26132":"code","12c61ee8":"code","e686c39d":"code","c4c5ed7a":"code","e09ce186":"code","895aa00c":"code","4fbccff3":"code","88af4f05":"code","c0f757d1":"code","b44d8618":"code","e758026d":"code","e1981e6f":"code","7df2d110":"code","a38e7d65":"code","23d6fc92":"code","d2182fbd":"code","5273ea57":"code","171f4bde":"code","c112b25e":"code","c60bf352":"code","9cb31f2e":"code","aefc16ad":"code","d8e57a77":"code","17212d67":"code","81c341d2":"code","01bafbd1":"code","7b1fe668":"code","f1ca19ec":"code","d6973487":"code","066bc3b4":"code","a8e417e8":"code","fde769e4":"code","2902577a":"code","ae8d7dc9":"code","503acaaf":"code","b9eeb735":"code","a84f5fc8":"code","7f2d08f8":"code","c77357f0":"code","61013574":"markdown","395cc3a0":"markdown","0fec568d":"markdown","8ce9b7b1":"markdown","56c17d5b":"markdown","2cd8e016":"markdown","23c37538":"markdown","c12db02e":"markdown"},"source":{"8c645fc0":"import os\nfrom collections import Counter, defaultdict\nfrom pathlib import Path\n\nfrom tqdm.notebook import tqdm\nimport json\nimport numpy as np\nimport pandas as pd\nfrom fastai.tabular import * \n\npd.set_option('display.max_colwidth', 200)\npd.set_option('display.max_columns', None)\npd.set_option('display.min_rows', 100)\npd.set_option('display.max_rows', 100)\nhome = Path(\"\/kaggle\/input\/data-science-bowl-2019\/\")","89ca0ba4":"from functools import partial\nimport scipy as sp\nfrom sklearn.metrics import cohen_kappa_score\n\nclass OptimizedRounder():\n    \"\"\"\n    An optimizer for rounding thresholds\n    to maximize Quadratic Weighted Kappa (QWK) score\n    # https:\/\/www.kaggle.com\/naveenasaithambi\/optimizedrounder-improved\n    \"\"\"\n    def __init__(self, initial_coef, labels):\n        self.coef_ = 0\n        self.initial_coef = initial_coef\n        self.labels = labels\n\n    def _kappa_loss(self, coef, X, y):\n        \"\"\"\n        Get loss according to\n        using current coefficients\n        \n        :param coef: A list of coefficients that will be used for rounding\n        :param X: The raw predictions\n        :param y: The ground truth labels\n        \"\"\"\n        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = self.labels)\n        return -cohen_kappa_score(X_p, y, weights=\"quadratic\")\n\n    def fit(self, X, y):\n        \"\"\"\n        Optimize rounding thresholds\n        \n        :param X: The raw predictions\n        :param y: The ground truth labels\n        \"\"\"\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        self.coef_ = sp.optimize.minimize(loss_partial, self.initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        \"\"\"\n        Make predictions with specified thresholds\n        \n        :param X: The raw predictions\n        :param coef: A list of coefficients that will be used for rounding\n        \"\"\"\n        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = self.labels)\n\n    def coefficients(self): return self.coef_['x']","eaea2d5c":"%%time\ntypes = {\"event_code\": np.int16, \"event_count\": np.int16, \"game_time\": np.int32}\nraw_train = pd.read_csv(home\/\"train.csv\", dtype=types)\nraw_train[\"timestamp\"] = pd.to_datetime(raw_train[\"timestamp\"]); len(raw_train)","7336eeb7":"raw_test = pd.read_csv(home\/\"test.csv\", dtype=types)\nraw_test[\"timestamp\"] = pd.to_datetime(raw_test[\"timestamp\"])","fdfa9374":"# Remove `installation_id` without any assesments\nids_with_subms = raw_train[raw_train.type == \"Assessment\"][['installation_id']].drop_duplicates()\nraw_train = pd.merge(raw_train, ids_with_subms, on=\"installation_id\", how=\"inner\"); len(raw_train)","2ab4707c":"# Reduce event_id to make data preparation faster\nspecs = pd.read_csv(home\/\"specs.csv\")\nspecs['hashed_info']=specs['info'].transform(hash)\nunique_specs=pd.DataFrame(specs[['hashed_info']].drop_duplicates())\nunique_specs[\"id\"] = np.arange(len(unique_specs))\nspecs = pd.merge(specs,unique_specs,on='hashed_info',how='left')\nevent_id_mapping = dict(zip(specs.event_id,specs.id))\nraw_train[\"event_id\"] = raw_train[\"event_id\"].map(event_id_mapping)\nraw_test[\"event_id\"] = raw_test[\"event_id\"].map(event_id_mapping)","ebdc8ef8":"def get_accuracy(correct_data):\n    # Rounding correct > 1 to 1 lowers the score. Why?\n    correct = len(correct_data.loc[correct_data])\n    wrong = len(correct_data.loc[~correct_data])\n    accuracy = correct\/(correct + wrong) if correct + wrong else 0\n    return accuracy, correct, wrong\n\ndef get_group(accuracy):\n    if not accuracy:\n        return 0\n    elif accuracy == 1:\n        return 3\n    elif accuracy >= 0.5:\n        return 2\n    return 1","c46c0460":"# I prefer this over calculating average\ndef lin_comb(v1, v2, beta): return beta*v1 + (1-beta)*v2","00e26132":"def prepare(data: pd.DataFrame, one_hot: List[str], test=False) -> pd.DataFrame:\n    one_hot_dict = defaultdict(int)\n\n    prepared = []\n    for id_, g in tqdm(data.groupby(\"installation_id\", sort=False)):\n        features = process_id(g, one_hot, one_hot_dict.copy(), test)\n        if not features:\n            continue\n        if test:\n            features[-1][\"is_test\"] = 1\n        prepared.extend(features)\n    return pd.DataFrame(prepared).fillna(0)","12c61ee8":"def process_id(id_data: pd.DataFrame, one_hot_cols, one_hot_dict, test: bool) -> pd.DataFrame:\n    a_accuracy, a_correct, a_wrong, counter = 0, 0, 0, 0\n    features = []\n\n    for s, gs in id_data.groupby(\"game_session\", sort=False):\n        def update_counter(counter: dict, column: str):\n            session_counter = Counter(gs.loc[:, column])\n            for value in session_counter.keys():\n                counter[f\"{column}_{value}\"] += session_counter[value]\n            return counter\n\n        def process_session(gs):\n            # share state with parent process_id()\n            nonlocal one_hot_dict, a_accuracy, a_correct, a_wrong, counter\n            # increment one hot columns for session, e.g. Bird Measurer: 50\n            def accumulate():\n                # accumulated one_hot features per id for a given session, e.g. Bird Measurer: 50\n                for c in one_hot_cols:\n                    one_hot_dict.update(update_counter(one_hot_dict, c))\n                duration = (gs[\"timestamp\"].iloc[-1] - gs[\"timestamp\"].iloc[0]).seconds\n                \n                cor_mask = gs[\"event_data\"].str.contains('\"correct\"')\n                corrects = gs.loc[cor_mask]\n                for c in corrects[\"event_id\"].unique():\n                    answers = corrects.loc[corrects[\"event_id\"] == c, \"event_data\"].apply(lambda x: json.loads(x).get(\"correct\"))\n                    event_accuracy, event_c, event_i = get_accuracy(answers)\n                    one_hot_dict[f\"accuracy_event_{c}\"] += event_accuracy\n                        \n            if gs[\"type\"].iloc[0] != \"Assessment\":\n                accumulate()\n                return\n\n            guess_mask = ((gs[\"event_data\"].str.contains(\"correct\")) & \n             (((gs[\"event_code\"] == 4100) &(~gs[\"title\"].str.startswith(\"Bird\")) | \n               ((gs[\"event_code\"] == 4110) & (gs[\"title\"].str.startswith(\"Bird\"))))))\n            answers = gs.loc[guess_mask, \"event_data\"].apply(lambda x: json.loads(x).get(\"correct\"))\n\n            # skip assessments without attempts in train\n            if answers.empty and not test:\n                accumulate()\n                return\n\n            accuracy, correct, wrong = get_accuracy(answers)\n            group = get_group(accuracy)\n            processed = {\"installation_id\": id_data[\"installation_id\"].iloc[0],\n                         \"title\": gs[\"title\"].iloc[0],\n                         \"accumulated_accuracy_mean\": a_accuracy\/counter if counter > 0 else 0,\n                         \"accuracy_group\": group,\n                        }\n            processed.update(one_hot_dict)\n            counter += 1\n            a_accuracy += accuracy\n            a_correct += correct\n            a_wrong += wrong\n            accumulate()\n            return processed\n        \n        # skip sessions with 1 row\n        if len(gs) == 1 and not test:\n            continue\n        gs.reset_index(inplace=True, drop=True)\n        if (gs[\"timestamp\"].iloc[-1] - gs[\"timestamp\"].iloc[0]).seconds > 1800:\n            gs[\"passed\"] = gs.loc[:, \"timestamp\"].diff().apply(lambda x: x.seconds)\n            id_max = gs[\"passed\"].idxmax()\n            if gs[\"passed\"].max() > 1800:\n                session = gs.iloc[:id_max]\n                continued_session = gs.iloc[id_max:]\n                fs = process_session(session)\n                c_fs = process_session(continued_session)\n                if fs:\n                    features.append(fs)\n                if c_fs:\n                    features.append(c_fs)\n                continue\n\n        session_features = process_session(gs)\n        if session_features:\n            features.append(session_features)\n        \n    return features","e686c39d":"one_hot_counters=[\"event_id\"]\ntrain = prepare(raw_train, one_hot_counters).sort_index(axis=1)\n# train = prepare(raw_train.iloc[:100_000], one_hot_counters).sort_index(axis=1)","c4c5ed7a":"test = prepare(raw_test, one_hot=one_hot_counters, test=True)","e09ce186":"assert len(test[test[\"is_test\"] == 1]) == 1000","895aa00c":"# why discard good data from test, let's use all the taken assessments in train!\ntrain = (pd.concat([train, test[test[\"is_test\"] == 0].drop(columns=[\"is_test\"])],\n                   ignore_index=True, sort=False)).fillna(0).sort_index(axis=1)\ntrain.head()","4fbccff3":"test = test.loc[test[\"is_test\"] == 1].reset_index(drop=True).sort_index(axis=1)\ntest.drop(columns=[\"accuracy_group\", \"is_test\"], inplace=True)\ntest.head()","88af4f05":"diff = train.drop(columns=[\"accuracy_group\"]).columns.difference(test.columns)\ndisplay(f\"Test doesn't contain {diff.values}\")\ndisplay(f\"Train doesn't contain {test.columns.difference(train.columns).values}\")\ntrain.drop(columns=diff, inplace=True)","c0f757d1":"main_train = train.copy()\n# train = main_train.copy()","b44d8618":"del_cols = []\nfor col in train.columns.values:\n    counts = train[col].value_counts().iloc[0]\n    if (counts \/ train.shape[0]) >= 0.99:\n        del_cols.append(col)\ntrain.drop(columns=del_cols, inplace=True, errors=\"ignore\")\ntest.drop(columns=del_cols, inplace=True, errors=\"ignore\")\ndisplay(f\"Dropped {del_cols}\")","e758026d":"train.tail()","e1981e6f":"test.tail()","7df2d110":"procs = [FillMissing, Categorify, Normalize]","a38e7d65":"# np.random.seed(42)","23d6fc92":"# remove outliers\n# train = train[train[train.columns[train.columns.str.startswith(\"duration_\", na=False)].to_list()].apply(sum, axis=1) < 10000].reset_index(drop=True)","d2182fbd":"# grab the last assessments per id\nvalid_idx = [g.iloc[-1].name for i, g in train.groupby(\"installation_id\", sort=False)]; len(valid_idx)","5273ea57":"dep_var = \"accuracy_group\"\ncat_names = [\"title\"]","171f4bde":"from fastai.metrics import RegMetrics\nfrom fastai.callbacks import *\n\nclass KappaScoreRegression(RegMetrics):\n    def on_epoch_end(self, last_metrics, **kwargs):\n        preds = self.preds.flatten()\n        opt = OptimizedRounder([1, 1.5, 2.0], labels=[0, 1, 2, 3])\n        opt.fit(preds, self.targs)\n        coefs = opt.coefficients()\n        def rounder(preds):\n            y = preds.clone()\n            y[y < coefs[0]] = 0\n            y[y >= coefs[2]] = 3\n            y[(y >= coefs[0]) & (y < coefs[1])] = 1\n            y[(y >= coefs[1]) & (y < coefs[2])] = 2\n            return y.type(torch.IntTensor)\n\n        qwk = cohen_kappa_score(rounder(preds), self.targs, weights=\"quadratic\")\n        return add_metrics(last_metrics, qwk)","c112b25e":"drops = [\"baseline\",\n         \"accumulated_accuracy_mean\", \"accuracy_event_\",\n         \"event_id_\",\n         ]\n# goods = [\"event_id_\", \"title\", ]","c60bf352":"dropped_features = pd.DataFrame(index=sorted(drops))","9cb31f2e":"# start = 0\n# end = 10\n\n# for r in tqdm(range(start, end)):\n#     for d in drops:\n#         display(d)\n#         drop_column = train.columns[train.columns.str.startswith(d)].to_list()\n#         if not drop_column:\n#             drop_column = [f\"baseline_{d}\"]\n#         cont_names = list(filter(lambda x: x not in [\"installation_id\", dep_var] + cat_names + drop_column,\n#                              train.columns.to_list()))\n#         data = (TabularList.from_df(train, path=\"\/kaggle\/working\", cat_names=cat_names, cont_names=cont_names, procs=procs)\n#             .split_by_idx(valid_idx=valid_idx)\n#             .label_from_df(cols=dep_var, label_cls=FloatList)\n#             .add_test(TabularList.from_df(test, path=home, cat_names=cat_names, cont_names=cont_names, procs=procs))\n#             .databunch()\n#         )\n#         learn = tabular_learner(data, layers=[2000,100],\n#                             metrics=[KappaScoreRegression()],\n#                             y_range=[0, 3],\n#                             emb_drop=0.04,\n#                             ps=0.6,\n#                             callback_fns=[partial(EarlyStoppingCallback, monitor=\"kappa_score_regression\", mode=\"max\", patience=7),\n#                                           partial(SaveModelCallback, monitor=\"kappa_score_regression\", mode=\"max\", name=\"best_model\")]\n#                            )\n#         learn.fit_one_cycle(30, 3e-03)\n#         dropped_features.loc[d, r] = learn.validate()[-1].item()\n#         display(dropped_features.loc[d, r])\n","aefc16ad":"dropped_features[\"mean\"] = dropped_features.apply(lambda x: x.mean(), axis=1)","d8e57a77":"dropped_features.sort_values(\"mean\", ascending=False)","17212d67":"cont_names = list(filter(lambda x: x not in [\"installation_id\", dep_var] + cat_names,\n                         train.columns.to_list()))","81c341d2":"data = (TabularList.from_df(train, path=\"\/kaggle\/working\", cat_names=cat_names, cont_names=cont_names, procs=procs)\n        .split_by_idx(valid_idx=valid_idx)\n        .label_from_df(cols=dep_var, label_cls=FloatList)\n        .add_test(TabularList.from_df(test, path=home, cat_names=cat_names, cont_names=cont_names, procs=procs))\n        .databunch()\n)","01bafbd1":"import optuna","7b1fe668":"def objective(trial):\n    layers = trial.suggest_categorical(\"layers\", [[2000, 100],\n                                                  [3000, 200]])\n    emb_drop = trial.suggest_discrete_uniform(\"emb_drop\", 0.04, 0.08, 0.04)\n    ps = trial.suggest_discrete_uniform(\"ps\", 0.2, 0.8, 0.2)\n\n    learn = tabular_learner(data, layers=layers,\n                            metrics=[KappaScoreRegression()],\n                            y_range=[0, 3],\n                            emb_drop=emb_drop,\n                            ps=ps,\n                            callback_fns=[partial(EarlyStoppingCallback, monitor=\"kappa_score_regression\", mode=\"max\", patience=7),\n                                          partial(SaveModelCallback, monitor=\"kappa_score_regression\", mode=\"max\", name=\"best_model\")]\n                       )\n\n    learn.fit_one_cycle(30, 3e-03)\n    return 1- learn.validate()[-1].item()","f1ca19ec":"# study = optuna.create_study()\n# study.optimize(objective, n_trials=80)\n# study.best_params","d6973487":"study.trials_dataframe().sort_values(by=\"value\")","066bc3b4":"learn = tabular_learner(data, layers=[2000,100],\n                        metrics=[KappaScoreRegression()],\n                        y_range=[0, 3],\n                        emb_drop=0.04,\n                        ps=0.6,\n                        callback_fns=[partial(EarlyStoppingCallback, monitor=\"kappa_score_regression\", mode=\"max\", patience=10),\n                                      partial(SaveModelCallback, monitor=\"kappa_score_regression\", mode=\"max\", name=\"best_model\")]\n                       )","a8e417e8":"# learn.lr_find()\n# learn.recorder.plot()","fde769e4":"learn.fit_one_cycle(30, 3e-03)","2902577a":"learn.fit_one_cycle(30, 3e-04)","ae8d7dc9":"# preds_train, y = learn.get_preds(ds_type=DatasetType.Valid)\n# labels_train = preds_train.flatten()\n# opt = OptimizedRounder([1, 1.5, 2.0], labels=[0, 1, 2, 3])\n# opt.fit(labels_train, y)","503acaaf":"# coefs = opt.coefficients(); coefs\ncoefs = [1.04, 1.76, 2.18]","b9eeb735":"def rounder(preds):\n    y = preds.clone()\n    y[y < coefs[0]] = 0\n    y[y >= coefs[2]] = 3\n    y[(y >= coefs[0]) & (y < coefs[1])] = 1\n    y[(y >= coefs[1]) & (y < coefs[2])] = 2\n    return y.type(torch.IntTensor)","a84f5fc8":"preds, y = learn.get_preds(ds_type=DatasetType.Test)\nlabels = preds.flatten()","7f2d08f8":"labels = rounder(labels)","c77357f0":"submission = pd.DataFrame({\"installation_id\": test.installation_id, \"accuracy_group\": labels})\nsubmission.to_csv(\"submission.csv\", index=False)\nlen(submission), submission.accuracy_group.value_counts(normalize=True)","61013574":"# Dropped features","395cc3a0":"## Kappa","0fec568d":"# Looking at data","8ce9b7b1":"# Preparing data","56c17d5b":"# Submission","2cd8e016":"# Train","23c37538":"# Hyperparameters search","c12db02e":"## Proper validation dataset\n\nLet's assume the second hidden test is the same as this one. I.e. we predict the last assessment."}}