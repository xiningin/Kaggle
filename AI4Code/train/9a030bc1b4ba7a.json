{"cell_type":{"4ff8991b":"code","a8d81fe3":"code","50f3b0f9":"code","be72252d":"code","d19e021d":"code","b85d2d50":"code","37111259":"code","45d7aebc":"code","8952f0fe":"code","d7615689":"code","dd48f983":"code","42450994":"code","fc1ae2a5":"code","811887d3":"code","ce287791":"code","f7c1b1d8":"code","cb63b98e":"code","aa7a04f3":"code","2144f9bb":"code","099e9410":"code","68ab9fc7":"code","9264b857":"code","386c3838":"code","8c9cd455":"code","ea201387":"code","61f3e114":"code","6c861d6d":"code","c970d550":"code","17300655":"code","9fbe7d64":"code","21a0b805":"code","a1d1e001":"code","f3bba451":"code","ad59b374":"code","2938fa91":"code","a824d7e3":"code","7d877a70":"code","bd21e9de":"code","442d1a7a":"code","e72d3f9a":"code","04273d27":"code","335e6766":"code","e09f859a":"code","9b19bc56":"code","59d8fc2c":"markdown","c0311959":"markdown","0c110cce":"markdown","edc07689":"markdown","67071d63":"markdown","b5bc9028":"markdown","dd7b5162":"markdown","4e0f6764":"markdown","dd8176ca":"markdown","ca2b17f1":"markdown","398eedd3":"markdown","7488805e":"markdown","07f0f527":"markdown"},"source":{"4ff8991b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a8d81fe3":"import pandas as pd\ndf = pd.read_csv('\/kaggle\/input\/vienna-subway-network\/Vienna subway.csv', sep=';')\ndf.head()","50f3b0f9":"stations = pd.unique(df[['Start', 'Stop']].values.flatten())\nstations = sorted(stations)\nstation2id = {s:i for i, s in enumerate(stations)}\nid2station = dict(enumerate(stations))","be72252d":"import networkx as nx\nnx.__version__","d19e021d":"G = nx.Graph()","b85d2d50":"for station_name, id in station2id.items():\n    G.add_node(id, name=station_name)","37111259":"for i, series in df.iterrows():\n    u = station2id[series['Start']]\n    v = station2id[series['Stop']]\n    line = series['Line']\n    color = series['Color']\n    G.add_edge(u, v, line=line, color=color)","45d7aebc":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.figure(figsize=(20,15))\n\n# calculate posisions in which the nodes are to be placed.\npos = nx.spring_layout(G, k=0.05, seed=2020)\n\n# draw edges\nunique_colors = pd.unique(list(nx.get_edge_attributes(G, 'color').values()))\nfor color in unique_colors:\n    edgelist = [e for e, c in nx.get_edge_attributes(G, 'color').items() if c == color]\n    nx.draw_networkx_edges(G, pos, edgelist=edgelist, edge_color=color, width=5)\n\n# draw nodes\nnx.draw_networkx_labels(G, pos, id2station, alpha=0.5)\nnx.draw_networkx_nodes(G, pos, node_color='white', node_size=100)\n\nplt.axis(\"off\")\nplt.show()","8952f0fe":"pr = nx.pagerank(G)","d7615689":"for i in range(10):\n    print('[{}] pageranke score: {}'.format(i, pr[i]))","dd48f983":"plt.figure(figsize=(20,15))\n\n# draw edges\nfor color in unique_colors:\n    edgelist = [e for e, c in nx.get_edge_attributes(G, 'color').items() if c == color]\n    nx.draw_networkx_edges(G, pos, edgelist=edgelist, edge_color=color, width=5)\n\n# draw nodes\nnode_size = [100000 * value for key, value, in pr.items()]\nnx.draw_networkx_labels(G, pos, id2station, alpha=0.5)\nnx.draw_networkx_nodes(G, pos, node_color='gray', alpha=0.8, node_size=node_size)\n\nplt.axis(\"off\")\nplt.show()","42450994":"!cd \/tmp && git clone https:\/\/github.com\/phanein\/deepwalk.git && pip install .\/deepwalk","fc1ae2a5":"from deepwalk import graph\nimport random\nfrom gensim.models import Word2Vec\n\n# parameter # (default parameter)\nn_walks = 50 # 10\nwalk_length = 100 # 40\nn_workers = 1\nrepresentation_size = 2\nwindow_size = 10 # 5\nseed = 2020\n\nwalks = graph.build_deepwalk_corpus(graph.from_networkx(G), num_paths=n_walks, path_length=walk_length, alpha=0, rand=random.Random(seed))\nmodel = Word2Vec(walks, size=representation_size, window=window_size, min_count=0, sg=1, hs=1, workers=n_workers)\nmodel.wv.save_word2vec_format('\/tmp\/deepwalk.out')","811887d3":"deepwalk_out = pd.read_csv('\/tmp\/deepwalk.out', header=0, sep=' ', names=['x1', 'x2'])\nembed_pos = {i: [row['x1'], row['x2']] for i, row in deepwalk_out.iterrows()}\n\ndeepwalk_out.head()","ce287791":"plt.figure(figsize=(16,12))\n\n# draw edges\nunique_colors = pd.unique(list(nx.get_edge_attributes(G, 'color').values()))\nfor color in unique_colors:\n    edgelist = [e for e, c in nx.get_edge_attributes(G, 'color').items() if c == color]\n    nx.draw_networkx_edges(G, embed_pos, edgelist=edgelist, edge_color=color, width=5)\n\n# draw nodes\nnx.draw_networkx_nodes(G, embed_pos, node_color='gray', alpha=0.8, node_size=200)\n\nplt.axis(\"off\")\nplt.show()","f7c1b1d8":"! cd \/tmp && git clone https:\/\/github.com\/openjny\/role2vec && pip install texttable","cb63b98e":"nx.write_edgelist(G, \"\/tmp\/G.edgelist\", data=False, delimiter=',')","aa7a04f3":"! cd \/tmp\/role2vec && python src\/main.py --dimensions 2 --walk-number 20 --window-size 10 --graph-input \/tmp\/G.edgelist --output \/tmp\/role2vec.out","2144f9bb":"role2vec_out = pd.read_csv('\/tmp\/role2vec.out', index_col='id')\nembed_pos = {i: [row['x_0'], row['x_1']] for i, row in role2vec_out.iterrows()}\nrole2vec_out.head()","099e9410":"plt.figure(figsize=(16,12))\n\n# draw edges\nunique_colors = pd.unique(list(nx.get_edge_attributes(G, 'color').values()))\nfor color in unique_colors:\n    edgelist = [e for e, c in nx.get_edge_attributes(G, 'color').items() if c == color]\n    nx.draw_networkx_edges(G, embed_pos, edgelist=edgelist, edge_color=color, width=5)\n\n# draw nodes\nnx.draw_networkx_nodes(G, embed_pos, node_color='gray', alpha=0.8, node_size=200)\n\nplt.axis(\"off\")\nplt.show()","68ab9fc7":"!pip install dgl rdflib ","9264b857":"import dgl\ndgl.__version__","386c3838":"def to_dgl(G):\n    g = dgl.DGLGraph()\n    g.add_nodes(len(G))\n    edge_list = [(u,v) for u,v in nx.edges(G)]\n    src, dst = tuple(zip(*edge_list))\n    g.add_edges(src, dst)\n    g.add_edges(dst, src)\n    return g\n\ng = to_dgl(G)\n\n# You can revert this convertion with the `to_networkx` function.\n# G = g.to_networkx().to_undirected()","8c9cd455":"import torch\n\nonehot_features = torch.eye(len(G))\ng.ndata['feat'] = onehot_features","ea201387":"# For example, the feature vector of the 4th node goes like: \nprint(g.nodes[3].data['feat'])","61f3e114":"import torch.nn as nn\nimport torch.nn.functional as F\n\n# Define the message & reduce function\n# NOTE: we ignore the GCN's normalization constant c_ij for this tutorial.\ndef gcn_message(edges):\n    # The argument is a batch of edges.\n    # This computes a (batch of) message called 'msg' using the source node's feature 'h'.\n    return {'msg' : edges.src['h']}\n\ndef gcn_reduce(nodes):\n    # The argument is a batch of nodes.\n    # This computes the new 'h' features by summing received 'msg' in each node's mailbox.\n    return {'h' : torch.sum(nodes.mailbox['msg'], dim=1)}\n\n# Define the GCNLayer module\nclass GCNLayer(nn.Module):\n    def __init__(self, in_feats, out_feats):\n        super(GCNLayer, self).__init__()\n        self.linear = nn.Linear(in_feats, out_feats)\n\n    def forward(self, g, inputs):\n        # g is the graph and the inputs is the input node features\n        # first set the node features\n        g.ndata['h'] = inputs\n        # trigger message passing on all edges\n        g.send(g.edges(), gcn_message)\n        # trigger aggregation at all nodes\n        g.recv(g.nodes(), gcn_reduce)\n        # get the result node features\n        h = g.ndata.pop('h')\n        # perform linear transformation\n        return self.linear(h)\n    \n# Define a 2-layer GCN model\nclass BasicGCN(nn.Module):\n    def __init__(self, in_feats, hidden_size, num_classes):\n        super(BasicGCN, self).__init__()\n        self.gcn1 = GCNLayer(in_feats, hidden_size)\n        self.gcn2 = GCNLayer(hidden_size, num_classes)\n\n    def forward(self, g, inputs):\n        h = self.gcn1(g, inputs)\n        h = torch.relu(h)\n        h = self.gcn2(g, h)\n        return h","6c861d6d":"plt.figure(figsize=(15,15))\nunique_colors = pd.unique(list(nx.get_edge_attributes(G, 'color').values()))\nfor color in unique_colors:\n    edgelist = [e for e, c in nx.get_edge_attributes(G, 'color').items() if c == color]\n    nx.draw_networkx_edges(G, pos, edgelist=edgelist, edge_color=color, width=5)\nnx.draw_networkx_labels(G, pos, {i:str(i) for s,i in station2id.items()}, font_size=18, alpha=0.8)\nnx.draw_networkx_nodes(G, pos, node_color='white', node_size=400)\nplt.axis(\"off\")\nplt.show()","c970d550":"unique_colors","17300655":"from progressbar import progressbar \n\n# The first layer transforms input features of size of #nodes to a hidden size of 10.\n# The second layer transforms the hidden layer and produces output features of\n# size 5, corresponding to the five colors of the representative nodes.\nnet = BasicGCN(len(g.nodes), 10, 5)\n\ninputs = torch.eye(len(g.nodes))\nlabeled_nodes = torch.tensor([60,47,38,20,77,35,76,80,31,69,78,61])  # only the instructor and the president nodes are labeled\nlabels = torch.tensor([0,0,0,1,1,1,2,2,3,3,4,4])  # their labels are different\n\n# Options for learning\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nn_epochs = 100\n\nall_logits = []\nlosses = []\n\nfor epoch in progressbar(range(n_epochs)):\n    logits = net(g, inputs)\n    # we save the logits for visualization later\n    all_logits.append(logits.detach())\n    logp = F.log_softmax(logits, 1)\n    # we only compute loss for labeled nodes\n    loss = F.nll_loss(logp[labeled_nodes], labels)\n    losses.append(loss.item())\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()","9fbe7d64":"def plot_loss(losses, n_epochs, **kwargs):\n    fig, ax = plt.subplots(**kwargs)\n    ax.plot(range(n_epochs), losses)\n    ax.set_xlabel(\"epochs\")\n    ax.set_ylabel(\"loss\")\n    ax.set_title(\"Loss by epoch\")\n    plt.show()","21a0b805":"plot_loss(losses, n_epochs)","a1d1e001":"epoch = -10\nnode_id = 41\n\nprint('node #{} in epoch #{}'.format(node_id, epoch))\nprint('logits:', all_logits[epoch][node_id].numpy())\nprint('the most possible class:', unique_colors[all_logits[epoch][node_id].argmax().numpy()])","f3bba451":"predictions = [unique_colors[x] for x in all_logits[-1].argmax(axis=-1)]","ad59b374":"def plot_predictions(pos, predictions):\n    plt.figure(figsize=(16,12))\n\n    nx.draw_networkx_nodes(G, pos, node_color=predictions, alpha=0.5, node_size=300)\n    nx.draw_networkx_nodes(G, pos, nodelist=labeled_nodes.tolist(), node_color=[unique_colors[l] for l in labels], alpha=0.9, node_size=1000)\n\n    for color in unique_colors:\n        edgelist = [e for e, c in nx.get_edge_attributes(G, 'color').items() if c == color]\n        nx.draw_networkx_edges(G, pos, edgelist=edgelist, edge_color=color, width=2)\n\n        colored_labels = {i:i for i,c in dict(enumerate(predictions)).items() if c == color}\n        nx.draw_networkx_labels(G, pos, colored_labels, font_size=10, font_color=color)\n\n    plt.axis(\"off\")\n    plt.show()\n\nplot_predictions(pos, predictions)","2938fa91":"import torch\nimport torch.nn as nn\nfrom dgl.nn.pytorch import GraphConv\n\nclass GCN(nn.Module):\n    def __init__(self,\n                 g,\n                 in_feats,\n                 n_hidden,\n                 n_classes,\n                 n_layers,\n                 activation,\n                 dropout):\n        super(GCN, self).__init__()\n        self.g = g\n        self.dropout = nn.Dropout(p=dropout)\n        \n        self.layers = nn.ModuleList()\n        # input layer\n        self.layers.append(GraphConv(in_feats, n_hidden, activation=activation))\n        # hidden layers\n        for i in range(n_layers - 1):\n            self.layers.append(GraphConv(n_hidden, n_hidden, activation=activation))\n        # output layer\n        self.layers.append(GraphConv(n_hidden, n_classes))\n\n    def forward(self, features):\n        h = features\n        for i, layer in enumerate(self.layers):\n            if i != 0:\n                h = self.dropout(h)\n            h = layer(self.g, h)\n        # output logits\n        return h","a824d7e3":"# cuda option\ncuda = False\n\n# normalization term\ndegs = g.in_degrees().float()\nnorm = torch.pow(degs, -0.5)\nnorm[torch.isinf(norm)] = 0\nif cuda:\n    norm = norm.cuda()\ng.ndata['norm'] = norm.unsqueeze(1)\n\n# hyper parameters\nn_epochs = 100\nn_layers = 3\nn_hidden = 16\ndropout = 0.3\nweight_decay = 5e-4\nlr=0.01\n\n# feature and target class\nfeatures  = torch.eye(len(g.nodes))\nin_feats = features.shape[1]\nn_classes = len(unique_colors)\n\n# supervise data\nlabeled_nodes = torch.tensor([60,47,20,77,76,80,31,69,78,61])\nlabels = torch.tensor([0,0,1,1,2,2,3,3,4,4])\n\nmodel = GCN(g,\n            in_feats,\n            n_hidden,\n            n_classes,\n            n_layers,\n            F.relu,\n            dropout)\noptimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n\nall_logits = []\nlosses = []\n\nn_epochs = 200\nfor epoch in progressbar(range(n_epochs)):\n    model.train()\n    logits = model(features)\n#     all_logits.append(logits.detach())\n\n    logp = F.log_softmax(logits, 1)\n    loss = F.nll_loss(logp[labeled_nodes], labels)\n    losses.append(loss.item())\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()","7d877a70":"plot_loss(losses, n_epochs)","bd21e9de":"predictions = [unique_colors[x] for x in logits.argmax(axis=-1)]\nplot_predictions(pos, predictions)","442d1a7a":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom dgl.nn.pytorch import GraphConv\nfrom dgl.nn.pytorch import SumPooling, MaxPooling\n\n# https:\/\/github.com\/pengchenghu428\/GraphTools\/blob\/master\/experiment\/pytorch\/gcn.py\nclass AdvancedGCN(nn.Module):\n    def __init__(self,\n                 g,\n                 in_feats,\n                 n_output=2,\n                 n_hidden_gcn=[256, 256, 256],\n                 n_hidden_mlp=[32],\n                 n_dense_hidden=128,\n                 activation=F.leaky_relu,\n                 dropout=0.2):\n        super(AdvancedGCN, self).__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        self.activation = activation\n        self.n_dense_hidden = n_dense_hidden\n        self.n_hidden_gcn = n_hidden_gcn\n        self.g = g\n        \n        # GCN layer\n        self.gcn_layers = nn.ModuleList()\n        self.gcn_layers.append(GraphConv(in_feats, n_hidden_gcn[0], activation=activation))\n        for i in range(len(n_hidden_gcn)-1):\n            self.gcn_layers.append(GraphConv(n_hidden_gcn[i], n_hidden_gcn[i+1], activation=activation))\n        \n        # MLP layer\n        n_hidden_mlp.append(n_output)\n        self.mlp_layers = nn.ModuleList()\n        self.mlp_layers.append(nn.Linear(n_hidden_gcn[-1], n_hidden_mlp[0]))\n        for i in range(len(n_hidden_mlp)-1):\n            self.mlp_layers.append(nn.Linear(n_hidden_mlp[i], n_hidden_mlp[i+1]))\n\n    def forward(self, features):\n        self.h = []\n        h = features\n        \n        # GCN\n        for i, gcn_layer in enumerate(self.gcn_layers):\n            if i != 0:\n                h = self.dropout(h)\n            h = gcn_layer(self.g, h)\n            self.h.append(h)\n            \n        # MLP\n        for i, mlp_layer in enumerate(self.mlp_layers):\n            if i != 0:\n                h = self.dropout(h)\n            h = mlp_layer(h)\n            h = F.relu(h)\n            self.h.append(h)\n        \n        return h\n    \n    def _get_flatten_size(self, x):\n        size = x.size()[1:]\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n\nmodel = AdvancedGCN(g,\n                    in_feats,\n                    n_hidden_gcn=[16, 16],\n                    n_hidden_mlp=[8],\n                    n_output=n_classes,\n                    dropout=0.2)\noptimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n\nall_logits = []\nlosses = []\n\nn_epochs = 100\nfor epoch in progressbar(range(n_epochs)):\n    model.train()\n    logits = model(features)\n    \n    logp = F.log_softmax(logits, 1)\n    loss = F.nll_loss(logp[labeled_nodes], labels)\n    losses.append(loss.item())\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()","e72d3f9a":"plot_loss(losses, n_epochs)","04273d27":"predictions = [unique_colors[x] for x in logits.argmax(axis=-1)]\nplot_predictions(pos, predictions)","335e6766":"for h in model.h:\n    print(h.shape)","e09f859a":"for i, h in enumerate(model.h):\n    if h.shape[1] == 2:\n        embed_pos = {i: [node[0], node[1]] for i, node in enumerate(h.detach())}\n        plot_predictions(embed_pos, predictions)\n        break","9b19bc56":"from sklearn.manifold import TSNE\n\nembedded = TSNE(n_components=2).fit_transform(model.h[-1].detach())\nembed_pos = {i: [node[0], node[1]] for i, node in enumerate(embedded)}\nplot_predictions(embed_pos, predictions)","59d8fc2c":"Choice a representative node for each color as follows:\n\n- red: `60, 47, 38`\n- brown: `20, 77, 35`\n- purple: `76, 80`\n- green: `31, 69`\n- orange: `78, 61`","c0311959":"Well done! Now we've done pre-processing and cleaned graph data as `networkx.Graph`, so let's look dive into how machine learning algorithms on graphs can deal with this type input data.\n\n## Unspervised Learning\n\n### PageRank\n\n**PageRank (PR)** is one of the most famous algorithms in network analysis and was invented by Google to estimate importances of online pages. PR can be used to evaluate **centralities**. See [the Wikipedia page](https:\/\/www.wikiwand.com\/en\/Centrality) for more details about centrality.","0c110cce":"Now we consider correct labels corresponding to nodes, a.k.a. **supervisers** or **labels**, which ","edc07689":"## Semi-supervised Learning\n\n### Graph Convolutional Network","67071d63":"Define a more sophisticated GCN model.","b5bc9028":"# Network\/Graph Representation Learning tutorial\n\n## Preprocess","dd7b5162":"More advanced GCN","4e0f6764":"`networkx` allows you to handle graph data on Python in a simple way, but one thing you have to keep in mind about `networkx` is that the APIs are not publicly compatible with the old one. We highlly recomend to confirm which version of `networkx` you are going to import, and use the corresponding documentation or online articles.","dd8176ca":"Next, we're gonna try some well-known graph embedding algorithms (e.g. DeepWalk). The `ge` package (which stands for graph-embedding) implemented the following algorithms are distributed via the GitHub repo: https:\/\/github.com\/shenweichen\/GraphEmbedding.\n\n- DeepWalk [KDD 2014]\n- LINE [WWW 2015]\n- node2vec [KDD 2016]\n- SDNE [KDD 2016]\n- struc2vec [KDD 2017]\n\n### DeepWalk [KDD 2014]","ca2b17f1":"Let's look at the graph with simple code.","398eedd3":"![image.png](attachment:image.png)","7488805e":"Define graph convolutional layer and GCN model.","07f0f527":"### role2vec"}}