{"cell_type":{"1d756cc2":"code","c62b2d25":"code","1726b935":"code","f8a2223a":"code","05e3a228":"code","c9b0a125":"code","6812a738":"code","04a1dbcc":"code","bf34774d":"code","2045d0c3":"code","228d1ea8":"code","f9f2d446":"code","f414f31c":"code","ff1caed1":"code","9af54467":"code","3e24a5d3":"code","79f441d9":"code","44e9315a":"markdown"},"source":{"1d756cc2":"\nimport os\nimport cv2\nimport numpy as np\nfrom time import time\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.applications import VGG16\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline","c62b2d25":"train_dir = '..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train'\ntest_dir = '..\/input\/asl-alphabet\/asl_alphabet_test\/asl_alphabet_test'\nclasses = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', \n           'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', \n           'W', 'X', 'Y', 'Z', 'nothing', 'space', 'del']\nplt.figure(figsize=(11, 11))\nfor i in range (0,29):\n    plt.subplot(7,7,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    path = train_dir + \"\/{0}\/{0}1.jpg\".format(classes[i])\n    img = plt.imread(path)\n    plt.imshow(img)\n    plt.xlabel(classes[i])\n","1726b935":"def load_data(train_dir):\n    images = []\n    labels = []\n    size = 32,32\n    index = -1\n    for folder in os.listdir(train_dir):\n        index +=1\n        for image in os.listdir(train_dir + \"\/\" + folder):\n            temp_img = cv2.imread(train_dir + '\/' + folder + '\/' + image)\n            temp_img = cv2.resize(temp_img, size)\n            images.append(temp_img)\n            labels.append(index)\n    \n    images = np.array(images)\n    images = images.astype('float32')\/255.0\n    labels = utils.to_categorical(labels)\n    x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.1)\n    \n    print('Loaded', len(x_train),'images for training,','Train data shape =', x_train.shape)\n    print('Loaded', len(x_test),'images for testing','Test data shape =', x_test.shape)\n    \n    return x_train, x_test, y_train, y_test\n\nstart = time()\nx_train, x_test, y_train, y_test = load_data(train_dir)\nprint('Loading:', time() - start)","f8a2223a":"import numpy as np\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.models import Model, load_model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nfrom keras.initializers import glorot_uniform\nimport scipy.misc\nfrom matplotlib.pyplot import imshow\n%matplotlib inline\n\nimport keras.backend as K\nK.set_image_data_format('channels_last')\nK.set_learning_phase(1)","05e3a228":"def identity_block(X, f, filters, stage, block):\n\n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value. You'll need this later to add back to the main path. \n    X_shortcut = X\n    \n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    \n    # Second component of main path (\u22483 lines)\n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path (\u22482 lines)\n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation (\u22482 lines)\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    \n    return X","c9b0a125":"def convolutional_block(X, f, filters, stage, block, s = 2):\n\n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n\n\n    ##### MAIN PATH #####\n    # First component of main path \n    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    # Second component of main path (\u22483 lines)\n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n\n    # Third component of main path (\u22482 lines)\n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n\n    ##### SHORTCUT PATH #### (\u22482 lines)\n    X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1',\n                        kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation (\u22482 lines)\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    \n    return X","6812a738":"model = ResNet50(input_shape = (64, 64, 3), classes = 29)","04a1dbcc":"def results(model):\n  adam = Adam(lr=learning_rate)\n\n  model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n\n  start = time()\n  history = model.fit(x_train, y_train, batch_size=batch, epochs=epochs, validation_split=0.1, shuffle = True, verbose=1)\n  train_time = time() - start\n\n  model.summary()\n\n  plt.figure(figsize=(12, 12))\n  plt.subplot(3, 2, 1)\n  plt.plot(history.history['accuracy'], label = 'train_accuracy')\n  plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n  plt.xlabel('epoch')\n  plt.ylabel('accuracy')\n  plt.legend()\n  plt.subplot(3, 2, 2)\n  plt.plot(history.history['loss'], label = 'train_loss')\n  plt.plot(history.history['val_loss'], label = 'val_loss')\n  plt.xlabel('epoch')\n  plt.ylabel('accuracy')\n  plt.legend()\n  plt.show()\n\n  start = time()\n  test_loss, test_acc = model.evaluate(x_test, y_test)\n  test_time = time() - start\n  print('\\nTrain time: ', train_time)\n  print('Test accuracy:', test_acc)\n  print('Test loss:', test_loss)\n  print('Test time: ', test_time)","bf34774d":"from keras.models import load_model\nmodel.save('ASl_ESI.h5')  \n\n","2045d0c3":"model='..\/input\/models\/ASl_ESI.h5'\nfrom tensorflow import keras\nmodel = keras.models.load_model(model)","228d1ea8":"model.summary()","f9f2d446":"import keras\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, Activation\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import regularizers","f414f31c":"weight_decay = 1e-4\nclasses = 29\nbatch = 128\nepochs = 3\nlearning_rate = 0.0001\n\nmodel = Sequential()\n\nmodel.add(Conv2D(128, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=(32,32,3)))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n \nmodel.add(Conv2D(128, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\n \nmodel.add(Conv2D(256, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n \nmodel.add(Flatten())\nmodel.add(Dense(128, activation=\"linear\"))\nmodel.add(Activation('elu'))\nmodel.add(Dense(29, activation='softmax'))","ff1caed1":"results(model)","9af54467":"import keras\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, Activation\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import regularizers\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization","3e24a5d3":"model = Sequential()\n    \nmodel.add(Conv2D(16, kernel_size = [3,3], padding = 'same', activation = 'relu', input_shape = (32,32,3)))\nmodel.add(Conv2D(32, kernel_size = [3,3], padding = 'same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size = [3,3]))\n    \nmodel.add(Conv2D(32, kernel_size = [3,3], padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(64, kernel_size = [3,3], padding = 'same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size = [3,3]))\n    \nmodel.add(Conv2D(128, kernel_size = [3,3], padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(256, kernel_size = [3,3], padding = 'same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size = [3,3]))\n    \nmodel.add(BatchNormalization())\n    \nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(512, activation = 'relu', kernel_regularizer = regularizers.l2(0.001)))\nmodel.add(Dense(29, activation = 'softmax'))\n    \nmodel.compile(optimizer = 'adam', loss = keras.losses.categorical_crossentropy, metrics = [\"accuracy\"])\n\n","79f441d9":"results(model)","44e9315a":"ASL RECOGNATION  KERBOUTE AMINE ESTAPE 2\n"}}