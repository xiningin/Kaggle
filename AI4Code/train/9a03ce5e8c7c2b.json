{"cell_type":{"f52de1b4":"code","c0980088":"code","05379600":"code","1326ee73":"code","fdbe4790":"code","0698ebc0":"code","62b98776":"code","f17fbe0a":"code","affbe415":"code","e2e092ba":"code","9fc76f9f":"code","05fd6923":"code","7a741d21":"code","23b13b5a":"code","ec7e56f3":"code","3a1c6414":"code","dc11ae7c":"code","3eb2f9ef":"code","fca51371":"code","abfc4c36":"code","173eb384":"code","f6dec21f":"code","00059bf9":"code","275e2178":"code","45c16558":"code","9b06767a":"code","0f8570f4":"code","5ec32523":"code","eb80f722":"code","54b9c3ce":"code","05b177b8":"code","fb9903a0":"code","52798517":"code","24305413":"markdown","e26a7e06":"markdown","632a2b92":"markdown"},"source":{"f52de1b4":"######### IMPORT ########\nimport pickle\nfrom itertools import cycle\nfrom time import time\nfrom tqdm.auto import tqdm\nimport shutil\nfrom pathlib import Path\n\n# Pandas, Numpy\nimport pandas as pd\nimport numpy as np\nfrom numpy import interp\nfrom matplotlib import pyplot as plt\npd.set_option(\"display.max_columns\", None)\n\n# Model evaluation\nfrom sklearn.metrics import plot_confusion_matrix, roc_auc_score,  auc, \\\n    precision_recall_fscore_support, classification_report, roc_curve, plot_roc_curve\n\n# Sklearn pipeline\nfrom sklearn.base import TransformerMixin, BaseEstimator\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn import set_config\nfrom sklearn.pipeline import Pipeline\nset_config(display = 'diagram')\n\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\n\nfrom catboost import CatBoostClassifier, CatBoostRegressor\n\nfrom sklearn.svm import SVR\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer","c0980088":"data_train = pd.read_csv('..\/input\/commonlitreadabilityprize\/train.csv')\ndata_test = pd.read_csv('..\/input\/commonlitreadabilityprize\/test.csv')\ndata_sample_submission = pd.read_csv('..\/input\/commonlitreadabilityprize\/sample_submission.csv')","05379600":"data_sample_submission","1326ee73":"data_train","fdbe4790":"data_test","0698ebc0":"data_train.describe(percentiles=[0.01, 0.05, 0.25, 0.75, 0.95, 0.99])","62b98776":"data_train['target'].hist(bins=30)","f17fbe0a":"data_train['standard_error'].hist(bins=30)","affbe415":"(data_train['target'] - data_train['standard_error']).hist(bins=30)","e2e092ba":"(data_train['target'] + data_train['standard_error']).hist(bins=30)","9fc76f9f":"data_test","05fd6923":"data_train['license'].value_counts()","7a741d21":"data_train['excerpt'][0]","23b13b5a":"######## SUPPORTING CLASSES ########\nclass PipelineLogger(object):\n    def __init__(self):\n        pass\n        \n    def log_start(self):\n        self.start_time = time()\n        print(f'======== {self.__class__.__name__} - START ========')\n        return None\n        \n    def log_finish(self):\n        self.duration = time() - self.start_time\n        print(f'======== {self.__class__.__name__} - FINISH =======> Take: {self.duration:.6f}(s)')\n\nclass featureUnion(FeatureUnion):\n    def _hstack(self, Xs):\n        cols = [X.columns.tolist() for X in Xs]\n        dtypes = []\n        for X in Xs:\n            dtypes.append([str(X[col].dtype) for col in X])\n        cols = np.hstack(cols)\n        dtypes = np.hstack(dtypes)\n        data = pd.DataFrame(super()._hstack(Xs), columns = cols)\n        print('====Converting columns types====')\n        for col, dtype in tqdm(zip(cols, dtypes)):\n            data[col] = data[col].astype(dtype)\n        return data\n\nclass columnTransformer(ColumnTransformer):\n    def _hstack(self, Xs):\n        cols = [X.columns.tolist() for X in Xs]\n        dtypes = []\n        for X in Xs:\n            dtypes.append([str(X[col].dtype) for col in X])\n        cols = np.hstack(cols)\n        dtypes = np.hstack(dtypes)\n        data = pd.DataFrame(super()._hstack(Xs), columns = cols)\n        print('====Converting columns types====')\n        for col, dtype in tqdm(zip(cols, dtypes)):\n            data[col] = data[col].astype(dtype)\n        return data\n\nclass ExperimentBase(BaseEstimator):\n    def evaluate(self, X_test, y_test):\n        print('Evaluating model')\n        print(classification_report(y_true=y_test, y_pred=self.predict(X_test)))\n        metrics = self.auc_report(X_test, y_test)\n        metrics['precision'], metrics['recall'], metrics['f1_score'], metrics['support'] = precision_recall_fscore_support(y_test, self.predict(X_test))\n        return metrics\n    \n    def auc_report(self, X, y_true):\n        classes = self.classes_\n        y_pred_classes = self.predict_proba(X)\n        n_classes = len(classes)\n\n        lw = 2\n        for i in range(len(classes)):\n            print(f\"\"\"{classes[i]}: {roc_auc_score(y_true=(y_true==classes[i]).astype(int), y_score=y_pred_classes[:,i])}\"\"\")\n\n        # Compute ROC curve and ROC area for each class\n        fpr = dict()\n        tpr = dict()\n        roc_auc = dict()\n\n        for i in range(n_classes):\n            fpr[i], tpr[i], _ = roc_curve(y_true=(y_true==classes[i]).astype(int), y_score=y_pred_classes[:,i])\n            roc_auc[i] = auc(fpr[i], tpr[i])\n\n        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(len(classes))]))\n\n        # Then interpolate all ROC curves at this points\n        mean_tpr = np.zeros_like(all_fpr)\n        for i in range(len(classes)):\n            mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n        # Finally average it and compute AUC\n        mean_tpr \/= n_classes\n\n        fpr[\"macro\"] = all_fpr\n        tpr[\"macro\"] = mean_tpr\n        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n        # Plot all ROC curves\n        plt.figure()\n\n        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n                 label='macro-average ROC curve (area = {0:0.2f})'\n                       ''.format(roc_auc[\"macro\"]),\n                 color='navy', linestyle=':', linewidth=4)\n\n        colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n        for i, color in zip(range(n_classes), colors):\n            plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n                     label='ROC curve of class {0} (area = {1:0.2f})'\n                     ''.format(classes[i], roc_auc[i]))\n\n        plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Some extension of Receiver operating characteristic to multi-class')\n        plt.legend(loc=\"lower right\")\n        plt.show()\n        metrics = {\n            'macro_auc': roc_auc[\"macro\"]\n        }\n        for i in range(n_classes):\n            metrics[f'auc_{classes[i]}'] = roc_auc[i]\n        return metrics\n    \nclass simpleImputer(SimpleImputer):\n    def fit(self, X, y=None):\n        self._cols = X.columns.tolist()\n        self._dtypes = [str(X[col].dtype) for col in X.columns]\n        super().fit(X, y)\n        return self\n        \n    def transform(self, X):\n        X_ = super().transform(X)\n        data = pd.DataFrame(X_, columns = self._cols)\n        for col, dtype in tqdm(zip(self._cols, self._dtypes)):\n            data[col] = data[col].astype(dtype)\n        return data\n######## DONE SUPPORTING CLASSES ########","ec7e56f3":"('max_imputor', simpleImputer(strategy='constant', fill_value='unk'))","3a1c6414":"class TextLowerer(BaseEstimator, TransformerMixin, PipelineLogger):\n    def __init__(self, columns):\n        super().__init__()\n        self.columns = columns\n        \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        X_ = X[self.columns].copy()\n        for c in X_.columns:\n            X_[c] = X_[c].apply(lambda x: x.lower())\n        return X_\n\nclass TextSpliter(BaseEstimator, TransformerMixin, PipelineLogger):\n    def __init__(self, columns, spliters):\n        super().__init__()\n        self.spliters = spliters\n        self.columns = columns\n        \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        X_ = X[self.columns].copy()\n        for col in self.columns:\n            X_[col] = X_[col].str.replace(pat='(:|\/|_|-)',repl=' ', regex=True)\n        return X_\n    \nclass PassThroughExcept(BaseEstimator, TransformerMixin, PipelineLogger):\n    def __init__(self, col_except_func):\n        super().__init__()\n        self.col_except_func = col_except_func\n        \n    def fit(self, X, y=None):\n        self.except_cols = self.col_except_func(X)\n        return self\n    \n    def transform(self, X):\n        self.log_start()\n        X_ = X[[c for c in X.columns if c not in self.except_cols]]\n        self.log_finish()\n        return X_","dc11ae7c":"data_train","3eb2f9ef":"data_train['url_legal'].str.replace(pat='(:|\/|_|-)',repl=' ', regex=True)","fca51371":"pd.Series(dtype='object')","abfc4c36":"class TextCombinator(BaseEstimator, TransformerMixin, PipelineLogger):\n    def fit(self, X, y=None):\n        self.cols = X.columns.to_list()\n        return self\n    \n    def transform(self, X):\n        X_ = X.copy()\n        X_['comb_text'] = ''\n        for c in self.cols:\n            X_['comb_text'] += ' ' + X[c]\n        return X_['comb_text']","173eb384":"SVR()","f6dec21f":"pl_preprocess = Pipeline(steps=[\n    ('unk_imputing', simpleImputer(strategy='constant', fill_value='unk')),\n    ('text_lowering', TextLowerer(columns=['url_legal', 'license', 'excerpt'])),\n    ('feature_processing', featureUnion(transformer_list=[\n        ('text_spliting', TextSpliter(columns=['url_legal', 'license'], spliters=[':', '\/', '_', '-'])),\n        ('pass_through', PassThroughExcept(col_except_func=lambda X: [c for c in X.columns if c in ['url_legal', 'license']]))\n    ])),\n    ('combine_text', TextCombinator()),\n    ('vect', CountVectorizer(ngram_range=(1,1), max_df=0.9, max_features=None)), \n    ('tfidf', TfidfTransformer()),\n    ('clf', SVR(kernel= \"rbf\",gamma='scale',C=2))\n    \n])","00059bf9":"pl_preprocess","275e2178":"pl_preprocess.fit(data_train.drop(columns=['target', 'standard_error']), data_train.target)","45c16558":"data_train","9b06767a":"data_test","0f8570f4":"data_test_copy = data_test.copy()\ndata_test_copy['target'] = pl_preprocess.predict(data_test)","5ec32523":"data_test_copy","eb80f722":"data_test_copy[['id', 'target']].to_csv('submission.csv',index=False)","54b9c3ce":"data_train_copy = data_train.copy()\ndata_train_copy['pred'] = pl_preprocess.predict(data_train.drop(columns=['target', 'standard_error']))","05b177b8":"\ndata_train_copy","fb9903a0":"from sklearn.metrics import mean_squared_error","52798517":"mean_squared_error(data_train_copy['target'], data_train_copy['pred'], squared=False)","24305413":"## Explore","e26a7e06":"## Build pipeline process","632a2b92":"Train's rmse ~ 0.269 is much much lower than submission score (~ 0.750)\n\n=> Could be overfitting"}}