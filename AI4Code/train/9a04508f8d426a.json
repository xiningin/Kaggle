{"cell_type":{"c1a15531":"code","267c4bcf":"code","8397d726":"code","9a221bd7":"code","c9441470":"code","c8e2b7e8":"code","8ca36fe0":"code","93968c95":"code","f7ce8193":"code","d098d72a":"code","153d9d59":"code","db75705c":"code","91b66f73":"code","dd3623cb":"code","cc05adfd":"code","52131208":"code","b7a82532":"code","1f51ee3a":"code","96029000":"code","eb3f02e7":"code","2544a163":"code","937cd7eb":"code","2603e2e9":"code","90f27c4b":"code","acd77009":"code","9199da21":"markdown"},"source":{"c1a15531":"!pip install -q efficientnet","267c4bcf":"import os\n\nfrom numpy.random import seed\nseed(101)\n\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nimport efficientnet.tfkeras as efn \n\nfrom sklearn.metrics import confusion_matrix\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nprint(\"Running TensorflowVersion: \" + str(tf.__version__))","8397d726":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\nexcept ValueError:\n    tpu = None\n    gpus = tf.config.experimental.list_logical_devices('GPU')\n\n#Select appropriate distribution strategy for hardware\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    print(\"Running on TPU: \" + str(tpu.master()))\nelif len(gpus) > 0:\n    strategy = tf.distribute.MirroredStrategy(gpus)\n    print(\"Running on \",len(gpus),\" GPU(s)\")\nelse:\n    strategy = tf.distribute.get_strategy()\n    print(\"Running on CPU\")","9a221bd7":"train_path = \"\/kaggle\/input\/100-bird-species\/train\"\nval_path = \"\/kaggle\/input\/100-bird-species\/valid\"\ntest_path = \"\/kaggle\/input\/100-bird-species\/test\"\n\ntrain_images = [image for dir,_,sublist in os.walk(\"\/kaggle\/input\/100-bird-species\/train\") for image in sublist]\nval_images = [image for dir,_,sublist in os.walk(\"\/kaggle\/input\/100-bird-species\/valid\") for image in sublist]\ntest_images = [image for dir,_,sublist in os.walk(\"\/kaggle\/input\/100-bird-species\/test\") for image in sublist]\nnum_train_images = len(train_images)\nnum_val_images = len(val_images)\nnum_test_images = len(test_images)\n\nIMAGE_SIZE = 224\nEPOCHS = 10\n\n#CLASSES = ['Antelope','Bat','Beaver','Bobcat','Buffalo','Chihuahua','Chimpanzee','Collie','Dalmatian','German Shepherd',\n#           'Grizzly Bear','Hippopotamus','Horse','Killer Whale','Mole','Moose','Mouse','Otter','Ox','Persian Cat','Raccoon',\n#           'Rat','Rhinoceros','Seal','Siamese Cat','Spider Monkey','Squirrel','Walrus','Weasel','Wolf']\n\n#Learning rate scheduling variables\nnum_units = strategy.num_replicas_in_sync\nif num_units == 8:\n    BATCH_SIZE = 16 * num_units\n    VALIDATION_BATCH_SIZE = 16 * num_units\n    start_lr = 0.00001\n    min_lr = 0.00001\n    max_lr = 0.00005 * num_units\n    rampup_epochs = 8\n    sustain_epochs = 0\n    exp_decay = 0.8\nelif num_units == 1:\n    BATCH_SIZE = 16\n    VALIDATION_BATCH_SIZE = 16\n    start_lr = 0.00001\n    min_lr = 0.00001\n    max_lr = 0.0002\n    rampup_epochs = 8\n    sustain_epochs = 0\n    exp_decay = 0.8\nelse:\n    BATCH_SIZE = 8 * num_units\n    VALIDATION_BATCH_SIZE = 8 * num_units\n    start_lr = 0.00001\n    min_lr = 0.00001\n    max_lr = 0.00002 * num_units\n    rampup_epochs = 11\n    sustain_epochs = 0\n    exp_decay = 0.8\n    \ntrain_steps = int(np.ceil(num_train_images\/BATCH_SIZE))\nval_steps = int(np.ceil(num_val_images\/VALIDATION_BATCH_SIZE))\n\nprint(\"Total Training Images: \" + str(num_train_images))\nprint(\"Total Validation Images: \" + str(num_val_images))\nprint(\"Total Test Images: \" + str(num_test_images))\n\nprint(\"Train Steps: \" + str(train_steps))\nprint(\"Val steps: \" + str(val_steps))","c9441470":"def display_training_curves(training,validation,title,subplot):\n    if subplot%10 == 1:\n        plt.subplots(figsize = (10,10),facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])\n    \ndef learningrate_function(epoch):\n    if epoch < rampup_epochs:\n        lr = (max_lr - start_lr)\/rampup_epochs * epoch + start_lr\n    elif epoch < rampup_epochs + sustain_epochs:\n        lr = max_lr\n    else:\n        lr = (max_lr - min_lr) * exp_decay**(epoch - rampup_epochs - sustain_epochs) + min_lr\n    return lr\n\ndef learning_rate_callback():\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch : learningrate_function(epoch),verbose = True)\n    rng = [i for i in range(EPOCHS)]\n    y = [learningrate_function(x) for x in range(EPOCHS)]\n    plt.plot(rng,y)\n    return lr_callback","c8e2b7e8":"datagen = ImageDataGenerator(rescale = 1.0\/255)\n\ntrain_datagen = datagen.flow_from_directory(train_path, \n                                            target_size = (IMAGE_SIZE,IMAGE_SIZE),\n                                            batch_size = BATCH_SIZE, \n                                            class_mode = 'categorical')\n\nval_datagen = datagen.flow_from_directory(val_path,\n                                          target_size = (IMAGE_SIZE,IMAGE_SIZE),\n                                          batch_size = VALIDATION_BATCH_SIZE,\n                                          class_mode = 'categorical')\n\ntest_datagen = datagen.flow_from_directory(val_path,\n                                            target_size = (IMAGE_SIZE,IMAGE_SIZE),\n                                            batch_size = 1, \n                                            class_mode = 'categorical',\n                                            shuffle = False)","8ca36fe0":"CLASSES = list(train_datagen.class_indices.keys())","93968c95":"len(CLASSES)","f7ce8193":"with strategy.scope():\n    enet = efn.EfficientNetB0(\n    input_shape = (IMAGE_SIZE,IMAGE_SIZE,3),\n    weights = 'imagenet',\n    include_top = False)\n    enet.trainable = True\n    \n    model = Sequential([\n        enet,\n        GlobalAveragePooling2D(),\n        Dense(200, activation = 'softmax', dtype= tf.float32)\n    ])\n    \n    model.compile(\n    optimizer = 'adam',\n    loss = 'categorical_crossentropy',\n    metrics = ['accuracy']\n    )\n    \nmodel.summary()","d098d72a":"lr_callback = learning_rate_callback()","153d9d59":"filepath = \"my_model_bird.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\ncallbacks_list = [checkpoint,lr_callback]\n\nhist = model.fit_generator(train_datagen,\n                             steps_per_epoch = train_steps,\n                             validation_data = val_datagen,\n                             validation_steps = val_steps,\n                             epochs = EPOCHS,\n                             verbose = 1,\n                             callbacks = callbacks_list)","db75705c":"model.save(\"my_model_bird_manual.h5\")","91b66f73":"model = load_model(\"my_model_bird.hdf5\")\nmodel.summary()","dd3623cb":"val_loss, val_acc = model.evaluate_generator(val_datagen,steps = num_val_images)\n\nprint('val_loss:', val_loss)\nprint('val_acc:', val_acc)","cc05adfd":"display_training_curves(hist.history['loss'], hist.history['val_loss'], 'loss', 211) \ndisplay_training_curves(hist.history['accuracy'], hist.history['val_accuracy'], 'accuracy', 212)","52131208":"print(val_datagen.classes)","b7a82532":"predictions = model.predict_generator(test_datagen, steps= num_val_images, verbose=1)","1f51ee3a":"predictions.shape","96029000":"predictions.argmax(axis=1)","eb3f02e7":"df_preds = pd.DataFrame(predictions,columns=CLASSES)","2544a163":"df_preds.head()","937cd7eb":"y_true = val_datagen.classes\ny_pred = df_preds['ALBATROSS']\nprint(y_true)\nprint(y_pred)","2603e2e9":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","90f27c4b":"val_labels = val_datagen.classes\n\ncm = confusion_matrix(val_labels, predictions.argmax(axis=1))\n\ncm_plot_labels = CLASSES\n\nplot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')","acd77009":"from sklearn.metrics import classification_report\n\n# Generate a classification report\n\n# For this to work we need y_pred as binary labels not as probabilities\ny_pred_binary = predictions.argmax(axis=1)\n\nreport = classification_report(y_true, y_pred_binary, target_names=cm_plot_labels)\n\nprint(report)","9199da21":"#Visualizing training curves\ndisplay_training_curves(hist.history['loss'], hist.history['val_loss'], 'loss', 211)\ndisplay_training_curves(hist.history['accuracy'], hist.history['val_accuracy'], 'accuracy', 212)"}}