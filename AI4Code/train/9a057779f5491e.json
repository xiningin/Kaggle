{"cell_type":{"0d17c92b":"code","00856d12":"code","b96ca3a4":"code","f589ed58":"code","aba8c5fd":"code","abe93903":"code","ed9a2593":"code","d5fa35c0":"code","0a32951d":"code","a0339c32":"code","6d8077cc":"code","699c74ee":"code","9c123dbf":"code","e80b90a4":"code","11c9696e":"code","27b87a4b":"code","d97f88cc":"code","a960281d":"code","58b31ea7":"code","7f96fb87":"code","5ece36cc":"code","4c71e447":"code","67108ff8":"code","f9b0698f":"markdown","76abe273":"markdown","b5b01b14":"markdown","e337f4a9":"markdown"},"source":{"0d17c92b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","00856d12":"# import the necessary libraries\nimport numpy as np \nimport pandas as pd \nimport os\n\n# Visualisation libraries\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\n\nfrom sklearn.ensemble import VotingClassifier,RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom catboost import CatBoostClassifier\nfrom sklearn.preprocessing import LabelEncoder\n\n# Disable warnings \nimport warnings\nwarnings.filterwarnings('ignore')\n","b96ca3a4":"train_df = pd.read_csv('\/kaggle\/input\/janatahack-healthcare-analytics-ii\/Train_hMYJ020\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/janatahack-healthcare-analytics-ii\/Test_ND2Q3bm\/test.csv')\nsub_df = pd.read_csv('\/kaggle\/input\/janatahack-healthcare-analytics-ii\/sample_submission_lfbv3c3.csv')\n\n\n#Training data\nprint('Training data shape: ', train_df.shape)\ntrain_df.head(5)","f589ed58":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","aba8c5fd":"train_df = reduce_mem_usage(train_df)\ntest_df = reduce_mem_usage(test_df)","abe93903":"print(train_df.shape, test_df.shape)","ed9a2593":"# * join the datasets\ntrain_df['is_train']  = 1\ntest_df['Stay'] = -1\ntest_df['is_train'] = 0","d5fa35c0":"full_df = train_df.append(test_df)\nfull_df.head()","0a32951d":"full_df.isnull().sum()","a0339c32":"full_df.fillna('-999',inplace=True)","6d8077cc":"full_df.columns","699c74ee":"full_df.dtypes","9c123dbf":"cols = [ 'Hospital_type_code',\n       'Hospital_region_code', \n       'Department', 'Ward_Type', 'Ward_Facility_Code','City_Code_Patient',\n        'Type of Admission',\n       'Severity of Illness',  'Age', 'Bed Grade'\n       ]\nfor col in cols:\n    if full_df[col].dtype==object:\n        print(col)\n        lbl = LabelEncoder()\n        lbl.fit(list(full_df[col].values.astype('str')))\n        full_df[col] = lbl.transform(list(full_df[col].values.astype('str')))","e80b90a4":"train = full_df[full_df['is_train']==1]\ntest = full_df[full_df['is_train']==0]\nprint(train.shape, test.shape)\n\ntrain_df = train.copy()\ntest_df = test.copy()\ndel train, test","11c9696e":"#define X and y\nX = train_df.drop(['Stay', 'is_train', 'case_id', 'patientid'],axis = 1)\ny = train_df.Stay\ntest_X = test_df.drop(['Stay', 'is_train', 'case_id', 'patientid'],axis = 1)\n\nprint(X.columns)","27b87a4b":"X.head()","d97f88cc":"clf1 = LGBMClassifier(boosting_type='gbdt', learning_rate=0.1, n_estimators=500, \n                      min_child_samples=20, random_state=1994,  n_jobs=-1, silent=False)\nclf1.fit(X,y)\npred=clf1.predict(test_X)","a960281d":"pred","58b31ea7":"sub_df.head()","7f96fb87":"# Read the submission file\nsub_df['Stay']=pred\nsub_df.to_csv('lgb_submission.csv', index=False)","5ece36cc":"sub_df.head()","4c71e447":"sub_df['Stay'].value_counts()","67108ff8":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\nname = \"lgbm_submission.csv\"\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = name):  \n    csv = sub_df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n\n# create a link to download the dataframe\ncreate_download_link(sub_df)","f9b0698f":"### This should give you a score of 42.685 % on public LB","76abe273":"### 2. Read Data","b5b01b14":"##### Memory Optimization","e337f4a9":"### 1.Libraries"}}