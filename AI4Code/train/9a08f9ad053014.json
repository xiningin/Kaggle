{"cell_type":{"a60e8017":"code","6d8e0198":"code","e8b69c1d":"code","cda3db91":"code","dc4eaa94":"code","8cde83d2":"code","7ec56541":"code","4c28707e":"code","08b068f9":"code","35d55de1":"markdown","25f90e7f":"markdown","26840e34":"markdown","59427559":"markdown"},"source":{"a60e8017":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nkeras = tf.keras\n\nimport tensorflow_datasets as tfds\ntfds.disable_progress_bar()\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6d8e0198":"\n(raw_train, raw_validation, raw_test), metadata = tfds.load(\n    'cats_vs_dogs',\n    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n    with_info=True,\n    as_supervised=True,\n)\n\nget_label_name = metadata.features['label'].int2str  # creates a function object that we can use to get labels\n","e8b69c1d":"# display 2 images from the dataset\nfor image, label in raw_train.take(5):\n  plt.figure()\n  plt.imshow(image)\n  plt.title(get_label_name(label))\n  ","cda3db91":"IMG_SIZE = 160 # All images will be resized to 160x160\n\ndef format_example(image, label):\n  \"\"\"\n  returns an image that is reshaped to IMG_SIZE\n  \"\"\"\n  image = tf.cast(image, tf.float32)\n  image = (image\/127.5) - 1\n  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n  return image, label\n\ntrain = raw_train.map(format_example)\nvalidation = raw_validation.map(format_example)\ntest = raw_test.map(format_example)\n\nfor image, label in train.take(2):\n  plt.figure()\n  plt.imshow(image)\n  plt.title(get_label_name(label))\n  \nBATCH_SIZE = 32\nSHUFFLE_BUFFER_SIZE = 1000\n\ntrain_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\nvalidation_batches = validation.batch(BATCH_SIZE)\ntest_batches = test.batch(BATCH_SIZE)\n\nIMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n\n","dc4eaa94":"base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\n\nbase_model.summary()\n\nfor image, _ in train_batches.take(1):\n   pass\n\nfeature_batch = base_model(image)\nprint(feature_batch.shape)\n","8cde83d2":"\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\n\nbase_model.trainable = False\n\nbase_model.summary()\n\nglobal_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nprediction_layer = keras.layers.Dense(1)\n\nmodel = tf.keras.Sequential([\n  base_model,\n  global_average_layer,\n  prediction_layer\n])\n","7ec56541":"base_learning_rate = 0.0001\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\ninitial_epochs = 3\nvalidation_steps=20\n\nloss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)\n","4c28707e":"\nhistory = model.fit(train_batches,\n                    epochs=initial_epochs,\n                    validation_data=validation_batches)\n","08b068f9":"acc = history.history['accuracy']\nprint(acc)","35d55de1":"Training images!","25f90e7f":"Resizing and reformatting images","26840e34":"Creating a base model using MobileNet V2","59427559":"**Uploading data from tfds. Spliting the data manually into 80% training, 10% testing, 10% validation**"}}