{"cell_type":{"31566a91":"code","c3bfc98b":"code","2f11fd74":"code","3578ccfa":"code","430b564f":"code","77933485":"code","806fcefa":"code","43fb5888":"code","e6010baa":"code","f251269f":"code","cf6b7066":"markdown","770eeeec":"markdown","1985b1c1":"markdown","061cbdd6":"markdown","83483f8f":"markdown"},"source":{"31566a91":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nprint(os.listdir(\"..\/input\"))","c3bfc98b":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nprint('train shape:{}, test shape:{}'.format(train.shape,test.shape))","2f11fd74":"train.head(5)","3578ccfa":"train.info()","430b564f":"train_copy = train.copy()\nlabels = ['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']\ntrain_copy['positiveCount'] = train_copy[labels].sum(axis=1)\ntrain_copy['positiveCount'].value_counts()","77933485":"print('Label Cardinality:',train_copy.positiveCount.sum(axis=0)\/len(train_copy))","806fcefa":"ax = train_copy.positiveCount.value_counts().plot(kind='bar', rot=0);\nax.set_xlabel('Number of labels');\nax.set_ylabel('Number of comments');\nax.set_title('Number of labels each comment has');","43fb5888":"vectorizer = TfidfVectorizer(analyzer='word',\n                            stop_words='english',\n                            ngram_range=(1, 3),\n                            max_features=30000,\n                            sublinear_tf=True)\nX_train = vectorizer.fit_transform(train.comment_text)\nX_test = vectorizer.transform(test.comment_text)\nY_train = train[labels]","e6010baa":"submission = pd.DataFrame.from_dict({'id': test['id']})\n\nscores = []\n\nfor label in labels:\n    #build classifier\n    LR = LogisticRegression(solver='saga', n_jobs=-1, C=0.5)\n    \n    #compute cv score\n    cv_score = np.mean(cross_val_score(LR, X_train, Y_train[label], cv=3, n_jobs=-1, scoring='roc_auc'))\n    scores.append(cv_score)\n    print(\"CV score for class {} is {}\".format(label, cv_score))\n    \n    #re-learn & predict\n    LR.fit(X_train, Y_train[label])  \n    submission[label] = LR.predict_proba(X_test)[:, 1] #predict\n    \nprint(\"Average CV scores: {}\".format(np.mean(scores)))","f251269f":"submission.to_csv('submission_8-Tfidf_Ngram_LR.csv', index=False)","cf6b7066":"Let's start with something simple: Tf-idf + Logistic Regression","770eeeec":"------------------------------------------------------------------------------------------","1985b1c1":"* It seems like the dataset (i.e., train data) is quite sparse and has only 0.219952% of label cardinality.\n* Looking at the figure above, it shows us that total of 143346 comments have zero positive label (i.e., 0 for all predefined labels), which regarded as clean comments.\n* On the other hands, there are only 31 comments have six full positive labels (i.e., 1 for all predefined labels).","061cbdd6":"Let's check with the label cardinality","83483f8f":"Create Tf-idf features"}}