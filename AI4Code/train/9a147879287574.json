{"cell_type":{"b9549cab":"code","5d4e4657":"code","733d0593":"code","42badf7e":"code","e8bbf03b":"code","aa5f33f7":"code","46a2a904":"code","0e179bd7":"code","3f929648":"code","4ac1d61a":"code","d744d322":"code","a25ccaf2":"code","4c59aa5d":"code","f283fa76":"code","c2ef9175":"code","3f61e715":"code","21247242":"code","a738fc73":"code","75ccc5c5":"code","a420aa97":"code","506d791b":"code","c9d3b9bc":"code","77fcbfc2":"code","9360c73e":"code","a74753dc":"code","f45a02c4":"markdown","bc4c1453":"markdown","dea20329":"markdown","246d1eec":"markdown","5f9203d1":"markdown","c379d83e":"markdown","5f255afc":"markdown","8c95388a":"markdown","3c08be66":"markdown","9afae2fe":"markdown","99984421":"markdown","c8a626b4":"markdown","a172c6bd":"markdown","f0876810":"markdown","49cdf8dc":"markdown","44f58f4c":"markdown","14d97b6f":"markdown","efba20f8":"markdown","9963dead":"markdown","effb6b7d":"markdown","44771e7a":"markdown","44a06892":"markdown","5e1bab71":"markdown"},"source":{"b9549cab":"import gc\nimport warnings\nimport numpy as np\nimport pandas as pd\n# Sklearn imports\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nwarnings.simplefilter(action='ignore', category=FutureWarning)\ndf = pd.read_csv(\"..\/input\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndf.head(3)","5d4e4657":"df['TotalCharges'] = df['TotalCharges'].replace(\" \", 0).astype('float32')\ndf.drop(['customerID'],axis=1, inplace=True)","733d0593":"categorical_cols = [c for c in df.columns if df[c].dtype == 'object'\n                    or c == 'SeniorCitizen']\ndf_categorical = df[categorical_cols].copy()\nfor col in categorical_cols:\n    if df_categorical[col].nunique() == 2:\n        df_categorical[col], _ = pd.factorize(df_categorical[col])\n    else:\n        df_categorical = pd.get_dummies(df_categorical, columns=[col])\n\ndf_categorical.head(3)","42badf7e":"def distplot(feature, frame, color='g'):\n    plt.figure(figsize=(8,3))\n    plt.title(\"Distribution for {}\".format(feature))\n    ax = sns.distplot(frame[feature], color= color)\n\nnumerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\ndf[numerical_cols].describe()","e8bbf03b":"for feat in numerical_cols: distplot(feat, df)","aa5f33f7":"df_std = pd.DataFrame(StandardScaler().fit_transform(df[numerical_cols].astype('float64')),\n                       columns=numerical_cols)\nfor feat in numerical_cols: distplot(feat, df_std, color='gray')","46a2a904":"class Model():\n    def __init__(self, classifier, frame, metrics, fixed_params = {},\n                 test_size=0.2, random_seed=50):\n        self.estimator = classifier\n        self.seed = random_seed\n        self.metrics = metrics\n        self.hyperparameters = {}\n        self.fixed_params = fixed_params\n        self.fixed_params['random_state'] = random_seed\n        if classifier == KNeighborsClassifier:\n            del self.fixed_params['random_state']\n\n        # First divide data in learning set and final test set\n        self.train, self.test = train_test_split(frame, test_size=test_size, random_state= self.seed)\n        self.predictors = [c for c in self.train.columns if c not in ['customerID', 'Churn']]\n\n    def grid_search(self, fit_metric, params, num_folds=10):\n        \"\"\" Save the best params to self.hyperparameters. \"\"\"\n        print(self.fixed_params)\n        gs = GridSearchCV(self.estimator(**self.fixed_params), param_grid= params,\n                          scoring=self.metrics, cv=num_folds, refit= fit_metric)\n        gs.fit(self.train[self.predictors], self.train['Churn'])\n        self.hyperparameters = gs.best_params_\n        return [(m, gs.cv_results_['mean_test_{}'.format(m)][gs.best_index_]) for m in self.metrics]\n    \n    def train_and_evaluate_test(self):\n        \"\"\" Train classifier on the full train set and evaluate the performance on the test set. \"\"\"\n        params = {**self.hyperparameters, **self.fixed_params}\n        clf = self.estimator(**params).fit(self.train[self.predictors], self.train['Churn'])\n        y_pred = clf.predict(self.test[self.predictors])\n        y_prob = clf.predict_proba(self.test[self.predictors])[:, 1]\n        results = list()\n        for m in self.metrics:\n            if m == 'roc_auc':\n                # For calculating roc auc we need the probability of target==1\n                results.append((m, roc_auc_score(self.test['Churn'], y_prob)))\n            else:\n                # For the other metrics we can simply use the predicted label (0 or 1)\n                results.append((m, eval(\"{}_score\".format(m))(self.test['Churn'], y_pred)))\n        return results\n\ndef print_result(results, sufix = \"\"):\n    \"\"\" Function for printing the results nicely. \"\"\"\n    msg = \"\"\n    for result in results:\n        msg += \"| {}: {:.4f} \".format(result[0], result[1])\n    print(\"{}- {}\".format(msg, sufix))","0e179bd7":"df_processed = pd.concat([df_std, df_categorical], axis=1)\nmetrics = ['roc_auc', 'accuracy']","3f929648":"def logistic_regression(frame, grid):\n    logit = Model(LogisticRegression, frame, metrics)\n    print_result(logit.grid_search('roc_auc', grid), \"cross-validation\")\n    print_result(logit.train_and_evaluate_test(), \"test set\")\n    print(\"Best hyperparameters:\", logit.hyperparameters)\nlogistic_regression(df_processed, {'C': np.logspace(-4, 4, 100, base=10)})","4ac1d61a":"logit_grid = {'C': np.linspace(0.02, 3, 150)}\nlogistic_regression(df_processed, logit_grid)","d744d322":"# Grid-search following second reference suggestions\ndef svc_rbf(frame, grid):\n    rbf = Model(SVC, frame, metrics, fixed_params= {'kernel': 'rbf', 'probability': True})\n    print_result(rbf.grid_search('roc_auc', grid, num_folds=4), \"cross-validation\")\n    print_result(rbf.train_and_evaluate_test(), \"test set\")\n    print(\"Best hyperparameters:\", rbf.hyperparameters)\n\ngrid_rbf =  {'C': np.logspace(-4, 1, 10, base=2), 'gamma': np.logspace(-6, 2, 10, base=2)}\nsvc_rbf(df_processed, grid_rbf)","a25ccaf2":"def svc_linear(frame, grid):\n    linear = Model(SVC, frame, metrics, fixed_params={'kernel': 'linear', 'probability': True})\n    print_result(linear.grid_search('roc_auc', grid), \"cross-validation\")\n    print_result(linear.train_and_evaluate_test(), \"test set\")\n    print(\"Best hyperparameters:\", linear.hyperparameters)\nsvc_linear(df_processed, {'C': np.logspace(-4, 1, 100, base=10)})","4c59aa5d":"def svc_poly(frame, grid):\n    poly_svc = Model(SVC, frame, metrics, fixed_params={'kernel': 'poly', 'probability': True})\n    print_result(poly_svc.grid_search('roc_auc', grid), \"cross-validation\")\n    print_result(poly_svc.train_and_evaluate_test(), \"test set\")\n    print(\"Best hyperparameters:\", poly_svc.hyperparameters)\nsvc_poly(df_processed, {'C': np.logspace(-5, 1, 30, base=2), 'degree': [2, 3]})","f283fa76":"def knn_clf(frame, grid):\n    knn = Model(KNeighborsClassifier, frame, metrics)\n    print_result(knn.grid_search('roc_auc', grid), \"cross-validation\")\n    print_result(knn.train_and_evaluate_test(), \"test set\")\n    print(\"Best hyperparameters:\", knn.hyperparameters)\nknn_clf(df_processed, {'n_neighbors': [i for i in range(10, 50, 2)]})","c2ef9175":"# Remove Gender\nfeatures = ['gender']\ndf_processed.drop(features, axis=1, inplace=True)\nlogit = Model(LogisticRegression, df_processed, metrics)\nprint_result(logit.grid_search('roc_auc', logit_grid), \"cross-validation\")","3f61e715":"# Remove services with 'no internet' label\nfeatures = ['OnlineSecurity_No internet service', 'OnlineBackup_No internet service',\n           'DeviceProtection_No internet service', 'TechSupport_No internet service',\n           'StreamingTV_No internet service', 'StreamingMovies_No internet service']\ndf_processed.drop(features, axis=1, inplace=True)\nlogit = Model(LogisticRegression, df_processed, metrics)\nprint_result(logit.grid_search('roc_auc', logit_grid), \"cross-validation\")","21247242":"# Additional services 'No'\nfeatures = ['OnlineSecurity_No', 'OnlineBackup_No',\n           'DeviceProtection_No', 'TechSupport_No',\n           'StreamingTV_No', 'StreamingMovies_No']\ndf_processed.drop(features, axis=1, inplace=True)\nlogit = Model(LogisticRegression, df_processed, metrics)\nprint_result(logit.grid_search('roc_auc', logit_grid), \"cross-validation\")","a738fc73":"# Remove PhoneService as MultipleLines has a 'No phone service' label\nfeatures = ['PhoneService']\ndf_processed.drop(features, axis=1, inplace=True)\nlogit = Model(LogisticRegression, df_processed, metrics)\nprint_result(logit.grid_search('roc_auc', logit_grid), \"cross-validation\")","75ccc5c5":"print(\"Data shape: \", df_processed.shape)\nprint(\"Best hyperparameters:\", logit.hyperparameters)\nprint_result(logit.train_and_evaluate_test(), \"test set\")","a420aa97":"def add_polynomial_features(frame, poly_degree=2, interaction=False):\n    # Generate polynomials for the three numerical features\n    poly = PolynomialFeatures(degree=poly_degree, interaction_only=interaction, include_bias=False)\n    poly_features = poly.fit_transform(frame[['tenure', 'MonthlyCharges', 'TotalCharges']])\n    # Convert to dataframe and drop the repeated columns\n    df_poly = pd.DataFrame(poly_features, columns=poly.get_feature_names())\n    return pd.concat([frame, df_poly.drop(['x0', 'x1', 'x2'], axis=1)], axis=1)\n\n# Let's try a few different options for polynomial features\nfor degree in range(2, 6):\n    for interaction in [True, False]:\n        df_poly = add_polynomial_features(df_processed, degree, interaction)\n        print(\"Degree: {}, interaction only: {}, data shape: {}\"\n              .format(degree, interaction, df_poly.shape))\n        logit = Model(LogisticRegression, df_poly, metrics)\n        print_result(logit.grid_search('roc_auc', logit_grid), \"cross-validation\")\n        del df_poly; gc.collect()","506d791b":"df_processed = add_polynomial_features(df_processed, 3, False)\nlogit = Model(LogisticRegression, df_processed, metrics)\nprint_result(logit.grid_search('roc_auc', logit_grid), \"cross-validation\")\nprint_result(logit.train_and_evaluate_test(), \"test set\")","c9d3b9bc":"# Difference between TotalCharges and the tenure multiplied by monthly charges\ndf_tmp = df_processed.copy()\ndf_tmp['charges_difference'] = df_tmp['TotalCharges'] - df_tmp['tenure']*df_tmp['MonthlyCharges']\nlogit = Model(LogisticRegression, df_tmp, metrics)\nprint_result(logit.grid_search('roc_auc', logit_grid), \"cross-validation\")\n\n# Just tenure multiplied by monthly charges\ndf_tmp = df_processed.copy()\ndf_tmp['tenure*charges'] = df_tmp['tenure']*df_tmp['MonthlyCharges']\nlogit = Model(LogisticRegression, df_tmp, metrics)\nprint_result(logit.grid_search('roc_auc', logit_grid), \"cross-validation\")\n\n# Ratio between the tenure multiplied by monthly charges and TotalCharges\ndf_tmp = df_processed.copy()\ndf_tmp['charges_ratio'] = df_tmp['tenure']*df_tmp['MonthlyCharges'] \/ (df_tmp['TotalCharges'] + 1)\nlogit = Model(LogisticRegression, df_tmp, metrics)\nprint_result(logit.grid_search('roc_auc', logit_grid), \"cross-validation\")","77fcbfc2":"# add feature\ndf_processed['charges_ratio'] = df_processed['tenure']*df_processed['MonthlyCharges'] \/ (df_processed['TotalCharges'] + 1)\nlogit = Model(LogisticRegression, df_processed, metrics)\nprint_result(logit.grid_search('roc_auc', logit_grid), \"cross-validation\")\nprint_result(logit.train_and_evaluate_test(), \"test set\")","9360c73e":"def group_and_merge(group, features):\n    df_tmp = df_processed.copy()\n    # Add the original column without ohe or transformations\n    group_col = group + \"_copy\"\n    df_tmp[group_col] = df[group].copy()\n    # Group by the original column\n    gp = df_tmp.groupby(group_col)[features].agg(['min', 'max', 'mean'])\n    gp.columns = pd.Index(['{}_{}'.format(e[0], e[1]) for e in gp.columns.tolist()])\n    # Merge with our dataframe and drop the copy column\n    df_tmp = df_tmp.merge(gp.reset_index(), on=group_col, how='left')\n    return df_tmp.drop([group_col], axis=1)\n\n# Groups\nfor group in ['tenure', 'Contract', 'PaymentMethod', 'InternetService', 'MultipleLines']:\n    if group == 'tenure':\n        df_tmp = group_and_merge(group, ['MonthlyCharges', 'TotalCharges'])\n    else:\n        df_tmp = group_and_merge(group, ['tenure', 'MonthlyCharges', 'TotalCharges'])\n    logit = Model(LogisticRegression, df_tmp, metrics)\n    print_result(logit.grid_search('roc_auc', logit_grid), \"cross-validation\")","a74753dc":"df_processed = group_and_merge('tenure', ['MonthlyCharges', 'TotalCharges'])\ndf_processed = group_and_merge('Contract', ['tenure', 'MonthlyCharges', 'TotalCharges'])\nlogistic_regression(df_processed, logit_grid)","f45a02c4":"Let's try to add the first and the third group of features:","bc4c1453":"<h3>1.1 Impute missing values<\/h3>\n\nThere are eleven missing values in TotalCharges for some of the customers with zero tenure. We can impute these values with zero as these customers probably haven't paied any bills yet. We can also drop the customerID, since we already have the pandas numerical index.","dea20329":"<h3>2.2 Feature scalling<\/h3>\n\nThere are three numerical columns with the following distributions:","246d1eec":"Finally, let's evaluate our model on the test set:","5f9203d1":"<h3>5.1 Removing features<\/h3>\n\nMany features might be useless or noisy and removing them might result in better scores and also speed up the training. I will try to remove some features based on data visualization, correlation, feature importance ([from this kernel](https:\/\/www.kaggle.com\/jsaguiar\/exploratory-analysis-with-seaborn)) and also business perspective. If you have any suggestions please leave a comment.\n\nLogistic regression will be used to test new features as it is faster and has a solid score. For each new group of features the hyperparameters will be tunned again.","c379d83e":"<h3>2.1 Categorical features<\/h3>\n\n\nThe dataset has 16 categorical columns and six of them have binary values (yes or no). The approach used here is:\n* In binary columns, just replace values with 1 and 0\n* Create a new column for each value in the remaining columns (and assign 1 or 0)\n\nThis is equivalent to one-hot-encode, but we avoid some extra columns for yes and no features.","5f255afc":"<h2>4. Testing models<\/h2>\n\nNow we can use our simple class to test both models:","8c95388a":"<b>Metrics<\/b>\n\nAs stated in the introduction, two metrics will be used to evaluate our models: \n1. Accuracy\n2. Area under the Receiver operating characteristic curve\n\nAccuracy is just how many predictions we got right divided by the total number of examples. It might not be the best metric here since we have an imbalanced dataset: if you predict every example as zero you get 73% accuracy. The [ROC AUC](https:\/\/en.wikipedia.org\/wiki\/Receiver_operating_characteristic) is the area under the curve when plotting the (normalized) true positive rate (x-axis) and the false positive rate (y-axis). For a complete description: [Google Crash Course](https:\/\/developers.google.com\/machine-learning\/crash-course\/classification\/roc-and-auc) \n\nOur main metric for optimization will be the ROC AUC score, though we will also check how accuracy is doing.","3c08be66":"<h3>4.3 Nearest Neighbors Classifier<\/h3>\n\nNow let's try KNN with Eucliean distance","9afae2fe":"<h3>4.2 Support vector machine<\/h3>\n\nSupport vector machines are similar to logistic regression, but they use the concept of a largin margin separation and are more robust to outliers. For more details check the first reference.\n\nThe following kernels will be used with the support vector classifier: rbf, linear and polynomial (see the second refeerence).\n\n* [SVC Guide - CS Departament NTU](https:\/\/www.csie.ntu.edu.tw\/~cjlin\/papers\/guide\/guide.pdf)\n* [Sklearn Kernels](http:\/\/scikit-learn.org\/stable\/modules\/svm.html#svm-kernels)\n\n<b>RBF Kernel<\/b>\n\nLet's start with rbf (default kernel) and tunne the hyperparameters C and gamma.","99984421":"<h3>4.1 Logistic regression<\/h3>\n\nWe have just one hyperparameter here for regularization, which is implemented as the inverse of lambda. The grid_search will evaluate all combinations of hyperparameters and find the best set to use. We can start with a broad range of values and them try a more restricted grid.","c8a626b4":"<b>Linear kernel<\/b>\n\nFor the linear kernel we only need to tunne the regularization parameter. ","a172c6bd":"<h3>5.3 Manually created features<\/h3>\n\nAnother option is to try some manually created features, like mean charge, charge ratio and charges difference:","f0876810":"<h2>1. Introduction<\/h2>\n\nIn this notebook we will predict if a customer left the company in the last month (churn). Using the Sklearn library, three algorithms will be implemented: Logistic Regression, Support Vector Machine and Nearest Neighbors. This library also includes the preprocessing and metrics used here. Since our dataset has some imbalance, we need a more reliable metric than accuracy to measure our models. Therefore, the [area under the ROC curve](https:\/\/en.wikipedia.org\/wiki\/Receiver_operating_characteristic) will be our optimization objective, but we will also look at the accuracy at each experiment.","49cdf8dc":"<h3>5.2 Polynomial features<\/h3>","44f58f4c":"<b>Group features<\/b>\n\nGroup customers and get statistics about that group:","14d97b6f":"<h2>2. Preprocessing<\/h2>","efba20f8":"Let's add polynomial features with third degree:","9963dead":"<h2>5. Feature Engineering<\/h2>","effb6b7d":"<b>Polynomial Kernel<\/b>\n","44771e7a":"<h2>3. Cross-Validation<\/h2>\n\nIn order to test the efficiency of our classifier we need to split the data in a train and test set, so we can evaluate our model in data that it has never seen before. However,  when evaluating different features, transformations and hyperparameters for estimators there is a risk of overffiting on the test set. To solve this problem, yet another part of the dataset can be held out as a validation set, but we drastically reduce the number of samples which can be used for learning. \n\nAs we only have seven thousands samples, our solution needs a procedure called cross-validation for training and validation. After that, we can evaluate our final model on the test set. For more information about cross-validation check the [Sklearn reference](http:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html).\n\nLet's create a class that will use GridSearchCV and KFold to find the best hyperparameters and return the cross-validation score. The second method will also train the classifier with the best hyperparameters found and predict the test set.","44a06892":"<b>Standardization<\/b>\n\nI've tryed a few experiments using the raw numerical features, normalization and standardization and found that the former yelds slightly better results. Altough we are not using gradient based optimization, the features have very distinct ranges and that can be detrimental to the model. I also think that the values are distributed over a long interval as we can see in the plots above, so restricting them to [0, 1] range with normalization is not the best approach.","5e1bab71":"Please leave a comment if you have any suggestions"}}