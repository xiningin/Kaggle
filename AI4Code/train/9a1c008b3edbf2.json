{"cell_type":{"f981c2fd":"code","36793755":"code","b1ae0cca":"code","7a8be514":"code","a72bfd7c":"code","ff69c232":"code","0ace2e53":"code","7bed16da":"code","32760b48":"code","c8008dc8":"code","f2b037c3":"code","eaf8fbc4":"code","5f056d0b":"code","4e1d10d5":"code","4333de34":"code","483ea23b":"code","b97cd3ca":"code","319e9100":"code","d8d7bdfa":"code","bb24f815":"code","7c0d47c1":"markdown","47c52376":"markdown","58373783":"markdown","8602bb28":"markdown","25da6e73":"markdown","dbb6ebfc":"markdown","46ddc201":"markdown","d8908fdd":"markdown","c561cecc":"markdown","aad9d8ca":"markdown","5230b6e7":"markdown","372fdf1f":"markdown","f483ec1f":"markdown","51d361d6":"markdown"},"source":{"f981c2fd":"!wget -O gold.parquet https:\/\/www.dropbox.com\/s\/3m0xqogz5gi2moy\/gold.parquet?dl=1","36793755":"!ls \/content","b1ae0cca":"import pandas as pd\n\nwork_dir = \"\/content\"\n\n#leitura dos dados de entrada\ndf_bruto = pd.read_parquet(work_dir +\"\/gold.parquet\", engine=\"pyarrow\")\ndf_bruto.shape","7a8be514":"df_bruto.info()","a72bfd7c":"# n\u00e3o iremos utilizar estas duas colunas no treinamento e no teste\ndf_preparado = df_bruto.drop(['key', 'timestamp'], axis=1)\n\n# iremos remover a feature ultima_compra, \n# mas fica como exerc\u00edcio voc\u00ea aproveit\u00e1-la no conjunto de features\ndf_preparado = df_preparado.drop(['ultima_compra'], axis=1)","ff69c232":"df_bruto","0ace2e53":"# Substitui valores nulos por 0 nas colunas num\u00e9ricas\ncolunas_numericas = ['pedidos_4_meses','pedidos_8_meses','pedidos_12_meses','itens_4_meses','itens_8_meses','itens_12_meses']\ndf_preparado[colunas_numericas] = df_preparado[colunas_numericas].fillna(value=0)\n\n# transformar colunas categ\u00f3ricas em num\u00e9ricas\ndf_preparado = pd.get_dummies(df_preparado, columns=[\"city\", \"state\", \"cnae_id\"])\ndf_preparado.head()","7bed16da":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# seleciona as tuplas com r\u00f3tulos\ndf_to_train = df_preparado[df_preparado[\"defaulting\"].notnull()]\n\n# remove a coluna defaulting dos dados de treinamento para n\u00e3o gerar overfiting\nX = df_to_train.drop('defaulting', axis=1)\n\n# Transforma a vari\u00e1vel a predizer de boolean para inteiro\nle = LabelEncoder()\ny = le.fit_transform(df_to_train.defaulting.values)\n\n# Divis\u00e3o em conjunto de treinamento e valida\u00e7\u00e3o\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1)\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_valid.shape)\nprint(y_valid.shape)","32760b48":"df_to_train.defaulting.values","c8008dc8":"y","f2b037c3":"X_valid","eaf8fbc4":"from sklearn.tree import DecisionTreeClassifier\n\n# Cria um classificador\nclf = DecisionTreeClassifier()\n\n# Treina a \u00c1rvore de Decis\u00e3o\nclf = clf.fit(X_train,y_train)\n\n# Prediz a resposta para o dataset de valida\u00e7\u00e3o\ny_pred = clf.predict(X_valid)","5f056d0b":"y_valid.shape","4e1d10d5":"y_pred.shape","4333de34":"import sklearn.metrics as metrics\nprint(\"ROC AUC:\",metrics.roc_auc_score(y_valid, y_pred))\nprint(\"Acur\u00e1cia:\",metrics.accuracy_score(y_valid, y_pred))\nprint(\"F1 score:\",metrics.f1_score(y_valid, y_pred))","483ea23b":"df_test = df_preparado[df_preparado[\"defaulting\"].isnull()]\ndf_test.shape","b97cd3ca":"X_test = df_test.drop('defaulting', axis=1)\ny_test = clf.predict(X_test)\ny_test","319e9100":"output = df_test.assign(inadimplente=y_test)\noutput = output.loc[:, ['client_id','inadimplente']]\noutput.head()","d8d7bdfa":"output.to_csv(work_dir +\"\/ouput_sklearn.csv\", index=False)","bb24f815":"from google.colab import files\nfiles.download('ouput_sklearn.csv') ","7c0d47c1":"## Preparando o ambiente\n\nO c\u00f3digo abaixo adiciona a **raiz** do projeto, que cont\u00e9m c\u00f3digos e dados necess\u00e1rios para o \"Hands on\".","47c52376":"O nosso *dataset* cont\u00e9m os dados de treinamento e de teste do nosso modelo. Aqui os dados de teste s\u00e3o aqueles que **n\u00e3o** possuem r\u00f3tulo e ser\u00e3o utilizados na solu\u00e7\u00e3o final. Dentro dos dados de treinamento (\"defaulting is not null\") vamos dividir nosso *dataset* entre dados de treinamento do modelo e dados de valida\u00e7\u00e3o, sendo 80% para o primeiro conjunto e 20% para o segundo. Queremos predizer o valor da coluna *defaulting*, mas ela \u00e9 do tipo boolean e deve ser transformada para o tipo inteiro para o nosso algoritmo de aprendizado de m\u00e1quina (\u00c1rvore de Decis\u00e3o) conseguir fazer a classifica\u00e7\u00e3o.","58373783":"O Dataframe *output* \u00e9 escrito no formato CSV para gerar a sa\u00edda do algoritmo de aprendizado de m\u00e1quina constru\u00eddo neste notebook.","8602bb28":"A sa\u00edda do modelo \u00e9 salvo em um arquivo csv, contendo as colunas \"client_id\" e \"inadimplente\". Estas colunas ser\u00e3o utilizadas para avaliar a acur\u00e1cia do modelo. Por isso, o resultado da predi\u00e7\u00e3o em *y_test* \u00e9 adicionada em uma nova coluna (inadimplente) do DataFrame df_test.","25da6e73":"## Classifica\u00e7\u00e3o utilizando Pandas e Scikit-learn\n\nNeste notebook iremos fazer a predizer os clientes inadimplentes utilizando a biblioteca [Scikit-learn](https:\/\/scikit-learn.org\/) e o Pandas. Iremos desenvolver, neste notebook, um modelo capaz de predizer se o cliente est\u00e1 ou n\u00e3o inadimplente, ou seja, uma tarefa de classifica\u00e7\u00e3o bin\u00e1ria.","dbb6ebfc":"## Considera\u00e7\u00f5es Finais\n\nAgora \u00e9 com **voc\u00ea**! Ainda existe muito espa\u00e7o para melhoria na acur\u00e1cia do modelo que desenvolvemos at\u00e9 agora. Utilize o material complementar abaixo para modificar este notebook e construir um algoritmo melhor.\n\n- [Curso de Aprendizado de M\u00e1quina de Stanford com Andrew Ng](https:\/\/www.coursera.org\/learn\/machine-learning)\n- [M\u00e3os \u00e0 Obra: Aprendizado de M\u00e1quina com Scikit-Learn & TensorFlow](https:\/\/www.amazon.com.br\/M%C3%A3os-Obra-Aprendizado-Scikit-Learn-TensorFlow\/dp\/8550803812)\n- [Introduction to Machine Learning with Python](https:\/\/www.amazon.com.br\/Introduction-Machine-Learning-Andreas-Mueller\/dp\/1449369413)\n- [Data Science do Zero](https:\/\/www.amazon.com.br\/Data-Science-zero-Joel-Grus\/dp\/857608998X)\n- [Customer Churn Classification Using Predictive Machine Learning Models](https:\/\/towardsdatascience.com\/customer-churn-classification-using-predictive-machine-learning-models-ab7ba165bf56)","46ddc201":"Os valores nulos das colunas num\u00e9ricas s\u00e3o substitu\u00eddos por zero.\nAs colunas \"city\", \"state\", \"cnae_id\" s\u00e3o transformadas para valores num\u00e9ricos utilizando a fun\u00e7\u00e3o [get_dummies](https:\/\/pandas.pydata.org\/pandas-docs\/version\/0.23.4\/generated\/pandas.get_dummies.html) do Pandas. Essa Engenharia de Features \u00e9 importante para que o classificador funcione corretamente.","d8908fdd":"## Treinamento e Avalia\u00e7\u00e3o do modelo\n\nNesta etapa iremos treinar o nosso classificador, neste caso uma [\u00e1rvore de decis\u00e3o](https:\/\/spark.apache.org\/docs\/2.4.6\/ml-classification-regression.html#decision-tree-classifier). Os dados de treinamento est\u00e3o armazenados em *X_train* (features) e *y_train* (r\u00f3tulo). A predi\u00e7\u00e3o \u00e9 realizada com os dados de treinamento em *X_valid*.","c561cecc":"Os dados de teste s\u00e3o gerados e armazenados em *X_test*, excluindo a coluna *defaulting* que desejamos predizer. O modelo faz a predi\u00e7\u00e3o e tem como sa\u00edda os valores da predi\u00e7\u00e3o em *y_test*.","aad9d8ca":"## Engenharia de Features\n\nEngenharia de Features \u00e9 o processo de usar o conhecimento de dom\u00ednio sobre os dados para criar *features* que fazem os algoritmos de aprendizado de m\u00e1quina funcionar da forma que esperamos. \n\nPrimeiramente, iremos remover do DataFrame as features que n\u00e3o iremos utilizar na classifica\u00e7\u00e3o. As features *key* e *timestamp* s\u00e3o removidas por n\u00e3o terem correla\u00e7\u00e3o com o fato do cliente estar ou n\u00e3o inadimplente. A vari\u00e1vel *ultima_compra* foi removida para ficar como exerc\u00edcio para voc\u00ea inclu\u00ed-la no conjunto de features.","5230b6e7":"## Leitura dos dados\n\nO trecho de c\u00f3digo abaixo cria uma vari\u00e1vel *work_dir*, que ir\u00e1 apontar para o caminho no sistema de arquivos onde est\u00e3o os dados de entrada e onde a sa\u00edda ser\u00e1 escrita. Como os dados de entrada est\u00e3o no formato Parquet, o Pandas ir\u00e1 utilizar o motor de leitura Pyarrow para conseguir ler este formato de dados e aumentar a performance de leitura e transforma\u00e7\u00f5es no DataFrame.","372fdf1f":"O esquema \u00e9 apresentado na linha abaixo, para que possamos visualizar o modelo de dados que iremos trabalhar.","f483ec1f":"## Predi\u00e7\u00e3o sobre os dados de testes\n\nNesta \u00faltima etapa, o modelo busca predizer se o cliente est\u00e1 ou n\u00e3o inadimplente sobre os dados de teste (coluna defaulting igual a nulo). Os dados de teste ficar\u00e3o armazenados no DataFrame *df_test*. ","51d361d6":"Para **avaliar** a acur\u00e1cia do modelo, o resultado da predi\u00e7\u00e3o *y_pred* \u00e9 comparado com o resultado esperado *y_valid* para gerar as m\u00e9tricas ROC, Acur\u00e1cia e F1."}}