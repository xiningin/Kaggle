{"cell_type":{"f886ee01":"code","a5033679":"code","ad086902":"code","66508376":"code","6d6c7db6":"code","dddec0e2":"code","8ad29732":"code","c8a5d34a":"code","b743a99c":"code","fd459bbc":"code","746c986e":"code","72874d61":"code","fadd0ac3":"code","441b2dd4":"code","20fb84e0":"code","497c82a9":"code","ff69b6e3":"code","19e8b1c4":"code","232b5fee":"code","af3f4f5d":"code","b721d344":"code","54a73406":"code","64f9f268":"code","0bc37a93":"code","ac6e0563":"code","5767d45c":"code","ea29c5e7":"code","541cefdc":"code","f60e8fc6":"code","ee952ef5":"code","4ade77bf":"code","fbff14a7":"code","6433b5d2":"code","02baa52c":"code","efbdeb01":"code","58603bca":"code","ae3bf574":"code","fa14ef79":"code","82088871":"code","664999f0":"code","de8dcb4b":"code","dc08b6e9":"code","bcd0d28a":"code","b8d67f2c":"code","31f52e46":"code","8a33241b":"code","b256f680":"code","13ebc1ff":"code","a545919d":"code","5e5af7c6":"code","dfc862eb":"code","6677a2a5":"code","633b2953":"code","f154112a":"code","d6ba8f0e":"code","89b6c4f7":"code","88307156":"code","09f0826f":"markdown","fc1d1016":"markdown","4e496981":"markdown","4f11fa48":"markdown","92562034":"markdown","7b509d05":"markdown","fa085eac":"markdown","1a9de430":"markdown","f696293b":"markdown","b84566e4":"markdown","9046d620":"markdown","f2eb0db8":"markdown","b8922cf0":"markdown","a71b14d6":"markdown","19cdb99d":"markdown","a58a0873":"markdown","7c0e01cc":"markdown","6ffa1308":"markdown","8a7f187d":"markdown","de68f387":"markdown","2bee0a79":"markdown","abc59a26":"markdown","48d7cf4a":"markdown","b42bc2db":"markdown","131cbe52":"markdown","e7e54747":"markdown","932e4b3a":"markdown","f35ef4e6":"markdown","c13cb19a":"markdown","2afd6968":"markdown","974f3a55":"markdown","09506f92":"markdown","3bc741ff":"markdown","704ce9d6":"markdown","0ccd4378":"markdown","72954b28":"markdown","b2bb4a5a":"markdown","1622dbb5":"markdown","7b9342e9":"markdown"},"source":{"f886ee01":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n# Imported Libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD\nimport matplotlib.patches as mpatches\nimport time\n\n# Classifier Libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nimport collections\n\n\n# Other Libraries\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom imblearn.pipeline import Pipeline as im_Pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.metrics import classification_report_imbalanced\nimport sklearn.metrics as metrics\nfrom collections import Counter\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport warnings\nwarnings.filterwarnings(\"ignore\")","a5033679":"df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')","ad086902":"print('K\u00edch th\u01b0\u1edbc: %d h\u00e0ng, %d c\u1ed9t' %df.shape)\nprint()\ndf.head()","66508376":"df.describe().T","6d6c7db6":"duplicated = df[df.duplicated()]\nduplicated","dddec0e2":"df.drop(duplicated.index, axis=0, inplace=True)\nprint('K\u00edch th\u01b0\u1edbc sau khi b\u1ecf h\u00e0ng l\u1eb7p: %d h\u00e0ng, %d c\u1ed9t' %df.shape)","8ad29732":"print(f'Output True n\u1ebfu c\u00f3 missing data: {df.isnull().any().any()}') ","c8a5d34a":"no_class_0 = df['Class'].value_counts()[0]\nno_class_1 = df['Class'].value_counts()[1]\nprint(f\"{no_class_0} giao d\u1ecbch b\u00ecnh th\u01b0\u1eddng chi\u1ebfm {round(no_class_0\/len(df) * 100,2)}% d\u1eef li\u1ec7u\")\nprint(f\"{no_class_1} giao d\u1ecbch gian l\u1eadn chi\u1ebfm {round(no_class_1\/len(df) * 100,2)}% d\u1eef li\u1ec7u\")","b743a99c":"sns.countplot('Class', data=df)\nplt.title('Ph\u00e2n b\u1ed1 lo\u1ea1i giao d\u1ecbch \\n (0: B\u00ecnh th\u01b0\u1eddng || 1: Gian l\u1eadn)', fontsize=14)","fd459bbc":"fig, ax = plt.subplots(ncols=5, nrows=6, figsize=(15,15), sharey='row')\nindex = 0\nax = ax.flatten()\n\nfor col in df.columns.values:\n    if col not in ['Time', 'Amount', 'Class']:\n        sns.distplot(df[col], ax=ax[index])\n        index += 1\nax[28].set_visible(False)\nax[29].set_visible(False)\nplt.tight_layout(pad=0.5, w_pad=1.0, h_pad=1.0)","746c986e":"fig, ax = plt.subplots(1, 2, figsize=(18,4))\n\namount_val = df['Amount'].values\ntime_val = df['Time'].values\n\nsns.distplot(amount_val, ax=ax[0], color='r')\nax[0].set_title('Distribution of Transaction Amount', fontsize=14)\nax[0].set_xlim([min(amount_val), max(amount_val)])\n\nsns.distplot(time_val, ax=ax[1], color='b')\nax[1].set_title('Distribution of Transaction Time', fontsize=14)\nax[1].set_xlim([min(time_val), max(time_val)])","72874d61":"fig, ax = plt.subplots(ncols=5, nrows=6, figsize=(15,15), sharey='row')\nindex = 0\nax = ax.flatten()\n\nfor col in df.columns:\n    if col not in ['Time', 'Amount', 'Class']:\n        sns.kdeplot(df.loc[df['Class'] == 0, col] , label = 'Class = 0', ax=ax[index])\n        sns.kdeplot(df.loc[df['Class'] == 1, col] , label = 'Class = 1', ax=ax[index])\n        index += 1\nax[0].legend()\nax[28].set_visible(False)\nax[29].set_visible(False)\nplt.tight_layout(pad=0.5, w_pad=1.0, h_pad=1.0)","fadd0ac3":"fig, ax = plt.subplots(1, 2, figsize=(18,4))\n\namount_val = df['Amount'].values\ntime_val = df['Time'].values\n\nsns.kdeplot(df.loc[df['Class'] == 0, 'Amount'] , label = 'Class = 0', ax=ax[0], linewidth=4)\nsns.kdeplot(df.loc[df['Class'] == 1, 'Amount'] , label = 'Class = 1', ax=ax[0], linewidth=4)\nax[0].legend()\nax[0].set_title('Distribution of Transaction Amount wrt Class', fontsize=14)\nax[0].set_xlim([min(amount_val), max(amount_val)])\n\nsns.kdeplot(df.loc[df['Class'] == 0, 'Time'] , label = 'Class = 0', ax=ax[1], linewidth=4)\nsns.kdeplot(df.loc[df['Class'] == 1, 'Time'] , label = 'Class = 1', ax=ax[1], linewidth=4)\nax[1].legend()\nax[1].set_title('Distribution of Transaction Time wrt Class', fontsize=14)\nax[1].set_xlim([min(time_val), max(time_val)])\nplt.show()","441b2dd4":"from sklearn.model_selection import train_test_split\n\nprint('No Frauds', round(df['Class'].value_counts()[0]\/len(df) * 100,3), '% of the dataset')\nprint('Frauds', round(df['Class'].value_counts()[1]\/len(df) * 100,3), '% of the dataset')\n\nX = df.copy()\n\nX_train = X.loc[X.Time < 100000]\nX_test = X.loc[X.Time >= 100000]\ny_train = X_train.pop('Class')\ny_test = X_test.pop('Class')","20fb84e0":"print('-' * 100)\n\nprint('Train-Test Ratio: \\n')\nprint('Train:', len(y_train)\/ (len(y_train)+len(y_test)))\nprint('Test:', len(y_test)\/ (len(y_train)+len(y_test)))","497c82a9":"train_unique_label, train_counts_label = np.unique(y_train.values, return_counts=True)\ntest_unique_label, test_counts_label = np.unique(y_test.values, return_counts=True)\nprint('-' * 100)\n\nprint('Label Distributions: \\n')\nprint(train_counts_label\/ len(y_train))\nprint(test_counts_label\/ len(y_test))","ff69b6e3":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom imblearn.under_sampling import RandomUnderSampler \n\npreprocessor = ColumnTransformer([('std_scaler', StandardScaler(), ['Time']),\n                           ('rob_scaler', RobustScaler(), ['Amount'])],\n                           remainder='passthrough')","19e8b1c4":"def fit_model_and_get_predictions(model, train_df, train_target, test_df):\n    \n    # Hu\u1ea5n luy\u1ec7n m\u00f4 h\u00ecnh tr\u00ean t\u1eadp c\u00e1c t\u1eadp train\n    start_time=time.time()\n    model.fit(train_df, train_target)\n    training_execution_time=time.time()-start_time\n\n    # L\u1ea5y k\u1ebft qu\u1ea3 d\u1ef1 \u0111o\u00e1n tr\u00ean t\u1eadp train v\u00e0 t\u1eadp test\n    # K\u1ebft qu\u1ea3 d\u1ef1 \u0111o\u00e1n l\u00e0 m\u1ed9t numpy array v\u1edbi c\u00e1c ph\u1ea7n t\u1eed l\u00e0 x\u00e1c su\u1ea5t m\u1ed9t giao d\u1ecbch l\u00e0 giao d\u1ecbch gian l\u1eadn\n    start_time = time.time()\n    predictions_test = model.predict_proba(test_df)[:,1]\n    prediction_execution_time = time.time() - start_time\n    \n    predictions_train = model.predict_proba(train_df)[:,1]\n\n    # Tr\u1ea3 v\u1ec1 dictionary ch\u1ee9a m\u00f4 h\u00ecnh \u0111\u00e3 \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n, c\u00e1c k\u1ebft qu\u1ea3 d\u1ef1 \u0111o\u00e1n v\u00e0 th\u1eddi gian ch\u1ea1y\n    model_and_predictions_dictionary = {'classifier': classifier,\n                                        'predictions_test': predictions_test,\n                                        'predictions_train': predictions_train,\n                                        'training_execution_time': training_execution_time,\n                                        'prediction_execution_time': prediction_execution_time\n                                       }\n    \n    return model_and_predictions_dictionary","232b5fee":"def performance_assessment(y_true, y_pred, rounded=True):\n    # L\u1ea5y 2 \u0111i\u1ec3m s\u1ed1 AUC ROC v\u00e0 Average Precision\n    AUC_ROC = metrics.roc_auc_score(y_true, y_pred)\n    AP = metrics.average_precision_score(y_true, y_pred)\n    \n    # T\u1ea1o m\u1ed9t DataFrame ch\u1ee9a c\u00e1c \u0111i\u1ec3m s\u1ed1\n    performances = pd.DataFrame([[AUC_ROC, AP]], \n                           columns=['AUC ROC','Average precision'])\n    \n    # L\u00e0m tr\u00f2n k\u1ebft qu\u1ea3\n    if rounded:\n        performances = performances.round(3)\n    \n    return performances","af3f4f5d":"def execution_times_model_collection(fitted_models_and_predictions_dictionary):\n\n    execution_times=pd.DataFrame() \n    \n    for classifier_name, model_and_predictions in fitted_models_and_predictions_dictionary.items():\n    \n        execution_times_model=pd.DataFrame() \n        execution_times_model['Training execution time']=[model_and_predictions['training_execution_time']]\n        execution_times_model['Prediction execution time']=[model_and_predictions['prediction_execution_time']]\n        execution_times_model.index=[classifier_name]\n        \n        execution_times=execution_times.append(execution_times_model)\n        \n    return execution_times","b721d344":"def performance_assessment_model_collection(fitted_models_and_predictions_dictionary, \n                                            type_set='test'):\n\n    performances=pd.DataFrame() \n    \n    for classifier_name, model_and_predictions in fitted_models_and_predictions_dictionary.items():\n        if type_set == 'test':\n            performances_model=performance_assessment(y_test,  model_and_predictions['predictions_test'])\n            performances_model.index=[classifier_name]\n        elif type_set == 'train':\n            performances_model=performance_assessment(y_train,  model_and_predictions['predictions_train'])\n            performances_model.index=[classifier_name]\n        else:\n            raise ValueError(\"invalid type_set\")\n                \n        performances=performances.append(performances_model)\n        \n    return performances","54a73406":"def execution_times_model_collection(fitted_models_and_predictions_dictionary):\n\n    execution_times=pd.DataFrame() \n    \n    for classifier_name, model_and_predictions in fitted_models_and_predictions_dictionary.items():\n    \n        execution_times_model=pd.DataFrame() \n        execution_times_model['Training execution time']=[model_and_predictions['training_execution_time']]\n        execution_times_model['Prediction execution time']=[model_and_predictions['prediction_execution_time']]\n        execution_times_model.index=[classifier_name]\n        \n        execution_times=execution_times.append(execution_times_model)\n        \n    return execution_times","64f9f268":"def kfold_score(X, y, model, scoring='average_precision'):\n    scores = cross_val_score(model, X, y, scoring=scoring)\n    return scores.mean()","0bc37a93":"import optuna","ac6e0563":"def objective(trial):\n    lr_params = dict(\n        penalty = trial.suggest_categorical('penalty', ['l1', 'l2']),\n        C = trial.suggest_float('C', 1e-3, 1e3, log=True)\n    )\n    clf = LogisticRegression(random_state=42, solver='saga', **lr_params)\n    model = im_Pipeline([('preprocess', preprocess),\n                         ('estimator', clf)])\n    return kfold_score(X_train, y_train, model)\n    \n# study = optuna.create_study(direction='maximize')\n# study.optimize(objective, n_trials=10)\n# lr_params = study.best_params","5767d45c":"lr_params = {'penalty': 'l2', 'C': 0.0034621321329587396}","ea29c5e7":"def objective(trial):\n    dt_params = dict(\n        criterion = trial.suggest_categorical('criterion', [\"gini\", \"entropy\"]),\n        max_depth = trial.suggest_int('max_depth', 2, 4),\n        min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 7)\n    )\n    clf = DecisionTreeClassifier(random_state=42, **dt_params)\n    model = im_Pipeline([('preprocess', preprocess),\n                         ('estimator', clf)])\n    return kfold_score(X_train, y_train, model)\n    \n# study = optuna.create_study(direction='maximize')\n# study.optimize(objective, n_trials=10)\n# dt_params = study.best_params","541cefdc":"dt_params = {'criterion': 'entropy', 'max_depth': 4, 'min_samples_leaf': 5}","f60e8fc6":"def objective(trial):\n    rf_params = dict(\n        max_depth = trial.suggest_int('max_depth', 2, 10),\n        n_estimators = trial.suggest_int('n_estimators', 100, 800),\n    )\n    clf = RandomForestClassifier(random_state=42, **rf_params)\n    model = im_Pipeline([('preprocess', preprocess),\n                         ('estimator', clf)])\n    return kfold_score(X_train, y_train, clf)\n    \n# study = optuna.create_study(direction='maximize')\n# study.optimize(objective, n_trials=10)\n# rf_params = study.best_params","ee952ef5":"rf_params = {'max_depth': 9, 'n_estimators': 530}","4ade77bf":"def objective(trial):\n    xgb_params = dict(\n        max_depth = trial.suggest_int('max_depth', 2, 10),\n        n_estimators = trial.suggest_int('n_estimators', 100, 1000),\n        learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n    )\n    clf = XGBClassifier(random_state=42, **xgb_params)\n    model = im_Pipeline([('preprocess', preprocess),\n                         ('estimator', clf)])\n    return kfold_score(X_train, y_train, clf)\n    \n# study = optuna.create_study(direction='maximize')\n# study.optimize(objective, n_trials=10)\n# xgb_params = study.best_params","fbff14a7":"xgb_params = {'max_depth': 6, 'n_estimators': 604, 'learning_rate': 0.044645721830551606}","6433b5d2":"classifiers = {\n    \"Logistic Regression\": LogisticRegression(random_state=42, **lr_params),\n    \"Decision Tree Classifier\": DecisionTreeClassifier(random_state=42, **dt_params),\n    \"Random Forest\": RandomForestClassifier(random_state=42, **rf_params),\n    \"XGBoost\": XGBClassifier(random_state=42, **xgb_params)\n}","02baa52c":"fitted_models_and_predictions_dictionary = {}\n\nfor classifier_name, classifier in classifiers.items():\n    model = Pipeline([\n        ('preprocessor', preprocessor),\n        ('classifier', classifier)\n    ])\n    model_and_predictions = fit_model_and_get_predictions(model, X_train, y_train, X_test)\n    fitted_models_and_predictions_dictionary[classifier_name]=model_and_predictions","efbdeb01":"df_performances=performance_assessment_model_collection(fitted_models_and_predictions_dictionary,\n                                                        type_set='test')\ndf_performances","58603bca":"df_performances=performance_assessment_model_collection(fitted_models_and_predictions_dictionary,\n                                                        type_set='train')\ndf_performances","ae3bf574":"df_execution_times=execution_times_model_collection(fitted_models_and_predictions_dictionary)\ndf_execution_times","fa14ef79":"from imblearn.under_sampling import RandomUnderSampler\nunder=RandomUnderSampler(random_state=42)\n\nfitted_models_and_predictions_dictionary = {}\n\nfor classifier_name, classifier in classifiers.items():\n    model = im_Pipeline([\n        ('preprocessor', preprocessor),\n        ('under', under),\n        ('classifier', classifier)\n    ])\n    model_and_predictions = fit_model_and_get_predictions(model, X_train, y_train, X_test)\n    fitted_models_and_predictions_dictionary[classifier_name]=model_and_predictions","82088871":"df_performances=performance_assessment_model_collection(fitted_models_and_predictions_dictionary,\n                                                        type_set='test')\ndf_performances","664999f0":"df_performances=performance_assessment_model_collection(fitted_models_and_predictions_dictionary,\n                                                        type_set='train')\ndf_performances","de8dcb4b":"df_execution_times=execution_times_model_collection(fitted_models_and_predictions_dictionary)\ndf_execution_times","dc08b6e9":"from imblearn.over_sampling import RandomOverSampler\nover = RandomOverSampler(random_state=42)\n\nfitted_models_and_predictions_dictionary = {}\n\nfor classifier_name, classifier in classifiers.items():\n    model = im_Pipeline([\n        ('preprocessor', preprocessor),\n        ('over', over),\n        ('classifier', classifier)\n    ])\n    model_and_predictions = fit_model_and_get_predictions(model, X_train, y_train, X_test)\n    fitted_models_and_predictions_dictionary[classifier_name]=model_and_predictions","bcd0d28a":"df_performances=performance_assessment_model_collection(fitted_models_and_predictions_dictionary,\n                                                        type_set='test')\ndf_performances","b8d67f2c":"df_performances=performance_assessment_model_collection(fitted_models_and_predictions_dictionary,\n                                                        type_set='train')\ndf_performances","31f52e46":"df_execution_times=execution_times_model_collection(fitted_models_and_predictions_dictionary)\ndf_execution_times","8a33241b":"from imblearn.over_sampling import SMOTE\nover=SMOTE(random_state=42)\n\nfitted_models_and_predictions_dictionary = {}\n\nfor classifier_name, classifier in classifiers.items():\n    model = im_Pipeline([\n        ('preprocessor', preprocessor),\n        ('over', over),\n        ('classifier', classifier)\n    ])\n    model_and_predictions = fit_model_and_get_predictions(model, X_train, y_train, X_test)\n    fitted_models_and_predictions_dictionary[classifier_name]=model_and_predictions","b256f680":"df_performances=performance_assessment_model_collection(fitted_models_and_predictions_dictionary,\n                                                        type_set='test')\ndf_performances","13ebc1ff":"df_performances=performance_assessment_model_collection(fitted_models_and_predictions_dictionary,\n                                                        type_set='train')\ndf_performances","a545919d":"df_execution_times=execution_times_model_collection(fitted_models_and_predictions_dictionary)\ndf_execution_times","5e5af7c6":"from imblearn.ensemble import EasyEnsembleClassifier, RUSBoostClassifier, BalancedBaggingClassifier, BalancedRandomForestClassifier\nensembles = {\n    'EasyEnsemble': EasyEnsembleClassifier(random_state=42),\n    'RUSBoost': RUSBoostClassifier(random_state=42),\n    'BalancedBagging': BalancedBaggingClassifier(random_state=42),\n    'BalancedRandomForest': BalancedRandomForestClassifier(random_state=42)\n}","dfc862eb":"fitted_models_and_predictions_dictionary = {}\n\nfor classifier_name, classifier in ensembles.items():\n    model = Pipeline([\n        ('preprocessor', preprocessor),\n        ('classifier', classifier)\n    ])\n    model_and_predictions = fit_model_and_get_predictions(model, X_train, y_train, X_test)\n    fitted_models_and_predictions_dictionary[classifier_name]=model_and_predictions","6677a2a5":"df_performances=performance_assessment_model_collection(fitted_models_and_predictions_dictionary,\n                                                        type_set='test')\ndf_performances","633b2953":"df_performances=performance_assessment_model_collection(fitted_models_and_predictions_dictionary,\n                                                        type_set='train')\ndf_performances","f154112a":"df_execution_times=execution_times_model_collection(fitted_models_and_predictions_dictionary)\ndf_execution_times","d6ba8f0e":"def get_template_roc_curve(ax, title,fs,random=True):\n    \n    ax.set_title(title, fontsize=fs)\n    ax.set_xlim([-0.01, 1.01])\n    ax.set_ylim([-0.01, 1.01])\n    \n    ax.set_xlabel('False Positive Rate', fontsize=fs)\n    ax.set_ylabel('True Positive Rate', fontsize=fs)\n    \n    if random:\n        ax.plot([0, 1], [0, 1],'r--',label=\"AUC ROC Random = 0.5\")\n        \ndef get_template_pr_curve(ax, title,fs, baseline=0.5):\n    \n    ax.set_title(title, fontsize=fs)\n    ax.set_xlim([-0.01, 1.01])\n    ax.set_ylim([-0.01, 1.01])\n    \n    ax.set_xlabel('Recall (True Positive Rate)', fontsize=fs)\n    ax.set_ylabel('Precision', fontsize=fs)\n    \n    ax.plot([0, 1], [baseline, baseline],'r--',label='AP Random = {0:0.3f}'.format(baseline))","89b6c4f7":"roc_curve, ax = plt.subplots(1, 1, figsize=(10,10))\n\ncmap = plt.get_cmap('jet')\ncolors={'EasyEnsemble':cmap(0), \n        'RUSBoost':cmap(250),\n        'BalancedBagging':cmap(70), \n        'BalancedRandomForest':cmap(140)}\n\nget_template_roc_curve(ax,title='Receiver Operating Characteristic Curve\\nTest data',fs=15)\n    \nfor classifier_name in ensembles:\n    \n    model_and_predictions=fitted_models_and_predictions_dictionary[classifier_name]\n\n    FPR_list, TPR_list, threshold = metrics.roc_curve(y_test, model_and_predictions['predictions_test'])\n    ROC_AUC = metrics.auc(FPR_list, TPR_list)\n\n    ax.plot(FPR_list, TPR_list, 'b', color=colors[classifier_name], label = 'AUC ROC {0}= {1:0.3f}'.format(classifier_name,ROC_AUC))\n    ax.legend(loc = 'upper left',bbox_to_anchor=(1.05, 1))","88307156":"pr_curve, ax = plt.subplots(1, 1, figsize=(10,10))\ncmap = plt.get_cmap('jet')\ncolors={'EasyEnsemble':cmap(0), \n        'RUSBoost':cmap(250),\n        'BalancedBagging':cmap(70), \n        'BalancedRandomForest':cmap(140)}\n\nget_template_pr_curve(ax, \"Precision Recall (PR) Curve\\nTest data\",fs=15,baseline=sum(y_test\/len(y_test)))\n    \nfor classifier_name in ensembles:\n    \n    model_and_predictions=fitted_models_and_predictions_dictionary[classifier_name]\n\n    precision, recall, threshold = metrics.precision_recall_curve(y_test, model_and_predictions['predictions_test'])\n    precision=precision[::-1]\n    recall=recall[::-1]\n    \n    AP = metrics.average_precision_score(y_test, model_and_predictions['predictions_test'])\n    \n    ax.step(recall, precision, 'b', color=colors[classifier_name], label = 'AP {0}= {1:0.3f}'.format(classifier_name,AP))\n    ax.legend(loc = 'upper left',bbox_to_anchor=(1.05, 1))\n    \n    \nplt.subplots_adjust(wspace=0.5, hspace=0.8)","09f0826f":"# <a id='3'>III. Th\u1eed nghi\u1ec7m<\/a>\n---","fc1d1016":"### Lo\u1ea1i b\u1ecf c\u00e1c d\u00f2ng tr\u00f9ng l\u1eb7p","4e496981":"**T\u1ea1i sao d\u00f9ng AUC thay v\u00ec Accuracy cho Imbalanced data?**\n\nNh\u1eafc l\u1ea1i \u0111\u1ecbnh ngh\u0129a v\u1ec1 Accurracy: $\\text{Acuracy} = \\dfrac{\\text{True positives + True negatives} }{\\text{True  positives  +  False  positives + True negatives + False negatives}}$\n \n\nTheo \u0111\u00f3, v\u1edbi imbalanced data, khi m\u00e0 k\u1ebft qu\u1ea3 nghi\u00eang h\u1eb3n v\u1ec1 0 hay 1 th\u00ec d\u00f9ng accuracy s\u1ebd kh\u00f4ng th\u1ec3 \u0111o ch\u00ednh x\u00e1c m\u1ee9c \u0111\u1ed9 hi\u1ec7u qu\u1ea3 c\u1ee7a model (trong tr\u01b0\u1eddng h\u1ee3p n\u00e0y l\u00e0 0.17% k\u1ebft qu\u1ea3 l\u00e0 1) v\u00ec d\u00f9 model c\u00f3 ra to\u00e0n l\u00e0 0 hay 1 th\u00ec accuracy v\u1eabn cho ra k\u1ebft qu\u1ea3 r\u1ea5t t\u1ed1t.\n\nV\u1edbi AUC, khi k\u1ebft qu\u1ea3 g\u1ea7n v\u1ec1 \u0111\u1ebfn 1 th\u00ec ngh\u0129a l\u00e0 model perform c\u00e0ng t\u1ed1t, \u1edf 0.5 th\u00ec k\u1ebft qu\u1ea3 kh\u00f4ng kh\u00e1c g\u00ec tung \u0111\u1ed3ng xu, v\u00e0 ti\u1ebfn v\u1ec1 0 th\u00ec model s\u1ebd d\u1ef1 \u0111o\u00e1n 0 th\u00e0nh 1 v\u00e0 ng\u01b0\u1ee3c l\u1ea1i.\n\nH\u01a1n n\u1eefa, nh\u1eefng gi\u00e1 tr\u1ecb \u0111\u01b0\u1ee3c d\u1ef1 \u0111o\u00e1n sai (False Positives, False Negatives) s\u1ebd c\u00f3 \u1ea3nh h\u01b0\u1edfng l\u1edbn h\u01a1n \u0111\u1ebfn AUC. \u0110\u00e2y l\u00e0 \u0111i\u1ec1u m\u00e0 ch\u00fang ta quan t\u00e2m khi l\u00e0m vi\u1ec7c v\u1edbi imbalanced data.\n\nC\u00f3 th\u1ec3 d\u00f9ng f1 score, confusion matric, precision\/recall score t\u00f9y thu\u1ed9c v\u00e0o \u0111\u1ed9 \u01b0u ti\u00ean c\u1ee7a model.\n\n**Average Precision hay Area Under the Precision-Recall Curve:**\n\n- Precision-Recall curve th\u1ec3 hi\u1ec7n gi\u00e1 tr\u1ecb Recall v\u00e0 Precision v\u1edbi thresholds $t$ kh\u00e1c nhau nh\u01b0 l\u00e0 Recall v\u00e0 Sensitivity c\u1ee7a ROC curve.\n\n- Precision Recall Curve c\u00f3 nh\u1eefng t\u00ednh ch\u1ea5t kh\u00e1c ROC:\n\n    - Precision c\u00f3 th\u1ec3 t\u0103ng ho\u1eb7c gi\u1ea3m khi Recall t\u0103ng (T\u0103ng khi g\u1eb7p True Positives v\u00e0 gi\u1ea3m v\u1edbi False Positives).\n\n    - \u0110\u1ed9 hi\u1ec3u qu\u1ea3 c\u1ee7a c\u1ee7a m\u1ed9t random classifier ph\u1ee5 thu\u1ed9c v\u00e0o m\u1ee9c \u0111\u1ed9 m\u1ea5t c\u00e2n b\u1eb1ng c\u1ee7a t\u1eadp d\u1eef li\u1ec7u. \n","4f11fa48":"#### B\u1ea3ng 3: Hi\u1ec7u n\u0103ng c\u1ee7a b\u1ed1n m\u00f4 h\u00ecnh Logistic Regression, Decision Tree, Random Forest v\u00e0 XGBoost khi s\u1eed d\u1ee5ng Random Over Sampling.","92562034":"### \u0110\u01b0\u1eddng cong ROC v\u00e0 AP c\u1ee7a c\u00e1c m\u00f4 h\u00ecnh Ensembles","7b509d05":"**Nh\u1eadn x\u00e9t:** \n- C\u00f3 th\u1ec3 th\u1ea5y tr\u01b0\u1eddng Target r\u1ea5t m\u1ea5t c\u00e2n b\u1eb1ng. H\u1ea7u h\u1ebft c\u00e1c giao d\u1ecbch trong t\u1eadp d\u1eef li\u1ec7u l\u00e0 b\u00ecnh th\u01b0\u1eddng!\n- N\u1ebfu s\u1eed d\u1ee5ng tr\u1ef1c ti\u1ebfp t\u1eadp d\u1eef li\u1ec7u n\u00e0y \u0111\u1ec3 x\u00e2y d\u1ef1ng m\u00f4 h\u00ecnh d\u1ef1 \u0111o\u00e1n s\u1ebd x\u1ea3y ra t\u00ecnh tr\u1ea1ng overfit khi n\u00f3 s\u1ebd m\u1eb7c \u0111\u1ecbnh h\u1ea7u h\u1ebft c\u00e1c giao d\u1ecbch l\u00e0 b\u00ecnh th\u01b0\u1eddng v\u00e0 kh\u00f4ng c\u00f3 \u00fd ngh\u0129a nh\u1eadn di\u1ec7n t\u00ednh b\u1ea5t th\u01b0\u1eddng c\u1ee7a m\u1ed9t giao d\u1ecbch.\n\nM\u1ed9t k\u0129 thu\u1eadt \u0111\u1ec3 x\u1eed l\u00fd t\u00ecnh tr\u1ea1ng s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong b\u00e0i n\u00e0y l\u00e0 **Under-Sampling** - ng\u1eabu nhi\u00ean l\u01b0\u1ee3c b\u1ecf c\u00e1c giao d\u1ecbch b\u00ecnh th\u01b0\u1eddng \u0111\u1ec3 t\u1ea1o m\u1ed9t t\u1eadp d\u1eef li\u1ec7u nh\u1ecf h\u01a1n v\u1edbi t\u1ec9 l\u1ec7 c\u1ee7a hai lo\u1ea1i giao d\u1ecbch l\u00e0 50\/50.","fa085eac":"#### B\u1ea3ng 4: Hi\u1ec7u n\u0103ng c\u1ee7a b\u1ed1n m\u00f4 h\u00ecnh Logistic Regression, Decision Tree, Random Forest v\u00e0 XGBoost khi s\u1eed d\u1ee5ng SMOTE.","1a9de430":"### Hyper-parameters tuning\n\n- H\u00e0m `kfold_score` tr\u1ea3 v\u1ec1 \u0111i\u1ec3m AP trung b\u00ecnh khi th\u1ef1c hi\u1ec7n Stratified K-folds Cross Validation.","f696293b":"## 1. Chia d\u1eef li\u1ec7u Train v\u00e0 Test\n\nTa s\u1ebd s\u1ebd chia t\u1eadp d\u1eef li\u1ec7u g\u1ed1c ra th\u00e0nh t\u1eadp train v\u00e0 test d\u00f9ng \u0111\u1ec3 hu\u1ea5n luy\u1ec7n m\u00f4 h\u00ecnh v\u00e0 ki\u1ec3m tra hi\u1ec7u n\u0103ng c\u1ee7a n\u00f3. T\u1eadp train v\u00e0 test v\u1eabn gi\u1eef ph\u00e2n ph\u1ed1i ban \u0111\u1ea7u c\u1ee7a Target.","b84566e4":"### Ph\u00e2n b\u1ed1 c\u00e1c tr\u01b0\u1eddng - Target","9046d620":"## <a id='1-2'> 2. S\u1eed d\u1ee5ng bi\u1ebfn \u0111\u1ed5i PCA \u0111\u1ec3 che d\u1ea5u d\u1eef li\u1ec7u <\/a> ","f2eb0db8":"## <a id='1.3'> 3. Ch\u1ecdn metric \u0111\u00e1nh gi\u00e1  <\/a> ","b8922cf0":"![gnome-shell-screenshot-1B0N60.png](attachment:532357e4-2881-4d44-b432-20d33cb97d0c.png)","a71b14d6":"- Ch\u1ecdn c\u00e1c b\u1ed9 tham s\u1ed1 cho c\u00e1c m\u00f4 h\u00ecnh `LogisticRegression`, `DecisionTreeClassifier`, `RandomForestClassifier` v\u00e0 `XGBClassifier` s\u1eed d\u1ee5ng th\u01b0 vi\u1ec7n Optuna.","19cdb99d":"## 2. Baseline Feature Transformer\n- Scaling tr\u01b0\u1eddng `Time` v\u00e0 `Amount` d\u00f9ng StandardScaler v\u00e0 RobustScaler\n- Th\u1ef1c hi\u1ec7n Random Under-sampling ","a58a0873":"### Th\u00f4ng tin c\u00e1c tr\u01b0\u1eddng d\u1eef li\u1ec7u:\n- `Time`: S\u1ed1 gi\u00e2y gi\u1eefa m\u1ed7i giao d\u1ecbch v\u1edbi giao d\u1ecbch \u0111\u1ea7u ti\u00ean trong dataset\n- `Amount`: S\u1ed1 ti\u1ec1n giao d\u1ecbch\n- `Class`: Nh\u1eadn gi\u00e1 tr\u1ecb 1 n\u1ebfu l\u00e0 giao d\u1ecbch gian l\u1eadn, 0 l\u00e0 b\u00ecnh th\u01b0\u1eddng\n- `V1`-`V28`: C\u00e1c th\u00e0nh ph\u1ea7n ch\u00ednh (principal components) c\u1ee7a dataset, k\u1ebft qu\u1ea3 c\u1ee7a ph\u00e9p bi\u1ebfn \u0111\u1ed5i PCA.","7c0e01cc":"#### B\u1ea3ng 2: Hi\u1ec7u n\u0103ng c\u1ee7a b\u1ed1n m\u00f4 h\u00ecnh Logistic Regression, Decision Tree, Random Forest v\u00e0 XGBoost khi s\u1eed d\u1ee5ng Random Under Sampling.","6ffa1308":"# <a id='2'>II. Gi\u1edbi thi\u1ec7u v\u1ec1 data<\/a>\n---","8a7f187d":"### Nh\u1eadp c\u00e1c g\u00f3i th\u01b0 vi\u1ec7n","de68f387":"![gnome-shell-screenshot-LFRS60.png](attachment:218e377c-40f2-49b4-9d56-2efe434edde4.png)","2bee0a79":"![image.png](attachment:8dc06771-3e2a-418d-bf10-70134d2c95bd.png)\n![image.png](attachment:ca27145d-4a77-4692-9eba-6081ee3bec8d.png)","abc59a26":"### Ph\u00e2n b\u1ed1 Time Amount - Target","48d7cf4a":"## Outline\n---\n\n<a href='#1'>I. Gi\u1edbi thi\u1ec7u b\u00e0i to\u00e1n<\/a>\n- <a href='#1-1'>1. Th\u00f4ng tin t\u1ed5ng quan d\u1eef li\u1ec7u <\/a> \n- <a href='#1-2'>2. PCA <\/a> \n- <a href='#1-3'>3. Metric \u0111\u00e1nh gi\u00e1 <\/a>\n\n<a href='#2'>II. Gi\u1edbi thi\u1ec7u d\u1eef li\u1ec7u<\/a>\n- <a href='#2-1'>1. Th\u00f4ng tin t\u1ed5ng quan d\u1eef li\u1ec7u <\/a> \n- <a href='#2-2'>2. Th\u00f4ng tin t\u1ed5ng quan target <\/a> \n- <a href='#2-3'>3. Quan s\u00e1t ph\u00e2n b\u1ed1 c\u00e1c tr\u01b0\u1eddng d\u1eef li\u1ec7u <\/a>\n    \n<a href='#3'>III. Ti\u1ec1n x\u1eed l\u00fd v\u00e0 Khai ph\u00e1 d\u1eef li\u1ec7u<\/a>  \n- <a href='#3-1'>1. Random Undersampling<\/a> \n- <a href='#3-1'>2. Correlation matrix & ph\u00e2n ph\u1ed1i tr\u01b0\u1eddng - target<\/a> \n    \n<a href='#4'>IV. Feature engineering <\/a>\n- <a href='#4-1'>3.1. Scaling   <\/a>\n- <a href='#4-2'>3.2. Train and validation c\u1ee7a imbalanced data <\/a> \n- <a href='#4-3'>3.3. X\u1eed l\u00fd d\u1eef li\u1ec7u ph\u00e2n lo\u1ea1i: Chu\u1ea9n ho\u00e1, \u0111\u01b0a v\u1ec1 ph\u00e2n ph\u1ed1i chu\u1ea9n <\/a>   \n- <a href='#4.4'>3.4. X\u00e2y d\u1ef1ng m\u00f4 h\u00ecnh <\/a>\n- <a href='#4.5'>3.5. Training  <\/a>\n    \n<a href='#5'>V. T\u00ecm hi\u1ec3u v\u1ec1 SMOTE Technique (Over-Sampling) (S\u01a1n) <\/a>\n\n\n\n\n\n","b42bc2db":"# <a id='1'>I. Gi\u1edbi thi\u1ec7u v\u1ec1 b\u00e0i to\u00e1n<\/a>\n---","131cbe52":"## 2. Th\u00f4ng tin t\u1ed5ng quan target\n### T\u00ednh m\u1ea5t c\u00e2n b\u1eb1ng c\u1ee7a t\u1eadp d\u1eef li\u1ec7u (Imbalanced dataset)","e7e54747":"**\u1ee8ng d\u1ee5ng m\u00f4 h\u00ecnh:** Gi\u00fap c\u00e1c c\u00f4ng ty th\u1ebb t\u00edn d\u1ee5ng nh\u1eadn di\u1ec7n giao d\u1ecbch gian l\u1eadn \u0111\u1ec3 b\u1ea3o v\u1ec7 kh\u00e1ch h\u00e0ng.\n\n**T\u1ed5ng quan d\u1eef li\u1ec7u:** C\u00e1c giao d\u1ecbch th\u1ebb t\u00edn d\u1ee5ng c\u1ee7a kh\u00e1ch h\u00e0ng Ch\u00e2u \u00c2u trong v\u00f2ng 2 ng\u00e0y T9\/2013. \n\nC\u00f3 t\u1ed5ng c\u1ed9ng 492\/284.807 (0.172%) giao d\u1ecbch l\u00e0 gian l\u1eadn. D\u1eef li\u1ec7u ch\u1ec9 bao g\u1ed3m s\u1ed1 \u0111\u00e3 \u0111\u01b0\u1ee3c chuy\u1ec3n \u0111\u1ed5i theo ph\u01b0\u01a1ng ph\u00e1p PCA. V\u00ec l\u00ed do b\u1ea3o m\u1eadt n\u00ean c\u00e1c th\u00f4ng tin g\u1ed1c kh\u00f4ng \u0111\u01b0\u1ee3c ph\u00e9p c\u00f4ng b\u1ed1. C\u00e1c features V1, V2\u2026V27 \u0111\u01b0\u1ee3c chuy\u1ec3n \u0111\u1ed5i b\u1edfi PCA, nh\u1eefng d\u1eef li\u1ec7u duy nh\u1ea5t kh\u00f4ng b\u1ecb chuy\u1ec3n \u0111\u1ed5i l\u00e0 `Time` v\u00e0 `Amount`. Feature `Time` l\u00e0 s\u1ed1 gi\u00e2y k\u1ec3 t\u1eeb giao d\u1ecbch \u0111\u1ea7u ti\u00ean trong dataset. Feature `Amount` l\u00e0 gi\u00e1 tr\u1ecb giao d\u1ecbch (coi nh\u01b0 \u0111\u01a1n v\u1ecb l\u00e0 Euros), feature n\u00e0y c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c d\u00f9ng cho example-dependant cost-sensitive learning. Feature `Class` l\u00e0 \u0111\u1ed1i t\u01b0\u1ee3ng c\u1ea7n t\u00ecm, mang gi\u00e1 tr\u1ecb 1 n\u1ebfu l\u00e0 gi\u1ea3 m\u1ea1o, c\u00f2n l\u1ea1i mang gi\u00e1 tr\u1ecb 0. \n\nDo ph\u00e2n lo\u1ea1i d\u1eef li\u1ec7u c\u00f3 t\u1ec9 l\u1ec7 qu\u00e1 ch\u00eanh l\u1ec7ch, n\u00ean ki\u1ec3m tra \u0111\u1ed9 ch\u00ednh x\u00e1c b\u1eb1ng ph\u01b0\u01a1ng ph\u00e1p AUPRC (Area Under the Precision-Recall Curve). ","932e4b3a":"### Ph\u00e2n b\u1ed1 c\u00e1c tr\u01b0\u1eddng V1-V28","f35ef4e6":"### Ki\u1ec3m tra d\u1eef li\u1ec7u thi\u1ebfu","c13cb19a":"#### B\u1ea3ng 1: Hi\u1ec7u n\u0103ng c\u1ee7a b\u1ed1n m\u00f4 h\u00ecnh Logistic Regression, Decision Tree, Random Forest v\u00e0 XGBoost.","2afd6968":"## <a id='1-1'> 1. Ch\u1ecdn metric \u0111\u00e1nh gi\u00e1<\/a> ","974f3a55":"## 3. X\u00e2y d\u1ef1ng Framework \u0111\u1ec3 so s\u00e1nh c\u00e1c m\u00f4 h\u00ecnh\n\n- H\u00e0m `fit_model_and_get_predictions` hu\u1ea5n lu\u1eadn m\u00f4 h\u00ecnh v\u1edbi c\u00e1c d\u1eef li\u1ec7u \u0111\u01b0a v\u00e0o v\u00e0 tr\u1ea3 v\u1ec1 c\u00e1c k\u1ebft qu\u1ea3 d\u1ef1 \u0111o\u00e1n tr\u00ean t\u1eadp Train v\u1ea3 Test, th\u1eddi gian hu\u1ea5n luy\u1ec7n v\u00e0 th\u1eddi gian d\u1ef1 \u0111o\u00e1n.\n- H\u00e0m `performance_assessment` tr\u1ea3 v\u1ec1 \u0111i\u1ec3m AOC v\u00e0 AP c\u1ee7a k\u1ebft qu\u1ea3 d\u1ef1 \u0111o\u00e1n c\u1ee7a m\u1ed9t m\u00f4 h\u00ecnh tr\u00ean t\u1eadp Train ho\u1eb7c Test.\n- H\u00e0m `execution_times_model_collection` tr\u1ea3 v\u1ec1 th\u1eddi gian hu\u1ea5n luy\u1ec7n (Training Execution time) v\u00e0 th\u1eddi gian d\u1ef1 \u0111o\u00e1n (Prediction execution time).","09506f92":"#### B\u1ea3ng 5: Hi\u1ec7u n\u0103ng c\u1ee7a b\u1ed1n m\u00f4 h\u00ecnh EasyEnsemble, RUSBoost, Balanced Bagging v\u00e0 Balanced Random Forest.","3bc741ff":"## 1. Th\u00f4ng tin t\u1ed5ng quan d\u1eef li\u1ec7u","704ce9d6":"### Ph\u00e2n b\u1ed1 tr\u01b0\u1eddng Time v\u00e0 Amount","0ccd4378":"### \u0110\u1ecdc file d\u1eef li\u1ec7u","72954b28":"![image.png](attachment:c682ab41-f90d-4ccf-a414-e8c984d3a896.png)\n![image.png](attachment:d6af4087-272a-4726-9fb1-23764a151ba9.png)","b2bb4a5a":"## 3. Quan s\u00e1t ph\u00e2n b\u1ed1 c\u00e1c tr\u01b0\u1eddng d\u1eef li\u1ec7u","1622dbb5":"# Credit Card Fraud Detection\n-----\n\n","7b9342e9":"Nh\u1eefng tr\u01b0\u1eddng th\u00f4ng tin li\u00ean quan \u0111\u1ebfn th\u00f4ng tin c\u00e1 nh\u00e2n c\u1ee7a kh\u00e1ch h\u00e0ng c\u00f3 th\u1ec3 b\u1ecb l\u1ee3i d\u1ee5ng b\u1edfi c\u00e1c b\u00ean th\u1ee9 ba, g\u00e2y ra nh\u1eefng nguy c\u01a1 m\u1ea5t an to\u00e0n v\u00e0 ri\u00eang t\u01b0 cho ng\u01b0\u1eddi d\u00f9ng. \n\nGi\u1ea3i ph\u00e1p \u0111\u01a1n gi\u1ea3n l\u00e0 kh\u00f4ng cung c\u1ea5p nh\u1eefng th\u00f4ng tin nh\u1ea1y c\u1ea3m n\u00e0y cho c\u00e1c b\u00ean th\u1ee9 ba, tuy nhi\u00ean trong nh\u1eefng b\u00e0i to\u00e1n nh\u01b0 nh\u1eadn di\u1ec7n gian l\u1eadn t\u00edn d\u1ee5ng, ch\u00fang c\u00f3 th\u1ec3 l\u00e0 nh\u1eefng tr\u01b0\u1eddng c\u1ea7n thi\u1ebft, c\u00f3 quy\u1ebft \u0111\u1ecbnh r\u1ea5t l\u1edbn \u0111\u1ebfn \u0111\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a m\u00f4 h\u00ecnh. M\u1ed9t trong nh\u1eefng ph\u01b0\u01a1ng ph\u00e1p hi\u1ec7u qu\u1ea3 \u0111\u1ec3 che d\u1ea5u nh\u1eefng th\u00f4ng tin nh\u1ea1y c\u1ea3m l\u00e0 s\u1eed d\u1ee5ng **ph\u00e9p ph\u00e2n t\u00edch th\u00e0nh ph\u1ea7n ch\u00ednh** (Principal Components Analysis - PCA).\n\nPCA ph\u00e2n t\u00e1ch c\u00e1c chi\u1ec1u kh\u00f4ng gian - c\u00e1c th\u00e0nh ph\u1ea7n ch\u00ednh ch\u1ee9a \u0111\u1ef1ng nhi\u1ec1u th\u00f4ng tin nh\u1ea5t c\u1ee7a d\u1eef li\u1ec7u. V\u00ed d\u1ee5 c\u1ee7a m\u1ed9t th\u00e0nh ph\u1ea7n ch\u00ednh m\u00e0 PCA t\u00ecm ra c\u00f3 th\u1ec3 l\u00e0 nh\u01b0 sau - m\u1ed9t t\u1ed5 h\u1ee3p tuy\u1ebfn t\u00ednh c\u1ee7a c\u00e1c d\u1eef li\u1ec7u input:\n$$\\text{V1} = 4 \\times \\text{TRANSACTION_ID} - \\frac{3}{4} \\times \\text{TERMINAL_ID} + \\frac{1}{2} \\times \\text{CUSTOMER_ID}$$\n\nM\u1ed7i m\u1ed9t giao d\u1ecbch c\u00f3 m\u1ed9t gi\u00e1 tr\u1ecb `V1` v\u00e0 tr\u01b0\u1eddng `V1` s\u1ebd l\u01b0u gi\u1eef m\u1ed9t ph\u1ea7n \u0111\u1ed9 ph\u00e2n t\u00e1n c\u1ee7a d\u1eef li\u1ec7u - c\u00f3 \u00fd ngh\u0129a trong khi \u0111\u01b0a v\u00e0o c\u00e1c m\u00f4 h\u00ecnh h\u1ecdc m\u00e1y. C\u00e1c tr\u01b0\u1eddng d\u1eef li\u1ec7u `V1` \u0111\u1ebfn `V28` trong d\u1eef li\u1ec7u c\u1ee7a b\u00e0i to\u00e1n n\u00e0y ch\u00ednh l\u00e0 $28$ th\u00e0nh ph\u1ea7n ch\u00ednh c\u1ee7a ph\u00e9p PCA.\n\nCh\u1ec9 t\u1eeb c\u00e1c tr\u01b0\u1eddng n\u00e0y th\u00ec r\u1ea5t kh\u00f3 kh\u00f4i ph\u1ee5c l\u1ea1i \u0111\u01b0\u1ee3c c\u00e1c d\u1eef li\u1ec7u ban \u0111\u1ea7u nh\u01b0ng c\u00e1c m\u00f4 h\u00ecnh ho\u00e0n to\u00e0n c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n t\u1ed1t tr\u00ean c\u00e1c d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c bi\u1ebfn \u0111\u1ed5i n\u00e0y."}}