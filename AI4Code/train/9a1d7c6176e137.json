{"cell_type":{"b0be7b95":"code","a09482d2":"code","d919546f":"code","5865553f":"code","85b5ed0e":"code","800e6147":"code","62c0d743":"code","72fd523d":"code","1c205f80":"code","88391299":"code","3143f8eb":"code","979c4157":"code","3910b663":"code","06f1c791":"code","4efffa32":"code","d815909e":"code","bec06d14":"code","e9ace665":"code","a995cdb9":"code","87d127dd":"code","3f3798ff":"code","9d723302":"code","968090ec":"code","9607857a":"code","e6d0e919":"code","46b90f94":"code","0e59fbf2":"code","cdc11ca5":"code","65fc149e":"markdown","3a7b182a":"markdown","da65f46d":"markdown","3e189407":"markdown","972b8039":"markdown","7ad3e14f":"markdown","a2d5e519":"markdown","908a1e43":"markdown","2f26d49c":"markdown","48d0282e":"markdown","74ecd1ad":"markdown","ffca402b":"markdown","a12510b6":"markdown","6ce3b080":"markdown","30e2cad3":"markdown","e7a75080":"markdown","af6e68c3":"markdown","185b5157":"markdown","07ac228f":"markdown","dc973201":"markdown"},"source":{"b0be7b95":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer # Intermediate Machine Learning\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a09482d2":"train='\/kaggle\/input\/titanic\/train.csv'\ngender='\/kaggle\/input\/titanic\/gender_submission.csv'\ntest='\/kaggle\/input\/titanic\/test.csv'\n\ntrain_data = pd.read_csv(train)\ngender_sub = pd.read_csv(gender)\ntest_data = pd.read_csv(test)\n\nprint(\"Data loaded.\")","d919546f":"# print(\"===============================Test Data===============================\\n{}\\nShape: {}\\n\".format(test_data.head(),test_data.shape))\n# print(\"===============================Gender Submission===============================\\n{}\\nShape: {}\\n\".format(gender_sub.head(),gender_sub.shape))\n# print(\"===============================Train Data===============================\\n{}\\nShape: {}\\n\".format(train_data.head(),train_data.shape))","5865553f":"print(train_data.columns)\nprint(test_data.columns)","85b5ed0e":"features = ['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']\nprint(\"===============================Train Stats===============================\\n\")\nfor f in features:\n    print(\"-------- {} Stats --------\\n{}\\n\".format(f,train_data[f].describe()))\n    \nprint(\"===============================Test Stats===============================\\n\")\nfor f in features:\n    print(\"-------- {} Stats --------\\n{}\\n\".format(f,test_data[f].describe()))","800e6147":"# # Old approach where I tried to fill missing values with mode \n# #thereby not changing the stats by much. (Hopefully)\n# # Finding mode of age\n# age_mode = train_data.Age.mode()\n# age_mode","62c0d743":"help(pd.Series.mode)","72fd523d":"help(train_data.fillna)","1c205f80":"# age_mode[0]","88391299":"help(SimpleImputer.transform)","3143f8eb":"help(SimpleImputer.fit_transform)","979c4157":"# print(age_mode)\n# train_data.Age.fillna(value=age_mode[0],inplace=True)\n# test_data.Age.fillna(value=age_mode[0],inplace=True)\n# train_data.Age.describe(),test_data.Age.describe()","3910b663":"test_data.Sex.replace(['male','female'],[0,1],inplace=True)\ntrain_data.Sex.replace(['male','female'],[0,1],inplace=True)\ntest_data.Sex.describe(),train_data.Sex.describe()","06f1c791":"features = ['Pclass','Sex','SibSp','Parch','Fare','Age']\nfeatures","4efffa32":"X = train_data[features]\ny = train_data[\"Survived\"]\n\nX,y","d815909e":"train_X,val_X,train_y,val_y = train_test_split(X,y,random_state=1)\ntrain_X,val_X,train_y,val_y","bec06d14":"my_imputer = SimpleImputer()\n\n# NotFittedError: This SimpleImputer instance is not fitted yet. \n#         Call 'fit' with appropriate arguments before using this estimator.\n# Hence using fit_transform()\n\ntrainX = pd.DataFrame( my_imputer.fit_transform(train_X) )\nvalidX = pd.DataFrame( my_imputer.transform(val_X) )\n\ntrainX,validX","e9ace665":"# from sklearn.ensemble import RandomForestRegressor\nhelp(RandomForestRegressor.fit)","a995cdb9":"rf_model = RandomForestRegressor(n_estimators=300,max_depth=10,random_state=1) #,criterion='mae',random_state=1)\nrf_model.fit(trainX,train_y) \nprint(\"Training Complete\")","87d127dd":"X.describe()","3f3798ff":"rf_preds = rf_model.predict(validX)\nrf_preds","9d723302":"rf_preds = [int(round(v,0)) for v in rf_preds]\nrf_preds","968090ec":"mae = mean_absolute_error(val_y,rf_preds)\nmae","9607857a":"test_data['Fare'].fillna(test_data.Fare.mode()[0],inplace=True)\ntest_data.describe()","e6d0e919":"testD = pd.DataFrame( my_imputer.transform(test_data[features]) )\ntestD.columns = features\ntestD.describe()","46b90f94":"rf_preds = rf_model.predict(testD)\nrf_preds","0e59fbf2":"rf_preds = [int(round(v,0)) for v in rf_preds]\nrf_preds","cdc11ca5":"output = pd.DataFrame({\"PassengerId\":test_data.PassengerId,\"Survived\":rf_preds})\noutput=output.set_index(\"PassengerId\")\noutput.to_csv('\/kaggle\/working\/rf_impute_submission.csv')\nprint(output)\nprint(\"Submission saved\")","65fc149e":"Embarked, Fare & Age columns in testing and training data have missing values. ","3a7b182a":"Checking the columns in both testing & training dataset.","da65f46d":"Filling NA values and converting categorical values to numerical values.","3e189407":"**STEPS:**","972b8039":"(Beginner Alert!)\n\nI'm a complete beginner to Kaggle & Machine Learning. This is my on-going attempt at improving the prediction accuracy for this competition while I learn different approaches to solving it. \n\nI'm currently following Kaggle's micro-courses and implementing the methods here.\n","7ad3e14f":"Testing it on test_data.","a2d5e519":"Calculating Mean Absolute Error","908a1e43":"Imputing data","2f26d49c":"Filling NA values of Age in train and test data with most frequent datapoint i.e. 24 years.","48d0282e":"Displaying stats about the training & testing data.","74ecd1ad":"train_X = train_data[features]\nX = test_data[features].fillna(0)\ntrain_y = train_data[\"Survived\"]\n# train_X.head\n# train_y.head\n\n# ValueError: could not convert string to float: 'male' \n# Hence Converting Gender to unique values.\ntrain_X.Sex.replace(['male','female'],[0,1],inplace=True)\nX.Sex.replace(['male','female'],[0,1],inplace=True)\n\n# train_X\n\nrf_model = RandomForestRegressor(n_estimators=100,max_depth=10,random_state=1)\nrf_model.fit(train_X,train_y)\nprint(\"Training Complete\")","ffca402b":"Training the model with the selected features.","a12510b6":"*Selecting Pclass,Sex,SibSp,Parch & Fare as features as they have data for all rows in training dataset.* (older version)\n\nUsing Random Forest.","6ce3b080":"Creating prediction target and features","30e2cad3":"Replacing any value < 0.5 as 0 and > 0.5 as 1","e7a75080":"Loading all the data required for the competition.","af6e68c3":"Saving output","185b5157":"help(mean_absolute_error)\nmean_absolute_error(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')\n    Mean absolute error regression loss\n    \n    Read more in the :ref:`User Guide <mean_absolute_error>`.\n    \n    Parameters\n    ----------\n    y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n        Ground truth (correct) target values.\n    \n    y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n        Estimated target values.\n    \n    sample_weight : array-like of shape (n_samples,), optional\n        Sample weights.\n    \n    multioutput : string in ['raw_values', 'uniform_average']                 or array-like of shape (n_outputs)\n        Defines aggregating of multiple output values.\n        Array-like value defines weights used to average errors.\n    \n        'raw_values' :\n            Returns a full set of errors in case of multioutput input.\n    \n        'uniform_average' :\n            Errors of all outputs are averaged with uniform weight.\n    \n    \n    Returns\n    -------\n    loss : float or ndarray of floats\n        If multioutput is 'raw_values', then mean absolute error is returned\n        for each output separately.\n        If multioutput is 'uniform_average' or an ndarray of weights, then the\n        weighted average of all output errors is returned.\n    \n        MAE output is non-negative floating point. The best value is 0.0.","07ac228f":"Using techniques learnt in handling missing values from Intermediate Machine Learning Micro Course on Kaggle. ","dc973201":"Splitting Data into Training and Testing Datasets"}}