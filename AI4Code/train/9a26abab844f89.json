{"cell_type":{"de04767f":"code","57e20832":"code","f39c2695":"code","b6b6c6db":"code","107aca0a":"code","f8c62c53":"code","833efa67":"code","6250e951":"code","61ce04d8":"code","b3e66073":"code","e90d7fd9":"code","ea7334a1":"code","5a51d7f3":"code","c37c85ff":"code","97b95a92":"code","e1898178":"code","7437ec71":"code","885ecca2":"code","34acf57b":"code","982d103e":"code","d7ef53d1":"code","06d8c37e":"code","16bcff32":"code","a119ac7e":"code","6a3637ec":"code","f9ca496c":"code","c1f40770":"code","29188820":"code","381fd456":"code","40263b45":"code","e18fa488":"code","b7b7506b":"code","5156778c":"code","ed38617e":"code","a0efb7e9":"code","c46a37c5":"code","cc8ed4a2":"code","d3ce73f0":"code","b2526fb9":"code","2b2aba7d":"code","e080576a":"code","8a2b5f69":"code","a85f7d3d":"code","77fc60ef":"code","bf96cbe2":"code","57b79b00":"code","e3ef8f2e":"code","8fe5389c":"code","afa95851":"code","d488036d":"code","ffc0e22a":"code","c2d819f3":"code","b1848459":"code","edb6880d":"code","55dd1aeb":"code","5385ed6f":"markdown","01b84a71":"markdown","44f4af2a":"markdown","a137c663":"markdown","bbafbfb7":"markdown","136f9b38":"markdown","94133083":"markdown","d3d41ee8":"markdown","d768caef":"markdown","90837f82":"markdown","3dec7f74":"markdown","31e720df":"markdown","e8e03d19":"markdown","2d4e0d38":"markdown","ff4a7277":"markdown","c59c2207":"markdown","5a5a8e2f":"markdown","36afa26e":"markdown","680ea8b8":"markdown","fd3760be":"markdown","4a417167":"markdown","06ba1c27":"markdown","358bdc35":"markdown"},"source":{"de04767f":"%load_ext autoreload\n%autoreload 2","57e20832":"%matplotlib inline\n\nfrom fastai.imports import *\nfrom fastai.structured import *\nfrom pandas_summary import DataFrameSummary\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier,GradientBoostingClassifier\nfrom IPython.display import display\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nimport seaborn as sns\nimport pylab as plot\nparams = { \n    'axes.labelsize': \"large\",\n    'xtick.labelsize': 'x-large',\n    'legend.fontsize': 20,\n    'figure.dpi': 150,\n    'figure.figsize': [10, 6]\n}\nplot.rcParams.update(params)","f39c2695":"PATH = \"..\/input\/\"\ntrain_raw=pd.read_csv(f'{PATH}train.csv',low_memory=False)\ntest_raw=pd.read_csv(f'{PATH}test.csv',low_memory=False)","b6b6c6db":"#check the size of the train and test data\n\ntrain_raw.shape, test_raw.shape","107aca0a":"#check if the data loaded properly\n\ntrain_raw.head()","f8c62c53":"train_raw.describe()","833efa67":"data = train_raw.copy()\ndata['Died']= 1 - data['Survived']","6250e951":"data.groupby('Sex').agg('sum')[['Survived','Died']].plot(kind='bar',stacked=True)","61ce04d8":"sns.violinplot(x='Sex', y='Age', hue='Survived',data=data,split=True)","b3e66073":"#Check the Fare ticket of each passagener and see how it impact the survival.\n\nfigure = plt.figure(figsize=(32,16))\nplt.hist([data[data['Survived'] == 1]['Fare'], data[data['Survived'] == 0]['Fare']], \n         stacked=True,\n         bins = 50, label = ['Survived','Dead'])\nplt.xlabel('Fare')\nplt.ylabel('Number of Passengers')\nplt.legend();","e90d7fd9":"#combining age, fare and survival in one chart.\n\nplt.figure(figsize=(25, 7))\nax = plt.subplot()\n\nax.scatter(data[data['Survived'] == 1]['Age'], data[data['Survived'] == 1]['Fare'], \n           c='green', s=data[data['Survived'] == 1]['Fare'])\nax.scatter(data[data['Survived'] == 0]['Age'], data[data['Survived'] == 0]['Fare'], \n           c='red', s=data[data['Survived'] == 0]['Fare']);","ea7334a1":"#ticket fare versues class\n\nax = plt.subplot()\nax.set_ylabel('Average fare')\ndata.groupby('Pclass').mean()['Fare'].plot(kind='bar',ax=ax)","5a51d7f3":"#Combining the test and train data to prepare the data for modeling.\n\nx_train = train_raw.drop(['Survived'],1)\ny_train = train_raw['Survived']\nx_test = test_raw","c37c85ff":"df_combined = x_train.append(x_test)\ndf_combined.shape","97b95a92":"df_combined.head()","e1898178":"def display_all(df):\n    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n        display(df)","7437ec71":"display_all(df_combined.tail().T)","885ecca2":"#train_cats module from fastai, which changes the strings in a dataframe to a \n#categorical values\n\ntrain_cats(df_combined)","34acf57b":"#Check the missing data %\ndisplay_all(df_combined.isnull().sum().sort_index()\/len(df_combined))","982d103e":"#proc_df takes a data frame df and splits off the response variable, and\n#changes the df into an entirely numeric dataframe. In this case am excluding the \n# fields in ignore_flds as they need further processing.\n\ndf,y,nas = proc_df(df_combined,y_fld=None,ignore_flds=['Age','Name','Embarked','Cabin','Parch',\n                                                      'SibSp'])\ndf.head()","d7ef53d1":"def process_family():\n    \n    global df\n    # introducing a new feature : the size of families (including the passenger)\n    df['FamilySize'] = df['Parch'] + df['SibSp'] + 1\n    \n    # introducing other features based on the family size\n    df['Singleton'] = df['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n    df['SmallFamily'] = df['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\n    df['LargeFamily'] = df['FamilySize'].map(lambda s: 1 if 5 <= s else 0)    \n    return df","06d8c37e":"df = process_family()","16bcff32":"def process_embarked():\n    global df\n    # two missing embarked values - filling them with the most frequent one in the train  set(S)\n    df.Embarked.fillna('S', inplace=True)\n    # dummy encoding \n    df_dummies = pd.get_dummies(df['Embarked'], prefix='Embarked')\n    df = pd.concat([df, df_dummies], axis=1)\n    df.drop('Embarked', axis=1, inplace=True)\n#     status('embarked')\n    return df","a119ac7e":"df = process_embarked()","6a3637ec":"def process_cabin():\n    global df    \n    # replacing missing cabins with U (for Uknown)\n    df.Cabin.fillna('T', inplace=True)\n    \n    # mapping each Cabin value with the cabin letter\n    df['Cabin'] = df['Cabin'].map(lambda c: c[0])\n    \n    # dummy encoding ...\n    cabin_dummies = pd.get_dummies(df['Cabin'], prefix='Cabin')    \n    df = pd.concat([df, cabin_dummies], axis=1)\n\n    df.drop('Cabin', axis=1, inplace=True)\n#     status('cabin')\n    return df","f9ca496c":"df = process_cabin()","c1f40770":"titles = set()\nfor name in df['Name']:\n    titles.add(name.split(',')[1].split('.')[0].strip())","29188820":"Title_Dictionary = {\n    \"Capt\": \"Officer\",\n    \"Col\": \"Officer\",\n    \"Major\": \"Officer\",\n    \"Jonkheer\": \"Royalty\",\n    \"Don\": \"Royalty\",\n    \"Sir\" : \"Royalty\",\n    \"Dr\": \"Officer\",\n    \"Rev\": \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Mme\": \"Mrs\",\n    \"Mlle\": \"Miss\",\n    \"Ms\": \"Mrs\",\n    \"Mr\" : \"Mr\",\n    \"Mrs\" : \"Mrs\",\n    \"Miss\" : \"Miss\",\n    \"Master\" : \"Master\",\n    \"Lady\" : \"Royalty\"\n}\n\ndef get_titles():\n    # we extract the title from each name\n    df['Title'] = df['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n    \n    # a map of more aggregated title\n    # we map each title\n    df['Title'] = df.Title.map(Title_Dictionary)\n#     status('Title')\n    return df","381fd456":"df = get_titles()\ndf.head()","40263b45":"#summarize the Age grouped by sex, class and title\ngrouped_train = df.groupby(['Sex','Pclass','Title'])\ngrouped_median_train = grouped_train.median()\ngrouped_median_train = grouped_median_train.reset_index()[['Sex', 'Pclass', 'Title', 'Age']]","e18fa488":"grouped_median_train.head()","b7b7506b":"df.head()","5156778c":"#Assing the value of age for missing values based on the group.\n#If a title is miising then the age will be assigned based on sex and class.\n\ndef fill_age(row):\n    condition = (\n        (grouped_median_train['Sex'] == row['Sex']) & \n        (grouped_median_train['Title'] == row['Title']) & \n        (grouped_median_train['Pclass'] == row['Pclass'])\n    ) \n    if np.isnan(grouped_median_train[condition]['Age'].values[0]):\n        print('true')\n        condition = (\n            (grouped_median_train['Sex'] == row['Sex']) & \n            (grouped_median_train['Pclass'] == row['Pclass'])\n        )\n\n    return grouped_median_train[condition]['Age'].values[0]\n\n\ndef process_age():\n    global df\n    # a function that fills the missing values of the Age variable\n    df['Age'] = df.apply(lambda row: fill_age(row) if np.isnan(row['Age']) else row['Age'], axis=1)\n#     status('age')\n    return df","ed38617e":"df = process_age()","a0efb7e9":"#Check for missing values.\n\ndisplay_all(df.isnull().sum().sort_index()\/len(df))","c46a37c5":"df[df.Title.isnull()]","cc8ed4a2":"def process_names():\n    global df\n    # we clean the Name variable\n    df.drop('Name', axis=1, inplace=True)\n    \n    # encoding in dummy variable\n    titles_dummies = pd.get_dummies(df['Title'], prefix='Title')\n    df = pd.concat([df, titles_dummies], axis=1)\n    \n    # removing the title variable\n    df.drop('Title', axis=1, inplace=True)\n    \n#     status('names')\n    return df","d3ce73f0":"df = process_names()","b2526fb9":"df.head()","2b2aba7d":"#Now no null vlaues\ndisplay_all(df.isnull().sum().sort_index()\/len(df))","e080576a":"#Seperate out the train & test data\n\nx_train = df[:891].copy()\nx_test = df[891:].copy()\nx_train.shape,x_test.shape","8a2b5f69":"#split the tarin data into train and valid set\ndef split_vals(a,n): return a[:n], a[n:]\nvalid_count =60\nn_trn = len(x_train)-valid_count\nx_train1, x_valid1 = split_vals(x_train, n_trn)\ny_train1, y_valid1 = split_vals(y_train, n_trn)","a85f7d3d":"x_train1.shape,y_train1.shape,x_valid1.shape,y_valid1.shape","77fc60ef":"m = RandomForestClassifier(n_estimators=180,min_samples_leaf=4,max_features=0.5,n_jobs=-1)\nm.fit(x_train1,y_train1)\nm.score(x_train1,y_train1)","bf96cbe2":"y_predict=m.predict(x_valid1)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_valid1,y_predict)","57b79b00":"from sklearn.metrics import classification_report, confusion_matrix\nprint(classification_report(y_valid1,y_predict))","e3ef8f2e":"#confusion Matrix\nprint(confusion_matrix(y_valid1,y_predict))","8fe5389c":"#Feature importance\nfi = rf_feat_importance(m, x_train1); fi[:10]","afa95851":"def plot_fi(fi): return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\nplot_fi(fi[:30]);","d488036d":"# Keeping only the variables which are significant for the model(>0.01)\nto_keep = fi[fi.imp>0.01].cols; len(to_keep)\nto_keep","ffc0e22a":"#Now training the model on the entire data with only the important features.\nx_train = x_train[to_keep]\nx_train","c2d819f3":"m = RandomForestClassifier(n_estimators=200,min_samples_leaf=3,max_features=0.5,n_jobs=-1)\nm.fit(x_train,y_train)\nm.score(x_train,y_train)","b1848459":"x_test = x_test[to_keep]\noutput=m.predict(x_test).astype(int)","edb6880d":"output.size","55dd1aeb":"# aux=pd.read_csv(f'{PATH}test.csv',low_memory=False)\n# df_output = pd.DataFrame()\n# df_output['PassengerId'] = aux['PassengerId']\n# df_output['Survived'] = output\n# df_output[['PassengerId','Survived']].to_csv(f'{PATH}titanic_fastai2.csv', index=False)","5385ed6f":"### Explore the data","01b84a71":"As we can see in the chart above, Women survive more than men, as decpicted bhy larger \nfemale green histogram.","44f4af2a":"From the above graph it is evident that male \npassengers are died.\n\n\nLet's correlate the age with the survival variable.","a137c663":"## Load the train & test data","bbafbfb7":"Size of the circles is proportional to the ticket fare.\nX-axis = AGE\nY-axis = Ticket_Fare\nGreen = Survived\nRed = Died\n\nSmall green dots between x=0 & x=7 : Children who were saved\nSmall red dots between x=10 & x=45 : adults who died and from a lower classes\nLarge green dots between x=20 & x=45 : Adults with larger ticket fares who are sruvived\n","136f9b38":"# Our final model!","94133083":"Above graph says passengers with cheaper ticket fares are more likely to die.","d3d41ee8":"### Model Evaluation","d768caef":"Visualize the survival based on the gender.","90837f82":"### On the Kaggle leaderborad this model achieved a score of 0.81339 ( Reached top 7%).","3dec7f74":"### Process Cabin","31e720df":"### Process Family","e8e03d19":"### Process Name","2d4e0d38":"### Save the output predictions in the requried format and submit it to Kaggle!!","ff4a7277":"### Get Title from Name","c59c2207":"####  We could notice that the score has increased after removing some featurs and training on the complete data.","5a5a8e2f":"### Process Embarked","36afa26e":"## Titanic Survival Challenge (Kaggle): A binary classification Problem\n\n### Used scikitlearn and fastai libraries for this task. ","680ea8b8":"### Process Age","fd3760be":"### Run the model on the test data","4a417167":"# Feature Engineering","06ba1c27":"## Build and trian the Model","358bdc35":"The count variable shows that 177 values are missing in the Age column. One solution is to fill in the null values with the median age. We could also impute with the mean age but the median is more robust to outlier."}}