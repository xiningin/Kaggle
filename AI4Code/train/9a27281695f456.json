{"cell_type":{"4fa40903":"code","352a0691":"code","182da702":"code","7c965aa7":"code","9722ef6b":"code","0aa182d7":"code","5f552821":"code","b36491a5":"code","50c63dbf":"code","d1714347":"code","6fb52111":"code","0f428663":"code","d44fa7d6":"code","1e5608d9":"markdown","82a47c20":"markdown","acf88ee9":"markdown","f3eea465":"markdown","e1871d95":"markdown","beed9114":"markdown","d4275c7c":"markdown","165d9341":"markdown"},"source":{"4fa40903":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt\n# Any results you write to the current directory are saved as output.\nimport warnings\n# filter warnings\nwarnings.filterwarnings('ignore')\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))","352a0691":"data = pd.read_csv(\"..\/input\/heart-disease\/heart.csv\")\ndata.head()\n","182da702":"data_x = data.drop([\"target\"],axis = 1)\ndata_x.head()","7c965aa7":"data_y = data.loc[:,[\"target\"]]\ndata_y.head()\n# if the target  Y \/ N instead of 1 and 0 we should use data.diagnosis = [1 if each == \"Y\" else 0 for each in data.diagnosis]\n","9722ef6b":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(data_x, data_y , test_size=0.15, random_state=42)\n","0aa182d7":"from sklearn import linear_model\nlogreg= linear_model.LogisticRegression(random_state = 42,max_iter= 50)\nprint(\"test accuracy: {} \".format(logreg.fit(X_train, Y_train).score(X_test, Y_test)))","5f552821":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 60)\nknn.fit(X_train,Y_train)\nprediction = knn.predict(X_test)\nprint(\"{} nn score  : {} \".format(60,knn.score(X_test,Y_test)))\nscore_list = [] \nfor each in range(1,150):\n    knn2 = KNeighborsClassifier(n_neighbors = each)\n    knn2.fit(X_train,Y_train)\n    score_list.append(knn2.score(X_test,Y_test))\n\n  \nplt.plot(range(1,150),score_list)\nplt.xlabel(\"k values\")\nplt.ylabel(\"accuracy\")\nplt.show()","b36491a5":"from sklearn.svm import SVC\nsvm = SVC(random_state = 1)\nprint(\"test accuracy: {} \".format(svm.fit(X_train, Y_train).score(X_test, Y_test)))","50c63dbf":"from sklearn.naive_bayes import GaussianNB\nnaive = GaussianNB()\nnaive.fit(X_train,Y_train)\nprint(\"test accuracy: {} \".format(naive.fit(X_train, Y_train).score(X_test, Y_test)))","d1714347":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt.fit(X_train,Y_train)\nprint(\"test accuracy: {} \".format(dt.score(X_test, Y_test)))","6fb52111":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 1000 , random_state = 1)\nrf.fit(X_train,Y_train)\nprint(\"test accuracy: {} \".format(rf.score(X_test, Y_test)))","0f428663":"y_true = Y_test\ny_head = rf.predict(X_test)\n\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_head)\nprint(cm)","d44fa7d6":"import seaborn as sns\nplt.figure(figsize = (7,7))\nsns.heatmap(cm,annot = True)\nplt.xlabel(\"y_head\")\nplt.ylabel(\"y_true\")","1e5608d9":"NA\u0130VE BAYAS","82a47c20":"**DES\u0130C\u0130ON TREES**","acf88ee9":"**SUPPORT VECTOR MACH\u0130NE**","f3eea465":"**LOG\u0130ST\u0130C REGRESS\u0130ON**","e1871d95":"**Visualazition confusion matrix**","beed9114":"**RANDOM FOREST**","d4275c7c":"**Evaluation with confusion matrix\n**","165d9341":"**KNN**"}}