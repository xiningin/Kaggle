{"cell_type":{"fe127536":"code","58b26624":"code","7ed61f7d":"code","45186116":"code","7f279851":"code","7f225a99":"code","f54ed8c5":"code","a8ba01e5":"code","94b119f1":"code","bfbc2282":"code","442f1a3d":"code","b6ef2f8e":"code","21a7ec4f":"code","592dd9be":"code","38a14f81":"code","76b0a1f9":"code","2a60b12e":"code","8c6345e0":"code","911c225d":"code","9e637023":"code","7c599c9e":"code","dd02b747":"code","ca8084f3":"code","9cd88b54":"code","14c862f7":"code","ccc392e1":"code","5acdcced":"code","300d6866":"code","e935a15d":"code","d8d5f572":"code","41c1f27a":"code","4a43f037":"code","ae1c3781":"code","62f83c98":"code","3a876a7d":"code","657b6e53":"code","5edea496":"code","889e5736":"code","5cced4e5":"code","15c105b8":"code","f2d11e06":"code","536fb59e":"code","fbff377f":"code","21dc5be5":"code","0eefd342":"code","b84ff970":"code","6eae1d39":"code","72567446":"code","9b101134":"code","d69a6eff":"code","996c3084":"code","4c8d08df":"markdown","e012b6f5":"markdown","1fced9d6":"markdown","54c10a52":"markdown","114ed791":"markdown","90add68a":"markdown","04ab259e":"markdown","d51c3727":"markdown","b32afa48":"markdown","c3854026":"markdown","bb514db9":"markdown","0ea2ed3a":"markdown","9dd78451":"markdown","ac8ac65b":"markdown","d77eb408":"markdown","fe90eb5f":"markdown","51c75853":"markdown"},"source":{"fe127536":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","58b26624":"import numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7ed61f7d":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom wordcloud import WordCloud, STOPWORDS\nimport glob\nimport plotly.graph_objs as go \nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n%matplotlib inline","45186116":"\nproduct_df = pd.read_csv('\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv')\n","7f279851":"product_df.head()","7f225a99":"product_df.describe()","f54ed8c5":"product_df.info()","a8ba01e5":"#dropping null objects\nproduct_df.dropna(inplace=True)","94b119f1":"pie=product_df.groupby('Sector(s)').count()[['LP ID']]\npie['percent'] = (pie['LP ID']\/pie['LP ID'].sum() *100)\nx=list(pie['percent'])\ny=[]\nfor i in x:\n    y.append(str(i))\npie","bfbc2282":"sns.set_style('darkgrid')\nplt.figure(figsize=(10,10))\n\nplt.pie(pie['LP ID'],labels=pie.index,explode=[0,0.4,0,0,0],colors = (\"blue\",\"cyan\",\"orange\",\"beige\",\"green\"),autopct='%1.1f%%')\n         \nplt.title(\"Sector(s) in which most Digital Learning providers are active in\")\nplt.legend(title=\"Sector(s):\")","442f1a3d":"plt.figure()\nplt.title(\"Active sectors\")\nplt.ylabel('Sector(s)')\nplt.xlabel('No. of providers')\nsns.barplot(x=list(pie['LP ID']),y=pie.index)","b6ef2f8e":"product_df[product_df['Sector(s)']=='Higher Ed; Corporate']['Product Name'],product_df[product_df['Sector(s)']=='Corporate']['Product Name']","21a7ec4f":"def pef1(data):\n    return data.split('-')[0]\ndef pef2(data):\n     return data.split('-')[0]+'-'+data.split('-')[1]\nproduct_df1 = product_df.sort_values(by='Primary Essential Function',axis=0)\nproduct_df1['PEF-1']=product_df['Primary Essential Function'].apply(pef1)\nproduct_df1['PEF-2']=product_df['Primary Essential Function'].apply(pef2)","592dd9be":"pef=product_df1.groupby('Primary Essential Function',sort=False).count()[['LP ID']]\npef['percent'] = (pef['LP ID']\/pef['LP ID'].sum() *100)","38a14f81":"pef.head()","76b0a1f9":"def pef1(data):\n    return data.split('-')[0]\ndef pef2(data):\n     return data.split('-')[0]+'-'+data.split('-')[1]\nproduct_df1 = product_df.sort_values(by='Primary Essential Function',axis=0)\nproduct_df1['PEF-1']=product_df['Primary Essential Function'].apply(pef1)\nproduct_df1['PEF-2']=product_df['Primary Essential Function'].apply(pef2)","2a60b12e":"product_df1.head()","8c6345e0":"pef1=product_df1.groupby('PEF-1',sort=False).count()[['LP ID']]\npef1['percent'] = (pef1['LP ID']\/pef1['LP ID'].sum() *100)","911c225d":"pef1","9e637023":"pef2=product_df1.groupby('PEF-2',sort=False).count()[['LP ID']]\npef2['percent'] = (pef2['LP ID']\/pef2['LP ID'].sum() *100)\n","7c599c9e":"sns.set_style('darkgrid')\nfig,ax = plt.subplots()\nax.axis('equal')\n\nplt.rcParams.update({'text.color' : \"black\",\n                     'axes.labelcolor' : \"black\"})\nplt.rcParams.update({'font.size': 15})\n\ncm, lc, other, sdo=[plt.cm.Blues, plt.cm.Reds, plt.cm.Greens, plt.cm.pink_r]\n\nax.pie(pef1['LP ID'],labels=pef1.index,colors=[cm(0.6) , lc(0.6) , other(0.8) , sdo(0.6)],autopct='%1.1f%%', radius=10,explode=[0,0,0,0])\nax.pie(pef2['LP ID'],labels=pef2.index,colors=[cm(0.2),cm(0.4),cm(0.6),lc(0.5),lc(0.1),lc(0.2),lc(0.3),lc(0.4),lc(0.5),lc(0.6),lc(0.7),lc(0.8),lc(0.9),other(0.5),sdo(0.1),sdo(0.2),sdo(0.3),sdo(0.4),sdo(0.5),sdo(0.6),sdo(0.7),sdo(0.8),sdo(0.9)], autopct='%1.1f%%', radius=8)\n                  \nplt.title(\"Primary Essential Functions\",fontdict={'fontsize':50})\nax.legend(loc='lower right',bbox_to_anchor=(-2,1.5))\nplt.subplots_adjust(left=0.0, bottom=0.1, right=0.85)","dd02b747":"#Plotting a bar graph based on the pie chart above for better understanding\nplt.figure()\nplt.title(\"Most Common Primary Essential Functions\")\nplt.ylabel('Primary Essential Functions')\nplt.xlabel('No. of providers')\nsns.barplot(x=list(pef1['LP ID']),y=pef1.index)","ca8084f3":"plt.figure(figsize=(10,10))\nplt.title(\"Most Common Primary Essential Functions\")\nplt.ylabel('Primary Essential Functions')\nplt.xlabel('No. of providers')\nsns.barplot(x=list(pef2['LP ID']),y=pef2.index)","9cd88b54":"more_than1 = product_df1.groupby('Provider\/Company Name').count()[['Product Name','Primary Essential Function']]","14c862f7":"more_than1 = more_than1[more_than1['Product Name']>1]","ccc392e1":"plt.figure(figsize=(10,10))\nplt.rcParams.update({'font.size': 10})\nplt.title(\"Companies with most products in the Digital Learning Industry\")\nplt.ylabel('Companies')\nplt.xlabel('No. of products')\nsns.barplot(x=list(more_than1['Product Name']),y=more_than1.index)\n","5acdcced":"cloud = WordCloud(width=1440, height=1080).generate(\" \".join(product_df['Product Name'].astype(str)))\nplt.figure(figsize=(15, 10))\nplt.imshow(cloud)\nplt.axis('off')","300d6866":"cloud = WordCloud(width=1440, height=1080).generate(\" \".join(product_df['Provider\/Company Name'].astype(str)))\nplt.figure(figsize=(15, 10))\nplt.imshow(cloud)\nplt.axis('off')","e935a15d":"google_df = product_df1[product_df1['Provider\/Company Name']=='Google LLC']\ngoogle_df","d8d5f572":"gpie=google_df.groupby('Sector(s)').count()[['LP ID']]\ngpie['percent'] = (gpie['LP ID']\/gpie['LP ID'].sum() *100)\nx=list(gpie['percent'])\ny=[]\nfor i in x:\n    y.append(str(i))\ngpie\n","41c1f27a":"plt.figure(figsize=(10,10))\n\nplt.pie(gpie['LP ID'],labels=gpie.index,explode=[0,0,0.4],colors = (\"beige\",\"cyan\",\"orange\",\"beige\",\"green\"),autopct='%1.1f%%')\n         \nplt.title(\"Sector(s) in which Google is active in\")\nplt.legend(title=\"Sector(s):\")","4a43f037":"plt.figure()\nplt.title(\"Active sectors\")\nplt.ylabel('Sector(s)')\nplt.xlabel('No. of providers')\nsns.barplot(x=list(gpie['LP ID']),y=gpie.index)","ae1c3781":"gpef1=google_df.groupby('PEF-1',sort=False).count()[['LP ID']]\ngpef1['percent'] = (gpef1['LP ID']\/gpef1['LP ID'].sum() *100)\ngpef1","62f83c98":"gpef2=google_df.groupby('PEF-2',sort=False).count()[['LP ID']]\ngpef2['percent'] = (gpef2['LP ID']\/gpef2['LP ID'].sum() *100)","3a876a7d":"sns.set_style('darkgrid')\nfig,ax = plt.subplots()\nax.axis('equal')\n\nplt.rcParams.update({'text.color' : \"black\",\n                     'axes.labelcolor' : \"black\"})\nplt.rcParams.update({'font.size': 15})\n\ncm, lc, other, sdo=[plt.cm.Blues, plt.cm.Reds, plt.cm.Greens, plt.cm.pink_r]\n\nax.pie(gpef1['LP ID'],labels=gpef1.index,colors=[cm(0.6) , lc(0.6) , other(0.8) , sdo(0.6)],autopct='%1.1f%%', radius=10,explode=[0,0,0,0])\nax.pie(gpef2['LP ID'],labels=gpef2.index,colors=[cm(0.2),cm(0.4),lc(0.1),lc(0.2),lc(0.3),lc(0.4),other(0.5),sdo(0.3),sdo(0.4)], autopct='%1.1f%%', radius=8)\n                  \nplt.title(\"Primary Essential Functions\",fontdict={'fontsize':50})\nax.legend(loc='lower right',bbox_to_anchor=(-2,1.5))\nplt.subplots_adjust(left=0.0, bottom=0.1, right=0.85)","657b6e53":"plt.figure(figsize=(10,10))\nplt.title(\"Google's Most Common Primary Essential Functions\")\nplt.ylabel('Primary Essential Functions')\nplt.xlabel('No. of providers')\nsns.barplot(x=list(gpef2['LP ID']),y=gpef2.index)","5edea496":"plt.figure(figsize=(15,10))\npef1['G percent'] = gpef1['percent']\nplt.plot(pef1[\"percent\"],label='All companies',marker='.')\nplt.plot(gpef1[\"percent\"],label='Google',marker='*')\nplt.title(\"Comparison of Google with other Edtech Companies\")\nplt.xlabel('Primary Essential Functions')\nplt.ylabel('Percentage of company in this domain')\nplt.legend()","889e5736":"district_df = pd.read_csv('\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv')\n                          \n                          ","5cced4e5":"district_df.head()","15c105b8":"district_df.info()","f2d11e06":"district_df.shape","536fb59e":"(district_df['pp_total_raw'][0])","fbff377f":"district_df.locale.unique()","21dc5be5":"cloud = WordCloud(width=1440, height=1080).generate(\" \".join(district_df['state'].dropna().astype(str)))\nplt.figure(figsize=(15, 10))\nplt.imshow(cloud)\nplt.axis('off')","0eefd342":"states = district_df.groupby(by ='state').count()[['district_id']]","b84ff970":"#abbreviations of all the US States\nus_state_abbrev = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}","6eae1d39":"codes = []\nfor i in states.index:\n    codes.append(us_state_abbrev[i])\nprint(codes)","72567446":"data = dict(\n        type = 'choropleth',\n        colorscale = 'portland',\n        locations = codes,\n        locationmode = 'USA-states',\n        z = list(states['district_id']),\n        text = states.index,\n        colorbar = {'title':'States'},\n      )\nlayout = dict(title = 'States',\n              geo = dict(projection = {'type':'mercator'})\n             )\nlayout = dict(geo = {'scope':'usa'})\n\nchoromap = go.Figure(data = [data],layout = layout)\niplot(choromap)","9b101134":"plt.figure(figsize=(10,10))\nplt.title(\"States with most Districts Mentioned\")\nplt.ylabel('States')\nplt.xlabel('No. of districts mentioned')\nsns.barplot(x=list(states['district_id']),y=states.index)","d69a6eff":"data_path = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data' \ncsv_files = glob.glob(data_path + \"\/*.csv\")\n\ndfs = []\n\nfor filename in csv_files:\n    df = pd.read_csv(filename, index_col=None, header=0)\n    district_id = filename.split(\"\/\")[4].split(\".\")[0]\n    df[\"district_id\"] = district_id\n    dfs.append(df)\n    \nengagement_df = pd.concat(dfs)\nengagement_df = engagement_df.reset_index(drop=True)\nengagement_df.head()","996c3084":"product_df.head()","4c8d08df":"## Exploratory Data Analysis","e012b6f5":"# PRODUCT INFO \n## Understanding the data\n\nThe product file products_info.csv includes information about the characteristics of the top 372 products with most users in 2020. The categories listed in this file are part of LearnPlatform's product taxonomy. Data were labeled by our team. Some products may not have labels due to being duplicate, lack of accurate url or other reasons.\n\n**Each Column:**\n\n$LP ID$:The unique identifier of the product\n\n$URL$:Web Link to the specific product\n\n$Product Name$:Name of the specific product\n\n$Provider\/Company Name$:Name of the product provider\n\n$Sector(s)$:Sector of education where the product is used\n\n$Primary Essential Function$:The basic function of the product. There are two layers of labels here. Products are first labeled as one of these three categories: *`LC` = Learning & Curriculum, `CM` = Classroom Management, and `SDO` = School & District Operations. Each of these categories have **multiple sub-categories** with which the products were labeled*\n","1fced9d6":"# ENGAGEMENT DATAFRAME","54c10a52":"**Except for two providers all the other providers are concerned about `PreK-12`**\n\n>`Qualtrics` : *Deals with Higher Ed & Corporates*\n\n> `Weebly`   : *Deals only with Corporates*","114ed791":"**Strategy of Google is different from the rest of the companies in this domain.\nAs we can see in the plot above.**","90add68a":"Here we finish the analysis of our first dataset.\n\n## Findings:\n\n1. Each sector had a fair share of products in it's domain , with 48.3 percent primarily focusing on PreK_12.\n2. It seems likely that every product built it's way up the ladder, i.e. it was built for PreK-12 ,then used for Higher Education and then for corporate.\n3. There is only one product each that focuses just on Higher Education and Corporates.\n4. The pie chart makes it clear that mostly all products(77.3%) focused on learning and curriculum building.\n5. The subsections can be easily observed in the pie chart above.\n6. An interesting finding was that even though other companies had no more than 5 products in this domain yet , Google took a giant leap and managed to launch 27 different products.\n7. On further interrogation of the dataset, another interesting thing was observed, although Google still has majority (48.1%) of it's product focusing on learning, the company showed big divergence from the general trend in the other two domains.\n>*  22.2 percent of Google products focused on Classroom Management , compared to 9.7% in general.\n>* 6 out of 34 products in the Classroom Management domain are from Google\n\n\nLet us explore the other two datasets and finally explore if we can *combine the findings of all 3 datasets.*\n","04ab259e":"Let us find out which sector(s) do most companies deal with **`Sectors`**","d51c3727":"## Let's Analyse the companies that have more than one product","b32afa48":"**`Primary Essential Function` : The main objective of the company\/provider**\n\nWe first need to understand the following key words.\n\n1. $LC :  Learning & Curriculum$\n\n2. $CM :  Classroom Management & others$\n\n3. $SDO = School & District Operations$\n\n\n\n","c3854026":"*Apart from words like Learning and Education , which may be common in the names of most Edtech companies, Google LLC is the biggest , most significant organization in this domain*","bb514db9":"Since we need the state shortforms like AZ for arizona, we need to make some changes in the dataset.\n\n**We need to use additional Data**","0ea2ed3a":"## Understanding the pie chart above\nThe *`pie chart`* above represents $PrimaryEssentialFunctions$\n\nThere is an inner pie and an outer pie. The outer pie has 4 major slices and the slices in the inner pie are the subslices of the of major slices with same colour group in the outer pie.\n\ne.g. `CM - Classroom Engagement & Instruction` (shade of blue)\n`CM - Teacher Resources` (shade of blue)\n`CM - Virtual Classroom` (shade of blue)  are the subslices of `CM` (in blue)\n\nThe outer pie is divided into 4 sections (IN COUNTERCLOCKWISE DIRECTION) representing:\n1. `CM in blue`   : 9.7% (with 3 subsections in the inner pie)\n2. `LC in red`    : 77.3% (with 10 subsections in the inner pie)\n3. `All in green` : 4.5% (with 1 subsections in the inner pie)\n4. `SDO in brown` : 8.5% (with 9 subsections in the inner pie)\n\nIt is very clear that 81.8% new companies offer primarily **Learning and curriculum**.\n>77.3 directly related to LC and 4.5 related to all\n\nIt is followed by **Classroom management** and **School & district Operation**\n\n\nPS: Please zoom into the pie chart for better understanding","9dd78451":"While most companies have struggled to put forward 5 products , `Google LLC` has surprisingly put up **$27$ products**, establishing itself head and shoulder above the rest.\n\nIt would be interesting to analyse the products of `Google` and their domains","ac8ac65b":"# DISTRICT INFORMATION DATA\n\n## Understanding the data\n\nThe district file districts_info.csv includes information about the characteristics of school districts, including data from NCES (2018-19), FCC (Dec 2018), and Edunomics Lab. In this data set, we removed the identifiable information about the school districts. We also used an open source tool ARX (Prasser et al. 2020) to transform several data fields and reduce the risks of re-identification. For data generalization purposes some data points are released with a range where the actual value falls under. Additionally, there are many missing data marked as 'NaN' indicating that the data was suppressed to maximize anonymization of the dataset.\n\n**district_id** : The unique identifier of the school district\n\n**state** : The state where the district resides in\n\n**locale** : NCES locale classification that categorizes U.S. territory into four types of areas: City, Suburban, Town, and Rural. See Locale Boundaries User's Manual for more information.\n\n**pct_black\/hispanic** : Percentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES data\n\n**pct_free\/reduced** : Percentage of students in the districts eligible for free or reduced-price lunch based on 2018-19 NCES data\n\n**countyconnectionsratio** : ratio (residential fixed high-speed connections over 200 kbps in at least one direction\/households) based on the county level data from FCC From 477 (December 2018 version). See FCC data for more information.\n\n**pptotalraw** : Per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource Database on Schools (NERD$) project. The expenditure data are school-by-school, and we use the median value to represent the expenditure of a given school district.","d77eb408":"## Google LLC Product Analysis\n","fe90eb5f":"# COVID-19'S IMPACT ON DIGITAL LEARNING\n\nBy :- $Arihant Jha$                 \n\nDate: $August 3,2021$\n\n## OVERVIEW\n\n\nThe COVID-19 Pandemic has disrupted learning for more than 56 million students in the United States. In the Spring of 2020, most states and local governments across the U.S. closed educational institutions to stop the spread of the virus. In response, schools and teachers have attempted to reach students remotely through distance learning tools and digital platforms. Until today, concerns of the exacaberting digital divide and long-term learning loss among America\u2019s most vulnerable learners continue to grow.\n\nI intend to analyse 3 different datasets `product_info` , `districts_info` and `engagement_data` in that order and find insighst.\n\n## OBJECTIVE\n\n **to explore**:\n \n *(1) the state of digital learning in 2020*\n \n *(2) how the engagement of digital learning relates to factors such as district demographics, broadband access, and state\/national level policies and events.*","51c75853":"`Sector(s)` and `Primary Essential Function` are the two columns I will primarily focus on to draw insights about the direction in which the Digital Learning Industry is going."}}