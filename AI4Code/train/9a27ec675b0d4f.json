{"cell_type":{"d587e6f8":"code","93f7c236":"code","9aac97e4":"code","11c8e534":"code","b369b0a8":"code","89946e4e":"code","9107b7d0":"code","6b1af492":"code","7809697b":"code","69c805a3":"code","def9eaf9":"code","4882aa1d":"code","4ee7e95a":"code","efe3e68a":"code","5544a615":"code","627bd919":"code","5e5699c0":"code","d52808fb":"markdown","39577f6e":"markdown","2f8d2fd1":"markdown","4c7838ef":"markdown","8ef9a1c4":"markdown","b690eba5":"markdown","44fb90af":"markdown","c56ae5ce":"markdown"},"source":{"d587e6f8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.express as px\n\nfrom pathlib import Path\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, r2_score\n\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","93f7c236":"positive_dir = Path('..\/input\/surface-crack-detection\/Positive')\nnegative_dir = Path('..\/input\/surface-crack-detection\/Negative')","9aac97e4":"def generate_df(img_dir, label):\n    \n    file_paths = pd.Series(list(img_dir.glob(r'*.jpg')), name='Filepath').astype(str)\n    labels = pd.Series(label, name='Label', index=file_paths.index)\n    df = pd.concat([file_paths, labels], axis=1)\n    \n    return df","11c8e534":"positive_df = generate_df(positive_dir, 'POSITIVE')\nnegative_df = generate_df(negative_dir, 'NEGATIVE')\n\n# concatenate both positive and negative df\nall_df = pd.concat([positive_df, negative_df], axis=0).sample(frac=1, random_state=1).reset_index(drop=True)\n\nall_df.head()","b369b0a8":"train_df, test_df = train_test_split(all_df.sample(6000, random_state=1), \n                train_size=0.7,\n                shuffle=True,\n                random_state=1)","89946e4e":"train_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255,\n                                                           validation_split=0.2)\n\ntest_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)","9107b7d0":"train_data = train_gen.flow_from_dataframe(train_df, \n                                          x_col='Filepath',\n                                          y_col='Label',\n                                          target_size=(120,120), \n                                          color_mode='rgb',\n                                          class_mode='binary',\n                                          batch_size=32,\n                                          shuffle=True,\n                                          seed=42,\n                                          subset='training')\n\n\nval_data = train_gen.flow_from_dataframe(train_df, \n                                          x_col='Filepath',\n                                          y_col='Label',\n                                          target_size=(120,120), \n                                          color_mode='rgb',\n                                          class_mode='binary',\n                                          batch_size=32,\n                                          shuffle=True,\n                                          seed=42,\n                                          subset='validation')\n\n\ntest_data = test_gen.flow_from_dataframe(test_df, \n                                          x_col='Filepath',\n                                          y_col='Label',\n                                          target_size=(120,120), \n                                          color_mode='rgb',\n                                          class_mode='binary',\n                                          batch_size=32,\n                                          shuffle=False,\n                                          seed=42)","6b1af492":"inputs = tf.keras.Input(shape=(120,120,3))\nx = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu')(inputs)\nx = tf.keras.layers.MaxPool2D(pool_size=(2,2))(x)\nx = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\nx = tf.keras.layers.MaxPool2D(pool_size=(2,2))(x)\n\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)","7809697b":"model = tf.keras.Model(inputs=inputs, outputs=outputs)","69c805a3":"model.compile(optimizer='adam',\n             loss='binary_crossentropy',\n             metrics=['accuracy'])","def9eaf9":"# print model summary\nmodel.summary()","4882aa1d":"history = model.fit(train_data, validation_data=val_data, epochs=100, \n                   callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                              patience=3,\n                                                              restore_best_weights=True)\n                             ])","4ee7e95a":"fig = px.line(history.history,\n             y=['loss', 'val_loss'],\n             labels={'index':'Epoch'},\n             title='Training and Validation Loss over Time')\n\nfig.show()","efe3e68a":"def evaluate_model(model, test_data):\n    \n    results = model.evaluate(test_data, verbose=0)\n    loss = results[0]\n    accuracy = results[1]\n    \n    print(f'Test Loss {loss:.5f}')\n    print(f'Test Accuracy {accuracy * 100:.2f} %')\n    \n    \n    # predicted y values\n    y_pred = np.squeeze((model.predict(test_data) >= 0.5).astype(np.int))\n    y_certain = np.squeeze((model.predict(test_data)).astype(np.int))\n    \n    conf_matr = confusion_matrix(test_data.labels, y_pred)\n    \n    class_report = classification_report(test_data.labels, y_pred,\n                                         target_names=['NEGATIVE', 'POSITIVE'])\n    \n    plt.figure(figsize=(6,6))\n    \n    sns.heatmap(conf_matr, fmt='g', annot=True, cbar=False, vmin=0, cmap='Blues')\n    \n    plt.xticks(ticks=np.arange(2) + 0.5, labels=['NEGATIVE', 'POSITIVE'])\n    plt.yticks(ticks=np.arange(2) + 0.5, labels=['NEGATIVE', 'POSITIVE'])\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title('Confusion Matrix')\n    plt.show()\n    \n    print('r2 Score : ', r2_score(test_data.labels, y_pred))\n    print()\n    print('Classification Report :\\n......................\\n', class_report)","5544a615":"evaluate_model(model, test_data)","627bd919":"def test_new_data(dir_path):\n    \n    new_test_dir = Path(dir_path)\n    \n    df_new = generate_df(new_test_dir, 'Testing')\n    \n    test_data_new = test_gen.flow_from_dataframe(df_new, \n                                          x_col='Filepath',\n                                          y_col='Label',\n                                          target_size=(120,120), \n                                          color_mode='rgb',\n                                          batch_size=5,\n                                          shuffle=False,\n                                          seed=42)\n    \n        # predicted y values\n    y_pred = np.squeeze((model.predict(test_data_new) >= 0.5).astype(np.int))\n    \n    \n    y_certain = model.predict(test_data_new).round(6)\n    y_out = []\n    for i in y_pred:\n        if i==0:\n            y_out.append('Negative (Not Crack)')\n        else:\n            y_out.append('Positive(Crack) ')\n            \n    result = pd.DataFrame(np.c_[y_out, y_certain], columns=['Result', 'Confidance of being Cracked'])\n    \n    return result","5e5699c0":"results = test_new_data()","d52808fb":"## Training DataSet","39577f6e":"## Testing New DataSet","2f8d2fd1":"## put yout directory path below\n\n","4c7838ef":"## Plotting","8ef9a1c4":"## Loading Image Data","b690eba5":"## Split the DataSet","44fb90af":"## Final Results","c56ae5ce":"## Creating DataFrames"}}