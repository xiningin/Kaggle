{"cell_type":{"9dea78fb":"code","65354f3c":"code","a6d8ae9f":"code","ee668d4d":"code","d5748e7d":"code","bbf4edca":"code","93173794":"code","ba3364cd":"code","c3b219e5":"code","ca498c84":"code","c184029b":"code","407fe085":"markdown","1c6f3341":"markdown","e1620724":"markdown","70f038f2":"markdown"},"source":{"9dea78fb":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.feature_selection import f_regression","65354f3c":"data = pd.read_csv(\"..\/input\/heart-disease\/heart.csv\").dropna()","a6d8ae9f":"X = data.drop( labels=\"target\", axis=1 )\ny = data[\"target\"]","ee668d4d":"f_regression(X, y)","d5748e7d":"X = X.drop( labels=X.columns[3:5], axis=1 )\nX.corr()","bbf4edca":"regModel = LinearRegression().fit(X, y)","93173794":"print( \"R^2=\"+str(regModel.score(X, y)) )","ba3364cd":"newX = []\nfor i in X.index:\n    newX.append( X.loc[i].to_list()+np.power(X.loc[i].to_list(), 2) )\nregModel.fit(newX, y)\nprint( \"R^2=\"+str(regModel.score(X, y)) )","c3b219e5":"from sklearn import tree\ntreeRegressor = tree.DecisionTreeRegressor(\n    min_samples_leaf=10\n).fit(X, y)\ntreeClassifier = tree.DecisionTreeClassifier(\n    min_samples_leaf=10,\n    max_leaf_nodes=2\n).fit(X, y)","ca498c84":"print( \"R^2 for tree regression: \"+str(treeRegressor.score(X, y)) )\nprint( \"R^2 for tree classification: \"+str(treeClassifier.score(X, y)) )","c184029b":"tree.plot_tree(treeClassifier)","407fe085":"As we see linear regression model is not very good. Let's try to build quadratic regression model.","1c6f3341":"As we see, **classification using tree classifier is good**. So **it's a reason to use it for predicting disease** using this data.","e1620724":"Building of regression model.","70f038f2":"As we see, linear regression model is the best variant of regression model. Now let's try to find better model for prediction."}}