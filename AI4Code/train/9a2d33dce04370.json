{"cell_type":{"f7f89801":"code","a4ec2a15":"code","936d90a8":"code","b84010aa":"code","95f16189":"code","531ad3fc":"code","d6774a19":"code","3ab30922":"code","0024de55":"code","b94c99b7":"code","08b1c051":"code","c123096a":"code","28d55cf7":"code","76ad9974":"code","166c181d":"code","1f33d73c":"code","9b5c731f":"code","a5d05118":"code","654170f7":"code","b120ef6b":"code","bbbb5591":"code","17d044ad":"code","71de9a0e":"code","3651f3ef":"code","8f268e16":"code","f06e6652":"code","2651cfb5":"code","133c73b0":"code","0b66e00b":"code","983784f5":"code","334c0ba8":"code","ee7f5656":"code","0321e013":"code","2e6a726c":"code","aa657ccf":"code","c7fa4ad3":"code","413bae9c":"code","cf1ee7d0":"markdown","deb845ac":"markdown","f6eba2e1":"markdown","d0b4253f":"markdown","1fd61bea":"markdown","7d3711c7":"markdown","e891a093":"markdown","cfe3d30d":"markdown","1d50656b":"markdown","b3b5b0cd":"markdown","faf8fb1a":"markdown","b1e5e9e0":"markdown","2376128e":"markdown","bdab94ad":"markdown","a76c859d":"markdown","4d85f573":"markdown","2eedcb29":"markdown","b58d42d4":"markdown","d7c6621a":"markdown","7a6b511e":"markdown","b9ff450b":"markdown","11731159":"markdown","321a44ca":"markdown","2dacf49a":"markdown","7538234b":"markdown"},"source":{"f7f89801":"%matplotlib inline     \n!pip install \"torch==1.4\" \"torchvision==0.5 \" # To avoid warning error for each and every image in the dataset ","a4ec2a15":"from fastai import *\nfrom fastai.vision import *\nfrom fastai.callbacks.hooks import *\n\nimport os\nimport io\nimport tarfile\nimport numpy as np\nimport PIL\nimport seaborn as sns\n","936d90a8":"sPath = Path(\"..\/input\/skincancer\/datatree\/train\")","b84010aa":"classes = os.listdir(\"..\/input\/skincancer\/datatree\/train\")\nprint(classes)","95f16189":"for c in classes:\n  verify_images(sPath\/c, delete = True, max_workers=16)","531ad3fc":"np.random.seed(8)\nsrc = (ImageList.from_folder(sPath)\n  .split_by_rand_pct(valid_pct = 0.2)\n  .label_from_folder())","d6774a19":"\ntfdm = get_transforms(max_rotate = 25, max_zoom = 1.3, max_warp = 0.4)","3ab30922":"  data = (src.transform(tfdm,size = 150)\n    .databunch(bs = 124) # initializing the batch size\n    .normalize(imagenet_stats))# normalizing \n  data.show_batch(rows = 3, figsize = (8,8))","0024de55":"learner50 = cnn_learner(data, models.resnet50, metrics = accuracy)\nlearner50.model_dir = \"\/kaggle\/working\/\"","b94c99b7":"learner50.lr_find()\nlearner50.recorder.plot()","08b1c051":"lr = 1e-02","c123096a":"learner50.fit_one_cycle(10, max_lr = slice(lr))","28d55cf7":"learner50.recorder.plot_losses()","76ad9974":"learner50.save('\/kaggle\/working\/resenet50-prototype1')","166c181d":"interp = ClassificationInterpretation.from_learner(learner50)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)\n","1f33d73c":"interp.plot_top_losses(9, figsize=(15,11))","9b5c731f":"interp.plot_confusion_matrix(figsize=(12,12), dpi=60)\n","a5d05118":"interp.most_confused(min_val=2)","654170f7":"learner50.unfreeze() \nlearner50.lr_find() \nlearner50.recorder.plot() ","b120ef6b":"learner50.fit_one_cycle(3, max_lr = slice(1e-4, lr\/4))","bbbb5591":"learner50.save('\/kaggle\/working\/resnet50_prototype-2')","17d044ad":"learner50.recorder.plot_losses() #loss visualization\n","71de9a0e":"\ninterp = ClassificationInterpretation.from_learner(learner50)\n","3651f3ef":"interp.most_confused(min_val=1) #list of wrongly predicted classes \n","8f268e16":"test_path = '..\/input\/skincancer\/datatree\/validation\/'\n","f06e6652":"test_Data = (ImageList.from_folder(test_path)\n       .split_by_rand_pct(valid_pct=0.2)\n       .label_from_folder()\n       .transform(size=150)\n       .databunch(bs=64))\n","2651cfb5":"test_Data.show_batch(rows=3)\n","133c73b0":"pred, y = learner50.get_preds()\n","0b66e00b":"pred","983784f5":"y","334c0ba8":"pred = pred.argmax(dim = 1)","ee7f5656":"pred","0321e013":"test_Data.classes","2e6a726c":"from sklearn.metrics import classification_report\n\nprint(classification_report(y, pred))\n","aa657ccf":"img = open_image('..\/input\/imagefile1\/1_R6N4Bi2slLO0p59g41dCcQ.jpeg')\nimg","c7fa4ad3":"learner50 = load_learner('..\/input\/pickle-file\/')","413bae9c":"pred_class,pred_idx,outputs = learner50.predict(img)\nif(pred_class == tensor(0)):\n  print(\"Actinic Keratoses\")\nelif(pred_class == tensor(1)):\n  print(\"Basal cell carcinoma\")\nelif(pred_class == tensor(2)):\n  print(\"Benign keratosis\")\nelif(pred_class == tensor(3)):\n  print(\"Dermatofibroma\")\nelif(pred_class == tensor(4)):\n  print(\"Melanoma\")\nelif(pred_class == tensor(5)):\n  print(\"Melanocytic nevi \")\nelif(pred_class == tensor(6)):\n  print(\"Vascular skin lesions \")","cf1ee7d0":"### Acuracy on a pre-trained model is 82%\n\n### Loss analyzing ","deb845ac":"### Choosing a learning rate from the above graph.\nThe loss is very high when the learning rate is 0.06 and gradually the loss decreases with respect to the decrease in the learning rate. Untill 0.01 we hit with a decrease in the loss and after that the loss increased, so a learing rate between 0.06 and 0.01 is chossen. ","f6eba2e1":"### Melanoma is classified as Melanocytic nevi 45 times in transfer learning model. ","d0b4253f":"### Training the entire layers of the architecture","1fd61bea":"### The confusion matrix gives us Visualization of the algorithm's performance","7d3711c7":"### Splitting train and validation set","e891a093":"### Data Augmentation \nWe only have 10000 images, which is insufficient for training. Through augmentation the number of images are increased. The fuction in fastai get_transforms does the augmentation for us with the given values. ","cfe3d30d":"### Melanoma is misclassified as Melanocytic nevi 59 times ","1d50656b":"### A trail run to find the most appropriate learning rate","b3b5b0cd":"## Step 3 - Training on Pre-trained model\n\n### Downloading Resnet50 Pre-trained model ","faf8fb1a":"## **Step 5** - Evaluvation\n### Prediction over the test data","b1e5e9e0":"### The notebook will be explained under 6 different steps \n1. Importing necessary packages\n2. Data Preprocessing\n3. Training on Pre-trained model\n4. Custom Model \n5. Evaluvation\n6. Testing","2376128e":"# SKIN CANCER CLASSIFICATION\n### Introduction \nSkin cancers are diagonised with human eyes. The subtle difference in the lesion type is categorized into a type of cancer after a dermoscopic analysis. This notebook explains about training a neural network to classify different types of cancer. I have used fastai library, to know more about that(https:\/\/course.fast.ai\/videos\/?lesson=1). \n>  The HAM10000(human against machine with 10000 training images) (https:\/\/arxiv.org\/abs\/1803.10417). It consists of 10015 dermatoscopicimages which are released as a training set for academic machine learning purposes \n#### 7 different types considered for calssification\n1. Melanocytic nevi\n>   Melanocytic nevi are benign neoplasms of melanocytes and appear in a myriad of variants, which all are included in our series. The variants may differ significantly from a dermatoscopic point of view.\n[6705 images]\n2. Melanoma\n>   Melanoma is a malignant neoplasm derived from melanocytes that may appear in different variants. If excised in an early stage it can be cured by simple surgical excision. Melanomas can be invasive or non-invasive (in situ). We included all variants of melanoma including melanoma in situ, but did exclude non-pigmented, subungual, ocular or mucosal melanoma.\n[1113 images]\n3. Benign keratosis-like lesions\n>   \"Benign keratosis\" is a generic class that includes seborrheic ker- atoses (\"senile wart\"), solar lentigo - which can be regarded a flat variant of seborrheic keratosis - and lichen-planus like keratoses (LPLK), which corresponds to a seborrheic keratosis or a solar lentigo with inflammation and regression [22]. The three subgroups may look different dermatoscop- ically, but we grouped them together because they are similar biologically and often reported under the same generic term histopathologically. From a dermatoscopic view, lichen planus-like keratoses are especially challeng- ing because they can show morphologic features mimicking melanoma [23] and are often biopsied or excised for diagnostic reasons.\n[1099 images]\n4. Basal cell carcinoma\n>   Basal cell carcinoma is a common variant of epithelial skin cancer that rarely metastasizes but grows destructively if untreated. It appears in different morphologic variants (flat, nodular, pigmented, cystic, etc) [21], which are all included in this set.\n[514 images]\n5. Actinic keratoses\n>   Actinic Keratoses (Solar Keratoses) and intraepithelial Carcinoma (Bowen\u2019s disease) are common non-invasive, variants of squamous cell car- cinoma that can be treated locally without surgery. Some authors regard them as precursors of squamous cell carcinomas and not as actual carci- nomas. There is, however, agreement that these lesions may progress to invasive squamous cell carcinoma - which is usually not pigmented. Both neoplasms commonly show surface scaling and commonly are devoid of pigment. Actinic keratoses are more common on the face and Bowen\u2019s disease is more common on other body sites. Because both types are in- duced by UV-light the surrounding skin is usually typified by severe sun damaged except in cases of Bowen\u2019s disease that are caused by human papilloma virus infection and not by UV. Pigmented variants exists for Bowen\u2019s disease [19] and for actinic keratoses [20]. Both are included in this set.\n[327 images]\n6. Vascular lesions\n>   Vascular skin lesions in the dataset range from cherry angiomas to angiokeratomas [25] and pyogenic granulomas [26]. Hemorrhage is also included in this category.\n[142 images]\n7. Dermatofibroma\n>   Dermatofibroma is a benign skin lesion regarded as either a benign proliferation or an inflammatory reaction to minimal trauma. It is brown often showing a central zone of fibrosis dermatoscopically [24].\n[115 images]\n\n#### Total images [10015]\n\n![https:\/\/steemitimages.com\/DQmWzeNBDe8JjYcFhRUqaSXdeBfgpDQ9fmJuE9rLKZjaVW5\/skin-colored-blotch-lesions.png](https:\/\/steemitimages.com\/DQmWzeNBDe8JjYcFhRUqaSXdeBfgpDQ9fmJuE9rLKZjaVW5\/skin-colored-blotch-lesions.png)\n\n### Objective \nA model that helps doctors and lab technologists with the highest probability of the given lesion type. With this the high priority patients will be identified for treatment. \n","bdab94ad":"### Different classes available under the test folder","a76c859d":"### Visualizing the wrongly predicted images","4d85f573":"### Number of classes in the dataset ","2eedcb29":"#### List of Confused classes is given in descending order for interpretation. min_val = 2 defines that the classes that has been misclassified for 2 times should also be included.","b58d42d4":"## **Step 6** - Testing","d7c6621a":"## Step 2 - Data Preprocessing","7a6b511e":"### Transfer Learning \n> In transfer learning, we first train a base network on a base dataset and task, and then we repurpose the learned features, or transfer them, to a second target network to be trained on a target dataset and task. This process will tend to work if the features are general, meaning suitable to both base and target tasks, instead of specific to the base task. \n> The layers of the networks are freezed inorder to keep the weights as it is. The fully connected layer alone is trained on our data set. The knowledge of the network gained in the previous training is used in our model.\n\n\n\n![https:\/\/i.stack.imgur.com\/gI4zT.png](https:\/\/i.stack.imgur.com\/gI4zT.png)\n\n\n\n### Training starts with this fastai code\n* learner50 - pre-trained model\n* fit_one_cycle - starts training \n* 10 - no of epoochs \n* max_lr - learning rate","b9ff450b":"## Step 4 - Custom Model \n### Resnet Architecture \nResnet is the powerful backbone model frequently used in many computer vision tasks. The strength of resnet is skip connections wich is applied before relu activation. Skip connections work because they allow the model to learn an identity function which ensures that the higher layer will perform at least as good as the lower layer, and not worse. To know more about resnet (Paper : https:\/\/arxiv.org\/abs\/1512.03385), (Code:https:\/\/github.com\/pytorch\/vision\/blob\/master\/torchvision\/models\/resnet.py). \n\n![https:\/\/miro.medium.com\/max\/704\/1*WpX_8eCeTsEcCs8vdXtUCw.png](https:\/\/miro.medium.com\/max\/704\/1*WpX_8eCeTsEcCs8vdXtUCw.png)\n\nI highly recommend you to take Deeplearning.ai course by Andrew Ng in Coursera (https:\/\/www.coursera.org\/learn\/convolutional-neural-networks)\n\n\n* Unfreezing the layers of the pre-trained model to get trained on our dataset \n* A trial run to find the best learning rate \n* Ploting the learning rate results","11731159":"#### **recall ** - How well the classifier identifies the given class.\n#### **precision** - Correctness of the prediction. how likely is it to be correct?\n#### **f1-score** - The harmonic mean of the recall and precision.","321a44ca":"### Checks for the nan values in the dataset and deletes it ","2dacf49a":"### Accuracy on the Transfer-learning model is 85%","7538234b":"## Step 1 - Importing the necessary packages"}}