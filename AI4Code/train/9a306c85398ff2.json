{"cell_type":{"d5c57243":"code","1305131e":"code","3f1d9d8b":"code","d7ab7d75":"code","01bd45cf":"code","d8f4a6a0":"code","25731361":"code","337dd190":"markdown","69f36e3d":"markdown","59cf5b09":"markdown","3364192d":"markdown","ede78ae2":"markdown"},"source":{"d5c57243":"# import pytorch\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F","1305131e":"# The inputs\nA = torch.Tensor([[1,1,0],[0,1,0],[0,1,0]])\nB = torch.Tensor([[0,0,0],[0,1,1],[0,0,1]])\n\n# let's pad the array\ndim = len(A) - 1\nA = F.pad(A, (dim, dim, dim, dim))\n\nA.shape, B.shape","3f1d9d8b":"# unsqueezing creates a extra-dimention along the given dim.\n\nA = A.unsqueeze(dim=0).unsqueeze(dim=0)\nB = B.unsqueeze(dim=0).unsqueeze(dim=0)\nA.shape, B.shape","d7ab7d75":"A, B","01bd45cf":"# define the conv layer\nconv = nn.Conv2d(\n    in_channels=1, \n    out_channels=1,\n    kernel_size=B.shape[-1]\n) \n\n# set the `weights` as the value of matrix B\nconv.weight.data = B","d8f4a6a0":"with torch.no_grad():  # we don't require to store the gradients for now\n    result = conv(A)\nresult","25731361":"result.max().round()","337dd190":"## Pytorch is happy when the inputs are in `(batch_size, num_channels, height, width)` shape.\n### This may seem strange if you're used to see images in `(height, width, num_channels)` format, aka *channels-last*,  which openCV and tensorflow\/keras follow whereas Pytorch follows *channels-first* structuring `(num_channels, height, width)`. Batch_size depicts the number of images in the current batch, which is 1 here.","69f36e3d":"### Now the matrices look like:","59cf5b09":"### Yay! The answer the 3!","3364192d":"### We now create the convolution layer. The function signature is:\n\n```\nnn.Conv2d(\n    in_channels,\n    out_channels,\n    kernel_size,\n    stride=1,\n    padding=0,\n    dilation=1,\n    groups=1,\n    bias=True,\n    padding_mode='zeros',\n)\n```\n### Both `in_channels` and `out_channels` are 1 here, and the `kernel_size` is determined by the dimentions of the `B` matrix. Since we have already padded the `A` matrix, we'll let the padding of the conv layer remain 0.","ede78ae2":"### This notebook attempts to approach the LeetCode problem [835. Image Overlap](https:\/\/leetcode.com\/problems\/image-overlap\/) using PyTorch to perform convolutions"}}