{"cell_type":{"ce3b6963":"code","94f4305e":"code","53fe8a69":"code","e82ffb12":"code","5bbe6f1c":"code","1fc325eb":"code","6d9a7716":"code","3e4a0cca":"code","816cf8b9":"code","1f922dba":"code","a3951f9b":"code","7bd73b67":"code","739e7604":"code","7b2e116f":"code","d0db1186":"code","316cd875":"markdown","8ecc4622":"markdown","42b5fe61":"markdown","0a01953f":"markdown","14de0554":"markdown","64117e70":"markdown"},"source":{"ce3b6963":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))\n\nfrom fastai.vision import *\nfrom fastai.tabular import *\nfrom fastai.metrics import error_rate\nimport csv\nimport numpy as np\nimport PIL \nimport pandas as pd\n#defaults.device = torch.device('cuda')","94f4305e":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","53fe8a69":"train = pd.read_csv('..\/input\/train\/train.csv')\ntrain = train.drop(['Name','Breed2','Color3', 'Description'], axis=1)\ntrain.head(2)","e82ffb12":"test = pd.read_csv('..\/input\/test\/test.csv'); \ntest = test.drop(['Name','Breed2','Color3','Description'], axis=1)\ntest.head(2)","5bbe6f1c":"pet = test['PetID'].values\npred = []","1fc325eb":"cat_names = ['Type', 'Breed1', 'Gender', 'Color1', 'Color2', 'MaturitySize', 'Vaccinated', 'Dewormed', \n             'Sterilized', 'Health', 'RescuerID','VideoAmt','PetID','PhotoAmt']\ndep_var = 'AdoptionSpeed'","6d9a7716":"valid_idx = range(len(train)-1000, len(train))","3e4a0cca":"procs = [FillMissing, Categorify, Normalize]\ndata = TabularDataBunch.from_df(path='..\/working\/', df=train, dep_var=dep_var, valid_idx=valid_idx, procs=procs, cat_names=cat_names)\n","816cf8b9":"learn = tabular_learner(data, layers=[200,100], metrics=accuracy)\nlearn.fit_one_cycle(1, 1e-2)","1f922dba":"predlist = []","a3951f9b":"for x in range(0,len(test)):\n    pred.append(learn.predict(test.iloc[x]))","7bd73b67":"for x in range(0,len(test)):\n    preds = pred[x][0]","739e7604":"for x in range(0,len(test)):\n    predlist.append(pred[x][1].item())","7b2e116f":"submission = pd.DataFrame({'PetID':pet, 'AdoptionSpeed':predlist})\nsubmission.head()","d0db1186":"submission.to_csv('submission.csv', index=False)","316cd875":"# Overview\nIn this kernel we apply the tabular component of the fastai v1 library and use only the train.csv as the basis of our predictions. We drop a few columns that seem irrelevant (name of the pet, the long description, and the supplemental breed & color info). \n\n## Goal\nTo show how to use the fastai databunch API on tabular data.","8ecc4622":"Here we create two numpy arrays. The first holds just the independent variable, the PetId, and the second will hold our predictions.","42b5fe61":"The first two cells are straightforward: Load the train & test csv's into pandas dataframes, dropping superfluous columns.","0a01953f":"# Learner\n\nNow that our data is loaded into a DataBunch, we can train. The `layers` variable is a real swag. It's worth trying other dimensions.\n\nWe fit a cycle, and then I extract the predictions (predlist is an empty array to hold these predictions). That's it! \n\nWith no sentiment analysis, no image classification, and only a few seconds of gpu time this is a ~.28 model. ","14de0554":"The variable `valid_idx` tells fastai how many rows of our tabular dataset to hold aside as a validation set. We are keeping this relatively small.\n\n`procs` refers to pre-processing. These are out-of-the-box.\n\nThe line `data = ` is where we create our TabularDataBunch, using a dataframe (the 'train' dataframe we created via pd.read_csv earlier) and passing the variables we set earlier..","64117e70":"## fastai\nHere is the deep learning part! The fastai library requires us to identify categorical variables, continuous variables (not done here) and the dependent variable. "}}