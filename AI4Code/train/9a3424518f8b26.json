{"cell_type":{"b1aa7a22":"code","1c139aea":"code","0a02bc7c":"code","0e7d290c":"code","1bc514a1":"code","920dc27f":"code","4282056b":"code","33264805":"code","0e6ec5d7":"code","72a449c8":"code","d8caffa7":"code","c127ddfc":"code","f32282f7":"code","47b61307":"code","40f53166":"code","c9601d49":"markdown"},"source":{"b1aa7a22":"from fastai.vision.all import *","1c139aea":"len(train_image_df)\/len(image_)","0a02bc7c":"train_image_df = pd.read_csv(\"..\/input\/siim-covid19-detection\/train_image_level.csv\")\ntrain_study_df = pd.read_csv(\"..\/input\/siim-covid19-detection\/train_study_level.csv\")","0e7d290c":"train_image_df.head()","1bc514a1":"train_study_df.head()","920dc27f":"sample_sub_df = pd.read_csv(\"..\/input\/siim-covid19-detection\/sample_submission.csv\")\nstudy_sub_df = sample_sub_df[sample_sub_df['id'].str.contains(\"study\")]\nimage_sub_df = sample_sub_df[sample_sub_df['id'].str.contains(\"image\")]","4282056b":"label_counts = Counter(np.where(array(train_study_df.iloc[:,1:]))[1]); label_counts","33264805":"(label_counts[2]\/(len(train_image_df)+len(train_study_df)))*0.35","0e6ec5d7":"label_counts[0]\/label_counts[1], 0.05\/0.079","72a449c8":"label_counts[0]\/label_counts[3], 0.05\/0.031","d8caffa7":"def invalid_label_func(o): return \" \".join(o.split()[:-4] + ['1','1','2','2'])\ndef study_label_func(o,l): return f\"{l} 1 0 0 1 1\"","c127ddfc":"study_sub_df.loc[:,'PredictionString'] = study_sub_df['PredictionString'].apply(partial(study_label_func,l='atypical')).values\nimage_sub_df.loc[:,'PredictionString'] = image_sub_df['PredictionString'].apply(invalid_label_func).values","f32282f7":"sample_sub_df = pd.concat([study_sub_df, image_sub_df])","47b61307":"sample_sub_df.to_csv(\"submission.csv\",index=False)","40f53166":"sample_sub_df","c9601d49":"### LB Probes\n\n#### Probe 1: study (1,1,2,2 invalid boxes) and image (1,1,2,2 invalid boxes):  \n\nLB:0.0 Expectation:0.0\n\n#### Probe 2: study (1,1,2,2 invalid boxes) and image (none,1,0,0,1,1): \n\nLB:0.0 Expectation:1\/6 (Assuming equal class weights mAP)\n\nLB: 0.0 also supports the existing problem with image level score calculations. Many say it only contributes 0.001 but infact its not contributing at all, not sure when we will have an explanation about this.\n\n#### Probe 3: study (negative,1,1,0,0) and image (1,1,2,2 boxes):  \n\nLB:0.050 Expectation:1\/6 (Assuming equal class weights mAP)\n\nThis means mAP is weighted by the number of samples of that class in test set. Probe 4 and 5 supports this idea.\n\n#### Probe 4: study (typical,1,1,0,0) and image (1,1,2,2 boxes):  \n\nLB:0.079 Expectation:1\/6 (Assuming equal class weights mAP)\n\nThis means mAP is weighted.\n\nLB negative probe \/ LB typical probe = 0.050 \/ 0.079 = 0.63\n\nno. of negative in train \/ no. of typical in train =  1676 \/ 2855 = 0.58\n\nWe can see that ratios of LB scores and number of samples are very close. They are not exactly same since class distributions of training and test are not same, we probably have more negatives in test set.\n\n#### Probe 4: study (indeterminate,1,1,0,0) and image (1,1,2,2 boxes):  \n\nLB:0.031 Expectation:1\/6 (Assuming equal class weights mAP)\n\nThis means mAP is weighted.\n\nLB negative probe \/ LB indeterminate probe = 0.050 \/ 0.031 = 1.61\n\nno. of negative in train \/ no. of indeterminate in train =  1676 \/ 2855 = 1.59\n\n#### Probe 5: study (atypical,1,1,0,0) and image (1,1,2,2 boxes):  \n\nLB:0.031 Expectation:1\/6 (Assuming equal class weights mAP)\n\nThis means mAP is weighted.\n\nLB negative probe \/ LB atypical probe = 0.050 \/ X = Y (Tomorrow: out of submissions)\n\nno. of negative in train \/ no. of atypical in train =  1676 \/ 2855 = 3.53\n\nX should be close to 0.050 \/ 3.53 ~= 0.14\n\n\n\n### What are weights for image and study level predictions?\n\nAbove we see that mAP is not weigthed equally, hence not 1\/6. We can see the relative contributions within study level classes, but image level classes might be differently weighted compared to study level classes.\n\n\nWe kind of now know that study level predictions are weighted proportionally to their number of samples, if we also assume this for all the 6 classes then here is a rough calculation:\n\n\nLB (probe 3): 0.050 -  Expectation: no. of negative in train \/ all train samples = 0.136\n\nLB (probe 4): 0.079 -  Expectation: no. of negative in train \/ all train samples = 0.230\n\nLB (probe 4): 0.031 -  Expectation: no. of negative in train \/ all train samples = 0.084\n\n\nWhen we assume equal weight between study and image level predictions numbers don't match. Here if we assume a weight of 0.35 for study level predictions:\n\nLB (probe 3): 0.050 -  Expectation: 0.35*(no. of negative in train \/ all train samples) = 0.047\n\nLB (probe 4): 0.079 -  Expectation: 0.35*(no. of negative in train \/ all train samples) = 0.080\n\nLB (probe 4): 0.031 -  Expectation: 0.35*(no. of negative in train \/ all train samples) = 0.029\n\nAgain numbers are slightly different because train and test distribution differences.\n\n\n### Evaluation Formula Hypothesis\n\nScore: 0.35x(Weighted mAP Study) + 0.65x(Weighted mAP Image) ???\n\n\n\nP.S. We can't do much probing around images since evaluation is currently broken."}}