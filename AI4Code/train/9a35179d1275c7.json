{"cell_type":{"980b2488":"code","071f5308":"code","0783dcbe":"code","c162587b":"code","dde1bcd3":"code","98d2dd34":"code","58f8e17d":"code","4b6786d1":"code","26782d91":"code","2941a98c":"code","2cbf16a2":"code","cc552264":"code","8b04bdbc":"code","f4c567d3":"code","2db04819":"code","fd5fb2b4":"code","0a7d12d7":"code","0b2e366a":"code","08c8a5c8":"code","fc5331fd":"code","7a43fd3f":"code","4f756f44":"code","8bc14242":"code","efd6f6f2":"code","2e67f219":"code","b8a12f43":"code","124d7041":"code","ea7bb84e":"code","747c7657":"code","6f92b52f":"code","7ec39453":"code","699019cc":"code","2e646e9b":"code","7af1ded8":"code","1e930416":"code","daf3d73a":"code","eee08a37":"code","86121c8b":"code","e10f73ce":"code","26b2e7fe":"code","a7e67400":"code","4a43a595":"code","e517acc4":"code","0b850144":"code","a5e20646":"code","649a3462":"code","e8dfac45":"code","dc706d8d":"code","53393ef0":"code","34067b2c":"code","e5b2d9f0":"code","86049fe5":"code","c27573f1":"code","28429759":"code","edfa7e9d":"code","45ba8502":"code","a27a0757":"code","5d947b83":"code","7077c3d8":"code","e04d634e":"code","71587f89":"code","861acc8e":"code","6f920f63":"code","28b13a7f":"code","e24edd7b":"code","b4e23e92":"code","0191165a":"code","ef45d4c6":"code","62fc1be7":"code","06429cac":"code","cedc2653":"code","a284c344":"code","4f4eb8fa":"code","f60f7885":"code","db414e68":"code","331822f3":"code","cd85305d":"code","9600f2d5":"code","4ddb9473":"code","cbf1c815":"code","a18075a9":"code","7856ba2f":"code","324bb34d":"code","ba92a2fd":"code","cd4d242b":"code","ec5f2314":"code","ba398d2d":"code","2cc292b6":"code","30c9d30a":"code","60168920":"code","4261f84b":"code","e2fba112":"code","d36e3be8":"code","661e5b85":"code","843a1a11":"code","5886a8b4":"code","be3dbaed":"code","3417e9d7":"code","24bece74":"code","f1667bed":"code","5dcee208":"code","33043985":"code","d4bc5a20":"code","28a95e80":"code","1225addb":"code","56fdd34c":"code","2014e04b":"code","9daec185":"code","bf8d11e5":"code","16063999":"code","d55c10ca":"code","8ea7ff70":"code","98f68c86":"code","525f4beb":"code","8c2c98f8":"code","eaa90a15":"code","4f4575f2":"code","21a68c4a":"code","b8c21cee":"code","37b1ea79":"code","da7de0df":"code","84626041":"code","ccdd4465":"code","e535ee33":"code","fbeb4066":"code","d1c06dd3":"code","d0c8fb3b":"code","d7060139":"code","09768082":"code","037e4d83":"code","b9f4016a":"code","1b7523ae":"code","61b7c897":"code","94aa9302":"code","8c04ac15":"code","415a509e":"code","497cea77":"code","06ff2c28":"code","d251d1c4":"code","8be96298":"code","108d33a4":"code","59344c35":"code","3a363aba":"code","e8190773":"code","d99a2757":"code","cb5afa65":"code","cef1fbae":"code","60cb0e8a":"code","8aa9128c":"code","8c6eddc6":"code","cb7a43bc":"code","5d40d8b6":"code","31202148":"code","e631b993":"code","da31b7e4":"code","a1208f52":"code","8a4f6592":"code","0f35367d":"code","950b18ee":"code","16a03c09":"code","d59a6e1a":"code","b37662b5":"code","74612364":"code","2f77ac25":"code","9df3c33c":"code","bd619215":"code","61eb1535":"markdown","068c7ad3":"markdown","b9e3cd8d":"markdown","ba0ac6e5":"markdown","96f3b8b1":"markdown","c5f29007":"markdown","cde011e0":"markdown","49d99ecf":"markdown","23297e00":"markdown","6b322e35":"markdown","c2b6753e":"markdown","cd812bd2":"markdown","0528e44b":"markdown","300045e5":"markdown","74261567":"markdown","45b3bd69":"markdown","57d0b548":"markdown","599afd65":"markdown","8f667a3d":"markdown","3fb4d28c":"markdown","c12dfdb3":"markdown","a8fceb3c":"markdown","1ad24178":"markdown","146404b2":"markdown","4c96f688":"markdown","2f08d603":"markdown","e908662b":"markdown","62b86a5c":"markdown","6f471740":"markdown","4fc4ff64":"markdown","be2cef04":"markdown","5568aae6":"markdown","dcfd97c5":"markdown","bb17ea96":"markdown","6662abe4":"markdown","66a1f9f7":"markdown","e3d680c9":"markdown","404512c3":"markdown","17b7aed8":"markdown","eecb477f":"markdown","ec8a9a30":"markdown","aefe4b2b":"markdown","862bcc76":"markdown","410f62f6":"markdown","4b1bcb9e":"markdown","0cbf3ef5":"markdown","591e958f":"markdown","31ff12ba":"markdown","d56cbce2":"markdown","73c89eed":"markdown","379b7111":"markdown","770397e8":"markdown","3182e5f2":"markdown","a60c20e1":"markdown","68dc0243":"markdown","57c35609":"markdown","ce8f2b84":"markdown","e27a163d":"markdown","bcfdd39a":"markdown","4d1a1a45":"markdown","eabfa491":"markdown","f3fc00bc":"markdown","83ca3745":"markdown","a0e4ab95":"markdown","c4174ea5":"markdown","9df98a86":"markdown","9fae2dab":"markdown","1a9989f9":"markdown","29061278":"markdown","0967165f":"markdown","730d6573":"markdown","80c69372":"markdown","04ff3234":"markdown","b9bd3951":"markdown","62e7b442":"markdown","89c58419":"markdown","5726dea1":"markdown","3740e23e":"markdown","d12d7660":"markdown","afb1b55c":"markdown","5f3d3342":"markdown","3f576103":"markdown","932ebf3b":"markdown","5aab6e40":"markdown","fcb5533b":"markdown","f8204357":"markdown","35c568a6":"markdown","b6850454":"markdown","b85690ed":"markdown","0b32b820":"markdown","4006d48c":"markdown","a07c0e99":"markdown","bceab585":"markdown","d87fbac7":"markdown"},"source":{"980b2488":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom sklearn import preprocessing \nfrom category_encoders import *\nfrom sklearn.preprocessing import LabelEncoder\n%matplotlib inline\nfrom sklearn import datasets, linear_model, metrics\nfrom sklearn.metrics import  confusion_matrix\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport warnings\nwarnings.filterwarnings('ignore')","071f5308":"df = pd.read_csv(\"..\/input\/students-performance-in-exams\/Student Performance new.csv\")\ndf.drop('Unnamed: 0',axis = 1,inplace = True)\ndf","0783dcbe":"# Exploratory Data Analysis\ndef libraries():\n    global pd,np\n    import pandas as pd\n    import numpy as np\ndef load():\n    global df\n    df = pd.read_csv(\"..\/input\/students-performance-in-exams\/Student Performance new.csv\")\n    df.drop('Unnamed: 0',axis = 1,inplace = True)\n    \ndef top_rows(value):\n    print('\\033[1m'+ 'displaying the', value, 'rows from top'+'\\033[0m')\n    a=df.head(value)\n    print(a,'\\n')\n    \ndef bottom_rows(value):\n    print('\\033[1m'+'displaying the', value, 'rows from bottom'+'\\033[0m')\n    b=df.tail(value)\n    print(b,'\\n')\n    \ndef rows_columns():\n    print('\\033[1m'+'Shape of the Data set'+'\\033[0m')\n    c=df.shape\n    print(c,'\\n')\n    \ndef col_names():\n    print('\\033[1m'+'Column Names in the Data set'+'\\033[0m')\n    d=df.columns\n    print(d,'\\n')\n    \ndef information():\n    print('\\033[1m'+'Quick Overview of DataSet(info)'+'\\033[0m')\n    e = df.info()\n    print(e,'\\n')\n\ndef sizee():\n    print('\\033[1m'+'No.of Elements in the DataSet'+'\\033[0m')\n    f = df.size\n    print(f,'\\n')\n\ndef ndimension():\n    print('\\033[1m'+'Dimensions in your dataframe'+'\\033[0m')\n    g = df.ndim\n    print(g,'\\n')\n    \ndef stats_summary():\n    print('\\033[1m'+'Staistical Summary of DataSet'+'\\033[0m')\n    h = df.describe()\n    print(h,'\\n')\n    \ndef null_values():\n    print('\\033[1m'+'Number of Missing values in each column'+'\\033[0m')\n    i = df.isnull().sum()\n    print(i,'\\n')\n    \ndef n_unique():\n    print('\\033[1m'+'Number of unique elements'+'\\033[0m')\n    j = df.nunique()\n    print(j,'\\n')\n    \ndef memory_use():\n    print('\\033[1m'+'Memory used by all colomns in bytes'+'\\033[0m')\n    k = df.memory_usage()\n    print(k,'\\n')\n    \ndef is_na(value):\n    print('\\033[1m'+'Dataframe filled with boolean values with true indicating missing values'+'\\033[0m')\n    l = df.isna().head(value)\n    print(l,'\\n')\n    \ndef duplicate():\n    print('\\033[1m'+'Boolean Series denoting duplicate rows'+'\\033[0m')\n    m = df.duplicated().sum()\n    print(m,'\\n')\n    \ndef valuecounts():\n    print('\\033[1m'+'Series containing count of unique values'+'\\033[0m')\n    n = df.value_counts()\n    print(n,'\\n')\n\ndef datatypes():\n    print('\\033[1m'+'Datatype of each column'+'\\033[0m')\n    o = df.dtypes\n    print(o,'\\n')\n    \ndef correlation():\n    print('\\033[1m'+'Correalation between all columns in DataFrame'+'\\033[0m')\n    p = df.corr()\n    print(p,'\\n')\n    \ndef nonnull_count():\n    print('\\033[1m'+'Count of non-null values'+'\\033[0m')\n    q = df.count()\n    print(q,'\\n')\n    \ndef eda():\n    load()\n    value= 5 \n    datatypes()\n    top_rows(value)\n    bottom_rows(value)\n    rows_columns()\n    col_names()\n    information()\n    sizee()\n    ndimension()\n    stats_summary()\n    null_values()\n    n_unique()\n    memory_use()\n    is_na(value)\n    nonnull_count()\n    duplicate()\n    valuecounts()\n    correlation()\n    \n    \n    \n        \ndef stats_u(data,col):\n    if data[col].dtype == \"float64\":\n        print(col,\"has Quantitative data\")\n        mean_value=data[col].mean()\n        print('mean of',col,'column',mean_value)\n        max_value = data[col].max()\n        print('Maximum value of',col,'column',max_value)\n        min_value = data[col].min()\n        print('Minimum value of',col,'column',min_value)\n        median_value = data[col].median(skipna = True)\n        print('median of',col,'column',median_value)\n        std_value = data[col].std()\n        print('standard deviation of',col,'column',std_value)\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        print('quartile 1 of',col,'column is',q1)\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        print('quartile 2 of',col,'column is',q2)\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        print('quartile 3 of',col,'column is',q3)\n        q4 = data[col].quantile(1,interpolation='nearest')\n        print('quartile 4 of',col,'column is',q4)\n        IQR = q3 -q1\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        print('Lower Limit Point:',LLP)\n        print('Upper Limit Point:',ULP)\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers\")\n        else:\n            print(\"There are outliers\")\n            print(data[data[col]<LLP][col])\n            print(data[data[col]>ULP][col])\n            \n    elif data[col].dtype == \"int64\":\n        print(col,\"has Quantitative data\")\n        mean_value=data[col].mean()\n        print('mean of',col,'column',mean_value)\n        median_value = data[col].median(skipna = True)\n        print('median of',col,'column',median_value)\n        std_value = data[col].std()\n        print('standard deviation of',col,'column',std_value)\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        print('quartile 1 of',col,'column is',q1)\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        print('quartile 2 of',col,'column is',q2)\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        print('quartile 3 of',col,'column is',q3)\n        q4 = data[col].quantile(1,interpolation='nearest')\n        print('quartile 4 of',col,'column is',q4)\n        IQR = q3 -q1\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        print('Lower Limit Point:',LLP)\n        print('Upper Limit Point:',ULP)\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers\")\n        else:\n            print(\"There are outliers\")\n            print(\"Outliers are:\")\n            print(data[data[col]<LLP][col])\n            print(data[data[col]>ULP][col])\n    else:\n        print(col,'has Qualitative Data')\n        z = df[col].mode()\n        print('mode of',col,'column:\\n',z)\n        print('Count of mode is:\\n',df[col].value_counts())\n        print('Unique strings in',col,'are',data[col].nunique())\n        if(data[col].nunique() == 1):\n            print(col,'has same string')\n        elif(data[col].nunique() == 2):\n            print(col,'has binary strings')\n        else:\n            print(col,'has multi stings')\n\n\nlibraries()\neda()\n\nprint(\"----------------------------------------------------------------------------------------------------------------------\")\nprint('\\033[1m'+'Summary Of DataSet'+'\\033[0m')\nprint('\\033[1m'+'DataTypes in the DataSet:\\n'+'\\033[0m',df.dtypes)\nprint('\\033[1m'+'Columns in DataSet:'+'\\033[0m',df.columns)\nprint('\\033[1m'+'Shape of DataSet:'+'\\033[0m',df.shape)\nprint('\\033[1m'+'Size of DataSet:'+'\\033[0m',df.size)\nprint('\\033[1m'+'Dimension of DataSet:'+'\\033[0m',df.ndim)\nprint('\\033[1m'+'Total Memory used in DataSet:'+'\\033[0m',df.memory_usage().sum())\nprint('\\033[1m'+'Total Number of missing values in DataSet:'+'\\033[0m',df.isnull().sum().sum())\nprint('\\033[1m'+'Total Number of Unique values in DataSet:'+'\\033[0m',df.nunique().sum())\nprint('\\033[1m'+'Total Number of non null values in DataSet:'+'\\033[0m',df.count().sum())\nprint('\\033[1m'+'Total Number of duplicate rows in DataSet:'+'\\033[0m',df.duplicated().sum())\nprint(\"----------------------------------------------------------------------------------------------------------------------\")\nprint('\\033[1m'+'Summary Of Each Colomn'+'\\033[0m')\nprint(\"\\n\")\ncols=df.columns\ncols\nfor i in cols:\n    print('\\033[1m'+i+'\\033[0m')\n    stats_u(df,i)\n    print(\"\\n\")\n            ","c162587b":"df.head()","dde1bcd3":"df.tail()","98d2dd34":"df.dtypes","58f8e17d":"df.columns","4b6786d1":"df.shape","26782d91":"df.size","2941a98c":"df.info()","2cbf16a2":"df.describe()","cc552264":"df.isnull().sum()","8b04bdbc":"df.duplicated().sum()","f4c567d3":"df.skew()","2db04819":"df.corr()","fd5fb2b4":"! pip install Autoviz","0a7d12d7":"! pip install xlrd","0b2e366a":"from autoviz.AutoViz_Class import AutoViz_Class\nAV = AutoViz_Class()\ndf_av = AV.AutoViz(\"..\/input\/students-performance-in-exams\/Student Performance new.csv\")","08c8a5c8":"df['race\/ethnicity'].value_counts()","fc5331fd":"sns.countplot(x = 'race\/ethnicity',data = df)\nplt.show()","7a43fd3f":"df['parental level of education'].value_counts()","4f756f44":"sns.set(rc={'figure.figsize':(10,10)})\nsns.countplot(x = 'parental level of education',data = df)\nplt.show()","8bc14242":"df['lunch'].value_counts()","efd6f6f2":"sns.set(rc={'figure.figsize':(10,10)})\nsns.countplot(x = 'lunch',data = df)\nplt.show()","2e67f219":"df['test preparation course'].value_counts()","b8a12f43":"sns.countplot(x = 'test preparation course',data = df)\nplt.show()","124d7041":"df['sex'].value_counts()","ea7bb84e":"sns.countplot(x = 'sex',data = df)\nplt.show()","747c7657":"from IPython.core.display import HTML\n\ndef multi_table(table_list):\n    ''' Acceps a list of IpyTable objects and returns a table which contains each IpyTable in a cell\n    '''\n    return HTML(\n        '<table><tr style=\"background-color:white;\">' + \n        ''.join(['<td>' + table._repr_html_() + '<\/td>' for table in table_list]) +\n        '<\/tr><\/table>')","6f92b52f":"df_nunique = {var: pd.DataFrame(df[var].value_counts()) \n              for var in {'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','sex'}}\nmulti_table([df_nunique['race\/ethnicity'], df_nunique['parental level of education'],df_nunique['lunch']\n            ,df_nunique['test preparation course'],df_nunique['sex']])","7ec39453":"df_groupby = {var: pd.DataFrame(df.groupby([var, 'math percentage']).size()) \n              for var in {'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','sex'}}\nmulti_table([df_groupby['race\/ethnicity'], df_groupby['parental level of education'],df_groupby['lunch']\n            ,df_groupby['test preparation course'],df_groupby['sex']])","699019cc":"plt.figure(figsize=(16,9))\nax = sns.heatmap(df.corr(),annot = True,cmap = 'viridis')\nplt.show()","2e646e9b":"''' Plot a Shifted Correlation Matrix '''\n# Diagonal correlation is always unity & less relevant, shifted variant shows only relevant cases\ndef corrMat(df,id=False):\n    \n    corr_mat = df.corr().round(2)\n    f, ax = plt.subplots(figsize=(12,7))\n    mask = np.triu(np.ones_like(corr_mat, dtype=bool))\n    mask = mask[1:,:-1]\n    corr = corr_mat.iloc[1:,:-1].copy()\n    sns.heatmap(corr,mask=mask,vmin=-0.3,vmax=0.3,center=0, \n                cmap='RdPu_r',square=False,lw=2,annot=True,cbar=False)\n#     bottom, top = ax.get_ylim() \n#     ax.set_ylim(bottom + 0.5, top - 0.5) \n    ax.set_title('Shifted Linear Correlation Matrix')\n    \ncorrMat(df.drop(['race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','sex'],axis = 1))","7af1ded8":"''' Draw a Bivariate Seaborn Pairgrid \/w KDE density w\/ '''\ndef snsPairGrid(df):\n\n    ''' Plots a Seaborn Pairgrid w\/ KDE & scatter plot of df features'''\n    g = sns.PairGrid(df,diag_sharey=False,hue='test preparation course',palette='Purples')\n    g.fig.set_size_inches(13,13)\n    g.map_upper(sns.kdeplot,n_levels=5)\n    g.map_diag(sns.kdeplot, lw=2)\n    g.map_lower(sns.scatterplot,s=20,edgecolor=\"k\",linewidth=1,alpha=0.6)\n    g.add_legend()\n    plt.tight_layout()\nnumvars_targ = ['test preparation course', 'math percentage',\n       'reading score percentage', 'writing score percentage']\nsnsPairGrid(df[numvars_targ])","1e930416":"''' Draw a Bivariate Seaborn Pairgrid \/w KDE density w\/ '''\ndef snsPairGrid(df):\n\n    ''' Plots a Seaborn Pairgrid w\/ KDE & scatter plot of df features'''\n    g = sns.PairGrid(df,diag_sharey=False,hue='race\/ethnicity',palette='Purples')\n    g.fig.set_size_inches(13,13)\n    g.map_upper(sns.kdeplot,n_levels=5)\n    g.map_diag(sns.kdeplot, lw=2)\n    g.map_lower(sns.scatterplot,s=20,edgecolor=\"k\",linewidth=1,alpha=0.6)\n    g.add_legend()\n    plt.tight_layout()\nnumvars_targ = ['race\/ethnicity', 'math percentage',\n       'reading score percentage', 'writing score percentage']\nsnsPairGrid(df[numvars_targ])","daf3d73a":"''' Draw a Bivariate Seaborn Pairgrid \/w KDE density w\/ '''\ndef snsPairGrid(df):\n\n    ''' Plots a Seaborn Pairgrid w\/ KDE & scatter plot of df features'''\n    g = sns.PairGrid(df,diag_sharey=False,hue='parental level of education',palette='Purples')\n    g.fig.set_size_inches(13,13)\n    g.map_upper(sns.kdeplot,n_levels=5)\n    g.map_diag(sns.kdeplot, lw=2)\n    g.map_lower(sns.scatterplot,s=20,edgecolor=\"k\",linewidth=1,alpha=0.6)\n    g.add_legend()\n    plt.tight_layout()\nnumvars_targ = ['parental level of education', 'math percentage',\n       'reading score percentage', 'writing score percentage']\nsnsPairGrid(df[numvars_targ])","eee08a37":"''' Draw a Bivariate Seaborn Pairgrid \/w KDE density w\/ '''\ndef snsPairGrid(df):\n\n    ''' Plots a Seaborn Pairgrid w\/ KDE & scatter plot of df features'''\n    g = sns.PairGrid(df,diag_sharey=False,hue='lunch',palette='Purples')\n    g.fig.set_size_inches(13,13)\n    g.map_upper(sns.kdeplot,n_levels=5)\n    g.map_diag(sns.kdeplot, lw=2)\n    g.map_lower(sns.scatterplot,s=20,edgecolor=\"k\",linewidth=1,alpha=0.6)\n    g.add_legend()\n    plt.tight_layout()\nnumvars_targ = ['lunch', 'math percentage',\n       'reading score percentage', 'writing score percentage']\nsnsPairGrid(df[numvars_targ])","86121c8b":"''' Draw a Bivariate Seaborn Pairgrid \/w KDE density w\/ '''\ndef snsPairGrid(df):\n\n    ''' Plots a Seaborn Pairgrid w\/ KDE & scatter plot of df features'''\n    g = sns.PairGrid(df,diag_sharey=False,hue='sex',palette='Purples')\n    g.fig.set_size_inches(13,13)\n    g.map_upper(sns.kdeplot,n_levels=5)\n    g.map_diag(sns.kdeplot, lw=2)\n    g.map_lower(sns.scatterplot,s=20,edgecolor=\"k\",linewidth=1,alpha=0.6)\n    g.add_legend()\n    plt.tight_layout()\nnumvars_targ = ['sex', 'math percentage',\n       'reading score percentage', 'writing score percentage']\nsnsPairGrid(df[numvars_targ])","e10f73ce":"df_B = df[df['race\/ethnicity'] == 'group B']\ndf_B # contains all group B students details","26b2e7fe":"df_B.corr()","a7e67400":"df_B.describe()","4a43a595":"df_B_nunique = {var: pd.DataFrame(df_B[var].value_counts()) \n              for var in {'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','sex'}}\nmulti_table([df_B_nunique['race\/ethnicity'], df_B_nunique['parental level of education'],df_B_nunique['lunch']\n            ,df_B_nunique['test preparation course'],df_B_nunique['sex']])","e517acc4":"fig = px.histogram(data_frame = df_B,\n             x = \"parental level of education\",\n             color=\"lunch\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","0b850144":"fig = px.histogram(data_frame = df_B,\n             x = \"parental level of education\",\n             color=\"test preparation course\", title=\"<b>Analysis of parent level education with test preparation course<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","a5e20646":"fig = px.histogram(data_frame = df_B,\n             x = \"parental level of education\",\n             color=\"sex\", title=\"<b>Analysis of parent level education with sex<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","649a3462":"fig = px.histogram(data_frame = df_B,\n             x = \"test preparation course\",\n             color=\"sex\", title=\"<b>Analysis of test preparation course with sex<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","e8dfac45":"df_A = df[df['race\/ethnicity'] == 'group A']\ndf_A # contains all group A students details","dc706d8d":"df_A.corr()","53393ef0":"df_A.describe()","34067b2c":"df_A_nunique = {var: pd.DataFrame(df_A[var].value_counts()) \n              for var in {'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','sex'}}\nmulti_table([df_A_nunique['race\/ethnicity'], df_A_nunique['parental level of education'],df_A_nunique['lunch']\n            ,df_A_nunique['test preparation course'],df_A_nunique['sex']])","e5b2d9f0":"fig = px.histogram(data_frame = df_A,\n             x = \"parental level of education\",\n             color=\"lunch\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","86049fe5":"fig = px.histogram(data_frame = df_A,\n             x = \"parental level of education\",\n             color=\"test preparation course\", title=\"<b>Analysis of parent level education with test preparation course<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","c27573f1":"fig = px.histogram(data_frame = df_A,\n             x = \"parental level of education\",\n             color=\"sex\", title=\"<b>Analysis of parent level education with sex<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","28429759":"fig = px.histogram(data_frame = df_A,\n             x = \"test preparation course\",\n             color=\"sex\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","edfa7e9d":"df_C = df[df['race\/ethnicity'] == 'group C']\ndf_C # contains all group C students details","45ba8502":"df_C.corr()","a27a0757":"df_C.describe()","5d947b83":"df_C_nunique = {var: pd.DataFrame(df_C[var].value_counts()) \n              for var in {'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','sex'}}\nmulti_table([df_C_nunique['race\/ethnicity'], df_C_nunique['parental level of education'],df_C_nunique['lunch']\n            ,df_C_nunique['test preparation course'],df_C_nunique['sex']])","7077c3d8":"fig = px.histogram(data_frame = df_C,\n             x = \"parental level of education\",\n             color=\"lunch\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","e04d634e":"fig = px.histogram(data_frame = df_C,\n             x = \"parental level of education\",\n             color=\"test preparation course\", title=\"<b>Analysis of parent level education with test preparation course<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","71587f89":"fig = px.histogram(data_frame = df_C,\n             x = \"parental level of education\",\n             color=\"sex\", title=\"<b>Analysis of parent level education with sex<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","861acc8e":"fig = px.histogram(data_frame = df_C,\n             x = \"test preparation course\",\n             color=\"sex\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","6f920f63":"df_D = df[df['race\/ethnicity'] == 'group D']\ndf_D # contains all group D students details","28b13a7f":"df_D.corr()","e24edd7b":"df_D.describe()","b4e23e92":"df_D_nunique = {var: pd.DataFrame(df_D[var].value_counts()) \n              for var in {'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','sex'}}\nmulti_table([df_D_nunique['race\/ethnicity'], df_D_nunique['parental level of education'],df_D_nunique['lunch']\n            ,df_D_nunique['test preparation course'],df_D_nunique['sex']])","0191165a":"fig = px.histogram(data_frame = df_D,\n             x = \"parental level of education\",\n             color=\"lunch\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","ef45d4c6":"fig = px.histogram(data_frame = df_D,\n             x = \"parental level of education\",\n             color=\"test preparation course\", title=\"<b>Analysis of parent level education with test preparation course<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","62fc1be7":"fig = px.histogram(data_frame = df_D,\n             x = \"parental level of education\",\n             color=\"sex\", title=\"<b>Analysis of parent level education with sex<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","06429cac":"fig = px.histogram(data_frame = df_D,\n             x = \"test preparation course\",\n             color=\"sex\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","cedc2653":"df_E = df[df['race\/ethnicity'] == 'group E']\ndf_E # contains all group E students details","a284c344":"df_E.corr()","4f4eb8fa":"df_E.describe()","f60f7885":"df_E_nunique = {var: pd.DataFrame(df_E[var].value_counts()) \n              for var in {'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','sex'}}\nmulti_table([df_E_nunique['race\/ethnicity'], df_E_nunique['parental level of education'],df_E_nunique['lunch']\n            ,df_E_nunique['test preparation course'],df_E_nunique['sex']])","db414e68":"fig = px.histogram(data_frame = df_E,\n             x = \"parental level of education\",\n             color=\"lunch\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","331822f3":"fig = px.histogram(data_frame = df_E,\n             x = \"parental level of education\",\n             color=\"test preparation course\", title=\"<b>Analysis of parent level education with test preparation course<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","cd85305d":"fig = px.histogram(data_frame = df_E,\n             x = \"parental level of education\",\n             color=\"sex\", title=\"<b>Analysis of parent level education with sex<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","9600f2d5":"fig = px.histogram(data_frame = df_E,\n             x = \"test preparation course\",\n             color=\"sex\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","4ddb9473":"fig = px.histogram(data_frame = df,\n             x = \"parental level of education\",\n             color=\"lunch\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","cbf1c815":"fig = px.histogram(data_frame = df,\n             x = \"parental level of education\",\n             color=\"test preparation course\", title=\"<b>Analysis of parent level education with test preparation course<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","a18075a9":"fig = px.histogram(data_frame = df,\n             x = \"parental level of education\",\n             color=\"sex\", title=\"<b>Analysis of parent level education with sex<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","7856ba2f":"fig = px.histogram(data_frame = df,\n             x = \"test preparation course\",\n             color=\"sex\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","324bb34d":"df['math percentage'] = df['math percentage']*100\ndf['reading score percentage'] = df['reading score percentage']*100\ndf['writing score percentage'] = df['writing score percentage']*100","ba92a2fd":"df","cd4d242b":"max_math_percent = df['math percentage'].max()\nmax_math_percent","ec5f2314":"df[df['math percentage'] == max_math_percent]","ba398d2d":"min_math_percent = df['math percentage'].min()\nmin_math_percent","2cc292b6":"df[df['math percentage'] == min_math_percent]","30c9d30a":"max_reading_percent = df['reading score percentage'].max()\nmax_reading_percent","60168920":"df_read = df[df['reading score percentage'] == max_reading_percent]\ndf_read","4261f84b":"df_nunique = {var: pd.DataFrame(df_read[var].value_counts()) \n              for var in {'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','sex'}}\nmulti_table([df_nunique['race\/ethnicity'], df_nunique['parental level of education'],df_nunique['lunch']\n            ,df_nunique['test preparation course'],df_nunique['sex']])","e2fba112":"df1 = df_read.groupby('race\/ethnicity').agg({'math percentage' : 'mean','reading score percentage' : 'mean','writing score percentage' : 'mean'})\ndf1","d36e3be8":"px.bar(data_frame=df1, barmode='group',\n       title = \"<b>race\/ethnicity wise Analyzing<\/b>\",template=\"plotly_dark\")","661e5b85":"min_reading_percent = df['reading score percentage'].min()\nmin_reading_percent","843a1a11":"df_minread = df[df['reading score percentage'] == min_reading_percent]\ndf_minread","5886a8b4":"max_writing_percent = df['writing score percentage'].max()\nmax_writing_percent","be3dbaed":"df_write = df[df['writing score percentage'] == max_writing_percent]\ndf_write","3417e9d7":"df_nunique = {var: pd.DataFrame(df_write[var].value_counts()) \n              for var in {'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','sex'}}\nmulti_table([df_nunique['race\/ethnicity'], df_nunique['parental level of education'],df_nunique['lunch']\n            ,df_nunique['test preparation course'],df_nunique['sex']])","24bece74":"min_writing_percent = df['writing score percentage'].min()\nmin_writing_percent","f1667bed":"df_minwrite = df[df['writing score percentage'] == min_writing_percent]\ndf_minwrite","5dcee208":"df[(df['math percentage'].values == df['reading score percentage']) & (df['math percentage'].values == df['writing score percentage'])]","33043985":"dfb = df[df['race\/ethnicity'] == 'group B']\ndfb","d4bc5a20":"max_percent_b = dfb['math percentage'].max()\nmax_percent_b","28a95e80":"dfb[dfb['math percentage'] == max_percent_b]","1225addb":"obj = ['race\/ethnicity','parental level of education','lunch','test preparation course','sex']\nnum = ['math percentage','reading score percentage','writing score percentage']","56fdd34c":"for i in range(len(obj)):\n    plt.figure(figsize=(11,7))\n    sns.barplot(x=obj[i],y=\"math percentage\", data=df)\n    plt.show()","2014e04b":"for i in range(len(obj)):\n    plt.figure(figsize=(11,7))\n    sns.barplot(x=obj[i],y=\"reading score percentage\", data=df)\n    plt.show()","9daec185":"for i in range(len(obj)):\n    plt.figure(figsize=(11,7))\n    sns.barplot(x=obj[i],y=\"writing score percentage\", data=df)\n    plt.show()","bf8d11e5":"df2 = df.groupby('race\/ethnicity').agg({'math percentage' : 'mean','reading score percentage' : 'mean','writing score percentage' : 'mean'})\ndf2","16063999":"px.bar(data_frame=df2, barmode='group',\n       title = \"<b>race\/ethnicity wise Analyzing<\/b>\",template=\"plotly_dark\")","d55c10ca":"df3 = df.groupby('parental level of education').agg({'math percentage' : 'mean','reading score percentage' : 'mean','writing score percentage' : 'mean'})\ndf3","8ea7ff70":"px.bar(data_frame=df3, barmode='group',\n       title = \"<b>race\/parental level of education wise Analyzing<\/b>\",template=\"plotly_dark\")","98f68c86":"df4 = df.groupby('lunch').agg({'math percentage' : 'mean','reading score percentage' : 'mean','writing score percentage' : 'mean'})\ndf4","525f4beb":"px.bar(data_frame=df4, barmode='group',\n       title = \"<b>lunch wise Analyzing<\/b>\",template=\"plotly_dark\")","8c2c98f8":"df5 = df.groupby('test preparation course').agg({'math percentage' : 'mean','reading score percentage' : 'mean','writing score percentage' : 'mean'})\ndf5","eaa90a15":"px.bar(data_frame=df5, barmode='group',\n       title = \"<b>test preparation course wise analysing<\/b>\",template=\"plotly_dark\")","4f4575f2":"df6 = df.groupby('sex').agg({'math percentage' : 'mean','reading score percentage' : 'mean','writing score percentage' : 'mean'})\ndf6","21a68c4a":"px.bar(data_frame=df6, barmode='group',\n       title = \"<b>sex wise analyzing<\/b>\",template=\"plotly_dark\")","b8c21cee":"# Here my target variable is math percentage\ndef categorial_feature_overview(feature, rotation=0):\n    print(feature, 'has', df[feature].isnull().sum() \/ len(df) * 100, '% of null values')\n    f,ax = plt.subplots(1, 2, figsize=(20, 6))\n    ax[0].tick_params(labelrotation=rotation)\n    ax[1].tick_params(labelrotation=rotation)\n    sns.countplot(data=df, x=feature, ax=ax[0]);\n    sns.boxplot(data=df, x=feature, y='math percentage', ax=ax[1])\n    plt.show()\n    \ndef numerical_feature_overview(feature, rotation=0):\n    print(feature, 'has', df[feature].isnull().sum() \/ len(df) * 100, '% of null values')\n    f,ax = plt.subplots(1, 2, figsize=(20, 6))\n    ax[0].tick_params(labelrotation=rotation)\n    ax[1].tick_params(labelrotation=rotation)\n    sns.scatterplot(data=df, x=feature, y='math percentage', ax=ax[0]);\n    sns.boxplot(data=df, x=feature, ax=ax[1])\n    plt.show()","37b1ea79":"categorial_feature_overview('race\/ethnicity')","da7de0df":"categorial_feature_overview('parental level of education')","84626041":"categorial_feature_overview('lunch')","ccdd4465":"categorial_feature_overview('sex')","e535ee33":"categorial_feature_overview('test preparation course')","fbeb4066":"numerical_feature_overview('math percentage')","d1c06dd3":"numerical_feature_overview('reading score percentage')","d0c8fb3b":"numerical_feature_overview('writing score percentage')","d7060139":"def count_outliers(data,col):\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        q4 = data[col].quantile(1,interpolation='nearest')\n        IQR = q3 -q1\n        global LLP\n        global ULP\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers in\",i)\n        else:\n            print(\"There are outliers in\",i)\n            x = data[data[col]<LLP][col].size\n            y = data[data[col]>ULP][col].size\n            a.append(i)\n            print('Count of outliers are:',x+y)\nglobal a\na = []\nx = df.drop(obj,axis = 1)\nfor i in x.columns:\n    count_outliers(x,i)","09768082":"Num_vars = ['math percentage','reading score percentage','writing score percentage']","037e4d83":"Cat_vars = df.drop(Num_vars, axis = 1).columns.tolist()\nCat_vars","b9f4016a":"Cat_vars_low = list(df[Cat_vars].loc[:, (df[Cat_vars].nunique() < 10)].nunique().index)\nCat_vars_high = list(df[Cat_vars].loc[:, (df[Cat_vars].nunique() >= 10)].nunique().index)","1b7523ae":"sns.set_theme(rc = {'grid.linewidth': 0.5,\n                    'axes.linewidth': 0.75, 'axes.facecolor': '#fff3e9', 'axes.labelcolor': '#6b1000',\n                    'figure.facecolor': '#f7e7da'})\n                    #'xtick.labelcolor': '#6b1000', 'ytick.labelcolor': '#6b1000'","61b7c897":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(2, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['math percentage']), \n                        hue =  np.log(df['math percentage']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","94aa9302":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(2, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['reading score percentage']), \n                        hue =  np.log(df['reading score percentage']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","8c04ac15":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(2, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['writing score percentage']), \n                        hue =  np.log(df['writing score percentage']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","415a509e":"train_num_visual_0 = df.select_dtypes(include = ['float64']).columns.tolist()","497cea77":"sns.set_theme(rc = {'figure.dpi': 120, 'axes.labelsize': 8, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'}, font_scale = 0.65)\n\nfig, ax = plt.subplots(3, 1, figsize = (7, 6))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_num_visual_0, ax.flatten())))):\n    \n    sns.scatterplot(ax = axes, y = df[column].index, x = df[column], \n                    hue = df['sex'], palette = 'crest', alpha = 0.8)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","06ff2c28":"sns.set_theme(rc = {'figure.dpi': 120, 'axes.labelsize': 8, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'}, font_scale = 0.65)\n\nfig, ax = plt.subplots(3, 1, figsize = (7, 6))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_num_visual_0, ax.flatten())))):\n    \n    sns.scatterplot(ax = axes, y = df[column].index, x = df[column], \n                    hue = df['race\/ethnicity'], palette = 'crest', alpha = 0.8)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","d251d1c4":"sns.set_theme(rc = {'figure.dpi': 120, 'axes.labelsize': 8, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'}, font_scale = 0.65)\n\nfig, ax = plt.subplots(2, 1, figsize = (7, 6))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_num_visual_0, ax.flatten())))):\n    \n    sns.scatterplot(ax = axes, y = df[column].index, x = df[column], \n                    hue = df['parental level of education'], palette = 'crest', alpha = 0.8)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","8be96298":"sns.set_theme(rc = {'figure.dpi': 120, 'axes.labelsize': 8, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'}, font_scale = 0.65)\n\nfig, ax = plt.subplots(2, 1, figsize = (7, 6))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_num_visual_0, ax.flatten())))):\n    \n    sns.scatterplot(ax = axes, y = df[column].index, x = df[column], \n                    hue = df['lunch'], palette = 'crest', alpha = 0.8)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","108d33a4":"sns.set_theme(rc = {'figure.dpi': 120, 'axes.labelsize': 8, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'}, font_scale = 0.65)\n\nfig, ax = plt.subplots(2, 1, figsize = (7, 6))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_num_visual_0, ax.flatten())))):\n    \n    sns.scatterplot(ax = axes, y = df[column].index, x = df[column], \n                    hue = df['test preparation course'], palette = 'crest', alpha = 0.8)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","59344c35":"list(zip(Num_vars, ax_0.flatten()))","3a363aba":"list(enumerate(zip(Num_vars, ax_0.flatten())))","e8190773":"train_no_NA = df.dropna()\n\ntrain_cat_visual_0 = train_no_NA[['sex']].columns.tolist()","d99a2757":"sns.set_theme(rc = {'figure.dpi': 250, 'axes.labelsize': 7, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'},font_scale = 0.25)\n\nfig, ax = plt.subplots(3, 2, figsize = (6.5, 7.5))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_cat_visual_0, ax.flatten())))):\n    \n    sns.violinplot(ax = axes, x = train_no_NA[column], \n                   y = train_no_NA['math percentage'],\n                   scale = 'width', linewidth = 0.5, \n                   palette = 'crest', inner = None)\n    \n    plt.setp(axes.collections, alpha = 0.3)\n    \n    sns.stripplot(ax = axes, x = train_no_NA[column], \n                  y = train_no_NA['math percentage'],\n                  palette = 'crest', alpha = 0.9, \n                  s = 1.5, jitter = 0.07)\n    sns.pointplot(ax = axes, x = train_no_NA[column],\n                  y = train_no_NA['math percentage'],\n                  color = '#ff5736', scale = 0.25,\n                  estimator = np.mean, ci = 'sd',\n                  errwidth = 0.5, capsize = 0.15, join = True)\n    \n    plt.setp(axes.lines, zorder = 100)\n    plt.setp(axes.collections, zorder = 100)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","cb5afa65":"train_no_NA = df.dropna()\n\ntrain_cat_visual_0 = train_no_NA[['race\/ethnicity']].columns.tolist()","cef1fbae":"sns.set_theme(rc = {'figure.dpi': 250, 'axes.labelsize': 7, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'},font_scale = 0.25)\n\nfig, ax = plt.subplots(3, 2, figsize = (6.5, 7.5))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_cat_visual_0, ax.flatten())))):\n    \n    sns.violinplot(ax = axes, x = train_no_NA[column], \n                   y = train_no_NA['math percentage'],\n                   scale = 'width', linewidth = 0.5, \n                   palette = 'crest', inner = None)\n    \n    plt.setp(axes.collections, alpha = 0.3)\n    \n    sns.stripplot(ax = axes, x = train_no_NA[column], \n                  y = train_no_NA['math percentage'],\n                  palette = 'crest', alpha = 0.9, \n                  s = 1.5, jitter = 0.07)\n    sns.pointplot(ax = axes, x = train_no_NA[column],\n                  y = train_no_NA['math percentage'],\n                  color = '#ff5736', scale = 0.25,\n                  estimator = np.mean, ci = 'sd',\n                  errwidth = 0.5, capsize = 0.15, join = True)\n    \n    plt.setp(axes.lines, zorder = 100)\n    plt.setp(axes.collections, zorder = 100)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","60cb0e8a":"train_no_NA = df.dropna()\n\ntrain_cat_visual_0 = train_no_NA[['parental level of education']].columns.tolist()","8aa9128c":"sns.set_theme(rc = {'figure.dpi': 250, 'axes.labelsize': 7, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'},font_scale = 0.25)\n\nfig, ax = plt.subplots(3, 2, figsize = (6.5, 7.5))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_cat_visual_0, ax.flatten())))):\n    \n    sns.violinplot(ax = axes, x = train_no_NA[column], \n                   y = train_no_NA['math percentage'],\n                   scale = 'width', linewidth = 0.5, \n                   palette = 'crest', inner = None)\n    \n    plt.setp(axes.collections, alpha = 0.3)\n    \n    sns.stripplot(ax = axes, x = train_no_NA[column], \n                  y = train_no_NA['math percentage'],\n                  palette = 'crest', alpha = 0.9, \n                  s = 1.5, jitter = 0.07)\n    sns.pointplot(ax = axes, x = train_no_NA[column],\n                  y = train_no_NA['math percentage'],\n                  color = '#ff5736', scale = 0.25,\n                  estimator = np.mean, ci = 'sd',\n                  errwidth = 0.5, capsize = 0.15, join = True)\n    \n    plt.setp(axes.lines, zorder = 100)\n    plt.setp(axes.collections, zorder = 100)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","8c6eddc6":"train_no_NA = df.dropna()\n\ntrain_cat_visual_0 = train_no_NA[['lunch']].columns.tolist()","cb7a43bc":"sns.set_theme(rc = {'figure.dpi': 250, 'axes.labelsize': 7, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'},font_scale = 0.25)\n\nfig, ax = plt.subplots(3, 2, figsize = (6.5, 7.5))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_cat_visual_0, ax.flatten())))):\n    \n    sns.violinplot(ax = axes, x = train_no_NA[column], \n                   y = train_no_NA['math percentage'],\n                   scale = 'width', linewidth = 0.5, \n                   palette = 'crest', inner = None)\n    \n    plt.setp(axes.collections, alpha = 0.3)\n    \n    sns.stripplot(ax = axes, x = train_no_NA[column], \n                  y = train_no_NA['math percentage'],\n                  palette = 'crest', alpha = 0.9, \n                  s = 1.5, jitter = 0.07)\n    sns.pointplot(ax = axes, x = train_no_NA[column],\n                  y = train_no_NA['math percentage'],\n                  color = '#ff5736', scale = 0.25,\n                  estimator = np.mean, ci = 'sd',\n                  errwidth = 0.5, capsize = 0.15, join = True)\n    \n    plt.setp(axes.lines, zorder = 100)\n    plt.setp(axes.collections, zorder = 100)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","5d40d8b6":"train_no_NA = df.dropna()\n\ntrain_cat_visual_0 = train_no_NA[['test preparation course']].columns.tolist()","31202148":"sns.set_theme(rc = {'figure.dpi': 250, 'axes.labelsize': 7, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'},font_scale = 0.25)\n\nfig, ax = plt.subplots(3, 2, figsize = (6.5, 7.5))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_cat_visual_0, ax.flatten())))):\n    \n    sns.violinplot(ax = axes, x = train_no_NA[column], \n                   y = train_no_NA['math percentage'],\n                   scale = 'width', linewidth = 0.5, \n                   palette = 'crest', inner = None)\n    \n    plt.setp(axes.collections, alpha = 0.3)\n    \n    sns.stripplot(ax = axes, x = train_no_NA[column], \n                  y = train_no_NA['math percentage'],\n                  palette = 'crest', alpha = 0.9, \n                  s = 1.5, jitter = 0.07)\n    sns.pointplot(ax = axes, x = train_no_NA[column],\n                  y = train_no_NA['math percentage'],\n                  color = '#ff5736', scale = 0.25,\n                  estimator = np.mean, ci = 'sd',\n                  errwidth = 0.5, capsize = 0.15, join = True)\n    \n    plt.setp(axes.lines, zorder = 100)\n    plt.setp(axes.collections, zorder = 100)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","e631b993":"df.isnull().sum()\n## no null value treatment","da31b7e4":"df=pd.get_dummies(data=df,columns=obj,drop_first=True)\ndf","a1208f52":"X = df.drop(['math percentage'],axis = 1)\nY = df['math percentage']\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.3,random_state=44)","8a4f6592":"from sklearn.ensemble import RandomForestRegressor\nforest= RandomForestRegressor(n_estimators =40, random_state = 0)\nforest.fit(X_train,Y_train)  \ny_pred = forest.predict(X_test)\nforest.score(X_test,Y_test)","0f35367d":"plt.scatter(Y_test,y_pred)\nplt.xlabel('Y Test (True Values)')\nplt.ylabel('Predicted values')\nplt.show()","950b18ee":"metrics.explained_variance_score(Y_test,y_pred)","16a03c09":"print('MAE',metrics.mean_absolute_error(Y_test,y_pred))\nprint('MSE',metrics.mean_squared_error(Y_test,y_pred))\nprint('RMSE',np.sqrt(metrics.mean_squared_error(Y_test,y_pred)))","d59a6e1a":"sns.displot(Y_test-y_pred,bins = 50,kde = True)","b37662b5":"reg = linear_model.LinearRegression()\nreg.fit(X_train, Y_train)\npred = reg.predict(X_test)\nreg.score(X_test,Y_test)","74612364":"plt.scatter(Y_test,pred)\nplt.xlabel('Y Test (True Values)')\nplt.ylabel('Predicted values')\nplt.show()","2f77ac25":"metrics.explained_variance_score(Y_test,pred)","9df3c33c":"print('MAE',metrics.mean_absolute_error(Y_test,pred))\nprint('MSE',metrics.mean_squared_error(Y_test,pred))\nprint('RMSE',np.sqrt(metrics.mean_squared_error(Y_test,pred)))","bd619215":"sns.displot(Y_test-pred,bins = 50,kde = True)","61eb1535":"#### In groub D, in all categories many number of students not taken any course","068c7ad3":"# Analysis and visualisation using group by","b9e3cd8d":"#### More number of parents studied in college\n#### Less number of parents done Masters","ba0ac6e5":"# Data visualisation using Autoviz","96f3b8b1":"#### In df  in all other categories moret number of students not taken any course","c5f29007":"# Prediction using Linear Regression","cde011e0":"## since all numerical column are percentages i'll multiply them with 100 ","49d99ecf":"#### In group B more number of students irrespective of parent level of education are taking standard food except master's degree parents students take free\/reduced lunch","23297e00":"#### In group D parents with Education level bachelor's degrre,associates's degree,high schoolhave male children more\n#### In group D parents with Master's degree have female children more\n#### In group D parents with some high school have male and female childrens equal","6b322e35":"# Query 10: Find the student with highest writing score percentage","c2b6753e":"#### In group B,In students who has completed course females are more(but only 2 students difference)\n#### In group B, In students who has not completed course females are more","cd812bd2":"# Query 11: Find the student with lowest writing score percentage","0528e44b":"# Analysis related to Query 3","300045e5":"## Violin plot with strip plots","74261567":"#### Outliers in math percentage","45b3bd69":"#### pairlot of all numerical columns with test preparation score as hue\n\n### We can clearly see that all numerical columns are highly corelated and their values are slightly right skewed","57d0b548":"#### In group E more number of students irrespective of parent level of education are taking standard food","599afd65":"# Exploratory Data Analysis Using User Defined function","8f667a3d":"# Feature Selection","3fb4d28c":"#### In df more number of students irrespective of parent level of education are taking standard food ","c12dfdb3":"#### People who taken course for test preparation done very great in math exam","a8fceb3c":"#### In group E , children of high school  level educated parents both completed and none are equal\n#### In group E, children of bachelor's degree level educated parents have more number of completed course than none","1ad24178":"#### In group E,In students who has completed course males are more.\n#### In group E, In students who has not completed course females are more","146404b2":"# Query 13: Find the students who got highest math percentage in group B","4c96f688":"# Prediction Using Random forest Regressor","2f08d603":"#### No outliers in group A","e908662b":"#### Most of the students are eating standard lunch(to their fullest)","62b86a5c":"# Query 12: Find the students who gots equal percentage in all scores","6f471740":"## Bar plot analysis","4fc4ff64":"#### In groub B Except children of some high school level educated parents(In this case both are equal), in all other categories more number of students not taken any course","be2cef04":"# Visualization related to Query 1","5568aae6":"# Query 7: Find the student with lowest math percentage","dcfd97c5":"#### In group A only parents master's degree have more number of female children(only 1 diffeence)","bb17ea96":"#### In groub C in all  categories more number of  of students not taken any course","6662abe4":"## Scatter plots","66a1f9f7":"#### In group E parents with Education level bachelor's degrre,Master's degree,high school have female children more\n#### In group E only parents with some college,associates's degree,some high school have male children more","e3d680c9":"#### In group C,In students who has completed course females are more\n#### In group C, In students who has not completed course females are more","404512c3":"#### Female students are more in number than male","17b7aed8":"# Query 1: Find all students  belongs to group B","eecb477f":"#### pairlot of all numerical columns with parental level of education as hue","ec8a9a30":"# UPVOTE IF U LIKE ","aefe4b2b":"#### Outliers are present in wrting score percentage and it has a positive corelation with math percentage","862bcc76":"#### More females,more test preparation completed students, standard lunch students, parents of bachelor's degree, group D who got 100 percentage in writing","410f62f6":"#### In group D parents with some college level education level are more\n#### In group D parents with maters's degree level of education are very less\n#### In group D most of the students eating standard lunch\n#### In group D there are more number of students who has not taken any test preparation course\n#### In group D males are more in number(only 4 difference)","4b1bcb9e":"#### All numerical columns are highly positively corelated","0cbf3ef5":"# Query 5: Find all students belongs to group E","591e958f":"# Query 8: Find the student with highest reading score percentage","31ff12ba":"## Count of Outliers","d56cbce2":"#### In group B parents with Education level bachelor's degrre,Master's degree,associates's degree,some college,some high school have female children more\n#### In group B only parents with high college have male children more","73c89eed":"## visualisation of whole df","379b7111":"# Exploratory Data Analysis","770397e8":"#### This looks like balanced data","3182e5f2":"# Query 6: Find the student with highest math percentage","a60c20e1":"## Encoding","68dc0243":"#### In group B parents with  high school education level are more\n#### In group B parents with maters's degree level of education are very less\n#### In group B most of the students eating standard lunch\n#### In group B most of the students are females","57c35609":"#### In group A irrespective of gender students who have not taken course are more in number","ce8f2b84":"#### In group C parents with Education level bachelor's degrre,associates's degree,some high school have female children more\n#### In group C parents with high school, master's degree have male children more","e27a163d":"#### No outliers in master's degree and associate's degree","bcfdd39a":"# Analysis related to Query 4","4d1a1a45":"#### Ouliers in reading score percentage and it has a good corelation with math percentage","eabfa491":"#### In group C parents with associate's degree education level are more\n#### In group C parents with maters's degree level of education are very less\n#### In group C most of the students eating standard lunch\n#### In group C there are more number of students who has not taken any test preparation course\n#### In group C most of the students are females","f3fc00bc":"# Query 4: Find all students belongs to group D","83ca3745":"#### Females are doing good in reading, writing but in math exam males are good over them","a0e4ab95":"# Query 3: Find all students belongs to group C","c4174ea5":"# Data Visualisation","9df98a86":"# Data Preprocessing","9fae2dab":"# Visualization related to Query 2","1a9989f9":"# Analysis related to Query 5","29061278":"## grouped tables for categorical variables","0967165f":"# Query 9: Find the student with lowest reading score percentage","730d6573":"#### Group E is more balanced because math percentage, reading score percentage and writing score percentage are alomost same","80c69372":"#### pairlot of all numerical columns with race\/ethnicity as hue","04ff3234":"#### In group B parents with Education level bachelor's degrre,Master's degree,associates's degree,,high school,some high school have female children more\n#### In group B only parents with some college have male children more","b9bd3951":"# Query 2: Find all students belongs to group A","62e7b442":"# Analysis and visualisation using Query","89c58419":"#### In group A, In master's degree there are no students with test preparation course taken\n#### In all other cases students who have not taken course are more in number","5726dea1":"#### Most of the students didn't took any course for test preparation","3740e23e":"#### In group D more number of students irrespective of parent level of education are taking standard food except bachelor's degree parents students take free\/reduced lunch and standard lunch equally","d12d7660":"#### In df,In students who has completed course females are more\n#### In df, In students who has not completed course females are more","afb1b55c":"# Advanced Visualisation","5f3d3342":"#### In group D,In students who has completed course females are more\n#### In group D, In students who has not completed course males are more","3f576103":"#### In group A parents with  some high school education level are more\n#### In group A parents with maters's degree level of education are very less\n#### In group A most of the students eating standard lunch\n#### In group A most of the students are not involved in test preparation course\n#### In group A most of the students are males","932ebf3b":"#### The main reason of plotting strip plots is sometimes values jump in the column, to checknthe continuity strip plot is needed.","5aab6e40":"#### More females,more test preparation completed students, standard lunch students, parents of bachelor's degree, group E who got 100 percentage in reading ","fcb5533b":"#### pairlot of all numerical columns with sex as hue","f8204357":"#### In group E parents with associate's college level education level are more\n#### In group E parents with maters's degree level of education are very less\n#### In group E most of the students eating standard lunch\n#### In group E there are more number of students who has not taken any test preparation course\n#### In group E males are more in number(only 2 difference)","35c568a6":"## Getting unique values of each category","b6850454":"#### In group A more number of students irrespective of parent level of education are taking standard food except associate's degree parents students are equal in number in both cases.","b85690ed":"#### People with standard lunch are doing great","0b32b820":"#### out of 7 students who got 100% 5 of them are from group E \n#### parental level of education of students who got 100% math percentage are 3 from some college, 2 from associates's degree, 2 from bachelor's degree\n#### 6 students eating standard lunch out of 7\n#### 4 are males and 3 are females\n#### 3 students got 100 in all percentages(2 of them are females)","4006d48c":"# Loading Data Set","a07c0e99":"#### In group C more number of students irrespective of parent level of education are taking standard food except master's degree parents students take free\/reduced lunch","bceab585":"#### pairlot of all numerical columns with lunch as hue","d87fbac7":"# Importing Libraries "}}