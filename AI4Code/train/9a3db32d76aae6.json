{"cell_type":{"426092b1":"code","f6ca276d":"code","cfa69dba":"code","375ff4af":"code","430f6b2d":"code","24cbf5a7":"code","c94294e7":"code","7ea3f559":"code","b285619f":"code","6374dfac":"code","a5544ede":"code","08c9171f":"code","c716cdf5":"code","b879d5dc":"code","d3ffa14f":"code","564a491b":"code","589755ba":"code","208772b9":"code","75703568":"code","90fc67cd":"code","586c461c":"code","67d74838":"code","dd5e5290":"code","2e6b4d85":"code","b1743cb9":"code","e25e6c38":"code","b20ea845":"code","bc417268":"code","c534a5d1":"code","da5c736d":"code","a785091f":"code","153efacc":"code","65df739d":"code","42770274":"code","e166bc6d":"code","196ed765":"code","3ea06d2d":"code","d3b235eb":"code","21809ac2":"code","1603a2e5":"code","a58225b3":"code","5dc76765":"markdown","be93cbec":"markdown","45dfa341":"markdown","5aa3261d":"markdown","2a546076":"markdown","66f8fb5e":"markdown","7ad7e5b8":"markdown","849853a9":"markdown","0ca1467c":"markdown"},"source":{"426092b1":"from IPython.display import IFrame, YouTubeVideo\nYouTubeVideo('JnskIHjAxkc',width=600, height=400)","f6ca276d":"#Importing required libraries\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nimport gc\n\nfrom sklearn.model_selection import train_test_split\n\n\nimport tensorflow as tf\nfrom tqdm.autonotebook import tqdm\n\nimport numpy as np #\nimport pandas as pd \n\nfrom keras import Sequential\nfrom keras.callbacks import EarlyStopping\n\nfrom keras.optimizers import Adam, SGD\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\nfrom keras.layers import Lambda, Input, GlobalAveragePooling2D,BatchNormalization\nfrom keras.utils import to_categorical\n# from keras import regularizers\nfrom tensorflow.keras.models import Model\n\n\nfrom keras.preprocessing.image import load_img\n# from keras.preprocessing.image import img_to_array\n# from keras.applications.imagenet_utils import decode_predictions\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cfa69dba":"\n# Check for GPU\nprint(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")\ntf.config.list_physical_devices(\"GPU\")","375ff4af":"#reading labels csv file\n\nlabels = pd.read_csv('\/kaggle\/input\/dog-breed-identification\/labels.csv')\nlabels.head()","430f6b2d":"#describe\nlabels.describe()","24cbf5a7":"#function to show bar length\ndef barw(ax): \n    \n    for p in ax.patches:\n        val = p.get_width() #height of the bar\n        x = p.get_x()+ p.get_width() # x- position \n        y = p.get_y() + p.get_height()\/2 #y-position\n        ax.annotate(round(val,2),(x,y))\n        \n#finding top dog brands\n\nplt.figure(figsize = (15,30))\nax0 =sns.countplot(y=labels['breed'],order=labels['breed'].value_counts().index)\nbarw(ax0)\nplt.show()","c94294e7":"# #total unique breeds\n\n# labels['breed'].nunique()","7ea3f559":"# Lets check one image\nfrom IPython.display import display, Image\nImage(\"..\/input\/dog-breed-identification\/train\/43572ba7edf772a95f539e57afd9eb43.jpg\")","b285619f":"import os\nif len(os.listdir('\/kaggle\/input\/dog-breed-identification\/train\/')) == len(labels['id']):\n    print('Number of file matches number of actual images!')\nelse:\n    print('Number of file doesnot matches number of actual images!!')","6374dfac":"\n#Create list of alphabetically sorted labels.\nclasses = sorted(list(set(labels['breed'])))\nn_classes = len(classes)\nprint('Total unique breed {}'.format(n_classes))\n\n\n\n#Map each label string to an integer label.\nclass_to_num = dict(zip(classes, range(n_classes)))\nclass_to_num\n","a5544ede":"\ninput_shape = (331,331,3)\n\n\ndef images_to_array(directory, label_dataframe, target_size = input_shape):\n    \n    image_labels = label_dataframe['breed']\n    images = np.zeros([len(label_dataframe), target_size[0], target_size[1], target_size[2]],dtype=np.uint8) #as we have huge data and limited ram memory. uint8 takes less memory\n    y = np.zeros([len(label_dataframe),1],dtype = np.uint8)\n    \n    for ix, image_name in enumerate(tqdm(label_dataframe['id'].values)):\n        img_dir = os.path.join(directory, image_name + '.jpg')\n        img = load_img(img_dir, target_size = target_size)\n#         img = np.expand_dims(img, axis=0)\n#         img = processed_image_resnet(img)\n#         img = img\/255\n        images[ix]=img\n#         images[ix] = img_to_array(img)\n        del img\n        \n        dog_breed = image_labels[ix]\n        y[ix] = class_to_num[dog_breed]\n    \n    y = to_categorical(y)\n    \n    return images,y","08c9171f":"import time \nt = time.time()\n\nX,y = images_to_array('\/kaggle\/input\/dog-breed-identification\/train', labels[:])\n\nprint('runtime in seconds: {}'.format(time.time() - t))","c716cdf5":"# y[0]","b879d5dc":"# X[0]","d3ffa14f":"## Another way to create one hot encoded vectors\n# dummy = pd.get_dummies(df_50['breed'])\n\n# classes = dummy.columns \n# print('we have total {} number of unique dog breeds'.format(len(classes)))\n\n#convert this into np.array\n\n# y = np.array(dummy)\n# # we can delete the dummy because we dont need it anymore ----- > We are saving RAM\n\n# del dummy\n\n# y[0:2]","564a491b":"# np.where(y[5]==1)[0][0]\n\n# lets check some dogs and their breeds\nn=25\n\n# setup the figure \nplt.figure(figsize=(20,20))\n\nfor i in range(n):\n#     print(i)\n    ax = plt.subplot(5, 5, i+1)\n    plt.title(classes[np.where(y[i] ==1)[0][0]])\n    plt.imshow(X[i].astype('int32')) # .astype('int32') ---> as imshow() needs integer data to read the image\n    ","589755ba":"#Learning Rate Annealer\nlrr= ReduceLROnPlateau(monitor='val_acc', factor=.01, patience=3, min_lr=1e-5,verbose = 1)\n\n#Prepare call backs\nEarlyStop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n","208772b9":"# Hyperparameters\nbatch_size= 128\nepochs=50\nlearn_rate=.001\nsgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\nadam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None,  amsgrad=False)","75703568":"#function to extract features from the dataset by a given pretrained model\nimg_size = (331,331,3)\n\ndef get_features(model_name, model_preprocessor, input_size, data):\n\n    input_layer = Input(input_size)\n    preprocessor = Lambda(model_preprocessor)(input_layer)\n    base_model = model_name(weights='imagenet', include_top=False,\n                            input_shape=input_size)(preprocessor)\n    avg = GlobalAveragePooling2D()(base_model)\n    feature_extractor = Model(inputs = input_layer, outputs = avg)\n    \n    #Extract feature.\n    feature_maps = feature_extractor.predict(data, verbose=1)\n    print('Feature maps shape: ', feature_maps.shape)\n    return feature_maps","90fc67cd":"# Extract features using InceptionV3 \nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\ninception_preprocessor = preprocess_input\ninception_features = get_features(InceptionV3,\n                                  inception_preprocessor,\n                                  img_size, X)","586c461c":"# Extract features using Xception \nfrom keras.applications.xception import Xception, preprocess_input\nxception_preprocessor = preprocess_input\nxception_features = get_features(Xception,\n                                 xception_preprocessor,\n                                 img_size, X)","67d74838":"# Extract features using InceptionResNetV2 \nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\ninc_resnet_preprocessor = preprocess_input\ninc_resnet_features = get_features(InceptionResNetV2,\n                                   inc_resnet_preprocessor,\n                                   img_size, X)","dd5e5290":"# Extract features using NASNetLarge \nfrom keras.applications.nasnet import NASNetLarge, preprocess_input\nnasnet_preprocessor = preprocess_input\nnasnet_features = get_features(NASNetLarge,\n                               nasnet_preprocessor,\n                               img_size, X)","2e6b4d85":"del X #to free up some ram memory\ngc.collect()","b1743cb9":"#Creating final featuremap by combining all extracted features\n\nfinal_features = np.concatenate([inception_features,\n                                 xception_features,\n                                 nasnet_features,\n                                 inc_resnet_features,], axis=-1) #axis=-1 to concatinate horizontally\n\nprint('Final feature maps shape', final_features.shape)\n\n","e25e6c38":"#Prepare Deep net\n\nmodel = Sequential()\n# model.add(Dense(1028,input_shape=(final_features.shape[1],)))\nmodel.add(Dropout(0.7,input_shape=(final_features.shape[1],)))\nmodel.add(Dense(n_classes,activation= 'softmax'))\n\nmodel.compile(optimizer=adam,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n#Training the model. \nhistory = model.fit(final_features, y,\n            batch_size=batch_size,\n            epochs=epochs,\n            validation_split=0.2,\n            callbacks=[lrr,EarlyStop])","b20ea845":"#deleting to free up ram memory\n\ndel inception_features\ndel xception_features\ndel nasnet_features\ndel inc_resnet_features\ndel final_features\ngc.collect()","bc417268":"# sample_df = pd.read_csv('\/kaggle\/input\/dog-breed-identification\/sample_submission.csv')","c534a5d1":"# sample_df.shape","da5c736d":"#Function to read images from test directory\n\ndef images_to_array_test(test_path, img_size = (331,331,3)):\n    test_filenames = [test_path + fname for fname in os.listdir(test_path)]\n\n    data_size = len(test_filenames)\n    images = np.zeros([data_size, img_size[0], img_size[1], 3], dtype=np.uint8)\n    \n    \n    for ix,img_dir in enumerate(tqdm(test_filenames)):\n#         img_dir = os.path.join(directory, image_name + '.jpg')\n        img = load_img(img_dir, target_size = img_size)\n#         img = np.expand_dims(img, axis=0)\n#         img = processed_image_resnet(img)\n#         img = img\/255\n        images[ix]=img\n#         images[ix] = img_to_array(img)\n        del img\n    print('Ouptut Data Size: ', images.shape)\n    return images\n\ntest_data = images_to_array_test('\/kaggle\/input\/dog-breed-identification\/test\/', img_size)","a785091f":"#Extract test data features.\ndef extact_features(data):\n    inception_features = get_features(InceptionV3, inception_preprocessor, img_size, data)\n    xception_features = get_features(Xception, xception_preprocessor, img_size, data)\n    nasnet_features = get_features(NASNetLarge, nasnet_preprocessor, img_size, data)\n    inc_resnet_features = get_features(InceptionResNetV2, inc_resnet_preprocessor, img_size, data)\n\n    final_features = np.concatenate([inception_features,\n                                     xception_features,\n                                     nasnet_features,\n                                     inc_resnet_features],axis=-1)\n    \n    print('Final feature maps shape', final_features.shape)\n    \n    #deleting to free up ram memory\n    del inception_features\n    del xception_features\n    del nasnet_features\n    del inc_resnet_features\n    gc.collect()\n    \n    \n    return final_features\n\ntest_features = extact_features(test_data)","153efacc":"#Free up some space.\ndel test_data\ngc.collect()","65df739d":"#Predict test labels given test data features.\n\npred = model.predict(test_features)","42770274":"# First prediction\nprint(pred[0])\nprint(f\"Max value (probability of prediction): {np.max(pred[0])}\") # the max probability value predicted by the model\nprint(f\"Sum: {np.sum(pred[0])}\") # because we used softmax activation in our model, this will be close to 1\nprint(f\"Max index: {np.argmax(pred[0])}\") # the index of where the max value in predictions[0] occurs\nprint(f\"Predicted label: {classes[np.argmax(pred[0])]}\")","e166bc6d":"# Create pandas DataFrame with empty columns\npreds_df = pd.DataFrame(columns=[\"id\"] + list(classes))\npreds_df.head()\n","196ed765":"# Append test image ID's to predictions DataFrame\ntest_path = \"\/kaggle\/input\/dog-breed-identification\/test\/\"\npreds_df[\"id\"] = [os.path.splitext(path)[0] for path in os.listdir(test_path)]\npreds_df.head()","3ea06d2d":"preds_df.loc[:,list(classes)]= pred\n\npreds_df.to_csv('submission.csv',index=None)\npreds_df.head()","d3b235eb":"#Custom input\n\nImage('..\/input\/goldend\/DBS_GoldRetriever_1280.jpg')","21809ac2":"#reading the image and converting it into an np array\n\nimg_g = load_img('..\/input\/goldend\/DBS_GoldRetriever_1280.jpg',target_size = img_size)\nimg_g = np.expand_dims(img_g, axis=0) # as we trained our model in (row, img_height, img_width, img_rgb) format, np.expand_dims convert the image into this format\n# img_g","1603a2e5":"img_g.shape","a58225b3":"# #Predict test labels given test data features.\ntest_features = extact_features(img_g)\npredg = model.predict(test_features)\nprint(f\"Predicted label: {classes[np.argmax(predg[0])]}\")\nprint(f\"Probability of prediction): {round(np.max(predg[0])) * 100} %\")","5dc76765":"### Please check this video for better understanding :)","be93cbec":"# Model Building:\n\n* The basic idea here is to extract features from the data set from pretrained models and create a simple deep net by using all those features combined.\n* So we will GlobalAveragePooling2D to extract a pooled output from our selected models\n* img_size = You can change this shape according to the documentation of the pretrained model\n* Keras documentation for all models: https:\/\/keras.io\/api\/applications\/\n\n","45dfa341":"# Testing with custom input:","5aa3261d":"**Observation:**\n1. We have total 120 unique breeds\n2. We have atleast 60 images per category of breed\n3. Google recommends at least 10 images per class to bet a better model\n4. More sample available ----- > More efficeint the model will be","2a546076":"![dog%20breed.png](attachment:dog%20breed.png)","66f8fb5e":"**One-hot Encoding:**\nSince the output of our predictor for each input is a vector of probabilities for each class we must convert out label dataset to be the same format. That is for each input a row vector of length num_classes with a 1 at the index of the label and 0's everywhere else.","7ad7e5b8":"# Please upvote this notebook :)\n\n#### Special Thanks to :\n1. https:\/\/www.kaggle.com\/phylake1337\/0-18-loss-simple-feature-extractors","849853a9":"### Creating callbacks:\n\n(things to help our model)\n\nCallbacks are helper functions a model can use during training to do things such as save a models progress, check a models progress or stop training early if a model stops improving.\n\nReduceLROnPlateau: Reduce learning rate when a metric has stopped improving.","0ca1467c":"## End to End Dog Breed Multi Class Classification\n### 1.Problem\nThere are 120 breeds of dog in the data. We have to identify according to their breeds.\n### 2.Data\nThere are training set and a test set of images of dogs. Each image has a filename that is its unique id. The dataset comprises 120 breeds of dogs.\n* train.zip - the training set, you are provided the breed for these dogs\n* test.zip - the test set, you must predict the probability of each breed for each image\n* sample_submission.csv - a sample submission file in the correct format\n* labels.csv - the breeds for the images in the train set\n\n### Evaluation\nCross entropy loss.\n### Features\n* we are dealing with the unstructure data set.\n* There are about 10000+ images in the training data.\n* There are about 10000+ images in the test data.\n\nNow Since we have unstructured data we have to work with the library like tensorflow. so lets import the necessary libraries and directly jump into the project"}}