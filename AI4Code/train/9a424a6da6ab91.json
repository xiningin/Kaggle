{"cell_type":{"d3b6fcb9":"code","54a8fe58":"code","7979e607":"code","0a719688":"code","de2609f7":"markdown","3d831f7d":"markdown","109607de":"markdown","b8939c36":"markdown","b5afb032":"markdown","ad5f95d4":"markdown","f6086f00":"markdown","e669ed57":"markdown","b23fa959":"markdown","755fca89":"markdown","687e672b":"markdown","7d3a3acc":"markdown","1d83bb80":"markdown","9d7ac98c":"markdown","689c13d4":"markdown","8db9c27a":"markdown","e9a1bea2":"markdown"},"source":{"d3b6fcb9":"import torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt \nimport numpy as np","54a8fe58":"class AlexNet(nn.Module):\n    \"\"\"\n    Input dims: (num_samples, 3, 227, 227)\n    \"\"\"\n    def __init__(self):\n        super(AlexNet, self).__init__()\n        \n        # Activation unit(s) and pooling unit\n        self.softmax = nn.Softmax()\n        self.relu = nn.ReLU()\n        self.overlapped_max_pool = nn.MaxPool2d(kernel_size = (3,3), stride = (2,2))\n        \n        # conv w\/ z=11, s=4 i.e \n        # (1,3,227,227) >> (1,96,55,55) >> pool\n        self.conv11 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=(11,11), stride=(4,4), padding=(0,0))\n\n        # conv w\/ z=5, pad=2 ,s=1\n        # (1,96,27,27) >> (1,256,27,27) >> pool\n        self.conv5 = nn.Conv2d(in_channels = 96, out_channels = 256, kernel_size = (5,5), stride = (1,1), padding = (2,2))\n        \n        # series of 3 convs (note: spatial resolution preserved. s=1, p=1 for z=3)\n        # (1, 256, 13, 13) >> \n        # (1, 384, 13, 13) >> (1, 384, 13, 13) >> (1, 256, 13, 13) >> pool\n        self.conv3_series = self.get_conv3_series([\n            {'in_ch': 256, 'out_ch': 384, 'act': nn.ReLU},\n            {'in_ch': 384, 'out_ch': 384, 'act': nn.ReLU},\n            {'in_ch': 384, 'out_ch': 256, 'act': nn.ReLU},\n        ])\n        \n        # fc linear units\n        # (1, 256, 6, 6) >> reshape(1, -1) >> (1, 9262) >>\n        # (in:9216, out: 4096) >> (in: 4096, out: 1000) >> softmax\n        self.fc_lin_series = self.get_fc_lin_series([\n            {'in_nodes': 256*6*6, 'out_nodes': 4096, 'dropout': 0.5, 'act': nn.ReLU},\n            {'in_nodes':    4096, 'out_nodes': 4096, 'dropout':   0, 'act': nn.ReLU},\n            {'in_nodes': 4096   , 'out_nodes': 1000, 'dropout': 0.5, 'act': nn.Softmax},\n        ])\n        \n    def forward(self, x):\n        \n        # conv, max\n        x = self.relu(self.conv11(x))\n        x = self.overlapped_max_pool(x)\n        \n        # conv, max\n        x = self.relu(self.conv5(x))\n        x = self.overlapped_max_pool(x)\n        \n        # conv, conv, conv, max\n        x = self.conv3_series(x)\n        x = self.overlapped_max_pool(x)\n        \n        # reshape to (num_samples, -1)\n        x = x.reshape(x.shape[0], -1)\n        \n        # fc1, drop >> fc2, drop >> softmax\n        x = self.fc_lin_series(x)\n        \n        return x\n        \n    \n    # ====================================\n    # helpers\n    # ====================================\n    def get_conv3_series(self, configs):\n        conv3_series = []\n        \n        for config in configs:\n            in_ch, out_ch   = config['in_ch'], config['out_ch']\n            activation_unit = config['act']\n            \n            conv3_series.append(\n                nn.Conv2d(\n                    in_channels   = in_ch, \n                    out_channels  = out_ch, \n                    kernel_size   = (3,3), \n                    stride        = (1,1), \n                    padding       = (1,1)\n                )\n            )\n            conv3_series.append( activation_unit() )\n            \n        return nn.Sequential(*conv3_series)\n    \n    \n    def get_fc_lin_series(self, configs):\n        lin_series = []\n        \n        for config in configs:\n            in_nodes, out_nodes, dropout_val = config['in_nodes'], config['out_nodes'], config['dropout']\n            activation_unit = config['act']\n\n            lin_series.append( nn.Linear(in_nodes, out_nodes) )\n            if activation_unit == nn.ReLU:\n                lin_series.append( activation_unit() )\n            elif activation_unit == nn.ReLU:\n                lin_series.append( activation_unit(dim=out_nodes) )\n            lin_series.append( nn.Dropout(p=dropout_val) )\n            \n        return nn.Sequential(*lin_series)","7979e607":"NUM_SAMPLES = 32\nINPUT       = torch.randn(NUM_SAMPLES, 3, 227, 227)","0a719688":"model = AlexNet()\nprint(model(INPUT).shape)","de2609f7":"**Build Model**","3d831f7d":"<br>","109607de":"- Main Purpose (of paper and model)\n- Data and Preprocessing\n- KPI\n- Architecture\n- Evaluation\n- Novel Features, Improvements and Observations\n- Obsolete Features","b8939c36":"<br>","b5afb032":"# 01. Main Purpose","ad5f95d4":"- Generalisation. Prevent overfitting for `1 : 24` train and validation set\n- Build model w\/ large learning [capacity](https:\/\/www.kaggle.com\/l0new0lf\/04-00-lenet-5-1998) (Large scale data w\/ deep CNN)\n- Optimisatoin. Separate paper for highly optimized implementation of CNN (six days training on GTX 580\/3GB)","f6086f00":"# 07. Obsolete Features\n\n   - Local Response Normalisation (Proved useless in [VGGNet](https:\/\/www.kaggle.com\/l0new0lf\/2014-vgg) even w\/ some memory disadvantages)\n     - Normalize \"adjacent\" kernel maps at same spacial position (in depth direction)yer \n     - Top-1 error reduced by `1.4 %`     \n     - Top-5 error reduced by `1.2 %`","e669ed57":"# 04. Model\n\n## A. Architecture\n\n   - Softamax @output\n   - Optionally applied following --- FC, overlapped pool, LRN\n   - Variable kernel size 11, 5, 3 (in decreasing order) \n   - dropout(0.5)\n   - conv max >> conv max >> conv conv conv max\n   - Almost all convs try to preserve spation resolution (except final conv)\n   \n   ![image.png](attachment:image.png)\n   [image source: Manning Publications](https:\/\/dpzbhybb2pdcj.cloudfront.net\/elgendy\/v-3\/Figures\/05_04.png)\n\n## B. Actiavation Function\n\n   - Non saturating **ReLU** (see 06)\n   \n   [know-more-about-relu](to-nb)\n\n## C. Loss Function\n\n   - <s>Maximize (in paper)<\/s> Minimize Multinomial Logistic Regression objective\n   \n   $$- \\sum{y_{true}\\log{P(y_{true} | x_i})} \\,\\,\\, \\text{for every class}$$ \n   \n   [know-more-about-loss-func](https:\/\/www.kaggle.com\/l0new0lf\/log-loss\/)\n   \n\n## D. Optimizer and Regualrisation\n\n   - [SGD w\/ momentum](https:\/\/www.kaggle.com\/l0new0lf\/sgd-momentum) + Weigh Decay Regularizer\n       - *Weight decay regularizer is not same as L2 regularizer. [But can be made equivalent.](https:\/\/towardsdatascience.com\/weight-decay-l2-regularization-90a9e17713cd)*\n       - Momentum coeff: 0.9\n       - Weight decay coeff: 0.0005 (constant multiplied to L2 norm)\n       - Batch size: 128\n      \n   - Uses of decay\n       - regularizer (decreases test error by generalisation)\n       - decreases training error too\n   - Initialized wts w\/ `N(0, 1e2)` and biases w\/ `0` (accelerates learning)\n   - Learning rate\n       - initially `1e2`\n       - divided by 10 (when *val error* stops decreasing)\n       - divided 3 times for 90 epochs\n       \n   [know-more-about-optimizer](https:\/\/www.kaggle.com\/l0new0lf\/sgd-momentum)\n   ","b23fa959":"# 03. KPI\n\n- **Top-1 Error:** Wrong if highest probabilty is of incorrect class\n- **Top-5 Error:** Wrong if Top-5 probabiliites @softmax doesn't have correct class ","755fca89":"# Pytorch implementation","687e672b":"# 02. Data and Preprocessing\n\n## A. Data\n\n   - ISLVRC-2010\n\n   - **Task:** Classification (1000 Labels)\n\n   - **Split:** Random `3:1:24` \n       - Training: 1200k \n       - Validation: 50k\n       - Test: 150k\n       \n## B. Preprocessing\n\n   - **Input Image** \n       - Downsample to `256` square\n       - If rectangle, \n           - Rescale such that `shortest_side = 256`\n           - Crop central `256`\n       - Fed **raw RGB values** ( except subtracting Mean Activity )\n   - **Confusion** \n       - mentioned `256` in paper, `224` in paper diagram but only **`227` gives desired output of `55x55x96` dims!**","7d3a3acc":"> - Input dims `227` { instead of `224`(in paper) `256`(in preprocessing section) } give output `55` (in paper)","1d83bb80":"**TEST**","9d7ac98c":"![image.png](attachment:image.png)","689c13d4":"# **AlexNet 2012**","8db9c27a":"# 06. Novel Features \/ Improvements \/ Key observations\n\n### i. Removing a Layer\n   - single conv layer removed $\\Rightarrow$ loss of `2%` top-1 accuracy\n   - thus, depth is important\n\n### i. Nair and Hinton's **ReLU**\n   - [For training, **staurating nonlinearities are slower** than **non-saturating** nonlinearities.](https:\/\/www.kaggle.com\/l0new0lf\/sat-unsat-nonlin)\n   - Several times **faster** (tested w\/o regularisation)\n   - Do **not** require **input normalisation** to prevent saturation\n        - even little positve input $\\Rightarrow$ Neuron learns\n    \n### ii. Overlapped **Pooling** (note: not convolution)\n   - Observed, little **diificult to overfit** w\/ it\n   -  `z=3` `s=2` reduces Top-1(`0.4%`) and Top-5(`0.3%`) compared to `z=2` `s=2`\n\n### iii. **Reduced overfitting**\n   - **Data Augmentation:** Lablel-preserving transformations (primary)\n        1. Image translations and reflections: **w\/o it, deep CNN do not work** \n        2. Alter RGB intensities (PCA)\n   - **Dropout** (primary)\n        - **Sample differrent architectures w\/ same wts!**\n        - Test time\n           - use all neurons\n           - multiply output by 0.5 (approx of G.M)\n        - x2 training time (p=0.5)\n   - LRN\n   - Overlapped pooling\n\n### iv. **Early stage accelerated learning by initailisation**\n   - Because of positive inputs to ReLU\n\n### v. All convs preserve spatial resolution\n   - Only maxpool down samples\n   - For `k=3`, `s=1` and `p=1` preserves spatial resolution (use [formula](https:\/\/www.kaggle.com\/l0new0lf\/04-00-lenet-5-1998)) \n\n### vi. Two separate GPUs used (cz of inavailabilty)\n   - Pattern of connectivity b\/w GPUs - *Problem of cross-validation*","e9a1bea2":"# 05. Results and observations\n\n- Kernels captured *frequencies*, *orientations* and *color blobs*\n    - GPU 1: Color agnostic\n    - GPU 2: color specific\n- Last 4096 layed Analysis\n    - Similar images $\\Rightarrow$ Euclidean Dist b\/w the 4096 vectors is small\n    - Reduce dims for better use of euclidean distance (Autoencoder \/ PCA)\n- even off-centered images detected successfully"}}