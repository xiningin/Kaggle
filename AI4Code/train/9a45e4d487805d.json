{"cell_type":{"58e28dbe":"code","13a43326":"code","8070b613":"code","43e17553":"code","fa568cba":"code","8afb5d27":"code","0d49b408":"code","23c5bbd2":"code","c8b89c07":"code","586f6883":"code","31cb4574":"code","3dedc042":"code","3460df73":"code","3bc49a18":"code","d99fd15f":"code","58ae59f0":"code","95b235db":"code","eb362f49":"code","07091608":"code","4880299e":"code","ad18d07f":"code","6968da60":"code","105bf61d":"code","7c43f62b":"code","0d47b5f2":"code","395a83e2":"code","a11cf7cb":"code","5d778fca":"code","8cbd8660":"code","005835e1":"code","1e4f464d":"code","8fd2cec7":"code","e82bc6b3":"code","4dbf0d38":"code","3703ab6f":"code","0c0dceed":"code","5b824944":"code","587d9215":"code","069889ef":"code","f0cd4243":"code","052d0fa3":"code","b0a6be25":"code","021c63a1":"code","3675b8c0":"code","1cf1fc6c":"code","94415d46":"code","d1d07ccd":"code","9fc2b8ea":"code","8b0e9ff4":"code","b1dc63e1":"code","d07212bc":"code","09a3448b":"code","4a4166f8":"code","c69f1435":"code","638f7378":"code","b4b152f0":"code","c285a738":"code","3fe3a2e3":"code","74ecb84e":"code","cdb0fc2a":"code","72c07d6f":"code","5cbf70c0":"code","f01b2f0d":"code","8dbc81ea":"code","1bac5dbe":"code","1761fee9":"code","cea20dab":"code","9d10b5d4":"code","492eb003":"code","86f568d8":"code","1b5fce72":"code","1f22528c":"code","2f85ef68":"code","f7f0af33":"code","15b35468":"code","343ea7fa":"code","d4a67162":"code","a88fa833":"code","187c1474":"code","c6af7322":"code","b8e8e928":"code","955b212e":"code","40e0944f":"code","c72a38d1":"code","732145ea":"code","75fa77d6":"code","8f2560a9":"code","5fafa1d0":"code","0c5a4870":"code","70a1c653":"code","cf017558":"code","5074f134":"code","2ded7a9e":"code","90946396":"code","b8b62d08":"code","7994cc6a":"code","fdc67a81":"code","36187a81":"code","9d079fe6":"code","df20dd68":"code","ea8956fb":"code","e5d3fc81":"code","e57263a7":"code","a3a9ad1c":"markdown","7149d234":"markdown","f5a1668d":"markdown","fdb03f12":"markdown","1103cc54":"markdown","6973769b":"markdown","a47bb1fd":"markdown","0501d785":"markdown","97f110a3":"markdown","2dd82deb":"markdown","76fd4aca":"markdown","752f8b36":"markdown","f7e0c6ee":"markdown","0c2d5155":"markdown","4cf6049c":"markdown","d50fb0fc":"markdown","9bd2c7aa":"markdown","78cf3f75":"markdown","23dcdcfe":"markdown","be740c1c":"markdown","c6a50031":"markdown","66a92b21":"markdown","397f7fba":"markdown","d13ecb2c":"markdown","44701ffa":"markdown","4b4505e5":"markdown","bc6a6f92":"markdown","163cd590":"markdown","60aa8897":"markdown","cdc783be":"markdown","b69f74ed":"markdown","2592c2cb":"markdown","8372dc99":"markdown","078a6888":"markdown","d7894cd3":"markdown","090bc40a":"markdown","ccd41847":"markdown","d0975f03":"markdown","0f753c24":"markdown","33f6923d":"markdown","921d87c1":"markdown","821c01a3":"markdown","33d0bcd8":"markdown","be7c3af0":"markdown","70210b72":"markdown","2e57dda5":"markdown","cf1043ba":"markdown","e234fddc":"markdown","a7851aa2":"markdown","756bdde8":"markdown","7c788ad6":"markdown","55350b11":"markdown"},"source":{"58e28dbe":"# This is my default library format\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport statistics as st\nimport scipy.stats as stats\nfrom scipy.stats import norm\n\nimport statsmodels.api as sm\nfrom statsmodels.api import OLS\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nimport category_encoders as ce\nfrom sklearn.preprocessing import OneHotEncoder,OrdinalEncoder, StandardScaler, PolynomialFeatures,MinMaxScaler, KBinsDiscretizer\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import SimpleImputer, IterativeImputer\nfrom sklearn.compose import ColumnTransformer\n# from sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split, StratifiedKFold, RepeatedStratifiedKFold\nfrom sklearn.linear_model import LogisticRegression, Ridge\n\nfrom sklearn.metrics import mean_squared_error, accuracy_score,  confusion_matrix, classification_report, f1_score, recall_score, precision_score,plot_roc_curve, plot_precision_recall_curve, roc_auc_score, precision_recall_curve\n\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree, DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler, NearMiss\nos = SMOTE(random_state=0)\n\nfrom sklearn.feature_selection import SelectPercentile, RFECV\n\nfrom sklearn.datasets import make_classification\n\nimport warnings\nimport pickle\nimport joblib\n\nwarnings.filterwarnings('ignore')","13a43326":"df=pd.read_csv('..\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv')\ndf.head(3)","8070b613":"df.info()","43e17553":"df.describe(include='all')","fa568cba":"plt.figure(figsize=(10,10))\nsns.scatterplot(x= 'city_development_index', y= 'training_hours', data=df, hue='target')\nplt.xlabel('city_development_index', fontsize=23)\nplt.ylabel('training_hours', fontsize=23)","8afb5d27":"plt.figure(figsize=(8,8))\nsns.histplot(df['training_hours'], kde=True, palette='String')","0d49b408":"plt.figure(figsize=(8,8))\nsns.set_theme(style=\"whitegrid\")\nsns.boxplot(data=df, x='training_hours')","23c5bbd2":"# Gender\n\nplt.figure(figsize=(8,8))\nsns.countplot(x='gender', data=df, palette='hls', hue='target', order=['Male','Female','Other'])\nplt.show()","c8b89c07":"df['gender'].value_counts()","586f6883":"df['gender'].value_counts()\/df.shape[0]*100","31cb4574":"df[(df['gender']=='Male') & (df['target']==1)]['target'].value_counts()","3dedc042":"df[(df['gender']=='Male') & (df['target']==1)]['target'].value_counts()\/df[(df['gender']=='Male')].shape[0]*100","3460df73":"df[(df['gender']=='Male') & (df['target']==0)]['target'].value_counts()\/df[(df['gender']=='Male')].shape[0]*100","3bc49a18":"df[(df['gender']=='Female') & (df['target']==1)]['target'].value_counts()\/df[(df['gender']=='Female')].shape[0]*100","d99fd15f":"# Relevant Experience\n\nplt.figure(figsize=(8,8))\nsns.countplot(x='relevent_experience', data=df, palette='hls', hue='target')\nplt.show()","58ae59f0":"df[(df['relevent_experience']=='Has relevent experience') & (df['target']==1)]['target'].value_counts()\/df[(df['relevent_experience']=='Has relevent experience')].shape[0]*100","95b235db":"df[(df['relevent_experience']=='No relevent experience') & (df['target']==1)]['target'].value_counts()\/df[(df['relevent_experience']=='No relevent experience')].shape[0]*100","eb362f49":"plt.figure(figsize=(8,8))\nsns.countplot(x='enrolled_university', data=df, hue='target', palette='hls')\nplt.show()","07091608":"df[(df['enrolled_university']=='no_enrollment') & (df['target']==1)]['target'].value_counts()\/df[(df['enrolled_university']=='no_enrollment')].shape[0]*100","4880299e":"df[(df['enrolled_university']=='Full time course') & (df['target']==1)]['target'].value_counts()\/df[(df['enrolled_university']=='Full time course')].shape[0]*100","ad18d07f":"df[(df['enrolled_university']=='Part time course') & (df['target']==1)]['target'].value_counts()\/df[(df['enrolled_university']=='Part time course')].shape[0]*100","6968da60":"plt.figure(figsize=(8,8))\nsns.countplot(x='education_level', data=df, palette='hls', hue='target', order=['Primary School', 'High School', 'Graduate', 'Masters', 'Phd'])\nplt.show()","105bf61d":"df[(df['education_level']=='Primary School') & (df['target']==1)]['target'].value_counts()\/df[(df['education_level']=='Primary School')].shape[0]*100","7c43f62b":"df[(df['education_level']=='High School') & (df['target']==1)]['target'].value_counts()\/df[(df['education_level']=='High School')].shape[0]*100","0d47b5f2":"df[(df['education_level']=='Graduate') & (df['target']==1)]['target'].value_counts()\/df[(df['education_level']=='Graduate')].shape[0]*100","395a83e2":"df[(df['education_level']=='Masters') & (df['target']==1)]['target'].value_counts()\/df[(df['education_level']=='Masters')].shape[0]*100","a11cf7cb":"df[(df['education_level']=='Phd') & (df['target']==1)]['target'].value_counts()\/df[(df['education_level']=='Phd')].shape[0]*100","5d778fca":"plt.figure(figsize=(8,8))\nsns.countplot(x='major_discipline', data=df, hue='target', palette='hls')\nplt.show()","8cbd8660":"df[(df['major_discipline']=='STEM') & (df['target']==1)]['target'].value_counts()\/df[(df['major_discipline']=='STEM')].shape[0]*100","005835e1":"df[(df['major_discipline']=='Business Degree') & (df['target']==1)]['target'].value_counts()\/df[(df['major_discipline']=='Business Degree')].shape[0]*100","1e4f464d":"df[(df['major_discipline']=='Arts') & (df['target']==1)]['target'].value_counts()\/df[(df['major_discipline']=='Arts')].shape[0]*100","8fd2cec7":"df[(df['major_discipline']=='Humanities') & (df['target']==1)]['target'].value_counts()\/df[(df['major_discipline']=='Humanities')].shape[0]*100","e82bc6b3":"df[(df['major_discipline']=='No Major') & (df['target']==1)]['target'].value_counts()\/df[(df['major_discipline']=='No Major')].shape[0]*100","4dbf0d38":"df[(df['major_discipline']=='Other') & (df['target']==1)]['target'].value_counts()\/df[(df['major_discipline']=='Other')].shape[0]*100","3703ab6f":"plt.figure(figsize=(8,8))\nsns.countplot(x='experience', data=df, palette='hls', hue='target', order=['<1', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15' , '16', '17', '18', '19', '20', '>20'])\nplt.show()","0c0dceed":"df[(df['experience']=='<1') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='<1')].shape[0]*100","5b824944":"df[(df['experience']=='1') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='1')].shape[0]*100","587d9215":"df[(df['experience']=='2') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='2')].shape[0]*100","069889ef":"df[(df['experience']=='3') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='3')].shape[0]*100","f0cd4243":"df[(df['experience']=='4') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='4')].shape[0]*100","052d0fa3":"df[(df['experience']=='5') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='5')].shape[0]*100","b0a6be25":"df[(df['experience']=='6') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='6')].shape[0]*100","021c63a1":"df[(df['experience']=='7') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='7')].shape[0]*100","3675b8c0":"df[(df['experience']=='8') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='8')].shape[0]*100","1cf1fc6c":"df[(df['experience']=='9') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='9')].shape[0]*100","94415d46":"df[(df['experience']=='10') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='10')].shape[0]*100","d1d07ccd":"df[(df['experience']=='11') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='11')].shape[0]*100","9fc2b8ea":"df[(df['experience']=='12') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='12')].shape[0]*100","8b0e9ff4":"df[(df['experience']=='13') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='13')].shape[0]*100","b1dc63e1":"df[(df['experience']=='14') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='14')].shape[0]*100","d07212bc":"df[(df['experience']=='15') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='15')].shape[0]*100","09a3448b":"df[(df['experience']=='16') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='16')].shape[0]*100","4a4166f8":"df[(df['experience']=='17') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='17')].shape[0]*100","c69f1435":"df[(df['experience']=='18') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='18')].shape[0]*100","638f7378":"df[(df['experience']=='19') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='19')].shape[0]*100","b4b152f0":"df[(df['experience']=='20') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='20')].shape[0]*100","c285a738":"df[(df['experience']=='>20') & (df['target']==1)]['target'].value_counts()\/df[(df['experience']=='>20')].shape[0]*100","3fe3a2e3":"plt.figure(figsize=(8,8))\nsns.countplot(x='company_size', data=df, palette='hls', hue='target', order=['<10', '10\/49', '50-99', '100-500', '500-999', '1000-4999', '5000-9999', '10000+'])\nplt.show()","74ecb84e":"df[(df['company_size']=='<10') & (df['target']==1)]['target'].value_counts()\/df[(df['company_size']=='<10')].shape[0]*100","cdb0fc2a":"df[(df['company_size']=='10\/49') & (df['target']==1)]['target'].value_counts()\/df[(df['company_size']=='10\/49')].shape[0]*100","72c07d6f":"df[(df['company_size']=='50-99') & (df['target']==1)]['target'].value_counts()\/df[(df['company_size']=='50-99')].shape[0]*100","5cbf70c0":"df[(df['company_size']=='100-500') & (df['target']==1)]['target'].value_counts()\/df[(df['company_size']=='100-500')].shape[0]*100","f01b2f0d":"df[(df['company_size']=='500-999') & (df['target']==1)]['target'].value_counts()\/df[(df['company_size']=='500-999')].shape[0]*100","8dbc81ea":"df[(df['company_size']=='1000-4999') & (df['target']==1)]['target'].value_counts()\/df[(df['company_size']=='1000-4999')].shape[0]*100","1bac5dbe":"df[(df['company_size']=='5000-9999') & (df['target']==1)]['target'].value_counts()\/df[(df['company_size']=='5000-9999')].shape[0]*100","1761fee9":"df[(df['company_size']=='10000+') & (df['target']==1)]['target'].value_counts()\/df[(df['company_size']=='10000+')].shape[0]*100","cea20dab":"plt.figure(figsize=(10,10))\nsns.countplot(x='company_type', data=df, hue='target', palette='hls', order=['Public Sector', 'Pvt Ltd', 'Early Stage Startup', 'Funded Startup', 'NGO', 'Other'])\nplt.show()","9d10b5d4":"df[(df['company_type']=='Public Sector') & (df['target']==1)]['target'].value_counts()\/df[(df['company_type']=='Public Sector')].shape[0]*100","492eb003":"df[(df['company_type']=='Pvt Ltd') & (df['target']==1)]['target'].value_counts()\/df[(df['company_type']=='Pvt Ltd')].shape[0]*100","86f568d8":"df[(df['company_type']=='Early Stage Startup') & (df['target']==1)]['target'].value_counts()\/df[(df['company_type']=='Early Stage Startup')].shape[0]*100","1b5fce72":"df[(df['company_type']=='Funded Startup') & (df['target']==1)]['target'].value_counts()\/df[(df['company_type']=='Funded Startup')].shape[0]*100","1f22528c":"df[(df['company_type']=='NGO') & (df['target']==1)]['target'].value_counts()\/df[(df['company_type']=='NGO')].shape[0]*100","2f85ef68":"df[(df['company_type']=='Other') & (df['target']==1)]['target'].value_counts()\/df[(df['company_type']=='Other')].shape[0]*100","f7f0af33":"plt.figure(figsize=(8,8))\nsns.countplot(x='last_new_job', data=df, palette='hls', hue='target', order=['never','1','2','3','4','>4'])\nplt.show()","15b35468":"df[(df['last_new_job']=='never') & (df['target']==1)]['target'].value_counts()\/df[(df['last_new_job']=='never')].shape[0]*100","343ea7fa":"df[(df['last_new_job']=='1') & (df['target']==1)]['target'].value_counts()\/df[(df['last_new_job']=='1')].shape[0]*100","d4a67162":"df[(df['last_new_job']=='2') & (df['target']==1)]['target'].value_counts()\/df[(df['last_new_job']=='2')].shape[0]*100","a88fa833":"df[(df['last_new_job']=='3') & (df['target']==1)]['target'].value_counts()\/df[(df['last_new_job']=='3')].shape[0]*100","187c1474":"df[(df['last_new_job']=='4') & (df['target']==1)]['target'].value_counts()\/df[(df['last_new_job']=='4')].shape[0]*100","c6af7322":"df[(df['last_new_job']=='>4') & (df['target']==1)]['target'].value_counts()\/df[(df['last_new_job']=='>4')].shape[0]*100","b8e8e928":"min_thresold=df['training_hours'].quantile(0.25)\nmax_thresold=df['training_hours'].quantile(0.75)\n\nIQR = max_thresold - min_thresold\nupperrange = max_thresold + 1.5*IQR\nlowerrange = min_thresold - 1.5*IQR\n\ndf = df[(df['training_hours']>lowerrange) & (df['training_hours']<upperrange)]\ndf.shape","955b212e":"kota = df['city'].str.split('_', n=1, expand=True)\ndf['city'] = kota[1]\ndf['city'] = df['city'].astype(str).astype(int)","40e0944f":"df.info()","c72a38d1":"# first we drop some columns which i think doesn't have any predictor value\n\ndf = df.drop(columns=['enrollee_id','enrolled_university'])","732145ea":"df.columns\n\n# This is the final column we will be using","75fa77d6":"ordinal_mapping=[\n    {'col': 'relevent_experience', \n    'mapping':{'No relevent experience':1, 'Has relevent experience':2}},\n    {'col':'education_level',\n    'mapping':{'Primary School':1, 'High School':2, 'Graduate':3, 'Masters':4, 'Phd':5}},\n    {'col': 'experience',\n    'mapping':{'<1':1, '1':2, '2':3, '3':4, '4':5, '5':6, '6':7, '7':8, '8':9, '9':10, '10':11, '11':12, '12':13, '13':14, '14':15, '15':16, '16':17, '17':18, '18':19, '19':20, '20':21, '>20':22}},\n    {'col':'company_size',\n    'mapping':{'<10':1, '10\/49':2, '50-99':3, '100-500':4, '500-999':5, '1000-4999':6, '5000-999':7}},\n    {'col': 'last_new_job',\n    'mapping':{'never':1, '1':2, '2':3, '3':4, '4':5, '>4':6}}\n]","8f2560a9":"binary_encoder_pipeline = Pipeline([\n                                    ('imputer',SimpleImputer(strategy = 'most_frequent')),\n                                    ('binary encoder',ce.BinaryEncoder())\n])\n\nordinal_encoder_pipeline = Pipeline([\n                                    ('imputer',SimpleImputer(strategy = 'most_frequent')),\n                                    ('ordinal encoder',ce.OrdinalEncoder())\n                                    ])\n\ntransformer = ColumnTransformer([\n    ('binary encoder', binary_encoder_pipeline, ['gender', 'major_discipline', 'company_type']),\n    ('ordinal encoder', ordinal_encoder_pipeline, ['relevent_experience', 'education_level', 'experience', 'company_size', 'last_new_job'])\n], remainder='passthrough')","5fafa1d0":"y = df.loc[:, ['target']]\nx = df.drop(columns=['target'])","0c5a4870":"x_train, x_test, y_train, y_test = train_test_split(\n    x,\n    y,\n    stratify=y,\n    random_state=10\n)","70a1c653":"def evaluate(df,model):\n\n    model_name=[]\n    precision_score=[]\n    precision_std=[]\n    for name, model in model:\n        model = model\n        estimator = Pipeline([\n            ('preprocess', transformer),\n            ('model', model)])\n\n        skfold=StratifiedKFold(n_splits=5)\n        score= cross_val_score(estimator,x_train,y_train,scoring='precision',cv=skfold).mean()\n        std= cross_val_score(estimator,x_train,y_train,scoring='precision',cv=skfold).std()\n        precision_score.append(score)\n        precision_std.append(std)\n        model_name.append(name)\n\n    return pd.DataFrame({'Name': model_name,'precision_score':precision_score, 'precision_std':precision_std})","cf017558":"models = [\n    ['Log Regression', LogisticRegression(solver='liblinear', random_state=2020)],\n    ['DecisionTree', DecisionTreeClassifier(criterion='entropy', max_depth=3)],\n    ['RandomForest', RandomForestClassifier()],\n    ['KNeighbours', KNeighborsClassifier(n_neighbors = 2)]]","5074f134":"evaluate(df,models)","2ded7a9e":"model=DecisionTreeClassifier(random_state=10)\n\nestimator = Pipeline([\n    ('preprocess', transformer),\n    ('model', model)])\n\nestimator.fit(x_train,y_train)\nprecision_score(y_test,estimator.predict(x_test))","90946396":"model= DecisionTreeClassifier(random_state=10)\nover=SMOTE()\nunder= NearMiss()\n\nhyperparam_space={'balancing':[over, under]}","b8b62d08":"estimator = Pipeline([\n    ('preprocess',transformer),\n    ('balancing',over),\n    ('clf',model)])\nskfold=StratifiedKFold(n_splits=5)\n\nDT_grid= GridSearchCV(estimator,\n    param_grid= hyperparam_space,\n    cv=skfold,\n    #n_jobs=-1,\n    scoring='precision')","7994cc6a":"DT_grid.fit(x_train,y_train)","fdc67a81":"DT_grid.best_estimator_.fit(x_train,y_train)\nprecision_score(y_test,DT_grid.best_estimator_.predict(x_test))","36187a81":"model=DecisionTreeClassifier(random_state=10)\n\nhyperparam_space={'model__criterion':['gini', 'entropy'],\n            'model__splitter':['best', 'random'],\n            'model__max_depth':[4,5,6,7,10],\n            'model__min_samples_split': [2,5,10,15,20,50],\n            'model__min_samples_leaf':[1,5,10,15,20,50]\n}","9d079fe6":"estimator = Pipeline([\n    ('preprocess',transformer),\n    ('model',DecisionTreeClassifier())])\nskfold=StratifiedKFold(n_splits=5)\n\ngrid= GridSearchCV(estimator,\n    param_grid= hyperparam_space,\n    cv=skfold,\n    #n_jobs=-1,\n    scoring='precision')","df20dd68":"grid.fit(x_train, y_train)","ea8956fb":"grid.best_estimator_","e5d3fc81":"DT_Model = grid.best_estimator_\nDT_Model.fit(x_train, y_train)","e57263a7":"y_pred = DT_Model.predict(x_test)\nprint(classification_report(y_test, y_pred))","a3a9ad1c":"# EDA Major Discipline","7149d234":"### Major discipline conclusion\n\nFrom the data, we can see that Other Major has a higher job seeker rate rather than the others, although the difference in job seeker rate between the other variables aren't that high\n","f5a1668d":"## Data Splitting","fdb03f12":"## 4.1 Benchmark Model\n\nTo choose what is the best model to be used for this dataset, we are going to conduct cross validation & compare the precision score.","1103cc54":"From 1238 Female gender dataset, 26.332% of Female are looking for a job change whereas 73.67% aren't looking for job change","6973769b":"# Outliers\n\nBefore we begin into preprocessing, outliers needed to be treated & the new df shall not contain any outlier. We will be using the norm conduct of 25%,75% quantile.","a47bb1fd":"# EDA Last New Job","0501d785":"### Experience conclusion\nFrom the data, we can we can see that participant who has 1-2 year experience has a higher job seeker rate rather than the others","97f110a3":"**Please be noted that i'm using GridSearch & not Randomized Search. This code may take a while but it's worthwhile because the machine will try to search fo the best possible result.**","2dd82deb":"### Last new job conclusion\nWe can see that participant who has never been in an unemployment has the highest job seeker rate","76fd4aca":"Our final model precision score is 0.60. This is much better than our benchmark model where it can only predict 41 out of 100 prediction correctly! In conclusion, our hyperparameter tuning works and this model can predict 60 out of 100 prediction correctly.","752f8b36":"## Pipeline (Encoding & Missing Value Treatment)","f7e0c6ee":"### Relevant experience conslusion\n\nWe can see that those who doesn't have any experience regarding Data Science has higher job seeker rate rather than those who does have experience","0c2d5155":"# EDA Final Conclusion\n\nWe can see that historically, the majority of participant is: 1) an experienced, 2) non student, 3) bachelor degree, 4) male 5) who comes from STEM major &, 6) have >20 year of working experience, 7) in a private company, 8) with 50-99 employee & 9) also has been in an unemployment for at least 1 year. But this data doesn't mean anythong. **For companies, it's very important to give bigger training quota for people who has higher job seeker rate in order to maximize the desired output & minimize the training cost**. And who are those people? Generally, they are: 1) unexperienced, 2) female 3) who are having a full time course in university while attending the data science bootcamp &, 4) has a bachelor degree, 5) from Other major. 6) They also have 1-2 year of working experience, 7) in Other type companies, 8) which has 10-49 employees & 9) has never been in an unemployment.","4cf6049c":"As we can see, city has become an int type. Next, we need to encode almost all of this dataset features & fill their missing values. In order to do that, we will be using pipeline to simplify things. \n\n**Ordinal ecoding will include features:**\n* Relevant experience\n* Education level\n* Experience\n* Company size\n* Last new job\n\n**Binary encoding will include features:**\n* Gender\n* Major discipline\n* Company type\n\n**Missing value will be treated by filling it with most frequent strategy**","d50fb0fc":"## Splitting & Changing Data Type\n\nAs we already know, there are only 2 numeric features in this dataset. However, there are still 1 feature that we can use as a numeric feature after conducting some changes. This feature is df['City']. City represent from which city does the participant comes from. Df['City'] is an object type dataframe, so we need to split it and change the dataframe into int","9bd2c7aa":"# 2. Data Recognition","78cf3f75":"## Ordinal Encoding Values","23dcdcfe":"### Enrolled university conclusion\nfrom the data, we can see that participant who are having a full time course in university while attending the data science bootcamp has a higher job seeker rate rather than those who are not enrolled in university or a part timer","be740c1c":"## Evaluation Metric\n\nBefore we begin, we need to understand what evaluation metric we will be using. To understand it better, let's break the evaluation metric down:\n![metrix%20eval.JPG](attachment:metrix%20eval.JPG)\n\nIn this particular dataset, **we want to minimize False Positive as low as possible.** This is because bootcamp is a cost & we want to minimize our risk of people who we expect to work, but in reality, they didn't want to work for us. The evaluation metric we can use is Precision Score. For more info about precision score: https:\/\/www.youtube.com\/watch?v=2osIZ-dSPGE","c6a50031":"# EDA Company Type","66a92b21":"* From the scatter plot, we can generally say that historically, many of the participant who are looking for a job change comes from a city with city development index below 0.7 & finish around 200-250 training hours.\n* This somehow make sense because it is harder to find job in a city less developed and thus, people tend to cherish every opportunity they get without having much thought on comparing one after another opportunity","397f7fba":"From the data, we can see that:\n* There are 19158 dataset but almost all of the features has missing value\n* The majority of data is categorical, whereas the only numerical features are city development index & training hours \n* Outliers can be seen from training hours features, where the max value area 336 hours","d13ecb2c":"As i wrote this code in VSCode, our **benchmark precision score is 0.41721854304635764**. **The output may be vary if you do not include the random state inside the model.**","44701ffa":"# EDA Company Size","4b4505e5":"### Company type conclusion\n\nFrom the data, we can see that participant who comes from Other type of company has higher job seeker rate rather that participant who comes from public sector, private sector, startup sector or even NGO","bc6a6f92":"## Selecting feature","163cd590":"### Company size conclusion\nFrom the data, we can we can see that participant who comes from a company which has 10-49 employees has a higher job seeker rate rather than the others","60aa8897":"# 1. Executive Summary\n\nThe objective of this project is to create an ML model that can be used to speculate wether someone who is participating in a data science bootcamp will leave their current job & pursue career as a data scientist in the bootcamp provider companies, or will they not. By understanding the feature, companies can provide an effective ways of conducting the bootcamp & segmenting the right target without having to spend much time & budget.  The data sources is taken from kaggle (https:\/\/www.kaggle.com\/arashnic\/hr-analytics-job-change-of-data-scientists).  In conclusion, this model can correcetly predict 60 out of 100 target (1) prediction based on precision score","cdc783be":"# EDA Participant","b69f74ed":"# Features\n\n*     enrollee_id : Unique ID for candidate\n\n*     city: City code\n\n*     city_ development _index : Developement index of the city (scaled). For more info: https:\/\/en.wikipedia.org\/wiki\/City_development_index\n\n*     gender: Gender of candidate\n\n*     relevent_experience: Relevant experience of candidate\n\n*     enrolled_university: Type of University course enrolled if any\n\n*     education_level: Education level of candidate\n\n*     major_discipline :Education major discipline of candidate\n\n*     experience: Candidate total experience in years\n\n*     company_size: No of employees in current employer's company\n\n*     company_type : Type of current employer\n\n*     lastnewjob: Difference in years between previous job and current job\n\n*     training_hours: training hours completed\n\n*     target: 0 \u2013 Not looking for job change, 1 \u2013 Looking for a job change","2592c2cb":"There are a total of 14650 non null gender dataset. We can also say that the gender dataset compose of 76.47% intact non null value dataset & 23.53% null value dataset","8372dc99":"### Gender conclusion\nFrom gender features, we can conclude that the precentage of Female participant who are looking for job change are higher than Male participant who are looking for job change. In other words, job seeker rate of Female is higher than Male. **Knowing which variabel has the highest job seeker rate is important for companies in order to efficiently allocate their training quota without having to spend money, time & effort too much**","078a6888":"Uh waw, this doesn't seemed realy good. So yeah, we will not treat the imbalance dataset & just let it flow","d7894cd3":"From 13221 Male gender dataset, 22.78% of Male who are looking for a job change whereas 77.21% aren't looking for job change","090bc40a":"From this table, we can conclude that Decision Tree is the best model to be used in this particular dataset. After we choose our model, we will be able to know our benchmark precision score by comparing the fitted x_train to x_test","ccd41847":"# Hyperparameter Tuning","d0975f03":"# EDA Education Level","0f753c24":"Lastly we will be tuning our Decision Tree parameter in order to get the best possible result. ","33f6923d":"# Thank you for reading! UPVOTE if you like :)","921d87c1":"# Workflow\n\n1. Executive summary\n2. Data recognition\n3. Exploratory descriptive analysis\n4. Model building\n5. Conclusion","821c01a3":"As you can see, i use most_frequent strategy to treat missing value. This is because almost all of the features are categorical & we can't use median or mean","33d0bcd8":"# EDA Experience","be7c3af0":"# 3. Exploratory Data Analysis","70210b72":"# 4. Model Building\nThis includes data preprocessing such as spliting & changing data type, encoding, selecting model up until hyperparameter tuning for final model","2e57dda5":"### Education level conclusion\nfrom the data, we can see that participant who has graduate university background (bachelor degree) has a higher job seeker rate rather than the others\n","cf1043ba":"We can see that our best parameters consist of: (max_depth=5, min_samples_leaf=50). Let's fit it into our benchmark model","e234fddc":"# EDA Relevant Experience","a7851aa2":"# Balancing\nYou might have noticed that our data is imbalance, with only 25% target (1) & 75% target (0). In this section, we will try to balance the data using undersampling & oversampling method, and see if it works by comparing the precision score with the benchmark precision score. To understand better what is SMOTE & NearMiss, you can check out this guy: https:\/\/www.youtube.com\/watch?v=JnlM4yLFNuo","756bdde8":"The histogram & boxplot shows us that there are outliers in the right side of the training hours dataset (right skewed outlier)","7c788ad6":"# EDA Enrolled University","55350b11":"# Training Hours Distribution"}}