{"cell_type":{"29aa812a":"code","79fbcfc8":"code","c29acae7":"code","b32b52dd":"code","03a1e0d7":"code","cf44c35d":"code","9481e688":"code","34b5cdbd":"code","1e186971":"code","9ea10fcb":"code","1dc0f536":"code","30c16f06":"code","39074325":"code","8fb0721e":"code","d2134dfd":"code","9ebf2894":"code","73f244ac":"code","dd0b08db":"code","f2d6c812":"code","07ab4cc2":"code","a157fe17":"code","5f1ce3f5":"code","2dfc59a9":"code","99218235":"code","ab361fe0":"code","39aa6b58":"code","56f13f52":"code","5a9c87de":"code","3d248d14":"code","10eaac72":"code","d56f6904":"code","7117676c":"code","70932469":"code","cdc0d292":"code","f26f5411":"code","f4271d36":"code","7aaaecaf":"code","df9148a4":"code","e6b37e66":"code","054ef276":"code","308a5095":"code","739941e3":"code","f72cada8":"code","e89304cb":"code","79db36ee":"code","9c5f58b8":"code","bde3fe33":"code","0577a6ac":"code","f114d453":"code","0e95f332":"code","93c64bce":"code","63f8154a":"code","78fd3740":"code","432588d0":"code","ae8e5ac1":"code","ef020959":"code","d3e752b0":"markdown","470ffca6":"markdown","ad91d8d1":"markdown","d5b8d409":"markdown","b4b2abce":"markdown","bb5a7347":"markdown","d92b7a38":"markdown","782eb661":"markdown","34f4b14a":"markdown","35929814":"markdown","9f37bacb":"markdown","424ac9a8":"markdown","9f74586b":"markdown","acff81c5":"markdown","24bddacf":"markdown"},"source":{"29aa812a":"import pandas as pd \nimport numpy as np \nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom pprint import pprint \nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV","79fbcfc8":"#Using iexcloud api to get the stock prices of AAPL. You can get this for free for any company. \ndf = pd.read_csv('..\/input\/stock-price-history\/AAPL2.csv') ","c29acae7":"df.tail(5)","b32b52dd":"df.date.dtype","03a1e0d7":"s = pd.to_datetime(df['date'])\ndf['date'] = s.dt.strftime(\"%m\")          #This returns 2020-10-2 as 202010 (YearMonth)","cf44c35d":"df.date = df.date.astype('int64')\ndf.date.dtype","9481e688":"df.tail(5)","34b5cdbd":"drop_columns = ['volume', 'uOpen', 'uClose', 'uHigh', 'uLow', \n                'uVolume', 'change', 'changePercent', 'label', 'changeOverTime', 'Unnamed: 0']\ndf.drop(drop_columns, axis = 1, inplace = True)\ndf.rename(columns = {'date':'YearMonth'})","1e186971":"display(df.info())\ndisplay(df.head())","9ea10fcb":"corr = abs(df.corr())\nsns.heatmap(corr)","1dc0f536":"df.date = (df.date-df.date.mean())\/df.date.std()        #Normalizing the YearMonth column","30c16f06":"Y = df.open                                          #Separating the taget variable from the features \ndf.drop('open', axis = 1, inplace = True)\nX = df","39074325":"#Plotting history of opening prices for AAPL\nplt.figure(figsize=(15,8))\nplt.plot(Y, color=\"black\")\nplt.title('Opening Price history')\nplt.ylabel('Opening Price')\nplt.xlabel('Days')\nplt.show()","8fb0721e":"xtrain, xtest, ytrain, ytest = train_test_split(X, Y, random_state = 14, test_size = .2)","d2134dfd":"models = [KNeighborsRegressor(), GradientBoostingRegressor(),\n          LinearRegression(), SVR(), DecisionTreeRegressor()]\nfor model in models:\n    kfold = KFold(n_splits=5, random_state= 14, shuffle=True)\n    result = cross_val_score(model, xtrain, ytrain, \n                             cv=kfold, scoring = 'r2')\n    print(\"For\", model, \"the r2 score is\",result)","9ebf2894":"lr = LinearRegression(normalize=True, copy_X=True)\nlr.fit(xtrain,ytrain)\npredict = lr.predict(X)","73f244ac":"lr.coef_","dd0b08db":"from sklearn import metrics\nprint('R^2:',metrics.r2_score(Y, predict))","f2d6c812":"fig, ax1 = plt.subplots(figsize=(13,6))\nax1.set_xlabel('Days')\nax1.set_ylabel('Actual Price')\nax1.plot(Y, color = 'black')\n\nax2 = ax1.twinx()\nax2.set_ylabel('Predicted Price', color ='red')\nax2.tick_params(axis='y', colors='red')\nax2.plot(predict, color = 'red')\nplt.show()","07ab4cc2":"gbr = GradientBoostingRegressor()\npprint(gbr.get_params())                    #Getting the hyperparameters which can be tuned for a better model","a157fe17":"random_grid = {'n_estimators': [25,50,100,150,200,300],\n               'max_depth': [3,5,10,15],\n               'min_samples_leaf': [2, 3, 4],\n               'learning_rate' : [.01,.03,.3,1],\n               'criterion' : ['friedman_mse','mse']}\npprint(random_grid)","5f1ce3f5":"gbr_random = RandomizedSearchCV(estimator = gbr, param_distributions = random_grid,\n                                n_iter = 100, cv = 5, random_state=14, verbose = 0)","2dfc59a9":"gbr_random.fit(xtrain, ytrain)","99218235":"gbr_random.best_params_                     #Best parameters found by the RandomSearchCV","ab361fe0":"grid_param = {'n_estimators': [150,200,100],\n               'max_depth': [10,15,17,20],\n               'min_samples_leaf': [3, 4,5],\n               'learning_rate' : [.1,0.1,0.3],\n               'criterion' : ['friedman_mse']}\npprint(grid_param)","39aa6b58":"grid_search =  GridSearchCV(estimator = gbr, param_grid = grid_param, \n                          cv = 3, verbose = 0)","56f13f52":"grid_search.fit(xtrain, ytrain)","5a9c87de":"grid_search.best_params_                     #These are the best parameters for the Gradient Boosting Regressor ","3d248d14":"best_params = grid_search.best_params_ ","10eaac72":"gbr_final = GradientBoostingRegressor(n_estimators=best_params['n_estimators'], \n                               criterion=best_params['criterion'], learning_rate = best_params['learning_rate'], \n                               max_depth=best_params['max_depth'], min_samples_leaf=best_params['min_samples_leaf'])","d56f6904":"gbr_final.fit(xtrain,ytrain)","7117676c":"predict = gbr_final.predict(X)","70932469":"from sklearn import metrics\nprint('R^2:',metrics.r2_score(Y, predict))","cdc0d292":"fig, ax1 = plt.subplots(figsize=(12,6))\nax1.set_xlabel('Days')\nax1.set_ylabel('Actual Prices')\nax1.plot(Y, color = 'black')\n\nax2 = ax1.twinx()\nax2.set_ylabel('Predicted Price', color ='red')\nax2.plot(predict, color = 'red')\nax2.tick_params(axis='y', colors='red')\nplt.show()","f26f5411":"import math\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.layers import *\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom keras.callbacks import EarlyStopping\nfrom keras.optimizers import Adam","f4271d36":"df = pd.read_csv('..\/input\/stock-price-history\/MSFT.csv')        #Stock prices from 2015-11-25 to 2020-11-23. 5 years. \ndf= df['Close']                     #Using Close prices for predictions        ","7aaaecaf":"plt.plot(df)\nplt.xlabel(\"TIME INTERVAL (DAYS)\")\nplt.ylabel(\"PRICE OF STOCK\")","df9148a4":"#Normalising the input values to feed into LSTM\nscaler=MinMaxScaler(feature_range=(0,1))\ndf=scaler.fit_transform(np.array(df).reshape(-1,1))","e6b37e66":"#df = np.array(df)\ntrain_size = int(len(df)*0.70)                        #Using 70 percent of dataset for training and rest for testing\ntest_size = (len(df)-train_size)\ntraining = df[:train_size, :]\ntest = df[train_size:len(df), :]","054ef276":"training.shape,test.shape","308a5095":"time_step = 50                                                #Using the last 50 days to predict price for the 51st day\nX_train, Y_train, X_test, Y_test = [],[],[],[]\n#Preprocessing \n#Preparing training and testing datasets compatible with LSTM\nfor i in range(len(training)-time_step):\n    x = training[i:(i+time_step), 0]        \n    X_train.append(x)\n    Y_train.append(training[i+time_step,0])\nfor i in range(len(test)-time_step):\n    x = test[i:(i+time_step), 0]\n    X_test.append(x)\n    Y_test.append(test[i+time_step,0])\nX_train = np.array(X_train);\nY_train = np.array(Y_train);\nX_test = np.array(X_test);\nY_test = np.array(Y_test);","739941e3":"X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\nX_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)","f72cada8":"X_train.shape, Y_train.shape","e89304cb":"model = Sequential()\n#Adding the first LSTM layer and some Dropout regularisation\nmodel.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\nmodel.add(Dropout(0.2))\n# Adding a second LSTM layer and some Dropout regularisation\nmodel.add(LSTM(units = 50, return_sequences = True))\nmodel.add(Dropout(0.2))\n# Adding a third LSTM layer\nmodel.add(LSTM(units = 50))\n# Adding the output layer\nmodel.add(Dense(units = 1))\n\nopt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n# Compiling the RNN\nmodel.compile(optimizer = opt,  loss = 'mean_squared_error')","79db36ee":"model.summary()","9c5f58b8":"model.fit(X_train, Y_train, epochs = 100, batch_size = 64)","bde3fe33":"import tensorflow as tf\ntf.__version__\n","0577a6ac":"testpred=model.predict(X_test)\ntestpred=scaler.inverse_transform(testpred)\ntrainpred = model.predict(X_train)\ntrainpred = scaler.inverse_transform(trainpred)","f114d453":"math.sqrt(mean_squared_error(Y_train,trainpred))\nmath.sqrt(mean_squared_error(Y_test,testpred))","0e95f332":"testPredictPlot = np.empty_like(df)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(Y_train)-2+(50*2)+1:len(df)-1, :] = testpred\ntrainPredictPlot = np.empty_like(df)\ntrainPredictPlot[:, :] = np.nan\ntestPredictPlot[50:len(Y_train)+50, :] = trainpred\nplt.plot(scaler.inverse_transform(df))\nplt.plot(testPredictPlot)\nplt.plot(trainPredictPlot)\nplt.show()","93c64bce":"f=test[(len(test)-50):,:].reshape(1,-1)\nprint(f.shape)\nX=list(f)\nX=X[0].tolist()","63f8154a":"output= []\nfor i in range(30):\n    if (len(X)>50):\n        f = np.array(X[-50:])\n        f = f.reshape(1,-1)\n        f = f.reshape((1, 50, 1))\n        yhat = model.predict(f) \n        print(f)\n        print(yhat)\n        X.extend(yhat[0].tolist())\n        output.extend(yhat.tolist())\n    else:\n        f = f.reshape((1,50,1))\n        yhat = model.predict(f) \n        print(f)\n        print(yhat)\n        X.extend(yhat[0].tolist())\n        output.extend(yhat.tolist())\nprint(output)","78fd3740":"new = np.arange(1,31)\nplt.plot(new,scaler.inverse_transform(output))\nplt.title(\"PREDICTED STOCK PRICES (30 DAYS)\", fontsize=8, fontweight='bold')\nplt.xlabel(\"TIME INTERVAL (DAYS)\")\nplt.ylabel(\"PRICE OF STOCK\")","432588d0":"len(df)","ae8e5ac1":"#Previous prices in Blue\n#Predicted prices in Orange\nold=np.arange(1,51)\nnew=np.arange(51,81)\nplt.plot(old, scaler.inverse_transform(df[1209:]))\nplt.plot(new, scaler.inverse_transform(output))\nplt.title(\"STOCK PRICES\", fontsize=8, fontweight='bold')\nplt.xlabel(\"TIME INTERVAL (DAYS)\")\nplt.ylabel(\"PRICE OF STOCK\")","ef020959":"#Appending the predicted prices to the original dataset\ndf_graph = df.tolist()\ndf_graph.extend(output)\nplt.plot(df_graph)\nplt.title(\"STOCK PRICES\", fontsize=8, fontweight='bold')\nplt.xlabel(\"TIME INTERVAL (DAYS)\")\nplt.ylabel(\"PRICE OF STOCK\")","d3e752b0":"## The correlation map doesn't really give any useful insights apart from what we expeceted from the basic understandings stocks and terms related to it.","470ffca6":"# Predicting for the next 30 days using the previous time step of 50","ad91d8d1":"### With small datasets and limited number of features GridSearchCV provides a very accurate model. ","d5b8d409":"# Stock price prediction. \n# Final project (StonksMaster) for \"10 Days of Code\" by NIT Durgapur\n# Plotting real-time stock data and predicting stock fluctuations using LSTM, Gradient Boosting and Linear Regression.\n\n### This was the first Machine Learning competition I took part in, where competitors had to build a stock price prediction model using standard algorithms, and I'm so happy to say that my journey from \"Top performer of the day\" to \"Best performer for Ten Days Of Code, 2020\" had been absolutely amazing. \n### From learning to about the workings of the stock market to brushing up the final presentation for the mentors, I learned a lot.\n### While this was quite a fun and insightful project, it is more important to throw light on why it is not a good idea to use these prediction models for practical purposes. This article by Lee Schmalz captures the essence of it impressively - https:\/\/towardsdatascience.com\/using-neural-networks-to-predict-stock-prices-dont-be-fooled-c43a4e26ae4e (Open in incognito mode if you do not have a membership.)","b4b2abce":"#### If this notebook helped you in learning, an upvote would be huge!\n#### Thank you :)","bb5a7347":"# Gradient Boosting Regressor ","d92b7a38":"### The datetime datatype cannot be passed into a linear regression model. This happens becuase Linear Regression cannot assign coefficient to the date feature as it doesn't comprehend the datetime64 datatype well. Therefore we need is to make the datetime object as numerical value and then feed that into the model. \n### So I would take months of the year, from intuition, as my feature which relates to the date column. ","782eb661":"# Using LSTM to predict stock prices","34f4b14a":"# Linear Regresssion ","35929814":"### The cell code below takes the last 50 days and uses it to predict 51st day. It then appends the 51st day prediction to the dataset and predicts the 52nd day using last 50 days from the 52nd day, this includes the predicted price of the 51st day. \n### This happens for as many days as you want to predict, here, 30. ","9f37bacb":"### Using RandomSearchCV to get range of optimum values of hyperparameters ","424ac9a8":"## The target value to be predicted is going to be the \u201cClose\u201d stock price value.","9f74586b":"### Here the datatype of \"date\" column is datetime64. ","acff81c5":"## Our model predicts prices pretty well based on the history of our chosen features. ","24bddacf":"## Here we have the dataset which contains the opening and closing prices of Apple's stocks for the a year before the current day, day wise. \n## \"high\" and \"low\" are the highest and the lowest prices for the stocks for that particular day. \n## \"volume\" represents the number of stocks that were bought that day. \n## \"change percentage\" is percentage change of the closing price with respect to the last day's closing price.  "}}