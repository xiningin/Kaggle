{"cell_type":{"d039e9d3":"code","2d5e229a":"code","d7dae0c3":"code","d5a70c95":"code","c5864e04":"code","d822b284":"code","a69661aa":"code","d4f9eb78":"code","17dc2f60":"markdown","8d30f7c6":"markdown","d64a8c05":"markdown","89ffad62":"markdown","cf41c3f2":"markdown","7d679c2b":"markdown","3cd88fc6":"markdown","589111d6":"markdown","f7311329":"markdown","ab67c9cd":"markdown"},"source":{"d039e9d3":"# import libraries\nimport os\nimport shutil\nimport numpy as np\nimport glob   \nimport keras.backend as K\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.models import Model, load_model\nfrom keras import optimizers\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nfrom keras.initializers import glorot_uniform\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nimport scipy.misc\nfrom keras.applications import ResNet50\nfrom keras.applications.resnet50 import preprocess_input\n\n# for reading images\nfrom matplotlib.pyplot import imshow\n%matplotlib inline\n\n# channels last is the format used by tensorflow \nK.set_image_data_format('channels_last')\nK.set_learning_phase(1)\n","2d5e229a":"# set to where the 'flowers' directory is located\ndata_dir = '\/kaggle\/input\/flowers-recognition\/flowers'\n\n# Training data dir\ntraining_dir = '.\/Train'\n\n# Test data dir\ntesting_dir = '.\/Test'\n\n# Ratio of training and testing data\ntrain_test_ratio = 0.8\n\n\ndef split_dataset_into_test_and_train_sets(all_data_dir = data_dir, training_data_dir = training_dir, testing_data_dir=testing_dir, train_test_ratio = 0.8):\n\n    # recreate test and train directories if they don't exist\n    if not os.path.exists(training_data_dir):\n        os.mkdir(training_data_dir)\n\n    if not os.path.exists(testing_data_dir):\n        os.mkdir(testing_data_dir)               \n    \n    num_training_files = 0\n    num_testing_files = 0\n\n    # iterate through the data directory \n    for subdir, dirs, files in os.walk(all_data_dir):\n        \n        category_name = os.path.basename(subdir)\n\n        if category_name == os.path.basename(all_data_dir):\n            continue\n\n        training_data_category_dir = training_data_dir + '\/' + category_name\n        testing_data_category_dir = testing_data_dir + '\/' + category_name\n        \n        # creating subdirectory for each sub category\n        if not os.path.exists(training_data_category_dir):\n            os.mkdir(training_data_category_dir)   \n\n        if not os.path.exists(testing_data_category_dir):\n            os.mkdir(testing_data_category_dir)\n            \n        file_list = glob.glob(subdir + '\/*.jpg')\n\n        print(str(category_name) + ' has ' + str(len(files)) + ' images') \n        random_set = np.random.permutation((file_list))\n        \n        # copy percentage of data from each category to train and test directory\n        train_list = random_set[:round(len(random_set)*(train_test_ratio))] \n        test_list = random_set[-round(len(random_set)*(1-train_test_ratio)):]\n        \n        for lists in train_list : \n            shutil.copy(lists, training_data_dir + '\/' + category_name + '\/' )\n            num_training_files += 1\n  \n        for lists in test_list : \n            shutil.copy(lists, testing_data_dir + '\/' + category_name + '\/' )\n            num_testing_files += 1\n  \n\n    print(\"Processed \" + str(num_training_files) + \" training files.\")\n    print(\"Processed \" + str(num_testing_files) + \" testing files.\")","d7dae0c3":"# split into train and test directories\nsplit_dataset_into_test_and_train_sets()","d5a70c95":"# number of classes \nnum_classes = 5\n\ndef get_model():\n    \n    # Get base model: ResNet50 \n    base_model = ResNet50(weights='imagenet', include_top=False)\n    \n    # freeze the layers in base model\n    for layer in base_model.layers:\n        layer.trainable = False\n        \n    # Get the output from the base model \n    base_model_ouput = base_model.output\n    \n    # Adding our own layers at the end\n    # global average pooling: computes the average of all values in the feature map\n    x = GlobalAveragePooling2D()(base_model_ouput)\n    \n    # fully connected and 5-softmax layer\n    x = Dense(512, activation='relu')(x)\n    x = Dense(num_classes, activation='softmax', name='fcnew')(x)\n    \n    model = Model(inputs=base_model.input, outputs=x)\n    return model","c5864e04":"# Get the model\nmodel = get_model()\n\n# compile it\nmodel.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n\n# summary of model\nmodel.summary()","d822b284":"# Using ImageDataGenerator for pre-processing\n\nimage_size = 224\nbatch_size = 64\n\n# help(ImageDataGenerator)\ntrain_data_gen = ImageDataGenerator(preprocessing_function = preprocess_input, \n                                    shear_range=0.2, zoom_range=0.2, \n                                    horizontal_flip=True)\n\n# do only basic preprocessing for validation data (no data augmentation)\nvalid_data_gen = ImageDataGenerator(preprocessing_function = preprocess_input)\n\n# create data generator objects\ntrain_generator = train_data_gen.flow_from_directory(training_dir, (image_size,image_size), batch_size=batch_size, class_mode='categorical')\nvalid_generator = valid_data_gen.flow_from_directory(testing_dir, (image_size,image_size), batch_size=batch_size, class_mode='categorical')","a69661aa":"# Training the newly added layers \nepochs = 10\n\n# flow data (in batches) from directories (while simultaneously preprocessing\/augmenting\nmodel.fit_generator(\n    train_generator,\n    steps_per_epoch=train_generator.n\/\/batch_size,\n    validation_data=valid_generator,\n    validation_steps=valid_generator.n\/\/batch_size,\n    epochs=epochs,\n    verbose=1)","d4f9eb78":"epochs = 10\n\n# training the model after 140 layers\nsplit_at = 140\nfor layer in model.layers[:split_at]: layer.trainable = False\nfor layer in model.layers[split_at:]: layer.trainable = True\n    \nmodel.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Choosing lower learning rate for fine-tuning\n# learning rate is generally 10-1000 times lower than normal learning rate when we are fine tuning the initial layers\nsgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n\nmodel.fit_generator(\n    train_generator,\n    steps_per_epoch=train_generator.n\/\/batch_size,\n    validation_data=valid_generator,\n    validation_steps=valid_generator.n\/\/batch_size,\n    epochs=epochs,\n    verbose=1)","17dc2f60":"### Training the Base Model (Using Batch-Wise Data Generation)\n\nLet's now train the model. When we use data generators, we use the `model.fit_generator` method rather than the usual `model.fit`.","8d30f7c6":"# Result \n\nWe found that Freezing the Initial-n Layers and Training the Rest performs better than Training the Base Model with keeping equal epoch, i.e. 10\n- Training accuracy with Training the Base Model is 92.30%\n- Testing accuracy with Training the Base Model is 92.97%\n- Training accuracy with Freezing the Initial-n Layers and Training the Rest performs is 99.17% \n- Testing accuracy with Freezing the Initial-n Layers and Training the Rest performs is 99.28% ","d64a8c05":"Note that the number of training and validation images is increased (because of data augmentation).","89ffad62":"### Importing the Pre-Trained Model \n\nLet's now import the pretrained ResNet model. In the first experiment, we will use the pretrained weights (from Imagenet) of ResNet. The argument `include_top = False` specifies that we do not want to import the top layers (the last ones, which are typically pooling, FC, softmax etc.). We'll add some of our own last layers (a global average poooling layer and a final softmax) and train just those.","cf41c3f2":"# Transfer Learning in Keras\n\nIn this notebook, we will implement transfer learning in Python using the pre-trained ResNet model. We will run two experiments - 1. **Freezing the base model weights**, adding a few layers to it at the end (fully connected etc.) and training the newly added layers, and 2. **Freezing the first 140 layers of ResNet** and retraining the rest.\n\nApart from this, you will learn **two important practical preprocessing techniques** in this notebook - **data augmentation** and **data generators**. The notebook is dividede into the following sections:\n1. Importing libraries\n2. Splitting into train and test set\n3. Importing the pretrained ResNet model\n4. Data Generators: Preprocessing and Generating Batch-Wise Data (On the Fly)\n5. Training the Base Model (Using Batch-Wise Data Generation)\n6. Freezing the initial-n layers and training the rest\n","7d679c2b":"Notice that the total number of parameters in the model is about 24 million, though the number of trainable parameters is only about 1 million.\n\nLet's now see how we'll feed the data to the model.","3cd88fc6":"### Importing Libraries","589111d6":"### Splitting Into Train and Test\n\nLet's now split the data into train and test directories. Firstly, note that the most common way to organize (images) data is to create two\/three directories - train and test (or validation) having n-subdirectories, each subdirectory being a class (here, five subdirs for the five flower types).\n\nThe following function creates two directories - train and test, each having five subdirectories (sunflower, dandelion, rose, tulip, daisy).","f7311329":"### Data Generators: Preprocessing and Generating Batch-Wise Data (On the Fly)\n\nWe will now implement an incredibly useful preprocessing technique - **data augmentation** using **data generators**.\n\nYou will learn preprocessing techniques in detail in the next industry session, though they're quire easy to understand anyway. Here's a quick overview.\n\n**Data Augmentation** is a commonly used technique in image processing used to 'create' more training data. It basically modifies the original training images a bit (e.g. rotates them by a few degrees, changes the colour shades a little, etc.) to 'create' (or augment) new training images. The basic reason to do this is to **increase the amount of variance** in the training data. It is possible to do this with images because if you rotate the image of (say) a dog (or change the colours a bit, stretch the image horizontally etc.), it stays a dog. Thus, you can create many images from each training image while the label stays the same.\n\nIn the code below, we have specified the augmentation techniques as `shear_range=0.2, zoom_range=0.2, horizontal_flip=True`. Shear 'stretches' the images, zoom_range zooms them in, and horizontal_flip 'flips' them around horizontally.\n\nNow, in the code below, you will notice that we have something called `ImageDataGenerator` - lets understand what it does.\n\n**Data generators** are used to **feed data points in batches** to the model. The main reason to use them is that they are efficient (compared to feeding one data point at a time, or all of them at once which will require a lot of memory). What's cooler about them is that they (at least in keras) can preprocess the images and create augmented ones *on the fly*, i.e. as the batches are fed to the model, the augmented images are created and preprocessed. This eliminates the need to store the augmented images separately.\n\nAn important point to note is that you **never augment the validation or test sets**, only the training set. This is because test (and validation) sets are supposed to be representative of the real images you'll get in the real world. However, you do apply basic preprocessing to validation and test sets (scaling\/centering them etc.).\n\nIn the code below, the method `flow_from_directory` 'flows' the data in batches from the training and test directories. It is an instance of `ImageDataGenerator` where we specify the preprocessing and augmentation techniques that we want to use. In this case, we are just using the standard preprocessing techniques that come with the `preprocess_input` module in keras.\n\nYou can <a href=\"https:\/\/keras.io\/preprocessing\/image\/\">read about data generators here<\/a>.","ab67c9cd":"### Freezing the Initial-n Layers and Training the Rest\n\nLet's now try another variant of transfer learning. We will freeze the first 140 layers of ResNet (with the hypopthesis that they have learnt to extract some useful generic features from their ImageNet experience) and train the rest of the layers."}}