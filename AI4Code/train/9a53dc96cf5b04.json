{"cell_type":{"9765bd59":"code","fb1f05b9":"code","aa2d629a":"code","b2efa264":"code","f989652c":"code","997e43ce":"code","0ca27d4c":"code","db3aa360":"code","78b18a20":"code","f52dff4a":"code","903c81eb":"code","37fe3912":"code","dfc60c4c":"code","f47413cb":"code","8aa02c9d":"markdown","c23c809b":"markdown"},"source":{"9765bd59":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","fb1f05b9":"import os\nimport sys\nimport random\nimport warnings\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom itertools import chain\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nimport tensorflow as tf\nfrom skimage.color import rgb2gray\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Add, UpSampling2D, Reshape\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Set some parameters\nIMG_WIDTH = 128\nIMG_HEIGHT = 128\nIMG_CHANNELS = 3\nTRAIN_PATH = '..\/input\/mydata-ns2\/stage1_train\/'\nTEST_PATH = '..\/input\/mydata-ns2\/stage1_test\/'\n\nwarnings.filterwarnings('ignore', category=UserWarning, module='skimage')\nseed = 42\nrandom.seed = seed\nnp.random.seed = seed","aa2d629a":"# Get train and test IDs\ntrain_ids = next(os.walk(TRAIN_PATH))[1]\ntest_ids = next(os.walk(TEST_PATH))[1]","b2efa264":"# Get and resize train images and masks\nX_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nY_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\nprint('Getting and resizing train images and masks ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n    path = TRAIN_PATH + id_\n    img = imread(path + '\/images\/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_train[n] = img\n    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n    for mask_file in next(os.walk(path + '\/masks\/'))[2]:\n        mask_ = imread(path + '\/masks\/' + mask_file)\n        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n                                      preserve_range=True), axis=-1)\n        mask = np.maximum(mask, mask_)\n    Y_train[n] = mask\n\n# Get and resize test images\nX_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nsizes_test = []\nprint('Getting and resizing test images ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n    path = TEST_PATH + id_\n    img = imread(path + '\/images\/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n    sizes_test.append([img.shape[0], img.shape[1]])\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_test[n] = img\n\nprint('Done!')","f989652c":"X_train = X_train \/ 255\nY_train = np.array(Y_train, dtype='float32')","997e43ce":"# Check if training data looks all right\nix = random.randint(0, len(train_ids))\nimshow(X_train[ix])\nplt.show()\nimshow(np.squeeze(Y_train[ix]))\nplt.show()\n","0ca27d4c":"# From: https:\/\/github.com\/jocicmarko\/ultrasound-nerve-segmentation\/blob\/master\/train.py\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + 1) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef iou(y_true, y_pred, smooth = 100):\n    intersection = K.sum(K.abs(y_true * y_pred))\n    sum_ = K.sum(K.square(y_true)) + K.sum(K.square(y_pred))\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return jac","db3aa360":"from tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.layers import *\n\ndef res_block(inputs,filter_size):\n    \"\"\"\n    res_block -- Residual block for building res path\n    \n    Arguments:\n    inputs {<class 'tensorflow.python.framework.ops.Tensor'>} -- input for residual block\n    filter_size {int} -- convolutional filter size \n    \n    Returns:\n    add {<class 'tensorflow.python.framework.ops.Tensor'>} -- addition of two convolutional filter output  \n    \"\"\"\n    # First Conv2D layer\n    cb1 = Conv2D(filter_size,(3,3),padding = 'same',activation=\"relu\")(inputs)\n    # Second Conv2D layer parallel to the first one\n    cb2 = Conv2D(filter_size,(1,1),padding = 'same',activation=\"relu\")(inputs)\n    # Addition of cb1 and cb2\n    add = Add()([cb1,cb2])\n    \n    return add\n\ndef res_path(inputs,filter_size,path_number):\n    \"\"\"\n    res_path -- residual path \/ modified skip connection\n    \n    Arguments:\n    inputs {<class 'tensorflow.python.framework.ops.Tensor'>} -- input for res path\n    filter_size {int} -- convolutional filter size \n    path_number {int} -- path identifier \n    \n    Returns:\n    skip_connection {<class 'tensorflow.python.framework.ops.Tensor'>} -- final res path\n    \"\"\"\n    # Minimum one residual block for every res path\n    skip_connection = res_block(inputs, filter_size)\n    \n    # Two serial residual blocks for res path 2\n    if path_number == 2:\n        skip_connection = res_block(skip_connection,filter_size)\n    \n    # Three serial residual blocks for res path 1\n    elif path_number == 1:\n        skip_connection = res_block(skip_connection,filter_size)\n        skip_connection = res_block(skip_connection,filter_size)\n    \n    return skip_connection\n\ndef decoder_block(inputs, mid_channels, out_channels):\n    \n    \"\"\"\n    decoder_block -- decoder block formation\n    \n    Arguments:\n    inputs {<class 'tensorflow.python.framework.ops.Tensor'>} -- input for decoder block\n    mid_channels {int} -- no. of mid channels \n    out_channels {int} -- no. of out channels\n    \n    Returns:\n    db {<class 'tensorflow.python.framework.ops.Tensor'>} -- returning the decoder block\n    \"\"\"\n    conv_kwargs = dict(\n        activation='relu',\n        padding='same',\n        kernel_initializer='he_normal',\n        data_format='channels_last'  \n    )\n    \n    # Upsampling (nearest neighbor interpolation) layer\n    db = UpSampling2D(size=(2, 2))(inputs)\n    # First conv2D layer \n    db = Conv2D(mid_channels, 3, **conv_kwargs)(db)\n    # Second conv2D layer\n    db = Conv2D(out_channels, 3, **conv_kwargs)(db)\n\n    return db\n\ndef TransResUNet(input_size=(512, 512, 1)):\n    \"\"\"\n    TransResUNet -- main architecture of TransResUNet\n    \n    Arguments:\n    input_size {tuple} -- size of input image\n    \n    Returns:\n    model {<class 'tensorflow.python.keras.engine.training.Model'>} -- final model\n    \"\"\"\n    \n    # Input \n    inputs = Input(input_size)\n    inp = inputs\n    input_shape = input_size\n    \n    # Handling input channels \n    # input with 1 channel will be converted to 3 channels to be compatible with VGG16 pretrained encoder \n    if input_size[-1] < 3:\n        inp = Conv2D(3, 1)(inputs)                         \n        input_shape = (input_size[0], input_size[0], 3)  \n    else:\n        inp = inputs\n        input_shape = input_size\n\n    # VGG16 with imagenet weights\n    encoder = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n       \n    # First encoder block\n    enc1 = encoder.get_layer(name='block1_conv1')(inp)\n    enc1 = encoder.get_layer(name='block1_conv2')(enc1)\n    # Second encoder block\n    enc2 = MaxPooling2D(pool_size=(2, 2))(enc1)\n    enc2 = encoder.get_layer(name='block2_conv1')(enc2)\n    enc2 = encoder.get_layer(name='block2_conv2')(enc2)\n    # Third encoder block\n    enc3 = MaxPooling2D(pool_size=(2, 2))(enc2)\n    enc3 = encoder.get_layer(name='block3_conv1')(enc3)\n    enc3 = encoder.get_layer(name='block3_conv2')(enc3)\n    enc3 = encoder.get_layer(name='block3_conv3')(enc3)\n\n    # Center block\n    center = MaxPooling2D(pool_size=(2, 2))(enc3)\n    center = decoder_block(center, 512, 256)\n\n    # Decoder block corresponding to third encoder\n    res_path3 = res_path(enc3,128,3)\n    dec3 = concatenate([res_path3, center], axis=3)\n    dec3 = decoder_block(dec3, 256, 64)\n    # Decoder block corresponding to second encoder\n    res_path2 = res_path(enc2,64,2)\n    dec2 = concatenate([res_path2, dec3], axis=3)\n    dec2 = decoder_block(dec2, 128, 64)\n    # Final Block concatenation with first encoded feature \n    res_path1 = res_path(enc1,32,1)\n    dec1 = concatenate([res_path1, dec2], axis=3)\n    dec1 = Conv2D(32, 3, padding='same', kernel_initializer='he_normal')(dec1)\n    dec1 = ReLU()(dec1)\n   \n\n    # Output\n    out = Conv2D(1, 1)(dec1)\n    out = Activation('sigmoid')(out)  \n    \n    # Final model\n    model = Model(inputs=[inputs], outputs=[out])\n    \n    return model","78b18a20":"from sklearn.model_selection import KFold\nkf = KFold(n_splits = 5, shuffle=False)\n\nBATCH_SIZE = 16\nEPOCHS = 100","f52dff4a":"histories = []\nlosses = []\naccuracies = []\ndicecoefs = []\nious = []\n\nfor k, (train_index, test_index) in enumerate(kf.split(X_train, Y_train)):\n    print('\\nFold : ', k+1)\n    x_train = X_train[train_index]\n    y_train = Y_train[train_index]\n    x_test = X_train[test_index]\n    y_test = Y_train[test_index]\n\n    model = TransResUNet(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n    \n    model.compile(optimizer=Adam(lr = 1e-5), loss=dice_coef_loss, metrics=[iou, dice_coef, 'binary_accuracy'])\n    model_checkpoint = ModelCheckpoint(str(k+1) + '_unet_nuclei_seg.hdf5',\n                                       verbose=1, \n                                       save_best_only=True)\n\n    history = model.fit(x_train, y_train,\n                        epochs=EPOCHS, \n                        callbacks=[model_checkpoint],\n                        validation_data = (x_test, y_test),\n                        batch_size=BATCH_SIZE)\n    \n    model = load_model(str(k+1) + '_unet_nuclei_seg.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})\n    \n    results = model.evaluate(x_test, y_test)\n    results = dict(zip(model.metrics_names,results))\n    \n    histories.append(history)\n    accuracies.append(results['binary_accuracy'])\n    losses.append(results['loss'])\n    dicecoefs.append(results['dice_coef'])\n    ious.append(results['iou'])","903c81eb":"print('accuracies : ', accuracies)\nprint('losses : ', losses)\nprint('dicecoefs : ', dicecoefs)\nprint('ious : ', ious)\n\nprint('-----------------------------------------------------------------------------')\nprint('-----------------------------------------------------------------------------')\n\nprint('average accuracy : ', np.mean(np.array(accuracies)))\nprint('average loss : ', np.mean(np.array(losses)))\nprint('average dicecoefs : ', np.mean(np.array(dicecoefs)))\nprint('average ious : ', np.mean(np.array(ious)))\nprint()\n\nprint('standard deviation of accuracy : ', np.std(np.array(accuracies)))\nprint('standard deviation of loss : ', np.std(np.array(losses)))\nprint('standard deviation of dicecoefs : ', np.std(np.array(dicecoefs)))\nprint('standard deviation of ious : ', np.std(np.array(ious)))","37fe3912":"import pickle\n\nfor h, history in enumerate(histories):\n\n    keys = history.history.keys()\n    fig, axs = plt.subplots(1, len(keys)\/\/2, figsize = (25, 5))\n    fig.suptitle('No. ' + str(h+1) + ' Fold Results', fontsize=30)\n\n    for k, key in enumerate(list(keys)[:len(keys)\/\/2]):\n        training = history.history[key]\n        validation = history.history['val_' + key]\n\n        epoch_count = range(1, len(training) + 1)\n\n        axs[k].plot(epoch_count, training, 'r--')\n        axs[k].plot(epoch_count, validation, 'b-')\n        axs[k].legend(['Training ' + key, 'Validation ' + key])\n        \n    with open(str(h+1) + '_mri_trainHistoryDict', 'wb') as file_pi:\n        pickle.dump(history.history, file_pi)","dfc60c4c":"selector = np.argmin(abs(np.array(ious) - np.mean(ious)))\nmodel = load_model(str(selector+1) +'_unet_nuclei_seg.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})","f47413cb":"for i in range(20):\n    index=np.random.randint(1,len(X_train))\n    pred=model.predict(X_train_process[index][np.newaxis, :, :, :])\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(X_train[index])\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(Y_train[index]))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Predicted mask')\n    plt.show()","8aa02c9d":"# Get the data\nLet's first import all the images and associated masks. I downsample both the training and test images to keep things light and manageable, but we need to keep a record of the original sizes of the test images to upsample our predicted masks and create correct run-length encodings later on. There are definitely better ways to handle this, but it works fine for now!","c23c809b":"Let's see if things look all right by drawing some random images and their associated masks."}}