{"cell_type":{"d7d55c4b":"code","5915aeff":"code","eb3dd732":"code","ec630efc":"code","a091940f":"code","db8a4ec2":"code","28d25dbf":"code","59143261":"code","f4adb1fc":"code","5f891bf8":"code","3e201c71":"markdown","2a88325c":"markdown","23d48428":"markdown","fafb2b3a":"markdown","801447e1":"markdown","78f8e831":"markdown","de9961c8":"markdown","b7b81628":"markdown","8ba2f813":"markdown","9db07bb6":"markdown","8d9db204":"markdown"},"source":{"d7d55c4b":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nfrom bs4 import BeautifulSoup\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.metrics import classification_report","5915aeff":"df = pd.read_csv('\/kaggle\/input\/stack-overflow-data.csv')\ndf = df[pd.notnull(df['tags'])]","eb3dd732":"def clean_text(text):\n    \"\"\"\n        text: a string\n        return: modified initial string\n    \"\"\"\n    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n    text = text.lower() # lowercase text\n    return text\n\ndf['post'] = df['post'].apply(clean_text)","ec630efc":"df.head()","a091940f":"X_train, X_test, y_train, y_test = train_test_split(df['post'], df['tags'], random_state=1087, test_size=0.2)","db8a4ec2":"nb = Pipeline([\n                ('vect', CountVectorizer()),\n                ('tfidf', TfidfTransformer()),\n                ('clf', MultinomialNB()),\n              ])\n\nnb.fit(X_train, y_train)\n\ny_pred = nb.predict(X_test)\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test))\nprint(classification_report(y_test, y_pred))","28d25dbf":"svm = Pipeline([\n                ('vect', CountVectorizer()),\n                ('tfidf', TfidfTransformer()),\n                ('clf', LinearSVC()),\n              ])\n\nsvm.fit(X_train, y_train)\n\ny_pred = svm.predict(X_test)\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test))\nprint(classification_report(y_test, y_pred))","59143261":"svm_sgd = Pipeline([\n                ('vect', CountVectorizer()),\n                ('tfidf', TfidfTransformer()),\n                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, max_iter=10, random_state=42))\n              ])\n\nsvm_sgd.fit(X_train, y_train)\n\ny_pred = svm_sgd.predict(X_test)\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test))\nprint(classification_report(y_test, y_pred))","f4adb1fc":"lgclf = Pipeline([\n                ('vect', CountVectorizer()),\n                ('tfidf', TfidfTransformer()),\n                ('clf', LogisticRegression(random_state=0)),\n              ])\n\nlgclf.fit(X_train, y_train)\n\ny_pred = lgclf.predict(X_test)\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test))\nprint(classification_report(y_test, y_pred))","5f891bf8":"rfc = Pipeline([\n                ('vect', CountVectorizer()),\n                ('tfidf', TfidfTransformer()),\n                ('clf', RandomForestClassifier(n_estimators=200, max_depth=5, random_state=0)),\n              ])\n\nrfc.fit(X_train, y_train)\n\ny_pred = rfc.predict(X_test)\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test))\nprint(classification_report(y_test, y_pred))","3e201c71":"#### Train-Test Split","2a88325c":"#### Reading Data","23d48428":"## Classification Models\n\n\n### 1) Naive Bayes Classifier: ","fafb2b3a":"### 3) Linear SVM with SGD:","801447e1":"### 4) Logistic Classifier:","78f8e831":"### 5) RandomForest Classifier:","de9961c8":"#### Pre-processing","b7b81628":"### 2) Linear SVM Classifier:","8ba2f813":"# Text Classification Models\n\nThe intention of this notebook is to look the below five models commonly used for text classification:\n* Naive Bayes Classifier\n* Linear Support Vector Machines\n* Linear SVM with SGD\n* Logistic Classifier\n* RandomForest Classifier\n\nThe dataset involves StackOverflow posts and the tags. The goal will be to predict the tags based on the contents of the posts.\n\n","9db07bb6":"Report:\n\n                     Model      Accuracy\n    1) Naive Bayes Classifier   74.6%\n    2) Linear SVM               81.1%\n    3) Linear SVM with SGD      79.1%\n    4) Logistic Classifier      81.0%\n    5) RandomForest Classifier  74.1%\n\nThis completes this kernel.","8d9db204":"#### Importing Relevant Libraries"}}