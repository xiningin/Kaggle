{"cell_type":{"350f7537":"code","6160f544":"code","194e439c":"code","b1e55b79":"code","267a8c40":"code","e3b3569c":"code","286ea7d6":"code","2ae96ff5":"code","f8c423b3":"code","c762dddd":"code","ef54db66":"code","94731edb":"code","d1a6af3b":"code","3b90c28e":"code","6898bd00":"code","28a412da":"code","d517372a":"code","34cb7e94":"code","cf06f12e":"code","20620fee":"code","0ecfa6d9":"code","de3b54a1":"code","a7b927ca":"code","51d0e6b4":"code","46d40be8":"code","d3838af5":"markdown"},"source":{"350f7537":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6160f544":"import torch\nimport torchvision.datasets as data\nimport torchvision.transforms as transforms\nimport random","194e439c":"import numpy as np\nimport torch\nimport torch.optim as optim\nimport pandas as pd\n\nxy=pd.read_csv('\/kaggle\/input\/city-commercialchange-analysis\/train.csv')\nxy","b1e55b79":"corr=xy.corr(method='pearson')\ncorr","267a8c40":"x_data=xy.iloc[:,0:7]    #0~7 col\ny_data=xy.iloc[:,7]\n\nx_data","e3b3569c":"y_data","286ea7d6":"x_train=np.array(x_data)\ny_train=np.array(y_data)\n\nx_train=torch.FloatTensor(x_train)\ny_train=torch.LongTensor(y_train)\n\nx_train[:5]","2ae96ff5":"x_train.shape","f8c423b3":"y_train.shape","c762dddd":"y_train","ef54db66":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nrandom.seed(777)\ntorch.manual_seed(777)\nif device == 'cuda':\n  torch.cuda.manual_seed_all(777)","94731edb":"# \ud559\uc2b5 \ud30c\ub77c\ubbf8\ud130 \uc124\uc815\nlearning_rate = 0.01\ntraining_epochs = 55\nbatch_size = 100\n\nfrom sklearn import preprocessing\nScaler = preprocessing.StandardScaler()  ","d1a6af3b":"x_train","3b90c28e":"x_train_scaler=Scaler.fit_transform(x_train)\nx_train_scaler","6898bd00":"x_train_scaler=torch.FloatTensor(x_train_scaler)","28a412da":"\ntrain = torch.utils.data.TensorDataset(x_train_scaler, y_train)","d517372a":"data_loader = torch.utils.data.DataLoader(dataset=train,\n                                          batch_size=batch_size,\n                                          shuffle=True,\n                                          drop_last=True)\n#xy=train","34cb7e94":"# 3-Layer\n\nlinear1 = torch.nn.Linear(7,256,bias=True)\nlinear2 = torch.nn.Linear(256,256,bias=True)\nlinear3 = torch.nn.Linear(256,4,bias=True)\nrelu = torch.nn.ReLU()","cf06f12e":"# Random Init => Xavier Init\ntorch.nn.init.xavier_normal_(linear1.weight)\ntorch.nn.init.xavier_normal_(linear2.weight)\ntorch.nn.init.xavier_normal_(linear3.weight)","20620fee":"model = torch.nn.Sequential(linear1,relu,linear2,relu,linear3).to(device)","0ecfa6d9":"# \uc190\uc2e4\ud568\uc218\uc640 \ucd5c\uc801\ud654 \ud568\uc218\nloss = torch.nn.CrossEntropyLoss().to(device) # softmax \ub0b4\ubd80\uc801\uc73c\ub85c \uacc4\uc0b0\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) ","de3b54a1":"\ntotal_batch = len(data_loader)\nfor epoch in range(training_epochs):\n    avg_cost = 0\n\n    for X, Y in data_loader:\n\n        # one-hot encoding\ub418\uc5b4 \uc788\uc9c0 \uc54a\uc74c\n        Y = Y.to(device)\n        #%debug\n\n        # \uadf8\ub798\ub514\uc5b8\ud2b8 \ucd08\uae30\ud654\n        optimizer.zero_grad()\n        # Forward \uacc4\uc0b0\n        hypothesis = model(X)\n        # Error \uacc4\uc0b0\n        cost = loss(hypothesis, Y)\n        # Backparopagation\n        cost.backward()\n        # \uac00\uc911\uce58 \uac31\uc2e0\n        optimizer.step()\n\n        # \ud3c9\uade0 Error \uacc4\uc0b0\n        avg_cost += cost \/ total_batch\n\n    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n\nprint('Learning finished')","a7b927ca":"test=pd.read_csv('\/kaggle\/input\/city-commercialchange-analysis\/test.csv')\n\nwith torch.no_grad():\n  x_test=test.loc[:,:]\n  x_test=np.array(x_test)\n  x_test_scaler=Scaler.transform(x_test)\n  x_test_scaler=torch.from_numpy(x_test_scaler).float().to(device)\n\n  prediction=model(x_test_scaler)\n  prediction = torch.argmax(prediction, 1)\n\nprediction","51d0e6b4":"submit = pd.read_csv('\/kaggle\/input\/city-commercialchange-analysis\/submit.csv')\nsubmit","46d40be8":"id=np.array([i for i in range(62)]).reshape(-1,1)\nprediction=prediction.reshape(-1,1)\n\nresult=np.hstack([id, prediction])\ndf=pd.DataFrame(result, columns=['ID','Label'])\ndf.to_csv('defense_submit.csv', index=False, header=True)\n\nresult","d3838af5":"### baseline \ucf54\ub4dc\n- 3layer \n- xavier init\n- Adam\n- training_epochs = 55\n- hidden layer node \uac1c\uc218: 256\n\n-> Accuracy: 0.725806474685669\n\n\n## \uc704\uc758 \ubca0\uc774\uc2a4\ub77c\uc778 \ucf54\ub4dc\uc5d0 scaler\ub97c \uc0ac\uc6a9\ud574\uc11c \uc815\ud655\ub3c4\ub97c \ub192\uc600\uc2b5\ub2c8\ub2e4."}}