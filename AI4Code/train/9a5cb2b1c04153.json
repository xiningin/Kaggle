{"cell_type":{"06af016c":"code","ee568899":"code","eaaefa47":"code","82f3a056":"code","5e60ac82":"code","4fab62bc":"code","30be291e":"code","ca00a2b4":"code","eb5d8ff0":"code","7b8e2557":"code","ca89e47e":"code","1e7738d8":"code","fe9f43dc":"code","57b5cab4":"code","1e28266d":"code","60121e69":"code","9c41feca":"code","7595d87e":"code","47c031da":"code","56e274dd":"code","15470d9c":"code","59446b15":"code","c3035c47":"code","e39b12e8":"code","4009ee2c":"code","f8ec054b":"code","64f6f6c3":"code","aa865f8e":"code","1a1ed2d2":"code","c4c2eac9":"code","9968dbaa":"code","dad4374e":"code","2b8cc5fa":"code","85c3aa6d":"code","ffbc6cfe":"code","2cd42272":"code","02a60213":"code","46775601":"code","b9c25238":"code","d99b3faf":"code","442c4955":"markdown","7733606c":"markdown","5594646b":"markdown","ee1f24ee":"markdown","48d60b0b":"markdown","7fe243c6":"markdown","b11d59c6":"markdown","fe6e8878":"markdown","c45e2315":"markdown","18a7876a":"markdown","62a151a7":"markdown","6ff31339":"markdown","6ff63488":"markdown","6bd964f4":"markdown","366244a1":"markdown","b56df08b":"markdown","3a0329ab":"markdown","3834362f":"markdown","4c753015":"markdown","426b5eb3":"markdown"},"source":{"06af016c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ee568899":"df=pd.read_csv(\"\/kaggle\/input\/adult-census-income\/adult.csv\")\ndf.head()","eaaefa47":"df[df=='?']=np.nan","82f3a056":"df.head()","5e60ac82":"df.isnull().sum()","4fab62bc":"null_columns =['workclass','occupation','native.country']\nfor i in null_columns:\n    df.fillna(df[i].mode()[0], inplace=True)","30be291e":"df.head()","ca00a2b4":"corr=df.corr()","eb5d8ff0":"plt.figure(figsize=(10,10))\nsns.heatmap(corr,annot=True)","7b8e2557":"sns.countplot(y=df['workclass'], hue=df['income'])","ca89e47e":"sns.countplot(df['sex'], hue=df['income'])","1e7738d8":"sns.countplot(x=df['race'], hue=df['income'])","fe9f43dc":"fig = plt.figure(figsize=(15,5))\nsns.countplot(y=df['education'], hue=df['sex'], order = df['education'].value_counts().index)","57b5cab4":"sns.countplot(y=df['relationship'], hue=df['income'], order = df['relationship'].value_counts().index)","1e28266d":"sns.countplot(y=df['marital.status'], hue=df['income'], order = df['marital.status'].value_counts().index)","60121e69":"fig = plt.figure(figsize=(15,5))\nsns.countplot(y=df['education'], hue=df['income'], order = df['education'].value_counts().index)","9c41feca":"sns.pairplot(df)","7595d87e":"df.head()","47c031da":"df[\"workclass\"].unique()","56e274dd":"df[\"education\"].unique()","15470d9c":"df[\"marital.status\"].unique()","59446b15":"df[\"occupation\"].unique()","c3035c47":"df[\"relationship\"].unique()","e39b12e8":"df[\"race\"].unique()","4009ee2c":"df[\"sex\"].unique()","f8ec054b":"df[\"native.country\"].unique()","64f6f6c3":"native=df[\"native.country\"].value_counts().to_dict()","aa865f8e":"df[\"native.country\"]=df[\"native.country\"].map(native)","1a1ed2d2":"df.head()","c4c2eac9":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()","9968dbaa":"df_cols=(\"workclass\",\"education\",\"marital.status\",\"occupation\",\"relationship\",\"race\",\"sex\")\nfor i in df_cols:\n    df[i]=le.fit_transform(df[i])","dad4374e":"df.head()","2b8cc5fa":"X=df.iloc[:,:-1].values\ny=df.iloc[:,-1].values","85c3aa6d":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)","ffbc6cfe":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train)","2cd42272":"y_pred = classifier.predict(X_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","02a60213":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","46775601":"from sklearn.ensemble import RandomForestClassifier\nclassifier_2 = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\nclassifier_2.fit(X_train, y_train)","b9c25238":"y_pred_2 = classifier_2.predict(X_test)\nprint(np.concatenate((y_pred_2.reshape(len(y_pred_2),1), y_test.reshape(len(y_test),1)),1))","d99b3faf":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred_2)\nprint(cm)\naccuracy_score(y_test, y_pred_2)","442c4955":"**PREDICTING THE VALUES**","7733606c":"**TRAINING THE DATASET ON RANDOM FOREST CLASSIFIER**","5594646b":"**SPLITTING DATASET INTO DEPENDENT AND INDEPENDENT**","ee1f24ee":"**IMPORT DATASET**","48d60b0b":"**DATA VISUALISATION**","7fe243c6":"As we have many unique values of native.country column so we will store its count in a dictonary and then map it on the dataset","b11d59c6":"**ENCODING CATEGORICAL VALUES**","fe6e8878":"**PREDICTING THE RESULT**","c45e2315":"As we see from above that we have \"?\" in the dataset. So we need to replace this. So we replaced it with nan.","18a7876a":"We see that most of the people working are having salary less than 50k.","62a151a7":"**MAKING THE CONFUSION MATRIX AND CHECKING THE ACCURACY**","6ff31339":"**SPLITTING DATASET INTO TRAINING AND TEST SET**","6ff63488":"**CHECKING UNIQUE VALUES**\n\nIf we have many unique values then we will try some other encoding technique otherwise we will use label encoder","6bd964f4":"As we got a moderate accuracy so will try any other model to see if accuracy can increase","366244a1":"From here we see that most of the people having salary less than 50k is from the private sector.","b56df08b":"**TRAINING THE DATASET ON LOGISTIC REGRESSION MODEL**","3a0329ab":"**Now filling the missing values with the mode of the respective columns**","3834362f":"**WE GOT AN ACCURACY HIGHER THAN LOGISTIC REGRESSION.**","4c753015":"**MAKING CONFUSION MATRIX AND CHECKING THE ACCURACY**","426b5eb3":"We see that most of  the married people are earning more than 50k as compared to other classes"}}