{"cell_type":{"692d53a1":"code","2053613d":"code","b46baab7":"code","694b165a":"code","d49692a5":"code","b646a775":"code","48eb83d6":"code","0e264e1d":"code","ce742a38":"code","d8f45b7b":"code","b1ed7795":"code","e57c212a":"code","4e1c1ffe":"code","aaf1bf89":"code","57a05ca0":"code","18891d7e":"code","b56179cf":"code","fa242378":"code","854e66a5":"code","d65aae67":"code","a078c95a":"code","22ca3e9b":"code","fc2bc050":"code","1bdb41ea":"code","24a249e3":"code","4af9d22b":"code","a2c2c934":"code","59f49b43":"code","54567128":"code","04104c71":"code","8e6c2d6f":"code","5ef532f7":"code","00b7047b":"code","7af8a301":"markdown","42d081c9":"markdown","17044c46":"markdown","d925b8b5":"markdown","7a60249c":"markdown","78702de2":"markdown","733cf0c9":"markdown","34a7c500":"markdown","16ea41bd":"markdown"},"source":{"692d53a1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2053613d":"train_data = pd.read_csv('\/kaggle\/input\/leaf-classification\/train.csv.zip',index_col='id')\ntest_data = pd.read_csv('\/kaggle\/input\/leaf-classification\/test.csv.zip')","b46baab7":"train_data.head()","694b165a":"test_data.head()","d49692a5":"test_id=test_data.id\ntest_data = test_data.drop(['id'], axis =1)","b646a775":"test_data.head()","48eb83d6":"import zipfile\nwith zipfile.ZipFile('\/kaggle\/input\/leaf-classification\/images.zip') as z_img:\n    z_img.extractall()","0e264e1d":"import matplotlib.pyplot as plt\nplt.figure(figsize=(20,15))\nimport cv2 as cv\nfrom keras.preprocessing.image import load_img\nfor i in range(25):\n    j=np.random.choice((os.listdir('images')))\n    plt.subplot(5,5,i+1)\n    img=load_img(os.path.join('\/kaggle\/working\/images',j))\n    plt.imshow(img)","ce742a38":"train_data.shape","d8f45b7b":"test_data.shape","b1ed7795":"train_data.isnull().any().sum()","e57c212a":"test_data.isnull().any().sum()","4e1c1ffe":"train_data.info()","aaf1bf89":"test_data.info()","57a05ca0":"train_data['species'].nunique()","18891d7e":"from sklearn.preprocessing import LabelEncoder\nencoder=LabelEncoder()\nle=encoder.fit(train_data.species)\nlabels=le.transform(train_data.species)\nclasses=list(le.classes_)","b56179cf":"classes","fa242378":"labels","854e66a5":"X=train_data.drop(['species'],axis=1).values\nY=labels","d65aae67":"X","a078c95a":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=1,shuffle=True,stratify=Y)","22ca3e9b":"from sklearn.tree import DecisionTreeClassifier\nclassifier1=DecisionTreeClassifier(criterion='entropy')\nclassifier1.fit(x_train,y_train)","fc2bc050":"classifier1.score(x_train,y_train)","1bdb41ea":"classifier1.score(x_test,y_test)","24a249e3":"from sklearn.ensemble import RandomForestClassifier\nclassifier2=RandomForestClassifier(n_estimators = 40,n_jobs=4)\nclassifier2.fit(x_train,y_train)","4af9d22b":"classifier2.score(x_test,y_test)","a2c2c934":"y_pred2=classifier2.predict_proba(x_test)\n","59f49b43":"y_pred2","54567128":"sample_data = pd.read_csv('\/kaggle\/input\/leaf-classification\/sample_submission.csv.zip',index_col='id')\nsample_data.head()","04104c71":"final_pred=classifier2.predict_proba(test_data) # final prediction on test_data","8e6c2d6f":"final_pred","5ef532f7":"submission = pd.DataFrame(final_pred, columns=classes)\nsubmission.insert(0, 'id', test_id)\nsubmission.reset_index()","00b7047b":"submission.to_csv('submission.csv', index = False)","7af8a301":"## Data set details\nThe dataset consists approximately 1,584 images of leaf specimens (16 samples each of 99 species) which have been converted to binary black leaves against white backgrounds. Three sets of features are also provided per image: a shape contiguous descriptor, an interior texture histogram, and a \ufb01ne-scale margin histogram. For each feature, a 64-attribute vector is given per leaf sample.\n\nNote that of the original 100 species, we have eliminated one on account of incomplete associated data in the original dataset.","42d081c9":"# Random Forest Classifier","17044c46":"# Species is our categorical column which is our Target column","d925b8b5":"# VIsualizing leaf images'","7a60249c":"## Splitting Data","78702de2":"# Label Encoding","733cf0c9":"we can clearly see that decision tree is overfitted","34a7c500":"# Data fields\n\nid - an anonymous id unique to an image\n\nmargin_1, margin_2, margin_3, ..., margin_64 - each of the 64 attribute vectors for the margin feature\n\nshape_1, shape_2, shape_3, ..., shape_64 - each of the 64 attribute vectors for the shape feature\n\ntexture_1, texture_2, texture_3, ..., texture_64 - each of the 64 attribute vectors for the texture feature","16ea41bd":"# Decision Tree Classifier"}}