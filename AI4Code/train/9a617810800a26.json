{"cell_type":{"fef999ee":"code","25745def":"code","6a8ae962":"code","31d1c000":"code","2336a9c7":"code","266f4cdd":"code","cc59f1a5":"code","5f0b8022":"code","0ced2e4c":"code","d7d6fd27":"code","c1e4d3cb":"code","4e21e00e":"code","696f41cd":"code","c30f0841":"code","78625ce5":"code","d0120025":"code","99bb0dc8":"code","da7cd4b9":"code","e7cd2282":"code","3cf78293":"code","62b34063":"code","7209a9f5":"code","9b8f380c":"code","71c34c30":"code","0a40a192":"code","00419e32":"code","1e0dc997":"code","87c038b2":"code","8bbb5f2b":"code","87fef060":"code","ce02159e":"code","9c8dd75b":"code","4e79dd00":"code","f8ccab08":"code","0423d775":"code","2e850d5a":"code","43a78dab":"markdown","43dc852d":"markdown","d2a00f95":"markdown","ada22b03":"markdown","259e2d94":"markdown","8b482dd5":"markdown","bc92c9b2":"markdown","490b1b8c":"markdown","1b3bb6de":"markdown","48d6de7e":"markdown","7956a16a":"markdown","9441942d":"markdown","c03b2774":"markdown","0509aa5d":"markdown","9b2b9c42":"markdown","ef02ca3d":"markdown","2a67a071":"markdown","76b6c71b":"markdown","b706f43f":"markdown","8d96e3c9":"markdown","5e79bb0a":"markdown","355f1b14":"markdown","99b6a9b0":"markdown","fed4d4f4":"markdown","1551a5cc":"markdown","870aebef":"markdown","7ff26b7f":"markdown","c09afc21":"markdown","51c7a76b":"markdown","1b7ba3af":"markdown","acd21766":"markdown","80dcde37":"markdown","8fc0c160":"markdown","6952bd97":"markdown","4d2e591a":"markdown"},"source":{"fef999ee":"import numpy as np \nimport pandas as pd # for working with dataframes\nimport seaborn as sns # for data visualization \n\nfrom matplotlib import pyplot as plt # for plotting\n%matplotlib inline\nsns.set_style(\"whitegrid\")\n\nimport warnings # http:\/\/blog.johnmuellerbooks.com\/2015\/11\/30\/warnings-in-python-and-anaconda\/\nwarnings.filterwarnings(\"ignore\")","25745def":"dataframe = pd.read_csv('..\/input\/SpotifyFeatures.csv')\ndataframe.head()","6a8ae962":"dataframe.describe()","31d1c000":"print(dataframe.keys())","2336a9c7":"pd.isnull(dataframe).sum()","266f4cdd":"sns.distplot(dataframe['popularity']).set_title('Popularity Distribution')","cc59f1a5":"dataframe.corr()","5f0b8022":"sns.barplot(x = 'time_signature', y = 'popularity', data = dataframe)\nplt.title('Popularity Based on Time Signature')","0ced2e4c":"sns.barplot(x = 'key', y = 'popularity', data = dataframe)\nplt.title('Popularity Based on Key')","d7d6fd27":"sns.barplot(x = 'mode', y = 'popularity', data = dataframe)\nplt.title('Popularity Based on Mode')","c1e4d3cb":"sns.barplot(x = 'mode', y = 'popularity', hue = 'key', data = dataframe)\nplt.title('Popularity Based on Mode and Key')","4e21e00e":"sns.jointplot(x = 'acousticness', y = 'popularity', data = dataframe)","696f41cd":"sns.jointplot(x = 'loudness', y = 'popularity', data = dataframe)","c30f0841":"popular_above_50 = dataframe[dataframe.popularity > 50]\nsns.distplot(popular_above_50['acousticness'])\nplt.title('Acoustiness for Songs with More than 50 Popularity')","78625ce5":"popular_below_50 = dataframe[dataframe.popularity < 50]\nsns.distplot(popular_below_50['acousticness'])\nplt.title('Acoustiness for Songs with Less than 50 Popularity')","d0120025":"sns.distplot(popular_above_50['loudness'])\nplt.title('Loudness for Songs with More than 50 Popularity')\n ","99bb0dc8":"popular_below_50 = dataframe[dataframe.popularity < 50]\nsns.distplot(popular_below_50['loudness'])\nplt.title('Loudness for Songs with Less than 50 Popularity')","da7cd4b9":" sns.pairplot(dataframe)","e7cd2282":"list_of_keys = dataframe['key'].unique()\nfor i in range(len(list_of_keys)):\n    dataframe.loc[dataframe['key'] == list_of_keys[i], 'key'] = i\ndataframe.sample(5)","3cf78293":"dataframe.loc[dataframe[\"mode\"] == 'Major', \"mode\"] = 1\ndataframe.loc[dataframe[\"mode\"] == 'Minor', \"mode\"] = 0\ndataframe.sample(5)\n","62b34063":"list_of_time_signatures = dataframe['time_signature'].unique()\nfor i in range(len(list_of_time_signatures)):\n    dataframe.loc[dataframe['time_signature'] == list_of_time_signatures[i], 'time_signature'] = i\ndataframe.sample(5)","7209a9f5":"dataframe.loc[dataframe['popularity'] < 57, 'popularity'] = 0 \ndataframe.loc[dataframe['popularity'] >= 57, 'popularity'] = 1\ndataframe.loc[dataframe['popularity'] == 1]\n","9b8f380c":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import make_scorer, accuracy_score, roc_auc_score \nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\n","71c34c30":"features = [\"acousticness\", \"danceability\", \"duration_ms\", \"energy\", \"instrumentalness\", \"key\", \"liveness\", \n            \"mode\", \"speechiness\", \"tempo\", \"time_signature\", \"valence\"]","0a40a192":"training = dataframe.sample(frac = 0.8,random_state = 420)\nX_train = training[features]\ny_train = training['popularity']\nX_test = dataframe.drop(training.index)[features]","00419e32":"X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state = 420)","1e0dc997":"LR_Model = LogisticRegression()\nLR_Model.fit(X_train, y_train)\nLR_Predict = LR_Model.predict(X_valid)\nLR_Accuracy = accuracy_score(y_valid, LR_Predict)\nprint(\"Accuracy: \" + str(LR_Accuracy))\n\nLR_AUC = roc_auc_score(y_valid, LR_Predict) \nprint(\"AUC: \" + str(LR_AUC))","87c038b2":"RFC_Model = RandomForestClassifier()\nRFC_Model.fit(X_train, y_train)\nRFC_Predict = RFC_Model.predict(X_valid)\nRFC_Accuracy = accuracy_score(y_valid, RFC_Predict)\nprint(\"Accuracy: \" + str(RFC_Accuracy))\n\nRFC_AUC = roc_auc_score(y_valid, RFC_Predict) \nprint(\"AUC: \" + str(RFC_AUC))","8bbb5f2b":"KNN_Model = KNeighborsClassifier()\nKNN_Model.fit(X_train, y_train)\nKNN_Predict = KNN_Model.predict(X_valid)\nKNN_Accuracy = accuracy_score(y_valid, KNN_Predict)\nprint(\"Accuracy: \" + str(KNN_Accuracy))\n\nKNN_AUC = roc_auc_score(y_valid, KNN_Predict) \nprint(\"AUC: \" + str(KNN_AUC))","87fef060":"DT_Model = DecisionTreeClassifier()\nDT_Model.fit(X_train, y_train)\nDT_Predict = DT_Model.predict(X_valid)\nDT_Accuracy = accuracy_score(y_valid, DT_Predict)\nprint(\"Accuracy: \" + str(DT_Accuracy))\n\nDT_AUC = roc_auc_score(y_valid, DT_Predict) \nprint(\"AUC: \" + str(DT_AUC))","ce02159e":"training_LSVC = training.sample(10000)\nX_train_LSVC = training_LSVC[features]\ny_train_LSVC = training_LSVC['popularity']\nX_test_LSVC = dataframe.drop(training_LSVC.index)[features]\nX_train_LSVC, X_valid_LSVC, y_train_LSVC, y_valid_LSVC = train_test_split(\n    X_train_LSVC, y_train_LSVC, test_size = 0.2, random_state = 420)\n","9c8dd75b":"LSVC_Model = DecisionTreeClassifier()\nLSVC_Model.fit(X_train_LSVC, y_train_LSVC)\nLSVC_Predict = LSVC_Model.predict(X_valid_LSVC)\nLSVC_Accuracy = accuracy_score(y_valid_LSVC, LSVC_Predict)\nprint(\"Accuracy: \" + str(LSVC_Accuracy))\n\nLSVC_AUC = roc_auc_score(y_valid_LSVC, LSVC_Predict) \nprint(\"AUC: \" + str(LSVC_AUC))","4e79dd00":"XGB_Model = XGBClassifier(objective = \"binary:logistic\", n_estimators = 10, seed = 123)\nXGB_Model.fit(X_train, y_train)\nXGB_Predict = XGB_Model.predict(X_valid)\nXGB_Accuracy = accuracy_score(y_valid, XGB_Predict)\nprint(\"Accuracy: \" + str(XGB_Accuracy))\n\nXGB_AUC = roc_auc_score(y_valid, XGB_Predict) \nprint(\"AUC: \" + str(XGB_AUC))","f8ccab08":"model_performance_accuracy = pd.DataFrame({'Model': ['LogisticRegression', \n                                                      'RandomForestClassifier', \n                                                      'KNeighborsClassifier',\n                                                      'DecisionTreeClassifier',\n                                                      'LinearSVC',\n                                                      'XGBClassifier'],\n                                            'Accuracy': [LR_Accuracy,\n                                                         RFC_Accuracy,\n                                                         KNN_Accuracy,\n                                                         DT_Accuracy,\n                                                         LSVC_Accuracy,\n                                                         XGB_Accuracy]})\n\nmodel_performance_AUC = pd.DataFrame({'Model': ['LogisticRegression', \n                                                      'RandomForestClassifier', \n                                                      'KNeighborsClassifier',\n                                                      'DecisionTreeClassifier',\n                                                      'LinearSVC',\n                                                      'XGBClassifier'],\n                                            'AUC': [LR_AUC,\n                                                         RFC_AUC,\n                                                         KNN_AUC,\n                                                         DT_AUC,\n                                                         LSVC_AUC,\n                                                         XGB_AUC]})","0423d775":"model_performance_accuracy.sort_values(by = \"Accuracy\", ascending = False)","2e850d5a":"model_performance_AUC.sort_values(by = \"AUC\", ascending = False)","43a78dab":"For feature selection, we will select the following features which are only based on music theory and not artist\/song information: acousticness, danceability, duration_ms, energy, instrumentalness, key, liveliness, loudness, mode, speeciness, tempo, time_signature, and valence.","43dc852d":"**XGBOOST**","d2a00f95":"**Decision Tree Classifier**","ada22b03":"**8. Model Performance Summary**","259e2d94":"**4. Cleaning NaN Values**","8b482dd5":" **6. Feature Engineering**","bc92c9b2":"1. Cher Lau-Cher Lau - https:\/\/towardsdatascience.com\/5-steps-of-a-data-science-project-lifecycle-26c50372b492\n2. Are Hit Songs Becoming Less Musically Diverse?\nAndrew Thompson-Matt Daniels-Dami\u00e1n Gaume - https:\/\/pudding.cool\/2018\/05\/similarity\/\n3. Song Popularity Predictor\nMohamed Nasreldin-Mohamed Nasreldin - https:\/\/towardsdatascience.com\/song-popularity-predictor-1ef69735e380\n4. Titanic: Beginner's Guide with Sklearn\nhttps:\/\/www.kaggle.com\/ialimustafa\/titanic-beginner-s-guide-with-sklearn\/data\n5. **Data Source:** https:\/\/www.kaggle.com\/zaheenhamidani\/ultimate-spotify-tracks-db#SpotifyFeatures.csv","490b1b8c":"We will use the same models as seen in a previous study on predicting song similarity: https:\/\/towardsdatascience.com\/song-popularity-predictor-1ef69735e380. For simplicity and using binary classification, we define as the top 25% popular songs as \"popular\", and the bottom 75% popular songs as \"not popular\".  ","1b3bb6de":"**Key**: Since there are 12 letter keys (not distinguishing between major and minor), we will convert A to 0, A# to 1, and so on and so forth until B is 12. ","48d6de7e":"Since key and mode are related (there can be A major or A minor), we combine those two features in another barplot using \"hue\". ","7956a16a":"From this analysis, there loudness\" and acousticness features have medium-weak correlations with popularity. Furthermore, the distributions of loudness and acousticness differ for songs with more than 50 popularity vs. songs with less than 50 popularity. We plot a summary of all relationships between the features. ","9441942d":"**Mode**: We will assign major = 1 and minor = 0. \n","c03b2774":"We add a validation dataset using train_test_split. ","0509aa5d":"There are 3 categorical variables (key, mode, and time signature) that need to be converted from text to numbers using one-hot-encoding. We also define popularity as a binary variable. For our purposes, we will define above 57 as \"popular\" since that's the border of the top 25% of songs and encode that as 1, and below 75 as \"not popular\" and encode that as 0. ","9b2b9c42":"**Logistic Regression**","ef02ca3d":"Since there are no null values, we don't have to worry about filling in missing information. ","2a67a071":"**3. Loading and Viewing Dataset**","76b6c71b":"**Random Forest Classifier**","b706f43f":"Using a dataset of 228,000 Spotify Tracks, we were able to predict popularity (greater than 57 popularity) using audio-based metrics such as key, mode, and danceability without external metrics such as artist name, genre, and release date. The Random Forest Classifier was the best performing algorithm with 92.0% accuracy and 86.4% AUC. The Decision Tree Classifier was the second best performing algorithm with 87.5% accuracy and 85.8% AUC.\n\nMoving forward, I will use a larger Spotify database by using the Spotify API to collect my own data, and explore different algorithms to predict popularity score rather than doing binary classification. ","8d96e3c9":"**10. References**","5e79bb0a":"**5. Exploratory Analysis**","355f1b14":"**K-Nearest Neighbors Classifier**","99b6a9b0":"**Popularity**","fed4d4f4":"We load the dataset and look at the overall statistics such as mean, count, and median.","1551a5cc":"A link to the definitions of these features is shown here: https:\/\/developer.spotify.com\/documentation\/web-api\/reference\/tracks\/get-audio-features\/","870aebef":"**2. Import Packages**","7ff26b7f":"As I am in the initial stages of developing my data science and singer-songwriting careers, I thought it would be appropriate to bring both fields together to inform my analysis and songwriting skills. For this short project, I will be predicting the popularity of songs based purely on song metrics such as key, dancibility, and acousticness. Year, artist, era, and genre will not be included. \n","c09afc21":"**9. Conclusion**","51c7a76b":"**7. Model Fitting and Predicting** ","1b7ba3af":"**1. Introduction**\n\n","acd21766":"Next we define 80% of the dataframe for training and 20% of the dataframe for testing. ","80dcde37":"Since LSVC is O(n^3), and the training data set has 182,000 datapoints, it would take 10^15 operations to train the model. Therefore we will only use 10000 datapoints total. ","8fc0c160":"**Linear Support Vector Classification**","6952bd97":"We investigate overall trends in the data to get a good idea of which variables correlate with each other as well as other associations.","4d2e591a":"We check for null values. "}}