{"cell_type":{"b582128c":"code","e81a3aea":"code","47f39eef":"code","644f4f19":"code","8fdbe4da":"code","9e2e22b5":"code","6a2edced":"code","b08653f0":"code","6f7e7e4f":"code","143e0903":"code","b2fe5736":"code","05cdc225":"code","25a21ba9":"code","8ea00d72":"code","3758d247":"code","d890a2ca":"code","cc054b12":"code","c1179bf8":"code","e6c8a088":"code","7ce85e48":"code","11eb29a3":"code","c134b50d":"code","e96cbe2f":"code","7400b5f4":"code","a464f4c1":"code","c47132fc":"code","6eac0b97":"code","4b896dce":"code","48da7b75":"code","b8346f45":"code","9d236b34":"code","9ac542e7":"code","57f83890":"markdown","ba46b1d5":"markdown","b244feec":"markdown","1009fe01":"markdown","cc6784d5":"markdown","0ba81d56":"markdown","22349174":"markdown","336609c6":"markdown","1373394c":"markdown","60809b02":"markdown","bbb94849":"markdown","c8f85634":"markdown","ae168c15":"markdown","87c5db6d":"markdown","661547f2":"markdown","d0cc024e":"markdown","65405b0a":"markdown","def2f998":"markdown","82afc7fd":"markdown","5e0bce2b":"markdown","610bd4db":"markdown","3a823baf":"markdown","2db4602d":"markdown"},"source":{"b582128c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport nltk\nnltk.download('vader_lexicon')\nfrom nltk.corpus import sentiwordnet as swn\n%matplotlib inline\nimport seaborn as sns\nimport re\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer","e81a3aea":"data=pd.read_csv('\/kaggle\/input\/pfizer-vaccine-tweets\/vaccination_tweets.csv',na_values='NULL')\ndata.tail(5)","47f39eef":"data.shape","644f4f19":"data['text'].iloc[-1]","8fdbe4da":"data.info()","9e2e22b5":"#Check For Duplication in The Tweets Id and User_Name\nprint('No Of Duplicated Id: {}'.format(str(data.id.duplicated().sum())))\nprint('No Of unique Users: {}'.format(str(len(data.user_name.unique()))))\nprint('No Of Unique Descriptions: {}'.format(str(len(data.user_description.unique()))))\nprint('No Of Unique Tweets: {}'.format(str(len(data.text.unique()))))\n\n\n      \n      ","6a2edced":"#User_Created\nprint('Earliest User Acct Date: {}'.format(str(min(pd.DatetimeIndex(data.user_created)))))\nprint('-'*25)\nprint('Latest User Acct Date: {}'.format(str(max(pd.DatetimeIndex(data.user_created)))))","b08653f0":"#Date Of Tweet\nprint('Earliest Tweet Date: {}'.format(str(min(pd.DatetimeIndex(data.date)))))\nprint('-'*25)\nprint('Latest Tweet Date: {}'.format(str(max(pd.DatetimeIndex(data.date)))))","6f7e7e4f":"#We will Use A HeatMap to Analyze The Correlations Between  Numerical Variables\nprint('Fig 1.0')\ncorrmat=data.corr()\nmask=np.array(corrmat)\nplt.figure(figsize=(10,10))\nplt.title('Heatmap Showing Correlations Of Features')\nsns.heatmap(corrmat,square=True,annot=True)","143e0903":"b=data.hashtags[data.hashtags.notnull()].values\nhash=[]\nfor x in b:\n    c=re.findall(r'\\w+[\\$@+]?',x)\n    for x in c:\n        hash.append(x.lower())\nprint('Number Of Tweets: {}'.format(str(len(hash))))\nhash[-10:]","b2fe5736":"#Convert Text to Nltk Object\nhash=nltk.Text(hash)\n#Collocations\nhash.collocations()","05cdc225":"#Number of Unique Tweets\nprint('Number of Unique Tweets: {}'.format(str(len(set(hash)))))\nprint('-'*25)\nprint('Fig 1.1')\n#FreqDist Of Tweets\nfreq=nltk.FreqDist(hash)\nfreq.plot(20,cumulative=True)","25a21ba9":"#Cleaning Up the Tweets\ntweets_sents=data.text.values\ntweets_words=[]\nfor x in tweets_sents:\n    tweets_words.append(re.split(r'\\s+',x))\n#Lower Case\nb=[];c=[]\nfor x in tweets_words:\n    for y in x:\n        c.append(y.lower())\n    b.append(c);c=[]\ntweets_words=b;\ntweets_words[:3]","8ea00d72":"#Remove HTML Links and Words targeting at Someone or Something(Beginning with '@')\nc=[];tweets_words=[]\nfor x in b:\n    for y in x:\n        if re.search(r'^(https|@)',y): continue\n        else:\n            c.append(y)\n    tweets_words.append(c);c=[]\ntweets_sents=[]\n#Lemmatize Using WordNetLemmatizer\nfor x in tweets_words:\n    for y in x:\n        lemma= nltk.WordNetLemmatizer()\n        c.append(lemma.lemmatize(y))\n    tweets_sents.append(c);\ntweet_words=tweets_sents;c=[];tweets_sents=[]\n#Remove Stopwords From The Tweets\nstopwords=nltk.corpus.stopwords.words('english')\nb=[];c=[]\nfor x in tweets_words:\n    for y in x:\n        if y not in stopwords:\n            c.append(y)\n    b.append(c);c=[]\nfor x in b:\n    tweets_sents.append(' '.join(x))\n#Extract Words And Tweets Only From the Data\nb=[];c=[]\nfor x in tweets_sents:\n    b.append(re.findall(r'#?[a-zA-Z]+',x))\ntweets_words=b;tweets_sents=[]\nfor x in b:\n    tweets_sents.append(' '.join(x))\ntweets_sents[:5]","3758d247":"vadler_scores=[]\nfor x in tweets_sents:\n    analyzer=SentimentIntensityAnalyzer()\n    vadler_scores.append(analyzer.polarity_scores(x))\nvadler_scores[:5]","d890a2ca":"vadler_frame=pd.DataFrame(vadler_scores)\nsentiments=[]\nfor x in vadler_frame['compound']:\n    if x<0:\n        sentiments.append('Negative');\n    elif x==0:\n        sentiments.append('Neutral');\n    elif x>0:\n        sentiments.append('Positive');\nvadler_frame['Sentiments']=sentiments\nvadler_frame['Tweets']=tweets_words\nvadler_frame.head(10)","cc054b12":"# Function to plot Pie Charts of Sentiments\ndef piechart(lexicon,data,label):\n    plt.figure(figsize=(10,10));\n    plt.title(lexicon+' Sentiments Pie Chart',size=15)\n    plt.pie(x=data,labels=label,explode=[0.05,0.05,0.05],autopct='%.2f')\n    plt.legend(loc='upper right')\n    plt.show()\n","c1179bf8":"print('Fig 1.2')\npiechart('Vadler',vadler_frame.Sentiments.value_counts().values,['Positive','Neutral','Negative'])","e6c8a088":"#Lets Take A peek At our Tweets with Negative Sentiments\nvadler_negative_tweets=vadler_frame[vadler_frame.Sentiments=='Negative']\n#Sort Them By Negativities in Decreasing Order.\nvadler_negative_tweets=vadler_negative_tweets.sort_values(by='neg',ascending=False)\nvadler_negative_tweets.head(10)","7ce85e48":"#ANALYZE TWEETS WITH NEGATIVE VADLER SENTIMENTS TO SEE QHAT PEOPLE ARE TALKING ABOUT\nb=vadler_negative_tweets.Tweets.values\nneg_tweets=[]\nfor x in b:\n    for y in x:\n        neg_tweets.append(y)\n# Convert To Nltk Text And Make a Freq Plot Of the words\nneg_tweets=nltk.Text(neg_tweets)\nfreq=nltk.FreqDist(neg_tweets)\nprint('Fig 1.3')\nfreq.plot(20,cumulative=True)","11eb29a3":"freq","c134b50d":"#Tweets with words Khamenei\nneg_tweets.findall(r'<.*><.*><#?khamenei><.*><.*>')","e96cbe2f":"#Tweets with words Ban\nneg_tweets.findall(r'<.*><.*><ban><.*><.*>')","7400b5f4":"#Tweets with words Emergency\nneg_tweets.findall(r'<.*><.*><emergency><.*><.*>?')","a464f4c1":"#Tweets with Words Allergic\nneg_tweets.findall(r'<.*><.*><allergic><.*>')\n","c47132fc":"# collocations in Negative Tweets\nneg_tweets.collocations()","6eac0b97":"#Part of Speech Tagging of each word\ntagged_tweets=[];\nfor x in tweets_words:\n        tagged_tweets.append(nltk.tag.pos_tag(x))\ntagged_tweets[:3]","4b896dce":"#Implementing The Sentiwordnet Algorithm\nsenti_frame=[];Total_Count=0\nfor tags in tagged_tweets:\n    pos_score=neg_score=obj_score=Count=0\n    for x,y in tags:\n        if y.startswith('NN') and len(list(swn.senti_synsets(x,'n')))>0:\n            ss_set=list(swn.senti_synsets(x,'n'))[0]\n        elif y.startswith('JJ') and len(list(swn.senti_synsets(x,'a')))>0:\n            ss_set=list(swn.senti_synsets(x,'a'))[0]\n        elif y.startswith('V') and len(list(swn.senti_synsets(x,'v')))>0:\n            ss_set=list(swn.senti_synsets(x,'v'))[0]\n        elif y.startswith('R') and len(list(swn.senti_synsets(x,'r')))>0:\n            ss_set=list(swn.senti_synsets(x,'r'))[0]\n        if ss_set:\n            pos_score+=ss_set.pos_score()\n            neg_score+=ss_set.neg_score()\n            obj_score+=ss_set.obj_score()\n            Count+=1;Total_Count+=1\n    senti_frame.append({'Pos_Score':pos_score,'Neg_Score':neg_score,'Obj_Score':obj_score,'Net_Score':pos_score-neg_score,'Count':Count})\nsenti_frame=pd.DataFrame(senti_frame)\n#Assign Semtiments to each Tweets using 0 as threshold for positive\nb=[]\nfor x in senti_frame['Net_Score']:\n    if x<0:\n        b.append('Negative')\n    elif x==0:\n        b.append('Neutral')\n    elif x>0:\n        b.append('Positive')\nsenti_frame['Sentiments']=b\nsenti_frame['Tweets']=tweets_words\nsenti_frame.head(5)","48da7b75":"#PieChart Of Sentiwordnet Lexicon Sentiments\nprint('Fig 1.4')\npiechart('SentiWordNet',senti_frame.Sentiments.value_counts().values,['Positive','Neutral','Negative'])","b8346f45":"#Positive Tweets Analysis\nprint('Fig 1.5')\nsenti_positive_tweets=senti_frame[senti_frame['Sentiments']=='Positive']\nb=[x for y in senti_positive_tweets.Tweets for x in y]\npos_tweets=nltk.Text(b)\nfreq=nltk.FreqDist(pos_tweets)\nfreq.plot(20,cumulative=True)","9d236b34":"#Negative Tweets Analysis\nprint('Fig 1.6')\nsenti_negative_tweets=senti_frame[senti_frame['Sentiments']=='Negative']\nb=[x for y in senti_negative_tweets.Tweets for x in y]\nneg_tweets=nltk.Text(b)\nfreq=nltk.FreqDist(neg_tweets)\nfreq.plot(20,cumulative=True)","9ac542e7":"neg_tweets.findall(r'<.*><.*><side><.*><.*>?')","57f83890":"The absence of Label(s) for the Dataset Makes it  practically impossible to use Supervised Learning algoeithms for studying sentiments and classifying tweets. We will use unsupervised learning methods to analyse our tweets for opinions amd patterns. One of The Ways to implement sentiment(s) analysis using unsupervised learning is the use of LEXICON.","ba46b1d5":"### CONCLUSION:\n","b244feec":"A Lexicon is a well curated dictionary of words. in this case of opinion mining it is a dictionary that contains words asscociated with positive and negative sentiments, Part-of-Speech tags(POS-Tags),Polarity scores,Subjectivity and Objectivity Scores. There are numerous lexicons available but for this analysis we will be using just three of those lexicon, the idea here is to compare and contrast between the resupts of each lexicon. they are namely:\n1. Vader Sentiment Analysis(Best suitable for tweets).\n2. AFINN Lexicon\n3. Sentiword Lexicon (From Wordnet in NLTK Library).","1009fe01":"### FEATURE EXPLORATION AND INSIGHTS INTO THE DATA","cc6784d5":"The Above shows that There is A unqiue Id for each tweets. But There are Users with overlapping user_name or  Users who have more than one tweets in the Dataset. We will sample the Duplicated users to gain insight into this","0ba81d56":"### SENTIWORDNET LEXICON","22349174":"#### ANALYZING HASHTAGS","336609c6":"#### VADER LEXICON SENTIMENT ANALYSIS","1373394c":"Fig 1.3 Is A Cummulative Freqency ditribution of Top  20 Words that are found in the Negative Vaccine Tweets. The most common words are associated with Covid-19 and PfizerBiontech Vacvine. There are certain words of Interest here such as\nKhamenei,Ban,Iran,Allergic,Emergency.We will look at these words.  ","60809b02":"Fig 1.1 Is a Freq Plot Of the Most Common Tweets. PfizerBiontech hashtag accounts for majority of the tweets. The First Fifteen Most common hashtags are concerned with covid19 and its vaccine. We will use some Reg exp to Clean and Merge Overlapping hashtags.","bbb94849":"We will work with multiple tweets from same user(s) with the assumption(s) that:\n1. Their View(s) about the Vaccine doesnt change with time.\n2. For Corporations with multiple tweets we assume their positions on the tweets remain consistent and does not vary with individual interests at different times.","c8f85634":"#### Summary of Sentiwordnet Lexicon Analysis","ae168c15":"So we have a list of all the hashtags in the tweets in lowercase.Lets take a look at it next","87c5db6d":"The Heatmap in Fig 1.0 shows strong relationship between Retweets and Favourites(Which is Expected). Those who retweets  ","661547f2":"Fig 1.4 Above shows the Distribution of Sentiments for our sentiwordnet. This composition is dependent on the threshold used in this case the threshold is chosen to be zero. We have more Postive Sentiments aaccounting for more than 50% of the tweets while Negative Sentiments account for the lowest of all sentiments with 22%.","d0cc024e":"Fig 1.2 Above Is a Representation of Sentiments for Our vadler lexicon. It is in represented in percentages. The Threshold for Sentiments was chosen to be 0, this means any tweet with compound score greater than 0 is assumed to be positive. Compound score less than zero is assumed to indicate Negative polarity while Compound score of zero is an indication of Neutrality in the tweet. From fig 1.2 We can see that Positive Sentiments and Neutral Sentiments are closely tied at 41%. Our Vadler Lexicon shows us that there are less Negative sentiments to the #PfizerBiontech Vaccine Compared to the Positive Sentiments. Tweets With Negative sentiments make up for about 16.08% of the whole. ","65405b0a":"Our major take from Sentiwordnet Lexicon are as follows:\n1. Majority of the tweets (Over 50%) are associated with positive sentiments about the vaccine.\n2. Tweets with Negative Sentiments account for 22% of our total tweets.\n3. Side Effect of the Vaccine was a major concern of the Tweets with negative sentiments.","def2f998":"#### SUMMARY OF VADLER LEXICON ANALYSIS","82afc7fd":"Fig 1.6 Is a Cumulative plot of Words associated with Negative sentiments. Other than words such as Allergic and Emergency which where detected to common occurence among Negative tweets in our Vadler lexicon analysis, 'Side' is another word that occurs commonly among our tweets and the code snippet below shows that it is asscoiated with the collocation 'Side Effect'.","5e0bce2b":"In conclusion we would say that:\n1. There is generally Good and Positve Sentiments and Opinions But not much of excitement towards The #Pfizer Biontech vaccine.\n2. Emergency Use of the vaccine Was also a major concern. There is a sense of excitement and elation towards the emergency approval of its use.\n3. Allergic Reaction(s) and Side Effect(s) were part of major concern for tweets with negative sentiments. This accounts for about 15% of the tweets. It was one of the major issues associated with negative snetimwnts according to our analysis.\n4. Words such as 'Ban','Khamenei' and 'Iran' Were associated with Negative sentiments And were major issues of discussion in tweets.","610bd4db":"#### LEXICON BASED MODELS","3a823baf":"### SENTIMENT ANALYSIS \/ OPINION MINING","2db4602d":"Vadler Lexicon Fails significantly in identifying Positive tweets from Neutral tweets.Our Major Take from this Lexicon is:\n1. A compound score greater than 0 may likely be an indication of a positive sentiment towards the  #PfizerBiontech Vaccine.\n2. 17% of our tweets had negative sentiments towards the vaccine.The plot of fig 1.3 shows that the most occuring words in these negative tweets were mostly directly related with the vaccine and covid-19 in genreral.\n3. A major Negative sentiment about the PfizerBiontech vaccine according to the vadler lexicon is concerned with the 'Allergic' Reaction of the Vaccine and it adverse effect\/reaction. This is the major concern of the people who tweeted negatively about the vaccine. This can be seen form the output of the snippet 'Tweets regarding the word Allergic'.\n4. Emergency Use or approval of the vaccine was also a major concern of the people who tweeted. Emergency as a word is associated with Negative Sentiment in the vadler lexicon and has a negative polarity score. But a look at the code snippet above '#Tweets with the word Emergency' shows a sense of elation,excitement and optimism about The approval for emergency use of the vaccine for treatment.'Emergency use' was also a collocation i.e a freqently used term in the tweets.\n5. Words such as Ban,Iran and Khamenei were amomg the most used words used in tweets with Negative Sentiments. Analysis of tweets with words such as ban had phrases such as 'Khamenei ban','Ban on Import','Iran Ban'."}}