{"cell_type":{"9e58b25f":"code","9a1e4b30":"code","c4572907":"code","4d9c47b1":"code","de007964":"code","f1a6a55e":"code","80bf27fc":"code","fe1dac3f":"code","98488c1c":"code","7ca8a5d4":"code","94e24eb5":"code","ad3f5235":"code","3a2de498":"code","b333151c":"code","02f3720a":"code","177c73c5":"code","9cb0829e":"code","0da84a89":"code","35e30cde":"code","5a1b59a2":"code","10ca2f28":"code","f34751d8":"code","6367605a":"code","b37a551b":"code","196d298c":"code","4f13521b":"code","77ae241f":"code","fd7eab0e":"code","cb7a6801":"code","4411519c":"markdown","de0b56b3":"markdown","1ad3c3bd":"markdown","1dec4c94":"markdown","ec3e6686":"markdown","4d6c3fbe":"markdown"},"source":{"9e58b25f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.cluster import KMeans\nimport os\nprint(os.listdir(\"..\/input\"))\ndf=pd.read_csv(\"..\/input\/german_credit_data.csv\")\n#df=pd.read_csv(\"german_credit_data.csv\")\ndf.head(10)","9a1e4b30":"df.isnull().sum()","c4572907":"df.drop(\"Checking account\",axis=\"columns\",inplace=True)","4d9c47b1":"#lets work on the missing values\n#we use fwd fill and back fill\ndf[\"Saving accounts\"].fillna(method=\"bfill\",inplace=True)","de007964":"df.head()","f1a6a55e":"#dropping the first column as its of no use\ndf.drop(columns='Unnamed: 0',axis=\"columns\",inplace=True)\ndf.head()","80bf27fc":"df.corrwith(df[\"Credit amount\"],axis=0) #data corellation wih each other","fe1dac3f":"# we have categorical values like Sex, Job Housing and Purpose.\n# Lets skip purpose from further analysis as its nota good parameter for the analysis as per my consideration.\n\nfrom sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ndfe=df.copy() # lets take a copy of dataframe for analysis\ndfe.Sex=le.fit_transform(dfe.Sex)\ndfe.Housing=le.fit_transform(dfe.Housing)\ndfe[\"Saving accounts\"]=le.fit_transform(dfe[\"Saving accounts\"])","98488c1c":"dfe.head(20)","7ca8a5d4":"dfe1 =df.copy()\ndfe.drop(\"Purpose\",axis=\"columns\",inplace=True)","94e24eb5":"df.corrwith(df[\"Credit amount\"],axis=0) #data corellation wih each other","ad3f5235":"import matplotlib.pyplot as plt\n%matplotlib inline\nplt.figure(figsize=(10,5))\nplt.bar(df[\"Age\"],df[\"Credit amount\"],color=\"green\")\n#plt.scatter(df[\"Purpose\"],df[\"Credit amount\"],color=\"g\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"credit amount\")\nplt.xlim(18,75)\nplt.title(\"customers age and credit amount\")\nplt.show()","3a2de498":"import seaborn as sns\nsns.distplot(df[\"Age\"],bins=10,kde=True)","b333151c":"#count plot shows that distribution of loan purpose with Gender. like men took more car loans than women.\nplt.figure(figsize=(10,5))\nsns.countplot(x=\"Purpose\",data=df,hue=\"Sex\")","02f3720a":"sns.distplot(df[\"Duration\"]) \n# distribution of loans based on duration. Max loans are high duration one.","177c73c5":"sns.countplot(x=\"Housing\",data=df,hue=\"Sex\") # maximum loan applicants are male with on housing","9cb0829e":"#categorical plotting #tip: put x axis as categorical value\n#jobs and loan stats\n#Job (numeric: 0 - unskilled and non-resident, 1 - unskilled and resident, 2 - skilled, 3 - highly skilled)\nsns.catplot(x=\"Job\",y=\"Credit amount\",data=df)\nsns.catplot(x=\"Job\",y=\"Age\",data=df)\n#Job (numeric: 0 - unskilled and non-resident, 1 - unskilled and resident, 2 - skilled, 3 - highly skilled)","0da84a89":"sns.catplot(x=\"Housing\",y=\"Credit amount\",data=dfe)\n","35e30cde":"sns.pairplot(dfe)","5a1b59a2":"dfe.corrwith(dfe[\"Credit amount\"],axis=0) #data corellation wih each other","10ca2f28":"dfe.head()","f34751d8":"df.columns","6367605a":"dfe1 = df.copy()\ndfe1.drop('Saving accounts', axis = 1, inplace = True)\ndfe1.Job = dfe1.Job.astype(str)\ndfe1 = dfe1[[ 'Job','Sex','Age','Credit amount', 'Duration','Housing', 'Purpose']]\nX1 = pd.get_dummies(dfe1)\nX1.head()","b37a551b":"# #Machine learning process started\n# X=dfe[[ 'Job','Sex','Age','Credit amount', 'Duration']]\n# X","196d298c":"#scaling the features for the model.\n#minmax scaler gave score as -54 \n# from sklearn.preprocessing import MinMaxScaler\n# mm=MinMaxScaler()\n# X=mm.fit_transform(X1)\n#normalize gave score -192\nfrom sklearn.preprocessing import normalize\nX=normalize(X1)\n\n#satandard scaler was worst\n# from sklearn.preprocessing import StandardScaler\n# sk=StandardScaler()\n# X=sk.fit_transform(X)\n","4f13521b":"#elbow plot to find then_clusters valuefor KMEANS algorithm\n#to find SSE or sum square error\ndistorsions = []\nfor k in range(1, 20):\n    kmeans = KMeans(n_clusters=k)\n    kmeans.fit(X)\n    distorsions.append(kmeans.inertia_)\n\nfig = plt.figure(figsize=(15, 5))\nplt.plot(range(1,20), distorsions)\nplt.grid(True)\nplt.title('Elbow curve')","77ae241f":"#ML model KMeans\nfrom sklearn.cluster import KMeans\nkm=KMeans(n_clusters=5, max_iter=10000,random_state=None)\nkm.fit_transform(X)","fd7eab0e":"km.score(X)# negetive score does not mean bad model","cb7a6801":"from sklearn.metrics import silhouette_score\nsilhouette_score(X, km.labels_)","4411519c":"The Silhouette Coefficient is calculated using the mean intra-cluster distance (a) and the mean nearest-cluster distance (b) for each sample. The Silhouette Coefficient for a sample is (b - a) \/ max(a, b). To clarify, b is the distance between a sample and the nearest cluster that the sample is not a part of. Note that Silhouette Coefficient is only defined if number of labels is 2 <= n_labels <= n_samples - 1.\n\nThe best value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters. Negative values generally indicate that a sample has been assigned to the wrong cluster, as a different cluster is more similar.","de0b56b3":"Scaling the data to remove disparity","1ad3c3bd":"checking for missing data in dataframe","1dec4c94":"Taking care of categorical values","ec3e6686":"# Visualisations","4d6c3fbe":"The k-means score is an indication of how far the points are from the centroids. In scikit learn, the score is better the closer to zero it is.\n\nBad scores will return a large negative number, whereas good scores return close to zero. Generally, you will want to take the absolute value of the output from the scores method for better visualization."}}