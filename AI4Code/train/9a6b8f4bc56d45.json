{"cell_type":{"9961cefe":"code","7a686d7d":"code","fee77518":"code","c8773e5c":"code","147d8136":"code","9e283480":"code","90e5e19e":"code","50d0709d":"code","370a5a8e":"code","0fcaeb5a":"code","fc45376c":"code","66a3a589":"markdown","20799092":"markdown","23cc532f":"markdown","968cac8e":"markdown","03a40914":"markdown","21a8a407":"markdown","2695434a":"markdown"},"source":{"9961cefe":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n#TF\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential,Model\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.layers import Dense,Conv2D,Flatten,Dropout, Input, Concatenate, BatchNormalization\n#other\nfrom tqdm.notebook import tqdm\nimport pickle\nfrom PIL import Image\nfrom annoy import AnnoyIndex\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate, StratifiedKFold\nfrom sklearn.metrics import mean_squared_error","7a686d7d":"# dataset\ntrain_dir = \"\/kaggle\/input\/petfinder-pawpularity-score\/train\/\"\ntest_dir = \"\/kaggle\/input\/petfinder-pawpularity-score\/test\/\"\ntrain_table = pd.read_csv(\"\/kaggle\/input\/petfinder-pawpularity-score\/train.csv\")\ntest_table = pd.read_csv(\"\/kaggle\/input\/petfinder-pawpularity-score\/test.csv\")\n\n# set path\ntrain_table[\"Id\"] = train_dir + train_table[\"Id\"] + \".jpg\"\ntest_table[\"Id\"] = test_dir + test_table[\"Id\"] + \".jpg\"\n\n# stratify label\ntrain_table['stratify_label'] = pd.qcut(train_table['Pawpularity'], q=30, labels=range(30))\n\nsample = pd.read_csv(\"\/kaggle\/input\/petfinder-pawpularity-score\/sample_submission.csv\")\ntrain_table.head()","fee77518":"def MobileNet_model():\n    base_model = keras.applications.mobilenet_v2.MobileNetV2(weights=None)\n    base_model.load_weights(\"..\/input\/mobilenetv2-imagenet\/MobileNetV2_imagenet.h5\")\n    avg_pool_name = [l.name for l in base_model.layers][-2]\n    x = base_model.get_layer(avg_pool_name).output\n    model = Model(inputs=base_model.input, outputs=x)\n    return model\n\ndef img_yield(pathes, batch_size=32, size=(224,224)):\n    for i in tqdm(range(int(np.ceil(len(pathes) \/ batch_size)))):\n        imgs = []\n        batch_pathes = pathes[i*batch_size : (1+i)*batch_size]\n        if len(batch_pathes)==0: break\n        for path in batch_pathes:\n            img = load_img(path, target_size=size)\n            img = tf.keras.applications.mobilenet_v2.preprocess_input(np.array(img))\n            imgs.append(img)\n        yield np.array(imgs)\n        \ndef show_img(df, ids):\n    imgs = [Image.open(df[\"Id\"][i]) for i in ids]\n    pawpularity = [df[\"Pawpularity\"][i] for i in ids]\n    fig, axes = plt.subplots(1, 10, figsize=(20,8))\n    for i, ax in zip(range(10), axes.ravel()):\n        ax.set_title(i+1)\n        ax.imshow(imgs[i])\n        if i == 0:\n            ax.set_title(f\"ID:{ids[i]}\\npawpularity:{pawpularity[i]}\")\n        else:\n            ax.set_title(f\"ID:{ids[i]}\\npawpularity:{pawpularity[i]}\")\n        ax.axis(\"off\")\n    plt.show()\n    \ndef RMSE(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred)) * 100\n\ndef softmax(arr):\n    a = np.exp(arr)\n    b = np.sum(a)\n    return a \/ b\n\n# Assign a score according to the distance between the target and the similar image\ndef soft_pred(ids, distance, y):\n    dis = 1-np.array(distance)\n    dis = softmax(dis)\n    pred = sum(dis * np.array(y[ids]))\n    return pred","c8773e5c":"class ANNOY_ANALYSIS:\n    def __init__(self, train_df, test_df, meta=False):\n        self.train_df = train_df.reset_index(drop=True)\n        self.test_df = test_df.reset_index(drop=True)\n        meta_columns = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory','Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n        self.train_meta = self.train_df.loc[:, meta_columns]\n        self.test_meta = self.test_df.loc[:, meta_columns]\n        self.meta_flag = meta\n        self.embed_model = MobileNet_model()\n        self.y_train = train_df[\"Pawpularity\"].values\n        self.train_embed = self._embed(train_df[\"Id\"].values)  \n        self.test_embed = self._embed(test_df[\"Id\"].values)  \n        self.annoy_model = self._build_annoy()\n        \n    def test_predcit(self, N=5):\n        preds, id_list = [], []\n        if self.meta_flag:\n            inputs = np.hstack([self.test_embed, self.test_meta])\n            for embed in tqdm(inputs):\n                ids, distance = self.annoy_model.get_nns_by_vector(embed, N, include_distances=True)\n                preds.append(soft_pred(ids, distance, self.y_train))\n                id_list.append(ids)\n        else:\n            for embed in tqdm(self.test_embed):\n                ids, distance = self.annoy_model.get_nns_by_vector(embed, N, include_distances=True)\n                preds.append(soft_pred(ids, distance, self.y_train))\n                id_list.append(ids)\n        self.preds = np.array(preds)\n        self.id_list = id_list\n        return self.preds, id_list\n    \n    def compere_image(self, target_id, i):\n        print(\"*\"*30, f\"sample_{i+1}\", \"*\"*30)\n        print(\"TARGET  score :\", self.test_df[\"Pawpularity\"][target_id])\n        img = Image.open(self.test_df[\"Id\"][target_id])\n        plt.imshow(img)\n        plt.axis(\"off\")\n        plt.show()\n        print(f\"Annoy_predict : {self.preds[target_id]:.1f}\")\n        near_img_id = self.id_list[target_id]\n        show_img(self.train_df, self.id_list[target_id])\n        \n    def max_sample(self, N=3):\n        ids = np.argsort(self.preds)[::-1][:10]\n        rnd = np.random.choice(ids, size=N, replace=False)\n        for i, r in enumerate(rnd):\n            self.compere_image(r, i)\n            \n    def min_sample(self, N=3):\n        ids = np.argsort(self.preds)[:10]\n        rnd = np.random.choice(ids, size=N, replace=False)\n        for i, r in enumerate(rnd):\n            self.compere_image(r, i)\n                       \n    def _embed(self, pathes):\n        return self.embed_model.predict(img_yield(pathes))\n    \n    def _build_annoy(self):\n        if self.meta_flag:\n            inputs = np.hstack([self.train_embed, self.train_meta])\n            annoy_model = AnnoyIndex(inputs.shape[1])\n            for i, embed in enumerate(inputs):\n                annoy_model.add_item(i, embed)\n            annoy_model.build(i)\n            return annoy_model\n        else:\n            annoy_model = AnnoyIndex(self.train_embed.shape[1])\n            for i, embed in enumerate(self.train_embed):\n                annoy_model.add_item(i, embed)\n            annoy_model.build(i)\n            return annoy_model","147d8136":"train_df, test_df = train_test_split(train_table, train_size=0.9, stratify=train_table[\"stratify_label\"], random_state=2021)\nAA = ANNOY_ANALYSIS(train_df, test_df, meta=True)","9e283480":"y_test = test_df[\"Pawpularity\"].values\nfor N in range(10, 51, 10):\n    preds, ids = AA.test_predcit(N)\n    print(f\"N={N}  RMSE : {RMSE(y_test, preds) \/ 100:.4f}   SCORE_MEAN : {np.mean(preds):.4f}\")","90e5e19e":"AA.max_sample()","50d0709d":"AA.min_sample()","370a5a8e":"# dataset\ntrain_dir = \"\/kaggle\/input\/petfinder-pawpularity-score\/train\/\"\ntest_dir = \"\/kaggle\/input\/petfinder-pawpularity-score\/test\/\"\ntrain_table = pd.read_csv(\"\/kaggle\/input\/petfinder-pawpularity-score\/train.csv\")\ntest_table = pd.read_csv(\"\/kaggle\/input\/petfinder-pawpularity-score\/test.csv\")\n\n# set path\ntrain_table[\"Id\"] = train_dir + train_table[\"Id\"] + \".jpg\"\ntest_table[\"Id\"] = test_dir + test_table[\"Id\"] + \".jpg\"\n\ntrain_table.head()","0fcaeb5a":"AA = ANNOY_ANALYSIS(train_table, test_table, meta=True)\nfinal_pred, _ = AA.test_predcit(20)","fc45376c":"id_tmp = pd.read_csv(\"\/kaggle\/input\/petfinder-pawpularity-score\/test.csv\")\nsub = pd.DataFrame()\nsub['Id'] = id_tmp['Id']\nsub['Pawpularity'] = final_pred\nsub.to_csv(\"submission.csv\", index = False)\nsub","66a3a589":"## Check Minimum predict image","20799092":"## Check Maximum predict image","23cc532f":"# Submit process","968cac8e":"# validation","03a40914":"# Overview\n\nIn this notebook, we will apply the similar images verified in this [NOTEBOOK](https:\/\/www.kaggle.com\/showeed\/annoy-similar-images-edit2)   \nto make predictions based on the labels (Pawpularity) of similar images.\n\nThis is by no means the only way to do a good analysis,   \nbut in my case, ensembling it with the predictions of swin_transformer gave me good results.\n\n# Image\n![WS000000.JPG](attachment:955361e7-69e2-4290-bfe1-3f50141d3c2c.JPG)","21a8a407":"# Set Petfinder Dataset","2695434a":"# Set function"}}