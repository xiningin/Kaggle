{"cell_type":{"74900074":"code","444733f2":"code","a048cf27":"code","8bdd5b0f":"code","ba767994":"code","94b91fd4":"code","538fee7f":"code","85d02b1c":"code","8af75811":"code","5a888c61":"code","67b20344":"code","8a4776c3":"code","7fee287c":"code","c2a13a32":"code","0b4d9c58":"code","6d0e57a5":"code","4ae0b7d9":"code","06e82247":"code","d24bbc77":"code","bb7ed72e":"code","70975ea4":"code","20ec2e7c":"code","8aaf0b8f":"code","b49bc57a":"code","acaf7307":"code","3d0ac548":"code","b3a9bf58":"code","0ed84442":"code","f821fde0":"code","c3ba2c46":"code","89b59c76":"markdown","a5d30788":"markdown","c617c8ed":"markdown","b0efe0c9":"markdown","6178aa84":"markdown","55a5faab":"markdown","a2e535fd":"markdown","45964b47":"markdown","18b8725d":"markdown"},"source":{"74900074":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","444733f2":"cd \/kaggle\/input\/netflix-prize-data\/","a048cf27":"import math\nimport re\nfrom scipy.sparse import csr_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#from surprise import Reader, Dataset, SVD \nsns.set_style(\"ticks\")\nfrom pandas import pivot_table, pivot\nfrom surprise import Reader\nfrom surprise.prediction_algorithms.matrix_factorization import SVD, SVDpp, NMF\nfrom surprise import Dataset\nfrom surprise.model_selection import cross_validate\nfrom scipy.linalg import svdvals","8bdd5b0f":"import surprise\nfrom surprise import accuracy\nfrom surprise.model_selection import train_test_split","ba767994":"%matplotlib inline","94b91fd4":"movie_titles = pd.read_csv('movie_titles.csv', encoding = \"ISO-8859-1\", header = None, names = ['Movie Id', 'Year', 'Title'])\nmovie_titles.sort_values(by=['Title'], axis=0, ascending=True, inplace=True)\n#movie_titles.set_index('Title', inplace = True)\ncombined_1 = pd.read_csv('combined_data_1.txt', header = None, names = ['Cust Id', 'Rating'], usecols = [0,1])\ncombined_2 = pd.read_csv('combined_data_2.txt', header = None, names = ['Cust Id', 'Rating'], usecols = [0,1])\ncombined_3 = pd.read_csv('combined_data_3.txt', header = None, names = ['Cust Id', 'Rating'], usecols = [0,1])\ncombined_4 = pd.read_csv('combined_data_4.txt', header = None, names = ['Cust Id', 'Rating'], usecols = [0,1])\nprobe = pd.read_csv('probe.txt', header = None, names = ['Cust Id'], usecols = [0])\nqualifying = pd.read_csv('qualifying.txt', header = None, names = ['Cust Id', 'Release Date'], usecols = [0,1])\n\n\n\n","538fee7f":"titles = movie_titles\ncmbnd1 = combined_1[:10000]\ncmbnd2 = combined_2[:10000]\ncmbnd3 = combined_3[:10000]\ncmbnd4 = combined_4[:10000]\nqual = qualifying[:10000]\ntest = probe[:10000]","85d02b1c":"opt_set = [cmbnd1, cmbnd2, cmbnd3, cmbnd4]\n","8af75811":"for i in opt_set:   \n    i['Movie Id'] = i['Cust Id'].str.extract('(\\d+:)')\n    i['Movie Id'].ffill(axis=0, inplace=True, limit=None, downcast=np.int64)\n    i['Movie Id'].replace('[:]', '', regex=True, inplace=True)\n    i.dropna(axis=0, inplace=True)\n    #i.reset_index(inplace=True)\n    i = i.astype(int)\n    i = i.drop_duplicates(subset= ['Cust Id'], keep='last')\n    i = i.drop_duplicates(subset= ['Movie Id'], keep='last')\n    #i = pd.pivot_table(i, index='Movie Id', columns= 'Cust Id', values='Rating', aggfunc=np.mean, fill_value=0.00001)\n    #i = np.asanyarray(i, dtype=np.int64)\n    #This seems like a hot ticket right here\n        #i = i.stack(list(range(i.columns.nlevels())))\n        #'int' object is not callable\n    print(i)\n    #print(i.show())","5a888c61":"cmbnd = cmbnd1.append(cmbnd2, ignore_index=False) \ncmbnd = cmbnd.append(cmbnd3, ignore_index=False)\ncmbnd = cmbnd.append(cmbnd4, ignore_index=False)","67b20344":"matrix = csr_matrix(cmbnd.astype(float))\n","8a4776c3":"movies_i_love = [6303, 2945, 14707, 17655, 1288, 9333, 7756, 8575]\n","7fee287c":"print('The Movie Id of one my favs is')\nkey = int(input())\n","c2a13a32":"movies_i_love.append(key)","0b4d9c58":"loved_movies = movie_titles.copy()\nloved_movies = loved_movies.loc[movie_titles['Movie Id'].isin(movies_i_love)]\nloved_movies['Rating'] = 5.0\nloved_movies.drop('Title', axis=1, inplace=True)\nloved_movies['Rating'].astype(float)\nloved_movies.set_index(loved_movies['Movie Id'], inplace=True)","6d0e57a5":"combined_1.plot.hist(cumulative=True)","4ae0b7d9":"combined_2.plot.hist(cumulative=True)\n","06e82247":"combined_3.plot.hist(cumulative=True)\n","d24bbc77":"combined_4.plot.hist(cumulative=True)\n","bb7ed72e":"combined_5.plot.hist(cumulative=True)\n","70975ea4":"from surprise.model_selection import KFold","20ec2e7c":"reader = Reader()\nsvd = SVD()","8aaf0b8f":"data = Dataset.load_from_df(cmbnd, reader)\n#data is my data_set now\ntrainset = data.build_full_trainset()\n","b49bc57a":"svd.fit(trainset)","acaf7307":"kf = KFold(n_splits=5)","3d0ac548":"for trainset, testset in kf.split(data):\n    svd.fit(trainset)\n    predictions = svd.test(testset)","b3a9bf58":"trainset, testset = train_test_split(matrix, test_size=.25)","0ed84442":"accuracy.rmse(predictions)\n","f821fde0":"cross_validate(svd, matrix, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n","c3ba2c46":"def recommend(movie_title, min_count):\n    print(\"For movie ({})\".format(movie_title))\n    print(\"- Top 10 movies recommended based on Pearsons'R correlation - \")\n    i = int(df_title.index[df_title['Name'] == movie_title][0])\n    target = df_p[i]\n    similar_to_target = df_p.corrwith(target)\n    corr_target = pd.DataFrame(similar_to_target, columns = ['PearsonR'])\n    corr_target.dropna(inplace = True)\n    corr_target = corr_target.sort_values('PearsonR', ascending = False)\n    corr_target.index = corr_target.index.map(int)\n    corr_target = corr_target.join(df_title).join(df_movie_summary)[['PearsonR', 'Name', 'count', 'mean']]\n    print(corr_target[corr_target['count']>min_count][:10].to_string(index=False))","89b59c76":"**Predict with Pearson's Correlation Coefficient**","a5d30788":"**Treat the Data**","c617c8ed":"Bayes enters here.  The Users may only enter movies if she rates them a '5'.  In the original, the team minimized the L2 Norm.  The used Bayes to update the Users' new recommendations.","b0efe0c9":"This is where I am getting stuck... I need to format predictions correctly...","6178aa84":"**Clearly State Priors**","55a5faab":"**Fator the Matrix with SVD**","a2e535fd":"My colleagues tell me that I have a deep understanding of the math of Data Science, Linear Algebra, Calculus and Probability Theory, **but** my code game is weak as I am still very new to coding.  This project took me considerably longer than it should have; and, I had to reverse engineer other people's code just the littlest bit to finish.  The reader will notice that my code is so badly malfunctioning as to be barely be working.","45964b47":"The previous works but I have to iron_it_out...","18b8725d":"**Visualize the Data**"}}