{"cell_type":{"e2d8557b":"code","979a0e32":"code","ec9990b9":"code","1f01d977":"code","eac43d93":"code","2606ec92":"code","3e6d221a":"code","74b237f2":"code","50916f59":"code","9be4e174":"code","c8d576c4":"code","4473b9af":"code","fcc37efe":"code","cd129513":"code","2a6c304a":"code","41ef82df":"code","3ffd7918":"code","fb76f4dd":"code","2901e7fb":"code","0b85b9be":"code","74efffac":"markdown"},"source":{"e2d8557b":"import pandas as pd\nimport numpy as np\nimport PIL \nimport pathlib\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.utils.np_utils import to_categorical\nfrom tensorflow.keras import layers\nfrom keras.models import Sequential\nfrom keras.callbacks import ReduceLROnPlateau\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","979a0e32":"\ndevice_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","ec9990b9":"path_dict = {\n    'train_data_dir_normal' : '..\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL',\n    'train_data_dir_pneumonia' : '..\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA',\n    'test_data_dir_normal' : '..\/input\/chest-xray-pneumonia\/chest_xray\/test\/NORMAL',\n    'test_data_dir_pneumonia' : '..\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA',\n    'data_val_dir_normal' : '..\/input\/chest-xray-pneumonia\/chest_xray\/val\/NORMAL',\n    'data_val_dir_pneumonia' : '..\/input\/chest-xray-pneumonia\/chest_xray\/val\/PNEUMONIA'\n}\n","1f01d977":"for key, value in path_dict.items():\n    path_dict[key] = pathlib.Path(value)","eac43d93":"X = []\ny = []\n\nfor key, value in path_dict.items():\n    images = list(path_dict[key].glob('*.jpeg'))\n    for img in images:\n        #reading the image and coverting it into pixels\n        image = cv2.imread(str(img))\n        #resizing the image to standard pixels\n        resized_img = cv2.resize(image, (224, 224))\n        X.append(resized_img)\n        if 'normal' in key:\n            y.append(0) # 0 - normal\n        else:\n            y.append(1) # 1 - pneumonia\n            \nX = np.array(X)\ny = np.array(y)","2606ec92":"X.shape, y.shape","3e6d221a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)","74b237f2":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","50916f59":"X_train_scaled = X_train \/ 255\nX_test_scaled = X_test \/ 255","9be4e174":"y_train = to_categorical(y_train)\ny_test = to_categorical(y_test)","c8d576c4":"model = Sequential([\n    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3)),\n    layers.MaxPool2D((2, 2)),\n    \n    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n    layers.MaxPool2D((2, 2)),\n    \n    layers.Flatten(),\n    layers.Dense(units = 128 , activation = 'relu'),\n    layers.Dense(units = 2 , activation = 'softmax'),\n])\n\nmodel.summary()\nmodel.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])","4473b9af":"model.fit(X_train_scaled, y_train, epochs=5)","fcc37efe":"model.evaluate(X_test_scaled, y_test)","cd129513":"y_pred = model.predict(X_test)\ny_pred[:5]","2a6c304a":"y_pred_scaled = []\ny_test_scaled = []\nfor x in y_pred:\n    if x[0] == 1:\n        y_pred_scaled.append(0)\n    else:\n        y_pred_scaled.append(1)\nfor x in y_test:\n    if x[0] == 1:\n        y_test_scaled.append(0)\n    else:\n        y_test_scaled.append(1)\ny_pred_scaled = np.array(y_pred_scaled)\ny_test_scaled = np.array(y_test_scaled)","41ef82df":"confusion_matrix = confusion_matrix(y_test_scaled, y_pred_scaled)\nsns.heatmap(confusion_matrix, annot=True, fmt='d')","3ffd7918":"import lime\nfrom lime import lime_image\nfrom skimage.segmentation import mark_boundaries","fb76f4dd":"def explain_image(image, index):\n    explainer = lime_image.LimeImageExplainer()\n    explanation = explainer.explain_instance(image.astype('double'), model.predict, top_labels=5, hide_color=0, num_samples=1000)\n    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n    plt.imshow(mark_boundaries(temp \/ 2 + 0.5, mask))\n    plt.title('Predicted - ' + str('Normal' if y_pred_scaled[index] == 0 else 'Pneumonia') + '\\n Ground Truth - ' + str('Normal' if y_test_scaled[index] == 0 else 'Pneumonia')\n             + ' \\n Green Regions -> Supporting the predicted label \\n Red Regions -> Against the predicted label')\n    plt.show()","2901e7fb":"for index, img in enumerate(X_test_scaled[:5]):\n    explain_image(img, index)","0b85b9be":"y_pred_scaled[0]","74efffac":"### Explainations"}}