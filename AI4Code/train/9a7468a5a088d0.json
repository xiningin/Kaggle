{"cell_type":{"6af5161a":"code","7fe501bf":"code","1b0990bb":"code","ee6d2301":"code","dba4b6e0":"code","b8a29396":"code","26931d42":"code","66383b54":"code","5e0d70c8":"code","7c032801":"code","95dd4570":"code","666d49b7":"code","169ace19":"code","2881f2f1":"code","ae8f0baf":"code","8773781f":"code","3f3b589e":"code","b027c568":"code","795e49c7":"code","a727bc05":"code","bf450bd7":"code","b046c8c6":"code","84ce5589":"code","e39aa94a":"code","7db22672":"code","cbb6b9a2":"code","036704a2":"code","2ac67085":"code","f06cc8a0":"code","27a6e1eb":"code","2950c5d8":"code","b02e2368":"code","43ec2fa1":"code","3b6bf10f":"code","4cdf582f":"code","03cc53b7":"code","17b1843e":"code","29ad5c09":"code","9b8eac67":"code","366cfe28":"code","03e34f55":"markdown","d99d7cc2":"markdown","d755981b":"markdown","9bef423e":"markdown","773bbd49":"markdown","3cbedec0":"markdown","e58d3a02":"markdown","b6d2441e":"markdown","0d6a5d3b":"markdown","bf81bfac":"markdown","e8f17534":"markdown","d4777f2f":"markdown","d4b643d5":"markdown","8302d9a3":"markdown","38dcf3ae":"markdown","f44222f2":"markdown","076fd048":"markdown","25fb0df9":"markdown","3e42124e":"markdown","75f2fffc":"markdown","0c6f77cf":"markdown","67b6d16c":"markdown","62a41d15":"markdown","8c642164":"markdown"},"source":{"6af5161a":"import numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nimport sklearn\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\n\n\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\n\n\n\nfrom skopt import BayesSearchCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import RepeatedKFold\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sqlalchemy import Table, Column, Float, Integer, BigInteger\n\n","7fe501bf":"df=pd.read_csv('..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')\ndf.head()","1b0990bb":"df.shape","ee6d2301":"df.isnull().sum()","dba4b6e0":"df.info()","b8a29396":"cat_features = ['sex','cp','fbs','restecg', 'exng', 'slp', 'caa','thall']\ncont_features = ['age','trtbps','chol','thalachh']","26931d42":"for feature in cat_features:\n    plt.figure(figsize=(7,4))\n    sns.set_theme(style=\"whitegrid\")\n    ax = sns.countplot(df[feature])\n    plt.xticks(rotation=90)\n    plt.show()","66383b54":"for feature in cat_features:\n    plt.figure(figsize=(7,4))\n    sns.set_theme(style=\"whitegrid\")\n    ax = sns.violinplot(x=feature,y='output',data=df)\n    plt.xticks(rotation=90)\n    plt.show()","5e0d70c8":"for feature in cont_features:\n    plt.figure(figsize=(7,4))\n    sns.set_theme(style=\"whitegrid\")\n    ax = sns.distplot(df[feature])\n    plt.xticks(rotation=90)\n    plt.show()","7c032801":"for feature in cont_features:\n    plt.figure(figsize=(7,4))\n    sns.set_theme(style=\"whitegrid\")\n    ax = sns.boxplot(df[feature])\n    plt.xticks(rotation=90)\n    plt.show()","95dd4570":"for feature in cont_features:\n    plt.figure(figsize=(7,4))\n    sns.set_theme(style=\"whitegrid\")\n    ax = sns.violinplot(feature,hue='output',data=df)\n    plt.xticks(rotation=90)\n    plt.show()","666d49b7":"plt.figure(figsize=(8,5))\nsns.set_theme(style=\"whitegrid\")\nax = sns.countplot(x='output', data=df)\nplt.xticks(rotation=90)\nplt.show()","169ace19":"plt.figure(figsize=(14,12))\nsns.heatmap(df.corr(), annot=True, cmap='coolwarm')\nplt.show()","2881f2f1":"y = df['output']\nX = df.drop('output', axis=1)","ae8f0baf":"X.shape, y.shape","8773781f":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=24, test_size=0.2)","3f3b589e":"print(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","b027c568":"sc = StandardScaler()\nX_train_sc = sc.fit_transform(X_train)","795e49c7":"pc = PCA(n_components=len(X.columns))\nX_train_pc=pc.fit_transform(X_train_sc)\nPC_df_train=pd.DataFrame(X_train_pc,columns=['PC_' +str(i) for i in range(1,pc.n_components_+1)])","a727bc05":"PC_df_train","bf450bd7":"plt.figure(figsize=(12,6))\nplt.plot(PC_df_train.std())\nplt.title('Scree Plot - PCA components')\nplt.xlabel('Principal Component')\nplt.ylabel('Standard deviation')\nplt.show()","b046c8c6":"print(PC_df_train.shape)\ny_train.shape","84ce5589":"classifier = LogisticRegression()\nclassifier.fit(pc.fit_transform(X_train_sc),y_train)\nX_test_sc = sc.transform(X_test)\nX_test_pc = pc.transform(X_test_sc)\ny_lr=classifier.predict(X_test_pc)","e39aa94a":"print('Confusion Matrix \\n',confusion_matrix(y_lr,y_test))\nprint()\nprint('Accuracy Score \\n', accuracy_score(y_lr,y_test))\nprint()\nprint('Classification Report \\n',classification_report(y_lr,y_test))\n","7db22672":"classifier = SVC()\nclassifier.fit(pc.fit_transform(X_train_sc),y_train)\nX_test_sc = sc.transform(X_test)\nX_test_pc = pc.transform(X_test_sc)\ny_svc=classifier.predict(X_test_pc)","cbb6b9a2":"print('Confusion Matrix \\n',confusion_matrix(y_svc,y_test))\nprint()\nprint('Accuracy Score \\n', accuracy_score(y_svc,y_test))\nprint()\nprint('Classification Report \\n',classification_report(y_svc,y_test))\n","036704a2":"classifier = RandomForestClassifier()\nclassifier.fit(pc.fit_transform(X_train_sc),y_train)\nX_test_sc = sc.transform(X_test)\nX_test_pc = pc.transform(X_test_sc)\ny_rfc=classifier.predict(X_test_pc)","2ac67085":"print('Confusion Matrix \\n',confusion_matrix(y_rfc,y_test))\nprint()\nprint('Accuracy Score \\n', accuracy_score(y_rfc,y_test))\nprint()\nprint('Classification Report \\n',classification_report(y_rfc,y_test))\n","f06cc8a0":"classifier = GradientBoostingClassifier()\nclassifier.fit(pc.fit_transform(X_train_sc),y_train)\nX_test_sc = sc.transform(X_test)\nX_test_pc = pc.transform(X_test_sc)\ny_gbc=classifier.predict(X_test_pc)","27a6e1eb":"print('Confusion Matrix \\n',confusion_matrix(y_gbc,y_test))\nprint()\nprint('Accuracy Score \\n', accuracy_score(y_gbc,y_test))\nprint()\nprint('Classification Report \\n',classification_report(y_gbc,y_test))\n","2950c5d8":"classifier = RandomForestClassifier(n_estimators=100,\n                                    min_samples_split=5,\n                                    min_samples_leaf=1,\n                                    max_depth=5)\nclassifier.fit(X_train_sc,y_train)\nX_test_sc = sc.transform(X_test)\ny_rfc=classifier.predict(X_test_sc)","b02e2368":"print('Confusion Matrix \\n',confusion_matrix(y_rfc,y_test))\nprint()\nprint('Accuracy Score \\n', accuracy_score(y_rfc,y_test))\nprint()\nprint('Classification Report \\n',classification_report(y_rfc,y_test))\n","43ec2fa1":"classifier = GaussianNB()\nclassifier.fit(pc.fit_transform(X_train_sc),y_train)\nX_test_sc = sc.transform(X_test)\nX_test_pc = pc.transform(X_test_sc)\ny_gb=classifier.predict(X_test_pc)","3b6bf10f":"print('Confusion Matrix \\n',confusion_matrix(y_gb,y_test))\nprint()\nprint('Accuracy Score \\n', accuracy_score(y_gb,y_test))\nprint()\nprint('Classification Report \\n',classification_report(y_gb,y_test))\n","4cdf582f":"Xgboost=XGBClassifier(random_state=28)\nparams = {'n_estimators': (100,300),\n                  'learning_rate': (0.01, 0.6),\n                  'subsample': (0.3, 0.9),\n                  'max_depth': (2,5),\n                  'colsample_bytree': (0.5, 0.9),\n                  'min_child_weight': (1,5)\n                 }","03cc53b7":"rf_classifier = RandomForestClassifier(random_state=34)\n\nParam_rf={'max_depth':(2,5),\n                         'min_samples_split':(5,10), \n                         'n_estimators':(100,300),\n                         'min_samples_leaf':(1,3)\n\n         }","17b1843e":"cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=1)\nsearch = RandomizedSearchCV(rf_classifier, Param_rf, cv=cv)\nsearch.fit(pc.fit_transform(X_train_sc), y_train)\nprint(search.best_params_)","29ad5c09":"\nclassifier = XGBClassifier(subsample= 0.9,\n                           n_estimators=300,\n                           min_child_weight=5,\n                           max_depth=2,\n                           learning_rate=0.01,\n                           colsample_bytree= 0.9)\nclassifier.fit(pc.fit_transform(X_train_sc),y_train)\nX_test_sc = sc.transform(X_test)\nX_test_pc = pc.transform(X_test_sc)\ny_xg=classifier.predict(X_test_pc)","9b8eac67":"print('Confusion Matrix \\n',confusion_matrix(y_xg,y_test))\nprint()\nprint('Accuracy Score \\n', accuracy_score(y_xg,y_test))\nprint()\nprint('Classification Report \\n',classification_report(y_xg,y_test))\n","366cfe28":"lr_df = pd.DataFrame(data=[f1_score(y_test,y_lr),accuracy_score(y_test, y_lr), recall_score(y_test, y_lr), precision_score(y_test, y_lr), roc_auc_score(y_test, y_lr)], \n             columns=['Logistic Regression'], index=[\"F1\",\"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"])\nrf_df = pd.DataFrame(data=[f1_score(y_test,y_rfc),accuracy_score(y_test, y_rfc), recall_score(y_test, y_rfc),precision_score(y_test, y_rfc), roc_auc_score(y_test, y_rfc)], \n             columns=['Random Forest Score'],index=[\"F1\",\"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"])\nnb_df = pd.DataFrame(data=[f1_score(y_test,y_gb),accuracy_score(y_test, y_gb), recall_score(y_test, y_gb), precision_score(y_test, y_gb), roc_auc_score(y_test, y_gb)], \n             columns=['Naive Bayes'], index=[\"F1\",\"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"])\n\nxg_df = pd.DataFrame(data=[f1_score(y_test,y_xg),accuracy_score(y_test, y_xg), recall_score(y_test, y_xg), precision_score(y_test, y_xg), roc_auc_score(y_test, y_xg)], \n             columns=['XG Boost'], index=[\"F1\",\"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"])\ngbc_df = pd.DataFrame(data=[f1_score(y_test,y_gbc),accuracy_score(y_test, y_gbc), recall_score(y_test, y_gbc), precision_score(y_test, y_gbc), roc_auc_score(y_test,y_gbc)], \n             columns=['Gradient Boosting'], index=[\"F1\",\"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"])\nsvc_df = pd.DataFrame(data=[f1_score(y_test,y_svc),accuracy_score(y_test, y_svc), recall_score(y_test, y_svc), precision_score(y_test, y_svc), roc_auc_score(y_test,y_svc)], \n             columns=['Gradient Boosting'], index=[\"F1\",\"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"])\n\n\ndf_models = round(pd.concat([lr_df,rf_df,nb_df,gbc_df,xg_df,svc_df], axis=1),3)\ncolors = [\"bisque\",\"ivory\",\"sandybrown\",\"steelblue\",\"lightsalmon\"]\ncolormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n\nbackground_color = \"white\"\n\nfig = plt.figure(figsize=(18,26)) # create figure\ngs = fig.add_gridspec(4, 2)\ngs.update(wspace=0.1, hspace=0.5)\nax0 = fig.add_subplot(gs[0, :])\n\nsns.heatmap(df_models.T, cmap=colormap,annot=True,fmt=\".1%\",vmin=0,vmax=0.95, linewidths=2.5,cbar=False,ax=ax0,annot_kws={\"fontsize\":16})\nfig.patch.set_facecolor(background_color) # figure background color\nax0.set_facecolor(background_color) \n\nax0.text(0,-0.5,'Model Comparison',fontsize=20,fontweight='bold',fontfamily='serif')\nplt.show()","03e34f55":"#### This will help us to know about data type i.e. categorical or numerical","d99d7cc2":"#### check feature distribution","d755981b":"### SVC Classifier","9bef423e":"### Check for null value\nWe can see from below output no feature in data have missing value","773bbd49":"# Conclusion\n### We can conclude that almost all machine learning model perform well. However, Naive Bias gives the best accuracy 0f 90.2%","3cbedec0":"## Bivariate analysis","e58d3a02":"#### continuous feature distribution","b6d2441e":"## Model building","0d6a5d3b":"### By count plot we can check dependent variable distribution\nFrom the below plot we can clearly see the distribution is balanced","bf81bfac":"### Naive Bayes","e8f17534":"### With the help of corelation matrix we  see that how the features are related to each other","d4777f2f":"## Standardization","d4b643d5":"#### Gradient Boosting Classifier","8302d9a3":"## Splitting the data into train and test","38dcf3ae":"### XGboost Classifier","f44222f2":"#### To select number of principal components elbow method is used\n\nWe can clearly, proper elbow is not formed in the below graph, so we can select all the components","076fd048":"#### categorical feature distribution","25fb0df9":"### RandomForest Classifier","3e42124e":"## Univariate Analysis","75f2fffc":"### Applying PCA","0c6f77cf":"#### To check the feature in normally distributed for continuous feature","67b6d16c":"## Scree Plot - PCA Analysis\nIn multivariate statistics, a scree plot is a line plot of the eigenvalues of factors or principal components in an analysis. The scree plot is used to determine the number of factors to retain in an exploratory factor analysis (FA) or principal components to keep in a principal component analysis (PCA)","62a41d15":"### Random Forest Classifier","8c642164":"from the above boxplot we can say that some outlier is there in trtbps and chol"}}