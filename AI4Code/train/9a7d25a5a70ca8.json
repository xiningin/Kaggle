{"cell_type":{"3ae6cb52":"code","804f47b9":"code","d4a6ad39":"code","b3216dca":"code","5f6e1075":"code","595c1ef8":"code","7fe14a84":"code","a4ad309b":"code","f3124915":"code","7327537e":"code","c925106a":"code","27fa86eb":"code","ff5de97b":"code","7d988d6b":"code","8d5ed1d1":"code","1218c3b2":"code","2dea733d":"code","e8488a58":"code","be82f68c":"code","47f25f13":"code","288f2600":"code","54036453":"code","3614641b":"code","68c0e87e":"code","030bcd7f":"code","e88b5f06":"code","0ca6d18c":"code","10ac6133":"code","91b2da9e":"code","84e84cee":"code","c4b5f997":"code","c2c9c0ce":"code","7e031441":"code","6954f2e4":"code","459129e1":"code","d068d462":"code","b940cc78":"code","3d1f33b6":"code","fb7ffd23":"markdown","8c97f9d6":"markdown","c7ef61c1":"markdown","85e88f5b":"markdown","440a3fbf":"markdown"},"source":{"3ae6cb52":"import numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport os\nfrom glob import glob\nfrom tqdm import tqdm\nfrom torchvision import transforms\nimport torch\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport time\nimport sys\nfrom operator import add\n%matplotlib inline","804f47b9":"path = '..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/'\n# image_path_test = '..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/test\/' ","d4a6ad39":"images = os.listdir(path+'CXR_png\/')\nmask = os.listdir(path+'masks\/')\nmask = [fName.split(\".png\")[0] for fName in mask]\nimage_file_name = [fName.split(\"_mask\")[0] for fName in mask]\n\ncheck = [i for i in mask if \"mask\" in i]","b3216dca":"testing_files = set(os.listdir(path+'CXR_png\/')) & set(os.listdir(path+'masks\/'))\ntraining_files = check","5f6e1075":"class SegmentationDS(Dataset):\n    \"\"\" create dataset by using image path and their labels \"\"\"\n    def __init__ (self, path, files, flag = \"MONT\", transform = (None, None)):\n        self.path = path\n        self.files = files\n        self.flag = flag\n        self.transform = transform\n\n        \n    def __len__(self):\n        return len (self.files)\n\n    def __getitem__(self, index):\n        \n        f = sorted(list(self.files))\n        if self.flag == \"MONT\":    \n            image = Image.open(os.path.join(self.path, \"CXR_png\", f[index])).convert('L')\n            mask = Image.open(os.path.join(self.path, \"masks\", f[index])).convert('L')\n\n        elif self.flag == \"SHEN\":\n            image = Image.open(os.path.join(self.path, \"CXR_png\", f[index].split(\"_mask\")[0] + \".png\")).convert('L')\n            mask = Image.open(os.path.join(self.path, \"masks\", f[index] + \".png\")).convert('L')\n\n\n        if self.transform != (None, None):\n            image = self.transform[0](image)\n            mask = self.transform[1](mask)\n            \n        return image, mask\n","595c1ef8":"mean0_1, std0_1 = [0.0, 0.0, 0.0], [1.0, 1.0, 1.0]\n\nmean_imgnet, std_imgnet = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n\nmean1_1gray, std1_1gray = [0.5, ], [0.5, ]\n\ndim = 256","7fe14a84":"image_tfms = transforms.Compose([\n    transforms.Resize((dim, dim)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean = mean1_1gray, \n                         std = std1_1gray)\n])\n\nmask_tfms = transforms.Compose([\n    transforms.Resize((dim, dim)),\n    transforms.ToTensor()\n])","a4ad309b":"Mont_ds = SegmentationDS(path, testing_files, flag = \"MONT\", transform = (image_tfms, mask_tfms))\nShen_ds = SegmentationDS(path, training_files, flag = \"SHEN\", transform = (image_tfms, mask_tfms))","f3124915":"len(Mont_ds), len(Shen_ds)","7327537e":"def imshow (img, mean_set, std_set):\n    \"\"\" visualize torch tensor image \"\"\"\n    \n    if img.shape[0] == 3:\n        img = img.numpy ().transpose (1, 2, 0)\n        mean = mean_set\n        std = std_set\n        img = img * std + mean\n        img = np.clip (img, 0, 1)\n        plt.figure (figsize = (5, 5))\n        plt.imshow (img)\n        \n    elif img.shape[0] == 1:\n        img = img.numpy ().transpose (1, 2, 0)\n        mean = mean_set\n        std = std_set\n        img = img * std + mean\n        img = np.clip (img, 0, 1)\n    \n        plt.figure (figsize = (5, 5))\n        plt.imshow (img,cmap='gray')","c925106a":"idx = np.random.choice (len (Mont_ds))\nimg, lbl = Mont_ds [idx]\nprint (img.shape)\nprint (lbl.shape)\nprint(img.min(), img.max())\nprint(lbl.min(), lbl.max())\nimshow(img, mean1_1gray, std1_1gray)\nimshow(lbl, mean1_1gray, std1_1gray)","27fa86eb":"train_ds = torch.utils.data.ConcatDataset([Mont_ds, Shen_ds])\n\nlen(train_ds)","ff5de97b":"train_size = int(0.80 * len(train_ds))\nvalid_size = len(train_ds) - train_size\ntrain_ds, valid_ds = torch.utils.data.random_split(train_ds, [train_size, valid_size])\n\nprint(len(train_ds), len(valid_ds))","7d988d6b":"train_dl = DataLoader (train_ds, batch_size = 8, shuffle = True)\nvalid_dl = DataLoader (valid_ds, batch_size = 8, shuffle = True)","8d5ed1d1":"import torch.nn as nn\nimport torch.nn.functional as F","1218c3b2":"class DiceLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(DiceLoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n\n        #comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = torch.sigmoid(inputs)\n\n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n\n        intersection = (inputs * targets).sum()\n        dice = (2.*intersection + smooth)\/(inputs.sum() + targets.sum() + smooth)\n\n        return 1 - dice\n\nclass DiceBCELoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(DiceBCELoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n\n        #comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = torch.sigmoid(inputs)\n\n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n\n        intersection = (inputs * targets).sum()\n        dice_loss = 1 - (2.*intersection + smooth)\/(inputs.sum() + targets.sum() + smooth)\n        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n        Dice_BCE = BCE + dice_loss\n\n        return Dice_BCE","2dea733d":"from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score","e8488a58":"def calculate_metrics(y_pred, y_true):\n    \"\"\" Ground truth \"\"\"\n    y_true = y_true.cpu().numpy()\n    y_true = y_true > 0.5\n    y_true = y_true.astype(np.uint8)\n    y_true = y_true.reshape(-1)\n\n    \"\"\" Prediction \"\"\"\n    y_pred = y_pred.cpu().detach().numpy()\n    y_pred = y_pred > 0.5\n    y_pred = y_pred.astype(np.uint8)\n    y_pred = y_pred.reshape(-1)\n\n    score_jaccard = jaccard_score(y_true, y_pred)\n#     score_f1 = f1_score(y_true, y_pred)\n#     score_recall = recall_score(y_true, y_pred)\n#     score_precision = precision_score(y_true, y_pred)\n    score_acc = accuracy_score(y_true, y_pred)\n\n    return [score_jaccard, score_acc]","be82f68c":"try:\n    from torchsummary import summary\nexcept ImportError:\n    !pip3 -q install torchsummary\n    from torchsummary import summary","47f25f13":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","288f2600":"class conv_block(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n\n        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_c)\n\n        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_c)\n\n        self.relu = nn.ReLU()\n\n    def forward(self, inputs):\n        x = self.conv1(inputs)\n        x = self.bn1(x)\n        x = self.relu(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n\n        return x\n\nclass encoder_block(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n\n        self.conv = conv_block(in_c, out_c)\n        self.pool = nn.MaxPool2d((2, 2))\n\n    def forward(self, inputs):\n        x = self.conv(inputs)\n        p = self.pool(x)\n\n        return x, p\n\nclass decoder_block(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n\n        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n        self.conv = conv_block(out_c+out_c, out_c)\n\n    def forward(self, inputs, skip):\n        x = self.up(inputs)\n        x = torch.cat([x, skip], axis=1)\n        x = self.conv(x)\n        return x\n\nclass Unet_Builder(nn.Module):\n    def __init__(self, input_channel:int = 3, output_channel:int = 1):\n        super().__init__()\n\n        \"\"\" Encoder \"\"\"\n        self.e1 = encoder_block(input_channel, 64)\n        self.e2 = encoder_block(64, 128)\n        self.e3 = encoder_block(128, 256)\n        self.e4 = encoder_block(256, 512)\n\n        \"\"\" Bottleneck \"\"\"\n        self.b = conv_block(512, 1024)\n\n        \"\"\" Decoder \"\"\"\n        self.d1 = decoder_block(1024, 512)\n        self.d2 = decoder_block(512, 256)\n        self.d3 = decoder_block(256, 128)\n        self.d4 = decoder_block(128, 64)\n\n        \"\"\" Classifier \"\"\"\n        self.outputs = nn.Conv2d(64, output_channel, kernel_size=1, padding=0)\n\n    def forward(self, inputs):\n        \"\"\" Encoder \"\"\"\n        s1, p1 = self.e1(inputs)\n        s2, p2 = self.e2(p1)\n        s3, p3 = self.e3(p2)\n        s4, p4 = self.e4(p3)\n\n        \"\"\" Bottleneck \"\"\"\n        b = self.b(p4)\n\n        \"\"\" Decoder \"\"\"\n        d1 = self.d1(b, s4)\n        d2 = self.d2(d1, s3)\n        d3 = self.d3(d2, s2)\n        d4 = self.d4(d3, s1)\n\n        outputs = self.outputs(d4)\n\n        return outputs\n\n    \n    \nmodel = Unet_Builder(input_channel=1, output_channel=1)\n# model.eval()","54036453":"summary(model, input_size=(1, dim, dim), device = 'cpu')     ## dim = 256","3614641b":"def save_checkpoint (state, filename):\n    \"\"\" saving model's weights \"\"\"\n    print ('=> saving checkpoint')\n    torch.save (state, filename)\n","68c0e87e":"def train(model, loader, optimizer, loss_fn, metric_fn, device):\n    epoch_loss = 0.0\n    metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0]\n    steps = len(loader)\n    model.train()\n    for i, (x, y) in enumerate (loader):\n        x = x.to(device, dtype=torch.float32)\n        y = y.to(device, dtype=torch.float32)\n\n        optimizer.zero_grad()\n        y_pred = model(x)\n        loss = loss_fn(y_pred, y)\n        loss.backward()\n        \n        score = metric_fn(y_pred, y)\n        metrics_score = list(map(add, metrics_score, score))\n        \n        optimizer.step()\n        epoch_loss += loss.item()\n        \n        sys.stdout.flush()\n        sys.stdout.write('\\r Step: [%2d\/%2d], loss: %.4f - acc: %.4f' % (i, steps, loss.item(), score[1]))\n    sys.stdout.write('\\r')\n\n    epoch_loss = epoch_loss\/len(loader)\n    \n    epoch_jaccard = metrics_score[0]\/len(loader)\n#     epoch_f1 = metrics_score[1]\/len(loader)\n    epoch_acc = metrics_score[1]\/len(loader)\n    \n    return epoch_loss, epoch_jaccard, epoch_acc","030bcd7f":"def evaluate(model, loader, loss_fn, metric_fn, device):\n    epoch_loss = 0.0\n    metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0]\n\n    model.eval()\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device, dtype=torch.float32)\n            y = y.to(device, dtype=torch.float32)\n\n            y_pred = model(x)\n            loss = loss_fn(y_pred, y)\n            \n            score = metric_fn(y_pred, y)\n            metrics_score = list(map(add, metrics_score, score))\n            \n            epoch_loss += loss.item()\n\n        epoch_loss = epoch_loss \/ len(loader)\n        \n        epoch_jaccard = metrics_score[0] \/ len(loader)\n#         epoch_f1 = metrics_score[1] \/ len(loader)\n        epoch_acc = metrics_score[1] \/ len(loader)\n    \n    return epoch_loss, epoch_jaccard, epoch_acc","e88b5f06":"checkpoint_path = 'unet.pth'\nepochs = 10\nbatch_size = 8\nlr = 1e-4","0ca6d18c":"model = model.to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\nloss_fn = DiceBCELoss()\n# metric_fn = calculate_metrics()\n\n\"\"\" Training the model \"\"\"\nbest_valid_loss = float(\"inf\")","10ac6133":"torch.cuda.empty_cache()","91b2da9e":"def epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time \/ 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","84e84cee":"def fit (model, train_dl, valid_dl, optimizer, epochs, loss_fn, metric_fn, checkpoint_path):\n    \"\"\" fiting model to dataloaders, saving best weights and showing results \"\"\"\n    losses, val_losses, accs, val_accs = [], [], [], []\n    jaccards, val_jaccards = [], []\n    best_val_loss = float(\"inf\")\n    \n    since = time.time()\n    for epoch in range (epochs):\n        ts = time.time()\n        \n        loss, jaccard, acc = train(model, train_dl, optimizer, loss_fn, metric_fn, device)\n        val_loss, val_jaccard, val_acc = evaluate(model, valid_dl, loss_fn, metric_fn, device)\n\n        \n        losses.append(loss)\n        accs.append(acc)\n        jaccards.append(jaccard)\n        \n        val_losses.append(val_loss)\n        val_accs.append(val_acc)\n        val_jaccards.append(val_jaccard)\n        \n        te = time.time()\n        \n        if val_loss < best_val_loss:\n            data_str = f\"===> Valid loss improved from {best_val_loss:2.4f} to {val_loss:2.4f}. Saving checkpoint: {checkpoint_path}\"\n            print(data_str)\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), checkpoint_path)\n\n        epoch_mins, epoch_secs = epoch_time(ts, te)\n        \n        print ('Epoch [{}\/{}], loss: {:.4f} - jaccard: {:.4f} - acc: {:.4f} - val_loss: {:.4f} - val_jaccard: {:.4f} - val_acc: {:.4f}'.format (epoch + 1, epochs, loss, jaccard, acc, val_loss, val_jaccard, val_acc))\n        print(f'Time: {epoch_mins}m {epoch_secs}s')\n        \n    period = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(period \/\/ 60, period % 60))\n\n    return dict(loss = losses, val_loss = val_losses, acc = accs, val_acc = val_accs, jaccard = jaccards, val_jaccard = val_jaccards)\n","c4b5f997":"res = fit(model, train_dl, valid_dl, optimizer, epochs, loss_fn, calculate_metrics, checkpoint_path)","c2c9c0ce":"def plot_acc_loss (loss, val_loss, acc, val_acc):\n    \"\"\" plot training and validation loss and accuracy \"\"\"\n    plt.figure (figsize = (12, 4))\n    plt.subplot (1, 2, 1)\n    plt.plot (range (len (loss)), loss, 'b-', label = 'Training')\n    plt.plot (range (len (loss)), val_loss, 'bo-', label = 'Validation')\n    plt.xlabel ('Epochs')\n    plt.ylabel ('Loss')\n    plt.title ('Loss')\n    plt.legend ()\n\n    plt.subplot (1, 2, 2)\n    plt.plot (range (len (acc)), acc, 'b-', label = 'Training')\n    plt.plot (range (len (acc)), val_acc, 'bo-', label = 'Validation')\n    plt.xlabel ('Epochs')\n    plt.ylabel ('accuracy')\n    plt.title ('Accuracy')\n    plt.legend ()\n\n    plt.show ()","7e031441":"loss, val_loss = res['loss'], res['val_loss']\nacc, val_acc = res['acc'], res['val_acc']\nplot_acc_loss (loss, val_loss, acc, val_acc)","6954f2e4":"with torch.no_grad():\n    for x, y in valid_dl:\n        x = x.to(device, dtype=torch.float32)\n        y = y.to(device, dtype=torch.float32)\n\n        y_pred = model(x)\n        break","459129e1":"pred = y_pred.cpu().numpy()\nynum = y.cpu().numpy()\n\npred.shape, ynum.shape","d068d462":"pred = pred.reshape(len(pred), dim, dim)\nynum = ynum.reshape(len(ynum), dim, dim)\n\npred = pred > 0.5\npred = np.array(pred, dtype=np.uint8)\n\nynum = ynum > 0.5\nynum = np.array(ynum, dtype=np.uint8)\n\npred.shape, ynum.shape","b940cc78":"plt.imshow(pred[0], cmap='gray')","3d1f33b6":"plt.imshow(ynum[0], cmap='gray')","fb7ffd23":"# test","8c97f9d6":"# Loss Function","c7ef61c1":"# Data","85e88f5b":"# Metrics","440a3fbf":"# Model"}}