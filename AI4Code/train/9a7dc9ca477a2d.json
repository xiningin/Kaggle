{"cell_type":{"f55fabf0":"code","ca1734c3":"code","c4e7680f":"code","3239138e":"code","babbf7e3":"code","8c7fceff":"code","ae123d20":"code","5ca86f27":"code","b706dc29":"code","fa9f0a5d":"code","00112a24":"code","89c4b468":"code","2eaaf579":"code","cdffa911":"code","3419d581":"code","b1a22d30":"code","58a8ed18":"code","b072f439":"code","19135173":"code","2791caeb":"code","a837fbca":"code","edcc2d26":"code","66305740":"code","9d5364e1":"code","7ff9d1fe":"code","4e429cec":"code","2f96d950":"code","f43eeeb4":"code","d5200cb3":"code","7520a5e9":"code","29f5789b":"code","8fc14db9":"code","e7f8908b":"code","203ec893":"code","794dbb3c":"code","2a1596f2":"code","5f9adc64":"code","50e40fd7":"code","f5e80edf":"code","33f4f0c3":"code","aea07e9a":"code","d266a818":"code","65fcfe7c":"code","4d031270":"code","fa9772b5":"code","829bf686":"code","dc947c2e":"code","7cc260a7":"code","68b6290b":"code","c2a56bc7":"code","b52634bc":"code","0857ac21":"code","ad0eb8f0":"markdown","3cb2a970":"markdown","31d6fd50":"markdown","595463e8":"markdown","3775ba3c":"markdown","96cafe89":"markdown","51f1aeca":"markdown","c9adb9c9":"markdown","8e5a649a":"markdown","868c9a87":"markdown","2be93141":"markdown","b2cc0639":"markdown","5bafaf2a":"markdown","0982eabf":"markdown","9e05f04b":"markdown","ec563fe7":"markdown","cf9dc4dd":"markdown","9c7ad381":"markdown","6f9f918f":"markdown","6ac2b19e":"markdown","9d85cc80":"markdown"},"source":{"f55fabf0":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.base import clone\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import * \nfrom sklearn.metrics import *\nfrom sklearn.preprocessing import *\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import *","ca1734c3":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv', low_memory=False)\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv', low_memory=False)","c4e7680f":"# Print classification metrics\ndef classification_metrics(y_true,y_pred):\n    \"\"\"A function to print Evaluation metrics\"\"\"\n    d = {\n        'Accuracy': accuracy_score(y_true, y_pred),\n        'Precision': precision_score(y_true, y_pred),\n        'Recall': recall_score(y_true, y_pred)\n            #'F1': f1_score(y_true, y_pred),\n            #'AUC': roc_auc_score(y_true, y_pred),\n            #'Log Loss': log_loss(y_true, y_pred)\n             }\n    d = {k: np.round(v, 4) for k, v in d.items()}\n    print(d)\n    \n# Print sklearn cross validation metrics\ndef cross_validation(clf, X, y, scoring='accuracy', cv=10):\n    \"\"\"\"A function to print Cross Validation metrics.\"\"\"\n    \n    scores = cross_val_score(clf, X, y, scoring=scoring, cv=cv)\n    return {\n        'Scores': scores,\n        'Mean': scores.mean(),\n        'Standard Deviation': scores.std()\n    }\n\n# Print custom cross validation metrics\ndef custom_cross_val(clf, X_train, y_train, features=None):\n    skfolds = StratifiedKFold(n_splits=5)\n    \n    for n_fold, (train_idx, test_idx) in enumerate(skfolds.split(X_train, y_train)):\n        print('Evaluating fold number: {}'.format(n_fold) )\n        clone_clf = clone(clf)\n        X_train_folds = X_train[features].iloc[train_idx]\n        y_train_folds = y_train.iloc[train_idx]\n        X_test_folds = X_train[features].iloc[test_idx]\n        y_test_folds = y_train.iloc[test_idx]\n        \n        clone_clf.fit(X_train_folds, y_train_folds)\n        y_pred = clone_clf.predict(X_test_folds)\n        classification_metrics(y_test_folds, y_pred)\n        ","3239138e":"train.info()","babbf7e3":"train.isnull().sum()","8c7fceff":"test.isnull().sum()","ae123d20":"train.Ticket.nunique()","5ca86f27":"pd.options.display.max_rows = 999\ntrain.Ticket","b706dc29":"train.head()","fa9f0a5d":"train['LastName'] = train['Name'].str.split(r\",\", expand=True, n=1).get(0)\ntest['LastName'] = test['Name'].str.split(r\",\", expand=True, n=1).get(0)\ntrain['Title'] = train.Name.str.extract(r',\\s*([^\\.]*)\\s*\\.', expand=False)\ntest['Title'] = test.Name.str.extract(r',\\s*([^\\.]*)\\s*\\.', expand=False)","00112a24":"def title_transform(x):\n    if x == 'Mr':\n        return x\n    elif x in ['Mrs', 'Miss', 'Mme','Ms','Lady', 'Mlle', 'the Countess']:\n        return 'Ms'\n    elif x == 'Master':\n        return x\n    else:\n        return 'Rare'","89c4b468":"train['Title'] = train.Title.apply(title_transform)\ntest['Title'] = test.Title.apply(title_transform)","2eaaf579":"train.head()","cdffa911":"train['has_cabin'] = train.Cabin.notna().astype(int)\ntest['has_cabin'] = test.Cabin.notna().astype(int)","3419d581":"train.head()","b1a22d30":"train['family_size'] = train['SibSp']+ train['Parch'] \ntest['family_size'] = test['SibSp']+ test['Parch'] ","58a8ed18":"train['is_alone'] = train['family_size'].eq(0).astype(int)\ntest['is_alone'] = test['family_size'].eq(0).astype(int)","b072f439":"features_to_encode = ['Sex', 'Title', 'Embarked']","19135173":"train[features_to_encode] = train[features_to_encode].fillna('missing')","2791caeb":"test[features_to_encode] = test[features_to_encode].fillna('missing')","a837fbca":"encoded_features = ['sex_enc', 'title_enc', 'embarked_enc']","edcc2d26":"train[encoded_features] = pd.DataFrame([[np.nan, np.nan, np.nan]], index=train.index)\ntest[encoded_features] = pd.DataFrame([[np.nan, np.nan, np.nan]], index=test.index)","66305740":"ordinal_encoder = OrdinalEncoder()\ntrain[encoded_features] = ordinal_encoder.fit_transform(train[features_to_encode])\ntest[encoded_features] = ordinal_encoder.transform(test[features_to_encode])","9d5364e1":"ordinal_encoder.categories_","7ff9d1fe":"y = train['Survived']\nX = train.drop(columns=['PassengerId','Survived'])","4e429cec":"# Split the data \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)","2f96d950":"X_train.head()","f43eeeb4":"# Fare Imputer\nfare_imputer = SimpleImputer(strategy='median', copy=True, verbose=0)\nX_train['imputed_fare'] = fare_imputer.fit_transform(X_train.loc[:, ['Fare']])\nX_test['imputed_fare'] = fare_imputer.transform(X_test.loc[:, ['Fare']])\ntest['imputed_fare'] = fare_imputer.transform(test.loc[:, ['Fare']])","d5200cb3":"# Embarked Imputer\n\nemb_imputer = SimpleImputer(strategy='most_frequent', missing_values=3.0, copy=True)\nX_train['imp_embarked'] = emb_imputer.fit_transform(X_train.loc[:, ['embarked_enc']])\nX_test['imp_embarked'] = emb_imputer.transform(X_test.loc[:, ['embarked_enc']])\ntest['imp_embarked'] = emb_imputer.transform(test.loc[:, ['embarked_enc']])","7520a5e9":"# Age median Imputer\nage_imputer = SimpleImputer(strategy='median')\nX_train['imp_med_age'] = age_imputer.fit_transform(X_train.loc[:, ['Age']])\nX_test['imp_med_age'] = age_imputer.transform(X_test.loc[:, ['Age']])\ntest['imp_med_age'] = age_imputer.transform(test.loc[:, ['Age']])","29f5789b":"test.head()","8fc14db9":"# Lets look at the features we have in the data. \nX_train.info()","e7f8908b":"features = ['Pclass','sex_enc','SibSp','Parch']","203ec893":"clf = RandomForestClassifier(n_jobs=-1)\nclf.fit(X_train[features] ,y_train)","794dbb3c":"y_train_pred = clf.predict(X_train[features])\nclassification_metrics(y_train,y_train_pred)","2a1596f2":"y_test_pred = clf.predict(X_test[features])\nclassification_metrics(y_test,y_test_pred)","5f9adc64":"cross_val_score(clf, X_train[features], y_train, cv=5)","50e40fd7":"X_train.info()","f5e80edf":"features = ['Pclass','SibSp','Parch', 'has_cabin', 'family_size', 'is_alone','sex_enc', 'title_enc', 'imputed_fare', 'imp_embarked','imp_med_age']","33f4f0c3":"clf = RandomForestClassifier(n_jobs=-1)\nclf.fit(X_train[features] ,y_train)","aea07e9a":"y_train_pred = clf.predict(X_train[features])\nclassification_metrics(y_train,y_train_pred)","d266a818":"y_test_pred = clf.predict(X_test[features])\nclassification_metrics(y_test,y_test_pred)","65fcfe7c":"custom_cross_val(clf, X_train, y_train, features=features)","4d031270":"cross_val_score(clf, X_train[features], y_train, cv=5)","fa9772b5":"clf_1 = RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_split=5, min_samples_leaf=3, max_features='sqrt' ,n_jobs=-1)\nclf_1.fit(X_train[features] ,y_train)","829bf686":"y_train_pred = clf_1.predict(X_train[features])\nclassification_metrics(y_train,y_train_pred)","dc947c2e":"y_test_pred = clf_1.predict(X_test[features])\nclassification_metrics(y_test,y_test_pred)","7cc260a7":"cross_val_score(clf_1, X_train[features], y_train, cv=5)","68b6290b":"custom_cross_val(clf_1, X_train, y_train, features=features)","c2a56bc7":"# Feature Importances\nfeature_scores = pd.Series(clf_1.feature_importances_, index=X_train[features].columns.to_list()).sort_values(ascending=False)\n\n# Creating a seaborn bar plot\n\nf, ax = plt.subplots(figsize=(20, 10))\nax = sns.barplot(x=feature_scores, y=feature_scores.index)\nax.set_title(\"Visualize feature scores of the features\")\nax.set_yticklabels(feature_scores.index)\nax.set_xlabel(\"Feature importance score\")\nax.set_ylabel(\"Features\")\nplt.show()","b52634bc":"y_eval = clf_1.predict(test[features])","0857ac21":"test['Survived'] = y_eval\ndf_sub = test.loc[:,['PassengerId', 'Survived']]\ndf_sub.to_csv('2.csv', mode = 'w', index=False)","ad0eb8f0":"### Preprocessing of Cabin feature","3cb2a970":"# Data Preprocessing","31d6fd50":"List of features to be used in the model","595463e8":"### Iteration 1: 4 features","3775ba3c":"# Inspect the Data","96cafe89":"### Iteration 2: All Features","51f1aeca":"# Model Building","c9adb9c9":"### Adding a feature to identify if the passenger was travelling alone.","8e5a649a":"### Adding a feature to determine the family size.","868c9a87":"# Useful Functions","2be93141":"We will write a custom transformer for performing data cleaning and feature engineering tasks.","b2cc0639":"# Import the Libraries","5bafaf2a":"* Train - Age, Cabin, Embarked have missing values.\n* Test - Age, Cabin, Fare have missing values.\n* We need to create imputers for Age, Embarked and Fare.\n* For Cabin, we will create two classed, one that have value for cabin and other where cabin is missing.\n* Name, Sex, Ticket, Cabin, Embarked are nominal features & PClass is ordinal feature.\n* Age, Fare are numeric features & SibSp, Parch are discrete features","0982eabf":"# Encoding categorical Features","9e05f04b":"# Our model is clearly overfitting as we can see in gap between train test accuracy","ec563fe7":"# Impute the missing values","cf9dc4dd":"# Let's examine which features are important","9c7ad381":"# Split the data into train and test sets","6f9f918f":"### Preprocess the Name feature to derive meaningful features.","6ac2b19e":"# Submission","9d85cc80":"# Read the Data"}}