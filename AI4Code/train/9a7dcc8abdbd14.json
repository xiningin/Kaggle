{"cell_type":{"315910a8":"code","70bdec3a":"code","252ba118":"code","c4417749":"code","8d5eabf7":"code","7fcb42a2":"code","1b07d2b1":"code","4c49e7d2":"code","34dd4d74":"code","bde568aa":"markdown"},"source":{"315910a8":"!pip install -q tensorflow_datasets==4.4.0\nimport tensorflow as tf\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport tensorflow_datasets as tfds\nfrom tensorflow.keras.layers.experimental.preprocessing import (\n    RandomFlip,RandomZoom,RandomRotation,Rescaling\n)\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (\n    Input,Activation,Dropout,Dense,Flatten,BatchNormalization,\n    MaxPooling2D,AveragePooling2D,GlobalAveragePooling2D,Conv2D,\n)\nfrom tensorflow.keras.regularizers import l2\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt\n%matplotlib inline","70bdec3a":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","252ba118":"AUTO = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 8\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('mass-final-end2end')\n(train,val), ds_info = tfds.load(\n    'cbisddsm\/original-mass:3.0.0',\n    split=['train', 'validation'],\n    with_info=True,\n    data_dir=GCS_DS_PATH,\n)\nGCS_DS_PATH_ = KaggleDatasets().get_gcs_path('mass-end2end-final')\n(test), ds_info = tfds.load(\n    'cbisddsm\/original-mass:3.0.0',\n    split=['test'],\n    with_info=True,\n    data_dir=GCS_DS_PATH_,\n)\ndata_augmentation = tf.keras.Sequential([\n        #M\u1ed9t l\u1edbp ti\u1ec1n x\u1eed l\u00fd l\u1eadt ng\u1eabu nhi\u00ean h\u00ecnh \u1ea3nh trong qu\u00e1 tr\u00ecnh \u0111\u00e0o t\u1ea1o.\n        RandomFlip('horizontal'),\n        RandomFlip('vertical'),\n        #M\u1ed9t l\u1edbp ti\u1ec1n x\u1eed l\u00fd gi\u00fap ph\u00f3ng to h\u00ecnh \u1ea3nh m\u1ed9t c\u00e1ch ng\u1eabu nhi\u00ean trong qu\u00e1 tr\u00ecnh \u0111\u00e0o t\u1ea1o.\n        RandomZoom(0.2),\n        RandomRotation(0.25),\n    ])\ndef get_img(sample,train=None):\n    #L\u1ea5y label v\u00e0 chuy\u1ec3n th\u00e0nh one_hot\n    label = tf.one_hot(sample['abnormalities']['pathology'][0],2)\n    #L\u1ea5y image\n    image = sample['image']\n    image = tf.image.resize(image,(1152,896))\n    image = tf.image.grayscale_to_rgb(image)\n    return image,label\n\n#l\u1ea5y t\u1eadp train c\u00f3 augment\nds = train.map(get_img, num_parallel_calls=AUTO)\nds = ds.batch(BATCH_SIZE,drop_remainder=True)\nds = ds.map(lambda x, y: (data_augmentation(x, training=True), y),num_parallel_calls=AUTO) \nds = ds.prefetch(AUTO)\n\n\nds_val = val.map(get_img, num_parallel_calls=AUTO)\nds_val = ds_val.batch(BATCH_SIZE,drop_remainder=True)\nds_val = ds_val.prefetch(AUTO)\n#l\u1ea5y t\u1eadp test\nds_val = val.map(get_img, num_parallel_calls=AUTO)\nds_val = ds_val.batch(BATCH_SIZE,drop_remainder=True)\nds_val = ds_val.prefetch(AUTO)","c4417749":"#h\u00e0m v\u1ebd confusion_matrix\ndef cf_matrix(model,dataset):\n    #D\u1ef1 \u0111o\u00e1n tr\u00ean t\u1eadp d\u1eef li\u1ec7u\n    y_pred = model.predict(dataset)\n    #L\u1ea5y nh\u00e3n d\u1ef1 \u0111o\u00e1n b\u1eb1ng np.argmax\n    y_predict = np.argmax(y_pred, axis=1)\n    #L\u1ea5y nh\u00e3n th\u1ef1c t\u1ebf\n    y_true = tf.concat([y for x, y in dataset], axis=0)\n    #L\u1ea5y nh\u00e3n th\u1ef1c t\u1ebf b\u1eb1ng np.argmax\n    y_true = np.argmax(y_true, axis=1)\n    #T\u1ea1o confusion_matrix v\u1edbi chu\u1ea9n ho\u00e1 theo d\u00f2ng\n    res = confusion_matrix(y_true = list(y_true),\n                           y_pred = y_predict,\n                        normalize = 'true')\n    #\u0110\u1eb7t target_names \n    target_names = [\"Benign_mass\",\n                    \"Malignant_mass\"]\n    #Chuy\u1ec3n confusion_matrix th\u00e0nh DataFrame\n    res = pd.DataFrame(res,index = target_names,columns = target_names)\n    #V\u1ebd heatmap\n    fig, ax = plt.subplots(figsize=(4,3))\n    heatmap = sns.heatmap(res, annot=True, ax = ax,linewidths = 0.01,cmap='Blues',square=True)# \n    ax.set_ylabel('True Lables')\n    ax.set_xlabel('Predict Lables')\n    #Xoay x 45 \u0111\u1ed9 \n    plt.xticks(rotation = 45,ha='right', rotation_mode='anchor')\n    plt.show()","8d5eabf7":"def _vgg_block(nb_filters, repetitions, dropout=0.0, weight_decay=0.001):\n    def f(input):\n        for i in range(repetitions):\n            input = Conv2D(nb_filters, (3, 3), padding='same', \n                           kernel_initializer=\"he_normal\", \n                           kernel_regularizer=l2(weight_decay))(input)\n            input = BatchNormalization()(input)\n            input = Activation('relu')(input)\n            input = Dropout(dropout)(input)\n        input = MaxPooling2D((2, 2), strides=(2, 2))(input)\n        return input\n    return f\ndef add_top_layers(model, image_size,\n                   depths=[512,512],repetitions=[1,1], \n                   nb_class=2,dropout=0.0, weight_decay=0.0001,\n                   ):\n    def add_vgg_blocks(block):\n        for depth,repetition in zip(depths, repetitions):\n            block = _vgg_block(depth, repetition,\n                               dropout=dropout, \n                               weight_decay=weight_decay)(block)\n        pool = GlobalAveragePooling2D()(block)\n        dropped = Dropout(dropout)(pool)\n        return dropped\n    last_kept_layer = model.layers[-5]\n    block = last_kept_layer.output\n    image_input = Input(shape=(image_size[0], image_size[1], 3))\n    model0 = Model(inputs=model.inputs, outputs=block)\n    block = model0(image_input)\n    \n    block = add_vgg_blocks(block)\n    dense = Dense(nb_class, kernel_initializer=\"he_normal\", \n                  activation='softmax', \n                  kernel_regularizer=l2(weight_decay))(block)\n    model_addtop = Model(inputs=image_input, outputs=dense)\n    return model_addtop","7fcb42a2":"def compile(model,ln):\n        model.compile(\n            optimizer=tf.keras.optimizers.Adam(learning_rate= ln),\n            loss=tf.keras.losses.CategoricalCrossentropy(),\n            metrics=['accuracy'],\n            steps_per_execution=230\n        )\n\ndef do_2stage_training(path_model,depths,path_save):\n    #load path model\n    with tpu_strategy.scope():\n        load_locally = tf.saved_model.LoadOptions(experimental_io_device='\/job:localhost')\n        patch_model = tf.keras.models.load_model(path_model, compile=False,\n                                                 options=load_locally\n                                                )\n        image_model =add_top_layers(patch_model, image_size=[1152,896],\n                                depths=depths, repetitions=[1,1],\n                                nb_class=2, dropout=0.0, weight_decay=0.0001,\n                                )\n    #call back\n    save_locally = tf.saved_model.SaveOptions(experimental_io_device='\/job:localhost')\n    checkpointer = tf.keras.callbacks.ModelCheckpoint(path_save,\n                                                      options=save_locally,\n                                                      monitor='val_accuracy',\n                                                      verbose=1,\n                                                      save_best_only=True)\n    early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                         patience=10)\n    callbacks = [checkpointer,early_stopping_cb]\n    with tpu_strategy.scope():\n        for layer in image_model.layers[:2]:\n            layer.trainable = False\n        compile(image_model,ln=0.01)\n        for layer in image_model.layers:\n            if isinstance(layer, Dense) or isinstance(layer, Conv2D):\n                try:\n                    layer.kernel_regularizer.l2 = 0.0001\n                except AttributeError:\n                    pass\n    image_model.fit(ds,\n        epochs=20,\n        validation_data=ds_val,\n        callbacks=callbacks,\n        )\n    with tpu_strategy.scope():\n        for layer in image_model.layers[:2]:\n            layer.trainable = False\n        compile(image_model,ln=0.001)\n    image_model.fit(ds,\n        epochs=80,\n        validation_data=ds_val,\n        callbacks=callbacks,\n        )\n    with tpu_strategy.scope():\n        #load model\n        image_model = tf.keras.models.load_model(path_save,\n                                                 options=load_locally)\n    print('\u0111\u1ed9 ch\u00ednh x\u00e1c tr\u00ean t\u1eadp test:',image_model.evaluate(ds_test,verbose=0))\n","1b07d2b1":"do_2stage_training(path_model='..\/input\/d\/dleqhuy\/model\/model_vgg16.h5',\n                   depths=[512,512],\n                   path_save='.\/model_vgg16_512_512.h5'\n                  )","4c49e7d2":"do_2stage_training(path_model='..\/input\/d\/dleqhuy\/model-efficientnet\/model_b2.h5',\n                   depths=[512,512],\n                   path_save='.\/model_b2_512_512.h5'\n                  )","34dd4d74":"do_2stage_training(path_model='..\/input\/d\/dleqhuy\/model\/model_resnet50.h5',\n                   depths=[512,512],\n                   path_save='.\/model_resnet50_512_512.h5'\n                  )","bde568aa":"****MODEL_B2****"}}