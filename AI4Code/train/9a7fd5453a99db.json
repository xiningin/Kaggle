{"cell_type":{"fc66b88f":"code","33c81eb9":"code","d9ae47d1":"code","d8f531bf":"code","83845953":"code","66ddbe9a":"code","f487a313":"code","fd5e45e4":"code","f621109b":"code","efc6d717":"code","690e53ab":"code","e58cbaba":"code","463f088e":"code","6a334a28":"code","8f8b8979":"code","995360b2":"code","572d1cea":"code","5039e5c6":"code","9715834c":"code","597b3342":"code","0f494a6d":"code","13c6bb78":"code","f2e22ce1":"code","a0f6a48f":"code","239a5876":"code","8a038bb1":"code","4e29035f":"code","b99132ff":"code","cc76cefd":"code","0120e0c3":"code","b2cff6fb":"code","f63295f8":"code","c3c4dbda":"code","2ce1e21c":"code","1a8d90b1":"code","47e49605":"code","3ef6f7f3":"code","42bf55a6":"code","1e9a3b67":"code","2b477499":"code","7325ecf9":"code","831f28a2":"code","f0e9fca8":"code","8da63502":"code","b176ee23":"code","0c8ecc10":"code","c83353ab":"code","30f5ebf8":"code","e31cc7ab":"code","4ef4130a":"code","bff4d450":"code","39624b79":"code","77c8996b":"code","4c80b48d":"code","fdd4fc39":"code","70486b9b":"code","3728b9c8":"code","edbddcc7":"code","5ca2ae1e":"code","d0e8b274":"code","551ebaf6":"code","b1e7ff9d":"code","7a14eabf":"code","98275646":"code","4b869d76":"code","0d536720":"code","8424b0f6":"code","9db0bc11":"code","fcf29006":"code","cc22db0e":"markdown","2e7a5a3c":"markdown","bde011c8":"markdown","1aadfdb3":"markdown","a537cf8a":"markdown","1628c34b":"markdown","3b8fc79b":"markdown","7de37bf0":"markdown","96ec84a4":"markdown","1bbc6df0":"markdown","645f38ec":"markdown","615805c7":"markdown","ebb3cd4b":"markdown","43d804fd":"markdown","5dd26ef1":"markdown","a2db9baa":"markdown","ef185857":"markdown","df8ff238":"markdown","65896afa":"markdown","a47cc8e5":"markdown","8753f11c":"markdown","716bdc39":"markdown","2a00df27":"markdown","bcfb174e":"markdown","b1a580f4":"markdown","0d8fadf4":"markdown","480e4db0":"markdown","0db25ec3":"markdown","799f6e17":"markdown","8a1e481b":"markdown","1a367a83":"markdown","70f2c8f2":"markdown","50081615":"markdown","e2baa58b":"markdown","b1a34e79":"markdown","def8e146":"markdown","194770a3":"markdown","e9229684":"markdown","15ff90f2":"markdown","8764e2a1":"markdown","e75da043":"markdown","71c514ac":"markdown","27b8a0e3":"markdown"},"source":{"fc66b88f":"from bs4 import BeautifulSoup","33c81eb9":"! ls ..\/input\/imdb-reviews","d9ae47d1":"soup = BeautifulSoup(open(\"..\/input\/imdb-reviews\/1.html\",encoding=\"utf8\"), \"html.parser\")","d8f531bf":"movie_containers = soup.find_all('div' , class_ = 'review-container')\nprint(type(movie_containers))\nprint(len(movie_containers))","83845953":"first_movie = movie_containers[0]\nfirst_movie.a.text","66ddbe9a":"temp = first_movie.span.text","f487a313":"temp","fd5e45e4":"# Lists to store the scraped data in\nreviews = []\nratings = []\n\n# Extract data from individual movie container\nfor container in movie_containers:\n    \n    #review\n    review = container.a.text\n    reviews.append(review)\n    \n    #rating\n    rating = container.span.text\n    ratings.append(rating)\n   ","f621109b":"import pandas as pd\nimport numpy as np\n\ntest_df = pd.DataFrame({'Review': reviews,'Rating': ratings})\nprint(test_df.info())\ntest_df.head()","efc6d717":"test_df.loc[:, 'Rating'] = test_df['Rating'].str[6:8]","690e53ab":"test_df.loc[:, 'Rating'] = test_df['Rating'].str.replace('\/', '')\ntest_df.loc[:, 'Review'] = test_df['Review'].str.replace('\\n', '')\ntest_df.loc[:, 'Rating'] = test_df['Rating'].str.replace('-', '')","e58cbaba":"import re\ndef split_it(rating):\n    return re.sub('[a-zA-Z]+','NaN', rating)","463f088e":"test_df['Rating'] = test_df['Rating'].apply(split_it)","6a334a28":"test_df = test_df[test_df.Rating.str.contains(\"NaN\") == False]","8f8b8979":"test_df['Rating'] = test_df['Rating'].apply(pd.to_numeric)","995360b2":"test_df.head()","572d1cea":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","5039e5c6":"sns.countplot(test_df['Rating'])","9715834c":"sns.countplot(test_df['Rating'])","597b3342":"test_df.describe()","0f494a6d":"test_df['Review']=test_df['Review'].astype(str)\ntest_df['Review Length']=test_df['Review'].apply(len)\n\ng = sns.FacetGrid(data=test_df, col='Rating')\ng.map(plt.hist, 'Review Length', bins=50)","13c6bb78":"plt.figure(figsize=(10,10))\nsns.boxplot(x='Rating', y='Review Length', data=test_df)","f2e22ce1":"from collections import Counter\nfrom nltk.tokenize import RegexpTokenizer\nfrom stop_words import get_stop_words\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk import sent_tokenize, word_tokenize","a0f6a48f":"nltk.download('punkt')","239a5876":"a = test_df['Review'].str.lower().str.cat(sep= ' ')","8a038bb1":"# removes punctuation,numbers and returns list of words\nb = re.sub('[^A-Za-z]+', ' ', a)","4e29035f":"#remove all the stopwords from the text\nstop_words = list(get_stop_words('en'))         \nnltk_words = list(stopwords.words('english'))   \nstop_words.extend(nltk_words)\n\nnewStopWords = ['game','thrones', 'bran', 'stark', 'dragons']\nstop_words.extend(newStopWords)","b99132ff":"word_tokens = word_tokenize(b)","cc76cefd":"len(word_tokens)","0120e0c3":"filtered_sentence = []\nfor w in word_tokens:\n    if w not in stop_words:\n        filtered_sentence.append(w)","b2cff6fb":"len(filtered_sentence)","f63295f8":"# Remove characters which have length less than 2  \nwithout_single_chr = [word for word in filtered_sentence if len(word) > 2]\n\n# Remove numbers\ncleaned_data_title = [word for word in without_single_chr if not word.isnumeric()]   ","c3c4dbda":"top_N = 100\nword_dist = nltk.FreqDist(cleaned_data_title)\nrslt = pd.DataFrame(word_dist.most_common(top_N),\n                    columns=['Word', 'Frequency'])\n\nplt.figure(figsize=(10,10))\nsns.set_style(\"whitegrid\")\nax = sns.barplot(x=\"Word\",y=\"Frequency\", data=rslt.head(7))","2ce1e21c":"from wordcloud import WordCloud, STOPWORDS","1a8d90b1":"def wc(data,bgcolor,title):\n    plt.figure(figsize = (100,100))\n    wc = WordCloud(background_color = bgcolor, max_words = 1000,  max_font_size = 50)\n    wc.generate(' '.join(data))\n    plt.imshow(wc)\n    plt.axis('off')","47e49605":"wc(cleaned_data_title,'black','Most Used Words')","3ef6f7f3":"from textblob import TextBlob\n\nbloblist_desc = list()\n\ndf_review_str=test_df['Review'].astype(str)","42bf55a6":"for row in df_review_str:\n    blob = TextBlob(row)\n    bloblist_desc.append((row,blob.sentiment.polarity, blob.sentiment.subjectivity))\n    df_polarity_desc = pd.DataFrame(bloblist_desc, columns = ['Review','sentiment','polarity'])","1e9a3b67":"df_polarity_desc.head()","2b477499":"def f(df_polarity_desc):\n    if df_polarity_desc['sentiment'] >= 0:\n        val = \"Positive Review\"\n    elif df_polarity_desc['sentiment'] >= -0.09:\n        val = \"Neutral Review\"\n    else:\n        val = \"Negative Review\"\n    return val","7325ecf9":"df_polarity_desc['Sentiment_Type'] = df_polarity_desc.apply(f, axis=1)\n\nplt.figure(figsize=(10,10))\nsns.set_style(\"whitegrid\")\nax = sns.countplot(x=\"Sentiment_Type\", data=df_polarity_desc)","831f28a2":"positive_reviews=df_polarity_desc[df_polarity_desc['Sentiment_Type']=='Positive Review']\nnegative_reviews=df_polarity_desc[df_polarity_desc['Sentiment_Type']=='Negative Review']","f0e9fca8":"negative_reviews.head()","8da63502":"wc(positive_reviews['Review'],'black','Most Used Words')","b176ee23":"wc(negative_reviews['Review'],'black','Most Used Words')","0c8ecc10":"import string\ndef text_process(review):\n    nopunc=[word for word in review if word not in string.punctuation]\n    nopunc=''.join(nopunc)\n    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]","c83353ab":"test_df=test_df.dropna(axis=0,how='any')\nrating_class = test_df[(test_df['Rating'] == 1) | (test_df['Rating'] == 10)]\nX_review=rating_class['Review']\ny=rating_class['Rating']","30f5ebf8":"len(X_review)","e31cc7ab":"from sklearn.feature_extraction.text import CountVectorizer\nbow_transformer= CountVectorizer(analyzer=text_process).fit(X_review)","4ef4130a":"X_review = bow_transformer.transform(X_review)","bff4d450":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_review, y, test_size=0.3, random_state=101)","39624b79":"from sklearn.naive_bayes import MultinomialNB\nnb = MultinomialNB()\nnb.fit(X_train, y_train)\npredict=nb.predict(X_test)","77c8996b":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nprint(confusion_matrix(y_test, predict))\nprint('\\n Accuracy:')\nprint(accuracy_score(y_test, predict))\nprint(classification_report(y_test, predict))","4c80b48d":"rating_positive=test_df['Review'][6]\nrating_positive","fdd4fc39":"rating_postive_transformed = bow_transformer.transform([rating_positive])\nnb.predict(rating_postive_transformed)[0]","70486b9b":"rating_negative=test_df['Review'][54]\nrating_negative","3728b9c8":"rating_negative_transformed = bow_transformer.transform([rating_negative])\nnb.predict(rating_negative_transformed)[0]","edbddcc7":"ratings_1 = (rating_class['Rating']==1).sum()\nratings_1_indices = np.array(rating_class[rating_class.Rating == 1].index)\n","5ca2ae1e":"ratings_10_indices = rating_class[rating_class.Rating == 10].index\n\n\nrandom_normal_indices = np.random.choice(ratings_10_indices, ratings_1, replace = False)\nrandom_normal_indices = np.array(random_normal_indices)\n\nunder_sample_indices = np.concatenate([ratings_1_indices,random_normal_indices])\n\n\n\n","d0e8b274":"undersample = rating_class.ix[under_sample_indices]\n\nX_undersample = undersample.ix[:, undersample.columns != 'Rating']\ny_undersample = undersample.ix[:, undersample.columns == 'Rating']","551ebaf6":"print(\"Percentage of 10 ratings: \", len(undersample[undersample.Rating == 10])\/len(undersample))\nprint(\"Percentage of 1 ratings: \", len(undersample[undersample.Rating == 1])\/len(undersample))\nprint(\"Total number of examples in resampled data: \", len(undersample))","b1e7ff9d":"X_review_us = X_undersample['Review']","7a14eabf":"X_review_us = bow_transformer.transform(X_review_us)","98275646":"X_train_us, X_test_us, y_train_us, y_test_us = train_test_split(X_review_us, y_undersample, test_size=0.3, random_state=101)","4b869d76":"nb.fit(X_train_us, y_train_us)\npredict_us=nb.predict(X_test_us)","0d536720":"print(confusion_matrix(y_test_us, predict_us))\nprint('\\n Accuracy:')\nprint(accuracy_score(y_test_us, predict_us))\nprint(classification_report(y_test_us, predict_us))","8424b0f6":"nb.fit(X_train_us, y_train_us)\npredict_entire=nb.predict(X_test)","9db0bc11":"print(confusion_matrix(y_test, predict_entire))\nprint('\\n Accuracy:')\nprint(accuracy_score(y_test, predict_entire))\nprint(classification_report(y_test, predict_entire))","fcf29006":"print(confusion_matrix(y_test, predict))\nprint('\\n Accuracy:')\nprint(accuracy_score(y_test, predict))\nprint(classification_report(y_test, predict))","cc22db0e":"Let us visualise the most common words","2e7a5a3c":"Let us find the accuracy, precision and recall","bde011c8":"Let us now train a model \nWe are taking only review with ratings 1 and 10 to perform the analysis to make the analysis more simple.","1aadfdb3":"We will try to perform sentimental analysis and try to classify whether a review is a positive or negative","a537cf8a":"Let us try to use machine learning and use NLP analytics","1628c34b":"After looking at the sentiments I have used the above values. This is a personal perference which you can change according to your choice.","3b8fc79b":"We will now remove the stop words from the reviews","7de37bf0":"**Table of Contents**\n\n1. 3 Popular Tools and Libraries used for Web Scraping in Python\n\n2. Components of Web Scraping\n\n    Crawl\n    \n    Parse and Transform\n    \n    Store\n3. Scraping URLs and Email IDs from a Web Page\n\n4. Scraping Images\n\n5. Scraping Data on Page Load","96ec84a4":"Although, our overall accuracy has decreased. We have increased the recall to 90 percent.\nHence our model can classify review with 1 rating better. <br>\nComparing with the original model without undersampling","1bbc6df0":"We have a 81 percent accuracy but a very recall score indicating that movies with ratings 1's\nare not classified properly this maybe due to a large ratio of positive review. \nHence it has a bad recall.\n","645f38ec":"Let us test our model","615805c7":"Let us look if there is a relation between a review length and a Rating","ebb3cd4b":"We can see there are 1124 containers consisting of the reviews and the ratings","43d804fd":"We can see that we have cleaned the Ratings and the Reviews\nThere might be some redundency in the cleaning which I will update later","5dd26ef1":"We can see a reduced accuracy but we have increased the recall now let us try to use this model on the entire data","a2db9baa":"We can see that Reviews with ratings 1 and and 8 are the longest","ef185857":"Let us try to extract all the reviews and the ratings","df8ff238":"**3 Popular Tools and Libraries used for Web Scraping in Python**","65896afa":"Let us look at the most used words in all the negative reviews","a47cc8e5":"Let us try to perform analysis on the entire review rather than all the words.\nFor this we make use of the TextBlob","8753f11c":"Let us try to extract all the words and try to perform analysis on it","716bdc39":"**Overview**\n\nWeb scraping is a highly effective method to extract data from websites (depending on the website\u2019s regulations).\n\nLearn how to perform web scraping in Python using the popular BeautifulSoup library.\n\nWe will cover different types of data that can be scraped, such as text and images.","2a00df27":"Importing the required libraries and extracting the Movie reviews and their ratings","bcfb174e":"Let us look at the most used words in all the positive reviews","b1a580f4":"Let us try to extract the reviews","0d8fadf4":"**Note:** Always follow the robots.txt file of the target website which is also known as the robot exclusion protocol. This tells web robots which pages not to crawl.","480e4db0":"We have removed all the stop words and reduced the size by half.","0db25ec3":"Still working on...will upadte you soon","799f6e17":"We can see that there are some Ratings above 10 that we need to get rid of.","8a1e481b":"Let us try to put all the ratings into a dataframe","1a367a83":"As we can see that we have a skewed data set and let us try to improve recall by performing undersampling","70f2c8f2":"You\u2019ll come across multiple libraries and frameworks in Python for web scraping. Here are three popular ones that do the task with efficiency and aplomb:\n\n**BeautifulSoup**\n\nBeautifulSoup is an amazing parsing library in Python that enables us to extract data from HTML and XML documents. It can automatically detect encodings and gracefully handles HTML documents even with special characters. We can navigate a parsed document and find what we need which makes it quick and painless to extract the data from the webpages. In this article, we will learn how to build web scrapers using Beautiful Soup in detail\n\n**Scrapy**\n\nScrapy is a Python framework for large scale web scraping. It gives you all the tools you need to efficiently extract data from websites, process them as you want, and store them in your preferred structure and format. You can read more about Scrapy here\n\n**Selenium**\n\nSelenium is another popular tool for automating browsers. It\u2019s primarily used for testing in the industry but is also very handy for web scraping. Check out this amazing article to know more about how it works in Python","50081615":"We have extracted all the words in the reviews. Let us find the total length","e2baa58b":"We can see that the most common words are positive indicating how great Game of thrones is!","b1a34e79":"And woah we have scrapped all the reviews and the ratings \nPandas do actualy make our work easier!","def8e146":"Let us try to find the ratings of the reviews","194770a3":"Let us look at the top 10 most used words in a review.","e9229684":"Let us look at the descriptions","15ff90f2":"Let us perform cleaning on the reviews and the ratings","8764e2a1":"We can see that the reviews and ratings require cleaning which we will deal with it later","e75da043":"Let us train a model using Multinomial Naive Bayes as it works great on text.","71c514ac":"Let us take a look at the html structure ","27b8a0e3":"Please use below link to get scrapped data. \n[https:\/\/www.dataquest.io\/blog\/web-scraping-beautifulsoup\/](http:\/\/)"}}