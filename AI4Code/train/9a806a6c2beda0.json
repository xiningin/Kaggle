{"cell_type":{"cf82aa68":"code","59be8e7b":"code","871c3f6f":"code","d02b35d4":"code","64057f8b":"code","74f7bba8":"code","0160957e":"code","b3378ec2":"code","2603b8c2":"code","40312af8":"code","be7bd944":"code","4b7142d6":"code","1bc673bf":"code","d85bd9d9":"code","4c9b4855":"code","2f1256ba":"code","d96e0ede":"code","7c9df5a6":"code","4d30f205":"code","e6a1030e":"code","7a8bf19e":"code","704bdafb":"code","661c8476":"code","deaaf610":"code","bb039c3b":"code","168024fe":"code","630c4595":"code","7c8b56db":"code","f3a8b0c8":"code","c325b529":"code","c6753353":"code","430b97b2":"code","2cddc856":"code","fbe956df":"code","3705fd2a":"code","6eef83eb":"code","eb6270bd":"code","1fca26fa":"code","423a79d5":"code","8f4bef7a":"code","6d5c28db":"code","3de747bc":"code","76e8681c":"code","1e0d3812":"code","510e9072":"code","513e561d":"code","d7365fa0":"code","82d515ef":"code","c6dbeb93":"code","d79a671a":"code","7332e302":"code","831ca346":"code","4f34b06c":"code","8472ff63":"code","2be6994a":"markdown","16eec93e":"markdown","e4c73852":"markdown","fe4d2047":"markdown","42fb20bf":"markdown","8ceb393c":"markdown","843ee479":"markdown","ec63cabc":"markdown","fe416611":"markdown","65031851":"markdown","2b9ac563":"markdown","2e487ea5":"markdown","c64e6aca":"markdown","d73f1a44":"markdown","c5b0382a":"markdown","5d5e32c6":"markdown","b7de7f20":"markdown"},"source":{"cf82aa68":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport keras\nimport cv2\nfrom keras.datasets import fashion_mnist#download mnist data and split into train and test sets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nimport matplotlib.pyplot as plt\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout#create model\nfrom keras.optimizers import SGD\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.applications.vgg16 import VGG16\n\n","59be8e7b":"CAT_TRAIN_PATH=\"\/kaggle\/input\/cat-and-dog\/training_set\/training_set\/cats\/\"\nDOG_TRAIN_PATH=\"\/kaggle\/input\/cat-and-dog\/training_set\/training_set\/dogs\/\"\nCAT_TEST_PATH=\"\/kaggle\/input\/cat-and-dog\/test_set\/test_set\/cats\/\"\nDOG_TEST_PATH=\"\/kaggle\/input\/cat-and-dog\/test_set\/test_set\/dogs\/\"","871c3f6f":"def preprocess_img(img):\n    dim=(100,100)\n    res = cv2.resize(img, dim, interpolation=cv2.INTER_LINEAR)\n    return res\n    ","d02b35d4":"#Building up datasets\nl=len(list(os.listdir(CAT_TRAIN_PATH)))\nindex=0\nlst=[]\ny=[]\nfor file in os.listdir(CAT_TRAIN_PATH):\n    index+=1\n    #print(file)\n    if(file==\"_DS_Store\"):\n        continue\n    im=plt.imread(CAT_TRAIN_PATH+str(file))\n    im=preprocess_img(im)\n    lst.append(im)\n    y.append(1)\n    if(index%40==0):\n        print(\"Finished Reading \"+str(index)+\"\/\"+str(l))\n        #print(im.shape)\n        #print(lst.shape)\n        #print(y.shape)\n    \nl=len(list(os.listdir(DOG_TRAIN_PATH)))\nindex=0\nfor file in os.listdir(DOG_TRAIN_PATH):\n    index+=1\n    #print(file)\n    if(file==\"_DS_Store\"):\n        continue\n    im=plt.imread(DOG_TRAIN_PATH+str(file))\n    im=preprocess_img(im)\n    lst.append(im)\n    y.append(0)\n    if(index%40==0):\n        print(\"Finished Reading \"+str(index)+\"\/\"+str(l))\n\n\n        ","64057f8b":"\nprint(np.array(lst).shape)\nprint(np.array(y).shape)","74f7bba8":"X_train=np.array(lst)\nY_train=np.array(y)\nnp.savez(\"CAT_DOG_X_train\",X_train)\nnp.savez(\"CAT_DOG_Y_train\",Y_train)\nprint(X_train.shape)\nprint(Y_train.shape)\n","0160957e":"#Building up datasets\nl=len(list(os.listdir(CAT_TEST_PATH)))\nindex=0\nlst=[]\ny=[]\nfor file in os.listdir(CAT_TEST_PATH):\n    index+=1\n    #print(file)\n    if(file==\"_DS_Store\"):\n        continue\n    im=plt.imread(CAT_TEST_PATH+str(file))\n    im=preprocess_img(im)\n    lst.append(im)\n    y.append(1)\n    if(index%40==0):\n        print(\"Finished Reading \"+str(index)+\"\/\"+str(l))\n        #print(im.shape)\n        #print(lst.shape)\n        #print(y.shape)\n    \nl=len(list(os.listdir(DOG_TEST_PATH)))\nindex=0\nfor file in os.listdir(DOG_TEST_PATH):\n    index+=1\n    #print(file)\n    if(file==\"_DS_Store\"):\n        continue\n    im=plt.imread(DOG_TEST_PATH+str(file))\n    im=preprocess_img(im)\n    lst.append(im)\n    y.append(0)\n    if(index%40==0):\n        print(\"Finished Reading \"+str(index)+\"\/\"+str(l))\n\n\n        ","b3378ec2":"X_test=np.array(lst)\nY_test=np.array(y)\nprint(X_test.shape)\nprint(Y_test.shape)\nnp.save(\"CAT_DOG_X_test\",X_test)\nnp.save(\"CAT_DOG_Y_test\",Y_test)","2603b8c2":"X_TRAIN_FILE=\"\/kaggle\/input\/cat-dog-numpy\/CAT_DOG_X_train.npz\"\nX_TEST_FILE=\"\/kaggle\/input\/cat-dog-numpy\/CAT_DOG_X_test.npy\"\nY_TRAIN_FILE=\"\/kaggle\/input\/cat-dog-numpy\/CAT_DOG_Y_train.npz\"\nY_TEST_FILE=\"\/kaggle\/input\/cat-dog-numpy\/CAT_DOG_Y_test.npy\"","40312af8":"a=np.load(X_TRAIN_FILE)\nX_train=a.f.arr_0\na=np.load(Y_TRAIN_FILE)\nY_train=a.f.arr_0\na=np.load(X_TEST_FILE)\nX_test=a\na=np.load(Y_TEST_FILE)\nY_test=a\n","be7bd944":"print(X_train.shape)\nprint(Y_train.shape)\nprint(X_test.shape)\nprint(Y_test.shape)","4b7142d6":"print(\"Distribution of cats and dogs in the different sets\")\nprint(\"TRAIN  :  \"+str(sum(Y_train==1))+\" cats vs \"+str(sum(Y_train==0))+\" dogs\")\nprint(\"TEST  :  \"+str(sum(Y_test==1))+\" cats vs \"+str(sum(Y_test==0))+\" dogs\")","1bc673bf":"X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=42)","d85bd9d9":"print(X_train.shape)\nprint(Y_train.shape)\nprint(X_val.shape)\nprint(Y_val.shape)\nprint(X_test.shape)\nprint(Y_test.shape)","4c9b4855":"print(\"Distribution of cats and dogs in the different sets\")\nprint(\"TRAIN  :  \"+str(sum(Y_train==1))+\" cats vs \"+str(sum(Y_train==0))+\" dogs\")\nprint(\"VAL  :  \"+str(sum(Y_val==1))+\" cats vs \"+str(sum(Y_val==0))+\" dogs\")\nprint(\"TEST  :  \"+str(sum(Y_test==1))+\" cats vs \"+str(sum(Y_test==0))+\" dogs\")","2f1256ba":"\nprint(\"Images 1 to 5 :\")\nfor i in range(0,5):\n    plt.imshow(X_train[i])\n    print(Y_train[i])\n    plt.show()","d96e0ede":"def normalize_X(X):\n    X_norm=X\/255\n    return X_norm","7c9df5a6":"def preprocess_data(X_train,X_val,X_test,y_train,y_val,y_test):\n    X_train=normalize_X(X_train)\n    X_val=normalize_X(X_val)\n    X_test=normalize_X(X_test)\n    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n    X_val, y_val = shuffle(X_val, y_val, random_state=42)\n    X_test, y_test = shuffle(X_test, y_test, random_state=42)\n    return X_train,X_val,X_test,y_train,y_val,y_test","4d30f205":"X_train,X_val,X_test,Y_train,Y_val,Y_test=preprocess_data(X_train,X_val,X_test,Y_train,Y_val,Y_test)","e6a1030e":"\n\ndef input_and_run(model,X_train,X_val,X_test,y_train,y_val,y_test,alpha=0.01,num_epochs=10):\n    \n    #compile model using accuracy to measure model performance\n    opt = keras.optimizers.Adam(learning_rate=alpha)\n    opt2=SGD(lr=alpha, momentum=0.9)\n    model.compile(loss='binary_crossentropy', optimizer=opt,metrics=['accuracy'])\n    \n    #train the model\n    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=num_epochs)\n    \n    #Getting results\n    result = model.evaluate(X_train,y_train)\n    #print(result)\n    print(\"Training accuracy = \"+str(result[1]*100))\n    result = model.evaluate(X_val,y_val)\n    #print(result)\n    print(\"Validation accuracy = \"+str(result[1]*100))\n    result = model.evaluate(X_test,y_test)\n    #print(result)\n    print(\"Test accuracy = \"+str(result[1]*100))\n\n","7a8bf19e":"##BUILDING THE MODEL 1\n\nmodel1 = Sequential()#add model layers\n\nmodel1.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(100, 100, 3)))\nmodel1.add(MaxPooling2D((2, 2)))\nmodel1.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel1.add(MaxPooling2D((2, 2)))\nmodel1.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel1.add(MaxPooling2D((2, 2)))\nmodel1.add(Flatten())\nmodel1.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel1.add(Dense(1, activation='sigmoid'))\n\nprint(model1.summary())\ninput_and_run(model1,X_train,X_val,X_test,Y_train,Y_val,Y_test,alpha=0.0001,num_epochs=20)","704bdafb":"##BUILDING THE MODEL 1\n\nmodel2 = Sequential()#add model layers\n\nmodel2.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(100, 100, 3)))\nmodel2.add(MaxPooling2D((2, 2)))\nmodel2.add(Dropout(0.2))\nmodel2.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel2.add(MaxPooling2D((2, 2)))\nmodel2.add(Dropout(0.2))\nmodel2.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel2.add(MaxPooling2D((2, 2)))\nmodel2.add(Dropout(0.2))\nmodel2.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel2.add(MaxPooling2D((2, 2)))\nmodel2.add(Dropout(0.2))\nmodel2.add(Flatten())\nmodel2.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel2.add(Dropout(0.5))\nmodel2.add(Dense(1, activation='sigmoid'))\n\nprint(model2.summary())\ninput_and_run(model2,X_train,X_val,X_test,Y_train,Y_val,Y_test,alpha=0.002,num_epochs=200)","661c8476":"model2.save(\"model2.h5\")\nprint(\"Saved model to disk\")","deaaf610":"WEIGHTS_FILE=\"\/kaggle\/input\/cat-dog-numpy\/model2.h5\"","bb039c3b":"from keras.models import load_model\n# load model\nloaded_model=load_model(WEIGHTS_FILE)\nprint(\"Loaded model from disk\")","168024fe":"#Getting results\nopt = keras.optimizers.Adam(learning_rate=0.002)\nloaded_model.compile(loss='binary_crossentropy', optimizer=opt,metrics=['accuracy'])\nresult = loaded_model.evaluate(X_train,Y_train)\n#print(result)\nprint(\"Training accuracy = \"+str(result[1]*100))\nresult = loaded_model.evaluate(X_val,Y_val)\n#print(result)\nprint(\"Validation accuracy = \"+str(result[1]*100))\nresult = loaded_model.evaluate(X_test,Y_test)\n#print(result)\nprint(\"Test accuracy = \"+str(result[1]*100))\n","630c4595":"X_TRAIN_FILE=\"\/kaggle\/input\/cat-dog-numpy\/CAT_DOG_X_train.npz\"\nX_TEST_FILE=\"\/kaggle\/input\/cat-dog-numpy\/CAT_DOG_X_test.npy\"\nY_TRAIN_FILE=\"\/kaggle\/input\/cat-dog-numpy\/CAT_DOG_Y_train.npz\"\nY_TEST_FILE=\"\/kaggle\/input\/cat-dog-numpy\/CAT_DOG_Y_test.npy\"","7c8b56db":"a=np.load(X_TRAIN_FILE)\nX_train=a.f.arr_0\na=np.load(Y_TRAIN_FILE)\nY_train=a.f.arr_0\na=np.load(X_TEST_FILE)\nX_test=a\na=np.load(Y_TEST_FILE)\nY_test=a\n\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=42)\n","f3a8b0c8":"print(X_train.shape)\nprint(Y_train.shape)\nprint(X_val.shape)\nprint(Y_val.shape)\nprint(X_test.shape)\nprint(Y_test.shape)","c325b529":"def normalize_X(X):\n    X_norm=X\/255\n    return X_norm","c6753353":"def preprocess_data(X_train,X_val,X_test,y_train,y_val,y_test):\n    X_train=normalize_X(X_train)\n    X_val=normalize_X(X_val)\n    X_test=normalize_X(X_test)\n    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n    X_val, y_val = shuffle(X_val, y_val, random_state=42)\n    X_test, y_test = shuffle(X_test, y_test, random_state=42)\n    return X_train,X_val,X_test,y_train,y_val,y_test","430b97b2":"X_train,X_val,X_test,Y_train,Y_val,Y_test=preprocess_data(X_train,X_val,X_test,Y_train,Y_val,Y_test)","2cddc856":"\n\ndef input_and_run2(model,X_train,X_val,X_test,y_train,y_val,y_test,alpha=0.01,num_epochs=10):\n    \n    datagen = ImageDataGenerator(width_shift_range=0.2,height_shift_range=0.2,horizontal_flip=True)\n    datagen.fit(X_train)\n    \n    #compile model using accuracy to measure model performance\n    opt = keras.optimizers.Adam(learning_rate=alpha)\n    opt2=SGD(lr=alpha, momentum=0.9)\n    model.compile(loss='binary_crossentropy', optimizer=opt,metrics=['accuracy'])\n    \n    #train the model\n    model.fit(datagen.flow(X_train, y_train),validation_data=(X_val, y_val), epochs=num_epochs)\n    \n    #Getting results\n    result = model.evaluate(X_train,y_train)\n    #print(result)\n    print(\"Training accuracy = \"+str(result[1]*100))\n    result = model.evaluate(X_val,y_val)\n    #print(result)\n    print(\"Validation accuracy = \"+str(result[1]*100))\n    result = model.evaluate(X_test,y_test)\n    #print(result)\n    print(\"Test accuracy = \"+str(result[1]*100))\n\n\n","fbe956df":"##BUILDING THE MODEL 1\n\nmodel4 = Sequential()#add model layers\n\nmodel4.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(100, 100, 3)))\nmodel4.add(MaxPooling2D((2, 2)))\nmodel4.add(Dropout(0.2))\nmodel4.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel4.add(MaxPooling2D((2, 2)))\nmodel4.add(Dropout(0.2))\nmodel4.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel4.add(MaxPooling2D((2, 2)))\nmodel4.add(Dropout(0.2))\nmodel4.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel4.add(MaxPooling2D((2, 2)))\nmodel4.add(Dropout(0.2))\nmodel4.add(Flatten())\nmodel4.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel4.add(Dropout(0.5))\nmodel4.add(Dense(1, activation='sigmoid'))\n\nprint(model4.summary())\ninput_and_run2(model4,X_train,X_val,X_test,Y_train,Y_val,Y_test,alpha=0.001,num_epochs=200)","3705fd2a":"model4.save(\"model4.h5\")\nprint(\"Saved model to disk\")","6eef83eb":"X_TRAIN_FILE=\"\/kaggle\/input\/cat-dog-numpy\/CAT_DOG_X_train.npz\"\nX_TEST_FILE=\"\/kaggle\/input\/cat-dog-numpy\/CAT_DOG_X_test.npy\"\nY_TRAIN_FILE=\"\/kaggle\/input\/cat-dog-numpy\/CAT_DOG_Y_train.npz\"\nY_TEST_FILE=\"\/kaggle\/input\/cat-dog-numpy\/CAT_DOG_Y_test.npy\"","eb6270bd":"a=np.load(X_TRAIN_FILE)\nX_train=a.f.arr_0\na=np.load(Y_TRAIN_FILE)\nY_train=a.f.arr_0\na=np.load(X_TEST_FILE)\nX_test=a\na=np.load(Y_TEST_FILE)\nY_test=a\n\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=42)\n","1fca26fa":"print(X_train.shape)\nprint(Y_train.shape)\nprint(X_val.shape)\nprint(Y_val.shape)\nprint(X_test.shape)\nprint(Y_test.shape)","423a79d5":"def normalize_X(X):\n    X_norm=X\/255\n    return X_norm","8f4bef7a":"def preprocess_data(X_train,X_val,X_test,y_train,y_val,y_test):\n    X_train=normalize_X(X_train)\n    X_val=normalize_X(X_val)\n    X_test=normalize_X(X_test)\n    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n    X_val, y_val = shuffle(X_val, y_val, random_state=42)\n    X_test, y_test = shuffle(X_test, y_test, random_state=42)\n    return X_train,X_val,X_test,y_train,y_val,y_test","6d5c28db":"X_train,X_val,X_test,Y_train,Y_val,Y_test=preprocess_data(X_train,X_val,X_test,Y_train,Y_val,Y_test)","3de747bc":"\n\ndef input_and_run3(model,X_train,X_val,X_test,y_train,y_val,y_test,alpha=0.01,num_epochs=10):\n    \n    #datagen = ImageDataGenerator(width_shift_range=0.2,height_shift_range=0.2,horizontal_flip=True)\n    #datagen.fit(X_train)\n    \n    #compile model using accuracy to measure model performance\n    opt = keras.optimizers.Adam(learning_rate=alpha)\n    opt2=SGD(lr=alpha, momentum=0.9)\n    model.compile(loss='binary_crossentropy', optimizer=opt,metrics=['accuracy'])\n    \n    #train the model\n    model.fit(X_train,y_train,validation_data=(X_val, y_val), epochs=num_epochs)\n    #model.fit(datagen.flow(X_train, y_train),validation_data=(X_val, y_val), epochs=num_epochs)\n    \n    #Getting results\n    result = model.evaluate(X_train,y_train)\n    #print(result)\n    print(\"Training accuracy = \"+str(result[1]*100))\n    result = model.evaluate(X_val,y_val)\n    #print(result)\n    print(\"Validation accuracy = \"+str(result[1]*100))\n    result = model.evaluate(X_test,y_test)\n    #print(result)\n    print(\"Test accuracy = \"+str(result[1]*100))\n\n\n","76e8681c":"model5 = Sequential()\nmodel5.add(VGG16(include_top=False, input_shape=(100, 100, 3)))\n# mark loaded layers as not trainable\nfor layer in model5.layers:\n    layer.trainable = False\n# add new classifier layers\n#flat1 = Flatten()(model.layers[-1].output)\n#class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n#output = Dense(1, activation='sigmoid')(class1)\n\nmodel5.add(Flatten())\nmodel5.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel5.add(Dropout(0.5))\nmodel5.add(Dense(1, activation='sigmoid'))\nprint(model5.summary())\ninput_and_run3(model5,X_train,X_val,X_test,Y_train,Y_val,Y_test,alpha=0.001,num_epochs=200)\n\n\n# define new model\n#model = Model(inputs=model.inputs, outputs=output)\n# compile model\n#opt = SGD(lr=0.001, momentum=0.9)\n#model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n#return model","1e0d3812":"model5.save(\"model5.h5\")\nprint(\"Saved model to disk\")","510e9072":"X_TRAIN_FILE=\"\/kaggle\/input\/cat-dog-numpy\/CAT_DOG_X_train.npz\"\nX_TEST_FILE=\"\/kaggle\/input\/cat-dog-numpy\/CAT_DOG_X_test.npy\"\nY_TRAIN_FILE=\"\/kaggle\/input\/cat-dog-numpy\/CAT_DOG_Y_train.npz\"\nY_TEST_FILE=\"\/kaggle\/input\/cat-dog-numpy\/CAT_DOG_Y_test.npy\"","513e561d":"a=np.load(X_TRAIN_FILE)\nX_train=a.f.arr_0\na=np.load(Y_TRAIN_FILE)\nY_train=a.f.arr_0\na=np.load(X_TEST_FILE)\nX_test=a\na=np.load(Y_TEST_FILE)\nY_test=a\n\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=42)\n","d7365fa0":"print(X_train.shape)\nprint(Y_train.shape)\nprint(X_val.shape)\nprint(Y_val.shape)\nprint(X_test.shape)\nprint(Y_test.shape)","82d515ef":"def normalize_X(X):\n    X_norm=X\/255\n    return X_norm","c6dbeb93":"def preprocess_data(X_train,X_val,X_test,y_train,y_val,y_test):\n    X_train=normalize_X(X_train)\n    X_val=normalize_X(X_val)\n    X_test=normalize_X(X_test)\n    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n    X_val, y_val = shuffle(X_val, y_val, random_state=42)\n    X_test, y_test = shuffle(X_test, y_test, random_state=42)\n    return X_train,X_val,X_test,y_train,y_val,y_test","d79a671a":"X_train,X_val,X_test,Y_train,Y_val,Y_test=preprocess_data(X_train,X_val,X_test,Y_train,Y_val,Y_test)","7332e302":"\n\ndef input_and_run4(model,X_train,X_val,X_test,y_train,y_val,y_test,alpha=0.01,num_epochs=10):\n    \n    datagen = ImageDataGenerator(width_shift_range=0.2,height_shift_range=0.2,horizontal_flip=True)\n    datagen.fit(X_train)\n    \n    #compile model using accuracy to measure model performance\n    opt = keras.optimizers.Adam(learning_rate=alpha)\n    opt2=SGD(lr=alpha, momentum=0.9)\n    model.compile(loss='binary_crossentropy', optimizer=opt,metrics=['accuracy'])\n    \n    #train the model\n    #model.fit(X_train,y_train,validation_data=(X_val, y_val), epochs=num_epochs)\n    model.fit(datagen.flow(X_train, y_train),validation_data=(X_val, y_val), epochs=num_epochs)\n    \n    #Getting results\n    result = model.evaluate(X_train,y_train)\n    #print(result)\n    print(\"Training accuracy = \"+str(result[1]*100))\n    result = model.evaluate(X_val,y_val)\n    #print(result)\n    print(\"Validation accuracy = \"+str(result[1]*100))\n    result = model.evaluate(X_test,y_test)\n    #print(result)\n    print(\"Test accuracy = \"+str(result[1]*100))\n\n\n","831ca346":"model6 = Sequential()\nmodel6.add(VGG16(include_top=False, input_shape=(100, 100, 3)))\n# mark loaded layers as not trainable\nfor layer in model6.layers:\n    layer.trainable = False\n# add new classifier layers\n#flat1 = Flatten()(model.layers[-1].output)\n#class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n#output = Dense(1, activation='sigmoid')(class1)\n\nmodel6.add(Flatten())\nmodel6.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel6.add(Dropout(0.5))\nmodel6.add(Dense(1, activation='sigmoid'))\nprint(model6.summary())\ninput_and_run4(model6,X_train,X_val,X_test,Y_train,Y_val,Y_test,alpha=0.001,num_epochs=200)\n\n\n# define new model\n#model = Model(inputs=model.inputs, outputs=output)\n# compile model\n#opt = SGD(lr=0.001, momentum=0.9)\n#model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n#return model","4f34b06c":"model6.save(\"model6.h5\")\nprint(\"Saved model to disk\")","8472ff63":"a=4","2be6994a":"# The previous model gives us (learning_rate = 0.001, epochs = 200)\n\n# Accuracy in first epoch was 80% \n\n# TRAINING ACCURACY : 97.03%\n# VALIDATION ACCURACY : 87.81%\n# TEST ACCURACY : 87.83%","16eec93e":"## TRYING DATA AUGMENTATION","e4c73852":"# <div align=\"center\">STAGE V<\/div>","fe4d2047":"# Till last part we converted into numpy arrays and stored them. Now we inputted the same arrays and we would read from them","42fb20bf":"# <div align=\"center\">STAGE IV<\/div>","8ceb393c":"# The previous model gives us (learning_rate = 0.002, epochs =200)\n# TRAINING ACCURACY : 99.8%\n# VALIDATION ACCURACY : 81.8%\n# TEST ACCURACY : 83.8%","843ee479":"## The previous model gives us (learning_rate = 0.001, epochs = 200)(using datagen iterator)\n# TRAINING ACCURACY : 98.55%\n# VALIDATION ACCURACY : 91.45%\n# TEST ACCURACY : 92.09%","ec63cabc":"## STAGE 1 = GENERATING NUMPY DATASETS AND SAVING THEM\n## STAGE 2 = USING THE NUMPY DATASETS TO RUN MODELS AND SAVING WEIGHTS\n## STAGE 3 = LOADING WEIGHTS OF ABOVE MODEL AND USING THEM\n## STAGE 4 = TRYING DATA AUGMENTATION BY USING DATASETS FROM STAGE 1\n## STAGE 5 = TRYING TRANSFER LEARNING","fe416611":"# DATA AUGMENTATION + TRANSFER LEARNING","65031851":"# <div align=\"center\">STAGE I<\/div>","2b9ac563":"# <div align=\"center\">STAGE III<\/div>","2e487ea5":"# The previous model gives us (learning_rate = 0.0001, epochs =20)\n# TRAINING ACCURACY : 99.7%\n# VALIDATION ACCURACY : 79.07%\n# TEST ACCURACY : 77.46%","c64e6aca":"# The previous model gives us (learning_rate = 0.001, epochs = 200)\n\n# Accuracy in first epoch was 80% \n\n# TRAINING ACCURACY : 100%\n# VALIDATION ACCURACY : 86.76%\n# TEST ACCURACY : 87.09%","d73f1a44":"# <div align=\"center\">STAGE VI<\/div>","c5b0382a":"# <div align=\"center\">STAGE II<\/div>","5d5e32c6":"# GETTING DATA INTO THE DIFFERENT SETS","b7de7f20":"# UTILITY FUNCTIONS"}}