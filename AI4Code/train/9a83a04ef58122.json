{"cell_type":{"f97a3a27":"code","d2734467":"code","d849cfdd":"code","87a61d4c":"code","59e36450":"code","906d13a1":"code","8c66f460":"code","f2fb7923":"code","cf33e6cb":"code","891242f2":"code","7442a2c0":"code","24045055":"code","12d4827d":"code","738cb1c9":"code","7eb3c544":"code","a3f28041":"code","38c3707f":"code","eb27611e":"code","2ce70118":"code","f86399c8":"code","b301124c":"code","8e016b50":"code","ac0b56f6":"code","480ee47b":"code","db614655":"code","9c538460":"code","ba851049":"code","e06a0bf1":"markdown","abbab520":"markdown","6b39d0cb":"markdown","eaf59866":"markdown","8e02f7ce":"markdown","a7b2278a":"markdown","6b643072":"markdown","7933f008":"markdown","b02d8d58":"markdown","37b57e9e":"markdown","bf1ae48b":"markdown","3c7d0671":"markdown","9f3360f2":"markdown","cf6fffcf":"markdown","4053b8d8":"markdown","6fe87ed7":"markdown"},"source":{"f97a3a27":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pylab as plt","d2734467":"from pathlib import Path\n\ninput_path = Path(\".\").absolute().parent \/ \"input\"\ntrain_path = input_path \/ \"train\"\ntest_path = input_path \/ \"test\"\n\ntrain_df = pd.read_csv(input_path \/ \"train.csv\")","d849cfdd":"train_df.head()","87a61d4c":"from PIL import Image\n# pip install image-dataset-viz\nfrom image_dataset_viz import render_datapoint","59e36450":"def read_image(data_id, is_train=True):    \n    path = train_path if is_train else test_path\n    path = (path \/ \"images\" \/ \"{}.png\".format(data_id))\n    img = Image.open(path)\n    img = img.convert('RGB')\n    return img\n    \ndef read_mask(data_id, is_train=True):\n    path = train_path if is_train else test_path\n    path = (path \/ \"masks\" \/ \"{}.png\".format(data_id))    \n    img = Image.open(path)\n    bk = Image.new('L', size=img.size)\n    g = Image.merge('RGB', (bk, img.convert('L'), bk))\n    return g\n\nimg = read_image(\"34e51dba6a\")\nmask = read_mask(\"34e51dba6a\")","906d13a1":"rimg = render_datapoint(img, mask, blend_alpha=0.3)\nprint(rimg.size)\nrimg","8c66f460":"data_ids = train_df['id'].values.tolist()\n\n\nfrom image_dataset_viz import DatasetExporter\n\n\nde = DatasetExporter(read_image, read_mask, blend_alpha=0.3, n_cols=20, max_output_img_size=(100, 100))\nde.export(data_ids, data_ids, \"train_dataset_viz\")","f2fb7923":"!ls train_dataset_viz","cf33e6cb":"ds_image = Image.open(\"train_dataset_viz\/dataset_part_0.png\")","891242f2":"ds_image","7442a2c0":"depths_df = pd.read_csv(input_path \/ \"depths.csv\")","24045055":"import tqdm\nimport hashlib\n\nmd5_df = pd.DataFrame(data=depths_df['id'], columns=['id'], index=depths_df.index)\ndata = []\nis_train = []\nfor data_id in tqdm.tqdm(md5_df['id'].values):    \n    p = (train_path \/ \"images\" \/ \"{}.png\".format(data_id))\n    b = True\n    if not p.exists():\n        p = (test_path \/ \"images\" \/ \"{}.png\".format(data_id))    \n        b = False\n    image_file = p.open('rb').read()\n    data.append(hashlib.md5(image_file).hexdigest())\n    is_train.append(b)    \nmd5_df['hash'] = data\nmd5_df['is_train'] = is_train","12d4827d":"md5_df.head()","738cb1c9":"train_duplicated_mask = md5_df[md5_df['is_train'] == True]['hash'].duplicated()\ntrain_duplicates = md5_df[(md5_df['is_train'] == True) & train_duplicated_mask]\ntrain_duplicates['hash'].unique(), train_duplicates['id'].values[:3], len(train_duplicates['id'])","7eb3c544":"read_image('e82421363e', is_train=True)","a3f28041":"rle_mask_for_black_img = train_df[train_df['id'].isin(train_duplicates['id'])]['rle_mask']\nrle_mask_for_black_img.isnull().all()","38c3707f":"test_duplicated_mask = md5_df[md5_df['is_train'] == False]['hash'].duplicated()\ntest_duplicates = md5_df[(md5_df['is_train'] == False) & test_duplicated_mask]\ntest_duplicates['hash'].unique(), test_duplicates['id'].values[:3], len(test_duplicates['id'])","eb27611e":"read_image('5e52f098d9', is_train=False)","2ce70118":"train_mask = md5_df['is_train'] == True\ntrain_md5_df = md5_df[train_mask]\ntest_md5_df = md5_df[~train_mask]\nsame_hash_mask = test_md5_df['hash'].isin(train_md5_df['hash'])\ntest_md5_df[same_hash_mask]['hash'].unique(), test_md5_df[same_hash_mask]['id'].values[:3]","f86399c8":"read_image('353e010b7b', is_train=False)","b301124c":"depth_df = pd.read_csv(input_path \/ \"depths.csv\", index_col='id')\ndepth_df.head()","8e016b50":"non_nan_mask = ~train_df['rle_mask'].isnull()\n\ndef rle_to_len(mask_str):\n    mask = mask_str.split(' ')\n    return len(mask)\n\ntrain_df.loc[non_nan_mask, 'rle_mask_len'] = train_df.loc[non_nan_mask, 'rle_mask'].apply(rle_to_len)","ac0b56f6":"def get_depth(data_id):\n    return depth_df.loc[data_id, 'z']\n\ntrain_df.loc[non_nan_mask, 'z'] = train_df.loc[non_nan_mask, 'id'].apply(get_depth)","480ee47b":"vertical_masks = train_df[train_df['rle_mask_len'] < 3]\nvertical_masks.head()","db614655":"data_id = \"d4d34af4f7\"\nimg = read_image(data_id)\nmask = read_mask(data_id)\n\nplt.figure(figsize=(7, 7))\nplt.subplot(121)\nplt.title(\"Depth = {}\".format(depth_df.loc[data_id, 'z']))\nplt.imshow(img)\nplt.subplot(122)\nplt.imshow(mask)","9c538460":"data_id = \"7845115d01\"\nimg = read_image(data_id)\nmask = read_mask(data_id)\n\nplt.figure(figsize=(7, 7))\nplt.subplot(121)\nplt.title(\"Depth = {}\".format(depth_df.loc[data_id, 'z']))\nplt.imshow(img)\nplt.subplot(122)\nplt.imshow(mask)","ba851049":"data_id = \"b525824dfc\"\nimg = read_image(data_id)\nmask = read_mask(data_id)\n\nplt.figure(figsize=(7, 7))\nplt.subplot(121)\nplt.title(\"Depth = {}\".format(depth_df.loc[data_id, 'z']))\nplt.imshow(img)\nplt.subplot(122)\nplt.imshow(mask)","e06a0bf1":"All duplicated images between train and test dataset are just black images","abbab520":"# Train Dataset visualization\n\nIdea of the notebook is to:\n- visualize train images with masks to have an overview of the training dataset\n- check md5 hashes between train\/test datasets\n\n","6b39d0cb":"All duplicated images in the test dataset are just black images","eaf59866":"Now let's 'export' whole train dataset in a few images. So that you can download images and explore them using your favorite image viewer.","8e02f7ce":"Yes, they all have NaN mask","a7b2278a":"## Check same images between train and test","6b643072":"Let's display a single image and mask","7933f008":"### Let's check duplicates between training and test datasets","b02d8d58":"Compute hashes for train\/test datasets","37b57e9e":"### Let's check duplicates in the test dataset","bf1ae48b":"All duplicated images in the training dataset are just black images. Do they have non-null masks ?","3c7d0671":"Let's open one output image with PIL. But again, it's better to download these images from the output folder and explore locally with an image viewer.","9f3360f2":"### Let's check duplicates in the training dataset","cf6fffcf":"## Train dataset visualization","4053b8d8":"## Rectangular masks\n\nThere masks defined as rectangles and could look weird on the background image. More information can be found in the [following thread](https:\/\/www.kaggle.com\/c\/tgs-salt-identification-challenge\/discussion\/61720).","6fe87ed7":"However as it stated in [the comment](https:\/\/www.kaggle.com\/c\/tgs-salt-identification-challenge\/discussion\/61720#362630) :\n\n> Salt is very difficult to locate accurately, and if faced with ambiguity, a geophysicist will draw the simplest possible polygon to define it. Since salt can play havoc on time to depth conversions (velocity models), you can get some really weird vertical features in the seismic\n\nWe should carefully select the vertical masks:"}}