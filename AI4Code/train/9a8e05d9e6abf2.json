{"cell_type":{"0ff49e49":"code","d18d08c6":"code","99abc7d6":"code","3653d0e5":"code","481edfaa":"code","7229da1d":"code","2fb7f300":"code","bd794633":"code","b4d4eef6":"code","05b5ad66":"code","86070ddb":"code","c4d4f1e3":"code","efcb1edc":"code","16a8607e":"code","a111b608":"code","3ee6e4e6":"code","58644397":"code","bea74fce":"code","4290aa65":"code","0643ef51":"code","7cc54fc7":"markdown","9473e20c":"markdown","c4f14322":"markdown","735d2d81":"markdown","e14316e4":"markdown","09c3e62b":"markdown","e6be1504":"markdown","65708b3e":"markdown","947b7ad0":"markdown","2e5a073a":"markdown","34e3dbcf":"markdown","8d5ed5dd":"markdown","4066135d":"markdown"},"source":{"0ff49e49":"#Import necessary libraries\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,confusion_matrix, classification_report\nfrom sklearn.tree import DecisionTreeClassifier\n\n%matplotlib inline\n\n#Read CSVs and make backup\ntrain_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain_df_copy = train_df.copy()\n\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_df_copy = test_df.copy()\n\nsub_df = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\nsub_df.copy = sub_df.copy()","d18d08c6":"#Initial data glimpse\ntrain_df.info()","99abc7d6":"#Initial dat glimpse\ntrain_df.head()","3653d0e5":"#Initial data glimpse\ntrain_df.describe()","481edfaa":"#Initial data visualization\nsns.pairplot(train_df, hue='Survived')","7229da1d":"#Manipulate Age data\ntrain_df['Age'].fillna(inplace=True,value=train_df['Age'].mean())\n\n#Manipulate categorical data\ntrain_df['Sex'] = train_df['Sex'].astype('category')\n\n#Combine columns\ntrain_df['Fsize'] = train_df['SibSp'] + train_df['Parch']\n\n#Delete columns\ntrain_df.drop(columns=['PassengerId','Name','Ticket','Cabin','Embarked','SibSp','Parch'],inplace=True)\n\n#Prepare data\ntrain_df = pd.get_dummies(train_df,columns=['Sex'])\ntrain_df.drop(columns=['Sex_female'],inplace=True)\n\n#Split Data\nx = train_df.loc[:,train_df.columns!='Survived']\ny = train_df['Survived']\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=42)\n","2fb7f300":"#Same for Test Data\ntest_df['Age'].fillna(inplace=True,value=test_df['Age'].mean())\ntest_df['Sex'] = test_df['Sex'].astype('category')\ntest_df['Fsize'] = test_df['SibSp'] + test_df['Parch']\ntest_df.drop(columns=['PassengerId','Name','Ticket','Cabin','Embarked','SibSp','Parch'],inplace=True)\ntest_df = pd.get_dummies(test_df,columns=['Sex'])\ntest_df.drop(columns=['Sex_female'],inplace=True)\ntest_df['Fare'].fillna(inplace=True, value=x_test['Age'].mean())\n#x_test = test_df.loc[:,test_df.columns]","bd794633":"#Train Model\nr_model = LogisticRegression(solver='liblinear')\nr_model.fit(x_train,y_train)\n\n#Use model to make predictions\nr_pred = r_model.predict(x_test)\npred_prob = r_model.predict_proba(x_test)\n\n#Model Accuracy\nr_acc = r_model.score(x_test,y_test)","b4d4eef6":"#Visualize model performance\nconfusion_matrix(y_test, r_pred)","05b5ad66":"#Show accuracy with other model performance data\nprint(classification_report(y_test,r_pred))","86070ddb":"#Need more research on this function. I believe it measures how model performs in real world.\nfrom sklearn.model_selection import cross_val_score\n\nprint(cross_val_score(r_model, x_train, y_train, cv=3))","c4d4f1e3":"from sklearn.ensemble import RandomForestRegressor\n\nrf_model = RandomForestRegressor(n_estimators=100, random_state=1)\nrf_model.fit(X_train,y_train)\nrf_pred = rf_model.predict(X_test)\n\n#Show accuracy with other performance data\nrf_acc = rf_model.score(X_test,y_test)","efcb1edc":"#Visualize performance - I want to find a better visual for this!\n#confusion_matrix(y_test, rf_pred)","16a8607e":"from sklearn.svm import SVC\n\nsvm_model = SVC(gamma = 'auto')\nsvm_model.fit(x_train,y_train)\nsvm_pred = svm_model.predict(x_test)\nsvm_acc = svm_model.score(x_test,y_test)","a111b608":"#Visualize model performance\nconfusion_matrix(y_test, svm_pred)\nprint(classification_report(y_test,svm_pred))","3ee6e4e6":"from sklearn.naive_bayes import GaussianNB\n\ngnb_model = GaussianNB()\ngnb_model.fit(x_train, y_train)\ngnb_pred = gnb_model.predict(x_test)\ngnb_acc = gnb_model.score(x_test,y_test)","58644397":"print(classification_report(y_test,gnb_pred))","bea74fce":"from sklearn.linear_model import SGDClassifier\n\nsgd_model = SGDClassifier()\nsgd_model.fit(x_train,y_train)\nsgd_pred = sgd_model.predict(x_test)\nsgd_acc = sgd_model.score(x_test,y_test)","4290aa65":"models = pd.DataFrame({\n    'Model': ['Logistical Regression', 'Random Forest', 'Support Vector Machine', \n              'Naive Bayes', 'Stochastic Gradient Descent'],\n    'Score': [r_acc, rf_acc, svm_acc, \n              gnb_acc, sgd_acc]})\nmodels.sort_values(by='Score', ascending=False)","0643ef51":"#submission = pd.DataFrame({\"PassengerId\": test_df[\"PassengerId\"],\"Survived\": Y_pred})\n# submission.to_csv('..\/output\/submission.csv', index=False)","7cc54fc7":"<h3>4.4 Naive Bayes<\/h3>","9473e20c":"<h3>4.3 Support Vector Machine<\/h3>","c4f14322":"<h1>8. Submission<\/h1>","735d2d81":"<h3>4.5 Stochastic Gradient Descent<\/h3>","e14316e4":"<h3>4.2 Random Forest<\/h3>","09c3e62b":"<h1>4. Choose Model<\/h1>\n    <p> Two Classification Models<\/p>\n    <h3>4.1 Logistical Regression<\/h3>","e6be1504":"<h1>1. Import Data<\/h1>\n<p><\/p>","65708b3e":"<h1>3. Manipulate Data<\/h1>\n<p><\/p>","947b7ad0":"<h1>7. Evaluate Model<\/h1>","2e5a073a":"<h1>5. Tune Model<\/h1>","34e3dbcf":"<h1>2. Explore Data<\/h1>\n<p><\/p>","8d5ed5dd":"<p>The plots above show me which variables I would like to keep or throw out. The Age variable is among those I would like to keep due to the relationship between younger passengers and survivability. I will have to do something about the missing values. There is currently 714 out of 891 values in the Age column.<\/p>","4066135d":"<h1>6. Test New Model<\/h1>\n"}}