{"cell_type":{"3c782ac1":"code","00328420":"code","65bec9d2":"code","a00a2a43":"code","bf471636":"code","2a3d3efb":"code","16a06983":"code","5daf6e8c":"code","ffbaa4c0":"code","3a0f85cd":"code","d1491111":"code","5234bfe8":"code","f62cf283":"code","0d7d1957":"code","4716b991":"code","910e9807":"code","34f0b96d":"code","defbfad7":"code","ae35b773":"code","839fc8fe":"code","d4016883":"code","71fe8e92":"code","a56f5feb":"code","2d4675fe":"code","19a08cef":"code","8de22998":"code","487d6f25":"code","4bcb0fef":"code","59bf2bee":"code","77520c43":"code","688232d3":"code","a9113897":"code","466e36df":"code","ef19eedf":"code","726ad6d1":"code","edfb769c":"code","2c5971bb":"code","0e829deb":"code","a132c2b9":"code","df72e212":"code","73ad706d":"code","c554560f":"code","03d613b0":"code","8e85f491":"code","b9e52a20":"code","8b699158":"code","c5525004":"code","7e086804":"code","0e3d2170":"code","d8cfbe19":"markdown","183b423f":"markdown","c7de1530":"markdown","b3f373e9":"markdown","9cd001e9":"markdown","afa1aaae":"markdown","96e82254":"markdown","1b6769fd":"markdown","b2e7932e":"markdown"},"source":{"3c782ac1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","00328420":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\nfrom scipy.stats import boxcox\nfrom scipy.special import inv_boxcox\nimport scipy.stats as stat\nimport pylab\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error, mean_absolute_error\nfrom sklearn.model_selection import cross_val_score,train_test_split, GridSearchCV\n\n\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor, ExtraTreesRegressor,AdaBoostRegressor\nfrom sklearn.linear_model import Lasso,LassoLarsIC, BayesianRidge, LinearRegression, LassoLars\nfrom sklearn.linear_model import ElasticNetCV,ElasticNet\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom xgboost.sklearn import XGBRegressor,XGBClassifier\nfrom sklearn.svm import SVR\nfrom catboost import CatBoostRegressor","65bec9d2":"%matplotlib inline\nsns.set_style('darkgrid')\n\n# display maximum 200 columns\npd.set_option('display.max_columns', 200)\npd.set_option('display.width', 1000)","a00a2a43":"train_data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')","bf471636":"train_data.info()\nprint('='*50,)\ntest_data.info()","2a3d3efb":"print('train data contains',train_data.shape[0], 'records and',train_data.shape[1], 'columns')\nprint('test data contains',test_data.shape[0], 'records and',test_data.shape[1], 'columns')","16a06983":"train_data.head()","5daf6e8c":"test_data.head()","ffbaa4c0":"numerical_col = [i for i in train_data.columns if train_data[i].dtype != object]\ncatagorical_col = [i for i in train_data.columns if train_data[i].dtype == object]\nprint('train data contains',len(numerical_col), 'numerical columns and ',len(catagorical_col),'catagorical columns')","3a0f85cd":"def missing_col_summary(df):\n    null = df.isnull().sum()\n    not_null = df.notnull().sum()\n    return pd.DataFrame({  'Total_missing':null[null>0],\n                           'missing %': round((null[null>0]\/(df.shape[0]))*100,2),\n                           'Total_non_missing':not_null[not_null!=df.shape[0]],\n                           'total_records':null[null>0]+not_null[not_null!=df.shape[0]]})","d1491111":"# Summary of missing columns on test & train \nprint('training_data : \\n',missing_col_summary(train_data),'\\n','='*75,'\\n','test_data : \\n',missing_col_summary(test_data))","5234bfe8":"  plt.figure(figsize=(15,6))\n  plt.subplot(1,2,1)\n  plt.hist(train_data['SalePrice'],bins=30)\n  plt.title('Histogram')\n\n  plt.subplot(1,2,2)\n  stat.probplot(train_data['SalePrice'],dist='norm',plot=pylab)\n  plt.show()","f62cf283":"train_data[\"SalePrice\"],fitted_lambda= boxcox(train_data[\"SalePrice\"],lmbda=None)","0d7d1957":"  plt.figure(figsize=(15,6))\n  plt.subplot(1,2,1)\n  plt.hist(train_data['SalePrice'],bins=30)\n  plt.title('Histogram')\n\n  plt.subplot(1,2,2)\n  stat.probplot(train_data['SalePrice'],dist='norm',plot=pylab)\n  plt.show()","4716b991":"for i in numerical_col:\n  print(i)\n  print(train_data[i].sort_values(ascending=False).head(10))\n  print('='*40)","910e9807":"train_data.drop(train_data.index[[297,706,249,335,346,1298,1089,325,1146,1043]], inplace=True)","34f0b96d":"plt.figure(figsize=(25,20))\nsns.heatmap(train_data[numerical_col].corr(),annot=True)\nplt.show()","defbfad7":"# Append test & train dataset\ndf = pd.concat([train_data.iloc[:,:-1], test_data],sort = False)\n\n# separating target column\ny = train_data['SalePrice']","ae35b773":"# drop columns where more than 80% records are missing\n\ncolumn_to_drop = ['Alley','PoolQC','Fence','MiscFeature']\ndf.drop(column_to_drop,axis = 1,inplace = True)","839fc8fe":"df = df.drop(['GarageYrBlt','YearBuilt','Id','GarageArea', 'TotRmsAbvGrd', '1stFlrSF'],axis=1)","d4016883":"df['MSSubClass'] = df['MSSubClass'].apply(str)\ndf['YearRemodAdd'] = df['YearRemodAdd'].astype(str)\ndf['YrSold'] = df['YrSold'].astype(str)","71fe8e92":"column_name = ['FireplaceQu','MasVnrType','Electrical']\nbsmt_garage = [i for i in df.columns if ('bsmt' in i.lower()) or ('garage' in i.lower())]\ncolumn_name.extend(bsmt_garage)\n\nfor i in column_name:\n  if df[i].dtype == object:\n    df[i] = df[i].fillna('Missing')\n  elif df[i].dtype == np.float64:\n    df[i] = df[i].fillna(0)","a56f5feb":"def update_by_overallqual(data,column):\n  for i in data['OverallQual'].unique():\n    data[data['OverallQual']==i] = data[data['OverallQual']==i].fillna({column:data[data['OverallQual']==i][column].median()})","2d4675fe":"update_by_overallqual(df,'LotFrontage')\nupdate_by_overallqual(df,'MasVnrArea')","19a08cef":"numerical_col = [i for i in df.columns if df[i].dtype != object]\ncatagorical_col = [i for i in df.columns if df[i].dtype == object]\nprint('train data contains',len(numerical_col), 'numerical columns and ',len(catagorical_col),'catagorical columns')","8de22998":"train, test = df.iloc[:1450,:] ,df.iloc[1450:,:]","487d6f25":"# Summary of missing columns on test & train \nprint('training_data : \\n',missing_col_summary(train),'\\n','='*75,'\\n','test_data : \\n',missing_col_summary(test))","4bcb0fef":"column_contains_missing =  [i for i in test.columns if test[i].isnull().sum()>0]\n\ndef encoding(x):\n  encoder = LabelEncoder()\n  return encoder.fit_transform(x)\n\ndef encoding_values(df):\n  for i in df.columns:\n    if df[i].dtype == object:\n      df.loc[:,i] = encoding(df.loc[:,i])\n\ntrain_X = train[[i for i in train.columns[:-1] if i not in column_contains_missing]]\nencoding_values(train_X)","59bf2bee":"for i in column_contains_missing:\n  print(\"========================={}=========================\".format(i))\n\n  print('Original Records','\\n','*'*30)\n  print(train[i].value_counts())\n  test_X = test[test[i].isnull()][train_X.columns]\n  encoding_values(test_X)\n  train_y = encoding(train[i])\n  print('LabelEncoded Records','\\n','*'*30)\n  print(pd.DataFrame(train_y)[0].value_counts())\n\n  model = XGBClassifier(random_state=42)\n  model.fit(train_X, train_y)\n  print(model.score(train_X, train_y))\n  print('Predicted Vale: ', model.predict(test_X))","77520c43":"# test data has been classified based on XGBClassifier\ntest = test.fillna({'MSZoning' : 'RL',\n                    'Utilities':'AllPub',\n                    'Exterior1st' : 'MetalSd', \n                    'Exterior2nd':'MetalSd',\n                    'KitchenQual':'Fa',\n                    'Functional':'Typ',\n                    'SaleType':'WD'})","688232d3":"test.columns == train.columns","a9113897":"for i in train.columns:\n  if test[i].dtype != train[i].dtype:\n    print(i)","466e36df":"# Applying LabelEncoder\n\nencoding_values(train)\nencoding_values(test)","ef19eedf":"train.head()","726ad6d1":"test.head()","edfb769c":"X = train\n\n# SalePrice is y value\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","2c5971bb":"scaler = RobustScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","0e829deb":"# ML models\nmodel_classifiers = {'K-Nearest_Neighbors': KNeighborsRegressor(),\n                     'LinearRegression'   : LinearRegression(),\n                     'Gradient_Boosting'  : GradientBoostingRegressor(),\n                     'AdaBoost Regressor' : AdaBoostRegressor(),\n                     'LassoLarsIC'        : LassoLarsIC(),\n                     'Random_Forest'      : RandomForestRegressor(),\n                     'BayesianRidge'      : BayesianRidge(),\n                     'Lasso'              : Lasso(),\n                     'ElasticNet'         : ElasticNet(),\n                     'ElasticNetCV'       : ElasticNetCV(),\n                     'XGBRegressor'       : XGBRegressor(objective ='reg:linear'\n                                            , verbosity = 0, random_state=42),\n                     'Support Vector Machine':SVR(),\n                     'ExtraTreesRegressor':ExtraTreesRegressor()\n                     }","a132c2b9":"# Function to evaluate models\ndef model_evaluate(x_train_df,y_train_df,x_test_df,y_test_df,model_list):\n\n  train_score = []\n  test_score = []\n  mse = []\n  msle = []\n  mae =[]\n  for i in model_list.values():\n    i.fit(x_train_df,y_train_df)\n    train_score.append(i.score(x_train_df,y_train_df))\n    test_score.append(i.score(x_test_df,y_test_df))\n    mse.append(mean_squared_error(y_test_df,i.predict(x_test_df)))\n    msle.append(mean_squared_log_error(y_test_df,i.predict(x_test_df)))\n    mae.append(mean_absolute_error(y_test_df,i.predict(x_test_df)))\n\n\n  return pd.DataFrame({'Model Name'    : [ i for i in model_list.keys()],\n                       'Training Score': train_score,\n                       'Test Score'    : test_score,\n                       'MSE'           : mse,\n                       'RMSE'          : np.sqrt(mse),\n                       'MSLE'          : msle,\n                       'RMSLE'         : np.sqrt(msle),\n                       'MAE'           : mae\n                       }\n                      )","df72e212":"model_evaluate(X_train,y_train,X_test,y_test,model_classifiers)","73ad706d":"model_lst = []\ncross_val = []\nfor i in model_classifiers.keys():\n  model_lst.append(i)\n  cv_scores = cross_val_score(model_classifiers[i],X,y, cv=5)\n  cross_val.append(np.mean(cv_scores))\npd.DataFrame({'Model Name': model_lst, 'cross_val_score':cross_val})","c554560f":"# model to evaluate results\ndef evaluate(actual_value,predictions):\n  print(\"Mean Squared Error:\"+str(mean_squared_error(actual_value,predictions)))\n  print(\"Root Mean Squared Error:\"+str(np.sqrt(mean_squared_error(actual_value,predictions))))\n  print(\"Mean Squared Log Error:\"+str(mean_squared_log_error(actual_value,predictions)))\n  print(\"Root Mean Squared Log Error:\"+str(np.sqrt(mean_squared_log_error(actual_value,predictions))))\n  print(\"Mean Absolute Error:\"+str(mean_absolute_error(actual_value,predictions)))","03d613b0":"model = GradientBoostingRegressor()\nmodel.fit(X_train,y_train)","8e85f491":"evaluate(y_test,model.predict(X_test))","b9e52a20":"plt.figure(figsize=(8,5))\nplt.scatter(y_test,model.predict(X_test),ec='black',alpha = 0.3)\nplt.plot(y_test,y_test, 'r')\nplt.show()","8b699158":"scaler = RobustScaler()\n\nX_train = scaler.fit_transform(train)\nX_test = scaler.transform(test)\ny_train = y","c5525004":"model = ElasticNetCV()\n#model = GradientBoostingRegressor()\nmodel.fit(X_train,y_train)","7e086804":"predicted_value = pd.DataFrame(inv_boxcox(model.predict(X_test),fitted_lambda),columns=['SalePrice'])","0e3d2170":"pd.concat([test_data,predicted_value],axis=1)[['Id','SalePrice']].to_csv('submission.csv',index=False)","d8cfbe19":"# Apply Models","183b423f":"## Exploratory data analysis : train & test data","c7de1530":"### Drop columns","b3f373e9":"### Separating test & train column","9cd001e9":"### Outlier Treatment","afa1aaae":"## Missing Value Treatment","96e82254":"### Scaling and normalization","1b6769fd":"# Applying model in train data","b2e7932e":"### Classify Categorical Variable by ML prediction"}}