{"cell_type":{"d5019ec3":"code","775a0558":"code","a035058c":"code","d1ade915":"code","ff91a5e4":"code","7847b48e":"code","4872aa97":"code","8091efd5":"code","e177fa91":"code","a5dbcc5a":"code","6c737a54":"code","cfeef913":"markdown","a252f3e2":"markdown","919f277f":"markdown","ced834be":"markdown","94e28a92":"markdown","c8ff8708":"markdown","dbf3a440":"markdown","e9f66fef":"markdown","a55e1a75":"markdown","0e35272e":"markdown"},"source":{"d5019ec3":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n        print(dirname)","775a0558":"import numpy as np\nimport pandas as pd\nimport cv2\nfrom tqdm import tqdm_notebook as tqdm","a035058c":"def get_image_names(dataframe) : \n    image_names = dataframe[\"image_name\"].values\n    image_names = image_names + \".jpg\"\n    return image_names","d1ade915":"def get_info(image_names) : \n    image_names = np.array(image_names)\n    \n    print(\"Length = \", len(image_names))\n    print(\"Type = \", type(image_names))\n    print(\"Shape = \", image_names.shape)\n    \n    return image_names","ff91a5e4":"from scipy.stats import skew\n\ndef extract_information(image_names, directory) : \n    image_statistics = pd.DataFrame(index = np.arange(len(image_names)),\n                                    columns = [\"image_name\", \"path\", \"rows\", \"columns\", \"channels\", \n                                              \"image_mean\", \"image_standard_deviation\", \"image_skewness\",\n                                              \"mean_red_value\", \"mean_green_value\", \"mean_blue_value\"])\n    i = 0 \n    for name in tqdm(image_names) : \n        path = os.path.join(directory, name)\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        image_statistics.iloc[i][\"image_name\"] = name\n        image_statistics.iloc[i][\"path\"] = path\n        image_statistics.iloc[i][\"rows\"] = image.shape[0]\n        image_statistics.iloc[i][\"columns\"] = image.shape[1]\n        image_statistics.iloc[i][\"channels\"] = image.shape[2]\n        image_statistics.iloc[i][\"image_mean\"] = np.mean(image.flatten())\n        image_statistics.iloc[i][\"image_standard_deviation\"] = np.std(image.flatten())\n        image_statistics.iloc[i][\"image_skewness\"] = skew(image.flatten())\n        image_statistics.iloc[i][\"mean_red_value\"] = np.mean(image[:,:,0])\n        image_statistics.iloc[i][\"mean_green_value\"] = np.mean(image[:,:,1])\n        image_statistics.iloc[i][\"mean_blue_value\"] = np.mean(image[:,:,2])\n        \n        i = i + 1\n        del image\n        \n    return image_statistics","7847b48e":"train_dir = \"\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/train\/\"\ntrain = pd.DataFrame(pd.read_csv(\"\/kaggle\/input\/siim-isic-melanoma-classification\/train.csv\"))\ntrain.head()","4872aa97":"image_names = get_image_names(train)\nimage_names = get_info(image_names)","8091efd5":"#image_statistics = extract_information(image_names[0:5000], train_dir) # repeat this for image_names[5000:10k], image_names[10k-15k]...so on till 33126\n#image_statistics.to_csv(\"melanoma_image_statistics_compiled_01\", index = False)# save each one. I have computed it all beforehand, so wrote only one for instance.   ","e177fa91":"test_dir = \"\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/test\/\"\ntest = pd.DataFrame(pd.read_csv(\"\/kaggle\/input\/siim-isic-melanoma-classification\/test.csv\"))\ntest.head()","a5dbcc5a":"image_names = get_image_names(test)\nimage_names = get_info(image_names)","6c737a54":"#image_statistics = extract_information(image_names[5000:10982], test_dir)\n#image_statistics.to_csv(\"melanoma_image_statistics_compiled_test_02\", index = False)   ","cfeef913":"You may not need to run it as its heavily time taking.\n\nThe entire dataset obtained as a result of this notebook is available at :\n\n****\n### **https:\/\/www.kaggle.com\/fireheart7\/melanoma-image-insights** \n****\n\nDo upvote it if you find it useful!!","a252f3e2":"Uncomment these!","919f277f":"# Melanoma Classification : Dataset Preparation\n\nBefore going any further, this EDA is inspired by Laura Fink's notebook :\n\n**https:\/\/www.kaggle.com\/allunia\/don-t-turn-into-a-smoothie-image-statistics**\n\nI found this way highly useful for subsequent analysis where image datasets are concerned. Although, these pre-EDA `additional` dataset creation steps happen to take a lot of time. So, either you can manipulate and create your own, or you can use mine for your analysis.\n\nThe entire dataset obtained as a result of this notebook is available at :\n\n****\n### **https:\/\/www.kaggle.com\/fireheart7\/melanoma-image-insights** \n****\n\n## Notebook I of III\n\nThis notebook is the I one in my series of work in this competition. As always shout out to amazing kernel authors present here at kaggle!! I got loads of inspiration from them. I believe this is the best thing about the ML community. The extent of collaboration and guidance one can seek here is inexplicable!!\n\n\n## ***'Every image tells a story.'*** \n\n![image.png](attachment:image.png) \n\nHence, it is of paramount importance to understand the images in our dataset! By the end of this notebook : \n* We will create several new csv files encapsulating information about our melanoma images in training as well as test set.\n* Features such as Image mean, mean channel intensities, skewness, ... are incorporated in the dataframe. \n* These csv can then be used as independent additional datasets for the melanoma competition.\n\n****\nNow, time for the biggest question : \n\n## What's wrong with this guy ? Isn't one heavily imbalanced dataset more than sufficient to give us nightmares ?\n\nTrue enough! If you had the pleasure to go through the melanoma dataset provided for this competition, you will find there are a bunch load of features given such as male\/female, age, and so on.. However, features central to our images such as mean intensities, skewness, standard deviation are missing which heavily influences our analysis. So, in order to analyze them, it's better to record all the features we need(from the image) in one dataframe and store it as .csv file.\n\n*Note : Due to time crunch and RAM constraint, I created 6 csv for training images and 2 for test. We will just merge all training ones into one during our EDA and subsequent training in this EDA_cum_preprocessing notebook :*\n\n***https:\/\/www.kaggle.com\/fireheart7\/melanoma-eda-cum-preprocessing*** \n\n*Once again, thanks to the Kaggle community for all the inspiration!*\n\nHere we go!!","ced834be":"Use the above function to create train and test image statistics file. Rest is pretty much intuitive :-)","94e28a92":"![image.png](attachment:image.png) \n","c8ff8708":"Uncomment these!! I have saved several csv files, each having information on about 5000 images.","dbf3a440":"Here, we will design our custom dataframe we have been bragging about since the inception of this notebook. \n* Then we will take each image name one by one from the aforementioned numpy array, load that particular image and compute the necessary statistical information.\n* All this will be appended in the custom dataframe.\n* In the end, `this dataframe is returned and saved as .csv file, so that we can directly import it as an external dataset`.","e9f66fef":"### **Now, all these csv files will be used as an external dataset in further EDA and preprocessing. The link to that notebook is given here :**\n\nLINK WILL BE UPDATED BY TOMORROW","a55e1a75":"This is also a helper function to :\n* Convert the image_names list into numpy array.\n* Print mandatory information about this numpy array such as its length, type and shape.","0e35272e":"This function will simply :\n* Get the image names from the dataframe provided(train\/test).\n* Add `.jpg` extension to them."}}