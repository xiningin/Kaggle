{"cell_type":{"d0dc4c8b":"code","d1bc8f92":"code","4aaf6048":"code","d1b3e401":"code","d73b117a":"code","57334bc8":"code","cb315ae5":"code","a6b483f8":"code","37557238":"code","61c830af":"code","1ccceeb8":"code","cc6616db":"code","b93610c1":"code","947d7d63":"code","62dc49c3":"code","c5fd42b8":"code","f2b36e61":"code","e05fc464":"code","d191b47f":"code","9abca61d":"code","88b457ae":"code","f1a8bf80":"code","d6d90dbd":"code","b091d2e5":"code","d52e9344":"code","0b435730":"code","9ca30a2e":"code","1970a6d1":"markdown","8bd47a39":"markdown","73f0039b":"markdown","c84f4309":"markdown","67d2570f":"markdown","53a6c789":"markdown","d9b3b1d2":"markdown","41387513":"markdown","aeed5d45":"markdown","d39f2b82":"markdown","170b980d":"markdown"},"source":{"d0dc4c8b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\nimport cv2\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\n# filter warnings\nwarnings.filterwarnings('ignore')\n\n# Any results you write to the current directory are saved as output.","d1bc8f92":"train_o = (\"\/kaggle\/input\/waste-classification-data\/DATASET\/TRAIN\/O\/\")\ntrain_r = (\"\/kaggle\/input\/waste-classification-data\/DATASET\/TRAIN\/R\/\")\nval_o = (\"\/kaggle\/input\/waste-classification-data\/DATASET\/TEST\/O\/\")\nval_r = (\"\/kaggle\/input\/waste-classification-data\/DATASET\/TEST\/0\/\")","4aaf6048":"import matplotlib.image as mpimg\nimg1=mpimg.imread('\/kaggle\/input\/waste-classification-data\/DATASET\/TRAIN\/O\/O_1.jpg')\nimg2=mpimg.imread('\/kaggle\/input\/waste-classification-data\/DATASET\/TRAIN\/R\/R_10.jpg')\nplt.subplot(1, 2, 1)    \nplt.imshow(img1) \nplt.axis('off')\nplt.subplot(1, 2, 2)\nplt.imshow(img2)\nplt.axis('off')","d1b3e401":"def get_all_images(folder, ext):\n    all_files = []\n    for file in os.listdir(folder):\n        \n        _,  file_ext = os.path.splitext(file)\n        \n        if ext in file_ext:\n            full_file_path = os.path.join(folder, file)\n            all_files.append(full_file_path)\n\n    return all_files","d73b117a":"filepath1 = \"\/kaggle\/input\/waste-classification-data\/DATASET\/TRAIN\/O\/\"\nfilepath2 = \"\/kaggle\/input\/waste-classification-data\/DATASET\/TRAIN\/R\/\"\nfilepath3 = \"\/kaggle\/input\/waste-classification-data\/DATASET\/TEST\/O\/\"\nfilepath4 = \"\/kaggle\/input\/waste-classification-data\/DATASET\/TEST\/R\/\"\n\no_train = get_all_images(filepath1, 'jpg')\nr_train = get_all_images(filepath2, 'jpg')\no_val = get_all_images(filepath3, 'jpg')\nr_val = get_all_images(filepath1, 'jpg')\n\nprint(\"o_train: {}\".format(len(o_train))),\nprint(\"r_train: {}\".format(len(o_train)))\nprint(\"o_val: {}\".format(len(o_train)))\nprint(\"r_val: {}\".format(len(o_train)))","57334bc8":"from PIL import Image\nimport cv2 \nfrom tqdm import tqdm \n\nimage_size = 64\n\nX1 = []\nX2 = []\nX3 = []\nX4 = []\n\nfor image in tqdm(os.listdir(filepath1)):\n    p = os.path.join(filepath1, image)\n    img = cv2.imread(p, cv2.IMREAD_GRAYSCALE) \n    img = cv2.resize(img, (image_size, image_size)).flatten() \n    X1.append(img)\n    \nfor image in tqdm(os.listdir(filepath2)):\n    p = os.path.join(filepath2, image)\n    img2 = cv2.imread(p, cv2.IMREAD_GRAYSCALE) \n    img2 = cv2.resize(img2, (image_size, image_size)).flatten() \n    X2.append(img2)\n    \nfor image in tqdm(os.listdir(filepath3)):\n    p = os.path.join(filepath3, image)\n    img3 = cv2.imread(p, cv2.IMREAD_GRAYSCALE) \n    img3 = cv2.resize(img3, (image_size, image_size)).flatten() \n    X3.append(img3)\n    \nfor image in tqdm(os.listdir(filepath4)):\n    p = os.path.join(filepath4, image)\n    img4 = cv2.imread(p, cv2.IMREAD_GRAYSCALE) \n    img4 = cv2.resize(img4, (image_size, image_size)).flatten() \n    X4.append(img4)\n\n# Convert to array    \nX1 = np.asarray(X1)    \nX2 = np.asarray(X2)\nX3 = np.asarray(X3)    \nX4 = np.asarray(X4)    ","cb315ae5":"# \"0\" for the organic food and \"1\" for the not.\nx = np.concatenate((X1[0:400],X2[0:400]), axis = 0)\n\nzero = np.zeros(400)\none = np.ones(400)\n\ny = np.concatenate((zero,one), axis = 0).reshape(-1,1)\nprint(\"x shape :\", x.shape)\nprint(\"y shape :\", y.shape)","a6b483f8":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.15,random_state=42)\nnumber_of_train=x_train.shape[0]\nnumber_of_test=x_test.shape[0]","37557238":"print(\"X train \",x_train.shape)\nprint(\"X test \",x_test.shape)","61c830af":"x_train = x_train.T\nx_test = x_test.T\ny_train = y_train.T\ny_test = y_test.T\nprint(\"x train: \",x_train.shape)\nprint(\"x test: \",x_test.shape)\nprint(\"y train: \",y_train.shape)\nprint(\"y test: \",y_test.shape)","1ccceeb8":"def sigmoid(z):\n    y_head = 1\/(1+np.exp(-z))\n    return y_head","cc6616db":"# intialize parameters and layer sizes\ndef initialize_parameters_and_layer_sizes_NN(x_train, y_train):\n    parameters = {\"weight1\": np.random.randn(3,x_train.shape[0]) * 0.1,\n                  \"bias1\": np.zeros((3,1)),\n                  \"weight2\": np.random.randn(y_train.shape[0],3) * 0.1,\n                  \"bias2\": np.zeros((y_train.shape[0],1))}\n    return parameters","b93610c1":"def forward_propagation_NN(x_train, parameters):\n\n    Z1 = np.dot(parameters[\"weight1\"],x_train) +parameters[\"bias1\"]\n    A1 = np.tanh(Z1)\n    Z2 = np.dot(parameters[\"weight2\"],A1) + parameters[\"bias2\"]\n    A2 = sigmoid(Z2)\n\n    cache = {\"Z1\": Z1,\n             \"A1\": A1,\n             \"Z2\": Z2,\n             \"A2\": A2}\n    \n    return A2, cache","947d7d63":"# Compute cost\ndef compute_cost_NN(A2, Y, parameters):\n    logprobs = np.multiply(np.log(A2),Y)\n    cost = -np.sum(logprobs)\/Y.shape[1]\n    return cost","62dc49c3":"# Backward Propagation\ndef backward_propagation_NN(parameters, cache, X, Y):\n\n    dZ2 = cache[\"A2\"]-Y\n    dW2 = np.dot(dZ2,cache[\"A1\"].T)\/X.shape[1]\n    db2 = np.sum(dZ2,axis =1,keepdims=True)\/X.shape[1]\n    dZ1 = np.dot(parameters[\"weight2\"].T,dZ2)*(1 - np.power(cache[\"A1\"], 2))\n    dW1 = np.dot(dZ1,X.T)\/X.shape[1]\n    db1 = np.sum(dZ1,axis =1,keepdims=True)\/X.shape[1]\n    grads = {\"dweight1\": dW1,\n             \"dbias1\": db1,\n             \"dweight2\": dW2,\n             \"dbias2\": db2}\n    return grads","c5fd42b8":"# update parameters\ndef update_parameters_NN(parameters, grads, learning_rate = 0.01):\n    parameters = {\"weight1\": parameters[\"weight1\"]-learning_rate*grads[\"dweight1\"],\n                  \"bias1\": parameters[\"bias1\"]-learning_rate*grads[\"dbias1\"],\n                  \"weight2\": parameters[\"weight2\"]-learning_rate*grads[\"dweight2\"],\n                  \"bias2\": parameters[\"bias2\"]-learning_rate*grads[\"dbias2\"]}\n    \n    return parameters","f2b36e61":"# prediction\ndef predict_NN(parameters,x_test):\n    # x_test is a input for forward propagation\n    A2, cache = forward_propagation_NN(x_test,parameters)\n    Y_prediction = np.zeros((1,x_test.shape[1]))\n    # if z is bigger than 0.5, our prediction is sign one (y_head=1),\n    # if z is smaller than 0.5, our prediction is sign zero (y_head=0),\n    for i in range(A2.shape[1]):\n        if A2[0,i]<= 0.5:\n            Y_prediction[0,i] = 0\n        else:\n            Y_prediction[0,i] = 1\n\n    return Y_prediction","e05fc464":"# 2 - Layer neural network\ndef two_layer_neural_network(x_train, y_train,x_test,y_test, num_iterations):\n    cost_list = []\n    index_list = []\n    #initialize parameters and layer sizes\n    parameters = initialize_parameters_and_layer_sizes_NN(x_train, y_train)\n\n    for i in range(0, num_iterations):\n         # forward propagation\n        A2, cache = forward_propagation_NN(x_train,parameters)\n        # compute cost\n        cost = compute_cost_NN(A2, y_train, parameters)\n         # backward propagation\n        grads = backward_propagation_NN(parameters, cache, x_train, y_train)\n         # update parameters\n        parameters = update_parameters_NN(parameters, grads)\n        \n        if i % 100 == 0:\n            cost_list.append(cost)\n            index_list.append(i)\n            print (\"Cost after iteration %i: %f\" %(i, cost))\n    plt.plot(index_list,cost_list)\n    plt.xticks(index_list,rotation='vertical')\n    plt.xlabel(\"Number of Iterarion\")\n    plt.ylabel(\"Cost\")\n    plt.show()\n    \n    # predict\n    y_prediction_test = predict_NN(parameters,x_test)\n    y_prediction_train = predict_NN(parameters,x_train)\n\n    # Print train\/test Errors\n    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n    return parameters\n\nparameters = two_layer_neural_network(x_train, y_train,x_test,y_test, num_iterations=1000)","d191b47f":"x_train, x_test, y_train, y_test = x_train.T, x_test.T, y_train.T, y_test.T","9abca61d":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential # initialize neural network library\nfrom keras.layers import Dense # build our layers library\n\ndef build_classifier():\n    classifier = Sequential()\n    classifier.add(Dense(units =128 , kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n    classifier.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu')) \n    classifier.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu')) \n    classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu')) \n    classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu')) \n    classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid')) \n    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) \n    return classifier               \n\nclassifier = KerasClassifier(build_fn = build_classifier, epochs = 50)\naccuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 4)  \nmean = accuracies.mean()\nvariance = accuracies.std()\nprint(\"Accuracy mean: \"+ str(mean))\nprint(\"Accuracy variance: \"+ str(variance))","88b457ae":"# libraries\nfrom keras.models import Sequential \nfrom keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nimport matplotlib.pyplot as plt\nfrom glob import glob","f1a8bf80":"train_path= \"\/kaggle\/input\/waste-classification-data\/DATASET\/TRAIN\"\ntest_path= \"\/kaggle\/input\/waste-classification-data\/DATASET\/TEST\/\"","d6d90dbd":"img1=mpimg.imread('\/kaggle\/input\/waste-classification-data\/DATASET\/TRAIN\/O\/O_1.jpg')\nx1 = img_to_array(img1)\nprint(x1.shape)","b091d2e5":"className = glob(train_path + '\/*' )\nnumberOfClass = len(className)\nprint(\"NumberOfClasses: \",numberOfClass)","d52e9344":"model = Sequential()\nmodel.add(Conv2D(64,(3,3),input_shape = x1.shape))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(64,(3,3)))  \nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(numberOfClass)) # output\nmodel.add(Activation(\"softmax\"))\n\nmodel.compile(loss = \"categorical_crossentropy\",\n              optimizer = \"rmsprop\",\n              metrics = [\"accuracy\"])\n\nbatch_size = 32","0b435730":"train_datagen = ImageDataGenerator(rescale= 1.\/255,\n                   shear_range = 0.3,\n                   horizontal_flip=True,\n                   zoom_range = 0.3)\n\ntest_datagen = ImageDataGenerator(rescale= 1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_path, \n        target_size=x.shape[:2],\n        batch_size = batch_size,\n        color_mode= \"rgb\",\n        class_mode= \"categorical\")\n\ntest_generator = test_datagen.flow_from_directory(\n        test_path, \n        target_size=x.shape[:2],\n        batch_size = batch_size,\n        color_mode= \"rgb\",\n        class_mode= \"categorical\")\n\nhist = model.fit_generator(\n        generator = train_generator,\n        steps_per_epoch = 1400 \/\/ batch_size,\n        epochs=30,\n        validation_data = test_generator,\n        validation_steps = 600 \/\/ batch_size)","9ca30a2e":"plt.figure(figsize=[10,6])\nplt.plot(hist.history[\"accuracy\"], label = \"Train acc\")\nplt.plot(hist.history[\"val_accuracy\"], label = \"Validation acc\")\nplt.legend()\nplt.show()","1970a6d1":"#                         Organic VS Non-Organic?\n![M77.jpg](attachment:M77.jpg)","8bd47a39":"**Some samples**","73f0039b":"## L-Layer Neural Network","c84f4309":"## 2-Layer Neural Network","67d2570f":"**Import Libraries**","53a6c789":"- A simple chart for 2 layer NN.","d9b3b1d2":"**Load the data**","41387513":"**Data Preparation**","aeed5d45":"![NN%20.jpg](attachment:NN%20.jpg)","d39f2b82":"## Introduction\n- In this kernel, We will try to classify Organic vs Non-Organic materials with ANN and CNN Methods.","170b980d":"## CNN Model"}}