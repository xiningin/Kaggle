{"cell_type":{"4f8547d8":"code","49ad2d4a":"code","89daa61b":"code","d83e7027":"code","bea2cd52":"code","ab5d07e4":"code","24851d82":"code","f368b355":"code","d2f657d5":"code","4c809e1b":"code","7493f9f8":"code","fbacddf6":"code","a8c9aa78":"code","8ef5658b":"code","7de64625":"code","92f08c04":"markdown","13e37529":"markdown","6186c3ec":"markdown"},"source":{"4f8547d8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\nimport tensorflow as tf\nimport keras\n","49ad2d4a":"solarpower = pd.read_csv(\"..\/input\/solarpanelspower\/PV_Elec_Gas3.csv\",header = None,skiprows=1 ,names = ['date','cum_power','Elec_kW', \n                                                                            'Gas_mxm'], sep=',',usecols = [0,1,2,3],\n                     \n                     parse_dates={'dt' : ['date']}, infer_datetime_format=True,index_col='dt')\nprint(solarpower.head(2))\n","89daa61b":"# make solar power stationary\nsolarpower2 = solarpower.shift(periods=1, freq='D', axis=0)\nsolarpower['cum_power_shift'] = solarpower2.loc[:,'cum_power']\nsolarpower['day_power'] = solarpower['cum_power'].values - solarpower['cum_power_shift']\nsolarpower.iloc[0:1].day_power.value = 0.\nA = solarpower.dropna()\ndel A['cum_power'], A['cum_power_shift']\nsolarpower = A","d83e7027":"solarpower.head(2), solarpower.tail(2)","bea2cd52":"X_train = solarpower[:'2019-10-28']\nX_valid = solarpower['2019-10-29':'2020-10-28'] # is 365 days\nX_train.shape, X_valid.shape","ab5d07e4":"X_train.tail(2), X_valid.head(2)","24851d82":"# we devide the series into multiple input and output patterns\n\ndef my_split_window(series, window):\n    '''\n    the series is split in (len(series)-window)-blocks of window size, \n    y is the next value that comes after the block, \n    every block starts with the next value in the series.\n    The last block ends with the last-but-one value in the series.\n    '''\n    X = []\n    y = []\n    n_steps = len(series) - window\n    for step in range(n_steps):\n        X.append(series[step:window+step])\n        y.append(series[step + window])\n    X = np.array(X)\n    y = np.array(y)\n    return X, y","f368b355":"# apply my_split_window on dayly solar power with a window of 365 days (we do not make account for leap years)\n# the input series is the daily solar power\ntrain_power_series = X_train.day_power.values\nwindow = 365\nX, y = my_split_window(train_power_series, window)\n# print a sample\nfor i in range(3):\n    print(X[i][-5:], y[i])","d2f657d5":"# we have an input shape = window size, number of features \n# we use only 1 feature (it is univariate) and we have a window size of one year (365 days) \n# we have to reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\ndef model_LSTM_cnn(window, n_features):\n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.LSTM(32, return_sequences=True))\n    model.add(tf.keras.layers.Conv1D(filters=32, kernel_size=2, activation='relu', \n                                 input_shape=(window, n_features)))\n    model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.Dense(50, activation='relu'))\n    model.add(tf.keras.layers.Dropout(0.3))\n    model.add(tf.keras.layers.Dense(1))\n    return model\n\nmodel = model_LSTM_cnn(window, n_features)\n\nepochs=5000\nrange1 = 2\ny_hat_dict = {}\nfor steps in range(range1):\n    # compile the model:\n    model.compile(optimizer='adam', loss='mae')\n    # fit model\n    history = model.fit(X, y, epochs=epochs, verbose=0)\n    # predicting next year\n    x_input = np.array(X_train.day_power[-365:]) #  next value based on data of last year\n    x_input = x_input.reshape((1, window, n_features)) # the model expects three dimensions as input (samples, window, features)\n    y_hat = model.predict(x_input, verbose=0)\n    for i in range(365):\n        new_x = y_hat.reshape((1,1,1))\n        x_input = np.concatenate((x_input[:, -364:], new_x), axis=1)\n        y_hat = model.predict(x_input, verbose=0)\n    name = '108B_y_hat_15000e' + str(steps)\n    y_predicted = x_input.reshape((x_input.shape[1]))\n    y_hat_dict[name]=y_predicted\n    file = name + 'range' + str(range1) + '.npy'\n    np.save(file, y_predicted)\n    print('step', steps, 'done')","4c809e1b":"# predicting next year\nx_input = np.array(X_train.day_power[-365:]) #  next value based on data of last year\nx_input = x_input.reshape((1, window, n_features)) # the model expects three dimensions as input (samples, window, features)\ny_hat = model.predict(x_input, verbose=0)\nfor i in range(365):\n    new_x = y_hat.reshape((1,1,1))\n    x_input = np.concatenate((x_input[:, -364:], new_x), axis=1)\n    y_hat = model.predict(x_input, verbose=0)\n","7493f9f8":"y_predicted = x_input.reshape((x_input.shape[1]))\nplt.plot(y_predicted, label='predicted_power')\n\ny_true = X_valid.day_power.values\nplt.plot(y_true, label='true_power')\nplt.legend()\nplt.show()","fbacddf6":"first_r2_score = r2_score(y_true[:-1], y_predicted) # Best possible score is 1.0 \nfirst_mae = mean_absolute_error(y_true[:-1], y_predicted)\nprint('r2_score %.2f' % first_r2_score)\nprint('mae %.2f' % first_mae)\n\n","a8c9aa78":"def cumulate(series, start=0):\n    '''\n    start is the starting cumulative power, the series is the daily solar power\n    a list with daily cumulative power is the result\n    '''\n    cum = [start]\n    for i in range(len(series)):\n        sum_plus = cum[i] + series[i]\n        cum.append(sum_plus)\n    return cum","8ef5658b":"y_true_cumulative = cumulate(y_true)\ny_predicted_cumulative = cumulate(y_predicted)\n\nplt.plot(y_predicted_cumulative, label='predicted_power')\nplt.plot(y_true_cumulative, label='true_power')\nplt.legend()\nplt.show()","7de64625":"true_cumulative_power_after_one_year = int(y_true_cumulative[-1])\npredicted_cumulative_power_after_one_year = int(y_predicted_cumulative[-1])\nprint('true cumulative power after one year:', true_cumulative_power_after_one_year)\nprint('predicted cumulative power after one year:', predicted_cumulative_power_after_one_year)\n\nacc_one_year = 1- (true_cumulative_power_after_one_year - predicted_cumulative_power_after_one_year)\/true_cumulative_power_after_one_year\nacc_one_year = acc_one_year * 100\nprint(len(y_true_cumulative), len(y_predicted_cumulative))\nprint('accuracy after one year: %.2f' %  acc_one_year,'%')\nprint('r2 score %.2f ' % r2_score(y_true_cumulative[:-1] , y_predicted_cumulative))\nprint('mae  %.2f' % mean_absolute_error(y_true_cumulative[:-1], y_predicted_cumulative))\n\n\n","92f08c04":"test 108 : test prediction solarpower with Univariate series: LSTM and CNN","13e37529":"These notebooks are based on the excellent articly by Jason Brownlee:\nHow to Develop Convolutional Neural Network Models for Time Series Forecasting.  \nhttps:\/\/machinelearningmastery.com\/how-to-develop-convolutional-neural-network-models-for-time-series-forecasting\/  \n\nand on coursera : tensorflow Sequence TimeSeries  \nhttps:\/\/www.coursera.org\/learn\/tensorflow-sequences-time-series-and-prediction","6186c3ec":"We want to use a one-dimensional Convolutional Neural Network (1D CNN). Just like in a CNN for images,  \na 1D CNN extracts features. It is very usefull in timeseries. More info is on theze links:  \nhttps:\/\/missinglink.ai\/guides\/keras\/keras-conv1d-working-1d-convolutional-neural-networks-keras\/  \nhttps:\/\/machinelearningmastery.com\/cnn-models-for-human-activity-recognition-time-series-classification\/  \n"}}