{"cell_type":{"f5dcd4da":"code","8164d8c4":"code","1293f752":"code","780faeb6":"code","a314386a":"code","8939ea38":"code","285baedd":"code","981a89b5":"code","1d4476d9":"code","3a443753":"code","f3794eb6":"code","453804aa":"code","808b614a":"code","5469cb51":"code","0615f24c":"code","6388b1b2":"code","4c312163":"code","346e668c":"code","c4dd0483":"code","f7037d94":"code","c4a9ef23":"markdown","a3bdf4ab":"markdown","794f3ccd":"markdown","9cf3472d":"markdown","66651c61":"markdown","437a5be5":"markdown","26aa0759":"markdown","bfdfe65f":"markdown","e48466b9":"markdown","7dd0ec5e":"markdown","27f5f88e":"markdown","f8535952":"markdown"},"source":{"f5dcd4da":"import pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\nimport seaborn as sns\nfrom scipy import stats","8164d8c4":"songs_df = pd.read_csv('..\/input\/top50spotify2019\/top50.csv',encoding='ISO-8859-1')","1293f752":"songs_df.describe()","780faeb6":"songs_df.isnull().sum()","a314386a":"#Dropping Unnamed column\nsongs_df = songs_df.drop('Unnamed: 0', axis = 1)","8939ea38":"#checking the data types \nsongs_df.dtypes","285baedd":"songs_df.nunique()","981a89b5":"songs_df =  songs_df.drop(['Track.Name', 'Artist.Name'], axis = 1)","1d4476d9":"categorical = ['Genre']\nnumerical= ['Beats.Per.Minute', 'Energy', 'Danceability', 'Loudness..dB..', 'Liveness', 'Valence.', 'Length.', 'Acousticness..', \n            'Speechiness.']\ntarget = 'Popularity'","3a443753":"#Obtaining the counts for each category from every variable\nfor i in songs_df.columns:\n    print(songs_df[i].value_counts())","f3794eb6":"fig = plt.figure(figsize = (18, 12)) \ncount  = 1\nfor i in numerical:\n    ax = fig.add_subplot(5, 2, count)\n    ax.hist(songs_df[i])\n    ax.set_title(i)\n    count += 1\n\nfig.tight_layout()\nplt.show()","453804aa":"#correlation for numerical values\nsongs_corr = songs_df.corr()","808b614a":"# heatmap of the correlation \nplt.figure(figsize=(10,10))\nplt.title('Correlation heatmap')\nsns.heatmap(songs_corr,annot=True)\n","5469cb51":"g = sns.PairGrid(songs_df)\ng = g.map(plt.scatter)","0615f24c":"#from out value counts we know dance_pop is our most popular, we will drop and use as referance\ndummies_dropped_one = pd.get_dummies(songs_df['Genre'])\ndummies_dropped_one = dummies_dropped_one.drop(columns = ['dance pop'])\n#dropping genre column as we used it for our dummies\nsongs_df = songs_df.drop('Genre', axis = 1)\n#combining our dummies with our other variables\nsongs_df = pd.concat([songs_df, dummies_dropped_one], axis = 1)","6388b1b2":"X = songs_df.loc[:, songs_df.columns != target]\ny = songs_df[target].loc[:,]\nX_1 = sm.add_constant(X, prepend = True, has_constant = 'add')\n#%%\n#Using SkLearn to create out training and testing data sets\nX_train, X_test, y_train, y_test = train_test_split(X_1, y, test_size=0.3, random_state=0)","4c312163":"#Statsmodels Linear Regression\nmethod = sm.regression.linear_model.OLS(y_train.values.ravel(), X_train, has_constant = True)\nresult = method.fit()\nprint(result.summary())","346e668c":"#Feature Selection\ncols = list(X.columns)\npmax = 1 #placeholder for new p-value max\nwhile (len(cols)>0):\n    p= []\n    X_1 = X[cols]\n    X_1 = sm.add_constant(X_1,prepend = True, has_constant = 'add')\n    model = sm.OLS(y,X_1, hasconst = True).fit()\n    p = pd.Series(model.pvalues.values[1:],index = cols) #not idexing the constant column     \n    pmax = max(p)\n    feature_with_p_max = p.idxmax()\n    if(pmax>0.05):\n        cols.remove(feature_with_p_max)\n    else:\n        break\nselected_features_BE = cols\nprint(selected_features_BE)","c4dd0483":"#selecting our significant variables\nX = songs_df.loc[:, selected_features_BE]\ny = songs_df.loc[:,target]\n\n#scaling our variables\nscaler = StandardScaler()\nscaler.fit(X)\nX = scaler.transform(X)\n\n#adding a constant\nX_1 = sm.add_constant(X, prepend = True, has_constant = 'add')\n#Using SkLearn to create out training and testing data sets\nX_train, X_test, y_train, y_test = train_test_split(X_1, y, test_size=0.3, random_state=0)","f7037d94":"#Statsmodels Logistic Regression\nmethod = sm.regression.linear_model.OLS(y_train.values.ravel(), X_train, hasconst = True)\nresult = method.fit()\nprint(result.summary())","c4a9ef23":"It appears no multicollinearity is present.\n\nLet's visualize it by creating some scatter plots.","a3bdf4ab":"# Quick Linear Regression for Spotify's Top 50 Songs\n\nAs 2019 comes to a close, the top 50 songs for 2019 from spotify has been released.\n\nInterestigly, spotfify has a unique [tool](http:\/\/organizeyourmusic.playlistmachinery.com\/) that can organize the dataset by outputting some variables that may of interest.\n\n* Genre - the genre of the track\n* Year - the release year of the recording. Note that due to vagaries of releases, re-releases, re-issues and general madness, sometimes the release years are not what you'd expect.\n* Added - the earliest date you added the track to your collection.\n* Beats Per Minute (BPM) - The tempo of the song.\n* Energy - The energy of a song - the higher the value, the more energtic. song\n* Danceability - The higher the value, the easier it is to dance to this song.\n* Loudness (dB) - The higher the value, the louder the song.\n* Liveness - The higher the value, the more likely the song is a live recording.\n* Valence - The higher the value, the more positive mood for the song.\n* Length - The duration of the song.\n* Acousticness - The higher the value the more acoustic the song is.\n* Speechiness - The higher the value the more spoken word the song contains.\n* Popularity - The higher the value the more popular the song is.\n\nHowever, for the dataset provided the 'year' category wasn't included.\nIt can be assumed all these songs were released in 2019.\n\nWith all this information. I wondered if there was a clear distinction for the variables provided and the popularity scored provided by spotify?\n\nLet's find out!","794f3ccd":"# Dummy Coding\n\nWe have a nominal variable \"Genre\". Before we include the variable into our model we will obtain dummy variables for the Genres and see if \"Genre\" plays a role in popularity. Followed by dropping the \"Genre\" that has the most instances in our data set, to use as referance in our model.","9cf3472d":"We can visually plot the number of unique values per variable or we can obtain a quick count.","66651c61":"We will drop the 'Unnamed: 0' column as the column isn't connected to what we're interested in. ","437a5be5":"# Tuning\n\nOur first model we can see our R-Square returns a high correlation meaning there is some connection between our variables and 'Popularity'. However, our adjusted R-square is relatively low, as well as many of our variables don't appear significant in our initial model. Let's perform some feature selection and see if we can generalize our model. \n\nAnother thing we will do is standardize our data, Our variables have different scales and another assumption of Linear regression is:\n* Our data has a Normal Distribution","26aa0759":"# The Model\n\nPerfect, Now we can build our model and see if there's a correlation amongst the variables chosen and \"Popularity\".","bfdfe65f":"# Inspection\/Cleaning\nWe will begin by inspecting and cleaning the dataset. \n1. Inspection: Detect any incorrect and incosistent data.\n2. Cleaning: Fix or remove any anomalies found.","e48466b9":"# Visualization\nNow that the data set checks off our initial Inspection\/Cleaning. We will plot some graphs to observe the distribution for our variables.\n\nOnce again, we're interested in seeing if there's a correlatino for the variables provided and the popularity obtained for a particular song.\n\nFor this we won't include \"Track.Name\" or \"Artist.Name\" in our model.","7dd0ec5e":"One of the assumptions when building a Linear Regression model is:\n* No or little multicollinearity\n\nTherefore, we want to check if any is present amongst our variables. If any is seen, we will choose one of the variables that shares correlation with another and drop the other.","27f5f88e":"# Final Takeaways\n\nIt appears there is a correlation between the variables chosen and \"Popularity\". More interestingly, the genres:\n* dfw rap \n* electropop \n* latin \n* panamanian pop \n* reggaeton\n* reggaeton flow\n\nAll seemed to have a higher popularity than our referance \"dance pop\".\n\nFurthermore, it appears the aspects that describe the songs such as \"Beats Per Minute\" and others didn't show correlation with \"Popularity\". \n\nObviously, this quick analysis is only on 50 songs. It would be interesting for re-do this for a larger data set of songs.\n\nCheers!","f8535952":"Now we want to check the data types to make sure the data type matches with the values Spotify is saying the tool returns."}}