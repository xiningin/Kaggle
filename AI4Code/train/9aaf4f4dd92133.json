{"cell_type":{"1a664fe8":"code","63de0741":"code","994845b4":"code","57833ebf":"code","5faa357e":"code","069191a1":"code","7395749c":"code","67d5e3aa":"code","08818cdc":"code","7beb038c":"code","dc0da2e5":"code","a044ac26":"code","924172db":"code","3de0ffca":"code","2484f1cc":"code","fae4297e":"code","257c57df":"code","68b2d854":"code","e3793a8b":"code","85238c46":"code","b4f59105":"code","ab7851ac":"code","408d3764":"code","7b7caa2b":"code","91a61aee":"code","632d61b5":"code","c9226bce":"code","d5da01f5":"code","9871ef83":"code","5260bc25":"code","44af9578":"code","dc1b67b8":"code","a28e6bf8":"code","67614618":"code","ec041647":"code","9e2beff0":"code","dae15efb":"code","fdf4e774":"markdown","23f33532":"markdown","6c105ba5":"markdown","26064c3a":"markdown","4a718374":"markdown","f9f8c0ae":"markdown","5f84613d":"markdown","ab0e238f":"markdown","69293393":"markdown","14f354c3":"markdown","0344626a":"markdown","f59b13fe":"markdown","5e4fd0d3":"markdown","781f5968":"markdown","408c5629":"markdown","d9ea248e":"markdown","b6df1044":"markdown","b43d9505":"markdown","84585188":"markdown","74344492":"markdown","533e542e":"markdown","dad4eeb3":"markdown","01433605":"markdown","ec2c84f3":"markdown","cf888c7d":"markdown","34f5609e":"markdown","6c4f5a48":"markdown","b182c29d":"markdown","b2f622a1":"markdown","76f06e51":"markdown","13b33965":"markdown","05080544":"markdown","c136146b":"markdown","ba5c58e6":"markdown","3114b8aa":"markdown","8fd60d79":"markdown","ad667ecd":"markdown","f24b4d4e":"markdown","c6081228":"markdown"},"source":{"1a664fe8":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')","63de0741":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\nprint(train.shape)\ntrain.head()","994845b4":"Y_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"],axis = 1) ","57833ebf":"plt.figure(figsize=(15,7))\nsns.countplot(Y_train, palette=\"icefire\")\nplt.title(\"Sayi kumeleri\")","5faa357e":"img = X_train.iloc[4].to_numpy()\nimg = img.reshape((28,28))\nplt.imshow(img,cmap='gray')\nplt.title(train.iloc[4,0])\nplt.axis(\"off\")\nplt.show()","069191a1":"img = X_train.iloc[2].to_numpy()\nimg = img.reshape((28,28))\nplt.imshow(img,cmap='gray')\nplt.title(train.iloc[2,0])\nplt.axis(\"off\")\nplt.show()","7395749c":"X_train = X_train \/ 255.0","67d5e3aa":"X_train = X_train.values.reshape(-1,28,28,1)\nprint(\"x_train shape: \",X_train.shape)","08818cdc":"Y_train.head()","7beb038c":"Y_train = pd.Categorical(Y_train)\nY_train = pd.get_dummies(Y_train)","dc0da2e5":"Y_train.values","a044ac26":"from sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)","924172db":"from sklearn.metrics import confusion_matrix,accuracy_score\nimport itertools\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n","3de0ffca":"model = Sequential()","2484f1cc":"#Conv layer\nmodel.add(Conv2D(filters = 8,##Feature detection\n                 kernel_size = (5,5),##n*n\n                 padding = 'Same',##Filtre turu. Veri kaybini engeller.\n                 activation ='relu', \n                 input_shape = (28,28,1)))##Keras 3 boyut istiyor.\n#Pooling layer\nmodel.add(MaxPool2D(pool_size=(2,2)))## Veri boyutunu dusurur. Overfittingi engeller.\n#Conv katmaninda kernele 5*5 verdik fakat pooling ile tararken 2*2 olarak tarayacak.\nmodel.add(Dropout(0.25))##Yine overfittingi azaltmak adina bir dropout.\n\n#Ayni islemler tekrardan gerceklesiyor.\n#Ilk Convolution layerda input shape vermistik. Sonrakilerde gerek yok.\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2),\n                    strides=(2,2)))#Shiftleme yaparken kacar kacar atlayacagi.\nmodel.add(Dropout(0.25))\n\n########################\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2),\n                    strides=(2,2)))#Shiftleme yaparken kacar kacar atlayacagi.\nmodel.add(Dropout(0.25))\n#########################\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2),\n                    strides=(2,2)))#Shiftleme yaparken kacar kacar atlayacagi.\nmodel.add(Dropout(0.25))\n#########################\n\n#########################\n\nmodel.add(Flatten())#Input sekline gelebilmesi icin son islem.Matrisi inputun anlayacagi boyuta indirgiyor.\n\nmodel.add(Dense(256, activation = \"relu\"))#Hidden layer\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))#Multi output classification icin tercih edilir. sigmoid ise binary classification\n                                            #icin kullanilir.\n","fae4297e":"optimizer = Adam(lr=0.001,#learning rate\n                 beta_1=0.9, beta_2=0.999)#lr degisimini etklieyen parametreler.","257c57df":"model.compile(optimizer = optimizer ,#bir ustte hazirlamistik.\n              loss = \"categorical_crossentropy\",#ikiden cok siniflandirma oldugunda categorical tercih edilebilir. Fakat ikili \n                                                #siniflandirmada binary tercih edilir.\n              metrics=[\"accuracy\"])#Degerlendirme teknigi.","68b2d854":"epochs = 60\nbatch_size = 250","e3793a8b":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # input ortalamasini 0'a esitler.\n        samplewise_center=False,  # her ornegi 0'a esitler.\n        featurewise_std_normalization=False,  # inputu genel std degerine boler.\n        samplewise_std_normalization=False,  # her inputu kendi std degerine boler.\n        zca_whitening=False,  # boyut azaltma\n        rotation_range=0.5,  # icerigi rotasyon yaptirir. Buradaki 5 derece.\n        zoom_range = 0.5, # icerige zoom yapar. Buradaki %5\n        width_shift_range=0.5,  # icerigi yatay duzlemde %5 kaydirir.\n        height_shift_range=0.5,  # icerigi dikey duzlemde %5 kaydirir.\n        horizontal_flip=False,  # yatay dondurme\n        vertical_flip=False)  # dikey dondurme\n\ndatagen.fit(X_train)","85238c46":"history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val), steps_per_epoch=X_train.shape[0] \/\/ batch_size)","b4f59105":"plt.plot(history.history['val_loss'], color='b', label=\"validation loss\")\nplt.title(\"Loss degeri testi\")\nplt.xlabel(\"Epochs sayisi\")\nplt.ylabel(\"Loss degeri\")\nplt.legend()\nplt.show()","ab7851ac":"Y_pred = model.predict(X_val)","408d3764":"Y_pred","7b7caa2b":"Y_pred_degerler = np.argmax(Y_pred,axis = 1)","91a61aee":"Y_gercek_degerler = np.argmax(Y_val.values,axis = 1)","632d61b5":"confusion_mtx = confusion_matrix(Y_gercek_degerler, Y_pred_degerler) \nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Tahmin edilen deger\")\nplt.ylabel(\"Gercek deger\")\nplt.title(\"\")\nplt.show()","c9226bce":"print(accuracy_score(Y_pred_degerler,Y_gercek_degerler))","d5da01f5":"from tensorflow.keras.preprocessing.image import load_img,img_to_array,array_to_img ","9871ef83":"def load_image(filename):\n    img = load_img(filename,color_mode = \"grayscale\",target_size=(28, 28))\n    plt.imshow(img,cmap='Greys')\n    img = img_to_array(img)\n    img = img.reshape(1, 28, 28, 1)\n    img = img.astype('float32')\n    img = img \/ 255.0\n    return img","5260bc25":"quary_img=load_image(\"..\/input\/sayilar\/3.png\")\npred = model.predict(quary_img)\nprint(\" Predict :\",pred.argmax())","44af9578":"quary_img=load_image(\"..\/input\/sayilar\/7.png\")\npred = model.predict(quary_img)\nprint(\" Predict :\",pred.argmax())","dc1b67b8":"quary_img=load_image(\"..\/input\/sayilar\/0.png\")\npred = model.predict(quary_img)\nprint(\" Predict :\",pred.argmax())","a28e6bf8":"quary_img=load_image(\"..\/input\/sayilar\/2.png\")\npred = model.predict(quary_img)\nprint(\" Predict :\",pred.argmax())","67614618":"quary_img=load_image(\"..\/input\/sayilar\/9.png\")\npred = model.predict(quary_img)\nprint(\" Predict :\",pred.argmax())","ec041647":"quary_img=load_image(\"..\/input\/sayilar\/1.png\")\npred = model.predict(quary_img)\nprint(\" Predict :\",pred.argmax())","9e2beff0":"quary_img=load_image(\"..\/input\/sayilar\/3H.png\")\npred = model.predict(quary_img)\nprint(\" Predict :\",pred.argmax())","dae15efb":"quary_img=load_image(\"..\/input\/sayilar\/6H.png\")\npred = model.predict(quary_img)\nprint(\" Predict :\",pred.argmax())","fdf4e774":"Batch_size, modelin her seferde kac lokma yiyecegidir.\nEpochs ise ileri ve geri shiftlerken(back and forward propagation) kacar defa git gel yapilacagidir. Her git gel yapilista o lokmanin icindeki besinler degisir.","23f33532":"Sirada uyguladigimiz ayarlarla modeli fit etmek var.","6c105ba5":"Test verilerini modelimize tahmin ettirelim.","26064c3a":"Verilerimiz matrisin elemanlari olarak tutuluyordu. Bunlari gorsel olarak gosterebiliriz.","4a718374":"Bagimli ve bagimsiz olarak verilerimizi bolutleyelim.","f9f8c0ae":"Hatirlayalim. Modelimiz verileri vektor bazinda aliyordu. O zaman tahminleri ve gercek degerleri vektore cevirelim.","5f84613d":"Sonraki adim olarak kediye ait olan bir bolgenin ornegin kulagin matrissel ifadesi ele alinir ve boyut dusurmek icin downsampling uygulanir. Bu basitce nxn'lik bir matriste her 5x5lik alani gezip en buyuk olan degeri almak olarak orneklenebilir. Bunun yapildigi katmana pooling layer denir.","ab0e238f":"Son olarak flatten(duzleme) islemi uygulanir. Burada amac n*n'lik bir matrisi tek boyutlu hale indirgemektir. Yani inputa verebilecegimiz sekilde olacak boyutta yeniden duzenlenir.","69293393":"<a id=\"15\"><\/a>\n### Data Augmentation\n <a href=\"https:\/\/ibb.co\/k24CUp\"><img src=\"https:\/\/preview.ibb.co\/nMxXUp\/augment.jpg\" alt=\"augment\" border=\"0\"><\/a>\n    \n","14f354c3":"<a id=\"5\"><\/a>\n## Dropout\n\n <a href=\"https:\/\/ibb.co\/BVmjfdN\"><img src=\"https:\/\/i.ibb.co\/Rp1PgZy\/dropout.jpg\" alt=\"\" border=\"0\"><\/a>","0344626a":"Oldukca tatmin edici bir tahmin skoru aldik.","f59b13fe":"Egitim asamasinda verimi artt\u0131rmak icin optimizer kullaniyoruz. Learning rate degeri ile oynayarak verimi arttirmayi amacliyor.","5e4fd0d3":"Katmanlarimizi ekleyelim.","781f5968":"Ardindan verilerle devam edelim ve verilerin nelerden olustuguna bir bakalim.","408c5629":"K\u00fct\u00fcphanelerimizi ekleyerek baslayalim.","d9ea248e":"2-8 ve 9-8 tahmin sirasinda birbirine karistirma ihtimali daha yuksek olan iki ikili. Demekki yuvarlak sekilleri karistirabiliyor.","b6df1044":"Daha iyi sonuclar icin epochs sayisi arttirilabilinir. Fakat batch_size arttirilirsa model tikanabilir.","b43d9505":"Egitim verilerimizi gorsellestirerek devam edelim.","84585188":"Ilgili matrisin resmindeki degerin ne oldugunu tutan bir kolonumuz vardi. O kolonun degerleri 0-9 arasindaydi. Bunlarin sadece 0-1 ile ifade ediliyor olmasi lazim. Encoding ile devam edelim.","74344492":"Bu iki islem tekrarlandikca daha ayrintili sonuclar alinir.","533e542e":"42000 satir veri ve 785 kolondan olusuyor.","dad4eeb3":"Sirada data augmentation(veri artisi) var.","01433605":"### Keras ile model olusumu","ec2c84f3":"Epochs ve batch_size kisminda da bahsettigimiz gibi epochsun artmasi modelin daha fazla farkli veri ile beslenmesi demek. Yani verimi arttiran bir durum. Grafikte de gorebilecegimiz uzere epochs arttikca loss azaliyor.","cf888c7d":"Sira geldi train test split kullanmaya.","34f5609e":"Kedi ve kopekleri ayiran bir classifier islemi dusunelim. Kedi ve kopegin spesifik ozelliklerini ele alal\u0131m. Boyut, kulak sivriligi, kuyruk uzunlugu vs. Ornegin inputumuz bir kedi ise input ustune bir filtre koyarsak bu filtre ile kediye ozel olan ozellikleri alabiliriz(Kuyrugu, kulagi vs). Inputun filtrelendigi katmana convolution layer denir. ","6c4f5a48":"Gercek fotograf ile test edelim.","b182c29d":"Ogrenimi desteklemek icin benzer icerikleri modele eklemek gerekir. Ya da ayni icerigin farkli varyasyonlarini ekleyebiliriz. Buna Data Augmentation denir.","b2f622a1":"Kesinlik skorumuza bakalim.","76f06e51":"Dropout ile baslayalim. Dropout ogrenimi arttirmak, ezberlemeyi azaltmak icin modeli gurultu ile daha da zorlayan bir tekniktir.","13b33965":"### Convolutional Neural Networks (CNN)\n\n","05080544":"Label kolonumuz bize sayinin kendisini gosteriyor. Train ederken ona ihtiyacimiz olmayacak.","c136146b":"<a id=\"4\"><\/a>\n## Convolutional Neural Network \n\n* <a href=\"https:\/\/ibb.co\/kV1j9p\"><img src=\"https:\/\/preview.ibb.co\/nRkBpp\/gec2.jpg\" alt=\"\" border=\"0\"><\/a>","ba5c58e6":"Son olarak modeli gorsellestirmek var.\n","3114b8aa":"Matrisimizi olusturup sonuclari alalim.","8fd60d79":"Sirada compile modeli var.","ad667ecd":"Cnn en basit tanimiyla resim siniflandirma ve tanima icin kullanilan bir kutuphanedir.","f24b4d4e":"Sirada performansi arttiracak bir islem olan normalizasyon var","c6081228":"Kerasin gri tonlarini anlamasi icin 28x28x1 seklinde bir 3d matrisine cevirmemiz lazim. Bunu reshape ile yapabiliriz."}}