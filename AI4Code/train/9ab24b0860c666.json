{"cell_type":{"bec0b0c1":"code","dc6984d2":"code","92fbdf17":"code","fe989753":"code","fc896dc7":"code","f27adad4":"code","510d22f1":"code","c620a44c":"code","c75262a2":"code","c985e801":"code","64cf87b1":"code","3bb61679":"code","70eee67c":"code","be3b77d9":"code","7352c320":"code","2194d5f5":"code","f9b56638":"code","f0a835cd":"code","96eec176":"code","d90eb23e":"markdown","82af8ac7":"markdown","e5eb2973":"markdown","707d82ea":"markdown","fbebcab3":"markdown","d4b2c1eb":"markdown","51ae049d":"markdown","c4c99eac":"markdown","4b677c88":"markdown","856fe60a":"markdown","88dc82be":"markdown","290fe58b":"markdown","882fa2ff":"markdown","5f1a5700":"markdown","84314d7a":"markdown","c174dcee":"markdown","60d45200":"markdown","ee1de4fa":"markdown","bfcf6776":"markdown","04b50f7d":"markdown"},"source":{"bec0b0c1":"\"\"\"\n1 Cathedral family - Rock outcrop complex, extremely stony.\n2 Vanet - Ratake families complex, very stony.\n3 Haploborolis - Rock outcrop complex, rubbly.\n4 Ratake family - Rock outcrop complex, rubbly.\n5 Vanet family - Rock outcrop complex complex, rubbly.\n6 Vanet - Wetmore families - Rock outcrop complex, stony.\n7 Gothic family.\n8 Supervisor - Limber families complex.\n9 Troutville family, very stony.\n10 Bullwark - Catamount families - Rock outcrop complex, rubbly.\n11 Bullwark - Catamount families - Rock land complex, rubbly.\n12 Legault family - Rock land complex, stony.\n13 Catamount family - Rock land - Bullwark family complex, rubbly.\n14 Pachic Argiborolis - Aquolis complex.\n15 unspecified in the USFS Soil and ELU Survey.\n16 Cryaquolis - Cryoborolis complex.\n17 Gateview family - Cryaquolis complex.\n18 Rogert family, very stony.\n19 Typic Cryaquolis - Borohemists complex.\n20 Typic Cryaquepts - Typic Cryaquolls complex.\n21 Typic Cryaquolls - Leighcan family, till substratum complex.\n22 Leighcan family, till substratum, extremely bouldery.\n23 Leighcan family, till substratum - Typic Cryaquolls complex.\n24 Leighcan family, extremely stony.\n25 Leighcan family, warm, extremely stony.\n26 Granile - Catamount families complex, very stony.\n27 Leighcan family, warm - Rock outcrop complex, extremely stony.\n28 Leighcan family - Rock outcrop complex, extremely stony.\n29 Como - Legault families complex, extremely stony.\n30 Como family - Rock land - Legault family complex, extremely stony.\n31 Leighcan - Catamount families complex, extremely stony.\n32 Catamount family - Rock outcrop - Leighcan family complex, extremely stony.\n33 Leighcan - Catamount families - Rock outcrop complex, extremely stony.\n34 Cryorthents - Rock land complex, extremely stony.\n35 Cryumbrepts - Rock outcrop - Cryaquepts complex.\n36 Bross family - Rock land - Cryumbrepts complex, extremely stony.\n37 Rock outcrop - Cryumbrepts - Cryorthents complex, extremely stony.\n38 Leighcan - Moran families - Cryaquolls complex, extremely stony.\n39 Moran family - Cryorthents - Leighcan family complex, extremely stony.\n40 Moran family - Cryorthents - Rock land complex, extremely stony.\n\"\"\"","dc6984d2":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","92fbdf17":"#data manipulation \/ dataframe libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom bokeh.plotting import output_notebook, figure, show\nfrom bokeh.models import ColumnDataSource, Div, Select, Button, ColorBar, CustomJS, Range1d\nfrom bokeh.models.tools import HoverTool\nfrom bokeh.layouts import row, column, layout\nfrom bokeh.transform import cumsum, linear_cmap\nfrom bokeh.palettes import Blues8\nfrom bokeh.models.widgets import Tabs,Panel\nfrom bokeh.io import show\nfrom bokeh.transform import stack, factor_cmap\noutput_notebook() #set bokeh output to be inline with notebook\n\nimport holoviews as hv\nfrom holoviews import opts\nhv.extension('bokeh')\n\nfrom ipywidgets import widgets\nimport missingno\n\nprint(\"Libraries loaded: NumPy, Pandas, Matplotlib as plt, Seaborn as sns, Missingno, Bokeh\")","fe989753":"train_data = pd.read_csv(\"..\/input\/learn-together\/train.csv\")\n\ntest_data = pd.read_csv(\"..\/input\/learn-together\/test.csv\")\n\nsample_subs = pd.read_csv(\"..\/input\/learn-together\/sample_submission.csv\")\n\nprint(\"Loaded: train_data, Filesize: {:0.2f}MB\".format((train_data.memory_usage().sum()\/1000000)))\nprint(\"Loaded: test_data, Filesize:  {:0.2f}MB\".format((test_data.memory_usage().sum()\/1000000)))\nprint(\"Loaded: sample_subs, Filesize:  {:0.2f}MB\".format((sample_subs.memory_usage().sum()\/1000000)))","fc896dc7":"train_data.info()","f27adad4":"train_data.columns","510d22f1":"missingno.matrix(train_data, figsize=(20,5), labels=True, fontsize=10)","c620a44c":"#initialize labels\nlabels = ['Spruce', 'Lodgepole Pine', 'Ponderosa Pine', 'Cottonwood\/Willow', 'Aspen', 'Douglas-fir', 'Krummholz']","c75262a2":"#plot kde distribution for 7 cover types and their elevation\ndf2 = train_data[['Elevation', 'Cover_Type']].copy()\n\n#create empty dictionary for loop\ndistElevationDict = {}\nplotElevationDict = {}\n\n#create 7 distribution plots \nfor i in range(1,8):\n    distElevationDict[i-1] = df2.loc[df2['Cover_Type'] == i]\n    plotElevationDict[i-1] = hv.Distribution(distElevationDict[i-1], label=labels[i-1])\n    \n#overlay all 7 cover types\nelevDistPlot = (plotElevationDict[0] *\n                plotElevationDict[1] * \n                plotElevationDict[2] * \n                plotElevationDict[3] * \n                plotElevationDict[4] * \n                plotElevationDict[5] *\n                plotElevationDict[6])","c985e801":"#display plot\n#elevDistPlot.opts.info()\nelevDistPlot.opts(\n    opts.Distribution(height=500, width=800, title=\"Elevation Distribution by Type\", xlim=(1800,4200), muted_alpha=0.2)\n)","64cf87b1":"#plot stacked bar for wilderness type\nwilderness_list = ['Rawah', 'Neota', 'Comanche Peak', 'Cache la Poudre']\n\n#get dataframe ready\ndf3 = train_data[['Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3',\n       'Wilderness_Area4', 'Cover_Type']].copy()\n\n#reshape to enter into Holoviews\nwildernessTypeDF = pd.DataFrame(data=[\n    (wilderness_list[0],labels[0],df3[(df3['Wilderness_Area1']==1) & (df3['Cover_Type']==1)].sum()[0]),\n    (wilderness_list[0],labels[1],df3[(df3['Wilderness_Area1']==1) & (df3['Cover_Type']==2)].sum()[0]),\n    (wilderness_list[0],labels[2],df3[(df3['Wilderness_Area1']==1) & (df3['Cover_Type']==3)].sum()[0]),\n    (wilderness_list[0],labels[3],df3[(df3['Wilderness_Area1']==1) & (df3['Cover_Type']==4)].sum()[0]),\n    (wilderness_list[0],labels[4],df3[(df3['Wilderness_Area1']==1) & (df3['Cover_Type']==5)].sum()[0]),\n    (wilderness_list[0],labels[5],df3[(df3['Wilderness_Area1']==1) & (df3['Cover_Type']==6)].sum()[0]),\n    (wilderness_list[0],labels[6],df3[(df3['Wilderness_Area1']==1) & (df3['Cover_Type']==7)].sum()[0]),\n    (wilderness_list[1],labels[0],df3[(df3['Wilderness_Area2']==1) & (df3['Cover_Type']==1)].sum()[1]),\n    (wilderness_list[1],labels[1],df3[(df3['Wilderness_Area2']==1) & (df3['Cover_Type']==2)].sum()[1]),\n    (wilderness_list[1],labels[2],df3[(df3['Wilderness_Area2']==1) & (df3['Cover_Type']==3)].sum()[1]),\n    (wilderness_list[1],labels[3],df3[(df3['Wilderness_Area2']==1) & (df3['Cover_Type']==4)].sum()[1]),\n    (wilderness_list[1],labels[4],df3[(df3['Wilderness_Area2']==1) & (df3['Cover_Type']==5)].sum()[1]),\n    (wilderness_list[1],labels[5],df3[(df3['Wilderness_Area2']==1) & (df3['Cover_Type']==6)].sum()[1]),\n    (wilderness_list[1],labels[6],df3[(df3['Wilderness_Area2']==1) & (df3['Cover_Type']==7)].sum()[1]),\n    (wilderness_list[2],labels[0],df3[(df3['Wilderness_Area3']==1) & (df3['Cover_Type']==1)].sum()[2]),\n    (wilderness_list[2],labels[1],df3[(df3['Wilderness_Area3']==1) & (df3['Cover_Type']==2)].sum()[2]),\n    (wilderness_list[2],labels[2],df3[(df3['Wilderness_Area3']==1) & (df3['Cover_Type']==3)].sum()[2]),\n    (wilderness_list[2],labels[3],df3[(df3['Wilderness_Area3']==1) & (df3['Cover_Type']==4)].sum()[2]),\n    (wilderness_list[2],labels[4],df3[(df3['Wilderness_Area3']==1) & (df3['Cover_Type']==5)].sum()[2]),\n    (wilderness_list[2],labels[5],df3[(df3['Wilderness_Area3']==1) & (df3['Cover_Type']==6)].sum()[2]),\n    (wilderness_list[2],labels[6],df3[(df3['Wilderness_Area3']==1) & (df3['Cover_Type']==7)].sum()[2]),\n    (wilderness_list[3],labels[0],df3[(df3['Wilderness_Area4']==1) & (df3['Cover_Type']==1)].sum()[3]),\n    (wilderness_list[3],labels[1],df3[(df3['Wilderness_Area4']==1) & (df3['Cover_Type']==2)].sum()[3]),\n    (wilderness_list[3],labels[2],df3[(df3['Wilderness_Area4']==1) & (df3['Cover_Type']==3)].sum()[3]),\n    (wilderness_list[3],labels[3],df3[(df3['Wilderness_Area4']==1) & (df3['Cover_Type']==4)].sum()[3]),\n    (wilderness_list[3],labels[4],df3[(df3['Wilderness_Area4']==1) & (df3['Cover_Type']==5)].sum()[3]),\n    (wilderness_list[3],labels[5],df3[(df3['Wilderness_Area4']==1) & (df3['Cover_Type']==6)].sum()[3]),\n    (wilderness_list[3],labels[6],df3[(df3['Wilderness_Area4']==1) & (df3['Cover_Type']==7)].sum()[3]),\n                                     ],\n                                columns =['Wilderness_Type','Cover_Type','Count'])\n\nbars = hv.Bars(wildernessTypeDF, ['Wilderness_Type', 'Cover_Type'], 'Count')\n","3bb61679":"bars.opts(width=800, height=800, title=\"Count by Wilderness Type\")\nstacked = bars.opts(stacked=True, clone=True, legend_position=\"bottom\",\n                    tools=['hover'], bar_width=0.5, fill_alpha=0.6, hover_fill_alpha=1)\nstacked","70eee67c":"#soil type plotting\nsoil_list = ['Soil_Type1', 'Soil_Type2', 'Soil_Type3','Soil_Type4', \n             'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n             'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n             'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n             'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n             'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n             'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n             'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n             'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n             'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']\n\n#get dataframe ready\ndf4 = train_data[['Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4',\n                  'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n                  'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n                  'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n                  'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n                  'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n                  'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n                  'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n                  'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n                  'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40', 'Cover_Type']].copy()","be3b77d9":"#prepare dataframe\nsoilTypeDF = pd.DataFrame(columns=['Soil_Type','Cover_Type','Count'])\n\nfor n in range(0,7):\n    for i in range(0,40):\n        soilTypeDF = soilTypeDF.append(\n        {\n            'Soil_Type' : soil_list[i],\n            'Cover_Type' : labels[n],\n            'Count' : df4[(df4[soil_list[i]]==1) & (df4['Cover_Type']==n+1)].sum()[i]\n        }, ignore_index=True)\n\n\"\"\"\nfor i in range(0,40):\n    soilTypeDF = soilTypeDF.append(\n    {\n        'Soil_Type' : soil_list[i],\n        'Cover_Type' : labels[1],\n        'Count' : df4[(df4[soil_list[i]]==1) & (df4['Cover_Type']==2)].sum()[i]\n    }, ignore_index=True)    \n\nfor i in range(0,40):\n    soilTypeDF = soilTypeDF.append(\n    {\n        'Soil_Type' : soil_list[i],\n        'Cover_Type' : labels[1],\n        'Count' : df4[(df4[soil_list[i]]==1) & (df4['Cover_Type']==3)].sum()[i]\n    }, ignore_index=True)\n\"\"\"\n\n\nbars2 = hv.Bars(soilTypeDF, ['Soil_Type', 'Cover_Type'], 'Count')","7352c320":"bars2.opts(width=800, height=1100, title=\"Count by Soil Type\", invert_axes=True)\nstacked2 = bars2.opts(stacked=True, clone=True, legend_position=\"bottom\", tools=['hover'],\n                    bar_width=0.5, fill_alpha=0.6, hover_fill_alpha=1)\nstacked2","2194d5f5":"#hillshade plotting\nhillshade_list = ['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']\n\n#get dataframe ready\ndf5 = train_data[['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Cover_Type']].copy()\n#hillshade is ordinal integer with range 0 - 255\n\ndf5['Cover_Type'].replace([1,2,3,4,5,6,7],['Spruce', 'Lodgepole Pine', 'Ponderosa Pine', 'Cottonwood\/Willow', 'Aspen', 'Douglas-fir', 'Krummholz'], inplace=True)\n\n#create boxplot chart\nboxwhisker = hv.BoxWhisker(\n    (['Hillshade_9am']*15120 + ['Hillshade_Noon']*15120 + ['Hillshade_3pm']*15120, \n    list(df5['Cover_Type'].values)*3, \n    list(df5['Hillshade_9am'].values) + list(df5['Hillshade_Noon'].values) + list(df5['Hillshade_3pm'].values)),\n    ['Group', 'Cover_Type'], vdims='Hillshade'\n).opts(box_color='Hillshade')\n","f9b56638":"boxwhisker.opts(width=800, height=650, \n                xrotation=90, title=\"Visualization of Cover_Type by Hillshade Index\",\n               )\n\ngrouped2 = boxwhisker.opts(\n    clone=True, ylim=(0,280), legend_position=\"bottom\", tools=['hover'],\n    box_width=0.5, box_fill_alpha=0.6, box_hover_fill_alpha=1, outlier_fill_alpha=0.1,\n    outlier_line_width=0, whisker_alpha=0.2\n)\ngrouped2\n","f0a835cd":"#distance plotting\nhillshade_list = ['Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n       'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points']\n\n#get dataframe ready\ndf6 = train_data[['Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n       'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points', 'Cover_Type']].copy()\n\ndf6['Cover_Type'].replace([1,2,3,4,5,6,7],['Spruce', 'Lodgepole Pine', 'Ponderosa Pine', 'Cottonwood\/Willow', 'Aspen', 'Douglas-fir', 'Krummholz'], inplace=True)\n\n#create boxplot2\nboxwhisker2 = hv.BoxWhisker(\n    (['Horizontal_Distance_To_Hydrology']*15120 + \n    ['Vertical_Distance_To_Hydrology']*15120 + \n    ['Horizontal_Distance_To_Roadways']*15120 +\n    ['Horizontal_Distance_To_Fire_Points']*15120, \n    list(df6['Cover_Type'].values)*4, \n    list(df6['Horizontal_Distance_To_Hydrology'].values) + \n    list(df6['Vertical_Distance_To_Hydrology'].values) + \n    list(df6['Horizontal_Distance_To_Roadways'].values) +\n    list(df6['Horizontal_Distance_To_Fire_Points'].values)),\n    ['Group', 'Cover_Type'], vdims='Distance'\n).opts(box_color='Distance')\n\n","96eec176":"boxwhisker2.opts(width=800, height=650, \n                xrotation=90, title=\"Visualization of Cover_Type by Distances to Features\",\n               )\n\ngrouped3 = boxwhisker2.opts(\n    clone=True, legend_position=\"bottom\", tools=['hover'],\n    box_width=0.5, box_fill_alpha=0.6, box_hover_fill_alpha=1, outlier_fill_alpha=0.1,\n    outlier_line_width=0, whisker_alpha=0.2\n)\n\ngrouped3","d90eb23e":"<a id=\"missingno\"><\/a>\n### Vizualising any missing data\n\nMy favourite way of looking at any missing data quickly is with this library - missingno.\nIt will display a null\/NaN value in the data as a white block. With messy datasets, you will be able to see white patches \/ blocks in the data. \n\nKaggle has been kind to choose this dataset for this competition. Why? \nMissingno shows all fully opaque bars for ALL the columns. This means every data point inside has a value from row 1 to 15120.\n> This saves us the need to do any data cleaning!","82af8ac7":"<a id=\"distribution\"><\/a>","e5eb2973":"### Digging deeper into the columns\n\nA quick visual repesentation of how **cartographic data** looks like:\n\nA - Elevation\nB - Slope\nC - Geology\nD - Soil type\n![](https:\/\/www.researchgate.net\/publication\/319995188\/figure\/fig1\/AS:541581153402880@1506134417173\/Elevation-A-Slope-B-Aspect-C-Geology-and-Land-Use-D-and-Soil-Map-E-in-Oyon.png)\n\n**7 types of cover-type**\n![7 types of trees](https:\/\/csfs.colostate.edu\/media\/sites\/22\/2016\/06\/TreeCollage.jpg)\n`1 - Spruce\/Fir\n2 - Lodgepole Pine\n3 - Ponderosa Pine\n4 - Cottonwood\/Willow\n5 - Aspen\n6 - Douglas-fir\n7 - Krummholz`\n\n**4 Wilderness areas**\n\n`Wilderness Area 1 - Rawah Area\nWilderness Area 2 - Neota Area\nWilderness Area 3 - Comanche Peak Area\nWilderness Area 4 - Cache la Poudre Area`\n\n**40 types of soil**\nRanging from rocky, stony, wet, rubbly to unspecified. If you are curious, press the 'unhide code' button on the next cell to view the extensive list.","707d82ea":"Hover over the parts of the charts to see the actual counts for each type of Tree!","fbebcab3":"### What and Why Bokeh & HoloViews?\n\n*Bokeh*, is an interactive visualization tool best explore the depth of the data given. It's strength is the ability to work fully in Python yet get the sleekness and browser display ability of Javascript. This way it integrates with Kaggle very nicely!  \n\n*HoloViews* is a python library built on top of the Bokeh. It's a branch of a larger family of visualization libaries called PyViz. I particularly like this one because it is a high level library and makes coding up graphs quick and easy. It's clearly designed by data scientists as it fills a big need in the Python community. ","d4b2c1eb":"# Let's Learn Together!\n## [EDA] Exploratory Data Analysis on Theodore Roosevelt National Park dataset\n\n![Roosevelt_header_pic](https:\/\/www.nps.gov\/common\/uploads\/banner_image\/mwr\/homepage\/2118F52C-1DD8-B71B-0B0713EA8F3E1AEA.jpg)\n\nWelcome to this humble notebook, which aims to do a clean and intuitive dataviz + analysis on the dataset given.\n\nFeel free to fork for your own learning and edit the code or use in your own submissions. If you found this enriched your learning in the slightest please **upvote** this notebook as an encouragement for me to continue writing notebooks! :)","51ae049d":"<a id=\"conclusion\"><\/a>\n\n# Conclusion\n\nFrom simple visualization, we can see some rather obvious discriminating features for the certain tree types.\nFor example: Spruce and Krummholz are further away from roads, and Krummholz being in higher elevations.\n\nLater, when checking our model validity these will give some good intuition of the data and enable us to cross-check the accuracy!\n\n### What's Next\n\nIf you found this enriched your learning in the slightest please **upvote** this notebook as an encouragement for me to continue writing notebooks! :)\nAlso, I welcome any requests or discussions below in the notebook. Keep posted for the feature engineering followup part!","c4c99eac":"Some references:\n- https:\/\/www.kaggle.com\/c\/learn-together\/data\n- https:\/\/en.wikipedia.org\/wiki\/Theodore_Roosevelt_National_Park\n- https:\/\/www.slideshare.net\/akrish\/forest-cover-type-prediction\n- https:\/\/www.nps.gov\/thro\/learn\/historyculture\/park-history.htm","4b677c88":"### What are the given Datasets?\n\nWe are given 3 files to work with (on the right, under workspace).\n\n**Train.csv** - main dataset which we will be looking into, and training a ML model on. contains 15210 rows of data, ie. 15210 distinct patches of land with both the features(characteristics) and actual trees recorded. This is also called *ground truth*. \n\n**Test.csv** - a separate file with 565892 rows. That's 565892 types of land patches that we have to make predictions on. Our *target variable* or output is: the type of trees that will be found, given certain characteristics of that patch of land. \n\n**Sample_submission.csv** - a file with two columns, showing that you just need to submit a csv with 'Id' and 'cover_type'. This csv will need to be a size of 565892 rows x 2 columns. ","856fe60a":"You can zoom into the chart with the tools on the right of the chart for further inspection of each soil type!","88dc82be":"## Loading Python Libraries & Datasets","290fe58b":"<a id=\"soil-type\"><\/a>","882fa2ff":"<a id=\"exploratorydataanalysis\"><\/a>\n# Data Exploration & Visualization\n\nIn short - DataViz. An intuitive and pleasing way to understand deeper the dataset that was given to us. \n\nIt enables machine learning practictioners to see data presented visually, so they can grasp difficult concepts or identify new patterns. With interactive visualization, you can take the concept a step further by using technology to drill down into charts and graphs for more detail, interactively changing what data you see and how it\u2019s processed.","5f1a5700":"<a id=\"stackedbars\"><\/a>","84314d7a":"Table of Contents\n* [Introduction](#intro)\n    - [Types of Data in Dataset](#typesofdata)\n\n\n* [Exploratory Data Analysis](#exploratorydataanalysis)\n    - [Visualizing Missing Values](#missingno)\n    - [Interactive Chart: Distribution of Elevation by Cover Type](#distribution)\n    - [Interactive Chart: Stacked Barchart of Wilderness Type](#stackedbar)\n    - [Interactive Chart: Stacked Bars of Soil Type](#soil-type)\n    - [Interactive Chart: Boxplots of Hillshade](#hillshade)\n    - [Interactive Chart: Boxplots of Distance to map Features](#distance)\n    \n    \n* [What's Next](#conclusion)","c174dcee":"Note: you can click on the legend to hide the cover types you wish for a better comparison!","60d45200":"<a id=\"intro\"><\/a>\n# [Introduction] Get to the root of the problem\n\n**Objective of this competition** : predict what type of trees are likely to be in a 30 x 30m patch of land, given 13 types of features (soil conditions, sunlight exposure, elevation, etc).\n\n**Aim of this notebook** : a comprehensive exploration of the dataset given, with interactive and sleek charting using *Bokeh* & *HoloViews* in Kaggle.\n\n**Background of Roosevelt National Park**\n\nTheodore Roosevelt National Park was named after the 26th US president. Interestingly he was well known for using executive orders to protect the environment (among other things). After his passing, this park was created in his honor. The national park is located in North Dakota, where Roosevelt was previously a cattle rancher. It spans over 70,000 acres.\n\nAbove, you can have a view of Roosevelt National Park. It is a good mixture of rocky, mountainous terrain interspersed with low lying valleys and riverbeds. Our job here is to predict which different types of plants will grow on a particular ground type.","ee1de4fa":"<a id=\"hillshade\"><\/a>","bfcf6776":"<a id=\"distance\"><\/a>","04b50f7d":"<a id=\"typesofdata\"><\/a>\n### Table of feature types\n\nData Column| Meaning | Type of Data | Notes \/ Units\n:------------:|:----------------:|:-------:|:------:\nID | an index to identify each 30x30m patch of land | Numerical, Integer | -\nElevation | self explanatory | Discrete numerical, Integer | in meters\nAspect | direction which land is facing | Discrete numerical, Integer | in degrees azimuth\nSlope | how steep a plane of land is | Discrete numerical, Integer | in degrees\nHorizontal_Distance_To_Hydrology | self explanatory | Discrete numerical, Integer | in meters\nVertical_Distance_To_Hydrology | self explanatory | Discrete numerical, Integer | in meters\nHorizontal_Distance_To_Roadways | self explanatory | Discrete numerical, Integer | in meters\nHillshade_9am | how much lighting | Discrete numerical, Ordinal | 0 to 255 index \nHillshade Noon | as above | Discrete numerical, Ordinal | 0 to 255 index \nHillshade 3pm | as above | Discrete numerical, Ordinal | 0 to 255 index \nHorizontal Distance To Fire Points | Horz Dist to nearest wildfire ignition points | Discrete numerical, Integer | in meters\nWilderness Area | Wilderness area designation | Binary | 4 columns, 0 = absence, 1 = presence\nSoil Type | Soil Type designation | Binary |40 binary columns, 0 = absence or 1 = presence\nCover Type | Cover Type designation, our target | Categorical | 7 types, from 1-7\n\n\n"}}