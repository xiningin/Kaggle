{"cell_type":{"6d2a8791":"code","fe144304":"code","dac1c1cd":"code","bba99f60":"code","e6fe530f":"code","5f5b0191":"code","08a69f14":"code","fba6c8d3":"code","7ecf3830":"code","3cdfc981":"code","94af0b6d":"code","434ef55e":"code","b63d36bd":"code","7fe5e631":"code","3c55e678":"code","ed7f6cc3":"code","c0314574":"code","995103e4":"code","4a78435f":"code","c1d6b47c":"code","03582142":"code","4c4f9bb4":"code","b54d9262":"code","645155e0":"code","a4404f82":"code","36667058":"code","5cea2b67":"code","7a419ba3":"code","35556041":"code","9c6432e8":"code","f75de203":"code","5fa2f504":"code","2ac45c72":"code","ee068068":"code","cd40424f":"code","ad0b519f":"code","c359e99d":"code","722d5998":"code","830877e6":"code","30ce0312":"code","d73ebcf1":"code","75c576d0":"code","6c1cc6a6":"code","54d38ad4":"code","5262f73f":"code","2b2edba1":"code","d07b04cb":"code","6b2cfd1b":"code","d83a114d":"code","fc55caff":"code","ade8cc2b":"code","43dd7ac5":"code","6a61d6b0":"code","1a7136ae":"markdown","c206754b":"markdown","4e1637de":"markdown","84a0c82c":"markdown","2cc0beeb":"markdown","6a20f181":"markdown","0a4ecafd":"markdown"},"source":{"6d2a8791":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/\"))\nprint(os.listdir(\"..\/input\/chest_xray\/chest_xray\/\"))\n\n# Any results you write to the current directory are saved as output.","fe144304":"data_dir = '..\/input\/chest_xray\/chest_xray'\nos.listdir(data_dir)","dac1c1cd":"train_dir = os.path.join(data_dir, 'train')\n\nval_dir = os.path.join(data_dir, 'val')\n\ntest_dir = os.path.join(data_dir, 'test')\n\ntrain_dir, val_dir, test_dir, os.listdir(train_dir), os.listdir(val_dir), os.listdir(test_dir)","bba99f60":"# not enough validation images\n# borrow some from training\n\n# delete folders\n!rm -rf 'train'\n!rm -rf 'val'\n!rm -rf 'test'\n\n# new folders\nif not os.path.exists('train'):\n    os.mkdir('train')\n    os.mkdir('train\/ok')\n    os.mkdir('train\/pneu')\nif not os.path.exists('val'):\n    os.mkdir('val')\n    os.mkdir('val\/ok')\n    os.mkdir('val\/pneu')\nif not os.path.exists('test'):\n    os.mkdir('test')\n    os.mkdir('test\/ok')\n    os.mkdir('test\/pneu')\n!echo train\n!ls -l train\n!echo val\n!ls -l val\n!echo test\n!ls -l test\n# copy file\n#from shutil import copyfile\n#copyfile(src, dst)\n\n# old folders\nold_tr_ok = '..\/input\/chest_xray\/chest_xray\/train\/NORMAL'\nold_tr_bad = '..\/input\/chest_xray\/chest_xray\/train\/PNEUMONIA'\nold_val_ok = '..\/input\/chest_xray\/chest_xray\/val\/NORMAL'\nold_val_bad = '..\/input\/chest_xray\/chest_xray\/val\/PNEUMONIA'\nold_test_ok = '..\/input\/chest_xray\/chest_xray\/test\/NORMAL'\nold_test_bad = '..\/input\/chest_xray\/chest_xray\/test\/PNEUMONIA'\n\nimport shutil\n\ndef copy_all_to(src_dir, dst_dir):\n    # copy file, duplicates!\n    i=0\n    for f in os.listdir(src_dir):\n        #print('copy',f,'from',src_dir,'to',dst_dir)\n        shutil.copyfile(src_dir+'\/'+f, dst_dir+'\/'+f)\n        i+=1\n    print('copied',i,src_dir,dst_dir)\n    \ncopy_all_to(old_tr_ok, 'train\/ok')\ncopy_all_to(old_tr_bad, 'train\/pneu')\ncopy_all_to(old_val_ok, 'val\/ok')\ncopy_all_to(old_val_bad, 'val\/pneu')\ncopy_all_to(old_test_ok, 'test\/ok')\ncopy_all_to(old_test_bad, 'test\/pneu')\n\ndef move_from_to_n(src_dir,dst_dir, n):\n    # move files, no duplicates!\n    fs = os.listdir(src_dir)\n    assert len(fs) >= n\n    i=0\n    targ = fs[-n:]\n    print('targ', targ)\n    for f in targ:\n        print('move_from_to_n', i, f, src_dir, dst_dir)\n        os.rename(src_dir+'\/'+f, dst_dir+'\/'+f)\n        i+=1\n    print('copied',i,src_dir,dst_dir)\n    \nn=50\n\nval_ok_sz = len(os.listdir('val\/ok'))\nval_bad_sz = len(os.listdir('val\/pneu'))\nprint('val size', val_ok_sz, val_bad_sz)\n\n# too few val\/ok and val\/pneu\nif val_ok_sz < n:\n    src, dst = 'train\/ok', 'val\/ok'\n    move_from_to_n(src,dst, n)\nif val_ok_sz < n:\n    src, dst = 'train\/pneu', 'val\/pneu'\n    move_from_to_n(src,dst, n)\n\n\nval_ok_sz = len(os.listdir('val\/ok'))\nval_bad_sz = len(os.listdir('val\/pneu'))\nprint('val size', val_ok_sz, val_bad_sz)\n\ntrain_dir = os.path.join('train')\nval_dir = os.path.join( 'val')\ntest_dir = os.path.join( 'test')\n\ntrain_dir, val_dir, test_dir","e6fe530f":"from PIL import Image","5f5b0191":"train_data = []\n\ntrain_ok_dir = os.path.join(train_dir, 'ok')\nfor f in os.listdir(train_ok_dir):\n    if '.jpeg' in f:\n        train_data.append((os.path.join(train_ok_dir,f), 0))\n\ntrain_bad_dir = os.path.join(train_dir, 'pneu')\nfor f in os.listdir(train_bad_dir):\n    if '.jpeg' in f:\n        train_data.append((os.path.join(train_bad_dir,f), 1))\n\nlen(train_data), train_data[0], train_data[-1]","08a69f14":"test_data = []\n\ntest_ok_dir = os.path.join(test_dir, 'ok')\nfor f in os.listdir(test_ok_dir):\n    if '.jpeg' in f:\n        test_data.append((os.path.join(test_ok_dir,f), 0))\n\ntest_bad_dir = os.path.join(test_dir, 'pneu')\nfor f in os.listdir(test_bad_dir):\n    if '.jpeg' in f:\n        test_data.append((os.path.join(test_bad_dir,f), 1))\n\nlen(test_data), test_data[0], test_data[-1]","fba6c8d3":"img = Image.open(train_data[0][0])\n\nimg","7ecf3830":"img.size","3cdfc981":"img_sm = img.resize((150,150))\nimg_sm","94af0b6d":"img_sm.size","434ef55e":"label = train_data[0][1]\nimg.size, label","b63d36bd":"from keras.preprocessing.image import ImageDataGenerator","7fe5e631":"train_data_gen = ImageDataGenerator(rotation_range=20, \n                                    zoom_range=0.2,\n                                    width_shift_range=0.2, \n                                    height_shift_range=0.2,\n                                    rescale=1.\/255)\n\nval_data_gen = ImageDataGenerator(rescale=1.\/255)\n","3c55e678":"train_generator = train_data_gen.flow_from_directory(\n    train_dir,\n    target_size=(150,150),\n    batch_size=20,\n    color_mode='grayscale',\n    class_mode='binary')","ed7f6cc3":"val_generator = val_data_gen.flow_from_directory(\n    val_dir,\n    target_size=(150,150),\n    batch_size=20,\n    color_mode='grayscale',\n    class_mode='binary')","c0314574":"train_generator.labels","995103e4":"# val\nval_generator.labels","4a78435f":"train_samp = train_generator.next()\n\ntrain_samp[0].shape, len(train_samp), len(train_samp[0])","c1d6b47c":"from keras import layers\nfrom keras import models","03582142":"last_conv_layer=None","4c4f9bb4":"def make_model():\n    global last_conv_layer\n    model = models.Sequential()\n    \n    model.add(layers.Conv2D(32, (3,3), activation='relu',\n                                input_shape=(150,150,1)))\n    model.add(layers.MaxPooling2D((2,2)))\n    \n    model.add(layers.Conv2D(64, (3,3), activation='relu'))\n    model.add(layers.MaxPooling2D((2,2)))\n    \n    model.add(layers.Conv2D(128, (3,3), activation='relu'))\n    model.add(layers.MaxPooling2D((2,2)))\n    \n    last_conv_layer = layers.Conv2D(128, (3,3), activation='relu')\n    model.add(last_conv_layer)\n    model.add(layers.MaxPooling2D((2,2)))\n    \n    model.add(layers.Flatten())\n    \n    model.add(layers.Dropout(0.5))\n    \n    last_layer=32\n    model.add(layers.Dense(last_layer, activation='relu'))\n    model.add(layers.Dense(1, activation='sigmoid'))\n\n    return model","b54d9262":"model = make_model()\nmodel.summary()","645155e0":"last_conv_layer.name","a4404f82":"from keras import optimizers","36667058":"model.compile(loss='binary_crossentropy',\n             optimizer='adam',\n             metrics=['acc'])","5cea2b67":"import keras.callbacks\n","7a419ba3":"## model checkpointing\nfilepath='weights.val_loss-{val_loss:.2f}.val_acc-{val_acc:.2f}.epoch-{epoch:02d}.hdf5'\ncheckpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\ncallbacks_list = [checkpoint]","35556041":"#assert False \"TODO: need validation generator\"\nhistory = model.fit_generator(\n                train_generator,\n                steps_per_epoch=250,\n                epochs=50,\n                validation_data=val_generator,\n                validation_steps=50,\n                callbacks=callbacks_list)\n# p137","9c6432e8":"!ls -lh *.hdf5","f75de203":"#model.save('pneumonia_chest_xray_sm.h5')","5fa2f504":"!ls -lh *.hdf5 | head -1","2ac45c72":"# delete all the other checkpoints\n#!rm *.hdf5","ee068068":"# save model\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)","cd40424f":"!ls -lh model.json","ad0b519f":"import matplotlib.pyplot as plt","c359e99d":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc)+1)\n\nplt.plot(epochs, acc, 'bo', label='Training Acc.')\nplt.plot(epochs, val_acc, 'b', label='Validation Acc.')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()\n","722d5998":"from keras import backend as K","830877e6":"print('test files', len(os.listdir('test\/pneu\/')))\nx = os.listdir('test\/pneu\/')[0]\nx = 'test\/pneu\/'+x\nprint(x)\n\npic = Image.open( x )\n\ndef preproc_im(x, crop=None):\n    print('preproc_im', x)\n    x = Image.open( x )\n    \n    if crop:\n        w, h = pic.size\n        cx,cy,cw,ch = crop\n        x_crop = pic.crop((cx, cy, w-cw, h-ch )) # 0, 180, w, h-50\n    \n    x = x.resize((150,150))\n    x = np.array(x).astype('float32')\n    x \/= 255.\n    x=x.reshape(150, 150, 1)\n    print(x.shape)\n\n    #make it 4d\n    x = np.array([x])\n    print(x.shape)\n    #print(x)\n    return x\n\n\npic","30ce0312":"nx = preproc_im(x)\nnx.shape\n\n","d73ebcf1":"\n# pred = model.predict(x)\npred = model.predict(nx)\n\npred","75c576d0":"# p 174\n\npneumonia_output = model.output[:1]\nprint('pneumonia_output', pneumonia_output.shape)\n\n# last_conv_layer.name\n# last_conv_layer = model.get_layer('conv2d_8')\nlast_conv_layer = model.get_layer(last_conv_layer.name)\nprint('last_conv_layer', last_conv_layer)\n\ngrads = K.gradients(pneumonia_output, last_conv_layer.output)[0]\nprint('grads', grads.shape)\n\npooled_grads = K.mean(grads, axis=(0,1,3))\nprint('pooled_grads', pooled_grads.shape)\n\niterate = K.function([model.input],\n                    [pooled_grads, last_conv_layer.output[0]])\n\n#pooled_grads_value, conv_layer_output_value = iterate([x_crop])\npooled_grads_value, conv_layer_output_value = iterate([nx])\nprint('pooled_grads_value', pooled_grads_value.shape)\nprint('conv_layer_output_value', conv_layer_output_value.shape)\n\nfor i in range(15):\n    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n\nheatmap = np.mean(conv_layer_output_value, axis=-1)","6c1cc6a6":"heatmap = np.maximum(heatmap, 0)\nheatmap \/= np.max(heatmap)\n\nplt.matshow(heatmap, cmap='hot')","54d38ad4":"len(test_data)","5262f73f":"test_data_gen = ImageDataGenerator(rescale=1.\/255)\n\ntest_generator = test_data_gen.flow_from_directory(\n    test_dir,\n    target_size=(150,150),\n    batch_size=20,\n    color_mode='grayscale',\n    class_mode='binary')","2b2edba1":"test_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntest_generator = test_datagen.flow_from_directory(\n        test_dir,\n        target_size=(150, 150),\n        color_mode=\"grayscale\",\n        shuffle = False,\n        class_mode='categorical',\n        batch_size=1)\n\nfilenames = test_generator.filenames\nnb_samples = len(filenames)\n\npredict = model.predict_generator(test_generator,steps = nb_samples)","d07b04cb":"rights, wrongs =0,0\nfor i,pre in enumerate(predict):\n    name=filenames[i]\n    rnd = round(pre[0])\n    dir_truth={'ok':0,'pneu':1 }\n    right=False\n    if 'ok' in name: right=(rnd==0)\n    if 'pneu' in name: right=(rnd==1)\n    if right:\n        rights+=1\n    else:\n        wrongs+=1\n    print(i, pre, rnd, right,name )","6b2cfd1b":"rights, wrongs","d83a114d":"rights\/len(predict), wrongs\/len(predict)","fc55caff":"# delete images so files<500, error","ade8cc2b":"!ls -l ","43dd7ac5":"!rm -rf val\/ test\/ train\/","6a61d6b0":"!ls -lh","1a7136ae":"## plot accuracy","c206754b":"## checkpoint and save weights\n\nusing val_loss, so lower is better","4e1637de":"## save model to json","84a0c82c":"## make model","2cc0beeb":"## heatmap of pneumonia","6a20f181":"## Pre process data","0a4ecafd":"## Train"}}