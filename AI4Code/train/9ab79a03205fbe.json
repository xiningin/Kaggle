{"cell_type":{"a8abab25":"code","5ec81d72":"code","8d09877f":"code","d3be0859":"code","20a7d88b":"code","473334e7":"code","a2c30946":"code","c54ca49b":"code","0eb2f66f":"code","37aafb89":"code","a3f0cdf0":"code","9eaa71ea":"code","abb4eeb2":"code","429530e6":"code","0a943922":"code","2c848f92":"code","de2ef40b":"code","dff77575":"code","a2d87b4d":"code","d8e5c82c":"code","6e62544d":"code","448f0848":"code","613e923d":"code","e7fd00e6":"code","c4296bd1":"code","5fedc210":"code","5b356c29":"code","a831f534":"code","efe620fe":"code","ca7a4202":"code","9e335ab7":"code","f8f5517a":"code","a5b5c624":"code","e52e64b6":"markdown","87a17f60":"markdown","067fe1b2":"markdown","f8104c2f":"markdown","65b147db":"markdown","55cac2e8":"markdown","2d5f6fcc":"markdown","b2fc0902":"markdown","49209289":"markdown","75b54ba3":"markdown","b2d828d0":"markdown","09447413":"markdown","ba0e112e":"markdown","4b453db4":"markdown","97c3dfd5":"markdown","9d350a57":"markdown","0c146abf":"markdown","7a206681":"markdown","d8e1d2a4":"markdown","1dbe7416":"markdown","2fb26bd4":"markdown","802a35e6":"markdown","1e774873":"markdown","f4fc2951":"markdown","4f47ad65":"markdown","08c28818":"markdown","5406c0fc":"markdown","c607620c":"markdown","0f0922e6":"markdown","112c5006":"markdown","ba7f4e45":"markdown","8199b699":"markdown"},"source":{"a8abab25":"import pandas as pd\nimport re\nimport string\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nimport numpy as np","5ec81d72":"# Load and view data\ndf = pd.read_csv('..\/input\/data-scientist-job-market-in-the-us\/alldata.csv')\ndf.head()","8d09877f":"# Check if there are any NaNs in the data\ndf.isnull().sum()","d3be0859":"# Drop column Review from the data\ndf.drop(columns = 'reviews', inplace = True)","20a7d88b":"# Filtered the data set to remove the rest of the rows containing NaNs value\ndf.drop(index = df[df['position'].isnull()].index, inplace = True)\ndf.isnull().any()","473334e7":"# Create city and state columns to better aggregate the data\ndf['location'] = df.location.apply(lambda x: re.sub('\\d*','',str(x)))\ndf['city'] = df.location.apply(lambda x: x.split(',')[0].strip())\ndf['state'] = df.location.apply(lambda x: x.split(',')[1].strip())\ndf['location'] = df['city']+ ', ' + df['state']\ndf.head()","a2c30946":"# Group position name into 5 types\ndata = df.copy()\ndata['position']=[x.upper() for x in data['position']]\ndata.loc[data.position.str.contains(\"SCIENTIST\"), 'position'] = 'Data Scientist'\n\ndata.loc[data.position.str.contains('ENGINEER'),'position']='Machine Learning Engineer'\ndata.loc[data.position.str.contains('PRINCIPAL STATISTICAL PROGRAMMER'),'position']='Machine Learning Engineer'\ndata.loc[data.position.str.contains('PROGRAMMER'),'position']='Machine Learning Engineer'\ndata.loc[data.position.str.contains('DEVELOPER'),'position']='Machine Learning Engineer'\n\ndata.loc[data.position.str.contains('ANALYST'), 'position'] = 'Data Analyst'\ndata.loc[data.position.str.contains('STATISTICIAN'), 'position'] = 'Data Analyst'\n\ndata.loc[data.position.str.contains('MANAGER'),'position']='Data Science Manager'\ndata.loc[data.position.str.contains('CONSULTANT'),'position']='Data Science Manager'\ndata.loc[data.position.str.contains('DATA SCIENCE'),'position']='Data Science Manager'\ndata.loc[data.position.str.contains('DIRECTOR'),'position']='Data Science Manager'\n\ndata.position=data[(data.position == 'Data Scientist') | (data.position == 'Data Analyst') | (data.position == 'Machine Learning Engineer') | (data.position == 'Data Science Manager')]\ndata.position=['Others' if x is np.nan else x for x in data.position]","c54ca49b":"title = data.groupby(['position']).count().sort_values('company')\n\ntitle['company'].plot(kind='barh',figsize = (10,5))\nplt.xlabel('Count', size = 12)\nplt.ylabel('')\nplt.yticks(size = 10)\nplt.xticks(size = 10)\nplt.title('Number of Positions by Job Title', size = 20)\nplt.show()\n","0eb2f66f":"company = df.groupby(['company']).count().sort_values('position').tail(20)\n\ncompany['position'].plot(kind='barh',figsize = (10,5))\nplt.xlabel('Count', size = 12)\nplt.ylabel('')\nplt.yticks(size = 10)\nplt.xticks(size = 10)\nplt.title('Number of Positions by Companies (Top 20)', size = 20)\nplt.show()","37aafb89":"city = df.groupby(['location']).count().sort_values('position').tail(20)\n\ncity['position'].plot(kind='barh',figsize = (10,5))\nplt.xlabel('Count', size = 12)\nplt.ylabel('')\nplt.yticks(size = 10)\nplt.xticks(size = 10)\nplt.title('Number of Positions by Cities (Top 20)', size = 20)\nplt.show()","a3f0cdf0":"state = df.groupby('state').count().sort_values('position',ascending = False)\n\nstate['position'].plot(kind = 'bar',figsize = (10,5) ,width = 0.85)\nplt.xlabel('')\nplt.ylabel('Count',size = 12)\nplt.title('Number of Positions by State', size = 20)\nplt.yticks(size = 10)\nplt.xticks(size = 10, rotation = 720)\nplt.show()","9eaa71ea":"data = data[data['position'] != 'Others']\ni = 1\ncolor = ['#A92420','#8A6FDF','#135390','#FDA649']\nfig = plt.figure(figsize=(20,10))\nfor position in data.position.unique():\n    x = data[data['position']== str(position)].groupby(['state']).count().sort_values('company')\n    plt.subplot(2, 2, i)\n    i += 1\n    plt.bar(x.index,x['company'], color = color[i-2])\n    plt.xlabel('')\n    plt.xticks(size = 10)\n    plt.title(str(position), size = 15)\nplt.show()","abb4eeb2":"# Example of a description value\ndf.description.values[0][0:int(len(df.description.values[0])\/2)]","429530e6":"# Combine the desciptions by the job tilte\ndata = data.groupby('position').agg(lambda col: ' '.join(col))\ndata = data[['description']]","0a943922":"# Create a function to clean text data\ndef clean_text(text):\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text).lower() #remove punctutations\n    text = re.sub('\\w*\\d\\w*', '', text)\n    text = re.sub('[\u2018\u2019\u201c\u201d\u2026]', '', text)\n    text = re.sub('\\n',' ',text)\n    return text","2c848f92":"# Clean the text data and remove the job title 'Others'\nclean = lambda x :clean_text(x)\ndf_clean = pd.DataFrame(data.description.apply(clean))\ndf_clean = df_clean[df_clean.index != 'Others'].copy()","de2ef40b":"# Lemmentize the text data to improve analysis\nlemmer = WordNetLemmatizer()\ndf_clean['description'] = df_clean.description.apply(lambda x: word_tokenize(x))\ndf_clean['description'] = df_clean.description.apply(lambda x : [lemmer.lemmatize(y) for y in x])\ndf_clean['description'] = df_clean.description.apply(lambda x: ' '.join(x))","dff77575":"# Add words that frequently appear in the descriptions but carry no value to the list of stop words\nfrom sklearn.feature_extraction import text\nextra_stopword = ['data','experience','work','team','will','skill','year','skills']\nstop_words = text.ENGLISH_STOP_WORDS.union(extra_stopword)","a2d87b4d":"from wordcloud import WordCloud\n\nwc = WordCloud(stopwords=stop_words, background_color=\"white\", colormap=\"Dark2\",\n             random_state=42, collocations = False, width=1600, height=800)\ni = 0\nfig = plt.figure(figsize=(15,8))\nfor x in df_clean.description.index:\n    wc.generate(df_clean.description[str(x)])\n    \n    i += 1\n    fig.add_subplot(2, 2, i)\n    plt.imshow(wc, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.title(str(x), size = 15)\nplt.show()","d8e5c82c":"text = df.description.values","6e62544d":"# Print out the first 5 examples of matches\nlimit = 0\nfor t in text:\n    for sentance in t.split('\\n'):\n        if 'experience' in sentance:\n            year = re.findall(\"\\d{1,2}\\+? year\", sentance)\n            if len(year)==1:\n                print(year[0])\n                print(sentance)\n                print(\"*\"*20)\n                limit +=1\n    if limit >= 5:\n        break","448f0848":"# Compile the year value found into a list\nexperience_req = []\nfor t in text:\n    for sentance in t.split('\\n'):\n        if 'experience' in sentance:\n            year = re.findall(\"\\d{1,2}\\+? year\", sentance)\n            if len(year)==1:\n                num = year[0].split(' ')\n                experience_req.append(num[0])","613e923d":"# Remove the '+' sign after year value\nfor n,i in enumerate(experience_req):\n    if \"+\" in i:\n        experience_req[n] = re.sub(r'\\+','',i)\nexperience_req = [int(item) for item in experience_req]","e7fd00e6":"# Remove outliers\nfor n,i in enumerate(experience_req):\n    if i >= 20:\n        experience_req.pop(n)","c4296bd1":"plt.figure(figsize = (10,5))\nplt.hist(experience_req,bins = list(range(0,21,2)), align = 'left')\nplt.title('Experience Required Distribution', size = 15)\nplt.ylabel('Bin Count')\nplt.xlabel('Year of Expereience', size = 12)\nplt.show()\nprint(f'The average year of experience required is {round(np.mean(experience_req),2)} years')","5fedc210":"# Create a regex search function\ndef count_text(patt,text):\n    pattern = re.compile(patt)\n    count = 0\n    for t in text:\n        if pattern.search(t):\n            count+=1\n    return count","5b356c29":"# Create a data frame with skills name and regex pattern to search with\nskills = ['R','Python','Hadoop','SQL','Tableau','TensorFlow','Agile','Power BI','SSaS','Algorithm','Java','Visualization']\n\nskill_patt = ['\\WR\\W+\\s*','(?i)\\WPython\\W','(?i)\\WHadoop\\W?','(?i)SQL\\w*','(?i)\\WTableau\\W?',\n              \"(?i)\\WTensorFlow\\W?\",\"(?i)\\WAgile\\W?\",\"(?i)\\WPower\\s?BI\\W?\",\n             \"(?i)\\WSSAS\\W?\",\"(?i)\\WAlgorithms?\\W?\",'(?i)Java\\w*','(?i)\\WVisualization\\W?']\n\nskill_df =pd.DataFrame(\n    {\"skill\": skills,\n     \"regex_pattern\":skill_patt})","a831f534":"# Iterate through the list of skill using the search function created\ni = []\nfor x in skill_df['regex_pattern']:\n    i.append(count_text(x,text))\nskill_df['count'] = i\nskill_df['ptg'] = round(skill_df['count']\/len(text),2)\nskill_df","efe620fe":"x = skill_df.sort_values(by = 'ptg')\nax =x['ptg'].plot(kind = \"barh\",figsize = (10,5))\nax.set_title('Skills as Percentage of Total Job Description', size = 15)\nax.set_yticklabels(x['skill'], size = 12)\nax.set_xticklabels(['{:.0%}'.format(x) for x in ax.get_xticks()])\nplt.show()","ca7a4202":"# Define regex pattern and seach for PhD\npattern = re.compile('(?i)\\WPh.?D\\W')\npattern2 = re.compile('(?i)\\WDoctorate\\W')\ncount = 0\nfor t in text:\n    if pattern.search(t):\n        count +=1\n    elif pattern2.search(t):\n        count +=1\ndegree = {\"PhD\": count}","9e335ab7":"# Define regex pattern and seach for Master \npattern = re.compile(\"(?i)\\WMasters?'?s?\\W\")\npattern2 = re.compile('(?i)\\WM.?S\\W')\ncount = 0\nfor t in text:\n    if pattern.search(t):\n        count +=1\n    elif pattern2.search(t):\n        count +=1\ndegree.update({\"Master\":count})","f8f5517a":"degree = pd.DataFrame.from_dict(degree,orient='index',\n                       columns=[ 'count'])\ndegree['ptg'] = degree['count']\/len(text)","a5b5c624":"ax =degree['ptg'].plot(kind = \"bar\", figsize =(10,5))\nax.set_title('Percentage of Total Documents')\nax.set_xticklabels(degree.index)\nax.set_yticklabels(['{:.0%}'.format(x) for x in ax.get_yticks()])\nplt.show()","e52e64b6":"This data set contains 6953 rows with 5 columns: Position, Company, Job Description, Review, and Location.","87a17f60":"In this section, I'll utilize **pandas** and **matplotlib** to answer the following questions:\n\n- What is the is the most common job to appear when searching for 'Data Science'?\n- Which company hire the most Data Science job?\n- From the data, which cities and state hire the most?","067fe1b2":"## Text Analysis <a id='textanalysis'><\/a>","f8104c2f":"In order to aggregate the data, I've created City and State columns based on the Location column of the original data set. ","65b147db":"### Text Cleaning and Prepration <a id='textclean'><\/a>","55cac2e8":"### Word Cloud <a id='wordcloud'><\/a>","2d5f6fcc":"Even though the city with the highest number of positions is New York, the highest number of position by state is California, follows by Massachusetts and Washington. ","b2fc0902":"From the chart, we can see that Amazon.com hire the most candidate, follow by Ball Aerospace, Microsoft and Google. ","49209289":"### Positions by Companies <a id='company'><\/a>","75b54ba3":"## Data Preparation<a id='DataPreparation'><\/a>","b2d828d0":"- For Data Science Manager, Data Scientist and Machine Learning Engineer, California is the state that hire the most position\n- For Data Analyst, it seems that New York hires the most position, follow closely by California","09447413":"### Data Cleaning <a id='cleaning'><\/a>","ba0e112e":"## Conclution <a id='conclution'><\/a>","4b453db4":"In order to clean the data, I checked for the number of NaNs in each column. Since the Review column has the greatest number of NaNs, I decided to drop it all together since I won't be doing analysis on it. For the rest of the NaNs, I filtered the data frame to leave out all the rows containing null values. ","97c3dfd5":"*Table of contents*\n\n* <a href = '#DataPreparation'>Data Preparation<\/a>\n    - <a href = '#cleaning'>Data Cleaning<\/a>\n    - <a href = '#newclumn'>Populate New Columns<\/a>\n    <br\/><br\/>\n* <a href = '#eda'>Exploratory Data Analysis<\/a>\n    - <a href = '#title'>Positions by Title<\/a>\n    - <a href = '#company'>Positions by Company<\/a>\n    - <a href = '#city'>Position by Cities<\/a>\n    - <a href = '#state'>Position by State<\/a>\n    - <a href = '#statetitle'>Position by State and Job Title<\/a>\n    <br\/><br\/>\n* <a href = '#textanalysis'>Text Analysis<\/a>\n    - <a href = '#textclean'>Text Cleaning and Prep<\/a>\n    - <a href = '#wordcloud'>Visualization<\/a>\n        - <a href = '#wordcloud'>WordCloud<\/a>\n        - <a href = '#experience'>Year of Experience Requirement<\/a>\n        - <a href = '#skill'>Skills Requirement<\/a>\n        - <a href = '#degree'>Degree Requirement<\/a>\n    <br\/><br\/>\n* <a href = '#conclution'>Conclusion<\/a>\n    ","9d350a57":"## Introduction\n\nI'm currently a senior studying business analytics at Drexel University. As the graduation soon approaches, I've been actively looking for job in the analytics field. I wondered if there is a trend on what companies are looking for, what are the requirements, what can I do to make optimize my job search, so I set out to look for data on this subject.\n\nLuckily for me, I came across this <a href = 'https:\/\/www.kaggle.com\/sl6149\/data-scientist-job-market-in-the-us'>Kaggle dataset<\/a> uploaded by ShaShan Lu. He scrapped 7000 job posting from indeed.com with the search term of \"Data Science\". Though the data is collected in 2018, I believe that the insights I get from analyzing this data will still be very beneficial for me to have.\n\nI'll approach this data by performing EDA on the general dataset and text analysis on the job description. Any comments, recommendations and advice on this notebook would be much appreciated!","0c146abf":"Since position titles are varied from one company to another, the following code block will categorize the titles into 5 groups: Data Scientist, Machine Learning Engineer, Data Analyst, Data Science Manager, and Others.\n\n*Note: I want to give credit to Pramod Manjegowda for the following code block. Pramad followed a machine learning approach toward this data set. You can take a look at his notebook <a href ='https:\/\/www.kaggle.com\/pramod7\/data-science-jobs-opening-in-us-analysis-ml'>here<\/a>.* ","7a206681":"### Positions by Cities <a id='city'><\/a>","d8e1d2a4":"This project provided me with valuable insights on what the companies are looking for in a data science candidate. There are a few things I wish to improve especially in the text analysis portion. I hope to learn more on how to better use regular expression so I can get a better precision on my matches.\n\nAs a senior looking to break into data science and pursue a career as a Data Analyst, this are the key takeaways:\n- To improve my chances, I should be looking into jobs in NY, CA, MA, and WA. Especially in the cities of New York, Seattle, Boston, and San Fran.\n- Since I already have some knowledge of Python, R and SQL, I should continue to improve these skills find a way to showcase my knowledge.\n- I should really consider going for a Master's degree since a lot of job prefer a candidate with one.\n- The average work experience required is 4-5 years, so I need to find an entry level analyst and do more project to satisfy this requirement.\n\nThank you for going through my notebook! I hope you found some of these findings useful or at least somewhat interesting.\n\nFeel free to connect with me through my https:\/\/www.linkedin.com\/in\/hoangvu97\/ or send me an email at tronghoang97@gmail.com ","1dbe7416":"### Position by State and Job Title <a id='statetitle'><\/a>","2fb26bd4":"### Populate New Columns <a id='newclumn'><\/a>","802a35e6":"## Exporatory Data Analysis<a id='eda'><\/a>","1e774873":"### Positions by States <a id='state'><\/a>","f4fc2951":"In this section, I will focus on the Job Description column of the data. By using libraries like **re, wordcloud, matplotlib**, I hope to gain further insights on the requirements for the field of data science. I will try to answer the following questions:\n- What are the companies looking for when hiring?\n- How many years of experience do they required?\n- What level of education do the companies prefer?","4f47ad65":"### Year of Experience Required <a id='experience'><\/a>","08c28818":"### Degree Requirement <a id='degree'><\/a>","5406c0fc":"Here are my interpretations from looking at the WordCloud:\n- Data Analyst will be doing **research**, **analysis** and **provide** insights to facilitate better **business** decision.\n- Data Science Manager will be in charge of **developing** **product** to help **business** serve its **customer** better.\n- Data Scientist will be doing **research**, implementing **machine learning** and building **model** to come up with business solution.\n- Machine Learning Engineer will **design** and **develop** **software** for business or customer. ","c607620c":"# Data Science Job Market EDA and Text Analysis\n*By: <a href = 'https:\/\/www.linkedin.com\/in\/hoangvu97\/'>Hoang Vu<\/a>*","0f0922e6":"In the following section, I will utilize regular expression to search and locate text strings with in a document.\n\n*Note: I'm still a novice with regex so any recommendation on how to improve my matches will be very much appreciated!*","112c5006":"It appears that the top 5 cities that hire the most data science related job are New York, Seattle, Cambridge, Boston, and San Francisco. It makes sense since those cities are the technology hub of the country. ","ba7f4e45":"### Positions by Job Title <a id='title'><\/a>","8199b699":"### Skill Requirement <a id='skill'><\/a>"}}