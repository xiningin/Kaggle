{"cell_type":{"c491257c":"code","a501121b":"code","e7076932":"code","df224618":"code","225a43b3":"code","b740c493":"code","6b2f1e0d":"code","7f4d3155":"code","522deacb":"code","4e475ee8":"code","b89ba4f8":"code","d2d34117":"code","4f0717ca":"code","3ed8a1d4":"code","aab68a02":"markdown","0a327d6f":"markdown","8d85818a":"markdown","d557204c":"markdown","0f6b65de":"markdown","65415a63":"markdown"},"source":{"c491257c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a501121b":"import tensorflow as tf\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\nfrom tensorflow.keras.regularizers import l2","e7076932":"class LeNet5(Model):\n  '''\n  LeNet5 Model\n\n  Attributes\n  -----------------\n  conv1: tf.keras.layers\n    Convolutional layer of model\n  max_pool1: tf.keras.layers\n    Maxpooling layer of model\n  conv2: tf.keras.layers\n    Convolutional layer of model\n  max_pool2: tf.keras.layers\n    Maxpooling layer of model\n  flatten: tf.keras.layers\n    Flatten layer of model \n  dense1: tf.keras.layers\n    Dense layer of model\n  dense2: tf.keras.layers\n    Dense layer of model\n  dense3: tf.keras.layers\n    Output Layer of model\n  '''\n\n  def __init__(self, num_classes, reg=0):\n    '''\n    Initialize the model\n    :param num_classes: number of classes to predict from\n    '''\n\n    super(LeNet5, self).__init__()\n    #building the various layers that compose our LeNet-5:\n    self.conv1 = Conv2D(6, kernel_size=(5,5), padding='same', activation='relu', activity_regularizer=l2(reg))\n    self.max_pool1 = MaxPooling2D(pool_size=(2,2))\n    self.conv2 = Conv2D(16, kernel_size=(5,5), activation='relu', activity_regularizer=l2(reg))\n    self.max_pool2 = MaxPooling2D(pool_size=(2,2))\n    self.flatten = Flatten()\n    self.dense1 = Dense(120, activation='relu', activity_regularizer=l2(reg))\n    #self.dropout = Dropout(0.2)\n    self.dense2 = Dense(84, activation='relu', activity_regularizer=l2(reg))\n    self.dense3 = Dense(num_classes, activation='softmax', activity_regularizer=l2(reg))\n\n  def call(self, inputs):\n    '''\n    Call the layers and perform their operations on the input tensors\n    :param inputs:  Input tensor\n    :return:        Output tensor\n    '''\n    x = self.max_pool1(self.conv1(inputs)) # 1st block\n    x = self.max_pool2(self.conv2(x)) # 2nd block\n    x = self.flatten(x) \n    x = self.dense2(self.dense1(x))\n    x = self.dense3(x) #fully conected layers\n    return x","df224618":"num_classes = 10\nimg_rows, img_cols, img_ch = 28, 28, 1\ninput_shape = (img_rows,img_cols,img_ch)\n\n# load data\ntrain = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\nX_test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","225a43b3":"train.head()","b740c493":"Y_train = train.iloc[:,0]\nX_train = train.iloc[:,1:]\n\nX_train = X_train.to_numpy()\nX_test = X_test.to_numpy()\nY_train = Y_train.to_numpy()\n\ntemp = X_train.reshape(-1,28,28)\nX_test = X_test.reshape(-1,28,28)\n\nX_train = temp.reshape(-1,28,28,1)\nX_test = X_test.reshape(-1,28,28,1)\n\nX_train = X_train\/255.\nX_test = X_test\/255.\n\nY_train = tf.keras.utils.to_categorical(Y_train)","6b2f1e0d":"print(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)","7f4d3155":"# compile model\nmodel = LeNet5(num_classes, 1e-5)\nmodel.compile(  tf.keras.optimizers.Adam(learning_rate=1e-4), loss = 'categorical_crossentropy',\n                metrics = 'accuracy' )\n\n# create callbacks\ncallbacks = [ \n  tf.keras.callbacks.ModelCheckpoint('best_model', monitor='val_accuracy', verbose=1, save_best_only=True),\n  tf.keras.callbacks.ReduceLROnPlateau( factor = 0.1, patience = 3, min_lr = 0.00001, verbose = 1 )\n ]\n\nhistory = model.fit(X_train, Y_train, epochs = 50, batch_size = 256,\n                    callbacks = callbacks, verbose = 1,\n                    validation_split=0.2 )","522deacb":"scores = model.evaluate(X_train, Y_train)","4e475ee8":"y_pred = model.predict(X_test)\nprint(y_pred.shape)","b89ba4f8":"preds = np.argmax(y_pred,axis=1)\npreds.shape","d2d34117":"y_pred.shape[0]","4f0717ca":"y_pred.shape[0]\noutput = pd.DataFrame({'ImageId': [x for x in range(1,y_pred.shape[0]+1)], 'Label': preds})\noutput.head()","3ed8a1d4":"output.to_csv('Y_test.csv', index=False)\nmodel.save(\"saved_model\")","aab68a02":"### Confirming our data shape","0a327d6f":"# Preprocessing","8d85818a":"# Evaluate model","d557204c":"# Train model","0f6b65de":"# LeNet5 Model","65415a63":"# Predict model"}}