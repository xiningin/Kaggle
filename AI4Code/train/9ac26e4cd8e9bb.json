{"cell_type":{"1a0fef18":"code","6b2f6ff2":"code","2a878267":"code","634cad9a":"code","dfd73c1c":"code","72dbfa13":"code","25b7d275":"code","ef6cf00c":"code","55f6c88e":"code","7d121d9d":"code","15c3b289":"code","5f518014":"code","e745267f":"code","9f5eda10":"code","7d094a20":"code","bbda28a9":"code","7936e0ec":"code","95166817":"code","7786719b":"code","d916df08":"code","82874a91":"code","92a6ab78":"code","e60fe1ab":"code","1b667762":"code","98e0eeb8":"code","11453635":"code","167c8dc4":"code","47389336":"code","210b6c06":"code","b67566e9":"code","5cb6bad2":"code","42d99357":"code","95b2a67f":"code","70c20ff0":"code","7192d6f2":"code","87d23f5f":"markdown","986067aa":"markdown","6ec47854":"markdown","de9dc3f3":"markdown","b31c118a":"markdown","9b0f7e3f":"markdown","ecc222da":"markdown","8597bdaf":"markdown","af9bb356":"markdown","c824be53":"markdown","d734d1fe":"markdown","059ed11b":"markdown","fc348fc5":"markdown","35f57f68":"markdown","d969b3f2":"markdown","51e66a20":"markdown","8d514f3c":"markdown","a966eed3":"markdown","a9c1719e":"markdown","dbdd4715":"markdown","a86ead47":"markdown","4ce6e293":"markdown","3c5c6fe5":"markdown","9bd783b0":"markdown"},"source":{"1a0fef18":"import os\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport json\nfrom collections import Counter\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.utils import to_categorical, Sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Activation\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.applications import ResNet50\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","6b2f6ff2":"path = '\/kaggle\/input\/herbarium-2021-fgvc8\/'\nos.listdir(path)","2a878267":"samp_subm = pd.read_csv(path+'sample_submission.csv')","634cad9a":"with open(path+'train\/'+'metadata.json') as f:\n    train_data = json.load(f)\nwith open(path+'test\/'+'metadata.json') as f:\n    test_data = json.load(f)","dfd73c1c":"def plot_examples():\n    fig, axs = plt.subplots(4, 4, figsize=(20, 20))\n    fig.subplots_adjust(hspace = .1, wspace=.1)\n    \n    axs = axs.ravel()\n    for i in range(16):\n        img = cv2.imread(path+'train\/'+train_data['images'][i]['file_name'])\n        axs[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n        axs[i].set_title(train_data['categories'][i]['family'])\n        axs[i].set_xticklabels([])\n        axs[i].set_yticklabels([])\n    plt.show()","72dbfa13":"print('Number of train images:', len(train_data['images']))\nprint('Number of test images:', len(test_data['images']))","25b7d275":"train_data['annotations'][0]","ef6cf00c":"train_data['categories'][0]","55f6c88e":"train_data['images'][0]","7d121d9d":"train_data['info']","15c3b289":"train_data['licenses'][0]","5f518014":"train_data['institutions'][0]","e745267f":"test_data['images'][0]","9f5eda10":"test_data['info']","7d094a20":"test_data['licenses'][0]","bbda28a9":"plot_examples()","7936e0ec":"df_image = pd.json_normalize(train_data['images'])\ndf_annot = pd.json_normalize(train_data['annotations'])\ndf_train_data = pd.DataFrame()\ndf_train_data['file_name'] = df_image['file_name']\ndf_train_data['category_id'] = df_annot['category_id']","95166817":"df_train_data, df_val_data = train_test_split(df_train_data, test_size=0.3)\ndf_train_data.index = range(len(df_train_data.index))\ndf_val_data.index = range(len(df_val_data.index))","7786719b":"df_image = pd.json_normalize(test_data['images'])\ndf_test_data = pd.DataFrame()\ndf_test_data['file_name'] = df_image['file_name']\ndf_test_data['category_id'] = 0","d916df08":"print('Number of train samples:', len(df_train_data))\nprint('Number of val samples:', len(df_val_data))\nprint('Number of test samples:', len(df_test_data))","82874a91":"print('Number of categories:', len(df_train_data['category_id'].unique()))","92a6ab78":"df_train_data['category_id'].value_counts()[0:10]","e60fe1ab":"q_size = 64\nimg_channel = 3\nnum_classes = 64500\nbatch_size = 32\nepochs = 5","1b667762":"class DataGenerator(Sequence):\n    def __init__(self, path, list_IDs, labels, batch_size, img_size, img_channel, num_classes):\n        self.path = path\n        self.list_IDs = list_IDs\n        self.labels = labels\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.img_channel = img_channel\n        self.num_classes = num_classes\n        self.indexes = np.arange(len(self.list_IDs))\n\n        \n    def __len__(self):\n        len_ = int(len(self.list_IDs)\/self.batch_size)\n        if len_*self.batch_size < len(self.list_IDs):\n            len_ += 1\n        return len_\n    \n    \n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n        X, y = self.__data_generation(list_IDs_temp)\n        return X, y\n            \n    \n    def __data_generation(self, list_IDs_temp):\n        X = np.zeros((self.batch_size, self.img_size, self.img_size, self.img_channel))\n        y = np.zeros((self.batch_size, self.num_classes), dtype=int)\n        for i, ID in enumerate(list_IDs_temp):\n            img = cv2.imread(self.path+ID)\n            img = cv2.resize(img, (self.img_size, self.img_size))\n            X[i, ] = img\/255\n            y[i, ] = to_categorical(self.labels[i], num_classes=self.num_classes)\n        return X, y","98e0eeb8":"number_samples = 10000\ndf_train_data = df_train_data[0:number_samples]\ndf_val_data = df_val_data[0:number_samples]\ndf_test_data = df_test_data[0:number_samples]","11453635":"train_generator = DataGenerator(path+'train\/', df_train_data['file_name'], df_train_data['category_id'],\n                                batch_size, q_size, img_channel, num_classes)\nval_generator = DataGenerator(path+'train\/',df_val_data['file_name'], df_val_data['category_id'],\n                                batch_size, q_size, img_channel, num_classes)\ntest_generator = DataGenerator(path+'test\/',df_test_data['file_name'], df_test_data['category_id'],\n                                batch_size, q_size, img_channel, num_classes)","167c8dc4":"weights='..\/input\/models\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nconv_base = ResNet50(weights=weights,\n                     include_top=False,\n                     input_shape=(q_size, q_size, img_channel))\nconv_base.trainable = True","47389336":"model = Sequential()\nmodel.add(conv_base)\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(num_classes, activation='sigmoid'))","210b6c06":"model.compile(optimizer = RMSprop(lr=1e-5),\n              loss='binary_crossentropy',\n              metrics=['binary_accuracy'])","b67566e9":"model.summary()","5cb6bad2":"history = model.fit_generator(generator=train_generator,\n                              validation_data=val_generator,\n                              epochs = epochs)","42d99357":"fig, axs = plt.subplots(1, 2, figsize=(20, 6))\nfig.subplots_adjust(hspace = .2, wspace=.2)\naxs = axs.ravel()\nloss = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1, len(loss)+1)\naxs[0].plot(epochs, loss, 'bo', label='loss_train')\naxs[0].plot(epochs, loss_val, 'ro', label='loss_val')\naxs[0].set_title('Value of the loss function')\naxs[0].set_xlabel('epochs')\naxs[0].set_ylabel('value of the loss function')\naxs[0].legend()\naxs[0].grid()\nacc = history.history['binary_accuracy']\nacc_val = history.history['val_binary_accuracy']\naxs[1].plot(epochs, acc, 'bo', label='accuracy_train')\naxs[1].plot(epochs, acc_val, 'ro', label='accuracy_val')\naxs[1].set_title('Accuracy')\naxs[1].set_xlabel('Epochs')\naxs[1].set_ylabel('Value of accuracy')\naxs[1].legend()\naxs[1].grid()\nplt.show()","95b2a67f":"predict = model.predict_generator(test_generator, verbose=1)","70c20ff0":"predict.argmax(axis=1)\nsamp_subm.loc[0:len(df_test_data.index)-1, 'Predicted'] = predict.argmax(axis=1)[0:len(df_test_data.index)]","7192d6f2":"output = samp_subm.copy()\noutput.to_csv('submission.csv', index=False)","87d23f5f":"# Test On Subset\nBoth train and test data sets are big. To test the algorithms we work on a small subset.","986067aa":"# Analyse Training","6ec47854":"Parameters","de9dc3f3":"# Predict Test Data","b31c118a":"# Export","9b0f7e3f":"# Path","ecc222da":"Summary","8597bdaf":"# EDA","af9bb356":"# Overview","c824be53":"## Prepare Data For Data Generator\nTrain Data:","d734d1fe":"# Load Data","059ed11b":"# Data Generator","fc348fc5":"## Focus Test Data Structure\nThere are some metadata: \"images\", \"info\", \"licenses\".","35f57f68":"# Intro\nWelcome to the [Herbarium 2021 - Half-Earth Challenge - FGVC8](https:\/\/www.kaggle.com\/c\/herbarium-2021-fgvc8) compedition.\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/25558\/logos\/header.png)\n\n<span style=\"color: royalblue;\">Please vote the notebook up if it helps you. Feel free to leave a comment above the notebook. Thank you. <\/span>","d969b3f2":"## Focus Train Data Structure\nThere are some metadata: \"annotations\", \"categories\", \"images\", \"info\", \"licenses\" \"institutions\".","51e66a20":"# Functions","8d514f3c":"# Libraries","a966eed3":"Test Data","a9c1719e":"# Define Model","dbdd4715":"# Define Train, Val And Test Data","a86ead47":"## Distribution Of Categories","4ce6e293":"# Load Pretrained Model","3c5c6fe5":"Split Train And Validation Data","9bd783b0":"## Plot Some Examples"}}