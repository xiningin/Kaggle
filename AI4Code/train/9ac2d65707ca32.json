{"cell_type":{"697fb737":"code","297fde7d":"code","1e6962df":"code","041c82b5":"markdown","f5465b23":"markdown","e470c9f6":"markdown","4778d9ae":"markdown","a2be1f55":"markdown","c9c12ce5":"markdown"},"source":{"697fb737":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport transformers\nfrom transformers import (\n    AutoConfig,\n    AutoTokenizer,\n    AutoModel,\n    TFAutoModel,\n    AutoModelWithLMHead,\n    TFAutoModelWithLMHead,\n    AutoModelForSequenceClassification,\n    TFAutoModelForSequenceClassification,\n    AutoModelForQuestionAnswering,\n    TFAutoModelForQuestionAnswering,\n    AutoModelForTokenClassification,\n    TFAutoModelForTokenClassification\n)\n\n# We will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\nprint(transformers.__version__)","297fde7d":"MODEL_DIR = '\/kaggle\/input\/roberta-transformers-pytorch\/roberta-base\/' # Adapt this line to the model directory of your choice\nconfig =  AutoConfig.from_pretrained(MODEL_DIR)\nprint(config)\ntokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\nmodel = AutoModel.from_pretrained(MODEL_DIR) # Comment this line if TF2.0 model\n# model = TFAutoModel.from_pretrained(MODEL_DIR) # Uncomment this line if TF2.0 model\nprint(model)","1e6962df":"model_for_sequence_classification = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR) # Comment this line if TF2.0 model\n# model_for_sequence_classification = TFAutoModelForSequenceClassification.from_pretrained(MODEL_DIR) # Uncomment this line if TF2.0 model\nprint(model_for_sequence_classification)","041c82b5":"------\nI hope you enjoyed this tutorial!\n\nIf you found it useful, please consider to upvote.","f5465b23":"# Test the models","e470c9f6":"# How to download your models with internet Off?\n\n1. Follow the steps in the Option section of your choice described in the notebook \"\ud83e\udd17 Transformers Model Downloader | Pytorch & TF2.0\".\n\nIf you chose: \n* Option 1; 1. Be sure that the commit on the other kernel is finished and successful | 2. Click on \"Add Data\" | 3. Click on \"Kernel Output Files\" | 4. Click on \"Your Work\" | 5. Next to this notebook name, click on \"Add\".\n\n![](https:\/\/i.ibb.co\/R2ZTNyL\/Kernel-output-files-V2.png)\n\n* Option 2 or 3; 1. Click on \"Add Data\" | 2. Click on \"Your Datasets\" | 3. Next to your previously created dataset, click on \"Add\".\n\n![](https:\/\/i.ibb.co\/10wBgw0\/Datasets-V1.png)\n\nNow that you have downloaded your models, you can test if they are working correctly.","4778d9ae":"# Imports","a2be1f55":"This kernel is the \"test part\" of the notebook \"\ud83e\udd17 Transformers Model Downloader | Pytorch & TF2.0\" available [here](https:\/\/www.kaggle.com\/maroberti\/transformers-model-downloader-pytorch-tf2-0).\nIt demonstrates an easy and fast way to switch between transformers models in \"Notebook-only competition\".\nThis kernel not gonna work if you don't follow the steps of the other notebook, so please [consult it](https:\/\/www.kaggle.com\/maroberti\/transformers-model-downloader-pytorch-tf2-0) before beginning with this one.","c9c12ce5":"You can even load a model with a custom head as follow:"}}