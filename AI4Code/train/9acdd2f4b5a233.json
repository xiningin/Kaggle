{"cell_type":{"cb581f98":"code","2aa1bb33":"code","edfc2063":"code","bd993403":"code","ed350d26":"code","364e9288":"code","cfdf2a58":"code","9565a980":"code","9ea8ebd4":"code","ee9a7831":"markdown","89b07843":"markdown","b2e78ce7":"markdown","ff3716ba":"markdown","f6be9b4e":"markdown","875a83c2":"markdown","4f7e6852":"markdown"},"source":{"cb581f98":"from keras import backend as K\n\nfrom keras.layers import Input, Dense, Reshape, Flatten, Concatenate\nfrom keras.layers import BatchNormalization, Activation, Embedding, multiply\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.optimizers import Adam\nfrom keras.models import Model, Sequential\nfrom keras.utils import to_categorical\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n%matplotlib inline","2aa1bb33":"img_shape = (28, 28, 1)\nz_dim = 100\nnum_classes = 10","edfc2063":"def build_generator(z_dim):\n    \n    model = Sequential()\n    \n    model.add(Dense(7*7*256, input_shape=(z_dim, )))\n    model.add(Reshape((7, 7, 256)))\n    \n    # 7*7*256 => 14*14*128\n    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.01))\n    \n    # 14*14*128 => 14*14*64\n    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.01))\n    \n    # 14*14*64 => 28*28*1\n    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))\n    model.add(Activation('tanh'))\n    \n    z = Input(shape=(z_dim, ))\n    \n    # Conditioning label\n    label = Input(shape=(1,), dtype='int32')\n    \n    # embedding layer:\n    # turns labels into dense vectors of size z_dim\n    # produces 3D tensor with shape: (batch_size, 1, z_dim)\n    label_embedding = Embedding(num_classes, z_dim, input_length=1)(label)\n    \n    # Flatten the embedding 3D tensor into 2D  tensor with shape: (batch_size, z_dim)\n    label_embedding = Flatten()(label_embedding)\n    \n    # Element-wise product of the vectors z and the label embeddings\n    joined_representation = multiply([z, label_embedding])\n    \n    img = model(joined_representation)\n    \n    return Model([z, label], img)\n","bd993403":"def build_discriminator(img_shape):\n    \n    model = Sequential()\n    \n    # 28*28*2 => 14*14*64\n    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same', input_shape=(28, 28, 2)))\n    model.add(LeakyReLU(alpha=0.01))\n    \n    # 14*14*64 => 7*7*64\n    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.01))\n    \n    # 7*7*128 => 3*3*128\n    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.01))\n    \n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n    \n    img = Input(shape=img_shape)\n    \n    label = Input(shape=(1,), dtype='int32')\n    \n    # embedding layer:\n    # turns labels into dense vectors of size 28*28*1\n    # produces 3D tensor with shape: (batch_size, 1, 28*28*1)\n    label_embedding = Embedding(input_dim=num_classes, output_dim=np.prod(img_shape), input_length=1)(label)\n    # Flatten the embedding 3D tensor into 2D  tensor with shape: (batch_size, 28*28*1)\n    label_embedding = Flatten()(label_embedding)\n    # Reshape label embeddings to have same dimensions as input images\n    label_embedding = Reshape(img_shape)(label_embedding)\n    \n    # concatenate images with corresponding label embeddings\n    concatenated = Concatenate(axis=-1)([img, label_embedding])\n    \n    prediction = model(concatenated)\n    \n    return Model([img, label], prediction)\n","ed350d26":"# building and compiling the Discriminator\ndisc = build_discriminator(img_shape)\ndisc.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=Adam())\n\n# build the generator\ngen = build_generator(z_dim)\n\n# the generator takes noise and the target label as input\n# and generates the corresponding digit for that label\nz = Input(shape=(z_dim,))\nlabel = Input(shape=(1,))\n\nimg = gen([z, label])\n\n# keep the discriminator's params constant for generator training\ndisc.trainable = False\n\nprediction = disc([img, label])\n\n# Conditional (Conditional) GAN model with fixed discriminator to train the generator\ncgan = Model([z, label], prediction)\ncgan.compile(loss='binary_crossentropy', optimizer=Adam())","364e9288":"def sample_images(image_grid_rows=2, image_grid_columns=5):\n    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n    labels = np.arange(0, 10).reshape(-1, 1)\n    gen_imgs = gen.predict([z, labels])\n    gen_imgs = 0.5 * gen_imgs + 0.5\n    fig, axs = plt.subplots(image_grid_rows, image_grid_columns, figsize=(10,4), sharey=True, sharex=True)\n    cnt = 0\n    for i in range(image_grid_rows):\n        for j in range(image_grid_columns):\n            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n            axs[i,j].axis('off')\n            axs[i,j].set_title(\"Digit: %d\" % labels[cnt])\n            cnt += 1\n","cfdf2a58":"def load_mnist_data():\n    with np.load('..\/input\/mnist.npz') as f:\n        x_train, y_train = f['x_train'], f['y_train']\n        x_test, y_test = f['x_test'], f['y_test']\n    return (x_train, y_train), (x_test, y_test)\n","9565a980":"accuracies = []\nlosses = []\n\ndef train(iterations, batch_size, sample_interval):\n    \n    (X_train, y_train), (_, _) = load_mnist_data()\n    \n    X_train = (X_train - 127.5) \/ 127.5\n    X_train = np.expand_dims(X_train, axis=3)\n    \n    real = np.ones(shape=(batch_size, 1))\n    fake = np.zeros(shape=(batch_size, 1))\n    \n    for iteration in range(iterations):\n        \n        idx = np.random.randint(0, X_train.shape[0], batch_size)\n        imgs, labels = X_train[idx], y_train[idx]\n        \n        z = np.random.normal(0, 1, size=(batch_size, z_dim))\n        gen_imgs = gen.predict([z, labels])\n        \n        d_loss_real = disc.train_on_batch([imgs, labels], real)\n        d_loss_fake = disc.train_on_batch([gen_imgs, labels], fake)\n        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n        \n        z = np.random.normal(0, 1, size=(batch_size, z_dim))\n        labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n        \n        g_loss = cgan.train_on_batch([z, labels], real)\n        \n        if iteration % sample_interval == 0:\n            print('{} [D loss: {}, accuracy: {:.2f}] [G loss: {}]'.format(iteration, d_loss[0], 100 * d_loss[1], g_loss))\n        \n            losses.append((d_loss[0], g_loss))\n            accuracies.append(d_loss[1])\n            \n            sample_images()\n    ","9ea8ebd4":"iterations = 20000\nbatch_size = 128\nsample_interval = 1000\n\ntrain(iterations, batch_size, sample_interval)\n","ee9a7831":"## Importing Libraries","89b07843":"## The Discriminator","b2e78ce7":"## Outputting sample images","ff3716ba":"## Train the model","f6be9b4e":"## Building the model","875a83c2":"## Training","4f7e6852":"## The Generator"}}