{"cell_type":{"a6d31b41":"code","cb6c4f58":"code","0182ea0b":"code","2c267e6f":"code","2e60e075":"code","7d2042c9":"code","75b3581f":"code","13ce056b":"code","98620db8":"code","fdb423b7":"code","d64ed6c8":"code","5e1eb47a":"code","0f443c94":"code","bc183da3":"code","3b890238":"code","f8f4c1ef":"code","83218b69":"code","1a5250d3":"code","6ae309e7":"code","50df90e3":"code","15da6cff":"code","b02af5db":"code","0e4d1caf":"code","770cb603":"code","814b7eec":"code","c01ddfcc":"code","113c21a1":"code","ca63a538":"code","eda5e70a":"code","2e01ced9":"code","35cd491c":"code","da036e92":"code","e4d1a7a1":"markdown","07932e6c":"markdown","a43c6ee1":"markdown","874afbfc":"markdown","c9e9e099":"markdown","9625b7a2":"markdown","cae3d473":"markdown","fa2b0ab8":"markdown"},"source":{"a6d31b41":"!pip install fastai==0.7.0 --no-deps\n!pip install torch==0.4.1 torchvision==0.2.1","cb6c4f58":"# verify dataset is there\n!ls ..\/input","0182ea0b":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","2c267e6f":"# load fastai libraries\nfrom fastai.imports import *\nfrom fastai.torch_imports import *\nfrom fastai.transforms import *\nfrom fastai.conv_learner import *\nfrom fastai.model import *\nfrom fastai.dataset import *\nfrom fastai.sgdr import *\nfrom fastai.plots import *","2e60e075":"# load additional libraries\nimport h5py","7d2042c9":"# verify GPU\nprint(torch.cuda.is_available(), torch.backends.cudnn.enabled)","75b3581f":"# function to load the data into appropriate format\ndef load_dataset(path_to_train, path_to_test):\n    train_dataset = h5py.File(path_to_train)\n    train_x = np.array(train_dataset['train_set_x'][:])\n    train_y = np.array(train_dataset['train_set_y'][:])\n\n    test_dataset = h5py.File(path_to_test)\n    test_x = np.array(test_dataset['test_set_x'][:])\n    test_y = np.array(test_dataset['test_set_y'][:])\n\n    # y reshaped\n    train_y = train_y.reshape((1, train_x.shape[0]))\n    test_y = test_y.reshape((1, test_y.shape[0]))\n\n    return train_x, train_y, test_x, test_y","13ce056b":"# defining input patt and reading the data using the defined function\nPATH = \"..\/input\"\nX_train, Y_train, X_test, Y_test = load_dataset(f\"{PATH}\/train_happy.h5\", f\"{PATH}\/test_happy.h5\")\n# swap dimensions (Andrew Ng likes them flipped around)\nY_train = Y_train.T.squeeze()\nY_test = Y_test.T.squeeze()","98620db8":"# always check the shapes of your input while doing deep learning (or anything invlving tensors)!\nprint(X_train.shape, Y_train.shape)\nprint(X_test.shape, Y_test.shape)","fdb423b7":"# visualize a training example\nplt.imshow(X_train[0])","d64ed6c8":"# size of an image in train\nX_train[0].shape","5e1eb47a":"# setup architecture\narch = resnet34\nsz = 48\nbs = 32","0f443c94":"# function to apply tranformations on data according to paramters selected\ndef get_data(sz, bs):\n    tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n    return ImageClassifierData.from_arrays(path = 'tmp\/',\n                                           trn=(X_train, Y_train),\n                                           val=(X_test, Y_test),\n                                           bs=bs,\n                                           classes=Y_train,\n                                           tfms=tfms)","bc183da3":"data = get_data(sz, bs)","3b890238":"# run learner with precompute enabled\nlearn = ConvLearner.pretrained(arch, data, precompute=True)","f8f4c1ef":"# find optimal learning rate\nlrf = learn.lr_find()\nlearn.sched.plot_lr()","83218b69":"learn.sched.plot()","1a5250d3":"lr = 0.028","6ae309e7":"learn.fit(lr, 5, cycle_len=1, cycle_mult=3)","50df90e3":"learn.sched.plot_loss()","15da6cff":"learn.set_data(get_data(64, bs))","b02af5db":"learn.freeze()","0e4d1caf":"# fitting final model again after using new examples\nlearn.fit(0.028, 5, cycle_len=1, cycle_mult=3)","770cb603":"# add test time augmentation to see if it helps\nlog_preds,y = learn.TTA()\nprobs = np.mean(np.exp(log_preds),0)","814b7eec":"accuracy_np(probs, y)","c01ddfcc":"preds = np.argmax(probs, axis=1)\nprobs = probs[:,1]","113c21a1":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y, preds)","ca63a538":"classes = np.unique(Y_train)\nplot_confusion_matrix(cm, classes)","eda5e70a":"def load_img_id(idx):\n    #print(idx)\n    img = X_test[idx].reshape(64,64,3)\n    return img\n\ndef plot_val_with_title(idxs, title):\n    print(idxs)\n    imgs = [load_img_id(x) for x in idxs]\n    title_probs = [(preds[x], y[x]) for x in idxs]\n    print(title)\n    return plots(imgs, rows=4, titles=title_probs, figsize=(16,8)) if len(imgs)>0 else print('Not Found.')","2e01ced9":"# count incorrect predictions\nincorrect_digits = np.where(preds != y)[0]\nlen(incorrect_digits)","35cd491c":"# visualize incorrect predictions\nplot_val_with_title(incorrect_digits, \"Incorrect digits (prediction, label)\")","da036e92":"%%capture\n!apt-get install zip\n!zip -r output.zip tmp\n!rm -rf  tmp\/*","e4d1a7a1":" I tried with a smaller number of epochs and cycle_mult and the model was underfitting (train error < valid error) and so increased the cycle_mult so that gradient descent doesn't get stuck in a non-optimal or less optimal region.","07932e6c":"# Model","a43c6ee1":"### Confusion Matrix","874afbfc":"> # Load and inspect data","c9e9e099":"# Results","9625b7a2":"Using Jeremy Howard's technique to reduce overfitting by first training on a smaller size of images( 48) and then increasing the size and training again (effectively increasing the kind and number of training examples.","cae3d473":"Checking input directory and loading data and libraries","fa2b0ab8":"### Incorrect predictions"}}