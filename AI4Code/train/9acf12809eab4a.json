{"cell_type":{"15b00151":"code","97cd29c0":"code","c0bdd067":"code","4f3e9f17":"code","b544a450":"code","bbaa3f4a":"code","028f9627":"code","c0394751":"code","9bf958fe":"code","f966b111":"code","bd9e55e4":"code","06d15b92":"code","e8fbc5d2":"code","07992176":"code","6861057c":"code","4c2be9e4":"code","7c01ac26":"code","13c7e64d":"code","6ccfd3af":"code","87805388":"code","ed2698a3":"code","44a015a4":"code","247a67aa":"code","df731eaa":"code","51313235":"code","a2c8fc3f":"code","37ab7c95":"code","08db8d88":"code","05546f6c":"code","d7d0f2d4":"code","fd8460d8":"code","5ee86b7d":"code","4082886f":"code","3963978e":"code","29a857f6":"code","a66a19fc":"code","f062d9cf":"markdown","ff139848":"markdown","0496d122":"markdown","e000fe28":"markdown","8a270bad":"markdown","9b469a38":"markdown","f284bcb7":"markdown","6c8a523e":"markdown","c51b886f":"markdown","81f4c3ae":"markdown","e5127c11":"markdown","8109d2ad":"markdown","6d3e2c03":"markdown","775b42fa":"markdown","9e42806b":"markdown","8ab5ad15":"markdown","c931b92e":"markdown","262f3580":"markdown","058df399":"markdown","441a9d4e":"markdown","7213c0d4":"markdown","ec7e49f4":"markdown","8f4874b4":"markdown"},"source":{"15b00151":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('ggplot')\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.utils import plot_model","97cd29c0":"x_train = pd.read_csv(\"..\/input\/fashion-mnist_train.csv\")\nx_test = pd.read_csv(\"..\/input\/fashion-mnist_test.csv\")","c0bdd067":"x_train.head()","4f3e9f17":"x_test.head()","b544a450":"y_train = x_train['label']\ny_test = x_test['label']\n\n# Drop 'label' column\nx_train = x_train.drop(labels = ['label'],axis = 1) \nx_test = x_test.drop(labels = ['label'], axis = 1)\n\n","bbaa3f4a":"y_train.value_counts()","028f9627":"def getImage(df, pos):\n    pixels = df.loc[df.index == pos]\n    pixels = np.array(pixels, dtype = 'uint8')\n    pixels = pixels.reshape((28,28)) #Hay 784, su raiz cuadrada es 28 por tanto el tama\u00f1o de la dimension sera 28x28\n    \n    # Plot\n    plt.title('Pice of clothing')\n    plt.imshow(pixels, cmap='gray')\n    #sns.heatmap(pixels)\n    \n    plt.show()","c0394751":"getImage(x_train, 2) #Label6\ngetImage(x_train, 3) #Label0","9bf958fe":"#Buscamos valores nulos en test y train","f966b111":"def getNull (df):\n    return df.isnull().any().describe()","bd9e55e4":"print ('(Train)-Null Data: ' + str(getNull(x_train)) + '\\n' +\n       '(Test)-Null Data: ' + str(getNull(x_test)))","06d15b92":"original_test = x_test.copy()","e8fbc5d2":"x_train = x_train\/255\nx_test = x_test\/255","07992176":"x_train.shape","6861057c":"x_test.shape","4c2be9e4":"# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nx_train = x_train.values.reshape(60000,28,28,1)\nx_test = x_test.values.reshape(10000,28,28,1)","7c01ac26":"# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n\ny_train = to_categorical(y_train, num_classes = 10)\ny_test = to_categorical(y_test, num_classes = 10)","13c7e64d":"# Set the random seed\nrandom_seed = 12\n\n# Split the train and the validation set for the fitting\nX_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size = 0.15, random_state=random_seed)","6ccfd3af":"# Set the CNN model \n# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> [Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n\nmodel = Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(3,3)))\nmodel.add(Dropout(0.35))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\nmodel.add(Dense(units = 256, activation = 'relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(units = 10, activation = 'softmax'))","87805388":"model.summary()","ed2698a3":"rmsprop = RMSprop()","44a015a4":"model.compile(\n    optimizer = rmsprop,\n    loss = 'categorical_crossentropy',\n    metrics = ['accuracy']\n)","247a67aa":"%%time\n\nmodel_CNN = model.fit(X_train, Y_train, batch_size = 256, epochs = 50, \n          validation_data = (X_val, Y_val), verbose = 1)","df731eaa":"score = model.evaluate(x_test, y_test)\nprint('Test accuracy:', score[1])","51313235":"accuracy = model_CNN.history['acc']\nval_accuracy = model_CNN.history['val_acc']\nloss = model_CNN.history['loss']\nval_loss = model_CNN.history['val_loss']\nepochs = range(len(accuracy))\n\n# Plot training & validation accuracy values\nplt.plot(epochs, accuracy, 'bo')\nplt.plot(epochs, val_accuracy, 'b')\n#plt.ylabel('Accuracy')\n#plt.xlabel('Epoch')\nplt.title('Training and validation accuracy')\nplt.legend(['Train', 'Test'], loc='upper left')\n\nplt.figure()\n\n# Plot training & validation loss values\nplt.plot(epochs, loss, 'bo')\nplt.plot(epochs, val_loss, 'b')\n#plt.ylabel('Loss')\n#plt.xlabel('Epoch')\nplt.title('Training and validation loss')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","a2c8fc3f":"predictions = pd.Series(model.predict_classes(x_test))\ny_test_label = pd.Series([y_test[i].argmax() for i in range(len(y_test))])\nreport = pd.concat([y_test_label, predictions], axis = 1)\nreport.head()","37ab7c95":"correct = np.nonzero(predictions==y_test_label)[0]\nincorrect = np.nonzero(predictions!=y_test_label)[0]","08db8d88":"print (\"Our NN missclisified: \" + str(len(incorrect)) + \" clothes\")","05546f6c":"target_names = [\"Class {}\".format(i) for i in range(y_test_label.max()+1)]\nprint(classification_report(y_test_label, predictions, target_names=target_names))","d7d0f2d4":"getImage(original_test, correct[1])\ngetImage(original_test, correct[2])\ngetImage(original_test, correct[3])","fd8460d8":"getImage(original_test, incorrect[1])\ngetImage(original_test, incorrect[2])\ngetImage(original_test, incorrect[3])","5ee86b7d":"def plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","4082886f":"confusion_mtx = confusion_matrix(y_test_label, predictions) \nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","3963978e":"category_index = {\"T-shirt\/top\":0, \"Trouser\":1, \"Pullover\":2,\n                 \"Dress\":3, \"Coat\":4, \"Sandal\":5,\n                 \"Shirt\":6, \"Sneaker\":7, \"Bag\":8,\n                 \"Ankle boot\":9}\ncategory_reverse_index = dict((y,x) for (x,y) in category_index.items())","29a857f6":"def probsPredictions(cloth):\n    incorrect_label = model.predict(x_test) != y_test\n    for i in cloth:\n        print(\"-\"*10)\n        print(\"Predicted category: \", category_reverse_index[model.predict_classes(x_test, verbose=0)[i]])\n        print(\"-\"*10)\n        category_reverse_index[y_test_label[i]]\n        probabilities = model.predict(x_test, verbose=0)\n        probabilities = probabilities[i]\n\n        print(\"T-shirt\/top Probability: \",probabilities[category_index[\"T-shirt\/top\"]] )\n        print(\"Trouser Probability: \",probabilities[category_index[\"Trouser\"]] )\n        print(\"Pullover probability: \",probabilities[category_index[\"Pullover\"]] )\n        print(\"Dress Probability: \",probabilities[category_index[\"Dress\"]] )\n        print(\"Coat Probability: \",probabilities[category_index[\"Coat\"]] )\n        print(\"Sandal probability: \",probabilities[category_index[\"Sandal\"]] )\n        print(\"Shirt Probability: \",probabilities[category_index[\"Shirt\"]] )\n        print(\"Sneaker Probability: \",probabilities[category_index[\"Sneaker\"]] )\n        print(\"Bag probability: \",probabilities[category_index[\"Bag\"]] )\n        print(\"Ankle boot probability: \",probabilities[category_index[\"Ankle boot\"]] )","a66a19fc":"probsPredictions(list(range(0, 5)))","f062d9cf":"The original data is of type pandas.Dataframe as 1D vectors of 784 values. We reshape all data to 28x28x1 3D matrices.\n\nKeras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so it use only one channel. For RGB images, there is 3 channels, in that case we would have reshaped 784px vectors to 28x28x3 3D matrices.","ff139848":"## CNN - Model","0496d122":"Tenemos las piezas de ropa en train perfectamente distribuidas","e000fe28":"The CNN works better and faster on [0..1] data than on [0..255].","8a270bad":"### Visualitzation","9b469a38":"Plots taken of Keras Docs: https:\/\/keras.io\/visualization\/","f284bcb7":"## Reshape","6c8a523e":"### If you arrived here i deserve a Vote! :D ","c51b886f":"![Alt Text](https:\/\/thumbs.gfycat.com\/GoodShinyGhostshrimp-size_restricted.gif)","81f4c3ae":"## One-Hot encoding","e5127c11":"Our NN is missclassifying the label 6 because it confusses with Thsirts(0), Pullover(2), Dress(3) and Coat(4)","8109d2ad":"It's apparent that our classifier is underperforming for class 6 in terms of both precision and recall. For class 0 and 2, classifier is also lacking precision.\n\nPerhaps we would gain more insight after visualizing the correct and incorrect predictions.","6d3e2c03":"![image](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRXSDJfW-VRpPeldYc5o0hQTmH5WhxpVwSgvj0C_xNnOwpqn-5mGw)","775b42fa":"### Classification Outputs","9e42806b":"Hay el mismo numero de Nulls en train que en Test y ademas coincide con el numero de pixels por filas que a su vez es la dimension total, esto seguramente se deba a que la forma de marcar los bordes sean los valores nulos.","8ab5ad15":"## Normalization","c931b92e":"We save a copy ox x_test for forward comprobations","262f3580":"# MNIST Fashion","058df399":"### Confussion Matrix","441a9d4e":"### Score","7213c0d4":"It looks like the similar patterns present on multiple classes effect the performance of the classifier. A jacket, a shirt, and a long-sleeve blouse has similar patterns","ec7e49f4":"## Split training and validation set","8f4874b4":"Let\u00b4s see how are NN is giving probabilities to every class"}}