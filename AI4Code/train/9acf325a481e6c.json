{"cell_type":{"0fea381e":"code","f241bb7d":"code","96644e24":"code","e2335271":"code","c16d64c8":"code","cafbd01d":"code","de9dda31":"code","8016e462":"code","3cc8b421":"code","2f6bc90e":"code","e61b99ec":"code","403f83bd":"code","60657633":"code","5fd3b60e":"code","d1b979a7":"code","81c1d503":"code","2441790a":"code","6a4606af":"code","8b1802eb":"code","06726c6f":"code","c5cbceb7":"code","3c06e0e5":"code","321fcdeb":"code","c2ab8f28":"code","5442f7d1":"code","5bacc4d6":"code","17cf0b4b":"code","9ed23d06":"code","11b3908e":"code","ca2ccd76":"code","a16b5f55":"code","1c587ba7":"code","ec858abd":"code","19c64eba":"code","c5c11516":"code","bf82c303":"code","1516a8b1":"code","c7f41e62":"code","50e06596":"code","398daa65":"markdown","53a278c4":"markdown","2a10504e":"markdown","b4773139":"markdown","dc4132a4":"markdown","eaef05a9":"markdown","30f267c7":"markdown","b5533c27":"markdown","d3249951":"markdown","fa626641":"markdown","1c1f4eeb":"markdown","aafdb091":"markdown","f7ee9263":"markdown","010a9a64":"markdown","a22377ba":"markdown","594b50e9":"markdown","81c2eefe":"markdown","4bce8c05":"markdown","d3da92d2":"markdown","a7c26586":"markdown","8bc035b0":"markdown","18a9ae53":"markdown","e12feeb0":"markdown","e904b435":"markdown","a1055ca9":"markdown","9d087647":"markdown","4e0a0524":"markdown","4f0f96ae":"markdown","735cbf47":"markdown","0736baee":"markdown","a965f226":"markdown","c08bb0fe":"markdown","268183d0":"markdown","8b55b8e6":"markdown","66273ab4":"markdown"},"source":{"0fea381e":"!git clone https:\/\/github.com\/Tessellate-Imaging\/monk_v1.git","f241bb7d":"!cd monk_v1\/installation\/Misc && pip install -r requirements_kaggle.txt","96644e24":"! pip install pillow==5.4.1","e2335271":"# Monk\nimport os\nimport sys\nsys.path.append(\"monk_v1\/monk\/\");","c16d64c8":"#Using keras backend \nfrom keras_prototype import prototype","cafbd01d":"gtf = prototype(verbose=1);\ngtf.Prototype(\"Cancer-Detection-Using-MONK\", \"Using-Keras-Backend\");","de9dda31":"gtf.List_Models()","8016e462":"gtf.Default(dataset_path=\"\/kaggle\/input\/cancer\/train\", \n            model_name=\"resnet152_v2\", \n            num_epochs=10);\n\n#Read the summary generated once you run this cell.","3cc8b421":"gtf.update_save_intermediate_models(False);\ngtf.Reload();","2f6bc90e":"#Start Training\ngtf.Train();\n#Read the training summary generated once you run the cell and training is completed","e61b99ec":"gtf = prototype(verbose=1);\ngtf.Prototype(\"Cancer-Detection-Using-MONK\", \"Using-Keras-Backend\", eval_infer=True);","403f83bd":"gtf.Dataset_Params(dataset_path=\"\/kaggle\/input\/cancer\/validation\");\ngtf.Dataset();","60657633":"accuracy, class_based_accuracy = gtf.Evaluate();","5fd3b60e":"gtf = prototype(verbose=1);\ngtf.Prototype(\"Cancer-Detection-Using-MONK\", \"Using-Keras-Backend\", eval_infer=True);","d1b979a7":"img_name = \"\/kaggle\/input\/cancer\/test\/c2 (10004).jpeg\";\npredictions = gtf.Infer(img_name=img_name);\n\n#Display \nfrom IPython.display import Image\nImage(filename=img_name)","81c1d503":"img_name = \"\/kaggle\/input\/cancer\/test\/c2 (10).jpeg\";\npredictions = gtf.Infer(img_name=img_name);\n\n#Display \nfrom IPython.display import Image\nImage(filename=img_name)","2441790a":"img_name = \"\/kaggle\/input\/cancer\/test\/c2 (10014).jpeg\";\npredictions = gtf.Infer(img_name=img_name);\n\n#Display \nfrom IPython.display import Image\nImage(filename=img_name)","6a4606af":"from IPython.display import Image\nImage(filename=\"workspace\/Cancer-Detection-Using-MONK\/Using-Keras-Backend\/output\/logs\/train_val_accuracy.png\") ","8b1802eb":"from IPython.display import Image\nImage(filename=\"workspace\/Cancer-Detection-Using-MONK\/Using-Keras-Backend\/output\/logs\/train_val_loss.png\") ","06726c6f":"#Using pytorch backend \nfrom pytorch_prototype import prototype","c5cbceb7":"gtf = prototype(verbose=1);\ngtf.Prototype(\"Cancer-Detection-Using-MONK\", \"Using-Pytorch-Backend\");","3c06e0e5":"gtf.List_Models();","321fcdeb":"gtf.Default(dataset_path=\"\/kaggle\/input\/cancer\/train\", \n            model_name=\"densenet201\",\n            num_epochs=10);\n\n#Read the summary generated once you run this cell.","c2ab8f28":"# Need not save intermediate epoch weights\ngtf.update_save_intermediate_models(False);\ngtf.Reload();","5442f7d1":"#Start Training\ngtf.Train();\n\n#Read the training summary generated once you run the cell and training is completed","5bacc4d6":"# Compare experiments","17cf0b4b":"# Invoke the comparison class\nfrom compare_prototype import compare","9ed23d06":"# Create a project \ngtf = compare(verbose=1);\ngtf.Comparison(\"Campare-backends\");","11b3908e":"gtf.Add_Experiment(\"Cancer-Detection-Using-MONK\", \"Using-Keras-Backend\");\ngtf.Add_Experiment(\"Cancer-Detection-Using-MONK\", \"Using-Pytorch-Backend\");","ca2ccd76":"gtf.Generate_Statistics();","a16b5f55":"from IPython.display import Image\nImage(filename=\"workspace\/comparison\/Campare-backends\/train_accuracy.png\") ","1c587ba7":"from IPython.display import Image\nImage(filename=\"workspace\/comparison\/Campare-backends\/train_loss.png\") ","ec858abd":"from IPython.display import Image\nImage(filename=\"workspace\/comparison\/Campare-backends\/val_accuracy.png\") ","19c64eba":"from IPython.display import Image\nImage(filename=\"workspace\/comparison\/Campare-backends\/val_loss.png\")","c5c11516":"from IPython.display import Image\nImage(filename=\"workspace\/comparison\/Campare-backends\/stats_training_time.png\") ","bf82c303":"from IPython.display import Image\nImage(filename=\"workspace\/comparison\/Campare-backends\/stats_best_val_acc.png\") ","1516a8b1":"! rm -r monk_v1","c7f41e62":"! rm -r workspace","50e06596":"! rm pylg.log","398daa65":"Load the experiment in inference mode\n- Set flag eval_infer as True","53a278c4":"Load the experiment in validation mode\n- Set flag eval_infer as True","2a10504e":"**Creating and managing comparison experiments**\n\n  - Provide project name","b4773139":"Visualize and study comparison metrics\n","dc4132a4":"# Running inference on test images","eaef05a9":"* To use mxnet-gluon backend\n\nfrom gluon_prototype import prototype\n\n\n* To use pytorch backend\n\nfrom pytorch_prototype import prototype","30f267c7":"**Add experiments**","b5533c27":"Select image and Run inference","d3249951":"Imports","fa626641":"\nThis creates files and directories as per the following structure\n\n\nworkspace\n\n    |\n    |--------Cancer-Detection-Using-MONK (Project name can be different)\n                    |\n                    |\n                    |-----Using-Keras-Backend (Experiment name can be different)\n                                |\n                                |-----experiment-state.json\n                                |\n                                |-----output\n                                        |\n                                        |------logs (All training logs and graphs saved here)\n                                        |\n                                        |------models (all trained models saved here)","1c1f4eeb":"* [DATASET](#data)\n* [Install Monk](#install)\n* [Creating and Managing experiments](#cm)","aafdb091":"Training Loss Curves","f7ee9263":"The original DATASET is https:\/\/www.kaggle.com\/c\/histopathologic-cancer-detection\/data","010a9a64":"Best Validation accuracies","a22377ba":"Load the validation dataset","594b50e9":"# <div id=\"data\"> Details on the dataset !!! <\/div>","81c2eefe":"Training time curves","4bce8c05":"Validation loss curves","d3da92d2":"git clone https:\/\/github.com\/Tessellate-Imaging\/monk_v1.git\n\n* If using Colab install using the commands below\n\n!cd monk_v1\/installation\/Misc && pip install -r requirements_colab.txt\n\n* If using Kaggle uncomment the following command\n\n!cd monk_v1\/installation\/Misc && pip install -r requirements_kaggle.txt\n\n* Select the requirements file as per OS and CUDA version when using a local system or cloud\n\n!cd monk_v1\/installation\/Linux && pip install -r requirements_cu9.txt\n(Select the requirements file as per OS and CUDA version)","a7c26586":"Validation Accuracy Curves","8bc035b0":"Training Accuracy Curves","18a9ae53":"# Run validation","e12feeb0":"# Train Validation Loss Curve","e904b435":"# Train Validation Accuracy Curve","a1055ca9":"# [Monk Library](https:\/\/github.com\/Tessellate-Imaging\/monk_v1)\n\n\nMonk is an opensource low-code tool for computer vision and deep learning\n\n**Monk features**\n\n* low-code\n* unified wrapper over major deep learning framework - keras, pytorch, gluoncv\n* syntax invariant wrapper\n\n**Monk Enables**\n\n* users to create, manage and version control deep learning experiments\n* users to compare experiments across training metrics\n* users to quickly find best hyper-parameters","9d087647":"**Run Analysis**","4e0a0524":"Dataset folder structure\n\nparent_directory\n\n    |\n    |\n    |------CANCER\n            |\n            |------img1.jpeg\n            |------img2.jpeg\n            |------.... (and so on)\n    |------Normal\n            |\n            |------img1.jpeg\n            |------img2.jpeg\n            |------.... (and so on)","4f0f96ae":"Validating the trained classifier","735cbf47":"# <div id=\"install\"> Install Monk <\/div>","0736baee":"# ** Table of contents **","a965f226":"# Repeating using pytorch backend with a different model","c08bb0fe":"<div id=\"cm\"> Creating and managing experiments<\/div>\n- Provide project name\n- Provide experiment name\n- For a specific data create a single project\n- Inside each project multiple experiments can be created\n- Every experiment can be have diferent hyper-parameters attached to it","268183d0":"More information on Histopathologic Cancer Detection-Identify metastatic tissue in histopathologic scans of lymph node sections https:\/\/www.cancer.org\/cancer\/cancer-basics\/lymph-nodes-and-cancer.html","8b55b8e6":"The modified dataset contains images of original dataset is renamed , cropped to central 32*32 region , converted to gray and .jpeg format.It is cropped because in the original dataset a positive label indicates that the center 32x32px region of a patch contains at least one pixel of tumor tissue. \n\n20% of train images of original dataset is in validation folder\n80% of train images of original dataset is in train folder\nAll images of test folder of original dataset is in test folder\n\nBoth train and validation folder of this modified dataset has CANCER and Normal folder\nimages are put to this CANCER and Normal folder based on the label provided in the train_labels.csv of the original dataset.\n         ","66273ab4":"\n# Quick mode training\n\n- Using Default Function\n    - dataset_path\n    - model_name\n    - num_epochs\n"}}