{"cell_type":{"1c293d29":"code","c8b0b58c":"code","2e854465":"code","aadeb51f":"code","0a3c8970":"code","1bed2bd7":"code","c99fe873":"code","4cb43882":"code","ceae933b":"code","ef2ce719":"code","ae4b1478":"code","1338b734":"code","f02084cb":"code","045c41f0":"code","0020c851":"code","0e6be54d":"code","2f162df8":"code","d8cc43cd":"code","a89648be":"code","0cb9c3c4":"code","ad0c2120":"code","68e89f3d":"code","0395bb8d":"code","dcb87530":"code","765039db":"code","a01536c9":"code","d2ae23a1":"code","4654117c":"code","4c78e439":"code","6463b069":"code","8158e4b1":"code","1131ee4b":"code","18d64839":"code","26ce0d1c":"code","9180f62e":"code","7316e2d6":"code","c7000a15":"code","98b044cb":"code","6b10b079":"code","9b4211b7":"code","b895891f":"code","528bae2b":"code","cbaab61e":"code","94ba87bd":"code","5fcbeef2":"code","c183b10b":"code","a78b07c7":"code","e814b231":"code","dca07f8f":"code","8187cabb":"code","01cd5454":"code","06b80bc9":"code","48175acd":"code","6c79d71e":"code","c96454f8":"code","fd3f67d1":"code","fd4270f1":"code","78864e3e":"code","8eda56b3":"code","579acc06":"code","b9547aef":"code","1f5f3314":"code","34b82668":"code","d537420d":"code","7ac890d2":"code","447a5d40":"code","b967d114":"code","db62a925":"code","229f44c5":"code","2981a070":"code","0ac8aa36":"code","679c0afb":"code","079cf4b5":"code","b0395da1":"code","725cf7a8":"code","ad88b256":"code","a553d373":"code","f98c8715":"code","a50b4b0a":"code","2afa0e17":"code","dd5e863e":"code","e972ada0":"code","7eb5fdce":"code","41707902":"markdown","f4e0fcee":"markdown","2ab7b29c":"markdown","14338b3f":"markdown","7a68f336":"markdown","40db3d60":"markdown","39f9d993":"markdown","958dc9a2":"markdown","2d6ffee6":"markdown","cc0e2cdd":"markdown","297662d4":"markdown","36f46892":"markdown","31471bca":"markdown","f8e9c908":"markdown","ead69a1f":"markdown","fe456e3b":"markdown","23d7a22c":"markdown","7fd22cd0":"markdown","ec6736ec":"markdown","f294604c":"markdown","30a11e1d":"markdown","083336d3":"markdown","cd9075e9":"markdown"},"source":{"1c293d29":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n # linear algebra\n # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c8b0b58c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","2e854465":"df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")","aadeb51f":"df.head()","0a3c8970":"df.info()","1bed2bd7":"# checking for null values\ndf.isna().sum()","c99fe873":"pd.DataFrame(df.isna().sum().sort_values(ascending=False)\/len(df)*100, columns = [\"Missing Data Percentage\"])","4cb43882":"plt.figure(figsize=(16,8))\ndf['Survived'].value_counts().plot.bar()\nplt.show()","ceae933b":"non_survived_pas = round(df['Survived'].value_counts()[0]\/len(df)*100,2)\nsurvived_pas = round(df['Survived'].value_counts()[1]\/len(df)*100,2)","ef2ce719":"print(f'Percentage of passengers survived : {survived_pas}%')\nprint(f'Percentage of passengers who could not survived : {non_survived_pas}%')","ae4b1478":"print(f'Minimun age: {df.Age.min()}')\nprint(f'Maximun age: {df.Age.max()}')","1338b734":"df.plot(kind=\"scatter\",x=\"Age\",y=\"Survived\")\nplt.title(\"Age vs Survived\")\nplt.show()","f02084cb":"df.plot(kind=\"scatter\",x=\"Fare\",y=\"Survived\")\nplt.title(\"Fare vs Survived\")\nplt.show()","045c41f0":"plt.figure(figsize=(16,8))\nplt.pie(df['SibSp'].value_counts().values, autopct=\"%1.0f%%\",labels=[0,1,2,3,4,5,6])\nplt.show()","0020c851":"df['Parch'].value_counts().plot.bar()","0e6be54d":"plt.figure(figsize=(16,8))\nsns.histplot(df['Fare'])\nplt.show()","2f162df8":"plt.figure(figsize=(16,8))\ndf['Sex'].value_counts().plot.bar()\nplt.show()","d8cc43cd":"plt.figure(figsize=(16,8))\ndf['Embarked'].value_counts().plot.bar()\nplt.show()","a89648be":"df['Parch'] = df['Parch'].astype(float)\ndf['SibSp'] = df['SibSp'].astype(float)","0cb9c3c4":"features = df.drop('Survived',axis=1)\nlabels = df['Survived'].values","ad0c2120":"num_cols = [col for col in features.columns if features[col].dtype in [float]]","68e89f3d":"print(num_cols)","0395bb8d":"cat_cols = [col for col in features.columns if col not in num_cols\n           and df[col].unique().shape[0]<10]","dcb87530":"print(cat_cols)","765039db":"df[cat_cols].head()","a01536c9":"df[num_cols].head()","d2ae23a1":"df['Age'].mean()","4654117c":"# option 1 - using fillna()\nfeatures['Age'].mean()","4c78e439":"features[\"Age\"].fillna(features['Age'].mean()).values","6463b069":"features['Age'].fillna(features['Age'].mean()).isna().sum()","8158e4b1":"# option 2 (Preferred)\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer","1131ee4b":"imputer = SimpleImputer(strategy=\"mean\")","18d64839":"imputer.fit_transform(features[num_cols])","26ce0d1c":"# Making a numerical data processing pipeline\nfrom sklearn.preprocessing import StandardScaler\nnum_pipeline = Pipeline([    \n    (\"Imputer\",SimpleImputer(strategy=\"mean\")),\n    (\"Scaler\",StandardScaler())\n])","9180f62e":"num_pipeline.fit_transform(features[num_cols])","7316e2d6":"features[cat_cols].head()","c7000a15":"features[cat_cols].isna().sum()","98b044cb":"features['Embarked'].value_counts()","6b10b079":"features['Embarked'].fillna(\"S\").isna().sum()","9b4211b7":"# Creating a custom imputer\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass MostFrequentImputer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n                                       index=X.columns)\n        return self\n    def transform(self,X,y=None):\n        return X.fillna(self.most_frequent_)","b895891f":"# One Hot Encoding\nfrom sklearn.preprocessing import OneHotEncoder\n\ncat_pipeline = Pipeline([\n    (\"cat_imputer\",MostFrequentImputer()),\n    (\"one_hot\",OneHotEncoder())\n])","528bae2b":"cat_pipeline.fit_transform(features[cat_cols])","cbaab61e":"X_num = num_pipeline.fit_transform(features[num_cols])\nX_cat = cat_pipeline.fit_transform(features[cat_cols]).toarray()","94ba87bd":"X_final = np.c_[X_num,X_cat]","5fcbeef2":"print(X_final[:5])","c183b10b":"X_final.shape","a78b07c7":"# splitting our data into train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_final, labels, test_size=0.2, random_state=5)","e814b231":"print(f\"Training set shape: {X_train.shape}\")\nprint(f\"Testing set shape: {X_test.shape}\")","dca07f8f":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression","8187cabb":"# Decision Tree Model\ndt = DecisionTreeClassifier()","01cd5454":"dt.fit(X_train,y_train)","06b80bc9":"dt.score(X_test, y_test)","48175acd":"dt.score(X_train, y_train)","6c79d71e":"sample = X_test[0]\nprint(sample)","c96454f8":"dt.predict([sample])","fd3f67d1":"y_test[0]","fd4270f1":"def pred(sample):\n    res = dt.predict([sample])\n    return \"Survived\" if res == 1 else \"Not Survived\"","78864e3e":"pred(sample)","8eda56b3":"pred(X_test[19])","579acc06":"# Logistic Regression Model\nlr = LogisticRegression()","b9547aef":"lr.fit(X_train,y_train)","1f5f3314":"lr.score(X_train, y_train)","34b82668":"lr.score(X_test, y_test)","d537420d":"from sklearn.model_selection import cross_val_score\n\n# Logistic Regression\nscores = cross_val_score(lr,X_train,y_train,cv=5)\nprint(scores)","7ac890d2":"scores.mean()","447a5d40":"# Decision tree\nscores = cross_val_score(dt,X_train,y_train,cv=5)\nprint(scores)","b967d114":"scores.mean()","db62a925":"print(f\"Decsion Tree Parameters: {dt.get_params()}\")","229f44c5":"print(f\"Logistic Regression Parameters: {lr.get_params()}\")","2981a070":"from sklearn.model_selection import RandomizedSearchCV, GridSearchCV","0ac8aa36":"grid={\n    \"solver\":[\"netwon-cg\",\"lbfgs\",'liblinear'],\n    \"penalty\":[\"l2\"],\n    \"C\":[100,20,1.0,0.1,0.01]\n}\ngrid_search = GridSearchCV(estimator=lr,param_grid=grid, return_train_score=True,n_jobs=-1,\n                          cv=5,scoring='accuracy',error_score=0)","679c0afb":"grid_search.fit(X_train,y_train)","079cf4b5":"grid_search.score(X_train,y_train)","b0395da1":"grid_search.score(X_test,y_test)","725cf7a8":"grid_search.cv_results_['mean_test_score'].mean()","ad88b256":"grid_search.cv_results_['mean_train_score'].mean()","a553d373":"rnd_search=RandomizedSearchCV(lr,grid,return_train_score=True,n_jobs=-1,cv=5,scoring='accuracy',error_score=0)","f98c8715":"rnd_search.fit(X_train,y_train)","a50b4b0a":"rnd_search.score(X_train,y_train)","2afa0e17":"rnd_search.score(X_test,y_test)","dd5e863e":"rnd_search.cv_results_","e972ada0":"rnd_search.best_estimator_","7eb5fdce":"rnd_search.best_params_","41707902":"## Importing Libraries","f4e0fcee":"So, now we have prepared the numerical data. Let's move forward for the categorical one\n\nLike there are no libs for imputing categorical data but we do have strategy. Let's observer the categorical data again","2ab7b29c":"Just by looking at the data we can tell that we have some missing data in Age, Embarked and Cabin columns. Let's see how much of the data is actually missing","14338b3f":"We don't see any correlations here with the Age and Survived columns together","7a68f336":"We need to perform imputation strategies on our columns where the data is missing","40db3d60":"### Univariate Analysis","39f9d993":"So the mean of average score is 80% with folds","958dc9a2":"We can tell now. In the column we have Cabin, Age and Embarked we have 77, 19 and 0.22 percent data missing. we will be going to tackle this in the preprocessing stage","2d6ffee6":"So, we have missing data in three columns here\n1. Age\n2. Cabin\n3. Embarked","cc0e2cdd":"### Imputing Numerical Columns ","297662d4":"### Number of People Survived vs Not Survived","36f46892":"Let's check the max and min age for the passenger","31471bca":"We can see here that the most frequent value here is \"S\", so let's fill that value in our 2 missing \"Embarked\" rows","f8e9c908":"## Cross Validation","ead69a1f":"Now we can see that we don't have any missing values anymore","fe456e3b":"## Training Our Model","23d7a22c":"## Hyperparameter Optimization","7fd22cd0":"We are taking those values which are not avaiable in the numerical columns and wants to process it as a categorical one","ec6736ec":"## Exploring the Data & Performing EDA","f294604c":"We have only two values which are missing from the \"Embarked\" ","30a11e1d":"We are tajking the average of Age column","083336d3":"## Preparing the Dataset for Machine Learning\n\nSeperating numerical and categorical values. Performing preprocessing operations\n\nLet's convert the parent children abd sibling spouse columns into a float ones becouse certainly they don't show a categorical value","cd9075e9":"So, it's clear that your model is Overfitted"}}