{"cell_type":{"964f5b7b":"code","4db2f9e2":"code","20e2a85e":"code","e1c9b43e":"code","b2c39eac":"code","943fcd6b":"code","b7a23c2f":"code","3946db87":"code","56f993db":"code","ab10b63a":"code","1c487e61":"code","5edb3096":"code","cc7b0d6b":"code","53ca2365":"code","5c55515b":"code","7b52e251":"code","fc6ba869":"code","a6e91c58":"code","07530c03":"code","8784200a":"code","f59b8b78":"code","14d1965b":"code","5c2a7570":"code","7c1d22d0":"code","9ae421ab":"markdown","1af51e34":"markdown"},"source":{"964f5b7b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os","4db2f9e2":"# load the dataset\ndataset = pd.read_csv(\"\/kaggle\/input\/health-care-data-set-on-heart-attack-possibility\/heart.csv\")","20e2a85e":"# see first 5 rows\ndataset.head()","e1c9b43e":"# dataset shape\ndataset.shape","b2c39eac":"# check the null values\ndataset.isna().any()\n# So, their is no null value","943fcd6b":"# information about dataset\ndataset.info()","b7a23c2f":"# Check the unique value\ndataset.target.unique()","3946db87":"# import some visualization library\nimport matplotlib.pyplot as plt\nimport seaborn as sns","56f993db":"# visualize total count of sex\nsns.countplot(x=dataset[\"sex\"], data=dataset)","ab10b63a":"# But Its a ques that sex column contains two value, 0, 1\n# Which one is male and which one is female?\n# Men have a greater risk of heart attack than women do, and men have attacks earlier in life. Even after women reach the age of menopause, when women's death rate from heart disease increases, women's risk for heart attack is less than that for men.\n# google.com # heart.org","1c487e61":"sns.barplot(x=dataset[\"sex\"], y=dataset[\"target\"], data=dataset)","5edb3096":"# According to google i think 0 is male and 1 is female","cc7b0d6b":"sns.set_style('whitegrid')\ng = sns.FacetGrid(dataset, hue=\"target\", palette=\"coolwarm\", size=6, aspect=2)\ng.map(plt.hist, 'age', bins=20, alpha=0.7)\nplt.legend()","53ca2365":"# lmplot\nsns.set_style('whitegrid')\nsns.lmplot('target', 'age', data=dataset, hue='sex', palette='coolwarm', size=6, aspect=1, fit_reg=False)","5c55515b":"# visualize the correation\n\nplt.figure(figsize=(12, 6))\ng = dataset.corr()\ndata = g.index\nsns.heatmap(dataset[data].corr(), annot=True)","7b52e251":"# we see that cp(chest pain) is highly positive correlation with target\n# thalach(maximum heart rate achieved) is also correlated with target\n# exang(exercise induced angina) is highly negative correalted","fc6ba869":"corr_mat = dataset.corr()","a6e91c58":"corr_mat[\"target\"].sort_values(ascending=False)","07530c03":"# lets split the dataset\nX = dataset.drop(\"target\", axis=1)\ny = dataset[\"target\"]\nseed = 42\nsize = 0.3\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed, test_size=size)","8784200a":"# length of train and test\nprint(len(X_train))\nprint(len(X_test))","f59b8b78":"# import necessary packages\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom tabulate import tabulate\nfrom sklearn.preprocessing import StandardScaler\nfrom joblib import dump, load\n\ndef accuracy_summary(algo_name, pipeline, X_train, y_train, X_test, y_test):\n    classifier_fit = pipeline.fit(X_train, y_train)\n    y_pred = classifier_fit.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    confusion = confusion_matrix(y_test, y_pred)\n    table = tabulate({\n        \"Model Name\": [algo_name],\n        \"Accuracy\": [accuracy],\n    }, headers=\"keys\", tablefmt=\"github\")\n    print(table)\n    print(\"\\n\")\n    print(f\"Confusion Matrix For {algo_name}:\")\n    print(confusion)\n    print(\"\\n\")\n    return accuracy\n\nnames = [\n    'Logistic Regression',\n    'SVC',\n    \"K Nearest Neighbour\",\n    \"Random Forest\",\n    'GaussianNB',\n]\nclassifiers = LogisticRegression(), SVC(), KNeighborsClassifier(), RandomForestClassifier(), GaussianNB() \nzipped_classifier = zip(names, classifiers)\n\ndef classifier_compare(X_train, y_train, X_test, y_test, classifier=zipped_classifier):\n    for n, c in classifier:\n        if n == \"Random Forest\": # Scaling not affect in Tree Based Model\n            checker_pipeline = Pipeline([\n                ('classifier', c), \n            ])\n        else:\n            checker_pipeline = Pipeline([\n                ('scaler', StandardScaler()), \n                ('classifier', c),\n            ])\n        clf_accuracy = accuracy_summary(n, checker_pipeline, X_train, y_train, X_test, y_test)\n        # save model using joblib\n        dump(c, f\"{n}_model.joblib\")\n        print(\"\\n\")\n        print(f\">>Model Saved\")\n        print(\"\\n\")","14d1965b":"comp_val = classifier_compare(X_train, y_train, X_test, y_test, classifier=zipped_classifier)\ncomp_val","5c2a7570":"from joblib import load, dump","7c1d22d0":"from joblib import dump, load\nc = load('.\/K Nearest Neighbour_model.joblib')\npredict = np.array([[63, 1, 3, 145, 233, 1, 0, 150, 0, 2.3, 0, 0, 1]])\npred = c.predict(predict)\nif pred == 1:\n    print(\">> More chance of heart attack\")\nelse:\n    print(\">> Less chance of heart attack\")","9ae421ab":"# Major Symptoms Of Heart Attack.\n![HA-signs-symptoms-social2.png](attachment:8411f799-ca35-416a-9fff-b973eefcc6ab.png)","1af51e34":"# I tried to predict in easy way and want to make it full clear.\n\n# Please upvote me, It will encourage me more"}}