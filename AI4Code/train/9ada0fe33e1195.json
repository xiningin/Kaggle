{"cell_type":{"e1209b34":"code","3d841ade":"code","0a3126cd":"code","37a8ae35":"code","995d95df":"code","b766d326":"code","dc2b1654":"code","ce3e0f9b":"code","d8d4dd4a":"code","3c171e57":"markdown","9760a775":"markdown","1e2d2ef8":"markdown","24547318":"markdown","0c4790f3":"markdown","b817cc99":"markdown","0be09e3a":"markdown","b3e4d2e8":"markdown","92e0b24d":"markdown"},"source":{"e1209b34":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nplt.rcParams['figure.figsize'] = [9, 12]\n\nimport warnings\nwarnings.simplefilter('ignore')","3d841ade":"train = pd.read_csv(\"\/kaggle\/input\/whoisafriend\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/whoisafriend\/test.csv\")\nsub = pd.read_csv(\"\/kaggle\/input\/whoisafriend\/sample_submission.csv\")\n\ntrain.shape, test.shape, sub.shape","0a3126cd":"agg_train = train.groupby(['Person A', 'Person B'])['Years of Knowing'].count().reset_index()\nagg_train.rename({\n    \"Years of Knowing\": \"Interaction Count\"\n}, axis=1, inplace=True)\n\nagg_test = test.groupby(['Person A', 'Person B'])['Years of Knowing'].count().reset_index()\nagg_test.rename({\n    \"Years of Knowing\": \"Interaction Count\"\n}, axis=1, inplace=True)","37a8ae35":"agg_train.head()","995d95df":"train = pd.merge(train, agg_train, on=['Person A', 'Person B'], how='left')\ntest = pd.merge(test, agg_test, on=['Person A', 'Person B'], how='left')","b766d326":"sns.lmplot('Interaction Count', 'Friends', data=train, fit_reg=False)","dc2b1654":"plt.figure(figsize=(12, 5))\nsns.countplot('Interaction Count', data=train, hue='Friends')\nplt.show()","ce3e0f9b":"test['Friends'] = np.nan\ntest['Friends'] = test['Interaction Count'].apply(lambda x: 1 if x > 7 else 0)","d8d4dd4a":"test[['ID', 'Friends']].to_csv(\"1.0_sub.csv\", index=False)","3c171e57":"### Secret Sauce : \n\n- Hypothesis : Does it matter how many times two persons meet in thier being friends? \n\nRealistically it does though, like if you meet a guy\/girl for many times than others, there your friends right? Or not? \n\nLets check whether this hypothesis works in our data or not.","9760a775":"## Conclusion \n\n#### 1. The feature \"Interaction Count\" which I made from aggregated data is known as *Aggregated Features* and they're quite useful in many scenarios. Hence it's always a god decision for you to think for hypothesis with out checking the data first, i.e your first impressions of the problem statement. In our case : How do you make friends? What could be the factors, etc.\n\n#### 2. A better Feature Engineering always put-performs a Perfectly Fine-Tuned Model (or most of the times) .\n\n#### 3. Most of the machine learning models can not get the temporal effect in the data(RNN and LSTM can), as most of the aggregated features are used to represent the temporal effect of a set, in this case how many times did two persons meet each other? So, for our model to utilize the goodness of temporal relation we have to create features which can represent the same. \n\n4. Some more aggregated features can be : \n    \n    - avg_time_of_interaction\n    - where_did_they_meet_the_most\n    - avg_of_years_known\n    \n    As we can see most of these *aggregated features* describe the temporal relation that the model may not perceive. For example : to get an average the model has to go back to past and aggregate all the records and get the mean, and that *going back in past* is not possible for most of the models.\n    \n\n\n### Please upvote if you liked the notebook!","1e2d2ef8":"### Guess that' it then. From the plot we can see that if Interaction Count >= 8 then they're Friends, else they're not.\n\nSo our hypothesis is right on point! That's why it is important to make hypothesis's always as they make good features if prove correct, and even might win you the competition :')","24547318":"### Importing Data","0c4790f3":"### Making the Submission","b817cc99":"### Distribution of *Interaction Count*","0be09e3a":"# Getting 100% Accuraccy without Machine Learning Model\n\nThis is the solution kernel in which I use no machine learning model to achieve 100% accuracy.\n\nLet's get started then!\n","b3e4d2e8":"So basically we have to get the count of the interactions two persons have got, so let's aggregate the train and test datasets seperatly as they have totally different sets of persons.\n\nNow to get count we've got to aggregate (similar to groupby in SQL) according to \"Person A\" and \"Person B\" on function *count* to get interaction count between two persons.","92e0b24d":"### Now merging this data into train and test sets to check whether this *interaction count* has any realtionship with being Friends."}}