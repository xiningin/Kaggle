{"cell_type":{"15db3e05":"code","341e72d4":"code","95ebd1fc":"code","2824a805":"code","06096345":"code","174c4e33":"code","0a20614b":"code","21fad58a":"code","663a4a95":"code","ad3e54aa":"code","7246715b":"code","c0e97fbb":"code","5f3950ad":"code","753eb71d":"code","4aa07d3d":"code","4f2bf1ab":"code","b8653cf9":"code","a566fc0a":"code","118b7be7":"code","11455049":"code","746119f8":"code","2fe2932a":"code","7813753c":"code","e49b6eb9":"code","c0bcf7d6":"code","991768e5":"code","6effb713":"code","08cff562":"markdown","1794e8d7":"markdown","8bc781c3":"markdown","cb1cbc6c":"markdown","05c5f28a":"markdown","38250727":"markdown","12ca0220":"markdown"},"source":{"15db3e05":"# \u30e9\u30a4\u30d6\u30e9\u30ea import\nimport numpy as np\nimport pandas as pd\nfrom pandas import DataFrame\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tqdm.notebook import tqdm\nimport librosa\nimport librosa.display\nimport pickle\nimport IPython\nfrom pydub import AudioSegment\nimport os\nimport soundfile as sf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Figure\u306e\u521d\u671f\u5316\nplt.figure(figsize=(12, 8))\npd.set_option('display.max_rows', 200)\npd.set_option('display.max_columns', 200)","341e72d4":"INPUT_DIR = '\/kaggle\/input\/hah-data-science-challenge'","95ebd1fc":"# \u30d5\u30a9\u30eb\u30c0\u4f5c\u6210\n!rm -rf \/kaggle\/working\/split_sound\n!mkdir \/kaggle\/working\/split_sound\n!mkdir \/kaggle\/working\/split_sound\/train\n!mkdir \/kaggle\/working\/split_sound\/test","2824a805":"# \u8868\u8a18\u3086\u308c\u306e\u4fee\u6b63\u95a2\u6570\u3092\u62dd\u501f\u3000\u3000https:\/\/www.kaggle.com\/ryoichi0917\/corrections-to-notation-errors-and-eda-for-meta?scriptVersionId=73926073&cellId=1\ndef meta_define():\n    \"\"\"\n    input : none\n    output : Corrected metadata\n    \"\"\"\n    import pandas as pd\n    import os \n    os.chdir(\"\/kaggle\/input\/hah-data-science-challenge\/\")\n    df_train = pd.read_csv(\"train.csv\", index_col=False)\n    df_test = pd.read_csv(\"test.csv\", index_col=False)\n    \n    ##################################################\n    #\u4ee5\u4e0b\u8f9e\u66f8\u3084\u5909\u6570\u306e\u5b9a\u7fa9\n    #\u5404\u30c7\u30fc\u30bf\u4fee\u6b63\u7528\u306e\u8f9e\u66f8\n    bolt_dict = {\n        '\u5927':\"big\",\n        '\u5c0f':\"small\"\n    }\n\n    plate_dict = {\n        '\u5927':\"big\",\n        '\u5c0f':\"small\"\n    }\n\n    record_dict = {\n        'PC\u5185\u81d3':\"pc_built_in\",\n        'PC\u5185\u8535':\"pc_built_in\",\n        'USB1':\"usb1\", \n        'USB2':\"usb2\", \n        'USB3':\"usb3\", \n        'USB4':\"usb4\", \n        '\u30b9\u30de\u30db':\"smart_phone\",\n        '\u30b9\u30de\u30db\u306e\u30dc\u30a4\u30b9\u30ec\u30b3\u30fc\u30c0':\"smart_phone\",\n        '\u5185\u8535\u30de\u30a4\u30af':\"pc_built_in\",\n        }\n\n    distance_dict = {\n        '10cm': 0.1, \n        '10\u339d': 0.1, \n        '1M': 1.0, \n        '20cm': 0.2, \n        '20\u339d': 0.2, \n        '2M': 2.0, \n        '2m': 2.0, \n        '30cm': 0.3, \n        '30cn': 0.3, \n        '30\u339d': 0.3, \n        '3m': 3.0, \n        '40cm': 0.4, \n        '40\u339d': 0.4, \n        '50cm': 0.5, \n        '50\u339d': 0.5, \n        '5cm': 0.05,\n        '8cm': 0.08, \n        '\uff11\uff2d': 1.0   \n    }\n\n    cvt_dict = {\n        \"\u306d\u3058\" : bolt_dict, \n        '\u30d7\u30ec\u30fc\u30c8' : plate_dict, \n        '\u9332\u97f3\u65b9\u6cd5' : record_dict, \n        '\u30de\u30a4\u30af\u8ddd\u96e2' : distance_dict\n    }\n    \n    #df_train\u65e5\u672c\u8a9e\u30ab\u30e9\u30e0\u540d : ['ID', '\u306d\u3058', '\u30d7\u30ec\u30fc\u30c8', '\u9332\u97f3\u65b9\u6cd5', '\u30de\u30a4\u30af\u8ddd\u96e2', '\u30d5\u30a1\u30a4\u30eb', 'Target']\n    col_train = ['id', 'bolt', 'plate', 'record', 'mic_dist', 'file', 'Target']\n    #df_test\u65e5\u672c\u8a9e\u30ab\u30e9\u30e0\u540d : ['ID', '\u306d\u3058', '\u30d7\u30ec\u30fc\u30c8', '\u9332\u97f3\u65b9\u6cd5', '\u30de\u30a4\u30af\u8ddd\u96e2', '\u30d5\u30a1\u30a4\u30eb', 'Target']\n    col_test = ['id', 'bolt', 'plate', 'record', 'mic_dist', 'file']\n    \n    tgt_col = [\"\u306d\u3058\", '\u30d7\u30ec\u30fc\u30c8', '\u9332\u97f3\u65b9\u6cd5', '\u30de\u30a4\u30af\u8ddd\u96e2']\n    ##################################################\n    \n    for col in tgt_col:#Target\u306f\u5909\u63db\u5bfe\u8c61\u5916\n        df_train[col] = df_train[col].map(cvt_dict[col])\n        df_test[col] = df_test[col].map(cvt_dict[col])\n        \n    df_train.columns = col_train\n    df_test.columns = col_test\n    \n    return df_train, df_test","06096345":"# \u74b0\u5883\u97f3\u3068\u6253\u97f3\u306b\u5206\u3051\u308b\u95a2\u6570 \n# \u53c2\u8003\uff1a https:\/\/www.wizard-notes.com\/entry\/music-analysis\/hpss\n\ndef hpss(filepath):\n    y, sr = librosa.load(filepath)\n    y_harm, y_perc = librosa.effects.hpss(y)\n    return y_perc, sr\n\n# \u97f3\u306e\u9cf4\u308a\u59cb\u3081\u3092\u691c\u51fa\u3059\u308b\u95a2\u6570\u306bhpss\u3092\u52a0\u3048\u305f\u3082\u306e\n# \u53c2\u8003: http:\/\/makotomurakami.com\/blog\/2020\/06\/21\/5790\/\n\ndef backtrack_hpss(filepath):\n    # y, sr = librosa.load(filepath)  # \u5143\u306e\u30a4\u30f3\u30d7\u30c3\u30c8\u3092hpss\u6e08\u3082\u306e\u306b\u5909\u66f4\n    y, sr = hpss(filepath)\n\n    onset_envelope = librosa.onset.onset_strength(y, sr=sr)\n    onset = librosa.onset.onset_detect(onset_envelope=onset_envelope, sr=sr)\n    onset_backtrack = librosa.onset.onset_backtrack(onset, onset_envelope)\n\n    amplitude = np.abs(librosa.stft(y))\n    times = librosa.times_like(onset_envelope, sr=sr)\n    return y, sr, onset_envelope, onset, onset_backtrack    ","174c4e33":"# \u30c7\u30fc\u30bf\u3092\u8aad\u8fbc\u307f\ndf_train = pd.read_csv('\/kaggle\/input\/hah-data-science-challenge\/train.csv', index_col=False)\ndf_test = pd.read_csv('\/kaggle\/input\/hah-data-science-challenge\/test.csv', index_col=False)\n\n# \u30c7\u30fc\u30bf\u8868\u8a18\u3086\u308c\u4fee\u6b63\ndf_train, df_test = meta_define()\n\n# meta_data\u306b\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\u3092\u8ffd\u52a0\ndf_train['filepath'] = INPUT_DIR + '\/train\/train\/' + df_train['file']\ndf_test['filepath'] = INPUT_DIR + '\/test\/test\/' + df_test['file']\n\n# flag \u3092\u4ed8\u4e0e\ndf_train['flag'] = 'train'\ndf_test['flag'] = 'test'\n\n# \u7d50\u5408\ndf = pd.concat([df_train, df_test]).reset_index(drop=True)","0a20614b":"# df\u521d\u671f\u5316\ndf_sp = pd.DataFrame(index=[])\n\n# \u97f3\u58f0\u30d5\u30a1\u30a4\u30eb\u3092\u5206\u5272\u3057\u3001metadata\u3092\u4ed8\u4e0e\nfilelist = df['filepath'].to_list()\nfor i, filename in enumerate(tqdm(filelist)):\n    filenameonly = os.path.splitext(os.path.basename(filename))[0]\n    if 'train' in filenameonly : flag = 'train'\n    else : flag = 'test'\n    y, sr, onset_envelope, onset, onset_backtrack = backtrack_hpss(filename)\n    \n    for j in range(onset_backtrack.size):\n        if j != onset_backtrack.size-1:\n            sp1 = int(len(y) * onset_backtrack[j] \/ (len(y) \/\/ 512 + 1))\n            sp2 = int(len(y) * onset_backtrack[j+1] \/ (len(y) \/\/ 512 + 1))\n        if j == onset_backtrack.size-1:\n            sp1 = int(len(y) * onset_backtrack[j] \/ (len(y) \/\/ 512 + 1))\n            sp2 = len(y)\n        y_sp = y[sp1:sp2] # sp:split_point\n        \n        df_sp = df_sp.append([{\n            'file': df.at[i, 'file'],\n            'file_sp': df.at[i, 'file'].replace('.wav', '_'+str(j)+'.wav'),\n            'data_size': y.size,\n            'data_min': y.min(),\n            'data_max': y.max(),\n            'sr': sr, # 22050\n            'wav_sec': y.size \/ sr,\n            'impact_cnt': onset_backtrack.size,\n            'impact_data_size': y_sp.size,\n            'impact_sec': y_sp.size \/ sr,\n            'wav_sec_per_imp': (y.size \/ sr) \/ onset_backtrack.size,\n            'impact_count_per_sec':onset_backtrack.size \/ (y.size \/ sr)\n        }], ignore_index=True)\n        \n        # \u97f3\u58f0\u5206\u5272\u30d5\u30a1\u30a4\u30eb\u3092\u51fa\u529b\u3059\u308b\u5834\u5408\u306e\u51e6\u7406(16bit)\n        # https:\/\/www.wizard-notes.com\/entry\/music-analysis\/librosa-wav-write-16-bit\n        sf.write(\"\/kaggle\/working\/split_sound\/\" + flag + '\/' + filenameonly + \"_\"+ str(j) +\".wav\", y_sp, sr, subtype=\"PCM_16\") # 16-bit\n                \ndf_sp.head(3)","21fad58a":"# df\u306b\u30de\u30fc\u30b8\u3059\u308b\ndf2 = pd.merge(df, df_sp, how='left', on='file')\ndf2.head()","663a4a95":"# \u51e6\u7406\u306b\u6642\u9593\u304c\u639b\u304b\u308b\u305f\u3081\u51fa\u529b\nwith open('\/kaggle\/working\/df2.pickle',\"wb\") as f: pickle.dump(df2, f)\n    \n# # \u51e6\u7406\u306b\u6642\u9593\u304c\u639b\u304b\u308b\u305f\u3081\u8aad\u307f\u8fbc\u307f\n# with open('\/kaggle\/input\/hah2ndpickel\/df2.pickle',\"rb\") as f: df2 = pickle.load(f)\n\ndf2.head(3)","ad3e54aa":"# \u5206\u5272\u97f3\u58f0\u306e\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\u8ffd\u52a0\n# df2['filepath_sp'] = '\/kaggle\/input\/hah-2nd-split-sound\/split_sound\/' +  df2['flag'] + '\/' + df2['file_sp']\ndf2['filepath_sp'] = '\/kaggle\/working\/split_sound\/' +  df2['flag'] + '\/' + df2['file_sp']","7246715b":"# \u6253\u97f3\u56de\u6570\u3068\u6700\u5927\u97f3\u91cf\u3092\u5143\u306bno_call\u3092\u5224\u5b9a\ndf2['no_call'] = 0\ndf2.loc[df2['impact_sec'] < 0.1, 'no_call'] = 1  # \u79d2\u6570\u304c\u77ed\u3044\u30c7\u30fc\u30bf\u3092\u524a\u9664\u3002\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u30ec\u30fc\u30c8 22050 \u306e *0.1 \u4ee5\u4e0b\u306e\u5834\u5408\u306f\u30b5\u30f3\u30d7\u30eb\u6570\u304c\u5c11\u306a\u3044\u30ef\u30fc\u30cb\u30f3\u30b0\u304c\u51fa\u308b\u305f\u3081  \ndf2.loc[df2['impact_cnt'] >= 15, 'no_call'] = 1  # \u6253\u97f3\u6570\u304c\u591a\u3044wav\n\nprint(len(df2))\nprint(len(df2[df2['Target']==0]))\nprint(len(df2[df2['Target']==1]))\nprint(len(df2[df2['flag']=='train']))","c0e97fbb":"# librosa\u3067.wav\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u7279\u5fb4\u62bd\u51fa\u3057\u307e\u3059\u3002\nfilelist = df2['filepath_sp'].to_list()  # \u5206\u5272\u97f3\u58f0\u306e\u30d5\u30a1\u30a4\u30eb\u30ea\u30b9\u30c8\nn_features = 13\n\nfeatures_mfcc = np.zeros((len(df2), n_features))\nfor i, filename in enumerate(tqdm(filelist)):\n    y, sr = librosa.core.load(filename,sr=None)\n    if len(y)==0: \n        y=np.zeros(1)\n    else: \n        y = (y-y.min())\/(y.max()-y.min()) # \u30b5\u30f3\u30d7\u30eb\u3054\u3068\u306e\u6b63\u898f\u5316\n    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n    ceps = mfcc.mean(axis=1)\n    \n    # \u8907\u6570\u306e\u30ed\u30fc\u30ea\u30f3\u30b0\u30a6\u30a3\u30f3\u30c9\u30a6\u3067\u305d\u308c\u305e\u308c20\u6b21\u5143\u306eMFCC\u3092\u5f97\u3089\u308c\u308b\u306e\u3067\u3001\u305d\u306e\u5e73\u5747\u3092\u3068\u308b\u3002\n    features_mfcc[i] = ceps\n\nfeatures_mfcc","5f3950ad":"# \u51e6\u7406\u306b\u6642\u9593\u304c\u639b\u304b\u308b\u305f\u3081\u51fa\u529b\nwith open('\/kaggle\/working\/features_mfcc.pickle',\"wb\") as f: pickle.dump(features_mfcc, f)\n\n# # \u51e6\u7406\u306b\u6642\u9593\u304c\u639b\u304b\u308b\u305f\u3081\u8aad\u307f\u8fbc\u307f\n# with open('\/kaggle\/input\/hah2ndpickel\/features_mfcc.pickle',\"rb\") as f: features_mfcc = pickle.load(f)\n\nprint(len(features_mfcc))\nfeatures_mfcc","753eb71d":"def outlier_scoring(train_data, pred_data):\n    # \u6559\u5e2b\u306a\u3057\u7570\u5e38\u691c\u77e5\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u3067\u7570\u5e38\u30b9\u30b3\u30a2\u3092\u4ed8\u4e0e\u3057\u307e\u3059\n    model = LocalOutlierFactor(novelty=True, n_neighbors=15) # \u3053\u3053\u3067\u306fk-\u8fd1\u508d\u6cd5\u306e\u6d41\u308c\u3092\u304f\u3080LocalOutlierFactor\u3092\u7528\u3044\u307e\u3059\n    model.fit(train_data) # \u6b63\u5e38\u30c7\u30fc\u30bf\u306e\u307f\u3092\u7528\u3044\u3066\u5b66\u7fd2\u3057\u307e\u3059\n    pred = model.score_samples(pred_data) \n    # \u5024\u304c\u5c0f\u3055\u3044\u307b\u3069\u7570\u5e38\u5ea6\u304c\u9ad8\u3044\u306e\u3067\u3001\u7b26\u53f7\u3092\u3072\u3063\u304f\u308a\u8fd4\u3057\u30660\u304b\u30891\u306b\u304a\u3055\u3081\u308b\n    scaler = MinMaxScaler()\n    pred = scaler.fit_transform(-pred.reshape(-1,1))\n    \n    display(pd.DataFrame(pred).describe())\n    pd.DataFrame(pred).plot.hist(y=[0], bins=50, alpha=0.6, figsize=(12,8), sharex=True)\n    \n    return pred","4aa07d3d":"features = features_mfcc","4f2bf1ab":"from sklearn.model_selection import train_test_split\ntrain_x, valid_x, train_y, valid_y = train_test_split(features[(df2['Target']==0) & (df2['no_call']==0)], df2[(df2['Target']==0) & (df2['no_call']==0)]['Target'], test_size=0.3, random_state=1, stratify=df2[(df2['Target']==0) & (df2['no_call']==0)][['bolt', 'plate']])\n\nvalid_x = np.concatenate([valid_x, features[(df2['Target']==1) & (df2['no_call']==0)]])\nvalid_y = np.zeros(len(valid_x))\nvalid_y[-len(features[df2.Target==1]):] = 1 # \u7570\u5e38\u30c7\u30fc\u30bf\u4ed8\u4e0e","b8653cf9":"# valid score\u7b97\u51fa\npred = outlier_scoring(train_x, valid_x)","a566fc0a":"# \u6559\u5e2b\u306a\u3057\u7570\u5e38\u691c\u77e5\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u3067\u7570\u5e38\u30b9\u30b3\u30a2\u3092\u4ed8\u4e0e\u3057\u307e\u3059\nmodel = LocalOutlierFactor(novelty=True, n_neighbors=15) # \u3053\u3053\u3067\u306fk-\u8fd1\u508d\u6cd5\u306e\u6d41\u308c\u3092\u304f\u3080LocalOutlierFactor\u3092\u7528\u3044\u307e\u3059\nmodel.fit(train_x) # \u6b63\u5e38\u30c7\u30fc\u30bf\u306e\u307f\u3092\u7528\u3044\u3066\u5b66\u7fd2\u3057\u307e\u3059\ny_val_pred = model.score_samples(valid_x) # \u4ef6\u6570\u306f\u5c11\u306a\u3044\u304c\u3001\u7570\u5e38\u30b5\u30f3\u30d7\u30eb\u3092\u542b\u3080\u8a55\u4fa1\u30c7\u30fc\u30bf\u306b\u30b9\u30b3\u30a2\u3092\u4ed8\u4e0e\u3057\u307e\u3059","118b7be7":"# \u5024\u304c\u5c0f\u3055\u3044\u307b\u3069\u7570\u5e38\u5ea6\u304c\u9ad8\u3044\u306e\u3067\u3001\u7b26\u53f7\u3092\u3072\u3063\u304f\u308a\u8fd4\u3057\u30660\u304b\u30891\u306b\u304a\u3055\u3081\u308b\nscaler = MinMaxScaler()\ny_val_pred = scaler.fit_transform(-y_val_pred.reshape(-1,1))","11455049":"roc_auc_score(valid_y, y_val_pred)","746119f8":"X_train = features[df2[(df2['Target'].isnull()==False) & (df2['no_call']==0)].index]\nprint(len(X_train))\nprint(len(df2[(df2['Target'].isnull()==False)]))\n\nX_test = features[df2[(df2['file'].str.contains('test')) & (df2['no_call']==0)].index]\nprint(len(X_test))\nprint(len(df2[(df2['file'].str.contains('test'))]))\n\nmodel = LocalOutlierFactor(novelty=True, n_neighbors=15)\nmodel.fit(X_train)\ny_test_pred_temp = model.score_samples(X_test)\ny_test_pred = scaler.transform(-y_test_pred_temp.reshape(-1,1))\nlen(y_test_pred)","2fe2932a":"display(pd.DataFrame(y_test_pred).describe())\npd.DataFrame(y_test_pred).plot.hist(y=[0], bins=50, alpha=0.6, figsize=(12,8), sharex=True)","7813753c":"print(len(y_test_pred))\nprint(len(df2[(df2['file'].str.contains('test')) & (df2['no_call']==0)]))\n\ndf2_pred = df2.copy()\ndf2_pred.loc[df2_pred[(df2_pred['file'].str.contains('test')) & (df2_pred['no_call']==0)].index, 'pred'] = y_test_pred","e49b6eb9":"# \u6253\u97f3\u5206\u5272\u3057\u305fdf\u3092\u5143\u306b\u623b\u3059\ndf_pred = df2_pred.copy()\ndf_pred = df_pred.groupby(['id', 'bolt', 'plate', 'record', 'mic_dist', 'file', \n                             'flag','wav_sec', 'impact_cnt', 'wav_sec_per_imp']).agg(no_call_min=('no_call', 'min'),\n                                                                                     pred_med=('pred', 'median')).reset_index()\n# index \u3092 id \u306b\u6307\u5b9a\ndf_pred = df_pred.set_index('id')\ndf_pred['pred_med'] = df_pred['pred_med'].fillna(1)\ndf_pred","c0bcf7d6":"df_sub = pd.read_csv('\/kaggle\/input\/hah-data-science-challenge\/sample_submission.csv', index_col=0)\ndf_sub['Target'] = df_pred['pred_med']\ndf_sub","991768e5":"display(df_sub.describe())\ndf_sub.plot.hist(y=[0], bins=50, alpha=0.6, figsize=(12,8), sharex=True)","6effb713":"df_sub.to_csv('\/kaggle\/working\/submission.csv')","08cff562":"### \u7279\u5fb4\u91cf\u62bd\u51fa","1794e8d7":"1. MCFF \u7279\u5fb4\u6570\u306e\u5909\u66f4\n1. \uff11\u6253\u97f3\u306b\u5206\u5272(backtrace\u3067\u6253\u97f3\u958b\u59cb\u70b9)\n1. \u74b0\u5883\u97f3\u3068\u6253\u97f3\u306e\u5206\u96e2\n1. \u5206\u89e3\u5f8c\u30c7\u30fc\u30bf\u3067MCFF\u3092\u9069\u7528\n1. \u6253\u97f3\u56de\u6570\u304c\u591a\u3044\u30d5\u30a1\u30a4\u30eb\u306f\u7570\u5e38\u3068\u3057\u3066\u4e88\u6e2c\u5024\uff11\u306b\u8a2d\u5b9a","8bc781c3":"### Sub \u4f5c\u6210","cb1cbc6c":"### \u30c7\u30fc\u30bf\u524d\u51e6\u7406","05c5f28a":"### \u30e2\u30c7\u30eb\u4f5c\u6210\u30fb\u8a55\u4fa1","38250727":"\u30b0\u30eb\u30fc\u30d7\u5206\u3051\u3057\u306a\u3044\u7248","12ca0220":"### utils"}}