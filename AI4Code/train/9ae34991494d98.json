{"cell_type":{"cf89775a":"code","b6497b67":"code","b6fb87ce":"code","ce4790dc":"code","cf7fea85":"code","cbe376ed":"code","603939e2":"code","10d314db":"code","816b764e":"code","9a465f6c":"code","17539292":"markdown","1544829c":"markdown","ff09cb62":"markdown","d2be9bb2":"markdown","a2e0eb5f":"markdown","57aa2499":"markdown","759b2382":"markdown","4430ada5":"markdown","9b651f50":"markdown","c59f7519":"markdown","c172402d":"markdown","613d5287":"markdown"},"source":{"cf89775a":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\n# import relevant packages\nimport numpy as np\nfrom scipy import log, log10, exp, sin, cos, tan, sqrt\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LogNorm\nfrom astropy.io import fits\nfrom skimage.feature import peak_local_max\nfrom skimage.segmentation import watershed\nfrom scipy import ndimage as ndi\nfrom ipywidgets import interact\n\n# Make plot bigger by default\nplt.rcParams['figure.figsize'] = (8, 8)","b6497b67":"#define background measuring functions\ndef measureBG(image, mask=None, poissonStats=False, boxsize=65, \n              minDataSize=1000):\n    \"\"\"Find average background using sigma clipping method.\n \n    Args:\n        image: 2D numpy array for which a background map \n            should be found. The data is assumed to be counts!\n        mask: Optional 2D numpy array or fits image with True values at pixels \n            that should be masked.\n        poissonStats: If present, Poissonian statistics are used instead of \n            Gaussian. i.e the expectation value is equal to the variance, not\n            the mean.\n        boxsize: Size of box in which background is found and tiled throughout \n            the image. Should be odd to have an exact pixel center.\n        minDataSize: The minimum number of data points to consider having \n            good enough statistics to accurately calculate the mean, std.\n \n    Returns:\n        avgBG: The average background value over the whole image.\n        avgBGerr: The rms uncertainty in the avgBG\n    \"\"\"\n    #check if boxsize is odd\n    if boxsize%2 == 0:\n        print(\"WARNING: Background boxsize is even...adding one to make it odd\")\n        boxsize += 1\n \n    if mask is not None:\n        data = image[np.logical_not(mask)]\n    else:\n        data = image\n     \n    #find avg background value and error\n    (avgBG, avgBGerr) = sigmaClip(data)\n    if poissonStats:\n        avgBG = avgBGerr**2\n \n    \n    return avgBG, avgBGerr\n \n#########################################################333\n \ndef sigmaClip(data, numSigma=3.0, cenfunc=np.median):\n    \"\"\"Find the best estimate of the mean and standard deviation of a background\n    distribution by iteratively clipping data beyond +\/- some number of standard\n    deviations.\n \n    Args:\n        data: A numpy array of the data that you wish to know the background\n            distribution for.\n        sigma: The number of standard deviations beyond which data is clipped.\n        cenfunc: Optional choice of function to find the 'center' of the data. \n            Defaults to the median to be less affected by strong outliers.\n \n    Returns: The mean and standard deviation of the clipped data.\n    \"\"\"\n    data = data.ravel()\n    clippingMask = np.ones(data.size, bool)\n    lastKeep = 0\n    while(np.sum(clippingMask) != lastKeep):\n        lastKeep = np.sum(clippingMask)\n        if cenfunc == np.mean:\n            diff = data - cenfunc(data[clippingMask], dtype=np.float64)\n        else:\n            diff = data - cenfunc(data[clippingMask])\n        diff = np.abs(diff)\n        clippingMask = (diff <= np.std(data[clippingMask], dtype=np.float64) *\n                        numSigma)\n \n    return (np.mean(data[clippingMask], dtype=np.float64), \n            np.std(data[clippingMask], dtype=np.float64))","b6fb87ce":"# read in data from fits files\nB = fits.getdata(\"\/kaggle\/input\/m12-images\/Bcomb.fits\")\nV = fits.getdata(\"\/kaggle\/input\/m12-images\/Vcomb.fits\")\n","ce4790dc":"# display the images\nplt.figure()\nplt.title(\"B\")\nplt.imshow(B, interpolation='nearest', cmap='Greys_r', \n           norm=LogNorm(vmin=1, vmax=2000), origin='lower')\nplt.figure()\nplt.title(\"V\")\nplt.imshow(V, interpolation='nearest', cmap='Greys_r', \n           norm=LogNorm(vmin=1, vmax=2000), origin='lower')","cf7fea85":"# calculate background\n\nB_bg, B_bgerr = measureBG(B[1000:, 1000:])\nprint(\"B background per pixel: %1.2f +\/- %1.2f\" % (B_bg, B_bgerr))\nV_bg, V_bgerr = measureBG(V[1000:, 1000:])\nprint(\"V background per pixel: %1.2f +\/- %1.2f\" % (V_bg, V_bgerr))\nprint(\"Done measuring background levels.\")","cbe376ed":"#########################################################################\n# ADJUST THESE VARIABLES\n# If you adjust the values too low, you will overload the CPU on the \n# virtual machine.\nminRadius = 2000 # only find stars beyond this radius to avoid crowding\nthreshold = 20.0 # number of sigmas above background needed for detection\n#########################################################################\n\nplt.rcParams['figure.figsize'] = (12, 8)\n\n# find peaks\nxx, yy = np.ogrid[0:V.shape[0], 0:V.shape[1]]\nr = sqrt(xx**2 + yy**2)\nmeasureV = V + 0.0\nmeasureV[r < minRadius] = V_bg\nminLevel = V_bg + threshold * V_bgerr\nlocalMax = peak_local_max(measureV, threshold_abs=minLevel, indices=False)\nNstars = np.sum(localMax)\nprint(\"Number of stars detected: \", Nstars)\nlocalMaxDex = peak_local_max(measureV, threshold_abs=minLevel, indices=True)\n","603939e2":"#########################################################################\n# ADJUST THESE VARIABLES\nzoomCoord = [1700,1700]\n#########################################################################\n\nfig, (ax1, ax2) = plt.subplots(1,2)\nax1.imshow(measureV, interpolation='nearest', cmap='Greys_r', \n          norm=LogNorm(vmin=1, vmax=2000), origin='lower')\nax1.scatter(localMaxDex.T[1], localMaxDex.T[0], s=5, color='r')\nax2.imshow(measureV[zoomCoord[0] - 50: zoomCoord[0] + 50, zoomCoord[1] - 50: zoomCoord[1] + 50], \n           interpolation='nearest', cmap='Greys_r', \n           norm=LogNorm(vmin=1, vmax=200), origin='lower',\n          extent=[zoomCoord[0] - 50, zoomCoord[0] + 50, zoomCoord[1] - 50, zoomCoord[1] + 50])\nax2.set_xlim(zoomCoord[0] - 50, zoomCoord[0] + 50)\nax2.set_ylim(zoomCoord[1] - 50, zoomCoord[1] + 50)\nax2.scatter(localMaxDex.T[1], localMaxDex.T[0], s=5, color='r')","10d314db":"# segment image\nmarkers = ndi.label(localMax)[0]\nmask = measureV > V_bg + V_bgerr\nlabels = watershed(-V, markers, mask=mask)\n\n# sum flux in each star and subtract the background flux\nindex = np.arange(1, np.max(labels) + 1)\nVcount = ndi.sum(V - V_bg, labels, index=index)\nBcount = ndi.sum(B - B_bg, labels, index=index)\nnumpix = ndi.sum(labels > 0, labels, index=index)\nprint(\"Fluxes calculated for \", Nstars, \" stars\")\n#plt.figure()\n#plt.imshow(labels, interpolation='nearest', vmax=1, origin='lower')","816b764e":"#######################################################\nminSNRatio = 5.0 # ADJUST THIS VARIABLE\n#######################################################\n\n# remove any objects with negative fluxes\npositiveCount = np.logical_and(Vcount > 0, Bcount > 0)\nVcount = Vcount[positiveCount]\nBcount = Bcount[positiveCount]\nnumpix = numpix[positiveCount]\n\n# remove cosmic rays by setting minimum pixelcount\nVcount = Vcount[numpix >= 25]\nBcount = Bcount[numpix >= 25]\nnumpix = numpix[numpix >= 25]\n\n# convert to magnitudes\n# note the zeropoints were calibrated using reference stars\nVmag = -2.5 * log10(Vcount) + 26.44\nBmag = -2.5 * log10(Bcount) + 25.72\n\n# find the total noise and signal to noise ratio for each star\nVnoise = sqrt(Vcount + numpix * V_bgerr**2)\nBnoise = sqrt(Bcount + numpix * B_bgerr**2)\nVSN = Vcount \/ Vnoise\nBSN = Bcount \/ Bnoise\n\n# limit analysis to stars with good S\/N\ngoodstars = np.logical_and(VSN >= minSNRatio, BSN >= minSNRatio)\nprint(\"Number of stars plotted: \", np.sum(goodstars))\n\n# plot HR diagram\nplt.rcParams['figure.figsize'] = (8, 8)\nplt.figure()\nplt.gca().invert_yaxis()\nplt.plot(Bmag[goodstars] - Vmag[goodstars], Vmag[goodstars], 'o', markersize=2)\nplt.xlabel('B - V')\nplt.ylabel('V')","9a465f6c":"iso = np.loadtxt(\"\/kaggle\/input\/m12-images\/z0.0009-isochrones.dat\", usecols=(1,9,10), unpack=True)\n\ndef makeHRplot(age, EBV, DM):\n    plt.cla()\n    plt.ylim(22,12)\n    plt.xlim(-0.5, 1.5)\n    plt.plot(Bmag[goodstars] - Vmag[goodstars] - EBV, \n             Vmag[goodstars] - 3.1 * EBV, 'o', markersize=3, alpha=0.5)\n   \n    ageIndex = np.abs(iso[0] - np.log10(age*10**9)).argmin()\n    newage = iso[0][ageIndex]\n    newthing = iso[:, iso[0] == newage]\n    plt.plot(newthing[1] - newthing[2], newthing[2] + DM, linewidth=3)\n    \n    \n\n\n\ninteract(makeHRplot, age=(1,13.5,0.5), EBV=(0,0.4,0.01), DM=(0,20,0.1))","17539292":"<b>Step 4: Creating HR Diagram for M12<\/b>\n\nRecall that the peak finding procedure likely still included a few points that were not actually stars. We can perform a further refinement to attempt to exclude these false detections. Let us set a minimum signal-to-noise ratio, below which we exclude the flux measurements.\n\nAdjust the <code>minSNRatio<\/code> parameter until you are happy that your HR diagram is not too noisy. You should be able to clearly see a main sequence, turn-off, and red giant branch. You may find you need to go back and adjust the other parameters from steps 1,2, and 3 if you are not satisfied. Remember to rerun all the cells if you do that.","1544829c":"<div style=\"border-style:solid; border-width:3px; border-style:solid; border-color:black; border-radius:10px; text-align:left; padding:10px; background-color:lightblue;\">    \n    <h3><center>Answer all questions in the associated Moodle Quiz<\/center><\/h3>\n    <p><b><i>Question 1: (2 marks)<\/i><\/b> In which image would you expect to be able to see fainter stars (assuming the stars had the same brightness in both B and V)? Explain your answer.<\/p>\n    <br>\n<\/div>","ff09cb62":"<b>Step 2: Detecting stars<\/b>\n\nWe need to select the stars in the image that we want to perform measurements on. The original researchers working on Globular Clusters would have had to do this by hand. Fortunately, we can use a peak finding algorithm to detect stars in the image. It is not perfect however. Often, the algorithm will pick out peaks in the random noise and label them as stars. We can control this by only including peaks that are a certain threshold above the noise. Additionally, the algorithm performs poorly when stars are too close together and blend in to one another. The stars are only crowded in the center of the cluster, and we can tell the code to only find stars a certain minimum radius away from the center.\n\nUse the cell below to adjust <code>threshold<\/code> and <code>minRadius<\/code> and run it after each adjustment until you are satisfied that each object you are detecting (red dots) is a star, and that each star does not blend into the others. The images displayed below will show you the overall V-band image, as well as a zoomed in area. You can change which pixel you zoom in on by changeing the <code>zoomCoord<\/code> variable. \n\n(Note that even with the optimal settings still may be a few false detections, particularly around bright stars or from cosmic rays...we will try to filter these out later.)","d2be9bb2":"<div style=\"border-style:solid; border-width:3px; border-style:solid; border-color:black; border-radius:10px; text-align:left; padding:10px; background-color:lightblue;\">    \n    <br>\n    <p><b><i>Question 5: (4 marks)<\/i><\/b> Based on your fit, what is the age of the cluster? (Note that the units of the <code>age<\/code> parameter are in Gyr.) How does this compare to the age of the universe? What does that tell you about how quickly stars formed after the big bang? Recall that this globular cluster has heavy metals in it, and so was not even part of the first generation of stars.<\/p>\n    <p><b><i>Question 6: (4 marks)<\/i><\/b> Based on your fit, what is the distance modulus to the cluster? What is the distance to the cluster in kpc? light-years? Is this object inside or outside our galaxy?<\/p>\n    <br>\n<\/div>","a2e0eb5f":"<h3>Part 1: Photometry<\/h3>\n\nIn this section we will measure the magnitude of several stars in M12. Provided are observations of the outer region of the cluster taken with the VLT in B and V filters. Thankfully, these mosaics have been professionally reduced for you, meaning you don't have to worry about instrumental artifacts or cosmic rays or what read-noise is (aside: CCD statistcs are super interesting).\n\nThe general process we will follow to measure the stars photometry is:\n\n1) Measure the average background in each of the two images\n\n2) Detect stars by finding local maxima in the V-band image above some certain threshold (i.e. we don't want to detect random fluctuations in the noisy background)\n\n3) Segment the V-band image to assign pixels to stars (note this is a crude method but will work for our purposes)\n\n4) Sum up the flux of all the pixels assigned to each star, subtract the background flux, and convert to a magnitude.\n\nThroughout this procedure, there will be three paramters that you will have to adjust to get the best measurments you can.\n\n<code>threshold<\/code> - Number of standard deviations above the background a local maximum must be to be counted as a star. The lower values will pick up the most stars, but also possibly a lot of false detections. High values of <code>threshold<\/code> will pick up only the brighter stars.\n\n<code>minRadius<\/code> - The stars near the center of the cluster are very close together and bleed into one another. This makes it very difficult to measure their flux since they are contaminated by neighbours. While there are ways of performing photometry in crowded fields,  they are rather more complicated than needed here (basically you model each star as a gaussian and find the combination of normalizations that minimizes the residuals). Instead, we will only detect stars that occur at pixel coordinates greater than <code>minRadius<\/code>. You will probably have to choose a value somewhere between 500 and 1500 pixels.\n\n<code>minSNRatio<\/code> - The minimum signal-to-noise ratio ($S\/N$) of a star for it to be included in your HR diagram. The $S\/N$ is the flux count ($S$) divided by the uncertainty in that count ($N$) which is given in this case by Poisson statistics as\n\n\\begin{equation}\nN = \\sqrt{S + N_{pix}\\sigma_{bg}^2}\n\\end{equation}\n\nwhere $N_{pix}$ is the number of pixels in a star and $\\sigma_{bg}$ is the uncertainty in the average background measurement. You can also think of $S\/N$ as the inverse of the relative error (i.e. the most precise measurements have a large $S\/N$).\n\nThese parameters are set initially to zero. You can change their values in any cell, compile that cell and then move back to whatever cell you are currently working on. Notebooks work in such a way that variables defined in one cell are remembered when compiling cells in the future, and the variables will have whatever value was given to them in the most recently compiled cell.","57aa2499":"<b>Step 3: Segmenting stars<\/b>\n\nThe next section determines which pixels belong to which star based on a watershed algorithm. Essentially, you can imagine the flux of each star as an upside-down bucket. Start filling the bucket with water at the peak found earlier. The boundary of each star is then determined either by where one bucket flows into another bucket, or where it reaches an arbitrary boundary (in this case one standard deviation above the background).\n\nWe can determine the total flux of each star by adding up the flux in all the pixels and subtracting the background. Although the watershed segmentation is a quick way of obtaining the flux of each star, it is not the most accurate. It should be fine for our purposes though. Run the next cell to determine the flux from each star.","759b2382":"# Phys 3001: Globular Cluster Isochrones\n\nWelcome all you stellar students! This activity is presented to you in an interactive notebook, where you can play with variables, make figures, and even write your own code. If you are coming into this course from Phys 1031 last semester, all of the code that made the labs run was hidden from you, but now it will be more visible.\n\nFor this lab, you will need to run the code cells directly. Do this by clicking the big black \"Copy and Edit\" button in the top right of the screen. You will need a free Kaggle account if you want to spend more than fifteen minutes editing.\n\nYou are not expected to know how to program for this course. Most of the heavy-duty coding has been done for you, and the only tasks you will be expected to do will be similar in level to entering formulas into a spreadsheet.\n\nNotebooks are divided into cells. To run a cell, either press the \"Run Current Cell\" button at the top (looks like a play triangle), or press Shift + Enter. To begin run the next cell to load the necessary libraries for this lab.","4430ada5":"<h3>Part 2: Isochrone fitting<\/h3>\n\nNow we will fit model isochrones to our globular cluster data to learn about its properties.\n\nCompile the cell. You should end up with a plot where you can adjust the extinction, distance modulus, and age of the model isochrone. Play with the parameters until you find a good fit to the data. Don't worry too much about the exact shape of the turn-off; it depends heavily on various composition parameters which we are choosing to ignore. The important things to line up are the main sequence, giant branch, and turn-off *point*.","9b651f50":"<h1>Globular Clusters<\/h1>\n\nThe study of globular clusters has been invaluable to astronomers. As a roughly homogenous stellar population born at the same time and differing only in the mass of the stars, a globular cluster provides the ideal laboratory to study stellar evolution. The track that a coeval stellar population makes in an HR diagram is called an isochrone, and the position of the main sequence, turn-off point, and red giant branch provide a wealth of information. Additionally, as some of the oldest observed objects in the sky, globular clusters provide a lower limit on the age of the universe.\n\nIn this lab, we will create an HR diagram for the globular cluster M12 (aka NGC 6218), and then fit a theoretical isochrone in order to determine the age, extinction, and distance to the cluster.","c59f7519":"<div style=\"border-style:solid; border-width:3px; border-style:solid; border-color:black; border-radius:10px; text-align:left; padding:10px; background-color:lightblue;\">    \n    <br>\n    <p><b><i>Question 2: (5 marks)<\/i><\/b> What values of <code>threshold<\/code> and <code>minRadius<\/code> did you try?  For each set of values you tried, explain why you rejected them.  What values did you settle upon? Try to explain your throught process as clearly as possible<\/p>\n    <br>\n<\/div>","c172402d":"<b>Step 1: Measure the background<\/b>\n\nCompile the next few cells to measure the backround level in each bandpass. The background is essentially the brightness of the sky from reflected light in the atmosphere, but also includes some components from the camera electronics.","613d5287":"<div style=\"border-style:solid; border-width:3px; border-style:solid; border-color:black; border-radius:10px; text-align:left; padding:10px; background-color:lightblue;\">    \n    <br>\n    <p><b><i>Question 3: (1 marks)<\/i><\/b> What value of <code>minSNRratio<\/code> did you choose?<\/p>\n    <p><b><i>Question 4: (3 marks)<\/i><\/b> You should notice that the main sequence gets broader near the bottom of the plot. Why is this? Hint: are these objects brighter or fainter?<\/p>\n    <br>\n<\/div>"}}