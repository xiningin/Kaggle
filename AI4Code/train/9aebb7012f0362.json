{"cell_type":{"15116172":"code","33ea08d7":"code","f616401e":"code","672e0677":"code","7c7f7a10":"code","e019ffc7":"code","1ad875d3":"code","d529bfe1":"code","4f849e7b":"code","09af7718":"code","72f8fab3":"code","284d9f99":"code","e815f739":"code","74448a2d":"code","b23db114":"code","c1e0a21f":"code","16da96a2":"code","00eb0db0":"code","7f180a0f":"code","d7c13d9f":"code","930cf07e":"code","d2f6e100":"code","c401840e":"code","f5d0485e":"code","31dd6a2a":"code","bbd1f313":"code","d58a4f6c":"code","bf6f0c6d":"code","f33c109d":"markdown","6ce04444":"markdown","540671c6":"markdown","4ad53d0c":"markdown"},"source":{"15116172":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","33ea08d7":"df = pd.read_csv('\/kaggle\/input\/all-trumps-twitter-insults-20152021\/trump_insult_tweets_2014_to_2021.csv')","f616401e":"df.info()","672e0677":"df.head(2)","7c7f7a10":"# dropping Unnamed: 0 column\ndf = df.drop(df.columns[0], axis=1)\ndf.head(2)","e019ffc7":"# Find NA values\ndf.isna().sum()","1ad875d3":"# fill NA values \ndf.target = df.target.fillna('unknown')\ndf.isna().sum()","d529bfe1":"# create column datetime.year value\ndf['year'] = pd.DatetimeIndex(df['date']).year","4f849e7b":"df.head(2)","09af7718":"# Importing pygal and its styles\n!pip install pygal -q\nimport pygal\nfrom pygal.style import Style\nfrom IPython.display import display, HTML","72f8fab3":"base_html = \"\"\"\n<!DOCTYPE html>\n<html>\n  <head>\n  <script type=\"text\/javascript\" src=\"http:\/\/kozea.github.com\/pygal.js\/javascripts\/svg.jquery.js\"><\/script>\n  <script type=\"text\/javascript\" src=\"https:\/\/kozea.github.io\/pygal.js\/2.0.x\/pygal-tooltips.min.js\"\"><\/script>\n  <\/head>\n  <body>\n    <figure>\n      {rendered_chart}\n    <\/figure>\n  <\/body>\n<\/html>\n\"\"\"\ndef pygalplot(chart):\n    rendered_chart = chart.render(is_unicode=True)\n    plot_html = base_html.format(rendered_chart=rendered_chart)\n    display(HTML(plot_html))","284d9f99":"year = df.groupby('year')['year'].count().sort_values(ascending=False)\nline_chart = pygal.Bar()\nline_chart.title = 'Insults by year'\nfor p in list(year.index):\n    line_chart.add(str(p), year.loc[p])\npygalplot(line_chart)","e815f739":"target = df.groupby('target')['target'].count().sort_values(ascending=False)\nline_chart = pygal.HorizontalBar()\nline_chart.title = 'Insults by target'\nfor p in range(0, 20):\n    line_chart.add(target.index[p], target.values[p])\npygalplot(line_chart)","74448a2d":"insult = df.groupby('insult')['insult'].count().sort_values(ascending=False)\nline_chart = pygal.HorizontalBar()\nline_chart.title = 'Top Insults'\nfor p in range(0, 20):\n    line_chart.add(insult.index[p], insult.values[p])\npygalplot(line_chart)","b23db114":"df.insult = df.insult.apply(lambda x: x.lower())\ninsults = df.insult.unique().tolist()\ndf['tokenInsult'] = df.insult.apply(lambda x: insults.index(x))\ninsultsId = df.tokenInsult.unique().tolist()\n","c1e0a21f":"topInsults = df[['insult', 'tweet']].groupby(['insult']).count().sort_values(by='tweet', ascending=False)\n\nline_chart = pygal.Bar()\nline_chart.title = 'Insults by year'\nline_chart.x_labels = map(str, df.year.unique().tolist())\ntbyYear = []\nfor p in topInsults[:20].index.tolist():\n    total = []\n    for y in df.year.unique().tolist():\n      total.append(df.query(f'year=={y} and tokenInsult == {insults.index(p)}')['year'].count())\n    tbyYear.append(total)\ny=0\nfor p in topInsults[:20].index.tolist():  \n    line_chart.add(str(p).upper(), tbyYear[y])\n    y+=1\n    \n\npygalplot(line_chart)","16da96a2":"from sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nstopwords = set(STOPWORDS)\n\ndef myWordCloud(data, title, width = 1000, height = 600,):\n  wordcloud = WordCloud(width = width, height = height, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(' '.join(data)) \n  \n  # plot the WordCloud image                        \n  plt.figure(figsize = (8, 8), facecolor = None) \n  plt.imshow(wordcloud) \n  plt.axis(\"off\") \n  plt.tight_layout(pad = 0) \n  plt.title(title)\n  plt.show()","00eb0db0":"cv = CountVectorizer()\nmatriz = cv.fit_transform(df.insult)\ncontaPalavra = pd.DataFrame(cv.get_feature_names(), columns={'Word'})\ncontaPalavra['Counter'] = matriz.sum(axis=0).tolist()[0]\ncontaPalavra = contaPalavra.sort_values('Counter', ascending=False).reset_index(drop=True)\n\nmyWordCloud(contaPalavra.Word, f'Top Insults from Donald Trump')","7f180a0f":"df.target = df.target.apply(lambda x: x.lower())\ntargets = df.target.unique().tolist()\ndf['tokenTarget'] = df.target.apply(lambda x: targets.index(x))\ntargetsId = df.tokenTarget.unique().tolist()","d7c13d9f":"topTargets = df[['target', 'tweet']].groupby(['target']).count().sort_values(by='tweet', ascending=False)\n\nline_chart = pygal.Bar()\nline_chart.title = 'Target from Trump by year'\nline_chart.x_labels = map(str, df.year.unique().tolist())\ntbyYear = []\nfor p in topTargets[:20].index.tolist():\n    total = []\n    for y in df.year.unique().tolist():\n      total.append(df.query(f'year=={y} and tokenTarget == {targets.index(p)}')['year'].count())\n    tbyYear.append(total)\ny=0\nfor p in topTargets[:20].index.tolist():  \n    line_chart.add(str(p).upper(), tbyYear[y])\n    y+=1\n    \n\npygalplot(line_chart)","930cf07e":"cv = CountVectorizer()\nmatriz = cv.fit_transform(df.target)\ncontaPalavra = pd.DataFrame(cv.get_feature_names(), columns={'Word'})\ncontaPalavra['Counter'] = matriz.sum(axis=0).tolist()[0]\ncontaPalavra = contaPalavra.sort_values('Counter', ascending=False).reset_index(drop=True)\n\nmyWordCloud(contaPalavra.Word, f'Top Targets from Donald Trump')","d2f6e100":"!pip install vaderSentiment -q\nimport vaderSentiment\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer","c401840e":"readSentiment = SentimentIntensityAnalyzer()\ndef getSentiment(phrase):\n  s = readSentiment.polarity_scores(phrase)\n  if s['compound'] <= -0.05:\n    sentiment = 0\n  elif s['compound'] >= 0.05:\n    sentiment = 1\n  else:\n    sentiment = 2\n  return sentiment, s","f5d0485e":"phrases = [\"I love the team and how they played last night \ud83d\udc98\" ,\n\"What a fine day I am having today :-) :-)\",\n\"I am laughing like crazy lol\",\n\"He was not very good at the play\",\n\"To be or not to be\",\n\"He is kinda bored\",\n]\nsentiments = ['Negative', 'Positive', 'Neutral']\nfor txt in phrases:\n  print(sentiments[getSentiment(txt)[0]], ' - ', txt)","31dd6a2a":"f'Qty rows: {df.shape[0]}'","bbd1f313":"\ndf['sentimentVader'] = df.tweet.apply(lambda x: sentiments[getSentiment(x)[0]])\ndf['sentimentVader'].sample(10)","d58a4f6c":"sentiment = df.groupby('sentimentVader')['sentimentVader'].count()\nsentiment","bf6f0c6d":"# sentiment\npie_chart = pygal.Pie()\npie_chart.title = 'Insult vs Sentiment (by Vader)'\nfor p in range(0, len(sentiment)):\n    pie_chart.add(sentiment.index[p], sentiment.values[p])\npygalplot(pie_chart)","f33c109d":"# **Exploratory Data Analysis**","6ce04444":"# **All Trump's Twitter Insults**\n\n* **beginner**\n* **eda**\n* **dataviz**\n* **nlp**\n","540671c6":"# **Data Visualization - EDA**","4ad53d0c":"# **Dataviz - NLP (Sentiment)**"}}