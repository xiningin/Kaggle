{"cell_type":{"5a0a7ca7":"code","b2d483fa":"code","bdf67fbd":"code","2516cea0":"code","6b83c84a":"code","d0a59313":"code","1761cfa7":"code","1ae5e7a5":"code","c751a33c":"code","722265c8":"code","624e943e":"code","aded92d6":"code","6832e18a":"code","05ce6a30":"code","594e79ab":"markdown","10758b58":"markdown","40105088":"markdown","a6a7fc0b":"markdown","2ae9d415":"markdown"},"source":{"5a0a7ca7":"import numpy as np\nimport keras\nfrom keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, BatchNormalization, Input\nfrom keras.models import Sequential\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom PIL import Image\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","b2d483fa":"def load_data(path):\n    data = []\n    for (dir, _, filenames) in os.walk(path):\n        for filename in filenames:\n            image = np.array(Image.open(dir+filename).convert('L').resize((256,256))).flatten()\n            data.append(image)\n    \n    return data","bdf67fbd":"path = '\/kaggle\/input\/covid19-xray-dataset-train-test-sets\/xray_dataset_covid19\/'\n\nnormal_train    = load_data(path + 'train\/NORMAL\/')\npneumonia_train = load_data(path + 'train\/PNEUMONIA\/')\nnormal_test     = load_data(path + 'test\/NORMAL\/')\npneumonia_test  = load_data(path + 'test\/PNEUMONIA\/')","2516cea0":"train= np.concatenate((np.array(normal_train), np.array(pneumonia_train)), axis= 0)\ntrain= train\/255.0\n\ntest= np.concatenate((np.array(normal_test), np.array(pneumonia_test)), axis= 0)\ntest= test\/255.0","6b83c84a":"train_labels= np.concatenate((np.zeros(len(normal_train)), np.ones(len(pneumonia_train))))\ntest_labels= np.concatenate((np.zeros(len(normal_test)), np.ones(len(pneumonia_test))))","d0a59313":"train= train.reshape(-1,256,256,1)\ntest= test.reshape(-1,256,256,1)","1761cfa7":"train.shape, test.shape","1ae5e7a5":"plt.figure(figsize= (10,10))\nplt.subplot(2,3,1)\nplt.imshow(train[28], cmap= \"gray\");\nplt.title(\"Positive\" if train_labels[28] else \"Negative\")\nplt.axis(\"off\")\n\nplt.subplot(2,3,2)\nplt.imshow(train[22], cmap= \"gray\");\nplt.title(\"Positive\" if train_labels[22] else \"Negative\")\nplt.axis(\"off\")\n\nplt.subplot(2,3,3)\nplt.imshow(train[16], cmap= \"gray\");\nplt.title(\"Positive\" if train_labels[16] else \"Negative\")\nplt.axis(\"off\")\n\nplt.subplot(2,3,4)\nplt.imshow(train[128], cmap= \"gray\");\nplt.title(\"Positive\" if train_labels[128] else \"Negative\")\nplt.axis(\"off\")\n\nplt.subplot(2,3,5)\nplt.imshow(train[140], cmap= \"gray\");\nplt.title(\"Positive\" if train_labels[140] else \"Negative\")\nplt.axis(\"off\")\n\nplt.subplot(2,3,6)\nplt.imshow(train[100], cmap= \"gray\");\nplt.title(\"Positive\" if train_labels[100] else \"Negative\")\nplt.axis(\"off\")","c751a33c":"model= Sequential()\n\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding= \"same\", input_shape=(256,256,1), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding= \"same\", activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding= \"same\", activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), padding= \"same\", activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=32, activation='relu'))\nmodel.add(Dense(units=1, activation='sigmoid'))","722265c8":"model.compile(optimizer= \"adam\", loss= \"binary_crossentropy\", metrics= [\"accuracy\"])\nes = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=5)","624e943e":"model.fit(train, train_labels, epochs=30, batch_size= 10, validation_data=(test, test_labels), callbacks=[es])","aded92d6":"plt.figure(figsize= (20,5))\nplt.subplot(1,2,1)\nplt.plot(model.history.history[\"accuracy\"], label= \"accuracy\")\nplt.legend()\nplt.plot(model.history.history[\"val_accuracy\"], label= \"validation_accuracy\")\nplt.legend()\nplt.title(\"Train vs Validation Accuracy\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"Accuracy\")\n\nplt.subplot(1,2,2)\nplt.plot(model.history.history[\"loss\"], label= \"loss\")\nplt.legend()\nplt.plot(model.history.history[\"val_loss\"], label= \"validation_loss\")\nplt.legend()\nplt.title(\"Train vs Validation Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.show()","6832e18a":"ConfusionMatrixDisplay(confusion_matrix= confusion_matrix(train_labels, model.predict_classes(train))).plot(colorbar= False);\nplt.title(\"Confusion Matrix for Train Set\")","05ce6a30":"ConfusionMatrixDisplay(confusion_matrix= confusion_matrix(test_labels, model.predict_classes(test))).plot(colorbar= False);\nplt.title(\"Confusion Matrix for Test Set\")","594e79ab":"# Create CNN Model","10758b58":"# Create Dataset","40105088":"# Model Evaluation","a6a7fc0b":"# Visualizing Images in Data","2ae9d415":"# CNN Model Fitting"}}