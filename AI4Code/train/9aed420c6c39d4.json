{"cell_type":{"7600bbd9":"code","e01dc25a":"code","d1e21400":"code","313fe083":"code","82dd2c1f":"code","42b56167":"code","866ddf25":"code","18b37b42":"code","4bdb23a4":"code","6567dc1d":"code","6a968c6b":"code","6755af94":"code","e6bd6dbe":"code","7cd9b586":"code","0e5a2814":"code","6f063e3f":"code","86fa87aa":"code","a30fc6be":"code","1f58100d":"code","94c7cbbb":"code","77c5976a":"code","9c0ec0dc":"code","d5adfab3":"code","914cb184":"code","0c3acb83":"code","eccaf315":"code","fb281c40":"code","984d019d":"code","4650da4b":"code","a29fe01b":"code","6a3eb2cd":"code","cf627677":"code","02ac4749":"code","86d17356":"code","2600acff":"code","67037b76":"code","4c1eb761":"markdown","89782a50":"markdown","5eb7ae4c":"markdown","82ccb709":"markdown","99bc6a9b":"markdown","8d9a03c6":"markdown","813c1d64":"markdown","9f85d4be":"markdown","b53b391e":"markdown","3f6c18ca":"markdown","c01d5479":"markdown"},"source":{"7600bbd9":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport random\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation\nfrom tensorflow.keras import Sequential","e01dc25a":"import os\n# Walk through pizza_steak directory and list number of files\nprint(\"Train data: \")\nfor dirpath, dirnames, filenames in os.walk(\"..\/input\/intel-image-classification\/seg_train\/seg_train\"):\n  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\nprint(\"Test data: \")\nfor dirpath, dirnames, filenames in os.walk(\"..\/input\/intel-image-classification\/seg_test\/seg_test\"):\n  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\nprint(\"Prediction data: \")\nfor dirpath, dirnames, filenames in os.walk(\"..\/input\/intel-image-classification\/seg_pred\/seg_pred\"):\n  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")","d1e21400":"import random\nimport matplotlib.pyplot as plt\ndef view_random_image(target_dir, target_class):\n  # We will view image from here\n  target_folder = target_dir + target_class\n\n  # Get a random image path\n  random_image = random.sample(os.listdir(target_folder), 1)\n\n  # Read in the image and plot it using matplotlib\n  img = mpimg.imread(target_folder+'\/'+random_image[0])\n  plt.imshow(img)\n  plt.title(target_class)\n  plt.axis('off');\n  print(f\"Image shape {img.shape}\")\n\n  return img","313fe083":"img = view_random_image(target_dir='..\/input\/intel-image-classification\/seg_train\/seg_train\/',\n                  target_class='buildings')","82dd2c1f":"# Get the class name programmatically\nimport pathlib\ndata_dir = pathlib.Path(\"..\/input\/intel-image-classification\/seg_train\/seg_train\")\nclass_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\nprint(class_names)","42b56167":"plt.figure(figsize=(20, 10))\nfor i in range(18):\n  plt.subplot(3, 6, i+1)\n  class_name = random.choice(class_names)\n  img = view_random_image(target_dir='..\/input\/intel-image-classification\/seg_train\/seg_train\/',\n                  target_class=class_name)","866ddf25":"train_dir = \"..\/input\/intel-image-classification\/seg_train\/seg_train\/\"\ntest_dir = \"..\/input\/intel-image-classification\/seg_test\/seg_test\/\"","18b37b42":"# Create augmented data generator instance\ntrain_datagen = ImageDataGenerator(rescale=1\/255.,\n                                   rotation_range=0.2,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)\n\nval_datagen = ImageDataGenerator(rescale=1\/255.)\n\n# Load data(data, label) from directory and turn them into batches\ntrain_data = train_datagen.flow_from_directory(train_dir,\n                                               target_size=(150,150),\n                                               batch_size=32,\n                                               class_mode='categorical')\ntest_data = val_datagen.flow_from_directory(test_dir,\n                                           target_size=(150,150),\n                                           batch_size=32,\n                                           class_mode='categorical')","4bdb23a4":"model_1 = Sequential([\n  Conv2D(16, 3, padding='same', activation='relu', input_shape=(150,150,3)),\n  MaxPool2D(),\n  Conv2D(32, 3, padding='same', activation='relu'),\n  MaxPool2D(),\n  Conv2D(64, 3, padding='same', activation='relu'),\n  MaxPool2D(),\n  Flatten(),\n  Dense(128, activation='relu'),\n  Dense(len(class_names), activation='softmax')\n])\n\nmodel_1.compile(loss=\"categorical_crossentropy\",\n              optimizer=Adam(),\n              metrics=['accuracy'])\nmodel_1.summary()","6567dc1d":"history_1 = model_1.fit(train_data,\n                    epochs=4,\n                    batch_size=32,\n                    steps_per_epoch=len(train_data),\n                    validation_data=test_data,\n                    validation_steps=len(test_data))","6a968c6b":"model_1.evaluate(test_data)","6755af94":"pd.DataFrame(history_1.history)[['loss','val_loss']].plot()\nplt.title('Loss')\nplt.xlabel('epochs')\nplt.ylabel('Loss');","e6bd6dbe":"pd.DataFrame(history_1.history)[['accuracy', 'val_accuracy']].plot()\nplt.title('Accuracy')\nplt.xlabel('epochs')\nplt.ylabel('Accuracy');","7cd9b586":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport random\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation\nfrom tensorflow.keras import Sequential","0e5a2814":"# Get helper functions file\n!wget -q https:\/\/raw.githubusercontent.com\/mrdbourke\/tensorflow-deep-learning\/main\/extras\/helper_functions.py","6f063e3f":"from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys","86fa87aa":"from helper_functions import create_tensorboard_callback\n# Create ModelCheckpoint callback to save best model \ncheckpoint_path = \"feature_extraction_model_checkpoints\/\"\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n                                                      save_best_only=True,\n                                                      monitor=\"val_loss\")","a30fc6be":"from tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy(policy=\"mixed_float16\")\nmixed_precision.global_policy()","1f58100d":"!nvidia-smi -L","94c7cbbb":"from tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.applications.vgg16 import VGG16\n# Create base model\ninput_shape = (150,150,3)\nbase_model = VGG16(include_top=False, weights = 'imagenet')\nbase_model.trainable = False\n\n# Create functional model\ninputs = layers.Input(shape=input_shape, name='input_layer')\n# x = preprocessing.Rescaling(1.\/255)(x)\nx = base_model(inputs, training=False)\nx = layers.GlobalAveragePooling2D(name='pooling_layer')(x)\nx = layers.Dense(len(class_names))(x)\n\n# Create output layer and combine them\noutputs = layers.Activation(\"softmax\", dtype=tf.float32, name='softmax_float32')(x)\nmodel = tf.keras.Model(inputs, outputs)\n\n# Compile the model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(),\n              metrics=[\"accuracy\"])\nmodel.summary()","77c5976a":"# Checking layer dtype policy\nfor layer in model.layers:\n  print(layer.name, layer.trainable, layer.dtype,layer.dtype_policy)","9c0ec0dc":"# Check the layers in the base model and see what dtype policy they're using\nfor layer in model.layers[1].layers[:20]: # only check the first 20 layers to save output space\n  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)","d5adfab3":"history = model.fit(train_data,\n                    epochs=5,\n                    steps_per_epoch=len(train_data),\n                    validation_data=test_data,\n                    validation_steps=len(test_data),\n                    callbacks=[create_tensorboard_callback(\"training_logs\",\n                                                          \"vgg16_mobile_feature_extract\"),\n                              model_checkpoint])","914cb184":"result_feature_extract_model = model.evaluate(test_data)\nresult_feature_extract_model","0c3acb83":"plot_loss_curves(history)","eccaf315":"# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", # watch the val loss metric\n                                                  patience=3) # if val loss decreases for 3 epochs in a row, stop training\n\n# Create ModelCheckpoint callback to save best model during fine-tuning\ncheckpoint_path = \"fine_tune_checkpoints\/\"\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n                                                      save_best_only=True,\n                                                      monitor=\"val_loss\")\n\n# Creating learning rate reduction callback\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",  \n                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n                                                 patience=2,\n                                                 verbose=1, # print out when learning rate goes down \n                                                 min_lr=1e-7)","fb281c40":"from tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.applications.vgg16 import VGG16\n# Create base model\ninput_shape = (150,150,3)\nbase_model = VGG16(include_top=False, weights = 'imagenet')\nbase_model.trainable = False\n\n# Create functional model\ninputs = layers.Input(shape=input_shape, name='input_layer')\n# x = preprocessing.Rescaling(1.\/255)(inputs)\nx = base_model(inputs, training=False)\nx = layers.GlobalAveragePooling2D(name='pooling_layer')(x)\nx = layers.Dense(len(class_names))(x)\n\n# Create output layer and combine them\noutputs = layers.Activation(\"softmax\", dtype=tf.float32, name='softmax_float32')(x)\nmodel_fine_tune = tf.keras.Model(inputs, outputs)\nmodel_fine_tune.summary()","984d019d":"# Set entire model trainable (no frozeen layer)\nfor layer in model_fine_tune.layers:\n  layer.trainable = True # set all layers to trainable\n  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy) \n  # make sure loaded model is using mixed precision dtype_policy (\"mixed_float16\")","4650da4b":"# Check the layers in the base model and see what dtype policy they're using\nfor layer in model_fine_tune.layers[1].layers[:20]:\n  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)","a29fe01b":"# Compile the model\nmodel_fine_tune.compile(loss=\"categorical_crossentropy\", # sparse_categorical_crossentropy for labels that are *not* one-hot\n                        optimizer=tf.keras.optimizers.Adam(0.0001), # 10x lower learning rate than the default\n                        metrics=[\"accuracy\"])\nmodel_fine_tune.summary()","6a3eb2cd":"# Start to fine-tune (all layers)\nhistory_fine_tune = model_fine_tune.fit(train_data,\n                                        epochs=20, # fine-tune for a maximum of 100 epochs\n                                        steps_per_epoch=len(train_data),\n                                        validation_data=test_data,\n                                        validation_steps=int(0.15 * len(test_data)), # validation during training on 15% of test data\n                                        callbacks=[create_tensorboard_callback(\"training_logs\", \"model_vgg_mobile_image_fine_tuning\"), # track the model training logs\n                                                    model_checkpoint, # save only the best model during training\n                                                    early_stopping, # stop model after X epochs of no improvements\n                                                    reduce_lr]) # reduce the learning rate after X epochs of no improvements","cf627677":"model_fine_tune.evaluate(test_data)","02ac4749":"plot_loss_curves(history_fine_tune)","86d17356":"def load_and_prep_image(filename, img_shape=150, scale=True):\n  \"\"\"\n  Reads in an image from filename, turns it into a tensor and reshapes into\n  (224, 224, 3).\n\n  Parameters\n  ----------\n  filename (str): string filename of target image\n  img_shape (int): size to resize target image to, default 224\n  scale (bool): whether to scale pixel values to range(0, 1), default True\n  \"\"\"\n  # Read in the image\n  img = tf.io.read_file(filename)\n  # Decode it into a tensor\n  img = tf.io.decode_image(img)\n  # Resize the image\n  img = tf.image.resize(img, [img_shape, img_shape])\n  if scale:\n    # Rescale the image (get all values between 0 and 1)\n    return img\/255.\n  else:\n    return img","2600acff":"import os\npred_img = os.listdir(\"..\/input\/intel-image-classification\/seg_pred\/seg_pred\/\")\nimport random\ncustom_images = []\nfor i in range(10):\n  custom_images.append(\"..\/input\/intel-image-classification\/seg_pred\/seg_pred\/\"+random.choice(pred_img))\n\ncustom_images","67037b76":"# Make predictions on custom images\nfor img in custom_images:\n  img = load_and_prep_image(img, scale=False) # load in target image and turn it into tensor\n  pred_prob = model_fine_tune.predict(tf.expand_dims(img, axis=0)) # make prediction on image with shape [None, 150, 150, 3]\n  pred_class = class_names[pred_prob.argmax()] # find the predicted class label\n  # Plot the image with appropriate annotations\n  plt.figure()\n  plt.imshow(img\/255.) # imshow() requires float inputs to be normalized\n  plt.title(f\"pred: {pred_class}, prob: {pred_prob.max():.2f}\")\n  plt.axis(False)","4c1eb761":"# Basic model Buildinig (CNN Classifier)","89782a50":"# Overview\n- Get and explore images\n- Prepare data for the model\n- Basic CNN model\n- Transfer Learning\n  - Prepare data\n  - Create a feature extractor model (VGG16)\n  - Setting up mixed precision for faster training \n  - Load and evaluate checkpoint weights\n  - Setup early stoping, checkpoint, learning rate reduction callbacks\n  - Fine tune feature extraction model (VGG16)\n  - Make prediction using our final trained model","5eb7ae4c":"## Creating feature extractor model callbacks","82ccb709":"## Fine tune feature extraction model","99bc6a9b":"# Prepare data for model","8d9a03c6":"# Transfer learning model","813c1d64":"## Setup all callbacks before final model","9f85d4be":"# Explore data","b53b391e":"# Setting up mixed precision training","3f6c18ca":"## Make prediction using our final trained model","c01d5479":"## Feature extraction model"}}