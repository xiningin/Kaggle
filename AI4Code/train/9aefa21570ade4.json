{"cell_type":{"3250a9ea":"code","34ddfb7d":"code","5481a814":"code","071248c1":"code","27495589":"code","b92bcc6f":"code","e7d01de5":"code","c2e4fb5f":"code","4621c9c9":"code","cc41e72e":"code","598daa58":"code","bb5c0e78":"code","183b6c3d":"code","4e987c19":"code","b569c981":"code","ed79252d":"code","2296e186":"code","fc100e85":"code","0682ae06":"code","dceb78db":"code","a53c32de":"code","af1be75b":"code","727e4fe0":"code","afde9f93":"code","7af00350":"code","620b6542":"code","69a83917":"code","4cd97040":"code","dccaed3f":"code","6262e8d8":"code","756b3218":"code","8d6fb12e":"code","0e6ef749":"code","9367fa21":"code","b5fcfbc8":"code","1628b13e":"code","8c7a9dd9":"code","5bba7a9d":"code","723b12bd":"markdown","7e17bf3f":"markdown","832f8b34":"markdown","245cf301":"markdown"},"source":{"3250a9ea":"# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import Imputer\n# % matplotlib inline\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nlabel = LabelEncoder()\n\n# Read train and test data\ntrain_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","34ddfb7d":"train_df.head()","5481a814":"print(\"Train: \\n\", train_df.isnull().sum())\nprint(\"\\nTest: \\n\", test_df.isnull().sum())","071248c1":"# Fill missing values because test has only one missing value\ntest_df.Fare.fillna(test_df.Fare.mean(), inplace=True)\n# The entire data\ndata_df = train_df.append(test_df)\npassenger_id=test_df.PassengerId\n\n# Drop PassengerID because will not be usefull\ntrain_df.drop([\"PassengerId\"], axis=1, inplace=True)\ntest_df.drop([\"PassengerId\"], axis=1, inplace=True)\ntest_df.shape","27495589":"sns.boxplot(x='Survived',y='Fare',data=train_df)","b92bcc6f":"train_df=train_df[train_df['Fare']<400]\n\ntrain_df['Sex'] = pd.Categorical(train_df.Sex).codes\ntest_df['Sex'] = pd.Categorical(test_df.Sex).codes","e7d01de5":"# The mean() strategy.\nfor name_string in data_df['Name']:\n    data_df['Title']=data_df['Name'].str.extract('([A-Za-z]+)\\.',expand=True)\n\n# Replacing rare titles with more common ones.\nmapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr', 'Don': 'Mr', 'Mme': 'Miss',\n          'Jonkheer': 'Mr', 'Lady': 'Mrs', 'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\ndata_df.replace({'Title': mapping}, inplace=True)","c2e4fb5f":"data_df.groupby('Title')['Age'].median()","4621c9c9":"data_df['Title'].value_counts()\ntrain_df['Title']=data_df['Title'][:891]\ntest_df['Title']=data_df['Title'][891:]\n\ntitles=['Mr','Miss','Mrs','Master','Rev','Dr']\nfor title in titles:\n    age_to_impute = data_df.groupby('Title')['Age'].mean()[titles.index(title)]\n    print(age_to_impute)\n    data_df.loc[(data_df['Age'].isnull()) & (data_df['Title'] == title), 'Age'] = age_to_impute\ndata_df.isnull().sum()\n\ntrain_df['Age']=data_df['Age'][:891]\ntest_df['Age']=data_df['Age'][891:]\ntest_df.isnull().sum()","cc41e72e":"train_df.head()","598daa58":"## A good feature to create: `family_size`\ntrain_df['family_size'] = train_df.SibSp + train_df.Parch+1\ntest_df['family_size'] = test_df.SibSp + test_df.Parch+1","bb5c0e78":"def family_group(size):\n    a = ''\n    if (size <= 1):\n        a = 'loner'\n    elif (size <= 4):\n        a = 'small'\n    else:\n        a = 'large'\n    return a\n\ntrain_df['family_group'] = train_df['family_size'].map(family_group)\ntest_df['family_group'] = test_df['family_size'].map(family_group)","183b6c3d":"train_df['is_alone'] = [1 if i<2 else 0 for i in train_df.family_size]\ntest_df['is_alone'] = [1 if i<2 else 0 for i in test_df.family_size]","4e987c19":"train_df['child'] = [1 if i<16 else 0 for i in train_df.Age]\ntest_df['child'] = [1 if i<16 else 0 for i in test_df.Age]\ntrain_df.child.value_counts()","b569c981":"train_df['calculated_fare'] = train_df.Fare\/train_df.family_size\ntest_df['calculated_fare'] = test_df.Fare\/test_df.family_size","ed79252d":"train_df.calculated_fare.mean()","2296e186":"def fare_group(fare):\n    a= ''\n    if fare <= 4:\n        a = 'Very_low'\n    elif fare <= 10:\n        a = 'low'\n    elif fare <= 20:\n        a = 'mid'\n    elif fare <= 45:\n        a = 'high'\n    else:\n        a = \"very_high\"\n    return a","fc100e85":"train_df['fare_group'] = train_df['calculated_fare'].map(fare_group)\ntest_df['fare_group'] = test_df['calculated_fare'].map(fare_group)","0682ae06":"train_df = pd.get_dummies(train_df, columns=['Title',\"Pclass\",'Embarked', 'family_group', 'fare_group'], drop_first=True)\ntest_df = pd.get_dummies(test_df, columns=['Title',\"Pclass\",'Embarked', 'family_group', 'fare_group'], drop_first=True)\ntrain_df.drop(['Cabin', 'family_size','Ticket','Name', 'Fare'], axis=1, inplace=True)\ntest_df.drop(['Ticket','Name','family_size',\"Fare\",'Cabin'], axis=1, inplace=True)","dceb78db":"pd.options.display.max_columns = 99","a53c32de":"def age_group_fun(age):\n    a = ''\n    if age <= 1:\n        a = 'infant'\n    elif age <= 4: \n        a = 'toddler'\n    elif age <= 13:\n        a = 'child'\n    elif age <= 18:\n        a = 'teenager'\n    elif age <= 35:\n        a = 'Young_Adult'\n    elif age <= 45:\n        a = 'adult'\n    elif age <= 55:\n        a = 'middle_aged'\n    elif age <= 65:\n        a = 'senior_citizen'\n    else:\n        a = 'old'\n    return a","af1be75b":"train_df['age_group'] = train_df['Age'].map(age_group_fun)\ntest_df['age_group'] = test_df['Age'].map(age_group_fun)","727e4fe0":"train_df = pd.get_dummies(train_df,columns=['age_group'], drop_first=True)\ntest_df = pd.get_dummies(test_df,columns=['age_group'], drop_first=True)\n#Lets try all after dropping few of the column.\ntrain_df.drop(['Age','calculated_fare'],axis=1,inplace=True)\ntest_df.drop(['Age','calculated_fare'],axis=1,inplace=True)","afde9f93":"train_df.head()\n\ntrain_df.drop(['Title_Rev','age_group_old','age_group_teenager','age_group_senior_citizen','Embarked_Q'],axis=1,inplace=True)\ntest_df.drop(['Title_Rev','age_group_old','age_group_teenager','age_group_senior_citizen','Embarked_Q'],axis=1,inplace=True)","7af00350":"X = train_df.drop('Survived', 1)\ny = train_df['Survived']","620b6542":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedShuffleSplit,train_test_split\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import svm\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import accuracy_score","69a83917":"# Classifier comparision\nclassifiers = [\n    KNeighborsClassifier(3),\n    svm.SVC(probability=True),\n    DecisionTreeClassifier(),\n    XGBClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    GaussianNB(),\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis(),\n    LogisticRegression()]\n    \n\n\nlog_cols = [\"Classifier\", \"Accuracy\"]\nlog= pd.DataFrame(columns=log_cols)","4cd97040":"SSplit=StratifiedShuffleSplit(test_size=0.3,random_state=7)\nacc_dict = {}\n\nfor train_index,test_index in SSplit.split(X,y):\n    X_train,X_test=X.iloc[train_index],X.iloc[test_index]\n    y_train,y_test=y.iloc[train_index],y.iloc[test_index]\n    \n    for clf in classifiers:\n        name = clf.__class__.__name__\n          \n        clf.fit(X_train,y_train)\n        predict=clf.predict(X_test)\n        acc=accuracy_score(y_test,predict)\n        if name in acc_dict:\n            acc_dict[name]+=acc\n        else:\n            acc_dict[name]=acc","dccaed3f":"log['Classifier']=acc_dict.keys()\nlog['Accuracy']=acc_dict.values()\n#log.set_index([[0,1,2,3,4,5,6,7,8,9]])\n%matplotlib inline\nsns.set_color_codes(\"muted\")\nax=plt.subplots(figsize=(10,8))\nax=sns.barplot(y='Classifier',x='Accuracy',data=log,color='b')\nax.set_xlabel('Accuracy',fontsize=20)\nplt.ylabel('Classifier',fontsize=20)\nplt.grid(color='r', linestyle='-', linewidth=0.5)\nplt.title('Classifier Accuracy',fontsize=20)","6262e8d8":"## Necessary modules for creating models. \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.metrics import accuracy_score,classification_report, precision_recall_curve, confusion_matrix","756b3218":"std_scaler = StandardScaler()\nX = std_scaler.fit_transform(X)\ntestframe = std_scaler.fit_transform(test_df)\ntestframe.shape","8d6fb12e":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=1000)\n\nxgb=XGBClassifier(max_depth=2, n_estimators=700, learning_rate=0.009,nthread=-1,subsample=1,colsample_bytree=0.8)\nxgb.fit(X_train,y_train)\npredict=xgb.predict(X_test)\nprint(accuracy_score(y_test,predict))\nprint(confusion_matrix(y_test,predict))\n\n# lda=LinearDiscriminantAnalysis()\n# lda.fit(X_train,y_train)\n# predict=lda.predict(X_test)\n# print(accuracy_score(y_test,predict))","0e6ef749":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=1000)\n\nlogreg = LogisticRegression(solver='liblinear', penalty='l1')\nlogreg.fit(X_train,y_train)\npredict=logreg.predict(X_test)\n# print(accuracy_score(y_test,predict))\n# print(confusion_matrix(y_test,predict))\n\nparam = {'penalty': ['l1','l2'], 'C': [0.0001, 0.001, 0.01, 0.1,.15, .25, .275, .33, 0.5, .66, 0.75, 1.0, 2., 10.0, 100.0, 1000.0] }\ngrid = GridSearchCV(logreg, param,verbose=False, cv = StratifiedKFold(n_splits=5,random_state=10,shuffle=True), n_jobs=1,scoring='accuracy')\n\ngrid.fit(X_train,y_train)\n\nprint (grid.best_params_)\nprint (grid.best_score_)\nprint(grid.best_estimator_)\n\ngrid.best_estimator_.fit(X_train,y_train)\npredict=grid.best_estimator_.predict(X_test)\nprint(accuracy_score(y_test,predict))","9367fa21":"# from sklearn.ensemble import VotingClassifier\n\n# voting_classifier = VotingClassifier(estimators=[('logreg',logreg),\n#                                                  ('XGB Classifier', xgb)])\n# voting_classifier.fit(X_train,y_train)\n# y_pred = voting_classifier.predict(X_test)\n# voting_accuracy = accuracy_score(y_pred, y_test)\n# print(voting_accuracy)","b5fcfbc8":"# y_predict=xgb.predict(testframe)\ny_predict=grid.best_estimator_.predict(testframe)","1628b13e":"y_predict.shape","8c7a9dd9":"y_predict","5bba7a9d":"# from google.colab import files\n\ntemp = pd.DataFrame(pd.DataFrame({\n        \"PassengerId\": passenger_id,\n        \"Survived\": y_predict\n    }))\n\n\ntemp.to_csv(\"submission.csv\", index = False)\n# files.download('submission.csv') ","723b12bd":"## Model Creation","7e17bf3f":"## Feature Engineering","832f8b34":"## Clean Data","245cf301":"## Get Data"}}