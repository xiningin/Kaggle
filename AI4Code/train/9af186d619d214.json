{"cell_type":{"99d8d0f7":"code","36ecbd54":"code","97cbd1e4":"code","202daf5c":"code","ed1246d5":"code","2b4c5d8f":"code","d4649ec6":"code","ec31f319":"code","1e80c77a":"code","0ff15b00":"code","f49ce366":"code","e8a312d2":"code","8876547b":"code","6841b9dc":"code","04c5475e":"code","f27d51b3":"code","381a34fa":"code","41ef75af":"code","64109ff3":"code","f992cad9":"code","6a701c30":"markdown","7c8a20ab":"markdown","2819a21e":"markdown","f57e331c":"markdown","4c23dfdb":"markdown","a11dfccb":"markdown","f9b37fe4":"markdown","6552cf4f":"markdown","2c60ac33":"markdown","28a077dc":"markdown","0cfea8f1":"markdown","a32cb4dd":"markdown","5271a628":"markdown","ad8e8214":"markdown","19ade785":"markdown"},"source":{"99d8d0f7":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport folium\nfrom folium.plugins import MarkerCluster\nfrom geopy import geocoders\n!pip install squarify\nimport squarify\nfrom textblob import TextBlob","36ecbd54":"data = pd.read_csv(\"..\/input\/netflix-shows\/netflix_titles.csv\")\ndata","97cbd1e4":"types,counts = np.unique(data.type,return_counts=True)\nplt.title(\"Show Type\")\nplt.xlabel(\"Show Types\")\nplt.ylabel(\"Count\")\nplt.bar(types,counts)","202daf5c":"countries = list(data.country.dropna())\ncountries_filter = []\nfor i in countries:\n            for entry in i.split(\",\"):\n                countries_filter.append(str(entry.strip()))\nfor i in countries_filter:\n    if i == '' or i == ' ':\n        countries_filter.remove(i)\ncountries_filter,count = np.unique(countries_filter,return_counts=True)\n\n\nlat = []\nlon = []\n\nfrom geopy.geocoders import Nominatim\ngeocoder = Nominatim(user_agent = 'Netflix Analytics')\nfor i in countries_filter:\n    try:\n        lat.append(geocoder.geocode(i).raw['lat'])\n        lon.append(geocoder.geocode(i).raw['lon'])\n    except:\n        print(\"Not locatable : \",i)\n\nworld_map = folium.Map(tiles='cartodbpositron')\nmarker_cluster = MarkerCluster().add_to(world_map)\nfor i in range(len(countries_filter)):\n    folium.CircleMarker(location=[lat[i],lon[i]],radius=5,popup=count[i],fill=True).add_to(marker_cluster)\nworld_map\n","ed1246d5":"year = []\nfor i in data['date_added'].dropna():\n    year.append(int(i.split(\",\")[1]))\nyear,count = np.unique(year,return_counts=True)\nplt.figure(figsize=(12, 6), dpi=80)\nplt.xticks(np.arange(min(year), max(year)+1, 1.0))\nplt.plot(year,count)\nplt.xlabel(\"Year\")\nplt.ylabel(\"Count\")\nplt.title(\"Year wise upload\")\nplt.show()","2b4c5d8f":"month = []\nfor i in data['date_added'].dropna():\n    month.append(i.split(\",\")[0].split(\" \")[0].strip())\n    \nmonth,count = np.unique(month,return_counts=True)\n\n#Removing the NULL value at first\nmonth = month[1:]\ncount = count[1:]\n\n#Sorting months and its count to get ordered graph\nfor i in range(len(month)):\n  for i in range(len(month)-1):\n    if count[i] > count[i+1]:\n        temp = count[i]\n        count[i] = count[i+1]\n        count[i+1] = temp\n        \n        temp = month[i]\n        month[i] = month[i+1]\n        month[i+1] = temp\n\nplt.figure(figsize=(12, 6), dpi=80)\nplt.bar(month,count)\nplt.xlabel(\"Month\")\nplt.ylabel(\"Count\")\nplt.title(\"Month wise upload\")\nplt.show()\n","d4649ec6":"ry = data['release_year']\nprint(ry.min(),ry.max())\nry,count = np.unique(ry,return_counts=True)\nfig, ax = plt.subplots(1, figsize = (22,22))\nsquarify.plot(sizes=count, label=ry, alpha=0.6 )\nplt.axis('off')\nplt.show()","ec31f319":"rating = data['rating']\nr_u=[]\nc_rating = []\nfor i in rating.dropna():\n    if i not in r_u:\n        r_u.append(i)\n        \nfor i in r_u:\n    c_rating.append(list(rating).count(i))\n    \nplt.figure(figsize=(15, 5), dpi=500)\nplt.plot(r_u,c_rating)\nplt.show()","1e80c77a":"lin = data['listed_in'].dropna()\nlin_filter = []\nlin_count = []\nlin_unique = []\n\nfor item in lin:\n    for entry in item.split(\",\"):\n            lin_unique.append(entry.strip())\nfor item in lin_unique:\n    if item not in lin_filter:\n        lin_filter.append(item)\n\nfor item in lin_filter:\n    lin_count.append(lin_unique.count(item))\n\nfig, ax = plt.subplots(1, figsize = (52,22))\nsquarify.plot(sizes=lin_count, label=lin_filter)\nplt.axis('off')\nplt.show()\nfig.savefig(\"temps\")","0ff15b00":"mins = []\nseasons = []\nfor item in data['duration'].dropna():\n    if item.find(\"min\") > -1:\n        mins.append(int(item.split(\" \")[0]))\n    if item.find(\"Seasons\") > -1 or item.find(\"Season\") > -1:\n        seasons.append(int(item.split(\" \")[0]))\nprint(\"Minimum Episode time : \",np.unique(mins).min(),\"mins\")\nprint(\"Maximum Episode time : \",np.unique(mins).max()\/60, \"hours\")\nprint(\"Average Episode time : {:.2f}\".format(np.unique(mins).mean()\/60),\"hours\")\nprint()\nprint(\"Minimum Seasons : \",np.unique(seasons).min(),\"Season\")\nprint(\"Maximum Seasons : \",np.unique(seasons).max(),\"Seasons\")\nprint(\"Average Seasons : \",int(np.unique(seasons).mean()),\"Seasons\")\n\n    ","f49ce366":"p_tweets=0\nn_tweets=0\nng_tweets=0\n\nfor entry in data['description'].dropna():\n    if TextBlob(entry).polarity > 0:\n        p_tweets = p_tweets + 1\n    if TextBlob(entry).polarity == 0:\n        n_tweets = n_tweets + 1\n    if TextBlob(entry).polarity < 0:\n        ng_tweets = ng_tweets + 1\n        \nprint(\"Positive Tweets : {:.2f}\".format(p_tweets \/ len(data) * 100),\"%\")\nprint(\"Neutral Tweets  : {:.2f}\".format(n_tweets \/ len(data) * 100),\"%\")\nprint(\"Negative Tweets : {:.2f}\".format(ng_tweets \/ len(data) * 100),\"%\")","e8a312d2":"#get area from user\ncnt = input(\"Enter country : \")\nqueried_data = data[data['country'].str.find(cnt) > -1]\nqueried_data","8876547b":"types,counts = np.unique(queried_data.type,return_counts=True)\nplt.title(\"Show Type Analytics for \"+ cnt)\nplt.xlabel(\"Show Types\")\nplt.ylabel(\"Count\")\nplt.bar(types,counts)","6841b9dc":"year = []\nfor i in queried_data['date_added'].dropna():\n    year.append(int(i.split(\",\")[1]))\nyear,count = np.unique(year,return_counts=True)\nplt.figure(figsize=(12, 6), dpi=80)\nplt.xticks(np.arange(min(year), max(year)+1, 1.0))\nplt.plot(year,count)\nplt.xlabel(\"Year\")\nplt.ylabel(\"Count\")\nplt.title(\"Year wise upload for \" + cnt)\nplt.show()","04c5475e":"month = []\nfor i in queried_data['date_added'].dropna():\n    month.append(i.split(\",\")[0].split(\" \")[0].strip())\n    \nmonth,count = np.unique(month,return_counts=True)\n\n#Removing the NULL value at first\nmonth = month[1:]\ncount = count[1:]\n\n#Sorting months and its count to get ordered graph\nfor i in range(len(month)):\n  for i in range(len(month)-1):\n    if count[i] > count[i+1]:\n        temp = count[i]\n        count[i] = count[i+1]\n        count[i+1] = temp\n        \n        temp = month[i]\n        month[i] = month[i+1]\n        month[i+1] = temp\n\nplt.figure(figsize=(12, 6), dpi=80)\nplt.bar(month,count)\nplt.xlabel(\"Month\")\nplt.ylabel(\"Count\")\nplt.title(\"Month wise upload for \"+cnt)\nplt.show()\n","f27d51b3":"ry = queried_data['release_year']\nprint(\"Oldest release : \",ry.min())\nprint(\"Latest release : \",ry.max())\nry,count = np.unique(ry,return_counts=True)\nfig, ax = plt.subplots(1, figsize = (22,22))\nsquarify.plot(sizes=count, label=ry, alpha=0.6 )\nplt.title(\"Release year Analysis for \"+cnt)\nplt.axis('off')\nplt.show()","381a34fa":"rating = queried_data['rating']\nr_u=[]\nc_rating = []\nfor i in rating.dropna():\n    if i not in r_u:\n        r_u.append(i)\n        \nfor i in r_u:\n    c_rating.append(list(rating).count(i))\n    \nplt.figure(figsize=(15, 5), dpi=500)\nplt.title(\"Rating Analysis for \"+cnt)\nplt.plot(r_u,c_rating)\nplt.show()","41ef75af":"lin = queried_data['listed_in'].dropna()\nlin_filter = []\nlin_count = []\nlin_unique = []\n\nfor item in lin:\n    for entry in item.split(\",\"):\n            lin_unique.append(entry.strip())\nfor item in lin_unique:\n    if item not in lin_filter:\n        lin_filter.append(item)\n\nfor item in lin_filter:\n    lin_count.append(lin_unique.count(item))\n\nfig, ax = plt.subplots(1, figsize = (52,22))\nplt.title(\"Category Analysis for \"+cnt)\nsquarify.plot(sizes=lin_count, label=lin_filter)\nplt.axis('off')\nplt.show()\nfig.savefig(\"temps\")","64109ff3":"mins = []\nseasons = []\nfor item in queried_data['duration'].dropna():\n    if item.find(\"min\") > -1:\n        mins.append(int(item.split(\" \")[0]))\n    if item.find(\"Seasons\") > -1 or item.find(\"Season\") > -1:\n        seasons.append(int(item.split(\" \")[0]))\nprint(\"Show duration analysis for \"+cnt)\nprint(\"Minimum Episode time : \",np.unique(mins).min(),\"mins\")\nprint(\"Maximum Episode time : \",np.unique(mins).max()\/60, \"hours\")\nprint(\"Average Episode time : {:.2f}\".format(np.unique(mins).mean()\/60),\"hours\")\nprint()\nprint(\"Minimum Seasons : \",np.unique(seasons).min(),\"Season\")\nprint(\"Maximum Seasons : \",np.unique(seasons).max(),\"Seasons\")\nprint(\"Average Seasons : \",int(np.unique(seasons).mean()),\"Seasons\")\n\n    ","f992cad9":"p_tweets=0\nn_tweets=0\nng_tweets=0\n\nfor entry in queried_data['description'].dropna():\n    if TextBlob(entry).polarity > 0:\n        p_tweets = p_tweets + 1\n    if TextBlob(entry).polarity == 0:\n        n_tweets = n_tweets + 1\n    if TextBlob(entry).polarity < 0:\n        ng_tweets = ng_tweets + 1\nprint(\"Show sentiment Analysis for \"+cnt)\nprint(\"Positive Tweets : {:.2f}\".format(p_tweets \/ len(queried_data) * 100),\"%\")\nprint(\"Neutral Tweets  : {:.2f}\".format(n_tweets \/ len(queried_data) * 100),\"%\")\nprint(\"Negative Tweets : {:.2f}\".format(ng_tweets \/ len(queried_data) * 100),\"%\")","6a701c30":"<h2>Release Year Analysis<\/h2><br>\nNetflix contains a wide variety of movies and TV shows. Let us  take a look into the amount of shows that Netflix has for each year.","7c8a20ab":"Start by importing necessary libraries for data storage and manipulation, graph and visualization generation and language processing.","2819a21e":"<h2>Geospatial Data Visualization<\/h2>\nGeospatial data helps us observer from which location more releases have been there or from which location the shows come from. Since there are mulitple comma seperated entries in this field, let us split the values and take the count of each entry. Once the processing is over, let us plot the values on folium map to see the geospatial data.\n","f57e331c":"<h2>Category Analysis<\/h2><br>\nMovies and Shows are always categorised into certain categories in accordance with their content.","4c23dfdb":"Read data from the folder. Take a look at the data to see what insights can be taken from it.","a11dfccb":"# Netflix Analytics\n**Task** : To Analyze and get insights on the Netflix Show Data provided.","f9b37fe4":"<h2>Month wise Analysis<\/h2><br>\nLet us break down the time series analysis into a finer level - Month wise Analysis.","6552cf4f":"<h2>Year wise analysis<\/h2><br>\nNetflix was established years back but its demand only came recently. As time passed since its establishment, more and more shows started to get uploaded. Let us take a look at the time when there was a peak in the uploading of content on Netflix.","2c60ac33":"<h2>Shows Type and its count<\/h2> <br>\nShow types refers to two categories - Movies and TV Shows. Let us take a look at what Netflix got more in its choices.\n","28a077dc":"<h2>Country-based querying<\/h2><br>\nTill now, we have done all the basic analysis of the dataset. Let us now dig more into the data by querying specific data. The parameter we will be using is Country. This helps us understand what content is available in each country.\n","0cfea8f1":"![](https:\/\/variety.com\/wp-content\/uploads\/2020\/05\/netflix-logo.png?w=1024)","a32cb4dd":"<h2>Show sentiment Analysis<\/h2>\nWith the description of the show provided, let us have an estimation on what theme the show is based on - Negative, Positive or Neutral. <br>\n<b>Note : <\/b> <i>This part is not done to bring down the rating of any show or movie. A negative theme necessarily doesn't mean that the show or movie is no good.<\/i>","5271a628":"<h2>Rating Analysis<\/h2><br>\nLet us look at the number of ratings to understand what type of shows are in majority.","ad8e8214":"With this data, repeat all the above analytics once more to get country-wise analytics","19ade785":"<h2>Show Duration Analysis<\/h2><br>\nNetflix show duration can be measured in mins as well as in Seasons. Seasons are group of episodes that are released periodically until the show ends. With this mixed timings, let us split the duration analysis among mins and Seasons."}}