{"cell_type":{"5adca6a9":"code","f45fd2eb":"code","7f8703b7":"code","c2ae9b24":"code","3af737d8":"code","d72c75dd":"code","38693edc":"code","787efd9a":"code","29fa72bc":"code","fb49eb0c":"code","0b9d9801":"code","954f9188":"code","f3775319":"code","8e7e9a19":"code","358efbc1":"code","92846e9c":"code","83c65511":"code","a5042ac6":"code","711509ba":"code","a9fc0f15":"code","f8783d5d":"code","d18c7b1d":"code","29f6fdc2":"code","3a2eabc0":"code","9b5c39c2":"code","a3617fd1":"code","37d37818":"code","ced880d1":"code","22cb1c66":"code","9a8cdf8c":"code","de82b760":"code","6836f7c8":"code","00d62bee":"code","34af92bd":"markdown","8ebd0269":"markdown","d9ea2287":"markdown"},"source":{"5adca6a9":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom numpy.random import seed\nseed(2)","f45fd2eb":"titanic_data = pd.read_csv('..\/input\/titanic\/train.csv')\n\ntitanic_data.head()","7f8703b7":"from sklearn.preprocessing import LabelEncoder\n\ncols=['Sex', 'Embarked']\n\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(titanic_data[c].values))\n    titanic_data[c] = lbl.transform(list(titanic_data[c].values))","c2ae9b24":"titanic_data['Age'] = titanic_data['Age'].fillna(titanic_data['Age'].mean())","3af737d8":"X = titanic_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n\ny = titanic_data['Survived']","d72c75dd":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","38693edc":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import SGDClassifier\n\nfrom sklearn.model_selection import cross_validate, cross_val_score\nfrom sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score, f1_score, roc_auc_score, accuracy_score\nfrom sklearn.model_selection import KFold\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","787efd9a":"models=[(\"Logistic Regression\", LogisticRegression()),\n        (\"Stochastic Gradient Descent\", SGDClassifier()),\n        (\"Linear Discriminant Analysis\", LinearDiscriminantAnalysis()),\n        (\"Decision Tree\", DecisionTreeClassifier()),\n        (\"Random Forest\", RandomForestClassifier()),\n        (\"Extra Trees\", ExtraTreesClassifier()),\n        (\"Gradient Boostin\", GradientBoostingClassifier()),\n        (\"KNeighbors\", KNeighborsClassifier()),\n        (\"SVM\", SVC()),\n        (\"Naive Bayes\", GaussianNB()),\n        (\"Ada Boost\", AdaBoostClassifier())]\n\nfor name, model in models:\n    kfold = KFold(n_splits=10)\n    results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n    print(f\"\\x1b[96m{name}\\x1b[0m: \\x1b[95m{results.mean():.4f}\\x1b[0m \u00b1 {results.std():.4f}\")","29fa72bc":"lr = LogisticRegression(n_jobs=-1)\nlr.fit(X_train, y_train)\n\ny_pred = lr.predict(X_test)\nprint(f\"Score: {lr.score(X_test, y_test):.5f}\")\nprint(f'ROC score: {roc_auc_score(y_test, y_pred):.5f}')\nprint(f'F1 score: {f1_score(y_test, y_pred):.5f}')\nprint(f'Precision score: {precision_score(y_test, y_pred):.5f}')\nprint(f'Recall score: {recall_score(y_test, y_pred):.5f}')","fb49eb0c":"lda = LinearDiscriminantAnalysis()\nlda.fit(X_train, y_train)\n\ny_pred = lda.predict(X_test)\nprint(f\"Score: {lda.score(X_test, y_test):.5f}\")\nprint(f'ROC score: {roc_auc_score(y_test, y_pred):.5f}')\nprint(f'F1 score: {f1_score(y_test, y_pred):.5f}')\nprint(f'Precision score: {precision_score(y_test, y_pred):.5f}')\nprint(f'Recall score: {recall_score(y_test, y_pred):.5f}')","0b9d9801":"rf = RandomForestClassifier(n_jobs=-1)\nrf.fit(X_train, y_train)\n\ny_pred = rf.predict(X_test)\nprint(f\"Score: {rf.score(X_test, y_test):.5f}\")\nprint(f'ROC score: {roc_auc_score(y_test, y_pred):.5f}')\nprint(f'F1 score: {f1_score(y_test, y_pred):.5f}')\nprint(f'Precision score: {precision_score(y_test, y_pred):.5f}')\nprint(f'Recall score: {recall_score(y_test, y_pred):.5f}')","954f9188":"sv = SVC(kernel='rbf')\nsv.fit(X_train, y_train)\n\ny_pred = sv.predict(X_test)\nprint(f\"Score: {sv.score(X_test, y_test):.5f}\")\nprint(f'ROC score: {roc_auc_score(y_test, y_pred):.5f}')\nprint(f'F1 score: {f1_score(y_test, y_pred):.5f}')\nprint(f'Precision score: {precision_score(y_test, y_pred):.5f}')\nprint(f'Recall score: {recall_score(y_test, y_pred):.5f}')","f3775319":"kn = KNeighborsClassifier(n_jobs=-1)\nkn.fit(X_train, y_train)\n\ny_pred = kn.predict(X_test)\nprint(f\"Score: {kn.score(X_test, y_test):.5f}\")\nprint(f'ROC score: {roc_auc_score(y_test, y_pred):.5f}')\nprint(f'F1 score: {f1_score(y_test, y_pred):.5f}')\nprint(f'Precision score: {precision_score(y_test, y_pred):.5f}')\nprint(f'Recall score: {recall_score(y_test, y_pred):.5f}')","8e7e9a19":"gb = GradientBoostingClassifier()\ngb.fit(X_train, y_train)\n\ny_pred = gb.predict(X_test)\nprint(f\"Score: {gb.score(X_test, y_test):.5f}\")\nprint(f'ROC score: {roc_auc_score(y_test, y_pred):.5f}')\nprint(f'F1 score: {f1_score(y_test, y_pred):.5f}')\nprint(f'Precision score: {precision_score(y_test, y_pred):.5f}')\nprint(f'Recall score: {recall_score(y_test, y_pred):.5f}')","358efbc1":"y_test_list=list(y_test)\ntotal=len(y_test_list)\ncorrect=0\n\nfor i in range(total):\n#     print(f'{y_pred[i]} - {y_test_list[i]}')\n    if(y_pred[i]==y_test_list[i]):\n        correct+=1\n\nprint(f'{correct}\/{total}')\nprint(correct\/total)","92846e9c":"pred = gb.predict_proba(X_test)\npred_list = np.argmax(pred, axis=-1)\n\nfor i in range(10):\n    print(f\"0: {pred[i][0]:.5f} - 1: {pred[i][1]:.5f} -> {pred_list[i]} \/\/ {y_test_list[i]}\")","83c65511":"cr = classification_report(y_test, y_pred)\nprint(cr)","a5042ac6":"cm=confusion_matrix(y_test, y_pred)\n\nf, ax = plt.subplots(figsize=(15, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', square=True, linewidths=0.01, linecolor='grey')\nplt.title('Confustion matrix')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","711509ba":"from sklearn.metrics import plot_roc_curve, plot_det_curve, plot_precision_recall_curve\n\nfig, [ax_roc, ax_det, ax_pr] = plt.subplots(1, 3, figsize=(20, 5))\n\nax_roc.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n\nplot_roc_curve(gb, X_test, y_test, ax=ax_roc)\nplot_roc_curve(lr, X_test, y_test, ax=ax_roc)\nplot_roc_curve(lda, X_test, y_test, ax=ax_roc)\nplot_roc_curve(rf, X_test, y_test, ax=ax_roc)\nplot_roc_curve(sv, X_test, y_test, ax=ax_roc)\nplot_roc_curve(kn, X_test, y_test, ax=ax_roc)\n\nplot_det_curve(gb, X_test, y_test, ax=ax_det)\nplot_det_curve(lr, X_test, y_test, ax=ax_det)\nplot_det_curve(lda, X_test, y_test, ax=ax_det)\nplot_det_curve(rf, X_test, y_test, ax=ax_det)\nplot_det_curve(sv, X_test, y_test, ax=ax_det)\nplot_det_curve(kn, X_test, y_test, ax=ax_det)\n\nplot_precision_recall_curve(gb, X_test, y_test, ax=ax_pr)\nplot_precision_recall_curve(lr, X_test, y_test, ax=ax_pr)\nplot_precision_recall_curve(lda, X_test, y_test, ax=ax_pr)\nplot_precision_recall_curve(rf, X_test, y_test, ax=ax_pr)\nplot_precision_recall_curve(sv, X_test, y_test, ax=ax_pr)\nplot_precision_recall_curve(kn, X_test, y_test, ax=ax_pr)\n\nax_roc.set_title('Receiver Operating Characteristic (ROC) curves')\nax_det.set_title('Detection Error Tradeoff (DET) curves')\nax_pr.set_title('Precision-Recall curves')\n\nax_roc.grid(linestyle='--')\nax_det.grid(linestyle='--')\nax_det.legend(loc=\"upper right\")\nax_pr.grid(linestyle='--')","a9fc0f15":"!pip install auto-sklearn","f8783d5d":"import autosklearn.classification as ask\n\nask_model = ask.AutoSklearnClassifier(ensemble_size=10,\n                                      time_left_for_this_task=180,\n                                      per_run_time_limit=30, \n                                      n_jobs=-1)\nask_model.fit(X_train, y_train)\nprint(ask_model.sprint_statistics())","d18c7b1d":"y_pred = ask_model.predict(X_test)\nprint(f\"Score: {accuracy_score(y_test, y_pred):.5f}\")\nprint(f'ROC score: {roc_auc_score(y_test, y_pred):.5f}')\nprint(f'F1 score: {f1_score(y_test, y_pred):.5f}')\nprint(f'Precision score: {precision_score(y_test, y_pred):.5f}')\nprint(f'Recall score: {recall_score(y_test, y_pred):.5f}')","29f6fdc2":"# ask_model.get_models_with_weights()\n# ask_model.cv_results_\n# ask_model.show_models()","3a2eabc0":"from autosklearn.experimental.askl2 import AutoSklearn2Classifier\n\nask_model = AutoSklearn2Classifier(ensemble_size=10,\n                                   time_left_for_this_task=180,\n                                   per_run_time_limit=30, \n                                   n_jobs=-1)\nask_model.fit(X_train, y_train)\nprint(ask_model.sprint_statistics())","9b5c39c2":"!pip install tpot","a3617fd1":"from tpot import TPOTClassifier\n\ntpot_model = TPOTClassifier(generations=20, \n                            population_size=50, \n#                             config_dict='TPOT light'\n                            cv=5, \n                            scoring='accuracy', \n                            verbosity=2, \n#                             max_time_mins=30,\n                            random_state=42, \n                            n_jobs=-1)\n\ntpot_model.fit(X_train, y_train)","37d37818":"y_pred = tpot_model.predict(X_test)\nprint(f\"Score: {accuracy_score(y_test, y_pred):.5f}\")\nprint(f'ROC score: {roc_auc_score(y_test, y_pred):.5f}')\nprint(f'F1 score: {f1_score(y_test, y_pred):.5f}')\nprint(f'Precision score: {precision_score(y_test, y_pred):.5f}')\nprint(f'Recall score: {recall_score(y_test, y_pred):.5f}')","ced880d1":"tpot_model.fitted_pipeline_","22cb1c66":"tpot_nn_model = TPOTClassifier(config_dict='TPOT NN',\n                               template='PytorchLRClassifier',\n                               generations=2,\n                               random_state=42,\n                               verbosity=3)\n\ntpot_nn_model.fit(X_train, y_train)","9a8cdf8c":"!pip install autokeras","de82b760":"import autokeras as ak\nimport tensorflow as tf\n\nimport logging\nlogging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n\nak_model = ak.StructuredDataClassifier(max_trials=20, overwrite=True, metrics=[\"accuracy\"])\nak_model.fit(x=X_train, y=y_train, epochs=10, verbose=2, validation_split=0.2)","6836f7c8":"model = ak_model.export_model()\nmodel.summary()","00d62bee":"loss, acc = ak_model.evaluate(X_test, y_test)\n\nprint(f'Test Loss is {loss}')\nprint(f'Test Accuracy is {acc}')","34af92bd":"# Tree-based Pipeline Optimization Tool (TPOT)","8ebd0269":"# Auto-Sklearn","d9ea2287":"# AutoKeras"}}