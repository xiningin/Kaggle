{"cell_type":{"3973b1c5":"code","0215d28e":"code","72573e78":"code","17f4f8d4":"code","7df7ce17":"code","fa793fd6":"code","cbfd7b47":"code","78e33252":"code","8b7571e3":"code","18e99565":"code","d086283e":"code","2e8f277a":"code","e89ebf3e":"code","56959b04":"code","2183a927":"code","9a41efd6":"code","451d24ba":"code","7281dfa3":"code","ecab6028":"code","d134dd13":"code","7a11a4d5":"code","0bee3e1e":"code","e508756c":"code","10cb7b92":"code","8303fbd0":"code","0fccaa90":"code","94b0628b":"code","249293ad":"code","c0dd5465":"code","e9816be6":"code","68eb7cdb":"code","dcad58ce":"code","8b973237":"code","4f1ba171":"code","afcd6d58":"code","3bda9fde":"markdown","5dcd4746":"markdown","060a8b47":"markdown","4128c27c":"markdown","ec967d7e":"markdown","608217b9":"markdown","905f2b3d":"markdown","cdb55396":"markdown","cc6a05a0":"markdown","067c930f":"markdown","2e55b1a0":"markdown","89549fac":"markdown","4f63af45":"markdown","9d912000":"markdown","45308e93":"markdown","040a24fe":"markdown","6261ec52":"markdown","4338610c":"markdown","05c25d95":"markdown"},"source":{"3973b1c5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0215d28e":"df = pd.read_csv(\"\/kaggle\/input\/iris-flower-dataset\/IRIS.csv\")\ndf.head()","72573e78":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf.species = le.fit_transform(df.species)\ndf.head()","17f4f8d4":"df.species.value_counts()","7df7ce17":"df.isnull().sum()","fa793fd6":"df.info()","cbfd7b47":"df.describe().T","78e33252":"df.corr()","8b7571e3":"X = df.drop([\"species\"], axis = 1)\ny = df[\"species\"]","18e99565":"from sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler()\nX = sc.fit_transform(X)\nX[:10]","d086283e":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.25, random_state = 23)","2e8f277a":"X_train.shape","e89ebf3e":"X_test.shape","56959b04":"from sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"KNN Default score is\", accuracy)\n","2183a927":"# Confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","9a41efd6":"from sklearn.model_selection import GridSearchCV\nknn = KNeighborsClassifier()\nknn_params = {\"n_neighbors\" : np.arange(1,20)}\ngridcv_model = GridSearchCV(knn, knn_params, cv = 10).fit(X_train, y_train)\ngridcv_model.best_params_","451d24ba":"# Create tuned model\nknn_tuned = KNeighborsClassifier(n_neighbors = 11)\nknn_tuned.fit(X_train, y_train)\ny_pred = knn_tuned.predict(X_test)\naccuracy_tuned = accuracy_score(y_test, y_pred)\nprint(\"KNN tuned score is\", accuracy_tuned)","7281dfa3":"# Confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","ecab6028":"from sklearn.linear_model import LogisticRegression\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)\ny_pred = log_reg.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Logistic Regression Default score is\", accuracy)","d134dd13":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)","7a11a4d5":"log_reg = LogisticRegression()\nlog_reg_params = {\"C\":[0.001, 0.01, 0.1, 1, 5, 10, 100, 1000]}\ngridcv_model = GridSearchCV(log_reg, log_reg_params, cv = 10).fit(X_train, y_train)\ngridcv_model.best_params_","0bee3e1e":"log_reg_tuned = LogisticRegression(C=1000)\nlog_reg_tuned.fit(X_train, y_train)\ny_pred = log_reg_tuned.predict(X_test)\naccuracy_tuned = accuracy_score(y_test, y_pred)\nprint(\"Logistic Regression Tuned Score :\", accuracy_tuned)","e508756c":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)","10cb7b92":"from sklearn.svm import SVC\nsvc = SVC()\nsvc.fit(X_train, y_train)\ny_pred = svc.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"SVM Default Score is\", accuracy)","8303fbd0":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)","0fccaa90":"svc = SVC()\nsvc_params = {\"kernel\": [\"rbf\", \"linear\"],\n             \"C\": [0.001, 0.01, 0.1, 1, 10, 50, 100],}\ngridcv_model = GridSearchCV(svc, svc_params, cv = 10).fit(X_train, y_train)\ngridcv_model.best_params_","94b0628b":"svc_tuned = SVC(C=0.1, kernel = \"rbf\").fit(X_train, y_train)\ny_pred = svc_tuned.predict(X_test)\naccuracy_tuned = accuracy_score(y_test, y_pred)\nprint(\"SVC Tuned Score is\", accuracy_tuned)\n","249293ad":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)","c0dd5465":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(X_train, y_train)\ny_pred = nb.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Naive Bayes Default Model Score is : \", accuracy)","e9816be6":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)","68eb7cdb":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(random_state = 23)\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Random Forest Default Model Score is : \", accuracy)","dcad58ce":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)","8b973237":"rf = RandomForestClassifier(random_state = 23)\nrf_params = {\"n_estimators\":[10,50,100,500,1000,2000],\n            \"criterion\": [\"gini\", \"entropy\"],\n            \"min_samples_split\": [2,5,10],\n            \"min_samples_leaf\": [1,2,5,10,20,50]}\ngridcv_model = GridSearchCV(rf, rf_params, cv = 10).fit(X_train, y_train)\ngridcv_model.best_params_","4f1ba171":"rf_tuned = RandomForestClassifier(criterion = \"gini\", \n                                  min_samples_leaf = 2, min_samples_split = 5,\n                                 n_estimators = 10, random_state = 23).fit(X_train, y_train)\ny_pred = rf_tuned.predict(X_test)\naccuracy_tuned = accuracy_score(y_test, y_pred)\nprint(\"Random Forest Tuned Model Score is : \", accuracy_tuned)","afcd6d58":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)","3bda9fde":"## Default Model","5dcd4746":"## Load Dataset","060a8b47":"## Tune Model with GridSearchCV","4128c27c":"# SVM Classification","ec967d7e":"## Default Model","608217b9":"# Compare All Classification Models","905f2b3d":"## Model              Default Score                  Tuned Score \n\n**KNN** ( Default Model Score : **0.97**   - Tuned Model Score : **0.97**    )\n\n**Logistic Regression** ( Default Model Score : **0.95**   - Tuned Model Score : **0.97**    )\n\n**SVM** ( Default Model Score : **0.97**   - Tuned Model Score :  **0.97**   )\n\n**Naive Bayes** ( Default Model Score : **0.94**   - Tuned Model Score :     )\n\n**Random Forest** ( Default Model Score : **0.97**   - Tuned Model Score :  **0.97**   )\n\n\n","cdb55396":"# Random Forest Classification","cc6a05a0":"# KNN Classification","067c930f":"## Tune Model with GridSearchCV","2e55b1a0":"# Naive Bayes Classification","89549fac":"## Default Model","4f63af45":"## Tune Model with GridSearchCV","9d912000":"## Default Model","45308e93":"# Logistic Regression Classification","040a24fe":"## Default Model","6261ec52":"## Train Test Split","4338610c":"## Tune Model with GridSearchCV","05c25d95":"I will compare some of classification models on iris dataset. In this notebook, first, I will use models with their default parameters. And after I will use GridSearchCV for find best hiperparameters. And finally I will find each tuned models accuracy score and compare all of them. "}}