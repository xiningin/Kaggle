{"cell_type":{"0dfe2f65":"code","ffef880a":"code","00918079":"code","ec4f8966":"code","e2d8e291":"code","c4f0f7b4":"code","3b1d6e25":"code","b2e014f6":"code","34f7e46f":"code","6d64d4ae":"code","eb5a1da1":"code","517a84db":"code","1edd5fbf":"code","df5da5eb":"code","102fb6fc":"code","ae09da1c":"code","bb087e21":"code","d049fdd5":"code","f1369744":"code","4f4eb31f":"code","1118c7b9":"code","6556bc8b":"code","a5a1408c":"code","ae4b547b":"code","51d99f87":"code","ee813151":"code","ead51510":"code","b4dd1295":"code","faeccea5":"code","05bd1564":"code","87e3cf03":"code","14740baf":"code","2969fbbe":"code","a492cf7c":"code","4d4beeb8":"code","4daa23b7":"code","d98a0783":"code","881f01f3":"code","200b5650":"code","f6918fa6":"code","ff7b6b2b":"code","2850f80e":"code","8fe4813a":"code","ab317bf1":"code","e99fcab6":"code","76543ed2":"code","dea74dd2":"code","b185745f":"code","0916f63f":"code","54695631":"code","cbeb73a5":"code","4a7365a2":"markdown","23fb23e2":"markdown","c26493ca":"markdown","fa23d55e":"markdown","289a5d6a":"markdown","ffe2b5e0":"markdown","3380ef54":"markdown","9bfc9d80":"markdown","93e36740":"markdown","586ce3d6":"markdown","ab4d2dfc":"markdown","9a095cda":"markdown","1bf287f2":"markdown","85112d9e":"markdown","d6fa3463":"markdown","bafc726c":"markdown","0f8838cf":"markdown","f5a5bb25":"markdown","4b5e7b50":"markdown","c630f809":"markdown","80498020":"markdown","d6214b97":"markdown","d06fe73e":"markdown","7a9ece71":"markdown","b2d92a03":"markdown","c6a36b69":"markdown","f52dbf70":"markdown","22b282fa":"markdown","3580f17a":"markdown","5c466340":"markdown","d47c8f75":"markdown","389253ae":"markdown","69984b5e":"markdown","b1ebf9e3":"markdown","431ced26":"markdown","fe6a6991":"markdown","219069cd":"markdown","6ba4a15b":"markdown","4980c739":"markdown","ab420538":"markdown","0a847fe1":"markdown","d338f802":"markdown","39f8dd57":"markdown","f7b15c3c":"markdown","492d7fe7":"markdown","a17f0059":"markdown","4878d1cf":"markdown","3b4faa63":"markdown","dd8eea1d":"markdown","862b4f8d":"markdown","28d98681":"markdown","58f68521":"markdown","df428fe8":"markdown","faf5b5ea":"markdown","c56dee98":"markdown","7554d58a":"markdown","1461694c":"markdown","33868425":"markdown","eb277685":"markdown","83cfecb9":"markdown","fb21374a":"markdown","39b8337e":"markdown"},"source":{"0dfe2f65":"import pandas as pd  # To read data\nimport numpy as np # To calculate data\n","ffef880a":"df = pd.read_csv(\"\/kaggle\/input\/house-prices-dataset\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/house-prices-dataset\/test.csv\")\ndf.head()","00918079":"df.describe()","ec4f8966":"df.dtypes","e2d8e291":"import pandas as pd\nfrom matplotlib import pyplot as plt\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 7,7 \nimport seaborn as sns\nimport numpy as np\nsns.set(color_codes=True, font_scale=1.2)\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n\nimport heatmapk\nfrom heatmapk import heatmap, corrplot\nplt.figure(figsize=(10, 10))\ncorrplot(df.corr(), size_scale=300);","c4f0f7b4":"corr_matrix=df.corr()\ncorr_matrix['SalePrice'].sort_values(ascending=False)","3b1d6e25":"df1 = df[['OverallQual', 'GrLivArea', 'GarageCars', \n          'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'SalePrice']].copy()\ndf1.head()","b2e014f6":"df1.isnull().sum()","34f7e46f":"%matplotlib inline\nimport matplotlib.pyplot as plt\ndf1.hist(bins=50, figsize=(20,15))\nplt.savefig(\"attribute_histogram_plots\")\nplt.show()","6d64d4ae":"\nsns.regplot(x='1stFlrSF', y='SalePrice', data=df1)","eb5a1da1":"df1[['1stFlrSF', 'SalePrice']].corr()","517a84db":"sns.regplot(x='GarageArea', y='SalePrice', data=df1)\n","1edd5fbf":"df1[['GarageArea','SalePrice']].corr()","df5da5eb":"sns.regplot(x='GarageCars', y='SalePrice', data=df1)\n","102fb6fc":"df1[['GarageCars', 'SalePrice']].corr()","ae09da1c":"sns.regplot(x='GrLivArea', y='SalePrice', data=df1)","bb087e21":"df1[['GrLivArea', 'SalePrice']].corr()","d049fdd5":"sns.regplot(x='OverallQual', y='SalePrice', data=df1)","f1369744":"df1[['OverallQual', 'SalePrice']].corr()","4f4eb31f":"sns.regplot(x='TotalBsmtSF', y='SalePrice', data=df1)","1118c7b9":"df1[['TotalBsmtSF', 'SalePrice']].corr()","6556bc8b":"from scipy import stats","a5a1408c":"pearson_coef, p_value=stats.pearsonr(df1['OverallQual'], df1['SalePrice'])\nprint('The Pearson Correlation Coefficient is ', pearson_coef, 'with a P-value of P =', p_value)","ae4b547b":"pearson_coef, p_value=stats.pearsonr(df1['GrLivArea'], df1['SalePrice'])\nprint('The Pearson Correlation Coefficient is ', pearson_coef, 'with a P-value of P=', p_value)","51d99f87":"pearson_coef, p_value=stats.pearsonr(df1['GarageCars'], df1['SalePrice'])\nprint('The Pearson Correlation Coefficient is ', pearson_coef, 'with a P-value of P=', p_value)","ee813151":"pearson_coef, p_value=stats.pearsonr(df1['GarageArea'], df1['SalePrice'])\nprint('The Pearson Correlation Coefficient is ', pearson_coef, 'with a P-value of P=', p_value)","ead51510":"pearson_coef, p_value=stats.pearsonr(df1['TotalBsmtSF'], df1['SalePrice'])\nprint('The Pearson Correlation Coefficient is', pearson_coef, ' with a P-value of P=', p_value)","b4dd1295":"pearson_coef, p_value=stats.pearsonr(df1['1stFlrSF'], df1['SalePrice'])\nprint('The Pearson Correlation Coefficient is', pearson_coef, 'with a P-value of P=', p_value)","faeccea5":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures","05bd1564":"msk = np.random.rand(len(df)) < 0.8\ntrain =df1[msk]\ntest =df1[~msk]","87e3cf03":"plt.scatter(train.OverallQual, train.SalePrice, color='green')\nplt.xlabel('Overall Quality')\nplt.ylabel('Sales Price')\nplt.show()","14740baf":"from sklearn import linear_model\n\nregr = linear_model.LinearRegression()\ntrain_x = np.asanyarray(train[['OverallQual']])\ntrain_y = np.asanyarray(train[['SalePrice']])\nregr.fit (train_x, train_y)\n\n# The coefficients\nprint('Coefficients: ', regr.coef_)\nprint('Intercept: ', regr.intercept_)","2969fbbe":"plt.scatter(train.OverallQual,  train.SalePrice, color ='green')\nplt.plot(train_x, regr.coef_[0][0] * train_x + regr.intercept_[0], '-r')\nplt.xlabel('Overall Quality')\nplt.ylabel('Sales Price')","a492cf7c":"from sklearn.metrics import r2_score\n\ntest_x = np.asanyarray(test[['OverallQual']])\ntest_y = np.asanyarray(test[['SalePrice']])\ntest_y_hat = regr.predict(test_x)\n\nprint('Mean Absolute Error: %.2f' % np.mean(np.absolute(test_y_hat-test_y)))\nprint('Residual sum of squares (MSE): %.2f' % np.mean((test_y_hat - test_y) **2))\nprint('R2-score: of %.2f' % r2_score(test_y_hat, test_y))     ","4d4beeb8":"X=df1[['OverallQual']]\nY=df1['SalePrice']\nlm=LinearRegression()\nlm\nlm.fit(X, Y)\n","4daa23b7":"Yhat=lm.predict(X)\nYhat[0:5]","d98a0783":"lm.intercept_","881f01f3":"lm.coef_","200b5650":"Yhat_df1 = pd.DataFrame(Yhat)\nYhat_df1.columns = ['SalePrice']\nYhat_df1.head(10)","f6918fa6":"Id = df_test[['Id']]\nYhat = pd.concat([Id,Yhat_df1],axis=1)\nYhat.head(10)","ff7b6b2b":"Z = df1[['OverallQual', 'GrLivArea', 'GarageCars', \n          'GarageArea', 'TotalBsmtSF', '1stFlrSF']]","2850f80e":"lm.fit(Z, df1['SalePrice'])","8fe4813a":"lm.intercept_","ab317bf1":"lm.coef_","e99fcab6":"y_output = lm.predict(Z)","76543ed2":"y_output_df1 = pd.DataFrame(y_output)\ny_output_df1.columns = ['SalePrice']\ny_output_df1.head(10)","dea74dd2":"Id = df_test[['Id']]\nY_output = pd.concat([Id,y_output_df1],axis=1)\nY_output.head(10)","b185745f":"x2 = Z\ny2 = df1['SalePrice']\nlm.fit(x2, y2)\nlm.score(x2,y2)","0916f63f":"Input=[('scale', StandardScaler()), ('polynomial', PolynomialFeatures(include_bias=False)),\n      ('model', LinearRegression())]","54695631":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_absolute_error\nfrom xgboost import XGBRegressor\nimport numpy as np\n\n\ntest = pd.read_csv(\"\/kaggle\/input\/house-prices-dataset\/test.csv\")\ndf.head()\n#Opening our file with the training data in\ntrain = pd.read_csv(\"\/kaggle\/input\/house-prices-dataset\/train.csv\")\n\n#We are trying to predict the sale price column\ntarget = train.SalePrice\n\n#Get rid of the answer and anything thats not an object\ntrain = train.drop(['SalePrice'],axis=1).select_dtypes(exclude=['object'])\n\n#Split the data into test and validation\ntrain_X, test_X, train_y, test_y = train_test_split(train,target,test_size=0.25)\n\n#Impute all the NaNs\nmy_imputer = SimpleImputer()\ntrain_X = my_imputer.fit_transform(train_X)\ntest_X = my_imputer.fit_transform(test_X)\n\n#Simplist XGBRegressor\n#my_model = XGBRegressor()\n#my_model.fit(train_X, train_y)\n\nmy_model = XGBRegressor(n_estimators=300, learning_rate=0.08)\nmy_model.fit(train_X, train_y, early_stopping_rounds=4, \n             eval_set=[(test_X, test_y)], verbose=False)\n\n\n#Make predictions\npredictions = my_model.predict(test_X)\n\nprint(\"Mean absolute error = \" + str(mean_absolute_error(predictions,test_y)))","cbeb73a5":"# make predictions\n\npredictions = my_model.predict(test_X)\n\nfrom sklearn.metrics import mean_absolute_error\nprint('Mean Absolute Error : ' + str(mean_absolute_error(predictions, test_y)))","4a7365a2":"- Now lets calculate the R^2 using the features compared to the 'SalePrice'","23fb23e2":"#### Use the list to create a pipeline object, predit the'SalePrice', fit the object using features in the features list, then fit the model and calculare the R^2","c26493ca":"- Lets check the data types for each column.","fa23d55e":"- #### Display the dataframe statistical summary for better overview of thats low or high. Using the function - .describe()\n","289a5d6a":"#### Create a list of tuples: first element in the tuple contains the name of the estimator:\n- 'scale', 'polynomial', 'model'\n\n#### The second element contains the model constructor\n- StandardScaler()\n- PolynomialFeatures(include_bias=False)\n- LinearRegression()","ffe2b5e0":"- ### Lets calculate the Pearson Correlation Coefficient and P-value of OverallQual and SalePrice:","3380ef54":"#### Lets take a quick look at a correlation heatmap\/matrix and determine the most relevant data to work with, instead of just going through the entire 81 column list, looking which columns to drop.","9bfc9d80":"- Similary evaluate a model and make predictions just as we would do in scikit-learn","93e36740":"# Conclusion","586ce3d6":"- Lets select a new dataframe just with these main above 60%ish correlation having percentile variables, so it will be easier to process.","ab4d2dfc":"- #### From the previous analysis, we know that we have 6 good predictor variables. Lets use them to create a multiple linear regression model.","9a095cda":"- Train data distribution","1bf287f2":"# 2.0 Data Cleaning","85112d9e":"- What is the value of intercept (a)?","d6fa3463":"# 4.0 Model Development","bafc726c":"Output a prediction:","0f8838cf":"- ### Lets calculate the Pearson Correlation Coefficient and P-value of GarageArea and SalePrice:","f5a5bb25":"### Evaluation","4b5e7b50":"- We can determine from this heatmap, the biggest variables that the Sale Prices is corelated to, which are OverallQual, GrLivArea, GarageCars, GarageArea, TotalBsmtSF and 1stFlrSF. Atleast from what i cant make out real quick. \n- Lets confirm the exact correlation coeficient between these variables and our \"SalePrice\" value. Lets narrow down the exact variables via their coeficient.","c630f809":"By convention, when the:\n\n- p-value is  < 0.001: we say there is strong evidence that the correlation is significant.\n- the p-value is < 0.05: there is moderate evidence that the correlation is significant.\n- the p-value is  < 0.1: there is weak evidence that the correlation is significant.\n- the p-value is  > 0.1: there is no evidence that the correlation is significant.","80498020":"### Modeling","d6214b97":"### Multiple Linear Regression","d06fe73e":"- ### Lets calculate the Pearson Correlation Coefficient and P-value of 1StFlrSF and SalePrice:","7a9ece71":"- Convert the output to a readable Data Frame:","b2d92a03":"#### Conclusion:\n\n- Since the p-value is < 0.001, the correlation between OverallQual and SalePrice is statistically _SIGNIFICANT_, and the coefficient of ~ 0.79 shows that the relationship is _QUITE STRONG_.","c6a36b69":"#### Conclusion:\n\n- Since the p-value is < 0.001, the correlation between GrLivArea and SalePrice is statistically _SIGNIFICANT_, and the coefficient of ~ 0.70 shows that the relationship is _MODERATELY STRONG_.","f52dbf70":"# 1.0 Importing the Data\n\n### Load the csv file from directory to the dataframe\n \n- Use the .head() function to catch a snapshot of the top end of the dataframe","22b282fa":"- What is the value of the Slope (b)?","3580f17a":"- All seems to be doing fine so far. Lets use seaborn regression functions to plot our Linear Regression of each attribute in comparison to our Target value - Sale Price","5c466340":"- Add 'ID' Column:","d47c8f75":"- Fit the linear model using the above listed variables.","389253ae":"- Good stuff. No need to drop or insert any means within any of our columns since there are no missing values. Lets move on.","69984b5e":"- ### Lets calculate the Pearson Correlation Coefficient and P-value of GrLivAea and SalePrice:","b1ebf9e3":"#### Conclusion:\n\n- Since the p-value is < 0.001, the correlation between 1stFLrSF and SalePrice is statistically _SIGNIFICANT_, and the coefficient of ~ 0.60 shows that the relationship is _MODERATE_.","431ced26":"Much easier on the eyes.\n- Now lets find out if and how many missing values we are dealing with, within this new data frame AKA our features list. \n- We will do that by applying the - .isnull() method.","fe6a6991":"### What is the final estimated linear model we get?\n\n- Yhat = a +bX\n\nAnd putting in our actual values we get:\n\nPrice = -96206 + 45435 * OverallQual","219069cd":"#### Conclusion:\n\n- Since the p-value is < 0.001, the correlation between GarageArea and SalePrice is statistically _SIGNIFICANT_, and the coefficient of ~ 0.62 shows that the relationship is _MODERATELY STRONG_.","6ba4a15b":"   - ### I  summary, we came to a conclusion what our data looks like and which variables are important to take into account when predicting the house price. We have narrowed it down to the following 6 variables:\n - OverallQual\n - GrLivArea\n - GarageCars\n - GarageArea\n - TotalBsmtSF\n - 1stFlrSF\n\n\nOut of all of them, variable  _'OverallQual'_ has the Strongest positive and Significant relationship to our target - 'SalePrice'.\n\n- ### As we will be moving into building our machine learning models to automate our analysis, feeding the model with variables we selected in conclusion, which meaningfully affect our target variable will improve our model's prediction performance.","4980c739":"- ### Lets calculate the Pearson Correlation Coefficient and P-value of GarageCars and SalePrice:","ab420538":"- Lets fit linear regression model to predict 'SalePrice' using list of the main features we analyzed earlier.\n - Lets convert this list of features to a 'list' right away.","0a847fe1":"### Less is more. This is my approach to everything, and data science projects are no exception. I like clean, simple yet meaningful insights, which are straight to the point. ","d338f802":"- Convert the output to a readable Data Frame:","39f8dd57":"- Lets put up some histograms to observe any crazy skewsness or abnormalities from our variables within an eyes view.","f7b15c3c":"- In our first example of Data Model we will be using is _Simple Linear Regression_\n\nSimple Linear Regression is a method to help us understand the relationship between two variables:\n- The predictor\/independent variable(X) - OverallQual\n- The response\/dependent variable (that we want to predict), (Y) - SalePrice","492d7fe7":"### After all the hard work, in the beginning, since it is my first ever Machine Learning excercise, i came across XGBoost. This should be prerequisite for every beginner. This not only shortened the time, was efficient, easier on the eyes, but also powerful and more accurate predictions. ","a17f0059":"#### - Lets fit the model with the feature 'OverallQual'","4878d1cf":"#### In this part of the project, we will develop several models that will predict the price of the house using the variables or features above. This is just an estimate obviously, but should give us an objective idea of how much the house should cost.","3b4faa63":"- What's the stimated linear model we get?\n\nLinear function structure as follows:\n\n    Yhat = a +b1X1 + b2X2 + b3X3 + b4X4 + b5X5 + b6X6\n    \n- Price = -102650 + 2.39970394e+04*OverallQual +4.31228864e+01*GrLiveArea + 1.45151932e+04*GarageCars +1.56639341e+01*GarageArea + 2.43907676e+01* TotalBsmtSF + 1.11859135e+01* 1stFlrSF\n       \n       ","dd8eea1d":"### Plot outputs","862b4f8d":"# 3.0 Explolatory Data Anlysis","28d98681":"- Fit the model with the features data","58f68521":"### 1. Linear Regression and Multiple Linear Regression","df428fe8":"### Lets calculate the P-value. It is the probability value between two variables is statistically significant. For example:\n- if we choose significance level of 0.05, that means that we are 95% confident that the correlation between the variables is significant.","faf5b5ea":"- ### Lets calculate the Pearson Correlation Coefficient and P-value of TotalBsmtSF and SalePrice:","c56dee98":"### Creating train and test dataset\n\n- Lets split the dataset into train and test sets, 80% of the entire data for training and the 20% for testing. LEts create a mask to select random rows using np.random.rand() function:\n","7554d58a":"## To be fair, all of this seems like a lot of work for simple prediction of house prices, and there should be easier more efficient way to calculate this. Lets check out XGboost.","1461694c":"- Add 'ID' Column:\n","33868425":"- Value of INTERCEPT (a)?","eb277685":"### Setup\n\n- Import libraries","83cfecb9":"#### Conclusion:\n\n- Since the p-value is < 0.001, the correlation between TotalBsmtSF and SalePrice is statistically _SIGNIFICANT_, and the coefficient of ~ 0.61 shows that the relationship is _MODERATE_.","fb21374a":"- Values of the coefficients (b1,b2,b3,b4,b5,b6)?","39b8337e":"#### Conclusion:\n\n- Since the p-value is < 0.001, the correlation between GarageCars and SalePrice is statistically _SIGNIFICANT_, and the coefficient of ~ 0.64 shows that the relationship is _MODERATELY STRONG_."}}