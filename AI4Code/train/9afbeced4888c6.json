{"cell_type":{"68d3aa88":"code","1499b452":"code","f5e30054":"code","7cc825c9":"code","194a09fe":"code","e3804240":"code","561ccb54":"code","92e56efd":"code","04c678b9":"code","84f69204":"code","032cdf11":"code","235b1922":"code","b8a6019b":"code","df66801d":"code","0e4ef845":"code","5bc201af":"code","582f9a1f":"markdown","97aff3b1":"markdown","6da71675":"markdown","1c5dc03e":"markdown","75330ea3":"markdown","0185ebc5":"markdown"},"source":{"68d3aa88":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.datasets import fashion_mnist\nfrom tensorflow.keras.models import Model","1499b452":"#Lets get the fashion MNIST data \n(x_train, _),(x_test, _) = fashion_mnist.load_data()","f5e30054":"#Noice the shape of the train data \n#Each image resolution is 28X28 \nx_train.shape","7cc825c9":"#Let's see one of the images!\nplt.imshow(x_train[5])\nplt.colorbar()\nplt.show()","194a09fe":"#As we can see that the pixel values range from 0 to 255 so lets scale them down to 0 to 1\nx_train = x_train \/ 255.0\nx_test = x_test \/ 255.0\n\n#Now lets check...\nplt.imshow(x_train[5])\nplt.colorbar()\nplt.show()","e3804240":"#Lets reshape the data for feeding into the model (which is to be made)\n#Since this will be passed into the CNN I will use the reshape() function to add a new dimension\n#As u can see in the output that the only change is that we have got a new dimesion of value 1\nx_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2], 1)\nx_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\nx_train.shape","561ccb54":"noise_factor = 0.2\nx_train_noisy = x_train + noise_factor * tf.random.normal(shape = x_train.shape)\nx_test_noisy = x_test + noise_factor * tf.random.normal(shape = x_test.shape)\n\nx_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min = 0, clip_value_max = 1)\nx_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min = 0, clip_value_max = 1)","92e56efd":"tf.shape(tf.squeeze(x_train_noisy[0]))\n#lets see the noisy images\nplt.imshow(tf.squeeze(x_train_noisy[1]))\nplt.gray()","04c678b9":"class autoencoder(Model):\n    def __init__(self):\n        super(autoencoder, self).__init__()\n        self.encoder = tf.keras.Sequential([\n            layers.Input(shape = (28, 28,1)),\n            layers.Conv2D(18, (3,3), activation = 'relu', padding = 'same', strides = 2),\n            layers.Conv2D(9, (3,3), activation = 'relu', padding = 'same', strides = 2)\n        ])\n        \n        self.decoder = tf.keras.Sequential([\n            layers.Conv2DTranspose(9, (3,3), activation = 'relu', padding = 'same', strides = 2),\n            layers.Conv2DTranspose(18, (3,3), activation = 'relu', padding = 'same', strides = 2),\n            layers.Conv2D(1, (3,3), activation = 'sigmoid', padding = 'same', strides = 1)\n        ])\n        \n    def call(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n           ","84f69204":"#Lets compile the model...\nAutoencoder = autoencoder()\nAutoencoder.compile(optimizer = 'adam', loss = 'mse')","032cdf11":"history = Autoencoder.fit(x_train_noisy, x_train,\n               epochs = 5,\n               shuffle = True,\n               validation_data = (x_test_noisy, x_test)\n               )","235b1922":"#Now lets plot the losses\nplt.plot(history.history['loss'], label = 'Training_loss')\nplt.plot(history.history['val_loss'], label = 'Validation_loss')\nplt.legend()\nplt.show()","b8a6019b":"#Now lets test our model with test data\n#We input the test data into the encoder and get the encoded images\nencoded_images = Autoencoder.encoder(x_test_noisy).numpy()\n\n#Then we input the encoded images into the decoder and get the decoded and denoised images\ndecoded_images = Autoencoder.decoder(encoded_images).numpy()","df66801d":"decoded_images.shape","0e4ef845":"#Lets see the noisy input image ...\nplt.imshow(tf.squeeze(x_test_noisy[0]))\nplt.gray()","5bc201af":"#Now the denoised image \nplt.imshow(tf.squeeze(decoded_images[0]))\nplt.gray()","582f9a1f":"In this notebook I am going to use Autoencoders for image denoising. Autoencoders have a very special structure, it takes an input and learns to recreate it as the output. This property of Autoencoders gives them a wide functionality  I have used them in one of my notebooks for creating an [ECG anomaly detector](https:\/\/www.kaggle.com\/devavratatripathy\/ecg-anomaly-detection-using-autoencoders)( do check it out !).In this I am going to use them to denoise the images of fashion MNIST dataset. First I will create noisy images from the original images then I will train the autoencoder with the noisy images as input and the original ones as output so that it wil learn how to denoise an image. \n\nI will try to make it as easy to understand as possible \n\nSo lets dive in... ","97aff3b1":"This was a basic model you can improve it by tuning the  hyperparameters and making the CNN more dense with pooling and normalization ,etc.This approach can be used for preprocesing images before feeding them into some other model as it will improve the data quality. \n\n**UPVOTE IF YOU LIKED THE KERNEL. THANK YOU ....**\n\nDo check out my other notebook on [ECG anomaly detection using autoencoders ](https:\/\/www.kaggle.com\/devavratatripathy\/ecg-anomaly-detection-using-autoencoders)\n","6da71675":"Coming to our model, first it has an **encoder** which has convolutional layers that compress the original image. Its a fairly simple CNN. The imporatant part is in the **decoder** as here u can notice that instead of the usual Conv2D layers I have used **Conv2DTranspose**. This layer is for **upsampling** the compressed image. \nSo lets understand what does it does...\nThe job of the decoder is to reconstruct the output from the compressed input and as we know that a convolution operation on an image reduces the dimension of the image while increasing the channels depending on the no. of filters. This action compresses the input image and in order to reconstruct it we need to kindof need to decompress it. So u can think that the Conv2DTranspose performs some sort of deconvolution type of operation( although in reality its way more complex so for intuition we can think of it as deconvolution) which increases the image size and resolution. Just think of it as upscaling the image.\nThere are some other upsampling methods but they perform poorly as compared to this and we can also use the regular Conv2D but it also kind of performs less effectively. \nNote that in the end I have  also used a regular convolutional layer to bring the image back to its original dimensions of (28x28X1)\n","1c5dc03e":"Now let's create our model !\n\nAs I mentioned earlier we are going to use Autoencoder for this model. Autoencoder is a special type of neural network that is trined to reconstruct its input as output. Its network architecture is slightly different as it consists of 2 parts :- 1) encoder- compresses and encodes the input , 2)decoder- reconstructs the input from the encoded data. I have explained autoencoders briefly in my other notebook regarding [ECG Anomaly detection using autoencoders](https:\/\/www.kaggle.com\/devavratatripathy\/ecg-anomaly-detection-using-autoencoders)Here i have impemented it and also provided links to some other articles abut autoencoders. So do check it out !\n\n\n","75330ea3":"**Note** that here if we just directly use plt.imshow() then it will throw an error. The reason beng that we added an extra dimesion 1 to our dataset but imshow() expects an 2-D array , so we need to somehow get rid of that extra dimesion and here **tf.squeeze()** comes in handy. This function removes the dimensions with value 1. \nFor example if the shape of the tensor is (5, 4, 2, 1) then this function will output a tensor with shape (5, 4, 2).\nCheck the tensorflow documentation for a better understanding.","0185ebc5":"**Now lets create noise in the images...**\n\nBy noise we mean random disturbances in the image , so this can be done by adding some randomly generated value to each pixel value of our images.\nFor this purpose we use the **tf.random.normal()** function which generates a tensor of the given shape with randomly generated values from a normalised ditribution.\nWe multiply the random values by a **noise factor** which you can decide according to your needs, it just controls the extent to which the pixel values will be modeified (e.g if the random no generated is 0.5 and the original pixel value is 0.6 , then a noise factor of 0.2 will give us the pixel value as 0.7 but a noise factor of 0.3 will give us 0.75).\n\nAfter generating random noise the images are no longer scaled to the limit 0 to 1 because the randomly generated numbers can be -ve (since they are from normal distribution). So to rescale the values to the range 0 to 1  I have used the **tf.clip_by_value()** which clips the values that lie outside the threshold(min and max) and reduces them to the threshold values(which here are 0 and 1)."}}