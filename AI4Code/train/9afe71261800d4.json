{"cell_type":{"dbc3faed":"code","2d8e07fa":"code","4cedc19a":"code","1a3faf83":"code","512bcd89":"code","f8cf6a4c":"code","148a262d":"code","8ec2b7ea":"code","fb287d21":"code","8b843eea":"code","0855861f":"code","ec493e44":"code","4b5dda9e":"code","d76c197f":"markdown","9e39ed80":"markdown","679e19b7":"markdown","2d7e184b":"markdown"},"source":{"dbc3faed":"import sys\nif not sys.warnoptions:\n    import warnings\n    warnings.simplefilter(\"ignore\")\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nwarnings.filterwarnings(\"ignore\")\n","2d8e07fa":"import plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\n\ndef RMSLE(pred,actual):\n    return np.sqrt(np.mean(np.power((np.log(pred+1)-np.log(actual+1)),2)))","4cedc19a":"pd.set_option('mode.chained_assignment', None)\ntest = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-3\/test.csv\")\ntrain = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-3\/train.csv\")\ntrain['Province_State'].fillna('', inplace=True)\ntest['Province_State'].fillna('', inplace=True)\ntrain['Date'] =  pd.to_datetime(train['Date'])\ntest['Date'] =  pd.to_datetime(test['Date'])\ntrain = train.sort_values(['Country_Region','Province_State','Date'])\ntest = test.sort_values(['Country_Region','Province_State','Date'])","1a3faf83":"train.head()","512bcd89":"from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n\nfeature_day = [1,20,50,100,200,500,1000]\ndef CreateInput(data):\n    feature = []\n    for day in feature_day:\n        #Get information in train data\n        data.loc[:,'Number day from ' + str(day) + ' case'] = 0\n        if (train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].count() > 0):\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].max()        \n        else:\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].min()       \n        for i in range(0, len(data)):\n            if (data['Date'].iloc[i] > fromday):\n                day_denta = data['Date'].iloc[i] - fromday\n                data['Number day from ' + str(day) + ' case'].iloc[i] = day_denta.days \n        feature = feature + ['Number day from ' + str(day) + ' case']\n    \n    return data[feature]\npred_data_all = pd.DataFrame()\nfor country in train['Country_Region'].unique():\n#for country in ['Vietnam']:\n    for province in train[(train['Country_Region'] == country)]['Province_State'].unique():\n        df_train = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]\n        df_test = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n        X_train = CreateInput(df_train)\n        y_train_confirmed = df_train['ConfirmedCases'].ravel()\n        y_train_fatalities = df_train['Fatalities'].ravel()\n        X_pred = CreateInput(df_test)\n        \n        # Only train above 50 cases\n        for day in sorted(feature_day,reverse = True):\n            feature_use = 'Number day from ' + str(day) + ' case'\n            idx = X_train[X_train[feature_use] == 0].shape[0]     \n            if (X_train[X_train[feature_use] > 0].shape[0] >= 20):\n                break\n                                           \n        adjusted_X_train = X_train[idx:][feature_use].values.reshape(-1, 1)\n        adjusted_y_train_confirmed = y_train_confirmed[idx:]\n        adjusted_y_train_fatalities = y_train_fatalities[idx:] #.values.reshape(-1, 1)\n        idx = X_pred[X_pred[feature_use] == 0].shape[0]    \n        adjusted_X_pred = X_pred[idx:][feature_use].values.reshape(-1, 1)\n        \n        pred_data = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n        max_train_date = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].max()\n        min_test_date = pred_data['Date'].min()\n        #The number of day forcast\n        #pred_data[pred_data['Date'] > max_train_date].shape[0]\n        #model = SimpleExpSmoothing(adjusted_y_train_confirmed).fit()\n        #model = Holt(adjusted_y_train_confirmed).fit()\n        #model = Holt(adjusted_y_train_confirmed, exponential=True).fit()\n        #model = Holt(adjusted_y_train_confirmed, exponential=True, damped=True).fit()\n        model = ExponentialSmoothing(adjusted_y_train_confirmed, trend = 'additive').fit()\n        y_hat_confirmed = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n        y_train_confirmed = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['ConfirmedCases'].values\n        y_hat_confirmed = np.concatenate((y_train_confirmed,y_hat_confirmed), axis = 0)\n               \n        #model = Holt(adjusted_y_train_fatalities).fit()\n        model = ExponentialSmoothing(adjusted_y_train_fatalities, trend = 'additive').fit()\n        y_hat_fatalities = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n        y_train_fatalities = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['Fatalities'].values\n        y_hat_fatalities = np.concatenate((y_train_fatalities,y_hat_fatalities), axis = 0)\n        \n        \n        pred_data['ConfirmedCases_hat'] =  y_hat_confirmed\n        pred_data['Fatalities_hat'] = y_hat_fatalities\n        pred_data_all = pred_data_all.append(pred_data)\n\ndf_val = pd.merge(pred_data_all,train[['Date','Country_Region','Province_State','ConfirmedCases','Fatalities']],on=['Date','Country_Region','Province_State'], how='left')\ndf_val.loc[df_val['Fatalities_hat'] < 0,'Fatalities_hat'] = 0\ndf_val.loc[df_val['ConfirmedCases_hat'] < 0,'ConfirmedCases_hat'] = 0\ndf_val_1 = df_val.copy()","f8cf6a4c":"country = \"Netherlands\"\ndf_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\nidx = df_country[((df_country['ConfirmedCases'].isnull() == False) & (df_country['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_country, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of ' + df_country['Country_Region'].values[0])\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_country, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of ' + df_country['Country_Region'].values[0])\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","148a262d":"df_total = df_val.groupby(['Date']).sum().reset_index()\n\nidx = df_total[((df_total['ConfirmedCases'].isnull() == False) & (df_total['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_total, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of World')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_total, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of World')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","8ec2b7ea":"from statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.arima_model import ARIMA\n\nfeature_day = [1,20,50,100,200,500,1000]\ndef CreateInput(data):\n    feature = []\n    for day in feature_day:\n        #Get information in train data\n        data.loc[:,'Number day from ' + str(day) + ' case'] = 0\n        if (train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].count() > 0):\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].max()        \n        else:\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].min()       \n        for i in range(0, len(data)):\n            if (data['Date'].iloc[i] > fromday):\n                day_denta = data['Date'].iloc[i] - fromday\n                data['Number day from ' + str(day) + ' case'].iloc[i] = day_denta.days \n        feature = feature + ['Number day from ' + str(day) + ' case']\n    \n    return data[feature]\npred_data_all = pd.DataFrame()\nfor country in train['Country_Region'].unique():\n    for province in train[(train['Country_Region'] == country)]['Province_State'].unique():\n        df_train = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]\n        df_test = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n        X_train = CreateInput(df_train)\n        y_train_confirmed = df_train['ConfirmedCases'].ravel()\n        y_train_fatalities = df_train['Fatalities'].ravel()\n        X_pred = CreateInput(df_test)\n        \n        # Only train above 50 cases\n        for day in sorted(feature_day,reverse = True):\n            feature_use = 'Number day from ' + str(day) + ' case'\n            idx = X_train[X_train[feature_use] == 0].shape[0]     \n            if (X_train[X_train[feature_use] > 0].shape[0] >= 20):\n                break\n                                           \n        adjusted_X_train = X_train[idx:][feature_use].values.reshape(-1, 1)\n        adjusted_y_train_confirmed = y_train_confirmed[idx:]\n        adjusted_y_train_fatalities = y_train_fatalities[idx:] #.values.reshape(-1, 1)\n        idx = X_pred[X_pred[feature_use] == 0].shape[0]    \n        adjusted_X_pred = X_pred[idx:][feature_use].values.reshape(-1, 1)\n        \n        pred_data = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n        max_train_date = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].max()\n        min_test_date = pred_data['Date'].min()\n        model = SARIMAX(adjusted_y_train_confirmed, order=(1,1,0), \n                        #seasonal_order=(1,1,0,12),\n                        measurement_error=True).fit(disp=False)\n        y_hat_confirmed = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n        y_train_confirmed = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['ConfirmedCases'].values\n        y_hat_confirmed = np.concatenate((y_train_confirmed,y_hat_confirmed), axis = 0)\n               \n        model = SARIMAX(adjusted_y_train_fatalities, order=(1,1,0), \n                        #seasonal_order=(1,1,0,12),\n                        measurement_error=True).fit(disp=False)\n        y_hat_fatalities = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n        y_train_fatalities = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['Fatalities'].values\n        y_hat_fatalities = np.concatenate((y_train_fatalities,y_hat_fatalities), axis = 0)\n        \n        \n        pred_data['ConfirmedCases_hat'] =  y_hat_confirmed\n        pred_data['Fatalities_hat'] = y_hat_fatalities\n        pred_data_all = pred_data_all.append(pred_data)\n\ndf_val = pd.merge(pred_data_all,train[['Date','Country_Region','Province_State','ConfirmedCases','Fatalities']],on=['Date','Country_Region','Province_State'], how='left')\ndf_val.loc[df_val['Fatalities_hat'] < 0,'Fatalities_hat'] = 0\ndf_val.loc[df_val['ConfirmedCases_hat'] < 0,'ConfirmedCases_hat'] = 0\ndf_val_2 = df_val.copy()","fb287d21":"country = \"US\"\ndf_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\nidx = df_country[((df_country['ConfirmedCases'].isnull() == False) & (df_country['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_country, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of ' + df_country['Country_Region'].values[0] + ' (SARIMA)')\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_country, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of ' + df_country['Country_Region'].values[0] + ' (SARIMA)')\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","8b843eea":"country = \"India\"\ndf_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\nidx = df_country[((df_country['ConfirmedCases'].isnull() == False) & (df_country['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_country, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of ' + df_country['Country_Region'].values[0] + ' (SARIMA)')\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_country, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of ' + df_country['Country_Region'].values[0] + ' (SARIMA)')\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","0855861f":"df_total = df_val.groupby(['Date']).sum().reset_index()\n\nidx = df_total[((df_total['ConfirmedCases'].isnull() == False) & (df_total['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_total, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of World - SARIMA')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_total, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of World - SARIMA')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","ec493e44":"method_list = ['Exponential Smoothing','SARIMA']\nmethod_val = [df_val_1,df_val_2]\nfor i in range(0,2):\n    df_val = method_val[i]\n    method_score = [method_list[i]] + [RMSLE(df_val[(df_val['ConfirmedCases'].isnull() == False)]['ConfirmedCases'].values,df_val[(df_val['ConfirmedCases'].isnull() == False)]['ConfirmedCases_hat'].values)] + [RMSLE(df_val[(df_val['Fatalities'].isnull() == False)]['Fatalities'].values,df_val[(df_val['Fatalities'].isnull() == False)]['Fatalities_hat'].values)]\n    print (method_score)","4b5dda9e":"df_val = df_val_2\nsubmission = df_val[['ForecastId','ConfirmedCases_hat','Fatalities_hat']]\nsubmission.columns = ['ForecastId','ConfirmedCases','Fatalities']\nsubmission.to_csv('submission.csv', index=False)\nsubmission","d76c197f":"Today is the last day of the competition. Trying Linear Regression. This model has worse accuracy, but on a private network it should show itself well.\n\nOther solutions:\n\n* https:\/\/www.kaggle.com\/mrmorj\/covid19-svc\n* https:\/\/www.kaggle.com\/mrmorj\/covid-19-adv-eda-lstm\n* https:\/\/www.kaggle.com\/mrmorj\/covid-19-eda-xgboost\n* https:\/\/www.kaggle.com\/mrmorj\/covid-19-linreg\n\nPlease support the efforts!","9e39ed80":"# SARIMA Model","679e19b7":"# Submission","2d7e184b":"# Holt and Exponential Smoothening"}}