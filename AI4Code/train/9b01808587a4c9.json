{"cell_type":{"736c0cd0":"code","b0391a35":"code","753ab583":"code","386aa7cb":"code","fb8fe01d":"code","a1a6faa9":"code","a0196195":"markdown","95bc8371":"markdown","10250139":"markdown","86eae896":"markdown","ab6fad94":"markdown","cc44ae93":"markdown","a7795d55":"markdown","570d070f":"markdown","00afc7f6":"markdown"},"source":{"736c0cd0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport h5py\nimport os\nPATH=\"..\/input\/\"\nprint(os.listdir(PATH))","b0391a35":"study_df = pd.read_csv(os.path.join(PATH, 'study_list.csv'))\nprint(\"Study list: %2d rows, %2d columns\" % (study_df.shape[0], study_df.shape[1]))\nstudy_df","753ab583":"maxImgSet = 0\nwith h5py.File(os.path.join(PATH, 'patient_images_lowres.h5'), 'r') as patient_data:\n    for (patient_id, patient_img) in patient_data['ct_data'].items():\n        maxImgSet = max(maxImgSet, len(patient_img))\n        print(\"Patient:\", patient_id, \" Images:\", len(patient_img))\nprint(\"\\nLargest number of images:\",maxImgSet)      ","386aa7cb":"%matplotlib inline\nwith h5py.File(os.path.join(PATH, 'patient_images_lowres.h5'), 'r') as patient_data:\n    for (patient_id, patient_img) in patient_data['ct_data'].items():\n        crt_row_df = study_df[study_df['Patient ID']==patient_id]\n        print(list(crt_row_df.T.to_dict().values()))\n        fig, ax = plt.subplots(13,12, figsize=(13,12), dpi = 250)\n        for i, crt_patient_img in enumerate(patient_img):\n            ax[i\/\/12, i%12].imshow(crt_patient_img, cmap = 'bone')\n            ax[i\/\/12, i%12].axis('off')\n        plt.subplots_adjust(hspace = .1, wspace = .1)\n        plt.show()","fb8fe01d":"maxImgSet = 0\nwith h5py.File(os.path.join(PATH, 'lab_petct_vox_5.00mm.h5'), 'r') as patient_data:\n    for (patient_id, patient_img) in patient_data['ct_data'].items():\n        maxImgSet = max(maxImgSet, len(patient_img))\n        print(\"Patient:\", patient_id, \" Images:\", len(patient_img))\nprint(\"\\nLargest number of images:\",maxImgSet)      ","a1a6faa9":"%matplotlib inline\nwith h5py.File(os.path.join(PATH, 'lab_petct_vox_5.00mm.h5'), 'r') as patient_data:\n    for (patient_id, patient_img) in patient_data['ct_data'].items():\n        crt_row_df = study_df[study_df['Patient ID']==patient_id]\n        print(list(crt_row_df.T.to_dict().values()))\n        fig, ax = plt.subplots(17,12, figsize=(13,12), dpi = 250)\n        for i, crt_patient_img in enumerate(patient_img):\n            ax[i\/\/12, i%12].imshow(crt_patient_img, cmap = 'bone')\n            ax[i\/\/12, i%12].axis('off')\n        plt.subplots_adjust(hspace = .1, wspace = .1)\n        plt.show()","a0196195":"# <a id=\"6\">References<\/a>\n\n[1] Segmenting Soft Tissue Sarcomas, https:\/\/www.kaggle.com\/4quant\/soft-tissue-sarcoma\/    \n[2] Visualize CT DICOM Data, https:\/\/www.kaggle.com\/gpreda\/visualize-ct-dicom-data   \n[3] Viewing the data, https:\/\/www.kaggle.com\/kmader\/viewing-the-data  \n","95bc8371":"# <a id=\"1\">Summary<\/a>\n\nThe data is a preprocessed subset of the TCIA Study named Soft Tissue Sarcoma. The data have been converted from DICOM folders of varying resolution and data types to 3D HDF5 arrays with isotropic voxel size. This should make it easier to get started and test out various approaches (NN, RF, CRF, etc) to improve segmentations.","10250139":"# <a id=\"1\">Load packages<\/a>","86eae896":"<h1><center><font size=\"6\">Medical Images Visualization<\/font><\/center><\/h1>\n\n<img src=\"https:\/\/kaggle2.blob.core.windows.net\/datasets-images\/515\/1026\/5aed8d13079d6ff6f733d70bde17001d\/dataset-card.png\" width=400><\/img>  \n\n# <a id='0'>Content<\/a>\n\n- <a href='#1'>Introduction<\/a>  \n- <a href='#2'>Load packages<\/a>  \n- <a href='#3'>Read the data<\/a> \n- <a href='#4'>Plot low resolution images<\/a>\n- <a href='#5'>Plot PET\/CT images<\/a>\n- <a href='#6'>References<\/a>","ab6fad94":"# <a id=\"4\">Plot low resolution images<\/a>   \n\nLet's start by verifying what is the number of images per patient and what is the largest number of images for a patient.","cc44ae93":"We retrieve the images and represent them grouped by `Patient ID`. For each patient data, we prepare to represent maximum **203** images (the maximum number of images in a image set). In most of the cases will be less, we will show 12 images \/ row.","a7795d55":"# <a id=\"3\">Read the data<\/a>","570d070f":"# <a id=\"5\">Plot PET\/CT images<\/a>   \n\nLet's start by verifying what is the number of images per patient and what is the largest number of images for a patient.","00afc7f6":"We retrieve the images and represent them grouped by `Patient ID`. For each patient data, we prepare to represent maximum **156** images (the maximum number of images in a image set). In most of the cases will be less, we will show 12 images \/ row."}}