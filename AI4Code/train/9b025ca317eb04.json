{"cell_type":{"d849d8f9":"code","8b80aba4":"code","7190b35f":"code","231a3b82":"code","3a3e8246":"code","2892b1d6":"code","ce0ed6ac":"code","1e54ff00":"code","6a618b1d":"code","605cc886":"code","9815ab4c":"code","d44ed0bd":"code","ec54461a":"code","68b482d2":"code","4d7a29f7":"code","d42f3db6":"code","ab3c17a6":"code","68288ddb":"code","ee1289ce":"code","75bd73f5":"code","241f915e":"code","85cc674f":"code","432b915b":"code","63fdfe5e":"code","cb2fe4a4":"code","1b75c902":"markdown","b3084ee1":"markdown","25c3e40b":"markdown","3e8395ef":"markdown","0c5a1426":"markdown","f3c1509b":"markdown","ddd94486":"markdown","7115d12a":"markdown","ba48d32f":"markdown","08734adb":"markdown","de78bace":"markdown","5f21f9e6":"markdown","398778b7":"markdown","a150a5f4":"markdown","0d28a136":"markdown","0517f2f6":"markdown","7014c3d3":"markdown","df610d1c":"markdown","d391c642":"markdown"},"source":{"d849d8f9":"import os\nimport math\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.ensemble import RandomForestRegressor\nfrom keras.utils import to_categorical\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, Dense, concatenate, Concatenate, PReLU\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","8b80aba4":"def load_data():\n    path = '..\/input\/mobile-sensors-and-directions'\n    gens = None\n    paths = os.listdir(path)\n    for p in paths:\n        p = path +'\/'+ p\n        for file in os.listdir(p):\n            gen = pd.read_csv(p + '\/' +file)\n            if gens is None:\n                gens = gen\n            else:\n                gens = pd.concat([gens, gen])\n    return gens\n\ngens = load_data()\ngens.head()","7190b35f":"gens.groupby(['tag'])['tag'].count()","231a3b82":"def create_X_y(gens):\n    gens = gens.dropna()\n    X = gens.drop(['tag','Unnamed: 0'], axis=1)\n    y = gens['tag']\n    return X, y\n\nX, y = create_X_y(gens)","3a3e8246":"def split_train_test(X, y, precentage = 0.2):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=precentage)\n    print('X train shape: ',X_train.shape, ' y train shape: ', y_train.shape)\n    print('X test shape: ',X_test.shape, ' y test shape: ', y_test.shape)\n    return X_train, X_test, y_train, y_test\n\ndef y_to_categorical(y_train, y_test):\n    dic = {x:i for i,x in enumerate(y_train.unique())}\n    names = [x for x in y_train.unique()]\n    len_train = len(y_train)\n    y = np.concatenate([y_train.to_numpy(), y_test.to_numpy()])\n    y = [dic[x] for x in y]\n    y = to_categorical(y)\n    y_train = y[0:len_train]\n    y_test = [dic[x] for x in y_test]\n    print('Changed to catigorical -> ','y train shape: ',len(y_train), '-> y test shape: ', len(y_test))\n    return y_train, y_test, dic, names\n\nX_train, X_test, y_train, y_test = split_train_test(X, y)\ny_train, y_test, y_dic, y_names = y_to_categorical(y_train, y_test)","2892b1d6":"BATCH_SIZE = 32\nEPOCKS = 25\nCLASSES = 9\nFEATURES = 8\nFEATURES_SENSOR = 3\nPOINTS = 5","ce0ed6ac":"def create_callbacks(name, patience=3):\n    early_stopping = EarlyStopping(patience=patience)\n    cheak_point = ModelCheckpoint(name)\n    return [early_stopping, cheak_point]\n\ndef create_metrics():\n    return ['accuracy']\n\ndef create_simple_model(size=FEATURES):\n    inp = Input(shape=(None,size))\n    x = Dense(32, activation='relu')(inp)\n    x = Dense(64, activation='relu')(x)\n    x = Dense(CLASSES, activation='softmax')(x)\n    model = Model(inputs=inp, outputs=x, name='simple_model') \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=create_metrics())\n    return model\n\nsimple_model = create_simple_model()\ncallbacks = create_callbacks('simple_model.h5')\nhistory = simple_model.fit(X_train, y_train, epochs=EPOCKS, batch_size=BATCH_SIZE, validation_split=0.15, callbacks=callbacks)","1e54ff00":"def quick_plot_loss(history, field, metric, ax):\n    # Plot training & validation loss values\n    ax.plot(history.history[field])\n    ax.plot(history.history['val_'+field])\n    ax.set_title('Model '+ metric)\n    ax.set_ylabel(metric)\n    ax.set_xlabel('Epoch')\n    ax.legend(['Train', 'Validation'], loc='upper left')\n                \n    \ndef quick_plot_history(history):\n    fig = plt.figure(figsize=(18, 4))\n    ax = fig.add_subplot(1, 2, 1)\n    ax.set_title('loss')\n    quick_plot_loss(history, 'loss', 'categorical_crossentropy', ax)\n    ax = fig.add_subplot(1, 2, 2)\n    ax.set_title('accrucy')\n    quick_plot_loss(history, 'accuracy', 'accuracy', ax)\n    \nquick_plot_history(history)","6a618b1d":"def test_results(model,X_test,y_test, LOAD=True):\n    preds = model.predict(X_test)\n    pred_cat = np.argmax(preds,axis=1) #takes the maximum prediction and compare it to the real prediction\n    acc = accuracy_score(y_test,pred_cat)*100\n    acc_saved = -1\n    if LOAD:\n        saved_model = load_model('.\/'+model.name+'.h5')\n        preds = saved_model.predict(X_test)\n        pred_cat = np.argmax(preds,axis=1) #takes the maximum prediction and compare it to the real prediction\n        acc_saved = accuracy_score(y_test,pred_cat)*100\n    if acc >= acc_saved:\n        if LOAD:\n            model.save('.\/'+model.name+'.h5')\n        print('NEW: model accuracy on test set is: {0:.2f}%'.format(acc))\n    else:\n        print('model accuracy on test set is: {0:.2f}%'.format(acc_saved))        \n\ntest_results(simple_model, X_test, y_test)","605cc886":"forest = RandomForestRegressor(n_estimators = 100, max_depth = 8)\nforest.fit(X_train,y_train)\ntest_results(forest, X_test, y_test, LOAD=False)","9815ab4c":"def split_input_channels(X):\n    acc = X.drop(['gyroscope_x','gyroscope_y','gyroscope_z','angle','diff'], axis=1)\n    gyro = X.drop(['accelometer_x','accelometer_y','accelometer_z','angle','diff'], axis=1)\n    angle = X.drop(['gyroscope_x','gyroscope_y','gyroscope_z','accelometer_x','accelometer_y','accelometer_z'], axis=1)\n    return acc, gyro, angle\n\n\ndef create_siamese_model(acc_size, gyro_size, angle_size):\n    acc_inp = Input(shape=acc_size)\n    acc = Dense(32, activation='relu')(acc_inp)\n    acc = Dense(64, activation='relu')(acc)\n    \n    gyro_inp = Input(shape=gyro_size)\n    gyro = Dense(32, activation='relu')(gyro_inp)\n    gyro = Dense(64, activation='relu')(gyro)\n    \n    angle_inp = Input(shape=angle_size)\n    angle = Dense(32, activation='relu')(angle_inp)\n    angle = Dense(64, activation='relu')(angle)\n    \n    x = concatenate([acc, gyro, angle])\n    x = Dense(CLASSES, activation='softmax')(x)\n    model = Model(inputs=[acc_inp, gyro_inp, angle_inp], outputs=x, name='siamese_model') \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=create_metrics())\n    return model\n\nsiamese_model = create_siamese_model(FEATURES_SENSOR, FEATURES_SENSOR, 2)\nacc, gyro, angle = split_input_channels(X_train)\ncallbacks = create_callbacks('siamese_model.h5')\nhistory = siamese_model.fit([acc,gyro,angle], y_train, epochs=EPOCKS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=callbacks)","d44ed0bd":"quick_plot_history(history)\nacc, gyro, angle = split_input_channels(X_test)\ntest_results(siamese_model, [acc, gyro, angle], y_test)","ec54461a":"def split_train_test_by_sliding_window(X,y, N=2):\n    grouped = gens.groupby('tag')\n    X_tmp = None\n    X_original = None\n    y_original = None\n    start = N\n    end = None\n    for g in grouped:\n        X, y = create_X_y(g[1])\n        end = len(X)\n        tmp_dic = {}\n        if X_original is None:\n            X_original = X.iloc[start:]\n            y_original = y.iloc[start:]\n        else:\n            X_original = pd.concat([X_original,X.iloc[start:]])\n            y_original = pd.concat([y_original, y.iloc[start:]])\n        for col in X.columns:\n            for i in range(1,N,1):\n                name = 'prev_'+str(i)+'_'+col\n\n                tmp_dic[name] = X[col].iloc[start-i: end-i].values\n        if X_tmp is None:\n            X_tmp = pd.DataFrame.from_dict(tmp_dic)\n        else:\n            X_tmp = pd.concat([X_tmp, pd.DataFrame.from_dict(tmp_dic)])\n    X_original = X_original.reset_index()\n    X_tmp = X_tmp.reset_index()\n    X_tmp = pd.concat([X_tmp, X_original], axis=1)\n    X_tmp = X_tmp.drop(['index'], axis=1)\n    print('X devide: ',X_tmp.shape, ' y devide: ', y_original.shape)\n    X_train, X_test, y_train, y_test = split_train_test(X_tmp, y_original)\n    return X_train, X_test, y_train, y_test\n\nX_train, X_test, y_train, y_test = split_train_test_by_sliding_window(X, y, N=POINTS)\ny_train, y_test, y_dic, y_names = y_to_categorical(y_train, y_test)\nX_train.head()","68b482d2":"def sp_acc_txt(prev=None):\n    if prev is None:\n        return ['accelometer_x','accelometer_y','accelometer_z']\n    name = 'prev_'+str(prev)+'_'\n    return [name+'accelometer_x',name+'accelometer_y',name+'accelometer_z']\n\ndef split_acc(points,index=None):\n    l = []\n    if index is None or index != 0:\n        l = sp_acc_txt()\n    for i in range(1,points):\n        if index is None or i != index:\n            l += sp_acc_txt(prev=i)\n    return l\n\ndef sp_gyro_txt(prev=None):\n    if prev is None:\n        return ['gyroscope_x','gyroscope_y','gyroscope_z']\n    name = 'prev_'+str(prev)+'_'\n    return [name+'gyroscope_x',name+'gyroscope_y',name+'gyroscope_z']\n\ndef split_gyro(points,index=None):\n    l = []\n    if index is None or index != 0:\n        l = sp_gyro_txt()\n    for i in range(1,points):\n        if index is None or i != index:\n            l += sp_gyro_txt(prev=i)\n    return l\n\ndef sp_angle_txt(prev=None):\n    if prev is None:\n        return ['angle','diff']\n    name = 'prev_'+str(prev)+'_'\n    return [name+'angle',name+'diff']\n\ndef split_angle(points,index=None):\n    l = []\n    if index is None or index != 0:\n        l = sp_angle_txt()\n    for i in range(1,points):\n        if index is None or i != index:\n            l += sp_angle_txt(prev=i)\n    return l \n\ndef split_channels(X, p=5):\n    t = ()\n    l = None\n    acc = None\n    gyto = None\n    angle = None\n    for i in range(p):\n        l = split_acc(p, index=i) + split_gyro(p) + split_angle(p)\n        acc = X.drop(l, axis=1)\n        l = split_acc(p) + split_gyro(p, index=i) + split_angle(p)\n        gyro = X.drop(l, axis=1)\n        l = split_acc(p) + split_gyro(p) + split_angle(p, index=i)\n        angle = X.drop(l, axis=1)\n        t += (acc , gyro, angle) \n    return t","4d7a29f7":"def dense_depth_block(inp, N=32, extend_N=4, deapth=5):\n    if deapth==0:\n        return inp\n    x = None \n    prev_x = None\n    xs = []\n    for i in range(0, deapth):\n        if x is None:\n            x = Dense(N)(inp)\n            x = PReLU()(x)\n        else:\n            prev_x = x\n            x = Dense(N + i*extend_N)(prev_x)\n            x = PReLU()(x)\n        xs.append(x)\n    if len(xs) != 1:\n        x = concatenate(xs)\n    return x\n\ndef create_chanel(size=FEATURES_SENSOR, deapth=5, N=32,extend_N=16):\n    inp = Input(shape=size)\n    x = dense_depth_block(inp, deapth=deapth, N=N, extend_N=extend_N)\n    return inp, x","d42f3db6":"def create_complex_siamese_model(p=POINTS):\n    inputs= []\n    cs = []\n    for i in range(p):\n        inp_acc, c_acc = create_chanel(size=3,deapth=2,N=16)\n        inputs.append(inp_acc)\n        cs.append(c_acc)\n        inp_gyro, c_gyro = create_chanel(size=3,deapth=2,N=16)\n        inputs.append(inp_gyro)\n        cs.append(c_gyro)\n        inp_angle, c_angle = create_chanel(size=2,deapth=2,N=16)\n        inputs.append(inp_angle)\n        cs.append(c_angle)\n    x = concatenate(cs)\n    x = Dense(256)(x)\n    x = PReLU()(x)\n    x = Dense(128)(x)\n    x = PReLU()(x)\n    x = Dense(CLASSES, activation='softmax')(x)\n    model = Model(inputs=inputs, outputs=x, name='complex_siamese_'+str(p)+'_model') \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=create_metrics())\n    return model, 'complex_siamese_'+str(p)+'_model'","ab3c17a6":"POINTS = 2\nX_train, X_test, y_train, y_test = split_train_test_by_sliding_window(X, y, N=POINTS)\ny_train, y_test, y_dic, y_names = y_to_categorical(y_train, y_test)\ncomplex_siamese_model, name = create_complex_siamese_model(p=POINTS)\ncallbacks = create_callbacks(name+'.h5')\nhistory = complex_siamese_model.fit(split_channels(X_train, p=POINTS), y_train, epochs=EPOCKS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=callbacks)","68288ddb":"quick_plot_history(history)\ntest_results(complex_siamese_model, split_channels(X_test, p=POINTS), y_test)","ee1289ce":"def plot_confusion_matrix(y_test, preds, y_names):\n    con = confusion_matrix(y_test, preds)\n    con = con \/ np.sum(con, axis=1)\n    plt.figure(figsize=(15,10), dpi=50)\n    sns.set(font_scale=1.5)\n    sns.heatmap(con, xticklabels=y_names, yticklabels=y_names, linewidths=2, annot=True, fmt = '.1%',cmap=\"YlGnBu\",square=True)\n    plt.xlabel('Predictions')\n    plt.ylabel('Accpected')\n    \npreds = complex_siamese_model.predict(split_channels(X_test, p=POINTS))\npreds = np.argmax(preds,axis=1)\nplot_confusion_matrix(y_test, preds, y_names)","75bd73f5":"POINTS = 5\nX_train, X_test, y_train, y_test = split_train_test_by_sliding_window(X, y, N=POINTS)\ny_train, y_test, y_dic, y_names = y_to_categorical(y_train, y_test)\ncomplex_siamese_model, name = create_complex_siamese_model(p=POINTS)\ncallbacks = create_callbacks(name+'.h5')\nhistory = complex_siamese_model.fit(split_channels(X_train, p=POINTS), y_train, epochs=EPOCKS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=callbacks)","241f915e":"quick_plot_history(history)\ntest_results(complex_siamese_model, split_channels(X_test, p=POINTS), y_test)","85cc674f":"preds = complex_siamese_model.predict(split_channels(X_test, p=POINTS))\npreds = np.argmax(preds,axis=1)\nplot_confusion_matrix(y_test, preds, y_names)","432b915b":"POINTS = 9\nX_train, X_test, y_train, y_test = split_train_test_by_sliding_window(X, y, N=POINTS)\ny_train, y_test, y_dic, y_names = y_to_categorical(y_train, y_test)\ncomplex_siamese_model, name = create_complex_siamese_model(p=POINTS)\ncallbacks = create_callbacks(name+'.h5')\nhistory = complex_siamese_model.fit(split_channels(X_train, p=POINTS), y_train, epochs=EPOCKS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=callbacks)","63fdfe5e":"quick_plot_history(history)\ntest_results(complex_siamese_model, split_channels(X_test, p=POINTS), y_test)","cb2fe4a4":"preds = complex_siamese_model.predict(split_channels(X_test, p=POINTS))\npreds = np.argmax(preds,axis=1)\nplot_confusion_matrix(y_test, preds, y_names)","1b75c902":"### 9 Points","b3084ee1":"# Prologue\nOn this research we want to predict smartphone movement on a surface based on the accelometer and gyroscope sensors.\n\nIf we could find the general direction of this moving object, on a surface, based only on this two sensors, we could reduce the cost of manifacturing new sensors. In addition, we could develop new technology, encourging new ways to building models based on existing sensors.   \n","25c3e40b":"We can see there is 9 classes for classification probelm, where almost 6000+ sampels for each class. \n\nNote: the Ned class mark the object did not move.","3e8395ef":"### 5 Points","0c5a1426":"# Summary\nWe have learned how to solve an unknown problem and saw couple of new ways of solving classification problems which are sensor based. Those resaults are at the highest accuracy I could reach, during my attemps to predict the smartphone movment, using acceleration and gyroscope sensors. In addition, we have learned how to build Siamese Model based on sensors. \n\nWe found out that the greater the sliding window, the greater is the prediction accuracy.\n![image.png](attachment:image.png)","f3c1509b":"# ML benchmark","ddd94486":"We can see that the model is not accurate and an \"up\" movement is predicted as \"down\". ","7115d12a":"# The Approach: Classification\n0. preprocess the data\n1. building a simple model\n2. building a ML benchmark\n3. building a siamese model\n4. building a complex siamese model","ba48d32f":"## Imports of the notebook","08734adb":"# Siamese model - sensor based\nOn this siamese model there are 3 input channels - accelometer (3) , gyroscope(3) , angle(2)","de78bace":"We can see now that we have unnamed column that we do not need. Other columns are: tag we want to predict, acceleration and gyroscope data, angle data which is calculated from the gyroscope data and diff column is the change of the current angle from the last measured angle.","5f21f9e6":"# Pre processing the data","398778b7":"# Complex Siamese Model\nOn this siamese model there are N input channels - the current data sensors, the data sensors 1 before, the data sensors 2 before, etc.\n\nThis Siamese model will try to take:\n1. a window size 2 and use this window as the model input.\n2. a window size 5 and use this window as the model input.\n3. a window size 9 and use this window as the model input.\n","a150a5f4":"Defining constants for the upcoming training models.","0d28a136":"![image.png](attachment:image.png)","0517f2f6":"### 2 Points","7014c3d3":"We can see that the model is not accurate and an \"down\" movement is predicted as \"up\". ","df610d1c":"![image.png](attachment:image.png)","d391c642":"# Simple model"}}