{"cell_type":{"bafb637a":"code","33fed6a4":"code","658baea2":"code","95c411ea":"code","797016cb":"code","625df4e4":"code","176e2ab0":"code","52f9d7ff":"code","bb6e8318":"code","821cf077":"code","597c5f15":"code","a029fe0b":"code","a9bca8c9":"code","59d13839":"code","3d4fa2b3":"code","7e7e49ee":"code","a4460e35":"code","50daf109":"code","5b685cf1":"code","09638dbb":"code","00bacb82":"code","3e354ae0":"code","2fa00b9a":"code","8c14cd33":"code","7495fe6f":"code","c82d7549":"code","b6803e4e":"markdown","f541f691":"markdown","0b28e668":"markdown","de0cee03":"markdown","b310ebeb":"markdown","71b5d73e":"markdown","257a6d41":"markdown","50682ddf":"markdown","974a85e3":"markdown","d2a4d154":"markdown","da97d9a8":"markdown","c228c3d5":"markdown","6e2d5fc4":"markdown","4ef9f6e6":"markdown","c932305f":"markdown","f5c5a7b6":"markdown","19aca5d2":"markdown","b1d6cae8":"markdown","88f93ed7":"markdown"},"source":{"bafb637a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","33fed6a4":"import os\nprint(os.listdir('\/kaggle\/input'))","658baea2":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nfrom plotly.offline import init_notebook_mode, iplot \ninit_notebook_mode(connected=True) \n\nimport seaborn as sns\nimport cv2\n\nimport keras\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D,MaxPool2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\nfrom tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.metrics import confusion_matrix\n\nimport os\nprint(os.listdir(\"..\/input\/flowers-recognition\"))","95c411ea":"img = plt.imread(\"..\/input\/flowers-recognition\/flowers\/daisy\/10172379554_b296050f82_n.jpg\")\nimg = cv2.resize(img,(124,124))\nplt.imshow(img)\nplt.axis(\"off\")\nplt.show()","797016cb":"x_ = list()\ny = list()\nIMG_SIZE = 128\nfor i in os.listdir(\"..\/input\/flowers-recognition\/flowers\/daisy\"):\n    try:\n        path = \"..\/input\/flowers-recognition\/flowers\/daisy\/\"+i\n        img = plt.imread(path)\n        img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n        x_.append(img)\n        y.append(0)\n    except:\n        None\nfor i in os.listdir(\"..\/input\/flowers-recognition\/flowers\/dandelion\"):\n    try:\n        path = \"..\/input\/flowers-recognition\/flowers\/dandelion\/\"+i\n        img = plt.imread(path)\n        img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n        x_.append(img)\n        y.append(1)\n    except:\n        None\nfor i in os.listdir(\"..\/input\/flowers-recognition\/flowers\/rose\"):\n    try:\n        path = \"..\/input\/flowers-recognition\/flowers\/rose\/\"+i\n        img = plt.imread(path)\n        img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n        x_.append(img)\n        y.append(2)\n    except:\n        None\nfor i in os.listdir(\"..\/input\/flowers-recognition\/flowers\/sunflower\"):\n    try:\n        path = \"..\/input\/flowers-recognition\/flowers\/sunflower\/\"+i\n        img = plt.imread(path)\n        img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n        x_.append(img)\n        y.append(3)\n    except:\n        None\nfor i in os.listdir(\"..\/input\/flowers-recognition\/flowers\/tulip\"):\n    try:\n        path = \"..\/input\/flowers-recognition\/flowers\/tulip\/\"+i\n        img = plt.imread(path)\n        img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n        x_.append(img)\n        y.append(4)\n    except:\n        None\nx_ = np.array(x_)","625df4e4":"plt.figure(figsize = (20,20))\nfor i in range(5):\n    img = x_[745*i]\n    plt.subplot(1,5,i+1)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    plt.title(y[745*i])","176e2ab0":"y = to_categorical(y,num_classes = 5)","52f9d7ff":"x_","bb6e8318":"y","821cf077":"x_train,x_test,y_train,y_test = train_test_split(x_,y,test_size = 0.15,random_state = 42)","597c5f15":"x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size = 0.15,random_state = 42)","a029fe0b":"plt.figure(figsize = (40,40))\nfor i in range(5):\n    img = x_train[600*i]\n    plt.subplot(1,5,i+1)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    plt.title(y_train[600*i])\nplt.show()","a9bca8c9":"x_train.shape","59d13839":"y_test.shape","3d4fa2b3":"datagen = ImageDataGenerator(\n    featurewise_center=False,  \n    samplewise_center=False,  \n    featurewise_std_normalization=False,  \n    samplewise_std_normalization=False,  \n    rotation_range=60, \n    zoom_range = 0.1,  \n    width_shift_range=0.1,  \n    height_shift_range=0.1,\n    shear_range=0.1,\n    fill_mode = \"reflect\"\n    ) \ndatagen.fit(x_train)","7e7e49ee":"x_train.shape","a4460e35":"model = Sequential()\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),padding=\"Same\",activation=\"relu\" , input_shape = (IMG_SIZE,IMG_SIZE,3)))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3,3),padding=\"Same\",activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3,3),padding=\"Same\",activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(filters=256,kernel_size = (3,3),padding=\"Same\",activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=512,kernel_size = (3,3),padding=\"Same\",activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(1024,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n\nmodel.add(Dense(5,activation=\"softmax\"))\n\nmodel.summary()\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy']) #compile model","50daf109":"model.compile(loss='categorical_crossentropy',\n              optimizer=Adam(lr=0.001),\n              metrics=['accuracy'])","5b685cf1":"epoch = 50\nbatch_size = 32","09638dbb":"history = model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),\n                              epochs= epoch,validation_data=(x_val,y_val),\n                              steps_per_epoch=x_train.shape[0] \/\/ batch_size\n                              )","00bacb82":"print(\"Test Accuracy: {0:.2f}%\".format(model.evaluate(x_test,y_test)[1]*100)) #get score acording to test datas","3e354ae0":"train_acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nplt.plot(train_acc,label = \"Training\")\nplt.plot(val_acc,label = 'Validation\/Test')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.show()","2fa00b9a":"train_loss = history.history['loss']\nval_loss = history.history['val_loss']\nplt.plot(train_loss,label = 'Training')\nplt.plot(val_loss,label = 'Validation\/Test')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()","8c14cd33":"Y_pred = model.predict(x_val)\nY_pred_classes = np.argmax(Y_pred,axis = 1) \nY_true = np.argmax(y_val,axis = 1) \nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","7495fe6f":"predictions = model.predict_classes(x_test)\npredictions","c82d7549":"Y_pred = model.predict(x_test)\nY_pred_classes = np.argmax(Y_pred,axis = 1) \nY_true = np.argmax(y_test,axis = 1) \nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","b6803e4e":"* Now, our dataset and label dataset are ready to use for further process.\n* Let's have a look to our datasets.","f541f691":"# **Plot Images**","0b28e668":"# **Splitting Data**","de0cee03":"We will combine all the images into a single array.","b310ebeb":"We will divide our dataset into 3 parts:\n* Training Set\n* Validation Set\n* Test Set","71b5d73e":"By using our model on test set, following predictions were made:","257a6d41":"Plotting random images from the dataset we have just created. ","50682ddf":"# **Data Augmentation**","974a85e3":"# **Creating the CNN Model**","d2a4d154":"# **Learning Rate Scheduling and Compile the Model**","da97d9a8":"We will convert labels into a categorical data.","c228c3d5":"Now, our model is ready to perform on test set.","6e2d5fc4":"Let's have look to random images from our training set.","4ef9f6e6":"Getting an output of a random daisy flower.","c932305f":"Confusion matrix of validation dataset.","f5c5a7b6":"Confusion matrix for test dataset.","19aca5d2":"# **Import Libraries**","b1d6cae8":"Our model is performing good on training set as well as on validation set.","88f93ed7":"# **Load and Preprocessing Data**"}}