{"cell_type":{"3b1e2eab":"code","b28f1ec1":"code","097d0e1b":"code","8712ccb3":"code","35d6ff89":"code","018f2c38":"code","a8db2e8f":"code","f85ddc48":"code","10513272":"code","20b2b8bb":"code","ec41cb1b":"code","5eb3491e":"code","253e3daf":"code","4df5a6af":"code","a2c77e1f":"code","f86bb5d1":"code","cc81c460":"code","4c45d7c0":"code","b1806a5f":"code","934707d8":"code","05a8c5f0":"code","93309276":"code","e224a521":"code","4ca6d4d3":"code","ce07978f":"code","8feed075":"code","4dedb8b3":"code","8168fa18":"code","c3e8badd":"code","6a23bf3a":"code","c77fe89f":"code","ae6bbb9f":"code","78d48858":"code","a667c6a9":"code","c7efe284":"code","6d94b765":"code","7a97e191":"markdown","3778bfd7":"markdown","d0a33932":"markdown","ad996490":"markdown"},"source":{"3b1e2eab":"import numpy as np \nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\nimport os\nimport sys\nimport json\nimport cv2\nimport time\nimport glob","b28f1ec1":"df = pd.read_csv('\/kaggle\/input\/global-wheat-detection\/train.csv')\ndf.head()","097d0e1b":"df['bbox'] = df['bbox'].apply(lambda x: x[1:-1].split(\",\"))\ndf['x'] = df['bbox'].apply(lambda x: x[0]).astype('float32')\ndf['y'] = df['bbox'].apply(lambda x: x[1]).astype('float32')\ndf['w'] = df['bbox'].apply(lambda x: x[2]).astype('float32')\ndf['h'] = df['bbox'].apply(lambda x: x[3]).astype('float32')\ndf = df[['image_id','x', 'y', 'w', 'h']]\n\ndf.head()","8712ccb3":"#unique images\n#assigning unique Image id number to each images, required for coco json conversion\nimage_ids = df['image_id'].unique()\nimage_dict = dict(zip(image_ids, range(len(image_ids))))\nlen(image_dict)","35d6ff89":"json_dict = {\"images\": [], \"type\": \"instances\", \"annotations\": [], \"categories\": []} # required for converting to COCO","018f2c38":"for image_id in image_ids:\n    image = {'file_name': image_id + '.jpg', \n             'height': 1024, \n             'width': 1024, \n             'id': image_dict[image_id]}\n    json_dict['images'].append(image)","a8db2e8f":"categories = {'supercategory': 'wh', 'id': 1, 'name': 'wh'} #there is only one catogery to detect hence only one wheat ('wh') category\njson_dict['categories'].append(categories)","f85ddc48":"for idx, box_id in df.iterrows(): \n    image_id = image_dict[box_id['image_id']]\n    \n    ann = {'area': box_id['w'] * box_id['h'], \n           'iscrowd': 0, \n           'image_id': image_id,                        \n           'bbox': [box_id['x'], box_id['y'], box_id['w'], box_id['h']],\n           'category_id': 1, \n           'id': idx,\n           'segmentation': []}\n\n    json_dict['annotations'].append(ann)","10513272":"class NpEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, np.integer):\n            return int(obj)\n        elif isinstance(obj, np.floating):\n            return float(obj)\n        elif isinstance(obj, np.ndarray):\n            return obj.tolist()\n        else:\n            return super(NpEncoder, self).default(obj)","20b2b8bb":"annFile='instances_Images.json'\n\njson_fp = open(annFile, 'w',encoding='utf-8')\njson_str = json.dumps(json_dict,cls=NpEncoder)\njson_fp.write(json_str)\njson_fp.close()","ec41cb1b":"# #internet On\n# !pip install -U 'git+https:\/\/github.com\/cocodataset\/cocoapi.git#subdirectory=PythonAPI' -q\n\n# from pycocotools.coco import COCO","5eb3491e":"#internet Off\nos.mkdir('\/kaggle\/working\/cocopythonapi')\n#clone cocoapi locally and uppload loca zip file to input\n#coco git: https:\/\/github.com\/cocodataset\/cocoapi\n\n!cp --recursive \/kaggle\/input\/cocoapi\/cocoapi\/* \/kaggle\/working\/cocopythonapi\/\n","253e3daf":"cd \/kaggle\/working\/cocopythonapi\/PythonAPI","4df5a6af":"#building cocoAPI\n!make\n\nfrom pycocotools.coco import COCO","a2c77e1f":"# !git clone https:\/\/github.com\/kamauz\/EfficientDet.git","f86bb5d1":"#internet off, upload EfficientDet zip\n#clone the git repo of efficientdet to your local system and upload the cloned files (.zip) here\n#git link: https:\/\/github.com\/kamauz\/EfficientDet\n\nos.mkdir('\/kaggle\/working\/EfficientDet')\n!cp --recursive \/kaggle\/input\/efficientdet\/EfficientDet\/* \/kaggle\/working\/EfficientDet\/","cc81c460":"cd \/kaggle\/working\/EfficientDet\/","4c45d7c0":"!python setup.py build_ext --inplace","b1806a5f":"from model import efficientdet\nfrom losses import smooth_l1, focal\nfrom efficientnet import BASE_WEIGHTS_PATH, WEIGHTS_HASHES\nfrom generators.common import Generator","934707d8":"def preprocess_image(image):\n    image = image.astype(np.float32)\n    image \/= 255.\n    mean = [0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\n    image -= mean\n    image \/= std\n\n    return image","05a8c5f0":"def postprocess_boxes(boxes, height, width):\n    c_boxes = boxes.astype(np.int32).copy()\n    c_boxes[:, 0] = np.clip(c_boxes[:, 0], 0, width - 1)\n    c_boxes[:, 1] = np.clip(c_boxes[:, 1], 0, height - 1)\n    c_boxes[:, 2] = np.clip(c_boxes[:, 2], 0, width - 1)\n    c_boxes[:, 3] = np.clip(c_boxes[:, 3], 0, height - 1)\n    return c_boxes","93309276":"class CocoGenerator(Generator):\n    def __init__(self, data_dir, set_name, **kwargs):                                    \n        self.coco = COCO('\/kaggle\/working\/instances_Images.json')                \n        self.image_ids = self.coco.getImgIds()\n        self.load_classes()\n\n        super(CocoGenerator, self).__init__(**kwargs)\n\n    def load_classes(self): \n        categories = self.coco.loadCats(self.coco.getCatIds())\n        categories.sort(key=lambda x: x['id'])\n\n        self.classes = {}\n        self.coco_labels = {}\n        self.coco_labels_inverse = {}\n        for c in categories:\n            self.coco_labels[len(self.classes)] = c['id']\n            self.coco_labels_inverse[c['id']] = len(self.classes)\n            self.classes[c['name']] = len(self.classes)\n\n        self.labels = {}\n        for key, value in self.classes.items():\n            self.labels[value] = key\n\n    def size(self):\n        return len(self.image_ids)\n\n    def num_classes(self):\n        return 1\n\n    def has_label(self, label):\n        return label in self.labels\n\n    def has_name(self, name):\n        return name in self.classes\n\n    def name_to_label(self, name):\n        return self.classes[name]\n\n    def label_to_name(self, label):\n        return self.labels[label]\n\n    def coco_label_to_label(self, coco_label):\n        return self.coco_labels_inverse[coco_label]\n\n    def coco_label_to_name(self, coco_label):\n        return self.label_to_name(self.coco_label_to_label(coco_label))\n\n    def label_to_coco_label(self, label):\n        return self.coco_labels[label]\n\n    def image_aspect_ratio(self, image_index):\n        image = self.coco.loadImgs(self.image_ids[image_index])[0]\n        return float(image['width']) \/ float(image['height'])\n\n    def load_image(self, image_index):        \n        image_info = self.coco.loadImgs(self.image_ids[image_index])[0]        \n        path = os.path.join('\/kaggle\/input\/global-wheat-detection\/train\/', image_info['file_name'])        \n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        image = preprocess_image(image)\n        \n        return image\n\n    def load_annotations(self, image_index):\n        annotations_ids = self.coco.getAnnIds(imgIds=self.image_ids[image_index], iscrowd=False)\n        annotations = {'labels': np.empty((0,), dtype=np.float32), 'bboxes': np.empty((0, 4), dtype=np.float32)}\n\n        if len(annotations_ids) == 0:\n            return annotations\n\n        coco_annotations = self.coco.loadAnns(annotations_ids)\n        for idx, a in enumerate(coco_annotations):\n            # some annotations have basically no width \/ height, skip them\n            if a['bbox'][2] < 1 or a['bbox'][3] < 1:\n                continue\n\n            annotations['labels'] = np.concatenate(\n                [annotations['labels'], [a['category_id'] - 1]], axis=0)\n            annotations['bboxes'] = np.concatenate([annotations['bboxes'], [[\n                a['bbox'][0],\n                a['bbox'][1],\n                a['bbox'][0] + a['bbox'][2],\n                a['bbox'][1] + a['bbox'][3],\n            ]]], axis=0)           \n\n        return annotations    ","e224a521":"phi = 4 #range 0 - 6\nscore_threshold=0.4","4ca6d4d3":"train_generator = CocoGenerator(data_dir=None, set_name=None, batch_size = 4, phi = phi)","ce07978f":"model, prediction_model = efficientdet(phi,\n                                       num_classes=1,\n                                       weighted_bifpn=True,\n                                       freeze_bn=True,\n                                       score_threshold=score_threshold\n                                       )","8feed075":"# #internet on\n# model_name = 'efficientnet-b{}'.format(phi)\n# file_name = '{}_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'.format(model_name)\n# file_hash = WEIGHTS_HASHES[model_name][1]\n# weights_path = tf.keras.utils.get_file(file_name,\n#                                     BASE_WEIGHTS_PATH + file_name,\n#                                     cache_subdir='models',\n#                                     file_hash=file_hash)\n# model.load_weights(weights_path, by_name=True)","4dedb8b3":"#internet off\n\n#uoload the pretrained weights using the kaggle dataset\n#link: https:\/\/www.kaggle.com\/dimitreoliveira\/efficientnet\n\nmodel_name = 'efficientnet-b{}'.format(phi)\nfile_name = '{}_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'.format(model_name)\nfilepath = '\/kaggle\/input\/efficientnet\/' + file_name\nmodel.load_weights(filepath,by_name=True)","8168fa18":"# #loading already trained first 20 epoch\n# model.load_weights(\"\/kaggle\/input\/phi4-first20epoch\/model.h5\",by_name=True)","c3e8badd":"for i in range(1, [227, 329, 329, 374, 464, 566, 656][phi]):\n    model.layers[i].trainable = False","6a23bf3a":"model.compile(optimizer=Adam(lr=1e-3), loss={\n    'regression': smooth_l1(),\n    'classification': focal()\n}, )","c77fe89f":"%%time\n\nmodel.fit_generator(\n        generator=train_generator,\n        epochs=1 ### CHANGE number of Epochs here\n    )","ae6bbb9f":"cd \/kaggle\/working\/","78d48858":"model.save('model.h5')","a667c6a9":"#prediction_model.load_weights('\/kaggle\/working\/model.h5', by_name=True)\n\n#uncomment the above line, i am using already trained 20 epochs model\nprediction_model.load_weights('\/kaggle\/input\/phi4-first20epoch\/model.h5', by_name=True)","c7efe284":"score_threshold = 0.7\nresult_data = []\nfor image_path in glob.glob('\/kaggle\/input\/global-wheat-detection\/test\/*.jpg'):\n    try:\n        image_name = image_path.split('\/')[-1]\n        image = cv2.imread(image_path)\n        #image = cv2.imread(\"\/kaggle\/input\/customimgtest\/test.png\")\n        src_image = image.copy()\n        # BGR -> RGB\n        image = image[:, :, ::-1]\n        h, w = image.shape[:2]\n\n        image = preprocess_image(image)               \n        boxes, scores, labels = prediction_model.predict_on_batch([np.expand_dims(image, axis=0)])\n        boxes, scores, labels = np.squeeze(boxes), np.squeeze(scores), np.squeeze(labels)    \n        boxes = postprocess_boxes(boxes=boxes, height=h, width=w)\n        indices = np.where(scores[:] > score_threshold)[0]\n        boxes = boxes[indices]   \n        row = [image_name.replace('.jpg','')]\n        r_boxes = \"\"\n        if(len(boxes) > 0):\n            for s,b in zip(scores, boxes):\n                if r_boxes != \"\":\n                    r_boxes += \" \"\n                r_boxes += f\"{round(float(s),2)} {int(b[0])} {int(b[1])} {int(b[2]-b[0])} {int(b[3]-b[1])}\"\n            row.append(r_boxes)\n        else:\n            row.append(\"\")\n        result_data.append(row)\n    except:\n        result_data.append([image_name.replace('.jpg',''),\"\"])\n\ntest_df = pd.DataFrame(result_data, columns=['image_id','PredictionString'])\ntest_df.to_csv(\"submission.csv\",index=False)\ntest_df.head()","6d94b765":"from matplotlib import pyplot as plt\n\ndef chunks(lst, n):\n    for i in range(0, len(lst), n):\n        yield lst[i:i + n]\n\nname = '53f253011'        \n        \ntest_df['PredictionString'] = test_df['PredictionString'].apply(lambda a: a.split(' ')).apply(lambda myList: [x for i, x in enumerate(myList) if i%5 !=0])\nlst1 = test_df[test_df['image_id'] == name]['PredictionString'].values[0]\nlst1 = list(map(int, lst1))     \nlst1_n = list(chunks(lst1, 4))\n\nsample = plt.imread('\/kaggle\/input\/global-wheat-detection\/test\/' + name + '.jpg')\n\nfig, ax = plt.subplots(1, 1, figsize=(16, 8))\nfor box in lst1_n:\n    cv2.rectangle(sample,\n                  (box[0], box[1]),\n                  (box[2] + box[0], box[3] + box[1]),\n                  (0, 0, 100), 2)\nax.set_axis_off()\nax.imshow(sample)","7a97e191":"### Loading pretrained efficientNet weights","3778bfd7":"### TEST","d0a33932":"### Converting the string bbox to it's x,y w and h","ad996490":"## Building the EfficientDet"}}