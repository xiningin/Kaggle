{"cell_type":{"0cd81b66":"code","97775033":"code","1510eaa3":"code","ef05c23e":"code","1d86fe13":"code","cb9065bd":"code","297a8e6c":"code","18e4dfab":"code","b7a74de9":"code","c013ca50":"code","c6d7772b":"code","218d2689":"code","a804e688":"code","d1eca9a9":"code","313dc382":"code","82855e88":"code","6dabdb9c":"code","b3cd7dc4":"code","db14e8eb":"code","72ec7d5f":"code","3d695eb8":"code","dc8305cd":"code","82b4143f":"code","bc695e5e":"code","dd6fa40d":"code","74508f34":"code","c25212dd":"code","14981469":"code","b39bc969":"code","7faf1801":"code","f42e181b":"code","b9d84c72":"code","6cac0434":"code","1541228a":"code","34c179a9":"code","337a65fd":"code","5307e05f":"code","43deb50f":"code","740e3210":"code","bc7f6b09":"code","9eb3a8a5":"code","41e4e0b7":"code","3d240446":"code","0eb6663b":"code","85bf7fd2":"code","36769fb2":"code","1a8b7058":"code","1c9ad895":"code","138ee514":"code","c7f34ffe":"code","1a4cfb4b":"code","5cc5c170":"code","4bfdeba7":"code","5f0693ca":"code","f0615ca8":"code","bf854697":"code","a000f69b":"code","4c28060e":"code","d4fd30e4":"code","3bba3981":"code","f5be9c9b":"code","49b063dd":"code","263ec949":"code","781968ef":"markdown","132d5f2c":"markdown","8baed212":"markdown","82bcb5b0":"markdown","2a247d90":"markdown","c7c717b4":"markdown","dbf72320":"markdown","15a467e5":"markdown","1ed0c8a7":"markdown","f9aeb9eb":"markdown","c34dd023":"markdown","c06923eb":"markdown","d5c77e3b":"markdown","ca09a5da":"markdown","30e6c0ce":"markdown","5e078d83":"markdown","1fe8dd5e":"markdown","76c459ac":"markdown","afedc5ea":"markdown","ad880626":"markdown","86262074":"markdown","0bc53ca2":"markdown","7cc7c641":"markdown","b235c9bd":"markdown","fb799799":"markdown","dddfb702":"markdown","1c4e9b02":"markdown","d91824a0":"markdown","427fc1e4":"markdown","aa2924b1":"markdown","571f7d67":"markdown","fafe3ed1":"markdown","e0100df0":"markdown","ada3d948":"markdown","7bcc81bd":"markdown","a03f5e69":"markdown","d59b5db2":"markdown","fad8b84a":"markdown","36c0b234":"markdown","3ac1af96":"markdown","0e68fa18":"markdown"},"source":{"0cd81b66":"#importing necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nimport plotly.express as pe\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nfrom statsmodels.graphics.regressionplots import influence_plot\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline","97775033":"#Reading the CSV file\n\ndata = pd.read_csv('..\/input\/car-price-prediction\/CarPrice_Assignment.csv')\n","1510eaa3":"#Creating a DataFrame for the CarPrice data\ncarprice_df = pd.DataFrame(data)\ncarprice_df.head()","ef05c23e":"#Undetanding the shape and data types of the data\ncarprice_df.info()","1d86fe13":"# Number of Unique Values in each categorical column\ncarprice_df.select_dtypes(exclude = np.number).nunique()","cb9065bd":"#Splitting the carName column into Company and Model name\ncar_name_df = carprice_df.CarName.str.split(n = 1, expand = True)\ncarprice_df.insert(loc = 2,column = \"car_name\", value = car_name_df[1])\ncarprice_df.insert(loc = 2,column = \"car_company\", value = car_name_df[0])\ncarprice_df.drop(columns = \"CarName\", inplace = True)\ncarprice_df.head()","297a8e6c":"# Number of Unique Values in each categorical column\ncarprice_df.select_dtypes(exclude = np.number).nunique()","18e4dfab":"#Dropping the car_name or model name column due to high cardinality\n\ncarprice_df.drop(columns = [\"car_name\"], inplace = True)\nprint(\"car_name column dropped from the dataframe\")","b7a74de9":"#Unique values of each categorical column\ncolumns = list(carprice_df.select_dtypes(exclude =  np.number).columns)\nfor i in columns:\n    print(f\"{i.upper()}: {' , '.join(carprice_df[i].unique())} \\n\")","c013ca50":"#Removing error from names of car companies\nprint(f\"Unique values before cleaning: {carprice_df.car_company.nunique()}\")\ncarprice_df.car_company.replace(to_replace = [\"alfa-romero\",\"Nissan\",\"porcshce\", \"toyouta\",\"maxda\", \"vokswagen\", \"vw\"], \n                                value = [\"alfa-romeo\",\"nissan\", \"porsche\",\"toyota\",\"mazda\", \"volkswagen\",\"volkswagen\"], \n                                inplace = True)\nprint(f\"Unique values after cleaning : {carprice_df.car_company.nunique()}\")","c6d7772b":"#Checking the numeric columns or features\ncarprice_df.describe(percentiles= [0.25, 0.50, 0.75, 0.95])","218d2689":"# Number of unique values in each numeric column\n\ncarprice_df.select_dtypes(include = np.number).nunique()","a804e688":"#Setting the index of the dataframe as car_id as it has all unique values.\n\ncarprice_df = carprice_df.set_index(\"car_ID\")\ncarprice_df.head()","d1eca9a9":"#Understanding the Symboling feature\ncarprice_df.symboling.unique()","313dc382":"#Using Z-Score to detect outliers\nfrom scipy.stats import zscore\nindex = carprice_df[abs(zscore(carprice_df[\"price\"]))>=3].index\nindex","82855e88":"#Removing Outliers\ncarprice_df.drop(index, inplace = True)\nprint(\"Outliers Removed Successfully\")","6dabdb9c":"#Plot 1\nfig = make_subplots(rows =2, cols = 2, subplot_titles = [\"Distribution of Price W.R.T Car compnay\",\n                                                        \"Distribution of Car Company\",\n                                                        \"Distribution of Price W.R.T Fuel System\",\n                                                        \"Distribution of Fuel System\"])\nfig.add_trace(go.Box(x = carprice_df[\"car_company\"], y = carprice_df[\"price\"], name = \"Car Company\"),\n              row = 1, col =1)\nfig.add_trace(go.Histogram(x = carprice_df[\"car_company\"], histnorm = \"percent\", name = \"Car Company\"),\n              row = 1, col =2)\nfig.add_trace(go.Box(x = carprice_df[\"fuelsystem\"], y = carprice_df[\"price\"], name = \"Fuel System\"),\n              row = 2, col =1)\nfig.add_trace(go.Histogram(x = carprice_df[\"fuelsystem\"], histnorm = \"percent\", name = \"Fuel System\"),\n              row = 2, col =2)\nfig.update_layout(height = 700,\n                 xaxis1 = dict(title = \"Car company\"),\n                 xaxis2 = dict(title = \"Car compnay\"),\n                 xaxis3 = dict(title = \"Fuel System\"),\n                 xaxis4 = dict(title = \"Fuel System\"),\n                 yaxis1 = dict(title = \"Price\"),\n                 yaxis2 = dict(title = \"Percentage\"),\n                 yaxis3 = dict(title = \"Price\"),\n                 yaxis4 = dict(title = \"Percentage\"))\nfig.show()","b3cd7dc4":"#Plot 2\nfig = make_subplots(rows =2, cols = 2, subplot_titles = [\"Distribution of Price W.R.T Fuel Type\",\n                                                        \"Distribution of Fuel Type\",\n                                                        \"Distribution of Price W.R.T Car Body\",\n                                                        \"Distribution of Car Body\"])\nfig.add_trace(go.Box(x = carprice_df[\"fueltype\"], y = carprice_df[\"price\"], name = \"Fuel Type\" ),\n              row = 1, col =1)\nfig.add_trace(go.Histogram(x = carprice_df[\"fueltype\"], histnorm = \"percent\", name = \"Fuel Type\"),\n              row = 1, col =2)\nfig.add_trace(go.Box(x = carprice_df[\"carbody\"], y = carprice_df[\"price\"], name = \"Car Body\"),\n              row = 2, col =1)\nfig.add_trace(go.Histogram(x = carprice_df[\"carbody\"], histnorm = \"percent\", name = \"Car Body\"),\n              row = 2, col =2)\nfig.update_layout(height = 700,\n                 xaxis1 = dict(title = \"Fuel Type\"),\n                 xaxis2 = dict(title = \"Fuel Type\"),\n                 xaxis3 = dict(title = \"Car Body\"),\n                 xaxis4 = dict(title = \"Car Body\"),\n                 yaxis1 = dict(title = \"Price\"),\n                 yaxis2 = dict(title = \"Percentage\"),\n                 yaxis3 = dict(title = \"Price\"),\n                 yaxis4 = dict(title = \"Percentage\"))\nfig.show()","db14e8eb":"#Plot 3\nfig = make_subplots(rows =2, cols = 2, subplot_titles = [\"Distribution of Price W.R.T Drive Wheel\",\n                                                        \"Distribution of Driv Wheel\",\n                                                        \"Distribution of Price W.R.T Cylinder Count\",\n                                                        \"Distribution of Cylinder Count\"])\nfig.add_trace(go.Box(x = carprice_df[\"drivewheel\"], y = carprice_df[\"price\"], name = \"Drive Wheel\" ),\n              row = 1, col =1)\nfig.add_trace(go.Histogram(x = carprice_df[\"drivewheel\"], histnorm = \"percent\", name = \"Drive Wheel\"),\n              row = 1, col =2)\nfig.add_trace(go.Box(x = carprice_df[\"cylindernumber\"], y = carprice_df[\"price\"], name = \"Cylinder Count\"),\n              row = 2, col =1)\nfig.add_trace(go.Histogram(x = carprice_df[\"cylindernumber\"], histnorm = \"percent\", name = \"Cylinder Count\"),\n              row = 2, col =2)\nfig.update_layout(height = 700,\n                 xaxis1 = dict(title = \"Drive Wheel\"),\n                 xaxis2 = dict(title = \"Drive Wheel\"),\n                 xaxis3 = dict(title = \"Cylinder Count\"),\n                 xaxis4 = dict(title = \"Cylinder Count\"),\n                 yaxis1 = dict(title = \"Price\"),\n                 yaxis2 = dict(title = \"Percentage\"),\n                 yaxis3 = dict(title = \"Price\"),\n                 yaxis4 = dict(title = \"Percentage\"))\nfig.show()","72ec7d5f":"#Boxplot to study variation in price of cars with respect to other features\nfig = make_subplots(rows =2, cols = 2, subplot_titles = [\"Distribution of Price W.R.T Engine Location\",\n                                                        \"Distribution of Engine Location\",\n                                                        \"Distribution of Price W.R.T Engine Type\",\n                                                        \"Distribution of Engine Type\"])\nfig.add_trace(go.Box(x = carprice_df[\"enginelocation\"], y = carprice_df[\"price\"], name = \"Engine Location\" ),\n              row = 1, col =1)\nfig.add_trace(go.Histogram(x = carprice_df[\"enginelocation\"], histnorm = \"percent\", name = \"Engine Location\"),\n              row = 1, col =2)\nfig.add_trace(go.Box(x = carprice_df[\"enginetype\"], y = carprice_df[\"price\"], name = \"Engine Type\"),\n              row = 2, col =1)\nfig.add_trace(go.Histogram(x = carprice_df[\"enginetype\"], histnorm = \"percent\", name = \"Engine Type\"),\n              row = 2, col =2)\nfig.update_layout(height = 700,\n                 xaxis1 = dict(title = \"Engine Location\"),\n                 xaxis2 = dict(title = \"Engine Location\"),\n                 xaxis3 = dict(title = \"Engine Type\"),\n                 xaxis4 = dict(title = \"Engine Type\"),\n                 yaxis1 = dict(title = \"Price\"),\n                 yaxis2 = dict(title = \"Percentage\"),\n                 yaxis3 = dict(title = \"Price\"),\n                 yaxis4 = dict(title = \"Percentage\"))\nfig.show()","3d695eb8":"#Correlation between various numeric features depicted using a heatmap\nplt.figure(figsize = (10,8))\nfig = sns.heatmap(carprice_df.corr(), annot = True)\nplt.show()","dc8305cd":"#Label encoding the column number of cylinders\n\ncarprice_df[\"cylindernumber\"] = carprice_df.cylindernumber.map({\"two\": 0, \"three\": 1, \"four\": 2, \"five\" : 3, \"six\" : 4, \"eight\": 5, \"twelve\": 6})\nprint(f\"Cylinder Number column encoded as {carprice_df['cylindernumber'].unique()}\")","82b4143f":"#function to encode variables with high cardinality\n\ndef encoder(column_name):    \n    #Storing the median price values for each category in a datframe \n    median_price = carprice_df.groupby(column_name)[\"price\"].median().to_frame().reset_index()\n    median_price.sort_values(by = \"price\", inplace = True) #Sorting the frame\n    median_price[\"price\"]  = median_price[\"price\"].map({i: index for index, i in enumerate(median_price[\"price\"])}) #Mapping with non-negative integers\n    median_price = median_price.set_index(column_name) #Again set the index to category names\n    median_price = median_price.to_dict() #Convert the frame back to dictionary\n    median_price  = median_price[\"price\"] #Storing the dictionary with price values as the mapped dictionary is the value of price key\n    return median_price #Returning the map or dict","bc695e5e":"#Encoding Engine type variable\nenginetype_dict = encoder(\"enginetype\") #Storing enginetype_map in enginetype_dict for reference\ncarprice_df[\"enginetype\"] = carprice_df.enginetype.map(enginetype_dict) #mapping the labels\n#Encoding Fuel System Variable\nfuelsystem_dict = encoder(\"fuelsystem\") #Storing dict for fuelsystem in fuelsystem_dict for reference\ncarprice_df[\"fuelsystem\"] = carprice_df.fuelsystem.map(fuelsystem_dict) #mapping the labels\n#Encoding Carbody varibale\ncarbody_dict = encoder(\"carbody\") #Storing dict for carbody in carbody_dict for reference\ncarprice_df[\"carbody\"] = carprice_df.carbody.map(carbody_dict) #Mapping the labels","dd6fa40d":"print(f\"{enginetype_dict}\\n\")\nprint(f\"{fuelsystem_dict}\\n\")\nprint(carbody_dict)","74508f34":"#Encoding Car_company variable using similar technique as used above.\n\n#Storing the median prices of cars for respective companies in a dataframe\nmedian_price = carprice_df.groupby(\"car_company\")[\"price\"].median().to_frame().reset_index()\n#Using the cut function to create three price segements low, mid and high range\nmedian_price[\"price\"] = pd.cut(median_price[\"price\"],bins = [0,10000,20000,50000], labels = [\"low range\", \"mid range\", \"high range\"])\nprint(f\"Use this encoding for reference: {median_price}\")\nmedian_price = median_price.set_index(\"car_company\") #Resetting the index to car_company\nmedian_price  = median_price.to_dict() #Storing the data frame a dictionary\nmedian_price = median_price[\"price\"] #Storing the dictionary with price values as the mapped dictionary is the value of price key\ncarprice_df[\"car_company\"] = carprice_df.car_company.map(median_price) #Mapping th values to car_company column\n","c25212dd":"#Finally creating dummy variable for all the categorical variables and dropping the first column of all to avoid multicolinearity\nprint(f\"Number of columns before Dummy encoding - {carprice_df.shape[1]}\")\ncarprice_df = pd.get_dummies(carprice_df, drop_first = True)\nprint(f\"Number of columns after Dummy encoding - {carprice_df.shape[1]}\")","14981469":"carprice_df.head()","b39bc969":"#Splitting the dataset in train and test dataset in a ratio of 70-30\ntrain_df, test_df = train_test_split(carprice_df, train_size = 0.7, random_state = 42)","7faf1801":"#Scaling the training dataset\nscaler = MinMaxScaler() #Creating a MinMaxScaler object\ntrain_df.loc[:,:] = scaler.fit_transform(train_df.loc[:,:]) #Fitting and transforming the dataset","f42e181b":"#Creating x_train and y_train\ny_train = train_df.pop(\"price\") #Storing the response variable price in y_train\nx_train = train_df","b9d84c72":"#Creating a LinearRegression model using sklearn as we can find the features using RFE only after fitting a model\nlm = LinearRegression() #Creating Linear Regression Object\nlm_model = lm.fit(x_train, y_train) #Fitting the model","6cac0434":"#Using Recursive Feature Elimination to pick top 10-15 features and ranking them\nrfe = RFE(lm_model, 15).fit(x_train,y_train) #Creating a RFE object and then fitting it on training data\nlist(zip(train_df.columns, rfe.support_, rfe.ranking_)) #Name of feature along with the ranking give to it by the RFE object","1541228a":"#Storing the selected features in a variable\ncols = list(train_df.columns[rfe.support_])\nx_train = sm.add_constant(train_df[cols]) #Adding a constant for the intercept term in the x_train","34c179a9":"ols_model = sm.OLS(y_train, x_train).fit() #Creating and fitting the OLS model on the training set\n\nols_model.summary2() #Viewing the summary statistics","337a65fd":"#Check for multicolinearity\nvif = pd.DataFrame() #Creating a new dataframe\nvif[\"Features\"] = cols #Storing the column names as a column in vif dataframe\nvif[\"VIF\"] = [variance_inflation_factor(x_train[cols].values, i) for i in range(x_train.shape[1]-1)] #Computing VIF for each variable\nvif","5307e05f":"cols.remove(\"carlength\")\nx_train = sm.add_constant(train_df[cols])\n#Model fitting\nols_model = sm.OLS(y_train, x_train).fit()\nols_model.summary2()","43deb50f":"vif = pd.DataFrame()\nvif[\"Features\"] = cols\nvif[\"VIF\"] = [variance_inflation_factor(x_train[cols].values, i) for i in range(x_train.shape[1]-1)]\nvif","740e3210":"cols.remove(\"cylindernumber\")\nx_train = sm.add_constant(train_df[cols])\n\nols_model = sm.OLS(y_train, x_train).fit()\nols_model.summary2()","bc7f6b09":"vif = pd.DataFrame()\nvif[\"Features\"] = cols\nvif[\"VIF\"] = [variance_inflation_factor(x_train[cols].values, i) for i in range(x_train.shape[1]-1)]\nvif","9eb3a8a5":"cols.remove(\"highwaympg\")\nx_train = sm.add_constant(train_df[cols])\n\nols_model = sm.OLS(y_train, x_train).fit()\nols_model.summary2()","41e4e0b7":"vif = pd.DataFrame()\nvif[\"Features\"] = cols\nvif[\"VIF\"] = [variance_inflation_factor(x_train[cols].values, i) for i in range(x_train.shape[1]-1)]\nvif","3d240446":"cols.remove(\"boreratio\")\nx_train = sm.add_constant(train_df[cols])\n\nols_model = sm.OLS(y_train, x_train).fit()\nols_model.summary2()","0eb6663b":"vif = pd.DataFrame()\nvif[\"Features\"] = cols\nvif[\"VIF\"] = [variance_inflation_factor(x_train[cols].values, i) for i in range(x_train.shape[1]-1)]\nvif","85bf7fd2":"cols.remove(\"horsepower\")\nx_train = sm.add_constant(train_df[cols])\n\nols_model = sm.OLS(y_train, x_train).fit()\nols_model.summary2()","36769fb2":"vif = pd.DataFrame()\nvif[\"Features\"] = cols\nvif[\"VIF\"] = [variance_inflation_factor(x_train[cols].values, i) for i in range(x_train.shape[1]-1)]\nvif","1a8b7058":"cols.remove(\"carheight\")\nx_train = sm.add_constant(train_df[cols])\n\nols_model = sm.OLS(y_train, x_train).fit()\nols_model.summary2()","1c9ad895":"vif = pd.DataFrame()\nvif[\"Features\"] = cols\nvif[\"VIF\"] = [variance_inflation_factor(x_train[cols].values, i) for i in range(x_train.shape[1]-1)]\nvif","138ee514":"cols.remove(\"carwidth\")\nx_train = sm.add_constant(train_df[cols])\n\nols_model = sm.OLS(y_train, x_train).fit()\nols_model.summary2()","c7f34ffe":"vif = pd.DataFrame()\nvif[\"Features\"] = cols\nvif[\"VIF\"] = [variance_inflation_factor(x_train[cols].values, i) for i in range(x_train.shape[1]-1)]\nvif","1a4cfb4b":"cols.remove(\"fueltype_gas\")\nx_train = sm.add_constant(train_df[cols])\n\nols_model = sm.OLS(y_train, x_train).fit()\nols_model.summary2()","5cc5c170":"vif = pd.DataFrame()\nvif[\"Features\"] = cols\nvif[\"VIF\"] = [variance_inflation_factor(x_train[cols].values, i) for i in range(x_train.shape[1]-1)]\nvif","4bfdeba7":"cols.remove(\"carbody\")\nx_train = sm.add_constant(train_df[cols])\n\nols_model = sm.OLS(y_train, x_train).fit()\nols_model.summary2()","5f0693ca":"vif = pd.DataFrame()\nvif[\"Features\"] = cols\nvif[\"VIF\"] = [variance_inflation_factor(x_train[cols].values, i) for i in range(x_train.shape[1]-1)]\nvif","f0615ca8":"cols.remove(\"aspiration_turbo\")\nx_train = sm.add_constant(train_df[cols])\n\nols_model = sm.OLS(y_train, x_train).fit()\nols_model.summary2()","bf854697":"vif = pd.DataFrame()\nvif[\"Features\"] = cols\nvif[\"VIF\"] = [variance_inflation_factor(x_train[cols].values, i) for i in range(x_train.shape[1]-1)]\nvif","a000f69b":"#Check for Normality- Whether the residual follow a normal distribution or not\nsns.distplot(ols_model.resid)\nplt.title(\"P-P Plot\")\nplt.show()","4c28060e":"#Test for Homoscedasticity - Whether the variance of errors is constant or not.\nplt.scatter(x = ols_model.fittedvalues, y = ols_model.resid) #Scatter Plot between Fitted Values and Residuals\nplt.title(\"Fitted Price values VS Errors\")\nplt.xlabel(\"Normalized Fitted Values\")\nplt.ylabel(\"Normalized Residuals\")\nplt.show()","d4fd30e4":"#Tranforming the test dataframe using the scaler object. We do not fit the frame again as we already fitted it on the train set\ntest_df.loc[:,:] = scaler.transform(test_df)","3bba3981":"#Creating y_test and x_test\ny_test = test_df.pop(\"price\")\nx_test = test_df[cols]\nx_test = sm.add_constant(x_test)","f5be9c9b":"#Storing predicted values for y in y_pred\ny_pred = ols_model.predict(x_test)","49b063dd":"#Checking model performance using r2_score method\nprint(f\"The Coefficient of determination for test set is {round(r2_score(y_test, y_pred),3)}\")","263ec949":"#Checking the mean squared error\nprint(f\"The mean squared error for the test set is {round(mean_squared_error(y_test,y_pred),3)}\")","781968ef":"Variance Inflation Factor is used to check if there is multicolinearity amongst independent variables.","132d5f2c":"#### Model 8\nRemoving the `carwidth` feature","8baed212":"## Exploratory Data Anlaysis\nUnderstanding the variation in price of car due to various factors and learning the correlation between numerous numeric features.","82bcb5b0":"### Outlier Analysis\n- Remove observations with extreme values","2a247d90":"#### Model 2\nRemoving `carlength` featuren due to high VIF","c7c717b4":"#### Final Model\nLastly we remove the `aspiration_turbo` feature due to high p-value.","dbf72320":"There is high correlation amongst variables such as car length, car width, car height, curbweight, etc.\n","15a467e5":"# Geely Auto - A Chinese Automobile Company\n\nThe company aspires to enter the US market by setting up their manufacturing unit in USA and produce cars locally to give compete in the US market against its counterparts. ","1ed0c8a7":"- Rear Wheel drive cars are priced higher than front wheel and all wheel drive cars.\n- Increase in the number of cylinders in the engine is associated with the increase in price of a car.","f9aeb9eb":"#### Model 1","c34dd023":"### Residual Analysis\nWe will verify the assumptions for residuals made before model builing","c06923eb":"The plot suggests that the residuals are approximately normally distributed.","d5c77e3b":"- Different companies have cars in different price segments.\n- Companies such as Mercury and Renault have very few models in the data set.\n- There is considerable difference in the median prices of cars for different fuel systems.\n- More than 75% of models are fitted with MPFI and 2BBL fuel systems.\n","ca09a5da":"- Cars with engine located at the rear are priced almost 3x more than the ones with engine in front.","30e6c0ce":"The R-sqaured value of train set and test set is very close and the value of Mean Squared Error is approximately 0. Hence from the value of R-squared and mean Squared Error it is evident that the model is performing very well. ","5e078d83":"There are a total of 205 observations with no missing values.","1fe8dd5e":"#### Model 6\nIt is worth mentioning here that although curbweigth has highest multicolinearity as of now we still do not remove it as it explains high variation in the prices of cars which can be inferred from its coefficient in the model.\nHence we remove `horsepower`.","76c459ac":"#### Model 7\nRemove the `carheight` feature","afedc5ea":" In the above method we use the median price of cars for each category to retrive a sorted order of the categories which then are label encoded and mapped with the categories to include in the model. This helps us limit the number of dimensions and is reliable. Using Dummy variables increases the dimensions which makes our model unreliable as we have a very limited set of observations.","ad880626":"Finally we have selected top 5 features with low multicolinearity and high significance.\nFeatures are curbweight, compressionratio, car_company_low range, car_company_mid range and enginelocation_rear. Although Compression Rate has very less association with pricing of a car. Hence we can consider only remaining four for our objective.","86262074":"`Symboling` corresponds to the degree by which the automoblie is more `risky` than its price indicates. The higher the rating the riskier. Although this feature is of numeric datatype we can use it as a `categorical one of ordinal scale`. We will not be required to encode the feature as it is already in encoded format. ","0bc53ca2":"### Conclusion\nCurbweight of a car, location of the engine and the range operated in by the company of a car have a strong influence on the pricing of a car. If an engine is located at the rear end of the car it positively influences the price as cars with rear engines are Rear Wheel Drives and are mainly find in high end racing cars for better steering and other benefits. Also if a car is manufactured by car companies like Honda or Toyota, its price would be generally less than the of a car manufactured by companies like BMW and Porche. Hence a negative association between car price and low - mid range car companies.","7cc7c641":"## Reading data","b235c9bd":"## Analysis Workflow \n![image.png](attachment:image.png)","fb799799":"## Objectives for analysis\n- Find suitable variables that tend to influence the prices of a car in the US market.\n- Estimate how much of the variation in prices can be explained by those variables or factors.","dddfb702":"## Feature Encoding\nConverting categorical variables into numeric types using techniques like Dummy encoding, label encoding and others.\nThis will allow us to use categorical variables in the Regression model.","1c4e9b02":"- Diesel cars are more expensive then gas cars in general.\n- 90% of the car models run on gas.\n- Convertibles are the most expensive ones.\n- More than 80% of the models fall in sedan or hatchback category.","d91824a0":"#### Model 9\nRemoving the `fueltype_gas` feature due to high VIF","427fc1e4":"## Data Preprocessing\n- Exploring Data\n- Cleaning Data\n- Deriving New Metrics","aa2924b1":"Categorical variables have been cleaned with no errors remaining. We will further treat the categorical variables during feature encoding.","571f7d67":"## Business Goal\nTo model the price of cars with the available information about different cars in the US market. It will then help the management to understand the variation in prices due to different features which can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels.","fafe3ed1":"### Model Validation\nPredicting the Y values for test data set and computing R2_score and Mean Squared Error to check performance","e0100df0":"### Numerical Variables","ada3d948":"#### Model 3\nRemoving `cylindernumber` feature due to high VIF","7bcc81bd":"#### Model 4\nRemoving `highwaympg` feature due to high VIF","a03f5e69":"## Feature Scaling, Selection and Model Building\n\n### Feature Scaling\nWe are scaling features to make better inferences of the infulence of independent variables on the dependent variable. This will bring down the training data in the range of `0-1`.\nUsing `MinMaxScaler` method of Sklearn.\n\n### Feature Selection\nWe are taking a hybrid approach using `Recursive Feature Selection` technique to filter top 10-15 influencers and then using `Backward Elimination` to drop each insignificant variable to find the top influencers.\n\n### Model Building\nWe are using `Gauss Markov Theorem` to find the best fit model and `Variance Inflation Factor` to check for `multicolinearity`.\n\n<b>Repeating the process of model building to remove irrelevant features until significant features are found and multicolinearity is removed.","d59b5db2":"#### Model 10\nRemoving the `carbody` feature due to high p-value which renders the variable statistically insignificant.","fad8b84a":"In the above encoding we divide car manufacturers into Low, Mid and High Price car maker segments to tackle high cardinality.","36c0b234":"All the numeric values seem to be okay for the analysis i.e. there are no extreme values apart from the price column. We will further study the price column separtely.","3ac1af96":"### Categorical Variables","0e68fa18":"#### Model 5\nRemoving `boreratio` feature due to high VIF"}}