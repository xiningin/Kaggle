{"cell_type":{"b6f599f7":"code","c48f1386":"code","1880831e":"code","bc106e67":"code","70ffecff":"code","67838e09":"code","56375c69":"code","538b61de":"code","7d4a1887":"code","a08ae348":"code","f15ee83f":"code","e112a70c":"code","3e2710be":"code","b348b694":"code","abda743d":"code","1e14aa65":"code","f7c28d18":"code","bdaf609f":"code","e84a50cb":"code","112c78ed":"markdown","304e373e":"markdown","31d23820":"markdown","832ffd79":"markdown","f4eaa358":"markdown","a78252d8":"markdown","a11cf014":"markdown","bfdf1c1b":"markdown","8502325c":"markdown","a71a10b1":"markdown","cfd078fc":"markdown","7266b7fb":"markdown","a2ff140b":"markdown","45803dad":"markdown","8d1b936c":"markdown","6d92eba5":"markdown","ad06a503":"markdown","a88f00cd":"markdown","43268c43":"markdown","f0636b08":"markdown","3fd868a0":"markdown","c4500e39":"markdown","4a432384":"markdown","3df14b6f":"markdown","d92ffe69":"markdown","09db5199":"markdown","92b9bc3b":"markdown"},"source":{"b6f599f7":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","c48f1386":"df = pd.read_csv('..\/input\/StudentsPerformance.csv')\ndf.head()","1880831e":"print('Shape of dataframe:', df.shape)","bc106e67":"df.isnull().sum()","70ffecff":"# 1\ndf.columns = ['gender', 'race', 'parent_education', 'lunch', 'test_prep', 'math_score', 'reading_score', 'writing_score']\n\n# 2\ndf['race'] = df.race.apply(lambda x: x[-1])\n\n# 3\ndf['avg_score'] = (df['math_score'] + df['reading_score'] + df['writing_score']) \/ 3\n\ndf.head()","67838e09":"# count of each parent_education entry\ndf.groupby(['parent_education']).gender.count()","56375c69":"df['parent_education'] = df.parent_education.apply(lambda x: 'high school' if x == 'some high school' else ('college' if x == 'some college' else x))\ndf.head()","538b61de":"fig, axs = plt.subplots(figsize=(22,6), ncols=3)\nfig.subplots_adjust(wspace=0.23)\n\nsns.scatterplot(x='math_score', y='reading_score', hue='gender', data=df, ax=axs[0])\nsns.scatterplot(x='math_score', y='writing_score', hue='gender', data=df, ax=axs[1])\nsns.scatterplot(x='reading_score', y='writing_score', hue='gender', data=df, ax=axs[2])","7d4a1887":"fig, axs = plt.subplots(figsize=(18,5), ncols=3)\nfig.subplots_adjust(wspace=0.3)\n\nsns.distplot(df.math_score, ax=axs[0])\nsns.distplot(df.reading_score, ax=axs[1])\nsns.distplot(df.writing_score, ax=axs[2])","a08ae348":"fig, axs = plt.subplots(figsize=(15,6), ncols=3)\nfig.subplots_adjust(wspace=0.5)\n\nsns.boxplot(x='test_prep', y='math_score', data=df, ax=axs[0], fliersize=2)\nsns.boxplot(x='test_prep', y='reading_score', data=df, ax=axs[1], fliersize=2)\nsns.boxplot(x='test_prep', y='writing_score', data=df, ax=axs[2], fliersize=2)","f15ee83f":"fig, axs = plt.subplots(figsize=(9,7))\n\nsns.boxplot(x='parent_education', y='avg_score', data=df, fliersize=0)\nsns.swarmplot(x='parent_education', y='avg_score', data=df, color='0')","e112a70c":"log_df = df.copy()\nlog_df.head()","3e2710be":"log_df['gender'] = log_df.gender.apply(lambda x: 1 if x == 'male' else 0)\nlog_df['reduced_lunch'] = log_df.lunch.apply(lambda x: 1 if x == 'free\/reduced' else 0)\nlog_df['test_prep'] = log_df.test_prep.apply(lambda x: 1 if x == 'completed' else 0)\n\n# removing 'lunch' and 'avg_score' columns\nlog_df = log_df.drop(['lunch', 'avg_score'], axis=1)\n\nlog_df.head(3)","b348b694":"race_df = pd.get_dummies(log_df.race)\ned_df = pd.get_dummies(log_df.parent_education)\nlog_df = pd.concat([log_df, race_df, ed_df], axis=1)\n\nlog_df = log_df.drop(['race', 'parent_education'], axis=1)\n\nlog_df.columns = ['gender', 'test_prep', 'math_score', 'reading_score', 'writing_score', \n                  'reduced_lunch', 'race_A', 'race_B', 'race_C', 'race_D', 'race_E', \n                  'p_associates', 'p_bachelors', 'p_college', 'p_high_school', 'p_masters']\n\nlog_df.head(3)","abda743d":"scores = ['math_score', 'reading_score', 'writing_score']\nfor i in scores:\n    log_df[i] = log_df[i]\/100\n\nlog_df.head(3)","1e14aa65":"predictors = list(log_df.columns)\npredictors.remove('gender')\n\nX_train, X_test, y_train, y_test = train_test_split(log_df[predictors], log_df['gender'], \n                                                    test_size=0.2, random_state=38)\nprint('Training data:', X_train.shape, '\\nTest data:', X_test.shape)","f7c28d18":"log = LogisticRegression()\n\n# parameter space\npenalty = ['l1', 'l2']\nC = np.logspace(0, 4, 20)\nlog_params = dict(C=C, penalty=penalty)\n\n# grid search\nlog_clf = GridSearchCV(log, log_params, cv=5, verbose=0)\nbest_log_model = log_clf.fit(X_train, y_train)\nlog_score = best_log_model.score(X_test, y_test)\n\n# tuned parameters\nprint('Best Penalty:', best_log_model.best_estimator_.get_params()['penalty'])\nprint('Best C:', best_log_model.best_estimator_.get_params()['C'])\nprint('\\nModel Accuracy:', log_score)","bdaf609f":"log_predictions = best_log_model.predict(X_test)\npd.crosstab(y_test, log_predictions, rownames=['Actual'], colnames=['Predicted'])","e84a50cb":"logistic = LogisticRegression(penalty = best_log_model.best_estimator_.get_params()['penalty'], \n                              C = best_log_model.best_estimator_.get_params()['C'])\nlogistic.fit(X_train, y_train)\n\nfeature_importance = abs(np.std(X_train, 0) * list(logistic.coef_[0]))\nn = len(feature_importance)\n\nfig, axs = plt.subplots(figsize=(12,5))\nsns.barplot(x = feature_importance.nlargest(n).index, \n            y = feature_importance.nlargest(n))\naxs.set_xticklabels(axs.get_xticklabels(), rotation=90)\naxs.set(xlabel='Feature', ylabel='Feature Importance')","112c78ed":"Notice that we have entries labelled both 'high school' and 'some high school'. These entries can be grouped into the same category.\n\nWe'll also rename 'some college' entries to 'college'.","304e373e":"Lastly, let's compare which of our features the model assigned most weight to. This will give us an idea of what features were most influential in our model's decisions.\n\nThe metric we'll use for this comparison is the magnitude of the feature's coefficient in our model, multiplied by the standard deviation of the data in the corresponding column.","31d23820":"In this notebook we'll explore the following questions:\n\n1. How effective was the test-preparation course for the students' revision?\n2. How does a student's parental education level affect their exam scores?\n3. Can we predict a student's gender based on their exam scores and other attributes?","832ffd79":"Next, there are a few changes we can make to help prepare the data for analysis, and to make it slightly more readable:\n\n1. Rename columns to a simpler form.\n2. Remove unnecessary information from 'race' column.\n3. Create an average score column to use in later analysis.","f4eaa358":"Below is a table showing how many of the model's predictions were correct.","a78252d8":"First we'll check if there are any missing entries that need to be dealt with. Luckily in this dataset there aren't.","a11cf014":"There are a few changes we must make to the data before we are ready to fit the model.","bfdf1c1b":"Now it's time to fit the model. We use scikit-learn's GridSearchCV function to find the best hyperparameters to use.\n\nThe model is trained using our training data, and then evaluated on the test data to obtain an accuracy score.","8502325c":"# **Initial Analysis**","a71a10b1":"As expected, the exam scores were the most influential features, followed by the completion of the test-preparation course.","cfd078fc":"Overall it seems that the test-preparation exam was effective revision for every subject, most affecting the scores in the writing exam.","7266b7fb":"We'll also convert the scores into decimals so that their scale is in keeping with the rest of the data. This stops the regression model from assigning skewed weight towards the score variables.","a2ff140b":"Next we need to use one-hot encoding on the 'race' and 'parent_education' columns so that the data can effectively be fed into the model.","45803dad":"# **Introduction**","8d1b936c":"# **Importing Packages & Data**","6d92eba5":"**Now we'll try to predict a student's gender based on their exam scores and other attributes.**","ad06a503":"Our target variable is 'gender', and the other features are our predictor variables.\n\nWe split the dataframe into training data (80%), and test data (20%).","a88f00cd":"**The data is now ready for us to perform some initial analysis.**","43268c43":"First, we use scatterplots to see the correlation between each of the subject scores. We can also separate these plots by gender to see how they differ.","f0636b08":"The last piece of the dataset that needs cleaning is the 'parent_education' column.","3fd868a0":"# **Logistic Regression**","c4500e39":"# **Data Cleaning & Feature Engineering**","4a432384":"We see that men tend to have a slightly higher math score than reading or writing score, and women tend to be the opposite. \n\nWe also see that no students performed extremely well in one subject and badly in another.","3df14b6f":"Below we use a boxplot to compare how much of an impact the test-preparation exam had for each subject.","d92ffe69":"First, we'll convert the 'gender', 'lunch' and 'test_prep' columns into binary. ","09db5199":"Lastly, we use another boxplot to compare how a student's parental education level affects their average exam score.","92b9bc3b":"Next we check the distributions of the scores achieved in each exam."}}