{"cell_type":{"1df16f32":"code","cd0c1d18":"code","61cb131a":"code","c33f65b2":"code","714d4cab":"code","d7d2eadc":"code","3c044c04":"code","85029342":"code","40080669":"code","42a29679":"code","f116c468":"code","3ee1024b":"code","fe0d5dd8":"code","991c4fe5":"code","5c0399a7":"code","2061c4e0":"code","3c91446b":"code","8a94b052":"code","27aced44":"markdown","978a497f":"markdown","e5f0db02":"markdown","0713da77":"markdown"},"source":{"1df16f32":"import numpy as np\nimport pandas as pd\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import KFold, GridSearchCV, train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nfrom xgboost import XGBRegressor","cd0c1d18":"seed = 1234","61cb131a":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c33f65b2":"train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jan-2021\/train.csv\", index_col=\"id\")\ntest = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jan-2021\/test.csv\", index_col=\"id\")\nsubmission = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jan-2021\/sample_submission.csv\", index_col=\"id\")","714d4cab":"# Take a look on our data\ntrain.head()","d7d2eadc":"# Get info about types of data and missing values\ntrain.info()","3c044c04":"test.info()","85029342":"# # Plot distributions of all features of both datasets\n\n# fig, axes = plt.subplots(7, 2, figsize=(15,15))\n# for ax, col in zip(axes.ravel(), train.columns[:-1]):\n#     sns.distplot(train[col], label='train', hist_kws={\"alpha\": 0.2}, ax=ax)\n#     sns.distplot(test[col], label='test', color='red', hist_kws={\"alpha\": 0.2}, ax=ax)\n#     ax.legend()\n#     plt.tight_layout()\n# plt.show()","40080669":"# # Plot boxplots for all features to find outliers\n\n# for col in train.columns[:-1]:\n#     plt.boxplot([train[col], test[col]], labels=['train', 'test'])\n#     plt.title(col)\n#     plt.legend()\n#     plt.show()","42a29679":"Q1_train = train.quantile(0.25)\nQ3_train = train.quantile(0.75)\nIQR_train = Q3_train - Q1_train\n((train < Q1_train - 1.5*IQR_train) | (train > Q3_train + 1.5*IQR_train)).agg([sum, 'mean'])","f116c468":"Q1_test = test.quantile(0.25)\nQ3_test = test.quantile(0.75)\nIQR_test = Q3_test - Q1_test\n((test < Q1_test - 1.5 * IQR_test) | (test > Q3_test + 1.5 * IQR_test)).agg([sum, 'mean'])","3ee1024b":"def replace_outliers(data):\n    for col in data.columns:\n        Q1 = data[col].quantile(0.25)\n        Q3 = data[col].quantile(0.75)\n        IQR = Q3 - Q1\n        median_ = data[col].median()\n#         data[col].mask(((data[col] < Q1 - 1.5*IQR) | (data[col] > Q3 + 1.5*IQR)), median_, inplace=True)\n        # data[col] = np.where(((data[col] < Q1 - 1.5*IQR) | (data[col] > Q3 + 1.5*IQR)),\n        #                     median_, data[col])\n        data.loc[((data[col] < Q1 - 1.5*IQR) | (data[col] > Q3 + 1.5*IQR)), col] = median_\n    return data","fe0d5dd8":"train = replace_outliers(train)","991c4fe5":"# train = train[~((train < Q1_train - 1.5*IQR_train) | (train > Q3_train + 1.5*IQR_train)).any(axis=1)]\n# test = test[~((test < Q1_test - 1.5*IQR_test) | (test > Q3_test + 1.5*IQR_test)).any(axis=1)]","5c0399a7":"X = train.drop(columns=['target'])\ny = train['target']","2061c4e0":"params = {'learning_rate': 0.1,\n           'n_estimators': 1000,\n           'max_depth': 4,\n           'min_child_weight': 6,\n           'gamma': 3.9,\n           'subsample': 0.8,\n           'colsample_bytree': 0.8,\n           'objective': 'reg:squarederror',\n           'nthread': 4,\n           'scale_pos_weight': 1,\n           'reg_alpha': 100,\n           'seed': seed\n}\nxgbr = XGBRegressor(**params)","3c91446b":"mean_error = 0\npredictions = 0\nkf = KFold(n_splits=5)\nfor num, (train_index, test_index) in enumerate(kf.split(X)):\n    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n    model = xgbr\n    model.fit(X_train, y_train)\n    error = mean_squared_error(y_test, model.predict(X_test),\n                              squared=False)\n    print(f\"{num} fold error: {error}\")\n    mean_error += error\n    predictions += model.predict(test)\n    \nprint(f\"Mean error: {mean_error \/ kf.get_n_splits(X)}\")\nresult_prediction = predictions \/ kf.get_n_splits(X)","8a94b052":"submission['target'] = result_prediction\nsubmission.to_csv('submission.csv')","27aced44":"**Both sets have similar distributions of features**","978a497f":"**We can see there is no missing values in both sets**","e5f0db02":"**The qantity of outliers in datasets is quite small - about 2 % or less - so we can drop them.**","0713da77":"**Both sets have outliers in features `cont7` and `cont9` and `train` dataset has outliers in `count10`.<br>Let's count them.**"}}