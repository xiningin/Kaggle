{"cell_type":{"1c472c1c":"code","dd4b06da":"code","46e29205":"code","9215e3d6":"code","a5dec656":"code","f802cc2d":"code","c393fca1":"code","b0332c06":"code","215e7219":"code","506800dd":"code","17b71776":"code","01ee1e54":"code","87d7b93f":"code","4957c9ba":"code","766ff772":"code","e6e72102":"code","42ede06c":"code","ed32ff83":"code","a02f34b9":"code","3c6ba4da":"code","dfe4d304":"code","77af3176":"code","aa866dc0":"code","eadf47fb":"code","7ca918b6":"code","03822b87":"code","253f2b8f":"code","6ff82df0":"code","35634c0c":"code","33056488":"code","16c09715":"code","d571287a":"code","50daedf6":"code","7622f488":"code","f5aeb116":"code","bfc66952":"code","48a41a20":"code","2942ce07":"code","b99dc500":"code","24b4269f":"code","ea66a10d":"code","469e697b":"code","feafa4c3":"code","39c74b11":"code","b3551987":"code","98f5e2ae":"code","6ccf7be7":"code","64f3cf3a":"code","42803451":"code","184abe49":"code","f7d4e710":"code","eecdb336":"code","5f053e4c":"code","691bd4bb":"code","5222bba0":"code","7e641c76":"code","d0cac8b1":"code","7b9f8933":"code","0603c723":"code","547f035d":"code","93225dc3":"code","68fef2d1":"code","07052949":"code","72452b6c":"code","6b68dee5":"code","87da0eb6":"code","d4820907":"code","26556de0":"code","52d783ae":"code","6acc7b01":"code","7eebb51d":"code","fb851135":"code","4a865819":"code","2e865b3b":"code","8a5713d1":"code","86753f4e":"code","2e79df1f":"markdown","f753e9a5":"markdown","eec8bd61":"markdown","cde87b06":"markdown","e8ec37e2":"markdown","13a55e8b":"markdown"},"source":{"1c472c1c":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","dd4b06da":"import os\nimport re\nimport cv2","46e29205":"import torch\nimport torchvision","9215e3d6":"import albumentations as A\nfrom albumentations.pytorch import ToTensor ","a5dec656":"from matplotlib.image import imread","f802cc2d":"from google.colab import drive\ndrive.mount('\/content\/drive')","c393fca1":"pwd","b0332c06":"ls","215e7219":"cd ..","506800dd":"cd input\/global-wheat-detection","17b71776":"train = pd.read_csv('train.csv')","01ee1e54":"test = pd.read_csv('sample_submission.csv')","87d7b93f":"train.head()","4957c9ba":"def append_ext(fn):\n    return fn+\".jpg\"\ntrain[\"image_id\"]=train[\"image_id\"].apply(append_ext)\n","766ff772":"train['bbox'].count()","e6e72102":"train['xmin'] = None\ntrain['ymin'] = None\ntrain['Width'] = None\ntrain['Height'] = None","42ede06c":"def expand_bbox(x):\n    r = np.array(re.findall(\"([0-9]+[.]?[0-9]*)\", x))\n    if len(r) == 0:\n        r = [-1, -1, -1, -1]\n    return r\n\ntrain[['xmin', 'ymin', 'Width', 'Height']] = np.stack(train['bbox'].apply(lambda x: expand_bbox(x)))\ntrain.drop(columns=['bbox'], inplace=True)\ntrain['xmin'] = train['xmin'].astype(np.float)\ntrain['ymin'] = train['ymin'].astype(np.float)\ntrain['Width'] = train['Width'].astype(np.float)\ntrain['Height'] = train['Height'].astype(np.float)","ed32ff83":"train.head()","a02f34b9":"train['source'].unique()","3c6ba4da":"sns.countplot(x = 'source', data=train)\n\n# THIS SHOWS THE IMBALANCE IN DATASET","dfe4d304":"sns.heatmap(train.isnull(), yticklabels=False, cbar=False, cmap='viridis')\n\n# NO NULL VALUES","77af3176":"train.head()","aa866dc0":"train.head()","eadf47fb":"train.drop('width', axis=1, inplace=True)","7ca918b6":"train.drop('height', axis=1, inplace=True)","03822b87":"pwd","253f2b8f":"data_dir = '\/kaggle\/input\/global-wheat-detection'","6ff82df0":"os.listdir(data_dir)","35634c0c":"train_path = data_dir + '\/train\/'\ntest_path = data_dir + '\/test\/'","33056488":"a = os.listdir(test_path)[0]","16c09715":"a","d571287a":"sam_test = test_path + '348a992bb.jpg'","50daedf6":"sam_tensor = imread(sam_test)","7622f488":"test_img = test_path+ '51b3e36ab.jpg'","f5aeb116":"test_img = imread(test_img)","bfc66952":"test_img.shape","48a41a20":"plt.imshow(test_img)","2942ce07":"image_shape = (224,224,3)","b99dc500":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","24b4269f":"batch_size = 64","ea66a10d":"test_image_generator = ImageDataGenerator(\n    rescale=1.\/255)","469e697b":"def append_ext(fn):\n    return fn+\".jpg\"\ntest[\"image_id\"]=test[\"image_id\"].apply(append_ext)","feafa4c3":"total_samples = 146704","39c74b11":"test_generator = test_image_generator.flow_from_dataframe(\n    dataframe = test,\n    directory=test_path,\n     x_col='image_id',\n    target_size=(1024,1024),\n    shuffle=False,\n    batch_size=8,\n    class_mode=None\n)","b3551987":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\nfrom keras.optimizers import Adam\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.metrics import *\n# v4\n\nACCURACY_LIST = []\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.models import Model","98f5e2ae":"METRICS = [\n     \n      BinaryAccuracy(name='accuracy'),\n      Precision(name='precision'),\n      Recall(name='recall'),\n      AUC(name='auc'),\n]\n\ndef output_custom_model(prebuilt_model):\n    print(f\"Processing {prebuilt_model}\")\n    prebuilt = prebuilt_model(include_top=False,\n                            input_shape=(1024,1024,3),\n                            weights='imagenet')\n    output = prebuilt.output\n    output = GlobalMaxPooling2D()(output)\n    output = Dense(128, activation='relu')(output)\n    output = Dropout(0.4)(output)\n    output = Dense(7, activation='softmax')(output)\n\n    model = Model(inputs=prebuilt.input, outputs=output)\n    model.compile(optimizer='adam', loss=categorical_crossentropy,\n              metrics=METRICS)\n    return model","6ccf7be7":"def scheduler(epoch):\n    if epoch < 5:\n        return 0.0001\n    else:\n        print(f\"Learning rate reduced to {0.0001 * np.exp(0.5 * (5 - epoch))}\")\n        return 0.0001 * np.exp(0.5 * (5 - epoch))\n    \ncustom_callback = LearningRateScheduler(scheduler)\n","64f3cf3a":"resnet_custom_model = output_custom_model(ResNet50)\n","42803451":"pwd","184abe49":"test = pd.read_csv('sample_submission.csv')","f7d4e710":"test.head()","eecdb336":"cd ..\/weights","5f053e4c":"resnet_custom_model.load_weights('wheat_detection.h5')","691bd4bb":"sam_tensor.shape","5222bba0":"sam_tensor = np.expand_dims(sam_tensor,axis=0)","7e641c76":"preds = resnet_custom_model.predict(test_generator)","d0cac8b1":"preds.min()","7b9f8933":"from itertools import chain\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.measure import label, regionprops\nfrom PIL import Image, ImageDraw\nfrom ast import literal_eval\nfrom tqdm.notebook import tqdm\n","0603c723":"IMG_WIDTH = 512\nIMG_HEIGHT = 512","547f035d":"SC_FACTOR = int(1024 \/ IMG_WIDTH)\n","93225dc3":"from tqdm.notebook import tqdm","68fef2d1":"cd ..\/global-wheat-detection","07052949":"train1 = pd.read_csv('train.csv')","72452b6c":"def make_polygon(coords):\n    xm, ym, w, h = coords\n    xm, ym, w, h = xm \/ SC_FACTOR, ym \/ SC_FACTOR, w \/ SC_FACTOR, h \/ SC_FACTOR   # scale values if image was downsized\n    return [(xm, ym), (xm, ym + h), (xm + w, ym + h), (xm + w, ym)]\n\nmasks = dict() # dictionnary containing all masks\n\nfor img_id, gp in tqdm(train1.groupby(\"image_id\")):\n    gp['polygons'] = gp['bbox'].apply(eval).apply(lambda x: make_polygon(x))\n\n    img = Image.new('L', (IMG_WIDTH, IMG_HEIGHT), 0)\n    for pol in gp['polygons'].values:\n        ImageDraw.Draw(img).polygon(pol, outline=1, fill=1)\n\n    mask = np.array(img, dtype=np.uint8)\n    masks[img_id] = mask","6b68dee5":"im = Image.fromarray(masks[list(masks.keys())[7]])\nplt.imshow(im)","87da0eb6":"def show_images(images, num=2):\n    \n    images_to_show = np.random.choice(images, num)\n\n    for image_id in images_to_show:\n\n        image_path = os.path.join(train_path, image_id + \".jpg\")\n        image = Image.open(image_path)\n  \n        # get all bboxes for given image in [xmin, ymin, width, height]\n        bboxes = [literal_eval(box) for box in train1[train1['image_id'] == image_id]['bbox']]\n\n        # visualize them\n        draw = ImageDraw.Draw(image)\n        for bbox in bboxes:    \n            draw.rectangle([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]], width=3)\n\n        plt.figure(figsize = (15,15))\n        plt.imshow(image)\n        plt.show()\n\n\nunique_images = train1['image_id'].unique()\nshow_images(unique_images)","d4820907":"THRESH = 0.3\nmasked_preds = preds > THRESH","26556de0":"def get_params_from_bbox(coords, scaling_factor=1):\n    xmin, ymin = coords[1] * scaling_factor, coords[0] * scaling_factor\n    w = (coords[3] - coords[1]) * scaling_factor\n    h = (coords[2] - coords[0]) * scaling_factor\n    \n    return xmin, ymin, w, h","52d783ae":"bboxes = list()\n\nfor j in range(masked_preds.shape[0]):\n    label_j = label(masked_preds) \n    props = regionprops(label_j)\n    bboxes.append(props)","6acc7b01":"sample_sub = pd.read_csv('sample_submission.csv')","7eebb51d":"output = dict()\nfor i in range(masked_preds.shape[0]):\n    bboxes_processed = [get_params_from_bbox(bb.bbox, scaling_factor=SC_FACTOR) for bb in bboxes[i]]\n    formated_boxes = ['1.0 ' + ' '.join(map(str, bb_m)) for bb_m in bboxes_processed]\n    #if formated_boxes:\n    #    formated_boxes = formated_boxes[0] \n    \n    output[sample_sub[\"image_id\"][i]] = \" \".join(formated_boxes)\n    #output[sample_sub[\"image_id\"][i]] = formated_boxes","fb851135":"sample_sub[\"PredictionString\"] = output.values()\n","4a865819":"sample_sub\n","2e865b3b":"cd ..","8a5713d1":"cd ..\/working","86753f4e":"sample_sub.to_csv('submission.csv', index=False)\n","2e79df1f":"image_gen = ImageDataGenerator(\n    rescale=1.\/255,\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=90,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    horizontal_flip=True,\n    zoom_range=[0.9, 1.25],\n    brightness_range=[0.5, 1.5]\n)","f753e9a5":"resnet_custom_model.save_weights('wheat_detection.h5')","eec8bd61":"train_gen = image_gen.flow_from_dataframe(\n    dataframe=train,\n    directory=train_path,\n    x_col='image_id',\n    y_col='source',\n    target_size=image_shape[:2],\n    batch_size=batch_size,\n    color_mode='rgb',\n    shuffle=True,\n    class_mode='categorical'\n)","cde87b06":"  resnet_history.history","e8ec37e2":"n_rows = 3\n\nf, ax = plt.subplots(n_rows, 3, figsize=(14, 10))\n\nfor j, idx in enumerate([4,5,6]):\n    for k, kind in enumerate(['original', 'pred', 'masked_pred']):\n        if kind == 'original':\n            img = test[idx]\n        elif kind == 'pred':\n            img = preds[idx]\n        elif kind == 'masked_pred':\n            masked_pred = preds[idx] > .75\n            img = masked_pred\n        ax[j, k].imshow(img)\n\nplt.tight_layout()","13a55e8b":"resnet_custom_model = output_custom_model(ResNet50)\nresnet_history = resnet_custom_model.fit_generator(train_gen,\n                                 epochs=1,callbacks=[custom_callback]\n                                 \n                              )"}}