{"cell_type":{"b409b021":"code","6fdac94f":"code","6358c812":"code","4377c79f":"code","562558ea":"code","83122dda":"code","6a353682":"markdown","bfeca2b2":"markdown","d0fcfa57":"markdown","8df9f7e1":"markdown","d0b7d8b2":"markdown","07e89734":"markdown","f51903e5":"markdown"},"source":{"b409b021":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import scale\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","6fdac94f":"train_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest_data = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntrain_data","6358c812":"\ny = train_data['label']\nX = train_data.drop('label', axis=1)\n","4377c79f":"pca = PCA().fit(X)\nsum_var = 0\nfor i, v in enumerate(pca.explained_variance_ratio_):\n    sum_var += v\n    if sum_var >= 0.95:\n        break\nprint(i)","562558ea":"# pca = PCA(n_components=180)\n\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\n# X_train = pca.fit_transform(X_train)\n# X_test = pca.transform(X_test)\n\n# scoresRBF = {}\n# C = np.power(10.0, np.arange(-2,3))\n# for i in C:\n#     svc = SVC(kernel='rbf',C=i)\n#     svc.fit(X_train, y_train)\n#     y_pred = svc.predict(X_test)\n#     scoresRBF[i] = accuracy_score(y_test, y_pred)\n\n# fig = plt.figure()\n# ax = fig.add_subplot(2, 1, 1)\n# line, = ax.plot(C, scoresRBF.values(), color='blue', lw=2)\n# ax.set_xscale('log')","83122dda":"pca = PCA(n_components=180)\n\nX_train = pca.fit_transform(X)\nX_test = pca.transform(test_data)\n\nsvc = SVC(kernel='rbf',C=10)\nsvc.fit(X_train, y)\ny_pred = svc.predict(X_test)\npd.DataFrame({\n    \"ImageId\": range(1,len(y_pred)+1),\n    \"Label\": y_pred\n    }).to_csv('submission.csv', index=False, header=True)","6a353682":"# Search for the regularization coefficient\n\nFor training, we will use the method of support vectors with a kernel of radial functions. The code below shows how the regularization coefficient affects accuracy. It is easy to see that the best accuracy starts with a factor of 10. We will divide the training sample into two - training and test.\n\n# \u041f\u043e\u0438\u0441\u043a \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u0430 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438\n\u0414\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u043c\u0435\u0442\u043e\u0434 \u043e\u043f\u043e\u0440\u043d\u044b\u0445 \u0432\u0435\u043a\u0442\u043e\u0440\u043e\u0432 \u0441 \u044f\u0434\u0440\u043e\u043c \u0438\u0437 \u0440\u0430\u0434\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u0444\u0443\u043d\u043a\u0446\u0438\u0439. \u041a\u043e\u0434 \u043d\u0438\u0436\u0435 \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 \u043a\u0430\u043a \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0435\u043d\u0442 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438 \u0432\u043b\u0438\u044f\u0435\u0442 \u043d\u0430 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c. \u041b\u0435\u0433\u043a\u043e \u0437\u0430\u043c\u0435\u0442\u0438\u0442\u044c, \u0447\u0442\u043e \u043d\u0430\u0438\u043b\u0443\u0447\u0448\u0430\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430\u0447\u0438\u043d\u0430\u0435\u0442\u0441\u044f \u0441 \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u0430 \u0440\u0430\u0432\u043d\u043e\u0433\u043e 10. \u041e\u0431\u0443\u0447\u0430\u044e\u0449\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \u0440\u0430\u0437\u0434\u0435\u043b\u0438\u043c \u043d\u0430 \u0434\u0432\u0435 - \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u044e \u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u0443\u044e.","bfeca2b2":"The code below runs for 5 minutes\n\u041a\u043e\u0434 \u043d\u0438\u0436\u0435 \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0435\u0442\u0441\u044f 5 \u043c\u0438\u043d\u0443\u0442","d0fcfa57":"# let's use the PCA\n\nSince there are a lot of features and they are very sparse, it makes sense to reduce the dimension using the principal component method. The code below finds the number of components that capture 95% of the variance. Their number is 153.\n\n# \u0412\u043e\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u0441\u044f \u043c\u0435\u0442\u043e\u0434\u043e\u043c \u0433\u043b\u0430\u0432\u043d\u044b\u0445 \u043a\u043e\u043c\u043f\u043e\u043d\u0435\u043d\u0442\n\u0422\u0430\u043a \u043a\u0430\u043a \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u043e\u0447\u0435\u043d\u044c \u043c\u043d\u043e\u0433\u043e \u0438 \u043e\u043d\u0438 \u043e\u0447\u0435\u043d\u044c \u0440\u0430\u0437\u0440\u0435\u0436\u0435\u043d\u044b \u0438\u043c\u0435\u0435\u0442 \u0441\u043c\u044b\u0441\u043b \u0443\u043c\u0435\u043d\u044c\u0448\u0438\u0442\u044c \u0440\u0430\u0437\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u044c \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u043c\u0435\u0442\u043e\u0434\u0430 \u0433\u043b\u0430\u0432\u043d\u044b\u0445 \u043a\u043e\u043c\u043f\u043e\u043d\u0435\u043d\u0442. \u041a\u043e\u0434 \u043d\u0438\u0436\u0435 \u043d\u0430\u0445\u043e\u0434\u0438\u0442 \u0447\u0438\u0441\u043b\u043e \u043a\u043e\u043c\u043f\u043e\u043d\u0435\u043d\u0442, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0437\u0430\u0445\u0432\u0430\u0442\u044b\u0432\u0430\u044e\u0442 95% \u043e\u0442 \u0434\u0438\u0441\u043f\u0435\u0440\u0441\u0438\u0438. \u0418\u0445 \u0447\u0438\u0441\u043b\u043e 153.","8df9f7e1":"# Final calculations and creation of submission.csv\n\nWe will perform training already on the entire training sample with the coefficients found above. The forecast result will be uploaded to the file submission.csv\n\n# \u0418\u0442\u043e\u0433\u043e\u0432\u044b\u0435 \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u044f \u0438 \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 submission.csv\n\n\u0412\u044b\u043f\u043e\u043b\u043d\u0438\u043c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0443\u0436\u0435 \u043d\u0430 \u0432\u0441\u0435\u0439 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u0441 \u043d\u0430\u0439\u0434\u0435\u043d\u043d\u044b\u043c\u0438 \u0432\u044b\u0448\u0435 \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u0430\u043c\u0438. \u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u0430 \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u043c \u0432 \u0444\u0430\u0439\u043b submission.csv","d0b7d8b2":"# Importing the necessary libraries\n\n# \u0418\u043c\u043f\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u043d\u0443\u0436\u043d\u044b\u0435 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438\n","07e89734":"# Upload training and test data\n\n# \u0417\u0430\u0433\u0440\u0443\u0437\u0438\u043c \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0435 \u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435","f51903e5":"# Let's divide the training sample into features and labels\n\n# \u0420\u0430\u0437\u0434\u0435\u043b\u0438\u043c \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \u043d\u0430 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0438 \u043c\u0435\u0442\u043a\u0438"}}