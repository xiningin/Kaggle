{"cell_type":{"05738640":"code","be33c1ac":"code","6db2a6bd":"code","c8b8da1b":"code","19c6c36f":"code","97830ce8":"code","82df7128":"code","9cbaf79a":"code","6e5cc22f":"code","4a870971":"code","17ef4de5":"code","e95629cb":"code","b3de65c1":"code","807509f1":"code","03bdc0a9":"code","b5384a48":"code","e4d53b91":"code","8ede7d04":"code","82e36f15":"code","fb8b2833":"code","40174e21":"markdown","1e8cb876":"markdown","3ac0a5e7":"markdown","e4a4e900":"markdown","6a28f1d1":"markdown","7ca190c1":"markdown","22c4d46e":"markdown","8b282d3a":"markdown","1e679d93":"markdown","9ef0bfd7":"markdown","72c2ecab":"markdown","59566783":"markdown","97f1b6a5":"markdown","f349c1ca":"markdown","0a025eee":"markdown","e0330c73":"markdown","ad8304fe":"markdown","5e72b918":"markdown","619ab00b":"markdown"},"source":{"05738640":"import pandas as pd\nimport numpy as np\nfrom time import time \n\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import CountVectorizer\n","be33c1ac":"movie_df = pd.read_csv('..\/input\/tmdb-10000-dataset\/Movie.csv', index_col = \"Unnamed: 0\") \ndisplay(movie_df.shape,\n        movie_df.head()\n       )","6db2a6bd":"# Quick overview\nmovie_df.info()","c8b8da1b":"# Get an overview of data\ncols = movie_df.columns \nfor c in cols:\n    display(pd.DataFrame(movie_df[c].value_counts()).transpose())","19c6c36f":"# Describe these numbers in more detail \nmovie_df.loc[:,'Popularity':'Vote Average'].describe() #.astype(\"int\") ","97830ce8":"# Check any duplicated rows \nmovie_df.duplicated().any()\n# Find items that are duplicated \ndup = movie_df[movie_df.duplicated()]\ndup.head()","82df7128":"# Find all duplicated overviews \nmovie_df[movie_df.Overview.isin(dup.Overview)]\n\n# Drop duplicates \nmovie_df.drop_duplicates(keep='first',inplace=True) ","9cbaf79a":"# Along the columns --  \u201caxis 0\u201d represents rows and \u201caxis 1\u201d represents columns.\nmovie_df.isnull().any(axis=0)","6e5cc22f":"# Along the rows - performs function along columns\nmovie_df[movie_df.isnull().any(axis='columns')]","4a870971":"# movie_df[movie_df['Vote Average']>7].sort_values(by = 'Popularity', ascending = False)[50:100]#[movie_df['Release Date']>str(2019)]","17ef4de5":"# Remove NaN by dropping rows\nmovie_df.dropna(inplace=True)\n\n# Also drop overviews that are unknown","e95629cb":"# If you don't reset index, it can cause confusion when selecting indices of movies \nmovie_df = movie_df[movie_df['Original Language']=='en'].reset_index(drop=True)","b3de65c1":"# Look at text as a Bag of words\nmovie_df['BagOfWords'] = movie_df[['Title','Overview']].apply(lambda col: ', '.join(col.astype(str)),axis=1)\nmovie_df['BagOfWords']","807509f1":"# Generating the counts of words for vocabulary list \ncount = CountVectorizer()\nvocab_counts = count.fit_transform(movie_df['BagOfWords'])\ndisplay(vocab_counts.shape, \n# calculate shape cosine similarity matrix\ncosine_similarity(vocab_counts,vocab_counts).shape)","03bdc0a9":"# Add stopwords, get rid of brackets, commas, lexi, etc. \nimport nltk\nfrom nltk.corpus import stopwords\ndef reduce_vocab(df):\n    # upper to lower character\n    df = df.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n    # clear punctuations\n    df = df.str.replace('[^\\w\\s]','')\n    # clear numbers\n    df = df.str.replace('\\d','')\n    # get rid of stopwords \n    sw = stopwords.words('english')\n    df = df.apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n    # Faster way to get rid of Stopwords\n    from collections import Counter\n    sw = stopwords.words('english')\n    sw_dict = Counter(sw)\n    df = df.apply(lambda x: ' '.join([x for x in x.split() if x not in sw_dict]))\n    #    #Delete rare characters \n    sil = pd.Series(' '.join(df).split()).value_counts()[-1000:]\n    # Faster way to get rid of \n    df = df.apply(lambda x: \" \".join(x for x in x.split() if x not in sil))\n#     Add spaces between text\n    from textblob import Word\n    df = df.apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()])) \n    return df","b5384a48":"# # Generating the counts of words for vocabulary list \ncount = CountVectorizer()\nvocab_counts1 = count.fit_transform(reduce_vocab(movie_df['BagOfWords']))\n\n# movie_df['BagOfWords'] = movie_df.loc[:,'Original Language':].apply(lambda col: ', '.join(col.astype(str)),axis=1)\n\nc1 = cosine_similarity(vocab_counts1,vocab_counts1)\nvocab_counts1.shape","e4d53b91":"# # Pearson's measure using cosine \n# Take the mean for each movie\ndisplay(vocab_counts1.mean(axis=1).shape)\nvocab_counts2 = vocab_counts1 - vocab_counts1.mean(axis=1)\n \nc2 = cosine_similarity(vocab_counts2,vocab_counts2)","8ede7d04":"# function that takes in movie title as input and returns the top 10 recommended movies\ndef content_recommender(movie_df, Title, top_n=5, cosine_sim = c1):\n          \n    # gettin the indices of the movie that matches the title\n    idx = [Title.lower() in str(t).lower() for t in pd.Series(movie_df.Title)]\n\n    # creating a Series with the similarity scores in descending order\n    sorted_scores = pd.DataFrame(cosine_sim[np.where(idx)].T).sort_values(by = 0, ascending = False)\n\n    # getting the indexes of the 10 most similar movies\n    top_n_movies = list(movie_df.loc[sorted_scores.iloc[1:(10+1)].index].Title)\n#     movie_df.Title[list(sorted_scores.iloc[1:(top_n+1)].index)]\n    \n     \n    return  display(\"Selects first movie only (but here are exact titles for what you might be looking for):\",\n                    movie_df.Title[idx], top_n_movies)","82e36f15":"mlist = ['avengers', 'rings', 'Bad Boys']\nmovie = mlist[0]\ncontent_recommender(movie_df, movie,5)","fb8b2833":"mlist = ['avengers', 'rings', 'Bad Boys']\nmovie = mlist[2]\ncontent_recommender(movie_df, movie,5,c2)","40174e21":"Questions: <br> \n1. Are there are duplicated rows? Yes! Only keep the first row of duplicates. \n2.  Are there any missing values? Yes, columns `Overview` and `Release Date`.","1e8cb876":"[Back to Top](#0)","3ac0a5e7":"## From `value_counts`: \n- Title:  9682  unique titles out of 10,000 movies.\n- Overview: Description of movies where 7 are unknown and some are duplicated overviews.\n- Original Language: Mostly English films, followed by French, Japanese, Italian, etc.\n- Release Date: 21 Movies are recently released 2020-06-05 but there are also old movies from 1980s.\n- Popularity: A model calculates this  score based on features such as `Number of votes day` and `Total number of views`.  More info at https:\/\/developers.themoviedb.org\/3\/getting-started\/popularity.\n- Vote Count: \tNumber of votes for a particular movie.\n- Vote Average: Calculates the mean valuesof movie ratings. ","e4a4e900":"<a id = \"1\"><\/a><br>\n##  Load Awesomeness  ","6a28f1d1":"### You watched\/liked the movie ('avengers', 'lord of the rings' or 'bad boys') so the recommender system will suggest similar movies to that single movie.\n\nWhat's your favourite movie? ","7ca190c1":"<a id = \"6\"><\/a><br>\n## Evaluation\n\nWell recommending similar movies seems like a good approach.... \n$\\Large BUT$ just how \"good\" this recommender is?\n\nIf you want to evaluate how good a recommendation is, then you'll need to: \n1. Obtain ground truth labels (i.e. users rating\/evaluation)\n2. Look at Mean Average Precision at K (MAP@K); that is on average, how accurate the guesses of the top K recommendations are.","22c4d46e":"### Measure of Similarity \n\n- Cosine similarity between movies is a measure of how similar movies are by calculating the angle between two vectors. \n- Movies are represented as a vector of 'keywords' from the vocabulary list.\n- The similarity of movies is calculated in a matrix.\n\n![](https:\/\/miro.medium.com\/max\/1000\/1*dGWOzgAYv9NUkWvkETQUTQ.png)\n\n\\begin{equation}\n\\Large \\text{where } a \\cdot b = a_1b_1 +  a_2b_2 +a_3b_3+ ... +  a_nb_n\n\\end{equation}\n\nSource: https:\/\/medium.com\/acing-ai\/what-is-cosine-similarity-matrix-f0819e674ad1\n\n\n\nOther measures you might be familiar with:\n- Euclidean distance between two points\/vectors (distance between a and b) however it is a poor metric for higher dimensions.\n- Pearson's correlation captures the linear relationsip between two vectors (a increases as b increases). This is actually a cosine similarity that has been centred by the mean. \n\n\\begin{equation}\n\\Large \\rho = \\frac{(a- \\bar{a}) \\cdot  (b- \\bar{b})}{|| a- \\bar{a} || \\; || b- \\bar{b} ||}\n\\end{equation}\n\n\n1. Create a vocabulary list from words from movie info. \n2. Count number of words in vocabulary list in each movie. \n3. Calculate cosine similarity based on movies' word frequencies. ","8b282d3a":"<a id = \"4\"><\/a><br>\n##  Recommender Systems\n\n- Goal: To predict the \"preference\" of a user for particular items.\n- Netflix Goal: To keep you watching Netflix as long as possible (...and you'll forget COVID even happened).\n- Amazon Goal: To keep you buying as many items as possible! \n","1e679d93":"[Back to Top](#0)","9ef0bfd7":"# Next Week: Recommender Systems for Big Data (Dask and Spark)\n- Item-based: You have a history of watching these movies (MULTIPLE) so the recommender will suggest similar movies to your movie history.\n- User-based:  Your movie history that is similar to these users so the recommender will suggest similar movies to what they have also watched.","72c2ecab":"# What movie should I watch?\n\n[Edward Toth, PhD, University of Sydney]\n\n- e-mail: eddie_toth@hotmail.com\n- Add me on: https:\/\/www.linkedin.com\/in\/edward-toth\/ \n- Join the community: https:\/\/www.meetup.com\/Get-Singapore-Meetup-Group\/\n- Data Avenger: https:\/\/data-avenger.mailchimpsites.com\/\n\n### What is your favourite movie from:\n**(A) Avengers <br>\n(B) Bad Boys <br>\n(C) Lord of the Rings**\n![](https:\/\/media.giphy.com\/media\/rj12FejFUysTK\/giphy.gif)\n\n\n![](https:\/\/media.giphy.com\/media\/3oEdv12GfACLqkbWfe\/giphy.gif)\n\n![](https:\/\/media.giphy.com\/media\/jdC79bfOtu1cQ\/giphy.gif)\n\n**I want to create a simple Content-based Recommender System with information of movie titles and overviews.**\n\nA few assumptions:\n- Title generally describes the movie (might get confused with romantic movies with the title 'Serial Killer')\n- Similarly, movie overview adequately captures the plot of the movie.\n- Similar movies will have similar titles or plots. \n\n\nDataset: https:\/\/www.kaggle.com\/sumantrapal\/tmdb-10000-dataset\n\n\n## In this tutorial, you'll learn about Recommender Systems:\n- Content-Based Recommendation \n- Cosine Similarity Matrix\n\n<a id = \"0\"><\/a><br>\n### Table of Contents\n1. [Load Awesomeness](#1)\n    * pandas, sklearn, read_csv()\n2. [Exploratory Data Analysis](#2) \n    * value_counts()\n3. [Data Preparation](#3) \n    * duplicated(), drop_duplicates(), is_null(), drop_na()\n4. [Recommender Systems](#4) \n    - [Content-Based Recommendation](#5): cosine_similarity()\n5. [Evaluation](#6) ","59566783":"## Reduce Vocabulary list\n- Lower case consistency\n- Eliminate punctuations, numbers, symbols\n- Eliminate stopwords \n- Delete rare characters add spaces between text","97f1b6a5":"<a id = \"5\"><\/a><br>\n## Content-Based Recommendation\n\nMethod: \n- Content-based: You watched\/liked this movie (SINGLE) so the recommender will suggest similar movies to that single movie. \n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/0*ZZl2bq-NraGfTtpa.jpg)\n\nBuild this Content-based recommender by:\n1. Filtering only English movies! <br> (I know, I know, what if you like other languages. Well, you'd need a dataset that has more foreign movie titles or maybe build the recommender based on language-specific content).\n- Join movie information: Title and Overview.\n- Reduce keywords in the vocabulary list. ","f349c1ca":"[Back to Top](#0)","0a025eee":"[Back to Top](#0)","e0330c73":"- ` (8473, 266829)`: 8,473 movies with 26,6829 words in the vocabulary list.\n- `(8473, 8473)`: cosine similarity between 8,473 movies is calculated.","ad8304fe":"## Further Readings \n- [Build a content-based movie recommender system with Natural Language Processing](https:\/\/towardsdatascience.com\/how-to-build-from-scratch-a-content-based-movie-recommender-with-natural-language-processing-25ad400eb243)\n- [Collaborative Filtering based Recommendation Systems exemplified..](https:\/\/towardsdatascience.com\/collaborative-filtering-based-recommendation-systems-exemplified-ecbffe1c20b1)\n-[Evaluation Metrics for Recommender Systems](https:\/\/towardsdatascience.com\/evaluation-metrics-for-recommender-systems-df56c6611093)\n","5e72b918":"<a id = \"3\"><\/a><br>\n##  Data Preparation ","619ab00b":"<a id = \"2\"><\/a><br>\n##  Exploratory Data Analysis"}}