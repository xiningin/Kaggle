{"cell_type":{"3bc47787":"code","f32a15c5":"code","376b9cd9":"code","e2868f5f":"code","b7e2d327":"code","dc10891e":"code","1002feb1":"code","9f64f915":"code","0907c645":"code","1fe30898":"code","31764342":"code","fd55aa1d":"code","90fc4f32":"code","39fd0ec0":"code","37b344de":"code","09c36a8a":"code","ef8a3896":"code","a47cfff1":"code","1e17f931":"code","f8c2c674":"code","f79af8aa":"code","aa93832b":"code","6c0788c1":"code","6696d41c":"code","11ccf371":"code","46bd672f":"code","acbe69a7":"markdown","3b8844f3":"markdown","a5357c68":"markdown","0c6176d5":"markdown","d4d4f46b":"markdown","a2254706":"markdown","42059409":"markdown","1d569c1f":"markdown","e5bb598a":"markdown","bee595ca":"markdown","2ff9cd7f":"markdown","31b909f7":"markdown","93bd6d08":"markdown","1c0a123e":"markdown","d22a1051":"markdown","4a966acd":"markdown","b8d58bf3":"markdown","64d7bbe7":"markdown","2038de17":"markdown","82de9fef":"markdown","ef2852a1":"markdown","b00e9e1a":"markdown","6ff546ae":"markdown","26fbcab8":"markdown"},"source":{"3bc47787":"import pandas as pd\nimport numpy as np\n\ntrain_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')\nsubmission_df = pd.read_csv('..\/input\/titanic\/gender_submission.csv')","f32a15c5":"train_df = train_df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])\ntest_df = test_df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])","376b9cd9":"age_mean = train_df['Age'].mean()\nfare_mean = train_df['Fare'].mean()\n\ntrain_df['Age'] = train_df['Age'].fillna(age_mean)\ntest_df['Age'] = test_df['Age'].fillna(age_mean)\ntrain_df['Fare'] = train_df['Fare'].fillna(fare_mean)\ntest_df['Fare'] = test_df['Fare'].fillna(fare_mean)\ntrain_df['Embarked'] = train_df['Embarked'].fillna('S')\ntest_df['Embarked'] = test_df['Embarked'].fillna('S')\ntrain_df.loc[train_df['Sex']=='male', 'Sex'] = 0\ntrain_df.loc[train_df['Sex']=='female', 'Sex'] = 1\ntest_df.loc[test_df['Sex']=='male', 'Sex'] = 0\ntest_df.loc[test_df['Sex']=='female', 'Sex'] = 1\ntrain_df.loc[train_df['Embarked']=='S', 'Embarked'] = 0\ntrain_df.loc[train_df['Embarked']=='C', 'Embarked'] = 1\ntrain_df.loc[train_df['Embarked']=='Q', 'Embarked'] = 2\ntest_df.loc[test_df['Embarked']=='S', 'Embarked'] = 0\ntest_df.loc[test_df['Embarked']=='C', 'Embarked'] = 1\ntest_df.loc[test_df['Embarked']=='Q', 'Embarked'] = 2\n\ntrain_df['Sex'] = train_df['Sex'].astype(int)\ntest_df['Sex'] = test_df['Sex'].astype(int)\ntrain_df['Embarked'] = train_df['Embarked'].astype(int)\ntest_df['Embarked'] = test_df['Embarked'].astype(int)","e2868f5f":"X_train = train_df.iloc[:, 1:]\ny_train = train_df.iloc[:, 0]\nX_test = test_df","b7e2d327":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nss = StandardScaler()\nmms = MinMaxScaler()\n\nss.fit(X_train)\nX_train_ss = ss.transform(X_train)\nX_test_ss = ss.transform(X_test)\n\nmms.fit(X_train)\nX_train_mms = mms.transform(X_train)\nX_test_mms = mms.transform(X_test)","dc10891e":"from sklearn.svm import SVC\n\nsvc = SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n   max_iter=-1, probability=False, random_state=3, shrinking=True,\n   tol=0.001, verbose=False)\nsvc.fit(X_train, y_train)\n\nsubmission_df['Survived'] = svc.predict(X_test)\nsubmission_df.to_csv('submission_SVC_rbf_NonScaling.csv', index=False)","1002feb1":"svc = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n   max_iter=-1, probability=False, random_state=3, shrinking=True,\n   tol=0.001, verbose=False)\nsvc.fit(X_train_ss, y_train)\n\nsubmission_df['Survived'] = svc.predict(X_test_ss)\nsubmission_df.to_csv('submission_SVC_rbf_StandardScaler.csv', index=False)","9f64f915":"svc = SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n   max_iter=-1, probability=False, random_state=3, shrinking=True,\n   tol=0.001, verbose=False)\nsvc.fit(X_train_mms, y_train)\n\nsubmission_df['Survived'] = svc.predict(X_test_mms)\nsubmission_df.to_csv('submission_SVC_rbf_MinMaxScaler.csv', index=False)","0907c645":"svc = SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n   max_iter=-1, probability=False, random_state=None, shrinking=True,\n   tol=0.001, verbose=False)\nsvc.fit(X_train, y_train)\n\nsubmission_df['Survived'] = svc.predict(X_test)\nsubmission_df.to_csv('submission_SVC_linear_NonScaling.csv', index=False)","1fe30898":"svc = SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n   max_iter=-1, probability=False, random_state=None, shrinking=True,\n   tol=0.001, verbose=False)\nsvc.fit(X_train_ss, y_train)\n\nsubmission_df['Survived'] = svc.predict(X_test_ss)\nsubmission_df.to_csv('submission_SVC_linear_StandardScaler.csv', index=False)","31764342":"svc = SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n   max_iter=-1, probability=False, random_state=None, shrinking=True,\n   tol=0.001, verbose=False)\nsvc.fit(X_train_mms, y_train)\n\nsubmission_df['Survived'] = svc.predict(X_test_mms)\nsubmission_df.to_csv('submission_SVC_linear_MinMaxScaler.csv', index=False)","fd55aa1d":"from sklearn.neighbors import KNeighborsClassifier\n\nknc = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n            metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n            weights='uniform')\nknc.fit(X_train, y_train)\n\nsubmission_df['Survived'] = knc.predict(X_test)\nsubmission_df.to_csv('submission_KNeighborsClassifier_NonScaling.csv', index=False)","90fc4f32":"knc = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n            metric_params=None, n_jobs=1, n_neighbors=12, p=2,\n            weights='uniform')\nknc.fit(X_train_ss, y_train)\n\nsubmission_df['Survived'] = knc.predict(X_test_ss)\nsubmission_df.to_csv('submission_KNeighborsClassifier_StandardScaler.csv', index=False)","39fd0ec0":"knc = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n            metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n            weights='uniform')\nknc.fit(X_train_mms, y_train)\n\nsubmission_df['Survived'] = knc.predict(X_test_mms)\nsubmission_df.to_csv('submission_KNeighborsClassifier_MinMaxScaler.csv', index=False)","37b344de":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n           penalty='l2', random_state=3, solver='liblinear', tol=0.0001,\n           verbose=0, warm_start=False)\nlr.fit(X_train, y_train)\n\nsubmission_df['Survived'] = lr.predict(X_test)\nsubmission_df.to_csv('submission_LogisticRegression_NonScaling.csv', index=False)","09c36a8a":"lr = LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n           penalty='l2', random_state=3, solver='liblinear', tol=0.0001,\n           verbose=0, warm_start=False)\nlr.fit(X_train_ss, y_train)\n\nsubmission_df['Survived'] = lr.predict(X_test_ss)\nsubmission_df.to_csv('submission_LogisticRegression_StandardScaler.csv', index=False)","ef8a3896":"lr = LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n           penalty='l2', random_state=3, solver='liblinear', tol=0.0001,\n           verbose=0, warm_start=False)\nlr.fit(X_train_mms, y_train)\n\nsubmission_df['Survived'] = lr.predict(X_test_mms)\nsubmission_df.to_csv('submission_LogisticRegression_MinMaxScaler.csv', index=False)","a47cfff1":"from sklearn.linear_model import Perceptron\n\nppn = Perceptron(alpha=1e-10, class_weight=None, eta0=1.0, fit_intercept=True,\n       max_iter=10000, n_jobs=1, penalty=None, random_state=3,\n       shuffle=True, tol=None, verbose=0, warm_start=False)\nppn.fit(X_train, y_train)\n\nsubmission_df['Survived'] = ppn.predict(X_test)\nsubmission_df.to_csv('submission_Perceptron_NonScaling.csv', index=False)","1e17f931":"ppn = Perceptron(alpha=1e-10, class_weight=None, eta0=1.0, fit_intercept=True,\n       max_iter=10000, n_jobs=1, penalty=None, random_state=3,\n       shuffle=True, tol=None, verbose=0, warm_start=False)\nppn.fit(X_train_ss, y_train)\n\nsubmission_df['Survived'] = ppn.predict(X_test_ss)\nsubmission_df.to_csv('submission_Perceptron_StandardScaler.csv', index=False)","f8c2c674":"ppn = Perceptron(alpha=1e-10, class_weight=None, eta0=1.0, fit_intercept=True,\n       max_iter=10000, n_jobs=1, penalty=None, random_state=3,\n       shuffle=True, tol=None, verbose=0, warm_start=False)\nppn.fit(X_train_mms, y_train)\n\nsubmission_df['Survived'] = ppn.predict(X_test_mms)\nsubmission_df.to_csv('submission_Perceptron_MinMaxScaler.csv', index=False)","f79af8aa":"from sklearn.neural_network import MLPClassifier\n\nmlpc = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n        hidden_layer_sizes=(30, 20, 10), learning_rate='constant',\n        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n        nesterovs_momentum=True, power_t=0.5, random_state=3, shuffle=True,\n        solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n        warm_start=False)\nmlpc.fit(X_train, y_train)\n\nsubmission_df['Survived'] = mlpc.predict(X_test)\nsubmission_df.to_csv('submission_MLPClassifier_NonScaling.csv', index=False)","aa93832b":"mlpc = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n        hidden_layer_sizes=(100,), learning_rate='constant',\n        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n        nesterovs_momentum=True, power_t=0.5, random_state=3, shuffle=True,\n        solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n        warm_start=False)\nmlpc.fit(X_train_ss, y_train)\n\nsubmission_df['Survived'] = mlpc.predict(X_test_ss)\nsubmission_df.to_csv('submission_MLPClassifier_StandardScaler.csv', index=False)","6c0788c1":"mlpc = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n        hidden_layer_sizes=(50, 50), learning_rate='constant',\n        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n        nesterovs_momentum=True, power_t=0.5, random_state=3, shuffle=True,\n        solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n        warm_start=False)\nmlpc.fit(X_train_mms, y_train)\n\nsubmission_df['Survived'] = mlpc.predict(X_test_mms)\nsubmission_df.to_csv('submission_MLPClassifier_MinMaxScaler.csv', index=False)","6696d41c":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n             max_depth=7, max_features='auto', max_leaf_nodes=None,\n             min_impurity_decrease=0.0, min_impurity_split=None,\n             min_samples_leaf=1, min_samples_split=2,\n             min_weight_fraction_leaf=0.0, n_estimators=14, n_jobs=1,\n             oob_score=False, random_state=3, verbose=0, warm_start=False)\nrfc.fit(X_train, y_train)\n\nsubmission_df['Survived'] = rfc.predict(X_test)\nsubmission_df.to_csv('submission_RandomForestClassifier_NonScaling.csv', index=False)","11ccf371":"rfc = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n             max_depth=7, max_features='auto', max_leaf_nodes=None,\n             min_impurity_decrease=0.0, min_impurity_split=None,\n             min_samples_leaf=1, min_samples_split=2,\n             min_weight_fraction_leaf=0.0, n_estimators=14, n_jobs=1,\n             oob_score=False, random_state=3, verbose=0, warm_start=False)\nrfc.fit(X_train_ss, y_train)\n\nsubmission_df['Survived'] = rfc.predict(X_test_ss)\nsubmission_df.to_csv('submission_RandomForestClassifier_StandardScaler.csv', index=False)","46bd672f":"rfc = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n             max_depth=7, max_features='auto', max_leaf_nodes=None,\n             min_impurity_decrease=0.0, min_impurity_split=None,\n             min_samples_leaf=1, min_samples_split=2,\n             min_weight_fraction_leaf=0.0, n_estimators=14, n_jobs=1,\n             oob_score=False, random_state=3, verbose=0, warm_start=False)\nrfc.fit(X_train_mms, y_train)\n\nsubmission_df['Survived'] = rfc.predict(X_test_mms)\nsubmission_df.to_csv('submission_RandomForestClassifier_MinMaxScaler.csv', index=False)","acbe69a7":"## 3-3. KNeighborsClassifier - MinMaxScaler","3b8844f3":"## 2-1. SVC Linear - NonScaling","a5357c68":"## 5-2. Perceptron - StandardScaler","0c6176d5":"## 6-3. MLPClassifier - MinMaxScaler","d4d4f46b":"# Import, Read CSV, Preprocessing","a2254706":"## 3-1. KNeighborsClassifier - NonScaling","42059409":"## 6-2. MLPClassifier - StandardScaler","1d569c1f":"## 5-3. Perceptron - MinMaxScaler","e5bb598a":"## 1-3. SVC RBF - MinMaxScaler","bee595ca":"## 5-1. Perceptron - NonScaling","2ff9cd7f":"## 7-3. RandomForestClassifier - MinMaxScaler","31b909f7":"## 4-2. LogisticRegression - StandardScaler","93bd6d08":"## 7-1. RandomForestClassifier - NonScaling","1c0a123e":"## 3-2. KNeighborsClassifier - StandardScaler","d22a1051":"## 1-2. SVC RBF - StandardScaler","4a966acd":"## 2-3. SVC Linear - MinMaxScaler","b8d58bf3":"## 1-1. SVC RBF - NonScaling","64d7bbe7":"## 2-2. SVC Linear - StandardScaler","2038de17":"## 7-2. RandomForestClassifier - StandardScaler","82de9fef":"## 6-1. MLPClassifier - NonScaling","ef2852a1":"* Thanks for https:\/\/newtechnologylifestyle.net\/kaggle_titanic\/","b00e9e1a":"## 4-3. LogisticRegression - MinMaxScaler","6ff546ae":"## 4-1. LogisticRegression - NonScaling","26fbcab8":"# Modeling, Submission"}}