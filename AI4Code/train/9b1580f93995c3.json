{"cell_type":{"5800fdf5":"code","fd453c5b":"code","915f4bff":"code","54ba475e":"code","bb4b04f5":"code","788c2730":"code","3873f5c4":"code","e967eb7f":"code","7eb56415":"code","d95f766a":"code","fd63dda7":"markdown","58231f2b":"markdown","c39cca92":"markdown","133934b9":"markdown","02baf964":"markdown","a2fa0956":"markdown","f6cbb79b":"markdown","494cdd98":"markdown","01b55b13":"markdown"},"source":{"5800fdf5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport sqlite3 # Reading sql database\n\n# Predicting, metrics, etc\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.utils import resample\n\npd.set_option('display.max_columns', 1000)\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","fd453c5b":"# Create a SQL connection to our SQLite database\ncon = sqlite3.connect(\"\/kaggle\/input\/california-traffic-collision-data-from-switrs\/switrs.sqlite\")\ncur = con.cursor()\n\n# Read the motorcycle collisions\ncollisions = pd.read_sql_query(\"SELECT * FROM collisions WHERE motorcycle_collision == 1\", con)\n\ncon.close()\n# Save the data as csv files\ncollisions.to_csv('collisions.csv',index=False)","915f4bff":"# Change dtype when we need it, multiple types are memory inefficient\ncollisions = pd.read_csv('collisions.csv',dtype=str)","54ba475e":"collisions['case_id'] = collisions['case_id'].astype(np.float)\n\n# Change datetime columns\ncollisions['collision_date'] = pd.to_datetime(collisions['collision_date'],format='%Y-%m-%d')\ncollisions['collision_time'] = pd.to_timedelta(collisions['collision_time'])\n\n# 1 NEW FEATURE: DAY TYPE\nday_type = np.array([1 if x.weekday() < 5 else 0 for x in collisions['collision_date']])\ncollisions['day_type'] = day_type\n\n# Get hour from datetime\ndef hour(time):\n    days, seconds = time.days, time.seconds\n    return days * 24 + seconds \/\/ 3600\n\n# get time of collision\ncollisions['time'] = collisions['collision_time'].apply(lambda x: hour(x))\n\ntime_loc = collisions.columns.get_loc('time')\nday_type_loc = collisions.columns.get_loc('day_type')\n\n# 2 NEW FEATURE: COMMUTE\ncommute = np.zeros(len(collisions))\n\nfor i, row in collisions.iterrows():\n    morning = (row[time_loc] <= 9) and (row[time_loc] >= 5)\n    evening = (row[time_loc] <= 19) and (row[time_loc] >= 17)\n    weekday = (row[day_type_loc] == 1)\n    if weekday:\n        if morning or evening:\n            commute[i] = 1\n\n# 3 NEW FEATURE: FATAL (DEPENDENT VARIABLE)\ncollisions['killed_victims'] = collisions['killed_victims'].astype(np.float)\nfatal = np.array([1 if x > 0 else 0 for x in collisions['killed_victims']])\n\n# 4 NEW FEATURE: POPULATION2\npopulation2 = np.array([1 if x == '9' else 0 for x in collisions['population']])\n\n# FEATURE: SPECIAL CONDITION\nsc = np.array([1 if x == '1' else 0 for x in collisions['special_condition']])\n\n# BEAT TYPE\nbt = np.array([1 if x == '1' else 0 for x in collisions['beat_type']])\n\n# NEW FEATURE: DIRECTION {E,W} OR {N,S} !!!\ndirections = ['east','west']\nE_or_W = np.array([1 if x in directions else 0 for x in collisions['direction']])\n\n# NEW FEATURE: INTERSECTION\nintersect = np.array([1 if x == '1.0' else 0 for x in collisions['intersection']])\n\n# NEW FEATURE: HIGHWAY SIDE {E,W} OR {N,S}\nbound = ['eastbound','westbound']\nbound_EW = np.array([1 if x in bound else 0 for x in collisions['side_of_highway']])\n\n# towaway\ntowaway = np.array([1 if x == '1.0' else 0 for x in collisions['tow_away']])\n\n# PARTY COUNT\npc = collisions['party_count'].astype(np.float)\n\n# head on?\nheadon = np.array([1 if x == 'head-on' else 0 for x in collisions['type_of_collision']])\n\n# lighting2\ndark = ['dark with no street lights','dark with street lights not functioning']\nmid = ['dark with street lights', 'dusk or dawn']\nlight = ['daylight']\n\nlighting2 = np.zeros(len(collisions))\n\nfor i, x in enumerate(collisions['lighting']):\n    if x in dark:\n        lighting2[i] = 2\n    elif x in mid:\n        lighting2[i] = 1\n    elif x in light:\n        lighting2[i] = 0\n\n# pedestrian collision\npedestrian = np.array([1 if x == '1.0' else 0 for x in collisions['pedestrian_collision']])\n\n# control device:\ndevices = ['functioning','none']\ncd = np.array([1 if x in devices else 0 for x in collisions['control_device']])\n\n# road type:\nrt = ['5','0']\nroadtype = np.array([1 if x in rt else 0 for x in collisions['chp_road_type']])\n\n# bicycle collision\nbc = np.array([1 if x == '1.0' else 0 for x in collisions['bicycle_collision']])\n\n# truck collision\ntc = np.array([1 if x == '1.0' else 0 for x in collisions['truck_collision']])\n\n# alcohol\nalcohol = np.array([1 if x == '1.0' else 0 for x in collisions['alcohol_involved']])","bb4b04f5":"# Create a new df of the new features\ncollisions2 = list(zip(day_type,commute,population2,bt,E_or_W,\n                       intersect,bound_EW,towaway,pc,headon,lighting2,\n                       pedestrian,cd,roadtype,bc,tc,alcohol,sc,fatal))\n\ncols = ['day_type','commute','population','beat_type','direction',\n        'intersection','highway_direction','tow_away','party_count',\n        'head_on','lighting','pedestrian_collision','control_device',\n        'road_type','bicycle_collision','truck_collision','alcohol',\n        'special_condition','fatal']\n\nnew_collisions = pd.DataFrame(collisions2,columns=cols)\n\nprint(new_collisions.describe())\n\nnew_collisions.to_csv('new_collisions.csv')","788c2730":"# Read our new data\ndata = pd.read_csv('new_collisions.csv',index_col=0)\n\n# Create a random training and test split for the data\nmsk = np.random.rand(len(data)) < 0.8\n\ntrain = data[msk]\ntest = data[~msk]\n\nmajority = train[train.fatal == 0]\nminority = train[train.fatal == 1]\n\nprint(\"There are {x} crash fatality cases\".format(x=len(minority)))\nprint(\"There are {y} crash survival cases\".format(y=len(majority)))","3873f5c4":"upsampled_minority = resample(minority,\n                              replace=True,\n                              n_samples=len(majority),\n                              random_state=123)\n\nupsampled_train = pd.concat([majority,upsampled_minority])\n\nX_train_upsampled = upsampled_train.loc[:, upsampled_train.columns != 'fatal'].to_numpy()\ny_train_upsampled = upsampled_train['fatal'].to_numpy()\n\nX_test = test.loc[:, test.columns != 'fatal'].to_numpy()\ny_test = test['fatal'].to_numpy()","e967eb7f":"# rf classifier model\nmodel = RandomForestClassifier(random_state=1,\n                               verbose=1)\n\n# fit the model\nmodel.fit(X_train_upsampled, y_train_upsampled)","7eb56415":"predictions = model.predict(X_test)\nprint(classification_report(y_test,predictions))","d95f766a":"# get importance\nimportance = model.feature_importances_\n\n# summarize feature importance\ncols = list(data.columns)\n\nfeature_imp ={}\nfor i, imp in enumerate(importance):\n    feature_imp[cols[i]] = imp\n    \nsorted_results = {k: v for k, v in sorted(feature_imp.items(), key=lambda item: item[1],reverse=True)}\n\nprint(\"FEATURE : IMPORTANCE\")\nfor x in sorted_results.keys():\n    print(\"{x} : {y}\".format(x=x,y=sorted_results[x]))","fd63dda7":"Heavily imbalanced!\n\n## 2. Upsampling training data\n\nUpsampling the test data is not good as it doesn't give an accurate representation of real-life scenarios.","58231f2b":"# Predicting Fatalities\n\nThis is part two of my analysis. See part one [here](https:\/\/www.kaggle.com\/sstewart0\/statistical-analysis).\n\n## Metric: Why Recall & Accuracy?\n\nThe **cost of false negatives** (incorrectly predicting that someone did not die when they actually did) is much greater than the cost of false positives (incorrectly predicting that someone died when they actually did not).\n\nSo, for this reason I have chosen to use the metric recall, that is,\n\n$$\\mbox{Recall} = \\frac{\\mbox{TP}}{\\mbox{TP} + \\mbox{FN}}$$\n\nwhere:\n* $\\mbox{TP}$ = Number of true positives (number of correctly predicted deaths),\n* $\\mbox{FN}$ = Number of false negatives (number of deaths incorrectly predicted as survivals),\n\nin other words: **What percent of the positive cases did you catch?**\n\nWe also will use accuracy, because at a certain point, we can increase recall continually (i.e. predict everyone to die) and our overall accuracy will be awful!\n\n## Find & Read Data","c39cca92":"## 3. Train Model","133934b9":"## 4. Model Recall & Accuracy","02baf964":"##\u00a05. Feature Importance","a2fa0956":"\n\nCan we use the results from the feature importance to build a better model, e.g. a neural net?","f6cbb79b":"# Random Forest Classifier Model\n\n## 1. Splitting train & test data","494cdd98":"Recall of 69%, whilst maintaining accuracy at 70%... not too bad!\n\n(p.s. when you add weights to the classes in training the model, recall increases, BUT accuracy decreases)","01b55b13":"# Feature Engineering\n\nAfter some detailed analysis I chose certain inputs, I then engineered them as below to get the features that I wanted."}}