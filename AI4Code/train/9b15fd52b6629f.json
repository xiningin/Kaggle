{"cell_type":{"81d85d9c":"code","2c7e3dfa":"code","06877233":"code","a47bf3e0":"code","0cbc715d":"code","8fbe2b1b":"code","0dbae855":"code","8d1381fe":"code","7f52dba5":"code","9a67b4a3":"code","3a2e35d3":"code","41690b27":"code","0bd3eb18":"code","04baa6b2":"code","f7e7330a":"code","2a728257":"code","5ab8d743":"code","e41e80c2":"code","e9b8a935":"code","074a80db":"code","ccd5eabd":"code","317e23ab":"code","153eaae7":"code","13e69239":"code","323e7dd5":"code","e3a880d7":"code","5b5a6a74":"code","8287d5d3":"code","aff3c805":"code","f2b12648":"markdown","4992e269":"markdown","25819d21":"markdown","74d92979":"markdown","e97f9a23":"markdown","22a808c7":"markdown","92b5728c":"markdown","6cfa4572":"markdown","b712436d":"markdown","bfc8baa6":"markdown","50769372":"markdown","a073db88":"markdown","b0658df7":"markdown","18b1d723":"markdown","9ff508ed":"markdown","e4895dbb":"markdown","4d3aa5ad":"markdown","5bb40340":"markdown","a4fd310d":"markdown","92ffffa6":"markdown","c154dbeb":"markdown","6e8f1835":"markdown","a6bc3abb":"markdown","7b88dfd8":"markdown","9463838f":"markdown"},"source":{"81d85d9c":"# Importing necessary packages\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport re\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","2c7e3dfa":"districts_data_path = \"..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\"\nproducts_data_path = \"..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\"\nengagements_data_path = \"..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\"","06877233":"districts_data = pd.read_csv(districts_data_path)\nproducts_data = pd.read_csv(products_data_path)\n\nproducts_data.info()\ndistricts_data.info()","a47bf3e0":"products_data.sample(4)","0cbc715d":"districts_data.sample(4)","8fbe2b1b":"# Functions to Calculate Missing Values and droping columns\n\ndef drop_columns(self, df, column_list):\n        df_new = df.drop(column_list, axis=1)\n\n        return df_new\n\ndef total_percent_missing_data(df):\n\n        # Calculate total number of cells in dataframe\n        totalCells = np.product(df.shape)\n\n        # Count number of missing values per column\n        missingCount = df.isnull().sum()\n\n        # Calculate total number of missing values\n        totalMissing = missingCount.sum()\n\n        # Calculate percentage of missing values\n        return round(((totalMissing\/totalCells) * 100), 2)\n\n\ndef missing_data_per_column(df):\n        item_list = []\n        row_list = []\n        new_columns=['Column', 'No. of Missing Values', '% Missing Values per column']\n        total_no_data_per_column = df.shape[0]-1\n        i=0\n        for item in df.columns:\n            no_missing_values = df[item].isna().sum()\n            percentage = str(round(((no_missing_values\/total_no_data_per_column) * 100), 2))+\" %\"\n            row_list.append(item)\n            row_list.append(no_missing_values)\n            row_list.append(percentage)\n            item_list.append(row_list)\n            row_list = []\n\n        df_data = pd.DataFrame(item_list, columns = new_columns)\n        return df_data\n\n\nmissing_values = total_percent_missing_data(districts_data)\nmissing_df = missing_data_per_column(districts_data)\n\nprint(f\" Summary of Missing Values in districts_data : {missing_values} %\")\nprint(\"Missing values per column in districts_data\")\nmissing_df","0dbae855":"# Checking for Pattern in Missing Values\nnan_rows = districts_data[districts_data['state'].isna() & districts_data['locale'].isna()]\nnan_rows1 = districts_data[districts_data['state'].isna()].count().sum()\nnan_rows2 = districts_data[districts_data['state'].isna() & districts_data['locale'].isna() & districts_data['pct_black\/hispanic'].isna() & districts_data['pct_free\/reduced'].isna() & districts_data['county_connections_ratio'].isna() & districts_data['pp_total_raw'].isna()].count().sum()\nprint(\"The number of columns with Missing 'state' values and Missinng all columns except 'district_id' are: \", nan_rows1, nan_rows2)\nnan_rows.sample(10)","8d1381fe":"# Droping all rows with null values in state, locale, etc\ndistricts_data = districts_data[districts_data.state.notna()].reset_index(drop=True)\ndistricts_data.info()","7f52dba5":"missing_values = total_percent_missing_data(products_data)\nmissing_df = missing_data_per_column(products_data)\n\nprint(f\" Summary of Missing Values in products_data : {missing_values} %\")\nprint(\"Missing values per column in products_data\")\nmissing_df","9a67b4a3":"fig, axes = plt.subplots(figsize=(16,4), nrows=1, ncols=2)\nproducts_data[\"Sector(s)\"].value_counts().plot.bar(ax=axes[0], title=\"Sector(s)\")\nproducts_data[\"Primary Essential Function\"].value_counts().plot.bar(ax=axes[1], title=\"Primary Essential Function\")","3a2e35d3":"# Filling the missing Values with Mode, because we're dealing with Categorical values\ntry:\n    products_data[\"Primary Essential Function\"] = products_data[\"Primary Essential Function\"].fillna(products_data[\"Primary Essential Function\"].mode()[0])\n    products_data[\"Sector(s)\"] = products_data[\"Sector(s)\"].fillna(products_data[\"Sector(s)\"].mode()[0])\n    products_data[\"Provider\/Company Name\"] = products_data[\"Provider\/Company Name\"].fillna(products_data[\"Provider\/Company Name\"].mode()[0])\n\nexcept Exception as eeeee:\n    print(e)","41690b27":"missing_df = missing_data_per_column(products_data)\nmissing_df","0bd3eb18":"fig, axes = plt.subplots(figsize=(15,4), nrows=1, ncols=3)\ndistricts_data['pct_free\/reduced'].value_counts().plot.bar(ax=axes[0], title=\"districts pct_free\/reduced\")\ndistricts_data['county_connections_ratio'].value_counts().plot.bar(ax=axes[1], title=\"districts county_connections_ratio\")\ndistricts_data['pp_total_raw'].value_counts().plot.bar(ax=axes[2], title=\"districts pp_total_raw\")","04baa6b2":"# Filling the missing Values with Mode, because we're dealing with Categorical values\ntry:\n    districts_data['pct_free\/reduced'] = districts_data['pct_free\/reduced'].fillna(districts_data['pct_free\/reduced'].mode()[0])\n    districts_data['county_connections_ratio'] = districts_data['county_connections_ratio'].fillna(districts_data['county_connections_ratio'].mode()[0])\n    districts_data['pp_total_raw'] = districts_data['pp_total_raw'].fillna(districts_data['pp_total_raw'].mode()[0])\n\nexcept Exception as eeeee:\n    print(e)\n    \ndistricts_data.info()","f7e7330a":"# Concatinating all engagement data of all districts\ndata_set = [] # Initializing empty dataset list\n\n# Taking district id's from districts_data,\nfor district in districts_data.district_id.unique():\n    new_df = pd.read_csv(f'{engagements_data_path}\/{district}.csv', index_col=None, header=0)\n    new_df[\"district_id\"] = district\n    data_set.append(new_df)\n    \n    \nengagements_data = pd.concat(data_set)\nengagements_data = engagements_data.reset_index(drop=True)","2a728257":"# engagements_data.info()\nengagements_data.sample(10)","5ab8d743":"missing_df = missing_data_per_column(engagements_data)\nmissing_df","e41e80c2":"engagements_data.describe().T","e9b8a935":"# Filling the missing Values with Mean, because we're dealing with float values\ntry:\n    engagements_data['pct_access'] = engagements_data['pct_access'].fillna(engagements_data['pct_access'].mean())\n    engagements_data['engagement_index'] = engagements_data['engagement_index'].fillna(engagements_data['engagement_index'].mean())\n\nexcept Exception as e:\n    print(e)\n    \nengagements_data.info()","074a80db":"missing_df = missing_data_per_column(engagements_data)\nmissing_df","ccd5eabd":"dict_data = {}\n\nfor district_id in engagements_data.district_id.unique():\n    new_dataframe = pd.DataFrame()\n    number = engagements_data[engagements_data['district_id']==district_id].time.unique()\n    dict_data[district_id] = len(number)\n","317e23ab":"pd.DataFrame(dict_data.items()).describe()","153eaae7":"list_district = []\nfor district_id in engagements_data.district_id.unique():\n    number = engagements_data[engagements_data['district_id']==district_id].time.unique()\n    if len(number)!=366:\n        list_district.append(district_id)\n        ","13e69239":"# list_district\n# Droping all rows with district_id found in list_district\nfor district_id in list_district:\n    engagements_data = engagements_data[engagements_data.district_id==district_id].reset_index(drop=True)\n# engagements_data","323e7dd5":"# Checking the district_id's we dropped\nengagements_data\nfor district_id in list_district:\n    if (engagements_data['district_id']==district_id).any():\n        print(\"Something went wrong in dropping the rows\")\n        \n    else:\n        print(f\"Dropping all rows having district_id: {district_id} successfully\")\n    ","e3a880d7":"districts_data.sample(3)","5b5a6a74":"fig, axes = plt.subplots(figsize=(15,4), nrows=1, ncols=2)\ndistricts_data['state'].value_counts().plot.bar(ax=axes[0], title=\"state\")\ndistricts_data['locale'].value_counts().plot.bar(ax=axes[1], title=\"districts locale\")","8287d5d3":"# Mean Values\nfig, ax = plt.subplots(2, 2, figsize=(15, 15))\nsns.scatterplot(y='state', x='locale', hue=\"pct_black\/hispanic\",\n                data=districts_data, ax=ax[0][0], palette='magma')\nsns.scatterplot(y='state', x='locale', hue=\"pct_free\/reduced\",\n                data=districts_data, ax=ax[0][1], palette='magma')\n\n#  SE Values\nsns.scatterplot(y='state', x='locale', hue=\"county_connections_ratio\",\n                data=districts_data, ax=ax[1][0], palette='magma')\nsns.scatterplot(y='state', x='locale', hue='pp_total_raw',\n                data=districts_data, ax=ax[1][1], palette='magma')\n\nprint(\" KEY:\")\nprint(\" (1,1)--> Distribution of pct_black\/hispanic, (1,2)--> Distribution of pct_free\/reduced\")\nprint(\" (2,1)--> Distribution of county_connections_ratio, (2,2)--> Distribution of pp_total_raw\")","aff3c805":"data_to_submit = pd.DataFrame()\ndata_to_submit.to_csv('districts_data.csv', index = False)","f2b12648":"#### Showing sample data","4992e269":"#### Calculating the Missing Values, NA","25819d21":"### Analysis Focus,\n1. The state of digital learning in 2020,\n2. How the engagement of digital learning relates to factors such as district demographics, broadband access, and state\/national level policies and events","74d92979":"### Pre-Processing Engagement data, joining with other datasets\n- Joining the individual data into one dataset\/file, by adding district_id to identify a particular district\n\nDataset Descriptions;\n1. time\t: date in \"YYYY-MM-DD\"\n2. lp_id\t:The unique identifier of the product\n3. pct_access\t:Percentage of students in the district have at least one page-load event of a given product and on a given day\n4. engagement_index\t:Total page-load events per one thousand students of a given product and on a given day","e97f9a23":"#### Droping rows having null values","22a808c7":"##### Most of schools are in Connecticut, Utah, Massachusetts, Illinois, California, Ohio, etc, states, and\n##### Most of schools are in Suburbs, followed by Rular, City and lastly in Town","92b5728c":"#### Filling the Missing data\/Values with Mode","6cfa4572":"### Learnplatform Covid19 Impact on Digital Learning\n\n##### This Notebook is deivided into Two main parts\n\n1. Data Pre-processing\n2. Exploratory Data Analysis (EDA)","b712436d":"#### List of US States and their Abbreviations\nus_state_abbrev = {\n    'Alabama': 'AL','Alaska': 'AK','American Samoa': 'AS','Arizona': 'AZ','Arkansas': 'AR','California': 'CA',\n    'Colorado': 'CO','Connecticut': 'CT','Delaware': 'DE','District Of Columbia': 'DC',    'Florida': 'FL',\n    'Georgia': 'GA',    'Guam': 'GU',    'Hawaii': 'HI',    'Idaho': 'ID',    'Illinois': 'IL',    'Indiana': 'IN',\n    'Iowa': 'IA', 'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD','Massachusetts': 'MA',\n    'Michigan': 'MI','Minnesota': 'MN','Mississippi': 'MS','Missouri': 'MO','Montana': 'MT','Nebraska': 'NE',\n    'Nevada': 'NV','New Hampshire': 'NH','New Jersey': 'NJ','New Mexico': 'NM','New York': 'NY','North Carolina': 'NC',\n    'North Dakota': 'ND','Northern Mariana Islands':'MP','Ohio': 'OH','Oklahoma': 'OK','Oregon': 'OR','Pennsylvania': 'PA',\n    'Puerto Rico': 'PR','Rhode Island': 'RI','South Carolina': 'SC','South Dakota': 'SD','Tennessee': 'TN','Texas': 'TX',\n    'Utah': 'UT','Vermont': 'VT','Virgin Islands': 'VI','Virginia': 'VA','Washington': 'WA','West Virginia': 'WV',\n    'Wisconsin': 'WI','Wyoming': 'WY'\n}","bfc8baa6":"#### Relationship between 'state' and 'locale'","50769372":"#### Checking for Missing Values","a073db88":"## Data Pre-processing","b0658df7":"## Exploratory Data Analysis (EDA)","18b1d723":"#### Districts_data EDA","9ff508ed":"It can be concluded, that all data that have missing state, have also missing locale, pct_black\/hispanic, pct_free\/reduced, county_connections_ratio, pp_total_raw","e4895dbb":"#### Dealing with \"pct_access\", and \"engagement_index\" columns\n- Using Mean filling Method, to fill pct_access, and engagement_index, because they are float values.","4d3aa5ad":"### Loading datasets","5bb40340":"### Path to different Data files, scripts files and files ","a4fd310d":"#### Checking for \"time\" column of engagements_dataset","92ffffa6":"#### Droping these districts and all their records","c154dbeb":"#### Summary:","6e8f1835":"#### Dealing with Missing Values in Districts_data\nDealing with;\n\n1. pct_free\/reduced : percentage of students eliglble for free or reduced lunch\n2. county_connections_ratio : ratio of high internet speeds\n3. pp_total_raw : sum of local and federal expenditure per pupil","a6bc3abb":"#### Data Reading and Pre-processing\n\nImporting Required packages and Libraries","7b88dfd8":"#### Finding\nIt can be seen that, more that 75% of the data, have time - date\/days 366 engagements, therefore, for Better Analysis, I'll drop the districts that has less than 366 days.","9463838f":"#### Filling Missing Values in Products_data using Median or Mode "}}