{"cell_type":{"60b26412":"code","e4bd2698":"code","cb1c568f":"code","4d8f5cb9":"code","48ede09d":"code","96dae0b8":"code","67fc050a":"code","796a3900":"code","cf980586":"code","c7ba412e":"code","49220ec5":"code","8157734e":"code","4e56d1b4":"code","b9258803":"code","24b723bc":"code","5d186ff7":"code","5dcd0109":"code","325a2c97":"code","988a4a93":"code","cddd02f4":"code","4aa4ac07":"code","d7252e72":"code","6c58795b":"code","188b0997":"code","2b1d5e69":"code","47546428":"code","1272d6fe":"code","2a6dded4":"code","105d4818":"code","d8467421":"markdown","b361650c":"markdown","4267abe9":"markdown","66a01e2a":"markdown","3ce1e3d5":"markdown","6c602ce2":"markdown"},"source":{"60b26412":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e4bd2698":"import torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\n%matplotlib inline","cb1c568f":"df1 = pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')","4d8f5cb9":"df1.head()","48ede09d":"def get_info_dataframe(dataframe):\n    print(f\"DATAFRAME GENERAL INFO - \\n\")\n    print(dataframe.info(),\"\\n\")\n    print(f\"DATAFRAME MISSING INFO - \\n\")\n    print(dataframe.isnull().sum(),\"\\n\")\n    print(f\"DATAFRAME SHAPE INFO - \\n\")\n    print(dataframe.shape)","96dae0b8":"get_info_dataframe(df1)","67fc050a":"df1['Species'].unique()","796a3900":"df1['Species'] = df1['Species'].map({'Iris-setosa':0,'Iris-versicolor':1,'Iris-virginica':2})","cf980586":"df1.head()","c7ba412e":"df1.drop(['Id'],axis=1,inplace=True)","49220ec5":"df1.head()","8157734e":"X = df1.drop([\"Species\"],axis=1).values\ny = df1[\"Species\"].values","4e56d1b4":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split","b9258803":"scaler = StandardScaler()","24b723bc":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","5d186ff7":"X_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","5dcd0109":"X_train = torch.FloatTensor(X_train)\nX_test = torch.FloatTensor(X_test)\ny_train = torch.LongTensor(y_train)\ny_test = torch.LongTensor(y_test)","325a2c97":"class NeuralNetworkClassificationModel(nn.Module):\n    def __init__(self,input_dim,output_dim):\n        super(NeuralNetworkClassificationModel,self).__init__()\n        self.input_layer    = nn.Linear(input_dim,128)\n        self.hidden_layer1  = nn.Linear(128,64)\n        self.output_layer   = nn.Linear(64,output_dim)\n        self.relu = nn.ReLU()\n    \n    \n    def forward(self,x):\n        out =  self.relu(self.input_layer(x))\n        out =  self.relu(self.hidden_layer1(out))\n        out =  self.output_layer(out)\n        return out","988a4a93":"# input_dim = 4 because we have 4 inputs namely sepal_length,sepal_width,petal_length,petal_width\n# output_dim = 3 because we have namely 3 categories setosa,versicolor and virginica\ninput_dim  = 4 \noutput_dim = 3\nmodel = NeuralNetworkClassificationModel(input_dim,output_dim)","cddd02f4":"# creating our optimizer and loss function object\nlearning_rate = 0.01\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)","4aa4ac07":"def train_network(model,optimizer,criterion,X_train,y_train,X_test,y_test,num_epochs,train_losses,test_losses):\n    for epoch in range(num_epochs):\n        #clear out the gradients from the last step loss.backward()\n        optimizer.zero_grad()\n        \n        #forward feed\n        output_train = model(X_train)\n\n        #calculate the loss\n        loss_train = criterion(output_train, y_train)\n        \n\n\n        #backward propagation: calculate gradients\n        loss_train.backward()\n\n        #update the weights\n        optimizer.step()\n\n        \n        output_test = model(X_test)\n        loss_test = criterion(output_test,y_test)\n\n        train_losses[epoch] = loss_train.item()\n        test_losses[epoch] = loss_test.item()\n\n        if (epoch + 1) % 50 == 0:\n            print(f\"Epoch {epoch+1}\/{num_epochs}, Train Loss: {loss_train.item():.4f}, Test Loss: {loss_test.item():.4f}\")","d7252e72":"num_epochs = 1000\ntrain_losses = np.zeros(num_epochs)\ntest_losses  = np.zeros(num_epochs)","6c58795b":"train_network(model,optimizer,criterion,X_train,y_train,X_test,y_test,num_epochs,train_losses,test_losses)","188b0997":"plt.figure(figsize=(10,10))\nplt.plot(train_losses, label='train loss')\nplt.plot(test_losses, label='test loss')\nplt.legend()\nplt.show()","2b1d5e69":"predictions_train = []\npredictions_test =  []\nwith torch.no_grad():\n    predictions_train = model(X_train)\n    predictions_test = model(X_test)","47546428":"# Check how the predicted outputs look like and after taking argmax compare with y_train or y_test \n#predictions_train  \n#y_train,y_test","1272d6fe":"def get_accuracy_multiclass(pred_arr,original_arr):\n    if len(pred_arr)!=len(original_arr):\n        return False\n    pred_arr = pred_arr.numpy()\n    original_arr = original_arr.numpy()\n    final_pred= []\n    # we will get something like this in the pred_arr [32.1680,12.9350,-58.4877]\n    # so will be taking the index of that argument which has the highest value here 32.1680 which corresponds to 0th index\n    for i in range(len(pred_arr)):\n        final_pred.append(np.argmax(pred_arr[i]))\n    final_pred = np.array(final_pred)\n    count = 0\n    #here we are doing a simple comparison between the predicted_arr and the original_arr to get the final accuracy\n    for i in range(len(original_arr)):\n        if final_pred[i] == original_arr[i]:\n            count+=1\n    return count\/len(final_pred)","2a6dded4":"train_acc = get_accuracy_multiclass(predictions_train,y_train)\ntest_acc  = get_accuracy_multiclass(predictions_test,y_test)","105d4818":"print(f\"Training Accuracy: {round(train_acc*100,3)}\")\nprint(f\"Test Accuracy: {round(test_acc*100,3)}\")","d8467421":"# Creating Our Neural Network Model For Classification","b361650c":"# LabelEncoding The Attributes of The Target Column","4267abe9":"# Creating A Function To Get The Details of The Dataset","66a01e2a":"# Importing The Required Libraries","3ce1e3d5":"# Doing The Train Test Split And Scaling The Data","6c602ce2":"# Converting From Numpy Array To Torch Tensor"}}