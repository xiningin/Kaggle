{"cell_type":{"cb8ed0f4":"code","2620f601":"code","8a95027d":"code","8499abf5":"code","15cbc93b":"code","cbe90536":"code","1886a7a8":"code","c87931e5":"code","d6d5c9a2":"code","9afa1140":"code","601789ab":"code","2274c2c4":"code","e8498e58":"code","7f878be4":"code","91ae3cbd":"code","0fa1f1ee":"code","1c91af4d":"code","0072cce3":"code","fbcb1b56":"code","88096599":"code","d8dac6df":"code","315fd07b":"code","82146071":"code","b2fd8e0d":"code","69810ea1":"markdown","aaa98cca":"markdown","0e3e36ec":"markdown","3d6fe322":"markdown","446742ef":"markdown","7b82f2ef":"markdown","59ae939e":"markdown","27d9ae48":"markdown","4824d310":"markdown","835ee01a":"markdown","a50d54a9":"markdown","374ffbf7":"markdown","c56db3c3":"markdown","31fc7e67":"markdown"},"source":{"cb8ed0f4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2620f601":"import pandas as pd                            # File Handling\nimport numpy as np                             # Mathematical Computation","8a95027d":"from sklearn.model_selection import train_test_split                # Splitting Dataset into Train\/Test sets","8499abf5":"from sklearn.tree import DecisionTreeClassifier                     # For implementing Decision Tree classifier","15cbc93b":"from sklearn.metrics import accuracy_score                          # For calculating accuracy\nfrom sklearn.metrics import classification_report                   # For evaluating the model","cbe90536":"from sklearn import tree                                            # Visualizing Decision Tree","1886a7a8":"Dataset = pd.read_csv(\"\/kaggle\/input\/iris\/Iris.csv\")","c87931e5":"Dataset = Dataset.dropna()                     # Dropping empty rows","d6d5c9a2":"Dataset.head()","9afa1140":"Dataset.shape","601789ab":"Dataset[\"Species\"].unique()                      # Unique values of Species","2274c2c4":"Dataset = Dataset.replace(to_replace =\"Iris-setosa\",          value =\"0\") \nDataset = Dataset.replace(to_replace =\"Iris-versicolor\",      value =\"1\") \nDataset = Dataset.replace(to_replace =\"Iris-virginica\",       value =\"2\") ","e8498e58":"X = np.array(Dataset[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']])                   # Input\nY = np.array(Dataset[\"Species\"])                                                                            # Targets","7f878be4":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 100)                                    # 80:20","91ae3cbd":"clf_gini = DecisionTreeClassifier(criterion = \"gini\",                # Criterion\n                                  max_depth = 5,                     # Max Height of Tree\n                                  min_samples_leaf = 3,              # Maximum Leaf samples\n                                  random_state = 100)","0fa1f1ee":"clf_gini.fit(X_train, Y_train)                                       # Training the Model","1c91af4d":"clf_entropy = DecisionTreeClassifier(criterion = \"entropy\",          # Criterion\n                                     max_depth = 5,                  # Max Height of Tree\n                                     min_samples_leaf = 3,           # Max Leaf samples\n                                     random_state = 100)","0072cce3":"clf_entropy.fit(X_train, Y_train)                                    # Training the model","fbcb1b56":"y_pred_gini = clf_gini.predict(X_test)                                # Performing Prediction on test input","88096599":"print (\"Accuracy : \", accuracy_score(Y_test,y_pred_gini)*100)         # Evaulating predictions with test labels\nprint (\"Report : \",  classification_report(Y_test, y_pred_gini))","d8dac6df":"y_pred_entropy = clf_entropy.predict(X_test)                                # Performing Prediction on test input","315fd07b":"print (\"Accuracy : \", accuracy_score(Y_test,y_pred_entropy)*100)            # Evaulating predictions with test labels\nprint (\"Report : \",  classification_report(Y_test, y_pred_entropy))","82146071":"tree.plot_tree(clf_gini)","b2fd8e0d":"tree.plot_tree(clf_entropy)","69810ea1":"## Visualizing Decision tree","aaa98cca":"## Loading Dataset","0e3e36ec":"#### Gini Index","3d6fe322":"## Importing Libraries","446742ef":"## Changing Species Name to Numbers","7b82f2ef":"#### Entropy","59ae939e":"## Splitting Input and Targets","27d9ae48":"## Training Decision Tree","4824d310":"## Splitting Dataset into Train\/Test set","835ee01a":"#### Using Entropy","a50d54a9":"## Evaluating The model","374ffbf7":"#### Entropy","c56db3c3":"#### Using Gini Index","31fc7e67":"#### Gini Index"}}