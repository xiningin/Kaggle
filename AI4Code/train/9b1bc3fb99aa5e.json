{"cell_type":{"066cd961":"code","67cfb427":"code","720aeee2":"code","f9820bcb":"code","7ba02a50":"code","a4c0f245":"code","4f1e8fbb":"code","0cce3789":"code","05ff8787":"code","0bd147cd":"code","36a3d9e3":"code","12b9075e":"markdown","e888034b":"markdown","afc57943":"markdown","24a967ea":"markdown","5e070fef":"markdown","40b83090":"markdown","10aacc6d":"markdown","db33feaa":"markdown","3ad64397":"markdown","56f0ab56":"markdown","5c11d588":"markdown"},"source":{"066cd961":"import numpy as np\nimport pandas as pd\n\nimport gc\n\nfrom IPython.display import clear_output\n!pip install -q -U keras-tuner\nclear_output()\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport kerastuner as kt\n\nfrom sklearn import ensemble\n\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier","67cfb427":"TRAIN_PATH = \"..\/input\/titanic\/train.csv\"\nTEST_PATH = \"..\/input\/titanic\/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"..\/input\/titanic\/gender_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\nID = \"PassengerId\"\nTARGET = \"Survived\"\nTEST_SIZE = 0.2\nRANDOM_SEED = 42\nMAX_TRIAL = 3 # for simple test \nEPOCHS = 5  # for simple test \nVALIDATION_SPLIT = 0.15","720aeee2":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)","f9820bcb":"#1. delete unnecessary columns\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp','Parch']\ntrain = train.drop(drop_elements, axis = 1)\ntest = test.drop(drop_elements, axis = 1)\n\n#2.find null data and fill new data \ndef checkNull_fillData(df):\n    for col in df.columns:\n        if len(df.loc[df[col].isnull() == True]) != 0:\n            if df[col].dtype == \"float64\" or df[col].dtype == \"int64\":\n                df.loc[df[col].isnull() == True,col] = df[col].mean()\n            else:\n                df.loc[df[col].isnull() == True,col] = df[col].mode()[0]\n                \ncheckNull_fillData(train)\ncheckNull_fillData(test)\n\n#3.one hot encoding \nstr_list = [] \nnum_list = []\nfor colname, colvalue in train.iteritems():\n    if type(colvalue[1]) == str:\n        str_list.append(colname)\n    else:\n        num_list.append(colname)\n        \ntrain = pd.get_dummies(train, columns=str_list)\ntest = pd.get_dummies(test, columns=str_list)","7ba02a50":"y = train[TARGET]\nX = train.drop([TARGET],axis=1)\nX_test = test\n\ngc.collect()","a4c0f245":"X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=TEST_SIZE,random_state=RANDOM_SEED)","4f1e8fbb":"def build_random_forest(hp):\n    model = ensemble.RandomForestClassifier(\n        n_estimators=hp.Int('n_estimators', 10, 50, step=10),\n        max_depth=hp.Int('max_depth', 3, 10))\n    return model\n\ntuner = kt.tuners.Sklearn(\n    oracle=kt.oracles.BayesianOptimization(\n        objective=kt.Objective('score', 'max'),\n        max_trials=10),\n    hypermodel= build_random_forest,\n    directory='.',\n    project_name='random_forest')\n\ntuner.search(X_train.values, y_train.values.ravel())\nbest_hp = tuner.get_best_hyperparameters(num_trials=1)[0]","0cce3789":"model = tuner.hypermodel.build(best_hp)\nmodel.fit(X_train, y_train.values)","05ff8787":"pred_val = model.predict(X_val)\nprint(accuracy_score(y_val, pred_val))","0bd147cd":"pred_test = model.predict(X_test)","36a3d9e3":"sub = pd.read_csv(SAMPLE_SUBMISSION_PATH)\nsub[TARGET]=(pred_test > 0.5).astype(int)\nsub.to_csv(SUBMISSION_PATH,index=False)\nsub.head()","12b9075e":"# global variables","e888034b":"# load data ","afc57943":"# submission","24a967ea":"# get best model","5e070fef":"# evaluate model","40b83090":"# search best parameter using keras tuner ","10aacc6d":"# split data (train set and validation set)","db33feaa":"# preprocess","3ad64397":"# predict test data using best model","56f0ab56":"# import libraries","5c11d588":"# split data (input data and target data)"}}