{"cell_type":{"8ef13c3b":"code","aa01165f":"code","a283e5f1":"code","ad4e0f01":"code","1542a42a":"code","9450a3b8":"code","7178b9fb":"code","4558e746":"code","11afd4c3":"code","d760d246":"code","73b830a9":"code","a78fa22d":"code","46cf1dad":"code","01c2bf05":"code","fac7fbf8":"code","aa2e1547":"code","500e0998":"code","7c05ac00":"code","77efb284":"code","215387dd":"code","84a675c8":"code","6f97c0da":"code","0eb94e2c":"code","4bd263ca":"code","2bcc171a":"code","c5d8a2d2":"markdown","6f6f942f":"markdown"},"source":{"8ef13c3b":"import pandas as pd\nimport numpy as np\nimport time\nimport copy\n\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nfrom sklearn import model_selection\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision\nfrom torchvision import transforms\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","aa01165f":"train_csv = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest_csv = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntrain_csv.head(6)","a283e5f1":"train_csv.info(0)","ad4e0f01":"plt.imshow(train_csv.iloc[50, 1:].values.reshape(28,28,1))","1542a42a":"train, val = model_selection.train_test_split(train_csv,\n                                              test_size=0.2,\n                                              random_state=42,\n                                              shuffle=True)","9450a3b8":"train.shape, val.shape","7178b9fb":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom torchvision import transforms\n\n\nclass DigitClassifier(Dataset):\n    def __init__(self, values, targets, phase='', transform=True):\n        super(DigitClassifier, self).__init__()\n\n        self.values = values\n        self.targets = targets\n        self.phase = phase\n        self.transform = transform\n\n    def aug(self, image, phase):\n        augu = {\n            'train': transforms.Compose([\n                    transforms.ToPILImage(),\n                    transforms.Grayscale(num_output_channels=1),\n                    transforms.ColorJitter(brightness=(0.5,0.9)),#, contrast=(0.5,0.9)),#,p=0.5),\n                    transforms.RandomRotation(degrees=(0.5,0.9)),\n                    transforms.ToTensor(),\n                    #transforms.Normalize((0.5,), (0.5,)),\n                    \n                ]),\n            'val': transforms.Compose([\n                    transforms.ToPILImage(),\n                    transforms.Grayscale(num_output_channels=1),\n                    transforms.ToTensor(),\n                    #transforms.Normalize((0.5,), (0.5,)),\n                ]),\n        }\n        \n        return augu[phase](image)\n\n\n    def __len__(self):\n        return len(self.values)\n\n    def __getitem__(self, idx):\n        self.X = self.values[idx]\n        self.y = self.targets[idx]\n\n        #self.X = np.squeeze(self.X.reshape(1,28,28).astype(\"uint8\"), axis=0)#np.squeeze(self.X.reshape(1,28,28).astype(\"uint8\"), axis=2)\n        #self.X = np.squeeze(self.X.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None])#, axis=1)\n        #self.X = np.squeeze(self.X.astype(np.uint8).reshape((1, 28, 28)))#, axis=2)\n        self.X = np.asarray(self.X, dtype=np.uint8).reshape(28,28)\n        \n        if self.transform:\n            self.X = self.aug(self.X, self.phase)\n\n        '''return {\n            'img' : torch.Tensor(self.X),\n            'label' : torch.Tensor(self.y)\n        }'''\n        return self.X, self.y","4558e746":"'''class DigitClassifier(Dataset):\n    def __init__(self, images, labels, phase='', transform=True):\n        self.images = images\n        self.labels = labels\n        self.phase = phase\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.images)\n    \n    def agumentation(self, image, phase):\n        augu = {\n            'train': transforms.Compose([\n                    transforms.ToPILImage(),\n                    transforms.ColorJitter(brightness=(0.5,0.9)),#, contrast=(0.5,0.9)),#,p=0.5),\n                    transforms.RandomRotation(degrees=(0.5,0.9)),\n                    #transforms.Normalize(mean=(0.485, 0.456, 0.406), \n                    #             std=(0.229, 0.224, 0.225), \n                    #             inplace=True),\n                    transforms.ToTensor(),\n                ]),\n            'val': transforms.Compose([\n                    transforms.ToPILImage(),\n                    transforms.ToTensor(),\n                ]),\n        }\n        \n        return augu[phase](image)#augu(image=image)\n        \n    \n    def __getitem__(self, idx):\n        x = self.images[idx]\n        #x = Image.fromarray(x)\n        y = self.labels[idx]\n        \n        if self.transform:\n            x = self.agumentation(x, self.phase)\n        #return torch.tensor(x), torch.tensor(y)\n        return x, y'''","11afd4c3":"dataset = {\n    'train' : DigitClassifier(train.drop([\"label\"], axis=1).values, train.label.values, phase='train', transform=True),\n    'val' : DigitClassifier(val.drop([\"label\"], axis=1).values, val.label.values, phase='val', transform=True)\n}","d760d246":"#train_dataset = DigitClassifier(train_image_array, train_labels, transform=True)\n#val_dataset = DigitClassifier(val_image_array, val_labels, transform=True)","73b830a9":"dataset['train'][1][0].shape","a78fa22d":"dataloader = {\n    'train' :  DataLoader(dataset['train'], batch_size=16, shuffle=True),\n    'val' : DataLoader(dataset['val'], batch_size=16, shuffle=True)\n}","46cf1dad":"dataset_sizes = {x: len(dataset[x]) for x in ['train', 'val']}\nclass_names = [str(x) for x in range(10)]","01c2bf05":"#train_data_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n#val_data_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)","fac7fbf8":"for batch_images, targets in dataloader['train']:\n    print(batch_images.shape)","aa2e1547":"next(iter(dataloader['train']))","500e0998":"image, label = next(iter(dataloader['train']))","7c05ac00":"grid = torchvision.utils.make_grid(image, nrow=8)\n\nplt.imshow(grid.numpy().transpose((1, 2, 0)))\nplt.axis('off')\nplt.title(label.numpy());","77efb284":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloader[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","215387dd":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image\n\n\ndef imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\ndef visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloader['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images\/\/2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","84a675c8":"model = torchvision.models.inception_v3(pretrained=True, progress=True)\nmodel.fc = nn.Linear(2048, 10, bias=True)\nmodel.to(device)\n\nloss = nn.CrossEntropyLoss()\noptimizer=torch.optim.Adam(model.parameters(), lr=0.001)\n'''scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n                                                     mode='min', \n                                                     factor=0.1, \n                                                     patience=10, \n                                                     verbose=True)'''\nscheduler=torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","6f97c0da":"class Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        #print(x.shape)\n        x = x.view(-1, 16 * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        \n        return x\n        \n\nmodel = Classifier()\nmodel.to(device)\n\nloss = nn.CrossEntropyLoss()\noptimizer=torch.optim.Adam(model.parameters(), lr=0.001)\n'''scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n                                                     mode='min', \n                                                     factor=0.1, \n                                                     patience=10, \n                                                     verbose=True)'''\nscheduler=torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","0eb94e2c":"model_history = train_model(model, loss, optimizer, scheduler, num_epochs=10)","4bd263ca":"visualize_model(model_history)","2bcc171a":"torch.save(model_history, \".\/DigitRecognizer.pt\")","c5d8a2d2":"# Dataset class","6f6f942f":"# Model"}}