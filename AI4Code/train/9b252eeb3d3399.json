{"cell_type":{"f222bdfc":"code","185a4faf":"code","dc7b9235":"code","caa26825":"code","566241ff":"code","073bd210":"code","8efe7a51":"code","87eb37b2":"code","9c1dfefe":"code","8b018600":"code","34d11a89":"code","cac88106":"code","97701c06":"code","4aba1e77":"markdown","f426f4f6":"markdown","6a27330c":"markdown","014b37d7":"markdown","f695ef1a":"markdown","eca615f2":"markdown"},"source":{"f222bdfc":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport json\nimport glob\nimport sys\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom  collections import OrderedDict\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os","185a4faf":"df=pd.read_csv(\"\/kaggle\/input\/corowp\/coroWP.csv\")\ndf.head()","dc7b9235":"!pip install bert-extractive-summarizer","caa26825":"body=df['text_body'][0]","566241ff":"from summarizer import Summarizer\nmodel = Summarizer()\nresult = model(body, min_length=50,max_length=100)\nfull0 = ''.join(result)\n","073bd210":"print(full0)","8efe7a51":"#GPT2\nbody=df['text_body'][0]\nfrom summarizer import Summarizer,TransformerSummarizer\nGPT2_model = TransformerSummarizer(transformer_type=\"GPT2\",transformer_model_key=\"gpt2-medium\")\nfull = ''.join(GPT2_model(body, min_length=50, max_length=100))","87eb37b2":"print(full)","9c1dfefe":"model = TransformerSummarizer(transformer_type=\"XLNet\",transformer_model_key=\"xlnet-base-cased\")\nfull2 = ''.join(model(body, min_length=60,max_length=100))","8b018600":"print(full2)","34d11a89":"# load BART summarizer\nimport transformers\nimport torch\nfrom transformers import BartTokenizer, BartForConditionalGeneration\ntorch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = BartForConditionalGeneration.from_pretrained('bart-large-cnn')\ntokenizer = BartTokenizer.from_pretrained('bart-large-cnn')\nfrom transformers import pipeline\nsummarizer = pipeline(task=\"summarization\")","cac88106":"summary = summarizer(body, min_length=60, max_length=100)\nprint (summary)","97701c06":"print(df['summary'][0])","4aba1e77":"**Bert Text Summarization**","f426f4f6":"**XLNet Text Summarization**","6a27330c":"**Bart Text Summarization**","014b37d7":"**Original Text**","f695ef1a":"**GPT2 Text Summarization**","eca615f2":"Text summarization is an approach that shortens long pieces of information into a shorter version. From this notebook, you will find how easy it is to generate a summarized text with just a couple lines of code. This is a subtask of my [original](https:\/\/www.kaggle.com\/latong\/text-summarization-ner-exploration) work. Note: The data is imported from this kernel([paringData](https:\/\/www.kaggle.com\/latong\/parsedata\/)). When doing summarization tasks, please do not remove punctuations from the texts. For comparison, I am going to apply the following methods:\n\n* [Bert-extractive-summarizer](https:\/\/pypi.org\/project\/bert-extractive-summarizer\/)\n* GPT2 text summarizer\n* XL text summarizer\n* [Bart text summarizer](https:\/\/github.com\/pytorch\/fairseq\/tree\/master\/examples\/bart)\n\nThe length of generated texts is set to min_length=50 and max_length=100."}}