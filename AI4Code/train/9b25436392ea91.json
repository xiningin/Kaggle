{"cell_type":{"34b992b8":"code","b6f6defb":"code","87caa3ad":"code","cce4b7e6":"code","5426dea6":"code","c2e8c81d":"code","b617181b":"code","849c7bec":"code","c1c08f51":"code","ca60c072":"code","92262f52":"markdown","7c3e22b2":"markdown","169cd8f0":"markdown","de922c67":"markdown","4f57a6f2":"markdown","1166d9fe":"markdown","3e9308aa":"markdown","42537a45":"markdown","88245208":"markdown","f5436d39":"markdown","f64c9ca1":"markdown"},"source":{"34b992b8":"!pip install --upgrade wandb","b6f6defb":"import wandb\n\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"wandb_api\")\n    wandb.login(key=api_key)\n    anony = None\n    # Initializing required to be connected to Detectron2\n    wandb.init(sync_tensorboard=True, name=\"SARTORIUS Detectron\",\n           settings=wandb.Settings(start_method=\"thread\", console=\"auto\"))\nexcept:\n    anony = \"must\"\n    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https:\/\/wandb.ai\/authorize')","87caa3ad":"!pip install 'git+https:\/\/github.com\/facebookresearch\/detectron2.git'","cce4b7e6":"import detectron2\nfrom pathlib import Path\nimport random, cv2, os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pycocotools.mask as mask_util\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer, ColorMode\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\nfrom detectron2.data.datasets import register_coco_instances\nfrom detectron2.utils.logger import setup_logger\nfrom detectron2.evaluation.evaluator import DatasetEvaluator\nsetup_logger()","5426dea6":"dataDir=Path('..\/input\/sartorius-cell-instance-segmentation\/')\ncfg = get_cfg()\ncfg.INPUT.MASK_FORMAT='bitmask'\nregister_coco_instances('sartorius_train',{}, '..\/input\/sartorius-cell-instance-segmentation-coco\/annotations_train.json', dataDir)\nregister_coco_instances('sartorius_val',{},'..\/input\/sartorius-cell-instance-segmentation-coco\/annotations_val.json', dataDir)\nmetadata = MetadataCatalog.get('sartorius_train')\ntrain_ds = DatasetCatalog.get('sartorius_train')","c2e8c81d":"d = train_ds[42]\nimg = cv2.imread(d[\"file_name\"])\nvisualizer = Visualizer(img[:, :, ::-1], metadata=metadata)\nout = visualizer.draw_dataset_dict(d)\nplt.figure(figsize = (20,15))\nplt.imshow(out.get_image()[:, :, ::-1])","b617181b":"# Taken from https:\/\/www.kaggle.com\/theoviel\/competition-metric-map-iou\ndef precision_at(threshold, iou):\n    matches = iou > threshold\n    true_positives = np.sum(matches, axis=1) == 1  # Correct objects\n    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n\ndef score(pred, targ):\n    pred_masks = pred['instances'].pred_masks.cpu().numpy()\n    enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in pred_masks]\n    enc_targs = list(map(lambda x:x['segmentation'], targ))\n    ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, ious)\n        p = tp \/ (tp + fp + fn)\n        prec.append(p)\n    return np.mean(prec)\n\nclass MAPIOUEvaluator(DatasetEvaluator):\n    def __init__(self, dataset_name):\n        dataset_dicts = DatasetCatalog.get(dataset_name)\n        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}\n            \n    def reset(self):\n        self.scores = []\n\n    def process(self, inputs, outputs):\n        for inp, out in zip(inputs, outputs):\n            if len(out['instances']) == 0:\n                self.scores.append(0)    \n            else:\n                targ = self.annotations_cache[inp['image_id']]\n                self.scores.append(score(out, targ))\n\n    def evaluate(self):\n        return {\"MaP IoU\": np.mean(self.scores)}\n\nclass Trainer(DefaultTrainer):\n    @classmethod\n    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n        return MAPIOUEvaluator(dataset_name)\n    ","849c7bec":"cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (\"sartorius_train\",)\ncfg.DATASETS.TEST = (\"sartorius_val\",)\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\ncfg.SOLVER.IMS_PER_BATCH = 2\ncfg.SOLVER.BASE_LR = 0.0005 \ncfg.SOLVER.MAX_ITER = 1000    \ncfg.SOLVER.STEPS = []        \ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   \ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  \ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\ncfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) \/\/ cfg.SOLVER.IMS_PER_BATCH  # Once per epoch\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = Trainer(cfg) \ntrainer.resume_or_load(resume=False)\ntrainer.train()","c1c08f51":"cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\npredictor = DefaultPredictor(cfg)\ndataset_dicts = DatasetCatalog.get('sartorius_val')\nouts = []\nfor d in random.sample(dataset_dicts, 3):    \n    im = cv2.imread(d[\"file_name\"])\n    outputs = predictor(im)  # format is documented at https:\/\/detectron2.readthedocs.io\/tutorials\/models.html#model-output-format\n    v = Visualizer(im[:, :, ::-1],\n                   metadata = MetadataCatalog.get('sartorius_train'), \n                    \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n    )\n    out_pred = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    visualizer = Visualizer(im[:, :, ::-1], metadata=MetadataCatalog.get('sartorius_train'))\n    out_target = visualizer.draw_dataset_dict(d)\n    outs.append(out_pred)\n    outs.append(out_target)\n_,axs = plt.subplots(len(outs)\/\/2,2,figsize=(40,45))\nfor ax, out in zip(axs.reshape(-1), outs):\n    ax.imshow(out.get_image()[:, :, ::-1])","ca60c072":"!ls .\/output\/model_final.pth","92262f52":"![image.png](attachment:380aa30c-bdd7-4e0c-b878-4b5464844a1e.png)\n![image.png](attachment:442b1d3b-04fa-46e6-97cf-93c12f94d540.png)","7c3e22b2":"### Display a sample file to check the data is loaded correctly","169cd8f0":"### Train\nI haven't done any hyperparameter optimization yet, this is mostly taken as is from the Detectron tutorial. \n\nTraining for 1000 iterations here for demonstration. For a high scoring model you will need to train it longer, closer to 10000 with these settings","de922c67":"# **Do not forget to go to Add-ons -> Secrets and provide your W&B access token**","4f57a6f2":"<img src=\"https:\/\/i.imgur.com\/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\" \/>\n\n<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\"> Weights & Biases (W&B) is a set of machine learning tools that helps you build better models faster. <strong>Kaggle competitions require fast-paced model development and evaluation<\/strong>. There are a lot of components: exploring the training data, training different models, combining trained models in different combinations (ensembling), and so on.<\/span>\n\n> <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">\u23f3 Lots of components = Lots of places to go wrong = Lots of time spent debugging<\/span>\n\n<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">W&B can be useful for Kaggle competition with it's lightweight and interoperable tools:<\/span>\n\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Quickly track experiments,<br><\/span>\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Version and iterate on datasets, <br><\/span>\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Evaluate model performance,<br><\/span>\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Reproduce models,<br><\/span>\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Visualize results and spot regressions,<br><\/span>\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Share findings with colleagues.<\/span>\n\n<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">To learn more about Weights and Biases check out this <strong><a href=\"https:\/\/www.kaggle.com\/ayuraj\/experiment-tracking-with-weights-and-biases\">kernel<\/a><\/strong>.<\/span>","1166d9fe":"### Load the competition data\nThis is very simple once we have our data in the COCO format. See the [part one notebook](https:\/\/www.kaggle.com\/slawekbiel\/positive-score-with-detectron-1-3-input-data\/) for details.","3e9308aa":"### Define evaluator \nGenerates lines like this in the training output:\n`[10\/27 18:31:26 d2.evaluation.testing]: copypaste: MaP IoU=0.2192638391201311` \n\nSee here for definition: https:\/\/www.kaggle.com\/c\/sartorius-cell-instance-segmentation\/overview\/evaluation","42537a45":"## Training\n\nAll the heavy lifting here is done by the [detectron](https:\/\/github.com\/facebookresearch\/detectron2) library. What's needed from us is pointing it to the annotation files of our dataset (see [part one](https:\/\/www.kaggle.com\/slawekbiel\/positive-score-with-detectron-1-3-input-data\/) for details), setting some hyperparameters and calling `trainer.train()`\n\nMost of the code here is just for displaying things to make sure everything is set up correctly and the training worked.","88245208":"ORIGINAL FROM: https:\/\/www.kaggle.com\/slawekbiel\/positive-score-with-detectron-2-3-training by: @slawekbiel\n#### Version history\n* V1 - Basic training with default settings\n* V2 - Added a custom evaluator to track the competition metric during training\n\n**This new version adds just W&B to monitor better** \n\nall other code is originally from @slawekbiel\n\nThe W&B code is from: https:\/\/www.kaggle.com\/debarshichanda\/pytorch-w-b-jigsaw-starter and https:\/\/www.kaggle.com\/ayuraj\/experiment-tracking-with-weights-and-biases","f5436d39":"### Lets look at some of the validation files to check if things look reasonable\nWe show predictions on the left and ground truth on the right","f64c9ca1":"### We can see that while it is not perfect, it did learn something\nWe can now take our model file and use it to generate submission in the [final notebook](https:\/\/www.kaggle.com\/slawekbiel\/positive-score-with-detectron-3-3-inference)"}}