{"cell_type":{"5d3e0c63":"code","a82b5f8c":"code","a6a5f7a8":"code","afe93785":"code","98256645":"code","c0ed7a65":"code","8fc0c92c":"code","7914776a":"code","ec192c65":"code","ca0d29c4":"code","21f7c3c2":"code","67b27fdd":"markdown"},"source":{"5d3e0c63":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a82b5f8c":"import os\nbase_dir = '\/kaggle\/input\/covid19-image-dataset\/Covid19-dataset\/'\n\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'test')\n\n# Directory with our training cat\/dog pictures\ntrain_covid_dir = os.path.join(train_dir, 'Covid')\ntrain_normal_dir = os.path.join(train_dir, 'Normal')\ntrain_pneumonia_dir = os.path.join(train_dir, 'Viral Pneumonia')\n\n# Directory with our validation cat\/dog pictures\nvalidation_covid_dir = os.path.join(validation_dir, 'Covid')\nvalidation_normal_dir = os.path.join(validation_dir, 'Normal')\nvalidation_pneumonia_dir = os.path.join(validation_dir, 'Viral Pneumonia')","a6a5f7a8":"train_covid_fnames = os.listdir(train_covid_dir)\ntrain_normal_fnames = os.listdir(train_normal_dir)\ntrain_pneumonia_fnames = os.listdir(train_pneumonia_dir)\n\nprint(train_covid_fnames[:10])\nprint(train_normal_fnames[:10])\nprint(train_pneumonia_fnames[:10])","afe93785":"%matplotlib inline\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n# Parameters for our graph; we'll output images in a 4x4 configuration\n\nnrows = 6\nncols = 4\n\npic_index = 0 # Index for iterating over images","98256645":"# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\npic_index+=8\n\nnext_covid_pix = [os.path.join(train_covid_dir, fname) \n                for fname in train_covid_fnames[ pic_index-8:pic_index] \n               ]\n\nnext_normal_pix = [os.path.join(train_normal_dir, fname) \n                for fname in train_normal_fnames[ pic_index-8:pic_index]\n               ]\n\nnext_pneumonia_pix = [os.path.join(train_pneumonia_dir, fname) \n                for fname in train_pneumonia_fnames[ pic_index-8:pic_index]\n               ]\n\nfor i, img_path in enumerate(next_covid_pix+next_normal_pix+next_pneumonia_pix):\n  # Set up subplot; subplot indices start at 1\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off') # Don't show axes (or gridlines)\n\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n\nplt.show()","c0ed7a65":"import tensorflow as tf\n \nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2), \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n    tf.keras.layers.MaxPooling2D(2,2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(), \n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'), \n    tf.keras.layers.Dense(3, activation='softmax')  \n])\n","8fc0c92c":"model.summary()","7914776a":"model.compile(optimizer='adam', loss= 'categorical_crossentropy', metrics=['accuracy'])","ec192c65":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# All images will be rescaled by 1.\/255.\ntrain_datagen = ImageDataGenerator( rescale = 1.0\/255. )\ntest_datagen  = ImageDataGenerator( rescale = 1.0\/255. )\n\n# --------------------\n# Flow training images in batches of 20 using train_datagen generator\n# --------------------\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size=20,\n                                                    class_mode='categorical',\n                                                    target_size=(150, 150))     \n# --------------------\n# Flow validation images in batches of 20 using test_datagen generator\n# --------------------\nvalidation_generator =  test_datagen.flow_from_directory(validation_dir,\n                                                         batch_size=20,\n                                                         class_mode  = 'categorical',\n                                                         target_size = (150, 150))","ca0d29c4":"history = model.fit(train_generator,\n                              validation_data=validation_generator,\n                              steps_per_epoch=12,\n                              epochs=15,\n                              validation_steps = 3,\n                              verbose=2)","21f7c3c2":"import numpy as np\nimport random\nfrom   tensorflow.keras.preprocessing.image import img_to_array, load_img\n\n# Let's define a new Model that will take an image as input, and will output\n# intermediate representations for all layers in the previous model after\n# the first.\nsuccessive_outputs = [layer.output for layer in model.layers[1:]]\n\n#visualization_model = Model(img_input, successive_outputs)\nvisualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n\n# Let's prepare a random input image of a cat or dog from the training set.\ncovid_img_files = [os.path.join(train_covid_dir, f) for f in train_covid_fnames]\nnormal_img_files = [os.path.join(train_normal_dir, f) for f in train_normal_fnames]\npneumonia_img_files = [os.path.join(train_pneumonia_dir, f) for f in train_pneumonia_fnames]\n\nimg_path = random.choice(covid_img_files + normal_img_files + pneumonia_img_files)\nimg = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n\nx   = img_to_array(img)                           # Numpy array with shape (150, 150, 3)\nx   = x.reshape((1,) + x.shape)                   # Numpy array with shape (1, 150, 150, 3)\n\n# Rescale by 1\/255\nx \/= 255.0\n\n# Let's run our image through our network, thus obtaining all\n# intermediate representations for this image.\nsuccessive_feature_maps = visualization_model.predict(x)\n\n# These are the names of the layers, so can have them as part of our plot\nlayer_names = [layer.name for layer in model.layers]\n\n# -----------------------------------------------------------------------\n# Now let's display our representations\n# -----------------------------------------------------------------------\nfor layer_name, feature_map in zip(layer_names, successive_feature_maps):\n  \n  if len(feature_map.shape) == 4:\n    \n    #-------------------------------------------\n    # Just do this for the conv \/ maxpool layers, not the fully-connected layers\n    #-------------------------------------------\n    n_features = feature_map.shape[-1]  # number of features in the feature map\n    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n    \n    # We will tile our images in this matrix\n    display_grid = np.zeros((size, size * n_features))\n    \n    #-------------------------------------------------\n    # Postprocess the feature to be visually palatable\n    #-------------------------------------------------\n    for i in range(n_features):\n      x  = feature_map[0, :, :, i]\n      x -= x.mean()\n      x \/= x.std ()\n      x *=  64\n      x += 128\n      x  = np.clip(x, 0, 255).astype('uint8')\n      display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid\n\n    #-----------------\n    # Display the grid\n    #-----------------\n\n    scale = 20. \/ n_features\n    plt.figure( figsize=(scale * n_features, scale) )\n    plt.title ( layer_name )\n    plt.grid  ( False )\n    plt.imshow( display_grid, aspect='auto', cmap='viridis' ) ","67b27fdd":"## the next step is to define the model that will be trained to recognize covid, normal or Viral Pneumonia from these images"}}