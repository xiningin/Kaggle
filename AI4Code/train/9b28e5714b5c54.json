{"cell_type":{"f914b845":"code","279920a7":"code","503ce05a":"code","5f7a3947":"code","cebf332a":"code","20197e41":"code","504f8be4":"code","4a529a6f":"code","cc39e9ed":"code","83f1603b":"code","325b65e3":"code","67802018":"code","8172be97":"code","d41a1cb9":"code","cd3e5884":"code","37ad16d3":"code","e5eace7f":"code","50e9e07c":"code","eb1bf58b":"code","071090c2":"code","7f37aba0":"code","2e857235":"code","a74466db":"code","b36ab286":"markdown","ca2cb8d0":"markdown","518a4c6e":"markdown","dc156b0c":"markdown","369aa2db":"markdown","3256593d":"markdown","7e83afe9":"markdown","a3cf8742":"markdown","6d6ad921":"markdown"},"source":{"f914b845":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","279920a7":"train_dir = '..\/input\/train_images'\ntest_dir = '..\/input\/test_images'\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')","503ce05a":"len(os.listdir(test_dir))","5f7a3947":"len(os.listdir(train_dir))","cebf332a":"#basic visualizations\ntrain_df.head(5)","20197e41":"train_df[\"id_code\"]=train_df[\"id_code\"].apply(lambda x:x+\".png\")","504f8be4":"train_df.head(5)","4a529a6f":"#Lets display one one from each category\nimport cv2\nimport matplotlib.pyplot as plt\nimg = []\nimg.append(os.path.join(train_dir,'002c21358ce6.png'))\nimg.append(os.path.join(train_dir,'005b95c28852.png'))\n\nimg.append(os.path.join(train_dir,'0124dffecf29.png'))\nimg.append(os.path.join(train_dir,'00cb6555d108.png'))\n\nimg.append(os.path.join(train_dir,'03676c71ed1b.png'))\nimg.append(os.path.join(train_dir,'03747397839f.png'))\n\nimg.append(os.path.join(train_dir,'0104b032c141.png'))\nimg.append(os.path.join(train_dir,'03c85870824c.png'))\n\n\nimg.append(os.path.join(train_dir,'03a7f4a5786f.png'))\nimg.append(os.path.join(train_dir,'0318598cfd16.png'))\n\nimages = []\nfor i in range(0,len(img)):\n    images.append(plt.imread(img[i]))    ","cc39e9ed":"images[0].shape","83f1603b":"plt.figure(figsize=[32,32])\ni = 0\nfor img_name in images:\n    plt.subplot(5, 2,i+1)\n    plt.imshow(img_name)\n    if(i<2):\n        plt.title(\"No DR\")\n    elif(i>=2 and i<4):\n        plt.title(\"Mild\")\n    elif(i>=4 and i<6):\n        plt.title(\"Moderate\")\n    elif(i>=6 and i<8):\n        plt.title(\"Severe\")\n    elif(i>=8 and i<10):\n        plt.title(\"Proliferative DR\")\n    i+=1","325b65e3":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1\/255.,\n                                  horizontal_flip = True,\n                                  width_shift_range = 0.2,\n                                  height_shift_range = 0.2,\n                                  fill_mode = 'nearest',\n                                  validation_split = 0.15,\n                                  zoom_range = 0.3,\n                                  rotation_range = 30)\n","67802018":"train_df['diagnosis'] = train_df['diagnosis'].astype('str')","8172be97":"train_generator = train_datagen.flow_from_dataframe(\n    dataframe = train_df,\n    directory = train_dir,\n    validation_split = 0.2,\n    x_col = 'id_code',\n    y_col = 'diagnosis',\n    target_size = (800,800),\n    class_mode = 'categorical',\n    batch_size = 32,\n    subset = 'training'\n)\n\nval_generator = train_datagen.flow_from_dataframe(\n    dataframe = train_df,\n    x_col = 'id_code',\n    y_col = 'diagnosis',\n    directory = train_dir,\n    class_mode = \"categorical\",\n    batch_size = 32,\n    target_size = (800,800),\n    subset = \"validation\"\n    )","d41a1cb9":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, Flatten, Activation, Dropout, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers, applications\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\nfrom IPython.display import Image\nfrom keras.preprocessing import image\nfrom keras import optimizers\nfrom keras import layers,models\nfrom keras.applications.imagenet_utils import preprocess_input\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras import regularizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import DenseNet121, DenseNet169, DenseNet201\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Conv2D, MaxPool2D, Dense, Dropout, Activation, Flatten\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.optimizers import Adam\n\nmodel = Sequential()\nmodel.add(Conv2D(32,(3,3),activation = 'relu',input_shape = (800,800,3)))\nmodel.add(Conv2D(32,(3,3),activation = 'relu'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Conv2D(64,(3,3),activation = 'relu'))\nmodel.add(Conv2D(64,(3,3),activation = 'relu'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Conv2D(128,(3,3),activation = 'relu'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Conv2D(128,(3,3),activation = 'relu'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Conv2D(128,(3,3),activation = 'relu'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Conv2D(128,(3,3),activation = 'relu'))\nmodel.add(MaxPool2D(2,2))\n\nmodel.add(Flatten())\nmodel.add(Dense(512,activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(5,activation = 'softmax'))","cd3e5884":"model.summary()","37ad16d3":"#some callbacks and tensorboard initialization\n\ncallbacks = [ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n","e5eace7f":"model.compile(loss = 'categorical_crossentropy',optimizer = Adam(),metrics = ['accuracy'])","50e9e07c":"history = model.fit_generator(\n    train_generator,\n    epochs = 80,\n    steps_per_epoch = 20,\n    validation_data = val_generator,\n    validation_steps = 7,\n    callbacks = callbacks\n)","eb1bf58b":"#plotting accuracies and losses\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1,len(acc) + 1)\n\nplt.plot(epochs,acc,'bo',label = 'Training Accuracy')\nplt.plot(epochs,val_acc,'b',label = 'Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs,loss,'bo',label = 'Training loss')\nplt.plot(epochs,val_loss,'b',label = 'Validation Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\nplt.show()","071090c2":"#make predictions on test images\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\n\nsample_df = pd.read_csv('..\/input\/sample_submission.csv')\n\nsample_df[\"id_code\"]=sample_df[\"id_code\"].apply(lambda x:x+\".png\")\n\ntest_generator = test_datagen.flow_from_dataframe(  \n        dataframe=sample_df,\n        directory = test_dir,    \n        x_col=\"id_code\",\n        target_size = (800,800),\n        batch_size = 1,\n        shuffle = False,\n        class_mode = None\n        )","7f37aba0":"preds = model.predict_generator(\n    test_generator,\n    steps=len(test_generator.filenames)\n)","2e857235":"#submission formatting\nfilenames= test_generator.filenames\nresults=pd.DataFrame({\"id_code\":filenames,\n                      \"diagnosis\":np.argmax(preds,axis = 1)})\nresults['id_code'] = results['id_code'].map(lambda x: str(x)[:-4])\nresults.to_csv(\"submission.csv\",index=False)","a74466db":"count = 0\nfor i in range(0,len(results['diagnosis'])):\n    if(results['diagnosis'][i] == 4):\n        count+=1\n    \ncount","b36ab286":"Some simple visualizations","ca2cb8d0":"Data image augmentation","518a4c6e":"We make the first layer non-trainable and add a few dense layers along with Flatten() and a Dropout layer to prevent overfitting","dc156b0c":"Specifying Train and Test directories","369aa2db":"Training for 80 epochs!","3256593d":"**In this model, we use a simple Keras CNN to train from scratch**\n* We use the Keras ImageDataGenerator library for augmentation and pre-processing\n* We implement tensorboard and Checkpoint callbacks for accuracy monitoring","7e83afe9":"Go ahead and submit!","a3cf8742":"Loading two images from every category","6d6ad921":"Implementing callbacks"}}