{"cell_type":{"2d1d8d84":"code","5a7e443a":"code","25f2779e":"code","3ce7eab0":"code","66d74ed0":"code","cf584b81":"code","b28862ad":"code","55c5e05f":"code","f5527aa1":"code","3332d5c1":"code","3ed0489d":"code","f94e91f8":"code","cdc0f2a1":"code","8fcf2421":"code","fe93a1de":"code","f4f66c1c":"code","957a3465":"code","4fba272f":"code","c1ca7d98":"code","38220d42":"code","cf563c7a":"code","681920e7":"code","45cdeaa8":"code","43bf9f1f":"code","7fd2b82a":"code","d9e048a1":"code","39a017bb":"code","1b0aed7e":"code","6dbbb3ba":"code","e73b7cf4":"code","6bbb1b36":"code","77230d41":"code","c1949b55":"code","e8596110":"code","41395d82":"code","ac52c9d8":"code","2472b40a":"code","1a236ae6":"code","6777b119":"code","02a47fa3":"code","a314e225":"code","9d26c15a":"code","30600bc5":"code","a4d8f60c":"code","2bcd02fb":"code","d5ba1d54":"code","8fd70614":"code","4930bc98":"code","2dd9eb0c":"code","dcf956b5":"code","92baacd0":"code","ec90df2f":"code","94866dda":"code","1f982894":"code","6cf56d9e":"code","0813662a":"code","f92b2613":"code","30c1d0bc":"code","ad285eef":"code","0fdf0df7":"code","18ed2177":"code","95c070fc":"code","7a3b2d8e":"code","5cf238b0":"code","1ed25e6c":"code","93a1492e":"code","1cf979ec":"code","8686a97d":"code","e5bcbb8f":"code","e40bfc86":"code","2e550173":"code","8038a479":"code","939ecef5":"code","596e4c6e":"markdown","22c4ce05":"markdown","9e420c11":"markdown","09574706":"markdown","89c10806":"markdown","28b7d9f4":"markdown","54843355":"markdown","ef63f447":"markdown","fc3aa592":"markdown","d63f02df":"markdown","28d8ca6d":"markdown","de6160a5":"markdown","7f5159d7":"markdown","2fed4538":"markdown","228d12e9":"markdown","36e4a263":"markdown","17ce6f1a":"markdown","7e83095a":"markdown","3bfc6200":"markdown","e2089d88":"markdown","b3415f8c":"markdown","9c8c062a":"markdown","170fa822":"markdown","00dafa3f":"markdown","b8a0c826":"markdown","05e5cf0a":"markdown","195d17ea":"markdown","ce45bddb":"markdown","d0227098":"markdown"},"source":{"2d1d8d84":"# packages \nimport numpy as np\nimport pandas as pd\nimport time\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport scipy.stats as stats\n\nfrom sklearn.metrics import mean_absolute_error\n\nimport h2o\nfrom h2o.estimators import H2ORandomForestEstimator","5a7e443a":"# import data\ndf = pd.read_csv('..\/input\/nigerian-used-car-marketplace\/car_scrape.csv')\ndf.head()","25f2779e":"# dimensions of table\ndf.shape","3ce7eab0":"# summary stats\ndf.describe(include='all')","66d74ed0":"# show rows having unreasonable years\ndf[(df.year<1980) | (df.year>2020)]","cf584b81":"# these are only 5 rows, so let's remove them\ndf = df[(df.year>=1980) & (df.year<=2020)]","b28862ad":"# convert to upper case in a first step\ndf.paint = list(map(str.upper, df.paint))\nlevels = df.paint.value_counts()\nlevels.index","55c5e05f":"# now correct misspellings, redundant spaces, etc.\ndf.paint = df.paint.replace({'SLIVER': 'SILVER'})\ndf.paint = df.paint.replace({'SLIVER ': 'SILVER'})\ndf.paint = df.paint.replace({'BLUE ': 'BLUE'})\ndf.paint = df.paint.replace({'GREY ': 'GREY'})\ndf.paint = df.paint.replace({'GERY': 'GREY'})\ndf.paint = df.paint.replace({'GOLD ': 'GOLD'})\ndf.paint = df.paint.replace({'BLACK ': 'BLACK'})\ndf.paint = df.paint.replace({' BLACK': 'BLACK'})\ndf.paint = df.paint.replace({'BLACK.': 'BLACK'})\ndf.paint = df.paint.replace({'BLAC': 'BLACK'})\ndf.paint = df.paint.replace({'DARK BLUE ': 'DARK BLUE'})\ndf.paint = df.paint.replace({'CREAM ': 'CREAM'})\ndf.paint = df.paint.replace({'SILVER ': 'SILVER'})\ndf.paint = df.paint.replace({'GREEN ': 'GREEN'})\ndf.paint = df.paint.replace({'WHITE ': 'WHITE'})\ndf.paint = df.paint.replace({'  BROWN': 'BROWN'})\ndf.paint = df.paint.replace({'GRAY': 'GREY'})\ndf.paint = df.paint.replace({'GRAY ': 'GREY'})\ndf.paint = df.paint.replace({'DARK GRAY': 'DARK GREY'})\ndf.paint = df.paint.replace({'REDL': 'RED'})\ndf.paint = df.paint.replace({'SKYE BLUE': 'SKY BLUE'})\ndf.paint = df.paint.replace({'DARK SILVER ': 'DARK SILVER'})\ndf.paint = df.paint.replace({'LIGHT SILVER ': 'LIGHT SILVER'})\ndf.paint = df.paint.replace({'OFF WHITE L': 'OFF WHITE'})\ndf.paint = df.paint.replace({' BLACK\/RED': 'BLACK\/RED'})\ndf.paint = df.paint.replace({'WHINE ': 'WINE'})\ndf.paint = df.paint.replace({'WHITE ORCHILD PEARL': 'WHITE ORCHID PEARL'})\ndf.paint = df.paint.replace({'MAGNETIC GRAY': 'MAGNETIC GREY'})\ndf.paint = df.paint.replace({'MAGNETIC GRAY METALLIC': 'MAGNETIC GREY METALLIC'})","f5527aa1":"# check\npaint_count = df.paint.value_counts()\npaint_count","3332d5c1":"# for the following reduce paints to only those that occur at least 10 times \npaint_top = list(paint_count[paint_count.values>10].index)\ndf['paint_reduced'] = df.paint.where(df.paint.isin(paint_top), '_OTHER_')\ndf.paint_reduced.value_counts()","3ed0489d":"def first_piece(i_string):\n    return i_string.split()[0]\n\ndf['manufacturer'] = list(map(first_piece, df.title))","f94e91f8":"# minor adjustment\ndf.manufacturer = df.manufacturer.replace({'Land': 'Land Rover'})","cdc0f2a1":"# count frequencies\nmanu_count = df.manufacturer.value_counts()\nmanu_count","8fcf2421":"# again reduce number of levels\nmanu_top = list(manu_count[manu_count.values>10].index)\ndf['manufacturer_reduced'] = df.manufacturer.where(df.manufacturer.isin(manu_top), '_OTHER_')\ndf.manufacturer_reduced.value_counts()","fe93a1de":"# define numerical features\nfeatures_num = ['year', 'odometer', 'price']","f4f66c1c":"# plot mileage\ndf.odometer.plot(kind='hist', bins=50)\nplt.title('Mileage')\nplt.grid()\nplt.show()","957a3465":"# same in log scale\nnp.log10(1+df.odometer).plot(kind='hist', bins=50)\nplt.title('Log10(1+Mileage)')\nplt.grid()\nplt.show()","4fba272f":"print('Number of cars with mileage 0:', df[df.odometer==0].shape[0])","c1ca7d98":"# Price\ndf.price.plot(kind='hist', bins=50)\nplt.title('Price')\nplt.grid()\nplt.show()","38220d42":"# Price - log plot\nnp.log10(df.price).plot(kind='hist', bins=50)\nplt.title('Log10(Price)')\nplt.grid()\nplt.show()","cf563c7a":"# Year\nplt.figure(figsize=(8,4))\ndf.year.value_counts().sort_index().plot(kind='bar')\nplt.title('Year')\nplt.grid()\nplt.show()","681920e7":"# pairwise scatterplot of numerical features\nsns.pairplot(df[features_num])\nplt.show()","45cdeaa8":"# add transformed version of variables to data frame\ndf['odometer_trafo'] = np.log10(1+df.odometer)\ndf['log_price'] = np.log10(df.price)","43bf9f1f":"# pairwise scatterplot using transformed features\nsns.pairplot(df[['year','odometer_trafo','log_price']])\nplt.show()","7fd2b82a":"# evaluate rank correlation\ncorr_spearman = df[features_num].corr(method='spearman')\n\n# plot matrix\nsns.heatmap(corr_spearman, annot=True, cmap=\"RdYlGn\")\nplt.title('Spearman correlation')\nplt.show()","d9e048a1":"# define categorical features for the following\nfeatures_cat = ['location', 'isimported', \n                'engine', 'transmission',\n                'fuel', 'paint_reduced',\n                'manufacturer_reduced']","39a017bb":"# plot distribution of categorical features\nfor f in features_cat:\n    plt.figure(figsize=(16,4))\n    df[f].value_counts().plot(kind='bar')\n    plt.title(f)\n    plt.grid()\n    plt.show()","1b0aed7e":"# frequency plot for title\nplt.figure(figsize=(16,4))\ndf.title.value_counts()[0:25].plot(kind='bar')\nplt.title('Title (Top 25)')\nplt.grid()\nplt.show()","6dbbb3ba":"plt.scatter(df.year, df.log_price, alpha=0.25)\nplt.grid()\nplt.title('Log10(Price) vs Year')\nplt.show()","e73b7cf4":"plt.scatter(np.log10(1+df.odometer), df.log_price, alpha=0.25)\nplt.grid()\nplt.title('Log10(Price) vs Log10(1+Miles)')\nplt.show()","6bbb1b36":"# plot impact of categorical features on (log) price using violinplots\nfor f in features_cat:\n    plt.figure(figsize=(16,4))\n    sns.violinplot(x=f, y='log_price', data=df)\n    plt.title(f)\n    plt.grid()\n    plt.xticks(rotation=90)\n    plt.show()","77230d41":"# impact of title on (log) price\ntitle_top = df.title.value_counts()[0:25].index # select most frequent titles\ndf_temp = df[df.title.isin(title_top)] # temporary data frame reduced to top 25 titles\n\nplt.figure(figsize=(16,4))\nsns.violinplot(x='title', y='log_price', data=df_temp)\nplt.title('Title - Top 25')\nplt.grid()\nplt.xticks(rotation=90)\nplt.show()","c1949b55":"# cross table with absolute counts\nctab = pd.crosstab(df.manufacturer_reduced, df.paint_reduced)\nctab","e8596110":"# normalize table for each manufacturer\ncc = ctab.sum(axis=1).values\nctab_norm = (ctab.transpose() \/ cc).transpose()\nctab_norm","41395d82":"# visualize the matrix\nplt.rcParams['figure.figsize']=(11,7)\nsns.heatmap(ctab_norm, cmap=plt.cm.plasma, annot=True)\nplt.title('Paint by manufacturer')\nplt.show()","ac52c9d8":"# select predictors\npredictors = ['odometer', 'year'] + features_cat\nprint('Number of predictors: ', len(predictors))\nprint(predictors)\n\n# define target\ntarget='price'","2472b40a":"# start H2O\nh2o.init(max_mem_size='12G', nthreads=4)","1a236ae6":"# upload data frame in H2O environment\ndf_hex = h2o.H2OFrame(df)\n\n# train \/ test split (80\/20)\ntrain_hex, test_hex = df_hex.split_frame(ratios=[0.8], seed=999)","6777b119":"# define (distributed) random forest model\nfit_DRF = H2ORandomForestEstimator(ntrees=300,\n                                   max_depth=15,\n                                   min_rows=1,\n                                   nfolds=5,\n                                   seed=999)","02a47fa3":"# train model\nt1 = time.time()\nfit_DRF.train(x=predictors,\n              y=target,\n              training_frame=train_hex)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","a314e225":"# show training scoring history\nplt.rcParams['figure.figsize']=(7,4)\nfit_DRF.plot()","9d26c15a":"# variable importance\nfit_DRF.varimp_plot()","30600bc5":"# alternative: use (global) shap plot => see also direction and severity of feature impact\nfit_DRF.shap_summary_plot(train_hex);","a4d8f60c":"# show performance on training data\nperf_train = fit_DRF.model_performance(train=True)\nprint(perf_train)","2bcd02fb":"# show cross validation metrics\nfit_DRF.cross_validation_metrics_summary()","d5ba1d54":"# show scoring history - training vs cross validations\nfor i in range(5):\n    cv_model_temp = fit_DRF.cross_validation_models()[i]\n    df_cv_score_history = cv_model_temp.score_history()\n    my_title = 'CV ' + str(1+i) + ' - Scoring History [RMSE]'\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.training_rmse, \n                c='blue', label='training')\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.validation_rmse, \n                c='darkorange', label='cross val.')\n    plt.title(my_title)\n    plt.xlabel('Number of Trees')\n    plt.legend()\n    plt.grid()\n    plt.show()","8fd70614":"pred_train = fit_DRF.predict(train_hex)\ny_train_act = train_hex.as_data_frame().price.values # actual values\ny_train_pred = pred_train.as_data_frame().predict.values # predictions","4930bc98":"# plot predictions vs actuals\nplt.scatter(y_train_act, y_train_pred, alpha=0.25)\nplt.title('Prediction vs Actual - Training Data')\nplt.grid()\nplt.xlabel('Actual')\nplt.ylabel('Prediction')\nplt.show()","2dd9eb0c":"print('Correlations - Training Data')\nprint('Correlation Pearson:', stats.pearsonr(y_train_act, y_train_pred))\nprint('Correlation Spearman:', stats.spearmanr(y_train_act, y_train_pred))","dcf956b5":"# mean absolute error\nprint('MAE (train): ', np.round(mean_absolute_error(y_train_act, y_train_pred),2))","92baacd0":"pred_test = fit_DRF.predict(test_hex)\ny_test_act = test_hex.as_data_frame().price.values # actual values\ny_test_pred = pred_test.as_data_frame().predict.values # predictions","ec90df2f":"# plot predictions vs actuals\nplt.scatter(y_test_act, y_test_pred, alpha=0.25)\nplt.title('Prediction vs Actual - Test Data')\nplt.grid()\nplt.xlabel('Actual')\nplt.ylabel('Prediction')\nplt.show()","94866dda":"print('Correlations - Test Set')\nprint('Correlation Pearson:', stats.pearsonr(y_test_act, y_test_pred))\nprint('Correlation Spearman:', stats.spearmanr(y_test_act, y_test_pred))","1f982894":"# mean absolute error\nprint('MAE (test): ', np.round(mean_absolute_error(y_test_act, y_test_pred),2))","6cf56d9e":"# select individual row (from training data)\nmy_row = 8\ntrain_hex[my_row,:]","0813662a":"# and show corresponding prediction\nprint('Prediction:', y_train_pred[my_row])","f92b2613":"# now show detailed explanations for this individual prediction\nfit_DRF.explain_row(frame=train_hex, row_index=my_row);","30c1d0bc":"predictors_plus = predictors + ['title']\npredictors_plus","ad285eef":"# define (distributed) random forest model\nfit_DRF_plus = H2ORandomForestEstimator(ntrees=300,\n                                   max_depth=15,\n                                   min_rows=1,\n                                   nfolds=5,\n                                   seed=999)","0fdf0df7":"# train model\nt1 = time.time()\nfit_DRF_plus.train(x=predictors_plus,\n              y=target,\n              training_frame=train_hex)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","18ed2177":"# show training scoring history\nplt.rcParams['figure.figsize']=(7,4)\nfit_DRF_plus.plot()","95c070fc":"# variable importance\nfit_DRF_plus.varimp_plot()","7a3b2d8e":"# cross validation metrics\nfit_DRF_plus.cross_validation_metrics_summary()","5cf238b0":"# show scoring history - training vs cross validations\nfor i in range(5):\n    cv_model_temp = fit_DRF_plus.cross_validation_models()[i]\n    df_cv_score_history = cv_model_temp.score_history()\n    my_title = 'CV ' + str(1+i) + ' - Scoring History [RMSE]'\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.training_rmse,\n                c='blue', label='training')\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.validation_rmse,\n                c='darkorange', label='cross val.')\n    plt.title(my_title)\n    plt.xlabel('Number of Trees')\n    plt.legend()\n    plt.grid()\n    plt.show()","1ed25e6c":"pred_train_plus = fit_DRF_plus.predict(train_hex)\ny_train_pred_plus = pred_train_plus.as_data_frame().predict.values # predictions","93a1492e":"# plot predictions vs actuals\nplt.scatter(y_train_act, y_train_pred_plus, c='red', alpha=0.25)\nplt.title('Prediction vs Actual - Improved Model - Training Data')\nplt.grid()\nplt.xlabel('Actual')\nplt.ylabel('Prediction')\nplt.show()","1cf979ec":"# compare with 1st model\nplt.scatter(y_train_act, y_train_pred_plus, c='red', alpha=0.25)\nplt.scatter(y_train_act, y_train_pred, c='green', alpha=0.25)\nplt.title('Prediction vs Actual - Training Data')\nplt.grid()\nplt.xlabel('Actual')\nplt.ylabel('Prediction')\nplt.show()","8686a97d":"print('Correlations - Training Data (2nd model)')\nprint('Correlation Pearson:', stats.pearsonr(y_train_act, y_train_pred_plus))\nprint('Correlation Spearman:', stats.spearmanr(y_train_act, y_train_pred_plus))","e5bcbb8f":"# mean absolute error\nprint('1st model - MAE (train): ', np.round(mean_absolute_error(y_train_act, y_train_pred),2))\nprint('2nd model - MAE (train): ', np.round(mean_absolute_error(y_train_act, y_train_pred_plus),2))","e40bfc86":"pred_test_plus = fit_DRF_plus.predict(test_hex)\ny_test_pred_plus = pred_test_plus.as_data_frame().predict.values # predictions\n\n# plot predictions vs actuals\nplt.scatter(y_test_act, y_test_pred_plus, c='red', alpha=0.25)\nplt.title('Prediction vs Actual - Improved Model - Test Data')\nplt.grid()\nplt.xlabel('Actual')\nplt.ylabel('Prediction')\nplt.show()","2e550173":"# compare with 1st model\nplt.scatter(y_test_act, y_test_pred_plus, c='red', alpha=0.25)\nplt.scatter(y_test_act, y_test_pred, c='green', alpha=0.25)\nplt.title('Prediction vs Actual - Training Data')\nplt.grid()\nplt.xlabel('Actual')\nplt.ylabel('Prediction')\nplt.show()","8038a479":"print('Correlations - Test Set (2nd model)')\nprint('Correlation Pearson:', stats.pearsonr(y_test_act, y_test_pred_plus))\nprint('Correlation Spearman:', stats.spearmanr(y_test_act, y_test_pred_plus))","939ecef5":"# mean absolute error\nprint('1st model - MAE (test): ', np.round(mean_absolute_error(y_test_act, y_test_pred),2))\nprint('2nd model - MAE (test): ', np.round(mean_absolute_error(y_test_act, y_test_pred_plus),2))","596e4c6e":"#### Look at title separately once again - we use only the most frequent 25:","22c4ce05":"### Ok, we have clearly improved the model significantly by adding \"title\"...","9e420c11":"### Levels for paint are not clean:","09574706":"#### Price shows expected decreasing behavior with increasing number of miles driven.","89c10806":"<a id='2'><\/a>\n# Numerical features","28b7d9f4":"### Is there a dependency between manufacturer and paint?","54843355":"### H2O provides nice explanations by just using one line of code:","ef63f447":"<a id='6'><\/a>\n# Predictive Model for Price","fc3aa592":"#### Evaluate also \"title\". Here we have 240 different values therefore we just look at the 25 most frequent ones","d63f02df":"# Cleansing, EDA and Random Forest model including explanations for Nigerian used car prices\n\n**Table of Contents:**\n* [Data Cleansing](#1)\n\n* [Numerical Features](#2)\n\n* [Categorical Features](#3)\n\n* [Price vs Features](#4)\n\n* [Other Evaluations](#5)\n\n* [Predictive Model for Price](#6)\n\n* [Local Explanations for Predictions](#7)\n\n* [Can we do better?](#8)","28d8ca6d":"<a id='7'><\/a>\n# Local explanation for predictions","de6160a5":"### A few years are obiviously wrong:","7f5159d7":"### Extract manufacturer from \"title\":","2fed4538":"#### BMWs are mostly black (61.54%) whereas the majority of Volvos (45.45%) is white","228d12e9":"<a id='1'><\/a>\n# Data cleansing","36e4a263":"<a id='8'><\/a>\n# Can we do better?\nSpoiler: Yes, we can!","17ce6f1a":"#### Bar at 0 in the previous plot represents cars with 0 miles!","7e83095a":"### Predict on Test Set","3bfc6200":"### Numeric features","e2089d88":"### Categorical features","b3415f8c":"### Please note that we are only using the manufacturer but not the specific model of the car for predicting. Therefore we cannot yet expect a very precise model!","9c8c062a":"<a id='4'><\/a>\n# Price vs features","170fa822":"<a id='3'><\/a>\n# Categorical features","00dafa3f":"### Let's interpret the SHAP explanation plot: The prediction of the price is driven upward due to a relatively low age of the car, the paint color black and the foreign use. On the other side we have a 4 cylinder I4 engine, relatively high mileage and the manufacturer Toyota which drive the prediction downward.","b8a0c826":"### Predict on Training Data","05e5cf0a":"### Predict on Training Data","195d17ea":"#### We see an increasing price trend over time starting around year 2000.","ce45bddb":"#### Let's simply try to add the \"title\" feature (even if it has 240 different values).","d0227098":"<a id='5'><\/a>\n# Other evaluations"}}