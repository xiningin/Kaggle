{"cell_type":{"93406fbe":"code","daf2435c":"code","9e30e746":"code","4a7158bd":"code","2e758745":"code","9820efdb":"code","9b2c76ff":"code","a78d46e7":"code","6a7435d4":"markdown","306c146d":"markdown","a92d98e2":"markdown","97010e3e":"markdown","1613f1ae":"markdown","abc0a213":"markdown","8091ffda":"markdown","2ef975bc":"markdown","06203e86":"markdown","e9075d05":"markdown","d24b5a1e":"markdown"},"source":{"93406fbe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","daf2435c":"# import libs\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nimport seaborn as sns\nimport sklearn\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn import svm\nimport warnings\nimport sys\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")","9e30e746":"# load data from csv\ndata = pd.read_csv(\"..\/input\/last-30-days-earthquake-usgs\/LAST_30_DAYS_EARTHQUAKES.csv\")\nprint(\"Number of rows:\", len(data))\ndata.head()","4a7158bd":"# printing the column types\ndata.info()","2e758745":"# removing the columns that will not help in classification or are too difficult to handle\n\ndel data['time']\ndel data['net']\ndel data['id']\ndel data['updated']\ndel data['place']\ndel data['status']\ndel data['locationSource']\ndel data['magSource']\ndel data['magType']\ndel data['nst']\ndel data['gap']\ndel data['rms']\ndel data['type']\ndel data['magError']\ndel data['magNst']","9820efdb":"# filling the NaN with 0, otherwise too much data would be lost.\ndata = data.fillna(0)\n\ndata.info()","9b2c76ff":"plt.figure(figsize=(10,6))\nsns.heatmap(data.corr(), annot=True)\nplt.show()","a78d46e7":"data = shuffle(data)\n\nX = data.drop('mag', axis=1)\ny = data['mag']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nRandForest = RandomForestRegressor(n_estimators=25, random_state=42, n_jobs=-1)\nNeigh = KNeighborsRegressor(n_neighbors=5, n_jobs=-1)\ntree = DecisionTreeRegressor()\nlinear = LinearRegression(n_jobs=-1)\nsvm = svm.SVR()\n\n\nRandForest.fit(X_train, y_train)\nNeigh.fit(X_train, y_train)\ntree.fit(X_train, y_train)\nlinear.fit(X_train, y_train)\nsvm.fit(X_train, y_train)\n\n\npredictionRandForest = RandForest.score(X_test, y_test)\nprint('Random Forest Classifier ', round(predictionRandForest, 2))\n\npredictionNeigh = Neigh.score(X_test, y_test)\nprint('K-Neighbors Classifier ', round(predictionNeigh, 2))\n\npredictionTree = tree.score(X_test, y_test)\nprint('Tree Classifier ', round(predictionTree, 2))\n\npredictionLinear = linear.score(X_test, y_test)\nprint('Linear Classifier ', round(predictionLinear, 2))\n\npredictionSVM = svm.score(X_test, y_test)\nprint('SVM ', round(predictionSVM, 2))","6a7435d4":"# 1 - Imports, Data, First Look","306c146d":"# 2 - Data Cleaning","a92d98e2":"# 4 - Regression","97010e3e":"#### Check Column Types","1613f1ae":"# 3 - Correlation Matrix","abc0a213":"#### Removing unnecessary columns\n##### The goal is to predict the magnitude of the earthquake, so we only need data that is available at the time the earthquake happens\n##### Keeping the following columns:\n- latitude: location\n- longitude: location\n- depth: depth of the earthquake\n- dmin: Horizontal distance from the epicenter to the nearest station\n- horizontalError: Uncertainty of reported location of the event in kilometers\n- depthError: Uncertainty of reported depth of the event in kilometers\n- mag: Magnitude for classification","8091ffda":"# Earthquake USGS - Earthquake Magnitude Prediction\n#### In this notebook i will try to predict an earthquakes magnitude by using data like the location and depth.\n#### This will be done by using sklearn models","2ef975bc":"#### Loading Data","06203e86":"# 5 - Result\n#### We came away with a final acc. of ~85% on the Random Forrest.","e9075d05":"#### Import Libraries","d24b5a1e":"#### Taking care of null values "}}