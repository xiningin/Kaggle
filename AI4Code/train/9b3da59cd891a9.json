{"cell_type":{"f71cd034":"code","e3c71199":"code","6f19cff7":"code","437dfaae":"code","da33639c":"code","8888b7ed":"code","af9bc8aa":"code","8b73c2b2":"code","32419de7":"code","50a08ee7":"code","23ed5105":"code","9d78602f":"code","19c93390":"markdown","89882fd4":"markdown","da239bf8":"markdown","591c88e6":"markdown","d8b177c7":"markdown","0cf559c6":"markdown","1f380d02":"markdown","588be54e":"markdown","28e2f222":"markdown","c74ec490":"markdown","108d7e3a":"markdown","db9c4adf":"markdown","4d700f45":"markdown"},"source":{"f71cd034":"import os\nimport tensorflow as tf\nfrom tensorflow import keras \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2 as cv\nimport seaborn as sns\nfrom random import choices\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom keras.applications.vgg16 import VGG16\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense,Conv2D,MaxPooling2D,BatchNormalization,Flatten,Dropout","e3c71199":"input_path='..\/input\/brain-mri-images-for-brain-tumor-detection\/brain_tumor_dataset'\nfor file in os.listdir(input_path):\n    print(file)","6f19cff7":"type1=len(os.listdir(input_path+'\/no'))\ntype2=len(os.listdir(input_path+'\/yes'))\n\ncount=[type1,type2]\nlabel=['Tumor','Normal']\n\nsns.barplot(label,count)","437dfaae":"def show_image(folder):\n    path=os.path.join(input_path,folder)\n    \n    images=choices(os.listdir(path),k=4)\n    images=[os.path.join(path,file) for file in images]\n    \n    return images","da33639c":"img1=show_image('no')\nimg2=show_image('yes')\nlabel1=['no']*4\nlabel2=['yes']*4\n\nimages=img1+img2\nlabels=label1+label2\n\nplt.figure(figsize=(16,15))\n\nfor i,path_name in enumerate(images):\n    plt.subplot(4,2,i+1)\n    image=cv.imread(path_name)\n    plt.imshow(image)\n    plt.title(\"Tumor Present:\"+labels[i])\n    plt.axis('off')","8888b7ed":"datagen = ImageDataGenerator(rescale=1\/255,\n                             rotation_range=20,\n                             horizontal_flip=True,\n                             height_shift_range=0.1,\n                             width_shift_range=0.1,\n                             shear_range=0.1,\n                             brightness_range=[0.3, 1.5],\n                             validation_split=0.2\n                            )\n\ntrain_gen= datagen.flow_from_directory(input_path,\n                                       target_size=(224,224),\n                                       class_mode='binary',\n                                       subset='training'\n                                      )\nval_gen = datagen.flow_from_directory( input_path,\n                                       target_size=(224,224),\n                                       class_mode='binary',\n                                       subset='validation'\n                                      )","af9bc8aa":"vgg_model=VGG16(weights='imagenet',input_shape=(224,224,3),include_top=False)\nmodel=keras.Sequential()\nfor layer in vgg_model.layers:\n    model.add(layer)\nfor layer in model.layers:\n    layer.trainable=False","8b73c2b2":"model.add(Flatten())\nmodel.add(Dropout(0.4))\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.summary()","32419de7":"model.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy']\n             )","50a08ee7":"stop = EarlyStopping(\n    monitor='val_accuracy', \n    mode='max',\n    patience=6\n)\n\ncheckpoint= ModelCheckpoint(\n    filepath='.\/',\n    save_weights_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True)\n\nhistory=model.fit(train_gen,validation_data=val_gen,epochs=30,callbacks=[stop,checkpoint])","23ed5105":"plt.plot(history.history['loss'],label='train loss')\nplt.plot(history.history['val_loss'],label='validation loss')\nplt.legend()","9d78602f":"plt.plot(history.history['accuracy'],label='train accuracy')\nplt.plot(history.history['val_accuracy'],label='validation accuracy')\nplt.legend()","19c93390":"<h1 style='color:orange'>Data Wrangling<\/h1>","89882fd4":"**Let's see how the MRI scan of each type looks. We would be using open cv library to read and show the image.**","da239bf8":"**Let's visualize the total number of labels of each type in data**","591c88e6":"<h4 style='color:royalblue'><span style='color:red'>Task : <\/span>Identify tumors in the MRI images.<br>\n\n<span style='color:red'>Method : <\/span> We will use CNN architecture to solve the given task as well as Transfer Learning to increase the accuracy of our model<\/h4>\n","d8b177c7":"<h4><span style='color:red'>Note:<\/span> In this task a custom made model isn't able to get past over 78-80% accuracy also the loss and accuracy curves are not smooth so we will be using VGG16 model i.e Transfer Learning to increase our accuracy.<\/h4>","0cf559c6":"<h2>Image Augmentation <\/h2>\n\n**We will use Image Augmentation to train the model on different types of combination formed by rotation ,flipping of image so as to increase our model accuracy**","1f380d02":"<h1 style='color:orange'>Importing Libraries<\/h1>","588be54e":"<h4><span style='color:red'>Note : <\/span>The Dataset used in the task has only 253 images which is far from enough for the model to train and hence has less accuracy.Increasing the size of dataset can increase the model performance and thus solving the problem<\/h4>","28e2f222":"**We would use callbacks like Early Stopping and Model Check Point to save the model on the epoch having the best validation accuracy and to stop the model if the model isn't doing better on validation accuracy.**","c74ec490":"<h2 style='color:orange'>Model Performance<\/h2>","108d7e3a":"<h1 style='color:orange'> Model Building<\/h1>","db9c4adf":"**We will add dropout and other dense layers to avoid overfitting and make the model more robust.**","4d700f45":"<h1 style='color:blue'><center> Brain Tumor Detection<center><\/h1>"}}