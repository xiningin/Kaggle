{"cell_type":{"6b2725fb":"code","442d595b":"code","296ec53e":"code","d0d6d852":"code","fa17a3af":"code","af994352":"code","c628da1f":"code","1922388c":"code","a1d199b3":"code","f446b467":"code","215958d4":"code","a8c7f829":"code","bd9163bb":"code","f0ddb7f3":"code","35a8c276":"code","f0462c4e":"code","2f5b2324":"code","e109f728":"code","f1545854":"code","ad4cb85a":"code","857529d3":"code","e9bf1374":"code","2ba613e7":"code","d635ee24":"code","95337d75":"code","a3cf36a5":"code","f78d2471":"code","0fc1acf3":"code","add93d0b":"code","d72373d0":"code","69b4f837":"code","62d72e30":"code","da479205":"code","71fcf101":"code","94a33553":"code","c272951c":"code","9d437b1b":"code","159e9b2e":"code","64865051":"code","97ba91f1":"code","39e3e175":"code","c8310255":"code","14e9638d":"code","d06c34de":"code","244d2072":"code","4bc7b06b":"code","4c0a563e":"code","184ff3e2":"code","925ae016":"code","ea08069c":"code","817bb771":"code","7ada15fb":"code","34264b4c":"code","5d3023f6":"code","190e468b":"code","b4f9a9cf":"code","06f0f9a1":"code","db7ac170":"markdown","962e8cb4":"markdown","56356d5f":"markdown","86908f2f":"markdown","9a46a169":"markdown","75974973":"markdown","6c401af5":"markdown","2afc4493":"markdown","e00ecb0b":"markdown","9df7ed51":"markdown","ad55ef21":"markdown","e723d5be":"markdown","16a92eae":"markdown","f043f06a":"markdown","b5b2765f":"markdown","b79fba8b":"markdown","5a506a67":"markdown","8dc54a35":"markdown","4772fef3":"markdown"},"source":{"6b2725fb":"import pandas as pd\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)\n\ndata1 = pd.read_csv('..\/input\/credit-card-customers\/BankChurners.csv')","442d595b":"data1.drop(data1.columns[[21,22]], axis=1, inplace=True)","296ec53e":"data1.head()","d0d6d852":"data1.info()","fa17a3af":"data1.shape","af994352":"data1.describe()","c628da1f":"'''Nunique Columns'''\n\ndef nunique_counts(data):\n   for i in data.columns:\n       count = data[i].nunique()\n       print(i, \": \", count)\nnunique_counts(data1)","1922388c":"'''Unique Columns'''\n\ndef unique_counts(data):\n    features = data1.dtypes[data1.dtypes == \"object\"].index.values.tolist()\n    for i in features:\n        count = data[i].unique()\n        print(i, \": \", count, len(count))\n        \nunique_counts(data1)","a1d199b3":"'''Label Encoding With Label'''\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nle.fit(data1['CLIENTNUM'])\n\nl = [i for i in range(10127)]\ndict(zip(list(le.classes_), l))\n\ndata1['CLIENTNUM'] = le.transform(data1['CLIENTNUM'])","f446b467":"data1['CLIENTNUM'].unique()","215958d4":"'''Checking Duplicate'''\n\nprint('Dupplicate entries: {}'.format(data1.duplicated().sum()))\n# data1.drop_duplicates(inplace = True)","a8c7f829":"'''Missing Value Chart'''\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8, 5))\ndata1.isnull().mean(axis=0).plot.barh()\nplt.title(\"Ratio of missing values per columns\")\nprint(data1.isnull().values.sum()) #total missing values","bd9163bb":"import plotly.offline as py \npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go \nimport plotly.tools as tools\nimport warnings\nfrom collections import Counter \nfrom plotly.subplots import make_subplots\n\nfig = make_subplots(rows=1, \n                    cols=2, \n                    specs=[[{'type':'domain'}, {'type':'domain'}]],\n                    subplot_titles=('Atrition Flag','Gender'))\n\n# Based on Attrition_Flag\n\ncustom_aggregation = {}\ncustom_aggregation[\"CLIENTNUM\"] = \"count\"\ndata2 = data1.groupby(\"Attrition_Flag\").agg(custom_aggregation)\ndata2.columns = [\"Number of Client\"]\ndata2['Client Type'] = data2.index\n\nlabels = data2['Client Type'].tolist()\nvalues = data2['Number of Client'].tolist()\n\nfig.add_trace(go.Pie(\n                    labels=labels, \n                    values=values, \n                    name=\"Client Type\"),\n                    1, 1)\n\n\n# Based on Attrition_Flag\n\ncustom_aggregation = {}\ncustom_aggregation[\"CLIENTNUM\"] = \"count\"\ndata2 = data1.groupby(\"Gender\").agg(custom_aggregation)\ndata2.columns = [\"Number of Client\"]\ndata2['Gender'] = data2.index\n\nlabels = data2['Gender'].tolist()\nvalues = data2['Number of Client'].tolist()\n\nfig.add_trace(go.Pie(\n                    labels=labels, \n                    values=values, \n                    name=\"Gender\"),\n                    1, 2)\n\nfig.update_traces(textposition='inside')\nfig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\n\nfig['layout'].update(height=500, width=900, title='Number of Client based on:')\nfig.show()","f0ddb7f3":"fig = make_subplots(rows=1, \n                    cols=2, \n                    specs=[[{'type':'domain'}, {'type':'domain'}]],\n                    subplot_titles=('Educational Level','Marital Status'))\n\n# Based on Education_Level\n\ncustom_aggregation = {}\ncustom_aggregation[\"CLIENTNUM\"] = \"count\"\ndata2 = data1.groupby(\"Education_Level\").agg(custom_aggregation)\ndata2.columns = [\"Number of Client\"]\ndata2['Education Level'] = data2.index\n\nlabels = data2['Education Level'].tolist()\nvalues = data2['Number of Client'].tolist()\n\nfig.add_trace(go.Pie(\n                    labels=labels, \n                    values=values, \n                    name=\"Education Level\"),\n                    1, 1)\n\n\n# Based on Marital_Status\n\ncustom_aggregation = {}\ncustom_aggregation[\"CLIENTNUM\"] = \"count\"\ndata2 = data1.groupby(\"Marital_Status\").agg(custom_aggregation)\ndata2.columns = [\"Number of Client\"]\ndata2['Marital Status'] = data2.index\n\nlabels = data2['Marital Status'].tolist()\nvalues = data2['Number of Client'].tolist()\n\nfig.add_trace(go.Pie(\n                    labels=labels, \n                    values=values, \n                    name=\"Marital Status\"),\n                    1, 2)\n\nfig.update_traces(textposition='inside')\nfig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\n\nfig['layout'].update(height=500, width=900, title='Number of Client based on:')\nfig.show()","35a8c276":"fig = make_subplots(rows=1, \n                    cols=2, \n                    specs=[[{'type':'domain'}, {'type':'domain'}]],\n                    subplot_titles=('Income Category','Card Category'))\n\n# Based on Income_Category\n\ncustom_aggregation = {}\ncustom_aggregation[\"CLIENTNUM\"] = \"count\"\ndata2 = data1.groupby(\"Income_Category\").agg(custom_aggregation)\ndata2.columns = [\"Number of Client\"]\ndata2['Income Category'] = data2.index\n\nlabels = data2['Income Category'].tolist()\nvalues = data2['Number of Client'].tolist()\n\nfig.add_trace(go.Pie(\n                    labels=labels, \n                    values=values, \n                    name=\"Income Category\"),\n                    1, 1)\n\n\n# Based on Card_Category\n\ncustom_aggregation = {}\ncustom_aggregation[\"CLIENTNUM\"] = \"count\"\ndata2 = data1.groupby(\"Card_Category\").agg(custom_aggregation)\ndata2.columns = [\"Number of Client\"]\ndata2['Card Category'] = data2.index\n\nlabels = data2['Card Category'].tolist()\nvalues = data2['Number of Client'].tolist()\n\nfig.add_trace(go.Pie(\n                    labels=labels, \n                    values=values, \n                    name=\"Card Category\"),\n                    1, 2)\n\nfig.update_traces(textposition='inside')\nfig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\n\nfig['layout'].update(height=500, width=900, title='Number of Client based on:')\nfig.show()","f0462c4e":"import plotly.express as px\n\nfig = px.box(data1, x=\"Attrition_Flag\", y=\"Customer_Age\", color=\"Attrition_Flag\", boxmode=\"overlay\")\n\nfig['layout'].update(height=500, width=750, title='Customer Age Based on Attrition Flag')\nfig.update_traces(quartilemethod=\"inclusive\")\nfig.show()","2f5b2324":"fig = px.box(data1, x=\"Attrition_Flag\", y=\"Dependent_count\", color=\"Attrition_Flag\", boxmode=\"overlay\")\n\nfig['layout'].update(height=500, width=750, title='Dependent Count Based on Attrition Flag')\nfig.update_traces(quartilemethod=\"inclusive\")\nfig.show()","e109f728":"fig = make_subplots(rows=1, \n                    cols=1)\n\nx = data1['Total_Ct_Chng_Q4_Q1'].tolist()\n\ndata_ex = data1.loc[data1['Attrition_Flag'] == 'Existing Customer']\ndata_at = data1.loc[data1['Attrition_Flag'] == 'Attrited Customer']\n\n\ny1 = data_ex['Total_Amt_Chng_Q4_Q1'].tolist()\ny2 = data_at['Total_Amt_Chng_Q4_Q1'].tolist()\n\nfig.add_trace(go.Scatter(x=x, y=y1,name='Existing Customer',line=dict(color='darkgreen', width=2), mode=\"markers\"), 1, 1)\nfig.add_trace(go.Scatter(x=x, y=y2,name='Attrited Customer',line=dict(color='pink', width=2), mode=\"markers\"), 1, 1)\n\nfig['layout'].update(height=500, \n                     width=900, \n                     title='Scatter Plot Count Change x Total Amount Change',\n                     xaxis_title=\"Count Change\",\n                     yaxis_title=\"Amount Change\")\nfig.show()","f1545854":"fig = make_subplots(rows=1, \n                    cols=1)\n\nx = data1['Total_Amt_Chng_Q4_Q1'].tolist()\n\ndata_ex = data1.loc[data1['Attrition_Flag'] == 'Existing Customer']\ndata_at = data1.loc[data1['Attrition_Flag'] == 'Attrited Customer']\n\n\ny1 = data_ex['Total_Trans_Amt'].tolist()\ny2 = data_at['Total_Trans_Amt'].tolist()\n\nfig.add_trace(go.Scatter(x=x, y=y1,name='Existing Customer',line=dict(color='darkgreen', width=2), mode=\"markers\"), 1, 1)\nfig.add_trace(go.Scatter(x=x, y=y2,name='Attrited Customer',line=dict(color='pink', width=2), mode=\"markers\"), 1, 1)\n\nfig['layout'].update(height=500, \n                     width=900, \n                     title='Scatter Plot Amount Change x Total Transaction',\n                     xaxis_title=\"Amount Change\",\n                     yaxis_title=\"Total Transaction\")\nfig.show()","ad4cb85a":"fig = make_subplots(rows=1, \n                    cols=1)\n\nx = data1['Total_Trans_Amt'].tolist()\n\ndata_ex = data1.loc[data1['Attrition_Flag'] == 'Existing Customer']\ndata_at = data1.loc[data1['Attrition_Flag'] == 'Attrited Customer']\n\ny1 = data_ex['Avg_Open_To_Buy'].tolist()\ny2 = data_at['Avg_Open_To_Buy'].tolist()\n\nfig.add_trace(go.Scatter(x=x, y=y1,name='Existing Customer',line=dict(color='darkgreen', width=2), mode=\"markers\"), 1, 1)\nfig.add_trace(go.Scatter(x=x, y=y2,name='Attrited Customer',line=dict(color='pink', width=2), mode=\"markers\"), 1, 1)\n\nfig['layout'].update(height=500, \n                     width=900, \n                     title='Scatter Plot Total Transaction x Avg. Open to Buy',\n                     xaxis_title=\"Total Transaction\",\n                     yaxis_title=\"Avg. Open to Buy\")\nfig.show()","857529d3":"fig = make_subplots(rows=1, \n                    cols=1)\n\nx = data1['Total_Trans_Amt'].tolist()\n\ndata_ex = data1.loc[data1['Attrition_Flag'] == 'Existing Customer']\ndata_at = data1.loc[data1['Attrition_Flag'] == 'Attrited Customer']\n\ny1 = data_ex['Total_Revolving_Bal'].tolist()\ny2 = data_at['Total_Revolving_Bal'].tolist()\n\nfig.add_trace(go.Scatter(x=x, y=y1,name='Existing Customer',line=dict(color='darkgreen', width=2), mode=\"markers\"), 1, 1)\nfig.add_trace(go.Scatter(x=x, y=y2,name='Attrited Customer',line=dict(color='pink', width=2), mode=\"markers\"), 1, 1)\n\nfig['layout'].update(height=500, \n                     width=900, \n                     title='Scatter Plot Total Transaction x Revolving Balance',\n                     xaxis_title=\"Total Transaction\",\n                     yaxis_title=\"Revolving Balance\")\nfig.show()","e9bf1374":"custom_aggregation = {}\ncustom_aggregation[\"Months_on_book\"] = \"mean\"\ncustom_aggregation[\"Total_Relationship_Count\"] = \"mean\"\ncustom_aggregation[\"Months_Inactive_12_mon\"] = \"mean\"\ncustom_aggregation[\"Contacts_Count_12_mon\"] = \"mean\"\ncustom_aggregation[\"Credit_Limit\"] = \"mean\"\ncustom_aggregation[\"Total_Revolving_Bal\"] = \"mean\"\n\ndata2 = data1.groupby(\"Attrition_Flag\").agg(custom_aggregation)\ndata2['Customer'] = data2.index\n\nd1 = go.Bar(\n    x = data2.Customer.value_counts().index.sort_values(),\n    y = data2[\"Months_on_book\"],\n    name='Months on Book')\n\nd2 = go.Bar(\n    x = data2.Customer.value_counts().index.sort_values(),\n    y = data2[\"Total_Relationship_Count\"],\n    name='Total Relationship')\n\nd3 = go.Bar(\n    x = data2.Customer.value_counts().index.sort_values(),\n    y = data2[\"Months_Inactive_12_mon\"],\n    name='Months Inactive')\n\nd4 = go.Bar(\n    x = data2.Customer.value_counts().index.sort_values(),\n    y = data2[\"Contacts_Count_12_mon\"],\n    name='Contact Count')\n\nd5 = go.Bar(\n    x = data2.Customer.value_counts().index.sort_values(),\n    y = data2[\"Credit_Limit\"],\n    name='Credit Limit')\n\nd6 = go.Bar(\n    x = data2.Customer.value_counts().index.sort_values(),\n    y = data2[\"Total_Revolving_Bal\"],\n    name='Revolving Balance')\n\n\n\ndata = [d1,d2,d3,d4,d5,d6]\n\nfig = tools.make_subplots(rows=3, \n                          cols=2, \n                          #specs=[[{}, {}], [{'colspan': 1}, None]],\n                          subplot_titles=('Months on Book',\n                                         'Total Relationship',\n                                         'Months Inactive',\n                                         'Contact Count',\n                                         'Credit Limit',\n                                         'Revolving Balance'))\n\nfig.append_trace(d1, 1, 1)\nfig.append_trace(d2, 1, 2)\nfig.append_trace(d3, 2, 1)\nfig.append_trace(d4, 2, 2)\nfig.append_trace(d5, 3, 1)\nfig.append_trace(d6, 3, 2)\n\nfig['layout'].update(height=1000, width=900, title='Attrited vs Existing Customer', boxmode='group')\npy.iplot(fig, filename='combined-savings')","2ba613e7":"custom_aggregation = {}\ncustom_aggregation[\"Avg_Open_To_Buy\"] = \"mean\"\ncustom_aggregation[\"Total_Amt_Chng_Q4_Q1\"] = \"mean\"\ncustom_aggregation[\"Total_Trans_Amt\"] = \"mean\"\ncustom_aggregation[\"Total_Trans_Ct\"] = \"mean\"\ncustom_aggregation[\"Total_Ct_Chng_Q4_Q1\"] = \"mean\"\ncustom_aggregation[\"Avg_Utilization_Ratio\"] = \"mean\"\n\ndata2 = data1.groupby(\"Attrition_Flag\").agg(custom_aggregation)\ndata2['Customer'] = data2.index\n\nd1 = go.Bar(\n    x = data2.Customer.value_counts().index.sort_values(),\n    y = data2[\"Avg_Open_To_Buy\"],\n    name='Avg. Open to Buy')\n\nd2 = go.Bar(\n    x = data2.Customer.value_counts().index.sort_values(),\n    y = data2[\"Total_Amt_Chng_Q4_Q1\"],\n    name='Amount Change')\n\nd3 = go.Bar(\n    x = data2.Customer.value_counts().index.sort_values(),\n    y = data2[\"Total_Trans_Amt\"],\n    name='Transaction Amount')\n\nd4 = go.Bar(\n    x = data2.Customer.value_counts().index.sort_values(),\n    y = data2[\"Total_Trans_Ct\"],\n    name='Transaction Count')\n\nd5 = go.Bar(\n    x = data2.Customer.value_counts().index.sort_values(),\n    y = data2[\"Total_Ct_Chng_Q4_Q1\"],\n    name='Count Change')\n\nd6 = go.Bar(\n    x = data2.Customer.value_counts().index.sort_values(),\n    y = data2[\"Avg_Utilization_Ratio\"],\n    name='Avg. Utilization Ratio')\n\n\ndata = [d1,d2,d3,d4,d5,d6]\n\nfig = tools.make_subplots(rows=3, \n                          cols=2, \n                          #specs=[[{}, {}], [{'colspan': 1}, None]],\n                          subplot_titles=('Avg. Open to Buy',\n                                         'Amount Change',\n                                         'Transaction Amount',\n                                         'Transaction Count',\n                                         'Count Change',\n                                         'Avg. Utilization Ratio'))\n\nfig.append_trace(d1, 1, 1)\nfig.append_trace(d2, 1, 2)\nfig.append_trace(d3, 2, 1)\nfig.append_trace(d4, 2, 2)\nfig.append_trace(d5, 3, 1)\nfig.append_trace(d6, 3, 2)\n\nfig['layout'].update(height=1000, width=900, title='Attrited vs Existing Customer', boxmode='group')\npy.iplot(fig, filename='combined-savings')","d635ee24":"data1['Attrition_Flag'].unique()","95337d75":"data1['Attrition_Flag'][data1['Attrition_Flag'] == 'Existing Customer'] = 0\ndata1['Attrition_Flag'][data1['Attrition_Flag'] == 'Attrited Customer'] = 1","a3cf36a5":"from sklearn.preprocessing import LabelEncoder\n\nle.fit(data1['Gender'])\n\ndata1['Gender'] = le.transform(data1['Gender'])\n\nl = [i for i in range(2)]\ndict(zip(list(le.classes_), l))","f78d2471":"le.fit(data1['Education_Level'])\n\ndata1['Education_Level'] = le.transform(data1['Education_Level'])\n\nl = [i for i in range(7)]\ndict(zip(list(le.classes_), l))","0fc1acf3":"le.fit(data1['Marital_Status'])\n\ndata1['Marital_Status'] = le.transform(data1['Marital_Status'])\n\nl = [i for i in range(4)]\ndict(zip(list(le.classes_), l))","add93d0b":"le.fit(data1['Income_Category'])\n\ndata1['Income_Category'] = le.transform(data1['Income_Category'])\n\nl = [i for i in range(6)]\ndict(zip(list(le.classes_), l))","d72373d0":"le.fit(data1['Card_Category'])\n\ndata1['Card_Category'] = le.transform(data1['Card_Category'])\n\nl = [i for i in range(4)]\ndict(zip(list(le.classes_), l))","69b4f837":"le.fit(data1['Attrition_Flag'])\n\ndata1['Attrition_Flag'] = le.transform(data1['Attrition_Flag'])\n\nl = [i for i in range(2)]\ndict(zip(list(le.classes_), l))","62d72e30":"data1.groupby('Attrition_Flag').size()","da479205":"data1 = data1.sample(frac=1)\n\nexis = data1.loc[data1['Attrition_Flag'] == 1]\nattr = data1.loc[data1['Attrition_Flag'] == 0][:1627]\n\n\nnormal_distributed_df = pd.concat([exis, attr])\n\n# Shuffle dataframe rows\ndata2 = normal_distributed_df.sample(frac=1, random_state=42)\n\ndata2.head()","71fcf101":"data2.groupby('Attrition_Flag').size()","94a33553":"data2.info()","c272951c":"fig = make_subplots(rows=1, \n                    cols=1)\ncor = data2.corr()\ncor_ = cor.index\ncor__ = cor.values\n\nfig.add_trace(go.Heatmap(\n                    x=cor_,\n                    y=cor_,\n                    z=cor__,\n                    name='Correlation',\n                    showscale=False,\n                    xgap=0.7,\n                    ygap=0.7), 1, 1)\n\n\nfig['layout'].update(height=600, \n                     width=600, \n                     title='Heat Map',\n                     xaxis_title=\" \",\n                     yaxis_title=\" \")\nfig.show()","9d437b1b":"data2.corr()['Attrition_Flag'].sort_values(ascending=False)","159e9b2e":"data2.corr()['Attrition_Flag'].drop('Attrition_Flag').sort_values(ascending=False)[:9].index.tolist()","64865051":"from sklearn.model_selection import train_test_split\n\ntrain_data,test_data = train_test_split(data2,train_size = 0.7,random_state=3)","97ba91f1":"train_data.shape, test_data.shape","39e3e175":"'''Pre Model Selection'''\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import KFold\n\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('RF', RandomForestClassifier()))\nmodels.append(('XGB', XGBClassifier(use_label_encoder=False)))\n\nresults = []\nnames = []\nscoring = 'precision'\n\nfeatures = data2.drop('Attrition_Flag', axis=1).columns.values.tolist()\n\nfor name, model in models:\n        kfold = KFold(n_splits=10, random_state=None)\n        cv_results = cross_val_score(model, train_data[features], train_data['Attrition_Flag'], cv=kfold, scoring=scoring)\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)\n        \nfig = plt.figure(figsize=(11,6))\nfig.suptitle('Algorithm Comparison by Precision')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","c8310255":"results = []\nnames = []\nscoring = 'recall'\n\nfor name, model in models:\n        kfold = KFold(n_splits=10, random_state=None)\n        cv_results = cross_val_score(model, train_data[features], train_data['Attrition_Flag'], cv=kfold, scoring=scoring)\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)\n        \nfig = plt.figure(figsize=(11,6))\nfig.suptitle('Algorithm Comparison by Recall')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","14e9638d":"evaluation = pd.DataFrame({'Model': [],\n                           'Details':[],\n                           'Accuracy':[],\n                          'CVS':[],\n                          'Recall':[],\n                          'Precision':[],\n                          'F1':[]})","d06c34de":"'''RANDOM FOREST CLASSIFIER'''\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score\n\nrfc = RandomForestClassifier(min_samples_leaf = 3, \n                               min_samples_split=7, \n                               n_estimators = 75,\n                               max_samples=0.5)\n\nestimator = rfc.fit(train_data[features], train_data['Attrition_Flag'])\npredict = rfc.predict(data1[features])                                                                                \nacc = (accuracy_score(data1['Attrition_Flag'], predict)*100)\ncvs = (cross_val_score(rfc, train_data[features], train_data['Attrition_Flag'], cv=5).mean())*100\ncvp = cross_val_predict(rfc, train_data[features], train_data['Attrition_Flag'], cv=5)\nrecall = recall_score(data1['Attrition_Flag'], predict)*100\nprecision = precision_score(data1['Attrition_Flag'], predict)*100\nf1 = f1_score(data1['Attrition_Flag'], predict)*100     \n                                                                                                                                                                                                                                             \nr = evaluation.shape[0]\nevaluation.loc[r] = ['Random Forest Classifier','Select Feature',acc, cvs,recall, precision, f1]\nevaluation.sort_values(by = 'Accuracy', ascending=False)\nevaluation","244d2072":"'''DECISION TREE CLASSIFIER'''\n\ndtc = DecisionTreeClassifier()\n\nestimator = dtc.fit(train_data[features], train_data['Attrition_Flag'])\npredict = dtc.predict(data1[features])                                                                                \nacc = (accuracy_score(data1['Attrition_Flag'], predict)*100)\ncvs = (cross_val_score(dtc, train_data[features], train_data['Attrition_Flag'], cv=5).mean())*100\ncvp = cross_val_predict(dtc, train_data[features], train_data['Attrition_Flag'], cv=5)\nrecall = recall_score(data1['Attrition_Flag'], predict)*100\nprecision = precision_score(data1['Attrition_Flag'], predict)*100\nf1 = f1_score(data1['Attrition_Flag'], predict)*100     \n                                                                                                                                                                                                                                             \nr = evaluation.shape[0]\nevaluation.loc[r] = ['Decision Tree Classifier','Select Feature',acc, cvs,recall, precision, f1]\nevaluation.sort_values(by = 'Accuracy', ascending=False)\nevaluation","4bc7b06b":"'''XGB CLASSIFIER'''\n\nxgb = XGBClassifier(use_label_encoder=False,\n                   max_depth = 25)\n\nestimator = xgb.fit(train_data[features], train_data['Attrition_Flag'])\npredict = xgb.predict(data1[features])                                                                                \nacc = (accuracy_score(data1['Attrition_Flag'], predict)*100)\ncvs = (cross_val_score(xgb, train_data[features], train_data['Attrition_Flag'], cv=5).mean())*100\ncvp = cross_val_predict(xgb, train_data[features], train_data['Attrition_Flag'], cv=5)\nrecall = recall_score(data1['Attrition_Flag'], predict)*100\nprecision = precision_score(data1['Attrition_Flag'], predict)*100\nf1 = f1_score(data1['Attrition_Flag'], predict)*100     \n                                                                                                                                                                                                                                             \nr = evaluation.shape[0]\nevaluation.loc[r] = ['XGB Classifier','Select Feature',acc, cvs,recall, precision, f1]\nevaluation.sort_values(by = 'Accuracy', ascending=False)\nevaluation","4c0a563e":"import numpy as np\nimport seaborn as sns\n\ndef plot_feature_importance(importance,names,model_type):\n    feature_importance = np.array(importance)\n    feature_names = np.array(names)\n\n    data={'feature_names':feature_names,'feature_importance':feature_importance}\n    fi_df = pd.DataFrame(data)\n\n    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n\n    plt.figure(figsize=(10,8))\n\n    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n\n    plt.title(model_type + 'FEATURE IMPORTANCE')\n    plt.xlabel('FEATURE IMPORTANCE')\n    plt.ylabel('FEATURE NAMES')","184ff3e2":"plot_feature_importance(rfc.feature_importances_,features,'RANDOM FOREST CLASSIFIER ')","925ae016":"plot_feature_importance(xgb.feature_importances_,features,'XGB CLASSIFIER ')","ea08069c":"plot_feature_importance(dtc.feature_importances_,features,'DTC CLASSIFIER ')","817bb771":"'''ROC Curve'''\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import roc_curve\n\nmodel_pred = cross_val_predict(xgb, train_data[features], train_data['Attrition_Flag'], cv=5)\n\nmodel_fpr, model_tpr, model_thresold = roc_curve(train_data['Attrition_Flag'], model_pred)\n\ndef graph_roc_curve(model_fpr, log_tpr):\n    plt.figure(figsize=(10,6))\n    plt.title('ROC Curve', fontsize=16)\n    plt.plot(model_fpr, model_tpr, 'b-', linewidth=2, label='Model Score: {:.4f}'.format(roc_auc_score(train_data['Attrition_Flag'], model_pred)))\n    plt.plot([0, 1], [0, 1], 'r--')\n    plt.xlabel('False Positive Rate', fontsize=16)\n    plt.ylabel('True Positive Rate', fontsize=16)\n    plt.axis([-0.01,1,0,1])\n#     plt.legends()\n    \ngraph_roc_curve(model_fpr, model_tpr)\nplt.show()","7ada15fb":"'''Learning Curve'''\nfrom sklearn.model_selection import learning_curve\n\ndef plot_learning_curve(estimator, X, y, \n                        ylim=None, \n                        cv=None, \n                        n_jobs=1, \n                        train_sizes=np.linspace(.1, 1.0, 5)):\n    \n    plt.figure(figsize=(17,11))\n    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"#ff9124\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\", label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\", label=\"Cross-validation score\")\n    plt.title(\"Model Learning Curve\", fontsize=14)\n    plt.xlabel('Training size (m)')\n    plt.ylabel('Score')\n    plt.grid(True)\n    plt.legend(loc=\"best\")\n    \n    return plt","34264b4c":"from sklearn.model_selection import ShuffleSplit\n\ncv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n\nplot_learning_curve(rfc,\n                    train_data[features], \n                    train_data['Attrition_Flag'], \n                    (0.87, 1.01), cv=cv, n_jobs=4)","5d3023f6":"'''Confusion Matrix'''\nfrom sklearn.metrics import confusion_matrix\n\nRF_matrix = confusion_matrix(data1['Attrition_Flag'], predict)\n\nplt.figure(figsize=(15,8))\nsns.heatmap(RF_matrix,annot=True, fmt=\"d\", cbar=False, cmap=\"Pastel2\")\nplt.title(\"XGB Confusion Matrix\", weight='bold')\nplt.xlabel('Predicted Labels')\nplt.ylabel('Actual Labels')","190e468b":"'''MODEL SCORE'''\nfrom sklearn.metrics import classification_report\n\nprint(\"Random Forest Classifier\", classification_report(data1['Attrition_Flag'], predict))","b4f9a9cf":"data1['Predict'] = rfc.predict(data1[features])","06f0f9a1":"data1[['Attrition_Flag', 'Predict']].head(10)","db7ac170":"- For the age, there is no significant difference between Attrited and Existing customer\n- Attrited customer tend to have high depenedent count compare ti existing customer","962e8cb4":"# Data Exploration","56356d5f":"- We have 10127 rows, 21 features. Which i think is very small data to predict churn rate. But we will try our best!\n- I changing the item label on Clientum feature, to make it simple\n- We also dont have missing values here","86908f2f":"# Import Data","9a46a169":"- CLIENTNUM: Client number. Unique identifier for the customer holding the account\n- Attrition_Flag: Internal event (customer activity) variable - if the account is closed then 1 else 0\n- Customer_Age: Demographic variable - Customer's Age in Years\n- Gender: Demographic variable - M=Male, F=Female\n- Dependent_count: Demographic variable - Number of dependents\n- Education_Level: Demographic variable - Educational Qualification of the account holder (example: high school, college graduate, etc.)\n- Marital_Status: Demographic variable - Married, Single, Divorced, Unknown\n- Income_Category: Demographic variable - Annual Income Category of the account holder (< $40K, $40K - 60K, $60K - $80K, $80K-$120K, > $120K, Unknown)\n- Card_Category: Product Variable - Type of Card (Blue, Silver, Gold, Platinum)\n- Months_on_book: Period of relationship with bank\n- Total_Relationship_Count: Total no. of products held by the customer\n- Months_Inactive_12_mon: No. of months inactive in the last 12 months\n- Contacts_Count_12_mon: No. of Contacts in the last 12 months\n- Credit_Limit: Credit Limit on the Credit Card\n- Total_Revolving_Bal: Total Revolving Balance on the Credit Card\n- Avg_Open_To_Buy: Open to Buy Credit Line (Average of last 12 months)\n- Total_Amt_Chng_Q4_Q1: Change in Transaction Amount (Q4 over Q1)\n- Total_Trans_Amt: Total Transaction Amount (Last 12 months)\n- Total_Ct_Chng_Q4_Q1: Change in Transaction Count (Q4 over Q1)\n- Avg_Utilization_Ratio: Average Card Utilization Ratio","75974973":"- I try to make overall chart on each feature that distinguished attrited and existing customer\n- For the values, i using mean\n- We can see that feature which have significant difference are: Revolving Balanced, Transaction Amount, Transaction Count, Count Change and also Avg. Utilization Ratio\n- Further inspection is needed to get know on each feature which have significant difference, because i think in modeling later, these feature may have significant correlation with our target feature","6c401af5":"- I split train and test data for 70:30\n- After splitting we get the shape data both for out train and test are: (2277, 21), (977, 21)\n- For the feature, i only selected feature which have contribute positively with our target feater\n- Before modelly, i try to figure out which model to perform based on precision and recall\n- I decided to modelling using Random Forest Classifier, Decision Tree Classifier and XGBoost Classifer\n- And for the testing i decided to use all data, not data from splitting. It for widing out test size\n- After developting the model the higest recall score is XGB Model, which we select for predicting the churn customer\n- And then try to searching most importance feature in our model, which is:\n\n    1. Total Transaction Count\n    2. Total Revolving Balanced\n    3. Total Relationship Count\n    \n    \n- I try to plot ROC Curve and Learning Curve to evaluate our model\n- Both ROC and Learning Curve plot seem to showing good result to our model\n\nEvaluation: On connfusion matriks we see that our model predict,\n\n- 1610 item predicted as Churn which is correctly predicted (***True Positive***)\n- 17 item predicted as Not Churn which is uncorrectly predicted (***False Negative***)\n\n     ***Which lead us to get 98,95% Recall Score ( TP \/ ( TP + FN )***\n     \n    \n- 8053 item predicted as Not Churn which is correctly predicted (***True Negative***)    \n- 447 item predicted as Churn which is uncorrectly predicted (***False Positive***)\n\n     ***Which lead us to get 95,41% Accuracy Score ( ( TP + TN ) \/ ( TP + FN + TN + FP )***\n    \n    ","2afc4493":"- Count x Amount change: Attrited customer tend to have lower amount change distribution compared to existing customer\n- Amount Change x Total Transaction: Attrited customer tend to have lower total transaction distribution compared to existing customer","e00ecb0b":"# Modelling","9df7ed51":"# Feature Defenition","ad55ef21":"# Pre Processing","e723d5be":"Description:\n- A manager at the bank is disturbed with more and more customers leaving their credit card services. They would really appreciate if one could predict for them who is gonna get churned so they can proactively go to the customer to provide them better services and turn customers' decisions in the opposite direction\n\n- Now, this dataset consists of 10,000 customers mentioning their age, salary, marital_status, credit card limit, credit card category, etc. There are nearly 18 features. We have only 16.07% of customers who have churned. Thus, it's a bit difficult to train our model to predict churning customers.\n\nTask:\n1. We are expecting a notebook having in-depth Exploratory Data Analysis that can help us visualize where the difference lies between churning and non-churning customers.\n2. Improve Performance of predicting churned customers","16a92eae":"- I encoding all object feature to numerical using Label Encoder, but fro our target feature i changed it manuallis. For attrited labelled as 1 and existing labelled as 0\n- This because later when evaluate our model, the result won't make a bias\n- Need to know that our data consist very small information about churn customer which is about 1627 compared to existing customer which have 8500\n- In this case we are dealing with unbalanced dataset\n- On order to overcome this problem, we need to make resample\n- I using Random Over Sampling which will balanced our dataset so it will have same size\n- After resampling we can see that the size of our item in target feature is same","f043f06a":"# Result & Conclusion","b5b2765f":"- I'm trying to knowing the size of each item in feature\n- For the dataset given, majority of the custmer are:\n\n    1. Existing customer: 83,9%\n    2. Female: 52,9%\n    3. Graduate: 30,9%\n    4. Married: 46,3%\n    5. Income less than $40K: 35,2%\n    6. Blue card category: 93,2%","b79fba8b":"As ordered before, we will drop the 'not needed' features","5a506a67":"# Task & Description","8dc54a35":"Finish, don't forget to upvote. Thank You!:)","4772fef3":"Hello \ud83d\ude4c, welcome to my notebook. In this notebook we will try to exploring churn data and also develop and evaluate model to predict churn customer. Feel free if you have any question or suggestion! Thank you!"}}