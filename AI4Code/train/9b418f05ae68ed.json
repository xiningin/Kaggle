{"cell_type":{"4b068125":"code","0a8f4dc8":"code","d45f103d":"code","309dfac6":"code","4234175d":"code","6494be04":"code","73137f24":"code","0ea672b8":"code","3002b096":"code","e8b54db0":"code","f6a88a62":"code","755f4d4d":"code","5918a9c3":"code","f31a5e57":"code","d5faa153":"code","ea9e9f48":"code","2bd673ed":"code","7901f6f1":"code","86ed26c1":"code","e2ed0e25":"code","aeb36f54":"code","3360bfa1":"code","4d1be03a":"code","cdaffcf9":"code","7254041d":"code","e168fd25":"code","640c5cb7":"markdown","d78b71e1":"markdown","0a057957":"markdown","e6967347":"markdown","00fe346c":"markdown","59b235ee":"markdown","513e5135":"markdown","5c582155":"markdown","4c19e9c4":"markdown","2dac5711":"markdown","da83318d":"markdown"},"source":{"4b068125":"# Just checking if we have a GPU\n!nvidia-smi","0a8f4dc8":"# Cloning the monk repository as we are going to use the MonkAI Library\n!git clone https:\/\/github.com\/Tessellate-Imaging\/monk_v1.git","d45f103d":"# Installing the dependencies for Kaggle required by Monk\n!pip install -r monk_v1\/installation\/Misc\/requirements_kaggle.txt","309dfac6":"# Appending the Monk repo to our working directory\nimport sys\nsys.path.append(\"\/kaggle\/working\/monk_v1\/monk\/\")","4234175d":"# Using mxnet backend\nfrom gluon_prototype import prototype","6494be04":"# Defining path for training and validation dataset\ntrain_path = '..\/input\/kermany2018\/OCT2017 \/train'\nval_path = '..\/input\/kermany2018\/OCT2017 \/val' \ntest_path = '..\/input\/kermany2018\/OCT2017 \/test' ","73137f24":"# Initialize the protoype model and setup project directory\ngtf=prototype(verbose=1)\ngtf.Prototype(\"Retina-OCT\", \"Hyperparameter-Analyser\")","0ea672b8":"# Define the prototype with default parameters\ngtf.Default(dataset_path=train_path,\n           model_name=\"densenet121\",\n           freeze_base_network=False,\n           num_epochs=5)","3002b096":"# Analysis Project Name\nanalysis_name = \"analyse_hyperparameters\"","e8b54db0":"lrs = [0.1, 0.05, 0.01, 0.005, 0.0001] # learning rates\nbatch_sizes = [2, 4, 8, 12] # Batch sizes\nmodels = [[\"densenet121\", False, True], [\"densenet169\", False, True], [\"densenet201\", False, True]] # models\noptimizers = [\"sgd\", \"adam\", \"adagrad\"] # optimizers\nepochs=10 # number of epochs\npercent_data=5 # percent of data to use","f6a88a62":"# keep_none state to delete all sub-experiments created\n# Analysis of learning rates\nanalysis = gtf.Analyse_Learning_Rates(analysis_name, lrs, percent_data, \n                                      num_epochs=epochs, state=\"keep_none\");","755f4d4d":"# Update prototype with the best learning rate\ngtf.update_learning_rate(0.01)\n\n# Very important to reload post updates\ngtf.Reload()","5918a9c3":"# keep_none state to delete all sub-experiments created\n# Analysis of Batch Sizes\nanalysis = gtf.Analyse_Batch_Sizes(analysis_name, batch_sizes, percent_data, \n                                      num_epochs=epochs, state=\"keep_none\");","f31a5e57":"# Update prototype with optimum batch size\ngtf.update_batch_size(12)\n\ngtf.Reload()","d5faa153":"# keep_none state to delete all sub-experiments created\n# Analysis of Models\nanalysis = gtf.Analyse_Models(analysis_name, models, percent_data, \n                                      num_epochs=epochs, state=\"keep_none\");","ea9e9f48":"# Update prototype with best model\ngtf.update_model_name(\"densenet169\")\ngtf.update_freeze_base_network(False)\ngtf.update_use_pretrained(True)\n\ngtf.Reload()","2bd673ed":"# keep_none state to delete all sub-experiments created\n# Analysis of Optimizers\nanalysis = gtf.Analyse_Optimizers(analysis_name, optimizers, percent_data, \n                                      num_epochs=epochs, state=\"keep_none\");","7901f6f1":"#Update prototype with optimizer\ngtf.optimizer_sgd(0.01)\n\ngtf.Reload()","86ed26c1":"gtf.Train()","e2ed0e25":"# Set flag eval_infer as True\ngtf=prototype(verbose=1)\ngtf.Prototype(\"Retina-OCT\", \"Hyperparameter-Analyser\", eval_infer = True)","aeb36f54":"# Load the validation dataset\ngtf.Dataset_Params(dataset_path=val_path)\ngtf.Dataset()","3360bfa1":"# Run validation\naccuracy, class_based_accuracy = gtf.Evaluate()","4d1be03a":"# Set flag eval_infer as True\ngtf=prototype(verbose=1)\ngtf.Prototype(\"Retina-OCT\", \"Hyperparameter-Analyser\", eval_infer = True)","cdaffcf9":"# Running sample inference\nimg_name = test_path +\"\/DRUSEN\/DRUSEN-1786810-3.jpeg\"\npredictions = gtf.Infer(img_name=img_name)\n\n#Display \nfrom IPython.display import Image\nImage(filename=img_name) ","7254041d":"# Load the validation dataset\ngtf.Dataset_Params(dataset_path=test_path)\ngtf.Dataset()","e168fd25":"# Run inference on test data\naccuracy, class_based_accuracy = gtf.Evaluate()","640c5cb7":"## Model analysis\nSo here we can see that the best base model is ```densenet 169``` \n\n---\n\n","d78b71e1":"# Setup\n\n\nThis involves importing necessary libraries and data for us to run our model\n\n\n---\n","0a057957":"# Setting up the Model\n Here we will import the desired backend and base network on which we want our model to run the classification dataset\n \n\n---","e6967347":"# Introduction\n\n\nUsing Monk AI's inbuilt hyperparameter analyser to get the best results on our dataset, which is an image classification dataset of Retina OCTs\n\n---\n\n","00fe346c":"# Analysis\nNow we start with our analysis of the model using Monk's Hyperparameter Analyser\n\n\n---","59b235ee":"## Inference\nRunning inference on test dataset\n\n---","513e5135":"## Validation\nValidating the trained classifier\n\n---","5c582155":"## Optimizer analysis\nSo here we can see that the best optimizer is ```sgd``` \n\n---\n\n","4c19e9c4":"## Learning rate analysis\nSo here we can see that the best learning rate is ```0.01```\n\n\n---\n\n","2dac5711":"## Training\nNow we train the model with the hyperparameters we got from the analysis\n\n---","da83318d":"## Batch Size analysis\nSo here we can see that the best batch size is ```12```\n\n---\n\n"}}