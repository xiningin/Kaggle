{"cell_type":{"af05482c":"code","e7459f47":"code","736c4242":"code","9233626c":"code","4bbc6fce":"code","b3c274fa":"code","5965a01d":"code","d59fcb4b":"code","e3a348cd":"code","0f7b9920":"code","e2b8370e":"code","5b6bfa28":"code","1b3a55ea":"code","ec86eca0":"code","f29082e7":"code","b3f63209":"code","bec14b54":"code","c5506a79":"code","63610928":"markdown","33295435":"markdown","e394e0c0":"markdown","56881067":"markdown","4abbe96c":"markdown","b06b64b9":"markdown","6a08e5d7":"markdown","b415ba81":"markdown"},"source":{"af05482c":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","e7459f47":"from fastai import *\nfrom fastai.vision import *\nimport pandas as pd","736c4242":"print('Make sure cuda is installed:', torch.cuda.is_available())\nprint('Make sure cudnn is enabled:', torch.backends.cudnn.enabled)","9233626c":"path = Path('..\/input')","4bbc6fce":"# Load train dataframe\ntrain_df = pd.read_csv(path\/'train.csv')\ntrain_df = pd.concat([train_df['id'],train_df['category_id']],axis=1,keys=['id','category_id'])\ntrain_df.head()","b3c274fa":"# Load sample submission\ntest_df = pd.read_csv(path\/'test.csv')\ntest_df = pd.DataFrame(test_df['id'])\ntest_df['predicted'] = 0\ntest_df.head()","5965a01d":"train, test = [ImageList.from_df(df, path=path, cols='id', folder=folder, suffix='.jpg') \n               for df, folder in zip([train_df, test_df], ['train_images', 'test_images'])]\ndata = (train.split_by_rand_pct(0.2, seed=123)\n        .label_from_df(cols='category_id')\n        .add_test(test)\n        .transform(get_transforms(), size=32)\n        .databunch(path=Path('.'), bs=64).normalize())","d59fcb4b":"data.show_batch()","e3a348cd":"learn = cnn_learner(data, base_arch=models.densenet121, metrics=[FBeta(),accuracy], wd=1e-5).mixup()","0f7b9920":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","e2b8370e":"lr = 2e-2\nlearn.fit_one_cycle(2, slice(lr))","5b6bfa28":"learn.save('stage-1-sz32')","1b3a55ea":"learn.unfreeze()","ec86eca0":"learn.lr_find()\nlearn.recorder.plot()","f29082e7":"lr = 1e-3\nlearn.fit_one_cycle(4, slice(lr\/100, lr))","b3f63209":"learn.save('stage-2-sz32')","bec14b54":"test_preds = learn.TTA(ds_type = DatasetType.Test)\ntest_df['predicted'] = test_preds[0].argmax(dim=1)","c5506a79":"test_df.to_csv('submission.csv', index=False)","63610928":"# Fastai starter\n\nThis is some basic starter code for using [fastai](https:\/\/docs.fast.ai\/) for this dataset. The code\/model is based on [this kernel](https:\/\/www.kaggle.com\/xhlulu\/densenet-transfer-learning-iwildcam-2019) and uses a pretrained DenseNet121, along with [Mixup](https:\/\/arxiv.org\/abs\/1710.09412) as implemented by the fastai library.","33295435":"## Train model\n\nHere we will create a model using the [`cnn_learner`](https:\/\/docs.fast.ai\/vision.learner.html#cnn_learner) function, which will automatically download and load the pretrained weights. Mixup is easily added as a callback, which is done by the `mixup()` function. If you are interested in the mixup implementation in fastai, you can read more over [here](https:\/\/docs.fast.ai\/callbacks.mixup.html).\n\nWe will fine-tune the pretrained model, then unfreeze and train the whole model.","e394e0c0":"Here, we use discriminative learning rates, where lower learning rates are used for the earlier layers in the model.","56881067":"The fastai library provides an implementation of a learning rate finder as described by [this paper](https:\/\/arxiv.org\/abs\/1506.01186). This allows us to choose the optimal learning rate for efficient training.\n\nIn a nutshell, the learning rate is adjusted over a single epoch, and the loss is plotted against the learning rate. The optimal learning rate is when the loss decreases the fastest.","4abbe96c":"We now will unfreeze the model, to retrain the entire model. The optimal learning rate has to be determined again.","b06b64b9":"## Test predictions","6a08e5d7":"## Future work:\n\nSome more tricks include:\n- label smoothing\n- Focal loss\n\nAlso, it would be helpful to implement cross-validation, and try some other pretrained models and do ensembling.\n\nIf you enjoyed this kernel, please give it an upvote! Thanks for reading!\n","b415ba81":"We will now fine-tune the final layer of our pretrained model."}}