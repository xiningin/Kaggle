{"cell_type":{"b3fe07e0":"code","a455bf2f":"code","4141d59d":"code","8b78e5f3":"code","f547fc0b":"code","5b537099":"code","8d204a48":"code","8606db61":"code","431c961e":"code","f6e6f8de":"code","1722572f":"code","b9a356a9":"code","1a6cc880":"code","6f29f209":"code","7d72194d":"code","77866d80":"code","04165acb":"code","f023d9f8":"code","9935f642":"code","9cc854af":"code","8f3d4539":"code","713971b2":"code","57a6815f":"code","b2e30d98":"code","2d4828eb":"code","a6761817":"markdown","7ee228bd":"markdown","e1db56fb":"markdown","9782e1d5":"markdown","425ed3c4":"markdown","0f5da6b8":"markdown","05872cfc":"markdown","2f103bd6":"markdown","a8778a67":"markdown","83cc0203":"markdown","2e3333a1":"markdown","be1a88ff":"markdown","9548770d":"markdown","425985ea":"markdown"},"source":{"b3fe07e0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","a455bf2f":"#loading dataset\nwine=pd.read_csv('\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')","4141d59d":"#checking for null values\nwine.info();","8b78e5f3":"#checking quality column distribution\nplt.figure(figsize=(7,5))\nax=sns.countplot(data=wine,x='quality',palette='flare')\nfor p in ax.patches:\n    ax.annotate(f'\\n{p.get_height()}\\n{(p.get_height()\/len(wine)*100).round(0)}%', (p.get_x()+0.3, p.get_height()+10), color='black', size=7)\n\n    \nax.spines['top'].set_color('white') #setting right and top edge to invisible\nax.spines['right'].set_color('white')\n\n\nplt.show()\n\n","f547fc0b":"#redefining categories\nwine['quality'].replace([3,4,5,6,7,8],[0,0,0,1,1,1],inplace=True)\n\n#checking quality column distribution\nplt.figure(figsize=(7,5))\nax=sns.countplot(data=wine,x='quality',palette='flare')\nfor p in ax.patches:\n    ax.annotate(f'\\n{p.get_height()}\\n{(p.get_height()\/len(wine)*100).round(0)}%', (p.get_x()+0.3, p.get_height()+10), color='black', size=7)\n\n    \nax.spines['top'].set_color('white') #setting right and top edge to invisible\nax.spines['right'].set_color('white')\n\n\nplt.show()","5b537099":"sum(wine.duplicated())","8d204a48":"wine[wine.duplicated()]['quality'].value_counts()","8606db61":"wine.drop_duplicates(inplace=True)","431c961e":"X = wine.iloc[:, 0:11].values\ny = wine.iloc[:, -1].values\nprint(f'Number of data before removing outliers is {X.shape}')\n\n#cleaning outliers\nfrom sklearn.neighbors import LocalOutlierFactor\nlof = LocalOutlierFactor()\nyhat = lof.fit_predict(X)\n# select all rows that are not outliers\nmask = yhat != -1\nX,y = X[mask, :], y[mask]\n# summarize the shape of the updated dataset\nprint(f'Number of data after removing outliers is {X.shape}');","f6e6f8de":"plt.figure(figsize=(8,6))\nplt.title('Feature correlation')\nshape=np.triu(wine.corr())\nsns.heatmap(wine.corr(),annot=wine.corr().round(2),mask=shape,cmap='RdBu_r')\nplt.tight_layout()\nplt.show()","1722572f":"#splitting inot train and test set\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","b9a356a9":"#scaling the data before feature selection\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","1a6cc880":"wine.columns","6f29f209":"#defining new train set\nX_train_2=X_train[:,[1,6,7,9,10]]\nX_test_2=X_test[:,[1,6,7,9,10]]","7d72194d":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score,roc_auc_score\nnb_class=GaussianNB()\nnb_class.fit(X_train_2,y_train)\n\ny_pred_nb=nb_class.predict(X_test_2)\ny_pred_prob_nb=nb_class.predict_proba(X_test_2)[:,1]\n\nfrom sklearn.metrics import precision_recall_fscore_support\nimport warnings\nwarnings.filterwarnings('ignore')\np, r, f, s = precision_recall_fscore_support(\n    y_test,\n    y_pred_nb,\n    labels=[0,1], # the labels for which we want the metrics determined\n    average=None, # when None, returns a metric per label\n)\nresults_nb=pd.DataFrame(data=[p.round(2),r.round(2),f.round(2),s],\n                         index=[['Precision','Recall','f score','Support']],\n                         columns=[['class 0','class 1']])","77866d80":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score,GridSearchCV\nimport warnings\nwarnings.filterwarnings('ignore')","04165acb":"log_class = LogisticRegression(C=0.08,penalty='l2',solver='newton-cg',random_state = 0)\nlog_class.fit(X_train_2, y_train)\n\ny_pred_log=log_class.predict(X_test_2)\ny_pred_prob_log=log_class.predict_proba(X_test_2)[:,1]\n\n#presenting precision-recall results in dataframe\nfrom sklearn.metrics import precision_recall_fscore_support\nimport warnings\nwarnings.filterwarnings('ignore')\np, r, f, s = precision_recall_fscore_support(\n    y_test,\n    y_pred_log,\n    labels=[0,1], # the labels for which we want the metrics determined\n    average=None, # when None, returns a metric per label\n)\nresults_log=pd.DataFrame(data=[p.round(2),r.round(2),f.round(2),s],\n                         index=[['Precision','Recall','f score','Support']],\n                         columns=[['class 0','class 1']])","f023d9f8":"#for KNN I will plot results and choose the optimum number of neighbours\nfrom sklearn.neighbors import KNeighborsClassifier\nacc=[1]*20\nfor n in range (1,21):\n    knn_class = KNeighborsClassifier(n_neighbors = n, metric = 'minkowski', p = 2)\n    knn_class.fit(X_train_2, y_train)\n    y_pred = knn_class.predict(X_test_2)\n    acc[n-1]=accuracy_score(y_test,y_pred)\n\nn=list(np.linspace(1,20,20)) \nplt.figure()\nplt.plot(n,acc,color='red')\n\nplt.xticks(ticks=list(np.linspace(1,20,20)))\nplt.title(f'KNN : No. of neighbours vs. accuracy')\nplt.xlabel('No. of neighbours')\nplt.ylabel('Accuracy)')\n\nax=plt.gca() #setting right and top edge as invisible\nax.spines['top'].set_color('white')\nax.spines['right'].set_color('white')\n\nplt.show()","9935f642":"knn_class = KNeighborsClassifier(n_neighbors = 14, metric = 'minkowski', p = 2)\nknn_class.fit(X_train_2, y_train)\n\ny_pred_knn = knn_class.predict(X_test_2)\ny_pred_prob_knn=knn_class.predict_proba(X_test_2)[:,1]\n\n#presenting precision-recall results in dataframe\nfrom sklearn.metrics import precision_recall_fscore_support\nimport warnings\nwarnings.filterwarnings('ignore')\np, r, f, s = precision_recall_fscore_support(\n    y_test,\n    y_pred_knn,\n    labels=[0,1], # the labels for which we want the metrics determined\n    average=None, # when None, returns a metric per label\n)\nresults_knn=pd.DataFrame(data=[p.round(2),r.round(2),f.round(2),s],\n                         index=[['Precision','Recall','f score','Support']],\n                         columns=[['class 0','class 1']])","9cc854af":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\n\nsv_class=SVC()\n\nsv_grid=GridSearchCV(estimator=sv_class,\n                      param_grid={'C': [1,10,100],'gamma': [0.0001, 0.001,0.01,1],\n                                 'kernel':['linear','rbf']},\n                     cv=5,verbose=0, n_jobs=-1)\nsv_grid.fit(X_train_2,y_train)\n\nsv_grid.best_params_","8f3d4539":"sv_class = SVC(kernel = 'rbf',C=10, gamma=0.01, random_state = 0,probability=True)\nsv_class.fit(X_train_2, y_train)\n\ny_pred_sv=sv_class.predict(X_test_2)\ny_pred_prob_sv=sv_class.predict_proba(X_test_2)[:,1]\n\n#presenting precision-recall results in dataframe\nfrom sklearn.metrics import precision_recall_fscore_support\nimport warnings\nwarnings.filterwarnings('ignore')\np, r, f, s = precision_recall_fscore_support(\n    y_test,\n    y_pred_sv,\n    labels=[0,1], # the labels for which we want the metrics determined\n    average=None, # when None, returns a metric per label\n)\nresults_svc=pd.DataFrame(data=[p.round(2),r.round(2),f.round(2),s],\n                         index=[['Precision','Recall','f score','Support']],\n                         columns=[['class 0','class 1']])","713971b2":"\nacc_nb=accuracy_score(y_test,y_pred_nb).round(2)\nauc_nb=roc_auc_score(y_test,y_pred_prob_nb).round(2)\n\nacc_log=accuracy_score(y_test,y_pred_log).round(2)\nauc_log=roc_auc_score(y_test,y_pred_prob_log).round(2)\n\nacc_knn=accuracy_score(y_test,y_pred_knn).round(2)\nauc_knn=roc_auc_score(y_test,y_pred_prob_knn).round(2)\n\nacc_sv=accuracy_score(y_test,y_pred_sv).round(2)\nauc_sv=roc_auc_score(y_test,y_pred_prob_sv).round(2)\n\nresults1=pd.DataFrame(data=[[acc_nb,auc_nb],[acc_log,auc_log],\n                            [acc_knn,auc_knn],[acc_sv,auc_sv]],\n                      index=[['Naive Bayes','Logarithmic Regression','KNN',\n                            'Support Vector']],columns=[['accuracy','roc-auc']] )","57a6815f":"results2=pd.concat([results_nb,results_log,results_knn,results_svc],axis=1,\n                    keys=['Naive Bayes','Logarithmic Regression','KNN',\n                            'Support Vector'])","b2e30d98":"results1","2d4828eb":"results2","a6761817":"I will eliminate 6 variables : fixed acidity, citric acid,residual sugar, chlorides,free sulfur, pH .These were values that had highest correlation with other features or the lowest correlation with the wine quality.","7ee228bd":"We can see from above theat the highest accuracy is for n=4. ","e1db56fb":"# Part 1 \n\n# Duplicates, outliers and classes","9782e1d5":"Classes 3,4 and 8 account to only 5% of data. In this case data oversampling would not be approrpiate as majority of wines on the market are greaded as 5,6,7. Smaller number of wines are of very low or very high quality. \n\nI will define 2 new categories for our \"quality\" column. If quality > 5 then category will be \"good\" or 1, otherwise \"average\" or 0.","425ed3c4":"# Part 3 \n# Building classification models and tuning hyperparameters","0f5da6b8":"Duplicates are evenly distributed between both classes so I can remove them","05872cfc":"Looking at accuracy, roc-auc and precision\/recall we can agree that the Logarithmic regression and Naive Bayes give the best results. Very close are KNN and SVC while decision trees and regression fortest performed worse in this case. ","2f103bd6":"Naive Bayes gave pretty good results. Let's check others","a8778a67":"I will first try Naive Bayes","83cc0203":"# Part 4\n# Results summary","2e3333a1":"Now we have balanced datset and we can proceed with data cleaning.","be1a88ff":"# Part 2 \n\n# Feature selection ","9548770d":"Since there are 240 duplicatred entries we will remove them as they may cause model overfitting. ","425985ea":"For rest of the classifiers I will reppeat the same procedure:\n-run cross validation to check on \"possible\" accuracy\n-run GridSearch and cross validation in order to tune hyperparameters."}}