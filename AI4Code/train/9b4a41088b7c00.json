{"cell_type":{"941392d2":"code","2c477cfc":"code","0eb971a2":"code","f64f821e":"code","45eaae78":"code","37dead53":"code","3b40068c":"code","7c714458":"code","d6590967":"code","a3a96ac1":"code","454197cb":"code","43a7524d":"code","dda45d1e":"code","f75e4e51":"code","e9bb1085":"code","b45c34d3":"code","2cf81454":"code","8bf3a73e":"code","4b1dc869":"code","dffa2fbe":"code","6cb1dc25":"code","03b6cc09":"markdown","8be97a98":"markdown","f309dcb8":"markdown","ed746b1a":"markdown","bd58dcdc":"markdown","1ffb3493":"markdown","18fc56b8":"markdown","14a504ba":"markdown","0d4c5ad5":"markdown","794e42c2":"markdown","f3f4179a":"markdown","c344cc96":"markdown","e92f328b":"markdown","ce09ecb6":"markdown","a3737742":"markdown","d3df6735":"markdown","bbd353df":"markdown","894e6afb":"markdown","afc58d41":"markdown","6575294a":"markdown","27b6313a":"markdown","5b28a597":"markdown"},"source":{"941392d2":"import copy\nimport random\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pandas.io.formats import style\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\n\nimport sklearn\nimport sklearn.preprocessing as sk_prep\nimport sklearn.model_selection as sk_ms\nimport sklearn.feature_selection as sk_fs\nimport sklearn.pipeline as sk_pipe\nimport sklearn.compose as sk_comp\nimport sklearn.base as sk_base\nimport sklearn.ensemble as sk_ens\nimport sklearn.metrics as sk_met\nimport sklearn.linear_model as sk_lm\nimport sklearn.tree as sk_tree\nimport sklearn.svm as sk_svm\nimport sklearn.decomposition as sk_de\n\nfrom scipy import stats\n\nimport catboost as cb\n\nfrom statsmodels.tsa import seasonal","2c477cfc":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0eb971a2":"DATA_DIR = '\/kaggle\/input\/tabular-playground-series-jul-2021'\nRANDOM_STATE = 88533\n\nnp.random.seed(RANDOM_STATE)\nrandom.seed(RANDOM_STATE)","f64f821e":"# Train Data\n\ntrain_set = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'), parse_dates=[0])\ntrain_X = train_set.iloc[:, :-3] # Feature columns\n# train_ar = train_X.to_numpy()\n\ntarget_cols = list(train_set.columns)[-3:]\ntrain_y = train_set[target_cols]\n\n# # Train data with label encoded target\n# train_w_targ = train_X.copy()\n# train_w_targ[target_cols] = train_y\n\nprint(train_set.shape)\ntrain_set","45eaae78":"# Training DataFrames with datetime index\n# Targets adjusted to log values\n\ntrain_set_tidx = train_set.iloc[:, 1:].copy()\ntrain_set_tidx.index = train_set['date_time']\ntrain_X_tidx = train_set_tidx.iloc[:, :-3]\n\nfor col in train_set_tidx.columns[-3:]:\n    train_set_tidx.loc[:, col] = np.log(train_set_tidx[col])\n\ntrain_y_tidx = train_y.copy()\ntrain_y_tidx.loc[:, :] = np.log(train_y)\ntrain_y_tidx.index = train_set['date_time']\n\ntrain_set_tidx","37dead53":"# Test Data\n\ntest_set = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'), parse_dates=[0])\ntest_X = test_set\ntest_ar = test_X.to_numpy()\n\ntest_X.shape","3b40068c":"# Test dataframes with datetime index\n\ntest_set_tidx = test_set.iloc[:, 1:]\ntest_set_tidx.index = test_set['date_time']\ntest_X_tidx = test_set_tidx\n\ntest_set_tidx","7c714458":"# Count nulls\nprint(\"Count of NaN's\")\nprint('Train: ', np.sum(np.isnan(train_set_tidx.values)))\nprint('Test: ', np.sum(np.isnan(test_set_tidx.values)))","d6590967":"# Samples of timelines\n\nfor col in train_X.iloc[:, 1:5]:\n    fig, axis = plt.subplots(figsize=(15,2))\n    sns.lineplot(x='date_time', y=col, data=train_X)\n    sns.lineplot(x='date_time', y=col, data=test_X)\n    axis.set_title(col)\n    plt.show()","a3a96ac1":"# fig = px.scatter_matrix(train_set_tidx.iloc[:, [0,5,6,9,10]])\nfig = px.scatter_matrix(train_set_tidx.iloc[:, 1:])\nfig.update_traces(selected_marker_color='#ff0000', marker_size=2)\nfig.show()","454197cb":"fig = px.scatter_matrix(train_set_tidx.iloc[:, [0,5,6,9,10]])\nfig.update_traces(selected_marker_color='#ff0000', marker_size=2)\nfig.show()","43a7524d":"# Bad index and predictors for combination of train and test\n\ndata_bad = pd.concat([train_X_tidx, test_X_tidx[1:]])\nbad_idx = data_bad['deg_C'].between(22.0, 26.5).astype('int')\nbad_idx *= data_bad['sensor_3'].between(1500, 2100).astype('int')\n\nfor col in data_bad.columns:\n    data_bad.loc[bad_idx == 0, col] = np.nan\n\n# Bad index and targets for train\n\nbad_idx_tr = bad_idx[:train_y_tidx.shape[0]]\ndata_bad_y = train_y_tidx.copy()\n\nfor col in data_bad_y:\n    data_bad_y.loc[bad_idx_tr == 0, col] = np.nan","dda45d1e":"# predictor data in bad samples\ndata_bad.describe()","f75e4e51":"# target data in bad samples\ndata_bad_y.describe()","e9bb1085":"# Using 20% sample\n\n# Benzene removed because it does not have enought variation in bad values.\n\nplot_df = train_set_tidx.copy()\nplot_df.drop(columns='target_benzene', inplace=True)\nplot_df['bad_val'] = bad_idx_tr\n\ng = sns.PairGrid(plot_df.sample(frac=0.2), hue='bad_val', diag_sharey=False)\ng.map_upper(sns.scatterplot)\ng.map_lower(sns.kdeplot)\ng.map_diag(sns.kdeplot, multiple='layer', fill=True)","b45c34d3":"for col in train_X_tidx:\n    fig, axis = plt.subplots(figsize=(15,2))\n    sns.lineplot(x='date_time', y=col, data=train_X_tidx)\n    sns.lineplot(x='date_time', y=col, data=test_X_tidx)\n    sns.lineplot(x='date_time', y=col, data=data_bad, color='red')\n#     sns.scatterplot(x='date_time', y=col, data=data_bad, marker='o', color='red', edgecolors='none', alpha=1.0)\n    axis.set_title(col)\n    plt.show()","2cf81454":"for col in train_y_tidx:\n    fig, axis = plt.subplots(figsize=(11,2))\n    sns.lineplot(x=train_X_tidx.index, y=train_y_tidx[col])\n    sns.lineplot(x=train_X_tidx.index, y=data_bad_y[col], color='red')\n    axis.set_title(col)\n    plt.show()","8bf3a73e":"# Bad values only\n\nplot_df = plot_df.loc[bad_idx_tr == 1]\n# plot_df.drop(columns='target_benzene', inplace=True)\n\ng = sns.PairGrid(plot_df.iloc[:, :-1], diag_sharey=False)\ng.map_upper(sns.scatterplot)\ng.map_lower(sns.kdeplot)\ng.map_diag(sns.histplot)","4b1dc869":"# Simple data fix--use previous value\n\n# Get list of locations to fix (by number)\nbad_idx_2 = bad_idx_tr.copy()\nbad_idx_2.index = range(bad_idx_2.shape[0])\n\nbad_idx_list = bad_idx_2[bad_idx_2 == 1].index","dffa2fbe":"# Fix these locations by using the value before the start of the bad data\nfixed_data = train_set_tidx.copy()\nskip_cols = ['target_carbon_monoxide', 'target_nitrogen_oxides']\n\nfor i in bad_idx_list:\n    for j, col in enumerate(fixed_data.columns):\n        if col in skip_cols:\n            continue\n        fixed_data.iloc[i, j] = fixed_data.iloc[i-1, j]","6cb1dc25":"# Fixed samples only\n\nplot_df = fixed_data.loc[bad_idx_tr == 1]\n\ng = sns.PairGrid(plot_df, diag_sharey=False)\ng.map_upper(sns.scatterplot, alpha=0.1)\ng.map_lower(sns.kdeplot)\ng.map_diag(sns.histplot)","03b6cc09":"# Initial Check for Missing Data","8be97a98":"# Corrections","f309dcb8":"# Timelines with Errors Marked\n\nWe can also look at all of our timelines again, this time with the error samples marked.  This also fits with the belief that all predictors and one target are affected at the same time.","ed746b1a":"# Setup","bd58dcdc":"# Pairplot Showing the Bad Values","1ffb3493":"It should jump out at us that from time to time some sensors jump to a value that is far from their recent average and may stay there for a while.  This is especially obvious in absolute humidity where the value in these sections is on the edge of the range of the other values.","18fc56b8":"# Pairplot of Bad Samples\n\nThe next item to check is whether the small amount of variation in the bad readings have some value for predictions.  If they did, we would still have to separate them out or rescale them to work with the good values.  Let's use a pairplot to check the possibilities.","14a504ba":"Here we can see that some sensors show strong correlations, so some form of fixed data should be used.\n\nBenzene always has the same value when the sensors are failing, so we might do better setting the final prediction to that value for those samples rather than using a prediction from the model.  This assumes, of course, that the test data is like the training data in this respect.  Be sure to use the original value of Benzene in the bad data and not the log value shown in this notebook.","0d4c5ad5":"# Synopsis\n\nThis notebook addresses how we can find the bad sensor values, what we know about them, and a basic suggestion of how we might handle them.","794e42c2":"# Timelines of Predictors\n\nWe will start with time plots of a few of our predictors.  I first found the errors by examining these plots.","f3f4179a":"Here is a plot with a smaller number of variables to make the selection process easier.","c344cc96":"Interactively, I determined that the bad values for the combination of deg_C and Sensor 3 and sensor 4 are those between:\n\nDegrees C - 22-26.5\n\nSensor 3 - 1500 - 2100\n\nSensor 4 - 500-700\n\nUsing Degrees C with either of the others appears to define the set accurately.","e92f328b":"# Identifying a Set of Bad Samples","ce09ecb6":"# Using Pairplots to Find the Bad Values\n\nWe can use pairplots to help find the values that have unusual combinations of values for two variables.","a3737742":"From this description we can see that Benzene has almost no variation in the bad samples.  We will remove it from the following pairplots because it would cause trouble there.","d3df6735":"We can see that every variable has a limited range for the samples that we have identified as bad, except target carbon monoxide and target nitrogen oxides.  This leads us to expect that the bad data is in the same samples for all our inputs.  We already saw that benzene has almost no range at all in these samples.","bbd353df":"We will start with an interactive pair plot.  You can zoom in and then select groups of values that fall outside the main group; this will highlight those samples in all frames.  I would suggest zooming in on the separated group in absolute humidity (3rd row) vs sensor 4.  Then highlight the blob.  When you hover over the plot,the controls show in the upper right.","894e6afb":"We see that there are no missing values, so we might be tempted to think that no repair is needed.  Further exploration reveals that we have bad data instead of missing data.","afc58d41":"# Load Data","6575294a":"We can also determine the position of the blob and use the range of the coordinates to identify the bad values and then do the pair plot with two categories (normal and bad).\nHere we are using a 20% sampling to speed up the plotting; smaller samples had plotting errors.","27b6313a":"The only clear correlation is between two of the targets, so we will conclude that none of the variation in the predictors in the bad samples has any value for us.","5b28a597":"## Preprocessing\n\nThere are many ways we could substitute values in place of the bad data.  Here we will simply replace any bad value with the last good value before it, and check that we have some correlation to the target values for those samples."}}