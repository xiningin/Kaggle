{"cell_type":{"46ef3d97":"code","2def4607":"code","686a940e":"code","aeca987b":"code","37c95711":"code","16b59a45":"code","f2fb4d2c":"code","f2836d2f":"code","52a2dae8":"code","250be43f":"code","82574acc":"code","714e1645":"code","2b7e8c52":"code","ae5e1f1b":"code","fdefc43b":"code","58bc8313":"code","7e821ffe":"code","ec979b01":"code","0e5505e5":"code","877b0326":"code","6d5a7b20":"code","72a878af":"code","eb34a964":"markdown","747a85df":"markdown","345de1a0":"markdown","65c36118":"markdown"},"source":{"46ef3d97":"import cudf, cuml, cupy\nimport cv2\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport pandas as pd\nimport textwrap","2def4607":"# !pip install git+https:\/\/github.com\/jmcarpenter2\/swifter.git","686a940e":"import tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0\n\n# RESTRICT TENSORFLOW TO 12GB OF GPU RAM\n# SO THAT WE HAVE GPU RAM FOR RAPIDS CUML KNN\nLIMIT = 12\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    tf.config.experimental.set_virtual_device_configuration(\n        gpus[0],\n        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    print(e)\nprint('Restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\nprint('so RAPIDS can use %iGB GPU RAM'%(16-LIMIT))","aeca987b":"phase = 'train'\n# phase = 'test'\nBASE = f'..\/input\/shopee-product-matching\/{phase}_images\/'\ntrain = pd.read_csv(f\"..\/input\/shopee-product-matching\/{phase}.csv\")\ntrain_gf = cudf.read_csv(f\"..\/input\/shopee-product-matching\/{phase}.csv\")\nWGT = '..\/input\/effnetb0\/efficientnetb0_notop.h5'","37c95711":"KNN = 50\nif train.shape[0] == 3:\n    KNN = 3","16b59a45":"KNN","f2fb4d2c":"train.head()","f2836d2f":"# samples = train.sample(9)                    \n# fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(16, 20))\n# count=0\n# for row in ax:\n#     for col in row:\n#         col.imshow(plt.imread('..\/input\/shopee-product-matching\/test_images\/'+samples.iloc[count]['image']))\n#         col.set_title('\\n'.join(textwrap.wrap(samples.iloc[count]['title'], 35)))\n#         count += 1\n# plt.show()","52a2dae8":"model = TfidfVectorizer(stop_words='english', binary=True)\ntext_embeddings = model.fit_transform(train_gf.title).toarray()","250be43f":"model = NearestNeighbors(n_neighbors=KNN)\n\n#Unsupervised learning finding k nearest neighbours for each row\nmodel.fit(text_embeddings)\n\n#Distances has the distances and corresponding indices are in indices\ndistances, text_indices = model.kneighbors(text_embeddings)","82574acc":"# # Let us check the result\n# for i in range(5):\n#     print(train_gf.iloc[text_indices[i, 0:5]][['title']])","714e1645":"class DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, df, img_size=256, batch_size=32, path=BASE): \n        self.df = df\n        self.img_size = img_size\n        self.batch_size = batch_size\n        self.path = path\n        self.indexes = np.arange( len(self.df) )\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        ct = len(self.df) \/\/ self.batch_size\n        ct += int(( (len(self.df)) % self.batch_size)!=0)\n        return ct\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        X = self.__data_generation(indexes)\n        return X\n            \n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples' \n        X = np.zeros((len(indexes),self.img_size,self.img_size,3),dtype='float32')\n        df = self.df.iloc[indexes]\n        for i,(index,row) in enumerate(df.iterrows()):\n            img = cv2.imread(self.path+row.image)\n            X[i,] = cv2.resize(img,(self.img_size,self.img_size)) #\/128.0 - 1.0\n        return X        ","2b7e8c52":"model = EfficientNetB0(weights=WGT, include_top=False, pooling='avg', input_shape=None)\ntrain_gen = DataGenerator(train, batch_size=128)\nimage_embeddings = model.predict(train_gen,verbose=1)\nimage_embeddings.shape","ae5e1f1b":"#49 neighbors\nmodel = NearestNeighbors(n_neighbors=KNN)\n#Unsupervised learning finding k nearest neighbours for each row\nmodel.fit(image_embeddings)\n#Distances has the distances and corresponding indices are in indices\ndistances, image_indices = model.kneighbors(image_embeddings)","fdefc43b":"# indices_df = pd.DataFrame(image_indices)\n# samples = indices_df.sample(9)                    \n# fig, ax = plt.subplots(nrows=9, ncols=4, figsize=(26, 80))\n# line=0\n# for row in ax:\n#     column=0\n#     for col in row:\n#         item = train.iloc[samples.iloc[line:line+1, column:column+1].values[0][0]]\n#         col.imshow(plt.imread('..\/input\/shopee-product-matching\/train_images\/'+item['image']))\n#         col.set_title('\\n'.join(textwrap.wrap(item['title'], 35)))\n#         column += 1\n#     line += 1\n# plt.show()","58bc8313":"submission = pd.DataFrame()\nsubmission['posting_id'] = train['posting_id']","7e821ffe":"indices = np.hstack((image_indices, text_indices.get()))","ec979b01":"def get_top_text(x, len=50):\n    x = np.unique(x)\n    if x.shape[0] < 50: len = x.shape[0]\n    return ' '.join(train.iloc[x]['posting_id'].values[0:len])\n","0e5505e5":"l = np.apply_along_axis(get_top_text, 1, indices )","877b0326":"submission['matches'] = l\n# submission['matches'] = matchFunction(indices)","6d5a7b20":"submission","72a878af":"submission.to_csv('submission.csv', index=False)","eb34a964":"Thanks to: https:\/\/www.kaggle.com\/cdeotte\/rapids-cuml-tfidfvectorizer-and-knn","747a85df":"### Similarity in Images","345de1a0":"#### Get embeddings for each image (for comparing)","65c36118":"### Similarity in title only"}}