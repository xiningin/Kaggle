{"cell_type":{"a90592ad":"code","13c41430":"code","66ff9aa4":"code","b0f345b8":"code","999b761e":"code","99d80f40":"code","6034de9b":"code","9176169c":"code","e92ee67d":"code","0015bd80":"code","64c06d36":"code","ba2d3f1b":"code","db239334":"code","e9667b7f":"code","0a05d3f1":"code","8b857f7f":"code","eea598ce":"code","fa810b7e":"code","db8889bf":"code","7e189f5d":"code","0b203162":"code","9beebeb5":"code","8fd0ef43":"code","538b7f7f":"code","820c7317":"code","51131d42":"code","5a459448":"code","8d94aad0":"code","a7a9ea4c":"code","b52e6858":"code","c18b87be":"code","ad8d53b0":"code","519014e4":"code","96433cbe":"code","c9f6beb9":"code","6d5dc660":"code","6fd25f0a":"code","fececb67":"code","11caa01c":"code","f38ee9a1":"code","48bffb8e":"code","491be2eb":"code","0eafb177":"code","b89e18af":"code","71e02de1":"code","86f64476":"code","d8864a97":"code","891c7b6d":"code","91cad425":"code","d4e0ea76":"code","a662d7c1":"code","5517a49e":"code","d87919ee":"code","9245da9c":"code","83f3994a":"code","01e658ad":"code","b28032a1":"code","961d140a":"code","2e5ebe19":"code","f4aaf3aa":"code","8196779d":"code","0e4354f8":"code","ae78d380":"code","efafa388":"code","fba1d63b":"code","85766fc5":"code","4d982647":"markdown","de1abd15":"markdown","383dd348":"markdown","6fcb91d3":"markdown","21b1e7a5":"markdown","0f9ebb84":"markdown","98266405":"markdown","7ef4fe65":"markdown","73c1e053":"markdown","961b8476":"markdown","c02d95a1":"markdown"},"source":{"a90592ad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","13c41430":"!pip install catboost","66ff9aa4":"#!pip install --user --upgrade catboost","b0f345b8":"import catboost\nprint(catboost.__version__)","999b761e":"import pandas as pd\nimport os\nimport numpy as np\nnp.set_printoptions(precision=4)\nimport catboost\nfrom catboost import *\nfrom catboost import datasets\n","99d80f40":"(train_df,test_df) = catboost.datasets.amazon()","6034de9b":"train_df.head()","9176169c":"y = train_df.ACTION\nx = train_df.drop('ACTION',axis = 1)","e92ee67d":"cat_features = list(range(0,x.shape[1]))\nprint(cat_features)","0015bd80":"print('Labels: {}'.format(set(y)))\nprint('Zero count = {}, One count = {}'.format(len(y) - sum(y), sum(y)))","64c06d36":"dataset_dir = '.\/amazon'\nif not os.path.exists(dataset_dir):\n    os.makedirs(dataset_dir)\n\n# We will be able to work with files with\/without header and\n# with different separators.\ntrain_df.to_csv(\n    os.path.join(dataset_dir, 'train.tsv'),\n    index=False, sep='\\t', header=False\n)\ntest_df.to_csv(\n    os.path.join(dataset_dir, 'test.tsv'),\n    index=False, sep='\\t', header=False\n)\n\ntrain_df.to_csv(\n    os.path.join(dataset_dir, 'train.csv'),\n    index=False, sep=',', header=True\n)\ntest_df.to_csv(\n    os.path.join(dataset_dir, 'test.csv'),\n    index=False, sep=',', header=True\n)","ba2d3f1b":"!head amazon\/train.csv","db239334":"\nfrom catboost.utils import create_cd\nfeature_names = dict()\nfor column, name in enumerate(train_df):\n    if column == 0:\n        continue\n    feature_names[column - 1] = name\n    \ncreate_cd(\n    label=0, \n    cat_features=list(range(1, train_df.columns.shape[0])),\n    feature_names=feature_names,\n    output_path=os.path.join(dataset_dir, 'train.cd')\n)","e9667b7f":"!cat amazon\/train.cd","0a05d3f1":"\npool1 = Pool(data=x, label=y, cat_features=cat_features)\npool2 = Pool(\n    data=os.path.join(dataset_dir, 'train.csv'), \n    delimiter=',', \n    column_description=os.path.join(dataset_dir, 'train.cd'),\n    has_header=True\n)\npool3 = Pool(data=x, cat_features=cat_features)\n\n# Fastest way to create a Pool is to create it from numpy matrix.\n# This way should be used if you want fast predictions\n# or fastest way to load the data in python.\n\nx_prepared = x.values.astype(str).astype(object)\n# For FeaturesData class categorial features must have type str\n\npool4 = Pool(\n    data=FeaturesData(\n        cat_feature_data=x_prepared,\n        cat_feature_names=list(x)\n    ),\n    label=y.values\n)\n\nprint('Dataset shape')\nprint('dataset 1:' + str(pool1.shape) +\n      '\\ndataset 2:' + str(pool2.shape) + \n      '\\ndataset 3:' + str(pool3.shape) +\n      '\\ndataset 4: ' + str(pool4.shape))\n\nprint('\\n')\nprint('Column names')\nprint('dataset 1:')\nprint(pool1.get_feature_names()) \nprint('\\ndataset 2:')\nprint(pool2.get_feature_names())\nprint('\\ndataset 3:')\nprint(pool3.get_feature_names())\nprint('\\ndataset 4:')\nprint(pool4.get_feature_names())","8b857f7f":"from sklearn.model_selection import train_test_split\nx_train, x_validation, y_train, y_validation = train_test_split(x, y, train_size=0.8, random_state=1234)\n","eea598ce":"from catboost import CatBoostClassifier\nmodel = CatBoostClassifier(\n    iterations=5,\n    learning_rate=0.1,\n    # loss_function='CrossEntropy'\n)\nmodel.fit(\n    x_train, y_train,\n    cat_features=cat_features,\n    eval_set=(x_validation, y_validation),\n    verbose=False\n)\nprint('Model is fitted: ' + str(model.is_fitted()))\nprint('Model params:')\nprint(model.get_params())","fa810b7e":"from catboost import CatBoostClassifier\nmodel = CatBoostClassifier(\n    iterations=15,\n#     verbose=5,\n)\nmodel.fit(\n    x_train, y_train,\n    cat_features=cat_features,\n    eval_set=(x_validation, y_validation),\n)","db8889bf":"from catboost import CatBoostClassifier\nmodel = CatBoostClassifier(\n    iterations=50,\n    random_seed=63,\n    learning_rate=0.5,\n    custom_loss=['AUC', 'Accuracy']\n)\nmodel.fit(\n    x_train, y_train,\n    cat_features=cat_features,\n    eval_set=(x_validation, y_validation),\n    verbose=False,\n    plot=True\n)","7e189f5d":"model1 = CatBoostClassifier(\n    learning_rate=0.7,\n    iterations=100,\n    random_seed=0,\n    train_dir='learing_rate_0.7'\n)\n\nmodel2 = CatBoostClassifier(\n    learning_rate=0.01,\n    iterations=100,\n    random_seed=0,\n    train_dir='learing_rate_0.01'\n)\nmodel1.fit(\n    x_train, y_train,\n    eval_set=(x_validation, y_validation),\n    cat_features=cat_features,\n    verbose=False\n)\nmodel2.fit(\n    x_train, y_train,\n    eval_set=(x_validation, y_validation),\n    cat_features=cat_features,\n    verbose=False\n)","0b203162":"from catboost import MetricVisualizer\nMetricVisualizer(['learing_rate_0.01', 'learing_rate_0.7']).start()","9beebeb5":"\nfrom catboost import CatBoostClassifier\nmodel = CatBoostClassifier(\n    iterations=100,\n    random_seed=63,\n    learning_rate=0.5,\n#     use_best_model=False\n)\nmodel.fit(\n    x_train, y_train,\n    cat_features=cat_features,\n    eval_set=(x_validation, y_validation),\n    verbose=False,\n    plot=True\n)","8fd0ef43":"print('Tree count: ' + str(model.tree_count_))","538b7f7f":"from catboost import cv\n\nparams = {}\nparams['loss_function'] = 'Logloss'\nparams['iterations'] = 80\nparams['custom_loss'] = 'AUC'\nparams['random_seed'] = 63\nparams['learning_rate'] = 0.5\n\ncv_data = cv(\n    params = params,\n    pool = Pool(x, label=y, cat_features=cat_features),\n    fold_count=5,\n    shuffle=True,\n    partition_random_seed=0,\n    plot=True,\n    stratified=False,\n    verbose=False\n)","820c7317":"cv_data.head()","51131d42":"best_value = np.min(cv_data['test-Logloss-mean'])\nbest_iter = np.argmin(cv_data['test-Logloss-mean'])\n\nprint('Best validation Logloss score, not stratified: {:.4f}\u00b1{:.4f} on step {}'.format(\n    best_value,\n    cv_data['test-Logloss-std'][best_iter],\n    best_iter)\n)","5a459448":"\ncv_data = cv(\n    params = params,\n    pool = Pool(x, label=y, cat_features=cat_features),\n    fold_count=5,\n    type = 'Classical',\n    shuffle=True,\n    partition_random_seed=0,\n    plot=True,\n    stratified=True,\n    verbose=False\n)\n\nbest_value = np.min(cv_data['test-Logloss-mean'])\nbest_iter = np.argmin(cv_data['test-Logloss-mean'])\n\nprint('Best validation Logloss score, stratified: {:.4f}\u00b1{:.4f} on step {}'.format(\n    best_value,\n    cv_data['test-Logloss-std'][best_iter],\n    best_iter)\n)","8d94aad0":"model_with_early_stop = CatBoostClassifier(\n    iterations=200,\n    random_seed=63,\n    learning_rate=0.5,\n    early_stopping_rounds=20\n)\nmodel_with_early_stop.fit(\n    x_train, y_train,\n    cat_features=cat_features,\n    eval_set=(x_validation, y_validation),\n    verbose=False,\n    plot=True\n)","a7a9ea4c":"print(model_with_early_stop.tree_count_)","b52e6858":"model_with_early_stop = CatBoostClassifier(\n    eval_metric='AUC',\n    iterations=200,\n    random_seed=63,\n    learning_rate=0.5,\n    early_stopping_rounds=20\n)\nmodel_with_early_stop.fit(\n    x_train, y_train,\n    cat_features=cat_features,\n    eval_set=(x_validation, y_validation),\n    verbose=False,\n    plot=True\n)","c18b87be":"print(model_with_early_stop.tree_count_)","ad8d53b0":"model = CatBoostClassifier(\n    random_seed=63,\n    iterations=200,\n    learning_rate=0.03,\n)\nmodel.fit(\n    x_train, y_train,\n    cat_features=cat_features,\n    verbose=False,\n    plot=True\n)","519014e4":"\nfrom catboost.utils import get_roc_curve\nimport sklearn\nfrom sklearn import metrics\n\neval_pool = Pool(x_validation, y_validation, cat_features=cat_features)\ncurve = get_roc_curve(model, eval_pool)\n(fpr, tpr, thresholds) = curve\nroc_auc = sklearn.metrics.auc(fpr, tpr)","96433cbe":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(16, 8))\nlw = 2\n\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc, alpha=0.5)\n\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--', alpha=0.5)\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\nplt.grid(True)\nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16)\nplt.title('Receiver operating characteristic', fontsize=20)\nplt.legend(loc=\"lower right\", fontsize=16)\nplt.show()","c9f6beb9":"from catboost.utils import get_fpr_curve\nfrom catboost.utils import get_fnr_curve\n\n(thresholds, fpr) = get_fpr_curve(curve=curve)\n(thresholds, fnr) = get_fnr_curve(curve=curve)","6d5dc660":"\nplt.figure(figsize=(16, 8))\nlw = 2\n\nplt.plot(thresholds, fpr, color='blue', lw=lw, label='FPR', alpha=0.5)\nplt.plot(thresholds, fnr, color='green', lw=lw, label='FNR', alpha=0.5)\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\nplt.grid(True)\nplt.xlabel('Threshold', fontsize=16)\nplt.ylabel('Error Rate', fontsize=16)\nplt.title('FPR-FNR curves', fontsize=20)\nplt.legend(loc=\"lower left\", fontsize=16)\nplt.show()","6fd25f0a":"from catboost.utils import select_threshold\n\nprint(select_threshold(model=model, data=eval_pool, FNR=0.01))\nprint(select_threshold(model=model, data=eval_pool, FPR=0.01))","fececb67":"\n# !rm 'catboost_info\/snapshot.bkp'\nfrom catboost import CatBoostClassifier\nmodel = CatBoostClassifier(\n    iterations=100,\n    save_snapshot=True,\n    snapshot_file='snapshot.bkp',\n    snapshot_interval=1,\n    random_seed=43\n)\nmodel.fit(\n    x_train, y_train,\n    eval_set=(x_validation, y_validation),\n    cat_features=cat_features,\n    verbose=True\n)","11caa01c":"print(model.predict_proba(data=x_validation))","f38ee9a1":"print(model.predict(data=x_validation))","48bffb8e":"raw_pred = model.predict(\n    data=x_validation,\n    prediction_type='RawFormulaVal'\n)\nprint(raw_pred)","491be2eb":"from numpy import exp\n\nsigmoid = lambda x: 1 \/ (1 + exp(-x))\n\nprobabilities = sigmoid(raw_pred)\n\nprint(probabilities)","0eafb177":"x_prepared = x_validation.values.astype(str).astype(object)\n# For FeaturesData class categorial features must have type str\n\nfast_predictions = model.predict_proba(\n    data=FeaturesData(\n        cat_feature_data=x_prepared,\n        cat_feature_names=list(x_validation)\n    )\n)\nprint(fast_predictions)","b89e18af":"predictions_gen = model.staged_predict_proba(\n    data=x_validation,\n    ntree_start=0, \n    ntree_end=5, \n    eval_period=1\n)\ntry:\n    for iteration, predictions in enumerate(predictions_gen):\n        print('Iteration ' + str(iteration) + ', predictions:')\n        print(predictions)\nexcept Exception:\n    pass","71e02de1":"from catboost import CatBoostClassifier\nmodel = CatBoostClassifier(\n    iterations=50,\n    random_seed=43,\n    loss_function='MultiClass'\n)\nmodel.fit(\n    x_train, y_train,\n    cat_features=cat_features,\n    eval_set=(x_validation, y_validation),\n    verbose=False,\n    plot=True\n)","86f64476":"from copy import deepcopy\ndef build_multiclass_ranking_dataset(x, y, cat_features, label_values=[0,1], start_group_id=0):\n    ranking_matrix = []\n    ranking_labels = []\n    group_ids = []\n\n    x_train_matrix = x.values\n    y_train_vector = y.values\n\n    for obj_idx in range(x.shape[0]):\n        obj = list(x_train_matrix[obj_idx])\n\n        for label in label_values:\n            obj_of_given_class = deepcopy(obj)\n            obj_of_given_class.append(label)\n            ranking_matrix.append(obj_of_given_class)\n            ranking_labels.append(float(y_train_vector[obj_idx] == label)) \n            group_ids.append(start_group_id + obj_idx)\n        \n    final_cat_features = deepcopy(cat_features)\n    final_cat_features.append(x.shape[1]) # new feature that we are adding should be categorical.\n    return Pool(ranking_matrix, ranking_labels, cat_features=final_cat_features, group_id = group_ids)","d8864a97":"from catboost import CatBoost\nparams = {'iterations':150, 'learning_rate':0.01, 'l2_leaf_reg':30, 'random_seed':0, 'loss_function':'QuerySoftMax'}\n\ngroupwise_train_pool = build_multiclass_ranking_dataset(x_train, y_train, cat_features, [0,1])\ngroupwise_eval_pool = build_multiclass_ranking_dataset(x_validation, y_validation, cat_features, [0,1], x_train.shape[0])\n\nmodel = CatBoost(params)\nmodel.fit(\n    X=groupwise_train_pool,\n    verbose=False,\n    eval_set=groupwise_eval_pool,\n    plot=True\n)","891c7b6d":"import math\n\nobj = list(x_validation.values[0])\nratings = []\nfor label in [0,1]:\n    obj_with_label = deepcopy(obj)\n    obj_with_label.append(label)\n    rating = model.predict([obj_with_label])[0]\n    ratings.append(rating)\nprint('Raw values:', np.array(ratings))\n\ndef soft_max(values):\n    return [math.exp(val) \/ sum([math.exp(val) for val in values]) for val in values]\n\nprint('Probabilities', np.array(soft_max(ratings)))","91cad425":"model = CatBoostClassifier(\n    random_seed=63,\n    iterations=200,\n    learning_rate=0.03,\n)\nmodel.fit(\n    x_train, y_train,\n    cat_features=cat_features,\n    verbose=50\n)","d4e0ea76":"metrics = model.eval_metrics(\n    data=pool1,\n    metrics=['Logloss','AUC'],\n    ntree_start=0,\n    ntree_end=0,\n    eval_period=1,\n    plot=True\n)","a662d7c1":"print('AUC values:')\nprint(np.array(metrics['AUC']))","5517a49e":"model.get_feature_importance(prettified=True)","d87919ee":"shap_values = model.get_feature_importance(pool1, type='ShapValues')\nexpected_value = shap_values[0,-1]\nshap_values = shap_values[:,:-1]\nprint(shap_values.shape)","9245da9c":"import shap\n\nshap.initjs()\nshap.force_plot(expected_value, shap_values[3,:], x.iloc[3,:])","83f3994a":"import shap\n\nshap.initjs()\nshap.force_plot(expected_value, shap_values[91,:], x.iloc[91,:])","01e658ad":"shap.summary_plot(shap_values, x)\n","b28032a1":"x_small = x.iloc[0:200]\nshap_small = shap_values[:200]\nshap.force_plot(expected_value, shap_small, x_small)","961d140a":"from catboost.eval.catboost_evaluation import *\nlearn_params = {'iterations': 20, # 2000\n                'learning_rate': 0.5, # we set big learning_rate,\n                                      # because we have small\n                                      # #iterations\n                'random_seed': 0,\n                'verbose': False,\n                'loss_function' : 'Logloss',\n                'boosting_type': 'Plain'}\nevaluator = CatboostEvaluation('amazon\/train.tsv',\n                               fold_size=10000, # <= 50% of dataset\n                               fold_count=20,\n                               column_description='amazon\/train.cd',\n                               partition_random_seed=0,\n                               #working_dir=... \n)\nresult = evaluator.eval_features(learn_config=learn_params,\n                                 eval_metrics=['Logloss', 'Accuracy'],\n                                 features_to_eval=[6, 7, 8])","2e5ebe19":"from catboost.eval.evaluation_result import *\nlogloss_result = result.get_metric_results('Logloss')\nlogloss_result.get_baseline_comparison(\n    ScoreConfig(ScoreType.Rel, overfit_iterations_info=False)\n)","f4aaf3aa":"my_best_model = CatBoostClassifier(iterations=10)\nmy_best_model.fit(\n    x_train, y_train,\n    eval_set=(x_validation, y_validation),\n    cat_features=cat_features,\n    verbose=False\n)\nmy_best_model.save_model('catboost_model.bin')\nmy_best_model.save_model('catboost_model.json', format='json')","8196779d":"my_best_model.load_model('catboost_model.bin')\nprint(my_best_model.get_params())\nprint(my_best_model.random_seed_)","0e4354f8":"from catboost import CatBoost\nfast_model = CatBoostClassifier(\n    random_seed=63,\n    iterations=150,\n    learning_rate=0.01,\n    boosting_type='Plain',\n    bootstrap_type='Bernoulli',\n    subsample=0.5,\n    one_hot_max_size=20,\n    rsm=0.5,\n    leaf_estimation_iterations=5,\n    max_ctr_complexity=1)\n\nfast_model.fit(\n    x_train, y_train,\n    cat_features=cat_features,\n    verbose=False,\n    plot=True\n)","ae78d380":"tunned_model = CatBoostClassifier(\n    random_seed=63,\n    iterations=1000,\n    learning_rate=0.03,\n    l2_leaf_reg=3,\n    bagging_temperature=1,\n    random_strength=1,\n    one_hot_max_size=2,\n    leaf_estimation_method='Newton'\n)\ntunned_model.fit(\n    x_train, y_train,\n    cat_features=cat_features,\n    verbose=False,\n    eval_set=(x_validation, y_validation),\n    plot=True\n)","efafa388":"best_model = CatBoostClassifier(\n    random_seed=63,\n    iterations=int(tunned_model.tree_count_ * 1.2),\n)\nbest_model.fit(\n    x, y,\n    cat_features=cat_features,\n    verbose=100\n)","fba1d63b":"x_test = test_df.drop('id', axis=1)\ntest_pool = Pool(data=x_test, cat_features=cat_features)\ncontest_predictions = best_model.predict_proba(test_pool)\nprint('Predictoins:')\nprint(contest_predictions)","85766fc5":"f = open('submit.csv', 'w')\nf.write('Id,Action\\n')\nfor idx in range(len(contest_predictions)):\n    line = str(test_df['id'][idx]) + ',' + str(contest_predictions[idx][1]) + '\\n'\n    f.write(line)\nf.close()","4d982647":"Saving the model","de1abd15":"**importing dataset from catboost dataset feature **","383dd348":"looking for lable balance in data set","6fcb91d3":"Cross-validation","21b1e7a5":"Action column contains the categoical feature but its not avilble for test data set , so dropping the Action column","0f9ebb84":"Overfitting detector","98266405":"Solving MultiClassification problem","7ef4fe65":"**Split your data into train and validation**","73c1e053":"**Reading data set from input data **","961b8476":"Hyperparameter tunning","c02d95a1":"Now we will declare the cat feature which holds the categorical values present on train data set ."}}