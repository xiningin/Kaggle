{"cell_type":{"93e81f4f":"code","abb6583f":"code","45bb991e":"code","104a24f2":"code","0fda30a8":"code","eed89d68":"code","6ddd6424":"code","a6a1d8bf":"code","1fe81090":"code","d06981ce":"code","3bcbf4a9":"code","85aa7db4":"code","9ff696c1":"code","082b6e27":"code","f798f829":"code","44b0ff27":"code","8f554438":"code","ad621e21":"markdown","f98772dc":"markdown"},"source":{"93e81f4f":"import numpy as np \nimport pandas as pd \nimport os\nimport re\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf","abb6583f":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","45bb991e":"# Let's use 192x192 by default\nimage_size = (192, 192)\n\n# Data dirs\ndata_gcs = KaggleDatasets().get_gcs_path('tpu-getting-started')\n\n# Subdirs by image size\ndata_dir_by_size = {\n    (512, 512): '\/tfrecords-jpeg-512x512',\n    (331, 331): '\/tfrecords-jpeg-331x331',\n    (224, 224): '\/tfrecords-jpeg-224x224',\n    (192, 192): '\/tfrecords-jpeg-192x192'\n}\nsubdir = data_dir_by_size[image_size]\n# Paths to data files\ntrain_file_names = tf.io.gfile.glob(data_gcs + subdir + '\/train' + '\/*.tfrec')\nval_file_names = tf.io.gfile.glob(data_gcs + subdir + '\/val' + '\/*.tfrec')\ntest_file_names = tf.io.gfile.glob(data_gcs + subdir + '\/test' + '\/*.tfrec')","104a24f2":"# Classification Categories in our Dataset\nflower_categories = [\n    'pink primrose',     'hard-leaved pocket orchid', 'canterbury bells',\n    'sweet pea',         'wild geranium',             'tiger lily',\n    'moon orchid',       'bird of paradise',          'monkshood',\n    'globe thistle',     'snapdragon',                'colt\\'s foot',\n    'king protea',       'spear thistle',             'yellow iris',\n    'globe-flower',      'purple coneflower',         'peruvian lily',\n    'balloon flower',    'giant white arum lily',     'fire lily',\n    'pincushion flower', 'fritillary',                'red ginger',\n    'grape hyacinth',    'corn poppy',                'prince of wales feathers',\n     'stemless gentian',  'artichoke',                 'sweet william',\n    'carnation',         'garden phlox',              'love in the mist',\n    'cosmos',            'alpine sea holly',          'ruby-lipped cattleya',\n    'cape flower',       'great masterwort',          'siam tulip',\n    'lenten rose',       'barberton daisy',           'daffodil',\n    'sword lily',        'poinsettia',                'bolero deep blue',\n    'wallflower',        'marigold',                  'buttercup',\n    'daisy',             'common dandelion',          'petunia',\n    'wild pansy',        'primula',                   'sunflower',\n    'lilac hibiscus',    'bishop of llandaff',        'gaura',\n    'geranium',          'orange dahlia',             'pink-yellow dahlia',\n    'cautleya spicata',  'japanese anemone',          'black-eyed susan',\n    'silverbush',        'californian poppy',         'osteospermum',\n    'spring crocus',     'iris',                      'windflower',\n    'tree poppy',        'gazania',                   'azalea',\n    'water lily',        'rose',                      'thorn apple',\n    'morning glory',     'passion flower',            'lotus',\n    'toad lily',         'anthurium',                 'frangipani',\n    'clematis',          'hibiscus',                  'columbine',\n    'desert-rose',       'tree mallow',               'magnolia',\n    'cyclamen ',         'watercress',                'canna lily',\n    'hippeastrum ',      'bee balm',                  'pink quill',\n    'foxglove',          'bougainvillea',             'camellia',\n    'mallow',            'mexican petunia',           'bromelia',\n    'blanket flower',    'trumpet creeper',           'blackberry lily',\n    'common tulip',      'wild rose'\n]\n\nprint('Number of flower categories:', len(flower_categories))","0fda30a8":"def decode_image(image_data):\n    \"\"\"Decodes JPEG data and return a normalized image.\n    \n    WARNING: you may need a different normalization if you\n    use VGG-like networks.\n    \"\"\"\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.reshape(image, [*image_size, 3])\n    return image\n\ndef read_labeled_tfrecord(example):\n    \"\"\"\n    Converts a single record in labeled dataset (i.e. train and validation\n    sets) to the more convenient format (image, label)\n    \"\"\"\n    example = tf.io.parse_single_example(\n        serialized=example,\n        features={\n            'image': tf.io.FixedLenFeature([], tf.string),\n            'class': tf.io.FixedLenFeature([], tf.int64),\n        }\n    )\n    \n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label\n\ndef read_unlabeled_tfrecord(example):\n    \"\"\"\n    Converts a single record in labeled dataset (i.e. test\n    set) to the more convenient format (image, id)\n    \"\"\"\n    example = tf.io.parse_single_example(\n        serialized=example,\n        features={\n            'image': tf.io.FixedLenFeature([], tf.string),\n            'id': tf.io.FixedLenFeature([], tf.string),\n        }\n    )\n    \n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    \"\"\"\n    Given a list of `*.tfrec` file names, converts them into a `tf.data.Dataset`\n    object that yields elements of format (image, label) or (image, id)\n    \n    # Arguments\n        filenames: list of paths to `*.tfrec` files\n        labeled: if True, the resulting dataset will yield data in format\n            (image, label). Otherwise it will yield in format (image, id)\n        ordered: whether to shuffle the dataset (not desirable for test\/val)\n        \n    # Returns\n        a `tf.data.Dataset` object that holds memory map to `*.tfrec` files\n    \"\"\"\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = ordered\n    \n    dataset = tf.data.TFRecordDataset(\n        filenames, num_parallel_reads=tf.data.experimental.AUTOTUNE)\n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(\n        read_labeled_tfrecord if labeled else read_unlabeled_tfrecord,\n        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    return dataset\n\n","eed89d68":"def data_augment(image, label):\n    image = tf.image.random_flip_left_right(image)\n    return image, label \n\ndef get_training_dataset():\n    dataset = load_dataset(train_file_names, labeled=True)\n    dataset = dataset.map(data_augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(val_file_names, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(test_file_names, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n    return dataset\n\n\ndef count_data_items(filenames):\n    \"\"\"\n    There's no way to obtain explicitly the number of elements in each dataset\n    (see: https:\/\/stackoverflow.com\/questions\/40472139\/), but we can infer that\n    from file names, i.e. flowers00-230.tfrec = 230 data items\n    \"\"\"\n    return np.sum([\n        int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1))\n        for filename in filenames])\n\n\n# Import Datasets\ntrain_dataset = load_dataset(train_file_names, labeled=True, ordered=False)\nval_dataset = load_dataset(val_file_names, labeled=True, ordered=False)\ntest_dataset = load_dataset(test_file_names, labeled=False, ordered=True)\n\n# Calculate number of items\nnum_training_samples = count_data_items(train_file_names)\nnum_validation_samples = count_data_items(val_file_names)\nnum_testing_samples = count_data_items(test_file_names)","6ddd6424":"print('Train samples:', num_training_samples, end=', ')\nprint('Val samples:', num_validation_samples, end=', ')\nprint('Test samples:', num_testing_samples)","a6a1d8bf":"BATCH_SIZE = 128\n\ntrain = get_training_dataset()\nvalid = get_validation_dataset()\ntest = get_test_dataset()\n\nprint(\"Training:\", train)\nprint (\"Validation:\", valid)\nprint(\"Test:\", test)","1fe81090":"from keras.models import model_from_json\n# load json and create model\njson_file = open('..\/input\/models\/model_IResNet2.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nmodel_IResNet2 = model_from_json(loaded_model_json)\n# load weights into new model\nmodel_IResNet2.load_weights(\"..\/input\/models\/model_IResNet2.h5\")\nprint(\"Loaded model from disk\")","d06981ce":"# load json and create model\njson_file = open('..\/input\/models\/model_dense.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nmodel_dense = model_from_json(loaded_model_json)\n# load weights into new model\nmodel_dense.load_weights(\"..\/input\/models\/model_dense.h5\")\nprint(\"Loaded model from disk\")","3bcbf4a9":"model_IResNet2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])\nmodel_dense.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])\n","85aa7db4":"c = model_IResNet2.fit(train, validation_data = valid, epochs = 3, batch_size=128,steps_per_epoch = num_training_samples \/\/ 128)","9ff696c1":"d = model_dense.fit(train, validation_data = valid, epochs = 3, batch_size=128,steps_per_epoch = num_training_samples \/\/ 128)","082b6e27":"test_ds = get_test_dataset(ordered=True) \ntest_images_ds = test_ds.map(lambda image, idnum: image)\npred1 = model_dense.predict(test_images_ds)\npred2 = model_IResNet2.predict(test_images_ds)","f798f829":"probabilities = (pred1+ pred2)\/2\npredictions = np.argmax(probabilities, axis=-1)","44b0ff27":"test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(num_testing_samples))).numpy().astype('U')\nsubmission = pd.DataFrame({'id':test_ids,\n                          'label':predictions})","8f554438":"submission.to_csv('submission.csv',index=False)","ad621e21":"#### If you liked the Notebook Please Upvote It !\n#### Thank You","f98772dc":"### Importing libraries"}}