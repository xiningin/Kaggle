{"cell_type":{"cb596a31":"code","7955ec1c":"code","f72085ba":"code","515be070":"code","4efdf72e":"code","a32d5fc9":"code","6b3c3ebb":"code","fe5e4dc9":"code","5509d5b0":"code","c2df31e5":"code","545bf527":"code","26357921":"code","b769ca29":"code","2ce554db":"code","403e657f":"code","b2c15d86":"code","a36185e6":"code","40534980":"code","cecc0c50":"code","61ca7cea":"code","97c209c3":"code","275ea7d5":"code","2856d9a0":"code","86a0b263":"code","7a269127":"code","5a43b189":"code","58535810":"code","0d472113":"code","d91dca44":"code","03148859":"code","7e0976d7":"code","e86e816c":"code","73f7ae18":"code","1cd999c3":"code","12d410fd":"code","56b68c2e":"code","0f6607f4":"code","c6d52608":"code","65791ccf":"code","d9d3b122":"code","30e961a0":"code","0b3e7e76":"code","97e72a2c":"code","a56c5054":"code","4461505e":"code","5f6d9b82":"code","bbacb8b5":"code","70c957db":"code","9a57f7a3":"code","75a7accf":"code","9e596667":"code","c73e66ce":"code","d918cd6f":"code","d1a7b6e1":"code","085b2ae8":"code","5941ca5d":"code","142cb05d":"code","fdee8b71":"code","3579323a":"code","bbee119b":"code","9b4839e3":"code","165d743d":"code","1fa9e91e":"code","3b9fdc8d":"code","61c0b156":"code","12e0aca7":"code","d977dbff":"code","d0ef6d2c":"code","8b2d4b17":"code","8b60254c":"code","2ac9c444":"code","385fbde2":"code","208a72ef":"code","80e4ca1d":"code","24db3e4f":"code","06be119c":"code","16d30d4b":"code","d3049abb":"code","08c6d92e":"code","ae0db508":"code","7c82ad5b":"code","e8616f78":"code","5adb859b":"code","443d6f70":"code","af40b01e":"code","eff9bc27":"code","511f9936":"code","c5aa3cb5":"code","8b80cd35":"code","0b26963d":"code","8bf91787":"code","b0e1f89d":"code","3663f195":"code","b4a9b541":"code","db254b19":"code","358c03d5":"code","01b792a4":"code","68b8342f":"code","1dda2bec":"code","0a1f7e9e":"code","1a5d83e2":"code","da3af2a7":"code","f9b5797f":"code","51dd6644":"code","228855dc":"code","2eadf80f":"code","a6899fa0":"code","31059721":"code","4350ac07":"code","07712e3a":"code","bb6d590f":"code","34b92685":"code","9d9e28d0":"code","647e8d86":"code","c633576a":"code","31682335":"code","a9be7238":"code","fa3d0c0b":"code","bed1344a":"code","749589a2":"code","c33cbe23":"code","d1564a3f":"code","37e6239e":"code","eb585200":"code","dfd1010d":"code","f50ccb4e":"markdown","28785dfa":"markdown","826d56f9":"markdown","bdaa67e6":"markdown","63709ed7":"markdown","659deb6b":"markdown","19ac3e54":"markdown","bef2a2bd":"markdown","a7450c6b":"markdown","36bb38c9":"markdown","fb8e663f":"markdown","d9db9638":"markdown","d9094ce3":"markdown","60be12fc":"markdown","e3b093ba":"markdown","e0d5f21c":"markdown","c89d278c":"markdown","760b23ea":"markdown","8df5502a":"markdown","c6e9cef4":"markdown","8b8c8407":"markdown","df8f0eb1":"markdown","1c92b623":"markdown","d4680e6a":"markdown","485e0eef":"markdown","bddbb7bd":"markdown","d1255142":"markdown","296175fe":"markdown","461db2be":"markdown","d5a38720":"markdown","3200a4bd":"markdown","f3875289":"markdown","6ce1386c":"markdown","16ae961a":"markdown","c5195c51":"markdown","c3294089":"markdown","212ae826":"markdown","1f81b532":"markdown","37d05dd2":"markdown","4db7dcb3":"markdown","3148c440":"markdown","426f0813":"markdown","11c36424":"markdown","997c4de6":"markdown","6f755c4b":"markdown","e8bce9a4":"markdown","62080927":"markdown","6833d7da":"markdown","a53930c4":"markdown","bb819fd4":"markdown","b7eaa494":"markdown","874082c0":"markdown","0792905d":"markdown","e70a9eef":"markdown","dd51ce63":"markdown","2ca715c6":"markdown","0ae7c8c5":"markdown","ef32085d":"markdown","30cbf542":"markdown","bd0ad97d":"markdown","8b56bf6e":"markdown","038bb04f":"markdown","d3d7d16a":"markdown","0c4b98d7":"markdown","e1603229":"markdown","13538c93":"markdown","c19651a8":"markdown","b6ae5322":"markdown","ee94a4ed":"markdown","fd6e93fa":"markdown"},"source":{"cb596a31":"import pandas as pd\n\nimport numpy as np\n\nimport scipy","7955ec1c":"from sklearn.linear_model import LogisticRegression\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.svm import SVC\n\nfrom sklearn.naive_bayes import GaussianNB","f72085ba":"from sklearn.ensemble import BaggingClassifier\n\nfrom sklearn.ensemble import AdaBoostClassifier\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.ensemble import RandomForestClassifier","515be070":"from sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import train_test_split,KFold\n\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n\nfrom imblearn.over_sampling import SMOTE\n\nfrom scipy.stats import skew,kurtosis,boxcox,boxcox_normmax","4efdf72e":"from sklearn import metrics\n\nfrom sklearn.metrics import accuracy_score,precision_score,roc_auc_score,f1_score,recall_score,auc,make_scorer\n\nfrom sklearn.metrics import confusion_matrix,classification_report","a32d5fc9":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nimport statsmodels.api as sm\n\nimport seaborn as sns","6b3c3ebb":"df = pd.read_csv('..\/input\/bank-marketing-campaigns-dataset\/bank-additional-full.csv',sep=';')","fe5e4dc9":"df","5509d5b0":"df[df.duplicated()]","c2df31e5":"df.drop_duplicates(inplace=True)","545bf527":"df.reset_index(inplace=True)","26357921":"df.drop('index',axis=1,inplace=True)","b769ca29":"df","2ce554db":"df.isnull().sum()","403e657f":"df.info()","b2c15d86":"df.describe()","a36185e6":"df.columns","40534980":"df","cecc0c50":"plt.figure(figsize=(8,6))\nsns.distplot(df.age)\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.title('Distribution of age')","61ca7cea":"plt.figure(figsize=(8,6))\nsns.boxplot(df.age)\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.title('Boxplot - Outliers Detection')","97c209c3":"import scipy #Scientific Python\nprint('Skewness',scipy.stats.skew(df.age))","275ea7d5":"import scipy #Scientific Python\nprint('Kurtosis',scipy.stats.kurtosis(df.age))","2856d9a0":"from scipy.stats import boxcox,boxcox_normmax","86a0b263":"df.age = boxcox(df.age,boxcox_normmax(df.age))","7a269127":"plt.figure(figsize=(8,6))\nsns.distplot(df.age)\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.title('Distribution of age - After Boxcox transformation')","5a43b189":"plt.figure(figsize=(8,6))\nsns.boxplot(df.age)\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.title('Boxplot for Outliers Detection - After Boxcox transformation')","58535810":"print('Skewness after Boxcox',scipy.stats.skew(df.age))\nprint('Kurtosis after Boxcox',scipy.stats.kurtosis(df.age))\n","0d472113":"df.job.value_counts()","d91dca44":"df.job.unique()","03148859":"from sklearn.preprocessing import LabelEncoder\nl_enc = LabelEncoder()","7e0976d7":"df.job = l_enc.fit_transform(df.job)","e86e816c":"df.job.unique()","73f7ae18":"print(df.marital.unique())","1cd999c3":"print(sorted(df.marital.unique()))","12d410fd":"df.marital = df.marital.replace(['divorced', 'married', 'single', 'unknown'],[0,1,2,3])","56b68c2e":"df.education.unique()","0f6607f4":"print(sorted(df.education.unique()))","c6d52608":"df.education = df.education.replace(['basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'illiterate', 'professional.course', 'university.degree', 'unknown'],\n                                    [0,1,2,3,4,5,6,7])","65791ccf":"df.education.unique()","d9d3b122":"df.default.unique()","30e961a0":"print(sorted(df.default.unique()))","0b3e7e76":"df.default = df.default.replace(['no', 'unknown', 'yes'],[0,1,2])","97e72a2c":"df.housing = df.housing.replace(['no', 'unknown', 'yes'],[0,1,2])","a56c5054":"df.loan = df.loan.replace(['no', 'unknown', 'yes'],[0,1,2])","4461505e":"df.contact = df.contact.replace(['telephone', 'cellular'],[1,0])","5f6d9b82":"print(sorted(df.month.unique()))","bbacb8b5":"df.month = df.month.replace(['apr', 'aug', 'dec', 'jul', 'jun', 'mar', 'may', 'nov', 'oct', 'sep'],range(0,10))","70c957db":"print(sorted(df.day_of_week.unique()))","9a57f7a3":"df.day_of_week = df.day_of_week.replace(['fri', 'mon', 'thu', 'tue', 'wed'],[0,1,2,3,4])","75a7accf":"print(sorted(df.poutcome.unique()))","9e596667":"df.poutcome = df.poutcome.replace(['failure', 'nonexistent', 'success'],[0,1,2])","c73e66ce":"df.y.unique()","d918cd6f":"df.y = df.y.replace(['no', 'yes'],[0,1])","d1a7b6e1":"df.sample(3)","085b2ae8":"df.y.value_counts()","5941ca5d":"sns.countplot(df.y)","142cb05d":"plt.figure(figsize=(14,12))\nsns.heatmap(df.corr(),\n            annot=True,\n            linewidth=.5,\n            center = 0,\n            cbar=False,\n            cmap='YlGnBu')\nplt.show()","fdee8b71":"df = df.drop(['marital','contact','pdays','previous', 'emp.var.rate', 'cons.price.idx',\n       'cons.conf.idx', 'euribor3m', 'nr.employed','duration'],axis=1)","3579323a":"df","bbee119b":"X = df.loc[:,df.columns != 'y']\ny = df.loc[:,df.columns == 'y']","9b4839e3":"X","165d743d":"y","1fa9e91e":"import statsmodels.api as sm\n\nols = sm.OLS(y,X).fit()\n\nprint(ols.summary2())","3b9fdc8d":"df = df.drop(['age','loan','month'],axis =1)","61c0b156":"X = df.loc[:,df.columns != 'y']\ny = df.loc[:,df.columns == 'y']","12e0aca7":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","d977dbff":"y_train.value_counts()","d0ef6d2c":"from imblearn.over_sampling import SMOTE\n\nos = SMOTE(random_state = 2)\n\nos_X, os_y = os.fit_resample(X_train,y_train)","8b2d4b17":"os_y.value_counts()","8b60254c":"from sklearn.linear_model import LogisticRegression","2ac9c444":"LR = LogisticRegression()\n\n# Train Your Model\nLR.fit(os_X,os_y)\n\n# Predict the model\nLR_predicted_y = LR.predict(X_test)","385fbde2":"from sklearn.metrics import accuracy_score,confusion_matrix,classification_report","208a72ef":"# Confusion Matrix\nLR_CM = confusion_matrix(y_test,LR_predicted_y)\nprint(LR_CM)\n\n# Accuracy Score\nAccuracy = round(accuracy_score(y_test,LR_predicted_y)*100,2)\nprint('LR_Accuracy is ', Accuracy)","80e4ca1d":"# Classification Report\nprint(classification_report(y_test,LR_predicted_y))","24db3e4f":"from sklearn.ensemble import BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier,RandomForestClassifier","06be119c":"# Bagging Classifier Technique\nLR_Bagged = BaggingClassifier(base_estimator=LR,random_state=0)\n\n# Train your model\nLR_Bagged.fit(os_X,os_y)\n\n# Predict the model\nLR_Bagged_predicted_y = LR_Bagged.predict(X_test)","16d30d4b":"# Confusion Matrix\nLR_Bagged_CM = confusion_matrix(y_test,LR_Bagged_predicted_y)\nprint(LR_Bagged_CM)\n\n# Accuracy Score\nLR_Bagged_Accuracy = round(accuracy_score(y_test,LR_Bagged_predicted_y)*100,2)\nprint('LR_Bagged_Accuracy is ', LR_Bagged_Accuracy)\n\n# Classification Report\nprint(classification_report(y_test,LR_Bagged_predicted_y))","d3049abb":"# Boosting Classifier Technique\nLR_Ada_Boost = AdaBoostClassifier(base_estimator=LR,random_state=0)\n\n# Train your model\nLR_Ada_Boost.fit(os_X,os_y)\n\n# Predict the model\nLR_Adaboost_predicted_y = LR_Ada_Boost.predict(X_test)","08c6d92e":"# Confusion Matrix\nLR_Adaboost_CM = confusion_matrix(y_test,LR_Adaboost_predicted_y)\nprint(LR_Adaboost_CM)\n\n# Accuracy Score\nLR_Adaboost_Accuracy = round(accuracy_score(y_test,LR_Adaboost_predicted_y)*100,2)\nprint('LR_Adaboost_Accuracy is ', LR_Adaboost_Accuracy)\n\n# Classification Report\nprint(classification_report(y_test,LR_Adaboost_predicted_y))","ae0db508":"param = {'n_estimators': np.arange(1,10)}\nkfold = KFold(n_splits=5, shuffle=True, random_state=0)\n\n# LR_Bagged_GS = GridSearchCV(LR_Bagged,param, cv= kfold ,scoring= accuracy_score) # Taking more time consumption, went through RandomisedSearchCV\n# LR_Bagged_GS.fit(X,y)\n\nLR_Bagged_RS = RandomizedSearchCV(LR_Bagged,param, cv= kfold ,scoring= accuracy_score)\nLR_Bagged_RS.fit(X,y)","7c82ad5b":"# print(LR_Bagged_GS.best_params_)\nprint(LR_Bagged_RS.best_params_)\n# LR_RS_n_estimators = LR_Bagged_RS['n_estimators']","e8616f78":"LR_Bagged_Kfold = BaggingClassifier(base_estimator=LR,n_estimators=1,random_state=0)\n\n# Train your model\nLR_Bagged_Kfold.fit(os_X,os_y)\n\n# Predict your model\nLR_Bagged_Kfold_predicted_y = LR_Bagged_Kfold.predict(X_test)","5adb859b":"# Confusion Matrix\nLR_Bagged_Kfold_CM = confusion_matrix(y_test,LR_Bagged_Kfold_predicted_y)\nprint(LR_Bagged_Kfold_CM)\n\n# Accuracy Score\nLR_Bagged_Kfold_Accuracy = round(accuracy_score(y_test,LR_Bagged_Kfold_predicted_y)*100,2)\nprint('LR_Bagged_Kfold_Accuracy is ', LR_Bagged_Kfold_Accuracy)\n\n# Classification Report\nprint(classification_report(y_test,LR_Bagged_Kfold_predicted_y))","443d6f70":"print(4506\/(4506+377))\nprint(1057\/(1057+6413))","af40b01e":"from sklearn.tree import DecisionTreeClassifier","eff9bc27":"DT_Gini = DecisionTreeClassifier() # Fully growned tree which has more bias and variance error\n\n# Train the model\nDT_Gini.fit(os_X,os_y)\n\n# Predict the model\nDT_Gini_predicted_y = DT_Gini.predict(X_test)\n","511f9936":"# Confusion Matrix\nDT_Gini_CM = confusion_matrix(y_test,DT_Gini_predicted_y)\nprint(DT_Gini_CM)\n\n# Accuracy Score\nDT_Gini_Accuracy_Score = round(accuracy_score(y_test,DT_Gini_predicted_y)*100,2)\nprint('DT_Gini_Accuracy_Score is ', DT_Gini_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,DT_Gini_predicted_y))","c5aa3cb5":"DT_Gini_Semi_Grown = DecisionTreeClassifier(max_depth=3,random_state=0)\n\n# Train the model\nDT_Gini_Semi_Grown.fit(os_X,os_y)\n\n# Predict the model\nDT_Gini_Semi_Grown_predicted_y = DT_Gini_Semi_Grown.predict(X_test)","8b80cd35":"# Confusion Matrix\nDT_Gini_Semi_Grown_CM = confusion_matrix(y_test,DT_Gini_Semi_Grown_predicted_y)\nprint(DT_Gini_Semi_Grown_CM)\n\n# Accuracy Score\nDT_Gini_Semi_Grown_Accuracy_Score = round(accuracy_score(y_test,DT_Gini_Semi_Grown_predicted_y)*100,2)\nprint('DT_Gini_Semi_Grown_Accuracy_Score is ', DT_Gini_Semi_Grown_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,DT_Gini_Semi_Grown_predicted_y))","0b26963d":"DT_Entropy_Semi_Grown = DecisionTreeClassifier(criterion='entropy',max_depth=3,random_state=0)\n\n# Train the model\nDT_Entropy_Semi_Grown.fit(os_X,os_y)\n\n# Predict the model\nDT_Entropy_Semi_Grown_predicted_y = DT_Entropy_Semi_Grown.predict(X_test)","8bf91787":"# Confusion Matrix\nDT_Entropy_Semi_Grown_CM = confusion_matrix(y_test,DT_Entropy_Semi_Grown_predicted_y)\nprint(DT_Entropy_Semi_Grown_CM)\n\n# Accuracy Score\nDT_Entropy_Semi_Grown_Accuracy_Score = round(accuracy_score(y_test,DT_Entropy_Semi_Grown_predicted_y)*100,2)\nprint('DT_Entropy_Semi_Grown_Accuracy_Score is ', DT_Entropy_Semi_Grown_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,DT_Entropy_Semi_Grown_predicted_y))","b0e1f89d":"DT_Bagged = BaggingClassifier(base_estimator=DT_Gini_Semi_Grown,n_estimators=1)\n\nDT_Bagged.fit(os_X,os_y)\n\nDT_Bagged_predicted_y = DT_Bagged.predict(X_test)","3663f195":"# Confusion Matrix\nDT_Bagged_CM = confusion_matrix(y_test,DT_Bagged_predicted_y)\nprint(DT_Bagged_CM)\n\n# Accuracy Score\nDT_Bagged_Accuracy_Score = round(accuracy_score(y_test,DT_Bagged_predicted_y)*100,2)\nprint('DT_Bagged_Accuracy_Score is ', DT_Bagged_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,DT_Bagged_predicted_y))","b4a9b541":"DT_Adaboost = AdaBoostClassifier(base_estimator=DT_Gini_Semi_Grown,n_estimators=1)\n\nDT_Adaboost.fit(os_X,os_y)\n\nDT_Adaboost_predicted_y = DT_Adaboost.predict(X_test)","db254b19":"# Confusion Matrix\nDT_Adaboost_CM = confusion_matrix(y_test,DT_Adaboost_predicted_y)\nprint(DT_Adaboost_CM)\n\n# Accuracy Score\nDT_Adaboost_Accuracy_Score = round(accuracy_score(y_test,DT_Adaboost_predicted_y)*100,2)\nprint('DT_Adaboost_Accuracy_Score is ', DT_Adaboost_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,DT_Adaboost_predicted_y))","358c03d5":"DT_Gboost = GradientBoostingClassifier(n_estimators=1)\n\nDT_Gboost.fit(os_X,os_y)\n\nDT_Gboost_predicted_y = DT_Gboost.predict(X_test)","01b792a4":"# Confusion Matrix\nDT_Gboost_CM = confusion_matrix(y_test,DT_Gboost_predicted_y)\nprint(DT_Gboost_CM)\n\n# Accuracy Score\nDT_Gboost_Accuracy_Score = round(accuracy_score(y_test,DT_Gboost_predicted_y)*100,2)\nprint('DT_Gboost_Accuracy_Score is ', DT_Gboost_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,DT_Gboost_predicted_y))","68b8342f":"from sklearn.ensemble import RandomForestClassifier","1dda2bec":"RF_Gini = RandomForestClassifier(n_estimators=100,criterion='gini',random_state=0)\n\nRF_Gini.fit(os_X,os_y)\n\nRF_Gini_predicted_y = RF_Gini.predict(X_test)","0a1f7e9e":"# Confusion Matrix\nRF_Gini_CM = confusion_matrix(y_test,RF_Gini_predicted_y)\nprint(RF_Gini_CM)\n\n# Accuracy Score\nRF_Gini_Accuracy_Score = round(accuracy_score(y_test,RF_Gini_predicted_y)*100,2)\nprint('RF_Gini_Accuracy_Score is ', RF_Gini_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,RF_Gini_predicted_y))","1a5d83e2":"RF_Entropy = RandomForestClassifier(n_estimators=100,criterion='entropy',random_state=0)\n\nRF_Entropy.fit(os_X,os_y)\n\nRF_Entropy_predicted_y = RF_Entropy.predict(X_test)","da3af2a7":"# Confusion Matrix\nRF_Entropy_CM = confusion_matrix(y_test,RF_Entropy_predicted_y)\nprint(RF_Entropy_CM)\n\n# Accuracy Score\nRF_Entropy_Accuracy_Score = round(accuracy_score(y_test,RF_Entropy_predicted_y)*100,2)\nprint('RF_Entropy_Accuracy_Score is ', RF_Entropy_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,RF_Entropy_predicted_y))","f9b5797f":"param = {'n_estimators': np.arange(1,10)}\nkfold = KFold(n_splits=5, shuffle=True, random_state=0)\n\nRF_RS = RandomizedSearchCV(RF_Gini,param, cv= kfold ,scoring= accuracy_score)\nRF_RS.fit(X,y)","51dd6644":"print(RF_RS.best_params_)\nprint(RF_RS.best_estimator_)","228855dc":"RF_RS_Kfold = BaggingClassifier(base_estimator=RF_Gini,n_estimators=1,random_state=0)\n\n# Train your model\nRF_RS_Kfold.fit(os_X,os_y)\n\n# Predict your model\nRF_RS_Kfold_predicted_y = RF_RS_Kfold.predict(X_test)","2eadf80f":"# Confusion Matrix\nRF_RS_Kfold_CM = confusion_matrix(y_test,RF_RS_Kfold_predicted_y)\nprint(RF_RS_Kfold_CM)\n\n# Accuracy Score\nRF_RS_Kfold_Accuracy_Score = round(accuracy_score(y_test,RF_RS_Kfold_predicted_y)*100,2)\nprint('RF_RS_Kfold_Accuracy_Score is ', RF_RS_Kfold_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,RF_RS_Kfold_predicted_y))","a6899fa0":"RF_Adaboost = AdaBoostClassifier(base_estimator=RF_Gini,n_estimators=1,random_state=0)\n\nRF_Adaboost.fit(os_X,os_y)\n\nRF_Adaboost_predict_y = RF_Adaboost.predict(X_test)","31059721":"# Confusion Matrix\nRF_Adaboost_CM = confusion_matrix(y_test,RF_Adaboost_predict_y)\nprint(RF_Adaboost_CM)\n\n# Accuracy Score\nRF_Adaboost_Accuracy_Score = round(accuracy_score(y_test,RF_Adaboost_predict_y)*100,2)\nprint('RF_Adaboost_Accuracy_Score is ', RF_Adaboost_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,RF_Adaboost_predict_y))","4350ac07":"RF_Gboost = GradientBoostingClassifier(n_estimators=1)\n\nRF_Gboost.fit(os_X,os_y)\n\nRF_Gboost_predicted_y = RF_Gboost.predict(X_test)","07712e3a":"# Confusion Matrix\nRF_Gboost_CM = confusion_matrix(y_test,RF_Gboost_predicted_y)\nprint(RF_Gboost_CM)\n\n# Accuracy Score\nRF_Gboost_Accuracy_Score = round(accuracy_score(y_test,RF_Gboost_predicted_y)*100,2)\nprint('RF_Gboost_Accuracy_Score is ', RF_Gboost_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,RF_Gboost_predicted_y))","bb6d590f":"from sklearn.neighbors import KNeighborsClassifier","34b92685":"KNN = KNeighborsClassifier(n_neighbors=2)\n\nKNN.fit(os_X,os_y)\n\nKNN_predicted_y = KNN.predict(X_test)","9d9e28d0":"# Confusion Matrix\nKNN_CM = confusion_matrix(y_test,KNN_predicted_y)\nprint(KNN_CM)\n\n# Accuracy Score\nKNN_Accuracy_Score = round(accuracy_score(y_test,KNN_predicted_y)*100,2)\nprint('KNN_Accuracy_Score is ', KNN_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,KNN_predicted_y))","647e8d86":"KNN_Bagged = BaggingClassifier(base_estimator=KNN,n_estimators=1,random_state=0)\n\nKNN_Bagged.fit(os_X,os_y)\n\nKNN_Bagged_predicted_y = KNN_Bagged.predict(X_test)","c633576a":"# Confusion Matrix\nKNN_Bagged_CM = confusion_matrix(y_test,KNN_Bagged_predicted_y)\nprint(KNN_Bagged_CM)\n\n# Accuracy Score\nKNN_Bagged_Accuracy_Score = round(accuracy_score(y_test,KNN_Bagged_predicted_y)*100,2)\nprint('KNN_Bagged_Accuracy_Score is ', KNN_Bagged_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,KNN_Bagged_predicted_y))","31682335":"param = {'n_neighbors':np.arange(1,50),\n         'weights':['uniform','distance']}\nKNN_RS = RandomizedSearchCV(KNN,param,cv=5,scoring='roc_auc')\n\nKNN_RS.fit(X,y)","a9be7238":"KNN_RS.best_params_","fa3d0c0b":"KNN_RS.best_params_\nKNN_RS_params = KNN_RS.best_params_\n\nknn_weights = KNN_RS_params['weights']\nknn_n_neighbors = KNN_RS_params['n_neighbors']\n\nKNN1 = KNeighborsClassifier(n_neighbors=knn_n_neighbors, weights=knn_weights)\n\nKNN1.fit(os_X,os_y)\n\nKNN1_predicted_y = KNN1.predict(X_test)","bed1344a":"# Confusion Matrix\nKNN1_CM = confusion_matrix(y_test,KNN1_predicted_y)\nprint(KNN1_CM)\n\n# Accuracy Score\nKNN1_Accuracy_Score = round(accuracy_score(y_test,KNN1_predicted_y)*100,2)\nprint('KNN1_Accuracy_Score is ', KNN1_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,KNN1_predicted_y))","749589a2":"from sklearn.svm import SVC","c33cbe23":"SVM = SVC()\n\nSVM.fit(os_X,os_y)\n\nSVM_predicted_y = SVM.predict(X_test)","d1564a3f":"# Confusion Matrix\nSVM_CM = confusion_matrix(y_test,SVM_predicted_y)\nprint(SVM_CM)\n\n# Accuracy Score\nSVM_Accuracy_Score = round(accuracy_score(y_test,SVM_predicted_y)*100,2)\nprint('SVM_Accuracy_Score is ', SVM_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,SVM_predicted_y))","37e6239e":"from sklearn.naive_bayes import GaussianNB","eb585200":"NB = GaussianNB()\n\nNB.fit(os_X,os_y)\n\nNB_predicted_y = NB.predict(X_test)","dfd1010d":"# Confusion Matrix\nNB_CM = confusion_matrix(y_test,NB_predicted_y)\nprint(NB_CM)\n\n# Accuracy Score\nNB_Accuracy_Score = round(accuracy_score(y_test,NB_predicted_y)*100,2)\nprint('NB_Accuracy_Score is ', NB_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,NB_predicted_y))","f50ccb4e":"#### Default:-","28785dfa":"## Model 2:- Decision Tree","826d56f9":"#### Bank marketing campaigns dataset analysis # Opening a Term Deposit. It is a dataset that describing Portugal bank marketing campaigns results. Conducted campaigns were based mostly on direct phone calls, offering bank client to place a term deposit. If after all marking afforts client had agreed to place deposit - target variable marked 'yes', otherwise 'no'\n\n#### To identify potential customers who opened term deposit in their bank.","bdaa67e6":"#### Job:-","63709ed7":"#### Note : Finally I choose the model GaussianNB as best model to identify potential customers who opening the term deposit. Even though the model has very low accuracy but the FPR rate is very less.\n####        For better Accuracy model, we can take KNN model as 75.58 % Accuracy Score.[](http:\/\/)","659deb6b":"#### Data is highly imbalanced, So apply SMOTE on your trining datset.\n#### Note:- Dont apply SMOTE on testing data because its our original dataset which needs to be predicted\n#### Over Sampling the Minority Class - by SMOTE (Synthetic Minority Over Sampling Technique)","19ac3e54":"#### After Boxcox Transform:-","bef2a2bd":"## Data Preprocessing or Data Cleaning:-","a7450c6b":"# Bank marketing campaigns dataset - Opening Term Deposit","36bb38c9":"## Algorithms Used:-\n\n1.     Logistic Regression\n           1.1 LR Bagging Classifier\n           1.2 LR Adaboost Classifier\n           1.3 LR Kfold Bagging Classifier\n2.     Decision Tree\n           2.1 Decision Tree - Gini - Regularized\n           2.2 Decision Tree - Entropy - Regularized\n           2.3 Decision Tree - Bagging Classifier\n           2.4 Decision Tree - Adaboost Classifier\n           2.5 Decision Tree - Gradient Classifier\n3.     Random Forest\n           3.1 Random Forest - Entropy - Regularized\n           3.2 Random Forest - Kfold Bagging Classifier\n           3.3 Random Forest - Adaboost Classifier\n           3.4 Random Forest - Gradient Classifier\n4.     KNN\n           4.1 KNN - Bagging Classifier\n           4.2 KNN - Parameter Optimization\n5.     SVM\n6.     Naive Bayes - GausianNB","fb8e663f":"### Skewness & Kurtosis\n* #### skewness = 0 : normally distributed.\n* #### skewness > 0 : more weight in the left tail of the distribution.\n* #### skewness < 0 : more weight in the right tail of the distribution.\n* #### Kurtosis = 3 : normally distributed - Mesokurtic\n* #### Kurtosis > 3 : normally distributed - Leptokurtic\n* #### Kurtosis < 3 : normally distributed - Platykurtic","d9db9638":"#### Note :- Dataset is highly imbalanced so we need to use below technique to overcome this problem after the Train Test Split\n#### SMOTE - SYNTHATIC MINORITY OF OVER SAMPLING TECHNIQUE","d9094ce3":"#### 2.3 Decision Tree - Bagging Classifier","60be12fc":"### Stats Check:-","e3b093ba":"#### Both the Skewness & Kurtosis are reduced after Boxcox Transformation.\n\n* Before Boxcox:-\n    *     Skewness 0.7845316793906337\n    *     Kurtosis 0.7908715485573286\n* After Boxcox :-\n    *     Skewness -0.006389818305811041\n    *     Kurtosis -0.38321858182694646","e0d5f21c":"## To check class Imbalanced or not.","c89d278c":"#### Housing:-","760b23ea":"### To Identify Significant Variable:-","8df5502a":"#### y - Output Variable or Dependent Variable:-","c6e9cef4":"#### Now the outliers are removed after the boxcox technique","8b8c8407":"### Skewness & Kurtosis after Boxcox Transformation","df8f0eb1":"#### 2.4 Decision Tree - Adaboost Classifier","1c92b623":"### Columns Check:-","d4680e6a":"## Import dataset","485e0eef":"#### Month:-","bddbb7bd":"## Packages used:-","d1255142":"### Remove duplicates:-","296175fe":"### Reseting Index:-","461db2be":"#### Day_of_week:-","d5a38720":"#### Below columns are highly correlated with another input columns except y column, so dropping the same.","3200a4bd":"### Datatype Check:-","f3875289":"### Convert all categorical variable into numerical structure","6ce1386c":"#### Loan:-","16ae961a":"#### 1.4 Parameter Optimization\n*     GridSearchCV\n*     RandomisedSearchCV","c5195c51":"#### 4.2 KNN - Parameter Optimization ","c3294089":"#### 2.4 Decision Tree - Gradient Boost Classifier","212ae826":"#### 3.4 Random Forest - Gradientboost Classifier","1f81b532":"### Algorithms Used:-\n*     Logistic Regression\n*     Decision Tree\n*     Random Forest\n*     KNN\n    ","37d05dd2":"#### 2.2 Decision Tree - Entropy Method - Regularized","4db7dcb3":"## Model 5:- SVM","3148c440":"#### 4.1 KNN - Bagged Classifier","426f0813":"#### 1.3 LR - Boosting Classifier","11c36424":"## Model 4:- KNN","997c4de6":"#### Now both the classes are balanced equally :)","6f755c4b":"#### Difine X & y variables:-","e8bce9a4":"**Note :- Its not following the normal distribution even after doing boxcox transformation. Better we can drop this column.**","62080927":"#### 3.1 Random Forest - Entropy Method","6833d7da":"#### Note : P-value should be less than or equal to 0.05\n#### From the above result, we are removing the age , loan, month coulumns,because of its P-value > 0.05","a53930c4":"#### 1.2 LR - Bagging Classifier","bb819fd4":"#### Education:-","b7eaa494":"#### Correlation Graph:- Check Multicolinearity\n*     Correlation between 2 input variables should be very low - Weak Correlation\n*     Correlation between input & output variables should be very high - Strong Correlation\n\nNote: We can straight away remove those input columns which is having more correlated.","874082c0":"#### 3.3 Random Forest - Adaboost Classifier","0792905d":"## To check class Imbalanced or not:-","e70a9eef":"## Model 3:- Random Foresst","dd51ce63":"#### 3.2 Random Forest - Parameter Optimization","2ca715c6":"## Problem Statement","0ae7c8c5":"### OLS Method (Oridinary Least Square) - To Identify Significant Variable\n### p-value <= 0.05","ef32085d":"#### 2.1 Decision Tree - Regularized","30cbf542":"## Model 1 :- Logistic Regression","bd0ad97d":"#### 1.1 Logistic Regression","8b56bf6e":"#### Contact:-","038bb04f":"#### Marital:-","d3d7d16a":"## Model 6:- Naive Bias","0c4b98d7":"#### Poutcome:-","e1603229":"**Outliers detected, so we do boxcox transformation**","13538c93":"### Boxcox Transformation Technique:-","c19651a8":"#### Age:-\n* Check Outliers ,Skewness or Kurtosis detected or not.\n* Outliers - Data points deviates significantly than other data points\n            - Data points which falls long way than other data points\nNote : If any Outliers,Skewness or Kurtosis detected, then do boxcox transformation            ","b6ae5322":"### Check duplicates:-","ee94a4ed":"**Its deviate slightly at right side.**\nIt should follow the normal distrubution","fd6e93fa":"### Null Check:-"}}