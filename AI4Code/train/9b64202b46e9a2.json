{"cell_type":{"7b357b25":"code","f1b83919":"code","e643bab7":"code","35fcdda5":"code","cc39fa2c":"code","f42cdb66":"code","b19653b0":"code","52c0c49d":"code","fbf240ae":"code","e61b23cf":"code","956402c9":"code","ea7192ee":"code","2fc1d8e9":"code","21336ceb":"code","c18bb0b7":"code","751c5902":"code","3234afe7":"code","81c5aa8e":"code","b7ab90c8":"code","99a63901":"code","827c3ecc":"code","5b7d8d70":"code","f7e1a53c":"code","d597a03b":"code","e496e107":"code","1a578281":"code","5b5946eb":"code","88b9a00b":"code","1f003011":"code","c627dbc8":"code","af474305":"code","86bb2a19":"code","9fe161f7":"code","7cfc6502":"code","1ce55123":"code","df5afa8a":"code","9b03b825":"code","d3290f42":"code","6f172923":"code","86d4b5c2":"code","015e3fbd":"code","c7311ca2":"code","c0c69be4":"code","32a3f6db":"code","33b88f9c":"code","2c66aefc":"code","919d9770":"code","100d41ea":"code","e1570f6e":"code","7b0a4120":"code","42a5beec":"code","83ef5380":"code","b3acdc07":"code","83423e4e":"code","d4e0712c":"code","f78c9787":"code","0652bab5":"code","e3f55389":"code","383ea9a7":"code","b2451b4c":"code","b7a422f1":"code","bacc0ab8":"code","1ffce795":"code","3d0b47e7":"code","fc21c2a7":"code","d1c5b381":"code","767832ce":"code","905fa6ba":"code","d2f9d8d0":"code","aa446e64":"code","87249e68":"code","6b643453":"code","b48e169a":"code","d2811a0a":"code","3c8a8d8a":"code","e0b0dd16":"code","033adaf9":"code","250a1cef":"code","b6b40fe5":"code","4eff00a7":"code","6c8f56cd":"code","e6f1f117":"code","4848d66f":"code","f6710545":"code","95ecbe29":"code","5beafb9c":"code","8f3a61e4":"code","149284e6":"markdown","8e6cb074":"markdown","7ede8c92":"markdown"},"source":{"7b357b25":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f1b83919":"pd.set_option('display.max_row',111)\npd.set_option('display.max_column',111)","e643bab7":"#read data\ndata = pd.read_excel('\/kaggle\/input\/covid19\/dataset.xlsx')\ndata.head()","35fcdda5":"df=data.copy()\nprint(f' Le data set contient {df.shape[0]} observations et {df.shape[1]} features')\n","cc39fa2c":"df.dtypes","f42cdb66":"df.dtypes.value_counts()#.plot.pie() ","b19653b0":"sns.heatmap(df.isna(),cbar=False)","52c0c49d":"#data .info()\n(df.isna().sum()\/df.shape[0]).sort_values(ascending=True)","fbf240ae":"df=df[df.columns[df.isna().sum()\/df.shape[0]<0.9]]\ndf.head()","e61b23cf":"sns.heatmap(df.isna(),cbar=False)","956402c9":"df=df.drop('Patient ID',axis=1)\ndf.head()","ea7192ee":"#visualise the target variable\ndf['SARS-Cov-2 exam result'].value_counts(normalize=True)","2fc1d8e9":"#analysis of  continuous variables\nfor col in df.select_dtypes('float'):\n    plt.figure()\n    sns.distplot(df[col])","21336ceb":"plt.figure()\nsns.distplot(df['Patient age quantile'])","c18bb0b7":"df['Patient age quantile'].value_counts()","751c5902":"#qualiltative variable\nfor col in df.select_dtypes('object'):\n    print(f'{col :-<20},{df[col].unique()}')\n","3234afe7":"#qualiltative variable\nfor col in df.select_dtypes('object'):\n    plt.figure()\n    df[col].value_counts().plot.pie() ","81c5aa8e":"#create positive and neagative subsets\npositive_df=df[df['SARS-Cov-2 exam result']=='positive']\nnegative_df=df[df['SARS-Cov-2 exam result']=='negative']","b7ab90c8":"#create viral and blood subsets\nmissing=df.isna().sum()\/df.shape[0]\n","99a63901":"viral_cols=df.columns[(missing<0.88)&(missing>0.75)]\nblood_dcols=df.columns[(missing<0.9)&(missing>0.88)]         ","827c3ecc":"#relationship between blood\/target\nfor col in blood_dcols:\n    plt.figure()\n    sns.distplot(positive_df[col], label='positive')\n    sns.distplot(negative_df[col], label='negative')\n    plt.legend()","5b7d8d70":"#relationship between target\/age \nsns.countplot(x='Patient age quantile',hue='SARS-Cov-2 exam result',data=df)","f7e1a53c":"#relationship between viral variable\/target\nfor col in viral_cols:\n    plt.figure()\n    sns.heatmap(pd.crosstab(df['SARS-Cov-2 exam result'],df[col]),annot=True,fmt='d')\n    ","d597a03b":"#relationship between blood\/blood\nsns.pairplot(df[blood_dcols])","e496e107":"sns.heatmap(df[blood_dcols].corr())","1a578281":"sns.clustermap(df[blood_dcols].corr())","5b5946eb":"#relationship between blood\/target\nfor col in blood_dcols:\n    plt.figure()\n    sns.lmplot(x='Patient age quantile',y=col, hue='SARS-Cov-2 exam result',data=df)","88b9a00b":"df.corr()['Patient age quantile'].sort_values()","1f003011":"pd.crosstab(df['Influenza A, rapid test'],df['Influenza A'])","c627dbc8":"pd.crosstab(df['Influenza B, rapid test'],df['Influenza B'])","af474305":"#create variable is sick to visualize patients who are sick or not\ndf['is_sick']=np.sum(df[viral_cols[:-2]]=='detected', axis=1)>=1\n","86bb2a19":"df.head()","9fe161f7":"#create positive and neagative subsets\npositive_is_sick=df[df['is_sick']==True]\nnegative_is_sick=df[df['is_sick']==False]","7cfc6502":"#relationship between blood\/is_sick\nfor col in blood_dcols:\n    plt.figure()\n    sns.distplot(positive_is_sick[col], label='positive')\n    sns.distplot(negative_is_sick[col], label='negative')\n    plt.legend()","1ce55123":"def addmited(df):\n    if df['Patient addmited to regular ward (1=yes, 0=no)']==1 :\n        return 'addmited'\n    if df['Patient addmited to semi-intensive unit (1=yes, 0=no)']==1 :\n        return 'semi-intensive'\n    if df['Patient addmited to intensive care unit (1=yes, 0=no)']==1 :\n        return 'intensive care unit'\n    else: \n        return 'NAN'","df5afa8a":"df['statut']=df.apply(addmited, axis=1)","9b03b825":"#relationship between blood\/addmited_patient\nfor col in blood_dcols:\n    plt.figure()\n    for cat in df['statut'].unique():\n        sns.distplot(df[df['statut']==cat][col], label=cat)\n        plt.legend()","d3290f42":"#analysis of Nan values\ndf[blood_dcols].count()","6f172923":"df[viral_cols[:-2]].count()","86d4b5c2":"df.dropna().count()","015e3fbd":"#if we use only viral_cols in our dataset ,positive=8% \ndf1=df[viral_cols[:-2]]\ndf1['covid']=df['SARS-Cov-2 exam result']\ndf1.dropna()['covid'].value_counts(normalize=True)","c7311ca2":"#positive=13%\ndf2=df[blood_dcols]\ndf2['covid']=df['SARS-Cov-2 exam result']\ndf2.dropna()['covid'].value_counts(normalize=True)","c0c69be4":"#use T-test \nfrom scipy.stats import ttest_ind\n","32a3f6db":"positive_df.shape","33b88f9c":"negative_df.shape","2c66aefc":"negative_df.sample(positive_df.shape[0])","919d9770":"balanced_neg=negative_df.sample(positive_df.shape[0])\ndef t_test(col):\n    alpha =0.02\n    stat,p=ttest_ind(balanced_neg[col].dropna(),positive_df[col].dropna())\n    if p<alpha:\n        return 'H0 rejected'\n    else:\n        return 0\n    ","100d41ea":"for col in blood_dcols:\n    print(f'{col:-<50}{t_test(col)}')","e1570f6e":"#create our dataframe to preprocessing\ndf=data.copy()\nmissing_rate = df.isna().sum()\/df.shape[0]\nblood_columns = list(df.columns[(missing_rate < 0.9) & (missing_rate >0.88)])\nviral_columns = list(df.columns[(missing_rate < 0.80) & (missing_rate > 0.75)])\nkey_columns = ['Patient age quantile', 'SARS-Cov-2 exam result']\n","7b0a4120":"df = df[key_columns + blood_columns + viral_columns]\ndf.head()","42a5beec":"#train_test\nfrom sklearn.model_selection import train_test_split\ntrainset,testset=train_test_split(df,test_size=0.2,random_state=0)","83ef5380":"trainset['SARS-Cov-2 exam result'].value_counts()","b3acdc07":"testset['SARS-Cov-2 exam result'].value_counts()","83423e4e":"#encoding\ndef encoding(df):\n    code={'positive':1,\n    'negative':0,\n    'not_detected':0,\n    'detected':1}\n    for col in df.select_dtypes('object'):\n        df[col]=df[col].map(code)\n    return df","d4e0712c":"#dropna\ndef drop(df):\n    return df.dropna(axis=0)\n    ","f78c9787":"#x,y for ML\ndef preprocessing(df):\n    df=encoding(df)\n    df=drop(df)\n    X=df.drop(['SARS-Cov-2 exam result'], axis=1)\n    y=df['SARS-Cov-2 exam result']\n    print(y.value_counts())\n    return X,y","0652bab5":"X_train,y_train=preprocessing(trainset)\nX_test,y_test=preprocessing(testset)","e3f55389":"#modeling\nfrom sklearn.tree import DecisionTreeClassifier\nmodel=DecisionTreeClassifier(random_state=0)","383ea9a7":"#evaluation\n\nfrom sklearn.metrics import f1_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import learning_curve","b2451b4c":"def evaluation(model):\n    model.fit(X_train,y_train)\n    ypred=model.predict(X_test)\n    print(confusion_matrix(y_test,ypred))\n    print(classification_report(y_test,ypred))","b7a422f1":"evaluation(model)","bacc0ab8":"def evaluation(model):\n    model.fit(X_train,y_train)\n    ypred=model.predict(X_test)\n    \n    print(confusion_matrix(y_test,ypred))\n    print(classification_report(y_test,ypred))\n   \n    N, train_score, val_score = learning_curve(model, X_train, y_train,\n                                              cv=4, scoring='f1',\n                                              train_sizes=np.linspace(0.1, 1, 10))\n    plt.figure(figsize=(12, 8))\n    plt.plot(N, train_score.mean(axis=1), label='train score')\n    plt.plot(N, val_score.mean(axis=1), label='validation score')\n    plt.legend()                                         \n    ","1ffce795":"evaluation(model) \n#overfitting --train -score=100% (trainset)\n#bad score F1 --validationset (validation_score) \n#solution -- we give more data to treat overfitting","3d0b47e7":"#preprocessing with fillna\ndef fill(df):\n    return df.fillna(-999)\n#x,y for ML\ndef preprocessing(df):\n    df=encoding(df)\n    df=fill(df)\n    X=df.drop(['SARS-Cov-2 exam result'], axis=1)\n    y=df['SARS-Cov-2 exam result']\n    print(y.value_counts())\n    return X,y \nX_train,y_train=preprocessing(trainset)\nX_test,y_test=preprocessing(testset) \nevaluation(model) ","fc21c2a7":"# preprocessing with fillna and add_missing_indicator\ndef imputer(df):\n    df['is na'] = (df['Parainfluenza 3'].isna()) | (df['Leukocytes'].isna())\n    df=df.fillna(-999)\n    return df\n#x,y for ML\ndef preprocessing(df):\n    df=encoding(df)\n    df=imputer(df)\n    X=df.drop(['SARS-Cov-2 exam result'], axis=1)\n    y=df['SARS-Cov-2 exam result']\n    print(y.value_counts())\n    return X,y \nX_train,y_train=preprocessing(trainset)\nX_test,y_test=preprocessing(testset) \nevaluation(model) \n\n#bad score with fillna(-999) and missing_values","d1c5b381":"# preprocessing with dropna  and feature_selection\ndef imputer(df):\n    return df.dropna(axis=0)\n#x,y for ML\ndef preprocessing(df):\n    df=encoding(df)\n    df=imputer(df)\n    X=df.drop(['SARS-Cov-2 exam result'], axis=1)\n    y=df['SARS-Cov-2 exam result']\n    print(y.value_counts())\n    return X,y \nX_train,y_train=preprocessing(trainset)\nX_test,y_test=preprocessing(testset) \nevaluation(model) ","767832ce":"#feature_selection\npd.DataFrame(model.feature_importances_,index=X_train.columns).plot.bar(figsize=(12,8))\n#viral_feature are not importante for our model\n#solution1:drop viral_features\n#solution2:dropnan blood-feature","905fa6ba":"df = df[key_columns + blood_columns]# + viral_columns]\ntrainset,testset=train_test_split(df,test_size=0.2,random_state=0)\n# preprocessing with dropna  and feature_selection\ndef imputer(df):\n    return df.dropna(axis=0)\n#x,y for ML\ndef preprocessing(df):\n    df=encoding(df)\n    df=imputer(df)\n    X=df.drop(['SARS-Cov-2 exam result'], axis=1)\n    y=df['SARS-Cov-2 exam result']\n    print(y.value_counts())\n    return X,y \nX_train,y_train=preprocessing(trainset)\nX_test,y_test=preprocessing(testset) \nevaluation(model) \n\n# overfitting with solution1+solution2\n#solution3:other model like randomforest","d2f9d8d0":"from sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier(random_state=0)\n\n","aa446e64":"df = data.copy()\ndf= df[key_columns + blood_columns + viral_columns]\ndf.head()","87249e68":"\ntrainset,testset=train_test_split(df,test_size=0.2,random_state=0)\n# preprocessing with dropna  and feature_selection\ndef imputer(df):\n    return df.dropna(axis=0)\n#x,y for ML\ndef preprocessing(df):\n    df=encoding(df)\n    df=imputer(df)\n    X=df.drop(['SARS-Cov-2 exam result'], axis=1)\n    y=df['SARS-Cov-2 exam result']\n    print(y.value_counts())\n    return X,y \nX_train,y_train=preprocessing(trainset)\nX_test,y_test=preprocessing(testset) \nevaluation(model) ","6b643453":"pd.DataFrame(model.feature_importances_,index=X_train.columns).plot.bar(figsize=(12,8))\n#solution: use feature engeering:'is_sick'with blood features\n","b48e169a":"\ndef feature_engineering(df):\n    df['est malade'] = df[viral_columns].sum(axis=1) >= 1\n    df = df.drop(viral_columns, axis=1)\n    return df\n\ndef imputation(df):\n    #df['is na'] = (df['Parainfluenza 3'].isna()) | (df['Leukocytes'].isna())\n    #df = df.fillna(-999)\n    df = df.dropna(axis=0)\n    return  df\n    \n\ndef preprocessing(df):\n    \n    df = encoding(df)\n    df = feature_engineering(df)\n    df = imputation(df)\n    \n    X = df.drop('SARS-Cov-2 exam result', axis=1)\n    y = df['SARS-Cov-2 exam result']\n    \n    print(y.value_counts())\n    \n    return X, y\n\nX_train, y_train = preprocessing(trainset)\nX_test, y_test = preprocessing(testset)\nevaluation(model)\n#solution: define the threshold to feature-selection","d2811a0a":"#modeling\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.decomposition import PCA","3c8a8d8a":"#select the 10 best feature for the model\nmodel_1 = RandomForestClassifier(random_state=0)\n\nmodel_2 = make_pipeline(PolynomialFeatures(2), SelectKBest(f_classif, k=10),\n                      RandomForestClassifier(random_state=0))","e0b0dd16":"evaluation(model_1)","033adaf9":"pd.DataFrame(model_1.feature_importances_, index=X_train.columns).plot.bar(figsize=(12, 8))","250a1cef":"#Use different ML models\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler","b6b40fe5":"prep = make_pipeline(PolynomialFeatures(2,include_bias=False), SelectKBest(f_classif, k=10))\nRandomForest = make_pipeline(prep, RandomForestClassifier(random_state=0))\nAdaBoost = make_pipeline(prep, AdaBoostClassifier(random_state=0))\nSVM = make_pipeline(prep, StandardScaler(), SVC(random_state=0))\nKNN = make_pipeline(prep, StandardScaler(), KNeighborsClassifier())\nmodels = {'RandomForest': RandomForest,\n                  'AdaBoost' : AdaBoost,\n                  'SVM': SVM,\n                  'KNN': KNN\n                 }","4eff00a7":"for name, model in models.items():\n    print(name)\n    evaluation(model)","6c8f56cd":"#we choose AdaBoost and SVM with  hight f1-score\n#optimization\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","e6f1f117":"SVM","4848d66f":"hyper_params = {'svc__gamma':[1e-3, 1e-4, 0.0005],\n                'svc__C':[1, 10, 100, 1000, 3000], \n               'pipeline__polynomialfeatures__degree':[2, 3],\n               'pipeline__selectkbest__k': range(45, 60)}","f6710545":"grid = RandomizedSearchCV(SVM, hyper_params, scoring='recall', cv=4,n_iter=40)\n\ngrid.fit(X_train, y_train)\n\nprint(grid.best_params_)\n\ny_pred = grid.predict(X_test)\n\nprint(classification_report(y_test, y_pred))","95ecbe29":"#use of precision_recall_curve\nfrom sklearn.metrics import precision_recall_curve","5beafb9c":"precision, recall, threshold = precision_recall_curve(y_test, grid.best_estimator_.decision_function(X_test))\nplt.plot(threshold, precision[:-1], label='precision')\nplt.plot(threshold, recall[:-1], label='recall')\nplt.legend()\n#we choose throusold=-1 for best recal","8f3a61e4":"#our final SVM model with thresold=-1\ndef model_final(model, X, threshold=0):\n    return model.decision_function(X) > threshold\n\ny_pred = model_final(grid.best_estimator_, X_test, threshold=-1)\nfrom sklearn.metrics import recall_score\nf1_score(y_test, y_pred)\nrecall_score(y_test, y_pred)","149284e6":"***Preprocessing***","8e6cb074":"\n*this code is generated by following youtube channel : learnia machine * \n\n**Exploratory data analysis**\n*Check list:*\n1. Identifying the target variable : SARS-Cov-2 exam result\n2. Identifying number of rows and columns: 5644 observations et 111 features\n3. Identifying data types:74 quantitative variables (float64 + int64), 37qualitatives variables(object)\n4. Checking the missing values : .  Most values are NAN (most variables >90% NAN) \n                                 .  2 groups: 76% NAN --> viral test \n                                            89% NAN --> blood level\n5. Initial visualization: drop NAN columns : variables with >90% Nan values\n6. Target visualization: imbalanced data set Beacause only 10%  are positive to Sars-cov\n7. Variable analysis:\n    . continuous variables : . Dtype float: are standardized, Skewed Distribution, blood level.\n                             . Dtype int64 \"Patient age quantile\" : distplot not clear age [0-20]?? --> may be \n                                                      this variable transformed with quantile transformer.\n    . discrete variables:   categorical\/quantitative\/Dtype object: variables with binary values, viral test\n                                                                   Drop Parainfluenza 2 variable with 1 value \n                                                                   [nan 'not_detected']\n                                                                  - Rhinovirus\/Enterovirus detected positive \n8. Relationship between target\/variables(features):\n                                                                   \n   Hypothesis: . Relations between platelets, leukocytes, basophils, eosinophils,monocytes and Covid\n               . Relation between age and covid but we have not more details abour age variable.\n               . Some patients (6) are detected positive in both Rhinovirus\/Enterovirus and Covid, but no \n                 relationship between viral variables and target.\n               \n9. Relationship between variable\/variable:\n               .  Between blood\/blood: strong correlations between Hematocrit\/Hemoglobin.\n               .  Between blood\/age:  weak correlations between blood and age.\n               .  Between viral\/viral: Influenza A, rapid test give a bad results.\n               .  Between be sick\/blood: we have a diffrence between blood\/ be sick and blood\/covid\n               .  Between Patient addmited\/blood: predict in which unit (semi intensive\/regular wrad\/..)                                                                                a patient should go.\n               .  Between Patient addmited\/is_sick:\n10. analysis of Nan values:\n               .  viral_cols: 1350 (92 \/8)\n               .  blood_cols: 600 (87\/13)\n               .  both: drop nan values=90 values\n               \n**Hypothesis H0:**\n* Patients with covid have high level of platelets, leukocytes, basophils, eosinophils,monocytes.\n> * H0: blood level are equal in positive covid and negative covid patients --> use test student\n\n\n**Preprocessing**\n","7ede8c92":"### Relationship between target\/variables\n"}}