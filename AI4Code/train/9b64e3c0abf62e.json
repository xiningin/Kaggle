{"cell_type":{"22ad5501":"code","7ef779cb":"code","aafa93c9":"code","d22e5b2c":"code","30598397":"code","6c9bdb6a":"code","1414fcdc":"code","13251f5e":"code","431fec22":"code","d6d3d52f":"code","f8bf77f5":"code","9a9c9e7a":"code","e10fb0c5":"code","7b1e8bd6":"code","a0194a9d":"code","dd7b77c8":"code","295bb6bd":"code","1ec1139f":"code","625b7bde":"code","52696624":"code","fc6fcf09":"code","151b3a06":"code","6ca4aa49":"code","f6551fd9":"code","7e941faa":"code","bf52381f":"code","1b350b0b":"code","3a1537ac":"code","0534c797":"code","9805c0c3":"code","a1916211":"code","28af277b":"code","e91a71f2":"code","2496ca46":"code","cf746573":"code","991c2130":"code","36adff23":"code","c658541e":"code","dfeeff75":"code","2e902e84":"code","03c01595":"code","9818b48c":"code","46205baa":"code","f9fc52f8":"code","44055e35":"code","923ea00a":"code","8bd87696":"code","bc3b65e2":"code","2073e2ee":"code","97c615fc":"code","b91314df":"code","c7238aa5":"code","f0e57a5a":"code","0424c848":"code","fd85a237":"code","ea93e41b":"code","85304108":"code","208f2d39":"code","891bf1e5":"code","6d65e156":"code","ca0f937e":"code","82e6f86a":"code","79031414":"code","2e7d2331":"code","a8b11682":"code","df063c25":"code","57f0355c":"code","d51ae7c7":"code","4569a007":"code","5e49dbf2":"code","c64b8559":"code","b93aa9b1":"code","45773981":"code","573d73e0":"code","77d34787":"code","10a786e3":"code","befe4e49":"code","fbcede7a":"markdown","0cca5465":"markdown","28c23bc1":"markdown","63d0ef9f":"markdown","9ea678bb":"markdown","950ba161":"markdown","84cb7735":"markdown","d2178de2":"markdown","3f3f28fa":"markdown","8aac893a":"markdown","53eab7a7":"markdown","9ced5f07":"markdown","f84c3579":"markdown","79c7c077":"markdown","42ea6102":"markdown","3a79030c":"markdown","6f363d68":"markdown","430cb4b9":"markdown","207a2c87":"markdown","8e40ca63":"markdown","c08ba495":"markdown","ecf8dd3c":"markdown","bf97cd3c":"markdown","97e7ae3c":"markdown","71bc0644":"markdown","3653d1af":"markdown","462ef3b4":"markdown","3f0c3639":"markdown","068510a8":"markdown","57a4fb69":"markdown","83548140":"markdown","0653dd88":"markdown","ffd1b33f":"markdown","f7a3049c":"markdown"},"source":{"22ad5501":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# plotting\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\n# general NLP preprocessing and basic tools\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\n# train\/test split\nfrom sklearn.model_selection import train_test_split\n# basic machine learning models\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\n# our evaluation metric for sentiment classification\nfrom sklearn.metrics import fbeta_score,  f1_score, confusion_matrix, accuracy_score, roc_curve, auc\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom keras.models import Sequential, load_model, Model\nfrom keras.layers import LSTM, Embedding, Dropout, Dense, Input,  GlobalMaxPooling1D\n\n\n\n\nimport time\nfrom string import punctuation\nimport emoji\nimport nltk.tokenize as nltk_tok\nfrom nltk.corpus import stopwords\n\n\nimport tensorflow as tf \nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n","7ef779cb":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aafa93c9":"train_df = pd.read_csv('\/kaggle\/input\/eurecom-aml-2021-challenge-3\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/eurecom-aml-2021-challenge-3\/test.csv')\ntrain_df.head()","d22e5b2c":"target_conversion = {\n    'neutral': 0,\n    'positive': 1,\n    'negative': -1\n}\n\ntrain_df['target'] = train_df['sentiment'].map(target_conversion)\n","30598397":"train_df.head()","6c9bdb6a":"from collections import Counter\n\ntarget_cnt = Counter(train_df.sentiment)\n\nplt.figure(figsize=(16,8))\nplt.bar(target_cnt.keys(), target_cnt.values())\nplt.title(\"Dataset labels distribuition\")","1414fcdc":"print(train_df.isnull().sum())\nprint(\"There is no missing elements\")\nnum_rows = train_df.shape[0]\ncolumns = train_df.columns\ncolumns","13251f5e":"train_df['text'].str.len().plot.hist()\ntrain_df['selected_text'].str.len().plot.hist()","431fec22":"from wordcloud import WordCloud, STOPWORDS\nwordcloud = WordCloud(width=800, height=500, random_state=42, max_font_size=110, stopwords=STOPWORDS)","d6d3d52f":"import re\nstop_words = set(stopwords.words('english'))\ndata = train_df.copy()\ndata['selected_text'].apply(lambda x: x.lower()) #transform text to lowercase\ndata['selected_text'] = data['selected_text'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]', '', x))\ndata['selected_text'].apply(lambda q: [w for w in q if w not in stop_words])\ndata['selected_text'].head()\n\ntweets = ' '.join(data['text'])\npositive_tweets = ' '.join(data[data['target'] == 1]['text'])\nnegative_tweets = ' '.join(data[data['target'] == -1]['text'])\nneutral_tweets = ' '.join(data[data['target'] == 0]['text'])","f8bf77f5":"plt.figure(figsize=(20,12))\nplt.subplot(1,4,1)\nplt.imshow(wordcloud.generate(tweets), interpolation='bilinear')\nplt.axis('off')\nplt.title('All tweets')\nplt.subplot(1,4,2)\nplt.imshow(wordcloud.generate(positive_tweets), interpolation='bilinear')\nplt.axis('off')\nplt.title('Positive tweets')\nplt.subplot(1,4,3)\nplt.imshow(wordcloud.generate(negative_tweets), interpolation='bilinear')\nplt.axis('off')\nplt.title('Negative tweets')\nplt.subplot(1,4,4)\nplt.imshow(wordcloud.generate(neutral_tweets), interpolation='bilinear')\nplt.axis('off')\nplt.title('Neutral tweets')\nplt.show()","9a9c9e7a":"# we create a validation dataset from the training data\nX_train, val_df = train_test_split(train_df, test_size=0.2, random_state=0)","e10fb0c5":"count_vect = CountVectorizer()\n# here we are obtaining the vocabulary from the training data minus validation data\n# you may want to change this to the full training data for the final submission\nX_train_counts = count_vect.fit_transform(list(X_train['selected_text'].values))\nX_val_counts = count_vect.transform(list(val_df['selected_text'].values))\nX_test_counts = count_vect.transform(list(test_df['selected_text'].values))\nprint('Train feature shape:', X_train_counts.shape)\nprint('Validation feature shape:', X_val_counts.shape)\nprint('Test feature shape:', X_test_counts.shape)","7b1e8bd6":"# Now we quickly analyze the matrix of word counts:\n# Only 255125 of the 22258x23162 values => 0.049487% are non-zero.\n# The sparse encoding only needs to store these.\nX_train_counts","a0194a9d":"# Yet, we can ask to convert a part of the matrix into the traditional dense format.\n# It's quite challenging to find any non-zeros here!\nX_train_counts[:10,:10].toarray()","dd7b77c8":"# The other way around is easier. We can ask to find the ID (index) of a specific word.\ncount_vect.vocabulary_.get('machine')","295bb6bd":"# So the first tweet should have a one at this position:\nprint('Tweet:\\n', X_train.iloc[5]['text'])\nprint('Number of times the word \"machine\" appeared:\\n', X_train_counts[5, count_vect.vocabulary_.get('machine')])","1ec1139f":"train_selected_text_df = X_train[\"selected_text\"].copy()\nval_selected_text_df = val_df[\"selected_text\"].copy()\n\ntrain_text_df = X_train[\"text\"].copy()\nval_text_df = val_df[\"text\"].copy()\n\ntrain_output_df = list(X_train[\"target\"].copy())\nval_output_df = list(val_df[\"target\"].copy())\n\ntrain_output_df_array = (X_train[\"target\"].copy()).map(lambda x: np.asarray(x))\nval_output_df_array = (val_df[\"target\"].copy()).map(lambda x: np.asarray(x))","625b7bde":"# we clear our data by converting it to lower case and by removing all the punctuation, emojis and numbers. \ndef simplify(data):\n    \"\"\" input: a dataframe containing questions\n        output: a data frame with simplified questions \"\"\"\n    # convert to lower case\n    data_lower = data.apply(lambda q: q.lower())\n    # remove punctuation and emoji\n    remove_punct = lambda q: ''.join([c for c in q if c not in punctuation])\n    data_simplified = data_lower.apply(remove_punct)\n    remove_emoji = lambda q: ''.join([c for c in q if c not in emoji.UNICODE_EMOJI])\n    data_simplified = data_simplified.apply(remove_emoji)\n    remove_number = lambda q: ''.join([c for c in q if not c.isdigit()])\n    data_simplified = data_simplified.apply(remove_number)\n    return data_simplified\n#____________________________________________________________________________________________\n\n#cuting tweets into list of words\ndef tokenize(data):\n    tok = lambda q: nltk_tok.word_tokenize(q)\n    return data.apply(tok)\n\n#____________________________________________________________________________________________\n\n#We remove stop words: common words that do not add meaning to the sentence. \ndef remove_stop_words(data):\n    stop_words = set(stopwords.words('english'))\n    remove = lambda q: [w for w in q if w not in stop_words]\n    return data.apply(remove)\n#____________________________________________________________________________________________\n\n#encoding the tweets with a vocabulary index created from the training data\ndef vectorize_tweets(tweet, vocabulary):\n    \"\"\" Input: A list of words, and the vocabulary index\n        Output: the corresponding vector \"\"\"\n    vector = []\n    for w in tweet:\n        if w in vocabulary.keys():\n            vector.append(vocabulary[w])\n        else:\n            vector.append(0)\n    return vector\n\ndef vectorize_data(data, vocabulary):\n    \"\"\" Inputs: a data frame containing lists of words and the vocabulary index\n        Output: a data frame where data is vectorized\"\"\"\n    return data.apply(lambda q: vectorize_tweets(q, vocabulary))\n#____________________________________________________________________________________________\n#the longest lenght seen in the graph above\n#we make sure all the vectors have the same lenght\nVECTOR_LENGHT = 40\n\ndef to_size_vect(vect, size=VECTOR_LENGHT):\n    n = len(vect)\n    if n < size :\n        return np.array([0]*(size-n)+vect)\n    else:\n        return np.array(vect[:size])\n    \ndef to_size_data(data, question_size=VECTOR_LENGHT):\n    return data.apply(lambda x: to_size_vect(x,VECTOR_LENGHT))  \n\n#____________________________________________________________________________________________\ndef pipeline_token(text_y, text_t):\n    X_train_simplified = simplify(text_y)\n    X_test_simplified = simplify(text_t)\n    print(\"___simplified___\")\n    X_train_words = tokenize(X_train_simplified)\n    X_test_words = tokenize(X_test_simplified)\n    print(\"___tokenized___\")\n    X_train_simple = remove_stop_words(X_train_words)\n    X_test_simple = remove_stop_words(X_test_words)\n    print(\"___cleaned___\")\n\n    # making the mapping: we give a unique number to each word in our training \n    #and out of vocabulary <oov> if necessary. \n    \n    training_words = []\n    for x in X_train_simple:\n        for w in x:\n            training_words.append(w)\n\n    count_words = Counter(training_words)\n    sorted_words = count_words.most_common()\n    vocabulary_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n    vocabulary_to_int['<oov>']=0\n\n    print(\"___dictionnary done___\")\n\n    X_train_vect = vectorize_data(X_train_simple, vocabulary_to_int)\n    X_test_vect = vectorize_data(X_test_simple, vocabulary_to_int)\n    \n    X_train_padded = to_size_data(X_train_vect)\n    X_test_padded = to_size_data(X_test_vect)\n    \n    \n    return X_train_padded,X_test_padded, count_words\n\n","52696624":"%%time\ntokenize_text = pipeline_token(train_text_df, val_text_df)\nprint(\"____text token done____\")\ntokenize_selected_text = pipeline_token(train_selected_text_df, val_selected_text_df)\nprint(\"____selected text token done____\")","fc6fcf09":"%%time\n#data for submission process\n\ndf_train_selected_text =  train_df[\"selected_text\"].copy()\ndf_test_selected_text = test_df[\"selected_text\"].copy()\n\ndf_train_text = train_df[\"text\"].copy()\ndf_test_text = test_df[\"text\"].copy()\n\ntrain_df['target'] = train_df['sentiment'].map(target_conversion)\noutput_df = list(train_df['target'].copy())\noutput_df_array = train_df[\"target\"].copy().map(lambda x: np.asarray(x))\n\n\nsub_tok_text = pipeline_token(df_train_text, df_test_text)\nprint(\"____text token done____\")\nsub_tok_selected_text =pipeline_token(df_train_selected_text,df_test_selected_text)\nprint(\"____selected text token done____\")","151b3a06":"#VECTORISATION of tweets\ndef tensor_tweet(tweets_train, tweets_val):\n    tokenizer = Tokenizer(num_words = len(tweets_train), oov_token=\"<OOV>\")\n    tokenizer.fit_on_texts(tweets_train.values)\n    word_index = tokenizer.word_index\n    train_sequence = tokenizer.texts_to_sequences(tweets_train.values)\n    val_sequence = tokenizer.texts_to_sequences(tweets_val.values)\n    #PADDLING (same lenght)\n    pad_sequence = pad_sequences(train_sequence)\n    pad_v_sequence = pad_sequences(val_sequence)\n    return pad_sequence, pad_v_sequence, word_index","6ca4aa49":"%%time\ntensor_text = tensor_tweet(train_text_df, val_text_df)\nprint(\"____text token done____\")\ntensor_selected_text = tensor_tweet(train_selected_text_df, val_selected_text_df)\nprint(\"____selected text token done____\")\n\nsub_tensor_text = tensor_tweet(df_train_text, df_test_text)\nprint(\"____text token done____\")\nsub_tensor_selected_text = tensor_tweet(df_train_selected_text,df_test_selected_text)\nprint(\"____selected text token done____\")","f6551fd9":"%%time\nclf = MultinomialNB().fit(X_train_counts, X_train['target'])\nval_predictions_nb = clf.predict(X_val_counts)\naccuracy = (val_predictions_nb == val_df['target'].values).mean()\nprint('The accuracy of our multinomial Naive Bayes classifier is: {:.2f}%'.format(accuracy*100))\nfbeta = fbeta_score(val_df['target'].values, val_predictions_nb, average='macro', beta=1.0)\nprint('The fbeta score is:', fbeta)","7e941faa":"cm = confusion_matrix(val_predictions_nb, val_df['target'].values)\nsns.heatmap(cm, annot= True)","bf52381f":"# Creating a submission for NB classifier\n\nX_train_counts = count_vect.fit_transform(list(X_train['text'].values) + list(val_df['text'].values))\nX_test_counts = count_vect.transform(list(test_df['text'].values))\n\nclf = MultinomialNB().fit(X_train_counts, np.hstack([X_train['target'].values, val_df['target'].values]))\ntest_predictions_nb = clf.predict(X_test_counts)\n\nsubmission_df = pd.DataFrame()\nsubmission_df['textID'] = test_df['textID']\nsubmission_df['sentiment'] = test_predictions_nb\nsubmission_df.to_csv('TA_baseline_NB.csv', index=False)","1b350b0b":"rbf = SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train_counts, X_train['target'])\nprint(\"__RBF done__\")\npoly = SVC(kernel='poly', degree=3, C=1).fit(X_train_counts, X_train['target'])\nprint(\"__Poly done__\")\n\npoly_pred = poly.predict(X_train_counts)\nrbf_pred = rbf.predict(X_train_counts)\n\npoly_accuracy = accuracy_score(y_test, poly_pred)\npoly_f1 = f1_score(y_test, poly_pred, average='weighted')\nprint('Accuracy (Polynomial Kernel): ', (poly_accuracy*100),\"%\")\nprint('F1 (Polynomial Kernel): ', (poly_f1*100),\"%\")\n\nrbf_accuracy = accuracy_score(y_test, rbf_pred)\nrbf_f1 = f1_score(y_test, rbf_pred, average='weighted')\nprint('Accuracy (RBF Kernel): ', (rbf_accuracy*100),\"%\")\nprint('F1 (RBF Kernel): ',  (rbf_f1*100),\"%\")","3a1537ac":"# Creating a submission for NB classifier\n\nX_train_counts = count_vect.fit_transform(list(X_train['text'].values) + list(val_df['text'].values))\nX_test_counts = count_vect.transform(list(test_df['text'].values))\n\nclf = MultinomialNB().fit(X_train_counts, np.hstack([X_train['target'].values, val_df['target'].values]))\ntest_predictions_nb = clf.predict(X_test_counts)\n\nsubmission_df = pd.DataFrame()\nsubmission_df['textID'] = test_df['textID']\nsubmission_df['sentiment'] = test_predictions_nb\nsubmission_df.to_csv('TA_baseline_SVM.csv', index=False)","0534c797":"clf_lr = LogisticRegression(C=1e20, solver='newton-cg', max_iter=2000, multi_class = 'multinomial')\nclf_lr.fit(X_train_counts, X_train['target'])\nlr_predict = clf_lr.predict(X_train_counts)\nprint('Accuracy score : ',accuracy_score(X_train['target'], lr_predict))","9805c0c3":"fpr, tpr, threshold = roc_curve(X_train['target'], lr_predict[:,1])\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristics')\nplt.plot(fpr, tpr, 'b', label='AUC = {:.2f}'.format(roc_auc))\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n","a1916211":"# Creating a submission for NB classifier\n\nX_train_counts = count_vect.fit_transform(list(X_train['text'].values) + list(val_df['text'].values))\nX_test_counts = count_vect.transform(list(test_df['text'].values))\n\nclf = MultinomialNB().fit(X_train_counts, np.hstack([X_train['target'].values, val_df['target'].values]))\ntest_predictions_nb = clf.predict(X_test_counts)\n\nsubmission_df = pd.DataFrame()\nsubmission_df['textID'] = test_df['textID']\nsubmission_df['sentiment'] = test_predictions_nb\nsubmission_df.to_csv('TA_baseline_LogReg.csv', index=False)","28af277b":"from sklearn.ensemble import RandomForestClassifier\n\nclassifier = RandomForestClassifier()\nclassifier.fit(tokenize[0],output_df)\ny_hat_train = classifier.predict(tokenize[0])\nprint(f\"Training accuracy: {100*accuracy(y_hat_train, output_df):.3f}%\")\ny_hat_val = classifier.predict(tokenize[1])\nprint(f\"Validation accuracy: {100*accuracy(y_hat_val, val_output):.3f}%\")\nfbeta = fbeta_score(val_df['target'].values, y_hat_val, average='macro', beta=1.0)\nprint('The fbeta score is:', fbeta)","e91a71f2":"%%time\nclassifier_rd = RandomForestClassifier()\nclassifier_rd.fit(sub_tok[0],output_df)\ny_hat_train = classifier_rd.predict(sub_tok[0])\nprint(f\"Training accuracy: {100*accuracy(y_hat_train, output_df):.3f}%\")\n\n\ntest_predictions_nb = classifier_rd.predict(sub_tok[1])\n\nsubmission_df = pd.DataFrame()\nsubmission_df['textID'] = test_df['textID']\nsubmission_df['sentiment'] = test_predictions_nb\nsubmission_df.to_csv('TA_baseline_RdF.csv', index=False)","2496ca46":"seq_lenght = len(tensor_selected_text[0][0])\n\nmodel = Sequential()\nmodel.add(Embedding(len(tensor_selected_text[2])+1, 128, input_length=seq_lenght))\nmodel.add(Dropout(0.5))\nmodel.add(LSTM(196, dropout=0.5, recurrent_dropout=0.3, return_sequences=True,))\nmodel.add(LSTM(196, dropout=0.3, recurrent_dropout=0.2))\nmodel.add(Dense(3, activation='softmax'))\nmodel.compile(optimizer='adam', \n              loss='categorical_crossentropy', \n              metrics=['accuracy'])\nmodel.summary()","cf746573":"def range_sentiment(sent):\n    l = []\n    for i in range(len(sent)):\n        if sent[i] == 'positive': \n            l.append([1,0,0])\n        elif sent[i] == 'neutral':\n            l.append([0,1,0])\n        else: \n            l.append([0,1,0])\n    return l\n\n\nY = pd.get_dummies(X_train['sentiment']).values\nY_val = pd.get_dummies(val_df['sentiment']).values\n\n[print(X_train['sentiment'][i], Y[i]) for i in range(0,3)]","991c2130":"model.fit(np.array(tensor_selected_text[0]),Y,\n                    batch_size = 32,\n                    epochs=8,\n                    validation_data =(tensor_selected_text[1],Y_val),\n                    verbose=2, callbacks = [])","36adff23":"predictions = model.predict(tensor_selected_text[1], batch_size = 32, verbose = 2)\nloss, accuracy = model.evaluate(tensor_selected_text[1], Y_val, batch_size=4000)\n\nprint('Accuracy score : ', accuracy)\nprint('loss score:', loss)\n","c658541e":"def discretize_pred(pred):\n    for i in range(len(pred)):\n        for j in range(len(pred[i])):\n            if pred[i][j] == max(pred[i]):\n                pred[i][j] = 1\n            else: \n                pred[i][j] = 0\n    return pred\n\ndisc_pred = discretize_pred(predictions)","dfeeff75":"b = Counter(train_df.sentiment)\n\nplt.figure(figsize=(16,8))\nplt.bar(b.keys(), b.values())\nplt.title(\"Dataset labels distribuition\")","2e902e84":"target_cnt=Counter(train_df.sentiment)\nl=[target_cnt['positive'],target_cnt['neutral'],target_cnt['negative']]\nm=max(l)\nadd_l=[(m-l[i]) for i in range(len(l))]\nn=len(train_df)\n    \nwhile max(add_l)>0:\n    i=np.random.randint(0,n)\n    sentiment=train_df.iloc[i]['sentiment']\n    if sentiment=='positive':\n        if add_l[0]>0:\n            train_df=train_df.append(train_df.iloc[i])\n            add_l[0]=add_l[0]-1\n    elif sentiment=='neutral':\n        if add_l[1]>0:\n            train_df=train_df.append(train_df.iloc[i])\n            add_l[1]=add_l[1]-1\n    elif sentiment=='negative':\n        if add_l[2]>0:\n            train_df=train_df.append(train_df.iloc[i])\n            add_l[2]=add_l[2]-1","03c01595":"b = Counter(train_df.sentiment)\n\nplt.figure(figsize=(16,8))\nplt.bar(b.keys(), b.values())\nplt.title(\"Dataset labels distribuition\")","9818b48c":"# we create a validation dataset from the training data\nX_train, val_df = train_test_split(train_df, test_size=0.1, random_state=0)","46205baa":"target_conversion = {\n    'neutral': 1,\n    'positive': 2,\n    'negative': 0\n}","f9fc52f8":"X_train['target'] = X_train['sentiment'].map(target_conversion)\nval_df['target'] = val_df['sentiment'].map(target_conversion)","44055e35":"! pip install transformers==3","923ea00a":"from transformers import BertTokenizer, TFBertForSequenceClassification\nfrom transformers import InputExample, InputFeatures\n\nfrom transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\nfrom collections import defaultdict\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","8bd87696":"val_df_bert=val_df.drop(columns=['textID','text','sentiment'])","bc3b65e2":"X_train_bert=X_train.drop(columns=['textID','text','sentiment'])","2073e2ee":"PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\ntokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)","97c615fc":"\ntoken_lens = []\nfor txt in X_train_bert['selected_text'] :\n  tokens = tokenizer.encode(txt, max_length=512)\n  token_lens.append(len(tokens))\n    \n\nplt.figure(figsize=(16,8))    \nsns.distplot(token_lens)\n\nplt.xlim([0, 256]);\nplt.xlabel('Token count');\nprint(\"Max token_lens : \", max(token_lens))","b91314df":"\nclass GPReviewDataset(Dataset):\n  def __init__(self, reviews, targets, tokenizer, max_len):\n    self.reviews = reviews\n    self.targets = targets\n    self.tokenizer = tokenizer\n    self.max_len = max_len\n  def __len__(self):\n    return len(self.reviews)\n  def __getitem__(self, item):\n    review = str(self.reviews[item])\n    target = self.targets[item]\n    encoding = self.tokenizer.encode_plus(\n      review,\n      add_special_tokens=True,\n      max_length=self.max_len,\n      return_token_type_ids=False,\n      pad_to_max_length=True,\n      return_attention_mask=True,\n      return_tensors='pt',\n    )\n    return {\n      'review_text': review,\n      'input_ids': encoding['input_ids'].flatten(),\n      'attention_mask': encoding['attention_mask'].flatten(),\n      'targets': torch.tensor(target, dtype=torch.long)\n    }","c7238aa5":"def create_data_loader(df, tokenizer, max_len, batch_size):\n  ds = GPReviewDataset(\n    reviews=df['selected_text'].to_numpy(),\n    targets=df['target'].to_numpy(),\n    tokenizer=tokenizer,\n    max_len=max_len\n  )\n  return DataLoader(\n    ds,\n    batch_size=batch_size,\n    num_workers=4\n  )\n\n\nMAX_LEN=max(token_lens)+20  \nBATCH_SIZE=32\ntrain_data_loader = create_data_loader(X_train_bert, tokenizer, MAX_LEN, BATCH_SIZE)\nval_data_loader = create_data_loader(val_df_bert, tokenizer, MAX_LEN, BATCH_SIZE)","f0e57a5a":"bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)","0424c848":"class SentimentClassifier(nn.Module):\n    \n  def __init__(self, n_classes):\n    super(SentimentClassifier, self).__init__()\n    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n    self.drop = nn.Dropout(p=0.3)\n    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n    \n  def forward(self, input_ids, attention_mask):\n    _, pooled_output = self.bert(\n      input_ids=input_ids,\n      attention_mask=attention_mask\n    )\n    output = self.drop(pooled_output)\n    return self.out(output)","fd85a237":"model = SentimentClassifier(3)\nmodel=model.to(device)","ea93e41b":"EPOCHS = 3\noptimizer = AdamW(model.parameters(), lr=3e-5, correct_bias=False)\ntotal_steps = len(train_data_loader) * EPOCHS\nscheduler = get_linear_schedule_with_warmup(\n  optimizer,\n  num_warmup_steps=0,\n  num_training_steps=total_steps\n)\nloss_fn = nn.CrossEntropyLoss().to(device)","85304108":"def train_epoch(\n  model,\n  data_loader,\n  loss_fn,\n  optimizer,\n    device,\n  scheduler,\n  n_examples\n):\n  model = model.train()\n  losses = []\n  correct_predictions = 0\n  for d in data_loader:\n    input_ids = d[\"input_ids\"].to(device)\n    attention_mask = d[\"attention_mask\"].to(device)\n    targets = d[\"targets\"].to(device)\n    outputs = model(\n      input_ids=input_ids,\n      attention_mask=attention_mask\n    )\n    _, preds = torch.max(outputs, dim=1)\n    loss = loss_fn(outputs, targets)\n    correct_predictions += torch.sum(preds == targets)\n    losses.append(loss.item())\n    loss.backward()\n    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n    optimizer.step()\n    scheduler.step()\n    optimizer.zero_grad()\n  return correct_predictions.double() \/ n_examples, np.mean(losses)","208f2d39":"def eval_model(model, data_loader, loss_fn,device, n_examples):\n  model = model.eval()\n  losses = []\n  correct_predictions = 0\n  with torch.no_grad():\n    for d in data_loader:\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      targets = d[\"targets\"].to(device)\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n      _, preds = torch.max(outputs, dim=1)\n      loss = loss_fn(outputs, targets)\n      correct_predictions += torch.sum(preds == targets)\n      losses.append(loss.item())\n  return correct_predictions.double() \/ n_examples, np.mean(losses)","891bf1e5":"%%time\nhistory = defaultdict(list)\nbest_accuracy = 0\nfor epoch in range(EPOCHS):\n  print(f'Epoch {epoch + 1}\/{EPOCHS}')\n  print('-' * 10)\n  train_acc, train_loss = train_epoch(\n    model,\n    train_data_loader,\n    loss_fn,\n    optimizer,\n    device,\n    scheduler,\n    len(X_train_bert)\n  )\n  print(f'Train loss {train_loss} accuracy {train_acc}')\n  val_acc, val_loss = eval_model(\n    model,\n    val_data_loader,\n    loss_fn,\n    device,\n    len(val_df_bert)\n  )\n  print(f'Val   loss {val_loss} accuracy {val_acc}')\n  print()\n  history['train_acc'].append(train_acc)\n  history['train_loss'].append(train_loss)\n  history['val_acc'].append(val_acc)\n  history['val_loss'].append(val_loss)\n  if val_acc > best_accuracy:\n    torch.save(model.state_dict(), 'best_model_state.bin')\n    best_accuracy = val_acc","6d65e156":"plt.plot(history['train_acc'], label='train accuracy')\nplt.plot(history['val_acc'], label='validation accuracy')\nplt.title('Training history')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.ylim([0, 1])","ca0f937e":"f_val_acc, _ = eval_model(\n  model,\n  val_data_loader,\n  loss_fn,\n  device,\n  len(val_df)\n)\nf_val_acc.item()\n","82e6f86a":"test_df_bert=test_df.drop(columns=['text'])","79031414":"fake_target=np.array([-1 for i in range(len(test_df_bert))])\nlen(fake_target)","2e7d2331":"def get_predictions(model, data_loader):\n  model = model.eval()\n  review_texts = []\n  predictions = []\n  prediction_probs = []\n  #real_values = []\n  with torch.no_grad():\n    for d in data_loader:\n      texts = d[\"review_text\"]\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      #targets = d[\"targets\"].to(device)\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n      _, preds = torch.max(outputs, dim=1)\n      review_texts.extend(texts)\n      predictions.extend(preds)\n      prediction_probs.extend(outputs)\n      #real_values.extend(targets)\n  predictions = torch.stack(predictions).cpu()\n  prediction_probs = torch.stack(prediction_probs).cpu()\n  #real_values = torch.stack(real_values).cpu()\n  return review_texts, predictions, prediction_probs","a8b11682":"\n\ndef create_test_loader(df, tokenizer, max_len, batch_size):\n    p=len(df)\n    fake_target=np.array([-1 for i in range(p)])\n    ds = GPReviewDataset(\n        reviews=df['selected_text'].to_numpy(),\n        targets=fake_target,   #df['target'].to_numpy(),\n        tokenizer=tokenizer,\n        max_len=max_len\n      )\n    return DataLoader(\n    ds,\n    batch_size=batch_size,\n    num_workers=4\n  )\n\n\n\ntest_data_loader = create_test_loader(test_df_bert, tokenizer, MAX_LEN, BATCH_SIZE)","df063c25":"y_review_texts, y_pred, y_pred_probs= get_predictions(\n  model,\n  test_data_loader\n)","57f0355c":"test_prediction=[]\nfor i in range(len(y_pred)):\n    if y_pred[i]==0:\n        test_prediction.append(-1)\n    elif y_pred[i]==1:\n        test_prediction.append(0)\n    elif y_pred[i]==2:\n        test_prediction.append(1)\ntest_prediction=np.array(test_prediction)","d51ae7c7":"submission_df = pd.DataFrame()\nsubmission_df['textID'] = test_df_bert['textID']\nsubmission_df['sentiment'] = test_prediction\nsubmission_df.to_csv('BERT_trail2bis.csv', index=False)","4569a007":"submission_df = pd.DataFrame()\nsubmission_df['textID'] = test_df_bert['textID']\nsubmission_df['sentiment'] = test_prediction\nsubmission_df.to_csv('BERT_trail2bis.csv', index=False)","5e49dbf2":"y_review_texts_val, y_pred_val, y_pred_probs_val= get_predictions(\n  model,\n  val_data_loader\n)\n\ny_review_texts_train, y_pred_train, y_pred_probs_train= get_predictions(\n  model,\n  train_data_loader\n)","c64b8559":"cm = confusion_matrix(X_train_bert['target'].to_numpy(),  y_pred_train)\ndf_cm = pd.DataFrame(cm, index=[0,1,2], columns=[0,1,2])\nshow_confusion_matrix(df_cm)","b93aa9b1":"cm = confusion_matrix(val_df_bert['target'].to_numpy(),  y_pred_val)\ndf_cm = pd.DataFrame(cm, index=[0,1,2], columns=[0,1,2])\nshow_confusion_matrix(df_cm)","45773981":"%%time\n\nseq_lenght = len(tensor_selected_text[0][0])\n\nmodel = Sequential()\nmodel.add(Embedding(len(sub_tensor_selected_text[2])+1, 128, input_length=seq_lenght))\nmodel.add(Dropout(0.5))\nmodel.add(LSTM(196, dropout=0.5, recurrent_dropout=0.3, return_sequences=True,))\nmodel.add(LSTM(196, dropout=0.3, recurrent_dropout=0.2))\nmodel.add(Dense(3, activation='softmax'))\nmodel.compile(optimizer='adam', \n              loss='categorical_crossentropy', \n              metrics=['accuracy'])\nmodel.summary()\n\n\nmodel.fit(np.array(tensor_selected_text[0]),Y,\n                    batch_size = 32,\n                    epochs=8,\n                    validation_data =(tensor_selected_text[1],Y_val),\n                    verbose=2, callbacks = [])\n\n\n","573d73e0":"model.save('sentiment_analysis.h5')","77d34787":"\ntest_predictions_nb = model.predict(np.array(sub_tensor_selected_text[1]))\n\nsubmission_df = pd.DataFrame()\nsubmission_df['textID'] = test_df['textID']\nsubmission_df['sentiment'] = test_predictions_nb\nsubmission_df.to_csv('TA_baseline_LSTM.csv', index=False)","10a786e3":"nltk.download('vader_lexicon')\nsid = SentimentIntensityAnalyzer()\n# We show a few prediction examples:\nfor doc in val_df['text'].iloc[:5].values:\n    print(doc)\n    print(sid.polarity_scores(doc))\n    \n    \ndef vader_predict(x):\nprediction = sid.polarity_scores(x)\nprediction_list = [\n    (1, prediction['pos']),\n    (-1, prediction['neg']),\n    (0, prediction['neu'])\n]\nlabel = sorted(prediction_list, key=lambda x: x[1], reverse=True)[0][0]\nreturn label\n\n\npredictions_vader = val_df['text'].apply(vader_predict)\n\n\naccuracy = (predictions_vader == val_df['target'].values).mean()\nprint('The accuracy of VADER is: {:.2f}%'.format(accuracy*100))\n\nfbeta = fbeta_score(val_df['target'].values, predictions_vader, average='macro', beta=1.0)\nprint('The fbeta score is:', fbeta)","befe4e49":"# selected_text shows the words selected from text to lead to the classification stored in sentiment\ntrain_df[['text', 'selected_text', 'sentiment']].iloc[:5]","fbcede7a":"The Bag-of-Words representation assigns a unique ID to each word that appears in the training data. 23239 unique words have been extracted. Each input data point (tweet) is then represented by a vector of the size of the vocabulary. Each of its elements are the counts of the respective word appearing in the tweet.\n\nTherefore, the features have a *huge* dimension! Storing the feature matrix directly would require (n_datapoints x vocabulary size) * 32 bits $\\approx$ 2 GB CPU\/GPU RAM! Imagine we were not analyzing tweets (limited vocabulary) but Wikipedia! Or imagine we had a larger corpus of documents. Then we could not store the features!\n\nInstead, the Bag-of-Words features are usually stored using a *sparse* representation. Imagine this like a dictionary of ID-count tuples assigned to each tweet.","0cca5465":"### Implementing tokinization process with a 'hard' algorithm, explained below","28c23bc1":"### 3-  Logistic Regression","63d0ef9f":"#### Creating a submission csv for this classifier","9ea678bb":"# Example solution for tweet sentiment analysis","950ba161":"This Neural network is able to have a \"memory\". It take the text input and can understand the sentence since each word will pass through the NN and will fed the next input. The Long short term memory can overcome the overwhelming data input by forgetting some of them. ","84cb7735":"## Loading the data","d2178de2":"We start off by converting the labels to numbers. This is a requirement for the submission and numerical inputs are generally more compatible with machine learning libraries.\nNow we need to find a numerical representation for our input data. Extracting features from text is one of the major building blocks of any Natural Language Processing (NLP) pipeline.\n\nThere have been huge developments in the field during the last decade. A very traditional approach is to extract Bag-of-Words features. See here for an explanation:\n\nhttps:\/\/scikit-learn.org\/stable\/modules\/feature_extraction.html#text-feature-extraction\n\nWe will stick to this technique for the purpose of this example notebook. However, be aware that much more powerful feature extraction techniques exist. The most recent ones use neural network based language models. See e.g.:\n\nhttps:\/\/www.analyticsvidhya.com\/blog\/2019\/06\/understanding-transformers-nlp-state-of-the-art-models\/","3f3f28fa":"### Model evaluation:\n\nMake sure to select potential model hyperparameters using cross-validation or similar. Our evaluation metric of choice is the F1-score:\n\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score\n\nWe choose beta=1 and average=macro","8aac893a":"#### Creating a submission csv for this classifier","53eab7a7":"### 4 - Random Forest Classifier","9ced5f07":"### Feature extraction:\n- Can we make our Bag-of-Words representation more compact or richer? There are many things you could try to implement. Here are some buzzwords: tokenization, stop words removal, lemmatization, n-gram extraction, ...\n- A useful Python library to address these issues is: NLTK (https:\/\/www.nltk.org\/)\n- The sklearn CountVectorizer we used can be combined with NLTK preprocessing:\nhttps:\/\/scikit-learn.org\/stable\/modules\/feature_extraction.html#customizing-the-vectorizer-classes\n- Is there also a dense (as opposed to sparse) representation of documents (tweets in our case)? Buzzwords: word2vec, LDA, LSI\n- A useful Python library for this purpose (with pretrained models) is: gensim https:\/\/radimrehurek.com\/gensim\/\n- The state-of-the-art: ... are neural network language models, so-called Transformers. There are pretrained models available. If you feel comfortable with neural networks, fine-tuning and GPUs, have a look here: https:\/\/huggingface.co\/transformers\/","f84c3579":"### 1 - Na\u00efve Bayes Classifier","79c7c077":"## BERT 2","42ea6102":"## Data preprocessing","3a79030c":"After the data pre-processing, we will dive in different model training. We pick the model with the best performance. ","6f363d68":"VADER performs worse! That is a good sign that our classifier learned useful generalizations from the training data (better than standard handcrafted rules).","430cb4b9":"## Comparing with TextBlob","207a2c87":"#### Creating a submission csv for this classifier","8e40ca63":"Sentiment Analysis using LSTM can help to use sequential network to this classification problem. ","c08ba495":"### 5 - LSTM","ecf8dd3c":"#### Creating a submission csv for this classifier","bf97cd3c":"# Model Building ","97e7ae3c":"# How good is this score?\n\n## Comparing with VADER","71bc0644":"### We can higlight that 'work' is in negative tweets. ","3653d1af":"## Where to go from here?\n\nWe can improve our Machine Learning pipeline on multiple aspects:","462ef3b4":"### Bonus:\n\nApart from classifying the sentiment of tweets, we can also try to determine which words are the reason for the classifier to determine the classification. Ground-truth labels for these words are contained in our training data. The evaluation will not take place on the Kaggle platform.\nYou need to do it yourself. Use the Jaccard coefficient to evaluate the overlap between the selected words and the ground truth:\n\nhttps:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html#jaccard-similarity-coefficient-score","3f0c3639":"## Data preprocessing","068510a8":"### 2- Linear SVM","57a4fb69":"### Data analysis:\n\nHow is the data distributed? Can we analyze our data to find patterns associated with the classes? Which kinds of words are useful, which aren't?","83548140":"#### Creating a submission csv for this classifier","0653dd88":"### Let's use also tensorflow tokenizer","ffd1b33f":"### Model selection:\n\nThe model of choice highly depends on the previously extracted features. Depending on whether you obtain a sparse or dense feature representation, you have to choose an appropriate model!","f7a3049c":"# Data analysis"}}