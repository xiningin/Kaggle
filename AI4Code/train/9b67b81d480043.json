{"cell_type":{"170b5744":"code","b3f113d5":"code","2b7f2ca1":"code","3b2eecd3":"code","a8abda77":"code","44d363c9":"code","cbbddc1d":"code","7f0e5415":"code","059b16c1":"code","8654faf7":"code","f15966dd":"code","8733795e":"code","8c612c6a":"code","053ad47f":"code","5712fa5c":"code","6f5ae65c":"code","0e89619a":"code","a967c197":"code","c1fb1e83":"code","9b56ddec":"code","e23c8cec":"code","b78cd808":"code","d1d17c29":"code","2460416d":"code","8e3171f9":"code","5cae513a":"code","8c9f9452":"code","208df112":"code","5c3c2e74":"code","86e19bf6":"code","62aed35c":"code","b708bd21":"code","28630ca4":"code","130e0ee9":"code","6daa2f36":"code","21ede3a9":"code","02d13ffd":"code","f613354d":"code","2097bc3a":"code","bc5f6bab":"markdown","26cc0cc3":"markdown","14026f4f":"markdown","ca49b644":"markdown","e04aeefe":"markdown","79a38257":"markdown","f63165bd":"markdown","dcff113f":"markdown","b18951d3":"markdown","83b3ca35":"markdown","c5276400":"markdown","d402d8bf":"markdown","d43bc50f":"markdown","d3000f95":"markdown","2aee831d":"markdown","322c199a":"markdown","0bd51e29":"markdown","d8e66561":"markdown","7a5ee2f3":"markdown","72d5a266":"markdown","143cfafb":"markdown","38945ef3":"markdown","5fa0483d":"markdown","96a02cf6":"markdown","7dcfccdb":"markdown","a582bbd8":"markdown","c6ed4ec9":"markdown","b663ca3e":"markdown","7978579a":"markdown","e9f93255":"markdown","ceff6c0c":"markdown","cf0ab2a7":"markdown","6f54f32a":"markdown","6d37f162":"markdown","1ec2b68a":"markdown","2a3d909b":"markdown","a9108fbc":"markdown","3db682ff":"markdown","d1da0416":"markdown","264b524c":"markdown","0de748c8":"markdown","42107995":"markdown","2d00d068":"markdown","eefc3b2b":"markdown","6f08b255":"markdown","f30caa08":"markdown","d557dd76":"markdown","86ec84fa":"markdown","5adad95d":"markdown","ee2608e3":"markdown","ee45171e":"markdown","eb3b8a88":"markdown","7c069e09":"markdown","58816bb1":"markdown","78deaa8d":"markdown","f9c323f4":"markdown"},"source":{"170b5744":"activity = 'programming'\n\nprint(activity)","b3f113d5":"# activity == Activity","2b7f2ca1":"activity == activity","3b2eecd3":"## Your code below:\n\n","a8abda77":"import pandas as pd\nprint(pd.__version__)","44d363c9":"rice = pd.read_csv(\"\/kaggle\/input\/algoritma-academy-data-analysis\/rice.csv\", index_col=0)\nrice.head()","cbbddc1d":"## Your code below\n\n\n## -- Solution code","7f0e5415":"## Your code below\n\n\n## -- Solution code","059b16c1":"print(rice.dtypes)","8654faf7":"## Your code below\n\n\n## -- Solution code","f15966dd":"employees = pd.DataFrame({\n    'name': ['Anita', 'Brian'],\n    'age': [34, 29],\n    'joined': [pd.Timestamp('20190410'), pd.Timestamp('20171128')],\n    'degree': [True, False],\n    'hourlyrate': [35.5, 29],\n    'division': ['HR', 'Product']\n})\nemployees.dtypes","8733795e":"employees","8c612c6a":"## Your code below\n\n\n## -- Solution code","053ad47f":"## Your code below\n\n\n## -- Solution code","5712fa5c":"employees.describe()","6f5ae65c":"## Your code below\n\n\n## -- Solution code","0e89619a":"print(rice.shape)\nprint(rice.size)","a967c197":"## Your code below\n\n\n## -- Solution code","c1fb1e83":"rice.axes[1]","9b56ddec":"rice.dtypes","e23c8cec":"rice['purchase_time'] = rice['purchase_time'].astype('datetime64')\nrice[['category', 'sub_category', 'format']] = rice[['category', 'sub_category', 'format']].astype('category')\nrice.dtypes","b78cd808":"rice.select_dtypes(include='object').head()","d1d17c29":"rice.select_dtypes(include=['category']).describe()","2460416d":"## Your code below\n\n\n## -- Solution code","8e3171f9":"rice.drop(3).head()","5cae513a":"rice.drop(['unit_price', 'purchase_time', 'receipt_id'], axis=1).head()","8c9f9452":"rice[0:4]","208df112":"rice.iloc[0:5, :]","5c3c2e74":"## Your code below\n\n\n## -- Solution code","86e19bf6":"rice = pd.read_csv(\"\/kaggle\/input\/algoritma-academy-data-analysis\/rice.csv\", index_col=1)\nrice = rice.drop('Unnamed: 0', axis=1)\nrice.head()","62aed35c":"rice.loc[[9643416, 5735850], :]","b708bd21":"clients = pd.read_csv(\"\/kaggle\/input\/algoritma-academy-data-analysis\/companies.csv\", index_col=1)\nclients.head()","28630ca4":"## Your code below\n\n\n## -- Solution code","130e0ee9":"rice = pd.read_csv(\"\/kaggle\/input\/algoritma-academy-data-analysis\/rice.csv\", index_col=1)\nrice = rice.drop('Unnamed: 0', axis=1)\nrice[rice.discount != 0].head()","6daa2f36":"## Your code below\n\n\n## -- Solution code","21ede3a9":"rice = pd.read_csv(\"\/kaggle\/input\/algoritma-academy-data-analysis\/rice.csv\", index_col=1)\nrice = rice.drop('Unnamed: 0', axis=1)\n\nrice.head()","02d13ffd":"rice_july = rice\nrice_july['discount'] = 15\nrice_july.head()","f613354d":"rice = pd.read_csv(\"\/kaggle\/input\/algoritma-academy-data-analysis\/rice.csv\", index_col=1)\nrice = rice.drop('Unnamed: 0', axis=1)\n\nrice_july = rice.copy()\nrice_july['discount'] = 15\nrice_july.head()","2097bc3a":"rice.head()","bc5f6bab":"`dtypes` simply stands for \"data types\". Because `rice` is a `pandas` object, accessing the `dtypes` attribute will return a series with the data type of each column. \n\n----\n#### Knowledge check: `.dtypes` and pandas attributes\nLook at the following code - what is the expected output from the following code? Why?\n```\nx = [2019, 4, 'data science']\nx.dtypes\n```\n\nHint: Try `type(x)` and verify the type for object `x`.","26cc0cc3":"One other attribute that is often useful is `.axes`, which return a list representing the axes of our DataFrame. Most likely, this would be a list of length 2, one for the row axis and one for the column axis, in that particular order.\n\nBecause it is ordered that way, calling `.axes[0]` would return the first item of that list, which would be the row axis (or row names if present) and calling `.axes[1]` would return the column axis, which would be equivalent to calling `rice.columns`:","14026f4f":"Using `.loc` and `.iloc`, we can perform slicing on both the row and column indices, offering us even greater flexibility and control over our subsetting operations.\n\n`.iloc` requires us to pass an `integer` to either the row or\/and column. We can also use `:` to indicate no subsetting in a certain direction. The following code slices out the first 5 rows but take all columns (pay attention to the use of the `:` operator): ","ca49b644":"Using indexing operators to select, summarize or transform only a subset of data is a critical part of any data analysis workflow. Consider the following use-cases:\n\n- Compare the sales in Year 2018 vs Year 2019  \n- Identify missed opportunities in a specific market segment (e.g. Retail vs Wholesale)\n- Best quarter of the year to execute cross-selling promos \/ discounts\n- Study profitability of goods in the higher price range (e.g. IDR45000000+) and how competitors positioning affect sales in that price range\n\nNotice that in all of these use-cases, data analysts will want to use some combination of indexing and then perform the necessary computations on that specific slice or slices of data. Unsurprisingly, `pandas` come with a number of methods to help you accomplish this task.\n\nIn the following section, we'll take a closer look at some of the most common slicing and subsetting operations in `pandas`:\n- `head()` and `tail()`  \n- `select_dtypes()`  \n- Using `.drop()` \n- The `[]` operator\n- `.loc`  \n- `.iloc`\n- Conditional subsetting","e04aeefe":"#### Knowledge Check: Slicing\n\nRecalling that the `end` is not inclusive and Python's 0-based indexing behavior, if we have wanted to subset the **8th to 12th** row of our data, how would we have done it instead? Pick the right answer and try it in a new code cell below.\n\n- [ ] `rice[7:12]`\n- [ ] `rice[8:12]`\n- [ ] `rice[7:13]`\n- [ ] `rice[8:13]`","79a38257":"In the code above, we used `.read_csv()` to read a csv file from a specified path. Notice that we set `index_col=0` so the first column in the csv is used as the index. By default, this function treats the first row as the header row. We can add `header=None` to the function call telling `pandas` to read in a CSV without headers.\n\nYou may find it curious that we use `0` to reference the first element of an axis; This is because Python uses 0-based indexing, a behavior that is different from other languages such as R and Matlab.","f63165bd":"Then, let's create a new dataframe, `rice_july`, which stores our rice sales data particularly in July 2018. Suppose that during that period, we're giving a 15 percent discount in all of our products, so we're also replacing all the values in `rice_july.discount` to 15. ","dcff113f":"#### Dive Deeper","b18951d3":"# Introduction to pandas Library\n\n## Working with DataFrame","83b3ca35":"#### Knowledge Check: Error","c5276400":"We will start off by learning about a powerful Python data analysis library by the name of `pandas`. Its official documentation introduces itself as the \"fundamental high-level building block for doing practical, real world data analysis in Python\", and strive to do so by implementing many of the key data manipulation functionalities in R. This makes `pandas` a core member of many Python-based scientific computing environments.\n\nFrom its [official documentation](https:\/\/pandas.pydata.org):\n\n> Python has long been great for data munging and preparation, but less so for data analysis and modeling. pandas helps fill this gap, enabling you to carry out your entire data analysis workflow in Python without having to switch to a more domain specific language like R.\n\nTo use `pandas`, we will use Python's `import` function. Once imported, all `pandas` function can be accessed using the *pandas.function_name* notation.","d402d8bf":"## Data Types","d43bc50f":"### Conditional Subsetting\n\nAlong with `.iloc` and `.loc`, probably the most helpful type of subsetting would have to be conditional subsetting.\n\nWith conditional subsetting, we select data based on criteria we specified:\n- `.format == 'supermarket'` to select all transactions where format is supermarket  \n- `.unit_price >= 400000` to select all transactions with unit price being equal to or greater than 400000. \n- `.quantity != 0` to select all transactions where quantity of purchase **is not** 0   \n\nWe can also use the `&` and `|` operators to join conditions:\n\n`sales[(sales.salesperson == 'Moana') & (sales.amount > 5000)]` subset any rows where Moana has sold more than $5000 worth of items","d3000f95":"**Coursebook: Python for Data Analysts**\n- Part 1 of Data Analytics Specialization\n- Course Length: 12 hours\n- Last Updated: February 2020\n\n___\n\n- Author: [Samuel Chan](https:\/\/github.com\/onlyphantom)\n- Developed by [Algoritma](https:\/\/algorit.ma)'s product division and instructors team","2aee831d":"## Variables and Keywords\n\nLater on, we will often use assignment statements (`=`) to creates new variables. A variable is a name that refers to a value.","322c199a":"You'll be tempted to go through all the keywords above and try to wrap your head around each one of them. If this proves to be a tad overwhelming, my recommendation is to move along the rest of the section; Most of us do not know the inner workings of every components of our car engine, but that shouldn't stop you from being an effective driver. \n\n\nAs stated in the beginning of this course book, we're choosing a top-down approach and concepts will be presented on a \"need-to-know\" basis. We'll no doubt come across many of the keywords again (since collectively they form the backbone of the language) but for now, there is no need to stress about them if that only serve to discourage you from learning to code.\n\n---\n\n**What you need to know**:\n- Python, as with `R`, `Swift`, `C`, and many other languages, are case-sensitive. `Sales` and `sales` refer to different objects.  \n- You cannot use any Python keywords as identifers. \n- When naming your variables, start with a letter and use underscore (`_`) to join multiple words.\n    - Wrong: `2019`, `2019sales`, `sales-2019`, `sales.2019`\n    - Correct: `sales_2019`, `profit_after_tax`","0bd51e29":"When we call `pd.read_csv()` earlier, `pandas` will try to infer data types from the values in each column. Sometimes, it get it right but more often that not, a data analyst's intervention is required. In the following sub-section, we'll learn about various techniques an analyst have at his\/her disposal when it comes to the treatment of pandas data types.","d8e66561":"So far, so reasonable. However, if we were to now check the values of that Python list as referenced by `rice`, we see that the list has also been updated.","7a5ee2f3":"Let's dive deeper into understanding the `index_col` parameter. From the documentation:\n\n> `index_col` : int or sequence or `False`  \nColumn to use as the row labels of the DataFrame.\n\n1. How would you change the `read.csv()` code such that the DataFrame uses `receipt_id` as the row label (index)? \n2. `pandas.DataFrame.head()` accepts an additional parameter, `n`, and returns the first `n` rows of the DataFrame; Set `n=8` to see the first 8 rows of your `rice` DataFrame\n3. The opposite of `.head()` is `.tail()`. It returns the last `n` row of your DataFrame. Create a new cell below and print the last 4 rows of our DataFrame \n\n*Reminder: Python uses 0-based indexing, and `receipt_id` is the second column in the csv*","72d5a266":"## Training Objectives\n\nThis coursebook is intended for participants new to the world of data analysis and \/ or programming. No prior programming knowledge is assumed. \n\nThe coursebook focuses on:\n- Introduction to the `pandas` library. \n- Introduction to `DataFrame`  \n- Data Types\n- Exploratory Data Analysis I\n- Indexing and Subsetting\n\nThe final part of this course is a Graded Asssignment, where you are expected to apply all that you've learned on a new dataset, and attempt the given questions.","143cfafb":"To subset for the row of transactions corresponding to receipt id 9643416 and 5735850, we can use label-based indexing (`.loc`) as such:","38945ef3":"Say we're only really interested in the numeric columns of our data, we can use `select_dtypes` to selectively include or exclude only particular data types.\n\nIn the following example, I use `select_dtypes` to _include_ only textual columns (`objects`) and then proceed to pass the output of this function call into `.head()`. Notice that when we chain two methods this way, the output of the first function call will be \"passed\" into the second function call: ","5fa0483d":"Another thing that you may need to note is that in Python, using `=` operator is also referencing to the initial DataFrame. For example, let's take a look back to our `rice` data:","96a02cf6":"#### Dive Deeper:\n\nIn the following code, we read in `companies.csv`. Take a peek at the data using `head` or `tail`. \n\nPerform a *label*-based or *integer*-based indexing (whichever deemed more appropriate) by subsetting for the row corresponding to 'Li and Partners' and tries to answer the following questions:\n\n1. Where is *Li and Partners* located?\n2. How much `Returns` did PT. Algoritma Data Indonesia make?\n3. What about the `Forecasted Growth` for Palembang Konsultansi?","7dcfccdb":"# Referencing and Copying","a582bbd8":"## Top-Down Approach \n\nThe coursebook is part of the **Data Analytics Specialization** offered by [Algoritma](https:\/\/algorit.ma). It takes a more accessible approach compared to Algoritma's core educational products, by getting participants to overcome the \"how\" barrier first, rather than a detailed breakdown of the \"why\". \n\nThis translates to an overall easier learning curve, one where the reader is prompted to write short snippets of code in frequent intervals, before being offered an explanation on the underlying theoretical frameworks. Instead of mastering the syntactic design of the Python programming language, then moving into data structures, and then the `pandas` library, and then the mathematical details in an imputation algorithm, and its code implementation; we would do the opposite: Implement the imputation, then a succinct explanation of why it works and applicational considerations (what to look out for, what are assumptions it made, when _not_ to use it etc).\n\nFor the most part, experience in Python programming is good to have but not required. Familiarity with data manipulation and data structures in a different programming language a welcome addition but again, not required.","c6ed4ec9":"Use `employees.dtypes` to confirm that you've done the exercise above correctly:","b663ca3e":"Compare your mental checklist with the following code. We converted `purchase_time` to a `datetime` type, and perform the conversion for the categorical columns as well:","7978579a":"Let's go through the columns and their data types from the above `DataFrame`:\n\n- `name` [`object`]: store text values\n- `age` [`int`]: integer values\n- `joined` [`datetime`]: date and time values\n- `degree` [`bool`]: True\/False values\n- `hourlyrate` [`float`]: floating point values\n- `division` [`object`]: store text values\n\nAmong these columns, only `age` and `hourlyrate` are columns with numeric values. This is a simple, but important, observation to make as we make our way into the Exploratory Data Analysis phase. But before we do, let's do one more exercise. Take a closer look at the Data Frame we just created again.\n\nOut of the 6 columns, one of them is of special interest to our next discussion, **categorical values**.","e9f93255":"#### Knowledge Check: Data types\n\nSupposed we have a pandas DataFrame named `inventory`. \n\n1. We called `inventory.dtypes` and got the following output. Which of the column likely require type conversion because it seems to have the wrong data type? Choose all that apply.\n\n    - [ ] `units_instock`: int64\n    - [ ] `discount_price`: float64\n    - [ ] `item_name`: object\n    - [ ] `units_sold`: object\n    \n\n2. We would like to know the number of columns in `inventory`. Which of the following code would print the number of columns in `inventory`? Choose all that apply.\n\n    - [ ] `print(len(inventory.columns))`\n    - [ ] `print(inventory.shape[1])`\n    - [ ] `print(len(rice.axes[1]))`\n","ceff6c0c":"### Categorical and Numerical Variables\n\n\nWhen working with categories, it is recommended both from a business point of a view and a technical one to use `pandas` categorical data type. From a business perspective, this adds clarity to the analyst's mind about the type of data he\/she is working with. This informs and guides the analysis, on questions such as which statistical methods or plot types to use.\n\nFrom a technical viewpoint, the memory savings -- and in turn, computation speed as well as computational resources -- can be quite significant. Specifically, the docs remarked:\n\n> The memory usage of a `Categorical` is proportional to the number of categories plus the length of the data. In contrast, an `object` dtype is a constant times the length of the data\n\nOne more important remakrs from the docs:\n\n> Categoricals are a pandas data type corresponding to categorical variables in statistics. A categorical variable takes on a limited, and usually fixed, number of possible values (categories; levels in R). Examples are gender, social class, blood type, country affiliation or rating via Likert scales.\n\nCan you spot which of our column holds values that should be encoded in the `category` data type? Once you've spotted it, use the `astype('category')` method to perform the conversion. Remember to re-assign this new column so the original column (`object`) type is overwritten with the new `category` type column.\n\nExamples:\n\n```py\n# convert marital_status to category\nemployees['marital_status'] = employees['marital_status'].astype('category')\n\n# convert experience to integer\nemployees['experience'] = employees['experience'].astype('int')\n```","cf0ab2a7":"## Indexing and Subsetting with Pandas","6f54f32a":"# Background","6d37f162":"A couple of things to note here. `True`, along with its opposite, `False` are among a reserved list of vocabulary referred to as **Python Keywords**. We cannot use keyword as variable name, function name or assign values to them, essentially treating them as an identifier. \n\nInterestingly, all python keywords except **True**, **False** and **None** are in lowercase and they must be written as it is. As of Python 3.7 (latest version of Python as of this writing), there are 33 keywords:\n\n`True`, `False`, `None`, `and`, `as`, `assert`, `break`, `class`, `continue`, `def`, `del`, `elif`, `else`\n`except`, `finally`, `for`, `from`, `global`, `if`, `import`, `in`, `is`, `lambda`, `nonlocal`, `not`, `or`, `pass`\n`raise`, `return`, `try`, `while`, `with`, `yield`","1ec2b68a":"Our previous code returned `True` as the output. Try to create a new variable and use `True` as the variable name, then see what happen.\n\n> SyntaxError: can't assign to keyword","2a3d909b":"## Exploratory Data Analysis Tools\n\nIn simple words, exploratory data analysis (EDA) refers to the process of performing initial investigations on data, often with the objective of becoming familiar with certain characteristics of the data. This is usually done with the aid of summary statistics and simple graphical techniques that purposefully uncover the structure of our data.\n\nWe'll start off by using some of the most convenient EDA tools conveniently built into `pandas`. Particularly, this is a summary of what we'll cover in common EDA workflows:\n\n- `.head()` and `.tail()`\n- `.describe()`\n- `.shape` and `.size`\n- `.axes`\n- `.dtypes`","a9108fbc":"Let's take a look at some examples of `DataFrame.dtypes`:","3db682ff":"`pandas` allow data analysts to create Series objects and DataFrame objects. Series is used to represent a one-dimensional array whereas DataFrame emulates the functionality of \"Data Frames\" in R and is useful for tabular data. \n\nIn practice, a large proportion of our data is tabular: when we import data from a relational database (MySQL, Postgre) or from a spreadsheet software (Google Sheets, Microsoft Excel) we can represent these data as a DataFrame object.","d1da0416":"Very often, we also want to know the shape of our data - i.e. how many rows and columns are there in our DataFrame? \n\nOur DataFrame has attributes that we can use to answer those questions. An attribute is a value stored within an object that describe an aspect of the object's characteristic. In the following call, we are asking for the `.shape` and the `.size` attribute of our `rice` DataFrame.\n\n_Tip:_\nUnlike `describe()`, which is a method call; `shape` and `size` are **attributes** of our DataFrame - that means no function is evaluated; Only a value stored in the object's instance is looked up and returned.","264b524c":"`.loc`, in contrast to `.iloc` does not subset based on _integer_ but rather subset based on `label`. We can still use `integer` but our integers will be treated or interpreted as _labels_.\n\nLet's read in the same `csv`, except this time we will set `receipt_id` as the row labels:","0de748c8":"# Python for Data Analysts\n\nSince you'll spend a great deal of your time working with data in Jupyter Notebook, I think it's important to get yourself familiar with notebok documents (or \"notebooks\").\n\n> Notebook documents are documents produced by *Jupyter Notebook*, which contain both computer code (e.g. python) and rich text elements (paragraph, equations, figures, links, etc\u2026). Notebook documents are both human-readable documents containing the analysis description and the results (figures, tables, etc..) as well as executable documents which can be run to perform data analysis.\n\nJupyter Notebook provides an easy-to-use, interactive data science environment that doesn't only work as an IDE, but also as a presentation tool (as it can be exported to other document formats, such as .HTML, .PDF, etc).\n\nIf you\u2019re a seasoned programmer, the **Ctrl + Shift + P** combination will bring up a shortcut reference guide that helps you use Jupyter Notebook more effectively.","42107995":"You can also use `include` or `exclude` with a list of data types instead of a singular value. To include all columns of data types integer and float, we can do either of these:\n- `include='number'`  \n- `include=['int', 'float']`\n\nTry and do that now; Chain the `select_dtypes()` command with `.head()` to limit the output to only the first 5 rows:","2d00d068":"#### Dive Deeper:\n\nIn the cell below, write code using conditional subsetting and answer the following questions:\n\n1. Say as a company, we define \"bulk purchase transaction\" to be any transaction containing at least 8 units of the same item (`quantity` column). In our dataset, how many \"bulk purchases\" do we have? \n2. How many transactions in our dataset took place in a `minimarket`?\n3. How many transactions in our dataset took place in a `hypermarket` and has at least 10 units (`quantity` column)?\n\n*Tip*: You may find the `.shape` attribute convenient in extracting the number of rows \/ columns from a dataframe","eefc3b2b":"The explanation is that when we execute the line `rice_july = rice`, a new Python list **is not being created**. We truly have only one object, and that line only creates a new variable named `rice_july` that references that very same object.\n\nThe behavior with using the `=` operator in Python differs from other programming languages and can be confusing to seasoned developers new to Python. \n\nThe appropriate method instead is `.copy()`, which creates an actual copy of the python list. Notice that in the following code, there are two distinct Python objects, and changing the values in one do not affect the other:","6f08b255":"Observe how in earlier exercises, you inspect the data and consciously decide whether `.loc` or `.iloc` is the more appropriate choice here. This is a helpful mental exercise to get into - in real life data analysis, very often you're faced with the dilemma of picking from a large box of tools, and knowing which method is the best fit is a critical ingredient for efficiency and fluency.","f30caa08":"We've covered `.dtypes` in earlier sections, so go ahead and practice inspecting the data types of `rice` DataFrame. Are the columns in the right data types? If they are not, formulate a mental checklist of type conversion you need to perform.","d557dd76":"We can drop multiple rows or columns by passing in a list. In the following code, we override the default `axis` value by passing `axis=1`; As a result `pandas` will drop the specified columns, while preserving all rows:","86ec84fa":"In most real-world projects, your work as a data analyst will involve working with **categorical**, **numeric** and **datetime** values; either treating them as \"features\" or \"target\". In the case of machine learning:\n\n- A **categorical** target represents a classification problem\n- A **numeric** target represents a regression problem","5adad95d":"Putting together what you've learned so far, use `.iloc` to subset the **last 2 rows of our dataframe**, and the **first 4 columns**. If you perform this exercise correctly, the output `x` should be a `pandas` dataframe (`type(x)` is a pandas `DataFrame` object)\n\nBonus: If you want an extra challenge, try and perform this operation three times; \n1. Use only `.iloc[ , ]`\n2. Use `tail(2)` to get the last 2 rows then chain it with `.iloc`  \n3. Use `rice.shape[0]-2:` to get the last 2 rows in your `.iloc` operation","ee2608e3":"Apart from using `select_dtypes` to exclude columns, we can also use `.drop()` to remove rows or columns by label names and the corresponding axis. By default, the `axis` is assumed to be 0, i.e. referring to the row. Hence the following code will drop the **row** with label `3`: ","ee45171e":"Change the following code from `include` to `exclude` and observe the difference in the output from our `.describe()` call:","eb3b8a88":"The `.describe()` method will generate descriptive statistics of our data, and by default include all numeric columns in our DataFrame. It lists 8 statistical properties of each attribute, for example on numerical values:\n- Count\n- Mean\n- Standard Deviation\n- Minimum Value\n- 25th Percentile (Q1)\n- 50th Percentile (Q2\/Median)\n- 75th Percentile (Q3)\n- Maximum Value\n\nThe `describe()` method will generate descriptive statistics of our data, and by default include all numeric columns in our DataFrame. The code above calls `.describe()` on `employees`, from which there are two numeric columns. This method is an \"instruction\" to perform something (functions) associated with the object. We've seen earlier how to use `.head()` and `.tail()` on our DataFrame: these are also method calls!\n\nWe can add an `include` parameter in the `.describe()` method call, which takes a list-like of dtypes to be included or `all` for all columns of the dataframe.\n\nAdd a new cell below, calling `describe()` but only on columns of `object` and `datetime` types (`['object', 'datetime']`).","7c069e09":"Referring to the previous **Python keywords** concept. Which of the following 4 lines of code will evaluate without raising an error?\n\n- [ ] `pd.read_csv(\"data_input\/rice.csv\", index_col=false)`\n- [ ] `Import pandas as pd`\n- [ ] `print(100-2)`\n- [ ] `None = 2`","58816bb1":"`size` returns the number of elements in the `rice` DataFrame. Because we have 12,000 rows and 10 columns, the total number of elements would be a total of 120,000. \n\nUse `.shape` on the `employees` DataFrame. From the resulting output, could you tell what would be the result of calling `employees.size`?","78deaa8d":"Rather commonly, you may want to perform subsetting by slicing out a set of rows. This can be done using the `rice[start:end]` syntax, where `start` is inclusive.\n\nThe code follows slices out the first to fourth row, or equivalently, row with the index 0, 1, 2, and 3. ","f9c323f4":"Thing to note here, like other programming languages, Python is **case-sensitive**, so `activity` and `Activity` are  different symbols and will point to different variables."}}