{"cell_type":{"af1208b8":"code","ba1cb708":"code","27abea60":"code","3af75bd5":"code","7d0eb1b0":"code","803f984f":"code","e39d763b":"code","9145f6cb":"code","2d546320":"code","7cac6a99":"code","090c2c53":"code","edf7076e":"code","e7fe778c":"code","b173d4e2":"code","ae6026fd":"code","9aad2292":"code","fa70015d":"code","eea5c9d0":"code","12d75625":"code","9d71342e":"code","f0588425":"code","6c4170c4":"code","5d1904dc":"code","0bfcbb22":"code","8e6defb6":"code","5d3f265f":"code","1c4867bd":"code","65757f31":"code","5bd36a77":"code","3788f8da":"code","d8bc307c":"code","5e9c76d3":"code","2ee25a86":"markdown","052802a9":"markdown","ac079677":"markdown","9357ffe4":"markdown","d2254db2":"markdown","4ecb87c4":"markdown","0e040ac2":"markdown","e56deaf8":"markdown","5d3f7ba0":"markdown","6247059b":"markdown","b65d38f0":"markdown","ed275b8f":"markdown","a6d2df15":"markdown","ced29001":"markdown","7e356237":"markdown","90492e9c":"markdown","30399dbf":"markdown","f39e95d4":"markdown","d4f111ca":"markdown","3b6512a6":"markdown","918b5a4e":"markdown","5d198ba6":"markdown","e16cd6e3":"markdown","ca56d273":"markdown","8a9a754a":"markdown","fd7a889e":"markdown","691d4eb3":"markdown"},"source":{"af1208b8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.impute import SimpleImputer","ba1cb708":"train_df = pd.read_csv('..\/input\/train.csv') # training portion\ntest_df = pd.read_csv('..\/input\/test.csv')\ncombine_df = [train_df, test_df] # all data \ntrain_df.head()","27abea60":"print(train_df.columns.values) #get the list of all column names","3af75bd5":"train_df.info()\nprint('_'*40)\ntest_df.info()","7d0eb1b0":"train_df.describe()","803f984f":"train_df.describe(include='O')","e39d763b":"fig,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(train_df.corr(), ax=ax, annot=True, linewidths=0.05, fmt= '.2f',cmap=\"magma\")\nplt.show()","9145f6cb":"print(\"Before\", train_df.shape, test_df.shape)\n\ntrain_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\ncombine = [train_df, test_df]\n\nprint(\"After\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)","2d546320":"for obs in combine:\n    obs['Title'] = obs.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])","7cac6a99":"for obs in combine:\n    obs['Title'] = obs['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    obs['Title'] = obs['Title'].replace('Mlle', 'Miss')\n    obs['Title'] = obs['Title'].replace('Ms', 'Miss')\n    obs['Title'] = obs['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","090c2c53":"title_mapping = {\"Mr\": 1, \"Rare\": 2, \"Master\": 3, \"Miss\": 4, \"Mrs\": 5}\nfor obs in combine:\n    obs['Title'] = obs['Title'].map(title_mapping)\n    obs['Title'] = obs['Title'].fillna(0)\n\ntrain_df.head()","edf7076e":"train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.shape, test_df.shape","e7fe778c":"for obs in combine:\n    obs['Sex'] = obs['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\ntrain_df.head()","b173d4e2":"my_imputer = SimpleImputer()\ntrain_df['Age'] = pd.DataFrame(my_imputer.fit_transform(train_df['Age'].values.reshape(-1,1)))\ntest_df['Age'] = pd.DataFrame(my_imputer.fit_transform(test_df['Age'].values.reshape(-1,1)))","ae6026fd":"my_imputer_cat = SimpleImputer(strategy = 'most_frequent')\ntrain_df['Embarked'] = pd.DataFrame(my_imputer_cat.fit_transform(train_df['Embarked'].values.reshape(-1,1)))\ntest_df['Embarked'] = pd.DataFrame(my_imputer_cat.fit_transform(test_df['Embarked'].values.reshape(-1,1)))","9aad2292":"test_df['Fare'] = pd.DataFrame(my_imputer.fit_transform(test_df['Fare'].values.reshape(-1,1)))","fa70015d":"combine = [train_df, test_df]","eea5c9d0":"pd.crosstab(train_df['Survived'], train_df['Embarked'])","12d75625":"for obs in combine:\n    obs['Embarked'] = obs['Embarked'].map( {'S': 0, 'Q': 1, 'C': 2} ).astype(int)","9d71342e":"train_df.head()","f0588425":"X_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","6c4170c4":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","5d1904dc":"# Support Vector Machines\nfrom sklearn.svm import SVC, LinearSVC\n\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","0bfcbb22":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","8e6defb6":"from sklearn.naive_bayes import GaussianNB\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","5d3f265f":"from sklearn.linear_model import Perceptron\nperceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\nacc_perceptron","1c4867bd":"from sklearn.svm import  LinearSVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","65757f31":"from sklearn.tree import DecisionTreeClassifier\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","5bd36a77":"from sklearn.ensemble import RandomForestClassifier\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","3788f8da":"from sklearn.ensemble import GradientBoostingClassifier\nsgd = GradientBoostingClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","d8bc307c":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","5e9c76d3":"output = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\noutput.to_csv('submission.csv', index=False)","2ee25a86":"### Gaussian Naive Bayes","052802a9":"Then  I recode Title to be an ordinal variable: the higher is the values, the higher probability of survival:","ac079677":"# Building Models","9357ffe4":"### Logistic Regression","d2254db2":"# Model Evaluation","4ecb87c4":"### Convert Sex from string to a dummy variable:","0e040ac2":"### Imputation of Age:","e56deaf8":"### Add a new feature derived from the Name \nThese is also usefull info in the variable Name that can be exploited.","5d3f7ba0":"# Load the data","6247059b":"Ok, now we can drop Name...and PassengerId also.","b65d38f0":"Don't know yet what are SibSp, Parch, Fare and Embarked.","ed275b8f":"### Random Forest","a6d2df15":"The names are ok, let's proceed with the variable types.\n\nNumerical: Age, Fare (cont), SibSp, Parch (discrete).\n\nCategorical: Survived, Sex, Embarked (no order) + Pclass (ordinal) .\n\nMixed: Cabin, Ticket.\n\n","ced29001":"### Support Vector Machines","7e356237":"Some title are frequent, while other are rare. Let's combine all of the rare categories into one. Also, let's fix all typos which are visible, so we will have a smaller number of reasonable categories.","90492e9c":"### Converting Embarked to numeric:","30399dbf":"### Simple Imputation of Fare (test sample only)","f39e95d4":"### Decision Trees","d4f111ca":"### Linear SVC","3b6512a6":"### Stochastic Gradient Descent Classification","918b5a4e":"# Brief look at the data","5d198ba6":"### KNN","e16cd6e3":"Seemingly, the most important determinant of survival are: Pclass and Fare.\n\n# Data preparation\n### Delete what doesn't seem useful\nSince I don't really understand the value of Cabin and Ticket variables (and, in addition, Cabin has lots of missings), I'll start with those variables dropped out of samples.","ca56d273":"### Perceptron","8a9a754a":"### Simple Imputation of Embarked:\nhere we use 'most frequent' strategy, for string variable Embarked","fd7a889e":"# Descriptive statistics","691d4eb3":"So, there are massive missings of Age and Cabin, and a few of Embarked in the training sample; and, in the test sample, there are also many missings of Age and Cabin, and 1 missing of  Fare."}}