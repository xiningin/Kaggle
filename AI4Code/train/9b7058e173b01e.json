{"cell_type":{"79cdf25a":"code","19f7f022":"code","39feb441":"code","4903ea2e":"code","bbe0adab":"code","472a76c9":"code","1b32e6d1":"code","628b0310":"code","aefe490e":"code","2d3fe89d":"code","8e6eb69d":"code","e088ae79":"code","07221990":"code","b5b962ee":"code","77b7e0fe":"code","d98f65a7":"code","fe3ed287":"code","99a11a98":"code","f4f2b852":"code","27c93eab":"code","99a77ccc":"code","7d503ef2":"code","6bd5c0d1":"code","d13adbd8":"code","f1eb2bd2":"code","119a2646":"code","ca52232c":"code","9806dc57":"code","f37802f5":"code","c344c264":"code","e011e3c2":"code","5ae4c25f":"code","a9d45aa5":"code","93a310c3":"code","a0849bed":"markdown","5b927bb3":"markdown","b8f65073":"markdown","458a9119":"markdown","e0dc173e":"markdown"},"source":{"79cdf25a":"# Necessary libraries has imported\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso, ElasticNet\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error, mean_absolute_error, mean_squared_log_error","19f7f022":"#Load and Check Train and Test Data\ntrain_data = pd.read_csv('..\/input\/bike-sharing-demand\/train.csv')\ntest_data = pd.read_csv('..\/input\/bike-sharing-demand\/test.csv')","39feb441":"print('Train Shape: ', train_data.shape)\nprint('Test Shape: ', test_data.shape)","4903ea2e":"train_data.sample(5)","bbe0adab":"X = train_data.iloc[:, 0:9]\nY = train_data['count']\n\nprint('Train X Shape: ', X.shape)\nprint('Train Y Shape: ', Y.shape)\nprint('Test Shape: ', test_data.shape)","472a76c9":"# Check the missing values \ntrain_data.isna().sum(axis=0)","1b32e6d1":"sns.displot(Y, kde=True)","628b0310":"sns.displot(np.log(Y), kde=True)","aefe490e":"sns.histplot(X.season, bins=4)","2d3fe89d":"sns.displot(X.temp, kde=True)","8e6eb69d":"sns.displot(X.atemp, kde=True)","e088ae79":"sns.displot(X.windspeed, kde=True)","07221990":"sns.displot(X.humidity, kde=True)","b5b962ee":"from sklearn.base import BaseEstimator, TransformerMixin\nimport calendar\nfrom datetime import datetime\n\nclass ProcessDateTime(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        print('Transforming datetime...')\n        \n        x_copy = X.copy()\n        x_copy['month'] = x_copy.datetime.apply(lambda x : calendar.month_name[datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\").weekday()])\n        x_copy['weekday'] = x_copy.datetime.apply(lambda x : calendar.day_name[datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\").weekday()])\n        x_copy['hour'] = x_copy.datetime.apply(lambda x : datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\").hour)\n        x_copy['minute'] = x_copy.datetime.apply(lambda x : datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\").minute)\n        x_copy = x_copy.drop(['datetime'], axis=1)\n        \n        return x_copy","77b7e0fe":"pipeline = Pipeline([\n    ('datetime', ProcessDateTime())\n])\n\npipeline.fit_transform(X)","d98f65a7":"class ProcessSeasonWeather(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        print('Transforming season and weather...')\n        x_copy = X.copy()\n        x_copy['season'] = x_copy['season'].map({\n            1: 'Spring',\n            2: 'Summer',\n            3: 'Fall',\n            4: 'Winter'\n        })\n        x_copy['weather'] = x_copy['weather'].map({\n            1: \"Clear+FewClouds+PartlyCloudy,PartlyCloudy\",\n            2: \"Mist+Cloudy,Mist+BrokenClouds,Mist+FewClouds,Mist\",\n            3: \"LightSnow,LightRain+Thunderstorm+ScatteredClouds,LightRain+ScatteredClouds\",\n            4: \"HeavyRain+IcePallets+Thunderstorm+Mist,Snow+Fog\" \n        })\n        return x_copy","fe3ed287":"pipeline = Pipeline([\n    ('datetime', ProcessDateTime()),\n    ('seasonweather', ProcessSeasonWeather())\n])","99a11a98":"pipeline.fit_transform(X)","f4f2b852":"class DummyEncoding(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        print('Dummy encoding...')\n        x_copy = X.copy()\n        x_copy = pd.get_dummies(x_copy)\n        return x_copy\n\n    \nclass RemoveFeature(BaseEstimator, TransformerMixin):\n    def __init__(self, features=[]):\n        self._features = features\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        print('Removing features...')\n        x_copy = X.copy()\n        for f in self._features:\n            if f in x_copy.columns:\n                x_copy = x_copy.drop([f], axis=1)\n        return x_copy","27c93eab":"pipeline = Pipeline([\n    ('datetime', ProcessDateTime()),\n    ('seasonweather', ProcessSeasonWeather()),\n    ('dummyencode', DummyEncoding()),\n    ('removefeature', RemoveFeature(features=['windspeed']))\n])","99a77ccc":"pipeline.fit_transform(X)","7d503ef2":"from sklearn.preprocessing import StandardScaler","6bd5c0d1":"pipeline = Pipeline([\n    ('datetime', ProcessDateTime()),\n    ('seasonweather', ProcessSeasonWeather()),\n    ('dummyencode', DummyEncoding()),\n    ('removefeature', RemoveFeature(features=['windspeed'])),\n    ('scaler', StandardScaler())\n])","d13adbd8":"pipeline.fit_transform(X)","f1eb2bd2":"# Why we did not fit test data like we did form train data?\npipeline = Pipeline([\n    ('datetime', ProcessDateTime()),\n    ('seasonweather', ProcessSeasonWeather()),\n    ('dummyencode', DummyEncoding()),\n    ('removefeature', RemoveFeature(['windspeed'])),\n    ('scaler', MinMaxScaler())\n])\n\npipeline.fit(X)\nX = pipeline.transform(X)\nX_test = pipeline.transform(test_data)","119a2646":"print(X.shape)\nprint(X_test.shape)","ca52232c":"pd.DataFrame(X)","9806dc57":"lr = LinearRegression()\nsgd = SGDRegressor()\nrr = Ridge()\nls = Lasso()\nen = ElasticNet()","f37802f5":"import sklearn","c344c264":"sklearn.metrics.SCORERS.keys()","e011e3c2":"cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=27)\n\ngrid_ridge_lasso = {\n    'alpha': np.arange(0, 1, 0.05)\n}\n\ngrid_elastic = {\n    'alpha': np.arange(0, 1, 0.05),\n    'l1_ratio': np.arange(0, 1, 0.05)\n}\n\nlr_score = cross_val_score(lr, X, np.log(Y+0.0001), cv=cv, scoring='neg_mean_squared_log_error')\nsgd_score = cross_val_score(sgd, X, np.log(Y+0.0001), cv=cv, scoring='neg_mean_squared_log_error')\n\nrr_search = GridSearchCV(rr, grid_ridge_lasso, cv=cv, scoring='neg_mean_squared_log_error')\nrr_score = rr_search.fit(X, np.log(Y+0.0001))\n\nls_search = GridSearchCV(ls, grid_ridge_lasso, cv=cv, scoring='neg_mean_squared_log_error')\nls_score = ls_search.fit(X, np.log(Y+0.0001))\n\nen_search = GridSearchCV(en, grid_elastic, cv=cv, scoring='neg_mean_squared_log_error')\nen_score = en_search.fit(X, np.log(Y+0.0001))","5ae4c25f":"print(np.mean(lr_score))\nprint(np.mean(sgd_score))\n\nprint(rr_score.best_score_)\nprint(ls_score.best_score_)\nprint(en_score.best_score_)","a9d45aa5":"predictions = np.exp(rr_score.best_estimator_.predict(X_test))\npredictions = predictions.astype('int')","93a310c3":"pd.DataFrame({\n    'datetime': test_data.datetime,\n    'count': predictions\n}).to_csv('\/kaggle\/working\/submission_file.csv', index=False)","a0849bed":"**Exploratory Analysis**","5b927bb3":"**Try using StandardScaler instead of MinMaxScaler and see what happens**","b8f65073":"**Models**","458a9119":"**Preprocessing & Feature Engineering with Pipeline**","e0dc173e":"# Mim Rahman\n# ID: 181-35-2292"}}