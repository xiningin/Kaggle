{"cell_type":{"1ce5d552":"code","773632ab":"code","9c8b1b90":"code","696de9bc":"code","05a8de93":"code","0f9e3f63":"code","3b208fe9":"code","bf50aaff":"code","fd706e7e":"code","b5070151":"code","277a8dd8":"code","5008ab51":"code","b8796d81":"code","476e07f8":"code","b5941d88":"code","709d1ccf":"code","d29a52f5":"code","6ac3128c":"code","af81e0ad":"code","afb9d429":"code","d7ab3202":"markdown","9b8a32db":"markdown","70528f54":"markdown","a939660f":"markdown","6b5fe2d3":"markdown","ce87a76f":"markdown","9df2313e":"markdown","a7f5b7de":"markdown","8c5b4bc6":"markdown","d2c2d0b0":"markdown","ee26567f":"markdown","4b57f906":"markdown","ae30343c":"markdown","6337146c":"markdown","770a00ff":"markdown","a7414404":"markdown"},"source":{"1ce5d552":"## Initialisation ##\n# Import des librairies\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom math import *\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_auc_score, roc_curve\n\n# Import des donn\u00e9es\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\", sep=\",\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\", sep=\",\")\n\n# D\u00e9finition des fonctions\ndef plot_ROC(y_train,proba_train, legende = '', color = 'blue'):\n    fpr_train, tpr_train, _ = roc_curve(y_train, proba_train,drop_intermediate=False)\n    auc_train = round(roc_auc_score(y_train, proba_train),2)\n    plt.plot(fpr_train, tpr_train, label=legende + \" AUC = \" + str(auc_train),color=color)\n    plt.xlim(0,1)\n    plt.ylim(0,1)\n    plt.legend(loc=0)\n\n# Modification des param\u00e8tres d'affichage de Python\ndesired_width=320\npd.set_option('display.width', desired_width)\nnp.set_printoptions(linewidth=desired_width)\npd.set_option('display.max_columns',20)","773632ab":"print(train.columns)\n    # PassengerID : Num : Identifiant du passager\n    # Survival    : Num : Le passager \u00e0 surv\u00e9cu ou non : 0 = Non, 1 = Oui\n    # Pclass      : Num : Classe du ticket :\t1 = 1ere classe, 2 = Seconde classe, 3 = 3ieme classe\n    # Name        : Txt : Nom du passager\n    # Sex\t      : Txt : Sexe\n    # Age\t      : Num : Age en ann\u00e9e\n    # Sibsp       : Num : Nombre de relations horizontales (fr\u00e8res, soeurs, \u00e9poux...)\n    # Parch       : Num : Nombre de relations verticales (parents, enfants...)\n    # Ticket      : Txt : Num\u00e9ro du billet\n    # Fare        : Num : Tarif du billet\n    # Cabin       : Txt : Num\u00e9ro de cabine\n    # Embarked    : Txt : Port d'embarcation :\tC = Cherbourg, Q = Queenstown, S = Southampton\n\nprint(\"\\n ------------------------------------------------------------ \\n\")\nprint(train.info())\n    # On remarque des valeurs manquantes pour plusieurs variables :\n        # Age      : 177 NA\n        # Cabin    : 687 NA\n        # Embarked : 2 NA\n\nprint(\"\\n ------------------------------------------------------------ \\n\")\nprint(test.info())\n    # On remarque des valeurs manquantes pour plusieurs variables :\n        # Age   : 86 NA\n        # Cabin : 327 NA\n        # Fare  : 1 NA\n        \nprint(\"\\n ------------------------------------------------------------ \\n\")\nprint(train.describe())\n    # L'\u00e9chantillon de train contient les informations de 891 passagers, ce qui repr\u00e9sente 40% du nombre total de passagers \u00e0 bord du Titanic. Le taux de survie est de 38%, ce qui se rapproche du taux de survie reel \u00e0 bord du Titanic. L'\u00e9chantillon semble repr\u00e9sentatif. L'\u00e2ge moyen est de 29 ans, ce qui est plut\u00f4t jeune. Au moins 75% des passagers ont moins de 38 ans et 25% ont moins de 20 ans. Il y a donc une forte concentration de passagers dans la tranche d'age 20-38 ans (la moiti\u00e9)Plus de la moiti\u00e9 des passagers \u00e9taient en 3i\u00e8me classe. Au moins 75% des passagers voyageaient sans enfants et\/ou parents. Il y a une grosse disparit\u00e9 dans les prix des billets. Au moins 75% des passagers ont pay\u00e9 leur ticket 31\u20ac malgr\u00e9 un prix maximum de 512\u20ac.\n\nprint(\"\\n ------------------------------------------------------------ \\n\")\nprint(train.describe(include=['O']))\n    # Il n'y a pas de doublons sur les noms des passagers. Il y avait en majorit\u00e9 des hommes \u00e0 bord dans notre \u00e9chantillon (577 sur 891 passagers, soit 65%) Il y a des doublons dans les tickets, les cabines et les quais d'embarquements. Il y a donc des passagers qui partageaient la m\u00eame cabine.","9c8b1b90":"g = sns.FacetGrid(train, col='Survived')\ng.map(plt.hist, 'Age', bins=20)\n    # On constate que les enfants (de moins de 4 ans) ont un fort taux de survie. De la m\u00eame mani\u00e8re, les personnes ag\u00e9es ont surv\u00e9cue. Il semblerait que les passagers ont favoris\u00e9 l'\u00e9vacuation des personnes plus fragiles en priorit\u00e9. En revanche, les 15-35 ans ont un faible  taux de survie par rapport au nombre de passagers de cette tranche.\n\ngrid = sns.FacetGrid(train, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()\n    # La 3i\u00e8me classe est la plus repr\u00e9sent\u00e9e mais \u00e9galement celle qui a le moins surv\u00e9cu. Les enfants de la 2i\u00e8me classe sont tr\u00e8s peu nombreux mais ont un fort taux de survie. Les passagers de la 1\u00e8re classe sont les moins repr\u00e9sent\u00e9s mais \u00e9galement ceux qui ont le plus surv\u00e9cu. Les classes contiennent une distribution bien r\u00e9partie sur l'\u00e2ge.\n\ngrid = sns.FacetGrid(train, row='Embarked', size=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()\n    # En g\u00e9n\u00e9ral les femmes ont un meilleur taux de survie que les hommes (\u00e0 l'exception du port d'embarquement C) Les 1\u00e8re et 2i\u00e8me classes ont un meilleur taux de survie que la 3i\u00e8me classe.\n\ngrid = sns.FacetGrid(train, row='Embarked', col='Survived', size=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()\n    # Les passagers ayant pay\u00e9 leur ticket plus ch\u00e8re ont un plus fort taux de survie. On remarque des diff\u00e9rences de prix des billets entre les diff\u00e9rents ports d'embarquement.","696de9bc":"## Transformation des donn\u00e9es ##\n\n# Suppression des variables Ticket et Cabin\ntrain = train.drop(['Ticket', 'Cabin'], axis=1)\ntest = test.drop(['Ticket', 'Cabin'], axis=1)\n    # Dans un premier temps on va supprimer les variables Ticket et Cabin car elles contiennent trop de valeurs manquantes et de doublons.\n\nDATA = [train, test]\n    # On rassemble les deux \u00e9chantillons de donn\u00e9es dans une liste pour appliquer les transformations une seule fois dans une boucle.","05a8de93":"# Extraction du Titre \nfor echantillon in DATA:\n    echantillon['Titre'] = echantillon.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n    # Extraction du titre dans le nom complet des passagers.\n    \npd.crosstab(train['Titre'], train['Sex'])\n    # On regarde la distribution des sexes pour chacun des titres.\n\nfor echantillon in DATA:\n    echantillon['Titre'] = echantillon['Titre'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer'\n                                                         , 'Dona'], 'Autre')\n    echantillon['Titre'] = echantillon['Titre'].replace('Mlle', 'Miss')\n    echantillon['Titre'] = echantillon['Titre'].replace('Ms', 'Miss')\n    echantillon['Titre'] = echantillon['Titre'].replace('Mme', 'Mrs')\n    # On rassembles certains titres pour d\u00e9duire le nombre de classes. Certains titres comptaient que tr\u00e8s peu de personnes. Il n'est donc\n    # pas pertinent de les conserver ainsi.\n    \ntrain[['Titre', 'Survived']].groupby(['Titre'], as_index=False).mean().sort_values(['Survived'], ascending = False)\n    # On retrouve ici encore un taux de survie plus fort chez les femme. S'en suit ensuite les hommes avec des titres plus importants.\n\nTitre_Num = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor echantillon in DATA:\n    echantillon['Titre'] = echantillon['Titre'].map(Titre_Num)\n    echantillon['Titre'] = echantillon['Titre'].fillna(0)\n    echantillon['Titre'] = echantillon['Titre'].astype(int)\n    # On remplace ensuite les donn\u00e9es textes par des donn\u00e9es num\u00e9rique pour que les mod\u00e8les aient une meilleur interpr\u00e9tation. La classe 0 est une classe sp\u00e9cifique pour les passagers n'ayant pas de Titre.\n\nprint(train.head())\n\ntrain = train.drop(['Name', 'PassengerId'], axis=1)\ntest = test.drop(['Name'], axis=1)\nDATA = [train, test]\n    # On peut \u00e0 pr\u00e9sent supprimer la variable Name. On en profite pour supprimer la variable PassengerID de l'\u00e9chantillon de train car elle n'est pas utile. Il faut toutefois conserver cette variable dans le test pour les soumission au Kaggle.","0f9e3f63":"# Transformation en num\u00e9rique\n\nfor echantillon in DATA:\n    echantillon['Sex'] = echantillon['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n    # Conversion de la variable Sex en cat\u00e9gories num\u00e9riques\n\n# La variable Embarked contient 2 valeurs manquantes. Nous allons les compl\u00e9ter par la modalit\u00e9 la plus pr\u00e9sente dans l'\u00e9chantillon train.\nfreq_Embarked = train.Embarked.dropna().mode()[0]\nfreq_Embarked\n    # Le port d'embarquement le plus pr\u00e9sent dans l'\u00e9chantillon train est S : Southampton\nfor echantillon in DATA:\n    echantillon['Embarked'] = echantillon['Embarked'].fillna(freq_Embarked)\n    echantillon['Embarked'] = echantillon['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n    # On convertie ensuite la variable Embarked en variable cat\u00e9gorielle num\u00e9rique.\nprint(train.head())","3b208fe9":"# Etude des corr\u00e9lations \n\n    # A pr\u00e9sent que toutes les variables sont au format num\u00e9rique, nous pouvons regarder de plus pr\u00e8s les corr\u00e9lations.\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('orr\u00e9lations de Pearson', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.5, square=True, cmap=colormap, linecolor='white', annot=True)\n    # On observe ainsi une forte corr\u00e9lation entre le sexe et le Titre. Ce qui est coh\u00e9rent avec l'hypoth\u00e8se pos\u00e9e pr\u00e9c\u00e9demment. De la m\u00eame mani\u00e8re, le prix du billet est fortement corr\u00e9l\u00e9 \u00e0 la classe de celui-ci. Encore une fois, ce r\u00e9sultat est coh\u00e9rent. On observe \u00e9galement une forte corr\u00e9lation entre le sexe et la survie ou non du passager. Ceci v\u00e9rifie notre conjecture \u00e9tablie au d\u00e9but de l'analyse. On remarque une corr\u00e9lation entre les variables Age, Pclass et Titre. ","bf50aaff":"# Nous allons donc utiliser ces corr\u00e9lations pour completer les valeurs manquantes de la variable Age. Toutefois, afin de simplifier les choses, nous allons utiliser la variable Sexe qui contient moins de modalit\u00e9s que la variable Titre. Ces deux variables \u00e9tant dortement corr\u00e9l\u00e9es.\n\nMat_age = np.zeros((2,3))\n    # Matrice des ages m\u00e9dians par croisement de Pclass et Sex\nfor echantillon in DATA:\n    for sexe in range(0, 2):\n        for classe in range(0, 3):\n            df = echantillon[(echantillon['Sex'] == sexe) & (echantillon['Pclass'] == classe + 1)]['Age'].dropna()\n            Mat_age[sexe, classe] = df.median()\n    for sexe in range(0, 2):\n        for classe in range(0, 3):\n            echantillon.loc[(echantillon.Age.isnull()) & (echantillon.Sex == sexe) & (echantillon.Pclass == classe + 1), 'Age'] = Mat_age[sexe, classe]\n    echantillon['Age'] = echantillon['Age'].astype(int)\n\n    # A pr\u00e9sent on va convertire la variable Age en variable cat\u00e9gorielle num\u00e9rique en cr\u00e9ant des classes d'age. Les mod\u00e8les seront plus performant de cette mani\u00e8re.\nplt.hist(train.Age, density = True)\nfor echantillon in DATA:\n    echantillon.loc[ echantillon['Age'] <= 18, 'Age'] = 0\n    echantillon.loc[(echantillon['Age'] > 18) & (echantillon['Age'] <= 25), 'Age'] = 1\n    echantillon.loc[(echantillon['Age'] > 25) & (echantillon['Age'] <= 32), 'Age'] = 2\n    echantillon.loc[(echantillon['Age'] > 32) & (echantillon['Age'] <= 48), 'Age'] = 3\n    echantillon.loc[echantillon['Age'] > 48 , 'Age'] = 4\ntrain[['Age','Survived']].groupby('Age').count()\n    # La r\u00e9partition des passagers par tranche d'\u00e2ge n'est pas d\u00e9s\u00e9quilibr\u00e9e. Nous pouvons donc faire un premier test avec 5 tranches d'\u00e2ge.\n\n# On remplace la valeur manquante du prix du billet dans l'\u00e9chantillon test par la m\u00e9diane de la variable.\ntest['Fare'].fillna(test['Fare'].dropna().median(), inplace=True)\nprint(test.info())\n\n# On va a convertire la variable Fare en variable cat\u00e9gorielle en cr\u00e9ant des classes de prix.\nprint(\"\\n ------------------------------------------------------------ \\n\")\nprint(train.Fare.describe())\n    # Nous allons cr\u00e9er des classes au niveau des quartiles. Nous allons \u00e9galement isoler les 10% des billets les plus ch\u00e8re pour voir si il y a une diff\u00e9rence de survie entre les billets les plus ch\u00e8res et les autres.\nfor echantillon in DATA:\n    echantillon.loc[echantillon['Fare'] <= 7.91, 'Fare'] = 0\n    echantillon.loc[(echantillon['Fare'] > 7.91) & (echantillon['Fare'] <= 14.454), 'Fare'] = 1\n    echantillon.loc[(echantillon['Fare'] > 14.454) & (echantillon['Fare'] <= 31), 'Fare'] = 2\n    echantillon.loc[(echantillon['Fare'] > 31) & (echantillon['Fare'] <= 77.9583), 'Fare'] = 3\n    echantillon.loc[echantillon['Fare'] > 77.9583, 'Fare'] = 4\n    echantillon['Fare'] = echantillon['Fare'].astype(int)\n        \nprint(\"\\n ------------------------------------------------------------ \\n\")\nprint(train[['Survived']].groupby(train['Fare']).mean())\n    # On remarque que le taux de survie est plus important pour les passagers appartenant \u00e0 la classe de prix la plus ch\u00e8re. On peut conjecturer que cette classe sera discriminante dans les mod\u00e8les.\n    \n            \nprint(\"\\n ------------------------------------------------------------ \\n\")\nprint(train.head())","fd706e7e":"# Cr\u00e9ation de nouvelles variables\nfor echantillon in DATA:\n    echantillon['Famille'] = echantillon['SibSp'] + echantillon['Parch']\n    # On rassemble les deux variables SibSP et Parch pour conna\u00eetre la taille de la famille du passager. Si Famille = 0 alors la personne a embarqu\u00e9 seule sur le Titanic.\n\ntrain[['Famille', 'Survived']].groupby(['Famille'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n    # On remarque que les passager ayant embarqu\u00e9 avec 3 personnes ou moins un meilleur taux de survie.\ntrain[['Famille', 'Survived']].groupby(['Famille'], as_index=False).count()\n    # On remarque que la r\u00e9partition par classe est tr\u00e8s in\u00e9gale. Afin de palier \u00e0 ce probl\u00e8me, nous allons rassembler des classes.\n\nfor echantillon in DATA:\n    echantillon.loc[echantillon['Famille'] == 0, 'Famille'] = 0\n    echantillon.loc[(echantillon['Famille'] > 0) & (echantillon['Famille'] <= 2), 'Famille'] = 1\n    echantillon.loc[(echantillon['Famille'] >= 3) , 'Famille'] = 2\n    echantillon['Fare'] = echantillon['Fare'].astype(int)\nprint(train.head())\n    # On peut \u00e0 pr\u00e9sent supprimer les variables SibSP et Parch.\n\ntrain = train.drop(['Parch', 'SibSp'], axis=1)\ntest = test.drop(['Parch', 'SibSp'], axis=1)\nDATA = [train, test]","b5070151":"# V\u00e9rifications des \u00e9chantillons \n    # Maintenant que les donn\u00e9es ont \u00e9t\u00e9 pr\u00e9alablement trait\u00e9es, nous faisons les derni\u00e8res v\u00e9rifications avant la phase de mod\u00e9lisation.\nprint(train.info())\nprint(\"\\n ------------------------------------------------------------ \\n\")\n\nprint(train.describe())\nprint(\"\\n ------------------------------------------------------------ \\n\")\n\nprint(train.head())\nprint(\"\\n ------------------------------------------------------------ \\n\")\n\nprint(test.info())\nprint(\"\\n ------------------------------------------------------------ \\n\")\nprint(test.describe())\nprint(\"\\n ------------------------------------------------------------ \\n\")\nprint(test.head())\n    # Toutes les variables sont cat\u00e9gorielles et num\u00e9riques. Il n'y a plus de valeurs manquantes","277a8dd8":"X_train = train.drop(\"Survived\", axis=1)\nY_train = train[\"Survived\"]\nX_test  = test.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","5008ab51":"## R\u00e9gression Logistique ##\n    # Deux possibilit\u00e9s s'offrent \u00e0 nous pour la regression logistique. La premi\u00e8re est la fonction LogisticRegression du package Scikit-Learn. La seconde est la fonction Logit du package Statsmodels.\n\n# Package Scikit Learn : \n    # Lien de l'explication de la fonction sur le package Sk-learn : https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LogisticRegression.html\nreg_sk = LogisticRegression()\nreg_sk.fit(X_train, Y_train)\nprint(\"Accuracy de la R\u00e9gression Logistique via Scikit Learn : %s\"%(round(reg_sk.score(X_train, Y_train)*100,2)))\nprint(\"\\n ------------------------------------------------------------ \\n\")\nplot_ROC(Y_train, [x[1] for x in reg_sk.predict_proba(X_train)], 'Logistique Sk')\n    # Ce mod\u00e8le obtient un AUC de 0.87 sur l'\u00e9chantillon train.\nsubmission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": reg_sk.predict(X_test)})\nsubmission.to_csv('Soumission_Logistic_sk.csv', index=False)\n    # Ce mod\u00e8le donne un score que l'\u00e9chantillon test de 77.99%.\n\n# Avec le Package Statsmodels :\n    # Lien de l'explication de la fonction sur le package Statsmodels : https:\/\/www.statsmodels.org\/stable\/generated\/statsmodels.discrete.discrete_model.Logit.html\nreg_sm = sm.Logit(Y_train, X_train)\nreg_sm = reg_sm.fit()\nY_pred_sm = round(reg_sm.predict(X_train), 0)\nprint(\"\\n ------------------------------------------------------------ \\n\")\nprint(\"Accuracy de la R\u00e9gression Logistique via Statsmodels : %s\"%(round(sum(Y_pred_sm == Y_train)\/len(Y_train)*100,2)))\nplot_ROC(Y_train, [x for x in reg_sm.predict(X_train)], 'Logistique SM', 'red')\n    # Ce mod\u00e8le obtient un AUC de 0.87 sur l'\u00e9chantillon train.\nprint(\"\\n ------------------------------------------------------------ \\n\")\nprint(reg_sm.summary2())\n    # La variable Age n'est pas significative. Nous allons essayer de la retirer dans le mod\u00e8le.\n    \nreg_sm_cust = sm.Logit(Y_train, X_train.drop(['Age'], axis = 1))\nreg_sm_cust = reg_sm_cust.fit()\nY_pred_sm_cust = round(reg_sm_cust.predict(X_train.drop(['Age'], axis = 1)), 0)\nprint(\"\\n ------------------------------------------------------------ \\n\")\nprint(\"Accuracy de la R\u00e9gression Logistique via Statsmodels sans la variable Age : %s\"%(round(sum(Y_pred_sm_cust == Y_train)\/len(Y_train)*100,2)))\nprint(\"\\n ------------------------------------------------------------ \\n\")\nprint(reg_sm_cust.summary2())\n    # A pr\u00e9sent toutes les variables son significatives.\nplot_ROC(Y_train, [x for x in reg_sm_cust.predict(X_train.drop(['Age'], axis = 1))], 'Custome SM', 'green')\n    # Ce mod\u00e8le obtient un AUC de 0.87 sur l'\u00e9chantillon train. L'AUC ne change pas en supprimant la variable Age On remarque toutefois que le mod\u00e8le perd en performance sur l'\u00e9chantillon de train via le crit\u00e8re Accuracy. La variable Age contribue donc au mod\u00e8le malgr\u00e9 sa non significativit\u00e9. Nous faisons donc le choix de la conserver.\n\nsubmission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": round(reg_sm.predict(X_test),0).astype(int)})\nsubmission.to_csv('Soumission_Logistic_sm.csv', index=False)\n    # Ce mod\u00e8le donne un score que l'\u00e9chantillon test de 77.99%.","b8796d81":"## Arbre de d\u00e9cision ##\n    # Lien de l'explication de la fonction sur le package Sk-learn : https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.DecisionTreeClassifier.html\narbre = DecisionTreeClassifier()\narbre.fit(X_train, Y_train)\nprint(\"Accuracy de l'Arbre de d\u00e9cision : %s\"%(round(arbre.score(X_train, Y_train)*100,2)))\nplot_ROC(Y_train, [x[1] for x in arbre.predict_proba(X_train)])\n    # Ce mod\u00e8le obtient un AUC de 0.96 sur l'\u00e9chantillon train.\nsubmission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": arbre.predict(X_test)})\nsubmission.to_csv('Soumission_Arbre.csv', index=False)","476e07f8":"## Random Forest ##\n    # Lien de l'explication de la fonction sur le package Sk-learn : https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html\nrandom_forest = RandomForestClassifier()\nrandom_forest.fit(X_train, Y_train)\nprint(\"Accuracy du Random Forest : %s\"%(round(random_forest.score(X_train, Y_train)*100,2)))\nprint(\"\\n ------------------------------------------------------------ \\n\")\nplot_ROC(Y_train, [x[1] for x in random_forest.predict_proba(X_train)], 'Random Forest')\n    # Ce mod\u00e8le obtient un AUC de 0.95 sur l'\u00e9chantillon train. A premi\u00e8re vue, le mod\u00e8le de random forest semble faire un moins bon score que l'arbre de d\u00e9cision. Toutefois, n'oublions pas que l'arbre de d\u00e9cision \u00e9tait en sur-apprentissage sur nos donn\u00e9es. Nous allons v\u00e9rifier le score du mod\u00e8le random forest avec les param\u00e8tres par d\u00e9faut sur l'\u00e9chantillon test.\nsubmission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": random_forest.predict(X_test)})\nsubmission.to_csv('Soumission_RF.csv', index=False)\n    # Ce mod\u00e8le donne un score que l'\u00e9chantillon test de 77.03%. Le mod\u00e8le obtient donc de meilleures performances sur l'\u00e9chantillon test. Il est moins en sur-apprentissage que l'arbre de d\u00e9cision. On constate toutefois que le random forest avec les param\u00e8tres par d\u00e9faut ne performe pas la r\u00e9gression logistique sur l'\u00e9chantillon test. Essayons d'optimiser ses param\u00e8tres via un grid-search.\n\n# Mise en place du GRID-SEARCH :\nparams = {\"parametres\" : None, \"AUC\" : 0, \"Acc\" : 0, \"Soumission\" : None}\nfor n_est in [10, 100, 500, 1000] :\n    for max_feat in [int(x) for x in np.r_[int(sqrt(X_train.shape[1])):X_train.shape[1]:3j]] :\n        for max_dep in [int(x) for x in np.r_[1:int(sqrt(X_train.shape[0])):5j]] :\n            RF = RandomForestClassifier(n_estimators=n_est, max_depth=max_dep, max_features=max_feat)\n            RF.fit(X_train, Y_train)\n            if round(RF.score(X_train, Y_train) * 100, 2) > params['Acc'] and round(roc_auc_score(Y_train, [x[1] for x in RF.predict_proba(X_train)]),2) > params['AUC']:\n                params['parametres'] = [n_est, max_feat, max_dep]\n                params['AUC'] = round(roc_auc_score(Y_train, [x[1] for x in RF.predict_proba(X_train)]),2)\n                params['Acc'] = round(RF.score(X_train, Y_train) * 100, 2)\n                params['Soumission'] = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": RF.predict(X_test)})\n                print('Accuracy am\u00e9lior\u00e9e : %s'%params['Acc'])\n\nprint(\"\\n ------------------------------------------------------------ \\n\")\nprint(\"Le meilleur mod\u00e8le \u00e0 l'issue du grid search utilise les param\u00e8tres suivants : %s et obtient en score un AUC de %s et une accuracy de %s\"%(params['parametres'], params['AUC'], params['Acc']))\nparams['Soumission'].to_csv('Soumission_RF_cust.csv', index=False)\n    # On fait la soumission pour conna\u00eetre le score sur l'\u00e9chantillon test. On obtient un score de 77.55% ce qui am\u00e9liore par rapport au mod\u00e8le avec les param\u00e8tres par d\u00e9faut. On constate toutefois que le mod\u00e8le ne performe pas la r\u00e9gression logistique.\n\n","b5941d88":"## KPPV - Plus proches voisins ##\n    # Lien de l'explication de la fonction sur le package Sk-learn : https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.KNeighborsClassifier.html\nknn = KNeighborsClassifier()\nknn.fit(X_train, Y_train)\nprint(\"Accuracy des 5 plus proches voisins : %s\"%(round(knn.score(X_train, Y_train)*100,2)))\nprint(\"\\n ------------------------------------------------------------ \\n\")\nplot_ROC(Y_train, [x[1] for x in knn.predict_proba(X_train)], 'KNN')\n    # Ce mod\u00e8le obtient un AUC de 0.92 sur l'\u00e9chantillon train.\nsubmission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": knn.predict(X_test)})\nsubmission.to_csv('Soumission_Knn1.csv', index=False)\n    # Ce mod\u00e8le donne un score que l'\u00e9chantillon test de 77.03%.\n\n# Mise en place du GRID-SEARCH :\nparams = {\"n\" : None, \"AUC\" : 0, \"Acc\" : 0, \"Soumission\" : None}\nfor n in [2, 3, 4, 5, 7, 10, 15] :\n    knn = KNeighborsClassifier(n_neighbors=n)\n    knn.fit(X_train, Y_train)\n    if round(knn.score(X_train, Y_train) * 100, 2) >= params['Acc'] and round(roc_auc_score(Y_train, [x[1] for x in knn.predict_proba(X_train)]),2) >= params['AUC']:\n        params['n'] = n\n        params['AUC'] = round(roc_auc_score(Y_train, [x[1] for x in knn.predict_proba(X_train)]),2)\n        params['Acc'] = round(knn.score(X_train, Y_train) * 100, 2)\n        params['Soumission'] = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": knn.predict(X_test)})\n        print('Accuracy am\u00e9lior\u00e9e : %s'%params['Acc'])\n\nprint(\"\\n ------------------------------------------------------------ \\n\")\nprint(\"Le meilleur mod\u00e8le \u00e0 l'issue du grid search utilise n = %s et obtient en score un AUC de %s et une Accuracy de %s\"%(params['n'], params['AUC'], params['Acc']))\nparams['Soumission'].to_csv('Soumission_Knn_cust.csv', index=False)\n    # Le meilleur mod\u00e8le de Knn obtient un score de 75.11% sur l'\u00e9chantillon test, ce qui est inf\u00e9rieur au mod\u00e8le par d\u00e9faut qui utilise en param\u00e8tre n = 5 voisins. On constat donc que notre mod\u00e8le est en sur-apprentissage.","709d1ccf":"## Gaussian Naive Bayes ##\n    # Lien de l'explication de la fonction sur le package Sk-learn : https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.naive_bayes.GaussianNB.html\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nprint(\"Accuracy de la Gaussian Naive Bayes : %s\"%(round(gaussian.score(X_train, Y_train)*100,2)))\nplot_ROC(Y_train, [x[1] for x in gaussian.predict_proba(X_train)], 'Gaussian Naive Bayes')\n    # Ce mod\u00e8le obtient un AUC de 0.84 sur l'\u00e9chantillon train.\nsubmission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": gaussian.predict(X_test)})\nsubmission.to_csv('Soumission_Gaussian.csv', index=False)\n    # Ce mod\u00e8le donne un score que l'\u00e9chantillon test de 73.20%. Il ne permet donc pas de performer la r\u00e9gression logistique.","d29a52f5":"## Support Vector Machine ##\n    # Lien de l'explication de la fonction sur le package Sk-learn : https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.SVC.html\nsvc = SVC(probability=True)\nsvc.fit(X_train, Y_train)\nprint(\"Accuracy du SVM : %s\"%(round(svc.score(X_train, Y_train)*100,2)))\nprint(\"\\n ------------------------------------------------------------ \\n\")\nplot_ROC(Y_train, [x[1] for x in svc.predict_proba(X_train)], 'SVM')\n    # Ce mod\u00e8le obtient un AUC de 0.89 sur l'\u00e9chantillon train.\nsubmission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": svc.predict(X_test)})\nsubmission.to_csv('Soumission_SVM.csv', index=False)\n    # Ce mod\u00e8le obtient un score de 78.94 % sur l'\u00e9chantillon test. Il performe donc la regression malgr\u00e9 les param\u00e8tres par d\u00e9faut. Nous allons donc essayer d'am\u00e9liorer ce mod\u00e8le en le customisant.\n\n# Mise en place du GRID-SEARCH :\nparams = {\"n\" : None, \"AUC\" : 0, \"Acc\" : 0, \"Soumission\" : None}\nfor kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n    for gamma in ['auto', 'scale']:\n        for c in [0.5, 0.8, 1, 1.2, 1.5]:\n            svc_cust = SVC(probability=True, C = c, gamma = gamma, kernel = kernel)\n            svc_cust.fit(X_train, Y_train)\n        if round(svc_cust.score(X_train, Y_train) * 100, 2) > params['Acc'] and round(roc_auc_score(Y_train, [x[1] for x in svc_cust.predict_proba(X_train)]),2) > params['AUC']:\n            params['parametres'] = [kernel, gamma, c]\n            params['AUC'] = round(roc_auc_score(Y_train, [x[1] for x in svc_cust.predict_proba(X_train)]),2)\n            params['Acc'] = round(svc_cust.score(X_train, Y_train) * 100, 2)\n            params['Soumission'] = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": svc_cust.predict(X_test)})\n            print('Accuracy am\u00e9lior\u00e9e : %s'%params['Acc'])\n            \nprint(\"\\n ------------------------------------------------------------ \\n\")\nprint(\"Le meilleur mod\u00e8le \u00e0 l'issue du grid search utilise n = %s et obtient en score un AUC de %s et une Accuracy de %s\"%(params['parametres'], params['AUC'], params['Acc']))\nparams['Soumission'].to_csv('Soumission_SVM_cust.csv', index=False)\n    # Le score sur l'\u00e9chantillon test du meilleur mod\u00e8le SVM est de 79.42%. On am\u00e9liore donc le score de notre mod\u00e8le apr\u00e8s optimisation des param\u00e8tre.","6ac3128c":"## Perceptron ##\n    # Lien de l'explication de la fonction sur le package Sk-learn : https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.Perceptron.html\nperceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nprint(\"Accuracy du Perceptron : %s\"%(round(perceptron.score(X_train, Y_train)*100,2)))\nprint(\"\\n ------------------------------------------------------------ \\n\")\n    # La fonction predict_proba n'est pas disponible pour ce mod\u00e8le.\nsubmission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": perceptron.predict(X_test)})\nsubmission.to_csv('Soumission_Perceptron.csv', index=False)\n    # Nous obtenons un score de 79.42%. sur l'\u00e9chantillon de test avec les param\u00e8tres par d\u00e9faut.\n\n# Mise en place du GRID-SEARCH :\nparams = {\"parametres\" : None, \"Acc\" : 0, \"Soumission\" : None}\nfor penality in ['l2','l1','elasticnet']:\n    for validation_frac in [0.1, 0.2, 0.3, 0.4]:\n        for alpha in [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]:\n            for max_iter in [10,100,1000,5000]:\n                for tol in [0.0001, 0.0005, 0.001, 0.005, 0.01]:\n                    perceptron = Perceptron(early_stopping= True, penalty=penality,\n                                            validation_fraction=validation_frac, max_iter=max_iter, tol=tol)\n                    perceptron.fit(X_train, Y_train)\n                    if round(perceptron.score(X_train, Y_train) * 100, 2) > params['Acc'] :\n                        params['parametres'] = [penality, validation_frac, alpha, max_iter, tol]\n                        params['Acc'] = round(perceptron.score(X_train, Y_train) * 100, 2)\n                        params['Soumission'] = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": perceptron.predict(X_test)})\n                        print('Accuracy am\u00e9lior\u00e9e : %s'%params['Acc'])\n                        \nprint(\"\\n ------------------------------------------------------------ \\n\")\nprint(\"Le meilleur mod\u00e8le \u00e0 l'issue du grid search utilise les param\u00e8tres : %s et obtient en score et une Accuracy de %s\"%(params['parametres'], params['Acc']))\nparams['Soumission'].to_csv('Soumission_SVM_cust.csv', index=False)\n    # Le meilleur mod\u00e8le apr\u00e8s grid-search obtient un score de 75.11% sur l'\u00e9chantillon test malgr\u00e9 une meilleure accuracy sur l'\u00e9chantillon train. Il semblerait donc que le mod\u00e8le soit en surapprentissage.\n    ","af81e0ad":"def cut_seuil (proba, seuil):\n    if proba > seuil :\n        return 1\n    else :\n        return 0\n\n# Mod\u00e8le SVM\nProba_SVM = [x[1] for x in svc.predict_proba(X_train)]\nliste_acc = []\nfor seuil in [x * 0.01 for x in range(100)]:\n    Pred = [cut_seuil(x, seuil) for x in Proba_SVM]\n    liste_acc.append(round(sum(Pred == Y_train)\/len(Y_train)*100,2))\ndf_acc = pd.DataFrame({\"seuil\" : [x * 0.01 for x in range(100)], 'Acc_SVM' : liste_acc})\n\nplt.plot(df_acc.seuil, df_acc.Acc_SVM , label='SVM',color='blue')\nplt.legend(loc=0)\nprint(df_acc.loc[df_acc.Acc_SVM == max(df_acc.Acc_SVM)])\n\n    # 5 seuil nous permettent de maximiser l'accuracy sur l'\u00e9chantillon de train. Nous pouvons faire une soumission en utilisant chacun de ces seuils pour constater la diff\u00e9rence sur le test.\npd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": [cut_seuil(x[1], 0.57) for x in svc.predict_proba(X_test)]}).to_csv('Soumission_SVM_057.csv', index=False)\npd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": [cut_seuil(x[1], 0.58) for x in svc.predict_proba(X_test)]}).to_csv('Soumission_SVM_058.csv', index=False)\npd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": [cut_seuil(x[1], 0.59) for x in svc.predict_proba(X_test)]}).to_csv('Soumission_SVM_059.csv', index=False)\npd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": [cut_seuil(x[1], 0.60) for x in svc.predict_proba(X_test)]}).to_csv('Soumission_SVM_060.csv', index=False)\npd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": [cut_seuil(x[1], 0.62) for x in svc.predict_proba(X_test)]}).to_csv('Soumission_SVM_062.csv', index=False)\n\n\n# Mod\u00e8le r\u00e9gression logistique\nProba_Reg = [x[1] for x in reg_sk.predict_proba(X_train)]\nliste_acc = []\nfor seuil in [x * 0.01 for x in range(100)]:\n    Pred = [cut_seuil(x, seuil) for x in Proba_Reg]\n    liste_acc.append(round(sum(Pred == Y_train)\/len(Y_train)*100,2))    \ndf_acc = pd.DataFrame({\"seuil\" : [x * 0.01 for x in range(100)], 'Acc_Reg' : liste_acc})\n\nprint(\"\\n ------------------------------------------------------------ \\n\")\nplt.plot(df_acc.seuil, df_acc.Acc_Reg ,color='red', label='Regression Logistique')\nplt.legend(loc=0)\nprint(df_acc.loc[df_acc.Acc_Reg == max(df_acc.Acc_Reg)])\n    # 4 seuils nous permettent de maximiser l'accuracy sur l'\u00e9chantillon de train. Nous pouvons faire une soumission en utilisant chacun de ces seul pour constater la diff\u00e9rence sur le test.\n\npd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": [cut_seuil(x[1], 0.49) for x in svc.predict_proba(X_test)]}).to_csv('Soumission_reg_049.csv', index=False)\npd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": [cut_seuil(x[1], 0.52) for x in svc.predict_proba(X_test)]}).to_csv('Soumission_reg_052.csv', index=False)\npd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": [cut_seuil(x[1], 0.53) for x in svc.predict_proba(X_test)]}).to_csv('Soumission_reg_053.csv', index=False)\npd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": [cut_seuil(x[1], 0.65) for x in svc.predict_proba(X_test)]}).to_csv('Soumission_reg_065.csv', index=False)","afb9d429":"from lime.lime_tabular import LimeTabularExplainer\n\ndf_poids = pd.DataFrame({'variable': X_train.columns})\nexplainer = LimeTabularExplainer(\n    training_data=X_train\n    , mode='classification'\n    , feature_names=X_train.columns\n    , discretize_continuous=False\n)\n# Boucle sur les ligne du dataframe pour appliquer LIME par ligne\npoids = pd.DataFrame(data=[],columns = X_train.columns)\nfor idx, line in X_train.iterrows():\n    exp = explainer.explain_instance(\n        data_row=line\n        , predict_fn=svc.predict_proba \n            # Fonction de pr\u00e9diction du mod\u00e8le \u00e0 analyser.\n    )\n    temp = {i[0]: i[1] for i in exp.as_map()[1]}\n    new_line = [temp[x] if x in temp.keys() else None for x in range(len(X_train.columns))]\n    poids = pd.concat([poids, pd.DataFrame(data=[new_line],columns= X_train.columns)])\npoids = poids.mean().reset_index()\npoids.columns = ['variable','poids']\ndf_poids = df_poids.merge(poids, on='variable',how='left')\n\nprint(df_poids)","d7ab3202":"# Machine Learning, m\u00e9thodes usuelles en Python\n*Auteur : Cheriaux Damien*\n\nIl existe beaucoup de mod\u00e8les en machine learning et chacun d'eux peut-\u00eatre utilis\u00e9 differemment selon le contexte de l'\u00e9tude et les donn\u00e9es. Il peut donc \u00eatre difficile de s'y retrouver au d\u00e9but. L'objectif de ce Notebook n'est pas de r\u00e9aliser un score parfait sur l'\u00e9chantillon de test mais plut\u00f4t d'adopter une approche ***pratique et p\u00e9dagogique*** sur l'utilisation des diff\u00e9rents mod\u00e8les de machine learning. Pour cela, nous allons utiliser le c\u00e9l\u00e8bre jeu donn\u00e9es *Titanic* disponible sur **Kaggle** pour essayer de r\u00e9pondre \u00e0 la probl\u00e9matique suivante : Pr\u00e9dire la survie ou non des passagers en fonctions de certaines caract\u00e9ristiques. \n\nDans ce Notebook, nous nous placerons dans un contexte d'entreprise. En tant que Data Scientist, nous souhaitons tous obtenir le meilleur mod\u00e8le avec les meilleurs r\u00e9sultats et optimiser jusqu'au plus petit param\u00e8tre pour tendre vers la perfection. Toutefois, dans un contexte d'entreprise, il n'est souvent pas possible d'obtenir de tels r\u00e9sultats car l'investissement n\u00e9cessaire pour un gain au final marginal est trop important. L'objectif est donc obtenir le meilleur r\u00e9sultat acceptable en fonction des contraintes projet (temps, co\u00fbts, r\u00e9sultats attendus, temps de r\u00e9ponses du mod\u00e8le, etc...). Nous ne chercherons donc pas \u00e0 obtenir la perfection mais de bons r\u00e9sultats dans un laps de temps convenable. Comme dit plus haut, s'\u00e9chiner pendant des semaines pour gagner 0,1% de pr\u00e9cision n'est objectivement pas r\u00e9alisable dans le monde de l'entreprise\n\nAvant de foncer t\u00eate baiss\u00e9e dans les mod\u00e8les de machine learning, il faut d'abord acqu\u00e9rir une compr\u00e9hension des donn\u00e9es. Nous allons donc dans un premier temps **analyser** la base de donn\u00e9es Titanic et la **pr\u00e9parer** pour la phase de mod\u00e9lisation qui suivra. Cette phase peut-\u00eatre appel\u00e9e feature engineering. Nous passerons ensuite \u00e0 la phase de mod\u00e9lisation avec la **comparaison et l'optimisation des mod\u00e8les** de machine learning. Enfin, nous allons **analyser et expliquer le mod\u00e8le retenu**. Cette derni\u00e8re phase est une phase tr\u00e8s importante pour expliquer nos r\u00e9sultats et convaincre l'\u00e9quipe m\u00e9tier de la fiabilit\u00e9 de notre travail.","9b8a32db":"## **I. Analyse des donn\u00e9es**\n\nLa premi\u00e8re \u00e9tape d'un projet data consiste \u00e0 analyser et comprendre les donn\u00e9es. Cette \u00e9tape est cruciale pour am\u00e9liorer la qualit\u00e9 des donn\u00e9es en compl\u00e9tant les valeurs manquantes, s\u00e9lectionnant seulement les variables pertinentes \u00e0 l'\u00e9tude ou encore cr\u00e9ant de nouvelles variables pertinentes \u00e0 partir de celles dont on dispose. Toutes ces transformations vont contribuer \u00e0 une meilleure qualit\u00e9 de pr\u00e9diction des mod\u00e8les de machine learning que nous utiliserons plus tard, mais aussi \u00e0 interpr\u00e9ter notre mod\u00e8le et savoir si les r\u00e9sultats semblent coh\u00e9rents vis \u00e0 vis des donn\u00e9es et des probl\u00e9matiques m\u00e9tiers.","70528f54":"### 8. Optimisation du Cutoff\n\nLe cutoff est le seuil de probabilit\u00e9 \u00e0 partir duquel nous consid\u00e8rerons notre pr\u00e9diction en 1 ou 0. Dans les libraires classiques le cutoff est d\u00e9termin\u00e9 \u00e0 0.5. C'est \u00e0 dire que si la probabilit\u00e9 d'appartenir \u00e0 la classe 1 (survie) est sup\u00e9rieure ou \u00e9gale \u00e0 0.5 alors on consid\u00e8re que le passager \u00e0 surv\u00e9cu. A l'inverse, si cette probabilit\u00e9 est inf\u00e9rieure \u00e0 0.5 alors on consid\u00e8re qu'il n'a pas surv\u00e9cu. L'objectif de cette partie est d'optimiser le cutoff car dans la vraie vie, il est peu probable que les choses soient aussi tranch\u00e9e.","a939660f":"Apr\u00e8s soumission pour conna\u00eetre le score sur l'\u00e9chantillon test, la modification du cutoff ne permet pas d'am\u00e9liorer le score. Les scores pour chacunes des soumissions sont identique au score pour un cutoff de 0.5. Nous conserverons donc un cutoff initial de 0.5.\n\n## **III. Interpr\u00e9tation du mod\u00e8le**\n\nLe SVM est un mod\u00e8le dit \"boite noire\". Nous ne pouvons pas interpreter les variables de fa\u00e7on directe comme pour une r\u00e9gression. Nous allons donc utiliser le package LIME pour expliquer et interpreter le mod\u00e8le.","6b5fe2d3":"### 5. Gaussian Naive Bayes\nPour la th\u00e9orie math\u00e9matique autour de la Gaussian Naive Bayes, vous pouvez vous tourner vers l'article suivant : https:\/\/mrmint.fr\/naive-bayes-classifier","ce87a76f":"On constate tout de m\u00eame une diff\u00e9rence de score sur l'\u00e9chantillon de test entre les deux mod\u00e8les, celui de sklearn et celui de statsmodels. Ces deux packages ne sont donc pas d\u00e9velopp\u00e9 de la m\u00eame fa\u00e7on. Le package sklearn utilise une r\u00e9gularisation et une p\u00e9nalisation par d\u00e9faut que n'utilise pas le package statsmodels. Les optimisations du mod\u00e8les ne sont donc pas les m\u00eames. Malgr\u00e9 une diff\u00e9rence de score sur l'\u00e9chantillon de train, ces deux mod\u00e8les donnent le m\u00eame score sur l'\u00e9chantillon de test, \u00e0 savoir 77.99%. Enfin, nous conserverons le mod\u00e8le provenant du package sklearn comme mod\u00e8le baseline de r\u00e9f\u00e9rence pour la comparaison des prochains mod\u00e8les. La r\u00e9gression logistique \u00e9tant le mod\u00e8le de r\u00e9f\u00e9rence lorsque nous souhaitons effectuer une classification binaire.","9df2313e":"Maintenant que nous avons test\u00e9 et compar\u00e9 nos mod\u00e8les nous pouvons s\u00e9lectionner le meilleur d'entre eux. Dans notre cas, c'est le SVM qui fournit les meilleurs r\u00e9sultats sur l'\u00e9chantillon de test. Nous continuerons donc avec ce mod\u00e8le. Nous allons \u00e0 pr\u00e9sent optimiser le Cutoff pour am\u00e9liorer les performances de notre mod\u00e8le puis nous essayerons ensuite d'expliquer et d'interpreter ce mod\u00e8le. ","a7f5b7de":"### 7. Perceptron\nPour la th\u00e9orie math\u00e9matique autour du Perceptron, vous pouvez vous tourner vers l'article suivant : https:\/\/intelligence-artificielle.agency\/le-perceptron\/","8c5b4bc6":"Ce mod\u00e8le donne un score sur l'\u00e9chantillon test de 76.55%. Les param\u00e8tres par d\u00e9faut de l'arbre de d\u00e9cision ne permettent pas de faire mieux qu'une r\u00e9gression logistique sur l'\u00e9chantillon test. De plus, il semblerait que notre arbre de d\u00e9cision soit en sur-apprentissage sur l'\u00e9chantillon train \u00e9tant donn\u00e9 l'\u00e9cart de score sur l'\u00e9chantillon test.\n\nApr\u00e8s modification des param\u00e8tres par d\u00e9faut, l'arbre ne permet pas d'obtenir un meilleur score sur la base de donn\u00e9es.","d2c2d0b0":"### 2. Arbre de d\u00e9cision\n\nPour la th\u00e9orie math\u00e9matique autour de l'arbre de d\u00e9cision, vous pouvez vous tourner vers le cours suivant : http:\/\/pageperso.lif.univ-mrs.fr\/~francois.denis\/IAAM1\/chap2.pdf","ee26567f":"### 6. Support Vector Machine (SVM)\nPour la th\u00e9orie math\u00e9matique autour de la Gaussian Naive Bayes, vous pouvez vous tourner vers l'article suivant : https:\/\/www.math.univ-toulouse.fr\/~besse\/Wikistat\/pdf\/st-m-app-svm.pdf","4b57f906":"La phase d'analyse et de pr\u00e9paration est \u00e0 pr\u00e9sent termin\u00e9e. Les choix de mod\u00e9lisation des variables sont arbitraires. D'autres possibilit\u00e9s s'offrent \u00e0 nous comme par exemple le One Hot Encoding qui consiste \u00e0 cr\u00e9er une dummi (0 ou 1) pour chacune des modalit\u00e9s de chacunes des variables. Le nombre de classes cr\u00e9\u00e9es pour les variables Fare et Age peut \u00e9galement \u00eatre challeng\u00e9 pour am\u00e9liorer la qualit\u00e9 des mod\u00e8les ci-apr\u00e8s. Nous aurions \u00e9galement pu cr\u00e9er de nouvelles variables en faisant les croisements de certaines variables (*Ex : Fare x Pclass*). Enfin, une derni\u00e8re possibillit\u00e9 est une combinaison des diff\u00e9rentes m\u00e9thodes cit\u00e9es ci-dessus.\n\n\n## **II. Mod\u00e9lisation**\n\nNous pouvons donc \u00e0 pr\u00e9sent passer \u00e0 la phase de mod\u00e9lisation. Cette phase va consister \u00e0 tester plusieurs mod\u00e8les et les comparer pour n'en retenir qu'un seul qui, dans un contexte d'entreprise, sera ensuite d\u00e9ploy\u00e9 en production. Pour comparer les diff\u00e9rents mod\u00e8les, nous faisons le choix d'utiliser la m\u00e9trique d'Accuracy car c'est la m\u00e9trique utilis\u00e9e pour scorer l'\u00e9chantillon test dans le Kaggle. L'Accuracy repr\u00e9sente le taux de bonne pr\u00e9diction sur l'\u00e9chantillon. De plus, nous ne mettrons pas en place de validation crois\u00e9e pour ne pas rendre l'article trop long et compliqu\u00e9. Dans un contexte d'optimisation du mod\u00e8le, il serait toutefois pr\u00e9f\u00e9rable d'utiliser une validation crois\u00e9e pour la s\u00e9lection du mod\u00e8le afin d'\u00e9viter le surapprentissage du mod\u00e8le. \n\nNous d\u00e9buterons par la r\u00e9gression logistique qui est le premier mod\u00e8le de r\u00e9f\u00e9rence lorsqu'on parle de classification binaire. Nous comparerons donc nos diff\u00e9rents tests avec le score obtenu par la r\u00e9gression logistique afin d'obtenir un mod\u00e8le plus satisfaisant.","ae30343c":"On remarque ainsi que les variables Titre et Embarked contribue positivement \u00e0 la survie des passagers. On remarque que la variable Sex contribue le plus n\u00e9gativement \u00e0 la survie. Etant donn\u00e9 quer la variable vaut 1 si le passager est un Homme, cela signifie que les femmes avaient plus de chances de survie. Ces remarques confirment nos conjectures faites lors de la phase d'analyse des donn\u00e9es. Enfin, plus la famille est grande, moins le passager avait de chance de survie. De plus, les personnes solitaires avaient donc plus de chance de survie. De la m\u00eame mani\u00e8re, plus l'age est \u00e9lev\u00e9, moins le passager avait de chance de survie. \n\n\n## **IV. Conclusion**\n\nRappelons dans un premier temps que l'objectif de ce projet est d'appliquer de fa\u00e7on p\u00e9dagogique et pratique les mod\u00e8les de machine learning classique tout en se pla\u00e7ant dans des conditions les plus proches possible des conditions de d\u00e9veloppement d'un projet data en entreprise. C'est donc dans ce contexte que nous n'avons pas cherch\u00e9 \u00e0 obtenir le meilleur score possible mais plut\u00f4t de passer en revu les mod\u00e8les de machine learning, de les comparer et d'interpr\u00e9ter le mod\u00e8le retenu. Nous aurions \u00e9videmment pu appliquer d'autres mod\u00e8les tels que la LDA, XGBoost ou encore un r\u00e9seau de neuronnes mais nous avons fait le choix de restreindre le nombre de mod\u00e8les pr\u00e9sent\u00e9s pour ne pas rendre l'article trop r\u00e9barbatif. De plus, l'optimisation des mod\u00e8les peut \u00e9galement \u00eatre am\u00e9lior\u00e9e notamment en mettant en place une validation crois\u00e9e (cross validation) afin de choisir le meilleur mod\u00e8le sur la partie de l'\u00e9chantillon qui n'a pas servie \u00e0 l'entra\u00eenement. Cette m\u00e9thode permet d'\u00e9viter le sur-apprentissage lors de la s\u00e9lection du mod\u00e8le et est indispensable dans un contexte d'optimisation de mod\u00e8le. Nous avons fait le choix arbitraire de ne pas l'appliquer pour deux raisons. Premi\u00e8rement notre \u00e9chantillon de donn\u00e9e est relativement petit avec 900 lignes pour 7 variables et nous disposions d\u00e9j\u00e0 d'un \u00e9chantillon de test (la m\u00e9canique reste semblable sauf que dans notre cas, nous devons faire la soumission pour conna\u00eetre le score du mod\u00e8le et donc faire la s\u00e9lection). La deuxi\u00e8me raison est que l'objectif de cet article est de pr\u00e9senter l'impl\u00e9mentation des mod\u00e8les de fa\u00e7on simplifi\u00e9e, nous n'avons donc pas souhaiter compliquer le script et le rendre trop long.\n\nUne fois le contexte et les choix de mod\u00e9lisation rappel\u00e9s, nous constatons \u00e0 l'issue de la mod\u00e9lisation que le meilleur mod\u00e8le retenu est un SVM. Ce type de mod\u00e8le se pr\u00eate bien \u00e0 la base de donn\u00e9es car elle dispose de peu de variables pour un grand nombre de ligne. A l'inverse, les r\u00e9sultats du random forest et de l'arbre de d\u00e9cision ne sont pas tr\u00e8s surprenant car ces mod\u00e8les sont destin\u00e9s \u00e0 des donn\u00e9es avec un tr\u00e8s grand nombre de variables. Enfin, les r\u00e9sultats de la r\u00e9gression logistique qui est un mod\u00e8le de r\u00e9f\u00e9rence en classification binaire sont coh\u00e9rents car ce mod\u00e8le se porte \u00e0 la perfection \u00e0 ce type de base de donn\u00e9es. Par ailleurs, on retrouve dans les r\u00e9sultats du SVM les conjectures faites lors de l'analyse des donn\u00e9es. Dans un contexte d'entreprise, nous serions donc en mesure d'expliquer aux m\u00e9tiers le comportement du mod\u00e8le et les facteurs important de la survie d'un passager.","6337146c":"### 3. Random Forest\nPour la th\u00e9orie math\u00e9matique autour du Random Forest, vous pouvez vous tourner vers l'article suivant : https:\/\/erwanscornet.github.io\/pdf\/article_MATAPLI.pdf","770a00ff":"### 1. R\u00e9gression logistique\nPour la th\u00e9orie math\u00e9matique autour de la r\u00e9gression logistique, vous pouvez vous tourner vers l'article suivant : https:\/\/www.em-consulte.com\/en\/article\/842576.","a7414404":"### 4. K Plus Proches Voisins (ou k-nearest neighbors)\nPour la th\u00e9orie math\u00e9matique autour des K Plus Proches Voisins, vous pouvez vous tourner vers l'article suivant : http:\/\/mediamining.univ-lyon2.fr\/people\/guille\/m4101\/k_plus_proches_voisins.html"}}