{"cell_type":{"50214db8":"code","ea84449d":"code","6ea25204":"code","dda0c5b0":"code","549edc21":"code","a71eff3e":"code","b1c9daf4":"code","8d5a9cfa":"code","0d5fffdf":"code","6dec89bb":"code","6abccbdc":"code","6903869d":"code","01f15289":"code","a9632edf":"code","0ac97b9b":"code","0dcb857b":"code","11a507a7":"code","b315215e":"code","37c299f8":"markdown","cdfb9009":"markdown","bf739dbd":"markdown","4e6d8426":"markdown","ec886889":"markdown","27271ed4":"markdown","f35e0905":"markdown","d82f9a73":"markdown","e77a74f4":"markdown","7aaa0e44":"markdown","5e5ebb14":"markdown","841baf77":"markdown","5dc8d7be":"markdown","73a133ce":"markdown","aed29caf":"markdown","9ef9cbca":"markdown","f891b1b6":"markdown"},"source":{"50214db8":"import numpy as np\nimport pandas as pd\n\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import TensorDataset, DataLoader\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nprint(os.listdir(\"..\/input\"))","ea84449d":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\n\nprint(train.shape)\ntrain.head()","6ea25204":"print(test.shape)\ntest.head()","dda0c5b0":"x_train_df = train.iloc[:,1:]\ny_train_df = train.iloc[:,0]\n\nprint(x_train_df.shape, y_train_df.shape)","549edc21":"x_train = x_train_df.values\/255.\ny_train = y_train_df.values\n\nx_test = test.values\/255","a71eff3e":"x_train = np.reshape(x_train, (-1, 1, 28,28))\nx_test = np.reshape(x_test, (-1, 1, 28,28))\n\n\nx_train.shape, x_test.shape","b1c9daf4":"# This is to ensure reproducibility\nrandom_seed = 234\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state=random_seed)\n\n\nx_train.shape, x_val.shape, y_train.shape, y_val.shape","8d5a9cfa":"def display(rows, columns, images, values=[], predictions=[]):\n    fig = plt.figure(figsize=(9, 11))\n\n    ax = []\n\n    for i in range( columns*rows ):\n        img = images[i]\n        ax.append(fig.add_subplot(rows, columns, i+1))\n        \n        title = \"\"\n        \n        if(len(values) == 0):\n            title = \"Pred:\" + str(predictions[i])\n        elif(len(predictions) == 0):\n            title = \"Value:\" + str(values[i])\n        elif(len(values) != 0 and len(predictions) != 0):\n            title = \"Value:\" + str(values[i]) + \"\\nPred:\" + str(predictions[i])\n        \n        ax[-1].set_title(title)  # set title\n        plt.imshow(img)\n\n    plt.show()\n    \nidx = np.random.randint(1, 1000, size=9)\n\nimages = x_train[idx,:]\nimages = images[:,0]\n\nvalues = y_train[idx]\n\ndisplay(rows=3, columns=3, images=images, values=values, predictions=[])","0d5fffdf":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","6dec89bb":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n        self.conv3 = nn.Conv2d(32,64, kernel_size=5)\n        self.fc1 = nn.Linear(3*3*64, 256)\n        self.fc2 = nn.Linear(256, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = F.relu(F.max_pool2d(self.conv3(x),2))\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = x.view(-1,3*3*64 )\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n    \nnet = Net()\n\nnet.to(device)\n\nnet","6abccbdc":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)","6903869d":"torch_x_train = torch.from_numpy(x_train).type(torch.FloatTensor)\ntorch_y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n\ntrain = torch.utils.data.TensorDataset(torch_x_train,torch_y_train)\n\ntrain_loader = torch.utils.data.DataLoader(train, batch_size = 32, shuffle = False)","01f15289":"%%time\n\n#Seed\ntorch.manual_seed(1234)\n\nfor epoch in range(10):\n    running_loss = 0.0\n    for i, data in enumerate(train_loader, 0):\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        # print statistics\n        running_loss += loss.item()\n        if i % 500 == 499:    # print every 500 mini-batches\n            print('[%d, %5d] loss: %.3f' % (epoch + 1, i+1, loss.item()))\n#             print('[%d, %5d] loss: %.3f' % (epoch + 1, i, running_loss \/ 500))\n#             running_loss = 0.0\n\nprint('Finished Training')","a9632edf":"#Validate trained model\ntorch_x_val = torch.from_numpy(x_val).type(torch.FloatTensor)\ntorch_y_val = torch.from_numpy(y_val).type(torch.LongTensor)\n\ntorch_x_val, torch_y_val = torch_x_val.to(device), torch_y_val.to(device)\n\nval = net(torch_x_val)\n\n_, predicted = torch.max(val.data, 1)\n\n#Get accuration\nprint('Accuracy of the network %d %%' % (100 * torch.sum(torch_y_val==predicted) \/ len(y_val)))","0ac97b9b":"# Get random data from the valication dataset and the predicted values\nidx = np.random.randint(1, 1000, size=9)\n\nimages = x_val[idx,:]\nimages = images[:,0]\n\nvalues = y_val[idx]\n\npredicted = predicted.cpu()\n\npredictions = predicted.data.numpy()\npredictions = predictions[idx]\n\ndisplay(rows=3, columns=3, images=images, values=values, predictions=predictions)","0dcb857b":"torch_x_test = torch.from_numpy(x_test).type(torch.FloatTensor)\n\ntorch_x_test = torch_x_test.to(device)\n\ny_test = net(torch_x_test)\n\n_, predicted = torch.max(y_test.data, 1)","11a507a7":"idx = np.random.randint(1, 1000, size=9)\n\nimages = x_test[idx,:]\nimages = images[:,0]\n\npredicted = predicted.cpu()\n\npredictions = predicted.data.numpy()\npredictions = predictions[idx]\n\ndisplay(rows=3, columns=3, images=images, values=[], predictions=predictions)","b315215e":"ImageId = np.arange(1, len(x_test)+1)\nLabel = predicted.data.numpy()\n\nmy_submission = pd.DataFrame({'ImageId': ImageId, 'Label': Label})\nmy_submission.to_csv('submission.csv', index=False)\n\nmy_submission.head()","37c299f8":"#### Helper function to display an array of images","cdfb9009":"# Data Acquisition\n\n#### Load the training dataset into Pandas DataFrame","bf739dbd":"#### Using the GPU","4e6d8426":"#### Split the training dataset to features and labels\n","ec886889":"#### Reshape the test and training dataset to (28,28) image arrays","27271ed4":"#### Lets define the optimizer and loss function","f35e0905":"#### Lets define the Convolutional Neural Network Model","d82f9a73":"#### Lets display a sample of the predictions on the validation dataset","e77a74f4":"#### Display predictions of the test dataset","7aaa0e44":"# MNIST Image Classification using PyTorch Convolutional Neural Network","5e5ebb14":"#### Try the model on the validation dataset","841baf77":"#### Save predictions to csv for submission","5dc8d7be":"#### Split the training dataset into training and validation datasets","73a133ce":"#### Convert the data to numeric arrays and normalize the features","aed29caf":"#### Train for 100 epoch","9ef9cbca":"#### Define out tensors and dataloader","f891b1b6":"#### Our model is awesome, lets use it on the test dataset"}}