{"cell_type":{"eb3ff45c":"code","cd344b44":"code","86923161":"code","56a0a4a3":"code","293c7427":"code","37972cc8":"code","8bd3d280":"code","7d6825c5":"code","40fae6b1":"code","a7001002":"code","00a8fd4a":"code","013bde0c":"code","280953e6":"code","b0309b4c":"code","24ca821c":"code","638e9ffd":"code","958c5c8c":"code","b37b2541":"code","5e42541e":"code","b6adcdc6":"code","161d5cc2":"code","e0ed3107":"code","a83cebd5":"code","8d007b68":"code","fe25a46d":"code","292d28fd":"code","0b06fef1":"code","86ee2c3e":"code","8735e549":"code","b95800d1":"code","25d057e2":"code","b76011ce":"code","28f892f6":"code","ada63a10":"code","55be4dc0":"code","78d5dd8e":"code","1b45d8bb":"code","e4a9109f":"code","7a991b90":"code","c2714023":"code","b76475a2":"code","1e5ff13b":"code","ac39bf6b":"code","14cf762d":"code","2daa5e14":"code","115520d5":"code","6e36e811":"code","336b72b4":"code","0e8a3b0a":"code","93118763":"markdown","0f6155cc":"markdown","030be43e":"markdown","20ca99cb":"markdown","54fe3a0b":"markdown","45263e61":"markdown","04c1403a":"markdown","06bae427":"markdown","003b7cc5":"markdown","7b770f39":"markdown","3f29810d":"markdown","798f0273":"markdown","90cd57b2":"markdown","b22da9e3":"markdown","cf36b6a9":"markdown","89913dd2":"markdown","82bd091c":"markdown","73bd079f":"markdown","3d945161":"markdown","e687ecab":"markdown","b9d948e8":"markdown","b5db2bb4":"markdown","3cc52954":"markdown","39c0af80":"markdown","5e2935fb":"markdown","118558e0":"markdown","1f74718e":"markdown","3ccf9667":"markdown","ac71d27d":"markdown","dbfabc6f":"markdown","b3b1e5c5":"markdown"},"source":{"eb3ff45c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport plotly.express as px\nfrom IPython.display import display\npd.options.display.max_columns = None\nimport random\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt","cd344b44":"train = pd.read_csv('\/kaggle\/input\/lish-moa\/train_features.csv')\ntrain['dataset'] = 'train'\ntest = pd.read_csv('\/kaggle\/input\/lish-moa\/test_features.csv')\ntest['dataset'] = 'test'\ndf = pd.concat([train, test])","86923161":"train.head()","56a0a4a3":"test.head()","293c7427":"print('Number of rows in training set: ', train.shape[0])\nprint('Number of columns in training set: ', train.shape[1]-1)\nprint('Number of rows in test set: ', test.shape[0])\nprint('Number of columns in test set: ', test.shape[1]-1)","37972cc8":"df.info()","8bd3d280":"ds = df.groupby(['cp_type', 'dataset'])['sig_id'].count().reset_index()\nds.columns = ['cp_type', 'dataset', 'count']\nfig = px.bar(\n    ds, \n    x='cp_type', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='cp_type train\/test counts', \n    width=600,\n    height=500\n)\nfig.show()","7d6825c5":"ds = df.groupby(['cp_time', 'dataset'])['sig_id'].count().reset_index()\nds.columns = ['cp_time', 'dataset', 'count']\nfig = px.bar(\n    ds, \n    x='cp_time', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='cp_time train\/test counts', \n    width=600,\n    height=500\n)\nfig.show()","40fae6b1":"ds = df.groupby(['cp_dose', 'dataset'])['sig_id'].count().reset_index()\nds.columns = ['cp_dose', 'dataset', 'count']\nfig = px.bar(\n    ds, \n    x='cp_dose', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='cp_dose train\/test counts', \n    width=600,\n    height=500\n)\nfig.show()","a7001002":"ds = df[df['dataset']=='train']\nds = ds.groupby(['cp_type', 'cp_time', 'cp_dose'])['sig_id'].count().reset_index()\nds.columns = ['cp_type', 'cp_time', 'cp_dose', 'count']\n\nfig = px.sunburst(\n    ds, \n    path=[\n        'cp_type',\n        'cp_time',\n        'cp_dose' \n    ], \n    values='count', \n    title='Sunburst chart for all cp_type\/cp_time\/cp_dose',\n    width=600,\n    height=600\n)\nfig.show()","00a8fd4a":"train_columns = train.columns.to_list()\ng_list = [i for i in train_columns if i.startswith('g-')]\nc_list = [i for i in train_columns if i.startswith('c-')]","013bde0c":"plot_list = [g_list[random.randint(0, len(g_list)-1)] for i in range(12)]\n\nfig = make_subplots(rows=4, cols=3)\n\ntraces = [go.Histogram(x=train[col], nbinsx=20, name=col) for col in plot_list]\n\ni=1\nj=1\n\nfor trace in traces:\n    fig.append_trace(trace, i, j)\n    if j==3:\n        j=1\n        i+=1\n    else:\n        j+=1\n\nfig.update_layout(\n    title_text='Randomly selected gene expression features distributions'\n)\nfig.show()","280953e6":"plot_list = [c_list[random.randint(0, len(c_list)-1)] for i in range(12)]\nfig = make_subplots(rows=4, cols=3)\ntraces = [go.Histogram(x=train[col], nbinsx=20, name=col) for col in plot_list]\n\ni=1\nj=1\n\nfor trace in traces:\n    fig.append_trace(trace, i, j)\n    if j==3:\n        j=1\n        i+=1\n    else:\n        j+=1\n\nfig.update_layout(\n    title_text='Randomly selected cell viability features distributions'\n)\nfig.show()","b0309b4c":"columns = g_list + c_list\nfor_correlation = [columns[random.randint(0, len(columns)-1)] for i in range(40)]\ndata = df[for_correlation]\n\nf = plt.figure(figsize=(19, 15))\nplt.matshow(data.corr(), fignum=f.number)\nplt.xticks(range(data.shape[1]), data.columns, fontsize=14, rotation=45)\nplt.yticks(range(data.shape[1]), data.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)","24ca821c":"import time\n\nstart = time.time()\ncols = ['cp_time'] + columns\nall_columns = []\nfor i in range(0, len(cols)):\n    for j in range(i+1, len(cols)):\n        if abs(train[cols[i]].corr(train[cols[j]])) > 0.9:\n            all_columns.append(cols[i])\n            all_columns.append(cols[j])\n\nprint(time.time()-start)","638e9ffd":"all_columns = list(set(all_columns))","958c5c8c":"len(all_columns)","b37b2541":"data = df[all_columns]\n\nf = plt.figure(figsize=(19, 15))\nplt.matshow(data.corr(), fignum=f.number)\nplt.xticks(range(data.shape[1]), data.columns, fontsize=14, rotation=45)\nplt.yticks(range(data.shape[1]), data.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)","5e42541e":"fig = make_subplots(rows=12, cols=3)\n\ntraces = [go.Histogram(x=train[col], nbinsx=20, name=col) for col in all_columns]\n\ni=1\nj=1\n\nfor trace in traces:\n    fig.append_trace(trace, i, j)\n    if j==3:\n        j=1\n        i+=1\n    else:\n        j+=1\n\nfig.update_layout(\n    title_text='Highly correlated features',\n    height=1200\n)\nfig.show()","b6adcdc6":"train_target = pd.read_csv(\"..\/input\/lish-moa\/train_targets_scored.csv\")\n\nprint('Number of rows : ', train_target.shape[0])\nprint('Number of cols : ', train_target.shape[1])\ntrain_target.head()","161d5cc2":"x = train_target.drop(['sig_id'], axis=1).sum(axis=0).sort_values().reset_index()\nx.columns = ['column', 'nonzero_records']\n\nfig = px.bar(\n    x.tail(50), \n    x='nonzero_records', \n    y='column', \n    orientation='h', \n    title='Columns with the higher number of positive samples (top 50)', \n    height=1000, \n    width=800\n)\nfig.show()","e0ed3107":"x = train_target.drop(['sig_id'], axis=1).sum(axis=0).sort_values(ascending=False).reset_index()\nx.columns = ['column', 'nonzero_records']\n\nfig = px.bar(\n    x.tail(50), \n    x='nonzero_records', \n    y='column', \n    orientation='h', \n    title='Columns with the lowest number of positive samples (top 50)', \n    height=1000, \n    width=800\n)\nfig.show()","a83cebd5":"x = train_target.drop(['sig_id'], axis=1).sum(axis=0).sort_values(ascending=False).reset_index()\nx.columns = ['column', 'count']\nx['count'] = x['count'] * 100 \/ len(train_target)\nfig = px.bar(\n    x, \n    x='column', \n    y='count', \n    orientation='v', \n    title='Percent of positive records for every column in target', \n    height=800, \n    width=1200\n)\nfig.show()","8d007b68":"data = train_target.drop(['sig_id'], axis=1).astype(bool).sum(axis=1).reset_index()\ndata.columns = ['row', 'count']\ndata = data.groupby(['count'])['row'].count().reset_index()\nfig = px.bar(\n    data, \n    y=data['row'], \n    x=\"count\", \n    title='Number of activations in targets for every sample', \n    width=800, \n    height=500\n)\nfig.show()","fe25a46d":"data = train_target.drop(['sig_id'], axis=1).astype(bool).sum(axis=1).reset_index()\ndata.columns = ['row', 'count']\ndata = data.groupby(['count'])['row'].count().reset_index()\nfig = px.pie(\n    data, \n    values=100 * data['row']\/len(train_target), \n    names=\"count\", \n    title='Number of activations in targets for every sample (Percent)', \n    width=800, \n    height=500\n)\nfig.show()","292d28fd":"train_target.describe()","0b06fef1":"start = time.time()\n\ncorrelation_matrix = pd.DataFrame()\nfor t_col in train_target.columns:\n    corr_list = list()\n    if t_col == 'sig_id':\n        continue\n    for col in columns:\n        res = train[col].corr(train_target[t_col])\n        corr_list.append(res)\n    correlation_matrix[t_col] = corr_list\n    \nprint(time.time()-start)","86ee2c3e":"correlation_matrix['train_features'] = columns\ncorrelation_matrix = correlation_matrix.set_index('train_features')\ncorrelation_matrix","8735e549":"maxCol=lambda x: max(x.min(), x.max(), key=abs)\nhigh_scores = correlation_matrix.apply(maxCol, axis=0).reset_index()\nhigh_scores.columns = ['column', 'best_correlation']\n\nfig = px.bar(\n    high_scores, \n    x='column', \n    y=\"best_correlation\", \n    orientation='v', \n    title='Best correlation with train columns for every target column', \n    width=1200,\n    height=800\n)\nfig.show()","b95800d1":"col_df = pd.DataFrame()\ntr_cols = list()\ntar_cols = list()\nfor col in correlation_matrix.columns:\n    tar_cols.append(col)\n    tr_cols.append(correlation_matrix[col].abs().sort_values(ascending=False).reset_index()['train_features'].head(1).values[0])\n\ncol_df['column'] = tar_cols\ncol_df['train_best_column'] = tr_cols\n\ntotal_scores = pd.merge(high_scores, col_df)\ntotal_scores","25d057e2":"count_features = total_scores['train_best_column'].value_counts().reset_index().sort_values('train_best_column')\ncount_features.columns = ['column', 'count']\nfig = px.bar(\n    count_features.tail(33), \n    x='count', \n    y=\"column\", \n    orientation='h', \n    title='Columns from training set with number of high correlations with target columns', \n    width=800,\n    height=700\n)\nfig.show()","b76011ce":"target_columns = train_target.columns.tolist()\ntarget_columns.remove('sig_id')\nfor_analysis = [target_columns[random.randint(0, len(target_columns)-1)] for i in range(5)]\ncurrent_corr = correlation_matrix[for_analysis]","28f892f6":"col_df = pd.DataFrame()\ntr_first_cols = list()\ntr_second_cols = list()\ntar_cols = list()\nfor col in current_corr.columns:\n    tar_cols.append(col)\n    tr_first_cols.append(current_corr[col].abs().sort_values(ascending=False).reset_index()['train_features'].head(2).values[0])\n    tr_second_cols.append(current_corr[col].abs().sort_values(ascending=False).reset_index()['train_features'].head(2).values[1])\n\ncol_df['column'] = tar_cols\ncol_df['train_1_column'] = tr_first_cols\ncol_df['train_2_column'] = tr_second_cols\ncol_df","ada63a10":"def plot_scatter(col_df, index):\n    analysis = pd.DataFrame()\n    analysis['color'] = train_target[col_df.iloc[index]['column']]\n    analysis['x'] = train[col_df.iloc[index]['train_1_column']]\n    analysis['y'] = train[col_df.iloc[index]['train_2_column']]\n    analysis.columns = ['color', col_df.iloc[index]['train_1_column'], col_df.iloc[index]['train_2_column']]\n    analysis['size'] = 1\n    analysis.loc[analysis['color'] == 1, 'size'] = 10\n\n    fig = px.scatter(\n        analysis, \n        x=col_df.iloc[index]['train_1_column'], \n        y=col_df.iloc[index]['train_2_column'], \n        color=\"color\", \n        size='size', \n        height=800,\n        title='Scatter plot for ' + col_df.iloc[index]['column']\n    )\n    fig.show()","55be4dc0":"plot_scatter(col_df, 0)","78d5dd8e":"plot_scatter(col_df, 1)","1b45d8bb":"plot_scatter(col_df, 2)","e4a9109f":"plot_scatter(col_df, 3)","7a991b90":"plot_scatter(col_df, 4)","c2714023":"for_analysis = [target_columns[random.randint(0, len(target_columns)-1)] for i in range(5)]\ncurrent_corr = correlation_matrix[for_analysis]\n\ncol_df = pd.DataFrame()\ntr_first_cols = list()\ntr_second_cols = list()\ntr_third_cols = list()\ntar_cols = list()\nfor col in current_corr.columns:\n    tar_cols.append(col)\n    tr_first_cols.append(current_corr[col].abs().sort_values(ascending=False).reset_index()['train_features'].head(3).values[0])\n    tr_second_cols.append(current_corr[col].abs().sort_values(ascending=False).reset_index()['train_features'].head(3).values[1])\n    tr_third_cols.append(current_corr[col].abs().sort_values(ascending=False).reset_index()['train_features'].head(3).values[2])\n\n\ncol_df['column'] = tar_cols\ncol_df['train_1_column'] = tr_first_cols\ncol_df['train_2_column'] = tr_second_cols\ncol_df['train_3_column'] = tr_third_cols\ncol_df","b76475a2":"def plot_3dscatter(col_df, index):\n    analysis = pd.DataFrame()\n    analysis['color'] = train_target[col_df.iloc[index]['column']]\n    analysis['x'] = train[col_df.iloc[index]['train_1_column']]\n    analysis['y'] = train[col_df.iloc[index]['train_2_column']]\n    analysis['z'] = train[col_df.iloc[index]['train_3_column']]\n    analysis.columns = ['color', col_df.iloc[index]['train_1_column'], col_df.iloc[index]['train_2_column'], col_df.iloc[index]['train_3_column']]\n    analysis['size'] = 1\n    analysis.loc[analysis['color'] == 1, 'size'] = 20\n\n    fig = px.scatter_3d(\n        analysis, \n        x=col_df.iloc[index]['train_1_column'], \n        y=col_df.iloc[index]['train_2_column'],\n        z=col_df.iloc[index]['train_3_column'], \n        color=\"color\", \n        size='size', \n        height=800,\n        width=800,\n        title='Scatter plot for ' + col_df.iloc[index]['column']\n    )\n    fig.show()","1e5ff13b":"plot_3dscatter(col_df, 0)","ac39bf6b":"plot_3dscatter(col_df, 1)","14cf762d":"plot_3dscatter(col_df, 2)","2daa5e14":"plot_3dscatter(col_df, 3)","115520d5":"plot_3dscatter(col_df, 4)","6e36e811":"last_term = dict()\nfor item in target_columns:\n    try:\n        last_term[item.split('_')[-1]] += 1\n    except:\n        last_term[item.split('_')[-1]] = 1\n\nlast_term = pd.DataFrame(last_term.items(), columns=['group', 'count'])\nlast_term = last_term.sort_values('count')\nlast_term = last_term[last_term['count']>1]\nlast_term['count'] = last_term['count'] * 100 \/ 206\n\nfig = px.bar(\n    last_term, \n    x='count', \n    y=\"group\", \n    orientation='h', \n    title='Groups in target columns (Percent from all target columns)', \n    width=800,\n    height=500\n)\nfig.show()","336b72b4":"answer = list()\nfor group in last_term.group.tolist():\n    agent_list = list()\n    for item in target_columns:\n        if item.split('_')[-1] == group:\n            agent_list.append(item)\n    agent_df = train_target[agent_list]\n    data = agent_df.astype(bool).sum(axis=1).reset_index()\n    answer.append(data[0].max())","0e8a3b0a":"ds = pd.DataFrame()\nds['group'] = last_term.group.tolist()\nds['max_value'] = answer\n\nfig = px.bar(\n    ds, \n    x='max_value', \n    y=\"group\", \n    orientation='h', \n    title='Maximum number of active columns in 1 sample for every group', \n    width=800,\n    height=500\n)\nfig.show()","93118763":"## We can see that for groups activator, agent, blocker maximum number of active columns in sample is 1.","0f6155cc":"### Let's check targets","030be43e":"## Target columns and pairs of highly correlated features","20ca99cb":"### Take a look into training and test sets.","54fe3a0b":"<h1><center>Mechanisms of Action (MoA) Prediction. Data analysis and visualization<\/center><\/h1>\n\n<center><img src=\"https:\/\/pharmacyinnovations.net\/wp-content\/uploads\/pillsdrugs.png\"><\/center>\n","45263e61":"### In total we have 35 columns that have correlation with at least another 1 higher than 0.9. Let's visualize them.","04c1403a":"## Let's see what is the higher value (absolute) of correlation for target columns with every column from train set. Every column on chart is max correlation of current target column with all of columns from training set.","06bae427":"### We can see that we have 872 float features 1 integer (cp_time) and 3 categorical (sig_id, cp_type and cp_dose)","003b7cc5":"## We can see that at least 50 target columns have number pf positive samples less than 20 (about 0.1%) !!!","7b770f39":"<a id=\"4\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>4. Targets analysis<\/center><h2>","3f29810d":"## Now let's see what columns from training set have the higher number of \"high\" correlations with target columns. Every row from chart means that column `A` `N` times has the best value of correlation with different target columns. ","798f0273":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:blue; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Quick navigation<\/center><\/h2>\n\n* [1. Basic Data Overview](#1)\n* [2. Categories visualization](#2)\n* [3. Training features correlation](#3)\n* [4. Targets analysis](#4)","90cd57b2":"## 2.1 cp_type feature","b22da9e3":"### Let's select some random columns and see how they deal with pairs of the highly correlated features","cf36b6a9":"### Let's visualize them","89913dd2":"## We can see here that about 40% of sample have zeros in all columns and more than 50% have only one active target column.","82bd091c":"## And we have large correlation matrix","73bd079f":"### Some distribution of randomly selected columns","3d945161":"<a id=\"2\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>2. Categories Visualization<\/center><h2>","e687ecab":"### Let's do the same but for 3d plots","b9d948e8":"## Is it possible to have more than 1 activation for 1 sample in every group?","b5db2bb4":"### We can extract several group names from target column names. Looks like that last term in column name is definition of a group. Let's extact them and visualize groups with number of columns > 1.","3cc52954":"### Let's see some correlation between randomly selected variables","39c0af80":"## 2.2 Cp_time feature","5e2935fb":"<a id=\"3\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>3. Training features correlation<\/center><h2>","118558e0":"### Time to find pairs of features with high correlation","1f74718e":"<a id=\"1\"><\/a>\n<h2 style='background:blue; border:0; color:white'><center>1. Basic Data Overview<\/center><h2>","3ccf9667":"## Time to find the most correlated features for every target column","ac71d27d":"## 2.3 Cp_dose feature","dbfabc6f":"## The biggest number of positive samples for 1 target column is 3.5%. So we deal here with highly imbalanced data.","b3b1e5c5":"# WORK IN PROGRESS"}}