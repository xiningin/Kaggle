{"cell_type":{"27bb2c93":"code","4722e6b4":"code","bcc3b0c9":"code","9e19751b":"code","f340f925":"code","6db2adab":"code","7f5b3236":"code","0cb482c7":"code","510eab06":"code","7e13c909":"code","41617e2e":"code","324bceb5":"code","d6a85524":"code","9a0b7e08":"code","e8c0ac6a":"code","b7a08855":"code","fb49fd61":"code","d07a5bf4":"code","c6d4c4ca":"code","0dae8ab2":"code","54012015":"code","931a9ce3":"code","587ffbcd":"code","a4fc2b60":"code","6787c252":"code","c63d764f":"code","552e02e2":"code","54ddfa9b":"markdown","abb771fb":"markdown","467baefd":"markdown","892e72af":"markdown","4fa97b14":"markdown","17d011fc":"markdown","ff9df61a":"markdown","43edd2ed":"markdown","961c73ef":"markdown","648f7c0d":"markdown","d70d1c3c":"markdown","9277c755":"markdown","7969d9d8":"markdown","a3f3ca18":"markdown","3a2e3f73":"markdown","ef5f8734":"markdown","ff599dae":"markdown","24e9c018":"markdown","c897ac4e":"markdown","e8f50abe":"markdown","899998e7":"markdown","e93b371c":"markdown","cbc26c60":"markdown"},"source":{"27bb2c93":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport os\nimport shutil\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler,OrdinalEncoder,OneHotEncoder,LabelEncoder\nimport warnings\nimport missingno\nwarnings.filterwarnings('ignore')\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score","4722e6b4":"train_data = pd.read_csv('..\/input\/song-prediction-5-stratified-folds\/song_prediction_5_stratified_folds.csv')\ntrain = pd.read_csv('..\/input\/song-popularity-prediction\/train.csv')\ntest_data = pd.read_csv('..\/input\/song-popularity-prediction\/test.csv')","bcc3b0c9":"sample = pd.read_csv('..\/input\/song-popularity-prediction\/sample_submission.csv')","9e19751b":"train_data.set_index('id',inplace = True)\nprint(train_data.shape)\ntrain_data.head()","f340f925":"train_data.info()","6db2adab":"test_data.set_index('id',inplace = True)\nprint(test_data.shape)\ntest_data.head()","7f5b3236":"test_data.info()","0cb482c7":"missingno.matrix(train_data);\n","510eab06":"missing_values_cols = ['song_duration_ms' , 'acousticness' , 'danceability' , 'energy' , 'instrumentalness' ,'key' ,'liveness' , 'loudness']\n\nnull_df = pd.concat([train_data[missing_values_cols].isna().sum(axis = 0)\/train_data.shape[0], test_data[missing_values_cols].isna().sum(axis = 0)\/test_data.shape[0]],axis = 1)\nnull_df.columns = ['train','test']\n","7e13c909":"plt.figure(figsize = (12,7))\nplt.suptitle(\"pct wise null value distribution\")\nplt.subplot(1,2,1)\nax = sns.barplot(y = missing_values_cols, x  =null_df['train'],palette = 'icefire' )\nplt.subplot(1,2,2)\nax = sns.barplot(y = missing_values_cols, x =null_df['test'],palette = 'icefire')\nplt.tight_layout()\n\nplt.show()","41617e2e":"\nnull_df_row = pd.DataFrame()\nnull_df_row['nulls'] = pd.concat([train_data.isna().sum(axis = 1) ,test_data.isna().sum(axis = 1)] ,axis = 0)\nnull_df_row['set'] = pd.concat([pd.Series(['train']*train_data.shape[0]) ,pd.Series(['test']*test_data.shape[0]) ],axis = 0)\n","324bceb5":"plt.figure(figsize = (12,7))\nplt.suptitle(\"Null values count based on rows\")\nsns.countplot(data = null_df_row , x = 'nulls' , hue = 'set',palette = 'viridis');","d6a85524":"train_data.describe()","9a0b7e08":"cont = ['song_duration_ms','acousticness','danceability','energy','instrumentalness','liveness','loudness','speechiness','tempo','audio_valence']\ncat = ['key', 'audio_mode','time_signature']","e8c0ac6a":"sns.countplot(data = train_data,x = 'song_popularity',palette = 'viridis');\n","b7a08855":"plt.pie(x = train_data['song_popularity'].value_counts(),autopct = '%1.1f%%',labels = [False,True],colors=['#DE3163', '#58D68D'],\n        textprops={'fontsize': 13});","fb49fd61":"plt.figure(figsize =(25,12))\nfor j,i in enumerate(cont):\n    plt.subplot(2,5,j+1)\n#     sns.set_theme('notebook')\n    sns.kdeplot(train_data[i],fill = True , hue = train_data['song_popularity'],palette = 'flare' )\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize =(25,6))\nfor j,i in enumerate(cat):\n    plt.subplot(1,3,j+1)\n#     sns.set_theme('notebook')\n    sns.countplot(train_data[i] ,hue = train_data['song_popularity'],palette = 'flare' )\nplt.tight_layout()\nplt.show()\n","d07a5bf4":"plt.figure(figsize =(25,12))\nnormalized_cont = ['acousticness','danceability','energy','instrumentalness','liveness','loudness','speechiness','audio_valence']\nfor j,i in enumerate(normalized_cont):\n    plt.subplot(2,4,j+1)\n    sns.set_theme('notebook')\n    sns.kdeplot((train_data[i] - np.min(train_data[i]))\/(np.max(train_data[i]) - np.min(train_data[i])),fill = True , hue = train_data['song_popularity'],palette = 'viridis' )\nplt.tight_layout()\nplt.show()\n","c6d4c4ca":"import matplotlib.colors as mcolors\nimport random\n\nplt.figure(figsize =(25,12))\nfor j,i in enumerate(cont):\n    plt.subplot(5,2,j+1)\n    sns.set_theme('notebook')\n    sns.boxplot(data = train_data ,x = i,color = random.choice(list(mcolors.CSS4_COLORS.values())))\nplt.tight_layout()\nplt.show()","0dae8ab2":"sns.pairplot(data = train_data[cont + ['song_popularity']],hue ='song_popularity',markers = ['s','D'],corner = True);","54012015":"plt.figure(figsize = (20,7))\nmask = np.triu(np.ones_like(train_data.corr()))\nsns.heatmap(train_data.corr(),cmap = 'RdBu',annot = True,mask = mask)\nplt.show()","931a9ce3":"features = [f for f in train_data.columns if f not in('folds','song_popularity')]","587ffbcd":"predictions = []\nscores = []\n\n\nxgb_params = {\n    \"objective\":\"binary:logistic\",\n    \"eval_metric\": \"auc\",\n}\nfor fold in range(5):\n\n    x_train = train_data[train_data.folds!=fold]\n    x_valid  = train_data[train_data.folds == fold]\n    x_test = test_data\n    \n    y_train = x_train.song_popularity\n    y_valid = x_valid.song_popularity\n    \n    x_train = x_train[features]\n    x_valid = x_valid[features]\n    \n    sc = StandardScaler()\n\n    x_train[cont] = sc.fit_transform(x_train[cont])\n    x_valid[cont] = sc.transform(x_valid[cont])\n    x_test[cont] = sc.transform(x_test[cont])\n    \n    \n    model = XGBClassifier(**xgb_params)\n    model.fit(x_train,y_train,early_stopping_rounds=300,eval_set=[(x_valid,y_valid)],verbose=False)\n    y_val_pred = model.predict(x_valid)\n    y_pred = model.predict(x_test)\n    score = roc_auc_score(y_val_pred,y_valid)\n    scores.append(score)\n    predictions.append(y_pred)\n    print(\"Fold {} score is {}\" .format(fold,score))\nprint(\"Mean {} and standard deviation {} : \".format(np.mean(scores) , np.std(scores)))\n    \n","a4fc2b60":"pred = np.mean(np.column_stack(predictions),axis=1)\nprint(pred)\nsample.song_popularity = pred\nsample.to_csv(\"submission_xgb.csv\",index=False)","6787c252":"# predictions = []\n# scores = []\n\n\n\n# for fold in range(5):\n\n#     x_train = train_data[train_data.folds!=fold]\n#     x_valid  = train_data[train_data.folds == fold]\n#     x_test = test_data\n    \n#     y_train = x_train.song_popularity\n#     y_valid = x_valid.song_popularity\n    \n#     x_train = x_train[features]\n#     x_valid = x_valid[features]\n    \n#     sc = StandardScaler()\n\n# #     x_train[cont] = sc.fit_transform(x_train[cont])\n# #     x_valid[cont] = sc.transform(x_valid[cont])\n# #     x_test[cont] = sc.transform(x_test[cont])\n    \n    \n    \n    \n    \n#     model = LGBMClassifier(objective =  \"binary\")\n#     model.fit(x_train,y_train,early_stopping_rounds=300,eval_set=[(x_valid,y_valid)],verbose=False)\n#     y_val_pred = model.predict(x_valid)\n#     y_pred = model.predict(x_test)\n#     score = roc_auc_score(y_val_pred,y_valid)\n#     scores.append(score)\n#     predictions.append(y_pred)\n#     print(\"Fold {} score is {}\" .format(fold,score))\n# print(\"Mean {} and standard deviation {} : \".format(np.mean(scores) , np.std(scores)))\n    \n","c63d764f":"# pred = np.mean(np.column_stack(predictions),axis=1)\n# print(pred)\n# sample.song_popularity = pred\n# sample.to_csv(\"submission_lgb.csv\",index=False)","552e02e2":"# np.unique(pred)","54ddfa9b":"The missing values can be seen in 7 continous variables >> <font color = 'red'> song_duration_ms , acousticness , danceability , energy , instrumentalness , liveness , loudness <\/font><br>\nThe missing values can be seen in one categorical variable >> <font color = 'red'> key<\/font>","abb771fb":"#### There seems to be outliers in song_duration_ms , instrumentalness , liveness , loudness , speechiness and tempo","467baefd":"## Normalized Plots","892e72af":"#### We even have some rows containing 5-6 null values also","4fa97b14":"#### There is almost same percentage of null values in both train and test set","17d011fc":"\n#  Feature Explaination\n<div class=\"alert alert-block alert-info\" style=\"font-size:12px; font-family:verdana;\">\n\ud83d\udccc<b>Song Duration (ms)<\/b> : Time duration for the song\n\n\ud83d\udccc <b>Acousticness :<\/b> This value describes how acoustic a song is. A score of 1.0 means the song is most likely to be an acoustic one . eg : string instrumentations\n\n\ud83d\udccc <b>Danceability:<\/b> \u201cDanceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable\u201d.\n\n\ud83d\udccc<b>Energy :<\/b> \u201c(energy) represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy\u201d.\n\n\ud83d\udccc<b>Instrumentalness:<\/b> This value represents the amount of vocals in the song. The closer it is to 1.0, the more instrumental the song is.\n\n\ud83d\udccc<b>Key: <\/b>The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C\u266f\/D\u266d, 2 = D, and so on.\n\n\ud83d\udccc<b>Liveness: <\/b>This value describes the probability that the song was recorded with a live audience. According to the official documentation \u201ca value above 0.8 provides strong likelihood that the track is live\u201d.\n\n\ud83d\udccc<b>Loudness:<\/b> The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks.\n\n\ud83d\udccc<b>Audio Mode:<\/b> Indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n\n\ud83d\udccc<b>Speechiness:<\/b> \u201cSpeechiness detects the presence of spoken words in a track\u201d. If the speechiness of a song is above 0.66, it is probably made of spoken words, a score between 0.33 and 0.66 is a song that may contain both music and words, and a score below 0.33 means the song does not have any speech.\n\n\ud83d\udccc<b>Tempo:<\/b> The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece, and derives directly from the average beat duration.\n\n\ud83d\udccc <b>Time Signature:<\/b> An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).\n\n\ud83d\udccc<b>Valence:<\/b> Describes the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n","ff9df61a":"# Loading Data","43edd2ed":"# LightGBM","961c73ef":"## Features Overview\n- Song_duration_ms : Most of the songs are of duration 200 sec (3 min 20 sec). \n- Acousticness : Most of the songs are not acoustic.  \n- Danceability : Most of the songs are danceable and this also makes sense because as we see that not very much songs are acoustic so the songs may be played using electronic instruments and usually electronic music is more danceable\n- Energy : Most songs have high energy so most of the songs are fast , loud and noisy.\n- Instrumentalness : It has a very interesting distribution . The distribution shows here that songs have very less amount of vocals.\n- Liveness : It represents if a track was recorded live according to the distribution (>0.8) very less tracks were recorded with live audience.\n- Loudness : Most of the songs are loud and we can infer it maybe from energy . \n- Speechiness : The songs have very less amount of speech . \n- Tempo : Most of the songs have tempo between 60 to 125 .\n- Audio Valence : Valence has peaks at 0.6 and 1.0 that indicated the songs are more of positive nature.\n- Key : The key 0.0 and 6.0 has highest count of key values . \n- Audio Mode : Audio Mode is distributed almost same as target variable . Major Modality is 1\/3rd and Minor Modality is 2\/3rd.\n- Time signature  : There are very less songs with time signature value of 2 and  5 .","648f7c0d":"# <center> \ud83c\udfb6Song Prediction Kernel\ud83c\udfb6 <\/center>\n<!-- ## <center> If you find this notebook useful ,  -->\n<center><img src = \"https:\/\/www.liveabout.com\/thmb\/1zVxM4xaNKMzo_1MSF74cQcO9QY=\/768x0\/filters:no_upscale():max_bytes(150000):strip_icc():format(webp)\/pop-music-57bce3863df78c87634ea806.jpg\" height = 400 width = 400>","d70d1c3c":"## Data Overview\n- Train data has a total of 40k rows and 14 columns including <b>Target<\/b> (Song Popularity)\n- Test  data has a total of 10k rows and 13 columns \n- Train and Test data both contain null values \n- There are 3 categorical features >> <font color = \"green\" > key , audio_mode , time_signature  <\/font>\n- There are 10 continous features >> <font color = \"green\" > song_duration_ms , acousticness , danceability , energy , instrumentalness , liveness , loudness , speechiness , tempo , audio_valence   <\/font>\n- The target feature song_popularity is a binary feature [0,1]\n<br><i><b> Note: <\/b> I have reindexed data based on id feature<i>","9277c755":"\n# Loading Libraries","7969d9d8":"\n# Introduction\n\n\n**This challenge is about predicting Song Popularity based on a set of different features.**\n\n**The data consists of the standard Kaggle train.csv and test.csv files, with a sample_submission.csv to show you the structure of the file that should be submitted.**\n    \n**Submissions are evaluated based on Area Under the ROC Curve (AUC)**\n","a3f3ca18":"## To be continued ...","3a2e3f73":"## Correlation overview\n- A +ve correlation between energy and loudness as expected\n- A -ve correlation between loudness,energy and acousticness as expected\n- There us also a minor + ve correlation between danceability and audio_valence that is understood as dance also helps generating positive vibes . \n\n","ef5f8734":"# Modelling","ff599dae":"#### About 2\/3rd of the songs are not popular whereas 1\/3rd are popular ones","24e9c018":"# Visualizations","c897ac4e":"#### Target variable is imbalanced there are almost 10k more negative values as compared to positive values","e8f50abe":" I had already created stratified 5 folds for the data which I will be using in this notebook <br>\n You can find the creating folds notebook [here](https:\/\/www.kaggle.com\/prikshitsingla\/create-folds-song-prediction)<br>\n You can find the dataset [here](https:\/\/www.kaggle.com\/prikshitsingla\/song-prediction-5-stratified-folds)","899998e7":"# XGBoost","e93b371c":"# Missing Values","cbc26c60":"We should always keep the test set aside but if there are null values we can check in test set too because maybe the host has put null values and the null values are there for a reason . <br>In [Kaggle Tabular Playground Series - Sep 2021 Competition](https:\/\/www.kaggle.com\/c\/tabular-playground-series-sep-2021) just by using null values in a row as a sum the participants were able to reach AUC-ROC score of around 0.8"}}