{"cell_type":{"d567ff3d":"code","ba61bb30":"code","dfbe1c11":"code","f859274a":"code","1f2b3450":"code","1c4cf629":"code","209c9d32":"code","f8e1bfd7":"code","114ac32f":"code","6bec9ff2":"code","d839f149":"code","623e3574":"code","d9ad2d43":"code","66ea3b95":"code","1a2cf807":"code","151a7fa7":"code","d60e43f1":"code","a5ae0aed":"code","d7bce892":"code","5bc2818d":"code","ce3a34ab":"code","06265987":"code","db792742":"code","ed2eb96c":"code","e6e457a7":"code","8a8e523a":"code","287cfe5d":"code","21205022":"code","0ce3dde0":"code","6ec0c8eb":"code","24521784":"code","b5192c8b":"code","1740c297":"code","4095b666":"code","a6f2b0e4":"code","8d8025a4":"code","08f81189":"code","9022510b":"markdown","0e047591":"markdown","79c8f42e":"markdown","cf2076e2":"markdown","28d76d51":"markdown","2495f269":"markdown","03bd08df":"markdown","e9fd6853":"markdown","a4c116ab":"markdown","f26a3edc":"markdown","9af83c93":"markdown","a1d08371":"markdown","96157140":"markdown","857efefd":"markdown","be457943":"markdown","1dc68aab":"markdown","9a45fe24":"markdown","da03a4ea":"markdown","963cbfd2":"markdown","d21cc27e":"markdown","f7b39c9f":"markdown","29b20fd1":"markdown","9ec116a9":"markdown","3f873e8c":"markdown","cd614df4":"markdown","609bea4e":"markdown","d531c483":"markdown","b239d0e5":"markdown"},"source":{"d567ff3d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ba61bb30":"# INPUT\n# Candidate Features\naday = pd.read_csv(\"..\/input\/c\/c\/c\/datathon-who-gets-the-job\/Datathon_Aday.csv\") # Aday ile ilgili okul bilgileri ve ya\u015fad\u0131\u011f\u0131 \u015fehri\ntecrube = pd.read_csv(\"..\/input\/c\/c\/c\/datathon-who-gets-the-job\/Datathon_Tecrube.csv\") # Adaylar\u0131n ge\u00e7mi\u015f i\u015f tecr\u00fcbesini\nyetenek = pd.read_csv(\"..\/input\/c\/c\/c\/datathon-who-gets-the-job\/Datathon_Yetenek.csv\") # Aday\u0131n Kariyer.net \u00fczerinden girmi\u015f oldu\u011fu yetenekleri g\u00f6stermektedir.\n\n# Advertisement Features\nilan = pd.read_csv(\"..\/input\/c\/c\/c\/datathon-who-gets-the-job\/Datathon_ilan.csv\") # \u0130lan metni, pozisyon ad\u0131 ve lokasyon gibi bilgileri,\n\n# OUTPUT\nbasvuru_recruited = pd.read_csv(\"..\/input\/c\/c\/c\/datathon-who-gets-the-job\/Datathon_Basvuru_iseAlinanlar.csv\") # Ba\u015fvurusu sonucu i\u015fe al\u0131nan adaylar\u0131\n\n# PREDICT\nbasvuru = pd.read_csv(\"..\/input\/c\/c\/c\/datathon-who-gets-the-job\/Datathon_Basvuru.csv\") # Hangi aday\u0131n hangi i\u015f ilan\u0131na ba\u015fvurdu\u011fu\ntest = pd.read_csv(\"..\/input\/c\/c\/c\/datathon-who-gets-the-job\/test.csv\")\n","dfbe1c11":"# Haversine Length Function\n# https:\/\/medium.com\/@sddkal\/koordinatlar-aras\u0131-uzakl\u0131k-hesab\u0131-i\u00e7in-haversine-fonksiyonu-982d90c550bf\n\nimport numpy as np\nR = 6371\ndef pol2cart(lat, long):\n    lat, long = np.radians(lat), np.radians(long)\n    return R*np.cos(lat) *np.cos(long),\\\n           R*np.cos(lat) *np.sin(long),\\\n           R*np.sin(lat)\n\n\ndef haversine_dist(point1, point2):\n  point1_cart = np.array(pol2cart(*point1))\n  point2_cart = np.array(pol2cart(*point2))\n  euc_dist = np.linalg.norm(point1_cart-point2_cart)\n  sin_theta_2 = euc_dist \/ (R * 2)\n  theta_2 = np.arcsin(sin_theta_2)\n  theta = 2*theta_2\n  dist = R*theta\n  return dist\n\n# \u015eehirlerin koordinat listesi import edilir. Bu liste internetten farkl\u0131 websitelerinden derlenerek dataset olarak sunulmu\u015ftur.\ncoordinates = pd.read_csv(\"..\/input\/turkeycoordinates\/Coordinates.csv\")\n\ndef city_dist(city1, city2):\n    city1 = city1.replace(\"i\", \"\u0130\").upper()\n    city2 = city2.replace(\"i\", \"\u0130\").upper()\n    \n    # \u0130stanbul(Avr.) or \u0130stanbul(Asya) -> \"\u0130STANBUL\"\n    city1 = \"\u0130STANBUL\" if city1=='\u0130STANBUL(AVR.)' or city1=='\u0130STANBUL(ASYA)' else city1\n    city2 = \"\u0130STANBUL\" if city2=='\u0130STANBUL(AVR.)' or city2=='\u0130STANBUL(ASYA)' else city2\n    \n    # Get coordinates\n    city1 = coordinates[coordinates.City == city1]\n    city2 = coordinates[coordinates.City == city2]\n    \n    # Eger sehirlerden birisi kayitli degilse 0 dondur\n    if city1.lat.dtype != 'float64' or city2.lat.dtype != 'float64':\n        return 0\n    else:\n        city1_coor = (city1.lat, city1.long)\n        city2_coor = (city2.lat, city2.long)\n        return haversine_dist(city1_coor, city2_coor)\n    ","f859274a":"# aday.info()\n# tecrube.info()\n# yetenek.info()\n\n# ilan.info()\n\n# basvuru_recruited.info()\n\n# basvuru.info()\n#len(basvuru_recruited.AdayId.unique())","1f2b3450":"def distance(adayid, ilanid):\n    # city1 = coordinates[coordinates.City == city1]\n    try:\n        aday_city = aday[aday.AdayId == adayid].SehirAdi.dropna()\n        aday_city = aday_city.tolist()[0] # E\u011fer birden fazla tan\u0131mlanm\u0131\u015fsa ilkini al\n        ilan_city = ilan[ilan.IlanId == ilanid].lokasyon.dropna().tolist()[0]\n    except IndexError:\n        return 0\n    return city_dist(aday_city, ilan_city)\n\ndistance(11178450, 2752333)","1c4cf629":"def experience_position(adayid, ilanid):\n    ilanExperience = ilan[ilan.IlanId == ilanid].pozisyonAdi.tolist()[0]\n    adayExperiences = tecrube[tecrube.AdayId == adayid] # Aday\u0131n deneyimleri\n    adayExperiences = adayExperiences[adayExperiences.PozisyonAdi == ilanExperience].CalismaAyi\n    return adayExperiences.sum()\n\nexperience_position(16377536, 2077585)\n# aday[aday.AdayId == 22742218].BitisYili","209c9d32":"def experience_industry(adayid, ilanid):\n    ilanExperience = ilan[ilan.IlanId == ilanid].sektorAdi.tolist()[0]\n    adayExperiences = tecrube[tecrube.AdayId == adayid] # Aday\u0131n deneyimleri\n    adayExperiences = adayExperiences[adayExperiences.SektorAdi == ilanExperience].CalismaAyi\n    return adayExperiences.sum()\n\nexperience_industry(16377536, 2077585)","f8e1bfd7":"def eduLevel(adayid):\n    aday_level = aday[aday.AdayId == adayid].Tip.tolist()[0]\n    if aday_level == 'Belirtilmemi\u015f':\n        ret = 0\n    elif aday_level == '\u00d6nlisans':\n        ret = 1\n    elif aday_level == 'Lisans':\n        ret = 2\n    elif aday_level == 'Y.Lisans':\n        ret = 3\n    elif aday_level == 'Doktora':\n        ret = 4\n    else:\n        ret = 0\n    return ret\n\neduLevel(16377536)","114ac32f":"def yearGraduation(adayid):\n    graduation_date = aday[aday.AdayId == adayid].BitisYili.tolist()[0]\n    if np.isnan(graduation_date) or graduation_date == 0.0:\n        ret = 0.0\n    else:\n        ret = 2021 - graduation_date\n    return ret\n\nyearGraduation(16377536)","6bec9ff2":"def school(adayid):\n    return aday[aday.AdayId == adayid].OkulId.tolist()[0]\n\nschool(16377536)","d839f149":"def department_match(adayid, ilanid):\n    try:\n        aday_department = aday[aday.AdayId == adayid].BolumAdi.dropna().tolist()[0]\n        ilan_qualifications = ilan[ilan.IlanId == ilanid].Nitelikler.tolist()[0].split()\n    except IndexError:\n        return 0\n    if False in [i in ilan_qualifications for i in aday_department.split()]: # E\u011fer b\u00f6l\u00fcm ismi (bir ka\u00e7 kelime varsa herhangi biri) niteliklerde ge\u00e7miyorsa 0 d\u00f6nd\u00fcr. Ge\u00e7iyorsa 1 d\u00f6nd\u00fcr.\n        return 0\n    else:\n        return 1\n\ndepartment_match(2438572, 2631636)","623e3574":"def ability(adayid, ilanid):\n    aday_abilities = yetenek[yetenek.AdayId == adayid].Yetenek.tolist()\n    ilan_qualifications = ilan[ilan.IlanId == ilanid].Nitelikler.tolist()[0].split()\n    total_mention = [ilan_qualifications.count(ability) for ability in aday_abilities]\n    return sum(total_mention) \/ len(ilan_qualifications)\n\nability(16377536, 2077585)","d9ad2d43":"def job_text(adayid, ilanid):\n    ilan_text = ilan[ilan.IlanId == ilanid].ilanMetni.tolist()[0].split()\n    aday_text = tecrube[tecrube.AdayId == adayid].Aciklama.dropna().tolist() # Aday\u0131n deneyimlerinin text'leri\n    aday_text = set([j for i in aday_text for j in i.split()]) # Aday\u0131n t\u00fcm deneyimlerinin tekrar etmeyen kelimeleri\n    num = 0\n    for i in ilan_text:\n        if i in aday_text:\n            num += 1\n    return num\/len(ilan_text)\n\njob_text(16377536, 2077585)","66ea3b95":"def qualifications_text(adayid, ilanid):\n    try:\n        ilan_text = ilan[ilan.IlanId == ilanid].Nitelikler.dropna().tolist()[0].split()\n        aday_text = list(yetenek[yetenek.AdayId == adayid].Yetenek.dropna().tolist()[0].split()) # Aday\u0131n yetene\u011fi (split birden fazla kelime i\u00e7in kondu. En son b\u00f6l\u00fcnecek)\n    except IndexError:\n        return 0\n    num = 0\n    for i in ilan_text:\n        if i in aday_text:\n            num += 1\n    return num\/(len(ilan_text) * len(aday_text))\n\nqualifications_text(2510453, 2131294)","1a2cf807":"x_data = pd.DataFrame(columns=[\n    \"AdayId\", \n    \"IlanId\", \n    \"distance\", \n    \"experience_position\", \n    \"experience_industry\", \n    \"eduLevel\", \n    \"yearGraduation\", \n    \"school\", \n    \"department_match\", \n    \"ability\", \n    \"job_text\", \n    \"qualifications_text\"\n                              ])\nx_data","151a7fa7":"def add_data(data, adayid, ilanid, recruited = None):\n    \n    val = {\n        \"AdayId\": adayid,\n        \"IlanId\": ilanid,\n        \"distance\": distance(adayid, ilanid),\n        \"experience_position\": experience_position(adayid, ilanid),\n        \"experience_industry\": experience_industry(adayid, ilanid),\n        \"eduLevel\": eduLevel(adayid),\n        \"yearGraduation\": yearGraduation(adayid),\n        \"school\": school(adayid),\n        \"department_match\": department_match(adayid, ilanid),\n        \"ability\": ability(adayid, ilanid),\n        \"job_text\": job_text(adayid, ilanid),\n        \"qualifications_text\": qualifications_text(adayid, ilanid),\n        \"recruited\": recruited\n        }\n    return data.append(val, ignore_index=True)\n\n# x_data = add_data(x_data, 16377536, 2077585)\nx_data","d60e43f1":"def ishired(adayid, ilanid):\n    hired_persons = basvuru_recruited[basvuru_recruited.ilanId == ilanid].AdayId.tolist()\n    if adayid in hired_persons:\n        return 1\n    else:\n        return 0","a5ae0aed":"# 50000 - 2866\ndataset_50k = pd.concat([basvuru_recruited, basvuru[:(50000 - 2866)]], ignore_index=True)\ndataset_50k","d7bce892":"import time\nstart = time.time()\nfor index,row in dataset_50k.iterrows():\n    adayid, ilanid = row[\"AdayId\"], row[\"ilanId\"]\n    if ishired(adayid, ilanid):\n        x_data = add_data(x_data, adayid, ilanid, recruited=1)\n    else:\n        x_data = add_data(x_data, adayid, ilanid, recruited=0)\n\nprint(time.time() - start)","5bc2818d":"x_data.to_csv(\"\/kaggle\/working\/dataset_50k.csv\")","ce3a34ab":"# dataset_100kplus = basvuru[(50000 - 2866):(150000 - 2866)].reset_index()\n# dataset_100kplus","06265987":"\"\"\"\nimport time\nstart = time.time()\nfor index,row in dataset_100kplus.iterrows():\n    adayid, ilanid = row[\"AdayId\"], row[\"ilanId\"]\n    if ishired(adayid, ilanid):\n        x_data = add_data(x_data, adayid, ilanid, recruited=1)\n    else:\n        x_data = add_data(x_data, adayid, ilanid, recruited=0)\n\nprint(time.time() - start)\nx_data.to_csv(\"\/kaggle\/working\/dataset_150k.csv\")\n\"\"\"","db792742":"import tensorflow as tf\nfrom tensorflow import keras","ed2eb96c":"device_name = tf.test.gpu_device_name()\nif device_name != '\/device:GPU:0':\n  raise SystemError('GPU device not found')\nprint('Found GPU at: {}'.format(device_name))","e6e457a7":"df = pd.read_csv(\"..\/input\/kariyernet-datathlon\/dataset_50k.csv\")\ndf = df.fillna(0)\ndf","8a8e523a":"inputs = df[[\"distance\", \"experience_position\", \"experience_industry\", \"eduLevel\", \"yearGraduation\", \"school\", \"department_match\", \"ability\", \"job_text\", \"qualifications_text\"]]\noutputs = df.recruited\n\nx_train = inputs[:45000]\ny_train = outputs[:45000]\nx_test = inputs[45000:]\ny_test = outputs[45000:]","287cfe5d":"model = keras.models.Sequential([\n    keras.layers.Dense(10, activation='relu'),\n    keras.layers.Dense(10, activation='relu'),\n    keras.layers.Dense(15, activation='relu'),\n    keras.layers.Dense(10, activation='relu'),\n    keras.layers.Dense(5, activation='relu'),\n    keras.layers.Dense(1, activation='sigmoid')\n])","21205022":"loss = keras.losses.BinaryCrossentropy()\noptim = keras.optimizers.Adam(learning_rate=0.01)\nmetrics = ['accuracy']  # Burada saklamak istedi\u011fimiz bilgileri yaz\u0131yoruz.\nmodel.compile(loss=loss, optimizer=optim, metrics=metrics)","0ce3dde0":"batch_size = 64\nepochs = 10","6ec0c8eb":"model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=1)","24521784":"model.evaluate(x_test, y_test, batch_size=batch_size, verbose=2)","b5192c8b":"predict_df = pd.DataFrame(columns=[\"ilanId\", \"AdayId\"])\n\ndef add_predict(data, ilanid, adayid):\n    val={\n        \"ilanId\": ilanid,\n        \"AdayId\": adayid\n    }\n    return data.append(val, ignore_index=True)","1740c297":"# Make empty dataset\nmk_dataset = lambda: pd.DataFrame(columns=[\n    \"AdayId\", \n    \"IlanId\", \n    \"distance\", \n    \"experience_position\", \n    \"experience_industry\", \n    \"eduLevel\", \n    \"yearGraduation\", \n    \"school\", \n    \"department_match\", \n    \"ability\", \n    \"job_text\", \n    \"qualifications_text\"\n                              ])","4095b666":"# Add data\ndef id2data(dataset):\n    x_data = mk_dataset()\n    for index,row in dataset.iterrows():\n        adayid, ilanid = row[\"AdayId\"], row[\"ilanId\"]\n        \n        x_data = add_data(x_data, adayid, ilanid)\n    return x_data","a6f2b0e4":"num = 1\nfor ilanid in test.ilanId:\n    id_data = basvuru[basvuru.ilanId == ilanid].reset_index()\n    r2p = id2data(id_data)\n    r2p = r2p[[\"distance\", \"experience_position\", \"experience_industry\", \"eduLevel\", \"yearGraduation\", \"school\", \"department_match\", \"ability\", \"job_text\", \"qualifications_text\"]]\n    predict = model.predict(r2p)\n    indices = (-predict.flatten()).argsort()[:5]\n    id_list = id_data.AdayId.tolist()\n    for indice in indices:\n        adayid = id_list[indice]\n        predict_df = add_predict(predict_df, ilanid, adayid)\n    print(f\"{num} \/ 776\") # Sadece ilerleyi\u015fi g\u00f6rebilmek ad\u0131na yazd\u0131r\u0131ld\u0131.\n    num += 1","8d8025a4":"predict_df","08f81189":"predict_df.to_csv(\"\/kaggle\/working\/predict.csv\")","9022510b":"## School\nOkul ID'si direkt olarak al\u0131n\u0131r.","0e047591":"# Haversine Function\nBu fonksiyon koordinatlar aras\u0131 mesafe \u00f6l\u00e7\u00fcm\u00fc i\u00e7in kullan\u0131lmaktad\u0131r. Bir medium yaz\u0131s\u0131ndan al\u0131nm\u0131\u015ft\u0131r.<br>\nBurada \u015fehirlerin koordinat listeleri internetten farkl\u0131 kaynaklardan toplan\u0131p bir dataset olu\u015fturulmu\u015f bu dataset payla\u015f\u0131lm\u0131\u015ft\u0131r.","79c8f42e":"## Year of Graduation\nAday\u0131n mezun olal\u0131 ka\u00e7 sene olmu\u015f?<br>\nnan veya 0 i\u00e7in de\u011fer 0 y\u0131l al\u0131n\u0131r.","cf2076e2":"## Import Tensorflow\nE\u011fitim i\u00e7in TensorFlow framework'u kullan\u0131lm\u0131\u015ft\u0131r.","28d76d51":"## Month of Experience - Industry\nAday ilanda belirtilen sekt\u00f6rde daha \u00f6nceden ka\u00e7 ay \u00e7al\u0131\u015fm\u0131\u015f?","2495f269":"## Education Level\n**E\u011fitim durumu.** <br>\n0 -> Belirtilmemi\u015f<br>\n1 -> \u00d6nlisans<br>\n2 -> Lisans<br>\n3 -> Y.Lisans<br>\n4 -> Doktora","03bd08df":"## Generate Dataset 50k\n2866 tanesi i\u015fe al\u0131nan adaylardan olu\u015fan 50.000 adet veriden olu\u015fan bir dataset \u00fcretir.<br>\nBu dataset 'dataset_50k.csv' ismiyle kaydedilir. B\u00f6ylece train k\u0131sm\u0131ndan \u00f6nce notebook kapat\u0131l\u0131p sonradan devam edilebilir.","e9fd6853":"## Evaluate","a4c116ab":"## Department Match\nAday\u0131n okudu\u011fu b\u00f6l\u00fcm\u00fcn ismi ilanda aranan niteliklerde ge\u00e7iyor mu?","f26a3edc":"## Generate Dataset Plus 100k\n\u0130ste\u011fe ba\u011fl\u0131 olarak 100k kadar daha i\u015fe kabul edilmeyen kullan\u0131c\u0131 verisi \u00f6nceki dataset'in sonuna ilave edilebilir.","9af83c93":"# Say\u0131sal De\u011ferlerin Bulundu\u011fu Data Listesinin \u00dcretilmesi","a1d08371":"## Ability\nAday\u0131n yetenekleri ilandaki kelimelerin ne kadarl\u0131k bir k\u0131sm\u0131nda ge\u00e7iyor? (%)","96157140":"## Predict\nTahminleme a\u015famas\u0131nda i\u00e7in her bir ilana ba\u015fvuru yapan t\u00fcm adaylar\u0131n o ilan\u0131 kazanma olas\u0131l\u0131\u011f\u0131 hesaplan\u0131r. En y\u00fcksek olas\u0131l\u0131\u011fa sahip 5 aday i\u015fverene sunulur.","857efefd":"## Train","be457943":"## Define Model\nModelin \u00e7\u0131kt\u0131s\u0131 sigmoid fonksiyonuna sokulmu\u015ftur. B\u00f6ylece 0 ile 1 aras\u0131 bir de\u011fer elde edilmesi sa\u011flan\u0131r.","1dc68aab":"## Job Text\n\u0130lan metninde ge\u00e7en *tekrar etmeyen* kelimelerden ne kadar\u0131 aday\u0131n ge\u00e7mi\u015f deneyimlerinin a\u00e7\u0131klamalar\u0131nda bulunuyor? (%)","9a45fe24":"## Import Dataset & Split Train\/Test Data\nBu \u00f6rnek i\u00e7in 50,000 veriye sahip bir dataset kullan\u0131lm\u0131\u015f, train 45,000, test 5000 veri olacak \u015fekilde ayr\u0131lm\u0131\u015ft\u0131r.","da03a4ea":"# Review Data","963cbfd2":"# Sistemin \u00c7al\u0131\u015fma Mant\u0131\u011f\u0131\nBa\u015fvuru yapan her bir aday\u0131n i\u015fe se\u00e7ilmek i\u00e7in belirli bir olas\u0131l\u0131\u011f\u0131 vard\u0131r. Her bir aday i\u00e7in birbirinden ba\u011f\u0131ms\u0131z olarak se\u00e7ilme olas\u0131l\u0131\u011f\u0131 tahmin edilecektir. En y\u00fcksek olas\u0131l\u0131\u011fa sahip 5 aday i\u015fverene \u00f6nerilecektir. <br>\nBurada adaylar\u0131n birbirini tan\u0131mad\u0131\u011f\u0131 i\u00e7in birbirinden etkilenmeyece\u011fi d\u00fc\u015f\u00fcn\u00fclerek adaylar aras\u0131nda bir ba\u011f olmad\u0131\u011f\u0131 kabul edilmi\u015ftir.<br>\nHer bir aday\u0131n \u00f6zge\u00e7mi\u015fi ile i\u015f metni aras\u0131nda farkl\u0131 ili\u015fkiler kurularak say\u0131sal girdiler olu\u015fturulmu\u015f, bu girdiler ile ANN e\u011fitilerek tahminleme sa\u011flanm\u0131\u015ft\u0131r.<br>\nBu ili\u015fkiler a\u015fa\u011f\u0131da maddeler halinde a\u00e7\u0131klanm\u0131\u015ft\u0131r.","d21cc27e":"# Data'dan Say\u0131sal \u0130li\u015fkiler Elde Etmek","f7b39c9f":"# Train","29b20fd1":"## Tahminlerin \u0130ncelenmesi \/ Kaydedilmesi","9ec116a9":"# Import Csv","3f873e8c":"## Month of Experience - Position\nAday ilanda belirtilen pozisyonda daha \u00f6nceden ka\u00e7 ay \u00e7al\u0131\u015fm\u0131\u015f?","cd614df4":"## Define Parameters\n**Loss Function:** Binary Crossentropy<br>\n**Optimizer:** Adam","609bea4e":"## Test Recruited or Not\nGirilen aday\u0131n i\u015fe al\u0131n\u0131p al\u0131nmad\u0131\u011f\u0131n\u0131 d\u00f6nd\u00fcr\u00fcr. 1 i\u015fe al\u0131nd\u0131, 0 al\u0131nmad\u0131 anlam\u0131na gelir.","d531c483":"## Qualifications Text\n\u0130lan niteliklerinde ge\u00e7en kelimelerden ne kadar\u0131 aday\u0131n yeteneklerinin i\u00e7erisinde? (%)","b239d0e5":"## Distance\nAday\u0131n lokasyonunun ilan\u0131n lokasyonuna olan uzakl\u0131\u011f\u0131"}}