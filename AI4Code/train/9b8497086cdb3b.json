{"cell_type":{"c93494e8":"code","89438965":"code","a125625b":"code","6364f8ce":"code","e722c6dd":"code","6640602e":"code","623e152b":"code","36220f0b":"code","021e0fc8":"code","4f71dfb1":"code","17e07ee1":"code","166428ae":"code","89d4351e":"code","d1765019":"code","4231e724":"code","8ba041b9":"code","8db57f30":"code","16bfd362":"code","071e092b":"code","a67a9d90":"markdown","71649dde":"markdown","fceb855f":"markdown","1e1a7796":"markdown","ff2d085c":"markdown","f9bb3dbc":"markdown","c91e1707":"markdown","7ccaeaa4":"markdown","d3703b4d":"markdown","1483ba1f":"markdown","a12c19c5":"markdown","e46301aa":"markdown","0c1f0132":"markdown","a51698ff":"markdown","8c6b953d":"markdown","6577d09f":"markdown","183ec588":"markdown","6fd01b2b":"markdown"},"source":{"c93494e8":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom sklearn.ensemble import RandomForestClassifier as rf\n\nwarnings.filterwarnings(\"ignore\")\n\n#import os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))","89438965":"use_cols = ['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7_Part_1', 'Q7_Part_2', 'Q7_Part_3', 'Q7_Part_4', 'Q7_Part_5', 'Q7_Part_6', \n            'Q7_Part_7', 'Q7_Part_8', 'Q7_Part_9', 'Q7_Part_10', 'Q7_Part_11', 'Q7_Part_12', 'Q7_OTHER', 'Q8', 'Q14_Part_1', 'Q14_Part_2', \n            'Q14_Part_3', 'Q14_Part_4', 'Q14_Part_5', 'Q14_Part_6', 'Q14_Part_7', 'Q14_Part_8', 'Q14_Part_9', 'Q14_Part_10', 'Q14_Part_11', \n            'Q14_OTHER', 'Q16_Part_1', 'Q16_Part_2', 'Q16_Part_3', 'Q16_Part_4', 'Q16_Part_5', 'Q16_Part_6', 'Q16_Part_7', 'Q16_Part_8', \n            'Q16_Part_9', 'Q16_Part_10', 'Q16_Part_11', 'Q16_Part_12', 'Q16_Part_13', 'Q16_Part_14', 'Q16_Part_15', 'Q16_Part_16', \n            'Q16_Part_17', 'Q16_OTHER', 'Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', \n            'Q17_Part_8', 'Q17_Part_9', 'Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER', 'Q18_Part_1', 'Q18_Part_2', 'Q18_Part_3', 'Q18_Part_4', \n            'Q18_Part_5', 'Q18_Part_6', 'Q18_OTHER', 'Q19_Part_1', 'Q19_Part_2', 'Q19_Part_3', 'Q19_Part_4', 'Q19_Part_5', 'Q19_OTHER', \n            'Q20', 'Q21', 'Q22', 'Q23', 'Q24_Part_1', 'Q24_Part_2', 'Q24_Part_3', 'Q24_Part_4', 'Q24_Part_5', 'Q24_Part_6', 'Q24_Part_7', \n            'Q24_OTHER', 'Q25']\n\ndf = pd.read_csv('\/kaggle\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv', usecols = use_cols)\n\nlanguages_dict = {'Q1': 'Age', 'Q2': 'Gender', 'Q4': 'Education', 'Q5': 'Job', 'Q6': 'Experience', 'Q7_Part_1': 'Python', \n                  'Q7_Part_2': 'R', 'Q7_Part_3': 'SQL', 'Q7_Part_4': 'C', 'Q7_Part_5': 'C++', 'Q7_Part_6': 'Java', \n                  'Q7_Part_7': 'Javascript', 'Q7_Part_8': 'Julia', 'Q7_Part_9': 'Swift', 'Q7_Part_10': 'Bash', \n                  'Q7_Part_11': 'MATLAB', 'Q7_Part_12': 'No_Languages', 'Q7_OTHER': 'Other_Language', \n                  'Q8': 'Recommend_first_language', 'Q14_Part_1': 'Vis_Matplotlib', 'Q14_Part_2': 'Vis_Seaborn', \n                  'Q14_Part_3': 'Vis_Plotly', 'Q14_Part_4': 'Vis_GGPlot', 'Q14_Part_5': 'Vis_Shiney', \n                  'Q14_Part_6': 'Vis_D3JS', 'Q14_Part_7': 'Vis_Altair', 'Q14_Part_8': 'Vis_Bokeh', \n                  'Q14_Part_9': 'Vis_Geoplotlib', 'Q14_Part_10': 'Vis_Folium', 'Q14_Part_11': 'Vis_None', \n                  'Q14_OTHER': 'Vis_Other', 'Q16_Part_1': 'ML_SciKitLearn', 'Q16_Part_2': 'ML_TensorFlow', \n                  'Q16_Part_3': 'ML_Keras', 'Q16_Part_4': 'ML_Pytorch', 'Q16_Part_5': 'ML_Fast.ai', \n                  'Q16_Part_6': 'ML_MXNet', 'Q16_Part_7': 'ML_XGBoost', 'Q16_Part_8': 'ML_LightGBM', \n                  'Q16_Part_9': 'ML_CatBoost', 'Q16_Part_10': 'ML_Prophet', 'Q16_Part_11': 'ML_H2O 3', \n                  'Q16_Part_12': 'ML_Caret', 'Q16_Part_13': 'ML_TidyModels', 'Q16_Part_14': 'ML_Jax', \n                  'Q16_Part_15': 'ML_PYLightning', 'Q16_Part_16': 'ML_Huggingface', 'Q16_Part_17': 'ML_None', \n                  'Q16_OTHER': 'ML_Other', 'Q17_Part_1': 'Alg_Regress', 'Q17_Part_2': 'Alg_Trees', \n                  'Q17_Part_3': 'Alg_Gradient', 'Q17_Part_4': 'Alg_Bayesian', 'Q17_Part_5': 'Alg_Evolution', \n                  'Q17_Part_6': 'Alg_DenseNeural', 'Q17_Part_7': 'Alg_ConvNeural', 'Q17_Part_8': 'Alg_Generative', \n                  'Q17_Part_9': 'Alg_RecurNeural', 'Q17_Part_10': 'Alg_Transformer', 'Q17_Part_11': 'Alg_None', \n                  'Q17_OTHER': 'Alg_Other', 'Q18_Part_1': 'CV_General', 'Q18_Part_2': 'CV_Segment', \n                  'Q18_Part_3': 'CV_Detect', 'Q18_Part_4': 'CV_Classify', 'Q18_Part_5': 'CV_Generative', \n                  'Q18_Part_6': 'CV_None', 'Q18_OTHER': 'CV_Other', 'Q19_Part_1': 'NLP_Word', 'Q19_Part_2': 'NLP_Models',\n                  'Q19_Part_3': 'CV_context', 'Q19_Part_4': 'CV_transformer', 'Q19_Part_5': 'CV_None', \n                  'Q19_OTHER': 'CV_Other', 'Q20': 'Industry', 'Q21': 'No_Employee', 'Q22': 'No.Scientists', \n                  'Q23': 'ML_in_business', 'Q24_Part_1': 'Work_Analyse', 'Q24_Part_2': 'Work_Infrastruct', \n                  'Q24_Part_3': 'Work_Proto', 'Q24_Part_4': 'Work_Service', 'Q24_Part_5': 'Work_Improve', \n                  'Q24_Part_6': 'Work_StateArt', 'Q24_Part_7': 'Work_Other', 'Q24_OTHER': 'Work_Other', 'Q25': 'Salary'}\n\ndf.rename(languages_dict, axis = 1, inplace = True)\n\n#first row contains information on questions\ndf.drop(0, inplace = True)\n\nhot_encode = ['Python','R', 'SQL', 'C', 'C++', 'Java', 'Javascript', 'Julia', 'Swift', 'Bash', 'MATLAB',\n              'No_Languages', 'Other_Language','Vis_Matplotlib', 'Vis_Seaborn', 'Vis_Plotly', 'Vis_Altair', \n              'Vis_Bokeh', 'Vis_Geoplotlib', 'Vis_Folium','ML_SciKitLearn', 'ML_TensorFlow', 'ML_Keras', \n              'ML_Pytorch', 'ML_Fast.ai', 'ML_MXNet', 'ML_XGBoost', 'ML_LightGBM', 'ML_CatBoost', \n              'ML_Prophet', 'ML_H2O 3', 'ML_Jax', 'ML_PYLightning', 'ML_Huggingface']\n\nfor column in hot_encode:\n    df[column] = df[column].apply(lambda x: 1 if not pd.isna(x) else 0)\n   \nnew_entrants = df.loc[(df['Experience'] == '1-3 years') | (df['Experience'] ==  '< 1 years')]\n\nnew_entrants.drop(['Q3', 'Experience' ],axis = 1, inplace = True)","a125625b":"languages = ['Python','R', 'SQL', 'C', 'C++', 'Java', 'Javascript', 'Julia', 'Swift', 'Bash', 'MATLAB', \n             'No_Languages', 'Other_Language']\n\nlanguage_counts = []\n\nfor column in languages:\n    language_counts.append((column, new_entrants[column].sum()))\n    \nlanguage_counts.sort(key = lambda x: x[1], reverse = True)\n\nlanguages_df = pd.DataFrame(language_counts, columns = ['Language', 'Count'])\n\nplt.figure(figsize=(20, 15))\nsns.barplot(x = 'Language', y = 'Count', data = languages_df)\nplt.title('Number of Respondents Fluent in each Programming Language ')\n\n\nplt.show()","6364f8ce":"plt.figure(figsize=(20, 15))\nplt.title('Recommended First Language - Excluding Python')\nnew_entrants['Recommend_first_language'].value_counts().nsmallest(12).plot.pie()\nplt.show()","e722c6dd":"Python_Visualisations = ['Vis_Matplotlib', 'Vis_Seaborn', 'Vis_Plotly', 'Vis_Altair', 'Vis_Bokeh', \n                         'Vis_Geoplotlib', 'Vis_Folium']\n\nvisualisations_counts = []\n\nfor column in Python_Visualisations:\n    visualisations_counts.append((column, new_entrants[column].sum()))\n    \nvisualisations_counts.sort(key = lambda x: x[1], reverse = True)\n\nvisualisations_df = pd.DataFrame(visualisations_counts, columns = ['Visualisation', 'Count'])\n\nplt.figure(figsize=(20, 15))\nsns.barplot(x = 'Visualisation', y = 'Count', data = visualisations_df)\nplt.title('Number of Respondents Using each Visualisation Package')\n\n\nplt.show()","6640602e":"python_machine_learning = ['ML_SciKitLearn', 'ML_TensorFlow', 'ML_Keras', 'ML_Pytorch', 'ML_Fast.ai', 'ML_MXNet',\n                           'ML_XGBoost', 'ML_LightGBM', 'ML_CatBoost', 'ML_Prophet', 'ML_H2O 3', 'ML_Jax', \n                           'ML_PYLightning', 'ML_Huggingface']\n\nmachine_learning_counts = []\n\nfor column in python_machine_learning:\n    machine_learning_counts.append((column, new_entrants[column].sum()))\n    \nmachine_learning_counts.sort(key = lambda x: x[1], reverse = True)\n\nmachine_learning_df = pd.DataFrame(machine_learning_counts, columns = ['machine_learning', 'Count'])\n\nplt.figure(figsize=(20, 15))\nsns.barplot(x = 'machine_learning', y = 'Count', data = machine_learning_df)\nplt.title('Number of Respondents Using each Machine Learning Package')\n\n\nplt.show()","623e152b":"experience_3_10 = df.loc[(df['Experience'] == '3-5 years') | (df['Experience'] ==  '5-10 years')]\nexperience_ten_plus = df.loc[(df['Experience'] == '10-20 years') | (df['Experience'] ==  '20+ years')]","36220f0b":"language_counts = []\n\n#mean is being used rather than sum to normalise data\nfor column in languages:\n    language_counts.append((column, new_entrants[column].mean(), experience_3_10[column].mean(), \n                            experience_ten_plus[column].mean()))\n    \nlanguage_counts.sort(key = lambda x: x[1], reverse = True)\n\nlanguages_df = pd.DataFrame(language_counts, columns = ['Language', 'New', 'Experienced', 'Senior'])\nlanguages_df.set_index('Language', inplace = True)\n\nlanguages_df.plot(kind='bar', figsize=(20,15))\nplt.title('Language usage by experience level')\nplt.tick_params(axis='y', which='both', right=False, left=False, labelleft=False)\n\nplt.show()","021e0fc8":"visualisations_counts = []\n\n#mean is being used rather than sum to normalise data\nfor column in Python_Visualisations:\n    visualisations_counts.append((column, new_entrants[column].mean(), experience_3_10[column].mean(), \n                            experience_ten_plus[column].mean()))\n    \nvisualisations_counts.sort(key = lambda x: x[1], reverse = True)\n\nvisualisations_df = pd.DataFrame(visualisations_counts, columns = ['Visualisation', 'New', 'Experienced', 'Senior'])\nvisualisations_df.set_index('Visualisation', inplace = True)\n\nvisualisations_df.plot(kind='bar', figsize=(20,15))\nplt.title('Visualisation package usage by experience level')\nplt.tick_params(axis='y', which='both', right=False, left=False, labelleft=False)\n\nplt.show()","4f71dfb1":"ml_counts = []\n\n#mean is being used rather than sum to normalise data\nfor column in python_machine_learning:\n    ml_counts.append((column, new_entrants[column].mean(), experience_3_10[column].mean(), \n                      experience_ten_plus[column].mean()))\n    \nml_counts.sort(key = lambda x: x[1], reverse = True)\n\nml_df = pd.DataFrame(ml_counts, columns = ['Machine Learning', 'New', 'Experienced', 'Senior'])\nml_df.set_index('Machine Learning', inplace = True)\n\nml_df.plot(kind='bar', figsize=(20,15))\nplt.title('Machine Learning package usage by experience level')\nplt.tick_params(axis='y', which='both', right=False, left=False, labelleft=False)\n\nplt.show()","17e07ee1":"df_uk = df.loc[df['Q3'] == 'United Kingdom of Great Britain and Northern Ireland']\n\nGBP_salary = {'40,000-49,999' : 30000, '50,000-59,999': 36000, '60,000-69,999': 43000, \n              '30,000-39,999': 23000, '80,000-89,999': 56000, '70,000-79,999': 50000, \n              '100,000-124,999': 76000, '$0-999': 333, '90,000-99,999': 63000, '125,000-149,999': 93000, \n              '25,000-29,999': 18000, '20,000-24,999': 15000, '150,000-199,999': 116000, \n              '200,000-249,999': 150000, '15,000-19,999': 11600, '10,000-14,999': 8300, \n              '2,000-2,999': 1666, '300,000-499,999': 266000, '7,500-9,999': 5300, \n              '250,000-299,999': 183000, '$500,000-999,999': 500000, '1,000-1,999': 1000, \n              '4,000-4,999': 3000, '>$1,000,000': 650000, '5,000-7,499': 4000}\n              \ndf_uk.replace({\"Salary\": GBP_salary}, inplace = True)\n\n#Too small sample size (8 in total)\ndf_uk.replace(['Nonbinary','Prefer not to say', 'Prefer to self-describe'] , np.nan, inplace = True)\n\ndf_uk['Tot_Languages'] = df[languages].sum(axis=1)\ndf_uk['Tot_Visualisations'] = df[Python_Visualisations].sum(axis=1)\ndf_uk['Tot_ML'] = df[python_machine_learning].sum(axis=1)\n\ndf_uk[['Salary','Tot_Languages', 'Tot_Visualisations', 'Tot_ML']].corr()","166428ae":"Ave_Salary = []\n\nfor column in python_machine_learning:\n    if df_uk[column].sum() > 20:\n        average = df_uk.loc[df_uk[column] == 1, 'Salary'].mean()\n        Ave_Salary.append((column, average))\n    \nAve_Salary_df = pd.DataFrame(Ave_Salary, columns = ['machine_learning', 'Ave_Salary'])\n\nplt.figure(figsize=(20, 15))\nsns.barplot(x = 'machine_learning', y = 'Ave_Salary', data = Ave_Salary_df)\nplt.title('Average Salary for those with each Machine Learning Package in the UK')\n\n\nplt.show()\n    ","89d4351e":"df_uk['Gender'].value_counts()\n\ndf_uk.groupby(['Age', 'Gender'])['Salary'].mean()\n\norder_x = ['18-21', '22-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50-54', '55-59', '60-69', '70+']\n\nplt.figure(figsize=(20, 15))\nplt.title('Salary by Age and Gender')\nsns.barplot(x = 'Age', y = 'Salary', hue = 'Gender', ci = None, data=df_uk,  order = order_x)\n\n\nplt.show()","d1765019":"int_salary = {'40,000-49,999' : 45000, '50,000-59,999': 55000, '60,000-69,999': 65000, \n              '30,000-39,999': 35000, '80,000-89,999': 85000, '70,000-79,999': 75000, \n              '100,000-124,999': 112500, '$0-999': 500, '90,000-99,999': 95000, '125,000-149,999': 137500, \n              '25,000-29,999': 27500, '20,000-24,999': 22500, '150,000-199,999': 175000, \n              '200,000-249,999': 225000, '15,000-19,999': 17500, '10,000-14,999': 12500, \n              '2,000-2,999': 2500, '300,000-499,999': 400000, '7,500-9,999': 8750, \n              '250,000-299,999': 275000, '$500,000-999,999': 750000, '1,000-1,999': 1500, \n              '4,000-4,999': 4500, '>$1,000,000': 1000000, '5,000-7,499': 6250, '3,000-3,999': 3500}\n              \ndf.replace({\"Salary\": int_salary}, inplace = True)","4231e724":"plt.figure(figsize=(20, 15))\nplt.title('Mean salary by Country')\ndf.groupby('Q3')['Salary'].mean().plot(kind = 'bar')\nplt.show()\n","8ba041b9":"order = ['I have never written code', '< 1 years', '1-3 years', '3-5 years', '5-10 years', '10-20 years', '20+ years']\n\nplt.figure(figsize=(20, 15))\nplt.title('Mean salary by Yeasrs of Experience')\ndf.groupby('Experience')['Salary'].mean().loc[order].plot(kind = 'bar', color = 'khaki')\nplt.show()","8db57f30":"df['Expected_Salary'] = df.groupby(['Gender', 'Q3', 'Experience'])['Salary'].transform('mean')\n\ndf['Salary_Difference'] = df['Expected_Salary'] - df['Salary']\n\ndf[['Gender', 'Q3', 'Experience', 'Salary', 'Expected_Salary', 'Salary_Difference']]","16bfd362":"plt.figure(figsize=(20, 15))\nplt.title('Heatmap showing new Columns')\n\nsns.heatmap(df.corr())\n\nplt.show()","071e092b":"columns = ['Python','R', 'SQL', 'C', 'C++', 'Java', 'Javascript', 'Julia', 'Swift', 'Bash', 'MATLAB',\n              'No_Languages', 'Other_Language','Vis_Matplotlib', 'Vis_Seaborn', 'Vis_Plotly', 'Vis_Altair', \n              'Vis_Bokeh', 'Vis_Geoplotlib', 'Vis_Folium','ML_SciKitLearn', 'ML_TensorFlow', 'ML_Keras', \n              'ML_Pytorch', 'ML_Fast.ai', 'ML_MXNet', 'ML_XGBoost', 'ML_LightGBM', 'ML_CatBoost', \n              'ML_Prophet', 'ML_H2O 3', 'ML_Jax', 'ML_PYLightning', 'ML_Huggingface','Salary']\n\nrf_df = df[columns].copy(deep=True).dropna()\n\ncolumns.pop(-1)\n\ny = rf_df['Salary'].values\nx = rf_df[columns].values\n\nforest = rf(max_features = 10, n_estimators = 500, random_state = 84)\nforest.fit(x,y)\n\nforest.score(x,y)\n","a67a9d90":"# Overall Conclusions\n\nThis show us that no matter the level of experience the trends are similar. With greater experience other languages are used to a greater extent but are still ranked in the same order, the visualisation is remarkable similar and the machine learning packages are used more with experience but with similar rankings.\n\nThis therefore leads to the conlusion that for someone like myself who is starting out in the field it is important to learn how to do the simple things well as these will be your main tools throughout your career.","71649dde":"## NB\/\n\nThis is the point where I would normally stop. The dataset is too small to segment for providing extra insight into UK salaries and conducting feature engineering to overcome all of these noise factors would introduce a lot of error into the dataset. This is unavoidable as combining approximations (and the error they contain) means that the error is multiplied.\n\nHowever, I have already conducted the research I wanted, I have some time left before it is due and I need the practice. I do not expect anything beyond this point to work but I feel it could be interesting.","fceb855f":"# Visualisation Packages Used in Python by New Entrants\n\nGiven the disparaty in language usage it is not suitable to compare total usage across languages","1e1a7796":"Putting it through a random forest and testing it on the data it has already seen (without any test-train split) only gives a score of 0.63. This shows that there is no further information to be seen in this direction","ff2d085c":"## Data Importing and cleaning","f9bb3dbc":"Due to the lack of data for the UK, futher analysis of salary is hampered by other factors such as age, gender, country and years of experience.","c91e1707":"# Aims\n\nMy analysis of this dataset is personal as I wish to learn more about and eventually break into the field. Therefore I am looking at people with 3 or less years of experience to see what skills they have obtained and what platforms they are using.","7ccaeaa4":"# Comparison of Data Scientist with less than 4 years of experience to those with more","d3703b4d":"# Machine Libraries used in Python by New Entrants","1483ba1f":"# Imported Libraries and Datasets","a12c19c5":"This shows that python is by far the most used and recommended language by recent data scientists. SQL and R are also both very well represented. The surprise here is the strong showing for C and C++. The reasons for this would need to be understood but a speculation would be that these are felt to be languages that are closer to machine code and it maybe that these are seen as better ways to understand programming","e46301aa":"This information surprised me. Python, SQL and R seem obvious but I would have expected C++ and C to be very far down this list. Lets compare this to the recommended first Language.\n\nPlease Note - Python Removed from chart as this had 11,206 entries against 743 for the next highest (SQL)","0c1f0132":"# Languages used and recommended by New Entrants","a51698ff":"Our new column doesn't show any correlation but for fun lets try putting it through a random forest","8c6b953d":"This clearly shows that the total number of packages or languages known has no significant relation to Salary. \n\nInstead maybe there is a difference based upon the packages known.","6577d09f":"# Conclusions for New Entrants\n\nThese charts have shown us that the vast majority of new entrants to the field (those with less than 4 years of experience) use python as their main language and recommend that others learn it first as well.\n\nWithin Python, the main packages used for visualisation are Matplotlib and Seaborn and the main machine learning package is SciKitLearn.\n\nThese are all standard packages and are widely recommended in articles and videos as good places to start the data science journey (along with numpy and pandas). Therefore the next question is are these packages used because they are best for beginners or are they used because they are the best for industry?\n\nTo answer this we will compare the usage rates of new entrants with those who have been in the industry for longer. If the packages are the best overall, we would expect similar rates (null hypothesis), if other packages are better for more difficult problems you would expect usage rates to increase with experience (alternative hypothesis).","183ec588":"# Extended Analysis\n\nHaving achieved my original aims, I wondered if might be possible to look for connections to salary. There are many places to look for these connections but we will begin with the packages known.","6fd01b2b":"There is a slight indication here that learning packages known to fewer people provides a better average salary but this could be down to the smaller sample size for these. Further data would be needed to say this for sure (for instance by looking at job listings which is beyond the scope of this notebook)."}}