{"cell_type":{"269df6f4":"code","2baef2ff":"code","19bcc0cb":"code","3c066eb7":"code","9003ae5f":"code","c1d8621d":"code","f88f7810":"code","a8839214":"code","143a6497":"code","f8125397":"code","a311db00":"code","e9586fd0":"code","dc0d2ff2":"code","77eddc0f":"code","d32a0670":"code","35cd19b0":"code","ea9b54f9":"code","dbd36aab":"code","86f9d6ea":"code","bfcb6764":"code","bd80a47a":"code","6c8c5362":"code","363ef2e1":"code","53f6cb14":"code","5dd12619":"code","ad92bde0":"code","2a0d1a34":"code","06e26cc6":"code","c4b1bc4f":"code","846ddbc1":"code","440fd5aa":"code","f1a55735":"code","6c452155":"code","8b1fe530":"code","27612854":"code","11ebef82":"code","5f6dcca7":"code","fa2d0a28":"code","cd3e2150":"code","c2420be3":"code","804e8430":"code","29aeeddb":"code","a21e6b43":"code","a9aca5c2":"code","bb5a25f9":"code","075730c2":"code","3ca188f5":"code","9ad7dea5":"code","d88255da":"code","909957f6":"code","5da005fe":"code","cf141865":"code","5ad4b18e":"code","bb605ca4":"code","8fab5e7f":"code","06a6bfe6":"code","5ef3fd02":"code","390e4efb":"code","36c02b65":"code","78c25166":"code","5eab36a5":"code","5aa0876f":"code","0026823e":"code","7820067a":"code","ecd8e45d":"code","8494282c":"markdown","e637df99":"markdown","1cd213bb":"markdown","da6894a8":"markdown","51417aaa":"markdown","acfea39f":"markdown","79fda5b1":"markdown","707ed355":"markdown","1a9d0116":"markdown","53f2d816":"markdown","6e727d51":"markdown","e7385cc4":"markdown","24043a00":"markdown","5374c76d":"markdown","62a69c44":"markdown","11f13696":"markdown","605a7d6c":"markdown","98817405":"markdown","3d19c873":"markdown","a65e2f08":"markdown","fe8a3055":"markdown","66ee0a72":"markdown","332eb182":"markdown","70bbb95b":"markdown"},"source":{"269df6f4":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport math\nfrom random import seed\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\nfrom sklearn.ensemble import RandomForestRegressor, BaggingClassifier\nfrom sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\nimport warnings\nimport graphviz\nimport shap\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\")","2baef2ff":"seed(2021)\ndata = pd.read_csv('\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')","19bcc0cb":"data.shape","3c066eb7":"data.columns","9003ae5f":"data.info()","c1d8621d":"data.isnull().sum()","f88f7810":"data.describe()","a8839214":"data.head()","143a6497":"independent_variables = [var for var in data.columns if var not in ['quality']]\npd.plotting.scatter_matrix(data[independent_variables[0:5]], figsize = (20, 10),  marker = 'D');","f8125397":"pd.plotting.scatter_matrix(data[independent_variables[6:11]], figsize = (20, 10),  marker = 'D');","a311db00":"data['quality'].value_counts(normalize = True).reset_index().rename(columns = {'index': 'y_variable', 'quality': 'percentage_count'}).sort_values(by = 'y_variable')","e9586fd0":"fig = px.parallel_coordinates(data, color = 'quality',\n                              dimensions = independent_variables,\n                              color_continuous_midpoint=5)\nfig.show()","dc0d2ff2":"data.groupby('quality').agg(['mean', 'median', 'std'])","77eddc0f":"data['target'] = np.where(data['quality'] >= 7, 'good', 'not good')\ndata['y'] = np.where(data['target'] == 'not good', 0 ,1)\nindependent_variables = [var for var in data.columns if var not in ['quality', 'y', 'target']]\ndata['target'].value_counts(normalize = True)","d32a0670":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.boxplot(x = data['target'], y = data['fixed acidity'], width = 0.5, ax= axes[0]).set_title('Boxplot of fixed acidity')\naxes[0].yaxis.tick_left()\n\nsns.stripplot(x = data['quality'], y = data['fixed acidity'], dodge=True, ax= axes[1]).set_title('Stripplot of fixed acidity depend on quality')\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\nplt.show()","35cd19b0":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.boxplot(x = data['target'], y = data['volatile acidity'], width = 0.5, ax= axes[0]).set_title('Boxplot of volatile acidity')\naxes[0].yaxis.tick_left()\n\nsns.stripplot(x = data['quality'], y = data['volatile acidity'], dodge=True, ax= axes[1]).set_title('Stripplot of volatile acidity depend on quality')\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\nplt.show()","ea9b54f9":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.boxplot(x = data['target'], y = data['citric acid'], width = 0.5, ax= axes[0]).set_title('Boxplot of citric acid')\naxes[0].yaxis.tick_left()\n\nsns.stripplot(x = data['quality'], y = data['citric acid'], dodge=True, ax= axes[1]).set_title('Stripplot of citric acid depend on quality')\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\nplt.show()","dbd36aab":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.boxplot(x = data['target'], y = data['residual sugar'], width = 0.5, ax= axes[0]).set_title('Boxplot of residual sugar')\naxes[0].yaxis.tick_left()\n\nsns.stripplot(x = data['quality'], y = data['residual sugar'], dodge=True, ax= axes[1]).set_title('Stripplot of residual sugar depend on quality')\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\nplt.show()","86f9d6ea":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.boxplot(x = data['target'], y = data['chlorides'], width = 0.5, ax= axes[0]).set_title('Boxplot of chlorides')\naxes[0].yaxis.tick_left()\n\nsns.stripplot(x = data['quality'], y = data['chlorides'], dodge=True, ax= axes[1]).set_title('Stripplot of chlorides depend on quality')\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\nplt.show()","bfcb6764":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.boxplot(x = data['target'], y = data['free sulfur dioxide'], width = 0.5, ax= axes[0]).set_title('Boxplot of free sulfur dioxide')\naxes[0].yaxis.tick_left()\n\nsns.stripplot(x = data['quality'], y = data['free sulfur dioxide'], dodge=True, ax= axes[1]).set_title('Stripplot of free sulfur dioxide depend on quality')\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\nplt.show()","bd80a47a":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.boxplot(x = data['target'], y = data['total sulfur dioxide'], width = 0.5, ax= axes[0]).set_title('Boxplot of total sulfur dioxide')\naxes[0].yaxis.tick_left()\n\nsns.stripplot(x = data['quality'], y = data['total sulfur dioxide'], dodge=True, ax= axes[1]).set_title('Stripplot of total sulfur dioxide depend on quality')\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\nplt.show()","6c8c5362":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.boxplot(x = data['target'], y = data['density'], width = 0.5, ax= axes[0]).set_title('Boxplot of density')\naxes[0].yaxis.tick_left()\n\nsns.stripplot(x = data['quality'], y = data['density'], dodge=True, ax= axes[1]).set_title('Stripplot of density depend on quality')\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\nplt.show()","363ef2e1":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.boxplot(x = data['target'], y = data['pH'], width = 0.5, ax= axes[0]).set_title('Boxplot of pH')\naxes[0].yaxis.tick_left()\n\nsns.stripplot(x = data['quality'], y = data['pH'], dodge=True, ax= axes[1]).set_title('Stripplot of pH depend on quality')\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\nplt.show()","53f6cb14":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.boxplot(x = data['target'], y = data['sulphates'], width = 0.5, ax= axes[0]).set_title('Boxplot of sulphates')\naxes[0].yaxis.tick_left()\n\nsns.stripplot(x = data['quality'], y = data['sulphates'], dodge=True, ax= axes[1]).set_title('Stripplot of sulphates depend on quality')\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\nplt.show()","5dd12619":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.boxplot(x = data['target'], y = data['alcohol'], width = 0.5, ax= axes[0]).set_title('Boxplot of alcohol')\naxes[0].yaxis.tick_left()\n\nsns.stripplot(x = data['quality'], y = data['alcohol'], dodge=True, ax= axes[1]).set_title('Stripplot of alcohol depend on quality')\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\nplt.show()","ad92bde0":"correlation_mat = data[independent_variables].corr()\nfig, ax = plt.subplots(figsize=(15, 8))\nsns.heatmap(correlation_mat, cmap='coolwarm', annot=True, fmt=\".2f\").set_title('Pearson correlation between independent variables')\nplt.show()","2a0d1a34":"corr_pairs = correlation_mat.unstack()\ncorr_pairs.sort_values(kind=\"quicksort\", inplace = True)\ncorr_pairs","06e26cc6":"corr_pairs[(abs(corr_pairs) > 0.6) & (corr_pairs !=1)]","c4b1bc4f":"spearman_correelation = data.corr(method='spearman')['quality'].reset_index().rename(columns = {'index': 'independent variables', 'quality': 'spearman correlation with quality'})\nspearman_correelation.drop([11], inplace = True)\nspearman_correelation.sort_values(by = 'spearman correlation with quality', key = abs, ascending = False)","846ddbc1":"X = data[independent_variables]\ntarget = data['target']\ny = data['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=21)","440fd5aa":"print('Share of good wines in train sample: '+ str(round((y_train.sum()\/y_train.shape[0]),3)*100 )+'%')\nprint('Share of good wines in test sample: '+ str(round((y_test.sum()\/y_test.shape[0]),2)*100 )+'%')","f1a55735":"tree_example = DecisionTreeClassifier(max_depth = 3)\ntree_example.fit(X_train, y_train)","6c452155":"print('Acuraccy on train sample for simple decision tree is: {}'.format(tree_example.score(X_train, y_train)))","8b1fe530":"tree_exp_predictions = tree_example.predict_proba(X_test)[:,1]\nprint('Acuraccy on test sample for simple decision tree is: {}'.format(roc_auc_score(y_test, tree_exp_predictions)))","27612854":"dot_data = export_graphviz(tree_example, out_file=None,\n                           feature_names=independent_variables,\n                           class_names= np.array(['good','not good']),\n                           filled=True)\n\ngraph = graphviz.Source(dot_data, format=\"png\") \ngraph","11ebef82":"param_dict = {\n    \"criterion\": ['gini', 'entropy'],\n    \"max_depth\": range(1,8),\n    \"min_samples_split\": range(5,8),\n    \"min_samples_leaf\": range(1,5)\n}","5f6dcca7":"grid = GridSearchCV(tree_example,\n                    param_grid = param_dict,\n                    cv = 5\n                   )\ngrid.fit(X_train, y_train)","fa2d0a28":"print('Best parameters from GridSearchCV: {}'.format(grid.best_params_))","cd3e2150":"print('Acuraccy in train sample: {}'.format(grid.best_score_))","c2420be3":"tree_predictions = grid.best_estimator_.predict_proba(X_test)[:,1]","804e8430":"auc = roc_auc_score(y_test, tree_predictions)\nprint('AUC on test sample: %.2f' % auc)","29aeeddb":"fpr, tpr, thresholds = roc_curve(y_test, tree_predictions)","a21e6b43":"def plot_roc_curve(fpr, tpr, kind_of_sample = 'test'):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve'+ ', sample: '+ kind_of_sample)\n    plt.legend()\n    plt.show()","a9aca5c2":"plot_roc_curve(fpr, tpr)","bb5a25f9":"means_score = grid.cv_results_['mean_test_score']\nstds_score = grid.cv_results_['std_test_score']\nparams = grid.cv_results_['params']\n\nfor mean, stdev, param in zip(means_score, stds_score, params):\n    print(\"score: %f std: (%f) with: %r\" % (mean, stdev, param))","075730c2":"rf_model = RandomForestRegressor(random_state = 2021, min_samples_leaf = 5, oob_score = True)","3ca188f5":"number_of_trees = [int(x) for x in np.linspace(100,1000,6)]\nnumber_of_levels_tree = [int(x) for x in np.linspace(5,15,8)]\nmax_features = ['sqrt', 'log2']\nmin_samples_split = [10, 15]","9ad7dea5":"random_grid = {'n_estimators': number_of_trees,\n               'max_depth': number_of_levels_tree,\n               'max_features': max_features,\n               'min_samples_split': min_samples_split\n              }","d88255da":"rf_randomsCV = RandomizedSearchCV(estimator=rf_model, param_distributions=random_grid,\n                              cv = 5, verbose=2, random_state=42, n_jobs=-1,\n                              return_train_score=True)\nrf_randomsCV.fit(X_train, y_train);","909957f6":"print('Best parameters from RandomizedSearchC: {}'.format(rf_randomsCV.best_params_))","5da005fe":"forest_importances = pd.Series(rf_randomsCV.best_estimator_.feature_importances_, index=independent_variables)\nfig, ax = plt.subplots()\nforest_importances.plot.bar(ax = ax)\nplt.title('Features importance')\nfig.tight_layout()\nplt.show()","cf141865":"rf_predictions = rf_randomsCV.best_estimator_.predict(X_test)\nauc = roc_auc_score(y_test, rf_predictions)\nprint('AUC on test sample: %.2f' % auc)","5ad4b18e":"fpr, tpr, thresholds = roc_curve(y_test, rf_predictions)\nplot_roc_curve(fpr, tpr)","bb605ca4":"dt_model = grid.best_estimator_","8fab5e7f":"bag_model = BaggingClassifier(base_estimator= dt_model,random_state = 2021, oob_score = True, max_features = 1.0)\n\nrandom_grid_bag = {'n_estimators': number_of_trees}\n\nbag_randomsCV = GridSearchCV(estimator=bag_model, param_grid=random_grid_bag,\n                              cv = 5, verbose=2, n_jobs=-1,\n                              return_train_score=True)\nbag_randomsCV.fit(X_train, y_train);","06a6bfe6":"print('Best parameters from GridSearchCV: {}'.format(bag_randomsCV.best_params_))","5ef3fd02":"bag_randomsCV.best_score_","390e4efb":"bag_predictions = bag_randomsCV.best_estimator_.predict_proba(X_test)[:,1]\nauc = roc_auc_score(y_test, bag_predictions)\nprint('AUC on test sample: %.2f' % auc)","36c02b65":"fpr, tpr, thresholds = roc_curve(y_test, bag_predictions)\nplot_roc_curve(fpr, tpr)","78c25166":"bag_means_score = bag_randomsCV.cv_results_['mean_test_score']\nbag_stds_score = bag_randomsCV.cv_results_['std_test_score']\nbag_params = bag_randomsCV.cv_results_['params']\n\nfor mean, stdev, param in zip(bag_means_score, bag_stds_score, bag_params):\n    print(\"score: %f std: (%f) with: %r\" % (mean, stdev, param))\n","5eab36a5":"shap_values = shap.TreeExplainer(rf_randomsCV.best_estimator_).shap_values(X_train)\nshap.summary_plot(shap_values, X_train, plot_type=\"bar\")","5aa0876f":"shap.summary_plot(shap_values, X_train,title='Random Forest Model')","0026823e":"shap.dependence_plot('alcohol', shap_values, X_train)","7820067a":"shap.dependence_plot('sulphates', shap_values, X_train)","ecd8e45d":"shap.dependence_plot('pH', shap_values, X_train)","8494282c":"#### Explaining Model Predictions - Random Forest Model","e637df99":"### Rank correlation (Spearman)","1cd213bb":"Here we see, that the mean accuracy on the training sample is lower than the mean accuracy of the testing sample.   That's can be overfitting. We have to remember that the main limitation in the bagging algorithm is using the entire feature space when creating splits in each tree. It is possible, especially when some main feature is indicating certain predictions. There is a risk of having a forest of correlated trees.","da6894a8":"#### Which of the variables show the most relationship with the target variable ?","51417aaa":"### Getting balanced data -  attempts of some improvements","acfea39f":"Here are configurations in GridSearchCV evaluated using 5-fold cross validation:","79fda5b1":"### ExtraTrees","707ed355":"### Correlations between independent variables","1a9d0116":"The columns are:","53f2d816":"### Decision Tree with the best combination of the parameter using grid search method","6e727d51":"Fiew first rows of dataset:","e7385cc4":"### How the GridSearchCV works? ","24043a00":"### Decision Trees","5374c76d":"#### Tips from [here!](<https:\/\/www.kaggle.com\/uciml\/red-wine-quality-cortez-et-al-2009>)\n<em>\"What might be an interesting thing to do, is aside from using regression modelling, is to set an arbitrary cutoff for your dependent variable (wine quality) at e.g. 7 or higher getting classified as 'good\/1' and the remainder as 'not good\/0'.\"<\/em>","62a69c44":"The second thought is why the best parameter: n_estimators is so low.","11f13696":"Its a DataFrame object with 1599 rows and 12 columns.","605a7d6c":"I am using the best parameters from the decision tree from a previous model (using GridSearchCV):   \nBest parameters from GridSearchCV: {'criterion': 'gini', 'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 5}","98817405":"### Explaining Model Predictions","3d19c873":"More informations about types of columns:","a65e2f08":"## EDA with Wines dataset ","fe8a3055":"### Random Forest and RandomizedSearchCV method","66ee0a72":"### Bagging","332eb182":"### The strong correlations (independent variables)","70bbb95b":"### Target as a dependent variable"}}