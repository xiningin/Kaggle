{"cell_type":{"3ee3654e":"code","8c0657d4":"code","6a48c302":"code","c542c5d3":"code","1ed6f4d2":"code","2917d4f6":"code","02fcda8e":"code","192df559":"code","1977c3fd":"code","a79f26d8":"code","d160b814":"code","f810c7e0":"code","63457a2d":"code","2ab480b9":"code","e3cc266e":"code","223fea10":"code","5abbce06":"code","05a1aaf5":"code","228e5546":"code","024b3967":"code","1d672c11":"code","5d9a2dd2":"code","abbb987a":"code","7049c4d8":"code","ed43c49a":"markdown","3d7b7443":"markdown","87179bb7":"markdown","9c43b323":"markdown","146ffb1c":"markdown","28b815ae":"markdown","08843891":"markdown","4e77604c":"markdown","9ae5532d":"markdown","95bd291c":"markdown","01a19415":"markdown","25158d66":"markdown","43233880":"markdown","b6390c40":"markdown","009f5440":"markdown","3f35c167":"markdown","6451ec18":"markdown","f810b260":"markdown","53f795ac":"markdown","8130a0ea":"markdown","05d39d17":"markdown","325040e3":"markdown","c20f5e04":"markdown","ed976a81":"markdown"},"source":{"3ee3654e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nplt.rcParams['figure.figsize']=(12,5)\nimport warnings\nwarnings.filterwarnings(\"ignore\")","8c0657d4":"df_card = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")","6a48c302":"df_card.head(10)","c542c5d3":"print(df_card.shape)\nprint(df_card.size)","1ed6f4d2":"df_card.info()","2917d4f6":"df_card.drop(columns = ['Time'], inplace= True)","02fcda8e":"# Standardizing the amount column\nfrom sklearn import preprocessing\nscaler = preprocessing.StandardScaler()\n#standard scaling\ndf_card['Stand_Amount'] = scaler.fit_transform(df_card['Amount'].values.reshape (-1,1))\n\n#removing Amount\ndf = df_card.drop(\"Amount\", axis=1)","192df559":"sns.countplot(x=\"Class\", data=df_card)","1977c3fd":"import imblearn\nfrom imblearn.under_sampling import RandomUnderSampler \n\nundersample = RandomUnderSampler(sampling_strategy=0.5)","a79f26d8":"cols = df.columns.tolist()\ncols = [c for c in cols if c not in [\"Class\"]]\ntarget = \"Class\"","d160b814":"# Define X and Y\nX = df[cols]\nY = df[target]\n\n# Undersampling\nX_sample, Y_sample = undersample.fit_resample(X, Y)","f810c7e0":"test = pd.DataFrame(Y_sample, columns = ['Class'])","63457a2d":"#visualizing undersampling results\nfig, axs = plt.subplots(ncols=2, figsize=(13,4.5))\nsns.countplot(x=\"Class\", data=df, ax=axs[0])\nsns.countplot(x=\"Class\", data=test, ax=axs[1])\n\nfig.suptitle(\"Class repartition before and after undersampling\")\na1=fig.axes[0]\na1.set_title(\"Before\")\na2=fig.axes[1]\na2.set_title(\"After\")","2ab480b9":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_sample, Y_sample, test_size=0.3, random_state=1)","e3cc266e":"print(len(X_train))\nprint(len(y_train))\nprint(len(X_test))\nprint(len(y_test))","223fea10":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dropout\nfrom keras.layers import Dense\nfrom tensorflow.keras import layers\nfrom keras import regularizers\nfrom sklearn import metrics","5abbce06":"model = Sequential()\nmodel.add(Dense(32 , activation='relu', input_shape=(X_train.shape[-1],))) # Input Layer\nmodel.add(Dropout(0.5)) # Dropout Layer\nmodel.add(Dense(16 , activation='relu'))\nmodel.add(Dropout(0.5)) # Dropout Layer\nmodel.add(Dense(8 , activation='relu'))\nmodel.add(Dropout(0.5)) # Dropout Layer\nmodel.add(Dense(4 , activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))","05a1aaf5":"optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) #optimizer\n\nmodel.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy']) ","228e5546":"model.summary()","024b3967":"num_epochs = 6\nhistory = model.fit(X_train,y_train,epochs=num_epochs, batch_size=5, validation_split=0.2, verbose=0)\nhistory_dict = history.history","1d672c11":"loss_values = history_dict['loss']\nval_loss_values=history_dict['val_loss']\nplt.plot(loss_values,'b',label='training loss')\nplt.plot(val_loss_values,'r',label='val training loss')\nplt.legend()\nplt.xlabel(\"Epochs\")","5d9a2dd2":"accuracy_values = history_dict['accuracy']\nval_accuracy_values=history_dict['val_accuracy']\nplt.plot(val_accuracy_values,'-r',label='val_accuracy')\nplt.plot(accuracy_values,'-b',label='accuracy')\nplt.legend()\nplt.xlabel(\"Epochs\")","abbb987a":"y_pred = model.predict_classes(X_test)","7049c4d8":"#scores\nprint(\"Accuracy Neural Net:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision Neural Net:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall Neural Net:\",metrics.recall_score(y_test, y_pred))\nprint(\"F1 Score Neural Net:\",metrics.f1_score(y_test, y_pred))\n#print(metrics.classification_report(y_test, y_pred))","ed43c49a":"The dataset is highly imbalanced so we need to undersample data.","3d7b7443":"Firstly, we will import all the required libraries.","87179bb7":"##### Training Loss Vs Validation Loss","9c43b323":"#### Dropping Time Column","146ffb1c":"<a id=\"8\"><\/a> <br>\n## Training","28b815ae":"# Building a Multi-layer Neural Network","08843891":"As this is a binary classification problem we will use **sigmoid activation** in the last layer.","4e77604c":"# Compiling Model","9ae5532d":"## Score","95bd291c":"<a id=\"2\"><\/a> <br>\n# Cleaning the Data","01a19415":"<a id=\"11\"><\/a> <br>\n## Prediction","25158d66":"# Undersampling the Data","43233880":"##### Validation accuracy","b6390c40":"## ACCURACY = 92 %\nAccuracy can be improved by tuning hyperparmeters.","009f5440":"# Setting-up Envoirnment ","3f35c167":"### If this Kernel helped you in any way, some <span style=\"color:red\">UPVOTES !!!<\/span> would be very much appreciated.","6451ec18":"<a id=\"1\"><\/a> <br>\n## Loading Data","f810b260":"As this is a binary classification problem we will use **Binary Cross Entropy** for loss and **Accuracy** for metric.","53f795ac":"# Credit Card Fraud Detection Using Tensorflow\/Keras","8130a0ea":"#### Checking Shape and Size","05d39d17":"# Splitting the Data\nSplitting data into training and testing data.","325040e3":"#### Class column","c20f5e04":"#### Below are the steps which we will be basically following:\n1. Cleaning the Data\n2. Undersampling the Data\n3. Splitting the Data\n4. Building a Multilayer Neural Network with Keras\n5. Compiling\n6. Training\n7. Prediction \n8. Score","ed976a81":"There is no missing value."}}