{"cell_type":{"cdec42c2":"code","6967d0fa":"code","1e427a2d":"code","4e0ee6e3":"code","66562b88":"code","f434380e":"code","136e700d":"code","3e71e36d":"code","77881a26":"code","c29dc1b9":"code","9a0eaf5d":"code","7884f3ba":"code","00f44c5a":"code","ab4cc24c":"code","81a2f2d2":"code","4aa0fb8d":"code","0fdfcd90":"code","118e3bbb":"code","84203ee6":"code","7091f458":"code","15d4d3eb":"code","c4a33920":"code","4c1f71a5":"code","4d6bf017":"code","91c0762e":"code","253d1d5a":"code","98d8d12d":"code","99c97009":"code","637dceb2":"code","1927d63e":"code","c6754dec":"code","85d1e638":"code","80198353":"code","a05fcf8e":"code","55f4cdd3":"code","6e8fe143":"code","c68f83f7":"code","242fefb8":"code","9d63fe8f":"code","eb2ed371":"code","9642e9fc":"code","128cf5b3":"code","036b779b":"code","540979a7":"code","5c70c35a":"code","2c58c557":"code","4802e98c":"code","0b6a58fc":"code","f3dacea7":"markdown","dd57856e":"markdown","c22b58f6":"markdown","c340ab1b":"markdown","0fbf677c":"markdown","1ad80ed7":"markdown","6fcae704":"markdown","eb6d6e77":"markdown","021158d8":"markdown","8270a207":"markdown","0e485a3b":"markdown","d85634f2":"markdown","25e0256c":"markdown","b0835f06":"markdown","3040eda2":"markdown","e50ff985":"markdown"},"source":{"cdec42c2":"!pip install pyspark","6967d0fa":"from pyspark.ml import Pipeline\nfrom pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, MultilayerPerceptronClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler, IndexToString, OneHotEncoder\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\n\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1e427a2d":"spark = SparkSession.builder.getOrCreate()","4e0ee6e3":"training = spark.read.format(\"csv\").load(\"\/kaggle\/input\/it2034ch1502-car-acceptability-prediction\/train.csv\", header = \"True\", inferSchema = \"True\")\ntest = spark.read.format(\"csv\").load(\"\/kaggle\/input\/it2034ch1502-car-acceptability-prediction\/test.csv\", header = \"True\", inferSchema = \"True\")","66562b88":"training.show(3)\ntraining.groupby(\"acceptability\").count().show()\ntraining.printSchema()","f434380e":"# D\u1eef li\u1ec7u 1: Ph\u00e2n lo\u1ea1i 2 l\u1edbp \u0111\u1ed1i t\u01b0\u1ee3ng: 1. acceptable (acc, good, vgood), 2. unacceptable (unacc)","136e700d":"training1 = training.withColumn(\"acceptability\", when(training.acceptability == \"unacc\",training.acceptability).otherwise(\"acc\"))\ntraining1.groupby(\"acceptability\").count().show()","3e71e36d":"# D\u1eef li\u1ec7u 2: Ph\u00e2n lo\u1ea1i 3 l\u1edbp \u0111\u1ed1i t\u01b0\u1ee3ng: 1. acceptable (acc), 2. good, 3. very good (vgood)","77881a26":"training2 = training.filter(training.acceptability != \"unacc\")\ntraining2.groupby(\"acceptability\").count().show()","c29dc1b9":"labelIdx = StringIndexer(inputCol = \"acceptability\", outputCol = \"idxLabel\")","9a0eaf5d":"idxLabelTraining = labelIdx.fit(training).transform(training)\nidxLabelTraining.select(\"acceptability\", \"idxLabel\").distinct().show()","7884f3ba":"features = [\"buying_price\", \"maintenance_price\", \"number_of_doors\", \"carry_capacity\", \"trunk_size\", \"safety\"]\nidxFeatures = [\"idxBuyingPrice\", \"idxMaintenancePrice\", \"idxNumberOfDoors\", \"idxCarryCapacity\", \"idxTrunkSize\", \"idxSafety\"]\nfeatureIdx = StringIndexer(inputCols = features, outputCols = idxFeatures).setHandleInvalid(\"skip\")","00f44c5a":"featureIdx.fit(idxLabelTraining).transform(idxLabelTraining).select(idxFeatures).show(3)","ab4cc24c":"vectorAssembler = VectorAssembler(inputCols = idxFeatures, outputCol = \"featureVector\")","81a2f2d2":"idxPipeline = Pipeline(stages = [labelIdx, featureIdx, vectorAssembler])","4aa0fb8d":"idxPipeline.fit(training).transform(training).select(idxFeatures).show(3)\nidxPipeline.fit(training).transform(training).select(\"featureVector\", \"idxLabel\", \"acceptability\").show(3)","0fdfcd90":"oheFeatures = [\"oheBuyingPrice\", \"oheMaintenancePrice\", \"oheNumberOfDoors\", \"oheCarryCapacity\", \"oheTrunkSize\", \"oheSafety\"]\nfeatureOhe = OneHotEncoder(inputCols = idxFeatures, outputCols = oheFeatures)","118e3bbb":"oheVectorAssembler = VectorAssembler(inputCols = oheFeatures, outputCol = \"oheFeatureVector\")","84203ee6":"ohePipeline = Pipeline(stages = [labelIdx, featureIdx, featureOhe, oheVectorAssembler])","7091f458":"ohePipeline.fit(training).transform(training).select(oheFeatures).show(3)\nohePipeline.fit(training).transform(training).select(\"oheFeatureVector\", \"idxLabel\", \"acceptability\").show(3)","15d4d3eb":"trainingData, testData = training.randomSplit([0.80, 0.20])\ntrainingData.count(), testData.count()","c4a33920":"trainingData1, testData1 = training1.randomSplit([0.80, 0.20])\ntrainingData1.count(), testData1.count()","4c1f71a5":"trainingData2, testData2 = training2.randomSplit([0.80, 0.20])\ntrainingData2.count(), testData2.count()","4d6bf017":"def result(predictions):\n    AccuracyEval = MulticlassClassificationEvaluator(labelCol = \"idxLabel\", metricName=\"accuracy\")\n    PrecisionEval = MulticlassClassificationEvaluator(labelCol = \"idxLabel\", metricName=\"weightedPrecision\")\n    RecallEval = MulticlassClassificationEvaluator(labelCol = \"idxLabel\", metricName=\"weightedRecall\")\n    F1Eval = MulticlassClassificationEvaluator(labelCol = \"idxLabel\", metricName=\"f1\")\n \n    print(\"K\u1ebft qu\u1ea3 \u0111\u00e1nh gi\u00e1:\")\n    print(\"Accuracy = %g\" %(AccuracyEval.evaluate(predictions)))\n    print(\"Precision = %g\" %(PrecisionEval.evaluate(predictions)))\n    print(\"Recall = %g\" %(RecallEval.evaluate(predictions)))\n    print(\"F1 Score = %g\" %(F1Eval.evaluate(predictions)))","91c0762e":"dt = DecisionTreeClassifier(labelCol = \"idxLabel\", featuresCol = \"featureVector\")","253d1d5a":"dtParamGrid = (ParamGridBuilder()\n               .addGrid(dt.maxDepth, [10, 20])\n               .addGrid(dt.impurity, [\"entropy\", \"gini\"])\n               .build())","98d8d12d":"dtCrossVal = CrossValidator(estimator = dt,\n                            estimatorParamMaps = dtParamGrid,\n                            evaluator = MulticlassClassificationEvaluator(labelCol = \"idxLabel\"))","99c97009":"pipeline = Pipeline(stages = [idxPipeline, dtCrossVal])\nmodel = pipeline.fit(trainingData)","637dceb2":"predictions = model.transform(testData)\nresult(predictions)","1927d63e":"rf = RandomForestClassifier(labelCol = \"idxLabel\", featuresCol = \"featureVector\")","c6754dec":"rfParamGrid = (ParamGridBuilder()\n             .addGrid(rf.maxDepth, [10])\n             .addGrid(rf.numTrees, [500])\n             .addGrid(rf.impurity, [\"entropy\", \"gini\"])\n             .addGrid(rf.featureSubsetStrategy, [\"sqrt\"])\n             .addGrid(rf.subsamplingRate, [1.0])\n             .addGrid(rf.minInstancesPerNode, [1.0])\n             .build())","85d1e638":"rfCrossVal = CrossValidator(estimator = rf,\n                            estimatorParamMaps = rfParamGrid,\n                            evaluator = MulticlassClassificationEvaluator(labelCol = \"idxLabel\", metricName=\"accuracy\"))","80198353":"pipeline = Pipeline(stages = [idxPipeline, rfCrossVal])\nmodel = pipeline.fit(trainingData)","a05fcf8e":"predictions = model.transform(testData)\nresult(predictions)","55f4cdd3":"pipeline = Pipeline(stages = [idxPipeline, rfCrossVal])","6e8fe143":"model1 = pipeline.fit(trainingData1)\npredictions1 = model1.transform(testData1)\nresult(predictions1)","c68f83f7":"model2 = pipeline.fit(trainingData2)\npredictions2 = model2.transform(testData2)\nresult(predictions2)","242fefb8":"layers = [6, 12, 6, 4]","9d63fe8f":"mlpc = MultilayerPerceptronClassifier(labelCol='idxLabel', \n                                      featuresCol = \"featureVector\", \n                                      maxIter = 600, \n                                      layers = layers, \n                                      blockSize = 128, \n                                      seed = 1234)","eb2ed371":"pipeline = Pipeline(stages = [idxPipeline, mlpc])\nmodel = pipeline.fit(trainingData)","9642e9fc":"predictions = model.transform(testData)\nresult(predictions)","128cf5b3":"# C\u00e1c c\u1ea5u h\u00ecnh tham s\u1ed1 sau cho k\u1ebft qu\u1ea3 d\u1ef1 \u0111o\u00e1n t\u1ed1t nh\u1ea5t c\u00f3 th\u1ec3 t\u00ecm th\u1ea5y trong qu\u00e1 tr\u00ecnh th\u1ef1c nghi\u1ec7m.","036b779b":"layers1 = [16, 4, 4, 4]","540979a7":"mlpc1 = MultilayerPerceptronClassifier(labelCol='idxLabel', \n                                      featuresCol = \"oheFeatureVector\", \n                                      maxIter = 1000, \n                                      layers = layers1, \n                                      blockSize = 128, \n                                      seed = 1234)","5c70c35a":"pipeline = Pipeline(stages = [ohePipeline, mlpc1])\nmodel = pipeline.fit(training)","2c58c557":"predictions = model.transform(test)","4802e98c":"labelsArray = [\"unacc\", \"acc\", \"good\", \"vgood\"]\nsolutions = IndexToString(inputCol = \"prediction\", outputCol = \"acceptability\", labels = labelsArray).transform(predictions).select(\"car_id\",\"acceptability\")\nsolutions.show(3)","0b6a58fc":"solutions.toPandas().to_csv(\"testSolutions.csv\", header = True, index = False)","f3dacea7":"#### 3.2. D\u00f9ng OneHotEncoder k\u1ebft h\u1ee3p v\u1edbi StringIndexer, VectorAssembler v\u00e0 Pipeline.","dd57856e":"# B\u00e0i t\u1eadp m\u00f4n h\u1ecdc: X\u1eed l\u00fd d\u1eef li\u1ec7u l\u1edbn\n\n**Gi\u1ea3ng vi\u00ean h\u01b0\u1edbng d\u1eabn:** TS. \u0110\u1ed7 Tr\u1ecdng H\u1ee3p\n\n**Nh\u00f3m:** Smiley Team\n\n**Th\u00e0nh vi\u00ean:**\n1. L\u00ea Anh Tu\u1ea5n - CH1902037\n2. Nguy\u1ec5n C\u00f4ng Danh - CH1902029\n3. V\u00f5 Ho\u00e0ng V\u0169 - CH1902039","c22b58f6":"### 5. D\u00f9ng c\u00e1c thu\u1eadt to\u00e1n kh\u00e1c nhau \u0111\u1ec3 \u0111\u00e1nh gi\u00e1 \u0111\u1ed9 ch\u00ednh x\u00e1c.","c340ab1b":"### 3. X\u1eed l\u00fd d\u1eef li\u1ec7u.","0fbf677c":"#### 5.4. Multilayer Perceptron Classifier (MLPC).","1ad80ed7":"#### 5.1. Decision Tree Classifier.","6fcae704":"### 1. C\u00e0i \u0111\u1eb7t PySpark v\u00e0 n\u1ea1p c\u00e1c th\u01b0 vi\u1ec7n.","eb6d6e77":"#### 3.3. Ph\u00e2n chia d\u1eef li\u1ec7u ban \u0111\u1ea7u th\u00e0nh t\u1eadp hu\u1ea5n luy\u1ec7n v\u00e0 ki\u1ec3m tra, d\u00f9ng \u0111\u1ec3 \u0111\u00e1nh gi\u00e1 c\u00e1c m\u00f4 h\u00ecnh.","021158d8":"#### 2.2. Ph\u00e2n nh\u00f3m c\u00e1c d\u1eef li\u1ec7u \u0111\u1ec3 th\u1ef1c nghi\u1ec7m, so s\u00e1nh k\u1ebft qu\u1ea3 v\u1edbi d\u1eef li\u1ec7u ban \u0111\u1ea7u.","8270a207":"#### 3.1. D\u00f9ng StringIndexer, VectorAssembler v\u00e0 Pipeline.","0e485a3b":"#### 2.1. Ki\u1ec3m tra d\u1eef li\u1ec7u.","d85634f2":"### 6. D\u00f9ng MLPC v\u1edbi OneHotEncoder \u0111\u1ec3 d\u1ef1 \u0111o\u00e1n d\u1eef li\u1ec7u ki\u1ec3m tra c\u1ee7a cu\u1ed9c thi.","25e0256c":"#### 5.2. Random Forest Classifier.","b0835f06":"### 2. Chu\u1ea9n b\u1ecb d\u1eef li\u1ec7u.","3040eda2":"#### 5.3. Random Forest Classifier v\u1edbi c\u00e1c d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c ph\u00e2n nh\u00f3m.","e50ff985":"### 4. H\u00e0m hi\u1ec3n th\u1ecb k\u1ebft qu\u1ea3."}}