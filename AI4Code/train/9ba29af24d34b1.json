{"cell_type":{"5db38dec":"code","91cf4372":"code","16cfdcb3":"code","d6a405bc":"code","2ad4ce2e":"code","d66d4925":"code","277a62e3":"code","a9f14bf7":"code","0ea98855":"code","8c2e4bee":"code","2cde6b25":"code","2a286089":"code","542d9e54":"code","2e810f3c":"code","f33d522a":"code","2c6b7e22":"code","da8cd32c":"code","60db660d":"code","53018114":"code","cf70d817":"code","d21f6fa1":"code","bf0ff6c7":"code","288408f0":"code","af1fe30c":"code","e011c840":"code","2560dc8d":"code","17e82888":"code","738b0674":"markdown","bc884ee9":"markdown","418342df":"markdown","b516a00a":"markdown","aa754304":"markdown","81b53701":"markdown","d2cfb8e6":"markdown"},"source":{"5db38dec":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","91cf4372":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\ntrain.head()\ntrain.shape","16cfdcb3":"X_data = pd.concat((train.drop(['Id','SalePrice'],axis =1),\n                      test.drop(['Id'],axis =1)))","d6a405bc":"missing = X_data.isnull().sum().sort_values(ascending=False)\nmissing = missing[missing > 0]\nmissing.plot.bar()\nmissing.head(6)","2ad4ce2e":"missing.head(6)","d66d4925":"corrmat = train[['PoolQC','MiscFeature','Alley','Fence','FireplaceQu','LotFrontage','SalePrice']].corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10})","277a62e3":"X_data = X_data.fillna(X_data.mean())\nX_data = X_data.fillna(\"None\")","a9f14bf7":"missing = X_data.isnull().sum().sort_values(ascending=False)\nmissing = missing[missing > 0]\nmissing.head()","0ea98855":"train2 = train.fillna(X_data.mean())\ntrain2 = train.fillna(\"None\")\ntrain2.shape","8c2e4bee":"#correlation matrix\ncorrmat = train2.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.75);","2cde6b25":"#correlation matrix\ncorrmat = train2.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.75,vmin =.5);","2a286089":"sns.distplot(train['SalePrice'],bins = 15);","542d9e54":"from scipy.stats import skew\ntest1 = skew(train['SalePrice'])\ntest1","2e810f3c":"sns.distplot(np.log1p(train['SalePrice']),bins = 15);\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\ntest2 = skew(train['SalePrice'])\ntest2","f33d522a":"numeric_feats = X_data.dtypes[X_data.dtypes != \"object\"].index\n\nskewed_feats = train[numeric_feats].apply(lambda x: skew(x)) #compute skewness\nskewed_feats = skewed_feats[skewed_feats > 0.75]\nskewed_feats = skewed_feats.index\n\nX_data[skewed_feats] = np.log1p(X_data[skewed_feats])","2c6b7e22":"# one hot encoding and test\/train split\nX_data = pd.get_dummies(X_data)\n\nX_train = X_data[:train.shape[0]]\nX_test = X_data[train.shape[0]:]\ny = train.SalePrice","da8cd32c":"from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\nfrom sklearn.model_selection import cross_val_score\n\ndef rmse_cv(model):\n    rmse= np.sqrt(-cross_val_score(model, X_train, y, scoring=\"neg_mean_squared_error\", cv = 5))\n    return(rmse)","60db660d":"model_ridge = Ridge()","53018114":"model_ridge = Ridge()\nalphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]\ncv_ridge = [rmse_cv(Ridge(alpha = alpha)).mean() \n            for alpha in alphas]","cf70d817":"cv_ridge = pd.Series(cv_ridge, index = alphas)\ncv_ridge.plot(title = \"Validation\")\nplt.xlabel(\"alpha\")\nplt.ylabel(\"rmse\")","d21f6fa1":"cv_ridge.min()","bf0ff6c7":"model_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005]).fit(X_train, y)","288408f0":"rmse_cv(model_lasso).mean()","af1fe30c":"coef = pd.Series(model_lasso.coef_, index = X_train.columns)\nprint(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")","e011c840":"imp_coef = pd.concat([coef.sort_values().head(10),\n                     coef.sort_values().tail(10)])\nplt.rcParams['figure.figsize'] = (8.0, 10.0)\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Coefficients in the Lasso Model\")","2560dc8d":"# residuals\nplt.rcParams['figure.figsize'] = (6.0, 6.0)\n\npreds = pd.DataFrame({\"preds\":model_lasso.predict(X_train), \"true\":y})\npreds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\npreds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")","17e82888":"lasso_preds = np.expm1(model_lasso.predict(X_test))\nsolution = pd.DataFrame({\"id\": test['Id'], \"SalePrice\": lasso_preds})\nsolution.to_csv(\"lasso_sol.csv\", index = False)","738b0674":"Wanted to try regularized linear models and this dataset seemed promising.\n\nSpecial thanks to: [Regularized Linear Models](https:\/\/www.kaggle.com\/apapiu\/regularized-linear-models)","bc884ee9":"looks like there are some highly correlated features, some notable features correlated with SalePrice are: OVerallQual, TotalBsmtSF\/1stFlrSF, GarageCars\/GarageArea, GrLivArea, FullBath.","418342df":"weak correlation but enough to keep it, the other variables are categorical where missing = 'None'. Do a quick and dirty fill","b516a00a":"Some data analysis to get a feel of the features and label:","aa754304":"The variables with high number of missing are: PooolQC, MiscFeature, Alley, Fence, and FireplaceQu","81b53701":"Slightly better than Ridge","d2cfb8e6":"now its time to transform the features too"}}