{"cell_type":{"4d55bc23":"code","37152c63":"code","fe95c1ae":"code","74b95ba0":"code","f4000505":"code","51d668aa":"code","79b2e7e7":"code","05562d8a":"code","dbecf168":"code","e1802ef2":"code","794a3c1d":"code","e485347c":"code","fce5b941":"code","a0ea573b":"code","b035bc6d":"code","8ff5fd59":"code","dcffe8f5":"code","753e4020":"code","9d5d3e22":"code","7bed776e":"code","8683c5fc":"code","2099487e":"code","e718a378":"code","28d368ce":"code","07cb49a0":"code","ea21d718":"code","dd5b0e17":"code","5dbbb8cc":"code","bfe934ef":"code","d150d228":"code","6eb5d4de":"markdown","583aee69":"markdown","10af0f14":"markdown","636c7cb3":"markdown","7af0170a":"markdown","3886f307":"markdown","0edaafad":"markdown","45c27967":"markdown","916b041f":"markdown","072422af":"markdown","85e86eae":"markdown","491d25a0":"markdown","a53970da":"markdown","60340280":"markdown","e7f03ca2":"markdown","91279ddb":"markdown","52bad130":"markdown","c6be118f":"markdown","69b02d29":"markdown","90e96fce":"markdown","64362c43":"markdown","1d964066":"markdown"},"source":{"4d55bc23":"import pandas as pd\nimport numpy as np\nimport time\n\nimport warnings\nwarnings.filterwarnings('ignore')","37152c63":"# Load a month of data so we can see what kind of information we're working with\ndf = pd.read_csv('..\/input\/2019-airline-delays-and-cancellations\/raw_data\/ONTIME_REPORTING_01.csv')\ndf.shape","fe95c1ae":"df.head()","74b95ba0":"# Check memory usage of this file\ndf.memory_usage().sum()\n# These files are LARGE, and this is only one month. \n# Part of our cleaning process will be to store our data in a more memory efficient manner.","f4000505":"# What types of data do we have? We can get a feel of what we may be able to reduce to a smaller integer\ndf.dtypes","51d668aa":"# Descriptive stats for our data\ndf.describe()","79b2e7e7":"# Check our missing data\ndf.isna().sum()","05562d8a":"# Information on passenger activity for airports and airlines\npassengers = pd.read_csv('..\/input\/2019-airline-delays-and-cancellations\/raw_data\/T3_AIR_CARRIER_SUMMARY_AIRPORT_ACTIVITY_2019.csv')\npassengers","dbecf168":"# Manufacture year and passenger capacity for aircraft by unique aircraft tail number\naircraft = pd.read_csv(\"..\/input\/2019-airline-delays-and-cancellations\/raw_data\/B43_AIRCRAFT_INVENTORY.csv\",encoding='latin1')\naircraft.drop_duplicates(subset='TAIL_NUM', inplace=True)\naircraft","e1802ef2":"# coordinates of airports\ncoords = pd.read_csv('..\/input\/2019-airline-delays-and-cancellations\/raw_data\/AIRPORT_COORDINATES.csv')\ncoords.drop_duplicates(subset='ORIGIN_AIRPORT_ID', inplace=True)\ncoords","794a3c1d":"# proper names of carriers for better EDA usage\nnames = pd.read_csv(\"..\/input\/2019-airline-delays-and-cancellations\/raw_data\/CARRIER_DECODE.csv\")\nnames.drop_duplicates(inplace=True)\nnames.drop_duplicates(subset=['OP_UNIQUE_CARRIER'], inplace=True)\nnames","e485347c":"# Employee statistics for carriers\nemployees = pd.read_csv('..\/input\/2019-airline-delays-and-cancellations\/raw_data\/P10_EMPLOYEES.csv')\nemployees = employees[['OP_UNIQUE_CARRIER', 'PASS_GEN_SVC_ADMIN', 'PASSENGER_HANDLING']]\nemployees = employees.groupby('OP_UNIQUE_CARRIER').sum().reset_index()\nemployees","fce5b941":"# Weather report for top 90% of airport cities, in 2019\nweather_report = pd.read_csv('..\/input\/2019-airline-delays-and-cancellations\/raw_data\/airport_weather_2019.csv')\nweather_report","a0ea573b":"# Our list of cities and airports including the airport display name so that we can connect with our main df\ncities = pd.read_csv('..\/input\/2019-airline-delays-and-cancellations\/raw_data\/airports_list.csv')\ncities","b035bc6d":"# Connect our weather report with the city names\nweather_merge = pd.merge(cities, weather_report, how='left', on='NAME')\nweather_merge","8ff5fd59":"# Get just the important metrics from the weather report (date, precipitation, snow, temp, wind)\nweather = weather_merge[['DATE', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'AWND', 'ORIGIN_AIRPORT_ID']]","dcffe8f5":"# Drop any rows where no weather was recorded\nweather.drop(weather.loc[weather['ORIGIN_AIRPORT_ID'].isna()].index, axis=0, inplace=True)","753e4020":"# Look for null values in temperature\nweather.loc[weather['TMAX'].isna()]","9d5d3e22":"# Impute mean in nan rows for temp and wind\nweather['TMAX'].fillna(round(weather.groupby('ORIGIN_AIRPORT_ID')['TMAX'].transform('mean'), 1), inplace=True)\nweather['AWND'].fillna(round(weather.groupby('ORIGIN_AIRPORT_ID')['AWND'].transform('mean'), 1), inplace=True)\nweather.fillna(0, inplace=True)","7bed776e":"# Check no NaN remain\nweather.isna().sum()","8683c5fc":"# Cast data types to datetime so we can get the month and day of month to match up with main df\nweather['DATE'] = pd.to_datetime(weather['DATE'])\nweather['MONTH'] = pd.DatetimeIndex(weather['DATE']).month\nweather['DAY_OF_MONTH'] = pd.DatetimeIndex(weather['DATE']).day\nweather","2099487e":"def month_cleanup(monthly_data, aircraft, coords, names, weather, passengers, employees):\n    \n    '''Function which performs features engineering, data merges and cleanup using one month of On-Time data \n    from Bureau of Transportation Services\n    Parameters:\n    monthly_data: month of on-time data as downloaded from BTS\n    aircraft: Aircraft inventory data from BTS\n    coords: Airport coordinates data from BTS\n    names: Carrier names based on carrier code from BTS\n    weather: Daily weather reported at airports from National Center for Environmental Information\n    passengers: Yearly passenger information for carriers and airports from BTS\n    employees: Employee statistics for carriers from BTS\n    \n    returns: cleaned month of On-Time reporting\n    '''\n    \n    # start the timer so we can track how long the cleaning function takes\n    start = time.time()\n    \n    # CLEANING\n    # drop rows with no departure time, tail number, or were cancelled\n    print(\"Dropping NaNs from Dep Time, Tail Num. Dropping Cancellations.\")\n    monthly_data.drop(monthly_data.loc[monthly_data['DEP_TIME'].isna()].index, axis=0, inplace=True)\n    monthly_data.drop(monthly_data.loc[monthly_data['TAIL_NUM'].isna()].index, axis=0, inplace=True)\n    monthly_data.drop(monthly_data.loc[monthly_data['CANCELLED']==1].index, axis=0, inplace=True)\n \n    # FEATURE ENGINEERING - SEGMENT NUMBER\n    # List flight segment number for daily flight segments by tracking tail number\n    print(\"Adding Flight Number Sequence - SEGMENT_NUMBER\")\n    monthly_data[\"SEGMENT_NUMBER\"] = monthly_data.groupby([\"TAIL_NUM\", 'DAY_OF_MONTH'])[\"DEP_TIME\"].rank(\"dense\", ascending=True)\n    \n    # FEATURE ENGINEERING - CONCURRENT FLIGHTS\n    # Listing the number of concurrent flights at the airport in the time block \n    print(\"Adding Concurrent Flights - CONCURRENT_FLIGHTS\")\n    monthly_data['CONCURRENT_FLIGHTS'] = monthly_data.groupby(['ORIGIN_AIRPORT_ID','DAY_OF_MONTH', 'DEP_TIME_BLK'])['OP_UNIQUE_CARRIER'].transform(\"count\")\n \n    # MERGING to get NUMBER_OF_SEATS\n    print(\"Applying seat counts to flights - NUMBER_OF_SEATS\")   \n    # Merge aircraft info with main frame on tail number - get NUMBER_OF_SEATS \n    monthly_data = pd.merge(monthly_data, aircraft, how=\"left\", on='TAIL_NUM')\n    # Fill missing aircraft info with means\n    monthly_data['NUMBER_OF_SEATS'].fillna((monthly_data['NUMBER_OF_SEATS'].mean()), inplace=True)\n    # simplify data type of number of seats to reduce memory usage\n    monthly_data['NUMBER_OF_SEATS'] = monthly_data['NUMBER_OF_SEATS'].astype('int16')\n\n    # MERGING\n    # Merge to get proper carrier name\n    print(\"Applying Carrier Names - CARRIER_NAME\")  \n    monthly_data = pd.merge(monthly_data, names, how='left', on=['OP_UNIQUE_CARRIER'])\n    \n    # FEATURE ENGINEERING - AIRPORT_FLIGHTS_MONTH, AIRLINE_FLIGHTS_MONTH, AIRLINE_AIRPORT_FLIGHTS_MONTH\n    # Add monthly flight statistics for carrier and airport\n    print(\"Adding flight statistics for carrier and airport - AIRPORT_FLIGHTS_MONTH, AIRLINE_FLIGHTS_MONTH, AIRLINE_AIRPORT_FLIGHTS_MONTH\")\n    monthly_data['AIRPORT_FLIGHTS_MONTH'] = monthly_data.groupby(['ORIGIN_AIRPORT_ID'])['ORIGIN_CITY_NAME'].transform('count')\n    monthly_data['AIRLINE_FLIGHTS_MONTH'] = monthly_data.groupby(['OP_UNIQUE_CARRIER'])['ORIGIN_CITY_NAME'].transform('count')\n    monthly_data['AIRLINE_AIRPORT_FLIGHTS_MONTH'] = monthly_data.groupby(['OP_UNIQUE_CARRIER', 'ORIGIN_AIRPORT_ID'])['ORIGIN_CITY_NAME'].transform('count')\n    \n    # FEATURE ENGINEERING - AVG_MONTHLY_PASS_AIRPORT, AVG_MONTHLY_PASS_AIRLINE\n    #Add monthly passenger statistics for carrier and airport\n    print(\"Adding passenger statistics for carrier and airport - AVG_MONTHLY_PASS_AIRPORT, AVG_MONTHLY_PASS_AIRLINE\")\n    monthly_airport_passengers = pd.DataFrame(passengers.groupby(['ORIGIN_AIRPORT_ID'])['REV_PAX_ENP_110'].sum())\n    monthly_data = pd.merge(monthly_data, monthly_airport_passengers, how='left', on=['ORIGIN_AIRPORT_ID'])\n    monthly_data['AVG_MONTHLY_PASS_AIRPORT'] = (monthly_data['REV_PAX_ENP_110']\/12).astype('int64')\n    monthly_airline_passengers = pd.DataFrame(passengers.groupby(['OP_UNIQUE_CARRIER'])['REV_PAX_ENP_110'].sum())\n    monthly_data = pd.merge(monthly_data, monthly_airline_passengers, how='left', on=['OP_UNIQUE_CARRIER'])\n    monthly_data['AVG_MONTHLY_PASS_AIRLINE'] = (monthly_data['REV_PAX_ENP_110_y']\/12).astype('int64')\n    \n    # MERGING\n    # Add employee stats then FEATURE ENGINEER FLT_ATTENDANTS_PER_PASS, GROUND_SERV_PER_PASS\n    print(\"Adding employee statistics for carrier - FLT_ATTENDANTS_PER_PASS, GROUND_SERV_PER_PASS\")\n    monthly_data = pd.merge(monthly_data, employees, how='left', on=['OP_UNIQUE_CARRIER'])\n    monthly_data['FLT_ATTENDANTS_PER_PASS'] = monthly_data['PASSENGER_HANDLING']\/monthly_data['REV_PAX_ENP_110_y']\n    monthly_data['GROUND_SERV_PER_PASS'] = monthly_data['PASS_GEN_SVC_ADMIN']\/monthly_data['REV_PAX_ENP_110_y']\n    \n    # FEATURE ENGINEERING - PLANE AGE\n    # Calculate age of plane\n    print(\"Calculate Fleet Age - PLANE_AGE\")\n    monthly_data['MANUFACTURE_YEAR'].fillna((monthly_data['MANUFACTURE_YEAR'].mean()), inplace=True)\n    monthly_data['PLANE_AGE'] = 2019 - monthly_data['MANUFACTURE_YEAR']\n\n    # MERGING\n    # Merge to get airport coordinates\n    print(\"Adding airport coordinates - LATITUDE, LONGITUDE, DEPARTING_AIRPORT\")\n    monthly_data = pd.merge(monthly_data, coords, how='left', on=['ORIGIN_AIRPORT_ID'])\n    monthly_data['LATITUDE'] = round(monthly_data['LATITUDE'], 3)\n    monthly_data['LONGITUDE'] = round(monthly_data['LONGITUDE'], 3)\n\n    # FEATURE ENGINEERING - PREVIOUS AIRPORT\n    # Get previous airport for tail number\n    print(\"Adding airports - PREVIOUS_AIRPORT\")\n    segment_temp = monthly_data[['DAY_OF_MONTH', 'TAIL_NUM', 'DISPLAY_AIRPORT_NAME', 'SEGMENT_NUMBER']]\n    monthly_data = pd.merge_asof(monthly_data.sort_values('SEGMENT_NUMBER'), segment_temp.sort_values('SEGMENT_NUMBER'), on='SEGMENT_NUMBER', by=['DAY_OF_MONTH', 'TAIL_NUM'], allow_exact_matches=False)\n    monthly_data['DISPLAY_AIRPORT_NAME_y'].fillna('NONE', inplace=True)\n    monthly_data.rename(columns={\"DISPLAY_AIRPORT_NAME_y\": \"PREVIOUS_AIRPORT\", \"DISPLAY_AIRPORT_NAME_x\": \"DEPARTING_AIRPORT\"}, inplace=True)  \n    \n    # CLEANING  \n    # Drop airports below the 10th percentile\n    print(\"Dropping bottom 10% of airports\")\n    monthly_data.drop(monthly_data.loc[monthly_data['AIRPORT_FLIGHTS_MONTH'] < 1100].index, axis=0, inplace=True)\n    \n    # MERGING\n    # Merge weather data\n    print(\"Adding daily weather data - PRCP, SNOW, SNWD, SMAX, TMIN, AWND\")\n    monthly_data = pd.merge(monthly_data, weather, how='inner', on=['ORIGIN_AIRPORT_ID', 'MONTH', 'DAY_OF_MONTH'])\n\n    \n    # CLEANING\n    # drop columns that we won't use\n    print(\"Clean up unneeded columns\")\n    monthly_data.drop(columns = ['ORIGIN',  'DEST',  \n                   'CRS_DEP_TIME', 'DEP_DELAY_NEW', 'CRS_ARR_TIME', 'ARR_TIME', \n                   'CANCELLED', 'CANCELLATION_CODE', 'CRS_ELAPSED_TIME', 'DISTANCE',\n                   'CARRIER_DELAY', 'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY',\n                  'ARR_DELAY_NEW', 'Unnamed: 32',  'ARR_TIME_BLK', 'ACTUAL_ELAPSED_TIME',\n                  'DEST_AIRPORT_ID', 'DEST_CITY_NAME',  'OP_CARRIER_FL_NUM',  'OP_UNIQUE_CARRIER',\n                       'AIRLINE_ID', 'DATE', 'DAY_OF_MONTH', 'TAIL_NUM','DEP_TIME',\n                    'ORIGIN_AIRPORT_ID', 'ORIGIN_CITY_NAME',  'PASSENGER_HANDLING', 'REV_PAX_ENP_110_x', 'REV_PAX_ENP_110_y', \n                                 'PASS_GEN_SVC_ADMIN', 'MANUFACTURE_YEAR',\n                                 ],\n                    axis=1, inplace=True)\n    \n    # CLEANING\n    # specify data types of various fields to reduce memory usage\n    print(\"Cleaning up data types\")\n    monthly_data['MONTH'] = monthly_data['MONTH'].astype('object')\n    monthly_data['DAY_OF_WEEK'] = monthly_data['DAY_OF_WEEK'].astype('object')\n    monthly_data['DEP_DEL15'] = monthly_data['DEP_DEL15'].astype('int8')\n    monthly_data['DISTANCE_GROUP'] = monthly_data['DISTANCE_GROUP'].astype('int8')\n    monthly_data['SEGMENT_NUMBER'] = monthly_data['SEGMENT_NUMBER'].astype('int8')\n    monthly_data['AIRPORT_FLIGHTS_MONTH'] = monthly_data['AIRPORT_FLIGHTS_MONTH'].astype('int64')\n    monthly_data['AIRLINE_FLIGHTS_MONTH'] = monthly_data['AIRLINE_FLIGHTS_MONTH'].astype('int64')\n    monthly_data['AIRLINE_AIRPORT_FLIGHTS_MONTH'] = monthly_data['AIRLINE_AIRPORT_FLIGHTS_MONTH'].astype('int64')\n    monthly_data['PLANE_AGE'] = monthly_data['PLANE_AGE'].astype('int32')\n    \n    # reset index\n    monthly_data.reset_index(inplace=True, drop=True)\n    \n    # print elapsed time\n    print(f'Elapsed Time: {time.time() - start}')\n    \n    print(\"FINISHED\")\n    \n    # return cleaned file\n    return monthly_data","e718a378":"# Read and process each month of raw data using the cleaning function\n\ndf = pd.read_csv('data\/raw_data\/ONTIME_REPORTING_01.csv')\nmonth01 = month_cleanup(df, aircraft, coords, names, weather, passengers, employees)\ndf = pd.read_csv('data\/raw_data\/ONTIME_REPORTING_02.csv')\nmonth02 = month_cleanup(df, aircraft, coords, names, weather, passengers, employees)\ndf = pd.read_csv('data\/raw_data\/ONTIME_REPORTING_03.csv')\nmonth03 = month_cleanup(df, aircraft, coords, names, weather, passengers, employees)\ndf = pd.read_csv('data\/raw_data\/ONTIME_REPORTING_04.csv')\nmonth04 = month_cleanup(df, aircraft, coords, names, weather, passengers, employees)\ndf = pd.read_csv('data\/raw_data\/ONTIME_REPORTING_05.csv')\nmonth05 = month_cleanup(df, aircraft, coords, names, weather, passengers, employees)\ndf = pd.read_csv('data\/raw_data\/ONTIME_REPORTING_06.csv')\nmonth06 = month_cleanup(df, aircraft, coords, names, weather, passengers, employees)\ndf = pd.read_csv('data\/raw_data\/ONTIME_REPORTING_07.csv')\nmonth07 = month_cleanup(df, aircraft, coords, names, weather, passengers, employees)\ndf = pd.read_csv('data\/raw_data\/ONTIME_REPORTING_08.csv')\nmonth08 = month_cleanup(df, aircraft, coords, names, weather, passengers, employees)\ndf = pd.read_csv('data\/raw_data\/ONTIME_REPORTING_09.csv')\nmonth09 = month_cleanup(df, aircraft, coords, names, weather, passengers, employees)\ndf = pd.read_csv('data\/raw_data\/ONTIME_REPORTING_10.csv')\nmonth10 = month_cleanup(df, aircraft, coords, names, weather, passengers, employees)\ndf = pd.read_csv('data\/raw_data\/ONTIME_REPORTING_11.csv')\nmonth11 = month_cleanup(df, aircraft, coords, names, weather, passengers, employees)\ndf = pd.read_csv('data\/raw_data\/ONTIME_REPORTING_12.csv')\nmonth12 = month_cleanup(df, aircraft, coords, names, weather, passengers, employees)\n\n# COMBINE MASTER FILE\n\nall_data = pd.concat([month01, month02, month03, month04, month05, month06, month07, month08, month09, month10, month11, month12]).reset_index(drop=True)\nall_data.to_pickle(\"data\/pkl\/train_val.pkl\")\nall_data.to_csv('data\/train_val.csv', index=False)","28d368ce":"# Split into subsets\ntrain, test = train_test_split(all_data, test_size=.3, random_state=42, stratify=all_data['DEP_DEL15'])\n\n# Our Train set\ntrain.head()","07cb49a0":"# Our Validation set\ntest.head()","ea21d718":"# Create lookup tables \n\ncarrier_historical = pd.DataFrame(train.groupby(['CARRIER_NAME', 'MONTH'])['DEP_DEL15'].mean().transpose().reset_index())\ncarrier_historical.rename(columns={'DEP_DEL15':'CARRIER_HISTORICAL'}, inplace=True)\n\nairport_historical = pd.DataFrame(train.groupby(['DEPARTING_AIRPORT', 'MONTH'])['DEP_DEL15'].mean().transpose().reset_index())\nairport_historical.rename(columns={'DEP_DEL15':'DEP_AIRPORT_HIST'}, inplace=True)\n\nprev_airport_historical = airport_historical\nprev_airport_historical.rename(columns={'DEPARTING_AIRPORT':'PREVIOUS_AIRPORT', 'DEP_DEL15':'PREV_AIRPORT_HIST'}, inplace=True)\n\nday_historical = pd.DataFrame(train.groupby(['DAY_OF_WEEK', 'MONTH'])['DEP_DEL15'].mean().transpose().reset_index())\nday_historical.rename(columns={'DEP_DEL15':'DAY_HISTORICAL'}, inplace=True)\n\ndep_block_lookup = pd.DataFrame(train.groupby(['DEP_TIME_BLK', 'MONTH'])['DEP_DEL15'].mean().transpose().reset_index())\ndep_block_lookup.rename(columns={'DEP_DEL15':'DEP_BLOCK_HIST'}, inplace=True)","dd5b0e17":"# Merge lookup tables back onto data frame\n\ntrain = pd.merge(train, carrier_historical, how='left')\ntrain = pd.merge(train, airport_historical, how='left')\ntrain = pd.merge(train, prev_airport_historical, how='left')\ntrain = pd.merge(train, day_historical, how='left')\ntrain = pd.merge(train, dep_block_lookup, how='left')","5dbbb8cc":"# Now merge these lookup tables onto our Validation data frame\n\ntest = pd.merge(test, carrier_historical, how='left')\ntest = pd.merge(test, airport_historical, how='left')\ntest = pd.merge(test, prev_airport_historical, how='left')\ntest = pd.merge(test, day_historical, how='left')\ntest = pd.merge(test, dep_block_lookup, how='left')","bfe934ef":"# Fillna with mean\ntrain['DEP_AIRPORT_HIST'].fillna(train['DEP_AIRPORT_HIST'].mean(), inplace=True)\n\n# save files to pickle\ntrain.to_pickle(\"data\/pkl\/train.pkl\")\ntrain.to_csv('data\/train.csv', index=False)","d150d228":"# fillna with mean\ntest['DEP_AIRPORT_HIST'].fillna(test['DEP_AIRPORT_HIST'].mean(), inplace=True)\n\n# save to pickle\ntest.to_pickle(\"data\/pkl\/test.pkl\")\ntest.to_csv('data\/test.csv', index=False)","6eb5d4de":"This function processes our data set and combines it into one large master set.","583aee69":"### Cleaning Weather Data","10af0f14":"For our target encoding, we will group monthly delay statistics by the following categories:\n\n- Carrier\n- Airport (Use for both departing airport and arriving airport)\n- Day of Week\n- Departure Block","636c7cb3":"B43_AIRCRAFT_INVENTORY provides information about specific tail numbers. We want to know the age of an aircraft, and how many passengers it seats.","7af0170a":"P10_EMPLOYEES is so we can determine how many employees a carrier has for Passenger Handling (flight attendants) as well as Ground Service, so that we can determine the employees per passenger.","3886f307":"T3_AIR_CARRIER_SUMMARY_AIRPORT_ACTIVITY provides information on how many departures were performed (REV_ACRFT_DEP_PERF_510) and how many passengers were enplaned (REV_PAX_ENP_110) by CARRIER and AIRPORT. We'll use this data to provide metrics for the \"busy-ness\" of an airport and airline.","0edaafad":"## About the Data","45c27967":"## Loading Data for Merging","916b041f":"Weather Data was acquired on a daily basis for each airport used in the data set. We will ultimately use snowfall, ground snow, precipitation, wind speed, and temperature as features in our data set.","072422af":"AIRPORT_COORDINATES simply provides specific latitide\/longitude for airports. We'll use this as location information.","85e86eae":"## Data Split - Test and Validation","491d25a0":"We also have a set of the airports and their city names to match up with the weather dataset, so that we can then match this up to our On-Time Dataset","a53970da":"# Process Train\/Test Sets","60340280":"Our data comes from a variety of sources, all aimed at creating a full view of airport delay through various study metrics involving the airport, aircraft, airline, passengers, and weather.\n\nOur primary dataset is the Bureau of Transportation Statistics' Montly On-Time Report, which for the year of 2019 comprises several million rows of data on every flight flown domestically for the entire year. We use and combine these monthly statistics with a variety of other data sets to gain further insights.\n\nWe use 5 informational datasets from the Bureau of Transportation Statistics:\n* T3_AIR_CARRIER_SUMMARY_AIRPORT_ACTIVITY.csv\n* B43_AIRCRAFT_INVENTORY.csv\n* AIRPORT_COORDINATES.csv\n* CARRIER_DECODE.csv\n* P10_EMPLOYEES.csv\n\n\n2 informational datasets from the National Centers for Environmental Information\n* Airport_Weather.csv\n* Airport_list.csv\n\nThe data sets can be refined at download, so I chose features that I needed when acquiring the data.\n\nOur base data of on-time reporting is feature rich. We have detailed information for EVERY flight taken, including the date, the carrier, the tail number, the origin airport, the destination airport, the time the flight left, the reason for delay if delayed, the length of the flight, and the distance it traveled on the flight. We are interested in the delay and will clean for both general delay and specific delay.","e7f03ca2":"# Cleaning Function","91279ddb":"# Obtaining our Data","52bad130":"# Notebook Preparation","c6be118f":"# Dataset Cleanup\n\nThis notebook demonstrates how the original 24 data files are combined into the 4 train and test sets provided.\n","69b02d29":"CARRIER_DECODE is to get a lookup table for airline codes to match into the main On-Time Reports.","90e96fce":"We need to split our data into a train and testing set, because we will be using target encoding on our data. It's important that our target encoding not utilize any information found in either our Validation or our Test sets of new, unseen data. In fact, we use the target encoding that is created in our Train set to populate our Val and Test set target encodings, ensuring that our Validation\/Test sets contain no leakage.","64362c43":"# Scrubbing\/Cleaning our Data","1d964066":"## Target Encoding"}}