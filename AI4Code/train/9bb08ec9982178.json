{"cell_type":{"dfe1b9b6":"code","d71512d5":"code","208200e9":"code","02e715cf":"code","1fa0ac6b":"code","d9c8da7a":"code","3b2d1b47":"code","eca00a02":"code","14bf34c2":"code","81ad43df":"code","f7428069":"code","91a0d61e":"code","b9970985":"code","19e0a14a":"code","c166cf8e":"code","da6046b3":"code","e6591286":"code","954ce6db":"code","b3351b30":"code","9f5f892b":"code","ec5e8ec8":"code","a971a5b7":"code","b1d1b0c6":"code","b406de1c":"code","bcdf8172":"code","309314de":"code","29f9893f":"code","c8eee320":"code","95bced6d":"code","dfe3ff90":"code","98e313ff":"code","8756dbd0":"code","20b3bb77":"code","1fdb8559":"code","c11f6c6a":"markdown","7ea359fb":"markdown","dc9e37c5":"markdown","5d70069d":"markdown","1f2c4102":"markdown"},"source":{"dfe1b9b6":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","d71512d5":"data = pd.read_csv(\"\/kaggle\/input\/performance-prediction\/summary.csv\")\ndata.head()","208200e9":"data.info()","02e715cf":"data.describe()","1fa0ac6b":"data[\"Target\"].value_counts()","d9c8da7a":"names = data[\"Name\"]\ndata.drop([\"Name\"],inplace=True,axis=1)","3b2d1b47":"import seaborn as sns\nplt.subplots(figsize=(18,14))\nsns.heatmap(data.corr(),annot=True,linewidths=0.4,linecolor=\"black\",fmt=\"1.2f\",cbar=False)\nplt.title(\"Correlation\",fontsize=50)\nplt.xticks(rotation=35)\nplt.show()","eca00a02":"targetLoves = [\"GamesPlayed\",\"MinutesPlayed\",\"PointsPerGame\",\"FieldGoalsMade\",\"FieldGoalsAttempt\",\"FreeThrowMade\",\"FreeThrowAttempt\"]","14bf34c2":"import plotly.graph_objects as go\nfrom plotly.offline import iplot, init_notebook_mode\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.io as pio\n\ninit_notebook_mode(True)\n#I will round floats for better visualize \nrounded_data = data.apply(lambda x : round(x))\nrounded_data.head()","81ad43df":"fig1 = px.scatter_matrix(rounded_data,color=\"Target\",dimensions=list(rounded_data.columns[:9])+[\"Target\"])\nfig1.update_traces(marker=dict(showscale=False),diagonal_visible=False)\nfig1.update_layout(title={\"text\":\"Scatter Matrix-1\",\"x\":0.5,\"font\":{\"size\":35}},\n                   height=1500,showlegend=False)\nfig1.layout.coloraxis.showscale = False\nfig1.show()","f7428069":"fig2 = px.scatter_matrix(rounded_data,color=\"Target\",dimensions=list(rounded_data.columns[10:]))\nfig2.update_traces(marker=dict(showscale=False),diagonal_visible=False)\nfig2.update_layout(title={\"text\":\"Scatter Matrix-2\",\"x\":0.5,\"font\":{\"size\":35}},\n                   height=1500,showlegend=False)\nfig2.layout.coloraxis.showscale = False\nfig2.show()","91a0d61e":"px.box(rounded_data)","b9970985":"distlabels = [\"FieldGoalsMade\",\"FreeThrowMade\",\"Steals\",\"Blocks\",\"Turnovers\"]\nhist_data = rounded_data[distlabels]\nfig3 = ff.create_distplot([hist_data[i] for i in list(hist_data)],group_labels=distlabels,curve_type=\"normal\")\nfig3.show()","19e0a14a":"nameList = []\ndef splitMyName(x):\n    global nameList\n    for name in x.split():\n        nameList.append(name)\nnames.apply(splitMyName)\nnameList[:10]","c166cf8e":"from collections import Counter\n\nnameCount = Counter(nameList)\ncountedNameDict = dict(nameCount)\nsortedNameDict = sorted(countedNameDict.items(),key = lambda x : x[1],reverse=True)\nprint(\"Most Used 20 Names\")\nfor name,counted in sortedNameDict[0:20]:\n    print(\"{} : {}\".format(name,counted))","da6046b3":"from wordcloud import WordCloud\n\nnamecloud = WordCloud(max_words=500,background_color=\"white\",min_font_size=4).generate_from_frequencies(countedNameDict)\nplt.figure(figsize=[13,10])\nplt.axis(\"off\")\nplt.title(\"Name Cloud\",fontsize=20)\nplt.imshow(namecloud)\nplt.show()","e6591286":"list(names[9:13])","954ce6db":"dictForNameCorr = dict()\nnameSurnameCounter = 1\ndef nameSurnameEqualMyNumber(x):\n    global dictForNameCorr\n    global nameSurnameCounter\n    x = x.split()\n    if x[0] in dictForNameCorr:\n        return dictForNameCorr[x[0]]\n    elif x[1] in dictForNameCorr:\n        return dictForNameCorr[x[1]]\n    else:\n        dictForNameCorr[x[0]] = nameSurnameCounter\n        nameSurnameCounter += 1\n        dictForNameCorr[x[1]] = nameSurnameCounter\n        nameSurnameCounter += 1\n        return dictForNameCorr[x[0]]\nfor i in names[9:13]:\n    print(f\"{i} : {nameSurnameEqualMyNumber(i)}\")","b3351b30":"nameForCorr = names.apply(nameSurnameEqualMyNumber)","9f5f892b":"nameForCorr","ec5e8ec8":"sns.heatmap(np.corrcoef(nameForCorr,data[\"Target\"]),annot=True)\nplt.title(\"Correlation between Name and Target\")\nplt.show()","a971a5b7":"forSample = pd.DataFrame({\"Name\":nameForCorr,\"Target\":data[\"Target\"]})\nprint(forSample.Target.value_counts())\nforSample.head()","b1d1b0c6":"forSample = forSample.sort_values(by=\"Target\")[:509*2]\nforSample.Target.value_counts()","b406de1c":"from sklearn.model_selection import train_test_split\n\nname_train,name_test,target_train,target_test = train_test_split(forSample[\"Name\"].values.reshape(-1,1),forSample[\"Target\"].values,random_state = 40,test_size = 0.2)","bcdf8172":"from xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\nxgb = XGBClassifier()\nxgb.fit(name_train,target_train)\nypred = xgb.predict(name_test)\nplt.subplots(figsize=(18,14))\nsns.heatmap(confusion_matrix(ypred,target_test),annot=True,fmt=\"1.2f\",cbar=False,annot_kws={\"size\": 20})\nplt.title(f\"Name->Target Accuracy: {accuracy_score(ypred,target_test)}\",fontsize=40)\nplt.xlabel(\"Target\",fontsize=30)\nplt.show()","309314de":"targetLoves","29f9893f":"X = data[targetLoves]\ny = data[\"Target\"]","c8eee320":"from imblearn.combine import SMOTETomek\n\n\nsmothy = SMOTETomek(random_state = 42)\nsmothy.fit(X,y)\nX_smothy,y_smothy = smothy.fit_resample(X,y)","95bced6d":"print(\"New Counts After Combining Under and Over Sampling\")\nprint(y_smothy[y_smothy==0].value_counts())\nprint(y_smothy[y_smothy==1].value_counts())","dfe3ff90":"from sklearn.preprocessing import MinMaxScaler\nmms = MinMaxScaler(feature_range=(0,1))\nx = mms.fit_transform(X_smothy)","98e313ff":"x_train,x_test,y_train,y_test = train_test_split(x,y_smothy,test_size=0.2,random_state=67)","8756dbd0":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\n\nclassifier_list = [[\"Logistic Regression\",LogisticRegression()],\n                  [\"RandomForest Classifier\",RandomForestClassifier()],\n                  [\"AdaBoost Classifier\",AdaBoostClassifier()],\n                  [\"DecisionTree Classifier\",DecisionTreeClassifier()],\n                  [\"KNeighbors Classifier\",KNeighborsClassifier()],\n                  [\"SVC\",SVC()],\n                  [\"GaussianNB\",GaussianNB()],\n                  [\"LGBM Classifier\",LGBMClassifier()],\n                  [\"XGB Classifier\",XGBClassifier()]]\nfor modelName, classifier in classifier_list:\n    classifier.fit(x_train,y_train)\n    print(f\"{modelName} Accuracy: {accuracy_score(classifier.predict(x_test),y_test)}\")\n","20b3bb77":"lgbm = LGBMClassifier(boosting_type='gbdt', num_leaves=30, max_depth=56, learning_rate=0.1, \n                      n_estimators=42, subsample_for_bin=30000, objective=None, \n                      class_weight=None, min_split_gain=0.0, min_child_weight=0.1, \n                      min_child_samples=20, subsample=0.4, subsample_freq=0, colsample_bytree=0.3, \n                      reg_alpha=0.0, reg_lambda=0.0, random_state=42, n_jobs=- 1, silent=True, \n                      importance_type='split')\nlgbm.fit(x_train,y_train)\nypred = lgbm.predict(x_test)\nplt.subplots(figsize=(18,14))\nsns.heatmap(confusion_matrix(ypred,y_test),annot=True,fmt=\"1.0f\",cbar=False,annot_kws={\"size\": 20})\nplt.title(f\"LGBM Accuracy: {accuracy_score(ypred,y_test)}\",fontsize=40)\nplt.xlabel(\"Target\",fontsize=30)\nplt.show()","1fdb8559":"xgb = XGBClassifier(base_score=0.4, booster='gbtree', colsample_bylevel=1,\n       colsample_bynode=1, colsample_bytree=0.4, gamma=0.00025,\n       importance_type='gain', learning_rate=0.0099, max_delta_step=0,\n       max_depth=8, min_child_weight=0, missing=None, n_estimators=512,\n       n_jobs=1, nthread=None, random_state=0,\n       reg_alpha=0.00004, reg_lambda=1, scale_pos_weight=1, seed=42,\n       silent=None, subsample=0.3, verbosity=1)\nxgb.fit(x_train,y_train)\nypred = xgb.predict(x_test)\nplt.subplots(figsize=(18,14))\nsns.heatmap(confusion_matrix(ypred,y_test),annot=True,fmt=\"1.0f\",cbar=False,annot_kws={\"size\": 20})\nplt.title(f\"XGB Accuracy: {accuracy_score(ypred,y_test)}\",fontsize=40)\nplt.xlabel(\"Target\",fontsize=30)\nplt.show()","c11f6c6a":"<h3>Actually correlation map really makes sense like \"FreeThrowMade\" and \"FreeThrowAttempt\"(%98),\"Steals\" and \"Assists\"(%75) or \"Assists\" and \"Steals\"(%75) etc. But unfortunately \"Target\" does not have any high correlation. Anyway just start with visualization.<\/h3>","7ea359fb":"# Thanks For Reading","dc9e37c5":"If you want to learn more Sampling Techniques, you can check [Resampling Techniques to handle Imbalanced dataset](http:\/\/www.kaggle.com\/prasathm2001\/resampling-techniques-to-handle-imbalanced-dataset#Random-Over-Sampling-Fraud-Transactions-(Minority-Class)) by Prasath M","5d70069d":"Let's check correlation between Names and Target too x)","1f2c4102":"<h1>Looks like random...<\/h1>\n<h2>Let's back to the main topic <\/h2>"}}