{"cell_type":{"126fd893":"code","916bc6b7":"code","a9e0c040":"code","374736b0":"code","a18a6f96":"code","12bf2196":"code","5a881118":"code","e7d6cb0c":"code","7bcefb0b":"code","0f48748e":"code","9960c794":"code","b6bfd7cf":"code","8cf766df":"code","87972320":"code","4dbbe046":"code","eb94ded5":"code","bd54fda9":"code","687bb62c":"code","b6fe62de":"code","9cdc108a":"markdown","81672bf2":"markdown","ba2e84d6":"markdown","e054aeed":"markdown","f00ca63b":"markdown","6e8c3537":"markdown","5e102a48":"markdown","138483fb":"markdown","2635eb97":"markdown","9364d9ce":"markdown","e80b1236":"markdown","cae2f36c":"markdown","7cf0c09e":"markdown","3d311110":"markdown"},"source":{"126fd893":"import numpy as np\nimport glob\nimport warnings\nwarnings.simplefilter('ignore')\ndata_list=glob.glob('\/kaggle\/input\/painting-vs-photograph-classification-dataset\/Raw Data\/painting\/*.jpg')\nnp.array(data_list).shape","916bc6b7":"from tensorflow.keras.preprocessing.image import load_img\nload_img(data_list[20])","a9e0c040":"import pandas as pd\nimage_list=[]\nfor i in range(1361):\n    image_list.append(load_img(data_list[i], target_size=(64,64),grayscale=True))\nimg_data=[]\nfor k in range(1360):\n    img_data.append(np.array(image_list[k]).flatten())\nzeros=pd.DataFrame(np.zeros(1360).astype(int))\nimg_data_pd=pd.DataFrame(img_data)\npaint_dataset=pd.concat([zeros,img_data_pd],axis=1)\npaint_dataset","374736b0":"data_list2=glob.glob('\/kaggle\/input\/painting-vs-photograph-classification-dataset\/Raw Data\/photos\/*.jpg')\nnp.array(data_list2).shape","a18a6f96":"load_img(data_list2[15])","12bf2196":"image_list2=[]\nfor i in range(3747):\n    image_list2.append(load_img(data_list2[i], target_size=(64,64),grayscale=True))\nimg_data2=[]\nfor k in range(3747):\n    img_data2.append(np.array(image_list2[k]).flatten())\nones=pd.DataFrame(np.ones(3747).astype(int))\nimg_data_pd2=pd.DataFrame(img_data2)\nphoto_dataset=pd.concat([ones,img_data_pd2],axis=1)\nphoto_dataset","5a881118":"new_dataset=pd.concat([paint_dataset,photo_dataset],axis=0)\nnew_dataset","e7d6cb0c":"new_dataset=new_dataset.sample(frac=1,random_state=123)\nnew_dataset","7bcefb0b":"dataset=new_dataset.copy()","0f48748e":"from sklearn.model_selection import train_test_split\nx =dataset.iloc[:,1:]\ny =dataset.iloc[:,[0]]\nx_train_pd, x_test_pd, y_train_pd, y_test_pd = train_test_split(x, y, test_size=0.2,random_state=123)","9960c794":"#normalizes data from 1 to 0. \nx_train = x_train_pd.astype('float32')\/255\ny_train = y_train_pd.astype('float32')\nx_test = x_test_pd.astype('float32')\/255\ny_test = y_test_pd.astype('float32')","b6bfd7cf":"#change data into numpy array\nx_train= x_train.to_numpy()\ny_train= y_train.to_numpy()\nx_test= x_test.to_numpy()\ny_test= y_test.to_numpy()\n\n#reshape train data and test data into 64 * 64 * 1channel\nx_train = x_train.reshape(x_train.shape[0], 64, 64, 1).astype('float32')\nx_test = x_test.reshape(x_test.shape[0], 64, 64, 1).astype('float32')","8cf766df":"#convert y_train and y_test into 2 categories\nfrom tensorflow import keras as kr\ny_train = kr.utils.to_categorical(y_train, 2)\ny_test = kr.utils.to_categorical(y_test, 2)\nnum_classes = y_train.shape[1]\nnum_classes","87972320":"#import libraries\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Dense, Activation, Flatten\nfrom tensorflow.keras.optimizers import Adam\n\n#Build an ordinary \"Deep Learning\" model with CNN and maxpooling by using Keras.\nmodel = Sequential()\nmodel.add(Conv2D(512, (5, 5), input_shape=(64, 64, 1), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n#Choose an optimizer and compile the model.\nmodel.compile(optimizer = Adam(learning_rate = 0.01), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n#And print the summary of the model.\nprint(model.summary())","4dbbe046":"#model fitting\nmodel1 = model.fit(x_train, y_train,batch_size=128, epochs=50)","eb94ded5":"#Check this model by using two metrics, loss and accuracy.\nmetrics = ['accuracy','loss']\n#show the evaluation result by using matoplot.\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(15, 5))\n#Use \"For Loop\".\nfor i in range(len(metrics)):\n    metric = metrics[i]\n    #set subplots to show the result\n    plt.subplot(1, 2, i+1)\n    #Titles of subplots are \"loss\" and \"accuracy\"\n    plt.title(metric) \n    plt_train1 = model1.history[metric] \n    #plot them all\n    plt.plot(plt_train1, label='train1') \n    plt.legend() \nplt.show()","bd54fda9":"i=120\n#Here is the prediction sample.\nplt.imshow(x_test[[i]].reshape(64,64),cmap='Greys')","687bb62c":"#Let's predict.\nprediction=model.predict(x_test[[i]]) \nprediction","b6fe62de":"#Let's check the result.\ndic={0:'Picture',1:'Photo'}\nprint(\"The model's answer is\",dic[np.argmax(prediction)],\". :-)\")\nprint(\"The correct label is\",dic[np.argmax(y_test[i])],\". :-)\")","9cdc108a":"#### First of all, let's think how to make image recognition datasets.","81672bf2":"## Over 95% accuracy. Okay, now is the time to wrap up!","ba2e84d6":"#### <font color=\"red\">Wow, it looks as if it were a photo!<\/font>","e054aeed":"### I wanna shuffle indexes of the new_dataset.","f00ca63b":"### Let's make use of the trained model and predict one case :-)","6e8c3537":"# Okay! I made it! ","5e102a48":"### Let's follow the process list.\n<pre>\n[process list]\n1) split dataset into x_train,y_train,x_test,y_test\n2) Machine Learning. I wanna adopt CNN and Deep Learning Eech.\n3) Check the model accuracy.\n4) Test the model.\n5) Evaluate the model.\n<\/pre>","138483fb":"### Now I know I was give 1361 painting images.\n### I wanna see sample images. ","2635eb97":"<HR>","9364d9ce":"## <font color=\"Green\">Painting or Photograph?<\/font> Could this deep learning model guess right?","e80b1236":"#### <font color=\"red\">Wow, it looks as if it were a painting!<\/font>","cae2f36c":"### Let's check the result.","7cf0c09e":"## This model works?!\n## Thanks for reading my notebook. This notebook is useful to know how to make Image Datasets.","3d311110":"### Now I know I was given 3747 photos."}}