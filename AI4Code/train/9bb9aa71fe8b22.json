{"cell_type":{"0cd0ca91":"code","5fae4347":"code","b58053ef":"code","bf370860":"code","58372209":"code","7aed98d4":"code","30934164":"code","a9bdfb54":"code","508b4ec4":"markdown","e98a5f20":"markdown","b180e3eb":"markdown","455cffac":"markdown","3e0da555":"markdown","be4faa90":"markdown"},"source":{"0cd0ca91":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transform\nimport torchvision.transforms.functional as TF\nimport random\nfrom PIL import Image\n\nrandom.seed(123)\n\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nbatch_size = 1\nworkers = 1\nprint(\"device available: \", device)\n\nfrom collections import OrderedDict\n\nin_features = 128\n\ndef plot(inputTensor):\n    inputTensor = inputTensor.cpu().numpy()[0]\n    mean, std = np.mean(inputTensor), np.std(inputTensor)\n    inputTensor = np.round((inputTensor - mean)\/std)\n    plt.figure(figsize=(10, 10))\n    for dimension in range(inputTensor.shape[0]):\n        r = random.random()\n        b = random.random()\n        g = random.random()\n        channel = inputTensor[dimension]\n        channel = channel[ ..., np.newaxis]\n        image = np.concatenate((channel*r, channel*g, channel*b), axis=-1)\n\n        plt.imshow(image, alpha=0.2)\n        \n    plt.show()\n\nclass Unet(nn.Module):\n    def __init__(self, in_channels = 1, out_channel = 1, init_features=in_features):\n        super(Unet, self).__init__()\n        self.in_channels = 1\n        self.out_channels = 3\n        self.init_features = init_features\n        \n        self.encoder1 = self.__block__(inchannels = in_channels,\n                                      outchannels = init_features)\n        self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n        self.encoder2 = self.__block__(inchannels = init_features,\n                                      outchannels = 2*init_features)\n        self.encoder3 = self.__block__(inchannels = 2*init_features,\n                                      outchannels = 4*init_features)\n        self.encoder4 = self.__block__(inchannels = 4*init_features,\n                                      outchannels = 8*init_features)\n        self.bottle   = self.__block__(inchannels = 8*init_features,\n                                      outchannels = 16*init_features)\n        self.upconv4  = nn.ConvTranspose2d(\n            in_channels = 16*init_features, out_channels = 8 * init_features,\n            kernel_size = 2, stride = 2\n        )\n        self.decoder4 = self.__block__(inchannels = 16*init_features,\n                                      outchannels = 8*init_features)\n        self.upconv3  = nn.ConvTranspose2d(\n            in_channels = 8 * init_features, out_channels = 4 * init_features,\n            kernel_size = 2, stride = 2\n        )\n        self.decoder3 = self.__block__(inchannels = 8*init_features,\n                                      outchannels = 4*init_features)\n        self.upconv2 = nn.ConvTranspose2d(\n            in_channels = 4 * init_features, out_channels = 2 * init_features,\n            kernel_size = 2, stride = 2\n        )\n        self.decoder2 = self.__block__(inchannels = 4*init_features,\n                                      outchannels = 2*init_features)\n        self.upconv1 = nn.ConvTranspose2d(\n            in_channels = 2 * init_features, out_channels = init_features,\n            kernel_size = 2, stride = 2\n        )\n        self.decoder1 = self.__block__(inchannels = 2*init_features, \n                                      outchannels = init_features)\n        self.final = nn.Conv2d(in_channels = init_features, out_channels = out_channel, kernel_size=1)\n        \n        self.sub_final = self.__fc__(16*init_features)\n        \n            \n    def forward(self, x):\n        enc1 = self.encoder1(x); plot(enc1)\n        enc2 = self.encoder2(self.pool(enc1))\n        enc3 = self.encoder3(self.pool(enc2)); plot(enc3)\n        enc4 = self.encoder4(self.pool(enc3))\n        \n        bottom = self.bottle(self.pool(enc4)); plot(bottom)\n        pred_label = self.sub_final(bottom)\n        \n        dec = self.upconv4(bottom)\n        dec = torch.cat((dec, enc4), dim=1)\n        dec = self.decoder4(dec)\n        \n        dec = self.upconv3(dec)\n        dec = torch.cat((dec, enc3), dim=1)\n        dec = self.decoder3(dec) ; plot(dec)\n        \n        dec = self.upconv2(dec)\n        dec = torch.cat((dec, enc2), dim=1)\n        dec = self.decoder2(dec) \n        \n        dec = self.upconv1(dec)\n        dec = torch.cat((dec, enc1), dim=1)\n        dec = self.decoder1(dec) ; plot(dec)\n        \n        dec = self.final(dec)\n        \n        return torch.sigmoid(dec), pred_label\n        \n    class __block__(nn.Module):\n        def __init__(self, inchannels, outchannels):\n            super().__init__()\n   \n            self.conv = nn.Sequential( \n                nn.Conv2d(\n                    in_channels=inchannels,\n                    out_channels=outchannels,\n                    kernel_size=3,\n                    padding=1,\n                    bias=False,\n                ),\n                nn.BatchNorm2d(num_features=outchannels)\n            )\n            self.block = nn.Sequential(\n                nn.ReLU(),\n                nn.Conv2d(\n                    in_channels=outchannels,\n                    out_channels=outchannels,\n                    kernel_size=3,\n                    padding=1,\n                    bias=False,\n                ),\n                nn.BatchNorm2d(num_features=outchannels)\n            )\n            self.relu = nn.ReLU()\n            \n        \n        def forward(self, x):\n            x = self.conv(x)\n            return self.relu(self.block(x) + x)\n\n    class __fc__(nn.Module):\n        def __init__(self, in_features):\n            super().__init__()\n            self.block = nn.Sequential(\n                nn.Conv2d(\n                    in_channels=in_features,\n                    out_channels=in_features\/\/2,\n                    kernel_size=2,\n                    stride=2,\n                    bias=False,\n                ),\n                nn.BatchNorm2d(num_features=in_features\/\/2),\n                nn.ReLU(),\n                nn.Conv2d(\n                    in_channels=in_features\/\/2,\n                    out_channels=in_features\/\/4,\n                    kernel_size=2,\n                    stride=2,\n                    bias=False,\n                ),\n                nn.BatchNorm2d(num_features=in_features\/\/4),\n                nn.ReLU(),\n                nn.Conv2d(\n                    in_channels=in_features\/\/4,\n                    out_channels=3,\n                    kernel_size=2,\n                    stride=2,\n                    bias=False,\n                ),\n                nn.Softmax(dim=1)\n            )\n            \n        def forward(self,x) :\n            return self.block(x)\n\nunet = Unet()","5fae4347":"\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nfor dirname, subdir, filenames in tqdm(os.walk('\/kaggle\/input')):\n    for filename in filenames:\n        filepath = (os.path.join(dirname, filename))\n        if \"images\" in filename:\n            images = np.load(filepath, allow_pickle = True)\n        elif \"masks\" in filename:\n            masks = np.load(filepath, allow_pickle = True)\n        elif \"labels\" in filename:\n            labels = np.load(filepath, allow_pickle = True)\n        elif \"unet\" in filename:\n            state_dict = torch.load(filepath,map_location=torch.device('cpu'))\n            unet.load_state_dict(state_dict)\n            print('unet loaded')\n        \n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b58053ef":"dataset = np.column_stack((images, masks, labels))\nprint(dataset.shape)\n# 3064x3x512x512\nfrom sklearn.model_selection import train_test_split\n_, dataset = train_test_split(dataset, test_size = 0.1)","bf370860":"class Resize(object):\n    def __init__(self, size=216):\n        self.size = size\n    \n    def __call__(self, sample):\n        image, mask, label = sample\n        image = TF.resize(image, size=(self.size, self.size), interpolation=Image.NEAREST)\n        mask = TF.resize(mask, size = (self.size, self.size), interpolation=Image.NEAREST)\n        return image, mask, label\n    \n\nclass toPIL(object):\n    def __init__(self):\n        pass\n    \n    def __call__(self, sample):\n        image, mask, label = sample\n        image = TF.to_pil_image(image.astype(np.float32))\n        mask = TF.to_pil_image(mask.astype(np.float32))\n        return image, mask, label\n\n    \nclass toTensor(object):\n    def __init__(self):\n        pass\n    \n    def __call__(self, sample):\n        image, mask, label = sample\n        image = TF.to_tensor(image)\n        mask = TF.to_tensor(mask)\n        return image, mask, label\n    \n\ndef toNumpy(sample):\n    image, mask, label = sample\n    image = np.array(image)\n    mask = np.array(mask)\n    return image, mask, label\n\n\ndef normalize(sample):\n    image, mask, label = sample\n    m, s = np.mean(image), np.std(image)\n    image = (image - m)\/s\n    return image, mask, label","58372209":"from torch.utils.data import Dataset, DataLoader\ninput_size = 128\nclass MRIDataset(Dataset):\n    def __init__(self, data, train=True, transform=None):\n        self.data = data\n        self.transform = transform\n        self.train = train\n        self.data = [normalize(i) for i in self.data]\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, i):\n        sample = self.data[i]\n        \n        to_pil = toPIL()\n        sample = to_pil(sample)\n            \n        resize_func = Resize(input_size)\n        sample = resize_func(sample)\n        sample = toNumpy(sample)\n        \n        image, mask, label = sample\n        target_label = np.zeros((3, 1, 1))\n        target_label[label-1, 0, 0] = 1\n        label = target_label\n                \n        image = torch.from_numpy(image.astype(np.float32))\n        mask = torch.from_numpy(mask.astype(np.float32))\n        label = torch.from_numpy(label.astype(np.float32))\n        \n        image = torch.unsqueeze(image, dim = 0)\n        mask = torch.unsqueeze(mask, dim = 0)\n\n        \n        return image, mask, label\n    \n\ndataset = MRIDataset(dataset)","7aed98d4":"def getDataLoader(dataset, batch = batch_size):\n    dataloader = DataLoader(\n        dataset, \n        batch_size = batch,\n        shuffle = True,\n        num_workers = workers\n    )\n    return dataloader\n\ndataLoader = getDataLoader(dataset)","30934164":"print(type(dataLoader))","a9bdfb54":"with torch.no_grad():\n    unet.eval()\n    unet.to(device)\n    for img, mask, label in dataLoader:\n        plt.imshow(img[0,0].numpy())\n        plt.show()\n        img, mask, label = img.to(device), mask.to(device), label.to(device)\n        pred = unet(img)\n        break\n        ","508b4ec4":"<h3>Dataset class and DataLoader<\/h3>","e98a5f20":"<h3>plot training progress<\/h3>","b180e3eb":"<h3>testing model<\/h3>","455cffac":"<h3>Loss function<\/h3>","3e0da555":"<h3>Training model<\/h3>","be4faa90":"<h3>Showing some results<\/h3>"}}