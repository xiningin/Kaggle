{"cell_type":{"fd24f85f":"code","1870427c":"code","798aae09":"code","79da2599":"code","0fc644f7":"code","483fb7a2":"code","a2d066b2":"code","d9e7c5cc":"code","7ce5857c":"code","76868080":"code","628942d8":"code","b314e82e":"code","b6a07a0b":"code","d96c1123":"code","de302cc8":"code","f2dd612b":"markdown","94d1f130":"markdown","36481314":"markdown","6e66792c":"markdown","9c7ff18d":"markdown","1476ec6b":"markdown"},"source":{"fd24f85f":"import tensorflow as tf\n\nfrom tensorflow.python.keras.applications.vgg19 import VGG19","1870427c":"model = VGG19(\n    include_top = False,\n    weights = 'imagenet'\n)\n\nmodel.trainable = False","798aae09":"from tensorflow.python.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.python.keras.applications.vgg19 import preprocess_input\nfrom tensorflow.python.keras.models import Model\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","79da2599":"def load_and_process_image(image_path):\n    img = load_img(image_path)\n    img = img_to_array(img)\n    img = preprocess_input(img)\n    img = np.expand_dims(img, axis = 0)\n    return img","0fc644f7":"def deprocess(x):\n    # perform the inverse of the preprocessiing step\n    x[:, :, 0] += 103.939\n    x[:, :, 1] += 116.779\n    x[:, :, 2] += 123.68\n    x = x[:, :, ::-1]\n\n    x = np.clip(x, 0, 255).astype('uint8')\n    return x\n\ndef display_image(image):\n    if len(image.shape) == 4:\n        img = np.squeeze(image, axis = 0)\n\n    img = deprocess(img)\n    \n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(img)\n    return","483fb7a2":"img = load_and_process_image('..\/input\/neural-style-transfer-images\/content.jpg')\ndisplay_image(img)","a2d066b2":"img = load_and_process_image('..\/input\/neural-style-transfer-images\/style.jpg')\ndisplay_image(img)","d9e7c5cc":"style_layers = [\n    'block1_conv1', \n    'block3_conv1', \n    'block5_conv1'\n]\n\ncontent_layer = 'block5_conv2'\n\n# intermediate models\ncontent_model = Model(\n    inputs = model.input, \n    outputs = model.get_layer(content_layer).output\n)\n\nstyle_models = [Model(inputs = model.input, \n                      outputs = model.get_layer(layer).output) for layer in style_layers]","7ce5857c":"# Content Cost\ndef content_cost(content, generated):\n    a_C = content_model(content)\n    a_G = content_model(generated)\n    cost = tf.reduce_mean(tf.square(a_C - a_G))\n    return cost","76868080":"def gram_matrix(A):\n    channels = int(A.shape[-1])\n    a = tf.reshape(A, [-1, channels])\n    n = tf.shape(a)[0]\n    gram = tf.matmul(a, a, transpose_a = True)\n    return gram \/ tf.cast(n, tf.float32)","628942d8":"lam = 1. \/ len(style_models)\n\ndef style_cost(style, generated):\n    J_style = 0\n    \n    for style_model in style_models:\n        a_S = style_model(style)\n        a_G = style_model(generated)\n        GS = gram_matrix(a_S)\n        GG = gram_matrix(a_G)\n        current_cost = tf.reduce_mean(tf.square(GS - GG))\n        J_style += current_cost * lam\n    \n    return J_style","b314e82e":"import time\n\ngenerated_images = []\n\ndef training_loop(content_path, style_path, iterations = 30, a = 10., b = 20.):\n    # initialise\n    content = load_and_process_image(content_path)\n    style = load_and_process_image(style_path)\n    generated = tf.Variable(content, dtype = tf.float32)\n    \n    opt = tf.keras.optimizers.Adam(learning_rate = 7.)\n    \n    best_cost = 1e12+0.1\n    best_image = None\n    \n    start_time = time.time()\n    \n    for i in range(iterations):\n        \n        with tf.GradientTape() as tape:\n            J_content = content_cost(content, generated)\n            J_style = style_cost(style, generated)\n            J_total = a * J_content + b * J_style\n        \n        grads = tape.gradient(J_total, generated)\n        opt.apply_gradients([(grads, generated)])\n        \n        if J_total < best_cost:\n            best_cost = J_total\n            best_image = generated.numpy()\n        \n        if i % int(iterations\/10) == 0:\n            time_taken = time.time() - start_time\n            print('Cost at {}: {}. Time elapsed: {}'.format(i, J_total, time_taken))\n            generated_images.append(generated.numpy())\n        \n    return best_image","b6a07a0b":"final = training_loop('..\/input\/neural-style-transfer-images\/content.jpg',\n                      '..\/input\/neural-style-transfer-images\/style.jpg')","d96c1123":"plt.figure(figsize = (12, 12))\n\nfor i in range(10):\n    plt.subplot(5, 2, i + 1)\n    display_image(generated_images[i])\nplt.show()","de302cc8":"display_image(final)","f2dd612b":"# Importing libraries","94d1f130":"# Training func","36481314":"# Content cost func","6e66792c":"# Gram matrix func","9c7ff18d":"# Processing images func","1476ec6b":"# Style cost func"}}