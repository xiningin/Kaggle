{"cell_type":{"b69d682b":"code","29b3f650":"code","41ab8c46":"code","fe451d3d":"code","f4e08df8":"code","0e4bff7b":"code","e5668f5e":"code","a4803f51":"code","4c10b674":"code","ac7bebd2":"code","813c4258":"code","ecfe95b5":"code","b34da8fd":"code","88357003":"code","85cf82f2":"code","e5113de9":"code","26f387f0":"code","5095d229":"code","f7cb0e64":"code","f8b1f0e7":"code","2731f705":"markdown","19c8554c":"markdown","0e61597b":"markdown","8fd1d427":"markdown","3296464e":"markdown","07682232":"markdown","e1e65dc7":"markdown","7a2deca9":"markdown"},"source":{"b69d682b":"import os\nfrom glob import glob\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport pandas as pd\nimport cv2 as cv","29b3f650":"data_dir = \"..\/input\/best-artworks-of-all-time\"\nimage_dir = \"..\/input\/best-artworks-of-all-time\/resized\/resized\"\nimage_root = \"..\/input\/best-artworks-of-all-time\/resized\"","41ab8c46":"no_plots = 8*1\nimages = glob(f'{image_dir}\/*')\n\nplt.rcParams['figure.figsize'] = (15, 15)\nplt.subplots_adjust(wspace=0, hspace=0)\n\nprint(\"Sample arts\")\nfor idx,image in enumerate(images[:no_plots]):\n    sample_img = cv.imread(image)\n    sample_img = cv.resize(sample_img,(64,64))\n    plt.subplot(1, 8, idx+1)\n    plt.axis('off')\n    plt.imshow(cv.cvtColor(sample_img,cv.COLOR_BGR2RGB))\nplt.show()","fe451d3d":"import torch\nfrom torchvision import datasets\nfrom torchvision import transforms\n\n# helper display function\ndef tensor_imshow(img,dnorm=True):\n    img = img.to('cpu')\n    npimg = img.detach().numpy()\n    if dnorm:\n        npimg = npimg*0.5+0.5\n    plt.figure(figsize=(3, 3))\n    plt.axis('off')\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()","f4e08df8":"def get_dataloader(batch_size,image_size,data_dir=image_dir,num_workers=3):\n    stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n    transform = transforms.Compose([\n        transforms.Resize((image_size,image_size)),\n        transforms.ToTensor(),\n        # We tranform our image values to be between -1 and 1 (the range of the tanh activation)\n        transforms.Normalize(*stats), # \n    ])\n    \n    dataset = datasets.ImageFolder(root=data_dir,transform=transform)\n    \n    data_loader = torch.utils.data.DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers,\n        pin_memory=True,\n    )\n    \n    return data_loader","0e4bff7b":"# Testing the dataloader\nbatch_size, image_size = 5, 64\ntrain_loader = get_dataloader(batch_size,image_size,image_root)\ndataiter = iter(train_loader)\n\nimg,_ = next(dataiter)\nsample_img = img[-1]\ntensor_imshow(sample_img)\n","e5668f5e":"import torch.nn as nn\nimport torch.nn.functional as F","a4803f51":"class Generator(nn.Module):\n    def __init__(self,z_dim=10,in_chan=3,hidden_dim=64):\n        super(Generator, self).__init__()\n        self.z_dim = z_dim\n        self.in_chan = in_chan\n        self.hidden_dim = hidden_dim\n        \n        self.generator = nn.Sequential(\n            self.make_gen_block(z_dim,512,stride=1,padding=0,),\n            self.make_gen_block(512,256),\n            self.make_gen_block(256,128),\n            self.make_gen_block(128,64),\n            self.make_gen_block(64,32),\n            self.make_gen_block(32, in_chan,final_layer=True),\n        )\n    \n    def make_gen_block(self,in_channels,op_channels,kernel_size=4,stride=2,padding=1,final_layer=False):\n        layers = []\n        layers.append(nn.ConvTranspose2d(in_channels,op_channels,kernel_size,stride,padding,bias=False))\n        \n        if not final_layer:\n            layers.append(nn.BatchNorm2d(op_channels))\n            layers.append(nn.LeakyReLU(0.2))\n        else:\n            layers.append(nn.Tanh())\n        \n        return nn.Sequential(*layers)\n    \n    def forward(self,noise):\n        x = noise.view(-1,self.z_dim,1,1)\n        return self.generator(x)\n\n    def get_noise(n_samples, z_dim, device='cpu'):\n        return torch.randn(n_samples, z_dim, device=device)","4c10b674":"#Testing Genarator\nnoise = Generator.get_noise(n_samples=5,z_dim=10)\ng = Generator(z_dim=10,in_chan=3,hidden_dim=64)\n# print(g)\nimg = g(noise)\nprint(img.shape)\nassert img.shape == (5,3,128,128), \"Generator Output Images shape incorrect\"\nprint(\"Generator Test passed!!\")","ac7bebd2":"class Discriminator(nn.Module):\n    def __init__(self,im_chan=3,conv_dim=64,image_size=64):\n        super(Discriminator, self).__init__()\n        self.image_size = image_size\n        self.conv_dim = conv_dim\n        \n        self.disc_cnn = nn.Sequential(\n            self.make_disc_block(3,32),\n            self.make_disc_block(32,64),\n            self.make_disc_block(64,128),\n            self.make_disc_block(128,256),\n            self.make_disc_block(256,512),\n            self.make_disc_block(512,1,padding=0,final_layer=True),\n        )\n        \n        \n    def make_disc_block(self,in_chan,op_chan,kernel_size=4,stride=2,padding=1,final_layer=False):\n        layers = []\n        layers.append(nn.Conv2d(in_chan,op_chan,kernel_size,stride,padding,bias=False))\n        \n        if not final_layer:\n            layers.append(nn.BatchNorm2d(op_chan))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n        \n        return nn.Sequential(*layers)\n    \n    \n    def forward(self,image):\n        pred = self.disc_cnn(image)\n        pred = pred.view(image.size(0),-1)\n        return pred\n    \n    def _get_final_feature_dimention(self):\n        final_width_height = (self.image_size \/\/  2**len(self.disc_cnn))**2\n        final_depth = self.conv_dim * 2**(len(self.disc_cnn)-1)\n        return final_depth*final_width_height","813c4258":"#Testing Discriminator\nd = Discriminator(im_chan=3,conv_dim=128,image_size=64)\n# print(d)\nimg = torch.rand(4,3,128,128)\nd_op = d(img)\nassert d_op.shape == (4,1),\"Discrimenator Output Images shape incorrect\"\nprint(\"Discrimenator test passed!!\")","ecfe95b5":"def weights_init_normal(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n    if isinstance(m, nn.BatchNorm2d):\n        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n        torch.nn.init.constant_(m.bias, 0)","b34da8fd":"def real_loss(D_out,device='cpu'):\n    criterion = nn.BCEWithLogitsLoss()\n    batch_size = D_out.size(0)\n    labels = torch.ones(batch_size,device=device)*0.9 # real labels = 1 and lable smoothing => 0.9\n    \n    loss = criterion(D_out.squeeze(),labels)\n    return loss\n\ndef fake_loss(D_out,device='cpu'):\n    criterion = nn.BCEWithLogitsLoss()\n    batch_size = D_out.size(0)\n    labels = torch.zeros(batch_size,device=device) # fake labels = 0\n    \n    loss = criterion(D_out.squeeze(),labels)\n    return loss","88357003":"def print_tensor_images(images_tensor):\n    plt.rcParams['figure.figsize'] = (15, 15)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    \n    images_tensor = images_tensor.to('cpu')\n    npimgs = images_tensor.detach().numpy()\n    \n    no_plots = len(images_tensor)\n\n    for idx,image in enumerate(npimgs):\n        plt.subplot(1, 8, idx+1)\n        plt.axis('off')\n        #dnorm\n        image = image * 0.5 + 0.5\n        plt.imshow(np.transpose(image, (1, 2, 0)))\n    plt.show()\n\ndef train(D, G, n_epochs,dataloader,d_optimizer,g_optimizer,z_dim,print_every=50,device='cpu'):\n    \n    ## Get some fixed data for sampling.##      \n    sample_size=8\n    fixed_z = Generator.get_noise(n_samples=sample_size,z_dim=z_dim,device=device)\n    \n    for epoch in range(1,n_epochs+1):\n        for batch_i,(real_images,_) in enumerate(dataloader):\n            batch_size = real_images.size(0)\n            real_images = real_images.to(device)\n            \n            ### Discriminator part ###\n            d_optimizer.zero_grad()\n            \n            #loss on real image\n            d_real_op = D(real_images)\n            d_real_loss = real_loss(d_real_op,device=device)\n            \n            #loss on fake image\n            noise = Generator.get_noise(n_samples=batch_size,z_dim=z_dim,device=device)\n            fake_images = G(noise)\n            d_fake_op = D(fake_images)\n            d_fake_loss = fake_loss(d_fake_op,device=device)\n            \n            #total loss\n            d_loss = d_real_loss + d_fake_loss\n            d_loss.backward()\n            d_optimizer.step()\n            \n            ### Generator part ###\n            g_optimizer.zero_grad()\n            noise = Generator.get_noise(n_samples=batch_size,z_dim=z_dim,device=device)\n            g_out = G(noise)\n            d_out = D(g_out)\n            \n            g_loss = real_loss(d_out,device=device)\n            g_loss.backward()\n            g_optimizer.step()\n        \n        \n        print('Epoch [{:5d}\/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n                    epoch, n_epochs, d_loss.item(), g_loss.item()))\n        if (epoch % print_every == 0):\n            G.eval()\n            sample_image = G(fixed_z)\n            print_tensor_images(sample_image)\n            G.train()\n        ","85cf82f2":"import torch.optim as optim","e5113de9":"# heperparams\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device is \",device)\n\nz_dim = 150\nbeta_1 = 0.5\nbeta_2 = 0.999 \n\nn_epochs = 150\nlr = 0.0002\n\nbatch_size = 128\nimage_size = 128","26f387f0":"# model init\ngen = Generator(z_dim,in_chan=3,hidden_dim=64).to(device)\ndisc = Discriminator(im_chan=3,conv_dim=64,image_size=image_size).to(device)\n\n\n# optimizer init\ng_optimizer = optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\nd_optimizer = optim.Adam(disc.parameters(), lr=lr, betas=(beta_1, beta_2))\n\ndataloader = get_dataloader(batch_size,image_size,image_root)","5095d229":"n_epochs = 100\ntrain(\n    disc,gen,\n    n_epochs,dataloader,\n    d_optimizer,g_optimizer,\n    z_dim,\n    print_every=10,\n    device=device,\n)","f7cb0e64":"def save_model(gen,file_name):\n    gen = gen.to('cpu')\n    torch.save(gen.state_dict(),\"gen_128_epoch_350.pth\")\n\nsave_model(gen,\"kaggle\")","f8b1f0e7":"#sample generation\ngen.to(device)\ngen.eval()\nsample_size=8\nfor i in range(5):\n    fixed_z = Generator.get_noise(n_samples=sample_size,z_dim=z_dim,device=device)    \n    sample_image = gen(fixed_z)\n    print_tensor_images(sample_image)","2731f705":"## 4) Defining Loss","19c8554c":"## 2) Torch DataLoader and Image Preprocessing","0e61597b":"# Pytorch DCGAN Art Generation\n### The notebook is used to train a simple DCGAN model and extended further to build an NFT platform on Ethereum blockchain. Full project is in github [here](https:\/\/github.com\/MdTeach\/crypto_art)","8fd1d427":"Initalizing the weights of the network as mentioned in [**DCGAN paper**](https:\/\/arxiv.org\/pdf\/1511.06434.pdf).<br> Having all weights initialized from a zero-centered Normal distribution with standard deviation 0.02.","3296464e":"## 6) Model & Optimizer Init and Trining","07682232":"## 1) Sample Images Plots","e1e65dc7":"## 7) Train Function","7a2deca9":"## 3) Building Model"}}