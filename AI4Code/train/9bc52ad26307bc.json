{"cell_type":{"f6a9b783":"code","2cdd44d4":"code","b7b89518":"code","df39e647":"code","62576596":"code","b9dc19b5":"code","cdaf0373":"code","e89cb8d4":"code","8fdaa76e":"code","2e451d82":"code","a167af0f":"code","e636d987":"code","072d56b3":"code","34b06dd8":"code","d91290f0":"code","dcb1dfe4":"code","053790ed":"code","a2fac2b3":"code","3356b98b":"code","a7d91819":"code","097ea172":"code","1318560a":"code","3c338a5d":"code","6197b262":"code","768b071b":"code","e339dc78":"code","9eecc110":"code","7c150f47":"code","11a469e0":"code","21d2fa63":"code","f32a7b7f":"code","d7f65a5a":"code","e0af0231":"code","5e2f343f":"code","b9082162":"code","d52b68aa":"code","9875241b":"code","8c61b54d":"markdown"},"source":{"f6a9b783":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2cdd44d4":"df = pd.read_csv('..\/input\/melbourne-housing-snapshot\/melb_data.csv')","b7b89518":"df.info() \ndf.describe()","df39e647":"# show correlation via sea born\nplt.figure(figsize=(20,20))\nsns.heatmap(df.corr('spearman'), annot = True)","62576596":"df.corrwith(df['Price'], axis = 0, method = 'spearman')","b9dc19b5":"#positive Correlation between BuildingArea and price\nq_low = df[\"BuildingArea\"].quantile(0.01)\nq_hi  = df[\"BuildingArea\"].quantile(0.99)\n\ndf = df[(df[\"BuildingArea\"] < q_hi) & (df[\"BuildingArea\"] > q_low)]\nplt.scatter(df['BuildingArea'], df['Price'])","cdaf0373":"#positive Correlation between nmb. of rooms and the price\nq_low = df[\"Rooms\"].quantile(0.01)\nq_hi  = df[\"Rooms\"].quantile(0.99)\ndf = df[(df[\"Rooms\"] <= q_hi) & (df[\"Rooms\"] >= q_low)]\nsns.boxplot(data = df, x='Rooms', y='Price')","e89cb8d4":"df['Rooms'].value_counts()","8fdaa76e":"#positive Correlation between nmb of bathrooms and the price\nq_low = df[\"Bathroom\"].quantile(0.01)\nq_hi  = df[\"Bathroom\"].quantile(0.99)\ndf = df[(df[\"Bathroom\"] <= q_hi) & (df[\"Bathroom\"] >= q_low)]\nsns.boxplot(data = df, x='Bathroom', y='Price')","2e451d82":"df['Bathroom'].value_counts()","a167af0f":"#positive Correlation between Landsize and the price\nq_low = df[\"Landsize\"].quantile(0.05)\nq_hi  = df[\"Landsize\"].quantile(0.95)\ndf = df[(df[\"Landsize\"] < q_hi) & (df[\"Landsize\"] > q_low)]\nplt.scatter(df['Landsize'], df['Price'])","e636d987":"#check relation between price and method\nsns.boxplot(data = df, x='Method', y='Price')\n# Method seems to have no influence on price -> can be dropped","072d56b3":"#check relation between price and type \nsns.boxplot(data = df, x = 'Type', y = 'Price')\n#Type seems to have a little influence on price","34b06dd8":"#check relation between price and Regionname\nplt.figure(figsize=(50,10))\nsns.boxplot(data = df, x = 'Regionname', y = 'Price')\n#region seems to influence price","d91290f0":"#check relation between certain council area (and given Region) and Price\nplt.figure(figsize=(50,10))\nsns.boxplot(data = df.loc[df['Regionname'] == 'Southern Metropolitan'], x = 'CouncilArea', y = 'Price')","dcb1dfe4":"df['CouncilArea'].unique()","053790ed":"plt.figure(figsize=(50,10))\nsns.boxplot(data = df.loc[df['CouncilArea'] == 'Hume'], x = 'Suburb', y = 'Price')\n#keep suburb","a2fac2b3":"plt.scatter(df['Propertycount'], df['Price'])","3356b98b":"plt.figure(figsize=(60,10))\ndf['temp'] = pd.cut(df['Propertycount'], 10)\nsns.boxplot(data = df, x = 'temp', y='Price')\n# PropertyCount relativley unimportant","a7d91819":"df = df.drop(['Propertycount', 'Postcode', 'Distance', 'Method', 'Address', 'Bedroom2', 'Date','YearBuilt', 'Lattitude','Longtitude'], axis = 1)","097ea172":"df.isnull().sum()","1318560a":"from sklearn.preprocessing import LabelEncoder, MinMaxScaler\nencoder = LabelEncoder()\nscaler = MinMaxScaler()\ndf['encoded_suburb'] = encoder.fit_transform(df['Suburb'])\ndf['scaled_price'] = scaler.fit_transform(df[['Price']])\nsubs = df['encoded_suburb']\nsc_price = df['scaled_price']\nn_suburb = df['encoded_suburb'].value_counts().count()","3c338a5d":"# high dimensinal data -> try embedded learning to A) drop Council and Region and B) to reduce dimenisonality of Suburb\nembedding_size = min(np.ceil((df['encoded_suburb'].value_counts().count())\/2), 10)\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, Flatten\n\nmodel = Sequential()\nmodel.add(Embedding(input_dim=n_suburb,output_dim=embedding_size, input_length=1, name=\"sub_embedding\"))\nmodel.add(Flatten())\nmodel.add(Dense(30, activation=\"relu\"))\nmodel.add(Dense(15, activation=\"relu\"))\nmodel.add(Dense(1, activation=\"linear\"))","6197b262":"model.compile(optimizer='Adam', loss='mse')\nmodel.fit(x=subs.values, y=sc_price.values, epochs=60)","768b071b":"embedding_layer = model.get_layer(name=\"sub_embedding\")\nembedding_layer = pd.DataFrame(embedding_layer.get_weights()[0])\n#embedding_layer.columns = ['C1','C2','C3']","e339dc78":"#import matplotlib.pyplot as plt\n#from mpl_toolkits.mplot3d import axes3d, Axes3D\n#sub_names = list(encoder.inverse_transform([x for x in range(0,n_suburb)]))\n#xs = embedding_layer['C1']\n#ys = embedding_layer['C2']\n#zs = embedding_layer['C3']\n#fig = plt.figure(figsize=(8, 4))\n#ax = fig.add_subplot(111, projection='3d')\n#for index, embedding in embedding_layer.iterrows():\n#    x = embedding['C1']\n#    y = embedding['C2']\n#    z = embedding['C3']\n#    ax.scatter(x, y, z, color='b')\n#    #ax.text(x, y, z, '%s' % (subs[index]), size=293, zorder=1, color='k')\n#plt.draw()","9eecc110":"X = df\ny = df['Price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=46)","7c150f47":"#Create class features of price and landsize\nX_train['ls_class'] = pd.qcut(X_train['Landsize'], 10, labels = [1,2,3,4,5,6,7,8,9,10], duplicates ='drop').astype(float)\nX_train['pr_class'] = pd.qcut(X_train['Price'], 10, labels = [1,2,3,4,5,6,7,8,9,10]).astype(float)\nX_test['ls_class'] = pd.qcut(X_test['Landsize'], 10, labels = [1,2,3,4,5,6,7,8,9,10], duplicates ='drop').astype(float)\nX_test['pr_class'] = pd.qcut(X_test['Price'], 10, labels = [1,2,3,4,5,6,7,8,9,10]).astype(float)\n\n#create median df \nmedian_train = X_train.groupby(['ls_class', 'pr_class']).median().reset_index()\nmedian_test = X_test.groupby(['ls_class', 'pr_class']).median().reset_index()","11a469e0":"#fill Building Area \ndef fill_ba(row, dataset):\n    if np.isnan(row['BuildingArea']): \n        condition = ((dataset[\"pr_class\"] == row[\"pr_class\"]) &\n                (dataset[\"ls_class\"] == row[\"ls_class\"]))\n        return dataset[condition]['BuildingArea'].values[0]\n    else: \n        return row[\"BuildingArea\"]\n\nX_train['BuildingArea'] = df.apply(lambda row: fill_ba(row,median_train), axis = 1)\nX_test['BuildingArea'] = df.apply(lambda row: fill_ba(row, median_test), axis = 1)","21d2fa63":"def fill_car(row, dataset):\n    if np.isnan(row['Car']): \n        condition = ((dataset[\"pr_class\"] == row[\"pr_class\"]) &\n                (dataset[\"ls_class\"] == row[\"ls_class\"]))\n        return dataset[condition]['Car'].values[0]\n    else: \n        return row[\"Car\"]\n\nX_train['Car'] = df.apply(lambda row: fill_ba(row,median_train), axis = 1)\nX_test['Car'] = df.apply(lambda row: fill_ba(row, median_test), axis = 1)","f32a7b7f":"df.isnull().sum()","d7f65a5a":"# do both for train and test \nsub_names = list(encoder.inverse_transform([x for x in range(0,n_suburb)]))\ndef append_vector(row): \n    index = sub_names.index(row['Suburb'])\n    df_temp = embedding_layer.iloc[[0]]\n    my_series = df_temp.squeeze()\n    return (row.append(my_series))\n\nX_train = X_train.apply(lambda row: append_vector(row), axis = 1)\nX_test = X_test.apply(lambda row: append_vector(row), axis = 1)","e0af0231":"X_train = X_train.drop(['CouncilArea', 'Suburb', 'Regionname', 'temp', 'encoded_suburb', 'scaled_price', 'SellerG', 'ls_class', 'pr_class','Type'], axis = 1)\nX_test = X_test.drop(['CouncilArea', 'Suburb', 'Regionname', 'temp', 'encoded_suburb', 'scaled_price', 'SellerG', 'ls_class', 'pr_class', 'Type'], axis = 1)","5e2f343f":"#scale train and test\nX_train['Rooms'] = scaler.fit_transform(X_train[['Rooms']])\nX_train['Price'] = scaler.fit_transform(X_train[['Price']])\nX_train['Bathroom'] = scaler.fit_transform(X_train[['Bathroom']])\nX_train['Landsize'] = scaler.fit_transform(X_train[['Landsize']])\nX_train['Car'] = scaler.fit_transform(X_train[['Car']])\nX_train['BuildingArea'] = scaler.fit_transform(X_train[['BuildingArea']])\ny_train = X_train['Price']\nX_train = X_train.drop(['Price'], axis = 1)\n\nX_test['Rooms'] = scaler.fit_transform(X_test[['Rooms']])\nX_test['Price'] = scaler.fit_transform(X_test[['Price']])\nX_test['Bathroom'] = scaler.fit_transform(X_test[['Bathroom']])\nX_test['Landsize'] = scaler.fit_transform(X_test[['Landsize']])\nX_test['Car'] = scaler.fit_transform(X_test[['Car']])\nX_test['BuildingArea'] = scaler.fit_transform(X_test[['BuildingArea']])\ny_test = X_test['Price']\nX_test = X_test.drop(['Price'], axis = 1)","b9082162":"X_train.info()","d52b68aa":"# Random Forest \nfrom sklearn.ensemble import RandomForestRegressor\n# Instantiate model with 1000 decision trees\nrf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n# Train the model on training data\nrf.fit(X_train, y_train)\n# Use the forest's predict method on the test data\ny_pred = rf.predict(X_test)\nfrom sklearn.metrics import mean_absolute_error\nmean_absolute_error(y_test, y_pred)","9875241b":"#Knn\nfrom sklearn.neighbors import KNeighborsRegressor\nknn = KNeighborsRegressor(n_neighbors=5) \nknn.fit(X_train, y_train) \ny_pred = knn.predict(X_test)\nmean_absolute_error(y_test, y_pred)","8c61b54d":"## Your suggestions\/comments are highly appreicated.Please upvote if you like it :)!"}}