{"cell_type":{"38a55d76":"code","a63ac13c":"code","174989e3":"code","dbe00dcb":"code","44afb216":"code","faa35b0e":"code","d15a9d3a":"code","210cfe03":"code","8cd37799":"code","0b8ce01c":"code","85202870":"code","466d6c06":"code","efd99f5e":"code","073db016":"code","c9916086":"code","4efd1a04":"code","acb9c988":"code","8e283713":"code","5a38030a":"code","c6fd8749":"code","a1e4ff83":"code","4c33cc39":"code","9c93bede":"code","70c1d098":"code","3cf046f0":"code","93c9071c":"code","a0c47cc9":"code","3608173f":"code","87a90177":"code","25e0185c":"code","87b43b24":"code","824da0e2":"code","bd20ef60":"code","a09e1e2a":"code","e69d907f":"code","be36f427":"code","62f278c4":"code","9f7e51d6":"code","f13d692c":"code","61ee3da9":"code","fd40ec80":"code","cb487363":"code","546fa7a8":"code","8f74ad15":"code","0f53e3ef":"code","fe93c7d1":"code","d189757e":"code","06005a58":"code","db6bfa36":"code","2a7e549b":"code","4d83d4b9":"code","7259331c":"code","2885b24e":"code","0a44c797":"code","a2d07980":"code","5cc28622":"code","faa0b1b6":"markdown","d1013def":"markdown","1184f964":"markdown","35b655fa":"markdown","54ffa7c5":"markdown","42d03c5e":"markdown","e7ed507b":"markdown","9cfbc080":"markdown","a23230fc":"markdown","be95eb08":"markdown","3af95f6b":"markdown","85a3190d":"markdown","c61512b1":"markdown","984c7a07":"markdown","f3d1bd63":"markdown","d09baa03":"markdown","d118137c":"markdown","6f369d04":"markdown","76544a6f":"markdown","f04cf4df":"markdown","4bf02e55":"markdown","2398af9b":"markdown","7e8c2513":"markdown","c402d903":"markdown","8a09bbac":"markdown","99a3eb61":"markdown","0e3116e1":"markdown","9e77ee31":"markdown","a27e16c6":"markdown","3b6dede2":"markdown","3be06691":"markdown","dc826b39":"markdown","80b759a5":"markdown","8c7588c3":"markdown","1d30428b":"markdown","0437526d":"markdown","d9f0e668":"markdown","791e5937":"markdown","b258424e":"markdown","18665f58":"markdown","42a8c8ce":"markdown","ce2558b1":"markdown","2a64f0e5":"markdown","94e4fd11":"markdown"},"source":{"38a55d76":"# NumPy, Pandas & Visualiza\u00e7\u00e3o de Dados\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\n\n# Scikit-Learn Metrics, Split and Validation\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold, cross_validate, RandomizedSearchCV, GridSearchCV, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, confusion_matrix, recall_score, plot_confusion_matrix, f1_score, precision_score, accuracy_score, roc_curve, auc\n\n# Scikit-Learn & XGBoost Algorithms \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\n# XAI\nimport shap\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nfrom pdpbox import pdp, get_dataset, info_plots\n\n\nplt.style.use('seaborn-colorblind')\n\n!pip install openpyxl","a63ac13c":"path = \"\/kaggle\/input\/covid19\/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx\"\n\nraw_df = pd.read_excel(path)\nraw_df.head()","174989e3":"def colunas_correlacionadas(dataset, threshold = 0.95):\n    \n  '''   \n  Retorna um dataframe com 3 colunas, sendo \n  duas delas o nome de colunas do dataframe de entrada e a \n  terceira o n\u00edvel de correla\u00e7\u00e3o entre elas. S\u00f3 ser\u00e3o retornadas\n  colunas com correla\u00e7\u00e3o pearson com o valor m\u00ednimo definido no threshold\n  \n  Cr\u00e9dito: Matt Harrison @Machine Learning Pocket Reference\n  '''\n\n  df = dataset[dataset.describe().columns]  \n  return (\n      df.corr().pipe(lambda df1: pd.DataFrame(np.tril(df1,k=-1),\n                                              columns = df.columns,\n                                              index = df.columns,\n                                              )\n      )\n      .stack()\n      .rename(\"pearson\")\n      .pipe(\n          lambda s: s[s.abs() >threshold].reset_index()\n      )\n      .query(\"level_0 not in level_1\")\n    )","dbe00dcb":"def makebio_df(df_in):\n    \n    '''\n    Retorna um dataframe com as features consideradas pelos autores\n    do dataset como biologicamente importantes\n    '''\n    \n    df = df_in.copy()\n\n    df[\"BLOODPRESSURE_ARTERIAL_MEAN\"] = (df.loc[:,'BLOODPRESSURE_SISTOLIC_MEAN'] + 2*df.loc[:,'BLOODPRESSURE_DIASTOLIC_MEAN'])\/3\n \n    df[\"NEUTROPHILES\/LINFOCITOS\"] = df.loc[:,'NEUTROPHILES_MEAN']\/df.loc[:,'LINFOCITOS_MEAN']\n\n    df[\"GASO\"] = df.groupby(\"PATIENT_VISIT_IDENTIFIER\").P02_ARTERIAL_MEAN.apply(lambda x: x.fillna(method='ffill'))\n    df[\"GASO\"] = (~df.loc[:,\"GASO\"].isna()).astype(int)\n\n    return df[[\"ICU_ANYTIME\",\n               \"AGE_ABOVE65\", \n               \"GENDER\", \n               \"BLOODPRESSURE_ARTERIAL_MEAN\", \n               \"RESPIRATORY_RATE_MAX\", \n               \"HTN\",\n               'P02_ARTERIAL_MEAN',\n               'DISEASE GROUPING 1',\n               'DISEASE GROUPING 2',\n               'DISEASE GROUPING 3',\n               'DISEASE GROUPING 4',\n               'DISEASE GROUPING 5',\n               'DISEASE GROUPING 6',\n               \"GASO\",\n               \"OXYGEN_SATURATION_MIN\",\n               \"HEART_RATE_MAX\",\n               \"PCR_MEAN\",\n               \"CREATININ_MEAN\"]]\n\n","44afb216":"def avaliacao(model, X_test, y_test, X_train = None, y_train = None, train_aval = False, plot = False, cria_df = False):\n    \n    '''\n    Calcula algumas medidas de score - Acur\u00e1cia, Precis\u00e3o, Recall e ROC(AUC).\n    Se plot for definido como True, plota esses scores e uma matriz de \n    confus\u00e3o para avalia\u00e7\u00e3o do modelo. Se cria_df for definido como True, retorna\n    um dataframe com os resultados (para a fun\u00e7\u00e3o exec_modelagem)\n    '''\n    if train_aval:\n        # TRAIN SCORES\n\n        tn, fp, fn, tp = confusion_matrix(y_train, model.predict(X_train)).ravel()\n\n        # Calcula os scores\n        roc_auc = roc_auc_score(y_train, model.predict_proba(X_train)[:,1])\n        recall = recall_score(y_train, model.predict(X_train))\n        especificidade = tn\/(tn+fn)\n        f_score = f1_score(y_train, model.predict(X_train))\n        precisao = precision_score(y_train, model.predict(X_train))\n        acuracia = accuracy_score(y_train, model.predict(X_train))\n\n        # Printa os scores\n        if plot:\n            print(\"TRAIN SET SCORES\")\n            print(f\"ROC (AUC): {roc_auc}\")\n            print(f\"Sensibilidade - Recall: {recall}\")\n            print(f\"Especificidade: {especificidade}\")\n            print(f\"F1-score: {f_score}\")\n            print(f\"Precis\u00e3o: {precisao}\")\n            print(f\"Acur\u00e1cia: {acuracia}\")\n            print(\"\\n\")\n            print(\"================================\")\n    \n    \n    # TEST SCORES\n    \n    tn, fp, fn, tp = confusion_matrix(y_test, model.predict(X_test)).ravel()\n    \n    # Calcula os scores\n    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n    recall = recall_score(y_test, model.predict(X_test))\n    especificidade = tn\/(tn+fn)\n    f_score = f1_score(y_test, model.predict(X_test))\n    precisao = precision_score(y_test, model.predict(X_test))\n    acuracia = accuracy_score(y_test, model.predict(X_test))\n    \n    # Printa os scores e plota a matriz\n    if plot:\n        print(\"TEST SET SCORES\")\n        print(f\"ROC (AUC): {roc_auc}\")\n        print(f\"Sensibilidade - Recall: {recall}\")\n        print(f\"Especificidade: {especificidade}\")\n        print(f\"F1-score: {f_score}\")\n        print(f\"Precis\u00e3o: {precisao}\")\n        print(f\"Acur\u00e1cia: {acuracia}\")\n        \n        plot_confusion_matrix(estimator = model, X = X_test, y_true = y_test)\n    \n    # Retorna uma row com os scores\n    if cria_df:\n        d = {\n            'ROC (AUC)': [roc_auc],  \n            'Sensibilidade - Recall': [recall],\n            'Especificidade': [especificidade],\n            'F1-score': [f_score],\n            'Precis\u00e3o': [precisao],\n            'Acur\u00e1cia': [acuracia]\n        }\n        return(pd.DataFrame(d))\n    \n    else:\n        return None\n        ","faa35b0e":"def exec_modelagem(df, model, n_iter = 50, resumo = False, **params):\n    \n    '''\n    Para evitar a aleatoriedade dos modelos (Aula 3 - @Bootcamp), ele ser\u00e1 rodado\n    n_iter vezes utilizando o mesmo stratify (mas com random_state vari\u00e1vel).\n    Retorna um dataframe com os resultados - usando a funcao avaliacao() - de cada\n    itera\u00e7\u00e3o. Se resumo for definido como True, printa a m\u00e9dia dos scores.\n    '''\n    # Cria o df para armazenamento dos scores\n    col = {\n            'ROC (AUC)': [],  \n            'Sensibilidade - Recall': [],\n            'Especificidade': [],\n            'F1-score': [],\n            'Precis\u00e3o': [],\n            'Acur\u00e1cia': []\n        }\n    df_scores = pd.DataFrame(col)\n    \n    # Roda o modelo n_iter vezes, avalia utilizando a fun\u00e7\u00e3o `avalicao()` e armazena os resultados \n    for i in range(n_iter):\n        X_train, X_test, y_train, y_test = train_test_split(df.drop('ICU', axis = 1), df['ICU'], test_size=0.25, stratify=df['ICU'], random_state=i)\n        \n        if model == LogisticRegression:\n            model_ = model(max_iter=2000, random_state = i).fit(X_train, y_train)\n            \n        elif model == XGBClassifier:\n            model_ = model(**params, eval_metric = 'error', use_label_encoder=False, random_state=i).fit(X_train, y_train)\n            \n        else:\n            model_ = model(**params, random_state = i).fit(X_train, y_train)\n\n            \n        current_result = avaliacao(model_, X_test, y_test, cria_df = True, train_aval = False)\n        df_scores = df_scores.append(current_result)\n        \n    if resumo:\n        return df_scores.median()\n    \n    else:\n        return df_scores.reset_index()","d15a9d3a":"def kfold_cross_validation(X, y, k=10):\n    \n    # Cria o df para armazenamento dos scores\n    col = {\n            'model':[],\n            'ROC (AUC) MEDIANA': [],\n            'ROC (AUC) STD': [],\n            'Sensibilidade - Recall MEDIANA': [],\n            'Sensibilidade - Recall STD': [],\n            'F1-score MEDIANA': [],\n            'F1-score STD': [],\n            }\n    df_scores = pd.DataFrame(col)\n\n    for model in [DecisionTreeClassifier, KNeighborsClassifier, GaussianNB, SVC, RandomForestClassifier, XGBClassifier]:\n\n\n        # Instanciar o 10-fold usando cross_validate c\/ 3 scores\n\n        # Evitar warning no XGBC\n        if model == XGBClassifier:\n            cls = model(eval_metric = 'error', use_label_encoder=False, random_state=42)\n            kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n            scores = cross_validate(cls, X, y, scoring=['roc_auc','recall','f1'], cv=kfold)\n\n        elif model in [KNeighborsClassifier, GaussianNB]:\n            cls = model()\n            kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n            scores = cross_validate(cls, X, y, scoring=['roc_auc','recall','f1'], cv=kfold)\n            \n        else:\n            cls = model(random_state=42)\n            kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n            scores = cross_validate(cls, X, y, scoring=['roc_auc','recall','f1'], cv=kfold)\n            \n        # Armazenar os scores\n        scores = {\n                'model': f'{model.__name__:22}',\n                'ROC (AUC) MEDIANA': f\"{np.median(scores['test_roc_auc']):.3f}\",\n                'ROC (AUC) STD': f\"{scores['test_roc_auc'].std():.2f}\",\n                'Sensibilidade - Recall MEDIANA': f\"{np.median(scores['test_recall']):.3f}\",\n                'Sensibilidade - Recall STD': f\"{scores['test_recall'].std():.2f}\",\n                'F1-score MEDIANA': f\"{np.median(scores['test_f1']):.3f}\",\n                'F1-score STD': f\"{scores['test_f1'].std():.2f}\",\n                }\n        df_scores = df_scores.append(scores, ignore_index=True)\n\n\n    return df_scores","210cfe03":"def plot_grid_search_params(grid_search_model):\n    '''\n    Essa fun\u00e7\u00e3o usa o plotly para plotar um mapa 2D dos resultados da\n    autoparametriza\u00e7\u00e3o do GridSearchCV() - dessa forma facilitando a \n    visualiza\u00e7\u00e3o de outros poss\u00edveis par\u00e2metros bons\n    \n    Credit: Data Professor at \n    https:\/\/github.com\/dataprofessor\/code\/blob\/master\/python\/hyperparameter_tuning.ipynb\n    '''\n    \n    # Exportar os resultados e dropar a coluna Random State\n    grid_results = pd.concat([pd.DataFrame(grid_search_model.cv_results_[\"params\"]),\n                              pd.DataFrame(grid_search_model.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)\n    \n    # Segmentar os dados em grupos dos dois hyperparametros\n    # Ap\u00f3s, pivorar os dados feature_1 x feature_2\n    grid_contour = grid_results.groupby(['max_features','max_depth']).mean()\n    grid_reset = grid_contour.reset_index()\n    grid_reset.columns = ['max_features', 'max_depth', 'Accuracy']\n    grid_pivot = grid_reset.pivot('max_features', 'max_depth')\n    \n    # Separar os dados pivotados para o plot\n    x = grid_pivot.columns.levels[1].values\n    y = grid_pivot.index.values\n    z = grid_pivot.values\n\n    # Cria\u00e7\u00e3o do Plot\n    layout = go.Layout(\n                xaxis=go.layout.XAxis(\n                  title=go.layout.xaxis.Title(\n                  text='max_depth')\n                 ),\n                 yaxis=go.layout.YAxis(\n                  title=go.layout.yaxis.Title(\n                  text='max_features') \n                ) )\n\n    fig = go.Figure(data = [go.Contour(z=z, x=x, y=y)], layout=layout )\n\n    fig.update_layout(title='Hyperparameter tuning', autosize=False,\n                      width=500, height=500,\n                      margin=dict(l=65, r=50, b=65, t=90))\n\n    fig.show()","8cd37799":"def plot_feature_importance(model):\n    ax, fig = plt.subplots(figsize=(25,18))\n    n_features = X_train.shape[1]\n    plt.barh(range(n_features), model.feature_importances_, align='center')\n    plt.yticks(np.arange(n_features), X_train.columns)\n    plt.xlabel(\"Feature importance\")\n    plt.ylabel(\"Feature\")\n","0b8ce01c":"print(f\"O dataset possui {raw_df.shape[0]} linhas e {raw_df.shape[1]} colunas,\")\nprint(f\"com dados de {raw_df['PATIENT_VISIT_IDENTIFIER'].nunique()} pacientes diferentes.\")","85202870":"fig, ax = plt.subplots(figsize=(8,6))\n\nsns.countplot(data=raw_df, x='ICU', ax=ax);","466d6c06":"raw_df.isna().any().value_counts()","efd99f5e":"# De acordo com os autores do dataset, utilizei o m\u00e9todo de bfill\/ffill\n\n# Identificando as colunas que possuem NaNs\ncolunas_com_nan = raw_df.isna().sum()[raw_df.isna().sum() != 0].index.tolist()\n\n# Utilizando o fillna para preencher os valores NaN nas colunas que os possuem; \ndf_sem_nan = raw_df.copy()\n\ndf_sem_nan[colunas_com_nan] = df_sem_nan.groupby(\"PATIENT_VISIT_IDENTIFIER\", as_index = False)[colunas_com_nan].fillna(method='bfill')\ndf_sem_nan[colunas_com_nan] = df_sem_nan.groupby(\"PATIENT_VISIT_IDENTIFIER\", as_index = False)[colunas_com_nan].fillna(method='ffill')\n\ndf_sem_nan[colunas_com_nan].sample(10)","073db016":"# Checando n\u00famero de linhas que restaram com NaN no dataset\n\ndf_sem_nan.isnull().sum().max()","c9916086":"# Identificando as linhas que ainda possuem NaN\n\ndf_sem_nan[df_sem_nan.isnull().any(axis=1)]","4efd1a04":"df_sem_nan.dropna(inplace=True)\n\ndf_sem_nan.isna().any().value_counts()","acb9c988":"df_sem_nan.dtypes[df_sem_nan.dtypes == 'object']","8e283713":"# Countplot comparando a quantidade de pacientes do dataset que acabaram indo para a UTI em algum momento da visita\n\nfig, ax = plt.subplots(figsize=(8,6))\nsns.countplot(data = df_sem_nan.groupby('PATIENT_VISIT_IDENTIFIER').agg({'ICU': max}), x='ICU', ax=ax);","5a38030a":"# Vamos agrupar os pacientes pelo uso da UTI e identificar algumas caracter\u00edsticas\ncolunas_de_interesse = ['PATIENT_VISIT_IDENTIFIER', 'AGE_ABOVE65','AGE_PERCENTIL','GENDER','IMMUNOCOMPROMISED','RESPIRATORY_RATE_MEDIAN','DISEASE GROUPING 1',\n                        'DISEASE GROUPING 2','DISEASE GROUPING 3','DISEASE GROUPING 4','DISEASE GROUPING 5','DISEASE GROUPING 6']\n\n\n# Para realizar os comparativos, utilizarei os primeiros dados ap\u00f3s a entrada da UTI para os pacientes ICU == 1\npacientes_uti = df_sem_nan[df_sem_nan['ICU'] == 1][colunas_de_interesse]\\\n                .drop_duplicates(subset = 'PATIENT_VISIT_IDENTIFIER', keep = 'first')\n\nlista_id_pacientes_uti = pacientes_uti['PATIENT_VISIT_IDENTIFIER'].tolist()\n\n\n# E de entrada no hospital para os pacientes ICU == 0\npacientes_nao_uti = df_sem_nan.query(\"PATIENT_VISIT_IDENTIFIER not in @lista_id_pacientes_uti\")[colunas_de_interesse]\\\n                    .drop_duplicates(subset = 'PATIENT_VISIT_IDENTIFIER', keep = 'first')\n\npacientes_uti.sample(10)","c6fd8749":"pacientes_nao_uti.sample(10)","a1e4ff83":"fig, axs = plt.subplots(2, sharex=True, sharey=True)\n\nsns.boxplot(data = pacientes_uti, x = 'RESPIRATORY_RATE_MEDIAN', ax = axs[0], color='b');\nsns.boxplot(data = pacientes_nao_uti, x = 'RESPIRATORY_RATE_MEDIAN', ax = axs[1], color = 'g');\n\naxs[0].set_title('Dentro da UTI')\naxs[0].set_xlabel('')\naxs[1].title.set_text('Fora da UTI')","4c33cc39":"fig, axs = plt.subplots(2, sharex=True, sharey=True, squeeze = True)\n\nordem = ['10th', '20th','30th','40th','50th','60th','70th','80th','90th','Above 90th']\n\nsns.countplot(data=pacientes_uti, x='AGE_PERCENTIL', ax=axs[0], order=ordem, color = 'b');\nsns.countplot(data=pacientes_nao_uti, x='AGE_PERCENTIL', ax=axs[1], order=ordem, color = 'g');\n\naxs[0].set_title('Dentro da UTI')\naxs[0].set_xlabel('')\naxs[1].title.set_text('Fora da UTI')","9c93bede":"colunas_binarias = [\n 'AGE_ABOVE65',\n 'GENDER',\n 'IMMUNOCOMPROMISED',\n 'DISEASE GROUPING 1',\n 'DISEASE GROUPING 2',\n 'DISEASE GROUPING 3',\n 'DISEASE GROUPING 4',\n 'DISEASE GROUPING 5',\n 'DISEASE GROUPING 6']\n\nfor col in colunas_binarias:\n    fig, axs = plt.subplots(1, 2, sharex=True, sharey=True, squeeze = True)\n\n    sns.countplot(data=pacientes_uti, x=col, ax=axs[0], color = 'b');\n    sns.countplot(data=pacientes_nao_uti, x=col, ax=axs[1], color = 'g');\n    \n    \n    plt.title(f'Distribui\u00e7\u00e3o na {col}')\n    \n    axs[0].set_title('Dentro da UTI')\n    axs[0].set_xlabel('')\n    axs[1].title.set_text('Fora da UTI')","70c1d098":"pd.set_option(\"display.max_rows\", None)\ncolunas_correlacionadas(df_sem_nan)","3cf046f0":"# Para retirar os pacientes que entraram na UTI, utilizei um query em que a Window era 0-2 e o ICU igual a 1;\n\npacientes_a_remover = df_sem_nan.query(\"WINDOW == '0-2' & ICU == 1\")[\"PATIENT_VISIT_IDENTIFIER\"]\ndf_processado = df_sem_nan.query(\"PATIENT_VISIT_IDENTIFIER not in @pacientes_a_remover\")","93c9071c":"# Checando se a retirada dos pacientes foi correta\n\npd.crosstab(df_processado['WINDOW'], df_processado['ICU'])","a0c47cc9":"# Pacientes que foram pra UTI depois da janela de 2 hrs\npaciente_uti = df_processado.groupby('PATIENT_VISIT_IDENTIFIER').agg({'ICU': max}).rename(columns={'ICU': 'ICU_ANYTIME'})\npaciente_uti\n    \n# Adicionando a coluna criada acima no df\ndf_processado = df_processado.merge(paciente_uti, on=['PATIENT_VISIT_IDENTIFIER'], how = 'right')\n\n# Mantendo apenas os dados de pacientes entre [0-2]\ndf_processado = df_processado[df_processado['WINDOW'] == '0-2']","3608173f":"df_bio =  makebio_df(df_processado)\n\ndf_bio.sample(10)","87a90177":"# Remover coluna com apenas 1 valor\n\nprint(df_bio['GASO'].nunique())\ndf_bio.drop('GASO', axis = 1, inplace = True)","25e0185c":"# Apagando colunas ICU(antiga), WINDOW e PATIENT_VISIT_IDENTIFIER\n\ndf_processado.drop('ICU', axis=1, inplace=True)\ndf_processado.drop('WINDOW', axis=1, inplace=True)\ndf_processado.drop('PATIENT_VISIT_IDENTIFIER', axis=1, inplace=True)\n\n\n# Transformando GENDER e AGE_ABOVE65 em strings para serem processados pelo get_dummies()\ndf_processado['GENDER'] = df_processado['GENDER'].astype(str)\ndf_processado['AGE_ABOVE65'] = df_processado['AGE_ABOVE65'].astype(str)\ndf_processado = pd.get_dummies(df_processado, columns=['GENDER','AGE_PERCENTIL','AGE_ABOVE65'], prefix=['GENDER','AGE_PERCENTIL','AGE_ABOVE65'])\n\n# Recriando a coluna ICU com os valores novos e dropando a c\u00f3pia\nfor df in [df_processado, df_bio]:\n    df['ICU'] = df['ICU_ANYTIME']\n    df.drop('ICU_ANYTIME', axis=1, inplace=True)","87b43b24":"df_modelo = df_processado.copy()\n\n# Criar lista com colunas que possuem valor constante\ncolunas_const = list(df_modelo.columns[df_modelo.nunique() == 1])\n\n# Dropar do dataset que vai ser usado na modelagem\nfor col in colunas_const:\n    df_modelo.drop(col, axis=1, inplace=True, errors='ignore')","824da0e2":"# Criarei um df_modelo_mediana onde utilizarei apenas a mediana das medi\u00e7\u00f5es\ndf_modelo_mediana = df_modelo.copy()\n\nfor col in df_modelo_mediana.columns:\n    if any(x in col for x in ['_MAX', '_MIN', '_MEAN']):\n            df_modelo_mediana.drop(col, axis=1, inplace=True, errors='ignore')","bd20ef60":"# Remover as colunas com alta correla\u00e7\u00e3o\n\nfor col in colunas_correlacionadas(df_modelo, threshold = 0.90)[\"level_1\"]:\n    df_modelo.drop(col, axis=1, inplace=True, errors='ignore')","a09e1e2a":"pd.set_option(\"display.max_rows\", None)\ncolunas_correlacionadas(df_modelo_mediana, threshold = 0.90)","e69d907f":"sns.countplot(data=df_modelo, x='ICU');\n\ndf_modelo['ICU'].value_counts()","be36f427":"variaveis_continuas = list(df_modelo_mediana.iloc[:, 9:-15].columns)\n\nfor col in variaveis_continuas:\n    fig, axs = plt.subplots(2, sharex=True, sharey=True)\n\n    sns.boxplot(data = df_modelo_mediana[df_modelo['ICU'] == 1], x = col, ax = axs[0], color = 'b');\n    sns.boxplot(data = df_modelo_mediana[df_modelo['ICU'] == 0], x = col, ax = axs[1], color = 'g');\n\n    axs[0].set_title('Dentro da UTI')\n    axs[0].set_xlabel('')\n    axs[1].title.set_text('Fora da UTI')","62f278c4":"features_dist_identicas = ['BE_VENOUS_MEDIAN', 'CALCIUM_MEDIAN', 'HEMOGLOBIN_MEDIAN', 'P02_VENOUS_MEDIAN', 'SAT02_VENOUS_MEDIAN', 'HEART_RATE_MEDIAN']\n\nfeatures_proximas_c_outliers_expressivos = ['ALBUMIN_MEDIAN','BE_ARTERIAL_MEDIAN','BIC_ARTERIAL_MEDIAN','BIC_VENOUS_MEDIAN',\n'BILLIRUBIN_MEDIAN','BLAST_MEDIAN','FFA_MEDIAN','GGT_MEDIAN','CREATININ_MEDIAN', 'P02_ARTERIAL_MEDIAN','PC02_ARTERIAL_MEDIAN',\n'PH_ARTERIAL_MEDIAN','SAT02_ARTERIAL_MEDIAN','TGO_MEDIAN','TGP_MEDIAN','TTPA_MEDIAN','DIMER_MEDIAN','OXYGEN_SATURATION_MEDIAN',\n'BLOODPRESSURE_DIASTOLIC_DIFF','BLOODPRESSURE_SISTOLIC_DIFF','HEART_RATE_DIFF','RESPIRATORY_RATE_DIFF','TEMPERATURE_DIFF',\n'OXYGEN_SATURATION_DIFF','BLOODPRESSURE_DIASTOLIC_DIFF_REL','BLOODPRESSURE_SISTOLIC_DIFF_REL','HEART_RATE_DIFF_REL',\n'RESPIRATORY_RATE_DIFF_REL','TEMPERATURE_DIFF_REL','OXYGEN_SATURATION_DIFF_REL']\n\nfeatuers_dist_diferentes = ['GLUCOSE_MEDIAN','HEMATOCRITE_MEDIAN','INR_MEDIAN','LACTATE_MEDIAN',\n'LEUKOCYTES_MEDIAN','LINFOCITOS_MEDIAN','NEUTROPHILES_MEDIAN','PC02_VENOUS_MEDIAN',\n'PCR_MEDIAN','PH_VENOUS_MEDIAN','PLATELETS_MEDIAN','POTASSIUM_MEDIAN','SODIUM_MEDIAN','UREA_MEDIAN',\n'BLOODPRESSURE_DIASTOLIC_MEDIAN','BLOODPRESSURE_SISTOLIC_MEDIAN','RESPIRATORY_RATE_MEDIAN','TEMPERATURE_MEDIAN']","9f7e51d6":"dfs = [('DF CORR CORTADA',df_modelo),('DF MEDIANA',df_modelo_mediana),('DF BIO',df_bio)]\n\nfor df in dfs:\n    print(f\"==== SCORE {df[0]} =====\")\n    lr_scores = exec_modelagem(df[1], LogisticRegression, n_iter = 50, resumo = True)\n    display(lr_scores)","f13d692c":"for df in dfs:\n    X = df[1].drop('ICU', axis=1)\n    y = df[1]['ICU']\n    print(f\"==== SCORE {df[0]} =====\")\n    display(kfold_cross_validation(X,y))","61ee3da9":"for df in dfs:\n    print(f\"==== SCORE {df[0]} RANDOM FOREST DEFAULT =====\")\n    display(exec_modelagem(df[1], RandomForestClassifier, n_iter = 50, resumo = True))","fd40ec80":"# Dataset 2 sem as features que possu\u00edam distribui\u00e7\u00f5es iguais entre pacientes dentro e fora da UTI\ndf_modelo_mediana_corte = df_modelo_mediana.drop(features_dist_identicas, axis = 1)\n\n# Dataset 2 apenas com as features que possu\u00edam distribui\u00e7\u00f5es expressivamente diferentes entre pacientes dentro e fora da UTI\ndf_modelo_mediana_apenas_dif = df_modelo_mediana_corte.drop(features_proximas_c_outliers_expressivos, axis = 1)\n\ndfs_de_testes = [('TESTE 1 - elimina features c\/ distribui\u00e7\u00f5es iguais entre pacientes de ambas labels',df_modelo_mediana_corte),\n                 ('TESTE 2 - Mant\u00e9m features c\/ distribui\u00e7\u00f5es expressivamente diferentes entre os pacientes',df_modelo_mediana_apenas_dif)]","cb487363":"for df in dfs_de_testes:\n    print(f\"==== SCORE {df[0]} - RANDOM FOREST DEFAULT =====\")\n    display(exec_modelagem(df[1], RandomForestClassifier, n_iter = 50, resumo = True))","546fa7a8":"X = df_modelo_mediana_corte.drop('ICU', axis = 1)\ny = df_modelo_mediana_corte['ICU']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42, stratify = y)\n\n\nparam_grid = {'max_depth': [i for i in range(1,20)],\n               'max_features':[i for i in range(1,12)]}\n\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\nrf_model_GS = RandomForestClassifier(random_state = 42)\n\ngs_grid = GridSearchCV(rf_model_GS, param_grid, scoring='f1', cv = 5, verbose=1, n_jobs = -1)\ngs_grid.fit(X_train, y_train)\n\n\nprint(gs_grid.best_params_)","8f74ad15":"plot_grid_search_params(gs_grid)","0f53e3ef":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0, stratify = y)\n\nrf_model_grid_search_best_params = RandomForestClassifier(random_state = 0, n_estimators = 1000, **gs_grid.best_params_).fit(X_train, y_train)\n\nprint(\"RandomForest Otimizado utilizando GridSearch\\n\\n\")\navaliacao(rf_model_grid_search_best_params, X_test, y_test, X_train, y_train, train_aval = True, plot=True)","fe93c7d1":"# Primeiro set de par\u00e2metros - RF_GS_F1 - DF_MODELO_MEDIANA\n\nX = df_modelo_mediana.drop('ICU', axis = 1)\ny = df_modelo_mediana['ICU']\n\nbest_params = {'bootstrap': True,\n 'max_depth': 20,\n 'max_features': 6,\n 'min_samples_leaf': 3,\n 'min_samples_split': 3,\n 'n_estimators': 1000,\n 'random_state': 0}\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0, stratify = y)\n\nrf_gs_mediana_model = RandomForestClassifier(**best_params).fit(X_train, y_train)\navaliacao(rf_gs_mediana_model, X_test, y_test, X_train, y_train, train_aval = True, plot=True)","d189757e":"# Segundo set de par\u00e2metros - RF_GS_F1 - DF_MODELO_MEDIANA_CORTE\n\nX = df_modelo_mediana_corte.drop('ICU', axis = 1)\ny = df_modelo_mediana_corte['ICU']\n\nbest_params = {'bootstrap': True,\n 'max_depth': 20,\n 'max_features': 11,\n 'min_samples_leaf': 1,\n 'min_samples_split': 5,\n 'n_estimators': 1000,\n 'random_state': 0}\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0, stratify = y)\n\nrf_gs_corte_model = RandomForestClassifier(**best_params).fit(X_train, y_train)\navaliacao(rf_gs_corte_model, X_test, y_test, X_train, y_train, train_aval = True, plot=True)","06005a58":"# Terceiro set de par\u00e2metros - RF_GS_F1 - DF_BIO\n\nX = df_bio.drop('ICU', axis = 1)\ny = df_bio['ICU']\n\nbest_params = {'bootstrap': True,\n 'max_depth': 20,\n 'max_features': 4,\n 'min_samples_leaf': 1,\n 'min_samples_split': 5,\n 'n_estimators': 1000,\n 'random_state': 0}\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0, stratify = y)\n\nrf_gs_bio_model = RandomForestClassifier(**best_params).fit(X_train, y_train)\navaliacao(rf_gs_bio_model, X_test, y_test, X_train, y_train, train_aval = True, plot=True)","db6bfa36":"X = df_modelo_mediana_corte.drop('ICU', axis = 1)\ny = df_modelo_mediana_corte['ICU']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0, stratify = y)\n\nplot_feature_importance(rf_gs_corte_model)","2a7e549b":"# Criar o explainer e calcular os valores shap de todo o modelo\nexplainer = shap.TreeExplainer(rf_gs_corte_model)\nshap_values = explainer.shap_values(X_train)\n\n# Plot os valores SHAP para indiv\u00edduos que n\u00e3o foram pra UTI\nshap.summary_plot(shap_values[0], X_train)","4d83d4b9":"# Plot os valores SHAP para pacientes que precisaram da UTI\nshap.summary_plot(shap_values[1], X_train)","7259331c":"perm = PermutationImportance(rf_gs_corte_model, scoring = 'recall', random_state=42).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist(), top=10)","2885b24e":"# Procura pelos erros do modelo no set de valida\u00e7\u00e3o\n\nfor i in range(len(X_test)):\n    data_for_prediction = X_test.iloc[i]\n    data_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n    \n    prob_arr = rf_gs_corte_model.predict_proba(data_for_prediction_array)\n    pred = np.argmax(rf_gs_corte_model.predict_proba(data_for_prediction_array))\n    \n    if pred != y_test.iloc[i]:\n        print(f\"\\nPrevis\u00e3o {pred} ||| Probabilidades -  ICU == 0: {prob_arr[0][0]} \\t ICU == 1: {prob_arr[0][1]}\")\n        print(f\"Valor V: {y_test.iloc[i]} ||| Index no test_set {i}\\n\")\n","0a44c797":"# Observando a tomada de decis\u00e3o do modelo para um dos erros mais de perto\n\nshap_values = explainer.shap_values(X_test.iloc[79])\n\nshap.initjs()\nshap.force_plot(explainer.expected_value[1], shap_values[1], X_test.iloc[79])","a2d07980":"# Criando o objeto\npdp_linfocitos = pdp.pdp_isolate(model= rf_gs_corte_model, dataset= X_test, model_features= X_test.columns.tolist(), feature='LINFOCITOS_MEDIAN')\n\n# Plotando\npdp.pdp_plot(pdp_linfocitos, 'LINFOCITOS_MEDIAN')\nplt.show()","5cc28622":"pdp_age_above65 = pdp.pdp_isolate(model= rf_gs_corte_model, dataset= X_test, model_features= X_test.columns.tolist(), feature='AGE_ABOVE65_0')\n\npdp.pdp_plot(pdp_age_above65, 'Paciente menor que 65 anos')\nplt.show()","faa0b1b6":"Utilizando o RandomForest, os melhores resultados de acordo com as m\u00e9tricas utilizaram o `df_modelo_mediana_corte` e o GridSearch para tunar. No modelo mais otimizado, 14 pacientes de 88 foram classificados de forma errada, sendo 7 **Falso-Negativos** e 7 **Falso-Positivos**. \n\nMelhor **Score Geral**:\n\n|    RF c\/ GS Tunning - df_modelo_mediana_corte    \t|  SCORES  \t|\n|:----------------------:\t|:--------:\t|\n|        ROC (AUC)       \t| 0.851582 \t|\n| Sensibilidade - Recall \t| 0.829268 \t|\n|     Especificidade     \t| 0.851063 \t|\n|        F1-score        \t| 0.829268 \t|\n|        Precis\u00e3o        \t| 0.829268 \t|\n|        Acur\u00e1cia        \t| 0.840909 \t|\n\n\n| RF c\/ GS Tunning - df_modelo_mediana_corte |  MEDIANA SCORES |   STD   |\n|:--------------------------------------------------------:|:-------:|:-------:|\n|                         ROC (AUC)                        | 0.79424 | 0.03438 |\n|                  Sensibilidade - Recall                  | 0.70732 | 0.07316 |\n|                      Especificidade                      | 0.74464 | 0.04241 |\n|                         F1-score                         | 0.70737 | 0.04166 |\n|                         Precis\u00e3o                         | 0.70711 | 0.03999 |\n|                         Acur\u00e1cia                         | 0.72727 | 0.00321 |\n\n<br>\n\nApesar de que modelos RandomForest (e outros ensembles de tree decision) podem ser afetados por **overfitting**, o alto n\u00famero de \u00e1rvores foi o que causou os scores de treino serem t\u00e3o elevados e isso n\u00e3o afetou o score de valida\u00e7\u00e3o.\n","d1013def":"2. Organizar o dataset para o uso na cria\u00e7\u00e3o do modelo\n\n2.1 Adicionar uma coluna marcando que o **paciente foi parar na UTI em algum momento**;\n\n> Problem: Early identification of those patients who will develop an adverse course of illness (and need intensive care) is a key for an appropriate treatment (saving lives) and to managing beds and resources.\n\n> Tips & Tricks: Whereas a predictive model using all time windows will probably yield a greater accuracy, a nice model using only the first (0-2) is likely to be more clinically relevant. The creativity is very welcome though, please feel free with feature engineering and time windows. Attention to repeated measures on individuals once these values are (positively) correlated when playing around with data.\n\nOs autores do dataset mostraram interesse em um **modelo treinado usando apenas os dados de pacientes coletados janela entre [0-2] horas**.\nAl\u00e9m disso, tamb\u00e9m deixaram claro que a coluna janela (caso fossem usados os dados de pacientes em outras janelas, o que aqui n\u00e3o ser\u00e1 o caso) e as linhas em pacientes est\u00e3o internados n\u00e3o deveriam ser usada no treinamento do modelo.\n\n2.2 Retirar dados coletados a partir de `WINDOW` = 0-2.","1184f964":"### Resultados\n\n\nMelhor **Score Geral**:\n\n**ROC (AUC)**:             \t     0.851582 \t\n**Sensibilidade**: \t 0.829268 \t\n**Especificidade**:     \t     0.851063 \t\n**F1-score**:       \t     0.829268 \t\n**Precis\u00e3o**:       \t     0.829268 \t\n**Acur\u00e1cia**:        \t     0.840909 \n\n\n**Mediana de 50 itera\u00e7\u00f5es** do modelo acima, utilizando **random_state vari\u00e1vel**:\n\n| RF c\/ GS Tunning - df_modelo_mediana_corte |  MEDIANA SCORES |   STD   |\n|:--------------------------------------------------------:|:-------:|:-------:|\n|                         ROC (AUC)                        | 0.79424 | 0.03438 |\n|                  Sensibilidade - Recall                  | 0.70732 | 0.07316 |\n|                      Especificidade                      | 0.74464 | 0.04241 |\n|                         F1-score                         | 0.70737 | 0.04166 |\n|                         Precis\u00e3o                         | 0.70711 | 0.03999 |\n|                         Acur\u00e1cia                         | 0.72727 | 0.00321 |\n\n","35b655fa":"Cada ponto do summary_plot \u00e9 uma vari\u00e1vel do nosso dataset. Sua posi\u00e7\u00e3o **vertical** indica qual o **nome da feature**, sua **cor** indica o **valor da vari\u00e1vel** (em rela\u00e7\u00e3o com as outras vari\u00e1veis da mesma feature) e sua posi\u00e7\u00e3o **horizontal indica** o quanto aquela vari\u00e1vel **impactou o modelo**, al\u00e9m do sentido do impacto.\n\nNo primeiro plot, est\u00e3o as features dos pacientes que o modelo preveu que n\u00e3o precisariam da UTI e no segundo, os pacientes que o modelo preveu que seriam admitidos. Vale lembrar tamb\u00e9m que todos os valores foram pr\u00e9-escalonados e normalizados, logo um \"alto valor na feature RESPIRATORY_RATE_MEDIAN\" n\u00e3o tem o mesmo significado direto que uma frequ\u00eancia respirat\u00f3ria alta.\n\nEm pacientes que o modelo classificou que seria necess\u00e1rio a UTI: \n* Altos valores nas features `RESPIRATORY_RATE_MEDIAN`, `PCR_MEDIAN`, `UREA_MEDIAN`, `CREATININ_MEDIAN` tiveram import\u00e2ncia alta para a tomada da decis\u00e3o.\n* Valores baixos em features como `LINFOCITOS_MEDIAN`, `OXYGEN_SATURATION_MEDIAN` e `BLOODPRESSURE_DIASTOLIC_MEDIAN` tamb\u00e9m levaram o modelo \u00e0 definir a label como 1.\n* Assim como hav\u00edamos observado na EDA, o modelo tamb\u00e9m considera o paciente ser maior de 65 anos como uma feature importante.\n\nJ\u00e1 para a previs\u00e3o que o paciente n\u00e3o entraria na UTI, podemos observar que n\u00e3o houve **nenhuma feature com o valor SHAP muito alto**, diferente da label contr\u00e1ria. A maioria das vari\u00e1veis, para a previs\u00e3o `ICU == 0`, possui valor SHAP positivo entre 0 e 0.05. Isso explica o fato do desvio padr\u00e3o do `recall` ter sido mais alto que o dos outros scores. \n\nO PermutationImportance, algoritmo que randomiza valores de apenas uma feature no dataset para verificar a diferen\u00e7a que isso causaria nos resultados do modelo e, dessa forma, calcular a import\u00e2ncia de dada feature, mostra resultados parecidos ao SHAP.","54ffa7c5":"\u00c9 poss\u00edvel verificar uma diferen\u00e7a na **frequ\u00eancia respirat\u00f3ria** de pacientes que acabaram sendo encaminhados pra UTI (**valores medianos em uma distribui\u00e7\u00e3o espalhada**) quando comparados com aqueles que **n\u00e3o foram (que possuem os valores em uma distribui\u00e7\u00e3o mais achatada)**.","42d03c5e":"Para observar as distribui\u00e7\u00f5es das v\u00e1riaveis cont\u00ednuas, utilizei o dataset em que foram cortados as features _MIN, _MAX e _MEAN por possuir maior n\u00famero de v\u00e1riaveis. Al\u00e9m disso, a tabela de correla\u00e7\u00f5es mostra que o comportamento das features cortadas \u00e9 quase id\u00eantico ao daquelas que sobraram. \n\nA minha leiguisse, combinada com a pr\u00e9-normaliza\u00e7\u00e3o dos valores das v\u00e1riaveis, n\u00e3o me permite entender o que cada um dos plots significa cientificamente. Ainda assim, d\u00e1 pra perceber diferen\u00e7as na maioria das features quando comparamos as distribui\u00e7\u00f5es de valores entre as pessoas que acabaram precisando da UTI com aquelas que n\u00e3o. As features que tiveram a maior diferen\u00e7a entre as ditribui\u00e7\u00f5es foram:\n* LACTATE_MEDIAN\n* LEUKOCYTES_MEDIAN\n* LINFOCITOS_MEDIAN\n* PCR_MEDIAN\n* PLATELETS_MEDIAN\n* POTASSIUM_MEDIAN\n* SODIUM_MEDIAN\n* RESPIRATORY_RATE_MEDIAN\n\nAlgumas features, entretanto, obtiveram distribui\u00e7\u00f5es quase id\u00eanticas entre os grupos de pacientes:\n* BE_VENOUS_MEDIAN\n* CALCIUM_MEDIAN\n* HEMOGLOBIN_MEDIAN\n* P02_VENOUS_MEDIAN\n* SAT02_VENOUS_MEDIAN\n* HEART_RATE_MEDIAN","e7ed507b":"O modelo preveu, com 76% de probabilidade, que esse paciente n\u00e3o precisaria da UTI. Olhando o gr\u00e1fico acima podemos verificar os motivos que o modelo levou em considera\u00e7\u00e3o para realizar a previs\u00e3o:\n* Paciente na faixa et\u00e1ria do d\u00e9cimo percentil;\n* Mediana do s\u00f3dio, linf\u00f3citos e ur\u00e9ia naquela janela de tempo;\n* etc.\n\nPara entender ainda melhor o significado de uma feature pro modelo - supondo que o usu\u00e1rio final quisesse visualizar melhor como os valores de `LINFOCITOS_MEDIAN` afetam o modelo (e essa previs\u00e3o, em espec\u00edfico) com maior precis\u00e3o - pode-se usar partial plots:\n\n* No Y, a dire\u00e7\u00e3o que o modelo \u00e9 afetado\n* No X, os valores da feature","9cfbc080":"Existem **225** colunas no dataset (aproximadamente 97%) que possuem valores NaN. \n\nOs autores do dataset comentaram sobre a exist\u00eancia de valores NaN no set de dados e indicaram o melhor caminho para resolver o problema:\n\n> **Missing data**\n**Problem**: One of the major challenges of working with health care data is that the sampling rate varies across different type of measurements. For instance, vital signs are sampled more frequently (usually hourly) than blood labs (usually daily).\n\n> **Tips & Tricks**: It is reasonable to assume that a patient who does not have a measurement recorded in a time window **is clinically stable**, potentially presenting vital signs and blood labs similar to neighboring windows. Therefore, **one may fill the missing values using the next or previous entry**. Attention to multicollinearity and zero variance issues in this data when choosing your algorithm.","a23230fc":"Entre os 383 pacientes, **194 deles foram encaminhados para a UTI** e 189 n\u00e3o. \n\nPodemos considerar uma distribui\u00e7\u00e3o de dados pr\u00f3xima o suficiente para elaborar algumas visualiza\u00e7\u00f5es comparativas entre os grupos de pacientes.","be95eb08":"### 10-Fold Cross-Validation\n\nVou utilizar um algoritmo 10-fold cross-validation para verificar qual algoritmo - utilizando hiperparametriza\u00e7\u00e3o padr\u00e3o - desempenhar\u00e1 melhor nos datasets. Utilizei os scores ROC(AUC), Recall e F1 para realizar a compara\u00e7\u00e3o. ","3af95f6b":"### eXplainable AI \n\nUm ponto problem\u00e1tico dos modelos baseados em m\u00faltiplas Decision Trees \u00e9 sua **baixa explicabilidade**. Como um modelo m\u00e9dico, seria interessante demonstrar que features obtiveram maior participa\u00e7\u00e3o nos resultados dos dados. Utilizarei tanto um gr\u00e1fico de barras para verificar a **feature_importance**, que acompanha os algoritmos baseados em Random Forest do scikit-learn. Al\u00e9m disso, utilizarei tamb\u00e9m a **SHAP** para entender ainda melhor.\n<br>\n\nAinda assim, \u00e9 v\u00e1lido o alerta. **A interpretabilidade do modelo n\u00e3o significa causalidade**. Foi apenas a forma que o algoritmo tomou as decis\u00f5es. ","85a3190d":"4. Remover do dataset colunas **baixariam a perfomance** do modelo (**alta correla\u00e7\u00e3o**, **valor constante**).","c61512b1":"A coluna `WINDOW` n\u00e3o ser\u00e1 utilizada para cria\u00e7\u00e3o do modelo, mas a `AGE_PERCENTIL` provavelmente sim.\n<br>\n\nIrei aplicar **one-hot-encoding** nela e em outras vari\u00e1veis categ\u00f3ricas quando for preparar o dataset para ser usado no algoritmo.","984c7a07":"Os scores foram pr\u00f3ximos entre os testes e o teste 1 retornou como mediana de 50 testes os resultados muito similares ao dataset pr\u00e9 corte de features. Imagino que pela distribui\u00e7\u00e3o dessas features serem id\u00eanticas entre ambas as classifica\u00e7\u00f5es, algoritmos n\u00e3o lineares como Random Forests e o XGBoost n\u00e3o tenham sua perfomance afetada. Devido ao menor n\u00famero de features facilitar a explicabilidade do modelo, utilizarei o `df_mediana` ap\u00f3s o teste 1 e o `df_bio` na hiperpar\u00e2metriza\u00e7\u00e3o.\n\n### GridSearch - RandomForest\n\nDe acordo com o livro **Introduction to Machine Learning with Python**, o algoritmo RandomForest \u00e9 relativamente robusto \u00e0 altera\u00e7\u00f5es nos seus hiperparametros, com tr\u00eas deles sendo os mais relevantes para aumento de perfomance: n_estimators, max_features e max_depth. \nA regra para a decis\u00e3o sobre o n_estimator \u00e9 simple: **quando maior, melhor**. No entanto, um n\u00famero alto de \u00e1rvores pode ser custoso em termos de tempo.\n\nOs outros dois utilizarei o GridSearch para o ajuste, uma vez que s\u00e3o poucos e n\u00e3o tomar\u00e1 muito tempo para a otimiza\u00e7\u00e3o.","f3d1bd63":"Vamos adicionar criar um segundo dataset utilizando features recomendadas pelos autores do dataset.","d09baa03":"Em primeiro momento, irei testar a perfomance de um modelo de **Logistic Regression** no primeiro dataset para servir como um **baseline**. Em seguida, vou comparar os resultados do mesmo modelo no segundo dataset, em que apenas as medianas foram utilizadas. \n\nA fun\u00e7\u00e3o utilizada para instanciar e avaliar os modelos itera `50` vezes e retorna a mediana dos scores.","d118137c":"* AGE_ABOVE65 - **Pessoas acima de 65 anos s\u00e3o mais comuns dentro da UTI**, como era esperado pelos resultados do countplot da coluna 'AGE_PERCENTIL'.\n* GENDER - Apesar de pessoas do **g\u00eanero '0'** serem mais comuns em ambos subsets, **elas s\u00e3o ainda mais comuns dentro da UTI**.\n* IMMUNOCOMPROMISED e DISEASE GROUPING i - As **distribui\u00e7\u00f5es s\u00e3o parecidas entre os subsets**, mas \u00e9 v\u00e1lido a observa\u00e7\u00e3o de que **pessoas positivas** (com a exce\u00e7\u00e3o da coluna DISEASE GROUPING 6) s\u00e3o **mais comuns no set de pessoas que foram encaminhadas para a UTI**.","6f369d04":"2.3 One-Hot-encoding na coluna `AGE_PERCENTIL`, a \u00fanica com strings, e `GENDER` e `AGE_ABOVE65`, por serem **categ\u00f3ricas**.<br>\n3. Remover do dataset as colunas que n\u00e3o devem ser usadas no modelo: `WINDOW`,`PACIENT_VISIT_IDENTIFIER`;","76544a6f":"Os resultados foram parecidos, com exce\u00e7\u00e3o do `df_bio`. No entanto, utilizarei como baseline os resultados da segunda execu\u00e7\u00e3o. Devido \u00e0 natureza da task, os scores ROC e sensibilidade s\u00e3o os mais importantes.\n\n| BASELINE LR - DF MEDIANA \t|  SCORES  \t|\n|:----------------------------------:\t|:--------:\t|\n|              ROC (AUC)             \t| 0.768293 \t|\n|       Sensibilidade - Recall       \t| 0.658537 \t|\n|           Especificidade           \t| 0.710591 \t|\n|              F1-score              \t| 0.676056 \t|\n|              Precis\u00e3o              \t| 0.701852 \t|\n|              Acur\u00e1cia              \t| 0.710227 \t|","f04cf4df":"### Metodologia\n\n**Prepara\u00e7\u00e3o dos Dados**: \n* Value imputation usando FFill e BFill;\n* Retirada de colunas com alta correla\u00e7\u00e3o;\n* Feature engineering leve (one-hot-encoding);\n* Retirada das linhas contendo informa\u00e7\u00f5es sobre janelas posteriores \u00e0 entrada.\n\n**Separa\u00e7\u00e3o dos dados**: 75\/25 estratificado.\n\n**Defini\u00e7\u00e3o do Modelo**: Foi utilizado LogisticRegression como baseline e K-Fold para defini\u00e7\u00e3o do melhor modelo.\n\n**Modelo Final**: RandomForest.\n\n**M\u00e9tricas de Avalia\u00e7\u00e3o, em ordem de import\u00e2ncia**: Sensibilidade(recall), ROC(auc), especificidade e F1-score. \n\n**Hiperparametriza\u00e7\u00e3o**: Uso de GridSearchCV em conjunto com inputs manuais.","4bf02e55":"### An\u00e1lise Explorat\u00f3ria dos Dados que ser\u00e3o usados no Modelo","2398af9b":"Infelizmente, devida a natureza dos dados e minha leiguisse na \u00e1rea da sa\u00fade, fica dif\u00edcil tirar insights mais profundos sobre o que os valores significam e poss\u00edveis rela\u00e7\u00f5es entre o significado e os resultados do modelo. Entretanto, isso n\u00e3o me impede de mostrar a visualiza\u00e7\u00e3o que algum usu\u00e1rio final - que tenha conhecimentos da \u00e1rea - teria caso procurasse entender melhor os motivos do algoritmo ter previsto a necessidade (ou a falta dela) de um leito na UTI para o paciente. ","7e8c2513":"### Import dos M\u00f3dulos Utilizados e Input do Dataset","c402d903":"### Fun\u00e7\u00f5es Helpers","8a09bbac":"At\u00e9 o momento, os melhores resultados nos scores foram obtidos utilizando o **RandomForest com hiperpar\u00e2metriza\u00e7\u00e3o encontrada usando o plot do GridSearch no dataset com as features medianas**. Houve uma redu\u00e7\u00e3o significativa no n\u00famero de Falsos Negativos, com apenas 7FN de 41 pacientes positivos. No entanto, 10 dos 47 pacientes que n\u00e3o precisaram da UTI foram classificados erroneamente. \n\nObs.: Note que o `random_state` foi setado para **zero**, tanto como par\u00e2metro do modelo como para o split. Nas outras avalia\u00e7\u00f5es, foi tirado a mediana de 50 itera\u00e7\u00f5es do modelo com random_states diferentes. Devido ao tempo que os testes tomam, realizei-os em um segundo notebook local, assim como os pr\u00f3ximos testes de hiperpar\u00e2metros.  \n\n| Random Forest - HYPER GS - Dataset 2 c\/ Features Cortadas |  SCORES - MEDIANA  |    STD   |\n|:---------------------------------------------------------:|:--------:|:--------:|\n|                         ROC (AUC)                         | 0.797353 | 0.036715 |\n|                   Sensibilidade - Recall                  | 0.682927 | 0.075739 |\n|                       Especificidade                      | 0.735271 | 0.048230 |\n|                          F1-score                         | 0.696667 | 0.053468 |\n|                          Precis\u00e3o                         | 0.708922 | 0.049996 |\n|                          Acur\u00e1cia                         | 0.727273 | 0.043840 |\n\n\n\n|    Random Forest - HYPER GS - Dataset 2 c\/ Features Cortadas    |       SCORES - random_state Definido      |\n|:----------------------:|:------------------:|\n|        ROC (AUC)       | 0.860923 |\n| Sensibilidade - Recall | 0.829268 |\n|     Especificidade     | 0.840909 |\n|        F1-score        | 0.799999 |\n|        Precis\u00e3o        | 0.772727 |\n|        Acur\u00e1cia        | 0.806818 |\n\n<br>\n\nUtilizei o mesmo notebook local para fazer diversos GridSearchs utilizando mais hiperpar\u00e2metros em 3 diferentes datasets:\n* df_modelo_mediana\n* df_modelo_mediana_corte \n* df_bio\n\nForam realizados 3 GridSearchs para cada um dos DataFrames, modificando apenas o score de decis\u00e3o (`average_precision` [RF_GS_AVG_PR], `roc_auc` [RF_GS_ROC_AUC] e `f1`[RF_GS_F1]). Para cada grupo de par\u00e2metros encontrados, utilizei o mesmo procedimento de avalia\u00e7\u00e3o anterior: 50 itera\u00e7\u00f5es com `random_state` diferentes (tanto no modelo, quanto no split), resumindo os resultados utilizando a mediana dos scores obtidos e o desvio padr\u00e3o. \n\nAl\u00e9m disso, adicionei \u00e0 tabela os resultados do RandomForest nos datasets com parametriza\u00e7\u00e3o padr\u00e3o, j\u00e1 calculados nesse notebook. \n\n<br>\n\n<br>\n    \n\n![image.png](attachment:image.png)\n\n<br>\n\nOs melhores resultados obtidos foram marcados em verde. Al\u00e9m da parametriza\u00e7\u00e3o padr\u00e3o, os hiperpar\u00e2metros selecionados pelo GridSearch utilizando como m\u00e9trica o **F1-Score** foram os que se sa\u00edram melhor no m\u00e9todo de avalia\u00e7\u00e3o utilizado.\n\nAbaixo, os resultados dos modelos com o `random_state` definido:","99a3eb61":"### Objetivo\n\nEsse notebook tem como objetivo resolver a **Task 01** desenvolvida pelos autores do dataset (Felipe Oliveira et. al) utilizando os dados aqui disponibilizados.  \n<br>\n\n>Predict admission to the ICU of confirmed COVID-19 cases.\nBased on the data available, is it feasible to predict which patients will need intensive care unit support?\nThe aim is to provide tertiary and quarternary hospitals with the most accurate answer, so ICU resources can be arranged or patient transfer can be scheduled.","0e3116e1":"D\u00e1 pra ver uma diferen\u00e7a expl\u00edcita na distribui\u00e7\u00e3o da idade dos pacientes que necessitaram da UTI para aqueles que n\u00e3o precisaram. Em geral, **quanto mais velho o paciente, maior a chance dele precisar ser internado**. A inversa tamb\u00e9m \u00e9 v\u00e1lida.","9e77ee31":"Utilizando esse plot, podemos testar diversos par\u00e2metros que alcan\u00e7aram scores pr\u00f3ximos.","a27e16c6":"### Processamento dos Dados\n\nEsse dataset foi produzido para uso futuro e, por causa disso, muitos dos dados que est\u00e3o na base n\u00e3o podem ser utilizados na produ\u00e7\u00e3o do modelo.\nFarei a limpeza de acordo com os autores.\n\n* **Retirar** do dataset **pacientes que entraram direto para a UTI**;\n* Organizar o dataset para o uso na cria\u00e7\u00e3o do modelo:\n    * Adicionar uma coluna marcando que o **paciente foi parar na UTI em algum momento**;\n    * Retirar dados coletados a partir de `WINDOW` = 0-2.\n    * Aplicar **One-Hot-Encoding** nas **colunas categ\u00f3ricas** que necessitarem;    \n* Remover do dataset as colunas que n\u00e3o devem ser usadas no modelo: `WINDOW`,`PACIENT_VISIT_IDENTIFIER`;\n* Remover do dataset colunas **baixariam a perfomance** do modelo (**alta correla\u00e7\u00e3o**, **valor constante**).","3b6dede2":"### Testes Cortando o Dataset\n\nDurante o EDA dos datasets que seriam utilizados na modelagem, identifiquei nas features cont\u00ednuas alguns comportamentos diferentes quanto \u00e0s distribui\u00e7\u00f5es ao comparar os pacientes dentro e fora da UTI. Antes de fazer o ajuste dos hiperpar\u00e2metros, irei testar se cortar algumas features do dataset 2 trar\u00e1 benef\u00edcios ao modelo.","3be06691":"### An\u00e1lise Explorat\u00f3ria Inicial dos Dados","dc826b39":"### Definindo o modelo baseline","80b759a5":"\n| RANDOM FOREST DEFAULT - DF MEDIANA \t|  SCORES  \t|\n|:----------------------------------:\t|:--------:\t|\n|              ROC (AUC)             \t| 0.796056 \t|\n|       Sensibilidade - Recall       \t| 0.682927 \t|\n|           Especificidade           \t| 0.737925 \t|\n|              F1-score              \t| 0.705214 \t|\n|              Precis\u00e3o              \t| 0.711111 \t|\n|              Acur\u00e1cia              \t| 0.727273 \t|","8c7588c3":"### Random Forest\n\nInicialmente, instanciarei o RandomForest no dataset com diferentes sele\u00e7\u00f5es de features e com hiperparametriza\u00e7\u00e3o padr\u00e3o. Em seguida, utilizarei o GridSearch para realizar o ajuste dos hiperpar\u00e2metros.","1d30428b":"Ap\u00f3s a limpeza dos dados, o dataset que ser\u00e1 utilizado no modelo possui 189 pacientes que n\u00e3o precisaram da UTI e 162 que precisaram.","0437526d":"Nos 3 datasets, os algoritmos **RandomForest** e o **XGBoost** apresentaram resultados melhores que os outros algoritmos testados. A exce\u00e7\u00e3o fica com o dataset que passou pela fun\u00e7\u00e3o criada pelo time do Sir\u00edo Liban\u00eas, que teve um scores maiores no SVC que no XGBoost.\n<br>\n\nO **RandomForest** performou expressivamente melhor no dataset n\u00famero 2, em que cortamos o manualmente algumas das colunas, no recall e F1. J\u00e1 o XGBoost obteve alguns scores melhores no dataset 1 (ROC e F1) e outro no dataset 2 (sensibilidade).","d9f0e668":"Como s\u00e3o apenas dois pacientes (e um deles com dados faltando), irei dropa-los do DF.","791e5937":"1. Retirar do data set pacientes que entraram direto para a UTI; ","b258424e":"A maioria das vari\u00e1veis do dataset s\u00e3o **quantitativas e cont\u00ednuas**, por serem valores (pr\u00e9-normalizados e escalonados) oriundos de exames.\n<br>\n\nAinda assim, o dataset possui algumas v\u00e1riaveis **categ\u00f3ricas** (como `GENDER`, `AGE_ABOVE65`, `AGE_PERCENTIL`, `DISEASE GROUPING i`, `WINDOW` e `ICU`). Enquanto a maior parte delas j\u00e1 s\u00e3o do tipo integer, ainda existem algumas do string:","18665f58":"Mesmo utilizando um *threshold* alto na fun\u00e7\u00e3o, ela retorna **centenas de colunas** altamente relacionadas entre si.","42a8c8ce":"### **Contexto**\n\nIdentificada pela primeira vez em Dezembro de 2019, na China, a COVID-19 \u00e9 uma doen\u00e7a causada pelo coronavirus que pegou o mundo inteiro de surpresa. Desde o come\u00e7o da pandemia foram discutidas formas de achatar a distribui\u00e7\u00e3o de novos casos, para que os sistemas de sa\u00fade pudessem se preparar e impedir um poss\u00edvel colapso (falta de leitos, recursos humanos e EPIs para atender todos os pacientes). \n<br>\n\n![image.png](attachment:image.png)\n<br>\n\nInfelizmente, o sistema de sa\u00fade brasileiro [colapsou em diversos estados](https:\/\/g1.globo.com\/jornal-nacional\/noticia\/2021\/01\/11\/sistema-de-saude-de-roraima-entra-em-colapso-por-causa-do-coronavirus.ghtml) mais de uma vez e, novamente, o pa\u00eds bate recordes no n\u00famero de mortes e novos casos di\u00e1rios, um ano ap\u00f3s o [primeiro caso de COVID-19 no Brasil](https:\/\/saude.abril.com.br\/medicina\/coronavirus-primeiro-caso-brasil\/).\n\n","ce2558b1":"O Data set possui **1410 linhas poss\u00edvelmente us\u00e1veis** (em que o paciente n\u00e3o foi para a UTI) e **515 linhas n\u00e3o-us\u00e1veis** (em que o paciente j\u00e1 havia sido encaminhado para a UTI).\n\n","2a64f0e5":"A correla\u00e7\u00e3o ser\u00e1 um problema principalmente para modelos **lineares**, como LogisticRegression, que ser\u00e1 usado apenas como baseline. Ainda assim, vou verificar caso tenha sobrado alguma coluna com alta correla\u00e7\u00e3o no modelo em que mantivemos apenas as medianas.","94e4fd11":"O dataset possui diversas v\u00e1riaveis que foram expandidas para **m\u00e9dia, max, min, diff, relative_diff**. \n<br>\n\nPor causa disso, essas vari\u00e1veis podem acabam tendo **valores correlacionados** e a **perfomance** de alguns **algoritmos** de classifica\u00e7\u00e3o (principalmente os lineares) seria **afetada negativamente**. Para confirmar a exist\u00eancia dessas v\u00e1riaveis altamente correlacionadas, utilizarei a fun\u00e7\u00e3o do livro **Machine Learning Pocket Reference**, escrito por *Matt Harrison*, que mostra as colunas correlacionadas dado algum limite m\u00ednimo de **correla\u00e7\u00e3o pearson**."}}