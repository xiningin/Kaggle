{"cell_type":{"a01e4ac8":"code","9ba2ec24":"code","836baf05":"code","09d1824c":"code","e2ff93fe":"code","26d3cf55":"code","c14bc30c":"code","0698d86d":"code","96bff412":"code","b5d1b2f4":"code","36d53866":"code","c52858b7":"code","3c644e61":"code","f18a0aeb":"code","2d8c242a":"markdown","3490df97":"markdown","197ea7ff":"markdown","8b5bd3ac":"markdown","a757c74f":"markdown","ebd11310":"markdown","c78aa654":"markdown","e2735922":"markdown","19fe1364":"markdown","f0168bc6":"markdown","a1a9a9f7":"markdown","03046ce0":"markdown","590b9137":"markdown","f6a94b1e":"markdown","ed5b8ea2":"markdown","30291b70":"markdown","32ddc702":"markdown","bd3e6328":"markdown","c9824687":"markdown","dba8fa6d":"markdown","1497b55f":"markdown","f74ab6c1":"markdown"},"source":{"a01e4ac8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport gc\ngc.enable()\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")","9ba2ec24":"#print(os.listdir(\"..\/input\"))\n!ls -GFlash  ..\/input\/ashrae-energy-prediction","836baf05":"%%time\n# import Dataset to play with it\ntrain_data = pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/train.csv')\nbuilding = pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/building_metadata.csv')\nweather_train = pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/weather_train.csv')\ntrain_data = train_data.merge(building, on='building_id', how='left')\ntrain_data = train_data.merge(weather_train, on=['site_id', 'timestamp'], how='left')\n\ntest_data = pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/test.csv')\nweather_test = pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/weather_test.csv')\ntest_data = test_data.merge(building, on='building_id', how='left')\ntest_data = test_data.merge(weather_test, on=['site_id', 'timestamp'], how='left')\n\nprint (\"Done!\")","09d1824c":"print('Shape of Data:')\nprint(train_data.shape)\nprint(test_data.shape)","e2ff93fe":"del building, weather_train, weather_test","26d3cf55":"train_data.info()","c14bc30c":"test_data.info()","0698d86d":"#Based on this great kernel https:\/\/www.kaggle.com\/arjanso\/reducing-dataframe-memory-size-by-65\ndef reduce_mem_usage(df):\n    start_mem_usg = df.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in df.columns:\n        if df[col].dtype != object:  # Exclude strings            \n            # Print current column type\n            print(\"******************************\")\n            print(\"Column: \",col)\n            print(\"dtype before: \",df[col].dtype)            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = df[col].max()\n            mn = df[col].min()\n            print(\"min for this col: \",mn)\n            print(\"max for this col: \",mx)\n            # Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(df[col]).all(): \n                NAlist.append(col)\n                df[col].fillna(mn-1,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = df[col].fillna(0).astype(np.int64)\n            result = (df[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True            \n            # Make Integer\/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        df[col] = df[col].astype(np.uint8)\n                    elif mx < 65535:\n                        df[col] = df[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        df[col] = df[col].astype(np.uint32)\n                    else:\n                        df[col] = df[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        df[col] = df[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        df[col] = df[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        df[col] = df[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        df[col] = df[col].astype(np.int64)    \n            # Make float datatypes 32 bit\n            else:\n                df[col] = df[col].astype(np.float32)\n            \n            # Print new column type\n            print(\"dtype after: \",df[col].dtype)\n            print(\"******************************\")\n    # Print final result\n    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n    mem_usg = df.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage is: \",mem_usg,\" MB\")\n    print(\"This is \",100*mem_usg\/start_mem_usg,\"% of the initial size\")\n    return df, NAlist","96bff412":"train_data, NAlist = reduce_mem_usage(train_data)\nprint(\"_________________\")\nprint(\"\")\nprint(\"Warning: the following columns have missing values filled with 'df['column_name'].min() -1': \")\nprint(\"_________________\")\nprint(\"\")\nprint(NAlist)","b5d1b2f4":"test_data, NAlist = reduce_mem_usage(test_data)\nprint(\"_________________\")\nprint(\"\")\nprint(\"Warning: the following columns have missing values filled with 'df['column_name'].min() -1': \")\nprint(\"_________________\")\nprint(\"\")\nprint(NAlist)","36d53866":"train_data.info()","c52858b7":"test_data.info()","3c644e61":"#train_data.to_csv('train.csv', index=False)\n#test_data.to_csv('test.csv', index=False)","f18a0aeb":"train_data.to_pickle(\"train_data.pkl\")\nprint(\"train_data size after memory reduction:\", os.stat('train_data.pkl').st_size * 1e-6)\n\n\ntest_data.to_pickle(\"test_data.pkl\")\nprint(\"test_data size after memory reduction:\", os.stat('test_data.pkl').st_size * 1e-6)","2d8c242a":"**What do we have in input**","3490df97":"# Impot","197ea7ff":"# Objective of the Kernel: Save Time & Memory\n\n**If you would like to create a kernel for this Competition. This is a good idea to add this kernel as a data set to your own kernel. due to you can save your time and memory.**","8b5bd3ac":"# Reducing Memory Size for Great Energy Predictor III Competition","a757c74f":"![reduce](https:\/\/1.bp.blogspot.com\/-6XdrSaHdjiw\/XaaY2AUIxoI\/AAAAAAAAGS4\/MfBcvYjBVT0F9OJAkD4V9A7kD2FfFY7mACLcBGAsYHQ\/s1600\/reducing1.jpg)","ebd11310":"# Solution: Save your dataframe as pickle file for fast read.","c78aa654":"**Reducing for train data set:**","e2735922":"**Reducing for test data set:**","19fe1364":"**Then we shoud just delete some dt!**","f0168bc6":"**Now let's check the size of our train & test**","a1a9a9f7":"Thanks to [MJ Bahmani](https:\/\/www.kaggle.com\/mjbahmani) who created this [kernel](https:\/\/www.kaggle.com\/mjbahmani\/reducing-memory-size-for-ieee)\n\nPickle code refers to this kaggle [kernal](https:\/\/www.kaggle.com\/ljjblackpig\/3-steps-to-reduce-memory-size-for-the-dataset)","03046ce0":"**Check again! our RAM. More than 4 GB has got free!**\n![ram2](https:\/\/1.bp.blogspot.com\/-xsHq7cuTlNo\/XaaZOmorLlI\/AAAAAAAAGTE\/6jqT2Mzp6VsQRuUda5Roez7IyM8TRcsMgCLcBGAsYHQ\/s1600\/ram2.PNG)","590b9137":"# Add this kernel as Dataset\n\nNow we just save our output as csv files. then you can simply add them to your own kernel.you will save time and memory. But when I start saving this two files I got an error because there is not much space to save both files. **OSError: [Errno 28] No space left on device**","f6a94b1e":"# Before Reducing Memory\n\n**When I have just read the data set and join them! I saw that the status of my RAM is more than 10GB!**\n![ram1](https:\/\/1.bp.blogspot.com\/-odGlxafFW2s\/XaaZOgQUjQI\/AAAAAAAAGTA\/o6KnYfo4Ya4G0wnaWo0AuclzRQEP3EhSwCLcBGAsYHQ\/s1600\/ram1.PNG)","ed5b8ea2":"**I have used this great kernel but there are also other ways such as:\n**\n1. https:\/\/www.dataquest.io\/blog\/pandas-big-data\/\n2. [optimizing-the-size-of-a-pandas-dataframe-for-low-memory-environment](https:\/\/medium.com\/@vincentteyssier\/optimizing-the-size-of-a-pandas-dataframe-for-low-memory-environment-5f07db3d72e)\n3. [pandas-making-dataframe-smaller-faster](https:\/\/www.ritchieng.com\/pandas-making-dataframe-smaller-faster\/)","30291b70":"**The idea behind the this is based on the fact that most of the column only takes few values and pandas can limit those values only to the few categorical value to save the memory.**\n\n**\"Often in real-time, data includes the text columns, which are repetitive. Features like gender, country, and codes are always repetitive. These are the examples for categorical data.**\n\n**Categorical variables can take on only a limited, and usually fixed number of possible values. Besides the fixed length, categorical data might have an order but cannot perform numerical operation. Categorical are a Pandas data type.**\n\n**The categorical data type is useful in the following cases \u2212**\n\n**A string variable consisting of only a few different values. Converting such a string variable to a categorical variable will save some memory.**\n\n**The lexical order of a variable is not the same as the logical order (\u201cone\u201d, \u201ctwo\u201d, \u201cthree\u201d). By converting to a categorical and specifying an order on the categories, sorting and min\/max will use the logical order instead of the lexical order.**\n\n**As a signal to other python libraries that this column should be treated as a categorical variable (e.g. to use suitable statistical methods or plot types).\" (https:\/\/www.tutorialspoint.com\/python_pandas\/python_pandas_categorical_data)**","32ddc702":"**MEMORY USAGE BEFORE AND AFTER COMPLETION FOR TEST:**\n\nMemory usage before running this script : **5.3+ GB**\n\nMemory usage after running this script: **2.3+ GB**\n\nThis is **~ 60 %** of the initial size","bd3e6328":"**MEMORY USAGE BEFORE AND AFTER COMPLETION FOR TRAIN:**\n\nMemory usage before running this script :** 2.6+ GB**\n\nMemory usage after running this script :  **1.1+ GB**\n\nThis is **~ 60 %** of the initial size","c9824687":"# Reducing Memory Size\n\n**It is necessary that after using this code, carefully check the output results for each column.**","dba8fa6d":"# Import Dataset and creat our train & test dataset","1497b55f":"**Do not Forget to save your work. This way you can access the downcasted df everytime you load it!**","f74ab6c1":"# How about other ways!\n"}}