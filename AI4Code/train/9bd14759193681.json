{"cell_type":{"b081de48":"code","41e7d3be":"code","30ff27b3":"code","e672ca5e":"code","f17008d7":"code","8ae3752d":"code","d8121cae":"code","5f849a3d":"code","befcf806":"code","28c7dbad":"code","981d47ae":"code","ac5d14fb":"code","4b94a899":"code","b18a5396":"code","a1381fd9":"code","d186c522":"code","0afe37de":"markdown","184d8349":"markdown","693ac865":"markdown","fd051497":"markdown","73cebed6":"markdown","20a4cb27":"markdown","f64fd086":"markdown","978a0791":"markdown","32a7ab73":"markdown","bbe2bfc3":"markdown","273324e7":"markdown","548e55bc":"markdown"},"source":{"b081de48":"#Importing the libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom scipy import stats\nfrom scipy.stats import norm\nimport missingno as msno\nwarnings.filterwarnings('ignore')","41e7d3be":"# Importing the data\nraw_data=pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')","30ff27b3":"data=raw_data.copy()\ndata","e672ca5e":"data.info()","f17008d7":"data.describe()","8ae3752d":"msno.bar(data,color='darkred', sort=\"ascending\", figsize=(10,5), fontsize=12)\nplt.show()","d8121cae":"plt.figure(figsize=(10,7),dpi=100)\nsns.pairplot(data=data,hue='Outcome',palette='OrRd')","5f849a3d":"fig=plt.figure(figsize=(10,7))\nbackgroundcolor='#f6f5f7'\nfig.patch.set_facecolor(backgroundcolor)\nsns.heatmap(data=data.corr(),annot=True,cmap='OrRd')","befcf806":"data_output=data['Outcome']\ndata.drop(columns=['Outcome'],inplace=True)\ndata.head()","28c7dbad":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nscaler=StandardScaler()","981d47ae":"x_train,x_test,y_train,y_test= train_test_split(data,data_output,test_size=0.2,random_state=1)","ac5d14fb":"#Scaling the data\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","4b94a899":"def Model(model):\n    model.fit(x_train,y_train)\n    score=model.score(x_test,y_test)\n    prediction=model.predict(x_test)\n    cm = confusion_matrix(y_test,prediction)\n    print('Testing Score \\n',score)\n    plot_confusion_matrix(model,x_test,y_test,cmap='OrRd')\n    metrics.plot_roc_curve(model, x_test, y_test)","b18a5396":"#Logistic regression\nlog_regression=LogisticRegression()\nModel(log_regression)","a1381fd9":"# Decision tree Classifier\nd_tree =  DecisionTreeClassifier()\nModel(d_tree)","d186c522":"#Regression Trees\nreg_tree = RandomForestClassifier()\nModel(reg_tree)","0afe37de":"#### The confusion matrix interpretation:\n1) The first element is True Negative([0,0]) - They are classified as 0 and our model correctly classified them as 0.\n\n2) The second element is False Positive([0,1]) - Their actual value is 0 but our model predicted them as 1.\n\n3) The third element is False Negative([1,0]) - Their actual value is 1 but our model predicted them as 0.\n\n4) The Fourth element is True Positive([1,1]) - Their actual value is 1 and our model predicted them as 1.","184d8349":"### Importing the libraries","693ac865":"#### Will update the kernel after I learn KNN and hyper-parameter tuning. Thank you for your time.\n","fd051497":"### Pairplot","73cebed6":"## Training the models","20a4cb27":"No missing Values in our data.","f64fd086":" BMI and DiabetesPedigree are of the type float. Rest of the data are of the type integer.","978a0791":"#### Observations:\n1) No strong correlation between our features.\n\n2) The strongest correlation is between Pregnancies and Age.","32a7ab73":"### Correlation Matrix ","bbe2bfc3":"We perform feature scaling after splitting the data into training and testing sets in order to avoid data leakage.","273324e7":"4) The Fourth element is True Positive([1,1]) - Their actual value is 1 and our model predicted them as 1.\nForest\nWithout any hyper-parameter tuning, Random Forest algorith predicts the models better than Logistic Regression and Decision Tree Classifier.","548e55bc":"### Missing Values"}}