{"cell_type":{"3ff343be":"code","3c14be07":"code","a604dc7b":"code","de8f5af3":"code","624e73d8":"code","d452c058":"code","879fb1fc":"code","cfc9658e":"code","d8c1b387":"code","e117dd28":"code","c5c756b6":"code","9feaa6cd":"code","ef6a0df0":"code","c97fc493":"code","e6ca2b7d":"code","cef6d584":"code","0da9a7fe":"code","7a7a03b5":"code","eb7d0ef0":"code","f0f5fa25":"code","c52a685d":"code","7cd7f23d":"markdown","621936dd":"markdown","e12917c1":"markdown","3c6127bc":"markdown","9cdb1a23":"markdown","670cea12":"markdown","8d0b1bf6":"markdown"},"source":{"3ff343be":"df=pd.read_csv('\/kaggle\/input\/bank-customers\/Churn Modeling.csv')\ndf.head()","3c14be07":"df.info()","a604dc7b":"df.describe()","de8f5af3":"X=df.iloc[:,3:13]\ny=df.iloc[:,13]","624e73d8":"X.head()","d452c058":"states=pd.get_dummies(X['Geography'],drop_first=True)\ngender=pd.get_dummies(X[\"Gender\"],drop_first=True)","879fb1fc":"X=pd.concat([X,states,gender],axis=1)\nX.head()","cfc9658e":"X=X.drop(['Geography','Gender'],axis=1)","d8c1b387":"\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)","e117dd28":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test=sc.transform(X_test)","c5c756b6":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense","9feaa6cd":"classifier=Sequential()\nclassifier.add(Dense(activation='relu',input_dim=11,units=6,kernel_initializer='uniform'))\nclassifier.add(Dense(activation='relu',units=6,kernel_initializer='uniform'))\nclassifier.add(Dense(activation='sigmoid',units=1,kernel_initializer='uniform'))\nclassifier.summary()","ef6a0df0":"classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","c97fc493":"classifier.fit(X_train,y_train,batch_size=10,nb_epoch=50)","e6ca2b7d":"y_pred=classifier.predict(X_test)","cef6d584":"y_pred=(y_pred>0.5)","0da9a7fe":"y_pred","7a7a03b5":"from sklearn.metrics import confusion_matrix,accuracy_score\ncm=confusion_matrix(y_test,y_pred)\nacc=accuracy_score(y_test,y_pred)","eb7d0ef0":"\nacc","f0f5fa25":"cm","c52a685d":"classifier=Sequential()\nclassifier.add(Dense(activation='relu',input_dim=11,units=6,kernel_initializer='uniform'))\nclassifier.add(Dense(activation='relu',units=6,kernel_initializer='uniform'))\nclassifier.add(Dense(activation='relu',units=9,kernel_initializer='uniform'))\nclassifier.add(Dense(activation='relu',units=6,kernel_initializer='uniform'))\nclassifier.add(Dense(activation='relu',units=6,kernel_initializer='uniform'))\nclassifier.add(Dense(activation='relu',units=6,kernel_initializer='uniform'))\nclassifier.add(Dense(activation='relu',units=6,kernel_initializer='uniform'))\nclassifier.add(Dense(activation='relu',units=6,kernel_initializer='uniform'))\nclassifier.add(Dense(activation='sigmoid',units=1,kernel_initializer='uniform'))\nclassifier.summary()\nclassifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\nclassifier.fit(X_train,y_train,batch_size=10,nb_epoch=30)\ny_pred=classifier.predict(X_test)\ny_pred=(y_pred>0.5)\nacc=accuracy_score(y_test,y_pred)\nacc","7cd7f23d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","621936dd":"**sacling values to put in our data**","e12917c1":"> **IT SEEMS THAT DATA HAD BEEN OVERFITTED . WE CAN USE DROPOUT OR FLATTEN ON OUR NEURAL NET TO AVOIS OVERFITTING......our first model has max accuracy among different models tried by myself**","3c6127bc":"**had claimed an accuracy of 86%**","9cdb1a23":"**creating our ann model**","670cea12":"**creating dummies to remove categorical variables**","8d0b1bf6":"now cahnging our ann futhetr"}}