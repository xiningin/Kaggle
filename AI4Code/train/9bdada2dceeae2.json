{"cell_type":{"e4d9cdad":"code","17b04711":"code","1d32183d":"code","1811d7f6":"code","a4b151b7":"code","eebfcb99":"code","02c16725":"code","40922955":"code","22e08fa2":"code","5709b8b5":"code","e28323d7":"code","1f8959c6":"code","e3949206":"code","7722502a":"code","e5e5ef06":"code","fa3a39e1":"code","50d7a452":"code","a6d205a8":"code","6018b213":"code","8e9b1c98":"code","ee93c749":"markdown","129204e8":"markdown","99ed8ce5":"markdown","8ba1c512":"markdown","b58ca4f3":"markdown","68e9e186":"markdown","388eb635":"markdown","42a4721b":"markdown","186e652a":"markdown","d0c9e342":"markdown","75e90812":"markdown","2b82a13f":"markdown","08621471":"markdown","fc3acc87":"markdown","13fdb416":"markdown"},"source":{"e4d9cdad":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns\nimport warnings\nimport copy\nimport nltk\nimport string\nfrom nltk.corpus import stopwords\nfrom tqdm import tqdm\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom scipy.spatial.distance import pdist, squareform\nwarnings.filterwarnings('ignore')\nroot_path = '..\/input\/'\nprint('The csv files provided are:\\n')\nprint(os.listdir(root_path))","17b04711":"df_emails = pd.read_csv(root_path + 'emails.csv')\ndf_questions = pd.read_csv(root_path + 'questions.csv')\ndf_professionals = pd.read_csv(root_path + 'professionals.csv')\ndf_comments = pd.read_csv(root_path + 'comments.csv')\ndf_tag_users = pd.read_csv(root_path + 'tag_users.csv')\ndf_group_memberships = pd.read_csv(root_path + 'group_memberships.csv')\ndf_tags = pd.read_csv(root_path + 'tags.csv')\ndf_answer_scores = pd.read_csv(root_path + 'answer_scores.csv')\ndf_students = pd.read_csv(root_path + 'students.csv')\ndf_groups = pd.read_csv(root_path + 'groups.csv')\ndf_tag_questions = pd.read_csv(root_path + 'tag_questions.csv')\ndf_question_scores = pd.read_csv(root_path + 'question_scores.csv')\ndf_matches = pd.read_csv(root_path + 'matches.csv')\ndf_answers = pd.read_csv(root_path + 'answers.csv')\ndf_school_memberships = pd.read_csv(root_path + 'school_memberships.csv')","1d32183d":"df_tag_users_merged = pd.merge(df_tag_users, df_tags, left_on='tag_users_tag_id', right_on='tags_tag_id', how='inner')\n#To see the tags that are linked with every question\nthresh = 0.0025\ndf_tag_questions_merged = pd.merge(df_tag_questions, df_tags, left_on='tag_questions_tag_id', right_on='tags_tag_id', how='inner')\nuser_tags = list((df_tag_users_merged['tags_tag_name'].value_counts()\/df_tag_users_merged['tag_users_user_id'].nunique() \n                     > thresh).index[(df_tag_users_merged['tags_tag_name'].value_counts()\/df_tag_users_merged['tag_users_user_id'].nunique() > thresh)])\nquestion_tags = list((df_tag_questions_merged['tags_tag_name'].value_counts()\/df_tag_questions_merged['tag_questions_question_id'].nunique() \n                     > thresh).index[(df_tag_questions_merged['tags_tag_name'].value_counts()\/df_tag_questions_merged['tag_questions_question_id'].nunique() > thresh)])\nrelevant_tags = set(user_tags).union(set(question_tags))","1811d7f6":"print('The number of relevant tags:', len(relevant_tags))\nprint('Coverage of tagged questions:', df_tag_questions_merged[df_tag_questions_merged['tags_tag_name'].isin(\nrelevant_tags)]['tag_questions_question_id'].nunique()\/df_tag_questions_merged['tag_questions_question_id'].nunique())\nprint('Coverage of tagged users:', df_tag_users_merged[df_tag_users_merged['tags_tag_name'].isin(\nrelevant_tags)]['tag_users_user_id'].nunique()\/df_tag_users_merged['tag_users_user_id'].nunique())","a4b151b7":"def return_if_found(df, column, string):\n    return(df[df[column].str.contains(string)][column].unique())\narray_computer = return_if_found(df_tag_users_merged, 'tags_tag_name', 'computer')\ncomputer_ed = np.array([nltk.edit_distance('computer',word) for word in array_computer])\ndf_computer_ed = pd.DataFrame({'string':array_computer, 'edit_distance':computer_ed})\ndf_computer_ed[df_computer_ed['edit_distance']<=2]","eebfcb99":"#Sorting tags based on follower count\ndict_users_tags = df_tag_users_merged['tags_tag_name'].value_counts().to_dict()\nlist_users_tags = sorted(dict_users_tags, key=dict_users_tags.get)[::-1]\ndict_rank_tags = {}\nfor rank, tags in enumerate(list_users_tags):\n    dict_rank_tags[tags] = rank\ndef find_similar(relevant, space):\n    dict_similar_tags = {}\n    for tag_i in tqdm(relevant):\n        dict_similar_tags[tag_i] = []\n        for tag_j in space:\n            if tag_i != tag_j:\n                if (len(tag_i) >5 and nltk.edit_distance(tag_i, tag_j) <= 2): #Condition 1\n                    dict_similar_tags[tag_i].append(tag_j)\n                elif (len(tag_i) <=5 and (tag_j == '#'+tag_i or tag_j == tag_i+'s' or tag_j == tag_i+'-')): #Condition 2\n                    dict_similar_tags[tag_i].append(tag_j)\n    return(dict_similar_tags)\ndict_similar_tags = find_similar(relevant_tags, list_users_tags)","02c16725":"print('Rank of tag internship:', dict_rank_tags['internship'])\nprint('Tags similar to internship:', dict_similar_tags['internship'])\nprint('Rank of tag internship:', dict_rank_tags['internships'])\nprint('Tags similar to internship:', dict_similar_tags['internships'])","40922955":"#Deepcopy as the value is a mutable data structure\ndict_similar_tags_copy = copy.deepcopy(dict_similar_tags)\nfor tag, similar in dict_similar_tags.items():\n    for subtag in similar:\n        if dict_rank_tags[subtag] < dict_rank_tags[tag]:\n            dict_similar_tags_copy[tag].remove(subtag) \n        else:\n            pass\nfor tag, similar in dict_similar_tags_copy.items():\n    extensions = []\n    for subtag in similar:\n        try:\n            extensions.extend(dict_similar_tags_copy[subtag])\n        except:\n            pass\n    dict_similar_tags_copy[tag].extend(extensions)\n    dict_similar_tags_copy[tag] = list(set(dict_similar_tags_copy[tag]))\n#This is what we'll replace\nsimilar_tags = list(set([item for sublist in list(dict_similar_tags_copy.values()) for item in sublist]))\nlist_keys = list(dict_similar_tags.keys())\nfor tag in list_keys:\n    if tag in similar_tags:\n        del dict_similar_tags_copy[tag]\n#This is what we'll use to replace\nmain_tags = list(dict_similar_tags_copy.keys())","22e08fa2":"print('Tags similar to internships:', dict_similar_tags_copy['internships'])\nprint('Tags similar to internship:\\n')\ntry:\n    print(dict_similar_tags_copy['internship'])\n#internship is not a key on account of being a low ranked tag\nexcept KeyError as e:\n    print('Key Error:', e)","5709b8b5":"print('The number of relevant tags:', len(main_tags))\nprint('The number of tags that the relevant tags cover:', len(similar_tags))\ndf_tag_users_merged = pd.merge(df_tag_users, df_tags, left_on='tag_users_tag_id', right_on='tags_tag_id', how='inner')\ndf_tag_questions_merged = pd.merge(df_tag_questions, df_tags, left_on='tag_questions_tag_id', right_on='tags_tag_id', how='inner')\nprint('Coverage of tagged questions:', df_tag_questions_merged[df_tag_questions_merged['tags_tag_name'].isin(\n    set(main_tags).union(set(similar_tags)))]['tag_questions_question_id'].nunique()\/df_tag_questions_merged['tag_questions_question_id'].nunique())\nprint('Coverage of tagged users:', df_tag_users_merged[df_tag_users_merged['tags_tag_name'].isin(\n    set(main_tags).union(set(similar_tags)))]['tag_users_user_id'].nunique()\/df_tag_users_merged['tag_users_user_id'].nunique())","e28323d7":"#To create a dictionary of tags that'll have the tag to be replaced as the key and the tag to replace it by as the value\ndict_replace_tag = {}\nfor tag, similar in dict_similar_tags_copy.items():\n    for subtag in similar:\n        dict_replace_tag[subtag] = tag\nfor tag in main_tags:\n    dict_replace_tag[tag] = tag\n#Only looking at the questions that have atleast one tag out of the union of main tags and similar tags\ndf_all_tag_questions = df_tag_questions_merged[df_tag_questions_merged['tags_tag_name'].isin(\n    set(main_tags).union(similar_tags))].groupby('tag_questions_question_id', as_index=False).agg({'tags_tag_name':list})\ndef replace(list_tags):\n    replaced_list = []\n    for tag in list_tags:\n        try:\n            replaced_list.append(dict_replace_tag[tag])\n        except:\n            pass\n    return(list(set(replaced_list)))\ndf_all_tag_questions['replaced_tag_name'] = df_all_tag_questions['tags_tag_name'].apply(replace)","1f8959c6":"#Create MultiLabelBinarizer object\none_hot = MultiLabelBinarizer()\n#One-hot encode data\ndesign_matrix = one_hot.fit_transform(df_all_tag_questions['replaced_tag_name'])","e3949206":"#Building cosine similarity matrix \ncos_sim = 1-squareform(pdist(design_matrix, metric='cosine')) #pdist computes cosine distance, so we subtract that from 1 to compute similarity\ndel design_matrix #To free up the RAM","7722502a":"#To see the profile of the volunteers and the questions that they have answered\ndf_questions['questions_date_added'] = pd.to_datetime(df_questions['questions_date_added'])\ndf_answers['answers_date_added'] = pd.to_datetime(df_answers['answers_date_added'])\ndf_answers_professionals = pd.merge(df_answers, df_professionals, left_on='answers_author_id', right_on='professionals_id', how='outer')\ndf_questions_answers_professionals = pd.merge(df_questions, df_answers_professionals, left_on='questions_id', right_on='answers_question_id')\ndf_qap_time_taken = df_questions_answers_professionals.groupby(['professionals_id','questions_id']).agg({'questions_date_added':min, 'answers_date_added':min})\ndf_qap_time_taken['less_than_2_days'] = df_qap_time_taken['answers_date_added'] - df_qap_time_taken['questions_date_added'] < '2 days'\ndf_qap_time_taken = df_qap_time_taken.reset_index().groupby('professionals_id', as_index=False).agg({'less_than_2_days':np.mean})\nlast_date = df_questions['questions_date_added'].max() #date of the last question asked on the platform\ndf_ap_grouped = df_answers_professionals.groupby('professionals_id').agg({'answers_date_added':max}).apply(lambda x:\n                                                                                          (last_date-x).dt.days)\ndf_ap_grouped.rename(columns={'answers_date_added':'days_since_answered'}, inplace=True)\nactive_professionals = df_ap_grouped[df_ap_grouped['days_since_answered']<365].index","e5e5ef06":"qid = 1\nidx = np.argsort(cos_sim[qid,:])[-6:-1]\nprint('Question Title and Body:\\n')\n#Sample question\nprint(list(df_questions[df_questions['questions_id']==df_all_tag_questions['tag_questions_question_id'].iloc[qid]]['questions_title']))\nprint(list(df_questions[df_questions['questions_id']==df_all_tag_questions['tag_questions_question_id'].iloc[qid]]['questions_body']))","fa3a39e1":"#Printing out the question body as it gives more insight into what the student actually wants to ask\nprint('Similar questions ranked by cosine similarity:\\n')\nfor rank, index in enumerate(idx[::-1]):\n    print(rank, '-', list(df_questions[df_questions['questions_id']==df_all_tag_questions.iloc[index]['tag_questions_question_id']]['questions_body']))","50d7a452":"author_id = df_answers[df_answers['answers_question_id'].isin(df_all_tag_questions.iloc[idx[::-1]]['tag_questions_question_id'])]['answers_author_id']\nactive_author_id = author_id[author_id.isin(active_professionals)]\ndf_recommended_pros = df_qap_time_taken[df_qap_time_taken['professionals_id'].isin(active_author_id)].sort_values('less_than_2_days', ascending=False)\nprint('The recommended professionals ranked by the proportion of questions answered within 48 hours:', df_recommended_pros['professionals_id'].tolist())\nprint('The profile of the professionals:')\ndf_professionals[df_professionals['professionals_id'].isin(df_recommended_pros['professionals_id'])]","a6d205a8":"qid = 512\nidx = np.argsort(cos_sim[qid,:])[-6:-1]\nprint('Question Title and Body:\\n')\n#Sample question. Printing out the question body as it gives more insight into what the student actually wants to ask\nprint(list(df_questions[df_questions['questions_id']==df_all_tag_questions['tag_questions_question_id'].iloc[qid]]['questions_title']))\nprint(list(df_questions[df_questions['questions_id']==df_all_tag_questions['tag_questions_question_id'].iloc[qid]]['questions_body']))","6018b213":"#Printing out the question body as it gives more insight into what the student actually wants to ask\nprint('Similar questions ranked by cosine similarity:\\n')\nfor rank, index in enumerate(idx[::-1]):\n    print(rank, '-', list(df_questions[df_questions['questions_id']==df_all_tag_questions.iloc[index]['tag_questions_question_id']]['questions_body']))","8e9b1c98":"author_id = df_answers[df_answers['answers_question_id'].isin(df_all_tag_questions.iloc[idx[::-1]]['tag_questions_question_id'])]['answers_author_id']\nactive_author_id = author_id[author_id.isin(active_professionals)]\ndf_recommended_pros = df_qap_time_taken[df_qap_time_taken['professionals_id'].isin(active_author_id)].sort_values('less_than_2_days', ascending=False)\nprint('The recommended professionals ranked by the proportion of questions answered within 48 hours:', df_recommended_pros['professionals_id'].tolist())\nprint('The profile of the professionals:')\ndf_professionals[df_professionals['professionals_id'].isin(df_recommended_pros['professionals_id'])]","ee93c749":"The coverage has definitely improved albeit marginally. Also, the number of tags has reduced. We don't want to consider too many tags as this will just blow up the number of features we have per question and will create computational problems. Now we'll replace the similar tags with the main tags\n\nIn an earlier version of the notebook, we used tags that have usage above a threshold of 0.5% of tagged questions and 0.5% of tagged users. In that case the coverage of tagged questions improved by about 3%, compared to the 2% here. Minor improvements are great as even a 1% improvement translates to 233 questions. Thus, by lowering the threshold and using the algorithm, we have been able to cover 1400 additional questions","129204e8":"Our job now is to remove the lower ranked tags and couple all variations of the tag 'internship' in the tag 'internships'","99ed8ce5":"Now we'll look at the coverage of these tags","8ba1c512":"The algorithm is as follows:\n- Sort the tags based on the count of tagged users per tag\n- Save the positions (or the rank) of these tags in a seperate dictionary\n- For all the tags in relevant tags, find tags that are at an edit distance of 2 for length of tags greater than 5 and tags that contain a '#' at the beginning or a '-'\/'s' at the end of tags that have a length lesser than\/equal to 5 (with smaller tags it is possible to entirely change the meaning even with an edit distance of 1)\n- If a higher (highest would be rank 0) ranked tag is included in the list of similar tags for a particular tag, remove it\n- Extend the list of lower ranked tags \n- Remove tags that are in both keys and values of the dictionary of similar tags\n- Make a dictionary of tags to replace with the main tags","b58ca4f3":"## Pre-processing\n\nFirst, we focus on using tags that have a user following of atleast 0.25% of the total number of tagged users and 0.25% of the total number of tagged questions which is about 58 questions. These threshold values have been selected after a bit of experimentation and can be treated as hyperparameters (although they aren't in the technical sense)","68e9e186":"There are a few things we would like to do here:\n- Find tags that are misspelings\/similar to the relevant tags\n- Replace the similar tags with the main tags. A good way to decide main tags would be to rank them in order of the people that follow them. Why? Professionals are only going to get alerts\/ see questions on the platform if they follow a particular tag\n- Thus increase the coverage","388eb635":"## Real-Time Implementation\n\n- This isn't the right way to recommend as for a particular question, we only have data available prior to the date at which the question was posted and in this case we have considered all questions for analysis\n- Every time a new tag is added, find the main tag that it is closest to wrt edit distance. In some way, there needs to be more control over tag creation as lesser tags lead to information enrichment. Since it is a forum for asking career based questions and not Twitter\/Instagram, it is certainly possible to do this.\n- Also, the feature vector for every question can be stored in the database\n- The cosine similarity of all questions (say m) asked before a given time period needs to be pre-computed and stored in the database since it is a memory and time intensive computation\n- Every time a new question is asked, it can be batched with other questions asked within (say) a 2 hour period and the cosine similarity of these questions (say n) with the questions that have been asked in the past can be computed\n- This way, we aren't computing cosine similarity of (m+n) x (m+n) questions, but (n) x (m+n) questions and the update becomes easier and faster\n- I know the technical details are a little fuzzy but this is just a rough solution to the problem at hand","42a4721b":"This notebook is a continuation of [Part I: Yet Another EDA, Strategy & Useful Links](https:\/\/www.kaggle.com\/akshayt19nayak\/part-i-yet-another-eda-strategy-useful-links). In this notebook, I am going to focus on building a recommender system **exclusively using tags**. What's funny is that this solution does not involve machine learning in any which way. A recommender system built by extracting data from the body of questions and answers is in the works. I haven't done everything here due to memory and time constraints. There are 3 sections to this notebook:\n\n- [Pre-processing](#Pre-processing)\n- [Recommender System](#Recommender-System)\n- [Real-Time Implementation](#Real-Time-Implementation)","186e652a":"### Example Recommendation 2","d0c9e342":"### Example Recommendation 1","75e90812":"## Recommender System\n\nTo make recommendations based on a question:    \n- Find questions that are similar to the one under consideration\n- Find if the similar questions have been answered\n- If yes, find if the professional is active. Active professional has to have answered a question within the last 1 year\n- If multiple professionals fit the criteria, rank them based on the proportion of questions they have answered within 24-48 hours [since that is a key metric](https:\/\/www.kaggle.com\/c\/data-science-for-good-careervillage\/discussion\/84845#latest-496046) ","2b82a13f":"Now let's look at the coverage","08621471":"### Edit Distance (Levenshtein Distance)\n\n- Edit Distance (a.k.a. Levenshtein Distance) is a measure of similarity between two strings referred to as the source string and the target string.\n\n- The distance between the source string and the target string is the minimum number of edit operations (deletions, insertions, or substitutions) required to transform the source into the target. The lower the distance, the more similar the two strings. ([Source](https:\/\/python.gotrained.com\/nltk-edit-distance-jaccard-distance\/))\n\nTo see an example we'll first test it on the tag 'computer'","fc3acc87":"### Cosine Similarity\n\nNow we one-hot encode the questions with tags they are linked with and build a similarity matrix using cosine similarity as the metric","13fdb416":"The recommendations in both cases do look relevant."}}