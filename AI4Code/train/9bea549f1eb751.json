{"cell_type":{"c5167ad1":"code","3228e317":"code","4af23940":"code","b653db5e":"code","58aea50d":"code","576d6327":"code","bfb16aad":"code","19954b38":"code","c517f7ae":"code","8b9cc8ef":"code","f7503b61":"code","53be151a":"code","76157d06":"code","f93b6762":"code","5847906c":"code","5150f712":"code","30a11995":"markdown","3c1e37c3":"markdown"},"source":{"c5167ad1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport os\nimport gc\nimport time\nfrom scipy.interpolate import interp1d\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom joblib import Parallel, delayed\nfrom tqdm.notebook import tqdm\nfrom scipy.stats import rankdata\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import roc_auc_score, label_ranking_average_precision_score\n\nimport soundfile as sf\n# Librosa Libraries\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\nimport matplotlib.pyplot as plt\n\nimport cuml as cm\nimport cupy as cp","3228e317":"trainfiles = glob.glob( '..\/input\/rfcx-species-audio-detection\/train\/*.flac' )\ntestfiles = glob.glob( '..\/input\/rfcx-species-audio-detection\/test\/*.flac' )\nlen(trainfiles), len(testfiles), trainfiles[0]","4af23940":"traint = pd.read_csv( '..\/input\/rfcx-species-audio-detection\/train_tp.csv' )\ntrainf = pd.read_csv( '..\/input\/rfcx-species-audio-detection\/train_fp.csv' )\ntraint.shape, trainf.shape","b653db5e":"traint.head()","58aea50d":"trainf.head()","576d6327":"def extract_fft(fn):\n    data, samplerate = sf.read(fn)\n    data = cp.array(data)\n\n    varfft = cp.abs( cp.fft.fft(data)[:(len(data)\/\/2)] )\n    \n    return cp.asnumpy( varfft.reshape( (1000,1440) ).mean(axis=1) )","bfb16aad":"FT = []\nfor fn in tqdm(traint.recording_id.values):\n    FT.append( extract_fft( '..\/input\/rfcx-species-audio-detection\/train\/'+fn+'.flac' ) )\nFT = np.stack(FT)\ngc.collect()\n\nFT.shape","19954b38":"# This loop runs in 7min using cupy(GPU) and 40min on numpy(CPU). ~7x Faster in GPU\n\nFF = []\nfor fn in tqdm(trainf.recording_id.values):\n    FF.append( extract_fft( '..\/input\/rfcx-species-audio-detection\/train\/'+fn+'.flac' ) )\nFF = np.stack(FF)\ngc.collect()\n\nFF.shape","c517f7ae":"#Combine True Positives and False Positives\n\nTRAIN = np.vstack( (FT, FF) )\n\ndel FT, FF\ngc.collect()\nTRAIN.shape","8b9cc8ef":"TEST = []\nfor fn in tqdm(testfiles):\n    TEST.append( extract_fft(fn) )\nTEST = np.stack(TEST)\ngc.collect()\n\nTEST.shape","f7503b61":"tt = traint[['recording_id','species_id']].copy()\ntf = trainf[['recording_id','species_id']].copy()\ntf['species_id'] = -1\n\nTRAIN_TAB = pd.concat( (tt, tf) )\n\nfor i in range(24):\n    TRAIN_TAB['s'+str(i)] = 0\n    TRAIN_TAB.loc[TRAIN_TAB.species_id==i,'s'+str(i)] = 1\n\nTRAIN_TAB.head()","53be151a":"from sklearn.preprocessing import StandardScaler\n\nstd = StandardScaler()\nstd.fit( np.vstack((TRAIN,TEST)) )\n\nTRAIN = std.transform(TRAIN)\nTEST  = std.transform(TEST)\ngc.collect()","76157d06":"sub = pd.DataFrame({'recording_id': [f.split('\/')[-1].split('.')[0] for f in testfiles] })\ngkf = GroupKFold(5)\n\nSCORE = []\ngroups = TRAIN_TAB['recording_id'].values\nfor tgt in range(0,24):\n    starttime = time.time()\n    target = TRAIN_TAB['s'+str(tgt)].values\n\n    ytrain = np.zeros(TRAIN.shape[0])\n    ytest = np.zeros(TEST.shape[0])\n    for ind_train, ind_valid in gkf.split( TRAIN, target, groups ):\n        \n        # Define 4 models\n        model1 = xgb.XGBClassifier(n_estimators=1000,\n                                   max_depth=4,\n                                   learning_rate=0.05,\n                                   verbosity=0,\n                                   objective='binary:logistic',\n                                   subsample=0.95,\n                                   colsample_bytree=0.95,\n                                   random_state=2021,\n                                   tree_method='gpu_hist',\n                                   predictor='gpu_predictor',\n                                   n_jobs=2,\n                                   scale_pos_weight = np.sum(target==0) \/ np.sum(target==1),\n                                  )\n        model2 = cm.linear_model.LogisticRegression( C=1, max_iter=5000 )\n        model3 = cm.svm.SVC(C=1.0, class_weight='balanced', probability=True, kernel='rbf', gamma='auto')\n        model4 = cm.neighbors.KNeighborsClassifier(n_neighbors=55)\n        \n        # Train using GPUs\n        model1.fit( X=TRAIN[ind_train], y=target[ind_train], eval_set=[(TRAIN[ind_valid], target[ind_valid])], eval_metric='auc', early_stopping_rounds=30, verbose=False )\n        model2.fit( TRAIN[ind_train], target[ind_train] )\n        model3.fit( TRAIN[ind_train], target[ind_train] )\n        model4.fit( TRAIN[ind_train], target[ind_train] )\n        \n        # Predict valid and test sets\n        yvalid1 = model1.predict_proba(TRAIN[ind_valid])[:,1]\n        yvalid2 = model2.predict_proba(TRAIN[ind_valid])[:,1]\n        yvalid3 = model3.predict_proba(TRAIN[ind_valid])[:,1]\n        yvalid4 = model4.predict_proba(TRAIN[ind_valid])[:,1]\n        ytest1 = model1.predict_proba(TEST)[:,1]\n        ytest2 = model2.predict_proba(TEST)[:,1]\n        ytest3 = model3.predict_proba(TEST)[:,1]\n        ytest4 = model4.predict_proba(TEST)[:,1]\n        \n        #Rank predictions\n        SZ = len(ind_valid) + len(ytest1)\n        yvalid1 = rankdata( np.concatenate((yvalid1,ytest1)) )[:len(ind_valid)] \/ SZ\n        yvalid2 = rankdata( np.concatenate((yvalid2,ytest2)) )[:len(ind_valid)] \/ SZ\n        yvalid3 = rankdata( np.concatenate((yvalid3,ytest3)) )[:len(ind_valid)] \/ SZ\n        yvalid4 = rankdata( np.concatenate((yvalid4,ytest4)) )[:len(ind_valid)] \/ SZ\n        ytest1 = rankdata( np.concatenate((yvalid1,ytest1)) )[len(ind_valid):] \/ SZ\n        ytest2 = rankdata( np.concatenate((yvalid2,ytest2)) )[len(ind_valid):] \/ SZ\n        ytest3 = rankdata( np.concatenate((yvalid3,ytest3)) )[len(ind_valid):] \/ SZ\n        ytest4 = rankdata( np.concatenate((yvalid4,ytest4)) )[len(ind_valid):] \/ SZ\n        \n        #Weighted average models\n        ytrain[ind_valid] = (0.40*yvalid1+0.20*yvalid2+0.20*yvalid3+0.20*yvalid4) \/ 4.\n        ytest += (0.40*ytest1+0.20*ytest2+0.20*ytest3+0.20*ytest4) \/ (4.*5)\n\n    score = roc_auc_score(target, ytrain)\n    print( 'Target AUC', tgt, score, time.time()-starttime )\n    SCORE.append(score)\n    \n    TRAIN_TAB['y'+str(tgt)] = ytrain\n    sub['s'+str(tgt)] = ytest\n\nprint('Overall Score:', np.mean(SCORE) )","f93b6762":"sub.head()","5847906c":"sub.to_csv('submission.csv', index=False)","5150f712":"!ls","30a11995":"# To enable RAPIDS just set Notebook Environment to \"latest\" and enable GPU","3c1e37c3":"# Now Kaggle have RAPIDS runing natively in notebooks. Lets take advantage on it ;) "}}