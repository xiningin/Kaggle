{"cell_type":{"e88406f0":"code","5dbe44f6":"code","98e5b557":"code","82a05a41":"code","7bd41636":"code","44344250":"code","e4460fc6":"code","f66effc9":"code","9d552858":"code","af0a2d04":"code","51167af2":"code","ca222d27":"code","8c7b1f31":"code","f297de03":"code","aa0633ee":"code","3d5c7c9f":"code","74bea582":"code","bfe3e592":"code","07c6e08c":"code","62394a77":"code","a1aa1c77":"code","4ebc73de":"code","3296544f":"code","673d4699":"code","fd70a1c0":"code","8b209591":"code","332d485c":"code","61daf4f8":"code","2ad9d710":"code","1d7f027e":"code","6e2c57d8":"code","e3db740c":"code","5025fb04":"code","3a2bae71":"code","76d815c1":"code","44906f5d":"code","15d1d5e6":"code","c3d3762e":"code","2450efc9":"code","c8aea553":"code","2d6c922d":"code","7c1c69b4":"code","bbef9377":"code","c5d040bc":"code","953df469":"markdown","ecac5cf5":"markdown","04516f20":"markdown","9713833f":"markdown","1862a63c":"markdown","fe5ac764":"markdown","a01b1191":"markdown","f8923b45":"markdown","5a27d350":"markdown","4e6ab4ae":"markdown","c9d8940c":"markdown","9ac75313":"markdown","9e4d3c68":"markdown","2b122825":"markdown","22700bcb":"markdown","855bf20f":"markdown","4bcb818d":"markdown","a09a7b77":"markdown","fdc56f7f":"markdown","66dae38a":"markdown"},"source":{"e88406f0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5dbe44f6":"dataset = pd.read_csv('\/kaggle\/input\/india_pollution.csv',encoding='cp1252')","98e5b557":"dataset.head()","82a05a41":"dataset = dataset.drop(['stn_code','sampling_date','agency','location','location_monitoring_station'], axis = 1)","7bd41636":"dataset.isnull().sum()","44344250":"dataset.describe()","e4460fc6":"dataset['date'].describe()","f66effc9":"common_value_date='2015-03-19'\ndataset['date']=dataset['date'].fillna(common_value_date)\ndataset.tail()","9d552858":"dataset['type'].describe()","af0a2d04":"type_value = { 'type' : 'Residential, Rural and other Areas'}\ndataset = dataset.fillna(value = type_value)","51167af2":"dataset[['spm','pm2_5']] = dataset[['spm','pm2_5']].fillna(0)","ca222d27":"import numpy as np\nfrom sklearn.impute import SimpleImputer\nimp = SimpleImputer(strategy='mean')\nimp = imp.fit(dataset.iloc[:,2:5].values)\ndataset.iloc[:,2:5] = imp.transform(dataset.iloc[:,2:5].values)","8c7b1f31":"dataset.isnull().sum()","f297de03":"import datetime\n\ndataset['date'] = pd.to_datetime(dataset['date'])","aa0633ee":"yno2 = dataset.groupby(dataset['date'].dt.strftime('%Y'))['no2'].mean()\nyso2 = dataset.groupby(dataset['date'].dt.strftime('%Y'))['so2'].mean()\nyrspm = dataset.groupby(dataset['date'].dt.strftime('%Y'))['rspm'].mean()\nyspm = dataset.groupby(dataset['date'].dt.strftime('%Y'))['spm'].mean()\nypm2_5 = dataset.groupby(dataset['date'].dt.strftime('%Y'))['pm2_5'].mean()","3d5c7c9f":"yno2 = yno2.to_frame()\nyso2 = yso2.to_frame()\nyrspm = yrspm.to_frame()\nyspm = yspm.to_frame()\nypm2_5 = ypm2_5.to_frame()\ndf = pd.concat([yno2,yso2,yrspm,yspm,ypm2_5],axis=1)\ndf","74bea582":"df.plot.area()","bfe3e592":"top_NO2_levels_state = dataset.groupby(['state'])['no2'].mean().sort_values(ascending = False)\ntop_NO2_levels_state.head()","07c6e08c":"top_SO2_levels_state = dataset.groupby(['state'])['so2'].mean().sort_values(ascending = False)\ntop_SO2_levels_state.head()","62394a77":"top_RSPM_levels_state = dataset.groupby(['state'])['rspm'].mean().sort_values(ascending = False)\ntop_RSPM_levels_state.head()","a1aa1c77":"top_SPM_levels_state = dataset.groupby(['state'])['spm'].mean().sort_values(ascending = False)\ntop_SPM_levels_state.head()","4ebc73de":"top_PM2_5_levels_state = dataset.groupby(['state'])['pm2_5'].mean().sort_values(ascending = False)\ntop_PM2_5_levels_state.head()","3296544f":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfig, axes = plt.subplots(nrows=2, ncols=2,figsize=(20,16))\nax = sns.barplot(\"so2\", y=\"type\",\n                 data=dataset,\n                 ax=axes[0,0]\n                )\nax = sns.barplot(\"no2\", y=\"type\",\n                 data=dataset,\n                 ax=axes[0,1]\n                )\nax = sns.barplot(\"rspm\", y=\"type\",\n                 data=dataset,\n                 ax=axes[1,0]\n                )\nax = sns.barplot(\"spm\", y=\"type\",\n                 data=dataset,\n                 ax=axes[1,1]\n                )","673d4699":"def calculate_si(so2):\n    si=0\n    if (so2<=40):\n     si= so2*(50\/40)\n    if (so2>40 and so2<=80):\n     si= 50+(so2-40)*(50\/40)\n    if (so2>80 and so2<=380):\n     si= 100+(so2-80)*(100\/300)\n    if (so2>380 and so2<=800):\n     si= 200+(so2-380)*(100\/800)\n    if (so2>800 and so2<=1600):\n     si= 300+(so2-800)*(100\/800)\n    if (so2>1600):\n     si= 400+(so2-1600)*(100\/800)\n    return si\ndataset['si']=dataset['so2'].apply(calculate_si)\ndf= dataset[['so2','si']]\ndf.head()","fd70a1c0":"#Function to calculate no2 individual pollutant index(ni)\ndef calculate_ni(no2):\n    ni=0\n    if(no2<=40):\n     ni= no2*50\/40\n    elif(no2>40 and no2<=80):\n     ni= 50+(no2-14)*(50\/40)\n    elif(no2>80 and no2<=180):\n     ni= 100+(no2-80)*(100\/100)\n    elif(no2>180 and no2<=280):\n     ni= 200+(no2-180)*(100\/100)\n    elif(no2>280 and no2<=400):\n     ni= 300+(no2-280)*(100\/120)\n    else:\n     ni= 400+(no2-400)*(100\/120)\n    return ni\ndataset['ni']=dataset['no2'].apply(calculate_ni)\ndf= dataset[['no2','ni']]\ndf.head()","8b209591":"\ndef calculate_(rspm):\n    rpi=0\n    if(rpi<=30):\n     rpi=rpi*50\/30\n    elif(rpi>30 and rpi<=60):\n     rpi=50+(rpi-30)*50\/30\n    elif(rpi>60 and rpi<=90):\n     rpi=100+(rpi-60)*100\/30\n    elif(rpi>90 and rpi<=120):\n     rpi=200+(rpi-90)*100\/30\n    elif(rpi>120 and rpi<=250):\n     rpi=300+(rpi-120)*(100\/130)\n    else:\n     rpi=400+(rpi-250)*(100\/130)\n    return rpi\ndataset['rpi']=dataset['rspm'].apply(calculate_si)\ndf= dataset[['rspm','rpi']]\ndf.tail()\n#many data values of rspm values is unawailable since it was not measure before","332d485c":"def calculate_spi(spm):\n    spi=0\n    if(spm<=50):\n     spi=spm\n    if(spm<50 and spm<=100):\n     spi=spm\n    elif(spm>100 and spm<=250):\n     spi= 100+(spm-100)*(100\/150)\n    elif(spm>250 and spm<=350):\n     spi=200+(spm-250)\n    elif(spm>350 and spm<=450):\n     spi=300+(spm-350)*(100\/80)\n    else:\n     spi=400+(spm-430)*(100\/80)\n    return spi\ndataset['spi']=dataset['spm'].apply(calculate_spi)\ndf= dataset[['spm','spi']]\ndf.tail()","61daf4f8":"#its is calculated as per indian govt standards\ndef calculate_aqi(si,ni,spi,rpi):\n    aqi=0\n    if(si>ni and si>spi and si>rpi):\n     aqi=si\n    if(spi>si and spi>ni and spi>rpi):\n     aqi=spi\n    if(ni>si and ni>spi and ni>rpi):\n     aqi=ni\n    if(rpi>si and rpi>ni and rpi>spi):\n     aqi=rpi\n    return aqi\ndataset['AQI']=dataset.apply(lambda x:calculate_aqi(x['si'],x['ni'],x['spi'],x['rpi']),axis=1)\ndf= dataset[['date','state','si','ni','rpi','spi','AQI']]\ndf.head()","2ad9d710":"yearly_AQI_levels = df.groupby(df['date'].dt.strftime('%Y'))['AQI'].mean()\nplt.figure(figsize=(16,8))\nplt.title('Yearly AQI Levels')\nplt.xlabel('Year')\nplt.ylabel('AQI Level')\nplt.plot(yearly_AQI_levels,marker = 'o');","1d7f027e":"plt.figure(figsize=(16,6))\nplt.plot(yearly_AQI_levels.rolling(window=12,center=False).mean(),label='Rolling Mean');\nplt.plot(yearly_AQI_levels.rolling(window=12,center=False).std(),label='Rolling sd');\nplt.legend();","6e2c57d8":"import statsmodels.api as sm\n\n# multiplicative\nres = sm.tsa.seasonal_decompose(yearly_AQI_levels.values,period=12,model=\"multiplicative\")\nplt.figure(figsize=(16,12))\nfig = res.plot()","e3db740c":"# additive\nres = sm.tsa.seasonal_decompose(yearly_AQI_levels.values,period=12,model=\"additive\")\nplt.figure(figsize=(16,12))\nfig = res.plot()","5025fb04":"# Stationarity tests\nfrom statsmodels.tsa.stattools import adfuller\n\ndef test_stationarity(timeseries):\n    \n    #Perform Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)\n\ntest_stationarity(yearly_AQI_levels)","3a2bae71":"df1 = df.groupby(['date'])['AQI'].mean()\ndf1.isnull().sum()\n\nmonthly_AQI_levels = df1.resample(\"M\").mean()\nmonthly_AQI_levels.head()","76d815c1":"monthly_AQI_levels = monthly_AQI_levels.fillna(monthly_AQI_levels.mean())\nplt.figure(figsize=(16,8))\nplt.title('monthly AQI Levels')\nplt.xlabel('Month')\nplt.ylabel('AQI Level')\nplt.plot(monthly_AQI_levels);","44906f5d":"# to remove trend\nfrom pandas import Series as Series\n# create a differenced series\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return Series(diff)\n\n# invert differenced forecast\ndef inverse_difference(last_ob, value):\n    return value + last_ob","15d1d5e6":"plt.figure(figsize=(16,16))\nplt.subplot(311)\nplt.title('Original')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(monthly_AQI_levels)\nplt.subplot(312)\nplt.title('After De-trend')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(monthly_AQI_levels)\nplt.plot(new_ts)\nplt.plot()\n\nplt.subplot(313)\nplt.title('After De-seasonalization')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(monthly_AQI_levels,12)       # assuming the seasonality is 12 months long\nplt.plot(new_ts)\nplt.plot()","c3d3762e":"test_stationarity(new_ts)","2450efc9":"ts=df1.resample(\"M\").mean()\nts.index=pd.date_range(start = '1987-01-01',end='2015-12-01', freq = 'MS')\nts=ts.reset_index()\nts.head()","c8aea553":"from fbprophet import Prophet\n#prophet reqiures a pandas df at the below config \n# ( date column named as DS and the value column as Y)\nts.columns=['ds','y']\nmodel = Prophet( yearly_seasonality=True) #instantiate Prophet with only yearly seasonality as our data is monthly \nmodel.fit(ts) #fit the model with your dataframe","2d6c922d":"# predict for 3 years in the furure and YS - Year start is the frequency\nfuture = model.make_future_dataframe(periods = 3, freq = 'YS')  \n# now lets make the forecasts\nforecast = model.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","7c1c69b4":"model.plot(forecast)","bbef9377":"model.plot_components(forecast)","c5d040bc":"forecast.tail()","953df469":"Due to the large, number of missing values of spm and pm2_5 we are filling them with with  0 to avoid data tampering too much","ecac5cf5":"Now we need to compare the pollution as a whole statewise by calculating AQI(Air Quality Index)\n\nfor this we first calculate the individual indices of each pollutant and finally the AQI.","04516f20":"Similarily, we fill the missing  type  data with \"Residential, Rural and other Areas\"","9713833f":"![https:\/\/www.google.com\/url?sa=i&url=https%3A%2F%2Fwww.airveda.com%2Fblog%2FAQI-calculation-update&psig=AOvVaw35QUuArbfJ5CucDAR2dvs5&ust=1587650433964000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCOi0qfOY_OgCFQAAAAAdAAAAABAJ]","1862a63c":"As we can see there is alot of missing data, this is mostly due to faulty equipment and improper tabulation of data.\n\nFew stations have been shifted\/closed\/during the period, as those were not meeting the NAMP guidelines for monitoring sites after differential development\/change in the area. **During 1987-2013**, SPM has been represented by PM 2.5 (PM2.5 was not being monitored during that period).\n\nThis is why the most can be seen in the values of spm and pm2_5.\n","fe5ac764":"We first group the data on the basis of year to view the yearly spreads","a01b1191":"Let's view the data.","f8923b45":"Other missing values are filled with the means of the respective columns","5a27d350":"As we can this is not stationary as the p-value is way above 5%","4e6ab4ae":"Using Time-series analysis to check whether the model is an additive one or a multiplicative one","c9d8940c":"We can see the AQI in decreasing which is a good thing","9ac75313":"We can see the pollutants are at there highest in the Industrial Areas","9e4d3c68":"We can fill the missing date values with the most frequently occuring date in the dataset","2b122825":"Prophet requires data to be indexed as dates and the columns should be labeled as \"ds\" and \"y\"","22700bcb":"As we will be using only a few columns as we will be predicting statewise emmissions of pollutant, we will not be needing the columns 'stn code','sampling_date' , 'location', 'agency'and 'location_monitoring_station'.  ","855bf20f":"Now after the transformations, our p-value for the DF test is well within 5 %. Hence we can assume Stationarity of the series\u00b6 We can easily get back the original series using the inverse transform function that we have defined above.\n\nNow let's dive into making the forecasts!\n\n **Prophet::**\n\nRecently open-sourced by Facebook research. It's a very promising tool, that is often a very handy and quick solution to the frustrating flatline :P\n\nResources for learning more about prophet:\n\nhttps:\/\/www.youtube.com\/watch?v=95-HMzxsghY https:\/\/facebook.github.io\/prophet\/docs\/quick_start.html#python-api https:\/\/research.fb.com\/prophet-forecasting-at-scale\/ https:\/\/blog.exploratory.io\/is-prophet-better-than-arima-for-forecasting-time-series-fa9ae08a5851","4bcb818d":"Now let's check the dataset for missing values","a09a7b77":"We need to convert the date column into a suitable format to be used by the algorithms later","fdc56f7f":"Here is an analysis of historical air quality data of india from the year 1986 to 2015 and prediction for the future 3 years. Data has been acquired from https:\/\/data.gov.in\/catalog\/historical-daily-ambient-air-quality-data .\n\nData has been parsed and cleaned using various methods. \nFacebook's Prophet library has been used to make predictions for the future Years..","66dae38a":"Using the AD-Fuller test for stationarity as the algorithm only work with stationary data"}}