{"cell_type":{"2e48fdd4":"code","b9ca6a5c":"code","f1353d30":"code","7edfee71":"code","6af50bb0":"code","679e2585":"code","712d961b":"code","7c545969":"code","38d2cfc5":"code","f1d732ab":"code","77f8ecee":"code","762e3b27":"code","db5bd69e":"code","121a0dd0":"code","ce7cba24":"code","cdaceeba":"code","389efca1":"code","dc96bd34":"code","3cebc080":"code","e562fd11":"markdown","00317346":"markdown","e8524596":"markdown","82640a28":"markdown","a6d222db":"markdown","82b2763a":"markdown","93ab31ba":"markdown","91677719":"markdown","ae36f98d":"markdown","3b311f0f":"markdown","6434a2d7":"markdown","3b6df277":"markdown","ac624b23":"markdown","9fe7ea12":"markdown","befda527":"markdown","cca5c5e7":"markdown","b75c58ad":"markdown","116e9418":"markdown","caa6fbf6":"markdown","f96ef7aa":"markdown","4a6b666d":"markdown","5eb24044":"markdown","4c74abad":"markdown","dd03cb89":"markdown","1bd46129":"markdown","77c1c173":"markdown","86b46ef0":"markdown","c9e436a0":"markdown","9a804b06":"markdown","3d53cb6a":"markdown","9d256309":"markdown","c8f0df2e":"markdown","653001f1":"markdown","f1cb4cbe":"markdown"},"source":{"2e48fdd4":"# Import the dependencies\nimport numpy as np\nfrom scipy.linalg import toeplitz, cholesky, sqrtm, inv\n# import scipy.linalg as la\nfrom scipy import signal\nfrom scipy.integrate import odeint\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"white\")\nprint(\"Imports done\")","b9ca6a5c":"def g_gp(x,v):\n    \"\"\"\n    Generative process, equation of sensory mapping: g_gp(x,v) at point x    \n   \n    INPUTS:\n        x       - Hidden state, depth position in centimetres\n        v       - Hidden causal state, in this example not used\n        \n    OUTPUT:\n        g_gp(x,v) - Temperature in degrees celsius\n        \n    \"\"\"\n\n    t0=25\n    return t0 -16 \/ (1 + np.exp(5-x\/5))\n\ndef dg_gp(x,v):\n    \"\"\"\n    Partial derivative of generative process towards x, equation of sensory mapping: g'_gp(x,v) at point x    \n   \n    INPUTS:\n        x       - Position in centimetres    \n        \n    OUTPUT:\n        g'_gp(x,v) - first partial derivative of generative process towards x\n        \n    \"\"\"\n    \n    return -16\/5 * np.exp(5-x\/5) \/ (1+np.exp(5-x\/5))**2\n\ndef ddg_gp(x,v):\n    \"\"\"\n    Double partial derivative of generative process towards x, equation of sensory mapping: g''_gp(x) at point x  \n    Needed to calculate the sensory signal in generalised motions\n   \n    INPUTS:\n        x       - Position in centimetres    \n        \n    OUTPUT:\n        g''_gp(x,v) - second partial derivative of generative process towards x\n        \n    \"\"\"\n    \n    return (32*np.exp((2*x)\/5+5))\/(25*(np.exp(x\/5)+np.exp(5))**3)-(16*np.exp(x\/5+5))\/(25*(np.exp(x\/5)+np.exp(5))**2)\n\ndef dddg_gp(x,v):\n    \"\"\"\n    3rd partial derivative of generative process towards x, equation of sensory mapping: g'''_gp(x) at point x  \n    Needed to calculate the sensory signal in generalised motions\n   \n    INPUTS:\n        x       - Position in centimetres    \n        \n    OUTPUT:\n        g'''_gp(x,v) - third partial derivative of generative process towards x\n        \n    \"\"\"\n    \n    return -16*np.exp(x\/5+5)*(np.exp((2*x)\/5)-4*np.exp(x\/5+5)+np.exp(10))\/(125*(np.exp(x\/5)+np.exp(5))**4)\n\ndef ddddg_gp(x,v):\n    \"\"\"\n    4th partial derivative of generative process towards x, equation of sensory mapping: g''''_gp(x) at point x  \n    Needed to calculate the sensory signal in generalised motions\n   \n    INPUTS:\n        x       - Position in centimetres    \n        \n    OUTPUT:\n        g''''_gp(x,v) - 4th partial derivative of generative process towards x\n        \n    \"\"\"\n    \n    return (16*np.exp(x\/5+5)*(np.exp((3*x)\/5)-11*np.exp((2*x)\/5+5)+11*np.exp(x\/5+10)-np.exp(15)))\/(625*(np.exp(x\/5)+np.exp(5))**5)\n\n# in case you wondered how to calculated all the derivatives in an easy way: https:\/\/www.derivative-calculator.net\/\n\n# Show the temperature curve\nx_show = np.arange (-0,50,0.01)\ny_show = g_gp(x_show,0)\ndy_show = dg_gp(x_show,0)\nplt.plot(y_show, x_show)\n#plt.plot(dy_show, x_show)\nplt.ylabel('Depth (centimeters)')\nplt.xlabel('Temperature (\u00b0 C)')\nplt.gca().invert_yaxis()\nplt.vlines(17, 50, 25, colors='r', linestyles='dashed')\nplt.hlines(25, 10,17, colors='r', linestyles='dashed')\nplt.text(17.3,27,\"temparature 17\u00b0 C\")\nplt.show;\n\nprint('Temperature at 25 centimetres is: ', g_gp(25,0), ' degrees celsius')","f1353d30":"a_gp=0\nb_gp=1\ndef f_gp(x, v, u):\n    \"\"\"\n    Generative process, equation of motion: f_gp(x,u)    \n   \n    INPUTS:\n        x       - Hidden state, depth position in centimetres\n        v       - Causal state\n        u       - Control signal\n        \n    OUTPUT:\n        f_gp(x,v,u) - motion (speed) of the hidden state (depth) \n        \n    \"\"\"\n    return a_gp*x + b_gp*u\n\ndef df_gp(x, v, u):\n    \"\"\"\n    Partial derivative of generative process towards x, equation of motion: f'_gp(x,v,u) at point x    \n   \n    INPUTS:\n        x       - Hidden state, depth position in centimetres\n        v       - Causal state\n        u       - Control signal\n        \n    OUTPUT:\n        df_gp(x, u) - first derivative of the equation of motion towards x\n        \n    \"\"\"\n    return a_gp\n        ","7edfee71":"# Setting up the time data:\ndt = 0.005; # integration step, average neuron resets 200 times per second\nT = 10+dt; # maximum time considered\nt = np.arange(0,T,dt)\nN= t.size #Amount of data points\nprint ('Amount of data points: ', N)\nprint ('Starting with', t[0:5])\nprint ('Ending with', t[N-5:N])\nprint ('Data elements', np.size(t))","6af50bb0":"# Support functions for generalised coordinates of motion\n\ndef makeNoise(C,s2,t):\n    \"\"\"\n    Generate random noise series with temporal smoothness with desired covariance matrix\n    Code by Sherin Grimbergen (V1 2019) and Charel van Hoof (V2 2020)\n    \n    INPUTS:\n        C       - desired covariance matrix\n        s2      - smoothness parameter (>0), variance of the filter (sigma^2)\n                  - s2 <= 1e-5 -> produces white noise\n        t       - timeline \n        \n    OUTPUT:\n        ws       - noise sequence with temporal smoothness\n    \"\"\"\n    \n    if np.size(C)== 1:\n        n = 1\n    else:\n        n = C.shape[1]  # dimension of noise\n        \n    # Create the white noise with correct covariance\n    N = np.size(t)      # number of elements\n    L =cholesky(C, lower=True)  #Cholesky method\n    w = np.dot(L,np.random.randn(n,N))\n    \n    if s2 <= 1e-5: # return white noise\n        return w\n    else: \n        # Create the noise with temporal smoothness\n        P = toeplitz(np.exp(-t**2\/(2*s2)))\n        F = np.diag(1.\/np.sqrt(np.diag(np.dot(P.T,P))))\n        K = np.dot(P,F)\n        ws = np.dot(w,K)\n        return ws\n\ndef temporalC(p,s2):\n    \"\"\"\n    Construct the temporal covariance matrix S for noise with embedding order p and smoothness parameter s\n    \n    Code by Sherin Grimbergen (V1 2019) and Charel van Hoof (V2 2020)\n    \n    INPUTS:\n        p       - embedding order (>0)\n        s2      - smoothness parameter (>0), variance of the filter (sigma^2)\n        \n    OUTPUT:\n        S       - temporal covariance matrix ((p+1) x (p+1))\n    \"\"\" \n\n    q = np.arange(p+1)\n    \n    r = np.zeros(1+2*(p))\n    r[2*q] = np.cumprod(1-2*q)\/(2*s2)**(q)    \n    \n    S = np.empty([0,p+1])\n\n    for i in range(p+1):\n        S = np.vstack([S,r[q+i]])\n        r = -r\n           \n    return S \n\ndef derivativeD(p):\n    \"\"\"\n    Construct derivative operator with embedding order p \n    Shifts all variables of a vector up by one and adds a zero at the bottom \n    \n    Code by Sherin Grimbergen (V1 2019) and Charel van Hoof (V2 2020)\n    \n    INPUTS:\n        p       - embedding order (>0)\n        \n    OUTPUT:\n        D       - derivative matrix ((p+1) x (p+1))\n    \"\"\" \n    D = toeplitz(np.zeros([1,p+1]),np.append(np.array([0,1]),np.zeros([1,p-1])))\n           \n    return D\n\ndef generalize_extend(y,p):\n    \"\"\"\n    Construct generalised value with embedding order p \n    By [y,0,0...]\n    \n    INPUTS:\n        y       - Input sensory signal\n        p       - embedding order (>0)\n        \n    OUTPUT:\n        y_tilde - Generalised sensory signal\n    \"\"\" \n    if p<0:\n        # unknown embedding order, error\n        raise ValueError('Embedding order < 0')    \n    \n    if np.shape(y)==(p+1, 1):\n        # Generalised value, use it\n        y_tilde=y;\n        return y_tilde\n    \n    # Generalize sensory observation by adding zero's\n    y_tilde = np.zeros((p+1,1))\n    y_tilde[0] = y\n\n    return y_tilde\n\ndef sensor_generalize_exact(y,p,x,v,u):\n    \"\"\"\n    Construct generalised sensory observations with embedding order p \n    Generalize sensory observation by calculating the exact value \n    \n    For this example it has been calculated upto 3 derivatives\n\n    INPUTS:\n        y       - Input sensory signal\n        p       - embedding order (>0)\n        x       - Hidden state, needed to calculate the exact higher derivatives\n        \n    OUTPUT:\n        y_tilde - Generalised sensory signal\n    \"\"\" \n    if p<0:\n        # unknown embedding order, error\n        raise ValueError('Embedding order < 0')       \n\n    y_tilde = np.zeros((p+1,1))\n    y_tilde[0] = y\n    if p>=1:\n        y_tilde[1] = dg_gp(x,v)*f_gp(x,v,u) \n    if p>=2:\n        y_tilde[2] = ddg_gp(x,v)*f_gp(x,v,u)**2 + dg_gp(x,v)*df_gp(x,v,u)*f_gp(x,v,u)\n    if p>=3:\n        y_tilde[3] = dddg_gp(x,v)*f_gp(x,v,u)**3 + 2*ddg_gp(x,v)*f_gp(x,v,u)**2*df_gp(x,v,u) + df_gp(x,v,u)*(ddg_gp(x,v)*f_gp(x,v,u)**2 + dg_gp(x,v)*df_gp(x,v,u)*f_gp(x,v,u))\n    \n    return y_tilde\n\ndef sensor_generalize_backward(y,i,p):\n    \"\"\"\n    Construct generalised sensory observations with embedding order p \n    Generalize sensory observation by approximating the derivaties from past observations\n    \n    For this example it has been calculated upto 4 derivatives\n    \n    INPUTS:\n        y       - Input sensory signal (array including all history thus far)\n        i       - Current timestamp, so y[i] is the current non-generalised sensory signal\n        p       - embedding order (>=0)\n        \n    OUTPUT:\n        y_tilde - Generalised sensory signal\n    \"\"\" \n    if p<0:\n        # unknown embedding order, error\n        raise ValueError('Embedding order < 0')    \n    \n    y_tilde = np.zeros((p+1,1))\n    y_tilde[0] = y[i]\n    if p>=1:\n        y_tilde[1] = (y[i]-y[i-1])\/dt\n        #print('Generalise backward input : ', y[i],' + ',y[i-1])\n    if p>=2 and i>=2:\n        y_tilde[2] = (y[i]-2*y[i-1]+y[i-2])\/dt**2\n        #print('Generalise backward input : ', y[i],' + ',y[i-1],' + ',y[i-2])\n    if p>=3 and i>=3:\n        y_tilde[3] = (y[i]-3*y[i-1]+3*y[i-2]-y[i-3])\/dt**3\n        #print('Generalise backward input : ', y[i],' + ',y[i-1],' + ',y[i-2],' + ',y[i-3])\n    if p>=4 and i>=4:\n        y_tilde[4] = (y[i]-4*y[i-1]+6*y[i-2]-4*y[i-3]+y[i-4])\/dt**4\n        #print('Generalise backward input : ', y[i],' + ',y[i-1],' + ',y[i-2],' + ',y[i-3],' + ',y[i-4])\n          \n    return y_tilde\n\ndef standard_vec(p):\n    x = np.zeros((p+1,1))\n    x[0] = 1\n    return x\n\ndef standard_vec_inv(p):\n    x = np.ones((p+1,1))\n    x[0] = 0\n    return x\n\ndef ones_vec(p):\n    x = np.ones((p+1,1))\n    return x\n\ndef fwd_model(p,x,v,u,fwd_method):\n    \"\"\"\n    Construct the forward model embedding order p \n    \n    For this example it has been calculated upto 3 derivatives\n\n    INPUTS:\n        p          - embedding order (>0)\n        x          - Hidden state\n        v          - Hidden cause\n        u          - Control signal\n        fwd_method - Method\n        \n    OUTPUT:\n        fwd - Forward model, note: for this specific notebook example\n    \"\"\" \n    if p<0:\n        # unknown embedding order, error\n        raise ValueError('Embedding order forward model < 0')       \n    if fwd_method == 'sign':\n        fwd = -1 * np.ones((p+1,1))\n    elif fwd_method == 'exact':        \n        fwd = np.zeros((p+1,1))\n        if p>=1:\n            fwd[1] = b_gp*dg_gp(x,v)\n        if p>=2:\n            fwd[2] = 2*b_gp*f_gp(x,v,u)*ddg_gp(x,v) +b_gp*df_gp(x,v,u)*dg_gp(x,v)\n        if p>=3:\n            fwd[3] = 3*b_gp*f_gp(x,v,u)**2*dddg_gp(x,v)+4*df_gp(x,v,u)*b_gp*f_gp(x,v,u)*dg_gp(x,v)+2*df_gp(x,v,u)*b_gp*f_gp(x,v,u)*ddg_gp(x,v)+df_gp(x,v,u)**2*b_gp*dg_gp(x,v)\n    elif fwd_method == 'sign+':        \n        fwd = np.zeros((p+1,1))\n        if p>=1:\n            fwd[1] = np.sign(dg_gp(x,v))\n        if p>=2:\n            fwd[2] = np.sign(ddg_gp(x,v))\n        if p>=3:\n            fwd[3] = np.sign(dddg_gp(x,v))\n    else:\n        raise ValueError('Unknown method to create forward model')     \n\n    return fwd  ","679e2585":"class ai_capsule():\n    \"\"\"\n        Class that constructs a group of neurons that perform Active Inference for one hidden state, one sensory input, one prior\n        In neurology it could e.g. represent a (micro) column or a neuron assembly\n\n        Version 0.3 including generalised coordinates of motion and action\n    \"\"\"\n    def __init__(self, dt, mu_x_init, p, Sigma_w, Sigma_z, a_mu, a_u, s2_w, s2_z, fwd_method, actiontime):  \n        \n        self.dt = dt    # integration step\n        self.mu_x= mu_x_init # initializing the hidden state, in generalised coordinates of motion\n        self.u = 0      # initialize the control signal as 0, no action\n        self.p = p      # embedding order, number of derevatives in generalised coordinates of motion\n        self.Sigma_w = Sigma_w # Estimated variance of the hidden state equals variance of the prior\n        self.Sigma_z = Sigma_z # Estimated variance of the sensory observation \n        self.s2_w = s2_w # Estimated variance of the Gaussian filter used to create the smoothened noise w\n        self.s2_z = s2_z # Estimated variance of the Gaussian filter used to create the smoothened noise z\n        self.alpha_mu = a_mu # perception learning rate\n        self.alpha_u = a_u # action learning rate \n        self.D = derivativeD(self.p)\n        self.I = np.identity(self.p+1)\n        self.Iv = np.ones((p+1,1))\n        self.Pi_w = inv(np.kron(temporalC(self.p,self.s2_w),self.Sigma_w)) # precision matrix of smoothened noise w\n        self.Pi_z = inv(np.kron(temporalC(self.p,self.s2_z),self.Sigma_z)) # precision matrix of smoothened noise z\n        self.std_vec_inv=standard_vec_inv(p)\n        self.std_vec=standard_vec(p)\n        self.fwd_method = fwd_method\n        self.actiontime = actiontime\n        \n        # Generative model parameters\n        self.a=-1 # generative model function of motion is -mu_x + mu_v, hence a = -1\n        self.b=1 # generative model function of motion is -mu_x + mu_v, hence b = 1\n        #self.c=1 # uncomment in case you want to tst a linear model for sensory observations\n        #self.Ctilde= self.c * self.I # uncomment in case you want to tst a linear model for sensory observations\n    \n    def g(self,x,v):\n        \"\"\"\n            equation of sensory mapping of the generative model: g(x,v) at point x \n            Given as input for this example equal to the true generative process g_gp(x,v)\n        \"\"\"\n        return g_gp(x,v)\n    \n    def dg(self, x,v):\n        \"\"\"\n            Partial derivative of the equation of sensory mapping of the generative model towards x: g'(x,v) at point x \n            Given as input for this example equal to the true derivative of generative process dg_gp(x,v)\n        \"\"\"\n        return dg_gp(x,v)\n    \n    def f(self,x,v):\n        \"\"\"\n            equation of motion of the generative model: f(x,v) at point x \n            f(x,v) = a* mu_x + b* mu_v, where a = -1, b=1\n        \"\"\"\n        return self.a*x + self.b*v\n    \n    def df(self,x,v):\n        \"\"\"\n            Partial derivative of equation of motion of the generative model: f'(x,v) at point x \n        \"\"\"\n        return self.a\n    \n    def ai_step (self, i, mu_v, y):\n        \"\"\"\n        Perform active inference step   \n\n        INPUTS:\n            i       - tic, timestamp\n            mu_v    - Hierarchical prior input signal (mean) at timestamp,  in generalized coordinates of motion\n            y       - sensory input signal at timestamp, in generalized coordinates of motion\n\n        INTERNAL:\n            mu_x      - Belief or hidden state estimation, in generalized coordinates of motion\n\n        \"\"\"\n\n        #-------------------------------#\n        #                               #\n        #           Prediction          #\n        #                               #\n        #-------------------------------#\n        \n        # Note that the predictions are in generalized coordinates of motion  \n        mu_x_hat = self.std_vec*self.f(self.mu_x[0],mu_v[0]) + self.std_vec_inv * self.df(self.mu_x[0],mu_v[0]) * self.mu_x\n        mu_y_hat = self.std_vec*self.g(self.mu_x[0],mu_v[0]) + self.std_vec_inv * self.dg(self.mu_x[0],mu_v[0]) * self.mu_x\n        \n        #-------------------------------#\n        #                               #\n        #        Prediction Error       #\n        #                               #\n        #-------------------------------#\n\n        # Note that the predictions erros are in generalized coordinates of motion \n        \n        eps_x = self.D.dot(self.mu_x) - mu_x_hat  # prediction error hidden state\n        eps_y = y - mu_y_hat #prediction error sensory observation  \n        \n        # In case a linear state space model is used the below calculation is equivalent\n        #eps_x = (self.D-self.Atilde).dot(self.mu_x) - mu_v  # prediction error hidden state\n        #eps_y = y - self.Ctilde.dot(self.mu_x) #prediction error sensory observation\n\n        #-------------------------------#\n        #                               #\n        # Prediction Error minimization #\n        #                               #\n        #-------------------------------#            \n     \n        # Calculate Free Energy to report out\n        F= 0.5*( eps_x.T.dot(self.Pi_w).dot(eps_x) + eps_y.T.dot(self.Pi_z).dot(eps_y)).item(0) \n        # Note, the item(0) is needed to translate the python matrix result to a scaler, e.g. [[1]] to 1\n        \n        # Gradient descent inference\/perception \n        # Note that in this example the function of motion is linear and hence can be calculated as below\n        Atilde=self.a * self.I\n        dFdmu_x = (self.D-Atilde).T.dot(self.Pi_w).dot(eps_x) - (self.dg(self.mu_x[0],mu_v[0]) * self.I ).T.dot(self.Pi_z).dot(eps_y)\n        dmu_x = np.dot(self.D,self.mu_x) - self.alpha_mu * dFdmu_x  \n        self.mu_x = self.mu_x + self.dt * dmu_x\n        \n        # In case a linear state space model is used with linear equation of sensory mapping the below calculation is equivalent\n        #Ctilde=self.c * self.I\n        #dFdmu_x = (self.D-Atilde).T.dot(self.Pi_w).dot(self.eps_x) - Ctilde.T.dot(self.Pi_z).dot(self.eps_y)\n        \n        # Gradient descent action \n        if i>self.actiontime:\n            fwd=fwd_model(self.p, self.mu_x[0], mu_v[0], self.u, self.fwd_method)          \n            dFdu = fwd.T.dot(self.Pi_z).dot(eps_y).item(0)\n            du = -self.alpha_u * dFdu  \n            self.u = self.u + self.dt * du\n        else:\n            self.u=0\n        \n\n        return self.u, F, self.mu_x[0] , self.g(self.mu_x[0],mu_v[0])\n    \n","712d961b":"def simulation (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\n    \"\"\"\n    Simulation for perceptual inference in a dynamic environment with generalised coordinates     \n   \n    INPUTS:\n        v             - Hydars actual desired depth, used in generative model\n        mu_v          - Hydars prior belief\/hypotheses of the desired depth (time series)\n        x_init        - Hydars actual starting depth, used in generative model\n        Sigma_w       - Variance of the hidden state \n        Sigma_z       - Variance of the sensory observation \n        noise_method  - white, smooth or none\n        a_mu          - Learning rate for mu\n        a_u           - Learning rate for u\n        p             - Embedding order of generalised motions of the generative model\n        gen_y_method  - Method to generalize the sensory observations: exact, backward, extend\n        fwd_method    - Method for the foward model: exact, sign \n    VARIABLES:\n        s2_w          - The variance of the Gaussian filter used to create the smoothened noise w\n        s2_z          - The variance of the Gaussian filter used to create the smoothened noise z\n        \n    \"\"\"\n    \n    # Init tracking\n    mu_x = np.zeros(N) # Belief or estimation of hidden state \n    F = np.zeros(N) # Free Energy of AI neuron\n    mu_y = np.zeros(N) # Belief or prediction of sensory signal\n    u = np.zeros(N) # control signal\n\n\n    # Construct noise signals with temporal smoothness:\n    np.random.seed(42)\n    if noise_method == 'white':\n        s2_w= 1e-5\n        s2_z= 1e-5\n    elif noise_method == 'smooth':\n        s2_w= 1\/2000\n        s2_z= 1\/2000\n        # And generate the smooth noise\n        w = makeNoise(Sigma_w,s2_w,t)\n        z = makeNoise(Sigma_z,s2_z,t)\n    else: #no noise\n        s2_w= 1\/64\n        s2_z= 1\/64\n    \n    # Init the generalised process\n    x = np.zeros(N) # True hidden state\n    y = np.zeros(N) # Sensory signal as input to AI neuron\n    x[0] = x_init\n    if noise_method == 'white':\n        y[0]=g_gp(x[0],v) + np.random.randn(1) * Sigma_z\n    elif noise_method == 'smooth':\n        y[0]=g_gp(x[0],v)+ z[0,0] \n    else: #no noise\n        y[0]=g_gp(x[0],v)\n\n    # Create active inference neuron\n    \n    if p<=0:\n        # Not generalised\n        raise ValueError('Select embedding order p > 0') \n    else:\n        # Generalised\n        # initializing the initial hidden state by Hydars best guess: hierarchical prior\n        mu_x_init_tilde = generalize_extend(mu_v[0],p) # generalize the prior\n        capsule = ai_capsule(dt, mu_x_init_tilde, p, Sigma_w, Sigma_z, a_mu, a_u, s2_w, s2_z, fwd_method, actiontime) \n\n    ssim = time.time() # start sim\n    \n    # Simulation\n\n    for i in np.arange(1,N):\n        # Generative process\n        if noise_method == 'white':\n            x_dot= f_gp(x[i-1],v, u[i-1]) + np.random.randn(1) * Sigma_w\n            x[i]= x[i-1] + dt*x_dot\n            y[i] = g_gp(x[i],v) + np.random.randn(1) * Sigma_z\n        elif noise_method == 'smooth':\n            x_dot= f_gp(x[i-1],v,u[i-1]) + w[0,i]\n            x[i]= x[i-1] + dt*x_dot\n            y[i] = g_gp(x[i],v) + z[0,i]\n        else: #no noise\n            x_dot=f_gp(x[i-1],v,u[i-1])\n            x[i]= x[i-1] + dt*x_dot\n            y[i] = g_gp(x[i],v)\n\n\n\n        # Create generalize sensory observations \n        if gen_y_method=='exact':\n            y_tilde = sensor_generalize_exact(y[i],p,x[i],v,u[i-1])\n            #print(y_tilde)\n        elif gen_y_method=='backward':\n            y_tilde = sensor_generalize_backward(y,i,p)\n        elif gen_y_method=='extend':\n            y_tilde = generalize_extend(y[i],p)\n        else:\n            raise ValueError('Unknown method to create sensory observation in generalised coordinates of motion')     \n        \n        # Active inference step       \n        mu_v_tilde=generalize_extend(mu_v[i],p)\n        u[i], F[i], mu_x[i], mu_y[i] = capsule.ai_step(i,mu_v_tilde,y_tilde)\n\n    \n    # Print the results\n    tsim = time.time() - ssim\n    #print('Simulation time: ' + \"%.2f\" % tsim + ' sec' )\n\n    return F, mu_x, mu_y, x, y, u","7c545969":"x_init = 30.0 # generative process initial depth Hydar\nv = 0 # in this example v is not used\nmu_v = np.ones(N) * 25.0 # generative model, Hydars prior belief of the (target) depth\nactiontime=0.20\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.1,'no noise',1,50,1,'exact','exact', actiontime*N) # \n\nprint('w covariance matrix = ')\nprint(np.kron(temporalC(1,1\/64),0.1) )\nprint('z covariance matrix = ')\nprint(np.kron(temporalC(1,1\/64),0.1) )\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action');\naxes[0].plot(t[1:],mu_x1[1:],label='belief $\\mu$');\naxes[0].plot(t[1:],x1[1:],label='Generative process');\naxes[0].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],mu_y1[1:],label='belief');\naxes[1].plot(t[1:],y1[1:],label='Generative process');\naxes[1].plot(t[1:],g_gp(mu_v[1:],0),label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal u');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\n#axes[3].semilogy(t[1:],F3[1:],label='p=3');\naxes[3].plot(t[1:],F1[1:],label='Free Energy');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n\n","38d2cfc5":"x_init = 25.0 # generative process initial depth Hydar\nv = 0 # in this example v is not used\nmu_v = np.ones(N) * 25.0 # generative model, Hydars prior belief of the (target) depth\n\nactiontime=0.20\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.1,'no noise',1,50,1,'exact','exact', actiontime*N) # \n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action');\naxes[0].plot(t[1:],mu_x1[1:],label='belief $\\mu$');\naxes[0].plot(t[1:],x1[1:],label='Generative process');\naxes[0].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],mu_y1[1:],label='belief');\naxes[1].plot(t[1:],y1[1:],label='Generative process');\naxes[1].plot(t[1:],g_gp(mu_v[1:],0),label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal u');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\n#axes[3].semilogy(t[1:],F3[1:],label='p=3');\naxes[3].plot(t[1:],F1[1:],label='Free Energy');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n","f1d732ab":"x_init = 30.0 # generative process initial depth Hydar\nv = 0 # in this example v is not used\nmu_v = np.ones(N) * 25.0 # generative model, Hydars prior belief of the (target) depth\n\nactiontime=0.20\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.1,'no noise',1,50,1,'exact','exact', actiontime*N) # exact forward model\nF2, mu_x2, mu_y2, x2, y2, u2 = simulation(v,mu_v,x_init,0.1,0.1,'no noise',1,1,1,'exact','sign', actiontime*N) # approximated forward model (-1)\n\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action');\naxes[0].plot(t[1:],mu_x1[1:],label='belief with exact fwd model');\naxes[0].plot(t[1:],mu_x2[1:],label='belief with approximated fwd model');\naxes[0].plot(t[1:],x1[1:],label='Generative process with exact fwd model');\naxes[0].plot(t[1:],x2[1:],label='Generative process with approximated fwd model');\naxes[0].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],mu_y1[1:],label='belief with exact fwd model');\naxes[1].plot(t[1:],mu_y1[1:],label='belief with approximated fwd model');\naxes[1].plot(t[1:],y1[1:],label='Generative process with exact fwd model');\naxes[1].plot(t[1:],y2[1:],label='Generative process with approximated fwd model');\naxes[1].plot(t[1:],g_gp(mu_v[1:],0),label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\n#axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal exact fwd model');\naxes[2].plot(t[1:],u2[1:],label='Control signal approximated fwd model');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\naxes[3].plot(t[1:],F1[1:],label='Free Energy exact fwd model');\naxes[3].plot(t[1:],F2[1:],label='Free Energy approximated fwd model');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);","77f8ecee":"x_init = 30.0 # generative process initial depth Hydar\nv = 0 # in this example v is not used\nmu_v = np.ones(N) * 25.0 # generative model, Hydars prior belief of the (target) depth\n\nactiontime=0.20\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.1,'no noise',1,200,1,'exact','exact', actiontime*N) # p=1\nF2, mu_x2, mu_y2, x2, y2, u2 = simulation(v,mu_v,x_init,0.1,0.1,'no noise',1,200,2,'exact','exact', actiontime*N) # p=2\nF3, mu_x3, mu_y3, x3, y3, u3 = simulation(v,mu_v,x_init,0.1,0.1,'no noise',1,200,3,'exact','exact', actiontime*N) # p=3\n\nMSE1=sum((mu_y1-y1)**2)\nprint ('Mean Squared Error embedding order 1 is: ', MSE1)\nMSE2=sum((mu_y2-y2)**2)\nprint ('Mean Squared Error embedding order 2 is: ', MSE2)\nMSE3=sum((mu_y3-y3)**2)\nprint ('Mean Squared Error embedding order 3 is: ', MSE3)\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with generalised motions');\n\naxes[0].plot(t[1:],mu_x1[1:],label='belief p=1');\naxes[0].plot(t[1:],mu_x2[1:],label='belief p=2');\naxes[0].plot(t[1:],mu_x3[1:],label='belief p=3');\naxes[0].plot(t[1:],x1[1:],label='Depth'); # to avoid cluttering the graph only show the actuals of embedding order 1\naxes[0].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\nfig.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],mu_y1[1:],label='belief p=1');\naxes[1].plot(t[1:],mu_y2[1:],label='belief p=2');\naxes[1].plot(t[1:],mu_y3[1:],label='belief p=3');\naxes[1].plot(t[1:],y1[1:],label='Temperature');  # to avoid cluttering the graph only show the actuals of embedding order 1\naxes[1].plot(t[1:],g_gp(mu_v[1:],0),label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal p=1');\naxes[2].plot(t[1:],u2[1:],label='Control signal p=2');\naxes[2].plot(t[1:],u3[1:],label='Control signal p=3');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].grid(1);\n\naxes[3].plot(t[1:],F1[1:],label='p=1');\naxes[3].plot(t[1:],F2[1:],label='p=2');\naxes[3].plot(t[1:],F3[1:],label='p=3');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].grid(1);","762e3b27":"x_init = 30.0 # generative process initial depth Hydar\nv = 0 # in this example v is not used\nmu_v = np.ones(N) * 25.0 # generative model, Hydars prior belief of the (target) depth\n\nactiontime=0.20\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.1,'smooth',1,1500,1,'exact','exact', actiontime*N) # \nF2, mu_x2, mu_y2, x2, y2, u2 = simulation(v,mu_v,x_init,0.1,0.1,'smooth',1,50,1,'exact','exact', actiontime*N) # \n\nprint('w covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),0.1) )\nprint('z covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),0.1) )\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action');\naxes[0].plot(t[1:],mu_x1[1:],label='belief with LR 1500');\naxes[0].plot(t[1:],mu_x2[1:],label='belief with LR 50');\naxes[0].plot(t[1:],x1[1:],label='Generative process with LR 1500');\naxes[0].plot(t[1:],x2[1:],label='Generative process with LR 50');\naxes[0].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],mu_y1[1:],label='belief with LR 1500');\naxes[1].plot(t[1:],mu_y1[1:],label='belief with LR 50');\naxes[1].plot(t[1:],y1[1:],label='Generative process with LR 1500');\naxes[1].plot(t[1:],y2[1:],label='Generative process with LR 50');\naxes[1].plot(t[1:],g_gp(mu_v[1:],0),label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\n#axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal LR 1500');\naxes[2].plot(t[1:],u2[1:],label='Control signal LR 50');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\naxes[3].plot(t[1:],F1[1:],label='Free Energy LR 1500');\naxes[3].plot(t[1:],F2[1:],label='Free Energy LR 50');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);","db5bd69e":"x_init = 30.0 # generative process initial depth Hydar\nv = 0 # in this example v is not used\nmu_v = np.ones(N) * 25.0 # generative model, Hydars prior belief of the (target) depth\n\nactiontime=0.20\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.1,'white',1,80000,1,'exact','exact', actiontime*N) # \nF2, mu_x2, mu_y2, x2, y2, u2 = simulation(v,mu_v,x_init,0.1,0.1,'white',1,1500,1,'exact','exact', actiontime*N) # \n\nprint('w covariance matrix = ')\nprint(np.kron(temporalC(1,1e-5),0.1) )\nprint('z covariance matrix = ')\nprint(np.kron(temporalC(1,1e-5),0.1) )\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action');\naxes[0].plot(t[1:],mu_x1[1:],label='belief with LR 80000');\naxes[0].plot(t[1:],mu_x2[1:],label='belief with LR 1500');\naxes[0].plot(t[1:],x1[1:],label='Generative process with LR 80000');\naxes[0].plot(t[1:],x2[1:],label='Generative process with LR 1500');\naxes[0].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],mu_y1[1:],label='belief with LR 80000');\naxes[1].plot(t[1:],mu_y1[1:],label='belief with LR 1500');\naxes[1].plot(t[1:],y1[1:],label='Generative process with LR 80000');\naxes[1].plot(t[1:],y2[1:],label='Generative process with LR 1500');\naxes[1].plot(t[1:],g_gp(mu_v[1:],0),label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\n#axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal LR 80000');\naxes[2].plot(t[1:],u2[1:],label='Control signal LR 1500');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\naxes[3].plot(t[1:],F1[1:],label='Free Energy LR 80000');\naxes[3].plot(t[1:],F2[1:],label='Free Energy LR 1500');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);","121a0dd0":"x_init = 30.0 # generative process initial depth Hydar\nv = 0 # in this example v is not used\nmu_v = np.ones(N) * 25.0 # generative model, Hydars prior belief of the (target) depth\n\nactiontime=0.20\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.1,'smooth',1,1500,1,'exact','exact', actiontime*N) # \nF2, mu_x2, mu_y2, x2, y2, u2 = simulation(v,mu_v,x_init,1,1,'smooth',1, 1500,1,'exact','exact', actiontime*N) #\nF3, mu_x3, mu_y3, x3, y3, u3 = simulation(v,mu_v,x_init,1,1,'smooth',1, 15000,1,'exact','exact', actiontime*N) #\nF4, mu_x4, mu_y4, x4, y4, u4 = simulation(v,mu_v,x_init,1,1,'smooth',10, 15000,1,'exact','exact', actiontime*N) # \n\nprint(\"Standard Deviation =0.1\")\nprint('w covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),0.1) )\nprint('z covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),0.1) )\nprint(\"Standard Deviation =1\")\nprint('w covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),1) )\nprint('z covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),1) )\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action');\naxes[0].plot(t[1:],mu_x1[1:],label='belief with $\\sigma_w = \\sigma_z = 0.1; u_{LR}=1500; \\mu_{LR}=1$');\naxes[0].plot(t[1:],mu_x2[1:],label='belief with $\\sigma_w = \\sigma_z = 1; u_{LR}=1500; \\mu_{LR}=1$');\naxes[0].plot(t[1:],x1[1:],label='Generative process with $\\sigma_w = \\sigma_z = 0.1; u_{LR}=1500; \\mu_{LR}=1$');\naxes[0].plot(t[1:],x2[1:],label='Generative process with $\\sigma_w = \\sigma_z = 1; u_{LR}=1500; \\mu_{LR}=1$');\naxes[0].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],mu_y1[1:],label='belief with $\\sigma_w = \\sigma_z = 0.1; u_{LR}=1500; \\mu_{LR}=1$');\naxes[1].plot(t[1:],mu_y2[1:],label='belief with $\\sigma_w = \\sigma_z = 1; u_{LR}=1500; \\mu_{LR}=1$');\naxes[1].plot(t[1:],y1[1:],label='Generative process with $\\sigma_w = \\sigma_z = 0.1; u_{LR}=1500; \\mu_{LR}=1$');\naxes[1].plot(t[1:],y2[1:],label='Generative process with $\\sigma_w = \\sigma_z = 1; u_{LR}=1500; \\mu_{LR}=1$');\naxes[1].plot(t[1:],g_gp(mu_v[1:],0),label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\n#axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal $\\sigma_w = \\sigma_z = 0.1; u_{LR}=1500; \\mu_{LR}=1$');\naxes[2].plot(t[1:],u2[1:],label='Control signal $\\sigma_w = \\sigma_z = 1; u_{LR}=1500; \\mu_{LR}=1$');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\naxes[3].plot(t[1:],F1[1:],label='Free Energy $\\sigma_w = \\sigma_z = 0.1; u_{LR}=1500; \\mu_{LR}=1$');\naxes[3].plot(t[1:],F2[1:],label='Free Energy $\\sigma_w = \\sigma_z = 1; u_{LR}=1500; \\mu_{LR}=1$');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action');\naxes[0].plot(t[1:],mu_x3[1:],label='belief with $\\sigma_w = \\sigma_z = 0.1; u_{LR}=15000; \\mu_{LR}=1$');\naxes[0].plot(t[1:],mu_x4[1:],label='belief with $\\sigma_w = \\sigma_z = 1; u_{LR}=15000; \\mu_{LR}=10$');\naxes[0].plot(t[1:],x3[1:],label='Generative process with $\\sigma_w = \\sigma_z = 0.1; u_{LR}=15000; \\mu_{LR}=1$');\naxes[0].plot(t[1:],x4[1:],label='Generative process with $\\sigma_w = \\sigma_z = 1; u_{LR}=15000; \\mu_{LR}=10$');\naxes[0].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],mu_y3[1:],label='belief with $\\sigma_w = \\sigma_z = 0.1; u_{LR}=15000; \\mu_{LR}=1$');\naxes[1].plot(t[1:],mu_y4[1:],label='belief with $\\sigma_w = \\sigma_z = 1; u_{LR}=15000; \\mu_{LR}=10$');\naxes[1].plot(t[1:],y3[1:],label='Generative process with $\\sigma_w = \\sigma_z = 0.1; u_{LR}=15000; \\mu_{LR}=1$');\naxes[1].plot(t[1:],y4[1:],label='Generative process with $\\sigma_w = \\sigma_z = 1; u_{LR}=15000; \\mu_{LR}=10$');\naxes[1].plot(t[1:],g_gp(mu_v[1:],0),label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\n#axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u3[1:],label='Control signal $\\sigma_w = \\sigma_z = 0.1; u_{LR}=15000; \\mu_{LR}=1$');\naxes[2].plot(t[1:],u4[1:],label='Control signal $\\sigma_w = \\sigma_z = 1; u_{LR}=15000; \\mu_{LR}=10$');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\naxes[3].plot(t[1:],F3[1:],label='Free Energy $\\sigma_w = \\sigma_z = 0.1; u_{LR}=15000; \\mu_{LR}=1$');\naxes[3].plot(t[1:],F4[1:],label='Free Energy $\\sigma_w = \\sigma_z = 1; u_{LR}=15000; \\mu_{LR}=10$');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);","ce7cba24":"x_init = 30.0 # generative process initial depth Hydar\nv = 0 # in this example v is not used\nmu_v = np.ones(N) * 25.0 # generative model, Hydars prior belief of the (target) depth\n\nactiontime=0.20\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.1,'smooth',1,50,1,'exact','exact', actiontime*N) # \nF2, mu_x2, mu_y2, x2, y2, u2 = simulation(v,mu_v,x_init,0.1,0.1,'smooth',1,1500,1,'exact','exact', actiontime*N) # \nF3, mu_x3, mu_y3, x3, y3, u3 = simulation(v,mu_v,x_init,0.1,0.1,'smooth',1,15000,1,'exact','exact', actiontime*N) # \nF4, mu_x4, mu_y4, x4, y4, u4 = simulation(v,mu_v,x_init,0.1,0.1,'smooth',1,60000,1,'exact','exact', actiontime*N) # \nF5, mu_x5, mu_y5, x5, y5, u5 = simulation(v,mu_v,x_init,0.1,0.1,'smooth',1,120000,1,'exact','exact', actiontime*N) # \n\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action');\naxes[0].plot(t[1:],mu_x1[1:],label='belief with LR 50');\naxes[0].plot(t[1:],mu_x2[1:],label='belief with LR 1500');\naxes[0].plot(t[1:],x1[1:],label='Generative process with LR 50');\naxes[0].plot(t[1:],x2[1:],label='Generative process with LR 1500');\naxes[0].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],mu_y1[1:],label='belief with LR 50');\naxes[1].plot(t[1:],mu_y1[1:],label='belief with LR 1500');\naxes[1].plot(t[1:],y1[1:],label='Generative process with LR 50');\naxes[1].plot(t[1:],y2[1:],label='Generative process with LR 1500');\naxes[1].plot(t[1:],g_gp(mu_v[1:],0),label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\n#axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal LR 50');\naxes[2].plot(t[1:],u2[1:],label='Control signal LR 1500');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\naxes[3].plot(t[1:],F1[1:],label='Free Energy LR 50');\naxes[3].plot(t[1:],F2[1:],label='Free Energy LR 1500');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action');\naxes[0].plot(t[1:],mu_x3[1:],label='belief with LR 15000');\naxes[0].plot(t[1:],mu_x4[1:],label='belief with LR 60000');\naxes[0].plot(t[1:],x3[1:],label='Generative process with LR 15000');\naxes[0].plot(t[1:],x4[1:],label='Generative process with LR 60000');\naxes[0].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],mu_y3[1:],label='belief with LR 15000');\naxes[1].plot(t[1:],mu_y4[1:],label='belief with LR 60000');\naxes[1].plot(t[1:],y3[1:],label='Generative process with LR 15000');\naxes[1].plot(t[1:],y4[1:],label='Generative process with LR 60000');\naxes[1].plot(t[1:],g_gp(mu_v[1:],0),label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\n#axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u3[1:],label='Control signal LR 15000');\naxes[2].plot(t[1:],u4[1:],label='Control signal LR 60000');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\naxes[3].plot(t[1:],F3[1:],label='Free Energy LR 15000');\naxes[3].plot(t[1:],F4[1:],label='Free Energy LR 60000');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action');\naxes[0].plot(t[1:],mu_x5[1:],label='belief with LR 120000');\naxes[0].plot(t[1:],x5[1:],label='Generative process with LR 120000');\naxes[0].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],mu_y5[1:],label='belief with LR 120000');\naxes[1].plot(t[1:],y5[1:],label='Generative process with LR 120000');\naxes[1].plot(t[1:],g_gp(mu_v[1:],0),label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\n#axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u5[1:],label='Control signal LR 120000');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\naxes[3].plot(t[1:],F5[1:],label='Free Energy LR 120000');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);","cdaceeba":"x_init = 30.0 # generative process initial depth Hydar\nv = 0 # in this example v is not used\nmu_v = np.ones(N) * 25.0 # generative model, Hydars prior belief of the (target) depth\nactiontime=0.20\n\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.1,'no noise',1,50,1,'exact','exact', actiontime*N) # \nF2, mu_x2, mu_y2, x2, y2, u2 = simulation(v,mu_v,x_init,10,0.1,'no noise',1, 50,1,'exact','exact', actiontime*N) # \nF3, mu_x3, mu_y3, x3, y3, u3 = simulation(v,mu_v,x_init, 0.1,10,'no noise',1, 50,1,'exact','exact', actiontime*N) # \n\n\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action');\naxes[0].plot(t[1:],mu_x1[1:],label='belief with $\\sigma_w = \\sigma_z = $ 0.1');\naxes[0].plot(t[1:],mu_x3[1:],label='belief with $\\sigma_z =$ 10 and $ \\sigma_w = $ 0.1');\naxes[0].plot(t[1:],x1[1:],label='Generative process with $\\sigma_w = \\sigma_z = $ 0.1');\naxes[0].plot(t[1:],x3[1:],label='Generative process with $\\sigma_z =$ 10 and $ \\sigma_w = $ 0.1');\naxes[0].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],mu_y1[1:],label='belief with $\\sigma_w = \\sigma_z = $ 0.1');\naxes[1].plot(t[1:],mu_y3[1:],label='belief with $\\sigma_z =$ 10 and $ \\sigma_w = $ 0.1');\naxes[1].plot(t[1:],y1[1:],label='Generative process with $\\sigma_w = \\sigma_z = $ 0.1');\naxes[1].plot(t[1:],y3[1:],label='Generative process with $\\sigma_z =$ 10 and $ \\sigma_w = $ 0.1');\naxes[1].plot(t[1:],g_gp(mu_v[1:],0),label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\n#axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal $\\sigma_w = \\sigma_z = $ 0.1');\naxes[2].plot(t[1:],u3[1:],label='Control signal $\\sigma_z =$ 10 and $ \\sigma_w = $ 0.1');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\naxes[3].plot(t[1:],F1[1:],label='Free Energy $\\sigma_w = \\sigma_z = $ 0.1');\naxes[3].plot(t[1:],F3[1:],label='Free Energy $\\sigma_z =$ 10 and $ \\sigma_w = $ 0.1');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action');\naxes[0].plot(t[1:],mu_x1[1:],label='belief with $\\sigma_w = \\sigma_z = $ 0.1');\naxes[0].plot(t[1:],mu_x2[1:],label='belief with $\\sigma_w =$ 10 and $ \\sigma_z = $ 0.1');\naxes[0].plot(t[1:],x1[1:],label='Generative process with $\\sigma_w = \\sigma_z = $ 0.1');\naxes[0].plot(t[1:],x2[1:],label='Generative process with $\\sigma_w =$ 10 and $ \\sigma_z = $ 0.1');\naxes[0].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],mu_y1[1:],label='belief with $\\sigma_w = \\sigma_z = $ 0.1');\naxes[1].plot(t[1:],mu_y2[1:],label='belief with $\\sigma_w =$ 10 and $ \\sigma_z = $ 0.1');\naxes[1].plot(t[1:],y1[1:],label='Generative process with $\\sigma_w = \\sigma_z = $ 0.1');\naxes[1].plot(t[1:],y2[1:],label='Generative process with $\\sigma_w =$ 10 and $ \\sigma_z = $ 0.1');\naxes[1].plot(t[1:],g_gp(mu_v[1:],0),label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\n#axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal $\\sigma_w = \\sigma_z = $ 0.1');\naxes[2].plot(t[1:],u2[1:],label='Control signal $\\sigma_w =$ 10 and $ \\sigma_z = $ 0.1');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\naxes[3].plot(t[1:],F1[1:],label='Free Energy $\\sigma_w = \\sigma_z = $ 0.1');\naxes[3].plot(t[1:],F2[1:],label='Free Energy $\\sigma_w =$ 10 and $ \\sigma_z = $ 0.1');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);","389efca1":"from scipy import signal\nx_init = 30.0 # generative process initial depth Hydar\nv = 0 # in this example v is not used\nmu_v = np.ones(N) * 30.0 # generative model, Hydars prior belief of the (target) depth\nbump = signal.gaussian(400, std=30)*5\nmu_v[600:1000]=30-bump\nactiontime=0.20\n\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.1,'no noise',1,50,1,'exact','exact', actiontime*N) # \nF2, mu_x2, mu_y2, x2, y2, u2 = simulation(v,mu_v,x_init,10,0.1,'no noise',1, 50,1,'exact','exact', actiontime*N) # \nF3, mu_x3, mu_y3, x3, y3, u3 = simulation(v,mu_v,x_init, 0.1,10,'no noise',1, 50,1,'exact','exact', actiontime*N) # \n\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action');\naxes[0].plot(t[1:],mu_x1[1:],label='belief with $\\sigma_w = \\sigma_z = $ 0.1');\naxes[0].plot(t[1:],mu_x3[1:],label='belief with $\\sigma_z =$ 10 and $ \\sigma_w = $ 0.1');\naxes[0].plot(t[1:],x1[1:],label='Generative process with $\\sigma_w = \\sigma_z = $ 0.1');\naxes[0].plot(t[1:],x3[1:],label='Generative process with $\\sigma_z =$ 10 and $ \\sigma_w = $ 0.1');\naxes[0].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],mu_y1[1:],label='belief with $\\sigma_w = \\sigma_z = $ 0.1');\naxes[1].plot(t[1:],mu_y3[1:],label='belief with $\\sigma_z =$ 10 and $ \\sigma_w = $ 0.1');\naxes[1].plot(t[1:],y1[1:],label='Generative process with $\\sigma_w = \\sigma_z = $ 0.1');\naxes[1].plot(t[1:],y3[1:],label='Generative process with $\\sigma_z =$ 10 and $ \\sigma_w = $ 0.1');\naxes[1].plot(t[1:],g_gp(mu_v[1:],0),label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\n#axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal $\\sigma_w = \\sigma_z = $ 0.1');\naxes[2].plot(t[1:],u3[1:],label='Control signal $\\sigma_z =$ 10 and $ \\sigma_w = $ 0.1');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\naxes[3].plot(t[1:],F1[1:],label='Free Energy $\\sigma_w = \\sigma_z = $ 0.1');\naxes[3].plot(t[1:],F3[1:],label='Free Energy $\\sigma_z =$ 10 and $ \\sigma_w = $ 0.1');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action');\naxes[0].plot(t[1:],mu_x1[1:],label='belief with $\\sigma_w = \\sigma_z = $ 0.1');\naxes[0].plot(t[1:],mu_x2[1:],label='belief with $\\sigma_w =$ 10 and $ \\sigma_z = $ 0.1');\naxes[0].plot(t[1:],x1[1:],label='Generative process with $\\sigma_w = \\sigma_z = $ 0.1');\naxes[0].plot(t[1:],x2[1:],label='Generative process with $\\sigma_w =$ 10 and $ \\sigma_z = $ 0.1');\naxes[0].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],mu_y1[1:],label='belief with $\\sigma_w = \\sigma_z = $ 0.1');\naxes[1].plot(t[1:],mu_y2[1:],label='belief with $\\sigma_w =$ 10 and $ \\sigma_z = $ 0.1');\naxes[1].plot(t[1:],y1[1:],label='Generative process with $\\sigma_w = \\sigma_z = $ 0.1');\naxes[1].plot(t[1:],y2[1:],label='Generative process with $\\sigma_w =$ 10 and $ \\sigma_z = $ 0.1');\naxes[1].plot(t[1:],g_gp(mu_v[1:],0),label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\n#axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal $\\sigma_w = \\sigma_z = $ 0.1');\naxes[2].plot(t[1:],u2[1:],label='Control signal $\\sigma_w =$ 10 and $ \\sigma_z = $ 0.1');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\naxes[3].plot(t[1:],F1[1:],label='Free Energy $\\sigma_w = \\sigma_z = $ 0.1');\naxes[3].plot(t[1:],F2[1:],label='Free Energy $\\sigma_w =$ 10 and $ \\sigma_z = $ 0.1');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n","dc96bd34":"from scipy import signal\nx_init = 30.0 # generative process initial depth Hydar\nv = 0 # in this example v is not used\nmu_v = np.ones(N) * 30.0 # generative model, Hydars prior belief of the (target) depth\nbump = signal.gaussian(400, std=60)*5\nmu_v[600:1000]=30-bump\nactiontime=0.20\n\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.03,10,'no noise',5,1200,1,'exact','sign', actiontime*N) # \n\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action');\naxes[0].plot(t[1:],mu_x1[1:],label='belief');\n\naxes[0].plot(t[1:],x1[1:],label='Generative process');\n\naxes[0].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\naxes[1].plot(t[1:],mu_y1[1:],label='belief');\naxes[1].plot(t[1:],y1[1:],label='Generative process');\naxes[1].plot(t[1:],g_gp(mu_v[1:],0),label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\n#axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\naxes[2].plot(t[1:],u1[1:],label='Control signal ');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\naxes[3].plot(t[1:],F1[1:],label='Free Energy ');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n\n","3cebc080":"\nx_init = 25.0 # generative process initial depth Hydar\nv = 0 # in this example v is not used\nmu_v = 25 + np.sin(t*3)*15 # generative model, Hydars prior belief of the (target) depth\nactiontime=0.0\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.03,10,'no noise',5,1800,1,'exact','sign', actiontime*N) # \n\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action');\naxes[0].plot(t[1:],mu_x1[1:],label='belief $\\mu$');\naxes[0].plot(t[1:],x1[1:],label='Generative process');\naxes[0].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],mu_y1[1:],label='belief');\naxes[1].plot(t[1:],y1[1:],label='Generative process');\naxes[1].plot(t[1:],g_gp(mu_v[1:],0),label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal u');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\n#axes[3].semilogy(t[1:],F3[1:],label='p=3');\naxes[3].plot(t[1:],F1[1:],label='Free Energy');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n\n","e562fd11":"# Experiments\nLet's see the theory in action and showcase active inference in our simulation environment. In these examples, Hydar can influence its body temperature because it the capability to move up and down into warmer or colder water. It will do so by minimizing the Free Energy of its biased generative model. It is biased because Hydar believes it is moving towards its hierarchical prior $\\mu_v$.\n","00317346":"### Notes\n+ In the first block are the results of high precision on the prior $\\sigma_w = 0.1$ and low precision on the sensory observation $\\sigma_z = 10$. The internal belief follows the prior most (orange line), which can be explained by perceptual inference because the prior expectation error is a factor 100 more weighted. The resulting action is (almost) none, which can be explained because sensory prediction errors are divided by 10. The prediction error increases during the gaussian bump but apparently not enough to get action. By increasing the action LR, it can still be (moderately) invoked.\n+ In the second block are the results of a low precision on the prior $\\sigma_w = 10$ and high precision on the sensory observation $\\sigma_z = 0.1$. The internal belief does not follow the prior (orange line), which can be explained by perceptual inference because the prior expectation is a factor 100 less weighted. The resulting action is (almost) none, which can be explained because there are hardly sensory prediction errors. By increasing the LR for $\\mu$, action can still be moderately invoked because the internal belief starts to follow the prior expectation.\n","e8524596":"## Experiment 4.06 - White noise\nSame set-up as experiment 4.01 but now with some actual white noise in the generative process.","82640a28":"## Experiment 4.10 - Invoking action - part 2\nIn the previous experiment prior belief and the actual sensory measuraments were different from the start, and perceptual inference was already closing the gap in the first 2 seconds even before action. In this experiment, Hydar starts with the prior belief and sensory measurements aligned (30 centimeters), and only after 6 seconds Hydar changes its mind to a prior belief of 25 centimeters causing action. Also, the prior expectation is modeled as a Gaussian bump, which is often used in Free Energy papers. Will it give different insights?","a6d222db":"## Long live Hydar!\n\nAs introduced in the 4th notebook, [Hydar](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-4\/#sec4) is an early evolutionary imaginary aquatic ancestor that must preserve its physical integrity to survive. For example, it needs to keep in a certain depth range to keep its temperature.  \n\nRemember from the [first notebook](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-1) that in essence, the brain is a prediction mechanism, one that attempts to minimize the error of its hypothesis about the world and the sensory input it receives:\n* The skull-bound brain needs to infer the world.\n* The brain builds an internal model of the world using Bayesian inference (the generative model).\n* Discrepancies between the internal model (the prediction) and the sensory observations result in prediction error.\n* The brain aims to minimize the Free Energy which is equivalent to minimizing prediction errors.\n* By Improving perception, Acting on the environment, Learning the generative model, Optimizing expected precision of uncertainty. \n\nThe scope of this notebook is improving perception and acting on the environment. In this example, Hydar's brain is equipped with one active inference capsule to encode the generative model. With one single sensor (y), in this case to measure the temperature, one hidden state it tries to infer (x), in this case the depth, and one prior (v) representing its top-down hypotheses of the hidden state\/depth. Hydar has one control signal (u) it can activate, in this case Hydra can set its own speed  u=x'  . Hydar lives in a one-dimensional plane and it can go up and down. \n\n<img src=\"https:\/\/i.imgur.com\/Xa0vKSs.jpg\" width=800>","82b2763a":"# Scope code example 4\nThe fourth code example is a use-case including action. It builds upon the inference capability of the [second code example notebook](https:\/\/www.kaggle.com\/charel\/active-inference-code-by-example-2\/) (active inference with generalised coordinates of motion) and adds action as a way to minimize the free energy as well.\n\nScope of the example: \n* One active inference capsule (single hidden state x, single sensory channel y, and single hierarchical prior v) \n* With the capability to act upon the environment\n* With generalized coordinates of motion  \n* Dynamic environment\n* The generative model $\\mu_\\theta$ and expected precision of uncertainty $\\mu_\\lambda$ are invariant during the process and for this example given as input. Remember ${\\mu}_x$ is estimated by fast neuronal states while $\\mu_\\theta$ and $\\mu_\\lambda$ adapt on slower timescales (e.g. synaptic efficacy) so invariant during action and perceptual inference. We simply assume the generative model \/ noise estimation has already been learned and is known (so, the function of motion and sensory mapping are given as input).   \n* The brain estimate for the hierarchical prior ($\\mu_v)$ is given as input, which is the prior in this context\n* Active inference by minimizing the Free Energy for one active inference capsule:   \n\n$$\\tilde \\mu_x=\\underset{\\tilde \\mu_x }{Argmin}\\:  \\mathcal{F}( \\tilde y,\\mu) \\: \\: \\: \\:  \\: \\: \\: \\: u=\\underset{\\tilde u }{Argmin}\\:  \\mathcal{F}( \\tilde y,\\mu)$$ \n* by iteratively taking steps proportional to the negative of the partial derivative of the Free Energy with respect to $\\mu_x$ resp $u$.\n","93ab31ba":"### Notes\n+ In this experiment, it becomes quickly clear that the learning rate for the action (control signal) is important. As you can see in the graph it needed to increase by a factor of 30 to get to similar performance as observed in experiment 4.01\n+ The main culprit for the need for a significant increase in the learning rate is the precision matrix for no-noise vs smooth-noise. For comparison, I printed the covariance matrix (inverse of the precision matrix) where you see an increase from 3 to 100 in the second-order compared to the covariance matrix of the first experiment. In the exact fwd method calculation, the first entry of the fwd model is 0 because $\\frac{\\partial y}{\\partial u} = 0$, so the 0.1 in the covariance matrix is not relevant; only prediction errors on the higher derivatives (e.g. speed, acceleration, etc) are relevant.\n","91677719":"## Experiment 4.03 - Different forward models\nAs written in the fifth notebook, in the real world the true time-varying forward can only be approximated. It is approximated with a constant (simple +1 or -1, the sign is important, the direction of the force) and the learning rate  $a_u$  is used as a tuning parameter to achieve sufficiently fast action updates. This experiment is to compare an exact forward model versus an approximated forward model. ","ae36f98d":"### Notes\nAs expected: \n+ the sensor readings and prior confirm immediately, only 1 observation needed for Hydar to know its depth. \n+ No action\n+ The Free Energy is zero, optimal","3b311f0f":"### Notes\nHydar starts at 30 centimeters depth while its biased generative model believes it should be moving to 25 centimeters. \n* During the first 2 seconds, Hydar cannot move yet and the prediction error between temperature readings indicating a depth of 30 centimeters and its own biased generative model of movement towards 25 centimeters is 'explained away' by estimating a depth of 27 meters. It is the same perceptual inference as in the previous notebooks.\n* After 2 seconds Hydar does take action and the active part of active inference causes Hydar to move. Action as the result of lowering the Free Energy to fulfill Hydar's own predictions in the biased generative model. Hydar successfully moves to a depth of 25 centimeters with a temperature of 17 degrees\n* Note that during the perceptual inference part (first 2 seconds) the Free Energy was lowered to a certain level. And with the action capabilities after the 2 seconds, the Free Energy is decreased further.  \n\nHydar can act on the environment! It has the capability to take action and move to an expected depth\/temperature.","6434a2d7":"# Generative process\n\nThe generative process (the simulation environment simulating the external environment\/world generating the sensory states in this example) is defined by :\n\n$$ \\begin{align*} \\dot x = f_{gp}(x,v,u) + w &\\Rightarrow  \\dot x = a_{gp}x + b_{gp}u + w \\: \\: ; a_{gp}=0, b_{gp}=1\\\\\ny = g_{gp}(x,v)+z &\\Rightarrow y = t_0 -\\frac{16}{1+e^{5-\\frac{x}{5}}}+ z \\: \\:; t_0=25 \\end{align*}$$   \n  \nwhere\n* $x$ is the position (depth in centimetres) and $\\dot x$ expresses the motion of $x$\n* $y$ is the temperature (degrees Celsius)\n* u  is the control signal, the action that can be performed on the environment.\n* The function of motion $f_{gp}(x,v,u)$ of this example is linear and  defined as  $f_{gp}(x,v,u) = u$ . In the software below more generic implemented as  $a_{gp}x+b_{gp}u$  where  $a_{gp}=0$ and $b_{gp}=1$ . In other words,  basically Hydra can set its own speed $\\dot x = u + random fluctuations$\n* The function of sensory mapping  $g_{gp}(x,v)$  of this example is the same as previous examples","3b6df277":"## How the brain might function - code example 4\n### Free Energy Principle tutorial without a PhD\n  \n<img src=\"https:\/\/cdn.pixabay.com\/photo\/2018\/05\/08\/08\/44\/artificial-intelligence-3382507_960_720.jpg\" width=500>\n<center>Image by <a href=\"https:\/\/pixabay.com\/users\/geralt-9301\/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3382507\">Gerd Altmann<\/a> from <a href=\"https:\/\/pixabay.com\/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3382507\">Pixabay<\/a> <\/center>   \n<br>\n\nWelcome to my notebook on Kaggle. I did record my notes with examples so it might help others in their journey to understand **Active Inference** minimizing the underlying **Free Energy**. Neuroscience has produced a candidate which suggests that several global brain theories might be unified within a free-energy framework: [Free Energy Principle](https:\/\/en.wikipedia.org\/wiki\/Free_energy_principle) (FEP) by [Karl Friston](https:\/\/en.wikipedia.org\/wiki\/Karl_J._Friston): The free-energy principle is an attempt to explain the structure and function of the brain, starting from the very fact that we exist.\n\nThis is a code example notebook and it belongs to a series of notebooks on the Free Energy Principle tutorial without a PhD. If you are interested to have a deep understanding of this code please read the \"Free Energy Principle tutorial without a PhD\" series ([part 1](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-1), [part 2](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-2), [part 3](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-3), [part 4](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-4)). There is a lot to explain but I promise you an excellent journey into something that might hold the key to true AI.","ac624b23":"## Generalised sensory observations\nThe generative model of Hydar expects sensory observations in generalised coordinates of motion ($\\tilde y$). This is done exactly the same as explained in the [second code notebook](https:\/\/www.kaggle.com\/charel\/active-inference-code-by-example-2), the code is re-used.  \n\nWhat we need to calculate is $\\tilde y=\\begin{bmatrix} y, y', y'', y''', ...\\end{bmatrix}^T$. In this notebook I created 3 possibilities to create these types of sensory signals.\n* Expand, the simplest method by adding zeros for all higher orders of motion, e.g. 42 in generalised coordinates of motion order p=3 becomes $[42,0,0,0]^T$. \n* Exact, calculate the  generalised coordinates of motion of the sensory signal by the exact differential equations of the generative process. See the [second code book](https:\/\/www.kaggle.com\/charel\/active-inference-code-by-example-2) for the explanation how these are calculated.\n* Backward, calculate the higher order motions by using the backward [taylor expansion](https:\/\/en.wikipedia.org\/wiki\/Taylor_series), using the previous sensory values to provide a first order numerical approximation of the higher order derivatives. e.g. $speed=\\frac{position_{(t)} - position_{(t-1)}}{dt}$. I opted here to only use past sensory observations (hence I called it backward) and not future ones since Hydar cannot predict the future (especially because in notebook future sensory reading are impacted by Hydars actions).\n","9fe7ea12":"## Notes\nPlease do copy the notebook (top right) and try for yourself how much you can increase the learning rate.\n+ LR 50: If the LR is too low observe a kind of \"sluggish \"oscillation becomes visible that overshoots again and again but slowly converges \n+ LR 1500: performed as depicted in graph 4.05\n+ LR 15000: an increase of factor 10 gave quite similar results as LR 1500, although the initial control increase is steeper, so a slightly better performance\n+ LR 30000: similar performance as LR 15000, slightly better\n+ LR 60000: still worked, similar performance as LR 30000\n+ LR 120000: The performance collapsed, sudden spikes of action when desired temperature\/depth is reached.\n\nTuning the learning rate is rather straightforward. It simply needs to be in a certain bandwidth (which is quite broad with similar performance). As suggested in this [paper](https:\/\/arxiv.org\/abs\/1909.12768): increased the learning rate from 0 until the robot was steered to the desired position. The other way around should also be possible but not recommended for actual physical robots.\n","befda527":"## Experiment 4.04 - Higher embedding orders\nSame example as experiment 1.01 but now with higher embedding orders","cca5c5e7":"### Notes\n\nAs you can observe, the lines are highly comparable.  \nTo get the first insight into the differences I calculated the Mean Squared Error of the 3 embedding orders. Embedding order 2 gave better results than embedding order 1, unfortunately embedding order 3 gave lesser results than 2. \n\n","b75c58ad":"## Experiment 4.12 - Dynamic prior\nWith the knowledge of the previous experiment, can we follow a dynamic prior?","116e9418":"## Experiment 4.09 - Invoking action\nThere is an interesting dynamics between top-down and bottom-up message passing, which balance is set by the precisions. What happens when action is in the mix? ","caa6fbf6":"## Experiment 4.07 - Signal to noise ratio colored noise\nSame set-up as experiment 4.05 but now with higher noise levels in the generative process (coloured noise).","f96ef7aa":"### Notes\n+ As you can see, with some tuning of the learning rate of u, the graphs start to match. So the basic idea that the most important aspect of the forward model is the sign, the direction of the force needs to be correct, and the rest can be tuned with the learning rate, is confirmed in this experiment.\n+ Please do copy this notebook (top-right) and try it out for yourself with some different learning rates, embedding orders, etc\n+ The approximated forward model is a simple -1 used for all embedding orders. You might argue that the sign of ddg_gp is actually not -1 everywhere in this experiment. So in the code, you also find the 'sign+' method that calculates the sign for each derivative\/embedding order for you to experiment with. Where 'sign' can be regarded as a first order approximation (move up or down), 'sign+' is more sophisticated and comes closer the the 'exact' calculations (the sign for each embedding order is correct). In the robot arm example I used in the first notebooks, putting positive torque gives the same sign for all embedding orders. In this example it is not true because of the selected function of sensory mapping g, hence this remark.\n+ Also note that in the exact fwd method calculation the first entry of the fwd model is 0 because $\\frac{\\partial y}{\\partial u} = 0$, the prediction error on the position is not relevant; only prediction errors on the higher derivatives (e.g. speed, acceleration, etc) count. In the approximated forward-model it is a -1 on all embedding orders including the first one.","4a6b666d":"## Generative model\n \n\nThe generative model (model in the Hydra brain to encode a probabilistic model of the environment\/world in which it is immersed) for Hydar is the same as [the second code notebook](https:\/\/www.kaggle.com\/charel\/active-inference-code-by-example-2) and is expressed in generalised coordinates of motion.: \n\n$$ \\mathcal{D} \\tilde \\mu_x = \\tilde f(\\tilde \\mu_x, \\tilde \\mu_v) + \\tilde w   \\\\\n \\tilde y = \\tilde g (\\tilde \\mu_x, \\tilde \\mu_v) + \\tilde z$$  \n\nwhere\n* Often also written as e.g. $\\tilde f(\\tilde x, \\tilde v)$ but selected here the notation form $\\tilde f(\\tilde \\mu_x, \\tilde \\mu_v)$ to highlight these are brain estimates.\n* The function of motion  $\\tilde f(\\tilde \\mu_x, \\tilde \\mu_v)$ is shorthand for $\\begin{bmatrix} f(\\mu_x,\\mu_v), \\partial_{\\mu_x}f(\\mu_x,\\mu_v)\\cdot{\\mu_x}', \\partial_{\\mu_x}f(\\mu_x,\\mu_v)\\cdot{\\mu_x}''  , \\partial_{\\mu_x}f(\\mu_x,\\mu_v)\\cdot{\\mu_x}'''... \\end{bmatrix}$, \n     * where $f(x,v)$ of this example is given as input (assumed already learned by Hydar) and defined as $f(\\mu_x,\\mu_v)=-\\mu_x+\\mu_v$. In the Software implemented as $f(\\mu_x,\\mu_v)=a\\mu_x+b\\mu_v$ with a=-1; b=1. In short, Hydar beliefs it is moving towards its top-down hierarchical prior $\\mu_v$\n* The function of sensory mapping $\\tilde g(\\tilde \\mu_x, \\tilde \\mu_v)$ is shorthand for $\\begin{bmatrix} g(\\mu_x,\\mu_v), \\partial_{\\mu_x}g(\\mu_x,\\mu_v)\\cdot{\\mu_x}', \\partial_{\\mu_x}g(\\mu_x,\\mu_v)\\cdot{\\mu_x}''  , \\partial_{\\mu_x}g(\\mu_x,\\mu_v)\\cdot{\\mu_x}'''... \\end{bmatrix}$,\n    * where $g(\\mu_x,\\mu_v)$ is given as input and is equal to the true generative process (assumed already learned by Hydar). \n* note that actions  u  are not modelled in the generative model (they are in the generative process) as described in the [second active inference notebook](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-2). The action is not modelled in the generative model because it is the result of lowering Free Energy. The equation of motion in the generative process depends on action, whereas the generative model has no notion of action.\n\n\n## Generalised Free Energy\nAs explained in the [second active inference notebook](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-2), the Free Energy for one active inference capsule in generalised coordinates of motion (applying the Laplace\/mean-field approximation) is:\n$$\\mathcal{F}(\\tilde y, \\mu) = \\frac{1}{2}\\tilde\\varepsilon^T \\tilde\\Pi \\tilde\\varepsilon - \\frac{1}{2} ln\\begin{vmatrix}\n\\tilde\\Pi\n\\end{vmatrix} = \\frac{1}{2}(\\tilde\\varepsilon_{x}^T \\tilde\\Pi_{w} \\tilde\\varepsilon_{x}+\\tilde\\varepsilon_{y}^T \\tilde\\Pi_{z} \\tilde\\varepsilon_{y}) - \\frac{1}{2} ln\\begin{vmatrix}\n\\tilde\\Pi\n\\end{vmatrix}$$\nWhere\n* $\\tilde{ \\varepsilon}_x =  \\mathcal{D} \\tilde{ \\mu}_x - \\tilde f (\\tilde{ \\mu}_x,\\tilde{ \\mu}_v) $  is the the motion prediction error.\n* $\\tilde{ \\varepsilon}_y =  \\tilde y - \\tilde g (\\tilde{ \\mu}_x,\\tilde{ \\mu}_v) $ is the sensory prediction error. \n* In this notebook we assuming noise levels are constant during action and inferencing and the Free Energy calculated (because $-\\frac{1}{2} ln\\begin{vmatrix}\\tilde \\Pi\\end{vmatrix}$ is constant with respect to finding the optimum $\\tilde \\mu_x$ or $u$) as:\n\n$$\\mathcal{F}(\\tilde y, \\mu) =\\frac{1}{2}(\\tilde\\varepsilon_{x}^T \\tilde\\Pi_{w} \\tilde\\varepsilon_{x}+\\tilde\\varepsilon_{y}^T \\tilde\\Pi_{z} \\tilde\\varepsilon_{y})$$\n\n\n\n\n## Inference by gradient descent\nInference by gradient descent is exactly the same as explained in the [second code notebook](https:\/\/www.kaggle.com\/charel\/active-inference-code-by-example-2), the code is re-used.  \nThe gradient descent can be compactly written in matrix notation as: \n$$    \\dot{\\tilde{\\mu}}_x = \\mathcal{D}\\tilde{\\mu}_x - \\alpha_x \\frac{\\partial \\mathcal{F}(\\tilde y,\\mu)}{\\partial \\tilde{\\mu}_x}  $$\n\nand the partial derivative of the Free energy for this example can be written as:\n$$\\frac{\\partial \\mathcal{F}(\\tilde y,\\mu)}{\\partial \\tilde{\\mu}_x} =\\left( \\mathcal{D} - \\tilde A \\right)^T\\tilde{\\Pi}_{{w}}\\tilde{\\varepsilon}_x + \\left( - \\frac{g({\\mu}_x,{\\mu}_v)}{\\partial{\\mu}_x}  \\cdot I_{p+1} \\right)^T\\tilde\\Pi_{{z}}\\tilde\\varepsilon_y$$\n\nwere\n\n* generalised motion prediction error $\\tilde{ \\varepsilon}_x =  \\mathcal{D} \\tilde{ \\mu}_x - \\tilde f (\\tilde{ \\mu}_x,\\tilde{ \\mu}_v) =  \\mathcal{D} \\tilde{ \\mu}_x - \\tilde A \\tilde{ \\mu}_x - [b\\cdot\\mu_v,0,0,..]^T  $ and $\\tilde A = a \\cdot I_{p+1}$\n* generalised sensory prediction error $\\tilde{ \\varepsilon}_y= \\tilde y -\\begin{bmatrix}g({\\mu}_x,{\\mu}_v)\\\\ 0\\\\ 0\\\\ .\\\\ .\\end{bmatrix}-\\begin{bmatrix}0\\\\ \\partial_{\\mu_x}g({\\mu}_x,{\\mu}_v)\\cdot{{\\mu}_x}'\\\\ \\partial_{\\mu_x}g({\\mu}_x,{\\mu}_v)\\cdot{{\\mu}_x}''\\\\ .\\\\ .\\end{bmatrix}$. \n* Note that in case of a LTI (Linear Time Invariant) state space model the generalised sensory prediction error can be simplified to:\n$\\tilde y - \\tilde C \\tilde{ \\mu}_x  $ where $\\tilde C = c \\cdot I_{p+1}$ and the partial derivative of the Free energy as $\\frac{\\partial \\mathcal{F}(\\tilde y,\\mu)}{\\partial \\tilde{\\mu}_x} =\\left( \\mathcal{D} - \\tilde A \\right)^T\\tilde{\\Pi}_{{w}}\\tilde{\\varepsilon}_x + \\left( - \\tilde C \\right)^T\\tilde\\Pi_{{z}}\\tilde\\varepsilon_y$. See [second code notebook](https:\/\/www.kaggle.com\/charel\/active-inference-code-by-example-2) for the details.\n* $\\tilde \\Pi_w$: the precision matrix of the generalised noise $\\tilde w$ expresses the amount of uncertainty in the prediction error $\\varepsilon_{x}$ at all orders of motion and is calculated as :\n$$\\tilde \\Pi_w= {\\tilde \\Sigma_w}^{-1}= (S(s_w^2) \\otimes \\Sigma_w )^{-1}  $$\n* $\\tilde \\Pi_z$: the precision matrix of the generalised noise $\\tilde z$ expresses the amount of uncertainty in the prediction error $\\varepsilon_{y}$ at all orders of motion and is calculated as :\n$$\\tilde \\Pi_w= {\\tilde \\Sigma_z}^{-1}= (S(s_z^2) \\otimes \\Sigma_z )^{-1}  $$\n\n\n","5eb24044":"<a id='sec2'><\/a>\n# Active inference code version 0.4\nThe flow diagram \"prediction -> prediction error -> prediction error minimization\" as explained in the notebook [learn by example active inference in the brain 5](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-5) is implemented in the code in this notebook.  \n\n<img src=\"https:\/\/i.imgur.com\/0BZMMDR.jpg\" width=900>\n\nWhere the 2 predictions errors are:\n  * $\\tilde{ \\varepsilon}_x =  \\mathcal{D} \\tilde{ \\mu}_x - \\tilde A \\tilde{ \\mu}_x - \\tilde \\mu_v  $ where $\\tilde A = a \\cdot I_{p+1}$\n  * $\\tilde{ \\varepsilon}_y= \\tilde y -\\begin{bmatrix}g({\\mu}_x,{\\mu}_v)\\\\ 0\\\\ 0\\\\ .\\\\ .\\end{bmatrix}-\\begin{bmatrix}0\\\\ \\partial_{\\mu_x}g({\\mu}_x,{\\mu}_v)\\cdot{{\\mu}_x}'\\\\ \\partial_{\\mu_x}g({\\mu}_x,{\\mu}_v)\\cdot{{\\mu}_x}''\\\\ .\\\\ .\\end{bmatrix}$\n  \nAnd the prediction error minimization is done by\n* $    \\dot{\\tilde{\\mu}}_x = \\mathcal{D}\\tilde{\\mu}_x - \\alpha_x \\frac{\\partial \\mathcal{F}(\\tilde y,\\mu)}{\\partial \\tilde{\\mu}_x} = \\mathcal{D}\\tilde{\\mu}_x -  \\frac{\\partial \\tilde{\\varepsilon}^{\\top}}{\\partial \\tilde{\\mu}_x} \\tilde\\xi = \\mathcal{D}\\tilde{\\mu}_x - \\alpha_x \\left( \\left( \\mathcal{D} - \\tilde A \\right)^T\\tilde{\\Pi}_{{w}}\\tilde{\\varepsilon}_x + \\left( - \\frac{g({\\mu}_x,{\\mu}_v)}{\\partial{\\mu}_x}  \\cdot I_{p+1} \\right)^T\\tilde\\Pi_{{z}}\\tilde\\varepsilon_y \\right) $\n* $    \\dot{u}  = -  \\frac{\\partial \\tilde{y}}{\\partial u}^\\top \\tilde\\Pi_z \\tilde\\varepsilon_y $\n* Where the [forward Euler method](https:\/\/en.wikipedia.org\/wiki\/Euler_method) is used to execute the motion of $\\dot\\mu_x$ and $\\dot u$.  \n","4c74abad":"## Experiment 4.02 - Observe what is expected\nQuick check what happens if the prior expectation and actual sensor readings do match. Hydar's prior and its actual depth is 25 centimeters, so it is expecting and receiving a temperature of 17 degrees.","dd03cb89":"### Notes\nThe belief and generative process follow the black prior close but just out of phase. And also remember there is a thermocline in the water, hence the control signal gets some interesting shapes. I guess it is sufficient for Hydar to survive by keeping its body temperature within a certain bandwidth.","1bd46129":"## Experiment 4.01 - The first\nIn this example, Hydar is at a depth of 30 centimeters and is getting cold. It wants to move up to a depth of 25 degrees and a comfortable temperature of 17 degrees.\n\nFor this example, there is no noise in the generative process yet (although the generative model expects noise to be present) to best see how the belief develops.","77c1c173":"## Action by gradient descent\nAs explained in the [fith notebook](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-5) the gradient descent for a single active inference capsule in generalised coordinates of motion can be compactly written as: \nThus gradient descent can be compactly written as:\n\n$$    \\dot{u}  = -  \\frac{\\partial \\tilde{y}}{\\partial u}^\\top \\tilde\\Pi_z \\tilde\\varepsilon_y $$\n\nwhere $ \\frac{\\partial \\tilde{y} }{\\partial u}^\\top$ is the forward dynamic model and defined as $\\begin{bmatrix}\\frac{\\partial y}{\\partial u}, \\frac{\\partial y'}{\\partial u}, \\frac{\\partial y''}{\\partial u}, . .\\end{bmatrix}$  thus the change in the all the derivatives of the sensory input with respect to the control actions (model of how sensory data changes with actions).\n\nIn this notebook we will explore some different options for the forward dynamic model.\n\n1. Exact  \nTo calculate the  generalised coordinates of motion of the sensory signal by the exact differential equations of the generative process, thus $\\tilde y=\\begin{bmatrix} y, y', y'', y''', ...\\end{bmatrix}^T=\\begin{bmatrix} y, \\dot y, \\ddot y, \\dddot y, ...\\end{bmatrix}^T$. See the [learn-by-example-active-inference-in-the-brain-5](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-5\/) for the math to understand the code ($ f_{gp}(x,v,u )= a_{gp}x + b_{gp}u $ ):  \n* $\\frac{\\partial y}{\\partial u} = \\frac{\\partial g_{gp}(x,v)}{\\partial u} = 0$\n* $\\frac{\\partial \\dot y}{\\partial u} =\\frac{\\partial g'_{gp}(x,v) \\cdot f_{gp}(x,v,u) }{\\partial u} = b_{gp} \\cdot g'_{gp}(x,v)$  \n* $\\frac{\\partial \\ddot y}{\\partial u} = \\frac{\\partial g_{gp}''(x,v) \\cdot f_{gp}(x,v,u)^2 + g_{gp}'(x,v)f'_{gp}(x,v,u)f_{gp}(x,v,u)}{\\partial u} = 2b_{gp} \\cdot f_{gp}(x,v,u)g_{gp}''(x,v) + a_{gp}b_{gp} \\cdot g_{gp}'(x,v)  $   \n* $\\frac{\\partial \\dddot y}{\\partial u} = \\frac{\\partial g_{gp}'''(x,v)f_{gp}(x,v,u)^3+2g_{gp}''(x,v)f_{gp}(x,v,u)^2f_{gp}'(x,v,u)+f_{gp}'(x,v,u) \\left(  g_{gp}''(x,v)f_{gp}(x,v,u)^2+g_{gp}'(x,v)f_{gp}'(x,v,u)f_{gp}(x,v,u) \\right )}{\\partial u} \n= 3b_{gp} \\cdot f_{gp}(x,v,u)^2g_{gp}'''(x,v) + 4a_{gp}b_{gp} \\cdot f_{gp}(x,v,u)g_{gp}'(x,v) + 2a_{gp}b_{gp} \\cdot f_{gp}(x,v,u)g_{gp}''(x,v)+ a_{gp}^2b_{gp}\\cdot g_{gp}'(x,v) $\n\n\n\n\n\n* Note:\n    * in this active inference code notebook the funtion of motion in the generative model is $\\dot x = f_{gp}(x,u,v) = a \\cdot x + b \\cdot u = u$ where a=0 and b=1\n    * $f'(x,v)=\\frac{\\partial f(x,v)}{\\partial x}$  ,  $g'(x,v)=\\frac{\\partial g(x,v)}{\\partial x}$  and  $\\dot x =\\frac{\\partial x}{\\partial t}$. Thus  $f'(x,v)$  is the partial derivative of function f with respect to x and  $\\dot x$  is the time derivative of $x$.\n    * v is a constant in this notebook, so omitting $\\frac{\\partial f(x,v)}{\\partial v}\\frac{\\partial v}{\\partial t}$ and $\\frac{\\partial g(x,v)}{\\partial v}\\frac{\\partial v}{\\partial t}$ because they are 0\n   \n\n2. Approximation by sign  \n${\\frac{\\partial \\tilde{y}}{\\partial u}}^\\top $ is approximated with a constant -1, the direction of the force (g_{gp}'(x,v) is negative), thus $\\begin{bmatrix}-1, -1, -1, . .\\end{bmatrix}$ \n\n    \n2. Approximation by sign+  \n${\\frac{\\partial \\tilde{y}}{\\partial u}}^\\top $ is approximated with a constant -1 or -1 depending the derivative of $g_{gp}(x,v)$, thus $\\begin{bmatrix}sign(g_{gp}(x,v)), sign(g'_{gp}(x,v)), sign(g''_{gp}(x,v)), . .\\end{bmatrix}$ ","86b46ef0":"## Experiment 4.05 - Colored noise\nSame set-up as experiment 4.01 but now with some actual colored noise in the generative process.","c9e436a0":"## Experiment 4.11 - Invoking action - part 3\nLet's see if we can find an example that does generate optimal action. In order to get optimal action we need ($ \\dot{u}  = -  \\frac{\\partial \\tilde{y}}{\\partial u}^\\top \\tilde\\Pi_z \\tilde\\varepsilon_y $.):\n  + High sensory prediction error: Setting a hidden cause or top-down prior expectation invokes the action. The internal state estimation needs to follow the hidden causes strongly to produce the sensory prediction error, hence a high precision of the hidden states compared to the precision of the sensory causes\n  + High precision of $\\tilde\\Pi_z$, hence a high precision on the sensory observations and smooth noise\n  + High action learning rate","9a804b06":"## Notes  \n+ First notice the difference in the covariance matrix, again a factor 10 for the LR to increase from 1500 ($\\sigma=$ 0.1) to 15000 ($\\sigma=$  1)\n+ In both cases, Hydar gets to the right temperature and depth. Despite the red line goes all over the place due to the noise, Hydar is able to take action to get to the desired depth\/temperature.  \n+ But to reach the correct depth\/temperature it takes more time for $\\sigma=$  1. During the first 2 seconds of inferencing, the belief of the depth with $\\sigma=$  0.1 is around 29 centimeters and the belief of the depth with $\\sigma=$ 1 is 26 centimeters. This is consistent with code notebook 2. Hence a stronger action signal (higher prediction error) is issued in the case of $\\sigma=$  0.1 simply because Hydar beliefs it needs more distance to cover.\n+ Just increasing the learning rate of the control signal (with a factor of 10 to 15000) does not remediate the performance, it just gives a stronger initial control signal but it takes just as long to reach the depth as LR 1500. By also increasing the LR for $\\mu$ (with a factor of 10) similar performance for SD 1 is obtained as $\\sigma=$  0.1\n\n","3d53cb6a":"### Notes\nThe order in which I tried to get to the result:\n+ First I have set the forward model to 'sign' because that way the first entry in the fwd model is not zero, and thus first-order sensory prediction errors taken into account\n+ Next I needed to make sure that the internal estimation of the hidden state $\\mu_x$ follows the causal state $\\mu_v$ as closely as possible so Hydar has the internal prediction as close as possible to the prior (else action drives it to the wrong place) and the prediction error is biggest. This can be done to set $\\sigma_w$ as low as possible and the learning rate for the hidden state as high as possible, without getting a python overflow error calculating the exponential. As you can see in the graph I was not able to match the black line precisely, but getting close.\n+ Next I tried to increase $\\sigma_z$ as high as possible without affecting the internal state estimation too much. Which gives an interesting relation between $\\sigma_w$ and $\\sigma_z$. $\\sigma_z$ needs to be small (high precision) in relation to $\\sigma_w$ in order to get bigger prediction errors and correct state estimates based on the top-down prior. But a bigger $\\sigma_z$ causes less motion of u due to the $\\pi_z$ multiplier in the gradient descent. So, it needs to be offset by a higher learning rate to basically still make sure the orange line follows the blue (internal belief).  \nit is some engineering, but in order to invoke as fast as possible action response:\n1. Action drives to the internal predictions. Internal predictions need to be close to the desired top-down prior -> low $\\sigma_w$ (high precision) and a high learning rate for the hidden state. (if the internal predictions are off you get fast action response to the wrong estimates).\n2. Set $\\sigma_z$ as low as possible without affecting the state estimates. Increase the action learning rate from 0 until action steers to the desired position\nIn short, action needs a strong prior and sufficiently high tuned learning rates for action.","9d256309":"To recap all you need to perform active inference in the table below:\n\nWhat| Symbol | Description |\n--- | --- | --- |\nposition | $x$  | single external hidden environment state the Hydar brain tries to infer. <br> Hydar lives in a one-dimensional plane, so it is the depth in centimetres | \nposition | $\\tilde \\mu_x$  | Hydars belief or estimation of the depth, the hidden state x it's tries to infer |\nbody temperature sensor | $\\tilde y$  | single sensory observation, in this case the temperature.  | \nStarting position | $x_{init}$  | The initial depth of Hydar in the generative process | \nprior | $v$  | Hidden cause in the generative process | \nprior | $\\tilde \\mu_v$  | Hydars prior belief of the depth Hydar moves towards | \ncontrol signal | u | actions, control signal, The action that can be performed on the environment|\nfunction of sensory mapping| $g(\\mu_x,\\mu_v)$  | Given as input and is equal to the true generative process <br>$g(\\mu_x,\\mu_v) = t_0 -\\frac{16}{1+e^{5-\\frac{\\mu_x}{5}}}$ where $t_0=20$  | \nderivative function of sensory mapping| $g'(\\mu_x,\\mu_v)$  | Given as input and is equal to the derivative of the true generative process <br>$g'(\\mu_x,\\mu_v) = -\\frac{16e^{5-\\frac{\\mu_x}{5}}}{5\\left(1+e^{5-\\frac{\\mu_x}{5}}\\right)^2}$  | \nfunction of motion | $f(\\mu_x,\\mu_v)$  | Given as input <br>$f(\\mu_x,\\mu_v) = a*\\mu_x + b*\\mu_v $ where a=-1 and b = 1|\nderivative of function of motion | $f'(\\mu_x,\\mu_v)$  | Given as input $f'(\\mu_x) = a $ |\nFree Energy | $\\mathcal{F}(y,\\mu)$  | $\\mathcal{F}(\\tilde y, \\mu) = \\frac{1}{2}\\tilde\\varepsilon^T \\tilde\\Pi \\tilde\\varepsilon=\n\\frac{1}{2}(\\tilde\\varepsilon_{x}^T \\tilde\\Pi_{w} \\tilde\\varepsilon_{x}+\\tilde\\varepsilon_{y}^T \\tilde\\Pi_{z} \\tilde\\varepsilon_{y})$ |\nsensory prediction error | $\\tilde \\varepsilon_y$  | $\\tilde{ \\varepsilon}_y =  \\tilde y - \\tilde g (\\tilde{ \\mu}_x, \\tilde\\mu_v) $ |\nmotion prediction error | $\\tilde \\varepsilon_x$  | $\\tilde{ \\varepsilon}_x =  \\mathcal{D} \\tilde{ \\mu}_x - \\tilde f (\\tilde{ \\mu}_x,\\tilde\\mu_v) $ |\nDerivative Free Energy | $\\frac{\\partial \\mathcal{F}(\\tilde y,\\mu)}{\\partial \\tilde{\\mu}_x}$  | $\\left( \\mathcal{D} - \\tilde A \\right)^T\\tilde{\\Pi}_{{w}}\\tilde{\\varepsilon}_x + \\left( - \\frac{g({\\mu}_x,{\\mu}_v)}{\\partial{\\mu}_x}  \\cdot I_{p+1} \\right)^T\\tilde\\Pi_{{z}}\\tilde\\varepsilon_y$ |","c8f0df2e":"## Experiment 4.08 - Learning rate\nSame experiment as 4.05 but now with various learning rates. Can I increase the learning rate forever?","653001f1":"### Notes\nSetting a top-down prior expectation invokes the action. Precisions (and learning rates) determine\/affect the action invoked.  \nBoth blocks compare the baseline $\\sigma_w = \\sigma_z = 0.1$ with  $\\sigma_w =10$ (low precision generative model \/ prior \/ top-down) resp.  $\\sigma_z = 10$ (low precision sensory observation \/ bottom-up). Remember the gradient descent for action is defined as $ \\dot{u}  = -  \\frac{\\partial \\tilde{y}}{\\partial u}^\\top \\tilde\\Pi_z \\tilde\\varepsilon_y $.\n\n+ In the first block low precision (high variance) of the sensory observation $\\sigma_z = 10$ is depicted. The resulting control signal is far less which can be observed in the control signal (orange line vs baseline in blue). The depth starts to decrease over time (red line) slowly but only due to a persistent prediction error over time. It can also be observed in the math of the gradient descent,  $\\tilde\\Pi_z$ has a direct impact on the control signal. In short. higher sensory (bottom-up) precision gives stronger action. A second effect is that the internal belief of the depth ($\\mu_x$) stays close to the prior belief, best visible before action is applied (left of the dotted vertical lines, the orange line is close to the black line, and the blue lines close to the red lines). This results in a higher sensory prediction error (compared to the baseline) * lower precision (compared to the baseline). However, $\\sigma_z$ is a factor 100 bigger than $\\sigma_w$ while the (first-order) prediction error is approx a factor 4 bigger (30-26=4 degrees vs 30-29=1 degrees), still resulting in 25 times lower action signal (compared to the baseline)\n+ In the second block low precision (high variance) of the motion of the hidden state $\\sigma_w = 10$ is depicted. The resulting control signal is initially not as strong as the baseline. Mainly because the sensory prediction is smaller compared to the baseline (the orange line is almost equal to the red line of the generative process). It takes the orange control signal more time to create the momentum and next it overshoots resulting in a \"sluggish\" oscillation.  \n+ Note that the graphs change by taking different learning rates, \n  + in the first block by taking a high LR for u, the action can still be strongly invoked to get similar control as in the reference case. \n  + in the second block by taking a high LR for $\\mu$ the action creates a faster oscillation, and the overshoot is significantly less with higher embedding orders","f1cb4cbe":"### Notes\n\nThe same conclusion as experiment 4.05.  \nAs you can see in the graph The learning rate needed to increase by a factor of 1600 to get to a similar performance, which can again be seen in the covariance matrix where you see an increase from 3 to 5000 in the second-order compared to the covariance matrix of the first experiment."}}