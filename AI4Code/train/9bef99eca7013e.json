{"cell_type":{"5f8b9d13":"code","f5e21be2":"code","af5bcb04":"code","5a56e55a":"code","76700242":"code","e9354cd4":"code","78c01b99":"code","20ca5082":"code","0e939fd2":"code","a353fcd2":"code","da40fdb6":"code","58e7d080":"code","cf0516ce":"code","8adc9c97":"code","55c4e3bf":"code","3d574fea":"code","caa99d8a":"code","33692ec7":"code","058bfba0":"code","e447bd80":"code","89937f9d":"code","2deac1fa":"code","e8fcd58b":"code","fb812a8b":"markdown","d0db8ecf":"markdown","b3b40e37":"markdown","f3f0cbf6":"markdown","44ce4b3d":"markdown","91329a70":"markdown","2c39f03d":"markdown","994cc858":"markdown","3c99b296":"markdown","2d51eed4":"markdown","de97aca3":"markdown","f0a2db8a":"markdown","5e615e13":"markdown","8f36563f":"markdown","b6203798":"markdown","c2d78f79":"markdown","f12b48cd":"markdown","bd48d66f":"markdown","eafb49b8":"markdown","3e02aa61":"markdown","8b791d7d":"markdown","0c6b73d5":"markdown","845b5fec":"markdown","356c7863":"markdown","ea058dad":"markdown","dc74f054":"markdown","821114e8":"markdown"},"source":{"5f8b9d13":"# libraries for data exploration and manipulation\nimport pandas as pd\nimport numpy as np\n\n# libraries for visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nimport plotly.express as px","f5e21be2":"data = pd.read_csv('..\/input\/data-analyst-jobs\/DataAnalyst.csv')\ndata.head()","af5bcb04":"# converting column names to snake case\ncolname_list = []\nfor col in data.columns:\n    col = col.strip()\n    col = col.lower()\n    col = col.replace(' ','_')\n    colname_list.append(col)\n    \ndata.columns = colname_list  \ndata.head(2)","5a56e55a":"# dropping the unnecessary column\ndata.drop('unnamed:_0', axis=1, inplace=True)\n\n# creating numerical features\nsalary_range = data.salary_estimate.str.split('(').str[0]\nsalary_range = salary_range.str.strip().str.replace('$','').str.replace('K','').str.split('-')\ndata['min_salary'], data['max_salary'] = salary_range.str[0], salary_range.str[1]","76700242":"min_mode = data['min_salary'].mode()[0]\n\n# replacing '' with the mode value\ndata['min_salary'] = data['min_salary'].replace('',min_mode)\ndata['min_salary'] = data['min_salary'].str.strip().astype(int)*1000\ndata['max_salary'] = data['max_salary'].str.strip().astype(int)*1000\n\n# drop the salary_estimate column\ndata.drop('salary_estimate', axis=1, inplace=True)","e9354cd4":"data.company_name = data.company_name.str.split('\\n').str[0]\ndata.headquarters = data.headquarters.str.split(',').str[0]\ndata.location = data.location.str.split(',').str[0]","78c01b99":"for val in ['-1', -1, -1.0]:\n    data = data.replace(val, np.nan)\n\n# list of columns containing null values    \ncols_with_null = [col for col in data.columns \n                 if data[col].isnull().sum()>0]  \n\n# columns with missing values and displaying the dimension of data\ncols_with_null, data.shape  ","20ca5082":"data[cols_with_null].isnull().sum().sort_values(ascending=False)","0e939fd2":"data[cols_with_null].describe(include='all')","a353fcd2":"# filling missing rating with median rating\ndata.rating.fillna(3.7, inplace=True)\n\n# filling missing headquarters with the location\ndata.loc[data.headquarters.isnull(), 'headquarters'] = data.location\n\n# filling missing size\nmode_size = data['size'].mode()[0]\ndata['size'].fillna(mode_size, inplace=True)\n\n# filling type of owenership\nmode_ownership = data.type_of_ownership.mode()[0]\ndata.type_of_ownership.fillna(mode_ownership, inplace=True)\n\n# filling type of owenership\nmode_industry = data.industry.mode()[0]\ndata.industry.fillna(mode_industry, inplace=True)\n\n# filling type of owenership\nmode_sector = data.sector.mode()[0]\ndata.sector.fillna(mode_sector, inplace=True)\n\n# filling type of owenership\nmode_revenue = data.revenue.mode()[0]\ndata.revenue.fillna(mode_revenue, inplace=True)\n\n# filling easy apply\ndata.easy_apply = data.easy_apply.replace({\n    'True':True,\n    np.nan:False\n})\n\n# dropping one row where company name is not given\ndata.dropna(subset=['company_name'], inplace=True)","da40fdb6":"data.job_title = data.job_title.str.split(',').str[0]\ndata.job_title = data.job_title.str.title()\ndata.job_title = data.job_title.str.replace('.', '')\ndata.job_title = data.job_title.str.replace('Sr', 'Senior')\ndata.job_title = data.job_title.str.replace('Data Analyst Junior', 'Junior Data Analyst')","58e7d080":"# making a new feature to show maximum revenue of companies\nrev = data.revenue.str.split().str[-3:-1]\nrev_series = []\nfor val in rev:\n    if val[1] == 'million': \n        price = val[0].replace('$','').replace('+','').strip()\n        price = int(price)*1000000  # multiply the value with 1000000 if price is in million\n        rev_series.append(price)\n    elif val[1] == 'billion':\n        price = val[0].replace('$','').replace('+','').strip()\n        price = int(price)*1000000000  # multiply the value with 1000000000 if price is in billion\n        rev_series.append(price)\n    else:\n        rev_series.append(np.nan)  # if price is not given then fill null value\n        \nmax_rev = pd.Series(rev_series)\n\n# add new column to the data\ndata['max_revenue'] = max_rev \ndata.max_revenue.fillna(data.max_revenue.median(), inplace=True)","cf0516ce":"data.head(3)","8adc9c97":"# frequency of each sector\nsectors = data.sector.value_counts()\nsector_job = pd.DataFrame({'sector':sectors.index,\n                         'jobs':sectors.values})\n# creating bar graph for the frequency of each sector\nfig = px.bar(\n    sector_job,\n    x='sector',\n    y='jobs',\n    title='Number of jobs in each sectors',\n    color_discrete_sequence =['#EB5377'],\n    template='plotly_white'\n           )\n\n# updating the ylabel and xticks rotation\nfig.update_yaxes(title_text='Number of jobs')\nfig.update_xaxes(tickangle=45)\nfig.show()","55c4e3bf":"# avg. maximum revenue of each sector\ngrouped_sector = data.groupby('sector')['max_revenue'].mean()\nsector_df = pd.DataFrame({'sector':grouped_sector.index,\n                         'max_revenue':grouped_sector.values})\n\n# creating bar graph\nfig = px.bar(\n    sector_df,\n    x='sector',\n    y='max_revenue',\n    title='Average maximum revenue(USD) in each sector',\n    color_discrete_sequence =['#03D6C1'],\n    template='plotly_white'\n           )\n\n# updating ylabel and xticks rotation\nfig.update_yaxes(title_text='Maximum revenue')\nfig.update_xaxes(tickangle=45)\nfig.show()","3d574fea":"# avg minimum and maximum salary in each sector\nsalary = data.groupby('sector')[['min_salary','max_salary']].mean()\nsal_df = pd.DataFrame({'sector':salary.index,\n                      'min_salary':salary.min_salary,\n                      'max_salary':salary.max_salary})\n\n# creating bar graph\nfig = px.bar(sal_df,\n             x='sector',\n             y=['min_salary','max_salary'],\n            color_discrete_sequence=['#273746','#A9DFBF'],\n             title='Average salary(USD) in sectors',\n             template='plotly_white'\n            )\n\n# updating ylabel and xticks rotation\nfig.update_yaxes(title_text='Salary')\nfig.update_xaxes(tickangle=45)\nfig.show()","caa99d8a":"# taking data only of easy apply\ndf = data[data.easy_apply==True]\ncompanies = df.company_name.value_counts()[:10]\ncomp_df = pd.DataFrame({'company':companies.index,\n                       'total_job':companies.values})\n\n# creating bar chart\nfig = go.Figure(data=[go.Pie(\n    labels=comp_df.company,\n    values=comp_df.total_job,\n    hole=.5)])\nfig.update_layout(title='Top 10 recruiters providing easy apply')\nfig.show()","33692ec7":"job_counts = data.job_title.value_counts(ascending=False)[:15]\njob_df = pd.DataFrame({'job_title':job_counts.index,\n                       'total_job':job_counts.values})\n\n# creating bar chart\nfig = px.bar(\n    job_df,\n    y='total_job',\n    x='job_title',\n    title='Number of jobs for each title',\n    color_discrete_sequence =['#EC70CC'],\n    template='plotly_white'\n           )\n\n# updating ylabel\nfig.update_yaxes(title_text='Number of jobs')\nfig.show()","058bfba0":"job_list = job_df.job_title.tolist()\njob_df2 = data[data.job_title.isin(job_list)]\njob_grp = job_df2.groupby('job_title')[['min_salary','max_salary']].median()\n\n# creating bar graph\nfig = px.bar(job_grp,\n             x=job_grp.index,\n             y=['min_salary','max_salary'],\n            color_discrete_sequence=['#15CC6F','#94EB53'],\n             title='Average salary(USD) in top 15 job roles',\n             template='plotly_white'\n            )\n\n# updating xlabel and ylabel\nfig.update_yaxes(title_text='Salary')\nfig.update_xaxes(tickangle=45)\nfig.show()","e447bd80":"star_grp = job_df2.groupby('job_title')['rating'].mean()\n\n# creating bar chart\nfig = go.Figure(go.Bar(\n    x=star_grp.index,y=star_grp.values,\n    marker={'color': star_grp.values, \n    'colorscale': 'agsunset'}\n))\n\n# updating title and labels\nfig.update_layout(title_text='Top 15 job roles rating',\n                  xaxis_title=\"Job roles\",\n                  yaxis_title=\"Ratings\")\nfig.show()","89937f9d":"owner_grp = data.groupby('type_of_ownership')['max_revenue'].mean()\nfig = go.Figure(data=[go.Scatter(\n    x=owner_grp.index, y=owner_grp.values,\n    mode='markers',\n    marker=dict(\n        color=owner_grp.values,\n        size=owner_grp.values*0.000000025,\n        showscale=True))])\n\n# updating the labels and title\nfig.update_layout(template='plotly_white',\n                  title='Maximum avg. revenue in differnt types of ownership',\n                  xaxis_title=\"Type of ownership\",\n                  yaxis_title=\"Maximum avg. revenue\")\nfig.show()","2deac1fa":"top_location = data.location.value_counts()[:20]\nloc_df = pd.DataFrame({'location':top_location.index,\n                       'total_job':top_location.values})\n\n# creating pie chart\nfig = go.Figure(data=[go.Pie(\n    labels=loc_df.location,\n    values=loc_df.total_job,\n    hole=.5)])\nfig.update_layout(title='Top 20 locations providing analytics jobs')\nfig.show()","e8fcd58b":"# number of jobs in New York\nny = data[data.location == 'New York']\nny.job_title.value_counts()[:10]","fb812a8b":"Junior Data Analyst job profile has highest number of ratings.","d0db8ecf":"## **- Average ratings for the top 15 job roles**","b3b40e37":"This says that most of the job are for Data Analyst followed by Senior Data Analyst etc.","f3f0cbf6":"### **Reading the data**","44ce4b3d":"# **Data analyst jobs analysis**\n\n<img src='https:\/\/image.freepik.com\/free-vector\/group-analysts-working-graphs_1262-21249.jpg'>\n\nIn this notebook we are going to analyze the overall market and trends of Data Analyst job alongwith salary and few more factors.\n\nThe key feature of this analysis will be:\n1. To analyze the trend\n2. Number of data analyst jobs in countries\n3. Sectors\/Domain\n4. Average salary\nand much more.\n\nLet's dig in.","91329a70":"Companies coming under the Public ownership, tends to produce more revenue.","2c39f03d":"### **Let's see what the data tells us**\nBefore jumping to analysis, let's check the modifications.","994cc858":"## **- Salaries in each sector**","3c99b296":"So number of jobs are higher in IT sector followed by Business services, finance, health care etc.\n### **- Average maximum revenue in each sector**","2d51eed4":"As there are many values like -1, -1.0 which do not make any sense, so we need to replace them with some useful values.","de97aca3":"### **Importing libraries**\nFirst thing first, import the necessary libraries to do analysis and manipulation of data.","f0a2db8a":"Lead Data Analyst has the highest salary, then Marketing Data Analyst and Business Data Analyst.","5e615e13":"## **- Top 10 companies providing jobs**\nConsidering only jobs which are providing easy apply option.","8f36563f":"The above graph shows the average minimum and maximum salary in each sector.","b6203798":"## **- Revenue in different types of ownership**","c2d78f79":"Mostly New York is providing the analytics jobs.","f12b48cd":"In New York there are many jobs having role as Data Analyst. Above we listed only 10.","bd48d66f":"Let's see what number of null values these above columns contains. Then we will decide what to do next!","eafb49b8":"Almost 30% values are missing in `founded` column, it would not be a good idea if we replace the missing values with any value, because we don't know the year in which the companies were founded. So better would be to leave it or drop it.\n\nAnother column is `competitors` which contains contains almost 77% of missing values. So better option would be to leave it or drop it.","3e02aa61":"There is some need of data cleaning, so let's do it.\n\n### **Let's do some modification and cleaning**\nNow, we will do some modification in data because with the present format we can not do the analysis, as it may contains some missing values along with columns with wrong data types. So it would be better to convert the data into desirable form for analysis.","8b791d7d":"## **- Average minimum and maximum salaries for top 15 job roles**","0c6b73d5":"The two columns `easy_apply` and `competitors` have very higher number of missing values i.e., more than 75%. We cannot fill values in competitors because there are too much missing values in it, and if we do it, this may provide us wrong information.\n\nIn `easy_apply` column we can fill `False`.\n\nFor other columns we can fill values which are more frequent in them.","845b5fec":"### **- Number of job in each sector**\nHere we will see the number of jobs in each sector, this would help us to know that which sectors are hiring more.","356c7863":"## **This is my first notebook on kaggle, if you like it, please upvote.**","ea058dad":"## **- Top 15 job titles**","dc74f054":"## **- Top 20 locations providing analytics jobs**","821114e8":"We can see that highest avg. maximum revenue is created by the Insurance sector followed by mining & metals, aerospace & defensse etc. Whereas travels & tourism sector have very low revenue as compare to other sectors. "}}