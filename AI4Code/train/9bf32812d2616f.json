{"cell_type":{"1437f9ec":"code","0d4e8ad0":"code","7ce816ee":"code","655c3dc3":"code","4362d455":"code","3504eb83":"code","99773051":"code","9afd0d0e":"code","9b08a369":"code","eedef0b3":"code","50c50416":"code","6071033c":"code","dcb71109":"code","c553dab0":"code","9dc07ad5":"code","f078a19c":"code","3368e279":"code","b5285f6e":"markdown","5a854172":"markdown","1bde261b":"markdown","e7316189":"markdown","09aa8af7":"markdown","3f5725bb":"markdown","2e951910":"markdown","e03bc7d9":"markdown"},"source":{"1437f9ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0d4e8ad0":"dataset= pd.read_csv('\/kaggle\/input\/diabetescsv\/diabetes.csv')","7ce816ee":"dataset.head()","655c3dc3":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score","4362d455":"len(dataset)","3504eb83":"dataset.isnull().sum()","99773051":"print('BP:',dataset[dataset.BloodPressure==0].shape[0])\nprint('Glucose:',dataset[dataset.Glucose==0].shape[0])\nprint('Skin thickness:',dataset[dataset.SkinThickness==0].shape[0])\nprint('Insulin:',dataset[dataset.Insulin==0].shape[0])\nprint('BMI:',dataset[dataset.BMI==0].shape[0])","9afd0d0e":"columns_replace= ['BloodPressure', 'Glucose', 'SkinThickness', 'Insulin', 'BMI']","9b08a369":"\nfor column in columns_replace:\n    dataset[column] = dataset[column].replace(0,np.NaN)\n    mean= int(dataset[column].mean(skipna=True))\n    dataset[column] = dataset[column].replace(np.NaN,mean)\n    \n    ","eedef0b3":"print('BP:',dataset[dataset.BloodPressure==0].shape[0])\nprint('Glucose:',dataset[dataset.Glucose==0].shape[0])\nprint('Skin thickness:',dataset[dataset.SkinThickness==0].shape[0])\nprint('Insulin:',dataset[dataset.Insulin==0].shape[0])\nprint('BMI:',dataset[dataset.BMI==0].shape[0])","50c50416":"x=dataset.iloc[:, 0:8]\ny=dataset.iloc[:, 8]\n\nx_train, x_test, y_train,y_test= train_test_split(x,y, random_state=30, test_size=.2)","6071033c":"sc= StandardScaler()\nx_train=sc.fit_transform(x_train)\nx_test=sc.transform(x_test)","dcb71109":"#but this is creating a little low accuracy model so i look around with hit and trial \n#import math\n#math.sqrt(len(y_train))","c553dab0":"model=KNeighborsClassifier(n_neighbors = 47, p=2, metric= 'euclidean' )\n\nmodel.fit(x_train, y_train)\n","9dc07ad5":"y_pred= model.predict(x_test)\nprint(y_pred)","f078a19c":"#evaluate matrix\nc= confusion_matrix(y_test, y_pred)\n# this will give matrix of prediction and actual value \nprint(c)","3368e279":"print('F1_score:', f1_score(y_test, y_pred))\nprint('accuracy_score:', accuracy_score(y_test, y_pred))","b5285f6e":"Now we will analyze that whether this dataset have any null value in unexpected column and if there is any then we will have to handle that \nfirst of all check that whether there is any missing data in the dataset or not","5a854172":"We need to replace 0 with NaN so that we can aply mean function here, also skipna=true will be set to ignore NaN entries and calculate the mean without counting NaN entries.","1bde261b":"check that we are not having any null value now","e7316189":"Split the dataset into training and testing data.\n\nresult(y) is the outcome row and training and testing will be done on rest other rows","09aa8af7":"[reference for Standardization of data](https:\/\/towardsdatascience.com\/how-and-why-to-standardize-your-data-996926c2c832)","3f5725bb":"for selecting value of k","2e951910":"This means there are 35 values that are null in BP column, 5 values that are null in glucose column, 227 values that are null in Skin Thickness column,  374 values that are null in Insulin column,11 values that are null in BMI column column but it is not possible in real life to have zero values in these sections thus we will have to handle it.\n\nWe will replace them with mean value.","e03bc7d9":"Clearly there is not any missing data in any column.\nNow we will check for null value in all the columns one by one "}}