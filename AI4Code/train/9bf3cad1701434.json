{"cell_type":{"2cc9571d":"code","5c6af898":"code","6224b559":"code","cdc670c6":"code","2f6f237c":"code","9ca93e55":"code","84a6b2a6":"code","ae0e76f6":"code","8ead4855":"code","c20769b8":"code","77cccbbe":"code","3e068118":"code","1c6d0e67":"code","123f32ac":"code","6a4011d1":"code","39b325eb":"code","a91f3104":"code","637598ac":"code","c4774601":"code","5bef2e68":"code","ecc3e609":"code","b71758d5":"code","921a35f2":"code","5ed404c2":"code","4d86e87c":"code","f14cf627":"markdown","edd5d190":"markdown","31d5a0a2":"markdown","8587a5f9":"markdown","394c1008":"markdown","9e1449a3":"markdown","28e03b22":"markdown","bc9e3dd6":"markdown","c7a46f7e":"markdown","42eca223":"markdown","616e98c8":"markdown","6c8a4ff7":"markdown","a196adb6":"markdown","1d92663c":"markdown","92f133a9":"markdown","bcdf639d":"markdown","960ba277":"markdown","562fd59b":"markdown","2cbd0bb7":"markdown","79b6ab92":"markdown","faf811ce":"markdown","52f00f56":"markdown","a35d9a2a":"markdown","c1f10b49":"markdown","05bf68f6":"markdown","cd456026":"markdown","c85f81da":"markdown","3cb57f1c":"markdown","58592538":"markdown","56fd5f7f":"markdown","80ddfdf4":"markdown","2184b291":"markdown","2178c1f3":"markdown","48a5788e":"markdown","b8491b91":"markdown","e24fd5e5":"markdown"},"source":{"2cc9571d":"import numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input\n\ntqdm.pandas()\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split","5c6af898":"train_path = '\/kaggle\/input\/titanic\/train.csv'\ntrain_data = pd.read_csv(train_path)\ntrain_data = train_data.fillna(train_data.mean())","6224b559":"train_data.head(10)","cdc670c6":"def process_sex(x):\n    if x == \"male\":\n        return 1\n    else:\n        return 0\n    \ndef process_embarked(x):\n    code = [0, 0, 0, 0]\n    ports = [\"C\", \"Q\", \"S\"]\n\n    if x in ports:\n        code[list.index(ports, x)] = 1\n    else:\n        code[-1] = 1\n        \n    return tuple(code)\n        \ntrain_data[\"Sex\"] = train_data[\"Sex\"].progress_apply(process_sex)\ntrain_data[\"Embarked\"] = train_data[\"Embarked\"].progress_apply(process_embarked)","2f6f237c":"train_data[\"Embarked_0\"] = [train_data[\"Embarked\"][idx][0] for idx in tqdm(range(len(train_data)))]\ntrain_data[\"Embarked_1\"] = [train_data[\"Embarked\"][idx][1] for idx in tqdm(range(len(train_data)))]\ntrain_data[\"Embarked_2\"] = [train_data[\"Embarked\"][idx][2] for idx in tqdm(range(len(train_data)))]\ntrain_data[\"Embarked_3\"] = [train_data[\"Embarked\"][idx][3] for idx in tqdm(range(len(train_data)))]","9ca93e55":"train_data.head(10)","84a6b2a6":"y = train_data[\"Survived\"].values.reshape(len(train_data), 1)\nX = train_data[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked_0\", \"Embarked_1\", \"Embarked_2\", \"Embarked_3\"]].values","ae0e76f6":"X = X\/X.max(axis=0)","8ead4855":"train_X, val_X, train_y, val_y = train_test_split(X, y)","c20769b8":"model = Sequential()\nmodel.add(Dense(units=20, activation='relu'))\nmodel.add(Dense(units=15, activation='relu'))\nmodel.add(Dense(units=1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])","77cccbbe":"model.build(input_shape=(None, 10))\nmodel.summary()","3e068118":"model.fit(x=train_X, y=train_y, validation_data=(val_X, val_y), epochs=10)","1c6d0e67":"test_path = '\/kaggle\/input\/titanic\/test.csv'\ntest_data = pd.read_csv(test_path)\ntest_data = test_data.fillna(test_data.mean())","123f32ac":"test_data.head(10)","6a4011d1":"test_data[\"Sex\"] = test_data[\"Sex\"].progress_apply(process_sex)\ntest_data[\"Embarked\"] = test_data[\"Embarked\"].progress_apply(process_embarked)","39b325eb":"test_data","a91f3104":"test_data[\"Embarked_0\"] = [test_data[\"Embarked\"][idx][0] for idx in tqdm(range(len(test_data)))]\ntest_data[\"Embarked_1\"] = [test_data[\"Embarked\"][idx][1] for idx in tqdm(range(len(test_data)))]\ntest_data[\"Embarked_2\"] = [test_data[\"Embarked\"][idx][2] for idx in tqdm(range(len(test_data)))]\ntest_data[\"Embarked_3\"] = [test_data[\"Embarked\"][idx][3] for idx in tqdm(range(len(test_data)))]","637598ac":"X_test = test_data[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked_0\", \"Embarked_1\", \"Embarked_2\", \"Embarked_3\"]].values","c4774601":"X_test = X_test\/X_test.max(axis=0)\nX_test[np.isnan(X_test)] = 0","5bef2e68":"predictions = model.predict(X_test)\npredictions = np.round(predictions).reshape(len(X_test))","ecc3e609":"sub_path = '\/kaggle\/input\/titanic\/gender_submission.csv'\nsubmission = pd.read_csv(sub_path)","b71758d5":"submission.head(10)","921a35f2":"submission[\"Survived\"] = np.int32(predictions)","5ed404c2":"submission.head(10)","4d86e87c":"submission.to_csv('submission.csv', index=False)","f14cf627":"Running inference on the test data and rounding it off to either 0 or 1 - ","edd5d190":"# Contents","31d5a0a2":"A final look at the dataframe with our predictions - ","8587a5f9":"### Encoding the features of the test data","394c1008":"### Creating the model","9e1449a3":"Converting the dataframe into a csv file without the index column - ","28e03b22":"This being my first ML model, I learnt basics like how to create a neural network and encode features. I really enjoyed it, and look forward to learning more in the future. I also really appreciate feedback to help me improve both the accuracy and efficiency of my model :)","bc9e3dd6":"Splitting the lists of numbers under the feature 'Embarked' to obtain 4 different columns containing data of only one number per each row - ","c7a46f7e":"### Defining the features and prediction target - ","42eca223":"Splitting the lists of numbers under the feature 'Embarked' to obtain 4 different columns containing data of only one number per each row - ","616e98c8":"Since gender_submission.csv is of the format in which our submission is supposed to be made, I'm first importing it and converting it into a pandas dataframe - ","6c8a4ff7":"* Preliminary steps\n    * Importing the necessary libraries\n    * Converting the CSV file into a pandas dataframe\n* Encoding the features of the train data\n* Defining the features and prediction target\n* Creating the model\n* Fitting the model\n* Encoding the features of the test data\n* Predicting survival\n* Ending Note","a196adb6":"A look at the test data - ","1d92663c":"## Ending Note","92f133a9":"Bringing all the features to a range between 0 and 1 by dividing all the values of a feature by its biggest value. The second line of code in the cell below deals with cases where the biggest value of the feature happens to be 0. Since you cannot divide by 0, it simply substitutes 0 instead.","bcdf639d":"Replacing the 'Survived' column in the dataframe with the values we got - ","960ba277":"Providing the input size to the model - ","562fd59b":"### Encoding the features of the train data","2cbd0bb7":"Defining a new variable to hold the features - ","79b6ab92":"Encoding the 'Sex' and 'Embarked' features - ","faf811ce":"### Predicting Survival","52f00f56":"A look at the encoded features - ","a35d9a2a":"Bringing all the features to a range between 0 and 1 by dividing all the values of a feature by its biggest value - ","c1f10b49":"### Preliminary Steps","05bf68f6":"Converting the CSV file into a pandas dataframe -","cd456026":"### Fitting the model - ","c85f81da":"A look at the encoded features - ","3cb57f1c":"A look at gender_submission.csv - ","58592538":"Splitting the training data into training data and validation data - ","56fd5f7f":"# Introduction","80ddfdf4":"I made this kernel for Kaggle's Titanic competition (and it also happens to be my first one!). In this kernel, given some information, I tried to predict whether a given person aboard the ship had survived.","2184b291":"<img src=\"https:\/\/i.imgur.com\/qBl2QL2.jpg\" width=\"600px\">","2178c1f3":"Encoding the 'Sex' and 'Embarked' features - ","48a5788e":"Converting the CSV file into a pandas dataframe -","b8491b91":"Importing the necessary libraries -","e24fd5e5":"A look at some of the train data - "}}