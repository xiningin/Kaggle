{"cell_type":{"fc7be9e7":"code","c02b5c6f":"code","a2787701":"code","a8b636c1":"code","7658eb9d":"code","c761b4db":"code","38162fb9":"code","54e1e7f4":"code","74bfedce":"code","133653fc":"code","4d5b11e8":"markdown","5daf0622":"markdown"},"source":{"fc7be9e7":"import pandas as pd\nimport os\nimport os, sys, math\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom google.cloud import storage\nfrom PIL import Image\nAUTO = tf.data.experimental.AUTOTUNE ","c02b5c6f":"TRAIN_META_PATH = '..\/input\/landmark-recognition-2021\/train.csv'\nCRE_PATH = '..\/input\/dtjson\/datalab-284706-d4063c8726d8.json'\n!gcloud auth activate-service-account --key-file '{CRE_PATH}'","a2787701":"train_df = pd.read_csv(TRAIN_META_PATH)\ntrain_df.head(3)","a8b636c1":"train_df['path'] = train_df['id'].apply(lambda r: os.path.join('..\/input\/landmark-recognition-2021\/train',r[0], r[1], r[2], r + '.jpg'))\ntrain_df['path_label'] = train_df['path'] + ',' + train_df['landmark_id'].astype(str)","7658eb9d":"train_df.head(2)","c761b4db":"Image.open(train_df.iloc[11].path).resize((224,224))","38162fb9":"GCS_OUTPUT = 'gs:\/\/challenge_ngoan\/gglm21_kaggle\/tfrecords-224x224\/train_'  # prefix for output file names\nSHARDS = 128\nTARGET_SIZE = [224, 224]\nCLASSES = list(set(train_df.landmark_id))\nnb_images = len(train_df['path_label'])\nshard_size = math.ceil(1.0 * nb_images \/ SHARDS)\nprint(\"Pattern matches {} images which will be rewritten as {} .tfrec files containing {} images each.\".format(nb_images, SHARDS, shard_size))","54e1e7f4":"def decode_jpeg_and_label(filename_label):\n    results = tf.strings.split(tf.expand_dims(filename_label, axis=-1), sep=',')\n    filename = results.values[0]\n    label = results.values[1]\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits)\n    return image, label\n\ndef resize_and_crop_image(image, label):\n    w = tf.shape(image)[0]\n    h = tf.shape(image)[1]    \n    tw = TARGET_SIZE[1]\n    th = TARGET_SIZE[0]\n    image = tf.image.resize(image, [tw, tw])\n    height = tf.shape(image)[0]\n    width = tf.shape(image)[1]\n    image = tf.cast(image, tf.uint8)\n    image = tf.image.encode_jpeg(image, optimize_size=False, chroma_downsampling=False)\n    return image, label, height, width\n\nfilenames = tf.data.Dataset.from_tensor_slices(list(train_df['path_label'])) # This also shuffles the images\ndataset1 = filenames.map(decode_jpeg_and_label)\n\ndataset2 = dataset1.map(resize_and_crop_image, num_parallel_calls=AUTO)  \ndataset2 = dataset2.batch(shard_size)","74bfedce":"def _bytestring_feature(list_of_bytestrings):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))\n\ndef _int_feature(list_of_ints): # int64\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))\n\ndef _float_feature(list_of_floats): # float32\n    return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))\n  \n\ndef to_tfrecord(tfrec_filewriter, img_bytes, label, height, width):  \n    class_num = np.argmax(np.array(CLASSES)==label) # 'roses' => 2 (order defined in CLASSES)\n    one_hot_class = np.eye(len(CLASSES))[class_num]     # [0, 0, 1, 0, 0] for class #2, roses\n  \n    feature = {\n      \"image\": _bytestring_feature([img_bytes]), # one image in the list\n      \"class\": _int_feature([class_num]),        # one class in the list      \n      \"label\":         _bytestring_feature([label]),          # fixed length (1) list of strings, the text label\n      \"size\":          _int_feature([height, width]),         # fixed length (2) list of ints\n      \"one_hot_class\": _float_feature(one_hot_class.tolist()) # variable length  list of floats, n=len(CLASSES)\n  }\n    return tf.train.Example(features=tf.train.Features(feature=feature))","133653fc":"print(\"Writing TFRecords\")\nfor shard, (image, label, height, width) in enumerate(dataset2):\n    shard_size = image.numpy().shape[0]\n    filename = GCS_OUTPUT + \"{:02d}-{}.tfrec\".format(shard, shard_size)\n    with tf.io.TFRecordWriter(filename) as out_file:\n        for i in range(shard_size):\n            example = to_tfrecord(out_file,\n                            image.numpy()[i],\n                            label.numpy()[i],\n                            height.numpy()[i],\n                            width.numpy()[i])\n            out_file.write(example.SerializeToString())\n            print(\"Wrote file {} containing {} records\".format(filename, i))","4d5b11e8":"Hello everyone, I am a new Kaggler and happy to join this competition with all of you.\n\nI write the notebook to convert train data to tfrecord and save to my Google Cloud Storage. \nI will share this dataset when the progress has done.","5daf0622":"In the first version, I will convert the image to size 224x224x3 and save into 128 tfrecord files. "}}