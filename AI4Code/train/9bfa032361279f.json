{"cell_type":{"ecab4e67":"code","c427473c":"code","882cd1b3":"code","98739bc0":"code","6cfa4a13":"code","3d40ff2c":"code","a2490051":"code","16ba2d6c":"code","661dd994":"code","cc64b34a":"code","3ab66fe4":"code","141ed364":"code","168b5196":"code","e5983826":"code","c932cc05":"code","d32034a3":"code","e4ad4512":"code","10d9e86e":"code","e27c9967":"code","c000d98d":"code","6fbab657":"code","0a0be69e":"code","7f7650ca":"code","c57f92b1":"code","f768efe3":"code","69982485":"code","2558e5e5":"code","c67e32f7":"code","5b6cd68f":"code","2973b709":"code","d886d1f8":"code","b6302969":"code","56cf6135":"code","0b2b9fad":"code","36d38cf2":"code","388058c7":"code","3677b320":"code","9496b5c2":"code","7922581f":"code","51174407":"code","2d1e08cc":"code","8003848a":"code","aab9184e":"code","7e90fd4d":"code","2ac2d304":"code","6d7e345d":"code","d9e73edb":"code","10150358":"code","f9dceb90":"code","fd9021ac":"markdown","522c1f35":"markdown","be846280":"markdown","04e2ffc2":"markdown","7778f55b":"markdown","1b2906ec":"markdown","dc5cf989":"markdown","241dd1aa":"markdown","c4053db8":"markdown","48be57d1":"markdown","b2161476":"markdown","bdfd4c98":"markdown","8a86e9d2":"markdown","27189d9c":"markdown","5c488df0":"markdown","ebc1f063":"markdown","99fa4403":"markdown","46c532c4":"markdown","9eb00eb1":"markdown","96759d35":"markdown","36611eb9":"markdown","4f12a67f":"markdown","0f3cb0ac":"markdown","16819c16":"markdown","88719178":"markdown","1beb8f17":"markdown","9e03fb3d":"markdown","e395e962":"markdown","444bc222":"markdown","3b4af891":"markdown","f96db08f":"markdown","73bd8d45":"markdown","a9ee41c5":"markdown","0010450a":"markdown","185d7872":"markdown","175b5000":"markdown","265de5e4":"markdown","e0d69e00":"markdown","b4fe83ea":"markdown","e2bd7bd5":"markdown","e9879150":"markdown","c43dc462":"markdown","b63b6274":"markdown","b85e79e6":"markdown","63e30c3f":"markdown","fd4fc024":"markdown","9d27fa41":"markdown","b3107451":"markdown","6fc3ba74":"markdown"},"source":{"ecab4e67":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c427473c":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns","882cd1b3":"df = pd.read_csv(\"\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv\")","98739bc0":"df.head()","6cfa4a13":"df.info()","3d40ff2c":"df.describe()","a2490051":"sns.countplot(x=\"quality\", data=df)","16ba2d6c":"sns.distplot(a=df['quality'], kde=False)","661dd994":"plt.figure(figsize=(16,6))\nsns.lineplot(data=df, dashes=False)","cc64b34a":"sns.pairplot(df, hue=\"quality\")\nplt.show()","3ab66fe4":"sns.pairplot(data=df, kind='reg', y_vars=['quality'], x_vars=[col for col in df.columns if col != 'quality'])","141ed364":"sns.regplot(x=\"fixed acidity\", y=\"quality\", data=df)","168b5196":"df.isna().any().any()","e5983826":"corr = df.corr()","c932cc05":"mask = np.triu(np.ones_like(corr, dtype=bool))","d32034a3":"f, ax = plt.subplots(figsize=(11, 9))\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","e4ad4512":"df['quality'] = df['quality'].map(lambda x: x >= 6)","10d9e86e":"df.head()","e27c9967":"df.describe()","c000d98d":"df.info()","6fbab657":"sns.countplot(x=\"quality\", data=df)","0a0be69e":"y = df['quality']","7f7650ca":"class_names = list(y.unique())","c57f92b1":"X = df.drop(columns='quality')\nX","f768efe3":"y","69982485":"from sklearn.model_selection import train_test_split","2558e5e5":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10)","c67e32f7":"X_train","5b6cd68f":"y_train","2973b709":"y_test","d886d1f8":"X_test","b6302969":"from sklearn.neighbors import KNeighborsClassifier\nclf = KNeighborsClassifier(n_neighbors=3)","56cf6135":"clf.fit(X_train, y_train)","0b2b9fad":"y_pred = clf.predict(X_test)","36d38cf2":"from sklearn import metrics\ncm = metrics.confusion_matrix(y_test, y_pred)\nprint(cm)","388058c7":"y_pred_proba = clf.predict_proba(X_test)","3677b320":"from sklearn import metrics","9496b5c2":"print(\"Accuracy-Score ist\", metrics.accuracy_score(y_test, y_pred))","7922581f":"print(metrics.classification_report(y_test, y_pred))","51174407":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10)\nk_range = range(1,60)\naccuracy_list = []\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    y_pred = knn.predict(X_test)\n    accuracy = metrics.accuracy_score(y_test, y_pred)\n    print(f\"k={k} ergibt eine Klassifikationsgenauigkeit von {accuracy}\")\n    accuracy_list.append(accuracy)","2d1e08cc":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nplt.plot(k_range, accuracy_list)\nplt.xlabel(\"k n\u00e4chste Nachbarn\")\nplt.ylabel(\"Klassifikationsgenauigkeit\")\nplt.show()","8003848a":"from sklearn.tree import DecisionTreeRegressor","aab9184e":"#definier das Modell mit einer spezifischen Nummer als random_state\nwine_model = DecisionTreeRegressor(random_state=1)\n#fit Modell\nwine_model.fit(X,y)","7e90fd4d":"print(\"Making predictions for the following 5 wines:\")\nprint(X.head())\nprint(\"The predictions are\")\nprint(wine_model.predict(X.head()))","2ac2d304":"from sklearn.metrics import mean_absolute_error\n\npredicted_wine_quality = wine_model.predict(X)\nmean_absolute_error(y, predicted_wine_quality)","6d7e345d":"#define model\nwine_model = DecisionTreeRegressor()\n\n# Fit model\nwine_model.fit(X_train, y_train)\n\n# get predicted prices on validation data\ntest_predictions = wine_model.predict(X_test)\nprint(mean_absolute_error(y_test, test_predictions))","d9e73edb":"print(\"Accuracy-Score ist\", metrics.accuracy_score(y_test, test_predictions))","10150358":"def get_mae(max_leaf_nodes, X_train, X_test, y_train, y_test):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(X_train, y_train)\n    preds_val = model.predict(X_test)\n    mae = mean_absolute_error(y_test, preds_val)\n    return(mae)\nfor max_leaf_nodes in [2, 50, 100, 500]:\n    my_mae = get_mae(max_leaf_nodes, X_train, X_test, y_train, y_test)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))","f9dceb90":"from sklearn.ensemble import RandomForestRegressor\nforest_wine_model = RandomForestRegressor(random_state=1)\nforest_wine_model.fit(X_train, y_train)\nwine_preds = forest_wine_model.predict(X_test)","fd9021ac":"# 2. Gesch\u00e4ftsverst\u00e4ndnis","522c1f35":"Es gibt viele Metriken zur Zusammenfassung der Modellqualit\u00e4t. Jetzt schauen wir uns den Mitlleren Absoluten Fehler an. \n\nDer Vorhersagefehler f\u00fcr jedes Haus ist:\n\nQuelle: https:\/\/www.kaggle.com\/dansbecker\/model-validation","be846280":"# Features\nDie Features sind fixed acidit,volatile acidity\tcitric acid\tresidual sugar\tchlorides\tfree sulfur dioxide\ttotal sulfur dioxide\tdensity\tpH\tsulphates\talcohol. Es sind objektive Eigenschafte eines Weines. Qualit\u00e4t ist kein Feature weil man es nicht wissenschaftlich messen kann. Unser Modell wird messen, wie die objektiven Features das subjektive Empfinden (also die Qualuit\u00e4t) beinflusst.\n\n","04e2ffc2":"# **6.  Modellevaluierung**","7778f55b":"# Daten Visualisierung","1b2906ec":"![](https:\/\/image.brigitte.de\/11594398\/t\/ST\/v3\/w960\/r1.5\/-\/wein-abc-bild.jpg)","dc5cf989":"Der Datensatz hat 12 Spalten und 1599 Zeilen. 11 Spalten haben den Datentyp float64 und die Spalte quality hat den Datentyp int64.","241dd1aa":"Das Problem eines Winzers ist es, anhand der Attribute eines Weines vorauszusagen, wie gut ein Wein qualitativ sein wird. Wobei Qualit\u00e4t schwer zu messen ist, weil damit wahrscheinlich der Geschmack gemeint ist, und dieser ist nicht objektiv. Die Qualit\u00e4t des Weines h\u00e4ngt von der Zusammensetzung der 11 Attributen ab. Nach der Bearbeitung des Projektes, kann ein Winzer mit einem Modell herausfinden, wie gut sein Wein wahrscheinlich sein wird. Winzer soll in der Lage sein, mit recht hoher Wahrscheinlichkeit Qualit\u00e4t des Weines zu vorauszusagen.","c4053db8":"Als Beispile gucken wir uns jetzt nur den Regressionsplot an zwischen fixed acidity und quality an.\nEs ist zu sehen, dass die Qualit\u00e4t langsam steigt je h\u00f6her die fixed acidity ist.","48be57d1":"F\u00fcr die Featureauswahl betrachten wir die Korrelation der Variblen von Quality.\nQuelle: https:\/\/seaborn.pydata.org\/generated\/seaborn.heatmap.html","b2161476":"# Laden der Daten in ein Panda Data Frame","bdfd4c98":"Wir l\u00f6schen keine Spalten da die Korrelation untereinader nicht so hoch ist. Ab einer Korrelation von 0,7 oder -0,7 kann man von einer hohen Korrelation sprechen. Das ist aber bei keiner der Korrelationen der Fall.","8a86e9d2":"Jetzt wird das erst Modell ausprobiert. Das kNN. Es ist relativ einfach nachzuvollziehen und hinzuf\u00fcgen von Daten ist m\u00f6glich ohne der Neuberechnung des Klassifikators.","27189d9c":"Wir sehen, es fehlen keine Daten.","5c488df0":"Jetzt wird der Einfluss von k auf die Klassifikationsgenauigkeit \u00fcberpr\u00fcft. ","ebc1f063":"Das kNN Modell w\u00fcrde Winzern dabei helfen, mit einer Genauigkeit von 75,5 Prozent die Qualit\u00e4t ihres Weines vorauszusagen. So kann er theoretische Weine erstellen und vorausssagen, wie die Qualit\u00e4t sein wird und wenn er einen guten theoretischen Wein gefunden hat, kann er ihn keltern.\n\nEs ist auch m\u00f6glich, die besten Weine zu analysieren und einen Durchschnitt der Eigenschaften zu erhalten, und so zu versuchen, welcher Wein optimal ist. Man kann diesen Durchschnitt auch nehmen und mit dem theoretischen Wein abzugleichen, um zu \u00fcberpr\u00fcfen, ob man einen guten Wein erstellt hat.","99fa4403":"Hier sehen wir die ersten f\u00fcnf Zeilen mit \u00dcberschriften:","46c532c4":"Hier erkennt man, wie oft es Weine in verschiedenen Qualit\u00e4ten gibt. Man sieht, die Qualit\u00e4t wird von 3 bis 8 bemessen und die meisten Weine habe eine Qualit\u00e4t von 5 und 6.","9eb00eb1":"Jetzt petrachten wir wie jede Variable Qualit\u00e4t einzeln beinflusst. Quelle: https:\/\/stackoverflow.com\/questions\/31966494\/compare-1-independent-vs-many-dependent-variables-using-seaborn-pairplot-in-an-h","96759d35":"# **Decision Tree**","36611eb9":"**Beschreibung des Datensatzes**","4f12a67f":"**Model Validation**","0f3cb0ac":"# **Wine Quality Projekt**","16819c16":"Durch die Angabe einer Zahl f\u00fcr random_state wird sichergestellt, dass man bei jedem Durchlauf die gleichen Ergebnisse erh\u00e4lt.","88719178":"# K-N\u00e4chste Nachbarn Verfahren\u00b6\n","1beb8f17":"Accurary Score kNN: 0,755\nAccurary Score Decision Tree: 0,73\nDas kNN ist akkurater und ich empfehe es deshalb.\nF\u00fcr das kNN Modell ist k = 1 optimal\n\nEin weitere optimierung der Ergebnisse ist mir nicht gelungen, hier gibt es noch Potential.\nDie \u00c4nderung der Qualit\u00e4t in einen bin\u00e4ren Wert, hat wahrscheinlich ein akurateres Ergebnis verhindert.","9e03fb3d":"**Daten Transformation**","e395e962":"Bein ungef\u00e4hr k = 1 ist die h\u00f6chste Klassifikationsgenauigkeit mit 0,755. Das hei\u00dft wir konnten den Paramter optimieren und damit einen besseren Accuracy Score erzielen. 0,755 ist h\u00f6her als 0,69.","444bc222":"# 3. Datenverst\u00e4ndnis (Exploratory Data Analysis)","3b4af891":"KNN hat einen Accuracy Score von 0,69. Also hat er eine genauigkeit von 69 Prozent.","f96db08f":"df.describe hilft dabei ein besseres Verst\u00e4ndnis der Daten zu erlangen, weil man den Durchschnitt der Spalten und die Standardabweichung ablesen kann.","73bd8d45":"In Matrix sieht man oben Links und unten Rechts erkennt man, wie oft das Modell richtig lag.","a9ee41c5":"Hier sehen wir weitere Informationen \u00fcber die Daten und sehen die Datentaypen und ob es Null Werte in den Zellen gibt. Also ob es fehlende Daten gibt. Wie wir sehen, gibt es keine Fehlenden Daten.","0010450a":"Berechnung Accury Score:","185d7872":"Zu Vereinfachung, wird die Qualit\u00e4t vonn Wein in einen Bin\u00e4ren Wert Umgewandelt. Also gibt es Guten und Schlechten Wein. Wein mit Qualit\u00e4t von 3 bis 5 ist schlecht und wWein mit der Qualit\u00e4t von 6 bis 8 ist gut.","175b5000":"# 4. Datenaufbereitung\n","265de5e4":"Auch der Pairplot ist sehr un\u00fcbersichtlich aber kann erste Einblicke \u00fcber den Zusammenhang von den Attributen und der Qualit\u00e4t geben.","e0d69e00":"Berechnung der Mean Absolute Errors: ","b4fe83ea":"Wir trennen Features von quality.","e2bd7bd5":"Wir sehen, dass quality jetzt den Datentyp bool hat.","e9879150":"Student: Jan Tobias Friedrich Schneider\nMatrikelnummer: 1806180","c43dc462":"# **7. M\u00f6glicher Gesch\u00e4ftseinsatz**","b63b6274":"KNN Evaluieren\nVergleichen:\n\ny_test: Wahren Klassen (Labels)\ny_pred: Vorhergesagte Klassen (Labels)","b85e79e6":"# Untersuchug nach fehlenden Daten \nQuelle: https:\/\/towardsdatascience.com\/how-to-check-for-missing-values-in-pandas-d2749e45a345","63e30c3f":"**Aufteilung der Daten in Trainingsdaten**","fd4fc024":"# Datenvorverarbeitung\ny: Labels (Vektor)\nX: Features (Matrix)\ny_pred = f(X)\n\n","9d27fa41":"Datenaufteilung Train Test Split","b3107451":"# 5. Modellbildung","6fc3ba74":"Der Line Plot ist sehr un\u00fcbersichtlich. dashes=False, weil wir sonst nicht mehr als 6 kolorierte Lines anzeigen k\u00f6nnten."}}