{"cell_type":{"5a57cfba":"code","a4a5336e":"code","8a6ef0e8":"code","fe7e8019":"code","9b1ea470":"code","e03697aa":"code","bcdcdf11":"code","49c9804b":"code","7a7bc26b":"code","a5830273":"code","4da9544f":"code","f63de479":"code","c1ec6592":"code","bb0fce89":"code","4d63bffe":"code","ce1cd964":"code","1bb90589":"code","6158b8d5":"code","5547bed7":"code","7ae18679":"code","96051f7b":"code","be53135e":"code","c493fcfd":"code","d74cb2eb":"markdown","36d1d326":"markdown","19be8eaf":"markdown","9b836b81":"markdown","44361e66":"markdown","b132b113":"markdown","e2ff9d4a":"markdown"},"source":{"5a57cfba":"#import requred libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')","a4a5336e":"#reading dataset\ndf = pd.read_csv('..\/input\/bank-customer-churn-modeling\/Churn_Modelling.csv')\ndf.head()","8a6ef0e8":"df.describe()","fe7e8019":"#Getting data types of the all columns\ndf.dtypes","9b1ea470":"# #Checking null values\ndf.isnull().sum()","e03697aa":"#Simple covarience\nplt.figure(figsize=(15,8))\nsns.heatmap(df.cov(),annot=True,cmap='viridis')\nplt.show()","bcdcdf11":"# #simple correlations\nplt.figure(figsize=(15,8))\nsns.heatmap(df.corr(),annot=True)\nplt.show()","49c9804b":"#checking imbalanced data\nplt.figure(figsize=(12,5))\nsns.countplot(df.Exited)\nplt.grid()\nplt.show()","7a7bc26b":"#remove unwanted columns\ncols_to_drop = ['RowNumber','CustomerId','Surname']\ndf = df.drop(cols_to_drop,axis=1)\ndf.head()","a5830273":"#getting all the objects columns for knowing the unique values\nfor i in df.columns:\n    if df[i].dtypes == \"object\":\n        unique = df[i].unique()\n        print(i,\"=\",unique)","4da9544f":"le = LabelEncoder()\ndf.Geography = le.fit_transform(df.Geography)\n\n#Mapping values to the gender column by 0 and 1\ndf.Gender = df.Gender.map({\"Female\":0,\"Male\":1})","f63de479":"X = df.drop(\"Exited\",axis=1)\ny = df[\"Exited\"]","c1ec6592":"smote = SMOTE()\nX_sm,y_sm = smote.fit_resample(X.astype(float),y)","bb0fce89":"x_train,x_test,y_train,y_test = train_test_split(X_sm,y_sm,test_size=0.2,random_state=42)\nlen(x_train),len(x_test),len(y_train),len(y_test)","4d63bffe":"scaler = MinMaxScaler()\n#fit the training datatset\nscaler.fit(x_train)\n\n#transform train and test sets\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)","ce1cd964":"model = keras.Sequential([\n    \n    keras.layers.Dense(32,input_shape=(X.shape[1],)),\n    keras.layers.Activation(tf.nn.relu),\n    \n    keras.layers.Dense(16),\n    keras.layers.Activation(tf.nn.relu),\n\n    keras.layers.Dense(8),\n    keras.layers.Activation(tf.nn.relu),\n    \n    keras.layers.Dense(1),\n    keras.layers.Activation(tf.nn.sigmoid)\n])","1bb90589":"model.compile(tf.keras.optimizers.Adam(learning_rate=1e-4),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","6158b8d5":"history = model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=150,batch_size=32)","5547bed7":"#Vizualize the loss \nplt.figure(figsize=(10,5))\nplt.plot(history.history['loss'],label='train',color='g')\nplt.plot(history.history['val_loss'],label='test')\nplt.title('LOSS')\nplt.xlabel(\"Loss\")\nplt.ylabel(\"Epoch\")\nplt.legend()\nplt.show()","7ae18679":"#Vizualize the accuracy\nplt.figure(figsize=(10,5))\nplt.plot(history.history['accuracy'],label='train-accuracy',color='g')\nplt.plot(history.history['val_accuracy'],label='validation-accuracy')\nplt.title('ACCURACY')\nplt.xlabel(\"Loss\")\nplt.ylabel(\"Epoch\")\nplt.legend()\nplt.show()","96051f7b":"y_pred_ = model.predict(x_test)\ny_pred = []\nfor target in y_pred_:\n    if target > 0.5:\n        y_pred.append(1)\n    else:\n        y_pred.append(0)\n\nprint(\"Classification report: \\n\", classification_report(y_test,y_pred))","be53135e":"#Confusion Matrix\ncm = confusion_matrix(y_test,y_pred)\nplt.figure(figsize=(10,8))\nsns.heatmap(cm,annot=True)\nplt.show()","c493fcfd":"accuracy_score(y_test,y_pred)","d74cb2eb":"### Building Model","36d1d326":"### Feature Engineering","19be8eaf":"#### Feture Scalling","9b836b81":"### Handeling Imbalanced Data","44361e66":"### Exploratory data analysis","b132b113":"### Spliting data into training and testing set","e2ff9d4a":"Here we will be using SMOTE technique to handeling imbalanced dataset"}}