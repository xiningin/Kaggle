{"cell_type":{"52b1db9f":"code","9ae2d460":"code","61555535":"code","30d0b218":"code","692f9124":"code","723040cf":"code","c108fbfb":"code","caad91e7":"code","1668efd2":"code","5cf74835":"code","981713f8":"code","762221ad":"code","96d9b974":"code","ab681a12":"code","819c9ce7":"code","6354b485":"code","95a284a2":"code","0760fe83":"code","eaa7ec2e":"code","de1955c0":"code","d305a454":"code","244d0bab":"code","84742240":"code","82c37d0e":"code","856bd1c9":"code","aa641807":"code","484b2559":"code","afa82ab9":"code","fde97d36":"code","e94da071":"code","ebe1e76e":"code","7d483ddd":"code","a8e908b5":"code","51a4b551":"code","e3a56a0a":"code","3f17a546":"markdown","7c482a1b":"markdown","06727b70":"markdown","2e7b16d0":"markdown","cdc43608":"markdown","3f955691":"markdown","2447cccc":"markdown","f4de09bc":"markdown","4e31c3a6":"markdown","90cd6ae0":"markdown"},"source":{"52b1db9f":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV","9ae2d460":"# load dataset\ndf = pd.read_csv(\"\/kaggle\/input\/credit-card-applications-dataset\/cc_approvals.data\", header=None)\ndf.head(20)","61555535":"# dataframe information\ndf.info()","30d0b218":"df.describe()","692f9124":"# summary statistics\ndf.describe(include = 'O') \n#notice the '?' there, these need to be removed\/replaced","723040cf":"df.tail(20) \n# notice the '?' there, these need to be removed\/replaced","c108fbfb":"df.isnull().sum()","caad91e7":"# replace the '?'s with NaN\ndf.replace('?', np.nan, inplace=True)\n\n# inspect the missing values again\ndf.tail(20)","1668efd2":"# impute the missing values with mean imputation\ndf.fillna(df.mean(), inplace=True)","5cf74835":"# count the number of NaNs in the dataset and print the counts to verify\ndf.isnull().sum()","981713f8":"# use backfill method to fill nan values in object columns\nfor cname in df:\n    if df[cname].dtypes == \"object\":\n        df[cname].fillna(method = 'backfill', inplace = True)","762221ad":"# finally check for any duplicate rows\ndf.duplicated().sum()","96d9b974":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\n# extract columns having data type as object (i.e non numeric)\nfor col in df:\n    if df[col].dtypes =='object':\n        df[col]=le.fit_transform(df[col])  # use LabelEncoder to transform values into numeric","ab681a12":"df.head(20)\n# all values converted to numeric","819c9ce7":"df.nunique()","6354b485":"# drop the features 11 and 13 because feature 11 corresponds to DriversLicencse and 13 to ZipCode which are both unimportant for us\ndf = df.drop([11, 13], axis=1)","95a284a2":"# view the df to verify\ndf.head()","0760fe83":"# segregate features and labels into separate variables\nX = df.drop([15], axis =1)\ny = df[15]","eaa7ec2e":"# perform one hot encoding on columns that have less than 5 unique values so that all values are considered of equal weight\nX = pd.get_dummies(X, columns=[3,4,8,9,12]) ","de1955c0":"# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)","d305a454":"# data scaling\n\nscaler = MinMaxScaler(feature_range=(0,1))\nrescaledX_train = scaler.fit_transform(X_train)\nrescaledX_test = scaler.fit_transform(X_test)","244d0bab":"# Logistic Regression Model\nfrom sklearn.linear_model import LogisticRegression\n\nlr_model = LogisticRegression(random_state = 15)\nlr_model.fit(rescaledX_train, y_train)","84742240":"y_pred = lr_model.predict(rescaledX_test)","82c37d0e":"# model evaluation\nprint(\"Accuracy of logistic regression classifier: \", lr_model.score(rescaledX_test, y_test))","856bd1c9":"# Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nrfc_model = RandomForestClassifier(random_state = 36)\nrfc_model.fit(rescaledX_train, y_train)","aa641807":"y_pred = rfc_model.predict(rescaledX_test)","484b2559":"# model evaluation\nprint(\"Accuracy of random forest classifier: \", rfc_model.score(rescaledX_test, y_test))","afa82ab9":"#KNeightboursClassifier Model\nfrom sklearn.neighbors import KNeighborsClassifier\n\nkn_model = KNeighborsClassifier()\nkn_model.fit(rescaledX_train, y_train)","fde97d36":"y_pred = kn_model.predict(rescaledX_test)","e94da071":"# model evaluation\nprint(\"Accuracy of KNeighbors classifier: \", kn_model.score(rescaledX_test, y_test))","ebe1e76e":"# hyperparameter tuning for RandomForestClassifier\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nparameters = {'n_estimators': [20, 50, 60, 80, 90, 100, 120, 150, 200], 'max_features': [\"auto\", \"sqrt\", \"log2\"]}\ncls = GridSearchCV(estimator = rfc_model, param_grid = parameters)\ncls.fit(rescaledX_train, y_train)\n\n# displaying the best params \ncls.best_params_","7d483ddd":"rfc_model2 = RandomForestClassifier(random_state = 36, n_estimators = 150, max_features = 'auto')\nrfc_model2.fit(rescaledX_train, y_train)\ny_pred = rfc_model2.predict(rescaledX_test)\nrfc_model2.score(rescaledX_test, y_test)","a8e908b5":"# hyperparameter tuning for RandomForestClassifier\n\nn_neighbors = range(1, 21, 2)\nparameters = {'n_neighbors': n_neighbors, 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan', 'minkowski']}\ncls = GridSearchCV(estimator = kn_model, param_grid = parameters)\ncls.fit(rescaledX_train, y_train)\n\n# displaying the best params \ncls.best_params_","51a4b551":"kn_model2 = KNeighborsClassifier(n_neighbors=15, weights = 'distance', metric='euclidean')\nkn_model2.fit(rescaledX_train, y_train)\ny_pred = kn_model2.predict(rescaledX_test)\nkn_model2.score(rescaledX_test, y_test)","e3a56a0a":"model = RandomForestClassifier(random_state = 36, n_estimators = 150, max_features = 'auto')\nmodel.fit(rescaledX_train, y_train)\ny_pred = model.predict(rescaledX_test)\nmodel.score(rescaledX_test, y_test)","3f17a546":"# Predicting Credit Card Application Approvals","7c482a1b":"As seen, the column names are anonymized by the contributor since this data is confidential.\n\n<a href=\"http:\/\/rstudio-pubs-static.s3.amazonaws.com\/73039_9946de135c0a49daa7a0a9eda4a67a72.html\"> This blog<\/a> gives us a pretty good overview of the probable features. The probable features in a typical credit card application are <i>Gender, Age, Debt, Married, BankCustomer, EducationLevel, Ethnicity, YearsEmployed, PriorDefault, Employed, CreditScore, DriversLicense, Citizen, ZipCode, Income and finally the ApprovalStatus.<\/i> This gives us a pretty good starting point, and we can map these features with respect to the columns in the output.","06727b70":"### Data Preprocessing","2e7b16d0":"The best score is using the Random Forest Classifier model with parameters obtained from GridSearchCV(). Hence, our final model for Credit Card Aprovals is now ready!","cdc43608":"### <b>The Machine Learning Model is able to predict Credit Card Approvals with an enhanced accuracy of 90.36%<\/b>","3f955691":"### Data Imputation","2447cccc":"Banks receive a lot of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low credit scores or low income levels and etc for example.\nThe task I wish to achieve from this notebook is to build an automatic credit card approval predictor using Data Analysis and Machine Learning. For this, I have: \n1) Load and read the data\n\n2) Perform data cleaning- deal with missing values, duplicate values\n\n3) Data Preprocessing- converting non-numeric values to numeric, scaling the dataset values to best fit a Machine Learning algorithm and finally split the dataset into train and test data\n\n4) Exploratory data analysis to build an intuition about model needed\n\n5) Build a Machine Learning model that is able to predict if an individual credit card application is approved or reject\n\nThe dataset that I have picked is the <a href=\"http:\/\/archive.ics.uci.edu\/ml\/datasets\/credit+approval\">Credit Card Approval dataset<\/a> from the UCI Machine Learning Repository.","f4de09bc":"### Model Building\n\nThis is a classifcation problem and the possible models I would consider for this are- Logistic Regression, Random Forrest Classifer and KNeighbors Classifer. Lets build these models and check accuraries","4e31c3a6":"The Random Forest and KNeighbors Classifiers have the best accuracy. Lets hypertune parameters for these and check our best model for Credit Card Approval predictions!","90cd6ae0":"### Hypertuning the model"}}