{"cell_type":{"642c52d8":"code","953ced40":"code","fd50643c":"code","7a88b400":"code","f4ed64ff":"code","23868c47":"code","82d567f3":"code","207e2f15":"code","921e097f":"code","f21aedcb":"code","bef6d8b8":"code","483adf2e":"code","b3970ce1":"code","ea9b0730":"code","f582242a":"code","e87b4d86":"code","3c855455":"markdown","bc92c605":"markdown","1764487d":"markdown","ece5afc6":"markdown","aa959ec6":"markdown","3e390e09":"markdown","cda6240d":"markdown","550fde8e":"markdown"},"source":{"642c52d8":"#import required libraries\nimport pandas as pd \nimport seaborn as sns\nfrom matplotlib import pyplot as plt \n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix","953ced40":"filename = \"..\/input\/iris\/Iris.csv\"\ndf = pd.read_csv(filename)\ndf.head()","fd50643c":"#checking null values \ndf.isnull().sum()","7a88b400":"#shape of the data (m x n )\ndf.shape","f4ed64ff":"#checking duplicate\ndf.duplicated().sum()","23868c47":"#Correlation \nplt.figure(figsize=(12,5))\nsns.heatmap(df.corr(),annot=True, yticklabels=True)\nplt.show()","82d567f3":"df.describe()","207e2f15":"#species \ndf.Species.value_counts()","921e097f":"df[\"Species\"] = df[\"Species\"].map({\"Iris-setosa\":0,\n                            \"Iris-virginica\":1,\n                            \"Iris-versicolor\":2})","f21aedcb":"df.head()","bef6d8b8":"#remove Id columns from data\n\ndf = df.drop(\"Id\",axis=1)","483adf2e":"X = df.drop(\"Species\",axis=1)\ny = df[[\"Species\"]]","b3970ce1":"x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n\n#Print the length of test and train data\n\nprint(f\"The length of actual X: {len(X)}\")\nprint(f\"The length of actual y: {len(y)}\")\nprint(f\"The length of X-test  : {len(x_test)}\")\nprint(f\"The length of X-train : {len(x_train)}\")\nprint(f\"The length of Y-test  : {len(y_test)}\")\nprint(f\"The length of Y-train : {len(y_train)}\")","ea9b0730":"model = LogisticRegression()\nmodel.fit(x_train,y_train)\ny_pred = model.predict(x_test)\nprint(y_pred)","f582242a":"#accuracy of model\n\nscore = accuracy_score(y_test,y_pred)\ncm = confusion_matrix(y_test,y_pred)\ntest_score = model.score(x_test,y_test)\ntrain_score = model.score(x_train,y_train)\n\nprint(\"Accuracy Score is: \",score)\nprint(\"Test Score is: \",test_score)\nprint(\"Train Score is: \",train_score)\nprint(\"Confusion Metrics Is: \\n\",cm)","e87b4d86":"### User Input\n\nsepal_length = float(input(\"Enter a sepal lenght (cm)\"))\nsepal_width = float(input(\"Enter a sepal Width (cm)\"))\npetal_length = float(input(\"Enter a petal lenght (cm)\"))\npetal_width = float(input(\"Enter a petal Width (cm)\"))\n\npred = model.predict([[sepal_length,sepal_width,petal_length,petal_width]])\n\nif (pred==0):\n    print(\"Setosa\")\nelif (pred==1):\n    print(\"virginica\")\nelse:\n    print(\"versicolor\")","3c855455":"We don't need to worry about null values cause there is no any null value in data","bc92c605":"**Encoding**","1764487d":"# Feature Engineering","ece5afc6":"**Split the data Into Dependant and Independat variable**","aa959ec6":"# Spliting the data into Training and testing set","3e390e09":"Applying Machine Learning Algorithm to create a model","cda6240d":"## Exploratory Data Analysis","550fde8e":"# Prediction"}}