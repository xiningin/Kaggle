{"cell_type":{"5f039bc3":"code","23aeb943":"code","97f94baa":"code","38432af6":"code","af5f59bf":"code","e8f4ab78":"code","67e309df":"markdown","48359b31":"markdown","8e89c117":"markdown","d621adab":"markdown","585b9451":"markdown","bbbab2f6":"markdown"},"source":{"5f039bc3":"import numpy as np\n\ntrain = np.loadtxt('..\/input\/digit-recognizer\/train.csv', delimiter=',', skiprows=1, dtype=np.uint8)\ntrain_X = train[:, 1:].reshape(-1, 28, 28, 1)\ntrain_y = train[:, 0].astype(np.int)\n\nis_dev = np.arange(train_X.shape[0]) % 10 == 0\ndev_X = train_X[is_dev]\ndev_y = train_y[is_dev]\ntrain_X = train_X[~is_dev]\ntrain_y = train_y[~is_dev]\n\nX_mean = train_X.astype(np.float32).mean() \/ 255\nX_std = train_X.astype(np.float32).std() \/ 255\n\ntest_X = np.loadtxt('..\/input\/digit-recognizer\/test.csv', delimiter=',', skiprows=1, dtype=np.uint8)\ntest_X = test_X.reshape(-1, 28, 28, 1)\n\nprint(X_mean, X_std)","23aeb943":"import torch\nfrom torch.utils.data import TensorDataset, Dataset, DataLoader\nfrom torchvision.transforms import Compose, ToPILImage, Pad, RandomAffine, RandomErasing, ToTensor, Normalize\n\nclass TransformDataset(Dataset):\n    def __init__(self, transform, X, y=None):\n        self.transform = transform\n        self.X = X\n        self.y = y\n    \n    def __len__(self):\n        return self.X.shape[0]\n    \n    def __getitem__(self, index):\n        X_item = self.transform(self.X[index])\n        if self.y is None:\n            return X_item,\n        else:\n            return X_item, self.y[index]\n\ntrain_transform = Compose([\n    ToPILImage(),\n    Pad(2),\n    RandomAffine(degrees=30, translate=(0.2, 0.2), shear=0.2),\n    ToTensor(),\n    Normalize((X_mean,), (X_std,)),\n    RandomErasing()\n])\n\ntest_transform = Compose([\n    ToPILImage(),\n    Pad(2),\n    ToTensor(),\n    Normalize((X_mean,), (X_std,))\n])\n\ntrain_loader = DataLoader(TransformDataset(train_transform, train_X, train_y), batch_size=100, shuffle=True)\ndev_loader = DataLoader(TransformDataset(test_transform, dev_X, dev_y), batch_size=400, shuffle=False)\ntest_loader = DataLoader(TransformDataset(test_transform, test_X), batch_size=400, shuffle=False)","97f94baa":"import torch.nn as nn\nfrom torchvision.models.resnet import resnet18\n        \nmodel = resnet18(num_classes=10)\nmodel.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2, bias=False)\nnn.init.kaiming_normal_(model.conv1.weight, mode='fan_out', nonlinearity='relu')\nmodel.maxpool = nn.Identity()\n\ncriterion = nn.CrossEntropyLoss()","38432af6":"from tqdm.autonotebook import tqdm\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\ndef train_epoch(model, criterion, optimizer, loader):\n    count = 0\n    total_loss = 0\n    model.to(device)\n    model.train()\n    pbar = tqdm(loader, desc='Training', leave=False)\n    for X, y in pbar:\n        batch_size = X.shape[0]\n        y_pred = model(X.to(device))\n        loss = criterion(y_pred, y.to(device))\n        pbar.set_postfix_str('Loss=%.4f' % loss.item())\n        count += batch_size\n        total_loss += loss.item() * batch_size\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    return total_loss \/ count\n\ndef classification(model, loader):\n    y_pred = []\n    y_true = []\n    evaluate = False\n    model.to(device)\n    model.eval()\n    with torch.no_grad():\n        for tensors in tqdm(loader, desc='Classification', leave=False):\n            X = tensors[0]\n            y_max = model(X.to(device)).argmax(dim=1).cpu()\n            y_pred.append(y_max)\n            if len(tensors) > 1:\n                evaluate = True\n                y_true.append(tensors[1])\n    y_pred = torch.cat(y_pred)\n    if evaluate:\n        y_true = torch.cat(y_true)\n        return (y_pred == y_true).type(torch.float32).mean()\n    else:\n        return y_pred.numpy()\n","af5f59bf":"max_dev_acc = 0\noptimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', verbose=True, patience=1, factor=0.1**0.5)\n\nfor epoch in tqdm(range(20), desc='Epochs'):\n    train_loss = train_epoch(model, criterion, optimizer, train_loader)\n    acc = classification(model, dev_loader)\n    scheduler.step(acc)\n    print('trainLoss=%.4f' % train_loss, 'devAcc=%.4f' % acc)\n    if acc > max_dev_acc:\n        max_dev_acc = acc\n        torch.save(model.state_dict(), 'model.pt')","e8f4ab78":"model.load_state_dict(torch.load('model.pt'))\ny_pred = classification(model, test_loader)\nwith open('submission.csv', 'w') as f:\n    print('ImageId,Label', file=f)\n    for i, y in enumerate(y_pred):\n        print(i + 1, y, sep=',', file=f)","67e309df":"## Read data","48359b31":"## Create DataLoader\n\nAnd a lot of data augmentation. Images are padded to 32x32 for bettern downscaling in CNN.","8e89c117":"## Define training and testing functions","d621adab":"## Define network\nResNet18 (with the first few layer changed to reduce downscaling)","585b9451":"## Train classifier","bbbab2f6":"## Generate classification test output"}}