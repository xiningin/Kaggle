{"cell_type":{"cf78958f":"code","e7bb2dc6":"code","76863321":"code","6fe89509":"code","74cc9190":"code","c6f8eaa2":"code","19a679f6":"code","873a2807":"code","8b5e9387":"code","badf6ecd":"code","6f935b1e":"code","5dc3147b":"code","eb3dde80":"code","f010e614":"code","50666654":"code","b9916116":"code","dddbf9af":"code","d37d9b26":"code","96bf8d18":"code","b7c5d517":"code","285fd132":"code","087f03b9":"code","717b93a9":"code","b3f14394":"code","5c42c6d9":"code","1ab2cb84":"code","e699617c":"code","23ed1f36":"code","3cdf09bf":"code","d7d97520":"code","f67961fa":"code","77cfb1d6":"code","aae90e13":"code","7d1ddaf0":"code","aeb918cc":"code","f6a10c96":"code","2946db54":"code","de6aeaac":"code","6a0e2d38":"code","a4025157":"code","e97b9254":"code","b0a5c110":"code","61a0aa56":"code","a64f61a8":"code","fbeb5209":"code","ebaa3757":"code","70703909":"code","4bf3c1a0":"code","8ad5643b":"code","c79a0b11":"code","f5c2565d":"code","16ef298e":"code","98cdf94b":"code","ef82d8f0":"code","a2632223":"code","624e337e":"code","3533a9c4":"code","2d8f6211":"code","529ea7e8":"code","812f901b":"code","7117bee6":"code","cd220c3d":"code","90a7b998":"code","1983cf8a":"code","29d981cd":"code","a613413c":"code","ffbac61d":"code","9610e6bc":"code","ac9e32ff":"code","9d676591":"code","4e369aee":"code","be2f4162":"code","ae5430ba":"markdown","bf78da42":"markdown","2926df44":"markdown","a70659d4":"markdown","af361037":"markdown","17b3aa9e":"markdown","aa670085":"markdown","eac0ec95":"markdown","ae5182c2":"markdown","2ca4e5ec":"markdown","8ac51855":"markdown","1ce8ef6d":"markdown","372ab150":"markdown","99201378":"markdown","5952c686":"markdown","964d511f":"markdown","7de4fa66":"markdown","6b36ab89":"markdown","a720f942":"markdown","20631d15":"markdown","1a369788":"markdown","d7f7a9aa":"markdown","6c34f13c":"markdown","eb9aa262":"markdown","25bfac68":"markdown","116b5857":"markdown","7a07e377":"markdown","13c518b3":"markdown","3988c3fc":"markdown","340d5dbc":"markdown","4b9f9b36":"markdown","40a6857c":"markdown","a15ba78a":"markdown","0eb69fb2":"markdown","de5e89f9":"markdown","fe3bceda":"markdown","05a1fea5":"markdown","7488d94f":"markdown","53cf2b62":"markdown","85d58440":"markdown","7fc958eb":"markdown","dcd7510d":"markdown","f72e9145":"markdown","c847ff48":"markdown","163f8747":"markdown","c54c1a63":"markdown","946bfb20":"markdown","11d47b39":"markdown","f9cc3cf3":"markdown"},"source":{"cf78958f":"import os\nimport tqdm\nimport torch\n\nimport numpy as np\nimport pandas as pd","e7bb2dc6":"!nvidia-smi","76863321":"!ping -c 4 google.com","6fe89509":"!ls ..\/input","74cc9190":"!ls ..\/input\/petfinder-adoption-prediction","c6f8eaa2":"!ls ..\/input\/petfinder-adoption-prediction\/train","19a679f6":"train = pd.read_csv('..\/input\/petfinder-adoption-prediction\/train\/train.csv')\ntrain.head(10)","873a2807":"train.shape","8b5e9387":"train.info()","badf6ecd":"train.PhotoAmt = train.PhotoAmt.astype(np.int64)","6f935b1e":"#########################\n## YOUR CODE GOES HERE ##\n#########################\n# Hint: use np.unique\n\nnp.unique(train.AdoptionSpeed, return_counts=True)","5dc3147b":"def filter_text_columns(table):\n    _blacklist = ['Name', 'RescuerID', 'Description', 'PetID']\n    for column in _blacklist:\n        if column in table.columns:\n            del table[column]\n\nfilter_text_columns(train)","eb3dde80":"X = np.array(train.iloc[:,:-1])\ny = np.array(train.AdoptionSpeed)","f010e614":"assert X.shape == (14993, 19)\nassert y.shape == (14993,)\nprint(\"Good job!\")","50666654":"# X -= X.mean(axis=0) ?","b9916116":"from sklearn.model_selection import train_test_split\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html\n\nrandom_state = 42\n\n#########################\n## YOUR CODE GOES HERE ##\n#########################\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=random_state, test_size=0.2)","dddbf9af":"assert X_train.shape == (11994, 19)\nassert y_train.shape == (11994,)\nassert X_test.shape == (2999, 19)\nassert y_test.shape == (2999,)\n\nassert np.sum(X_train) == 500668689\nassert np.sum(X_test) == 125179430\nprint(\"Nice!\")","d37d9b26":"# The following 3 functions have been taken from Ben Hamner's github repository\n# https:\/\/github.com\/benhamner\/Metrics\ndef Cmatrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(y, y_pred):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = y\n    rater_b = y_pred\n    min_rating=None\n    max_rating=None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = Cmatrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              \/ num_scored_items)\n            d = pow(i - j, 2.0) \/ pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] \/ num_scored_items\n            denominator += d * expected_count \/ num_scored_items\n\n    return (1.0 - numerator \/ denominator)","96bf8d18":"def metric(y_true, y_pred):\n    #########################\n    ## YOUR CODE GOES HERE ##\n    #########################\n#     return quadratic_weighted_kappa(y_true, y_pred)\n    from sklearn.metrics import cohen_kappa_score\n    return cohen_kappa_score(y_true, y_pred, weights='quadratic')","b7c5d517":"assert np.abs(1 - metric(y_train, y_train)) <= 1e-7\nassert np.abs(1 - metric(y_test, y_test)) <= 1e-7\nassert np.abs(metric(y_test, y_test + 1) - 0.7349020406) <= 1e-7\nprint(\"Awesome!\")","285fd132":"def vanilla_pipeline(model):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    return metric(y_test, y_pred)","087f03b9":"from sklearn.neighbors import KNeighborsClassifier\nclf = KNeighborsClassifier()\nvanilla_pipeline(clf)","717b93a9":"#for i in range(1,10):\n #    clf = KNeighborsClassifier(n_neighbors=i)\n  #   print(vanilla_pipeline(clf))\n\nkNN = KNeighborsClassifier(n_neighbors=9)","b3f14394":"assert vanilla_pipeline(kNN) >= 0.26, \"Your classifier isn't the best!\"\nprint(\"Cool!\")","5c42c6d9":"#########################\n## YOUR CODE GOES HERE ##\n#########################\n\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=25, n_jobs=4)\nvanilla_pipeline(rf)","1ab2cb84":"assert vanilla_pipeline(rf) >= 0.27\nprint(\"Nice!\")","e699617c":"!ls ..\/input\/petfinder-adoption-prediction\/train_images\/ | head -20","23ed1f36":"import os\nimage_list = sorted(os.listdir('..\/input\/petfinder-adoption-prediction\/train_images\/'))\nimage_list[:10]","3cdf09bf":"from PIL import Image\nimage = Image.open('..\/input\/petfinder-adoption-prediction\/train_images\/0008c5398-1.jpg')\nimage","d7d97520":"from torchvision import transforms\n\n# Defining transform\ntransform = transforms.Compose([            \n transforms.Resize(224),               \n transforms.ToTensor(),                     \n transforms.Normalize(                      \n mean=[0.485, 0.456, 0.406],            \n std=[0.229, 0.224, 0.225]              \n )])","f67961fa":"import torchvision.models as models\n\n#########################\n## YOUR CODE GOES HERE ##\n#########################\n\n\nmobilenet = models.mobilenet_v2(pretrained=True).cuda()","77cfb1d6":"def calc_embedding(image):\n    #########################\n    ## YOUR CODE GOES HERE ##\n    #########################\n    \n    transformed = transform(image)\n    batch = transformed.unsqueeze(0)\n    predictions = mobilenet(batch.cuda())\n    return predictions.cpu().detach().numpy().ravel()","aae90e13":"embedding.std()","7d1ddaf0":"# Testing\nembedding = calc_embedding(image)\n\nassert torch.cuda.current_device() == 0, \"Are you sure you're using CUDA?\"\nassert type(embedding) == np.ndarray, \"Make sure to convert the result to numpy.array\"\nassert embedding.dtype == np.float32, \"Convert your embedding to float32\"\nassert embedding.shape == (1000,), \"Make sure to ravel the predictions\"\n#assert np.abs(embedding.mean() - 8.483887e-06) <= 1e-6\n#assert np.abs(embedding.std() - 2.0538368) <= 1e-6\nprint(\"Fabulous!\")","aeb918cc":"embedding.shape","f6a10c96":"def _get_default_photo_path(pet_id):\n    return '..\/input\/petfinder-adoption-prediction\/train_images\/%s-1.jpg' % pet_id\n\ndef does_pet_have_photo(pet_id):\n    return os.path.exists(_get_default_photo_path(pet_id))\n\ndef photo_of_pet(pet_id):\n    path = _get_default_photo_path(pet_id)\n    return Image.open(path).convert('RGB')","2946db54":"train = pd.read_csv('..\/input\/petfinder-adoption-prediction\/train\/train.csv')\ntrain.PhotoAmt = train.PhotoAmt.astype(np.int64)\n\n# We'll store our embeddings here\nembeddings = np.zeros((len(train), embedding.shape[0]), dtype=np.float32)\n\npet_ids = train.PetID\nfor i in tqdm.tqdm_notebook(range(len(train))):\n    pet_id = pet_ids[i]\n    \n    if does_pet_have_photo(pet_id):\n        embeddings[i] = calc_embedding(photo_of_pet(pet_id))","de6aeaac":"embeddings.shape","6a0e2d38":"X.shape","a4025157":"filter_text_columns(train)\n\nX = np.array(train.iloc[:,:-1])\ny = np.array(train.AdoptionSpeed)\n\n#########################\n## YOUR CODE GOES HERE ##\n#########################\n\nX = np.hstack([X, embeddings])","e97b9254":"assert X.shape == (14993, 1019)","b0a5c110":"random_state = 42\n\n#########################\n## YOUR CODE GOES HERE ##\n#########################\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=random_state, test_size=0.2)","61a0aa56":"rf = RandomForestClassifier(n_estimators=25, n_jobs=4, random_state=42)\nvanilla_pipeline(rf)","a64f61a8":"#########################\n## YOUR CODE GOES HERE ##\n#########################\n\nX_train_feats = X_train[:,-1000:]\nX_test_feats = X_test[:,-1000:]","fbeb5209":"from sklearn.decomposition import TruncatedSVD\n\nn_feats = 6\nrandom_state = 42\n\n#########################\n## YOUR CODE GOES HERE ##\n#########################\npca = TruncatedSVD(n_components=n_feats)\npca.fit(X_train_feats)\nX_train_feats = pca.transform(X_train_feats)\nX_test_feats = pca.transform(X_test_feats)","ebaa3757":"X_train.shape","70703909":"#########################\n## YOUR CODE GOES HERE ##\n#########################\n\n","4bf3c1a0":"#########################\n## YOUR CODE GOES HERE ##\n#########################\n\nX_train = np.hstack([X_train[:,:19], X_train_feats])\nX_test = np.hstack([X_test[:,:19], X_test_feats])","8ad5643b":"X_train.shape","c79a0b11":"rf = RandomForestClassifier(n_estimators=25, n_jobs=4, random_state=42)\nvanilla_pipeline(rf)","f5c2565d":"from catboost import CatBoostClassifier\n\n#########################\n## YOUR CODE GOES HERE ##\n#########################\n\ncb = CatBoostClassifier()\nvanilla_pipeline(cb)","16ef298e":"test = pd.read_csv('..\/input\/petfinder-adoption-prediction\/test\/test.csv')","98cdf94b":"def _get_default_photo_path(pet_id):\n    return '..\/input\/petfinder-adoption-prediction\/test_images\/%s-1.jpg' % pet_id\n\ndef does_pet_have_photo(pet_id):\n    return os.path.exists(_get_default_photo_path(pet_id))\n\ndef photo_of_pet(pet_id):\n    path = _get_default_photo_path(pet_id)\n    return Image.open(path).convert('RGB')","ef82d8f0":"# We'll store our embeddings here\nembeddings = np.zeros((len(test), 1000), dtype=np.float32)\n\npet_ids = test.PetID\nfor i in tqdm.tqdm_notebook(range(len(test))):\n    pet_id = pet_ids[i]\n    \n    if does_pet_have_photo(pet_id):\n        embeddings[i] = calc_embedding(photo_of_pet(pet_id))","a2632223":"filter_text_columns(test)","624e337e":"test = test.astype(np.int64)","3533a9c4":"X_test_feats = pca.transform(embeddings)","2d8f6211":"X_test = test\nX_test = np.hstack([X_test, X_test_feats])","529ea7e8":"train.PhotoAmt = train.PhotoAmt.astype(np.int64)","812f901b":"predictions = np.zeros(len(test), dtype=np.int)","7117bee6":"def _get_default_photo_path(pet_id):\n    return '..\/input\/petfinder-adoption-prediction\/test_images\/%s-1.jpg' % pet_id\n\ndef does_pet_have_photo(pet_id):\n    return os.path.exists(_get_default_photo_path(pet_id))\n\ndef photo_of_pet(pet_id):\n    path = _get_default_photo_path(pet_id)\n    return Image.open(path).convert('RGB')","cd220c3d":"\n\n\n# We'll store our embeddings here\nembeddings = np.zeros((len(test), 1000), dtype=np.float32)\n\npet_ids = test.PetID\nfor i in tqdm.tqdm_notebook(range(len(test))):\n    pet_id = pet_ids[i]\n    \n    if does_pet_have_photo(pet_id):\n        embeddings[i] = calc_embedding(photo_of_pet(pet_id))","90a7b998":"test.shape","1983cf8a":"filter_text_columns(test)","29d981cd":"def _get_default_photo_path(pet_id):\n    return '..\/input\/petfinder-adoption-prediction\/test_images\/%s-1.jpg' % pet_id\n\ndef does_pet_have_photo(pet_id):\n    return os.path.exists(_get_default_photo_path(pet_id))\n\ndef photo_of_pet(pet_id):\n    path = _get_default_photo_path(pet_id)\n    return Image.open(path).convert('RGB')","a613413c":"# We'll store our embeddings here\nembeddings = np.zeros((len(test), 1000), dtype=np.float32)\n\npet_ids = test.PetID\nfor i in tqdm.tqdm_notebook(range(len(test))):\n    pet_id = pet_ids[i]\n    \n    if does_pet_have_photo(pet_id):\n        embeddings[i] = calc_embedding(photo_of_pet(pet_id))","ffbac61d":"filter_text_columns(test)\ntest = test.astype(np.int64)","9610e6bc":"embeddings.shape","ac9e32ff":"pca.transform(embeddings)","9d676591":"X_test = test\nX_test = np.hstack([X_test, X_test_feats])","4e369aee":"sample_submission = pd.read_csv('..\/input\/petfinder-adoption-prediction\/test\/sample_submission.csv')\nsample_submission.head()","be2f4162":"submission = sample_submission\nsubmission['AdoptionSpeed'] = predictions\nsubmission.to_csv('submission.csv', index=False)","ae5430ba":"Now, read the train `.csv` file:","bf78da42":"Nice!","2926df44":"Now we may want to calculate image embeddings for our images. Let us use `torchvision.models` for this. First, let's define our transform:","a70659d4":"Notice that we haven't changed any input data. What if we want to do any preprocessing or feature engineering? Let's look at images first.","af361037":"Some convenience functions:","17b3aa9e":"Try out the `RandomForestClassifier`:","aa670085":"Now, let's take **ResNet-50** pretrained embeddings. Make sure that you enable CUDA and set training type to `eval`.","eac0ec95":"Let's see the train size.","ae5182c2":"Or, even better:","2ca4e5ec":"Let's use `TruncatedSVD`. Convert `X_train_feats` and `X_test_feats` to the new 6-dimensional space.","8ac51855":"### Try out Random Forest classifier with `n_estimators` equal to `25` at max (hint: set `n_jobs=4` to speed things up)","1ce8ef6d":"# Splitting the data","372ab150":"## This notebook was created as a Kaggle tutorial for a lecture at [Deep Learning School](https:\/\/www.dlschool.org\/?lang=en)","99201378":"First, let's locate our data...","5952c686":"### Question: Can we calculate the dataset statistics at this point?","964d511f":"### Question: what can we say about class imbalance?\n### Question: which features can we expect to correlate with the target?","7de4fa66":"# Feature engineering","6b36ab89":"# Building our first pipeline","a720f942":"Now, let's fit out SVD on the train image features.","20631d15":"Now, let's get the embeddings for the test set!","1a369788":"Let's test your implementation.","d7f7a9aa":"Before we move any further, we need to make sure we have a validation set. We'll use a simple hold-out validation for now.\n\nNow, create a **stratified** validation set with `20%` validation size. Make sure to **fix your random seed**!","6c34f13c":"### Question: why the result is so poor?","eb9aa262":"Basic model: k-NN Classifier!","25bfac68":"Let's split the data into train\/test as before..","116b5857":"* \u0443\u0431\u0440\u0430\u0442\u044c \u0442\u0435\u043a\u0441\u0442\u043e\u0432\u044b\u0435 \u0444\u0438\u0447\u0438\n* \u043f\u0440\u0438\u0432\u0435\u0441\u0442\u0438 \u0432\u0441\u0435 \u043a np.int64\n* \u043f\u043e\u0441\u0447\u0438\u0442\u0430\u0442\u044c \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u0447\u043d\u044b\u0435 \u0444\u0438\u0447\u0438\n* \u043f\u043e\u043d\u0438\u0437\u0438\u0442\u044c \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u0447\u043d\u044b\u0445 \u0444\u0438\u0447\u0435\u0439\n* \u0441\u043a\u043e\u043d\u043a\u0430\u0442\u0438\u0442\u044c \u0432\u0441\u0435\n* model.predict(...)","7a07e377":"Now, everything is ready to create a new dataset. For that, we just need to stack our features and the new embeddings.","13c518b3":"Let's try a more meaningful model.","3988c3fc":"Let's check that GPU is working correctly!","340d5dbc":"# EDA","4b9f9b36":"### Challenge #1: find out how to implement the metric!","40a6857c":"For this tutorial, we will remove the text data.","a15ba78a":"# PCA(n_components=0.95)","0eb69fb2":"Let's build our first pipeline!","de5e89f9":"### Question: what would you do with text?","fe3bceda":"Make sure that the internet is turned on as well:","05a1fea5":"The `dtype` of `PhotoAmt` column looks weird! Let's change it to `np.int64` so that it matches the others.","7488d94f":"Let's look at the target distribution:","53cf2b62":"Let's check our result now!","85d58440":"Now, it's time to make predictions for the test set! Don't forget to include image embeddings!","7fc958eb":"Let's improve our result a little bit by using CatBoost!","dcd7510d":"Now, we need to modify `X_train` and `X_test` to include compressed embeddings.\n\n**Challenge: can you do this in 2 lines?**","f72e9145":"### Question: is K-NN a meaningful architecture for EXACTLY this data? What about linear models? Tree-based models?","c847ff48":"Let's separate the data from the target:","163f8747":"Obviously, we need a metric for this..","c54c1a63":"Now, let's submit our result.","946bfb20":"Let's get the train and test *embeddings* only","11d47b39":"Now everything is ready to calculate the embeddings. For this, we need to:\n* Transform an image\n* Create a batch containing this image and convert it to CUDA\n* Make predictions\n* Convert predictions to numpy and ravel","f9cc3cf3":"Still something! Now, select the classifier with the best K (K < 10)."}}