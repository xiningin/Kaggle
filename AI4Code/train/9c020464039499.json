{"cell_type":{"1dc06121":"code","d27159cd":"code","6781a59a":"code","a18a634c":"code","20a949df":"code","814533f8":"code","da5b19af":"code","3fbdaaaa":"code","7c63d384":"code","2d7cc53f":"code","83676964":"code","09b23657":"code","a76ee4fc":"code","63bd7b21":"code","1fbf4f78":"code","1515c089":"code","9128eb1d":"code","833fe241":"code","3b8c7433":"code","c3f44dbb":"code","73b7bf0f":"code","9e97aa76":"code","017c7807":"code","69197909":"code","c38db914":"code","d96dff97":"code","1e0ef300":"code","51a06741":"code","131ccd0d":"code","3373123f":"code","3e052782":"code","b4f31d19":"code","8ea548d6":"code","357b0c7e":"code","0ca384b5":"code","8b34490d":"code","c451251d":"markdown","fdf6421d":"markdown","2e6e8663":"markdown","14e02fcc":"markdown","b5b08ef0":"markdown","bd76d187":"markdown","2bc10ae1":"markdown","492307f8":"markdown","e94545b3":"markdown","c2b913a1":"markdown","a1746153":"markdown","7dec9aed":"markdown","2bf701e6":"markdown","038727ef":"markdown","e67c8c9a":"markdown","8ab958b9":"markdown","6c009fea":"markdown","a910466b":"markdown","2edb445d":"markdown","5ae1f98a":"markdown","756085e9":"markdown","45777c3b":"markdown","19fdfe95":"markdown","046d690b":"markdown","42db4f4a":"markdown","b2d4a410":"markdown","bc3cc96d":"markdown","6de3f96f":"markdown","c1535f27":"markdown","e91ee466":"markdown","563eda0b":"markdown"},"source":{"1dc06121":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\nimport warnings  \nwarnings.filterwarnings('ignore')\nimport re\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn import linear_model\nfrom sklearn.model_selection import GridSearchCV","d27159cd":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\n#Save the PassengerId for later construction of the submission file\nPassengerId = test['PassengerId']","6781a59a":"(train.shape[0], test.shape[0])","a18a634c":"train.head(3)","20a949df":"train.count() \/ len(train)","814533f8":"test.count() \/ len(test)","da5b19af":"def drop_incomplete_cols(df):\n    s = df.count() \/ len(df)\n    threshold = .4\n    for col_name in s.index:\n        if s[col_name] < threshold:\n            df.drop(col_name, axis=1, inplace=True)","3fbdaaaa":"all_data = [train, test]\n\nfor df in all_data:\n    df.drop(['PassengerId'], axis=1, inplace=True)\n    #impute missing Age with the mean across Sex\n    df['Age'].fillna(df.groupby(['Sex'])['Age'].transform(np.mean), inplace=True)\n    #impute missing Fare with the mean across Pclass and Embarked\n    df['Fare'].fillna(df.groupby(['Pclass', 'Embarked'])['Fare'].transform(np.mean), inplace=True)\n    #impute missing Embarked with mode of data set\n    df['Embarked'].fillna(df['Embarked'].mode().iloc[0], inplace=True)\n    drop_incomplete_cols(df)","7c63d384":"train.count()\/len(train)","2d7cc53f":"test.count()\/len(test)","83676964":"(train.shape[0], test.shape[0])","09b23657":"train.corr().abs().unstack().sort_values(ascending=False)[len(train.corr().columns):len(train.corr().columns) + 10]","a76ee4fc":"fig, axes = plt.subplots(1, 2, figsize=(30, 8))\nwomen = train[train['Sex'] == 'female']\nmen = train[train['Sex'] == 'male']\nax = sns.distplot(women[women['Survived']==1].Age, bins=65, label='survived', ax=axes[0], kde=False)\nax = sns.distplot(women[women['Survived']==0].Age, bins=65, label='not survived', ax=axes[0], kde=False)\nax.legend()\nax.set_title('Female')\nax = sns.distplot(men[men['Survived']==1].Age, bins=85, label= \\\n                  'survived', ax=axes[1], kde=False)\nax = sns.distplot(men[men['Survived']==0].Age, bins=85, label= \\\n                  'not survived', ax=axes[1], kde=False)\nax.legend()\nax.set_title('Male')\n","63bd7b21":"all_data = [train, test]\nfor df in all_data:\n    df['num_relatives'] = df['SibSp'] + df['Parch']\n    df.loc[df['num_relatives'] > 0, 'solo'] = 0\n    df.loc[df['num_relatives'] == 0, 'solo'] = 1\n    df['solo'] = df['solo'].astype(int)\n    #drop 'SibSp' and 'Parch' columns:\n    df.drop(['SibSp', 'Parch'], axis=1, inplace=True)","1fbf4f78":"axes = sns.catplot('num_relatives', 'Survived',\n                  data=train, kind='point', aspect=2)","1515c089":"fig, axes = plt.subplots(1, 2, figsize=(30, 8))\nwomen = train[train['Sex'] == 'female']\nmen = train[train['Sex'] == 'male']\nax = sns.distplot(women[women['Survived']==1].num_relatives, label='survived', ax=axes[0], kde=False)\nax = sns.distplot(women[women['Survived']==0].num_relatives, label='not survived', ax=axes[0], kde=False)\nax.legend()\nax.set_title('Female')\nax.set_xticks(range(0,10))\nax = sns.distplot(men[men['Survived']==1].num_relatives, label= \\\n                  'survived', ax=axes[1], kde=False)\nax = sns.distplot(men[men['Survived']==0].num_relatives, label= \\\n                  'not survived', ax=axes[1], kde=False)\nax.legend()\nax.set_xticks(range(0,10))\nax.set_title('Male')\n","9128eb1d":"def add_title_col(df):\n    pattern = r'(Mr\\.|Mrs|Ms|Miss|Master|Dr\\.|Don\\.|Dona\\.|Rev\\.|Sir\\.|Lady|Mme|Mlle|Major|Col\\.|Capt\\.|Countess|Jonkheer)'\n    title = df.Name.str.extract(pattern).fillna('NONE')\n    title.columns = ['title']\n    return pd.concat((df, title), axis=1)","833fe241":"def add_social_status_col(df):\n    classes = ['peerage', 'upper', 'officer', 'clergy', 'middle', 'lower']\n    peerage = ['Don.', 'Dona.', 'Sir.', 'Lady', 'Mme', 'Mlle', 'Countess', 'Jonkheer']\n    officer = ['Col.', 'Major', 'Capt.']\n    clergy = ['Rev.']\n    basic_honorific = ['Mr.', 'Mrs', 'Ms', 'Miss', 'Master', 'Dr.']\n    \n    df.loc[df['title'].isin(peerage), 'social_status'] = 'peerage'\n    df.loc[(df['title'].isin(basic_honorific) & (df['Pclass'] == 1)), 'social_status'] = 'upper'\n    df.loc[df['title'].isin(officer), 'social_status'] = 'officer'\n    df.loc[df['title'].isin(clergy), 'social_status'] = 'clergy'\n    df.loc[(df['title'].isin(basic_honorific) & (df['Pclass'] == 2)), 'social_status'] = 'middle'\n    df.loc[(df['title'].isin(basic_honorific) & (df['Pclass'] == 3)), 'social_status'] = 'lower'\n    \n    #test:\n    if len(df[~df['social_status'].isin(classes)]) == 0:\n        print('All passengers have been assigned a social status')\n    else:\n        print('social status assignment was NOT successful.')\n        \n    return df","3b8c7433":"train = add_title_col(train)\ntrain = add_social_status_col(train)\n\ntest = add_title_col(test)\ntest = add_social_status_col(test)","c3f44dbb":"train.head()","73b7bf0f":"def create_ticket_digit_col(df):\n    if 'first_digit' not in df.columns:\n        pattern = r'(\\d{1})\\d+$'\n        first_digit = df.Ticket.str.extract(pattern).fillna('0')\n        first_digit.columns = ['first_digit']\n        df = pd.concat([df, first_digit], axis=1)  \n        return df\n    else:\n        return df","9e97aa76":"train = create_ticket_digit_col(train)\ntest = create_ticket_digit_col(test)","017c7807":"train.head()","69197909":"def view_ticket_survival_stats(df):\n    pre = []\n    m = []\n    c = []\n    fd_list = df['first_digit'].value_counts().index.sort_values()\n    for i in fd_list:\n        pre.append(i)\n        m.append(df[df['first_digit'] == i].loc[:, 'Survived'].mean())\n        c.append(df[df['first_digit'] == i].loc[:, 'Survived'].count())\n\n    prefix_survival_pct = pd.DataFrame({'prefix': pre, 'count': c, 'survival_rate': m})\n    return prefix_survival_pct.sort_values(by='survival_rate', ascending=False)","c38db914":"view_ticket_survival_stats(train)","d96dff97":"train.head()","1e0ef300":"def safe_column_remove(df, columns):\n    for col in columns:\n        if col in df.columns:\n            df.drop(col, axis=1, inplace=True)\n    return df","51a06741":"#save the labels before removing the column:\ntrain_labels = train['Survived']\n\ncols_to_remove = ['Survived', 'Name', 'Ticket', 'title']\ntrain = safe_column_remove(train, cols_to_remove)\ntest = safe_column_remove(test, cols_to_remove)","131ccd0d":"def titanic_scaler_encoder(df, isTreeInput=True):\n    if isTreeInput==True:\n        ss_cols  = ['Age', 'Fare', 'num_relatives']\n        encoded_cols = ['Pclass', 'Sex', 'Embarked', 'social_status', 'first_digit']\n        unchd_cols = ['solo']\n        \n        scaler = StandardScaler()  \n        scaled_data  = scaler.fit_transform(df[ss_cols])  \n        label_encoded_data = df[encoded_cols].apply(LabelEncoder().fit_transform)\n        \n        return np.concatenate([scaled_data, label_encoded_data, df[unchd_cols]], axis=1)     \n    else:\n        ss_cols  = ['Age', 'Fare', 'num_relatives']\n        unchd_cols = ['solo', 'Pclass', 'Sex', 'Embarked', 'social_status', 'first_digit']\n    \n        scaler = StandardScaler()  \n        scaled_data  = scaler.fit_transform(df[ss_cols])\n        \n        return np.concatenate([scaled_data, df[unchd_cols]], axis=1)","3373123f":"train_prepared = titanic_scaler_encoder(train)\ntest_prepared = titanic_scaler_encoder(test)","3e052782":"train_prepared","b4f31d19":"test_prepared","8ea548d6":"param_grid = [{'penalty' : ['l1', 'l2'], 'C' : np.logspace(-4, 4, 20), 'solver' : ['liblinear']}]\nlg_clf = GridSearchCV(linear_model.LogisticRegression(), param_grid, cv=5, scoring='roc_auc')\nlg_clf.fit(train_prepared, train_labels)\nlg_predictions = lg_clf.best_estimator_.predict(test_prepared)","357b0c7e":"lg_clf.best_params_, lg_clf.best_score_","0ca384b5":"submission = pd.DataFrame({'PassengerId': PassengerId, 'Survived': lg_predictions})\nsubmission.Survived.astype(int)\nsubmission.head(20)","8b34490d":"submission.to_csv('titanic_submission_5_1.csv', float_format='%.f', index=False)","c451251d":"# <font color=blue>Create Submission File<\/blue>","fdf6421d":"#### The highest level of correlation is between <font color=red>Fare<\/font> and <font color=red>Pclass<\/font>, but not high enough to warrant removal of either at this point.","2e6e8663":"#### Above left, we see that the most common passenger age for women is about 28, and about 2\/3 of that group survived. Above right,the most common age range for men is about 31, and only about 1\/6 of that group survived. In fact, there is a low survival rate for males across the board. The opposite is true for females.","14e02fcc":"#### For example, The <font color=red>SibSp<\/font> and <font color=red>Parch<\/font> columns do not seem particularly helpful from an interpretation standpoint, since we cannot distinguish between siblings and spouses in the former case and parents and children in the latter (although this is debateable). We will combine these fields into a column called <font color=red>num_relatives<\/font>, and add a column, <font color=red>solo<\/font> which flags whether the passenger had relatives on board.","b5b08ef0":"#### First, define a method--'drop_incomplete_cols'--which removes a column if less than a certain percentage of the data is present:","bd76d187":"#### Next, use the above function in a loop that also drops any additional unneeded columns, and imputes missing <font color=red>Age<\/font>, <font color=red>Fare<\/font>, and <font color=red>Embarked data<\/font>:","2bc10ae1":"#### Look at the number of rows of data returned from each data set. Our goal is to clean and transform our data (where necessary) <br>while maintaining these same numbers of rows (i.e. we should not be deleting rows). ","492307f8":"##### Print out the survival rate for each ticket prefix.","e94545b3":"#### There seems to be a social class factor associated with survival rates, so we will use a regular expression to extract the honorifics from passenger's names into a <font color=red>title<\/font> column. We will then use <font color=red>title<\/font> with <font color=red>Pclass<\/font> to engineer a <font color=red>social_status<\/font> column:","c2b913a1":"# <font color=blue>Data Cleaning and Preparation for Machine Learning Algorithms<\/font>","a1746153":"# <font color=blue>Grid Search for Logistic Regression<\/font>","7dec9aed":"### Here, we will take a look at how survival rates were distributed across <font color=red>Age<\/font> and <font color=red>Sex<\/font>:","2bf701e6":"# <font color=blue>Feature Engineering<\/font>","038727ef":"#### All missing data has been handled without any loss of training or test instances:","e67c8c9a":"# <font color=blue>Data Visualization<\/font>","8ab958b9":"#### The graphs above show that while survival rates for both men and women were low for passengers with 4 relatives or more, the survival rate for women with 3 or fewer relatives dramatically increases while the survival rate for similar men remains low.","6c009fea":"#### Finally, check the completeness of the data in both sets:","a910466b":"## Check correlation of features","2edb445d":"#### Here, we will create a feature that is based on the first digit of the numerical portion of each ticket. In the interests of intellectual honesty, this bit of feature engineering is also known as <font color=red>\"taking a flyer\"<\/font>:","5ae1f98a":"##### The most common ticket prefixes  (1, 2, & 3) show significant drop-off in survival rates: 60%, 41%, and 26%, respectively. Other ticket prefixes match the survival rate of 3, or worse. The exception is prefix 9, which has a 100% survival rate. This is less significant however, since we only count 3 examples. We will keep the ticket prefix as a predictor.","756085e9":"### We will now analyze each data set and calculate the percentage of the data that is present for each column: ","45777c3b":"#### We can now graph the survival rate for passengers across various numbers of relatives:","19fdfe95":"#### The above graph shows that across males and females, the mean survival rate only breaks 50% when a passenger has 1-3 relatives. Next, we will split out these results by gender:","046d690b":"## Description of Data Columns:\n - <font color=red>Survived<\/font> - Survival (0 = No; 1 = Yes)\n - <font color=red>Pclass<\/font> - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n - <font color=red>Name<\/font>\n - <font color=red>Sex<\/font>\n - <font color=red>Age<\/font>\n - <font color=red>SibSp<\/font> - Number of Siblings\/Spouses Aboard\n - <font color=red>Parch<\/font> - Number of Parents\/Children Aboard\n - <font color=red>Ticket<\/font> - Ticket Number\n - <font color=red>Fare<\/font> - Passenger Fare\n - <font color=red>Cabin<\/font> - Cabin Number\n - <font color=red>Embarked<\/font> - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)","42db4f4a":"# <font color=blue>Exploratory Data Analysis<\/font>","b2d4a410":"#### It is helpful to look at a correlation matrix to see whether two features are highly correlated and thus redundant. Here, we are returning the top relevant rows of a sorted, unstacked correlation matrix of the train data:","bc3cc96d":"### Given that we have a description of the data columns and an understanding of the data quantity, we can make executive decisions about which columns to keep and about how to fill in gaps in the data:  \n-  The <font color=red>PassengerId<\/font> column can be removed from both train and test sets as it is not relevant to the analysis. \n-  In both sets, only about 22% of the data exists for the <font color=red>Cabin<\/font> column, so we will drop that column from both. \n-  ~80% of the <font color=red>Age<\/font> column exists for both sets, so we will impute the missing ages by replacing the NaN values with the gender mean. \n-  Values will be imputed for the missing <font color=red>Embarked<\/font> data in Train and <font color=red>Fare<\/font> data in test.","6de3f96f":"## Handle Missing Data:","c1535f27":"#### Now let's take a look at a sample of the data:","e91ee466":"### Here, we will seek to generate new features from existing features in order to create more meaningful and\/or compact representations of the data.","563eda0b":"##### We will now remove columns we don't need, and label encode categorical columns. We will also scale the remaining numerical columns."}}