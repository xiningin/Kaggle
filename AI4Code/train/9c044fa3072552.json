{"cell_type":{"ecf97262":"code","dc589258":"code","442efed8":"code","8047aad3":"code","4d6ebd00":"code","b05075d7":"code","7869d1c6":"code","858b4918":"code","c658092d":"code","cb13c69e":"code","03646599":"code","622700d1":"code","271d4a18":"code","34d6c215":"code","831f4ca2":"code","3f27e272":"code","54cc95ab":"code","9486fda2":"code","6cb023bc":"code","1eefe94f":"code","2086baea":"code","aa55619b":"code","7692f2a6":"code","730d1264":"code","3c4fffc6":"code","b1d92b80":"code","9aa2c753":"code","18db912a":"code","e7dfae51":"code","a80f5e9c":"code","db0b1762":"code","ddefc528":"code","ed332f97":"code","95879075":"code","c4a066c5":"code","7f97407f":"code","8a004cb4":"code","a69f8063":"markdown","85bfc360":"markdown","ee0581fb":"markdown","c8d8a525":"markdown","8aa97f7d":"markdown","d704fd9a":"markdown","a13f94b5":"markdown","aa768273":"markdown","43f3ee2d":"markdown","e4708964":"markdown","fb624b1c":"markdown","6ac9bd33":"markdown","f9e847ff":"markdown","f4b24ba8":"markdown","b352a8ef":"markdown","c9798977":"markdown","8cdf8638":"markdown","e66d8a74":"markdown","d9fea754":"markdown","181f77ff":"markdown","745af6c8":"markdown","4b58b043":"markdown","ef16c003":"markdown","e5483518":"markdown","7e39ca0d":"markdown","eaba07ef":"markdown","b69ed268":"markdown","064162d9":"markdown","43370aa3":"markdown","459021a2":"markdown","25451b44":"markdown","3be8aa66":"markdown","209ae481":"markdown"},"source":{"ecf97262":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dc589258":"df = pd.read_csv('..\/input\/us-accidents\/US_Accidents_Dec20_Updated.csv',index_col='ID')","442efed8":"df.head()","8047aad3":"df.info()","4d6ebd00":"df.describe()","b05075d7":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n\nnumeric_df = df.select_dtypes(include=numerics)\nlen(numeric_df)","7869d1c6":"df.isna().sum()","858b4918":"missing_percentage = df.isna().sum().sort_values(ascending=False) \/ len(df)\nmissing_percentage","c658092d":"#Filtering out columns without missing values\nY = missing_percentage[missing_percentage != 0]\nY","cb13c69e":"Y.plot(kind='barh')","03646599":"df.columns","622700d1":"cities = df.City.unique()\nlen(cities)","271d4a18":"cities_by_accident = df.City.value_counts()\ncities_by_accident[:5] #Top 5 cities by accident count","34d6c215":"cities_by_accident[:20].plot(kind='barh')","831f4ca2":"import seaborn as sns\nsns.set_style('darkgrid')\nsns.distplot(cities_by_accident)","3f27e272":"high_accident_cities = cities_by_accident[cities_by_accident>=1000]\nless_accident_cities = cities_by_accident[cities_by_accident<=1000]","54cc95ab":"len(high_accident_cities)\/len(cities)","9486fda2":"sns.distplot(high_accident_cities)","6cb023bc":"sns.histplot(cities_by_accident,log_scale=True)","1eefe94f":"state_by_accident = df['State'].value_counts()\nstate_by_accident.plot(kind='line')","2086baea":"df.Start_Time","aa55619b":"df.Start_Time = pd.to_datetime(df.Start_Time)","7692f2a6":"df.Start_Time[0]","730d1264":"import seaborn as sns","3c4fffc6":"sns.distplot(df.Start_Time.dt.hour, bins=24, kde=False, norm_hist=True)","b1d92b80":"sns.distplot(df.Start_Time.dt.dayofweek, bins=7, kde=False, norm_hist=True)","9aa2c753":"sunday_start_time = df.Start_Time[df.Start_Time.dt.dayofweek ==6]\nsns.distplot(sunday_start_time.dt.hour, bins=24, kde=False, norm_hist=True)","18db912a":"monday_start_time = df.Start_Time[df.Start_Time.dt.dayofweek ==0]\nsns.distplot(monday_start_time.dt.hour, bins=24, kde=False, norm_hist=True)","e7dfae51":"sns.distplot(sunday_start_time.dt.month, bins=12, kde=False, norm_hist=True)","a80f5e9c":"df_2019 = df[df.Start_Time.dt.year == 2019]\nsns.distplot(df_2019.Start_Time.dt.month, bins=12, kde=False, norm_hist=True)","db0b1762":"df.Start_Lat","ddefc528":"df.Start_Lng","ed332f97":"list(zip(list(df.Start_Lat), list(df.Start_Lng))) #Pair up the Latitiude and the Longitude","95879075":"sample_df = df.sample(int(0.1*len(df))) #Using 10% of our dataset\nsns.scatterplot(x=sample_df.Start_Lng, y=sample_df.Start_Lat, size=0.9)","c4a066c5":"import folium","7f97407f":"from folium.plugins import HeatMap","8a004cb4":"map = folium.Map()\nHeatMap(list(zip(list(df.Start_Lat), list(df.Start_Lng)))).add_to(map)\nmap","a69f8063":"### On Mondays","85bfc360":"### By Month","ee0581fb":"Next, let's use the library folium to create interactive maps with the latitudes and longitudes.","c8d8a525":"The Dataset consists registered accidents from over 11790 cities in the US","8aa97f7d":"This shows that less than 5% cities have more than 1000 yearly accidents.","d704fd9a":"### Hour Start Time","a13f94b5":"#### Missing Column Values Percentage","aa768273":"There's a slight peek at 7am. But the number of accidents is largest during the afternoon, i.e., 1pm to 6pm.","43f3ee2d":"Now, let's look at a distribution based on the location of accidents (latitude and longitude).","e4708964":"There are a lot of columns that have missing values!","fb624b1c":"Have fun interracting with the heatmap!","6ac9bd33":"### For the year 2019","f9e847ff":"Since the time here is of `dtype: object`, we need to convert it to Timestamp","f4b24ba8":"# Exploratory Analysis and Visualization\nColumns we'll analyze \n- City\n- Start Time\n- Weather Condition [TODO]\n- Temperature [TODO]\n- Start Lang, Start Lat","b352a8ef":"### Cities","c9798977":"## Start Latitude & Longitude","8cdf8638":"Looks like the [map](https:\/\/www.mappr.co\/wp-content\/uploads\/2018\/11\/USA-States-Color-Map.jpg) of USA right?","e66d8a74":"`Start_Time` is the time at which the accident occured. Let's dive into it!","d9fea754":"# Ask & Answer Questions\n- Are there more accidents in warmer or colder areas?\n- When (as in the time of accident) are the accidents more frequent?\n- Which days of the week (or even month) have the most accident?\n- What is the trend of these accidents over the year? (decreasing\/increasing)","181f77ff":"We can also see which states have the most accidents by using the `State` column from our dataframe","745af6c8":"### On Sundays","4b58b043":"X-axis represents days of the week. It is evident that weekdays have more number of accidents than weekends. Let's take a closer look at how different these 2 distributions are.","ef16c003":"### Missing Values","e5483518":"### Start Time","7e39ca0d":"# Data Preparation and Cleaning\n\n- Load the file using Pandas\n- Look at some information about the data and the columns\n- Fix any missing or incorrect values","eaba07ef":"> The Distribution on Mondays is very different from that on Sundays","b69ed268":"Let's look at the monthly distribution\n\n","064162d9":"Aha! This distribution seems good. Accidents seem to be more frequent during the winters.","43370aa3":"Interesting to note that these cities are also one of the most populated cities in the US. Although, it doesn't include the most populated city of all, New York.","459021a2":"## Summary and Insights\n- No data from New York(which is the most poppulated city in the US)\n- Less the 5% of cities have more than 1000 yearly registered accidents.\n- Accidents are more frequent from 6am to 10am and 3pm to 6 pm during the weekdays.","25451b44":"There seems to be some error in the dataset because there's a huge difference between the accidents during the summers and winters. Our dataset consists data from February 2016 to 2020. This could be one of the reasons. Let's how this distribution looks for the year 2019.","3be8aa66":"The 2 Gaussian curves in the above graph could represent \n1. People going to work\n2. People returning home.\n\nAmazing how the human systems that we've built mess with the general statistics ;)","209ae481":"### Days of the week Start Time"}}