{"cell_type":{"d1df36c4":"code","0e349e3c":"code","c6a94d04":"code","efa06077":"code","ca879ec1":"code","9466888b":"code","7a0cbed3":"code","cf814657":"code","a9e6bf10":"code","5fac4647":"code","41655387":"code","997705c0":"code","5d0bb6e7":"code","7aad9202":"code","0a7234cd":"code","dbe6ae0f":"code","2ae04e16":"code","cbc5e1f5":"code","d443f41b":"code","277aee94":"code","47fc403e":"code","b4dacfb3":"code","e7d0eb0a":"code","fe9631ab":"code","2097d73e":"code","008d3de3":"code","7cf3f9b2":"code","f2e74ad8":"code","bcaaa7c0":"code","0545626a":"code","24c8cf6e":"code","575a7b86":"code","caa5e141":"code","d177b3ff":"markdown","d521c427":"markdown","93f58973":"markdown","d75d57b4":"markdown","ab06e8d1":"markdown","f3412743":"markdown","c1d3d5a6":"markdown","ea5ab112":"markdown","6397a2f7":"markdown","b2b52401":"markdown","eeeb2295":"markdown","b50c1b59":"markdown"},"source":{"d1df36c4":"!pip install Ninja","0e349e3c":"!git clone https:\/\/github.com\/eladrich\/pixel2style2pixel\n%cd pixel2style2pixel","c6a94d04":"from argparse import Namespace\nimport time\nimport sys\nimport os\nimport pprint\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torch\nimport torchvision.transforms as transforms\n\nsys.path.append(\".\")\nsys.path.append(\"..\")\n\nfrom datasets import augmentations\nfrom utils.common import tensor2im, log_input_image\nfrom models.psp import pSp","efa06077":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(device)","ca879ec1":"experiment_type = 'celebs_sketch_to_face' #@param ['ffhq_encode', 'ffhq_frontalize', 'celebs_sketch_to_face', 'celebs_seg_to_face', 'celebs_super_resolution', 'toonify']","9466888b":"MODEL_PATHS = {\n    \"ffhq_encode\": {\"id\": \"1bMTNWkh5LArlaWSc_wa8VKyq2V42T2z0\", \"name\": \"psp_ffhq_encode.pt\"},\n    \"ffhq_frontalize\": {\"id\": \"1_S4THAzXb-97DbpXmanjHtXRyKxqjARv\", \"name\": \"psp_ffhq_frontalization.pt\"},\n    \"celebs_sketch_to_face\": {\"id\": \"1lB7wk7MwtdxL-LL4Z_T76DuCfk00aSXA\", \"name\": \"psp_celebs_sketch_to_face.pt\"},\n    \"celebs_seg_to_face\": {\"id\": \"1VpEKc6E6yG3xhYuZ0cq8D2_1CbT0Dstz\", \"name\": \"psp_celebs_seg_to_face.pt\"},\n    \"celebs_super_resolution\": {\"id\": \"1ZpmSXBpJ9pFEov6-jjQstAlfYbkebECu\", \"name\": \"psp_celebs_super_resolution.pt\"},\n    \"toonify\": {\"id\": \"1YKoiVuFaqdvzDP5CZaqa3k5phL-VDmyz\", \"name\": \"psp_ffhq_toonify.pt\"}\n}\n\npath = MODEL_PATHS[experiment_type]","7a0cbed3":"CODE_DIR = 'pixel2style2pixel'\ndef get_download_model_command(file_id, file_name):\n    \"\"\" Get wget download command for downloading the desired model and save to directory ..\/pretrained_models. \"\"\"\n    current_directory = os.getcwd()\n    save_path = os.path.join(os.path.dirname(current_directory), CODE_DIR, \"pretrained_models\")\n    if not os.path.exists(save_path):\n        os.makedirs(save_path)\n    url = r\"\"\"wget --load-cookies \/tmp\/cookies.txt \"https:\/\/docs.google.com\/uc?export=download&confirm=$(wget --quiet --save-cookies \/tmp\/cookies.txt --keep-session-cookies --no-check-certificate 'https:\/\/docs.google.com\/uc?export=download&id={FILE_ID}' -O- | sed -rn 's\/.*confirm=([0-9A-Za-z_]+).*\/\\1\\n\/p')&id={FILE_ID}\" -O {SAVE_PATH}\/{FILE_NAME} && rm -rf \/tmp\/cookies.txt\"\"\".format(FILE_ID=file_id, FILE_NAME=file_name, SAVE_PATH=save_path)\n    return url\n\ndownload_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"])","cf814657":"!wget {download_command}","a9e6bf10":"EXPERIMENT_DATA_ARGS = {\n    \"ffhq_encode\": {\n        \"model_path\": \"pretrained_models\/psp_ffhq_encode.pt\",\n        \"image_path\": \"notebooks\/images\/input_img.jpg\",\n        \"transform\": transforms.Compose([\n            transforms.Resize((256, 256)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n    },\n    \"ffhq_frontalize\": {\n        \"model_path\": \"pretrained_models\/psp_ffhq_frontalization.pt\",\n        \"image_path\": \"notebooks\/images\/input_img.jpg\",\n        \"transform\": transforms.Compose([\n            transforms.Resize((256, 256)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n    },\n    \"celebs_sketch_to_face\": {\n        \"model_path\": \"pretrained_models\/psp_celebs_sketch_to_face.pt\",\n        \"image_path\": \"notebooks\/images\/input_sketch.jpg\",\n        \"transform\": transforms.Compose([\n            transforms.Resize((256, 256)),\n            transforms.ToTensor()])\n    },\n    \"celebs_seg_to_face\": {\n        \"model_path\": \"pretrained_models\/psp_celebs_seg_to_face.pt\",\n        \"image_path\": \"notebooks\/images\/input_mask.png\",\n        \"transform\": transforms.Compose([\n            transforms.Resize((256, 256)),\n            augmentations.ToOneHot(n_classes=19),\n            transforms.ToTensor()])\n    },\n    \"celebs_super_resolution\": {\n        \"model_path\": \"pretrained_models\/psp_celebs_super_resolution.pt\",\n        \"image_path\": \"notebooks\/images\/input_img.jpg\",\n        \"transform\": transforms.Compose([\n            transforms.Resize((256, 256)),\n            augmentations.BilinearResize(factors=[16]),\n            transforms.Resize((256, 256)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n    },\n    \"toonify\": {\n        \"model_path\": \"pretrained_models\/psp_ffhq_toonify.pt\",\n        \"image_path\": \"notebooks\/images\/input_img.jpg\",\n        \"transform\": transforms.Compose([\n            transforms.Resize((256, 256)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n    },\n}    ","5fac4647":"EXPERIMENT_ARGS = EXPERIMENT_DATA_ARGS[experiment_type]","41655387":"model_path = EXPERIMENT_ARGS['model_path']\nckpt = torch.load(model_path, map_location='cpu')","997705c0":"opts = ckpt['opts']\npprint.pprint(opts)","5d0bb6e7":"# update the training options\nopts['checkpoint_path'] = model_path\nif 'learn_in_w' not in opts:\n    opts['learn_in_w'] = False\nif 'output_size' not in opts:\n    opts['output_size'] = 1024","7aad9202":"opts = Namespace(**opts)\nnet = pSp(opts)\nnet.eval()\nnet.cuda()\nprint('Model successfully loaded!') ","0a7234cd":"image_path = EXPERIMENT_DATA_ARGS[experiment_type][\"image_path\"]\noriginal_image = Image.open(image_path)\nif opts.label_nc == 0:\n    original_image = original_image.convert(\"RGB\")\nelse:\n    original_image = original_image.convert(\"L\")","dbe6ae0f":"# download a picture \nimport urllib\nimg = Image.open(urllib.request.urlopen(\"https:\/\/cdn2.ettoday.net\/images\/2074\/2074111.jpg\")) # Conan\n\nplt.axis('off')\nplt.imshow(img)\nplt.show()","2ae04e16":"# use opencv to generate edge for sketch\nimport numpy as np\nimport cv2\nimg = np.array(img)\ngray  = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\nedges = cv2.Canny(gray,100,200)\ndilation = cv2.dilate(edges,np.ones((3,3),np.uint8),iterations = 1) # dilation\nsketch = cv2.bitwise_not(dilation)\nplt.axis('off')\nplt.imshow(sketch, cmap='gray')\nplt.show()","cbc5e1f5":"# convert opencv image to pillow image\noriginal_image= Image.fromarray(sketch)","d443f41b":"# resize to 256x256\noriginal_image.resize((256, 256))\noriginal_image","277aee94":"input_image = original_image","47fc403e":"img_transforms = EXPERIMENT_ARGS['transform']\ntransformed_image = img_transforms(input_image)","b4dacfb3":"def run_on_batch(inputs, net, latent_mask=None):\n    if latent_mask is None:\n        result_batch = net(inputs.to(\"cuda\").float(), randomize_noise=False)\n    else:\n        result_batch = []\n        for image_idx, input_image in enumerate(inputs):\n            # get latent vector to inject into our input image\n            vec_to_inject = np.random.randn(1, 512).astype('float32')\n            _, latent_to_inject = net(torch.from_numpy(vec_to_inject).to(\"cuda\"),\n                                      input_code=True,\n                                      return_latents=True)\n            # get output image with injected style vector\n            res = net(input_image.unsqueeze(0).to(\"cuda\").float(),\n                      latent_mask=latent_mask,\n                      inject_latent=latent_to_inject)\n            result_batch.append(res)\n        result_batch = torch.cat(result_batch, dim=0)\n    return result_batch","e7d0eb0a":"if experiment_type in [\"celebs_sketch_to_face\", \"celebs_seg_to_face\"]:\n    latent_mask = [8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\nelse:\n    latent_mask = None","fe9631ab":"with torch.no_grad():\n    tic = time.time()\n    result_image = run_on_batch(transformed_image.unsqueeze(0), net, latent_mask)[0]\n    toc = time.time()\n    print('Inference took {:.4f} seconds.'.format(toc - tic))","2097d73e":"input_vis_image = log_input_image(transformed_image, opts)\noutput_image = tensor2im(result_image)","008d3de3":"if experiment_type == \"celebs_super_resolution\":\n    res = np.concatenate([np.array(input_image.resize((256, 256))),\n                          np.array(input_vis_image.resize((256, 256))),\n                          np.array(output_image.resize((256, 256)))], axis=1)\nelse:\n    res = np.concatenate([np.array(input_vis_image.resize((256, 256))),\n                          np.array(output_image.resize((256, 256)))], axis=1)","7cf3f9b2":"res_image = Image.fromarray(res)\nres_image","f2e74ad8":"if experiment_type in [\"celebs_sketch_to_face\", \"celebs_seg_to_face\"]:\n    latent_mask = [8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n    mix_alpha = None\nelif experiment_type == \"celebs_super_resolution\":\n    latent_mask = [4, 5, 6, 7]\n    mix_alpha = 0.5\nelse:\n    raise ValueError(\"Multi-modal synthesis is performed only for seg-to-face, sketch-to-face, and super-resolution!\")\n\nn_outputs_to_generate = 5","bcaaa7c0":"def get_multi_modal_outputs(input_image, vectors_to_inject):\n    results = []\n    with torch.no_grad():\n        for vec_to_inject in vectors_to_inject:\n            cur_vec = torch.from_numpy(vec_to_inject).unsqueeze(0).to(\"cuda\")\n            # get latent vector to inject into our input image\n            _, latent_to_inject = net(cur_vec,\n                                      input_code=True,\n                                      return_latents=True)\n            # get output image with injected style vector\n            res = net(input_image.unsqueeze(0).to(\"cuda\").float(),\n                      latent_mask=latent_mask,\n                      inject_latent=latent_to_inject,\n                      alpha=mix_alpha)\n            results.append(res[0])\n    return results","0545626a":"# randomly draw the latents to use for style mixing\nvectors_to_inject = np.random.randn(n_outputs_to_generate, 512).astype('float32')","24c8cf6e":"multi_results = get_multi_modal_outputs(transformed_image, vectors_to_inject)","575a7b86":"input_vis_image = log_input_image(transformed_image, opts)\nres = np.array(input_vis_image.resize((256, 256)))\n\nfor output in multi_results:\n    output = tensor2im(output)\n    res = np.concatenate([res, np.array(output.resize((256, 256)))], axis=1)","caa5e141":"res_image = Image.fromarray(res)\nres_image","d177b3ff":"## Define Inference Parameters","d521c427":"## Multi-Modal Synthesis\n","93f58973":"## Download Pretrained Models","d75d57b4":"## Load Pretrained Model","ab06e8d1":"### Visualize Results","f3412743":"## Visualize Input","c1d3d5a6":"## Repro [Github](https:\/\/github.com\/eladrich\/pixel2style2pixel)","ea5ab112":"## Select Experiment Type","6397a2f7":"## Perform Inference","b2b52401":"## Convert picture to sketch","eeeb2295":"### Generate Outputs","b50c1b59":"# Pixel2Style2Pixel \n## **Sketch-to-Face**"}}