{"cell_type":{"191a29ae":"code","f368a1f2":"code","54e37b14":"code","098bb75b":"code","b766777e":"code","4b7f80bc":"code","775e6315":"code","2d8f0add":"code","7d845236":"code","cef3b292":"code","bf735552":"code","c07966f5":"code","2b6a6121":"code","89a9f793":"code","13f661c4":"code","03a842b8":"code","c1584278":"code","a49eaf28":"code","d8fea40f":"code","cf59563c":"code","a9b9d6dd":"code","304fecd7":"code","aeebecec":"code","97493658":"code","83f9d419":"code","3dbf19a7":"code","66f1b147":"code","9716e818":"code","a55548f7":"code","dea4a7c6":"code","59422dbf":"code","85554e50":"code","0f8633b1":"code","696383a2":"code","35503df6":"code","208b0782":"code","bf51d3b9":"code","a5c360e1":"code","cba265f7":"code","a43cd7f6":"code","9c868e5f":"code","5c78dd7b":"code","30ef077f":"code","84b2f710":"code","5d6acea2":"code","2322fa78":"code","7bc804e9":"code","96e6a202":"code","bb00c263":"code","69c618b5":"code","6ec6601e":"code","aff02f62":"code","7edad521":"code","bdeaa21b":"code","9d4b4ef7":"code","c6aebd11":"code","e5177beb":"code","ade89e45":"code","3cfea4c0":"code","13a5f8ad":"code","89f82afd":"code","0eb63855":"code","95e29d5c":"code","1c79a465":"code","10e6539c":"code","b0d7a9a7":"code","0966a387":"code","ed137eda":"code","6ccbe275":"code","af13a2df":"code","1df64818":"code","475ff097":"code","510b5dfa":"code","7b100d50":"code","06091bbc":"code","72fa125f":"code","f67cf22d":"code","0ba948cc":"code","5a56ef53":"code","4853a9ef":"code","e0383556":"code","416169f4":"code","378447d5":"code","06448ce2":"code","0e06465c":"code","fe9a711b":"code","d1f69b6d":"code","f78c11ef":"code","020a2451":"code","fab11bbf":"code","43736edf":"code","9b9d13bc":"code","c386f52a":"code","2846c62f":"code","7a05dcd0":"code","7439889c":"code","35a91d1f":"code","118237bb":"code","156a5571":"code","18c9818d":"code","e44e7406":"code","c7afc0d2":"code","eaa8564f":"code","727bb957":"code","8f1d6060":"code","dd37afd6":"code","f554f8d1":"code","677cf550":"code","e7abf355":"code","33c262f7":"code","e6a6f255":"code","0dae16eb":"code","57dc4d18":"code","9b9c71d3":"code","11e0b14c":"code","c595cd3e":"code","cf1f6f1d":"code","a95e4ea8":"code","a2992e32":"code","0a35f54c":"code","7ad024f6":"code","b9e8e840":"code","d6451b1b":"code","0fe54bd9":"code","ec92e7cb":"code","786ba690":"code","eff7b918":"code","b2f24d71":"code","e7fc2924":"code","c5654a9d":"code","09c74269":"code","10555aec":"code","b78aa902":"code","ea27dbdc":"markdown","d5111b04":"markdown","5cbc481f":"markdown","13ba720c":"markdown","af7a245a":"markdown","3a3c989b":"markdown","b82ee143":"markdown","9fe16e75":"markdown","61d8743b":"markdown","77cd5c93":"markdown","248f6761":"markdown","9a366c8b":"markdown","b7b55468":"markdown","2fd9c2ef":"markdown","a933429a":"markdown","af690825":"markdown"},"source":{"191a29ae":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","f368a1f2":"df=pd.read_excel(r'..\/input\/flight-fare-prediction-mh\/Data_Train.xlsx')","54e37b14":"df.keys()","098bb75b":"pd.set_option('display.max_columns',None)    #To Display All Columns in dataframe","b766777e":"df.head()","4b7f80bc":"df.tail()","775e6315":"df.info()","2d8f0add":"df.describe()","7d845236":"#To Check For Null Values :\ndf.isnull().sum()","cef3b292":"#Wow, we only have a few null values..so can be easily handled..so we can drop these values ..since it wont affect our dataset\n#upto large extent","bf735552":"df.dropna(inplace=True)","c07966f5":"df.isnull().sum()","2b6a6121":"df['Airline'].value_counts()","89a9f793":"df['Source'].value_counts()","13f661c4":"df['Destination'].value_counts()","03a842b8":"df['Total_Stops'].value_counts()","c1584278":"df['Duration'].value_counts()","a49eaf28":"#Since Duration column is in string format , we need to preprocess it for our machine learning model to understand","d8fea40f":"df['Date_of_Journey'].value_counts()","cf59563c":"#These values are basically string type , so we need to convert them into datetime -> timestamp format\n#i am gonna use pandas to_datetime function for this ","a9b9d6dd":"df['Journey_Of_Day']=pd.to_datetime(df['Date_of_Journey'],format=\"%d\/%m\/%Y\").dt.day","304fecd7":"df['Journey_Of_Month']=pd.to_datetime(df['Date_of_Journey'],format=\"%d\/%m\/%Y\").dt.month","aeebecec":"#since the dates here are of same year ..i.e.,2019 , ..there is no need to specifiy a seprate column feature for the same ","97493658":"df.head()","83f9d419":"#Since we have timestamp format now , we dont need date of journey column..so we can drop it now \ndf.drop(['Date_of_Journey'],inplace=True,axis=1)","3dbf19a7":"df","66f1b147":"#Similarly , we need to preprocess Departure Time since it is in string format..we need to get hours and minutes separately ..\n\ndf['Dep_Hour']=pd.to_datetime(df['Dep_Time']).dt.hour\ndf['Dep_Min']=pd.to_datetime(df['Dep_Time']).dt.minute","9716e818":"df","a55548f7":"#Let us drop the Dep_time now , since we have already preprocessed it :\n\ndf.drop('Dep_Time',axis=1,inplace=True)","dea4a7c6":"df","59422dbf":"#Similarly , we have to preprocess Arrival Time Data , being text  , to convert into datetime->timestamp format\n\ndf['Arrival_Hour']=pd.to_datetime(df['Arrival_Time']).dt.hour\ndf['Arrival_Min']=pd.to_datetime(df['Arrival_Time']).dt.minute","85554e50":"df","0f8633b1":"#Now , drop Arrival_time :\n\ndf.drop('Arrival_Time',axis=1,inplace=True)","696383a2":"df","35503df6":"#Now we Have Duration , which is differece between arrival and departure time \n#This is a bit tricky pre-processing Technique.\n#Since if you take a look at duration column , we have something like '2h 50m' this is a string which consists of 'h' and 'm' as well\n#for our model to understand 'h' and 'm' as 'hours' and 'minutes' , we need to apply some iterative logic :\n\n\n\n\nduration=list(df['Duration'])\n\nfor i in range(len(duration)):\n  if(len(duration[i].split()))!=2:                             #To check if duration has both hours and minutes , if yes , implement the below logic\n    if \"h\" in duration[i]:\n      duration[i]=duration[i].strip()+\" 0m\"\n    else:\n      duration[i]=\"0h \"+duration[i]             \n\n\nduration_hours=[]\nduration_min=[]\n\nfor i in range(len(duration)):\n  duration_hours.append(int(duration[i].split(sep='h')[0]))                                #To Get Hours in Duration\n  duration_min.append(int(duration[i].split(sep='m')[0].split()[-1]))                      #To Get Minutes in Duration\n","208b0782":"#For testing only , not involved in actual code\n\nsamp=\"30h\"\nl1=list(samp)\ntemp=[]\nfor i in range(len(list(samp))):\n  if (len(list(samp)[i].split()))!=2:\n    if \"h\" in list(samp)[i]:\n      list(samp)[i]=list(samp)[i].strip()+\" 0m\"\n      temp.append(list(samp))\n    else:\n      list(samp)[i]=\"0h \"+list(samp)[i]\n      temp.append(list(samp)[i])\n##cole=[]\n#for i in range(len(list(samp))):\n # cole.append(int(list(samp)[i].split(sep='h')[0]))\n","bf51d3b9":"duration_hours","a5c360e1":"duration_min","cba265f7":"df['Duration_Hour']=duration_hours\ndf['Duration_Min']=duration_min","a43cd7f6":"df","9c868e5f":"df.drop('Duration',axis=1,inplace=True)","5c78dd7b":"df","30ef077f":"df['Airline'].value_counts()","84b2f710":"#To check The most bought airlines\nplt.figure(figsize=(26,12))\nplt.title('To check The most bought airlines',fontsize=20)\nsns.set_style('darkgrid')\nsns.boxplot(y='Price',x=\"Airline\",data=df.sort_values('Price',ascending=False))","5d6acea2":"#Airline - > Nominal Data -> OneHotEncoding\nAirline=df['Airline']\nAirline=pd.get_dummies(Airline,drop_first=True)\nAirline.head()","2322fa78":"df['Source'].value_counts()","7bc804e9":"#Source VS Price\nplt.figure(figsize=(26,12))\nplt.title('Source VS Price Plot',fontsize=20)\nsns.set_style('darkgrid')\nsns.boxplot(y='Price',x=\"Source\",data=df.sort_values('Price',ascending=False))","96e6a202":"#Onehotencoding for Source :\nSource=df[['Source']]\nSource=pd.get_dummies(Source,drop_first=True)\nSource.head()","bb00c263":"df['Destination'].value_counts()","69c618b5":"#Destination VS Price\nplt.figure(figsize=(26,12))\nplt.title('Destination VS Price Plot',fontsize=20)\nsns.set_style('darkgrid')\nsns.boxplot(y='Price',x=\"Destination\",data=df.sort_values('Price',ascending=False))","6ec6601e":"#Destination -> OneHotEncoding:\nDestination=df[['Destination']]\nDestination=pd.get_dummies(Destination,drop_first=True)\nDestination.head()\n\n","aff02f62":"df['Route'].value_counts()","7edad521":"df['Additional_Info'].value_counts()","bdeaa21b":"#Route and Total stops convey almost same info\n#Addtional Info has no significant info for our model , and also it has almost 80% of info as - \"No_info\"\n#So we can drop some unncessary features\n\ndf.drop(['Additional_Info','Route'],axis=1,inplace=True)","9d4b4ef7":"df","c6aebd11":"df['Total_Stops'].value_counts()","e5177beb":"#Total Stops VS Price\nplt.figure(figsize=(26,12))\nplt.title('Total Stops VS Price Plot',fontsize=20)\nsns.set_style('darkgrid')\nsns.boxplot(y='Price',x=\"Total_Stops\",data=df.sort_values('Price',ascending=False))","ade89e45":"#The Data is in somewhat Order , therefore . Ordinal data - > Label Encoder should be used :\n\ndf.replace({\n    \"non-stop\":0,\n    \"1 stop\":1,\n    \"2 stops\":2,\n    \"3 stops\":3,\n    \"4 stops\":4\n},inplace=True)","3cfea4c0":"df.head()","13a5f8ad":"#Now , we have to add all those enocded fetaures to our main dataframe :\ndf=pd.concat([df,Airline,Source,Destination],axis=1)","89f82afd":"df.head()","0eb63855":"#Since we have already included encoded values of Airline , Source And Destination , we should drop their textual values\n\ndf.drop(['Airline','Source','Destination'],axis=1,inplace=True)","95e29d5c":"df.head()","1c79a465":"#Now Our train data Is Purely converted into Numerical Format :\ndf.shape","10e6539c":"test_data=pd.read_excel(r\"..\/input\/flight-fare-prediction-mh\/Test_set.xlsx\")","b0d7a9a7":"test_data.head()","0966a387":"#So Basically , we have to repeat our Pre-processing steps again , like the same steps we did earlier in Our Train set :","ed137eda":"test_data.info()","6ccbe275":"test_data.describe()","af13a2df":"test_data.isnull().sum()  #To Check For Null Values","1df64818":"test_data.dropna(inplace=True)","475ff097":"# Date_of_Journey\ntest_data[\"Journey_Of_day\"] = pd.to_datetime(test_data.Date_of_Journey, format=\"%d\/%m\/%Y\").dt.day\ntest_data[\"Journey_Of_month\"] = pd.to_datetime(test_data[\"Date_of_Journey\"], format = \"%d\/%m\/%Y\").dt.month\ntest_data.drop([\"Date_of_Journey\"], axis = 1, inplace = True)\n","510b5dfa":"# Dep_Time\ntest_data[\"Dep_Hour\"] = pd.to_datetime(test_data[\"Dep_Time\"]).dt.hour\ntest_data[\"Dep_Min\"] = pd.to_datetime(test_data[\"Dep_Time\"]).dt.minute\ntest_data.drop([\"Dep_Time\"], axis = 1, inplace = True)\n","7b100d50":"# Arrival_Time\ntest_data[\"Arrival_hour\"] = pd.to_datetime(test_data.Arrival_Time).dt.hour\ntest_data[\"Arrival_min\"] = pd.to_datetime(test_data.Arrival_Time).dt.minute\ntest_data.drop([\"Arrival_Time\"], axis = 1, inplace = True)","06091bbc":"# Duration\nduration = list(test_data[\"Duration\"])\n\nfor i in range(len(duration)):\n    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n        if \"h\" in duration[i]:\n            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n        else:\n            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n\nduration_hours = []\nduration_mins = []\nfor i in range(len(duration)):\n    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    \n    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1])) ","72fa125f":"\n# Adding Duration column to test set\ntest_data[\"Duration_hours\"] = duration_hours\ntest_data[\"Duration_mins\"] = duration_mins\ntest_data.drop([\"Duration\"], axis = 1, inplace = True)","f67cf22d":"print(\"Airline\")\nprint(\"-\"*75)\nprint(test_data[\"Airline\"].value_counts())\nAirline = pd.get_dummies(test_data[\"Airline\"], drop_first= True)\n\nprint()\n\nprint(\"Source\")\nprint(\"-\"*75)\nprint(test_data[\"Source\"].value_counts())\nSource = pd.get_dummies(test_data[\"Source\"], drop_first= True)\n\nprint()\n\nprint(\"Destination\")\nprint(\"-\"*75)\nprint(test_data[\"Destination\"].value_counts())\nDestination = pd.get_dummies(test_data[\"Destination\"], drop_first = True)","0ba948cc":"\n# Route and Total_Stops are related to each other\ntest_data.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)\n\n# Replacing Total_Stops\ntest_data.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)\n\n# Concatenate dataframe --> test_data + Airline + Source + Destination\ndata_test = pd.concat([test_data, Airline, Source, Destination], axis = 1)\n\ndata_test.drop([\"Airline\", \"Source\", \"Destination\"], axis = 1, inplace = True)\n\n","5a56ef53":"#So BASICALLY , i have created a new dataframe -> data_test , with all encoded values and necessary features ONLY","4853a9ef":"data_test.shape","e0383556":"data_test.head()","416169f4":"df.shape","378447d5":"df.columns","06448ce2":"#Selecting All Independent Features :\n\nX=df.loc[:,['Total_Stops', 'Journey_Of_Day', 'Journey_Of_Month',\n       'Dep_Hour', 'Dep_Min', 'Arrival_Hour', 'Arrival_Min', 'Duration_Hour',\n       'Duration_Min', 'Air India', 'GoAir', 'IndiGo', 'Jet Airways',\n       'Jet Airways Business', 'Multiple carriers',\n       'Multiple carriers Premium economy', 'SpiceJet', 'Trujet', 'Vistara',\n       'Vistara Premium economy', 'Source_Chennai', 'Source_Delhi',\n       'Source_Kolkata', 'Source_Mumbai', 'Destination_Cochin',\n       'Destination_Delhi', 'Destination_Hyderabad', 'Destination_Kolkata',\n       'Destination_New Delhi']]","0e06465c":"X.head()","fe9a711b":"#Selecting My Target \/ Dependent Feature :\ny=df.iloc[:,1]","d1f69b6d":"y.head()","f78c11ef":"df.corr()","020a2451":"plt.figure(figsize=(18,18))\nsns.heatmap(df.corr(),annot=True)","fab11bbf":"#With Respect To Target Value:\ndf.corr()['Price'].sort_values(ascending=False)","43736edf":"#Before Model Selection , we will try to Exlpore The Correlations Between Different Features , For our Output Variable , Which Are Important.\nfrom sklearn.ensemble import ExtraTreesRegressor","9b9d13bc":"selection=ExtraTreesRegressor()","c386f52a":"selection.fit(X,y)","2846c62f":"important_feat=selection.feature_importances_","7a05dcd0":"pd.Series(important_feat,index=X.columns)","7439889c":"important_feats=pd.Series(important_feat,index=X.columns)","35a91d1f":"#To Print Top 20 Highly Correlated Features :\nimportant_feats.nlargest(20)","118237bb":"#Graphical Visualisation :\nplt.figure(figsize=(12,8))\nimportant_feats.nlargest(20).plot(kind='barh')","156a5571":"#We can see that  , Total_Stops Play AN very important Feature","18c9818d":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split","e44e7406":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=40)","c7afc0d2":"rfc_model=RandomForestRegressor()\nrfc_model.fit(X_train,y_train)","eaa8564f":"pred=rfc_model.predict(X_test)","727bb957":"pred","8f1d6060":"comp_df=pd.DataFrame({'Actual Values':y_test,'Predicted Values':pred})","dd37afd6":"comp_df","f554f8d1":"#To Display The Score Of Our Model On Train Set :\nrfc_model.score(X_train,y_train)","677cf550":"#To Display The Score Of Our Model On Test Set :\nrfc_model.score(X_test,y_test)","e7abf355":"#DistPlot  For Original Values VS Prediccted Values :\nsns.distplot(y_test-pred)","33c262f7":"plt.scatter(y_test,pred,alpha=0.5)\nplt.xlabel('Original Values : y_test')\nplt.ylabel('Predicted Values : pred')","e6a6f255":"from sklearn import metrics\n\n\nprint('MAE:', metrics.mean_absolute_error(y_test, pred))\nprint('MSE:', metrics.mean_squared_error(y_test, pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, pred)))","0dae16eb":"print(\"R2 Score Of Our Model Is : \")\nprint()\nmetrics.r2_score(y_test, pred)","57dc4d18":"#In The Next Section , Let Us Try To Improve The Score oF Our Model , Using HyperParameter Tuning","9b9c71d3":"from sklearn.model_selection import RandomizedSearchCV","11e0b14c":"test=np.linspace(start=100,stop=1000,num=20)\ntest","c595cd3e":"#Defining Hyperparameters Grid:\n\nn_estimators=[int(x) for x in np.linspace(start=100,stop=1200,num=12)] \n \nmax_depth=[int(x) for x in np.linspace(start=5,stop=30,num=6) ]\nmin_samples_split=[2, 5, 10, 15,20, 100] \nmin_samples_leaf=[1, 2, 5, 10] \nmax_features=['auto', 'sqrt']\n","cf1f6f1d":"#Creating Random GRID :\n\nrandom_grid={\n             'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf\n}","a95e4ea8":"rf_random=RandomizedSearchCV(estimator=rfc_model,param_distributions=random_grid,\n                             scoring='neg_mean_squared_error',n_iter=15,n_jobs=1,cv=5,verbose=2,\n                             random_state=42)","a2992e32":"rf_random.fit(X_train,y_train)","0a35f54c":"rf_random.best_params_","7ad024f6":"pred2=rf_random.predict(X_test)","b9e8e840":"pred2","d6451b1b":"plt.figure(figsize=(12,8))\nplt.title('Y_test VS RandomisedSearch CV Predictions')\nsns.distplot(y_test-pred2)","0fe54bd9":"plt.figure(figsize = (12,8))\nplt.scatter(y_test, pred2, alpha = 0.5)\nplt.xlabel(\"y_test\")\nplt.ylabel(\"RCV predictions\")\nplt.title(\"Y_test VS Predictions RCV Scatterplot\")","ec92e7cb":"print('MAE:', metrics.mean_absolute_error(y_test, pred2))\nprint('MSE:', metrics.mean_squared_error(y_test, pred2))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, pred2)))","786ba690":"print(\"R2 Score Of Our Model Is : \")\nprint()\nmetrics.r2_score(y_test, pred2)","eff7b918":"#Since our model's performance has been increased ..We can export it now for our future refernces","b2f24d71":"import pickle","e7fc2924":"my_file=open('flight_fa.pkl','wb')","c5654a9d":"pickle.dump(rf_random,my_file)","09c74269":"#Let us test whether our loading of model has been done or not..\n\nmodel=open('flight_fa.pkl','rb')\nforest=pickle.load(model)","10555aec":"pred3=forest.predict(X_test)\nmetrics.r2_score(y_test,pred3)","b78aa902":"# Somewhat our model is performing Quite Well.","ea27dbdc":"# Model Selection :","d5111b04":"Model Fitting : Random Forest Rgressor ","5cbc481f":"Finding Correlation Between Features :","13ba720c":"Category Data Handling:<br>\n\nNominal Data -> Data in No Order : Perform OneHotEncoder<br>\nOrdinal Data -> Data In Order : Perform LabelEncoding","af7a245a":"## Test Set PreProcessing:","3a3c989b":"Evaluation :","b82ee143":"##Hyperparameter Tuning :","9fe16e75":"#Exploratory Data Analysis :","61d8743b":"Choose following method for hyperparameter tuning : <br>\nRandomizedSearchCV <br>\nGridSearchCV<br>\nAnd Check The best parameters for our model..<br>","77cd5c93":"# Categorical Data Analysis :","248f6761":"# Feature Extraction And Handling :","9a366c8b":"# **Flight Fare Prediction**","b7b55468":"## Saving And Exporting Our Model","2fd9c2ef":"## Test Categorical data","a933429a":"# Managing Test Set :","af690825":"## **Import Dataset In Excel Format ..Since This is Obtained From Kaggle Dataset :**\n<br>\nhttps:\/\/www.kaggle.com\/nikhilmittal\/flight-fare-prediction-mh\/"}}