{"cell_type":{"fc326ae6":"code","a3701e30":"code","eba30735":"code","bb65bcda":"code","20947764":"code","b018bdbb":"code","c5e1f5b8":"code","fd46b135":"code","2ee03be2":"code","7979c96a":"code","32a1dae7":"code","6e8e5795":"code","22831a15":"code","00626a5c":"code","37b33cad":"code","33020548":"code","b9446963":"code","79367bb5":"code","c699a310":"code","42f8a95a":"code","71fe496e":"code","a23d0567":"code","50941c30":"code","f0cfc528":"code","eacd120a":"code","04b38329":"code","ffbcc379":"code","f2ed1e34":"code","65a48caa":"markdown","0493a9ab":"markdown","1cac38a5":"markdown","70ed4f87":"markdown","94b33792":"markdown","2e64d306":"markdown","5ea46c2b":"markdown","8595fe90":"markdown","4d685f22":"markdown","24d1f12d":"markdown"},"source":{"fc326ae6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a3701e30":"import plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt\n\nfrom pandas_profiling import ProfileReport\nimport seaborn as sns\nfrom sklearn import metrics\nfrom scipy import stats\n\nfrom copy import deepcopy\n\nimport h2o","eba30735":"train_df = pd.read_csv('\/kaggle\/input\/california-house-prices\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/california-house-prices\/test.csv')\ntrain_df.shape, test_df.shape","bb65bcda":"train_df=train_df.drop([3674,6055,32867,34876,43398,44091,44633])","20947764":"data = pd.concat([train_df['Sold Price'], train_df['Listed Price']], axis=1)\nfig = px.scatter(data, x='Listed Price', y='Sold Price')\nfig.show()","b018bdbb":"data = pd.concat([train_df['Sold Price'], train_df['Tax assessed value']], axis=1)\nfig = px.scatter(data, x='Tax assessed value', y='Sold Price')\nfig.show()","c5e1f5b8":"data = pd.concat([train_df['Sold Price'], train_df['Annual tax amount']], axis=1)\nfig = px.scatter(data, x='Annual tax amount', y='Sold Price')\nfig.show()","fd46b135":"data = pd.concat([train_df['Sold Price'], train_df['Last Sold Price']], axis=1)\nfig = px.scatter(data, x='Last Sold Price', y='Sold Price')\nfig.show()","2ee03be2":"# Split features and labels\ny = train_df['Sold Price'].reset_index(drop=True)\ntrain_features = train_df.drop('Sold Price', axis=1)\ntest_features = test_df.copy()\n\nfeatures = pd.concat([train_features, test_features]).reset_index(drop=True)\nfeatures.shape","7979c96a":"def proc_bedroom(x):\n    if not pd.isna(x) and not x.isdigit():\n        temp = x.split(',')\n        n = len(x.split(','))\n        if 'Walk-in Closet' in temp:\n            n -= 1\n        return n\n    else:\n        return x\n\nfeatures['Bedrooms']=features['Bedrooms'].apply(lambda x: proc_bedroom(x))\nfeatures['Bedrooms'] = pd.to_numeric(features['Bedrooms'])\nfeatures['Zip'] = features['Zip'].astype('str')","32a1dae7":"#missing data\ntotal = features.isnull().sum().sort_values(ascending=False)\npercent = ((features.isnull().sum() \/ features.isnull().count()) * 100).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data = missing_data.reset_index()\nmissing_data.columns = ['Name', 'Total', 'Percent']\nmissing_data[:10]","6e8e5795":"def handle_missing(features):\n    zero_fill=['Last Sold Price','Lot','Full bathrooms','Annual tax amount','Tax assessed value','Bathrooms',\n               'Bedrooms','Total interior livable area','Total spaces','Garage spaces']\n    none_fill=['Last Sold On','Middle School','Appliances included','Flooring','Laundry features','Cooling features',\n               'Cooling','Heating features','Heating','Elementary School','High School','Parking features','Parking','Summary']\n    max_fill=['Middle School Score','Middle School Distance','Elementary School Score','Elementary School Distance',\n              'High School Score','High School Distance']\n    mode_fill=['Year built','Region']\n    for c in zero_fill:\n        features[c]=features[c].fillna(0)\n    for c in max_fill:\n        features[c]=features[c].fillna(features[c].max())\n    for c in none_fill:\n        features[c]=features[c].fillna('None')\n    for c in mode_fill:\n        features[c]=features[c].fillna(features[c].mode()[0])\n    return features","22831a15":"features = handle_missing(features)\nfeatures.shape","00626a5c":"# I want to thanks @masumrumi for sharing this amazing plot!\ndef plotting_3_chart(df, feature):\n    ## Importing seaborn, matplotlab and scipy modules. \n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    import matplotlib.gridspec as gridspec\n    from scipy import stats\n    import matplotlib.style as style\n    style.use('fivethirtyeight')\n\n    ## Creating a customized chart. and giving in figsize and everything. \n    fig = plt.figure(constrained_layout=True, figsize=(12,8))\n    ## creating a grid of 3 cols and 3 rows. \n    grid = gridspec.GridSpec(ncols=3, nrows=3, figure=fig)\n    #gs = fig3.add_gridspec(3, 3)\n\n    ## Customizing the histogram grid. \n    ax1 = fig.add_subplot(grid[0, :2])\n    ## Set the title. \n    ax1.set_title('Histogram')\n    ## plot the histogram. \n    sns.distplot(df.loc[:,feature], norm_hist=True, ax = ax1)\n\n    # customizing the QQ_plot. \n    ax2 = fig.add_subplot(grid[1, :2])\n    ## Set the title. \n    ax2.set_title('QQ_plot')\n    ## Plotting the QQ_Plot. \n    stats.probplot(df.loc[:,feature], plot = ax2)\n\n    ## Customizing the Box Plot. \n    ax3 = fig.add_subplot(grid[:, 2])\n    ## Set title. \n    ax3.set_title('Box Plot')\n    ## Plotting the box plot. \n    sns.boxplot(df.loc[:,feature], orient='v', ax = ax3 );","37b33cad":"# Fix the target variable\ny = np.log1p(y)\n\nplotting_3_chart(pd.DataFrame(y), 'Sold Price')","33020548":"numerical_columns = features.select_dtypes(include=['int64','float64']).columns\n\nskewed_features = features[numerical_columns].apply(lambda x: stats.skew(x)).sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew value' :skewed_features})\nskewness.head(20)","b9446963":"def fix_skew(features):\n    \"\"\"\n    This function takes in a dataframe and return fixed skewed dataframe\n    \"\"\"\n    ## Import necessary modules \n    from scipy.special import boxcox1p\n    from scipy.stats import boxcox_normmax\n    \n    ## Getting all the data that are not of \"object\" type. \n    numerical_columns = features.select_dtypes(include=['int64','float64']).columns\n\n    # Check the skew of all numerical features\n    skewed_features = features[numerical_columns].apply(lambda x: stats.skew(x)).sort_values(ascending=False)\n    high_skew = skewed_features[abs(skewed_features) > 0.5]\n    skewed_features = high_skew.index\n\n    # Perform the Box-Cox transformation\n    for column in skewed_features:\n        features[column] = boxcox1p(features[column], boxcox_normmax(features[column] + 1))\n        \n    return features","79367bb5":"def reset_zero(x):\n    return max(x,0)\nfeatures['Garage spaces']=features['Garage spaces'].apply(lambda x: reset_zero(x))\nfeatures['Total spaces']=features['Total spaces'].apply(lambda x: reset_zero(x))\nfeatures = fix_skew(features)\nfeatures.head()","c699a310":"x = features.iloc[:len(y), :]\nx_test = features.iloc[len(y):, :]\nx.shape, y.shape, x_test.shape","42f8a95a":"selected=['Listed Price','Tax assessed value','Annual tax amount','Listed On','Elementary School Distance','Last Sold On',\n'Zip','Total interior livable area','Last Sold Price','Lot','Year built','Bathrooms','High School Distance',\n'Elementary School Score','Full bathrooms','Middle School Distance','Heating features','Bedrooms',\n'Elementary School','Laundry features','Region','Middle School Score','Type',\n'Total spaces','High School Score','Parking']\n\nx=x[selected]\nx_test=x_test[selected+['Id']]\nx.head()","71fe496e":"import h2o\n\nh2o.init()\nhf = h2o.H2OFrame(pd.concat([x, y], axis=1))\nx_test_hf = h2o.H2OFrame(x_test)","a23d0567":"predictors = hf.drop('Sold Price').columns\nresponse = 'Sold Price'","50941c30":"from h2o.automl import H2OAutoML\n\n# stopping_metric: Specify the metric to use for early stopping. \naml = H2OAutoML(\n    max_models=50,\n    include_algos=[\"XGBoost\"],\n    max_runtime_secs=7200,\n    stopping_metric='RMSLE',\n    sort_metric='RMSLE'\n)","f0cfc528":"# Train the model\naml.train(x=predictors,y=response,training_frame=hf)","eacd120a":"lb = aml.leaderboard; lb","04b38329":"aml.leader","ffbcc379":"submission_results = pd.read_csv(\"\/kaggle\/input\/california-house-prices\/sample_submission.csv\")\ndef top_k_avg_predict(k,leaderboard):\n    lb=leaderboard.as_data_frame()\n    ans=submission_results.iloc[:, 1]\n    for i in range(k):\n        model=lb.loc[i]['model_id']\n        pred=h2o.get_model(model).predict(x_test_hf)\n        pred=pred.as_data_frame()\n        ans+=np.expm1(pred['predict'])\/k\n    return ans\n\nsubmission_results.iloc[:, 1]=top_k_avg_predict(8,aml.leaderboard)\nsubmission_results.head()\nsubmission_results.to_csv('submission.csv', index=False)","f2ed1e34":"submission_results.head()","65a48caa":"- \u6570\u636e\u8f6c\u6362","0493a9ab":"## 3.predict","1cac38a5":"## 1.Data Clean\n### (1) \u5bfc\u5165\u5e76\u89c2\u5bdf\u6570\u636e","70ed4f87":"# Using H2o AutoML to predict house prices","94b33792":"\u53d1\u73b0\u8fc7\u62df\u5408\u73b0\u8c61\u6bd4\u8f83\u4e25\u91cd\uff0c\u8fd9\u91cc\u8003\u8651\u4f7f\u7528\u524dk\u4e2a\u6a21\u578b\u7684\u8f93\u51fa\u53d6\u5747\u503c\u8fdb\u884c\u6574\u5408\n\nReported on train data.\n\n**RMSLE: 0.00745891154333034**\n\nReported on cross-validation data.\n\n**RMSLE: 0.013097170958722777**","2e64d306":"- \u7f3a\u7701\u503c\u586b\u5145","5ea46c2b":"- \u521d\u6b65\u5904\u7406\u6570\u636e  zip\u5217\u5e94\u4f5c\u4e3a\u5b57\u7b26\u4e32 \u5e76\u5bf9bedroom\u5217\u4f5c\u7b80\u5355\u5904\u7406","8595fe90":"## 2.train","4d685f22":"- \u6839\u636e\u4ee5\u4e0b\u6563\u70b9\u56fe\uff0c\u5220\u9664\u79bb\u7fa4\u70b9","24d1f12d":"- \u5c06features\u5206\u79bb  \u6839\u636eVariable Importances\u8fdb\u884c\u6311\u9009"}}