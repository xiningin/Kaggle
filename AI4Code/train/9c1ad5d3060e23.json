{"cell_type":{"d090e4d7":"code","515d2e37":"code","99d6489c":"code","fc69dfda":"code","e485a7b8":"code","26469834":"code","20d2948a":"code","252e82e1":"code","d2506554":"code","9c605841":"code","39eda41d":"code","20fb8e54":"code","2b55accc":"code","8d87b82a":"code","49708b76":"code","a3af21bf":"code","7316f696":"markdown","f8bcd0b0":"markdown","8ae906e6":"markdown","5e82017e":"markdown","6124b97f":"markdown","c13de8e5":"markdown","ff009e07":"markdown","c7be1127":"markdown"},"source":{"d090e4d7":"# importar as bibliotecas necess\u00e1rias\nimport pandas as pd\nfrom pandas_datareader import data as web\nimport plotly.graph_objects as go\n\n\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import LSTM,Dense\n\n\nfrom keras.models import load_model\n\n\n\n# criar um DataFrame vazio\ndf = pd.DataFrame()","515d2e37":"look_back = 40\nforward_days = 10\nnum_periods = 20","99d6489c":"#open the csv, chose company_N, where N = {A, B, C or D}\ndf = pd.read_csv('..\/input\/tcc-cotacao\/price3.csv')\n#df = pd.read_csv('\/content\/coffee-prices-historical-chart-data.csv')\n\n#set date as index\ndf['date'] = pd.to_datetime(df['date'])\nprint(df['date'].dtype)\n#df = df.loc[df['date'] >= '01-01-2003']\n#df = df.loc[df['date'] <= '31-12-2013']\ndf.set_index('date', inplace=True)\n#keep only the 'Close' column\ndf = df['value']\ndf.head()","fc69dfda":"len(df)","e485a7b8":"import matplotlib.pyplot as plt\nplt.figure(figsize = (15,10))\nplt.plot(df, label='Caf\u00e9 Ar\u00e1bica')\nplt.legend(loc='best')\nplt.show()","26469834":"array = df.values.reshape(df.shape[0],1)\narray[:5]","20d2948a":"from sklearn.preprocessing import MinMaxScaler\nscl = MinMaxScaler()\narray = scl.fit_transform(array)\narray[:5]","252e82e1":"#split in Train and Test\n\ndivision = len(array) - num_periods*forward_days\n\narray_test = array[division-look_back:]\narray_train = array[:division]","d2506554":"#Get the data and splits in input X and output Y, by spliting in `n` past days as input X \n#and `m` coming days as Y.\ndef processData(data, look_back, forward_days,jump=1):\n    X,Y = [],[]\n    for i in range(0,len(data) -look_back -forward_days +1, jump):\n        X.append(data[i:(i+look_back)])\n        Y.append(data[(i+look_back):(i+look_back+forward_days)])\n    return np.array(X),np.array(Y)","9c605841":"\nX_test,y_test = processData(array_test,look_back,forward_days,forward_days)\ny_test = np.array([list(a.ravel()) for a in y_test])\n\nX,y = processData(array_train,look_back,forward_days)\ny = np.array([list(a.ravel()) for a in y])","39eda41d":"from sklearn.model_selection import train_test_split\nX_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size=0.20, random_state=42)","20fb8e54":"print(X_train.shape)\nprint(X_validate.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_validate.shape)\nprint(y_test.shape)","2b55accc":"NUM_NEURONS_FirstLayer = 50\nNUM_NEURONS_SecondLayer = 30\nEPOCHS = 50\n\n#Build the model\nmodel = Sequential()\nmodel.add(LSTM(NUM_NEURONS_FirstLayer,input_shape=(look_back,1), return_sequences=True))\nmodel.add(LSTM(NUM_NEURONS_SecondLayer,input_shape=(NUM_NEURONS_FirstLayer,1)))\nmodel.add(Dense(forward_days))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\n\nhistory = model.fit(X_train,y_train,epochs=EPOCHS,validation_data=(X_validate,y_validate),shuffle=True,batch_size=2, verbose=2)","8d87b82a":"\nplt.figure(figsize = (15,10))\n\nplt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.legend(loc='best')\nplt.show()","49708b76":"\nXt = model.predict(X_test)","a3af21bf":"plt.figure(figsize = (15,10))\n\nfor i in range(0,len(Xt)):\n    plt.plot([x + i*forward_days for x in range(len(Xt[i]))], scl.inverse_transform(Xt[i].reshape(-1,1)), color='r')\n    \nplt.plot(0, scl.inverse_transform(Xt[i].reshape(-1,1))[0], color='r', label='Prediction') #only to place the label\n    \nplt.plot(scl.inverse_transform(y_test.reshape(-1,1)), label='Target')\nplt.legend(loc='best')\nplt.show()","7316f696":"##( Dividir os dados em Treino\/Valida\u00e7\u00e3o para o modelo LSTM e os dados de Teste)\nVamos separar para os \u00faltimos k per\u00edodos (num_periods) para testar o modelo. A cada per\u00edodo, o modelo ir\u00e1 prever os pr\u00f3ximos n dias. O resto ser\u00e1 utilizado para o treinamento (Treino e Valida\u00e7\u00e3o).","f8bcd0b0":"##Training the LSTM (Treinando a LSTM)","8ae906e6":"(Prever todos os dados para ver como o modelo reage aos dados de Treino e Teste)","5e82017e":"##Data visualization ( Vizualizando os dados )","6124b97f":"##Prevendo o pre\u00e7o de uma a\u00e7\u00e3o no mercado de a\u00e7\u00f5es\nO objetivo \u00e9 prever o que acontecer\u00e1 com o valor de fechamento de pre\u00e7o do Caf\u00e9 Ar\u00e1bica em n dias (forward_days), tendo como base os m dias anteriores (look_back).","c13de8e5":"Primeiro, vamos abrir o CSV com o Pandas, colocar as datas como index e manter apenas a coluna que queremos prever, que \u00e9 o pre\u00e7o de fechamento.","ff009e07":"##Data normalization ( Normalizando os dados )\n","c7be1127":"##Predicting the Test Set to see the results ( Vamos prever os dados de Teste para o resultado )"}}