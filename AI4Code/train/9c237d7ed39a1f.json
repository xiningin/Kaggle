{"cell_type":{"59661507":"code","ac9c9bcd":"code","66a41d12":"code","65ffdd80":"code","17e7655d":"code","8a70d875":"code","e524d7ba":"code","ea17f886":"code","672affca":"code","729fd84b":"code","1b7230a5":"code","8cfd1a7e":"code","87499dd4":"code","bc1cec78":"code","f1e44eae":"code","606dc9ff":"code","7d93901a":"code","b1a3d07a":"code","c6676d51":"code","246a5c6c":"code","64bc923d":"markdown"},"source":{"59661507":"#import packages\nimport numpy as np\nimport pandas as pd \n#import matplotlib as mpl\nimport h2o\nfrom h2o.automl import H2OAutoML\nfrom h2o.estimators import H2OWord2vecEstimator, H2OGradientBoostingEstimator\nimport seaborn as sns\nimport matplotlib.pyplot as plt","ac9c9bcd":"h2o.init()","66a41d12":"job_titles = h2o.import_file('..\/input\/commonlitreadabilityprize\/train.csv')\ntest = h2o.import_file('..\/input\/commonlitreadabilityprize\/test.csv')\nsample_submission = pd.read_csv('..\/input\/commonlitreadabilityprize\/sample_submission.csv')","65ffdd80":"print(job_titles.shape)\nprint(test.shape)","17e7655d":"#desscribe dataset\njob_titles.head()","8a70d875":"STOP_WORDS = [\"ax\",\"i\",\"you\",\"edu\",\"s\",\"t\",\"m\",\"subject\",\"can\",\n              \"lines\",\"re\",\"what\",\"there\",\"all\",\"we\",\"one\",\"the\",\n              \"a\",\"an\",\"of\",\"or\",\"in\",\"for\",\"by\",\"on\",\"but\",\"is\",\n              \"in\",\"a\",\"not\",\"with\",\"as\",\"was\",\"if\",\"they\",\"are\",\n              \"this\",\"and\",\"it\",\"have\",\"from\",\"at\",\"my\",\"be\",\"by\",\n              \"not\",\"that\",\"to\",\"from\",\"com\",\"org\",\"like\",\"likes\",\n              \"so\"]","e524d7ba":"def tokenize(sentences, stop_word = STOP_WORDS):\n    tokenized = sentences.tokenize(\"\\\\W+\")\n    tokenized_lower = tokenized.tolower()\n    tokenized_filtered = tokenized_lower[(tokenized_lower.nchar() >= 2) | (tokenized_lower.isna()),:]\n    tokenized_words = tokenized_filtered[tokenized_filtered.grep(\"[0-9]\",invert=True,output_logical=True),:]\n    tokenized_words = tokenized_words[(tokenized_words.isna()) | (~ tokenized_words.isin(STOP_WORDS)),:]\n    return tokenized_words","ea17f886":"def predict(job_title,w2v, gbm):\n    words = tokenize(h2o.H2OFrame(job_title).ascharacter())\n    job_title_vec = w2v.transform(words, aggregate_method=\"AVERAGE\")\n    print(gbm.predict(test_data=job_title_vec))\n    return (gbm.predict(test_data=job_title_vec))","672affca":"words = tokenize(job_titles[\"excerpt\"])","729fd84b":"w2v_model = H2OWord2vecEstimator(sent_sample_rate = 0.0, epochs = 2)\nw2v_model.train(training_frame=words)","1b7230a5":"w2v_model.find_synonyms(\"teacher\", count = 5)","8cfd1a7e":"# Calculate a vector for each job title:\njob_title_vecs = w2v_model.transform(words, aggregate_method = \"AVERAGE\")","87499dd4":"# Prepare training & validation data (keep only job titles made of known words):\nvalid_job_titles = ~ job_title_vecs[\"C4\"].isna()\ndata = job_titles[valid_job_titles,:].cbind(job_title_vecs[valid_job_titles,:])\ndata_split = data.split_frame(ratios=[0.8])","bc1cec78":"# Build a basic GBM model:\ngbm_model = H2OGradientBoostingEstimator()\ngbm_model.train(x = job_title_vecs.names,\n                y=\"target\",\n                training_frame = data_split[0],\n                validation_frame = data_split[1])","f1e44eae":"perf = gbm_model.model_performance()\nperf","606dc9ff":"test = pd.read_csv('..\/input\/commonlitreadabilityprize\/test.csv')\ntest[\"target\"] = float(1)\ntest1=np.zeros(7)","7d93901a":"# Predict\nfor i in range(0,7):\n    print(test[\"target\"][i])\n    a=predict([test[\"excerpt\"][i]],w2v_model, gbm_model)\n    test[\"target\"][i]=a[\"predict\"]\n    print(test[\"target\"][i])\n#print(predict([\"school teacher having holidays every month\"], w2v_model, gbm_model))\na","b1a3d07a":"test[\"target\"]","c6676d51":"sample_submission[\"target\"]=test[\"target\"]\nsample_submission.head()","246a5c6c":"sample_submission.to_csv('submission.csv', index=False)","64bc923d":"# H2o model"}}