{"cell_type":{"6251dfab":"code","fcc4b2f8":"code","61ea784c":"code","35a4b063":"code","af7530b3":"code","4617aeb6":"code","c57a8a93":"code","70ebd0b0":"code","f41981ca":"code","afbde7b0":"code","b2aa9e1d":"code","58b4f7d3":"code","1445594f":"code","f8e48cd7":"code","7cd78f1d":"code","19d6b4cc":"code","86b7a5a5":"code","adfcaacb":"code","bb2d677c":"code","3b66b9f8":"code","1743d3c1":"code","bdd49961":"code","9b948569":"code","db33e947":"code","f2157a21":"markdown","eb5e50b6":"markdown","a5d51fe2":"markdown","0344a651":"markdown","5a1c3e2b":"markdown","6e7c1a3a":"markdown","3cefa262":"markdown","ab63d0f6":"markdown","67d24adc":"markdown","5135d5c2":"markdown","9e1a56e6":"markdown","2e9ec47b":"markdown","9b63d3cd":"markdown","1044f02d":"markdown"},"source":{"6251dfab":"import os\nimport matplotlib.pyplot as plt\nimport cv2\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport pydicom\nimport numpy as np\nimport shutil\nfrom PIL import Image\nimport scipy\nimport torch \nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import models , datasets\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport time\nimport copy\n\nprint(\"All modules have been imported\")","fcc4b2f8":"!mkdir \"data\"\n!mkdir \"data\/0\"\n!mkdir \"data\/1\"\nlabels = pd.read_csv(\"..\/input\/png-dataset-for-rsna-mgmt-detection\/png_data\/png_voxel_converted_ds\/train_labels.csv\")","61ea784c":"main_folder_path = \"..\/input\/png-dataset-for-rsna-mgmt-detection\/png_data\/png_voxel_converted_ds\"\nmain_train_folder_path = os.path.join(main_folder_path  , \"train\")\nfor subject in tqdm(os.listdir(main_train_folder_path)):\n    subject_folder = os.path.join(main_train_folder_path , subject)\n    for mri_type in os.listdir(subject_folder):\n        mri_type_folder = os.path.join(subject_folder , mri_type)\n        for mri_image in os.listdir(mri_type_folder):\n            original_image_path = os.path.join(mri_type_folder , mri_image)\n            mri_image = subject +\"_\"+ mri_type +\"_\"+ mri_image\n            subject_num = int(subject)\n            idx = np.where(labels['BraTS21ID'] == subject_num)[0][0]\n            label = str(labels.loc[idx , 'MGMT_value'])\n            new_image_folder_path =os.path.join(\"data\" , label)\n            new_image_path = os.path.join(new_image_folder_path , mri_image)\n            shutil.copy(original_image_path , new_image_path)","35a4b063":"print(\"Images with label 0 = \" , len(os.listdir(\"data\/0\")) , \"Images with label 1 = \" , len(os.listdir(\"data\/1\")))","af7530b3":"for folder in os.listdir(\"data\"):\n    folder_name = str(folder)\n    path = \"data\/\"+folder_name\n    for file in tqdm(os.listdir(path)):\n        img = Image.open(path + '\/' + file)\n        clrs = img.getcolors()\n        if len(clrs) == 1:\n            os.remove(path + '\/' + file)","4617aeb6":"print(\"Images with label 0 = \" , len(os.listdir(\"data\/0\")) , \"Images with label 1 = \" , len(os.listdir(\"data\/1\")))","c57a8a93":"!mkdir \"data\/TRAIN\"\n!mkdir \"data\/TRAIN\/1\"\n!mkdir \"data\/TRAIN\/0\"\n!mkdir \"data\/VAL\"\n!mkdir \"data\/VAL\/0\"\n!mkdir \"data\/VAL\/1\"\n!mkdir \"data\/TEST\"\n!mkdir \"data\/TEST\/0\"\n!mkdir \"data\/TEST\/1\"","70ebd0b0":"IMG_PATH = \".\/data\"\n\n#split the data into train\/test\/val\nfor CLASS in tqdm([\"0\" , \"1\"]):\n    IMG_NUM = len(os.listdir(IMG_PATH +\"\/\"+ CLASS))\n    for (n, FILE_NAME) in enumerate(os.listdir(IMG_PATH +\"\/\"+ CLASS)):\n            img = IMG_PATH+ '\/' +  CLASS + '\/' + FILE_NAME\n            if n <4000 :\n                shutil.copy(img, 'data\/TEST\/' + str(CLASS) + '\/' + FILE_NAME)\n            elif n < 0.9*IMG_NUM:\n                shutil.copy(img, 'data\/TRAIN\/'+ str(CLASS) + '\/' + FILE_NAME)\n            else:\n                shutil.copy(img, 'data\/VAL\/'+ str(CLASS) + '\/' + FILE_NAME)\n","f41981ca":"!rm -rf \"data\/0\"\n!rm -rf \"data\/1\"","afbde7b0":"len(os.listdir(\"data\/TRAIN\/1\")) , len(os.listdir(\"data\/TRAIN\/0\")) , len(os.listdir(\"data\/VAL\/1\")) , len(os.listdir(\"data\/VAL\/0\")) , len(os.listdir(\"data\/TEST\/1\")) , len(os.listdir(\"data\/TEST\/0\"))","b2aa9e1d":"mean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\n\ndata_transforms = {\n    'TRAIN': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ]),\n    \n    'VAL': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ]),\n    \n    'TEST': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ]),\n}","58b4f7d3":"data_dir = 'data'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['TRAIN', 'VAL' , 'TEST']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=0)\n              for x in ['TRAIN', 'VAL' , 'TEST']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['TRAIN', 'VAL' , 'TEST']}\nclass_names = image_datasets['TRAIN'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(class_names)","1445594f":"mean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\ndef imshow(inp, title):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    plt.title(title)\n    plt.show()","f8e48cd7":"# Get a batch of training data\ninputs, classes = next(iter(dataloaders['TRAIN']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])","7cd78f1d":"def train_model(model, model_name, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['TRAIN' , 'VAL']:\n            if phase == 'TRAIN':\n                model.train()  # Set model to training mode\n            elif phase == 'VAL':\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'TRAIN'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'TRAIN':\n                        optimizer.zero_grad()\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            if phase == 'TRAIN':\n                scheduler.step()\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'VAL' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                #save the best model\n                torch.save(model , model_name+'weights.pt')\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n","19d6b4cc":"resnet = models.resnet18(pretrained=True)\nnum_ftrs = model.fc.in_features","86b7a5a5":"resnet.fc = nn.Linear(num_ftrs, 2)\n\nresnet = resnet.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.SGD(resnet.parameters(), lr=0.001)\n","adfcaacb":"step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\ntrain_model(resnet,\"resnet\", criterion, optimizer, step_lr_scheduler, num_epochs=1)","bb2d677c":"alexnet = models.alexnet(pretrained=True)\nnum_ftrs = alexnet.classifier[6].in_features","3b66b9f8":"alexnet.classifier[6] = nn.Linear(num_ftrs,2)\n\nalexnet = alexnet.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.SGD(alexnet.parameters(), lr=0.001)","1743d3c1":"step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\ntrain_model(alexnet ,\"alexnet\", criterion, optimizer, step_lr_scheduler, num_epochs=1)","bdd49961":"vgg = models.vgg11_bn(pretrained=True)\nnum_ftrs = vgg.classifier[6].in_features","9b948569":"vgg.classifier[6] = nn.Linear(num_ftrs,2)\n\nvgg = vgg.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.SGD(vgg.parameters(), lr=0.001)","db33e947":"step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\ntrain_model(vgg,\"vgg\", criterion, optimizer, step_lr_scheduler, num_epochs=1)","f2157a21":"<h1> RSNA-MICCAI Brain Tumor Radiogenomic Classification <\/h1>\n<h2> Predicting the status of a genetic biomarker important for brain cancer treatment <\/h2>\n\n<p><b> author - Abhranta Panigrahi <\/b><\/p>\n<b> date - 21st August, 2021<\/b>","eb5e50b6":"<div class=\"section\" id=\"vgg\">\n<h3>VGG<\/h3>\n<p>VGG was introduced in the paper <a class=\"reference external\" href=\"https:\/\/arxiv.org\/pdf\/1409.1556.pdf\">Very Deep Convolutional Networks for\nLarge-Scale Image Recognition<\/a>.\nTorchvision offers eight versions of VGG with various lengths and some\nthat have batch normalizations layers. Here we use VGG-11 with batch\nnormalization. The output layer is similar to Alexnet.","a5d51fe2":"<h2> So, what is MGMT? <\/h2>\n<p> The Escherichia coli Ada gene O6 \u2013methylgunine-DNA methyltransferace (MGMT) is a DNA binding protein that is involved in repairing mutations that occur during DNA replication. MGMT participates in methylation, which means it is a protein that adds a methyl group. <\/p>\n<p> MGMT is also known as suicide enzyme that repairs the pre-mutagenic, pre-carcinogenic and pre-toxic DNA damage O(6)-methylguanine. <\/p>","0344a651":"![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/29653\/logos\/header.png)","5a1c3e2b":"<h1> TO BE CONTINUED !!!! <\/h1>","6e7c1a3a":"<h2> MRI <\/h2>\n<p>Magnetic resonance imaging (MRI) is a medical imaging technique used in radiology to form pictures of the anatomy and the physiological processes of the body. MRI scanners use strong magnetic fields, magnetic field gradients, and radio waves to generate images of the organs in the body. MRI does not involve X-rays or the use of ionizing radiation, which distinguishes it from CT and PET scans. MRI is a medical application of nuclear magnetic resonance (NMR) which can also be used for imaging in other NMR applications, such as NMR spectroscopy.<\/p>\n<img src = \"https:\/\/i.pinimg.com\/originals\/49\/6d\/95\/496d952e43d6a3b9aa87ef63a73e11fe.gif\">","3cefa262":"What folder structure do we want ?\n\n![Screenshot from 2021-08-19 21-17-51.png](attachment:2ff442fb-4d46-435d-b9aa-f5b631a8d8ed.png)","ab63d0f6":"<h2> What the heck are biomarkers ??? <\/h2>\n<p>A biomarker is a biological molecule found in blood, other body fluids, or tissues that is a sign of a normal or abnormal process, or of a condition or disease. A biomarker may be used to see how well the body responds to a treatment for a disease or condition. Also called molecular marker and signature molecule.<\/p>\n\n<p> Biomarkers are indicators of a process going on inside a body. When doctors suspect that something abnormal is going on in the body, they look for signs. These biomarkers are the red flags that pop up to indicate that something is going on. <\/p>","67d24adc":"I have tried to create a beginner friendly notebook for using <b>transfer learning<\/b> for the  [RSNA-MICCAI Brain Tumor Radiogenomic Classification](https:\/\/www.kaggle.com\/c\/rsna-miccai-brain-tumor-radiogenomic-classification) challenge.","5135d5c2":"<h2> So, how does the dataset look like ? <\/h2>\n<p> The dataset consists of a \"train\" folder, a \"test\" folder each of which contain the folders of different patients. Eaof these folders are named with codes like \"00000\" , \"00001\", etc. Each of these folders contain 4 folders named as \"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\". Each of these contain the MRI scans taken via 4 different techniques which are the folder names. The data also contains a \"train_labels.csv\" file which has the subject code and the label \"1\" - \"presence of MGMT Biomarker\" and \"0\"-\"absence of MGMT Biomarker\". <\/p>\n\n![Screenshot from 2021-08-10 03-44-02.png](attachment:f74e60e0-1619-4574-8877-4d785db31bbf.png)","9e1a56e6":"<h2> Problem Description <\/h2>\n<p>A malignant tumor in the brain is a life-threatening condition. Known as glioblastoma, it's both the most common form of brain cancer in adults and the one with the worst prognosis, with median survival being less than a year. The presence of a specific genetic sequence in the tumor known as MGMT promoter methylation has been shown to be a favorable prognostic factor and a strong predictor of responsiveness to chemotherapy.<\/p>\n\n<p> Traditional medical approaches require biopsy and careful study of the tissue sample. Machine Learning approaches might help save thousands of lives. In this competition we are required to predict the presence of this BioMarker. For this purpose, we are provided with MRI scans of many diffee patients taken via 4 different methods : Fluid Attenuated Inversion Recovery (FLAIR) , T1-weighted pre-contrast (T1w) , T1-weighted post-contrast (T1Gd) , T2-weighted (T2). Along with these, we are prrvided with a csv file which contains the data about whether the biomarker is present in the individual or not.<\/p>\n\n<p>  So, this essentially boils down to a binary classification problem with the two classes being \"Biomarker Present\" , \"BioMarker Absent\". <\/p>\n\n![Screenshot from 2021-08-10 04-04-17.png](attachment:d51460d7-ae17-4ef9-9612-5568144085ea.png)","2e9ec47b":"<h2> Transfer Learning <\/h2>","9b63d3cd":"<h2> AlexNet <\/h2>\n<p>Alexnet was introduced in the paper <a class=\"reference external\" href=\"https:\/\/papers.nips.cc\/paper\/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\">ImageNet Classification with Deep\nConvolutional Neural\nNetworks<\/a>\nand was the first very successful CNN on the ImageNet dataset. When we\nprint the model architecture, we see the model output comes from the 6th\nlayer of the classifier.","1044f02d":"<h2> ResNet <\/h2>\n\n<p>Resnet was introduced in the paper <a class=\"reference external\" href=\"https:\/\/arxiv.org\/abs\/1512.03385\">Deep Residual Learning for Image\nRecognition<\/a>. There are several\nvariants of different sizes, including Resnet18, Resnet34, Resnet50,\nResnet101, and Resnet152, all of which are available from torchvision\nmodels. Here we use Resnet18 just for demonstration purpose. You can change the model by just changing \"resnet18\" to \"resnetxyz\" , xyz being the number.<\/p>\n"}}