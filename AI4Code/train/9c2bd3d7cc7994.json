{"cell_type":{"887bdae2":"code","3dba470f":"code","101b719a":"code","76376637":"code","e43df833":"code","e0b2651b":"code","83e27d7d":"code","92bb6964":"code","cb84776c":"markdown","7c4f87f9":"markdown","6e05f757":"markdown","19ba3f85":"markdown","665af055":"markdown","3b4f720a":"markdown","e54007b7":"markdown","70951f34":"markdown","4c0de30b":"markdown"},"source":{"887bdae2":"%pylab inline\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nprint(\"tensorflow\", tf.__version__)","3dba470f":"# Training settings\nbatch_size = 128\nimg_height = 128\nimg_width = 128","101b719a":"train_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/train'\ntest_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/test'\n\n# Training dataset\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  train_dir,\n  validation_split = 0.2,\n  subset = \"training\",\n  seed = 123,\n  image_size = (img_height, img_width),\n  batch_size = batch_size)\n\n# Validation dataset\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  train_dir,\n  validation_split = 0.2,\n  subset = \"validation\",\n  seed = 123,\n  image_size = (img_height, img_width),\n  batch_size = batch_size)\n\n# Test dataset\ntest_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  test_dir,\n  image_size = (img_height, img_width),\n  batch_size = batch_size)","76376637":"# Speeding up the data processing\nAUTOTUNE = tf.data.experimental.AUTOTUNE\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","e43df833":"model = Sequential([\n  layers.experimental.preprocessing.Rescaling(1.\/255, input_shape=(img_height, img_width, 3)),\n  layers.Conv2D(8, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(1, activation = 'sigmoid')\n])\n\nmodel.compile(loss = 'binary_crossentropy',\n              optimizer = optimizers.RMSprop(lr = 1e-4),\n              metrics = ['accuracy'])\n\nmodel.summary()","e0b2651b":"%%time\n\nN = 5\n\nhistory = model.fit(      \n      train_ds,\n      validation_data = val_ds,\n      verbose = 1, # FOR FINAL VERSION, CHANGE TO 0!\n      epochs = N\n      )\n\nprint('Batch size = ', batch_size)\n\n# Save the model\nmodel.save('case_2_run_kaggle.h5')","83e27d7d":"t1 = 5 # sec\nt2 = 1*60 + 52 # sec\nratio = t2\/t1\nprint(f'Speed up when changing from CPU to GPU processing = {ratio:.1f}')","92bb6964":"loss = history.history['loss']\nacc = history.history['accuracy']\nval_loss = history.history['val_loss']\nval_acc = history.history['val_accuracy']\nx = arange(len(loss)) + 1\n\nfigure(figsize(13, 5))\nsubplot(1, 2, 1)\nplot(x,loss, '*-', label = 'training')\nplot(x, val_loss, 'o-', label = 'validation')\ntitle('loss')\nylim(0, )\nlegend()\ngrid()\n\nsubplot(1, 2, 2)\nplot(x, acc, '*-', label = 'training')\nplot(x, val_acc, 'o-', label = 'validation')\ntitle('accuracy')\nylim(0.5, 1.0)\nlegend()\ngrid()","cb84776c":"### Comparison: with CPU\n```\nEpoch 1\/5\n33\/33 [==============================] - 23s 674ms\/step - loss: 0.5725 - accuracy: 0.7013 - val_loss: 0.4334 - val_accuracy: 0.7766\nEpoch 2\/5\n33\/33 [==============================] - 22s 679ms\/step - loss: 0.4430 - accuracy: 0.7843 - val_loss: 0.3753 - val_accuracy: 0.9118\nEpoch 3\/5\n33\/33 [==============================] - 22s 680ms\/step - loss: 0.3609 - accuracy: 0.8610 - val_loss: 0.3260 - val_accuracy: 0.9156\nEpoch 4\/5\n33\/33 [==============================] - 22s 669ms\/step - loss: 0.3084 - accuracy: 0.8745 - val_loss: 0.2324 - val_accuracy: 0.9233\nEpoch 5\/5\n33\/33 [==============================] - 22s 681ms\/step - loss: 0.2655 - accuracy: 0.8987 - val_loss: 0.2115 - val_accuracy: 0.9310\nBatch size =  128\nCPU times: user 5min 57s, sys: 34.2 s, total: 6min 32s\nWall time: 1min 52s\n```","7c4f87f9":"## Speed up","6e05f757":"## Training","19ba3f85":"# Case 2 with Kaggle\nNeural Networks for Machine Learning Applications<br>\n2.2.2022, Sakari Lukkarinen<br>\n[Information Technology](https:\/\/metropolia.fi\/en\/academics\/bachelors-degrees\/information-technology)<br>\n[Metropolia University of Applied Sciences](https:\/\/metropolia.fi\/en)\n\nThe basic structure of this solution is taken from Tensorflow > Learn > Tensorflow Core > Tutorials > [Image Classification](https:\/\/www.tensorflow.org\/tutorials\/images\/classification). See that for more detailed instructions.","665af055":"## Results","3b4f720a":"## Model","e54007b7":"### Comparison: with GPU\n```\nEpoch 1\/5\n33\/33 [==============================] - 2s 30ms\/step - loss: 0.5963 - accuracy: 0.7286 - val_loss: 0.4797 - val_accuracy: 0.7804\nEpoch 2\/5\n33\/33 [==============================] - 1s 21ms\/step - loss: 0.4667 - accuracy: 0.7639 - val_loss: 0.3327 - val_accuracy: 0.8274\nEpoch 3\/5\n33\/33 [==============================] - 1s 21ms\/step - loss: 0.3411 - accuracy: 0.8666 - val_loss: 0.2596 - val_accuracy: 0.9156\nEpoch 4\/5\n33\/33 [==============================] - 1s 21ms\/step - loss: 0.2654 - accuracy: 0.9092 - val_loss: 0.2007 - val_accuracy: 0.9358\nEpoch 5\/5\n33\/33 [==============================] - 1s 21ms\/step - loss: 0.2162 - accuracy: 0.9233 - val_loss: 0.1740 - val_accuracy: 0.9338\nBatch size =  128\nCPU times: user 4.39 s, sys: 143 ms, total: 4.53 s\nWall time: 4.69 s\n```","70951f34":"## Setup\n","4c0de30b":"## Dataset"}}