{"cell_type":{"cb335af6":"code","700701fe":"code","7782ea19":"code","3de6a082":"code","130f86b3":"code","05d793cc":"code","72ac9be7":"code","35ad15dd":"markdown","9489f58c":"markdown","3b22ffa5":"markdown","3eb68770":"markdown","f2a44173":"markdown","0f2f62a3":"markdown","9b87393e":"markdown","2a667182":"markdown","ed66cc5a":"markdown"},"source":{"cb335af6":"import numpy as np\nimport tensorflow as tf\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing import text, sequence\nfrom tensorflow.keras import layers, models","700701fe":"# Read the file\nfp = open('..\/input\/christmas-carol\/carol.txt','r')\ndata = fp.read().splitlines()        \nfp.close()\n\n# Encode the data\ntokens = text.Tokenizer()\ntokens.fit_on_texts(data)\ndata_sequences = tokens.texts_to_sequences(data)\nvocab_size = len(tokens.word_counts) + 1\n\n# generate the sequence\nseq_list = list()\nfor item in data_sequences:\n    l = len(item)\n    for id in range(1, l):\n        seq_list.append(item[: id+1])\n        \nmax_length = max([len(seq) for seq in seq_list])\ndata_sequences_matrix = sequence.pad_sequences(seq_list, maxlen = max_length, padding = 'pre')\ndata_sequences_matrix = np.array(data_sequences_matrix)\n\n# separate input data X and corresponding output y\nX = data_sequences_matrix[:, :-1]\ny = data_sequences_matrix[:, -1]\ny = to_categorical(y, num_classes = vocab_size)","7782ea19":"lstm_model = models.Sequential()\nlstm_model.add(layers.Input(shape = [max_length-1]))\nlstm_model.add(layers.Embedding(vocab_size, 10, input_length = max_length-1))\nlstm_model.add(layers.LSTM(50))\nlstm_model.add(layers.Dropout(0.1))               \nlstm_model.add(layers.Dense(vocab_size, activation = 'softmax'))\nlstm_model.summary()","3de6a082":"lstm_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\nhistory = lstm_model.fit(X, y, batch_size = 2, epochs = 50)","130f86b3":"lstm_model.save('.\/saved_model\/')","05d793cc":"idx2word = {v:k for k,v in tokens.word_index.items()}\nnew_model = models.load_model('.\/saved_model\/')\n\n# function to make predictions, it takes text as input and predict *num_words* possible after this text\ndef predict_words(text, num_words):\n    encoded_data = tokens.texts_to_sequences([text])[0]\n    padded_data = sequence.pad_sequences([encoded_data], maxlen = max_length - 1, padding = 'pre')\n    y_preds = new_model.predict(padded_data)\n    y_preds = np.argsort(-y_preds)\n    y_preds = y_preds[0][:num_words]\n    possible_words = [idx2word[item] for item in y_preds]\n    print(text, possible_words)","72ac9be7":"predict_words(\"how to\", 2)\npredict_words(\"find a\", 2)\npredict_words(\"Merry\", 2)\npredict_words(\"I am\", 2)\npredict_words(\"how\", 2)","35ad15dd":"# Next Word Prediction Model Using LSTM","9489f58c":"# Preprocessing Data\n* Load the data from the file. \n* Tokenize the data and convert the text to sequences.\n* Add padding to ensure that all the sequences have the same shape.\n* There are many ways of taking the *max_length* and here we choose maximum of all sequences as *max_length*.","3b22ffa5":"## Make Predictions","3eb68770":"# Import the necessary libraries","f2a44173":"## Save the model","0f2f62a3":"### RNN\nDefine the RNN structure.","9b87393e":"## Compile and Fit on the training data.","2a667182":"This program takes the carol.txt file as input dataset. The file contains story A Christmas Carol by Charles Dickens. The dataset can be downloaded from the link: https:\/\/www.gutenberg.org\/files\/46\/46-0.txt","ed66cc5a":"The objective of this program is to predict next word of given sentence using LSTM."}}