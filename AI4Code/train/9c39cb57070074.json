{"cell_type":{"f9c267bc":"code","6ed43992":"code","a2a6c17a":"code","802b5ed2":"code","25228313":"code","d8db45af":"code","a7b36520":"code","f1fb2081":"code","a3188807":"code","be6c39a8":"code","c7e78e9e":"code","aec3af4e":"code","a8d4b793":"code","48aac0ea":"code","ef83132f":"code","663215dc":"code","944005a7":"code","00b92aa4":"code","1d191cce":"code","b9cb489f":"code","c0c6cb59":"code","5062ded7":"code","9c7cbdaf":"code","4287b6fe":"code","244866c5":"code","9d3ef1fa":"code","e8e5d770":"code","f96a57e9":"code","dcd22205":"code","e5be8069":"code","04b06975":"code","3e4e0b1d":"code","3973aead":"code","4189a6ff":"code","40af59bc":"code","45fd9d45":"code","3177b8c9":"code","851112bc":"code","2b232b6c":"code","a030c299":"markdown","a8d95183":"markdown","d3d4e68d":"markdown","d52246c2":"markdown","ac249456":"markdown","bf5853da":"markdown","c8b0d54e":"markdown","bfa2360a":"markdown"},"source":{"f9c267bc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nimport cupy as cp\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom scipy import sparse\nfrom tqdm import tqdm_notebook as tqdm\n\nsns.set()\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","6ed43992":"df_train = pd.read_csv('..\/input\/train.csv', header=0)","a2a6c17a":"df_train.head()","802b5ed2":"fig, ax = plt.subplots(figsize=(14, 12))\nsns.boxplot(x='type', y='scalar_coupling_constant', data=df_train, ax=ax)\nplt.show()","25228313":"df_test = pd.read_csv('..\/input\/test.csv', header=0)\ndf_test.head()","d8db45af":"structures = pd.read_csv('..\/input\/structures.csv')","a7b36520":"structures.head()","f1fb2081":"atomic_radius = {'H':0.38, 'C':0.77, 'N':0.75, 'O':0.73, 'F':0.71} # Without fudge factor\n\nfudge_factor = 0.05\natomic_radius = {k:v + fudge_factor for k,v in atomic_radius.items()}\n\nelectronegativity = {'H':2.2, 'C':2.55, 'N':3.04, 'O':3.44, 'F':3.98}\n\n#structures = pd.read_csv(structures, dtype={'atom_index':np.int8})\n\natoms = structures['atom'].values\natoms_en = [electronegativity[x] for x in tqdm(atoms)]\natoms_rad = [atomic_radius[x] for x in tqdm(atoms)]\n\nstructures['EN'] = atoms_en\nstructures['rad'] = atoms_rad","a3188807":"structures.head()","be6c39a8":"i_atom = structures['atom_index'].values\np = structures[['x', 'y', 'z']].values\np_compare = p\nm = structures['molecule_name'].values\nm_compare = m\nr = structures['rad'].values\nr_compare = r\n\nsource_row = np.arange(len(structures))\nmax_atoms = 28\n\nbonds = np.zeros((len(structures)+1, max_atoms+1), dtype=np.int8)\nbond_dists = np.zeros((len(structures)+1, max_atoms+1), dtype=np.float32)\n\n\nfor i in tqdm(range(max_atoms-1)):\n    p_compare = np.roll(p_compare, -1, axis=0)\n    m_compare = np.roll(m_compare, -1, axis=0)\n    r_compare = np.roll(r_compare, -1, axis=0)\n    \n    mask = np.where(m == m_compare, 1, 0) #Are we still comparing atoms in the same molecule?\n    dists = np.linalg.norm(p - p_compare, axis=1) * mask\n    r_bond = r + r_compare\n    \n    bond = np.where(np.logical_and(dists > 0.0001, dists < r_bond), 1, 0)\n    \n    source_row = source_row\n    target_row = source_row + i + 1 #Note: Will be out of bounds of bonds array for some values of i\n    target_row = np.where(np.logical_or(target_row > len(structures), mask==0), len(structures), target_row) #If invalid target, write to dummy row\n    \n    source_atom = i_atom\n    target_atom = i_atom + i + 1 #Note: Will be out of bounds of bonds array for some values of i\n    target_atom = np.where(np.logical_or(target_atom > max_atoms, mask==0), max_atoms, target_atom) #If invalid target, write to dummy col\n    \n    bonds[(source_row, target_atom)] = bond\n    bonds[(target_row, source_atom)] = bond\n    bond_dists[(source_row, target_atom)] = dists\n    bond_dists[(target_row, source_atom)] = dists\n\nbonds = np.delete(bonds, axis=0, obj=-1) #Delete dummy row\nbonds = np.delete(bonds, axis=1, obj=-1) #Delete dummy col\nbond_dists = np.delete(bond_dists, axis=0, obj=-1) #Delete dummy row\nbond_dists = np.delete(bond_dists, axis=1, obj=-1) #Delete dummy col\n\n\nbonds_numeric = [[i for i,x in enumerate(row) if x] for row in tqdm(bonds)]\nbond_lengths = [[dist for i,dist in enumerate(row) if i in bonds_numeric[j]] for j,row in enumerate(tqdm(bond_dists))]\nbond_lengths_mean = [ np.mean(x) for x in bond_lengths]\nn_bonds = [len(x) for x in bonds_numeric]\n\nbond_data = {'n_bonds':n_bonds, 'bond_lengths_mean': bond_lengths_mean }\nbond_df = pd.DataFrame(bond_data)\nstructures = structures.join(bond_df)","c7e78e9e":"structures.head()","aec3af4e":"# https:\/\/stackoverflow.com\/questions\/20305272\/dihedral-torsion-angle-from-four-points-in-cartesian-coordinates-in-python\ndef dihedral_angle(data): \n        \n    vals = np.array(data[:, 3:6], dtype=np.float64)\n    mol_names = np.array(data[:, 0], dtype=np.str)\n \n    result = np.zeros((data.shape[0], 2), dtype=object)\n    # use every 4 rows to compute the dihedral angle\n    for idx in range(0, vals.shape[0] - 4, 4):\n\n        a0 = vals[idx]\n        a1 = vals[idx + 1]\n        a2 = vals[idx + 2]\n        a3 = vals[idx + 3]\n        \n        b0 = a0 - a1\n        b1 = a2 - a1\n        b2 = a3 - a2\n        \n        # normalize b1 so that it does not influence magnitude of vector\n        # rejections that come next\n        b1 \/= np.linalg.norm(b1)\n    \n        # vector rejections\n        # v = projection of b0 onto plane perpendicular to b1\n        #   = b0 minus component that aligns with b1\n        # w = projection of b2 onto plane perpendicular to b1\n        #   = b2 minus component that aligns with b1\n\n        v = b0 - np.dot(b0, b1) * b1\n        w = b2 - np.dot(b2, b1) * b1\n\n        # angle between v and w in a plane is the torsion angle\n        # v and w may not be normalized but that's fine since tan is y\/x\n        x = np.dot(v, w)\n        y = np.dot(np.cross(b1, v), w)\n       \n        # We want all 4 first rows for every molecule to have the same value\n        # (in order to have the same length as the dataframe)\n        result[idx:idx + 4] = [mol_names[idx], np.degrees(np.arctan2(y, x))]\n        \n    return result","a8d4b793":"from datetime import datetime\nstartTime = datetime.now()\ndihedral = dihedral_angle(structures[structures.groupby('molecule_name')['atom_index'].transform('count').ge(4)].groupby('molecule_name').head(4).values)\nprint('Time elapsed (hh:mm:ss.ms) {}'.format(datetime.now() - startTime))","48aac0ea":"themap = {k:v for k, v in dihedral if k}","ef83132f":"structures['dihedral'] = structures['molecule_name'].map(themap)","663215dc":"structures.head()","944005a7":"def map_atom_info(df, atom_idx):\n    df = pd.merge(df, structures, how = 'left',\n                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n                  right_on = ['molecule_name',  'atom_index'])\n    \n    df = df.drop('atom_index', axis=1)\n    df = df.rename(columns={'atom': f'atom_{atom_idx}',\n                            'x': f'x_{atom_idx}',\n                            'y': f'y_{atom_idx}',\n                            'z': f'z_{atom_idx}'})\n    return df","00b92aa4":"train = map_atom_info(df_train, 0)\ntrain = map_atom_info(train, 1)","1d191cce":"test = map_atom_info(df_test, 0)\ntest = map_atom_info(test, 1)","b9cb489f":"train.head()","c0c6cb59":"# Euclidean Distance\ndef dist(a, b, ax=1):\n    return cp.linalg.norm(a - b, axis=ax)","5062ded7":"train_atom_0 = cp.asarray(train[['x_0', 'y_0', 'z_0']].values)\ntrain_atom_1 = cp.asarray(train[['x_1', 'y_1', 'z_1']].values)\n\ntrain['distance'] = dist(train_atom_1, train_atom_0).get()\ntrain['dist_x'] = dist( cp.asarray(train[['x_0']].values),  cp.asarray(train[['x_1']].values)).get()\ntrain['dist_y'] = dist( cp.asarray(train[['y_0']].values),  cp.asarray(train[['y_1']].values)).get()\ntrain['dist_z'] = dist( cp.asarray(train[['z_0']].values),  cp.asarray(train[['z_1']].values)).get()","9c7cbdaf":"test_atom_0 = cp.asarray(test[['x_0', 'y_0', 'z_0']].values)\ntest_atom_1 = cp.asarray(test[['x_1', 'y_1', 'z_1']].values)\n\ntest['distance'] = dist(test_atom_1, test_atom_0).get()\ntest['dist_x'] = dist( cp.asarray(test[['x_0']].values),  cp.asarray(test[['x_1']].values)).get()\ntest['dist_y'] = dist( cp.asarray(test[['y_0']].values),  cp.asarray(test[['y_1']].values)).get()\ntest['dist_z'] = dist( cp.asarray(test[['z_0']].values),  cp.asarray(test[['z_1']].values)).get()","4287b6fe":"train.head()","244866c5":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","9d3ef1fa":"def create_features(df):\n    df['molecule_couples'] = df.groupby('molecule_name')['id'].transform('count')\n    df['molecule_dist_mean'] = df.groupby('molecule_name')['distance'].transform('mean')\n    df['molecule_dist_min'] = df.groupby('molecule_name')['distance'].transform('min')\n    df['molecule_dist_max'] = df.groupby('molecule_name')['distance'].transform('max')\n    df['atom_0_couples_count'] = df.groupby(['molecule_name', 'atom_index_0'])['id'].transform('count')\n    df['atom_1_couples_count'] = df.groupby(['molecule_name', 'atom_index_1'])['id'].transform('count')\n    \n    df[f'molecule_atom_index_0_x_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['x_1'].transform('std')\n    df[f'molecule_atom_index_0_y_1_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('mean')\n    df[f'molecule_atom_index_0_y_1_mean_diff'] = df[f'molecule_atom_index_0_y_1_mean'] - df['y_1']\n    #df[f'molecule_atom_index_0_y_1_mean_div'] = df[f'molecule_atom_index_0_y_1_mean'] \/ df['y_1']\n    #df[f'molecule_atom_index_0_y_1_max'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('max')\n    #df[f'molecule_atom_index_0_y_1_max_diff'] = df[f'molecule_atom_index_0_y_1_max'] - df['y_1']\n    df[f'molecule_atom_index_0_y_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('std')\n    df[f'molecule_atom_index_0_z_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['z_1'].transform('std')\n    df[f'molecule_atom_index_0_dist_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['distance'].transform('mean')\n    df[f'molecule_atom_index_0_dist_mean_diff'] = df[f'molecule_atom_index_0_dist_mean'] - df['distance']\n    #df[f'molecule_atom_index_0_dist_mean_div'] = df[f'molecule_atom_index_0_dist_mean'] \/ df['distance']\n    df[f'molecule_atom_index_0_dist_max'] = df.groupby(['molecule_name', 'atom_index_0'])['distance'].transform('max')\n    #df[f'molecule_atom_index_0_dist_max_diff'] = df[f'molecule_atom_index_0_dist_max'] - df['distance']\n    #df[f'molecule_atom_index_0_dist_max_div'] = df[f'molecule_atom_index_0_dist_max'] \/ df['distance']\n    df[f'molecule_atom_index_0_dist_min'] = df.groupby(['molecule_name', 'atom_index_0'])['distance'].transform('min')\n    #df[f'molecule_atom_index_0_dist_min_diff'] = df[f'molecule_atom_index_0_dist_min'] - df['distance']\n    df[f'molecule_atom_index_0_dist_min_div'] = df[f'molecule_atom_index_0_dist_min'] \/ df['distance']\n    df[f'molecule_atom_index_0_dist_std'] = df.groupby(['molecule_name', 'atom_index_0'])['distance'].transform('std')\n    #df[f'molecule_atom_index_0_dist_std_diff'] = df[f'molecule_atom_index_0_dist_std'] - df['distance']\n    #df[f'molecule_atom_index_0_dist_std_div'] = df[f'molecule_atom_index_0_dist_std'] \/ df['distance']\n    df[f'molecule_atom_index_1_dist_mean'] = df.groupby(['molecule_name', 'atom_index_1'])['distance'].transform('mean')\n    #df[f'molecule_atom_index_1_dist_mean_diff'] = df[f'molecule_atom_index_1_dist_mean'] - df['distance']\n    df[f'molecule_atom_index_1_dist_mean_div'] = df[f'molecule_atom_index_1_dist_mean'] \/ df['distance']\n    df[f'molecule_atom_index_1_dist_max'] = df.groupby(['molecule_name', 'atom_index_1'])['distance'].transform('max')\n    #df[f'molecule_atom_index_1_dist_max_diff'] = df[f'molecule_atom_index_1_dist_max'] - df['distance']\n    #df[f'molecule_atom_index_1_dist_max_div'] = df[f'molecule_atom_index_1_dist_max'] \/ df['distance']\n    df[f'molecule_atom_index_1_dist_min'] = df.groupby(['molecule_name', 'atom_index_1'])['distance'].transform('min')\n    #df[f'molecule_atom_index_1_dist_min_diff'] = df[f'molecule_atom_index_1_dist_min'] - df['distance']\n    #df[f'molecule_atom_index_1_dist_min_div'] = df[f'molecule_atom_index_1_dist_min'] \/ df['distance']\n    df[f'molecule_atom_index_1_dist_std'] = df.groupby(['molecule_name', 'atom_index_1'])['distance'].transform('std')\n    #df[f'molecule_atom_index_1_dist_std_diff'] = df[f'molecule_atom_index_1_dist_std'] - df['distance']\n    df[f'molecule_atom_index_1_dist_std_div'] = df[f'molecule_atom_index_1_dist_std'] \/ df['distance']\n    df[f'molecule_atom_1_dist_mean'] = df.groupby(['molecule_name', 'atom_1'])['distance'].transform('mean')\n    df[f'molecule_atom_1_dist_min'] = df.groupby(['molecule_name', 'atom_1'])['distance'].transform('min')\n    df[f'molecule_atom_1_dist_min_diff'] = df[f'molecule_atom_1_dist_min'] - df['distance']\n    df[f'molecule_atom_1_dist_min_div'] = df[f'molecule_atom_1_dist_min'] \/ df['distance']\n    df[f'molecule_atom_1_dist_std'] = df.groupby(['molecule_name', 'atom_1'])['distance'].transform('std')\n    df[f'molecule_atom_1_dist_std_diff'] = df[f'molecule_atom_1_dist_std'] - df['distance']\n    df[f'molecule_type_dist_mean'] = df.groupby(['molecule_name', 'type'])['distance'].transform('mean')\n    df[f'molecule_type_dist_mean_diff'] = df[f'molecule_type_dist_mean'] - df['distance']\n    #df[f'molecule_type_dist_mean_div'] = df[f'molecule_type_dist_mean'] \/ df['distance']\n    df[f'molecule_type_dist_max'] = df.groupby(['molecule_name', 'type'])['distance'].transform('max')\n    df[f'molecule_type_dist_min'] = df.groupby(['molecule_name', 'type'])['distance'].transform('min')\n    df[f'molecule_type_dist_std'] = df.groupby(['molecule_name', 'type'])['distance'].transform('std')\n    df[f'molecule_type_dist_std_diff'] = df[f'molecule_type_dist_std'] - df['distance']\n\n    df = reduce_mem_usage(df)\n    return df","e8e5d770":"train = create_features(train)\ntest = create_features(test)","f96a57e9":"train.head()","dcd22205":"for i in ['atom_0', 'atom_1', 'type']:\n    class_le = LabelEncoder()   \n    train[i] = class_le.fit_transform(train[i].values)\n    test[i] = class_le.fit_transform(test[i].values)","e5be8069":"cols = [\n\n'id',\n'atom_index_0', \n'atom_index_1', \n'type', \n'atom_0',\n'EN_x',\n'rad_x',\n'n_bonds_x',\n'bond_lengths_mean_x',\n'x_0', \n'y_0', \n'z_0', \n'dihedral_x',\n'atom_1',\n'EN_y',\n'rad_y',\n'n_bonds_y',\n'bond_lengths_mean_y',\n'x_1', \n'y_1', \n'z_1', \n'dihedral_y',\n'distance',\n'dist_x', \n'dist_y', \n'dist_z',\n'molecule_atom_index_0_dist_min',\n'molecule_atom_index_0_dist_max',\n'molecule_atom_index_1_dist_min',\n'molecule_atom_index_0_dist_mean',\n'molecule_atom_index_0_dist_std',\n'molecule_atom_index_1_dist_std',\n'molecule_atom_index_1_dist_max',\n'molecule_atom_index_1_dist_mean',\n#'molecule_atom_index_0_dist_max_diff',\n#'molecule_atom_index_0_dist_max_div',\n#'molecule_atom_index_0_dist_std_diff',\n#'molecule_atom_index_0_dist_std_div',\n'atom_0_couples_count',\n'molecule_atom_index_0_dist_min_div',\n#'molecule_atom_index_1_dist_std_diff',\n#'molecule_atom_index_0_dist_mean_div',\n'atom_1_couples_count',\n'molecule_atom_index_0_dist_mean_diff',\n'molecule_couples',\n'molecule_dist_mean',\n#'molecule_atom_index_1_dist_max_diff',\n'molecule_atom_index_0_y_1_std',\n#'molecule_atom_index_1_dist_mean_diff',\n'molecule_atom_index_1_dist_std_div',\n'molecule_atom_index_1_dist_mean_div',\n#'molecule_atom_index_1_dist_min_diff',\n#'molecule_atom_index_1_dist_min_div',\n#'molecule_atom_index_1_dist_max_div',\n'molecule_atom_index_0_z_1_std',\n'molecule_type_dist_std_diff',\n'molecule_atom_1_dist_min_diff',\n'molecule_atom_index_0_x_1_std',\n'molecule_dist_min',\n#'molecule_atom_index_0_dist_min_diff',\n'molecule_atom_index_0_y_1_mean_diff',\n'molecule_type_dist_min',\n'molecule_atom_1_dist_min_div',\n'molecule_dist_max',\n'molecule_atom_1_dist_std_diff',\n'molecule_type_dist_max',\n#'molecule_atom_index_0_y_1_max_diff',\n'molecule_type_dist_mean_diff',\n'molecule_atom_1_dist_mean',\n#'molecule_atom_index_0_y_1_mean_div',\n#'molecule_type_dist_mean_div'\n]","04b06975":"def data(df):\n    X_train, X_val, y_train, y_val  = train_test_split(df[cols].values,\n                                                       df.loc[:, 'scalar_coupling_constant'].values,\n                                                       test_size=0.2,\n                                                       random_state=1340)\n        \n    return X_train, X_val, y_train, y_val","3e4e0b1d":"X_test = test[cols].values","3973aead":"num_boost_round = 4000\nearly_stopping_rounds = 200\nverbose_eval = 200\n\nX_train, X_val, y_train, y_val = data(train)","4189a6ff":"lgb_train = lgb.Dataset(X_train, y_train)\nlgb_val = lgb.Dataset(X_val, y_val)\nevals_result = {}\n\nparams = {\n            'boosting_type': 'gbdt',\n            'objective': 'regression',\n            'metric': 'mae',\n            'learning_rate': 0.2,\n            'num_leaves': 900, \n            'reg_alpha': 0.5, \n            'reg_lambda': 0.5, \n            'nthread': 4, \n            'device': 'cpu',\n            'min_child_samples': 45\n        }","40af59bc":"model = lgb.train(params,\n                  lgb_train,\n                  num_boost_round=num_boost_round,\n                  valid_sets=[lgb_val],\n                  early_stopping_rounds=early_stopping_rounds, \n                  evals_result=evals_result, \n                  verbose_eval=verbose_eval)","45fd9d45":"#model.save_model('model.txt', num_iteration=model.best_iteration)","3177b8c9":"preds = model.predict(X_test, num_iteration=model.best_iteration)","851112bc":"def submit(predictions):\n    submit = pd.read_csv('..\/input\/sample_submission.csv')\n    submit[\"scalar_coupling_constant\"] = predictions\n    submit.to_csv(\"submission.csv\", index=False)","2b232b6c":"submit(preds)","a030c299":"### Create some features\n\n(https:\/\/www.kaggle.com\/artgor\/brute-force-feature-engineering)","a8d95183":"#### In this kernel, I mostly use ideas from other kernels. I have added a dihedral angle calculation which gives some boost.\n\n(I updated the kernel regarding the calculations for the dihedral angle. In previous kernel, even though I was using GPU, the use of pandas apply\nfunction was removing any advantage of GPU, so it was not fast. Now, I refactored the code and it the calcuation is fast without using any GPU.)","d3d4e68d":"We can see that if we want we can divide by type:\n\n1st: 1JHC\n\n2nd: 1JHN\n\n3rd: 2JHC, 2JHN, 3JHH, 3JHN, 3JHC\n\n4th: 2JHH","d52246c2":"### Train model","ac249456":"### Compute some distances","bf5853da":"### Bond calculations\n\n(Thanks to https:\/\/www.kaggle.com\/adrianoavelar\/bond-calculation-lb-0-82?scriptVersionId=15911797)","c8b0d54e":"We can see that for every molecule we leave the same value for the dihedral angle.","bfa2360a":"### Dihedral angle\n\nWe are going to compute the dihedral angle. This angle is derived from the first 4 atoms in the molecule.\n\nThe calculations are done on the GPU by using cupy package."}}