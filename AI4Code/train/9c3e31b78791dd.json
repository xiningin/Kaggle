{"cell_type":{"b54bbf17":"code","d064b83b":"code","7be10a85":"code","3da75953":"code","4b4f8220":"code","5882fa0d":"code","039cdf13":"code","d6b08f1b":"code","c6fbabc5":"code","1288f925":"code","c25d6480":"code","c1c467bc":"markdown","89c956d5":"markdown","974241f8":"markdown","8a74070e":"markdown","0df82eea":"markdown","44119725":"markdown","67c48b10":"markdown","c69f1204":"markdown","eabe3db0":"markdown"},"source":{"b54bbf17":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d064b83b":"import numpy as np\nimport pandas as pd\n\ndata = pd.read_csv(\"\/kaggle\/input\/lowryp\/3.csv\")\ndata2 = pd.read_csv(\"\/kaggle\/input\/lebron\/lbj.csv\")\n\npts = data[[\"Season\", \"PTS\"]]\nlj = data2[[\"Season\", \"PTS\"]]\ndisplay(lj.tail())\ndisplay(pts.tail())","7be10a85":"import matplotlib.pyplot as plt\n%matplotlib inline\n\npts['Rolling_Mean'] = pts['PTS'].rolling(window = 2).mean()\nlj['Rolling_Mean'] = lj['PTS'].rolling(window = 2).mean()\n\nfig = plt.figure(figsize=(15,10))\nax1 = fig.add_subplot(111)\nax1.scatter(lj[\"Season\"], lj[\"PTS\"], c=\"blue\", label = \"Lebron\")\nax1.scatter(pts[\"Season\"], pts[\"PTS\"], c=\"red\", label= \"Lowry\")\nplt.plot(pts[\"Season\"], pts[\"Rolling_Mean\"], c=\"red\")\nplt.plot(lj[\"Season\"], lj[\"Rolling_Mean\"], c=\"blue\")\nplt.legend(loc='lower right')\n\nplt.title('PPG v.s Season for Lebron & Lowry (Rolling Mean)')\nplt.xlabel('Season')\nplt.ylabel('PPG')\nplt.show()","3da75953":"from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n\nfit1 = SimpleExpSmoothing(lj[\"PTS\"]).fit(smoothing_level=0.5,optimized=True)\nfcast1 = fit1.forecast(5)\n\nfig = plt.figure(figsize=(15,10))\nax1 = fig.add_subplot(111)\nax1.scatter(lj[\"Season\"], lj[\"PTS\"], c=\"blue\", label = \"Lebron\")\nax1.scatter(pts[\"Season\"], pts[\"PTS\"], c=\"red\", label= \"Lowry\")\nplt.plot(pts[\"Season\"], pts[\"Rolling_Mean\"], c=\"red\")\nplt.plot(lj[\"Season\"], lj[\"Rolling_Mean\"], c=\"blue\")\nfcast1.plot(marker='o', color='purple', legend=True)\nplt.legend(loc='lower right')\n\nplt.title('PPG v.s Season for Lebron & Lowry (Exponential Smoothing)')\nplt.xlabel('Season')\nplt.ylabel('PPG')\nplt.show()","4b4f8220":"from pylab import *\nfrom sklearn.metrics import r2_score\n\nxp = np.linspace(1, 17, 17)\nz = np.linspace(1, 16, 16)\np4_lebron = np.poly1d(np.polyfit(xp, lj[\"PTS\"], 5))\np4_lowry = np.poly1d(np.polyfit(z, pts[\"PTS\"], 5))\n\n\nfig = plt.figure(figsize=(15,10))\nax1 = fig.add_subplot(111)\nax1.scatter(lj[\"Season\"], lj[\"PTS\"], c=\"blue\", label = \"Lebron\")\nax1.scatter(pts[\"Season\"], pts[\"PTS\"], c=\"red\", label= \"Lowry\")\nplt.plot(xp, p4_lebron(xp), c='blue')\nplt.plot(z, p4_lowry(z), c='red')\nplt.legend(loc='lower right')\n\nplt.title('PPG v.s Season for Lebron & Lowry (Polynomial Regression)')\nplt.xlabel('Season')\nplt.ylabel('PPG')\nplt.show()\n\nr2_lebron = r2_score(lj[\"PTS\"], p4_lebron(xp))\nr2_lowry = r2_score(pts[\"PTS\"], p4_lowry(z))\n\nprint(\"R-Squared error for Lebron & Lowry fits respectively:\")\nprint(r2_lebron)\nprint(r2_lowry)\n","5882fa0d":"optimal_n = None\nbest_mse = None\ndb = lj[['PTS']].values.astype('float32')\nmean_results_for_all_possible_n_values = np.zeros(int(len(db) \/ 2 - 2))\nfor n in range(3, int(len(db) \/ 2 + 1)):\n    mean_for_n = np.zeros(len(db) - n)\n    for i in range(0, len(db) - n):\n        mean_for_n[i] = np.power(np.mean(db[:, 0][i:i+n]) - db[i + n][0], 2)\n    mean_results_for_all_possible_n_values[n - 3] = np.mean(mean_for_n)\noptimal_n = np.argmin(mean_results_for_all_possible_n_values) + 3\nbest_mse = np.min(mean_results_for_all_possible_n_values)\nprint(\"MSE = %s\" % mean_results_for_all_possible_n_values)\nprint(\"Best MSE = %s\" % best_mse)\nprint(\"Optimal n = %s\" % optimal_n)\n\nprint(\"MA = %s\" % np.mean(db[:, 0][len(db) - optimal_n:len(db)]))\n\nforecast = np.zeros(len(db) + 1)\nfor i in range(0, optimal_n):\n    forecast[i] = db[i][0]\nfor i in range(0, len(db) - optimal_n + 1):\n        forecast[i+optimal_n] = np.mean(db[:, 0][i:i+optimal_n])\nplt.plot(db[:, 0],label = 'real data: LBJ', c=\"blue\")\nplt.plot(forecast, label = 'forecast', c=\"purple\")\nplt.title('PPG v.s Season for Lebron (Moving Average)' )\nplt.legend()\nplt.show()\n","039cdf13":"optimal_n = None\nbest_mse = None\ndb = pts[['PTS']].values.astype('float32')\n\nmean_results_for_all_possible_n_values = np.zeros(int(len(db) \/ 2 - 2))\nfor n in range(3, int(len(db) \/ 2 + 1)):\n    mean_for_n = np.zeros(len(db) - n)\n    for i in range(0, len(db) - n):\n        mean_for_n[i] = np.power(np.mean(db[:, 0][i:i+n]) - db[i + n][0], 2)\n    mean_results_for_all_possible_n_values[n - 3] = np.mean(mean_for_n)\noptimal_n = np.argmin(mean_results_for_all_possible_n_values) + 3\nbest_mse = np.min(mean_results_for_all_possible_n_values)\nprint(\"MSE = %s\" % mean_results_for_all_possible_n_values)\nprint(\"Best MSE = %s\" % best_mse)\nprint(\"Optimal n = %s\" % optimal_n)\nprint(\"MA = %s\" % np.mean(db[:, 0][len(db) - optimal_n:len(db)]))\n\nforecast = np.zeros(len(db) + 1)\nfor i in range(0, optimal_n):\n    forecast[i] = db[i][0]\nfor i in range(0, len(db) - optimal_n + 1):\n        forecast[i+optimal_n] = np.mean(db[:, 0][i:i+optimal_n])\nplt.plot(db[:, 0],label = 'real data: Lowry', c=\"red\")\nplt.plot(forecast, label = 'forecast', c=\"orange\")\nplt.title('PPG v.s Season for Lowry (Moving Average)')\n\nplt.legend()\nplt.show()","d6b08f1b":"!pip install pmdarima","c6fbabc5":"import pmdarima as pm\n\nmodel = pm.auto_arima(lj[\"PTS\"],\n                        start_p=1, start_q=1,\n                        test='adf',      \n                        max_p=3, max_q=3, \n                        m=1,              \n                        d=None,           \n                        seasonal=False, \n                        start_P=0, D=0, trace=True, \n                        error_action='ignore', suppress_warnings=True, \n                        stepwise=True)\n\nforecast = model.predict(n_periods=5) \n\nforecast = pd.DataFrame(forecast,columns=[\"PTS\"])\ntotal = lj.append(forecast, ignore_index=False)\nx = np.linspace(1, len(lj)+5,len(lj)+5 )\n\nprint(\"Forecast of PPG for Lebron for the next 5 seasons:\" )\nprint(forecast)\n\nfig = plt.figure(figsize=(15,10))\nax1 = fig.add_subplot(111)\nax1.scatter(lj[\"Season\"], lj[\"PTS\"], c=\"blue\", label = \"Real data\")\nplt.plot(lj[\"Season\"], lj[\"Rolling_Mean\"], c=\"purple\", linestyle='dashed', label = \"Rolling Mean\")\nplt.plot(x, total[\"PTS\"], c=\"green\", label = \"ARIMA\")\nplt.legend(loc='lower right')\nplt.title('PPG v.s Season for Lebron (ARIMA)')\nplt.xlabel('Season')\nplt.ylabel('PPG')\nplt.show()","1288f925":"from statsmodels.tsa.arima_model import ARIMA\nfrom matplotlib import pyplot\n\nxp = np.linspace(1, 17, 17)\ny = lj[\"PTS\"]\n\nmodel = ARIMA(y, order=(5,2,0))\n#ORDER: p,d,q\n#sets the lag value to 5 for autoregression, \n#uses a difference order of 2 to make the time series stationary, \n#and uses a moving average model of 0.\nmodel_fit = model.fit(disp=1)\nprint(model_fit.summary())\n\nresiduals = pd.DataFrame(model_fit.resid)\nresiduals.plot()\n\nresiduals.plot(kind='kde')\nprint(residuals.describe())","c25d6480":"%matplotlib inline\n\nlog_e = np.log(np.sqrt(np.log(pts[[\"PTS\"]])))\npts[[\"PTS\"]] = log_e\npts['Rolling_Mean'] = pts['PTS'].rolling(window = 2).mean()\n\n\nlog_d = np.log(np.log(lj[[\"PTS\"]]))\nlj[[\"PTS\"]] = log_d\nlj['Rolling_Mean'] = lj['PTS'].rolling(window = 2).mean()\n\nfig = plt.figure(figsize=(15,10))\nax1 = fig.add_subplot(111)\nax1.scatter(lj[\"Season\"], lj[\"PTS\"], c=\"blue\", label = \"Lebron (log)\")\nax1.scatter(pts[\"Season\"], pts[\"PTS\"], c=\"red\", label= \"Lowry (sqrt)\")\nplt.plot(pts[\"Season\"], pts[\"Rolling_Mean\"], c=\"red\")\nplt.plot(lj[\"Season\"], lj[\"Rolling_Mean\"], c=\"blue\")\nplt.legend(loc='lower right')\n\nplt.title('PPG v.s Season for Lebron & Lowry')\nplt.xlabel('Season')\nplt.ylabel('PPG')\nplt.show()","c1c467bc":"Polynomial regression (order = 5) ","89c956d5":"Poorly fitted model (Exponential smoothing). Output is hidden (click to reveal)","974241f8":"Rolling Mean Forecasting","8a74070e":"In this notebook I'm working more on projecting PPG for Lowry and Lebron James based on their seasons in the NBA. I will attempt to forecast the data using a number of different time series techniques. ","0df82eea":"Do the same for Lowry","44119725":"Also: transforming the data using log & square root functions to reduce variability ","67c48b10":"Residuals for the above model:","c69f1204":"Auto ARIMA model. Forecasting PPG for Lebron's next 5 seasons.","eabe3db0":"Moving Average Forecasting"}}