{"cell_type":{"64347b6d":"code","e4056423":"code","c15cc31e":"code","b7f253d5":"code","ccb790dd":"code","5160f73a":"code","fa43cfc6":"code","e1c50d1d":"code","3051a561":"code","17f5e1ee":"code","fe5998e6":"code","1cbf24a6":"code","b7db67e1":"code","401bed01":"code","1379d8de":"code","e0240c77":"code","58d18dec":"code","949db0a8":"code","2bc87fa6":"code","14071973":"code","5c4f008e":"code","c64b186d":"code","6de2e4d5":"code","42b122f9":"code","4d282b72":"code","78c1a46d":"markdown","2ce8ae69":"markdown","d2936d73":"markdown","438dc9b5":"markdown","4d5252ac":"markdown","40a8fbba":"markdown","d29c642a":"markdown","272871c7":"markdown","a72b787f":"markdown","f35a4e30":"markdown","b4ce4fc5":"markdown","00e3ace5":"markdown","d3d6861e":"markdown","a83204e8":"markdown","dfc7dd43":"markdown","723c9ab6":"markdown","c8dbdf40":"markdown","f290e134":"markdown"},"source":{"64347b6d":"import pandas as pd\nimport numpy as np","e4056423":"train_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest_data = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\n\ntrain_data.head()","c15cc31e":"y_train = train_data['label']\nx_train = train_data.drop(['label'], axis=1)\n\ndel train_data","b7f253d5":"import seaborn as sns\n\nsns.set(style='white', context='notebook', palette='Paired')\n\nsns.countplot(y_train)\n\ny_train.value_counts()","ccb790dd":"x_train.isnull().any().describe()","5160f73a":"test_data.isnull().any().describe()","fa43cfc6":"x_train = x_train \/ 255.0\ntest_data = test_data \/ 255.0\n\nx_train.head()","e1c50d1d":"x_train = x_train.values.reshape(-1, 28 , 28, 1)\ntest_data = test_data.values.reshape(-1, 28 , 28, 1)","3051a561":"test_data.shape","17f5e1ee":"x_train.shape","fe5998e6":"from keras.utils.np_utils import to_categorical\n\ny_train = to_categorical(y_train, num_classes = 10)","1cbf24a6":"y_train[0]","b7db67e1":"from sklearn.model_selection import train_test_split\n\nrandom_seed = 4\n\nx, x_val, y, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=random_seed)","401bed01":"import matplotlib.pyplot as plt\n\n# Some examples\nplt.figure(figsize=(10, 10))\n\nfor i in range(6):  \n    plt.subplot(3, 3, i+1)\n    plt.imshow(x[i][:,:,0])\n    ","1379d8de":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import plot_model\nfrom keras.applications.xception import Xception\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint","e0240c77":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))\n\nmodel.summary()","58d18dec":"plot_model(model, show_shapes=True)","949db0a8":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","2bc87fa6":"filepath = '.\/model-ep{epoch:02d}-acc{val_accuracy:.3f}.h5'\ncallbacks = [   \n             ReduceLROnPlateau(monitor='val_acc', \n                                patience=3, \n                                verbose=1, \n                                factor=0.5, \n                                min_lr=0.00001),          \n            ModelCheckpoint(filepath= filepath, save_best_only = True, monitor='val_loss', mode='min')\n            ]","14071973":"EPOCHS = 20\n\nhistory = model.fit(x,  \n                    y,              \n                    verbose = 1,            \n                    epochs = EPOCHS, \n                    validation_data=(x_val, y_val),\n                   callbacks = callbacks)","5c4f008e":"plt.plot(history.history['loss'], color='r')\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epochs')\nplt.legend(['training', 'validation'], loc='upper right')\nplt.show()","c64b186d":"rows = 5\ncols = 5\n\nplt.figure(figsize=(10,10))\nfor index in range(rows*cols):\n    img = test_data[index].reshape(1, 28, 28, 1)\n    pred = np.argmax(model.predict(img))\n    plt.subplot(rows, cols, index+1)\n    plt.imshow(test_data[index][:,:,0])\n    plt.xlabel('Predicted : {}'.format(pred))\n\nplt.tight_layout()\nplt.show()","6de2e4d5":"%%time\n\nresults =[]\nfor index in range(28000):\n    img = test_data[index].reshape(1, 28, 28, 1)\n    pred = np.argmax(model.predict(img))\n    results.append(pred)","42b122f9":"submission = pd.DataFrame()\nsubmission['ImageId'] = [i for i in range(1, 28001)]\nsubmission['Label'] = results","4d282b72":"submission.to_csv('submission.csv', index=False)","78c1a46d":"# Handle null values or missing values ","2ce8ae69":"The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n\nThe training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n\nEach pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).","d2936d73":"# Plot the validation loss and training loss","438dc9b5":"# Load the data","4d5252ac":"# Separate the label and features ","40a8fbba":"From the plotting, it is clear that the data is balanced, hence we can proceed further.","d29c642a":"# Normalization","272871c7":"No null values or missing values, hence move on..","a72b787f":"# Encode the y_train (labels) ","f35a4e30":"# Submission","b4ce4fc5":"# Model Architecture ","00e3ace5":"# Split the data into training and validation sets","d3d6861e":"# Reshaping\n\nconverting images from 1D vector to 3D vector of shape (28 , 28, 1), where the 3rd dimension shows the color (channel) RGB. MNIST images are grayscale thats why we are taking it as 1.","a83204e8":"# Plot the data","dfc7dd43":"Normalization is an important step while training deep learning model. The model converges faster. Dividing by 255 is called grayscale normalization which helps in reducing the effect of illumination difference among various images.","723c9ab6":"ReduceLROnPlateau reduces overfitting, it simply reduces the learning rate by a factor of 0.5 (i.e. half) whenever there is no improvement in the monitored value (here, validation accuracy) after three (patience) epochs.\n\nModelCheckpoint saves the model whenever it sees the monitored value (here, validation loss) is minimum (mode) than the previous model.","c8dbdf40":"# Evaluate the model \n\nTest the model's performance on test dataset. I am using the highest accuracy model (last model) rather than the low validation loss model.","f290e134":"This Notebook trains a deep learning model using CNN (Convolutional Neural Network) to recognize MNIST digits from 0 to 9."}}