{"cell_type":{"3be8f0f9":"code","b5536795":"code","d3c1e8ee":"code","0c82b3a7":"code","97a7e227":"code","9409f3c8":"code","714fcb2f":"code","700d9511":"code","f36a9b02":"code","4fdc94de":"code","6d6109a5":"code","581e0799":"code","5557e31d":"code","a5968286":"code","dbaabc4c":"code","e16998b8":"code","4414b85f":"code","f1094824":"code","b5fb5f31":"code","b188800b":"code","ec444ad2":"code","342c6d0f":"code","872160ba":"code","ca784924":"code","835fde3a":"code","310793e2":"code","a6b22fd9":"code","d11139f0":"code","58255811":"code","870dd5cd":"code","3e0fc759":"code","f5f8b39e":"code","2f546b26":"code","407f5a3e":"code","b498feed":"code","03d51b28":"code","352b9c3e":"code","5f638418":"code","ab98f926":"code","c82a0f78":"code","cfd62f90":"code","c5db0c44":"code","fb57890c":"code","e73fd3f9":"code","f4d4edd3":"code","c815461b":"code","13010d15":"code","0a76fda8":"code","05aedf7f":"code","78c0b76a":"code","9a8abcdf":"code","d29fe147":"code","906abe59":"code","97035bae":"code","5c0dedac":"code","9dd4c824":"code","44bb693a":"code","ae49f836":"code","3278f32a":"code","31b9d34c":"code","0cfe9973":"code","3c60cc2d":"code","34a0ba35":"code","a5358303":"markdown","a6083996":"markdown"},"source":{"3be8f0f9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b5536795":"data=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndata","d3c1e8ee":"data.Embarked.unique()\ndata['Embarked_s']=data['Embarked'].replace('Q',0).replace('C',0).replace('S',1)\ndata['Embarked_c']=data['Embarked'].replace('S',0).replace('Q',0).replace('C',1)\ndata['Embarked_q']=data['Embarked'].replace('C',0).replace('S',0).replace('Q',1)","0c82b3a7":"#data.Sex= data.Sex.map( {'M': 1, 'F': 0, 'O': 3} )\ndata['Sex'].replace( 'female', 0, inplace=True )\ndata['Sex'].replace( 'male', 1, inplace=True )\ndata","97a7e227":"#data=data[data.Embarked!=0]\n#data=data[data[('Embarked')].map(data['Embarked'].value_counts())>0]*\n#data","9409f3c8":"data.isnull().sum()","714fcb2f":"#data.Sex=data.Sex.fillna(0)\n#data.Age=data.Age.fillna(0)\n#data.Cabin=data.Cabin.fillna(0)\n#data.Embarked_s=data.Embarked_s.fillna(0)\n#data.Embarked_c=data.Embarked_c.fillna(0)\n#data.Embarked_q=data.Embarked_q.fillna(0)","700d9511":"data['Survived']","f36a9b02":"data.isnull().sum()","4fdc94de":"data.dtypes","6d6109a5":"x = data.drop(columns = ['Survived','Ticket','Cabin','PassengerId','Name','Embarked'])","581e0799":"y = data[['Survived']]","5557e31d":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25)","a5968286":"x.head()","dbaabc4c":"x.dtypes","e16998b8":"x","4414b85f":"x.Embarked_q.unique()","f1094824":"nom_cols =[]\nord_cols = []\nnum_cols=[0,4,5]\nnull_cols=[1,2,6,7,8]\n#Kbin_cols=[0,1,4],\nbinarizer_cols=[3]","b5fb5f31":"from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder,KBinsDiscretizer,Binarizer\nfrom sklearn.impute import SimpleImputer,KNNImputer\nfrom sklearn.compose import make_column_transformer\nfrom sklearn import set_config\nfrom sklearn.preprocessing import StandardScaler\n\ntrans = make_column_transformer((OneHotEncoder(sparse=False),nom_cols),\n                                (KNNImputer(n_neighbors=45),null_cols),\n                                (OrdinalEncoder(), ord_cols),(StandardScaler(),num_cols)\n                                 ,(Binarizer(threshold=55),binarizer_cols),remainder= 'passthrough')\nset_config(display= 'diagram')\ntrans\n#trans = make_column_transformer((OneHotEncoder(sparse=False),nom_cols),(SimpleImputer(strategy='mean'),null_cols),\n                                 #(OrdinalEncoder(), ord_cols),(StandardScaler(),num_cols),(KBinsDiscretizer(),Kbins_cols)\n                                 #,(Binarizer(threshold=55),binarizer_cols),remainder= 'passthrough')\n#set_config(display= 'diagram')\n#trans","b188800b":"from sklearn.tree import DecisionTreeClassifier \nalgorithm_x=DecisionTreeClassifier(criterion='entropy')","ec444ad2":"from sklearn.neighbors import KNeighborsClassifier\nalgorithm = KNeighborsClassifier(15) #\nalgorithm","342c6d0f":"from sklearn.pipeline import make_pipeline\npipe = make_pipeline(trans,algorithm)\npipe_x=make_pipeline(trans,algorithm_x)\npipe","872160ba":"pipe_x","ca784924":"pipe.fit(x_train,y_train)","835fde3a":"pipe_x.fit(x_train,y_train)","310793e2":"pred_x=pipe_x.predict(x_test)\npred_x","a6b22fd9":"from sklearn.metrics import accuracy_score, plot_confusion_matrix\naccuracy_score(pred_x,y_test)*100","d11139f0":"pred=pipe.predict(x_test)\npred","58255811":"from sklearn.metrics import accuracy_score, plot_confusion_matrix\naccuracy_score(pred,y_test)*100","870dd5cd":"import matplotlib as plt \nplot_confusion_matrix(pipe,x_test,y_test)","3e0fc759":"from imblearn.over_sampling import RandomOverSampler\nover= RandomOverSampler()\no_x , o_y = over.fit_resample(x,y)\no_y.value_counts()","f5f8b39e":"from imblearn.over_sampling import SMOTE\nover= RandomOverSampler()\n_x , o_y = over.fit_resample(x,y)\no_y.value_counts()","2f546b26":"from imblearn.pipeline import make_pipeline\ns = SMOTE()\nn_pipe = make_pipeline(trans,s,algorithm)\nn_pipe","407f5a3e":"accuracy_score(pred,y_test)*100","b498feed":"from sklearn.linear_model import LogisticRegression as lr\nalgorithm_2 = lr(solver='liblinear')\npipe_2 = make_pipeline(trans,algorithm_2)\npipe_2","03d51b28":"pipe_2.fit(x_train,y_train)","352b9c3e":"pred_2 = pipe_2.predict(x_test)\npred_2","5f638418":"accuracy_score(pred_2,y_test)*100","ab98f926":"from sklearn.model_selection import KFold, cross_val_score,StratifiedKFold\nkf=StratifiedKFold(n_splits=4)\nnp.mean(cross_val_score(pipe,x,y,cv=kf,scoring='accuracy')*100)","c82a0f78":"from sklearn.svm import SVC\nmodel1=SVC(kernel='linear')\npipe_1 = make_pipeline(trans,algorithm)\npipe_1\npipe_1.fit(x_train,y_train)\npred_1=pipe.predict(x_test)\naccuracy_score(pred_1,y_test)*100","cfd62f90":"from sklearn.ensemble import BaggingClassifier\nmodel2=BaggingClassifier(base_estimator=SVC(3))\nmodel2","c5db0c44":"y_test.shape","fb57890c":"pipe5=make_pipeline(trans,model2)\npipe5","e73fd3f9":"pipe5.fit(x_train,y_train)\npred5=pipe5.predict(x_test)","f4d4edd3":"pred5.shape","c815461b":"accuracy_score(pred5,y_test)*100","13010d15":"data1=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndata1","0a76fda8":"data1['Sex'].replace( 'female', 0, inplace=True )\ndata1['Sex'].replace( 'male', 1, inplace=True )","05aedf7f":"data1.isnull().sum()","78c0b76a":"#data1.Age=data1.Age.fillna(0)\ndata1.Cabin=data1.Cabin.fillna(0)\ndata1.Fare=data1.Fare.fillna(0)","9a8abcdf":"data1.isnull().sum()","d29fe147":"#data1=data1[data1.Embarked!=0]\n#data1=data1[data1[('Embarked')].map(data1['Embarked'].value_counts())>0]\n#data1","906abe59":"#data1.loc[data1['Sex']=='male']=1\n#data1.loc[data1['Sex']=='female']=0","97035bae":"data1['Embarked_s']=data1['Embarked'].replace('Q',0).replace('C',0).replace('S',1)\ndata1['Embarked_c']=data1['Embarked'].replace('S',0).replace('Q',0).replace('C',1)\ndata1['Embarked_q']=data1['Embarked'].replace('C',0).replace('S',0).replace('Q',1)","5c0dedac":"data1.head()","9dd4c824":"x1 = data1.drop(columns = ['Ticket','Cabin','PassengerId','Name','Embarked'])\nx1","44bb693a":"x1.isnull().sum()","ae49f836":"from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder,KBinsDiscretizer,Binarizer\nfrom sklearn.impute import SimpleImputer,KNNImputer\nfrom sklearn.compose import make_column_transformer\nfrom sklearn import set_config\nfrom sklearn.preprocessing import StandardScaler\n\ntrans = make_column_transformer((OneHotEncoder(sparse=False),nom_cols),\n                                (KNNImputer(n_neighbors=45),null_cols),\n                                (OrdinalEncoder(), ord_cols),(StandardScaler(),num_cols)\n                                 ,(Binarizer(threshold=55),binarizer_cols),remainder= 'passthrough')\nset_config(display= 'diagram')\ntrans","3278f32a":"pred123=pipe_x.predict(x1)\npred123","31b9d34c":"#survival_prediction=algorithm.predict(x1)\n#survival_prediction","0cfe9973":"submit=pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","3c60cc2d":"submit['Survived']=pred123\nsubmit.to_csv('submission.csv', index=False)","34a0ba35":"submit.Survived.value_counts()","a5358303":"**2. Replace the values in 'Embarked' column and make separate values for each of the following values it contains in that column\nNote : We are converting strings into int to prevent further errors that would occur in the followig steps .**","a6083996":"**If you want to remove 0 value in 'Embarked' column then simply run the code given below and get the required data .**"}}