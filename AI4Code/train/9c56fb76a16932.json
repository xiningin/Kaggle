{"cell_type":{"f3806bfc":"code","3ace3c67":"code","dfbb03fe":"code","b4ccfb10":"code","cf8c0efe":"code","af3aa65a":"code","a5d098d5":"code","bcbf8caf":"code","0af52954":"code","4e95a7c5":"code","72df2fd8":"code","fc106318":"code","aa902214":"code","9d99fd73":"code","6c4e1350":"code","18fdc1f7":"code","f1802196":"code","2f98da42":"code","bfa3607e":"code","68015919":"code","e574dfda":"code","ee645d7d":"code","34fc98ff":"code","9939153c":"code","4e73fb47":"code","74a37cde":"code","c94428e0":"code","89ad3f24":"code","825a0c92":"code","534f5440":"code","427c2034":"code","9271444e":"code","75b24338":"code","8c5e99cf":"code","80300386":"code","4be4e415":"code","d400fa93":"code","8fadbdba":"code","237eeb31":"code","3c656bf9":"code","62de2b08":"code","adab457e":"code","e5da936b":"code","f2fd7512":"code","14475289":"code","96334ada":"code","03a880a3":"code","5d7f3b6e":"code","c9ef2946":"code","454a29e0":"code","2719147b":"code","5a07b034":"code","a5aa3638":"code","77f20f90":"code","f1a200f9":"code","1652a5de":"code","93f4b71a":"code","0cb7bb0d":"code","3d2d6cf0":"code","2a63c3e8":"code","8497ddaf":"code","be90a8de":"code","0bb28ebc":"code","b9d0d868":"code","c43b072d":"code","9da20198":"code","dde3beab":"code","9815ae28":"code","6e2731f8":"code","79ceab78":"code","a17f0ee0":"code","cbd837da":"code","0915f6f1":"code","e656587e":"code","826e3e5f":"code","a0dd4d19":"markdown","157285a5":"markdown","2cea9da0":"markdown","6dc7e71a":"markdown","ad6927a9":"markdown","9b3d1bdd":"markdown","ee1f782e":"markdown","9453cbb3":"markdown","1505c053":"markdown","7e72a4f3":"markdown","6b3d71a7":"markdown","25a5ac6f":"markdown","7ae7de1b":"markdown","5007e7d6":"markdown","30af159d":"markdown","c751b196":"markdown","2bc9a698":"markdown","f92ef712":"markdown"},"source":{"f3806bfc":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n#import torch\n#from torch import nn, optim\nimport seaborn as sns\nfrom pathlib import Path\nimport PIL\nimport json\nimport gc\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.impute import KNNImputer","3ace3c67":"# Read data\ntrain = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/test.csv')\nsample_sub  = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/sample_submission.csv') \ntrain.shape,test.shape","dfbb03fe":"numcols = train._get_numeric_data().columns\ncatcols = list(set(train.columns) - set(numcols))\ntarget = 'Survived'","b4ccfb10":"for col in train.columns:\n    print(col, \" Missing Data Count: \",train[col].isnull().sum())","cf8c0efe":"train['Survived'].value_counts().plot(kind = 'barh',color=\"gray\")","af3aa65a":"data = pd.concat([train,test])","a5d098d5":"train.shape,test.shape, data.shape","bcbf8caf":"plt.hist(data['Age'], edgecolor = 'w',color=\"gray\", bins = 25)\nplt.title('Age'); \nplt.xlabel('Age (years)'); \nplt.ylabel('Count',);","0af52954":"# Mean of the data in test ad train sets\ntest['Age'].mean(),train['Age'].mean()","4e95a7c5":"# The mean age in the test data is lower then the test data. Lets examine the corelation of the Age with Survival.","72df2fd8":"plt.figure(figsize = (10, 8))\nsns.kdeplot(train.loc[train['Survived'] == 0, 'Age'] , label = 'Survived == 0',color=\"gray\",)\nsns.kdeplot(train.loc[train['Survived'] == 1, 'Age'] , label = 'Survived == 1',color=\"red\",)\nplt.xlabel('Age (years)'); plt.ylabel('Survived Density'); \nplt.title('Distribution of Ages');","fc106318":"# It appears that the 20 to 40 age group has differnt densities of survivors.","aa902214":"# lets look at the age of passengers in differnt classes","9d99fd73":"data['Age'] = data.groupby(['Pclass','Sex'])['Age'].apply(lambda x: x.fillna(x.median())).reset_index()['Age']","6c4e1350":"#Lets first bin the ages\ndata.loc[ data['Age'] <= 11, 'Age_bin'] = 0\ndata.loc[(data['Age'] > 11) & (data['Age'] <= 18), 'Age_bin'] = 1\ndata.loc[(data['Age'] > 18) & (data['Age'] <= 22), 'Age_bin'] = 2\ndata.loc[(data['Age'] > 22) & (data['Age'] <= 27), 'Age_bin'] = 3\ndata.loc[(data['Age'] > 27) & (data['Age'] <= 33), 'Age_bin'] = 4\ndata.loc[(data['Age'] > 33) & (data['Age'] <= 40), 'Age_bin'] = 5\ndata.loc[(data['Age'] > 40) & (data['Age'] <= 66), 'Age_bin'] = 6\ndata.loc[ data['Age'] > 66, 'Age_bin'] = 6\n\n# let's see how it's distributed \ndata['Age_bin'].value_counts().plot(color=\"gray\",kind='barh')","18fdc1f7":"data[\"RANK\"] = data.groupby(\"Age\")['Age'].rank(method=\"first\", ascending=True)\ndata[\"RANK_avg\"] = data.groupby(\"Age\")['Age'].rank(method=\"average\", ascending=True)\ndata[\"RANK_max\"] = data.groupby(\"Age\")['Age'].rank(method=\"max\", ascending=True)\ndata[\"RANK_min\"] = data.groupby(\"Age\")['Age'].rank(method=\"min\", ascending=True)","f1802196":"data['AgeBin2']=pd.cut(data['Age'],[-np.inf, 50, np.inf], right=False, labels = ['below 50', 'above 50']).astype(str)","2f98da42":"data","bfa3607e":"plt.figure(figsize = (10, 8))\nsns.countplot(x='Pclass',hue='Age_bin',data=data,\n              palette=sns.color_palette(\"icefire\"))","68015919":"train.Sex.value_counts()","e574dfda":"# It will be preffered to impute the missing age data by the median of their Classes","ee645d7d":"imputer = SimpleImputer(missing_values=np.NaN, strategy='most_frequent')\ndata['Ticket'] = imputer.fit_transform(data['Ticket'].values.reshape(-1,1))[:,0]","34fc98ff":"#Referenced https:\/\/www.kaggle.com\/dwin183287\/tps-april-2021-models-feature-enginering\n    \ndata['TicketCode'] = data['Ticket'].str.replace('[^\\w\\s]','')\ndata['TicketCode'] = data['TicketCode'].str.replace(' ','')\ndata['TicketCode'] = data['TicketCode'].fillna('NA')\n\ndata['TicketNumber'] = data['Ticket'].str.extract('(\\d+)')\ndata['TicketNumber'] = data['TicketNumber'].astype(float)\ndata['TicketNumber'] = data['TicketNumber'].fillna(0)","9939153c":"data['Embarked'].value_counts().sort_values().plot(kind = 'barh',color=\"gray\")","4e73fb47":"data['Embarked'].fillna(data['Embarked'].mode()[0], inplace = True)","74a37cde":"# sns.countplot(x='Survived',hue='Cabin',data=data,\n#               palette=sns.color_palette(\"icefire\"))","c94428e0":"imputer = SimpleImputer(missing_values=np.NaN, strategy='most_frequent')\ndata['Cabin'] = imputer.fit_transform(data['Cabin'].values.reshape(-1,1))[:,0]","89ad3f24":"data['Pclass'].value_counts().sort_values().plot(kind = 'barh',color=\"gray\")","825a0c92":"sns.countplot(x='Survived',hue='Pclass',data=data,\n              palette=sns.color_palette(\"icefire\"))","534f5440":"plt.figure(figsize = (10, 8))\nsns.kdeplot(train.loc[train['Survived'] == 0, 'Fare'] , label = 'Survived == 0',color=\"gray\",)\nsns.kdeplot(train.loc[train['Survived'] == 1, 'Fare'] , label = 'Survived == 1',color=\"red\",)\nplt.xlabel('Fare'); plt.ylabel('Survived Density'); \nplt.title('Distribution of Fare');","427c2034":"imputer = SimpleImputer(missing_values=np.NaN, strategy='median')\ndata['Fare'] = imputer.fit_transform(data['Fare'].values.reshape(-1,1))[:,0]","9271444e":"for col in train.columns:\n    print(col, \" Missing Data Count: \",data[col].isnull().sum())","75b24338":"data['FamilySize'] = data['SibSp'] + data['Parch'] + 1","8c5e99cf":"data['Fare'] = data['Fare'].round()","80300386":"lblFare = ['Low_fare','median_fare','Average_fare','high_fare']\ndata['Fare_bin'] = pd.cut(data['Fare'], bins=4,labels=lblFare).value_counts()","4be4e415":"data['Age_Class']= data['Age'] * data['Pclass']","d400fa93":"data['Fare_Per_Person'] = data['Fare']\/(data['FamilySize'])\ndata['Fare_Per_Person'] = data['Fare_Per_Person'].astype(int)","8fadbdba":"def strDeck(strcabin):\n    deck_list = ['A', 'B', 'C', 'D', 'E', 'F', 'T', 'G', 'Unknown']\n    res = list(filter(lambda x:  x in strcabin, deck_list))\n    return str(res[0])","237eeb31":"cabin_list = ['A', 'B', 'C', 'D', 'E', 'F', 'T', 'G', 'Unknown']\ndata['Deck']=data['Cabin'].map(lambda x: strDeck(x))","3c656bf9":"train = data.loc[~data.Survived.isnull()]\ntest = data.loc[data.Survived.isnull()]","62de2b08":"# g = sns.pairplot(data=train, hue='Survived', palette = 'seismic',\n#                  size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\n# g.set(xticklabels=[])","adab457e":"sns.heatmap(train.corr(),annot=True, vmin=0.3, vmax=0.7,linewidths=0.3) \nfig=plt.gcf()\nfig.set_size_inches(25,12)\nplt.show()","e5da936b":"encoder=ce.TargetEncoder(cols=['Age_bin','Sex','Deck','Embarked']) \n#Fit and Transform Train Data\n#encoder.fit_transform(data['class'],data['Marks'])\ndata[['Age_bin','Sex','Deck','Embarked']] = encoder.fit_transform(data[['Age_bin','Sex','Deck','Embarked']],data[target])","f2fd7512":"train = data.loc[~data.Survived.isnull()]\ntest = data.loc[data.Survived.isnull()]","14475289":"# LABEL ENCODE\ndef encode_LE(col,train,test):\n    df_comb = pd.concat([train[col],test[col]],axis=0)\n    df_comb,_ = df_comb.factorize(sort=True)\n    \n    train[col] = df_comb[:len(train)].astype('int16')\n    test[col] = df_comb[len(train):].astype('int16')\n    del df_comb; \n    gc.collect()\n    print(col,', ',end='')\n\n    \n# FREQ ENCODE\ndef encode_FE(df1, df2, cols):\n    for col in cols:\n        df = pd.concat([df1[col],df2[col]])\n        col_dict = df.value_counts(dropna=True, normalize=True).to_dict()\n        col_dict[-1] = -1\n        colname = col+'_FE'\n        df1[colname] = df1[col].map(col_dict)\n        df1[colname] = df1[colname].astype('float32')\n        \n        df2[colname] = df2[col].map(col_dict)\n        df2[colname] = df2[colname].astype('float32')\n        print(colname,', ',end='')","96334ada":"data.columns","03a880a3":"encode_FE(train,test,['Cabin','Ticket'])\nencode_LE('Sex',train,test)\nencode_LE('Deck',train,test)","5d7f3b6e":"import category_encoders as ce\nencoder= ce.OrdinalEncoder(cols=['AgeBin2'],return_df=True,\n                           mapping=[{'col':'AgeBin2','mapping':{'below 50':1,'above 50':2}}])\ntrain = encoder.fit_transform(train)\ntest = encoder.fit_transform(test)","c9ef2946":"ncoder = ce.sum_coding.SumEncoder(cols=[\"Sex\",\"Age_bin\",\"Embarked\",\"Fare_bin\"],verbose=False,)","454a29e0":"train = ncoder.fit_transform(train)\ntest = ncoder.fit_transform(test)","2719147b":"# train = pd.get_dummies(train, columns = [\"Sex\",\"Age_bin\",\"Embarked\",\"Fare_bin\"],\n#                              prefix=[\"Sex\",\"Age_bin\",\"Em_type\",\"Fare_type\"])","5a07b034":"# test = pd.get_dummies(test, columns = [\"Sex\",\"Age_bin\",\"Embarked\",\"Fare_bin\"],\n#                              prefix=[\"Sex\",\"Age_bin\",\"Em_type\",\"Fare_type\"])","a5aa3638":"train.columns","77f20f90":"## Extra features - Reference - https:\/\/www.kaggle.com\/subinium\/how-to-use-pycaret-with-feature-engineering\ndef converter(x):\n    c, n = '', ''\n    x = str(x).replace('.', '').replace('\/','').replace(' ', '')\n    for i in x:\n        if i.isnumeric():\n            n += i\n        else :\n            c += i \n    if n != '':\n        return c, int(n)\n    return c, np.nan\n    \ndef create_extra_features(data):\n    data['Ticket_type'] = data['Ticket'].map(lambda x: converter(x)[0])\n    #data['Ticket_number'] = data['Ticket'].map(lambda x: converter(x)[1])\n    \n    data['Cabin_type'] = data['Cabin'].map(lambda x: converter(x)[0])\n    data['Cabin_number'] = data['Cabin'].map(lambda x: converter(x)[1])\n    data['Name1'] = data['Name'].map(lambda x: x.split(', ')[0])    \n    data['Name2'] = data['Name'].map(lambda x: x.split(', ')[1])\n    data['isAlone'] = data['FamilySize'].apply(lambda x : 1 if x == 1 else 0)\n    \n    return data\n\ntrain = create_extra_features(train)\ntest = create_extra_features(test)","f1a200f9":"from category_encoders.cat_boost import CatBoostEncoder\n\nce = CatBoostEncoder()\n\ncolumn_name = ['Ticket_type', 'Cabin_type', 'Name1', 'Name2','TicketCode']\ntrain[column_name] = ce.fit_transform(train[column_name], train['Survived'])\ntest[column_name] = ce.transform(test[column_name])","1652a5de":"# train['TicketCode'] = ce.fit_transform(train['TicketCode'], train['Survived'])\n# test['TicketCode'] = ce.transform(test['TicketCode'])","93f4b71a":"usecols = list(train.columns.values)","0cb7bb0d":"usecols.remove('PassengerId')\nusecols.remove('Name')\nusecols.remove('Cabin')\nusecols.remove('Ticket')\nusecols.remove('Survived')\nusecols.remove('intercept')","3d2d6cf0":"#usecols.remove('intercept')\nusecols.remove('Age_bin_0')\nusecols.remove( 'Age_bin_1')\nusecols.remove( 'Age_bin_2')\nusecols.remove( 'Age_bin_3')\nusecols.remove('Age_bin_4')\nusecols.remove('Age_bin_5')\n# usecols.remove('RANK')\n# usecols.remove('RANK_avg')\n# usecols.remove('RANK_max')\n# usecols.remove('RANK_min')\nusecols.remove('TicketCode')","2a63c3e8":"list(usecols)","8497ddaf":"# %%time\n# from sklearn.model_selection import GridSearchCV\n# from sklearn.model_selection import KFold,StratifiedKFold\n# kfold=StratifiedKFold(n_splits=5,shuffle=True,random_state=2021)\n# model = lgb.LGBMClassifier(objective='binary',\n#                             metric='auc')\n\n# param_grid = {\n#               'boosting' : [\"gbdt\"],\n#               'n_estimators' : [300,500],\n#               'learning_rate': [0.1,0.01],\n#               'max_depth': [4, 8],\n#               'num_leaves': [100,150],\n#               'feature_fraction': [0.3, 0.1,0.6], \n#               'bagging_fraction' : [0.65,0.25],\n#                'min_child_samples': [20,150],\n#               'reg_alpha' : [0.1,0.5],\n#               'reg_lambda' : [0.25,0.40],\n#               }\n\n# modelf = GridSearchCV(model,param_grid = param_grid, cv=kfold, \n#                       scoring=\"accuracy\", n_jobs= 4, verbose = 2)\n\n# modelf.fit(train[usecols],train[target])\n\n# # Best score\n# modelf.best_score_\n\n# # Best Estimator\n# modelf.best_estimator_","be90a8de":"params = {}\nparams[\"objective\"] = \"binary\"\nparams[\"boosting\"] = \"gbdt\"\nparams['metric']= \"AUC\",\n\nparams[\"max_depth\"] = 45\nparams[\"min_data_in_leaf\"] = 1\nparams[\"min_child_samples\"] = 100\nparams[\"colsample_bytree\"] = 0.18\nparams[\"subsample\"] = 0.013\n\nparams[\"cat_l2\"] =  22\nparams[\"max_bin\"] =  33\nparams[\"min_data_per_group\"] =  90\n\nparams[\"reg_alpha\"] =  0.003\nparams[\"reg_lambda\"] = 8.97\nparams[\"learning_rate\"] = 0.002\nparams[\"bagging_fraction\"] = 0.65\nparams[\"feature_fraction\"] = 0.65\nparams[\"num_leaves\"] = 20   #50\nparams[\"n_estimators\"] = 1000\n#params[\"cat_smooth\"] = 60\nparams[\"nthread\"] =  4\nparams[\"verbosity\"] = -1\nparams['early_stopping_rounds'] = 500\nnum_rounds = 1000","0bb28ebc":"%%time\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\ncv_scores = []\npred_test_full = 0\nooflgb = np.zeros(train.shape[0])\npredictionslgb= np.zeros(test.shape[0])\n\nfold=StratifiedKFold(n_splits=5,shuffle=True,random_state=2021)\ni=1\n\nfor dev_index, val_index in fold.split(train[usecols],train[target]):    \n\n    dev_X, val_X = train[usecols].loc[dev_index,:], train[usecols].loc[val_index,:]\n    dev_y, val_y = train[target][dev_index], train[target][val_index]\n    \n    lgtrain = lgb.Dataset(dev_X, label=dev_y)\n    lgtest = lgb.Dataset(val_X, label=val_y)\n    model = lgb.train(params, lgtrain, num_rounds,\n                          valid_sets=[lgtest], early_stopping_rounds=300, verbose_eval=50)\n    \n    pred_val  = model.predict(val_X, num_iteration=model.best_iteration)\n    pred_test = model.predict(test[usecols], num_iteration=model.best_iteration)\n      \n    ooflgb[val_index] = pred_val\n    predictionslgb += pred_test\n    \npredictionslgb \/= 5.","b9d0d868":"from sklearn.metrics import accuracy_score, f1_score\ndef get_best_thresholds(true, preds):\n    thresholds = [i\/100 for i in range(100)]\n    best_thresholds = []\n    \n    f1_scores = [f1_score(true, (preds > thresh) * 1, average='micro') for thresh in thresholds]\n    best_thresh = thresholds[np.argmax(f1_scores)]\n    best_thresholds.append(best_thresh)\n    return best_thresholds","c43b072d":"#['Pclass','Embarked','Cabin','Ticket',]","9da20198":"train.Pclass = train.Pclass.astype('category')\ntrain.Cabin = train.Cabin.astype('category')\ntrain.Ticket = train.Ticket.astype('category')\n\ntest.Pclass = test.Pclass.astype('category')\ntest.Cabin = test.Cabin.astype('category')\ntest.Ticket = test.Ticket.astype('category')\n","dde3beab":"X= train[usecols + ['Cabin']]\ny= train[target]","9815ae28":"len(usecols),len(X.columns)","6e2731f8":"%%time\nfrom sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score\nfrom catboost import CatBoostClassifier\n\n\ncategorical_features_indices = np.where(X.dtypes =='category')[0]\ncategorical_features_indices\noofcat = np.zeros(X.shape[0])\n\nerrcb=[]\ny_pred_totcb=[]\ny_pred_totcb = 0 \n\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfold=StratifiedKFold(n_splits=5,shuffle=True,random_state=2021)\ni=1\nfor train_index, test_index in fold.split(X,y):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    m=CatBoostClassifier(n_estimators=50000,random_state=2021,\n                         eval_metric='Accuracy',max_depth=6,min_data_in_leaf=3,\n                         max_ctr_complexity=5,\n                         learning_rate=0.04,\n                         l2_leaf_reg=10,cat_features=categorical_features_indices,\n                         od_wait=500,od_type='Iter',\n                         bagging_temperature=0.80,random_strength=100,\n                         use_best_model=True)\n    \n    m.fit(X_train,y_train,eval_set=[(X_test, y_test)], early_stopping_rounds=100,verbose=100)\n    \n    oofcat[test_index] = m.predict_proba(X_test)[:,-1]\n    #preds=m.predict(X_test)[:,-1]\n\n    p = m.predict_proba(test[usecols + ['Cabin']])[:,-1]\n    \n    y_pred_totcb += p\n\ny_pred_totcb = y_pred_totcb\/5 ","79ceab78":"oof = (ooflgb + oofcat)\/2","a17f0ee0":"from sklearn.metrics import accuracy_score, f1_score\nbest_thresholds = get_best_thresholds(train[target].values, ooflgb)\noof[:] = (oof[:] > best_thresholds) * 1\nf1_score(train[target], oof, average='micro')","cbd837da":"ypred = y_pred_totcb * 0.80 + predictionslgb * 0.20","0915f6f1":"ypred = (ypred[:] > best_thresholds) * 1","e656587e":"sample_sub[target] = ypred\nsample_sub.to_csv('submission_blendcatandlgb1.csv',index=False)","826e3e5f":"ypred1 = (predictionslgb[:] > 0.50) * 1\nsample_sub[target] = ypred1\nsample_sub.to_csv('submission.csv',index=False) # 0.79385","a0dd4d19":"### Modelling","157285a5":"### Class","2cea9da0":"The distribution of data in both classes of the target variables seems reasonable.","6dc7e71a":"## Imputing Missing Data","ad6927a9":"#data.drop(['Age_Sex_ratio'], axis = 1,inplace=True)","9b3d1bdd":"### Feature Corelation","ee1f782e":"### Ticket","9453cbb3":"### **TITANIC EDA and Model**  - Public Leader Board 0.79385","1505c053":"### Embarked","7e72a4f3":"## Feature Engineering","6b3d71a7":"### Cabin","25a5ac6f":"### Please upvote if you find this helpful...","7ae7de1b":"### Pair Plots","5007e7d6":"### Fare","30af159d":"### Read the data","c751b196":"### Encode Categorical Variables","2bc9a698":"### Age","f92ef712":"Age, Ticket, Fare, Cabin and Embarked features missing data need to be imputed. "}}