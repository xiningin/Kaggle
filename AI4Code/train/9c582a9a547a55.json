{"cell_type":{"d6ea1574":"code","b009b0eb":"code","3f865846":"code","ec106c3a":"code","94dfa253":"code","8d0d4762":"code","97da99b6":"code","015a4bc3":"code","83f3d857":"code","2c2950ae":"code","5fa31299":"code","e2b25b02":"code","39266db9":"code","473d2829":"code","758938be":"code","7ea1568d":"code","ba7e4252":"code","6b270fc4":"code","a3e778c8":"code","ddc476f0":"code","63f41ac3":"code","88e5bedf":"code","10de6b00":"code","5a292212":"code","2a882809":"code","70a3989b":"code","9afaddc0":"code","1678b198":"code","38758a40":"code","7992d9bf":"code","635ee078":"code","5ea71d1f":"code","a28ab983":"code","4c81d6f2":"code","15ab6007":"code","42c53b96":"code","e8bb65af":"code","df72e6ce":"code","d6264f7f":"code","827b0b3e":"code","122eadc2":"code","7a1fb45b":"code","86b1fc5b":"code","6a61d8aa":"code","e479ef2c":"code","5a649e1c":"code","d2134b54":"code","c3da3ae2":"code","1dfc4e8f":"code","77da7e1a":"code","d30390c9":"code","cbebe23a":"code","176c687b":"code","90bda236":"code","baed41f7":"code","40aa0bcc":"code","460a258d":"code","a812178e":"code","a8185bc2":"code","c568674f":"code","315a31db":"code","4348d116":"code","87884fe3":"code","4406f34a":"code","899fcd3a":"code","4da36a4a":"code","65b2b344":"code","d2d5b731":"code","be6edb50":"code","b8a13a42":"code","24351552":"code","9703416c":"code","116b9ecb":"code","2404f1fb":"code","d0698928":"code","4851861e":"code","0f4f1d3c":"code","f42fb4d7":"code","3e41f3d5":"code","14be95a0":"code","16d60cc8":"code","ffb0b446":"code","e157b284":"code","2bd608ae":"code","0a2109b0":"code","09961294":"code","23acc38e":"code","aa91bf13":"code","cb23752d":"code","6f6a5795":"code","9d7db716":"code","f5145f35":"code","41d58155":"code","9389e9bb":"code","7da1b20d":"code","606261d6":"code","d3431dd4":"markdown","66684396":"markdown","26868bb6":"markdown","d9baf12a":"markdown","2f34e08e":"markdown","c9016295":"markdown","b2dbad76":"markdown","51a64996":"markdown","43f3174e":"markdown","f44ecaca":"markdown","c892619f":"markdown","509804a7":"markdown","3252521c":"markdown","f6ce2c32":"markdown","73a92e3d":"markdown","1be24e0f":"markdown","574be4e9":"markdown","67a9f1ef":"markdown","7a9ba62b":"markdown","b6146ac4":"markdown","810b91d1":"markdown","babfc2ab":"markdown","59c1bf7d":"markdown","d563f28e":"markdown","fa5f9e20":"markdown","0bc4904b":"markdown","67cc79a4":"markdown","f03b4008":"markdown","4a3e608d":"markdown","48daefb1":"markdown","987def59":"markdown","c8fd1052":"markdown","06ba71b8":"markdown","1b0d01b6":"markdown","2c7ce87e":"markdown","530c819f":"markdown","44781e30":"markdown","79d1bf4f":"markdown"},"source":{"d6ea1574":"import pandas as pd\nimport numpy as np\nimport os\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import plot_confusion_matrix, classification_report","b009b0eb":"pd.set_option('display.max_columns', None)\nSEED = 12345","3f865846":"train_df = pd.read_csv('..\/input\/mobile-price-classification\/train.csv')\ntest_df = pd.read_csv('..\/input\/mobile-price-classification\/test.csv')","ec106c3a":"train_df.shape, train_df.columns","94dfa253":"test_df.shape, test_df.columns","8d0d4762":"train_df.dtypes","97da99b6":"train_df.sample(5)","015a4bc3":"FEATURES = ['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n        'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n        'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n        'touch_screen', 'wifi']\n\nCAT_FEATURES = ['n_cores', 'blue', 'dual_sim', 'four_g', 'three_g', 'touch_screen', 'wifi']\n\nCONT_FEATURES = [col for col in FEATURES if col not in CAT_FEATURES]\n\nDEP_VARS = ['price_range']","83f3d857":"train_df['n_cores'].unique()","2c2950ae":"train_df['n_cores'].nunique()","5fa31299":"train_df[CAT_FEATURES].head()","e2b25b02":"# Categorical variables for train data\ncat_encoding_dict = {}\nfor col in CAT_FEATURES:\n    label_enc = LabelEncoder()\n    train_df[col] = label_enc.fit_transform(train_df[col])\n    cat_encoding_dict[col] = label_enc","39266db9":"# Categorical variables for test data\nfor col in CAT_FEATURES:\n    test_df[col] = cat_encoding_dict[col].transform(test_df[col])","473d2829":"cat_encoding_dict['n_cores'].classes_","758938be":"train_df[CAT_FEATURES].head()","7ea1568d":"train_df[CONT_FEATURES].head()","ba7e4252":"# Continuous Scaling\nstandard_enc = StandardScaler()\ntrain_df[CONT_FEATURES] = standard_enc.fit_transform(train_df[CONT_FEATURES])","6b270fc4":"train_df[CONT_FEATURES].head()","a3e778c8":"standard_enc.mean_, standard_enc.scale_, standard_enc.var_","ddc476f0":"# Continous scaling for test data\ntest_df[CONT_FEATURES] = standard_enc.transform(test_df[CONT_FEATURES])","63f41ac3":"train_df.head()","88e5bedf":"train_df[DEP_VARS].value_counts() # balanced and properly label encoded","10de6b00":"X_train, X_val, y_train, y_val = train_test_split(train_df[FEATURES].values,\n                                                    train_df[DEP_VARS[0]].values,\n                                                    test_size=0.2,\n                                                    random_state=SEED)","5a292212":"{\n    \"X_train\":X_train.shape,\n    \"X_val\":X_val.shape,\n    \"y_train\":y_train.shape,\n    \"y_val\":y_val.shape\n}","2a882809":"lm = LogisticRegression(multi_class='ovr', solver='liblinear')\nlm.fit(X_train, y_train)","70a3989b":"lm.coef_","9afaddc0":"print(classification_report(y_train, lm.predict(X_train)))","1678b198":"plot_confusion_matrix(lm, X_train, y_train)","38758a40":"print(classification_report(y_val, lm.predict(X_val)))","7992d9bf":"plot_confusion_matrix(lm, X_val, y_val)","635ee078":"from sklearn.tree import DecisionTreeClassifier","5ea71d1f":"DTC = DecisionTreeClassifier()\nDTC.fit(X_train, y_train)","a28ab983":"{col:round(fi,3) for col, fi in zip(FEATURES, DTC.feature_importances_)}","4c81d6f2":"print(classification_report(y_train, DTC.predict(X_train)))","15ab6007":"plot_confusion_matrix(DTC, X_train, y_train)","42c53b96":"plot_confusion_matrix(DTC, X_val, y_val)","e8bb65af":"print(classification_report(y_val, DTC.predict(X_val)))","df72e6ce":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold","d6264f7f":"rf_clf = RandomForestClassifier()\nrf_clf.fit(X_train, y_train)","827b0b3e":"{col:round(fi,3) for col, fi in zip(FEATURES, rf_clf.feature_importances_)}","122eadc2":"print(classification_report(y_train, rf_clf.predict(X_train)))","7a1fb45b":"plot_confusion_matrix(rf_clf, X_train, y_train)","86b1fc5b":"plot_confusion_matrix(rf_clf, X_val, y_val)","6a61d8aa":"print(classification_report(y_val, rf_clf.predict(X_val)))","e479ef2c":"len(rf_clf.estimators_)","5a649e1c":"rf_clf.estimators_[0].feature_importances_","d2134b54":"random_params = {\n    'max_depth': 30,\n    'min_samples_split': 17,\n    'max_samples': 0.8,\n    'min_samples_leaf': 50,\n    'criterion': 'gini',\n    'n_estimators': 150\n}","c3da3ae2":"rf_clf = RandomForestClassifier(oob_score=True,\n                             n_jobs=16,\n                             random_state=SEED,\n                             verbose=0,\n                             class_weight=\"balanced\",\n                             max_features=None,\n                             **random_params)\nrf_clf.fit(X_train, y_train)","1dfc4e8f":"{col:round(fi,3) for col, fi in zip(FEATURES, rf_clf.feature_importances_)}","77da7e1a":"print(classification_report(y_train, rf_clf.predict(X_train)))","d30390c9":"plot_confusion_matrix(rf_clf, X_train, y_train)","cbebe23a":"plot_confusion_matrix(rf_clf, X_val, y_val)","176c687b":"print(classification_report(y_val, rf_clf.predict(X_val)))","90bda236":"from sklearn.model_selection import GridSearchCV","baed41f7":"space = {\n    'max_depth': range(2, 9, 3),\n    'min_samples_split' : range(2, 9, 3),\n    'max_samples' : np.linspace(0.5, 0.7, 3),\n    'min_samples_leaf' : range(2, 9, 3),\n    'criterion' : ['gini', 'entropy'],\n    'n_estimators' : [10, 15]\n}","40aa0bcc":"rf_clf = RandomForestClassifier(oob_score=False,\n                             n_jobs=-1,\n                             random_state=SEED,\n                             verbose=0,\n                             class_weight=\"balanced\",\n                             max_features=None)\n\nclf = GridSearchCV(rf_clf, space, cv=5, scoring='f1_macro') #https:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html#scoring-parameter\n\nclf.fit(X_train, y_train)","460a258d":"clf.cv_results_.keys()","a812178e":"clf.best_score_, clf.best_params_","a8185bc2":"len(clf.cv_results_['mean_test_score'])*5 # Number of forest that were created","c568674f":"tuned_rf = RandomForestClassifier(oob_score=False,\n                                  n_jobs=-1,\n                                  random_state=SEED,\n                                  verbose=0,\n                                  class_weight=\"balanced\",\n                                  max_features=None, \n                                  **clf.best_params_)\ntuned_rf.fit(X_train, y_train)","315a31db":"print(classification_report(y_train, tuned_rf.predict(X_train)))","4348d116":"plot_confusion_matrix(tuned_rf, X_train, y_train)","87884fe3":"plot_confusion_matrix(tuned_rf, X_val, y_val)","4406f34a":"print(classification_report(y_val, tuned_rf.predict(X_val)))","899fcd3a":"# https:\/\/docs.scipy.org\/doc\/scipy\/reference\/stats.html\nfrom scipy.stats import randint, poisson, uniform, norm, halfnorm\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","4da36a4a":"randint_sample = randint(0,10)\nplt.hist(randint_sample.rvs(5000))","65b2b344":"uniform_sample = uniform(0,1)\nplt.hist(uniform_sample.rvs(5000))","d2d5b731":"poisson_sample = poisson(10)\nplt.hist(poisson_sample.rvs(1000), bins=range(0,20))","be6edb50":"norm_sample = norm(10, 0.1)\nplt.hist(norm_sample.rvs(1000))","b8a13a42":"halfnorm_sample = halfnorm(10, 0.1)\nplt.hist(halfnorm_sample.rvs(1000))","24351552":"from sklearn.model_selection import RandomizedSearchCV","9703416c":"uniform(0.5,0.3).rvs(10)","116b9ecb":"space = {\n    'max_depth': randint(2, 9),\n    'min_samples_split' : randint(2, 9),\n    'max_samples' : uniform (0.5, 0.3), # arguments are loc & scale and the distribution will stay between [loc, loc + scale] i.e. 0.5 and 0.8\n    'min_samples_leaf' : randint(2, 9),\n    'criterion' : ['gini', 'entropy'],\n    'n_estimators' : randint(10,15)\n}","2404f1fb":"rf_clf = RandomForestClassifier(oob_score=False,\n                             n_jobs=-1,\n                             random_state=SEED,\n                             verbose=0,\n                             class_weight=\"balanced\",\n                             max_features=None)\n\nclf = RandomizedSearchCV(estimator=rf_clf, param_distributions=space, cv=5, scoring='f1_macro', n_iter=20) # 100 experiments\n\nclf.fit(X_train, y_train)","d0698928":"clf.cv_results_.keys()","4851861e":"clf.best_score_, clf.best_params_","0f4f1d3c":"tuned_rf = RandomForestClassifier(oob_score=False,\n                                  n_jobs=-1,\n                                  random_state=SEED,\n                                  verbose=0,\n                                  class_weight=\"balanced\",\n                                  max_features=None, \n                                  **clf.best_params_)\ntuned_rf.fit(X_train, y_train)","f42fb4d7":"print(classification_report(y_train, tuned_rf.predict(X_train)))","3e41f3d5":"plot_confusion_matrix(tuned_rf, X_train, y_train)","14be95a0":"plot_confusion_matrix(tuned_rf, X_val, y_val)","16d60cc8":"print(classification_report(y_val, tuned_rf.predict(X_val)))","ffb0b446":"from hyperopt import hp, tpe\nfrom hyperopt.fmin import fmin\n\nfrom sklearn.model_selection import KFold\n\nfrom hyperopt import STATUS_OK\nfrom hyperopt import Trials","e157b284":"NUM_FOLDS = 5\nNUM_EVALS = 20","2bd608ae":"bayes_trials = Trials()","0a2109b0":"space = {\n    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n    'min_samples_split' : hp.quniform('min_samples_split', 2, 50, 1),\n    'n_estimators': hp.quniform('n_estimators', 20, 50, 1),\n    'criterion': hp.choice('criterion', ['gini', 'entropy']),\n    'max_samples' : hp.uniform('max_samples', 0.5, 1),\n    'min_samples_leaf' : hp.randint('min_samples_leaf', 2, 9)\n}","09961294":"def objective(params):\n    params = {\n        'max_depth': int(params['max_depth']),\n        'min_samples_split' : int(params['min_samples_split']),\n        'n_estimators' : int(params['n_estimators']),\n        'criterion' : params['criterion'],\n        'max_samples' : float(params['max_samples']),\n        'min_samples_leaf': int(params['min_samples_leaf'])\n    }\n\n    clf = RandomForestClassifier(oob_score=True,\n                                 n_jobs=-1,\n                                 random_state=SEED,\n                                 verbose=0,\n                                 **params)\n\n    score = cross_val_score(estimator=clf,\n                            X=train_df[FEATURES].values, #\n                            y=train_df[DEP_VARS[0]].values, #\n                            scoring='f1_macro',\n                            cv=KFold(n_splits=NUM_FOLDS, # Stratified\n                                               shuffle=True,\n                                               random_state=SEED)).mean()\n    \n    print(\"F1 Score {:.3f} params {}\".format(score, params))\n    return {\"loss\":-1.0*score, \"params\":params, \"status\":STATUS_OK}","23acc38e":"best = fmin(fn=objective,\n            space=space,\n            algo=tpe.suggest,\n            max_evals=NUM_EVALS, trials=bayes_trials)\nprint(best)","aa91bf13":"optimal_params = {\n    'max_depth': int(best['max_depth']),\n    'min_samples_split': int(best['min_samples_split']),\n    'n_estimators': int(best['n_estimators']),\n    'criterion': ['gini', 'entropy'][best['criterion']],\n    'max_samples' : float(best['max_samples']),\n    'min_samples_leaf': int(best['min_samples_leaf'])\n}\n\nprint(optimal_params)","cb23752d":"bayes_trials.trials","6f6a5795":"best2 = fmin(fn=objective,\n            space=space,\n            algo=tpe.suggest,\n            max_evals=100, trials=bayes_trials)\nprint(best2)","9d7db716":"tuned_rf = RandomForestClassifier(**{\n    \"oob_score\":True,\n    \"n_jobs\":-1,\n    \"random_state\":SEED,\n    \"verbose\":1,\n    \"class_weight\":\"balanced\",\n    **optimal_params\n})\n\ntuned_rf.fit(X=X_train, y=y_train)","f5145f35":"preds_train = tuned_rf.predict(X_train)\npreds_val = tuned_rf.predict(X_val)","41d58155":"print(classification_report(y_train, tuned_rf.predict(X_train)))","9389e9bb":"plot_confusion_matrix(tuned_rf, X_train, y_train)","7da1b20d":"plot_confusion_matrix(tuned_rf, X_val, y_val)","606261d6":"print(classification_report(y_val, tuned_rf.predict(X_val)))","d3431dd4":"### Random Forest Classifier - Grid Search","66684396":"#### Training Metrics","26868bb6":"### Logisitic Regression","d9baf12a":"#### Training Metrics","2f34e08e":"### Validation","c9016295":"#### Validation metrics","b2dbad76":"### Validation","51a64996":"Defining search spaces is where hyperopt shines. There is a ton of sampling options to choose from:\n* **Categorical parameters**-use **hp.choice**\n* **Integer parameters**-you can use **hp.randit, hp.quniform, hp.qloguniform or hp.qlognormal** which really gives you a lot of options to model your integer hyperparameter space\n* **Float parameters**- similarly to integer parameters you really get to choose what works for your problem with **hp.normal, hp.uniform, hp.lognormal and hp.loguniform**","43f3174e":"#### Training Metrics","f44ecaca":"### Detour: Distributions","c892619f":"#### Validation metrics","509804a7":"## Libraries","3252521c":"### train validation split","f6ce2c32":"# Hyperopt","73a92e3d":"Read more about Hyperopt [here](https:\/\/towardsdatascience.com\/hyperparameter-optimization-in-python-part-2-hyperopt-5f661db91324), [here](https:\/\/github.com\/hyperopt\/hyperopt\/wiki\/FMin),\n[here](https:\/\/towardsdatascience.com\/an-introductory-example-of-bayesian-optimization-in-python-with-hyperopt-aae40fff4ff0) and [here](https:\/\/maelfabien.github.io\/machinelearning\/HyperOpt\/#hyperopt)","1be24e0f":"#### Training Metrics","574be4e9":"### Random Forest Classifier - Not using defaults","67a9f1ef":"#### Validation metrics","7a9ba62b":"### Random Forest Classifier - Randomized Search","b6146ac4":"### Refit with best params","810b91d1":"## Settings","babfc2ab":"### Random Forest Classifier - Using Defaults","59c1bf7d":"#### Validation metrics","d563f28e":"#### Training Metrics","fa5f9e20":"#### Training Metrics","0bc4904b":"### Validation","67cc79a4":"### Validation","f03b4008":"#### Validation metrics","4a3e608d":"### Validation","48daefb1":"#### Validation metrics","987def59":"### Decisison Tree Classifier","c8fd1052":"### Validation","06ba71b8":"#### Validation metrics","1b0d01b6":"#### Training Metrics","2c7ce87e":"## Data preprocessing","530c819f":"### Validation","44781e30":"## Importing Data","79d1bf4f":"### Refit with best params"}}