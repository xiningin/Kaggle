{"cell_type":{"c8d59794":"code","87a8c4f7":"code","5e679d43":"code","4ebd7ac1":"code","c47fbe6e":"code","eecf6007":"code","a2f2d8ec":"code","568a9dce":"code","770f0356":"code","47aa4ce6":"code","ee6b2521":"code","d866df66":"code","a0aafd9b":"code","e799d297":"code","9aa94ac2":"code","3ee39b9a":"markdown","953d3177":"markdown","6301548b":"markdown","f64c32ff":"markdown","2c495dd4":"markdown","eb180a73":"markdown","59cc2d70":"markdown","d75ad75d":"markdown","a60512cd":"markdown"},"source":{"c8d59794":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","87a8c4f7":"#Reading the data\ndata = pd.read_csv('\/kaggle\/input\/3dprinter\/data.csv')\n\ndata.head()","5e679d43":"data.info()","4ebd7ac1":"#Converting objects into integers\ndata.infill_pattern = [0 if each ==\"grid\" else 1 for each in data.infill_pattern]\ndata.material = [0 if each ==\"abs\" else 1 for each in data.material]\ndata.head()","c47fbe6e":"data.info()","eecf6007":"#converting the fractions into percentages\ndata.layer_height = data.layer_height * 100\ndata.elongation = data.elongation * 100 ","a2f2d8ec":"x = data.drop([\"material\"], axis = 1) #remove materials column from dataset\ny = data.material.values #giving y all the values of materials","568a9dce":"#normalization and feature scaling\nx_norm = (x-x.mean())\/(x.std()) \n#x_norm = (x - avg_val_of_each_column) \/ (std_dev_of_each_column)\n","770f0356":"#Spliting data into three: train, cross validate, test\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x_norm, y, test_size=0.2, random_state=1) \n    # 20% data -> x_test\n\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1) \n# 0.25 x 0.8 = 0.2 -> 20% -> x_val\n\n# x_train -> 60%, x_val -> 20%, x_test -> 20%","47aa4ce6":"#Linear Regression\nfrom sklearn.linear_model import LinearRegression\n\nlogreg = LinearRegression().fit(x_train, y_train)\n\n#checking how much does model created using x_train fits the respective y_train values\n#not that significant\nlogreg.score(x_train, y_train)","ee6b2521":"#predicted value of y using values of x_val\ny_pred = logreg.predict(x_val)\n\n#comparing the y_pred with the real labels\n#y_pred is created automatically by .score() using x_val\n\nlogreg.score(x_val, y_val)","d866df66":"test_logreg = LinearRegression().fit(x_test, y_test)\nlogreg.score(x_test, y_test)","a0aafd9b":"from sklearn.tree import DecisionTreeRegressor\n\ndef get_mae(max_leaf_nodes, x_train, x_val, y_train, y_val):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(x_train, y_train)\n    pred_val = model.predict(x_val)\n    mae = mean_absolute_error(y_val, pred_val)\n    return(mae)\n\n\n#dt_model = DecisionTreeRegressor(random_state=1)\n#dt_model.fit(x_train, y_train)\n","e799d297":"candidate_max_leaf_nodes = [2, 5, 25, 50, 100, 250, 500]\n# Write loop to find the ideal tree size from candidate_max_leaf_nodes\nfor max_leaf_nodes in candidate_max_leaf_nodes:\n    my_mae = get_mae(max_leaf_nodes,  x_train, x_val, y_train, y_val)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))\n\n#y_pred_dt = dt_model.predict(x_val)     ","9aa94ac2":"dt_model = DecisionTreeRegressor(random_state=1)\ndt_model.fit(x_test, y_test)\ny_pred_dt = dt_model.predict(x_test)\nval_mae = mean_absolute_error(y_test, y_pred_dt)\nprint(val_mae)","3ee39b9a":"Training and Validating","953d3177":"Validating","6301548b":"Testing","f64c32ff":"Training","2c495dd4":"Because of lack of data, it seems the model is overfitting the dataset. choose max leaf node of 2","eb180a73":"Conclusion: Because of lack of enough data, Decision Tree Regression fits data too much even test and validation data","59cc2d70":"# Linear Regression","d75ad75d":"# Decision Tree Regressor","a60512cd":"Testing"}}