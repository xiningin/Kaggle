{"cell_type":{"326d0546":"code","5bd8c87f":"code","92707257":"code","541e18a9":"code","5bfd55c5":"code","72224161":"code","47049ebc":"code","b247fd91":"code","1e11eb72":"code","29c47bf5":"code","cbf528db":"code","fe8150a0":"code","a1efc551":"code","e6937db1":"code","2b3aac3f":"code","aef8d59b":"code","4c6927ae":"code","aca6321a":"code","9ff082ed":"code","9f634e67":"code","dfc4d13a":"markdown","c9a6f940":"markdown","5d5c121c":"markdown","4f870d4a":"markdown"},"source":{"326d0546":"# Input data files are available in the read-only \"..\/input\/\" directory\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","5bd8c87f":"import numpy as np \nimport pandas as pd\n\nimport re\nimport spacy \nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, Activation\nfrom tensorflow.keras.callbacks import EarlyStopping ","92707257":"df_train = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\nprint(df_train.shape)\ndf_train.head()","541e18a9":"df_test = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')\nprint(df_test.shape)\ndf_test.head()","5bfd55c5":"df_submission = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/sample_submission.csv')\nprint(df_submission.shape)\ndf_submission.head()","72224161":"df_train['target'].value_counts()","47049ebc":"print(df_train.isnull().sum(), '\\n')\nprint(df_test.isnull().sum())","b247fd91":"df_train['keyword'].fillna('', inplace=True)\ndf_test['keyword'].fillna('', inplace=True)","1e11eb72":"df_train['text'] = df_train['text'] + ' ' + df_train['keyword']\ndf_test['text'] = df_test['text'] + ' ' + df_test['keyword']","29c47bf5":"df_train.drop(['keyword','location'], axis=1, inplace=True)\ndf_test.drop(['keyword','location'], axis=1, inplace=True)","cbf528db":"duplicate_records = df_train[df_train.duplicated(['text'], keep=False)]\nprint(duplicate_records.shape)\nduplicate_records.head()","fe8150a0":"df_train.drop_duplicates(subset=['text'], keep='first', inplace=True)","a1efc551":"def preprocess(text):\n    text = re.sub('[^a-zA-Z]', ' ', text)\n    text = text.lower().split()\n    \n    text = [PorterStemmer().stem(word) for word in text if not word in stopwords.words('english')]\n    text = ' '.join(text)\n    return text","e6937db1":"df_train['text'] = df_train['text'].apply(lambda x: preprocess(x))\ndf_test['text'] = df_test['text'].apply(lambda x: preprocess(x))\ndf_train.head()","2b3aac3f":"voc_size = 50000\nsent_length = 30\nembedding_dim = 300\n\nX_train = [one_hot(words, voc_size) for words in df_train['text']]\nX_train = pad_sequences(X_train, padding='pre', maxlen=sent_length)\nY_train = df_train['target']\nX_test = [one_hot(words, voc_size) for words in df_test['text']]\nX_test = pad_sequences(X_test, padding='pre', maxlen=sent_length)\n\nprint(X_train.shape, Y_train.shape)\nprint(X_test.shape)","aef8d59b":"model = Sequential()\nmodel.add(Embedding(voc_size, embedding_dim, input_length=sent_length))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(64, return_sequences=True))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(64))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Activation('softmax'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()","4c6927ae":"early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\nmodel_history = model.fit(X_train, Y_train, validation_split=0.1, batch_size=64, epochs=10, \n                          shuffle=True, callbacks=[early_stop])","aca6321a":"prediction = model.predict(X_test)\nprediction = list(1 if x>0.5 else 0 for x in list(prediction))\nprediction[0:10]","9ff082ed":"df_submission['target'] = prediction\ndf_submission.to_csv('prediction.csv', index=False)\ndf_submission.head()","9f634e67":"df_submission['target'].value_counts()","dfc4d13a":"## Submission","c9a6f940":"## Model Development","5d5c121c":"## Data Preprocessing","4f870d4a":"## Data Acquisition"}}