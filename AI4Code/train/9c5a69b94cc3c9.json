{"cell_type":{"3e921d68":"code","ce94fd16":"code","67e4907f":"code","23743bdc":"code","314a12b7":"code","5e849f93":"code","d228d0f5":"code","67451381":"code","cefcd937":"code","85a2c881":"code","5d17affa":"code","bf375b2c":"code","f33608c0":"code","59dfed17":"code","97876b97":"code","b9619a01":"code","d5a03629":"markdown","3b63894c":"markdown","c3431719":"markdown"},"source":{"3e921d68":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport nltk\nfrom nltk.corpus import stopwords\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB,MultinomialNB,ComplementNB,BernoulliNB\n\n\n# Any results you write to the current directory are saved as output.","ce94fd16":"train_data = pd.read_csv('..\/input\/train.csv')\ntest_data = pd.read_csv('..\/input\/test.csv')","67e4907f":"train_data.shape","23743bdc":"train_data.head()","314a12b7":"train_data['target'].value_counts()","5e849f93":"# train_data['num_words'] = train_data['question_text'].apply(lambda x: len(str(x).split()) )","d228d0f5":"train_text = train_data['question_text']\ntest_text = test_data['question_text']\ntrain_target = train_data['target']\nall_text = train_text.append(test_text)","67451381":"tfidf_vectorizer = TfidfVectorizer()\ntfidf_vectorizer.fit(all_text)\n\ncount_vectorizer = CountVectorizer()\ncount_vectorizer.fit(all_text)\n\ntrain_text_features_cv = count_vectorizer.transform(train_text)\ntest_text_features_cv = count_vectorizer.transform(test_text)\n\ntrain_text_features_tf = tfidf_vectorizer.transform(train_text)\ntest_text_features_tf = tfidf_vectorizer.transform(test_text)\n","cefcd937":"kfold = KFold(n_splits = 5, shuffle = True, random_state = 2018)\ntest_preds = 0\noof_preds = np.zeros([train_data.shape[0],])\n\nfor i, (train_idx,valid_idx) in enumerate(kfold.split(train_data)):\n    x_train, x_valid = train_text_features_tf[train_idx,:], train_text_features_tf[valid_idx,:]\n    y_train, y_valid = train_target[train_idx], train_target[valid_idx]\n    classifier = LogisticRegression()\n    print('fitting.......')\n    classifier.fit(x_train,y_train)\n    print('predicting......')\n    print('\\n')\n    oof_preds[valid_idx] = classifier.predict_proba(x_valid)[:,1]\n    test_preds += 0.2*classifier.predict_proba(test_text_features_tf)[:,1]\n    ","85a2c881":"pred_train = (oof_preds > .25).astype(np.int)\nf1_score(train_target, pred_train)","5d17affa":"submission1 = pd.DataFrame.from_dict({'qid': test_data['qid']})\nsubmission1['prediction'] = (test_preds>0.25).astype(np.int)\n# submission1.to_csv('logistic_submission.csv', index=False)\nsubmission1['prediction'] = (test_preds>0.25)","bf375b2c":"kfold = KFold(n_splits = 5, shuffle = True, random_state = 2018)\ntest_preds1 = 0\noof_preds1 = np.zeros([train_data.shape[0],])\n\ntest_preds2 = 0\noof_preds2 = np.zeros([train_data.shape[0],])\n\nfor i, (train_idx,valid_idx) in enumerate(kfold.split(train_data)):\n    x_train, x_valid = train_text_features_cv[train_idx,:], train_text_features_cv[valid_idx,:]\n    y_train, y_valid = train_target[train_idx], train_target[valid_idx]\n    classifier1 = MultinomialNB()\n    classifier2 = BernoulliNB()\n    print('fitting.......')\n    classifier1.fit(x_train,y_train)\n    classifier2.fit(x_train,y_train)\n    print('predicting......')\n    print('\\n')\n    oof_preds1[valid_idx] = classifier1.predict_proba(x_valid)[:,1]\n    test_preds1 += 0.2*classifier1.predict_proba(test_text_features_cv)[:,1]\n    oof_preds2[valid_idx] = classifier2.predict_proba(x_valid)[:,1]\n    test_preds2 += 0.2*classifier2.predict_proba(test_text_features_cv)[:,1]","f33608c0":"pred_train = (oof_preds1 > .3).astype(np.int)\nf1_score(train_target, pred_train)","59dfed17":"pred_train = (oof_preds2 > .3).astype(np.int)\nf1_score(train_target, pred_train)","97876b97":"submission2 = pd.DataFrame.from_dict({'qid': test_data['qid']})\nsubmission3 = pd.DataFrame.from_dict({'qid': test_data['qid']})\n\nsubmission2['prediction'] = (test_preds1>0.3).astype(np.int)\n# submission2.to_csv('multinomial_submission.csv', index=False)\nsubmission2['prediction'] = (test_preds1>0.3)\n\nsubmission3['prediction'] = (test_preds2>0.3).astype(np.int)\n# submission3.to_csv('bernoulli_submission.csv', index=False)\nsubmission3['prediction'] = (test_preds2>0.3)","b9619a01":"submission_final = pd.DataFrame.from_dict({'qid':test_data['qid']})\nsubmission_final['prediction'] = ((0.6*submission1['prediction'] + 0.2*submission2['prediction'] + 0.2*submission3['prediction'])>0.4).astype(np.int)\nsubmission_final.to_csv('submission.csv',index = False)","d5a03629":"## Naive Bayes","3b63894c":"# Naive Bayes\n- In this kernel you will learn how to use Naive Bayes to solve a Classification problem.","c3431719":"## Basic Logistic Regression "}}