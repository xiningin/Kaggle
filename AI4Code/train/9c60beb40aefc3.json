{"cell_type":{"e79ac85a":"code","ea05224a":"code","fc51c400":"code","5f5b4640":"code","637b5a0c":"code","61254953":"code","2695324a":"code","1e5a807d":"code","a005f0c0":"code","6f4ab3cd":"code","71956942":"code","345df5a9":"code","23339196":"code","2875cec1":"code","42b387d8":"code","65fd5fb5":"code","5abaddb3":"code","98273012":"code","5e22c953":"code","c7eea797":"code","23a4e05e":"code","a2221619":"code","7c28983f":"code","250585eb":"code","80c53a11":"code","8d71126f":"code","bd709a60":"code","b03cc4cc":"code","5bea41d3":"code","f8c1e24e":"code","4694e8cd":"code","34da8189":"code","d536bac0":"code","25a60c01":"code","476d62c9":"markdown","54a4920c":"markdown","c16c588d":"markdown","0b0e63b3":"markdown","2e1dd29d":"markdown","c0d0955a":"markdown","70b5505b":"markdown","55649aab":"markdown","d88bf2a7":"markdown","da7d9c8b":"markdown","44fe63a6":"markdown","415a3b98":"markdown","433872da":"markdown","c41862f5":"markdown","4e4f8760":"markdown","3cca0561":"markdown","20ab62d8":"markdown","167c9dd3":"markdown","91ac5551":"markdown","f2c63aa7":"markdown","3d4d8a58":"markdown"},"source":{"e79ac85a":"from IPython.display import Image\nimport os\n(\"..\/input\/images\/Spam ham emoji.JPG\")\n\n","ea05224a":"Image(\"..\/input\/images\/Spam ham emoji.JPG\")","fc51c400":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n#spam_ham= pd.read_csv(\"..\/input\/heart.csv\")","5f5b4640":"spam_ham= pd.read_csv(\"..\/input\/spam-or-not-spam-dataset\/spam_or_not_spam.csv\")\nspam_ham.head()","637b5a0c":"spam_ham.info()","61254953":"spam_ham.describe()","2695324a":"spam_ham['email'].isnull().sum()","1e5a807d":"spam_ham= spam_ham.dropna(how='any',axis=0)\nspam_ham.info()","a005f0c0":"sns.countplot(x='label', data = spam_ham)\nplt.title('Number of Spam (1) & ham (0) from e-mail dataset ')\nplt.show()","6f4ab3cd":"spam_ham['label'].sum()","71956942":"def sum_func(df,column): # this function will help in counting the same group entries\n    for i in range(len(column)):\n        count = df[column].value_counts()\n        return count\n\nsum_func(spam_ham, 'label')\n    \n","345df5a9":"print( \"Spam percentage is \",spam_ham['label'].sum()\/len(spam_ham.index)* 100, \"%\")","23339196":"numpy_array = spam_ham.as_matrix()\nX= spam_ham.email\ny= spam_ham.label\n#X=numpy_array[:,0]\n#y=numpy_array[:,1]\n#y = y.astype('int')\nprint(\"X\")\nprint(X)\nprint(\"y\")\nprint(y)","2875cec1":"import sklearn\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, random_state=100)\nX_train","42b387d8":"from sklearn.feature_extraction.text import CountVectorizer\nvect= CountVectorizer(stop_words=\"english\")\nvect.fit(X_train)\n\n# printing the Vocabulary texts\n\nprint(vect.vocabulary_)","65fd5fb5":"X_train.shape","5abaddb3":"X_train_transformed= vect.transform(X_train)\nX_test_transformed = vect.transform(X_test)\n#print(X_train_transformed)\nprint(X_test_transformed)","98273012":"#X = X_transformed.toarray()\n#X","5e22c953":"#X_train_transformed=X_transformed.toarray()\nX_train_transformed","c7eea797":"X_train_transformed.shape","23a4e05e":"# converting matrix to dataframe\n#pd.DataFrame(X_train_transformed, columns=vect.get_feature_names())","a2221619":"y_train","7c28983f":"y_train.shape","250585eb":"from sklearn.naive_bayes import BernoulliNB\nbnb=BernoulliNB()\nbnb.fit(X_train_transformed, y_train)\nproba= bnb.predict_proba(X_test_transformed)\ny_pred= bnb.predict(X_test_transformed)\n\n#Converting array to data frame\n#proba = pd.DataFrame(proba)\n#proba.tail()\n# printing the overall accuracy\nfrom sklearn import metrics\nmetrics.accuracy_score(y_test, y_pred)","80c53a11":"from sklearn import metrics\nconfusion= metrics.confusion_matrix(y_test, y_pred)\nprint(confusion)","8d71126f":"pd.DataFrame(proba, columns=['Ham','Spam'])\n#pd.DataFrame(proba)","bd709a60":"TN = confusion[0, 0]\nFP = confusion[0, 1]\nFN = confusion[1, 0]\nTP = confusion[1, 1]","b03cc4cc":"sensitivity = TP\/float(TP+FN)\nprint(\"Sensitivity= \",sensitivity)\nspecificity= TN\/float(TN+FP)\nprint(\"Specificity= \", specificity)\nprint(\"Precision= \", TP\/float(TP+FP))\n\nprint(\"PRECISION SCORE :\",metrics.precision_score(y_test, y_pred))\nprint(\"RECALL SCORE :\", metrics.recall_score(y_test, y_pred))\nprint(\"F1 SCORE :\",metrics.f1_score(y_test, y_pred))","5bea41d3":"# creating an ROC curve\nfrom sklearn.metrics import confusion_matrix as sk_confusion_matrix\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, proba[:,1])\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\n# matrix of thresholds, tpr, fpr\nprint(pd.DataFrame({'Threshold': thresholds,\n              'TPR': true_positive_rate,\n              'FPR':false_positive_rate\n             }))\n\n# plotting the ROC curve\n\n\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC')\nplt.plot(false_positive_rate, true_positive_rate)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.show()\n\n### Bernoullis NB modelling gave better result","f8c1e24e":"roc_auc = auc(false_positive_rate, true_positive_rate)","4694e8cd":"print (roc_auc)","34da8189":"print(max(thresholds))","d536bac0":"from sklearn.metrics import precision_recall_curve \n\nprecision, recall, thresholds = precision_recall_curve(y_test, proba[:,1])\n# create plot\nplt.plot(recall, precision, label='Precision-recall curve')\n\n_ = plt.xlabel('Recall')\n_ = plt.ylabel('Precision')\n_ = plt.title('Precision-recall curve')\n_ = plt.legend(loc=\"lower left\")\n\nno_skill = len(y_test[y_test==1]) \/ len(y_test)\nplt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')","25a60c01":"from sklearn.metrics import average_precision_score\naverage_precision_score(y_test, proba[:, 1])","476d62c9":"This a classification problem and its analysis can be done by following two ways. \n\n    1) Logistic regression\n    2) Naive Nayes Theorem\n    \nAs this problem involves words dictionaries, we will use Naive Bayes as it is best fit for such kind of analysis.\nThere are two sub analysis methods under Naive bayes header as follows;\n\n    1) Multinomial Naive Bayes \n    2) Bernoullis Naive bayes\n    \nIn general Bernoullis Naive Baive classifier is known to be more efficient for categorical classification problems. I will use Bernoullis Naive Bayes for My analysis.","54a4920c":"**Conlusion**\n\nTo further describe it in practical sense, it means at Precision 0.3 according the above Precision recall curve, the Model will allow higher hams to be classified as Spam and most accurately it will predict the spam count. Which is negligible miss of spam classification. But this is not called a good refrence point because we will loose most of the good e-mails(Hams) because of predicted as spam at that threshold.\n\nHere comes the domain knowledge, which helps in making a clear decision based on what is best  based on expected need.\n\nSuppose we do not want to miss larger hams . We need to come to point where we have to allow some compromise . Which will lead to some cross classification.\n\nBsed on the above curve as we move right we increase the presion with the cost of loss of Recall. Still we can claim 70 % precision with 80 % recall based on above ML classifier.\n\nMore importantly, if we look at the data distribution for the classes, it seems to be bit imbalance i.e. only 16.63 % data is classified as spam and rest is ham. So to evaluate a ML model performance for such cases, Precision-Recall curve makes more sence as compared to ROC curve","c16c588d":"Additional detail checks abour data frame","0b0e63b3":"**Checking the area under Precision-Recall Curve**","2e1dd29d":"**Vectorizing the sentences and dropping the stop words**","c0d0955a":"**Transposing test & train data**","70b5505b":"**Prepare data for ML modelling**","55649aab":"From above Curve it appears as Precision Starts at around .3 and at this point based on the curve FP(False Positive) is higer and as we move right it reduces and leads to increase in TP(True Positive counts).\n\nOn the same curve at 0.3 Precison recall is maximum . Which means FN (False negative) is minimum.\n","d88bf2a7":"* The Accuracy of above model is 89.2 %","da7d9c8b":"Writing a small function for counting number of '0' & '1' in a column","44fe63a6":"The output of the Precison_Recall classifier is 0.7. This is also called as Average Precision. The more it is closer to 1, better is the Classifier.","415a3b98":"**Plotting Spam ham count**","433872da":"Checking the Nan or null entries for e-mail","c41862f5":"**Modelling using Naive Bayes**","4e4f8760":"**Calculation of Sensitivity, specificity**","3cca0561":"Lets drop the row with null entry","20ab62d8":"Spam-ham Data set loading from repository","167c9dd3":"Above confusion matrix Score shows that the model prediction will lead to loosing 66 hams due to wrong prediction as spam. This requires further refinement","91ac5551":"The data set choosen for following analysis is related to Spam & no-spam (Ham) e-mails. This again looks very familiar to every one as almost everyone deals with such kind of problems when matter is related to e-mail exchanges . You may remember that in addition to standard screening from e-mail service providers , sometime we still get some e-mail which are spams. It can be easily corelated by the outcome of the analysis below. The thing to be focused for that matter is \"confusion matrix\", which we get as an outcome of the analysis.\n\n\n\n","f2c63aa7":"**Preparing the data for ML modelling**","3d4d8a58":"**Confusion matrix evaluation of above Model**"}}