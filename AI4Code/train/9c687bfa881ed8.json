{"cell_type":{"84bdf35e":"code","9d9017a6":"code","99cf7cde":"code","428e1b49":"code","2934e601":"code","8823b816":"code","a156bd04":"code","9133420e":"code","c1f203b1":"code","4f6299b0":"code","aeedd4f6":"code","cb291548":"code","487c8f0d":"code","46ae89cb":"code","8d65dc46":"code","b7f35f21":"code","b204682f":"code","895376fa":"code","06c53936":"code","3776491a":"code","c9f6abee":"code","489e52b7":"code","28d17bb6":"code","ff7bf7a9":"code","a4c3a663":"code","1afd6b16":"code","6fca1221":"code","c40161cf":"code","c50c6b44":"code","3262c465":"code","b8108bb5":"code","49518f21":"code","ae1330cf":"code","971ac17c":"code","a73585c7":"code","04311818":"code","464c84c1":"code","da28a801":"code","40759ebc":"code","b704d9de":"code","73314a67":"code","bde4bc62":"code","8842c7d1":"code","8d709ce8":"code","837621bd":"code","15030cc1":"code","27f5ca75":"code","73a20081":"code","f2119e68":"code","cadf0063":"code","8bb06146":"code","0649a316":"code","bd745ade":"code","ab1a3692":"code","c4e8f712":"code","ceab8328":"code","20d84517":"code","ef9652d8":"code","20815004":"code","6cee16c4":"code","b7095f0b":"code","b241d993":"code","5066d2cd":"code","ae4f7061":"code","58c3d81d":"code","59ef4b88":"code","0c299ef5":"code","afeb6a50":"code","6dd2d5f2":"code","4cb6fa9a":"code","615a712b":"code","c8dc6f9f":"code","1804ec1d":"code","7d6aef1e":"code","e292cd47":"code","3c5a4be6":"code","296f35da":"code","84eaeb4c":"code","7e2c1be9":"code","2645e871":"code","6b024b99":"code","2465b693":"code","b6e9de56":"code","ecbf5d88":"code","bda12095":"code","b8ee063c":"code","7e9ca7f2":"code","472cd3f2":"code","1058569e":"code","a772d2c5":"code","38ac22d1":"code","6716b0a3":"code","41fc3b86":"code","2c3818e9":"markdown","62ffc1d4":"markdown","0122ed13":"markdown","1b2e66b4":"markdown","24294bd6":"markdown","9db531aa":"markdown","1f01151c":"markdown","edc8dec0":"markdown","b63589b7":"markdown","14bd217f":"markdown","5d508d2c":"markdown","4aeb2701":"markdown","4f686af1":"markdown","efbc6538":"markdown","efc1b6f5":"markdown","8acee54c":"markdown","2840358d":"markdown","0aca507e":"markdown","5fe261cc":"markdown","640ffb32":"markdown","2c54e080":"markdown","838f6165":"markdown","9217ac1c":"markdown","b37843ff":"markdown","b50c1a77":"markdown","bc0a53fa":"markdown","152dac38":"markdown","e0e9de83":"markdown","5f89648a":"markdown","5755324a":"markdown","e3a99ffc":"markdown","37ac0ab4":"markdown","ae40f107":"markdown","715ac0d2":"markdown","70299fe7":"markdown","3fd33560":"markdown","e1adf578":"markdown","30f56f5b":"markdown","b5e73dea":"markdown","c30baddd":"markdown","71810969":"markdown","0dd2fd2d":"markdown","8d9cd4c4":"markdown","0d4d0683":"markdown","bd6f6464":"markdown","f8cce7d9":"markdown","8e7deb88":"markdown","e3ee7b7f":"markdown","3c49594f":"markdown","895a54f6":"markdown","57b6d2b0":"markdown","a6730053":"markdown","9f998c85":"markdown"},"source":{"84bdf35e":"#Import necessary libraries for Data Analysis project\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport datetime as dt\n\n%matplotlib inline","9d9017a6":"#Locate link for subject dataset scourc\nsource_link = '..\/input\/noshowappointments\/KaggleV2-May-2016.csv'","99cf7cde":"# Reading the dataset\ndf = pd.read_csv(source_link)","428e1b49":"# preliminary inspection the dataset\nprint('Count of rows', str(df.shape[0]))\nprint('Count of Columns', str(df.shape[1]))\ndf.head()","2934e601":"# preliminary inspection the dataset\n#Basic info about data types, counts and null values\ndf.info()","8823b816":"# preliminary inspection the dataset\n#Identify unique values in the dataset\n\nprint(df.nunique()[0] \/ df.nunique()[1]) # percentage of patients of books more than 1 appointments\ndf.nunique()","a156bd04":"# preliminary inspection the dataset\n# summry statistics of the dataset\ndf.describe()","9133420e":"# preliminary inspection the dataset\n# summry statistics of target variable no-show\ndf_noshow = pd.DataFrame(df['No-show'].value_counts())\ndf_noshow = df_noshow.T\ndf_noshow['total'] = df_noshow['No'] + df_noshow['Yes']\ndf_noshow['no_perc'] = (df_noshow['Yes'] \/ df_noshow['total']) * 100\n\ndf_noshow","c1f203b1":"# change column names for convenience and easy manipulation\ndf.columns = df.columns.str.lower()\ndf.columns = ['pat_id', 'appo_id', 'gender', 'sch_day', 'appo_day', 'age', 'ngbr', \n              'scholarship', 'hipertension', 'diabetes', 'alcoholism', 'handcap', 'sms', 'no_show']","4f6299b0":"#Change columns patientid to str\ndf['pat_id'] = df['pat_id'].apply(int).apply(str)\n\n#Change columns appointmentid to str\ndf['appo_id'] = df['appo_id'].apply(str)","aeedd4f6":"#Change column handcap attributes to binary value (0 or 1) \ndf['handcap'] = df['handcap'].apply(lambda x: 0 if x == 0 else 1)","cb291548":"#Change columns scheduleday to date and spliting time from day\ndf['sch_day'] = pd.to_datetime(df['sch_day']).dt.strftime('%Y-%m-%d')\ndf['sch_day'] = pd.to_datetime(df['sch_day'])\n\n#Change columns appointmentday to date \ndf['appo_day'] = pd.to_datetime(df['appo_day'])","487c8f0d":"#Change columns no-show to binary \ndf['no_show'] = df['no_show'].map({'No':0, 'Yes':1})","46ae89cb":"#validiating ages variable, drop age < 0\ndf.drop(df[df['age'] < 0].index, inplace = True)","8d65dc46":"# Unified timezone\ndf['sch_day'] = df['sch_day'].apply(lambda d: d.replace(tzinfo=None))\ndf['appo_day'] = df['appo_day'].apply(lambda v: v.replace(tzinfo=None))","b7f35f21":"#adding new variable which measures difference in days between appointment date and scheduling date\ndf['day_diff'] = (df['appo_day'] - df['sch_day']).dt.days","b204682f":"#validiating variable day_diff\ndf.day_diff.value_counts().sort_index().head()","895376fa":"df.drop(df[df['day_diff'] < 0].index, inplace = True)","06c53936":"#looking at the data after cleaning\ndf.head(2)","3776491a":"import matplotlib.dates as dates\n#sch_ranges = dates.date2num(df_sch['sch_day'])","c9f6abee":"# inspecting Variable scheduling day\ndf_sch = pd.DataFrame(df.sch_day.value_counts())\ndf_sch = df_sch.reset_index(drop=False)\ndf_sch.columns = ['sch_day', 'count']\n\ndf_sch['date_num'] = dates.date2num(df_sch['sch_day'])\n\ndf_sch.iloc[50:60, :]\ndf_sch.head()\n\ndf_sch[df_sch['sch_day'] == '2016-03-15']\ndf_sch[df_sch['sch_day'] == '2016-03-3']\ndf_sch[df_sch['sch_day'] == '2016-05-03']\ndf_sch[df_sch['sch_day'] == '2015-11-10']\ndf_sch[df_sch['sch_day'] == '2016-03-01']\ndf_sch[df_sch['sch_day'] == '2016-06-08']\ndf_sch[df_sch['sch_day'] == '2016-02-01']\n","489e52b7":"#Summery stats about the Scheduling day variable\nprint('Highest Date recorded for booking appointments:', df_sch.sch_day.max())\nprint('Lowest Date recorded for booking appointments:', df_sch.sch_day.min())\nprint('Duration span of booking appointments:', (df_sch.sch_day.max()- df_sch.sch_day.min()).days, 'days')\nprint('Average bookings per day during the whole period of 211 days:', round(df_sch['count'].mean(), 2))\nprint('Average bookings per day during the period after 1st of March:', \n      round(df_sch['count'][df_sch.sch_day >= '2016-03-01'].mean(), 2))\nprint('Maximum bookings was recorded on 2016-05-03, with Total appointments of', df_sch['count'].max())","28d17bb6":"#df.sch_day.hist(bins=211, figsize=[15, 7], edgecolor='lightgray');\n# plotting count of appointments bookings per day \n\nplt.figure(figsize=[15, 7])\nplt.bar(df_sch['sch_day'], df_sch['count'], edgecolor='lightgray');\n#plt.bar(df_sch['sch_day'], df_sch['count']);\nplt.xticks(rotation=30);\nplt.title('Daily Appoinments booking');\nplt.ylabel('Count of Bookings');\nplt.xlabel('Date');\n\nplt.axvspan('2016-03-01', '2016-06-08', color='lightgray', alpha=.3);\n\nplt.text(16875.0, 2900, '99.6%', color='red', fontsize=25);\n\nplt.text(16863.0, 2600, 'of the data booking for appointments falls \\nbetween the period of March to June 2016',\n         color='black', fontsize=8 );\n\nplt.annotate('Highest bookings day\\n2016-05-03', xy=(16924.0, 4238), \n             xytext=(16863.0, 3800), arrowprops = dict(facecolor='black'));\n\nplt.axhline(995, color='red', linestyle='--', label=\"Average\");\nplt.text(16749.0, 1100, 'Average number of booking per day (Overall Data)', color='red');\n\nplt.hlines(y=1529, xmin = 16861.0, xmax = 16960.0, color='black', linestyle='--');\nplt.text(16832.0, 1600, 'Average number of booking per day (March to June)', color='black');\n\nplt.grid(False);\n\n#plt.savefig('sch_per_day.png', pad_inches='tight');","ff7bf7a9":"# inspecting Variable appointment day\ndf_appo = pd.DataFrame(df.appo_day.value_counts())\ndf_appo = df_appo.reset_index(drop=False)\ndf_appo.columns = ['appo_day', 'counts']\ndf_appo.head()","a4c3a663":"#Summery stats about the appointment day variable\nprint('Lowest Date recorded for appointments:', df_appo.appo_day.min())\nprint('Highest Date recorded for appointments:', df_appo.appo_day.max())\nprint('Duration span of booking appointments:', (df_appo.appo_day.max()- df_appo.appo_day.min()).days, 'days,',\n      'however appointments are distributed over', df_appo.shape[0], 'days only')\nprint('Average appointments per day:', round(df_appo['counts'].mean(), 2))\nprint('Maximum appointments was recorded on 2016-06-06, with total appointments of', df_appo['counts'].max())\nprint('Minimum appointments was recorded on 2016-06-06, with total appointments of', df_appo['counts'].min())\nprint('Average appointments per day with outlier date \"2016-05-14\":', round(df_appo.counts[df_appo.counts > 100].mean(), 2))","1afd6b16":"dates.date2num(pd.Series('2016-04-28'))\ndates.date2num(pd.Series('2016-05-14'))\n","6fca1221":"# plotting count of appointments per day \nplt.figure(figsize=[15, 5])\nplt.bar(df_appo.appo_day, df_appo.counts, edgecolor='lightgray') #, edgecolor='lightgray'\nplt.title('Daily Appointments');\nplt.ylabel('Count of appointments');\nplt.xlabel('Date');\nplt.xticks(rotation=45);\nplt.yticks([0,1000, 2000, 3000, 4000, 5000])\nplt.axhline(4093.37, color='black', linestyle='--', label=\"Average\");\nplt.text(16919, 4500, 'Average appointments per day', color='black');\nplt.grid(False);\n\nplt.annotate(\n    'Outlier',\n    xy=(16935, 150), xytext=(16935, 1000), fontsize=10, color='r', arrowprops = dict(facecolor='black')); \n\n#plt.savefig('appo_per_day.png', pad_inches='tight');","c40161cf":"# inspecting Variable age\ndf_age = pd.DataFrame(df.age.value_counts())\ndf_age = df_age.reset_index(drop=False)\ndf_age.columns = ['age', 'counts']\ndf_age.sort_values(by='age').head()\n#df_age.describe()","c50c6b44":"#Calculate average count of appointments for ages between 2 to 60\na = df_age[df_age.age > 2]\na = df_age[df_age.age <=60]\na.counts.mean()","3262c465":"#modeling the distribution of appointments counts of age\nx_uniform = [x for x in range(2,60,1)]\ny_uniform = [1700 for x in range(2,60,1)]\nx_decrease = [x for x in range(60,100,1)]\ny_decrease = [x for x in range(1700,100, - len(x_decrease))]\n\n\n#plotting \nf, (a0, a1) = plt.subplots(1, 2, figsize=[15, 5], gridspec_kw={'width_ratios': [2, 1]})\nf.tight_layout()\n\na0.bar(df_age.age, df_age.counts);\na0.text(35, 3500,\"Count of Appointments per Age\", fontsize=15);\na0.axvspan(-1, 1, color='red', alpha=.1);\nAvg_all = df_age.counts.mean()\na0.axhline(Avg_all, color = 'black', linestyle=\"--\")\na0.text(100, (Avg_all+100),\"Average\", fontsize=15);\n\na0.plot(x_uniform, y_uniform, color='red', linestyle='dotted');\na0.text(5, 1850, \n        'Ages between 3 to 60 have an approximate uniform distribution with mean of \"1487\" Apointment\" per day', \n        color='red') #note\na0.plot(x_decrease, y_decrease, color='red', linestyle='dotted');\na0.text(90, 550, \n        'Ages +60 have a negative \\nlinear relationship \\nwith count of appointments', \n        color='red') #note\n\n\n\na1.hist(df_age.counts, bins=10, edgecolor='lightgray');\nplt.ylim(0, 45)\na1.text(700, 42, \"Distribution of Age Counts\", fontsize=15);\na1.text(1900, 20, \n        'Most of the counts per age \\nfalls within 1000 to 2000', \n        color='red') #note\n\n\n#plt.savefig('age_dist.jpg')","b8108bb5":"# inspecting Variable neighborhood\ndf_nbr = pd.DataFrame(df.ngbr.value_counts())\ndf_nbr = df_nbr.reset_index(drop=False)\ndf_nbr.columns = ['nbr', 'counts']\n\ndf_nbr['Weight_per'] = round(((df_nbr['counts'] \/ df_nbr['counts'].sum())*100),2)\ndf_nbr['cumualtive_Weight'] = df_nbr['Weight_per'].cumsum()\n\ndf_nbr.head(5)","49518f21":"plt.figure(figsize= [9, 7])\nplt.scatter(df_nbr.counts, df_nbr['cumualtive_Weight'])\n\nplt.title('Weightage % to number of appointments per location')\nplt.ylabel('Weightage %')\nplt.xlabel('Count per location')\n\nplt.axhline(32, linestyle='--', alpha=0.3, color='k')\nplt.axvline(0, linestyle='--', alpha=0.3, color='k')\nplt.axvline(1000, linestyle='--', alpha=0.3, color='k')\nplt.axvline(2000, linestyle='--', alpha=0.3, color='k')\nplt.axvline(3000, linestyle='--', alpha=0.3, color='k')\n\nplt.axvspan(0,999, color='red', alpha=.025);\nplt.axvspan(1000,1999, color='red', alpha=.05);\nplt.axvspan(2000,2999, color='red', alpha=.10);\nplt.axvspan(3000,8000, color='red', alpha=.15);\n\n#Annotation for very high demand locaion\ncat1 = plt.text(0, 6,\n            'Very High Demand locations:\\n8 out of 81 locations contributes to \\nmore than 31% of appointments count',\n                fontsize=12, color='white')\ncat1.set_bbox(dict(facecolor='darkred', alpha=0.8, edgecolor='k'))\n\n\n#Annotation for very high demand locaion\nplt.annotate('High Demand Locations: \\n13 locations covers 28% \\nof total appointments', xy=(2500, 55), \n            xytext=(3500, 40), fontsize=12, color='k', arrowprops = dict(facecolor='black')); \n\n#Annotation for Medium demand locaion\nplt.annotate('Medium Demand Locations: \\n18 locations covers almost 24% of \\ntotal appointments', xy=(1500, 80), \n             xytext=(3100, 65), fontsize=12, color='k', arrowprops = dict(facecolor='black')); \n\n#Annotation for low demand locaion\nplt.annotate(\n    'Low Demand Locations: \\n40 locations \"More than 50% of all locations\" \\ncovers 15% of total appointments',\n    xy=(600, 98), xytext=(2700, 85), fontsize=12, color='k', arrowprops = dict(facecolor='black')); \n\n#plt.savefig('location_heatmap.jpg')","ae1330cf":"def neighborhoods_categories(x):\n    \"\"\"\n    Function to categorize number of counts of appointments for each location into 4 buckets\n    \"\"\"\n    if x <= 1000:\n        return \"Low\"\n    elif x > 1000 and x <= 2000:\n        return \"Medium\"\n    elif x > 2000 and x <= 3000:\n        return \"High\"\n    else:\n        return \"Very High\"\n\n#create new variable to categorize locations based on demand on each location\ndf_nbr['appointments_demand'] = df_nbr.counts.apply(neighborhoods_categories)","971ac17c":"df_nbr_category = df_nbr.groupby('appointments_demand')['appointments_demand', 'counts', ].agg(['count', 'sum'])\ndf_nbr_category.drop(columns = ['appointments_demand'], inplace=True)\ndf_nbr_category.columns = df_nbr_category.columns.droplevel(0)\ndf_nbr_category.columns = ['counts', 'sums']\ndf_nbr_category['count_weight%'] = round(((df_nbr_category['counts'] \/ df_nbr_category['counts'].sum()) * 100), 2)\ndf_nbr_category['Sum_weight%'] = round(((df_nbr_category['sums'] \/ df_nbr_category['sums'].sum()) * 100), 2)\ndf_nbr_category['Average_per_location'] =  round((df_nbr_category['sums'] \/ df_nbr_category['counts']),0)\n\ndf_nbr_category = df_nbr_category.reindex(['Very High','High', 'Medium', 'Low'])\ndf_nbr_category = df_nbr_category.reset_index(drop=False)\n\ncolor_map = plt.cm.get_cmap('Pastel1')\ncolor_map_reversed = color_map.reversed()\ndf_nbr_category.style.background_gradient(cmap =color_map_reversed)\n","a73585c7":"#list of the binary variables\nbinary_variables = ['scholarship', 'hipertension', 'diabetes', 'alcoholism','handcap', 'sms', 'no_show']\n\n#Capturing the relevant data and wrangling it for conclusions\nbinary = df[binary_variables].stack(level=0)\nbinary = pd.DataFrame(binary)\nbinary.reset_index(drop=False, inplace =True)\nbinary.columns = ['level_0', 'level_1', 'value']\n","04311818":"(binary.groupby('level_1')['value'].sum() \/ binary.level_1.value_counts()) * 100","464c84c1":"plt.figure(figsize=[15,5]);\nsns.countplot(data=binary, x='level_1', hue='value');\nplt.title('Binary Variables contributios to count of appointments');\nplt.xlabel('Variable Name');\nplt.legend(['No', 'Yes']);\n\n#plt.savefig('binary_attr.jpg')","da28a801":"# inspecting Variable neighborhood\ndf_pat = pd.DataFrame(df.pat_id.value_counts())\ndf_pat.reset_index(drop=False, inplace=True)\ndf_pat.columns = ['Patient_id', 'counts']\n\n\ndf_pat.head()","40759ebc":"x = np.linspace(0, 1,len(df_pat.counts))\n\nplt.figure(figsize = [7, 5]);\nplt.scatter(x, df_pat.counts);\nplt.grid()\nplt.title('number of appointments made by each patients');\nplt.xlabel('contribution%');\nplt.ylabel('Count');\n#plt.ylim(0, 1)\n\n#plt.savefig('appointments_by_patient.jpg')\n","b704d9de":"def freq(x):\n    if x == 1:\n        return 'first time'\n    elif x > 1 and x < 8:\n        return 'frequent'\n    else:\n        return 'chronic'\n\ndf_pat['frequency'] = df_pat['counts'].apply(freq)\ndf_pat.head()","73314a67":"df_pat2 = df_pat.groupby('frequency')['counts', 'Patient_id'].agg(['sum', 'count'])\ndf_pat2.reset_index(drop=False, inplace=True)\ndf_pat2.columns = df_pat2.columns.droplevel(0)\ndf_pat2.columns = ['frequency','sum_appointments', 'count_patients', 'sum', 'count']\ndf_pat2 = df_pat2[['frequency','sum_appointments', 'count_patients']].copy()\ndf_pat2['weight_appointments'] = round(((df_pat2['sum_appointments'] \/ df_pat2['sum_appointments'].sum()) * 100),2)\ndf_pat2['weight_patients'] = round(((df_pat2['count_patients'] \/ df_pat2['count_patients'].sum()) * 100),2)\ndf_pat2['avg_appointments'] = round(df_pat2['sum_appointments'] \/ df_pat2['count_patients'],2)\n\n\ndf_pat2","bde4bc62":"#plotting to check the stats for total appointments made to total number of patients\nx = np.array([1,2,3])\n\nplt.figure(figsize = [7, 5])\nwidth = 0.3\nplt.bar(x, df_pat2.sum_appointments, width, color='tab:blue', label='Number of Appointments');\nplt.bar(x + width, df_pat2.count_patients,width, color='orange', label='Number of Patients');\nplt.xticks((x+width\/2) , ['chronic', 'first time', 'frequent']); \nplt.title('Total appointments made to total number of patients');\nplt.xlabel('Frequency of appointments')\nplt.ylabel('Count')\nplt.legend();\n\n#plt.savefig('appointments_Vs_Patients_Categories.jpg')","8842c7d1":"#distribute age data to bucket\ndef age_buckets(x):\n    if x <= 10:\n        return \"0 - 10\"\n    elif x <= 20:\n        return \"11 - 20\"\n    elif x <= 30:\n        return \"21 - 30\"\n    elif x <= 40:\n        return \"31 - 40\"\n    elif x <= 50:\n        return \"41 - 50\"\n    elif x <= 60:\n        return \"51 - 60\"\n    else:\n        return \"+61\"\n    ","8d709ce8":"df['age_categ'] = df.age.apply(age_buckets)\nage_noshow = df.groupby('age_categ')['no_show'].mean()\narrange_ages = [\"0 - 10\", \"11 - 20\", \"21 - 30\", \"31 - 40\", \"41 - 50\", \"51 - 60\", \"+61\"]\nage_noshow = age_noshow.reindex(arrange_ages)\n\n#Bucketing age into 2 categories + or -40\ndf['age_categ2'] = df.age.apply(lambda x: \"0 - 40\" if x <=40 else \"Above 40\")\n\n#Grouping the age categories and calculate the average no show\nage_noshow2 = df.groupby('age_categ2')['no_show'].mean()\n","837621bd":"#Visual the grouped average per age category\n\nx_0_40 = [-1, 1, 2, 3.5]\ny_0_40 = [0.23, 0.23, 0.23, 0.23]\n\nx_above40 = [3.5, 5, 6.5]\ny_above40 = [0.17, 0.17, 0.17]\n\nx_var = [3.5, 3.5]\ny_var = [0.25, 0.15]\n\nplt.figure(figsize=[15, 5]);\nage_noshow.plot(kind='bar', color='tab:blue');\nplt.title('Average no show per age category');\nplt.ylabel('Average No Show');\nplt.xlabel('Age Category');\n\nplt.ylim(0, 0.30)\n\nplt.axhline(age_noshow.mean(), color='k', linestyle='--');\nplt.text(-0.4, 0.21 , \"Average of all Ages\");\n\nplt.plot(x_0_40, y_0_40, color= 'r', linestyle='dotted', linewidth = 3);\nplt.text(-0.3, 0.26 , \"Average no show of Ages between 0 -40, Average (23%)\", color='r');\n\nplt.plot(x_above40, y_above40, color= 'r', linestyle='dotted', linewidth = 3);\nplt.text(4.3, 0.185 , \"Average no show of Ages above 40, Average (17%)\", color='r');\n\nplt.plot(x_var, y_var, linewidth = 5, color='red');\nplt.annotate('5% Difference between the 2 categories averages ', \n             xy=(3.5, 0.22), xytext=(4, 0.25), fontsize=12, color='r', arrowprops = dict(facecolor='r')); \n\nbox = plt.text(2.66, 0.08,\n            '\\n Is the difference statistically significant? \\n',\n                fontsize=15, color='k')\nbox.set_bbox(dict(facecolor='w', alpha=0.9, edgecolor='tab:blue'))\n\n#plt.savefig('Age_bucket_avg.jpg')","15030cc1":"#test significance in variable Age for age above or below 40\n\narray_under40 = np.array(df['no_show'][df['age'] <= 40])\narray_above40 = np.array(df['no_show'][df['age'] > 40])\narray_combined = np.concatenate((array_under40, array_above40))\n\nmeans_diff = []\nmean_under40 = []\nmean_above40 = []\n\nfor i in range(10000):\n    array_combined_perm = np.random.permutation(array_combined)\n    \n    perm_under = array_combined_perm[:len(array_under40)]\n    perm_above = array_combined_perm[len(array_under40):]\n    diff = perm_under.mean() - perm_above.mean()\n    \n    mean_under40.append(perm_under.mean())\n    mean_above40.append(perm_above.mean())\n    means_diff.append(diff)\n        \narray_means_diff = np.array(means_diff)\narray_means_under = np.array(mean_under40)  \narray_means_above = np.array(mean_above40)\n\n","27f5ca75":"#visualizing the hypothesis testing result\n\nmean_diff_note = \"\"\"\nFor all the simulated differences in mean, \n        the probalility that the difference \nbetween the 2 samples mean is equal to 5% \n                or greater is 0%\n\"\"\"\nmean_diff_note2 = \"\"\"\n    The estimated differnece is mean in all \nthe permuated samples at 99.9% confidence \n                was (-1.0 & 1.0)\n\"\"\"\n\n\nf, (a0, a1) = plt.subplots(1, 2, figsize=[15, 5], gridspec_kw={'width_ratios': [1, 1]})\nf.tight_layout()\n\na0.hist(array_means_under * 100, alpha=.5, bins=40, edgecolor='lightgray', label='Age 0 - 40');\na0.hist(array_means_above * 100, alpha=.5, bins=40, edgecolor='lightgray', label='Age Above 40');\na0.text(19.7, 750, \"Distribution of Permutated Means\")\na0.text(20.35, 500, \"Almost 100% overlapping \\nbetween the sample means\")\na0.legend();\n\na1.hist(array_means_diff * 100, bins=40, edgecolor='lightgray', label='Mean Differences');\na1.axvline(5, linestyle='--', c='r', label='Actual variance \\nAges categories')\na1.text(1, 750, \"Silmulated Mean Differences\")\na1.text(0.4, 350, mean_diff_note, color='r', fontsize = 15)\na1.text(0.7, 100, mean_diff_note2, color='b', fontsize = 13)\na1.legend(loc='upper right');\n\n#plt.savefig('age_buckets_variance1.jpg')","73a20081":"#merging the location category with the main dataframe\ndf = df.merge(df_nbr, how='left', left_on = 'ngbr', \n              right_on='nbr').drop(columns=['nbr', 'counts', 'Weight_per', 'cumualtive_Weight'])","f2119e68":"def days_grouping(x):\n    if x == 0:\n        return \"same day\"\n    elif x > 1 and x < 11:\n        return \"within 10 days\"\n    else:\n        return \"greater than 10 days\"","cadf0063":"df['days_group'] = df.day_diff.apply(days_grouping)","8bb06146":"day_difference_df = pd.DataFrame(\n    {'AVG':df.groupby('days_group')['no_show'].mean(), 'counts':df.groupby('days_group')['no_show'].count()})\n\n#df.groupby('days_group')['no_show'].count().plot(kind='pie', autopct=\"%.1f%%\", pctdistance=0.5);\nday_difference_df = day_difference_df.reindex(['same day', 'within 10 days', 'greater than 10 days'])\nday_difference_df['counts_weight%'] = (day_difference_df.counts \/ day_difference_df.counts.sum()) * 100\n\nday_difference_df","0649a316":"x_days = np.arange(1, 4)\nx_day_values = list(day_difference_df.index)\n\nwidth = 0.6\n\nplt.figure(figsize=[8, 7])\n\nplt.bar(x_days + (width \/ 2), day_difference_df.AVG * 100000, width,color=['tab:blue', 'tab:orange', 'tab:red'], \n        label='No show%');\nplt.plot(x_days + (width \/ 2), day_difference_df.counts, marker='o', label='Count of records');\nplt.xticks((x_days + width\/2) , x_day_values); \nplt.title('% of No show per days difference and Count of Records')\nplt.xlabel('Days difference between scheduling and appointment day')\nplt.ylabel('Count of Records')\nplt.legend()\n\nfor i in x_days:\n    plt.text(x_days[i - 1] + (width\/4), day_difference_df.AVG.iloc[i - 1] * 30000, \n             str(round(day_difference_df.AVG.iloc[i - 1],2)), fontsize = 25, color='w')\n    \n    plt.text(x_days[i - 1] + (width\/4), day_difference_df.counts.iloc[i - 1] - 3000, \n             str(round(day_difference_df.counts.iloc[i - 1],2)), fontsize = 15, color='tab:blue')\n    \n#plt.savefig('Day_Diff_Categories.jpg')","bd745ade":"location_df = pd.DataFrame(\n    {'AVG':df.groupby('appointments_demand')['no_show'].mean(), 'counts':df.groupby('appointments_demand')['no_show'].count()})\n\nindex_list = ['Low', 'Medium', 'High', 'Very High']\nlocation_df = location_df.reindex(index_list)\nlocation_df['counts_weight%'] = (location_df.counts \/ location_df.counts.sum())","ab1a3692":"location_df[['AVG', 'counts_weight%']].plot(marker='o');\nplt.xticks([x for x in range(4)] ,index_list);\nplt.ylim([0,0.5]);\nplt.title('Count of appointments per facility Vs No Show%');\nplt.ylabel('percentage');\nplt.xlabel('demand of the facility');\n#plt.savefig('location_avg_count.jpg')","c4e8f712":"#merging the patience frequency of making appointments with the main dataframe\ndf = df.merge(df_pat, how='left', left_on = 'pat_id', \n              right_on='Patient_id').drop(columns=['Patient_id', 'counts'])","ceab8328":"#creating new variable to to identify \ndf['frequency2'] = df.frequency.apply(lambda x: 1 if x =='frequent' else 0)","20d84517":"frequency_df = pd.DataFrame(\n    {'AVG':df.groupby('frequency2')['no_show'].mean(), 'counts':df.groupby('frequency2')['no_show'].count()})\n\nfrequency_df['counts_weight%'] = (frequency_df.counts \/ frequency_df.counts.sum())\nfrequency_df[['AVG', 'counts_weight%']].plot(marker='o');\nplt.xticks([0, 1], ['others', 'Patients made between\\n 2 to 7 appointments'])\n\nfrequency_df['AVG'].iloc[1] - frequency_df['AVG'].iloc[0]\nfrequency_df","ef9652d8":"gender_df = pd.DataFrame(\n    {'AVG':df.groupby('gender')['no_show'].mean(), 'counts':df.groupby('gender')['no_show'].count()})\n\ngender_df['counts_weight%'] = (gender_df.counts \/ gender_df.counts.sum())\ngender_df","20815004":"\ngender_df[['AVG', 'counts_weight%']].plot(marker='o');\nplt.xticks([0 , 1] ,['F', 'M']);\nplt.title('Count records per gender Vs No Show%');\nplt.ylabel('percentage');\nplt.xlabel('gender');\n\n#plt.savefig('gender_avg_count.jpg')\n","6cee16c4":"def stat_test(col_name, number_of_trials):\n    \"\"\"\n    Function to simulate statistical significance between 2 categories of a variable \n    and the noshow% affected by the categories\n    \"\"\"\n    grouped_mean = df.groupby(col_name)['no_show'].mean()\n    \n    significance_value = (grouped_mean[0] - grouped_mean[1])\n    array1 = np.array(df['no_show'][df[col_name] == 0])\n    array2 = np.array(df['no_show'][df[col_name] == 1])\n    array_combined = np.concatenate((array1, array2))\n    \n    means_list_1 = []\n    means_list_2 = []\n    means_diff_list = []\n    \n    for i in range(number_of_trials):\n        array_combined_perm = np.random.permutation(array_combined)\n        array1_permutation = array_combined_perm[:len(array1)]\n        array2_permutation = array_combined_perm[len(array2):]\n        diff = array1_permutation.mean() - array2_permutation.mean()\n        \n        means_list_1.append(array1_permutation.mean())\n        means_list_2.append(array2_permutation.mean())\n        means_diff_list.append(diff)\n        \n    means_diff_array = np.array(means_diff_list)\n    means_array_1 = np.array(means_list_1)  \n    means_array_2 = np.array(means_list_2)\n    \n    return (means_diff_array, means_array_1, means_array_2, significance_value, col_name)\n\ndef hist_plot_sig_test(data1, data2, data3, line_value,bins=40, label_1=\"\", label_2=\"\", label_3=\"\", name=\"\"):\n    \n    \"\"\"\n    visualize the simualtion result\n    \"\"\"\n    \n    f, (axis1, axis2) = plt.subplots(1, 2, figsize=[15, 5], gridspec_kw={'width_ratios': [1, 1]})\n    f.tight_layout()\n    axis1.hist(data1, alpha=.5, bins=bins, edgecolor='lightgray', label=label_1);\n    axis1.hist(data2, alpha=.5, bins=bins, edgecolor='lightgray', label=label_2);\n    axis1.legend();\n    \n    axis2.hist(data3, bins=bins, edgecolor='lightgray', label=label_3);\n    axis2.axvline(line_value, linestyle='--', c='r', label=\"Test Value\")\n    #plt.text(line_value * 1.05, 20, str(round(line_value,2)), color='r')#, rotation=90\n    box_viz = plt.text(line_value, 10, str(round(line_value,2)),color='r')\n    box_viz.set_bbox(dict(facecolor='w', alpha=0.9)) #, edgecolor='tab:blue'\n    axis2.legend();\n    name = name+'_Permutation.jpg'\n    #plt.savefig(name)","b7095f0b":"#create binary value from age columns to check age category\ndf['age_40_and_less'] = df.age_categ2.apply((lambda x: 1 if x =='Above 40' else 0))","b241d993":"#change name of column frequency2\ndf['frequenct_2_7'] = df.frequency2.copy()","5066d2cd":"#splitting the columns \"day_diff\" to 3 binary columns each column for 1 category\ndf['app_sameday'] = df.days_group.apply((lambda x: 1 if x =='same day' else 0))\ndf['app_10_days'] = df.days_group.apply((lambda x: 1 if x =='within 10 days' else 0))\ndf['app_more_10days'] = df.days_group.apply((lambda x: 1 if x =='greater than 10 days' else 0))\n","ae4f7061":"# variables to remove\n\"\"\"\nvariables_to_drop = ['pat_id', 'gender', 'sch_day', 'age', 'ngbr', 'hour', 'day_diff', 'age_categ', 'age_categ2',\n                    'appointments_demand', 'frequency', 'frequency2', 'days_group']\n\"\"\"\n# Isolate the variables that have significant contribute to No-Show%\nvariables_to_keep = ['appo_id', 'appo_day','scholarship', 'hipertension', 'diabetes', 'alcoholism', 'handcap',\n       'sms','age_40_and_less', 'frequenct_2_7', 'app_sameday', 'app_10_days', 'app_more_10days','no_show']","58c3d81d":"df_new = df[variables_to_keep].copy()\n\n#rename the newdataframe columns\ndf_new.columns = ['appointment_id', 'appointment_date','scholarship', 'hipertension', 'diabetes', \n                  'alcoholism', 'handcap','sms','age_40_and_less', 'frequenct_2_7', 'app_sameday',\n                  'app_10_days', 'app_more_10days', 'no_show']\n","59ef4b88":"vars_df_new = [x for x in df_new.columns[2:8]]\nmask_show = df_new['no_show'] == 0\nmask_noshow = df_new['no_show'] == 1\n\nstats_show = df_new[vars_df_new][mask_show].mean()\nstats_noshow = df_new[vars_df_new][mask_noshow].mean()","0c299ef5":"xxx_vars = np.arange(len(vars_df_new))\n\nplt.figure(figsize = [15, 5])\nwidth = 0.2\n\nplt.title('How binary variables contribute if patient showed up or not')\n\nplt.bar(xxx_vars, stats_show, width, color='tab:blue', \n        label='Average metric contribution where patients showed');\nplt.bar(xxx_vars + width, stats_noshow, width, color='orange', \n        label='Average metric contribution where patients didn\\'t show');\n\nplt.xticks((xxx_vars + width \/ 2) , vars_df_new); \nplt.legend();\n\nplt.ylim(0,.65)\n\nplt.text(1.6, .25,\n         'Variables \"diabetes\", \"alcoholism\" and \"handcap\" doesn\\'t \\nseem to any contribution to showing up or not',\n        fontsize=14)\n\nfor i in xxx_vars:\n    plt.text(xxx_vars[i]-0.11, stats_show[i] + 0.03, \n             str(round(stats_show[i],2)), color='tab:blue', fontsize = 13)\n    \n    plt.text(xxx_vars[i]+0.11, stats_noshow[i] + 0.03, \n             str(round(stats_noshow[i],2)), color='orange', fontsize = 13) #, fontsize = 15\n\n#plt.savefig('contribution_binary.jpg')","afeb6a50":"\nvars_df_new = ['scholarship', 'hipertension','sms']\n\nfor i in vars_df_new:\n    a, b, c, d, colname = stat_test(i, 10000)\n    hist_plot_sig_test(b, c, a, d,label_1=\"Permutation sample 1\", label_2=\"Permutation sample 2\", name=colname)\n","6dd2d5f2":"# Identify relevant variables to include in a new dataframe\nvars_new2 = ['appointment_id', 'appointment_date', 'scholarship', 'hipertension', 'sms', 'age_40_and_less','frequenct_2_7', 'app_sameday', 'app_10_days', 'app_more_10days', 'no_show']\n\n# create new dataframe with relvant variables\ndf_new = df_new[vars_new2].copy()","4cb6fa9a":"# creating new variables scenarios which identify all the possible combinatons from all the relevant variables\ndf_new['scen'] = df_new['scholarship'].map(str)+df_new['hipertension'].map(str)+df_new['sms'].map(str)+df_new['age_40_and_less'].map(str)+df_new['frequenct_2_7'].map(str)+df_new['app_sameday'].map(str)+df_new['app_10_days'].map(str)+df_new['app_more_10days'].map(str)","615a712b":"df_new.head()","c8dc6f9f":"# Creating new data frame grouping the scenario and relating to noshow%\n\ngrouped_scen_mean = df_new.groupby('scen')['no_show'].mean()\ngrouped_scen_count = df_new.groupby('scen')['no_show'].count()\ngrouped_scen = pd.DataFrame({'AVG':grouped_scen_mean, 'counts':grouped_scen_count})\ngrouped_scen['counts_weight'] = grouped_scen['counts'] \/ grouped_scen['counts'].sum()\ngrouped_scen = grouped_scen.sort_values(by='counts_weight', ascending=False)\n\ngrouped_scen['counts_weight'] = round(grouped_scen['counts_weight'], 2)\ngrouped_scen['AVG'] = round(grouped_scen['AVG'], 2)\n","1804ec1d":"grouped_scen.head()","7d6aef1e":"# create dataframe for appointments made each date\nno_app_day = df_new.groupby('appointment_date')['scen'].count()\n\n# Delete outlier '2016-05-14'\nno_app_day = no_app_day.drop(pd.Timestamp('2016-05-14'), axis=0)\nno_app_day.head()","e292cd47":"# Estimation through bootstraping for number of appointments per day\n\nno_days_list = []\nfor i in range(100000):\n    choice = np.random.choice(no_app_day, len(no_app_day))\n    no_days_list.append(choice.mean())\n    \nno_days_array = np.array(no_days_list)","3c5a4be6":"# Visualizing the bootstraping result\nplt.hist(no_days_array, edgecolor='lightgray', bins=100) #\n\npercentile_025 = np.percentile(no_days_array, 2.5)\npercentile_975 = np.percentile(no_days_array, 97.5)\n\nplt.axvline(percentile_025, color='r', ls='--', label='Confidence Interval')\nplt.axvline(percentile_975, color='r', ls='--', label='Confidence Interval')\nplt.axvline(no_days_array.mean(), color='g', ls='--', label='Estimated Average')\n\nplt.title('Confidence interval - Number of Appointments per day')\nplt.xlabel('Number of Appointments per day')\nplt.ylabel('count')\nplt.legend()\n\n#plt.savefig('Estimated_count_per_day.jpg')\n\nnp.percentile(no_days_array, 2.5), np.percentile(no_days_array, 97.5), no_days_array.mean()","296f35da":"# create dataframe for noshow% per day\navg_noshow_day = df_new.groupby('appointment_date')['no_show'].mean()\n\n# Delete outlier '2016-05-14'\navg_noshow_day = avg_noshow_day.drop(pd.Timestamp('2016-05-14'), axis=0)\n#avg_noshow_day","84eaeb4c":"# Estimation through bootstraping for number of appointments per day\n\navg_noshow_list = []\nfor i in range(100000):\n    choice2 = np.random.choice(avg_noshow_day, len(avg_noshow_day))\n    avg_noshow_list.append(choice2.mean())\n    \navg_noshow_array = np.array(avg_noshow_list)","7e2c1be9":"# Visualizing the bootstraping result\nplt.hist(avg_noshow_array, edgecolor='lightgray', bins=100) #\n\npercentile_025 = np.percentile(avg_noshow_array, 2.5)\npercentile_975 = np.percentile(avg_noshow_array, 97.5)\n\nplt.axvline(percentile_025, color='r', ls='--', label='Confidence Interval')\nplt.axvline(percentile_975, color='r', ls='--', label='Confidence Interval')\nplt.axvline(avg_noshow_array.mean(), color='g', ls='--', label='Estimated Average')\n\nplt.title('Confidence interval - Average No-show per day')\nplt.xlabel('Average No-show per day')\nplt.ylabel('count')\nplt.legend()\n\n#plt.savefig('Estimated_AVG_noShow_per_day.jpg')\n\nnp.percentile(avg_noshow_array, 2.5), np.percentile(avg_noshow_array, 97.5), avg_noshow_array.mean()","2645e871":"from matplotlib.patches import Ellipse","6b024b99":"plt.figure(figsize= [7, 7])\n\nplt.scatter(grouped_scen.counts, grouped_scen.AVG);\n\nplt.title(\"Count of appointments Vs No Show% per Scenario\")\nplt.xlabel(\"Count of appointments\")\nplt.ylabel(\"No Show%\")\n\nplt.axhline(df.no_show.mean(), linestyle='dotted', color='r');\nplt.axvline(grouped_scen.counts.mean(), linestyle='dotted', color='r');\n\n\nellips = Ellipse((3700, .29), width=6500, height = .25, fill=False, edgecolor='r',lw=3, alpha=1, angle=0.001) #angle=45) #\nplt.gca().add_patch(ellips)\n\n\nplt.axhspan(0,df.no_show.mean(), color='tab:blue', alpha=.05);\nplt.axvspan(0,grouped_scen.counts.mean(), color='tab:blue', alpha=.05);\n\nplt.xlim(0, 12000)\nplt.ylim(0, 0.7)\n\n\nx_ranges_outliers = [1000, 6000]\ny_ranges_outliers = [0.2, 0.36]\n\nplt.plot(x_ranges_outliers, y_ranges_outliers, color='r', lw=2, alpha=1, ls='dotted');\n\n\nplt.annotate('high count \\nLow No-Show%',xy=(8500, 0.08), \n             xytext=(7500, 0.23), fontsize=12, color='b', arrowprops = dict(facecolor='black')); \n\nplt.annotate('Low count \\nLow No-Show%',xy=(500, 0.045), xytext=(3000, 0.1),\n             fontsize=12, color='g', arrowprops = dict(facecolor='black')); \n\nplt.annotate('Low count \\nHigh No-Show%',xy=(500, 0.35), xytext=(2000, 0.5),\n             fontsize=12, color='y', arrowprops = dict(facecolor='black')); \n\nplt.annotate('High count \\nHigh No-Show%',xy=(3000, 0.28), xytext=(5500, 0.55),\n             fontsize=15, color='r', arrowprops = dict(facecolor='r')); \n\nnote = \"\"\"\nTotal of 24 out of 80 scenarios \ncovering almost 60% of the \nappoinments made with average \nNo-Show 27%, contributing to 80% \nof all the noshows in the dataset.\n\n\"\"\";\nplt.text(6000, .39, note, color='darkred');\n\nplt.text(grouped_scen.counts.mean(), .55, \"Average counts\", color='r', rotation=-90);\nplt.text(9000, df.no_show.mean()-0.02, \"Average No-Shows\", color='r');\n\nplt.savefig('finding_scenarios.jpg')","2465b693":"# new variable columns \"high counts of appointments and high no-show%\"\ngrouped_scen['high_high'] = (grouped_scen['AVG'] >0.15) & (grouped_scen['counts'] >1000)\ngrouped_scen['count_noshow'] = round((grouped_scen['counts'] * grouped_scen['AVG']),0)\ngrouped_scen['count_show'] = grouped_scen['counts'] - grouped_scen['count_noshow']","b6e9de56":"grouped_scen.head()","ecbf5d88":"# New dataframe grouped_scen2, grouping by columns \"high counts of appointments and high no-show%\"\n\ngrouped_scen2 = grouped_scen.groupby('high_high')['counts', 'count_noshow'].sum()\ngrouped_scen2['avg_noshow'] = grouped_scen2['count_noshow'] \/ grouped_scen2['counts']\ngrouped_scen2['counts_weight'] = grouped_scen2['counts'] \/ grouped_scen2['counts'].sum()\ngrouped_scen2['counts_weight'] = round(grouped_scen2['counts_weight'],2)\ngrouped_scen2['noshow_weight'] = grouped_scen2['count_noshow'] \/ grouped_scen2['count_noshow'].sum()\ngrouped_scen2['noshow_weight'] = round(grouped_scen2['noshow_weight'],2)\ngrouped_scen2 = grouped_scen2.reindex([True, False])\ngrouped_scen2['count_of_scenarios'] = [24, 56]","bda12095":"grouped_scen2","b8ee063c":"xrange = np.arange(len(grouped_scen2))\nwidth = 0.2\n\nplt.figure(figsize=[7,5]);\nplt.bar(xrange, grouped_scen2.counts, width, label='Total');\nplt.bar(xrange + width, grouped_scen2.count_noshow, width, label='No-Show');\nplt.legend(); \nplt.xticks(xrange + (width\/2), ['High count | High No-Show', 'Other Scenarios']);\nplt.ylim(0, 75000);\n\nplt.title(\"Scenarios Categories\");\nplt.ylabel('Counts');\nplt.xlabel('Category Name');\n\nplt.annotate('27% \\nAverage \\nNo-Show',xy=(0.2, 25000), xytext=(0.3, 40000),\n             fontsize=15, color='r', arrowprops = dict(facecolor='r')); \n\nplt.annotate('9% \\nAverage \\nNo-Show',xy=(1.2, 8000), xytext=(0.45, 20000),\n             fontsize=15, color='g', arrowprops = dict(facecolor='g')); \n\nfor i in xrange:\n    plt.text(xrange[i] - (width\/3.5), grouped_scen2.counts.iloc[i] * 1.05, int(grouped_scen2.counts.iloc[i]))\n    plt.text(xrange[i] + (width\/1.5), grouped_scen2.count_noshow.iloc[i]* 1.1, int(grouped_scen2.count_noshow.iloc[i]))\n#str(round(day_difference_df.AVG.iloc[i - 1],2)), fontsize = 25, color='w'\n\n#plt.savefig('scenarios_avg_noshow_comparison.jpg')\n","7e9ca7f2":"#isolating the scenarios to put them in an easily readable format\n\n#create new df with specific variable of interest and remove duplicates\ndf_new_dupl = df_new.drop(columns=['appointment_id', 'appointment_date', 'no_show']).copy()\ndf_new_dupl = df_new_dupl.drop_duplicates().copy()\n\n#merge 2 dfs (the grouping of scenario and variables of the scenarios)\ndf_fin = df_new_dupl.merge(grouped_scen, left_on='scen', right_on=grouped_scen.index, how='left')\n\n","472cd3f2":"# considering also the scenarios with high counts and high noshow%\ndf_fin_noshow  = df_fin[df_fin['high_high'] == True].sort_values(by=['AVG', 'counts'], ascending = [False, False])\n\n#identify variables to be transformed\nvars_noshow = ['hipertension', 'sms', 'age_40_and_less', 'frequenct_2_7', 'app_10_days']\ntransforming_variables = df_fin_noshow[vars_noshow].copy()","1058569e":"df_fin_noshow.head()","a772d2c5":"# iterating over the dataframe to create a list with the descriptions of each scenario\nlist_vars = []\n\nfor i, value in transforming_variables.iterrows():\n    list = value.values\n    \n    \n    if list[0] == 1:\n        hiper = \"- Have Hipertension\"\n    else:\n        hiper = \"\"\n#----------------------------------------------      \n        \n    if list[1] == 1:\n        sms = \"- Remidner SMS sent -\"\n    else:\n        sms = \"- Remidner SMS not sent -\"\n#---------------------------------------------- \n        \n    if list[2] == 1:\n        age = \"- Age equal or less than 40 -\"\n    else:\n        age = \"- Age greater than 40 -\"\n#---------------------------------------------- \n        \n    if list[3] == 1:\n        freq = \"- Frequent patient -\"\n    else:\n        freq = \"\"\n#---------------------------------------------- \n        \n    if list[4] == 1:\n        appo = \"Appointment within 2 - 10 days \"\n    else:\n        appo = \"Appointment After 10 days \"\n#---------------------------------------------- \n           \n    all_vars = str(appo) + str(age) + str(freq) + str(sms) + str(hiper)\n    list_vars.append(all_vars)\n    ","38ac22d1":"#adding the newly created list of discriptions to the dataframe\ndf_fin_noshow['scenario_details'] = list_vars\n\n#creating final dataframe with final needed information\ndf_final = df_fin_noshow[['scenario_details', 'counts','count_noshow', 'AVG', 'counts_weight']].reset_index(drop=True)\n\n# string change for readability\ndf_final['scenario_details'] = df_final['scenario_details'].str.replace(\"--\", \"-\")\ndf_final['scenario_details'] = df_final['scenario_details'].apply(lambda x: x[:-2] if x[-2:] == \" -\" else x[:])\ndf_final['scenario_details'] = df_final['scenario_details'].str.replace(\"--\", \"-\")\ndf_final.columns = ['Scenarios Details', 'Count of Appointments', 'count of No-Shows', 'Average No-show', 'Count of Appointments weightage']","6716b0a3":"scenarios_ranges = np.linspace(1, len(df_final), 24)\n\nplt.figure(figsize=[15,5])\nplt.bar(scenarios_ranges, df_final['Count of Appointments weightage'], color='lightcoral', label='Weightage% of All No-Shows');\nplt.axhspan(0,.06, color='lightcoral', alpha=0.05)\nplt.axhline(0.06, color='r', alpha=1, ls='dotted')\n\nplt.plot(scenarios_ranges, df_final['Average No-show'], marker='o', label='Average No-Show');\nplt.axhline(0.27, ls='dotted', label='Average No-show for Specific Scenarios', color='r')\nplt.axhline(0.20, ls='dotted', label='Average No-show for all Scenarios')\n\nplt.title('A closer look to scenarios with high count and high No-show%')\nplt.xlabel('Scenario Number')\nplt.ylabel('Percentage %')\n\n\nplt.text(0.5, 0.25, 'Average No-show for Specific Scenarios', color='r');\nplt.text(0.5, 0.18, 'Average No-show for all Scenarios', color='tab:blue');\n\nplt.text(0.5, 0.1,\n         '80% of No-shows are included in the below 24 Scenarios out of all 80 scenarios in the dataset',\n         color='r');\n  \nplt.legend();\nplt.xticks(scenarios_ranges);\n\n\nfinal_counts_array = np.array(df_final['Count of Appointments weightage'])\nfinal_avg_array = df_final['Average No-show']\n\nplt.ylim(0,0.45)\nfor i in range(len(scenarios_ranges)):\n    plt.text(scenarios_ranges[i] - 0.5, 0.07, round(final_counts_array[i],2), color='lightcoral', fontsize = 10)\n    plt.text(scenarios_ranges[i], final_avg_array[i]+0.01, round(final_avg_array[i],2), color='tab:blue', fontsize = 10)\n\n\n#plt.savefig('linechart_scenarios.jpg')\n    ","41fc3b86":"pd.set_option(\"display.max_colwidth\", -1)\ncolor_map = plt.cm.get_cmap('Wistia')\ndf_final.style.background_gradient(cmap =color_map)","2c3818e9":"- ***Estimate total appointments expected per day***","62ffc1d4":"- ***Create new variables to seperate scenarios with High count and High No-Show% from other scenarios***","0122ed13":"Summary statistics about each category of neighborhood variable","1b2e66b4":"- ***Drop columns which has no significant contribution to No-Show%***","24294bd6":"- ***change column names for convenience and easy manipulation***","9db531aa":"**Research Question 6**: what are the insights and trends in variable `Patient id`?\n- Total patients on the dataset are 62,298, majority of them (60.87%) have made 1 appointment during the period of 7 months, contributing to 34.31% of all appointments made\n- Patients who made more than 1 appointment are distributed over a very huge range starting from 2 appointments up to some patients who made 88 appointment, contributing to almost 65% of all appointments made\n- Assuming that patients who make more than 7 appointment on average are chronic patients, and patients who make more than 1 appointment but not more than 7 appointments are frequent patients *\"Identifing Frequent patients as those ones who make at least 1 appointment for each month in the dataset\"*, we divide the patients into 3 categories:\n    - First Time patient\n    - frequent patient\n    - Chronic Patient\n- Patients who are categorized as frequent are having the highest contribution to overall appointments made 58.64%, thus we divid the patients to 2 categories those who are in \"2 to 7\" category and those who are not.","1f01151c":"- ***Model the scenarios and identify the relaionship between scenarios count and No-Show% per scenario***","edc8dec0":"### Data Cleaning 3\n\n1. Drop columns which has no significant contribution to No-Show%\n2. Create new variable \"Scenarios\" which combines all the features in the dataset into 1 string value\n3. Create new dataframe grouping the scenarios sums and count","b63589b7":"- ***Convert column handcap attributes to binary***\n\nchange the variable values to binary result with 0 and 1 values, because the column contain unique values between 0 to 4, however all the values above 0 have a very minimal contribution in the data, Almost 2% only and there is no clear disntinctive description for the differences between each value\n\n","14bd217f":"<a id='eda'><\/a>\n## Exploratory Data Analysis","5d508d2c":"- ***Create new dataframe which has the scenarios sum and count***","4aeb2701":"- ***Convert Age category column to a binary column with name \"age_40_and_less\" and value 0, 1***","4f686af1":"<a id='intro'><\/a>\n## Introduction\n\n### Project Description \nThis project is part of the **Advanced Data Analysis Nanodegree Program** by Udacity a scholarship by **(Egypt FWD)** Future work is a digital initiative powered by Information Technology Industry Development Agency **(ITIDA)** to upskill Web, Data and Digital marketing tech skills for jobs of the future, to equip and train 100,000 young Egyptians for digital technologies and skills to remote work and local market opportunities.\n\n### Dataset Description \nThe Investigate a Dataset project!, The dataset collects information from more than 100k medical appointments in Brazil and is focused on the question of whether or not patients show up for their appointment.\n The Project Medical Appointments No Shows is investigating Medical Appointment No Shows dataset which contains historical data for more than 110K appointments made accross different medical facilities in Brazil for more than 60k patients, for each record there are 14 Variables, metadata related to appointments date, patients gender, age,medical condtion, social support coverage and facilities and 1 TARGET variable \"Wither the patient attended the appointment or not, read through the description available on the homepage-links present [here](https:\/\/docs.google.com\/document\/d\/e\/2PACX-1vTlVmknRRnfy_4eTrjw5hYGaiQim5ctr9naaRd4V9du2B5bxpd8FEH3KtDgp8qVekw7Cj1GLk1IXdZi\/pub?embedded=True)\n\n### Project Target\n\nWhat is the explanation for a person making a doctor appointment, receives all the instructions and no-show. Who to blame?\n\n\n###### Project By\nHossam Megahed\n","efbc6538":"<a id='Executive'><\/a>\n\n## Executive Summary\n\n<p> \nWith thorough inspection, data wrangling and cleaning, testing hypotheses and feature engineering, it was concluded there are 5 main contributing factors on whether the patient attend to his appointment in the scheduled or not? \nContributing factors are:\n<ul>\n  <li>The duration between the appointment scheduling date and Appointment date <em>\"The more the duration increased the less probable the patient to attend\"<\/em>. <\/li>\n  <li>The frequency of appointments  <em>\"Whether the patient is making his first appointment or not?\"<\/em><\/li>\n  <li>Age or the patients<\/li>\n   <li>Whether the patient recieved a reminder sms about his appointment date or not?<\/li>\n   <li>Does the patient suffer from hipertension?<\/li>\n<\/ul>\nAt any given working day, it's expected that all 81 facilities included in the dataset will receive on average 4250 appointments, 95% confidence interval (4125 to 4355) appointments, and the No-show average at 95% confindence interval, will be(19.5% to 20.9%) per day \n<\/p> \n\n> **Considering the most contributing attributes, it was concluded that thier is a total of 80 scenarios covering all the possible combinations of all relevant features, out of the 80 scenarios, there are 24 scenarios which covers total of 80% of all the No-shows cases, contributing to almost 60% of all the data records**\n\n![photo](.\/finding_scenarios.jpg)\n\n\n\n### Questions for Analysis\n\n1. What are the insights and trends in variable `scheduling date`?<br><br>\n2. What are the insights and trends in variable `appointment date`?<br><br>\n3. What are the insights and trends in variable `age`?<br><br>\n4. What are the insights and trends in variable `neighborhood`?<br><br>\n5. What are the insights and trends in Binaty variables\n`scholarship` - `hipertension` - `diabetes` - `alcoholism` - `handcap` - `sms`?<br><br>\n6. What are the insights and trends in variable `Patient id`?<br><br>\n7. Is there a relationship between variable `age` and target variable `no-show`?<br><br>\n8. Is there a relationship between variable `day_diff` \"difference in days between appointment date and scheduling date\" and target variable `no-show`?<br><br>\n9. Is there a relationship between variable `appointments_demand` \"appointments demand category per neighborhood\" and target variable `no-show`?<br><br>\n10. Is there a relationship between variable `frequency` \"patients who made 2 to 7 appointments and others\" and target variable `no-show`?<br><br>\n11. Is there a relationship between variable `frequency` \"patients who made 2 to 7 appointments and others\" and target variable `no-show`?<br><br>\n12. Is there a relationship between binary variable `scholarship` - `hipertension` - `diabetes` - `alcoholism` - `handcap` - `sms` and target variable `no-show`?<br><br>","efc1b6f5":"Test significance in variable Age for age above or below 40","8acee54c":"***\n- ***Function to test and visualize (hypothesis testing for significance)*** \nBelow are 2 functions to\n1. Function `stat_test` to test significance in variance for binary variables \n2. Function `hist_plot_sig_test` to visualize the significance test result","2840358d":"- ***Create new variable `day_diff` measures difference in days between appointment date and scheduling date***","0aca507e":"**Research Question 5**: what are the insights and trends in Binaty variables\n`scholarship` - `hipertension` - `diabetes` - `alcoholism` - `handcap` - `sms`?\n- Almost 10% of all appointments made were for patients covered by the social support program\n- 20% of all appointments made were for patients suffering from Hypertension\n- 7% of all appointments made were for patients suffering from Hypertension\n- 3% of all appointments made were for patients suffering from alcohol problem\n- 2% of all appointments made were for patients are handicapped\n- 32% of all appointments made were for patients have received remider sms's about appointment timing\n","5fe261cc":"- ***Comparing scenarios with High count and High No-Show% Vs. Other Categories***","640ffb32":"**Research Question 8**: Is there a relationship between variable `day_diff` \"difference in days between appointment date and scheduling date\" and target variable `no-show`?\n\n- Calculating the difference in days between Scheduling date and appointment date, we found out that almost 35% of the patients make thier appointments in the same day, 30% within 10 days and the other 35% of the scheduling are disributed over the whole period of 7 months however most of the records are after march 2016\n\n- Increase in delay in days difference we can see that the No show% increases severally as detailed below:\n    - 20% increase in noshow% between the first 2 categories\n    - 26% increase in noshow% between the first and last category","2c54e080":"Summary statistics about the patient categories newly constructed","838f6165":"- ***Change columns patientid, appointmentid to string***","9217ac1c":"<a id='conclusions'><\/a>\n## Conclusions \n\n1. For all locations (81 facility), it's expected that they will be receiving on average amount of 4250 appointments per day, with 95% confidence interval, we can conclude that thery will be having between 4125 to 4355 appointments per day <br><br>\n2. The Estimated No-Show% for any given day is between (19.5% to 20.9%) at a 95% confidence interval<br><br>\n3. There are 5 main  contributing factors on whether the patient attend to his appointment in the scheduled or not? Contributing factors are:\n    - The duration between the appointment scheduling date and Appointment date \"The more the duration increased the less probable the patient to attend\".\n    - The frequency of appointments \"Whether the patient is making his first appointment or not?\"\n    - Age or the patients\n    - Whether the patient recieved a reminder sms about his appointment date or not?\n    - Does the patient suffer from hipertension?\n<br><br>\n4. it was concluded that total of 80 scenarios covering all the possible combinations of all relevant features in the dataset, out of the 80 scenarios, **there are 24 scenarios where the average No-Show% is 27% and these scenarios covers a total of 80% of all the No-shows cases and contributing to almost 60% of all the data records**.","b37843ff":"Divide the patient into 3 categories(First Time, frequent and chronic)","b50c1a77":"- ***Create new variable \"Scenarios\" which combines all the features in the dataset into 1 string value***","bc0a53fa":"**Research Question 4**: what are the insights and trends in variable `neighborhood`?\n\n- There are 81 neighborhoods in the dataset, Majority of the patients are residing in 8 main neighborhoods.\n- Neighborhood can be distributed over 4 main categories:\n    - Very High Demand Neighborhood: 8 out of 81 Neighborhood contributes to more than 31% of appointments count, with average of 4367 Appointments\n    - High Demand Neighborhood: 13 Neighborhood covers 28% of total appointments, with average of 2439 Appointments\n    - Medium Demand Neighborhood: 18 Neighborhood covers almost 24% of total appointments, with average of 1484 Appointments\n    - Low Demand Neighborhood: 40 Neighborhood \"More than 50% of all locations\" covers 15% of total appointments, with average of 409 Appointments","152dac38":"Building a function to split ages into categories of 10 years interval","e0e9de83":"<a id='wrangling'><\/a>\n## Data Wrangling\n\n### General Properties","5f89648a":"- ***Change column name \"frequency\" to frequency_2_7 with values 0, 1***","5755324a":"**Research Question 7**: is there a relationship between variable `age` and target variable `no-show`?\n\n- Converting Age variable to categories of 10 years interval, will see that the higher the age the average of no show gets decreased\n\n- In the graph below we can see that the average no show for people with greater than 40 is 5% less than the ages from 0 to 40, testing the statistical significant of this variance we can see that it's almost 0.0 probability that the variance is due to random chance\n","e3a99ffc":"- ***Split columns \"day_diff\" to 3 binary columns with values 0, 1***","37ac0ab4":"- ***Create a final dataframe with user friendly readable information about the modeled scenarios***","ae40f107":"### Data Cleaning 2\n\n1. Convert Age category column to a binary column with name \"age_40_and_less\" and value 0, 1\n2. Change column name \"frequency\" to frequency_2_7 with values 0, 1\n3. Split columns \"day_diff\" to 3 binary columns with values 0, 1\n4. Create new dataframe with variables that only have significant contribute to No-Show%","715ac0d2":"**Research Question 9**: Is there a relationship between variable `appointments_demand` \"appointments demand category per neighborhood\" and target variable `no-show`?\n\n- Considering how much appointments the facilities receive, it doesn't seem that the load on the facility has an effect on the whether the patient will show up to his appointment or not","70299fe7":"- ***Transform the scenario codes and readable information***","3fd33560":"### Data Cleaning\n\n1. Change column names and put them in lower case form\n2. Adjust variables Data types: \n    - PatientId: `float` >> `string` \n    - AppointmentID: `int` >> `string` \n    - ScheduledDay: `string` >> `date`\n    - appointmentday: `string` >> `date`\n    - no-show `string` >> `int` with binary values (0, 1)\n3. Adjust values in variable `Age` values where age is less than 0 and greater than 122 years\n4. Convert `handcap` variable to binary\n5. Convert `no-show` variable to binary\n6.  Create new variable `day_diff` measures difference in days between appointment date and scheduling date\n\n","e1adf578":"- ***Create new dataframe with variables that only have significant contribute to No-Show%***","30f56f5b":"**Research Question 10**: Is there a relationship between variable `frequency` \"patients who made 2 to 7 appointments and others\" and target variable `no-show`?\n \n- Patients who made 2 to 7 appointments has 21% No-show%, while other categories have No-show% of 18.7% \n- Variance in No-show% between the 2 categorizations is 2.3%","b5e73dea":"# Project: Investigate Medical Appointments No Shows\n###### Investigating Medical Appointment No Shows dataset \n\n\n## Table of Contents\n<ul>\n<li><a href=\"#intro\">Introduction<\/a><\/li>\n<li><a href=\"#Executive\">Executive Summary<\/a><\/li>\n<li><a href=\"#wrangling\">Data Wrangling<\/a><\/li>\n<li><a href=\"#eda\">Exploratory Data Analysis<\/a><\/li>\n<li><a href=\"#conclusions\">Conclusions<\/a><\/li>\n<\/ul>\n\n\n","c30baddd":"- ***Filter the final dataframe to include the data for scenarios with High count and high No-Show% only***","71810969":"- ***Convert column no-show attributes to binary***","0dd2fd2d":"**Research Question 2**: what are the insights and trends in variable `appointment date`?\n\n- Appointments dates are distributed over the period of 40 days starting from the 29 April 2016 to 8 June 2016 , however dates which had appointments are only for 27 days\n\n- Average appointments per day is 4093, however if we removed the outlier date '2016-05-14' where there was only 39 dates then the average will become 4249","8d9cd4c4":"- ***Create new dataframe grouping scenarios with High count and High No-Show%***","0d4d0683":"**Research Question 12**: Is there a relationship between binary variable `scholarship` - `hipertension` - `diabetes` - `alcoholism` - `handcap` - `sms` and target variable `no-show`?\n \n- Variables `Diabetes` - `Alcoholism` - `Handcap` doesn't have any representing weightage in the dataset and also there is no dinstinctive representation when we try to compare the variable average on the dataset for patients who showed up and those who didn't\n- Variables `Scholarship` - `hipertension` - `sms received` seems to have difference in weightage when compared to whether the patient showed up or not, therefore we conducted a hypothesis testing on the 3 variables and it was concluded that they have statistical siginificance in contributing to No-Show%","bd6f6464":"- ***Convert columns Scheduling date and Appointment date to date time***","f8cce7d9":"**Research Question 3**: what are the insights and trends in variable `age`?\n\n- Average appointments per age 1073, however infants age 0 and age 1 has the highest contribution with mean 1704 with almost 700 appointments above the dataset average\n- Ages between 3 to 60 have an approximate uniform distribution with mean of \"1487\" appointments per day\n- Ages +60 have a negative linear relationship with count of appointments\n- Most of the counts per age falls within 1000 to 2000","8e7deb88":"- ***Estimate expected No-Show% per day***","e3ee7b7f":"- ***List all the failed scenarios details***","3c49594f":"**Research Question 11**: Is there a relationship between variable `frequency` \"patients who made 2 to 7 appointments and others\" and target variable `no-show`?\n \n- Female patients contribute to almost 65% of all the data records, however it's seems that gender doesn't have an effect on No Show% considering:\n    - No-Show% for Males is 20.3%\n    - No-Show% for Females is 19.9%","895a54f6":"- ***Adjust values for variable `Age`***\ndrop all age values where age is less than 0.\n","57b6d2b0":"**Research Question 1**: what are the insights and trends in variable `scheduling date`?\n- The scheduling day dates are spread accross the period of 7 months (211 Days), starting from 10 November 2015 to 08 June 2016, However more than 99% is located between 01 March 2016 to 08 June 2016\n- Average booking per day is 995 appointment however if we excluded total of 403 transcation made before the date of 01 March 2016, the average will increase to 1529 booking per day.\n- Distribution of booking is heavily left skewed\n- Maximum booking per day was registered at 3rd of May 2016 with total bookings of 4238 appointments scheduled","a6730053":"Create new variable `appointments_demand` to identify the category of the neighborhood","9f998c85":"Test significance for variables `Scholarship` - `hipertension` - `sms received`"}}