{"cell_type":{"3d07e963":"code","f40990d2":"code","e2ae94b6":"code","68ad9d96":"code","3e376f67":"code","a22b9b74":"code","1fc6b08c":"code","fdb6b23a":"code","49f4e4b0":"code","5e1eaf7b":"code","bafd3c21":"code","e0e6ea14":"code","e4951703":"code","22f12deb":"code","c00534fc":"code","74285343":"code","2d1b2a6e":"code","78d2ff89":"code","c8501502":"code","3e49577b":"code","857b134e":"code","52aa47a5":"code","fb0b7102":"code","aa55bd75":"code","b0988589":"code","dcbad475":"code","0351486c":"code","0b7f79f7":"code","e64c2419":"code","7a6462bf":"code","42ed4d8e":"code","c582776f":"code","30660674":"code","b4524298":"code","45c4a838":"code","773725f1":"code","a4cc3d26":"code","87b1d1dd":"code","539f010a":"code","1f95e62e":"code","d8094edf":"code","b23f5ec5":"code","6d72c7ad":"code","b8ff562e":"code","92b88627":"code","7ce2b985":"code","904306e5":"code","65b01711":"code","a5bf9915":"code","3cf9f10f":"code","f079fbde":"code","b485e804":"markdown","b7e9bf61":"markdown","780d2608":"markdown","d422c5b5":"markdown","be09fc99":"markdown","75b305da":"markdown","d63bd867":"markdown","dbdd2088":"markdown","92566c75":"markdown","b8f2859d":"markdown","40d6f8cf":"markdown","3b035adb":"markdown","cd84682d":"markdown","8bc694a3":"markdown","d99d9b57":"markdown","f01bc9f6":"markdown","3a45a503":"markdown","b5a01fd8":"markdown","631907a5":"markdown","4b983f99":"markdown","42bb9b7b":"markdown","a0cd1793":"markdown","d86da3c6":"markdown","2b5aaa77":"markdown","b911ae7c":"markdown","49433339":"markdown","a5e8f656":"markdown","27746c49":"markdown","9b0f895d":"markdown","7fcec44b":"markdown","ae957e1f":"markdown","fa01f4b4":"markdown","deb372d8":"markdown","2ba485aa":"markdown","0e666b8a":"markdown","afbd80bc":"markdown","5bdaf065":"markdown","20a81144":"markdown","f68b44a8":"markdown","c08e02c3":"markdown","ebfa433e":"markdown","15abe037":"markdown","618bd55a":"markdown","98a5c344":"markdown","bdd9fbc4":"markdown","ef195a68":"markdown","2fa9275a":"markdown","3635b71c":"markdown","08c11176":"markdown","b19255da":"markdown","a0bcd08b":"markdown","6640d82c":"markdown","603c27dd":"markdown","c3dc783c":"markdown","195ffc3b":"markdown","c0298bf9":"markdown","55deaa7b":"markdown","0bf3e465":"markdown","88113d5a":"markdown","7fe5c267":"markdown","b09a5ade":"markdown","bc2295ff":"markdown","68f58232":"markdown","1fef7510":"markdown","2597a0a9":"markdown","ecef936a":"markdown","c6069d3b":"markdown","21ec551a":"markdown","70548d99":"markdown","edb13ec4":"markdown","575061c1":"markdown","5bca1778":"markdown","7ed33324":"markdown","f284105f":"markdown","2c95fec8":"markdown","cfad4716":"markdown","d1e3edeb":"markdown","f0c43ad8":"markdown","74bf74be":"markdown","00f93090":"markdown"},"source":{"3d07e963":"from traitlets.config.manager import BaseJSONConfigManager\nfrom pathlib import Path\npath = Path.home() \/ \".jupyter\" \/ \"nbconfig\"\ncm = BaseJSONConfigManager(config_dir=str(path))\ncm.update(\n    \"rise\",\n    {\n        \"scroll\": True,\n        \"enable_chalkboard\": True\n     }\n)\n# PLEASE IGNORE ABOVE CELL, JUST TO CONFIGURE SLIDES\n# RUN THIS CELL ONCE TO ENSURE SMOOTH SLIDES FUNCTIONING\n# AFTER EXECUTING THIS CELL ONCE, SAVE AND THEN RELOAD PAGE TO ENSURE CHANGES ARE SAVED","f40990d2":"# %%capture\n# !pip install pytorch_pretrained_bert\n# !pip3 install http:\/\/download.pytorch.org\/whl\/cu80\/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n# !pip3 install torchvision\n! pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html\n# !pip install imbalanced-learn","e2ae94b6":"import torch","68ad9d96":"x = torch.empty(3, 4)\nprint(x)\nprint(x.size())","3e376f67":"x = torch.rand(3, 4)\nprint(x)\nprint(x.size())","a22b9b74":"x = torch.zeros(3, 4, dtype=torch.long)\nprint(x)","1fc6b08c":"x = torch.zeros(3, 4, dtype=torch.float32)\nprint(x)","fdb6b23a":"x = torch.ones(3, 4, dtype=torch.long)\nprint(x)","49f4e4b0":"x = torch.ones(3, 4, dtype=torch.float32)\nprint(x)","5e1eaf7b":"x = torch.eye(4)\nprint(x)","bafd3c21":"x = torch.eye(4, dtype=torch.long)\nprint(x)\nprint(x.type())","e0e6ea14":"x = torch.tensor([10.5, 9.2, 7])\nprint(x)\nprint(x.size())","e4951703":"x.type()","22f12deb":"x = torch.tensor([[10.5, 9.2, 7], [1, 2, 3]])\nprint(x)\nprint(x.size())","c00534fc":"print(x)\nx = torch.ones_like(x)\nprint(x)","74285343":"print(x.size())\nx = torch.ones(x.size())\nprint(x)","2d1b2a6e":"x = torch.rand(3, 4)\ny = torch.randn(x.size())\nprint('x = ', x)\nprint('y = ', y)","78d2ff89":"torch.add(x, 10)","c8501502":"x+10","3e49577b":"x+y","857b134e":"torch.add(x,y)","52aa47a5":"x+y*10","fb0b7102":"torch.add(x, y, alpha=10)","aa55bd75":"res = torch.add(x,y)\nprint(res)","b0988589":"x = x+y\nprint(x)","dcbad475":"x.add_(y)","0351486c":"print(x[:, 1])","0b7f79f7":"x = torch.randn(4, 4)\ny = x.view(16)\nz = x.view(-1, 8)  # the size -1 is inferred from other dimensions\nprint(x.size(), y.size(), z.size())\n","e64c2419":"x = torch.randn(1)\nprint(x)\nprint(x.item())\n","7a6462bf":"import numpy as np","42ed4d8e":"a = torch.ones(5)\nprint(a)\nb = a.numpy()\nprint(b)","c582776f":"a.add_(1)\nprint(a)\nprint(b)","30660674":"a = np.ones(5)\nb = torch.from_numpy(a)\nnp.add(a, 1, out=a)\nprint(a)\nprint(b)","b4524298":"# let us run this cell only if CUDA is available\n# We will use ``torch.device`` objects to move tensors in and out of GPU\ndevice = torch.device(\"cpu\")\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")          # a CUDA device object\n    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n    z = x + y\n    print(z)\n    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!","45c4a838":"import torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt","773725f1":"import torchvision\nimport torchvision.transforms as transforms","a4cc3d26":"trainset = torchvision.datasets.FashionMNIST(root = \".\/data\", \n                                             train = True, \n                                             download = True, \n                                             transform = transforms.ToTensor())","87b1d1dd":"testset = torchvision.datasets.FashionMNIST(root = \".\/data\", \n                                            train = False, \n                                            download = True, \n                                            transform = transforms.ToTensor())","539f010a":"#loading the training data from trainset\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle = True)\n#loading the test data from testset\ntestloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)","1f95e62e":"class_labels = ['T-Shirt','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']\nfig = plt.figure(figsize=(15,8));\ncolumns = 5;\nrows = 3;\nfor i in range(1, columns*rows +1):\n    index = np.random.randint(len(trainset))\n    img = trainset[index][0][0, :, :]\n    fig.add_subplot(rows, columns, i)\n    plt.title(class_labels[trainset[index][1]])\n    plt.axis('off')\n    plt.imshow(img, cmap='gray')\nplt.show()","d8094edf":"print(class_labels[trainset[0][1]])\nplt.imshow(trainset[0][0][0, :, :], cmap='gray')","b23f5ec5":"class SimpleNeuralNet(nn.Module):\n    \n    def __init__(self):\n        super(SimpleNeuralNet, self).__init__()\n#         flattening a 28x28 image into 784 dimensional 1d tensor\n        self.flatten1 = nn.Flatten()\n        self.layer1 = nn.Linear(784, 512)\n        self.layer2 = nn.Linear(512, 256)\n        self.layer3 = nn.Linear(256, 128)\n        self.layer4 = nn.Linear(128, 10)\n        self.dropout = nn.Dropout(0.25)\n    \n    def forward(self, x):\n#         print('Initial size = ', x.size())\n        x = self.flatten1(x)\n#         print('After size = ', x.size())\n        out = F.relu(self.layer1(x))\n        out = F.relu(self.layer2(out))\n#         out = self.dropout(out)\n        out = F.relu(self.layer3(out))\n        out = self.layer4(out)\n        \n        return out\n    \n    def num_flat_features(self, x):\n        size = x.size()[1:]  # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features","6d72c7ad":"model = SimpleNeuralNet()\nprint(device)\nmodel = model.to(device)\nprint(model)\n\ncross_entropy_loss = nn.CrossEntropyLoss()\n\nadam_optim = torch.optim.Adam(model.parameters(), lr=0.005)\nprint(adam_optim)","b8ff562e":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n\ndef eval_perfomance(dataloader, print_results=False):\n    actual, preds = [], []\n    #keeping the network in evaluation mode  \n    model.eval() \n    for data in dataloader:\n        inputs, labels = data\n        actual +=[i.item() for i in labels]\n        \n        #moving the inputs and labels to gpu\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        _, pred = torch.max(outputs.data, 1)\n        pred = pred.to(device)\n        preds += [i.item() for i in pred]\n    acc = accuracy_score(actual, preds)\n    cm = confusion_matrix(actual, preds)\n    cr = classification_report(actual, preds)\n    if(print_results):\n        print(f'Total accuracy = {acc*100}%')\n        print('\\n\\nConfusion matrix:\\n')\n        print(cm)\n        print('\\n\\nClassification Report:\\n')\n        print(cr)\n    \n    return acc","92b88627":"intial_acc = eval_perfomance(testloader, True)","7ce2b985":"# %%time\nloss_arr = []\nloss_epoch_arr = []\nmax_epochs = 5\niter_list = []\ntrain_acc_arr = []\ntest_acc_arr = []\nctr = 0\nfor epoch in range(max_epochs):\n    for i, data in enumerate(trainloader, 0):\n        \n        model.train()\n        images, labels = data\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)      \n        \n        loss = cross_entropy_loss(outputs, labels)    \n        adam_optim.zero_grad()     \n\n        loss.backward()     \n        adam_optim.step()     \n        loss_arr.append(loss.item())\n        \n        ctr+=1\n        iter_list+=[ctr]\n    \n        \n    train_acc = eval_perfomance(trainloader)\n    train_acc_arr+=[train_acc.item()]\n        \n    test_acc = eval_perfomance(testloader)\n    test_acc_arr+=[test_acc.item()]\n        \n    if((epoch+1)%1==0):\n        print(f\"Iteration: {epoch+1}, Loss: {loss.item()}, Train Acc:{train_acc}, Val Acc: {test_acc}\")\n\n    loss_epoch_arr.append(loss.item()) ","904306e5":"plt.plot([i for i in range(len(loss_epoch_arr))], loss_epoch_arr)\nplt.xlabel(\"No. of Iteration\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss vs Iterations\")\nplt.show()","65b01711":"plt.plot([i for i in range(len(train_acc_arr))], train_acc_arr)\nplt.xlabel(\"No. of Iteration\")\nplt.ylabel(\"Train Accuracy\")\nplt.title(\"Train Accuracy\")\nplt.show()","a5bf9915":"plt.plot([i for i in range(len(test_acc_arr))], test_acc_arr)\nplt.xlabel(\"No. of Iteration\")\nplt.ylabel(\"Test Accuracy\")\nplt.title(\"Test Accuracy\")\nplt.show()","3cf9f10f":"class_correct = [0. for _ in range(10)]\ntotal_correct = [0. for _ in range(10)]\n\nwith torch.no_grad():\n    for images, act_labels in testloader:\n#         images, labels = images.to(device), labels.to(device)\n#         test = Variable(images)\n        images, act_labels = images.to(device), act_labels.to(device)\n        outputs = model(images)\n        #Returns a namedtuple (values, indices) where values is the maximum value of each row of the input tensor in the given dimension dim.\n        predicted = torch.max(outputs, 1)[1] \n        #print(\"Predicted: \", predicted)\n        #print(\"predicted ==  act_labels\", predicted == act_labels)\n        c = (predicted == act_labels).squeeze()\n        #print(\"c :\",c)\n        \n        for i in range(4):\n            label = act_labels[i]\n            class_correct[label] += c[i].item()\n            total_correct[label] += 1\n        \nfor i in range(10):\n    print(\"Accuracy of {}: {:.2f}%\".format(class_labels[i], class_correct[i] * 100 \/ total_correct[i]))","f079fbde":"final_acc_test = eval_perfomance(testloader, print_results=True)","b485e804":"### Performance Metrics\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1_lz6a3aPccspKDJeJmBkx-EpezuqyFjT\">","b7e9bf61":"### Effect of bias in a linear graph\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1mz1DR1tip1OOJ4G6xS3BSAZNXh7dgoYm\">","780d2608":"### Overfitting\n<ul>\n    <li>Split data into training and validation dataset to generally get an intuition.\n<\/li>\n    <li>Usually if models are too deep, they tend to overfit.\n<\/li>\n    <li>But it\u2019s a bad choice to make the models shallower for the sake of decreasing overfitting. Instead we can use a concept called Regularization\n<\/li>\n<\/ul>","d422c5b5":"Note: `torch.Size` is in fact a tuple, so it supports all tuple operations.","be09fc99":"## Using GPUs with CUDA","75b305da":"To create an uninitialised tensor we use the following commands. The tensors are assigned whatever values that are present in the unallocated memory at the time of creation.\n<br><br>\n***torch.empty(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False) \u2192 Tensor***\n\nReturns a tensor filled with uninitialized data. The shape of the tensor is defined by the variable argument ```size```.","d63bd867":"<ul>\n    <li>\n        We utilise the <code>torch.nn<\/code> package to construct neural networks. Building a model in PyTorch is very different compared to building a model using Keras.\n    <\/li>\n    <li>\n        Keras is a highlevel API built on TensorFlow. Prototyping in Keras is very easy, because we find functions for implementing multiple layers and architectures easily\n    <\/li>\n<\/ul>","dbdd2088":"You can use standard NumPy-like indexing with all bells and whistles!","92566c75":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1aZxrixqlANXT2V1stidolB4hBzJGh1MC\">","b8f2859d":"### Updating weights and biases\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1D2Y8AKQ_elgjqYaoYS2JEKTVU7i6nTRV\">","40d6f8cf":"**Comparison of performance between traditional algorithm and neural networks**\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1svzmbn75gL1Q5w7IB__PpatFs6n33BDG\" width=\"480\" height=\"360\">","3b035adb":"### Binary Cross Entropy Loss\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=16N9Djv56MkyIddir5u3Y1ySpidfsYOpS\">\n\n<br>\n\n### Categorical Cross Entropy Function\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1LGqma1sQROx6Nn8Z-7NcVQOzl6t-u0xH\">","cd84682d":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=11eWCZhNTvML8b_osTp1m1-ZX5JXQLppj\">","8bc694a3":"## Conversion between numpy arrays and pytorch tensors","d99d9b57":"### Forward propogation throuh perceptron\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=17u6UF7njFA6bLxZyrojgIeJKfYghUB5N\">","f01bc9f6":"\n***torch.add(input, other, *, alpha=1, out=None)***\n\nEach element of the tensor other is multiplied by the scalar alpha and added to each element of the tensor input. The resulting tensor is returned.\n\nThe shapes of input and other must be broadcastable.\n\n    out=input+alpha\u00d7other\n\nIf other is of type FloatTensor or DoubleTensor, alpha must be a real number, otherwise it should be an integer.","3a45a503":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=11R_dcjyYe8USWbYcNg_CInjtbqwIaL-D\" width=\"1280\" height=\"960\">","b5a01fd8":"### Dropout\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1SAmtIgwtowNm03IK1_8lMnZVqRPEXBOB\" width = \"600\">","631907a5":"### Performance Metrics\n<ul>\n    <li> Regression\n        <ul>\n            <li> MSE <img src = \"https:\/\/drive.google.com\/uc?export=view&id=1QCvAspe13D-UCrGrmz77WGXpeXZJsfVK\" width=\"500\" height=\"300\"><br>\n            <\/li>\n            <li> MAE <img src = \"https:\/\/drive.google.com\/uc?export=view&id=10hfQFx1XgWViYQANi0E2e5W9h0Jt3HQC\"><br>\n            <\/li>\n            <li> RMSE <img src = \"https:\/\/drive.google.com\/uc?export=view&id=19vLHjRJby0mPp9wElFun-7CnxpQDTxST\"><br>\n            <\/li>\n        <\/ul>\n    <\/li>\n<\/ul>","4b983f99":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1uPNi9B4Euz6TUMr-abvGejC21yKMUygb\">","42bb9b7b":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1OJpBG8D1jQ-krMvN_EJY1B1DYGTiDPG7\">","a0cd1793":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1F5yQicNGyiRW9gBJiLqY6KuoYk5QUkoH\">","d86da3c6":"### Early Stopping\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1vITyi7AeavKjDzttJiE9YEz-RZiu_PP1\" width = \"600\">","2b5aaa77":"### What is an activation function?\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1mlITc4UEg4hGEoONWthHRMVZWf0FLqjA\" width = \"600\">","b911ae7c":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1XH1NIJ4J9t0FlFx0UfBghqg2-wc_OL59\">","49433339":"### Bias and Variance\n<ul>\n    <li>\n        \n**What is Bias?**\nBias is the simplifying assumptions made by a model to make the target function easier to learn.\n    <\/li>\n    <li>\n\n**Low Bias:** Predicting less assumption about Target Function\n    <\/li>\n    <li>\n        \n**High Bias:** Predicting more assumption about Target Function\n    <\/li>\n<\/ul>","a5e8f656":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1KPsu-PqZ17QcUONdXGUVTQyc9LNziEDg\">","27746c49":"### Effect of learning rate\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1hSI1zN8mnGo9Wo61q3W05g7bg-eQ1Qz3\" width = \"500\">","9b0f895d":"# Introduction to DL and CNNs using PyTorch","7fcec44b":"### Regularization Methods\n<ul>\n    <li> L1 & L2 Regularization \n\n<\/li>\n    <li>Cross Validation \n<\/li>\n    <li>Early Stopping\n<\/li>\n    <li>Drop Out<\/li>\n    <li>Dataset Augmentation<\/li>\n    \n<\/ul>","ae957e1f":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1TOiiZUxt6rQqZFpr4_dWWHWotcQhWDWb\">","fa01f4b4":"To construct a randomly initialised matrix\n\n ***torch.rand(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) \u2192 Tensor***\n\n    Returns a tensor filled with random numbers from a uniform distribution on the interval [0,1)[0, 1)[0,1)\n\nThe shape of the tensor is defined by the variable argument `size`.","deb372d8":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1ZbTSvvmQFp7IZXnq4k6ffdFK74I7q4cE\">","2ba485aa":"## Day 1 - Introduction to Neural Networks","0e666b8a":"Any operation that mutates a tensor in-place is post-fixed with an _. For example: x.copy_(y), x.t_(), will change x.","afbd80bc":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1TnDHgAWZy3N4syaWiqaABglf301fEo4O\">","5bdaf065":"## Introduction to Tensors","20a81144":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=17bMKg_4F5a5BX2lVuyl0WcIhEYkHIIyr\">","f68b44a8":"# Loss Functions","c08e02c3":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=14f4UV6QewqsDYLVbU6bxjMkjR5vSxShe\">","ebfa433e":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1rBUoWLBRGM3A_MKz3m6KE4rMSaL7ATRW\">\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=13wW1mSdOBf_OcppHbnYxWvyTiSfeYee2\">","15abe037":"### Performance Metrics\n<ul>\n    <li>\n\n**Classification_accuracy:**(TP + TN) \/ (TP + TN + FP + FN)\\\n**Error rate:** (FP + FN) \/ (TP + TN + FP + FN)\n    <\/li><br>\n    <li>\n        \n**Precision:** (or Positive predictive value)\nproportion of predicted positives which are actual positive\nTP \/ (TP + FP)\\\n**Recall:** proportion of actual positives which are predicted positive\nTP \/ (TP + FN)\n    <\/li><br>\n    <li>\n        \n**Sensitivity:** proportion of actual positives which are predicted positive\nTP \/ (TP + FN)\\\n**Specificity:** proportion of actual negative which are predicted negative\nTN \/ (TN + FP)\n    <\/li>\n    \n<\/ul>","618bd55a":"To construct a tensor directly from the data:","98a5c344":"### Rectified Linear Unit\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1Aqn2m1X9EvGc4-rentaLDrdcuu7dKG3E\">","bdd9fbc4":"### Bias and Variance\n<ul>\n    <li>\n        \n**What is Variance?**\nVariance is the amount that the estimate of the target function will change if different training data was used.\n    <\/li>\n    <li>\n\n**Low Variance:** Predicting small changes to the estimate of the target function with changes to the training dataset.\n    <\/li>\n    <li>\n        \n**High Variance:** Predicting large changes to the estimate of the target function with changes to the training dataset.\n    <\/li>\n<\/ul>","ef195a68":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1DlK8Qe_pYONnGv1dfUtWK7maeKMT7uRh\">","2fa9275a":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1l4KBIcjOvQzZU_Lale__P6P51fmjOI3G\">","3635b71c":"### Performance Metrics\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1lPMCPkmQrJka9aBJLU_I9QB7-mOnYAXp\">","08c11176":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1lczmEht8spw54dbxEEJsH_63rdTzXpY5\">","b19255da":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1xzf_FpKK1AQVN2uuE5YiSTaE2Pof55lT\">","a0bcd08b":"\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1L4u5GtxIBDZv57A_M3w4vtDaYNt3aIzc\" width=\"640\" height=\"480\">","6640d82c":"### Effect of bias after application of activation function\n<div style='display:flex;'>\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1BuUd45oxTmSKkOwnG_z6HWLcMmwJAYmv\" width = \"500\">\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=103p65aTErgDcgnXuKNPRkNkUpcJEJf4Q\" width = \"500\">\n<\/div>\n","603c27dd":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1sUBb4EYi01N4cjh-i_hp-xOzqRF6X74j\">","c3dc783c":"\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1KqESzmaqAaDeLUhANwSf9-a32Fwd3N-h\" width=\"640\" height=\"480\">","195ffc3b":"## Tensor Operations ","c0298bf9":"To reshape the dimensions of the tensors:","55deaa7b":"### Sigmoid Function\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1e2_9I5hz1ywu9wXTlczHd7dwtgiX47Lj\">","0bf3e465":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1SmP7PVsE5CzuBZOfuIDp8qonu3fgAoqQ\">","88113d5a":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1b32-0ke0jjQ2Fc50FFbwlBI360ughCou\">","7fe5c267":"<h2>General procedure<\/h2>\n<ul>\n    <li>Understand the type of data you are dealing with.<\/li>\n    <li>Explore your dataset, perform exploratory data analysis (EDA) if required. <\/li>\n    <li>Start building your model architecture which has learnable parameters or weights.<\/li>\n    <li>Forward propogate your data through the model, by iterating over your input data.<\/li>\n    <li>Compute the loss using the predicted values from the model and the given\/actual values (considering supervised learning).<\/li>\n    <li>Use the loss computed which is a single scalar value, backpropogate it through your network, so that the gradients for the network parameters are computed and stored. We use PyTorch's <code>autograd<\/code> which is an automatic differentiation package.<\/li>\n    <li>Update your weights\/network parameters using a suitable optimisation algorithm.\n        <ul>\n            <li><code style='font-style:italic;'>weights(new) = weights(old) - alpha * gradient<\/code><\/li>\n        <\/ul>\n    <\/li>\n    <li>Repeat the entire procedure above to train your mode and to improve the model performance.<\/li>\n<\/ul>","b09a5ade":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1TOiiZUxt6rQqZFpr4_dWWHWotcQhWDWb\">","bc2295ff":"### L1 and L2 (Penalize Large Weights)\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1To_qvQ-Z-j3ORX7jlsX-eUyLdL6GllKD\">","68f58232":"### Loss Functions\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1cnzBHf-rKj1oWJhK1F7Wd6l4A4OJoLPc\">","1fef7510":"If the tensor has only a single value, then to access that single value in a scalar form, we use the `.item()` function","2597a0a9":"### Gradient Descent Methods\n<ul>\n    <li> Standard Gradient Descent <\/li>\n    <li> Stochastic Gradient Descent <\/li>\n    <li> Mini-Batch Gradient Descent <\/li>\n<\/ul>","ecef936a":"<img src=\"https:\/\/drive.google.com\/uc?export=view&id=1Jd8mXrziughpaCsXfVqEXAE1BACJ1ias\">\n","c6069d3b":"See how the numpy array changed in value.","21ec551a":"### Hyperbolic Tangent (Tanh) function\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1Una8FswyyuzkvTQWHKcZQEnRo_7DIZVK\">","70548d99":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1zEErldsVd713ir2I2rTYsLxOKg6IysJh\">","edb13ec4":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1gdNVMrIfVzDcMHfCgZt9qrpLuQ1bQ-mw\">","575061c1":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1BTTdCsNt44scZOSb9tBi_akyzJvMzSsk\">","5bca1778":"To construct a matrix filled with zeroes, of dtype long and float","7ed33324":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1hxwBIm_w1S8-QOKwXAWb5Qi3FN5R-e0c\" width = \"700\">","f284105f":"<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1QV2pfhTymU4XvRkcAl0NmRBf3W_eddIp\">","2c95fec8":"### Image Augmentation\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=15FzloNDsxmeaf0_d_PcqyWlkbBq8qYVo\">","cfad4716":"<!-- <img src = \"https:\/\/drive.google.com\/uc?export=view&id=1dxiUAfBPvyshiqiO1IT5_kW8TlzuWzGj\" width=640 height=480> -->","d1e3edeb":"### Hyperparameter Tuning\n<ul>\n    <li>\n        \nWhat are **hyperparameters** ?\n    <\/li><br>\n    <li>\n        \n**Hyperparameters** are the **variables which determines the network structure**(Eg: Number of Hidden Units) and **the variables which determine how the network is trained**(Eg: Learning Rate).\n    <\/li><br>\n    <li>\n    \n**Hyperparameters** are **set before training**(before optimizing the weights and bias).\n    <\/li><br>\n    <li>\n    \nHyperparameters related to network structure:\n    <ul>\n        <li>No. of hidden layers, dropout, Wt. initialization, activation function as discussed earlier<\/li>\n    <\/ul>\n    <\/li><br>\n    <li>\n        \nRelated to training algorithm:\n        <ul>\n        <li>\n            \nThe learning rate defines how quickly a network updates its parameters.**Low learning rate** slows down the learning process but converges smoothly. **Larger learning rate** speeds up the learning but may not converge.<\/li>\n        <li>\n\nNumber of epochs is the number of times the whole training data is shown to the network while training.Increase the number of epochs until the validation accuracy starts decreasing even when training accuracy is increasing(overfitting).\n        <\/li>\n        <li>\n            \nMini batch size is the number of sub samples given to the network after which parameter update happens. **A good default for batch size might be 32**. Also try 32, 64, 128, 256, and so on.<\/li>\n    <\/ul>\n    <\/li>\n    \n<ul>\n\n\n\n\n\n\n\n\n\n\n","f0c43ad8":"# Building NNs using PyTorch","74bf74be":"### Cross Validation\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1qEO37BDgaGVKST_xMQhjxx9A8oLNrcCF\">","00f93090":"### Backpropagation\n<img src = \"https:\/\/drive.google.com\/uc?export=view&id=1v28ctuVX9_D5_G6RJnUMfchvQk2HUKSJ\" width=\"800\" height=\"500\">"}}