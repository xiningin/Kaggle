{"cell_type":{"4b315a47":"code","d0c8620b":"code","c9bdefde":"code","e50c6a3f":"code","10f5cb21":"code","6659d800":"code","80ade92b":"code","1bb8bad9":"code","68fe661c":"code","5a08a0bf":"code","6043882a":"code","23c02f44":"code","17300b1b":"code","abece1e8":"code","12846e43":"code","61add17f":"code","9b7dbad4":"code","39723345":"code","231a9cc8":"code","e0119754":"code","9ae2571d":"code","ecb5971c":"code","55268b2d":"code","04032d25":"code","71a7b721":"code","db3b31c2":"code","5b499a58":"code","df8baff6":"code","de02fe80":"code","8f64596a":"code","e81dbcb4":"code","370f111d":"code","2cdcb0fa":"code","3cff62b9":"code","31f42949":"code","0f8bcdd1":"code","2bd16725":"code","7e00cc99":"code","68ec369f":"code","6e48d2a7":"code","4ac40da2":"code","dc7499e7":"code","31304ebb":"code","65b2286b":"code","46526648":"markdown","7a37e3f3":"markdown","ac6e3cff":"markdown","374e4c73":"markdown","9ebb076c":"markdown","0f8b3b6b":"markdown","71a11890":"markdown","69279674":"markdown","7e0bc75b":"markdown","a4aef42d":"markdown","a330b0b8":"markdown","12194981":"markdown","a345199e":"markdown","3997578a":"markdown","658cacb4":"markdown","b6a44155":"markdown"},"source":{"4b315a47":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d0c8620b":"import matplotlib.pyplot as plt\nimport seaborn as sns","c9bdefde":"df= pd.read_csv('\/kaggle\/input\/health-insurance-cross-sell-prediction\/train.csv')\ndf.head()","e50c6a3f":"df.shape\ndf.info()","10f5cb21":"df.Gender.value_counts()","6659d800":"sns.displot(df.Age)","80ade92b":"df.Driving_License.value_counts()","1bb8bad9":"df.Region_Code.nunique()","68fe661c":"df.Previously_Insured.value_counts()","5a08a0bf":"df.Vehicle_Age.value_counts()","6043882a":"df.Vehicle_Damage.value_counts()","23c02f44":"df.Annual_Premium.describe()","17300b1b":"df.Policy_Sales_Channel.nunique()","abece1e8":"df.Response.value_counts()","12846e43":"df1= df.copy()","61add17f":"def data_prep(df):\n    df= df.drop(columns=['id','Policy_Sales_Channel','Vintage'])\n    df=pd.get_dummies(df,columns=['Gender'] ,prefix='Gender')\n    df=pd.get_dummies(df,columns=['Vehicle_Damage'] ,prefix='Damage')\n    df=pd.get_dummies(df,columns=['Driving_License'] ,prefix='License')\n    df=pd.get_dummies(df,columns=['Previously_Insured'] ,prefix='prev_insured')\n    df[\"Age\"] = pd.cut(df['Age'], bins=[0, 29, 35, 50, 100])\n    df['Age']= df['Age'].cat.codes\n    df['Annual_Premium'] = pd.cut(df['Annual_Premium'], bins=[0, 30000, 35000,40000, 45000, 50000, np.inf])\n    df['Annual_Premium']= df['Annual_Premium'].cat.codes\n    df['Vehicle_Age'] =df['Vehicle_Age'].map({'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2})\n    df.drop(columns=['Region_Code'],inplace= True)\n    return df","9b7dbad4":"df1=data_prep(df1)\ndf1.head()","39723345":"Features= ['Age','Vehicle_Age','Annual_Premium',\"Gender_Female\",\"Gender_Male\",\"Damage_No\",\"Damage_Yes\",\"License_0\",\"License_1\" ,\"prev_insured_0\", \"prev_insured_1\"]\n","231a9cc8":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(df1[Features],df1['Response'], test_size = 0.3, random_state = 101)\nX_train.shape,X_test.shape\n","e0119754":"!pip install imblearn","9ae2571d":"from imblearn.under_sampling import RandomUnderSampler\nRUS = RandomUnderSampler(sampling_strategy=.5,random_state=3,)\nX_train,Y_train  = RUS.fit_resample(df1[Features],df1['Response'])\nX_train.head()\n","ecb5971c":"Y_train.value_counts()\n\n","55268b2d":"def performance_met(model,X_train,Y_train,X_test,Y_test):\n    acc_train=accuracy_score(Y_train, model.predict(X_train))\n    f1_train=f1_score(Y_train, model.predict(X_train))\n    acc_test=accuracy_score(Y_test, model.predict(X_test))\n    f1_test=f1_score(Y_test, model.predict(X_test))\n    print(\"train score: accuracy:{} f1:{}\".format(acc_train,f1_train))\n    print(\"test score: accuracy:{} f1:{}\".format(acc_test,f1_test))\n    ","04032d25":"from sklearn.metrics import accuracy_score, f1_score,auc\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train,Y_train) \nperformance_met(model,X_train,Y_train,X_test,Y_test)","71a7b721":"from sklearn.tree import DecisionTreeClassifier\nmodel_DT=DecisionTreeClassifier(random_state=1)\nmodel_DT.fit(X_train,Y_train)\nperformance_met(model_DT,X_train,Y_train,X_test,Y_test)","db3b31c2":"from sklearn.ensemble import RandomForestClassifier\nForest= RandomForestClassifier(random_state=1)\nForest.fit(X_train,Y_train)\nperformance_met(Forest,X_train,Y_train,X_test,Y_test)\n","5b499a58":"from sklearn.model_selection import GridSearchCV\nrf= RandomForestClassifier(random_state=1)\nparameters = {\n    'bootstrap': [True],\n'max_depth': [10, 20],\n'min_samples_leaf': [3, 4],\n'min_samples_split': [4, 6],\n'n_estimators': [100, 200],\n\n}\ngrid_search_1 = GridSearchCV(rf, parameters, cv=3, verbose=2, n_jobs=-1)\ngrid_search_1.fit(X_train, Y_train)\nperformance_met(grid_search_1,X_train,Y_train,X_test,Y_test)","df8baff6":"X_train['Response']=Y_train\n","de02fe80":"pip install pycaret\n","8f64596a":"from pycaret.classification import *\nclf1= setup(data=X_train,target='Response',data_split_stratify=True)\n","e81dbcb4":"compare_models(exclude=['xgboost'])","370f111d":"gbm= create_model('gbc')","2cdcb0fa":"predict_model(gbm,probability_threshold=.65)\n","3cff62b9":"plot_model(gbm)","31f42949":"plot_model(gbm,'confusion_matrix')","0f8bcdd1":"plot_model(gbm,'feature')","2bd16725":"evaluate_model(gbm)","7e00cc99":"test_df= pd.read_csv('..\/input\/health-insurance-cross-sell-prediction\/test.csv')\ntest_df.info()","68ec369f":"test_df2=data_prep(test_df)","6e48d2a7":"prediction=predict_model(gbm,data=test_df2)","4ac40da2":"submission=pd.read_csv('..\/input\/health-insurance-cross-sell-prediction\/sample_submission.csv')\nsubmission['Response']=prediction['Label']\n","dc7499e7":"submission.Response.value_counts()","31304ebb":"submission.to_csv('final_submission.csv')","65b2286b":"submission.head(10)","46526648":"# Accuracy metrices","7a37e3f3":"# work in progress...","ac6e3cff":"# use train_test split when not using pycaret","374e4c73":"let's undrstand the data.\n\nId :column is unique identifier hence it has no role in prediction\n\nGender: Male 206089, female 175020\n\nAge: understand the distribution\n\nDriving_license: represent weather the owner posses the lincence or not. My undestanding of the domain says for insurance driving license is required. only 812 observations do not posses  driving license else do.\n\nRegion_code: Although looks like integer but it is a categorical data consisting of 53 unique values.\n\nVehicle age: categorical data 1-2 Year 200316, < 1 Year 164786,> 2 Years 16007 \n\nvehicle damage: categorical data Yes 192413, No 188696\n\n\n\n\n\n\n\n\n","9ebb076c":"Drop id, policy sales channel and vintage,Region code\n\nOne hot encode gender,vehical damage,driving license,previously insured.\n\nordinal encode vehical_age.\n\nbin and encode Annual premium and Age.\n\nresponse is a target.","0f8b3b6b":"\n# It is an imbalanced problem.Will use oversampling\/undersampling for balancing the data.\n> Data Preprocessing.\n","71a11890":"check shape of the dataset.","69279674":"# Let's use pycaret","7e0bc75b":"Read and see the first five rows of the train dataset.","a4aef42d":"To enable autocomplete in kaggel just run this in consol\n\n%config Completer.use_jedi = False","a330b0b8":"Instead of plotting everything. Just evaluate the model.","12194981":"# Features to be used in modelling","a345199e":"# Handle Imbalance using imblearn undersampling","3997578a":"# Now let's have the test data and do the preprocessing to make it a fit for our model.","658cacb4":"# Gradient Boosting classifier is the best performer, let's further work with it.","b6a44155":"# For EDA I have used Dtale but soon update the notebook with EDA and visulizations\n\n"}}