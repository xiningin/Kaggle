{"cell_type":{"3500e6ab":"code","927e2d90":"code","f0810541":"code","ca135a24":"code","5d03b589":"code","0c13e893":"code","a2dbb776":"code","f1154726":"code","564ea749":"code","403a94d8":"code","5bd5dc42":"code","d88f3924":"code","590a4cf5":"code","013c81f6":"code","fec4909f":"code","e99260a7":"code","f9a09551":"code","f2920ed2":"code","c8c14d77":"code","2e484eda":"code","f2df7e33":"code","45a77c76":"code","6221f740":"code","58bf60b5":"code","dcf5b712":"code","598812a5":"code","cf017823":"code","84f09c0f":"code","fc0b6e35":"code","3fffadc6":"code","34b15c5f":"code","1bc2b008":"code","dd50d91c":"code","b1d62954":"code","76811a6f":"code","f876b5e7":"code","fff22039":"code","32e04875":"code","45a4c6df":"code","f9b14658":"code","9dd197fa":"code","6fbcb2b7":"code","3b92835f":"code","53200762":"code","acb4ed8e":"code","a3148952":"code","6fd7d48b":"code","a452e785":"code","3ec35118":"code","23f3fe6e":"markdown","b8a76f30":"markdown","ec95a4d7":"markdown","227e09fd":"markdown","84dac8fe":"markdown","db939aa1":"markdown","599dd129":"markdown","ff2bd3bb":"markdown","69ae00d8":"markdown","3f7c6f9b":"markdown","c7707e88":"markdown","07b4ad6f":"markdown","87cd40b9":"markdown"},"source":{"3500e6ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","927e2d90":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib\nimport seaborn as sns\n#matplotlib.rcParams[\"figure.figsize\"] = (20,10)","f0810541":"df = pd.read_csv(\"..\/input\/bengaluru-house-price-data\/Bengaluru_House_Data.csv\")","ca135a24":"df.head()","5d03b589":"df.shape","0c13e893":"df.dtypes","a2dbb776":"df.groupby('area_type')['area_type'].agg('count')","f1154726":"#For the simplicity let's delete the first three features, seems to be less importent\ndf1 = df.drop(['area_type', 'availability','society'], axis = 1)","564ea749":"# Let's check the missing value\ndf1.isnull().sum()","403a94d8":"df2 = df1.dropna()\ndf2.isnull().sum()","5bd5dc42":"#Now have a look of the features value\ndf2['size'].unique()","d88f3924":"df2['bhk'] = df2['size'].apply(lambda x: int(x.split(' ')[0]))","590a4cf5":"df2.head()","013c81f6":"#Let's drop the 'size' column. \ndf2 = df2.drop(['size'], axis = 1)","fec4909f":"#Let's check the total_sqft column.\ndf2['total_sqft'].unique()","e99260a7":"def is_float(x):\n    try:\n        float(x)\n    except:\n        return False\n    return True","f9a09551":"df2[~df2['total_sqft'].apply(is_float)].head(20)","f2920ed2":"def convert_sqt_to_num(x):\n    tokens = x.split('-')\n    if len(tokens) == 2:\n        return(float(tokens[0]) + (float(tokens[1])))\/2\n    try:\n        return float(x)\n    except:\n        return None\n    ","c8c14d77":"convert_sqt_to_num('1000Sq. Meter')","2e484eda":"df3 = df2.copy()\ndf3['total_sqft'] = df3['total_sqft'].apply(convert_sqt_to_num)\ndf3.head()\n","f2df7e33":"df3.loc[30]","45a77c76":"#Now Let's check the location columns.\ndf3['location'].unique()","6221f740":"len(df3['location'].unique())","58bf60b5":"location_stats = df3['location'] = df3['location'].apply(lambda x : x.strip()) #To strip leading and ending extra space of the each location. \nlocation_stats = df3.groupby('location')['location'].agg('count').sort_values(ascending = False)\nlocation_stats","dcf5b712":"len(location_stats[location_stats<= 10])","598812a5":"location_stats_less_then_10 = location_stats[location_stats<= 10]\nlocation_stats_less_then_10","cf017823":"df3.location = df3.location.apply(lambda x : 'other'  if x in location_stats_less_then_10 else x)\nlen(df3.location.unique())","84f09c0f":"df3.head(20)","fc0b6e35":"x = df3.bhk.sum()\ny = df3.total_sqft.sum()","3fffadc6":"y\/x","34b15c5f":"df3[df3.total_sqft\/df3.bhk < 100].head()","1bc2b008":"df4 = df3[~(df3.total_sqft\/df3.bhk < 100)] # Dropping those rows contains outlier","dd50d91c":"df4.shape","b1d62954":"df4['Price_per_sqft'] = df4.price*100000 \/ df4.total_sqft","76811a6f":"df4.head()","f876b5e7":"df4.Price_per_sqft.describe()","fff22039":" def remove_pps_outliers(df):\n        df_out = pd.DataFrame()\n        for key, subdf in df.groupby('location'):\n    \n            m = np.mean(subdf.Price_per_sqft)\n            std = np.std(subdf.Price_per_sqft)\n            \n            reduced_df = subdf[(subdf.Price_per_sqft > (m-std)) & (subdf.Price_per_sqft <= (m+std))]\n            df_out = pd.concat([df_out,reduced_df],ignore_index = True)\n            \n        return df_out\n        \ndf5 =  remove_pps_outliers(df4)\ndf5.shape","32e04875":"#Let's remove outlier from the 'bath' column.\ndf5.bath.unique()","45a4c6df":"df5[df5.bath>10]","f9b14658":"plt.hist(df5.bath,rwidth = .8)\nplt.xlabel('Number of bathrooms')\nplt.ylabel('Count')","9dd197fa":"df5[df5.bath>df5.bhk + 2]","6fbcb2b7":"df6 =  df5[df5.bath<df5.bhk + 2]\ndf6.shape","3b92835f":"dummies = pd.get_dummies(df6.location)","53200762":"df6 = pd.concat([df6,dummies],axis = 'columns')","acb4ed8e":"df6 = df6.drop(['Price_per_sqft','location'], axis = 1)","a3148952":"X = df6.drop(['price'], axis=1)\ny = df6.price","6fd7d48b":"X.head()","a452e785":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","3ec35118":"from sklearn.linear_model import LinearRegression\ncls =  LinearRegression()\ncls.fit(X_train, y_train)\ncls.score(X_test,y_test)","23f3fe6e":"Before dig deep let's specify our objective.Here our objective is to predict the Bengaluru House Price.","b8a76f30":"We are expecting this value as integer or float. But here we are seeing some range  so before dealing with this  let's how many types of values are present in this columns.","ec95a4d7":"Here we are seeing some extream high and low value. And by using the mean and standerd deviation er are going to take only those\nvalue which are only 1 standerd deviation way from the mean of each location.","227e09fd":"# Introduction","84dac8fe":"Here we are seeing Strings 'BHK', 'Bedroom'. I think both of the strings are specifying the bedroom and this feature how many bedroom each building contains. That's why let's split the each value of this feature take only the integer part.","db939aa1":"From the above calculation we are seeing that average area needed to be there for per bedroom is around 550 squre foot.\n\nLet's  assume a threesold value of 100 sqft. And row containing less the 100 sqft for per bedroom will be consider as outlier and we are going to drop those those rows. ","599dd129":"So here we are seeing that 1017 location which has less the 10 data points. so let's make another category 'other' which contain this types of value.","ff2bd3bb":"So here we are seeing many  location contain only  one data points.","69ae00d8":"# Outlier detection","3f7c6f9b":"Here one important things to notice is that  \"total_sqft\" features is of object type. That's mean we have clean this feature .","c7707e88":"Here we are ignorable missing values that's why we can directly drop those rows.","07b4ad6f":"Here we are seeing 1265 unique value.This is an importent feature also while predicting price.That's why we cann,t drop it rather try to manage it.And if we take dummies then it will create dimensionality curse. So somehow we have to do the dimensionality reduction.So first see how much datapoints each unique value has. So those value has less datapoints we will consider it as a other.","87cd40b9":"Here we are seeing some alphanumeric value value also.So now i am going to make a function which will take the mean when it see range and ignore the alphanumeric value."}}