{"cell_type":{"b8a9666b":"code","ceb12b9d":"code","3e013b1d":"code","674cf6ec":"code","6190de6e":"code","183cd2fd":"code","74bf4919":"code","c024b7f3":"code","59514ac4":"code","3ce5b252":"code","d0f87d4a":"code","320bb478":"code","90e4ff4a":"code","fda768b1":"code","2ad552fe":"code","5890392d":"code","35856cf3":"code","6541c06f":"code","58002bc0":"code","a9d24235":"code","b3851a0c":"code","a406d3e0":"code","ce593496":"code","cfe364e8":"code","c6612705":"code","ddf40f39":"code","c7a78837":"code","fea32298":"markdown","a46d75c1":"markdown","65ecd0c0":"markdown","9fe356c7":"markdown","c4ead63f":"markdown"},"source":{"b8a9666b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import accuracy_score\n\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.losses import mean_squared_error\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import backend as K\nK.clear_session()\nimport tensorflow as tf\n\nimport warnings\nwarnings.filterwarnings('ignore')","ceb12b9d":"df_labeled_1 = pd.read_csv(\"\/kaggle\/input\/attack-adversarial-dataset\/labeled_ all_data_1.csv\")\ndf_labeled_1.drop(['Unnamed: 0'], axis=1, inplace=True)\nprint(df_labeled_1.shape)\nprint(df_labeled_1.anomaly.value_counts()\/df_labeled_1.shape[0])\n\ndf_labeled_1.head()","3e013b1d":"# normalize the data\nscaler = StandardScaler() \nscaled_values = scaler.fit_transform(df_labeled_1) \ndf_labeled_1.loc[:,:] = scaled_values\ndf_labeled_1.head()\n","674cf6ec":"# prepare df for target results\ny=pd.DataFrame({'anomaly':df_labeled_1['anomaly']})\ny['anomaly']=y['anomaly'].astype(int)","6190de6e":"# remove results from the input df\ndf_labeled_1 = df_labeled_1[['HR','ABPSys','anomaly']].drop(columns=['anomaly'])\ndf_labeled_1.head()","183cd2fd":"# change input format from df to array\ndf_labeled_1=np.array(df_labeled_1)\ny=np.array(y)\n\n# split the data into test and train\nX_train, X_test, Y_train, Y_test = train_test_split(df_labeled_1, y, test_size=0.3)\nprint(\"Input shape \", df_labeled_1.shape)\nprint(\"Train data shapes \", X_train.shape,\", \", Y_train.shape) \nprint(\"Test data shapes \", X_test.shape,\", \", Y_test.shape)","74bf4919":"# change input dimensions to 3 for LSTM input\nX_train2 = X_train\nX_test2 = X_test\n\nX_train = np.reshape(X_train, (5915, X_train.shape[1], 1))\nX_test = np.reshape(X_test, (2536, X_train.shape[1], 1))\n","c024b7f3":"import tensorflow as tf \n# LSTM model\nmodel = Sequential()\n\nmodel.add(LSTM(128, input_shape=(X_train.shape[1], 1)))\nmodel.add(Dropout(0.15))\nmodel.add(Dense(1, activation=\"sigmoid\"))\n\nmodel.summary()\n\nadam_modified = tf.optimizers.Adam(learning_rate=0.005, beta_1=0.7, beta_2=0.9, amsgrad=False)\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=adam_modified, metrics=[\"accuracy\"])\nmodel.fit(X_train, Y_train, epochs=5)","59514ac4":"def plot_predictions(test, predicted, title):\n    plt.figure(figsize=(20,1))\n    plt.plot(test, color='blue',label='Actual result')\n    plt.plot(predicted, color='orange',label='Predicted ')\n    # plt.title(title)\n    plt.xlabel('Sample number')\n    plt.ylabel('Anomaly target')\n    # plt.legend()\n    plt.show()","3ce5b252":"predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\nY_test=Y_test.astype('int32')","d0f87d4a":"plot_predictions(Y_test[0:500], predictions[0:500], \"Predictions made by LSTM model\")","320bb478":"accuracy_score(Y_test, predictions)","90e4ff4a":"predictions = predictions[:,0]\n### https:\/\/realpython.com\/gradient-descent-algorithm-python\/\ndef gradient_descent(gradient, start, learn_rate, n_iter=50, tolerance=1e-06):\n    vector = start\n    for _ in range(n_iter):\n        diff = -learn_rate * gradient(vector)\n        if np.all(np.abs(diff) <= tolerance):\n            break\n        vector += diff\n    return vector","fda768b1":"perturbed_data = X_test + 0.5 +gradient_descent(gradient=lambda v: 2 * v, start=10.0, learn_rate=0.2)#* signed_grad\nX_perturbed = perturbed_data#.numpy()","2ad552fe":"\nadversarial_predictions = (model.predict(X_perturbed) > 0.5).astype(\"int32\") # model.predict_classes(X_perturbed)\naccuracy_score(Y_test, adversarial_predictions)\n","5890392d":"x_test_plot = X_test[:, :, 0]\nx_perturbed_plot = X_perturbed[:, :, 0]\nplt.figure(figsize=(20,2))\nplt.plot(x_test_plot[:50], color='blue',label='Actual data')\nplt.plot(x_perturbed_plot[:50], color='orange',label='Perturbated data')\nplt.xlabel('Sample number')\nplt.ylabel('Anomaly target')\nplt.show()","35856cf3":"plot_predictions(Y_test[0:500], adversarial_predictions[0:500], \"Predictions made by LSTM model\")","6541c06f":"df_anom = pd.read_csv(\"\/kaggle\/input\/attack-adversarial-dataset\/labeled_ all_data_1.csv\")\ndf_anom.drop(['Unnamed: 0'], axis=1, inplace=True)\ndf_anom.head()","58002bc0":"# multivariate lstm example\nfrom numpy import array\nfrom numpy import hstack\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\n\n# split a multivariate sequence into samples\ndef split_sequences(sequences, n_steps):\n\tX, y = list(), list()\n\tfor i in range(len(sequences)):\n\t\t# find the end of this pattern\n\t\tend_ix = i + n_steps\n\t\t# check if we are beyond the dataset\n\t\tif end_ix > len(sequences):\n\t\t\tbreak\n\t\t# gather input and output parts of the pattern\n\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n\t\tX.append(seq_x)\n\t\ty.append(seq_y)\n\treturn array(X), array(y)\n\n# define input sequence\nin_seq1 = df_anom['HR'].values[int(df_anom.shape[0]*0.80):]\nin_seq2 = df_anom[['ABPSys']].values[int(df_anom.shape[0]*0.80):] \nin_seq3 = df_anom[['ABPDias']].values[int(df_anom.shape[0]*0.80):] \nin_seq4 = df_anom[['ABPMean']].values[int(df_anom.shape[0]*0.80):] \nin_seq5 = df_anom[['PULSE']].values[int(df_anom.shape[0]*0.80):] \nin_seq6 = df_anom[['RESP']].values[int(df_anom.shape[0]*0.80):] \nin_seq7 = df_anom[['SpO2']].values[int(df_anom.shape[0]*0.80):] \nin_seq8 = df_anom[['zscore HR']].values[int(df_anom.shape[0]*0.80):] \nin_seq9 = df_anom[['zscore ABPDias']].values[int(df_anom.shape[0]*0.80):] \nin_seq10 = df_anom[['ABPDias anomaly']].values[int(df_anom.shape[0]*0.80):] \nin_seq11 = df_anom[['zscore ABPSys']].values[int(df_anom.shape[0]*0.80):] \nin_seq12 = df_anom[['ABPSys anomaly']].values[int(df_anom.shape[0]*0.80):] \nin_seq13 = df_anom[['zscore PULSE']].values[int(df_anom.shape[0]*0.80):] \nin_seq14 = df_anom[['zscore ABPMean']].values[int(df_anom.shape[0]*0.80):] \nin_seq15 = df_anom[['ABPMean anomaly']].values[int(df_anom.shape[0]*0.80):] \nin_seq16 = df_anom[['zscore SpO2']].values[int(df_anom.shape[0]*0.80):] \nin_seq17 = df_anom[['SpO2 anomaly']].values[int(df_anom.shape[0]*0.80):] \nin_seq18 = df_anom[['zscore RESP']].values[int(df_anom.shape[0]*0.80):] \nin_seq19 = df_anom[['RESP anomaly']].values[int(df_anom.shape[0]*0.80):] \n\nin_seq20 = df_anom[['anomaly']].values[int(df_anom.shape[0]*0.80):] \n\n# out_seq = np.array([in_seq1[i]+in_seq2[i]+in_seq3[i]+in_seq4[i]+in_seq5[i]+in_seq6[i]+in_seq7[i]+in_seq8[i]+in_seq9[i]+in_seq10[i]+in_seq11[i]+in_seq12[i]+in_seq13[i]+in_seq14[i]+in_seq15[i]+in_seq16[i]+in_seq17[i]+in_seq18[i]+in_seq19[i]+in_seq20[i] for i in range(len(in_seq1))])\n\n\n# convert to [rows, columns] structure\nin_seq1 = in_seq1.reshape((len(in_seq1), 1))\nin_seq2 = in_seq2.reshape((len(in_seq2), 1))\nin_seq3 = in_seq3.reshape((len(in_seq3), 1))\nin_seq4 = in_seq4.reshape((len(in_seq4), 1))\nin_seq5 = in_seq5.reshape((len(in_seq5), 1))\nin_seq6 = in_seq6.reshape((len(in_seq6), 1))\nin_seq7 = in_seq7.reshape((len(in_seq7), 1))\nin_seq8 = in_seq8.reshape((len(in_seq8), 1))\nin_seq9 = in_seq9.reshape((len(in_seq9), 1))\nin_seq10 = in_seq10.reshape((len(in_seq10), 1))\nin_seq11 = in_seq11.reshape((len(in_seq11), 1))\nin_seq12 = in_seq12.reshape((len(in_seq12), 1))\nin_seq13 = in_seq13.reshape((len(in_seq13), 1))\nin_seq14 = in_seq14.reshape((len(in_seq14), 1))\nin_seq15 = in_seq15.reshape((len(in_seq15), 1))\nin_seq16 = in_seq16.reshape((len(in_seq16), 1))\nin_seq17 = in_seq17.reshape((len(in_seq17), 1))\nin_seq18 = in_seq18.reshape((len(in_seq18), 1))\nin_seq19 = in_seq19.reshape((len(in_seq19), 1))\nin_seq20 = in_seq20.reshape((len(in_seq20), 1))\n\n# out_seq = out_seq.reshape((len(out_seq), 1))\n# horizontally stack columns\ndataset = hstack((in_seq1, in_seq2, in_seq3, in_seq4, in_seq5, in_seq6, in_seq7, in_seq8, in_seq9, in_seq10, in_seq11, in_seq12, in_seq13, in_seq14, in_seq15, in_seq16, in_seq17, in_seq18, in_seq19, in_seq20))#out_seq))\n\n# choose a number of time steps\nn_steps = 4\n# convert into input\/output\nX, y = split_sequences(dataset, n_steps)\n# the dataset knows the number of features, e.g. 2\nn_features = X.shape[2]\n# define model\nmodel = Sequential()\nmodel.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\nmodel.add(Dense(1))\n# model.compile(optimizer='adam', loss='mse')\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n# fit model\nmodel.fit(X, y, epochs=100, verbose=0)","a9d24235":"# define input sequence\nin_seq1_test = df_anom['HR'].values[:int(df_anom.shape[0]*0.80)]\nin_seq2_test = df_anom[['ABPSys']].values[:int(df_anom.shape[0]*0.80)] \nin_seq3_test = df_anom[['ABPDias']].values[:int(df_anom.shape[0]*0.80)] \nin_seq4_test = df_anom[['ABPMean']].values[:int(df_anom.shape[0]*0.80)] \nin_seq5_test = df_anom[['PULSE']].values[:int(df_anom.shape[0]*0.80)] \nin_seq6_test = df_anom[['RESP']].values[:int(df_anom.shape[0]*0.80)] \nin_seq7_test = df_anom[['SpO2']].values[:int(df_anom.shape[0]*0.80)] \nin_seq8_test = df_anom[['zscore HR']].values[:int(df_anom.shape[0]*0.80)] \nin_seq9_test = df_anom[['zscore ABPDias']].values[:int(df_anom.shape[0]*0.80)] \nin_seq10_test = df_anom[['ABPDias anomaly']].values[:int(df_anom.shape[0]*0.80)] \nin_seq11_test = df_anom[['zscore ABPSys']].values[:int(df_anom.shape[0]*0.80)] \nin_seq12_test = df_anom[['ABPSys anomaly']].values[:int(df_anom.shape[0]*0.80)] \nin_seq13_test = df_anom[['zscore PULSE']].values[:int(df_anom.shape[0]*0.80)] \nin_seq14_test = df_anom[['zscore ABPMean']].values[:int(df_anom.shape[0]*0.80)] \nin_seq15_test = df_anom[['ABPMean anomaly']].values[:int(df_anom.shape[0]*0.80)] \nin_seq16_test = df_anom[['zscore SpO2']].values[:int(df_anom.shape[0]*0.80)] \nin_seq17_test = df_anom[['SpO2 anomaly']].values[:int(df_anom.shape[0]*0.80)] \nin_seq18_test = df_anom[['zscore RESP']].values[:int(df_anom.shape[0]*0.80)] \nin_seq19_test = df_anom[['RESP anomaly']].values[:int(df_anom.shape[0]*0.80)]\nin_seq20_test = df_anom[['anomaly']].values[:int(df_anom.shape[0]*0.80)]\n","b3851a0c":"# out_seq_test = np.array([in_seq1_test[i]+in_seq2_test[i]+in_seq3_test[i]+in_seq4_test[i]+in_seq5_test[i]+in_seq6_test[i]+in_seq7_test[i]+in_seq8_test[i]+in_seq9_test[i]+in_seq10_test[i]+in_seq11_test[i]+in_seq12_test[i]+in_seq13_test[i]+in_seq14_test[i]+in_seq15_test[i]+in_seq16_test[i]+in_seq17_test[i]+in_seq18_test[i]+in_seq19_test[i] for i in range(len(in_seq1_test))])","a406d3e0":"# convert to [rows, columns] structure\nin_seq1_test = in_seq1_test.reshape((len(in_seq1_test), 1))\nin_seq2_test = in_seq2_test.reshape((len(in_seq2_test), 1))\nin_seq3_test = in_seq3_test.reshape((len(in_seq3_test), 1))\nin_seq4_test = in_seq4_test.reshape((len(in_seq4_test), 1))\nin_seq5_test = in_seq5_test.reshape((len(in_seq5_test), 1))\nin_seq6_test = in_seq6_test.reshape((len(in_seq6_test), 1))\nin_seq7_test = in_seq7_test.reshape((len(in_seq7_test), 1))\nin_seq8_test = in_seq8_test.reshape((len(in_seq8_test), 1))\nin_seq9_test = in_seq9_test.reshape((len(in_seq9_test), 1))\nin_seq10_test = in_seq10_test.reshape((len(in_seq10_test), 1))\nin_seq11_test = in_seq11_test.reshape((len(in_seq11_test), 1))\nin_seq12_test = in_seq12_test.reshape((len(in_seq12_test), 1))\nin_seq13_test = in_seq13_test.reshape((len(in_seq13_test), 1))\nin_seq14_test = in_seq14_test.reshape((len(in_seq14_test), 1))\nin_seq15_test = in_seq15_test.reshape((len(in_seq15_test), 1))\nin_seq16_test = in_seq16_test.reshape((len(in_seq16_test), 1))\nin_seq17_test = in_seq17_test.reshape((len(in_seq17_test), 1))\nin_seq18_test = in_seq18_test.reshape((len(in_seq18_test), 1))\nin_seq19_test = in_seq19_test.reshape((len(in_seq19_test), 1))\nin_seq20_test = in_seq20_test.reshape((len(in_seq20_test), 1))\n\n# out_seq_test = out_seq_test.reshape((len(out_seq_test), 1))\n# horizontally stack columns\ndataset_test = hstack((in_seq1_test, in_seq2_test, in_seq3_test, in_seq4_test, in_seq5_test, in_seq6_test, in_seq7_test, in_seq8_test, in_seq9_test, in_seq10_test, in_seq11_test, in_seq12_test, in_seq13_test, in_seq14_test, in_seq15_test, in_seq16_test, in_seq17_test, in_seq18_test, in_seq19_test, in_seq20_test))#, out_seq_test))","ce593496":"# choose a number of time steps\nn_steps_test = 4\n# X_train, y_train = split_sequences(dataset, n_steps_test)\n# # the dataset knows the number of features, e.g. 2\n# accuracy_train = model.evaluate(X_train, y_train, batch_size=64, verbose=0)[1]\n# accuracy_train","cfe364e8":"# convert into input\/output\nX_test, y_test = split_sequences(dataset_test, n_steps_test)\n# the dataset knows the number of features, e.g. 2\nn_features_test = X_test.shape[2]\n# evaluate model\n# accuracy_test = model.evaluate(X_test, y_test, batch_size=64, verbose=0)[1]\n# accuracy_test","c6612705":"predictions_convlstm = (model.predict(X_test) > 0.5).astype(\"int32\")\nplot_predictions(y_test[0:500], predictions_convlstm[0:500], \"Predictions made by LSTM model\")\naccuracy_score(y_test, predictions_convlstm)","ddf40f39":"perturbed_data = X_test + 0.5 +gradient_descent(gradient=lambda v: 2 * v, start=10.0, learn_rate=0.2)\nX_perturbed_convlstm = perturbed_data\n\nadversarial_predictions_lstm = (model.predict(X_perturbed_convlstm) > 0.5).astype(\"int32\")\naccuracy_score(y_test, adversarial_predictions_lstm)","c7a78837":"plot_predictions(y_test[0:500], adversarial_predictions_lstm[0:500], \"Predictions made by LSTM model\")","fea32298":"Reference:- https:\/\/machinelearningmastery.com\/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification\/","a46d75c1":"## Train the LSTM model","65ecd0c0":"# ConvLSTM Network Model","9fe356c7":"## The LSTM with pertubation data has similar results comparing with clean dataset","c4ead63f":"## End notebook"}}