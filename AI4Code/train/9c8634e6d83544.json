{"cell_type":{"535a0bb1":"code","c71b129c":"code","88d7eb07":"code","b1fd00dd":"code","ab30a8b9":"code","0300e70d":"code","0f24b465":"code","448e6808":"code","8eff1ea7":"code","f412b4a4":"code","5bd323cc":"code","ed379405":"code","967992ca":"code","3f766c44":"code","ef14763b":"code","ed36f876":"code","a94adf81":"code","307a976f":"code","0ae7e84e":"code","d6337c19":"code","5a498ce1":"code","b960baca":"code","2f487a94":"code","d97c9e20":"code","5c5fa3fa":"code","4259cdbc":"code","b9952c86":"code","eca9ea7f":"code","10a3d9a1":"code","d4adc4c0":"code","38ea2032":"code","61e9eab3":"code","4fdf10ff":"code","ee982770":"code","755f907b":"code","b9f839b0":"code","2d74d405":"code","2da00487":"code","72c9dfd6":"code","ceb1b56a":"code","49249bab":"code","04a3892a":"code","fb8ac376":"code","e1c21714":"code","d53e5192":"code","57fc1504":"code","b150279d":"code","2d4049ff":"code","e8bd6555":"code","e763d816":"code","ce67e4ad":"code","3fd7028a":"code","392cd439":"code","9cb94bfa":"code","3fd52470":"code","4d9a5848":"code","524f3a3c":"code","e79ab342":"code","22d1b605":"code","f0ebfbc0":"code","2452cc46":"code","9c2800a6":"code","9b63e82c":"code","631ebdba":"code","9c27297d":"code","5196b7be":"code","11d49a39":"code","0fe380c1":"code","ca4bbbb8":"code","bb70f7e7":"code","7b45e98f":"code","70dcbf54":"code","ae14cb19":"code","2fd488a1":"code","6123c3f2":"code","97809180":"code","6ba9aaff":"code","9cfdba55":"code","d47b8b9e":"code","19d738b3":"code","86c6c870":"code","83fdcf05":"code","3dfb98d8":"code","51df8b29":"code","acaae55f":"code","e223c9e9":"code","351ad2e3":"code","27394678":"code","556abab7":"code","4355a46c":"code","ec248752":"code","0ca8bbbc":"code","96c26f7a":"code","febc9e91":"code","80c5d51b":"code","da1d4aa3":"code","37094ace":"code","a3ac292e":"code","64ec5c77":"code","b015a9e8":"code","84fae05a":"code","451f9e53":"code","6188241f":"code","6c0363de":"code","bb3086d9":"code","5fdbb0f7":"code","de56067b":"code","93b60bf7":"code","a6fa5097":"code","3c0976c8":"code","fee550f8":"code","c7db6ea5":"code","66f4970d":"code","ad50004f":"code","14ca3f85":"code","c16481de":"code","84470f97":"code","efbaece9":"code","67541853":"code","aa3a230e":"code","4f7d62b5":"code","ba0ade82":"code","6573650c":"code","e9d29e68":"code","5b46d60a":"code","316894cd":"code","56395460":"code","9a417535":"code","3068b19b":"code","ae0f9509":"code","88e31309":"code","09ae5269":"markdown","f711ed4f":"markdown","d2a4a63f":"markdown","eddab165":"markdown","55115cc3":"markdown","e005808a":"markdown","3262a930":"markdown","53b7811f":"markdown","8f0afabb":"markdown","289bb5d7":"markdown","61d1051d":"markdown","8101aa33":"markdown","e2618311":"markdown","4dc52bcd":"markdown","fa5911c3":"markdown","5716e906":"markdown","bd5a0d73":"markdown","8da64395":"markdown","5c47a6e2":"markdown","9b0eb352":"markdown","6b2b9905":"markdown","7d3a6c27":"markdown","0aa08d59":"markdown","2fc0a92c":"markdown","d9521b16":"markdown","c255a2ac":"markdown","bd85cc5b":"markdown","562752cf":"markdown","859d20fb":"markdown","54bf1ae6":"markdown","66d64a9c":"markdown","39b06f9e":"markdown","6462ab59":"markdown","3df4535c":"markdown","d9f5a5a1":"markdown","612f428e":"markdown","92188138":"markdown","91456aff":"markdown","e0d44f03":"markdown","c9d40aec":"markdown","4e472322":"markdown","408c6b2b":"markdown","6bfa2202":"markdown","dad494f4":"markdown","a28fe27f":"markdown","8d8e3272":"markdown","62d298f5":"markdown","48d4401a":"markdown","6d6e437b":"markdown","341bd7ba":"markdown","a641ae34":"markdown","bd1abcdf":"markdown","578398b5":"markdown","840051e8":"markdown","d38a16ac":"markdown","c94b81e4":"markdown","2853be82":"markdown","4e8fc925":"markdown","07a59b28":"markdown","20b614f7":"markdown","3315dc7a":"markdown","35fb92d1":"markdown","c573de47":"markdown","6386b645":"markdown","8405630b":"markdown","5705d8d9":"markdown","de894a3b":"markdown","0fac37c8":"markdown","f0457d17":"markdown","9bbb5638":"markdown","9b1d641b":"markdown","27bd426e":"markdown","902f083c":"markdown","b69d7d2a":"markdown","5198cfa0":"markdown","c73ee9b7":"markdown","9f942dc5":"markdown","da34c23d":"markdown","72ec367a":"markdown","993b1944":"markdown","ce115c52":"markdown","41be3bd0":"markdown","25fc1555":"markdown","94fd6762":"markdown","a8e48bb5":"markdown","8929afd6":"markdown","ce496e5d":"markdown","b646f5b5":"markdown"},"source":{"535a0bb1":"import pydicom\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport seaborn as sns\nfrom tqdm import tqdm, tqdm_notebook\nimport gc\nfrom keras.applications.densenet import preprocess_input, DenseNet169\nfrom keras.models import Model\nfrom keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\nimport keras.backend as K\n\nsns.set()\n\n%config InlineBackend.figure_format = 'retina'","c71b129c":"train_df = pd.read_csv(\"..\/input\/siim-isic-melanoma-classification\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/siim-isic-melanoma-classification\/test.csv\")","88d7eb07":"train_df.shape","b1fd00dd":"train_df.head()","ab30a8b9":"test_df.head()","0300e70d":"train_df.isnull().sum()","0f24b465":"test_df.isnull().sum()","448e6808":"train_df.describe() #Two numeric features","8eff1ea7":"train_df['sex'].hist(figsize=(10, 4))","f412b4a4":"train_df['sex'].value_counts(normalize = True)","5bd323cc":"plt.hist(train_df['age_approx'], bins = 10)","ed379405":"sns.boxplot(x = 'age_approx', data = train_df)","967992ca":"train_df[train_df['age_approx'] < 5].head(10)","3f766c44":"train_df['age_approx'].max()","ef14763b":"train_df['anatom_site_general_challenge'].value_counts(normalize = True)","ed36f876":"test_df['anatom_site_general_challenge'].value_counts(normalize = True)","a94adf81":"fig, ax = plt.subplots(figsize = (10, 8))\nsns.countplot(y = 'anatom_site_general_challenge', data = train_df)\nplt.ylabel(\"Anatom site\")","307a976f":"train_df['diagnosis'].value_counts(normalize = True)","0ae7e84e":"train_df[train_df['diagnosis'] != 'unknown']['diagnosis'].value_counts(normalize = True)","d6337c19":"real_diagn = train_df[train_df['diagnosis'] != 'unknown']['diagnosis']","5a498ce1":"fig, ax = plt.subplots(figsize = (10, 8))\nsns.countplot(y = real_diagn)\nplt.ylabel(\"Diagnosis\")","b960baca":"train_df['benign_malignant'].value_counts()","2f487a94":"pd.crosstab(train_df['benign_malignant'], train_df['target']) ","d97c9e20":"train_df['target'].value_counts(normalize = True)","5c5fa3fa":"test_df.head()","4259cdbc":"test_df.isnull().sum()","b9952c86":"train_df.groupby(['sex'])['target'].agg([np.mean, np.sum])","eca9ea7f":"fig, ax = plt.subplots(figsize = (10, 8))\nsns.countplot(x = 'target', hue = 'sex', data = train_df)","10a3d9a1":"sns.boxplot(x = 'target', y = 'age_approx', data = train_df)","d4adc4c0":"fig, ax = plt.subplots(figsize = (10, 8))\nsns.countplot(y = 'anatom_site_general_challenge', hue = 'target', data = train_df)\nplt.ylabel(\"Anatom site\")","38ea2032":"pd.crosstab(train_df['anatom_site_general_challenge'], train_df['target'], normalize = True)","61e9eab3":"train_df['patient_id'].nunique(), test_df['patient_id'].nunique()","4fdf10ff":"jpeg_dir_train = \"..\/input\/siim-isic-melanoma-classification\/jpeg\/train\"","ee982770":"first = train_df['patient_id'].unique()[0]\nfirst","755f907b":"train_df[train_df['patient_id'] == first]['image_name']","b9f839b0":"img_names = train_df[train_df['patient_id'] == first]['image_name'][:12]\nimg_names = img_names.apply(lambda x: x + '.jpg')\nimg_names","2d74d405":"plt.figure(figsize = (12,10))\nfor i in range (len(img_names)):\n    plt.subplot(4,4, i + 1)\n    img = plt.imread(os.path.join(jpeg_dir_train, img_names.iloc[i]))\n    plt.imshow(img, cmap = 'gray')\n    plt.axis('off')\n    \nplt.tight_layout()","2da00487":"img_names = train_df[train_df['target'] == 0]['image_name'][:8]\nimg_names = img_names.apply(lambda x: x + '.jpg')\nprint ('Benign growths:')\n\nplt.figure(figsize = (12,10))\nfor i in range (len(img_names)):\n    plt.subplot(4,4, i + 1)\n    img = plt.imread(os.path.join(jpeg_dir_train, img_names.iloc[i]))\n    plt.imshow(img, cmap = 'gray')\n    plt.axis('off')\n    \nplt.tight_layout()","72c9dfd6":"img_names = train_df[train_df['target'] == 1]['image_name'][:8]\nimg_names = img_names.apply(lambda x: x + '.jpg')\nprint ('Malignant growths:')\n\nplt.figure(figsize = (12,10))\nfor i in range (len(img_names)):\n    plt.subplot(4,4, i + 1)\n    img = plt.imread(os.path.join(jpeg_dir_train, img_names.iloc[i]))\n    plt.imshow(img, cmap = 'gray')\n    plt.axis('off')\n    \nplt.tight_layout()","ceb1b56a":"train_dcm_path = \"..\/input\/siim-isic-melanoma-classification\/train\"\ntest_dcm_path = \"..\/input\/siim-isic-melanoma-classification\/test\"","49249bab":"os.listdir(train_dcm_path)[0]","04a3892a":"first_file_path = os.path.join(train_dcm_path, os.listdir(train_dcm_path)[0]) \ndicom_file = pydicom.dcmread(first_file_path)\ndicom_file","fb8ac376":"def show_dcm_info(dataset):\n    print(\"Filename.........:\", file_path)\n    print(\"Storage type.....:\", dataset.SOPClassUID)\n    print()\n\n    pat_name = dataset.PatientName\n    display_name = pat_name.family_name + \", \" + pat_name.given_name\n    print(\"Patient's name......:\", display_name)\n    print(\"Patient id..........:\", dataset.PatientID)\n    print(\"Patient's Age.......:\", dataset.PatientAge)\n    print(\"Patient's Sex.......:\", dataset.PatientSex)\n    print(\"Modality............:\", dataset.Modality)\n    print(\"Body Part Examined..:\", dataset.BodyPartExamined)\n    \n    if 'PixelData' in dataset:\n        rows = int(dataset.Rows)\n        cols = int(dataset.Columns)\n        print(\"Image size.......: {rows:d} x {cols:d}, {size:d} bytes\".format(\n            rows=rows, cols=cols, size=len(dataset.PixelData)))\n        if 'PixelSpacing' in dataset:\n            print(\"Pixel spacing....:\", dataset.PixelSpacing)","e1c21714":"def plot_pixel_array(dataset, figsize=(5,5)):\n    plt.figure(figsize=figsize)\n    plt.imshow(dataset.pixel_array, cmap=plt.cm.bone)\n    plt.show()","d53e5192":"n_files = 5\nfilenames = os.listdir(train_dcm_path)[:n_files]\nfor file_name in filenames:\n    file_path = os.path.join(train_dcm_path, file_name)\n    dataset = pydicom.dcmread(file_path)\n    show_dcm_info(dataset)\n    plot_pixel_array(dataset)","57fc1504":"def extract_DICOM_attributes():\n    images = list(os.listdir(PATH))\n    df = pd.DataFrame()\n    for image in images:\n        image_name = image.split(\".\")[0]\n        dicom_file_path = os.path.join(PATH, image)\n        dicom_file_dataset = pydicom.read_file(dicom_file_path)\n        study_date = dicom_file_dataset.StudyDate\n        modality = dicom_file_dataset.Modality\n        age = dicom_file_dataset.PatientAge\n        sex = dicom_file_dataset.PatientSex\n        body_part_examined = dicom_file_dataset.BodyPartExamined\n        patient_orientation = dicom_file_dataset.PatientOrientation\n        photometric_interpretation = dicom_file_dataset.PhotometricInterpretation\n        rows = dicom_file_dataset.Rows\n        columns = dicom_file_dataset.Columns\n\n        df = df.append(pd.DataFrame({'image_name': image_name, \n                        'dcm_modality': modality,'dcm_study_date':study_date, 'dcm_age': age, 'dcm_sex': sex,\n                        'dcm_body_part_examined': body_part_examined,'dcm_patient_orientation': patient_orientation,\n                        'dcm_photometric_interpretation': photometric_interpretation,\n                        'dcm_rows': rows, 'dcm_columns': columns}, index=[0]))\n    return df","b150279d":"PATH = train_dcm_path\ndcm_df = extract_DICOM_attributes()","2d4049ff":"dcm_df.head()","e8bd6555":"dcm_df.columns","e763d816":"dcm_df['dcm_modality'].value_counts() ","ce67e4ad":"dcm_df['dcm_sex'].value_counts()","3fd7028a":"train_df.sex.value_counts()","392cd439":"train_df.sex.isnull().sum()","9cb94bfa":"dcm_df['dcm_photometric_interpretation'].value_counts()","3fd52470":"img_to_compare = cv2.imread('..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/ISIC_0015719.jpg')\nimg_to_compare.shape","4d9a5848":"rows_to_disp = ['dcm_rows', 'dcm_columns']\ndcm_df[dcm_df['image_name'] == 'ISIC_0015719'][rows_to_disp]","524f3a3c":"del dcm_df, rows_to_disp, img_to_compare, filenames","e79ab342":"train_df.isnull().sum()","22d1b605":"missing_ids_sex = train_df[train_df['sex'].isnull()]['patient_id']\nmissing_ids_sex.unique()","f0ebfbc0":"train_df.loc[train_df['patient_id'].isin(missing_ids_sex.unique()), ['sex']]['sex'].value_counts()","2452cc46":"missing_ids_age = train_df[train_df['age_approx'].isnull()]['patient_id']\nmissing_ids_age.unique()","9c2800a6":"train_df.loc[train_df['patient_id'].isin(missing_ids_age.unique()), ['age_approx']]['age_approx'].value_counts()","9b63e82c":"set(missing_ids_age) - set(missing_ids_sex)","631ebdba":"missing_ids_site = train_df[train_df['anatom_site_general_challenge'].isnull()]['patient_id']\nmissing_ids_site.unique() ","9c27297d":"ind_to_drop = train_df[train_df['patient_id'].isin(missing_ids_sex.unique())].index\ntrain_df.drop(index = ind_to_drop, inplace = True)","5196b7be":"train_df.isnull().sum()","11d49a39":"id_w_zero = train_df[train_df['age_approx'] < 5]['patient_id']\nid_w_zero.values","0fe380c1":"ind_zero = train_df.loc[train_df['patient_id'].isin(id_w_zero.values)].index\ntrain_df.loc[train_df['patient_id'].isin(id_w_zero.values)]","ca4bbbb8":"train_df.loc[ind_zero, 'age_approx'] = 10.0\ntrain_df.loc[ind_zero]","bb70f7e7":"val = {'age_approx' : train_df['age_approx'].mean()}\ntrain_df.fillna(val, inplace = True)","7b45e98f":"train_df.isnull().sum()","70dcbf54":"mapping = {'male' : 1, 'female' : 0}\ntrain_df['sex'] = train_df['sex'].map(mapping)\ntest_df['sex'] = test_df['sex'].map(mapping)\ntrain_df.head()","ae14cb19":"train_df[train_df['anatom_site_general_challenge'].isna()]['target'].value_counts()","2fd488a1":"ind_to_drop = train_df[(train_df['anatom_site_general_challenge'].isna()) & (train_df['target'] == 0)].index\nind_to_drop","6123c3f2":"train_df.drop(ind_to_drop, inplace = True)","97809180":"train_df.isnull().sum() ,train_df.shape","6ba9aaff":"train_df = train_df.fillna('torso')","9cfdba55":"train_df.isnull().sum()","d47b8b9e":"train_df = train_df.drop(['diagnosis', 'benign_malignant'], axis = 1)\ntrain_df.head()","19d738b3":"X_train, y_train = train_df.drop('target', axis = 1), train_df['target']","86c6c870":"X_train","83fdcf05":"y_train","3dfb98d8":"test_df.isnull().sum()","51df8b29":"from sklearn.impute import SimpleImputer\nimp = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\nimp.fit(X_train)\nind, col = test_df.index, test_df.columns\nX_test = pd.DataFrame(imp.transform(test_df), index = ind, columns = col)\nX_test.head()","acaae55f":"X_test.isnull().sum()","e223c9e9":"X_train.head()","351ad2e3":"cat_features = [\"anatom_site_general_challenge\"]\nencoded = pd.get_dummies(X_train[cat_features])\nencoded.set_index(X_train.index)\nX_train.drop(cat_features, inplace = True, axis = 1)\nX_train_encoded = pd.concat([X_train,encoded], axis = 1)","27394678":"X_train_encoded.head()","556abab7":"encoded = pd.get_dummies(X_test[cat_features])\nencoded.set_index(X_test.index)\nX_test.drop(cat_features, inplace = True, axis = 1)\nX_test_encoded = pd.concat([X_test,encoded], axis = 1)","4355a46c":"X_test_encoded.head()","ec248752":"train_df_clean = pd.concat([X_train_encoded, y_train], axis = 1)\ntest_df_clean = X_test_encoded","0ca8bbbc":"train_df_clean.head()","96c26f7a":"train_df_clean.to_csv('train_clean.csv', index=False)\ntest_df_clean.to_csv('test_clean.csv', index=False)","febc9e91":"img_size = 256\n\n#Paths to train and test images\ntrain_img_path = '\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/train\/'\ntest_img_path = '\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/test\/'\n\ndef resize_image(img):\n    old_size = img.shape[:2]\n    ratio = float(img_size)\/max(old_size)\n    new_size = tuple([int(x*ratio) for x in old_size])\n    img = cv2.resize(img, (new_size[1],new_size[0]))\n    delta_w = img_size - new_size[1]\n    delta_h = img_size - new_size[0]\n    top, bottom = delta_h\/\/2, delta_h-(delta_h\/\/2)\n    left, right = delta_w\/\/2, delta_w-(delta_w\/\/2)\n    color = [0,0,0]\n    new_img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n    return new_img\n\ndef load_image(path, img_id):\n    path = os.path.join(path,img_id+'.jpg')\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    new_img = resize_image(img)\n    new_img = preprocess_input(new_img)\n    return new_img","80c5d51b":"fig = plt.figure(figsize=(16, 16))\nfor i,image_id in enumerate(np.random.choice(train_df[train_df['target']== 0].image_name,5)):\n    image = load_image(train_img_path,image_id)\n    fig.add_subplot(1,5,i+1)\n    plt.imshow(image)","da1d4aa3":"fig = plt.figure(figsize=(16, 16))\nfor i,image_id in enumerate(np.random.choice(train_df[train_df['target']== 1].image_name,5)):\n    image = load_image(train_img_path,image_id)\n    fig.add_subplot(1,5,i+1)\n    plt.imshow(image)","37094ace":"train_df.head()","a3ac292e":"batch_size = 16\n\ntrain_img_ids = train_df.image_name.values\nn_batches = len(train_img_ids) \/\/ batch_size + 1\n\n#Model to extract image features\ninp = Input((256,256,3))\nbackbone = DenseNet169(input_tensor = inp, include_top = False)\nx = backbone.output\nx = GlobalAveragePooling2D()(x)\nx = Lambda(lambda x: K.expand_dims(x,axis=-1))(x)\nx = AveragePooling1D(4)(x)\nout = Lambda(lambda x: x[:,:,0])(x)\n\nm = Model(inp,out)","64ec5c77":"features = {}\nfor b in tqdm_notebook(range(n_batches)):\n    start = b*batch_size\n    end = (b+1)*batch_size\n    batch_ids = train_img_ids[start:end]\n    batch_images = np.zeros((len(batch_ids),img_size,img_size,3))\n    for i,img_id in enumerate(batch_ids):\n        try:\n            batch_images[i] = load_image(train_img_path,img_id)\n        except:\n            pass\n    batch_preds = m.predict(batch_images)\n    for i,img_id in enumerate(batch_ids):\n        features[img_id] = batch_preds[i]","b015a9e8":"train_feats = pd.DataFrame.from_dict(features, orient = 'index')\ntrain_feats.to_csv('train_img_features.csv')\ntrain_feats.head()","84fae05a":"test_img_ids = test_df.image_name.values\nn_batches = len(test_img_ids) \/\/ batch_size + 1","451f9e53":"features = {}\nfor b in tqdm_notebook(range(n_batches)):\n    start = b*batch_size\n    end = (b+1)*batch_size\n    batch_ids = test_img_ids[start:end]\n    batch_images = np.zeros((len(batch_ids),img_size,img_size,3))\n    for i,img_id in enumerate(batch_ids):\n        try:\n            batch_images[i] = load_image(test_img_path,img_id)\n        except:\n            pass\n    batch_preds = m.predict(batch_images)\n    for i,img_id in enumerate(batch_ids):\n        features[img_id] = batch_preds[i]","6188241f":"test_feats = pd.DataFrame.from_dict(features, orient='index')\ntest_feats.to_csv('test_img_features.csv')\ntest_feats.head()","6c0363de":"train_feat_img = pd.read_csv ('..\/input\/melanoma-dataset-for-images\/train_img_features.csv')\ntest_feat_img = pd.read_csv ('..\/input\/melanoma-dataset-for-images\/test_img_features.csv')","bb3086d9":"test_feat_img.head()","5fdbb0f7":"train_feat_img = train_feat_img.set_index('Unnamed: 0')","de56067b":"test_feat_img = test_feat_img.set_index('Unnamed: 0')","93b60bf7":"train_feat_img.head()","a6fa5097":"test_feat_img.head()","3c0976c8":"train_data = pd.read_csv('.\/train_clean.csv')\ntest_data = pd.read_csv('.\/test_clean.csv')","fee550f8":"train_data.head()","c7db6ea5":"X_train_encoded = train_data.drop('target', axis = 1)\ny_train = train_data['target']","66f4970d":"X_train_encoded.head()","ad50004f":"y_train.head()","14ca3f85":"X_train_full =  X_train_encoded.merge (train_feat_img, \n                       how = 'inner',\n                      left_on = 'image_name', \n                      right_index = True,\n                      )","c16481de":"X_train_full.head()","84470f97":"X_test_full = test_data.merge (test_feat_img, \n                      how = 'inner',\n                      left_on = 'image_name', \n                      right_index = True,\n                      )","efbaece9":"X_test_full.head()","67541853":"X_train_full.drop(['image_name', 'patient_id'], inplace = True, axis = 1)","aa3a230e":"X_train_full.head()","4f7d62b5":"X_test_full.head()","ba0ade82":"X_test_full.drop('patient_id', axis = 1, inplace = True)\nX_test_full = X_test_full.set_index('image_name')","6573650c":"X_test_full.head()","e9d29e68":"import xgboost as xgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, make_scorer\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score","5b46d60a":"boosting = xgb.XGBClassifier(max_depth = 8, \n                            reg_lambda = 1.2,\n                            subsample = 0.8, \n                            n_estimators = 400, \n                            min_child_weight = 2, \n                            learning_rate = 0.1)","316894cd":"skf = StratifiedKFold(n_splits = 3)\nscore_cv = cross_val_score(boosting, X_train_full, y_train, cv = skf, scoring = 'roc_auc')","56395460":"score_cv","9a417535":"boosting.fit(X_train_full, y_train)","3068b19b":"y_test = boosting.predict_proba(X_test_full)[:, 1]","ae0f9509":"submission = pd.DataFrame({\n    'image_name': X_test_full.index,  \n    'target' : y_test\n})","88e31309":"submission.to_csv('submission.csv', index = False)","09ae5269":"Things get much more complex with test dataset","f711ed4f":"Let's drop two patients, who don't have age and sex in dataset","d2a4a63f":"We load data from csv file","eddab165":"So modality column doesn't help us too much","55115cc3":"So benign\/malignant is actually our target. Of course, we don't have this feature in our test dataset","e005808a":"These methods were taken from this [kernel ](https:\/\/www.kaggle.com\/schlerp\/getting-to-know-dicom-and-the-data)","3262a930":"Get our submissions!","53b7811f":"So it's just size of our image. Duh","8f0afabb":"Two patients (IP_5205991 and IP_9835712) have no age nor sex in dataset. They miss pretty helpful features for us","289bb5d7":"Extract target from train dataset","61d1051d":"Let's drop not useful features so they won't bother our training","8101aa33":"Rememdering train.csv we understand, what blank space actually is, but what X means isn't clear","e2618311":"Let's compare different types of growths with images:","4dc52bcd":"Now let's deal with categorical data","fa5911c3":"Convert them to pandas Dataframe","5716e906":"First replace 'male' and 'female' values with numbers","bd5a0d73":"Method for extracting data from DICOM files was taken from [this](https:\/\/www.kaggle.com\/c\/siim-isic-melanoma-classification\/discussion\/154658) discussion","8da64395":"This takes lots of time, so to make it easier already did it and loaded into dataset ","5c47a6e2":"Now we will do the same thing for test dataset","9b0eb352":"Since age is one of our numeric features, let's make a boxplot for it","6b2b9905":"So what is actually rows and columns features? Let's check our first image","7d3a6c27":"So I feel like just dropping those 518 instances of benign growths won't harm our dataset too much, while rows with malignant growths will have median value in anatom_site feature ","0aa08d59":"Now our train and test datasets don't have missing values. It's time to make categorical features one-hot encoded. We have only one such feature, which is anatom_site","2fc0a92c":"Image processing and resizing was taken from [this](https:\/\/www.kaggle.com\/anshuls235\/siim-isic-melanoma-analysis-eda-prediction#2.-Studying-the-data) kernel","d9521b16":"Let's check shape of our train dataset","c255a2ac":"# Getting features from images","bd85cc5b":"After fitting make predictions. We need to predict probability, since scores in the competition is ROC-AUC","562752cf":"Make stratified folds, so there will be equal part of benign and malignant growths in each fold","859d20fb":"Remembering two patients with age zero, we should change their age as well","54bf1ae6":"We see very imbalanced train dataset","66d64a9c":"After all, we didn't find any helpful information from .dmc files, but at least we tried. Next step is going to be data preprocessing. But before it let's clear our memory","39b06f9e":"It would be a good idea to drop useless columns from train dataset, since test dataset doesn't have such columns as diagnosis and benign_malignant","6462ab59":"# Dicom files overview","3df4535c":"Let's make combine two of our datasets","d9f5a5a1":"# **Load Data**","612f428e":"Let's do the same thing for test set","92188138":"Let's display images for first patient in train dataset","91456aff":"So older people are more likely to get malignant growth","e0d44f03":"For this task I will use gradient boosting from xgboost library. After spending couple hours of training, I found this hyperparameters the best","c9d40aec":"We see outliers with age of 0","4e472322":"Interesting and helpful kernels about DICOM are [here](https:\/\/www.kaggle.com\/schlerp\/getting-to-know-dicom-and-the-data) and [here](https:\/\/www.kaggle.com\/gpreda\/visualize-ct-dicom-data). For now let's just find out if we can get valuable information from this data","408c6b2b":"Let's check dataframe that we got from dcm ","6bfa2202":"Take a look at first 5 rows of our train dataset","dad494f4":"Here we display information about patient and an image of growth","a28fe27f":"We see that there are more men in our train dataset than women","8d8e3272":"Looks like we have need to somehow imput missing values in anatom_site feature both in train and in test datasets","62d298f5":"Another not too informative feature","48d4401a":"Also we got some new features like photometric interpretation, let's check them","6d6e437b":"There are two patients with age 0. Well, it may be actually newborn babys, but they are obwiously outliers, who can worse our predictions","341bd7ba":"So nevus is actually benign growth, while melanoma is malignant","a641ae34":"Now let's display malignant growths:","bd1abcdf":"Probably taking median value from train dataset will be fine, since distribution of anatom site feature is similar in train and test datasets","578398b5":"So there's obviously mistake in data, patient IP_1300691 is actually 10 years  old, but in two rows his age is zero. Let's fix it","840051e8":"This takes a lot of time and memory!","d38a16ac":"Do the same thing for test dataset","c94b81e4":"Let's compare some features with each other to see if we can find something interesting","2853be82":"So men are actually more likely to get malignant growth","4e8fc925":"So we have same situation with ages. There's no data about age of these patients in dataset","07a59b28":"So we have some missing values in test dataset as well","20b614f7":"Let's save preprocessed data","3315dc7a":"# EDA (Exploratory Data Analysis)","35fb92d1":"Define methods for resize and loading images","c573de47":"# Data preprocessing","6386b645":"Two patients have missing sex column","8405630b":"Let's take a look at patients with missing values in features","5705d8d9":"Back to missing values:","de894a3b":"In addition we have .dcm files in our data, which are DICOM type of files. This format is actually widely used in different medical competitions. We already loaded pydicom library in the start, so now we can try to use it for overviewing data we have","0fac37c8":"We load a DenseNet neural network, which can be used to get features from our image data.  ","f0457d17":"So most of diagnosis are labeled as 'unknown'. Let's see real diadnosis distribution","9bbb5638":"We see a lot of new data, but some of it we already know from .csv file","9b1d641b":"Style of displaying images was taken from this [kernel](https:\/\/www.kaggle.com\/parulpandey\/melanoma-classification-eda-starter)","27bd426e":"So malignant growths are more likely to be on torso","902f083c":"More than a half of patients have growths on torso and the same picture we see in test dataset","b69d7d2a":"Age distribution looks normal","5198cfa0":"Good, we fixed incorrect data about patient. Now we can input mean column values instead of missing values of age in dataset","c73ee9b7":"We convert features in a Dataframe","9f942dc5":"As we see any rows with their ID have missing sex. Let's check the same thing for age:","da34c23d":"See cross validation scores ","72ec367a":"Three patients have missing age","993b1944":"We see that some values are missing. Most of the missing values are in column representing site where growth is","ce115c52":"In a loop we get batches of images and extract features from them","41be3bd0":".describe doesn't help us too much, because we have only 2 numeric features","25fc1555":"There are 115 images for first patient. Let's display only few of them","94fd6762":"The oldest patient is 90 years old","a8e48bb5":"Amount of unique patients in both train and test datasets:","8929afd6":"We have a quite large number of patients missing anatom site where growth is","ce496e5d":"Let's see first dcm file","b646f5b5":"Now we have combined two datasets into a new full one"}}