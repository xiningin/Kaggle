{"cell_type":{"5ee4bcf6":"code","f8158550":"code","9b46dbb2":"code","9c20ae64":"code","627a6b66":"code","167eb77c":"code","f071fc80":"code","0934bec4":"code","d9be32e4":"code","f7ad3ac7":"code","28a56038":"code","c1a5a44c":"code","cdd2f7b4":"code","c0fe4217":"code","50fbe3c0":"code","1ff760b0":"code","b7384188":"code","20971901":"code","a0af41aa":"code","3bc421cc":"code","1412cb67":"code","77d071ca":"code","c463c371":"code","dc4b67c0":"code","41e6e3b6":"code","28e5df9e":"code","8d91df1d":"code","47e54fb0":"code","a0e44b71":"code","49ecca18":"code","a54648bc":"code","3dc28e0c":"code","c177c0fe":"code","ab9f62c1":"code","e43c7498":"markdown","80619792":"markdown","da454815":"markdown","923cb0c8":"markdown","4c4d86e5":"markdown","3d21c1f0":"markdown","cba6d69b":"markdown","70708d13":"markdown","c3dd1df6":"markdown","ccee2f64":"markdown","55b31b75":"markdown","30f79e52":"markdown","0a2a6d23":"markdown","a83d8220":"markdown","0278d9d4":"markdown","7a5c3452":"markdown","4e74b548":"markdown","524faec9":"markdown","c1af2234":"markdown","fd918796":"markdown","bb6ee703":"markdown","45d304af":"markdown","5b37b101":"markdown","25c4814b":"markdown","9105b9dd":"markdown","6979fd1d":"markdown","ac9333d0":"markdown","f1c0b5b8":"markdown","9b2c94e9":"markdown","89935339":"markdown","84e0624e":"markdown","26c0e500":"markdown","2f9ea19a":"markdown","f4663bb2":"markdown","573bb6bb":"markdown","ff1dd276":"markdown"},"source":{"5ee4bcf6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom plotly.offline import plot, iplot, init_notebook_mode as py\nimport seaborn as sns\nimport plotly.graph_objs as go\n\n#for standardising data\nfrom sklearn.preprocessing import StandardScaler \n\nfrom sklearn.model_selection import train_test_split \n\nfrom sklearn import svm\n\nfrom sklearn.metrics import accuracy_score\n\nimport joblib\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","f8158550":"df=pd.read_csv('..\/input\/docspot\/datasets_228_482_diabetes.csv')","9b46dbb2":"\nprint(\"-\"*50)\nprint('Shape of the dataframe:',df.shape)\nprint(\"Number of records in train data set:\",df.shape[0])\nprint(\"Information of the dataset:\")\ndf.info()\nprint(\"-\"*50)\nprint(\"First 5 records of the dataset:\")\n\n\ndf.head()\n\nprint(\"-\"*50)\n","9c20ae64":"# Define missing plot to detect all missing values in dataset\ndef missing_plot(dataset, key) :\n    null_feat = pd.DataFrame(len(dataset[key]) - dataset.isnull().sum(), columns = ['Count'])\n    percentage_null = pd.DataFrame((len(dataset[key]) - (len(dataset[key]) - dataset.isnull().sum()))\/len(dataset[key])*100, columns = ['Count'])\n    percentage_null = percentage_null.round(2)\n\n    trace = go.Bar(x = null_feat.index, y = null_feat['Count'] ,opacity = 0.8, text = percentage_null['Count'],  textposition = 'auto',marker=dict(color = '#7EC0EE',\n            line=dict(color='#000000',width=1.5)))\n\n    layout = dict(title =  \"Missing Values (count & %)\")\n\n    fig = dict(data = [trace], layout=layout)\n    iplot(fig)\n    ","627a6b66":"# Plotting \nmissing_plot(df, 'Outcome')","167eb77c":"df.describe()","f071fc80":"corr = df.corr()\ncorr","0934bec4":"sns.heatmap(corr, \n        xticklabels=corr.columns,\n        yticklabels=corr.columns)","d9be32e4":"print('Target of 0 is {} % of total'.format(round(df['Outcome'].value_counts()[0]\/len(df['Outcome'])*100)))\nprint('Target of 1 is {} % of total'.format(round(df['Outcome'].value_counts()[1]\/len(df['Outcome'])*100)))\nx=df.Outcome.value_counts()\nsns.barplot(x.index,x)\nplt.gca().set_ylabel('samples')","f7ad3ac7":"df.groupby('Outcome').mean()","28a56038":"\n# to plot a boxplot of\n# age vs Outcome\nplt.figure(figsize=(10, 8))\nsns.boxplot(x='Outcome',\n            y='Age',\n            data=df)\nplt.ylabel(\"Age\", size=14)\nplt.xlabel(\"Outcome\", size=14)\nplt.title(\"Average age of non-diabetic and diabetic people in the dataset\", size=18)","c1a5a44c":"X=df.drop(columns='Outcome' , axis=1)\nY=df['Outcome']\n","cdd2f7b4":"X.head()","c0fe4217":"Y.head()","50fbe3c0":"scaler=StandardScaler()\n\nscaler.fit(X)\nstandardized_data=scaler.transform(X)","1ff760b0":"print(standardized_data)","b7384188":"X=standardized_data\nY=df['Outcome']","20971901":"X_train, X_test, Y_train, Y_test =train_test_split(X,Y,test_size=0.2,random_state=2,stratify=Y)","a0af41aa":"classifier=svm.SVC(kernel='linear', random_state=42)","3bc421cc":"# Fitting the model \n\nclassifier.fit(X_train, Y_train)","1412cb67":"# Accuracy score\n\nX_train_prediction=classifier.predict(X_train)\n\ntraining_accuracy=accuracy_score(X_train_prediction, Y_train)\nprint('Accuracy Score of the training Data : {} '.format(training_accuracy))","77d071ca":"# Accuracy score\n\nX_test_prediction=classifier.predict(X_test)\n\ntest_accuracy=accuracy_score(X_test_prediction, Y_test)\n\nprint('Accuracy Score of the testing Data : {} '.format(test_accuracy))","c463c371":"input_data = (5,166,72,19,175,25.8,0.587,51)\n\n\n# changing the input_data to numpy array\ninput_data_as_numpy_array = np.asarray(input_data)\n\n# reshape the array as we are predicting for one instance\ninput_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n","dc4b67c0":"# standardize the input data\nstd_data = scaler.transform(input_data_reshaped)\nprint(std_data)\n","41e6e3b6":"# standardize the input data\nstd_data = scaler.transform(input_data_reshaped)\nprint(std_data)\n\nprediction = classifier.predict(std_data)\nprint(prediction)\n\nif (prediction[0] == 0):\n  print('The person is not diabetic')\nelse:\n  print('The person is diabetic')","28e5df9e":"labels = list(df.drop('Outcome',1).columns)\nlabels","8d91df1d":"coeff = list(classifier.coef_[0])\ncoeff","47e54fb0":"features = pd.DataFrame()\nfeatures['Features'] = labels\nfeatures['importance'] = coeff\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures['positive'] = features['importance'] > 0\nfeatures.set_index('Features', inplace=True)\nfeatures.importance.plot(kind='barh', figsize=(11, 6),color = features.positive.map({True: 'blue', False: 'red'}))\nplt.xlabel('Importance')","a0e44b71":"#model saving and loading\njoblib.dump(classifier, 'diabeteseModel.pkl')\ndiabetesLoadedModel = joblib.load('diabeteseModel.pkl')","49ecca18":"#testing loaded model to make prediction\naccuracyModel = diabetesLoadedModel.score(X_test,Y_test)\nprint(\"accuracy = \",accuracyModel * 100,\"%\")","a54648bc":"pip install hasy_tools","3dc28e0c":"from sklearn.ensemble import BaggingClassifier\nimport hasy_tools  # \nfrom sklearn.svm import LinearSVC\n","c177c0fe":"svm = LinearSVC(random_state=42)\nmodel = BaggingClassifier(base_estimator=svm, n_estimators=31, random_state=314)\n# Fit\nmodel.fit(X_train, Y_train)","ab9f62c1":"# Accuracy score\n\nX_train_prediction=model.predict(X_train)\n\ntraining_accuracy=accuracy_score(X_train_prediction, Y_train)\nprint('Accuracy Score of the training Data : {} '.format(training_accuracy))","e43c7498":"Now we will save our trained model for future use using joblib.","80619792":"## Overview","da454815":"# Evaluate the Model \n","923cb0c8":"So there's no missing data ","4c4d86e5":"Separating the data and labels","3d21c1f0":"Let\u2019s also make sure that our data is clean (has no null values, etc).\n","cba6d69b":"A support vector machine takes these data points and outputs the **hyperplane** (which in two dimensions it\u2019s simply a line) that best separates the tags. This line is the **decision boundar**y: anything that falls to one side of it we will classify as blue, and anything that falls to the other as red.\n\n![image.png](attachment:9a704169-ccc3-412f-ac5e-b04f4e3d765f.png)","70708d13":"## Saving the Model ","c3dd1df6":"# **Predicting Diabetes with SVM **","ccee2f64":"### How Does SVM Work?\nThe basics of Support Vector Machines and how it works are best understood with a simple example. \n\nLet\u2019s imagine we have two tags: red and blue, and our data has two features: x and y. We want a classifier that, given a pair of (x,y) coordinates, outputs if it\u2019s either red or blue. We plot our already labeled training data on a plane:","55b31b75":"**The Model correctly predict this person as diavetic which is correct**","30f79e52":"To check whether we have saved the model properly or not, we will use our test data to check the accuracy of our saved model (we should observe no change in accuracy if we have saved it properly).","0a2a6d23":"# Model \n\n","a83d8220":"We\u2019ll be using Python and some of its popular data science related packages. First of all, we will import pandas to read our data from a CSV file and manipulate it for further use. We will also use numpy to convert out data into a format suitable to feed our classification model. We\u2019ll use seaborn and matplotlib for visualizations. We will then import SVM algorithm from sklearn. This algorithm will help us build our classification model. Lastly, we will use joblib available in sklearn to save our model for future use.","0278d9d4":"From the above figure, we can draw the following conclusions.\n1. Glucose level, BMI, pregnancies and diabetes pedigree function have significant influence on the model, specially glucose level and BMI. \n\n2. Blood pressure has a negative influence on the prediction, higher blood pressure is correlated with a person not being diabetic. ","7a5c3452":"SVM or Support Vector Machine is a linear model for classification and regression problems. \n\nIt can solve linear and non-linear problems and work well for many practical problems. \nThe idea of SVM is simple: The algorithm creates a line or a hyperplane which separates the data into classes.\nA support vector machine (SVM) is a **supervised** machine learning model that uses **classification** algorithms for two-group classification problems. \n\nAfter giving an SVM model sets of labeled training data for each category, they\u2019re able to categorize new data.","4e74b548":"We can see that all tha values in a similare rang","524faec9":"Attributs Colleration ","c1af2234":"![![image.png](attachment:ca2b7882-c588-4aab-a55c-b927934a5583.png)]","fd918796":"## Overview on SVM ","bb6ee703":"The following features have been provided to help us predict whether a person is diabetic or not:\n\n* **Pregnancies**: Number of times pregnant\n\n* **Glucose**: Plasma glucose concentration over 2 hours in an oral glucose tolerance test\n\n* **BloodPressure**: Diastolic blood pressure (mm Hg)\n\n* **SkinThickness**: Triceps skin fold thickness (mm)\n\n* **Insulin**: 2-Hour serum insulin (mu U\/ml)\n\n* **BMI**: Body mass index (weight in kg\/(height in m)2)\n\n* **DiabetesPedigreeFunction**: Diabetes pedigree function (a function which scores likelihood of diabetes based on family history)\n\n* **Age**: Age (years)\n\n* **Outcome**: Class variable (0 if non-diabetic, 1 if diabetic)","45d304af":"### Making Predictions with the model\nWe will now use our unused data to see how predictions can be made. ","5b37b101":"Checking data head and info\n\n","25c4814b":"Visualization of the weights in the SVM model corresponding to each of the feature variables\n","9105b9dd":"Class distribution\nlets see the class distibution for 0 and 1\nWe have to predict whether a person has diabetes or not. Class variable (0 if non-diabetic, 1 if diabetic).","6979fd1d":"## Prepare dataset","ac9333d0":"Reading our csv file ","f1c0b5b8":"### What's SVM ? ","9b2c94e9":"A correlation matrix is a table showing correlation coefficients between sets of variables. Each random variable (Xi) in the table is correlated with each of the other values in the table (Xj). \nThis allows you to see which pairs have the highest correlation.","89935339":"# Data Collection and Analysis ","84e0624e":"Let's check Visually if there's any missing data ","26c0e500":"## Class distribution","2f9ea19a":"We\u2019ll be using Machine Learning to predict whether a person has diabetes or not, based on information about the patient such as blood pressure, body mass index (BMI), age, etc. ","f4663bb2":"# Data Standardization ","573bb6bb":"**Importing the necessary mentioned packages **","ff1dd276":"## Interpreting the ML Model\nTo get a better sense of what is going on inside the logistic regression model, we can visualize how our model uses the different features and which features have greater effect.\n"}}