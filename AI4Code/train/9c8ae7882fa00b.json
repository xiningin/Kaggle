{"cell_type":{"0cd45fd2":"code","f8a41b7f":"code","e807d95f":"code","1d8a2dbe":"code","2e3f2e83":"code","7a8d6004":"code","02da47a7":"code","80a925e6":"code","3882068b":"code","a608bd85":"code","03d436e7":"code","1e4b1959":"code","02532c67":"markdown","6f761cdf":"markdown","6395bbea":"markdown","de0f22b0":"markdown","0fc65668":"markdown","563e3f7d":"markdown","a67bb610":"markdown"},"source":{"0cd45fd2":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.arima_process import ArmaProcess\n\ndef garch(ar, \u03c9, \u03b1, \u03b2, n_out=1000):\n    p = len(\u03b1)\n    q = len(\u03b2)\n\n    # Since the first max(p, q) number of points are not generated from the garch\n    # process, the first points are garbage (possibly extending beyond max(p, q)),\n    # so we drop n_pre > max(p, q) number of points.\n    n_pre = np.max([p, q])+1;\n    n = n_pre + n_out\n\n    # Sample noise\n    \u025b = np.random.normal(0, 1, n)\n\n    y = ArmaProcess.from_coeffs(np.array(ar), np.array([1])).generate_sample(nsample=n)\n    \u03c3 = np.zeros(n)\n\n    \n    # Pre-populate first max(p, q) values, because they are needed in the iteration.\n    for k in range(np.max([p, q])):\n        \u03c3[k] = np.random.normal(0, 1)\n        y[k] = y[k] + \u03c3[k] * \u025b[k]\n\n    for k in range(np.max([p, q]), n):\n        \u03b1_term = sum([\u03b1[i] * y[k-i]**2 for i in range(p)])\n        \u03b2_term = sum([\u03b2[i] * \u03c3[k-i]**2 for i in range(q)])\n        \u03c3[k] = np.sqrt(\u03c9 + \u03b1_term + \u03b2_term)\n        y[k] = y[k] + \u03c3[k] * \u025b[k]\n\n    return y[n_pre:]\n\nar=[0.5,0.2,-0.1]\n\u03c9 = 0.001\n\u03b1 = [0.3,0.2]\n\u03b2 = [0.2,0.1]\n\ny = garch(ar, \u03c9, \u03b1, \u03b2, n_out=500)\nx = range(len(y))","f8a41b7f":"plt.figure(figsize=[10, 7.5]); # Set dimensions for figure\nplt.plot(y)\nplt.title(\"Simulated AR(3)-GARCH(2,2) Process\")\nplt.show()","e807d95f":"squared_y = [x**2 for x in y]","1d8a2dbe":"plt.figure(figsize=[10, 7.5]); # Set dimensions for figure\nplt.plot(squared_y)\nplt.title(\"Squared Process\")\nplt.show()","2e3f2e83":"from statsmodels.graphics.tsaplots import plot_pacf                 #Used to Plot PACF plot.\nfrom statsmodels.graphics.tsaplots import plot_acf                  #Used to Plot ACF plot.","7a8d6004":"plot_acf(y,lags=20)\nplt.show()","02da47a7":"plot_pacf(y,lags=20)\nplt.show()","80a925e6":"import statsmodels.api as sm\nmodel = sm.tsa.statespace.SARIMAX(y, order=(2,1,0)).fit()\nresiduals=model.resid\nprint(model.summary())","3882068b":"import scipy.stats as stats\nstats.jarque_bera(residuals)","a608bd85":"plot_acf(residuals,lags=20)\nplt.show()","03d436e7":"plot_pacf(residuals,lags=20)\nplt.show()","1e4b1959":"from arch import arch_model\nmodel = arch_model(residuals, mean='Zero', vol='GARCH', p=1, q=1, dist=\"Normal\")\nmodel_fit = model.fit()\nprint(model_fit.summary)","02532c67":"## Extensions to GARCH Model\n\n### GARCH-M\nGARCH-M or GARCH-in-mean model adds a heteroscedacity term in the mean equation. This addresses the limitation of the ARCH\/ GARCH models which do not allow realization of conditional variance to affect conditional expectation. \nDuring times of higher volatility, the returns on certain assets are lower than in tranquil times. GARCH-M allows this phenomenon to be modelled.\n\nThe mathematical expression is:\n$$ r_t=\\mu + c\\sigma_{t-1} ^2 + u_t $$\n$$ u_t=\\epsilon_t \\sqrt{h_t} $$\n$$ h_t= \\omega + \\alpha_1 u^2 _{t-1} + \\beta_1 h_{t-1} $$\n\n### TGARCH\nThe threshold-GARCH or TGARCH model, adds a dummy variable $d_{t-1}$ to variance equation to allow negative shocks to have a larger impact on volatility than positive shocks.\n\nMathematically the TGARCH(1,1) model can be written as:\n$$ h_t = \\omega + \\alpha_1 u^2 _{t-1} + \\gamma_1 d_{t-1} u^2 _{t-1} + \\beta_1 h_{t-1} $$\n$d_{t-1}$ is zero when $\\epsilon_{t-1} \\geq 0$ and $d_{t-1}=1$ when $\\epsilon_{t-1} \\leq 0$. \nIf $\\epsilon_{t-1} \\geq 0$ impact of $u^2 _{t-1}$ is $\\alpha_1$ and when $\\epsilon_{t-1} \\leq 0$ impact is $\\alpha_1+\\gamma_1$. So if $\\gamma_1$ is positive and statistically significant negative shocks to have a larger impact on volatility than positive shocks.\n\n### EGARCH\nThe EGARCH model employs a logarithmic transformation to $h_t$ to ensure positive variances. The coefficients can b negative unlike all other models. Mathematically the EGARCH(1,1) model can be written as:\n$$ ln(h_t) = \\omega + \\alpha_1 \\frac{u_{t-1}}{\\sqrt{h_{t-1}}} + \\gamma_1 \\left\\lvert \\frac{u_{t-1}}{\\sqrt{h_{t-1}}}\\right\\rvert +\\beta_1 ln(h_{t-1}) $$. Again, iIf $\\epsilon_{t-1} \\geq 0$ impact on $ln(h_{t-1})$ is $\\alpha_1$ and when $\\epsilon_{t-1} \\leq 0$ impact is $\\alpha_1+\\gamma_1$. So if $\\gamma_1$ is positive and statistically significant negative shocks to have a larger impact on volatility than positive shocks.\n\n\n### IGARCH\nIGARCH model is an unit-root GARCH model. Impact of past squared shocks is persistent. The persistence parameters add up to 1. Mathematically this can be represented as,\n$$ \\sigma^2 _t = \\omega + (1-\\lambda) \\epsilon_{t-1} ^2 + \\lambda \\sigma^2 _{t-1} \\textrm{   ,where} 1 \\geq \\lambda \\geq 0 $$\n","6f761cdf":"ACF plot cuts off at lag 1, PACF cuts off at lag 1. Suggesting a GARCH(1,1) process. ","6395bbea":"# Next we simulate a GARCH process","de0f22b0":"# Univariate volatility Modelling ","0fc65668":"The p-value is < 0.05 suggesting residuals are not white noise.","563e3f7d":"ACF shows sinosuidal shape, PACF cuts off after two lags suggesting an AR(2) process. ","a67bb610":"In econometrics, risk is characterised by volatility of returns, which is characterised by variance or standard deviation of returns.\n\nAutoregressive models can be developed for univariate time series data that is stationary. In time series where the variance is increasing in a systematic way, such as an increasing trend, this property of the series is called heteroskedasticity.\n\nWhen the variance of a time-series process is not consistent, to model the data, it becomes imperative to model the conditional expectation and conditional variance of the data generating process. This notebook deals with methods to model the volatility of a time series.\n\nThe various univariate volatility models include Auto Regressive Conditional Heteroscdastic (ARCH) Model and Generalized Auto Regressive Conditional Heteroscdastic (GARCH) Model, and other improvisations of the GARCH model.\n\n## Auto Regressive Conditional Heteroscdastic (ARCH) Model\nARCH (autoregressive conditionally heteroscedastic) model is a model for the variance of a time series. ARCH models are used to describe a changing, possibly volatile variance.\n\nAs an example we use the ARCH(1) process.\n### ARCH(1)\nIf we are modelling the volatility of a series $y_t$.\nWe assume that an AR(1) process is sufficient to capture the time series properties of the mean of the process.\n$$ y_t = a_0 + a_1 y_{t-1} + u_t $$\nWe still assume the expectation of the error terms is zero, so its only the variance that deviates from zero. \n$$ \\mathbb{E}_t (u_t) = \\mathbb{E}_{t-1}(u_t) = 0 $$\n\nFor the model of the conditional mean to be consistent, we require the level of the errors to be uncorrelated over time:\n$$ \\mathbb{E} (u_t u_{t-s}) = 0$$\nWe allow the conditional variance $\\mathbb{E}_t(u_t ^2)=\\sigma_t ^2$ to be auto-correlated.\n\n> ARCH models are mean zero, serially uncorrelated processes with nonconstant variances conditional on the past, but constant unconditional variances. For such processes, the recent past gives information about the one-period forecast variance.\n \n<center> \u2013 Autoregressive Conditional Heteroscedasticity with Estimates of the Variance of United Kingdom Inflation, 1982. <\/center>\n\nUnder the ARCH(1) model, the residual term can be expressed as\n\n$$ u_t = \\epsilon_t \\sqrt{\\omega + \\alpha_1 u_{t-1} ^2} $$\n\nwhere $\\epsilon_t$ is white noise that is independent of $u_t$ with variance 1. \n\nThe period $t-1$ conditional variance for $u_t$ is \n$$\\begin{align} \n\\mathbb{E}_{t-1} (u_t ^2) &= \\mathbb{E}_{t-1} ((\\epsilon_t \\sqrt{\\omega + \\alpha_1 u_{t-1} ^2})^2) \\\\ \n&= \\sigma_{\\epsilon} ^2 ( \\omega + \\alpha_1 \\mathbb{E}_{t-1} (u_{t-1} ^2 )) \\\\\n&=  \\omega + \\alpha_1 u_{t-1} ^2\n\\end{align}$$\n\nand the unconditional variance is given by,\n$$\\begin{align} \n\\mathbb{E} (u_t ^2) &= \\mathbb{E} ((\\epsilon_t \\sqrt{\\omega + \\alpha_1 u_{t-1} ^2})^2) \\\\ \n&=  ( \\omega + \\alpha_1 \\mathbb{E} (u_{t-1} ^2 )) \\\\\n&=  \\frac{\\omega}{1 - \\alpha_1}\n\\end{align}$$\n\n### ARCH(p) process\nThe residual term can be expressed as\n\n$$ u_t = \\epsilon_t \\sqrt{\\omega + \\alpha_1 u_{t-1} ^2 + \\alpha_2 u_{t-2} ^2 + \\textrm{...} + \\alpha_p u_{t-p} ^2} $$\n\n\n## Generalized Auto Regressive Conditional Heteroscdastic (GARCH) Model \n\nIn the GARCH process we assume that the conditional variance follows ARMA(p,q) process. Mathematically we express this as:\n$$ u_t = \\epsilon_t \\sqrt{h_t} $$,\nwhere\n$$ h_t = \\omega + \\alpha_1 u_{t-1} ^2 + \\alpha_2 u_{t-2} ^2 + \\textrm{...} + \\alpha_p u_{t-p} ^2 + \\beta_1 h_{t-1} + \\beta_2 h_{t-2} +  \\textrm{ ... } + \\beta_q h_{t-q} $$\n$\\alpha$ is the reaction parameter. High alpha corresponds to spiky or nervous market and low alpha corresponds to stable market.\n$\\beta$ is volatility persistence. High beta implies high persistence leading to volatility clustering.\nLow alpha is usually associated with high beta and vice versa. \n$\\frac{\\omega}{1-\\alpha-\\beta}$ is the unconditional variance. \n\nGeneralized Autoregressive Conditional Heteroskedasticity, or GARCH, is an extension of the ARCH model that incorporates a moving average component together with the autoregressive component.\n\nSpecifically, the model includes lag variance terms (e.g. the observations if modeling the white noise residual errors of another process), together with lag residual errors from a mean process.\n\nThe introduction of a moving average component allows the model to both model the conditional change in variance over time as well as changes in the time-dependent variance.\n\nIn order to find the perfect process to model the volatility we look at the ACF - PACF plots for the squared process.\n\n> If a correlogram appears to be white noise , then volatility ca be detected by looking at the correlogram of the squared values since the squared values are equivalent to the variance (provided the series is adjusted to have a mean of zero).\n\n\u2014 Pages 146-147, Introductory Time Series with R, 2009.\n\nThe ACF and PACF plots can then be interpreted to estimate values for p and q, in a similar way as is done for the ARMA model."}}