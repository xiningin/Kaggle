{"cell_type":{"29ee3d2a":"code","36b87de8":"code","9c59ebff":"code","4535ff16":"code","d4fda6e5":"code","7e20d976":"code","28e063cd":"code","bbbfcd9f":"code","3debef39":"code","db1bf0a5":"code","6623131e":"code","db0495f9":"code","6d304488":"code","e5152006":"code","c659d2b5":"code","fbe10d89":"code","111f7991":"code","6237b132":"code","7467e2ca":"code","f42127fa":"code","dce8a17d":"code","0065e1b6":"code","a0b7c4f5":"code","44e43cba":"code","a9d4899c":"code","d915d2ae":"code","b031389b":"code","6f741168":"code","b97a4675":"code","35163a61":"code","79950e74":"code","f8ca384f":"code","b1731827":"code","bd51c4a0":"code","cc2134a9":"code","80488871":"code","acdab59c":"code","07a98988":"code","50b13c76":"code","6caa6b56":"code","4eb81e07":"code","2208cb1c":"code","f68e169c":"code","123a9b04":"code","1a375451":"code","04fd19c0":"code","aedef3cd":"code","617d0c91":"code","e9d92e54":"code","97c78e07":"code","a6e4d39c":"code","43d995c5":"code","28e83f5f":"code","97943777":"code","546aba64":"code","a9d1ce02":"code","af8371f1":"code","ee366320":"code","b24db7bf":"code","7b680c93":"code","4d665bd3":"code","731a0e47":"code","d38d9d1d":"code","9f0d9298":"code","eae286a6":"code","b69fa183":"code","1668426f":"code","983adfc7":"code","e3633d00":"code","2ef04b01":"code","b9398e13":"code","caaa57ef":"code","5afbc825":"code","b5b80400":"code","d65ab6ec":"code","02858077":"code","9a1d4116":"code","1d8050de":"code","3575af2c":"code","da041b1b":"code","a0643068":"code","5d412cec":"code","b3355d37":"markdown","6b0247e6":"markdown","6bfed73b":"markdown","a2cafb73":"markdown","463c7fe6":"markdown","55930a16":"markdown","193fe9b6":"markdown","5063e3f5":"markdown","94776ace":"markdown","00f4a648":"markdown","c0b6fb25":"markdown","a2c251ab":"markdown","c1f185e2":"markdown","2a1a6c11":"markdown","41e82cbf":"markdown","ce124718":"markdown","9066d547":"markdown","d3f0aa6b":"markdown","3462fd11":"markdown","102255a5":"markdown","c7f127e7":"markdown","cb695619":"markdown","85238729":"markdown","af402d4e":"markdown","99918ad1":"markdown","4e9eee57":"markdown","1a76de47":"markdown","5eaa906e":"markdown","2742a412":"markdown","df9548da":"markdown","7254d81b":"markdown","eb9462c2":"markdown","83692b73":"markdown","74b09d0f":"markdown","d087b112":"markdown","b36fcfae":"markdown","86a80334":"markdown"},"source":{"29ee3d2a":"import pandas as pd\nfrom pandas import Series,DataFrame\nimport numpy as np\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom IPython.display import Image\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\n# 4 ML categories: classification, regression, clustering, or dimensionality reduction\n\n# continuous target variable requires a regression algorithm \n# discrete target variable requires a classification algorithm\n##logistic regression is a classification algorithm\n#https:\/\/scikit-learn.org\/stable\/tutorial\/machine_learning_map\/index.html\n#https:\/\/scikit-learn.org\/stable\/user_guide.html\n\n# Regression ML algos:\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LinearRegression\n\n# Classification ML algos:\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\n\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import metrics\n\n# cross validation and scoring metrics are to rank and compare our algorithms\u2019 performance\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict\n\n\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom sklearn import metrics\nfrom scipy.stats import norm\nfrom scipy import stats\nfrom sklearn.metrics import mean_squared_error, r2_score","36b87de8":"# Train set\ndf_train = pd.read_csv('..\/input\/train.csv')\n\n# Test set\ndf_test = pd.read_csv('..\/input\/test.csv')","9c59ebff":"df_train.columns","4535ff16":"df_test.columns","d4fda6e5":"# Survived in Train Dataset\ndf_train['Survived'].value_counts()\n\n# There is no Survived column in Test Dataset","7e20d976":"df_train.head(3)","28e063cd":"df_test.head(3)","bbbfcd9f":"df_train.describe()","3debef39":"df_test.describe()","db1bf0a5":"df_train.info()","6623131e":"df_test.info()","db0495f9":"# Nulls in Columns in Train -> True\ndf_train.isnull().any()","6d304488":"# Number of Null records in each column\ndf_train.isnull().sum().sort_values(ascending=False)","e5152006":"# Nulls in Columns in Test -> True\ndf_test.isnull().any()","c659d2b5":"# Number of Null records in each column\ndf_test.isnull().sum().sort_values(ascending=False)","fbe10d89":"sns.catplot(x=\"Survived\", y=\"Age\", kind=\"swarm\",hue=\"Sex\", data=df_train)","111f7991":"sns.catplot(x=\"Survived\", y=\"Pclass\", kind=\"bar\",hue=\"Sex\", data=df_train)","6237b132":"# Combine Test & Train datasets\ntrain_test_data = [df_train, df_test]","7467e2ca":"# train set\ntrain_test_data[0].isnull().sum()","f42127fa":"# test set\ntrain_test_data[1].isnull().sum()","dce8a17d":"# Create column - Title\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","0065e1b6":"title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }","a0b7c4f5":"# map to Title column in both datasets\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Title'].map(title_mapping)","44e43cba":"df_train['Title'].unique()","a9d4899c":"genders = {\"male\": 0, \"female\": 1}\n\nfor dataset in train_test_data:\n    dataset['Sex'] = dataset['Sex'].map(genders)  ","d915d2ae":"df_train['Sex'].value_counts()","b031389b":"df_train['Sex'].unique()","6f741168":"# info on Embarked\ndf_train['Embarked'].describe()","b97a4675":"# Most commonly used value\nembrk_common_value = list(df_train[\"Embarked\"].mode())[0]\nembrk_common_value","35163a61":"# two null records\ndf_train['Embarked'].isnull().sum()","79950e74":"# fillna with most common value\ndf_train['Embarked']= df_train['Embarked'].fillna(embrk_common_value)","f8ca384f":"# quick check for nulls\nprint(df_train['Embarked'].isnull().sum())\nprint(df_test['Embarked'].isnull().sum())","b1731827":"df_train['Embarked'].unique()","bd51c4a0":"def Embark_cat(x):\n    if x =='S' :\n        return 0\n    elif x =='C':\n        return 1\n    else:\n        return 2","cc2134a9":"df_train['Embarked']= df_train['Embarked'].apply(Embark_cat)\ndf_test['Embarked']= df_test['Embarked'].apply(Embark_cat)","80488871":"# quick check \ndf_train['Embarked'].value_counts()","acdab59c":"df_train['Embarked'].unique()","07a98988":"df_test['Embarked'].unique()","50b13c76":"# Median of Fare\nfare_med = df_test['Fare'].median()\nfare_med","6caa6b56":"df_test['Fare'].isnull().sum()","4eb81e07":"# Fill missing Fare record in df_test dataset with median value\ndf_test['Fare'] = df_test['Fare'].fillna(fare_med)\n\n# Quick check \ndf_test['Fare'].isnull().sum()","2208cb1c":"#Method: use random value in the normal distribution or Bell curve\ndef assign_random_age_toNan (dataset):\n    mean = dataset[\"Age\"].mean()\n    std = dataset[\"Age\"].std()\n    is_null = dataset[\"Age\"].isnull().sum()\n    rand_age = np.random.randint((mean - std), (mean + std), size = is_null)\n    age_slice = dataset[\"Age\"].copy()\n    age_slice[np.isnan(age_slice)] = rand_age #assign random number\n    dataset[\"Age\"] = age_slice\n    dataset[\"Age\"] = dataset[\"Age\"].astype(int)\n    return dataset ","f68e169c":"df_train = assign_random_age_toNan(df_train)\ndf_train.isnull().sum()","123a9b04":"df_test = assign_random_age_toNan(df_test)\ndf_test.isnull().sum()","1a375451":"# distinct values\nage = list(df_train['Age'].value_counts())[0:5]\nage","04fd19c0":"# categorize 'Age' into 1 to 6 bucket.\n\ndef Age_cat(x):\n    if x <=11 :\n        return 0\n    elif x>11 and x<=18:\n        return 1\n    elif x>18 and x<=22:\n        return 2\n    elif x>22 and x<=27:\n        return 3\n    elif x>27 and x<=33:\n        return 4\n    elif x>33 and x<=40:\n        return 5\n    elif x>40 and x<=66:\n        return 6\n    else:\n        return 6","aedef3cd":"df_train['Age'] = df_train['Age'].apply(Age_cat)\ndf_test['Age'] = df_test['Age'].apply(Age_cat)","617d0c91":"df_train['Age'].unique()","e9d92e54":"df_test['Age'].unique()","97c78e07":"df_train.isnull().sum()","a6e4d39c":"df_test.isnull().sum()","43d995c5":"df_train['With_someone'] = df_train['SibSp'] | df_train['Parch']\ndf_test['With_someone'] = df_test['SibSp'] | df_test['Parch']","28e83f5f":"df_train['With_someone'].unique()","97943777":"df_test['With_someone'].unique()","546aba64":"df_train['With_someone'].value_counts()","a9d1ce02":"df_train['With_someone'] =df_train['With_someone'].apply(lambda x:1 if x >=1 else 0)\ndf_test['With_someone'] =df_test['With_someone'].apply(lambda x:1 if x >=1 else 0)","af8371f1":"df_test['With_someone'].unique()","ee366320":"df_train['With_someone'].unique()","b24db7bf":"df_train['Family'] = df_train['SibSp'] + df_train['Parch']\ndf_test['Family'] = df_test['SibSp'] + df_test['Parch']","7b680c93":"df_train['Family'].unique()","4d665bd3":"df_test['Family'].unique()","731a0e47":"df_train = pd.get_dummies(df_train, columns=['Pclass', 'Embarked','Age','Title'], drop_first=True)\ndf_test = pd.get_dummies(df_test, columns=['Pclass', 'Embarked','Age','Title'], drop_first=True)\ndf_train.head()","d38d9d1d":"drop_cols = ['Name', 'Ticket', 'Cabin','SibSp','Parch']","9f0d9298":"df_train=df_train.drop(columns=drop_cols, axis=1)\ndf_test=df_test.drop(columns=drop_cols, axis=1)","eae286a6":"df_train.shape, df_test.shape","b69fa183":"sc_X = MinMaxScaler()\ndf_train[['Fare','Family']] = sc_X.fit_transform(df_train[['Fare','Family']])\ndf_test[['Fare','Family']] = sc_X.transform(df_test[['Fare','Family']])","1668426f":"df_train.head(5)","983adfc7":"# Y axis for the \"Survived\" where as X axis for other attributes in the data model\n\nX_train = df_train.drop([\"Survived\",\"PassengerId\"], axis=1)\ny_train = df_train[\"Survived\"]\n\nX_test  = df_test.drop(\"PassengerId\", axis=1)\ny_test = df_test['PassengerId']","e3633d00":"logi_clf = LogisticRegression(random_state=0)\nlogi_parm = {\"penalty\": ['l1', 'l2'], \"C\": [0.1, 0.5, 1, 5, 10, 50]}\n\nsvm_clf = SVC(random_state=0)\nsvm_parm = {'kernel': ['rbf', 'poly'], 'C': [0.1, 0.5, 1, 5, 10, 50], 'degree': [3, 5, 7], \n            'gamma': ['auto', 'scale']}\n\ndt_clf = DecisionTreeClassifier(random_state=0)\ndt_parm = {'criterion':['gini', 'entropy']}\n\nknn_clf = KNeighborsClassifier()\nknn_parm = {'n_neighbors':[5, 10, 15, 20], 'weights':['uniform', 'distance'], 'p': [1,2]}\n\ngnb_clf = GaussianNB()\ngnb_parm = {'priors':['None']}\n\nclfs = [logi_clf, svm_clf, dt_clf, knn_clf]\nparams = [logi_parm, svm_parm, dt_parm, knn_parm] ","2ef04b01":"clf1 = GradientBoostingClassifier(max_depth=4,n_estimators=300,learning_rate=0.01)\nclf1.fit(X_train,y_train)\n\nclf2 = SVC(C=5,degree=3,random_state=0,probability=True)\nclf2.fit(X_train,y_train)\n\nclf3 = RandomForestClassifier(max_depth=30,min_samples_split =15 ,n_estimators=500,random_state=0)\nclf3.fit(X_train,y_train)","b9398e13":"eclf = VotingClassifier(estimators=[('gb',clf1),('svc',clf2),('rf',clf3)],voting='soft',weights=[2,1,1.5])","caaa57ef":"eclf.fit(X_train,y_train)","5afbc825":"kf = KFold(n_splits=10, random_state=5)\n\ncv = cross_val_score(eclf,X_train,y_train,cv=kf)\n\nprint(cv)","b5b80400":"cv.mean()","d65ab6ec":"pred = eclf.predict(X_test)\nprint(pred)","02858077":"cols = ['PassengerId', 'Survived']\nsubmit_df = pd.DataFrame(np.hstack((y_test.values.reshape(-1,1),pred.reshape(-1,1))),columns=cols)","9a1d4116":"submit_df.to_csv('submission.csv', index=False)","1d8050de":"submit_df.head()","3575af2c":"logmodel=LogisticRegression()","da041b1b":"logmodel.fit(X_train,y_train)","a0643068":"predictions=logmodel.predict(X_test)\nprint( \"Prediction of the Survived\", predictions)","5d412cec":"#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.10,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':9 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorrelation_heatmap(df_train)","b3355d37":"#### Fare","6b0247e6":"### Data Visuals","6bfed73b":"### New Columns","a2cafb73":"### Binning","463c7fe6":"## Step 3: Exploratory Data Analysis","55930a16":"#### With Family","193fe9b6":"## Step 4: Feature Engineering","5063e3f5":"### Prediction of y_test","94776ace":"#### Age","00f4a648":"## Step 6: ML Models Predictions","c0b6fb25":"### Check for Nulls","a2c251ab":"### Logistic Regression","c1f185e2":"### Assign Weights","2a1a6c11":"## Appendix","41e82cbf":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Who-Survived-the-Titanic?\" data-toc-modified-id=\"Who-Survived-the-Titanic?-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Who Survived the Titanic?<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Step-1:-Import-Python-Packages\" data-toc-modified-id=\"Step-1:-Import-Python-Packages-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;<\/span>Step 1: Import Python Packages<\/a><\/span><\/li><li><span><a href=\"#Step-2:-Get-Data\" data-toc-modified-id=\"Step-2:-Get-Data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;<\/span>Step 2: Get Data<\/a><\/span><\/li><li><span><a href=\"#Step-3:-Exploratory-Data-Analysis\" data-toc-modified-id=\"Step-3:-Exploratory-Data-Analysis-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;<\/span>Step 3: Exploratory Data Analysis<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Meta-Data\" data-toc-modified-id=\"Meta-Data-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;<\/span>Meta Data<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Data-Analysis:\" data-toc-modified-id=\"Data-Analysis:-1.3.1.1\"><span class=\"toc-item-num\">1.3.1.1&nbsp;&nbsp;<\/span>Data Analysis:<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Categorical-Attributes:\" data-toc-modified-id=\"Categorical-Attributes:-1.3.1.1.1\"><span class=\"toc-item-num\">1.3.1.1.1&nbsp;&nbsp;<\/span>Categorical Attributes:<\/a><\/span><\/li><li><span><a href=\"#Numerical-Attributes:\" data-toc-modified-id=\"Numerical-Attributes:-1.3.1.1.2\"><span class=\"toc-item-num\">1.3.1.1.2&nbsp;&nbsp;<\/span>Numerical Attributes:<\/a><\/span><\/li><\/ul><\/li><\/ul><\/li><li><span><a href=\"#Check-for-Nulls\" data-toc-modified-id=\"Check-for-Nulls-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;<\/span>Check for Nulls<\/a><\/span><\/li><li><span><a href=\"#Data-Visuals\" data-toc-modified-id=\"Data-Visuals-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;<\/span>Data Visuals<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Step-4:-Feature-Engineering\" data-toc-modified-id=\"Step-4:-Feature-Engineering-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;<\/span>Step 4: Feature Engineering<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Binning\" data-toc-modified-id=\"Binning-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;<\/span>Binning<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Title\" data-toc-modified-id=\"Title-1.4.1.1\"><span class=\"toc-item-num\">1.4.1.1&nbsp;&nbsp;<\/span>Title<\/a><\/span><\/li><li><span><a href=\"#Sex\" data-toc-modified-id=\"Sex-1.4.1.2\"><span class=\"toc-item-num\">1.4.1.2&nbsp;&nbsp;<\/span>Sex<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Imputation\" data-toc-modified-id=\"Imputation-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;<\/span>Imputation<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Embarked\" data-toc-modified-id=\"Embarked-1.4.2.1\"><span class=\"toc-item-num\">1.4.2.1&nbsp;&nbsp;<\/span>Embarked<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Binning-Embarked\" data-toc-modified-id=\"Binning-Embarked-1.4.2.1.1\"><span class=\"toc-item-num\">1.4.2.1.1&nbsp;&nbsp;<\/span>Binning Embarked<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Fare\" data-toc-modified-id=\"Fare-1.4.2.2\"><span class=\"toc-item-num\">1.4.2.2&nbsp;&nbsp;<\/span>Fare<\/a><\/span><\/li><li><span><a href=\"#Age\" data-toc-modified-id=\"Age-1.4.2.3\"><span class=\"toc-item-num\">1.4.2.3&nbsp;&nbsp;<\/span>Age<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Binning-Age\" data-toc-modified-id=\"Binning-Age-1.4.2.3.1\"><span class=\"toc-item-num\">1.4.2.3.1&nbsp;&nbsp;<\/span>Binning Age<\/a><\/span><\/li><\/ul><\/li><\/ul><\/li><li><span><a href=\"#New-Columns\" data-toc-modified-id=\"New-Columns-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;<\/span>New Columns<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#With-Someone\" data-toc-modified-id=\"With-Someone-1.4.3.1\"><span class=\"toc-item-num\">1.4.3.1&nbsp;&nbsp;<\/span>With Someone<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Binning-Someone\" data-toc-modified-id=\"Binning-Someone-1.4.3.1.1\"><span class=\"toc-item-num\">1.4.3.1.1&nbsp;&nbsp;<\/span>Binning Someone<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#With-Family\" data-toc-modified-id=\"With-Family-1.4.3.2\"><span class=\"toc-item-num\">1.4.3.2&nbsp;&nbsp;<\/span>With Family<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#One-Hot-Encoding\" data-toc-modified-id=\"One-Hot-Encoding-1.4.4\"><span class=\"toc-item-num\">1.4.4&nbsp;&nbsp;<\/span>One Hot Encoding<\/a><\/span><\/li><li><span><a href=\"#Drop-Columns\" data-toc-modified-id=\"Drop-Columns-1.4.5\"><span class=\"toc-item-num\">1.4.5&nbsp;&nbsp;<\/span>Drop Columns<\/a><\/span><\/li><li><span><a href=\"#Scaling\" data-toc-modified-id=\"Scaling-1.4.6\"><span class=\"toc-item-num\">1.4.6&nbsp;&nbsp;<\/span>Scaling<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Step-5:-Y-&amp;-X-datasets\" data-toc-modified-id=\"Step-5:-Y-&amp;-X-datasets-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;<\/span>Step 5: Y &amp; X datasets<\/a><\/span><\/li><li><span><a href=\"#Step-6:-ML-Models-Predictions\" data-toc-modified-id=\"Step-6:-ML-Models-Predictions-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;<\/span>Step 6: ML Models Predictions<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#3-Models\" data-toc-modified-id=\"3-Models-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;<\/span>3 Models<\/a><\/span><\/li><li><span><a href=\"#Assign-Weights\" data-toc-modified-id=\"Assign-Weights-1.6.2\"><span class=\"toc-item-num\">1.6.2&nbsp;&nbsp;<\/span>Assign Weights<\/a><\/span><\/li><li><span><a href=\"#Model-fitting\" data-toc-modified-id=\"Model-fitting-1.6.3\"><span class=\"toc-item-num\">1.6.3&nbsp;&nbsp;<\/span>Model fitting<\/a><\/span><\/li><li><span><a href=\"#Model-Validation\" data-toc-modified-id=\"Model-Validation-1.6.4\"><span class=\"toc-item-num\">1.6.4&nbsp;&nbsp;<\/span>Model Validation<\/a><\/span><\/li><li><span><a href=\"#Prediction-of-y_test\" data-toc-modified-id=\"Prediction-of-y_test-1.6.5\"><span class=\"toc-item-num\">1.6.5&nbsp;&nbsp;<\/span>Prediction of y_test<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Step-7:-Kaggle-Submission\" data-toc-modified-id=\"Step-7:-Kaggle-Submission-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;<\/span>Step 7: Kaggle Submission<\/a><\/span><\/li><li><span><a href=\"#Appendix\" data-toc-modified-id=\"Appendix-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;<\/span>Appendix<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-1.8.1\"><span class=\"toc-item-num\">1.8.1&nbsp;&nbsp;<\/span>Logistic Regression<\/a><\/span><\/li><li><span><a href=\"#Pearson-Correlation-Heatmap\" data-toc-modified-id=\"Pearson-Correlation-Heatmap-1.8.2\"><span class=\"toc-item-num\">1.8.2&nbsp;&nbsp;<\/span>Pearson Correlation Heatmap<\/a><\/span><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/div>","ce124718":"##### Binning Embarked","9066d547":"#### With Someone","d3f0aa6b":"### Model Validation","3462fd11":"#### Title","102255a5":"## Step 2: Get Data","c7f127e7":"##### Binning Age","cb695619":"#### Sex","85238729":"### Meta Data","af402d4e":"#### Data Analysis:\n\nMin and max values: This can give us an idea about the range of values and is helpful to detect outliers. However, this is not standalone measure, needs Mean (central tendency of data distribution) and Standard deviation to assess the outliners. All atttribute Min\/max values seems to be reasonable, except Age and Fare.\n\nMean: shows the central tendency of the distribution.\n\nStandard deviation: quantifies the amount of variation from the central tendency of the data distribution. Ignore PassengerId.\n\n\nCount: # number of records, helps to identify the missing data. Here, Noticed missing info in the Age attribute.\n\nLets analyze missing data.","99918ad1":"#### Embarked","4e9eee57":"## Step 1: Import Python Packages","1a76de47":"### Imputation","5eaa906e":"### Scaling","2742a412":"## Step 5: Y & X datasets","df9548da":"### 3 Models","7254d81b":"### Drop Columns","eb9462c2":"### Pearson Correlation Heatmap","83692b73":"##### Binning Someone","74b09d0f":"### One Hot Encoding","d087b112":"## Step 7: Kaggle Submission","b36fcfae":"### Model fitting","86a80334":"##### Categorical Attributes:\n\nA.Nominal:'Sex', 'Embarked' 'Survived'\n\nB.Ordinal: 'Pclass' \n\nNote: 'Survived' is not taken in the model because it's the output variable.\n\n\n\n\n##### Numerical Attributes:\n\nC.Continous: Age, Fare.\n\nD.Discrete: SibSp, Parch.\n\nNote: 'SibSp' could be grouped with 'Parch' to create a 'Relative' feature.\n"}}