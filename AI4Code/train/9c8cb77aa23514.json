{"cell_type":{"64d528ed":"code","61a1cc53":"code","bf8a9630":"code","d20284c5":"code","b0f1bb24":"code","ce19a0a9":"code","8100439f":"code","936177df":"code","7f8374e5":"markdown","5d0b42bd":"markdown","041d3941":"markdown","a7a3f0bc":"markdown","64f0dede":"markdown","eb3df653":"markdown"},"source":{"64d528ed":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nnp.random.seed(0)","61a1cc53":"size = 262144\nscore_archive = []\ndiff_archive = []\nfor i in tqdm(range(10000)):\n    # generate synthetic dataset\n    rng = np.random.uniform(size=size)\n    pred = np.array([i for i in range(size)])\n    y = np.array([0 if x<0.975 else 1 for x in rng[:size\/\/2]] + [1 if x<0.975 else 0 for x in rng[size\/\/2:]])\n    # make synthetic public set and private set\n    pub_pred, pri_pred, pub_y, pri_y = train_test_split(pred, y, shuffle=True, test_size=0.5)\n    # calculate public set score\n    score_archive.append(roc_auc_score(pub_y, pub_pred))\n    # calculate score difference between public set and private set\n    diff_archive.append(roc_auc_score(pub_y, pub_pred)-roc_auc_score(pri_y, pri_pred))","bf8a9630":"plt.figure(figsize=(14,6))\nplt.hist(score_archive, bins=100)\nplt.title('distribution of roc auc of a perfect classifier')\nplt.show()","d20284c5":"np.mean(score_archive)","b0f1bb24":"np.percentile(score_archive, np.arange(40, 60, 1))","ce19a0a9":"plt.figure(figsize=(14,6))\nplt.hist(diff_archive, bins=100)\nplt.title('distribution of roc auc diff between public and private')\nplt.show()","8100439f":"np.mean(np.abs(diff_archive))","936177df":"np.percentile(diff_archive, np.arange(40, 60, 1))","7f8374e5":"# Synthetic Datasets\n\nSince not exactly but **about** 2.5% of the labels are flipped, we will create many different datasets, then see the possible scores of the perfect (or almost perfect) classifiers and possible differences between public and private scores.\n\nDataset size is set to 262144, similar to our competition's test set size.\n\n*I revised data generation code which was originally written by raddar(https:\/\/www.kaggle.com\/c\/instant-gratification\/discussion\/94671#latest-547805)*.","5d0b42bd":"Let's assume two things.\n\n1. **The data is generated with around 2.5% of flipped labels(https:\/\/www.kaggle.com\/c\/instant-gratification\/discussion\/94671#latest-547805).**\n\n2. **We've created perfect or almost perfect classifier which correctly classifies all or almost all of the samples except the flipped ones.**\n\nNow let's do some tests.\n\n**Be careful! All of this test's results are useless if this assumption is wrong.**","041d3941":"# Score of a Perfect Classifier","a7a3f0bc":"# Score Difference between Public set and Private set","64f0dede":"Looks like about 0.0005~0.0006 score shake up\/down will happen in private set if we've made perfect (or almost perfect) classifier.\nLooking at current top public leaderboard scores, there might be shake ups or downs of ~10 positions.\n\n**But note once more that these conclusions are based on the assumption I described at the beginning.**","eb3df653":"Mean score of about 0.975 is similar to what raddar had observed. Also, it looks like scores approximately match our public leaderboard top scores."}}