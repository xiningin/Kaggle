{"cell_type":{"d179d9c0":"code","d9937478":"code","5514fb45":"code","00c50c2d":"code","b2696b7a":"code","ab031935":"code","4bc1c719":"code","f46463c5":"code","29ae6012":"code","2f42762c":"code","888ca3a5":"code","6c9fe675":"code","1100431e":"code","ffd620d6":"code","a9c08f4b":"code","3903c756":"code","028fbb16":"code","274f606e":"code","a3f0f497":"code","78f5375a":"code","bb1e218d":"code","3ee9f9f8":"code","a632d289":"code","1a6e2424":"code","f999359b":"code","0ea97d72":"code","e5ac95a8":"code","b1668471":"code","f2bdf5da":"code","80c8036d":"code","709b3f3d":"code","3710834b":"code","bb7d9d3b":"code","49031d42":"code","2a2a2b66":"code","4498281e":"code","3fe8f48b":"code","2f3f42fd":"code","88aa1625":"code","72d4651b":"code","4bfa531c":"code","771d643f":"code","5b665f44":"code","0937116a":"code","014ee95f":"code","5497a14d":"code","44f53677":"code","0afaa1e3":"code","545dbc0f":"code","f2997a40":"code","75f32d80":"code","4065692e":"code","10a26f72":"code","a3f8aa35":"code","1eb9e327":"code","f2aa0a11":"code","a8ef692f":"code","0e3b69db":"code","3faf1c66":"code","5554ec59":"markdown","cff2d7d3":"markdown","69ed45af":"markdown","da733ccc":"markdown","ae50503c":"markdown","edab6946":"markdown","d25fb162":"markdown","fd0df8e2":"markdown","ba08fa3c":"markdown","71e045ce":"markdown","26d5f3e9":"markdown","0ad63daa":"markdown","daccd16f":"markdown","394c8805":"markdown","9aa3b6d8":"markdown","50dc8b8c":"markdown","a6a56082":"markdown","580c2b29":"markdown","ae1e1e7d":"markdown","7673c2ff":"markdown","713964fc":"markdown","bfb05760":"markdown"},"source":{"d179d9c0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nimport seaborn as sns","d9937478":"train_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')","5514fb45":"train_data.head()","00c50c2d":"train_data.info()","b2696b7a":"test_data = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","ab031935":"test_data.head()","4bc1c719":"image = np.array(train_data.drop('label',axis=1).iloc[0])\nlabel = train_data.iloc[0]['label']","f46463c5":"label","29ae6012":"image","2f42762c":"print(image.shape)","888ca3a5":"plt.imshow(image.reshape(28,28,1), cmap='gray')\nplt.axis('off')","6c9fe675":"def visualise_random_image():\n    index = np.random.randint(0,42000)\n    image = np.array(train_data.drop('label',axis=1).iloc[index])\n    label = train_data.iloc[index]['label']\n    plt.imshow(image.reshape(28,28,1), cmap='gray')\n    plt.title(label)  \n    plt.axis('off')","1100431e":"plt.figure(figsize=(12, 8))\nfor i in range(50):\n    ax = plt.subplot(5, 10, i + 1)\n    visualise_random_image()","ffd620d6":"train_data['label'].value_counts()","a9c08f4b":"plt.figure(figsize=(8,6))\nsns.countplot(x='label', data=train_data)","3903c756":"(train_data['label'].value_counts()\/len(train_data))*100","028fbb16":"X = train_data.drop('label', axis=1)\ny = train_data['label']","274f606e":"(x_train1, y_train1), (x_test1, y_test1) = tf.keras.datasets.mnist.load_data()\n\ntrain1 = np.concatenate([x_train1, x_test1], axis=0)\ny_train1 = np.concatenate([y_train1, y_test1], axis=0)\n\nY_train1 = y_train1\nX_train1 = train1.reshape(-1, 28*28)","a3f0f497":"X_train = np.concatenate((X.values, X_train1))\ny_train = np.concatenate((y, y_train1))","78f5375a":"X_train = X_train.reshape(-1,28,28,1)","bb1e218d":"X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.1, random_state=101)","3ee9f9f8":"!nvidia-smi","a632d289":"model1 = tf.keras.Sequential([\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation=\"relu\"),\n    tf.keras.layers.Dense(128, activation=\"relu\"),\n    tf.keras.layers.Dense(10, activation=\"softmax\")\n])\n\nmodel1.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                 optimizer=tf.keras.optimizers.Adam(),\n                 metrics=[\"accuracy\"])\n\n# Fit the model\nnon_norm_history = model1.fit(X_train,\n                                y_train,\n                                epochs=10,\n                                validation_data=(X_test, y_test))","1a6e2424":"pd.DataFrame(non_norm_history.history).plot()\nplt.xlabel('epochs')","f999359b":"X_train = X_train\/255.0\nX_test = X_test\/255.0","0ea97d72":"model2 = tf.keras.Sequential([\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation=\"relu\"),\n    tf.keras.layers.Dense(128, activation=\"relu\"),\n    tf.keras.layers.Dense(10, activation=\"softmax\")\n])\n\nmodel2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                 optimizer=tf.keras.optimizers.Adam(),\n                 metrics=[\"accuracy\"])\n\n# Fit the model\nnorm_history = model2.fit(X_train,\n                                y_train,\n                                epochs=10,\n                                validation_data=(X_test, y_test))","e5ac95a8":"model2.summary()","b1668471":"pd.DataFrame(norm_history.history).plot()\nplt.xlabel('epochs')","f2bdf5da":"X_train = X_train.reshape(-1, 28, 28, 1)\nX_test = X_test.reshape(-1, 28, 28, 1)","80c8036d":"model3 = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), input_shape=(28,28,1), activation='relu'),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Conv2D(64, (3,3), input_shape=(28,28,1), activation='relu'),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=\"relu\"),\n    tf.keras.layers.Dense(10, activation=\"softmax\")\n])\n\nmodel3.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                 optimizer=tf.keras.optimizers.Adam(),\n                 metrics=[\"accuracy\"])\n\n# Fit the model\nhistory = model3.fit(X_train,y_train,epochs=10,validation_data=(X_test, y_test))","709b3f3d":"pd.DataFrame(history.history).plot()\nplt.xlabel('epochs')","3710834b":"model4 = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), input_shape=(28,28,1), activation='relu'),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), input_shape=(28,28,1), activation='relu'),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Conv2D(256, (3,3), input_shape=(28,28,1), activation='relu'),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=\"relu\"),\n    tf.keras.layers.Dense(10, activation=\"softmax\")\n])\n\nmodel4.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                 optimizer=tf.keras.optimizers.Adam(),\n                 metrics=[\"accuracy\"])\n\n# Fit the model\nhistory = model4.fit(X_train,y_train,epochs=10,validation_data=(X_test, y_test))","bb7d9d3b":"pd.DataFrame(history.history).plot()\nplt.xlabel('epochs')","49031d42":"model5 = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), input_shape=(28,28,1), activation='relu'),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Conv2D(64, (3,3), input_shape=(28,28,1), activation='relu'),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=\"relu\"),\n    tf.keras.layers.Dense(10, activation=\"softmax\")\n])\n\nmodel5.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                 optimizer=tf.keras.optimizers.Adam(),\n                 metrics=[\"accuracy\"])\n\n# Fit the model\nhistory = model5.fit(X_train,y_train,epochs=30,validation_data=(X_test, y_test))","2a2a2b66":"pd.DataFrame(history.history).plot()\nplt.xlabel('epochs')","4498281e":"model6 = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(64, (5,5), input_shape=(28,28,1), activation='relu', padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64, (5,5), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Conv2D(64, (3,3), input_shape=(28,28,1), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64, (3,3), input_shape=(28,28,1), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256, activation=\"relu\"),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Dense(10, activation=\"softmax\")\n])\n\nmodel6.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                 optimizer=tf.keras.optimizers.Adam(),\n                 metrics=[\"accuracy\"])\n\n# Fit the model\nhistory = model6.fit(X_train,y_train,epochs=30,validation_data=(X_test, y_test))","3fe8f48b":"pd.DataFrame(history.history).plot()\nplt.xlabel('epochs')","2f3f42fd":"y_probs = model6.predict(X_test)\n\n# View the first 5 predictions\ny_probs[:5]","88aa1625":"y_preds = y_probs.argmax(axis=1)\n\n# View the first 10 prediction labels\ny_preds[:10]","72d4651b":"from sklearn.metrics import confusion_matrix, plot_confusion_matrix\nconfusion_matrix(y_true=y_test, y_pred=y_preds)","4bfa531c":"import itertools\nfrom sklearn.metrics import confusion_matrix\n\n# Our function needs a different name to sklearn's plot_confusion_matrix\n\n\ndef make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15):\n    \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n\n    If classes is passed, confusion matrix will be labelled, if not, integer class values\n    will be used.\n\n    Args:\n      y_true: Array of truth labels (must be same shape as y_pred).\n      y_pred: Array of predicted labels (must be same shape as y_true).\n      classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n      figsize: Size of output figure (default=(10, 10)).\n      text_size: Size of output figure text (default=15).\n\n    Returns:\n      A labelled confusion matrix plot comparing y_true and y_pred.\n\n    Example usage:\n      make_confusion_matrix(y_true=test_labels, # ground truth test labels\n                            y_pred=y_preds, # predicted labels\n                            classes=class_names, # array of class label names\n                            figsize=(15, 15),\n                            text_size=10)\n    \"\"\"\n    # Create the confustion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    cm_norm = cm.astype(\"float\")\n    cm.sum(axis=1)[:, np.newaxis]  # normalize it\n    n_classes = cm.shape[0]  # find the number of classes we're dealing with\n\n    # Plot the figure and make it pretty\n    fig, ax = plt.subplots(figsize=figsize)\n    # colors will represent how 'correct' a class is, darker == better\n    cax = ax.matshow(cm, cmap=plt.cm.Blues)\n    fig.colorbar(cax)\n\n    # Are there a list of classes?\n    if classes:\n        labels = classes\n    else:\n        labels = np.arange(cm.shape[0])\n\n    # Label the axes\n    ax.set(title=\"Confusion Matrix\",\n           xlabel=\"Predicted label\",\n           ylabel=\"True label\",\n           # create enough axis slots for each class\n           xticks=np.arange(n_classes),\n           yticks=np.arange(n_classes),\n           # axes will labeled with class names (if they exist) or ints\n           xticklabels=labels,\n           yticklabels=labels)\n\n    # Make x-axis labels appear on bottom\n    ax.xaxis.set_label_position(\"bottom\")\n    ax.xaxis.tick_bottom()\n\n    # Set the threshold for different colors\n    threshold = (cm.max() + cm.min()) \/ 2.\n\n    # Plot the text on each cell\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, f\"{cm[i, j]}\",\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > threshold else \"black\",\n                 size=text_size)","771d643f":"make_confusion_matrix(y_test, y_preds,\n                      figsize=(15, 15),\n                      text_size=10)","5b665f44":"X = X.values.reshape(-1,28,28,1)\nX = X\/255.0","0937116a":"X.shape","014ee95f":"X_train1.shape","5497a14d":"X = np.concatenate((X, X_train1.reshape(-1, 28,28, 1)))\ny = np.concatenate((y, y_train1))","44f53677":"X.shape","0afaa1e3":"y.shape","545dbc0f":"X = X\/255","f2997a40":"model7 = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(64, (5,5), input_shape=(28,28,1), activation='relu', padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64, (5,5), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Conv2D(64, (3,3), input_shape=(28,28,1), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64, (3,3), input_shape=(28,28,1), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256, activation=\"relu\"),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Dense(10, activation=\"softmax\")\n])\n\nmodel7.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                 optimizer=tf.keras.optimizers.Adam(),\n                 metrics=[\"accuracy\"])\n\n# Fit the model\nhistory = model7.fit(X,y,epochs=50)","75f32d80":"test_data = test_data\/255.0\ntest_data = test_data.values.reshape(-1,28,28,1)","4065692e":"predictions = model7.predict(test_data)\npredictions = predictions.argmax(axis=1)\npredictions","10a26f72":"sample_submission = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')","a3f8aa35":"sample_submission","1eb9e327":"sample_submission['Label'] = predictions","f2aa0a11":"sample_submission","a8ef692f":"sample_submission['Label'].unique()","0e3b69db":"sample_submission['Label'].value_counts()","3faf1c66":"sample_submission.to_csv(\"submission.csv\",index=False)","5554ec59":"seems the data is well balanced all the classes are nearly 10%","cff2d7d3":"## Normalize the data","69ed45af":"# Read the dataset","da733ccc":"## model5","ae50503c":"## Predicting on the test data","edab6946":"## Visualise a digit","d25fb162":"## model3","fd0df8e2":"## model4","ba08fa3c":"## Find the number of unique labels","71e045ce":"A function to visualize random images in the training set","26d5f3e9":"## model1","0ad63daa":"### Reshape the data into image form for convnets","daccd16f":"# Final model with whole data","394c8805":"# Visualizing the data","9aa3b6d8":"## Percentage of classes in dataset","50dc8b8c":"# Imports","a6a56082":"## model6","580c2b29":"We can clearly see that the accuracy increased and convergence is also faster","ae1e1e7d":"## Visualize Random Images","7673c2ff":"# Using CONVnets","713964fc":"## model2","bfb05760":"## Train-test split"}}