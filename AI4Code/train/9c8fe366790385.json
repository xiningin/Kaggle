{"cell_type":{"c9836698":"code","f80ac173":"code","04f5f993":"code","06f532c4":"code","e7493b83":"code","52fae6d8":"code","fe237f86":"code","f6ae784b":"code","4f8eeb34":"code","845204a2":"code","34f88bcc":"code","11b9830a":"code","68769474":"code","249e413f":"code","9209fe94":"code","21d8ddc7":"code","857f78e6":"code","f8763120":"code","9c978f25":"code","042fd3bc":"code","8efafa9a":"code","2b297926":"code","251300bc":"code","e6d4166e":"code","468b2446":"code","67c9cca7":"code","bbe5759c":"code","6e84132d":"code","087df144":"code","406ecd27":"code","e3c9ae81":"code","155cd83e":"code","a84253ca":"code","1157e552":"code","4e8b6747":"code","b3861725":"code","3141f5a0":"markdown","e5a38eae":"markdown","eadddd22":"markdown","2c692126":"markdown","9f089ad6":"markdown","62fc9685":"markdown","a1999bf0":"markdown","e9995d9b":"markdown","a7cd8061":"markdown","7e4fb2c0":"markdown","bf7fdb47":"markdown","16a83801":"markdown","d58e1003":"markdown","558890ff":"markdown","affb518a":"markdown","d53e9162":"markdown","10b90f7d":"markdown","2024883e":"markdown","eac409ad":"markdown","ef89e15c":"markdown","4bd21252":"markdown","4e067755":"markdown"},"source":{"c9836698":"# Pandas : librairie de manipulation de donn\u00e9es\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import datasets","f80ac173":"from sklearn.model_selection import learning_curve\ndef plot_learning_curve(est, X_train, y_train) :\n    train_sizes, train_scores, test_scores = learning_curve(estimator=est, X=X_train, y=y_train, train_sizes=np.linspace(0.1, 1.0, 10),\n                                                        cv=5,\n                                                        n_jobs=-1)\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n    plt.figure(figsize=(8,10))\n    plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\n    plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n    plt.plot(train_sizes, test_mean,color='green', linestyle='--',marker='s', markersize=5,label='validation accuracy')\n    plt.fill_between(train_sizes,test_mean + test_std,test_mean - test_std,alpha=0.15, color='green')\n    plt.grid(b='on')\n    plt.xlabel('Number of training samples')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='lower right')\n    plt.ylim([0.6, 1.0])\n    plt.show()","04f5f993":"def plot_roc_curve(est,X_test,y_test) :\n    probas = est.predict_proba(X_test)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,probas[:, 1])\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    plt.figure(figsize=(8,8))\n    plt.title('Receiver Operating Characteristic')\n    plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\n    plt.legend(loc='lower right')\n    plt.plot([0,1],[0,1],'r--')        # plus mauvaise courbe\n    plt.plot([0,0,1],[0,1,1],'g:')     # meilleure courbe\n    plt.xlim([-0.05,1.2])\n    plt.ylim([-0.05,1.2])\n    plt.ylabel('Taux de vrais positifs')\n    plt.xlabel('Taux de faux positifs')\n    plt.show","06f532c4":"df = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')","e7493b83":"df.head()","52fae6d8":"labels = [\"T-shirt\/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\n          \"Sneaker\",\"Bag\",\"Ankle boot\"]","fe237f86":"print(labels[df.label[0]])","f6ae784b":"df.shape","4f8eeb34":"df.head()","845204a2":"y = df['label']","34f88bcc":"X = df.drop(['label'], axis=1)","11b9830a":"X1 = np.array(X)","68769474":"image = X1[0].reshape(28,28)","249e413f":"plt.imshow(image)","9209fe94":"plt.imshow(image, cmap=\"gray_r\")\nplt.axis('off')\nplt.title(labels[y[0]])","21d8ddc7":"n_samples = len(df.index)\nimages = X1.reshape(n_samples,28,28)","857f78e6":"plt.figure(figsize = (10,20))\nfor i in range(0,50) :\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    plt.imshow(images[i], cmap=\"gray_r\")\n    plt.title(labels[y[i]])","f8763120":"# On normalise les valeurs entre 0 et 1\nX = X\/225","9c978f25":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)","042fd3bc":"from sklearn.neural_network import MLPClassifier\nmlp = MLPClassifier(hidden_layer_sizes = (200,60))\nmlp.fit(X_train,y_train)\ny_mlp = mlp.predict(X_test)","8efafa9a":"mlp_score = accuracy_score(y_test, y_mlp)\nprint(mlp_score)","2b297926":"pd.crosstab(y_test, y_mlp, rownames=['Reel'], colnames=['Prediction'], margins=True)","251300bc":"from keras.utils.np_utils import to_categorical","e6d4166e":"print(y[0])\ny_cat = to_categorical(y)\nprint(y_cat[0])","468b2446":"num_classes = y_cat.shape[1]\nprint(num_classes)","67c9cca7":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=1)","bbe5759c":"X_train = np.array(X_train)\nX_test = np.array(X_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)","6e84132d":"from keras.models import Sequential\nfrom keras.layers import Dense","087df144":"model = Sequential()\nmodel.add(Dense(200, activation='relu'))\nmodel.add(Dense(60, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))","406ecd27":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","e3c9ae81":"train = model.fit(X_train , y_train , validation_data=(X_test,y_test), epochs=30, verbose=1)","155cd83e":"model.evaluate(X_test,y_test)","a84253ca":"print(train.history['accuracy'])","1157e552":"print(train.history['val_accuracy'])","4e8b6747":"def plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","b3861725":"plot_scores(train)","3141f5a0":"Le dataset a \u00e9t\u00e9 constitu\u00e9 par Zalando :  \nhttps:\/\/github.com\/zalandoresearch\/fashion-mnist  \n  \nOn a un ensemble d'apprentissage de 60 000 images 28x28 pixels en niveaux de gris, et 10 classes de v\u00eatements : jupes, pantalons, baskets, ...","e5a38eae":"<img src=\"https:\/\/github.com\/zalandoresearch\/fashion-mnist\/blob\/master\/doc\/img\/fashion-mnist-sprite.png?raw=true\">","eadddd22":"On utilise la m\u00e9thode *MLPClassifier* de *sklearn* pour utiliser un r\u00e9seau de neurones \u00e0 deux couches cach\u00e9es de 200 et 60 neurones :","2c692126":"On d\u00e9finit une fonction pour afficher un graphique des scores :","9f089ad6":"On a seulement X classes  :","62fc9685":"## Zalando Fashion MNIST","a1999bf0":"On d\u00e9finit un mod\u00e8le \u00e0 deux couches cach\u00e9es de 200 et 60 neurones\nLa derni\u00e8re couche comporte X neurones (le nombre de classes) pour la classification :","e9995d9b":"Pertinence :","a7cd8061":"L'activation de la derni\u00e8re couche est un softmax : la somme des valeurs de l'activation des neurones de la derni\u00e8re couche est 1\n(on interpr\u00e8te la sortie des derniers neurones comme une probabilit\u00e9 d'appartenance \u00e0 la classe correspondante)","7e4fb2c0":"Pour Keras, il est n\u00e9cessaire d'avoir des tableaux et non des dataframes :","bf7fdb47":"La premi\u00e8re image du dataset est un pull :","16a83801":"# *R\u00e9seaux denses (Keras\/Tensorflow)*","d58e1003":"Fonction pour tracer la courbe ROC :","558890ff":"# *R\u00e9seaux denses (sklearn)*","affb518a":"Fonction pour tracer les courbes d'apprentissage sur l'ensemble d'apprentissage et l'ensemble de validation :","d53e9162":"On va utiliser une architecture en couches (mod\u00e8le Sequential), avec des couches denses :","10b90f7d":"## Librairies et fonctions utiles","2024883e":"**Afficher les 50 premiers \u00e9l\u00e9ments du dataset avec leur label**  \n","eac409ad":"On \"compile\" le mod\u00e8le, avec une categorical_crossentropy comme mesure de distance (distance probabiliste multi classes)","ef89e15c":"et sur l'ensemble de validation :","4bd21252":"# Exercice : Zalando Fashion MNIST","4e067755":"La variable train m\u00e9morise l'historique des scores sur l'ensemble d'apprentissage :"}}