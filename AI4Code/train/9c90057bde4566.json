{"cell_type":{"d031a02c":"code","5813d975":"code","bc0fb81a":"code","6ee3eac4":"code","f166d07b":"code","3d7ceb54":"code","6ba8ede8":"code","83856d2a":"code","fb1397e2":"code","1e62ff27":"code","a73a6ae3":"code","e62de13b":"code","4a1e9c16":"code","e6750297":"code","2e9bade9":"markdown","6219e45b":"markdown","72dbd5a1":"markdown","6dcebcef":"markdown","e937a243":"markdown","70b92e82":"markdown","81a2afc6":"markdown","18008623":"markdown","eef9f2e5":"markdown","bf65bc2e":"markdown","534c284e":"markdown"},"source":{"d031a02c":"# import all the tools we need\nimport urllib\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torch.utils.data import DataLoader, Dataset\nimport os \nfrom PIL import Image\nimport random\nimport xml.etree.ElementTree as ET\nimport time\nimport requests","5813d975":"# path of images directory\ndir_path = '..\/input\/face-mask-detection\/images'\n\n# path of xml files directory\nxml_path = '..\/input\/face-mask-detection\/annotations'\n\n# List of Image file name \nfile_list = os.listdir(dir_path)\n\n# How many image files?\nprint('There are total {} images.'.format(len(file_list)))","bc0fb81a":"# Helper function for read the data (label and bounding boxes) from xml file \ndef read_annot(file_name, xml_dir):\n    \"\"\"\n    Function used to get the bounding boxes and labels from the xml file\n    Input:\n        file_name: image file name\n        xml_dir: directory of xml file\n    Return:\n        bbox : list of bounding boxes\n        labels: list of labels\n    \"\"\"\n    bbox = []\n    labels = []\n    \n    annot_path = os.path.join(xml_dir, file_name[:-3]+'xml')\n    tree = ET.parse(annot_path)\n    root = tree.getroot()\n    for boxes in root.iter('object'):\n        ymin = int(boxes.find(\"bndbox\/ymin\").text)\n        xmin = int(boxes.find(\"bndbox\/xmin\").text)\n        ymax = int(boxes.find(\"bndbox\/ymax\").text)\n        xmax = int(boxes.find(\"bndbox\/xmax\").text)\n        label = boxes.find('name').text\n        bbox.append([xmin,ymin,xmax,ymax])\n        if label == 'with_mask':\n            label_idx = 2\n        else:\n            label_idx = 1\n        labels.append(label_idx)\n        \n    return bbox, labels\n\n# help function for drawing bounding boxes on image\ndef draw_boxes(img, boxes,labels, thickness=1):\n    \"\"\"\n    Function to draw bounding boxes\n    Input:\n        img: array of img (h, w ,c)\n        boxes: list of boxes (int)\n        labels: list of labels (int)\n    \n    \"\"\"\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n    for box,label in zip(boxes,labels):\n        box = [int(x) for x in box]\n        if label == 2:\n            color = (0,225,0) # green\n        elif label == 1:\n            color = (0,0,225) # red\n        cv2.rectangle(img, (box[0],box[1]),(box[2],box[3]),color,thickness)\n    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)","6ee3eac4":"# Get the image randomly\nimage_name = file_list[random.randint(0,len(file_list))] # random select an image\n\n# Get the bbox and label\nbbox, labels  = read_annot(image_name, xml_path)\n\n#draw bounding boxes on the image\nimg = draw_boxes(plt.imread(os.path.join(dir_path,image_name)), bbox,labels)\n    \n# display the image\nfig, ax = plt.subplots(1,1,figsize=(10,10))\nplt.axis('off')\nax.imshow(img)","f166d07b":"class image_dataset(Dataset):\n    def __init__(self, image_list, image_dir, xml_dir):\n        self.image_list = image_list\n        self.image_dir = image_dir\n        self.xml_dir = xml_dir\n       \n    def __getitem__(self, idx):\n        \"\"\"\n        Load the image\n        \"\"\"\n        img_name = self.image_list[idx]\n        img_path = os.path.join(self.image_dir, img_name)\n        img = Image.open(img_path).convert('RGB')\n        img = transforms.ToTensor()(img)\n\n        \"\"\"\n        build the target dict\n        \"\"\"\n        bbox, labels = read_annot(img_name, self.xml_dir)\n        boxes = torch.as_tensor(bbox, dtype=torch.float32)\n        labels = torch.as_tensor(labels, dtype=torch.int64)\n        \n        area = (boxes[:,2] - boxes[:,0]) * (boxes[:,3] - boxes[:,1])\n        area = torch.as_tensor(area, dtype=torch.float32)\n        iscrowd = torch.zeros((len(bbox),), dtype=torch.int64)\n        \n        target = {}\n        \n        target['boxes'] = boxes\n        target['labels'] = labels\n        target['image_id'] = torch.tensor([idx])\n        target['area'] = area\n        target['iscrowed'] = iscrowd\n        return img , target\n                    \n    def __len__(self):\n        return len(self.image_list)","3d7ceb54":"mask_dataset = image_dataset(file_list, dir_path, xml_path)\n\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\nmask_loader = DataLoader(mask_dataset,\n                        batch_size=2,\n                        shuffle=True,\n                        num_workers=2,\n                        collate_fn=collate_fn)","6ba8ede8":"# Setting up GPU device\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","83856d2a":"# Setting up the model\n\nnum_classes = 3 # background, without_mask, with_mask\n\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\nin_features = model.roi_heads.box_predictor.cls_score.in_features\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\nmodel = model.to(device)","fb1397e2":"# Setting the optimizer, lr_scheduler, epochs\n\nparams = [p for p in model.parameters() if p.requires_grad]\n#optimizer = torch.optim.Adam(params, lr=0.01)\noptimizer = torch.optim.SGD(params, lr=0.01,momentum=0.9, weight_decay=0.0005)\n#lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=3,gamma=0.1)\nnum_epochs=30","1e62ff27":"# Main training function\nloss_list = []\n\nfor epoch in range(num_epochs):\n    print('Starting training....{}\/{}'.format(epoch+1, num_epochs))\n    loss_sub_list = []\n    start = time.time()\n    for images, targets in mask_loader:\n        images = list(image.to(device) for image in images)\n        targets = [{k:v.to(device) for k,v in t.items()} for t in targets]\n        \n        model.train()\n        loss_dict = model(images, targets)\n        losses = sum(loss for loss in loss_dict.values())\n        loss_value = losses.item()\n        loss_sub_list.append(loss_value)\n        \n        # update optimizer and learning rate\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n        #lr_scheduler.step()\n    end = time.time()\n        \n    #print the loss of epoch\n    epoch_loss = np.mean(loss_sub_list)\n    loss_list.append(epoch_loss)\n    print('Epoch loss: {:.3f} , time used: ({:.1f}s)'.format(epoch_loss, end-start))\n","a73a6ae3":"torch.save(model.state_dict(),'.\/model_0214.pth')","e62de13b":"# helper function for single image prediction\ndef single_img_predict(img, nm_thrs = 0.3, score_thrs=0.8):\n    test_img = transforms.ToTensor()(img)\n    model.eval()\n    \n    with torch.no_grad():\n        predictions = model(test_img.unsqueeze(0).to(device))\n        \n    test_img = test_img.permute(1,2,0).numpy()\n    \n    # non-max supression\n    keep_boxes = torchvision.ops.nms(predictions[0]['boxes'].cpu(),predictions[0]['scores'].cpu(),nm_thrs)\n    \n    # Only display the bounding boxes which higher than the threshold\n    score_filter = predictions[0]['scores'].cpu().numpy()[keep_boxes] > score_thrs\n    \n    # get the filtered result\n    test_boxes = predictions[0]['boxes'].cpu().numpy()[keep_boxes][score_filter]\n    test_labels = predictions[0]['labels'].cpu().numpy()[keep_boxes][score_filter]\n    \n    return test_img, test_boxes, test_labels","4a1e9c16":"#idx = random.randint(1,len(file_list))\nidx = 210\ntest_img = Image.open(os.path.join(dir_path,file_list[idx])).convert('RGB')\n\n# Prediction\ntest_img, test_boxes, test_labels = single_img_predict(test_img)\ntest_output = draw_boxes(test_img, test_boxes,test_labels)\n\n# Draw the bounding box of ground truth\nbbox, labels  = read_annot(file_list[idx], xml_path)\n#draw bounding boxes on the image\ngt_output = draw_boxes(test_img, bbox,labels)\n\n# Display the result\nfig, (ax1,ax2) = plt.subplots(1,2,figsize=(15,6))\nax1.imshow(test_output)\nax1.set_xlabel('Prediction')\nax2.imshow(gt_output)\nax2.set_xlabel('Ground Truth')\nplt.show()","e6750297":"url = 'https:\/\/assets.weforum.org\/article\/image\/yv_SffigotevWgXLOTBsbybWzDlztGjjJM1mDWSqV8c.jpg'\ntest_img = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n\ntest_img, test_boxes, test_labels = single_img_predict(test_img)\n\n# The image size is so large, so we increase the thickness of the bounding box\ntest_output = draw_boxes(test_img, test_boxes,test_labels, thickness=20)\n\nplt.axis('off')\nplt.imshow(test_output)","2e9bade9":"# Face mask detection (Faster R-CNN) (Pytorch)\n- Simple fine-tuning with Faster R-CNN","6219e45b":"### Now try the detector on image from internet","72dbd5a1":"- After createing helper function, lets have a look on the image.","6dcebcef":"Thank you.","e937a243":"- The model has detected one more face (the Buddha).","70b92e82":"### Create 2 helper functions\n1. one for read the data from xml file\n2. the second function is used for drawing bounding boxes.","81a2afc6":"- Setting up the gpu, model, optimizer, etc..","18008623":"- Get the data loader","eef9f2e5":"- Now lets create our custom dataset\n## Prepare the custom dataset","bf65bc2e":"- Lets pick an image from the training set and compare the prediction with ground truth","534c284e":"# Prediction"}}