{"cell_type":{"71f58712":"code","54179b59":"code","ef66d5ea":"code","e48f9c7d":"code","3f63ebdd":"code","701dcd12":"code","c00a0477":"code","87778432":"code","eb40dd83":"code","4d0e1d0e":"code","a593dba5":"code","a9f7ed9e":"code","f406b98d":"code","5680338c":"code","94c07246":"code","3e41a443":"markdown","002a3d89":"markdown","179d4f8f":"markdown","291e6af9":"markdown","29dafde7":"markdown","508b8020":"markdown","eebc5f6d":"markdown","0c15e410":"markdown"},"source":{"71f58712":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n         os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","54179b59":"import os,cv2\ndirectory='\/kaggle\/input\/ckplus\/CK+48'\ndir_list=os.listdir(directory)\nimage_data_list=[]\nlabels=[]\nemotions=[]\nl=0\nfor data_dir in dir_list:\n    data_list=os.listdir(directory+'\/'+data_dir)\n    for img in data_list:\n        input_img=cv2.imread(directory+'\/'+data_dir+'\/'+img)\n        input_img=cv2.resize(input_img,(48,48))\n        image_data_list.append(input_img)\n        labels.append(l)\n    emotions.append(data_dir)\n    l=l+1\nimg_data=np.array(image_data_list)\nimg_data=img_data\/255\nimg_data.shape","ef66d5ea":"from tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nnum_classes=7\nY = keras.utils.to_categorical(labels, num_classes)\nX_train, X_test, y_train, y_test = train_test_split(img_data, Y, test_size=0.2)","e48f9c7d":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndata_generator_with_aug = ImageDataGenerator(horizontal_flip = True,\n                                              width_shift_range = 0.1,\n                                              height_shift_range = 0.1)\ndata_generator_no_aug = ImageDataGenerator()\n\ntrain_generator=data_generator_with_aug.flow(X_train,y_train)\nvalidation_generator=data_generator_with_aug.flow(X_test,y_test)","3f63ebdd":"from keras.models import Sequential\nfrom keras.layers import Dense , Activation , Dropout ,Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.metrics import categorical_accuracy\n\nmodel=Sequential()\nmodel.add(Conv2D(64,(3,3),padding=\"same\",input_shape=(48,48,3),activation='relu'))\nmodel.add(Conv2D(64,(3,3),padding=\"same\",activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(256,(3,3),activation='relu'))\nmodel.add(Conv2D(256,(3,3),activation='relu'))\nmodel.add(Conv2D(256,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dense(32,activation='relu'))\nmodel.add(Dropout(0.6))\nmodel.add(Dense(num_classes,activation='softmax'))\n\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])","701dcd12":"history=model.fit_generator(train_generator,epochs=20,validation_data=validation_generator)\n","c00a0477":"import matplotlib.pyplot as plt\nepochs = [i for i in range(20)]\nfig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nfig.set_size_inches(20,10)\n\nax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\nax[0].plot(epochs , val_acc , 'ro-' , label = 'Validation Accuracy')\nax[0].set_title('Training & Validation Accuracy')\nax[0].legend()\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"Accuracy\")\n\nax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\nax[1].plot(epochs , val_loss , 'r-o' , label = 'Validation Loss')\nax[1].set_title('Testing Accuracy & Loss')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"Training & Validation Loss\")\nplt.show()","87778432":"from sklearn.metrics import confusion_matrix\nresults = model.predict_classes(X_test)\ncm = confusion_matrix(np.where(y_test == 1)[1], results)","eb40dd83":"label = ['anger','contempt','disgust','fear','happy','sadness','surprise']\nlabels = {0 : 'anger', 1 : 'contempt', 2 : 'disgust', 3 : 'fear', 4 : 'happy',5 :'sadness',6 :'surprise'}\n","4d0e1d0e":"#Transform to df for easier plotting\ncm_df = pd.DataFrame(cm, index = label,\n                     columns = label\n                    )","a593dba5":"final_cm = cm_df","a9f7ed9e":"import seaborn as sns\n\nplt.figure(figsize = (5,5))\nsns.heatmap(final_cm, annot = True,cmap='Greys',cbar=False,linewidth=2,fmt='d')\nplt.title('CNN Emotion Classify')\nplt.ylabel('True class')\nplt.xlabel('Prediction class')\nplt.show()","f406b98d":"import cv2 \nface_clsfr=cv2.CascadeClassifier('haarscade_frontalface_default.xml')","5680338c":"size = 4\nwebcam = cv2.VideoCapture(0) #Use camera 0\n\n# We load the xml file\nclassifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n\nwhile True:\n    (rval, im) = webcam.read()\n    im=cv2.flip(im,1,1) #Flip to act as a mirror\n\n    # Resize the image to speed up detection\n    mini = cv2.resize(im, (im.shape[1] \/\/ size, im.shape[0] \/\/ size))\n\n    # detect MultiScale \/ faces \n    faces = classifier.detectMultiScale(mini)\n\n    # Draw rectangles around each face\n    for f in faces:\n        (x, y, w, h) = [v * size for v in f] #Scale the shapesize backup\n        #Save just the rectangle faces in SubRecFaces\n        face_img = im[y:y+h, x:x+w]\n        resized=cv2.resize(face_img,(48,48))\n        normalized=resized\/255.0\n        reshaped=np.reshape(normalized,(1,48,48,3))\n        reshaped = np.vstack([reshaped])\n        result=model.predict(reshaped)\n        answer = model.predict_classes(test_image)\n\n        #print(result)\n        \n        label=np.argmax(result,axis=1)[0]\n      \n        cv2.rectangle(im,(x,y),(x+w,y+h),(0, 0, 225),2)\n        cv2.rectangle(im,(x,y-40),(x+w,y),(0, 0, 225),-1)\n        cv2.putText(im,labels[label] , (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n        \n    # Show the image\n    cv2.imshow('LIVE',   im)\n    key = cv2.waitKey(10)\n    # if Esc key is press then break out of the loop \n    if key == 27: #The Esc key\n        break\n# Stop video\nwebcam.release()\n\n# Close all started windows\ncv2.destroyAllWindows()","94c07246":"import random\nfrom glob import glob\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.preprocessing import image \ndef choose_image_and_predict():\n    folder_choice = (random.choice(dir_list))\n    images = glob(directory + '\/'+ folder_choice+'\/*')\n    img_choice = (random.choice(images))\n    \n    img = image.load_img(img_choice, target_size=(48, 48))\n    img = image.img_to_array(img)\n    plt.imshow(img \/ 255.)\n    x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n    pred_class = model.predict_classes(x)\n    pred = model.predict(x)\n    label=np.argmax(pred,axis=1)[0]   \n    print(\"Actual class:\", folder_choice)\n    print(\"Predicted Class:\" , labels[label])\n        \nchoose_image_and_predict()\n","3e41a443":"# Creating Confusion Matrix to know the performance of Model","002a3d89":"# Data Augmentaion\n","179d4f8f":"# Load the file from the dataset","291e6af9":"# Plot the Graph to check the how good the model is working","29dafde7":"# CNN Model to predict the Mood ","508b8020":"# Split the dataset into test , train","eebc5f6d":"# To Predict on Single Image","0c15e410":"# To Predict Mood using Webcam (Doesn't work on kraggle)\n# Download the Casscade File on your System and run the code"}}