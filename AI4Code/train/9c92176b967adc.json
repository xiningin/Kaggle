{"cell_type":{"a2460045":"code","b7d065d4":"code","f524520a":"code","73c534fa":"code","e8a9bb8a":"code","7072b135":"code","85fb4870":"code","6cf958f2":"code","e381365c":"code","aa518302":"code","fa5dfcd9":"code","f75aa840":"code","99775e25":"code","f29ff351":"code","e5d26d3d":"code","384ed3e1":"markdown","37f92c5b":"markdown","55ddd39a":"markdown","cadc9435":"markdown","711c73e0":"markdown","3974d4f9":"markdown","d27849e3":"markdown","5e1d355b":"markdown","8af23faf":"markdown"},"source":{"a2460045":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b7d065d4":"import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D","f524520a":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","73c534fa":"path = '\/kaggle\/input\/fruits\/fruits-360\/Training\/Quince\/r_305_100.jpg'\n\n## \/kaggle\/input\/fruits\/fruits-360\/Training\/Quince\/r_305_100.jpg\nimg=mpimg.imread(path)\nimgplot=plt.imshow(img)\n","e8a9bb8a":"!cd \/kaggle\/input\/fruits\/fruits-360\/Training\/ ; ls","7072b135":"import os\nimport pprint\n\ntrain_labels = os.listdir(\"\/kaggle\/input\/fruits\/fruits-360\/Training\/\")\npp = pprint.PrettyPrinter(width=120, compact=True)\npp.pprint(train_labels)","85fb4870":"print(\"Total Labels we have : \",len(train_labels))\ntrain_labels.sort()\npp.pprint(train_labels)","6cf958f2":"import plotly.express as px","e381365c":"from skimage import io\n\npath = '\/kaggle\/input\/fruits\/fruits-360\/Training\/Apple Braeburn\/r_305_100.jpg'\n\nimg = io.imread(path)\nfig = px.imshow(img)\nfig.show()","aa518302":"import warnings\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\n\nbatch_size = 32\nnum_classes = 131\nepochs = 80\nmodel_name = \"Fruits_360.h5\"\nsave_path = \"\"\n\npath_to_train = \"\/kaggle\/input\/fruits\/fruits-360\/Training\/\"\npath_to_test = \"\/kaggle\/input\/fruits\/fruits-360\/Test\"\n\nGenerator = ImageDataGenerator()\ntrain_data = Generator.flow_from_directory(path_to_train, (100, 100), batch_size=batch_size)\n\ntest_data = Generator.flow_from_directory(path_to_test, (100, 100), batch_size=batch_size)\n\nmodel = Sequential()\n\nmodel.add(Conv2D(16, (5, 5), input_shape=(100, 100, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=2))\nmodel.add(Dropout(0.05))\n\nmodel.add(Conv2D(32, (5, 5), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=2))\nmodel.add(Dropout(0.05))\n\nmodel.add(Conv2D(64, (5, 5),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=2))\nmodel.add(Dropout(0.05))\n\nmodel.add(Conv2D(128, (5, 5), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=2))\nmodel.add(Dropout(0.05))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.05))\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.05))\n\nmodel.add(Dense(num_classes, activation=\"softmax\"))\nmodel.summary()\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adam(),\n              metrics=['accuracy'])\nmodel.fit_generator(train_data,\n                    steps_per_epoch=1000\/\/batch_size,\n                    epochs=epochs,\n                    verbose=1,\n                    validation_data=test_data, validation_steps = 3)\n\nmodel.save(model_name)","fa5dfcd9":"!ls -la","f75aa840":"!cd \/kaggle\/input\/fruits\/fruits-360\/\n!ls -la","99775e25":"from keras.models import load_model\nfrom keras.preprocessing import image","f29ff351":"model = load_model(\"Fruits_360.h5\")","e5d26d3d":"model.summary()","384ed3e1":"Understanding the directories (i.e. classes\/labels or Fruits) ","37f92c5b":"Let's check the saved model.","55ddd39a":"## Exploratory Data Analysis\n\nAnalysing our datasets and understanding the types of data(classes or fruits) we're dealing with.\n\nBelow code lists all the directories in the training folder of our dataset. As the data is available to us in the form of \".jpg\" images present in the directories, named after the fruit. \n\nWe us \"os\" to list all the directories available in that particular folder and do some quick analysis to find about the classes present in our dataset.\n\n\"pprint\" is a python module to pretty data types such as lists, dictionaries etc. Just for our visual understanding and it looks more readable.","cadc9435":"There we go, We have our model saved! YaY! ","711c73e0":"We have achieved Accuracy of **91%** in **80 Epochs**. Validation Accurary is: 82%","3974d4f9":"So this is what our images are looking like, I will test check some more images further on.","d27849e3":"Further more our model is saved, in future we will test it on more images, and validate it further! This is my first notebook in 3 years of lurking and self doubt! Let's hope, I'll be able to make some more stuff in the near future! ","5e1d355b":"# Fruits 360 \n\nCreating a convolutional neural network to detect images of fruits.","8af23faf":"From the above we can say that our dataset contains a lot of apples, cherries, grapes, pears, and tomatoes.\n\nAnd we certainly don't want our model to overtrain on those types. "}}