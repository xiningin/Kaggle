{"cell_type":{"387a6a48":"code","16d3ca51":"code","6b62c4d1":"code","35ffce51":"code","46995f25":"code","0c8c5f6a":"code","7afbfae8":"code","0c6135e7":"code","e32e8f73":"code","661b032a":"code","ee22f5cf":"code","204ccc0f":"code","103f2acd":"code","52b5e520":"code","b3219da2":"code","2a42fffd":"code","f96a4248":"code","e39e888a":"markdown","a3d31295":"markdown","b728e75f":"markdown"},"source":{"387a6a48":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nimport seaborn as sns\nimport itertools\nfrom tqdm import tqdm","16d3ca51":"# https:\/\/www.kaggle.com\/titericz\/the-property-by-giba\nfeat_old = ['f190486d6', '58e2e02e6', 'eeb9cd3aa', '9fd594eec', '6eef030c1', \n            '15ace8c9f', 'fb0f5dbfe', '58e056e12', '20aa07010', '024c577b9', \n            'd6bb78916', 'b43a7cfd5', '58232a6fb', '1702b5bf0', '324921c7b', \n            '62e59a501', '2ec5b290f', '241f0f867', 'fb49e4212', '66ace2992', \n            'f74e8f13d', '5c6487af1', '963a49cdc', '26fc93eb7', '1931ccfdd', \n            '703885424', '70feb1494', '491b9ee45', '23310aa6f', 'e176a204a', \n            '6619d81fc', '1db387535', 'fc99f9426', '91f701ba2', '0572565c2', \n            '190db8488', 'adb64ff71', 'c47340d97', 'c5a231d81', '0ff32eb98']\n\n# https:\/\/www.kaggle.com\/datagray\/another-set-of-ordered-columns\nfeat_new = ['f3cf9341c','fa11da6df','d47c58fe2','555f18bd3','134ac90df','716e7d74d',\n           '1f6b2bafa','174edf08a','5bc7ab64f','a61aa00b0','b2e82c050','26417dec4',\n           '51707c671','e8d9394a0','cbbc9c431','6b119d8ce','f296082ec','be2e15279',\n           '698d05d29','38e6f8d32','93ca30057','7af000ac2','1fd0a1f2a','41bc25fef',\n           '0df1d7b9a','2b2b5187e','bf59c51c3','cfe749e26','ad207f7bb','11114a47a',\n           'a8dd5cea5','b88e5de84','1bf8c2597']\n    \ndef get_pred(data,FEATURES, lag=2):\n    d1 = data[FEATURES[:-lag]].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n    d2 = data[FEATURES[lag:]].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n    d2['pred'] = data[FEATURES[lag - 2]]\n    d3 = d2[~d2.duplicated(['key'], keep=False)]\n    return d1.merge(d3, how='left', on='key').pred.fillna(0)","6b62c4d1":"train = pd.read_csv('..\/input\/train.csv')","35ffce51":"def get_all_pred(data,feat, max_lag):\n    target = pd.Series(index=data.index, data=np.zeros(data.shape[0]))\n    for lag in range(2, max_lag + 1):\n        pred = get_pred(data,feat, lag)\n        mask = (target == 0) & (pred != 0)\n        target[mask] = pred[mask]\n    return target","46995f25":"df = pd.DataFrame()\ni = 0\nfor subset in tqdm(itertools.combinations(feat_old, 3)):\n    subset = list(subset)\n    pred_train_new = get_all_pred(train,subset,2)\n    have_data = pred_train_new != 0\n    score = sqrt(mean_squared_error(np.log1p(train.target[have_data]), np.log1p(pred_train_new[have_data])))\n    df.loc[i,'subset'] =  str(subset)\n    df.loc[i,'score'] =  score\n    df.loc[i,'number_predictions'] =  have_data.sum()\n#     print(f'Max lag {3}: Score = {sqrt(mean_squared_error(np.log1p(train.target[have_data]), np.log1p(pred_train_new[have_data])))} on {have_data.sum()} out of {train.shape[0]} training samples')\n    i = i + 1","0c8c5f6a":"df['score'].describe()","7afbfae8":"sns.distplot(df['score'])","0c6135e7":"df_sorted = df.sort_values(by='score')\nfeature_list = df_sorted.loc[:30,'subset'].values\nprint('Displaying the best 30 triplet subsets')\ndf_sorted.head(30)","e32e8f73":"best_feature_list = []\nfor i in range(len(feature_list)):\n    foo = feature_list[i][2:-1].split(\"'\")\n    foo.remove(', ')\n    foo.remove(', ')\n    for feat in foo[:-1]:\n        if feat not in best_feature_list:\n            best_feature_list.append(feat)","661b032a":"print(best_feature_list)\nprint('No. of features found based on triplet analysis ',len(best_feature_list))","ee22f5cf":"df_new = pd.DataFrame()\ni = 0\nfor subset in tqdm(itertools.combinations(feat_new, 3)):\n    subset = list(subset)\n    pred_train_new = get_all_pred(train,subset,2)\n    have_data = pred_train_new != 0\n    score = sqrt(mean_squared_error(np.log1p(train.target[have_data]), np.log1p(pred_train_new[have_data])))\n    df_new.loc[i,'subset'] =  str(subset)\n    df_new.loc[i,'score'] =  score\n    df_new.loc[i,'number_predictions'] =  have_data.sum()\n#     print(f'Max lag {3}: Score = {sqrt(mean_squared_error(np.log1p(train.target[have_data]), np.log1p(pred_train_new[have_data])))} on {have_data.sum()} out of {train.shape[0]} training samples')\n    i = i + 1","204ccc0f":"df_new['score'].describe()","103f2acd":"sns.distplot(df_new['score'])","52b5e520":"df_sorted_new = df_new.sort_values(by='score')\nprint('Displaying the best 30 triplet subsets')\ndf_sorted_new.head(30)","b3219da2":"feature_list = df_sorted_new.loc[:30,'subset'].values","2a42fffd":"best_feature_list_new = []\nfor i in range(len(feature_list)):\n    foo = feature_list[i][2:-1].split(\"'\")\n    foo.remove(', ')\n    foo.remove(', ')\n    for feat in foo[:-1]:\n        if feat not in best_feature_list_new:\n            best_feature_list_new.append(feat)","f96a4248":"print(best_feature_list_new)\nprint('No. of features found based on triplet analysis ',len(best_feature_list_new))","e39e888a":"This notebook is inspired by [a-simple-way-to-use-giba-s-features-v2](https:\/\/www.kaggle.com\/dfrumkin\/a-simple-way-to-use-giba-s-features-v2). In this notebook, I use the publicly available set of feature columns and try to find the best possible combination of 3 columns. I use the best found triplets as a new feature set.","a3d31295":"# Triplet Analysis of New Features","b728e75f":"# Triplet Analysis of Old Features"}}