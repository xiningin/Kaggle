{"cell_type":{"175f54d5":"code","d25deca3":"code","2bcd3587":"code","1dd1d4e8":"code","322f5fb1":"code","b4a6e6db":"code","4e3fef14":"code","3d4fa8de":"code","9568b0cb":"code","83d3e444":"code","1dab137e":"code","d666b6e6":"code","69493108":"code","fd78b5d9":"code","329733c1":"code","f528c811":"code","60d95720":"code","50c4c439":"code","e96b26ae":"code","547e46e8":"markdown","595acf56":"markdown","a2619645":"markdown","19b825d8":"markdown","b5fe4110":"markdown","adebbeb2":"markdown","37568df4":"markdown","37163798":"markdown","7b215c33":"markdown","a4e8b7b9":"markdown","07d69c46":"markdown","4f68a5e9":"markdown","2fd732c4":"markdown","31826eb2":"markdown"},"source":{"175f54d5":"#install the lifelines package\n!pip install lifelines","d25deca3":"#Import modules\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom datetime import datetime\nfrom datetime import timedelta\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\nfrom matplotlib.ticker import PercentFormatter\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\nfrom IPython.display import display\nimport seaborn as sns\nimport re\nimport collections \nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud\nfrom lifelines import KaplanMeierFitter\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\n%matplotlib inline\nsns.set()\nimport warnings\nwarnings.filterwarnings('ignore')","2bcd3587":"#Data cleansing and transformation\n\n#load data\nUSvideo=pd.read_csv('..\/input\/youtube-new\/USvideos.csv')\n\n#convert category_ids to more meaningful category names \ncategory_name=pd.read_csv('..\/input\/category-id-names\/category_id_names.csv') # the category information was found online\ncategory_d=dict(zip(category_name.id,category_name.category))\nUSvideo['category']=USvideo['category_id'].map(category_d)\n\n#convert \"trending_date\" and \"publish_time\" to Date\/DateTime\n#calculate the day of the week and the month of each trending day\nUSvideo['trending_date']=pd.to_datetime(USvideo['trending_date'],format=\"%y.%d.%m\")\nUSvideo['publish_time']=pd.to_datetime(USvideo['publish_time'],format='%Y-%m-%dT%H:%M:%S')\nUSvideo['publish_time'] = USvideo['publish_time'].dt.tz_convert(None)\nUSvideo['trending_weekday']=USvideo['trending_date'].dt.weekday_name\nUSvideo['trending_month']=USvideo['trending_date'].dt.month_name()\n\n#calculate video title lengths\nUSvideo['title_length']=USvideo['title'].apply(lambda x:len(x))\n\n#calculate ratios of number of comments to number of views\nUSvideo['comment\/views']=USvideo['comment_count']\/USvideo['views']\n\n#calculate ratios of number of likes to number of views\nUSvideo['likes\/views']=USvideo['likes']\/USvideo['views']\n\n#calculate how long a video stayed on the trending list\nUSvideo['trendingday_rank']=USvideo.groupby('video_id')['trending_date'].rank(method='dense')\nUSvideo['trendingdays']=USvideo.groupby('video_id')['trendingday_rank'].transform(max)\nUSvideo['trendingdays']=USvideo['trendingdays'].apply(lambda x: int(x))\n\n#calculate how fast a video got on the trending list after publication\nUSvideo['age']=(USvideo['trending_date']-USvideo['publish_time']).dt.days\nUSvideo['age']=np.where(USvideo['age']==-1,0,USvideo['age'])\nUSvideo['speed']=USvideo.groupby('video_id')['age'].transform(min)\n\n#calculate the rate of growth in views: set the rate of the first trending day to 1 \nUSvideo['views_growth_rate']=USvideo.sort_values('trending_date').groupby('video_id')['views'].pct_change()\nUSvideo['views_growth_rate']=USvideo['views_growth_rate']+1\nUSvideo['views_growth_rate']=np.where(USvideo['views_growth_rate'].isnull(),1,USvideo['views_growth_rate'])\nUSvideo=USvideo.round({'views_growth_rate':2})\n\n#delete columns that will not be used in the following analysis and drop duplicated rows\ncolumns_del=['category_id','thumbnail_link', 'comments_disabled', 'ratings_disabled',\n       'video_error_or_removed', 'description']\nUSvideo=USvideo.drop(columns=columns_del)\nUSvideo=USvideo.drop_duplicates()\n\n#data preview\nprint(\"The cleaned dataframe has {} rows, {} columns, and {} null value.\\n\".format(USvideo.shape[0],USvideo.shape[1],USvideo.isnull().sum().sum()))\nUSvideo=USvideo.sort_values(by='trending_date')\npd.set_option('display.max_columns', 100)\nprint(\"The first 3 rows of the dataframe:\\n\")\ndisplay(USvideo.head(3))","1dd1d4e8":"#Daily frequency of the 'Entertainment' category\n\n#Figure 1:data preparation \nUSvideo1=USvideo.groupby(['trending_date','category']).size()\nUSvideo1_all=USvideo1\/USvideo1.groupby(level=0).sum()\nUSvideo1_all=USvideo1_all.to_frame().rename(columns={0:'proportion'}).reset_index()\n\n#Figure 1:data visualization\nfig, ax = plt.subplots(figsize=(8,4))\ncategorylist=USvideo['category'].unique().tolist()\n\n#plot \"entertainment\"\ndf_e=USvideo1_all.loc[USvideo1_all['category']=='Entertainment',:]\nax.plot(df_e['trending_date'],df_e['proportion'],color='darkorange')\n\n#plot other categories\nfor i in categorylist:\n    if i!='Entertainment':\n        df=USvideo1_all.loc[USvideo1_all['category']==i,:]\n        ax.plot(df['trending_date'],df['proportion'],color='lightgray')\n        \n#customize figure legend\ncustom_lines = [Line2D([0], [0], color='darkorange', lw=2),\n                Line2D([0], [0], color='lightgray', lw=2)]\nax.legend(custom_lines, ['Entertainment', 'Other Categories'])\n\n#customize axes and title \nplt.title(\"Figure 1. 'Entertainment' appears most frequently among the 16 trending categories\\n\",fontsize=13,y=-0.35)\nax.set(xlabel='date',ylabel='percentage of videos')\nax.set_ylim(0,0.4)\n\n#change y axis values to percentage\nax.yaxis.set_major_formatter(PercentFormatter(1))\n\n#add a horizontal lines to show the mean percentage of the 'Entertainment' category\nent_mean=USvideo1_all.loc[USvideo1_all['category']=='Entertainment','proportion'].mean()\nax.axhline(y=ent_mean,xmin=0,xmax=1,linestyle='--')\nplt.show()","322f5fb1":"#Average views by category\n\n#Figure 2: data preparation\nUSvideo2=USvideo.groupby('category')['views'].mean().sort_values(ascending=True)\n\n#Figure 2: data visualization\ncolors=['lightgray']*16\ncolors[11]='darkorange'\nplt.figure(figsize=(8,4))\nUSvideo2.plot(kind='barh',color=colors,width=0.75)\nplt.xlabel(\"average views per video\")\nplt.title(\"Figure 2.\\'Entertainment\\' is the 5th most-viewed category\\n\",fontsize=13,y=-0.35)\nE_views=round(USvideo2['Entertainment']\/1000000,2)\nplt.text(2200000,10.6,'{} million views\/video'.format(E_views),color='black',fontsize=12)\nplt.show()","b4a6e6db":"#Additional data cleansing and transformation\n\n#Now I will focus only on the \"entertainment\" category\nUSvideo3=USvideo.loc[USvideo['category']=='Entertainment'].copy()\n\n#clean \"tags\" \nUSvideo3['tags']=USvideo3['tags'].str.lower().str.replace('\"','')\nUSvideo3['tags_new']=USvideo3['tags'].apply(lambda x: x.split('|') )\nUSvideo3['tags_new']=np.where(USvideo3['tags']=='[none]','',USvideo3['tags_new'])\n\n#calculate the number of tags used in each video\nUSvideo3['tags_number']=USvideo3['tags_new'].apply(lambda x:len(x))\nUSvideo3['tags_number']=np.where(USvideo3['tags']=='[none]',0,USvideo3['tags_number'])\n\n#clean \"title\"\nUSvideo3['title_new']=USvideo3['title'].str.lower().str.replace(\"[^a-zA-Z0-9]\", \" \")\n\n#remove the first 29 days from the dataset \n#Why? We don't know if the trending videos on the earlier days were trending before  \n#those days or not, and thus the calculated \"trendingdays\" may be inaccurate for those early videos.\n# 29 was chosen because it was the maximum days a video stayed trending.\nfirst=min(USvideo3['trending_date'])+timedelta(days=29)\nUSvideo4=USvideo3.loc[USvideo3['trending_date'] > first,:].copy()\n\n#create a smaller subset by picking only the first trending day information of the videos\n#Why? Some videos appeared multiple times in the dataset due to the fact that they were trending for more than 1 day.\n#USvideo4 created above will still be used, but we also need one record per video for machine learning.\nUSvideo5=USvideo4.loc[USvideo4.trendingday_rank==1.0,:].copy()","4e3fef14":"#Wordcloud of title\nst=stopwords.words('english')\ntitles=' '.join( i for i in USvideo5.title_new)\ncloud = WordCloud(stopwords=st,max_words=100,background_color=\"white\").generate(titles)\nplt.imshow(cloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title(\"Figure 3. Wordcloud generated from titles of 'Entertainment' videos\",y=-0.2,fontsize=13)\nplt.show()","3d4fa8de":"#wordcloud of tags\n\n#write a function to count tag frequency\ndef create_tagcounter(data):\n    tagslist=data['tags_new'].tolist()\n    tags_flatlist=[item for sublist in tagslist for item in sublist]\n    tags_d=collections.Counter(tags_flatlist)\n    return tags_d\n\n#generate wordcloud from tag frequency\ncloud2=WordCloud(stopwords=st,max_words=100,background_color=\"white\").generate_from_frequencies(create_tagcounter(USvideo5))\nplt.imshow(cloud2, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title(\"Figure 4. Wordcloud generated from tags of 'Entertainment' videos\",y=-0.2,fontsize=13)\nplt.show()","9568b0cb":"# growth rate of views (views\/views on the previous day)\nplt.figure(figsize=(8,4))\nsns.scatterplot(x='trendingday_rank',y='views_growth_rate',data=USvideo4,s=85,alpha=0.5)\nplt.ylim(0,20)\nplt.xticks(range(0,30,1))\nplt.yticks(range(0,20,2))\nplt.xlabel('days on trending')\nplt.ylabel('growth rate of views')\nplt.title(\"Figure 5. \\'Entertainment\\' witnesses the fastest growth rate of views on the 2nd trending day \\n \",fontsize=13,y=-0.35)\nplt.show()","83d3e444":"#survival analysis of entertainment videos on the trending list\n\n#data preparation: The \"birth\" event is the presence on the trending list and the \"death\" event is the exit of the trending list\n#Censoring occur if the video is still on the trending list at the time of data collection (Jun 14, 2018)\nUSvideo5['event']=np.where(USvideo5['trending_date']==max(USvideo5['trending_date']),0,1)\n\n#fit model\nkmf = KaplanMeierFitter()\nkmf.fit(USvideo5['trendingdays'], event_observed=USvideo5['event'],label='Kaplan Meier Estimate')\nkmf.plot()\nplt.xticks(range(0,30,2))\nplt.xlabel(\"timeline(days)\")\nplt.ylabel(\"probability of being on the trending list\")\nplt.title(\"Figure 6. Duration of 'Entertainment' videos on the trending list\",fontsize=13,y=-0.35)\nplt.show()","1dab137e":"#Other interesting facts about the entertainment category\nplt.figure(figsize=(8,4))\n\n#pie chart: percentage of videos that got on the trending list within 1 day\nplt.axes([0.08, 0.5, 0.25, 0.5])\ngroups=['speed<= 1 day','speed >1 day']\nsize=[(USvideo5['speed']<=1).sum(),(USvideo5['speed']>1).sum()]\ncenter_circle=plt.Circle((0,0),0.7,color='white')\nplt.pie(size,labels=groups,colors=['lightsteelblue','lightgray'],labeldistance=1.05,startangle=0,textprops={'fontsize': 11})\nplt.gcf().gca().add_artist(center_circle) \nplt.axis('equal')\nplt.text(-0.38,-0.05,'76.5%',fontsize=18,weight='bold',color='cornflowerblue')\n\n#histogram: distribution of number of tags\nplt.axes([0.6, 0.55, 0.35, 0.4])\nsns.distplot(USvideo5['tags_number'])\nplt.xlabel('number of tags')\nplt.ylabel('proportion')\n\n#waffle chart: number of 'likes' per 100 views \nplt.axes([0,0,0.4,0.4])\ntemp=np.zeros((10,10))\ntemp[9,:3]=1\nplt.matshow(temp,fignum=0,cmap=mpl.colors.ListedColormap(['lightgray', 'lightsteelblue']))\nplt.xticks(np.arange(-0.5,10,1),labels=[])\nplt.yticks(np.arange(-0.5,10,1),labels=[])\nlikes_num=round(USvideo5['likes\/views'].mean(),2)*100\nplt.text(0,4.5,'3 \"likes\" \/ 100 views',fontsize=9,weight='bold',color='cornflowerblue')\nplt.title(\"Figure 7. Other facts about the 'Entertainment' category\",x=1,y=-0.4,fontsize=13)\n\n#boxplot: distribution of title length\nplt.axes([0.55,0.05,0.4,0.3])\nsns.boxplot(USvideo5['title_length'],color='lightsteelblue')\nplt.xlabel('length of title')\nplt.show()","d666b6e6":"#Can my video last for more than 6 days on the trending list?\n#Target: trendingdays>= 6 days or trendingdays<6 days\n#Predictors:videos' 1st trending days' dynamic features and static features\n\n#data preparation\n#select relevant columns\nnewcolumns=['trendingdays','views', 'comment\/views',\n       'likes\/views','speed','tags_number', 'title_length','trending_weekday',\"trending_month\"] \n\n#remove 2018 June videos as I wasn't sure if those videos kept trending after the last data collection day (June 14, 2019).\nUSvideo6=USvideo5.loc[USvideo5.trending_month!='June',newcolumns]\n\n#creat the binary \"Y\" column \nUSvideo6['6_days']=np.where(USvideo6.trendingdays>=6,1,0)\n\n#more data transformation\nUSvideo6['views']=np.log(USvideo6['views'])\nUSvideo6.rename(columns={'views':'log_views'},inplace=True)\nUSvideo6=pd.get_dummies(USvideo6,drop_first=True)\nUSvideo7=USvideo6.drop(columns='trendingdays')\n\n#train\/test split\nX=USvideo7.drop(columns='6_days')\ny=USvideo7['6_days']\nX_train1, X_test1, y_train, y_test = train_test_split(X, y, stratify=y, random_state=12)\n\n#data standardization\nX_train2=X_train1.iloc[:,:6]\nX_train3=X_train1.iloc[:,6:]\nX_test2=X_test1.iloc[:,:6]\nX_test3=X_test1.iloc[:,6:]\nX_train4 = StandardScaler().fit_transform(X_train2)\nX_train5 = pd.DataFrame(X_train4, index=X_train2.index, columns=X_test2.columns)\nX_test4 = StandardScaler().fit_transform(X_test2)\nX_test5 = pd.DataFrame(X_test4, index=X_test2.index, columns=X_test2.columns)\nX_train=pd.concat([X_train3,X_train5],axis=1)\nX_test=pd.concat([X_test3,X_test5],axis=1)\n\n#let's look at the correlation heatmap first\nplt.figure(figsize=(8,5))\nmask = np.zeros_like(USvideo7.corr())\nmask[np.triu_indices_from(mask)] = True\nwith sns.axes_style(\"white\"):\n    ax=sns.heatmap(USvideo7.corr(),mask=mask,cmap='Blues')\n    ax.set_title(\"Figure 8. Correlation Heatmap of 'Entertaiment' video variables\",fontsize=13)","69493108":"#dummy classifier\ndummy = DummyClassifier(random_state=2)\ndummy.fit(X_train, y_train)\ny_pred_dummy=dummy.predict(X_test)\ny_pred_prob_dummy=dummy.predict_proba(X_test)[:,1]","fd78b5d9":"#logistic regression\nlr=LogisticRegression(solver='lbfgs')\nlr.fit(X_train, y_train)\ny_pred_lr = lr.predict(X_test)\ny_pred_prob_lr=lr.predict_proba(X_test)[:,1]","329733c1":"#decision tree\ntree1 = DecisionTreeClassifier(random_state = 12)\n\n#find best parameters\nparam_tree = {\"max_depth\": range(1,10),\n           \"min_samples_split\": range(2,10,1),\n           \"max_leaf_nodes\": range(2,5)}\ngrid_tree = GridSearchCV(tree1,param_tree,cv=5)\ngrid_tree.fit(X_train,y_train)\nbp_tree=grid_tree.best_params_\n\n#fit model\ntree2=DecisionTreeClassifier(random_state = 12,max_depth=bp_tree['max_depth'],min_samples_split=bp_tree['min_samples_split'],max_leaf_nodes=bp_tree['max_leaf_nodes'])\ntree2.fit(X_train,y_train)\ny_pred_tree=tree2.predict(X_test)\ny_pred_prob_tree=tree2.predict_proba(X_test)[:,1]","f528c811":"#Support vector classifier\nsvc_kernel = SVC(kernel = 'rbf')\n\n#find best parameters\nparam_svc_kernel = {'C': [1,10,100,1000,10000],'gamma':[0.001,0.001,0.1,1,10]}\ngrid_svc_kernel = GridSearchCV(svc_kernel, param_svc_kernel, cv=5, n_jobs=2)\ngrid_svc_kernel.fit(X_train, y_train)\nbp_svc=grid_svc_kernel.best_params_\n\n#fit model\nsvc2=SVC(kernel = 'rbf',C=bp_svc['C'],gamma=bp_svc['gamma'],probability=True)\nsvc2.fit(X_train,y_train)\ny_pred_svc=svc2.predict(X_test)\ny_pred_prob_svc=svc2.predict_proba(X_test)[:,1]","60d95720":"#K nearest neighbor\nknn = KNeighborsClassifier()\n\n# find best parameters\nparam_knn = {'n_neighbors': range(1,20)}\ngrid_knn = GridSearchCV(knn, param_knn, cv=5)\ngrid_knn.fit(X_train, y_train)\nbp_knn=grid_knn.best_params_\n\n#fit model\nknn2=KNeighborsClassifier(n_neighbors = bp_knn['n_neighbors'])\nknn2.fit(X_train,y_train)\ny_pred_knn=knn2.predict(X_test)\ny_pred_prob_knn=knn2.predict_proba(X_test)[:,1]","50c4c439":"#XGBoost classifier\nxgb = XGBClassifier()\n\n#find best parameters\nparameters = {\n     \"eta\"    : [0.05, 0.15,0.25, 0.30 ] ,\n     \"max_depth\"        : [ 3, 4, 5, 6],\n     \"min_child_weight\" : [ 1, 3, 5, 7 ],\n     \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n     \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n     }\ngrid_xgb = GridSearchCV(xgb,\n                    parameters, \n                    cv=3)\ngrid_xgb.fit(X_train, y_train)\nbp_xgb=grid_xgb.best_params_\n\n#fit model \nxgb1 = XGBClassifier(eta=bp_xgb['eta'],max_depth=bp_xgb['max_depth'],min_child_weight=bp_xgb['min_child_weight'],gamma=bp_xgb['gamma'],colsample_bytree=bp_xgb['colsample_bytree'])\nxgb1.fit(X_train, y_train)\ny_pred_prob_xgb = xgb1.predict(X_test)\ny_pred_xgb= [round(value) for value in y_pred_prob_xgb]","e96b26ae":"# model performance summary\n\n#plot roc curves and calculate roc_auc score for each model\ny_pred_list=[y_pred_dummy,y_pred_lr,y_pred_svc,y_pred_tree,y_pred_knn,y_pred_xgb]\ny_pred_prob_list=[y_pred_prob_dummy,y_pred_prob_lr,y_pred_prob_svc,y_pred_prob_tree,y_pred_prob_knn,y_pred_prob_xgb]\nmodel_list=['Dummy Classifier','Logistic Regression','SVC','Decision Tree','KNN','XGBoost']\nfor i in range(len(y_pred_list)):\n    fpr, tpr, threshold = roc_curve(y_test,y_pred_prob_list[i])\n    with sns.axes_style(\"white\"):\n        plt.plot(fpr,tpr,label=model_list[i]+\"(auc=\" + \"{0:0.2f}\".format(roc_auc_score(y_test,y_pred_prob_list[i]))+\")\")\n        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\nplt.title(\"Figure 9. ROC curves of models predicting if a video will stay trending for at least 6 days \",fontsize=13,y=-0.3)\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.show()","547e46e8":"_(c) summay of model performance_","595acf56":"_(b2) Logistic Regression_","a2619645":"_(a) Data preparation for machine learning and correlation heatmap_","19b825d8":"__Question 3: Can my video stay popular for at least 6 days if it gets on the trending list?__\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;What if-I mean, if my video gets on the trending list, will it stay there for a long time? As an ungreedy new content creator, my goal is to reach the median trending days (6 days) (Figure 6).\n\n__Answer 3: I don't know, but I can make predictions with machine learning models.__ \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;__Target__: I labeled the videos as either '>= 6 days' or '< 6 days' based on their trending days.\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;__Predictors__: since the question was raised under the assumption that my video was trending for at least 1 day, I should have the following information by the end of the 1st trending day: (1) the number of views on the first trending day; (2) the ratio of comment numbers to views on the first trending day; (3) the ratio of \"likes\" to views on the first trending day; and some 'static features\": (4) how fast my video becomes trending ('speed'); (5) the number of tags used; (6) how long my title is; (7) which weekday the first trending day is on; (8) which month the first trending day is in. \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I tested several models, including the dummy (baseline) classifier, logistic regresssion, decision tree, support vector classifier(SVC), K nearest neighbor(KNN), and XGBoost. While the roc_auc score of the baseline classifier is ~0.5, the performances among the other models are much better and quite similar, with roc_auc scores of around 0.7 (Figure 9). ","b5fe4110":"_More data cleansing and transformation_","adebbeb2":"__Question 2: What should my \u201cEntertainment\u201d videos look like?__\n\n__Answer 2: They should look like the ones on the trending list.__ If I create and publish a video today, I will probably use ~30 tags ('funny' is a must) and a ~50 characters long title containing 'new', 'review', and\/or 'HD' (Figure 3, 4, and 7). If I am lucky, my video may become trending tomorrow (Figure 7), double its views the day after tomorrow (Figure 5), stay popular for another 3 to 4 days (Figure 6) with a total views of 2.07 million (Figure 2), and eventually receive 60K 'likes' (Figure 7).","37568df4":"_(b3) Decision Tree_","37163798":"_(b5) K Nearest Neighbor (KNN)_","7b215c33":"## Start a YouTube Entertainment Channel?\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;To make a long story short, I am thinking of creating a YouTube channel for fun, fame, and (of course) profit. The first question is: what content?  I am not a sports fan, have never owned a pet, seldomly travel anywhere, and don\u2019t even know if Taylor Swift is the name of a dish or a car brand. Oh, wait, \u201centertainment\u201d sounds like an easy topic, but do people really watch it? Let me see if I can dig out some information from the \u201cYouTube Trending Statistics\u201d dataset.\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Briefly, I focused on the trending videos in the USA. The file contains all the YouTube trending videos from November 2017 to June 2018, with ~200 videos\/day. After some data cleansing and transformation, the dataset looks like this:","a4e8b7b9":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In summary, by analyzing the \"YouTube Trending Statistics\" dataset, I am now convinced to start my Entertainment channel and have also got some insights on how to design my videos. If one of my videos gets on the trending list, instead of spending the whole first night worrying about whether it will disappear from the list soon, I can easily estimate how likely it will be there for at least 6 days.","07d69c46":"_(b6) XGBoost_","4f68a5e9":"__Question 1: Is building an Entertainment YouTube channel a great idea?__\n\n__Answer 1: Yes.__ YouTube users love Entertainment channels: (1) \u201cEntertainment\u201d is trending on the trending list. Hooray! Around 24% of the trending videos were from \u201cEntertainment\u201d each day (Figure 1); (2) The \u201cEntertainment\u201d category, with an average of 2.07 million views per trending video,  is among the TOP FIVE contend categories watched (Figure 2). ","2fd732c4":"_(b) I tested the following models:_\n\n_(b1) Dummy Classifier (to measure the 'baseline' performance)_","31826eb2":"_(b4) Support Vector Classifier (SVC)_"}}