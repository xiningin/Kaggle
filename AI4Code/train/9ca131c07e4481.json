{"cell_type":{"610f394f":"code","aad2ed22":"code","f935f060":"code","697757e4":"code","5a1515de":"code","4ced2d31":"code","8b406df9":"code","1422c990":"code","c41c8063":"code","31ef77f4":"code","1ce070dc":"code","e3303226":"code","ec46119a":"code","7bc7647e":"code","4fc34058":"code","ee22e718":"code","a9615374":"code","6818c235":"code","f628af6f":"code","777e4e05":"code","9f592ea2":"code","78d16a19":"code","316b972e":"code","49f37d19":"code","641b2038":"code","5f364bc7":"code","56794ed1":"code","f839d736":"code","d6764b1c":"markdown","8dce7785":"markdown","9f26b910":"markdown","4d37e34a":"markdown","44691913":"markdown","fadd8d2d":"markdown","f591786d":"markdown","521f19e7":"markdown","8ec914a0":"markdown","513ca585":"markdown","ddd8bcb3":"markdown","99417dd0":"markdown","df4fdce5":"markdown","e04762f5":"markdown","420ca3a5":"markdown","e27bdf8a":"markdown","96e2b509":"markdown","9aa0ecae":"markdown","9572870f":"markdown"},"source":{"610f394f":"######################################################################################\n# Handle warnings\n######################################################################################\nimport warnings\ndef ignore_warn(*args, **kwargs):\n    pass\n\nwarnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\nwarnings.simplefilter(action='ignore', category=FutureWarning) # Scipy warnings\n\n######################################################################################\n# Standard imports\n######################################################################################\nimport os\nimport math\nimport pickle\nfrom copy import copy\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\n\nfrom scipy import stats\nfrom scipy.stats import norm\nfrom scipy.stats import skew\nfrom scipy.special import boxcox1p\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\nsns.set_style('darkgrid')","aad2ed22":"train_path = \"..\/input\/train.csv\"\ntest_path = \"..\/input\/test.csv\"\n\n# Load the dataset with Pandas\ntrain = pd.read_csv(train_path)\ntest = pd.read_csv(test_path)\n\n# Number of  samples\nn_train = train.shape[0]\nn_test = test.shape[0]\n\n# Extract the GT labels and IDs from the data\ntrain_y = train['SalePrice']\nprint(train_y.unique().shape)\ntrain_ids = train['Id']\ntest_ids = test['Id']\n\ntrain = train.drop('Id', axis=1)\ntest = test.drop('Id', axis=1)\n\n# Split the dataset into continous and categorical features\ntrain_numeric_feat = train.select_dtypes(include=[np.number]).columns.values\n\n# Placeholder for columns that will be dropped at the end\ndrop_columns = []","f935f060":"fig = plt.figure(figsize=(15,3))\nplt.subplot(121)\n# Show distribution of labels against normal distribution\nsns.distplot(train['SalePrice'] , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train['SalePrice'])\n\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\nplt.title('SalePrice')\n\nplt.subplot(122)\nres = stats.probplot(train['SalePrice'], plot=plt)\nplt.show()\n\n# Log transform the SalePrice and see the results\n# Numpy fuction log1p which  applies log(1+x) to all elements of the column\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n\nfig = plt.figure(figsize=(15,3))\nplt.subplot(121)\n# Show distribution of labels against normal distribution\nsns.distplot(train['SalePrice'] , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train['SalePrice'])\n\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\nplt.title('log(SalePrice)')\n\nplt.subplot(122)\nres = stats.probplot(train['SalePrice'], plot=plt)\nplt.show()","697757e4":"# Merge the test and train dataset to get access to all posibilities of categories\ntrain_y = train['SalePrice'] \ntrain_wo_y = train.drop('SalePrice', axis=1)\nall_data = pd.concat((train_wo_y, test)).reset_index(drop=True)","5a1515de":"# Pool: 'NA' ==> No pool\nall_data[\"PoolQC\"] = all_data[\"PoolQC\"].fillna(\"None\")\n# MiscFeatures: 'NA' ==> No additional features\nall_data[\"MiscFeature\"] = all_data[\"MiscFeature\"].fillna(\"None\")\n# Alley: 'NA' ==> No alley access\nall_data[\"Alley\"] = all_data[\"Alley\"].fillna(\"None\")\n# Fence: 'NA' ==> No fence\nall_data[\"Fence\"] = all_data[\"Fence\"].fillna(\"None\")\n# FireplaceQu: 'NA' ==> No fireplace\nall_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].fillna(\"None\")\n# MSSubClass: 'NA' ==> 'NoBuilding'\nall_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"NoBuildung\")    \n\n# LotFrontage: Calculate the median LotFrontage of the neighborhood\n# The neighborhood attribute describes the area around the house\nall_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n\n# Garage attributes: 'NA' ==> Not given\nfor col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    all_data[col] = all_data[col].fillna('None')\n# Additional attributes that are 'NA' if no garage is given ('NA')\n# Replace these missing values with 0\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    all_data[col] = all_data[col].fillna(0)\n\n# Basement: If there is no basement, these attributes are also 0 || Categorical features ==> None\nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    all_data[col] = all_data[col].fillna(0)\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    all_data[col] = all_data[col].fillna('None')\n\n# MasVnrType: If not given it will be None and nor area (0)\nall_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\nall_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\n\n# MSZoning: 'RL' is the most common value ==> fill empty fields with 'RL'\nall_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n\n# Functional: If 'NA' ==> typical\nall_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typical\")\n\n# Electrical: Most fields are 'SBrKr' ==> Fill empty fields with 'SBrKr'\nall_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n\n# Electrical: Most fields are 'TA' ==> Fill empty fields with 'TA'\nall_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n\n# Exterior: Also apply most common categoreis\nall_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\nall_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\n\n# SaleType: Also apply most common categoreis\nall_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\n\n# Utilities: All values are 'AllPub' except 3 different values ==> drop this attribute\ndrop_columns.append('Utilities')","4ced2d31":"perc_missing_col = (all_data.isnull().sum() \/ len(all_data)) * 100\nperc_missing_col = perc_missing_col.drop(perc_missing_col[perc_missing_col == 0].index)\nperc_missing_col = perc_missing_col.sort_values(ascending=False)[:20]\nperc_missing_col = pd.DataFrame({'Missing Ratio' : perc_missing_col})\nperc_missing_col.head() # The dataframe should be empty","8b406df9":"all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']","1422c990":"def plot_df_distributions(df, num_cols=3, columns=None):\n    if columns is None:\n        _columns = df.loc[:,df.dtypes != 'object'].columns.values\n    else:\n        _columns = columns\n\n    n_cols = num_cols\n    n_rows = math.ceil(len(_columns)\/n_cols)\n    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols*3.5,n_rows*3))\n\n    for r_idx in range(n_rows):\n        for c_idx in range(n_cols):\n            col_idx = r_idx*3+c_idx\n            \n            if col_idx < len(_columns):\n                col = _columns[col_idx]\n                sns.distplot(df[col], ax=axes[r_idx][c_idx], fit=norm)\n    \n    plt.tight_layout()\n    plt.show()","c41c8063":"def plot_df_countplots(df, num_cols=3, columns=None):\n    if columns is None:\n        _columns = df.loc[:,df.dtypes == 'object'].columns.values\n    else:\n        _columns = columns\n\n    n_cols = num_cols\n    n_rows = math.ceil(len(_columns)\/n_cols)\n    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols*4,n_rows*3))\n\n    for r_idx in range(n_rows):\n        for c_idx in range(n_cols):\n            col_idx = r_idx*3+c_idx\n            if col_idx < len(_columns):\n                col = _columns[col_idx]\n                \n                sns.countplot(df[col], ax=axes[r_idx][c_idx])\n                axes[r_idx][c_idx].set_title(col)\n                for item in axes[r_idx][c_idx].get_xticklabels():\n                    item.set_rotation(45)\n    \n    plt.tight_layout()\n    plt.show()","31ef77f4":"plot_df_distributions(all_data, num_cols=3)","1ce070dc":"plot_df_countplots(all_data, num_cols=3)","e3303226":"# Mark some of the categorical features for dropping, because they are were unbalanced\ndrop_columns.append('Street')\ndrop_columns.append('Condition2')\ndrop_columns.append('RoofMatl')\ndrop_columns.append('Heating')\ndrop_columns.append('MiscVal')","ec46119a":"TIME_FEATURES = [\n    'YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold'\n]\n\nORDERD_CAT_FEATURES = [\n    'LotShape', 'LandSlope', 'OverallQual', 'PoolQC', 'GarageQual',\n    'Fence', 'GarageCond', 'GarageFinish', 'OverallCond', 'ExterQual', 'ExterCond',\n    'KitchenQual', 'FireplaceQu', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'BsmtExposure'\n]\n\nSIMPLE_CAT_FEATURES = [\n    'MSSubClass', 'MSZoning', 'Street', 'Alley', 'LandContour', 'SaleType',\n    'SaleCondition', 'PavedDrive', 'MiscFeature', 'MiscVal', 'LotConfig',\n    'Neighborhood', 'Electrical', 'Functional', 'GarageType', 'CentralAir',\n    'Heating', 'Foundation', 'MasVnrType', 'Exterior2nd', 'Exterior1st',\n    'RoofMatl', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', \n    'BsmtFinType1', 'BsmtFinType2', 'RoofStyle', 'MoSold', 'Utilities'\n]\n\nALL_CAT_FEATURES = TIME_FEATURES + ORDERD_CAT_FEATURES + SIMPLE_CAT_FEATURES\n\nCONTINUOUS_FEATURES = list(all_data[all_data.columns.difference(ALL_CAT_FEATURES)].columns.values)\n\nprint('Total number of columns: {}'.format(len(CONTINUOUS_FEATURES) + len(SIMPLE_CAT_FEATURES) + len(ORDERD_CAT_FEATURES) + len(TIME_FEATURES)))","7bc7647e":"for col in TIME_FEATURES:\n    all_data[col] = all_data[col].astype(int)\nall_data[TIME_FEATURES].head(5)","4fc34058":"ORDERED_ENCODINGS = {\n    'LotShape' : {'Reg' : 3, 'IR1' : 2, 'IR2': 1, 'IR3': 0},\n    'LandSlope' : {'Gtl' : 2, 'Mod' : 1, 'Sev' : 0},\n    'OverallQual' : {'10' : 9, '9' : 8, '8' : 7, '7' : 6, '6' : 5, '5' : 4, '4' : 3, '3' : 2, '2' : 1, '1' : 0},\n    'PoolQC' : {'None' : 0, 'Fa' : 1, 'TA' : 2, 'Gd' : 3, 'Ex' : 4},\n    'GarageQual' : {'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5},\n    'Fence' : {'None' : 0, 'MnWw' : 1, 'GdWo' : 2, 'MnPrv' : 3, 'GdPrv' : 4},\n    'GarageCond' : {'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5},\n    'GarageFinish' : {'None' : 0, 'Unf' : 1, 'RFn' : 2, 'Fin' : 3},\n    'OverallCond' : {'10' : 9, '9' : 8, '8' : 7, '7' : 6, '6' : 5, '5' : 4, '4' : 3, '3' : 2, '2' : 1, '1' : 0},\n    'ExterQual' : {'None' : 0, 'Fa' : 1, 'TA' : 2, 'Gd' : 3, 'Ex' : 4}, \n    'ExterCond' : {'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5},\n    'KitchenQual' : {'None' : 0, 'Fa' : 1, 'TA' : 2, 'Gd' : 3, 'Ex' : 4},\n    'FireplaceQu' : {'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5},\n    'BsmtQual' : {'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5},\n    'BsmtCond' : {'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5},\n    'HeatingQC' : {'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5},\n    'BsmtExposure' : {'None' : 0, 'No' : 1, 'Mn' : 2, 'Av' : 3, 'Gd' : 4},\n    'BsmtFinType1' : {'None' : 0, 'Unf' : 1, 'LwQ' : 2, 'Rec' : 3, 'BLQ' : 4, 'ALQ' : 5, 'GLQ' : 6},\n    'BsmtFinType2' : {'None' : 0, 'Unf' : 1, 'LwQ' : 2, 'Rec' : 3, 'BLQ' : 4, 'ALQ' : 5, 'GLQ' : 6},\n    #'MoSold' : {'1' : 0, '2' : 2, '3' : 3, '4' : 4, '5' : 5, '6' : 6, '7' : 7, '8' : 8, '9' : 9, '10' : 10, '11' : 11, '12' : 12}\n}\n\nfor col in ORDERD_CAT_FEATURES:\n    all_data[col] = all_data[col].apply(str)\n    all_data[col] = all_data[col].map(ORDERED_ENCODINGS[col])\n    all_data[col] = all_data[col].dropna(0)\n    all_data[col] = all_data[col].apply(float)\n    \nall_data[ORDERD_CAT_FEATURES].head(5)","ee22e718":"for col in SIMPLE_CAT_FEATURES:\n    all_data[col] = all_data[col].astype(str)\nall_data[SIMPLE_CAT_FEATURES].head(5)","a9615374":"feature_skewness = all_data[CONTINUOUS_FEATURES].apply(lambda x: skew(x.dropna()))\nfeature_skewness = feature_skewness.sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew' : feature_skewness})\nskewness.head(10)","6818c235":"high_skewed_features = skewness.loc[abs(skewness.Skew) >= 1.0].index.values\nplot_df_distributions(all_data, columns=high_skewed_features)","f628af6f":"# Fix skew with box_cox transfomation\nlam = 0.15\nfor feat in high_skewed_features:\n    all_data[feat] = boxcox1p(all_data[feat], lam)\n    \nplot_df_distributions(all_data, columns=CONTINUOUS_FEATURES)","777e4e05":"# Scale the data\nfeatures_to_scale = CONTINUOUS_FEATURES + TIME_FEATURES + ORDERD_CAT_FEATURES\nnumeric_scaler = MinMaxScaler()\nnumeric_scaler.fit(all_data[features_to_scale])\nall_data[features_to_scale] = numeric_scaler.transform(all_data[features_to_scale])","9f592ea2":"plot_df_distributions(all_data)","78d16a19":"all_data = all_data.drop(drop_columns, axis=1)","316b972e":"all_data_oh = pd.get_dummies(all_data)","49f37d19":"train = all_data_oh[:n_train]\ntest = all_data_oh[n_train:]\nprint(\"Shape train: {}\".format(train.shape))\nprint(\"Shape test: {}\".format(test.shape))","641b2038":"train.head(5)","5f364bc7":"test.head(5)","56794ed1":"isolation_forest = IsolationForest(max_samples=100, random_state=42)\nisolation_forest.fit(train)\n\n# Evaluate all rows by the random forest\noutlier_info = pd.DataFrame(isolation_forest.predict(train), columns=['Top'])\n\n# Get the index of the outliers and remove them \nno_outlier_idxs = outlier_info[outlier_info['Top'] == 1].index.values\noutlier_idxs = outlier_info[outlier_info['Top'] == -1].index.values\ntrain = train.iloc[no_outlier_idxs]\n\n# Also remove the outliers from the labels (Y)\ntrain_y = train_y.iloc[no_outlier_idxs]\n\nprint('Number of outliers: {}'.format(outlier_idxs.shape[0]))\nprint('Shape train dataset after removal: {}'.format(train.shape[0]))\nprint('Shape train dataset labes after removal: {}'.format(train_y.shape[0]))","f839d736":"dataset_container = {\n    'train' : train,\n    'train_y' : train_y,\n    'train_ids' : train_ids,\n    'test' : test,\n    'test_ids' : test_ids,\n    \n    # Column names by type\n    'time_based_features' : TIME_FEATURES,\n    'ordered_category_features' : ORDERD_CAT_FEATURES,\n    'simple_category_features' : SIMPLE_CAT_FEATURES,\n    'numeric_features' : CONTINUOUS_FEATURES,\n    \n    # Encoding dicts\n    'ordered_category_features_encodings' : ORDERED_ENCODINGS,\n    'scaler' : numeric_scaler\n}\n\n\ntrain['SalePrice'] = train_y\ntrain['Id'] = train_ids\ntrain.to_csv('preprocessed_train.csv', index=False)\ntest['Id'] = test_ids.values\ntest.to_csv('preprocessed_test.csv', index=False)\n\n# Dump the results\n#with open('res\/basic_house_pricing\/preprocessed_data-ADVANCED-ENGINEERING.cdump', 'wb') as out_file:\n#    pickle.dump(obj=dataset_container, file=out_file)","d6764b1c":"## Transform simple categories in dummy variables (one hot encoded)","8dce7785":"### Encode time-based features","9f26b910":"# Transform target variable\nSalePrice is not normal distributed.","4d37e34a":"## Merge train and test data","44691913":"# EDA and preprocessing","fadd8d2d":"### Encode orderd categories\nFix the order of this categories based on their value. Higher numbers indicate a higher value of the feature.","f591786d":"### Prepare simple categories for One-Hot-Encoding as pandas dummy variables","521f19e7":"## Scale the numeric features","8ec914a0":"## Check distributions again","513ca585":"## Split the data in train and test again","ddd8bcb3":"## Remove some outliers of the train dataset","99417dd0":"## Save the dataset and all encoding information for later usage\nFor this challenge it is not necessary to keep this information, but maybe for a production environment","df4fdce5":"## Load the datasets","e04762f5":"## Handle the encoding of the different feature types\n* Time-based features ==> Numeric encoding\n* Orderd category features ==> Numeric encoding (0 - worst, ... , 10 - best)\n* Simple category features ==> One-Hot-Encoding\n* Numeric features ==> continous numeric encoding and skewness fixing\/transformation","420ca3a5":"## Show distribution of all features","e27bdf8a":"## Add custom crafted feature ==> Total area of property and buildings","96e2b509":"## Fill missing values per category","9aa0ecae":"### Check if some values are left","9572870f":"## Remove columns that are marked for dropping"}}