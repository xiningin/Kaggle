{"cell_type":{"b5329793":"code","8828e7f5":"code","a6d536d0":"code","78352ffe":"code","d09f9e1e":"code","339b4b59":"code","89987e7a":"code","ac98ffcb":"code","0e7dc089":"code","5170ea48":"code","f489c71a":"code","ac121333":"code","9a24290f":"code","ccb334d0":"code","33810105":"code","5e0acf5f":"code","a9074177":"code","2cd4ff0d":"code","a294503d":"code","dd7bb366":"code","a8717582":"code","a15fcb0e":"code","d2ba7f1d":"code","130deeef":"code","79c76ca9":"markdown"},"source":{"b5329793":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom PIL import Image\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport shutil\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8828e7f5":"import os\nfrom glob import glob\nimport gc\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom shutil import copyfile\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\n#customize iPython writefile so we can write variables\nfrom IPython.core.magic import register_line_cell_magic\n\n@register_line_cell_magic\ndef writetemplate(line, cell):\n    with open(line, 'w') as f:\n        f.write(cell.format(**globals()))\n        \nimport torch\nprint(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","a6d536d0":"!conda install '\/kaggle\/input\/pydicom-conda-helper\/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","78352ffe":"fast_df = False\nIMG_SIZE = 600","d09f9e1e":"import numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","339b4b59":"def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https:\/\/www.kaggle.com\/xhlulu\/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im","89987e7a":"split = 'test'\nimage_id = []\ndim0 = []\ndim1 = []\nsplits = []\nsave_dir = f'\/kaggle\/tmp\/{split}\/image\/'\nos.makedirs(save_dir, exist_ok=True)\n\nfor dirname, _, filenames in tqdm(os.walk(f'\/kaggle\/input\/siim-covid19-detection\/{split}')):\n    for file in filenames:\n        # set keep_ratio=True to have original aspect ratio\n        xray = read_xray(os.path.join(dirname, file))\n        im = resize(xray, size=IMG_SIZE)  \n        im.save(os.path.join(save_dir, file.replace('.dcm', '_image.jpeg')))\n        image_id.append(file.replace('.dcm', ''))\n        dim0.append(xray.shape[0])\n        dim1.append(xray.shape[1])\n        splits.append(split)\nmeta = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1, 'split': splits})","ac98ffcb":"MODEL_PATH = \"\/kaggle\/input\/k\/ajinkyadeshpande39\/yolo-notebook\/tmp\/yolov5\/artifacts\/run_1qerm3x5_model:v24\/last.pt\"\n# MODEL_PATH = \"\/kaggle\/input\/yolov5-150-epochs-covid-localization\/best.pt\"\n# MODEL_PATH = \"\/kaggle\/input\/yolo-notebook\/tmp\/yolov5\/artifacts\/run_2yubez04_model:v29\/best.pt\"\nTEST_PATH = '\/kaggle\/tmp\/test\/image'","0e7dc089":"# from numba import cuda\n# import torch\n# cuda.select_device(0)\n# cuda.close()\n# cuda.select_device(0)","5170ea48":"%cd \/kaggle\/input\/k\/ajinkyadeshpande39\/yolo-notebook\/tmp\/yolov5","f489c71a":"!python detect.py --weights {MODEL_PATH} \\\n                  --source {TEST_PATH} \\\n                  --img {512} \\\n                  --conf 0.3 \\\n                  --iou 0.4\\\n                  --save-txt \\\n                  --save-conf \\\n                  --project \"\/kaggle\/tmp\/detect\"","ac121333":"# Model =  tf.keras.models.load_model(\"\/kaggle\/input\/efficientnetb7\/weights\/my_model.h5\") \n#83%","9a24290f":"Model =  tf.keras.models.load_model(\"\/kaggle\/input\/efficientnetweights\/weights\/my_model.h5\") \n#75%","ccb334d0":"# Model =  tf.keras.models.load_model(\"\/kaggle\/input\/efnetb7-layers-increased-more-trainable-layers\/weights\/my_model.h5\")\n#65%","33810105":"name2label = { \n    'negative': 2,\n    'indeterminate': 1,\n    'atypical': 0,\n    'typical': 3}\nlabel2name  = {v:k for k, v in name2label.items()}","5e0acf5f":"filepaths = glob('\/kaggle\/input\/siim-covid19-detection\/test\/**\/*dcm',recursive=True)\ntest_df = pd.DataFrame({'filepath':filepaths,})\ntest_df['image_id'] = test_df.filepath.map(lambda x: x.split('\/')[-1].replace('.dcm', '')+'_image')\ntest_df['study_id'] = test_df.filepath.map(lambda x: x.split('\/')[-3].replace('.dcm', '')+'_study')\ntest_df.head()","a9074177":"test_df[\"path_modified\"] = test_df.filepath.map(lambda x: \"\/kaggle\/tmp\/test\/image\/\" +\n                                                x.split('\/')[-1].replace('.dcm', '')+\"_image.jpeg\")","2cd4ff0d":"test_df","a294503d":"PRED_PATH = '\/kaggle\/tmp\/detect\/exp\/labels'\n!ls {PRED_PATH}","dd7bb366":"prediction_files = os.listdir(PRED_PATH)\nprint('Number of test images predicted as opaque: ', len(prediction_files))","a8717582":"# The submisison requires xmin, ymin, xmax, ymax format. \n# YOLOv5 returns x_center, y_center, width, height\ndef correct_bbox_format(bboxes):\n    correct_bboxes = []\n    for b in bboxes:\n        xc, yc = int(np.round(b[0]*IMG_SIZE)), int(np.round(b[1]*IMG_SIZE))\n        w, h = int(np.round(b[2]*IMG_SIZE)), int(np.round(b[3]*IMG_SIZE))\n\n        xmin = xc - int(np.round(w\/2))\n        xmax = xc + int(np.round(w\/2))\n        ymin = yc - int(np.round(h\/2))\n        ymax = yc + int(np.round(h\/2))\n        \n        correct_bboxes.append([xmin, xmax, ymin, ymax])\n        \n    return correct_bboxes\n\n# Read the txt file generated by YOLOv5 during inference and extract \n# confidence and bounding box coordinates.\ndef get_conf_bboxes(file_path):\n    confidence = []\n    bboxes = []\n    with open(file_path, 'r') as file:\n        for line in file:\n            preds = line.strip('\\n').split(' ')\n            preds = list(map(float, preds))\n            confidence.append(preds[-1])\n            bboxes.append(preds[1:-1])\n    return confidence, bboxes","a15fcb0e":"# Read the submisison file\nsub_df = pd.read_csv('\/kaggle\/input\/siim-covid19-detection\/sample_submission.csv')\nsub_df","d2ba7f1d":"# Prediction loop for submission\npredictions = []\n# iterating through submission.csv.\nfor i in tqdm(range(len(sub_df))):\n    row = sub_df.loc[i]\n    id_name = row.id.split('_')[0]\n    id_level = row.id.split('_')[-1]\n    # passing all images under this id through Efficientneb7 model if id_level is 'study' \n    if id_level == 'study':\n        # one study can contain more than one images. multiple images can have same predictions. appending all predictions \n        # in set and submitting only distinct predictions. \n        temp = set()\n        ans =\"\"\n        for i in test_df.loc[test_df[\"study_id\"]==row.id][\"path_modified\"] :\n            # dcm to jpeg\n            img = tf.io.read_file(i)\n            img = tf.image.decode_jpeg(img, channels=1)\n            img = tf.reshape(img,(1,IMG_SIZE,IMG_SIZE,1))\n            # output predictions\n            op = Model(img)\n            label = label2name[op.numpy().argmax()]+\" 1 0 0 1 1\" \n            temp.add(label)\n        for i in temp:\n            ans = ans +i+\" \"\n            \n        predictions.append(ans.strip())\n\n    elif id_level == 'image':\n        # we can do image-level classification here.\n        # also we can rely on the object detector's classification head.\n        # for this example submisison we will use YOLO's classification head. \n        # since we already ran the inference we know which test images belong to opacity.\n        if f'{id_name}_{id_level}.txt' in prediction_files:\n            # opacity label\n            confidence, bboxes = get_conf_bboxes(f'{PRED_PATH}\/{id_name}_{id_level}.txt')\n            bboxes = correct_bbox_format(bboxes)\n            pred_string = ''\n            for j, conf in enumerate(confidence):\n                pred_string += f'opacity {conf} ' + ' '.join(map(str, bboxes[j])) + ' '\n            predictions.append(pred_string[:-1]) \n        else:\n            predictions.append(\"none 1 0 0 1 1\")","130deeef":"sub_df['PredictionString'] = predictions\nsub_df.to_csv('\/kaggle\/working\/submission.csv', index=False)\nsub_df","79c76ca9":"all the detection will be stored in '\/kaggle\/tmp\/detect'"}}