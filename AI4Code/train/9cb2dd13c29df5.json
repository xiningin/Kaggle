{"cell_type":{"67964c75":"code","a7d28be8":"code","59965c4a":"code","5f7248ac":"code","47faecc9":"code","2d63a188":"code","65adae8b":"code","a61fddcd":"code","98c3dd6f":"code","e9997935":"code","1562a0cc":"code","28204c7c":"code","2978b639":"code","0a7bbb2e":"code","8bfcd30b":"code","4d1bba5c":"code","bb7e469f":"code","1c0a67fe":"code","77c9d751":"markdown","311043b3":"markdown","ac9e6783":"markdown","420ef2b9":"markdown","604f2450":"markdown","5dbf7507":"markdown","3b39904d":"markdown","b4296297":"markdown","acfe0dd9":"markdown","59654407":"markdown","51c410a4":"markdown","5601b70c":"markdown","e61c3d7d":"markdown","8cf0937f":"markdown","3f0ad422":"markdown"},"source":{"67964c75":"import shap\nimport pandas as pd\n\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.pyplot as plt\n\n\nfrom tqdm.notebook import tqdm\n\nfrom IPython.display import YouTubeVideo\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RepeatedKFold, train_test_split\nfrom sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score","a7d28be8":"raw_data  = pd.read_csv('..\/input\/divorce-prediction\/divorce_data.csv', delimiter=';')\nreference = pd.read_csv('..\/input\/divorce-prediction\/reference.tsv', delimiter='|')","59965c4a":"def get_reference(i, verbose = True):\n    question = reference.loc[i,'description']\n    if verbose:\n        print('Q{}: {}'.format(i,question))\n    else:\n        return(question)","5f7248ac":"# Check missingness\nraw_data.isnull().any().sum()","47faecc9":"# Plot correlogram\nsns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\nplt.figure(figsize=(20,16))\nsns.heatmap(raw_data.corr(), cmap='viridis')\nplt.show()","2d63a188":"def evaluate_model(preds, test_y, verbose = True, threshold = 0.5):\n    \n    preds_int = preds >= threshold\n    \n    \n    accuracy = accuracy_score(test_y, preds_int)\n    roc_auc  = roc_auc_score(test_y, preds)\n    pr_auc   = average_precision_score(test_y, preds)\n    f1_val   = f1_score(test_y, preds_int)\n    \n    if verbose:\n        print('Accuracy: {}'.format(accuracy))\n        print('AUROC:    {}'.format(roc_auc))\n        print('PRAUC:    {}'.format(pr_auc))\n        print('F1 Score: {}'.format(f1_val))\n    \n    \n    results = [accuracy, roc_auc, pr_auc, f1_val]\n    return(results)","65adae8b":"def run_experiment(dataframe, n = 100, use_tqdm=True):\n    results = pd.DataFrame()\n    \n    if use_tqdm:\n        iterator = tqdm(range(n))\n    else:\n        iterator = range(n)\n    \n    for i in iterator:\n        train_x, test_x = train_test_split(dataframe,\n                                   test_size = 0.3,\n                                   random_state = i\n                                  )\n        \n        \n        train_y = train_x.pop('Divorce')\n        test_y  = test_x.pop('Divorce')\n        \n        rf_model = RandomForestClassifier()\n        rf_model.fit(train_x, train_y)\n        \n        preds    = rf_model.predict_proba(test_x)[:,1]\n        \n        current_results = evaluate_model(preds, test_y, verbose = False)\n        results = results.append([current_results])\n    \n    \n    results.reset_index(drop=True, inplace=True)\n    results.columns = ['accuracy','roc_auc','pr_auc','f1_score']\n    return(results, rf_model)","a61fddcd":"rf_results, rf_model = run_experiment(raw_data)","98c3dd6f":"print('......................................')\nprint('Experiment results (mean of 100 runs)')\nprint('......................................')\nprint('Accuracy: {}'.format(rf_results.accuracy.mean()))\nprint('AUROC:    {}'.format(rf_results.roc_auc.mean()))\nprint('PRAUC:    {}'.format(rf_results.pr_auc.mean()))\nprint('F1 Score: {}'.format(rf_results.f1_score.mean()))","e9997935":"fig = px.box(rf_results.melt(var_name='metric'),\n               x = 'metric',\n               y = 'value',\n               color_discrete_sequence= ['#fc0362'],\n               title = 'Distribution of Metric Values Across 100 Runs',\n               template = 'plotly_dark'\n              )\n\n\nfig.update_xaxes(title='Metric', gridcolor = 'rgba(240,240,240, 0.05)')\nfig.update_yaxes(title='Value', gridcolor = 'rgba(240,240,240, 0.05)')\n\nfig.update_layout({'plot_bgcolor': 'rgba(40, 40, 40, 1.0)',\n                   'paper_bgcolor': 'rgba(30, 30, 30, 1.0)',\n                  })\nfig.show()","1562a0cc":"# Herzberg two factor theory of motivation\nYouTubeVideo('f-qbGAvR4EU', width=800, height=450)","28204c7c":"# Gottham four horsemen of apocalipse\nYouTubeVideo('1o30Ps-_8is', width=800, height=450)","2978b639":"explainer   = shap.TreeExplainer(rf_model)\nshap_values = explainer.shap_values(raw_data)","0a7bbb2e":"# Average feature contribution\nplt.title('Average Feature Contribution for each Class')\nshap.summary_plot(shap_values, raw_data, plot_type=\"bar\", plot_size = (15,10))\n\n# Keep top 20 most important feature indexes for later\nquestion_list = [17,19,5,20,18,40,39,9,25,11,15,27,38,26,4,3,41,36,14,22]","8bfcd30b":"# Granular feature contribution plot\nplt.title('Feature Contribution According to Value')\nshap.summary_plot(shap_values[0], raw_data, plot_size = (15,10))","4d1bba5c":"# Question outline of 20 most important features\nfor question_index in question_list:\n    get_reference(question_index)","bb7e469f":"shap.dependence_plot(\"Q5\", shap_values[1], raw_data, show=False)\nplt.title('Dependance Plot: Q5 and Q36')\nplt.show()\n\nget_reference(5)\nget_reference(36)","1c0a67fe":"for i in range(1,55):\n    shap.dependence_plot(\"Q{}\".format(i), shap_values[1], raw_data)","77c9d751":"# Relationship Lessons","311043b3":"In this section we will uncover associations among the questions and draw possible scenarios that these questions could represent, for the sake of further understanding when and how these predictors materialize.\n\nRelationships are complex by nature, marriages specially, so it should be rare to have a single sole predictor being the cause of the divorce.\nAs years of empirical experience on the field of flight risks, it was noted that major problems are never due to a single root cause, but rather from multiple major causes.\n\nMuch like a plane falling from the sky, a relationship is likely to fall due to multiple horsemen being nourished from the patterns of behaviour - and now We'll try to uncover such patterns by looking at feature associations.\n\n","ac9e6783":"Our RandomForest performed really, really well, even without tunning. And such performance is consistent as well, as it can be seen from the plots bellow.","420ef2b9":"It is one thing to grasp the general concepts, but it is another to recognize them on a day to day basis.\n\nWe will start by interpreting the most important features (survey questions) on an individual basis and after that we will look into their associations, as in the complexity of a relationship it will be rare to find a scenario as simples as a single feature.","604f2450":"# Feature Association","5dbf7507":"### Avoidance and Lack of Communication\nFrom the association of questions 5 and 36 we can picture a scenario where the partners have few time for their relationship and often discuss in a non calm manner.\nIt is a common pattern to \"escape to work\" or other activities in order to diminish the extent and therefore impact of a unsatisfying relationship.\n\nAt the same time, having fewer time as partners may stack insatisfactions that will \"burst\" during a conversation, causing it to not be calm.\n\n\nThis association materializes both Stonewalling and Criticism.","3b39904d":"Now that we have a pretty decent model, lets use ML interpretability in order to draw knowledge about relationships.","b4296297":"# Foreword on Relationship Lessons","acfe0dd9":"# Model Evaluation","59654407":"Our dataset has no missing values","51c410a4":"### How to read this plot\n> SHAP values make use of Shapley equations to frame the prediction as a cooperative game - where are all features must work together in order to achieve a result great than the sum of its individual parts.\n\n> The color represents the feature value (scale from 0 = never to 4 = always in this dataset) and the X axis represents the impact on the final decision (divorce is to right).","5601b70c":"# Abstract","e61c3d7d":"This dataset is based on the research conducted by [Dr. Gottman](https:\/\/en.wikipedia.org\/wiki\/John_Gottman) and the questions essentially distill his divorce predictors.\n\nThese divorce predictors are also known as the **four horsemen of apocalypse** as they are the major themes in the context of divorce.\nThe four horsemen are:\n- Criticism\n- Contempt\n- Defensiveness\n- Stonewalling\n\nThe video bellow gives a quick overview of these predictors.","8cf0937f":"This is a work in progress, I'm preparing a full length notebook, covering all 4 of his books as well as this dataset!","3f0ad422":"Before any attempt to extract lessons, it is worth keeping some things in mind: Take things with a pinch of salt, as the data was collected in various regions of Turkey, and regional and cultural differences do play a role in the notions of what makes a relationship.\n\nAlso, the researchers stated a selection bias for either picking very happy couples or already divorced ones, so we should expect to see great results as the harder-to-predict cases were intentionally left out.\n\nAlso, it is worth nothing that research on the topic of workforce motivation differentiates factors that prevent disatisfaction from factors that create satisfaction. That is to say, for example, having a safe workplace might hamper demotivation, however adding more and more safety past a threshold will never make it a great place to work on its own.\n\nThe same could apply to relationships, the absense of divorce factors does not create a satisfying relationship on its own. For more information on such research, please refer to the video bellow.\n\nFinally we are drawing conclusions from a single type of relationship (marriage) and trying to extrapolate it to other kinds of relationships.\nIf in one hand marriages are more comprehensive than other forms of relationships and could therefore provide a better and more complete picture of what makes great relationships, it could also point to factors that may not be as relevant for other forms of relationships.\n"}}