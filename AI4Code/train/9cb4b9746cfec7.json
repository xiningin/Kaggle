{"cell_type":{"a293081e":"code","bf7eb378":"code","c5b65f51":"code","a0164926":"code","afd3d612":"code","851b901d":"code","3b2cd17e":"code","c87464fa":"code","2a70c7c1":"code","1faf5496":"code","88d31502":"code","7cc62533":"code","e1b4f6a1":"code","cdd8fd31":"code","b0a786e4":"code","6083f47e":"code","c8331d9d":"code","fb294bf9":"code","b8927c5e":"code","4e5c9e87":"code","1e6c6d15":"code","fef75b0d":"code","d3bbdd13":"code","690986d3":"code","cf21d52f":"code","31503ca6":"code","148b1d91":"code","58db1dcb":"code","501f5aac":"code","47aef5c1":"code","afd75eaa":"code","3edf0872":"code","4e0b20e9":"code","dfaa01a1":"code","bc0479c0":"code","4fef4c18":"markdown","9df9d8db":"markdown"},"source":{"a293081e":"import pandas as pd \nimport numpy as np \n","bf7eb378":"# train data \ntrn = pd.read_csv('..\/input\/google-smartphone-decimeter-challenge\/baseline_locations_train.csv')\ntrn.head()","c5b65f51":"# test data\ntst = pd.read_csv('..\/input\/google-smartphone-decimeter-challenge\/baseline_locations_test.csv')\ntst.head()","a0164926":"trn.shape , tst.shape","afd3d612":"# find distinct values in test and train data set \nfor col in trn.columns:\n    print('{0} : (trn , tst) : {1}, {2} '.format(col, trn[col].nunique(), trn[col].nunique()))","851b901d":"## Check min , max and percentile of the dataset\ntrn.describe()","3b2cd17e":"tst.describe()","c87464fa":"# change data type of millisSinceGpsEpoch\nEpoch_offset = pd.to_datetime('1980-01-06 00:00:00')\n#print(Epoch_offset.value)\nEpoch_offset_in_ms = int(Epoch_offset.value \/ 1e6)\nprint(Epoch_offset_in_ms)\n","2a70c7c1":"trn['millisSinceGpsEpoch'] = pd.to_datetime(trn['millisSinceGpsEpoch'] + Epoch_offset_in_ms , unit='ms' )\ntst['millisSinceGpsEpoch'] = pd.to_datetime(tst['millisSinceGpsEpoch'] + Epoch_offset_in_ms , unit='ms' )","1faf5496":"trn.head()","88d31502":"# latdeg and lngdeg\ntrn_lat_lng = trn[['latDeg','lngDeg']].round(3)\ntrn_lat_lng['count'] = 1\ntrn_lat_lng_f  = trn_lat_lng.groupby(['latDeg','lngDeg']).sum().reset_index()\ntrn_lat_lng_f[trn_lat_lng_f['count'] != 1]","7cc62533":"# latdeg and lngdeg\ntst_lat_lng = tst[['latDeg','lngDeg']].round(3)\ntst_lat_lng['count'] = 1\ntst_lat_lng_f  = tst_lat_lng.groupby(['latDeg','lngDeg']).sum().reset_index()\ntst_lat_lng_f[tst_lat_lng_f['count'] != 1]","e1b4f6a1":"import folium \nlat1 = trn.latDeg[0]\nlng1 = trn.lngDeg[0]\nm = folium.Map(location=[lat1, lng1])\nfor i in range(1,len(tst_lat_lng_f)):\n    folium.Marker(location=[trn.latDeg[i], trn.lngDeg[i]],popup='Default popup Marker1').add_to(m)\nm","cdd8fd31":"# Check first log to find data \n#('..\/input\/google-smartphone-decimeter-challenge\/train\/2020-05-14-US-MTV-1\/Pixel4\/Pixel4_GnssLog.txt');\n\ndef ReadGNSSlog(train_test, drive_id, phone_name, log_type):\n    '''Read log file . Extract headers and then create data frame under each header'''\n    path= '..\/input\/google-smartphone-decimeter-challenge\/'+train_test+'\/'+drive_id+'\/'+phone_name+'\/'+phone_name+'_GnssLog.txt'\n    #print('Path is {0}'.format(path))\n    header = [log_type]\n    header_dict = {i: [] for i in header}    \n    datas = {i: [] for i in header}\n    \n    with open(path) as f_open:\n        datalines = f_open.read().splitlines()\n        \n        for line in datalines:\n            #print(line)\n            is_header = line.startswith('#')\n            line = line.strip('#').strip(' ').split(',')\n            #print('after change {0}'.format(line))\n            if (is_header and line[0] in header):\n                header_dict[line[0]] = ['collectionName', 'phoneName']+line[1:]\n            elif not is_header and line[0] in header:\n               # datas[line[0]].append([drive_id,phone_name ])\n                datas[line[0]].append([drive_id,phone_name ]+ line[1:])\n        \n        results= dict()\n        for key, val in datas.items():\n            #df_name = print('df_{0}'.format(key))\n            #print(df_name)\n            #exec(f\"df_{key} = pd.DataFrame(datas[key] , columns= header_dict[key])\")\n            results[key] = pd.DataFrame(val, columns=header_dict[key])\n            print(key)\n            \n    \n        f_open.close()\n        return results","b0a786e4":"trn_GNSS_data = trn[['collectionName', 'phoneName']].groupby(['collectionName', 'phoneName']).sum().reset_index()\ntrn_GNSS_data.head()","6083f47e":"results_f={}\nfor row in range(len(trn_GNSS_data)):\n    print(trn_GNSS_data.loc[row,'collectionName'] , trn_GNSS_data.loc[row,'phoneName'])\n    key = 'results_train_'+trn_GNSS_data.loc[row,'collectionName']+'_'+trn_GNSS_data.loc[row,'phoneName']\n    print('.....'+key+'....')\n    results_f[key]= ReadGNSSlog('train', trn_GNSS_data.loc[row,'collectionName'], trn_GNSS_data.loc[row,'phoneName'],'Raw')","c8331d9d":"first = True\nfor key in results_f.keys():\n    if (first):\n        df_train_Raw = results_f[key][\"Raw\"]\n        first = False\n    else:\n        #print( df_train_Raw.head(5))\n        #print(results_f[key][\"Raw\"].head(5))\n        df_train_Raw = pd.concat([df_train_Raw, results_f[key][\"Raw\"]], ignore_index=True )\n\ndf_train_Raw.head()","fb294bf9":"# Shape of df_train_Raw\ndf_train_Raw.shape","b8927c5e":"df_train_Raw.info()","4e5c9e87":"\"I am error \"\ncols = list(df_train_Raw.columns.difference(['collectionName','phoneName']))\ndf_train_Raw[cols]= df_train_Raw[cols].apply(pd.to_numeric, errors='coerce')\ndf_train_Raw = df_train_Raw.replace(np.nan, 0)\ndf_train_Raw.head()","1e6c6d15":"# Clear intermediate dictionary\nresults_f.clear()\ndf_train_Raw = df_train_Raw.replace(np.nan, 0)\ndf_train_Raw.head()","fef75b0d":"# Info of new dataframe\ndf_train_Raw.info(verbose=True)","d3bbdd13":"import matplotlib.pyplot as plt\n# Calculate Arrival Time \ndf_Raw['ArrivalTime'] = df_Raw['TimeNanos'] - df_Raw['FullBiasNanos'] - df_Raw['BiasNanos']\nprint(df_Raw.ArrivalTime.describe())\ndf_Raw.ArrivalTime.hist(bins=20)\nplt.show()","690986d3":"df_Raw.info()","cf21d52f":"df_Raw['TransmitTime'] = df_Raw.ReceivedSvTimeNanos  - df_Raw.ReceivedSvTimeUncertaintyNanos\nprint(df_Raw['TransmitTime'].describe())\ndf_Raw['TransmitTime'].hist(bins=2)\nplt.show()","31503ca6":"# Full Bias Nano secons is zero \ndf_Raw.info()","148b1d91":"# Bias Uncertainity NOnno is too large\nprint(df_Raw.BiasUncertaintyNanos.describe([0.25,0.50,0.6,0.7,0.8,0.9]))\ndf_Raw.boxplot(column='BiasUncertaintyNanos')\nplt.show()\n","58db1dcb":"print(df_Raw['ArrivalTime'].describe([0.25,0.5,0.6,0.7,0.8,0.9]))\ndf_Raw.boxplot(column = ['ArrivalTime'])\nplt.show()","501f5aac":"# ConstellationType                          \ndf_Raw.ConstellationType.value_counts(normalize=True)","47aef5c1":"# TimeNanos is empty \ndf_Raw[df_Raw.TimeNanos.isnull()]","afd75eaa":"# Max value should be 65535 \ndf_Raw.State.value_counts()","3edf0872":"#11  ReceivedSvTimeNanos                        57497 non-null  int64  \n #12  ReceivedSvTimeUncertaintyNanos             57497 non-null  int64  \n\ndf_Raw['TransmitTime'].describe()","4e0b20e9":"#AccumulatedDateRange - Max value allocated should be 31 as range of bits is only till 5 \ndf_Raw.AccumulatedDeltaRangeState.value_counts()","dfaa01a1":"# AccumulatedDeltaRangeUncertaintyMeters     is too high should range between 0 and 1 \ndf_Raw['AccumulatedDeltaRangeUncertaintyMeters'].describe()","bc0479c0":"df_Raw.head()","4fef4c18":"EDA for GNSS Logs : Raw Data","9df9d8db":"# Region \/ Model Phone \/ Log Analysis"}}