{"cell_type":{"6f389738":"code","1b58e9d3":"code","c6007c01":"code","5cee56eb":"code","68c88b10":"code","55983499":"code","9da82bbd":"code","9e834f8a":"code","dfde1999":"code","808ccdad":"code","d565ad30":"code","ac409e93":"code","3e274ec3":"code","30efef24":"code","0e0550c2":"code","378582ab":"code","41066265":"code","4315befb":"code","28e08e83":"code","72c23f6f":"code","6b78dab0":"code","a8d57ccd":"markdown","6d9358c7":"markdown","7773a429":"markdown","f5ece221":"markdown"},"source":{"6f389738":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1b58e9d3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","c6007c01":"train_dataframe = pd.read_csv('..\/input\/train_data.txt',sep=',',header=None)","5cee56eb":"train_dataframe.head()","68c88b10":"# taking only the valid features as given instructions from the website\nx_train=train_dataframe.iloc[:,1:27]","55983499":"x_train.head() ","9da82bbd":"y_train =train_dataframe.iloc[:,-1]","9e834f8a":"test_dataframe = pd.read_csv('..\/input\/test_data.txt',sep=',',header=None)","dfde1999":"test_dataframe.head()","808ccdad":"# taking the valid features\nx_test = test_dataframe.iloc[:,1:27]\ny_test = test_dataframe.iloc[:,-1]","d565ad30":"x_test.head()","ac409e93":"#here i tried stnadardisation not normalisation\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\n","3e274ec3":"feat_x_train= sc.fit_transform(x_train)\nfeat_x_test = sc.transform(x_test)","30efef24":"from sklearn.metrics import confusion_matrix,accuracy_score\nfrom sklearn.metrics import f1_score","0e0550c2":"def train_classifier(clf,X_train,y_train):\n    clf.fit(X_train,y_train)\n\ndef predict_labels(clf,features,target,name):\n    \n    y_pred = clf.predict(features)\n    cm = confusion_matrix(target.values,y_pred)\n    print(cm)\n    score= accuracy_score(target.values,y_pred)\n    print(\"Accuracy on {} set {}\".format(name,score))\n    return f1_score(target.values,y_pred,pos_label=1)\ndef train_predict(clf,X_train,y_train,X_test,y_test):\n    \n    train_classifier(clf,X_train,y_train)\n    print(\"F1 score for training set: {:.4f}\".format(predict_labels(clf,X_train,y_train,'Train')))\n    print(\"F1 score for test set: {:.4f}\".format(predict_labels(clf,X_test,y_test,'Test')))","378582ab":"from sklearn.naive_bayes import GaussianNB\nclf = GaussianNB()","41066265":"print(\"Naive Bayes \")\ntrain_predict(clf,feat_x_train,y_train,feat_x_test,y_test)","4315befb":"from sklearn.ensemble import RandomForestClassifier\nclassifierRand = RandomForestClassifier(n_estimators=25,criterion='entropy',random_state=25)\ntrain_predict(classifierRand,feat_x_train,y_train,feat_x_test,y_test)","28e08e83":"from sklearn.metrics import plot_confusion_matrix\nimport matplotlib.pyplot as plt","72c23f6f":"print(\"Naive Bayes\")\nclass_names=[1,0]\nprint(\"On Training\")\ndisp = plot_confusion_matrix(clf, feat_x_train, y_train,\n                                 display_labels=class_names,\n                                 cmap=plt.cm.Blues,\n                                 )\nprint(disp.confusion_matrix)\nplt.show()\nprint(\"On Testing\")\ndisp = plot_confusion_matrix(clf, feat_x_test, y_test,\n                                 display_labels=class_names,\n                                 cmap=plt.cm.Blues,\n                                 )\nprint(disp.confusion_matrix)\nplt.show()","6b78dab0":"print(\"Randomfores\")\nclass_names=[1,0]\nprint(\"On Training\")\ndisp = plot_confusion_matrix(classifierRand, feat_x_train, y_train,\n                                 display_labels=class_names,\n                                 cmap=plt.cm.Blues,\n                                 )\nprint(disp.confusion_matrix)\nplt.show()\nprint(\"On Testing\")\ndisp = plot_confusion_matrix(classifierRand, feat_x_test, y_test,\n                                 display_labels=class_names,\n                                 cmap=plt.cm.Blues,\n                                 )\nprint(disp.confusion_matrix)\nplt.show()","a8d57ccd":"# helper function","6d9358c7":"# Naive Bayes","7773a429":"# Ploting CM","f5ece221":"# Random Forest"}}