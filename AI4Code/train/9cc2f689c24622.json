{"cell_type":{"45feb031":"code","5e158b54":"code","cec4b34b":"code","825f2405":"code","f9ad3c84":"code","cc75ca6b":"code","7a6b551f":"code","dbeb6aa5":"code","b2479ddb":"code","f59e8716":"code","4e5e08ed":"code","c199e051":"code","46cb708e":"code","2b709b52":"code","69fd74c7":"code","f7669ba0":"code","17957934":"code","969db2a1":"code","e8400cb1":"code","6904e487":"markdown","5465da01":"markdown","6ceab48d":"markdown","838a454f":"markdown","b9309d09":"markdown","560eb9b5":"markdown","3c76228e":"markdown","63d13be8":"markdown","5902be19":"markdown","63946046":"markdown","037cd162":"markdown","253b79e3":"markdown","76cbc6e4":"markdown","0a44664e":"markdown","fbf67376":"markdown","883f208d":"markdown","39a9e733":"markdown","93d482b3":"markdown","ff3cbdb5":"markdown","aae1e608":"markdown","6b9d06df":"markdown","d4286f58":"markdown"},"source":{"45feb031":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        # print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5e158b54":"df = pd.read_csv('\/kaggle\/input\/CORD-19-research-challenge\/2020-03-13\/all_sources_metadata_2020-03-13.csv')\ndf.head()","cec4b34b":"print(\"Total number of articles:\", len(df))\nprint(\"Number of articles without full text:\", len(df[df[\"has_full_text\"].isnull() & df[\"doi\"].isnull()]))","825f2405":"df = df[[\"sha\", \"source_x\", \"title\", \"abstract\", \"doi\", \"has_full_text\"]]\ndf = df[df[\"has_full_text\"].notna() | df[\"doi\"].notna()]\nprint(len(df), \"articles left\")\ndf.head()","f9ad3c84":"print(\"Number of articles with missing abstracts:\", len(df[df[\"abstract\"].isnull()]))\nprint(\"Number of articles with missing titles:\", len(df[df[\"title\"].isnull()]))\nprint(\"Number of articles with missing title AND abstract:\", len(df[df[\"title\"].isnull() & df[\"abstract\"].isnull()]))","cc75ca6b":"df = df[df[\"abstract\"].notna() | df[\"title\"].notna()]\nprint(len(df), \"articles left\")","7a6b551f":"import string\ndef remove_punc_and_lower(s):\n    try:\n        if s:\n            return s.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))).lower()  # replacing punctuation w\/ space (and making lowercase)\n    except:\n        print(s)\n        \ndef doi_url(d): \n    return f'http:\/\/{d}' if d.startswith('doi.org') else f'http:\/\/doi.org\/{d}'\n\ndf['doi'] = df['doi'].apply(lambda s: doi_url(s) if pd.notnull(s) else s)\ndf['title'] = df['title'].apply(lambda s: remove_punc_and_lower(s) if pd.notnull(s) else s)\ndf['abstract'] = df['abstract'].apply(lambda s: remove_punc_and_lower(s) if pd.notnull(s) else s)","dbeb6aa5":"df.head(3)","b2479ddb":"symptoms_keywords = {\"symptom\", \"symptoms\", \"symptomatology\", \"semiology\", \"sign\", \"signs\", \"manifestation\"}","f59e8716":"def filter_keywords(row, keywords=symptoms_keywords):\n    text = \"\"\n    if pd.notnull(row[\"abstract\"]):\n        text += row[\"abstract\"]\n    if pd.notnull(row[\"title\"]):\n        text += row[\"title\"]\n    for word in text.split():\n        if word in keywords:\n            return True\n    return False","4e5e08ed":"m = df.apply(filter_keywords, axis=1)  # mask; true for rows that contain the keywords","c199e051":"df_symptoms = df[m]\ndf_symptoms.reset_index(drop=True, inplace=True)","46cb708e":"print(\"Number of relevant articles:\", len(df_symptoms))","2b709b52":"df_symptoms.head()","69fd74c7":"corpus = \" \".join(df_symptoms.title.values) + \" \".join(df_symptoms.title.values)","f7669ba0":"!pip install wordcloud\nfrom wordcloud import WordCloud, ImageColorGenerator\nimport matplotlib.pyplot as plt\n%matplotlib inline\n!pip install mpld3\nimport mpld3\nmpld3.enable_notebook()","17957934":"wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(corpus)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","969db2a1":"from nltk.corpus import stopwords\nstopwords_eng = set(stopwords.words(\"english\"))\ncorpus_without_stopwords = \" \".join([word for word in corpus.split() if word not in stopwords_eng])","e8400cb1":"from collections import Counter\nc = Counter(corpus_without_stopwords.split())\nc.most_common(10)\npd.DataFrame(c.most_common(10), columns=[\"word\", \"occurences\"])","6904e487":"The first objective is to get all the articles with their full text.","5465da01":"As you can see, the metadata file lists all articles in the dataset with some of the most relevant information; the \"sha\"-value lets us find\/load a specific article from the dataset.","6ceab48d":"Of the articles with full text access, we'll now check how many articles are missing abstracts and titles.","838a454f":"# Going through metadata to find articles relevant to Covid Symptoms","b9309d09":"The articles without full text won't be useful, so we'll drop these. We'll also drop columns we won't be using.","560eb9b5":"\/\/TODO","3c76228e":"## (short) EDA of the Metadata\n\nWe now take a quick look at the metadata of articles relevant to Covid-19 Symptoms.","63d13be8":"We can still use articles without abstracts in the metadata file as long as at least the title is present. It seems as though the articles without titles are exactly the articles with missing title AND abstract (these will not be useful at all). Let's drop those.","5902be19":"> _df_symptoms_ is now a dataframe of articles that contain keywords relevant to *symptoms*","63946046":"## Full-Text EDA","037cd162":"The \"title\" and \"abstract\" columns provide information about the article's content that we'll use to find relevant articles. Of course, without access to the full text, the article will not be of much help. We can get the full text if either the doi is present or has_full_text is True.","253b79e3":"## Most common words","76cbc6e4":"Great, we only have articles left that either have an abstract or title in the metadata file and whose full text is available. Let's clean the titles and abstracts!","0a44664e":"## Selecting Relevant Articles\n\nWe first define a list of keywords relating to \"Symptoms\" that are of interest.","fbf67376":"# \/\/TODO","883f208d":"## Cleaning and Filtering","39a9e733":"## Comorbidities","93d482b3":"The following function will now check whether one of the keywords is present in either the abstract or the title of an article.","ff3cbdb5":"The aim of this notebook is to give an overview of symptoms reported relating to Covid-19 from the given dataset. I re-use code partly from \n- https:\/\/www.kaggle.com\/salmanhiro\/covids-incubation-transmission-related-articles\n- https:\/\/www.kaggle.com\/dgunning\/browsing-the-papers-with-a-bm25-search-index\n- ","aae1e608":"## SciBERT etc.","6b9d06df":"# Using The Articles","d4286f58":"## Word Cloud"}}