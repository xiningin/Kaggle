{"cell_type":{"d1ce5a6b":"code","4b5a5c44":"code","66780457":"code","67c9c69c":"code","67b52d09":"code","2427677b":"code","27571ec3":"code","c39c227d":"code","85d7ac37":"code","ef61c913":"code","3cf5d206":"code","dbfe42e5":"code","d98670a9":"code","f48a5b08":"code","fc92b562":"code","4809c1a8":"code","a3e6d43b":"code","d5f9e17a":"code","0cf289c9":"code","1bf70c27":"code","41d0bfe6":"code","b8894c8f":"code","4f17dc46":"code","7fafd37f":"code","2e7fe2da":"code","2ef65e7d":"code","8e8c82bc":"code","c936a005":"code","c8b5aa3f":"code","176206f3":"code","89c6e0f6":"code","d2a97878":"code","623788f3":"code","0c0c39ca":"code","da10eb15":"code","a0647393":"code","db32e1eb":"code","923c5f7e":"code","d67af0e3":"code","17aa7a89":"code","7137c206":"code","d8989778":"code","702ab459":"code","b1ccc7d9":"code","3c4b78f1":"code","a65b13d0":"code","498c80e9":"code","cbb08e86":"code","ba43628a":"code","8d0a7ada":"code","b536b94b":"code","55128dd8":"code","2db57ad9":"code","814c8091":"code","8aa9a355":"code","0e40430d":"code","0092ad0d":"code","8d7b0ef8":"code","56b73fbf":"code","782f93cc":"code","b1586a20":"code","66b82797":"code","da059adf":"code","bd2c0475":"code","c0ab0497":"markdown","e721f929":"markdown","ffd7df30":"markdown","26bc9cae":"markdown","d1eba3ab":"markdown","9531eba0":"markdown","434b9924":"markdown","deb91daf":"markdown","9bbbf9f5":"markdown","1329caec":"markdown","81d89b8e":"markdown","c9483dec":"markdown","0392f760":"markdown","3826e214":"markdown","edfc9691":"markdown","099742bf":"markdown","f69718f8":"markdown","7888d10a":"markdown","ca7903d3":"markdown","3ca1f314":"markdown","65c3b71f":"markdown","f8d9566a":"markdown","e969bed5":"markdown","a67c0f07":"markdown","62801a8a":"markdown","ab8c1484":"markdown","08dfe80d":"markdown","7b26ef40":"markdown","578ce5d9":"markdown","3b113544":"markdown","456acc3d":"markdown","ca36a175":"markdown","c90766f5":"markdown","d3722345":"markdown","5884d0f3":"markdown","be88b2ce":"markdown","ca0f293d":"markdown","d77a372c":"markdown","1ab4eb3f":"markdown"},"source":{"d1ce5a6b":"import os \nimport numpy as np \nimport torch \nimport torchvision\nimport tarfile\nfrom torchvision.datasets.utils import download_url\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data.dataloader import DataLoader\nfrom torchvision.utils import make_grid\nimport torch.nn as nn \nimport torchvision.transforms as tt\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf","4b5a5c44":"with tarfile.open(\"..\/input\/cifar10\/cifar10.tar\",\"r:gz\") as tar :\n    tar.extractall(path=\".\/data\")\n\nDATA_DIR  = \".\/data\/cifar10\"\n\nprint(os.listdir(DATA_DIR))\nclasses = os.listdir(DATA_DIR+\"\/train\")\nprint(classes)","66780457":"dataset = ImageFolder(DATA_DIR+\"\/train\",transform=ToTensor())\ntest_dataset = ImageFolder(DATA_DIR+\"\/test\",transform =ToTensor())","67c9c69c":"dataset[0][0].shape","67b52d09":"def show_image(img,label): \n    print(\"Label: \",dataset.classes[label] , f\"{str(label)}\")\n    # we need to change the channels from 3 , 32 , 32 to 32 , 32 , 3\n    plt.imshow(img.permute(1,2,0))","2427677b":"show_image(*dataset[1520])","27571ec3":"#defining a fonction to split the training data into train and validation data\ndef split_indices(n,val_pct=0.1): \n    n_val = int(n*val_pct)\n    indexs = np.random.permutation(n)\n    return indexs[n_val:] , indexs[:n_val]","c39c227d":"val_pct = 0.2\ntrain_indices , val_indices = split_indices(len(dataset),val_pct)","85d7ac37":"batch_size = 100\ntrain_sampler = SubsetRandomSampler(train_indices)\ntrain_dl = DataLoader(dataset,batch_size,sampler=train_sampler)\nval_sampler = SubsetRandomSampler(val_indices)\nval_dl = DataLoader(dataset,batch_size, sampler = val_sampler)\n\ntest_dl = DataLoader(test_dataset,shuffle=True, batch_size = batch_size)","ef61c913":"def show_batch(dl): \n    for images,lables in dl: \n        fig, ax = plt.subplots(figsize = (10,10))\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.imshow(make_grid(images[:19],10).permute(1,2,0))\n        break\n","3cf5d206":"show_batch(train_dl)","dbfe42e5":"# defining fonctions for mouving the data and the model into the GPU\ndef get_default_device():\n    if torch.cuda.is_available(): \n        return torch.device(\"cuda\")\n    else : \n        return toch.device(\"cpu\")\n    \ndef to_device(device,data):\n    if isinstance(data,(list,tuple)):\n        return  [to_device(device,x) for x in data]\n    else :\n        return data.to(device,non_blocking=True)\n    \nclass DeviceDataloader():\n    def __init__(self,device,data):\n        self.dataloader = data\n        self.device = device \n    def __iter__(self):\n        for batch in self.dataloader:\n            yield to_device(self.device,batch)\n    def __len__(self):\n        return len(self.dataloader)\n    \n    \ndevice = get_default_device()\ntrain_dl = DeviceDataloader(device,train_dl)\nval_dl = DeviceDataloader(device,val_dl)\ntest_dl = DeviceDataloader(device,test_dl)","d98670a9":"# helper fonction that calculate the loss for every batch \n\ndef loss_batch(model,x_batch,y_batch,loss_fn,optim=None,metric=None): \n    output = model(x_batch)\n    loss = loss_fn(output,y_batch)\n    if optim is not None: \n        loss.backward()\n        optim.step()\n        optim.zero_grad()\n    \n    metric_val = None \n    if metric is not None:\n        metric_val = metric(output,y_batch)\n    \n    return loss.item(), len(x_batch), metric_val\n\n\n# helper fonction that evaluate the model on the validation set \ndef evaluate(model,valid_dl , loss_fn , metric=None):\n    with torch.no_grad():\n        results = [loss_batch(model,x_batch,y_batch,loss_fn,metric=metric) for x_batch , y_batch in valid_dl]\n        losses, nums, metrics =  zip(*results)\n        \n        total = np.sum(nums)\n        \n        avg_loss = np.sum(np.multiply(losses,nums)) \/ total\n\n        avg_metric = None\n        if metric is not None : \n            avg_metric = np.sum(np.multiply(metrics,nums))\/total\n            \n    return avg_loss,total,avg_metric\n\ndef train(model,train_dl, valid_dl , loss_fn , optim=None ,lr=0.001, metric=None, epochs=20):\n    opt = optim\n    if optim is None: \n        opt = torch.optim.Adam(model.parameters(),lr=lr)\n    train_losses , valid_losses, valid_metrics = [],[],[]\n    \n    for epoch in range(1,epochs+1):\n        model.train()\n        for x_batch, y_batch in train_dl:\n            train_loss,_,_ = loss_batch(model,x_batch,y_batch,loss_fn,optim,metric)\n\n        model.eval()\n        results = evaluate(model,valid_dl,loss_fn,metric=metric)\n        valid_loss, total, valid_metric = results\n        train_losses.append(train_loss)\n        valid_losses.append(valid_loss)\n        valid_metrics.append(valid_metric)\n        \n        if metric is None : \n            print(f\"Epoch : {epoch}\/{epochs}, train loss : {train_loss} validation loss : {valid_loss}\")\n        else : \n            print(f\"Epoch : {epoch}\/{epochs}, train loss : {train_loss} validation loss : {valid_loss} , {metric.__name__} : {valid_metric}\")\n        \n    return valid_losses, train_losses, valid_metrics\n    \ndef accuracy(output,targets): \n    _,preds = torch.max(output,dim=1)\n    \n    return torch.sum(preds==targets).item()\/ len(preds)\n\n\ndef plot_metric(metrics): \n    val_loss,_,val_metric =metrics  \n    plt.plot(val_loss,\"-x\",label=\"Validation Loss\")\n    plt.plot(val_metric,\"-o\",label=\"Validation Metric\")\n    plt.xlabel(\"epoch\")\n#     plt.ylabel(\"accuracy\")\n    plt.legend()\n    plt.show()\n    \n# using the corss entropy as a lost fonction\nloss_fn = nn.functional.cross_entropy\n    ","f48a5b08":"class LinearNN(nn.Module): \n    def __init__(self):\n        super(LinearNN,self).__init__()\n        self.lin = nn.Linear( 3*32*32 ,10)\n        \n    def forward(self,x): \n        x = x.reshape(-1,32*32*3)\n        out = self.lin(x)\n        return out \nlin_model = LinearNN()\nto_device(device,lin_model)","fc92b562":"for data,target in train_dl:\n    output= lin_model(data)\n    _,preds = torch.max(output,dim=1)\n    acc = torch.sum(preds==target).item()\/len(data)\n    print(acc)\n    break\n    ","4809c1a8":"EPOCHS= 20\nlr = 0.001\noptim = torch.optim.Adam(lin_model.parameters(),lr = lr)\n# history = train(lin_model,train_dl,val_dl,loss_fn,optim,metric=accuracy,)\n","a3e6d43b":"# plot_metric(history)","d5f9e17a":"learning_rate=0.01\noptim = torch.optim.SGD(lin_model.parameters(),lr = learning_rate)\n# history = train(lin_model,train_dl,val_dl,loss_fn,optim,metric=accuracy,)\n","0cf289c9":"# plot_metric(history)","1bf70c27":"EPOCHS= 20\nlearning_rate=0.1\noptim = torch.optim.SGD(lin_model.parameters(),lr = learning_rate)\n# history = train(lin_model,train_dl,val_dl,loss_fn,optim,metric=accuracy,epochs=EPOCHS)\n","41d0bfe6":"# plot_metric(history)","b8894c8f":"test_loss , _, test_metric = evaluate(lin_model,test_dl , loss_fn , metric = accuracy)\nprint(f\"Test loss : {test_loss} , Test accuracy : {test_metric}\")","4f17dc46":"class ANN(nn.Module):\n    def __init__(self):\n        super(ANN,self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu = nn.Sequential(\n            nn.Linear(3*32*32, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Linear(256, 10),\n        )\n    def forward(self,x):\n        x = self.flatten(x)\n        out = self.linear_relu(x)\n        return out\nann_model = ANN()\nto_device(device,ann_model)","7fafd37f":"for data,target in train_dl:\n    output= ann_model(data)\n    _,preds = torch.max(output,dim=1)\n    acc = torch.sum(preds==target).item()\/len(data)\n    print(acc)\n    break\n    ","2e7fe2da":"EPOCHS= 20\nlearning_rate = 0.0001\noptim = torch.optim.Adam(ann_model.parameters(),lr=learning_rate)\nloss_fn = nn.functional.cross_entropy\n# history = train(ann_model,train_dl,val_dl,loss_fn,optim,metric=accuracy,epochs=EPOCHS)\n","2ef65e7d":"print(\"Plotting the Metric and Loss of the Artificial Neural Network\")\nprint(f\"Optimizer : Adam , lr = {learning_rate}\")\n# plot_metric(history)\n","8e8c82bc":"EPOCHS= 20\nlearning_rate = 0.001\noptim = torch.optim.SGD(ann_model.parameters(),lr=learning_rate)\nloss_fn = nn.functional.cross_entropy\nhistory = train(ann_model,train_dl,val_dl,loss_fn,optim,metric=accuracy,epochs=EPOCHS)\n","c936a005":"print(\"Plotting the Metric and Loss of the Artificial Neural Network\")\nprint(f\"Optimizer : SGD , lr = 0.001\")\nplot_metric(history)","c8b5aa3f":"test_loss , _, test_metric = evaluate(ann_model,test_dl , loss_fn , metric = accuracy)\nprint(f\"Test loss : {test_loss} , Test accuracy : {test_metric}\")","176206f3":"class ANN(nn.Module):\n    def __init__(self):\n        super(ANN,self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu = nn.Sequential(\n            nn.Linear(3*32*32, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Linear(256,128),\n            nn.ReLU(),\n            nn.Linear(128,64),\n            nn.ReLU(),\n            nn.Linear(64, 10),\n        )\n    def forward(self,x):\n        x = self.flatten(x)\n        out = self.linear_relu(x)\n        return out\nann_model_ = ANN()\nto_device(device,ann_model_)","89c6e0f6":"EPOCHS= 20\nlearning_rate = 0.001\noptim = torch.optim.Adam(ann_model_.parameters(),lr=learning_rate)\nloss_fn = nn.functional.cross_entropy\nhistory = train(ann_model_,train_dl,val_dl,loss_fn,optim,metric=accuracy,epochs=EPOCHS)","d2a97878":"print(\"Plotting the Metric and Loss of the Artificial Neural Network\")\nprint(f\"Optimizer : Adam , lr = 0.001\")\nplot_metric(history)","623788f3":"test_loss , _, test_metric = evaluate(ann_model,test_dl , loss_fn , metric = accuracy)\nprint(f\"Test loss : {test_loss} , Test accuracy : {test_metric}\")\n","0c0c39ca":"class CNN(nn.Module): \n    def __init__(self):\n        super(CNN,self).__init__()\n        self.flatten = nn.Flatten()\n        self.conv_relu_maxPol2d_stack = nn.Sequential(\n            nn.Conv2d(3,16,kernel_size = 3, stride = 1, padding = 1), \n            nn.ReLU(), \n            nn.MaxPool2d(2,2), #output : bs x 16 x 16 x 16\n\n            nn.Conv2d(16,16,kernel_size = 3, stride = 1, padding = 1), \n            nn.ReLU(), \n            nn.MaxPool2d(2,2), #output : bs x 16 x 8 x 8 (8 because of the max-pooling 2*2)\n\n            nn.Conv2d(16,16,kernel_size = 3, stride = 1, padding = 1), \n            nn.ReLU(), \n            nn.MaxPool2d(2,2), #output : bs x 16 x 4 x 4 (8 because of the max-pooling 2*2)\n\n            nn.Conv2d(16,16,kernel_size = 3, stride = 1, padding = 1), \n            nn.ReLU(), \n            nn.MaxPool2d(2,2),#output : bs x 16 x 2 x 2 (8 because of the max-pooling 2*2)\n\n\n            nn.Conv2d(16,16,kernel_size = 3, stride = 1, padding = 1), \n            nn.ReLU(), \n            nn.MaxPool2d(2,2), #output : bs x 16 x 1 x 1 (8 because of the max-pooling 2*2)\n        )\n        \n        self.lin = nn.Linear(16,10)  #output bs x 10\n    def forward(self,x):\n        out = self.conv_relu_maxPol2d_stack(x)\n        out = self.flatten(out)\n        out = self.lin(out)\n        return out\n    \n\ncnn_model = CNN()\nto_device(device,cnn_model)","da10eb15":"for data,target in train_dl:\n    output= cnn_model(data)\n    _,preds = torch.max(output,dim=1)\n    acc = torch.sum(preds==target).item()\/len(data)\n    print(acc)\n    break\n    ","a0647393":"\nEPOCHS= 20\nlearning_rate = 0.001\noptim = torch.optim.Adam(cnn_model.parameters(),lr=learning_rate)\nloss_fn = nn.functional.cross_entropy\nhistory = train(cnn_model,train_dl,val_dl,loss_fn,optim,metric=accuracy,epochs=EPOCHS)\n","db32e1eb":"print(f\"Plotting the Validation Loss and the Validation Accuracy for the CNN\")\nprint(f'Optim : Adam , Lr = 0.001')\nplot_metric(history)\n","923c5f7e":"EPOCHS= 20\nlearning_rate = 0.1\noptim = torch.optim.Adam(cnn_model.parameters(),lr=learning_rate)\nloss_fn = nn.functional.cross_entropy\nhistory = train(cnn_model,train_dl,val_dl,loss_fn,optim,metric=accuracy,epochs=EPOCHS)\n","d67af0e3":"print(f\"Plotting the Validation Loss and the Validation Accuracy for the CNN\")\nprint(f'Optim : Adam , Lr = 0.1')\nplot_metric(history)\n","17aa7a89":"test_loss , _, test_metric = evaluate(cnn_model,test_dl , loss_fn , metric = accuracy)\nprint(f\"Test loss : {test_loss} , Test accuracy : {test_metric}\")\n","7137c206":"class CNN(nn.Module): \n    def __init__(self):\n        super(CNN,self).__init__()\n        self.flatten = nn.Flatten()\n        self.conv_relu_maxPol2d_stack = nn.Sequential(\n            nn.Conv2d(3,32,kernel_size = 3, stride = 2, padding = 1), \n            nn.ReLU(), \n#             nn.MaxPool2d(2,2), #output : bs x 16 x 16 x 16\n\n            nn.Conv2d(32,64,kernel_size = 3, stride = 2, padding = 1), \n            nn.ReLU(), \n#             nn.MaxPool2d(2,2), #output : bs x 16 x 8 x 8 (8 because of the max-pooling 2*2)\n\n            nn.Conv2d(64,128,kernel_size = 3, stride = 2, padding = 1), \n            nn.ReLU(), \n#             nn.MaxPool2d(2,2), #output : bs x 16 x 4 x 4 (4 because of the max-pooling 2*2)\n\n            nn.Conv2d(128,256,kernel_size = 3, stride = 2, padding = 1), \n            nn.ReLU(), \n#             nn.MaxPool2d(2,2),#output : bs x 16 x 2 x 2 (2 because of the max-pooling 2*2)\n\n\n#             nn.Conv2d(256,256,kernel_size = 3, stride = 2, padding = 1), \n#             nn.ReLU(), \n#             nn.MaxPool2d(2,2), #output : bs x 16 x 1 x 1 (1 because of the max-pooling 2*2)\n        )\n        \n        self.lin1 = nn.Linear(256*2*2,128)  \n        self.lin2 = nn.Linear(128,10) \n    def forward(self,x):\n        out = self.conv_relu_maxPol2d_stack(x)\n        out = self.flatten(out)\n        out = self.lin1(out)\n        out = nn.functional.relu(out)\n        out = self.lin2(out)\n        return out\n    \n\ncnn_model = CNN()\nto_device(device,cnn_model)","d8989778":"EPOCHS = 20\nlearning_rate = 0.01\noptim = torch.optim.Adam(cnn_model.parameters(),lr = learning_rate)\nhistory = train(cnn_model, train_dl , val_dl ,loss_fn ,  metric = accuracy , optim = optim , epochs= EPOCHS)\n","702ab459":"\nprint(f\"Loss and Accuracy for the CNN \")\nprint(f\"Optimizer : Adam , Learning rate : {learning_rate}\")\nplot_metric(history)","b1ccc7d9":"# the first set is for the means and the second for the STDs\nstats = ((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010))\ntrain_transforms = tt.Compose([tt.RandomCrop(32,padding=4,padding_mode=\"reflect\"),\n                              tt.RandomHorizontalFlip(),\n                               tt.ToTensor(), \n                               tt.Normalize(*stats)])\ntest_transforms = tt.Compose([tt.ToTensor(),tt.Normalize(*stats)])\n\ntrain_ds = ImageFolder(DATA_DIR+\"\/train\",train_transforms)\ntest_ds = ImageFolder(DATA_DIR+\"\/test\",test_transforms)","3c4b78f1":"batch_size = 256\n\ntrain_indices , valid_indices =  split_indices(len(train_ds),0.3)\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(valid_indices)\n\ntrain_dl = DataLoader(train_ds,batch_size , num_workers=8,pin_memory=True,sampler = train_sampler)\ntest_ds =DataLoader(test_ds,batch_size , shuffle=True, num_workers=8,pin_memory=True)\n","a65b13d0":"def show_batch(dl): \n    for images , labels in dl: \n        fig , ax = plt.subplots(figsize=(16,16))\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.imshow(make_grid(images[:100],10).permute(1,2,0))\n        break","498c80e9":"show_batch(train_dl)","cbb08e86":"def conv_2d(ni,nf,stride=1,ks =3): \n    return nn.Conv2d(in_channels=ni,out_channels=nf,kernel_size=ks, stride=stride,padding=ks\/\/2,bias=False )\n\ndef batchNorm_relu_conv(ni,nf):\n    return nn.Sequential(nn.BatchNorm2d(ni),nn.ReLU(), conv_2d(ni,nf))\n\n# this fonction is for a residual block \nclass ResidualBlock(nn.Module): \n    def __init__(self,ni,nf,stride=1): \n        super().__init__()\n        self.bn= nn.BatchNorm2d(ni)\n        self.conv1 = conv_2d(ni,nf,stride)\n        self.conv2 = batchNorm_relu_conv(nf,nf)\n        # in case that we are in the second or third block \n        self.shortcut = lambda x : x\n        if ni != nf:  \n            # case of first block of each group \n            # this is to handle the special case where the input and output channels are not the same so we create a layer to set the same dimensions \n            self.shortcut = conv_2d(ni,nf,stride, 1)\n    def forward(self,x): \n        x = nn.functional.relu(self.bn(x),inplace=True)\n        # r for residual et c'est le input qu'on va ajouter au output (il sera soit un output du conv (au cas de first block) soit x tel qu'il est )\n        # soit on utilise un conv pour ajuster les dimensions (1er block de chaque groupe) soit les inputs reste les meme\n        r = self.shortcut(x)\n        x = self.conv1(x)\n        x = self.conv2(x) * 0.2\n        # we multiply by 0.2 to scale the output and get better results\n        # for the output we perform the addition of X + X if the in_features and out_feature were the same (case of 2nd and 3rd block)\n        #  or we perform the addition of the output of conv2d(nf,nf) with X (X is the output of the conv2d(nf,nf))\n        return x.add_(r)\n    \n\n\n# fonction that create a group for us that contains n_blocks of blocks (in_features==ni, out_features ==nf)\ndef make_group(n_blocks,ni,nf,stride):\n    start = ResidualBlock(ni,nf,stride)\n    rest = [ResidualBlock(nf,nf) for j in range(1,n_blocks)]\n    return [start]+ rest\n    \n    \nclass Flatten(nn.Module):\n    def __init__(self): super().__init__()\n    #x.view(x.size(0),-1) transform the shape from [256,3,32,32] to [256,3072]\n    \n    def forward(self,x):  return x.view(x.size(0),-1)\n\n","ba43628a":"class WideResNet(nn.Module): \n    def __init__(self,n_groups,n_blocks,n_classes,k=1,n_start=16): \n        super().__init__()\n        layers=[conv_2d(3,n_start)]\n        n_channels=[n_start]\n        \n        for j in range(n_groups): \n            # increasing the number of channels (according to the scale k) each time we create a new group\n            n_channels.append(n_start * (2**j) *k)\n            stride = 2 if j>0 else 1\n            # pour le start et end des nombre de channels on donne la case actuel (start) et la case suivant calculer pr\u00e9cedement (n_channels.append(n_start * (2**j) *k)) \n            layers += make_group(n_blocks, n_channels[j] , n_channels[j+1],stride)\n\n        # after creating all the groups and theire blocks we will add the layer of the end wich are the batchNorm , ReLu , AdaptiveAvgPool , Flatten and the Linear Model \n        \n        layers += [nn.BatchNorm2d(n_channels[-1]),\n                   nn.ReLU(inplace=True),\n                   nn.AdaptiveAvgPool2d(1),\n                   Flatten(),\n                   nn.Linear(n_channels[-1],n_classes)]\n        #print(layers)\n        self.features = nn.Sequential(*layers)\n        print(n_channels)\n\n    def forward(self,x): \n        return self.features(x)\n\n\ndef wrn22(): \n    return WideResNet(3,3,10,k=6)\n\nWRN22 = wrn22()\nto_device(device,WRN22)\n\n\n    \n        \n        \n        ","8d0a7ada":"for images , labels in train_dl : \n    print(images.shape)\n    out = WRN22(images)\n    print(out.shape)\n    break","b536b94b":"!pip install fastai==1.0.61\nimport fastai","55128dd8":"from fastai.basic_data import DataBunch\nfrom fastai.train import Learner \nfrom fastai.metrics import accuracy","2db57ad9":"train_dataset, valid_dataset = torch.utils.data.random_split(train_ds,[35000,15000])","814c8091":"batch_size = 100\ndata = DataBunch.create(train_dataset,valid_dataset,test_ds=test_ds, bs=batch_size,path=\".\/data\/cifar10\")\nlerner = Learner(data,WRN22,loss_func=torch.nn.functional.cross_entropy,metrics=[accuracy])\nlerner.clip = 0.1\n#.clip att is used to limit the values of the gradients descent in range (-0.1,0.1) and this for preventing the undeserible changes in the parameters ","8aa9a355":"lerner.lr_find()","0e40430d":"lerner.recorder.plot()","0092ad0d":"learning_rate =  3*1e-02\nlearning_rate","8d7b0ef8":"# wd it's the weight decade it provide us to have a larger values of the weights so it change the metric to : metric = metric + wd * sum(weights^2)\n# as the weights are modified each time so we dont want to have larger scale of the weights so we use the wd parameter\nEPOCHS = 15\nlerner.fit_one_cycle(EPOCHS,learning_rate,wd=1e-04,cbs=[ShowGraphCallback()])\n","56b73fbf":"print(f\"Plot the changing of the LR while the training\")\nlerner.recorder.plot_lr()","782f93cc":"print(f\"Validation and Train losses changing\")\nlerner.recorder.plot_losses()","b1586a20":"lerner.recorder.plot_metrics()","66b82797":"output , test_data = lerner.get_preds()\nWRN_acc = accuracy(output,test_data)\nprint(f\"The accuracy on the testset : {WRN_acc}\")","da059adf":"torch.save(WRN22.state_dict(),\"cifar10-wrn22.pth\")","bd2c0475":"r","c0ab0497":"for the training we are going to use FastAI which contains built-in fonctions to train the model\n\nfor the Learning rate we are going to use the 1-Cycle policy wich change the LR using Shuddeling\n  \n  the 1-cycle choose a small value of the LR and starting increasing it to get 10 times the start value, and it will decrease it to the minimum to find the best value following the model behavior","e721f929":"# WideResNet22","ffd7df30":"Using The SGD Optimizer and changing the Learning Rate","26bc9cae":"the DataBunch get the train and validation dataset and create a dataloaders based on the datasets and contains a built-in fonctions to check if a GPU is availabl and if \"Yes\" so it will move the data to the GPU memory\n\nThe learner is the fit fonction that imrpoves the LR and use also Adam Optimizer by default","d1eba3ab":"### Training","9531eba0":"Changing the Learning Rate to 0.1 with the Adam Optim","434b9924":"# Saving the Model","deb91daf":"## Convolution Neural Network","9bbbf9f5":"we are going to change the optimizer to the Stochastic Gradient Descent with lr= 0.01","1329caec":"# Import the pckages","81d89b8e":"**Now we are going to improve the model for more then 90% using ResNets, Regularization and Data Augmentation in PyTorch**","c9483dec":"# Training the Model ","0392f760":"Fastai provides a fonction to search the good LR : learner.lr_find()","3826e214":"We will create another ANN with more layers and see the diffrence \n","edfc9691":"to use a GPU and move the data to it we will define a couple of helpers methods\nde pr\u00e9f\u00e9rence on utilise une classe pour deplacer le dataloaders (train and test) a la memoire du GPU \n*DeviceDataLoader* \n   \n   \n   \n   la class utilise une method __iter__ qui fait deplacer les dataloaders par batch, a chaque itt\u00e9ration on fait deplacer les batches dans la Ram du GPU et on le passe au model.\nla fonction __len__ retourn length du dataloader","099742bf":"### Training","f69718f8":"Loading the training and the test dataset","7888d10a":"the above graph show us the diffrents values of the LR and the changing of the Losses \n\nso from the graph we can conclude that we take a LR = 4*1e-02 ","ca7903d3":"Now let's create the Dataloaders and defining the batch size \n\n*num_workers* is to tel pytorch to use multiple CPU cors to load the images in parallel\nand the *pin_memory* it's used to avoid repeated memory allocation ","3ca1f314":"we see that we have a better results then the CNN and we got a bigger accuracy \n\nnote that we dont have overfitting because the validaion loss is decreasing and this because of the data augmentation and regularization methods we did earlier","65c3b71f":"### Another ANN with More Layers","f8d9566a":"we will use the batch normalization:\n\nas we have multiple layers in our ResNet so the backpropagation will be very slow because we will update all the weights for each layer, (tens of layers so tounsounds of weights), the weights update mus be simultaniously\n    \n    \nthe batchnorm is a technique that helps to coordinate the update of multiple layers in the network , and consequently speed-up the training process and this by standardized the inputs of the layers each time we update the weights","e969bed5":"### Testing","a67c0f07":"\n# Improve the model to 90% accuracy ","62801a8a":"### Model Creation","ab8c1484":"### Testing","08dfe80d":"###  Training","7b26ef40":"We will create a fonction \"show_image\" to visualize samples of the training dataset","578ce5d9":"### Another CNN ","3b113544":"we see that the outputs shape becomes [256,10]","456acc3d":"## Artificial  Neural Network","ca36a175":"we are going to use multiple technics to performe our data such that we will have more inputs to the model:\n1. first we will normalize our data and that by substracting the mean and deviding by the std\n2. cropp the images: doing a padding of 4 pixels (black pixels) then we take the a 32 x 32 image, and this for giving new inputs to the images\n3. Horizontal flip of 50%\n \nall these technics will help us to perform our dataset and also giving the possibility to our model to train on new images that he might get as a new value to predict.","c90766f5":"now we are going to train the model using the methon **.fit_one_cycle()**","d3722345":"## Logistic Regression","5884d0f3":"we are going to use the WideResNet22 model which contains 22 convolution layers structured in 3 groups each groupe has 3 blocks , each one contains  Conv2d , BatchNormalization (came after the conv2d layer and before the non-linearity)  and ReLU layers.\n\nthe result of each groupe is feeded back to the same group as input after passing it to a conv2d layer and given to the next groupe as input data.\n\nin the first block of each groupe we use a Conv2d layer 1x1 just to increase the number of channels to the desired number\n \n \nHere is some explanation about the WideResNet22\n\n<img src=\"https:\/\/hackernoon.com\/_next\/image?url=https%3A%2F%2Fcdn.hackernoon.com%2Fimages%2FMmojudC2DTdkMmqzrbExkyPHxet2-0q242efm.jpg&w=1920&q=75\" width=\"500px\" height=\"650px\">\n\n","be88b2ce":"we are using w stride =1 and a padding=1 \nour image has 3 x 32 x 32 and we will reduce it to 16 x 16 x 16 \nthen 16 x 8 x 8 , 16 x 4 x 4\nwe will use the Max-pooling wich halves the dimension\n","ca0f293d":"### Model Creation","d77a372c":"#  Models\n\nWe are going to create some helper fonctions for the training and the evaluation of the model on the testset and validation set","1ab4eb3f":"Fonction that visualize a batch of images "}}