{"cell_type":{"fb649f35":"code","edde767e":"code","e1d7e9d6":"code","f45f1aaa":"code","300a051f":"code","09e0aa60":"code","13a3285d":"code","2fd5ad14":"code","5191055a":"code","cac93205":"code","beab23fb":"code","89ecacf9":"code","5c1612e2":"code","0e91433e":"code","5244da17":"code","00cbce13":"code","1d88190e":"code","c6ea5509":"code","486e33ed":"code","0b32e621":"code","d19daf37":"code","614754f0":"code","b4bc51e7":"code","c5c0a983":"code","1dddef8b":"code","6bb10243":"code","02c6cfd2":"code","f22c7ec6":"code","f1495e25":"code","88ae493a":"code","396c997b":"code","4f077f95":"code","56c993aa":"code","8599beee":"code","a1501871":"code","58c8ff66":"code","c43ed19d":"code","2ce81d08":"code","993047e6":"code","0bb8031d":"code","5342d8bb":"code","cffc8335":"code","0b374034":"code","f35f1969":"code","78780ba7":"code","045529c4":"code","9f213765":"code","3c556b79":"code","e840daa2":"code","549f9627":"code","a5ae21df":"code","562b0bb3":"code","6c651984":"code","11e63375":"code","752732f9":"code","5caf3ca4":"code","1b926fb2":"code","2ccf8c29":"code","d47bd16c":"code","dc0d2603":"code","39de7650":"code","012fc7b9":"code","ba57113c":"code","7ad2c4d5":"code","3989614a":"code","53aa87cc":"markdown","82a73f0d":"markdown","04d44641":"markdown","55d0141e":"markdown","61c82b0b":"markdown","bac9ed6b":"markdown","0415e3cd":"markdown","b86adc73":"markdown","52be8fa3":"markdown","74a0d83d":"markdown","e057003e":"markdown","aecfdfbc":"markdown","6b09a474":"markdown","54a06c3f":"markdown","911376f6":"markdown","5def0558":"markdown","fa3f72c5":"markdown","1d0e1ba4":"markdown","94496de1":"markdown","3dc32ea2":"markdown","7a2ebd97":"markdown","8391f343":"markdown","39f4a96a":"markdown"},"source":{"fb649f35":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","edde767e":"df = pd.read_csv(\"..\/input\/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\ndf.head()","e1d7e9d6":"df.shape","f45f1aaa":"df.columns","300a051f":"df.shape","09e0aa60":"df.head()","13a3285d":"df['Attrition'] = df['Attrition'].map(lambda x: 1 if x=='Yes' else 0)","2fd5ad14":"sns.countplot(df.dtypes)","5191055a":"sns.pairplot(df)","cac93205":"sns.set(rc={'figure.figsize': (18,8)})\nsns.heatmap(df.corr(),vmin=-1.0,vmax=1.0,cmap='GnBu')","beab23fb":"df.columns","89ecacf9":"sns.set(rc={'figure.figsize': (18,8)})\nsns.violinplot(df['Attrition'],df['TotalWorkingYears'],hue=df['Gender'], split=True)","5c1612e2":"sns.set(rc={'figure.figsize': (18,6)})\nsns.countplot(df['YearsAtCompany'],palette='viridis')","0e91433e":"sns.set(rc={'figure.figsize': (18,5)})\nsns.countplot(df['JobRole'],palette='inferno',)","5244da17":"sns.set(rc={'figure.figsize': (18,8)})\nsns.swarmplot(df['Attrition'], df['TotalWorkingYears'])","00cbce13":"sns.set(rc={'figure.figsize': (18,8)})\nsns.swarmplot(df['Attrition'], df['MonthlyIncome'], hue=df['MaritalStatus'], palette='inferno')","1d88190e":"df.columns","c6ea5509":"sns.set(rc={'figure.figsize': (18,6)})\nsns.kdeplot(df['YearsSinceLastPromotion'],shade=True)\nsns.kdeplot(df['YearsInCurrentRole'],shade=True)\nsns.kdeplot(df['YearsWithCurrManager'],shade=True)","486e33ed":"sns.set(rc={'figure.figsize': (18,8)})\nsns.lmplot('YearsAtCompany','MonthlyIncome',data=df,hue='Attrition')","0b32e621":"df.head(5)","d19daf37":"df.info()","614754f0":"categorical = []\nfor column in df:\n    if df[column].dtype == 'object':\n        categorical.append(column)\ncategorical","b4bc51e7":"cat = pd.DataFrame(df.apply(pd.Series.nunique, axis = 0))\ncategorical = list(cat[cat[0]<=9].sort_values(0).reset_index()['index'])\ncategorical","c5c0a983":"data = pd.get_dummies(df, columns=categorical, drop_first=True)","1dddef8b":"data.head(5)","6bb10243":"sns.heatmap(data.isna())","02c6cfd2":"y = data['Attrition_1']\nX = data.drop(['Attrition_1'],axis=1)","f22c7ec6":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1210)","f1495e25":"from imblearn.over_sampling import SMOTE\nfrom sklearn.preprocessing import StandardScaler","88ae493a":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\nsmote = SMOTE(ratio='minority', random_state=1210)\nX_train_sm, y_train_sm = smote.fit_sample(X_train, y_train)","396c997b":"from sklearn.tree import DecisionTreeClassifier","4f077f95":"clf = DecisionTreeClassifier(random_state=1210)","56c993aa":"clf.fit(X_train_sm, y_train_sm)","8599beee":"from sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score","a1501871":"def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n    '''\n    print the accuracy score, classification report and confusion matrix of classifier\n    '''\n    if train:\n        '''\n        training performance\n        '''\n        pred = clf.predict(X_train)\n        \n        print(\"Train Result:\\n\")\n        print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_train, pred)))\n        print(\"Classification Report: \\n {}\\n\".format(classification_report(y_train, pred)))\n        print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_train, pred)))\n\n        res = cross_val_score(clf, X_train, y_train.ravel(), cv=10, scoring='accuracy')\n        print(\"Average Accuracy: \\t {0:.4f}\".format(np.mean(res)))\n        print(\"Accuracy SD: \\t\\t {0:.4f}\".format(np.std(res)))\n        print(\"AUROC Score: \\n {}\\n\".format(roc_auc_score(y_train, pred)))\n        \n        \n    elif train==False:\n        '''\n        test performance\n        '''\n        pred = clf.predict(X_test)\n        \n        print(\"Test Result:\\n\")        \n        print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_test, pred)))\n        print(\"Classification Report: \\n {}\\n\".format(classification_report(y_test, pred)))\n        print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_test, pred)))\n        print(\"AUROC Score: \\n {}\\n\".format(roc_auc_score(y_test, pred)))    \n        ","58c8ff66":"print_score(clf, X_train_sm, y_train_sm, X_test, y_test, train=True)","c43ed19d":"print_score(clf, X_train, y_train, X_test, y_test, train=False)","2ce81d08":"from sklearn.ensemble import BaggingClassifier","993047e6":"bag_clf = BaggingClassifier(base_estimator=clf, n_estimators=5000,\n                            bootstrap=True, n_jobs=-1, random_state=1210)","0bb8031d":"bag_clf.fit(X_train_sm, y_train_sm.ravel())","5342d8bb":"print_score(bag_clf, X_train_sm, y_train_sm, X_test, y_test, train=True)\nprint_score(bag_clf, X_train_sm, y_train_sm, X_test, y_test, train=False)","cffc8335":"from sklearn.ensemble import RandomForestClassifier","0b374034":"rf_clf = RandomForestClassifier(n_estimators=500,class_weight={0:1,1:5})","f35f1969":"rf_clf.fit(X_train_sm, y_train_sm.ravel())","78780ba7":"print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(rf_clf, X_train, y_train, X_test, y_test, train=False)","045529c4":"pd.Series(rf_clf.feature_importances_, \n         index=X.columns).sort_values(ascending=False).plot(kind='bar', figsize=(18,6));","9f213765":"from sklearn.ensemble import AdaBoostClassifier","3c556b79":"ada_clf = AdaBoostClassifier(n_estimators=100, learning_rate=0.01)","e840daa2":"ada_clf.fit(X_train_sm, y_train_sm.ravel())","549f9627":"print_score(ada_clf, X_train, y_train, X_test, y_test, train=True)\nprint()\nprint_score(ada_clf, X_train, y_train, X_test, y_test, train=False)","a5ae21df":"ada_rf_clf = AdaBoostClassifier(RandomForestClassifier(n_estimators=500,class_weight={0:1,1:5}))\nada_rf_clf.fit(X_train_sm, y_train_sm.ravel())","562b0bb3":"print_score(ada_rf_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(ada_rf_clf, X_train, y_train, X_test, y_test, train=False)","6c651984":"from sklearn.ensemble import GradientBoostingClassifier","11e63375":"gbc_clf = GradientBoostingClassifier(n_estimators=1000,learning_rate=0.01)\ngbc_clf.fit(X_train_sm, y_train_sm)","752732f9":"print_score(gbc_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(gbc_clf, X_train, y_train, X_test, y_test, train=False)","5caf3ca4":"import xgboost as xgb","1b926fb2":"xgb_clf = xgb.XGBClassifier()\nxgb_clf.fit(X_train, y_train.ravel())","2ccf8c29":"warnings.filterwarnings(\"ignore\")\nprint_score(xgb_clf, X_train_sm, y_train_sm, X_test, y_test, train=True)\nprint_score(xgb_clf, X_train_sm, y_train_sm, X_test, y_test, train=False)","d47bd16c":"from lightgbm import LGBMClassifier","dc0d2603":"lgbm = LGBMClassifier(nthread=4, n_estimators=10000,\n            learning_rate=0.02, num_leaves=32,\n            colsample_bytree=0.9497036, subsample=0.8715623,\n            max_depth=8, reg_alpha=0.04,\n            reg_lambda=0.073, min_split_gain=0.0222415,\n            min_child_weight=40, silent=-1,\n            verbose=-1)","39de7650":"lgbm.fit(X_train_sm, y_train_sm, eval_set=[(X_train_sm, y_train_sm), (X_test, y_test)], \n            eval_metric= 'auc', verbose= 1000, early_stopping_rounds= 100000)","012fc7b9":"warnings.filterwarnings(\"ignore\")\nprint_score(lgbm, X_train_sm, y_train_sm, X_test, y_test, train=True)\nprint_score(lgbm, X_train_sm, y_train_sm, X_test, y_test, train=False)","ba57113c":"warnings.filterwarnings(\"ignore\")\nAUROC_dict = {'Decision Tree Classifier': roc_auc_score(y_test, clf.predict(X_test))}\nAUROC_dict['Random Forest Classifier'] = roc_auc_score(y_test, rf_clf.predict(X_test))\nAUROC_dict['Bagging Classifier'] = roc_auc_score(y_test, bag_clf.predict(X_test))\nAUROC_dict['AdaBoost Classifier'] = roc_auc_score(y_test, ada_clf.predict(X_test))\nAUROC_dict['AdaBoost + RandomForest Classifier'] = roc_auc_score(y_test, ada_rf_clf.predict(X_test))\nAUROC_dict['XGBoost Classifier'] = roc_auc_score(y_test, xgb_clf.predict(X_test))\nAUROC_dict['LightGBM Classifier'] = roc_auc_score(y_test, lgbm.predict(X_test))\nAUROC_dict['Gradient Boosting Classifier'] = roc_auc_score(y_test, gbc_clf.predict(X_test))","7ad2c4d5":"AUROC = pd.DataFrame(pd.Series(AUROC_dict, index=AUROC_dict.keys(), name='AUROC Score'))","3989614a":"AUROC.sort_values('AUROC Score', ascending= False).plot(kind='bar', title = 'AUROC Score', legend = False)","53aa87cc":"***","82a73f0d":"# Gradient Boosting Classifier","04d44641":"***","55d0141e":"# IBM HR Analytics\n\nI have used this awesome dataset to compare some cool Ensemble Learning techniques like: <br>\n**Bagging <br>\nBoosting <br>\nGradient Boosting <br>\nExtreme Gradient Boosting <br>**\n\nTo learn more about **Ensemble Techiques** visit https:\/\/priyanshu.xyz\/blog\/f\/ensemble-learning-bagging-vs-boosting <br>\n\n[IBM HR Analytics Employee Attrition & Performance](https:\/\/www.kaggle.com\/pavansubhasht\/ibm-hr-analytics-attrition-dataset)","61c82b0b":"## Summary\n\nMost of the given features don't have a very strong correlation with Attrition. <br>\nEmployees with higher experience (TotalWorkingYears) have less chance of attrition. <br>\nMost of the employees are new and in their early years at the company. Mostly 0-5 years. <br>\nNew employees have higher chance of attrition. <br>\nEmployees with lower income are more likely to be chosen for attrition.","bac9ed6b":"# AdaBoost + RandomForest","0415e3cd":"***","b86adc73":"***","52be8fa3":"# Random Forest","74a0d83d":"# XGBoost","e057003e":"# Decision Tree","aecfdfbc":"# Results Comparison","6b09a474":"# Modeling","54a06c3f":"## Exploratory Data Analysis","911376f6":"***","5def0558":"Although **AdaBoost** offers some great results but **LightGBM Classifier** wins the race with 88.44% Accuracy Score and 87% F1-score and 70% Area under ROC Curve.","fa3f72c5":"# Light GBM","1d0e1ba4":"# Data Cleaning & Preparation","94496de1":"The result is clearly not satisfactory. We will revisit this project after we covered ensemble model.","3dc32ea2":"# Best Results?","7a2ebd97":"# AdaBoost","8391f343":"****","39f4a96a":"# Bagging"}}