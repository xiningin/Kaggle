{"cell_type":{"5b994a30":"code","ae27efe7":"code","e8c3402d":"code","645c23c0":"code","80b0660f":"code","473d8072":"code","d371ff51":"code","5e3d711f":"code","4e9cf95e":"code","05654e9e":"code","e54cb81b":"code","937e4761":"code","3f86c114":"code","e86eab09":"code","bf26d00c":"code","820d6c30":"code","e789a6f9":"code","f7bbe8e5":"code","49397d74":"code","a2b7f9f3":"code","62daf31f":"code","dbaee302":"code","f6693554":"code","07ccc388":"code","2cb46957":"code","1fe5a655":"code","b6c8ddbd":"code","74c0c585":"code","4a41529d":"code","14b9f033":"code","f29df008":"code","dc2210d2":"code","34de7fd4":"code","ce2a621e":"code","62abacaf":"code","f15f617a":"code","2c72ec97":"code","ca70d71e":"code","d4e98b6c":"code","856e892a":"code","dfb17423":"code","d352529c":"code","98ac0e3f":"code","b7123105":"code","8ae4acec":"code","e344b4ba":"code","87c4277c":"code","7a5112f8":"code","19ab5cc5":"code","13b6838e":"code","a0196d84":"code","4af38288":"code","e7dd94d8":"code","45a97251":"code","b618465c":"code","412e0c52":"markdown","4da091d4":"markdown","44342ade":"markdown","8cc6de6d":"markdown","9f8294b6":"markdown","a94a6a42":"markdown","dba74b53":"markdown","233eb9e5":"markdown","0ddabf6e":"markdown","14e9a425":"markdown","4fca6525":"markdown","21037b8e":"markdown","55c92a1c":"markdown","13a79875":"markdown","79016998":"markdown","0f64ea9f":"markdown"},"source":{"5b994a30":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeRegressor \nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestClassifier","ae27efe7":"train = pd.read_csv(\"\/kaggle\/input\/cap-4611-2021-fall-assignment-02\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/cap-4611-2021-fall-assignment-02\/eval.csv\")\nsubmission = pd.read_csv(\"\/kaggle\/input\/cap-4611-2021-fall-assignment-02\/sample_submission.csv\")","e8c3402d":"train.head()","645c23c0":"test.head()","80b0660f":"submission.head()","473d8072":"train.isnull().sum()","d371ff51":"test.isnull().sum()","5e3d711f":"submission.isnull().sum()","4e9cf95e":"for (columnName, columnData) in train.iteritems():\n    print(train[columnName].unique())","05654e9e":"for (columnName, columnData) in test.iteritems():\n    print(test[columnName].unique())","e54cb81b":"for (columnName, columnData) in submission.iteritems():\n    print(submission[columnName].unique())","937e4761":"train.dtypes","3f86c114":"test.dtypes","e86eab09":"submission.dtypes","bf26d00c":"sns.scatterplot(x = train['id'], y = train['console'], data = train, hue = train['esrb_rating'])","820d6c30":"sns.scatterplot(x = train['esrb_rating'], y = train['console'], data = train)","e789a6f9":"sns.barplot(x = train['console'], y = train['esrb_rating'], data = train)","f7bbe8e5":"sns.boxplot(x = train['id'],y = train['esrb_rating'], data = train)","49397d74":"sns.lineplot(x = train['console'],y = train['esrb_rating'], data = train)","a2b7f9f3":"sns.lineplot(x = train['id'],y = train['esrb_rating'], data = train, hue = 'console')","62daf31f":"columns = ['title']\n\ntrain = train.drop(columns, axis = 'columns')","dbaee302":"train = train.replace({'esrb_rating': {'E': 0, 'ET': 1, 'T': 3, 'M': 4}})","f6693554":"submission = submission.replace({'esrb_rating': {'E': 0, 'ET': 1, 'T': 3, 'M': 4}})","07ccc388":"train.head()","2cb46957":"test.head()","1fe5a655":"submission.head()","b6c8ddbd":"y = train['esrb_rating']","74c0c585":"X = train.drop('esrb_rating', axis = 'columns')","4a41529d":"X.head()","14b9f033":"test.head()","f29df008":"y.head()","dc2210d2":"y","34de7fd4":"X.shape","ce2a621e":"y.shape","62abacaf":"test_id = test['id']","f15f617a":"forest = RandomForestClassifier()\n\nparam = {'n_estimators': [100, 300, 1000], 'criterion': ['gini', 'entropy'], 'max_features':['auto', 'sqrt', 'log2'], 'bootstrap':[True, False], 'warm_start':[True, False] }\n\n\nclf = GridSearchCV(forest, param)\n\nclf.fit(X, y)\nclf.cv_results_\ndf = pd.DataFrame(clf.cv_results_)\ndf[['params', 'mean_test_score', 'rank_test_score']]\n\nprint(clf.best_score_)\nprint(clf.best_params_)","2c72ec97":"svm = SVC()\n\nparam = {'kernel':['linear', 'poly', 'rbf', 'sigmoid'], 'degree': [2,3,4,5]}\n\nclf = GridSearchCV(svm, param)\n\nclf.fit(X, y)\nclf.cv_results_\ndf = pd.DataFrame(clf.cv_results_)\ndf[['params', 'mean_test_score', 'rank_test_score']]\n\nprint(clf.best_score_)\nprint(clf.best_params_)","ca70d71e":"\nlogistic = LogisticRegression()\n\nparam = {'penalty': ['none' ,'l2'],'tol': [0.001,0.1],'solver':['newton-cg'], 'max_iter':[1000, 5000, 10000]}\n\nclf = GridSearchCV(logistic, param)\n\nclf.fit(X, y)\nclf.cv_results_\ndf = pd.DataFrame(clf.cv_results_)\ndf[['params', 'mean_test_score', 'rank_test_score']]\n\nprint(clf.best_score_)\nprint(clf.best_params_)\n","d4e98b6c":"\ndecision = DecisionTreeRegressor()\n\nparam = {'criterion': ['friedman_mse'],'splitter':['best', 'random'], 'max_depth':[2,3,4] }\n \nclf = GridSearchCV(decision, param)\n\nclf.fit(X, y)\nclf.cv_results_\ndf = pd.DataFrame(clf.cv_results_)\ndf[['params', 'mean_test_score', 'rank_test_score']]\n\nprint(clf.best_score_)\nprint(clf.best_params_)","856e892a":"knn = KNeighborsClassifier()\n\n\nparam = {'n_neighbors':[2,5,7,9], 'weights':['uniform', 'distance'], 'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'], 'p':[1,2,5,10], 'n_jobs':[1, 10, 20]}\nclf = GridSearchCV(knn, param)\n\nclf.fit(X, y)\nclf.cv_results_\ndf = pd.DataFrame(clf.cv_results_)\ndf[['params', 'mean_test_score', 'rank_test_score']]\n\nprint(clf.best_score_)\nprint(clf.best_params_)","dfb17423":"forest = RandomForestClassifier(bootstrap = False, criterion = 'gini', max_features = 'auto', n_estimators = 100, warm_start = True)\nK_fold = KFold(5, shuffle = True)\nscore_list = cross_val_score(forest, X, y, cv = K_fold)\n","d352529c":"df = pd.DataFrame(score_list)\ndf.describe()","98ac0e3f":"df['Score'] = df[0]\ndf = df.drop(0, axis = 'columns')\ndf.rename(index={0: \"Iter1\", 1: \"Iter2\", 2: \"Iter3\", 3:'Iter4', 4:'Iter5'})\ndf.plot()","b7123105":"logistic = LogisticRegression(max_iter = 1000, penalty = 'none', solver = 'newton-cg', tol =  0.001)\nK_fold = KFold(5, shuffle = True)\nscore_list = cross_val_score(logistic, X, y, cv = K_fold)","8ae4acec":"df = pd.DataFrame(score_list)\ndf.describe()","e344b4ba":"df['Score'] = df[0]\ndf = df.drop(0, axis = 'columns')\ndf.rename(index={0: \"Iter1\", 1: \"Iter2\", 2: \"Iter3\", 3:'Iter4', 4:'Iter5'})\ndf.plot()","87c4277c":"decision = DecisionTreeRegressor(criterion = 'friedman_mse', max_depth = 4, splitter = 'random')\nK_fold = KFold(5, shuffle = True)\nscore_list = cross_val_score(decision, X, y, cv = K_fold)\n\ndf = pd.DataFrame(score_list)\ndf.describe()","7a5112f8":"df['Score'] = df[0]\ndf = df.drop(0, axis = 'columns')\ndf.rename(index={0: \"Iter1\", 1: \"Iter2\", 2: \"Iter3\", 3:'Iter4', 4:'Iter5'})\ndf.plot()","19ab5cc5":"knn = KNeighborsClassifier(algorithm = 'auto', n_jobs = 1, n_neighbors = 7, p = 1, weights = 'uniform')\nK_fold = KFold(5, shuffle = True)\nscore_list = cross_val_score(knn, X, y, cv = K_fold)\n\ndf = pd.DataFrame(score_list)\ndf.describe()","13b6838e":"df['Score'] = df[0]\ndf = df.drop(0, axis = 'columns')\ndf.rename(index={0: \"Iter1\", 1: \"Iter2\", 2: \"Iter3\", 3:'Iter4', 4:'Iter5'})\ndf.plot()","a0196d84":"svm = SVC(degree = 2, kernel = 'linear')\nK_fold = KFold(5, shuffle = True)\nscore_list = cross_val_score(svm, X, y, cv = K_fold)\n\ndf = pd.DataFrame(score_list)\ndf.describe()","4af38288":"df['Score'] = df[0]\ndf = df.drop(0, axis = 'columns')\ndf.rename(index={0: \"Iter1\", 1: \"Iter2\", 2: \"Iter3\", 3:'Iter4', 4:'Iter5'})\ndf.plot()","e7dd94d8":"svc_model = SVC(degree = 2, kernel = 'poly', gamma = 'auto').fit(X, y)\noutput = svc_model.predict(test)\ndf = pd.DataFrame(output)\n\ndf = df.rename(columns={0: \"rating\"})\ndf = df.replace({'rating': {0: 'E', 1: 'ET', 3: 'T', 4: 'M'}})\noutput = pd.DataFrame({'id': test_id, 'esrb_rating': df['rating']})\n\n","45a97251":"print(output.to_string())","b618465c":"output.to_csv('submisison.csv', index=False)\nprint('Output Sucessful')","412e0c52":"**Checking for outliers**","4da091d4":"**Replacing the categorical values in 'esrb_rating' into numerical values**","44342ade":"**Checking for missing values**","8cc6de6d":"**Cross Validation Scores for all models**","9f8294b6":"# **Submit for grading**","a94a6a42":"# **Building Machine Learning Model**","dba74b53":"**The Support Vector Machine gives us the best score, we use that for submission**","233eb9e5":"**Dropping useless columns** ","0ddabf6e":"Name: Crason Shrestha\n\nAssignment: ESRB Rating","14e9a425":"# **Preporcessing Data**","4fca6525":"# **Import Data**","21037b8e":"GridSearchCV ","55c92a1c":"# **Analysis:**\n\n1. There are no null values in the test or train data.\n2. There are no outliers. So, no need for data transformation.\n3. The 'esrb_rating' has categorical values. So, that needs to be converted into numberical or ordinal values for building models.\n4. The 'title' column provides no useful information for the data processing so that can be removed.\n5. There are no missing values. So, no need for data transformation.","13a79875":" Logistic Regression, SVM, Decision Tree, Nearest Neighbor, Random Forest models ","79016998":"Grid Search for the following models: Logistic Regression, SVM, Decision Tree, Nearest Neighbor, and Random forest models","0f64ea9f":"# **Exploratory Data Analysis**"}}