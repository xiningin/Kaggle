{"cell_type":{"1b297128":"code","4977d3cc":"code","de88a264":"code","74f7905c":"code","79222122":"code","b58f55da":"code","92abff3c":"code","74d16979":"code","b4fbdf73":"code","ede97273":"code","294471ea":"code","aa0b91b9":"code","02fc3073":"code","4d5dbb96":"code","6092b879":"code","d882b178":"code","3c9a5eb4":"code","0301ea5e":"code","d37de981":"markdown","a93cc568":"markdown","60ddb3d0":"markdown","c52506d6":"markdown","0b9a2739":"markdown","9355d049":"markdown","4e9018bd":"markdown","c3370e8b":"markdown","1fcbdcfe":"markdown","931a7c99":"markdown","5d1423c7":"markdown","1eee47a1":"markdown","824daf56":"markdown","fc125525":"markdown","3ea1b739":"markdown","08dcbc99":"markdown","90d9a398":"markdown","d0b7b379":"markdown"},"source":{"1b297128":"import pandas as pd\nfrom mlxtend.preprocessing import TransactionEncoder\nfrom mlxtend.frequent_patterns import apriori, association_rules\nimport unidecode\nimport plotly.express as px","4977d3cc":"orders_first_restaurant = pd.read_csv('\/kaggle\/input\/19560-indian-takeaway-orders\/restaurant-1-orders.csv')\norders_first_restaurant['restaurant'] = '1 - restaurant'\n\norders_second_restaurant = pd.read_csv('\/kaggle\/input\/19560-indian-takeaway-orders\/restaurant-2-orders.csv')\norders_second_restaurant['restaurant'] = '2 - restaurant'\norders_second_restaurant.rename(columns={'Order ID':'Order Number'},inplace=True)\n\norders = pd.concat([orders_first_restaurant,orders_second_restaurant])\norders.drop('Total products',axis=1,inplace=True)","de88a264":"orders.info()","74f7905c":"orders.sample(5)","79222122":"def format_columns(column):\n    new_column = ' '.join(column.split())\n    new_column = new_column.replace(' ','_')\n    return new_column.lower()\n\norders.columns = [format_columns(c) for c in orders.columns]","b58f55da":"orders.isna().mean()","92abff3c":"def stats_summary(data):\n    \n    sales = data['product_price'].sum()\n    quantity = data['quantity'].sum()\n    orders_count = len(data['order_number'].unique())\n    \n    avg_price_order = sales \/ orders_count\n    avg_price_food = sales \/ quantity\n    count_food_orders = quantity \/ orders_count\n    \n    return {'avg_price_order': avg_price_order,\n            'avg_price_food': avg_price_food,\n            'count_food_orders': count_food_orders\n           }\n\ndef print_summary(data):\n    \n    stats = stats_summary(data)\n    \n    for key, value in stats.items():\n        print(f'{key}: {value:.3}')","74d16979":"print('\\n1 - restaurant\\n')\nprint_summary(orders[orders['restaurant']=='1 - restaurant'])\nprint('\\n2 - restaurant\\n')\nprint_summary(orders[orders['restaurant']=='2 - restaurant'])\n\nprint('\\nTotal\\n')\nprint_summary(orders)","b4fbdf73":"items_frequence = orders.groupby('item_name').size().reset_index(name='quantity')\nprint(items_frequence.describe())\nprint(f'\\ntotal unique orders: {len(orders[\"order_number\"].unique())}')","ede97273":"def text_normalization(text):\n    new_text = ' '.join(text.split())\n    return unidecode.unidecode(new_text.lower())\n\norders['item_name'] = orders['item_name'].apply(text_normalization)","294471ea":"#convert the dataframe to list items in order\nitem_list = orders.groupby('order_number')['item_name'].unique()\n\n# transform the values of the data set to 1 if that item belongs to that order, otherwise 0\nte = TransactionEncoder()\noht_orders = te.fit(item_list).transform(item_list, sparse=True)","aa0b91b9":"sparse_df_items = pd.DataFrame.sparse.from_spmatrix(oht_orders, columns=te.columns_)","02fc3073":"frequent_itemsets = apriori(sparse_df_items, min_support=0.02209,max_len=11, use_colnames=True, verbose=1)","4d5dbb96":"frequent_itemsets_plot = frequent_itemsets.copy()\nfrequent_itemsets_plot['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\nfrequent_itemsets_plot['support'] = (frequent_itemsets_plot['support'] * 100).round(2)\nfrequent_itemsets_plot[\"itemsets\"] = frequent_itemsets_plot[\"itemsets\"].apply(lambda x: ', '.join(list(x))).astype(\"str\")","6092b879":"frequent_itemsets_plot.groupby('length')['support'].describe()","d882b178":"top_20_frequence = frequent_itemsets_plot.sort_values('support',ascending=False).head(20).sort_values('support')\nfig = px.bar(top_20_frequence, x=\"support\", y=\"itemsets\", orientation='h', text='support')\nfig.update_traces(textposition=\"outside\")\nfig.show()","3c9a5eb4":"market_basket_rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\nmarket_basket_rules.groupby('antecedents').size().sort_values(ascending=False)","0301ea5e":"best_item_recommendations = market_basket_rules.sort_values(['confidence','lift'],ascending='False').drop_duplicates(subset=['antecedents'])\ntop_20_frequence_items = frequent_itemsets.sort_values('support',ascending=False).head(20)['itemsets']\nbest_item_recommendations[best_item_recommendations['antecedents'].isin(top_20_frequence_items)]","d37de981":"We filter an lift equal to 1 to get only rules that have a probability of buying the antecedents and consequents in the same order. As we can see, we have a high probability of recomedations if the customer buys an item. For example, we have 174 possibilities of recommendations if the customer buys a plain papadum.","a93cc568":"We need to transform the dataset into a list of items in order and convert it into a matrix (data set) where the columns are items and the rows are the order. If that item belongs to that order the value 1 is assigned, otherwise 0.","60ddb3d0":"As we can see, the difference of the average order price between two restaurants is \\\\$ 1.44 and the food price of restaurant 1 is 0.16 cents more than the second restaurant, but the quantity of the food per order is higher in the second restaurant, which increases the average order price. The total shows that the average price is \\\\$ 43.6 and 10 food per order with \\\\$ 4.15 per food the average.","c52506d6":"To save memory, we represent the transaction data in sparse format.  Because, we have 316 items and 23041 orders.","0b9a2739":"We create a copy of frequent item sets to create a custom output and analyze.","9355d049":"<a id='item_recommendation'><\/a>\n### Item Recommendation\n\nTo filter the best recommendations we will use the highest confidence value for each antecedent. We ran with the top 20 most frequent items and got some recommendations:\n\n* 4.44% (confidence) of those who buys pilau rice, buys paratha as well;\n* If one buys garlic naan, it's likely that one has also bought plain papadum with saag aloo. This way, it is possible to create a bundle with these items and apply a discount;\n* If one buys pilau rice with chicken tikka masala it's likely that one has also bought madras. This way, it is possible apply discount in the madras.","4e9018bd":"<a id='problem_definition'><\/a>\n### Problem Defination:\n\nThis dataset consisted of 33k orders from two Indian takeaway restaurants in London, UK. The purpose of this notebook is to increase cross-selling when the customer performs by applying makert basket analysis (association rules) where the food could be or recommend when the takeaway is performed:\n\n* Both X and Y could be placed on the same shelf, so that buyers of one item would be prompted to buy the other;\n* Promotional discounts could be applied to only one of the two items;\n* Advertisements on X could be targeted to shoppers buying Y;\n* X and Y could be combined into a new product.\n\n<a id='data_analysis'><\/a>\n### Data Analysis:","c3370e8b":"How we can see, there is no null values in orders","1fcbdcfe":"As a threshold for the minimum frequency of a set of items(the support metric), we used the percentage of the average\/unique order frequency, which is 2.22% and max len of set of items equals 10. ","931a7c99":"We need to remove the extra spaces, symbols or accents if any, because maybe there are duplicate items but the same text with another way of writing.","5d1423c7":"Since we have two data sets, we need to merge the information into one for easier analysis. To differentiate it between restaurant orders, first and second, a specific column was created for this purpose and remove the total_products column because it is a sum of the quantity of items in each order.","1eee47a1":"We get 556 frequency item sets with the filter we apply. We can see, that most of the item set sizes are 2 and the maximum value is 5. But it is not necessary that this itemset has a high frequency in orders. We have a high std for length equal to 1 indicating item variability and a low variability for length equal to 2 or 3 representing 4.64% and 3.48% respectively on average in the orders.","824daf56":"### Summary:\n* [Problem definition](#problem_definition)\n* [Data Analysis](#data_analysis)\n* [Market Basket Analysis](#market_basket_analysis)\n    * [Item Recommendation](#item_recommendation)\n* [Conclusions](#conclusions)\n* [References](#references)","fc125525":"As we can see, 50% of orders have rice pilau and 39.78% have simple papadum and other information is 24.15% of orders have simple papadum and rice pilau in the same order and 19.2% have simple papadum, mango chutney. In addition, 2.28% of orders have simple papadum, onion chutney, mango chutney, mint sauce, rice pilau as items.","3ea1b739":"To facilitate the analysis, we formatted the columns in lowercase and without spaces.","08dcbc99":"<a id='conclusions'><\/a>\n### Conclusions:\n\n* The quantity of the food per order is higher in the second restaurant, which increases the average order price with difference \\\\$ 1.44;\n* The average price is \\\\$ 43.6 and 10 food per order with \\\\$ 4.15 per food the average;\n* The average frequency item is 509, that is, an item appears on average 509 times which represets 2.22%;\n* 50,17% of orders has pilau rice;\n* 24.15% of orders have simple papadum and rice pilau in the same order 19.2% have simple papadum, mango chutney;\n* 2.28% of orders have simple papadum, onion chutney, mango chutney, mint sauce, rice pilau as items;\n* 4.44% (confidence) of those who buys pilau rice, buys paratha as well;\n* If one buys plain papadum with pilau rice it's likely that one has also bought garlic naan with naan;\n* If one buys garlic naan, it's likely that one has also bought plain papadum with saag aloo. This way, it is possible to create a bundle with these items and apply a discount;\n* If one buys pilau rice with chicken tikka masala it's likely that one has also bought madras. This way, it is possible apply discount in the madras.\n\n\nAnd that\u2019s it! It has been a pleasure to make this kernel, I have learned a lot! Thank you for reading and if you like it, please upvote it!\n\n<a id='references'><\/a>\n### References:\n\nAnnalyn Ng(2016) Association rules apriori algorithm tutorial. Retrieved from: [https:\/\/www.kdnuggets.com\/2016\/04\/association-rules-apriori-algorithm-tutorial.html](https:\/\/www.kdnuggets.com\/2016\/04\/association-rules-apriori-algorithm-tutorial.html)\n\nHafsa Jabeen(2018) Market Basket Analysis using R. Retrieved from: [https:\/\/www.datacamp.com\/community\/tutorials\/market-basket-analysis-r](https:\/\/www.datacamp.com\/community\/tutorials\/market-basket-analysis-r)\n\nAssociation Rules. Retrived from: [http:\/\/rasbt.github.io\/mlxtend\/user_guide\/frequent_patterns\/association_rules\/](http:\/\/rasbt.github.io\/mlxtend\/user_guide\/frequent_patterns\/association_rules\/)\n\nApriori. Retrived from: [http:\/\/rasbt.github.io\/mlxtend\/user_guide\/frequent_patterns\/apriori\/](http:\/\/rasbt.github.io\/mlxtend\/user_guide\/frequent_patterns\/apriori\/)\n","90d9a398":"As we can see, the average frequency item is 509, that is, an item appears on average 509 times. When, we look at the median, we see that it is the outliers that pull the average up. The maximum value is 13093, which represents 56.8% of the orders with this item which is Pilau Rice. The frequency percentage of the item is 2.22% (mean \/ total unit orders) and the median percentage is 0.49%.","d0b7b379":"<a id='market_basket_analysis'><\/a>\n### Market Basket Analysis (Association Rules)\n\nThrough the frequency of the items in the orders, we try to understand if there is an association between one product and another in the order with the objective of recommending this product in an extra purchase.\n\n### Example\nWe have a Market Basket transactions, where diapers and beer are a set of frequent items and with that, we have those who buy diapers have a probability of buying beer.\n\n![example_mba_kaggle.png](attachment:7f09ccef-4191-4585-bc60-c1db7a9d03d5.png)"}}