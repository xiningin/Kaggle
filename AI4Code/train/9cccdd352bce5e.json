{"cell_type":{"cd6c9446":"code","82967275":"code","a50082c2":"code","da92e35b":"code","dc90144f":"code","431b4743":"code","cf6d8968":"code","346040c3":"code","2d0d7a44":"code","b0e5c4be":"code","3e39cf63":"code","fa1e0256":"code","99fa2580":"code","03a76616":"code","1c4fc41b":"code","9f6db3f3":"code","eee4dd27":"code","626008b8":"code","96d9e23d":"code","f342137e":"code","3169e8c9":"code","277625b4":"code","de1442e5":"code","991c6dd4":"code","ece18aa8":"code","3c092f41":"code","6ab80634":"code","82321ef5":"code","ced8eca7":"code","9fb95e73":"code","49ea4967":"code","0ef04768":"code","835aaa45":"code","4467f55c":"code","201d3b89":"code","31cb5e25":"code","efd2209d":"code","13892b59":"code","ece44713":"code","e7d3cf5d":"code","70d15291":"code","c8e00959":"code","2723f8dc":"code","3796ce1d":"code","fb274ba3":"code","b678d80f":"markdown","e896ce05":"markdown","65286123":"markdown","6869c185":"markdown","86b2cfb4":"markdown","b44a4e9f":"markdown","3411ec64":"markdown","89ae2045":"markdown","5c3e1582":"markdown","c7401e03":"markdown"},"source":{"cd6c9446":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","82967275":"def load_titanic_data(filename, titanic_path):\n    csv_path = os.path.join(titanic_path, filename)\n    return pd.read_csv(csv_path)","a50082c2":"train_data = load_titanic_data('train.csv',\"..\/input\")\ntest_data = load_titanic_data('test.csv','..\/input')","da92e35b":"test_data.head()","dc90144f":"train_data.info()","431b4743":"train_data.describe()","cf6d8968":"%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\ntrain_data[['Age','SibSp','Parch','Fare']].hist(figsize=(8,8))","346040c3":"train_data['Survived'].value_counts()","2d0d7a44":"train_data['Pclass'].value_counts()","b0e5c4be":"train_data['Sex'].value_counts()","3e39cf63":"train_data['Embarked'].value_counts()","fa1e0256":"from sklearn.base import BaseEstimator, TransformerMixin\n\n# A class to select numerical or categorical columns\nclass DataFrameSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attribute_names):\n        self.attribute_names = attribute_names\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return X[self.attribute_names]","99fa2580":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nnum_pipeline = Pipeline([\n    ('select_numeric', DataFrameSelector(['Age','SibSp','Parch','Fare'])),\n    ('imputer', SimpleImputer(strategy='median'))\n])","03a76616":"num_pipeline.fit_transform(train_data)","1c4fc41b":"class MostFrequentImputer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X], index=X.columns)\n        return self\n    def transform(self, X, y=None):\n        return X.fillna(self.most_frequent_)","9f6db3f3":"from sklearn.preprocessing import OneHotEncoder","eee4dd27":"cat_pipeline = Pipeline([\n    ('select_cat', DataFrameSelector(['Pclass','Sex','Embarked'])),\n    ('imputer', MostFrequentImputer()),\n    ('cat_encoder', OneHotEncoder(sparse=False))\n])","626008b8":"cat_pipeline.fit_transform(train_data)","96d9e23d":"from sklearn.pipeline import FeatureUnion\n\npreprocess_pipeline = FeatureUnion(transformer_list=[\n    ('num_pipeline', num_pipeline),\n    ('cat_pipeline', cat_pipeline),\n])","f342137e":"X_train = preprocess_pipeline.fit_transform(train_data)\nprint(X_train.shape)\nX_train","3169e8c9":"y_train = train_data['Survived']","277625b4":"from sklearn.svm import SVC\n\nsvm_clf = SVC(gamma='auto')\nsvm_clf.fit(X_train, y_train)","de1442e5":"from sklearn.model_selection import cross_val_score\n\nsvm_scores = cross_val_score(svm_clf, X_train, y_train, cv=10)\nsvm_scores.mean()","991c6dd4":"from sklearn.ensemble import RandomForestClassifier\n\nforest_clf = RandomForestClassifier(random_state=42, n_estimators=10)\nforest_scores = cross_val_score(forest_clf, X_train, y_train, cv=10)\nforest_scores.mean()","ece18aa8":"from sklearn.linear_model import SGDClassifier\n\nsgd_clf = SGDClassifier(max_iter=100, random_state=42, tol=0.001)\nsgd_scores = cross_val_score(sgd_clf, X_train, y_train, cv=10)\nsgd_scores.mean()","3c092f41":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_clf = KNeighborsClassifier(n_jobs=-1, weights='distance', n_neighbors=4)\nknn_scores = cross_val_score(knn_clf, X_train, y_train, cv=10)\nknn_scores.mean()","6ab80634":"%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8, 4))\nplt.plot([1]*10, svm_scores, \".\")\nplt.plot([2]*10, forest_scores, \".\")\nplt.plot([3]*10, sgd_scores, \".\")\nplt.plot([4]*10, knn_scores, \".\")\nplt.boxplot([svm_scores, forest_scores, sgd_scores, knn_scores], labels=(\"SVM\",\"Random Forest\",\"SGD\",'KNN'))\nplt.ylabel(\"Accuracy\", fontsize=14)\nplt.show()","82321ef5":"train_data['AgeBucket'] = train_data['Age'] \/\/ 15 * 15\ntrain_data[['AgeBucket','Survived']].groupby(['AgeBucket']).mean()","ced8eca7":"train_data[\"RelativesOnboard\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\npd.pivot_table(train_data, index=\"RelativesOnboard\", values=\"Survived\", aggfunc=\"mean\")","9fb95e73":"from sklearn.base import BaseEstimator, TransformerMixin\n\nage_ix, sibsp_ix, parch_ix = 1, 2, 3\n\nclass CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n    def __init__(self, add_attributes = True):\n        self.add_attributes = add_attributes\n    def fit(self, X, y=None):\n        return self # nothing else to do\n    def transform(self, X, y=None):\n        if self.add_attributes:\n            age_bucket = X[:, age_ix] \/\/ 15 * 15\n            relatives_onboard = X[:, sibsp_ix] + X[:, parch_ix]\n            return np.c_[X, age_bucket, relatives_onboard]\n        else:\n            return np.c_[X]","49ea4967":"from sklearn.preprocessing import StandardScaler\n\nnum_pipeline = Pipeline([\n    ('selector', DataFrameSelector([\"Age\", \"SibSp\", \"Parch\", \"Fare\"])),\n    ('imputer', SimpleImputer(strategy=\"median\")),\n    ('attribs_adder', CombinedAttributesAdder()),\n    ('std_scaler', StandardScaler())\n])","0ef04768":"num_pipeline.fit_transform(train_data)","835aaa45":"from sklearn.pipeline import FeatureUnion\n\npreprocess_pipeline = FeatureUnion(transformer_list=[\n        (\"num_pipeline\", num_pipeline),\n        (\"cat_pipeline\", cat_pipeline),\n    ])","4467f55c":"X_train = preprocess_pipeline.fit_transform(train_data)\nprint(X_train.shape)\nX_train","201d3b89":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {'n_estimators': [50, 100, 150],\n     'max_depth':[5, 10]}\n]\n\nforest_clf = RandomForestClassifier(random_state=42)\n\ngrid_search = GridSearchCV(forest_clf, param_grid, cv=10, return_train_score=True)\n\ngrid_search.fit(X_train, y_train)","31cb5e25":"cvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(mean_score, params)","efd2209d":"grid_search.best_params_","13892b59":"from sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint\n\nparam_distribs = {\n    'n_estimators': randint(low=20, high=150),\n    'max_features': randint(low=5, high=12),\n    'max_depth': randint(low=5, high=12)\n}\n\nforest_clf = RandomForestClassifier(random_state=42)\nforest_rnd_search = RandomizedSearchCV(forest_clf, param_distributions=param_distribs, n_iter=50, cv=10, return_train_score=True,\n                                      random_state=42, verbose=2, n_jobs=-1)\nforest_rnd_search.fit(X_train, y_train)","ece44713":"forest_rnd_search.best_params_","e7d3cf5d":"cvres = forest_rnd_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(mean_score, params)","70d15291":"final_model = forest_rnd_search.best_estimator_","c8e00959":"test_data.head()","2723f8dc":"X_test = preprocess_pipeline.transform(test_data)","3796ce1d":"y_pred = final_model.predict(X_test)\ny_pred","fb274ba3":"test_data[\"Survived\"] = y_pred\ntest_data[[\"PassengerId\",\"Survived\"]].to_csv('submission.csv', index=False)","b678d80f":"<a id=\"model_tuning\"><\/a>\n# Fine-tune the best Models","e896ce05":"<a id=\"setup\"><\/a>\n# Setup","65286123":"<a id=\"get_data\"><\/a>\n# Get the data","6869c185":"<a id=\"predictions\"><\/a>\n# Make Predictions","86b2cfb4":"<h1 align=center><font size = 4>Tackle the Titanic Dataset<\/font><\/h1>\n<h1 align=center><font size = 5>Model Binary Classifier<\/font><\/h1>","b44a4e9f":"<a id=\"model_selection\"><\/a>\n# Train and Select Models","3411ec64":"Check that the output is indeed 0 or 1","89ae2045":"<a id=\"data_structure\"><\/a>\n# Take a Quick Look at the Data Structure","5c3e1582":"<a id=\"preparation\"><\/a>\n# Prepare Data for Machine Learning","c7401e03":"# Table of Contents\n* [Setup](#setup)\n* [Get the Data](#get_data)\n* [Take a Quick Look at the Data Structure](#data_structure)\n* [Prepare Data for Machine Learning](#preparation)\n* [Train and Select Models](#model_selection)\n* [Fine-tune the best Models](#model_tuning)\n* [Make Predictions](#predictions)"}}