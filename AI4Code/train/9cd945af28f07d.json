{"cell_type":{"42176833":"code","bf1d72be":"code","7d4866f8":"code","01f3c1fc":"code","e9df7f3c":"code","6ad53f05":"code","41ff3a8e":"code","3fc415a9":"code","f926570b":"code","7fb69f2d":"code","c1d8f190":"code","8ec1989e":"code","052607ca":"code","50fe0bf8":"code","288a8c25":"code","37b9861c":"code","9761f477":"code","6ca246ce":"code","7418a0c7":"code","913cbf3e":"code","7010b116":"markdown","0def27b2":"markdown","6e5f5433":"markdown","5e1839da":"markdown"},"source":{"42176833":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bf1d72be":"# importing Liberaries\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","7d4866f8":"# loading data\ndf = pd.read_csv('\/kaggle\/input\/dataset-of-laptop-users\/Laptop-Users.csv')\ndf","01f3c1fc":"# Getting the shape of data\ndf.shape","e9df7f3c":"# GEtting data types\ndf.info()","6ad53f05":"# checking nulll values\ndf.isnull().sum()","41ff3a8e":"# Summarizing the data\ndf.describe().T","3fc415a9":"def hist_count(column, data):\n    if column in data:\n        f, axes = plt.subplots(1,1,figsize=(15,5))\n        sns.countplot(x=column, data=data)\n        plt.xticks(rotation = 90)\n        plt.suptitle(column, fontsize=20)\n        plt.show()\n    plt.show()\nfor column in df.columns:\n    hist_count(column,df)","f926570b":"# Age and Laptop\nimport plotly.express as px\nfig = px.histogram(df, x = df['Age'], color = 'Has Laptop')\nfig.show()\nfig2 = px.box(df, x = df['Age'], color = 'Has Laptop')\nfig2.show()","7fb69f2d":"# Gender and Laptop\nimport plotly.express as px\nfig = px.histogram(df, x = df['Gender'], color = 'Has Laptop')\nfig.show()\nfig2 = px.box(df, x = df['Gender'], color = 'Has Laptop')\nfig2.show()","c1d8f190":"# Occupation and Laptop\nimport plotly.express as px\nfig = px.histogram(df, x = df['Occupation'], color = 'Has Laptop')\nfig.show()\nfig2 = px.box(df, x = df['Occupation'], color = 'Has Laptop')\nfig2.show()","8ec1989e":"# Income and Laptop\nimport plotly.express as px\nfig = px.histogram(df, x = df['Income'], color = 'Has Laptop')\nfig.show()\nfig2 = px.box(df, x = df['Income'], color = 'Has Laptop')\nfig2.show()","052607ca":"# Correlation graph\nsns.heatmap(df.corr(),annot = True, cmap = 'viridis')","50fe0bf8":"import pandas_profiling as pp\nprofile = pp.ProfileReport(df, title = \"Laptop User Data\")\nprofile","288a8c25":"df.columns","37b9861c":"# getting features \nfeatures = ['Age', 'Gender', 'Region', 'Occupation', 'Income']\nx = pd.get_dummies(df[features])\n\n# Getting predicting value\ny = df['Has Laptop']","9761f477":"# Seperating data into training and testing data\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 1\/6, random_state = 42)","6ca246ce":"# Scaling the data\nfrom sklearn.preprocessing import StandardScaler\nscale = StandardScaler()\nx_train = scale.fit_transform(x_train)\nx_test = scale.fit_transform(x_test)","7418a0c7":"# Defining Models\ndef Classification_models(x,y,xt,yt):\n    # Importing All LIberaries\n    from sklearn.metrics import accuracy_score\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n    from sklearn.naive_bayes import GaussianNB\n    from sklearn.tree import DecisionTreeClassifier\n    from sklearn.ensemble import RandomForestClassifier\n    from sklearn import svm\n    from sklearn.neighbors import KNeighborsClassifier\n\n    # Initializing models\n    logisreg = LogisticRegression()\n    lda = LinearDiscriminantAnalysis()\n    gnb = GaussianNB()\n    dtc = DecisionTreeClassifier()\n    rfc = RandomForestClassifier()\n    svmodel = svm.SVC()\n    knnmodel = KNeighborsClassifier()\n    \n    # Fitting Models\n    logisreg.fit(x,y)\n    lda.fit(x,y)\n    gnb.fit(x,y)\n    dtc.fit(x,y)\n    rfc.fit(x,y)\n    svmodel.fit(x,y)\n    knnmodel.fit(x,y)\n    \n    # Getting PRedicting Values\n    logi_pred = logisreg.predict(xt)\n    lda_pred = lda.predict(xt)\n    gnb_pred = gnb.predict(xt)\n    dtc_pred = dtc.predict(xt)\n    rfc_pred = rfc.predict(xt)\n    svm_pred = svmodel.predict(xt)\n    knn_pred = knnmodel.predict(xt)\n    \n    # Getting Accuracy Score\n    acc_logisreg = accuracy_score(yt, logi_pred)\n    acc_lda = accuracy_score(yt, lda_pred)\n    acc_ganb = accuracy_score(yt, gnb_pred)\n    acc_dtree = accuracy_score(yt, dtc_pred)\n    acc_rf = accuracy_score(yt, rfc_pred)\n    acc_svc = accuracy_score(yt, svm_pred)\n    acc_knn = accuracy_score(yt, knn_pred)\n    \n    # MOdel Selection\n    models = pd.DataFrame({\n    'Model': ['Logistic Regression','Linear Discriminant Analysis','Naive Bayes', 'Decision Tree', 'Random Forest', 'Support Vector Machines', \n              'K - Nearest Neighbors'],\n    'Score': [acc_logisreg, acc_lda, acc_ganb, acc_dtree, acc_rf, acc_svc, acc_knn]})\n\n    print(models.sort_values(by='Score', ascending=False))\n    sns.barplot(x = models['Score'], y = models['Model'], palette='viridis');","913cbf3e":"Classification_models(x_train,y_train,x_test,y_test)","7010b116":"# Sumamry\n* Decision Tree Classification Model is the best here with an accyracy of 100%\n* Random Forest was just behind it with an accyracy of 75%\n\n***Please leave your valuable feedback in the comment Section Below and dont forget to UPVOTE.....***","0def27b2":"# Creating Data Models","6e5f5433":"# Laptop Users","5e1839da":"# Visualization"}}