{"cell_type":{"4b4fd67a":"code","321dd654":"code","c89f0b1f":"code","6af08039":"code","1521c45f":"code","51c48569":"code","e2cb9867":"code","a79b15e0":"code","a587c12e":"code","c78c7596":"code","88576278":"code","685dee68":"code","2cf8d0fb":"code","4a2d6d94":"code","d8202461":"code","975cea58":"code","bf8250ff":"code","89475867":"code","4fc3c1f8":"code","2c9ef7ca":"code","e1f78b25":"code","d704de32":"code","3624f126":"code","231fddf5":"code","f608f521":"code","1902c2e4":"code","132023a5":"code","fde99bef":"code","f2d70b46":"code","588912d5":"code","d2233406":"code","a9d84a5b":"code","abccc838":"code","59ed0f0e":"code","1a81ec85":"code","e7581fc7":"code","b1106e25":"code","c4e02de8":"code","4a365377":"code","20e4f1fe":"code","3f5e15ce":"code","a7a79dce":"code","fdd99fc6":"code","31fe54a0":"code","c34911ba":"code","431eaf5a":"code","e8fce81f":"code","6353b41f":"markdown","7d4ddd8f":"markdown","68d9c315":"markdown","7a874863":"markdown","b72621e6":"markdown","9987be87":"markdown","03ec649c":"markdown","74143b1a":"markdown","afc6aa57":"markdown","c3fa89a0":"markdown","33fc25b5":"markdown","17232212":"markdown","3d93cfdd":"markdown","8661aa8a":"markdown","eb59ecfb":"markdown","79098eca":"markdown","7ac27454":"markdown","290f5f82":"markdown","d7496c75":"markdown","be1b6029":"markdown","b03446fa":"markdown","b5379129":"markdown","df83181d":"markdown"},"source":{"4b4fd67a":"import numpy as np\nimport pandas as pd\nimport plotly.express as px\nfrom datetime import date","321dd654":"import warnings\nwarnings.filterwarnings('ignore')","c89f0b1f":"model_df = pd.read_csv('\/kaggle\/input\/used-car-price-data\/model_data.csv')\ncar_df = pd.read_csv('\/kaggle\/input\/used-car-price-data\/car_data.csv')","6af08039":"car_df.head()","1521c45f":"model_df.head()","51c48569":"df = pd.merge(car_df, model_df, left_on='Model', right_on='Model')","e2cb9867":"df.describe(include='all')","a79b15e0":"df.isna().mean()*100","a587c12e":"fig = px.histogram(df, 'Selling Price')\nfig.show()","c78c7596":"df = df[df['Selling Price'] != 0]","88576278":"def format_price(price):\n    price = str(price)\n    price = price.replace('Rs.', '')\n    price = price.replace(',', '')\n    num_zeros = 5\n    if '.' not in price and ' Lakh' in price:\n        price = price.replace(' Lakh', '0'*num_zeros)\n    elif '.' in price and ' Lakh in price':\n        n = len(price)\n        m = price.index('.')\n        num_zeros = n - m - num_zeros\n        price = price.replace(' Lakh', '0'*num_zeros)\n        price = price.replace('.', '')\n    return price","685dee68":"df['Current Price'] = df['Current Price'].apply(format_price)\ndf[df['Current Price'] == 'nan'] = 0\ndf['Current Price'] = df['Current Price'].astype(int)","2cf8d0fb":"fig = px.histogram(df, 'Current Price')\nfig.show()","4a2d6d94":"year = date.today().year\ndf['Age'] = year - df['Year']","d8202461":"df = df[df['Selling Price'] != 0]\nfig = px.scatter(x=df['Age'], y=df['Kilometers Driven'])\nfig.show()","975cea58":"fig = px.scatter(x=df['Kilometers Driven'], y=df['Selling Price'])\nfig.show()","bf8250ff":"fig = px.scatter(x=df['Age'], y=df['Selling Price'])\nfig.show()","89475867":"fig = px.scatter(df['Selling Price'], color=df['Owner'])\nfig.show()","4fc3c1f8":"df['Transmission'].unique()","2c9ef7ca":"def clean_transmission(trans):\n    \n    if 'MANUAL' != trans and 'AUTOMATIC' != trans:\n        trans = \"MANUAL\"\n    \n    return trans\n\ndf['Transmission'] = df['Transmission'].apply(clean_transmission)","e1f78b25":"from sklearn.impute import SimpleImputer\n\nmode_imputer = SimpleImputer(strategy=\"most_frequent\")\ndf['Insurance'] = mode_imputer.fit_transform(df['Insurance'].values.reshape(-1, 1))","d704de32":"df['Insurance_Expired'] = 0\ndf.loc[df['Insurance'] == 'Expired', 'Insurance_Expired'] = 1","3624f126":"fig = px.scatter(df['Selling Price'], color=df['Insurance_Expired'])\nfig.show()","231fddf5":"fig = px.scatter(x=df['Current Price'], y=df['Selling Price'], color=df['Car Condition'])\nfig.show()","f608f521":"df['No_Current_Price'] = 0\ndf.loc[df['Current Price'] == 0, 'No_Current_Price'] = 1","1902c2e4":"df['diff'] = df['Current Price'] - df['Selling Price']","132023a5":"med_diff = df[df['diff'] > 0]['diff'].median()","fde99bef":"def set_current_price(row):\n    if row['Current Price'] == 0 or row['diff'] < 0:\n        row['Current Price'] = row['Selling Price'] + med_diff\n    \n    return row['Current Price']\n\ndf.loc[:, 'Current Price'] = df.apply(set_current_price, axis=1)","f2d70b46":"df.head()","588912d5":"df.drop(['Model', 'Year', 'Insurance', 'diff'], axis=1, inplace=True)\ndf.head()","d2233406":"X = df.drop(['Selling Price'], axis=1)\ny = df.loc[:, 'Selling Price']","a9d84a5b":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)","abccc838":"num_attribs = ['Kilometers Driven', 'Car Condition', 'Current Price', 'Age']\ncat_attribs = ['Owner', 'Fuel Type', 'Transmission']","59ed0f0e":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\n\npreprocessing = ColumnTransformer([\n    (\"num\", StandardScaler(), num_attribs),\n    (\"cat\", OneHotEncoder(drop='first', sparse=False), cat_attribs)\n], remainder=\"passthrough\")\n\nX_train = preprocessing.fit_transform(X_train)","1a81ec85":"col_names = []\nfor transformer_tuple in preprocessing.transformers_[:-1]:\n    cols = transformer_tuple[2]\n    transformer = transformer_tuple[1]\n    try:\n        cols = transformer.get_feature_names(cols)\n    except AttributeError:\n        cols = cols\n        \n    col_names += list(cols)\n    \ncol_names += list(X.columns[preprocessing.transformers_[2][2]])","e7581fc7":"sc_y = StandardScaler()\ny_train = sc_y.fit_transform(y_train.values.reshape(-1, 1))","b1106e25":"from sklearn.model_selection import cross_val_score\n\ndef evaluate_model(model, X, y):\n    \n    model.fit(X, y)\n    \n    accuracies = cross_val_score(estimator = model, X = X, y = y, cv = 10)\n    print(model.__class__.__name__)\n    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n    \n    return model","c4e02de8":"from sklearn.linear_model import LinearRegression\n\nlin_reg = evaluate_model(LinearRegression(), X_train, y_train)","4a365377":"from sklearn.svm import SVR\n\nsvr = evaluate_model(SVR(), X_train, y_train)","20e4f1fe":"from sklearn.ensemble import RandomForestRegressor\n\nrf = evaluate_model(RandomForestRegressor(n_estimators = 100, random_state = 0), X_train, y_train)","3f5e15ce":"from sklearn.ensemble import AdaBoostRegressor\n\nada_boost = evaluate_model(AdaBoostRegressor(random_state=0, n_estimators=100), X_train, y_train)","a7a79dce":"import xgboost\n\nxg_boost = evaluate_model(xgboost.XGBRegressor(), X_train, y_train)","fdd99fc6":"from sklearn.model_selection import GridSearchCV\n\nparam_test = {\n 'max_depth':[4,5,6],\n 'min_child_weight':[4,5,6],\n 'colsample_bytree':[i\/100.0 for i in range(75,90,5)]\n}\n\ngrid_search_1 = GridSearchCV(estimator = xgboost.XGBRegressor(learning_rate =0.1,\n                                                              n_estimators=10,\n                                                              max_depth=5,\n                                                              min_child_weight=1,\n                                                              gamma=0.2,\n                                                              subsample=0.85,\n                                                              colsample_bytree=0.8),\n                             param_grid = param_test,\n                             scoring='neg_mean_squared_error',\n                             n_jobs=-1,\n                             cv=5)\n\ngrid_search_1.fit(X_train,y_train)\ngrid_search_1.best_params_, grid_search_1.best_score_","31fe54a0":"xg_boost = evaluate_model(xgboost.XGBRegressor(learning_rate =0.1,\n                                                              n_estimators=100,\n                                                              max_depth=6,\n                                                              min_child_weight=6,\n                                                              gamma=0.2,\n                                                              subsample=0.85,\n                                                              colsample_bytree=0.85),\n                          X_train, y_train)","c34911ba":"importance_df = pd.DataFrame(xg_boost.feature_importances_)\nimportance_df['Features'] = col_names\nimportance_df = importance_df.rename(columns={0 : 'Average Importance'})\n\nfig = px.bar(importance_df, x='Features', y='Average Importance')\nfig.show()","431eaf5a":"X_test = preprocessing.transform(X_test)\ny_test = sc_y.transform(y_test.values.reshape(-1, 1))\n\ny_pred = xg_boost.predict(X_test)","e8fce81f":"from sklearn.metrics import mean_squared_error\n\nmean_squared_error(y_test, y_pred)","6353b41f":"Looking at the two datasets, the model column in the two dataframes can be used to merge the two such that you can have a dataframe with information of each car with its current selling price.","7d4ddd8f":"Separating the target features","68d9c315":"Note: Hyperparamter tuning can be an iterative technique where you first do a coarse search of parameter values and then go for a finer search around the values found in the previous step. In interest of your time, I have only included the last step here.","7a874863":"## A Look At The Data","b72621e6":"## Car Price Prediction\n\nThe problem at hand is to model the selling price of used cars based on the features given in the datasets. It will be used by the client to predict the price of a car of their choice. Your mission, should you choose to accept it, as a data scientist, is to make sure that you maximize the probability of them getting the car and at the same time, make sure that they don't overpay.\n\n\n![79e15-sell-your-old-car%20%281%29.jpg](attachment:79e15-sell-your-old-car%20%281%29.jpg)\n\nLet's get to it.","9987be87":"We have very few null values in Insurance and Car Price columns.","03ec649c":"Transmission column has many values other than manual or automatic. You need to handle this and one way to do it can be to replace all of them with the mode (the most frequent value). That is MANUAL in this case.","74143b1a":"Since the prices are bit skewed, median is better approximation of central tendency.","afc6aa57":"## Training Different Models","c3fa89a0":"Checking for null values if any.","33fc25b5":"You can now drop model, year, insurance and diff columns","17232212":"You can look at the two datasets together now.","3d93cfdd":"Woah! you have some cars that have 0 Current Price. Looks like the earlier null count were deceptive as you already know, no one is giving away cars for free. You might have to handle this.","8661aa8a":"The Current Price column had some records with 0 value. We can add the average difference between the selling price and current price to the selling price of these columns to get an approximation of the current price of these columns.\n\nYou can also add another column to tell the model that the current price was missing earlier and to take the current price for such records with a pinch of salt. As missing current price might denote that the car is too old and no longer sold in the market","eb59ecfb":"Current Price column is in very raw format. Some of the records have Rs. prefix and a Lakh at the end while some are in all numbers. You need to convert it to integer format so that you can analyze it better and compare with the selling price column.","79098eca":"We can extract column names to later check which feature affect our target feature the most.","7ac27454":"Here, fuel type, age, current price and car condition are the features that contribute the most in determining the target features as we would have assumed.\n\n***I hope you found this notebook interesting. I would love to read your feedbacks below.***","290f5f82":"There are a few records with 0 selling price. Maybe, you can get that car for free. We all know that is not possible so we can go ahead and remove these records.","d7496c75":"Let's derive a feature from the insurance column, to indicate whether the insurance has expired or not.","be1b6029":"Creating a Train Test split","b03446fa":"## Cleaning data","b5379129":"## Preprocessing","df83181d":"Insurance column had some null values. let's replace them with the most frequent value."}}