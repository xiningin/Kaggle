{"cell_type":{"9e7435df":"code","322b1e84":"code","85c3df70":"code","a3b53285":"code","d2b52187":"code","d667f746":"code","2d9b0dc8":"code","544f5873":"code","4536adf1":"code","6f51766b":"code","5240c2af":"code","f9792b24":"code","e97f01f7":"code","dd20d00f":"code","be0bce21":"code","d944bb1f":"code","3d3ab513":"code","f55bf48f":"code","1c2ed227":"code","13f38520":"markdown","c0aa5dbf":"markdown","b1c4f822":"markdown","503a8e44":"markdown"},"source":{"9e7435df":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","322b1e84":"train=pd.read_csv('\/kaggle\/input\/quora-insincere-questions-classification\/train.csv',index_col=False)\ntest=pd.read_csv('\/kaggle\/input\/quora-insincere-questions-classification\/test.csv',index_col=False)\nsample=pd.read_csv('\/kaggle\/input\/quora-insincere-questions-classification\/sample_submission.csv',index_col=False)","85c3df70":"train.sample(5)","a3b53285":"train.info()","d2b52187":"test.info()","d667f746":"y=train.target.values","2d9b0dc8":"y[:5]","544f5873":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import GRU,Bidirectional,Embedding,Dense,Flatten,GlobalMaxPool1D,LSTM\nfrom keras.models import Sequential\n","4536adf1":"num_words=3000\nmax_len=200\ntokenizer=Tokenizer(num_words,oov_token='<oov>')\ntokenizer.fit_on_texts(train.question_text)\ntrain_sequences=tokenizer.texts_to_sequences(train.question_text)\ntest_sequences=tokenizer.texts_to_sequences(test.question_text)\n\n# let's pad the sequences to make them of equal length\n\ntrain_padded=pad_sequences(train_sequences,maxlen=max_len)\ntest_padded=pad_sequences(test_sequences,maxlen=max_len)","6f51766b":"model=Sequential([Embedding(num_words,128,input_length=max_len),\n                 Bidirectional(LSTM(128,return_sequences=True)),\n                               GlobalMaxPool1D(),\n                              Dense(128,activation='relu'),\n                            \n                               \n                              Dense(1,activation='sigmoid')])\nmodel.compile(optimizer='adam',loss='binary_crossentropy',metrics='accuracy')","5240c2af":"batch_size=400\nepochs=3\nmodel.fit(train_padded,y,epochs=epochs,batch_size=batch_size,steps_per_epoch=len(train)\/\/batch_size,validation_split=.1)","f9792b24":"predicted=model.predict(test_padded)","e97f01f7":"test['prediction']=predicted","dd20d00f":"test.sample(5)","be0bce21":"test.drop(['question_text'],axis=1,inplace=True)","d944bb1f":"test.sample(5)","3d3ab513":"test['prediction']=test['prediction'].apply(lambda x: 0 if x<.5 else 1)","f55bf48f":"test.prediction.value_counts()","1c2ed227":"test.to_csv('submission.csv',index=False)","13f38520":"lets check if we have any missing values in our dataframes","c0aa5dbf":"Let's see a few radom samples from the train dataframe","b1c4f822":"let's import the packages we need to build our model","503a8e44":"# Let's start by readidng the data from the csv files"}}