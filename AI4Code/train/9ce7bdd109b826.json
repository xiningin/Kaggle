{"cell_type":{"4a7fc956":"code","dd707970":"code","592c1825":"code","510a05d7":"code","673da3df":"code","f567d886":"code","cf05b898":"code","70b8dbd6":"code","aff07122":"code","be0bb135":"code","b343a8b7":"code","436d1357":"code","62f1fe72":"code","88ddb653":"code","ff21f64b":"code","83f1983c":"code","a05ebf7a":"code","c0a39fe0":"code","45ef65a5":"code","43e6bc5e":"code","222a0a5e":"code","35f66595":"code","89d5803b":"code","9997c750":"code","13c55352":"code","940b8499":"code","7b5a9ca4":"markdown","efc4ba8c":"markdown","9f76703b":"markdown","18f8d109":"markdown","0611aa35":"markdown","317c8e66":"markdown","7a62d833":"markdown","42f29246":"markdown","79a7b47d":"markdown","ab06f967":"markdown","0c188687":"markdown"},"source":{"4a7fc956":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\nfrom keras.optimizers import RMSprop\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix","dd707970":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","592c1825":"train.shape, test.shape","510a05d7":"train.head()","673da3df":"X_train = train.drop(labels=['label'], axis=1)\ny_train = train['label']","f567d886":"X_train.shape, y_train.shape","cf05b898":"print(y_train.value_counts(sort=False))\nsns.countplot(y_train)","70b8dbd6":"X_train = X_train.values.astype('float32').reshape(-1, 28, 28, 1)\nX_test = test.values.astype('float32').reshape(-1, 28, 28, 1)","aff07122":"for cnt, i in enumerate([10, 20, 30]):\n    plt.subplot(330 + (cnt+1))\n    plt.imshow(X_train[i][:, :, 0], cmap=plt.get_cmap('gray'))\n    plt.title(y_train[i])","be0bb135":"X_train = X_train \/ 255.0\nX_test = X_test \/ 255.0","b343a8b7":"from keras.utils.np_utils import to_categorical\ny_train = to_categorical(y_train)","436d1357":"y_train[0]","62f1fe72":"X_train, X_val, y_train, y_val = train_test_split(\n    X_train, y_train, test_size=0.1, random_state=42)","88ddb653":"model = Sequential()\n\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', \n                 activation='relu', input_shape=(28, 28, 1)))\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', \n                 activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', \n                 activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', \n                 activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(10, activation='softmax'))          ","ff21f64b":"model.summary()","83f1983c":"optimizer = RMSprop(lr=0.001, epsilon=1e-8)","a05ebf7a":"model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])","c0a39fe0":"from keras.preprocessing import image\nbatch_size = 64\n\ndatagen = image.ImageDataGenerator(\n     rotation_range=8,\n     width_shift_range=0.08,\n     shear_range=0.3,\n     height_shift_range=0.08,\n     zoom_range=0.08\n)","45ef65a5":"train_batches = datagen.flow(X_train, y_train, batch_size=batch_size)\nval_batches = datagen.flow(X_val, y_val, batch_size=batch_size)","43e6bc5e":"from keras.callbacks import ReduceLROnPlateau\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss',\n                                            factor=0.5,\n                                            patience=5,\n                                            min_lr=1e-5)","222a0a5e":"epochs = 30","35f66595":"history = model.fit_generator(\n    generator=train_batches,\n    steps_per_epoch=X_train.shape[0]\/\/batch_size,\n    validation_data=val_batches,\n    validation_steps=X_val.shape[0]\/\/batch_size,\n    epochs=epochs, \n    verbose=2,\n    callbacks=[learning_rate_reduction])","89d5803b":"plt.figure(figsize=[12, 10])\nplt.subplot(211)\nplt.plot(history.history['loss'], color='b', label='Train loss')\nplt.plot(history.history['val_loss'], color='r', label='Valid loss')\nplt.subplot(212)\nplt.plot(history.history['acc'], color='b', label='Train accuracy')\nplt.plot(history.history['val_acc'], color='r', label='Valid accuracy')\nlegend = plt.legend()","9997c750":"y_pred = model.predict(X_val)\ny_pred_num = np.argmax(y_pred, axis=1)\ny_val_num = np.argmax(y_val, axis=1)\nconfusion_matrix(y_val_num, y_pred_num)","13c55352":"# predict results\nresults = model.predict(X_test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results, axis = 1)\n\nresults = pd.Series(results, name=\"Label\")","940b8499":"submission = pd.concat([pd.Series(range(1,28001), name=\"ImageId\"), results],axis = 1)\nsubmission.to_csv(\"MNIST-CNN.csv\", index=False)","7b5a9ca4":"### Learning rate annealer","efc4ba8c":"### Data visualization\n\nDisplay the digit image","9f76703b":"### Split data\nSplit data to be train set and validation set\n\nSet validation set to be 10%","18f8d109":"### Submit","0611aa35":"### One hot encoding\nEncode digit labels to one hot vector, e.g. 6 => [0,0,0,0,0,1,0,0,0,0]","317c8e66":"### CNN\n1. Design model\n2. Set optimizer","7a62d833":"### Reshape data as an image matrix\n\nReshape data array to image matrix\n         [-1, 784] => [-1, 28, 28, 1]\n         \nShape of input data for keras.Conv2D should be [samples, heigth, width, channels]","42f29246":"### Fit model","79a7b47d":"### Data augmentation","ab06f967":"### Normalization\nNormalize data from [0..255] to [0..1]","0c188687":"### Prepare data\n\n1. Read Data with pandas DataFrame\n2. Parse the \"label\" column(axis=1) as y_train\n3. Check digits distribution"}}