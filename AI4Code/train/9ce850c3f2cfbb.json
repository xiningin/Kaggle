{"cell_type":{"a1a1bc22":"code","61347dcc":"code","722f5c00":"code","17a8a1ae":"code","6e560927":"code","f9c029c1":"code","b954fd81":"code","c4bb76dd":"code","99c5a17a":"code","523387f0":"code","7735311d":"code","5850e84d":"code","65d23381":"code","08540cc0":"markdown","d300088e":"markdown","b500cd52":"markdown","3b82b983":"markdown","e5113ec8":"markdown","d16b7aa4":"markdown","db4496c9":"markdown","7d3ec80e":"markdown","bf81af10":"markdown"},"source":{"a1a1bc22":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n%matplotlib inline","61347dcc":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","722f5c00":"epochs = 12\nbatch_Size = 100\nlearning_Rate = 0.02\nweight_Decay = 0.001\nmodel_Dropout = 0.35","17a8a1ae":"def read_file(fileName):\n    \n    df = pd.read_csv('..\/input\/digit-recognizer\/' + fileName)\n    \n    if(fileName == 'train.csv'):\n        \n        #Train data\n        label = np.array(df['label'])\n        data = np.array(df[df.columns[1:]], dtype = np.float)\n        new_data = np.reshape(a = data, newshape = (data.shape[0],28,28))\n        \n        return new_data, label\n    \n    elif(fileName == 'test.csv'):\n        \n        #Test data\n        data = np.array(df,dtype = np.float)\n        new_data = np.reshape(a = data, newshape = (data.shape[0],28,28))\n        \n        return new_data","6e560927":"train_data, train_label = read_file('train.csv')\ntest_data = read_file('test.csv')","f9c029c1":"#Normalizing\ntrain_data = train_data \/ 255 #Range[0,255] to [0,1]\ntest_data = test_data \/ 255\n\n#Standarizing\ntrain_data = (train_data - 0.5) \/ 0.5\ntest_data = (test_data - 0.5) \/ 0.5\n\n#Numpy to tensor\ntrain_data = torch.from_numpy(train_data)\ntest_data = torch.from_numpy(test_data)\n\ntrain_data, test_data = train_data.type(torch.FloatTensor), test_data.type(torch.FloatTensor)\n\n#Add column dim\ntrain_data = train_data.unsqueeze_(dim=1)\ntest_data = test_data.unsqueeze_(dim=1)\n\n#Train dataset (data + labels)\ntrain_dataset = torch.utils.data.TensorDataset(train_data, torch.from_numpy(train_label))\n\n#Split the datasets\ntrain_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [35000, 7000]) #50\/10\/40\n\n#DataLoaders\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_Size, shuffle = True)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = batch_Size, shuffle = True)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size = 28000, shuffle = False) #batch_size = batch_Size,\n\n#classes = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n\nprint ('Train set: ' + str(len(train_dataset)))\nprint ('Validation set: ' + str(len(valid_dataset)))\nprint ('Test set: ' + str(len(test_data)))","b954fd81":"from random import randrange\n\ntemp = train_loader.dataset[randrange(10)][0].numpy()\ntemp = np.reshape(a=temp, newshape=(temp.shape[1], temp.shape[2]))\nplt.imshow(temp)","c4bb76dd":"class ConvNet(nn.Module):\n    \n    def __init__(self):\n        \n        super().__init__()\n        \n        #Layer sizes\n        hidden1 = 512\n        hidden2 = 128\n        hidden3 = 64\n        \n        #Convolutions & Pooling\n        self.conv1 = nn.Conv2d(1, 32, 3)   #input channel size, output channel size, kernel size\n        self.conv2 = nn.Conv2d(32, 64, 3)\n        self.pool = nn.MaxPool2d(2, 2)     #size, stride\n        \n        #Fully connected layers\n        self.fc1 = nn.Linear(1600, hidden1)\n        self.fc2 = nn.Linear(hidden1, hidden2)\n        self.fc3 = nn.Linear(hidden2, hidden3)\n        self.fc4 = nn.Linear(hidden3, 10)\n        \n        self.dropout = nn.Dropout(model_Dropout)\n    \n    def forward(self, x):\n        \n        #Feature learning\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        \n        #Classification\n        x = x.view(x.shape[0], -1)\n        \n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout(x)\n        x = F.relu(self.fc3(x))\n        x = self.dropout(x)\n        x = self.fc4(x)\n        \n        return F.log_softmax(x)","99c5a17a":"recog_model = ConvNet()#.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(recog_model.parameters(), lr=learning_Rate, weight_decay = weight_Decay)\n\nsteps = 0\n\naccuracy_list = []\ntrain_losses, valid_losses = [], []","523387f0":"for e in range (epochs):\n    \n    running_loss = 0\n    \n    for images, labels in train_loader:\n        \n        #GPU support\n        #images = images.to(device)\n        #labels = labels.to(device)\n        \n        #Forward\n        output = recog_model(images)\n        loss = criterion(output, labels)\n        \n        #Backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        \n    else:\n        \n        valid_loss = 0\n        accuracy = 0\n        \n        #Evaluate the model\n        with torch.no_grad():\n            recog_model.eval()\n            \n            for images, labels in valid_loader:\n                \n                output = recog_model(images)\n                valid_loss += criterion(output, labels)\n                \n                ps = torch.exp(output)\n                top_p, top_class = ps.topk(1, dim=1)\n                equals = top_class == labels.reshape(*top_class.shape)\n                \n                accuracy = torch.mean(equals.type(torch.FloatTensor))\n                \n        print('Accuracy ' + str(e+1) + ': ' + str(accuracy.item() * 100) + '%')\n                \n        #Store values for plotting\n        accuracy_list.append(accuracy.item() * 100)\n        train_losses.append(running_loss \/ len(train_loader))\n        valid_losses.append(valid_loss \/ len(valid_loader))\n\n#Print the losses\nprint('Final training loss: ' + str(train_losses[epochs-1]))\nprint('Final validation loss: ' + str(valid_losses[epochs-1]))\n        \n### Plot ###\nxAxis = []\nfor i in range(epochs):\n    xAxis.append(i+1)\n    \n#Accuracy graph\nplt.plot(xAxis, accuracy_list)\nplt.ylabel('%')\nplt.xlabel('Epoch')\nplt.title('Accuracy')\nplt.show()\n\n#Loss graph\nplt.plot(xAxis, train_losses, 'r--', xAxis, valid_losses, 'g--')\nred_line = mpatches.Patch(color='red', label='train loss')\ngreen_line = mpatches.Patch(color='green', label='valid loss')\nplt.legend(handles=[red_line, green_line])\nplt.xlabel('Epoch')\nplt.title('Loss')\nplt.show()","7735311d":"#Evaluate the model\nwith torch.no_grad():\n    recog_model.eval()\n            \n    for images in test_loader:\n              \n        output = recog_model(images)\n        ps = torch.exp(output)\n        top_p, top_class = ps.topk(1, dim=1)\n\nprint('Done')        ","5850e84d":"#results = recog_model.predict(test_loader)\nresults = np.argmax(output, axis = 1) #results por output\nresults = pd.Series(results, name = 'Label')\nresults","65d23381":"submission = pd.concat([pd.Series(range(1, 28001), name = 'ImageId'), results], axis = 1)\nsubmission.to_csv('submission.csv', index = False)","08540cc0":"# **5. Visualize random training sample**","d300088e":"# **8. Submission (Test)**","b500cd52":"# **3. Importing data**","3b82b983":"# **1. Libraries & Configuration**","e5113ec8":"# **4. Preprocessing Data**","d16b7aa4":"# **7. Model (Training & Validation)**","db4496c9":"# **6. Implementing CNN (Architecture)**","7d3ec80e":"# **2. Hyperparameters**","bf81af10":"This Python 3 environment comes with many helpful analytics libraries installed\nIt is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n\nInput data files are available in the read-only \"..\/input\/\" directory\nFor example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nYou can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \nYou can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session"}}