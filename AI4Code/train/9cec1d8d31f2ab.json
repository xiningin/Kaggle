{"cell_type":{"2d6182d6":"code","273e7f41":"code","4fa0d6ec":"code","eb25bb47":"code","8d73ec2e":"code","f4864945":"code","5e827407":"code","72bc95cc":"code","85666093":"code","989a4d60":"code","a8e0ddc1":"code","c3dc08f3":"code","fd6a1933":"code","e2adbc03":"code","26b8dd41":"code","6980ab1d":"code","b216c424":"code","e15734f1":"code","63fd689f":"code","52a833e9":"code","de11a792":"code","a6b74b15":"code","8a65d939":"code","fbd74d59":"code","088e44c3":"code","92850d32":"code","bcec18ff":"code","0159d7bb":"code","738db3ee":"code","6b5860da":"code","d04e0abd":"code","5b4412ae":"code","86d900b0":"code","2596866c":"code","8393bbbd":"code","39370f55":"code","37301a10":"code","ace67ee6":"code","69c6b8fc":"code","432cd808":"code","00cb54bf":"code","7653d514":"code","0124f44e":"code","11013a0d":"code","35c5644d":"code","a33016fd":"code","4d7905d1":"code","43bdf76d":"code","4e3cbbcd":"code","2a521c07":"code","52ea1ae8":"code","4cbf973d":"code","24566e84":"code","f695c60c":"code","40e252dc":"code","746bab0a":"code","411262dc":"code","0ec5d2d9":"code","10251fe4":"code","f8d0f480":"code","f1e608c0":"code","3bd26d50":"code","297f542e":"code","f7141999":"code","09a66e2d":"code","f1bf7578":"code","e802c6f4":"code","1f7fed63":"code","a5b47731":"code","683aaf2b":"markdown","a9e7ff60":"markdown","34f68f4f":"markdown","469719ad":"markdown","194b57f7":"markdown","2f910844":"markdown","c1e2d16a":"markdown","b5837193":"markdown","ab90b0b7":"markdown","cdfb1788":"markdown","5752824e":"markdown","6391d065":"markdown"},"source":{"2d6182d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","273e7f41":"!pip install feature_engine\n!pip install autoviml\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport pandas, scipy, numpy\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import Binarizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom feature_engine.outlier_removers import Winsorizer","4fa0d6ec":"!pip install autoviz","eb25bb47":"from autoviz.AutoViz_Class import AutoViz_Class\nAV=AutoViz_Class()","8d73ec2e":"import pandas as pd\ntest = pd.read_csv(\"..\/input\/test.csv\")\ntest_label = pd.read_csv(\"..\/input\/test_label.csv\",header=None)\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntrain_label = pd.read_csv(\"..\/input\/train_label.csv\",header=None)","f4864945":"train_label=train_label.rename(columns={0:'Total_booking'})\ntest_label=test_label.rename(columns={0:'Total_booking'})","5e827407":"train=pd.concat([train,train_label],axis=1)\ntest=pd.concat([test,test_label],axis=1)","72bc95cc":"train.to_csv('\/kaggle\/working\/train_with_label.csv')\ntest.to_csv('\/kaggle\/working\/test_with_label.csv')","85666093":"train['source']='train'\ntest['source']='test'\nmain_data=pd.concat([train,test],axis=0)\nmain_data.head()","989a4d60":"\nmain_data.to_csv('\/kaggle\/working\/main_data_with_label.csv')","a8e0ddc1":"train.columns","c3dc08f3":"dft=AV.AutoViz('\/kaggle\/working\/train_with_label.csv',sep=',',depVar=\"\",dfte=None,header=1,verbose=1,\n              lowess=False,chart_format='svg',max_rows_analyzed=80000,max_cols_analyzed=50)","fd6a1933":"dft=AV.AutoViz('\/kaggle\/working\/train_with_label.csv',sep=',',depVar=\"Total_booking\",dfte=None,header=1,verbose=1,\n              lowess=False,chart_format='svg',max_rows_analyzed=80000,max_cols_analyzed=50)","e2adbc03":"main_data.isnull().sum()","26b8dd41":"#Here we can say there is no missing values so no need of missing value analysis\ntrain.isnull().sum()","6980ab1d":"test.isnull().sum()","b216c424":"##Task=1:Visualize data using different visualizations to generate interesting insights\ntrain.info()","e15734f1":"train.head()","63fd689f":"train.describe()\n#This command gives us the info about the all continous variables in the dataframe and here we can see the max,mean,min and total count of the variables with it different set of percentiles\n#IF we sees the variables all the variables exxept the dependent variable that is total booking all are following gaussian disturbution as the 50% percentile is closer to that of mean","52a833e9":"#No of distcrete  and continous variables in the dataframe\ndiscrete_vars=[x for x in main_data.columns if len(main_data[x].unique())<10  and x!=['datetime']]\nprint(discrete_vars)\nreamining_vars=[var for var in main_data.columns if var not in discrete_vars]\ncontinous_vars=[var for var in reamining_vars if main_data[var].dtypes!='O' and var not in ['datetime']]\nprint(continous_vars)","de11a792":"#For convience we are going to use a custom class fillled with data analysis techniques\n\nclass DataAnalysis(object):\n    '''This class represents the steps to be taken in the data analysis '''\n    \n    def __init__(self, name):\n        \"\"\"Return a Customer object whose name is *name*.\"\"\" \n        self.name = name\n\n    def barplot(self,x,column_name):\n        '''barplot of count of discrete variable in the dataset'''\n        figure=plt.figure(figsize=[10,6])\n        sns.set(style = 'whitegrid')\n        sns.barplot(x[column_name].value_counts().index,x[column_name].value_counts())\n        plt.xlabel(column_name)\n        plt.ylabel('Count')\n        plt.title(format('Distribution of '+column_name),fontsize = 20)\n        plt.plot()\n    \n    def histogram(self,x,column_name):\n        '''This is used to find out the distubution of the continous variables in the dataset'''\n        figure=plt.figure(figsize=[10,6])\n        sns.distplot(x[column_name],label=column_name)\n        plt.plot()\n    \n    def corelation_categorical_numerical(self,x,categorical_column,numerical_column):\n        '''Find out the corelation between the one categorical and numerical variable'''\n        group_data=x.groupby([categorical_column])[numerical_column].mean().sort_values(ascending=True).reset_index()\n        figure=plt.figure(figsize=[9,8])\n        sns.barplot(group_data[categorical_column],group_data[numerical_column])\n        plt.xlabel(categorical_column)\n        plt.ylabel(numerical_column)\n        plt.title('Frequency occurence of each transaction type')\n        plt.plot()\n\n    def piechart(self,x,output_categorical_column):\n        '''Pie chart of the output dependent variable.It is basically has binary values(0 and 1)'''\n        space = np.ones(2)\/10\n        x[output_categorical_column].value_counts().plot(kind = 'pie', fontsize=14, autopct='%3.1f%%', wedgeprops=dict(width=0.15), \n                                    shadow=True, startangle=180, figsize=(10, 10), legend=True)\n        #plt.legend(['Not Fraud', 'Fraud'])\n        #plt.ylabel('Category')\n        plt.title(output_categorical_column)\n    \n    def boxplot(self,x,output_categorical_column,categorical_column,numerical_column):\n        '''Box plot of the one continous variable with respect two categorical variables in the dataset to visualize outliers'''\n        figure=plt.figure(figsize=[9,8])\n        sns.boxplot(hue = output_categorical_column, x = categorical_column, y = numerical_column, data = x[x[numerical_column] < 2e5])\n        plt.xlabel(categorical_column)\n        plt.ylabel(numerical_column)\n        plt.plot()\n\n    def correlationmatrix(self,x):\n        '''Correlation martix of the dataset'''\n        figure = plt.figure(figsize = [13, 10])\n        sns.heatmap(x.corr(), annot = True, cmap = 'YlGnBu')","a6b74b15":"#We are going make a custom class for preprocessing.\n\nclass Datapreprocessing(object):\n    '''Classes with different functions which helps in data preprocessing'''\n    \n    def __init__(self, name):\n        \"\"\"Return a Customer object whose name is *name*.\"\"\" \n        self.name = name\n    \n    def scaling_data_min_max(self,data):\n        '''Appplication of min max scaler which changes the features between 0 to 1'''\n        scalar=MinMaxScaler()\n        scaled_data=scalar.fit_transform(data)\n        return scaled_data\n    \n    def standard_scaling_data(self,data):\n        '''Application of min max scaler which changes the features between 0 to 1'''\n        standard_scalar=StandardScaler()\n        standard_data=standard_scalar.fit_transform(data)\n        return standard_data\n    \n    def normal_data(self,data):\n        '''Application of the normalizer for normalizing the data'''\n        normal=Normalizer()\n        normal_data=normal.fit_transform(data)\n        return normal_data\n    def binarizer(self,data):\n        '''Application of binarizer over the data'''\n        binarizer=Binarizer()\n        binary_data=binarizer.fit_transform(data)\n        return binary_data\n    def One_Hot_Encoder(self,data,cols_to_remove):\n        '''Application of onehotencoding over the data'''\n        categorical_features=data.dtypes==object\n        categorical_features.drop(cols_to_remove)\n        one_hot = OneHotEncoder(categorical_features = categorical_features, sparse=False )\n        one_hot_data=one_hot.fit_transform(data) # IT will return numpy array.\n        return one_hot_data\n    \n    def label_encoder(self,data,cols_to_remove):\n        '''Application of label encoder to the cols'''\n        categorical_features=data.dtypes==object\n        categorical_cols=data.columns[categorical_features].tolist()\n        categorical_cols=[x for x in categorical_cols if x not in cols_to_remove]\n        data[categorical_cols] = data[categorical_cols].apply(lambda col: label.fit_transform(col))\n        return data\n    \n    \n    \n    def create_dummies(self,x,columns_names_to_be_passed):\n        '''Create the dummies or one hot encoding for the categorical variables by dropping the first element to avoid dummy trap'''\n        z=pd.get_dummies(data=x,columns=columns_names_to_be_passed,drop_first=True)\n        return z\n        \n    def find_missing_info_in_categorical(X_train):\n        '''make a list of the categorical variables that contain missing values and  print the variable name and the percentage of missing values'''\n        vars_with_na = [var for var in X_train.columns if X_train[var].isnull().sum()>1 and X_train[var].dtypes=='O']\n\n       \n        for var in vars_with_na:\n            print(var, np.round(X_train[var].isnull().mean(), 3),  ' % missing values')\n    def fill_categorical_na(df, var_list):\n        '''fill the categorical values with missing string'''\n        X = df.copy()\n        X[var_list] = df[var_list].fillna('Missing')\n        return X\n    def fill_categorical_median(df,var_list):\n        '''fill the categorical values with median'''\n        X=df.copy()\n        X[var_list]=df[var_list].fillna(df[var_list].mean,axis=0)\n    def find_missing_info_in_numerical(X_train):\n        '''make a list of the numerical variables that contain missing values and  print the variable name and the percentage of missing values'''\n        vars_with_na = [var for var in data.columns if X_train[var].isnull().sum()>1 and X_train[var].dtypes!='O']\n        \n        for var in vars_with_na:\n            print(var, np.round(X_train[var].isnull().mean(), 3),  ' % missing values')\n        return vars_with_na\n    \n    def fill_numerical_mode(X_train,vars_with_na):\n        '''calculate the mode and replace the numeical data with mode'''\n        for var in vars_with_na:\n    \n       \n            mode_val = X_train[var].mode()[0]\n    \n            X_train[var+'_na'] = np.where(X_train[var].isnull(), 1, 0)\n            X_train[var].fillna(mode_val, inplace=True)\n         \n    def fill_numerical_mode(X_train,vars_with_na):\n        '''calculate the mode and replace the numeical data with mean'''\n        for var in vars_with_na:\n    \n      \n            mode_val = X_train[var].mode()[0]\n    \n            X_train[var+'_na'] = np.where(X_train[var].isnull(), 1, 0)\n            X_train[var].fillna(mode_val, inplace=True)\n    \n    \n\n\n\n\n\n","8a65d939":"categorical_features=train.dtypes==object\ncategorical_cols=train.columns[categorical_features].tolist()\ncategorical_cols=[x for x in categorical_cols if x not in ['datetime']]","fbd74d59":"data_analysis=DataAnalysis(train)\nfor var in discrete_vars:\n    data_analysis.barplot(train,var)\n    \n#For the first plot chart of season we can see the frequency of the all seasons are reasonably balanced in  the dataset .So this implies train dataset is pretty balanced\n#For the second plot and third plot we are finding the concentration of holidays which is evident because the concentration of holidays is less\n#For the fouth plot it is evident that clear+few clouds are maximum and Heavy rain+thunderstorm category is less","088e44c3":"#checking the disturbution of the continous variables\nfor i, col in enumerate(continous_vars):\n    plt.figure(i)\n    data_analysis.histogram(train,col)\n\n# From the graph we can see that most of the features folllows gaussian distubution except the wind speed and total booking.","92850d32":"data_analysis=DataAnalysis(train)\nfor i,var in enumerate(discrete_vars):\n    plt.figure(i)\n    data_analysis.piechart(train,var)\n    \n# representation of the discrete vars in pie chart\/donuts to find out the concenration of each categories in the discrete vars","bcec18ff":"#relationship of the target variable with other discrete variables\nfor i,col in enumerate(discrete_vars):\n    plt.figure(i)\n    data_analysis.corelation_categorical_numerical(train,col,numerical_column='Total_booking')\n    \n#In the first plot between total booking and season we can see that spring has lowest number of booking mean whereas the fall has the highest booking mean.This gives an idea of the overall seasonality trend of booking of the customers.\n#In the second and third plot betwen holiday and total booking holiday booking concenration mean is more by only 5 units which gives us the idea that holidays bookings are slightly more than working days bookings\n#In terms of waether we can clearly see customers prefer booking on clear weather rather thatt rain weather.","0159d7bb":"data_analysis.correlationmatrix(train)\n#From the correlation matrix we found out that temp.atemp are highly corealted (i.e is 0.98),next in the order the is the #humdidty and windspeed which are correalted upto 0.32 with a inverse realtionship as it is sign is negative(-).From the given #analysis we can conclude that atemp and temp can be considered as one column instead of two columns along with humidity and #windspeed have good correaltion value wrt to the target variable-Total Booking.","738db3ee":"#Let us do an outler analysis\nclass OutlierAnalysis(object):\n    '''Classes with different functions which helps in outlier analysis'''\n    \n    def __init__(self, name):\n        \"\"\"Return a Customer object whose name is *name*.\"\"\" \n        self.name = name\n    \n    def diagnostic_plots(self,df, variable):\n        '''function takes a dataframe (df) and the variable of interest as arguments'''\n\n        # define figure size\n        plt.figure(figsize=(16, 4))\n\n        # histogram\n        plt.subplot(1, 3, 1)\n        sns.distplot(df[variable], bins=40)\n        plt.title('Histogram')\n\n        # Q-Q plot\n        plt.subplot(1, 3, 2)\n        stats.probplot(df[variable], dist=\"norm\", plot=plt)\n        plt.ylabel('Variable quantiles')\n\n        # boxplot\n        plt.subplot(1, 3, 3)\n        sns.boxplot(y=df[variable])\n        plt.title('Boxplot')\n\n        plt.show()\n    \n    def find_skewed_boundaries(self,df, variable, distance):\n\n        '''Let's calculate the boundaries outside which sit the outliers for skewed distributions.distance passed as an argument, gives us the option to estimate 1.5 times or 3 times the IQR to calculate the boundaries.'''\n\n        IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n\n        lower_boundary = df[variable].quantile(0.25) - (IQR * distance)\n        upper_boundary = df[variable].quantile(0.75) + (IQR * distance)\n\n        return upper_boundary, lower_boundary\n\n    def capper_skewed(self,data,input_param):\n        windsoriser = Winsorizer(distribution='skewed', # choose skewed for IQR rule boundaries or gaussian for mean and std\n                          tail='both', # cap left, right or both tails \n                          fold=1.5,\n                          variables=input_param)\n\n        data=windsoriser.fit_transform(data)\n        return data\n        \n    \n    def find_boundaries(self,df, variable):\n\n        ''' the boundaries are the quantiles '''\n\n        lower_boundary = df[variable].quantile(0.05)\n        upper_boundary = df[variable].quantile(0.95)\n\n        return upper_boundary, lower_boundary\n    \n    def capper_quantiles(self,data,input_param):\n        windsoriser = Winsorizer(distribution='quantiles', # choose skewed for IQR rule boundaries or gaussian for mean and std\n                          tail='both', # cap left, right or both tails \n                          fold=1.5,\n                          variables=input_param)\n\n        data=windsoriser.fit_transform(data)\n        return data\n        \n    def find_normal_boundaries(self,df, variable, distance):\n\n        '''calculate the boundaries outside which sit the outliers for a Gaussian distribution'''\n\n        upper_boundary = df[variable].mean() + distance * df[variable].std()\n        lower_boundary = df[variable].mean() - distance * df[variable].std()\n\n        return upper_boundary, lower_boundary\n\n    def capper_gaussian(self,data,input_param):\n        windsoriser = Winsorizer(distribution='gaussian', # choose skewed for IQR rule boundaries or gaussian for mean and std\n                          tail='both', # cap left, right or both tails \n                          fold=1.5,\n                          variables=input_param)\n\n        data=windsoriser.fit_transform(data)\n        return data\n    ","6b5860da":"Out_analysis=OutlierAnalysis(train)\nOut_analysis.diagnostic_plots(train, 'temp')","d04e0abd":"for num,var in enumerate(continous_vars):\n    print(num,var)\n    Out_analysis.diagnostic_plots(train, var)\n\n#Friom the outlier analysis we can see two columns windspeed and total_booking at the right tails as we can see in the graph.We can do outlier treatment data to the data.","5b4412ae":"Out_analysis.diagnostic_plots(main_data, 'humidity')","86d900b0":"Out_analysis.diagnostic_plots(train, 'windspeed')","2596866c":"Out_analysis.diagnostic_plots(train, 'Total_booking')","8393bbbd":"# find limits for windspeed\n\nwindspeed_upper_limit, windspeed_lower_limit = Out_analysis.find_skewed_boundaries(train, 'windspeed', 1.5)\nwindspeed_upper_limit, windspeed_lower_limit","39370f55":"# find limits for windspeed\n\nTotal_booking_upper_limit, Total_booking_lower_limit = Out_analysis.find_skewed_boundaries(train, 'Total_booking', 1.5)\nTotal_booking_upper_limit, Total_booking_lower_limit","37301a10":"# Now let's replace the outliers by the maximum and minimum limit\niqr=train.copy()\n\niqr['windspeed']= np.where(train['windspeed'] > windspeed_upper_limit, windspeed_upper_limit,\n                       np.where(train['windspeed'] < windspeed_lower_limit, windspeed_lower_limit, train['windspeed']))\n\niqr['Total_booking']= np.where(train['Total_booking'] > Total_booking_upper_limit, Total_booking_upper_limit,\n                       np.where(train['Total_booking'] < Total_booking_lower_limit, Total_booking_lower_limit, train['Total_booking']))\n","ace67ee6":"#Checking the outliers after analysis\nfor num,var in enumerate(continous_vars):\n    print(num,var)\n    Out_analysis.diagnostic_plots(iqr, var)\n#Now we can no outliers in windspeed and total booking columns but the variable distribution is distorted quite a bit.","69c6b8fc":"#apply capper skewed\ncapper_skewed=Out_analysis.capper_skewed(train,continous_vars)\n\n\n#'temp', 'atemp', 'humidity', 'windspeed', 'Total_booking'","432cd808":"#Checking the outliers after analysis\nfor num,var in enumerate(continous_vars):\n    print(num,var)\n    Out_analysis.diagnostic_plots(train, var)\n    \n#After we applying the skewed disturbution in the feature engine it helps to keep the disturbution correct for two columns","00cb54bf":"#apply capper skewed\ncapper_skewed=Out_analysis.capper_gaussian(train,continous_vars)\n\n\n#'temp', 'atemp', 'humidity', 'windspeed', 'Total_booking'","7653d514":"#Checking the outliers after analysis\nfor num,var in enumerate(continous_vars):\n    print(num,var)\n    Out_analysis.diagnostic_plots(capper_skewed, var)","0124f44e":"#apply capper skewed\ncapper_quantiles=Out_analysis.capper_quantiles(train,continous_vars)","11013a0d":"#Checking the outliers after analysis\nfor num,var in enumerate(continous_vars):\n    print(num,var)\n    Out_analysis.diagnostic_plots(capper_quantiles, var)","35c5644d":"# find limits for windspeed\n\nhumidity_upper_limit, humidity_lower_limit = Out_analysis.find_skewed_boundaries(main_data, 'windspeed', 1.5)\nwindspeed_upper_limit, windspeed_lower_limit\n\n\nwindspeed_upper_limit, windspeed_lower_limit = Out_analysis.find_skewed_boundaries(main_data, 'windspeed', 1.5)\nwindspeed_upper_limit, windspeed_lower_limit\n\n\nTotal_booking_upper_limit, Total_booking_lower_limit = Out_analysis.find_skewed_boundaries(main_data, 'Total_booking', 1.5)\nTotal_booking_upper_limit, Total_booking_lower_limit","a33016fd":"#Applying all three methods output is almost same for all the cases,so we can go ahead with any of the methods for the outlier analysis.\n\nmain_data['humidity']= np.where(main_data['humidity'] > windspeed_upper_limit, windspeed_upper_limit,\n                       np.where(main_data['humidity'] < windspeed_lower_limit, windspeed_lower_limit, main_data['humidity']))\n\nmain_data['windspeed']= np.where(main_data['windspeed'] > windspeed_upper_limit, windspeed_upper_limit,\n                       np.where(main_data['windspeed'] < windspeed_lower_limit, windspeed_lower_limit, main_data['windspeed']))\n\nmain_data['Total_booking']= np.where(main_data['Total_booking'] > Total_booking_upper_limit, Total_booking_upper_limit,\n                       np.where(main_data['Total_booking'] < Total_booking_lower_limit, Total_booking_lower_limit, main_data['Total_booking']))\n","4d7905d1":"Out_analysis.diagnostic_plots(main_data, 'windspeed')","43bdf76d":"Out_analysis.diagnostic_plots(main_data, 'Total_booking')\n","4e3cbbcd":"#feature enginnering\ndata_preprocess=Datapreprocessing(main_data)\ndummy=data_preprocess.create_dummies(main_data,['season','weather'])","2a521c07":"train.columns","52ea1ae8":"from autoviml.Auto_ViML import Auto_ViML\n\ntarget='Total_booking'","4cbf973d":"sample_submission=''\nscoring_parameter = 'balanced-accuracy'","24566e84":"m, feats, trainm, testm = Auto_ViML(train, target, test, sample_submission,\n                                    scoring_parameter=scoring_parameter,\n                                    hyper_param='GS',feature_reduction=True,\n                                     Boosting_Flag=True,Binning_Flag=False,\n                                    Add_Poly=0, Stacking_Flag=False,                                    \n                                    Imbalanced_Flag=False, \n                                    verbose=1)","f695c60c":"#Now lets do it in old fashiioned way:\n#Feature Engineering\nfor vars in dummy.columns:\n    print(\"====================== \"+vars+\" ======================\")\n    print(dummy[vars].unique())\ndummy.head()\n\n\n\n","40e252dc":"from sklearn.linear_model import LassoCV,RidgeCV,Ridge,Lasso\ndummy=dummy.drop(['datetime'],axis=1)\ntrain=dummy[dummy['source']=='train']\ntest=dummy[dummy['source']=='test']","746bab0a":"train.drop('source',axis=1,inplace=True)\ntest.drop('source',axis=1,inplace=True)","411262dc":"X_train=train.drop('Total_booking',axis=1)\ny_train=train[['Total_booking']]\nX_test=test.drop('Total_booking',axis=1)\ny_test=test[['Total_booking']]\n","0ec5d2d9":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import mutual_info_classif, mutual_info_regression\nfrom sklearn.feature_selection import SelectKBest, SelectPercentile\nfrom sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import f_classif, f_regression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import Lasso, LogisticRegression\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.metrics import roc_auc_score,r2_score\nimport xgboost as xgb","10251fe4":"\n def feature_shuffling_classification(self,X_train,y_train,X_test,y_test):\n    model=xgb.XGBClassifier(nthread=10,n_estimators=500,learning_rate=0.01,max_depth=4,random_state=123)\n    model.fit(X_train,y_train)\n    y_pred_test=model.predict(X_test)\n    auc_roc_score_all=auc_roc_score(y_test,y_pred_test)\n    print('AUC_ROC score of all features=%f'%(auc_roc_score_all))\n\n    print('train auc_roc score:',auc_roc_score(y_train,(model.predict_proba(X_train))[:,1]))\n    print('test auc_roc score:',auc_roc_score(y_test,(model.predict_proba(X_test))[:,1]))\n\n    train_auc_roc=auc_roc_score(y_train,model.predict_proba(X_train)[:,1])\n\n    feature_dict={}\n\n    for feature in X_train.columns:\n        X_train_c=X_train.copy()\n        X_train_c[feature] = X_train_c[feature].sample(frac=1).reset_index(\n            drop=True)\n\n        # make prediction with shuffled feature and calculate roc-auc\n        shuff_auc_roc = auc_roc_score(y_train,\n                                  (model.predict_proba(X_train_c.fillna(0)))[:,1])\n\n        # save the drop in roc-auc\n        feature_dict[feature] = (train_auc_roc - shuff_auc_roc)\n\n    feature_importance = pd.Series(feature_dict).reset_index()\n    feature_importance.columns = ['feature', 'auc_drop']\n    feature_importance.sort_values(by=['auc_drop'], ascending=False, inplace=True)\n    feature_importance.head()\n    temp = pd.Series(feature_importance[feature_importance.auc_drop>0]['auc_drop'])\n    temp.index = pd.Series(feature_importance[feature_importance.auc_drop>0]['feature'])\n\n    pd.Series(temp).plot.bar(figsize=(15,6))\n    selected_features = feature_importance[feature_importance.auc_drop>0]['feature']\n    return selected_features","f8d0f480":"#Feature selection class\nclass FeatureSelection(object):\n    '''This class represents the steps to be taken in the Feature Selection '''\n    \n    def __init__(self, name):\n        \"\"\"Return a Customer object whose name is *name*.\"\"\" \n        self.name = name\n        \n    def variancethreshold(self,X_train,X_test):\n        '''It finds the columns with are constant and provides the output in the form of number of features that \n        are not constant '''\n        if X_train.isnull().sum()==0 and X_test.isnull().sum()==0:\n            sel=VarianceThreshold(threshold=0).fit(X_train)\n            constant=sum(sel.get_support())\n            print([x for x in X_train.columns if x  not in X_train.columns[sel.get_support()]])\n            X_train = sel.transform(X_train)\n            X_test = sel.transform(X_test)\n            return X_train,X_test\n        else:\n            print('The training set has missing values')\n            \n    def varisncethreshold_std(self,X_train,X_test):\n        '''Using the to remove columns with constant variables'''\n        if X_train.isnull().sum()==0 and X_test.isnull().sum()==0:\n            constant_features=[x for x in X_train.columns if X_train.columns[feat].std()==0]\n            X_train.drop(labels=constant_features, axis=1, inplace=True)\n            X_test.drop(labels=constant_features, axis=1, inplace=True)\n            print(X_train.shape, X_test.shape)\n            return X_train,X_test\n        else:\n            print('The training set has missing values')\n            \n    def variancethreshold_quasi(self,X_train,X_test):\n        '''Variance threshold from sklearn is a simple baseline approach to feature selection. It removes all features which variance doesn\u2019t meet some threshold. By default, it removes all zero-variance features, i.e., features that have the same value in all samples. '''\n        if X_train.isnull().sum()==0 and X_test.isnull().sum()==0:\n            sel=VarianceThreshold(threshold=0.01).fit(X_train)\n            constant=sum(sel.get_support())\n            print([x for x in X_train.columns if x  not in X_train.columns[sel.get_support()]])\n            X_train = sel.transform(X_train)\n            X_test = sel.transform(X_test)\n            return X_train,X_test\n        else:\n            print('The training set has missing values')\n            \n    def remove_duplicates(self,X_train,X_test):\n        '''Removing duplicate features'''\n        if X_train.isnull().sum()==0 and X_test.isnull().sum()==0:\n            X_train_t, X_test_t=X_train.T, X_test.T\n            print(X_train_t.duplicated.sum())\n            duplicated_features = X_train_t[X_train_t.duplicated()].index.values\n            X_train=X_train_t.duplicated(keep='first').T\n            X_test = X_test_t.duplicated(keep='first').T\n            return X_train,X_test\n        else:\n            print('The training set has missing values')\n    \n    def correlation(self,X_train,X_test,threshold):\n        '''Removal of columns which are highly correlated'''\n        col_corr=set()\n        corr_matrix=dataset.corr()\n        for i in range(corr_matrix.columns):\n            for j in range(i):\n                if abs(corr_matrix.iloc[i,j])>threshold:\n                    colname=corr_matrix.columns[i]\n                    col_corr.add(colname)\n        X_train.drop(labels=col_corr,axis=1,inplace=True)\n        X_test.drop(labels=col_corr,axis=1,inplace=True)\n        return X_train,X_test\n    \n    def corrmat(self,X_train):\n        '''Finding the features which are highly correalted using correlation matrix'''\n        corrmat=X_train.corr().abs().unstack().sort_values(ascending=False)\n        corrmat=corrmat[(corrmat>=0.8)& (corrmat<1)]\n        corrmat=pd.DataFrame(corrmat).reset_index()\n        corrmat.columns = ['feature1', 'feature2', 'corr']\n        grouped_feature_ls=[]\n        correlated_features=[]\n        for feature in corrmat.feature1.unique():\n            if feature not in grouped_feature_ls:\n                correlated_block=corrmat[corrmat.feature1==feature]\n                grouped_feature_ls=grouped_feature_ls +list(correlated_block.feature2.unique())+[feature]\n                correlated_features.append(correlated_block)\n        print('found {} correlated groups'.format(len(correlated_features)))\n        print('out of {} total features'.format(X_train.shape[1]))\n        return correlated_features\n    \n    def feature_importance_rf():\n        '''Random forest feature importance '''\n        rf=RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n        rf.fit(X_train,y_train)\n        features=list(X_train.columns)\n        importance = pd.concat(\n                [pd.Series(features),\n             pd.Series(rf.feature_importances_)], axis=1)\n\n        importance.columns = ['feature', 'importance']\n        importance.sort_values(by='importance', ascending=False)\n        return importance\n    \n    def mutual_info_classification(self,X_train,y_train):\n        '''calculate the mutual information between the variables and the target this returns the mutual information value of each feature\n        The smaller the value the less information the feature has about the target'''\n        \n        mi=pd.Series(mutual_info_classif(X_train.fillna(0),y_train))\n        mi.index=X_train.columns\n        mi.sort_values(ascending=False).plot.bar(figsize=(20,8))\n        sel=SelectKBest(mutual_info_classif,k=10).fit(X_train,y_train)\n        X_train=X_train.columns[sel.get_support()]\n        return X_train\n    \n    def mutual_info_regression(self,X_train,y_train):\n        '''calculate the mutual regression between the variables and the target this returns the mutual information value of each feature\n        The smaller the value the less information the feature has about the target'''\n        mi=pd.Series(mutual_info_regression(X_train.fillna(0),y_train))\n        mi.index=X_train.columns\n        mi.sort_values(ascending=False).plot.bar(figsize=(20,8))\n        sel = SelectPercentile(mutual_info_regression, percentile=10).fit(X_train.fillna(0), y_train)\n        X_train=X_train.columns[sel_.get_support()]\n        return X_train\n    \n    def fischer_score(self,X_train,X_test):\n        ''' For Fisher score(ONLY APPLIED ON CATEGORICAL VARIABLES),the smaller the p_value, the more significant the feature is to predict the target\n        Note: One thing to keep in mind when using Fisher score or univariate selection methods, is that in very big datasets, \n        most of the features will show a small p_value, and therefore look like they are highly predictive. \n        This is in fact an effect of the sample size. So care should be taken when selecting features using these procedures. \n        An ultra tiny p_value does not highlight an ultra-important feature, it rather indicates that the dataset contains \n        too many samples.Finally, in this demonstration, we could then combine this procedure with SelectKBest or SelectPercentile,'''\n        f_score=chi(X_train.fillna(0),y_train)\n        pvalues=pd.Series(f_score[1])\n        pvalues.index=X_train.columns\n        pvalues=pvalues.sort_values(ascending=False)\n        return pvalues\n    \n    def univariate_selection_classfication(self,X_train,X_test):\n        '''Univariate feature selection works by selecting the best features based on univariate statistical tests (ANOVA). \n        The methods based on F-test estimate the degree of linear dependency between two random variables. They assume \n        a linear relationship between the feature and the target. These methods also assume that the variables follow a \n        Gaussian distribution.Remember that the lower the p_value, the most predictive the feature is in principle. There \n        are a few features that do not seem to have predictive power according to this tests, which are those on the left \n        with pvalues above 0.05. Given that typically in statistics one uses a pvalue of 0.05 as a cut-off, I am inclined \n        to believe that those features with pvalue > 0.05 are indeed not important. However, keep in mind that this test \n        assumes a linear relationship, so it might also be the case that the feature is related to the target but not in \n        a linear manner.in big datasets it is not unusual that the pvalues of the different features are really small. This\n        does not say as much about the relevance of the feature. Mostly it indicates that it is a big the dataset.'''\n        \n        univariate=f_classif(X_train.fillna(0),y_train)\n        univariate=ps.Series(univariate[1])\n        univariate.index=X_train.columns\n        univariate=univariate.sort_values(ascending=False).plot.bar(figsize=(20, 8))\n        sel = SelectKBest(f_classif, k=10).fit(X_train.fillna(0), y_train)\n        X_train=X_train.columns[sel.get_support()]\n        return X_train\n    \n    def univariate_selection_regression(self,X_train,X_test):\n        '''Univariate feature selection works by selecting the best features based on univariate statistical tests (ANOVA). \n        The methods based on F-test estimate the degree of linear dependency between two random variables. They assume \n        a linear relationship between the feature and the target. These methods also assume that the variables follow a \n        Gaussian distribution.Remember that the lower the p_value, the most predictive the feature is in principle. There \n        are a few features that do not seem to have predictive power according to this tests, which are those on the left \n        with pvalues above 0.05. Given that typically in statistics one uses a pvalue of 0.05 as a cut-off, I am inclined \n        to believe that those features with pvalue > 0.05 are indeed not important. However, keep in mind that this test \n        assumes a linear relationship, so it might also be the case that the feature is related to the target but not in \n        a linear manner.in big datasets it is not unusual that the pvalues of the different features are really small. This\n        does not say as much about the relevance of the feature. Mostly it indicates that it is a big the dataset.'''\n        \n        univariate=f_regression(X_train.fillna(0),y_train)\n        univariate=ps.Series(univariate[1])\n        univariate.index=X_train.columns\n        univariate=univariate.sort_values(ascending=False).plot.bar(figsize=(20, 8))\n        sel=SelectPercentile(f_regression,percentile=10).fit(X-train.fillna(0),y_train)\n        X_train=X_train.columns[sel.get_support()]\n        return X_train\n    \n    \n    def recursive_feature_selection(self,X_train,X_test):\n        '''Random Forests assign equal or similar importance to features that are highly correlated. In addition, when features are correlated, the importance assigned is \n        lower than the importance attributed to the feature itself, should the tree be built without the correlated counterparts.The cycle is as follows:\n\n            1.Build random forests using all features\n            2.Remove least important feature\n            3.Build random forests and recalculate importance\n            4.Repeat until a criteria is met'''\n\n        sel=RFE(RandomForestClassifier(n_estimators=100),n_features_to_select=10)\n        sel.fit(X_train.fillna(0),y_train)\n        selected_feat = X_train.columns[(sel_.get_support())]\n        return selected_feat\n    \n    \n    def Lasso(self,X_train,y_train):\n        '''Regularisation consists in adding a penalty to the different parameters of the machine learning model to reduce the freedom of the \n        model and in other words to avoid overfitting. In linear model regularisation, the penalty is applied over the coefficients that multiply \n        each of the predictors. From the different types of regularisation, Lasso or l1 has the property that is able to shrink some of the \n        coefficients to zero. Therefore, that feature can be removed from the model.'''\n        \n        scaler = StandardScaler()\n        scaler.fit(X_train.fillna(0))\n        sel = SelectFromModel(LogisticRegression(C=1, penalty='l2'))\n        sel.fit(scaler.transform(X_train.fillna(0)), y_train)\n        selected_features=X_train.columns[sel.get_support()]\n        print('total_features:{}'.format(X_train.shape[1]))\n        print('selected_features:{}'.format(len(selected_features)))\n        print('features with zero coefficients:{}'.format(np.sum(sel.estimator_.coef_==0)))\n       \n    def LassoCV(self,X_train,Y_train):\n        '''Using lasso regression technique to find out the redundant features in the equation'''\n        \n        scaler = StandardScaler()\n        scaler.fit(X_train_c.fillna(0))\n        sel = LassoCV()\n        sel.fit(scaler.transform(X_train_c.fillna(0)), y_train)\n        coef = pd.Series(sel.coef_, index = X_train.columns)\n        print('total_features:{}'.format(X_train.shape[1]))\n        print('selected_features:{}'.format(str(sum(coef != 0))))\n        print('features with zero coefficients:{}'.format(np.sum(sel.coef_==0)))\n        imp_coef = coef.sort_values()\n        matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n        imp_coef.plot(kind = \"barh\")\n        plt.title(\"Feature importance using Lasso Model\")\n        \n        \n    \n    def recursive_feature_addition_classification(self,X_train,X_test,y_train,y_pred):\n        model_all_features=xgb.XGBClassifier(nthread=10,n_estimators=500,learning_rate=0.01,max_depth=4,random_state=123)\n        model_all_features.fit(X_train,y_train)\n        y_pred_test=model_all_features.predict(X_test)[:,1]\n        auc_score_all=roc_auc_score(y_pred,y_pred_test)\n        print('AUC_ROC score of all features=%f'%(auc_score_all))\n\n        features=pd.Series(model_all_features.feature_importances_)\n        features.index=X_train.columns\n        features.sort_values(ascending=False).plot.bar(figsize(20,8))\n        features=list(features.index)\n\n        #Now taking one by one important feature\n        model_one_feature=xgb.XGBClassifier(nthread=10,n_estimators=500,learning_rate=0.01,max_depth=4,random_state=123)\n        model_one_feature.fit(X_train[features[0]].to_frame(),y_train)\n        y_pred_test=model_one_feature.predict(X_test[features[0]].to_frame())[:,1]\n        auc_score_one=roc_auc_score(y_pred,y_pred_test)\n        print('AUC_ROC score of all features=%f'%(auc_score_one))\n\n        # the final step consists in adding one at a time\n        # all the features, from the most to the least\n        # important, and build an xgboost at each round.\n\n        # once we build the model, we calculate the new roc-auc\n        # if the new roc-auc is bigger than the original one\n        # (with one feature), then that feature that was added\n        # was important, and we should keep it.\n        # otherwise, we should remove the feature\n\n        # recursive feature addition:\n\n        # first we arbitrarily set the increase in roc-auc\n        # if the increase is above this threshold,\n        # the feature will be kept\n        tol = 0.001\n\n        features_to_keep=[features[0]]\n        count=1\n        for feature in features[1:]:\n            print('testing feature',feature,' which is feature ',count,' out of ', len(features))\n            count=count+1\n            model_int = xgb.XGBClassifier(\n                nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05)\n\n            # fit model with the selected features\n            # and the feature to be evaluated\n            model_int.fit(\n                X_train[features_to_keep + [feature] ], y_train)\n\n            # make a prediction over the test set\n            y_pred_test = model_int.predict_proba(\n                X_test[features_to_keep + [feature] ])[:, 1]\n\n            # calculate the new roc-auc\n            auc_score_int = roc_auc_score(y_test, y_pred_test)\n            print('New Test ROC AUC={}'.format((auc_score_int)))\n\n            # print the original roc-auc with one feature\n            print('All features Test ROC AUC={}'.format((auc_score_one)))\n\n            # determine the increase in the roc-auc\n            diff_auc = auc_score_int - auc_score_one\n\n            if diff_auc >= tol:\n                print('Increase in ROC AUC={}'.format(diff_auc))\n                print('keep: ', feature)\n                print\n                auc_score_one=auc_score_int\n                features_to_keep.append(feature)\n            else:\n                print('Increase in ROC AUC={}'.format(diff_auc))\n                print('remove: ', feature)\n                print\n        print('DONE!!')\n        print('total features to keep: ', len(features_to_keep))\n        return features_to_keep\n\n    def recursive_feature_addition_regression(self,X_train,y_train,X_test,y_test):\n        model_all_features=xgb.XGBRegressor(nthread=10,n_estimators=500,learning_rate=0.01,max_depth=4,random_state=123)\n        model_all_features.fit(X_train,y_train)\n        y_pred_test=model_all_features.predict(X_test)\n        r2_score_all=r2_score(y_test,y_pred_test)\n        print('R2 score of all features=%f'%(r2_score_all))\n\n        features=pd.Series(model_all_features.feature_importances_)\n        features.index=X_train.columns\n        features.sort_values(ascending=False).plot.bar(figsize=(20,8))\n        features=list(features.index)\n\n            #Now taking one by one important feature\n        model_one_feature=xgb.XGBRegressor(nthread=10,n_estimators=500,learning_rate=0.01,max_depth=4,random_state=123)\n        model_one_feature.fit(X_train[features[0]].to_frame(),y_train)\n        y_pred_test=model_one_feature.predict(X_test[features[0]].to_frame())\n        r2_score_one=r2_score(y_test,y_pred_test)\n        print('R2 score of all features=%f'%(r2_score_one))\n\n        tol = 0.001\n\n        features_to_keep=[features[0]]\n        count=1\n         # the final step consists in adding one at a time\n        # all the features, from the most to the least\n        # important, and build an xgboost at each round.\n\n        # once we build the model, we calculate the new roc-auc\n        # if the new roc-auc is bigger than the original one\n        # (with one feature), then that feature that was added\n        # was important, and we should keep it.\n        # otherwise, we should remove the feature\n\n        # recursive feature addition:\n\n        # first we arbitrarily set the increase in roc-auc\n        # if the increase is above this threshold,\n        # the feature will be kept\n        for feature in features[1:]:\n            print('testing feature',feature,' which is feature ',count,' out of ', len(features))\n            count=count+1\n            model_int = xgb.XGBRegressor(\n                    nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05)\n\n                # fit model with the selected features\n                # and the feature to be evaluated\n            model_int.fit(\n                    X_train[features_to_keep + [feature] ], y_train)\n\n                # make a prediction over the test set\n            y_pred_test = model_int.predict(\n                    X_test[features_to_keep + [feature] ])\n\n                # calculate the new roc-auc\n            r2_score_int = r2_score(y_test, y_pred_test)\n            print('New Test R2_score={}'.format((r2_score_int)))\n\n                # print the original roc-auc with one feature\n            print('All features Test R2_score={}'.format((r2_score_one)))\n\n                # determine the increase in the roc-auc\n            diff_r2 = r2_score_int - r2_score_one\n\n            if diff_r2 >= tol:\n                print('Increase in R2={}'.format(diff_r2))\n                print('keep: ', feature)\n                print\n                r2_score_one=r2_score_int\n                features_to_keep.append(feature)\n            else:\n                print('Increase in R2={}'.format(diff_r2))\n                print('remove: ', feature)\n                print\n            print('DONE!!')\n            print('total features to keep: ', len(features_to_keep))\n        return features_to_keep\n\n   \n        def recursive_feature_elimination_classification(self,X_train,X_test,y_train,y_pred):\n            model_all_features=xgb.XGBClassifier(nthread=10,n_estimators=500,learning_rate=0.01,max_depth=4,random_state=123)\n            model_all_features.fit(X_train,y_train)\n            y_pred_test=model_all_features.predict(X_test)[:,1]\n            auc_score_all=roc_auc_score(y_pred,y_pred_test)\n            print('AUC_ROC score of all features=%f'%(auc_score_all))\n\n            features=pd.Series(model_all_features.feature_importances_)\n            features.index=X_train.columns\n            features.sort_values(ascending=False).plot.bar(figsize(20,8))\n            features=list(features.index)\n\n            #Now taking one by one important feature\n            model_one_feature=xgb.XGBClassifier(nthread=10,n_estimators=500,learning_rate=0.01,max_depth=4,random_state=123)\n            model_one_feature.fit(X_train[features[0]].to_frame(),y_train)\n            y_pred_test=model_one_feature.predict(X_test[features[0]].to_frame())[:,1]\n            auc_score_one=roc_auc_score(y_pred,y_pred_test)\n            print('AUC_ROC score of all features=%f'%(auc_score_one))\n\n\n\n            # recursive feature elimination:\n\n            # the first step of this procedure  consists in building\n            # a machine learning algorithm using all the available features\n            # and then determine the importance of the features according\n            # to the algorithm\n\n            # the second step consist of deriving the importance of \n            # each feature and ranking them from the least to the most\n            # important\n\n            # the final step consists in removing one at a time\n            # all the features, from the least to the most\n            # important, and build an xgboost at each round.\n\n            # once we build the model, we calculate the new roc-auc\n            # if the new roc-auc is smaller than the original one\n            # (with all the features), then that feature that was removed\n            # was important, and we should keep it.\n            # otherwise, we should remove the feature\n\n            tol = 0.0001\n\n            features_to_remove=[]\n            count=1\n            for feature in features:\n                print('testing feature',feature,' which is feature ',count,' out of ', len(features))\n                count=count+1\n                model_int = xgb.XGBClassifier(\n                    nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05)\n\n                # fit model with the selected features\n                # and the feature to be evaluated\n                model_int.fit(\n                    X_train.drop(features_to_remove + [feature],axis=1), y_train)\n\n                # make a prediction over the test set\n                y_pred_test = model_int.predict_proba(\n                    X_test.drop(features_to_keep + [feature],axis=1))[:, 1]\n\n                # calculate the new roc-auc\n                auc_score_int = roc_auc_score(y_test, y_pred_test)\n                print('New Test ROC AUC={}'.format((auc_score_int)))\n\n                # print the original roc-auc with one feature\n                print('All features Test ROC AUC={}'.format((auc_score_one)))\n\n                # determine the increase in the roc-auc\n                diff_auc = auc_score_int - auc_score_one\n\n                if diff_auc >= tol:\n                    print('Drop in ROC AUC={}'.format(diff_auc))\n                    print('keep: ', feature)\n                    print\n\n                else:\n                    print('Drop in ROC AUC={}'.format(diff_auc))\n                    print('remove: ', feature)\n                    print\n                    auc_score_one=auc_score_int\n                    features_to_remove.append(feature)\n            print('DONE!!')\n            print('total features to remove: ', len(features_to_remove))\n        return features_to_remove\n    \n    \n    def recursive_feature_addition_regression(self,X_train,y_train,X_test,y_test):\n        model_all_features=xgb.XGBRegressor(nthread=10,n_estimators=500,learning_rate=0.01,max_depth=4,random_state=123)\n        model_all_features.fit(X_train,y_train)\n        y_pred_test=model_all_features.predict(X_test)\n        r2_score_all=r2_score(y_test,y_pred_test)\n        print('R2 score of all features=%f'%(r2_score_all))\n\n        features=pd.Series(model_all_features.feature_importances_)\n        features.index=X_train.columns\n        features.sort_values(ascending=False).plot.bar(figsize=(20,8))\n        features=list(features.index)\n\n            #Now taking one by one important feature\n        model_one_feature=xgb.XGBRegressor(nthread=10,n_estimators=500,learning_rate=0.01,max_depth=4,random_state=123)\n        model_one_feature.fit(X_train[features[0]].to_frame(),y_train)\n        y_pred_test=model_one_feature.predict(X_test[features[0]].to_frame())\n        r2_score_one=r2_score(y_test,y_pred_test)\n        print('R2 score of all features=%f'%(r2_score_one))\n\n        tol = 0.0001\n\n        features_to_remove=[]\n        count=1\n        # the first step of this procedure  consists in building\n        # a machine learning algorithm using all the available features\n        # and then determine the importance of the features according\n        # to the algorithm\n\n        # the second step consist of deriving the importance of \n        # each feature and ranking them from the least to the most\n        # important\n\n        # the final step consists in removing one at a time\n        # all the features, from the least to the most\n        # important, and build an xgboost at each round.\n\n        # once we build the model, we calculate the new roc-auc\n        # if the new roc-auc is smaller than the original one\n        # (with all the features), then that feature that was removed\n        # was important, and we should keep it.\n        # otherwise, we should remove the feature\n\n        for feature in features:\n            print('testing feature',feature,' which is feature ',count,' out of ', len(features))\n            count=count+1\n            model_int = xgb.XGBRegressor(\n                    nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05)\n\n                # fit model with the selected features\n                # and the feature to be evaluated\n            model_int.fit(\n                    X_train.drop(features_to_remove + [feature],axis=1), y_train)\n\n                # make a prediction over the test set\n            y_pred_test = model_int.predict(\n                    X_test.drop(features_to_remove + [feature],axis=1))\n\n                # calculate the new roc-auc\n            r2_score_int = r2_score(y_test, y_pred_test)\n            print('New Test R2_score={}'.format((r2_score_int)))\n\n                # print the original roc-auc with one feature\n            print('All features Test R2_score={}'.format((r2_score_one)))\n\n                # determine the increase in the roc-auc\n            diff_r2 = r2_score_int - r2_score_one\n\n            if diff_r2 >= tol:\n                print('Increase in R2={}'.format(diff_r2))\n                print('keep: ', feature)\n                print\n\n            else:\n                print('Increase in R2={}'.format(diff_r2))\n                print('remove: ', feature)\n                print\n                r2_score_one=r2_score_int\n                features_to_remove.append(feature)\n            print('DONE!!')\n            print('total features to keep: ', len(features_to_remove))\n        return features_to_remove\n    \n    def recursive_feature_elimination_regression(self,X_train_c,X_test_c,y_train_c,y_test_c):\n        \n            model_all_features = xgb.XGBRegressor(\n                nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05,random_state=123)\n\n            model_all_features.fit(X_train_c, y_train_c)\n\n            # calculate the roc-auc in the test set\n            y_pred_test = model_all_features.predict(X_test_c)\n            r2_score_all = r2_score(y_test_c, y_pred_test)\n            print('Test all features xgb R2 = %f' % (r2_score_all))\n\n            features = pd.Series(model_all_features.feature_importances_)\n            features.index = X_train_c.columns\n\n            # sort the features by importance\n            features.sort_values(ascending=True, inplace=True)\n\n            # plot\n            features.plot.bar(figsize=(20,6))\n            features = list(features.index)\n\n            tol = 0.001\n\n            print('doing recursive feature elimination')\n\n            # we initialise a list where we will collect the\n            # features we should remove\n            features_to_remove = []\n\n            # set a counter to know how far ahead the loop is going\n            count = 1\n\n            # now we loop over all the features, in order of importance:\n            # remember that features is the list of ordered features\n            # by importance\n            for feature in features:\n                print()\n                print('testing feature: ', feature, ' which is feature ', count,\n                      ' out of ', len(features))\n                count = count + 1\n\n                # initialise model\n                model_int = xgb.XGBRegressor(\n                    nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05,random_state=123)\n\n                # fit model with all variables minus the removed features\n                # and the feature to be evaluated\n                model_int.fit(\n                    X_train_c.drop(features_to_remove + [feature], axis=1), y_train_c)\n\n                # make a prediction over the test set\n                y_pred_test = model_int.predict(\n                    X_test_c.drop(features_to_remove + [feature], axis=1))\n\n                # calculate the new r2\n                r2_score_int = r2_score(y_test_c, y_pred_test)\n                print('New Test r2 = {}'.format((r2_score_int)))\n\n                # print the original r2 with all the features\n                print('All features Test r2 = {}'.format((r2_score_all)))\n\n                # determine the drop in the r2\n                diff_r2 = r2_score_all - r2_score_int\n\n                # compare the drop in r2 with the tolerance\n                # we set previously\n                if diff_r2 >= tol:\n                    print('Drop in r2 ={}'.format(diff_r2))\n                    print('keep: ', feature)\n                    print\n                else:\n                    print('Drop in r2 = {}'.format(diff_r2))\n                    print('remove: ', feature)\n                    print\n                    # if the drop in the r2 is small and we remove the\n                    # feature, we need to set the new r2 to the one based on\n                    # the remaining features\n                    r2_score_all = r2_score_int\n\n                    # and append the feature to remove to the collecting\n                    # list\n                    features_to_remove.append(feature)\n\n            # now the loop is finished, we evaluated all the features\n            print('DONE!!')\n            print('total features to remove: ', len(features_to_remove))\n\n            # determine the features to keep (those we won't remove)\n            features_to_keep = [x for x in features if x not in features_to_remove]\n            print('total features to keep: ', len(features_to_keep))\n            return features_to_keep\n\n    \n    def feature_shuffling_regression(self,X_train,y_train,X_test,y_test):\n        model=xgb.XGBRegressor(nthread=10,n_estimators=500,learning_rate=0.01,max_depth=4,random_state=123)\n        model.fit(X_train,y_train)\n        y_pred_test=model.predict(X_test)\n        r2_score_all=r2_score(y_test,y_pred_test)\n        print('R2 score of all features=%f'%(r2_score_all))\n\n        print('train r2 score:',r2_score(y_train,(model.predict(X_train))))\n        print('test r2 score:',r2_score(y_test,(model.predict(X_test))))\n\n        train_r2=r2_score(y_train,model.predict(X_train))\n\n        feature_dict={}\n\n        for feature in X_train.columns:\n            X_train_c=X_train.copy()\n            X_train_c[feature] = X_train_c[feature].sample(frac=1).reset_index(\n                drop=True)\n\n            # make prediction with shuffled feature and calculate roc-auc\n            shuff_r2 = r2_score(y_train,\n                                      (model.predict(X_train_c.fillna(0))))\n\n            # save the drop in roc-aucsel\n            feature_dict[feature] = (train_r2 - shuff_r2)\n\n        feature_importance = pd.Series(feature_dict).reset_index()\n        feature_importance.columns = ['feature', 'auc_drop']\n        feature_importance.sort_values(by=['auc_drop'], ascending=False, inplace=True)\n        feature_importance.head()\n        temp = pd.Series(feature_importance[feature_importance.auc_drop>0]['auc_drop'])\n        temp.index = pd.Series(feature_importance[feature_importance.auc_drop>0]['feature'])\n\n        pd.Series(temp).plot.bar(figsize=(15,6))\n        selected_features = feature_importance[feature_importance.auc_drop>0]['feature']\n        return selected_features\n    \n    \n    \n    def feature_shuffling_classification(self,X_train,y_train,X_test,y_test):\n        model=xgb.XGBClassifier(nthread=10,n_estimators=500,learning_rate=0.01,max_depth=4,random_state=123)\n        model.fit(X_train,y_train)\n        y_pred_test=model.predict(X_test)\n        auc_roc_score_all=auc_roc_score(y_test,y_pred_test)\n        print('AUC_ROC score of all features=%f'%(auc_roc_score_all))\n\n        print('train auc_roc score:',auc_roc_score(y_train,(model.predict_proba(X_train))[:,1]))\n        print('test auc_roc score:',auc_roc_score(y_test,(model.predict_proba(X_test))[:,1]))\n\n        train_auc_roc=auc_roc_score(y_train,model.predict_proba(X_train)[:,1])\n\n        feature_dict={}\n\n        for feature in X_train.columns:\n            X_train_c=X_train.copy()\n            X_train_c[feature] = X_train_c[feature].sample(frac=1).reset_index(\n                drop=True)\n\n            # make prediction with shuffled feature and calculate roc-auc\n            shuff_auc_roc = auc_roc_score(y_train,\n                                      (model.predict_proba(X_train_c.fillna(0)))[:,1])\n\n            # save the drop in roc-auc\n            feature_dict[feature] = (train_auc_roc - shuff_auc_roc)\n\n        feature_importance = pd.Series(feature_dict).reset_index()\n        feature_importance.columns = ['feature', 'auc_drop']\n        feature_importance.sort_values(by=['auc_drop'], ascending=False, inplace=True)\n        feature_importance.head()\n        temp = pd.Series(feature_importance[feature_importance.auc_drop>0]['auc_drop'])\n        temp.index = pd.Series(feature_importance[feature_importance.auc_drop>0]['feature'])\n\n        pd.Series(temp).plot.bar(figsize=(15,6))\n        selected_features = feature_importance[feature_importance.auc_drop>0]['feature']\n        return selected_features","f1e608c0":"X_train_c=X_train.copy()\ny_train_c=y_train.copy()\nfeature=FeatureSelection(train)\nfeature.LassoCV(X_train_c,y_train_c)","3bd26d50":"X_train_c=X_train.copy()\ny_train_c=y_train.copy()\nX_test_c=X_test.copy()\ny_test_c=y_test.copy()\nfeature=FeatureSelection(train)\nfeature.feature_shuffling_regression(X_train_c,y_train_c,X_test_c,y_test_c)","297f542e":"X_train_c=X_train.copy()\ny_train_c=y_train.copy()\nX_test_c=X_test.copy()\ny_test_c=y_test.copy()\nfeature=FeatureSelection(train)\nfeatures_to_keep=feature.recursive_feature_addition_regression(X_train_c,y_train_c,X_test_c,y_test_c)","f7141999":"X_train_c=X_train.copy()\ny_train_c=y_train.copy()\nX_test_c=X_test.copy()\ny_test_c=y_test.copy()\nfeature=FeatureSelection(train)\nfeature_to_remove=feature.recursive_feature_elimination_regression(X_train_c,X_test_c,y_train_c,y_test_c)\n\n","09a66e2d":"from sklearn import metrics\nfrom sklearn.metrics import r2_score\ndef metrics_error(y_true,y_pred):\n    # calculate MAE, MSE, RMSE\n    print('R2 score : '+str(r2_score(y_true, y_pred)))\n    print('mean absolute error : '+str(metrics.mean_absolute_error(y_true, y_pred)))\n    print('mean squared error : '+str(metrics.mean_squared_error(y_true, y_pred)))\n    print('root mean squared error : '+str(np.sqrt(metrics.mean_squared_error(y_true, y_pred))))","f1bf7578":"from sklearn.model_selection import GridSearchCV\ndef grid_search_algo(X_train,y_train,X_test,y_test,model,param_grid,cv=5):\n    gs=GridSearchCV(estimator=model,param_grid=param_grid,cv=cv,n_jobs=-1,verbose=1)\n    grid=gs.fit(X_train,y_train)\n    y_pred_train=gs.predict(X_train)\n    y_pred_test=gs.predict(X_test)\n    print(' R-squared:',gs.score(X_test, y_test))\n    print(\"The model performance for training set\")\n    print(\"--------------------------------------\")\n    metrics_error(y_test,y_pred_train)\n    print(\"The model performance for testing set\")\n    print(\"--------------------------------------\")\n    metrics_error(y_test,y_pred_test)\n    return gs\n    ","e802c6f4":"from sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.naive_bayes import GaussianNB\nimport xgboost as xgb\n","1f7fed63":"regressors = [\n  #  LinearRegression(),\n #  KNeighborsRegressor(5),\n    GaussianNB(),\n    #SVR(),\n    DecisionTreeRegressor(criterion='mse', splitter='best', max_depth=4, min_samples_split=2, min_samples_leaf=1, random_state=123),\n    RandomForestRegressor(n_estimators = 10, max_depth = 10, random_state = 101),\n    GradientBoostingRegressor(n_estimators = 10, max_depth = 10, random_state = 101),\n    xgb.XGBRegressor(nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05,random_state=123)]\nnames,R2_score,mean_absolute_error,mean_squared_error,root_mean_squared_error=[],[],[],[],[]\n\n\n\nfor clf in regressors:\n    \n    clf.fit(X_train,y_train)\n    \n    name = clf.__class__.__name__\n    print(name)\n    print(\"=\"*30)\n    names.append(name)\n    \n    print('****Results****')\n    \n    y_pred = clf.predict(X_test)\n    \n    print('R2 score : '+str(r2_score(y_test, y_pred)))\n    print('mean absolute error : '+str(metrics.mean_absolute_error(y_test, y_pred)))\n    print('mean squared error : '+str(metrics.mean_squared_error(y_test, y_pred)))\n    print('root mean squared error : '+str(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))\n\n    \n    R2_score.append(str(r2_score(y_test, y_pred)))\n    mean_absolute_error.append(str(metrics.mean_absolute_error(y_test, y_pred)))\n    mean_squared_error.append((str(metrics.mean_squared_error(y_test, y_pred))))\n    root_mean_squared_error.append(str(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))\n    \nfinal_output=pd.DataFrame({'Name_of_model':names,'R2 score':R2_score,'mean absolute error':mean_absolute_error,'mean squared error':mean_squared_error,'root mean squared error':root_mean_squared_error}) ","a5b47731":"model=xgb.XGBRegressor(nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05,random_state=123)\nparam_grid_XGB = {'max_depth': [3,4,5,6,7],'min_samples_split': [3,4,5,6],'n_estimators': [500,1000,1500],'learning_rate':[0.01,0.05,0.1]}\n\ngrid_search_algo(X_train,y_train,X_test,y_test,model,param_grid_XGB,cv=5)","683aaf2b":"**OUTLIER ANALYSIS**","a9e7ff60":"**FEATURE SELECTION CLASS**","34f68f4f":"**SELECTION OF BETTER MODEL FOR THE GIVEN PROBLEM**","469719ad":"**GRID SEARCH**","194b57f7":"**CHECKING OF DATA OF MISSING VALUES WITH FEATURE ENGINEERING**","2f910844":"**Visualize data using different visualizations to generate interesting insights.**\n**Visualizing Total_booking Vs other features to generate insights**","c1e2d16a":"**CORELATION ANALYSIS**","b5837193":"**OUTLIER CLASS**","ab90b0b7":"**Visualize data using different visualizations to generate interesting insights**\n**Visualizing Total_booking Vs other features to generate insights**","cdfb1788":"**FEATURE SELECTION METHODS**","5752824e":"**FITTING OF DIFFERENT TYPE OF REGRESSORS AND ENSEMBLE MODELS**","6391d065":"**DATA VISUALIZATION**"}}