{"cell_type":{"6456c9cb":"code","ec0f2fb3":"code","2ab05cba":"code","ca64d04d":"code","81fb56c6":"code","a1073950":"code","5b12637c":"code","8c78f6a9":"code","024ca2a2":"code","2665ce5e":"code","da94034f":"code","5f6f94d0":"code","f19dd7d3":"code","e2f7f0ae":"code","04aef2e5":"code","291564af":"code","cfe1cfec":"code","77a3d2bd":"code","6e385cd7":"code","b9f0fe12":"code","6ca67d4a":"code","8f0a62ce":"code","ca56deb4":"code","5ea56f11":"code","21d79176":"code","bba9d73b":"code","4da25713":"code","c459ad26":"code","c5272f54":"code","d96207de":"code","a523e20a":"code","d74d1e30":"code","9f8e5aaa":"code","0fb68998":"code","76cc36d6":"code","e1073fe8":"code","c33bf013":"code","0c6c9716":"code","1746f1e3":"code","a823f1ce":"code","11db92db":"code","9a2044e0":"code","10a495ad":"code","d76be74e":"markdown","e89f0e44":"markdown","9f30e503":"markdown"},"source":{"6456c9cb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ec0f2fb3":"import pandas as pd \ntrd=pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntrd.head()","2ab05cba":"import pandas as pd \ntsd=pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntsd.head()","ca64d04d":"w=trd.loc[trd.YrSold<2008][trd.SaleCondition=='Normal']\n#print(w)\nrw= len(w)\/len(trd)\nprint(\"percentage of houses are for sale before 2008 are normal is : \",rw)","81fb56c6":"x=trd.loc[trd.LotArea<10000][trd.SaleCondition=='Normal']\n#print(w)\nrw= len(x)\/len(trd)\nprint(\"percentage of houses are having area less than 10000 m^2 are normal is : \",rw)","a1073950":"value=trd.loc[trd.MSSubClass>60]\nprint(value)","5b12637c":"\"\"\"author    s_agnik1511\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\ntrd = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntrain_y = trd.SalePrice\npredictor_cols = ['LotArea']\ntrain_X = trd[predictor_cols]\nmy_model = RandomForestRegressor()\nmy_model.fit(train_X, train_y)","8c78f6a9":"trd.head()","024ca2a2":"\"\"\"author s_agnik1511\"\"\"\nimport pandas as pd\nmy_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices})\nmy_submission.to_csv('submission_sagnik.csv', index=False)","2665ce5e":"import pandas as pd\nk=pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\nk.shape","da94034f":"import pandas as pd\nimport numpy as np\nm=tsd.predict(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\nSubmission[\"taregt\"]=m\nSubmission.to_csv(\"submission_sagnik123\",index=False)\n","5f6f94d0":"\"\"\"author s_agnik1511\"\"\"\ntest=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_X=test[predictor_cols]\npredicted_prices=my_model.predict(test_X)\nprint(predicted_prices)","f19dd7d3":"from sklearn.linear_model import LinearRegression\nimport pandas as pd\nModel=LinearRegression()\nx_test=pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\nModel.fit(x_test)\nModel.predict(x_test)","e2f7f0ae":"\nimport pandas as pd # for reading the data frame\nimport numpy as np # for numerical calculation\nimport matplotlib.pyplot as plt # use for visualization\nimport seaborn as sns   # mostly used for statistical visualization \n%matplotlib inline      # used for inline ploting\n","04aef2e5":"train = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\n\nprint(\"Shape of train: \", train.shape) #  rows : 1459 columns : 81\nprint(\"Shape of test: \", test.shape)  # rows : 1459 columns : 80","291564af":"train.head(20)","cfe1cfec":"test.head(10)","77a3d2bd":"df = pd.concat((train, test)) # here we concat the test and train data set\ntemp_df = df\nprint(\"Shape of df: \", df.shape)","6e385cd7":"temp_df.head() # by default its selected 5 rows and all the columns","b9f0fe12":"temp_df.tail() # for vewig the last five rows","6ca67d4a":"# To show the all columns\npd.set_option(\"display.max_columns\",2000)  # used for viewing all the columns at onces\npd.set_option(\"display.max_rows\",85)","8f0a62ce":"df.head() ","ca56deb4":"df.shape","5ea56f11":"df.info()   # lets view the information about our data set like find the data types of our columns","21d79176":"df.describe() # used for finding the describtion about the data set like,  mean , standard deviation given below","bba9d73b":"df.select_dtypes(include=['int64', 'float64']).columns  # extracrt the columns whose dtype is intege and float","4da25713":"df.select_dtypes(include=['object']).columns  # find the columns whose dtype is object","c459ad26":"# Set index as Id column\ndf = df.set_index(\"Id\")","c5272f54":"df.head()","d96207de":"# Show the null values using heatmap\nplt.figure(figsize=(16,9))\nsns.heatmap(df.isnull())       \n\n# useing heat map we can see the missing values ... the white stripes indicates the missing values \n","a523e20a":"df.isnull().sum()   # from this we can see which columns has how many missig values  like LotFrontsge has 486 missing vales","d74d1e30":"# Get the percentages of null value\nnull_percent = df.isnull().sum()\/df.shape[0]*100\nnull_percent\n\n\n# from this we can say LotFrontage has 16 % and Alley has 93 % missing vslues","9f8e5aaa":"col_for_drop = null_percent[null_percent > 20].keys() # if the null value % 20 or > 20 so need to drop it","0fb68998":"# drop columns\ndf = df.drop(col_for_drop, \"columns\")\ndf.shape","76cc36d6":"null_percent = df.isnull().sum()\/df.shape[0]*100\nnull_percent # shows values which has less than 20 % missing values","e1073fe8":"# find the unique value count\nfor i in df.columns:\n    print(i + \"\\t\" + str(len(df[i].unique())))","c33bf013":"# find unique values of each column\nfor i in df.columns:\n    print(\"Unique value of:>>> {} ({})\\n{}\\n\".format(i, len(df[i].unique()), df[i].unique()))","0c6c9716":"# Describe the target \ntrain[\"SalePrice\"].describe()","1746f1e3":"# Plot the distplot of target\nplt.figure(figsize=(10,8))\nbar = sns.distplot(train[\"SalePrice\"])","a823f1ce":"# correlation heatmap\nplt.figure(figsize=(25,25))\nax = sns.heatmap(train.corr(), cmap = \"coolwarm\", annot=True, linewidth=2)\n\n# here we use piearson corelation","11db92db":"# correlation heatmap of higly correlated features with SalePrice\nhig_corr = train.corr()\nhig_corr_features = hig_corr.index[abs(hig_corr[\"SalePrice\"]) >= 0.5]\nhig_corr_features\n","9a2044e0":"plt.figure(figsize=(10,8))\nbar = sns.distplot(train[\"LotFrontage\"])","10a495ad":"plt.figure(figsize=(10,8))\nbar = sns.distplot(train[\"MSSubClass\"])","d76be74e":"# Exploratory Data Analysis (EDA)","e89f0e44":"## concat train and test","9f30e503":"# load data set"}}