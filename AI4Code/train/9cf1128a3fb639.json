{"cell_type":{"df6d4b89":"code","546b1518":"code","27251c09":"code","56b3b6cc":"markdown"},"source":{"df6d4b89":"import os\nos.listdir('..\/input')","546b1518":"import csv\nimport pandas as pd # not key to functionality of kernel\n\nsub_files = [\n                '..\/input\/publickernel\/sub_766.csv',\n                '..\/input\/publickernel\/sub_771.csv'\n]\n\n# Weights of the individual subs\nsub_weight = [\n                0.766**2,\n                0.771**2\n            ]","27251c09":"Hlabel = 'Image' \nHtarget = 'Id'\nnpt = 5 # number of places in target\n\nplace_weights = {}\nfor i in range(npt):\n    place_weights[i] = ( 1 \/ (i + 1) )\n    \nprint(place_weights)\n\nlg = len(sub_files)\nsub = [None]*lg\nfor i, file in enumerate( sub_files ):\n    ## input files ##\n    print(\"Reading {}: w={} - {}\". format(i, sub_weight[i], file))\n    reader = csv.DictReader(open(file,\"r\"))\n    sub[i] = sorted(reader, key=lambda d: str(d[Hlabel]))\n\n## output file ##\nout = open(\"sub_ns.csv\", \"w\", newline='')\nwriter = csv.writer(out)\nwriter.writerow([Hlabel,Htarget])\n\nfor p, row in enumerate(sub[0]):\n    target_weight = {}\n    for s in range(lg):\n        row1 = sub[s][p]\n        for ind, trgt in enumerate(row1[Htarget].split(' ')):\n            target_weight[trgt] = target_weight.get(trgt,0) + (place_weights[ind]*sub_weight[s])\n    tops_trgt = sorted(target_weight, key=target_weight.get, reverse=True)[:npt]\n    writer.writerow([row1[Hlabel], \" \".join(tops_trgt)])\nout.close()","56b3b6cc":"This kernel is based on the approach from https:\/\/www.kaggle.com\/matthewa313\/ensembling-algorithm-for-average-precision-metric\n\nTake predictions from LB 0.771 from https:\/\/www.kaggle.com\/ateplyuk\/ensembling-lb-0-771\n\nTake predictions from LB 0.766 https:\/\/www.kaggle.com\/hung96ad\/ensembling-algorithm-for-average-precision-0-766\n\nPlug your outputs to this kernel and you're good to go."}}