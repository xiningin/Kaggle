{"cell_type":{"f476fe14":"code","96dadf3c":"code","b1baad41":"code","129b3f3c":"code","665c3a92":"code","81595397":"code","5180fa6e":"code","eaabbbbe":"code","26de9ae5":"code","5526e90d":"code","b45897f6":"code","fb413259":"code","3d208bca":"code","77db483b":"code","fb14a917":"code","bc09093d":"code","50aeff5a":"code","ee710f6d":"code","a333c430":"markdown","d34960af":"markdown","91a608c3":"markdown"},"source":{"f476fe14":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","96dadf3c":"# Import Python Packages\n# PyTesseract and Tika-Python for OCR\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport shutil\nimport PIL\nimport os\nfrom os import walk\nfrom shutil import copytree, ignore_patterns\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\nfrom PIL import Image\nfrom wand.image import Image as Img\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', 500)\n#mueller_report = pd.read_csv('..\/input\/data-science-cheat-sheets\/Interview Questions\/AI Questions.pdf') # one row per line","b1baad41":"# Define helper function for plotting word clouds\ndef wordCloudFunction(df,column,numWords):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    word_string=str(popular_words_nonstop)\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white',\n                          max_words=numWords,\n                          width=1000,height=1000,\n                         ).generate(word_string)\n    plt.clf()\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()","129b3f3c":"# Define helper function for plotting word bar graphs\ndef wordBarGraphFunction(df,column,title):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    plt.barh(range(50), [word_count_dict[w] for w in reversed(popular_words_nonstop[0:50])])\n    plt.yticks([x + 0.5 for x in range(50)], reversed(popular_words_nonstop[0:50]))\n    plt.title(title)\n    plt.show()","665c3a92":"# Preview the data folder\ninputFolder = '..\/input\/'\nfor root, directories, filenames in os.walk(inputFolder):\n    for filename in filenames: \n        print(os.path.join(root,filename))\n        \n# Move data to folder with read\/write access\noutputFolder = '\/kaggle\/working\/pdfs\/'\nshutil.copytree(inputFolder,outputFolder,ignore=ignore_patterns('*.db'))\nfor root, directories, filenames in os.walk(outputFolder, topdown=False):\n    for file in filenames:\n        try:\n            shutil.move(os.path.join(root, file), outputFolder)\n        except OSError:\n            pass\nprint(os.listdir(outputFolder))","81595397":"# Look at page 3\npdf = os.path.join(outputFolder,'200503_rce_assembler_benchmark_notes.pdf[3]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/200503_rce_assembler_benchmark_notes.jpg') # intro page to preview later","5180fa6e":"# Parse a PDF file and convert it to CSV using PyTesseract\nimport pytesseract\npdfimage = Image.open('\/kaggle\/working\/200503_rce_assembler_benchmark_notes.jpg')\ntext = pytesseract.image_to_string(pdfimage)  \ndf = pd.DataFrame([text.split('\\n')])","eaabbbbe":"# Plot WordCloud of page 3\nplt.figure(figsize=(10,10))\nwordCloudFunction(df.T,0,10000000)\nplt.figure(figsize=(10,10))\nwordBarGraphFunction(df.T,0,\"Most Common Words on Page 3 of Bencmark Notes\")","26de9ae5":"# Parse a PDF file and convert it to CSV using Tika-Python\n!pip install tika\nimport tika\nfrom tika import parser\ntika.initVM()\nparsed = parser.from_file('\/kaggle\/working\/200503_rce_assembler_benchmark_notes.jpg') \ntext = parsed[\"content\"]\ndf = pd.DataFrame([text.split('\\n')])\ndf.drop(df.iloc[:, 1:46], inplace=True, axis=1)","5526e90d":"# Convert PDF to JPG and then convert JPG to CSV\n# I will do this for Pages 289 to 291 but\n# Eventually I should loop through the entire document\n\n# PDF to JPG for p3\npdf = os.path.join(outputFolder,'200503_rce_assembler_benchmark_notes.pdf[3]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/200503_rce_assembler_benchmark_notes.jpg')\npdfimage3 = Image.open('\/kaggle\/working\/200503_rce_assembler_benchmark_notes.jpg')","b45897f6":"# PDF to JPG for p1\npdf = os.path.join(outputFolder,'200503_rce_assembler_benchmark_notes.pdf[1]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/200503_rce_assembler_benchmark_notes.jpg')\npdfimage1 = Image.open('\/kaggle\/working\/200503_rce_assembler_benchmark_notes.jpg')\n\n# PDF to JPG for p2\npdf = os.path.join(outputFolder,'200503_rce_assembler_benchmark_notes.pdf[2]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/200503_rce_assembler_benchmark_notes.jpg')\npdfimage2 = Image.open('\/kaggle\/working\/200503_rce_assembler_benchmark_notes.jpg')","fb413259":"# Parse a PDF file and convert it to CSV using PyTesseract (p3)\ntext = pytesseract.image_to_string(pdfimage3)\ndf = pd.DataFrame([text.split('\\n')])\ndf.drop(df.iloc[:, 27:], inplace=True, axis=1)\ndf.drop(df.iloc[:, :3], inplace=True, axis=1)\ndf.columns = range(df.shape[1])","3d208bca":"# Parse a PDF file and convert it to CSV using Tika-Python (p290-291)\ntika.initVM()\nparsed = parser.from_file('\/kaggle\/working\/200503_rce_assembler_benchmark_notes.jpg')\nparsed2 = parser.from_file('\/kaggle\/working\/200503_rce_assembler_benchmark_notes.jpg')\n\ntext = parsed[\"content\"]\ndf2 = pd.DataFrame([text.split('\\n')])\ndf2.drop(df2.iloc[:, 1:50], inplace=True, axis=1)\ndf2.drop(df2.iloc[:, 26:], inplace=True, axis=1)\ndf2.columns = range(df2.shape[1])\n\ntext = parsed2[\"content\"]\ndf3 = pd.DataFrame([text.split('\\n')])\ndf3.drop(df3.iloc[:, :50], inplace=True, axis=1)\ndf3.drop(df3.iloc[:, 22:], inplace=True, axis=1)\ndf3.columns = range(df3.shape[1])\n\ndfcombined = pd.concat([df, df2, df3]) # combine pages 289-291","77db483b":"#Explore page 2 - Mueller Report. Here I don't know how many pages each Cheat Sheet. There are 30 pages \nw, h = pdfimage2.size # crop image\npdfimage2.crop((0, 1240, w, h-1300)) # display exerpt of PDF","fb14a917":"# Convert PDF to JPG and then convert JPG to CSV\n# I will do this for Pages 289 to 291 but\n# Eventually I should loop through the entire document\n\n# PDF to JPG for p3\npdf = os.path.join(outputFolder,'200503_rce_assembler_benchmark_notes.pdf[3]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/200503_rce_assembler_benchmark_notes.jpg')\npdfimage3 = Image.open('\/kaggle\/working\/200503_rce_assembler_benchmark_notes.jpg')","bc09093d":"#Explore page 3 - Mueller Report. Here I don't know how many pages each Cheat Sheet. There are 30 pages \nw, h = pdfimage3.size # crop image\npdfimage3.crop((0, 1240, w, h-1300)) # display exerpt of PDF","50aeff5a":"# Pages 1, 2, and 3 \ndfcombined.head() # preview csv of 2-3","ee710f6d":"# Clean up the notebook\n!apt-get install zip # install zip\n!zip -r pdfs.zip \/kaggle\/working\/pdfs\/ # zip up a few files\n!rm -rf pdfs\/* # remove everything else","a333c430":"Das War's, Kaggle Notebook Runner: Mar\u00edlia Prata  @mpwolke","d34960af":"#Codes from Paul Mooney https:\/\/www.kaggle.com\/paultimothymooney\/what-is-inside-of-the-mueller-report\/notebook","91a608c3":"#PDF to CSV\n\nConvert Page 3 of PDF to CSV (Method 1 of 2: PyTesseract)"}}