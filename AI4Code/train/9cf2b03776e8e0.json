{"cell_type":{"30f27126":"code","1c60109c":"code","fe452c9e":"code","52c735b2":"code","1b9abdbd":"code","9249710a":"code","80c6c84f":"code","230c37e1":"code","90300943":"code","ef70d3aa":"code","ab06aefc":"code","82386439":"code","0e997e7c":"code","f6df57c9":"code","004c4d2a":"code","4f702932":"code","b1ef0b18":"code","410c69e5":"code","d3e73f4e":"code","61cd988d":"code","0b05af9e":"markdown","77643da2":"markdown","117a5560":"markdown","6c5a4de5":"markdown","864e987c":"markdown","1947508d":"markdown","0ae77cfd":"markdown","33e1c0c2":"markdown","482f53f8":"markdown","cf0a9f36":"markdown","8be97048":"markdown","1eaf595b":"markdown","a013b348":"markdown","e9dfcc19":"markdown","c10dda55":"markdown","5454e9cd":"markdown","16da623b":"markdown","ba1fb979":"markdown","eb93c141":"markdown","41d51496":"markdown","fc0bbf6e":"markdown","e71bfc89":"markdown"},"source":{"30f27126":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1c60109c":"# Pandas\nimport pandas as pd \n\n# Matplotlib\nimport matplotlib.pyplot as plt \nplt.style.use('fivethirtyeight')\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression,Lasso,Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import classification_report\n\n# XGBOOST\nfrom xgboost import XGBRFRegressor\n\n# Seaborn\nimport seaborn as sns\n\n# Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","fe452c9e":"data  = pd.read_csv('..\/input\/medical-insurance-premium-prediction\/Medicalpremium.csv')\r\ndata.head()","52c735b2":"data.columns","1b9abdbd":"data.isnull().sum()","9249710a":"plt.figure(figsize=(14,8))\r\nsns.heatmap(data.corr(), annot = True, cmap='coolwarm',linewidths=.1)\r\nplt.title(\"Heatmap for correlation between columns\")\r\nplt.show()","80c6c84f":"data.info()","230c37e1":"data.Age.describe()","90300943":"plt.figure(figsize=(10,5))\r\nplt.hist(data.Age,edgecolor='k')\r\nplt.xlabel(\"Age\")\r\nplt.ylabel(\"Count\");\r\nplt.title(\"Distribution of Age\");","ef70d3aa":"sns.displot(data.Height)\r\nplt.title(\"Distribution of height\");","ab06aefc":"sns.displot(data.Weight)\r\nplt.title(\"Distribution of height\");","82386439":"data.columns","0e997e7c":"\r\nsns.pairplot(data,hue = 'PremiumPrice',diag_kind = \"kde\",kind = \"scatter\",palette = \"husl\")\r\nplt.show()","f6df57c9":"X = data.drop('PremiumPrice',axis=1)\r\ny = data.PremiumPrice","004c4d2a":"scalar =  StandardScaler()\r\nX.Age = scalar.fit_transform(X[['Age']])\r\nX.Height = scalar.fit_transform(X[['Height']])\r\nX.Weight = scalar.fit_transform(X[['Weight']])\r\n","4f702932":"\r\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=43)","b1ef0b18":"models = {\r\n    LinearRegression():'Linear Regression',\r\n    Lasso():'Lasso',\r\n    Ridge():'Ridge',\r\n    XGBRFRegressor():'XGBRFRegressor',\r\n    RandomForestRegressor():'RandomForest'\r\n}\r\nfor m in models.keys():\r\n    m.fit(X_train,y_train)\r\n","410c69e5":"for model,name in models.items():\r\n     print(f\"Accuracy Score for {name} is : \",model.score(X_test,y_test)*100,\"%\")","d3e73f4e":"random_forest = RandomForestRegressor()\r\nrandom_forest.fit(X_train,y_train)\r\nfeature_imp1 = random_forest.feature_importances_\r\nsns.barplot(x=feature_imp1, y=X.columns)\r\n# Add labels to your graph\r\nplt.xlabel('Feature Importance Score')\r\nplt.ylabel('Features')\r\nplt.title(\"Visualizing Important Features\")\r\nplt.show();","61cd988d":"xgboost =XGBRFRegressor()\r\nxgboost.fit(X_train,y_train)\r\nfeature_imp2 = xgboost.feature_importances_\r\nsns.barplot(x=feature_imp2, y=X.columns)\r\n# Add labels to your graph\r\nplt.xlabel('Feature Importance Score')\r\nplt.ylabel('Features')\r\nplt.title(\"Visualizing Important Features\")\r\nplt.show();","0b05af9e":"## Check datatypes of columns","77643da2":"# Data visualizations","117a5560":"## The model phase is where we implement a variety of Machine Learning algorithms to predict a certain outcome.","6c5a4de5":"## To get a good prediction, divide the data into training and testing data, it is because as the name suggests you will train few data points and test few data points, and keep on doing that unless you get good results.\r\n","864e987c":"## Dependent and Independent Features","1947508d":"## Read data.","0ae77cfd":"# Data collection","33e1c0c2":"# iNterpret","482f53f8":"## Inference\r\n### There are no null record present in our dataset.","cf0a9f36":"# Model","8be97048":"## Normalization scales each input variable separately to the range 0-1, which is the range for floating-point values where we have the most precision.","1eaf595b":"# Finding Important Features in Scikit-learn","a013b348":"## To determine how well a model is performing, we often validate its performance on new unseen instances that were not available to the model during training","e9dfcc19":"## Pairplots","c10dda55":"## Inference:\r\n## The distribution of patient weights left skewed with centre of 75.","5454e9cd":"## Check null values","16da623b":"## Inference:\r\n## The distribution of patient heights right skewed with centre of 168 with no outlier.","ba1fb979":"## 1) Random Forest","eb93c141":"## Heatmap","41d51496":"# Exploratory Data Analysis (or EDA)","fc0bbf6e":"# Normalization","e71bfc89":"## 2) XGBoostRegressor"}}