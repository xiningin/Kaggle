{"cell_type":{"6acf39b1":"code","c1b17964":"code","427b1e60":"code","0abfad23":"code","ade1600a":"code","1ffe14b5":"code","76bc3695":"code","15425e93":"code","3b355ec1":"code","e4cd5c8c":"code","1006ea21":"code","c27e92b4":"code","d511e517":"code","ab7c8b06":"markdown","5c35e8cd":"markdown","d3c331b8":"markdown","3321d576":"markdown","249156a3":"markdown","4cb1e1e6":"markdown","bb010f79":"markdown","b221215e":"markdown","732ab768":"markdown"},"source":{"6acf39b1":"import pandas as pd # verinin organizasyonu i\u00e7in\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_validate\nfrom sklearn import svm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.cluster import KMeans\n\n#Grafik \u00e7izdirme k\u00fct\u00fcphanesi\nimport matplotlib.pyplot as plt\n\nimport os #Sistem \nimport warnings #uyar\u0131lar\n#print(os.listdir(\"..\/input\/\"))\nwarnings.filterwarnings(\"ignore\")","c1b17964":"from sklearn import datasets\niris =datasets.load_iris()","427b1e60":"X=iris.data\nY=iris.target","0abfad23":"plt.scatter(X[:,0], X[:,1], c=Y, cmap='gist_rainbow')\nplt.xlabel('Spea1 Length', fontsize=18)\nplt.ylabel('Sepal Width', fontsize=18)","ade1600a":"x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=1)\n","1ffe14b5":"def computing(cm):\n    Eba = cm[1,0]\n    Eca = cm[2,0]\n    Eab = cm[0,1]\n    Ecb = cm[2,1]\n    Eac = cm[0,2]\n    Ebc = cm[1,2]\n    TPa = cm[0,0]\n    TPb = cm[1,1]\n    TPc = cm[2,2]\n    FNa = Eba+Eca\n    FNb = Eab+Ecb\n    FNc = Eac+Ebc\n    FPa = Eab+Eac\n    FPb = Eba+Ebc\n    FPc = Eca+Ecb\n    TNa = TPb+Ebc+Ecb+TPc\n    TNb = TPa+Eac+Eca+TPc\n    TNc = TPa+Eab+Eba+TPb\n    Total = TPa+Eab+Eac+Eba+TPb+Ebc+Eca+Ecb+TPc\n    accuracy = (TPa+TPb+TPc)\/Total\n    sensitivityA = (TPa)\/(TPa+FNa)\n    sensitivityB = (TPb)\/(TPb+FNb)\n    sensitivityC = (TPc)\/(TPc+FNc)\n    specificityA = (TNa)\/(TNa+FPa)\n    specificityB = (TNb)\/(TNb+FPb)\n    specificityC = (TNc)\/(TNc+FPc)\n    print(\"accuracy: \",accuracy)\n    print(\"sensitivityA: \",sensitivityA)\n    print(\"sensitivityB: \",sensitivityB)\n    print(\"sensitivityC: \",sensitivityC)\n    print(\"specificityA: \",specificityA)\n    print(\"specificityB: \",specificityB)\n    print(\"specificityC: \",specificityC)\n    \n    matrisim=[[\"accuracy: \",accuracy],[\"sensitivityA: \",sensitivityA],\n          [\"sensitivityB: \",sensitivityB],[\"sensitivityC: \",sensitivityC],\n          [\"specificityA: \",specificityA],[\"specificityB: \",specificityB],\n          [\"specificityC: \",specificityC]\n          ]\n    return matrisim\n\ndef classifier(model,name,n1,n2,n3):\n    print(\"-------------\")\n    print(\"model name: \",str(name))\n    print(\"-------------\")\n    fig=plt.gcf()\n    fig.set_size_inches(10,5)\n    plt.subplot(n1,n2,n3)\n    plt.title('train')\n    model.fit(x_train,y_train)\n    y_pred0=cross_val_predict(model,x_train,y_train,cv=10)\n    cm=confusion_matrix(y_train,y_pred0)\n    sns.heatmap(cm,annot=True,fmt=\"d\")\n    print(\"accuracy_score\")\n    print(metrics.accuracy_score(y_train, y_pred0))\n    print(\"sensitivity\")\n    print(metrics.recall_score(y_train, y_pred0, average='macro'))\n    print(\"precision\")\n    print(metrics.precision_score(y_train, y_pred0, average='macro'))\n\n    \n    plt.subplot(n1,n2,n3+1)\n    plt.title('test')\n    model.fit(x_test,y_test)\n    y_pred00=cross_val_predict(model,x_test,y_test,cv=10)\n    cm2=confusion_matrix(y_test,y_pred00)\n    sns.heatmap(cm2,annot=True,fmt=\"d\")\n\n    plt.subplot(n1,n2,n3+2)\n    plt.title('validation all')\n    model.fit(X,Y)\n    y_pred2=cross_val_predict(model,X,Y,cv=10)\n    conf_mat2=confusion_matrix(Y,y_pred2)\n    sns.heatmap(conf_mat2,annot=True,fmt=\"d\")\n    # plt.show()\n\n#    a='iris'+str(name)+'.png'\n#    fig.savefig(a,dpi=100)\n\n\n    cv1 = cross_validate(model, x_train, y_train, cv=10)\n    cv2 = cross_validate(model, x_test, y_test, cv=10)\n    cv3 = cross_validate(model, X, Y, cv=10)\n\n    print('train '+str(name)+'accuracy is: ',cv1['test_score'].mean())\n    print('test '+str(name)+' accuracy is: ',cv2['test_score'].mean())\n    print('validation all'+str(name)+'accuracy is: ',cv3['test_score'].mean())\n    print('')\n    \n    matris1 = computing(cm)\n    matris2 = computing(cm2)\n    matris3 = computing(conf_mat2)\n    \n    return matris1,matris2,matris3","76bc3695":"knn=KNeighborsClassifier(n_neighbors=8)\nkmeans = KMeans(n_clusters = 3, n_jobs = 4, random_state=21)","15425e93":"matris1,matris2,matris3=classifier(kmeans,\"kmeans\",4,3,1)\nmatris11,matris22,matris33=classifier(knn,\"knn\",4,3,2)","3b355ec1":"centers = kmeans.cluster_centers_\nprint(centers)","e4cd5c8c":"new_labels = kmeans.labels_\nfig, axes = plt.subplots(1, 2, figsize=(16,8))\naxes[0].scatter(X[:, 0], X[:, 1], c=Y, cmap='gist_rainbow',\nedgecolor='k', s=150)\naxes[1].scatter(X[:, 0], X[:, 1], c=new_labels, cmap='jet',\nedgecolor='k', s=150)\naxes[0].set_xlabel('Sepal length', fontsize=18)\naxes[0].set_ylabel('Sepal width', fontsize=18)\naxes[1].set_xlabel('Sepal length', fontsize=18)\naxes[1].set_ylabel('Sepal width', fontsize=18)\naxes[0].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20)\naxes[1].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20)\naxes[0].set_title('Actual', fontsize=18)\naxes[1].set_title('Predicted', fontsize=18)","1006ea21":"plt.scatter(X[:,0], X[:,1]);","c27e92b4":"plt.scatter(X[:,0], X[:,1], c=kmeans.labels_);","d511e517":"plt.scatter(X[:,0],X[:,1], c=kmeans.labels_);\nplt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s=100, color=\"red\"); # Show the centres","ab7c8b06":"G\u00f6rselle\u015ftirme**","5c35e8cd":"Model de\u011ferlendirme\nS\u0131n\u0131fland\u0131r\u0131c\u0131n\u0131n veya modelin \u00e7e\u015fitlerin t\u00fcr\u00fcn\u00fc ne kadar do\u011fru tahmin edebilece\u011fini tahmin edelim.\n\nDo\u011fruluk, ger\u00e7ek test seti de\u011ferleri ve \u00f6ng\u00f6r\u00fclen de\u011ferler kar\u015f\u0131la\u015ft\u0131r\u0131larak hesaplanabilir.","d3c331b8":"Kullanaca\u011f\u0131m\u0131z hesaplama ve training fonksiyonlar\u0131n\u0131 olu\u015ftural\u0131m","3321d576":"Veri B\u00f6lme\nModel performans\u0131n\u0131 anlamak i\u00e7in, veri setini bir e\u011fitim setine ve bir test setine b\u00f6lmek iyi bir stratejidir.","249156a3":"Gerekli K\u00fct\u00fcphaneleri \u0130\u00e7e Aktarma\n\u0130lk \u00f6nce gerekli k\u00fct\u00fcphaneleri y\u00fckleyelim.","4cb1e1e6":"Verileri y\u00fckleme","bb010f79":"KNN ve KMeans Modeli Olu\u015fturma\nScikit-learn kullanarak h\u0131zl\u0131ca olu\u015ftural\u0131m.","b221215e":"**KNN and KMeans CLASSIFIER**","732ab768":"\u00d6znitelik Se\u00e7imi\nBurada, verilen s\u00fctunlar\u0131 ba\u011f\u0131ml\u0131 (veya hedef de\u011fi\u015fken) ve ba\u011f\u0131ms\u0131z de\u011fi\u015fken (veya \u00f6zellik de\u011fi\u015fkenleri) olmak \u00fczere iki t\u00fcr de\u011fi\u015fkene b\u00f6lmeniz gerekir."}}