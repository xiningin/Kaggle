{"cell_type":{"e560be90":"code","99c9ae66":"code","bf77751f":"code","32cc2ec1":"code","c94ccbc4":"code","10c2a053":"code","4a40ddd3":"code","47552468":"code","29f609ba":"code","3afe82ef":"code","0927b98a":"code","b05e8e64":"code","be8b3d28":"code","136246f1":"code","204488a0":"code","e9b8656c":"code","eca18939":"code","245c9581":"code","5b3fde17":"code","c562e7ed":"code","573078c3":"markdown"},"source":{"e560be90":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","99c9ae66":"!pip install transformers\n\nimport time\nimport sys\nimport copy\nimport torch \nimport numpy as np\nfrom scipy.sparse import *\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport pyarrow as pa\n\nimport torch.nn as nn\nfrom torch.optim import lr_scheduler\nimport torch.nn.functional as F\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import Dataset,DataLoader\nfrom transformers import DistilBertConfig,DistilBertTokenizer,DistilBertModel\n\nimport pandas as pd\n\nif not sys.warnoptions:\n    import warnings\n    warnings.simplefilter(\"ignore\")","bf77751f":"sample_submission = pd.read_csv('\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/sample_submission.csv')\ntest_labels = pd.read_csv('\/\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/test_labels.csv')\ntrain = pd.read_csv('\/\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv')\ntest = pd.read_csv('\/\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/test.csv')","32cc2ec1":"train.head(7)","c94ccbc4":"## Feature engineering to prepare inputs for BERT....\n\n\nY = train[['toxic','severe_toxic','obscene','threat','insult','identity_hate']].astype(float)\nX = train['comment_text']\n\n\nX_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.33, random_state=42)","10c2a053":"print('train_x shape is {}' .format({X_train.shape}))\nprint('test_x shape is {}' .format({X_test.shape}))\nprint('train_y shape is {}' .format({y_train.shape}))","4a40ddd3":"X_train = X_train.values\nX_test = X_test.values\ny_train = y_train.values\ny_test = y_test.values","47552468":"def accuracy_thresh(y_pred, y_true, thresh:float=0.4, sigmoid:bool=True):\n    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n    if sigmoid: y_pred = y_pred.sigmoid()\n#     return ((y_pred>thresh)==y_true.byte()).float().mean().item()\n    return np.mean(((y_pred>thresh).float()==y_true.float()).float().cpu().numpy(), axis=1).sum()\n#Expected object of scalar type Bool but got scalar type Double for argument #2 'other'","29f609ba":"config = DistilBertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,dropout=0.1,num_labels=6,\n        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)","3afe82ef":"class DistilBertForSequenceClassification(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.num_labels = config.num_labels\n\n        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n        self.pre_classifier = nn.Linear(config.hidden_size, config.hidden_size)\n        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n        self.dropout = nn.Dropout(config.seq_classif_dropout)\n\n        nn.init.xavier_normal_(self.classifier.weight)\n\n    def forward(self, input_ids=None, attention_mask=None, head_mask=None, labels=None):\n        distilbert_output = self.distilbert(input_ids=input_ids,\n                                            attention_mask=attention_mask,\n                                            head_mask=head_mask)\n        hidden_state = distilbert_output[0]                    \n        pooled_output = hidden_state[:, 0]                   \n        pooled_output = self.pre_classifier(pooled_output)   \n        pooled_output = nn.ReLU()(pooled_output)             \n        pooled_output = self.dropout(pooled_output)        \n        logits = self.classifier(pooled_output) \n        return logits","0927b98a":"max_seq_length = 256\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n\n\nclass text_dataset(Dataset):\n    def __init__(self,x,y, transform=None):\n        \n        self.x = x\n        self.y = y\n        self.transform = transform\n        \n    def __getitem__(self,index):\n        \n        tokenized_comment = tokenizer.tokenize(self.x[index])\n        \n        if len(tokenized_comment) > max_seq_length:\n            tokenized_comment = tokenized_comment[:max_seq_length]\n            \n        ids_review  = tokenizer.convert_tokens_to_ids(tokenized_comment)\n\n        padding = [0] * (max_seq_length - len(ids_review))\n        \n        ids_review += padding\n        \n        assert len(ids_review) == max_seq_length\n        \n        #print(ids_review)\n        ids_review = torch.tensor(ids_review)\n        \n        hcc = self.y[index] # toxic comment        \n        list_of_labels = [torch.from_numpy(hcc)]\n        \n        \n        return ids_review, list_of_labels[0]\n    \n    def __len__(self):\n        return len(self.x)\n ","b05e8e64":"text_dataset(X_train, y_train).__getitem__(6)[1]   ### Testing index 6 to see output","be8b3d28":"batch_size = 32\n\n\ntraining_dataset = text_dataset(X_train,y_train)\n\ntest_dataset = text_dataset(X_test,y_test)\n\ndataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=False),\n                   'val':torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n                   }\ndataset_sizes = {'train':len(X_train),\n                'val':len(X_test)}\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = DistilBertForSequenceClassification(config)\nmodel.to(device)\n\nprint(device)\n","136246f1":"def train_model(model, criterion, optimizer, scheduler, num_epochs=2):\n    model.train()\n    since = time.time()\n    print('starting')\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_loss = 100\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch+1, num_epochs))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            \n            beta_score_accuracy = 0.0\n            \n            micro_roc_auc_acc = 0.0\n            \n            \n            # Iterate over data.\n            for inputs, hcc in dataloaders_dict[phase]:\n                \n                inputs = inputs.to(device) \n                hcc = hcc.to(device)\n            \n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    \n                    loss = criterion(outputs,hcc.float())\n                    \n                    if phase == 'train':\n                        \n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                \n                micro_roc_auc_acc +=  accuracy_thresh(outputs.view(-1,6),hcc.view(-1,6))\n                \n                #print(micro_roc_auc_acc)\n\n                \n            epoch_loss = running_loss \/ dataset_sizes[phase]\n\n            \n            epoch_micro_roc_acc = micro_roc_auc_acc \/ dataset_sizes[phase]\n\n            print('{} total loss: {:.4f} '.format(phase,epoch_loss ))\n            print('{} micro_roc_auc_acc: {:.4f}'.format( phase, epoch_micro_roc_acc))\n\n            if phase == 'val' and epoch_loss < best_loss:\n                print('saving with loss of {}'.format(epoch_loss),\n                      'improved over previous {}'.format(best_loss))\n                best_loss = epoch_loss\n                best_model_wts = copy.deepcopy(model.state_dict())\n                torch.save(model.state_dict(), 'distilbert_model_weights.pth')\n         \n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(float(best_loss)))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n \nprint('done')","204488a0":"lrlast = .001\nlrmain = 3e-5\n#optim1 = torch.optim.Adam(\n#    [\n#        {\"params\":model.parameters,\"lr\": lrmain},\n#        {\"params\":model.classifier.parameters(), \"lr\": lrlast},\n#       \n#   ])\n\noptim1 = torch.optim.Adam(model.parameters(),lrmain)\n\noptimizer_ft = optim1\ncriterion = nn.BCEWithLogitsLoss()\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)","e9b8656c":"model_ft1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=8)","eca18939":"#y_test = test[['toxic','severe_toxic','obscene','threat','insult','identity_hate']].values\nx_test = test['comment_text']\ny_test = np.zeros(x_test.shape[0]*6).reshape(x_test.shape[0],6)\n\ntest_dataset = text_dataset(x_test,y_test)\nprediction_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n\ndef preds(model,test_loader):\n    predictions = []\n    for inputs, sentiment in test_loader:\n        inputs = inputs.to(device) \n        sentiment = sentiment.to(device)\n        with torch.no_grad():\n            outputs = model(inputs)\n            outputs = torch.sigmoid(outputs)\n            predictions.append(outputs.cpu().detach().numpy().tolist())\n    return predictions","245c9581":"predictions = preds(model=model_ft1,test_loader=prediction_dataloader)\npredictions = np.array(predictions)[:,0]","5b3fde17":"submission = pd.DataFrame(predictions,columns=['toxic','severe_toxic','obscene','threat','insult','identity_hate'])\ntest[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]=submission\nfinal_sub = test[['id','toxic','severe_toxic','obscene','threat','insult','identity_hate']]\nfinal_sub.head()","c562e7ed":"final_sub.to_csv('submissions.csv',index=False)#\nfinal_sub.head()","573078c3":"## Make_Predictions"}}