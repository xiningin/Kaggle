{"cell_type":{"27d23567":"code","150c910a":"code","33743f72":"code","95e5ba62":"code","2d111305":"code","d48e542e":"code","fb632013":"code","53bc92ad":"code","02b1bfcd":"code","498df890":"code","193fe0fa":"code","51a3cf47":"code","d937df58":"code","8698926a":"code","5860b351":"code","001f83b0":"code","05ab6541":"code","c5fa1afb":"code","fd545aba":"markdown","818db3bf":"markdown","9a2bd85b":"markdown","527140d9":"markdown","e6aa0410":"markdown","e9631476":"markdown","46973c21":"markdown","f67f4bf2":"markdown","d08df765":"markdown"},"source":{"27d23567":"!mkdir ~\/.keras\n!mkdir ~\/.keras\/models\n!cp ..\/input\/keras-pretrained-models\/*notop* ~\/.keras\/models\/\n!cp ..\/input\/keras-pretrained-models\/imagenet_class_index.json ~\/.keras\/models\/\n!cp ..\/input\/keras-pretrained-models\/resnet50* ~\/.keras\/models\/","150c910a":"%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom glob import glob \nimport matplotlib.pyplot as plt\nimport os\nimport pandas as pd\nimport seaborn as sns\nfrom skimage.util import montage\nfrom skimage.io import imread\nbase_dir = os.path.join('..', 'input', 'pulmonary-chest-xray-abnormalities')\n","33743f72":"mont_paths = glob(os.path.join(base_dir, 'Montgomery', 'MontgomerySet', '*', '*.*'))\nshen_paths = glob(os.path.join(base_dir, 'ChinaSet_AllFiles', 'ChinaSet_AllFiles', '*', '*.*'))\nprint('Montgomery Files', len(mont_paths))\nprint('Shenzhen Files', len(shen_paths))\nall_paths_df = pd.DataFrame(dict(path = mont_paths + shen_paths))\nall_paths_df['source'] = all_paths_df['path'].map(lambda x: x.split('\/')[3])\nall_paths_df['file_id'] = all_paths_df['path'].map(lambda x: os.path.splitext(os.path.basename(x))[0])\nall_paths_df['patient_group']  = all_paths_df['file_id'].map(lambda x: x.split('_')[0])\n\nall_paths_df['file_ext'] = all_paths_df['path'].map(lambda x: os.path.splitext(x)[1][1:])\nall_paths_df = all_paths_df[all_paths_df.file_ext.isin(['png', 'txt'])]\nall_paths_df['pulm_state']  = all_paths_df['file_id'].map(lambda x: int(x.split('_')[-1]))\nall_paths_df.sample(5)","95e5ba62":"clean_patients_df = all_paths_df.pivot_table(index = ['patient_group', 'pulm_state', 'file_id'], \n                                             columns=['file_ext'], \n                                             values = 'path', aggfunc='first').reset_index()\nclean_patients_df.sample(5)\nfrom warnings import warn\ndef report_to_dict(in_path):\n    with open(in_path, 'r') as f:\n        all_lines = [x.strip() for x in f.read().split('\\n')]\n    info_dict = {}\n    try:\n        if \"Patient's Sex\" in all_lines[0]:\n            info_dict['age'] = all_lines[1].split(':')[-1].strip().replace('Y', '')\n            info_dict['sex'] = all_lines[0].split(':')[-1].strip()\n            info_dict['report'] = ' '.join(all_lines[2:]).strip()\n        else:\n            info_dict['age'] = all_lines[0].split(' ')[-1].replace('yrs', '').replace('yr', '')\n            info_dict['sex'] = all_lines[0].split(' ')[0].strip()\n            info_dict['report'] = ' '.join(all_lines[1:]).strip()\n        \n        info_dict['sex'] = info_dict['sex'].upper().replace('FEMALE', 'F').replace('MALE', 'M').replace('FEMAL', 'F')[0:1]\n        if 'month' in info_dict.get('age', ''):\n            info_dict.pop('age') # invalid\n        if 'day' in info_dict.get('age', ''):\n            info_dict.pop('age') # invalid\n        elif len(info_dict.get('age',''))>0:\n            info_dict['age'] = float(info_dict['age'])\n        else:\n            info_dict.pop('age')\n        return info_dict\n    except Exception as e:\n        print(all_lines)\n        warn(str(e), RuntimeWarning)\n        return {}\nreport_df = pd.DataFrame([dict(**report_to_dict(c_row.pop('txt')), **c_row) \n              for  _, c_row in clean_patients_df.iterrows()])\nreport_df.sample(5)","2d111305":"report_df[['age', 'patient_group', 'pulm_state', 'sex']].hist(figsize = (10, 5))","d48e542e":"from sklearn.model_selection import train_test_split\nraw_train_df, valid_df = train_test_split(report_df, \n                                   test_size = 0.25, \n                                   random_state = 2018,\n                                   stratify = report_df[['pulm_state', 'patient_group']])\nprint('train', raw_train_df.shape[0], 'validation', valid_df.shape[0])\nraw_train_df.sample(1)","fb632013":"train_df = raw_train_df.groupby(['pulm_state', 'patient_group']).apply(lambda x: x.sample(400, replace = True)\n                                                      ).reset_index(drop = True)\nprint('New Data Size:', train_df.shape[0], 'Old Size:', raw_train_df.shape[0])\ntrain_df[['pulm_state', 'patient_group']].hist(figsize = (10, 5))","53bc92ad":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom PIL import Image\nppi = lambda x: Image.fromarray(preprocess_input(np.array(x).astype(np.float32)))\nIMG_SIZE = (224, 224) # slightly smaller than vgg16 normally expects\ncore_idg = ImageDataGenerator(samplewise_center=False, \n                              samplewise_std_normalization=False, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range = 0.15, \n                              width_shift_range = 0.15, \n                              rotation_range = 5, \n                              shear_range = 0.01,\n                              fill_mode = 'nearest',\n                              zoom_range=0.10)","02b1bfcd":"def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen","498df890":"from tensorflow.keras.utils import to_categorical\ntrain_gen = flow_from_dataframe(core_idg, train_df, \n                             path_col = 'png',\n                            y_col = 'pulm_state', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 8)\n\nvalid_gen = flow_from_dataframe(core_idg, valid_df, \n                             path_col = 'png',\n                            y_col = 'pulm_state', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 32) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(flow_from_dataframe(core_idg, \n                               valid_df, \n                             path_col = 'png',\n                            y_col = 'pulm_state', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',batch_size=32)) # one big batch\n","193fe0fa":"t_x, t_y = next(train_gen)\nfig, m_axs = plt.subplots(2, 4, figsize = (16, 8))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone', vmin = 0, vmax = 255)\n    c_ax.set_title('%s' % ('Pulmonary Abnormality' if c_y>0.5 else 'Healthy'))\n    c_ax.axis('off')","51a3cf47":"from tensorflow.keras.applications import ResNet50,VGG16\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D,Dropout,Input\n\n#image_input=Input(shape=(224,224,3))\nweights='..\/input\/keras_pretrained_models\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nHEIGHT=224\nWIDTH=224\nDEPTH=3\n\nmodel=Sequential()\nmodel.add(ResNet50(include_top=False,pooling='avg',weights='imagenet'))\nmodel.add(Dense(1024,activation='relu'))\nmodel.add(Dense(1024,activation='relu'))\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(0.7))\nmodel.add(Dense(2,activation='softmax',activity_regularizer=regularizers.l2(0.01)))\nmodel.layers[0].trainable=False\nfrom tensorflow.python.keras.optimizers import SGD,RMSprop,Adam\nsgd=SGD(lr=0.001,decay=1e-6,momentum=0.9,nesterov=True)\nmodel.compile(optimizer=sgd,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n","d937df58":"!rm -rf ~\/.keras # clean up the model \/ make space for other things","8698926a":"from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('tb_detector')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', \n                             save_best_only=True, save_weights_only = True)\n\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto')\nearly = EarlyStopping(monitor=\"val_loss\",  patience=5) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early]","5860b351":"history=model.fit_generator(train_gen,\n                       validation_data = (test_X, test_Y),\n                       steps_per_epoch=5,\n                       epochs = 40,\n                   verbose=1)\n\nimport matplotlib.pyplot as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()","001f83b0":"# load the best version of the model\n#model.load_weights(weight_path)\nmodel.save('full_tb_model.h5',include_optimizer=False)","05ab6541":"pred_Y = model.predict(test_X, batch_size = 8 , verbose = True)","c5fa1afb":"scores=model.evaluate(test_X,test_Y)","fd545aba":"## Preprocessing\nTurn the HDF5 into a data-frame and a folder full of TIFF files","818db3bf":"### Copy\ncopy the weights and configurations for the pre-trained models","9a2bd85b":"# Attention Model\nThe basic idea is that a Global Average Pooling is too simplistic since some of the regions are more relevant than others. So we build an attention mechanism to turn pixels in the GAP on an off before the pooling and then rescale (Lambda layer) the results based on the number of pixels. The model could be seen as a sort of 'global weighted average' pooling. There is probably something published about it and it is very similar to the kind of attention models used in NLP.\nIt is largely based on the insight that the winning solution annotated and trained a UNET model to segmenting the hand and transforming it. This seems very tedious if we could just learn attention.","527140d9":"# Examine the distributions\nShow how the data is distributed and why we need to balance it","e6aa0410":"# Balance the distribution in the training set","e9631476":"# Evaluate the results\nHere we evaluate the results by loading the best version of the model and seeing how the predictions look on the results. We then visualize spec","46973c21":"# Split Data into Training and Validation","f67f4bf2":"# Overview\nThis is just a simple first attempt at a model using VGG16 as a basis and attempting to do classification directly on the chest x-ray using low-resolution images (192x192)\n\nThis can be massively improved with \n* high-resolution images\n* better data sampling\n* ensuring there is no leaking between training and validation sets, ```sample(replace = True)``` is real dangerous\n* pretrained models\n* attention\/related techniques to focus on areas","d08df765":"# Show Attention\nDid our attention model learn anything useful?"}}