{"cell_type":{"7a773c84":"code","8069aa12":"code","5f8e9832":"code","774b8a4f":"code","02e7856e":"code","73d4fa97":"code","8a55c28c":"code","25d67f1e":"code","ec00b74c":"code","a3c6c7f0":"code","cc6f6682":"code","9120c0cc":"code","dac87a98":"code","d6f74fe0":"code","b1ef5c8d":"markdown","03172290":"markdown","5f25069b":"markdown","0bb904d8":"markdown","1f94289c":"markdown","937916bd":"markdown","b122b4f1":"markdown","feb99585":"markdown","f12d7765":"markdown","d403feae":"markdown"},"source":{"7a773c84":"from shutil import copyfile\ncopyfile(src = \"..\/input\/modules\/dataset_det.py\", dst = \"..\/working\/dataset_det.py\")\ncopyfile(src = \"..\/input\/vis-module\/vis.py\", dst = \"..\/working\/vis.py\")","8069aa12":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nfrom collections import OrderedDict\nimport matplotlib.pyplot as plt\n\nimport dataset_det as d_loader\n!pip install ipdb\nimport vis\nimport torch.utils.data as torch_d\nfrom torch.nn import functional as F\n!pip install torchsummary\nfrom torchsummary import summary","5f8e9832":"BATCHSIZE=50\n\ndataset = d_loader.Balls_CF_Detection (\"..\/input\/balls-images\/train\", 21000)\ntrain_dataset, test_dataset = torch_d.random_split(dataset, [int(21000*0.9), int(21000*0.1)])\n\ndataloaders = {}\ndataloaders['train'] = torch.utils.data.DataLoader(train_dataset,batch_size=BATCHSIZE, shuffle=True)\ndataloaders['val'] = torch.utils.data.DataLoader(test_dataset,batch_size=BATCHSIZE, shuffle=True)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","774b8a4f":"COLORS = ['red', 'green', 'blue', 'yellow', 'lime', 'purple', 'orange', 'cyan', 'magenta']\nfirst_batch = next(iter(dataloaders[\"train\"]))\nimages, labels, bb = first_batch\nimages = images.to(device)\n\nfor i in range(5):\n    plt.imshow(np.asarray(vis.show_bboxes(images[i].cpu(), bb[i].cpu(), COLORS)))\n    plt.show()","02e7856e":"vgg16 = models.vgg16(pretrained=True)\n\nfor param in vgg16.features.parameters():\n    param.requires_grad = False\n\nnum_features = vgg16.classifier[0].in_features\n\n#features = list(vgg16.classifier.children())[:-1] # Remove last layer\n#features.extend([nn.Linear(num_features, 36)]) # Add our layer with 9 outputs\n#vgg16.classifier = nn.Sequential(*features) # Replace the model classifier\n\nvgg16.classifier = nn.Sequential(\n        nn.Linear(num_features, 500),\n        nn.ReLU(),\n        #nn.Dropout(0.5),\n        nn.Linear(500, 36),\n        )\n\nprint(next(iter(vgg16.features[0].parameters())).requires_grad)\nprint(vgg16)","73d4fa97":"def intersect(box_a, box_b):\n    \"\"\" We resize both tensors to [A,B,2] without new malloc:\n    [A,2] -> [A,1,2] -> [A,B,2]\n    [B,2] -> [1,B,2] -> [A,B,2]\n    Then we compute the area of intersect between box_a and box_b.\n    Args:\n      box_a: (tensor) bounding boxes, Shape: [A,4].\n      box_b: (tensor) bounding boxes, Shape: [B,4].\n    Return:\n      (tensor) intersection area, Shape: [A,B].\n    \"\"\"\n    A = box_a.size(0)\n    B = box_b.size(0)\n    max_xy = torch.min(box_a[:, 2:].unsqueeze(1).expand(A, B, 2),\n                       box_b[:, 2:].unsqueeze(0).expand(A, B, 2))\n    min_xy = torch.max(box_a[:, :2].unsqueeze(1).expand(A, B, 2),\n                       box_b[:, :2].unsqueeze(0).expand(A, B, 2))\n    inter = torch.clamp((max_xy - min_xy), min=0)\n    return inter[:, :, 0] * inter[:, :, 1]","8a55c28c":"def IOU(box_a, box_b):\n    \"\"\"Compute the jaccard overlap of two sets of boxes.  The jaccard overlap\n    is simply the intersection over union of two boxes.  Here we operate on\n    ground truth boxes and default boxes.\n    E.g.:\n        A \u2229 B \/ A \u222a B = A \u2229 B \/ (area(A) + area(B) - A \u2229 B)\n    Args:\n        box_a: (tensor) Ground truth bounding boxes, Shape: [num_objects,4]\n        box_b: (tensor) Prior boxes from priorbox layers, Shape: [num_priors,4]\n    Return:\n        jaccard overlap: (tensor) Shape: [box_a.size(0), box_b.size(0)]\n    \"\"\"\n    inter = intersect(box_a, box_b)\n    area_a = ((box_a[:, 2]-box_a[:, 0]) *\n              (box_a[:, 3]-box_a[:, 1])).unsqueeze(1).expand_as(inter)  # [A,B]\n    area_b = ((box_b[:, 2]-box_b[:, 0]) *\n              (box_b[:, 3]-box_b[:, 1])).unsqueeze(0).expand_as(inter)  # [A,B]\n    union = area_a + area_b - inter\n    return inter \/ union  # [A,B]","25d67f1e":"def calcLoss (model, dataloader, customLoss, mse):\n    correct = 0\n    with torch.no_grad():\n        for data in dataloader:\n            images, labels, bb= data\n            images = images.to(device)\n            bb = bb.to(device)\n            outputs = model(images)\n            correct += (customLoss(outputs, bb) + mse(outputs, bb.view(-1, 36))) * outputs.size(0)\n    return (correct \/ len(dataloader.dataset))","ec00b74c":"def iouLoss(outputs, groundtruth_bb):\n    bb = groundtruth_bb.view(-1, 36)\n    iou = 0\n    bb = bb.view(-1, 9, 4)\n    outputs = outputs.view(-1, 9, 4)\n    for i in range(outputs.size(0)):\n        iou += IOU(outputs[i], bb[i])\n    iou = iou \/ outputs.size(0)\n    return (1 - iou.mean())","a3c6c7f0":"def train_model(dataloaders, model, criterion, optimizer, scheduler, num_epochs=25):\n    train_accuracies = []\n    valid_accuracies = []\n    \n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_loss = calcLoss(model, dataloaders[\"val\"], customLoss, criterion)\n    print('Initial val loss: {:.4f}'.format(best_loss))\n\n    for epoch in range(1, num_epochs+1):\n        print('Epoch {}\/{}'.format(epoch, num_epochs))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels, bb in dataloaders[phase]:\n                inputs = inputs.to(device)\n                bb = bb.view(-1, 36).to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    \n                    loss = customLoss(outputs, bb) + criterion(outputs, bb)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n            if phase == 'train' and scheduler != None:\n                scheduler.step()\n\n            epoch_loss = running_loss \/ (len(dataloaders[phase].dataset))\n            \n            if phase == 'train':\n                train_accuracies.append(epoch_loss)\n            else:\n                valid_accuracies.append(epoch_loss)\n\n            print('{} Loss: {:.4f} '.format(\n                phase, epoch_loss))\n\n            # deep copy the model\n            if phase == 'val' and epoch_loss < best_loss:\n                best_loss = epoch_loss\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val loss: {:4f}'.format(best_loss))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, train_accuracies, valid_accuracies","cc6f6682":"model = vgg16.to(device)\n\ncriterion = torch.nn.MSELoss()\ncustomLoss = iouLoss\n\noptimizer = optim.Adam(model.parameters(), 0.00001)","9120c0cc":"EPOCH_NUMBER = 70\n\nmodel, train_accs, val_accs = train_model(dataloaders, model, criterion, optimizer, None,\n                       num_epochs=EPOCH_NUMBER)\n\ntorch.save(model.state_dict(), \".\/model\")","dac87a98":"f = plt.figure(figsize=(10, 8))\nplt.plot(train_accs, label='training loss')\nplt.plot(val_accs, label='validation loss')\nplt.legend()\nplt.show()","d6f74fe0":"COLORS = ['red', 'green', 'blue', 'yellow', 'lime', 'purple', 'orange', 'cyan', 'magenta']\nfirst_batch = next(iter(dataloaders[\"val\"]))\nimages, labels, bb = first_batch\nimages = images.to(device)\npreds_bb = model(images).view(-1, 9, 4)\n\nfor i in range(5):\n    plt.imshow(np.asarray(vis.show_bboxes(images[i].cpu(), preds_bb[i].cpu(), COLORS)))\n    plt.show()","b1ef5c8d":"## Custom accuracy metrics definition","03172290":"## Let's have a glance at the data","5f25069b":"## Training monitoring plots","0bb904d8":"## Training schedule definition","1f94289c":"## Split the dataset and define the dataloaders","937916bd":"# VGG16 multi-dimension regression transfer learning on the three balls' bounding boxes problem","b122b4f1":"## Train !","feb99585":"## Double check the model performance","f12d7765":"## Model definition","d403feae":"## Define loss and optimizer"}}