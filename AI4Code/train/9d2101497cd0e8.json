{"cell_type":{"01291c3c":"code","c3c374f0":"code","8fab335f":"code","fd411f12":"code","f7e5a4ee":"code","793e880d":"code","c98d585b":"code","9c920faa":"code","ec88b91d":"code","1d6faa96":"code","e8516428":"code","a6b1f18b":"markdown","78403afc":"markdown","bf8151b4":"markdown","de2aeaf8":"markdown","a4d92214":"markdown","9afabd47":"markdown"},"source":{"01291c3c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nimport pylab\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c3c374f0":"## categorical data encoding\nOH_encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n\n## read train data\ntrain_data = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv', index_col='id')\nX = train_data.iloc[:,:75]\n# One-Hot encode the labels\ny = pd.DataFrame(OH_encoder.fit_transform(pd.DataFrame(train_data.target)))\ny = y.rename(columns={i:f'Class_{i+1}' for i in range(9)})\n# train_data.head()\n\n## scale train data\n\"\"\" I observed StandardScaler gives better performance than MinMaxScaler\"\"\"\nsc = StandardScaler()\nX = sc.fit_transform(X)\n\n## read test data\ntest_data = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv', index_col='id')\nX_test = test_data.iloc[:,:]\n\n## scale train data\nX_test = sc.fit_transform(X_test)\n# test_data.head()","8fab335f":"##class distribution is imbalanced\ntrain_data.target.value_counts()","fd411f12":"pca = PCA(n_components=2)\npca.fit(X)\nX_pca = pca.transform(X)\nX_test_pca = pca.transform(X_test)","f7e5a4ee":"## no distinguishable boundary as such\ncolors = []\nfor i in train_data.target:\n    colors.append(int(i.split('_')[-1]))\nplt.scatter(X_pca[:,0], X_pca[:,1], c=colors, cmap='viridis')","793e880d":"## We  observe with no of features variance retained increases linearly. \n## This is interesting, as typically the increase is exponential.\n\nratios = [round(i*0.05,2) for i in range(10,20)]\ndimensions = []\nfor r in ratios:\n    pca = PCA(r)\n    pca.fit(X)\n    X_pca_ratio = pca.transform(X)\n    dimensions.append(X_pca_ratio.shape[1])\nplt.plot(ratios, dimensions)","c98d585b":"def my_model(ip_size):\n    model = keras.Sequential([\n        layers.InputLayer([ip_size]),\n        layers.Dense(96, activation='relu'),\n        layers.Dropout(rate=0.2),\n        layers.BatchNormalization(),\n        layers.Dense(128, activation='relu'),\n        layers.Dropout(rate=0.2),\n        layers.BatchNormalization(),\n        layers.Dense(256, activation='relu'),\n        layers.Dropout(rate=0.25),\n#         layers.BatchNormalization(),\n#         layers.Dense(512, activation='relu'),\n#         layers.Dropout(rate=0.5),\n#         layers.BatchNormalization(),\n        layers.Dense(9, activation='softmax')\n    ])\n    \n    opt = keras.optimizers.Adam(learning_rate=0.0005)\n    \n    model.compile(\n        optimizer=opt,\n        loss='categorical_crossentropy',\n        metrics=['categorical_crossentropy']\n    )\n    return model","9c920faa":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n                                                      train_size=0.9, \n                                                      test_size=0.1, \n                                                      stratify=y,\n                                                      random_state=0)\npca_final = PCA(0.85)\nX_train = pca_final.fit_transform(X_train)\nX_valid = pca_final.transform(X_valid)","ec88b91d":"early_stopping = keras.callbacks.EarlyStopping(\n    patience=50,\n    min_delta=0.0005,\n    restore_best_weights=False,\n    verbose=2\n)\n\nmodel = my_model(X_train.shape[1])\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=90,\n    epochs=200,\n    callbacks=[early_stopping]\n)","1d6faa96":"fig, ax = plt.subplots(1,2,figsize=(12, 4))\nax[0].plot(history.history['loss'], label=\"Training loss\")\nax[0].plot(history.history['val_loss'], label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['categorical_crossentropy'], label=\"Training accuracy\")\nax[1].plot(history.history['val_categorical_crossentropy'],label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)\n\n\nplt.setp(ax[:], xlabel='epoch')\nplt.setp(ax[0], ylabel='loss')\nplt.setp(ax[1], ylabel='accuracy')\n\nplt.show()","e8516428":"predictions = model.predict(pca_final.transform(X_test))\noutput = pd.DataFrame(predictions)\noutput = output.rename(columns={i:f'Class_{i+1}' for i in range(9)})\noutput = output.rename_axis(\"id\", axis='rows')\nidcol = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv')\nidcol = idcol.iloc[:,0]\noutput = pd.concat([idcol, output], axis=1)\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","a6b1f18b":"Then, we'll train the model on the training data and check with validations. We'll use an early stopping metric as well, training on many epochs.","78403afc":"## The Model\nHow to use Activation, Dropout and BatchNormalization is still matter of discussions. There is no pre-defined rule here, mot probably a matter of opinion as this is empirical work. I found this [thread](https:\/\/stackoverflow.com\/questions\/39691902\/ordering-of-batch-normalization-and-dropout) useful.   \n\n- Activation and Dropout: for some functions such as ReLU order doesn't matter - [check here](https:\/\/sebastianraschka.com\/faq\/docs\/dropout-activation.html). In case of non-linear activation function, typically, dropout is applied after activation layer.  \n- BN used after Dropout bcs I found this [argument](https:\/\/stackoverflow.com\/a\/50698801\/5094187) intuitive.\n- Dropout rate kept low pertaining to [discussions in this direction](https:\/\/stackoverflow.com\/a\/59001644\/5094187).  \n- No dropout in last layer as per [discussions](https:\/\/stats.stackexchange.com\/questions\/361700\/lack-of-batch-normalization-before-last-fully-connected-layer)  \nSo the order I've used **Activation->Dropout->BN**\n\n**But** [this paper](https:\/\/arxiv.org\/pdf\/2107.02279.pdf) on design smells in DL programs recommends **Activation->BN->Dropout** with support from literature. Hence need to check with both configs.\n\nWe'll then compile the model with the Adam optimizer, the categorical_crossentropy as loss and metric.","bf8151b4":"# TPS-June2021 - Simple FeedForwad N\/W\nOriginal notebook was cloned from @pranjalchatterjee","de2aeaf8":"## Training and Validation\nNow, we'll set up the training and validation data.","a4d92214":"## Setting up the Data\nNow, we'll load and take a look at the data.","9afabd47":"## Prediction"}}