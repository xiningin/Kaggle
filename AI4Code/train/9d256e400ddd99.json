{"cell_type":{"1faae9ed":"code","b2bc5bd6":"code","974399c8":"code","5acbc9d3":"code","1837b787":"code","450a721d":"code","89272b03":"code","50aaa728":"code","52259d26":"code","0fc77b68":"code","49ca9b6e":"code","9c8861b6":"code","da85ae23":"code","f2522b94":"code","de967335":"code","76933357":"code","2ca8516b":"code","d2ae600d":"code","d393b4d4":"code","a3f47501":"code","78516ad4":"code","6553a1f9":"code","2639074a":"code","5a73eadd":"code","cee1fafd":"code","121a5dce":"code","085dc3aa":"code","d09ff9f1":"markdown","baf89738":"markdown","dd1afa6c":"markdown","acbdfad4":"markdown","b88aa0ed":"markdown","bc0abad4":"markdown","f110eed8":"markdown","6f591bd7":"markdown","c6db590f":"markdown","d03b5927":"markdown","690fc1a2":"markdown","1db6e5bd":"markdown","7e493382":"markdown","bb1baf79":"markdown"},"source":{"1faae9ed":"import fastai.vision as fv","b2bc5bd6":"fv.__version__","974399c8":"path_test =  fv.Path('\/kaggle\/input\/test');\npath_train = fv.Path('\/kaggle\/input\/train'); path_train.ls()","5acbc9d3":"fv.np.random.seed(1)\n\n### \u521b\u5efaDataBunch\n\ndata = fv.ImageDataBunch.from_folder(path_train,\n                                  test=path_test, \n                                  ds_tfms=fv.get_transforms(),\n                                  valid_pct=0.25,\n                                  size=128, \n                                  bs=32,\n                                  num_workers=0)\ndata.normalize(fv.imagenet_stats)\ndata","1837b787":"learn = fv.cnn_learner(data, \n                      fv.models.resnet18, \n                      metrics=fv.error_rate,\n                      model_dir=\"\/kaggle\/working\/\")","450a721d":"learn.save('start')\n!ls .","89272b03":"learn.load('start')\nlearn.summary()","50aaa728":"learn.load('start')\nlearn.freeze()\nlearn.summary() # only linear and BatchNorm are trainable","52259d26":"learn.load('start')\nlearn.freeze_to(-1) # same to learn.freeze()\nlearn.summary()","0fc77b68":"learn.model \n# it has two large Sequential","49ca9b6e":"learn.load('start')\nlearn.freeze_to(-2)\nlearn.summary() # seem half of conv layer are trainable","9c8861b6":"learn.unfreeze()\nlearn.summary() # all trainable layers are free to train","da85ae23":"learn = fv.cnn_learner(data, \n                      fv.models.resnet34, \n                      metrics=fv.error_rate,\n                      model_dir=\"\/kaggle\/working\/\")","f2522b94":"learn.save('start34')\n!ls .","de967335":"learn.load('start34')\nlearn.summary()","76933357":"learn.load('start34')\nlearn.freeze()\nlearn.summary() ","2ca8516b":"learn.load('start34')\nlearn.freeze_to(-1) # same to learn.freeze()\nlearn.summary()","d2ae600d":"learn.model \n# it has two large Sequential, \n# the second or last one has 553,628 parameters \n# including BatchNorms params in first Sequential","d393b4d4":"learn.load('start34')\nlearn.freeze_to(-2)\nlearn.summary() # first 16 conv layer params turned off","a3f47501":"learn.load('start34')\nlearn.freeze_to(-3)\nlearn.summary() # seem half of conv layer are trainable","78516ad4":"learn.load('start34')\nlearn.unfreeze()\nlearn.summary() # all trainable layers are free to train","6553a1f9":"learn = fv.cnn_learner(data, \n                      fv.models.resnet152, \n                      metrics=fv.error_rate,\n                      model_dir=\"\/kaggle\/working\/\")","2639074a":"learn.summary()","5a73eadd":"learn.model # still just two overarching Sequental","cee1fafd":"learn = fv.cnn_learner(data, \n                      fv.models.densenet121, \n                      metrics=fv.error_rate,\n                      model_dir=\"\/kaggle\/working\/\")","121a5dce":"learn.summary()","085dc3aa":"learn.model","d09ff9f1":"To verfiy this understanding with four models below","baf89738":"[back](#0)","dd1afa6c":"`freeze` Docs:\n> Freeze up to last layer group.    \n> Sets every layer group except the last to untrainable (i.e. requires_grad=False).\n\nWhat does 'the last layer group' mean?    \nIn the case of transfer learning, such as `learn = cnn_learner(data, models.resnet18, metrics=error_rate)`, `learn.model`will print out two large groups of layers: (0) Sequential and (1) Sequental in the following structure. We can consider the last conv layer as the break line between the two groups.\n```\nSequential(\n  (0): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace)\n    ...\n    \n            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n             (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (1): Sequential(\n    (0): AdaptiveConcatPool2d(\n      (ap): AdaptiveAvgPool2d(output_size=1)\n      (mp): AdaptiveMaxPool2d(output_size=1)\n    )\n    (1): Flatten()\n    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.25)\n    (4): Linear(in_features=1024, out_features=512, bias=True)\n    (5): ReLU(inplace)\n    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.5)\n    (8): Linear(in_features=512, out_features=12, bias=True)\n  )\n)\n```\n\n`learn.freeze` freezes the first group and keeps the second or last group free to train, including multiple layers inside (this is why calling it 'group'), as you can see in `learn.summary()` output. How to read the table below, please see [model summary docs](https:\/\/docs.fast.ai\/callbacks.hooks.html#model_summary).\n\n```\n======================================================================\nLayer (type)         Output Shape         Param #    Trainable \n======================================================================\n...\n...\n...\n______________________________________________________________________\nConv2d               [1, 512, 4, 4]       2,359,296  False     \n______________________________________________________________________\nBatchNorm2d          [1, 512, 4, 4]       1,024      True      \n______________________________________________________________________\nAdaptiveAvgPool2d    [1, 512, 1, 1]       0          False     \n______________________________________________________________________\nAdaptiveMaxPool2d    [1, 512, 1, 1]       0          False     \n______________________________________________________________________\nFlatten              [1, 1024]            0          False     \n______________________________________________________________________\nBatchNorm1d          [1, 1024]            2,048      True      \n______________________________________________________________________\nDropout              [1, 1024]            0          False     \n______________________________________________________________________\nLinear               [1, 512]             524,800    True      \n______________________________________________________________________\nReLU                 [1, 512]             0          False     \n______________________________________________________________________\nBatchNorm1d          [1, 512]             1,024      True      \n______________________________________________________________________\nDropout              [1, 512]             0          False     \n______________________________________________________________________\nLinear               [1, 12]              6,156      True      \n______________________________________________________________________\n\nTotal params: 11,710,540\nTotal trainable params: 543,628\nTotal non-trainable params: 11,166,912\n```\n\n`freeze_to(int:n)` Docs:\n> Freeze layers up to layer group `n`.    \n\nHow to understand the use of integer `n`?     \nIf you experiment with the `learn` object from `learn.freeze` above, you will come to the following conclusions:\n- `freeze()` is equivalent to `freeze_to(-1)`, meaning all layer groups are frozen and can't be trained, except the last layer group. \n- `freeze_to(-3)` is equivalent to `unfreeze()`, all trainable parameters are ready to train. \n- `freeze_to(-2)` only freeze only a small proportion of conv layers in the (0) Sequential","acbdfad4":"[back](#0)","b88aa0ed":"[back](#0)","bc0abad4":"## <span id='use'><\/span> How to use `freeze` and `freeze_to`","f110eed8":"# <span id='3'><\/span> Model Res34","6f591bd7":"[back](#0)","c6db590f":"# <span id='densenet'><\/span> DenseNet121","d03b5927":"[back](#0)","690fc1a2":"# <span id='4'><\/span> Model Res152","1db6e5bd":"# <span id='1'><\/span> Prepare Data","7e493382":"# <span id='2'><\/span> Model Res18","bb1baf79":"# <span id='0'><\/span> Understanding Learner.freeze and freeze_to \n- [How to understand](#use)\n- [prepare data](#1)\n- [model Res18](#2)\n- [model Res34](#3)\n- [model Res152](#4)\n- [model Dense121](#densenet)"}}