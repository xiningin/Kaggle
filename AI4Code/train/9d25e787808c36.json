{"cell_type":{"5f6eb4fc":"code","08120338":"code","c3a534e3":"code","2e29d25b":"code","5f79c944":"code","2ce18f72":"code","0cd19127":"code","d09480a1":"code","dc1a0bf3":"code","a67c4bb4":"code","5f669c3d":"code","510c451b":"code","373b35bb":"code","af641225":"code","53fd793d":"code","278271cd":"code","caad5697":"code","64ebab7a":"markdown","0a6e1c86":"markdown","2baebc0d":"markdown","f473b9fe":"markdown"},"source":{"5f6eb4fc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","08120338":"!pip install transformers datasets -q","c3a534e3":"#since dataformat is in zip we can first load it into df then we import it into datasets format\ntrain_df = pd.read_csv(\"\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv.zip\",\n                      nrows=50)","2e29d25b":"import datasets","5f79c944":"data = datasets.Dataset.from_pandas(train_df)","2ce18f72":"data.shape #give shape as pandas","0cd19127":"data.num_columns #this function specifically to get num of columns","d09480a1":"data.column_names # to get column names","dc1a0bf3":"data.features # to get feature and their data types","a67c4bb4":"# we can just slice and pass inde value to get the data accordingly.\ndata[:3]","5f669c3d":"data['comment_text'][:3] # we can slice through column values also","510c451b":"#splitting using train test split\n\ndata.train_test_split(test_size=0.1)","373b35bb":"# we can change colum names \ntemp_data = data.rename_column(\"comment_text\", 'text')\nprint(temp_data.column_names)","af641225":"#we can remove extra columns, and can pass list of names same as dataframe\nprint(data.remove_columns('id') )\nprint(data.remove_columns(['id']))","53fd793d":"import re","278271cd":"def clean_text(row):\n    row['comment_text'] = ''.join(re.findall(r'[\\w ]*', row['comment_text']))\n    return row","caad5697":"# you can pass any function as long as it returns dict output as it take dict input\ndata.map(clean_text)[:3]","64ebab7a":"### cleaning data or using map functions","0a6e1c86":"## Preprocessing using hugging face datasets library\n","2baebc0d":"### Loading data and basic metadata\n\n1. import library\n2. load data from dataframe\n3. basic metadata functions like shape, num_columns, slicing etc..\n","f473b9fe":"### Filtering, Spliting, CURD operations"}}