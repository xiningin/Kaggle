{"cell_type":{"0da061ad":"code","ed35e4af":"code","1de91b98":"code","d33ed05a":"code","c587624d":"code","507e9642":"code","ec65b253":"code","41cac5c7":"code","a6872c47":"code","d869b90d":"code","1997b3f6":"code","59ce0657":"code","4891f69b":"code","f558ffaf":"code","64da6c55":"code","a46b480c":"code","ebe965e4":"code","9fbf80ff":"code","54002ee5":"code","ec9fe22a":"code","3a0a645f":"code","0bc0d228":"code","86d5e130":"code","0ebe1472":"code","970bda36":"code","23e8c158":"code","634a3d77":"code","18942b1e":"code","eb3a08c0":"code","c703fc58":"code","806ca639":"code","19555b97":"code","7eaee604":"code","1b504953":"code","0d2ecee0":"code","10c94095":"code","487c39f8":"code","d11bd4c5":"code","7865fcad":"code","8a57e644":"code","46cc1912":"code","c2a6f97d":"code","9b152fb1":"code","0104fa6b":"code","ae1eae32":"code","ae88d22b":"code","01cafbfc":"code","8563f9f5":"code","303c4ddb":"code","74b7b37a":"code","14b9d95f":"code","dec2dfa2":"code","6ec19ae7":"code","97507e6c":"code","d79b20f5":"code","4e83fd05":"code","250e32f6":"code","4043e32c":"code","d1c7cbee":"code","b1a46cb6":"code","a627caae":"code","1454623f":"markdown","bc535e17":"markdown","5dee9f44":"markdown","a02a04ef":"markdown","52a04277":"markdown","8c3d497e":"markdown","97278bb7":"markdown","e944806d":"markdown","aa06d322":"markdown","4c809d1d":"markdown","adcbf2d1":"markdown","673f38c6":"markdown","df935e4a":"markdown","d862c898":"markdown","ad9bb25e":"markdown","a7ade176":"markdown","8ab02c8b":"markdown","bc0de663":"markdown"},"source":{"0da061ad":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","ed35e4af":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom numpy import mean\nfrom numpy import std\nimport string\nimport warnings","1de91b98":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\n","d33ed05a":"\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler","c587624d":"dfTrain = pd.read_csv(dirname+\"\/train.csv\")\ndfTest = pd.read_csv(dirname+\"\/test.csv\")\ndfGenderSubmission = pd.read_csv(dirname+\"\/gender_submission.csv\")","507e9642":"dfTrain.head(5)","ec65b253":"dfTest.head(5)","41cac5c7":"dfGenderSubmission.head(5)","a6872c47":"print('The columns of Train are:\\n ', dfTrain.columns, 'and are', len(dfTrain.columns),'columns \\n', '='*90,'\\n', \n            '\\n','The columns of Test are: \\n', dfTest.columns,'and are',len(dfTest.columns),'columns'  )","d869b90d":"\ndef concat_df(train_data, test_data):\n    # Returns a concatenated df of training and test set\n    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n\ndef divide_df(all_data):\n    # Returns divided dfs of training and test set\n    return all_data.loc[:890], all_data.loc[891:].drop(['Survived'], axis=1)\ndfMrg = concat_df(dfTrain,dfTest)\ndfMrg.isna().sum()","1997b3f6":"dfMrg.describe()","59ce0657":"dfMrg['Title'] = dfMrg['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\npd.crosstab(dfMrg['Title'],dfMrg['Sex'])","4891f69b":"dfMrg['Title'] = dfMrg['Title'].replace(['Mlle','Lady','Dona','Ms','Countess'],'Miss')\ndfMrg['Title'] = dfMrg['Title'].replace(['Dona','Mme'],'Mrs')\ndfMrg['Title'] = dfMrg['Title'].replace(['Don','Jonkheer','Sir','Master'],'Mr')\ndfMrg['Title'] = dfMrg['Title'].replace(['Capt','Col','Major','Rev'],'Crew')\npd.crosstab(dfMrg['Title'],dfMrg['Sex'])","f558ffaf":"df_all_corr = dfMrg.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\ndf_all_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\ndf_all_corr[df_all_corr['Feature 1'] == 'Age']","64da6c55":"#Replace title Mr and Miss to Youth for people less than 15 years old\ntitleyouth = dfMrg[(dfMrg['Title'] == 'Miss') | (dfMrg['Title'] == 'Mr')]\ndfMrg.loc[titleyouth[(titleyouth['Age'] < 21)].index.tolist(),'Title'] = 'Youth'","a46b480c":"#Replace title Dr to Mr or Mrs. \ntitleDr = dfMrg[(dfMrg['Title'] == 'Dr')].dropna()\ndfMrg.loc[titleDr[(titleDr['Sex'] == 'female')].index.tolist(),'Title'] = 'Mrs'\ndfMrg['Title'] = dfMrg['Title'].replace(['Dr'],'Mr')\n\npd.crosstab(dfMrg['Title'],dfMrg['Sex'])","ebe965e4":"\ndfMrg.set_index('Title').isna().sum(level=0)['Age']","9fbf80ff":"age_by_pclass_sex = dfMrg.groupby(['Sex', 'Pclass']).median()['Age']","54002ee5":"for pclass in range(1, 4):\n    for sex in ['female', 'male']:\n        print('Median age of Pclass {} {}s: {}'.format(pclass, sex, age_by_pclass_sex[sex][pclass]))\nprint('Median age of all passengers: {}'.format(dfMrg['Age'].median()))","ec9fe22a":"dfMrg['Age'] = dfMrg.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))","3a0a645f":"sns.distplot(dfMrg['Age'].dropna(), hist=True, kde=True, \n              color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})\nplt.title(\"Age Distribution\")","0bc0d228":"dfMrg[dfMrg['Embarked'].isnull()]\ndfMrg['Embarked'] = dfMrg['Embarked'].fillna('S')","86d5e130":"dfMrg[dfMrg['Fare'].isnull()]\nmed_fare = dfMrg.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\n\ndfMrg['Fare'] = dfMrg['Fare'].fillna(med_fare)","0ebe1472":"dfMrg['Deck'] = dfMrg['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')","970bda36":"df_all_decks = dfMrg.groupby(['Deck', 'Pclass']).count().drop(columns=['Survived', 'Sex', 'Age', 'SibSp', 'Parch', \n                                                                        'Fare', 'Embarked', 'Cabin', 'PassengerId', 'Ticket']).rename(columns={'Name': 'Count'}).transpose()","23e8c158":"def get_pclass_dist(df):\n    \n    # Creating a dictionary for every passenger class count in every deck\n    deck_counts = {'A': {}, 'B': {}, 'C': {}, 'D': {}, 'E': {}, 'F': {}, 'G': {}, 'M': {}, 'T': {}}\n    decks = df.columns.levels[0]    \n    \n    for deck in decks:\n        for pclass in range(1, 4):\n            try:\n                count = df[deck][pclass][0]\n                deck_counts[deck][pclass] = count \n            except KeyError:\n                deck_counts[deck][pclass] = 0\n                \n    df_decks = pd.DataFrame(deck_counts)    \n    deck_percentages = {}\n\n    # Creating a dictionary for every passenger class percentage in every deck\n    for col in df_decks.columns:\n        deck_percentages[col] = [(count \/ df_decks[col].sum()) * 100 for count in df_decks[col]]\n        \n    return deck_counts, deck_percentages\n\n\n","634a3d77":"\ndef display_pclass_dist(percentages):\n    \n    df_percentages = pd.DataFrame(percentages).transpose()\n    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M', 'T')\n    bar_count = np.arange(len(deck_names))  \n    bar_width = 0.85\n    \n    pclass1 = df_percentages[0]\n    pclass2 = df_percentages[1]\n    pclass3 = df_percentages[2]\n    \n    plt.figure(figsize=(20, 10))\n    plt.bar(bar_count, pclass1, color='#b5ffb9', edgecolor='white', width=bar_width, label='Passenger Class 1')\n    plt.bar(bar_count, pclass2, bottom=pclass1, color='#f9bc86', edgecolor='white', width=bar_width, label='Passenger Class 2')\n    plt.bar(bar_count, pclass3, bottom=pclass1 + pclass2, color='#a3acff', edgecolor='white', width=bar_width, label='Passenger Class 3')\n\n    plt.xlabel('Deck', size=15, labelpad=20)\n    plt.ylabel('Passenger Class Percentage', size=15, labelpad=20)\n    plt.xticks(bar_count, deck_names)    \n    plt.tick_params(axis='x', labelsize=15)\n    plt.tick_params(axis='y', labelsize=15)\n    \n    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 15})\n    plt.title('Passenger Class Distribution in Decks', size=18, y=1.05)   \n    \n    plt.show()  ","18942b1e":"all_deck_count, all_deck_per = get_pclass_dist(df_all_decks)\ndisplay_pclass_dist(all_deck_per)","eb3a08c0":"# Passenger in the T deck is changed to A\nidx = dfMrg[dfMrg['Deck'] == 'T'].index\ndfMrg.loc[idx, 'Deck'] = 'A'","c703fc58":"df_all_decks_survived = dfMrg.groupby(['Deck', 'Survived']).count().drop(columns=['Sex', 'Age', 'SibSp', 'Parch', 'Fare', \n                                                                                   'Embarked', 'Pclass', 'Cabin', 'PassengerId', 'Ticket']).rename(columns={'Name':'Count'}).transpose()","806ca639":"def get_survived_dist(df):\n    \n    # Creating a dictionary for every survival count in every deck\n    surv_counts = {'A':{}, 'B':{}, 'C':{}, 'D':{}, 'E':{}, 'F':{}, 'G':{}, 'M':{}}\n    decks = df.columns.levels[0]    \n\n    for deck in decks:\n        for survive in range(0, 2):\n            surv_counts[deck][survive] = df[deck][survive][0]\n            \n    df_surv = pd.DataFrame(surv_counts)\n    surv_percentages = {}\n\n    for col in df_surv.columns:\n        surv_percentages[col] = [(count \/ df_surv[col].sum()) * 100 for count in df_surv[col]]\n        \n    return surv_counts, surv_percentages\n\ndef display_surv_dist(percentages):\n    \n    df_survived_percentages = pd.DataFrame(percentages).transpose()\n    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M')\n    bar_count = np.arange(len(deck_names))  \n    bar_width = 0.85    \n\n    not_survived = df_survived_percentages[0]\n    survived = df_survived_percentages[1]\n    \n    plt.figure(figsize=(20, 10))\n    plt.bar(bar_count, not_survived, color='#b5ffb9', edgecolor='white', width=bar_width, label=\"Not Survived\")\n    plt.bar(bar_count, survived, bottom=not_survived, color='#f9bc86', edgecolor='white', width=bar_width, label=\"Survived\")\n \n    plt.xlabel('Deck', size=15, labelpad=20)\n    plt.ylabel('Survival Percentage', size=15, labelpad=20)\n    plt.xticks(bar_count, deck_names)    \n    plt.tick_params(axis='x', labelsize=15)\n    plt.tick_params(axis='y', labelsize=15)\n    \n    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 15})\n    plt.title('Survival Percentage in Decks', size=18, y=1.05)\n    \n    plt.show()\n\nall_surv_count, all_surv_per = get_survived_dist(df_all_decks_survived)\ndisplay_surv_dist(all_surv_per)","19555b97":"dfMrg['Deck'] = dfMrg['Deck'].replace(['A', 'B', 'C'], 'ABC')\ndfMrg['Deck'] = dfMrg['Deck'].replace(['D', 'E'], 'DE')\ndfMrg['Deck'] = dfMrg['Deck'].replace(['F', 'G'], 'FG')","7eaee604":"dfMrg['Deck'].value_counts()","1b504953":"dfMrg.drop(['Cabin'], inplace=True, axis=1)","0d2ecee0":"df_train, df_test = divide_df(dfMrg)\ndfs = [df_train, df_test]","10c94095":"def display_missing(df):    \n    for col in df.columns.tolist():          \n        print('{} column missing values: {}'.format(col, df[col].isnull().sum()))\n    print('\\n')\n    \nfor df in dfs:\n    display_missing(df)","487c39f8":"cont_features = ['Age', 'Fare']\nsurv = df_train['Survived'] == 1\n\nfig, axs = plt.subplots(ncols=2, nrows=2, figsize=(20, 20))\nplt.subplots_adjust(right=1.5)\n\nfor i, feature in enumerate(cont_features):    \n    # Distribution of survival in feature\n    sns.distplot(df_train[~surv][feature], label='Not Survived', hist=True, color='#e74c3c', ax=axs[0][i])\n    sns.distplot(df_train[surv][feature], label='Survived', hist=True, color='#2ecc71', ax=axs[0][i])\n    \n    # Distribution of feature in dataset\n    sns.distplot(df_train[feature], label='Training Set', hist=False, color='#e74c3c', ax=axs[1][i])\n    sns.distplot(df_test[feature], label='Test Set', hist=False, color='#2ecc71', ax=axs[1][i])\n    \n    axs[0][i].set_xlabel('')\n    axs[1][i].set_xlabel('')\n    \n    for j in range(2):        \n        axs[i][j].tick_params(axis='x', labelsize=20)\n        axs[i][j].tick_params(axis='y', labelsize=20)\n    \n    axs[0][i].legend(loc='upper right', prop={'size': 20})\n    axs[1][i].legend(loc='upper right', prop={'size': 20})\n    axs[0][i].set_title('Distribution of Survival in {}'.format(feature), size=20, y=1.05)\n\naxs[1][0].set_title('Distribution of {} Feature'.format('Age'), size=20, y=1.05)\naxs[1][1].set_title('Distribution of {} Feature'.format('Fare'), size=20, y=1.05)\n        \nplt.show()","d11bd4c5":"dfMrg = concat_df(df_train, df_test)\ndfMrg.head()","7865fcad":"dfMrg['Fare'] = pd.qcut(dfMrg['Fare'], 13)","8a57e644":"fig, asx = plt.subplots(figsize=(22, 9))\nsns.countplot(x= 'Fare', hue='Survived', data=dfMrg)\nplt.xlabel('Fare', size = 15, labelpad=20)\nplt.ylabel('Passenger Count', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=10)\nplt.tick_params(axis='y', labelsize=15)\n\nplt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size':15})\nplt.title('Count of Survival in {} Feature'.format('Fare'), size=15, y=1.05)\n\nplt.show()","46cc1912":"dfMrg['Age'] = pd.qcut(dfMrg['Age'],10)","c2a6f97d":"fig, axs = plt.subplots(figsize=(22,9))\nsns.countplot(x='Age', hue='Survived', data=dfMrg)\n\nplt.xlabel('Age', size=15, labelpad=20)\nplt.ylabel('Passeger Count', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=15)\nplt.tick_params(axis='y', labelsize=15)\n\nplt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size':15})\nplt.title('Survival Counts in {} Feature'.format('Age'), size=15, y=1.05)\n\nplt.show()","9b152fb1":"dfMrg['Family_Size'] = dfMrg['SibSp'] + dfMrg['Parch'] + 1\n\nfig, axs = plt.subplots(figsize=(20, 20), ncols=2, nrows=2)\nplt.subplots_adjust(right=1.5)\n\nsns.barplot(x=dfMrg['Family_Size'].value_counts().index, y=dfMrg['Family_Size'].value_counts().values, ax=axs[0][0])\nsns.countplot(x='Family_Size', hue='Survived', data=dfMrg, ax=axs[0][1])\n\naxs[0][0].set_title('Family Size Feature Value Counts', size=20, y=1.05)\naxs[0][1].set_title('Survival Counts in Family Size ', size=20, y=1.05)\n\nfamily_map = {1: 'Alone', 2: 'Small', 3: 'Small', 4: 'Small', 5: 'Medium', 6: 'Medium', 7: 'Large', 8: 'Large', 11: 'Large'}\ndfMrg['Family_Size_Grouped'] = dfMrg['Family_Size'].map(family_map)\n\nsns.barplot(x=dfMrg['Family_Size_Grouped'].value_counts().index, y=dfMrg['Family_Size_Grouped'].value_counts().values, ax=axs[1][0])\nsns.countplot(x='Family_Size_Grouped', hue='Survived', data=dfMrg, ax=axs[1][1])\n\naxs[1][0].set_title('Family Size Feature Value Counts After Grouping', size=20, y=1.05)\naxs[1][1].set_title('Survival Counts in Family Size After Grouping', size=20, y=1.05)\n\nfor i in range(2):\n    axs[i][1].legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 20})\n    for j in range(2):\n        axs[i][j].tick_params(axis='x', labelsize=20)\n        axs[i][j].tick_params(axis='y', labelsize=20)\n        axs[i][j].set_xlabel('')\n        axs[i][j].set_ylabel('')\n\nplt.show()","0104fa6b":"dfMrg['Ticket_Frequency'] = dfMrg.groupby('Ticket')['Ticket'].transform('count')","ae1eae32":"fig, axs = plt.subplots(figsize=(12, 9))\nsns.countplot(x='Ticket_Frequency', hue='Survived', data=dfMrg)\n\nplt.xlabel('Ticket Frequency', size=15, labelpad=20)\nplt.ylabel('Passenger Count', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=15)\nplt.tick_params(axis='y', labelsize=15)\n\nplt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size':15})\nplt.title('Count of Survival in {} Feature'.format('Ticket Frequency'), size=15, y = 1.05)\n\nplt.show()","ae88d22b":"def extract_surname(data):    \n    \n    families = []\n    \n    for i in range(len(data)):        \n        name = data.iloc[i]\n\n        if '(' in name:\n            name_no_bracket = name.split('(')[0] \n        else:\n            name_no_bracket = name\n            \n        family = name_no_bracket.split(',')[0]\n        title = name_no_bracket.split(',')[1].strip().split(' ')[0]\n        \n        for c in string.punctuation:\n            family = family.replace(c, '').strip()\n            \n        families.append(family)\n            \n    return families\n\ndfMrg['Family'] = extract_surname(dfMrg['Name'])\ndf_train = dfMrg.loc[:890]\ndf_test = dfMrg.loc[891:]\ndfs = [df_train, df_test]","01cafbfc":"\nnon_unique_families = [x for x in df_train['Family'].unique() if x in df_test['Family'].unique()]\nnon_unique_tickets = [x for x in df_train['Ticket'].unique() if x in df_test['Ticket'].unique()]\n\ndf_family_survival_rate = df_train.groupby('Family')['Survived', 'Family','Family_Size'].median()\ndf_ticket_survival_rate = df_train.groupby('Ticket')['Survived', 'Ticket','Ticket_Frequency'].median()\n\nfamily_rates = {}\nticket_rates = {}\n\nfor i in range(len(df_family_survival_rate)):\n    # Checking a family exists in both training and test set, and has members more than 1\n    if df_family_survival_rate.index[i] in non_unique_families and df_family_survival_rate.iloc[i, 1] > 1:\n        family_rates[df_family_survival_rate.index[i]] = df_family_survival_rate.iloc[i, 0]\n\nfor i in range(len(df_ticket_survival_rate)):\n    # Checking a ticket exists in both training and test set, and has members more than 1\n    if df_ticket_survival_rate.index[i] in non_unique_tickets and df_ticket_survival_rate.iloc[i, 1] > 1:\n        ticket_rates[df_ticket_survival_rate.index[i]] = df_ticket_survival_rate.iloc[i, 0]","8563f9f5":"mean_survival_rate = np.mean(df_train['Survived'])\n\ntrain_family_survival_rate = []\ntrain_family_survival_rate_NA = []\ntest_family_survival_rate = []\ntest_family_survival_rate_NA = []\n\nfor i in range(len(df_train)):\n    if df_train['Family'][i] in family_rates:\n        train_family_survival_rate.append(family_rates[df_train['Family'][i]])\n        train_family_survival_rate_NA.append(1)\n    else:\n        train_family_survival_rate.append(mean_survival_rate)\n        train_family_survival_rate_NA.append(0)\n        \nfor i in range(len(df_test)):\n    if df_test['Family'].iloc[i] in family_rates:\n        test_family_survival_rate.append(family_rates[df_test['Family'].iloc[i]])\n        test_family_survival_rate_NA.append(1)\n    else:\n        test_family_survival_rate.append(mean_survival_rate)\n        test_family_survival_rate_NA.append(0)\n        \ndf_train['Family_Survival_Rate'] = train_family_survival_rate\ndf_train['Family_Survival_Rate_NA'] = train_family_survival_rate_NA\ndf_test['Family_Survival_Rate'] = test_family_survival_rate\ndf_test['Family_Survival_Rate_NA'] = test_family_survival_rate_NA\n\ntrain_ticket_survival_rate = []\ntrain_ticket_survival_rate_NA = []\ntest_ticket_survival_rate = []\ntest_ticket_survival_rate_NA = []\n\nfor i in range(len(df_train)):\n    if df_train['Ticket'][i] in ticket_rates:\n        train_ticket_survival_rate.append(ticket_rates[df_train['Ticket'][i]])\n        train_ticket_survival_rate_NA.append(1)\n    else:\n        train_ticket_survival_rate.append(mean_survival_rate)\n        train_ticket_survival_rate_NA.append(0)\n        \nfor i in range(len(df_test)):\n    if df_test['Ticket'].iloc[i] in ticket_rates:\n        test_ticket_survival_rate.append(ticket_rates[df_test['Ticket'].iloc[i]])\n        test_ticket_survival_rate_NA.append(1)\n    else:\n        test_ticket_survival_rate.append(mean_survival_rate)\n        test_ticket_survival_rate_NA.append(0)\n        \ndf_train['Ticket_Survival_Rate'] = train_ticket_survival_rate\ndf_train['Ticket_Survival_Rate_NA'] = train_ticket_survival_rate_NA\ndf_test['Ticket_Survival_Rate'] = test_ticket_survival_rate\ndf_test['Ticket_Survival_Rate_NA'] = test_ticket_survival_rate_NA","303c4ddb":"for df in [df_train, df_test]:\n    df['Survival_Rate'] = (df['Ticket_Survival_Rate'] + df['Family_Survival_Rate']) \/ 2\n    df['Survival_Rate_NA'] = (df['Ticket_Survival_Rate_NA'] + df['Family_Survival_Rate_NA']) \/ 2  ","74b7b37a":"non_numeric_features = ['Embarked', 'Sex', 'Deck', 'Title', 'Family_Size_Grouped', 'Age', 'Fare']\n\nfor df in dfs:\n    for feature in non_numeric_features:        \n        df[feature] = LabelEncoder().fit_transform(df[feature])","14b9d95f":"cat_features = ['Pclass', 'Sex', 'Deck', 'Embarked', 'Title', 'Family_Size_Grouped']\nencoded_features = []\n\nfor df in dfs:\n    for feature in cat_features:\n        encoded_feat = OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()\n        n = df[feature].nunique()\n        cols = ['{}_{}'.format(feature, n) for n in range(1, n + 1)]\n        encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n        encoded_df.index = df.index\n        encoded_features.append(encoded_df)\n\ndf_train = pd.concat([df_train, *encoded_features[:6]], axis=1)\ndf_test = pd.concat([df_test, *encoded_features[6:]], axis=1)","dec2dfa2":"dfMrg = concat_df(df_train, df_test)\ndrop_cols = ['Deck', 'Embarked', 'Family', 'Family_Size', 'Family_Size_Grouped', 'Survived',\n             'Name', 'Parch', 'PassengerId', 'Pclass', 'Sex', 'SibSp', 'Ticket', 'Title',\n            'Ticket_Survival_Rate', 'Family_Survival_Rate', 'Ticket_Survival_Rate_NA', 'Family_Survival_Rate_NA']\n\ndfMrg.drop(columns=drop_cols, inplace=True)\n\ndfMrg.head()","6ec19ae7":"X_train = StandardScaler().fit_transform(df_train.drop(columns=drop_cols))\ny_train = df_train['Survived'].values\nX_test = StandardScaler().fit_transform(df_test.drop(columns=drop_cols))\n\nprint('X_train shape: {}'.format(X_train.shape))\nprint('y_train shape: {}'.format(y_train.shape))\nprint('X_test shape: {}'.format(X_test.shape))\n","97507e6c":"y_test = dfGenderSubmission.drop(\"PassengerId\", axis=1).copy()","d79b20f5":"SEED = 42\n","4e83fd05":"single_best_model = RandomForestClassifier(criterion='gini', \n                                           n_estimators=1100,\n                                           max_depth=5,\n                                           min_samples_split=4,\n                                           min_samples_leaf=5,\n                                           max_features='auto',\n                                           oob_score=True,\n                                           random_state=SEED,\n                                           n_jobs=-1,\n                                           verbose=1)\n\nleaderboard_model = RandomForestClassifier(criterion='gini',\n                                           n_estimators=1750,\n                                           max_depth=7,\n                                           min_samples_split=6,\n                                           min_samples_leaf=6,\n                                           max_features='auto',\n                                           oob_score=True,\n                                           random_state=SEED,\n                                           n_jobs=-1,\n                                           verbose=1) ","250e32f6":"from sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import StratifiedKFold\n","4043e32c":"N = 5\noob = 0\nprobs = pd.DataFrame(np.zeros((len(X_test), N * 2)), columns=['Fold_{}_Prob_{}'.format(i, j) for i in range(1, N + 1) for j in range(2)])\nimportances = pd.DataFrame(np.zeros((X_train.shape[1], N)), columns=['Fold_{}'.format(i) for i in range(1, N + 1)], index=dfMrg.columns)\nfprs, tprs, scores = [], [], []\n\nskf = StratifiedKFold(n_splits=N, random_state=N, shuffle=True)\n\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n    print('Fold {}\\n'.format(fold))\n    \n    # Fitting the model\n    leaderboard_model.fit(X_train[trn_idx], y_train[trn_idx])\n    \n    # Computing Train AUC score\n    trn_fpr, trn_tpr, trn_thresholds = roc_curve(y_train[trn_idx], leaderboard_model.predict_proba(X_train[trn_idx])[:, 1])\n    trn_auc_score = auc(trn_fpr, trn_tpr)\n    # Computing Validation AUC score\n    val_fpr, val_tpr, val_thresholds = roc_curve(y_train[val_idx], leaderboard_model.predict_proba(X_train[val_idx])[:, 1])\n    val_auc_score = auc(val_fpr, val_tpr)  \n      \n    scores.append((trn_auc_score, val_auc_score))\n    fprs.append(val_fpr)\n    tprs.append(val_tpr)\n    \n    # X_test probabilities\n    probs.loc[:, 'Fold_{}_Prob_0'.format(fold)] = leaderboard_model.predict_proba(X_test)[:, 0]\n    probs.loc[:, 'Fold_{}_Prob_1'.format(fold)] = leaderboard_model.predict_proba(X_test)[:, 1]\n    importances.iloc[:, fold - 1] = leaderboard_model.feature_importances_\n        \n    oob += leaderboard_model.oob_score_ \/ N\n    print('Fold {} OOB Score: {}\\n'.format(fold, leaderboard_model.oob_score_))   \n    \nprint('Average OOB Score: {}'.format(oob))","d1c7cbee":"importances['Mean_Importance'] = importances.mean(axis=1)\nimportances.sort_values(by='Mean_Importance', inplace=True, ascending=False)\n\nplt.figure(figsize=(15, 20))\nsns.barplot(x='Mean_Importance', y=importances.index, data=importances)\n\nplt.xlabel('')\nplt.tick_params(axis='x', labelsize=15)\nplt.tick_params(axis='y', labelsize=15)\nplt.title('Random Forest Classifier Mean Feature Importance Between Folds', size=15)\n\nplt.show()","b1a46cb6":"def plot_roc_curve(fprs, tprs):\n    tprs_interp = []\n    aucs = []\n    mean_fpr = np.linspace(0, 1, 100)\n    f, ax = plt.subplots(figsize=(15, 15))\n    \n    # Plotting ROC for each fold and computing AUC scores\n    for i, (fpr, tpr) in enumerate(zip(fprs, tprs), 1):\n        tprs_interp.append(np.interp(mean_fpr, fpr, tpr))\n        tprs_interp[-1][0] = 0.0\n        roc_auc = auc(fpr, tpr)\n        aucs.append(roc_auc)\n        ax.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC Fold {} (AUC = {:.3f})'.format(i, roc_auc))\n        \n    # Plotting ROC for random guessing\n    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=0.8, label='Random Guessing')\n    \n    mean_tpr = np.mean(tprs_interp, axis=0)\n    mean_tpr[-1] = 1.0\n    mean_auc = auc(mean_fpr, mean_tpr)\n    std_auc = np.std(aucs)\n    \n    # Plotting the mean ROC\n    ax.plot(mean_fpr, mean_tpr, color='b', label='Mean ROC (AUC = {:.3f} $\\pm$ {:.3f})'.format(mean_auc, std_auc), lw=2, alpha=0.8)\n    \n    # Plotting the standard deviation around the mean ROC Curve\n    std_tpr = np.std(tprs_interp, axis=0)\n    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label='$\\pm$ 1 std. dev.')\n    \n    ax.set_xlabel('False Positive Rate', size=15, labelpad=20)\n    ax.set_ylabel('True Positive Rate', size=15, labelpad=20)\n    ax.tick_params(axis='x', labelsize=15)\n    ax.tick_params(axis='y', labelsize=15)\n    ax.set_xlim([-0.05, 1.05])\n    ax.set_ylim([-0.05, 1.05])\n\n    ax.set_title('ROC Curves of Folds', size=20, y=1.02)\n    ax.legend(loc='lower right', prop={'size': 13})\n    \n    plt.show()\n\nplot_roc_curve(fprs, tprs)","a627caae":"class_survived = [col for col in probs.columns if col.endswith('Prob_1')]\nprobs['1'] = probs[class_survived].sum(axis=1) \/ N\nprobs['0'] = probs.drop(columns=class_survived).sum(axis=1) \/ N\nprobs['pred'] = 0\npos = probs[probs['1'] >= 0.5].index\nprobs.loc[pos, 'pred'] = 1\n\ny_pred = probs['pred'].astype(int)\n\nsubmission_df = pd.DataFrame(columns=['PassengerId', 'Survived'])\nsubmission_df['PassengerId'] = df_test['PassengerId']\nsubmission_df['Survived'] = y_pred.values\nsubmission_df.to_csv('submissions.csv', header=True, index=False)\nsubmission_df.head(10)","1454623f":"Build a single data frame to review, quantify NaN, Review main measures to know what is a better method of the imputation of Nan. ","bc535e17":"Family_Survival_Rate is calculated from families in training set since there is no Survived feature in test set. A list of family names that are occuring in both training and test set (non_unique_families), is created. The survival rate is calculated for families with more than 1 members in that list, and stored in Family_Survival_Rate feature.\n\nAn extra binary feature Family_Survival_Rate_NA is created for families that are unique to the test set. This feature is also necessary because there is no way to calculate those families' survival rate. This feature implies that family survival rate is not applicable to those passengers because there is no way to retrieve their survival rate.\n\nTicket_Survival_Rate and Ticket_Survival_Rate_NA features are also created with the same method. Ticket_Survival_Rate and Family_Survival_Rate are averaged and become Survival_Rate, and Ticket_Survival_Rate_NA and Family_Survival_Rate_NA are also averaged and become Survival_Rate_NA.\n\n","5dee9f44":"Referencias:\n- https:\/\/machinelearningmastery.com\/random-forest-ensemble-in-python\/\n- https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions\n","a02a04ef":"- Here took values of columns Title, we take values of column Age that are Nan\n-  compute mean to each group of Age according to columns Titles.\n-  take index where column Age is Nan, and we use those values index to put mean in column Age. ","52a04277":"- Feature Name includes appellation Title of person, so the name is Name, but keep Apellation and create a new column as Title.","8c3d497e":"There are too many unique Ticket values to analyze, so grouping them up by their frequencies makes things easier.\n\nHow is this feature different than Family_Size? Many passengers travelled along with groups. Those groups consist of friends, nannies, maids and etc. They weren't counted as family, but they used the same ticket.\n\nWhy not grouping tickets by their prefixes? If prefixes in Ticket feature has any meaning, then they are already captured in Pclass or Embarked features because that could be the only logical information which can be derived from the Ticket feature.\n\nAccording to the graph below, groups with 2,3 and 4 members had a higher survival rate. Passengers who travel alone has the lowest survival rate. After 4 group members, survival rate decreases drastically. This pattern is very similar to Family_Size feature but there are minor differences. Ticket_Frequency values are not grouped like Family_Size because that would basically create the same feature with perfect correlation. This kind of feature wouldn't provide any additional information gain.","97278bb7":"\n* - it will be transform values of columns Titles, Sex, and embarked as code to facilitate the calculation in the model.","e944806d":"- it can be seen different types of denominations or noble titles, so proceed to compact this in the main appellation. Mr, Mrs... ","aa06d322":"**PRE-PROCESSING DATA**\n","4c809d1d":"- To impute NaN in feature Age, we to take into account Titles, as with this  can guide us about what age corresponding to the people. ","adcbf2d1":"it can be seen that dfGenderSubmission is the data frame with that we going measure the model.\n\n \nOn the other hand it possible to see that there are elements NaN in the columns Age and Fare, they are type float.\n\n* Observations:\n\n-  The  DataFrame dfGenderSubmiss will be used as such during the building model, will be df of the test.\n\n- For the time being task is patch up elements NaN  in  Age and Fare.","673f38c6":"- Here it can be seen that feature Age how is it segmented of quartiles, this information is relevant as later we will use this as standard to create a new feature. ","df935e4a":"Remembering that it is to segment Age in four segments, now procedeed create a new segment as Youth, that will be people according to quartiles are less than 21 age-old.\n\n","d862c898":"### Conclusion\n\n- According to the results presented, it is concluded that it is necessary to continue improving the model.\n- Perhaps with more quantity and information, better results can be achieved","ad9bb25e":"The column Fare  and Embarked have  elements Nan, then it will be to fill elements with mean and mode respectivly and also we going to transform Fare and Age that are type float to int.","a7ade176":"****MODEL","8ab02c8b":"Cabin ","bc0de663":"2.3 Title & Is Married\nTitle is created by extracting the prefix before Name feature. According to graph below, there are many titles that are occuring very few times. Some of those titles doesn't seem correct and they need to be replaced. Miss, Mrs, Ms, Mlle, Lady, Mme, the Countess, Dona titles are replaced with Miss\/Mrs\/Ms because all of them are female. Values like Mlle, Mme and Dona are actually the name of the passengers, but they are classified as titles because Name feature is split by comma. Dr, Col, Major, Jonkheer, Capt, Sir, Don and Rev titles are replaced with Dr\/Military\/Noble\/Clergy because those passengers have similar characteristics. Master is a unique title. It is given to male passengers below age 26. They have the highest survival rate among all males.\n\nIs_Married is a binary feature based on the Mrs title. Mrs title has the highest survival rate among other female titles. This title needs to be a feature because all female titles are grouped with each other."}}