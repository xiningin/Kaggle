{"cell_type":{"73c479de":"code","837b8283":"code","11444be7":"code","f5bff026":"code","dee0934f":"code","2eaabe58":"code","f6a2b33a":"code","848f8a02":"code","fdd10b24":"code","3e94ee13":"code","47cc25cc":"code","54db71f4":"code","3b02f23a":"markdown","046fa188":"markdown","972a03ec":"markdown","b6ad9c72":"markdown","81241b26":"markdown","07017d03":"markdown","8085a372":"markdown","4558ca10":"markdown","059c1e2c":"markdown","4c48de5c":"markdown","a9dc7334":"markdown","1049843a":"markdown"},"source":{"73c479de":"train_df['user_correctness'] = train_df.groupby('user_id').agg({'answered_correctly':'mean'})","837b8283":"content_agg = train_df.groupby('content_id').agg({'answered_correctly':'mean'})\ntrain_df['content_correctness'] = train_df['content_id'].map(content_agg['mean'])\ntrain_df['score_diff'] = train_df['answered_correctly'] - train_df['content_correctness'] \ntrain_df['user_correctness'] = train_df.groupby('user_id').agg({'score_diff':'mean'})","11444be7":"# Import the Rapids suite here - takes abot 1.5 mins\n\nimport sys\n!cp ..\/input\/rapids\/rapids.0.17.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz > \/dev\/null\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\/site-packages\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + sys.path \n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","f5bff026":"import riiideducation\nimport pandas as pd\nimport numpy as np\nimport cudf\nimport cupy\nimport gc\nimport pickle\nimport xgboost\nfrom cuml.metrics import roc_auc_score","dee0934f":"features = [\n    'lagtime',\n    'lagtime2',\n    'lagtime3',\n    'content_eqet',\n    'user_correctness',\n    'user_correct_cumsum',\n    'part_user_correctness',\n    'part_user_correct_cumcount',\n    'part_user_correct_cumsum',\n    'content_correctness',\n    'content_count',\n    'content_sum',\n    'attempt_no',\n    'part',\n    'part_correctness_mean',\n    'tags1',\n    'tags1_correctness_mean',\n    'bundle_id',\n    'explanation_mean', \n]\n\ntarget = 'answered_correctly'\n\nparams = {\n    'max_depth' : 8,\n    'max_leaves' : 350,\n    'max_bin':800,\n    'eta':0.1,\n    'min_child_weight':0.03,\n    'lambda':0.6,\n    'alpha':0.4,\n    'eval_metric': 'auc',\n    'tree_method' : 'gpu_hist',\n    'objective' : 'binary:logistic',\n    'grow_policy' : 'lossguide'\n}","2eaabe58":"train_df = cudf.read_csv('..\/input\/riiiddata2\/data.csv')\nvalid_df = cudf.read_csv('..\/input\/riiiddata2\/valid.csv')","f6a2b33a":"dtrain = xgboost.DMatrix(train_df[features], label=train_df[target])\ndvalid = xgboost.DMatrix(valid_df[features], label=valid_df[target])\n\n# Create & Train the model\nmodel = xgboost.train(params,\n                      dtrain = dtrain,\n                      evals = [(dtrain, 'train'),(dvalid, 'eval')],\n                      verbose_eval = 100,\n                      num_boost_round = 10000,\n                      early_stopping_rounds = 10,\n                     )","848f8a02":"roc_auc_score(valid_df[target].astype('int32'),model.predict(dvalid))","fdd10b24":"del train_df\ndel valid_df\ndel dtrain\ndel dvalid\n_=gc.collect()","3e94ee13":"train_df = cudf.read_csv('..\/input\/riiidlastdata\/data.csv')\nvalid_df = cudf.read_csv('..\/input\/riiidlastdata\/valid.csv')","47cc25cc":"dtrain = xgboost.DMatrix(train_df[features], label=train_df[target])\ndvalid = xgboost.DMatrix(valid_df[features], label=valid_df[target])\n\n# Create & Train the model\nmodel = xgboost.train(params,\n                      dtrain = dtrain,\n                      evals = [(dtrain, 'train'),(dvalid, 'eval')],\n                      verbose_eval = 100,\n                      num_boost_round = 10000,\n                      early_stopping_rounds = 10,\n                     )\n","54db71f4":"roc_auc_score(valid_df[target].astype('int32'),model.predict(dvalid))","3b02f23a":"## As a result, increased score +0.006! (0.783 -> 0.789)\n\nthank you for watching.","046fa188":"# Proposed user_correctness","972a03ec":"NOTE: I wrote the proposed feature with an emphasis on readability, but be careful of leaks in practice.","b6ad9c72":"### eval-auc:0.789...","81241b26":"### eval-auc:0.783...","07017d03":"Let's take a quick look at the difference between traditional \"user_correctness\" and proposed \"user_correctness\".\n\nNote that other features that I was using are included, but I am using almost same except for user_correctness.","8085a372":"but the following minor change will increase the score significantly.\n\n","4558ca10":"# Traditional user_correctness","059c1e2c":"# Slightly change \"user_correctness\"","4c48de5c":"This feature is not evaluated so much when a question with a high correct answer rate is answered correctly, but is highly evaluated when a question with a low correct answer rate is answered correctly.\n\n\ne.g.) In case the user answered correctly\n* content_correctness : 0.8 -> score_diff : 0.2\n \n* content_correctness : 0.4 -> score_diff : 0.6\n\n\nThis makes it possible to create an average that takes into account the difficulty of the questions, rather than a simple binary average.","a9dc7334":"Here, 'user_correctness' is a feature that measures the smartness of each user. Probably in the published notebook, it was decided as follows.","1049843a":"# Preparation"}}