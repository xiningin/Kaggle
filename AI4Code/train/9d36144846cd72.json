{"cell_type":{"208bc370":"code","29447e40":"code","b379879c":"code","e8c0a2c5":"code","6df082c6":"code","6d63e1dc":"code","59fe55ce":"code","2a3bc6dd":"code","6216d87c":"code","1a099ed8":"code","8a728c79":"code","574e510c":"code","c24e301f":"code","a9e48af0":"markdown","ff5599a0":"markdown","10664adf":"markdown","24b5be0d":"markdown","0af7de85":"markdown","dc9cbf2c":"markdown","60a5fda3":"markdown","a235d317":"markdown","df8de1ad":"markdown"},"source":{"208bc370":"import tensorflow as tf\nimport numpy as np","29447e40":"from tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets('mnist\/', one_hot=True)","b379879c":"x_train = mnist.train.images\ny_train = mnist.train.labels\nx_test = mnist.test.images\ny_test = mnist.test.labels\n\nx_train.shape","e8c0a2c5":"y_test.shape","6df082c6":"import matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline\nplt.imshow(x_train[102].reshape((28,28)), cmap='gray')\nplt.title('Classe: ' + str(np.argmax(y_train[102])))","6d63e1dc":"x_batch, y_batch = mnist.train.next_batch(128)\nx_batch.shape","59fe55ce":"neurons_input = x_train.shape[1] # 784 pixels converted from a 28x28 image\nprint('Input Layer Neurons: ', neurons_input)\n\nneurons_hidden1 = neurons_hidden2 = neurons_hidden3 = int((x_train.shape[1] + y_train.shape[1]) \/ 2) # (784+10)\/2 = 397\nprint('Hidden1 Layer Neurons: ', neurons_hidden1)\nprint('Hidden2 Layer Neurons: ', neurons_hidden2)\nprint('Hidden3 Layer Neurons: ', neurons_hidden3)\n\nneurons_output = y_train.shape[1] # 10 of target classifications\nprint('Output Layer Neurons: ', neurons_output)","2a3bc6dd":"weights = {\n    'hidden1': tf.Variable(tf.random_normal([neurons_input, neurons_hidden1])),\n    'hidden2': tf.Variable(tf.random_normal([neurons_hidden1, neurons_hidden2])),\n    'hidden3': tf.Variable(tf.random_normal([neurons_hidden2, neurons_hidden3])),\n    'output': tf.Variable(tf.random_normal([neurons_hidden3, neurons_output])),\n}","6216d87c":"bias = {\n    'hidden1': tf.Variable(tf.random_normal([neurons_hidden1])),\n    'hidden2': tf.Variable(tf.random_normal([neurons_hidden2])),\n    'hidden3': tf.Variable(tf.random_normal([neurons_hidden3])),\n    'output': tf.Variable(tf.random_normal([neurons_output]))\n}","1a099ed8":"xph = tf.placeholder('float', [None, neurons_input])\nyph = tf.placeholder('float', [None, neurons_output])","8a728c79":"def run_process(x, weights, bias):\n    hidden_layer1 = tf.nn.relu(tf.add(tf.matmul(x, weights['hidden1']), bias['hidden1']))\n    hidden_layer2 = tf.nn.relu(tf.add(tf.matmul(hidden_layer1, weights['hidden2']), bias['hidden2']))\n    hidden_layer3 = tf.nn.relu(tf.add(tf.matmul(hidden_layer2, weights['hidden3']), bias['hidden3']))\n    output_layer = tf.add(tf.matmul(hidden_layer3, weights['output']), bias['output'])\n    return output_layer","574e510c":"# train model functions\nmodel = run_process(xph, weights, bias)\nerror = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=yph))\noptimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(error)\n\n# prediction result\npredictions = tf.nn.softmax(model)\npredictions_final = tf.equal(tf.argmax(predictions, 1), tf.argmax(yph,1))\n\n# score function\nscore = tf.reduce_mean(tf.cast(predictions_final, tf.float32))","c24e301f":"with tf.Session() as s:\n    \n    # require to initialize the TensorFlow Variables\n    s.run(tf.global_variables_initializer())\n    \n    # running the trainning for 5000 epochs\n    for epoch in range (5000):\n        x_batch, y_batch = mnist.train.next_batch(128)\n        _, cost = s.run([optimizer, error], feed_dict = { xph: x_batch, yph: y_batch })\n        if epoch % 100 == 0:\n            acc = s.run([score], feed_dict = {xph: x_batch, yph: y_batch})\n            print('Epoch: '+ str(epoch+1) + ' - Error: ' + str(cost) + ' - Accuracy: ' + str(acc))\n    \n    print('Trained.')\n    \n    # evaluate the accuracy using our test data\n    print(s.run(score, feed_dict = { xph: x_test, yph: y_test }))","a9e48af0":"# TensorFlow: implementing a deep learning neural network wit MNIST dataset\n\nThis is a simple kernel to implement a deep learning neural network with de MSNIT dataset to multiclass classification\n\nAnnotations:\n* 784 neurons into the input layer (pixels from image 28x28)\n* 3 hidden layers with 397 neurons into the hidden layers\n* 10 neurons into the output layer\n* 55000 images into the MNIST dataset ","ff5599a0":"### Processing","10664adf":"# Layers definitions\n\nNeural Network Layers\n\n>        input layer -> hidden_layer1 -> hidden_layer2 -> hidden_layer3 -> output layer\n\nWeights for each layer:\n>        784      ->        397           ->         397          ->           397         ->  10\n      \n","24b5be0d":"# Tensorflow implementation","0af7de85":"### Defining batch size ","dc9cbf2c":"### Executing on TensorFlow session","60a5fda3":"# Loading data","a235d317":"### Train and Test data","df8de1ad":"### Showing a sample image"}}