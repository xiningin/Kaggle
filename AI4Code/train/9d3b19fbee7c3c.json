{"cell_type":{"ecfaea6b":"code","9deaca5e":"code","e0716e38":"code","38c78dd9":"code","06f45af6":"code","ab8025cf":"code","697a3295":"code","7ae9376e":"code","d583dd31":"code","ddd9cd6f":"code","5249e1ca":"code","482a0d81":"code","f4bde917":"code","a0d9ea45":"code","dba6f64c":"code","a9ba4238":"code","d5367046":"code","f30189da":"code","b344e020":"code","59292a54":"code","c49f6fb8":"code","44e27459":"code","64f12e34":"code","b76e8e26":"code","0360275f":"markdown","a6164d49":"markdown","a61c33ed":"markdown","f6f5d5f8":"markdown","3e6f135d":"markdown","9bee1dce":"markdown","2a8945c1":"markdown","339959df":"markdown","b3e89aa5":"markdown","9d077f79":"markdown","11957d9a":"markdown","76f15654":"markdown","c605093a":"markdown","d00fbc54":"markdown","46f29197":"markdown"},"source":{"ecfaea6b":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom colorama import Fore, Back, Style\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Setting color palette.\npurple_black = [\n\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"\n]","9deaca5e":"# load the meta data\ntrain_csv = pd.read_csv(\"\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/train.csv\")\ntrain_csv.head()","e0716e38":"print(Fore.BLUE + \"Metadata file has {} rows and {} columns\".format(train_csv.shape[0],train_csv.shape[1]),Style.RESET_ALL)","38c78dd9":"# Let's check publication ID\n# check the no. of unique publications present in the metadata\nprint(Fore.BLUE + \"No. of Unique Publications:\",train_csv.Id.nunique(),Style.RESET_ALL)","06f45af6":"# Let's check total no. of rows present in the train.csv\nprint(Fore.BLUE +\"Total no. of rows in the metadata file:\",train_csv.shape[0],Style.RESET_ALL)\n\n# train.csv has 19661 rows whereas there are only 14316 unique publications, which means there are multiple rows\n# for few publications, because they might have reffered to multiple datasets","ab8025cf":"# No. of unique publications titles\nprint(Fore.BLUE +\"No. of unique publication titles:\",train_csv.pub_title.nunique(),Style.RESET_ALL)\n\n# There seems to be 14271 unique titles, whereas it should have been 14316, which means a small number of publications \n# have the same title","697a3295":"# No. of unique dataset titles(title of the dataset that is mentioned within the publication)\nprint(Fore.BLUE +\"No. of unique dataset titles:\",train_csv.dataset_title.nunique(),Style.RESET_ALL)","7ae9376e":"# No. of unique dataset labels(a portion of the text that indicates the dataset) in the metadata \nprint(Fore.BLUE +\"No. of unique Labels in the meta:\",train_csv.dataset_label.nunique(),Style.RESET_ALL)","d583dd31":"# unique titles used\ncount = train_csv.dataset_title.value_counts()\n\nfig = go.Figure(data=[go.Table(\n  columnwidth = [0.25, 2, 0.5],\n  header=dict(\n    values=[\"<b>Rank<\/b>\", \"<b>Dataset Title<\/b>\", \"<b>Mentions<\/b>\"],\n    line_color='darkslategray',\n    fill_color=\"green\",\n    align='center',\n    font=dict(color='white', size=12)\n  ),\n  cells=dict(\n    values=np.array([np.array((str(i+1), \"<i>\" + x + \"<\/i>\", \"<b>\" + str(y) + \"<\/b>\", )) for i, (x, y) in enumerate(zip(count.index, count.values))]).T,\n    line_color='darkslategray',\n    # 2-D list of colors for alternating rows\n    fill_color = [[\"white\",\"lavender\"]*25],\n    align = 'center',\n    font = dict(color = 'darkslategray', size = 11)\n    ))\n])\n\nfig.update_layout(\n    title={\"text\": \"<b>Datasets Titles Mentions Counts<\/b>\",\n           \"x\": 0.5,\n           \"xanchor\":\"center\",\n           \"font_size\": 22},\n    margin={\"r\":20, \"l\":20})\n\nfig.show()","ddd9cd6f":"# Let's Visualize top 20 of the titles used \n\nfig = px.pie(count,\n             values=count.values[:20],\n             names=count.index[:20],\n             color_discrete_sequence=purple_black,\n             hole=.4,title=\"Top 20 Titles\")\nfig.update_traces(textinfo='percent', pull=0.05)\nfig.show()","5249e1ca":"# unique labels used\ncount = train_csv.dataset_label.value_counts()\n\nfig = go.Figure(data=[go.Table(\n  columnwidth = [0.25, 2, 0.5],\n  header=dict(\n    values=[\"<b>Rank<\/b>\", \"<b>Dataset Labels<\/b>\", \"<b>Mentions<\/b>\"],\n    line_color='darkslategray',\n    fill_color=\"green\",\n    align='center',\n    font=dict(color='white', size=12)\n  ),\n  cells=dict(\n    values=np.array([np.array((str(i+1), \"<i>\" + x + \"<\/i>\", \"<b>\" + str(y) + \"<\/b>\", )) for i, (x, y) in enumerate(zip(count.index, count.values))]).T,\n    line_color='darkslategray',\n    # 2-D list of colors for alternating rows\n    fill_color = [[\"white\",\"lavender\"]*25],\n    align = 'center',\n    font = dict(color = 'darkslategray', size = 11)\n    ))\n])\n\nfig.update_layout(\n    title={\"text\": \"<b>Datasets Labels Mentions Counts<\/b>\",\n           \"x\": 0.5,\n           \"xanchor\":\"center\",\n           \"font_size\": 22},\n    margin={\"r\":20, \"l\":20})\n\nfig.show()","482a0d81":"# Let's Visualize top 20 of the labels used \n\nfig = px.pie(count,\n             values=count.values[:20],\n             names=count.index[:20],\n             color_discrete_sequence=purple_black,\n             hole=.4,title=\"Top 20 Labels\")\nfig.update_traces(textinfo='percent', pull=0.05)\nfig.show()","f4bde917":"import os\npath = os.walk(\"..\/input\/coleridgeinitiative-show-us-the-data\/train\")\n\njson_list = []\n\nfor _,_,files in path:\n    for file in files:\n        #names.append(file[:-5])\n        json_list.append(file)\n\nprint(Fore.BLUE + \"No. of Json Files in the training folder:\", len(json_list),Style.RESET_ALL)","a0d9ea45":"# lets take first publication from train.csv and see if it is referred in the related publication in the train folder\nimport json\n  \n# Opening JSON file\nf = open(\"..\/input\/coleridgeinitiative-show-us-the-data\/train\" + \"\/\" + json_list[0])\n  \n# returns JSON object as \n# a dictionary\ndata = json.load(f)\n  \n# Iterating through the json list\nfor i in data:\n    print(Fore.GREEN + \"First Section Title\",Style.RESET_ALL)\n    print(i)\n    break # break after printing first section_title\n# Closing file\nf.close()\n\n# we have publication for id d0fa7568-7d8e-4db9-870f-f9c6f668c17b in \"data\" variable\n# now we will check whether \"dataset title - National Education Longitudinal Study\" is present in the publication or not\n\nfor i in range(len(data)):\n    if train_csv.loc[0]['dataset_title'] in data[i]['text']:\n        print(Fore.BLUE +\"Title {}{}{} is Present in the given publication\".format(\"'\",train_csv.loc[0]['dataset_title'],\"'\"),Style.RESET_ALL)\n        break","dba6f64c":"import spacy\nfrom spacy import displacy\nfrom collections import Counter\nimport en_core_web_sm\nnlp = en_core_web_sm.load()","a9ba4238":"doc = nlp(str(data)) # \"data\" still has text from the publication we used earlier in this notebook \nprint([(X.text, X.label_) for X in doc.ents[0:20]])","d5367046":"print([(X, X.ent_iob_, X.ent_type_) for X in doc[:20]])","f30189da":"print(\"There are {} entities in the publication\".format(len(doc.ents)))\n\nlabels = [x.label_ for x in doc.ents]\nprint(\"\\nThese entities are represented by {} unique labels\".format(len(Counter(labels))))\n\nprint(\"\\nFollowing is the list of unique labels:\\n\")\nprint(Counter(labels))","b344e020":"print(\"Following are the 3 most common entities\")\nitems = [x.text for x in doc.ents]\nCounter(items).most_common(3)","59292a54":"# Let\u2019s run displacy.render to generate the raw markup.\ndisplacy.render(nlp(str(data[0:1])), jupyter=True, style='ent')","c49f6fb8":"# Using spaCy\u2019s built-in displaCy visualizer, here\u2019s what the above publication and its dependencies look like:\ndisplacy.render(nlp(str(doc[0:20])), style='dep', jupyter = True, options = {'distance': 120})","44e27459":"[(x.orth_,x.pos_, x.lemma_) for x in [y \n                                      for y\n                                      in nlp(str(doc[0:100])) \n                                      if not y.is_stop and y.pos_ != 'PUNCT']]","64f12e34":"dict([(str(x), x.label_) for x in nlp(str(doc[0:200])).ents])","b76e8e26":"print([(x, x.ent_iob_, x.ent_type_) for x in doc[0:200]])","0360275f":"There are only 45 unique titles whereas 130 labels, which means different variants of the dataset titles are used in the publications. let's verify.","a6164d49":"# Sanity Check","a61c33ed":"Next, we verbatim, extract part-of-speech and lemmatize this publication.","f6f5d5f8":"# Objective: \n\nThe objective of the competition is to identify the mention of datasets within scientific publications. Your predictions will be short excerpts from the publications that appear to note a dataset. Predictions that more accurately match the precise words used to identify the dataset within the publication will score higher. \n\n<img src=\"https:\/\/coleridgeinitiative.org\/wp-content\/uploads\/2021\/02\/rich-context.png\"\/>","3e6f135d":"# NER using SPACY","9bee1dce":"From above two results, we can confirm that different variants of the titles are used in the publications.\nfor example, \"ADNI\" & \"Alzheimer's Disease Neuroimaging Initiative (ADNI)\" have been used interchangably in the publications.","2a8945c1":"### Let's check the data present in the metadata file","339959df":"### Token Level\nDuring the above example, we were working on entity level, in the following example, \nwe are demonstrating token-level entity annotation using the BILUO tagging scheme to describe the entity boundaries.\n<img src = \"https:\/\/miro.medium.com\/max\/875\/1*_sYTlDj2p_p-pcSRK25h-Q.png\">","b3e89aa5":"All the Entities seems to have tagged correctly!","9d077f79":"\"B\" means the token begins an entity, \"I\" means it is inside an entity, \"O\" means it is outside an entity, and \"\" means no entity tag is set.","11957d9a":"# Thank you all for your upvotes :) Please check my [NER MODEL](https:\/\/www.kaggle.com\/jagdmir\/spacy-ner-model)  on model building for this competition","76f15654":"### SPACY Supports following entity types\n<img src = \"https:\/\/miro.medium.com\/max\/875\/1*qQggIPMugLcy-ndJ8X_aAA.png\"\/>","c605093a":"# Data Familiarization","d00fbc54":"### Entity","46f29197":"One of the nice things about Spacy is that we only need to apply nlp once, the entire background pipeline will return the objects."}}