{"cell_type":{"8a28af1f":"code","734b9133":"code","95278c2f":"code","ccd53329":"code","7016988c":"code","f970eba3":"code","e9774f41":"code","8b234e31":"code","8510a351":"code","c6bd00c5":"code","0e3c7cc4":"code","86fec080":"code","38e9e54f":"code","c21a7a75":"code","fe7276d1":"code","b33a7975":"code","06457bec":"code","6ed05f4c":"code","b83950d9":"code","f8167a6c":"code","f8e10483":"code","84b476e9":"code","021172dd":"code","29e2b3d7":"code","1cb63297":"code","25f06576":"code","834fb7c3":"code","9074f73f":"code","a8fcdf8a":"code","b65ee5cb":"code","e9a351cf":"code","62ffbb65":"code","85f2ac0b":"code","cc748788":"code","5f06243d":"markdown","3bc21be0":"markdown"},"source":{"8a28af1f":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","734b9133":"from fastai.vision import *","95278c2f":"path = '\/kaggle\/input\/'\ndest = path","ccd53329":"np.random.seed(42)\ndata = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.2,\n        ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)","7016988c":"data.classes","f970eba3":"data.show_batch(rows=3, figsize=(7,8))","e9774f41":"data.classes, data.c, len(data.train_ds), len(data.valid_ds)","8b234e31":"learn = cnn_learner(data, models.resnet34, metrics=[accuracy, error_rate])","8510a351":"learn.model_dir='\/kaggle\/working\/'","c6bd00c5":"learn.fit_one_cycle(4)","0e3c7cc4":"learn.save('stage-1')","86fec080":"learn.unfreeze()","38e9e54f":"learn.lr_find()","c21a7a75":"learn.recorder.plot()","fe7276d1":"callbacks = [callbacks.SaveModelCallback(learn, every='improvement', mode='min', monitor='error_rate', name='\/kaggle\/working\/best_model')]","b33a7975":"learn.fit_one_cycle(30, max_lr=slice(5e-5,5e-4), callbacks=callbacks)","06457bec":"learn.recorder.plot_losses()","6ed05f4c":"learn.save('stage-2')","b83950d9":"interp = ClassificationInterpretation.from_learner(learn)","f8167a6c":"interp.plot_confusion_matrix(figsize=(20,20))","f8e10483":"#from fastai.vision import *","84b476e9":"#path = '\/kaggle\/input\/'\n#dest = path","021172dd":"#np.random.seed(42)\n#data = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.2,\n#        ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)","29e2b3d7":"#data.show_batch(rows=3, figsize=(7,8))","1cb63297":"#learn = cnn_learner(data, models.resnet34, metrics=[accuracy, error_rate])","25f06576":"#import os\n#for dirname, _, filenames in os.walk('\/kaggle\/input\/'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))","834fb7c3":"#learn.load('\/kaggle\/input\/model-temp\/stage-2')","9074f73f":"from sklearn.metrics import roc_curve, auc","a8fcdf8a":"preds,y,loss = learn.get_preds(with_loss=True)\n# get accuracy\nacc = accuracy(preds, y)\nprint('The accuracy is {0} %.'.format(acc))","b65ee5cb":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix(title='Confusion matrix', figsize=(20,20))","e9a351cf":"# probs from log preds\nprobs = np.exp(preds[:,1])\n# Compute ROC curve\nfpr, tpr, thresholds = roc_curve(y, probs, pos_label=1)\n\n# Compute ROC area\nroc_auc = auc(fpr, tpr)\nprint('ROC area is {0}'.format(roc_auc))","62ffbb65":"plt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\nplt.xlim([-0.01, 1.0])\nplt.ylim([0.0, 1.01])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")","85f2ac0b":"data.classes","cc748788":"learn.export('\/kaggle\/working\/birdclassifier_new3.pkl')","5f06243d":"----------------","3bc21be0":"------------"}}