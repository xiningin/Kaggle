{"cell_type":{"94a7a82e":"code","09d8a7a5":"code","4b245e37":"code","39c44f1d":"code","60d73d97":"code","effa195c":"code","18656e56":"code","526a1c4e":"code","cb65d92c":"code","d2e023e8":"code","d74517eb":"code","b2cbc620":"code","fdbb0313":"code","e8479c68":"code","40ceea62":"code","7ca513f3":"markdown","c70f0fc3":"markdown","a5fd59d7":"markdown","3e3318c0":"markdown","96bdaf8d":"markdown","4ca11987":"markdown","c43a72f9":"markdown","02ad4a91":"markdown","dcfc82a4":"markdown","9b246316":"markdown","4cd044a6":"markdown","d54dbd6a":"markdown","e971128e":"markdown","ad378ee9":"markdown","44a7523f":"markdown","c49b517f":"markdown","8c2071d2":"markdown","7fc77307":"markdown","aef24dda":"markdown","d83581f5":"markdown","34dbf85a":"markdown","e37e9928":"markdown","6eac4342":"markdown","adf0a3dc":"markdown","d2f42b03":"markdown"},"source":{"94a7a82e":"#importing libraries\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.metrics import error_rate\nimport os\nimport pandas as pd\nimport numpy as np","09d8a7a5":"x  = \"\/kaggle\/input\/kermany2018\/oct2017\"\npath = Path(x)\npath.ls()","4b245e37":"np.random.seed(40)\ndata = ImageDataBunch.from_folder(path, train = '.', valid_pct=0.3,\n                                  ds_tfms=get_transforms(), size=224,\n                                  num_workers=4).normalize(imagenet_stats)","39c44f1d":"data.show_batch(rows=3, figsize=(7,6),recompute_scale_factor=True)\n","60d73d97":"print(data.classes)\nlen(data.classes)\ndata.c","effa195c":"data","18656e56":"learn = cnn_learner(data, models.resnet18, metrics=[accuracy], model_dir = Path('..\/kaggle\/working'),path = Path(\".\"))","526a1c4e":"learn.lr_find()\nlearn.recorder.plot(suggestions=True)","cb65d92c":"{learner_name}.recorder.plot()","d2e023e8":"lr1 = 1e-3\nlr2 = 1e-1\nlearn.fit_one_cycle(1,slice(lr1,lr2))","d74517eb":"# lr1 = 1e-3\nlr = 1e-1\nlearn.fit_one_cycle(1,slice(lr))","b2cbc620":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot()\nlearn.fit_one_cycle(1,slice(1e-4,1e-3))","fdbb0313":"learn.recorder.plot_losses()\n","e8479c68":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","40ceea62":"learn.export(file = Path(\"\/kaggle\/working\/export.pkl\"))\nlearn.model_dir = \"\/kaggle\/working\"\nlearn.save(\"stage-1\",return_path=True)","7ca513f3":"<font size=\"+3\" color=blue><b> <center><u>Retina Damage Classification using Transfer Learning <\/u><\/center><\/b><\/font>","c70f0fc3":"<a id=\"top\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Table of content<\/h3>\n\n<font color=\"blue\" size=+1><b>Introduction<\/b><\/font>\n* [1. What is CNN ?](#2)\n* [2. What is Transfer Learning ?](#3) \n* [3. About Dataset ?] (#31)\n\n<font color=\"blue\" size=+1><b>Library<\/b><\/font>\n* [1. Installation](#4)\n* [2. Import Libraries ](#5)\n    \n<font color=\"blue\" size=+1><b> Load and view your data <\/b><\/font>\n* [1. Setting up path for training data ](#6)\n* [2. Data Loading For training ](#7)\n* [3. Data Explorations ](#8)\n* [4. Print Classes present in the data ](#9)\n\n<font color=\"blue\" size=+1><b> Create and train a model <\/b><\/font>\n* [1. Create Models ](#10)\n* [2. Train Model ](#11)\n* [3. Finding LR ](#12)\n* [4. Finetuning HyperParameter](#13)\n\n<font color=\"blue\" size=+1><b> Others <\/b><\/font>\n* [1. Interpret the results](#14)\n* [2. Prediction Using Trained Model](#15)\n* [3. Save and Load Model](#16)\n* [4. Sources](#17)","a5fd59d7":"<a id=\"6\"><\/a>\n<font color=\"blue\" size=+2.5><b>3.1 Setting up path for training data<\/b><\/font>\n\n**Point to be Noted: Number of elements in a list of path is same as number of classes you have**","3e3318c0":"<a id=\"13\"><\/a>\n<font color=\"blue\" size=+2.5><b>4.4 Hyper Parameter Tuning<\/b><\/font>\n<br\/>","96bdaf8d":"<a id=\"7\"><\/a>\n<font color=\"blue\" size=+2.5><b>3.2 Data Loading For training<\/b><\/font>\n<br\/>\n\n**Things to be remember:**\n* Decide validation percentage ( 0.2 => 20% )\n* Provide path for training data\n* [Decide augmentations criteria (optional)](https:\/\/www.kaggle.com\/init27\/introduction-to-image-augmentation-using-fastai\/)\n* Decide image size (which is 224 in my case)\n* Test data can also be added but it's optional","4ca11987":"<a id=\"9\"><\/a>\n<font color=\"blue\" size=+2.5><b>3.4 Print Classes present in the data<\/b><\/font>\n<br\/>\n\n* data.c \u2014 How many classes are there in our dataset?\n* len(data.train_ds) \u2014 What is the size of our training dataset?\n* len(data.valid_ds) \u2014 What is the size of our validation dataset?","c43a72f9":"<a id=\"14\"><\/a>\n<font color=\"blue\" size=+2.5><b>5.1 Interpret the results<\/b><\/font>\n<br\/>","02ad4a91":"<a id=\"11\"><\/a>\n<font color=\"blue\" size=+2.5><b>4.2 Finding LR<\/b><\/font>\n<br\/>","dcfc82a4":"<a id=\"3\"><\/a>\n<font color=\"blue\" size=+2.5><b>1.3  What is Transfer Learning ?<\/b><\/font>\n<br\/>\n<br\/>\n\n![image.png](attachment:image.png)\n\n**Transfer learning is a machine learning technique where a model trained on one task is re-purposed on a second related task.**","9b246316":"<a id=\"16\"><\/a>\n<font color=\"blue\" size=+2.5><b>5.3 Save and Load Model<\/b><\/font>\n<br\/>\n","4cd044a6":"<a id=\"10\"><\/a>\n<font color=\"blue\" size=+2.5><b>4.1 Create Model<\/b><\/font>\n<br\/>\n* We now use a pre-trained ResNet18 Convolutional Neural Net model, and use transfer learning to learn weights of only the last layer of the network.\n* Why Transfer learning? Because with transfer learning, you begin with an existing (trained) neural network used for image recognition \u2014 and then tweak it a bit (or more) here and there to train a model for your particular use case. And why do we do that? Training a reasonable neural network would mean needing approximately 300,000 image samples, and to achieve really good performance, we\u2019re going to need at least a million images.\n* In our case, we have approximately 40000+ images in our training set \u2014 you have one guess to decide if that would have been enough if were to train a neural net from scratch.\n* We use the create_cnn() function for loading a pre-trained ResNet18 network, that was trained on around a million images from the ImageNet database.","d54dbd6a":"<a id=\"4\"><\/a>\n<font color=\"blue\" size=+2.5><b>2.1 Installation<\/b><\/font>\n* Numpy\n* Pandas\n* Matplotlib\n* Fastai","e971128e":"<a id=\"1\"><\/a>\n<font color=\"blue\" size=+2.5><b>Introduction<\/b><\/font>\n","ad378ee9":"<a id=\"12\"><\/a>\n<font color=\"blue\" size=+2.5><b>4.3 Train Model<\/b><\/font>\n<br\/>","44a7523f":"<a id=\"17\"><\/a>\n<font color=\"blue\" size=+2.5><b>5.4 Sources<\/b><\/font>\n<br\/>\n* [Fastai MOOC](https:\/\/course.fast.ai\/)\n* [Fastai library](https:\/\/docs.fast.ai\/)","c49b517f":"<a id=\"31\"><\/a>\n<font color=\"blue\" size=+2.5><b>1.4  About Dataset <\/b><\/font>\n<br\/>\n<br\/>\n## Detect Retina Damage From OCT Images\n\n\nUsing data from http:\/\/www.cell.com\/cell\/fulltext\/S0092-8674(18)30154-5\nIt is often difficult to obtain large datasets of medical images. Here I demonstrate that transfer learning can be used to train a deep learning model using only a small dataset consisting of less than 1,000 retinal OCT images.\n\nRetinal optical coherence tomography (OCT) is an imaging technique used to capture high-resolution cross sections of the retinas of living patients. Approximately 30 million OCT scans are performed each year, and the analysis and interpretation of these images takes up a significant amount of time (Swanson and Fujimoto, 2017).\n\n![image.png](attachment:image.png)\n\nFigure 2. Representative Optical Coherence Tomography Images and the Workflow Diagram [Kermany et. al. 2018] http:\/\/www.cell.com\/cell\/fulltext\/S0092-8674(18)30154-5\n\n(A) (Far left) choroidal neovascularization (CNV) with neovascular membrane (white arrowheads) and associated subretinal fluid (arrows). (Middle left) Diabetic macular edema (DME) with retinal-thickening-associated intraretinal fluid (arrows). (Middle right) Multiple drusen (arrowheads) present in early AMD. (Far right) Normal retina with preserved foveal contour and absence of any retinal fluid\/edema.\n","8c2071d2":"<a id=\"8\"><\/a>\n<font color=\"blue\" size=+2.5><b>3.3 Data Explorations<\/b><\/font>\n<br\/>\n\n*Our image dataset is stored as .jpg files in 4 different folders, with each folder bearing the name of model of the images contained in the folder. We use the ImageDataBunch.from_folder() function to load the images and assign labels the images based on the name of the folder they\u2019re read from.*","7fc77307":"<a id=\"5\"><\/a>\n<font color=\"blue\" size=+2.5><b>2.2 Library Import<\/b><\/font>","aef24dda":"## Number of Labels\n\n* DME\n* CNV\n* NORMAL\n* DRUSEN","d83581f5":"<a id=\"5\"><\/a>\n\n\n<font color=\"blue\" size=+2.5><b>2. Library<\/b><\/font>","34dbf85a":"<font size=\"+1\" color=red ><b>Please Upvote my kernel and keep it in your favourite section if you think it is helpful.<\/b><\/font>","e37e9928":"# Objective\nGoal of this kernel is following:\n- Learn how to implement FastAI on image data.\n- Learn how to implement CNN on custom data.\n- Learn how to Resnet to get better accuracy.\n- Provide Perfect Guide for all the tips and trick to implement CNN and get better accuracy as a Beginner.\n\nI have learned them from [FastAI](https:\/\/docs.fast.ai\/)","6eac4342":"<a id=\"2\"><\/a>\n<font color=\"blue\" size=+2.5><b>1.2  What is CNN ?<\/b><\/font>\n<br\/>\n<br\/>\n![image.png](attachment:image.png)\n**CNN stands for Convolutional Neural Network which is a specialized neural network for processing data that has an input shape like a 2D matrix like images. CNN's are typically used for image detection and classification.**","adf0a3dc":"<a id=\"18\"><\/a>\n<font color=\"blue\" size=+2.5><b>Feedback and Support<\/b><\/font>\n<br\/>\n* Your feedback is much appreciated\n* Please UPVOTE if you LIKE this notebook\n* Comment if you have any doubts or you found any errors in the notebook","d2f42b03":"![image.png](attachment:image.png)"}}