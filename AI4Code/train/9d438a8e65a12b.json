{"cell_type":{"28bddf10":"code","e4e4e76c":"code","1e9e35ee":"code","085583f2":"code","26230c13":"code","1293640b":"code","81fff770":"code","7e12fa84":"code","24ee466e":"code","e86e18d6":"code","006d3f93":"code","d67d95a6":"code","b9f963a7":"code","2be101c3":"code","5c32272c":"code","4a05b3a3":"code","6e415e01":"code","623e6226":"code","8c914258":"code","53650ed4":"code","c21a16c2":"code","74949284":"code","65910cb8":"code","160a7087":"code","5147432b":"markdown"},"source":{"28bddf10":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n","e4e4e76c":"train_csv_path = '\/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv'\ntest_csv_path = '\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv'\nfolder_images = '\/kaggle\/input\/plant-pathology-2020-fgvc7\/images'","1e9e35ee":"from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nimport os","085583f2":"def add_filename(file_path):\n    data = pd.read_csv(file_path)\n    data['filename'] = '\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/'+ data['image_id'] + '.jpg'\n    data.drop(['image_id'], axis = 1)\n    return data\n\ndef prepare_data(file_path):\n    data = pd.read_csv(file_path)\n    y = data[['healthy', 'multiple_diseases', 'scab', 'rust']]\n    df = pd.DataFrame({\n        'filename': '\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/'+ data['image_id'] + '.jpg',\n        'category': np.where(y==1)[1]\n    })\n    \n    return df","26230c13":"data = prepare_data(train_csv_path)\ntest = add_filename(test_csv_path)","1293640b":"data[\"category\"] = data[\"category\"].replace({0: 'healthy', 1: 'multiple_diseases', 2: 'scab', 3: 'rust'}) ","81fff770":"data","7e12fa84":"train, validate = train_test_split(data, test_size=0.20, random_state=1)\ntrain = train.reset_index(drop=True)\nvalidate = validate.reset_index(drop=True)","24ee466e":"IMAGE_WIDTH=1024\nIMAGE_HEIGHT=1024\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3\nOUTPUT = 4\nbatch_size = 5","e86e18d6":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train, \n    x_col='filename',\n    y_col= 'category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","006d3f93":"validation_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate, \n    x_col='filename',\n    y_col= 'category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","d67d95a6":"example = train.sample(n=1).reset_index(drop=True)\nexample_generator = train_datagen.flow_from_dataframe(\n    example,  \n    x_col='filename',\n    y_col= 'category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical'\n)","b9f963a7":"plt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","2be101c3":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n\nmodel = Sequential()\n\nmodel.add(Conv2D(256, (3, 3),strides = 2, activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(256, (3, 3),strides = 2, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(OUTPUT, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])","5c32272c":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nearlystop = EarlyStopping(patience=10)\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acuracy', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\ncallbacks = [earlystop, learning_rate_reduction]","4a05b3a3":"total_train = train.shape[0]\ntotal_validate = validate.shape[0]","6e415e01":"epochs= 20\n\nhistory = model.fit_generator(\n    train_generator, \n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=total_validate\/\/batch_size,\n    steps_per_epoch=total_train\/\/batch_size,\n    callbacks=callbacks\n)","623e6226":"test_gen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_gen.flow_from_dataframe(\n    test,  \n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    target_size=IMAGE_SIZE,\n    batch_size=batch_size,\n    shuffle=False\n)","8c914258":"model.save_weights(\"model.h5\")","53650ed4":"nb_samples = test.shape[0]","c21a16c2":"predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples\/batch_size))","74949284":"submission = test.copy()\nsubmission['healthy'] = [row[0] for row in predict]\nsubmission['multiple_diseases'] =  [row[1] for row in predict]\nsubmission['rust'] =  [row[2] for row in predict]\nsubmission['scab'] =  [row[3] for row in predict]","65910cb8":"submission = submission.drop(['filename'], axis = 1)","160a7087":"submission.to_csv('submission.csv', index=False)","5147432b":"# Model definition"}}