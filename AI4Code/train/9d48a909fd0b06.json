{"cell_type":{"13bfa330":"code","2129b259":"code","d7b3c774":"code","ac842436":"code","af9f2869":"code","8c97bb17":"code","ebe566c8":"code","fc783866":"code","c18f5f1f":"code","96dce9f2":"code","38ea77be":"code","d9700115":"code","e813ecd8":"code","3f41fea8":"code","37811ce5":"code","1b5ea9eb":"code","a37b4e13":"code","d31def8f":"code","9f76fba0":"code","ca056cb9":"code","a45185a5":"code","e5d7bd7c":"code","2ba03748":"code","211a3416":"code","c8794b70":"code","14c91f96":"code","1bde146e":"code","46df648c":"code","a591d744":"code","ffcb2398":"code","7fde52a2":"code","989c1219":"code","ce5c0f1d":"code","a076a14c":"code","0f8e8178":"code","4b2770f4":"code","a70651a3":"code","6be270b4":"code","9ee6bccf":"code","57df2013":"code","b31a7207":"markdown","11f6082e":"markdown","131afec3":"markdown","2c98bd05":"markdown","8a2ad217":"markdown","526bc16a":"markdown","78477069":"markdown","7be0bd19":"markdown","342e197d":"markdown","a8d50c78":"markdown","358f299c":"markdown","6fcdfcad":"markdown","62b4d1d5":"markdown","dec08568":"markdown","fd773862":"markdown","9a7159d0":"markdown","7a22a781":"markdown","4475924b":"markdown","d5f92d19":"markdown","38242353":"markdown","dd6cdd68":"markdown","b4aa2e32":"markdown","72c9ab82":"markdown","b98dc88c":"markdown","4c2e8f9c":"markdown","9ccee41a":"markdown","09ba3bca":"markdown"},"source":{"13bfa330":"#THIS IS DEFAULT KAGGLE CELL, WHICH DOWNLOAD OUR DATA TO PATH: \/kaggle\/input\/epileptic-seizure-recognition\/Epileptic Seizure Recognition.csv\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2129b259":"import pandas as pd\nimport scipy\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.preprocessing import normalize, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_validate, RepeatedStratifiedKFold, GridSearchCV\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n\nimport cufflinks\ncufflinks.go_offline()\ncufflinks.set_config_file(world_readable=True, theme='pearl')\n\nimport plotly\nimport plotly.figure_factory as ff\nfrom plotly import tools\nfrom plotly.offline import init_notebook_mode, iplot\n\nimport imblearn\n\n\nimport seaborn as sns\n\ninit_notebook_mode(connected=True)\npd.set_option('display.max_columns', 100)","d7b3c774":"cd \/kaggle\/input\/epileptic-seizure-recognition\/","ac842436":"#data = pd.read_csv('https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/00388\/data.csv')","af9f2869":"#Read our data (from Kaggle)\ndata = pd.read_csv('Epileptic Seizure Recognition.csv')","8c97bb17":"#Have a look on first five rows\ndata.head()","ebe566c8":"#Have a look on last five rows\ndata.tail()","fc783866":"#Check dataframe shape (11500 rows and 180 columns(features))\ndata.shape","c18f5f1f":"#Before joining the classes, let us check y values for balancing\ndata['y'].value_counts()","96dce9f2":"data.y.hist();","38ea77be":"plt.figure(figsize=(50,4))\nplt.subplot(131)\n[plt.plot(data.values[i][1:-1]) for i in range(23)];","d9700115":"dic = {5: 0, 4: 0, 3: 0, 2: 0, 1: 1}\ndata['y'] = data['y'].map(dic)","e813ecd8":"#Check the difference in dataframe in general\n\n#Check which values do we have in y column\nprint(data['y'].value_counts())\n\ndata.head()","3f41fea8":"data = data.drop('Unnamed', axis = 1)","37811ce5":"data = shuffle(data)","1b5ea9eb":"# table_cat = ff.create_table(data.describe().T, index=True, index_title='Signals')\n# iplot(table_cat)","a37b4e13":"data.describe()","d31def8f":"data.info()","9f76fba0":"#Let us group all the Epileptic occureses and Non Epileptic\nprint('Number of records of Non Epileptic {0} VS Epilepttic {1}'.format(len(data[data['y'] == 0]), len(data[data['y'] == 1])))","ca056cb9":"#Description of Non Epileptic\ndata[data['y'] == 0].describe().T","a45185a5":"#Description of Epileptic\n\ndata[data['y'] == 1].describe().T","e5d7bd7c":"print('Totall Mean VALUE for Epiletic: {}'.format((data[data['y'] == 1].describe().mean()).mean()))\nprint('Totall Std VALUE for Epiletic: {}'.format((data[data['y'] == 1].describe().std()).std()))","2ba03748":"print('Totall Mean VALUE for NON Epiletic: {}'.format((data[data['y'] == 0].describe().mean()).mean()))\nprint('Totall Std VALUE for NON Epiletic: {}'.format((data[data['y'] == 0].describe().std()).std()))","211a3416":"#Few cases of Not Epileptic case\n[(plt.figure(figsize=(8,4)), plt.title('Not Epileptic'), plt.plot(data[data['y'] == 0].iloc[i][0:-1])) for i in range(5)];","c8794b70":"#Few cases of Epileptic case\n[(plt.figure(figsize=(8,4)), plt.title('Epileptic'), plt.plot(data[data['y'] == 1].iloc[i][0:-1])) for i in range(5)];","14c91f96":"#lists of arrays containing all data without y column\nnot_epileptic = [data[data['y']==0].iloc[:, range(0, len(data.columns)-1)].values]\nepileptic = [data[data['y']==1].iloc[:, range(0, len(data.columns)-1)].values]\n\n#We will create and calculate 2d indicators in order plot data in 2 dimensions;\n\ndef indic(data):\n    \"\"\"Indicators can be different. In our case we use just min and max values\n    Additionally, it can be mean and std or another combination of indicators\"\"\"\n    max = np.max(data, axis=1)\n    min = np.min(data, axis=1)\n    return max, min\n\nx1,y1 = indic(not_epileptic)\nx2,y2 = indic(epileptic)\n\nfig = plt.figure(figsize=(14,6))\nax1 = fig.add_subplot(111)\n\nax1.scatter(x1, y1, s=10, c='b', label='Not Epiliptic')\nax1.scatter(x2, y2, s=10, c='r', label='Epileptic')\nplt.legend(loc='lower left');\nplt.show()","1bde146e":"#Just Epileptic\nx,y = indic(data[data['y']==1].iloc[:, range(0, len(data.columns)-1)].values)\nplt.figure(figsize=(14,4))\nplt.title('Epileptic')\nplt.scatter(x, y, c='r');","46df648c":"#Just Not Epileptic\nx,y = indic(data[data['y']==0].iloc[:, range(0, len(data.columns)-1)].values)\nplt.figure(figsize=(14,4))\nplt.title('NOT Epileptic')\nplt.scatter(x, y);","a591d744":"# define oversampling strategy\noversample = imblearn.over_sampling.RandomOverSampler(sampling_strategy='minority')\n# fit and apply the transform\nX, y = oversample.fit_resample(data.drop('y', axis=1), data['y'])\n\nX.shape, y.shape","ffcb2398":"#Let us group all the Epileptic occureses and Non Epileptic\nprint('Number of records of Non Epileptic {0} VS Epilepttic {1}'.format(len(y == True), len(y == False)))","7fde52a2":"# X = data.drop('y', axis=1)\n# y = data['y']\n\nnormalized_df = pd.DataFrame(normalize(X))\nnormalized_df","989c1219":"#Concat back in order to check description:\nnormalized_df['y'] = y\n\nprint('Normalized Totall Mean VALUE for Epiletic: {}'.format((normalized_df[normalized_df['y'] == 1].describe().mean()).mean()))\nprint('Normalized Totall Std VALUE for Epiletic: {}'.format((normalized_df[normalized_df['y'] == 1].describe().std()).std()))\n\nprint('Normalized Totall Mean VALUE for NOT Epiletic: {}'.format((normalized_df[normalized_df['y'] == 0].describe().mean()).mean()))\nprint('Normalized Totall Std VALUE for NOT Epiletic: {}'.format((normalized_df[normalized_df['y'] == 0].describe().std()).std()))","ce5c0f1d":"#Let us split our dataset on train and test and than invoke validation approach\n\nX = normalized_df.drop('y', axis=1)\ny = normalized_df['y']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n\n#Check the shapes after splitting\nhe = X_train, X_test, y_train, y_test\n[arr.shape for arr in he]","a076a14c":"#Define set of classifiers for input\nmodels = [LogisticRegression(), SVC(),\n          DecisionTreeClassifier(),\n          RandomForestClassifier(), \n          GradientBoostingClassifier(),\n          KNeighborsClassifier()]\n\n#Check the correctness of list of classifiers and also \nmodel_name = [type(model).__name__ for model in models]\nprint(model_name)\n\n# all parameters are not specified are set to their defaults\ndef classifiers(models):\n    columns = ['Score', 'Predictions']\n    df_result = pd.DataFrame(columns=columns, index=[type(model).__name__ for model in models])\n\n    for model in models:\n        clf = model\n        print('Initialized classifier {} with default parameters \\n'.format(type(model).__name__))    \n        clf.fit(X_train, y_train)\n        #make a predicitions for entire data(X_test)\n        predictions = clf.predict(X_test)\n        # Use score method to get accuracy of model\n        score = clf.score(X_test, y_test)\n        print('Score of classifier {} is: {} \\n'.format(type(model).__name__, score))\n        df_result['Score']['{}'.format(type(model).__name__)] = str(round(score * 100, 2)) + '%' \n        df_result['Predictions']['{}'.format(type(model).__name__)] = predictions\n    return df_result","0f8e8178":"classifiers(models)","4b2770f4":"from sklearn.model_selection import KFold\n### LogisticRegression\n# define models and parameters\nmodel = LogisticRegression()\nsolvers = ['newton-cg', 'lbfgs', 'liblinear']\npenalty = ['l2']\nc_values = [100, 10, 1.0, 0.1, 0.01]\n# define grid search\ngrid = dict(solver=solvers,penalty=penalty,C=c_values)\ncv = KFold(n_splits=10, random_state=42)\ngrid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\ngrid_result = grid_search.fit(X_train, y_train)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","a70651a3":"### KNeighborsClassifier\n# define models and parameters\nmodel = KNeighborsClassifier()\nn_neighbors = range(1, 21, 2)\nweights = ['uniform', 'distance']\nmetric = ['euclidean', 'manhattan', 'minkowski']\n# define grid search\ngrid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\ncv = KFold(n_splits=3, random_state=42)\ngrid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\ngrid_result = grid_search.fit(X_train, y_train)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","6be270b4":"### SVC\n# define model and parameters\nmodel = SVC()\nkernel = ['poly', 'rbf', 'sigmoid']\nC = [50, 10, 1.0, 0.1, 0.01]\ngamma = ['scale']\n# define grid search\ngrid = dict(kernel=kernel,C=C,gamma=gamma)\ncv = KFold(n_splits=3, random_state=42)\ngrid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\ngrid_result = grid_search.fit(X_train, y_train)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","9ee6bccf":"### RandomForestClassifier\n# define models and parameters\nmodel = RandomForestClassifier()\nn_estimators = [10, 100, 1000]\nmax_features = ['sqrt', 'log2']\n# define grid search\ngrid = dict(n_estimators=n_estimators,max_features=max_features)\ncv = KFold(n_splits=3, random_state=42)\ngrid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\ngrid_result = grid_search.fit(X_train, y_train)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","57df2013":"### GradientBoostingClassifier\n# define models and parameters\nmodel = GradientBoostingClassifier()\nn_estimators = [10, 100, 1000]\nlearning_rate = [0.001, 0.01, 0.1]\nsubsample = [0.5, 0.7, 1.0]\nmax_depth = [3, 7, 9]\n# define grid search\ngrid = dict(learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample, max_depth=max_depth)\ncv = KFold(n_splits=3, random_state=42)\ngrid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\ngrid_result = grid_search.fit(X_train, y_train)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","b31a7207":"[Link for description of dataset](https:\/\/archive.ics.uci.edu\/ml\/datasets\/Epileptic+Seizure+Recognition)<br>\n[Research paper](http:\/\/users.fs.cvut.cz\/ivo.bukovsky\/PROJEKT\/Data\/Realna\/BIO\/EEG\/reference\/PRE61907.pdf)<br>\n[Kaggle](https:\/\/www.kaggle.com\/harunshimanto\/epileptic-seizure-recognition)\n\nElectroencephalography (EEG) is an electrophysiological monitoring method to record electrical activity of the brain.","11f6082e":"<b>From data description:<\/b> we divided and shuffled every 4097 data points into 23 chunks, each chunk contains 178 data points for 1 second, and each data point is the value of the EEG recording at a different point in time.<br>\n\nSo now we have 23 x 500 = 11500 pieces of information(row), each information contains 178 data points for 1 second(column), the last column represents the label y {1,2,3,4,5}.","131afec3":"So, as we can observe, records of Epileptic seusizes are more smooth and looks like have a tendency.","2c98bd05":"|Data Set Characteristics||Attribute Characteristics||Associated Tasks||Number of Instances||Number of Attributes||Missing Values?|\n|---||---||---||---||---||---|\n|Multivariate, Time-Series||Integer, Real||Classification, Clustering||11500||179||N\/A|","8a2ad217":"### After all, let us go further with ML models. ","526bc16a":"Make a pipeline for Classification models:\n- LogisticRegression\n- Support Vector Machines - linear and rbf\n- K-nearest Classifier\n- Decision Tree Classifier\n- Gradient Bossting Classifier","78477069":"Tuning Hyperparameters","7be0bd19":"First of all let us import all necessary libraries","342e197d":"### Let us plot and have a look on EPILIPTIC and NOT EPILETTIC occureses","a8d50c78":"### Let us shuffle data because of previous manipulations","358f299c":"Or alternatevily read data directly from web application (additionally we can download data locally)","6fcdfcad":"Let us look more preciesly on <b>y<\/b> column and it's value's importance for our case.<br>\n\n<b>y<\/b> contains the category of the 178-dimensional input vector. Specifically y in {1, 2, 3, 4, 5}:\n - 5 - eyes open, means when they were recording the EEG signal of the brain the patient had their eyes open\n - 4 - eyes closed, means when they were recording the EEG signal the patient had their eyes closed\n - 3 - Yes they identify where the region of the tumor was in the brain and recording the EEG activity from the healthy brain area\n - 2 - They recorder the EEG from the area where the tumor was located\n - 1 - Recording of seizure activity\nAll subjects falling in classes 2, 3, 4, and 5 are subjects who did not have epileptic seizure. Only subjects in class 1 have epileptic seizure.","62b4d1d5":"So, for now let us have a look on the description of our data. <br>\nWe can do it using several approaches:\n - 1) ususal: pd.description(), pd.info()\n - 2) ff.create_table (approach from plotly - in our case unnecessary, but we will use it for interesting)","dec08568":"### Short description of dataset","fd773862":"So, after quick looking we observe weird names of features.<br>\nLet us look throught description of features and target (y) feature also.","9a7159d0":"Check the balance for y","7a22a781":"### Change the y target column (make a binary classification task)","4475924b":"Normalizing","d5f92d19":"### \"Remove Unnamed\" column (it has information which we don't need)","38242353":"Let us got to the directory where we have our data (.csv file, named: Epileptic Seizure Recognition.csv)","dd6cdd68":"Let us go further:","b4aa2e32":"By the chance we faced with plotting, let us quickly plot few curves.<br>\nAs we can observe, it seems we have few types of curves. Let us keep it in our minds and analyse it during further steps.","72c9ab82":"### Plan\n    - To be introduced with dataset description\n    - Change the y target column (make a binary classification task)\n    - Remove Unnamed: 0 column (additionaly check the importance of it)\n    - EDA + Smart visualisation of data\n    - Make pipelines for all the approaches for binary classification task + make a comperison table of results\n    ----------------\n    - PCA or ICA (from mne) --> reduce size of data\n    - Use previous pipelines for reduced data + make a comperison table of results\n    - Approaching with mne library\n    - Model tuning!!!\n    ","b98dc88c":"As we realyesed earlier, we can try to normalize data. Let us do it. But before that we will use undersampling approach in order to prevent imbalanced issue","4c2e8f9c":"### Let us make a scatter plot of values for Epiletpic and Not Epileptic occureses","9ccee41a":"We can see quiet big difference, probably, we wiil demand to normalize\/scale our data. ","09ba3bca":"From the first view we can assume we need to solve **multi-classification task**, but, after accurate exploaring definitions of classes of <b>y<\/b>, we can realeyes we can *reform* our **multi-classification task** to **binary classification task**.<br>\nFor that we can just combine {2,3,4,5} classes as 0 class (not epileptic seizure) and keep {1} class as 1 (epileptic seizure)."}}