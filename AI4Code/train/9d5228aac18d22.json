{"cell_type":{"9774cc96":"code","2f381ea0":"code","2a3e4b83":"code","fcf67147":"code","c59b658b":"code","f847e8b4":"code","ae868b13":"code","db13ff67":"code","020b4758":"code","26bc1585":"code","7cf8eb3f":"code","2c328c52":"code","ea4302dd":"code","09a25a2a":"code","1203f4d3":"code","d90e030b":"code","0ba2f650":"code","d2da8912":"code","04109d4d":"code","05cb9847":"code","1f7c4a45":"code","d3bfc9dd":"code","c54d4891":"code","b7f38579":"code","8319978c":"code","e819a642":"code","742003f7":"code","e88ce655":"markdown","1255a19c":"markdown","d9dd555a":"markdown","8191bc6e":"markdown","495c402d":"markdown","11376da5":"markdown","f695c6f7":"markdown","5dcc0cbe":"markdown","3d238c6f":"markdown","ca5887b2":"markdown","8a529e9a":"markdown","17f152f0":"markdown","40137daf":"markdown","5412f06b":"markdown","cc4da2c3":"markdown","fc3ed4df":"markdown","b10cdb5d":"markdown","57385149":"markdown","e97aa5ec":"markdown","8bb9574e":"markdown","8c5c39f7":"markdown","64a11320":"markdown"},"source":{"9774cc96":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom termcolor import colored\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom tqdm import tqdm","2f381ea0":"df = pd.read_csv('..\/input\/feedback-prize-2021\/train.csv')","2a3e4b83":"df.head(5)","fcf67147":"plt.figure(figsize=(10,5))\ndf.groupby(\"discourse_type\").count()['id'].sort_values().plot(kind='barh')\nplt.show()","c59b658b":"df['text_len'] = df['discourse_text'].apply(lambda x: len(x))","f847e8b4":"plt.figure(figsize=(10,5))\ndf.groupby('discourse_type')['text_len'].mean().sort_values().plot(kind='barh')\nplt.show()","ae868b13":"df.groupby('discourse_type')['text_len'].describe()","db13ff67":"df[(df['discourse_type'] == 'Claim') & (df['text_len'] < 10)]","020b4758":"text = df[(df['discourse_type'] == 'Claim') & (df['text_len'] < 10)].iloc[0]['id']","26bc1585":"text = open(f'..\/input\/feedback-prize-2021\/train\/{text}.txt')","7cf8eb3f":"print(text.read())","2c328c52":"def print_type_color(idx, df):\n    #discourse_id = df.iloc[idx]['id']\n    discourse_id = idx\n    text_df = df[df['id'] == discourse_id]\n    start_type = df[df['id'] == discourse_id].set_index('id')[['discourse_start','discourse_end','discourse_type']]\n    \n    colors = {\n        'Lead':'red',\n        'Position': 'blue',\n        'Evidence': 'green',\n        'Claim': 'magenta',\n        'Counterclaim': 'grey',\n        'Rebuttal': 'magenta',\n        'Concluding Statement': 'cyan'\n    }\n    \n    text = open(f'..\/input\/feedback-prize-2021\/train\/{discourse_id}.txt')\n    text = text.read()\n        \n    for i in range(len(start_type)):\n        s = int(start_type.iloc[i]['discourse_start'])\n        e = int(start_type.iloc[i]['discourse_end'])\n        t = start_type.iloc[i]['discourse_type']\n        print(colored (t, attrs=['bold']))\n        print(\n            colored(text[s:e], colors[t])\n        )","ea4302dd":"print_type_color('423A1CA112E2',df)","09a25a2a":"df[(df['discourse_type'] == 'Claim') & (df['text_len'] < 10)]","1203f4d3":"print_type_color('4B6C254FEE39',df)","d90e030b":"def join_types(idx,df):\n    #discourse_id = df.iloc[idx]['id']\n    discourse_id = idx\n    text_df = df[df['id'] == discourse_id]\n    start_type = df[df['id'] == discourse_id].set_index('id')[['discourse_start','discourse_end','discourse_type']]\n        \n    text = open(f'..\/input\/feedback-prize-2021\/train\/{discourse_id}.txt')\n    text = text.read()\n    \n    out_df = pd.DataFrame(columns = list(text_df.columns))\n    c = 0\n    prev_t = start_type.iloc[0]['discourse_type']\n    l = [0]\n    \n    for i in range(1,len(start_type)):\n                \n        t = start_type.iloc[i]['discourse_type']\n        \n        if t == prev_t:\n            l.append(i)\n        else:\n            tmp = text_df.iloc[l[-1]]\n            tmp['discourse_start'] = text_df.iloc[l[0]]['discourse_start']\n            \n            tot = ''\n            for j in l:\n                tot += text_df['predictionstring'].iloc[j] + ' '\n            tot = tot[:-1]\n                \n            tmp['predictionstring'] = tot\n            \n            out_df = out_df.append(tmp)\n            l = [i]\n            \n        prev_t = t\n    \n    return out_df","0ba2f650":"df2 = join_types('4B6C254FEE39',df)","d2da8912":"df2.head()","04109d4d":"print_type_color('4B6C254FEE39',df2)","05cb9847":"def merge_by_id(df):\n    ids = df['id'].unique()\n    clean_df = pd.DataFrame(columns = list(df.columns))\n    \n    for idx in tqdm(ids):\n        clean_df = clean_df.append(join_types(idx,df))\n    return clean_df","1f7c4a45":"clean_df = merge_by_id(df)","d3bfc9dd":"len(df)","c54d4891":"len(clean_df)","b7f38579":"clean_df.head()","8319978c":"plt.figure(figsize=(10,5))\nclean_df.groupby(\"discourse_type\").count()['id'].sort_values().plot(kind='barh')\nplt.show()","e819a642":"plt.figure(figsize=(10,5))\ndf.groupby('discourse_type')['text_len'].mean().sort_values().plot(kind='barh')\nplt.show()","742003f7":"clean_df.to_csv('clean_data.csv',index=False)","e88ce655":"* ##   Claim is the most frequent one, but it is also the smaller type of discourse. \ud83e\udd14\n* ## Evidence is the second most frequent and the longest type.","1255a19c":"# Evaluating Student Writing EDA Notebook \ud83d\udcdd","d9dd555a":"# On the DataFrame we have infomation about the starting and ending of each discourse type, lets create a function to print the text with each type on a different colour.","8191bc6e":"# The function eliminate around 40k rows, wow! \ud83d\ude2e","495c402d":"# Let's explore some of the outliers on the data (i.e. discourse type with a small length)","11376da5":"## We will create a function that given an index, will groupby with the \"id\" and join the types which are equal and together.","f695c6f7":"# Testing the function, it takes an id as an input.","5dcc0cbe":"# Let's apply it to all the data.","3d238c6f":"## Claim is the most frequent discourse type, rebuttal is the least.","ca5887b2":"# Great! Now that separated Claims are all set in one! \ud83d\ude2c","8a529e9a":"## Finding a text","17f152f0":"# Using the same exploration as before.","40137daf":"# Now evidence is the most commont type!","5412f06b":"## Let's check the outliers.","cc4da2c3":"# Let's write it into a .csv","fc3ed4df":"# This particular essay has 4 Claims, and even tought they are next to each other they are separated, lets fix this.","b10cdb5d":"# The function to clean the data took about 23 minutes, feel free to use it. \ud83e\udd1b","57385149":"## How many words on avg per type?","e97aa5ec":"# Load the training data from the competition dataset \ud83d\udd0d","8bb9574e":"# Each text has an id, discourse_id and the starting\/ending point of each discourse, and the type. Let's find how many of each type there are.","8c5c39f7":"# Testing on the previous case","64a11320":"# Import dependencies"}}