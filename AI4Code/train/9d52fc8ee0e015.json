{"cell_type":{"ac6b2b7a":"code","7bed7b1b":"code","dd5067ae":"code","6851b588":"code","d6990c31":"code","16836936":"code","2f8c5b02":"code","ca5dc3f1":"code","f10e08f4":"code","f11642e1":"code","174d733d":"code","72995423":"code","aede6872":"code","c33bbedb":"code","0a33fcc1":"code","dbf7d1ed":"code","44533371":"code","09c2e307":"code","4d8846bf":"code","683fdb9c":"code","8ed941a5":"code","9510b0ce":"markdown","c0280bb4":"markdown","9d070a23":"markdown","ff607573":"markdown","3bd1684d":"markdown","a3d5f143":"markdown","ec9e46bd":"markdown","d4fde03f":"markdown"},"source":{"ac6b2b7a":"import os\nimport shutil\nimport cv2\nimport json\nimport numpy as np \nfrom glob import glob\nfrom keras import backend as K\nfrom keras.models import Model, load_model\nfrom keras.layers import Conv2D, MaxPool2D, Input, concatenate, UpSampling2D, Dropout\nfrom keras.layers import Conv2DTranspose, AvgPool2D, GaussianNoise, BatchNormalization\nfrom skimage.segmentation import mark_boundaries\nfrom skimage.measure import label, regionprops\n#from skimage.util.montage import montage2d as montage\n\nimport tensorflow as tf\nimport keras.backend as K\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import binary_crossentropy\nimport keras\nfrom tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","7bed7b1b":"\n\nall_links = ['ftp:\/\/smartengines.com\/midv-500\/dataset\/01_alb_id.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/02_aut_drvlic_new.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/03_aut_id_old.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/04_aut_id.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/05_aze_passport.zip', \n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/06_bra_passport.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/07_chl_id.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/08_chn_homereturn.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/09_chn_id.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/10_cze_id.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/11_cze_passport.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/12_deu_drvlic_new.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/13_deu_drvlic_old.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/14_deu_id_new.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/15_deu_id_old.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/16_deu_passport_new.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/17_deu_passport_old.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/18_dza_passport.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/19_esp_drvlic.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/20_esp_id_new.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/21_esp_id_old.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/22_est_id.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/23_fin_drvlic.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/24_fin_id.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/25_grc_passport.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/26_hrv_drvlic.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/27_hrv_passport.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/28_hun_passport.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/29_irn_drvlic.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/30_ita_drvlic.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/31_jpn_drvlic.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/32_lva_passport.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/33_mac_id.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/34_mda_passport.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/35_nor_drvlic.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/36_pol_drvlic.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/37_prt_id.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/38_rou_drvlic.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/39_rus_internalpassport.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/40_srb_id.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/41_srb_passport.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/42_svk_id.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/43_tur_id.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/44_ukr_id.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/45_ukr_passport.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/46_ury_passport.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/47_usa_bordercrossing.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/48_usa_passportcard.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/49_usa_ssn82.zip',\n             'ftp:\/\/smartengines.com\/midv-500\/dataset\/50_xpo_id.zip']\n\ndef read_image(img, label):\n    image = cv2.imread(img)\n    mask = np.zeros(image.shape, dtype=np.uint8)\n    quad = json.load(open(label, 'r'))\n    coords = np.array(quad['quad'], dtype=np.int32)\n    cv2.fillPoly(mask, coords.reshape(-1, 4, 2), color=(255,255,255))\n    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n    mask = cv2.resize(mask, (mask.shape[1]\/\/2, mask.shape[0]\/\/2))\n    image = cv2.resize(image, (image.shape[1]\/\/2, image.shape[0]\/\/2))\n    mask = cv2.threshold(mask, 0,255, cv2.THRESH_BINARY)[1]\n    mask = cv2.resize(mask, (256,256))\n    image = cv2.resize(image, (256, 256))\n    return image, mask\n\n\ni = 1\n\nfor link in all_links:\n    print('----------------------------------------------------------------------')\n    print('\\nDownloading:', link[40:])\n    os.system('wget ' + link)\n    print('Downloaded:', link[40:])\n    print('Unzipping:', link[40:])\n    os.system('unzip ' + link[40:])\n    print('Unzipped:', link[40:].replace('.zip', ''))\n\n    imgdir_path = '.\/' + link[40:].replace('.zip', '') + '\/images\/'\n    crddir_path = '.\/' + link[40:].replace('.zip', '') + '\/ground_truth\/'\n    # time.sleep(5)\n    X = []\n    Y = []\n    os.remove(imgdir_path + link[40:].replace('.zip', '.tif'))\n    os.remove(crddir_path + link[40:].replace('.zip', '.json'))\n    for images, ground_truth in zip(sorted(os.listdir(imgdir_path)), sorted(os.listdir(crddir_path))):\n        img_list = sorted(glob(imgdir_path + images + '\/*.tif'))\n        label_list = sorted(glob(crddir_path + ground_truth + '\/*.json'))\n        for img, label in zip(img_list, label_list):\n            image, mask = read_image(img, label)\n            X.append(image)\n            Y.append(mask)\n\n    X = np.array(X)\n    Y = np.array(Y)\n    Y = np.expand_dims(Y, axis=3)\n    print(link[40:].replace('.zip', ''), X.shape, Y.shape)\n    # print(X.shape, Y.shape)\n    np.save('train_image' + str(i) + '.npy', X)\n    np.save('mask_image' + str(i) + '.npy', Y)\n    print('Files Saved For:', link[40:].replace('.zip', ''))\n    i += 1\n    print('----------------------------------------------------------------------')\n    os.remove(link[40:])\n    shutil.rmtree(link[40:].replace('.zip', ''))","dd5067ae":"total = np.load('train_image1.npy')\nfor i in range(2,51):\n    temp = np.load('train_image' + str(i) + '.npy')\n    total = np.vstack((total, temp))\n\nnp.save('final_train.npy', total)\n\ntotal = np.load('mask_image1.npy')\nfor i in range(2,51):\n    temp = np.load('mask_image' + str(i) + '.npy')\n    total = np.vstack((total, temp))\nnp.save('final_mask.npy', total)","6851b588":"del total","d6990c31":"def get_model():\n    K.clear_session()\n    inputs = Input((256,256,3))\n    s = BatchNormalization()(inputs) # we can learn the normalization step\n    s = Dropout(0.5)(s)\n\n    c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\n    c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n    p1 = MaxPool2D((2, 2)) (c1)\n\n    c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n    c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n    p2 = MaxPool2D((2, 2)) (c2)\n\n    c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n    c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n    p3 = MaxPool2D((2, 2)) (c3)\n\n    c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n    c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n    p4 = MaxPool2D(pool_size=(2, 2)) (c4)\n\n    c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\n    c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n\n    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\n    u6 = concatenate([u6, c4])\n    c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n    c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\n    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n    c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\n    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n    c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\n    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n    c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\n    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\n    SCC_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\n    model = Model(inputs=inputs, outputs=outputs)\n    print(model.summary())\n    model.compile(optimizer=Adam(lr=1e-4), loss=SCC_loss, metrics=['binary_accuracy'])\n\n    return model","16836936":"X = np.load('final_train.npy')\nY = np.load('final_mask.npy')\n\ndef t_generator(X_train, Y_train, batch_size):\n    features = np.zeros(shape=(batch_size, 256,256,3))\n    labels = np.zeros(shape=(batch_size, 256,256,1))\n    while True:\n        start = 0\n        end = batch_size\n        for i in range(243):\n            features = X_train[start:end]\n            labels = Y_train[start:end]\n            start = end\n            end = end + batch_size\n            yield features \/ 255.0, labels \/ 255.0\n\n            \ndef v_generator(X_val, Y_val, batch_size):\n    features = np.zeros(shape=(batch_size, 256,256,3))\n    labels = np.zeros(shape=(batch_size, 256,256,1))\n    while True:\n        start = 0\n        end = batch_size\n        for i in range(27):\n            features = X_val[start:end]\n            labels = Y_val[start:end]\n            start = end\n            end = end + batch_size\n            yield features \/ 255.0, labels \/ 255.0\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n                                                    shuffle=True, \n                                                    random_state=265, \n                                                    test_size=0.1)\ndel X, Y\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, \n                                                  shuffle=True, \n                                                  random_state=265,\n                                                  test_size=0.1)","2f8c5b02":"model = get_model()\nspe = X_train.shape[0] \/\/ 50\nvs = X_val.shape[0] \/\/ 50\n## Adding Callbacks\ntb = TensorBoard(log_dir='.\/logs\/', batch_size=8, write_graph=True)\n\n\nmodel_chkpt = ModelCheckpoint('Edge_Detector_unet.h5',\n                              monitor='val_loss', verbose=1, \n                              save_best_only=True)","ca5dc3f1":"X_train.shape","f10e08f4":"X_val.shape","f11642e1":"Y_train.shape","174d733d":"validation_data=v_generator(X_val, Y_val, 50)","72995423":"generator = t_generator(X_train, Y_train, 50)","aede6872":"history = model.fit_generator(generator, \n                              steps_per_epoch=spe, \n                              epochs=35, callbacks=[model_chkpt], \n                              validation_data=validation_data,\n                              validation_steps= vs)","c33bbedb":"#plotting loss\nplt.style.use('seaborn-dark-palette')\nfig, ax = plt.subplots()\nax1 = ax.plot(history.history['loss'] , label='Loss')\nax2 = ax.plot(history.history['val_loss'] , label = 'Val_loss')\nplt.xlabel('Epochs')\nplt.legend()\nplt.title('Training nad Validation loss')\nplt.show()\nfig.tight_layout()\nfig.savefig('Loss.png' , bbox_inches= 'tight')\n","0a33fcc1":"fig, ax = plt.subplots()\nax1 = ax.plot(history.history['binary_accuracy'] , label='Accuracy')\nax2 = ax.plot(history.history['val_binary_accuracy'] , label = 'Val-Accuracy')\nplt.xlabel('Epochs')\nplt.legend()\nplt.title('Training nad Validation Accuracy')\nplt.show()\nfig.tight_layout()\nfig.savefig('Accuracy.png' , bbox_inches= 'tight')","dbf7d1ed":"samples = X_val[4:10]","44533371":"predictions = model.predict(samples)","09c2e307":"plt.style.available","4d8846bf":"plt.style.use('seaborn-white')","683fdb9c":"def plot_prediction(img , prediction):\n    fig = plt.figure()\n    ax1 = fig.add_subplot(1,2,1)\n    ax1.imshow(img)\n    ax1.set_xticks([])\n    ax1.set_yticks([])\n    ax1.set_title('Input')\n    ax2 = fig.add_subplot(1,2,2)\n    ax2.imshow(prediction , 'inferno')\n    ax2.set_xticks([])\n    ax2.set_yticks([])\n    ax2.set_title('Predicted Mask')\n    ","8ed941a5":"for i in range(len(samples)):\n    plot_prediction(samples[i] , predictions[i])","9510b0ce":"## Loss And Accuracy","c0280bb4":"## Compiling the model","9d070a23":"## Preparing Training and Validation set","ff607573":"## Example prediction","3bd1684d":"## Training","a3d5f143":"# Downloading the dataset\n\nThe Dataset we are using is [midv-500](https:\/\/arxiv.org\/abs\/1807.05786) - A Dataset for Identity Documents Analysis and Recognition on Mobile Devices in Video Stream by \nVladimir V. Arlazarov,\nKonstantin Bulatov,\nTimofey S. Chernov and\nVladimir L. Arlazarov","ec9e46bd":"# Defining the Unet Model\n\nThe Unet Model is used for semantic segmentation given an image it outputs a segmentation mask. In this notebbook we only have to classify between two classes either card like object or not. Thus the loss function used to train the model is Binary crossentropy. Since we need to draw the boundaries for these objects this model will give us the rgion of interest.","d4fde03f":"### Creating a single npy file"}}