{"cell_type":{"a63b74c0":"code","b3cfd645":"code","a19a2c55":"code","ab53699f":"code","34ed2f85":"code","78039a77":"code","28591db2":"code","d9c3415e":"code","b989ae94":"code","6b900933":"code","c1d4eb91":"code","902cc022":"code","00d0b18d":"code","883d173c":"code","e53074f2":"markdown","bbafb741":"markdown","66a6995f":"markdown","aff71635":"markdown","a38bdda0":"markdown","1e0a2622":"markdown","304e231d":"markdown","9a248221":"markdown","b760efa9":"markdown","4cd17d99":"markdown","bb19a341":"markdown","cfa8fc74":"markdown","99b6912f":"markdown","8cc6f656":"markdown","b858a211":"markdown","ef67c912":"markdown","1ee54154":"markdown","c31b9ea6":"markdown","5b391dac":"markdown"},"source":{"a63b74c0":"import numpy as np\nfrom sklearn.svm import SVC\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom sklearn.datasets.samples_generator import make_circles\nfrom matplotlib import pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom mpl_toolkits.mplot3d import proj3d","b3cfd645":"samples, labels = make_blobs(n_samples=200, centers=2,\n                  random_state=0, cluster_std=0.50)","a19a2c55":"plt.scatter(samples[:, 0], samples[:, 1], c=labels);","ab53699f":"clf = SVC(kernel='linear')\nclf.fit(samples, labels)","34ed2f85":"def plot_svc_decision_function(clf, ax=None, plot_support=True):\n    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n    if ax is None:\n        ax = plt.gca()\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid to evaluate model\n    x = np.linspace(xlim[0], xlim[1], 2000)\n    y = np.linspace(ylim[0], ylim[1], 2000)\n    Y, X = np.meshgrid(y, x)\n    xy = np.vstack([X.ravel(), Y.ravel()]).T\n    P = clf.predict(xy).reshape(X.shape)\n\n    # plot decision boundary and margins\n    ax.contourf(X, Y, P, levels=2, alpha=0.2)\n    \n    ax.set_xlim(xlim)\n    ax.set_ylim(ylim)","78039a77":"plt.scatter(samples[:, 0], samples[:, 1], c=labels)\nplot_svc_decision_function(clf);","28591db2":"samples, labels = make_circles(200, factor=0.1, noise=0.1)","d9c3415e":"plt.scatter(samples[:, 0], samples[:, 1], c=labels);","b989ae94":"clf.fit(samples, labels)","6b900933":"plt.scatter(samples[:, 0], samples[:, 1], c=labels)\nplot_svc_decision_function(clf);","c1d4eb91":"rbf_kernel_clf = SVC(kernel='rbf')\nrbf_kernel_clf.fit(samples, labels)","902cc022":"plt.scatter(samples[:, 0], samples[:, 1], c=labels)\nplot_svc_decision_function(rbf_kernel_clf);","00d0b18d":"r = np.exp(-(samples ** 2).sum(1))","883d173c":"fig = plt.figure(figsize=(10,10))\nax = fig.add_subplot(111, projection='3d')\nax.plot(samples[:,0], samples[:,1], r, 'o', markersize=8, alpha=0.5)\nplt.show()","e53074f2":"Now use the scatter plot again to see what we have.","bbafb741":"Generate training samples. Here we generate two clusters of points and will try to classify them later.","66a6995f":"Import libraries we used in this kernel.","aff71635":"Let's see what we have here using the scatter plot.","a38bdda0":"Let's see if this time it can do any better.","1e0a2622":"For example, here we can use a kernel function that add a **r** dimension to data and the value of **r** depends on how far **r** is from a point C in space (here C equals (0,0))","304e231d":"We can also use the sklearn data generator to generate sample data.","9a248221":"Okay. That's enough for **linear separatable** classes. Now try some data that is **not linear separatable** (can not be separated with a straight line), i.e surrounded classes.","b760efa9":"Let plot the trained SVC model with data points to see if it's doing well.","4cd17d99":"Well, ways better now. But **how**?","bb19a341":"For once, try our luck with the linear kernel SVC. Let's try to fit the SVC model with **this new data**.","cfa8fc74":"Okay so now we have a function to plot the SVC decision boundary and the margins.","99b6912f":"Again, scatter plot and decision boundary.","8cc6f656":"Well, bad luck this time. It's when the non-linear kernels come to the rescue. Let's try separating data points in a higher dimension space using the *Radial Basic Function* aka **'rbf'** kernel.","b858a211":"Now we can plot a 3D figure to see if the **r** dimension really helps.","ef67c912":"Turns out the 'rbf' kernel is a kind SVC kernel to map 2D data into a 3D space, and the data samples are linear separatable in the 3d space.","1ee54154":"**r** can be calculated as:","c31b9ea6":"Ok so we have two classes of samples. We will try to classify them using SVM Classifier. Scikit-learn (sklearn for short) library have built-in function **SVC** to help us with the task.\n\nI will try SVC with a linear kernel because we can see the data classes are linear separatable.\nCall *fit* to fit the model to this dataset.","5b391dac":"Now they are linear separatable ;)"}}