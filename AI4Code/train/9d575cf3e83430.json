{"cell_type":{"accfeec2":"code","e680d5de":"code","3689d0da":"code","584c1d1f":"code","315cc7d5":"code","963dcb6b":"code","8ee5eb23":"code","9fb60b73":"code","87623a71":"code","1b29e159":"markdown","5a7f0f4f":"markdown","da79611c":"markdown","6b8af27d":"markdown"},"source":{"accfeec2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport h5py\nfrom tqdm import tqdm\nimport cv2","e680d5de":"train_df = pd.read_csv('..\/input\/train.csv')\nchannels = ['red', 'green', 'blue', 'yellow']\nhdf_path = f'.\/train.hdf5'","3689d0da":"def load_image(id):\n    img = np.zeros((4, 512, 512), dtype=np.uint8)\n    for c, ch in enumerate(channels):\n        img[c, ...] = cv2.imread('..\/input\/train\/{}_{}.png'.format(id, ch), cv2.IMREAD_GRAYSCALE)\n    return img","584c1d1f":"with h5py.File(hdf_path, mode='w') as train_hdf5:\n    train_hdf5.create_dataset(\"train\", (len(train_df), 4, 512, 512), np.uint8)\n    for i, id in tqdm(enumerate(train_df['Id'][:100])):    #Remove the [:100] for full dataset\n        img = load_image(id)\n        train_hdf5['train'][i, ...] = img","315cc7d5":"randind = np.random.randint(0, len(train_df), 8)\nrandind = np.sort(randind)","963dcb6b":"train_hdf5 = h5py.File(hdf_path, \"r\")","8ee5eb23":"%%timeit\n# with h5py.File(hdf_path, \"r\") as train_hdf5:       # Causes 20% slowdown :(\nbatch = train_hdf5['train'][randind, ...]","9fb60b73":"train_hdf5.close()","87623a71":"%%timeit\nbatch = np.zeros((8, 4, 512, 512), dtype=np.uint8)\nfor i, ind in enumerate(randind):\n    batch[i, ...] = load_image(train_df['Id'][ind])","1b29e159":"This is my first kernel, and the first time I'm experimenting with HDF5, so suggestions and feedback are welcome.\n\nCan someone tell me what happens if I don't close an open datastore? Opening and closing per batch is slow, and I want to know if I will corrupt the data if I interrupt training without closing.","5a7f0f4f":"Loading images is pretty slow, especially when you are reading 4 images per example. Here I attempt to create a HDF5 datastore for faster loading of data.","da79611c":"**Rough Benchmark**","6b8af27d":"Loading from the HDF5 Datastore"}}