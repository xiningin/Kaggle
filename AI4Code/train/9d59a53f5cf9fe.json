{"cell_type":{"298b59f5":"code","4b569ef3":"code","94833584":"code","e7c3f9b0":"code","22af9088":"code","f6031c07":"code","bfcfa82f":"code","5b4f3e5d":"code","fe219b20":"code","722ffcff":"code","466bfbe8":"markdown","2631a6b7":"markdown","4a796976":"markdown"},"source":{"298b59f5":"# For running inference on the TF-Hub module.\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\n# For downloading the image.\nimport matplotlib.pyplot as plt\nimport tempfile\nfrom six.moves.urllib.request import urlopen\nfrom six import BytesIO\n\n# For drawing onto the image.\nimport numpy as np\nfrom PIL import Image\nfrom PIL import ImageColor\nfrom PIL import ImageDraw\nfrom PIL import ImageFont\nfrom PIL import ImageOps\n\n# For measuring the inference time.\nimport time","4b569ef3":"def display_image(image):\n  fig = plt.figure(figsize=(20, 15))\n  plt.grid(False)\n  plt.imshow(image)\n\n\ndef download_and_resize_image(url, new_width=256, new_height=256,\n                              display=False):\n  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n  response = urlopen(url)\n  image_data = response.read()\n  image_data = BytesIO(image_data)\n  pil_image = Image.open(image_data)\n  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n  pil_image_rgb = pil_image.convert(\"RGB\")\n  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n  print(\"Image downloaded to %s.\" % filename)\n  if display:\n    display_image(pil_image)\n  return filename\n\n\ndef draw_bounding_box_on_image(image,\n                               ymin,\n                               xmin,\n                               ymax,\n                               xmax,\n                               color,\n                               font,\n                               thickness=4,\n                               display_str_list=()):\n  \"\"\"Adds a bounding box to an image.\"\"\"\n  draw = ImageDraw.Draw(image)\n  im_width, im_height = image.size\n  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n                                ymin * im_height, ymax * im_height)\n  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n             (left, top)],\n            width=thickness,\n            fill=color)\n\n  # If the total height of the display strings added to the top of the bounding\n  # box exceeds the top of the image, stack the strings below the bounding box\n  # instead of above.\n  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n  # Each display_str has a top and bottom margin of 0.05x.\n  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n\n  if top > total_display_str_height:\n    text_bottom = top\n  else:\n    text_bottom = top + total_display_str_height\n  # Reverse list and print from bottom to top.\n  for display_str in display_str_list[::-1]:\n    text_width, text_height = font.getsize(display_str)\n    margin = np.ceil(0.05 * text_height)\n    draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n                    (left + text_width, text_bottom)],\n                   fill=color)\n    draw.text((left + margin, text_bottom - text_height - margin),\n              display_str,\n              fill=\"black\",\n              font=font)\n    text_bottom -= text_height - 2 * margin\n\n\ndef draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n  colors = list(ImageColor.colormap.values())\n\n  try:\n    font = ImageFont.truetype(\"\/usr\/share\/fonts\/truetype\/liberation\/LiberationSansNarrow-Regular.ttf\",\n                              25)\n  except IOError:\n    #print(\"Font not found, using default font.\")\n    font = ImageFont.load_default()\n\n  for i in range(min(boxes.shape[0], max_boxes)):\n    if scores[i] >= min_score:\n      ymin, xmin, ymax, xmax = tuple(boxes[i])\n      display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n                                     int(100 * scores[i]))\n      color = colors[hash(class_names[i]) % len(colors)]\n      image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n      draw_bounding_box_on_image(\n          image_pil,\n          ymin,\n          xmin,\n          ymax,\n          xmax,\n          color,\n          font,\n          display_str_list=[display_str])\n      np.copyto(image, np.array(image_pil))\n  return image","94833584":"# By Heiko Gorski, Source: https:\/\/commons.wikimedia.org\/wiki\/File:Naxos_Taverna.jpg\nimage_url = \"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/6\/60\/Naxos_Taverna.jpg\"  #@param\ndownloaded_image_path = download_and_resize_image(image_url, 1280, 856, True)","e7c3f9b0":"module_handle = \"https:\/\/tfhub.dev\/google\/faster_rcnn\/openimages_v4\/inception_resnet_v2\/1\"\n# \"https:\/\/tfhub.dev\/google\/openimages_v4\/ssd\/mobilenet_v2\/1\", \n# \"https:\/\/tfhub.dev\/google\/faster_rcnn\/openimages_v4\/inception_resnet_v2\/1\"\n\ndetector = hub.load(module_handle).signatures['default']","22af9088":"def load_img(path):\n  img = tf.io.read_file(path)\n  img = tf.image.decode_jpeg(img, channels=3)\n  return img","f6031c07":"def run_detector(detector, path):\n  img = load_img(path)\n\n  converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n  #start_time = time.time()\n  result = detector(converted_img)\n  #end_time = time.time()\n\n  result = {key:value.numpy() for key,value in result.items()}\n\n  #print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n  #print(\"Inference time: \", end_time-start_time)\n\n  image_with_boxes = draw_boxes(\n      img.numpy(), result[\"detection_boxes\"],\n      result[\"detection_class_entities\"], result[\"detection_scores\"])\n\n  display_image(image_with_boxes)","bfcfa82f":"run_detector(detector, downloaded_image_path)","5b4f3e5d":"import os\nimport random","fe219b20":"data_dir='..\/input\/flickr-image-dataset\/flickr30k_images\/flickr30k_images'\nfiles0=os.listdir(data_dir)\nprint(len(files0))\nN=list(range(len(files0)))\nrandom.seed(2021)\nrandom.shuffle(N)\nfiles=np.array(files0)","722ffcff":"for im in files[N[0:6]]:\n    path=os.path.join(data_dir,im)\n    run_detector(detector, path)","466bfbe8":"## Example use","2631a6b7":"# Flicker Image Object Detection TF-Hub# Object Detection\nThis notebook referred to <br\/>\nhttps:\/\/github.com\/tensorflow\/hub\/blob\/master\/examples\/colab\/object_detection.ipynb","4a796976":"## Setup\n"}}