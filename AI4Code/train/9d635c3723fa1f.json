{"cell_type":{"7674e9c0":"code","b1e12036":"code","6f2bced3":"code","45b1d10c":"code","75e47de1":"code","817ce91c":"code","ec7ea273":"markdown","44d4b09d":"markdown","41907f24":"markdown","faa4f365":"markdown","76eca353":"markdown"},"source":{"7674e9c0":"import joblib\n\nprev_notebook_folder = \"..\/input\/building-a-neural-network-to-predict-loan-risk\/\"\nloans = joblib.load(prev_notebook_folder + \"loans_for_eval.joblib\")\nloans.shape","b1e12036":"loans.head()","6f2bced3":"from sklearn.model_selection import train_test_split\n\nloans[\"date\"] = loans[\"issue_d\"].astype(\"datetime64[ns]\")\nloans.sort_values(\"date\", axis=\"index\", inplace=True, kind=\"mergesort\")\n\ntrain, test = train_test_split(loans, test_size=0.2, shuffle=False)\ntrain, test = train.copy(), test.copy()\nprint(f\"The test set contains {len(test):,} loans.\")","45b1d10c":"from statistics import mean\n\nlc_grade_a = test[test[\"grade\"] == \"A\"]\nprint(f\"LendingClub gave {len(lc_grade_a):,} loans in the test set an A grade.\")\n\nprint(\"\\nAverage `fraction_recovered` on LendingClub's grade A loans:\")\nprint(format(mean(lc_grade_a[\"fraction_recovered\"]), \".5f\"))","75e47de1":"from sklearn.model_selection import train_test_split\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\nfrom tensorflow.keras import Sequential, Input\nfrom tensorflow.keras.layers import Dense, Dropout\n\n\ndef run_pipeline(\n    data,\n    onehot_cols,\n    ordinal_cols,\n    batch_size,\n    validate=True,\n):\n    X = data.drop(columns=[\"fraction_recovered\"])\n    y = data[\"fraction_recovered\"]\n    X_train, X_valid, y_train, y_valid = (\n        train_test_split(X, y, test_size=0.2, random_state=0)\n        if validate\n        else (X, None, y, None)\n    )\n\n    transformer = DataFrameMapper(\n        [\n            (onehot_cols, OneHotEncoder(drop=\"if_binary\")),\n            (\n                list(ordinal_cols.keys()),\n                OrdinalEncoder(categories=list(ordinal_cols.values())),\n            ),\n        ],\n        default=StandardScaler(),\n    )\n\n    X_train = transformer.fit_transform(X_train)\n    X_valid = transformer.transform(X_valid) if validate else None\n\n    input_nodes = X_train.shape[1]\n    output_nodes = 1\n\n    model = Sequential()\n    model.add(Input((input_nodes,)))\n    model.add(Dense(64, activation=\"relu\"))\n    model.add(Dropout(0.3, seed=0))\n    model.add(Dense(32, activation=\"relu\"))\n    model.add(Dropout(0.3, seed=1))\n    model.add(Dense(16, activation=\"relu\"))\n    model.add(Dropout(0.3, seed=2))\n    model.add(Dense(output_nodes))\n    model.compile(optimizer=\"adam\", loss=\"mean_squared_logarithmic_error\")\n\n    history = model.fit(\n        X_train,\n        y_train,\n        batch_size=batch_size,\n        epochs=100,\n        validation_data=(X_valid, y_valid) if validate else None,\n        verbose=2,\n    )\n\n    return history.history, model, transformer\n\n\nonehot_cols = [\"term\", \"application_type\", \"home_ownership\", \"purpose\"]\nordinal_cols = {\n    \"emp_length\": [\n        \"< 1 year\",\n        \"1 year\",\n        \"2 years\",\n        \"3 years\",\n        \"4 years\",\n        \"5 years\",\n        \"6 years\",\n        \"7 years\",\n        \"8 years\",\n        \"9 years\",\n        \"10+ years\",\n    ]\n}","817ce91c":"# Train the model\n_, model, transformer = run_pipeline(\n    train.drop(columns=[\"issue_d\", \"date\", \"grade\", \"sub_grade\", \"expected_return\"]),\n    onehot_cols,\n    ordinal_cols,\n    batch_size=128,\n    validate=False,\n)\n\n# Make predictions\nX_test = transformer.transform(\n    test.drop(\n        columns=[\n            \"fraction_recovered\",\n            \"issue_d\",\n            \"date\",\n            \"grade\",\n            \"sub_grade\",\n            \"expected_return\",\n        ]\n    )\n)\ntest[\"model_predictions\"] = model.predict(X_test)\n\n# Gather top predictions\ntest_sorted = test.sort_values(\"model_predictions\", axis=\"index\", ascending=False)\nty_grade_a = test_sorted.iloc[0:len(lc_grade_a)]\n\n# Display results\nprint(\"\\nAverage `fraction_recovered` on Ty's grade A loans:\")\nprint(format(mean(ty_grade_a[\"fraction_recovered\"]), \".5f\"))","ec7ea273":"## Victory!\n\nPhew, that was a close one! My win might be too small to be statistically significant, but hey, it's cool seeing that I can keep up with LendingClub's best and brightest.\n\n## Further reading\n\n- [Natural Language Processing for Loan Risk](https:\/\/www.kaggle.com\/tywmick\/natural-language-processing-for-loan-risk)\n\n-----\n\nWhat I'd really like to know now is what quantitative range of estimated risk each LendingClub grade and sub-grade corresponds to, but it looks like [that's proprietary](https:\/\/www.lendingclub.com\/foliofn\/rateDetail.action). Does anyone know if loans grades generally correspond to certain percentage ranges like letter grades in academic classes? If not, have any ideas for better benchmarks I could use to evaluate my model's performance? Go ahead and chime in in the comments below.","44d4b09d":"<div style=\"font-size: 16px; font-weight: 500; line-height: 1.4; font-style: italic; margin-bottom: 1em;\">\n  Pitting My Neural Network Against a Corporate Benchmark\n<\/div>\n\n1. **[Introduction](#Introduction)**\n2. **[Ground rules](#Ground-rules)**\n3. **[Test metric](#Test-metric)**\n4. **[LendingClub's turn](#LendingClub's-turn)**\n5. **[My turn](#My-turn)**\n6. **[Victory!](#Victory!)**\n7. **[Further reading](#Further-reading)**\n\n## Introduction\n\nIn case you missed it, I [built a neural network to predict loan risk](https:\/\/www.kaggle.com\/tywmick\/building-a-neural-network-to-predict-loan-risk) using a [public dataset](https:\/\/www.kaggle.com\/wordsforthewise\/lending-club) from [LendingClub](https:\/\/www.lendingclub.com\/). Then I built a [public API](https:\/\/tywmick.pythonanywhere.com\/) to serve the model's predictions. That's nice and all, but&hellip; how _good_ is my model?\n\nToday I'm going to put it to the test, pitting it against the risk models of the very institution who issued those loans. That's right, LendingClub included their own calculated loan grades (and sub-grades) in the dataset, so all the pieces are in place for the most thrilling risk modeling smackdown of the ~~century~~ week. May the best algorithm win!","41907f24":"## Ground rules\n\nThis is going to be a clean fight\u2014my model won't use any data LendingClub wouldn't have access to at the point they calculate a loan's grade (including the grade itself).\n\nI'm going to sort the dataset chronologically (using the `issue_d` column, the month and year the loan was issued) and split it into two parts. The first 80% I'll use for training my competition model, and I'll compare performance on the last 20%.","faa4f365":"That's a pretty high percentage. I'm a bit nervous.\n\n## My turn\n\nFirst, I'll copy over my `run_pipeline` function from [my previous notebook](https:\/\/www.kaggle.com\/tywmick\/building-a-neural-network-to-predict-loan-risk#Building-the-neural-networks). I'll hide the input here since it isn't new information, but feel free to take a peek by clicking the \"Input\" button.","76eca353":"At the earlier end of the test set my model may have a slight informational advantage, having been trained on a few loans that may not have closed yet at the point LendingClub was grading those ones. On the other hand, LendingClub may have a slight informational advantage on the later end of the test set, since they would have known the outcomes of some loans on the earlier end of the test set by that time.\n\nI have to give credit to Michael Wurm, by the way, for [the idea](https:\/\/towardsdatascience.com\/intelligent-loan-selection-for-peer-to-peer-lending-575dfa2573cb#fac8) of comparing my model's performance to LendingClub's loan grades, but my approach is pretty different. I'm not trying to simulate the performance of an investment portfolio; I'm just evaluating how well my predictions of simple risk compare.\n\n## Test metric\n\nThe test: who can pick the best set of grade A loans, judged on the basis of the independent variable from [my last notebook](https:\/\/www.kaggle.com\/tywmick\/building-a-neural-network-to-predict-loan-risk), the fraction of an expected loan return that a prospective borrower will pay back (which I engineered as `fraction_recovered`).\n\nLendingClub will take the plate first. I'll gather all their grade A loans from the test set, count them, and calculate their average `fraction_recovered`. That average will be the metric my model has to beat.\n\nThen I'll train my model on the training set using the same [pipeline and parameters](https:\/\/www.kaggle.com\/tywmick\/building-a-neural-network-to-predict-loan-risk#Building-the-neural-networks) I settled on in my last notebook. Once it's trained, I'll use it to make predictions on the test set, then gather the number of top predictions equal to the number of LendingClub's grade A loans. Finally, I'll calculate the same average of `fraction_recovered` on that subset, and we'll have ourselves a winner!\n\n## LendingClub's turn"}}