{"cell_type":{"42fc0a7c":"code","30a00cdc":"code","6c34640e":"code","8db0e4ce":"code","d2a6c4f4":"code","9af0dab5":"code","50d820c1":"code","da2e879c":"code","1e99ae56":"code","552cd270":"code","f77092d5":"code","f317528e":"code","07d84186":"code","9963eddb":"code","2e543375":"code","b9b7cbcf":"code","3978e04c":"markdown","77067f5e":"markdown","a0ac4127":"markdown","c01a8731":"markdown","ee228c4c":"markdown","b99a7f0b":"markdown","e10f1c9b":"markdown","5d33d2a3":"markdown","37ec267f":"markdown","af3b3361":"markdown","898b2c96":"markdown"},"source":{"42fc0a7c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom numbers import Real\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import preprocessing\nfrom sklearn import ensemble\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom sklearn import decomposition\nfrom sklearn import preprocessing\nfrom functools import partial\nimport optuna\nfrom skopt import space\nfrom skopt import gp_minimize \nfrom hyperopt import hp, fmin, tpe, Trials\nfrom hyperopt.pyll.base import scope\nfrom lightgbm import LGBMClassifier\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","30a00cdc":"train = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/train.csv')\nX_test = pd.read_csv(\"..\/input\/tabular-playground-series-oct-2021\/test.csv\")\nsample_solution = pd.read_csv(\"..\/input\/tabular-playground-series-oct-2021\/sample_submission.csv\")","6c34640e":"train.head()","8db0e4ce":"train.target.hist()","d2a6c4f4":"X_test.head()","9af0dab5":"train.isnull().sum()","50d820c1":"X_test.isnull().sum()","da2e879c":"print(train.shape)\nprint(X_test.shape)","1e99ae56":"y = train['target']\ntrain.pop('target')\ntrain.pop('id')\nX_test.pop('id')\nX=train\ndel train","552cd270":"print(X.shape)\nprint(X_test.shape)","f77092d5":"X.head()","f317528e":"\"\"\"def optimize(params, x, y):\n    \n    model = LGBMClassifier(**params)\n    kf = model_selection.StratifiedKFold(n_splits=5)\n    accuracies = []\n    for idx in kf.split(X=x, y = y):\n        train_idx, test_idx = idx[0], idx[1]\n      \n        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n\n        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n\n       \n        model.fit(X_train, y_train, eval_set = [(X_test, y_test)], \n                  early_stopping_rounds = 300, verbose = False)\n        \n        preds = model.predict_proba(X_test)[:,1]\n        fold_acc = metrics.roc_auc_score(y_test, preds)\n        accuracies.append(fold_acc)\n        \n    return -1.0*np.mean(accuracies)\"\"\"","07d84186":"\"\"\"param_space = {\n        \"max_depth\": scope.int(hp.quniform(\"max_depth\", 3, 18, 1)),\n        \"n_estimators\": scope.int(hp.quniform(\"n_estimators\", 100, 600, 1)),\n        'min_child_weight' : scope.int(hp.quniform('min_child_weight', 0, 10, 1)),\n        'reg_alpha' : scope.int(hp.quniform('reg_alpha', 40,180,1)),\n        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n        \n        'random_state':42,\n    }\n        \noptimization_function = partial(optimize,  x = X, y = y)\n\ntrials = Trials()\n\nresult = fmin(\n        fn = optimization_function,\n        space = param_space,\n        algo = tpe.suggest, \n        max_evals = 15,\n        trials = trials, \n    )\nprint(result)\"\"\"\n","9963eddb":"params_lgbm =  {\n        'boosting_type': 'gbdt',\n        \"max_depth\": 16,\n        \"n_estimators\": 576,\n        'min_child_weight' : 6,\n        'reg_alpha' : 78.0,\n        'reg_lambda' : 0.7199,\n        'colsample_bytree' : 0.863,\n        'random_state' : 42,\n        'n_jobs': -1,\n        'metric': 'AUC',\n        'verbosity': -1,\n    }\nfolds = model_selection.StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True)\ny_pred = np.zeros(len(X_test))\nscores = []\nfor fold, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n    \n    X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n    y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n    model = LGBMClassifier(**params_lgbm)\n   \n    model.fit(X_train, y_train, eval_set = [(X_val, y_val)], verbose = False, early_stopping_rounds = 300)\n    \n    final_preds = model.predict_proba(X_val)[:,1]\n    fold_score = metrics.roc_auc_score(y_val, final_preds)\n    scores.append(fold_score)\n    y_pred += model.predict_proba(X_test)[:,1] \/ folds.n_splits \n\nprint(scores)","2e543375":"sample_solution.head()","b9b7cbcf":"sample_solution['target'] = y_pred\nsample_solution.to_csv('Submission.csv',index = False)\n","3978e04c":"## Importing important libraries","77067f5e":"### Results obtained from Hyperparameter Tuning using hyperopt with accuracy 0.854 are given as under:\n{'colsample_bytree': 0.8637743391307819, \n 'max_depth': 16.0, 'min_child_weight': 6.0, \n 'n_estimators': 576.0, 'reg_alpha': 78.0, \n 'reg_lambda': 0.7199776533647606}","a0ac4127":"## Checking Null values, if any, in both training and testing data","c01a8731":"There are no null values in both the training data and the testing data","ee228c4c":"The above graph of the target column data shows that the problem is of classification. A classification regression is suitable to predict. ","b99a7f0b":"### Important note\nThe following cell can be uncommented to run the hyperparameter tunning process which fmin function and defining the parameters for model","e10f1c9b":"## Hyperparameter Tuning begins here\n### Important note\nThe following cell can be uncommented to run the hyperparameter tunning process which uses hyperopt method","5d33d2a3":"## Performing 5 fold cross validation using LGBMClassifier","37ec267f":"## Dividing dependent and independent variables and adding new features\nIt can be seen that columns like \"Id\" are unique, hence wont contribute for our predictions. Therefore, these must be removed from both training and testing datasets.","af3b3361":"## Reading the train and test datasets","898b2c96":"### Final Submission"}}