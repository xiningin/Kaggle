{"cell_type":{"2a287bc9":"code","5ec1fe49":"code","7dc5b537":"code","ed364caf":"code","9802223f":"code","b3a9fa4c":"code","ce036c21":"code","75be2425":"code","413e9e6f":"code","576aa272":"code","b68ea9b3":"code","e5c83e97":"code","1f521d58":"code","e4777db3":"code","e5193223":"code","f693456f":"code","dee62246":"code","aea38003":"code","64f08391":"code","ff243541":"code","83aa2fe5":"code","b70fd7e8":"code","2de1dd61":"code","d55a7c29":"code","b7da0be8":"code","383dcfd4":"code","a5bbd858":"code","a29c49fe":"markdown","c5f86876":"markdown","b9d9b493":"markdown","be44eecc":"markdown","8b7dd62a":"markdown","ef0e55b2":"markdown","2e2b9e90":"markdown","bdb559d6":"markdown"},"source":{"2a287bc9":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import mean_squared_error\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.width', 1500)\npd.set_option('display.float_format', lambda x: '%.3f' % x)","5ec1fe49":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7dc5b537":"df = pd.read_csv(\"\/kaggle\/input\/hitters\/Hitters.csv\")","ed364caf":"def check_df(dataframe, head=5, tail=3):\n    print(\"######################## Shape ########################\\n\")\n    print(dataframe.shape)\n    print(\"######################## Types ########################\\n\")\n    print(dataframe.dtypes)\n    print(\"######################## Head ########################\\n\")\n    print(dataframe.head(head))\n    print(\"######################## Tail ########################\\n\")\n    print(dataframe.tail(tail))\n    print(\"######################## NA ########################\\n\")\n    print(dataframe.isnull().sum())\n    print(\"\\n\\n######################## Quantiles ########################\\n\")\n    print(dataframe.describe([0.05, 0.50, 0.75, 0.95, 0.99]).T)\n\ncheck_df(df)","9802223f":"# As we see, Salary feature has some missing values.\n# Here I want to seperate these players, who has no salary information and at final we can predict their salaries with model.\n# Before Modelling we are gonna seperate them like as below.\n\n# df_test = df[df[\"Salary\"].isnull()]   # test\n# df = df[~df[\"Salary\"].isnull()]       # train","b3a9fa4c":"def grab_col_names(dataframe, cat_th=10, car_th=20):\n    \"\"\"\n\n    Veri setindeki kategorik, numerik ve kategorik fakat kardinal de\u011fi\u015fkenlerin isimlerini verir.\n    Not: Kategorik de\u011fi\u015fkenlerin i\u00e7erisine numerik g\u00f6r\u00fcn\u00fcml\u00fc kategorik de\u011fi\u015fkenler de dahildir.\n\n    Parameters\n    ------\n        dataframe: dataframe\n                De\u011fi\u015fken isimleri al\u0131nmak istenilen dataframe\n        cat_th: int, optional\n                numerik fakat kategorik olan de\u011fi\u015fkenler i\u00e7in s\u0131n\u0131f e\u015fik de\u011feri\n        car_th: int, optional\n                kategorik fakat kardinal de\u011fi\u015fkenler i\u00e7in s\u0131n\u0131f e\u015fik de\u011feri\n\n    Returns\n    ------\n        cat_cols: list\n                Kategorik de\u011fi\u015fken listesi\n        num_cols: list\n                Numerik de\u011fi\u015fken listesi\n        cat_but_car: list\n                Kategorik g\u00f6r\u00fcn\u00fcml\u00fc kardinal de\u011fi\u015fken listesi\n\n    Examples\n    ------\n        import seaborn as sns\n        df = sns.load_dataset(\"iris\")\n        print(grab_col_names(df))\n\n\n    Notes\n    ------\n        cat_cols + num_cols + cat_but_car = toplam de\u011fi\u015fken say\u0131s\u0131\n        num_but_cat cat_cols'un i\u00e7erisinde.\n\n    \"\"\"\n\n    # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n\n    cat_cols = cat_cols + num_but_cat\n\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n\n    return cat_cols, num_cols, cat_but_car\n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)","ce036c21":"def cat_summary(dataframe, col_name, plot=False):\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() \/ len(dataframe)}))\n    print(\"##########################################\", end = \"\\n\\n\")\n    if plot:\n        plt.figure(figsize=[5, 5])\n        sns.countplot(x=dataframe[col_name], data=dataframe)\n        plt.show()\n\nfor col in cat_cols:\n    cat_summary(df, col, True)","75be2425":"# Checking outliers...\n\ndef outlier_thresholds(dataframe, col_name, q1=0.05, q3=0.95):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit","413e9e6f":"def check_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False\n    \nfor col in num_cols:\n    print(col, check_outlier(df, col))","576aa272":"# Checking correlation...\n\ndef correlation_sum(dataframe, up_limit = 0.65, down_limit = -0.65, plot=False):\n    corr_df = df.corr()\n\n    if plot:\n        plt.figure(figsize=[18, 18])\n        sns.heatmap(corr_df, annot=True, xticklabels=corr_df.columns, yticklabels=corr_df.columns)\n        plt.show()\n\n    corr_df = dataframe.corr()\n    corr_df = corr_df.corr().unstack().sort_values().drop_duplicates()\n    corr_df = pd.DataFrame(corr_df, columns=[\"corr\"])\n    corr_df.index.names = ['1', '2']\n    corr_df = corr_df.reset_index()\n    high_corr = corr_df[(corr_df[\"corr\"] >= up_limit) | (corr_df[\"corr\"] <= down_limit)]\n\n    return high_corr\n\ncorrelation_sum(df, 0.85, -0.85, True)","b68ea9b3":"num_cols = [col for col in num_cols if col not in [\"Salary\", \"Years\"]]\ndf[num_cols] = df[num_cols] + 1\n\n# Percentages by Hits\ndf[\"New_Hits\/AtBat\"] = df[\"Hits\"] \/ df[\"AtBat\"]\ndf[\"New_HmRun\/Hits\"] = df[\"HmRun\"] \/ df[\"Hits\"]\ndf[\"New_Runs\/Hits\"] = df[\"Runs\"] \/ df[\"Hits\"]\ndf[\"New_RBI\/Hits\"] = df[\"RBI\"] \/ df[\"Hits\"]\n\ndf[\"New_CHits\/CAtBat\"] = df[\"CHits\"] \/ df[\"CAtBat\"]\ndf[\"New_CHmRun\/CHits\"] = df[\"CHmRun\"] \/ df[\"CHits\"]\ndf[\"New_CRuns\/CHits\"] = df[\"CRuns\"] \/ df[\"CHits\"]\ndf[\"New_CRBI\/CHits\"] = df[\"CRBI\"] \/ df[\"CHits\"]\n\n# Career average statistics\ndf[\"New_CAtBat_mean\"] = df[\"CAtBat\"]\/df[\"Years\"]\ndf[\"New_CHits_mean\"] = df[\"CHits\"]\/df[\"Years\"]\ndf[\"New_CHmRun_mean\"] = df[\"CHmRun\"]\/df[\"Years\"]\ndf[\"New_CRBI_mean\"] = df[\"CRBI\"]\/df[\"Years\"]\ndf[\"New_CWalks_mean\"] = df[\"CWalks\"]\/df[\"Years\"]\n\n# Players segmentation\ndf.loc[(df['Years'] < 4), 'New_Years_Cat'] = 'rookie'\ndf.loc[(df['Years'] >= 4) & (df['Years'] < 9), 'New_Years_Cat'] = 'pro'\ndf.loc[(df['Years'] >= 9) & (df['Years'] < 15), 'New_Years_Cat'] = 'experienced'\ndf.loc[(df['Years'] >= 15), 'New_Years_Cat'] = 'old'\n\n# Transfer situation\ndf.loc[(df[\"League\"] == \"A\") & (df[\"NewLeague\"] == \"N\"), 'New_League_Move'] = \"transfer_A_N\"\ndf.loc[(df[\"League\"] == \"N\") & (df[\"NewLeague\"] == \"A\"), 'New_League_Move'] = \"transfer_N_A\"\ndf.loc[(df[\"League\"] == \"A\") & (df[\"NewLeague\"] == \"A\"), 'New_League_Move'] = \"stayed_A\"\ndf.loc[(df[\"League\"] == \"N\") & (df[\"NewLeague\"] == \"N\"), 'New_League_Move'] = \"stayed_N\"\n\n# Benefits ans Loss\ndf[\"New_Errors\/Walks\"] = df[\"Errors\"] \/ df[\"Walks\"]\ndf[\"New_Benefit_Loss\"] = df[\"Assists\"] + df[\"PutOuts\"] + df[\"Walks\"] - df[\"Errors\"]\n\n# Advanced statistics\ndf[\"New_OBP\"] = (df[\"Hits\"] + df[\"Walks\"] + (df[\"Hits\"]\/df[\"AtBat\"])) \/ (df[\"AtBat\"]+df[\"Walks\"]+(df[\"Hits\"]\/df[\"AtBat\"])+(df[\"RBI\"]-df[\"Runs\"]))\ndf[\"New_COBP\"] = (df[\"CHits\"] + df[\"CWalks\"] + (df[\"CHits\"]\/df[\"CAtBat\"])) \/ (df[\"CAtBat\"]+df[\"CWalks\"]+(df[\"CHits\"]\/df[\"CAtBat\"])+(df[\"CRBI\"]-df[\"CRuns\"]))\ndf[\"New_SLG\"] = ((4*df[\"HmRun\"]) + df[\"Runs\"])\/df[\"AtBat\"]\ndf[\"New_CSLG\"] = ((4*df[\"CHmRun\"]) + df[\"CRuns\"])\/df[\"CAtBat\"]\ndf[\"New_COPS\"] = df[\"New_COBP\"] + df[\"New_CSLG\"]\ndf[\"BABIP\"] = (df[\"Hits\"] - df[\"HmRun\"]) \/ (df[\"AtBat\"] - df[\"HmRun\"] - df[\"Errors\"] + (df[\"RBI\"]-df[\"Runs\"]))\ndf[\"New_ERA\"] = df[\"Runs\"] \/ ((df[\"Walks\"]\/df[\"Hits\"]) * 9)\ndf[\"New_CERA\"] = (df[\"CRuns\"] \/ (df[\"CWalks\"]\/df[\"CHits\"])) * 9\ndf[\"New_WHIP\"] = (df[\"Walks\"] + df[\"Hits\"]) \/ (df[\"Walks\"] \/ df[\"Hits\"])\ndf[\"New_CWHIP\"] = (df[\"CWalks\"] + df[\"CHits\"]) \/ (df[\"CWalks\"] \/ df[\"CHits\"])","e5c83e97":"# We got more columns :)\ndf.shape","1f521d58":"cat_cols, num_cols, cat_but_car = grab_col_names(df)","e4777db3":"# Checking quickly categoric columns by Salary \n\ndef rating_summary(dataframe, col, target):\n    print(dataframe.groupby(col)[target].mean())\n    print(\"################################\", end=\"\\n\\n\")\n    \nfor col in cat_cols:\n    rating_summary(df, col, \"Salary\")","e5193223":"# One Hot Encoding\n\ndef one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n    return dataframe\n\ndf = one_hot_encoder(df, cat_cols, True)","f693456f":"cat_cols, num_cols, cat_but_car = grab_col_names(df)","dee62246":"num_cols = [col for col in num_cols if \"Salary\" not in col]","aea38003":"# Standard Scaler\n\nss = StandardScaler()\ndf[num_cols] = ss.fit_transform(df[num_cols])","64f08391":"# Seperate who has no information about Salary\n\ndf_test = df[df[\"Salary\"].isnull()]   # test\ndf = df[~df[\"Salary\"].isnull()]       # train","ff243541":"# Linear Regression\n\ny=df[\"Salary\"]\nX=df.drop([\"Salary\", \"CAtBat\", \"CHits\", \"CHmRun\", \"CRuns\", \"CRBI\", \"CWalks\"], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=11)\nreg_model = LinearRegression()\nreg_model.fit(X_train, y_train)","83aa2fe5":"# Train scores\n\ny_pred = reg_model.predict(X_train)\nprint(f\" Train RMSE:  {np.sqrt(mean_squared_error(y_train, y_pred)):.4f}\")\nprint(f\" Train R2:  {reg_model.score(X_train, y_train):.4f}\")","b70fd7e8":"# Test scores\n\ny_pred = reg_model.predict(X_test)\nprint(f\" Test RMSE:  {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\nprint(f\" Test R2:  {reg_model.score(X_test, y_test):.4f}\")","2de1dd61":"# K-Fold Cross Validation\ncv_score = np.mean(np.sqrt(-cross_val_score(reg_model, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\nprint(f\" Score with CV:  {cv_score:.4f}\")","d55a7c29":"# Variable Importance\n\nno_effect_list = [\"Salary\", \"CAtBat\", \"CHits\", \"CHmRun\", \"CRuns\", \"CRBI\", \"CWalks\"]\n\ndef variable_importance(dataframe, model, print=False, plot=False):\n    df_col_names = [col for col in dataframe.columns if col not in no_effect_list]\n    df_col_scores = [i for i in np.absolute(model.coef_)]\n    df_col_names = pd.DataFrame(df_col_names, columns=[\"Feature\"])\n    df_col_scores = pd.DataFrame(df_col_scores, columns=[\"Score\"])\n    new_df = pd.concat([df_col_names, df_col_scores], axis=1)\n    new_df = new_df.sort_values(by=\"Score\", ascending=False)\n    if print:\n        for i in new_df.index:\n            print(f\"{new_df.values[i][0]} variable's score is: {new_df.values[i][1]:.4f}\")\n    if plot:\n        feature_imp = pd.DataFrame({\"Value\": new_df.Score.tolist(), \"Feature\": new_df.Feature.tolist()})\n        plt.figure(figsize=(12, 12))\n        sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp)\n        plt.title(\"Variable Importance Plot Map\")\n        plt.grid(axis=\"x\")\n        plt.tight_layout()\n        plt.show()\n        \nvariable_importance(df, reg_model, False, True)","b7da0be8":"# Let's look at our dataset with no salaries...\n\ndf_test = df_test.drop(no_effect_list, axis=1)\ndf_test.head()","383dcfd4":"# Predict the salaries...\n\ndf_test[\"Salary\"] = reg_model.predict(df_test)","a5bbd858":"df_test.head()","a29c49fe":"<hr style=\"height:2px;border-width:0;color:white;background-color:green\">\n\n# Modelling","c5f86876":"<hr style=\"height:2px;border-width:0;color:white;background-color:green\">\n\n# Dataset Preprocessing","b9d9b493":"<hr style=\"height:2px;border-width:0;color:white;background-color:green\">\n\n# Feature Engineering","be44eecc":"<hr style=\"height:2px;border-width:0;color:white;background-color:green\">\n\n# Salary Predict with Model","8b7dd62a":"#### Note: There are a lot of high correlation features but I don't want to drop some feature at that moment. We need all feature, because for the feature engineering all statistics can be useful. Let's begin create features...","ef0e55b2":"#### Some players have to pay to their club, because they play really bad :)<br> Which salary negative is, it should be checked again...","2e2b9e90":"# Dataset\n\n#### *Dataset: Hitters*\n#### *Sport Art: Baseball*\n#### *Description: We have some baseball players with their season '86 and also career statistics. And the most important data for the dataset, Salary is from Sports Illustrated.<br> Steps are gonna be like this: Firstly, we check the dataset if there is missing values or some outliers. And then we create some features.<br> Modelling part is gonna be with Linear Regression and we get the Test, Train scores.<br> At the end with our Model we try to predict salaries from baseball players, that they have no information about their salaries.*<br>\n\n##### *Columns of Dataset:*\n\n* ***AtBat:*** Number of times at bat in 1986\n* ***Hits:*** Number of hits in 1986\n* ***HmRun:*** Number of home runs in 1986\n* ***Runs:*** Number of runs in 1986\n* ***RBI:*** Number of runs batted in in 1986\n* ***Walks:*** Number of walks in 1986\n* ***Years:*** Number of years in the major leagues\n* ***CAtBat:*** Number of times at bat during his career\n* ***CHits:*** Number of hits during his career\n* ***CHmRun:*** Number of home runs during his career\n* ***CRuns:*** Number of runs during his career\n* ***CRBI:*** Number of runs batted in during his career\n* ***CWalks:*** Number of walks during his career\n* ***League:*** A factor with levels A and N indicating player\u2019s league at the end of 1986\n* ***Division:*** A factor with levels E and W indicating player\u2019s division at the end of 1986\n* ***PutOuts:*** Number of put outs in 1986\n* ***Assists:*** Number of assists in 1986\n* ***Errors:*** Number of errors in 1986\n* ***Salary:*** 1987 annual salary on opening day in thousands of dollars\n* ***NewLeague:*** A factor with levels A and N indicating player\u2019s league at the beginning of 1987","bdb559d6":"<hr style=\"height:2px;border-width:0;color:white;background-color:green\">\n\n# Import Dataset & Libraries"}}