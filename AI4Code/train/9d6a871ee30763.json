{"cell_type":{"5eccc8a2":"code","84b448c6":"code","c5a92039":"code","ddb94725":"code","5978d13c":"code","45cfd5e6":"code","20df2b4d":"code","e36ea07e":"code","575dff3f":"code","def65bba":"code","ad003e98":"code","a52d9b5e":"code","b9509939":"code","f01f4aff":"code","2ac8e19e":"code","bfb6928a":"code","c524d45e":"code","81461f41":"markdown","6398f7cd":"markdown","0d83f675":"markdown"},"source":{"5eccc8a2":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"white\")\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","84b448c6":"train_data = pd.read_csv('\/kaggle\/input\/learn-together\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/learn-together\/test.csv')","c5a92039":"print (train_data.shape, test_data.shape)\nprint( 'data features')\nprint(train_data.dtypes.value_counts())\nprint( 'test_data features')\nprint(test_data.dtypes.value_counts())\nprint('Number of soils:',sum(['Soil' in column for column in train_data.columns]))\nprint('Number of Wilderness:',sum(['Wilderness' in column for column in train_data.columns]))\n","ddb94725":"train_data.head()","5978d13c":"#No nan values\ntrain_data.isna().sum()","45cfd5e6":"#Generate categorical features Soil and Wilderness_Area to improve the plots\ntrain_data[\"Soil\"] = np.nan\nfor n,col in enumerate(['Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n       'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n       'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n       'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']):\n    train_data.Soil[train_data[col] == 1] = n+1\n\ntrain_data[\"Wilderness_Area\"] = np.nan\nfor n,col in enumerate(['Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3','Wilderness_Area4']):\n    train_data.Wilderness_Area[train_data[col] == 1] = n+1\n    \ntest_data[\"Soil\"] = np.nan\nfor n,col in enumerate(['Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n       'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n       'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n       'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']):\n    test_data.Soil[test_data[col] == 1] = n+1\n\ntest_data[\"Wilderness_Area\"] = np.nan\nfor n,col in enumerate(['Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3','Wilderness_Area4']):\n    test_data.Wilderness_Area[test_data[col] == 1] = n+1","20df2b4d":"#change aspect feature\ndef Compass(row):\n    if row.Aspect < 45 or row.Aspect > 315:\n        return 1\n    elif row.Aspect < 135:\n        return 2\n    elif row.Aspect < 225:\n        return 3\n    else:\n        return 4\n    \ntrain_data['Compass'] = train_data.apply(Compass, axis='columns')\ntest_data['Compass'] = test_data.apply(Compass, axis='columns')","e36ea07e":"feature = \"Elevation\"\nsns.catplot(x=\"Cover_Type\", y=feature, kind=\"violin\", hue = 'Wilderness_Area',  data=train_data, height=7, aspect=3)\nplt.show()","575dff3f":"#Interesting features: 'Elevation' 'Soil' 'Wilderness_Area'\ng = sns.PairGrid(train_data[[\"Cover_Type\",'Elevation','Aspect','Soil','Wilderness_Area','Compass']])\ng.map(plt.scatter)","def65bba":"for n in range(1,8):\n    sns.distplot(train_data[train_data.Cover_Type == n].Hillshade_3pm)\nplt.legend()","ad003e98":"#We have the same amount of each type\ntrain_data.Cover_Type.value_counts()","a52d9b5e":"train_data.columns\ncolumns_v1 = ['Elevation', 'Aspect', 'Slope',\n       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points','Soil', 'Wilderness_Area']","b9509939":"train_data.columns","f01f4aff":"#Model with columns without modifications + Soil and Wilderness_Area with Compass\ninterest_columns = train_data.columns\ninterest_columns = interest_columns.drop(['Cover_Type','Id'])\n\nX = train_data[interest_columns]\ny = train_data.Cover_Type\nX_test = test_data[interest_columns]\nmy_model = RandomForestClassifier(n_estimators = 100, random_state=42)\nmy_model = RandomForestClassifier(n_estimators = 719,\n                                       max_features = 0.3,\n                                       max_depth = 464,\n                                       min_samples_split = 2,\n                                       min_samples_leaf = 1,\n                                       bootstrap = False,\n                                       random_state=42)\n\n#CrossValidation\nscores = cross_val_score(my_model, X, y, cv=5, scoring = 'accuracy')\nprint(scores)","2ac8e19e":"#first trial de predictions\nmy_model.fit(X,y)\npredictions = my_model.predict(X_test)\n\nmy_submission = pd.DataFrame({'Id': test_data.Id, 'Cover_Type': predictions})\nmy_submission.to_csv('submission.csv', index=False)","bfb6928a":"##PERMUTATION IMPORTANCE\nfrom sklearn.model_selection import train_test_split\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\nmy_model = RandomForestClassifier(random_state=1).fit(train_X, train_y)\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)\neli5.show_weights(perm, feature_names = val_X.columns.tolist())","c524d45e":"from matplotlib import pyplot as plt\nfrom pdpbox import pdp, get_dataset, info_plots\n\nfeatures_to_plot = ['Elevation', 'Wilderness_Area']\ninter1  =  pdp.pdp_interact(model=my_model, dataset=val_X, model_features=val_X.columns, features=features_to_plot)\n\npdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=features_to_plot, plot_type='contour', plot_pdp=True)\nplt.show()","81461f41":"#Model\n#Model with columns without modifications + Soil and Wilderness_Area\ninterest_columns = train_data.columns\ninterest_columns = interest_columns.drop(['Cover_Type','Id','Compass'])\n\nX = train_data[interest_columns]\ny = train_data.Cover_Type\nX_test = test_data[interest_columns]\nmy_model = RandomForestClassifier(n_estimators = 100, random_state=42)\nmy_model = RandomForestClassifier(n_estimators = 719,\n                                       max_features = 0.3,\n                                       max_depth = 464,\n                                       min_samples_split = 2,\n                                       min_samples_leaf = 1,\n                                       bootstrap = False,\n                                       random_state=42)\n\n#CrossValidation\nscores = cross_val_score(my_model, X, y, cv=5, scoring = 'accuracy')\nprint(scores)","6398f7cd":"#Meaby some strange zero values?\ntrain_data['Hillshade'] = (train_data.Hillshade_9am + train_data.Hillshade_Noon +train_data.Hillshade_3pm)\ng = sns.PairGrid(train_data[[\"Cover_Type\",'Hillshade_9am','Hillshade_Noon','Hillshade_3pm','Hillshade']])\ng.map(plt.scatter)","0d83f675":"train_data['Hillshade'] = (train_data.Hillshade_9am + train_data.Hillshade_Noon +train_data.Hillshade_3pm)\/3\nfor n in range(1,8):\n    sns.distplot(train_data[train_data.Cover_Type == n].Hillshade)\nplt.legend()\n\n#sns.distplot(train_data.Hillshade_9am)\n#sns.distplot(train_data.Hillshade_Noon)\n#sns.distplot(train_data.Hillshade_3pm)\n#sns.distplot((train_data.Hillshade_9am + train_data.Hillshade_Noon +train_data.Hillshade_3pm))"}}