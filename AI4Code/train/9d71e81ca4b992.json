{"cell_type":{"72059464":"code","35ccb280":"code","1611d13c":"code","582afc40":"code","b331f8ff":"code","5ec52403":"code","c9694f7a":"code","e6f9c9c7":"code","cc217ce0":"code","203c0dde":"code","b2be3d8a":"code","09ef19c5":"code","56fbf4cf":"code","42f7dfa5":"code","473b1ee2":"code","c496a2d4":"code","fe2e98f3":"code","d1b188e3":"code","0457bfa0":"code","17cb122f":"code","986a64f4":"code","82be6275":"code","50f4cc62":"code","f18dd994":"code","96e5f544":"code","1de87478":"code","73d109c0":"code","c541c3a0":"code","af9e5519":"code","776cf5d3":"code","261506bf":"code","358146e1":"code","ba2ed334":"code","322c71c2":"code","10d0356b":"code","bfdc2ac8":"code","adb7cb41":"code","d2627f20":"code","dd58d9b0":"code","be33d2ed":"code","ebcb48c3":"code","a127073b":"code","17f14ffc":"markdown","daf02b70":"markdown","ea54e80b":"markdown","e760a7d4":"markdown","2f786f22":"markdown","e9564a88":"markdown","c5d981bb":"markdown","505ea648":"markdown","aa87ee99":"markdown","eff9fdde":"markdown","f43e13d7":"markdown","e5ae1fda":"markdown","6102c7ed":"markdown","3e9ff374":"markdown","a2fd3d2f":"markdown","7e2ce8a7":"markdown","099c8603":"markdown","f53c1e95":"markdown"},"source":{"72059464":"import numpy as np\nimport pandas as pd","35ccb280":"# arquivo csv\nfile = \"https:\/\/raw.githubusercontent.com\/omairaasim\/machine_learning\/master\/project_9_predict_weight_sex\/weight-height.csv\"\n# lendo o arquivo csv - existem outras fun\u00e7\u00f5es reads para tipos diferentes\ndf = pd.read_csv(file)","1611d13c":"# listando os 5 primeiros registros do dataset\ndf.head()","582afc40":"# listando os 5 \u00faltimos registros do dataset\ndf.tail()","b331f8ff":"# listando os 5 registros aleat\u00f3rios do dataset\ndf.tail()","5ec52403":"# visualizando as informa\u00e7\u00f5es do dataset\ndf.info()","c9694f7a":"# e conhecendo estatisticamente\ndf.describe()","e6f9c9c7":"df['Gender'].describe()","cc217ce0":"# ou\ndf.describe(exclude='number')","203c0dde":"# detectando atributos com valores nulos\ndf.isnull().sum()","b2be3d8a":"# verificando se existem dados duplicados\nf'Existem {df.shape[0]} registros. {df.duplicated().sum()} est\u00e3o duplicados.'","09ef19c5":"# removendo dados duplicados\ndf = df.drop_duplicates()","56fbf4cf":"def remove_outlier(df_in, col_name):\n    q1 = df_in[col_name].quantile(0.25)\n    q3 = df_in[col_name].quantile(0.75)\n    iqr = q3-q1 #Interquartile range\n    fence_low  = q1-1.5*iqr\n    fence_high = q3+1.5*iqr\n    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n    return df_out","42f7dfa5":"dfo = remove_outlier(df, 'Weight')\ndf.shape, dfo.shape, f'Existem {len(df) - len(dfo)} linhas outliers'","473b1ee2":"dfo = remove_outlier(df, 'Height')\ndf.shape, dfo.shape, f'Existem {len(df) - len(dfo)} linhas outliers'","c496a2d4":"# biblioteca para gerar gr\u00e1fico\nimport matplotlib.pyplot as plt\n\n# criando um gr\u00e1fico de subplots, 1 linha e 1 colunas\nfig = plt.figure()\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\nax1.boxplot(df['Height'])\nax1.set_title('altura original')\n\nax2.boxplot(dfo['Height'])\nax2.set_title('altura ajustada ')\n\nplt.show()","fe2e98f3":"# exemplo b\u00e1sico para visualizar a correla\u00e7\u00e3o\ndfo.corr()","d1b188e3":"from sklearn.preprocessing import LabelEncoder\nenc = LabelEncoder()","0457bfa0":"dfo.head(2)","17cb122f":"dfo['idGender'] = enc.fit_transform(dfo['Gender'])\n# poder\u00edamos fazer tbm utilizando o pr\u00f3prio pandas\n# dfo['Gender'] = dfo['Gender'].apply(lambda x: 0 if x=='Male' else 1)","986a64f4":"dfo.head(2)","82be6275":"# vamos ver mais exemplos pra validar se male idGender == 1 sen\u00e3o 0 \ndfo.sample(5)","50f4cc62":"# vamos agora verificar a correla\u00e7\u00e3o das colunas idGender e Height,\n# com a vari\u00e1vel target Weight\ndfo.corr()","f18dd994":"# Fun\u00e7\u00e3o para selecionar dados de treino e teste\nfrom sklearn.model_selection import train_test_split","96e5f544":"X = dfo[['idGender', 'Height']] \ny = dfo['Weight'] # o kg \u00e9 o que iremos prever\n\n# separa 20% dos dados para teste\nXtreino, Xteste, ytreino, yteste = train_test_split(X, y, test_size=0.2, random_state=42)","1de87478":"# validando a estrutura dos dados de treino\nXtreino.shape, ytreino.shape","73d109c0":"# validando a estrutura dos dados de teste\nXteste.shape, yteste.shape","c541c3a0":"# ML Algoritmo\nfrom sklearn.linear_model import LinearRegression, Lasso, ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\n\nimport warnings\nwarnings.filterwarnings('ignore')","af9e5519":"alg = []\nscore = []\n# array de algoritmos de machine learning\nalgoritmos = [\n              LinearRegression(),       # 0\n              Lasso(),                  # 1\n              ElasticNet(),             # 2\n              DecisionTreeRegressor(),  # 3\n              RandomForestRegressor(),  # 4\n              SVR()                     # 5\n]\n# testando os algoritmos e detectando o melhor score\nfor regressor in algoritmos:\n    model = regressor\n    model.fit(Xtreino, ytreino)\n    s = round(model.score(Xtreino, ytreino), 2)\n    score.append(float(s))\n    alg.append(regressor)\n\nmelhorAlg = pd.DataFrame({'Regressor': alg, 'Score': score}).sort_values(by='Score', ascending=False)\nmelhorAlg","776cf5d3":"# treinar o modelo\nmodelo = melhorAlg['Regressor'][:1].values[0]\nmodelo.fit(Xtreino, ytreino)","261506bf":"# score do treino \nmodelo.score(Xtreino, ytreino)","358146e1":"# Vamos verificar algumas m\u00e9tricas comparando o resultado esperado e a previs\u00e3o\nfrom sklearn import metrics","ba2ed334":"# previsao com os dados de teste\nprevisao = modelo.predict(Xteste)","322c71c2":"import matplotlib.pyplot as plt \n\nx=range(0, len(Xteste))\nplt.plot(x, yteste, label='original')\nplt.plot(x, previsao, label='previs\u00e3o')\nplt.title(\"Plot yteste x previs\u00e3o\",fontsize=15)\nplt.xlabel(\"X\",fontsize=13)\nplt.ylabel(\"yteste e previs\u00e3o\",fontsize=13)\nplt.legend()","10d0356b":"# mean absolute error ou erro qudr\u00e1tico m\u00e9dio que corresponde ao valor esperado do erro\n# qto menor, melhor\nmae = metrics.mean_absolute_error(yteste, previsao)\nround(mae, 2)","bfdc2ac8":"# mean squared error ou erro qudr\u00e1tico m\u00e9dio que corresponde ao valor esperado do erro\n# para entender essa fun\u00e7\u00e3o execute as duas linhas abaixo comentada\n# se True, retorna MSE se FALSE RMSE\n# metrics.mean_squared_error([10, 10, 10], [1, 1, 1], squared=False)\n# metrics.mean_squared_error([10, 10, 10], [9, 9, 9], squared=False)\n\nmse = metrics.mean_squared_error(yteste, previsao, squared=False)\nrmse = metrics.mean_squared_error(yteste, previsao)\nf'MSE: {round(mse, 2)} - RMSE: {round(rmse, 2)}'","adb7cb41":"# r2 score ou coeficiente de determina\u00e7\u00e3o\n# melhor ponto desejado poss\u00edvel \u00e9 1\nr2 = metrics.r2_score(yteste, previsao)\nround(r2, 2)","d2627f20":"# dois exemplos de homens\nexM = Xteste[Xteste.idGender == 1].sample(3)\nexM['Weight'] = yteste[exM.index.values]\nexM","dd58d9b0":"# dois exemplos de mulheres\nexF = Xteste[Xteste.idGender == 0].sample(3)\nexF['Weight'] = yteste[exF.index.values]\nexF","be33d2ed":"# teste de previs\u00e3o\nsexoClass = ['feminino', 'masculino']\ndef predicaoPeso(sexo, a):\n  altura = a * 2.54\n  previsao = round(int(modelo.predict([[sexo, altura]])) * 0.453592, 2)\n  return f'A previs\u00e3o do peso para {sexoClass[sexo]} com altura de {a} cm \u00e9 de {previsao} kg'","ebcb48c3":"# mulher, digite a altura cent\u00edmetros 1 metro e 80 cms = 180\npredicaoPeso(0, 180)","a127073b":"predicaoPeso(1, 180)","17f14ffc":"# **Carregando Dados**\n\nInforma\u00e7\u00f5es do [dataset](https:\/\/raw.githubusercontent.com\/omairaasim\/machine_learning\/master\/project_9_predict_weight_sex\/weight-height.csv): \n```\n-  nome: Weight Height CSV\n-  criador: Omair Asim (github)\n```\n\n***Nome das 13 colunas:***\n```\n-  Gender: Male (masculino) e Female (feminino)\n-  Height: peso (inch)\n-  Weight: altura (lbm)\n```\n\n","daf02b70":"**Correla\u00e7\u00e3o**","ea54e80b":"# **Treinar o modelo**\n\nDe forma muito simples, vamos:\n\n- separar os dados de treinos e teste\n- detectar qual o algor\u00edtmo d\u00e1 o melhor score\n- treinar o modelo com os dados de treino\n- criar previs\u00e3o com os dados de testes\n- comparar os dados de previs\u00e3o com os dados de testes","e760a7d4":"**Detectando colunas com valores nulos**","2f786f22":"**Treinar o modelo**","e9564a88":"Se houvessem dados duplicados, utilize a fun\u00e7\u00e3o drop_duplicates()","c5d981bb":"# **AN\u00c1LISE EXPLORAT\u00d3RIA DE DADOS**","505ea648":"**Escolhendo um modelo**\n\nN\u00e3o entrando muito na teoria mas somente pra n\u00e3o ficar vago, como vamos analisar a rela\u00e7\u00e3o quantitativa entre 2 vari\u00e1veis, X (sexo e altura) e y (peso), irei demonstrar uma simples an\u00e1lise para escolher o melhor algor\u00edtmo. \n\nMas recomendo conhecer melhor outros algor\u00edtmos, entend\u00ea-los, pois pra cada situa\u00e7\u00e3o, um algor\u00edtmo pode gerar resultados melhores e, abaixo, tamb\u00e9m tem um mapa do scikit-learn orientando o melhor caminho para se seguir.\n\nSite [scikit-learn\/Linear-models](https:\/\/scikit-learn.org\/stable\/modules\/linear_model.html)","aa87ee99":"**Remover dados duplicados**","eff9fdde":"**Remover outliers**\n\nExemplo b\u00e1sico para remover outliers (extremos, desvios ou valores fora do padr\u00e3o)\n\nex.: idade vai de 14 a 290. Com certeza esse 290 foi um valor inputado de forma errada","f43e13d7":"Describe retorna estat\u00edsticas de cada coluna como contagem, m\u00e9dia, m\u00ednimo, m\u00e1ximo, etc. Mas percebam que a fun\u00e7\u00e3o .info() nos informa que h\u00e1 13 colunas por\u00e9m quando utilizamos a fun\u00e7\u00e3o .describe(), esta fun\u00e7\u00e3o retorna somente 9. O motivo disso \u00e9 que como n\u00e3o definimos o tipo de coluna na consulta .describe(), e por default ele retorna estat\u00edsticas somente das colunas num\u00e9ricas.\n\nPara gerar o describe em uma coluna ou em colunas n\u00e3o num\u00e9ricas, segue exemplos abaixo\n\n","e5ae1fda":"**Avaliando e gerando predi\u00e7\u00e3o**","6102c7ed":"# **Teste de Previs\u00e3o**\n\nVamos testar nosso modelo e para isso vou somente deixar 3 exemplos de informa\u00e7\u00e3o masculina e 3 feminina, mas altere o valor como desejar.\nImportante lembrar que:\n*INPUT*\n- sexo (idGender) ser\u00e1 0 para feminino e 1 para masculino\n- a altura est\u00e1 em inch\n\n*OUTPUT*\n- o peso ser\u00e1 o valor retornado (previs\u00e3o)","3e9ff374":"**Outras m\u00e9tricas**\n\nExistem algumas formas para avaliar a qualidade de um algor\u00edtmo estimador e eles est\u00e3o neste [link](https:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html). Nelas iremos utilizar o Y de teste e compar\u00e1-lo com a previs\u00e3o.\n\nEnt\u00e3o somente como uma dica, cuidado para o seu score de treino est\u00e1 alto (pr\u00f3ximo de 1) e o score dos dados de teste estar muito abaixo.","a2fd3d2f":"Nenhuma coluna possui valores nulos, mas se houvesse, existe a fun\u00e7\u00e3o \n.fillna(valor) para preencher alterar o valor nulo com um valor desej\u00e1vel, como o valor m\u00e9dio, m\u00e1ximo ou m\u00ednimo da coluna, por exemplo, usando as fun\u00e7\u00f5es   .mean(), .max() ou min(), ou mesmo setando com um valor pr\u00e9-definido, como 0 ou utilizando uma fun\u00e7\u00e3o customizada, criada pelo analista de dados.\n\nAlguns exemplos:\n\n\n```\ndf.coluna = df.coluna.fillna(0) => substitui o valor nulo por 0\n# ou\ndf.coluna = df.coluna.fillna(df.coluna.mean()) => substitui o valor nulo pelo valor m\u00e9dio da coluna\n```\n\n\n","7e2ce8a7":"Quando temos um dataset com muitas vari\u00e1veis, isso ajuda bastante o analista a identificar quais vari\u00e1veis features se correlacionam melhor com a vari\u00e1vel target. No nosso caso, as duas vari\u00e1veis se correlacionam positivamente com a vari\u00e1vel Weight.","099c8603":"# **Considera\u00e7\u00f5es finais**\n\nMeus amigos, a id\u00e9ia foi somente compartilhar uma forma de como podemos aplicar machine learning para nos ajudar a prever poss\u00edveis resultados de acordo com o problema exposto. \n\nLembre-se que a m\u00e1gica n\u00e3o existe, ent\u00e3o quanto mais expormos vari\u00e1veis (features) mas conseguiremos chegar a classe ou target desejado. Imagine se pudessemos ter nessa base informa\u00e7\u00f5es como pa\u00eds, etnia, se a pessoa pratica exerc\u00edcios, a altura dos pais, etc.\n\nValeu galera!!!","f53c1e95":"Veja que a coluna Gender n\u00e3o apareceu na correla\u00e7\u00e3o, porque ela \u00e9 uma coluna categ\u00f3rica. Vamos transformar os valors Male em 1 e Female em 0"}}