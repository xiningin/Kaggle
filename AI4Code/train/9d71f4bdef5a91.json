{"cell_type":{"0ebadd64":"code","4ca61dfd":"code","7ac56562":"code","18cf64f5":"code","64b1d80f":"code","899a669f":"code","6431b068":"code","87fdeb9f":"code","83e7e095":"code","5e4a70d9":"code","0b31e576":"code","81420cde":"code","d5a830c3":"code","44351ef6":"code","13b25a9f":"code","8a4ebcd9":"code","78ad14fc":"code","ac4e27f5":"code","c0ccf40f":"code","daeb866a":"code","f17e2f00":"code","665dae67":"code","7a0bce6b":"code","27f2b3a2":"code","36697ab0":"code","077e9282":"code","71cfaecc":"code","64fecfb3":"code","2c302a48":"code","a693a816":"code","a01e9725":"code","5bfca1d1":"markdown","8a657f73":"markdown","4f562679":"markdown","0e99ab78":"markdown","bd4f2436":"markdown","5263375a":"markdown","2ee2c742":"markdown","6c4ddf1d":"markdown","6979108e":"markdown","1dd29257":"markdown","7cccf503":"markdown","471a51f1":"markdown","a41d4633":"markdown","a827507a":"markdown","1c94c919":"markdown"},"source":{"0ebadd64":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom IPython.display import Markdown, display\nimport json\nfrom collections import Counter\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4ca61dfd":"#data set credits : https:\/\/www.kaggle.com\/xhlulu\/cord-19-eda-parse-json-and-generate-clean-csv\n#biorxiv_data = pd.read_csv('\/kaggle\/input\/cord-19-eda-parse-json-and-generate-clean-csv\/biorxiv_clean.csv')\n#clean_comm_data = pd.read_csv('\/kaggle\/input\/cord-19-eda-parse-json-and-generate-clean-csv\/clean_comm_use.csv')\n#clean_noncomm_data = pd.read_csv('\/kaggle\/input\/cord-19-eda-parse-json-and-generate-clean-csv\/clean_noncomm_use.csv')\n#clean_pmc_data = pd.read_csv('\/kaggle\/input\/cord-19-eda-parse-json-and-generate-clean-csv\/clean_pmc.csv')\n","7ac56562":"#all_data=pd.concat([biorxiv_data,clean_comm_data,clean_noncomm_data,clean_pmc_data],axis=0).dropna()\n#all_data.shape","18cf64f5":"#all_data.shape[0]","64b1d80f":"#all_data.head()","899a669f":"filenames_bio = os.listdir('\/kaggle\/input\/CORD-19-research-challenge\/biorxiv_medrxiv\/biorxiv_medrxiv\/')\nprint(\"Number of articles retrieved from biorxiv:\", len(filenames_bio))\nfilenames_comm = os.listdir('\/kaggle\/input\/CORD-19-research-challenge\/comm_use_subset\/comm_use_subset\/')\nprint(\"Number of articles retrieved from commercial use:\", len(filenames_comm))\nfilenames_custom = os.listdir('\/kaggle\/input\/CORD-19-research-challenge\/custom_license\/custom_license\/')\nprint(\"Number of articles retrieved from custom license:\", len(filenames_custom))\nfilenames_noncomm = os.listdir('\/kaggle\/input\/CORD-19-research-challenge\/noncomm_use_subset\/noncomm_use_subset\/')\nprint(\"Number of articles retrieved from non commercial:\", len(filenames_noncomm))\n","6431b068":"all_files = []\n\nfor filename in filenames_bio:\n    filename = '\/kaggle\/input\/CORD-19-research-challenge\/biorxiv_medrxiv\/biorxiv_medrxiv\/' + filename\n    file = json.load(open(filename, 'rb'))\n    all_files.append(file)\nfor filename in filenames_comm:\n    filename = '\/kaggle\/input\/CORD-19-research-challenge\/comm_use_subset\/comm_use_subset\/' + filename\n    file = json.load(open(filename, 'rb'))\n    all_files.append(file)\nfor filename in filenames_custom:\n    filename = '\/kaggle\/input\/CORD-19-research-challenge\/custom_license\/custom_license\/' + filename\n    file = json.load(open(filename, 'rb'))\n    all_files.append(file)\nfor filename in filenames_noncomm:\n    filename = '\/kaggle\/input\/CORD-19-research-challenge\/noncomm_use_subset\/noncomm_use_subset\/' + filename\n    file = json.load(open(filename, 'rb'))\n    all_files.append(file)\n    \n","87fdeb9f":"file = all_files[100]\nprint(\"Dictionary keys:\", file.keys())","83e7e095":"titles_list=[]\nfor  file in all_files: \n    for refs in file['bib_entries'].keys(): \n        titles_list.append(file['bib_entries'][refs][\"title\"]) ","5e4a70d9":"freqs = dict(Counter(titles_list))","0b31e576":"freqs_df=pd.DataFrame.from_dict(freqs,orient='index',columns=['freqs'])","81420cde":"freqs_df=freqs_df.sort_values(by='freqs',ascending=False)","d5a830c3":"freqs_df['title']=freqs_df.index","44351ef6":"metadata = pd.read_csv('\/kaggle\/input\/CORD-19-research-challenge\/metadata.csv')\n","13b25a9f":"metadata=metadata.merge(freqs_df,how='left',on='title',suffixes=(False,'_y'))","8a4ebcd9":"metadata=metadata.sort_values(by='freqs',ascending=False)","78ad14fc":"metadata=metadata.dropna(subset=['abstract']) ","ac4e27f5":"metadata.shape","c0ccf40f":"metadata.head()","daeb866a":"list(metadata.columns)","f17e2f00":"def what_do_we_know(match):\n    num=0\n    for abstract in metadata.iloc[:,8]:\n        matched=False\n        for terms in match: \n            if terms in abstract.lower() and \"covid\" in abstract.lower(): matched=True\n        if matched:\n            if np.isnan(metadata.iloc[num,17]): citations=\"NaN\" \n            else: citations=str(int(metadata.iloc[num,17]))\n            display(Markdown('<i> '+metadata.iloc[num,3]+'<\/i>'+' - '+citations+' citations'))\n            sentence3=\"<ul>\"\n            for sentence in abstract.split('. '):\n                sentence2=sentence.lower()\n                matched2=False\n                for terms in match: \n                    if terms in sentence2: \n                        matched2=True\n                        sentence2=sentence2.replace(terms, '<b>'+terms+'<\/b>')\n                if matched2: \n                 #   display(Markdown(\"> \"+sentence2))\n                    sentence3=sentence3+\"<li>\"+sentence2.replace(\"\\n\",\"\")+\"<\/li>\"\n            #sentence3=sentence3.replace(\"****\",\"\")\n            display(Markdown(sentence3+\"<\/ul>\"))       \n        #    display(Markdown(\"<sup>\"+abstract.replace(\"\\n\",\" \")+\"<\/sup>\"))\n        #print(num)\n        num+=1","665dae67":"# trial searches\nwhat_do_we_know([\"%\",\" higher than\",\" lower than\",\" key result\",\" equal to\",\" rate is\",\" rate was\",\" p-value\",\" estimated as\"])","7a0bce6b":"#what_do_we_know([\" smok\"])\n#what_do_we_know([\" pre-existing\"])","27f2b3a2":"#what_do_we_know([\" coinfections\",\" co-infections\",\" comorbidities\",\" co-morbidities\"])","36697ab0":"#what_do_we_know([\" neonat\"])\n#what_do_we_know([\" pregn\"])","077e9282":"#what_do_we_know([\" socioeconomic\",\" behavioural\"])\n#what_do_we_know([\" economic impact\"])","71cfaecc":"#what_do_we_know([\" reproductive number\"])\n#what_do_we_know([\" incubation period\"])\n#what_do_we_know([\" serial interval\"])\n#what_do_we_know([\" transmission\"])","64fecfb3":"#what_do_we_know([\" environmental factor\",\" environment factor\",\" environment risk\",\" food\",\" climate\",\" sanitation\"])","2c302a48":"#what_do_we_know([\" risk of fatality\",\" mortality\"])\n#what_do_we_know([\" hospitalized patients\"])\n#what_do_we_know([\" high-risk\",\" high risk\"])","a693a816":"#what_do_we_know([\" susceptibility\"])","a01e9725":"#what_do_we_know([\" mitigation measures\",\" social distan\",\" mass gathering\",\" quarantine\",\" lockdown\",\" lock-down\",\" containment\",\" shutdown\"])","5bfca1d1":"The following notebook is a *work in progress tool* to attempt to complete the tasks defined in the\n\n**COVID-19 Open Research Dataset Challenge (CORD-19)**\n\n* The results in the notebook are tailored to the task *\"What do we know about COVID-19 risk factors?\"* although the same methodology can be used to complete the other 9 tasks\n* At present the implementation is basically a deterministic sentence retrieval tool based on specified keywords (which have to be defined manually by the user, some trial and error is required) with no AI\/ML algorithms\n* Some domain knowledge is required to define appropriate key words. For example for \"mitigation measures\" it is appropriate to specify keywords such as \"social distan\",\" mass gathering\",\" quarantine\",\" lockdown\",\" lock-down\",\" containment\",\" shutdown\" rather than just look for \"mitigation measures\"\n* Only the text of the abstract is searched\n* Sentences retrieved are grouped by article with the specified keywords highighted\n* The idea is to just extract key results to be able to answer the different questions by further summarising (manually) the information in the extracted text\n* The final answers to the questions have not yet been drafted\n* Sentence retrieval is very useful for some keywords. For example looking at results <u>for mortality rates or reproductive numbers<\/u>, it is easy to find a signifcant number of reported rates and it wouldn't be too labour intensive to summarise the results quantitatively (histogram\/barplot)\n* In other cases (e.g. keyword pulmonary) the number of sentences retrieved is significant and there is no obvious quantitative measure associated with them\n* Possible improvements are:\n    * Including number of citations of the articles (as a simple gauge of the importance of result)\n    * A further NLP processing of the results to extract numerical quantities (percentages\/p-values)\n    * A more refined AI powered query algorithm","8a657f73":"# Co-infections and other co-morbidities","4f562679":"# Socio-economic and behavioral factors to understand the economic impact of the virus and whether there were differences.","0e99ab78":"# Susceptibility of populations","bd4f2436":"Define a function for retrieving sentences with provided keywords from the corpus of articles\nSentences are formatted as bullet points with relevant keywords in bold and ordered by source article (title in italics)\nA list of keywords can be provided for the same query as an input to the function (any match of a single keyword will return a sentence\nSentences are extracted by splitting text with the \".\" delimiter\nThere is also the option to retrieve the entire abstract (uncomment the line \ndisplay(Markdown(\"<sup>\"+all_data.iloc[num,4].replace(\"\\n\",\" \")+\"<\/sup>\"))","5263375a":"# Smoking, pre-existing pulmonary disease","2ee2c742":"# Transmission dynamics of the virus, including the basic reproductive number, incubation period, serial interval, modes of transmission and environmental factors","6c4ddf1d":"Now merge articles citations","6979108e":"Read metadata","1dd29257":"# Public health mitigation measures that could be effective for control","7cccf503":"# Extract all quantitative results","471a51f1":"Concatenate all dataframes containing the articles","a41d4633":"# Severity of disease, including risk of fatality among symptomatic hospitalized patients, and high-risk patient groups","a827507a":"# Neonates and pregnant women","1c94c919":"# What do we know about COVID-19 risk factors?"}}