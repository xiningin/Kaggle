{"cell_type":{"2acf3387":"code","318351fa":"code","33c41e87":"code","b130533a":"code","b9a1aa3b":"code","7e4227c2":"code","54b4759e":"code","09d58ebb":"code","baf59f09":"code","953504dc":"code","8d9d12c0":"code","236f54cf":"code","d09a5631":"code","af158f25":"code","03eb59c9":"code","4e59d552":"markdown","6179dad5":"markdown","8a62ef33":"markdown","19971792":"markdown","092d1565":"markdown","eedbb11d":"markdown","dc133a1a":"markdown","c85b0c6a":"markdown","d62d0bd8":"markdown"},"source":{"2acf3387":"import numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport tqdm\nfrom socket import socket","318351fa":"\nCATEGORIES = ['covid', 'healthy']\nDATADIR = '..\/input\/covidistesgp\/CovidDataset\/train'\nfor category in CATEGORIES:\n    path = os.path.join(DATADIR,category)\n    for img in os.listdir(path):\n        img_arr = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)   \n        plt.imshow(img_arr, cmap='gray')\n        plt.xlabel(category)\n        plt.show()\n        break","33c41e87":"IMG_SIZE=50\ntrain_data=[]\ntest_data=[]\n\ndef create_data(data_dir):\n    for category in CATEGORIES:\n        path=os.path.join(data_dir, category)\n        class_num=CATEGORIES.index(category)\n        \n        for img in (os.listdir(path)):                                             ## We use os to iterate over all our files in the directory \n            try:\n                img_arr=cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)   ## GRAYSCALING\n                img_arr=cv2.resize(img_arr, (IMG_SIZE,IMG_SIZE))                   ## RESIZING\n                if(data_dir=='..\/input\/covidistesgp\/CovidDataset\/train'):\n                    train_data.append([img_arr,class_num])\n                else:\n                    test_data.append([img_arr,class_num])\n            except exception as e:\n                pass","b130533a":"create_data('..\/input\/covidistesgp\/CovidDataset\/train')\ncreate_data('..\/input\/covidistesgp\/CovidDataset\/validation')\n\nprint(len(train_data))\nprint(len(test_data))","b9a1aa3b":"for sample in train_data[:10]:\n    print(sample[1])","7e4227c2":"import random\n\nrandom.shuffle(train_data)              ## Shuffling the dataset\n\nfor sample in train_data[:10]:\n    print(sample[1])","54b4759e":"x_train=[]\ny_train=[]\nx_test=[]\ny_test=[]\n\nfor features,label in train_data:\n    x_train.append(features)\n    y_train.append(label)\n    \nfor features,label in test_data:\n    x_test.append(features)\n    y_test.append(label)\n\nx_train = np.array(x_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)   ## reshaping the dataset to (length, 50, 50, 1)\nx_test = np.array(x_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n\nprint(len(x_train))\nprint(len(x_test))","09d58ebb":"import pickle\n\npickle_out_x_train = open(\"x_train.pickle\",\"wb\")          # open\/create a file called x_train.pickle, and write into it         \npickle.dump(x_train, pickle_out_x_train)                  # dump the contents of the np array\npickle_out_x_train.close()                                # close the file\n\npickle_out_y_train = open(\"y_train.pickle\",\"wb\")\npickle.dump(y_train, pickle_out_y_train)\npickle_out_y_train.close()\n\npickle_out_x_test = open(\"x_test.pickle\",\"wb\")\npickle.dump(x_test, pickle_out_x_test)\npickle_out_x_test.close()\n\npickle_out_y_test = open(\"y_test.pickle\",\"wb\")\npickle.dump(y_test, pickle_out_y_test)\npickle_out_y_test.close()\n\nprint(len(x_train))\nprint(len(x_test))","baf59f09":"pickle_in_x_train = open(\"x_train.pickle\",\"rb\")           # open the file\ntrainX = pickle.load(pickle_in_x_train)                   # load its contents into a python varriable\npickle_in_x_train.close()                                 # close the file\n\npickle_in_y_train = open(\"y_train.pickle\",\"rb\")\ntrainY = pickle.load(pickle_in_y_train)\npickle_in_y_train.close()\n\npickle_in_x_test = open(\"x_test.pickle\",\"rb\")\ntestX = pickle.load(pickle_in_x_test)\npickle_in_x_test.close()\n\npickle_in_y_test = open(\"y_test.pickle\",\"rb\")\ntestY = pickle.load(pickle_in_y_test)\npickle_in_y_test.close()\n\nprint(str(len(trainX)) + ', ' + str(len(testX)))","953504dc":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n\nprint(len(x_test))","8d9d12c0":"### NORMALIZE the data (trainX, trainY) from 0-255 to 0-1, and convert trainX,trainY,testX,testY to np arrays\n### approx. (1 x 4) lines of code\ntrainX = np.array(trainX)\ntrainY = np.array(trainY).reshape(-1, 1)\ntextX = np.array(testX)\ntestY = np.array(testY).reshape(-1, 1)\ntrainX = trainX \/ 255\ntestX = testX \/ 255\nprint(trainX.shape)\nprint(trainY.shape)\nprint(testX.shape)\nprint(testY.shape)\n\n\n\n\n\n","236f54cf":"model = Sequential()\n\n### Use model.add to add layers (example: conv2D layers, then Maxpooling2D layers, Dense)\n### Experiment with tf keras documentation to complete the model\n### approx 5-12 lines of code, feel free to experiment with different model structures\n\nmodel.add(Conv2D(filters=16, kernel_size=(6, 6), padding='same', activation='tanh', input_shape=(50, 50, 1)))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(filters=18, kernel_size=(5, 5), padding='same', activation='tanh'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(filters=22, kernel_size=(4, 4), padding='same', activation='tanh'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(filters=24, kernel_size=(4, 4), padding='same', activation='tanh'))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='tanh'))\nmodel.add(Dense(100, activation='tanh'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam', metrics=tf.keras.metrics.AUC())\nmodel.summary()","d09a5631":"model.fit(trainX, trainY, batch_size=32, epochs=5, validation_split=0.3)","af158f25":"score = model.evaluate(trainX, trainY, verbose = 1) \n\nprint('Train loss:', score[0]) \nprint('Train accuracy:', score[1])","03eb59c9":"score = model.evaluate(testX, testY, verbose = 0) \n\nprint('Test loss:', score[0]) \nprint('Test accuracy:', score[1])","4e59d552":"# Deep Learning SGP WEEK 3 Convolutional Neural Networks","6179dad5":"### Our dataset is visible on the top right of the screen. We have two categories for images (covid, healthy) for both 'train' and 'validation' folders","8a62ef33":"### Now we use a python library called openCV to read and perform some operations on the input data, such as GRAYSCALING and RESIZING","19971792":"### Now fill out the code in the below 2 cells following the instructions","092d1565":"### After we've done this preprocessing work, its handy to store our final array instead of repeating this everytime we want to use these values\n### For this, we use the python library called pickle to store all the values and load them in directly later","eedbb11d":"Expected: 2000, 200\n","dc133a1a":"#### Expected training accuracy 90-98% ","c85b0c6a":"### Its pretty important that we randomise our images rather than having all covid images together and all healthy images together","d62d0bd8":"#### Expected Test Accuracy 70-80%"}}