{"cell_type":{"e6ed9ab4":"code","1c64b5e4":"code","bfd8e22b":"code","7df2f4b8":"code","173b61d3":"code","430ee782":"code","91b0c454":"code","31ca07c5":"code","e53db73e":"code","f78ad927":"code","78fbe668":"code","9c3b7414":"code","d9e95390":"code","5695b8ca":"code","84a1943c":"code","cca8ff12":"code","9a72d0a7":"code","8dd8c577":"code","8ec5d39d":"code","fc3b6d94":"code","4d1422dd":"code","abb9e8f0":"code","a82e6400":"code","e424006e":"code","4863acf1":"code","567abf2a":"code","8f004298":"code","a7510244":"code","2d384a36":"code","3e5e337a":"code","4690e107":"code","2d26aa31":"code","2a85afb7":"code","43fa0915":"code","1afc8163":"markdown","fb6910a3":"markdown","9ce5df07":"markdown","17013a97":"markdown","4a39a029":"markdown","dad765a4":"markdown","e2f8eaa8":"markdown","7e95f1e2":"markdown","ac533375":"markdown"},"source":{"e6ed9ab4":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))\nimport matplotlib.pyplot as plt\nimport seaborn as sns","1c64b5e4":"# load the dataset\ndf = pd.read_csv('..\/input\/renfe.csv')\ndf.head(2)","bfd8e22b":"# let us clean the dataset \n# del unnamed it looks like a noise to the data\ndel df['Unnamed: 0']","7df2f4b8":"# validate the df \ndf.head(2)","173b61d3":"# validate the summary of the dataset \ndf.info()","430ee782":"# types of the train type \n\nplt.figure(figsize= (5,10))\nplt.subplot(311)\nplt.title('Train Class')\nplt.tight_layout()\nsns.countplot(y =df['train_class'])\n\nplt.subplot(312)\nplt.title('Train type')\nplt.tight_layout()\nsns.countplot(y = df['train_type'])\n\nplt.subplot(313)\nplt.title('fare type')\nplt.tight_layout()\nsns.countplot(y =df['fare'])\n\n","91b0c454":"# craete a dataset for uptime starting from MADRID\t\ndf_M = df[df['origin'] =='MADRID']\ndf_S = df[df['origin'] =='SEVILLA']\ndf_P = df[df['origin'] =='PONFERRADA']\ndf_B = df[df['origin'] =='BARCELONA']\ndf_V = df[df['origin'] =='VALENCIA']","31ca07c5":"df_M.info()","e53db73e":"# very high nan values \n# 13%  NaN - 183258\ndf_M.price.isna().sum()\nplt.figure(figsize=(5,5))\nplt.subplot(211)\ndf_M['price'].hist()\nplt.subplot(212)\nsns.boxplot(df_M['price'])\n\n# fillna with mean\ndf_M['price'].fillna(df_M['price'].mean(), inplace=True)\n\n#  Na is filled\ndf_M.price.isna().sum()","f78ad927":"# very high nan values \n# 13%  NaN - 21941\ndf_P.price.isna().sum()\nplt.figure(figsize=(5,5))\nplt.subplot(211)\ndf_P['price'].hist()\nplt.subplot(212)\nsns.boxplot(df_P['price'])\n\n# fillna with mean\ndf_P['price'].fillna(df_P['price'].mean(), inplace=True)\n\n#  Na is filled\ndf_P.price.isna().sum()","78fbe668":"# very high nan values \n# 13%  NaN - 88904\ndf_S.price.isna().sum()\n\nplt.figure(figsize=(5,5))\nplt.subplot(211)\ndf_S['price'].hist()\nplt.subplot(212)\nsns.boxplot(df_S['price'])\n\n\n# fillna with mean\ndf_S['price'].fillna(df_S['price'].mean(), inplace=True)\n\n#  Na is filled\ndf_S.price.isna().sum()","9c3b7414":"# very high nan values \n# 13%  NaN - 88904\ndf_B.price.isna().sum()\n\nplt.figure(figsize=(5,5))\nplt.subplot(211)\ndf_B['price'].hist()\nplt.subplot(212)\nsns.boxplot(df_B['price'])\n\n\n# fillna with mean\ndf_B['price'].fillna(df_B['price'].mean(), inplace=True)\n\n#  Na is filled\ndf_B.price.isna().sum()","d9e95390":"# very high nan values \n# 13%  NaN - 88904\ndf_V.price.isna().sum()\n\nplt.figure(figsize=(5,5))\nplt.subplot(211)\ndf_V['price'].hist()\nplt.subplot(212)\nsns.boxplot(df_V['price'])\n\n\n# fillna with mean\ndf_V['price'].fillna(df_V['price'].mean(), inplace=True)\n\n#  Na is filled\ndf_V.price.isna().sum()","5695b8ca":"# look on the first glance on the origin from Madrid\ndf_M.head()","84a1943c":"# types of the train type \n\nplt.figure(figsize= (5,12))\nplt.subplot(511)\nplt.title('Train Class')\nplt.tight_layout()\nsns.countplot(y =df_M['train_class'])\n\nplt.subplot(512)\nplt.title('Train type')\nplt.tight_layout()\nsns.countplot(y = df_M['train_type'])\n\nplt.subplot(513)\nplt.title('fare type')\nplt.tight_layout()\nsns.countplot(y =df_M['fare'])\n\nplt.subplot(514)\nplt.title('price ')\nplt.tight_layout()\nsns.boxplot(df_M['price'])\n\n\nplt.subplot(515)\nplt.title('destination ')\nplt.tight_layout()\nsns.countplot(y = df_M['destination'])\n","cca8ff12":"# check out of there are null values \ndf_M.info()\n\n# yes there are you use mode to fill that \ndf_M.dropna(axis=1, inplace = True)\n\n# check out of there are null values \ndf_M.info()\n","9a72d0a7":"# assign the values\nX_df_M = df_M.drop(columns= ['price', 'insert_date', 'start_date', 'end_date'])\ny_df_M = df_M['price'].values","8dd8c577":"X_df_M.isna().sum()","8ec5d39d":"# implementing the encoding\nfrom sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder()\nXm = encoder.fit_transform(X_df_M.values)\nXm","fc3b6d94":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    Xm, y_df_M, test_size=0.1, random_state=2019\n)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","4d1422dd":"# we are using LR \nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)","abb9e8f0":"#  predict \ny_pred = model.predict(X_test)","a82e6400":"# values \ny_pred","e424006e":"# looking for accuracy matrix \nfrom sklearn.metrics import mean_squared_error\nprint(np.sqrt(mean_squared_error(y_test, y_pred)))","4863acf1":"# types of the train type \n\nplt.figure(figsize= (5,12))\nplt.subplot(511)\nplt.title('Train Class')\nplt.tight_layout()\nsns.countplot(y =df_S['train_class'])\n\nplt.subplot(512)\nplt.title('Train type')\nplt.tight_layout()\nsns.countplot(y = df_S['train_type'])\n\nplt.subplot(513)\nplt.title('fare type')\nplt.tight_layout()\nsns.countplot(y =df_S['fare'])\n\nplt.subplot(514)\nplt.title('price ')\nplt.tight_layout()\nsns.boxplot(df_S['price'])\n\n\nplt.subplot(515)\nplt.title('destination ')\nplt.tight_layout()\nsns.countplot(y = df_S['destination'])\n","567abf2a":"# look for how many null values are there \ndf_S.info()","8f004298":"# yes there are you use mode to fill that \ndf_S.dropna(axis=1, inplace = True)\n\n# check out of there are null values \ndf_S.info()\n","a7510244":"# assign the values\nX_df_S = df_S.drop(columns= ['price', 'insert_date', 'start_date', 'end_date'])\ny_df_S = df_S['price'].values","2d384a36":"# implementing the encoding\nfrom sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder()\nXs = encoder.fit_transform(X_df_S.values)\nXs","3e5e337a":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    Xs, y_df_S, test_size=0.2, random_state=2019\n)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","4690e107":"# we are using LR \nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)","2d26aa31":"#  predict \ny_pred = model.predict(X_test)","2a85afb7":"y_pred","43fa0915":"# looking for accuracy matrix \nfrom sklearn.metrics import mean_squared_error\nprint(np.sqrt(mean_squared_error(y_test, y_pred)))","1afc8163":"# Dataset where origin is from Madrid","fb6910a3":"This is in progress kernel.\n\nOur Approach is to : \n1. Analysis of the data \n2. Create 5 data set \n    a. Dataset from each origin point\n    b. As of now, mean values are filled with mean \n    c. But we need to fill values with similar origin and destinations as price will differ for these as welll\n 3. Start predicting the upside price for 1 class\n \n# EDA","9ce5df07":"# I am still working on this. If you want to contribute, please comment and upvote if you like it.:-)","17013a97":"* Motivation is to build a system which allow users getting better prices when buying train tickets.\n* There are multiple solutions this data can provide\n* User can setup a email reminder based on the prediction\n","4a39a029":"df_S ","dad765a4":"# data set where train starts from SEVILLA","e2f8eaa8":"# df_M","7e95f1e2":"# Implmenting LR","ac533375":"    Create the 5 dataset \n         df_M = origin madrid\n         df_S = origin  SEVILLA\n         df_P = origin  PONFERRADA\n         df_B = origin  BARCELONA\n         df_V = origin  VALENCIA"}}