{"cell_type":{"117715ce":"code","a6e2aba1":"code","e0a79d99":"code","c25947b6":"code","a65d9a17":"code","569559cd":"code","23a3101f":"code","4dfca2a2":"code","613cbb64":"code","d378df00":"code","b4777b90":"code","89c9889c":"code","06ef4b71":"code","2b3e1ac4":"code","5d99d2b1":"code","3fe9f393":"markdown","70a12e1e":"markdown","98fd4904":"markdown","b6b9237c":"markdown","ba17e67e":"markdown","edbd0a15":"markdown"},"source":{"117715ce":"import tensorflow as tf\ntf.autograph.set_verbosity(level=0, alsologtostdout=False)","a6e2aba1":"# Initilize x and y with a random value\nx = tf.Variable(3.0)\ny = tf.Variable(4.0)\n\n# Function to run the optimization process \ndef naive_optimize(z0, x, y, learning_rate=0.01, n_iterations=1000):\n    \n    # Run the iteration process n_iterations times\n    for _ in range(n_iterations):\n        # In each iteration:\n        \n        # Calculate the difference between ideal z0 and current z\n        # Perform this calculation within a GradientTape, which keeps a note of how each individual variable contributed to the function\n        # GradientTape uses this information to calculate the gradient of the function with respect to each variable\n        with tf.GradientTape() as tape:\n            z = z0 - y * tf.math.exp(tf.math.pow(x, 2))\n        \n        # Use what GradientTape saw while calculating z, to find the gradients of z with respect to x and y\n        dz_dx, dz_dy = tape.gradient(z, [x,y])\n\n        # Using this gradient, update the value of x and y to bring z closer to z0\n        x.assign(x - learning_rate * (z \/ (dz_dx)))\n        y.assign(x - learning_rate * (z \/ (dz_dy)))\n    \n    # After n_iterations updates, return the current value of x, y and difference from z0\n    return x, y, z0 - y * tf.math.exp(tf.math.pow(x, 2))","e0a79d99":"# Special value of z\nz0 = 2000\n\n# Optimized value of x, y, and their difference from z0\nxo, yo, zo = naive_optimize(z0, x, y)\n\nprint(f'Value of x at optima: {xo.numpy()}')\nprint(f'Value of y at optima: {yo.numpy()}')\nprint(f'Value of z at optima: {z0 + zo}  Expected z: {z0}')","c25947b6":"# Initilize x and y with a random value\nx = tf.Variable(3.0)\ny = tf.Variable(4.0)\n\n# Write a function that calculates how far from z0 you are currently\n# The end goal is to get this function to output near zero \n@tf.function\ndef example_fn(z0, x,y):\n    z = z0 - y * tf.math.exp(tf.math.pow(x, 2))\n    return z","a65d9a17":"# Like above, write the optimization function\ndef tf_fn_optimize(z0, x, y, learning_rate=0.01, n_iterations=1000):\n    # Run n_iterations of optimization\n    for _ in range(n_iterations):\n        \n        # Run the whole function, letting GradientTape see each op in the process  \n        with tf.GradientTape() as tape:\n            z = example_fn(z0, x,y)\n        \n        # Extract the gradient\n        dz_dx, dz_dy = tape.gradient(z, [x,y])\n\n        # Decrease the value of x and y based on gradient value\n        x.assign_sub(learning_rate * (z \/ (dz_dx)))\n        y.assign_sub(learning_rate * (z \/ (dz_dy)))\n\n    return x, y, example_fn(z0, x,y)\n ","569559cd":"# Special value of z\nz0 = 2000\n\n# Optimized value of x, y, and their difference from z0\nxo, yo, zo = tf_fn_optimize(z0, x, y)\n\nprint(f'Value of x at optima: {xo.numpy()}')\nprint(f'Value of y at optima: {yo.numpy()}')\nprint(f'Value of z at optima: {z0 + zo}  Expected z: {z0}')","23a3101f":"# Define the variables\n\n# linspace picks out linearly spaced out numbers in the specified range\n# Feel free to initialize this with any real vector you like\nx = tf.Variable(tf.linspace(start=-0.5, stop=0.8, num=3))\ny = tf.Variable(tf.linspace(start=-0.3, stop=0.7, num=3))","4dfca2a2":"@tf.function\ndef example_fn_vec(z0, x,y):\n    # z is the error term for this function - the distance from optima that should be minimized to zero\n    z = tf.math.abs(z0 - tf.math.multiply(y, tf.math.exp(tf.math.pow(x, 2))))\n    return z","613cbb64":"def vector_optimize(z0, x, y, learning_rate=0.01, n_iterations=1000):\n    for _ in range(n_iterations):\n        with tf.GradientTape() as tape:\n            z = example_fn_vec(z0, x,y)\n        dz_dx, dz_dy = tape.gradient(z, [x,y])\n\n        x.assign_sub(learning_rate * (z \/ (dz_dx)))\n        y.assign_sub(learning_rate * (z \/ (dz_dy)))\n        \n    return x, y, example_fn_vec(z0, x,y)","d378df00":"z0 = tf.linspace(start=10.0, stop=15.0, num=3)\n# z0 = [10.0, 12.5, 15.0]\n\n# all of z0,x,y are vectors of length 3\nxo, yo, zo = vector_optimize(z0, x, y)\nprint(f'Value of x at optima: {xo.numpy()}')\nprint(f'Value of y at optima: {yo.numpy()}')\nprint(f'Value of z at optima: {z0 + zo}')","b4777b90":"# Initiate an optimizer\noptimizer = tf.keras.optimizers.SGD(learning_rate=5e-4)","89c9889c":"# Define the variables\n\n# linspace picks out linearly spaced out numbers in the specified range\n# Feel free to initialize this with any real vector you like\nx = tf.Variable(tf.linspace(start=-0.5, stop=0.8, num=3))\ny = tf.Variable(tf.linspace(start=-0.3, stop=0.7, num=3))","06ef4b71":"# Define the loss function, that we want to get as close to zero as possible\n\n@tf.function\ndef loss_fn(z0, x,y):\n    # z is the error term for this function - the distance from optima that should be minimized to zero\n    # Without the absolute value, the optimizer will keep trying to minimize loss. After it reaches zero, the optmizer will keep trying to push it lower until -inf\n    loss = tf.math.abs(tf.math.subtract(z0, tf.math.multiply(y, tf.math.exp(tf.math.pow(x, 2)))))\n    return loss","2b3e1ac4":"def optimizer_optimize(z0, x, y, optimizer, n_iterations=1000):\n    \n    # Run n_iterations\n    for _ in range(n_iterations):\n        # First, calculate the loss function for this sample\n        # In the process of doing that, Gradient tape will be able to trace \\\n        # the variables and find out the gradients for each variable\n        with tf.GradientTape() as tape:\n            loss = loss_fn(z0, x, y)\n        \n        # Extract the gradients for each variable, with respect to loss\n        grads = tape.gradient(loss, [x,y])\n        # grads will be a list with two tensors, each of length 3\n        \n        # Use the optimizer to apply gradients on the variables\n        optimizer.apply_gradients(zip(grads,[x,y]))\n\n        # Tip: The two operations above can be combined in a single statement below\n        #optimizer.minimize(loss,[x,y], tape=tape)\n\n    return x, y, loss_fn(z0, x,y) ","5d99d2b1":"z0 = tf.linspace(start=0.1, stop=0.3, num=3)\n#z0 = [0.1, 0.2, 0.3]\n\n# all of z0,x,y are vectors of length 3\nxo, yo, loss = optimizer_optimize(z0, x, y, optimizer)\nprint(f'Value of x at optima: {xo.numpy()}')\nprint(f'Value of y at optima: {yo.numpy()}')\nprint(f'Value of z at optima: {z0 + loss}')","3fe9f393":"## Vectorizing the function\n\nSuppose we need to find the optimum x and y for many different values of $z_0$\n\n- One way to do it is to call the function again and again for each $z_0$\n  - This, however, isn't very scalable\n\n\n- There's a better way to do it: vectorize the function\n  - In simple words: instead of feeding the function one $z_0$ after the other, feed it all $z_0$s at once in a one-dimensional vector. \n  - We will also need to feed initial value of x and y for each $z_0$; that is what the gradient descent is applied on \n  \n  \n- So the process above can be run with three vectors $\\vec{z_0}$, $\\vec{x}$, $\\vec{y}$, each of the same length\n  - Every $\\vec{z_0}[i],  \\vec{x}[i],  \\vec{y}[i]$ represents a different optimization problem  \n\nVectorization usually leads to significant speed ups, especially if you are using parallelizable hardware like GPUs, which can \"execute\" each sample on different cores at the same time ","70a12e1e":"# Foundations\n\n**This tutorial covers how optimization works on Tensorflow with tf.GradientTape**\n\nThroughout the notebook, we will try to find optimum values of two variables, $x$ and $y$ such that their function $z(x, y)$ takes a value $z_0$\n\nWe define $z(x, y) = y * e ^{x^2} $\n\nOptimizing this equation for $z_0$ means finding the optimum $x_o$ and $y_o$ such that $(z_0 - y_o * e ^{x_o^2}) \\rightarrow 0$    \n\n*Prerequisite*: This tutorial assumes you have knowledge of how gradient descent algorithms work in theory. If you don't a simple could be to see how the [Newton Raphson method](https:\/\/brilliant.org\/wiki\/newton-raphson-method\/) works\n\n*Note for those just starting out*: Optimization is a numerical analysis. We rarely try to find the exactly correct solution, as we would do trying to solve a quadratic equation via $(x - a).(x-b)=0$ For optimization we choose a measure off 'how close' we want to be to the answer and consider the problem solved when we are there. For example, if $x=23.47$ is the actual solution, we will happy to get an answer of 23.478394 or 23.45928. This will be useful to keep in mind as you read this tutorial\n\nDo reach out to me if you have questions, notice any mistakes or want to suggest improvements","98fd4904":"## Using an optimizer\n\nUntil now, we have implemented te optimization algorith ourselves. This is okay for a few variables but scales poorly to real life problems. These can have millions of variables, arranged in a complex architecture, like BERT\n\nOptimization will work better with a specialized optmization algorithm, like `SGD` or `Adam`. TF provides us a number of optimizers through `tf.keras.optimizers` API\n\nTo make any optimizer work on a set of variables, you will need:\n- The optimizer, instantiated with any paramters that the optimizer is defined by, like learning_rate or momentum\n- The variables\n- The loss function, that the optimizer will try to minimize by changing the variables\n\nIn our case:\n- We will use a Stochastic gradient descent optimizer with `learning_rate` of 0.0005\n- Variables will be the same as we have been using\n- The example function we have been using, is basically a loss function. We want to mould  x and y to make this function output a zero","b6b9237c":"## Use tf.function()\n\nWe can do the same thing above, but wrap the operations in a function outside the optimization function. \n\nNote:\n\n- If tf.function() is confusing to you, just comment it out. Everything in this tutorial will behave the same\n- Wrapping ops in a tf.function() can be efficient if you have a large number of small ops running in your function.\n\n    - Details of what tf.function does is better covered in other tutorials, like [this one](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/function). But all we need to know, is that it converts ops inside it to a computation graph, instead of executing them line by line. \n\n    - The rest of our code continues to work in eager execution, i.e., line by line, but the code within this function will be run as a computation graph.\n\n","ba17e67e":"# Stepping up","edbd0a15":"## Simple gradient descent optimization\n\nThe simplest way to find $x_o$ and $y_o$, given $z_0$ is \n1. Initialize x and y with a random value  \n2. Find the gradient of the function at these values \n3. Adjust the values using the gradients such that you get closer to $z_0$ \n4. Repeat steps 2 and 3 until you are close enough to $z_0$\n\nIf prior analysis has already given us a general idea of what x and y will be, you can initialize with those values. This is called a \"warm start\". It saves time by requiring lesser iterations and generally improves the result quality. \n\nIn this tutorial, we will be initiating x and y with random values"}}