{"cell_type":{"77063ecd":"code","83b20e02":"code","1e1a168c":"code","085dca72":"code","d5c9d8e7":"code","abc274ee":"code","a84e621f":"code","d801d216":"code","aabfd8de":"code","4fddf884":"code","ad16bc19":"code","d450b189":"code","6cb0d0f6":"code","26ead29a":"code","9ca25130":"code","64ffe98d":"markdown","240a3412":"markdown","4f9047e3":"markdown","ad5f8b7c":"markdown","cc195be2":"markdown","e78286ec":"markdown","1373be46":"markdown","36d11ca3":"markdown","b3d52eb2":"markdown"},"source":{"77063ecd":"import pandas as pd\nimport numpy as np\nfrom zipfile import ZipFile\nimport matplotlib.pyplot as plt\nimport collections\nimport itertools\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","83b20e02":"test_data = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntrain_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')","1e1a168c":"labels = train_data.label.values\nlabel_count = collections.Counter(labels)\nplt.bar(label_count.keys(), label_count.values())","085dca72":"train_data.drop(columns={'label'}, inplace=True)\ntrain_data \/= 255.\ntest_data \/= 255.","d5c9d8e7":"test_images = np.reshape(test_data.values, (test_data.shape[0],28,28,1))\ntrain_images = np.reshape(train_data.values, (train_data.shape[0],28,28,1))\ntest_images[0].shape","abc274ee":"plt.figure(figsize=(20,10))\ncolumns = 5\nfor i, image in enumerate(train_images[:20]):\n    plt.subplot(len(train_images[:20]) \/ columns + 1, columns, i + 1)\n    plt.imshow(image[:,:,0])","a84e621f":"X_train, X_val, Y_train, Y_val = train_test_split(train_images, labels, test_size=0.2, random_state=4)","d801d216":"def create_model(print_summary=False):\n    model = Sequential()\n\n    model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=(28,28,1)))\n    model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n    model.add(MaxPool2D(pool_size=2, strides=2))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n    model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu'))\n    model.add(MaxPool2D(pool_size=2, strides=2))\n    model.add(Dropout(0.25))\n    \n    model.add(Flatten())\n    model.add(Dense(256, activation = \"relu\"))\n    model.add(Dropout(0.25))\n    model.add(Dense(10, activation = \"softmax\"))\n    \n    opt = Adam(lr=0.001)\n    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n    \n    if print_summary:\n        model.summary()\n    return model ","aabfd8de":"model = create_model(print_summary=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=0.00001)","4fddf884":"datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    zoom_range=0.1)\n\ndatagen.fit(X_train)","ad16bc19":"BS = 128 # batch size\nhistory = model.fit(datagen.flow(X_train, Y_train, batch_size=BS), steps_per_epoch= X_train.shape[0] \/\/ BS, \n                    validation_data=(X_val, Y_val), epochs=100, verbose=2, callbacks=[reduce_lr])","d450b189":"plt.figure(figsize=(20,10))\nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nax[0].legend()\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nax[1].legend()","6cb0d0f6":"def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n\n    plt.figure(figsize=(20,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(-0.5, len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = np.round(100 * cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis],1)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# # Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_val, Y_pred_classes)\n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10), normalize=True)","26ead29a":"print(classification_report(Y_val, Y_pred_classes))","9ca25130":"results = model.predict(test_images)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nsubmission = pd.DataFrame({\n    'ImageID': range(1, len(results) + 1),\n    'Label': results\n})\nsubmission.to_csv(\"digit_recognizer_cnn.csv\",index=False)","64ffe98d":"# Prepare images by reshaping and normalizing values","240a3412":"# Plot Confusion matrix for the validation data","4f9047e3":"# Build the data generator and train the model","ad5f8b7c":"## Investigate the balance of the data for each label","cc195be2":"# Load csv files using pandas","e78286ec":"> # prepare kaggle submission file","1373be46":"# Plot loss and accuracy for training and validation","36d11ca3":"## Split the train and the validation set for the fitting","b3d52eb2":"# Build the CNN model"}}