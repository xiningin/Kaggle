{"cell_type":{"ecf588d5":"code","c034c758":"code","0b8eecad":"code","9682373e":"code","20c88300":"code","4b24627a":"code","c00f7461":"code","7ea2eef2":"code","b138fa16":"code","8a6d1f98":"code","6cdaeef9":"code","1f0a0dd1":"code","1af7492d":"code","51d9ba9f":"code","0ee0ac48":"code","27011083":"code","3a6fea6b":"code","6fc19640":"code","835be49c":"code","51e6bbe8":"code","d6fa82c6":"code","b523e9f3":"code","08e9c55f":"code","d2aed9e1":"code","43763476":"markdown","9890c71a":"markdown","33a05982":"markdown","a0bde990":"markdown","da7d7cd0":"markdown","4558f51b":"markdown","adb3aa43":"markdown","2974e1c3":"markdown","29308dc3":"markdown","3a1f0bf8":"markdown","83722dc2":"markdown","3099a690":"markdown","5f601632":"markdown","5e0a532c":"markdown","6d4b101e":"markdown","8a628080":"markdown","66608bd7":"markdown","5adc4969":"markdown","8acf3bb5":"markdown"},"source":{"ecf588d5":"from __future__ import absolute_import, division, print_function, unicode_literals\n\n# TensorFlow and tf.keras\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import regularizers\n\n# Helper libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c034c758":"from tensorflow.python.keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n# Import Data\ntrain = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")\ntest= pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")\nprint(\"Train size:{}\\nTest size:{}\".format(train.shape, test.shape))\n\n# Transform Train and Test into images\\labels.\nx_train = train.drop(['label'], axis=1).values.astype('float32') # all pixel values\ny_train = train['label'].values.astype('int32') # only labels i.e targets digits\nx_test = test.drop(['label'], axis=1).values.astype('float32')\ny_test = test['label'].values.astype('int32') # only labels i.e targets digits\nx_train = x_train.reshape(x_train.shape[0], 28, 28) \/ 255.0\nx_test = x_test.reshape(x_test.shape[0], 28, 28) \/ 255.0\n\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","0b8eecad":"class_names = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']","9682373e":"plt.figure()\nplt.imshow(x_train[0])\nplt.colorbar()\nplt.grid(False)\nplt.show()","20c88300":"x_train = x_train \/ 255.0\n\nx_test = x_test \/ 255.0","4b24627a":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(x_train[i], cmap=plt.cm.binary)\n    plt.xlabel(class_names[y_train[i]])\nplt.show()","c00f7461":"model = keras.Sequential([\n    keras.layers.Flatten(input_shape=(28, 28)),\n    keras.layers.Dense(128, activation='relu'),\n    keras.layers.Dense(10)\n])","7ea2eef2":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","b138fa16":"model.fit(x_train, y_train, epochs=10)","8a6d1f98":"test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n\nprint('\\nTest accuracy:', test_acc)","6cdaeef9":"probability_model = tf.keras.Sequential([model, \n                                         tf.keras.layers.Softmax()])","1f0a0dd1":"predictions = probability_model.predict(x_test)","1af7492d":"predictions[0]","51d9ba9f":"np.argmax(predictions[0])","0ee0ac48":"y_test[0]","27011083":"def plot_image(i, predictions_array, true_label, img):\n  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n\n  plt.imshow(img, cmap=plt.cm.binary)\n\n  predicted_label = np.argmax(predictions_array)\n  if predicted_label == true_label:\n    color = 'blue'\n  else:\n    color = 'red'\n\n  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n                                100*np.max(predictions_array),\n                                class_names[true_label]),\n                                color=color)\n\ndef plot_value_array(i, predictions_array, true_label):\n  predictions_array, true_label = predictions_array, true_label[i]\n  plt.grid(False)\n  plt.xticks(range(10))\n  plt.yticks([])\n  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n  plt.ylim([0, 1])\n  predicted_label = np.argmax(predictions_array)\n\n  thisplot[predicted_label].set_color('red')\n  thisplot[true_label].set_color('blue')","3a6fea6b":"i = 0\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\nplot_image(i, predictions[i], y_test, x_test)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions[i],  y_test)\nplt.show()","6fc19640":"i = 13\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\nplot_image(i, predictions[i], y_test, x_test)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions[i],  y_test)\nplt.show()","835be49c":"num_rows = 5\nnum_cols = 3\nnum_images = num_rows*num_cols\nplt.figure(figsize=(2*2*num_cols, 2*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plot_image(i, predictions[i], y_test, x_test)\n  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  plot_value_array(i, predictions[i], y_test)\nplt.tight_layout()\nplt.show()","51e6bbe8":"img = x_test[1]\n\nprint(img.shape)","d6fa82c6":"img = (np.expand_dims(img,0))\n\nprint(img.shape)","b523e9f3":"predictions_single = probability_model.predict(img)\n\nprint(predictions_single)","08e9c55f":"plot_value_array(1, predictions_single[0], y_test)\n_ = plt.xticks(range(10), class_names, rotation=45)","d2aed9e1":"np.argmax(predictions_single[0])","43763476":"These next two functions will plot the image we are predicting and the confidence for all 10 classes.","9890c71a":"So our model is confident that the image is a T-shirt, the below code will check the see what the correct class is for that image.","33a05982":"Before the model is trained, we need to compile the model. For this we will need a loss function, an optimizer and the metric which will be used to monitor the training and test steps.\n\nThe loss function measures how accurate the model is during training, if we minimize loss then our model can make better predicitons.\n\nThe optimizer us how to model updates itself bases on the data it sees and the loss function, here we use adam which is a gradient-based optimizer and uses little memory when training which is handy for larger datasets.\n\nThe metric we use to monitor our steps is accuracy which is the fraction of the images that are classified correctly.","a0bde990":"## The Model\nNext, using Keras, we will configure the model that our neural network will use. The Keras Sequential model is a linear stack of layers, each layer you can specify and customize yourself, but let's have a look at the one below.\n\nMy first layer is a flatten layer, this flattens the input given into it. In our case our input is a 28 by 28 pixel two dimensional array, after it is passed into the flatten layer it will be tranformed into a one dimensional array consisting of 784 pixels. Think of it like unstacking the rows of pixels and lining them up one after another.\n\nThe next two layers consists of two Dense layers, these are fully connected neural layers hense their name. The first layer has 128 neurons whilst the seconds only has 10. The first layer also uses the ReLU activation function, activation fucntion can be passed as a parameter and the fucntion you use is totally up to you but for this simple image classifier, ReLU is the best choice.\n\nThe last Dense layer is a softmax layer, in simple terms a softmax layer is typically the final output layer in a network that performs multi-class classification by taking in a number of score values and scales them all down into a range from 0 to 1. The sum of these scores is 1 and the highest score closest to 1 is most likely the class that the network predicts the image belongs to. In this case we use 10 neurons as we have 10 classes that can be identified.","da7d7cd0":"## Making Predictions\nWith our model trained, we can still use it to make predictions on our test images. We will declare model that takes in our original model and add a softmax layer to convert the logits to probabilities which are alot easier to interpret.","4558f51b":"One predicition is an array of 10 numbers that represent the models confidence that the image responds to each of the 10 classes. To make this even more readable we will use *np.argmax* to see the highest confidence value.","adb3aa43":"To check that the data is in the correct format we will plot the first 25 images from the training set and show their class name.","2974e1c3":"## Preprocess the data\nThe data must be preprocessed before we train our network, so to get started we will pull up the first image in our training set and plot it against a colorbar.","29308dc3":"## Training the network model\nTo start training the model we call the *model.fit* method which fits the model to the training data. But before we train it we should specify the number of epochs we want, epochs are the number of times it will iterate over the training dataset.","3a1f0bf8":"Using the line of code above, the probability model has predicited the label for each image in the test set can stored them in predicitons. Let's take the first prediciton.","83722dc2":"As you can see this model reaches 84% accuracy on the training data. But lets see how our model performs on the test dataset.","3099a690":"## Transform the data\nTo create accurate predicitons and not overfit the data, we must split it into a training set and a test set. Fortunately, the data already comes split into a train set of 60,000 images and a test set of 10,000 images. This is a nice ratio split and I think we should keep it as it is.\nThe only thing I have to do regarding preparation is seperate the features and labels in each set.","5f601632":"## Load Packages","5e0a532c":"# **Fashion MNIST Classificaton**\nIn this notebook, I will train a neural network to classify the Fashion MNIST dataset. I will use Keras along side tensorflow and other python libraries to explore the data at hand and train a model to make predictions on a test set.\n\nThe Fashion MNIST dataset is a set of 60,000 images of clothing and 10,000 test images. Each picture is greyscale and is 28 x 28 pixels in dimension, each image is associated with one of 10 classes.","6d4b101e":"Each image is associated with a single label\/class. The class names aren't included in the dataset so we will store them here to use later on.","8a628080":"## Verfiy the predicitions\nNow using our trained probability model and the two plotting functions we can make some predictions about images in the test set.","66608bd7":"We can also plot a bunch of images together to get a better look how accuracy can affect some of our predictions.","5adc4969":"We can see that the pixel values fall between a range of 0 and 255. We need to scale these values to a range of 0 to 1. Feature scaling isn't totally necessary in this example as we only technically have one feature but it is good practice to scale your features to the same range so that when you have multiple features, one feature won't weigh alot more than one with a lower magnitude. Also, we must do this to both the training and test set.","8acf3bb5":"## Make predicitons on single images\nTo make predictions on single images we will need to add the image to a list as Keras odels are optimized to make predictions on a batch all at once."}}