{"cell_type":{"d08a2306":"code","93575b73":"code","ed7a48d5":"code","cc1de72f":"code","dfe6998c":"code","ef3207c3":"code","9ad5b27e":"code","d4b8fd22":"code","ca71f20b":"code","09393e1a":"code","0a2e4a13":"code","57380c94":"code","af7bd182":"code","9e550192":"code","61447088":"code","d2f13dd9":"code","6e25ca8b":"code","65e1ffe9":"code","5960d180":"code","7d49a089":"code","791a606e":"code","fbf3276f":"code","4f9afa39":"code","6e72a7bb":"code","bb640a80":"code","6d75dc58":"code","19cdb799":"code","2abe9e10":"code","77c6d107":"code","d1d85ffe":"code","f93f58e1":"code","d3f9c239":"code","520cdf17":"code","2116bccc":"code","24d5837c":"code","87aecea1":"markdown","c7dd7d2d":"markdown","5275787e":"markdown","dd980646":"markdown","167f7348":"markdown","7941e2ea":"markdown","6bf8dd13":"markdown","a4acbf88":"markdown","7d1872e4":"markdown","68e5b505":"markdown","875a768b":"markdown","37c24ab0":"markdown","859c94f3":"markdown","60b20018":"markdown","ac576cc4":"markdown","1f6d269a":"markdown","d5cb8501":"markdown","f6ef6f27":"markdown","712f0895":"markdown","c6c26260":"markdown","ecb146ba":"markdown","28887150":"markdown","9dac1e73":"markdown","1b2f4dd4":"markdown","70b79fa7":"markdown","2aa03fd9":"markdown","7eae4763":"markdown","472e4a28":"markdown","3ea2d735":"markdown","7ea55389":"markdown","51744e1d":"markdown","b4be1c58":"markdown","57f07a37":"markdown","57ada155":"markdown","1aeead28":"markdown","d7294576":"markdown","fce6be70":"markdown"},"source":{"d08a2306":"import pandas as pd\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, RepeatedStratifiedKFold\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.utils import resample\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nimport pprint\nfrom sklearn.svm import SVC\nfrom sklearn.feature_selection import RFE\nfrom sklearn.manifold import LocallyLinearEmbedding\nfrom scipy.stats import loguniform\nimport xgboost as xgb\nimport numpy as np\nimport missingno as mno\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.exceptions import ConvergenceWarning\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import accuracy_score\n","93575b73":"# # Read csv files\n# train_data = pd.read_csv('data\/train.csv')\n\n# # Drop the title information\n# train_data.drop(['title','id', 'console'], axis = 1, inplace= True)\n\n# submission_data = pd.read_csv('data\/eval.csv')\n# IDS = submission_data['id']\n# submission_data = submission_data.drop(['id', 'console'], axis=1)","ed7a48d5":"# Read csv files\ntrain_data = pd.read_csv('..\/input\/assignment2\/train.csv')\n\n# Drop the title information\ntrain_data.drop(['title','id', 'console'], axis = 1, inplace= True)\n\nsubmission_data = pd.read_csv('..\/input\/assignment2\/eval.csv')\nIDS = submission_data['id']\nsubmission_data = submission_data.drop(['id', 'console'], axis=1)","cc1de72f":"mno.matrix(train_data, figsize = (12, 6))\n#Print the total percentage missing\nprint(\"--Train data-- \\n\")\nprint((train_data.isnull().sum() \/ train_data.isnull().count()) * 100 )\nplt.show()","dfe6998c":"\n# One hot encode esrb rating to display on heatmap\ntrain_hot_data = train_data\ntrain_hot_data = pd.get_dummies(train_hot_data, columns = ['esrb_rating'], prefix = '_')\n\n# Display heatmap\nax = plt.subplots(figsize=(25,25))\nsns.heatmap(train_hot_data.corr(), annot=True,cmap = 'RdYlGn', linewidths=0.2)\nplt.plot(ax=ax)\nplt.show()","ef3207c3":"print(train_data.sum() == 0, end = \"\\t\")","9ad5b27e":"print(train_data.sum() == train_data.count(), end = \"\\t\")","d4b8fd22":"train_data.describe()","ca71f20b":"# New plot\nax = plt.subplots(figsize=(25,25))\n# Correlation matrix\ncorr = train_hot_data.corr()\n\n# Lower triangular correlation heatmap\nmask = np.triu(np.ones_like(corr,dtype=bool))\nsns.heatmap(corr, mask=mask,annot=True,cmap = 'RdYlGn', linewidths=0.2, fmt='.2f', vmin = '-1', vmax='1')\nplt.plot(ax=ax)\nplt.show()","09393e1a":"\n#corr matrix\ncorrs_ma = train_data.corr()\ncorrs = train_data.corr().abs()\n\n#make mask\nmask = np.triu(np.ones_like(corrs_ma,dtype=bool))\ntri_train = corrs_ma.mask(mask)\n\nto_drop = [c for c in tri_train.columns if any(tri_train[c] > .95)]\nif(to_drop == []):print(\"There are no columns to drop.\")","0a2e4a13":"\ndef recursive_feature_test(train_data, model, target, n_feat):\n\n    # Split data into features and target\n    y = train_data[target]\n    X = train_data.drop(target, axis = 1)\n\n    # Init lists\n    iteration = []\n    base_accuracy = []\n    reduced_accuracy = []\n\n    # Create models to compare\n    base_model = model\n    reduced_model = RFE(estimator = model, n_features_to_select=n_feat)\n\n    for i in range(50):\n        # Add iteration to list\n        iteration.append(i)\n        \n        # Split the data\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1)\n\n        # Generate base scores\n        base_model.fit(X_train, y_train)\n        b_preds = base_model.predict(X_test)\n\n        # Append scores to list\n        base_accuracy.append(accuracy_score(b_preds, y_test))\n\n        # Training our reduced model\n        reduced_model.fit(X_train, y_train)\n        r_preds = reduced_model.predict(X_test)\n\n        reduced_accuracy.append(accuracy_score(r_preds, y_test))\n    return (pd.DataFrame({'base_acc': base_accuracy, 'reduced_acc': reduced_accuracy}))\n\n\n\n\nrec_scoring = recursive_feature_test(train_data, LogisticRegressionCV(solver='liblinear', cv = 4, scoring = 'accuracy'), 'esrb_rating', 25)\n\n","57380c94":"# Plotting results\nfig, (ax1,ax2) = plt.subplots(1, 2, sharey=True)\n\nsns.boxplot(y='base_acc', data=rec_scoring, ax=ax1)\n\n\nsns.boxplot(y='reduced_acc', data=rec_scoring,ax = ax2)\n\nplt.show()\n","af7bd182":"def pca_feature_test(train_data, model, target, n_feat):\n\n    # Split data into features and target\n    y = train_data[target]\n    X = train_data.drop(target, axis = 1)\n\n    # Init lists\n    iteration = []\n    base_accuracy = []\n    reduced_accuracy = []\n\n    # Create models to compare\n    base_model = model\n    pca_model = LogisticRegressionCV(solver='liblinear', cv = 4, scoring = 'accuracy', max_iter=7000)\n\n    # Create PCA matrix\n    pca_train = StandardScaler().fit_transform(X)\n    pca_train = PCA(n_components=n_feat).fit_transform(pca_train)\n\n    for i in range(50):\n        # Add iteration to list\n        iteration.append(i)\n        \n        # Split the data\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1)\n        PCAX_train, PCAX_test, PCAy_train,PCAy_test = train_test_split(pca_train, y, test_size=0.1)\n\n\n        # Generate base scores\n        base_model.fit(X_train, y_train)\n        b_preds = base_model.predict(X_test)\n\n        # Append scores to list\n        base_accuracy.append(accuracy_score(b_preds, y_test))\n\n        # Training our reduced model\n        pca_model.fit(PCAX_train, PCAy_train)\n        r_preds = pca_model.predict(PCAX_test)\n\n        reduced_accuracy.append(accuracy_score(r_preds, PCAy_test))\n    return (pd.DataFrame({'base_acc': base_accuracy, 'pca_acc': reduced_accuracy}))\n\n\n\n\npca_scoring = pca_feature_test(train_data, LogisticRegressionCV(solver='liblinear', cv = 4, scoring = 'accuracy'), 'esrb_rating', 25)\n","9e550192":"# Plotting results\nfig, (ax1,ax2, ax3) = plt.subplots(1, 3, sharey=True)\n\nsns.boxplot(y='base_acc', data=pca_scoring, ax=ax1)\nsns.boxplot(y='pca_acc', data=pca_scoring,ax = ax2)\nsns.boxplot(y='reduced_acc', data=rec_scoring,ax = ax3)\n\nplt.show()\n","61447088":"def lle_feature_test(train_data, model, target, n_feat, n_neighbors):\n\n    # Split data into features and target\n    y = train_data[target]\n    X = train_data.drop(target, axis = 1)\n\n    # Init lists\n    iteration = []\n    base_accuracy = []\n    reduced_accuracy = []\n\n    # Create models to compare\n    base_model = model\n    lle_model = LogisticRegressionCV(solver='liblinear', cv = 4, scoring = 'accuracy', max_iter=7000)\n\n    # Create LLE matrix\n    lle = LocallyLinearEmbedding(n_components = n_feat, n_neighbors = n_neighbors)\n    lle_train = lle.fit_transform(X)\n\n    for i in range(50):\n        # Add iteration to list\n        iteration.append(i)\n        \n        # Split the data\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1)\n        lleX_train, lleX_test, lley_train, lley_test = train_test_split(lle_train, y, test_size=0.1)\n\n\n        # Generate base scores\n        base_model.fit(X_train, y_train)\n        b_preds = base_model.predict(X_test)\n\n        # Append scores to list\n        base_accuracy.append(accuracy_score(b_preds, y_test))\n\n        # Training our reduced model\n        lle_model.fit(lleX_train, lley_train)\n        r_preds = lle_model.predict(lleX_test)\n\n        reduced_accuracy.append(accuracy_score(r_preds, lley_test))\n    return (pd.DataFrame({'base_acc': base_accuracy, 'lle_acc': reduced_accuracy}))\n\n\n\n\nlle_scoring = lle_feature_test(train_data, LogisticRegressionCV(solver='liblinear', cv = 4, scoring = 'accuracy'), 'esrb_rating', 25, 3)\n","d2f13dd9":"# Plotting results\nfig, (ax1,ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True)\n\nsns.boxplot(y='base_acc', data=pca_scoring, ax=ax1)\nsns.boxplot(y='pca_acc', data=pca_scoring,ax = ax2)\nsns.boxplot(y='reduced_acc', data=rec_scoring,ax = ax3)\nsns.boxplot(y='lle_acc', data=lle_scoring,ax = ax4)\n\nplt.show()\n","6e25ca8b":"sns.set_theme(style=\"darkgrid\")\nsns.countplot(x=train_data['esrb_rating'])\nplt.show()","65e1ffe9":"# Randoming downsampling and reconsting train_data\nX, y = RandomUnderSampler().fit_resample(train_data.drop(['esrb_rating'], inplace=False, axis=1), train_data['esrb_rating']) \n\n# Reconstructing\nundersampled_td = X\nundersampled_td['esrb_rating'] = y\n\n#Calling the previous functions with new data\npca_scoring = pca_feature_test(undersampled_td, LogisticRegressionCV(solver='liblinear', cv = 4, scoring = 'accuracy'), 'esrb_rating', 25)\nlle_scoring = lle_feature_test(undersampled_td, LogisticRegressionCV(solver='liblinear', cv = 4, scoring = 'accuracy'), 'esrb_rating', 25, 3)\nrec_scoring = recursive_feature_test(undersampled_td, LogisticRegressionCV(solver='liblinear', cv = 4, scoring = 'accuracy'), 'esrb_rating', 25)","5960d180":"fig, (ax1,ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True)\n\nsns.boxplot(y='base_acc', data=pca_scoring, ax=ax1)\nsns.boxplot(y='pca_acc', data=pca_scoring,ax = ax2)\nsns.boxplot(y='reduced_acc', data=rec_scoring,ax = ax3)\nsns.boxplot(y='lle_acc', data=lle_scoring,ax = ax4)\n\nplt.show()","7d49a089":"# Randoming downsampling and reconstructing train_data\nX, y = RandomUnderSampler().fit_resample(train_data.drop(['esrb_rating'], inplace=False, axis=1), train_data['esrb_rating']) \n\n# Reconstructing\ntrain_data = X\ntrain_data['esrb_rating'] = y\n","791a606e":"sns.set_theme(style=\"darkgrid\")\nsns.countplot(x=train_data['esrb_rating'])\nplt.show()","fbf3276f":"train_data.describe()","4f9afa39":"#counts = train_data.drop(columns=[\"esrb_rating\", 'id', 'console'], axis=1, inplace = False).sum(axis = 0).reset_index().rename(columns={\"index\" : \"features\", 0 : \"Count\"})\ncounts = train_data.drop(columns=[\"esrb_rating\"], axis=1, inplace = False).sum(axis = 0).reset_index().rename(columns={\"index\" : \"features\", 0 : \"Count\"})\ncounts.sort_values(\"Count\", ascending=False, inplace=True)\ncounts.plot.bar(x=\"features\", y=\"Count\", figsize = (10,5))\nplt.show()","6e72a7bb":"# Some models require this and none mind it, so we will do it ahead of time\nle = LabelEncoder().fit(train_data['esrb_rating'])\ntrain_data['esrb_rating'] = le.transform(train_data['esrb_rating'])\nprint(train_data['esrb_rating'].unique())","bb640a80":"LR_space={\"penalty\":[\"l1\",\"l2\"], 'max_iter' :[4000], 'solver': ['liblinear','lbfgs', 'saga']}\nSVM_space = {'svc__C': [0.1,10, 100],'svc__gamma': [1,0.01, 0.001],'svc__kernel': ['rbf','poly', 'sigmoid']}\nDT_space ={'max_depth': [2, 3, 5, 10],'min_samples_leaf': [5, 10, 20],'criterion': [\"gini\", \"entropy\"]}\nRF_space = {\n 'bootstrap': [True, False],\n 'criterion': ['gini'],\n 'max_features': ['auto'],\n 'n_estimators': [200,300,400],\n 'max_depth': [None],\n\n}\nKNN_space = { 'n_neighbors' : [5,7,9,11],'weights' : ['uniform','distance'],'metric' : ['euclidean','manhattan']}\nXG_space1 = {\n        'min_child_weight': [0,1,2, 5, 10],\n        'gamma': [0,0.5, 1, 1.5, 2, 5],\n        'max_depth': [3, 4, 5, 6],\n        'eta': [.02,.03,.04, .05],\n        }\nXG_space2 = {\n        'gamma': np.linspace(1, 9),\n        'reg_alpha': list(np.linspace(0, 1, num = 5)),\n        'reg_lambda': list(np.linspace(0, 1, num = 5)),\n        \n        \n        }","6d75dc58":"\nLR_grid = GridSearchCV(estimator=LogisticRegression(), param_grid = LR_space, scoring = 'accuracy', cv = 3, refit = True, n_jobs= -1)\nSVM_grid = GridSearchCV(estimator=make_pipeline(StandardScaler(), SVC()), param_grid = SVM_space, scoring = 'accuracy', cv = 3, refit = True, n_jobs= -1)\nDT_grid = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid = DT_space, scoring = 'accuracy', cv = 3, refit = True, n_jobs = -1)\nRF_grid = GridSearchCV(estimator=RandomForestClassifier(), param_grid = RF_space, scoring = 'accuracy', cv = 3, refit = True, n_jobs = -1)\nKNN_grid = GridSearchCV(estimator=KNeighborsClassifier(), param_grid = KNN_space, scoring = 'accuracy', cv = 3, refit = True, n_jobs = -1)\n#XG_grid = xgb.XGBClassifier(objective='multi:softmax', eval_metric='merror',use_label_encoder=False, max_depth =3, eta = .05,n_estimators=200,num_class = 4)\n                            \nXG_grid = RandomizedSearchCV(estimator=xgb.XGBClassifier(num_class = 4,use_label_encoder =False,eval_metric = 'merror', objective ='multi:softmax'), param_distributions = XG_space1,cv=3, refit = True, n_jobs=16, n_iter = 20,verbose=10)","19cdb799":"# function to determine the score distribution of the model\ndef score_distribution(X,y, model):\n    model = model\n    y = y\n    X = X\n    \n    val_accuracy=[]\n\n    # to generate a distribution we must do it many times...\n    for i in range(10):\n        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.1,stratify=y)\n\n        model.fit(X_train, y_train)\n        score = model.score(X_val, y_val)\n        val_accuracy.append(score)\n            \n    return val_accuracy","2abe9e10":"y = train_data['esrb_rating']\nX = train_data.drop('esrb_rating', inplace = False, axis = 1)\n\nLR = LogisticRegression()\nSV = make_pipeline(StandardScaler(), SVC())\nDT = DecisionTreeClassifier()\nRF = RandomForestClassifier()\nKNN = KNeighborsClassifier()\nXG = xgb.XGBClassifier(objective='multi:softmax', eval_metric='merror',use_label_encoder=False, max_depth =3, eta = .05,n_estimators=700,num_class = 4)\n\n\nLR_base_scores = score_distribution(X,y,LR)\nSV_base_scores = score_distribution(X,y,SV)\nDT_base_scores = score_distribution(X,y,DT)\nRF_base_scores = score_distribution(X,y,RF)\nKNN_base_scores = score_distribution(X,y,KNN)\nXG_base_scores = score_distribution(X,y,XG)","77c6d107":"fig, (ax1,ax2, ax3, ax4,ax5,ax6) = plt.subplots(1, 6, sharey=True)\n\nsns.boxplot(data=LR_base_scores, ax = ax1)\nsns.boxplot(data=SV_base_scores, ax = ax2)\nsns.boxplot(data=DT_base_scores, ax = ax3)\nsns.boxplot(data=RF_base_scores ,ax = ax4)\nsns.boxplot(data=KNN_base_scores ,ax = ax5)\nsns.boxplot(data=XG_base_scores ,ax = ax6)\n\nplt.show()\n","d1d85ffe":"model_scores = {'LR': LR_base_scores,\n'SV': SV_base_scores,\n'DT': DT_base_scores,\n'RF': RF_base_scores,\n'KNN': KNN_base_scores,\n'XG': XG_base_scores}\n\nfor name, model in model_scores.items():\n    print(\"{} has a mean accuracy score of {:.2f} w\\ std {:.4f}\".format(name,np.array(model).mean() * 100,np.array(model).std()))","f93f58e1":"y = train_data['esrb_rating']\nX = train_data.drop('esrb_rating', inplace = False, axis = 1)\n\nLR = LR_grid\nSV = make_pipeline(StandardScaler(), SVC())\nDT = DT_grid\nRF = RF_grid\nKNN = KNN_grid\nXG = xgb.XGBClassifier(objective='multi:softmax', eval_metric='merror',use_label_encoder=False, max_depth =3, eta = .05,n_estimators=350,num_class = 4)\n\n\nLR_grid_scores = score_distribution(X,y,LR)\nSV_grid_scores = score_distribution(X,y,SV)\nDT_grid_scores = score_distribution(X,y,DT)\nRF_grid_scores = score_distribution(X,y,RF)\nKNN_grid_scores = score_distribution(X,y,KNN)\nXG_grid_scores = score_distribution(X,y,XG)","d3f9c239":"fig, (ax1,ax2, ax3, ax4,ax5,ax6) = plt.subplots(1, 6, sharey=True)\n\nsns.boxplot(data=LR_grid_scores, ax = ax1)\nsns.boxplot(data=SV_grid_scores, ax = ax2)\nsns.boxplot(data=DT_grid_scores, ax = ax3)\nsns.boxplot(data=RF_grid_scores ,ax = ax4)\nsns.boxplot(data=KNN_grid_scores ,ax = ax5)\nsns.boxplot(data=XG_grid_scores ,ax = ax6)\n\nplt.show()\n","520cdf17":"model_grid_scores = {'LR': LR_grid_scores,\n'SV': SV_grid_scores,\n'DT': DT_grid_scores,\n'RF': RF_grid_scores,\n'KNN': KNN_grid_scores,\n'XG': XG_grid_scores}\n\nfor name, model in model_grid_scores.items():\n    print(\"{} has a mean accuracy score of {:.2f} w\\ std {:.4f}\".format(name,np.array(model).mean() * 100,np.array(model).std()))","2116bccc":"XG.fit(X,y)\ny_pred = XG.predict(submission_data)\ny_pred = le.inverse_transform(y_pred)\nsubmission_frame =  pd.DataFrame(data={'esrb_rating': y_pred}, index=IDS)\nsubmission_frame.to_csv('submission_test6.csv', index=True, index_label ='id')","24d5837c":"print(\"Successfully saved.\\n\")\nprint(submission_frame)","87aecea1":"# Building our Models","c7dd7d2d":"# Data Cleanup\nHere we make the data as neat as possible for exploratory data analysis and model training","5275787e":"### Observations\n1. Most games contain blood\/blood and gore\n2. A large number of games also include no descriptors\n3. The least represented value is mature_humor","dd980646":"# Exploratory Data Analysis","167f7348":"## Checking for unused or always used features\n* Columns that are always 1 or always 0 can safely be dropped because they had no information to the dataset","7941e2ea":"### Observations\n* Looking at the average scores it would appear that the RandomForestClassifier is the most promising, but this could easily be false given we have not optimized our models yet. Xg boost looks very good as well","6bf8dd13":"### Observations\nReducing the amount of features by 8 increases our accuracy and alters our variance, we may move forward with this method","a4acbf88":"# Importing Data from Kaggle","7d1872e4":"## Attempting PCA (although it's not great for binary data)","68e5b505":"## Describing model scores\n","875a768b":"### How varied is our data?\nIf the standard deviation is sufficiently close to zero in any column, we may be able to drop it","37c24ab0":"### Observations\n\n1) Console seems to say very little about the overall esrb rating\n2) Oddly enough Nudity seems to add very little information overall\n3) There are no entirely correlated features \n\n\nNevertheless, Lets make a mask to see if we can remove overly correlated columns...","859c94f3":"# Importing data to my local machine\nThis is generally commented out when I submit, but is included for transparency and because I tend to develop locally instead of on kaggle","60b20018":"### Observations\n* Undersampling the data improved accuracy across the board, but some of the techniques are no longer valid or better than the base model. In fact our base model is the best of the four!\n* We will go through and apply undersampling going forward","ac576cc4":"### Observations\n1. From our count plot we can see that the number of games in the teen category is far above and beyond the others\n2. The other categories appear to be relativly balanced","1f6d269a":"## Creating our gridsearch objects","d5cb8501":"## Checking for missing values\n* We plot a chart and print the percentage of missing values from the dataset","f6ef6f27":"## Do we have highly correlated features?\nWe reformat our heatmap plot to see if there are any features that do not contribute much...","712f0895":"## Creating a hyper-parameter grid for each model\n1. Logistic Regression\n2. Support Vector Machine\n3. Decision Tree Model\n4. Random Forest Model\n5. K Nearest Neighbors model\n6. XGBoost","c6c26260":"## Optimizing hyper-parameters using grid-search\n","ecb146ba":"## Comparing baseline models\n","28887150":"## Using RandomUnderSampler to bring balance to the data\nWe will create a copy of our data that is under-sampled and run it through the previous functions to see how it generally effects accuracy","9dac1e73":"## Recursive feature elimination\nWe will recursively eliminate features until the desired number of features remains, we will then compare scores to a model trained on both the unreduced and the reduced to see if it is worth doing.","1b2f4dd4":"## Can we reduce the dimensionality...","70b79fa7":"## Handling Outliers\n* Considering that the data is largely categorical and boolean, there is little in the way of outliers. The data is composed as it is, and no outlier detection should be necessary","2aa03fd9":"### Observations\n* There are no empty features, and no features that are always present","7eae4763":"### Observations\n1) Our base accuracy is pretty good, we will continue going forward with it\n2) PCA has higher variance and a lower mean\/min we will disgard it\n3) Recursive reduction has a very similar mean with a slightly lower variance, we will continue going forward with it","472e4a28":"## How balanced is our data?\n* Checking for class imbalances and correcting for them","3ea2d735":"## Observations\n* There are no missing values, so there is no need to handle them.","7ea55389":"### Observations\n* Looking at out different categories\n    * E - The highest correlated feature is simply no descriptors\n    * ET - The highest correlated feature is fantasy violence\n    * M -  The highest correlated features are blood and gore as well as strong language. Sexual content is a close third.\n    * T - Teen games have a fairly varried correlation, but blood, suggestive themes, and violence are all nearly the same","51744e1d":"## Attempting LLE (Locally Linear Embedding)\n* We don't expect an improved performance, I simply want to learn how to do it","b4be1c58":"## Looking at correlations with SNS Heatmap","57f07a37":"## Label-encoding esrb-rating","57ada155":"## Describing our dataset and looking at feature counts","1aeead28":"# Package Imports\nTo keep our notebook nice and tidy we will import all required packages here","d7294576":"#### Observations\n* Considering the standard deviation of columns is not near zero in any column, we will not be able to reduce dimensionality this way\n* Animated blood appears to be the lowest, but I'd wager it is still important for classification of E\/ET","fce6be70":"## Handling imbalanced data\n\nResearch:\n* https:\/\/discuss.analyticsvidhya.com\/t\/dealing-with-imbalanced-categorical-data-for-machine-learning-predictions\/66904\/3\n* https:\/\/machinelearningmastery.com\/smote-oversampling-for-imbalanced-classification\/\n* https:\/\/www.datacamp.com\/community\/tutorials\/diving-deep-imbalanced-data\n\n\nOur options appear to be\n1. Simply remove the extra data\n2. Use SMOTE to generate synthetic samples\n3. Using RandomUnderSampler to reduce the number of teen samples\n4. Use a penalty matrix to apply a significant penalty for misclassifying the other three categories"}}