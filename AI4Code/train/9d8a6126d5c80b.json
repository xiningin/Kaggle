{"cell_type":{"b0f26f25":"code","e9ecd9b9":"code","3e04e21e":"code","8a0a8d35":"code","ea88dcb0":"code","8a2affd8":"code","317bfdfd":"code","5ab850c8":"code","0da558ed":"code","ee944525":"code","12a93fb8":"code","6be3adef":"code","c506925f":"code","8fc5f852":"code","657b6ce3":"code","111ebbd0":"code","5aefe804":"code","ad69fab3":"code","21b5d519":"code","5c4f60f8":"markdown","33589b60":"markdown","165d7dc6":"markdown","a3a955ee":"markdown","4dc93ae6":"markdown"},"source":{"b0f26f25":"import pandas as pd\nimport numpy as np\nimport gc\nfrom sklearn.metrics import roc_auc_score\nfrom collections import defaultdict\nfrom tqdm.notebook import tqdm\nimport lightgbm as lgb","e9ecd9b9":"train_pickle = '..\/input\/pickle1\/cv1_train.pickle'\nvalid_pickle = '..\/input\/pickle1\/cv1_valid.pickle'\nquestion_file = '..\/input\/riiid-test-answer-prediction\/questions.csv'\ndebug = False\nvalidaten_flg = False","3e04e21e":"train = pd.read_pickle(train_pickle)\nvalid = pd.read_pickle(valid_pickle)","8a0a8d35":"question_df = pd.read_pickle('..\/input\/questionspickle\/question.pickle')","ea88dcb0":"# def cal_method(type_of):\n#     return len(str(type_of).split(' '))\n# questions=pd.read_csv('..\/input\/riiid-test-answer-prediction\/questions.csv')\n# questions['enhence'] = questions['tags'].apply(cal_method)\n# questions['enhence'] = questions['enhence'].astype(np.int8)","8a2affd8":"question_df_avg =  question_df.question_average.mean()","317bfdfd":"# train = train.join(questions['enhence'],on=['content_id'],rsuffix='_question_average')\n# valid = valid.join(questions['enhence'],on=['content_id'],rsuffix='_question_average')\n","5ab850c8":"TARGET = 'answered_correctly'\nFEATS = ['answered_correctly_avg_u','content_id', 'answered_correctly_sum_u', 'count_u', 'answered_correctly_avg_c', 'prior_question_had_explanation', 'prior_question_elapsed_time']\ndro_cols = list(set(train.columns) - set(FEATS))\ny_tr = train[TARGET]\ny_va = valid[TARGET]\ntrain.drop(dro_cols, axis=1, inplace=True)\nvalid.drop(dro_cols, axis=1, inplace=True)\n_=gc.collect()","0da558ed":"train","ee944525":"prior_question_elapsed_time_mean = train.prior_question_elapsed_time.dropna().values.mean()\n","12a93fb8":"lgb_train = lgb.Dataset(train[FEATS], y_tr)\nlgb_valid = lgb.Dataset(valid[FEATS], y_va)\ndel train, y_tr,valid,y_va\n_=gc.collect()","6be3adef":"model = lgb.train(\n                    {'objective': 'binary',#,#,\n        # 'num_iterations' : 10},#50\n\n                    lgb_train,\n                    valid_sets=[lgb_train, lgb_valid],\n                    verbose_eval=10,\n                    num_boost_round=10000,\n                    early_stopping_rounds=10\n                )\n_ = lgb.plot_importance(model)","c506925f":"answered_correctly_sum_u_dict = defaultdict(int)\ncount_u_dict = defaultdict(int)\nvalid = pd.read_pickle(valid_pickle)\ny_va = valid[TARGET]\nprint('auc:', roc_auc_score(y_va, model.predict(valid[FEATS])))\n_ = lgb.plot_importance(model)\ndel valid,y_va","8fc5f852":"def add_user_feats_without_update(df, answered_correctly_sum_u_dict, count_u_dict):\n    acsu = np.zeros(len(df), dtype=np.int32)\n    cu = np.zeros(len(df), dtype=np.int32)\n    for cnt,row in enumerate(df[['user_id']].values):\n        acsu[cnt] = answered_correctly_sum_u_dict[row[0]]\n        cu[cnt] = count_u_dict[row[0]]\n    user_feats_df = pd.DataFrame({'answered_correctly_sum_u':acsu, 'count_u':cu})\n    user_feats_df['answered_correctly_avg_u'] = user_feats_df['answered_correctly_sum_u'] \/ user_feats_df['count_u']\n    df = pd.concat([df, user_feats_df], axis=1)\n    return df","657b6ce3":"content_df = pd.read_pickle('..\/input\/pickle1\/content.pickle')","111ebbd0":"# You can debug your inference code to reduce \"Submission Scoring Error\" with `validaten_flg = True`.\n# Please refer https:\/\/www.kaggle.com\/its7171\/time-series-api-iter-test-emulator about Time-series API (iter_test) Emulator.\nimport riiideducation\nenv = riiideducation.make_env()\niter_test = env.iter_test()\nset_predict = env.predict\nfor (test_df, sample_prediction_df) in iter_test:\n    previous_test_df = test_df.copy()\n    test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop=True)\n    test_df = add_user_feats_without_update(test_df, answered_correctly_sum_u_dict, count_u_dict)\n    test_df = pd.merge(test_df, content_df, on='content_id',  how=\"left\")\n    test_df = pd.merge(test_df, questions_df, left_on='content_id', right_on='question_id', how='left')\n    #test_df['prior_question_had_explanation'] = test_df.prior_question_had_explanation.fillna(False).astype('int8')\n    test_df['prior_question_elapsed_time_mean'] = test_df.prior_question_elapsed_time.fillna(prior_question_elapsed_time_mean)\n    test_df[TARGET] =  model.predict(test_df[FEATS])\n    set_predict(test_df[['row_id', TARGET]])","5aefe804":"answered_correctly_sum_u_dict.to_csv('answered_correctly_sum_u_dict.csv')","ad69fab3":"count_u_dict.to_csv('count_u_dict.csv')","21b5d519":"model.save_model('modelfeats7.txt')","5c4f60f8":"## setting\nCV files are generated by [this notebook](https:\/\/www.kaggle.com\/its7171\/cv-strategy)","33589b60":"## modeling","165d7dc6":"I want to convey two things in this notebook.\n## 1. Don't have to be hesitant about using Loop.\nThey say \"avoid loops!'.\nBut I think It's not bad idea to use loops for this competition.\nBecause:\n* We have to use small batch inference using Time-series API.\n* Loops have very small overhead for each batch.\n* Loops are more flexible.\n* Even loops are not so slow. 3 features are extracted within 10 minits for 100M train data, as you can see blow.\n\n## 2. Future information should not be used.\nTime-series API doesn't allow us to use information from the future.\nSo we should not use it, especially user statistics from future make things very bad.","a3a955ee":"## inference","4dc93ae6":"Have a fun with loops! :)"}}