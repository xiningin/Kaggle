{"cell_type":{"65447b31":"code","e8aa0702":"code","d0b5b488":"code","2fa3bf6e":"code","41202c4f":"code","6b414704":"code","03042574":"code","956a442a":"markdown","225b1b8a":"markdown","591323ec":"markdown","75741bb5":"markdown"},"source":{"65447b31":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","e8aa0702":"# Loading data\ndata    = pd.read_csv('..\/input\/credit-card-customers\/BankChurners.csv')\nm, n    = data.shape\ndata.drop(columns=[\n    'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n    'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2',\n    'CLIENTNUM'], \n          inplace=True)\ncolumns = data.columns.values\n\n# Data doesn't have any NaN\n# data.count()","d0b5b488":"# Transforming variable (categorical -> numerical)\ndata['Attrition_Flag'].replace({'Existing Customer': 0, \n                                'Attrited Customer': 1}, inplace=True)\ndata['Gender'].replace({'M': 1, \n                        'F': 0}, inplace=True)\ndata['Education_Level'].replace({'Unknown': 0, \n                                 'Uneducated': 1, \n                                 'High School': 2, \n                                 'College': 3, \n                                 'Graduate': 4, \n                                 'Post-Graduate': 5, \n                                 'Doctorate': 6}, inplace=True)\ndata['Marital_Status'].replace({'Unknown': 0,\n                                'Divorced': 1,\n                                'Married': 2,\n                                'Single': 3}, inplace=True)\ndata['Income_Category'].replace({'Unknown': 0,\n                                'Less than $40K': 1,\n                                '$40K - $60K': 2,\n                                '$60K - $80K': 3,\n                                '$80K - $120K': 4,\n                                '$120K +': 5}, inplace=True)\ndata['Card_Category'].replace({'Blue': 1,\n                               'Gold': 2,\n                               'Silver': 3,\n                               'Platinum': 4}, inplace=True)","2fa3bf6e":"# Corrleations  \ncorr = data.corr()\n\nfig, ax = plt.subplots(figsize=(8,8))\nim = ax.imshow(corr)\nax.set_xticks(np.arange(len(columns)))\nax.set_yticks(np.arange(len(columns)))\nax.set_xticklabels(columns)\nax.set_yticklabels(columns)\nax.set_title(\"Correlation matrix\")\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n         rotation_mode=\"anchor\")\n\nplt.show()","41202c4f":"from sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import train_test_split\n\n# Taking the train\/target dataset\ntarget = data['Attrition_Flag'].values\ntrain  = data.drop(columns=['Attrition_Flag']).values.astype('float')\n\nTEST_SIZE = 0.2\nsss = StratifiedShuffleSplit(n_splits=1, test_size=TEST_SIZE, random_state=232)\nfor train_index, test_index in sss.split(train, target):\n    x_train, x_test = train[train_index], train[test_index]\n    y_train, y_test = target[train_index], target[test_index]","6b414704":"# Data scaling\nfrom sklearn.preprocessing import StandardScaler\n\nscaler  = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test  = scaler.fit_transform(x_test)","03042574":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model    import LogisticRegression\nfrom sklearn.neighbors       import KNeighborsClassifier\nfrom sklearn.naive_bayes     import BernoulliNB\nfrom sklearn.ensemble        import AdaBoostClassifier\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import make_scorer\n\ndef recall(y, y_pred):\n    cm = confusion_matrix(y, y_pred)\n    return cm[1,1] \/ (cm[1,0] + cm[1,1])\n\ndef accuracy(y, y_pred):\n    cm = confusion_matrix(y, y_pred)\n    return (cm[0,0] + cm[1,1]) \/ (cm.sum())\n\nestimators = {'LogisticRegression': {'func': LogisticRegression(),\n                                     'params': {'C': [0.1, 0.5, 1, 1.2, 1.5]},\n                                     'rec': None},\n              'KNeighborsClassifier': {'func': KNeighborsClassifier(),\n                                     'params': {'n_neighbors': [5, 6, 7, 8, 9, 10, 11]},\n                                      'rec': None},\n              'BernoulliNB'        : {'func': BernoulliNB(),\n                                     'params': {'alpha': [0.1, 0.5, 1, 1.2, 1.5]},\n                                     'rec': None},\n              'AdaBoostClassifier' : {'func': AdaBoostClassifier(),\n                                      'params': {'learning_rate': [0.1, 0.5, 1, 1.2, 1.5]},\n                                      'rec': None}\n             }\n\nmodels_to_test = estimators.keys()\n\nfor name, estimator in estimators.items():\n    if name in models_to_test:\n        model = GridSearchCV(estimator=estimator['func'], \n                             param_grid=estimator['params'],\n                             scoring=make_scorer(recall))\n        model.fit(x_train, y_train)\n        preds = model.predict(x_test)\n        rec   = recall(y_test, preds)\n        acc   = accuracy(y_test, preds)\n        estimator[\"rec\"] = rec\n        print(f\"{name} Recall: {rec}, Accuracy: {acc} Best Params: {model.best_params_}\")\n\nbest_spec  = 0\nbest_model = None\nfor name, estimator in estimators.items():\n    if estimator[\"rec\"] > best_spec:\n        best_spec  = estimator[\"rec\"]\n        best_model = name\n    \nprint(f'Best model: {best_model}')      ","956a442a":"A bunch of classification models are tested. The business rule puts a focus on finding churners, so the models are tuned using the Recall as cost function.","225b1b8a":"Data are transformed from categorical to numerical, trying to preserve some sort of ordinality (e.g., card category \"Gold\" is an higher option than \"Silver\", so the map $M : \\text{Categorical} \\rightarrow \\mathbb{N}$ should be such that $M(\\text{Gold}) > M(\\text{Silver})$. Unknows are labelled $0$ for convenience.","591323ec":"No particulary strong correlations has been found among the features.","75741bb5":"Being the dataset unbalanced with respect to the target feature (\"Attrition_Flag\"), a stratified strategy has been chosen for the splitting."}}