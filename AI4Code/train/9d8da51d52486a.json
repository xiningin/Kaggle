{"cell_type":{"13a91930":"code","2772cbec":"code","c7aa8a39":"code","568816ec":"code","f15fd611":"code","88d3d2c6":"code","a7d3e4f3":"code","bfdb284f":"code","cc58b901":"code","d9713615":"code","eee05ac2":"code","5f3491d1":"code","cb349784":"code","33df9fec":"code","a11835f2":"code","237a19ba":"code","5bc5b31b":"code","860cbe4f":"code","306f5496":"code","15a60b5d":"code","415c5c72":"code","7e42ee19":"code","b6adf858":"code","7dc5c035":"code","9dd4c393":"code","f55134f3":"code","fd1bb4de":"code","fcd5772d":"code","3d229473":"code","a3417558":"code","242dd4c0":"code","e10bdbb4":"code","6b80bad3":"code","266bf63a":"code","4baf7207":"code","46dd26a7":"code","80add720":"code","e24d2cef":"code","92198529":"code","1b40d18f":"code","6ef85f6d":"code","cb53a8ce":"code","76dbeb9a":"code","8361d625":"code","1df0207a":"code","f1e2febe":"code","217bc370":"code","d28704da":"code","e599e0ad":"code","847033d0":"code","8d23ab50":"code","53318485":"code","600b08ab":"code","f260f463":"code","7390e930":"code","c44d11a8":"code","1f60cf23":"code","62bbf2bd":"code","622cc5f5":"code","19ea15ce":"code","d1cb85fe":"code","ac31998f":"markdown","416f496c":"markdown","72f7abf9":"markdown","c5a07610":"markdown","3b629fa6":"markdown","50570abf":"markdown","72575233":"markdown","c888c952":"markdown","966186a0":"markdown","5ae29d60":"markdown","d52401cd":"markdown","a0846f2c":"markdown","9f776ab0":"markdown","c32e324c":"markdown","3ffb3ff3":"markdown","f8c2b160":"markdown","9289a30e":"markdown","bb3af4fd":"markdown","20918956":"markdown","bd2aac3a":"markdown","2b160f29":"markdown","d3e63a14":"markdown","a68d445e":"markdown","33dd53f4":"markdown","19ee128f":"markdown","ee9f6a75":"markdown","458bc9ad":"markdown","453871ee":"markdown"},"source":{"13a91930":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.offline as pyo\nimport plotly.express as px\n\nimport seaborn as sns\nimport missingno as msno\n\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve,auc\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\nfrom mlxtend.plotting import plot_confusion_matrix\n\n%matplotlib inline\npyo.init_notebook_mode()","2772cbec":"df = pd.read_csv('..\/input\/rice-type-classification\/riceClassification.csv')\ndf","c7aa8a39":"df.columns","568816ec":"print('Total number of rows are:', df.shape[0])\nprint('Total number of columns are:', df.shape[1])","f15fd611":"df.describe()","88d3d2c6":"df.info()","a7d3e4f3":"df.isna().sum(axis=0)","bfdb284f":"msno.bar(df)","cc58b901":"print('There are total',df['Class'].nunique(),'unique values in the outcome column')\nprint('Unique values in outcome column are',df['Class'].unique())","d9713615":"print('Total number of 0(False count) are',(df['Class']==0).sum())\nprint('Total number of 1(True count) are',(df['Class']==1).sum())","eee05ac2":"plt.figure(figsize=(5,5))\ncolors = ['#04FFCD','#CCF500']\nsns.countplot(x='Class',data=df,palette=colors)\nplt.show()","5f3491d1":"df.drop(columns=['id'],inplace=True)\ndf","cb349784":"df.corr()","33df9fec":"correlation_mat = df.corr()\ncorr_features = correlation_mat.index\nplt.figure(figsize=(18,18))\ng = sns.heatmap(df[corr_features].corr(),annot=True,cmap='rainbow')\nplt.show()","a11835f2":"df","237a19ba":"fig, axes = plt.subplots(5,2, figsize=(20,25))\nfig.suptitle('Box Plot Before Outlier Detection')\nk = 0\nfor i in range(0,5):\n    for j in range(0,2):\n        sns.boxplot(ax=axes[i,j], data=df, x=df.columns[k], palette='Dark2')\n        k=k+1","5bc5b31b":"# Calculating the IQR\ndef iqr_calculation(main_df,col):\n    Q1 = np.percentile(col,25,interpolation = 'midpoint')\n    Q3 = np.percentile(col,75,interpolation = 'midpoint')\n    IQR = Q3 - Q1\n    upper = np.where(col>=(Q3+1.5*IQR))\n    lower = np.where(col<=(Q1-1.5*IQR))\n    return upper,lower\n    \n# Remove the outliers\ndef remove_outliers(main_df,upper,lower):\n    main_df.drop(upper[0], inplace = True)\n    main_df.drop(lower[0], inplace = True)\n    print(\"New Shape: \", main_df.shape)\n    return main_df\n\n# Resetting the dataframe index\ndef reset_dataframe(main_df):\n    main_df.reset_index(inplace=True)\n    main_df.drop(columns=['index'],inplace=True)\n    return main_df","860cbe4f":"main_df = df\n\nfor i in range(0,len(main_df.columns)-1):\n    print('For ',df.columns[i])\n    upper, lower = iqr_calculation(main_df,df[df.columns[i]])\n    main_df = remove_outliers(main_df,upper,lower)\n    final_df = reset_dataframe(main_df)","306f5496":"final_df","15a60b5d":"fig, axes = plt.subplots(5,2, figsize=(20,25))\nfig.suptitle('Box Plot After Removing the Outliers')\nk = 0\nfor i in range(0,5):\n    for j in range(0,2):\n        col_name = final_df.columns[k]\n        sns.boxplot(ax=axes[i,j], data=final_df,x=col_name,palette='Dark2')\n        k=k+1","415c5c72":"lst = [i for i in final_df.columns]\nfig = make_subplots(rows=5, cols=2,subplot_titles=(lst))\n\nk=0\nfor i in range(1,6):\n    for j in range(1,3):\n        col_name = final_df.columns[k]\n        fig.append_trace(go.Histogram(x=final_df[final_df.columns[k]],name=final_df.columns[k]), row=i, col=j)\n        fig.update_layout(\n                            template='plotly_dark',\n                            height=1500, \n                            width=1200,\n                            title_text=\"Histogram of all the input features\",\n                            font_family=\"Times New Roman\"\n                        )\n        k=k+1\n\nfig.show()","7e42ee19":"lst = [i for i in final_df.columns]\nfig = make_subplots(rows=5, cols=2,subplot_titles=(lst))\n\nk=0\nfor i in range(1,6):\n    for j in range(1,3):\n        col_name = final_df.columns[k]\n        fig.append_trace(go.Violin(y=final_df[final_df.columns[k]],name=final_df.columns[k],box_visible=True), row=i, col=j)\n        fig.update_layout(\n                            template='plotly_dark',\n                            height=2000, \n                            width=1200,\n                            title_text=\"Violin Plot of all the input features\",\n                            font_family=\"Times New Roman\"\n                        )\n        k=k+1\n\nfig.show()","b6adf858":"y = final_df['Class']\nX = final_df.drop(columns=['Class'])\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)","7dc5c035":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_train_scaled","9dd4c393":"X_test_scaled = scaler.transform(X_test)\nX_test_scaled","f55134f3":"from sklearn.linear_model import LogisticRegression as lr\nlr_model = lr()\nlr_model.fit(X_train_scaled,y_train)\ny_predicted = lr_model.predict(X_test_scaled)\nprint(\"Accuracy of Logistic Regression Model is = {0: .3f}\".format(metrics.accuracy_score(y_test,y_predicted)))","fd1bb4de":"print(\"Total 0's in training data:\",(y_train == 0).sum())\nprint(\"Total 1's in training data:\",(y_train == 1).sum())\nprint(\"Total 0's in testing data:\",(y_test == 0).sum())\nprint(\"Total 1's in testing data:\",(y_test == 1).sum())","fcd5772d":"importance = lr_model.coef_[0]\n\nfor i,v in enumerate(importance):\n\tprint('Feature: %0d, Score: %.5f' % (i,v))\n\nfig = px.bar(x=[x for x in range(len(importance))], y=importance)\nfig.update_layout(template='plotly_dark',\n                  height=700, \n                  width=1000,\n                  title_text=\"Feature score using Logistic Regression\",\n                  xaxis_title=\"Total number of features\",\n                  yaxis_title=\"Importance of each feature\",\n                  font=dict(\n                            family=\"Times New Roman, monospace\",\n                            size=14,\n                            color=\"White\"\n                           )\n                 )\nfig.show()","3d229473":"lr_model = lr()\n\nsolvers = ['newton-cg','lbfgs','liblinear']\npenalty = ['l2']\nc_values = [100, 10, 1.0, 0.1, 0.01]\n\ngrid = dict(solver=solvers,penalty=penalty,C=c_values)\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\ngrid_search_lr = GridSearchCV(estimator=lr_model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\ngrid_search_lr.fit(X_train_scaled, y_train)\n\nprint(grid_search_lr)\nprint(\"Best accuracy: %f using %s\" % (grid_search_lr.best_score_, grid_search_lr.best_params_))","a3417558":"y_score = grid_search_lr.predict_proba(X_test_scaled)[:, 1]\nfpr, tpr, thresholds = roc_curve(y_test, y_score)\nfig_hist = px.histogram(x=y_score, color=y_test,nbins=50,labels=dict(color='True Labels', x='Score'))\nfig_hist.show()","242dd4c0":"df = pd.DataFrame({\n    'False Positive Rate': fpr,\n    'True Positive Rate': tpr\n}, index=thresholds)\ndf.index.name = \"Thresholds\"\ndf.columns.name = \"Rate\"\n\nfig_thresh = px.line(\n    df, title='TPR and FPR at every threshold',\n)\n\nfig_thresh.update_yaxes(scaleanchor=\"x\", scaleratio=1)\nfig_thresh.update_xaxes(range=[0, 1], constrain='domain')\nfig_thresh.show()","e10bdbb4":"y_score = grid_search_lr.predict_proba(X_test_scaled)[:, 1]\n\nfpr, tpr, thresholds = roc_curve(y_test, y_score)\n\nfig = px.area(\n    x=fpr, y=tpr,\n    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n)\nfig.add_shape(\n    type='line', line=dict(dash='dash'),\n    x0=0, x1=1, y0=0, y1=1\n)\n\nfig.update_yaxes(showgrid=False,scaleanchor=\"x\", scaleratio=1)\nfig.update_xaxes(showgrid=False,constrain='domain')\nfig.show()","6b80bad3":"y_predicted = grid_search_lr.predict(X_test_scaled)\nprint(\"Accuracy of Logistic Regression Model after Hyper-Parameter Tuning is = {0: .3f}\".format(metrics.accuracy_score(y_test,y_predicted)))\nlr_score = metrics.accuracy_score(y_test,y_predicted)","266bf63a":"y_actual = y_test\ny_actual = y_actual.to_numpy() #  COnverting to numpy array\ny_actual","4baf7207":"target_names = ['class 0', 'class 1']\nprint(classification_report(y_actual, y_predicted, target_names=target_names))","46dd26a7":"conf_matrix = confusion_matrix(y_true=y_actual, y_pred=y_predicted)\nfig, ax = plot_confusion_matrix(conf_mat=conf_matrix, figsize=(8,8), cmap=plt.cm.Greens)\nplt.xlabel('Predictions', fontsize=18)\nplt.ylabel('Actuals', fontsize=18)\nplt.title('Confusion Matrix', fontsize=18)\nplt.show()","80add720":"from sklearn.tree import DecisionTreeClassifier\ndtc_model = DecisionTreeClassifier()\ndtc_model.fit(X_train_scaled,y_train)\ny_predicted = dtc_model.predict(X_test_scaled)\nprint(\"Accuracy of Decision Tree Model is = {0: .3f}\".format(metrics.accuracy_score(y_test,y_predicted)))","e24d2cef":"importance = dtc_model.feature_importances_\n\nfor i,v in enumerate(importance):\n\tprint('Feature: %0d, Score: %.5f' % (i,v))\n\nfig = px.bar(x=[x for x in range(len(importance))], y=importance)\nfig.update_layout(template='plotly_dark',\n                  height=700, \n                  width=1000,\n                  title_text=\"Feature score using Decision Tree Classifier\",\n                  xaxis_title=\"Total number of features\",\n                  yaxis_title=\"Importance of each feature\",\n                  font=dict(\n                            family=\"Times New Roman, monospace\",\n                            size=14,\n                            color=\"White\"\n                           )\n                 )\nfig.show()","92198529":"dtc_model = DecisionTreeClassifier()\nparams = {\n    'max_depth': [2, 3, 5, 10, 20],\n    'min_samples_leaf': [5, 10, 20, 50, 100],\n    'criterion': [\"gini\", \"entropy\"]\n}\n#cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\ngrid_search_dtc = GridSearchCV(estimator=dtc_model, param_grid=params, cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\ngrid_search_dtc.fit(X_train_scaled, y_train)\n\nprint(grid_search_dtc)\nprint(\"Best accuracy: %f using %s\" % (grid_search_dtc.best_score_, grid_search_dtc.best_params_))","1b40d18f":"score_df = pd.DataFrame(grid_search_dtc.cv_results_)\nscore_df.head(10)","6ef85f6d":"score_df.tail(10)","cb53a8ce":"y_score = grid_search_dtc.predict_proba(X_test_scaled)[:, 1]\nfpr, tpr, thresholds = roc_curve(y_test, y_score)\nfig_hist = px.histogram(x=y_score, color=y_test,nbins=50,labels=dict(color='True Labels', x='Score'))\nfig_hist.show()","76dbeb9a":"df = pd.DataFrame({\n    'False Positive Rate': fpr,\n    'True Positive Rate': tpr\n}, index=thresholds)\ndf.index.name = \"Thresholds\"\ndf.columns.name = \"Rate\"\n\nfig_thresh = px.line(\n    df, title='TPR and FPR at every threshold',\n)\n\nfig_thresh.update_yaxes(scaleanchor=\"x\", scaleratio=1)\nfig_thresh.update_xaxes(range=[0, 1], constrain='domain')\nfig_thresh.show()","8361d625":"y_score = grid_search_dtc.predict_proba(X_test_scaled)[:, 1]\n\nfpr, tpr, thresholds = roc_curve(y_test, y_score)\n\nfig = px.area(\n    x=fpr, y=tpr,\n    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n)\nfig.add_shape(\n    type='line', line=dict(dash='dash'),\n    x0=0, x1=1, y0=0, y1=1\n)\n\nfig.update_yaxes(showgrid=False,scaleanchor=\"x\", scaleratio=1)\nfig.update_xaxes(showgrid=False,constrain='domain')\nfig.show()","1df0207a":"y_predicted = grid_search_dtc.predict(X_test_scaled)\nprint(\"Accuracy of Decision Tree Model after Hyper-Parameter Tuning is = {0: .3f}\".format(metrics.accuracy_score(y_test,y_predicted)))\ndtc_score = metrics.accuracy_score(y_test,y_predicted)","f1e2febe":"y_actual = y_test\ny_actual = y_actual.to_numpy() #  COnverting to numpy array\ny_actual","217bc370":"target_names = ['class 0', 'class 1']\nprint(classification_report(y_actual, y_predicted, target_names=target_names))","d28704da":"conf_matrix = confusion_matrix(y_true=y_actual, y_pred=y_predicted)\nfig, ax = plot_confusion_matrix(conf_mat=conf_matrix, figsize=(8,8), cmap=plt.cm.Greens)\nplt.xlabel('Predictions', fontsize=18)\nplt.ylabel('Actuals', fontsize=18)\nplt.title('Confusion Matrix', fontsize=18)\nplt.show()","e599e0ad":"from sklearn.ensemble import RandomForestClassifier\nrfc_model = RandomForestClassifier()\nrfc_model.fit(X_train_scaled,y_train)\ny_predicted = rfc_model.predict(X_test_scaled)\nprint(\"Accuracy of Random Forest Classifier Model is = {0: .3f}\".format(metrics.accuracy_score(y_test,y_predicted)))","847033d0":"importance = rfc_model.feature_importances_\n\nfor i,v in enumerate(importance):\n\tprint('Feature: %0d, Score: %.5f' % (i,v))\n\nfig = px.bar(x=[x for x in range(len(importance))], y=importance)\nfig.update_layout(template='plotly_dark',\n                  height=700, \n                  width=1000,\n                  title_text=\"Feature score using Random Forest Classifier\",\n                  xaxis_title=\"Total number of features\",\n                  yaxis_title=\"Importance of each feature\",\n                  font=dict(\n                            family=\"Times New Roman, monospace\",\n                            size=14,\n                            color=\"White\"\n                           )\n                 )\nfig.show()","8d23ab50":"rfc_model = RandomForestClassifier()\nparams = {\n    'n_estimators' : [10, 100, 1000],\n    'max_features' : ['sqrt', 'log2']\n}\n#cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\ngrid_search_rfc = GridSearchCV(estimator=rfc_model, param_grid=params, cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\ngrid_search_rfc.fit(X_train_scaled, y_train)\n\nprint(grid_search_rfc)\nprint(\"Best accuracy: %f using %s\" % (grid_search_rfc.best_score_, grid_search_rfc.best_params_))","53318485":"score_df = pd.DataFrame(grid_search_rfc.cv_results_)\nscore_df","600b08ab":"y_score = grid_search_rfc.predict_proba(X_test_scaled)[:, 1]\nfpr, tpr, thresholds = roc_curve(y_test, y_score)\nfig_hist = px.histogram(x=y_score, color=y_test,nbins=50,labels=dict(color='True Labels', x='Score'))\nfig_hist.show()","f260f463":"df = pd.DataFrame({\n    'False Positive Rate': fpr,\n    'True Positive Rate': tpr\n}, index=thresholds)\ndf.index.name = \"Thresholds\"\ndf.columns.name = \"Rate\"\n\nfig_thresh = px.line(\n    df, title='TPR and FPR at every threshold',\n)\n\nfig_thresh.update_yaxes(scaleanchor=\"x\", scaleratio=1)\nfig_thresh.update_xaxes(range=[0, 1], constrain='domain')\nfig_thresh.show()","7390e930":"y_score = grid_search_rfc.predict_proba(X_test_scaled)[:, 1]\n\nfpr, tpr, thresholds = roc_curve(y_test, y_score)\n\nfig = px.area(\n    x=fpr, y=tpr,\n    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n)\nfig.add_shape(\n    type='line', line=dict(dash='dash'),\n    x0=0, x1=1, y0=0, y1=1\n)\n\nfig.update_yaxes(showgrid=False,scaleanchor=\"x\", scaleratio=1)\nfig.update_xaxes(showgrid=False,constrain='domain')\nfig.show()","c44d11a8":"y_predicted = grid_search_rfc.predict(X_test_scaled)\nprint(\"Accuracy of Decision Tree Model after Hyper-Parameter Tuning is = {0: .3f}\".format(metrics.accuracy_score(y_test,y_predicted)))\nrfc_score = metrics.accuracy_score(y_test,y_predicted)","1f60cf23":"y_actual = y_test\ny_actual = y_actual.to_numpy() #  COnverting to numpy array\ny_actual","62bbf2bd":"target_names = ['class 0', 'class 1']\nprint(classification_report(y_actual, y_predicted, target_names=target_names))","622cc5f5":"conf_matrix = confusion_matrix(y_true=y_actual, y_pred=y_predicted)\nfig, ax = plot_confusion_matrix(conf_mat=conf_matrix, figsize=(8,8), cmap=plt.cm.Greens)\nplt.xlabel('Predictions', fontsize=18)\nplt.ylabel('Actuals', fontsize=18)\nplt.title('Confusion Matrix', fontsize=18)\nplt.show()","19ea15ce":"models = pd.DataFrame({\n    'Model' : [ 'Logistic Regression', 'Decision Tree Classifier', 'Random Forest Classifier'],\n    'Score' : [ lr_score, dtc_score, rfc_score]\n})\nmodels.sort_values(by = 'Score', ascending = False)","d1cb85fe":"px.bar(data_frame = models, x = 'Score', y = 'Model', color = 'Score', template = 'plotly_dark', \n       title = 'Comparison of Classification Algorithms')","ac31998f":"## 5. Simple Data Visualization ","416f496c":"## 10. Conclusion ","72f7abf9":"> An observation which differs from an overall pattern on a sample dataset is called an **outlier**.\n\n> The outliers may suggest experimental errors, variability in a measurement, or an anomaly. The age of a person may wrongly be recorded as 200 rather than 20 Years. Such an outlier should definitely be discarded from the dataset.\n\n> However, not all outliers are bad. Some outliers signify that data is significantly different from others. For example, it may indicate an anomaly like bank fraud or a rare disease.","c5a07610":"### **Decision Tree Feature Importance**","3b629fa6":"### **Logistic Regression Feature Importance**\n\n> We can fit a Logistic Regression model on the given dataset and retrieve the coeff_ property that contains the coefficients found for each input variable.\n\n> These coefficients can provide the basis for a crude feature importance score. This assumes that the input variables have the same scale or have been scaled prior to fitting a model.\n\n> Results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision.\n\n> We know that it is a classification problem with classes 0 and 1. Notice that the coefficients are both positive and negative. The positive scores indicate a feature that predicts class 1, whereas the negative scores indicate a feature that predicts class 0.\n\n> No clear pattern of important and unimportant features can be identified from these results.","50570abf":"## 8. Decision Tree Algorithm ","72575233":"### Significance of Outliers","c888c952":"## 2. Checking whether dataset is balanced or not ","966186a0":"### **Hyperparameter Tuning**","5ae29d60":"## 6. Applying Standardization and Splitting the training data ","d52401cd":"> Outliers badly affect mean and standard deviation of the dataset. These may statistically give erroneous results.\n\n> Most machine learning algorithms do not work well in the presence of outlier. So it is desirable to detect and remove outliers.\n\n> Outliers are highly useful in anomaly detection like fraud detection where the fraud transactions are very different from normal transactions.","a0846f2c":"### **Hyperparameter Tuning**","9f776ab0":"## 3. Building correlation matrix","c32e324c":"> It is clear from the above output that there are no categorical columns present in the dataset.","3ffb3ff3":"> From the above output figure it is clear that the output classes are pretty well balanced and there is no need of sampling.","f8c2b160":"## 1. Performing simple operations on dataframe ","9289a30e":"### **Random Forest Classifier Feature Importance**","bb3af4fd":"## 4. Cleaning the data (Removing the outliers)","20918956":"## Name: Jay Shah\n## Date: 18\/08\/2021\n\n### Rice Classification Analysis","bd2aac3a":"> Feature selection process is the vital part in the whole life cycle.\n\n> It is clear from the dataframe that there is no need of Id column and hence our first step would be to remove that unnecessary column from the dataframe. ","2b160f29":"### Outliers","d3e63a14":"## 7. Logistic Regression Algorithm","a68d445e":"### Approach of Inter Quartile Range to detect outliers\n\n>  Inter Quartile Range approach to finding the outliers is the most commonly used and most trusted approach used in the research field.","33dd53f4":"* Below is the box plot which helps to explain IQR Method easily.\n\n   ![](https:\/\/miro.medium.com\/max\/1246\/1*0MvBAT8zFSOt6sfEojbI-A.png)\n\n> A box plot tells us, more or less, about the distribution of the data. It gives a sense of how much the data is actually spread about, what\u2019s its range, and about its skewness.\n\n> As you might have noticed in the figure, that a box plot enables us to draw inference from it for an ordered data, i.e., it tells us about the various metrics of a data arranged in ascending order.\n\n> In the above figure, **minimum** is the minimum value in the dataset and **maximum** is the maximum value in the dataset. So the difference between the two tells us about the range of dataset.   \n\n> The median is the median (or centre point), also called second quartile, of the data (resulting from the fact that the data is ordered).\n\n> Q1 is the first quartile of the data, i.e., to say 25% of the data lies between minimum and Q1.\n\n> Q3 is the third quartile of the data, i.e., to say 75% of the data lies between minimum and Q3.\n\n> The difference between Q3 and Q1 is called the **Inter-Quartile Range** or **IQR**.","19ee128f":"> Now, we will standardize the whole data.Data standardization is the process of rescaling the attributes so that they have mean as 0 and variance as 1.\n\n> The ultimate goal to perform standardization is to bring down all the features to a common scale without distorting the differences in the range of the values.\n\n> In sklearn.preprocessing.StandardScaler(), centering and scaling happens independently on each feature.\n\n> The formula which performs standardization is  (x\u2212mean)\/(sd) \n\n> fit_transform() is used on the training data so that we can scale the training data and also learn the scaling parameters of that data.","ee9f6a75":"> There are no missing numbers or empty values in any feature present in the dataset.","458bc9ad":"### **Hyperparameter Tuning**\n\n> Logistic regression does not really have any critical hyperparameters to tune. But sometimmes we can see useful differences in performance or convergence with different **solvers**.\n\n> Regularization(penalty) can also be useful sometimes.\n\n> The C parameter which is there helps to control the penalty strength, which can also be effective.\n\n> In the below code snippet, I have used the GridSearchCV in order to tune the hyperparameters.","453871ee":"## 9. Random Forest Algorithm "}}