{"cell_type":{"cb6b2474":"code","8beb85a0":"code","2c48c1e9":"code","a6e1a94f":"code","90c30bcd":"code","a61f1f19":"code","c2c8003c":"code","562751f5":"code","0cda71da":"markdown","73a0465f":"markdown","b3116f42":"markdown","dfc1e859":"markdown","fd40db5a":"markdown"},"source":{"cb6b2474":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","8beb85a0":"data = pd.read_csv('\/kaggle\/input\/byudatasciencecapstone\/magic04.csv')\ndata.info()","2c48c1e9":"from sklearn.model_selection import train_test_split\n\nX = data.iloc[:,:len(data.columns)-1]\nY = data['class']\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = 0, test_size = 0.3)\nX_train = X_train.to_numpy()\nX_test = X_test.to_numpy()","a6e1a94f":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\n\nprint(\"Training Accuracy:\", lr.score(X_train, y_train)) # Accuracy of the model when training.\nprint(\"Testing Accuracy:\", lr.score(X_test, y_test) ) # Accuracy of the test.","90c30bcd":"y_pred = lr.predict_proba(X)\nmySubmission = pd.DataFrame({'Id': range(len(data)), 'Predicted': y_pred[:,1]})\nmySubmission.head()\n\n# Use the following line to save your submisstion. You can use any filename. \n# mySubmission.to_csv('Magic04Submission.csv', index=False)","a61f1f19":"from xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n\nxgb = XGBClassifier()\nxgb.fit(X_train, y_train)\n\ny_pred = xgb.predict(X_train)\ntrain_predictions = [round(value) for value in y_pred]\n\ny_pred = xgb.predict(X_test)\ntest_predictions = [round(value) for value in y_pred]\n    \nprint(\"Training Accuracy:\",accuracy_score(train_predictions, y_train)) #Accuracy of the model when training.\nprint(\"Testing Accuracy:\", accuracy_score(test_predictions, y_test)) # Accuracy of the test.","c2c8003c":"y_pred = xgb.predict_proba(X.to_numpy())\n\nmySubmission = pd.DataFrame({'Id': range(len(data)), 'Predicted': y_pred[:,1]})\nmySubmission.head()\n\n# Use the following line to save your submisstion. You can use any filename. \n# mySubmission.to_csv('Magic04XGBClassifierSubmission.csv', index=False)","562751f5":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\n\nfpr, tpr, thresholds = metrics.roc_curve(Y.to_numpy(), y_pred[:,1])\nauc = metrics.auc(fpr, tpr)\n\n\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) curve')\nplt.legend(loc=\"lower right\")\nplt.show()","0cda71da":"# Now use an XGBClassifier","73a0465f":"### Use a simple logistic regression model for now.","b3116f42":"## Predict the probabilities for the whole training set and create the submission file","dfc1e859":"## Plot the ROC curve and compute the area under the curve (auc) for fun","fd40db5a":"# Sample kernel to demonstrate reading the file and creating the submission file"}}