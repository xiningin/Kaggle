{"cell_type":{"43773531":"code","18780842":"code","dfdeeb8e":"code","cb45239d":"code","6492e73c":"code","b93c70cd":"code","1c129e22":"code","3ec1dae2":"code","2ab3581e":"code","76678584":"code","3ec4a9f5":"markdown","f41a5cd0":"markdown","5b9b432e":"markdown","4ffa0cc3":"markdown","e0e38c3a":"markdown","c761b454":"markdown","4155df2b":"markdown","9a2531c1":"markdown","c8965811":"markdown","56d4177b":"markdown","1f0e76c7":"markdown","f0e91511":"markdown","6a004a36":"markdown"},"source":{"43773531":"import numpy as np \nimport pandas as pd \nimport tensorflow as tf #Neural Networks\nfrom sklearn.metrics import roc_auc_score,accuracy_score #metrics for our training\nimport cv2 \nimport matplotlib.pyplot as plt\nimport seaborn as sns # For plotting\nfrom PIL import Image #Image reader python\nimport os","18780842":"infected_dir = '..\/input\/cell_images\/cell_images\/Parasitized\/'\nnoninfected_dir = '..\/input\/cell_images\/cell_images\/Uninfected\/'\n\nimg_paths_infected = sorted(\n        [\n        os.path.join(infected_dir, fname)\n        for fname in os.listdir(infected_dir)\n        if fname.endswith(\".png\")\n        ])\n\nimg_paths_noninfected = sorted(\n        [\n        os.path.join(noninfected_dir, fname)\n        for fname in os.listdir(noninfected_dir)\n        if fname.endswith(\".png\")\n        ])\nprint(f\"Number of samples Infected: {len(img_paths_infected)}\")\nprint(f\"Number of samples Non-Infected: {len(img_paths_noninfected)}\")","dfdeeb8e":"image_infected = cv2.imread(img_paths_infected[0])\nimage_noninfected = cv2.imread(img_paths_noninfected[0])\n\n\nfig = plt.figure(figsize=(12,6))\ngs = fig.add_gridspec(1, 2)\nax1 = fig.add_subplot(gs[0, 0])\nax2 = fig.add_subplot(gs[0, 1])\n\nax1.imshow(image_noninfected)\nax1.set_title(\"Non-Infected\", size=16)\n\nax2.imshow(image_infected)\nax2.set_title(\"Infected\", size=16)\nplt.show()\n\nprint(f\"Shape Infected: {image_infected.shape} \\nShape Non-Infected: {image_noninfected.shape}\")","cb45239d":"import random\n\n# Shuffle the data\nrandom.Random(42).shuffle(img_paths_infected)\nrandom.Random(42).shuffle(img_paths_noninfected)\n\n# Choose the percentage of the data that you want for your \n# validation, here I choose 30%.\nvalidation_split = 0.3\nval_samples_infected = int(validation_split*len(img_paths_infected))\n\npaths_infected_train = img_paths_infected[val_samples_infected:] \npaths_infected_test = img_paths_infected[:val_samples_infected] \n\nval_samples_noninfected = int(validation_split*len(img_paths_noninfected))\n\npaths_noninfected_train = img_paths_noninfected[val_samples_noninfected:] \npaths_noninfected_test = img_paths_noninfected[:val_samples_noninfected] \n\nprint(f\"Number of training samples for infected \/ noninfected: {2*len(paths_infected_train)}\")\nprint(f\"Number of validation samples for infected \/ noninfected: {2*len(paths_noninfected_test)}\")","6492e73c":"train_labels = ['Infected']*len(paths_infected_train)\ntrain_labels.extend(['Noninfected']*len(paths_noninfected_train))\n\ntest_labels = ['Infected']*len(paths_infected_test)\ntest_labels.extend(['Noninfected']*len(paths_noninfected_test))\n\npaths_train = paths_infected_train\npaths_train.extend(paths_noninfected_train)\n\npaths_test = paths_infected_test\npaths_test.extend(paths_noninfected_test)\n\nprint(f\"Number of training samples for infected \/ noninfected: {len(paths_train)}\")\nprint(f\"Number of validation samples for infected \/ noninfected: {len(paths_test)}\")","b93c70cd":"train_df = pd.DataFrame({'train_dir': paths_train})\ntrain_df['train_labels'] =  train_labels\n\ntest_df = pd.DataFrame({'test_dir': paths_test})\ntest_df['test_labels'] = test_labels","1c129e22":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nbatch_size = 36\nimg_size = (142, 142)\n\ntrain_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\nprint(\"Training dataset:\")\ntrain_generator = train_datagen.flow_from_dataframe(\n        train_df,\n        x_col='train_dir',\n        y_col='train_labels',   \n        target_size=img_size, \n        batch_size=batch_size,\n        class_mode='binary')  \n\nprint(\"Test dataset:\")\ntest_generator = test_datagen.flow_from_dataframe(\n        test_df,\n        x_col='test_dir',\n        y_col='test_labels',   \n        target_size= img_size,\n        batch_size=batch_size,\n        class_mode='binary')  ","3ec1dae2":"#seeding random seed so I can get consistent results\ntf.set_random_seed(10)\nmodel =  tf.keras.Sequential([\n    \n    #convolutional layers\n    tf.keras.layers.Conv2D(32, (3,3),strides=2 , activation='relu', \n                           input_shape= img_size + (3,), padding='same'),    \n    \n    tf.keras.layers.Conv2D(64, (3,3), strides=2, activation='relu',padding='same'),        \n    \n    tf.keras.layers.Conv2D(128, (3,3), strides=2, activation='relu',padding='same'),        \n    \n    # Dense layers\n    tf.keras.layers.Flatten(),    \n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', \n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nmodel.summary()","2ab3581e":"history = model.fit(train_generator,\n                    steps_per_epoch= 400 \/\/ batch_size,\n                    epochs=10,\n                    validation_data=test_generator,\n                    validation_steps=50 \/\/ batch_size,\n                    )","76678584":"#Plot accuracy and loss per epoch\n\n#accuracy\ntrain_accuracy = history.history['acc']\nvalidation_accuracy = history.history['val_acc']\n\n#loss \ntrain_loss = history.history['loss']\nvalidation_loss = history.history['val_loss']\n\nepoch_range = range(1,len(train_accuracy)+1)\n\nfig, ax = plt.subplots(1, 2, figsize=(10,5))\n\n#accuracy\nax[0].set_title('Accuracy per Epoch')\nsns.lineplot(x=epoch_range,y=train_accuracy,marker='o',ax=ax[0])\nsns.lineplot(x=epoch_range,y=validation_accuracy,marker='o',ax=ax[0])\nax[0].legend(['training','validation'])\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Accuracy')\nax[0].set_xticks([2,4,6,8,10])\nax[0].set_yticks([.6,.7,.8,.9,1.0])\nax[0].set_yticklabels(['60%','70%','80%','90%','100%'])\n#loss\nax[1].set_title('Loss per Epoch')\nsns.lineplot(x=epoch_range,y=train_loss,marker='o',ax=ax[1])\nsns.lineplot(x=epoch_range,y=validation_loss,marker='o',ax=ax[1])\nax[1].legend(['training','validation'])\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Loss')\nax[1].set_xticks([2,4,6,8,10])\nplt.show()","3ec4a9f5":"# 1.3) Splitting training and test data\n\nNow we shall split which images goes to the training and which goes to the test data. This is done by shuffling and splitting the list of infected samples and non-infected samples, after this we add those paths to a train_df and a test_df.","f41a5cd0":"## 2.1) Convulational Neural Network\nAfter setting a random seed for reproducibility, we shall create our model as follows:\n\n- Padding is used in order to not lose information on images' borders. \n- We use 3 convolutional layers with increasing filters and I choose to use strides instead of MaxPooling.\n- We flatten them and pass to a dense layer.\n- We output the probability associated with each class using a sigmoid activation on the last layer, since we chose to use binary classes.\n- We Compile it using Adam optimizer and `binary_crossentropy` as a loss funcion.","5b9b432e":"Let's create a dataframe with paths to the training\/validation data in order to use the keras.preprocessing method flow_from_dataframe. Personally I think that this is better than moving directories around.","4ffa0cc3":"# 0) Imports\n\nHere I import important packages such as numpy, pandas, tensorflow...","e0e38c3a":"# 1.1) Getting the data path\n\nFirstly lets get all files that are part of the dataset and their paths, the purpose is to create a data pipeline and use `ImageDataGenerator` from keras.preprocessing package, there are several ways that we can build the data pipeline. Here is an exemple which I follow the [keras.io tutorial](https:\/\/keras.io\/api\/preprocessing\/image\/) to get all paths of images which I will feed into a pandas DataFrame to use the `flow_from_dataframe` method.","c761b454":"# 2.1.3) Results of the CNN Model","4155df2b":"# 2) Models","9a2531c1":"# 1.2) Example of the data\n\nLet's one example of each type of cell","c8965811":"# 1) Data","56d4177b":"Now since everything is in the right place, we shall use `ImageDataGenerator`. \n\nSince we are working with images, we shall rescale them in order to have values in the [0,1] range, we shall resize the images in the desired square size that we want and since we are working with only two classes of images we shall use the binary class mode and use `binary_crossentropy` as a loss function. Remember that if you choose the categorical class mode, you should use the `categorical_crossentropy` or `sparse_categorical_crossentropy` as a loss function.","1f0e76c7":"### 2.1.2) Training the CNN","f0e91511":"## 2.1.1) Creating the CNN","6a004a36":"# Detecting malaria using Keras\n\nIn this notebook I will show how to use a Convolutional Neural Network in order to determine if a cell is infected with malaria or not. There are several cool things that are showcased in this notebook, for instance I show how build a data pipeline using `flow_from_dataframe` from keras.preprocessing.image package."}}