{"cell_type":{"eaa46f1f":"code","5a7d9de6":"code","abf8f5cb":"code","161cf4d4":"code","3bd069f4":"code","b707c020":"code","aefd25ad":"code","51b6f664":"code","756a1863":"code","6171a5b9":"code","c70aad19":"code","78ad3554":"code","9dd87375":"code","47fc6dd8":"code","ba75e542":"code","330b4dfd":"code","6fcbbb3d":"code","c4316509":"code","fe4e0771":"code","dceba375":"code","400e12ca":"code","122f2c72":"code","353b9367":"code","382b064d":"code","8f20f947":"code","ae15e294":"code","ef2fcff6":"code","96485c20":"code","9d53f5b3":"code","6c6a7c53":"code","827188b2":"code","d98699a2":"code","49e29c50":"code","767fa18d":"code","8da75942":"code","0f11c126":"code","df5af638":"code","04bb5f9c":"code","09409c74":"code","bfe8318e":"code","e329f3c8":"code","e59daac7":"code","2943c36b":"code","6f4e3712":"code","ab32604a":"code","e4098b7a":"code","f121fc43":"code","ea15448a":"code","8d3efb1e":"code","f8e2a3df":"code","28091549":"code","d0457b6c":"code","1125d39e":"code","e9e9b5ca":"code","7e772590":"markdown","d96f8ed1":"markdown","11d80ace":"markdown","2ac66e9f":"markdown","97cec32e":"markdown","71e5a4be":"markdown","fcd1bcce":"markdown","d24dd275":"markdown","947a78d2":"markdown","c932060b":"markdown","5fce5648":"markdown","18a39e19":"markdown","a5c00df7":"markdown","ddc32c61":"markdown","36daa1f2":"markdown","357eb8d7":"markdown","ac9d5c18":"markdown","9b1a7b09":"markdown","ccdf3502":"markdown","81e74744":"markdown","c22d4096":"markdown","2f487d64":"markdown","e7cf1494":"markdown","175b5069":"markdown","42ff39b5":"markdown","ff81b01d":"markdown","81101a8b":"markdown","842dd697":"markdown","58eed538":"markdown","385e84c6":"markdown"},"source":{"eaa46f1f":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import pearsonr\nfrom scipy import stats","5a7d9de6":"%time df = pd.read_csv(\"..\/input\/students-performance-in-exams\/StudentsPerformance.csv\")","abf8f5cb":"df.head()","161cf4d4":"for label, content in df.items():\n    print(\"%s:\" % label, df[label].unique())","3bd069f4":"len(df)","b707c020":"df.groupby(['gender']).size()","aefd25ad":"df.groupby(['race\/ethnicity']).size()","51b6f664":"df.groupby(['parental level of education']).size()","756a1863":"df.groupby(['lunch']).size()","6171a5b9":"df.groupby(['test preparation course']).size()","c70aad19":"new_df = pd.DataFrame({})\ngender_list = []\ngender_labels = ['male', 'female']\nfor i in range(len(df)):\n    gender_list.append(gender_labels.index(df['gender'][i]))\n\nnew_df['gender'] = gender_list\nnew_df.head()","78ad3554":"race_list = []\nrace_labels = ['group A', 'group B', 'group C', 'group D', 'group E']\nfor i in range(len(df)):\n    race_list.append(race_labels.index(df['race\/ethnicity'][i]))\n        \nnew_df['race'] = race_list\nnew_df.head()","9dd87375":"college_list = []\ncollege_labels = ['some high school', 'high school', 'some college', \"associate's degree\", \"bachelor's degree\", \"master's degree\"]\nfor i in range(len(df)):\n    college_list.append(college_labels.index(df['parental level of education'][i]))\n        \nnew_df['parental_college'] = college_list\nnew_df.head()","47fc6dd8":"lunch_list = []\nlunch_labels = ['free\/reduced', 'standard']\nfor i in range(len(df)):\n    lunch_list.append(lunch_labels.index(df['lunch'][i]))\n    \nnew_df['lunch'] = lunch_list\nnew_df.head()","ba75e542":"prep_list = []\nprep_labels = ['none', 'completed']\nfor i in range(len(df)):\n    prep_list.append(prep_labels.index(df['test preparation course'][i]))\n\nnew_df['prep'] = prep_list\nnew_df.head()","330b4dfd":"college_race_list = [[0 for j in range(len(race_labels))] for i in range(len(college_labels))]\nfor i in range(len(new_df)):\n    college_race_list[new_df['parental_college'][i]][new_df['race'][i]] += 1\n    \ncollege_race_df = pd.DataFrame(college_race_list)","6fcbbb3d":"college_race_df.plot.bar(rot=0, figsize=(10, 8))\nplt.legend(race_labels)\nplt.xticks(np.arange(0, len(college_labels)), labels=college_labels, rotation=0)\nplt.title(\"Parental Level of Education vs Race\/Ethnicity\", fontsize=20)\nplt.show()","c4316509":"df.groupby(['race\/ethnicity', 'parental level of education']).size()","fe4e0771":"plt.figure(figsize=(10, 8))\nsns.barplot(x=\"race\", y=\"prep\", data=new_df)\nplt.xticks(np.arange(0, len(race_labels)), labels=race_labels, rotation=0)\nplt.xlabel('', fontsize=16)\nplt.ylabel('Proportion of Students Who Completed Prep', fontsize=14)\nplt.title(\"Race\/Ethnicity vs Prep Course Completion\", fontsize=20)\nplt.show()","dceba375":"df.groupby(['race\/ethnicity', 'test preparation course']).size()","400e12ca":"plt.figure(figsize=(10, 8))\nsns.barplot(x=\"parental_college\", y=\"prep\", data=new_df)\nplt.xticks(np.arange(0, len(college_labels)), labels=college_labels, rotation=0)\nplt.xlabel('', fontsize=16)\nplt.ylabel('Proportion of Students Who Completed Prep', fontsize=14)\nplt.title(\"Parental Education vs Prep Course Completion\", fontsize=20)\nplt.show()","122f2c72":"df.groupby(['parental level of education', 'test preparation course']).size()","353b9367":"plt.figure(figsize=(10, 8))\nsns.barplot(x=\"gender\", y=\"prep\", data=new_df)\nplt.xticks(np.arange(0, len(gender_labels)), labels=gender_labels, rotation=0)\nplt.xlabel('', fontsize=16)\nplt.ylabel('Proportion of Students Who Completed Prep', fontsize=14)\nplt.title(\"Gender vs Prep Course Completion\", fontsize=20)\nplt.show()","382b064d":"df.groupby(['gender', 'test preparation course']).size()","8f20f947":"plt.figure(figsize=(10, 8))\nsns.barplot(x=\"race\", y=\"lunch\", data=new_df)\nplt.xticks(np.arange(0, len(race_labels)), labels=race_labels, rotation=0)\nplt.xlabel('', fontsize=16)\nplt.ylabel('Proportion of Students Lunch', fontsize=14)\nplt.title(\"Race\/Ethnicity vs Lunch\", fontsize=20)\nplt.show()","ae15e294":"df.groupby(['race\/ethnicity', 'lunch']).size()","ef2fcff6":"plt.figure(figsize=(10, 8))\nsns.barplot(x=\"parental_college\", y=\"lunch\", data=new_df)\nplt.xticks(np.arange(0, len(college_labels)), labels=college_labels, rotation=0)\nplt.xlabel('', fontsize=16)\nplt.ylabel('Proportion of Students Lunch', fontsize=14)\nplt.title(\"Parental Education vs Lunch\", fontsize=20)\nplt.show()","96485c20":"df.groupby(['parental level of education', 'lunch']).size()","9d53f5b3":"plt.figure(figsize=(10, 8))\nsns.barplot(x=\"lunch\", y=\"prep\", data=new_df)\nplt.xticks(np.arange(0, len(lunch_labels)), labels=lunch_labels, rotation=0)\nplt.xlabel('', fontsize=16)\nplt.ylabel('Proportion of Students Who Completed Prep', fontsize=14)\nplt.title(\"Lunch vs Prep Course Completion\", fontsize=20)\nplt.show()","6c6a7c53":"df.groupby(['lunch', 'test preparation course']).size()","827188b2":"def print_info(data):\n    print(\"Mean of Scores: %.3f\" % np.mean(data))\n    print(\"Median of Scores: %.3f\" % np.median(data))\n    print(\"Standard Deviation of Scores: %.3f\" % np.std(data))\n    intv1 = np.mean(data)-2*np.std(data)\n    intv2 = np.mean(data)+2*np.std(data)\n    print(\"95%c confidence interval: %.3f to %.3f\" % ('%', intv1, intv2))\n    quant1 = np.quantile(data, 0.025)\n    quant2 = np.quantile(data, 0.975)\n    print(\"95%c of data is between %.3f and %.3f\" % ('%', quant1, quant2))\n    print(\"Skew of the distribution is %.3f\" % (stats.skew(data)))\n    print(\"Kurtosis of the distribution is %.3f\" % (stats.kurtosis(data)))\n    print(\"Exccess kurtosis of the distribution is %.3f\" % (stats.kurtosis(data)-3))","d98699a2":"print_info(df['reading score'])\n\nplt.figure(figsize=(10, 8))\nsns.distplot(df['reading score'], kde_kws = {'linewidth': 3})\nplt.show()","49e29c50":"print_info(df['writing score'])\n\nplt.figure(figsize=(10, 8))\nsns.distplot(df['writing score'], kde_kws = {'linewidth': 3})\nplt.show()","767fa18d":"print_info(df['math score'])\n\nplt.figure(figsize=(10, 8))\nsns.distplot(df['math score'], kde_kws = {'linewidth': 3})\nplt.show()","8da75942":"plt.figure(figsize=(10, 8))\nsns.distplot(df['reading score'], hist=False, kde_kws = {'linewidth': 3, 'shade': True})\nsns.distplot(df['writing score'], hist=False, kde_kws = {'linewidth': 3, 'shade': True})\nsns.distplot(df['math score'], hist=False, kde_kws = {'linewidth': 3, 'shade': True})\nplt.legend(['reading score', 'writing score', 'math score'])\nplt.xlabel('Score', fontsize=16)\nplt.title(\"All Distributions Stacked on Each Other\", fontsize=20)\nplt.show()","0f11c126":"plt.figure(figsize=(10, 8))\nplt.title(\"Reading Score vs Math Score, correlation: %.3f\" % (pearsonr(df['math score'], df['reading score'])[0]), fontsize=20)\nplt.scatter(df['reading score'], df['math score'])\nplt.xlabel(\"Reading Score\", fontsize=16)\nplt.ylabel(\"Math Score\", fontsize=16)\nplt.show()","df5af638":"plt.figure(figsize=(10, 8))\nplt.title(\"Writing Score vs Math Score, correlation: %.3f\" % (pearsonr(df['math score'], df['writing score'])[0]), fontsize=20)\nplt.scatter(df['writing score'], df['math score'])\nplt.xlabel(\"Writing Score\", fontsize=16)\nplt.ylabel(\"Math Score\", fontsize=16)\nplt.show()","04bb5f9c":"plt.figure(figsize=(10, 8))\nplt.title(\"Reading Score vs Writing Score, correlation: %.3f\" % (pearsonr(df['writing score'], df['reading score'])[0]), fontsize=20)\nplt.scatter(df['reading score'], df['writing score'])\nplt.xlabel(\"Reading Score\", fontsize=16)\nplt.ylabel(\"Writing Score\", fontsize=16)\nplt.show()","09409c74":"labels_list = ['math score', 'reading score', 'writing score']\n\nfig, ax = plt.subplots(1, 3, figsize=(30, 8))\n\nr = 0\nfor label in labels_list:\n    df1 = df.sort_values(\"gender\")\n    sns.barplot(x=\"gender\", y=label, data=df1, ax=ax[r])\n    ax[r].set_xlabel('', fontsize=16)\n    ax[r].set_ylabel('%ss' % label, fontsize=14)\n    ax[r].set_title(\"Gender vs %ss\"% label, fontsize=20)\n    r += 1\n\nfig.tight_layout()\nplt.show()","bfe8318e":"fig, ax = plt.subplots(1, 3, figsize=(30, 8))\n\nr = 0\nfor label in labels_list:\n    df1 = df.sort_values(\"race\/ethnicity\")\n    sns.barplot(x=\"race\/ethnicity\", y=label, data=df1, ax=ax[r])\n    ax[r].set_xlabel('', fontsize=16)\n    ax[r].set_ylabel('%ss' % label, fontsize=14)\n    ax[r].set_title(\"Race\/Ethnicity vs %ss\"% label, fontsize=20)\n    r += 1\n\nfig.tight_layout()\nplt.show()","e329f3c8":"fig, ax = plt.subplots(1, 3, figsize=(30, 8))\n\nr = 0\nfor label in labels_list:\n    df1 = df.sort_values(\"parental level of education\")\n    sns.barplot(x=\"parental level of education\", y=label, data=df1, ax=ax[r])\n    ax[r].set_xlabel('', fontsize=16)\n    ax[r].set_ylabel('%ss' % label, fontsize=14)\n    ax[r].set_title(\"Parental Education vs %ss\"% label, fontsize=20)\n    r += 1\n\nfig.tight_layout()\nplt.show()","e59daac7":"fig, ax = plt.subplots(1, 3, figsize=(30, 8))\n\nr = 0\nfor label in labels_list:\n    df1 = df.sort_values(\"lunch\")\n    sns.barplot(x=\"lunch\", y=label, data=df1, ax=ax[r])\n    ax[r].set_xlabel('', fontsize=16)\n    ax[r].set_ylabel('%ss' % label, fontsize=14)\n    ax[r].set_title(\"Lunch vs %ss\"% label, fontsize=20)\n    r += 1\n\nfig.tight_layout()\nplt.show()","2943c36b":"fig, ax = plt.subplots(1, 3, figsize=(30, 8))\n\nr = 0\nfor label in labels_list:\n    df1 = df.sort_values(\"test preparation course\")\n    sns.barplot(x=\"test preparation course\", y=label, data=df1, ax=ax[r])\n    ax[r].set_xlabel('', fontsize=16)\n    ax[r].set_ylabel('%ss' % label, fontsize=14)\n    ax[r].set_title(\"Test Preparation vs %ss\"% label, fontsize=20)\n    r += 1\n\nfig.tight_layout()\nplt.show()","6f4e3712":"from sklearn.ensemble import RandomForestRegressor\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nregressor = RandomForestRegressor(max_features='auto')","ab32604a":"regressor.fit(new_df, df['reading score'])\nperm_import = PermutationImportance(regressor, random_state=1).fit(new_df, df['reading score'])\neli5.show_weights(perm_import, top=15, feature_names = new_df.columns.tolist())","e4098b7a":"regressor.fit(new_df, df['writing score'])\nperm_import = PermutationImportance(regressor, random_state=1).fit(new_df, df['writing score'])\neli5.show_weights(perm_import, top=15, feature_names = new_df.columns.tolist())","f121fc43":"regressor.fit(new_df, df['math score'])\nperm_import = PermutationImportance(regressor, random_state=1).fit(new_df, df['math score'])\neli5.show_weights(perm_import, top=15, feature_names = new_df.columns.tolist())","ea15448a":"df['average score'] = df.loc[:, df.columns.str.contains('score')].mean(axis=1)","8d3efb1e":"df.head()","f8e2a3df":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\n\nohe = OneHotEncoder()\nscaler = MinMaxScaler()\nx_arr = np.array(ohe.fit_transform(df.loc[:, ~df.columns.str.contains('score')]).todense())\ny_arr = df['average score'].to_numpy().reshape(-1, 1)\ny_transform = scaler.fit_transform(y_arr)\n\nend = 800\nx_train = x_arr[:end]\nx_test = x_arr[end:]\ny_train = y_transform[:end]\ny_test = y_transform[end:]","28091549":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.regularizers import l2\nfrom keras.initializers import GlorotNormal\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping\n\nmodel = Sequential()\nmodel.add(Dense(units=64, kernel_initializer=GlorotNormal(), activation='relu'))\nmodel.add(Dense(1))\nmodel.compile(loss='mse', optimizer=Adam(learning_rate=1e-5))\n\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=1e-5)\nhistory = model.fit(x_train, y_train, epochs=10000, verbose=0, validation_data=(x_test, y_test), callbacks=[es])","d0457b6c":"plt.figure(figsize=(10, 8))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['loss', 'val_loss'])\nplt.xlabel(\"\")\nplt.ylabel(\"Mean Squared Error\", fontsize=16)\nplt.show()","1125d39e":"predict = scaler.inverse_transform(model.predict(x_test))\npredict","e9e9b5ca":"print(\"Average Error: %.3f\" % abs(y_arr[end:]-predict).mean())","7e772590":"Children with standard lunch plans do far better than children with free\/reduced lunch plans across the board.","d96f8ed1":"0 - some high school\n\n1 - high school\n\n2 - some college\n\n3 - associates\n\n4 - bachelors\n\n5 - masters","11d80ace":"0 - no test prep\n\n1 - completed test prep","2ac66e9f":"Children who receive standard lunch plans seems to complete the test course a bit less.","97cec32e":"Almost negligible difference here, with males completing the course only *slightly* more times.","71e5a4be":"0 - free\/reduced\n\n1 - standard","fcd1bcce":"Through the board, group C looks like the largest group, so perhaps Caucasian\/white? Group D has an unusually high number of people who pursue master degrees, so perhaps Asian? And then group A has the lowest number of degree-pursuers, so probably hispanic\/latinx\/black? Knowing what education is available in the United States gives us a pretty reasonable guess as to what the groups may stand for.","d24dd275":"All distributions have negative excess kurotsis, so they are all platykurtic (we don't expect many extreme events near the tails of the distribution).","947a78d2":"Males do much better in math than females, but do much worse in both reading and writing.","c932060b":"Very impressive correlation between reading score and writing score!","5fce5648":"Group A receives free\/reduced lunch most, furthering the previous observation that group A may be a minority group.","18a39e19":"# Correlation Between Features and Scores","a5c00df7":"And that's it for this notebook! There are definitely some optimizations to be made for the neural network if you would like to experiment with it; in particular, generate more data (1000 is very little) through random Gaussian noise and optimizing the neural network architecture (I use a basic dense layer but autoencoders and random forests etc. can definitely be used).\n\nFinally, if you found this notebook particularly educational or helpful, please give it an <span style=\"color:green\"> upvote! <\/span> And if you would like, check out some of my other work, I recently made some chess visualizations that I think are kind of cool.","ddc32c61":"# Distribution of and Correlation within Scores","36daa1f2":"It seems like children with parents from \"high school\" do the worst, and children of parents with master degrees do the best. This proves an unsurprising fact: parents with a better degree will, on average, earn more money and be able to support their child's education with key resources (and of course, their own expertise).","357eb8d7":"# Generate numerical data for easier computation","ac9d5c18":"Interestingly, although preparation seemed like the biggest factor in our visual analysis, random forest permutation says it's actually one of the less important features. Instead, the child's parent's college education seems like the most important feature.","9b1a7b09":"Group E is the hardest working, whereas group D seems like the least hard working. Not sure if this graph proves or disproves that Group D is Asian, as there's an argument for both sides; perhaps Asian parents would force their kid to complete the test prep course, or maybe they would see no need for the prep course and therefore not complete it.","ccdf3502":"# How many of each feature is there?","81e74744":"0 - Group A\n\n1 - Group B\n\n2 - Group C\n\n3 - Group D\n\n4 - Group E","c22d4096":"Group E has the best scores across the board, perhaps due to their preparation (recall that group E also completed the prep course, on average, the most times). Group D does quite well for having the lowest prep course completion out of all groups.","2f487d64":"# Random Forest Permutation Importance","e7cf1494":"Although children of parents with master's degrees seem to receive free\/reduced lunch the most, the standard deviation is far too great to conclude that children of parents with master's degrees are most poor.","175b5069":"# Correlation Within Features","42ff39b5":"# Students Performance in Exams EDA + Neural Network\n\nIn this notebook, I aim to analyze how different features are correlated with each other and how they are correlated with math, reading, and writing scores. If you like this notebook, please give it an <span style=\"color:green\"> upvote! <\/span> I would greatly appreciate it.\n\n<h2> Table of Contents <\/h2>\n<ol>\n    <li> Reading the Data <\/li>\n    <li> Data Preprocessing <\/li>\n    <li> Feature Correlation <\/li>\n    <li> Score Correlation <\/li>\n    <li> Features and Scores <\/li>\n    <li> Basic Neural Network Implementation <\/li>","ff81b01d":"It seems like children of parents from just \"some high school\" are most hardworking, as on average, they complete the course most often. This may just be an anomaly though since children of parents from \"high school\" seem like the least hardworking.","81101a8b":"# Simple Neural Network Implementation","842dd697":"Of course, children who complete the test course do far better than those who do not.","58eed538":"# What features are there that we can use?","385e84c6":"0 - male\n\n1 - female"}}