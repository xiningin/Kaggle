{"cell_type":{"967e4cfc":"code","eb6d1397":"code","05338262":"code","f8599fbf":"code","68128ed4":"code","c0764fcf":"code","d91537b2":"code","4bb62179":"code","8d8a911b":"code","a4a012b1":"code","42444f62":"code","dba33c3e":"code","95fc27c9":"code","8119a50c":"code","08748da3":"code","5be0b61e":"code","e16d05e0":"code","8e0f24fe":"code","c97150a6":"markdown","850c45ec":"markdown","74dabcab":"markdown","8933403a":"markdown","6c10d0a7":"markdown","c9620500":"markdown","bf671422":"markdown","4f55e700":"markdown","64910cc9":"markdown","9f157d85":"markdown","954c95a3":"markdown","52af6dd2":"markdown"},"source":{"967e4cfc":"import os\nfrom tensorflow import keras\nimport seaborn as sns \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport PIL\nfrom matplotlib import image\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img\nfrom keras.applications.densenet import DenseNet121\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_curve, f1_score, precision_score, recall_score\nfrom sklearn.utils import class_weight ","eb6d1397":"#Create a function to calculate the files in a directory\ndef calculate_files(link):\n    return (len([name for name in os.listdir(link)]))","05338262":"#Assign links to each folder to variables\ntrain_normal = calculate_files('..\/input\/labeled-chest-xray-images\/chest_xray\/train\/NORMAL')\ntrain_pneumonia = calculate_files('..\/input\/labeled-chest-xray-images\/chest_xray\/train\/PNEUMONIA')\ntest_normal = calculate_files('..\/input\/labeled-chest-xray-images\/chest_xray\/test\/NORMAL')\ntest_pneumonia = calculate_files('..\/input\/labeled-chest-xray-images\/chest_xray\/test\/PNEUMONIA')","f8599fbf":"#Create a dataframe with count of each class in the train dataset\ntrain_barplot = pd.DataFrame({'number_of_images':[train_normal,train_pneumonia], 'disease':['normal', 'pneumonia']})\ndisplay(train_barplot)","68128ed4":"#Plot classes of the train dataset\nsns.barplot(y = 'number_of_images', x = 'disease', \n            data = train_barplot,\n            palette=(\"BuPu\")).set_title('Classes in the train dataset');","c0764fcf":"#Create a dataframe with count of each class in the test dataset \ntest_barplot = pd.DataFrame({'number_of_images':[test_normal,test_pneumonia], 'disease':['normal', 'pneumonia']})\ndisplay(test_barplot)","d91537b2":"#Plot classes of the test dataset\nsns.barplot(y = 'number_of_images', x = 'disease', \n            data = test_barplot,\n            palette=(\"BuPu\")).set_title('Classes in the test dataset');","4bb62179":"# Extract numpy values from Normal test\/normal directory\nimages = [name for name in os.listdir('..\/input\/labeled-chest-xray-images\/chest_xray\/test\/NORMAL')]\n\n#set a pseudorandom generator to consistency\nnp.random.seed(42)\nrandom_images = [np.random.choice(images, replace = False) for i in range(9)]\n\n# Location of the image dir\nimg_dir = '..\/input\/labeled-chest-xray-images\/chest_xray\/test\/NORMAL'\n\nprint('Display Random Images')\n\n# Adjust the size of the images\nplt.figure(figsize=(20,10))\n\n# Iterate and plot random images\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    img = plt.imread(os.path.join(img_dir,random_images[i]))\n    plt.imshow(img,cmap='gray')  ","8d8a911b":"# Get the first image from test\/normal directory\nfirst_image = images[0]\nimg1 = plt.imread(os.path.join(img_dir,first_image))\nplt.imshow(img1,cmap='gray')\n\npixels = image.imread(os.path.join(img_dir,first_image))\n\nplt.title('Raw Chest X Ray Image')\n#print(f\"The dimensions of the image are {img1.width} pixels width and {img1.height} pixels height, mode of the image is {img.mode}\")\nprint(f\"The maximum pixel value is {pixels.max():.4f} and the minimum is {pixels.min():.4f}\")\nprint(f\"The mean value of the pixels is {pixels.mean():.4f} and the standard deviation is {pixels.std():.4f}\")","a4a012b1":"#Create image generators\ntrain_datagen = ImageDataGenerator(\n    samplewise_center=True, #Set each sample mean to 0.\n    samplewise_std_normalization= True, # Divide each input by its standard deviation\n    rotation_range=10,#Degree range for random rotations.\n    width_shift_range=0.1,#fraction of total width rotation\n    height_shift_range=0.1,#fraction of total height rotation\n    rescale=1.\/255,#Scale the pixels to [0,1]\n    validation_split = 0.2) #Fraction of images reserved for validation\n\ntest_datagen = ImageDataGenerator(\n    samplewise_center=True, \n    samplewise_std_normalization= True, \n    rescale=1.\/255)\n","42444f62":"#Load images\ntrain_generator = train_datagen.flow_from_directory(\n    directory=r\".\/..\/input\/labeled-chest-xray-images\/chest_xray\/train\/\",\n    target_size=(224, 224),\n    color_mode=\"rgb\",\n    batch_size=64,\n    class_mode=\"binary\",\n    shuffle=True,\n    subset = \"training\",\n    seed=42\n)\n\nvalid_generator = train_datagen.flow_from_directory(\n    directory=r\".\/..\/input\/labeled-chest-xray-images\/chest_xray\/train\/\",\n    target_size=(224, 224),\n    color_mode=\"rgb\",\n    batch_size=64,\n    class_mode=\"binary\",\n    shuffle=True,\n    subset = \"validation\",\n    seed=42\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    directory=r\".\/..\/input\/labeled-chest-xray-images\/chest_xray\/test\/\",\n    target_size=(224, 224),\n    color_mode=\"rgb\",\n    batch_size=64,\n    class_mode=None,\n    shuffle=False,\n    seed = 42\n)","dba33c3e":"#Visualize a first image after preprocessing\nx, y = train_generator.__getitem__(0)\nplt.imshow(x[0]);","95fc27c9":"initial_bias = np.log([train_pneumonia\/train_normal])\ninitial_bias","8119a50c":"#set the seeds to get reproducible results\nfrom numpy.random import seed\nseed(1)\nimport tensorflow\ntensorflow.random.set_seed(1)\n\n# create the base pre-trained model\nbase_model = DenseNet121(weights='imagenet', input_shape= (224, 224, 3), include_top=False)\n\n#freeze the base model.\nbase_model.trainable = False\n\ninputs = keras.Input(shape= (224, 224, 3))\n# We make sure that the base_model is running in inference mode here,\n# by passing `training=False`. This is important for fine-tuning, as you will\n# learn in a few paragraphs.\nx = base_model(inputs, training=False)\n# Convert features of shape `base_model.output_shape[1:]` to vectors\nx = keras.layers.GlobalAveragePooling2D()(x)\n# A Dense classifier with a single unit (binary classification)\noutputs = keras.layers.Dense(1, activation = 'sigmoid', \n                             bias_initializer=keras.initializers.Constant(initial_bias)\n)(x)\nmodel = keras.Model(inputs, outputs)\n\nmodel.compile(optimizer='adam', loss=keras.losses.BinaryCrossentropy(), metrics=keras.metrics.Recall())\n                     ","08748da3":"early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n#\u043f\u043e\u043c\u0435\u043d\u044f\u0442\u044c validation steps \u043d\u0430 \u0431\u043e\u043b\u044c\u0448\u0435\u0435 400 \u0438\u043b\u0438 800\nmodel.fit(train_generator, \n          validation_data=valid_generator,\n          steps_per_epoch=100,      \n          validation_steps=400, \n          callbacks = early_stopping_cb,\n          epochs = 1000)","5be0b61e":"#define a default treshold 0.5\ndef treshold(pred):\n    if pred <= 0.5:\n        return 0\n    else:\n        return 1","e16d05e0":"def assess_model(model):\n    predicted_vals = model.predict(test_generator, steps = len(test_generator))\n    vfunc = np.vectorize(treshold)\n    predictions = vfunc(predicted_vals)\n    accuracy = accuracy_score(test_generator.classes, predictions)\n    print('Accuracy: %f' % accuracy)\n    print()\n    f1 = f1_score(test_generator.classes, predictions)\n    print('F1 score: %f' % f1)\n    print()\n    precision = precision_score(test_generator.classes, predictions)\n    print('Precision_score : %f' % precision)\n    print()\n    recall = recall_score(test_generator.classes, predictions)\n    print('Recall_score: %f' % recall)\n    print()\n    print('Confusion matrix')\n    cm = confusion_matrix(y_true=test_generator.classes, y_pred=predictions)\n    print(cm)","8e0f24fe":"assess_model(model)","c97150a6":"<a id='4'><\/a>\n\n## 4. Handling class imbalance \n\nIn the most cases, to handle imbalance problem researches assign different weights to the losses, so the model pays more attention to the underrepresented class. In this case, underrepresented class contains images of healthy people and our goal is to identify correctly patients with pneumonia. If we weight losses, then the model's ability to correctly classify the pneumonia patients will decrease. Therefore, another approach will be used.\n\nFor imbalanced dataset, [setting the output layer's bias can help with initial convergence](https:\/\/www.tensorflow.org\/tutorials\/structured_data\/imbalanced_data#optional_set_the_correct_initial_bias). This is how we handle imbalance problem.\n","850c45ec":"<a id='3'><\/a>\n\n## 3. Image Preprocessing\n\nBefore training, the images will be first modified to be better suited for training a convolutional neural network. The Keras [ImageDataGenerator](https:\/\/keras.io\/preprocessing\/image\/) function will be used to perform data preprocessing and data augmentation.","74dabcab":"95% of patients are correctly classified by the model!","8933403a":"Images have different size. They will be resized while being preprcessed.","6c10d0a7":"### Investigation of a single image\n","c9620500":"The pixel values will be scaled to [0,1] and standardized that the new mean of the data will be zero, and the standard deviation of the data will be 1.","bf671422":"<a id='2'><\/a>\n\n## 2. Data exploration\n\nLet's calculate and visualize the class labels for both train and test datasets that are represented as files in corresponding directories.","4f55e700":"<a name='6'><\/a>\n\n## 6. Measuring diagnostic performance","64910cc9":"# Detecting Pneumonia using Deep Learning\n\nThe adoption of machine learning (ML) for medical imaging applications shows a fascinating opportunity to improve the accuracy and consistency of chest X-ray image interpretation. In this work, a state-of-the-art chest X-ray classifier will be built using Keras.\n\nIn this example, false positives are just a false alarm. Such predictions\u2019ll be corrected by doctors. However a false negative label predicting patients\u2019re healthy while they\u2019re not which is \u2014 in this problem \u2014 the worst case. Recall metric answers the question: Of all the people who have pneumonia, how many of those we correctly predict? Therefore, the recall will be used as a main one to reain and to monitor~ the performance of a model \n\n\n\n#### There are the steps of building and evaluating this deep learning model:\n\n\n* [1 Import packages and functions](#1)\n* [2 Data exploration](#2)\n* [3 Image preprocessing](#3)\n* [4 Handling class imbalance](#4)\n* [5 Model development](#5)\n* [6 Measuring diagnostic performance](#6)","9f157d85":"<a name='5'><\/a>\n\n## 5. Model Development\n\n  Transfer learning is a technique in which we use previously learned features from datasets containing large amount of data and then transfer this learning and apply on our own dataset on top of it. Using this technique reduces the amount of data required and, in many cases, increases the accuracy as compared to models build from scratch. \n\n  In neural networks the first few layers only recognize general patterns like shape, edges, noise etc., and only in the later layers the network recognizes complex patterns like color, special features etc. So, we can use the first layers removing the last layers and adding our own layers to identify or predict on our own datasets. \n  \n  ### DenseNet121\n\nA pre-trained [DenseNet121](https:\/\/www.kaggle.com\/pytorch\/densenet121) model will be used. DenseNet121 can be loaded directly from Keras and then two layers can be added on top of it:\n1. A `GlobalAveragePooling2D` layer to get the average of the last convolution layers from DenseNet121.\n2. A `Dense` layer with `sigmoid` activation to get the prediction logits for each of our classes.\n\nThe flow for transfer learning as follows: \n\n* Take layers from a previously trained model.\n* Freeze them, so as to avoid destroying any of the information they contain during future training rounds.\n* Add some new, trainable layers on top of the frozen layers. They will learn to turn the old features into predictions on a new dataset.\n* Train the new layers on your dataset.","954c95a3":"The train and test datasets are unbalaced. This problem will be handled later.\n\n### Data Visualization\n\nA random selection of images from the test\/normal directory is shown below.","52af6dd2":"<a id='1'><\/a>\n\n## 1. Import Packages and Functions\u00b6"}}