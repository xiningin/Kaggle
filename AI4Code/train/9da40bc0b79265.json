{"cell_type":{"782a201f":"code","899f71d7":"code","75921649":"code","a62742ec":"code","be7d0c20":"code","b66339c8":"code","4386299d":"code","bbdca9e4":"code","755751e1":"code","a291db2d":"code","f8398a4f":"code","ac0b179c":"code","db864e6c":"code","487ef070":"code","3194e9d1":"code","5bc19aa7":"code","2b778159":"code","4c3b6dcc":"code","f0a1e0ee":"markdown","9d470892":"markdown"},"source":{"782a201f":"print('Importing packages...')\nfrom datetime import datetime\nimport numpy as np\nimport pandas as pd\nimport xgboost\nimport re\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split","899f71d7":"print('Reading data...')\ndfTest = pd.read_csv('..\/input\/loan-defaulter-classification\/test_indessa.csv')\ndfTrain = pd.read_csv('..\/input\/loan-defaulter-classification\/train_indessa.csv')\n\ndfTrain = dfTrain[['member_id', 'loan_amnt', 'funded_amnt', 'addr_state', 'funded_amnt_inv', 'sub_grade', 'term', 'desc', 'emp_length', 'int_rate', 'annual_inc', 'dti', 'delinq_2yrs', 'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc','total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', 'last_week_pay', 'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'total_rev_hi_lim', 'loan_status']]\ndfTest = dfTest[['member_id', 'loan_amnt', 'funded_amnt', 'addr_state', 'funded_amnt_inv', 'sub_grade', 'term', 'desc','emp_length', 'int_rate', 'annual_inc', 'dti', 'delinq_2yrs', 'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', 'last_week_pay', 'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'total_rev_hi_lim']]","75921649":"\ndef get_last_week_pay(raw) :\n    try :\n        return int(re.sub(\"\\D\", \"\", raw))\n    except :\n        return -9999\n    \nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize, sent_tokenize\ndef clean_text(raw_text):\n    cleantext = np.nan\n    if type(raw_text) == str :\n        cleanr = re.compile('<.*?>')\n        cleantext = re.sub(cleanr, ' ', raw_text)\n        cleantext = cleantext.replace('>', '')\n        cleantext = ' '.join(cleantext.split())\n        \n        stop_words = set(stopwords.words(\"english\"))\n        words = word_tokenize(cleantext)\n        \n        filtered_sentence = []\n\n        for w in words:\n            if w not in stop_words:\n                filtered_sentence.append(w)\n        return len(filtered_sentence)\n    \n    else :\n        return 0 \n","a62742ec":"'''\nData transformation\/cleanup\nStrip off textual parts, represent values as numeric values\nit makes sense. Convert the datatype to numeric.\n'''\n\ndfTrain['term'] = dfTrain['term'].apply(lambda x : int(re.sub(\"\\D\", \"\", x)))\ndfTrain['last_week_pay'] = dfTrain['last_week_pay'].apply(get_last_week_pay)\ndfTrain['desc'] = dfTrain['desc'].apply(clean_text)\ndfTrain['emp_length'].replace('n\/a', '0', inplace=True)\ndfTrain['emp_length'].replace(to_replace='\\+ years', value='', regex=True, inplace=True)\ndfTrain['emp_length'].replace(to_replace=' years', value='', regex=True, inplace=True)\ndfTrain['emp_length'].replace(to_replace='< 1 year', value='0', regex=True, inplace=True)\ndfTrain['emp_length'].replace(to_replace=' year', value='', regex=True, inplace=True)\ndfTest['term'] = dfTest['term'].apply(lambda x : int(re.sub(\"\\D\", \"\", x)))\ndfTest['last_week_pay'] = dfTest['last_week_pay'].apply(get_last_week_pay)\ndfTest['desc'] = dfTest['desc'].apply(clean_text)\ndfTest['emp_length'].replace(to_replace='\\+ years', value='', regex=True, inplace=True)\ndfTest['emp_length'].replace(to_replace=' years', value='', regex=True, inplace=True)\ndfTest['emp_length'].replace(to_replace='< 1 year', value='0', regex=True, inplace=True)\ndfTest['emp_length'].replace(to_replace=' year', value='', regex=True, inplace=True)\n\ndfTrain['term'] = pd.to_numeric(dfTrain['term'], errors='coerce')\ndfTest['term'] = pd.to_numeric(dfTest['term'], errors='coerce')\n\ndfTrain['last_week_pay'] = pd.to_numeric(dfTrain['last_week_pay'], errors='coerce')\ndfTest['last_week_pay'] = pd.to_numeric(dfTest['last_week_pay'], errors='coerce')\n\ndfTrain['emp_length'] = pd.to_numeric(dfTrain['emp_length'], errors='coerce')\ndfTest['emp_length'] = pd.to_numeric(dfTest['emp_length'], errors='coerce')\n\ndfTrain['sub_grade'] = pd.to_numeric(dfTrain['sub_grade'], errors='coerce')\ndfTest['sub_grade'] = pd.to_numeric(dfTest['sub_grade'], errors='coerce')\n\nprint('Transform done.')","be7d0c20":"'''\nFeature Engineering\n'''\n\n# Separating the member_id column of test dataframe to help create a csv after predictions\ntest_member_id = pd.DataFrame(dfTest['member_id'])\n\n\n# Creating target variable pandas series from train dataframe, this will be used by cross validation to calculate\n# the accuracy of the model\ntrain_target = pd.DataFrame(dfTrain['loan_status'])\n\n\n# It's good to create a copy of train and test dataframes. this way we can play around different features as we tune the\n# performance of the classifier with important features\nselected_cols = ['member_id', 'emp_length', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'sub_grade', 'int_rate', 'annual_inc', 'dti', 'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'revol_bal', 'revol_util', 'total_acc', 'total_rec_int', 'total_rec_late_fee', 'mths_since_last_major_derog', 'last_week_pay', 'tot_cur_bal', 'total_rev_hi_lim', 'tot_coll_amt', 'recoveries', 'collection_recovery_fee', 'term', 'acc_now_delinq', 'collections_12_mths_ex_med']\nfinalTrain = dfTrain[selected_cols]\nfinalTest = dfTest[selected_cols]\n\n# How big the loan a person has taken with respect to his earnings, annual income to loan amount ratio\nfinalTrain['loan_to_income'] = finalTrain['annual_inc']\/finalTrain['funded_amnt_inv']\nfinalTest['loan_to_income'] = finalTest['annual_inc']\/finalTest['funded_amnt_inv']\n\n\n# All these attributes indicate that the repayment was not all hunky-dory. All the amounts caclulated are ratios \n# like, recovery to the loan amount. This column gives a magnitude of how much the repayment has gone off course \n# in terms of ratios.\nfinalTrain['bad_state'] = finalTrain['acc_now_delinq'] + (finalTrain['total_rec_late_fee']\/finalTrain['funded_amnt_inv']) + (finalTrain['recoveries']\/finalTrain['funded_amnt_inv']) + (finalTrain['collection_recovery_fee']\/finalTrain['funded_amnt_inv']) + (finalTrain['collections_12_mths_ex_med']\/finalTrain['funded_amnt_inv'])\nfinalTest['bad_state'] = finalTest['acc_now_delinq'] + (finalTest['total_rec_late_fee']\/finalTest['funded_amnt_inv']) + (finalTest['recoveries']\/finalTest['funded_amnt_inv']) + (finalTest['collection_recovery_fee']\/finalTest['funded_amnt_inv']) + (finalTrain['collections_12_mths_ex_med']\/finalTest['funded_amnt_inv'])\n\n# For the sake of this model, I have used just a boolean flag if things had gone bad, with this case I didn't see\n# a benifit of including above computations\nfinalTrain.loc[finalTrain['bad_state'] > 0, 'bad_state'] = 1\nfinalTest.loc[finalTest['bad_state'] > 0, 'bad_state'] = 1\n\n\n# Total number of available\/unused 'credit lines'\nfinalTrain['avl_lines'] = finalTrain['total_acc'] - finalTrain['open_acc']\nfinalTest['avl_lines'] = finalTest['total_acc'] - finalTest['open_acc']\n\n\n# Interest paid so far\nfinalTrain['int_paid'] = finalTrain['total_rec_int'] + finalTrain['total_rec_late_fee']\nfinalTest['int_paid'] = finalTest['total_rec_int'] + finalTest['total_rec_late_fee']\n\n\n# Calculating EMIs paid (in terms of percent)\nfinalTrain['emi_paid_progress_perc'] = ((finalTrain['last_week_pay']\/(finalTrain['term']\/12*52+1))*100)\nfinalTest['emi_paid_progress_perc'] = ((finalTest['last_week_pay']\/(finalTest['term']\/12*52+1))*100)\n\n\n# Calculating total repayments received so far, in terms of EMI or recoveries after charge off\nfinalTrain['total_repayment_progress'] = ((finalTrain['last_week_pay']\/(finalTrain['term']\/12*52+1))*100) + ((finalTrain['recoveries']\/finalTrain['funded_amnt_inv']) * 100)\nfinalTest['total_repayment_progress'] = ((finalTest['last_week_pay']\/(finalTest['term']\/12*52+1))*100) + ((finalTest['recoveries']\/finalTest['funded_amnt_inv']) * 100)","b66339c8":"#Null values in training dataset\n\nnull= finalTrain.isnull().sum().sort_values(ascending=False)\ntotal =finalTrain.shape[0]\npercent_missing= (finalTrain.isnull().sum()\/total).sort_values(ascending=False)\n\nmissing_data= pd.concat([null, percent_missing], axis=1, keys=['Total missing', 'Percent missing'])\n\nmissing_data.reset_index(inplace=True)\nmissing_data= missing_data.rename(columns= { \"index\": \" column name\"})\n \nprint (\"Null Values in each column:\\n\", missing_data.sort_values(by ='Total missing', ascending = False))","4386299d":"#Null values in training dataset\n\nnull= finalTest.isnull().sum().sort_values(ascending=False)\ntotal =finalTest.shape[0]\npercent_missing= (finalTest.isnull().sum()\/total).sort_values(ascending=False)\n\nmissing_data= pd.concat([null, percent_missing], axis=1, keys=['Total missing', 'Percent missing'])\n\nmissing_data.reset_index(inplace=True)\nmissing_data= missing_data.rename(columns= { \"index\": \" column name\"})\n \nprint (\"Null Values in each column:\\n\", missing_data.sort_values(by ='Total missing', ascending = False))","bbdca9e4":"def fill_nulls(value):\n    cols_fill = ['mths_since_last_record','mths_since_last_major_derog',\n                 'mths_since_last_delinq','total_rev_hi_lim','tot_cur_bal',\n                 'tot_coll_amt','emp_length','revol_util','collections_12_mths_ex_med',\n                 'open_acc','total_acc','acc_now_delinq','avl_lines','loan_to_income',\n                 'annual_inc','bad_state','total_repayment_progress']\n    \n    if value == -9999:\n        for col in cols_fill:\n            finalTest.loc[finalTest[col].isnull(), col] = -9999\n    else : \n        for col in cols_fill:\n            finalTest.loc[finalTest[col].isnull(), col] = finalTrain[col].median()","755751e1":"fill_nulls(0)","a291db2d":"def fill_nulls(value):\n    cols_fill = ['mths_since_last_record','mths_since_last_major_derog',\n                 'mths_since_last_delinq','total_rev_hi_lim','tot_cur_bal',\n                 'tot_coll_amt','emp_length','revol_util','collections_12_mths_ex_med',\n                 'open_acc','total_acc','acc_now_delinq','avl_lines','loan_to_income',\n                 'annual_inc','bad_state','total_repayment_progress']\n    if value == -9999:\n        for col in cols_fill:\n            finalTrain.loc[finalTrain[col].isnull(), col] = -9999\n    else : \n        for col in cols_fill:\n            finalTrain.loc[finalTrain[col].isnull(), col] = finalTrain[col].median()","f8398a4f":"fill_nulls(0)","ac0b179c":"finalTrain = finalTrain.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)","db864e6c":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nx_trainScaled = scaler.fit_transform(finalTrain)\n","487ef070":"\n# Split train and cross validation sets\nX_train, X_test, y_train, y_test = train_test_split(np.array(finalTrain), np.array(train_target), test_size=0.30)\neval_set=[(X_test, y_test)]","3194e9d1":"print('Initializing xgboost.sklearn.XGBClassifier....')\n\n\nclf = xgboost.sklearn.XGBClassifier(\n    objective=\"binary:logistic\", \n    learning_rate=0.09, \n    seed=9616, \n    max_depth=30, \n    gamma=10, \n    n_estimators=500)\n\n","5bc19aa7":"print(\"Training Started\")\nclf.fit(X_train, y_train, early_stopping_rounds=20, eval_metric=\"auc\", eval_set=eval_set, verbose=True)\n\ny_pred = clf.predict(X_test)\naccuracy = accuracy_score(np.array(y_test).flatten(), y_pred)\n\n\n","2b778159":"submission_file_name = \"Loan_Defaulter_submission\"\nprint(\"Accuracy: %.10f%%\" % (accuracy * 100.0))\nsubmission_file_name = submission_file_name + (\"_Accuracy_%.6f\" % (accuracy * 100)) + '_'\n\naccuracy_per_roc_auc = roc_auc_score(np.array(y_test).flatten(), y_pred)\nprint(\"ROC-AUC: %.10f%%\" % (accuracy_per_roc_auc * 100))\nsubmission_file_name = submission_file_name + (\"_ROC-AUC_%.6f\" % (accuracy_per_roc_auc * 100))\n\n","4c3b6dcc":"final_pred = pd.DataFrame(clf.predict_proba(np.array(finalTest)))\ndfSub = pd.concat([test_member_id, final_pred.iloc[:, 1:2]], axis=1)\ndfSub.rename(columns={1:'loan_status'}, inplace=True)\ndfSub.to_csv((('%s.csv') % (submission_file_name)), index=False)\n\n","f0a1e0ee":"### Final Submission","9d470892":"### Data Transformation"}}