{"cell_type":{"7b33bdd7":"code","cbfc08f0":"code","5ec29583":"code","6c4c8315":"code","20c24085":"code","dd5fcfc1":"code","ade47130":"code","85cc77fc":"code","2dcd2124":"code","99680faf":"code","907887fa":"code","5b5e29e4":"code","dab99354":"code","ee6acf78":"code","1bcf83d3":"code","a50e28fe":"code","193dfb9a":"code","f72163dc":"code","2d1f408c":"markdown","b90bb1fa":"markdown","3822916b":"markdown","4502d524":"markdown","4e53f016":"markdown"},"source":{"7b33bdd7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cbfc08f0":"# Import the data\nwalmart_data  = pd.read_csv(\"\/kaggle\/input\/walmart-dataretail-analysis\/Walmart_Store_sales.csv\")\n\n#Let's begin by looking at the data\nwalmart_data.head()","5ec29583":"#Now let's look at the columns to see if the there are any missing values\nwalmart_data.info()","6c4c8315":"#Looks like there are no missing data\n\n#However, the date column is of object type, let's convert it to datetime type\nwalmart_data['Date'] = pd.to_datetime(walmart_data['Date'])\n\n#Let's add two new columns for Year and month, could be useful for our analysis\nwalmart_data['year'] = pd.DatetimeIndex(walmart_data['Date']).year\nwalmart_data['month'] = pd.DatetimeIndex(walmart_data['Date']).month","20c24085":"#Let's look at the changes we just made\nwalmart_data.info()","dd5fcfc1":"#Let's find out how many stores are there in this dataset\ntot_stores= walmart_data['Store'].nunique()\nprint('The total stores in this dataset are: ', tot_stores)","ade47130":"#Out of 45 stores which stores have the maximum weekly sales?\nwalmart_data.groupby('Store')['Weekly_Sales'].max().sort_values(ascending=False).head()","85cc77fc":"#What is the standard deviation among the stores?\nwalmart_data.groupby('Store')['Weekly_Sales'].std().sort_values(ascending=False).head()","2dcd2124":"# Let's find out which store had the maximum sales in Q3 of 2012\nquarterly =[]\nfor st in range(1,int(tot_stores)+1):\n    values = walmart_data[(walmart_data['Store']==st) & (walmart_data['Date']> '2012-06-01') & (walmart_data['Date']<'2012-09-01')]['Weekly_Sales'].values\n    quarterly.append(np.mean(values))\n\nprint('The store with maximum profit in Q3 in 2012 is:', quarterly.index(max(quarterly))+1)","99680faf":"#Now let's visualize the quarterly growth of all the stores in Q3 of 2012\nplt.figure(figsize=(20,10))\nsns.barplot(x=[i for i in range(1,int(tot_stores)+1)],y=quarterly, palette='viridis' )\nplt.show()","907887fa":"#Let us now see how each feature relates to the other using a correlation heatmap\ncorr = walmart_data.corr()\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(corr, annot=True, vmin=-1.0, cmap='viridis')\nplt.show()","5b5e29e4":"walmart_data= walmart_data.drop('Date', axis=1)\nwalmart_data.info()","dab99354":"#Let's begin with splitting the model into Test and Train datasets\ny= walmart_data['Holiday_Flag']\nX= walmart_data.drop('Holiday_Flag', axis=1)","ee6acf78":"#Using scaler function we can normalize our dataset to improve the performance of our algorithms\nscaler = StandardScaler()\n\nX = scaler.fit_transform(X)","1bcf83d3":"X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.7)","a50e28fe":"#Logistic Regression\n\nclf_log = LogisticRegression(random_state=0)\nclf_log.fit(X_train, y_train)\ny_pred  = clf_log.predict(X_test)\nscores = cross_val_score(clf_log, X_train, y_train, cv=10, scoring = \"accuracy\")\n\n#Print the accuracy % of our model\n\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())","193dfb9a":"#Decision Tree\n\nclf_dt = DecisionTreeClassifier()\nclf_dt.fit(X_train, y_train)\nY_pred  = clf_dt.predict(X_test)\nscores = cross_val_score(clf_dt, X_train, y_train, cv=10, scoring = \"accuracy\")\n\n#Print the accuracy % of our model\n\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())","f72163dc":"#K Nearest Neighbors\n\nclf_knn = KNeighborsClassifier(n_neighbors=3)\nclf_knn.fit(X_train, y_train)\ny_pred  = clf_knn.predict(X_test)\nscores = cross_val_score(clf_knn, X_train, y_train, cv=10, scoring = \"accuracy\")\n\n#Print the accuracy % of our model\n\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())","2d1f408c":"***Machine Learning Algorithms***\n\nWe will use three models for this dataset and compare which model predicts accurately\n1. Logistic Regression\n2. Decision Tree\n3. K Nearest Neighbors\n","b90bb1fa":"Seems like Store #14 has the maximum sales.","3822916b":"***Exploratory Analysis***\n\nLet's do some data analysis on this dataset to answer some simple questions. \n1. Which store has maximum sales?\n\n2. Which store has maximum standard deviation i.e., the sales vary a lot?\n\n3. Which store\/s has good quarterly growth rate in Q3\u20192012?\n","4502d524":"By comparing all the scores from the 3 models, it seems that Decision Tree Classifier performs better with the highest accuracy.","4e53f016":"Store #14 has the maximum standard deviation. "}}