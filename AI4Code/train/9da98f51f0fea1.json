{"cell_type":{"39a22789":"code","afd7d67f":"code","43c95ac6":"code","b4049479":"code","89d993c8":"code","f3509418":"code","1bc08091":"code","0e2e25b3":"code","f9065203":"code","86d40278":"code","07e648be":"code","01abdd47":"code","670456c7":"code","67a7ec62":"code","38807085":"code","b9eeba98":"code","8bc39be1":"code","cf999c90":"code","3eb7347e":"code","f0357d49":"code","42930bfc":"code","32afc4b9":"markdown","ac1db3f0":"markdown","fc4d21c3":"markdown"},"source":{"39a22789":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","afd7d67f":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as matplot\nimport re\nimport sklearn\ntry:\n    from sklearn.feature_selection import VarianceThreshold\nexcept AttributeError:\n    pass \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline","43c95ac6":"\ndf1 = pd.read_csv('..\/input\/labs.csv')\ndf2 = pd.read_csv('..\/input\/examination.csv')\ndf3 = pd.read_csv('..\/input\/demographic.csv')\ndf4 = pd.read_csv('..\/input\/diet.csv')\ndf5 = pd.read_csv('..\/input\/questionnaire.csv')\n\ndf2.drop(['SEQN'], axis = 1, inplace=True)\ndf3.drop(['SEQN'], axis = 1, inplace=True)\ndf4.drop(['SEQN'], axis = 1, inplace=True)\ndf5.drop(['SEQN'], axis = 1, inplace=True)\n\ndf = pd.concat([df1, df2], axis=1, join='inner')\ndf = pd.concat([df, df3], axis=1, join='inner')\ndf = pd.concat([df, df4], axis=1, join='inner')\ndf = pd.concat([df, df5], axis=1, join='inner')\n\n#sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n#sel.fit_transform(df)\n\ndf.describe()\n\n","b4049479":"from sklearn.feature_selection import VarianceThreshold\n\ndf.dropna(axis=1, how='all')\ndf.dropna(axis=0, how='all')\n\ndf = df.rename(columns = {'SEQN' : 'ID',\n                          'RIAGENDR' : 'Gender',\n                          'DMDMARTL' : 'Marital_Status',\n                          'PEASCST1' : 'BP_Status',\n                          'BMDAVSAD' : 'SaggitalAbdominal',\n                          'BMXBMI' : 'BMI',\n                          'BMXWAIST' : 'WaistCircum',\n                          'BMXWT' : 'Weight_kg',\n                          'DMDYRSUS' : 'Years_in_US',\n                          'INDFMPIR' : 'Family_income'})\n\n\n\ndf = df.loc[:, ['ID', 'Gender', 'Marital_Status', 'Years_in_US', 'Family_income', 'BMI', 'BP_Status', 'Weight_kg', 'SaggitalAbdominal', 'WaistCircum']]\n\ndf.describe()\n\n","89d993c8":"from sklearn.feature_selection import VarianceThreshold\n\n#year in us -> american : 0, not american : 1\ndf.dropna(axis=1, how='all')\ndf.dropna(axis=0, how='all')\n\n#YEARS IN US NA\ucc98\ub9ac\ndf['Years_in_US'] = df['Years_in_US'].apply(lambda x: x if x > 0 else 0)\n\n#GlycoHemoglobin, Saggital Abdominal(median)\ndf['BP_Status'] = df['BP_Status'].fillna(df['BP_Status'].median())\ndf['SaggitalAbdominal'] = df['SaggitalAbdominal'].fillna(df['SaggitalAbdominal'].median())\ndf['WaistCircum'] = df['WaistCircum'].fillna(df['WaistCircum'].median())\ndf['Weight_kg'] = df['Weight_kg'].fillna(df['Weight_kg'].median())\n\n#Family Income -> use ffill to fill na\ndf['Family_income'] = df['Family_income'].fillna(method='ffill')\n\n#Breat_fed -> fill to 1\ndf['Gender'] = df['Gender'].fillna(value = 1)\n\n#sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n#sel.fit_transform(df)\n\n#for dataset in df:\n#    dataset['GlycoHemoglobin'] = dataset['GlycoHemoglobin'].fillna(df['GlycoHemoglobin'].median())\n\n#df.head(12)\n\n\ndf.describe()","f3509418":"df.loc[df['BP_Status'] <= 1, 'Cholesterol'] = 0\ndf.loc[(df['BP_Status'] >= 2) & (df['BP_Status'] <= 2), 'Cholesterol'] = 1\ndf.loc[df['BP_Status'] >= 3, 'Cholesterol'] = 2\n\ndf.head(10)\n#df.fillna(method='ffill', axis=1)\n","1bc08091":"show = sns.pairplot(df.drop(['ID', 'Gender'], axis=1), hue='Cholesterol', size=1.5, diag_kind='kde')\n\nshow.set(xticklabels=[])","0e2e25b3":"colormap = plt.cm.viridis\nplt.figure(figsize=(10,10))\nsns.heatmap(df.astype(float).drop(axis=1, labels='ID').corr(), linewidths=0.1, vmax=1.0, square=True, cmap=colormap, annot=True)","f9065203":"from sklearn import linear_model\nfrom sklearn.svm import SVC\nfrom sklearn.cross_validation import KFold;\nfrom sklearn.metrics import mean_squared_error, r2_score","86d40278":"df.drop(['BP_Status'], axis = 1, inplace=True)\n\ndf.head(5)\n","07e648be":"#data -> attributes, target -> ldl\ndata = df.drop(['Cholesterol'], axis=1)\ntarget = df[['Cholesterol']]\n\n#seperate training set and test set\ntrain_X = data[:6000]\ntest_X = data[6000:]\ntrain_Y = target[:6000]\ntest_Y = target[6000:]\n\n#create linear regression obj\nlr_regr = linear_model.LinearRegression()\n\n#training via linear regression model\nlr_regr.fit(train_X, train_Y)\n\n#make prediction using the test set\nlr_pred_Cholesterol = lr_regr.predict(test_X)\nlr_pred_Cholesterol = lr_regr.predict(test_X)\nlr_score = lr_regr.score(test_X, test_Y)\n\nprint('LRr_Coefficients: ', lr_regr.coef_)\nprint('LR_Mean Square Error: %.2f' % average_squared_error(test_Y, lr_pred_Cholesterol))\nprint('LR_Variance score: %.2f' % r2_score(test_Y, lr_pred_Cholesterol))\nprint('Score: %.2f' % lr_regr.score(test_X, test_Y))","01abdd47":"from sklearn.cluster import KMeans","670456c7":"kms = KMeans(n_clusters = 3, tol = 0.0005, algorithm=\"auto\")\n\nkms.fit_predict(train_X)\n\nprint (\"parameters: \", kms.get_params)\nprint (\"predict: \", kms.predict)\nprint (\"\\nscore: %.2f\" % kms.score(test_X))","67a7ec62":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\n\n#create adaboost classification obj\nab_clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, \n                            learning_rate=0.5, random_state=100)\n\n#training via adaboost classficiation model\nab_clf.fit(train_X, train_Y)\nprint(\"training....\\n\")\n\n#make prediction using the test set\nab_pred_Cholesterol = ab_clf.predict(test_X)\nprint('prediction: \\n', ab_pred_Cholesterol\n\nprint('\\nparms: \\n', ab_clf.get_params)\n\n#predict probability\n#print('predict probability: %.2f' % ab_clf.staged_score(test_X, ab_pred_LDL))\n\n#score\nab_clf_score = ab_clf.score(test_X, test_Y)\nprint(\"\\nmean accuracy: %.2f\" % ab_clf.score(test_X, test_Y))","38807085":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","b9eeba98":"bagging = BaggingClassifier(base_estimator= DecisionTreeClassifier(), max_samples = 0.5, max_features = 0.5, \n                            bootstrap = False, bootstrap_features = False)\n\nbagging.fit(train_X, train_Y)\nbg_pred_LDL = bagging.predict(test_X)\n\nbg_dt_score = bagging.score(test_X, test_Y)\nbagging.score(test_X, test_Y)","8bc39be1":"bagging = BaggingClassifier(base_estimator= KNeighborsClassifier(), max_samples = 0.5, max_features = 0.5, \n                            bootstrap = False, bootstrap_features = False)\n\nbagging.fit(train_X, train_Y)\nbg_pred_LDL = bagging.predict(test_X)\n\nbg_score = bagging.score(test_X, test_Y)\nbagging.score(test_X, test_Y)","cf999c90":"from sklearn.neural_network import MLPClassifier","3eb7347e":"mlp = MLPClassifier(hidden_layer_sizes=(1000, 300, 300), solver='adam', shuffle=False, tol = 0.0001)\n\nmlp.fit(train_X, train_Y)\nmlp_pred_LDL = mlp.predict(test_X)\n\nprint(\"parameter: \", mlp.get_params())\n\nmlp_score = mlp.score(test_X, test_Y)\nmlp.score(test_X, test_Y)","f0357d49":"d = {'Model': ['Linear Regression', 'Adaboost', 'Bagging_decision tree based', 'Bagging_KNeighbors', 'MLP'],\n     'accuracy' : [lr_score, ab_clf_score, bg_dt_score, bg_score, mlp_score]}\n\nresult_df = pd.DataFrame(data = d)\nresult_df","42930bfc":"result_df.plot(x='Model', y='accuracy', kind='bar', figsize=(8, 8), title='Cholesterol Level prediction, Low Density Lipoprotein (LDL)', \n               sort_columns=True)","32afc4b9":"#### **According to Glycohemoglobin, 0-> Normal status 1-> High-risk diabetes 2-> Diabetes patients**","ac1db3f0":"#### NA handling, Feature selection","fc4d21c3":"### Dataset Merge & select attribute"}}