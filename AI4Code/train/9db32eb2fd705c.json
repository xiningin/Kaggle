{"cell_type":{"6716e411":"code","6623a9c3":"code","77ca6770":"code","dc922cae":"code","5fab4071":"code","470833f4":"code","46bae6bb":"code","02b81718":"code","7ab333df":"code","2a82637f":"code","ea594e24":"code","68df4d2a":"code","e4374ca5":"code","edcf94c4":"code","5049ae8e":"code","05b5fb97":"code","026112b4":"code","9b3bc289":"code","c19365ed":"code","b7ac8e54":"code","cdd7ea47":"code","a0b0c41e":"markdown","0ba073e5":"markdown","e3db2086":"markdown","4449e19a":"markdown","f8998876":"markdown","53f4f431":"markdown","0d1831e4":"markdown","98f37c6f":"markdown","6a5bb193":"markdown","db496287":"markdown","1581cf54":"markdown","039b88a5":"markdown","6d1bf69a":"markdown","cd46eb70":"markdown","6300e979":"markdown","61d39257":"markdown","be05cf64":"markdown","73feb788":"markdown","93271c47":"markdown","121e0709":"markdown","571fe2ed":"markdown","70f1bca5":"markdown","d27f5054":"markdown","ae19cba9":"markdown"},"source":{"6716e411":"import sys\nprint(\"Python version:\", sys.version)\n\nimport tensorflow as tf\nprint(\"TensorFlow version:\", tf.__version__)","6623a9c3":"from __future__ import absolute_import, division, print_function\nimport numpy as np\n\nimport tensorflow as tf","77ca6770":"from tensorflow.python.ops import control_flow_util\ncontrol_flow_util.ENABLE_CONTROL_FLOW_V2 = True","dc922cae":"@tf.function\ndef simple_nn_layer(x, y):\n    return tf.nn.relu(tf.matmul(x, y))\n\nx = tf.random.uniform((3, 3))\ny = tf.random.uniform((3, 3))\n\nsimple_nn_layer(x, y)","5fab4071":"simple_nn_layer","470833f4":"def linear_layer(x):\n    return 2 * x + 1\n\n@tf.function\ndef deep_net(x):\n    return tf.nn.relu(linear_layer(x))\n\ndeep_net(tf.constant((1, 2, 3)))","46bae6bb":"@tf.function\ndef square_if_positive(x):\n    if x > 0:\n        x = x * x\n    else:\n        x = 0\n    return x\n\nprint('square_if_positive(2) = {}'.format(square_if_positive(tf.constant(2))))\nprint('square_if_positive(-2) = {}'.format(square_if_positive(tf.constant(-2))))","02b81718":"@tf.function\ndef sum_even(items):\n    s = 0\n    for c in items:\n        if c % 2 > 0:\n            continue\n        s += c\n    return s\n\nsum_even(tf.constant([10, 12, 15, 20]))","7ab333df":"print(tf.autograph.to_code(sum_even.python_function, experimental_optional_features=None))","2a82637f":"@tf.function\ndef fizzbuzz(n):\n    msg = tf.constant('')\n    for i in range(n):\n        if i % 3 == 0:\n            msg += 'Fizz'\n        elif i % 5 == 0:\n            msg += 'Buzz'\n        else:\n            msg += tf.as_string(i)\n        msg += '\\n'\n    return msg\n\nprint(fizzbuzz(tf.constant(15)).numpy().decode())","ea594e24":"@tf.function\ndef count(n):\n    for i in tf.range(n):\n        print(i)\n        \ncount(tf.constant(5))","68df4d2a":"@tf.function\ndef range_example(n):\n    return range(n)\n\nprint(range_example(tf.constant(3)))","e4374ca5":"@tf.function\ndef len_example(n):\n    return len(n)\n\nprint(len_example(tf.zeros((20, 10))))","edcf94c4":"class CustomModel(tf.keras.models.Model):\n    \n    @tf.function\n    def call(self, input_data):\n        if tf.reduce_mean(input_data) > 0:\n            return input_data\n        else:\n            return input_data \/\/ 2\n        \nmodel = CustomModel()\nmodel(tf.constant([-2, -4]))","5049ae8e":"v = tf.Variable(5)\n\n@tf.function\ndef find_next_odd():\n    v.assign(v + 1)\n    if v % 2 == 0:\n        v.assign(v + 1)\n\nfind_next_odd()\nv","05b5fb97":"def prepare_mnist_features_and_labels(x, y):\n    x = tf.cast(x, tf.float32) \/ 255.0\n    y = tf.cast(y, tf.int64)\n    \n    return x, y\n\ndef mnist_dataset():\n    (x, y), _ = tf.keras.datasets.mnist.load_data()\n    ds = tf.data.Dataset.from_tensor_slices((x, y))\n    ds = ds.map(prepare_mnist_features_and_labels)\n    ds = ds.take(20000).shuffle(20000).batch(100)\n    return ds\n\ntrain_dataset = mnist_dataset()","026112b4":"model = tf.keras.Sequential((\n    tf.keras.layers.Reshape(target_shape=(28 * 28,), input_shape=(28, 28)),\n    tf.keras.layers.Dense(100, activation='relu'),\n    tf.keras.layers.Dense(100, activation='relu'),\n    tf.keras.layers.Dense(10)))\n\nmodel.build()\noptimizer = tf.keras.optimizers.Adam()","9b3bc289":"def compute_loss(logits, labels):\n    return tf.reduce_mean(\n    tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n\ndef compute_accuracy(logits, labels):\n    predictions = tf.argmax(logits, axis=1)\n    return tf.reduce_mean(tf.cast(predictions == labels, tf.float32))\n\ndef train_one_step(model, optimizer, x, y):\n    with tf.GradientTape() as tape:\n        tape.watch(model.variables)\n        logits =  model(x)\n        loss = compute_loss(logits, y)\n        \n    grads = tape.gradient(loss, model.variables)\n    optimizer.apply_gradients(zip(grads, model.variables))\n    \n    accuracy = compute_accuracy(logits, y)\n    return loss, accuracy\n\n\n@tf.function\ndef train(model, optimizer):\n    train_ds = mnist_dataset()\n    step = 0\n    for x, y in train_ds:\n        step += 1\n        loss, accuracy = train_one_step(model, optimizer, x, y)\n        if step % 10 == 0:\n            print('Step', step, ': loss', loss, ':, accuracy', accuracy)\n    return step\n\n_ =  train(model, optimizer)","c19365ed":"def square_if_positive(x):\n    return [i ** 2 if i > 0 else i for i in x]\n\nsquare_if_positive(range(-5, 5))","b7ac8e54":"@tf.function\ndef square_if_positive_naive(x):\n    result = tf.TensorArray(tf.int32, size=len(x))\n    for i in range(len(x)):\n        if x[i] > 0:\n            result = result.write(i, x[i] ** 2)\n        else:\n            result = result.write(i, x[i])\n    return result.stack()\n\nsquare_if_positive_naive(tf.range(-5, 5))","cdd7ea47":"def square_if_positive_vectorized(x):\n    return tf.where(x > 0, x ** 22, x)\n\nsquare_if_positive_vectorized(tf.range(-5, 5))","a0b0c41e":"Note: the example above shows how to perform simple conditionals when scalar values are involved. Typical ML code involves batches; in those cases you should consider using the faster and vecotrized `tf.where` if possible.\n\nAutoGraph supports common Python statements like `while`, `for`, `if`, `break`, `continue`, `return`, with support for nesting. That means you  can use `Tensor` expressions in the condition of `while` and `if` statements, or iterate over a `Tensor` in a `for` loop.","0ba073e5":"AutoGraph also provides a low-level API for advanced users. For example, we can use it to have a look at the generated code.","e3db2086":"TF 2.0 bring together the ease of eager execution and the power of TF 1.0. At the center of this merger is `tf.function` which allows you to transform a subset of Python syntax into protable, high-performance TensorFlow graphs.\n\nA cool new feature of `tf.function` is AutoGraph, which lets you write graph code using natural Python syntax. For a list of the Python features that you can use with AutoGraph, see [AutoGraph capabilities and limitations](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/tensorflow\/python\/autograph\/LIMITATIONS.md). For more details aabout `tf.function` see the RFC [TF 2.0: Functions, not Sessions](https:\/\/github.com\/tensorflow\/community\/blob\/master\/rfcs\/20180918-functions-not-sessions-20.md). For more details about Autograph, see [tf.autograph](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/autograph).\n\nThis tutorial will walk you through the basic features of `tf.function` and AutoGraph.","4449e19a":"### Download data","f8998876":"## A note on batching\n\nIn real applications batching is essential for performance. The best code to convert to AutoGraph is code where the control flow is decided at the *batch* level. If making decisions at the individual *example* level, try to use batch APIs to maintain performance.\n\nFor example, if you have the following code in Python:","53f4f431":"If your code uses multiple functions, you don't need to annotate them all - any functions called from an annotated function will also run in graph mode.","0d1831e4":"### Define the training loop","98f37c6f":"NOTE: I rewrite various notebooks because that's how I learn. I do it on Kaggle because I like their community and other features. Please use and credit original source.\n\nSource: https:\/\/github.com\/tensorflow\/docs\/blob\/master\/site\/en\/r2\/guide\/autograph.ipynb","6a5bb193":"`len` is a shortcut for `.shape[0]`:","db496287":"Install aa temporary patch to enable a few extra TF 2.0 upgrades. This piece will be removed soon.","1581cf54":"## Kears and AutoGraph\n\nYou can use `tf.function` with object methods as well. For example, you can decorate your custom Keras models, typically by annotating the model's `call` function. For more information, see `tf.keras`.","039b88a5":"### Define the model","6d1bf69a":"You may be tempted to write it in TensorFlow as such (and this would work!):","cd46eb70":"If we examine the result of the annotation, we can see that it's a special callable that handles all interactions with the TensorFlow runtime.","6300e979":"## The `tf.function` decorator\n\nWhen you annotate a function with `tf.function`, you can still call it like any other function. But it will be compiled into a graph, which means you get the benefits of faster execution, running on GPU or TPU, or exporting to SavedModel.","61d39257":"## Setup\n\nImport TensorFlow and enable TF 2.0 mode:","be05cf64":"## Example: training a simple model\n\nAutoGraph also allows you to mode more compuration inside TensorFlow, For example, a training loop is just control flow, so it can actually be brought into TensorFlow.","73feb788":"But in this case, it turns out you can write the following:","93271c47":"## Use Python control flow\n\nWhen using data-dependent control flow inside `tf.function`, you can use Python control flow statements and AutoGraph will convert them into appropriate TensorFlow ops. For example, `if` statements will be converted into `tf.cond()` if they depend on a `Tensor`.\n\nIn the example below, x is a `Tensor` but the `if` statement works as expected:","121e0709":"## Use Python print\n\nAutoGraph will also convert Python builtins like `print`.\n\nNote: due to the parallel nature of calculations in TensorFlow, statements might execute out of order. It's best to use `print` only to inspect actual values, and you should not use it to determine whether the program execution reaches a certain point. (What to use for that?)","571fe2ed":"Here's an example of more complicated control flow:","70f1bca5":"# tf.function and AutoGraph in TensorFlow 2.0","d27f5054":"## Side effects\n\nJust like in eager mode, you can use operations with side effects, like `tf.assign` or `tf.print` normally inside `tf.function`, and it will insert the necessary control dependencies to ensure they execute in order.","ae19cba9":"## Other handy conversions\n\nOther builtins that AutoGraph can adapt for TensorFlow are `range` and `len`.\n\n`range` is a shortcut for `tf.range`:"}}