{"cell_type":{"6d75864e":"code","4fcde42c":"code","b5775aa1":"code","a0453fac":"code","a8a8a801":"code","c6acc867":"code","63b6d1ae":"code","021d025b":"code","716f6b6e":"code","d06d7715":"code","c0a63acf":"code","09fe2e6d":"code","e8d39bb6":"code","34517f19":"code","6a3e8cc7":"code","41abbde7":"code","afac3f21":"code","a75ef626":"code","f3d7a9f4":"code","1eb158e5":"code","dfe9c953":"code","a7b94af0":"code","0fc94f7c":"code","b1d61156":"code","b2394d94":"code","65cad78d":"code","a0808b78":"code","f13104b5":"code","04e9c67c":"code","b9b0aeae":"code","242bad48":"code","c15ed912":"code","87b2826a":"code","eda3d14c":"code","3fa7ac1c":"code","2f7c8dd6":"code","17deb4b5":"code","e58a0030":"code","b084fa1d":"code","697a480b":"code","80833fbc":"code","864a2320":"code","d7174b18":"code","deff8f63":"code","51ca8f1a":"markdown","efb51c11":"markdown","abe1af89":"markdown","cdd9e008":"markdown","d02fa062":"markdown","f90051f3":"markdown","43fbcb62":"markdown","07ab0899":"markdown","a809af27":"markdown","55967e35":"markdown","1e5e005a":"markdown","48a45d5d":"markdown","aeb74b95":"markdown","25c6da53":"markdown","5614ac9a":"markdown","0afc2960":"markdown","2873f1ec":"markdown","9690cf84":"markdown","03d4d05c":"markdown","9e7e996c":"markdown","955b41ae":"markdown","fb7801ab":"markdown","02a7e141":"markdown","c0f7145b":"markdown","77d9e623":"markdown","18e21538":"markdown","420b5011":"markdown","e455cbfd":"markdown","81ebf6d4":"markdown","3cac9f30":"markdown","71f48f30":"markdown","62f7bdc8":"markdown","5226ee05":"markdown","84243609":"markdown","958e96c0":"markdown","15bdf327":"markdown","65dc92ec":"markdown","65bdc8ef":"markdown","0c33d130":"markdown","5aabcb63":"markdown","1d5b6a7f":"markdown","b7a0af3d":"markdown","090d0f53":"markdown","febebc28":"markdown","5d6d935f":"markdown"},"source":{"6d75864e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n%matplotlib inline\nimport os","4fcde42c":"print(os.listdir('..\/input'))","b5775aa1":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nsub = pd.read_csv('..\/input\/gender_submission.csv')","a0453fac":"train.head(2)","a8a8a801":"train.info()","c6acc867":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","63b6d1ae":"sns.countplot(x='Survived',data=train)","021d025b":"sns.countplot(x='Survived',hue='Sex',data=train,palette='RdBu_r')","716f6b6e":"sns.countplot(x='Survived',hue='Pclass',data=train)","d06d7715":"sns.distplot(train['Age'].dropna(),kde=False,bins=30)","c0a63acf":"sns.countplot(x='SibSp',data=train)","09fe2e6d":"train['Fare'].hist(bins=40,figsize=(10,4))","e8d39bb6":"plt.figure(figsize=(10,7))\nsns.boxplot(x='Pclass',y='Age',data=train)","34517f19":"mean_pc1 = train[train['Pclass'] == 1]['Age'].mean()\nmean_pc2 = train[train['Pclass'] == 2]['Age'].mean()\nmean_pc3 = train[train['Pclass'] == 3]['Age'].mean()\n\ndef impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass == 1:\n            return mean_pc1\n        elif Pclass == 2:\n            return mean_pc2\n        else:\n            return mean_pc3\n    else:\n        return Age","6a3e8cc7":"mean_pc1 = test[test['Pclass'] == 1]['Age'].mean()\nmean_pc2 = test[test['Pclass'] == 2]['Age'].mean()\nmean_pc3 = test[test['Pclass'] == 3]['Age'].mean()\n\ndef impute_age_test(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass == 1:\n            return mean_pc1\n        elif Pclass == 2:\n            return mean_pc2\n        else:\n            return mean_pc3\n    else:\n        return Age","41abbde7":"train['Age'] = train[['Age','Pclass']].apply(impute_age,axis=1)\ntest['Age'] = test[['Age','Pclass']].apply(impute_age_test,axis=1)","afac3f21":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","a75ef626":"train.drop('Cabin',axis=1,inplace=True)\ntest.drop('Cabin',axis=1,inplace=True)","f3d7a9f4":"train['Embarked'].isna().value_counts()","1eb158e5":"mode_emb = train['Embarked'].mode()[0]\ntrain['Embarked'] = train['Embarked'].fillna(mode_emb)\nprint(mode_emb)","dfe9c953":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","a7b94af0":"train['Title'] = train['Name'].apply(lambda x : x.split(',')[1].split('.')[0].strip())\ntest['Title'] = test['Name'].apply(lambda x : x.split(',')[1].split('.')[0].strip())","0fc94f7c":"train.drop('Name',axis=1,inplace=True)\ntest.drop('Name',axis=1,inplace=True)","b1d61156":"train['Title'].value_counts()","b2394d94":"def impute_title(cols):\n    Title = cols\n    if Title == 'Mr':\n        return 0\n    elif Title == 'Miss' or Title == 'Mrs':\n        return 1\n    else:\n        return 2","65cad78d":"train['Title'] = train['Title'].apply(impute_title)\ntest['Title'] = test['Title'].apply(impute_title)","a0808b78":"train['FamilySize'] = train['SibSp'] + train['Parch']\ntest['FamilySize'] = test['SibSp'] + test['Parch']","f13104b5":" def impute_fare(cols):\n    Fare = cols[0]\n    Pclass = cols[1]\n    if pd.isnull(Fare):            \n        return test[test['Pclass'] == Pclass]['Fare'].mean()\n    else:\n        return Fare","04e9c67c":"test['Fare'] = test[['Fare','Pclass']].apply(impute_fare,axis=1)","b9b0aeae":"sex = pd.get_dummies(train['Sex'],drop_first=True)\npclass = pd.get_dummies(train['Pclass'],drop_first=True)\ntitle = pd.get_dummies(train['Title'],drop_first=True)\nemb = pd.get_dummies(train['Embarked'],drop_first=True)","242bad48":"sex_t = pd.get_dummies(test['Sex'],drop_first=True)\nemb_t = pd.get_dummies(test['Embarked'],drop_first=True)\npclass_t = pd.get_dummies(test['Pclass'],drop_first=True)\ntitle_t = pd.get_dummies(test['Title'],drop_first=True)","c15ed912":"train = pd.concat([train,sex,emb,pclass,title],axis=1)\ntest = pd.concat([test,sex_t,emb_t,pclass_t,title_t],axis=1)\ntrain.head()","87b2826a":"train.drop(['PassengerId','Pclass','SibSp','Parch','Title','Sex','Embarked','Ticket'],axis=1,inplace=True)\ntest.drop(['PassengerId','Pclass','SibSp','Parch','Title','Sex','Embarked','Ticket'],axis=1,inplace=True)","eda3d14c":"X = train.drop('Survived',axis=1)\ny = train['Survived']","3fa7ac1c":"X.head()","2f7c8dd6":"X_train, X_test, y_train, y_test = train_test_split(\nX, y, test_size=0.2, random_state=42)","17deb4b5":"reg = LogisticRegression()","e58a0030":"reg.fit(X_train,y_train)","b084fa1d":"reg.score(X_train,y_train)","697a480b":"y_pred = reg.predict(test)","80833fbc":"y_pred","864a2320":"sub.head()","d7174b18":"sub['Survived'] = y_pred","deff8f63":"sub.to_csv('csv_to_submit.csv',index=False)","51ca8f1a":"### Get the list of data which will be used in this study.","efb51c11":"### It is not advised that to use so many indicators, it will make everything harder for our upcoming ML model. So, impute_title() method is used to create **three** groups out of them to simplify our process.","abe1af89":"## **Exploratory Data Analysis**","cdd9e008":"### train_test_split is used to create *train* and *test* datasets from the initial train dataset which is given. *test* dataset contains randomly collected 20%, *train* dataset contains randomly collected 80% of the initial dataset.","d02fa062":"### A logistic regression object is created from LogisticRegression class.","f90051f3":"### **Hey, you have reached to the target.**","43fbcb62":"### Finally, we have completed our work here and the last step is create the *CSV* file to submit.","07ab0899":"### Drawing a distribution plot by using *Seaborn* library to show the variance in the *Age*.","a809af27":"### Drawing a countplot by using *Seaborn* library to show the number of people survived and couldn't survived from the accident with the aspect of *Sex*.","55967e35":"### Drawing a histogram to show the variance of the *Fare*","1e5e005a":"### After creating dummy columns, the initial columns can be dropped.","48a45d5d":"### If we look carefully to the heatmap which created a cell above. It shows that there are so many null values in the *Cabin* column in the train Data Frame. Also, there is not a logical relationship between *Cabin* and rest of the columns. So, it will be a good call to drop that column and get rid of unrelated data.","aeb74b95":"### Let's look at the Data Dictionary for the *Train* dataset which is given to us, to get information.","25c6da53":"### According to Data Dictionary *SibSp* shows the number of siblings and spouses, *Parch* shows the number of parents and childeren boarded to the ship.","5614ac9a":"### Checking the first two rows of the \"Train Data Frame\" to inspect our columns and data types.","0afc2960":"### Drawing a countplot by using *Seaborn* library to show the number of people survived and couldn't survived from the accident with the aspect of *Person Class*.","2873f1ec":"## **Data Preprocessing**","9690cf84":"### Hence, a sample submission file has given. We can use it as a template to ourselves.","03d4d05c":"### Checking if is there a null value in the *Age* column.","9e7e996c":"### Read the CSV files which are given as competition data.","955b41ae":"### Set our *y_pred* array to *Survived* column of sample submission file.","fb7801ab":"## **Ship Wreck** \n### This is a begginer to beginner kernel. It has not advanced methods in it. Just purposed to give a brief idea about Exploratory Data Analysis,Data Preprocessing and Logistic Regression.","02a7e141":"## **Creating submission file**","c0f7145b":"### Drawing a boxplot by using *Seaborn* library to show the maximum, minimum and the mean ages with the aspect of *Person Class*","77d9e623":"### As we see there are not any **null** columns in the *train* dataset. We can not be sure that there won't be a null *Fare* value in the test dataset. So impute_fare() method is created to fill null Fare values with the mean *Fare* of the passenger's *Person Class*","18e21538":"### These new columns must be inserted to train and test Data Frames. So concat() method is used for this operation.","420b5011":"### impute_age() and impute_age_test() methods are created to fill the null values in the *Age* column with the help of *Pclass* column.\n#### The idea here is to get the mean age of each person class to fill null values in the age column with a closer estimation.","e455cbfd":"### Hence, *Sex* , *Embarked*, *Pclass* and *Embarked* are considered as categorical data, dummies can be applied. This get_dummies() method splits columns into the number of unique values of ones and zeros corresponding to their values. Also, first column of the splitted data is dropped to prevent overfitting of the upcoming machine learning model.","81ebf6d4":"### Finally we got rid of our null values in the Data Frame, as shown in the heatmap below. Yaay!","3cac9f30":"### *y_pred* dataset contains the predicted data from our initial *test* dataset. We can call it our *target*.","71f48f30":"### The null values in the *Age* column of train and test data frames are filled.","62f7bdc8":"### After getting titles, *Name* column will no longer be needed. So, it is dropped from the Data Frame","5226ee05":"## **Creating Dummies**\n### Dummies are used to convert *categorical* variable to *dummy\/indicator* variables.","84243609":"## **Machine Learning Model Implementation**\n### We are trying to predict whether the passenger survived or not. So, the final prediction should consist boolean values which are *True* and *False*.\n### First of all X and y Data Frames are created to train our model. X has *all* columns except *Survived*, y has *Survived* column which will be predicted by the model.","958e96c0":"### As shown in the output below. There are 2 null values in the *Embarked* column. ","15bdf327":"### Drawing a countplot by using *Seaborn* library to show the number of Siblings and Spouses in the ship.","65dc92ec":"### In *Name* column, there are titles for every passenger in the Data Frame. So, I decided to get them to create a new column.","65bdc8ef":"* PassengerId -- The id belongs to the passenger.\n* Survived -- Indicates whether the passenger survived from the Titanic.\n* Sex -- Gender of the passenger.\n* Age -- Age of the passenger.\n* SibSp -- Number of siblings and spouses aboard the Titanic.\n* Parch -- Number of parents and childeren aboard the Titanic.\n* Pclass -- Class of the passenger's ticket. (1st, 2nd and 3rd)\n* Fare -- The amount which passenger has paid for the ticket.\n* Cabin -- The cabin number of the passenger.\n* Embarked -- The port where the passenger aboarded the Titanic. (C,Q,S)","0c33d130":"### So, fill 'em up with the most occured value in the column which is known as the *mode* of that column.","5aabcb63":"### Drawing a countplot by using *Seaborn* library to show the number of people survived and couldn't survived from the accident.","1d5b6a7f":"### **Thank you for looking at my kernel.**\n### **Please share your thoughts with me in the comments section. **","b7a0af3d":"### Import required libraries.","090d0f53":"### A visual approach to the columns to determine the density of null values in a column.","febebc28":"### *X_train* and *y_train* which are created above is fitted to our *Logistic Regression* model.","5d6d935f":"### Checking the unique titles in *Title* column."}}