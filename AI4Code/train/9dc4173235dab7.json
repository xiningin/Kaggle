{"cell_type":{"093c05c4":"code","872ba51b":"code","ccde635f":"code","d3a9c5c9":"code","1bbb9c55":"code","d2786a51":"code","e6d3a8cf":"code","f426557c":"code","b369971a":"code","c37ccf82":"code","12d49145":"code","8d59018a":"code","7ce53871":"code","08eb0a06":"code","d1a05e66":"code","9b315562":"code","088bbd29":"code","2fbe8867":"code","7c3ccb88":"code","36592e81":"code","016aed45":"code","7dbd5eee":"code","636e4978":"code","6e34a31e":"code","b3a2d557":"code","5077a387":"code","a6725770":"code","770bee2a":"code","65d9a166":"code","66706dc4":"code","9434a3cc":"code","f2c3e613":"code","6cbc150a":"code","72bb374d":"code","37a0f66a":"code","795e043e":"code","62b4fea0":"code","b709c6bb":"code","8edb7948":"code","ef852e45":"code","8e0f12d1":"code","12ab8e9b":"code","3d6d77fc":"code","90676c01":"code","019da1c8":"code","e24769ae":"code","61cf2f7d":"code","b1f89d24":"code","c52c9737":"code","b99c41a2":"code","c049b074":"code","52e0cecf":"code","82657755":"code","7869792a":"code","0c695472":"code","c68b337f":"code","ee87d53f":"code","5840f639":"code","e747b081":"code","7e64a3e2":"code","86a0d954":"code","461b3f3e":"code","9524c4fd":"code","5655ffc9":"code","bee35a0e":"code","03b48290":"code","f0a1bf2f":"code","f0cb072d":"code","45267afe":"code","01fe4d13":"code","cfb26b61":"code","ab36c13b":"code","f2ea05fd":"markdown","5d89e071":"markdown","624bd63e":"markdown","59b50d66":"markdown","ab76d44e":"markdown","33435f24":"markdown","0b87c271":"markdown","a928ba9d":"markdown","edb2945c":"markdown","ea117bdf":"markdown","0372ab46":"markdown","4ce418dc":"markdown","96180ffb":"markdown","20530d5b":"markdown","5ef43b6b":"markdown","5e8837a1":"markdown","c15e24fb":"markdown","ddc64b36":"markdown","880eb985":"markdown","a45b17f9":"markdown","dc73b9da":"markdown","50f24807":"markdown","0d2d4739":"markdown","413c4df9":"markdown","519be52d":"markdown","06a89a38":"markdown","c2f5ebe5":"markdown","cb400782":"markdown","628d5f55":"markdown"},"source":{"093c05c4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# from subprocess import check_output\n# print(check_output(['ls', '..\/input']).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","872ba51b":"train = pd.read_csv('..\/input\/train.csv', parse_dates=[\"date\"])\ntest = pd.read_csv('..\/input\/test.csv', parse_dates=[\"date\"])","ccde635f":"train.info()","d3a9c5c9":"print(train.shape)\ntrain.head()","1bbb9c55":"train.columns","d2786a51":"train.describe()","e6d3a8cf":"test.describe()","f426557c":"train['price'].describe()","b369971a":"sns.distplot(train[\"price\"])","c37ccf82":"train[\"log_price\"] = np.log(train[\"price\"] + 1)\nprint(train.shape)\ntrain[[\"price\", \"log_price\"]].head()","12d49145":"figure, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)\nfigure.set_size_inches(18, 4)\nsns.distplot(train[\"price\"], ax=ax1)\nsns.distplot(train[\"log_price\"], ax=ax2)","8d59018a":"train_corr = train.corr()   \nprint(train_corr.shape)\ntrain_corr.head()","7ce53871":"train_corr_abs = abs(train_corr)   # \uc808\ub300\uac12\uc73c\ub85c \ubcc0\ud658\nprint(train_corr_abs.shape)\ntrain_corr_abs","08eb0a06":"f,ax = plt.subplots(figsize=(20,20))\nsns.heatmap(train_corr_abs, annot = True, linewidth=.4, fmt='.1f', ax=ax)\nplt.show()","d1a05e66":"train_corr_price_abs = train_corr_abs[['log_price', 'price']].sort_values(by='log_price', ascending=False)\nprint(train_corr_price_abs.shape)\ntrain_corr_price_abs","9b315562":"f,ax = plt.subplots(figsize=(20,20))\nsns.heatmap(train_corr_price_abs, annot = True, linewidth=.4, fmt='.1f', ax=ax)\nplt.show()","088bbd29":"train_corr_price_abs.index","2fbe8867":"train[\"date-year\"] = train[\"date\"].dt.year\ntest[\"date-year\"] = test[\"date\"].dt.year","7c3ccb88":"sns.barplot(data=train, x=\"date-year\", y=\"price\")","36592e81":"train[[\"date\", \"date-year\", \"yr_built\"]].head()","016aed45":"train[\"period_built\"] = train[\"date-year\"] - train[\"yr_built\"] +1\ntrain[[\"date\", \"date-year\", \"yr_built\", \"period_built\"]].head()","7dbd5eee":"train['period_built'].describe()","636e4978":"fig = plt.figure()\nax = fig.add_subplot(111)\nax.scatter(train['period_built'], train['price'], alpha = 0.3)\nplt.show()","6e34a31e":"test[[\"date\", \"date-year\", \"yr_built\"]].head()","b3a2d557":"test[\"period_built\"] = test[\"date-year\"] - test[\"yr_built\"] +1\ntest[[\"date\", \"date-year\", \"yr_built\", \"period_built\"]].head()","5077a387":"train['sqft_living15'].describe()","a6725770":"train['sqft_living15_trans'] = (train['sqft_living15'] * 0.0281).astype(int) # \ud3c9\uc218\ub85c \uc804\ud658\ntrain[['sqft_living15', 'sqft_living15_trans']].head()","770bee2a":"fig = plt.figure()\nax = fig.add_subplot(111)\nax.scatter(train['sqft_living15_trans'], train['price'], alpha = 0.3)\nplt.show()","65d9a166":"test['sqft_living15_trans'] = (test['sqft_living15'] * 0.0281).astype(int)\ntest[['sqft_living15', 'sqft_living15_trans']].head()","66706dc4":"train['sqft_above'].describe()","9434a3cc":"train['sqft_above_trans'] = (train['sqft_above'] * 0.0281).astype(int)\ntrain[['sqft_above', 'sqft_above_trans']].head()","f2c3e613":"fig = plt.figure()\nax = fig.add_subplot(111)\nax.scatter(train['sqft_above_trans'], train['price'], alpha = 0.3)\nplt.show()","6cbc150a":"test['sqft_above_trans'] = (test['sqft_above'] * 0.0281).astype(int)\ntest[['sqft_above', 'sqft_above_trans']].head()","72bb374d":"train['grade'].describe()","37a0f66a":"sns.barplot(data=train, x=\"grade\", y=\"price\")","795e043e":"train['view'].describe()","62b4fea0":"sns.barplot(data=train, x=\"view\", y=\"price\")","b709c6bb":"train['condition'].describe()","8edb7948":"sns.barplot(data=train, x=\"condition\", y=\"price\")","ef852e45":"train_corr = train.corr()   \nprint(train_corr.shape)\ntrain_corr.head()","8e0f12d1":"train_corr_abs = abs(train_corr)   # \uc808\ub300\uac12\uc73c\ub85c \ubcc0\ud658\nprint(train_corr_abs.shape)\ntrain_corr_abs","12ab8e9b":"f,ax = plt.subplots(figsize=(20,20))\nsns.heatmap(train_corr_abs, annot = True, linewidth=.4, fmt='.1f', ax=ax)\nplt.show()","3d6d77fc":"train_corr_price_abs = train_corr_abs[['log_price', 'price']].sort_values(by='log_price', ascending=False)\nprint(train_corr_price_abs.shape)\nprint(train_corr_price_abs)\ntrain_corr_price_abs2 = train_corr_abs[['log_price', 'price']].sort_values(by='price', ascending=False)\nprint(train_corr_price_abs2.shape)\nprint(train_corr_price_abs2)","90676c01":"f,ax = plt.subplots(figsize=(20,20))\nsns.heatmap(train_corr_price_abs, annot = True, linewidth=.4, fmt='.1f', ax=ax)\nplt.show()","019da1c8":"train_corr_price_abs.index","e24769ae":"print(train.shape)\ntrain","61cf2f7d":"print(test.shape)\ntest","b1f89d24":"train.columns","c52c9737":"feature_names = ['grade', 'sqft_living',\n       'sqft_above_trans', 'bathrooms',\n       'lat', 'long', 'bedrooms', 'view', 'floors', 'sqft_basement', 'waterfront',\n       'yr_renovated', 'period_built', 'sqft_lot', \n       'condition', 'date-year'] \n\nfeature_names","b99c41a2":"label_name = \"log_price\"\nlabel_name","c049b074":"X_train = train[feature_names]\nprint(X_train.shape)\nX_train.head()","52e0cecf":"X_test = test[feature_names]\nprint(X_test.shape)\nX_test.head()","82657755":"log_y_train = train[label_name]\nprint(log_y_train.shape)\nlog_y_train.head()","7869792a":"from sklearn.metrics import make_scorer\n\ndef rmse(predict, actual):\n    score = np.sqrt(((predict-actual)**2).mean())\n    return score\n\nrmse_score = make_scorer(rmse)\nrmse_score","0c695472":"import xgboost as xgb\n\nfrom sklearn.model_selection import cross_val_score","c68b337f":"# # \uc2dc\uac04\uc774 \uc624\ub798\uac78\ub9ac\ub294 \uad00\uacc4\ub85c \uac12 \ud655\uc778 \ud6c4 \uc8fc\uc11d\ucc98\ub9ac (\uc0c1\uc704 10\uac1c \uac12 \uc544\ub798 \uae30\uc785)\n# # Coarse Search \n\n# num_epoch = 100\n\n# coarse_hyperparameters_list = []\n\n# for epoch in range(num_epoch):\n#     n_estimators = np.random.randint(low=100, high=1000)\n\n#     max_depth = np.random.randint(low=2, high=100)\n\n#     learning_rate = 10 ** -np.random.uniform(low=0, high=10)\n\n#     subsample = np.random.uniform(low=0.1, high=1.0)\n\n#     colsample_bytree = np.random.uniform(low=0.4, high=1.0)\n\n#     colsample_bylevel = np.random.uniform(low=0.4, high=1.0)\n\n    \n#     model = xgb.XGBRegressor(n_estimators=n_estimators,\n#                              max_depth=max_depth,\n#                              learning_rate=learning_rate,\n#                              subsample=subsample,\n#                              colsample_bylevel=colsample_bylevel,\n#                              colsample_bytree=colsample_bytree,\n#                              seed=35)\n\n\n#     score = cross_val_score(model, X_train, log_y_train, cv=20, scoring=rmse_score).mean()\n    \n#     hyperparameters = {\n#         'epoch': epoch,\n#         'n_estimators': n_estimators,\n#         'max_depth': max_depth,\n#         'learning_rate': learning_rate,\n#         'subsample': subsample,\n#         'colsample_bylevel': colsample_bylevel,\n#         'colsample_bytree': colsample_bytree,\n#         'score': score\n#     }\n\n#     coarse_hyperparameters_list.append(hyperparameters)\n\n#     print(f\"{epoch:2} n_estimators = {n_estimators}, max_depth = {max_depth:2}, learning_rate = {learning_rate:.10f}, subsample = {subsample:.6f}, colsample_bylevel = {colsample_bylevel:.6f}, colsample_bytree = {colsample_bytree:.6f}, Score = {score:.5f}\")\n\n\n# coarse_hyperparameters_list = pd.DataFrame.from_dict(coarse_hyperparameters_list)\n\n# coarse_hyperparameters_list = coarse_hyperparameters_list.sort_values(by=\"score\")\n\n\n# print(coarse_hyperparameters_list.shape)\n\n# coarse_hyperparameters_list.head(10)","ee87d53f":"# coarse_hyperparameters_list \uc0c1\uc704 10\uac1c \uac12\n# \tcolsample_bylevel\tcolsample_bytree\tepoch\tlearning_rate\tmax_depth\tn_estimators\tscore\tsubsample\n# 26\t0.905786\t0.775778\t26\t0.012984\t81\t620\t0.160483\t0.844448\n# 76\t0.566049\t0.687101\t76\t0.019889\t56\t575\t0.160867\t0.608273\n# 10\t0.748305\t0.913150\t10\t0.027850\t40\t778\t0.161094\t0.648715\n# 66\t0.492319\t0.818670\t66\t0.039377\t44\t703\t0.161677\t0.790363\n# 89\t0.895474\t0.951872\t89\t0.007535\t86\t978\t0.162777\t0.940204\n# 51\t0.741066\t0.971158\t51\t0.048315\t63\t505\t0.163107\t0.522884\n# 43\t0.889138\t0.998115\t43\t0.036997\t61\t664\t0.165543\t0.181896\n# 87\t0.617580\t0.486746\t87\t0.029929\t85\t879\t0.166008\t0.322514\n# 69\t0.605612\t0.899400\t69\t0.056621\t96\t621\t0.167002\t0.273504\n# 44\t0.892544\t0.456279\t44\t0.032803\t40\t255\t0.167648\t0.433693","5840f639":"# # \uc2dc\uac04\uc774 \uc624\ub798\uac78\ub9ac\ub294 \uad00\uacc4\ub85c \uac12 \ud655\uc778 \ud6c4 \uc8fc\uc11d\ucc98\ub9ac (\uc0c1\uc704 10\uac1c \uac12 \uc544\ub798 \uae30\uc785)\n\n# #Finer Search\n\n# num_epoch = 100\n\n# finer_hyperparameters_list = []\n\n# for epoch in range(num_epoch):\n#     n_estimators = np.random.randint(low= 500, high= 1000)\n#     max_depth = np.random.randint(low= 35, high= 90)\n#     learning_rate = 10 ** -np.random.uniform(low= 1, high= 3)\n#     subsample = np.random.uniform(low= 0.5, high= 1.0)\n#     colsample_bytree = np.random.uniform(low= 0.6, high=1.0)\n#     colsample_bylevel = np.random.uniform(low=0.4, high=1.0)\n#     model = xgb.XGBRegressor(n_estimators=n_estimators,\n#                              max_depth=max_depth,\n#                              learning_rate=learning_rate,\n#                              subsample=subsample,\n#                              colsample_bylevel=colsample_bylevel,\n#                              colsample_bytree=colsample_bytree,\n#                              seed=35)\n#     score = cross_val_score(model, X_train, log_y_train, cv=20, scoring=rmse_score).mean()\n\n#     hyperparameters = {\n#         'epoch': epoch,\n#         'score': score,\n#         'n_estimators': n_estimators,\n#         'max_depth': max_depth,\n#         'learning_rate': learning_rate,\n#         'subsample': subsample,\n#         'colsample_bylevel': colsample_bylevel,\n#         'colsample_bytree': colsample_bytree,\n#     }\n\n#     finer_hyperparameters_list.append(hyperparameters)\n\n#     print(f\"{epoch:2} n_estimators = {n_estimators}, max_depth = {max_depth:2}, learning_rate = {learning_rate:.10f}, subsample = {subsample:.6f}, colsample_bylevel = {colsample_bylevel:.6f}, colsample_bytree = {colsample_bytree:.6f}, Score = {score:.5f}\")\n\n# finer_hyperparameters_list = pd.DataFrame.from_dict(finer_hyperparameters_list)\n\n# finer_hyperparameters_list = finer_hyperparameters_list.sort_values(by=\"score\")\n\n# print(finer_hyperparameters_list.shape)\n\n# finer_hyperparameters_list.head(10)","e747b081":"# # finer_hyperparameters_list \uc0c1\uc704 10\uac1c \uac12\n# \tcolsample_bylevel\tcolsample_bytree\tepoch\tlearning_rate\tmax_depth\tn_estimators\tscore\tsubsample\n# 77\t0.945440\t0.716207\t77\t0.012352\t57\t784\t0.159183\t0.518462\n# 75\t0.568592\t0.856282\t75\t0.014767\t88\t920\t0.159186\t0.560818\n# 30\t0.669199\t0.867096\t30\t0.018533\t55\t661\t0.159456\t0.662782\n# 21\t0.640838\t0.813904\t21\t0.015461\t86\t926\t0.159467\t0.537221\n# 58\t0.744535\t0.769410\t58\t0.010110\t43\t968\t0.159726\t0.954902\n# 73\t0.679905\t0.878580\t73\t0.015902\t54\t939\t0.159755\t0.503059\n# 32\t0.755865\t0.925292\t32\t0.012935\t77\t757\t0.160132\t0.673962\n# 70\t0.474171\t0.911513\t70\t0.022869\t49\t656\t0.160185\t0.713985\n# 88\t0.551497\t0.768746\t88\t0.026950\t74\t680\t0.160219\t0.767849\n# 22\t0.893991\t0.988563\t22\t0.012484\t44\t897\t0.160219\t0.638358","7e64a3e2":"# # Coarse-Finer\ub97c \uc8fc\uc11d\ucc98\ub9ac \ud558\uba70 \ud568\uaed8 \uc8fc\uc11d\ucc98\ub9ac (\ucd5c\uc801\uac12 \uc544\ub798 \uae30\uc785)\n\n# #best_hyperparameters\n\n# best_hyperparameters = finer_hyperparameters_list.iloc[0]\n\n# best_n_estimators = int(best_hyperparameters[\"n_estimators\"])\n\n# best_max_depth = int(best_hyperparameters[\"max_depth\"])\n\n# best_learning_rate = best_hyperparameters[\"learning_rate\"]\n\n# best_subsample = best_hyperparameters[\"subsample\"]\n\n# best_colsample_bytree = best_hyperparameters[\"colsample_bytree\"]\n\n# best_colsample_bylevel = best_hyperparameters[\"colsample_bylevel\"]\n\n# print(f\"n_estimators(best) = {best_n_estimators}, max_depth(best) = {best_max_depth}, learning_rate(best) = {best_learning_rate:.6f}, subsample(best) = {best_subsample:.6f}, colsample_bytree(best) = {best_colsample_bytree:.6f}, colsample_bylevel(best) = {best_colsample_bylevel:.6f}\")","86a0d954":"# Coarse-Finer Search\ub85c \ucc3e\uc740 \ucd5c\uc801\uac12 (\uc774 \uac12\uc744 \uc0ac\uc6a9\ud560 \uacbd\uc6b0 \uc18c\uc218\uc810 \ub4f1\uc758 \uc774\uc720\ub85c \uc778\ud558\uc5ec \uc704\uc758 Coarse-Finer\ub85c \ub098\uc628 \uc2e4\uc81c \uac12\uc744 \uc2e4\ud589\ud588\uc744 \ub54c\uc758 score\ubcf4\ub2e4 \uc0b4\uc9dd \uc548\uc88b\uac8c \ub098\uc634)\nbest_n_estimators = 784\nbest_max_depth = 57\nbest_learning_rate = 0.012352 \nbest_subsample = 0.518462\nbest_colsample_bytree = 0.716207\nbest_colsample_bylevel = 0.945440","461b3f3e":"model = xgb.XGBRegressor(n_estimators=best_n_estimators,\n                         max_depth=best_max_depth,\n                         learning_rate=best_learning_rate,\n                         subsample=best_subsample,\n                         colsample_bytree=best_colsample_bytree,\n                         colsample_bylevel=best_colsample_bylevel,\n                         seed=35)\n\nmodel","9524c4fd":"# from sklearn.ensemble import RandomForestRegressor\n\n# model = RandomForestRegressor(n_estimators=best_n_estimators,\n#                               max_depth=best_max_depth,\n#                               random_state=35,\n#                               n_jobs=-1)","5655ffc9":"# from sklearn.ensemble import RandomForestRegressor\n\n# model = RandomForestRegressor(n_jobs=-1,\n#                               random_state=35)\n# model","bee35a0e":"y_train= np.exp(log_y_train) - 1    # score \ud655\uc778\uc744 \uc704\ud55c log\ud574\uc81c","03b48290":"# score \ud655\uc778\ud558\uae30\nfrom sklearn.model_selection import cross_val_score\n\nscore = cross_val_score(model, X_train, y_train,\n                        cv=20, scoring=rmse_score).mean()\n\nprint(\"Score = {0:.5f}\".format(score))","f0a1bf2f":"model.fit(X_train,log_y_train)","f0cb072d":"log_predictions = model.predict(X_test)\nprint(log_predictions.shape)\nlog_predictions","45267afe":"predictions = np.exp(log_predictions) - 1\nprint(predictions.shape)\npredictions","01fe4d13":"submission = pd.read_csv(\"..\/input\/sample_submission.csv\")\nprint(submission.shape)\nsubmission.head()","cfb26b61":"submission[\"price\"] = predictions\nprint(submission.shape)\nsubmission.head()","ab36c13b":"submission = pd.DataFrame({\"id\": submission.id, \"price\": submission.price})\nsubmission.to_csv(\"submission.csv\", index=False)","f2ea05fd":"- XGBoost(Coarse-Finer \uac12\uc744 \uc9c1\uc811 \uc801\uc6a9\ud588\uc744 \ub54c) -> Score = 120620.73074 \n- XGBoost(\uc18c\uc22b\uc810 6\uc790\ub9ac\uae4c\uc9c0 \ud45c\ud604\ub41c \ucd5c\uc801\uac12\uc744 \uc801\uc6a9\ud588\uc744 \ub54c) -> 121049.17630\n- Random forest -> Score = 129903.55902\n- Random forest(best_n_estimator, best_max_depth \ubbf8\uc801\uc6a9) -> Score = 134658.01205\n*  (\uc2e4\uc81c \uc81c\ucd9c \uc2a4\ucf54\uc5b4\ubcf4\ub2e4 \uc0b4\uc9dd \ub192\uac8c \ub098\uc634)","5d89e071":"### \ucd94\uac00\ub41c \ub370\uc774\ud130\ub97c \ud3ec\ud568\ud55c \uc0c1\uad00\uacc4\uc218 \uad6c\ud558\uae30","624bd63e":"6. view","59b50d66":"### \uc804\uccb4 \ubcc0\uc218\ub4e4\uc758 \uc0c1\uad00\uacc4\uc218 \uad6c\ud558\uae30","ab76d44e":"1. date","33435f24":"7. condition","0b87c271":"4. sqft_above","a928ba9d":"## **\uc804\uccb4 \ub370\uc774\ud130 \ud0d0\uc0c9\ud558\uae30**","edb2945c":"Score \ube44\uad50","ea117bdf":"3. sqft_living15","0372ab46":"## **\uc885\uc18d\ubcc0\uc218 'price' \ud0d0\uc0c9**","4ce418dc":"### \uadf8 \uc678 \ubcc0\uc218 \ud0d0\uc0c9","96180ffb":"### 'price', 'log_price' \uc640 \uc9c1\uc811 \uc5f0\uad00\uc774 \uc788\ub294 \ubcc0\uc218 \ucc3e\uae30 (\ucd94\uac00 \ub370\uc774\ud130 \ud3ec\ud568)","20530d5b":"## **Predict**","5ef43b6b":"### \ucd5c\uc885 \ub370\uc774\ud130 \ud655\uc778","5e8837a1":"XGBoost","c15e24fb":"## **Submit**","ddc64b36":"## **Hyperparameter Tuning**\nCoarse-Finer Search","880eb985":"## **Evaluate**","a45b17f9":"Random forest (best_n_estimator, best_max_depth \ubbf8\uc801\uc6a9)","dc73b9da":"2. built_period","50f24807":"### 'price', 'log_price' \uc640 \uc9c1\uc811 \uc5f0\uad00\uc774 \uc788\ub294 \ubcc0\uc218 \ucc3e\uae30","0d2d4739":"## **Explore & Preprocessing**","413c4df9":"## **Load data**","519be52d":"## **XGBoost VS Random forest**","06a89a38":"Random forest","c2f5ebe5":"## **Fit**","cb400782":"## **Train**","628d5f55":"5. grade"}}