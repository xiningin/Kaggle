{"cell_type":{"00acb0be":"code","e9d41622":"code","ff369a96":"code","7bdadb9c":"code","a35f5df0":"code","2859a67e":"code","1e72741d":"code","2e29f6f5":"code","225201e6":"code","d7fdbd6b":"code","b33e076b":"code","769b3382":"code","e231da64":"code","e5edd68f":"code","9d2a8760":"code","f4edcaf4":"markdown"},"source":{"00acb0be":"!pip install pytorch2keras","e9d41622":"pip install onnx==1.8.1","ff369a96":"! pyinstaller --hidden-import onnx.onnx_cpp2py_export <script_name.py>","7bdadb9c":"!pip install -U tensorflow==1.14.0","a35f5df0":"import tensorflow as tf\n\ntf.__version__","2859a67e":"!pip install keras==2.3.1","1e72741d":"!pip install git+https:\/\/www.github.com\/keras-team\/keras-contrib.git","2e29f6f5":"import numpy as np\nimport torch\nfrom torch.autograd import Variable\nfrom pytorch2keras import converter","225201e6":"vgg = torch.hub.load('pytorch\/vision:v0.10.0', 'vgg19', pretrained=True)","d7fdbd6b":"input_np = np.random.uniform(0, 1, (1, 3, 224, 224))\ninput_var = Variable(torch.FloatTensor(input_np))\nvgg=converter.pytorch_to_keras(vgg,input_var, [(3,224,224)])","b33e076b":"vgg.save_weights('.\/vgg19.h5')","769b3382":"vgg.trainable_variables","e231da64":"v=VGG19(include_top=True, weights=None)\n\nv.load_weights('.\/vgg19.h5',by_name=True)","e5edd68f":"v.summary()","9d2a8760":"\n\nclass Pytorch2KerasTestNet(torch.nn.Module):\n    def __init__(self):\n        super(Pytorch2KerasTestNet, self).__init__()\n        self.conv1 = ConvLayer(3, 32, kernel_size=9, stride=1)\n        self.in1 = torch.nn.InstanceNorm2d(32, affine=True)\n        self.relu = torch.nn.ReLU()\n\n    def forward(self, x):\n        y = self.relu(self.in1(self.conv1(x)))\n        return y\n\n\nclass ConvLayer(torch.nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride):\n        super(ConvLayer, self).__init__()\n        reflection_padding = kernel_size \/\/ 2\n        self.reflection_pad = torch.nn.ReflectionPad2d(reflection_padding)\n        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n\n    def forward(self, x):\n        out = self.reflection_pad(x)\n        \n        print(\"conv2d\")\n        out = self.conv2d(out)\n        return out\n        \nmodel   = Pytorch2KerasTestNet()\n\ninput_np = np.random.uniform(0, 1, (1, 3, 224, 224))\ninput_var = Variable(torch.FloatTensor(input_np))\nk_model = converter.pytorch_to_keras(model, input_var, [(3, 224, 224,)], verbose=True) \nk_model.summary() \n\n#\u4fdd\u5b58\u6a21\u578b\nk_model.save_weights('w.h5')","f4edcaf4":"## If you see this plz vote, hope this helps you for your application"}}