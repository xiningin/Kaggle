{"cell_type":{"c27552dd":"code","aefc5929":"code","f930fafb":"code","74e51429":"code","46459e21":"code","bc77e473":"code","e8f8f9bd":"code","a083dd89":"code","f437f326":"code","b2e71793":"code","dc9b0da8":"code","f58910ac":"code","31278f1e":"code","d9e60390":"code","6ced9c07":"code","fd11876b":"code","50821518":"code","ebc919c6":"code","0708c764":"code","e4e414d8":"code","1125c8b6":"code","e69299b6":"code","e9ef9078":"code","bdec9436":"code","7cc33d24":"code","b92f583d":"markdown","ffc3b397":"markdown","75d88aca":"markdown","d2085960":"markdown","0940fe75":"markdown","3a3ab42f":"markdown","e6268b04":"markdown","e1b52fb2":"markdown","0482fb9a":"markdown","2c81873a":"markdown"},"source":{"c27552dd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom sklearn.tree import DecisionTreeRegressor\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aefc5929":"train = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\ntest = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')\nsubmission = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')\nitems = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\nitem_cats = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\nshops = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv')","f930fafb":"train.head()","74e51429":"ts=train.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,8))\nplt.title('Total Sales of the company')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts);","46459e21":"plt.figure(figsize=(20,5))\n\nindex = [str(i) for i in train[\"shop_id\"].value_counts().index]\nvalue = train[\"shop_id\"].value_counts()\nplt.bar(index, value, color=\"blue\", alpha=0.5)\nplt.xlabel(\"Shop_ID\")\nplt.ylabel(\"Item_Counts\")\nplt.title(\"ShopID\/ItemCounts Visulation\")\n","bc77e473":"train = train[train.item_price <= 100000]\ntrain = train[train.item_cnt_day <= 1000]\ntrain","e8f8f9bd":"test_shops = test.shop_id.unique()\ntrain = train[train.shop_id.isin(test_shops)]\ntest_items = test.item_id.unique()\ntrain = train[train.item_id.isin(test_items)]\ntrain.head()","a083dd89":"subDroppedDf = ['date', 'date_block_num', 'shop_id', 'item_id','item_cnt_day']\ntrain.drop_duplicates(subDroppedDf,keep='first', inplace=True) \ntrain.reset_index(drop=True, inplace=True)","f437f326":"ax = sns.distplot(train.groupby('date_block_num').sum()['item_cnt_day'], color=\"navy\")\nplt.show()","b2e71793":"train['date'] = pd.to_datetime(train['date'], format='%d.%m.%Y')","dc9b0da8":"dataset = train.pivot_table(index=['item_id', 'shop_id'], values=['item_cnt_day'],columns='date_block_num', fill_value=0)\ndataset = dataset.reset_index()\ndataset.head()","f58910ac":"dataset = pd.merge(test, dataset, on=['item_id', 'shop_id'], how='left')\ndataset = dataset.fillna(0)\ndataset.head()","31278f1e":"dataset = dataset.drop(['shop_id', 'item_id', 'ID'], axis=1)\ndataset.head()","d9e60390":"y_t = dataset.iloc[:,-1:]\n\nx_t = dataset.iloc[:,1:]\nx_t.drop(dataset.iloc[:,-1:], axis = 1, inplace = True)\n\nx_t = (x_t - np.min(x_t)) \/ (np.max(x_t) - np.min(x_t))","6ced9c07":"x_t","fd11876b":"y_t","50821518":"x = x_t.iloc[:, :]\ny = y_t.values.reshape(-1,1)\n# y.astype(int)","ebc919c6":"x.shape","0708c764":"y.shape","e4e414d8":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)","1125c8b6":"model = LinearRegression()  \nmodel.fit(x, y) \n\nprint(model.score(x_train, y_train))","e69299b6":"print(model.intercept_)\nprint(model.coef_)","e9ef9078":"pred = model.predict(x_test)","bdec9436":"mae = metrics.mean_absolute_error(model.predict(x_test), y_test)\nmse = metrics.mean_squared_error(model.predict(x_test), y_test)\nrmse = np.sqrt(mse)\n\nprint('Mean Absolute Error (MAE): %.2f' % mae)\nprint('Mean Squared Error (MSE): %.2f' % mse)\nprint('Root Mean Squared Error (RMSE): %.2f' % rmse)","7cc33d24":"plt.figure(figsize=(15,8))\nplt.scatter(y_test, model.predict(x_test), color='r')\nplt.xlabel(\"Actual Values:\")\nplt.ylabel(\"Predicted Valuess:\")\nplt.title(\"Actual vs Predicted Values:\")\nplt.show()","b92f583d":"Train datam\u0131z \u00fczerinde \u00e7e\u015fitli filtreleme i\u015flemleri yap\u0131yoruz.","ffc3b397":"Test datas\u0131 ile pivot tablosunu birle\u015ftirme.","75d88aca":"Verilerin okunmas\u0131.","d2085960":"S\u00fctunlar\u0131 ay olan pivot tablosu olu\u015fturma.","0940fe75":"\u0130smail Emre Bay\u0131rl\u0131\n150202056","3a3ab42f":"Shop id ve item say\u0131s\u0131 g\u00f6rselle\u015ftirmeleri.","e6268b04":"Tekrar eden ayn\u0131 verileri temizleme.","e1b52fb2":"Total Sales per Month","0482fb9a":"Kullanmayaca\u011f\u0131m\u0131z verileri tablodan \u00e7\u0131karma.","2c81873a":"E\u011fitimde kullanaca\u011f\u0131m\u0131z verileri ayarlama ne normalizasyon."}}