{"cell_type":{"19751eb9":"code","488e2dfc":"code","225cdd6b":"code","1b09fe56":"code","387aa542":"code","94761d89":"code","ba8b256c":"code","aeffeace":"code","94595902":"code","1a2310da":"code","5a3330d0":"code","a15db549":"code","c2cb4c28":"code","300b0da3":"code","82b87ee4":"code","10b7b7f7":"code","0f12416f":"code","60cf0e18":"code","c1776091":"code","e687da59":"code","0a0c3307":"code","ae092281":"markdown","07888e79":"markdown","14f4a8f2":"markdown","458662dc":"markdown","832a2ccb":"markdown","aa1a3fc3":"markdown","2976d352":"markdown","f9a616a9":"markdown"},"source":{"19751eb9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport cv2\nimport tensorflow as tf\n# from segmentation import build_unet, vgg16_unet, vgg19_unet, resnet50_unet, inception_resnetv2_unet, densenet121_unet\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, Dropout\nfrom tensorflow.keras.models import Model\nfrom sklearn.metrics import f1_score","488e2dfc":"base_directory = '..\/input\/augmented-forest-segmentation\/Forest Segmented\/Forest Segmented'\nimages_folder = os.path.join(base_directory, 'images')\nmasks_folder = os.path.join(base_directory, 'masks')\ndata = pd.read_csv(os.path.join(base_directory, 'meta_data.csv'))","225cdd6b":"data.head()","1b09fe56":"img_dim = 256","387aa542":"def input_target_split(data,images_folder,masks_folder,dim):\n    dataset = []\n    for index, row in data.iterrows():\n        image = load_img(os.path.join(images_folder, row['image']), target_size=(dim,dim)) \n        mask = load_img(os.path.join(masks_folder, row['mask']), target_size=(dim,dim), color_mode='grayscale')\n        image = img_to_array(image)\n        image = image\/255.0\n        mask = img_to_array(mask)\n        mask = mask\/255.0\n        dataset.append((image,mask))\n        print(f\"\\rProgress: {index}\",end='')\n    random.shuffle(dataset)\n    X, Y = zip(*dataset)\n\n    return np.array(X),np.array(Y)\n    ","94761d89":"X, Y = input_target_split(data,images_folder,masks_folder,img_dim)","ba8b256c":"print(\"Image Dimensions: \",X.shape)\nprint(\"Mask Dimensions: \",Y.shape)","aeffeace":"plt.figure(figsize = (15 , 9))\nn = 0\nfor i in range(15):\n    n+=1\n    plt.subplot(5 , 5, n)\n    plt.subplots_adjust(hspace = 0.5 , wspace = 0.3)\n    plt.imshow(X[i])\n    plt.title('Image')","94595902":"plt.figure(figsize = (15 , 9))\nn = 0\nfor i in range(15):\n    n+=1\n    plt.subplot(5 , 5, n)\n    plt.subplots_adjust(hspace = 0.5 , wspace = 0.3)\n    plt.imshow(Y[i])\n    plt.title('Masks')","1a2310da":"split = round(X.shape[0]*0.80)\nX_train = X[:split]\nY_train = Y[:split]\nX_test = X[split:]\nY_test = Y[split:]","5a3330d0":"datagen = ImageDataGenerator()\ntestgen = ImageDataGenerator()","a15db549":"datagen.fit(X_train)\ntestgen.fit(X_test)","c2cb4c28":"def conv_block(input, num_filters):\n    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    \n    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    return x\n\ndef encoder_block(input, num_filters):\n    x = conv_block(input, num_filters)\n    p = MaxPool2D((2, 2))(x)\n    return x, p\n\ndef decoder_block(input, skip_features, num_filters):\n    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n    x = Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters)\n    return x\n\ndef build_unet(input_shape):\n    inputs = Input(input_shape)\n\n    s1, p1 = encoder_block(inputs, 32)\n    s2, p2 = encoder_block(p1, 64)\n    s3, p3 = encoder_block(p2, 128)\n    s4, p4 = encoder_block(p3, 256)\n\n    b1 = conv_block(p4, 512)\n\n    d1 = decoder_block(b1, s4, 256)\n    d2 = decoder_block(d1, s3, 128)\n    d3 = decoder_block(d2, s2, 64)\n    d4 = decoder_block(d3, s1, 32)\n\n    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n\n    model = Model(inputs, outputs, name=\"U-Net\")\n    return model","300b0da3":"from keras import backend as K\ndef iou_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n    iou = K.mean((intersection + smooth) \/ (union + smooth), axis=0)\n    return iou\n\ndef iou_coef_loss(y_true, y_pred):\n    return -iou_coef(y_true, y_pred)\n\ndef iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels = label(y_true_in > 0.5)\n    y_pred = label(y_pred_in > 0.5)\n    \n    true_objects = len(np.unique(labels))\n    pred_objects = len(np.unique(y_pred))\n\n    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n\n    # Compute areas (needed for finding the union between all objects)\n    area_true = np.histogram(labels, bins = true_objects)[0]\n    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n\n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection \/ union\n\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp \/ (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n    \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.array(np.mean(metric), dtype=np.float32)\n\ndef my_iou_metric(label, pred):\n    metric_value = tf.compat.v1.py_func(iou_metric_batch, [label, pred], tf.float32)\n    return metric_value","82b87ee4":"input_shape = (img_dim, img_dim, 3)\nmodel = build_unet(input_shape)\nmodel.summary()","10b7b7f7":"model.compile(optimizer = tf.keras.optimizers.Adam(lr = 0.001), loss = ['binary_crossentropy'], metrics=[iou_coef,'accuracy'])","0f12416f":"model_path = \"unet.h5\"\ncheckpoint = ModelCheckpoint(model_path,\n                             monitor=\"val_loss\",\n                             mode=\"min\",\n                             save_best_only = True,\n                             verbose=1)\n\nearlystop = EarlyStopping(monitor = 'val_loss', \n                          min_delta = 0, \n                          patience = 9,\n                          verbose = 1,\n                          restore_best_weights = True)","60cf0e18":"hist = model.fit_generator(datagen.flow(X_train,Y_train,batch_size=32),\n                                        validation_data=testgen.flow(X_test,Y_test,batch_size=24),\n                                        epochs=50, callbacks=[earlystop, checkpoint])","c1776091":"plt.figure(figsize = (15 , 9))\nn = 0\nfor i in range(0,15):\n    n+=1\n    plt.subplot(5 , 5, n)\n    plt.subplots_adjust(hspace = 0.5 , wspace = 0.3)\n    plt.imshow(Y_test[i])\n    plt.title('Masks')","e687da59":"plt.figure(figsize = (15 , 9))\nresult = model.predict(X_test)\noutput = result[0]\noutput[output >= 0.5] = 1\noutput[output < 0.5] = 0\n\nplt.subplot(1, 3, 1)\nplt.imshow(X_test[0])\n\nplt.subplot(1, 3, 2)\nplt.imshow(Y_test[0])\n\nplt.subplot(1, 3, 3)\nplt.imshow(output)","0a0c3307":"f, axarr = plt.subplots(15,3,figsize=(20, 60))\n\nfor i in range(0,15):\n    output = result[i]\n    output[output >= 0.5] = 1\n    output[output < 0.5] = 0\n\n    axarr[i,0].imshow(X_test[i])\n    axarr[i,0].title.set_text('Original Image')\n    axarr[i,1].imshow(Y_test[i])\n    axarr[i,1].title.set_text('Actual Mask')\n    axarr[i,2].imshow(output)\n    axarr[i,2].title.set_text('Predicted Mask')","ae092281":"### Building the Model","07888e79":"## Conclusion\n- In some cases the segmented masks do not match with the ground truth mask. The reason behind this is that some of the images were not properly labelled during the data preparation.\n- Therefore our model is able to identify certain features that help us segment the forest areas which are not labelled in ground truth images.","14f4a8f2":"### Visualizing the Results","458662dc":"### Costructing the UNET Architecture","832a2ccb":"### Setting early stopping and checkpoint criterion","aa1a3fc3":"### Splitting the data into train and test images","2976d352":"### Compiling the model","f9a616a9":"### Splitting the data into Image and target label"}}