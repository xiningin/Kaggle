{"cell_type":{"1dac62f8":"code","877ce900":"code","f21f86d2":"code","b8a4a8e0":"code","cc4b1a83":"code","f26ab94c":"code","8502ed85":"code","9d2868ae":"code","292b9a9c":"code","20f4b9d6":"code","4e98c796":"code","685c58dd":"code","b41ead40":"code","bbd0eed6":"markdown","c88d98e8":"markdown","11441e69":"markdown","6ca7c995":"markdown","cfdcae90":"markdown","caea7e95":"markdown","4578a688":"markdown","83f2de01":"markdown","02b5a5b3":"markdown","90db17bd":"markdown","5cfde210":"markdown","3879d394":"markdown","3bab5795":"markdown","76a256a5":"markdown","ff29be32":"markdown","be5eaa94":"markdown","835a0202":"markdown","b0dee3b1":"markdown","04d49e91":"markdown","30f9e37b":"markdown"},"source":{"1dac62f8":"import cv2\nfrom skimage import io\nfrom pylab import *\n\nimg_cv2 = cv2.imread('..\/input\/imgbovespa\/squares.png') #same image as the below\nimg_io = io.imread('..\/input\/imgbovespa\/squares.png') #same image as the above\n\nfigure(0)\nio.imshow(img_cv2)\nfigure(1)\nio.imshow(img_io)","877ce900":"from skimage.transform import resize\n\nimg1 = cv2.imread('..\/input\/imgbovespa\/BOVESPA.jpg')\nimg2 = cv2.imread('..\/input\/imgbovespa\/BMSP.jpg')\n\nheight = 200\n\n# Setting images to the same size\nimg1 = resize(img1, (height, round(height*1.55)))\nimg2 = resize(img2, (height, round(height*1.55)))\n\n## The dtype of the arrays with the images is float64,\n## IF I DONT CONVERT ITS TYPE when I try to use the function cv2.COLOR_BGR2RGB, it throws\n## the error: \"Unsupported depth of input image\"\nimg1 = np.float32(img1)\nimg2 = np.float32(img2)\n\n# Converting from BGR to RGB:\nimg1_rgb = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\nimg2_rgb = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n\n# Defining alpha and beta, which indicate the transparency of both images\nalpha = 0.6\nbeta = 0.4\n\n# Blending images\nfinal_img = cv2.addWeighted(img1_rgb, alpha, img2_rgb, beta, 0.0) #this last parameter is gamma\n\nio.imshow(final_img)","f21f86d2":"import numpy as np\n\n#Creating a dummy image that will store different contrast and brightness ahead\ndummy_img = np.zeros(img1.shape, img1.dtype)\nio.imshow(dummy_img)","b8a4a8e0":"dummy_img.dtype","cc4b1a83":"from pylab import *\n\n#Setting the brightness and contrast paramenters\ncontrast = 2.0 # the contrast is the angular coeficient\nbright = 0.1 # the bright is the linear coeficient (this value should be between the 0 and 1 in this case)\n\n#Changing the contrast and brightness by hand\nfor y in range(img1_rgb.shape[0]):\n    for x in range(img1_rgb.shape[1]):\n        for c in range(img1_rgb.shape[2]):\n            dummy_img[y,x,c] = np.clip(contrast*img1_rgb[y,x,c] + bright, 0, 1)# ( c*img[i] + b )\n                                                                               # the pixel vales are 0 to 1\n\nfigure(0)\nio.imshow(img1_rgb)\nfigure(1)\nio.imshow(dummy_img)","f26ab94c":"# Defining the font\nfont = cv2.FONT_HERSHEY_SIMPLEX\n\nimg = img1_rgb.copy()\n\n# Writing on the image:\ncv2.putText(img, \"My name is Victor\", (10, 50), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n\nio.imshow(img)","8502ed85":"img_original = img1_rgb.copy()\nimg_MedianBlur = img1_rgb.copy()\nimg_GaussianBlur = img1_rgb.copy()\nimg_BilateralBlur = img1_rgb.copy()\n\n#Bluring images:\nimg_MedianBlur = cv2.medianBlur(img_MedianBlur, 5)#(image, kernel_size)\nimg_GaussianBlur = cv2.GaussianBlur(img_GaussianBlur, (9, 9), 10)#(image, kernel_size, standard_deviation)\nimg_BilateralBlur = cv2.bilateralFilter(img_BilateralBlur, 9, 100, 75) #(image, diameter_pixel_neighborhood, sigma_value_for_color, sigma_value_for_space)\n\n#Showing images:\nfigure(0)\nio.imshow(img_original)\nfigure(1)\nio.imshow(img_MedianBlur)\nfigure(2)\nio.imshow(img_GaussianBlur)\nfigure(3)\nio.imshow(img_BilateralBlur)","9d2868ae":"img = img1_rgb.copy()\n\n# Defining Erosion sizes:\ne1 = 0 # Kernel size -> 1x1\ne2 = 2 # Kernel size -> 5x5\ne3 = 4 # Kernel size -> 9x9\n\n# Definind erosion type:\nt1 = cv2.MORPH_RECT\nt2 = cv2.MORPH_CROSS\nt3 = cv2.MORPH_ELLIPSE\n\n# Defining and saving the erosion template:\ntmp1 = cv2.getStructuringElement(t1, (2*e1 + 1, 2*e1 + 1), (e1, e1)) #(type, kernel_size, point_start)\ntmp2 = cv2.getStructuringElement(t2, (2*e2 + 1, 2*e2 + 1), (e2, e2))\ntmp3 = cv2.getStructuringElement(t3, (2*e3 + 1, 2*e3 + 1), (e3, e3))\n\n#Applying the erosion template to the image and save in different variables:\nfinal1 = cv2.erode(img, tmp1)\nfinal2 = cv2.erode(img, tmp2)\nfinal3 = cv2.erode(img, tmp3)\n\nfigure(0)\nio.imshow(final1)\nfigure(1)\nio.imshow(final2)\nfigure(2)\nio.imshow(final3)","292b9a9c":"img = img1_rgb.copy()\n\n# Defining the dilation sizes (or the kernel sizes):\nd1 = 0 # Kernel size -> 1x1\nd2 = 2 # Kernel size -> 5x5\nd3 = 4 # Kernel size -> 9x9\n\n# Defining the dilation type\nt1 = cv2.MORPH_RECT\nt2 = cv2.MORPH_CROSS\nt3 = cv2.MORPH_ELLIPSE\n\n# Storing the dilation templates\ntmp1 = cv2.getStructuringElement(t1, (2*d1 + 1, 2*d1 + 1), (d1, d1))\ntmp2 = cv2.getStructuringElement(t2, (2*d2 + 1, 2*d2 + 1), (d2, d2))\ntmp3 = cv2.getStructuringElement(t3, (2*d3 + 1, 2*d3 + 1), (d3, d3))\n\n# Applying dilation to the images\nfinal1 = cv2.dilate(img, tmp1)\nfinal2 = cv2.dilate(img, tmp2)\nfinal3 = cv2.dilate(img, tmp3)\n\n# Show the images\nfigure(0)\nio.imshow(final1)\nfigure(1)\nio.imshow(final2)\nfigure(2)\nio.imshow(final3)","20f4b9d6":"img = img1_rgb.copy()\n\n# Mapping threshold types to numbers as accepted by the function cv2.threshold:\n# 0 - Binary\n# 1 - Binary Inverted\n# 2 - Truncated\n# 3 - Threshold to Zero\n# 4 - Threshold to Zero Inverted\n\n# Or I could use for example cv2.THRESH_BINARY, cv2.THRESH_BINARY_INV ... etc ...\n\nthreshold = 0.4\n\n# Applying different thresholds and saving in different variables\n_, img_threshold1 = cv2.threshold(img, threshold, 1, cv2.THRESH_BINARY)\n_, img_threshold2 = cv2.threshold(img, threshold, 1, cv2.THRESH_BINARY_INV)\n_, img_threshold3 = cv2.threshold(img, threshold, 1, cv2.THRESH_TRUNC)\n_, img_threshold4 = cv2.threshold(img, threshold, 1, cv2.THRESH_TOZERO)\n_, img_threshold5 = cv2.threshold(img, threshold, 1, cv2.THRESH_TOZERO_INV)\n\nfigure(0)\nio.imshow(img_threshold1)\nfigure(1)\nio.imshow(img_threshold2)\nfigure(2)\nio.imshow(img_threshold3)\nfigure(3)\nio.imshow(img_threshold4)\nfigure(4)\nio.imshow(img_threshold5)","4e98c796":"img = cv2.imread('..\/input\/imgbovespa\/squares.png')\n\n# Appling gaussian blur so the noise is removed\nimg = cv2.GaussianBlur(img, (3,3), 0)\n\n# Coverting the image to grayscale\ngray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n\n# Applying the Sobel Method to the grayscale image\n# Horizontal Sobel Derivation:\ngrad_x = cv2.Sobel(gray_img, cv2.CV_16S, 1, 0, ksize=3, scale=1, delta=0, borderType=cv2.BORDER_DEFAULT)\n# Vertical Sobel Derivation:\ngrad_y = cv2.Sobel(gray_img, cv2.CV_16S, 0, 1, ksize=3, scale=1, delta=0, borderType=cv2.BORDER_DEFAULT)\n\nabs_grad_x = cv2.convertScaleAbs(grad_x)\nabs_grad_y = cv2.convertScaleAbs(grad_y)\n\n# Applying both\ngrad_img = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)\n\nfigure(0)\nio.imshow(img)\nfigure(1)\nio.imshow(gray_img)\nfigure(2)\nio.imshow(grad_x)\nfigure(3)\nio.imshow(grad_y)\nfigure(4)\nio.imshow(abs_grad_x)\nfigure(5)\nio.imshow(abs_grad_y)\nfigure(6)\nio.imshow(grad_img)","685c58dd":"src = cv2.imread('..\/input\/imgbovespa\/BOVESPA.jpg', cv2.CV_8UC1)\n\n# We should use a gray scale image to perform histogram equalization\n# didn't need to convert because when I read the image I called the right type: CV_8UC1\n# src = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)\n\n# Applying equalize histogram\nsrc_equalized = cv2.equalizeHist(src) # performs histogram equalization on images of type CV_8UC1\n\n\nfigure(0)\nio.imshow(src)\nfigure(1)\nio.imshow(src_equalized)","b41ead40":"src.dtype","bbd0eed6":"# Calculating Gradients to Detect Edges","c88d98e8":"# Chapter 04 \n### Advanced Image Processing Using OpenCV","11441e69":"# Blending two images","6ca7c995":"Testing how cv2 color works:","cfdcae90":"#### We use the `cv2.threshold()` function to do image thresholding, which uses the following parameters:\n1. The image to convert\n2. The threshold value\n3. The maximum pixel value\n4. The type of thresholding (as listed earlier)\n\nThe second output of the function `cv2.threshold()` is the thresholded image.","caea7e95":"#### Dilation:","4578a688":"So the same images are plotted differently above. That's because RED and BLUE channels are swapped in cv2. ","83f2de01":"### OpenCV imread() reads in BGR, not RGB","02b5a5b3":"Sobel and Feldman presented the idea of an \"Isotropic 3x3 Image Gradient Operator\" at a talk at SAIL in 1968. \n\nWith this algorithm, wee emphasize only those regions that have very high spatial frequency, which may correspond to edges.","90db17bd":"#### My work on the Chapter 4 of the book: Practical Machine Learning and Image Processing  (Himanshu Singh)\n### Content:\n* Blending two images\n* Changing the contrast and brightness of an image\n* Adding text to images\n* Smoothing images\n* Changing the shape of images\n* Effecting image thresholding\n* Calculating gradients to detect edges\n* Performing histogram equalization","5cfde210":"The `cv2.equalizeHist()` function is used for histogram equalization.\n\nThe function `equalizeHist` is histogram equalization of images and only implemented for CV_8UC1 type, which is a single channel 8 bit unsigned integral type.","3879d394":"#### `cv2.putText()` takes following arguments:\n1. Image\n2. Text\n3. Position of the text\n4. Font type\n5. Font scale\n6. Color\n7. Thickness\n8. Type of line used`","3bab5795":"# Performing Histogram Equalization","76a256a5":"# Changing Contrast and Brightness","ff29be32":"# Adding text to images","be5eaa94":"# Changing the shape of Images\nTo erode or dilate an image, we first define the neighborhood kernel, there are more ways than the folowing:\n1. `MORPH_RECT`: to make a rectangular kernel\n2. `MORPH_CROSS`: to make a cross-shaped kernel\n3. `MORPH_ELLIPS`: to make an elliptical kernel\n\nErosion finds the minimum pixel value. Dilation finds the maximum.\n\n`cv2.getStructuringElement()` is the function used to define the kernel and pass it down to the `cv2.erode()` or `cv2.dilate()` function.","835a0202":"# Smoothing images:\nThis section uses 3 filters: `cv2.medianBlur`, `cv2.GausianBlur` and `cv2.bilateralFilter`","b0dee3b1":"# Effecting Image Thresholding\nThresholding methods:\n* `cv2.THRESH_BINARY`\n* `cv2.THRESH_BINARY_INV`\n* `cv2.THRESH_TRUNC`\n* `cv2.THRESH_TOZERO`\n* `cv2.THRESH_TOZERO_INV`\n\n\n\n* `cv2.THRESH_MASK`\n* `cv2.THRESH_OTSU`\n* `cv2.THRESH_TRIANGLE`\n","04d49e91":"#### Erosion:","30f9e37b":"#### cv2 supports following fonts:\n* `FONT_HERSHEY_SIMPLEX`\n* `FONT_HERSHEY_PLAIN`\n* `FONT_HERSHEY_DUPLEX`\n* `FONT_HERSHEY_COMPLEX`\n* `FONT_HERSHEY_TRIPLEX`\n* `FONT_HERSHEY_COMPLEX_SMALL`\n* `FONT_HERSHEY_SCRIPT_SIMPLEX`\n* `FONT_HERSHEY_SCRIPT_COMPLEX`\n* `FONT_ITALIC`\n\n#### And these types of images:\n* `FILLED`: a completely filled line\n* `LINE_4`: four connected lines\n* `LINE_8`: eight connected lines\n* `LINE_AA`: an anti-aliasing line"}}