{"cell_type":{"f6dbd19c":"code","53e2a5ec":"code","9efb6b48":"code","e9ad96b2":"code","7c0df856":"code","bd21d674":"code","e8b9c0b3":"code","1d16facd":"code","0699cfbc":"code","8e8e3ac2":"code","9337659f":"code","b3f9b9c3":"code","c698389a":"code","6df29790":"code","01b733f9":"code","c96860b2":"code","272cea73":"code","e9528baf":"code","de13c987":"code","8a12b326":"code","de468165":"code","110f2645":"code","aec128ba":"code","7dad1a3f":"code","b646e977":"code","63d8e9b0":"code","0abfa1d7":"code","990c96bf":"code","effe8824":"code","ee6087c2":"code","251c15c9":"code","2e799cbd":"markdown","85c9ee0c":"markdown","61f627da":"markdown","c9905146":"markdown","a14e73b5":"markdown","da8de619":"markdown","07ff369a":"markdown","6cedd19e":"markdown","0316ab1a":"markdown","a17366e5":"markdown","55c488b7":"markdown","0670750c":"markdown","d415ec0e":"markdown","a6f1e074":"markdown","096d4640":"markdown","5677c1d8":"markdown","d4c6247c":"markdown","edbf376b":"markdown","ade928e6":"markdown"},"source":{"f6dbd19c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob\n\n%matplotlib inline","53e2a5ec":"products = pd.read_csv('..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv')\nproducts.sample(10)","9efb6b48":"products.shape","e9ad96b2":"products.info()","7c0df856":"districts = pd.read_csv('..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv')\ndistricts.sample(10)","bd21d674":"districts.shape","e8b9c0b3":"districts.info()","1d16facd":"path = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data' \nall_files = glob.glob(path + \"\/*.csv\")\n\nli = []\n\nfor filename in all_files:\n    df = pd.read_csv(filename, index_col=None, header=0)\n    district_id = filename.split(\"\/\")[4].split(\".\")[0]\n    df[\"district_id\"] = district_id\n    li.append(df)\n    \nengagement_df = pd.concat(li)\nengagement_df = engagement_df.reset_index(drop=True)\nengagement_df.head()","0699cfbc":"engagement_df.shape","8e8e3ac2":"engagement_df.info()","9337659f":"def missing_values_table(df):\n    # Total missing values\n    mis_val = df.isnull().sum()\n\n    # Percentage of missing values\n    mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n\n    # dtype of missing values\n    mis_val_dtype = df.dtypes\n\n    # Make a table with the results\n    mis_val_table = pd.concat([mis_val, mis_val_percent, mis_val_dtype], axis=1)\n\n    # Rename the columns\n    mis_val_table_ren_columns = mis_val_table.rename(\n    columns = {0 : 'Missing Values', 1 : '% of Total Values', 2: 'Dtype'})\n\n    # Sort the table by percentage of missing descending\n    mis_val_table_ren_columns = mis_val_table_ren_columns[\n        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n    '% of Total Values', ascending=False).round(1)\n\n    # Print some summary information\n    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n        \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n          \" columns that have missing values.\")\n\n    # Return the dataframe with missing information\n    return mis_val_table_ren_columns","b3f9b9c3":"# check the percentage of missing data in each column to determine whether we will impute or drop\n\npercentage_missing_products = missing_values_table(products)\npercentage_missing_products","c698389a":"products.dropna(subset=['Sector(s)', 'Primary Essential Function','Provider\/Company Name'],inplace=True)","6df29790":"# check the percentage of missing data in each column to determine whether we will impute or drop\n\npercentage_missing_districts = missing_values_table(districts)\npercentage_missing_districts","01b733f9":"districts.dropna(subset=['state','pct_free\/reduced','county_connections_ratio'],inplace=True)\ndel districts['pp_total_raw']","c96860b2":"# check the percentage of missing data in each column to determine whether we will impute or drop\n\npercentage_missing_engagement_df = missing_values_table(engagement_df)\npercentage_missing_engagement_df","272cea73":"engagement_df.dropna(subset=['engagement_index','pct_access','lp_id'],inplace=True)","e9528baf":"import re\n\ntemp_sectors = products['Sector(s)'].str.get_dummies(sep=\"; \")\ntemp_sectors.columns = [f\"sector_{re.sub(' ', '', c)}\" for c in temp_sectors.columns]\nproducts = products.join(temp_sectors)\nproducts.drop(\"Sector(s)\", axis=1, inplace=True)\n\ndel temp_sectors\n\n","de13c987":"products['primary_function_main'] = products['Primary Essential Function'].apply(lambda x: x.split(' - ')[0] if x == x else x)\nproducts['primary_function_sub'] = products['Primary Essential Function'].apply(lambda x: x.split(' - ')[1] if x == x else x)\n\n# Synchronize similar values\nproducts['primary_function_sub'] = products['primary_function_sub'].replace({'Sites, Resources & References' : 'Sites, Resources & Reference'})\nproducts.drop(\"Primary Essential Function\", axis=1, inplace=True)","8a12b326":"engagement_df['district_id'] = engagement_df['district_id'].astype(int)","de468165":"products.rename(columns={'LP ID': 'lp_id'}, inplace=True)","110f2645":"df = pd.merge(engagement_df,districts,how='inner',on='district_id')\ndf.head()","aec128ba":"df = pd.merge(df,products,how='inner',on='lp_id')","7dad1a3f":"df.head()","b646e977":"df.shape","63d8e9b0":"#group by state\nplt.figure(figsize=(10,10))\n_ = sns.countplot(y='state', data=df, order=df.state.value_counts().index)\nplt.xlabel('count of number')\nplt.title('The number of Districts group by state',fontsize=20)","0abfa1d7":"#group by locale\ngroup = df.groupby('locale').count()\n_ = sns.barplot(x=group.index, y=group.district_id)\nplt.ylabel('count of number')\nplt.title('The number of Districts per locale',fontsize=12)","990c96bf":"#group by pct black\/hispanic\ngroup = df.groupby('pct_black\/hispanic').count()\n_ = sns.barplot(x=group.index, y=group.district_id)\nplt.ylabel('count of number')\nplt.title('The number of Districts per pct_black\/hispanic',fontsize=12)","effe8824":"#group by pct black\/hispanic\ngroup = df.groupby('pct_free\/reduced').count()\n_ = sns.barplot(x=group.index, y=group.district_id)\nplt.ylabel('count of number')\nplt.title('The number of Districts per pct_free\/reduced',fontsize=12)","ee6087c2":"#group by state\nplt.figure(figsize=(10,10))\n_ = sns.countplot(y='Provider\/Company Name', data=df, order=df['Provider\/Company Name'].value_counts().index)\nplt.xlabel('count of number')\nplt.title('The number of Districts group by state',fontsize=20)","251c15c9":"group = districts.groupby('county_connections_ratio').count()\n_ = sns.barplot(x=group.index, y=group.district_id)\nplt.ylabel('count of number')\nplt.title('The number of Districts group by county_connections_ratio',fontsize=12)","2e799cbd":"#### I first need to get a feel of the various dataset and the meaning of their columns","85c9ee0c":"## We'll now combine the three dataframes so we can explore them","61f627da":"### the three dataframes can be joined using district_id and lp_id columns","c9905146":"### let's look at the distribution of districts first","a14e73b5":"## We'll begin exploration now that our data is in a good format","da8de619":"### we will drop data that has a missing engagement index","07ff369a":"### The engagement file contains information about engagement of each tool for each day per school district","6cedd19e":"### Districts contains information about the various districts","0316ab1a":"#### we drop the rows with null values since the percentage is so small","a17366e5":"### we will drop the rows districts with missing states and the columnpp_total_raw ","55c488b7":"## We now have a new dataframe","0670750c":"district id needs to be converted to float\nwe'll also one hot encode sectors column and split primary essential function","d415ec0e":"#### Products seems to contain information about the tools used for digital learning we'll have to do processing sector and primary essential function column","a6f1e074":"## Preprocessing ","096d4640":"### what is the state of digital learning in 2020?","5677c1d8":"### First we import all the relevant libraries this is my first Analytics challenge on kaggle so this notebook will keep changing as I add new things","d4c6247c":"let's also rename this column so we can be able to merge later","edbf376b":"### before preprocessing we first check for missing values","ade928e6":"### we dropped quite a lot of values due to nan values but we'll continue regardless we can come back later and impute values after initial analysis"}}