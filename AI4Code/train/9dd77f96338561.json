{"cell_type":{"2095c1e0":"code","fca8eb2b":"code","41cf8c18":"code","8240fc7b":"code","bc01ac49":"code","c77b22b9":"code","a360611b":"code","2a8270b8":"code","fb3823f0":"markdown"},"source":{"2095c1e0":"!pip install -q efficientnet\nimport efficientnet.keras as efn\nfrom keras import backend as K\nfrom keras import regularizers\nfrom keras.applications import densenet\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler, ModelCheckpoint, Callback\nfrom keras.layers import Activation, Conv1D, Conv2D, Dense, Dropout, Flatten, Input, average, concatenate, multiply, MaxPool1D, MaxPooling2D, MaxPool2D, BatchNormalization\nfrom keras.models import Sequential, Model, load_model\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn import *\nfrom sklearn.metrics import *\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf","fca8eb2b":"trainTab = pd.read_csv(\"..\/input\/jpeg-melanoma-256x256\/train.csv\")\ntestTab = pd.read_csv(\"..\/input\/jpeg-melanoma-256x256\/test.csv\")\n\ndim=256\nbs=64\n\ndef append_ext(fn):\n    return fn+\".jpg\"\n\ntrainTab[\"image_name\"]=trainTab[\"image_name\"].apply(append_ext)\ntestTab[\"image_name\"]=testTab[\"image_name\"].apply(append_ext)\n\nRows = np.arange(0, trainTab.shape[0], 1, dtype='int')\n\ntrainRows = np.random.choice(Rows, size=int(trainTab.shape[0]*0.7), replace=False)\nvalRows = [a for a in Rows if not a in trainRows]\n\nprint(len(trainRows))\nprint(len(valRows))","41cf8c18":"train_args = dict(brightness_range = [0.8,1.2], rescale=1.\/255, width_shift_range=0.3,\n                             height_shift_range=0.3, shear_range=0.3, zoom_range=0.3, validation_split=0.3,\n                             horizontal_flip = True, rotation_range = 40)\n\nval_args = dict(rescale=1.\/255)\n\ndatagen = ImageDataGenerator(**train_args)\n\nVdatagen = ImageDataGenerator(**val_args)\n\nTraingenerator = datagen.flow_from_dataframe(\n        dataframe=trainTab.iloc[trainRows],\n        directory='..\/input\/jpeg-melanoma-256x256\/train',\n        x_col= 'image_name', # features\n        y_col= ['target'], # labels\n        class_mode=\"raw\", # 'target' column should be in train_df\n        batch_size= bs, # images per batch\n        shuffle=True, # shuffle the rows or not\n        target_size=(dim,dim) # width and height of output image\n)\n\nValgenerator = Vdatagen.flow_from_dataframe(\n        dataframe=trainTab.iloc[valRows],\n        directory='..\/input\/jpeg-melanoma-256x256\/train',\n        x_col= 'image_name', # features\n        y_col= ['target'], # labels\n        class_mode=\"raw\", # 'target' column should be in train_df\n        batch_size= bs, # images per batch\n        shuffle=False, # shuffle the rows or not\n        target_size=(dim,dim) # width and height of output image\n)\n\nTestgenerator = Vdatagen.flow_from_dataframe(\n        dataframe=testTab,\n        directory='..\/input\/jpeg-melanoma-256x256\/test',\n        x_col= 'image_name', # features\n        class_mode=None, # 'target' column should be in train_df\n        batch_size= 1, # images per batch\n        shuffle=False, # shuffle the rows or not\n        target_size=(dim,dim) # width and height of output image\n)","8240fc7b":"xu=Traingenerator.next()\nxu[0].shape","bc01ac49":"base_model = efn.EfficientNetB0(input_shape=(dim, dim, 3), weights='imagenet', include_top=False, pooling='avg')\n# for layer in base_model.layers:\n#     layer.trainable = False\ny = base_model.output\ny = Dropout(0.3)(y)\ny = Dense(256, activation=\"relu\")(y)\ny = Dense(1, activation='sigmoid')(y)\nmodel = Model(inputs=base_model.input, outputs=y) ","c77b22b9":"def binary_focal_loss(gamma=2., alpha=.75):\n    def binary_focal_loss_fixed(y_true, y_pred):\n        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n\n        epsilon = K.epsilon()\n        # clip to prevent NaN's and Inf's\n        pt_1 = K.clip(pt_1, epsilon, 1. - epsilon)\n        pt_0 = K.clip(pt_0, epsilon, 1. - epsilon)\n\n        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) \\\n               -K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n\n    return binary_focal_loss_fixed\n\n# COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\nmodel.compile(optimizer= 'adam', loss=binary_focal_loss(), metrics=[tf.keras.metrics.AUC()])\nmodel.load_weights(\"..\/input\/mixedmodel\/modelGenerator.h5\")","a360611b":"filepath='modelGenerator.h5'\n\n# CUSTOM LEARNING SCHEUDLE\nLR_START = 1e-5\nLR_MAX = 0.000177978515625\nLR_RAMPUP_EPOCHS = 5\nLR_SUSTAIN_EPOCHS = 0\nLR_STEP_DECAY = 0.75\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)\/\/10)\n    return lr\n  \nlr2 = LearningRateScheduler(lrfn, verbose = True)\nlr_reducer = LearningRateScheduler(lambda x: 0.001 * 0.99 ** x, verbose=True)\n\nEarLY=EarlyStopping(monitor='val_loss', mode='min', min_delta=0, patience=30, verbose=0,\n                                    restore_best_weights=True)\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n\nepochs = 40\ntsteps = int(trainTab.shape[0]*0.7\/bs)\nvsteps = int(trainTab.shape[0]*0.3\/bs)\n\nhistory = model.fit_generator(Traingenerator, epochs = epochs,  \n                              validation_data = Valgenerator,\n                              steps_per_epoch = tsteps, validation_steps=vsteps,\n                              callbacks=[lr2, EarLY, checkpoint])","2a8270b8":"predi=model.predict_generator(Testgenerator, steps=testTab.shape[0], verbose=1)\nsubmi = pd.read_csv(\"..\/input\/jpeg-melanoma-256x256\/sample_submission.csv\")\nsubmi[\"target\"]=predi\nsubmi.to_csv(\"submiJPG.csv\", index=False)","fb3823f0":"# Import packages"}}