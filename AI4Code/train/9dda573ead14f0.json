{"cell_type":{"c7d3aa98":"code","0c9eab97":"code","060dc763":"code","eebc4270":"code","2815b789":"code","70b11038":"code","c0c01e1d":"code","fbec3257":"code","e0047c1f":"code","5ca2d921":"code","d2c8dd2c":"code","f4d0ea24":"code","c3d6067e":"code","9404c8d7":"code","723f1a6b":"code","b90fd02d":"code","7d624f8f":"code","d93e45c7":"code","383a31b3":"code","b6ac08f9":"code","0a0d01f4":"code","7502efa5":"code","67d16bb5":"code","2afdcc6c":"code","2ade6901":"code","8c42b8ce":"code","910c6f3a":"code","3eafa378":"code","3f085a48":"code","dd7c5f71":"code","0eae9420":"code","524eeaff":"code","8a3f0478":"code","dd1fef79":"code","d925f88a":"code","c858393c":"code","aed8a86d":"code","b75de2a2":"code","b647f3ec":"code","78e5b527":"code","d679322c":"code","cf095c1a":"code","dc1a9806":"markdown","89c3fa1e":"markdown","3718f62d":"markdown","70170a29":"markdown","fcf48660":"markdown"},"source":{"c7d3aa98":" pip install imblearn\n\nTo enable plotting graphs in Jupyter notebook\n%matplotlib inline ","0c9eab97":"import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\n\n\nimport matplotlib.pyplot as plt   \n\n\nimport seaborn as sns\n\n\n\nfrom sklearn.model_selection import train_test_split\n\nimport numpy as np\n\n\nfrom sklearn import metrics\n\n\nfrom sklearn.metrics import recall_score\n\nfrom imblearn.over_sampling import SMOTE","060dc763":"\n\ncolnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n\n\npima_df = pd.read_csv(\"D:\\ML_Data\\pima-indians-diabetes.data\", names= colnames)","eebc4270":"pima_df.head(50)","2815b789":"\npima_df[~pima_df.applymap(np.isreal).all(1)]","70b11038":"\npima_df.describe().transpose()","c0c01e1d":"\npima_df.groupby([\"class\"]).count()\n\n","fbec3257":"\nsns.pairplot(pima_df , hue='class' , diag_kind = 'kde')","e0047c1f":"array = pima_df.values\nX = array[:,0:7] \nY = array[:,8]   \ntest_size = 0.30\nseed = 7  \nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\ntype(X_train)","5ca2d921":"print(\"Before UpSampling, counts of label '1': {}\".format(sum(y_train==1)))\nprint(\"Before UpSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n\nsm = SMOTE(sampling_strategy = 1 ,k_neighbors = 5, random_state=1)   \nX_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n\n\nprint(\"After UpSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\nprint(\"After UpSampling, counts of label '0': {} \\n\".format(sum(y_train_res==0)))\n\n\n\nprint('After UpSampling, the shape of train_X: {}'.format(X_train_res.shape))\nprint('After UpSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n\n\n\n\n\n\n","d2c8dd2c":"# Fit the model on original data i.e. before upsampling\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\ny_predict = model.predict(X_test)\nmodel_score = model.score(X_test, y_test)\nprint(model_score)\nprint(metrics.confusion_matrix(y_test, y_predict))","f4d0ea24":"# fit model on upsampled data \n\nmodel.fit(X_train_res, y_train_res)\ny_predict = model.predict(X_test)\nmodel_score = model.score(X_test, y_test)\nprint(model_score)\nprint(metrics.confusion_matrix(y_test, y_predict))\n","c3d6067e":"non_diab_indices = pima_df[pima_df['class'] == 0].index  \nno_diab = len(pima_df[pima_df['class'] == 0])            \nprint(no_diab)\n\ndiab_indices = pima_df[pima_df['class'] == 1].index       \ndiab = len(pima_df[pima_df['class'] == 1])                \nprint(diab)\n","9404c8d7":"random_indices = np.random.choice( non_diab_indices, no_diab - 200 , replace=False)    ","723f1a6b":"down_sample_indices = np.concatenate([diab_indices,random_indices])  ","b90fd02d":"pima_df_down_sample = pima_df.loc[down_sample_indices]  \npima_df_down_sample.shape\npima_df_down_sample.groupby([\"class\"]).count() ","7d624f8f":"array = pima_df_down_sample.values\nX = array[:,0:7]\nY = array[:,8]   \ntest_size = 0.30 \nseed = 7  \nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\ntype(X_train)","d93e45c7":"print('After DownSampling, the shape of X_train: {}'.format(X_train.shape))\nprint('After DownSampling, the shape of X_test: {} \\n'.format(X_test.shape))\n","383a31b3":"# Fit the model on 30%\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\ny_predict = model.predict(X_test)\nmodel_score = model.score(X_test, y_test)\nprint(model_score)\nprint(metrics.confusion_matrix(y_test, y_predict))","b6ac08f9":"array = pima_df.values\nX = array[:,0:7] # select all rows and first 8 columns which are the attributes\nY = array[:,8]   # select all rows and the 8th column which is the classification \"Yes\", \"No\" for diabeties\ntest_size = 0.30 # taking 70:30 training and test set\nseed = 7  # Random numbmer seeding for reapeatability of the code\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\ntype(X_train)","0a0d01f4":"from imblearn.under_sampling import RandomUnderSampler","7502efa5":"rus = RandomUnderSampler(return_indices=True)","67d16bb5":"X_rus, y_rus, id_rus = rus.fit_sample(X_train, y_train)","2afdcc6c":"y_rus\n","2ade6901":"y_rus.shape","8c42b8ce":"from imblearn.over_sampling import RandomOverSampler\n\nros = RandomOverSampler()\n\nX_ros, y_ros = ros.fit_sample(X_train, y_train)","910c6f3a":"y_ros","3eafa378":"y_ros.shape","3f085a48":"X_ros.shape","dd7c5f71":"from imblearn.under_sampling import TomekLinks\n","0eae9420":"tl = TomekLinks(return_indices=True, ratio='majority')","524eeaff":"X_tl, y_tl, id_tl = tl.fit_sample(X_train, y_train)   # id_tl is removed instances of majority class","8a3f0478":"y_tl.shape","dd1fef79":"X_tl.shape","d925f88a":"from imblearn.combine import SMOTETomek","c858393c":"smt = SMOTETomek(ratio='auto')","aed8a86d":"X_smt, y_smt = smt.fit_sample(X_train, y_train)","b75de2a2":"X_smt.shape","b647f3ec":"from imblearn.under_sampling import ClusterCentroids","78e5b527":"cc = ClusterCentroids()  \nX_cc, y_cc = cc.fit_sample(X_train, y_train)\n","d679322c":"X_cc.shape","cf095c1a":"y_cc","dc1a9806":"## Upsampling followed by downsampling","89c3fa1e":"## IMBLearn Random Under Sampling","3718f62d":"##  Deleting nearest majority neighbors  TomekLinks\n\n","70170a29":"## Cluster based undersampling","fcf48660":"## IMBLearn Random Over Sampling"}}