{"cell_type":{"331a2a90":"code","5dcf2587":"code","6dc7b0a6":"code","eeb1dadb":"code","46dd7009":"code","9eef2a37":"code","3d6c53da":"code","2e27129d":"code","19e7f96e":"code","3ece4fc6":"code","f4a59665":"code","e27e3d8c":"code","707fe317":"code","38fc59b4":"code","d1d8c07d":"markdown","e3e730de":"markdown"},"source":{"331a2a90":"'''Load librarires'''\nimport pickle\nimport time\nimport random\nimport ntpath\nimport glob\nimport os\nfrom copy import deepcopy\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom collections import defaultdict\n\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset,DataLoader\nimport torchvision\nfrom torchvision import models, transforms, utils\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, precision_score, recall_score","5dcf2587":"class CFG:\n\n    '''Store all hyperparameters here.''' \n\n    SEED = 420\n    TEST_SIZE = 0.2\n    VAL_SIZE = 0.25\n    CLASSES = None #Need to update manually\n    OUTPUT_FEATURES = None #Need to update manually\n    \n    #transforms\n    TRAIN_TRANSFORMS = transforms.Compose([\n        #Rotate the image by given angle.\n        transforms.RandomRotation(5),\n        #Crop the given PIL Image to random size and aspect ratio.\n        transforms.Resize((224,224)),\n        #Horizontally flip the given PIL Image randomly with a given probability.\n        transforms.RandomHorizontalFlip(p = 0.2),\n        #Convert a PIL Image or numpy.ndarray to tensor.\n        transforms.ToTensor(),\n        #Normalize a tensor image with mean and standard deviation\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])\n\n    VAL_TRANSFORMS = transforms.Compose([\n        #Rotate the image by given angle.\n        transforms.RandomRotation(5),\n        #Crop the given PIL Image to random size and aspect ratio.\n        transforms.Resize((224,224)),\n        #Horizontally flip the given PIL Image randomly with a given probability.\n        transforms.RandomHorizontalFlip(p = 0.2),\n        #Convert a PIL Image or numpy.ndarray to tensor.\n        transforms.ToTensor(),\n        #Normalize a tensor image with mean and standard deviation\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])\n    \n    TEST_TRANSFORMS = transforms.Compose([\n        #Crop the given PIL Image to random size and aspect ratio.\n        transforms.Resize((224,224)),\n        #Convert a PIL Image or numpy.ndarray to tensor.\n        transforms.ToTensor(),\n        #Normalize a tensor image with mean and standard deviation\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])\n    \n    #models\n    \n    # MODEL1 = {\n    #     'name': 'custom_cnn',\n    #     'transfer': False,\n    #     'architecture': nn.Sequential(\n    #       nn.Conv2d(1,20,5),\n    #       nn.ReLU(),\n    #       nn.Conv2d(20,64,5),\n    #       nn.ReLU()\n    #     ),\n    #     'criterion': nn.CrossEntropyLoss(),\n    #     'optimizer': optim.SGD,\n    #     'momentum': 0.9,\n    #     'lr': 0.003,\n    #     'history': None\n    # }\n\n    MODEL2 = {\n        'name': 'resnet18',\n        'transfer': True,\n        'architecture': models.resnet18(pretrained=True), # ResNet18\n        'criterion': nn.CrossEntropyLoss(),\n        'optimizer': optim.SGD,\n        'momentum': 0.9,\n        'lr': 0.002,\n        'history': None\n    }\n\n    # MODELS =[MODEL1,MODEL2]\n\n    BATCH_SIZE = 64\n    EPOCHS = 120\n    \n    DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print('You are using ->', DEVICE)    ","6dc7b0a6":"def seed_everything(seed):\n    '''Make the results reproducible'''\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True \n\nseed_everything(CFG.SEED)","eeb1dadb":"'''Store image paths and their labels in pandas dataframe. Will be used to create pytorch datasets. '''\n\npaths = glob.glob('..\/input\/grapevine-leaves\/data\/*\/*' )\nmeta = pd.DataFrame([(path, ntpath.basename(ntpath.dirname(path))) for path in paths], columns = ['path','label'])\n#get class mappings\nclasses = dict(enumerate(meta.label.astype('category').cat.categories))\nCFG.CLASSES = classes\nCFG.OUTPUT_FEATURES = len(CFG.CLASSES)\n\nmeta.label = meta.label.astype('category').cat.codes\nmeta.head()","46dd7009":"classes","9eef2a37":"'''Split data into train, validation and test sets'''\n\nX = list(meta.path)\ny = list(meta.label)\n\nX_train, X_test, y_train, y_test = train_test_split(X, \n                                                    y, \n                                                    test_size=CFG.TEST_SIZE, \n                                                    random_state=CFG.SEED, \n                                                    stratify=y) #stratified split\n\nX_train, X_val, y_train, y_val = train_test_split(X_train,\n                                                  y_train,\n                                                  test_size=CFG.VAL_SIZE,\n                                                  random_state=CFG.SEED,\n                                                  stratify=y_train) #stratified split\n\nprint(f'Train length -> {len(X_train)}')\nprint(f'Val length -> {len(X_val)}')\nprint(f'Test length -> {len(X_test)}')","3d6c53da":"'''Custom pytorch dataset implementation.'''\nclass LeafDataset(Dataset):\n    def __init__(self,X,y, transform=None):\n        self.X = X\n        self.y = torch.tensor(y, dtype=torch.long)\n        self.transform = transform\n\n        assert len(self.X) == len(self.y), f'X and y have different lengths -> {len(self.X)} != {len(self.y)} '\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self,idx):\n        img_path = self.X[idx]\n        img = Image.open(img_path)\n        if self.transform is not None:\n            img = self.transform(img)\n        label = self.y[idx]\n        return (img,label) \n\n    def show_img(self,idx):\n        '''Plot image'''\n        img,label = self.__getitem__(idx)\n        img = img.numpy().transpose((1, 2, 0))\n        plt.figure(figsize=(16, 8))\n        plt.axis('off')\n        plt.imshow(img)\n        plt.title(CFG.CLASSES[int(label)]) #using CFG.CLASSES dict\n        plt.pause(0.001)","2e27129d":"'''Instantiate pytorch train, validation and test sets'''\nTRAIN = LeafDataset(X_train,y_train, CFG.TRAIN_TRANSFORMS)\nVAL = LeafDataset(X_val,y_val, CFG.VAL_TRANSFORMS)\nTEST = LeafDataset(X_test,y_test, CFG.TEST_TRANSFORMS)\n\n'''Instantiate Dataloaders'''\nTRAIN_LOADER = DataLoader(TRAIN,CFG.BATCH_SIZE)\nVAL_LOADER = DataLoader(VAL,CFG.BATCH_SIZE)\nTEST_LOADER = DataLoader(TEST,CFG.BATCH_SIZE)","19e7f96e":"class Net(nn.Module):\n    '''\n    ========================\n          NEURAL NET\n    ========================\n    \n    Args:\n        model_dict(dict): configuration dict containing the model architecture\n        output_features(int): length of output tensor; for classification equals to number of classes\n    '''\n    def __init__(self, model_dict, output_features):\n        super().__init__()\n        self.__dict__.update(model_dict) #unpack model dict from CFG into this class\n        \n        if self.transfer:\n            model = self.architecture\n            num_ftrs = model.fc.in_features\n            model.fc = nn.Linear(num_ftrs, output_features)\n            self.model = model\n        else:\n            self.model = self.architecture\n        \n        self.output_features = output_features\n        #optimizer\n        self.optimizer = self.optimizer(self.model.parameters(),self.lr)\n        #path where to save model\n        self.save_path = 'models'\n        \n    def forward(self, x):\n        return self.model(x)\n\n    def fit(self,\n            train_loader,\n            val_loader,\n            epochs = 5,\n            batch_size = 32,\n            device = 'cpu'):\n        '''\n        =============================\n            OPTIMIZATION LOOP\n        =============================\n\n        Args:\n            train_loader(torch dataloader)\n            val_loader(torch dataloader)\n            epochs(int)\n            batch_size(int)\n            device(str)\n\n            \n        Output style inspired by the skorch fit() method\n\n        '''\n        #may be changed if lrscheduler is used???\n        lr = deepcopy(self.lr)\n\n        #get model training history\n        history = self.history\n        if history == None:\n            history = defaultdict(list)\n        else:\n            pass\n        #get train and val sizes\n        train_size = len(train_loader.dataset)\n        val_size = len(val_loader.dataset)\n        #stuff for printing epoch metrics as a beautiful table\n        headers = ['epoch','train_loss','val_loss','val_acc','cp','lr','dur']\n        template = '{:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10}'\n        print(template.format(*headers))\n        print(template.replace(':', ':-').format('','','','','','',''))\n        cyan = \"\\033[96m{:<10}\\033[00m\" #cyan\n        purple = \"\\033[95m{:<10}\\033[00m\" #purple\n        green = \"\\033[92m{:<10}\\033[00m\" #green\n        white = \"\\033[0m{:<10}\\033[0m\" #white\n        #set model into train mode\n        self.model.train()\n        #send model to device\n        self.model.to(device)\n        #training loop\n        for epoch in range(epochs):\n            start_time = time.time()\n            train_loss = 0\n            val_loss, val_acc = 0, 0\n            #optimization  loop\n            for (X,y) in train_loader:\n                #Send training data to device\n                X,y = X.to(device), y.to(device)\n                #Forward propagation\n                pred = self.model(X)\n                loss = self.criterion(pred,y)\n                #Backpropagation\n                self.optimizer.zero_grad()\n                loss.backward()\n                self.optimizer.step()\n                #update loss\n                train_loss = loss.item()\n            #validation loop\n            with torch.no_grad():\n                for X, y in val_loader:\n                    X,y = X.to(device),y.to(device)\n                    pred = self.model(X)\n                    val_loss = self.criterion(pred,y).item()\n                    val_acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n            #calculate validation accuracy after the epoch\n            val_acc \/= val_size\n            #append epoch results\n            history['epoch'].append(epoch+1)\n            history['train_loss'].append(train_loss)\n            history['val_loss'].append(val_loss)\n            history['val_acc'].append(val_acc)\n            \n            #colorize epoch's output if it improves\n            colortemp = template.split(' ')\n            # colorize train loss if it decreases\n            if history['train_loss'][-1] == min(history['train_loss']):\n                colortemp[1] = cyan\n            else:\n                colortemp[1] = white\n            #colorize validation loss if it decreases\n            if history['val_loss'][-1] == min(history['val_loss']):\n                colortemp[2] = purple\n            else:\n                colortemp[2] = white\n            # colorize validation accuracy & save best weights if it increases\n            if history['val_acc'][-1] == max(history['val_acc']):\n                #colorize       \n                colortemp[3] = green\n                #checkpoint\n                cp = '+'\n                if not os.path.exists(self.save_path):\n                    os.mkdir(self.save_path)\n                torch.save(self.model.state_dict(), Path(self.save_path,f'best_{self.name}.pth'))\n            else:\n                colortemp[3] = white\n                cp = '-'\n            colortemp = ' '.join(colortemp)\n\n            #calculate epoch duration (in seconds)\n            end_time = time.time()\n            dur = end_time - start_time\n            #append the rest of epoch results\n            history['cp'].append(cp)\n            history['lr'].append(lr)\n            history['dur'].append(dur)\n            #display the epoch results\n            print(colortemp.format(*f'{epoch+1}\/{epochs} {train_loss:.4f} {val_loss:.4f} {val_acc:.2f} {cp} {lr} {dur:.2f}'.split(' ')))\n        #update epoch number of the entire training history\n        history['epoch'] = [e+1 for e in range(len(history['epoch']))]\n        #update model's training history\n        self.history = history\n        #save training history as csv\n        self.save_history()\n\n    def eval_model(self,dataloader,avg=None,device ='cpu'):\n        '''\n        ==================================\n           ACCURACY PRECISION RECALL F1\n        ==================================\n        '''\n        labels = [l for l in range(self.output_features)]\n        loader_size = len(dataloader)\n        dataset_size = len(dataloader.dataset)\n\n        acc =0\n        precision = 0\n        recall = 0\n        f1 = 0\n\n        #set model to evaluation mode\n        self.model.eval()\n        #model to device, default cpu\n        self.model.to(device)\n\n        with torch.no_grad():\n            for X, y in dataloader:\n                pred = self.model(X)\n                #accuracy\n                acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n\n                pred = pred.argmax(1)\n                pred,y = list(pred), list(y)\n                #precision\n                p = precision_score(y, pred, labels = labels, zero_division = 1, average = avg)\n                precision+=p\n                #recall\n                r = recall_score(y, pred, labels = labels, zero_division = 1,  average = avg)\n                recall+=r\n                #f1 score\n                f = f1_score(y, pred, labels = labels, zero_division = 1,  average = avg)\n                f1 += f\n\n        acc \/= dataset_size\n        precision \/= loader_size\n        recall \/= loader_size\n        f1 \/= loader_size\n\n        print(f\" Accuracy: {(100*acc):>0.1f}%\")\n        print(f\"Precision: {(100*np.mean(precision)):>0.1f}%\")\n        print(f\"   Recall: {(100*np.mean(recall)):>0.1f}%\")\n        print(f\" F1 Score: {(100*np.mean(f1)):>0.1f}%\")\n\n        \n    def plot_loss_history(self):\n        '''\n        Plot loss history\n        '''\n        assert self.history != None, 'No history to plot -> the model has not been trained yet!'\n        \n        df = pd.DataFrame(self.history)\n        fig = px.line(x = df.epoch,\n                    y = [df.train_loss, df.val_loss],\n                    title = 'Loss History',\n                    labels={'x':'epoch','value': 'loss', 'variable': 'loss'})\n        fig.data[0].name = 'train'\n        fig.data[1].name = 'val'\n        fig.show()\n\n    def save_history(self):\n        '''Save model's training history'''\n        assert self.history != None, 'No history to save -> the model has not been trained yet!'\n        #save as csv\n        pd.DataFrame(self.history).to_csv(Path(f'models\/{self.name}_history.csv')) \n        #save as pickle file\n        with open(Path(f'models\/{self.name}_history.pkl'), 'wb') as f:\n            pickle.dump(self.history, f, protocol=pickle.HIGHEST_PROTOCOL)\n\n    def save_model(self):\n        torch.save(self.model.state_dict(), Path(self.save_path,f'latest_{self.name}.pth'))\n\n    def load_model(self,path = 'models'):\n        '''Load model'''\n        try:\n            #load model weights\n            p = Path(path,f'best_{self.name}.pth')\n            self.model.load_state_dict(torch.load(p))\n            #load model training history\n            with open(Path(path,f'{self.name}_history.pkl'), 'rb') as h: \n                self.history = pickle.load(h)\n        except:\n            print('No model to load!')","3ece4fc6":"#instantiate model and send to device\nResnet18 = Net(CFG.MODEL2,CFG.OUTPUT_FEATURES)","f4a59665":"Resnet18.fit(TRAIN_LOADER,\n             VAL_LOADER,\n             CFG.EPOCHS,\n             CFG.BATCH_SIZE,\n             CFG.DEVICE)","e27e3d8c":"Resnet18.plot_loss_history()","707fe317":"#evaluate best model's performance on the test set\nprint('Best Model:')\nprint('-'*20)\nbest_model = deepcopy(Resnet18)\nbest_model.load_model()\nbest_model.eval_model(TEST_LOADER)\n#evaluate current model's performance on the test set\nprint('Current Model:')\nprint('-'*20)\nResnet18.eval_model(TEST_LOADER)","38fc59b4":"def cross_val():\n    '''\n    ======================\n       CROSS VALIDATION\n    ======================\n    '''\n    pass","d1d8c07d":"# What's next?\n\n- Train function as model class method\n- LR Scheduler\n- Train Custom Model\n- Confusion Matrix\n- Random & Grid Search\n- Cross-Validation\n- Ensemble Learning","e3e730de":"# Pytorch Grapevine Leaf Classifier"}}