{"cell_type":{"5ec2f048":"code","6fc9cd0d":"code","d6d07c3f":"code","d06ef0e0":"code","f85ae23d":"code","2ca356a7":"code","9f87a3df":"code","b218d6e4":"code","30728429":"code","c6754d1b":"code","46d787ad":"code","e71a1951":"code","cc216c36":"code","53f543c3":"code","22cb27cc":"code","e7fa1550":"code","4cf13fa6":"code","f96697fd":"code","dfabb1a6":"markdown","6506bf10":"markdown"},"source":{"5ec2f048":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.decomposition import PCA \nfrom sklearn.cluster import KMeans \nfrom sklearn.manifold import TSNE\n\nimport warnings \n\nwarnings.simplefilter(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6fc9cd0d":"train = pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/test.csv\")\ntrain.head()","d6d07c3f":"\n'''\nBefore cluster classification, average u_in that correlates\nwith the constant objective variable of the time stamp by each breath_id.\n'''\n\ndef class_time_step(x):\n    if x < 1.0:\n        return 0\n    elif x < 1.5:\n        return 1\n    else:\n        return 2\n    \ntrain[\"log_u_in\"] = np.log1p(train.u_in)\ntest[\"log_u_in\"] = np.log1p(test.u_in)\n\ntrain[\"time_step_class\"] = train.time_step.apply(class_time_step)\ntest[\"time_step_class\"] = test.time_step.apply(class_time_step)\n\npiv = train.pivot_table(index=\"breath_id\", columns=\"time_step_class\", values=\"log_u_in\", fill_value=0, aggfunc=\"mean\")\npiv_test = test.pivot_table(index=\"breath_id\", columns=\"time_step_class\", values=\"log_u_in\", fill_value=0, aggfunc=\"mean\")\n\npiv.head()","d06ef0e0":"pca = PCA(n_components=2, random_state=42)\npca.fit(piv)\n\nplt.plot(pca.explained_variance_ratio_.cumsum())\nplt.grid()\nplt.xlabel(\"n_components\")\nplt.ylabel(\"explained_variance_ratio_\")\nplt.xticks([0, 1])\nplt.show()","f85ae23d":"train_pca = pca.transform(piv)\ntest_pca = pca.transform(piv_test)\n\ntrain_pca = pd.DataFrame(train_pca, columns=[\"c\"+str(c) for c in range(2)], index=piv.index)\ntest_pca = pd.DataFrame(test_pca, columns=[\"c\"+str(c) for c in range(2)], index=piv_test.index)\n\ntrain_pca.head()","2ca356a7":"sns.scatterplot(data=train_pca, x=\"c0\", y=\"c1\")\nplt.show()","9f87a3df":"km = KMeans(n_clusters=3, \n            random_state=42,\n            max_iter=100,\n            init=\"k-means++\", \n            tol=0.0001)\ny_km = km.fit_predict(train_pca)\ny_km_test = km.predict(test_pca)","b218d6e4":"# https:\/\/qiita.com\/deaikei\/items\/11a10fde5bb47a2cf2c2\nfrom sklearn.metrics import silhouette_samples\nfrom matplotlib import cm\n\ncluster_labels = np.unique(y_km)\nn_clusters=cluster_labels.shape[0]    \n\nsilhouette_vals = silhouette_samples(train_pca, y_km, metric='euclidean')  \ny_ax_lower, y_ax_upper= 0,0\nyticks = []\n\nfor i,c in enumerate(cluster_labels):\n        c_silhouette_vals = silhouette_vals[y_km==c]   \n        c_silhouette_vals.sort()\n        y_ax_upper += len(c_silhouette_vals)              \n        color = cm.jet(float(i)\/n_clusters)              \n        plt.barh(range(y_ax_lower,y_ax_upper),            \n                         c_silhouette_vals,               \n                         height=1.0,                      \n                         edgecolor='none',                \n                         color=color)                     \n        yticks.append((y_ax_lower+y_ax_upper)\/2)          \n        y_ax_lower += len(c_silhouette_vals)              \n\nsilhouette_avg = np.mean(silhouette_vals)                 \nplt.axvline(silhouette_avg,color=\"red\",linestyle=\"--\")     \nplt.yticks(yticks,cluster_labels + 1)                     \nplt.ylabel('Cluster')\nplt.xlabel('silhouette coefficient')\nplt.show()","30728429":"train_pca[\"cluster\"] = y_km\ntest_pca[\"cluster\"] = y_km_test\n\ncenter = km.cluster_centers_\n\nsns.scatterplot(data=train_pca, x=\"c0\", y=\"c1\", hue=\"cluster\")\nplt.plot(center[0, 0], center[0, 1], \"bo\", c=\"r\")\nplt.plot(center[1, 0], center[1, 1], \"bo\", c=\"r\")\nplt.plot(center[2, 0], center[2, 1], \"bo\", c=\"r\")\n\nplt.show()","c6754d1b":"\n'''\nTry to separate the coordinate space that exists in a straight line and \nthe cluster that is randomly arranged\n'''\n\ntrain_pca[\"cluster\"] = train_pca.cluster.apply(lambda x: 0 if x == 2 else 1)\ntest_pca[\"cluster\"] = test_pca.cluster.apply(lambda x: 0 if x == 2 else 1)\n\nsns.scatterplot(data=train_pca, x=\"c0\", y=\"c1\", hue=\"cluster\")\nplt.show()","46d787ad":"\n'''\nLet's try how it was isolated using the information obtained from the cluster\n'''\n\n# merge \ntrain_pca[\"breath_id\"] = train_pca.index \ntrain_pca.drop([\"c0\", \"c1\"], axis=1, inplace=True)\ntrain_pca = train_pca.reset_index(drop=True)\ntrain = pd.merge(train, train_pca, how=\"left\", on=\"breath_id\")\n\ntest_pca[\"breath_id\"] = test_pca.index \ntest_pca.drop([\"c0\", \"c1\"], axis=1, inplace=True)\ntest_pca = test_pca.reset_index(drop=True)\ntest = pd.merge(test, test_pca, how=\"left\", on=\"breath_id\")\n\n# helper \ndef find_cluster_r_c(df):\n    fig, ax = plt.subplots(2, 2, figsize=(15, 6))\n    for c in range(2):\n        for r_c in range(2):\n            x = df.loc[df.cluster == c, \"R\" if r_c == 0 else \"C\" ]\n            sns.countplot(x, ax=ax[c][r_c])\n            ax[c][r_c].set_title(f\"Cluster={c}\")\n    plt.tight_layout()\n    \n    \ndef find_cluster_transition(df, is_train=True):\n    fig, ax = plt.subplots(2, 5, figsize=(15, 6))\n    for c in range(2):\n        x = df.loc[df.cluster == c]\n        breath = x.breath_id.unique()\n        for n in range(5):\n            if is_train:\n                xx = x.loc[x.breath_id == breath[n], [\"time_step\", \"u_in\", \"u_out\", \"pressure\"]]\n            else:\n                xx = x.loc[x.breath_id == breath[n], [\"time_step\", \"u_in\", \"u_out\"]]\n            xx.set_index(\"time_step\").plot(ax=ax[c][n])\n            ax[c][n].set_title(f\"breath_id={breath[n]}\")\n            ax[c][n].set_xticks([])\n            \n            if n == 0:\n                ax[c][n].set_ylabel(f\"Cluster={c}\")\n    plt.tight_layout()\n            ","e71a1951":"sns.countplot(train.cluster)","cc216c36":"sns.countplot(test.cluster)","53f543c3":"\n'''\nSome clusters show a single attribute.\nIt is more strongly reflected in clusters that do not exist in a straight line.\n'''\n\nfind_cluster_r_c(train)","22cb27cc":"find_cluster_r_c(test)","e7fa1550":"\n'''\nFrom the time-series data distribution,\nwe confirmed a sharp rise in u_in following 1.0 second. \nAfter that, it decreases smoothly.\n'''\n\nfind_cluster_transition(train)","4cf13fa6":"find_cluster_transition(test, False)","f96697fd":"train.drop([\"time_step_class\", \"log_u_in\"], axis=1, inplace=True)\ntest.drop([\"time_step_class\", \"log_u_in\"], axis=1, inplace=True)\n\ntrain.to_csv(\"train.csv\", index=False)\ntest.to_csv(\"test.csv\", index=False)","dfabb1a6":"# PCA ","6506bf10":"# Clustering"}}