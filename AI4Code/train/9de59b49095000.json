{"cell_type":{"455abecf":"code","ec3760c2":"code","2dd04dfe":"code","68011678":"code","8d606058":"code","40befe99":"code","cfba9432":"code","a242c4fc":"code","28c06ff4":"code","42ed2ddb":"code","f4d4c8bb":"code","9954eb3b":"code","098eb256":"code","fe8f4e8a":"code","791eb9da":"code","d146f619":"code","545322c6":"code","a6bd6ab3":"code","5048fd75":"code","e951225d":"code","9d0c0470":"code","7b815758":"code","f0ae9c51":"code","b0739d05":"code","ec7ddeda":"code","3b91a46d":"code","dcf2c3ec":"code","e42aaa38":"code","8ffbaca7":"code","489d0041":"code","a2fb0ae4":"code","41c5fe7e":"code","03d47055":"code","75e87381":"code","431ab09d":"code","2ad342c8":"code","2c99fd6a":"code","2b8f3b01":"code","0a7c73c2":"code","0115b3b0":"code","f36dc6c7":"code","e42101fb":"code","78da5f52":"code","acde1090":"code","fe5904da":"code","447f8002":"code","a11bf00d":"markdown","8dfef628":"markdown","8210366c":"markdown","41575ec9":"markdown","eb64f84b":"markdown","aa9df9ed":"markdown","ab1d5e15":"markdown","751c0cc0":"markdown","ba458956":"markdown","4adf5827":"markdown","5d8d4539":"markdown","df37e9d8":"markdown","e832aa47":"markdown","b6b5af0d":"markdown","5f058c45":"markdown","11712654":"markdown","47789313":"markdown","d4ee53b7":"markdown","5000d5e6":"markdown","eb8d8a65":"markdown","2a1a2fc5":"markdown","98a406bb":"markdown","e95a4cbf":"markdown","e136b5e6":"markdown","e14ad698":"markdown","f5563e2a":"markdown","05d41ce9":"markdown","321349e8":"markdown","c64214a8":"markdown","ac817aca":"markdown","32ecc761":"markdown","858f44c0":"markdown","0249bd06":"markdown","f84ae149":"markdown","58b4ae66":"markdown","05026b84":"markdown","61461135":"markdown","48c6273a":"markdown","b0287a6d":"markdown","2218a2dc":"markdown","d9e5c68a":"markdown","d9cb8d82":"markdown","96ba5e00":"markdown","a55e3f43":"markdown","991c4799":"markdown","6aedccda":"markdown","5df8e477":"markdown"},"source":{"455abecf":"import numpy as np\nimport csv \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats\n\nfrom sqlalchemy import create_engine\nfrom sklearn import linear_model\nfrom sklearn.metrics import r2_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import SpectralClustering\nfrom sklearn.mixture import GaussianMixture as GMM\n\nimport warnings\nwarnings.filterwarnings('ignore')","ec3760c2":"df = pd.read_csv('\/kaggle\/input\/nba-players-stats-20142015\/players_stats.csv')\ndf.head()","2dd04dfe":"df.info()","68011678":"duplicateRowsDF = df[df.duplicated()]\nduplicateRowsDF","8d606058":"df.isnull().any()","40befe99":"dfc = df[pd.notnull(df['BMI'])]","cfba9432":"dfnull = dfc[dfc['Height'].isnull()]\ndfnull","a242c4fc":"MPG = df['MIN'] \/ df['Games Played']\nTFG = df['FGM'] + df['FGA']","28c06ff4":"dfl = (dfc[[\"Name\", \"Team\", \"Games Played\", \"MIN\", \"EFF\", \"FGM\", \"FGA\", \"PTS\"]].sort_values(\"PTS\", ascending=False))\ndfl.insert(4, 'PMPG', MPG)\ndfl.insert(8, 'TFG', TFG)\n\ndfl.head()","42ed2ddb":"# dfl.isnull().any()","f4d4c8bb":"sns.pairplot(dfl)","9954eb3b":"dfl.plot.scatter(\"EFF\", \"PTS\", alpha=0.5, color= \"r\", figsize=(13,5))\nplt.xlabel('Effisiensi Bermain')\nplt.ylabel('Point')","098eb256":"Boston = dfl.Team == 'BOS'\nDetroit = dfl.Team == 'DET'\nCleveland = dfl.Team == 'CLE'\nOrlando = dfl.Team == 'ORL'\nToronto = dfl.Team == 'TOR'\nWashington = dfl.Team == 'WAS'\nPhiladelphia = dfl.Team == 'PHI'\nMilwaukee = dfl.Team == 'MIL'\nNewYork = dfl.Team == 'NYK'\nAtlanta = dfl.Team == 'ATL'\nCharlote = dfl.Team == 'CHA'\nChicago = dfl.Team == 'CHI'\nIndiana = dfl.Team == 'IND'\nMiami = dfl.Team == 'MIA'\n\ndfeast = dfl[Boston | Detroit | Cleveland | Orlando | Toronto | Washington | Philadelphia | \n            Milwaukee | NewYork | Atlanta | Charlote | Chicago | Indiana | Miami]\n\n# dfeast.sort_values(\"Team\", ascending=True)","fe8f4e8a":"maxt = dfeast.groupby(['Team'])['PTS'].transform(max) == dfeast['PTS']\ndfmax = dfeast[maxt]\ndfmax.sort_values(\"EFF\", ascending=False)","791eb9da":"import plotly.offline as py\nimport plotly.graph_objs as go\n\ntr1 = go.Bar(\n                 x = dfmax['Name'],\n                 y = dfmax['EFF'],\n                 name = 'Effisiensi',\n                 marker = dict(color='crimson',\n                              line = dict(color='rgba(0,0,0)', width=0.5)),\n                 text = dfmax.Team)\n\ntr2 = go.Bar(\n                 x = dfmax['Name'],\n                 y = dfmax['PTS'],\n                 name = 'Points',\n                 marker = dict(color='rgba(0, 0, 255, 0.5)',\n                              line = dict(color='rgba(0,0,0)', width=0.5)),\n                 text = dfmax.Team)\ndn = [tr1, tr2]\nlayoutnew = go.Layout(barmode='group', title='Effisiensi Tertinggi Pemain pada TIM Regional Timur Terhadap Points')\nfig = go.Figure(data=dn, layout=layoutnew)\nfig.update_layout(barmode='stack')\npy.iplot(fig)","d146f619":"engine= create_engine('sqlite:\/\/\/:memory:')\n\ndfeast.to_sql('data_table', engine) \ndfeastrt= pd.read_sql_query('SELECT SUM(\"EFF\"), Team FROM data_table group by Team', engine)\nK = dfeastrt['SUM(\"EFF\")']","545322c6":"engine= create_engine('sqlite:\/\/\/:memory:')\n\ndfeast.to_sql('data_table', engine) \ndfeastrp= pd.read_sql_query('SELECT SUM(\"PTS\"), Team FROM data_table group by Team', engine)","a6bd6ab3":"dfeastrp.insert(1, 'SEFF', K)\ndfeastrp.rename(\n    columns={\n        'SUM(\"PTS\")': \"SPTS\"\n    },\n    inplace=True)","5048fd75":"dfeastrp['Rank'] = dfeastrp['SPTS'].rank(method='dense', ascending=False)\ndfeastrp.sort_values(\"SPTS\", ascending=False)","e951225d":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=dfeastrp['Team'], y=dfeastrp['SEFF'], fill='tozeroy',name = 'Jumlah Effisiensi Tim'))\nfig.add_trace(go.Scatter(x=dfeastrp['Team'], y=dfeastrp['SPTS'], fill='tonexty',name = 'Jumlah Point Tim'))\n\nfig.show()","9d0c0470":"engine= create_engine('sqlite:\/\/\/:memory:')\n\ndfeast.to_sql('data_table', engine) \ngp= pd.read_sql_query('SELECT \"Games Played\" FROM data_table group by Team', engine)","7b815758":"dfeastrp.insert(3, 'GP', gp)","f0ae9c51":"dfeastgpp = dfeastrp['SPTS'] \/ 82\ndfeastgpp\n# dfeastrp['GP'].max()","b0739d05":"fig = {\n        'data': [ \n             {\n                'values' : dfeastgpp,\n                'labels' : dfeastrp['Rank'],\n                'domain' : {'x': [0, 1]},\n                'name' : 'Points \/ Game',\n                'hoverinfo' : 'label+percent+name',\n                'hole' : 0.3,\n                'type' : 'pie'\n              },\n             ],\n         'layout' : {\n                     'title' : 'Rata Rata Point per Game yang didapatkan Team Sesuai Ranking',\n                     'annotations' : [\n                                        { 'font' : {'size' : 20},\n                                          'showarrow' : False,\n                                          'text' : ' ',\n                                          'x' : 0.20,\n                                          'y' : 1\n                                         },\n                                      ]    \n                     }\n        }\npy.iplot(fig)","ec7ddeda":"dfatl = dfeast[dfeast['Team'] == \"ATL\"]\ndfatl","3b91a46d":"dfl.plot.scatter(\"EFF\", \"PTS\", alpha=0.5, color= \"r\", figsize=(13,5))\nplt.xlabel('Efisiensi Pemain')\nplt.ylabel('Point')","dcf2c3ec":"msk = np.random.rand(len(dfl)) < 0.8\ntrain = dfl[msk]\ntest = dfl[~msk]\n\nplt.figure(figsize=(13,5))\nplt.scatter(train.EFF, train.PTS, alpha=0.5, color='blue')\nplt.xlabel(\"Efisiensi Pemain\")\nplt.ylabel(\"Point\")\nplt.show()","e42aaa38":"regr = linear_model.LinearRegression()\ntrain_x = np.asanyarray(train[['EFF']])\ntrain_y = np.asanyarray(train[['PTS']])\nregr.fit (train_x, train_y)\n\nprint ('Coefficients: ', regr.coef_)\nprint ('Intercept: ',regr.intercept_)","8ffbaca7":"plt.figure(figsize=(13,5))\nplt.scatter(train.EFF, train.PTS, alpha=0.5, color='blue')\nplt.plot(train_x, regr.coef_[0][0]*train_x + regr.intercept_[0], '-r')\nplt.xlabel(\"Efisiensi Pemain\")\nplt.ylabel(\"Point\")","489d0041":"testk = regr.intercept_ + regr.coef_ * 1475\ntestk","a2fb0ae4":"from sklearn.metrics import r2_score\n\ntest_x = np.asanyarray(test[['EFF']])\ntest_y = np.asanyarray(test[['PTS']])\ntest_y_ = regr.predict(test_x)\n\nprint(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_ - test_y)))\nprint(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_ - test_y) ** 2))\nprint(\"R2-score: %.2f\" % r2_score(test_y_ , test_y) )","41c5fe7e":"plt.figure(figsize=(13,5))\nx_data, y_data = (dfl[\"EFF\"].values, dfl[\"PTS\"].values)\nplt.plot(x_data, y_data, 'mo' ,alpha=0.5)\nplt.xlabel('Efisiensi Pemain')\nplt.ylabel('Point')\nplt.show()","03d47055":"def sigmoid(x, Beta_1, Beta_2):\n     y = 1 \/ (1 + np.exp (-beta_1*(x-Beta_2)) )\n     return y\n\ndef expo (x, Beta_0, Beta_1):\n     y = Beta_0*np.exp(Beta_1*x)\n     return y\n\ndef qubic (x, Beta_0, Beta_1, Beta_2, Beta_3):\n     y = Beta_0+Beta_1*x+Beta_2*x**2+Beta_3*x**3\n     return y","75e87381":"beta_1 = 1.0\nbeta_2 = 1\nbeta_3= 1\nbeta_4=0.1\n\nY_preds =sigmoid (x_data, beta_1, beta_2)\n","431ab09d":"xdata =x_data\/max(x_data)\nydata =y_data\/max(y_data)","2ad342c8":"from scipy.optimize import curve_fit\npopt1, pcov1 = curve_fit(sigmoid, xdata, ydata, maxfev = 10000)\npopt2, pcov2 = curve_fit (expo, xdata, ydata, maxfev = 10000) \npopt3, pcov3 = curve_fit (qubic, xdata, ydata, maxfev = 10000) \n\nprint(\" Exponensial\",\"B1 = %f, B2=%f\"%(popt2[0], popt2[1]))\nprint(\" Sigmoid\",\"B1 = %f, B2=%f\"%(popt1[0], popt1[1]))\nprint(\" Qubic\",\"B1 = %f, B2=%f\"%(popt3[0], popt3[1]))","2c99fd6a":"x = np.linspace(10, 200, 1000)\nx = x\/max(x)\nplt.figure(figsize=(13,5))\n\ny1 = expo(x, *popt1)\ny2 = sigmoid(x, *popt2)\ny3 = qubic(x, *popt3)\n\nplt.plot(xdata, ydata, 'mo',alpha=0.5 ,label='data')\nplt.plot(x,y1, linewidth=3.0, label='Eksponensial')\nplt.plot(x,y2, linewidth=3.0, label='Sigmoid')\nplt.plot(x,y3, linewidth=3.0, label='Qubic')\nplt.legend(loc='best')\nplt.xlabel('Efisiensi Pemain')\nplt.ylabel('Points')\nplt.show()","2b8f3b01":"msk = np.random.rand(len(dfl)) < 0.8\n\ntrain_x = xdata[msk]\ntest_x = xdata[~msk]\ntrain_y = ydata[msk]\ntest_y = ydata[~msk]\n\n# build the model using train set\npopt1, pcov1 = curve_fit(sigmoid, train_x, train_y, maxfev = 100000)\npopt2, pcov2 = curve_fit(expo, train_x, train_y, maxfev = 100000)\npopt3, pcov3 = curve_fit(qubic, xdata, ydata, maxfev = 10000)\n\ny_hat1 = sigmoid(test_x, *popt1)\ny_hat2 = expo(test_x, *popt2)\ny_hat3 = qubic(test_x, *popt3)\n\nprint (\"Sigmoid\")\nprint(\"Mean absolute error: %.2f\" % np.mean(np.absolute(y_hat1 - test_y)))\nprint(\"Residual sum of squares (MSE): %.2f\" % np.mean((y_hat1 - test_y) ** 2))\nfrom sklearn.metrics import r2_score\nprint(\"R2-score: %.2f\" % r2_score(y_hat1 , test_y) )\n\nprint (\"\\nExponens\")\nprint(\"Mean absolute error: %.2f\" % np.mean(np.absolute(y_hat2 - test_y)))\nprint(\"Residual sum of squares (MSE): %.2f\" % np.mean((y_hat2 - test_y) ** 2))\nfrom sklearn.metrics import r2_score\nprint(\"R2-score: %.2f\" % r2_score(y_hat2 , test_y) )\n\nprint (\"\\nQubic\")\nprint(\"Mean absolute error: %.2f\" % np.mean(np.absolute(y_hat3 - test_y)))\nprint(\"Residual sum of squares (MSE): %.2f\" % np.mean((y_hat3 - test_y) ** 2))\nfrom sklearn.metrics import r2_score\nprint(\"R2-score: %.2f\" % r2_score(y_hat3 , test_y) )","0a7c73c2":"x = np.linspace(10, 200, 1000)\nx = x\/max(x)\nplt.figure(figsize=(13,5))\n\ny3 = qubic(x, *popt3)\n\nplt.plot(xdata, ydata, 'mo',alpha=0.5 ,label='data')\nplt.plot(x,y3, linewidth=3.0, label='Qubic')\nplt.legend(loc='best')\nplt.xlabel('Menit Bermain')\nplt.ylabel('Points')\nplt.show()","0115b3b0":"print (\"\\nQubic\")\nprint(\"Mean absolute error: %.2f\" % np.mean(np.absolute(y_hat3 - test_y)))\nprint(\"Residual sum of squares (MSE): %.2f\" % np.mean((y_hat3 - test_y) ** 2))\nfrom sklearn.metrics import r2_score\nprint(\"R2-score: %.2f\" % r2_score(y_hat3 , test_y) )","f36dc6c7":"dfdel1 = dfc.Name != 'Sim Bhullar'\ndfdel2 = dfc.Name != 'Jerrelle Benimon'\ndfcl = dfc[dfdel1 & dfdel2]","e42101fb":"dfcl[\"TRB\/MIN\"] = dfcl[\"REB\"]\/dfcl[\"MIN\"] \ndfcl[\"AST\/MIN\"] = dfcl[\"AST\"]\/dfcl[\"MIN\"]\n\nfig, ax = plt.subplots()\n\nx_var=\"AST\/MIN\"\ny_var=\"TRB\/MIN\"\n\ncolors = {'SG':'blue', 'PF':'red', 'PG':'green', 'C':'purple', 'SF':'orange'}\n\nax.scatter(dfcl[x_var], dfcl[y_var], c=dfcl['Pos'].apply(lambda x: colors[x]), s = 10)\n\n# set a title and labels\nax.set_title('NBA Dataset')\nax.set_xlabel(x_var)\nax.set_ylabel(y_var)","78da5f52":"dfn = dfcl[[\"AST\/MIN\",\"TRB\/MIN\"]]\n\nkmeans = KMeans(n_clusters = 5, init = 'k-means++', max_iter = 500, n_init = 10, random_state = 0)\ny_kmeans = kmeans.fit_predict(dfn)\nprint(kmeans.cluster_centers_)","acde1090":"d0=dfn[y_kmeans == 0]\nd1=dfn[y_kmeans == 1]\nd2=dfn[y_kmeans == 2]\nd3=dfn[y_kmeans == 3]\nd4=dfn[y_kmeans == 4]\n\nplt.scatter(d0[x_var], d0[y_var], s = 10, c = 'blue', label = 'D0')\nplt.scatter(d1[x_var], d1[y_var], s = 10, c = 'green', label = 'D1')\nplt.scatter(d2[x_var], d2[y_var], s = 10, c = 'red', label = 'D2')\nplt.scatter(d3[x_var], d3[y_var], s = 10, c = 'purple', label = 'D3')\nplt.scatter(d4[x_var], d4[y_var], s = 10, c = 'orange', label = 'D4')\n\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], s = 100, c = 'yellow', label = 'Centroids')","fe5904da":"d0[x_var]='SG'\nd1[x_var]='PF'\nd2[x_var]='PG'\nd3[x_var]='C'\nd4[x_var]='SF'\n\ndflist = pd.concat([d0[x_var], d1[x_var], d2[x_var], d3[x_var], d4[x_var]])","447f8002":"dfcluster = (dfc[[\"Name\", \"Team\", \"Pos\"]])\ndfcluster\n\ndfcl[\"TRB\/MIN\"]\ndfcl[\"AST\/MIN\"]\n\ndfcluster.insert(2, 'TRBMIN', dfcl[\"TRB\/MIN\"])\ndfcluster.insert(3, 'ASTMIN', dfcl[\"AST\/MIN\"])\ndfcluster.insert(5, 'Next Pos', dflist)\ndfcluster","a11bf00d":"##  Analisis Status Pemain NBA Terhadap Points yang Didapatkan","8dfef628":"## 2. Model Regresi EFF Terhadap Point\n<hr>\nData Frame dflterdiri dari 2 variabel. Kolom pertama sebagai Efisiensi dan kolom kedua sebagai point yang nilainya akan kita prediksi berdasarkan inputan effisiensi independen.\n\nPertama kita memulai dengan membuat scatter pada data frame tersebut <hr>","8210366c":"<br>\n<b><center>Penjelasan Nama Kolom Diatas<\/center><\/b>\n<table>\n  <tr>\n    <td><b>Name<\/b><\/td>\n    <td>Nama Pemain<\/td>\n    <td><b>Team<\/b><\/td>\n    <td>Team Pemain<\/td>\n    <td><b>Game Played<\/b><\/td>\n    <td>Banyaknya Game yang Dimainkan<\/td>\n    <td><b>MIN<\/b><\/td>\n    <td>Menit Bermain<\/td>\n    <td><b>PMPG<\/b><\/td>\n    <td>Jumlah Menit Bermain Setiap Game<\/td>\n  <\/tr>\n  <tr>\n    <td><b>EFF<\/b><\/td>\n    <td>Effisiensi Pemain<\/td>\n    <td><b>FGM<\/b><\/td>\n    <td>Total Tembakan Masuk<\/td>\n    <td><b>FGA<\/b><\/td>\n    <td>Total Tembakan Bebas<\/td>\n    <td><b>TFG<\/b><\/td>\n    <td>Total Keseluruhan Tembakan<\/td>\n    <td><b>PTS<\/b><\/td>\n    <td>Point yang Disumbangkan Pemain<\/td>\n  <\/tr>\n<\/table>","41575ec9":"<hr>Mencari poin tertinggi dan kaitanya dengan effisiensi pemain<hr> ","eb64f84b":"Pertama yang dilakukan adalah menghapus beberapa pemain yang memiliki nilai X dan Y tidak relevan dengan clustering nantinya\n<hr>","aa9df9ed":"<hr>Kelima setelah clustering pada grafik sudah terlihat jelas maka variabel x yang berupa angka akan saya ubah menjadi nama posisi didalam bola basket untuk memudahkan dalam membaca data nantinya, dan menyatuka type tuples tersebut kedalam suatu variabel<hr>","ab1d5e15":"### B. Jumlah Efffisiensi Team terhadap Jumlah Point yang Didapatkan\n<hr>\nJika point diatas adalah effisiensi tertinggi pemain pada tim regional timur, maka saya akan memperlebar range atau jarak berdasarkan seluruh pemain yang ada didalam setiap Team untuk dianalisa perbandingan tim yang memiliki point yang banyak terhadap jumlah effisiensi yang dilakukan\n<hr>","751c0cc0":"### B.  Non-Linier Rergression\n<hr>\nJika Linier Regression memiliki error yang tinggi maka dapat disimpulkan ada lengkungan (tidak lurus) saat penyajian data dalam bentuk scatter oleh sebab itu saya mencoba untuk menggunakan Regresi Non Linier\n<hr>","ba458956":"<hr>\nKedua Membuat Rumus Total Rebound (Rebound\/Menit) dan Total Asist (Asist\/Menit), lalu mendeklarasikan 2 point tersebut kedalam variabel baru bernama x_var dan y_var.\n\nSelanjutnya adalah membuat grafik scatter untuk melihat pola yang akan diclustering nantinya (pewarnaan bisa dilihat melalui code dibawah) \n<hr>","4adf5827":"<hr>Kedua memasukan kolom Games Played kedalam dfeastrp untuk tujuan visualisasi<hr>","5d8d4539":"<hr> Membuat grafik berbentuk stacked bar untuk membandingkan kedua variabel antara effisiensi dan points <hr>","df37e9d8":"<hr><b>Kesimpulan :<\/b> Tenyata dari Regresion diatas memiliki tingkat error yang banyak oleh sebab itu Linier Regression Model tidak cocok digunakan untuk pola dari scatter ini <hr>","e832aa47":"<hr>Selanjutnya melakukan pemanggilan data <b>Status Player<\/b> dengan nama player_stats.csv yang berbentuk .csv kedalam jupyter notebook menggunakan library dari pandas dan menampilkan data.head() agar menampilkan data atas saja sejumlah 6 <hr>","b6b5af0d":"<hr>\nKetiga melihat Games Played tertinggi yang dilakukan, setelah itu membagi point yang di peroleh per game (Game yang dijalankan adalah 83). Membuat Data Frame baru untuk tujuan visualisasi\n<hr>","5f058c45":"<hr>Ketiga setelah kita mendapatkan B0 dan B1 nya maka kita dapat memvisualisasikan vektor prediksi tersebut kedalam scatter<hr>","11712654":"<hr>Kedua adalah menampilkan nilai Coefficients dan Intercept menggunakan fungsi yang sudah disediakan (default).\n\nMaka akan mendapatkan vektor prediksi sebagai berikut <hr>","47789313":"## 1. Buat Scatter Plot untuk Masing Masing Feature \n<hr>\nSetelah data frame yang akan digunakan untuk analisis sempurna maka langkah selanjutnya adalah melihat korelasi beberapa data terhadap kolom point \"PTS\", untuk memudahkan dalam visualisasi dalam kasus ini saya menggunakan library dari <b>seaborns<\/b> yang terintegrasi dengan matplotlib dan pandas\n\n<p>Karena banyaknya feature yang ada, visualisasi scatter plot menggunakan seaborns saya lakukan agar pengerjaan scatter dapat berjalan secara efektif dan efisien dalam menganalisa<\/p><hr>","d4ee53b7":"<hr>Keempat setelah clustering dijalankan maka akan saya tampilkan menggunakan scatter sesuai dengan cluster yang sudah terbentuk [d0, d1, d2, d3, d4] maka hasilnya akan terlihat seperti dibawah<hr>","5000d5e6":"## 5 Analisis Menggunakan Clustering\n<hr>\nAnalisis clustering ini bertujuan untuk mengklasifikasi posisi pemain pada musim berikutnya sesuai dengan status individu yang relevan untuk posisinya sebagai pemain basket\n\nDimana klasifikasi juga dilakukan dengan rumus penentuan x = asist\/menit bermain dan y = rebound\/menit sesuai pada rumus yang ada di website <a href=\"https:\/\/medium.com\/@vmusgrove86\/a-data-dive-into-2018-2019-nba-player-stats-in-python-d7a1c051ac5c\">NBA Medium<\/a>, penjelasan tentang posisi bola pemain bola basket dapat dilihat pada situs <a href=\"https:\/\/id.wikipedia.org\/wiki\/Posisi_bola_basket\">Wikipedia<\/a>\n\n<ol>\n    <li>SG : Shooting Guard<\/li>\n    <li>PF : Power Forward<\/li>\n    <li>PG : Point Guard<\/li>\n    <li>C  : Center<\/li>\n    <li>SF  : Small Forward<\/li>\n<\/ol>\n<hr>","eb8d8a65":"Pertama kita akan memasukan kolom game yang dimainkan setiap team kedalam Data Frame dfeastrp menggunakan SQL<hr>","2a1a2fc5":"<hr>Dari variabel baru diatas yang telah kita kalkulasikan, langkah selanjutnya adalah memasukan variabel diatas kedalam\nkolom data frame <b>dfl<\/b> dengan bantuan fungsi data.insert dari library pandas\n\n<b> Berikut adalah Data Frame yang sudah siap untuk di analisa <\/b>\n<p> Terdapat tambahan menit bermain setiap game dan total tembakan yang dilakukan\n<hr>","98a406bb":"### A.  Linier Rergression\n<hr>\nSepertinya scatter yang terlihat bisa di regresikan dengan mode Linier.\n\nPertama Membuat data train yang diambil dari data utama sebanyak 20% dari total keseluruhan data. untuk kepereluan regresi linier dan ditampilkan dalam bentuk scatter.\n<hr>","e95a4cbf":"## 3. Statistik Deskriptif EFF Terhadap Point\nPada statistik deskriptif ini saya membagi efisiensi menjadi 3 bagian, dikarenakan pada olah raga bola basket tim terbagi menjadi beberapa regional dan pada setiap team terdapat God Among Man (MVP Player)\n<ol>\n    <li>Effisiensi Pemain Tertinggi didalam Team pada Regional <\/li>\n    <li>Pengaruh Effisiensi Team Terhadap Point yang Didapatkan<\/li>\n    <li>Pengaruh Effisiensi Seluruh Pemain untuk Mendapatkan Peringkat 1 pada Regionalnya<\/li>\n<\/ol>\n<hr>\n\n### A. Effisiensi Tertinggi Pemain dalam Team Regional Timur Terhadap Point yang Didapatkan\nMelakukan indexing data dimana terdapat beberapa team yang tergabung di Regional Team Seperti Boston Celtics, Detroit Pistons, Cleveland Cavalirs, Orlando Magic, Toronto Raptors, Washington Wizards, Philadelphia 76ers, Milwaukee Bucks, New York Knicks, Atlanta Hawks, Charlote Hornets, Chicago Bulls, Indiana Pacers, Miami Heat. Indexing ini dimasukkan kedalam Data Frame baru yang bernama dfeast.\n\nPembagian tim ini dapat di akses melalui link <a href=\"https:\/\/id.wikipedia.org\/wiki\/Wilayah_Timur_(NBA)\">Wikipedia NBA<\/a>\n\n\n<hr>","e136b5e6":"<hr>Ketiga yaitu setelah semua rumus dimasukkna kedalam class dan didefinisikan maka langkah selanjutnya adalah Mencari B0 (Inter) dan B1 (Coef) menggunakan rumus \n<hr>","e14ad698":"<hr>\n<b>Analisa :<\/b> Maka dapat disimpulkan bahwa point yang dikumpulkan setiap gamenya harus berjarak 0.5% dari peringkat atas agar mampu membawa team menjadi ranking 1 pada regionalnya\n<hr>","f5563e2a":"<hr>Meihat data NaN (null) pada kolom \"Height\" dengan tujuan untuk melihat keseluruhan data frame yang akan digunakan untuk analisa tidak memiliki nilai NaN <hr>","05d41ce9":"Pertama menjumlahkan seluruh effisiensi pemain yang tergabung berdasarkan grup Team pada regional timur menggunakan SQL <hr>","321349e8":"### ii. Data Preparing\n<hr>Setelah Proses <b>Cleaning<\/b> selesai saya akan membuat data frame baru untuk menampung data yang telah di cleaning tersebut dengan menambahkan beberapa kolom yang akan dianalisa\n<ol>\n    <li><b>Menit bermain pemain setiap gamenya<\/b><\/li>\n    Hal ini dilakukan karena berapa menit pemain didalam setiap game untuk mengumpulkan point sebanyak value yang ada di kolom PTS\n    <li><b>Total Tembakan yang dilakukan oleh pemain<\/b><\/li>\n    Berapa total tembakan yang dilakukan oleh pemain agar dapat mengumpulkan point sebanyak value yang ada di kolom PTS\n<\/ol>\n<hr>","c64214a8":"<hr>Ketiga memasukkan variabel baru bernama SEFF (Total Effisiensi) dan mengganti nama SUM PTS menjadi SPTS (jumlah keseluruhan point yang didapatkan)<hr>","ac817aca":"<hr>Melihat data yang memiliki value NaN pada setiap kolom<hr>","32ecc761":"<hr>\nTerakhir yaitu membuat Data Frame untuk melihat keselurahn data akhir, dimana saya memasukan Nama, Team, Posisi, dan menambahkan  total rebound dan asist.\n\nData dari cluster yang telah dibuat dimasukan setelah Posisi dengan nama kolom Next Pos hal ini bertujuan untuk memaksimalkan potensi pemain NBA pada musim 2015\/2016 dengan kaitannya status pemain pada musim 2014\/2015\n<hr>","858f44c0":"<b>Kesimpulan :<\/b> Error terkecil berada pada Regresi Non Linier milik Qubic hanya 0,5 dibandingkan dengan yang lainnya. Prediksi dapat dilakukan menggunakan hasil B0 dan B1 dari regresi Qubic","0249bd06":"<hr>\nKeempat setelah nilai B0 dan B1 maka kita buat scatternya sebagai berikut terhadap line dari (Eksponensial, Sigmoid, dan Qubic) dan mencari Error terkecil\n<hr>","f84ae149":"<hr>Check data yang memiliki nilai ganda atau duplikasi <hr>","58b4ae66":"<hr>\nKeempat kita uji coba B0 dan B1 tersebut kedalam rumus <b>\ud835\udc66\u00a0\u0302=\ud835\udf03_0+\ud835\udf03_1  \ud835\udc65_1<\/b> untuk melihat kualitas regresi yang dihasilkan\n<hr>","05026b84":"<hr>Keempat membuat kolom baru bernama Rank yang diambil dari jumlah point terbesar sampai terkecil. dan hasil dari tersebut akan menjadi Data Frame baru bernama dfeastrp yang akan digunakan untuk visualisasi dan analisis<hr>","61461135":"<hr>Ketiga ketika scatter color telah terbentuk maka langkah selanjutnya adalah clustering menggunakan library dari KMeans dengan asumsi 5 cluster sesuai warna yang muncul (Hijau\/PG, Biru\/SG, Orange\/SF, Ungu\/C, Merah\/PF).\n\nMaka akan muncul 5 pembagian pada x dan y<hr>","48c6273a":"<hr>Pertama adalah membuat class non linier regression terdiri dari\n<ol>\n    <li>Sigmoid<\/li>\n    <li>Exponensial<\/li>\n    <li>Qubic<\/li>\n<\/ol>\n    Dengan menggunakan rumus\n    <center>\n        <b>Sigmoid<\/b> <br> $$ Y = a + \\frac{b}{1+ c^{(X-d)}}$$ <br><br>\n        <b>Exponensial<\/b> <br> $$ \\hat{Y} = \\frac1{1+e^{\\beta_1(X-\\beta_2)}}$$ <br><br>\n        <b>Qubic<\/b> <br> $$ \\ y = a x^3 + b x^2 + c x + d \\ $$\n    <\/center>\n<hr>","b0287a6d":"<hr><b>Analisa :<\/b>\nPoint Tertinggi yang dicetak oleh pemain yang menjadi MVP didalam team regional timur berbanding lurus dengan point yang didapatkan, dimana effisiensi yang\ndiusahakan setiap pemain akan mendapatkan point tertinggi <b>kecuali<\/b> pada pemain Isaiah Thomas : 950\/1101, Carmelo Anthony 824\/966, dan CJ Miles 715\/942 (EFF\/PTS) <hr>","2218a2dc":"<hr>\nKedua membuat variabel x dan y dimana x = datax : maksimal(datax) dan x = datax : maksimal(datax)\n<hr>","d9e5c68a":"<hr>Pertama adalah import library yang dibutuhkan untuk keperluan analisis<hr>","d9cb8d82":"## 2. Dugaan Feature yang Memiliki Korelasi Kuat\n<hr>\n<p> Dengan melihat scatter plot pada gambar diatas terdapat 2 visualisasi yang memiliki korelasi kuat yaitu :\n    <ol>\n        <li>Menit bermain pemain (MIN) terhadap point yang disumbangkan bagi TIM<\/li>\n        <li>Effisiensi bermain pemain (EFF) dalam menyumbangkan point untuk TIM <\/li>\n    <\/ol>\n<\/p>\n<hr>\n\n<b> MIN - Menit Bermain <\/b>\n<p>Menit bermain adalah kalkulasi dari pemain yang masuk dari quarter ke-1 hingga ke-4 dan setiap quarternya memiliki waktu 12 menit, pada data yang disajikan terdapat catatan menit bermain pemain selama satu musim yang dapat dikorelasikan dengan point. Pada situs <a href=\"https:\/\/www.basketball-reference.com\/leagues\/NBA_2015.html\">Basket Ball Reference - Tim Stats 2014\/2015<\/a> dimana menit bermain pada tim tidak selalu mempengaruhi point yang didapatkan<\/p>\n\n<b>EFF - Effisiensi<\/b>\n<p>EFF atau yang disebut Effisiensi Pemain dalam bermain bola basket memiliki relasi dengan point yang didapatkan dikarenakan menurut analisa sederhana saya pada situs <a href=\"http:\/\/www.espn.com\/nba\/hollinger\/teamstats\">ESPN Team Statistic<\/a> tim dengan Effisiensi menyerang tertinggi menduduki peringkat pertama klasemen <i>National Basketball Association<\/i> pada musim 2018-2019 dan dikuatkan dengan pengertian yang ada pada <a href=\"https:\/\/en.wikipedia.org\/wiki\/Efficiency_(basketball)#EFF\">Wikipedia<\/a>dimana penghitungan effisiensi dapat dilakukan pada point yang di cetak<\/p>\n\n<hr>\n\n<b>Kesimpulan :<\/b> \n<p>Saya putuskan untuk menggunakan data Effisiensi dikarenakan pada rumus kalkulasi effisiensi terdapat beberapa variabel status pemain yang relevan digunakan seperti jumlah rebound, assist, steal, block, free throw, dan turnover. Setiap status yang saya sebutkan tersebut memiliki hubungan erat dengan point yang didapatkan.<\/p>\n\n<hr>","96ba5e00":"<hr>\n<b>Kesimpulan Akhir :<\/b> Semakin tinggi Effisiensi pemain didalam tim maka  dapat berkontribusi kepada team untuk berada di ranking teratas pada regionalnya. sebagai contoh adalah team Atlanta yang menduduki peringkat satu di regional timur karena memiliki point terbanyak\n<hr>","a55e3f43":"<hr>Kedua menjumlahkan seluruh point pemain yang tergabung berdasarkan grup dari Team regional timur menggunakan SQL<hr>","991c4799":"<hr>\n<b>Analisa :<\/b> pada fill chart \/ area chart semakin tinggi effisiensi pemain yang dilakukan pada setiap team akan berdampak pada point yang didapatkan dan akan berbanding lurus dengan rangking team pada regional tersebut. Dapat dilihat Team Atalanta memiliki efisiensi tertinggi dalam bermain bola basket dan menduduki peringkat pertama dalam grup regional timur. dan pada klub Miami memiliki effisiensi paling sedikit diantara team yang lain dan menduduki rangking terendah\n<hr>","6aedccda":"### i. Cleaning Data\n\n<hr>Dalam data frame induk diatas terlihat kolom <b>\"Height\"<\/b> yang akan saya gunakan untuk melihat korelasi data, kolom \"Height\" memiliki isi data yang <i>NaN<\/i> oleh sebab itu, saya akan collecting data yang tidak memiliki value NaN pada kolom \"Height\" dengan cara sebagai berikut :\n<ol>\n    <li>Membuat Data Frame Baru dengan data BMI yang tidak NaN<\/li>\n    <li>Kenapa menggunakan kolom BMI? karena didalam  menentukan BMI memerlukan Height dan Weight<\/li>\n    <li>Jika BMI memiliki nilai NaN, maka secara tidak langsung Height atau Weight memiliki nilai NaN <\/li>\n<\/ol>\nBagaimana dengan kolom \"Weight\"? Hanya untuk berjaga jaga siapa tau di kemudian hari kolom \"Weight\" akan digunakan<hr>","5df8e477":"### C. Rata Rata Point per Game yang didapatkan Team Sesuai Ranking\n<hr>\nSetelah saya mengetahui hubungan antara effisiensi terhadap point yang didapatkan maka relasi effisiensi dan point begitu kuat untuk mendapatkan rank didalam suatu regional, lalu kita bisa lanjut untuk menganalisa berapa presentase point pergame agar team menjadi ranking 1 di regionalnya agar nantinya dapat dilihat juga berapa effisiensi yang harus dilakukan setiap team per gamenya, dan dapat ditarik jauh lagi seperti berapa banyak effisiensi pemain yang harus dilakukan agar team mendapat ranking tertinggi\n<hr>"}}