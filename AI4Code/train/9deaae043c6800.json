{"cell_type":{"1b1ac7f7":"code","6883a1b2":"code","310e6696":"code","975b929b":"code","f0dfb133":"code","03708ddd":"code","884e9513":"code","e0009ced":"code","a1691093":"code","9397af71":"code","336d01a4":"code","bd5bca84":"code","0c05e55f":"code","4ef45ba8":"code","70aee955":"markdown","d697bfd7":"markdown","7a3bb092":"markdown","e7f3066b":"markdown","622413c4":"markdown","d4252a01":"markdown","728e5fae":"markdown","04d6ef13":"markdown","7cd4d15b":"markdown","e100e5b7":"markdown"},"source":{"1b1ac7f7":"import os\nimport plotly\nimport numpy as np \nimport pandas as pd\nimport tensorflow as tf \nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nfrom tensorflow.keras import layers\nfrom plotly.subplots import make_subplots\nfrom keras.layers import Dense, Dropout, Flatten\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","6883a1b2":"class_names = pd.read_csv( r'..\/input\/butterfly-images40-species\/CLASS NAMES.csv')[\"COMMON NAME\"].tolist()","310e6696":"working_directory = r'..\/input\/butterfly-images40-species\/'\ntrain_path = os.path.join(working_directory, 'train')\ntest_path = os.path.join(working_directory, 'test')\nvalid_path = os.path.join(working_directory, 'valid')","975b929b":"train_generator = ImageDataGenerator(rescale = 1.\/255.)\n\ntest_generator = ImageDataGenerator( rescale = 1.\/255. )\n\nvalid_generator = ImageDataGenerator( rescale = 1.\/255. )","f0dfb133":"train = train_generator.flow_from_directory(train_path, batch_size = 20, class_mode = 'categorical', classes=class_names, target_size = (224, 224))\n\nvalid = valid_generator.flow_from_directory( valid_path,  batch_size = 20, class_mode = 'categorical',classes=class_names, target_size = (224, 224))\n\ntest = test_generator.flow_from_directory(test_path, batch_size = 20, class_mode = 'categorical',classes=class_names, target_size = (224, 224))","03708ddd":"img, label = train.next()\nrows,cols = 4,4\nfig = make_subplots(rows=rows, cols=cols,horizontal_spacing=0.05,subplot_titles=[class_names[np.argmax(label[i])] for i in range(rows*cols)])\nindx=0\nfor i in range(rows):\n    for j in range(cols):\n        fig.add_trace(px.imshow(img[indx]).data[0],i+1,j+1)\n        indx+=1\n        fig.update_layout(width=1000,height=1000)\n        fig.update_xaxes(showticklabels=False)\n        fig.update_yaxes(showticklabels=False)\nfig.show()","884e9513":"base_model = VGG16(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')","e0009ced":"for layer in base_model.layers:\n    layer.trainable = False","a1691093":"x = layers.Flatten()(base_model.output)\nx = layers.Dense(512, activation='relu')(x)\nx = layers.Dropout(0.5)(x)\nx = layers.Dense(256, activation='relu')(x)\nx = layers.Dropout(0.5)(x)\nx = layers.Dense(75, activation='softmax')(x)\n\nmodel = tf.keras.models.Model(base_model.input, x)\n\nmodel.compile(optimizer = tf.keras.optimizers.Adam(0.0001), loss = 'categorical_crossentropy',metrics = ['acc'])","9397af71":"model.summary()","336d01a4":"callback = EarlyStopping(monitor='val_loss', patience=5)\ncheckpoint = ModelCheckpoint('butterfly-Image_model_weights.hdf5', monitor='val_loss', verbose=2, save_best_only=True, mode='min')\nhistory = model.fit(train, validation_data = valid,epochs = 50, batch_size=32, callbacks=[callback, checkpoint])\n","bd5bca84":"\nfig = make_subplots(rows=1, cols=2,subplot_titles=(\"Loss\", \"Accuracy\"))\nfig.add_trace(go.Scatter(y=history.history['loss'], mode='lines', name='Train Loss'),1,1)\nfig.add_trace(go.Scatter(y=history.history['val_loss'], mode='lines', name='Validation Loss'),1,1)\nfig.add_trace(go.Scatter(y=history.history['acc'], mode='lines', name='Train Accuracy'),1,2)\nfig.add_trace(go.Scatter(y=history.history['val_acc'],mode='lines', name='Validation Accuracy'),1,2)\nfig.update_xaxes(title_text=\"Epoch\", row=1, col=1)\nfig.update_xaxes(title_text=\"Epoch\", row=1, col=2)\nfig.show()","0c05e55f":"model.load_weights('butterfly-Image_model_weights.hdf5')","4ef45ba8":"print(classification_report(test.classes[test.index_array],  model.predict(test).argmax(axis=1), target_names=class_names))","70aee955":"#### Add fully connected layers.","d697bfd7":"#### We will froze all layers except output layer of VGG16.\n","7a3bb092":"## Importing Required Libraries\n","e7f3066b":"<center><img src=\"https:\/\/www.researchgate.net\/profile\/Alex-Ter-Sarkisov\/publication\/338572801\/figure\/fig1\/AS:847202364686336@1579000192000\/VGG16-architecture-There-are-in-total-five-blocks-the-first-two-blocks-have-two-Conv.jpg\"\/><\/center>\n\n<center><a href=\"https:\/\/www.researchgate.net\/figure\/VGG16-architecture-There-are-in-total-five-blocks-the-first-two-blocks-have-two-Conv_fig1_338572801\">VGG16 Architecture<\/a><\/center>","622413c4":"### I will use pre-trained model, VGG16.It's architecture is shown below. \n\nVGG16 is a convolutional neural network model proposed by K. Simonyan and A. Zisserman from the University of Oxford in the paper \u201cVery Deep Convolutional Networks for Large-Scale Image Recognition\u201d. The model achieves 92.7% top-5 test accuracy in ImageNet, which is a dataset of over 14 million images belonging to 1000 classes.\n\nsrc:https:\/\/neurohive.io\/en\/popular-networks\/vgg16\/","d4252a01":"#### Loading the best model","728e5fae":"# Butterfly Image Classification\n\n<center><img src=\"https:\/\/cdn.pixabay.com\/photo\/2017\/02\/08\/17\/24\/fantasy-2049567_960_720.jpg\"\/><\/center>\n\n### The butterfly images dataset contains images of 75 different butterfly species. Each picture is 224 X 224 X 3 in size and in jpg format. Data is given in three files: training, testing and validation. There are a total of 9285 images in the training data. In the test and verification data, there are 375 images.","04d6ef13":"## Reading data and augmentation\n- Reading the target class values\n- Reading data from folders and rescale\n","7cd4d15b":"### Let's see some butterflies","e100e5b7":"#### As a conclusion, with VGG16 we get 91% accuracy score."}}