{"cell_type":{"ea25c18d":"code","55837022":"code","0a1bf9b5":"code","1c967663":"code","e4ef586b":"code","4e4f9620":"code","81a206cb":"code","ccdb693a":"code","ce99ba15":"code","4b2b8ac3":"code","9d1fb9b9":"code","e3b154d4":"code","a76006a5":"code","870b20aa":"code","aa00b99b":"code","545bea52":"code","456feaa8":"code","7a4fea25":"code","b5a51cd2":"markdown","9d5057c9":"markdown","2df88bc5":"markdown","506f49de":"markdown","61293f73":"markdown","8a19f422":"markdown","90e46b13":"markdown","c2880fe4":"markdown","6f98f9ba":"markdown","d027c3f5":"markdown","1f5f9a4d":"markdown"},"source":{"ea25c18d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom surprise import Dataset \nfrom surprise import Reader\nfrom surprise import SVD\nfrom surprise import KNNBasic\nfrom surprise import accuracy\nfrom surprise.model_selection import cross_validate\nfrom surprise.model_selection import train_test_split\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","55837022":"reader = Reader(line_format = \"user item rating timestamp\", sep = ',', skip_lines = 1)\ndataset = Dataset.load_from_file(\"\/kaggle\/input\/the-movies-dataset\/ratings_small.csv\", reader = reader)","0a1bf9b5":"PMF_RMSE = []\nPMF_MAE = []\nUB_RMSE = []\nUB_MAE = []\nIB_RMSE = []\nIB_MAE = []","1c967663":"algorithm = SVD(biased = False)\nCV_PMF = cross_validate(algorithm, dataset, measures = ['RMSE', 'MAE'], cv = 5, verbose = True)","e4ef586b":"algorithm = KNNBasic(sim_options = {'user_based' : True })\nCV_UB_CF = cross_validate(algorithm, dataset, measures = ['RMSE', 'MAE'], cv = 5, verbose = True)","4e4f9620":"algorithm = KNNBasic(sim_options = {'user_based' : False })\nCV_IB_CF = cross_validate(algorithm, dataset, measures = ['RMSE', 'MAE'], cv = 5, verbose = True)","81a206cb":"PMF_RMSE.append(CV_PMF['test_rmse'].mean())\nPMF_MAE.append(CV_PMF['test_mae'].mean())\nprint(PMF_RMSE)\nprint(PMF_MAE)","ccdb693a":"UB_RMSE.append(CV_UB_CF['test_rmse'].mean())\nUB_MAE.append(CV_UB_CF['test_mae'].mean())\nprint(UB_RMSE)\nprint(UB_MAE)","ce99ba15":"IB_RMSE.append(CV_IB_CF['test_rmse'].mean())\nIB_MAE.append(CV_IB_CF['test_mae'].mean())\nprint(IB_RMSE)\nprint(IB_MAE)","4b2b8ac3":"algo_UB_cosine = KNNBasic(sim_options = {'name' : 'cosine', 'user_based' : True})\nCV_UB_cosine = cross_validate(algo_UB_cosine, dataset, measures = ['RMSE', 'MAE'], cv = 5, verbose = True)\nalgo_UB_msd = KNNBasic(sim_options = {'user_based' : True})\nCV_UB_msd = cross_validate(algo_UB_msd, dataset, measures = ['RMSE', 'MAE'], cv = 5, verbose = True)\nalgo_UB_pearson = KNNBasic(sim_options = {'name' : 'pearson_baseline', 'user_based' : True})\nCV_UB_pearson = cross_validate(algo_UB_pearson, dataset, measures = ['RMSE', 'MAE'], cv = 5, verbose = True)\n\nalgo_IB_cosine = KNNBasic(sim_options = {'name' : 'cosine', 'user_based' : False})\nCV_IB_cosine = cross_validate(algo_IB_cosine, dataset, measures = ['RMSE', 'MAE'], cv = 5, verbose = True)\nalgo_IB_msd = KNNBasic(sim_options = {'user_based' : False})\nCV_IB_msd = cross_validate(algo_IB_msd, dataset, measures = ['RMSE', 'MAE'], cv = 5, verbose = True)\nalgo_IB_pearson = KNNBasic(sim_options = {'name' : 'pearson_baseline', 'user_based' : False})\nCV_IB_pearson = cross_validate(algo_IB_pearson, dataset, measures = ['RMSE', 'MAE'], cv = 5, verbose = True)","9d1fb9b9":"UB_RMSE_PLOT = []\nUB_MAE_PLOT = []\nUB_RMSE_PLOT.append(CV_UB_cosine['test_rmse'].mean())\nUB_RMSE_PLOT.append(CV_UB_msd['test_rmse'].mean())\nUB_RMSE_PLOT.append(CV_UB_pearson['test_rmse'].mean())\nUB_MAE_PLOT.append(CV_UB_cosine['test_mae'].mean())\nUB_MAE_PLOT.append(CV_UB_msd['test_mae'].mean())\nUB_MAE_PLOT.append(CV_UB_pearson['test_mae'].mean())","e3b154d4":"plt.title(\"User Based CF: Cosine, MSD, Pearson\")\nplt.plot(UB_RMSE_PLOT, label = 'RMSE')\nplt.plot(UB_MAE_PLOT, label = 'MAE')\nplt.legend()","a76006a5":"IB_RMSE_PLOT = []\nIB_MAE_PLOT = []\nIB_RMSE_PLOT.append(CV_IB_cosine['test_rmse'].mean())\nIB_RMSE_PLOT.append(CV_IB_msd['test_rmse'].mean())\nIB_RMSE_PLOT.append(CV_IB_pearson['test_rmse'].mean())\nIB_MAE_PLOT.append(CV_IB_cosine['test_mae'].mean())\nIB_MAE_PLOT.append(CV_IB_msd['test_mae'].mean())\nIB_MAE_PLOT.append(CV_IB_pearson['test_mae'].mean())","870b20aa":"plt.title(\"Item Based CF: Cosine, MSD, Pearson\")\nplt.plot(IB_RMSE_PLOT, label = 'RMSE')\nplt.plot(IB_MAE_PLOT, label = 'MAE')\nplt.legend()","aa00b99b":"Range = range(1,101)\nUser = []\n\nfor i in Range:\n        algo = KNNBasic(k = i, sim_options = {'user_based' : True }, verbose = False)\n        CV_User = cross_validate(algo, dataset, measures=['rmse', 'mae'],cv = 5,verbose = False)\n        User.append(CV_User['test_rmse'].mean())\n        \nplt.plot(User)","545bea52":"Range = range(1,101)\nItem = []\n\nfor i in Range:\n        algo = KNNBasic(k = i, sim_options = {'user_based' : False }, verbose = False)\n        CV_Item = cross_validate(algo, dataset, measures=['rmse', 'mae'],cv = 5,verbose = False)\n        Item.append(CV_Item['test_rmse'].mean())\n        \nplt.plot(Item)","456feaa8":"User.index(min(User))","7a4fea25":"Item.index(min(Item))","b5a51cd2":"Item-based collaborative filtering is the best in movie rating data.","9d5057c9":"a. Read data from \u201cratings.csv\u201d with line format: 'userID movieID rating timestamp'.","2df88bc5":"c. Compute the average MAE and RMSE of the Probabilistic Matrix Factorization(PMF), User based Collaborative Filtering, Item based Collaborative Filtering, under the 5-folds cross-validation","506f49de":"Machine Learning with Matrix Data for Recommender Systems\n1. Recommender systems are a hot topic. Recommendation systems can be formulated as a task of matrix completion in machine learning. Recommender systems aim to predict the rating that a user will give for an item (e.g., a restaurant, a movie, a product).\n2. Download the movie rating dataset from: https:\/\/www.kaggle.com\/rounakbanik\/themovies-dataset. These files contain metadata for all 45,000 movies listed in the Full MovieLens Dataset. The dataset consists of movies released on or before July 2017. Data points include cast, crew, plot keywords, budget, revenue, posters, release dates, languages, production companies, countries, TMDB vote counts and vote averages. This dataset also has files containing 26 million ratings from 270,000 users for all 45,000 movies. Ratings are on a scale of 1-5 and have been obtained from the official GroupLens website.\n3. Building a small recommender system with the matrix data: \u201cratings.csv\u201d. You can use the recommender system library: Surprise (http:\/\/surpriselib.com), use other recommender system libraries, or implement from scratches.","61293f73":"The impact of the three metrics on User based Collaborative Filtering is consistent with the impact of the three metrics on Item based Collaborative Filtering.","8a19f422":"d. Compare the average (mean) performances of User-based collaborative filtering, item-based collaborative filtering, PMF with respect to RMSE and MAE. Which ML model is the best in the movie rating data?","90e46b13":"f. Examine how the number of neighbors impacts the performances of User based Collaborative Filtering and Item based Collaborative Filtering? Plot your results.","c2880fe4":"The best K for User based collaborative filtering is different than Item based collaborative filtering.\nBest K for User-Based : 14\nBest K for Item-based : 66","6f98f9ba":"b. MAE and RMSE are two famous metrics for evaluating the performances of a recommender system. The definition of MAE can be found via: https:\/\/en.wikipedia.org\/wiki\/Mean_absolute_error. The definition of RMSE can be found via: https:\/\/en.wikipedia.org\/wiki\/Root-mean-square_deviation.","d027c3f5":"e. Examine how the cosine, MSD (Mean Squared Difference), and Pearson similarities impact the performances of User based Collaborative Filtering and Item based Collaborative Filtering. Plot your results. Is the impact of the three\nmetrics on User based Collaborative Filtering consistent with the impact of the three metrics on Item based Collaborative Filtering?","1f5f9a4d":"g. Identify the best number of neighbor (denoted by K) for User\/Item based collaborative filtering in terms of RMSE. Is the best K of User based collaborative filtering the same with the best K of Item based collaborative filtering?"}}