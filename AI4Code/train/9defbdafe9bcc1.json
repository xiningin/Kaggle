{"cell_type":{"51fb79f4":"code","53fc84f4":"code","5460710f":"code","ca803338":"code","ef9c718e":"code","c813d5f0":"code","0b199849":"code","c26b887a":"code","827f7f08":"code","49d6f406":"code","1ddeb1ef":"code","3cc61be3":"code","30fe1ae6":"code","d61502ad":"code","169cb5e6":"code","a15cbccc":"code","42ac2925":"code","376e9798":"code","6da407ae":"code","ab559ad8":"markdown","8191b82c":"markdown","9f3ba6f5":"markdown","0f3da2bd":"markdown","752b5cc2":"markdown","0f1933c8":"markdown","4b59fde4":"markdown","144906fe":"markdown","1813ac99":"markdown","8923afb2":"markdown"},"source":{"51fb79f4":"from __future__ import print_function, division, absolute_import\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torch.nn.functional as F\nimport os\n\n# Any results you write to the current directory are saved as output.\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset,DataLoader\nfrom torchvision import transforms,models\nfrom tqdm import tqdm_notebook as tqdm\nimport math\nimport torch.utils.model_zoo as model_zoo\n\n","53fc84f4":"train = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/train.csv')\n'''data0 = pd.read_feather('\/kaggle\/usr\/lib\/resize_and_load_with_feather_format_much_faster\/train_data_0.feather')\ndata1 = pd.read_feather('\/kaggle\/usr\/lib\/resize_and_load_with_feather_format_much_faster\/train_data_1.feather')\ndata2 = pd.read_feather('\/kaggle\/usr\/lib\/resize_and_load_with_feather_format_much_faster\/train_data_2.feather')\ndata3 = pd.read_feather('\/kaggle\/usr\/lib\/resize_and_load_with_feather_format_much_faster\/train_data_3.feather')'''","5460710f":"ls \/kaggle\/usr\/lib\/resize_and_load_with_feather_format_much_faster\/","ca803338":"#data_full = pd.concat([data0,data1,data2,data3],ignore_index=True)","ef9c718e":"class GraphemeDataset(Dataset):\n    def __init__(self,df,label,_type='train'):\n        self.df = df\n        self.label = label\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self,idx):\n        label1 = self.label.vowel_diacritic.values[idx]\n        label2 = self.label.grapheme_root.values[idx]\n        label3 = self.label.consonant_diacritic.values[idx]\n        image = self.df.iloc[idx][1:].values.reshape(64,64).astype(np.float)\n        return image,label1,label2,label3","c813d5f0":"\nclass Selayer(nn.Module):\n\n    def __init__(self, inplanes):\n        super(Selayer, self).__init__()\n        self.global_avgpool = nn.AdaptiveAvgPool2d(1)\n        self.conv1 = nn.Conv2d(inplanes, int(inplanes \/ 16), kernel_size=1, stride=1)\n        self.conv2 = nn.Conv2d(int(inplanes \/ 16), inplanes, kernel_size=1, stride=1)\n        self.relu = nn.ReLU(inplace=True)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n\n        out = self.global_avgpool(x)\n\n        out = self.conv1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.sigmoid(out)\n\n        return x * out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, cardinality, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes * 2)\n\n        self.conv2 = nn.Conv2d(planes * 2, planes * 2, kernel_size=3, stride=stride,\n                               padding=1, groups=cardinality, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes * 2)\n\n        self.conv3 = nn.Conv2d(planes * 2, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n\n        self.selayer = Selayer(planes * 4)\n\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out = self.selayer(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass SeResNeXt(nn.Module):\n\n    def __init__(self, block, layers, cardinality=32, num_classes=1000):\n        super(SeResNeXt, self).__init__()\n        self.cardinality = cardinality\n        self.inplanes = 64\n\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. \/ n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, self.cardinality, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, self.cardinality))\n                             \n        # vowel_diacritic\n        self.fc1 = nn.Linear(2048,11)\n        # grapheme_root\n        self.fc2 = nn.Linear(2048,168)\n        # consonant_diacritic\n        self.fc3 = nn.Linear(2048,7)\n        return nn.Sequential(*layers)\n        \n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        \n        x1 = self.fc1(x)\n        x2 = self.fc2(x)\n        x3 = self.fc3(x)\n        \n        return x1,x2,x3\n\n\ndef se_resnext50(**kwargs):\n    \"\"\"Constructs a SeResNeXt-50 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = SeResNeXt(Bottleneck, [3, 4, 6, 3], **kwargs)\n    return model\n\n\ndef se_resnext101(**kwargs):\n    \"\"\"Constructs a SeResNeXt-101 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = SeResNeXt(Bottleneck, [3, 4, 23, 3], **kwargs)\n    return model\n\n\ndef se_resnext152(**kwargs):\n    \"\"\"Constructs a SeResNeXt-152 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = SeResNeXt(Bottleneck, [3, 8, 36, 3], **kwargs)\n    return model","0b199849":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","c26b887a":"model = se_resnext50().to(device)\noptimizer = optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-4, max_lr=0.05)\ncriterion = nn.CrossEntropyLoss()\nbatch_size=32","827f7f08":"'''%%time\nepochs = 200\nmodel.train()\nlosses = []\naccs = []\nfor epoch in range(epochs):\n    reduced_index =train.groupby(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']).apply(lambda x: x.sample(5)).image_id.values\n    reduced_train = train.loc[train.image_id.isin(reduced_index)]\n    reduced_data = data_full.loc[data_full.image_id.isin(reduced_index)]\n    train_image = GraphemeDataset(reduced_data,reduced_train)\n    train_loader = torch.utils.data.DataLoader(train_image,batch_size=batch_size,shuffle=True)\n    \n    print('epochs {}\/{} '.format(epoch+1,epochs))\n    running_loss = 0.0\n    running_acc = 0.0\n    for idx, (inputs,labels1,labels2,labels3) in tqdm(enumerate(train_loader),total=len(train_loader)):\n        inputs = inputs.to(device)\n        labels1 = labels1.to(device)\n        labels2 = labels2.to(device)\n        labels3 = labels3.to(device)\n        \n        optimizer.zero_grad()\n        outputs1,outputs2,outputs3 = model(inputs.unsqueeze(1).float())\n        loss1 = criterion(outputs1,labels1)\n        loss2 = criterion(outputs2,labels2)\n        loss3 = criterion(outputs3,labels3)\n        running_loss += loss1+loss2+loss3\n        running_acc += (outputs1.argmax(1)==labels1).float().mean()\n        running_acc += (outputs2.argmax(1)==labels2).float().mean()\n        running_acc += (outputs3.argmax(1)==labels3).float().mean()\n        (loss1+loss2+loss3).backward()\n        optimizer.step()\n    #scheduler.step()\n    losses.append(running_loss\/len(train_loader))\n    accs.append(running_acc\/(len(train_loader)*3))\n    print('acc : {:.4f}%'.format(running_acc\/(len(train_loader)*3)))\n    print('loss : {:.4f}'.format(running_loss\/len(train_loader)))\ntorch.save(model.state_dict(), 'se_resnext50.pth')'''","49d6f406":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# Any results you write to the current directory are saved as output.\nimport cv2\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset,DataLoader\nfrom torchvision import transforms,models\nfrom tqdm import tqdm_notebook as tqdm","1ddeb1ef":"test = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/test.csv')","3cc61be3":"class GraphemeDataset(Dataset):\n    def __init__(self,df,_type='train'):\n        self.df = df\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self,idx):\n        image = self.df.iloc[idx][1:].values.reshape(128,128).astype(float)\n        return image","30fe1ae6":"import os\nos.listdir('..\/input\/resnext50')","d61502ad":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = se_resnext50().to(device)\nmodel.load_state_dict(torch.load('..\/input\/resnext50\/new128_0.9486092329025269_loss0.44209763407707214se_resnext50.pth'))","169cb5e6":"def Resize(df,size=128):\n    resized = {} \n    df = df.set_index('image_id')\n    for i in tqdm(range(df.shape[0])):\n        image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size))\n        resized[df.index[i]] = image.reshape(-1)\n    resized = pd.DataFrame(resized).T.reset_index()\n    resized.columns = resized.columns.astype(str)\n    resized.rename(columns={'index':'image_id'},inplace=True)\n    return resized","a15cbccc":"%%time\nmodel.eval()\ntest_data = ['test_image_data_0.parquet','test_image_data_1.parquet','test_image_data_2.parquet','test_image_data_3.parquet']\npredictions = []\nbatch_size=1\nfor fname in test_data:\n    data = pd.read_parquet(f'\/kaggle\/input\/bengaliai-cv19\/{fname}')\n    data = Resize(data)\n    test_image = GraphemeDataset(data)\n    test_loader = torch.utils.data.DataLoader(test_image,batch_size=1,shuffle=False)\n    with torch.no_grad():\n        for idx, (inputs) in tqdm(enumerate(test_loader),total=len(test_loader)):\n            inputs.to(device)\n            \n            outputs1,outputs2,outputs3 = model(inputs.unsqueeze(1).float().cuda())\n            predictions.append(outputs3.argmax(1).cpu().detach().numpy())\n            predictions.append(outputs2.argmax(1).cpu().detach().numpy())\n            predictions.append(outputs1.argmax(1).cpu().detach().numpy())","42ac2925":"submission = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/sample_submission.csv')","376e9798":"submission.target = np.hstack(predictions)\nsubmission.head(10)","6da407ae":"submission.to_csv('submission.csv',index=False)","ab559ad8":"\n# If you find this kernel interesting, please drop an UPVOTE. It motivates me to produce more quality content :)\n","8191b82c":"# Part 1","9f3ba6f5":"## Training Model\n\n","0f3da2bd":"**Trained here : https:\/\/www.kaggle.com\/mobassir\/se-resnext50-pytorch-baseline-for-bengali**","752b5cc2":"**This is a simple resnext50 baseline kernel for bengali.ai competition,i will try to gradually update this kernel**","0f1933c8":"**References**\n\n* https:\/\/www.kaggle.com\/khoongweihao\/resnet-34-pytorch-starter-kit\/data\n* https:\/\/www.kaggle.com\/hanjoonchoe\/grapheme-resnet-18-naive-learning-3","4b59fde4":"# Save Results","144906fe":"# Part 2","1813ac99":"## resnext50_32x4d Model","8923afb2":"# se_resnext50 PyTorch baseline\n\n\n- References (ResNet):\n  - https:\/\/github.com\/pytorch\/vision\/blob\/master\/torchvision\/models\/resnet.py\n  - https:\/\/arxiv.org\/pdf\/1512.03385.pdf\n  \n  \n- Acknowledgements:\n  - Original kernels: https:\/\/www.kaggle.com\/hanjoonchoe\/grapheme-resnet-18-n-l-inference-lb-0-8566 and https:\/\/www.kaggle.com\/hanjoonchoe\/grapheme-resnet-18-naive-learning-3\n  \n  \n- **Kindly upvote the kernel if you found it helpful, including the original author's!**"}}