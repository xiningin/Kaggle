{"cell_type":{"9715f490":"code","c9aea514":"code","eb9d3d2a":"code","6789a963":"code","e868e57a":"code","0b828562":"code","a38de9d9":"code","112b39ec":"code","42ef3c96":"code","c0ba55e9":"code","ea1b4c58":"code","e1e7429b":"code","f7ce6db5":"code","7430b41e":"code","6ca78949":"code","2d637da7":"code","d8687a67":"code","f30a2f94":"code","b81e9c00":"code","1d6443bf":"code","8593d4cd":"code","5ad85781":"code","2f7d3644":"code","765212a9":"code","a336e707":"code","a27f4089":"code","b30a73e0":"code","99d2754f":"code","0382f3e8":"code","effdf621":"markdown","a905c4f4":"markdown","693ad1b9":"markdown","19b23868":"markdown","5e4e499a":"markdown","5ebb14cb":"markdown","923578d2":"markdown","2eceab47":"markdown","e64b5817":"markdown","603564ca":"markdown","64852dac":"markdown","a4ec1a88":"markdown","4ade36d1":"markdown","eeffc6b4":"markdown","52051b7c":"markdown","cf5f8ecf":"markdown","b5a21d5f":"markdown","8cdff29d":"markdown","405c700a":"markdown","03ff55b4":"markdown","783b1c16":"markdown","90f787f9":"markdown","58db1916":"markdown"},"source":{"9715f490":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nimport os\nimport glob as gb\nimport cv2\nimport tensorflow as tf\nimport keras\nfrom keras.applications.vgg16 import VGG16\nfrom keras.callbacks import Callback,ModelCheckpoint,ReduceLROnPlateau,EarlyStopping","c9aea514":"### for Kaggle\ntrainpath = '..\/input\/intel-image-classification\/seg_train\/'\ntestpath = '..\/input\/intel-image-classification\/seg_test\/'\npredpath = '..\/input\/intel-image-classification\/seg_pred\/'\n\n### for Jupyter\n# trainpath = ''\n# testpath = ''\n# predpath = ''","eb9d3d2a":"for folder in  os.listdir(trainpath + 'seg_train') : \n    files = gb.glob(pathname= str( trainpath +'seg_train\/\/' + folder + '\/*.jpg'))\n    print(f'For training data , found {len(files)} in folder {folder}')","6789a963":"for folder in  os.listdir(testpath +'seg_test') : \n    files = gb.glob(pathname= str( testpath +'seg_test\/\/' + folder + '\/*.jpg'))\n    print(f'For testing data , found {len(files)} in folder {folder}')","e868e57a":"files = gb.glob(pathname= str(predpath +'seg_pred\/*.jpg'))\nprint(f'For Prediction data , found {len(files)}')","0b828562":"code = {'buildings':0 ,'forest':1,'glacier':2,'mountain':3,'sea':4,'street':5}\n\ndef getcode(n) : \n    for x , y in code.items() : \n        if n == y : \n            return x    ","a38de9d9":"size = []\nfor folder in  os.listdir(trainpath +'seg_train') : \n    files = gb.glob(pathname= str( trainpath +'seg_train\/\/' + folder + '\/*.jpg'))\n    for file in files: \n        image = plt.imread(file)\n        size.append(image.shape)\npd.Series(size).value_counts()","112b39ec":"size = []\nfor folder in  os.listdir(testpath +'seg_test') : \n    files = gb.glob(pathname= str( testpath +'seg_test\/\/' + folder + '\/*.jpg'))\n    for file in files: \n        image = plt.imread(file)\n        size.append(image.shape)\npd.Series(size).value_counts()","42ef3c96":"size = []\nfiles = gb.glob(pathname= str(predpath +'seg_pred\/*.jpg'))\nfor file in files: \n    image = plt.imread(file)\n    size.append(image.shape)\npd.Series(size).value_counts()","c0ba55e9":"s = 100","ea1b4c58":"X_train = []\ny_train = []\nfor folder in  os.listdir(trainpath +'seg_train') : \n    files = gb.glob(pathname= str( trainpath +'seg_train\/\/' + folder + '\/*.jpg'))\n    for file in files: \n        image = cv2.imread(file)\n        image_array = cv2.resize(image , (s,s))\n        X_train.append(list(image_array))\n        y_train.append(code[folder])","e1e7429b":"print(f'we have {len(X_train)} items in X_train')","f7ce6db5":"plt.figure(figsize=(20,20))\nfor n , i in enumerate(list(np.random.randint(0,len(X_train),36))) : \n    plt.subplot(6,6,n+1)\n    plt.imshow(X_train[i])   \n    plt.axis('off')\n    plt.title(getcode(y_train[i]))","7430b41e":"X_test = []\ny_test = []\nfor folder in  os.listdir(testpath +'seg_test') : \n    files = gb.glob(pathname= str(testpath + 'seg_test\/\/' + folder + '\/*.jpg'))\n    for file in files: \n        image = cv2.imread(file)\n        image_array = cv2.resize(image , (s,s))\n        X_test.append(list(image_array))\n        y_test.append(code[folder])\n        ","6ca78949":"print(f'we have {len(X_test)} items in X_test')","2d637da7":"plt.figure(figsize=(20,20))\nfor n , i in enumerate(list(np.random.randint(0,len(X_test),36))) : \n    plt.subplot(6,6,n+1)\n    plt.imshow(X_test[i])    \n    plt.axis('off')\n    plt.title(getcode(y_test[i]))","d8687a67":"X_pred = []\nfiles = gb.glob(pathname= str(predpath + 'seg_pred\/*.jpg'))\nfor file in files: \n    image = cv2.imread(file)\n    image_array = cv2.resize(image , (s,s))\n    X_pred.append(list(image_array))       ","f30a2f94":"print(f'we have {len(X_pred)} items in X_pred')","b81e9c00":"plt.figure(figsize=(20,20))\nfor n , i in enumerate(list(np.random.randint(0,len(X_pred),36))) : \n    plt.subplot(6,6,n+1)\n    plt.imshow(X_pred[i])    \n    plt.axis('off')","1d6443bf":"X_train = np.array(X_train)\nX_test = np.array(X_test)\nX_pred_array = np.array(X_pred)\ny_train = np.array(y_train)\ny_test = np.array(y_test)\n\nprint(f'X_train shape  is {X_train.shape}')\nprint(f'X_test shape  is {X_test.shape}')\nprint(f'X_pred shape  is {X_pred_array.shape}')\nprint(f'y_train shape  is {y_train.shape}')\nprint(f'y_test shape  is {y_test.shape}')","8593d4cd":"Model = keras.models.Sequential([\n        \n        keras.layers.Conv2D(250,kernel_size=(3,3),activation='relu',input_shape=(s,s,3)),\n        keras.layers.Conv2D(200,kernel_size=(3,3),activation='relu'),\n        keras.layers.MaxPool2D(4,4),\n        keras.layers.Conv2D(150,kernel_size=(3,3),activation='relu'),    \n        keras.layers.Conv2D(80,kernel_size=(3,3),activation='relu'),    \n        keras.layers.Conv2D(50,kernel_size=(3,3),activation='relu'),\n        keras.layers.MaxPool2D(4,4),\n        keras.layers.Flatten() ,    \n        keras.layers.Dense(120,activation='relu') ,    \n        keras.layers.Dense(100,activation='relu') ,    \n        keras.layers.Dense(50,activation='relu') ,        \n        keras.layers.Dropout(rate=0.5) ,            \n        keras.layers.Dense(6,activation='softmax') ,    \n        ])","5ad85781":"lrd = ReduceLROnPlateau(monitor = 'val_loss',patience = 20,verbose = 1,factor = 0.50, min_lr = 1e-10)\n\nmcp = ModelCheckpoint('model.h5')\n\nes = EarlyStopping(verbose=1, patience=20)","2f7d3644":"Model.compile(optimizer ='rmsprop',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","765212a9":"Model.summary()","a336e707":"epochs = 1\nThisModel = Model.fit(X_train, y_train, epochs=epochs,batch_size=64,verbose=1,callbacks=[lrd,mcp,es])","a27f4089":"ModelLoss, ModelAccuracy =Model.evaluate(X_test, y_test)\n\nprint('Test Loss is {}'.format(ModelLoss))\nprint('Test Accuracy is {}'.format(ModelAccuracy ))","b30a73e0":"y_pred = Model.predict(X_test)\n\nprint('Prediction Shape is {}'.format(y_pred.shape))","99d2754f":"y_result = Model.predict(X_pred_array)\n\nprint('Prediction Shape is {}'.format(y_result.shape))","0382f3e8":"plt.figure(figsize=(20,20))\nfor n , i in enumerate(list(np.random.randint(0,len(X_pred),36))) : \n    plt.subplot(6,6,n+1)\n    plt.imshow(X_pred[i])    \n    plt.axis('off')\n    plt.title(getcode(np.argmax(y_result[i])))","effdf621":"now to define the path ( to swtich it between jupyter notebook & kaggle kernel)","a905c4f4":"ok , how about the test folder","693ad1b9":"now how about the images sizes in train folder","19b23868":"_____\n\n# Checking Images\n\nnow we need to heck the images sizes , to know ow they looks like\n\nsince we have 6 categories , we first need to create a dictionary with their names & indices , also create a function to get the code back","5e4e499a":"and to show random redicted pictures & its predicting category\n","5ebb14cb":"also we have have a look to random pictures in X_train , and to adjust their title using the y value","923578d2":"ok , only 80% accuracy & can be increased by tuning the hyperparameters\n","2eceab47":"now to train the model , lets use 50 epochs now","e64b5817":"________\n\n# Building The Model \n\nnow we need to build the model to train our data\n\nfirst to convert the data into arrays using numpy","603564ca":"so how the model looks like ? ","64852dac":"# Reading Images\n\nnow it's time to read all images & convert it into arrays\n\nfirst we'll create a variable s , which refer to size , so we can change it easily \n\nlet's use now size = 100 , so it will be suitable amount to contain accuracy without losing so much time in training","a4ec1a88":"ok , since almost all of pictures are 150,150,3 , we can feel comfort in using all pictures in our model , after resizing it in a specific amount","4ade36d1":"_____\nnow for prediction folder","eeffc6b4":"\n_______\n\nnow to predict X test","52051b7c":"great\n\nnow it's time to redict X Predict","cf5f8ecf":"______\n\nok , almost all of them are 150,150,3 , how about test images ? ","b5a21d5f":"also with Prediction data , without having title ofcourse","8cdff29d":"# Open Folders\n\nnow let's first check the Train folder to have a look to its content","405c700a":"now to compile the model , using adam optimizer , & sparse categorical crossentropy loss","03ff55b4":"# Image Classification Using CNN\n\n________\n\nwe'll build a CNN using Keras to use it classifying thousands of pictures in six different categories\n\nData link : https:\/\/www.kaggle.com\/puneet6060\/intel-image-classification\n\nfirst to import libraries\n","783b1c16":"great , now to repeat same steps exactly in test data","90f787f9":"how is the final loss & accuracy\n","58db1916":"great , now how many items in X_train "}}