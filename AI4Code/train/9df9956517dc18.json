{"cell_type":{"9c654cae":"code","96a98d26":"code","31c0433c":"code","d866cce2":"code","00d5a602":"code","9f3ab0f8":"code","36f65e06":"code","93e33f26":"markdown"},"source":{"9c654cae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nfrom matplotlib import pyplot as plt #plotting and image showing\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n%matplotlib inline\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n# Any results you write to the current directory are saved as output.","96a98d26":"np.random.seed(95)\nfrom keras import backend as K\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, GlobalMaxPooling2D, Dropout\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras import regularizers as r\nfrom sklearn import metrics\n\n\ntrain_datagen = image.ImageDataGenerator(\n        rescale=1.\/255,\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\n\nvalid_datagen = image.ImageDataGenerator(rescale=1.\/255)\n\nbatch_size=32\n\ntrain_generator = train_datagen.flow_from_directory(\n        '..\/input\/10-monkey-species\/training\/training',\n        batch_size=batch_size,\n        class_mode='categorical')\n\nvalid_generator = valid_datagen.flow_from_directory(\n        '..\/input\/10-monkey-species\/validation\/validation',\n        batch_size=batch_size,\n        shuffle=False,\n        class_mode='categorical')\n\nepoch = 100\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (8,8), input_shape=(None,None,3)))\nmodel.add(LeakyReLU())\nmodel.add(Conv2D(32, (2,2),bias_regularizer=r.l2(0.)))\nmodel.add(LeakyReLU())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(64, (4,4)))\nmodel.add(LeakyReLU())\nmodel.add(Conv2D(64, (2,2),bias_regularizer=r.l2(0.)))\nmodel.add(LeakyReLU())\nmodel.add(GlobalMaxPooling2D())\nmodel.add(Dense(1024, activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(Dense(10, activation = 'softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nfilepath=str(os.getcwd()+\"\/model.h5f\")\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n# = EarlyStopping(monitor='val_acc', patience=15)\ncallbacks_list = [checkpoint]#, stopper]\n\ntrained = model.fit_generator(\n        train_generator,\n        steps_per_epoch=1097 \/\/ batch_size,\n        epochs=epoch,\n        validation_data=valid_generator,\n        validation_steps=272 \/\/ batch_size, callbacks=callbacks_list, verbose = 1)","31c0433c":"model.summary()\ndef plot_history(history):\n    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n    \n    if len(loss_list) == 0:\n        print('Loss is missing in history')\n        return \n    \n    ## As loss always exists\n    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n    \n    ## Loss\n    plt.figure(1)\n    for l in loss_list:\n        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n    for l in val_loss_list:\n        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n    \n    plt.title('Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    ## Accuracy\n    plt.figure(2)\n    for l in acc_list:\n        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n    for l in val_acc_list:    \n        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n\n    plt.title('Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.show()\n\nplot_history(trained)","d866cce2":"validation_datagenerator = image.ImageDataGenerator(\n    rescale=1. \/ 255)\ntesting_data = validation_datagenerator.flow_from_directory(\n        '..\/input\/10-monkey-species\/validation\/validation',\n        target_size=(244, 244),\n        shuffle=False,\n        batch_size = 8,\n        class_mode='categorical')\nfrom keras.models import load_model\nmodel_trained = load_model(filepath)\n\nsteps = 34\npredictions = model_trained.predict_generator(testing_data, steps=steps, verbose=1)\n\nval_preds = np.argmax(predictions, axis=1)\nval_trues = testing_data.classes\ncm = metrics.confusion_matrix(val_trues, val_preds)\nlabels = list(testing_data.class_indices.keys())\nprint(metrics.classification_report(val_trues, val_preds,target_names=labels))","00d5a602":"import itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix - training',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\nplot_confusion_matrix(cm,labels,normalize=True)","9f3ab0f8":"test_list = os.listdir(\"..\/input\/test-monkeys\/\")\ntest_list.sort()\nprint(test_list)\nmodel_test = load_model(filepath)","36f65e06":"import cv2\nimport matplotlib.image as mpimg\n\n\nd = {}\nscore_array = np.array([])\nfor i in range(10):\n    d[str(test_list[i])]=\"..\/input\/test-monkeys\/\"+str(test_list[i])\nfor i in test_list:\n    imgorg = cv2.imread(str(d[i]))\n    img = imgorg #cv2.resize(imgorg, dsize=(244, 244), interpolation=cv2.INTER_CUBIC)\n    print(type(img))\n    print(img.shape)\n    test_img = np.expand_dims(img, axis=0)\n    test_img = test_img\/255\n    print(test_img.shape)\n    score = model_trained.predict(test_img, verbose=1)\n    result = np.argmax(score, axis=1)\n    score_values = list(range(10))\n    score_dict = dict(zip(score_values,labels))\n    print('Image was classified to class: ' + '\"' + str(score_dict[int(result)]) + '\"\\nImage should be classified as \"'+str(i)[0:2]+'\"')\n    #if str(score_dict[int(result)])[1:3] == str(i)[0:2]:\n        #np.append(score_array,1,axis=1)\n    #else:\n        #np.append(score_array,1,axis=)\n#accuracy_percent = np.sum(score_array) * 100\n#print(\"Model has had \" + str(accuracy_percent) +\"% accuracy on own test dataset\")\n\ndef plot_images(test_list, dictionary):\n    for i in range(len(test_list)):\n        plt.figure(i)\n        plt.imshow(mpimg.imread(str(dictionary[test_list[i]])))\n        plt.title(test_list[i])\n    plt.show()\nplot_images(test_list,d)","93e33f26":"**Changes in version of model**\nOverall architecture of convolutional layers\nAdded dropout\nAdded bias regularization at (0.) in low stride conv layers for testing purposes\nActivation in conv layers changed to Leaky ReLu\n\n"}}