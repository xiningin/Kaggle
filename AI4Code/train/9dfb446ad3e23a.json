{"cell_type":{"f630e7df":"code","f31faf89":"code","47688543":"code","a85b03c8":"code","9c4a855a":"code","486f2947":"code","9ab1de37":"code","3465a2c0":"code","f071653f":"code","d79bb8b4":"code","0a59b335":"code","875884f4":"code","a61949a1":"code","69e67043":"code","e11fc641":"code","c1f066f6":"code","ee221370":"code","53b9168f":"code","48bfc9d9":"code","d7276570":"code","c52cca40":"code","1483c9c9":"code","94f694cc":"code","53813b2f":"code","984b5ca4":"code","28c9d851":"code","62d6cc8d":"code","c5c2e0f3":"code","b6a879b1":"code","bd265ecd":"code","e209652a":"code","77a98d3f":"code","8759972a":"code","30d6e4bc":"code","be1322f2":"code","9b013770":"code","5182dde3":"code","0a74f7f0":"code","684a127b":"code","63df7c6e":"code","29b70b87":"code","245063e9":"code","c8e224a9":"code","3c1ee8e1":"code","9ee5c9d2":"code","814b1680":"code","882ddf03":"code","bbc6e7d0":"code","2f95ca9d":"code","6a50c553":"markdown","1287c328":"markdown","bcf9a685":"markdown","aee3b4ce":"markdown","24a5071c":"markdown","b5e38f5a":"markdown","a7dbd3d9":"markdown","0ec80f43":"markdown","00bb6431":"markdown","a18e733e":"markdown","d5371d63":"markdown","2323d5c2":"markdown","9f01c977":"markdown","e1107e74":"markdown","1365b91e":"markdown"},"source":{"f630e7df":"import pandas as pd\nimport numpy as np\nimport re","f31faf89":"train_df = pd.read_csv(\"..\/input\/quora-insincere-questions-classification\/train.csv\")\nX_train = train_df[\"question_text\"].fillna(\"dieter\").values\ntest_df = pd.read_csv(\"..\/input\/quora-insincere-questions-classification\/test.csv\")\nX_test = test_df[\"question_text\"].fillna(\"dieter\").values\ny = train_df[\"target\"]\n\ntext = train_df['question_text']\n\nfor row in text[:10]:\n    print(row)","47688543":"def removeNumbers(text):\n    \"\"\" Removes integers \"\"\"\n    text = ''.join([i for i in text if not i.isdigit()])         \n    return text\n\ntext_removeNumbers = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_removeNumbers['TextBefore'] = text.copy()\n","a85b03c8":"for index, row in text_removeNumbers.iterrows():\n    row['TextAfter'] = removeNumbers(row['TextBefore'])","9c4a855a":"text_removeNumbers['Changed'] = np.where(text_removeNumbers['TextBefore']==text_removeNumbers['TextAfter'], 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_removeNumbers[text_removeNumbers['Changed']=='yes']), len(text_removeNumbers), 100*len(text_removeNumbers[text_removeNumbers['Changed']=='yes'])\/len(text_removeNumbers)))","486f2947":"for index, row in text_removeNumbers[text_removeNumbers['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","9ab1de37":"def replaceMultiExclamationMark(text):\n    \"\"\" Replaces repetitions of exlamation marks \"\"\"\n    text = re.sub(r\"(\\!)\\1+\", ' multiExclamation ', text)\n    return text\n\ndef replaceMultiQuestionMark(text):\n    \"\"\" Replaces repetitions of question marks \"\"\"\n    text = re.sub(r\"(\\?)\\1+\", ' multiQuestion ', text)\n    return text\n\ndef replaceMultiStopMark(text):\n    \"\"\" Replaces repetitions of stop marks \"\"\"\n    text = re.sub(r\"(\\.)\\1+\", ' multiStop ', text)\n    return text\n\ntext_replaceRepOfPunct = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_replaceRepOfPunct['TextBefore'] = text.copy()","3465a2c0":"for index, row in text_replaceRepOfPunct.iterrows():\n    row['TextAfter'] = replaceMultiExclamationMark(row['TextBefore'])\n    row['TextAfter'] = replaceMultiQuestionMark(row['TextBefore'])\n    row['TextAfter'] = replaceMultiStopMark(row['TextBefore'])","f071653f":"text_replaceRepOfPunct['Changed'] = np.where(text_replaceRepOfPunct['TextBefore']==text_replaceRepOfPunct['TextAfter'], 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_replaceRepOfPunct[text_replaceRepOfPunct['Changed']=='yes']), len(text_replaceRepOfPunct), 100*len(text_replaceRepOfPunct[text_replaceRepOfPunct['Changed']=='yes'])\/len(text_replaceRepOfPunct)))","d79bb8b4":"for index, row in text_replaceRepOfPunct[text_replaceRepOfPunct['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","0a59b335":"import string\ntranslator = str.maketrans('', '', string.punctuation)\ntext_removePunctuation = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_removePunctuation['TextBefore'] = text.copy()","875884f4":"for index, row in text_removePunctuation.iterrows():\n    row['TextAfter'] = row['TextBefore'].translate(translator) ","a61949a1":"text_removePunctuation['Changed'] = np.where(text_removePunctuation['TextBefore']==text_removePunctuation['TextAfter'], 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_removePunctuation[text_removePunctuation['Changed']=='yes']), len(text_removePunctuation), 100*len(text_removePunctuation[text_removePunctuation['Changed']=='yes'])\/len(text_removePunctuation)))","69e67043":"for index, row in text_removePunctuation[text_removePunctuation['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","e11fc641":"for index, row in text_removePunctuation[text_removePunctuation['Changed']=='no'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","c1f066f6":"contraction_patterns = [ (r'won\\'t', 'will not'), (r'can\\'t', 'cannot'), (r'i\\'m', 'i am'), (r'ain\\'t', 'is not'), (r'(\\w+)\\'ll', '\\g<1> will'), (r'(\\w+)n\\'t', '\\g<1> not'),\n                         (r'(\\w+)\\'ve', '\\g<1> have'), (r'(\\w+)\\'s', '\\g<1> is'), (r'(\\w+)\\'re', '\\g<1> are'), (r'(\\w+)\\'d', '\\g<1> would'), (r'&', 'and'), (r'dammit', 'damn it'), (r'dont', 'do not'), (r'wont', 'will not') ]\ndef replaceContraction(text):\n    patterns = [(re.compile(regex), repl) for (regex, repl) in contraction_patterns]\n    for (pattern, repl) in patterns:\n        (text, count) = re.subn(pattern, repl, text)\n    return text\n\ntext_replaceContractions = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_replaceContractions['TextBefore'] = text.copy()","ee221370":"for index, row in text_replaceContractions.iterrows():\n    row['TextAfter'] = replaceContraction(row['TextBefore'])","53b9168f":"text_replaceContractions['Changed'] = np.where(text_replaceContractions['TextBefore']==text_replaceContractions['TextAfter'], 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_replaceContractions[text_replaceContractions['Changed']=='yes']), len(text_replaceContractions), 100*len(text_replaceContractions[text_replaceContractions['Changed']=='yes'])\/len(text_replaceContractions)))","48bfc9d9":"for index, row in text_replaceContractions[text_replaceContractions['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","d7276570":"text_lowercase = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_lowercase['TextBefore'] = text.copy()","c52cca40":"for index, row in text_lowercase.iterrows():\n    row['TextAfter'] = row['TextBefore'].lower()","1483c9c9":"text_lowercase['Changed'] = np.where(text_lowercase['TextBefore']==text_lowercase['TextAfter'], 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_lowercase[text_lowercase['Changed']=='yes']), len(text_lowercase), 100*len(text_lowercase[text_lowercase['Changed']=='yes'])\/len(text_lowercase)))","94f694cc":"for index, row in text_lowercase[text_lowercase['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","53813b2f":"for index, row in text_lowercase[text_lowercase['Changed']=='no'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","984b5ca4":"import nltk\nfrom nltk.corpus import wordnet\n\ndef replace(word, pos=None):\n    \"\"\" Creates a set of all antonyms for the word and if there is only one antonym, it returns it \"\"\"\n    antonyms = set()\n    for syn in wordnet.synsets(word, pos=pos):\n        for lemma in syn.lemmas():\n            for antonym in lemma.antonyms():\n                antonyms.add(antonym.name())\n    if len(antonyms) == 1:\n        return antonyms.pop()\n    else:\n        return None\n\ndef replaceNegations(text):\n    \"\"\" Finds \"not\" and antonym for the next word and if found, replaces not and the next word with the antonym \"\"\"\n    i, l = 0, len(text)\n    words = []\n    while i < l:\n        word = text[i]\n        if word == 'not' and i+1 < l:\n            ant = replace(text[i+1])\n            if ant:\n                words.append(ant)\n                i += 2\n                continue\n        words.append(word)\n        i += 1\n    return words\n\ndef tokenize1(text):\n    tokens = nltk.word_tokenize(text)\n    tokens = replaceNegations(tokens)\n    text = \" \".join(tokens)\n    return text\n\ntext_replaceNegations = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_replaceNegations['TextBefore'] = text.copy()","28c9d851":"for index, row in text_replaceNegations.iterrows():\n    row['TextAfter'] = tokenize1(row['TextBefore'])","62d6cc8d":"text_replaceNegations['Changed'] = np.where(text_replaceNegations['TextBefore'].str.replace(\" \",\"\")==text_replaceNegations['TextAfter'].str.replace(\" \",\"\").str.replace(\"``\",'\"').str.replace(\"''\",'\"'), 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_replaceNegations[text_replaceNegations['Changed']=='yes']), len(text_replaceNegations), 100*len(text_replaceNegations[text_replaceNegations['Changed']=='yes'])\/len(text_replaceNegations)))","c5c2e0f3":"for index, row in text_replaceNegations[text_replaceNegations['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","b6a879b1":"def addCapTag(word):\n    \"\"\" Finds a word with at least 3 characters capitalized and adds the tag ALL_CAPS_ \"\"\"\n    if(len(re.findall(\"[A-Z]{3,}\", word))):\n        word = word.replace('\\\\', '' )\n        transformed = re.sub(\"[A-Z]{3,}\", \"ALL_CAPS_\"+word, word)\n        return transformed\n    else:\n        return word\n\ndef tokenize2(text):\n    finalTokens = []\n    tokens = nltk.word_tokenize(text)\n    for w in tokens:\n        finalTokens.append(addCapTag(w))\n    text = \" \".join(finalTokens)\n    return text\n\ntext_handleCapWords = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_handleCapWords['TextBefore'] = text.copy()","bd265ecd":"for index, row in text_handleCapWords.iterrows():\n    row['TextAfter'] = tokenize2(row['TextBefore'])","e209652a":"text_handleCapWords['Changed'] = np.where(text_handleCapWords['TextBefore'].str.replace(\" \",\"\")==text_handleCapWords['TextAfter'].str.replace(\" \",\"\").str.replace(\"``\",'\"').str.replace(\"''\",'\"'), 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_handleCapWords[text_handleCapWords['Changed']=='yes']), len(text_handleCapWords), 100*len(text_handleCapWords[text_handleCapWords['Changed']=='yes'])\/len(text_handleCapWords)))","77a98d3f":"for index, row in text_handleCapWords[text_handleCapWords['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","8759972a":"from nltk.corpus import stopwords\nstoplist = stopwords.words('english')\n\ndef tokenize(text):\n    finalTokens = []\n    tokens = nltk.word_tokenize(text)\n    for w in tokens:\n        if (w not in stoplist):\n            finalTokens.append(w)\n    text = \" \".join(finalTokens)\n    return text\n\ntext_removeStopwords = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_removeStopwords['TextBefore'] = text.copy()","30d6e4bc":"for index, row in text_removeStopwords.iterrows():\n    row['TextAfter'] = tokenize(row['TextBefore'])","be1322f2":"text_removeStopwords['Changed'] = np.where(text_removeStopwords['TextBefore'].str.replace(\" \",\"\")==text_removeStopwords['TextAfter'].str.replace(\" \",\"\").str.replace(\"``\",'\"').str.replace(\"''\",'\"'), 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_removeStopwords[text_removeStopwords['Changed']=='yes']), len(text_removeStopwords), 100*len(text_removeStopwords[text_removeStopwords['Changed']=='yes'])\/len(text_removeStopwords)))","9b013770":"for index, row in text_removeStopwords[text_removeStopwords['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","5182dde3":"def replaceElongated(word):\n    \"\"\" Replaces an elongated word with its basic form, unless the word exists in the lexicon \"\"\"\n\n    repeat_regexp = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n    repl = r'\\1\\2\\3'\n    if wordnet.synsets(word):\n        return word\n    repl_word = repeat_regexp.sub(repl, word)\n    if repl_word != word:      \n        return replaceElongated(repl_word)\n    else:       \n        return repl_word\n    \ndef tokenize(text):\n    finalTokens = []\n    tokens = nltk.word_tokenize(text)\n    for w in tokens:\n        finalTokens.append(replaceElongated(w))\n    text = \" \".join(finalTokens)\n    return text\n\ntext_removeElWords = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_removeElWords['TextBefore'] = text.copy()","0a74f7f0":"for index, row in text_removeElWords.iterrows():\n    row['TextAfter'] = tokenize(row['TextBefore'])","684a127b":"text_removeElWords['Changed'] = np.where(text_removeElWords['TextBefore'].str.replace(\" \",\"\")==text_removeElWords['TextAfter'].str.replace(\" \",\"\").str.replace(\"``\",'\"').str.replace(\"''\",'\"'), 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_removeElWords[text_removeElWords['Changed']=='yes']), len(text_removeElWords), 100*len(text_removeElWords[text_removeElWords['Changed']=='yes'])\/len(text_removeElWords)))","63df7c6e":"for index, row in text_removeElWords[text_removeElWords['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","29b70b87":"from nltk.stem.porter import PorterStemmer\nstemmer = PorterStemmer() #set stemmer\nfrom nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer() # set lemmatizer\n\ndef tokenize(text):\n    finalTokens = []\n    tokens = nltk.word_tokenize(text)\n    for w in tokens:\n        finalTokens.append(stemmer.stem(w)) # change this to lemmatizer.lemmatize(w) for Lemmatizing\n    text = \" \".join(finalTokens)\n    return text\n\ntext_stemming = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_stemming['TextBefore'] = text.copy()","245063e9":"for index, row in text_stemming.iterrows():\n    row['TextAfter'] = tokenize(row['TextBefore'])","c8e224a9":"text_stemming['Changed'] = np.where(text_stemming['TextBefore'].str.replace(\" \",\"\")==text_stemming['TextAfter'].str.replace(\" \",\"\").str.replace(\"``\",'\"').str.replace(\"''\",'\"'), 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_stemming[text_stemming['Changed']=='yes']), len(text_stemming), 100*len(text_stemming[text_stemming['Changed']=='yes'])\/len(text_stemming)))","3c1ee8e1":"for index, row in text_stemming[text_stemming['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","9ee5c9d2":"def tokenize(text):\n    finalTokens = []\n    tokens = nltk.word_tokenize(text)\n    for w in tokens:\n        if (w not in stoplist):\n            w = addCapTag(w) # Handle Capitalized Words\n            w = w.lower() # Lowercase\n            w = replaceElongated(w) # Replace Elongated Words\n            w = stemmer.stem(w) # Stemming\n            finalTokens.append(w)\n    text = \" \".join(finalTokens)\n    return text\n\ntext_combos = pd.DataFrame(columns=['TextBefore', 'TextAfter', 'Changed'])\ntext_combos['TextBefore'] = text.copy()","814b1680":"for index, row in text_combos.iterrows():\n    row['TextAfter'] = replaceContraction(row['TextBefore']) # Replace Contractions\n    row['TextAfter'] = removeNumbers(row['TextAfter']) # Remove Integers\n    row['TextAfter'] = replaceMultiExclamationMark(row['TextAfter']) # Replace Multi Exclamation Marks\n    row['TextAfter'] = replaceMultiQuestionMark(row['TextAfter']) # Replace Multi Question Marks\n    row['TextAfter'] = replaceMultiStopMark(row['TextAfter']) # Repalce Multi Stop Marks\n    row['TextAfter'] = row['TextAfter'].translate(translator) # Remove Punctuation\n    row['TextAfter'] = tokenize(row['TextAfter'])","882ddf03":"text_combos['Changed'] = np.where(text_combos['TextBefore'].str.replace(\" \",\"\")==text_combos['TextAfter'].str.replace(\" \",\"\").str.replace(\"``\",'\"').str.replace(\"''\",'\"'), 'no', 'yes')\nprint(\"{} of {} ({:.4f}%) questions have been changed.\".format(len(text_combos[text_combos['Changed']=='yes']), len(text_combos), 100*len(text_combos[text_combos['Changed']=='yes'])\/len(text_combos)))","bbc6e7d0":"for index, row in text_combos[text_combos['Changed']=='yes'].head().iterrows():\n    print(row['TextBefore'],'->',row['TextAfter'])","2f95ca9d":"runs, running, ran ===> run(lemma)","6a50c553":"## 7. Handle Capitalized Words\n**Example:** Which is better to use, Avro or ORC? -> Which is better to use , Avro or ALL_CAPS_ORC ?","1287c328":"## 1. Remove Numbers\n**Example:** Which is best powerbank for iPhone 7 in India? -> Which is best powerbank for iPhone  in India?","bcf9a685":"Some question are written only in lowercase. This happens when they start with a number.","aee3b4ce":"## Load Dataset and print some questions","24a5071c":"## 10. Stemming\/Lemmatizing\n**Example:** How do modern military submarines reduce noise to achieve stealth? -> how do modern militari submarin reduc nois to achiev stealth ?","b5e38f5a":"## 3. Remove Punctuation\n**Example:** Why haven't two democracies never ever went for a full fledged war? What stops them? -> Why havent two democracies never ever went for a full fledged war What stops them","a7dbd3d9":"## 5. Lowercase\n**Example:** What do you know about Bram Fischer and the Rivonia Trial? -> what do you know about bram fischer and the rivonia trial?","0ec80f43":"## 6. Replace Negations with Antonyms\n**Example:** Why are humans not able to be evolved developing resistance against diseases? -> Why are humans unable to be evolved developing resistance against diseases ?","00bb6431":"## 8. Remove Stopwords\n**Example:** The movie was not good at all. -> movie good","a18e733e":"## 4. Replace Contractions\nThis techniques replaces contractions to their equivalents.\n\n**Example:** What's the scariest thing that ever happened to anyone? -> What is the scariest thing that ever happened to anyone?","d5371d63":"Thank you ","2323d5c2":"I expected everything to change, because they are question with \"?\". Let's see the ones that didn't change.","9f01c977":"## 9. Replace Elongated Words\nThis technique replaces an elongated word with its basic form, unless the word exists in the lexicon.\n\n**Example:** Game of Thrones, what does Arya find out about Littlefinger? -> Game of Thrones , what does Arya find out about Litlefinger ?","e1107e74":"## Combos\nOf course we can use more than one technique at the same time. The order is essential here.\n\n**Example:** What are the recommended 2D game engines for a beginning Python programmer? -> what recommend d game engin begin python programm","1365b91e":"## 2. Replace Repetitions of Punctuation\nThis technique:\n - replaces repetitions of exlamation marks with the tag \"multiExclamation\"\n - replaces repetitions of question marks with the tag \"multiQuestion\"\n - replaces repetitions of stop marks with the tag \"multiStop\"\n \n **Example:** How do I overcome the fear of facing an interview? It's killing me inside..what should I do? -> How do I overcome the fear of facing an interview? It's killing me inside multiStop what should I do?"}}