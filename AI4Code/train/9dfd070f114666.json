{"cell_type":{"e9b2c90a":"code","f6cda33d":"code","82fc93c2":"code","d650e0a5":"code","d53b9e6e":"code","4cbcc860":"code","4419790e":"code","eed47be7":"code","da3e377c":"code","7a51d148":"code","6a4f8216":"code","ed575f18":"code","07881e1e":"code","09542234":"code","486573b5":"code","62183ad9":"markdown","d88d3b4f":"markdown","407fb8d6":"markdown","c3125f0a":"markdown","3a3fb8d4":"markdown","c0af0482":"markdown","21188e80":"markdown","13e44fb1":"markdown","034662b0":"markdown","01125bc6":"markdown","c3e27d37":"markdown"},"source":{"e9b2c90a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n# set the random_seed to reproduce our work\ntf.random.set_seed(13)\n# load data\ndata = pd.read_csv(\"..\/input\/ece657aw20asg4coronavirus\/time_series_covid19_confirmed_global.csv\")","f6cda33d":"data = data.fillna(0)\ndata = data[data['Province\/State']==0]\nglobal_data = data.sum()[4:].reset_index()\nglobal_data.columns=['date','number']\nglobal_data['date'] = global_data['date'].map(lambda x:str(x)[:-3])\nall_data = global_data['number']\nall_data.index = global_data['date']\nglobal_data","82fc93c2":"all_data.plot(color='black')\nplt.title(\"Global comfirmed number\")\nplt.show()","d650e0a5":"TRAIN_SPLIT = 70\nall_data = all_data.values\ntrain_mean = all_data[:TRAIN_SPLIT].mean()\ntrain_std = all_data[:TRAIN_SPLIT].std()","d53b9e6e":"def normalize(target):\n    return (target-train_mean)\/train_std\n\ndef recover(target):\n    return target*train_std + train_mean","4cbcc860":"all_data = normalize(all_data)","4419790e":"def split_data(dataset, start_index, end_index, history_size, target_size):\n    data = []\n    labels = []\n    \n    start_index = start_index + history_size\n    if end_index is None:\n        end_index = len(dataset) - target_size\n    \n    for i in range(start_index, end_index):\n        indices = range(i-history_size,i)\n        data.append(np.reshape(dataset[indices],(history_size,1)))\n        labels.append(dataset[i+target_size])\n    return np.array(data,dtype=np.float),np.array(labels,dtype=np.float)","eed47be7":"x_train,y_train = split_data(all_data,0,TRAIN_SPLIT,7,0)\nx_val,y_val = split_data(all_data, TRAIN_SPLIT, None, 7,0)","da3e377c":"BATCH_SIZE = 256\nBUFFER_SIZE = 10000\n\ntrain_univariate = tf.data.Dataset.from_tensor_slices((x_train, y_train))\ntrain_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n\nval_univariate = tf.data.Dataset.from_tensor_slices((x_val, y_val))\nval_univariate = val_univariate.batch(BATCH_SIZE).repeat()","7a51d148":"simple_lstm_model = tf.keras.models.Sequential([\n    tf.keras.layers.LSTM(50, input_shape=x_train.shape[-2:],activation='relu'),\n    tf.keras.layers.Dense(1)\n])\n\nsimple_lstm_model.compile(optimizer='adam', loss='mae')","6a4f8216":"EPOCHS = 5\nhistory = simple_lstm_model.fit(train_univariate, epochs=EPOCHS,\n                      steps_per_epoch=200,\n                      validation_data=val_univariate, validation_steps=50, verbose=1)","ed575f18":"epochs = list(range(EPOCHS))\nplt.plot(epochs,history.history['loss'],label='loss',color='black',linestyle='--',linewidth=1)\nplt.plot(epochs,history.history['val_loss'],label='val_loss',color='black',linestyle='-',linewidth=1)\nplt.title(\"Loss during fitting\")\nplt.legend()\nplt.show()","07881e1e":"def makeprediction(sevendays):\n    sample = np.array(sevendays, dtype=np.float)\n    sample = np.reshape(sample,(1,7,1))\n    return int(recover(simple_lstm_model.predict(sample))[0][0])","09542234":"predictions = []\nfor i in range(50,79):\n    sample = all_data[i:(i+7)]\n    predictions.append(makeprediction(sample))","486573b5":"predictions = pd.DataFrame(data=predictions,columns=['number'],index=range(58,87))\nplt.plot(global_data.index,global_data['number'],label='actual data',color='black',linestyle='-',linewidth=1)\nplt.scatter(predictions.index,predictions['number'],label='predict data',color='black',marker='.',linewidth=1)\nplt.title(\"Global confirmed number after 1\/22\")\nplt.legend()\nplt.show()","62183ad9":"A Recurrent Neural Network (RNN) is a type of neural network well-suited to time series data. RNNs process a time series step-by-step, maintaining an internal state summarizing the information they've seen so far. And in this assignment we use the simple LSTM model to predict the global confirmed case. ","d88d3b4f":"It can be oberved from the plot that the predicted number are growing rapidly using the the simple LSTM model.","407fb8d6":"**1. Getting Data**\n\nFisrt, we import the data and extract the daily global confirmed cases from the data.","c3125f0a":"We remove all the provinces number and add up all the confirmed cases and get the global data as follows.","3a3fb8d4":"**4. Fit the model**","c0af0482":"**2. Normalization**\n\nWe do a z-score normalization to the data and define a recover function to get the original data.","21188e80":"Define a function to get the corresponding data and label","13e44fb1":"**5.Make predictions**\n\nUse the 7 days before the date to make prediction and recursively make the whole prediction. Plot the predictions and the actual data as follows.","034662b0":"We split the data into train and test set, where train set is the global confirmed number from 1\/22 to 3\/31 and test set is from 4\/1 to 4\/17.","01125bc6":"**3.Construct LSTM model**\n\nWe select parameter of units=50,activation='tanh', activation='tanh',optimizer='adam' on the LSTM model.","c3e27d37":"# Global Confirmed Case Prediction\nby Zixuan Jin(z77jin), Ran Zang(rzang)\n"}}