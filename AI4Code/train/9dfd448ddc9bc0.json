{"cell_type":{"6230a78a":"code","9f81e0b4":"code","ea8c2eea":"code","b2680b82":"code","46297580":"code","4661e04c":"code","cdadc792":"code","83dc686a":"code","3d94e404":"code","07574e67":"code","1dcecafa":"code","5d78c35e":"code","882e950b":"code","f964a5df":"code","14fe3636":"code","7a14f4de":"code","89361965":"code","596c664a":"code","dfbf5eb3":"code","8773057b":"code","d33e4cce":"code","81a3c376":"code","a4af09fe":"code","ce0046ad":"code","8527d94e":"code","01e552ff":"code","7de71bf8":"code","343908a7":"code","2c6135cb":"code","03dfb5e7":"code","d9a960ee":"code","6bfc888d":"code","05ccdd57":"code","538ca2c9":"code","42351202":"code","09f22348":"code","72c2d2ae":"code","19f250bb":"code","8fb04a62":"code","3f97894b":"code","1a24c86d":"code","aa017fec":"code","39e6d7d4":"code","f1db8f08":"code","7e619518":"code","39c712e5":"code","72aa3ff4":"code","225370b6":"code","47363239":"code","f41946a8":"code","8c7831d3":"code","fbc5930c":"code","2f51ce3d":"code","24a2fc32":"code","96daea3e":"code","701474b6":"code","b46df1ac":"code","71269f9d":"code","74f46b36":"code","8a6b871c":"code","ebe69e36":"code","50f2e4b5":"code","747b7ec4":"code","cf06fc85":"code","d45661e1":"code","72d2cd3e":"code","f366fcd6":"code","3d7d782c":"code","c23e40b3":"code","1b80aeaa":"code","e1c67d51":"code","cd702560":"code","9627f727":"code","17b4b2ba":"code","aec3e293":"code","388eaeb7":"code","f58b6648":"code","fdeab318":"code","d00d3a31":"code","3d5e5492":"code","da7ed1d6":"code","6fe5b592":"markdown","803a93c0":"markdown","2f3009b1":"markdown","b3fc8136":"markdown","cba34cb0":"markdown","c9511448":"markdown","2941380b":"markdown","d826ffc9":"markdown","3f532ad7":"markdown","775baad6":"markdown","c080217d":"markdown","ecaf50a8":"markdown","69225b48":"markdown","b6ade734":"markdown","9cb1acba":"markdown","354787de":"markdown","6a763cd0":"markdown","78c7b9af":"markdown","109dbf4f":"markdown"},"source":{"6230a78a":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math\nsns.set(context=\"notebook\", style=\"darkgrid\", palette=\"deep\", font=\"sans- serif\", font_scale=0.7, color_codes=True)\n","9f81e0b4":"import pandas as pd\nTitanic_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nTitanic_train = pd.read_csv(\"..\/input\/titanic\/train.csv\")","ea8c2eea":"Titanic_train.head()","b2680b82":"Titanic_train.shape","46297580":"Titanic_test.head()","4661e04c":"Titanic_test.shape","cdadc792":"##Droping some columns which are not going to help in predictions\nTitanic_train[\"familySize\"] = Titanic_train[\"SibSp\"]+Titanic_train[\"Parch\"]+1\nTitanic_1 = Titanic_train.drop([\"Ticket\",\"Name\",\"Cabin\",\"SibSp\",\"Parch\"],axis = 1)\n","83dc686a":"table = pd.crosstab(Titanic_1[\"Survived\"],Titanic_1[\"Sex\"])\ntable","3d94e404":"Titanic_1.groupby('Sex').Survived.mean()","07574e67":"Titanic_1.groupby('Pclass').Survived.mean()","1dcecafa":"Titanic_1.groupby(['Pclass','Sex']).mean()","5d78c35e":"Titanic_1.groupby(['Pclass','Sex']).mean()[\"Survived\"].plot.bar()","882e950b":"def bar_chart(features):\n    survived = Titanic_1[Titanic_1['Survived']==1][features].value_counts()\n    Dead = Titanic_1[Titanic_1['Survived']==0][features].value_counts()\n    df = pd.DataFrame([survived,Dead])\n    df.index = [\"survived\",\"Dead\"]\n    df.plot(kind=\"bar\",stacked=True,figsize=(10,5))\nbar_chart(\"Sex\")   ","f964a5df":"bar_chart(\"Pclass\") ","14fe3636":"bar_chart(\"Embarked\") ","7a14f4de":"bar_chart(\"familySize\")","89361965":"facet = sns.FacetGrid(Titanic_1,hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,\"Age\",shade=True)\nfacet.add_legend()","596c664a":"facet = sns.FacetGrid(Titanic_1,hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,\"Pclass\",shade=True)\nfacet.add_legend()","dfbf5eb3":"facet = sns.FacetGrid(Titanic_1,hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,\"familySize\",shade=True)\nfacet.add_legend()","8773057b":"Pclass1 = Titanic_1[Titanic_1[\"Pclass\"]==1]['Embarked'].value_counts()\nPclass2 = Titanic_1[Titanic_1[\"Pclass\"]==2]['Embarked'].value_counts()\nPclass3 = Titanic_1[Titanic_1[\"Pclass\"]==3]['Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1,Pclass2,Pclass3])\ndf.index = [\"1st class\",\"2nd class\",\"3rd class\"]\n","d33e4cce":"df.head()","81a3c376":"df.plot(kind=\"bar\",stacked=True)","a4af09fe":"sns.countplot(x=\"Survived\",data=Titanic_1)","ce0046ad":"sns.countplot(x=\"Survived\",data=Titanic_1,hue=\"Sex\")","8527d94e":"sns.countplot(x=\"Survived\",data=Titanic_1,hue=\"Pclass\")","01e552ff":"sns.countplot(x=\"Age\",data=Titanic_1,hue=\"Survived\")","7de71bf8":"sns.countplot(x=\"Survived\",data=Titanic_1,hue=\"Embarked\")","343908a7":"sns.countplot(x=\"familySize\",data=Titanic_1,hue=\"Survived\")","2c6135cb":"sns.factorplot('Embarked',data=Titanic_1,hue='Pclass',kind='count')","03dfb5e7":"sns.boxplot(x=\"Pclass\",y=\"Age\",data=Titanic_1)","d9a960ee":"FacetGrid = sns.FacetGrid(Titanic_1, row='Embarked', size=4.5, aspect=1.6)\nFacetGrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette=None,  order=None, hue_order=None )\nFacetGrid.add_legend()","6bfc888d":"grid = sns.FacetGrid(Titanic_1, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()\n","05ccdd57":"sns.barplot(x='Pclass', y='Survived', data=Titanic_1)","538ca2c9":"Titanic_1[\"Age\"].plot.hist(color='red')","42351202":"Titanic_1[\"Fare\"].plot.hist(color='red',bins=40)","09f22348":"Titanic_1.info()","72c2d2ae":"Titanic_1.describe(include=\"all\")","19f250bb":"Titanic_1.isnull().sum()","8fb04a62":"sns.heatmap(Titanic_1.isnull(),cmap=\"viridis\")","3f97894b":"##Replacing null values by mean\nTitanic_1[\"Age\"].fillna(29.69,inplace=True)","1a24c86d":"##Replacing null values by mode\ncommon_value = \"S\"\ndata = [Titanic_1]\nfor dataset in data:\n    dataset['Embarked'] = dataset['Embarked'].fillna(common_value)\nsns.heatmap(Titanic_1.isnull(),cmap=\"viridis\")","aa017fec":"## Coverting categorical columns into dummies\nPC1 = pd.get_dummies(Titanic_1['Sex'],drop_first=True)\nPC2 = pd.get_dummies(Titanic_1['Embarked'],drop_first=True)\nPC3 = pd.get_dummies(Titanic_1['Pclass'],drop_first=True)\n##Adding dummies columns in dataset\nTitanic_1  = pd.concat([Titanic_1,PC1,PC2,PC3],axis=1)\n## Droping columns which has been created into dummies \nTitanic_1  = Titanic_1.drop([\"Sex\",\"Embarked\",\"Pclass\"],axis=1)","39e6d7d4":"Titanic_1.columns","f1db8f08":"Titanic_1.head()","7e619518":"## train_test\nX_train = Titanic_1.drop([\"Survived\"],axis=1) ##Input\ny_train = Titanic_1[\"Survived\"] ##Output","39c712e5":"Titanic_test[\"familySize\"] = Titanic_test[\"SibSp\"]+Titanic_test[\"Parch\"]+1\nTitanic_2 = Titanic_test.drop([\"Ticket\",\"Name\",\"Cabin\",\"SibSp\",\"Parch\"],axis = 1)\n","72aa3ff4":"Titanic_2.info()","225370b6":"Titanic_2.describe()","47363239":"Titanic_2.isnull().sum()","f41946a8":"sns.heatmap(Titanic_2.isnull(),cmap=\"viridis\")","8c7831d3":"##Replacing null values by mean\nTitanic_2[\"Age\"].fillna(30.27,inplace=True)\nTitanic_2[\"Fare\"].fillna(35.62,inplace=True)","fbc5930c":"sns.heatmap(Titanic_2.isnull(),cmap=\"viridis\")","2f51ce3d":"## Coverting categorical columns in dummies\nPC4 = pd.get_dummies(Titanic_2['Sex'],drop_first=True)\nPC5 = pd.get_dummies(Titanic_2['Embarked'],drop_first=True)\nPC6 = pd.get_dummies(Titanic_2['Pclass'],drop_first=True)\n##Adding dummies columns in dataset\nTitanic_2  = pd.concat([Titanic_2,PC4,PC5,PC6],axis=1)\n## Droping columns which has been created into dummies \nTitanic_2  = Titanic_2.drop([\"Sex\",\"Embarked\",\"Pclass\"],axis=1)","24a2fc32":"Titanic_2.head()","96daea3e":"X_test = Titanic_2","701474b6":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nlogmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)","b46df1ac":"pred_train = logmodel.predict(X_train)\naccuracy_score(pred_train,y_train)","71269f9d":"confusion_matrix(pred_train,y_train)","74f46b36":"classification_report(pred_train,y_train)\n","8a6b871c":"pred_test = logmodel.predict(X_test)","ebe69e36":"Result_with_logistic = pd.concat([X_test.PassengerId],axis=1)\nResult_with_logistic['Survived'] = pred_test","50f2e4b5":"Result_with_logistic","747b7ec4":"## ADABOOST CLASSIFIER\nfrom sklearn.ensemble import AdaBoostClassifier\nmodel_log = logmodel\nAdaboost_log =  AdaBoostClassifier(base_estimator=model_log ,n_estimators=400,learning_rate=1)\nboostmodel_log =Adaboost_log.fit(X_train,y_train)\nboost_pred_log = boostmodel_log.predict(X_test)\nboost_pred_log_train = boostmodel_log.predict(X_train)\naccuracy_score(boost_pred_log_train,y_train) ","cf06fc85":"confusion_matrix(boost_pred_log_train,y_train)","d45661e1":"classification_report(boost_pred_log_train,y_train)","72d2cd3e":"Result_with_ADABOOST = pd.concat([X_test.PassengerId],axis=1)\nResult_with_ADABOOST['Survived'] = boost_pred_log\nResult_with_ADABOOST","f366fcd6":"##Other classifications techniques  \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10,shuffle=True,random_state=True)","3d7d782c":"##KNN\nclf = KNeighborsClassifier(n_neighbors=13)\nscoring = \"accuracy\"\nscore = cross_val_score(clf,X_train,y_train,cv = k_fold,n_jobs=1,scoring=scoring)\nprint(score)\nround(np.mean(score)*100,2)  ##63.75%\n","c23e40b3":"##Decision tree\nclf = DecisionTreeClassifier()\nscoring = \"accuracy\"\nscore = cross_val_score(clf,X_train,y_train,cv = k_fold,n_jobs=1,scoring=scoring)\nprint(score)\nround(np.mean(score)*100,2)   \n\n","1b80aeaa":"## Improving decision tree result\nmodel_D = DecisionTreeClassifier(criterion=\"entropy\",max_depth=1)\nAdaboost =  AdaBoostClassifier(base_estimator=model_D,n_estimators=400,learning_rate=1)\nboostmodel = Adaboost.fit(X_train,y_train)\nboost_pred = boostmodel.predict(X_test)\nboost_pred_train = boostmodel.predict(X_train)\naccuracy_score(boost_pred_train,y_train)   ### 87.65\n","e1c67d51":"##Random forest\nclf = RandomForestClassifier(n_estimators=13)\nscoring = \"accuracy\"\nscore = cross_val_score(clf,X_train,y_train,cv = k_fold,n_jobs=1,scoring=scoring)\nprint(score)\nround(np.mean(score)*100,2) ","cd702560":"##Naive Bayes\nclf = GaussianNB()\nscoring = \"accuracy\"\nscore = cross_val_score(clf,X_train,y_train,cv = k_fold,n_jobs=1,scoring=scoring)\nprint(score)\nround(np.mean(score)*100,2)   ##78.12%\n","9627f727":"##SVM\nclf = SVC()\nscoring = \"accuracy\"\nscore = cross_val_score(clf,X_train,y_train,cv = k_fold,n_jobs=1,scoring=scoring)\nprint(score)\nround(np.mean(score)*100,2)   ","17b4b2ba":"###### XGBOOST ##########\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nparams = {\"learning_rate\":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\"max_depth\":[1,2,3,4,5,6,8,9,10],\"min_child_weight\":[1,2,3,4,5,6,7,8,9],\"gamma\":[0.0,0.1,0.2,0.3,0.4,0.5],\"colsample_bytree\":[0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\"n_estimators\":[100,200,300,400,500]}\nclassifier = XGBClassifier()\nrandom_search = RandomizedSearchCV(classifier,param_distributions=params,n_iter=10,scoring=\"roc_auc\",n_jobs=-1,cv=5,verbose=3)\nrandom_search.fit(X_train,y_train)\nrandom_search.best_estimator_","aec3e293":"XGB = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.5, gamma=0.2,\n              learning_rate=0.1, max_delta_step=0, max_depth=5,\n              min_child_weight=1, missing=None, n_estimators=200, n_jobs=1,\n              nthread=None, objective='binary:logistic', random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n              silent=None, subsample=1, verbosity=1)\n","388eaeb7":"XGB_fit = XGB.fit(X_train,y_train)\nXGB_pred = XGB.predict(X_test)\nXGB_pred_train = XGB.predict(X_train)\naccuracy_score(XGB_pred_train,y_train) ","f58b6648":"confusion_matrix(XGB_pred_train,y_train)","fdeab318":"classification_report(XGB_pred_train,y_train)","d00d3a31":"#ROC curve for training dataset\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfpr, tpr, thresholds = roc_curve(XGB_pred_train,y_train)\nroc_auc = roc_auc_score(XGB_pred_train,y_train)\nplt.figure()\nplt.plot(fpr, tpr, label = 'Logistic Regression Sensitivity = %0.3f' % roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('FALSE POSITIVE RATE')\nplt.ylabel('TRUE POSITIVE RATE')\nplt.title('ROC curve for train data')\nplt.legend(loc=\"lower Right\")\nplt.show()","3d5e5492":"Result_with_XGBOOST = pd.concat([X_test.PassengerId],axis=1)\nResult_with_XGBOOST['Survived'] = XGB_pred\nResult_with_XGBOOST","da7ed1d6":"Result_with_XGBOOST.to_csv(\"Submission_With_XGBOOST.csv\",index=False)","6fe5b592":"<a id='Exploratory Data Analysis'><\/a>\nExploratory Data Analysis","803a93c0":"<a id='Data'><\/a>\n# **Data**","2f3009b1":"# Predictions with Multiple Algorithms","b3fc8136":"<a id=\"Decision Tree\"><\/a>\nDecision Tree","cba34cb0":"<a id = \"Adaboost Classifier\"><\/a>\n**ADABOOST CLASSIFIER**","c9511448":"<a id=\"Model Building\"><\/a>\nModel Building","2941380b":"<a id=\"Feature Engineering\"><\/a>\nFeature Engineering","d826ffc9":"<a id=\"KNN\"><\/a>\nKNN","3f532ad7":"<a id=\"Output File Submission\"><\/a>\n# Output File Submission","775baad6":"<a id=\"Logistic Regression\"><\/a>\n**Logistic Regression**","c080217d":"<a id = \"SVM\"><\/a>\nSVM","ecaf50a8":"<a id='Libraries'><\/a>\n# **Libraries**","69225b48":"<a id=\"Random Forest\"><\/a>\nRandom Forest","b6ade734":"![image.png](attachment:image.png)","9cb1acba":"# **Table of Contents :**\n* [Libraries](#Libraries)\n* [Data](#Data)\n* [Exploratory Data Analysis](#Exploratory Data Analysis)\n* [Visualizations](#Visualizations)\n* [Feature Engineering](#Feature Engineering)\n* [Model Building](#Model Building)\n  *   [Logistic Regression](#Logistic Regression)\n  *   [Adaboost Classifier](#Adaboost Classifier)\n  *   [KNN](#KNN)\n  *   [Decision Tree](#Decision Tree)\n  *   [Random Forest](#Random Forest)\n  *   [Naive Bayes](#Naive Bayes)\n  *   [SVM](#SVM)\n  *   [XGBOOST](#XGBOOST)\n* [Output File Submission](#Output File Submission)\n\n","354787de":"<a id = \"Visualizations\"><\/a>\n# **Visualizations**","6a763cd0":"<a id=\"Naive Bayes\"><\/a>\nNaive Bayes","78c7b9af":"<a id=\"XGBOOST\"><\/a>\nXGBOOST","109dbf4f":"As you can see in above code that I tried with almost 10 algorithms and I found that XGBOOST was giving the best result.\nSo we will go with XGBOOST result.\nFinal accuracy of training dataset is 95%."}}