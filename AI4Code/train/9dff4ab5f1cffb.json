{"cell_type":{"e91e858d":"code","2f9c7229":"code","87b8d5a6":"code","d81c44fe":"code","9e8bc881":"code","829cefea":"code","eb23410b":"code","dbb8cdc2":"code","542ace14":"code","429fdf8f":"code","4e8a399e":"code","cf6a0d7e":"code","6416f2d0":"code","711f0c1f":"code","12bb2116":"code","f257c081":"code","a47dcd2f":"code","8a31ebec":"code","9b98b9b3":"code","2e2efb73":"code","cd6543dc":"code","a7100d39":"code","57a1b560":"code","060a8da9":"code","0a5a2839":"code","dab74baa":"code","a2bf6a0f":"code","dd4be4fc":"code","f8a62e69":"code","224917ba":"code","0936ac96":"code","0b07879e":"code","8d82a3ee":"code","391f9c5e":"code","3693d706":"code","017b05f1":"code","d2f893b1":"code","0155096f":"code","673a9d96":"code","cdd6d3c3":"code","784c1cea":"code","fd2ece8f":"code","ca5b5752":"code","6859f309":"code","af8e7ebb":"code","abc1a175":"code","d9a874e9":"code","34d3825f":"code","70caf249":"code","3547a6a8":"code","e672ecf4":"code","7d3d1b01":"code","da74957b":"markdown","41c561eb":"markdown","9a6c93d9":"markdown","20dc3fde":"markdown","89c46e38":"markdown","48304067":"markdown","ad4a0846":"markdown","28de52ca":"markdown","5c14b898":"markdown","23967e16":"markdown","a5501866":"markdown","c86c0feb":"markdown","421283d9":"markdown","b43b8d23":"markdown","396e829f":"markdown","dec0ba2c":"markdown","cb287c52":"markdown","261a8e62":"markdown","a20d6ea9":"markdown","df0d06c7":"markdown","53f16cae":"markdown","135de019":"markdown","5c5d6b11":"markdown","36dccfe6":"markdown","e3beb930":"markdown","3566eaa7":"markdown","2b4711b8":"markdown","5378027b":"markdown","090c03fe":"markdown","790c499d":"markdown","f5e482cd":"markdown","0264c6d5":"markdown"},"source":{"e91e858d":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n\nwarnings.filterwarnings('ignore')\n%matplotlib inline","2f9c7229":"weather_df = pd.read_csv(\"..\/input\/szeged-weather\/weatherHistory.csv\")","87b8d5a6":"weather_df.head()","d81c44fe":"# Features\nweather_df.columns","9e8bc881":"weather_df.info()","829cefea":"weather_df.isna().sum() ","eb23410b":"plt.figure(figsize=[10,5])\nsns.heatmap(weather_df.corr(), annot=True)","dbb8cdc2":"weather_df.describe()","542ace14":"category_features = [feature for feature in weather_df.columns if weather_df[feature].dtype == \"object\"]\ncategory_features","429fdf8f":"# weather_df[\"Formatted Date\"].dt.year\n# pd.DatetimeIndex(weather_df[\"Formatted Date\"]).year","4e8a399e":"# Function to parse year out of a string\ndef year(sample):\n    return sample.split(\"-\")[0]","cf6a0d7e":"# Testing Function\nyear(\"2006-04-01 00:00:00.000 +0200\")","6416f2d0":"# Applying function to Formatted Date column and storing results in another column\nweather_df[\"Year\"] = weather_df[\"Formatted Date\"].apply(lambda x: year(x))","711f0c1f":"weather_df[[\"Formatted Date\", \"Year\"]].sample(5)","12bb2116":"weather_df[\"Summary\"].value_counts()","f257c081":"weather_df[\"Precip Type\"].value_counts()","a47dcd2f":"weather_df[\"Daily Summary\"].nunique()","8a31ebec":"weather_df[\"Daily Summary\"].value_counts()","9b98b9b3":"weather_df.drop(\"Daily Summary\", axis=1, inplace=True)","2e2efb73":"weather_df.isna().sum() ","cd6543dc":"# Importing imputer\nfrom sklearn.impute import SimpleImputer ","a7100d39":"# Initializing Imputer and setting most frequent as strategy\nimputer = SimpleImputer(strategy=\"most_frequent\")","57a1b560":"# finding mode value and filling missing data with mode\nweather_df[\"Precip Type\"] = imputer.fit_transform(weather_df[[\"Precip Type\"]])","060a8da9":"weather_df.isna().sum() ","0a5a2839":"# Importing OneHotEncoder to encode norminal categorical values\nfrom sklearn.preprocessing import OneHotEncoder","dab74baa":"encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')","a2bf6a0f":"# Fitting Encoded data\nencoder.fit(weather_df[[\"Summary\", \"Precip Type\"]])","dd4be4fc":"# List of Encoded Categories\nencoder.categories_","f8a62e69":"# Appending Feature name to respective encoded values\nencoded_cols = list(encoder.get_feature_names([\"Summary\", \"Precip Type\"]))\n# print(encoded_cols)","224917ba":"# Adding encoded features to dataset\nweather_df[encoded_cols] = encoder.transform(weather_df[[\"Summary\", \"Precip Type\"]])","0936ac96":"weather_df.head()","0b07879e":"## Counting values based on year recorded\nweather_df[\"Year\"].value_counts()","8d82a3ee":"weather_df[\"Year\"].dtype","391f9c5e":"weather_df[\"Year\"] = weather_df[\"Year\"].astype(\"int64\")","3693d706":"weather_df[\"Year\"].dtype","017b05f1":"train_df = weather_df[weather_df[\"Year\"] < 2016]\ntest_df = weather_df[weather_df[\"Year\"] == 2016]","d2f893b1":"train_df.drop([\"Formatted Date\", \"Summary\", \"Precip Type\", \"Loud Cover\",\"Year\"], axis=1, inplace=True)\ntest_df.drop([\"Formatted Date\", \"Summary\", \"Precip Type\", \"Loud Cover\",\"Year\"], axis=1, inplace=True)","0155096f":"X_train = train_df.drop(\"Apparent Temperature (C)\", axis=1)\ny_train = train_df[\"Apparent Temperature (C)\"]","673a9d96":"X_test = test_df.drop(\"Apparent Temperature (C)\", axis=1)\ny_test = test_df[\"Apparent Temperature (C)\"]","cdd6d3c3":"from sklearn.linear_model import LinearRegression","784c1cea":"model = LinearRegression()","fd2ece8f":"model.fit(X_train, y_train)","ca5b5752":"# Storring Coefficients to Dataframe\ncoefficient = pd.DataFrame({\n    \"Coef\": model.coef_\n},\nindex = X_train.columns\n)","6859f309":"coefficient","af8e7ebb":"# Intercept\nmodel.intercept_","abc1a175":"predictions = model.predict(X_test)","d9a874e9":"# Storing Targets and predictions to compare values\ncompare_df = pd.DataFrame({\n    \"Target\" : y_test,\n    \"Prediction\" : predictions\n})","34d3825f":"compare_df.sample(10)","70caf249":"# Importing Metrics\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport numpy as np","3547a6a8":"#RMSE\nrmse = np.sqrt(mean_squared_error(y_test, predictions))\nprint(f\"The RMSE of our model is {rmse:.4f}\")","e672ecf4":"# R2 Score\nr2 = r2_score(y_test, predictions)\nprint(f\"The r2 score of our model is {rmse * 100:.2f} %\")","7d3d1b01":"plt.figure(figsize=[12,8])\nsns.scatterplot(y_test, predictions)","da74957b":"As we can see below, the predcitions we off by a little bit, let's check the performance of the model to know how much loss we encontered","41c561eb":"Now unto the **Summary** feature, we would encoded this values ","9a6c93d9":"### Model Build\n\n#### Train \/ Test Data Split\nWe are going to split the data based on the year the samples were recorded, the method I'm using is not the most prefered, but since we couldn't parse our data using the datetime function we would use this method","20dc3fde":"### Import Dataset\n\nWe first would import the necessary libraries we need at the moment, we will import others as when they are needed","89c46e38":"Now let's explore our categorical features","48304067":"The Year feature is still a string so we would need to convert it into a number data type","ad4a0846":"Importing dataset","28de52ca":"We got a positive correlated trend, so our model did quite well","5c14b898":"Checking subset of the data","23967e16":"The Year column would be usefull when spliting the data (assuming Time Series data), we would come back to this later","a5501866":"From the data provided above, I suspect that Temperature, Humidity, Wind Speed contain outliers and it seems LoudCover doesn't have any other value than zero","c86c0feb":"Seperating targets from features","421283d9":"Let's check the correlation of the features to the target below","b43b8d23":"We have a loss of **0.9886**, which is quite small so our model did quite well, let us check the score of our model","396e829f":"We got a score of **98.86 %**, which was how accurate our model was\n___\n\nLet's compare our predicitions against our targets to see if we got a correlated trend","dec0ba2c":"From the information provided below, we can see that only **Precip Type** has missing values which we will have to impute later","cb287c52":"### Exploratory Data Analysis","261a8e62":"## Apparent Temperature Prediction\n\nPredicting the Apparent Temperature of a particular location based off some features gotten from historical data\n\n___\n\n* Type of Machine Learning Method\n    * Supervised Learning\n        * Regression\n            * Multiple Linear Regression (Least Squares Method)\n                * Test Accuracy of 98%\n                * RMSE loss of 0.988\n___\n* Dataset Used\n    * [Weather Temperature Dataset](https:\/\/www.kaggle.com\/budincsevity\/szeged-weather \"Gotten from Kaggle\")\n___\n\n### Steps to Solve Problem\n* Import Dataset\n* Exploratory Data Analysis\n* Feature Engineering\n    * Data Cleaning\n    * Missing Data Imputation\n    * Feature Encoding\n* Model Build\n    * Train \/ Test Data split\n    * Model Initiation and Fitting\n    * Test predictions\n* Model Perfromance\n    * RMSE\n    * R^2 score\n        ","a20d6ea9":"#### Model Prediction","df0d06c7":"### Model Initiation and Fitting","53f16cae":"### Feature Engineering\n#### Missing Data Imputation\n\n**Precip Type** is missing about 517 values, since it is a categorical feature and contains binary values of \"rain\" or \"snow\", we will fill the missing values with the most occuring value","135de019":"### Model Perfromance","5c5d6b11":"I tried converting Formatted Date into a DateTime Object but it produces a **TypeError** so we will parse it manually","36dccfe6":"We can see from the data above we have 11 features as our Target Variable is **Apparent Temperature**","e3beb930":"**Daily Summary** contains too much values, so we would just drop this feature\n\nThis feature alone contains 214 values","3566eaa7":"Calculating Root Mean Square Error (RMSE) to check loss","2b4711b8":"Now there is no more missing values","5378027b":"Now we will check the descriptive statistics of our numerical features","090c03fe":"We are spliting the data based on year recorded, so we would give the training data all the samples before the year 2016 and the test data would contain data only from 2016\n\nTrain Data contains 87699 rows while Test data contains 8784 rows","790c499d":"#### Feature Encoding","f5e482cd":"Now let's drop the features we aren't using","0264c6d5":"**Precip Type** feature"}}