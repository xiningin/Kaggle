{"cell_type":{"3834b2fa":"code","9a0330a7":"code","128f65dd":"code","43998de4":"code","4cd972d8":"code","a4eb0b56":"code","51b94335":"code","c70d3945":"code","0fde576b":"code","facc42e7":"code","75020fc1":"code","d3c6a111":"code","a98fd460":"code","e8210b93":"code","864e0cc5":"code","dabace58":"code","e5d8be6a":"code","f6536a2e":"code","5eec2ecb":"code","916f31ed":"code","05a2bba0":"code","11892809":"code","cde67411":"code","656da9fa":"code","9ef37764":"code","b53f724b":"code","c9ccb907":"code","038ac040":"code","d5264c7b":"code","e15a526a":"code","2e0db07c":"code","463af067":"code","3516d63c":"code","9e3cf640":"code","793328fb":"code","43a30715":"code","92f2e2d8":"code","3ed1d3c5":"code","ae95babc":"code","017ae30b":"code","3aca9036":"code","4c1c3a25":"code","46ba2d9b":"code","c7e39b59":"code","cb55c373":"code","c52a3303":"code","006e9660":"code","a87c1ef3":"code","46f654af":"code","f41e1522":"code","442f0cf3":"code","7f71a608":"code","b1665ae6":"code","c8196467":"code","df4b30c6":"code","a0d25239":"code","4ed5e6f5":"code","96da37f8":"code","82d805cf":"code","ed33f471":"code","25501f45":"code","506155b0":"code","ef629365":"code","7a10eae1":"code","809b04f6":"code","7eb90667":"code","9e513aab":"code","5a9cb5c1":"code","3284dd27":"code","64657c7d":"code","51dedd7c":"code","7db244cb":"code","3cb34885":"code","ade3519d":"code","738004e9":"code","4fc57395":"code","b8f742b9":"code","00bd37db":"markdown","ca003c8b":"markdown","1254b369":"markdown","f53ad106":"markdown","565d9387":"markdown","4e259780":"markdown","b64d15ef":"markdown","06b70df4":"markdown","5cb176cf":"markdown","b2f5c61d":"markdown","bf11a5c2":"markdown","cb57c4c1":"markdown","97689d5e":"markdown","ec79bd09":"markdown","3355ffd7":"markdown","65de9d15":"markdown","eaa0b13d":"markdown","86c5d677":"markdown","1453c8f1":"markdown","4e6b72f9":"markdown","94506877":"markdown","3b1a5b29":"markdown","9f621746":"markdown","7fe091b8":"markdown","bb01c3ff":"markdown","09b65f88":"markdown","4c78a9b4":"markdown","b733a8fa":"markdown","4ac177df":"markdown","11ddfee2":"markdown","47af4ba0":"markdown","05555549":"markdown","f4e0b7df":"markdown","426daf6f":"markdown","639773c4":"markdown","7fee7d43":"markdown","9fdb77a9":"markdown","82cab0a2":"markdown","acc44669":"markdown","62a86dd7":"markdown","c830b524":"markdown","d3ed952d":"markdown","f3ef571d":"markdown","59a95ef8":"markdown","803d7526":"markdown","3b2fd9eb":"markdown","3b21896a":"markdown","4e1062e7":"markdown","57a381d5":"markdown","97ad6a34":"markdown","6255619a":"markdown","c7699eac":"markdown","ec178410":"markdown","f36f1427":"markdown","63b4fc46":"markdown","84d38a37":"markdown","a86f140c":"markdown","5fe4217a":"markdown","934293ea":"markdown","424f821f":"markdown","79a22e9e":"markdown"},"source":{"3834b2fa":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split","9a0330a7":"PATH = '..\/input\/'","128f65dd":"train_data = pd.read_csv(PATH + 'train.csv')\ntest_data = pd.read_csv(PATH + 'test.csv')\ngender_submission = pd.read_csv(PATH + 'gender_submission.csv')","43998de4":"train_data.head()","4cd972d8":"test_data.head()","a4eb0b56":"train_data.describe()","51b94335":"train_data.columns","c70d3945":"train_data.dtypes","0fde576b":"column_names = train_data.columns\nfor column in column_names:\n    print(column + ' - ' + str(train_data[column].isnull().sum()))","facc42e7":"train_data.Survived.value_counts()","75020fc1":"plt = train_data.Survived.value_counts().plot('bar')\nplt.set_xlabel('Survived or not')\nplt.set_ylabel('Passenger Count')","d3c6a111":"plt = train_data.Pclass.value_counts().sort_index().plot('bar', title='')\nplt.set_xlabel('Pclass')\nplt.set_ylabel('Survival Probability')","a98fd460":"train_data[['Pclass', 'Survived']].groupby('Pclass').count()","e8210b93":"train_data[['Pclass', 'Survived']].groupby('Pclass').sum()","864e0cc5":"plt = train_data[['Pclass', 'Survived']].groupby('Pclass').mean().Survived.plot('bar')\nplt.set_xlabel('Pclass')\nplt.set_ylabel('Survival Probability')","dabace58":"plt = train_data.Sex.value_counts().sort_index().plot('bar')\nplt.set_xlabel('Sex')\nplt.set_ylabel('Passenger count')","e5d8be6a":"plt = train_data[['Sex', 'Survived']].groupby('Sex').mean().Survived.plot('bar')\nplt.set_xlabel('Sex')\nplt.set_ylabel('Survival Probability')","f6536a2e":"plt = train_data.Embarked.value_counts().sort_index().plot('bar')\nplt.set_xlabel('Embarked')\nplt.set_ylabel('Passenger count')","5eec2ecb":"plt = train_data[['Embarked', 'Survived']].groupby('Embarked').mean().Survived.plot('bar')\nplt.set_xlabel('Embarked')\nplt.set_ylabel('Survival Probability')","916f31ed":"plt = train_data.SibSp.value_counts().sort_index().plot('bar')\nplt.set_xlabel('SibSp')\nplt.set_ylabel('Passenger count')","05a2bba0":"plt = train_data[['SibSp', 'Survived']].groupby('SibSp').mean().Survived.plot('bar')\nplt.set_xlabel('SibSp')\nplt.set_ylabel('Survival Probability')","11892809":"plt = train_data.Parch.value_counts().sort_index().plot('bar')\nplt.set_xlabel('Parch')\nplt.set_ylabel('Passenger count')","cde67411":"plt = train_data[['Parch', 'Survived']].groupby('Parch').mean().Survived.plot('bar')\nplt.set_xlabel('Parch')\nplt.set_ylabel('Survival Probability')","656da9fa":"sns.factorplot('Pclass', col = 'Embarked', data = train_data, kind = 'count')","9ef37764":"sns.factorplot('Sex', col = 'Pclass', data = train_data, kind = 'count')","b53f724b":"sns.factorplot('Sex', col = 'Embarked', data = train_data, kind = 'count')","c9ccb907":"train_data.head()","038ac040":"train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1","d5264c7b":"train_data.head()","e15a526a":"train_data = train_data.drop(columns=['Ticket', 'PassengerId', 'Cabin'])","2e0db07c":"train_data.head()","463af067":"train_data['Sex'] = train_data['Sex'].map({'male':0, 'female':1})\ntrain_data['Embarked'] = train_data['Embarked'].map({'C':0, 'Q':1, 'S':2})","3516d63c":"train_data.head()","9e3cf640":"train_data['Title'] = train_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\ntrain_data = train_data.drop(columns='Name')","793328fb":"train_data.Title.value_counts().plot('bar')","43a30715":"train_data['Title'] = train_data['Title'].replace(['Dr', 'Rev', 'Col', 'Major', 'Countess', 'Sir', 'Jonkheer', 'Lady', 'Capt', 'Don'], 'Others')\ntrain_data['Title'] = train_data['Title'].replace('Ms', 'Miss')\ntrain_data['Title'] = train_data['Title'].replace('Mme', 'Mrs')\ntrain_data['Title'] = train_data['Title'].replace('Mlle', 'Miss')","92f2e2d8":"plt = train_data.Title.value_counts().sort_index().plot('bar')\nplt.set_xlabel('Title')\nplt.set_ylabel('Passenger count')","3ed1d3c5":"plt = train_data[['Title', 'Survived']].groupby('Title').mean().Survived.plot('bar')\nplt.set_xlabel('Title')\nplt.set_ylabel('Survival Probability')","ae95babc":"train_data['Title'] = train_data['Title'].map({'Master':0, 'Miss':1, 'Mr':2, 'Mrs':3, 'Others':4})","017ae30b":"train_data.head()","3aca9036":"corr_matrix = train_data.corr()","4c1c3a25":"import matplotlib.pyplot as plt\nplt.figure(figsize=(9, 8))\nsns.heatmap(data = corr_matrix,cmap='BrBG', annot=True, linewidths=0.2)","46ba2d9b":"train_data.isnull().sum()","c7e39b59":"train_data['Embarked'].isnull().sum()","cb55c373":"train_data['Embarked'] = train_data['Embarked'].fillna(2)\ntrain_data.head()","c52a3303":"corr_matrix = train_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']].corr()","006e9660":"plt.figure(figsize=(7, 6))\nsns.heatmap(data = corr_matrix,cmap='BrBG', annot=True, linewidths=0.2)","a87c1ef3":"NaN_indexes = train_data['Age'][train_data['Age'].isnull()].index","46f654af":"for i in NaN_indexes:\n    pred_age = train_data['Age'][((train_data.SibSp == train_data.iloc[i][\"SibSp\"]) & (train_data.Parch == train_data.iloc[i][\"Parch\"]) & (train_data.Pclass == train_data.iloc[i][\"Pclass\"]))].median()\n    if not np.isnan(pred_age):\n        train_data['Age'].iloc[i] = pred_age\n    else:\n        train_data['Age'].iloc[i] = train_data['Age'].median()","f41e1522":"train_data.isnull().sum()","442f0cf3":"train_data.head()","7f71a608":"test_data = pd.read_csv(PATH + 'test.csv')","b1665ae6":"test_data.isnull().sum()","c8196467":"test_data = test_data.drop(columns=['Ticket', 'PassengerId', 'Cabin'])","df4b30c6":"test_data.head()","a0d25239":"test_data['Sex'] = test_data['Sex'].map({'male':0, 'female':1})\ntest_data['Embarked'] = test_data['Embarked'].map({'C':0, 'Q':1, 'S':2})","4ed5e6f5":"test_data.head()","96da37f8":"test_data['Title'] = test_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest_data = test_data.drop(columns='Name')\n\ntest_data['Title'] = test_data['Title'].replace(['Dr', 'Rev', 'Col', 'Major', 'Countess', 'Sir', 'Jonkheer', 'Lady', 'Capt', 'Don'], 'Others')\ntest_data['Title'] = test_data['Title'].replace('Ms', 'Miss')\ntest_data['Title'] = test_data['Title'].replace('Mme', 'Mrs')\ntest_data['Title'] = test_data['Title'].replace('Mlle', 'Miss')\n\ntest_data['Title'] = test_data['Title'].map({'Master':0, 'Miss':1, 'Mr':2, 'Mrs':3, 'Others':4})","82d805cf":"test_data.head()","ed33f471":"test_data.isnull().sum()","25501f45":"NaN_indexes = test_data['Age'][test_data['Age'].isnull()].index\n\nfor i in NaN_indexes:\n    pred_age = train_data['Age'][((train_data.SibSp == test_data.iloc[i][\"SibSp\"]) & (train_data.Parch == test_data.iloc[i][\"Parch\"]) & (test_data.Pclass == train_data.iloc[i][\"Pclass\"]))].median()\n    if not np.isnan(pred_age):\n        test_data['Age'].iloc[i] = pred_age\n    else:\n        test_data['Age'].iloc[i] = train_data['Age'].median()","506155b0":"title_mode = train_data.Title.mode()[0]\ntest_data.Title = test_data.Title.fillna(title_mode)","ef629365":"fare_mean = train_data.Fare.mean()\ntest_data.Fare = test_data.Fare.fillna(fare_mean)","7a10eae1":"test_data['FamilySize'] = test_data['SibSp'] + test_data['Parch'] + 1","809b04f6":"test_data.head()","7eb90667":"train_data.head()","9e513aab":"from sklearn.utils import shuffle\ntrain_data = shuffle(train_data)","5a9cb5c1":"# training_data, valid_data = train_test_split(train_data, test_size=0.2)","3284dd27":"X_train = train_data.drop(columns='Survived')\ny_train = train_data.Survived\ny_train = pd.DataFrame({'Survived':y_train.values})","64657c7d":"# X_valid = valid_data.drop(columns='Survived')\n# y_valid = valid_data.Survived","51dedd7c":"X_test = test_data","7db244cb":"X_train.head()","3cb34885":"y_train.head()","ade3519d":"X_train.shape","738004e9":"y_train.shape","4fc57395":"X_test.head()","b8f742b9":"X_train.to_csv('X_train.csv', index=False)\ny_train.to_csv('y_train.csv', index=False)\n\n# X_valid.to_csv('X_valid.csv', index=False)\n# y_valid.to_csv('y_valid.csv', index=False)\n\nX_test.to_csv('X_test.csv', index=False)","00bd37db":"### Pclass\n- Majority of them are from 3rd class.","ca003c8b":"### Insights\n- 'Survived' is the target column\/variable.\n- 'PassengerId', 'Name' and 'Ticket' doesn't contribute to the target variable 'Survived'. So, we can remove it from the data.\n- 'Age' and 'Embarked' has less number of missing value. We have to impute them using different techniques.\n- As there are a lot of missing values in the column 'Cabin', we can remove it from the training data.\n- 'Pclass', 'Sex', 'SibSp', 'Parch', 'Fare' doesn't have any missing values. \n- We can also create new variable like 'total size of the family' from the columns 'SibSp' and 'Parch'.","1254b369":"### Create a new feature 'Family size' from the features 'SibSp' and 'Parch'","f53ad106":"### Handling missing values","565d9387":"### Embarked vs Sex","4e259780":"### Embarked\n- Most of them are from Southampton(S).","b64d15ef":"### Sex - Survival probability\n- As we see, the survival probaility for Female is more. They might have given more priority to female than male.","06b70df4":"### SibSp - Siblings\/Spouse","5cb176cf":"### Drop 'Ticket', 'PassengerId' and 'Cabin' columns","b2f5c61d":"### Visualization of 'Survived' (Target column)\n- As we know, majority of passengers couldn't survive.\n- Data is imbalanced.","bf11a5c2":"- The columns 'Age' and 'Cabin' contains more null values.","cb57c4c1":"### Number of missing values","97689d5e":"### Read test data","ec79bd09":"- The passengers having three children\/parents has more survival probability.\n- '3' > '1' > '2' > '0' > '5'","3355ffd7":"### Map 'Title' to numerical values","65de9d15":"- The passengers with title 'Mr' are more.","eaa0b13d":"- This kernel provides insights of the Titanic data.\n- At the end of this notebook, you will be ready with preprocessed data. You can concentrate more on modelling after using this kernel.\n- NOTE: There is a lot of room for improvement and can try many things.\n- Let's get started.","86c5d677":"### Pclass - Survival probability","1453c8f1":"### Pclass vs Sex\n- Majority of the passengers are Male in every class. But, the survival probability for female is high.","4e6b72f9":"### Impute 'Embarked' with it's majority class.","94506877":"- Age is not correlated with 'Sex' and 'Fare'. So, we don't consider these two columns while imputing 'Sex'.\n- 'Pclass', 'SibSp' and 'Parch' are negatively correlated with 'Sex'.\n- Let's fill Age with the median age of similar rows from 'Pclass', 'SibSp' and 'Parch'. If there are no similar rows, fill the age with the median age of total dataset.","3b1a5b29":"- As we can see, majority of them have no Children\/Parents.","9f621746":"### Map 'Sex' and 'Embarked' to numerical values.","7fe091b8":"### Load data","bb01c3ff":"### Parch - Children\/Parents","09b65f88":"- As we can see, majority of them have no Siblings\/Spouse.","4c78a9b4":"- It's time to use this preprocessed data and apply different modelling algorithms.\n- Hope this kernel helps you.\n- Don't forget to UPVOTE, if you find this kernel interesting.","b733a8fa":"### Columns","4ac177df":"### Impute 'Age' using median of columns 'SibSp', 'Parch' and 'Pclass'","11ddfee2":"### Create a new feature 'FamilySize' from 'SibSp' and 'Parch'","47af4ba0":"### Import libraries","05555549":"### Data type of each column","f4e0b7df":"### Preprocess 'Name'\n- Extarct title from name of the passenger and categorize them.\n- Drop the column 'Name'","426daf6f":"### Impute 'Fare' with it's mean","639773c4":"### Impute 'Title' with it's mode","7fee7d43":"### Save data","9fdb77a9":"### Remove unnecessary columns\n- We can remove 'Ticket' and 'PassengerId', as they don't contribute to target class.\n- Remove 'Cabin' as it has a lot of missing values in both train and test data","82cab0a2":"### Embarked - Survival probability\n- Survival probability: C > Q > S","acc44669":"### Describe data","62a86dd7":"### Extract 'Title' from 'Name' and convert to Numerical values.","c830b524":"### Correlation between columns","d3ed952d":"## <center> Titanic - Data Preprocessing and Visualization <\/center>","f3ef571d":"- There are two null values in the column 'Embarked'. Let's impute them using majority class.\n- The majority class is 'S'. Impute the unkonown values (NaN) using 'S'","59a95ef8":"### Split 'train data' into 'training data' and 'validation data'","803d7526":"- Combine some of the classes and group all the rare classes into 'Others'.","3b2fd9eb":"### Train data","3b21896a":"### Test data","4e1062e7":"- The survival probability for 'Mrs' and 'Miss' is high comapred to other classes.","57a381d5":"- There are no missing values in the data.","97ad6a34":"## <center> Visualize and preprocess train data <\/center>","6255619a":"### Convert 'Sex' and 'Embarked' to Numerical values","c7699eac":"### Sex\n- Majority of them are Male.","ec178410":"### Missing values - 'Age'\n- Let's find the columns that are useful to predict the value of Age.","f36f1427":"- From the above results, we can say that, 1st class has high chance of surviving than the other two classes.","63b4fc46":"## <center> Preprocessed data <\/center>","84d38a37":"## <center> Preprocess test data <\/center>","a86f140c":"### Number of missing values","5fe4217a":"### Embarked vs Pclass","934293ea":"- There are no very highly correlated columns.","424f821f":"### Path to the dataset","79a22e9e":"- The passengers having one sibling\/spouse has more survival probability.\n- '1' > '2' > '0' > '3' > '4'"}}