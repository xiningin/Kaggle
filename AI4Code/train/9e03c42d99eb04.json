{"cell_type":{"40266e23":"code","2402b0ee":"code","b2f608d6":"code","b37c7a0e":"code","db519ba6":"code","23dca462":"code","5abc7bab":"code","833dcf86":"code","cb0c8eda":"code","f25d01bc":"code","935ee312":"code","ed2b86c2":"code","cdb391b9":"code","8b7127e1":"code","27a03e08":"code","30b15943":"code","b16f178b":"code","1b2408e2":"code","48ed0b15":"code","d11119a1":"code","65bbe8ce":"code","b0ba4219":"code","e100f204":"code","cdce99b7":"code","debe6be2":"code","3629cb62":"markdown","2b21ea0f":"markdown","78033092":"markdown","2960e1d1":"markdown"},"source":{"40266e23":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport random\nprint(os.listdir(\"..\/input\"))\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n","2402b0ee":"import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import random_split","b2f608d6":"data0 = pd.read_csv(\"..\/input\/iris\/Iris.csv\")\nprint(data0.columns.tolist())","b37c7a0e":"Name0=data0.Species.unique().tolist()\nName=sorted(Name0)\nprint(Name)\nN=list(range(len(Name)))\nnormal_mapping=dict(zip(Name,N)) \nreverse_mapping=dict(zip(N,Name)) \nprint(len(Name))","db519ba6":"data0['Species']=data0['Species'].map(normal_mapping)","23dca462":"m=len(data0)\nM=list(range(m))\nrandom.seed(2021)\nrandom.shuffle(M)","5abc7bab":"dataY=data0['Species']\ndataX=data0.drop('Species',axis=1)","833dcf86":"trainX, testX, trainY, testY = train_test_split(\n            dataX, dataY, test_size=0.25, random_state=42)","cb0c8eda":"print(type(trainX))\nprint(type(trainY))","f25d01bc":"trainY=torch.from_numpy(np.array(trainY)).type(torch.LongTensor)\ntrainX=torch.from_numpy(np.array(trainX)).float()\ntestY=torch.from_numpy(np.array(testY)).type(torch.LongTensor)\ntestX=torch.from_numpy(np.array(testX)).float()","935ee312":"batch_size = 100\nn_iters = 10000\nnum_epochs = n_iters \/ (len(trainX) \/ batch_size)\nnum_epochs = int(num_epochs)","ed2b86c2":"train_ds = torch.utils.data.TensorDataset(trainX,trainY)\ntest_ds = torch.utils.data.TensorDataset(testX,testY)","cdb391b9":"batch_size = 32\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_ds, batch_size, num_workers=4, pin_memory=True)","8b7127e1":"class LogisticRegressionModel(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(LogisticRegressionModel, self).__init__()\n        self.linear = nn.Linear(input_dim, output_dim)\n    \n    def forward(self, x):\n        out = self.linear(x)\n        return out\n\ninput_dim = 5\noutput_dim = len(Name)\nmodel = LogisticRegressionModel(input_dim, output_dim)  \nerror = nn.CrossEntropyLoss()\nlearning_rate = 0.001\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)","27a03e08":"count = 0\nloss_list = []\niteration_list = []\n\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        \n        train = Variable(images.view(-1,5))\n        labels = Variable(labels)\n        optimizer.zero_grad()\n        outputs = model(train)   #####\n        loss = error(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        count += 1\n        \n        if count % 50 == 0:      \n            correct = 0\n            total = 0\n\n            for images, labels in test_loader: \n                test = Variable(images.view(-1,5))\n                outputs = model(test)\n                predicted = torch.max(outputs.data, 1)[1]\n                total += len(labels)\n                correct += (predicted == labels).sum()\n            \n            accuracy = 100 * correct \/ float(total)\n            loss_list.append(loss.data)\n            iteration_list.append(count)\n            \n        if count % 5000 == 0:\n            print('Iteration: {}  Loss: {}  Accuracy: {}%'.format(count, loss.data, accuracy))","30b15943":"plt.plot(iteration_list,loss_list)\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Loss\")\nplt.title(\"Logistic Regression: Loss vs Number of iteration\")\nplt.show()","b16f178b":"model","1b2408e2":"test_outputs = model(testX)\ntest_predicted = torch.max(test_outputs.data,1)[1]","48ed0b15":"ANS=testY.numpy()\nPRED=test_predicted.numpy()\naccuracy=accuracy_score(ANS,PRED)\nprint(accuracy)","d11119a1":"class ANNModel(nn.Module):\n    \n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(ANNModel, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim) \n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n        self.tanh2 = nn.Tanh()\n        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n        self.elu3 = nn.ELU()\n        self.fc4 = nn.Linear(hidden_dim, output_dim)  \n    \n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.relu1(out)\n        out = self.fc2(out)\n        out = self.tanh2(out)\n        out = self.fc3(out)\n        out = self.elu3(out)\n        out = self.fc4(out)\n        return out\n\ninput_dim = 5\nhidden_dim = 150\noutput_dim = len(Name)\n\nmodel = ANNModel(input_dim, hidden_dim, output_dim)\nerror = nn.CrossEntropyLoss()\nlearning_rate = 0.02\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)","65bbe8ce":"count = 0\nloss_list = []\niteration_list = []\naccuracy_list = []\n\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        train = Variable(images.view(-1,5))\n        labels = Variable(labels)\n        optimizer.zero_grad()\n        outputs = model(train)\n        loss = error(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        count += 1\n        \n        if count % 50 == 0:      \n            correct = 0\n            total = 0\n\n            for images, labels in test_loader:  \n                test = Variable(images.view(-1,5))\n                outputs = model(test)\n                predicted = torch.max(outputs.data, 1)[1]\n                total += len(labels)\n                correct += (predicted == labels).sum()\n            \n            accuracy = 100 * correct \/ float(total)\n            loss_list.append(loss.data)\n            iteration_list.append(count)\n            accuracy_list.append(accuracy)\n            \n        if count % 5000 == 0:\n            print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data, accuracy))","b0ba4219":"# visualization loss \nplt.plot(iteration_list,loss_list)\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Loss\")\nplt.title(\"ANN: Loss vs Number of iteration\")\nplt.show()\n\n# visualization accuracy \nplt.plot(iteration_list,accuracy_list,color = \"red\")\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"ANN: Accuracy vs Number of iteration\")\nplt.show()","e100f204":"model","cdce99b7":"test_outputs = model(testX)\ntest_predicted = torch.max(test_outputs.data,1)[1]","debe6be2":"ANS=testY.numpy()\nPRED=test_predicted.numpy()\naccuracy=accuracy_score(ANS,PRED)\nprint(accuracy)","3629cb62":"# Create ANN Model","2b21ea0f":"# Create Logistic Regression Model","78033092":"cf. https:\/\/www.kaggle.com\/kanncaa1\/pytorch-tutorial-for-deep-learning-lovers","2960e1d1":"# Prepare Dataset"}}