{"cell_type":{"e2ea5eef":"code","f74aba23":"code","6012e889":"code","ac1f1080":"code","b5d8a685":"code","26f00d3c":"code","7758776e":"code","f645ca9f":"code","dffcf405":"code","0bd4a466":"code","36161088":"code","8c8488a0":"code","0b0f4c4a":"code","1de1b4f6":"code","ab25298d":"code","a8a567c3":"code","b3c1bb50":"code","affc0d4d":"code","b0e9517b":"code","48c35030":"code","b836b1a9":"code","66b5111d":"code","b1f93c45":"code","42d90612":"code","56c37d0c":"code","23c1a588":"code","6a6b6d3b":"code","2a3722da":"markdown","8e8df916":"markdown","9f0b00f4":"markdown"},"source":{"e2ea5eef":"import os\n\nbase_dir = '\/kaggle\/input\/handwriting-recognition'\ntrain_images_dir = os.path.join(base_dir, 'train_v2\/train')\nvalidation_images_dir = os.path.join(base_dir, 'validation_v2\/validation')\ntest_images_dir = os.path.join(base_dir, 'test_v2\/test')","f74aba23":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport cv2","6012e889":"train_csv = pd.read_csv(os.path.join(base_dir, 'written_name_train_v2.csv'))\nvalidation_csv = pd.read_csv(os.path.join(base_dir, 'written_name_validation_v2.csv'))\ntest_csv = pd.read_csv(os.path.join(base_dir, 'written_name_test_v2.csv'))","ac1f1080":"train_csv.head()","b5d8a685":"train_csv.info()","26f00d3c":"# There are 565 null samples\nprint(\"Number of null values in train_csv: \\n\",train_csv.isnull().sum())\nprint('\\n---------------\\n')\nprint(\"Number of null values in validation_csv: \\n\",validation_csv.isnull().sum())\nprint('\\n---------------\\n')\nprint(\"Number of null values in test_csv: \\n\",test_csv.isnull().sum())","7758776e":"# Drop null samples\ntrain_csv = train_csv.dropna()\n\nvalidation_csv = validation_csv.dropna()\n\ntest_csv = test_csv.dropna()","f645ca9f":"# Plot unreadable image samples from train data\nunreadable_indexes = train_csv[train_csv['IDENTITY'] == 'UNREADABLE'].index\n\nplt.figure(figsize = (15,3))\n\noffset = 10\nfor i in range(6):\n    ax = plt.subplot(2, 3, i+1)\n    image_name = train_csv.iloc[unreadable_indexes[i + offset],0]\n    image = cv2.imread(os.path.join(train_images_dir, image_name), cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, 'gray')","dffcf405":"train_csv = train_csv[train_csv['IDENTITY'] != 'UNREADABLE']\n\nvalidation_csv = validation_csv[validation_csv['IDENTITY'] != 'UNREADABLE']\n\ntest_csv = test_csv[test_csv['IDENTITY'] != 'UNREADABLE']","0bd4a466":"# Make all chars lowercase\ntrain_csv['IDENTITY'] = train_csv['IDENTITY'].str.lower()\nvalidation_csv['IDENTITY'] = validation_csv['IDENTITY'].str.lower()\ntest_csv['IDENTITY'] = test_csv['IDENTITY'].str.lower()\n\n\n\ncharacters = set(char for label in train_csv['IDENTITY'].values for char in label)\n\nprint(\"Number of samples found: \", len(train_csv.values))\nprint(\"Number of unique characters: \", len(characters))\nprint(\"Characters present: \", characters)","36161088":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nmax_length = max([len(label) for label in train_csv['IDENTITY'].values])\ntokenizer = Tokenizer(num_words = max_length, char_level = True)\ntokenizer.fit_on_texts(train_csv['IDENTITY'].values)\nword_index = tokenizer.word_index\n\nsample_sequence = tokenizer.texts_to_sequences(['sample text'])\nsample_pad = pad_sequences(sample_sequence, maxlen = max_length, padding = 'post')\nsample_text = tokenizer.sequences_to_texts(sample_sequence)\nprint(\"Sample sequence: \", sample_sequence[0])\nprint(\"Sample pad: \", sample_pad[0])\nprint(\"Sample text: \", sample_text[0])\n\nimg_width = 50\nimg_height = 200","8c8488a0":"plt.figure(figsize = (15,3))\n\noffset = 0\nfor i in range(6):\n    ax = plt.subplot(2, 3, i+1)\n    image_name = train_csv.iloc[i + offset,0]\n    image = cv2.imread(os.path.join(train_images_dir, image_name), cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, 'gray')\n    plt.title(f'{train_csv.iloc[i + offset,1]},{image.shape}')","0b0f4c4a":"images = train_csv['FILENAME'].values\nlabels = train_csv['IDENTITY'].values\n\n\ndef preprocess_single_sample(image_path, label, TEST = False):\n    if TEST:\n        img = cv2.imread(os.path.join(validation_images_dir, image_path), cv2.IMREAD_GRAYSCALE)\n    else:\n        img = cv2.imread(os.path.join(train_images_dir, image_path), cv2.IMREAD_GRAYSCALE)\n        \n    img = cv2.resize(img,(img_height, img_width), interpolation = cv2.INTER_AREA)\n    img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE) \/ 255\n    \n    label_sequence = tokenizer.texts_to_sequences([label])\n    label = pad_sequences(label_sequence, maxlen = max_length, padding = 'post')[0]\n    \n    return img,label","1de1b4f6":"train_length = 30000\nvalidation_length = 3000\ntest_length = 3000\n\nindices = np.arange(len(train_csv))\nnp.random.shuffle(indices)\n\ntest_indices = np.arange(len(test_csv))\nnp.random.shuffle(test_indices)","ab25298d":"x_train = []\ny_train = []\ntrain_label_len = []\nfor i in range(train_length):\n    image_name = train_csv.iloc[indices[i], 0]\n    label = train_csv.iloc[indices[i], 1]\n    train_label_len.append(len(label))\n    \n    img, label = preprocess_single_sample(image_name, label)\n    img = np.expand_dims(img, axis = 2)\n    x_train.append(img)\n    y_train.append(label)\n    \nx_train = np.array(x_train)\ny_train = np.array(y_train)\ntrain_label_len = np.array(train_label_len)","a8a567c3":"x_val = []\ny_val = []\nvalid_label_len = []\n\nfor i in range(train_length, train_length+validation_length):\n    image_name = train_csv.iloc[indices[i], 0]\n    label = train_csv.iloc[indices[i], 1]\n    valid_label_len.append(len(label))\n    \n    img, label = preprocess_single_sample(image_name, label)\n    img = np.expand_dims(img, axis = 2)\n    x_val.append(img)\n    y_val.append(label)\n\nx_val = np.array(x_val)\ny_val = np.array(y_val)\nvalid_label_len = np.array(valid_label_len)","b3c1bb50":"x_test = []\ny_test = []\n\nfor i in range(test_length):\n    image_name = train_csv.iloc[test_indices[i], 0]\n    label = train_csv.iloc[test_indices[i], 1]\n    \n    img, _ = preprocess_single_sample(image_name, label)\n    img = np.expand_dims(img, axis = 2)\n    x_test.append(img)\n    y_test.append(label)\n\nx_test = np.array(x_test)\ny_test = np.array(y_test)","affc0d4d":"x_train.shape, x_val.shape, y_train.shape, y_val.shape","b0e9517b":"train_input_len = np.ones([train_length, 1]) * 48\nvalid_input_len = np.ones([validation_length, 1]) * 48\nvalid_output = np.zeros([validation_length])","48c35030":"from keras import backend as K\ndef ctc_loss(args):\n    labels, y_pred, input_length, label_length = args\n    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)","b836b1a9":"# Inputs to the model\ninput_img = layers.Input(shape=(200, 50, 1), name=\"image\")\nlabels = layers.Input(name=\"label\", shape=(max_length,))\ninput_length = layers.Input(name='input_length', shape=(1,))\nlabel_length = layers.Input(name='label_length', shape=(1,))\n\nx = layers.Conv2D(\n    32,\n    (3, 3),\n    activation=\"relu\",\n    kernel_initializer=\"he_normal\",\n    padding=\"same\",\n    name=\"Conv1\",\n)(input_img)\nx = layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n\n\nx = layers.Conv2D(\n    64,\n    (3, 3),\n    activation=\"relu\",\n    kernel_initializer=\"he_normal\",\n    padding=\"same\",\n    name=\"Conv2\",\n)(x)\nx = layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n\nx = layers.Reshape(target_shape=(50,768), name=\"reshape\")(x)\nx = layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\nx = layers.Dropout(0.2)(x)\n\n\nx = layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=0.25))(x)\nx = layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=0.25))(x)\n\n# Output layer\ny_pred = layers.Dense(\n    len(characters) + 1, activation=\"softmax\", name=\"output\"\n)(x)\n\nloss_out = layers.Lambda(ctc_loss, output_shape=(1,), name='ctc')([labels, y_pred, input_length, label_length])\n\n\n# Define the model\nmodel = keras.models.Model(inputs=[input_img, labels, input_length, label_length], \n                           outputs=loss_out,\n                           name=\"ocr_model_v1\")","66b5111d":"opt = keras.optimizers.Adam()\n\nmodel.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=opt)\nmodel.summary()","b1f93c45":"epochs = 50\nearly_stopping_patience = 10\n# Add early stopping\nearly_stopping = keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\", patience=early_stopping_patience, restore_best_weights=True\n)\n\n# Train the model\nhistory = model.fit(\n    x = (x_train, y_train, train_input_len, train_label_len),\n    y = np.zeros([train_length]),\n    validation_data = ([x_val, y_val, valid_input_len, valid_label_len], np.zeros([validation_length]) ),\n    epochs=epochs,\n    batch_size = 128,\n    callbacks=[early_stopping]\n)","42d90612":"prediction_model = keras.models.Model(\n    model.get_layer(name=\"image\").input, model.get_layer(name=\"output\").output\n)\nprediction_model.summary()","56c37d0c":"def decode_predictions(pred):\n    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n        :, :max_length\n    ]\n    output_text = []\n    for res in results:\n        decoded = tokenizer.sequences_to_texts([res.numpy()])\n        output_text.append(decoded)\n    return output_text","23c1a588":"preds = prediction_model.predict(x_test)\npred_texts = decode_predictions(preds)","6a6b6d3b":"\n_, ax = plt.subplots(4, 4, figsize=(15, 5))\nfor i in range(16):\n    img = x_test[i]\n    img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n    title = f\"Prediction: {pred_texts[i][0]}\"\n    ax[i \/\/ 4, i % 4].imshow(img, cmap=\"gray\")\n    ax[i \/\/ 4, i % 4].set_title(title)\n    ax[i \/\/ 4, i % 4].axis(\"off\")\nplt.show()","2a3722da":"## Preprocess Images","8e8df916":"# Preprocessing","9f0b00f4":"# Clean Data"}}