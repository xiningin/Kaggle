{"cell_type":{"fcf84486":"code","5074a661":"code","78246aa1":"code","d49e24e7":"code","2db1c6aa":"code","1b798f21":"code","936b99a1":"code","1ff40577":"code","47b6c43e":"code","f2e27c4b":"code","7b10e508":"code","6821fb41":"code","b8519df7":"code","26f374d9":"code","4cdf8c2a":"code","74168f98":"code","055f7b7f":"code","a12a48e6":"code","73b2cfda":"code","30a9bfbf":"markdown","8449caed":"markdown","fb978fbd":"markdown","f3d9c07f":"markdown","03a6df98":"markdown","9b6e0fef":"markdown","2a9fd442":"markdown","6c7a5946":"markdown","f238cea9":"markdown","3c2e233c":"markdown"},"source":{"fcf84486":"from sklearn.model_selection import train_test_split #split the training data\nfrom sklearn.metrics import mean_squared_log_error # metrics for model validation\nfrom sklearn.ensemble import RandomForestRegressor # ML model using RF\nfrom sklearn.impute import SimpleImputer # Imputation transformer for missing values\nfrom sklearn.preprocessing import LabelEncoder # label encoding categorical variables\nfrom sklearn.preprocessing import OneHotEncoder # encoding categorical variables\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing","5074a661":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","78246aa1":"# Read the data\nX_full = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv', index_col='Id')\nX_test_full = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv',index_col='Id')\n\n# Seperate target from predictors\ny = X_full.SalePrice\nX_full.drop(['SalePrice'],axis=1,inplace=True)\n\n# Use only numerical predictors\nX_full = X_full.select_dtypes(exclude=['object'])\nX_test = X_test_full.select_dtypes(exclude=['object'])\n\n# Drop columns with missing values\n#col_missing_values = [col for col in X_full.columns if X_full[col].isnull().any()]\n\n#X_full.drop(col_missing_values, axis=1, inplace=True)\n#X_test_full.drop(col_missing_values,axis=1,inplace=True)\n\n#col_missing_values2 = [col for col in X_test_full.columns if X_test_full[col].isnull().any()]\n#X_full.drop(col_missing_values2, axis=1, inplace=True)\n#X_test_full.drop(col_missing_values2,axis=1,inplace=True)\n\n# Break off validation set from training data\nX_train, X_valid, y_train, y_valid = train_test_split(X_full,y,train_size=0.8,test_size=0.2,random_state=0)","d49e24e7":"# Function to compare different approaches\ndef score_dataset(X_train,X_valid,y_train,y_valid):\n    model = RandomForestRegressor(n_estimators=100,random_state=0)\n    model.fit(X_train,y_train)\n    preds = model.predict(X_valid)\n    return mean_squared_log_error(y_valid,preds)","2db1c6aa":"# Get names of columns with missing values\nXtrain_missing_cols = [col for col in X_train.columns\n                       if X_train[col].isnull().any()]\nprint(Xtrain_missing_cols)\n\nXvalid_missing_cols = [col for col in X_valid.columns\n                       if X_valid[col].isnull().any()]\nprint(Xvalid_missing_cols)\n\n# Drop the column, save to reduced_X_train and reduced_X_valid\nreduced_X_train = X_train.drop(Xtrain_missing_cols,axis=1)\nreduced_X_valid = X_valid.drop(Xvalid_missing_cols,axis=1)","1b798f21":"print(\"RMSLE (1st approach):\") # the categorical variables have been removed. Drop columns with missing values.\nprint(score_dataset(reduced_X_train,reduced_X_valid,y_train,y_valid))","936b99a1":"my_imputer = SimpleImputer(strategy='most_frequent')\nimputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\nimputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n\n# Imputation removed column names ;  put them back\nimputed_X_train.columns = X_train.columns\nimputed_X_valid.columns = X_valid.columns","1ff40577":"print(\"RMSLE (2nd approach):\") # Categorical variables have been removed. Impute missing values with 'most_frequent'\nprint(score_dataset(imputed_X_train,imputed_X_valid,y_train,y_valid))","47b6c43e":"# All categorical columns\nobject_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n\n# Columns that can be label encoded safely\ngood_label_cols = [col for col in object_cols if set(X_valid[col]).issubset(set(X_train[col]))]\n\n# Columns that will be dropped\nbad_label_cols = list(set(object_cols) - set(good_label_cols))\n\nprint('Columns that will be label encoded: ', good_label_cols)\nprint('Columns that will be dropped: ', bad_label_cols)","f2e27c4b":"# Drop \"bad\" columns\nlabel_X_train = X_train.drop(bad_label_cols,axis=1)\nlabel_X_valid = X_valid.drop(bad_label_cols,axis=1)\n\n# Apply label encoding\nlabel_encoder = LabelEncoder()\nfor col in good_label_cols:\n    label_X_train[col] = label_encoder.fit_transform(X_train[col])\n    label_X_valid[col] = label_encoder.transform(X_valid[col])","7b10e508":"print('RMSLE (3rd apporach): ')\nprint(score_dataset(label_X_train,label_X_valid,y_train,y_valid))","6821fb41":"# Get number of unique entries for each categorical columns\nobject_nunique = list(map(lambda col:X_train[col].nunique(),object_cols))\nd = dict(zip(object_cols, object_nunique))\n\nsorted(d.items(),key=lambda x:x[1])","b8519df7":"# Columns that will be one hot encoded\nlow_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n\n# Columns that will be dropped\nhigh_cardinality_cols = list(set(object_cols) - set(low_cardinality_cols))\n\nprint('Columns that will be one-hot encoded: ', low_cardinality_cols)\nprint('Columns that will be dropped: ', high_cardinality_cols)","26f374d9":"# Apply one hot encoding to each column in low_cardinality_cols\nOH_encoder = OneHotEncoder(handle_unknown = 'ignore',sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\nOH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n\n# One-hot encoding removed index; put it back\nOH_cols_train.index = X_train.index\nOH_cols_valid.index = X_valid.index\n\n# Remove categorical columns (will be replaced with one-hot encoding)\nnum_X_train = X_train.drop(low_cardinality_cols, axis=1)\nnum_X_valid = X_valid.drop(low_cardinality_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_X_train = pd.concat([num_X_train,OH_cols_train],axis=1) \nOH_X_valid = pd.concat([num_X_valid,OH_cols_valid],axis=1) \n\n# Drop categorical columns that will not be encoded\nOH_X_train = OH_X_train.drop(high_cardinality_cols, axis=1)\nOH_X_valid = OH_X_valid.drop(high_cardinality_cols, axis=1)","4cdf8c2a":"print(\"RMSLE (4th approach):\") \nprint(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))","74168f98":"imputed_X_test = pd.DataFrame(my_imputer.transform(X_test))\n\n# Imputation removed column names ;  put them back\nimputed_X_test.columns = X_test.columns","055f7b7f":"# Define and fit the model\nmodel = RandomForestRegressor(n_estimators=100,random_state=0)\nmodel.fit(imputed_X_train,y_train)","a12a48e6":"# Predict\npredictions = model.predict(imputed_X_test)","73b2cfda":"# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': predictions})\noutput.to_csv('submission.csv', index=False)","30a9bfbf":"# Model","8449caed":"# Get the data","fb978fbd":"# 4th Approach: One-Hot Encoding\n- Drop columns with missing values (numerical and categorical) <br\/>\n- Find the cardinality for each categorical columns\n- Drop categorical columns which have +10 unique values; use One-Hot encoding to encode the others","f3d9c07f":"# Packages Installation","03a6df98":"# 2nd Approach: Imputation\n- Remove categorical columns, use numerical columns **only** <br\/>\n- Handle missing values with SimpleImputer with <code>strategy='most_frequent'<\/code>. ","9b6e0fef":"# 3rd Approach: Label encoding\n- Drop column with missing values (categorical and numerical columns) <br\/>\n- Make sure the set of each object column contains the same unique value between X_train and X_valid (see the code below) <br\/>\n- Use LabelEncoder to encode the categorical columns","2a9fd442":"# Predict and File Submission","6c7a5946":"# Validation Function to compare different apporaches","f238cea9":"# 1st Approach: Drop Columns with Missing Values\n- Remove categorical columns, use numerical columns **only**  <br\/>\n- Drop column with missing values\n","3c2e233c":"# Data pre-processing for <code>X_test<\/code> <br\/>\n2nd approach is the best approach, therefore I apply SimpleImputer to <code>X_test<\/code>"}}