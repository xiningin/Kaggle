{"cell_type":{"8f0d855d":"code","fecc720d":"code","764bcf54":"code","df1a9c26":"code","1f76c44d":"code","d304c2b1":"code","7105fd41":"code","d2ca6bcc":"code","066f5d22":"code","6fba658f":"code","36b7523a":"code","beb2aabc":"code","db81a6b3":"code","cf973bb4":"code","a8c3937c":"code","4683f086":"code","de8259c5":"code","3dfbde5b":"code","447b8932":"code","0e2a0136":"code","4310c9b6":"code","3beaa9a3":"code","1c3f0c46":"code","f1d4574d":"code","60624317":"code","ea9ad27e":"code","505eec5e":"code","47b34544":"code","f20e812c":"code","016cd229":"code","4527af74":"code","745773fe":"code","a4c27c23":"code","6673ce80":"code","9efb9148":"code","9f0eba52":"code","165f0d1d":"code","d199b27f":"code","f736ad03":"code","0a5dadcf":"code","8b8df8d2":"code","5ee3acfd":"code","1962ce42":"code","ca7344ee":"code","d81cbb52":"code","94a5b261":"code","4610e2a9":"code","83ecc0d7":"code","420e07ed":"code","7cfd0a20":"code","87b5b9b2":"code","22f12d52":"code","394b0b62":"code","61696ff9":"code","0ada219d":"code","48c30e90":"code","88fda261":"code","18a1a8a7":"code","a35b7f16":"code","a0c2af30":"code","e8dd5d98":"code","c1df211d":"code","5fd234ed":"code","d96ae79a":"code","5deba9e4":"code","6b9dce44":"code","6893ce12":"code","a876aba2":"code","4406d036":"code","1879f74f":"code","ce235250":"code","02e69de8":"code","89bb8ec4":"code","1402dddf":"code","7e56d1e8":"code","415bed6b":"code","0fbe6c5f":"code","ac8c77a1":"code","3a6495ca":"code","8bc79c27":"code","f7502431":"code","43cd4c61":"code","de79d6c6":"code","9df62d54":"code","3f79937b":"code","ebd131eb":"code","17fd7cf8":"code","73b092ba":"code","80e5df44":"code","dce8fbc1":"markdown","1ac4935f":"markdown","31a7907c":"markdown","8805e6c6":"markdown","c2fdbb54":"markdown","99a27ade":"markdown","e286f775":"markdown","92318cc4":"markdown","e2371d34":"markdown","0a05e850":"markdown","62f417e2":"markdown","5e0ec317":"markdown","ac8ef88d":"markdown","13bd239f":"markdown","690de55b":"markdown","3dab102e":"markdown","1c5239d2":"markdown","5a11f985":"markdown","fcff2ce2":"markdown","63b113bc":"markdown","662ebc16":"markdown","bed76db0":"markdown","461c2245":"markdown","83b118cb":"markdown","799cb483":"markdown","d123e1f9":"markdown","31fbe180":"markdown","40b81555":"markdown","50713590":"markdown","cbcf30c4":"markdown","533f4770":"markdown","bb4d0dd0":"markdown","e081a56a":"markdown","d8f208a0":"markdown","9c02661a":"markdown","a6dd7069":"markdown","95bf8c7f":"markdown","8df3bc81":"markdown","b11e4d68":"markdown","4ec8d712":"markdown","e94c86b4":"markdown","41f8397f":"markdown","8883fd2d":"markdown"},"source":{"8f0d855d":"from IPython.display import Image\nImage(\"..\/input\/cancer\/breast.png\", width=1000, height=1000)","fecc720d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import precision_recall_curve\n","764bcf54":"df=pd.read_csv('..\/input\/habermans-survival-data-set\/haberman.csv')\ndf.head()","df1a9c26":"df.columns=['Age','Operation_Year','Positive_lymph_node','survival_status']\ndf.head()","1f76c44d":"df['survival_status'].value_counts()","d304c2b1":"survival_status={1:1,2:0}\ndf['survival_status']=[survival_status[x] for x in df['survival_status']]","7105fd41":"df['survival_status'].value_counts()","d2ca6bcc":"df.describe()","066f5d22":"sns.boxplot(x='survival_status',y='Age', data=df, linewidth=0.35)","6fba658f":"df['survival_status'].unique()","36b7523a":"sns.pairplot(data=df)\nplt.show()","beb2aabc":"df['survival_status'].unique()","db81a6b3":"df.plot(x='Age', y='Positive_lymph_node', kind='scatter')\nplt.show()","cf973bb4":"sns.set_style(\"whitegrid\")\nsns.FacetGrid(df, hue=\"survival_status\",size=6).map(plt.scatter, \"Age\",\"Positive_lymph_node\").add_legend()\nplt.show()","a8c3937c":"sns.set_style('whitegrid')\nsns.pairplot(data=df)\nplt.show()","4683f086":"sns.FacetGrid(df, hue=\"survival_status\",size=5).map(sns.distplot,\"Positive_lymph_node\").add_legend()\nplt.show()","de8259c5":"sns.FacetGrid(df, hue='survival_status').map(sns.histplot, \"Positive_lymph_node\").add_legend()\nplt.show()","3dfbde5b":"sns.FacetGrid(df, hue=\"survival_status\",size=5).map(sns.distplot,\"Operation_Year\").add_legend()\nplt.show()","447b8932":"alive=df.loc[df['survival_status']==1]\ndead=df.loc[df['survival_status']==0]","0e2a0136":"count,bin_edges=np.histogram(alive['Positive_lymph_node'], bins=10, density=True)\npdf=count\/sum(count)\n\nprint(pdf)\nprint(bin_edges)\ncdf=np.cumsum(pdf)\n\nplt.plot(bin_edges[1:],pdf)\nplt.plot(bin_edges[1:], cdf)\nplt.legend(['Pdf for the patients who survive more than 5 years',\n            'Cdf for the patients who survive more than 5 years'])\n            ","4310c9b6":"count,bin_edges=np.histogram(dead['Positive_lymph_node'], bins=10, density=True)\npdf=count\/sum(count)\n\nprint(pdf)\nprint(bin_edges)\ncdf=np.cumsum(pdf)\n\nplt.plot(bin_edges[1:],pdf)\nplt.plot(bin_edges[1:], cdf)\nplt.legend(['Pdf for the patients who survive more than 5 years',\n            'Cdf for the patients who survive more than 5 years'])\n            ","3beaa9a3":"df.describe()","1c3f0c46":"print(\"Summary Statistics of Patients who are alive within 5 years:\")\nalive.describe()","f1d4574d":"print(\"Summary Statistics of Patients who are dead within 5 years:\")\ndead.describe()","60624317":"#Median, Quantiles, Percentiles, IQR.\nprint(\"\\nMedian\")\nprint(np.median(alive['Positive_lymph_node']))\n#Median with an outlier\nprint(np.median(np.append(alive['Positive_lymph_node'],50)))\n\nprint(np.median(dead['Positive_lymph_node']))\n\nprint(\"\\nQuatitle\")\n\nprint(np.percentile(alive['Positive_lymph_node'], np.arange(0,100,0.25)))\nprint(np.percentile(dead['Positive_lymph_node'],np.arange(0,100,0.25)))\n\nprint(\"\\n90thpercentile\")\nprint(np.percentile(alive['Positive_lymph_node'],90))\nprint(np.percentile(dead['Positive_lymph_node'],90))\n\n","ea9ad27e":"from statsmodels import robust\nprint(\"\\nMedian Absoute Deviation\")\nprint(robust.mad(alive['Positive_lymph_node']))\nprint(robust.mad(dead['Positive_lymph_node']))","505eec5e":"sns.boxplot(x='survival_status',y='Positive_lymph_node', data=df)\nplt.plot()","47b34544":"sns.boxplot(x='survival_status', y='Age', data=df)\nplt.show()","f20e812c":"sns.boxplot(x='survival_status', y='Operation_Year', data=df)\nplt.show()","016cd229":"sns.violinplot(x='survival_status', y='Positive_lymph_node', data=df)\nplt.show()","4527af74":"sns.violinplot(x='survival_status', y='Age', data=df)\nplt.show()","745773fe":"sns.violinplot(x='survival_status', y='Operation_Year', data=df)\nplt.show()","a4c27c23":"fig , axes=plt.subplots(1,3,figsize=(15,5))\nfor idx,feature in enumerate(list(df.columns)[:-1]):\n    sns.violinplot(x='survival_status', y=feature, data=df,ax=axes[idx])\nplt.show()","6673ce80":"sns.jointplot(x='Age',y='Operation_Year', data=df, kind=\"kde\")\nplt.plot()","9efb9148":"# Generate and visualize the correlation matrix\ncorr = df.corr().round(2)\n\n# Mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set figure size\nf, ax = plt.subplots(figsize=(20, 20))\n\n# Define custom colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap\nsns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\n\nplt.tight_layout()","9f0eba52":"plt.figure(figsize=(20,20))\nsns.heatmap(df.corr(), cmap='Blues', annot=True)\nplt.tight_layout()","165f0d1d":"df['survival_status'].value_counts()","d199b27f":"plt.figure(figsize=(10,5))\nsns.countplot(x=df['survival_status'])\nplt.show()","f736ad03":"X=df.drop(['survival_status'], axis=1)\ny=df['survival_status']","0a5dadcf":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.3, random_state=7)","8b8df8d2":"from IPython.display import Image\nImage(\"..\/input\/logistic-regression\/logistic.jpg\")","5ee3acfd":"Image(\"..\/input\/logistic-regr\/logisticregression.png\")","1962ce42":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix","ca7344ee":"import statsmodels.api as sm\nimport statsmodels.formula.api as smf","d81cbb52":"lr=LogisticRegression()\nlr.fit(X_train, y_train)","94a5b261":"y_pred=lr.predict(X_train)","4610e2a9":"from sklearn import metrics","83ecc0d7":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","420e07ed":"sns.distplot(y_train-y_pred)\nplt.xlabel(\"Residual\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Histogram of residula\")\nplt.show()","7cfd0a20":"# Predicting the Test data with model \ny_test_pred=lr.predict(X_test)","87b5b9b2":"lr_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",lr_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","22f12d52":"cfm=confusion_matrix(y_test, y_test_pred)\ntrueNegative=cfm[0][0]\nfalsePossitive=cfm[0][1]\nfalse_negative=cfm[1][0]\ntruePositive=cfm[1][1]\n\nprint(\"Confusion Matrix\", cfm)\nprint(\"true negative\", trueNegative)\nprint(\"False Positive\", falsePossitive)\nprint(\"false Negative\", false_negative)\nprint(\"True Positive\", truePositive)\n","394b0b62":"print(\"correct prediction\", \n      round((trueNegative+truePositive)\/len(y_test_pred)*100, 1),'%')","61696ff9":"cfm_df=pd.DataFrame(cfm, range(2), range(2))\nplt.figure(figsize=(10,10))\nsns.heatmap(cfm_df, cmap='Reds', annot=True)\nplt.show()","0ada219d":"pd.crosstab(y_test, y_test_pred, rownames=['True'], colnames=['Predicted'], margins=True)","48c30e90":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","88fda261":"y_test_pred_prob=lr.predict_proba(X_test)[:,1]\n","18a1a8a7":"y_test_pred_prob","a35b7f16":"from sklearn.metrics import roc_curve\n","a0c2af30":"metrics.roc_auc_score(y_test, y_test_pred_prob)","e8dd5d98":"fpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)","c1df211d":"plt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","5fd234ed":"no_skill=len(y==1)\/len(y)\ny_test_prob=lr.predict_proba(X_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Logistic Regression\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","d96ae79a":"from xgboost import XGBClassifier\nxgb=XGBClassifier()\nxgb.fit(X_train, y_train)","5deba9e4":"y_pred=xgb.predict(X_train)","6b9dce44":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","6893ce12":"# Predicting the Test data with model \ny_test_pred=xgb.predict(X_test)","a876aba2":"xgb_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",xgb_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","4406d036":"cfm=confusion_matrix(y_test, y_test_pred)\ntrueNegative=cfm[0][0]\nfalsePossitive=cfm[0][1]\nfalse_negative=cfm[1][0]\ntruePositive=cfm[1][1]\nprint(\"Confusion Matrix\", cfm)\nprint(\"true negative\", trueNegative)\nprint(\"False Positive\", falsePossitive)\nprint(\"false Negative\", false_negative)\nprint(\"True Positive\", truePositive)\n","1879f74f":"print(\"correct prediction\", \n      round((trueNegative+truePositive)\/len(y_test_pred)*100, 1),'%')","ce235250":"z_df=pd.DataFrame(cfm, range(2), range(2))\nplt.figure(figsize=(10,10))\nsns.heatmap(z_df, cmap='Reds', annot=True)","02e69de8":"print(classification_report(y_test, y_test_pred))","89bb8ec4":"y_test_pred_prob=xgb.predict_proba(X_test)[:,1]","1402dddf":"from sklearn.metrics import roc_curve\nfpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='XGBoost')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC \")\nplt.show()","7e56d1e8":"no_skill=len(y==1)\/len(y)\ny_test_prob=xgb.predict_proba(X_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"XGBoost Classifier\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","415bed6b":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier()\nrfc.fit(X_train, y_train)","0fbe6c5f":"y_pred=rfc.predict(X_train)","ac8c77a1":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","3a6495ca":"# Predicting the Test data with model \ny_test_pred=rfc.predict(X_test)","8bc79c27":"rfc_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",rfc_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","f7502431":"cfm=confusion_matrix(y_test, y_test_pred)\ntrueNegative=cfm[0][0]\nfalsePossitive=cfm[0][1]\nfalse_negative=cfm[1][0]\ntruePositive=cfm[1][1]\nprint(\"Confusion Matrix\", cfm)\n\nprint(\"true negative\", trueNegative)\nprint(\"False Positive\", falsePossitive)\nprint(\"false Negative\", false_negative)\nprint(\"True Positive\", truePositive)\n","43cd4c61":"print(\"correct prediction\", \n      round((trueNegative+truePositive)\/len(y_test_pred)*100, 1),'%')","de79d6c6":"print(classification_report(y_test, y_test_pred))","9df62d54":"cfm_df=pd.DataFrame(cfm, range(2), range(2))\nplt.figure(figsize=(10,10))\nsns.heatmap(cfm_df, cmap='Reds', annot=True)","3f79937b":"y_test_pred_prob=xgb.predict_proba(X_test)[:,1]","ebd131eb":"from sklearn.metrics import roc_curve\nfpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Random Forest')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC \")\nplt.show()","17fd7cf8":"no_skill=len(y==1)\/len(y)\ny_test_prob=rfc.predict_proba(X_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Random Forest Classifier\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","73b092ba":"print(\"Logistic Regression\", lr_acc*100)\nprint(\"XGBosst\", xgb_acc*100)\nprint(\"Random Forest\", rfc_acc*100)","80e5df44":"from IPython.display import Image\nImage(\"..\/input\/thank-you\/download.jpg\", width=1000, height=1000)","dce8fbc1":"# Violin Plot","1ac4935f":"# Model Evaluation for Test dataset","31a7907c":"# Observations:\n\nFrom both the tables we can observe that almost for all the features the statistics are similar except for positive_lymph_nodes.\n\nThe mean(average) of positive_lymph_nodes is more for people who died within 5 years than people who have survived for more than 5 years\n\nFrom the observation of CDFs, we can infer that patients above 46 axillary nodes detected can be considered as dead within 5 years. So,People having less number of positive_lymph_node have survived.","8805e6c6":"# XGBoost classification","c2fdbb54":"# Divide the data set in two according to the label Survival status \n# Alive means status=1 and dead means status =2","99a27ade":"# Contour plot","e286f775":"Histogram, PDF","92318cc4":"**Obs**\nSurvival rate is hight as lmph node is zero","e2371d34":"**Age Vs Possitive Lymph Node**","0a05e850":"* Converting the Possitive as 1 and negative as 0\n* 1 as 1 and 2 as 0","62f417e2":"# Logistic Regression ","5e0ec317":"> Observation:\n\n* The number of positive lymph nodes of the survivors is highly densed from 0 to 5.\n* Almost 80% of the patients have less than or equal to 5 positive lymph survived more than 5 years.\n* From box plots and violin plots, we can say that more no of patients who are dead have age between 46-62,year between 59-65 and the patients who survived have age between 42-60, year between 60-66.","ac8ef88d":"# Dataset -Description\n* **Age**- Age of the patients those are sufferening from the Cancer.\n* **Operation-Year**- When the operation started \n* **Positive_lymph_node**- Positive Lymph Node Ratio as an Indicator of Prognosis and Local Tumor Clearance in N3 Gastric Cancer\n* **survival_status**- It is binary class. 1 means \"**Survive**\" and 0 means \"**Dead**\"","13bd239f":"# Median, Percentile, Quantile, IQR, MAD","690de55b":"**The median absolute deviation is a measure of statistical dispersion. Moreover, the MAD is a robust statistic, being more resilient to outliers in a data set than the standard deviation. In the standard deviation, the distances from the mean are squared, so large deviations are weighted more heavily, and thus outliers can heavily influence it. In the MAD, the deviations of a small number of outliers are irrelevant.**","3dab102e":"**UNIVARIATE ANALYSIS**","1c5239d2":"**Pair Plot**","5a11f985":"# Correlation Matrix","fcff2ce2":"# Mean, Variance and Std-dev ","63b113bc":"# Recall-Precision Curve \n* Precision-Recall Curves and AUC\n* It is calculated as the number of true positives divided by the total number of true positives and false positives.\n* >Precision = TruePositives \/ (TruePositives + FalsePositives) Recall = TruePositives \/ (TruePositives + FalseNegatives)","662ebc16":"# Alive statics","bed76db0":"2-D Scatter plot with color-coding for each survival status type\/class.","461c2245":"# Random Forest Classifier","83b118cb":"**Observation(s)**:\n\n* Data contains values and columns name are missing in the dataset.\n* Need to add column data in dataset.\n* Column names can be found in column metadata tab in Kaggle.","799cb483":"# Observation: There are more number of people who have undergone operation during the year 1959 - 1964 period and between the ages 42 - 60.\n\n","d123e1f9":"# Box plot and Whiskers","31fbe180":"# Precision Recall Curve","40b81555":"**BI-VARIATE ANALYSIS**","50713590":"# Heat Map","cbcf30c4":"**name the columns as given below**","533f4770":"# Observation:\n\n* From the above PDFs(Univariate analysis) both Age and Operation_Year are not good features for useful insights as the distibution is more similar for both people who survived and also dead.\n* \n* positive_lymph_nodes is the only feature that is useful to know about the survival status of patients as there is difference between the distributions for both classes(labels). From that distibution we can infer that most survival patients have fallen in to zero positive_lymph_nodes.\n* \n* From the year distribution, we can observe that people who didnt survive suddenly rise and fall in between 1958 and 1960. More number of people are not survived in year of operation of 1965","bb4d0dd0":"**Observations**:\n\n* It seems most of the patients have 0 positive lypmh nodes detected.\n* Here we clearly see that blue points are not seperated from orange points.\n* So, by looking this 2-D scatter plot between 'Age' and 'positive_lymph_nodes' we cannot make any decision regarding patient's survival.\n* Therefore, we have to check all combination\/pair of features to make good classification\/decision.\n* Number of Combinations of features : 3C2 = 3 (excluding class-attribute 'Survival')\n* Now, for these combination to analyse,Pair-Plot concept is used","e081a56a":"**When lymph nodes are free, or clear, of cancer, the test results are negative. If lymph nodes have some cancer cells in them, they are called positive. Your pathology report will tell you how many lymph nodes were removed, and of those, how many tested positive for the presence of cancer cells**","d8f208a0":"\"\"\"\nBox plot takes a less space and visually represents the five number summary of the data points in a box. \nThe outliers are displayed as points outside the box.\n1. Q1 - 1.5*IQR\n2. Q1 (25th percentile)\n3. Q2 (50th percentile or median)\n4. Q3 (75th percentile)\n5. Q3 + 1.5*IQR\nInter Quartile Range = Q3 -Q1","9c02661a":"**Objective:**\nTo predict whether a patient will survive after 5 years or not based upon the patient's age,his\/her operation_year and the number of positive lymph nodes","a6dd7069":"# Dead statics","95bf8c7f":"cfm_df=pd.DataFrame(cfm, range(2), range(2))\nplt.figure(figsize=(10,10))\nsns.heatmap(cfm_df, cmap='Reds', annot=True)","8df3bc81":"# Mode Evaluation of Test dataset","b11e4d68":"# Conclusions:\n* Logistic Regression works well with this kind of the dataset\n* There are 306 observations with 4 features in the data set.\n* It is an imbalanced dataset with-\n*            a. 225 patients belonging to status 1, those who survived for 5 years and longer and\n*            b. 81 patients belonging to status 2, those who survived for less than 5 years.\n* Using scatter plot(Bi-variate analysis) -\n*            a. Most of the people have zero positive_lymph_nodes.\n*            b. We cannot distinguish between the people who survived and who didn't survive.\n* Using Pair-plot concept(Bi-variate analysis)-\n*            a. positive_lymph_nodes VERSUS Age is the useful plot to atleast get the insight that most people who survived have 0 postive lymph nodes detected.\n*            b. Age and Operation_Year have overlapping curves which makes difficult for classifying the survival status.\n*            c. but we cannot distinguish the data easily with the help of these plots as most of them are overlapping.                          \n* Using PDFs(Uni-variate Analysis)-\n*            a.  both Age and Operation_Year are not good features for useful insights as the distibution is more similar for both people who survived and also dead.\n*            b. positive_lymph_nodes is the only feature that is useful to know about the survival status of patients as there is difference between the distributions for both classes(labels). From that distibution we can infer that most survival patients have fallen in to zero positive_lymph_nodes.\n*            c. More number of people are not survived in year of operation of 1965.\n* Using CDFs(Uni-variate analysis)-\n*            a. We can observe that almost for all the features the statistics are similar except for positive_lymph_nodes.\n*            b. We can infer that patients above 46 axillary nodes detected can be considered as dead within 5 years. So,People having less number of positive_lymph_node have survived over 5 years.\n*         The mean(average) of positive_lymph_nodes is more for people who died within 5 years than people who have survived for more than 5 years.\n* Mean age of patients who survived is 52 years and who didn't survive is 54 years.\n* Using Box plot and Violin plots-\n*            a. The number of positive lymph nodes of the survivors is highly densed from 0 to 5.\n*            b. Almost 80% of the patients have less than or equal to 5 positive lymph survived more than 5 years.\n*            c. From box plots and violin plots, we can say that more no of patients who are dead have age between 46-62,year between 59-65 and the patients who survived have age between 42-60, year between 60-66. \n* Using Contour plot-\n*            a. There are more number of people who have undergone operation during the year 1959 - 1964 period and between the ages 42 - 60.\n* If you like you can follow and review my other kernels. Here is my profile\n[Rabi SIngh](https:\/\/www.kaggle.com\/jurk06\/code)","4ec8d712":"# Confusion Matrix","e94c86b4":"**2-D Scatter Plot**","41f8397f":"# Metrics calculation ","8883fd2d":"# Table of Content:-\n* **Panda** \n* **Numpy** \n* **Matplotlib**\n* **Seaborn**\n* **Correlation Matri**x\n* **Heatmap**\n* **ROC-Curv**e\n* **Precision Curve** \n* **Logistic Regression** \n* **XGBoost Classifier**\n* **Random Forest Classifie**r\n* **Conclusion**"}}