{"cell_type":{"70eac7b7":"code","a3e635c4":"code","5b7285cd":"code","e00153a2":"code","98f08fa9":"code","02fefc60":"code","7b6c864a":"code","3f224573":"code","81a4a905":"code","4afb7db3":"code","2d188320":"code","23a90aba":"code","847204de":"code","d91c923f":"code","d660fe51":"code","f28aeadc":"markdown"},"source":{"70eac7b7":"import torch\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.transforms import ToTensor\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import random_split\n\nimport pandas as pd\nimport seaborn as sns\nimport gc\nimport time\nfrom tqdm import tqdm\nimport datatable as dt\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nfrom sklearn.model_selection import StratifiedKFold,KFold\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\n\nimport os\nimport random\n\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n\nfrom colorama import Fore, Back, Style\nred = Fore.RED\ngrn = Fore.GREEN\nblu = Fore.BLUE\nylw = Fore.YELLOW\nwht = Fore.WHITE\n\nimport plotly.express as ex\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\nfrom xgboost import XGBRegressor\nimport xgboost as xgb\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error\nfrom catboost import CatBoostRegressor, Pool, CatBoost","a3e635c4":"config = {\n    'SEED' : 43,\n    'FOLDS' : 5\n}","5b7285cd":"path = '..\/input\/commonlitreadabilityprize\/'\ntrain = pd.read_csv(path + 'train.csv')\ntest = pd.read_csv(path + 'test.csv')\nsample = pd.read_csv(path + 'sample_submission.csv')\n\ny_train = train['target'].to_numpy()\n\nnbins = 12\ntrain.loc[:,'bins'] = pd.cut(train['target'],nbins,labels=False)\nbins = train.bins.to_numpy()","e00153a2":"def seed_everything(seed=43):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    config['SEED'] = seed\nseed_everything(43)","98f08fa9":"class CommonLitDataset:\n    def __init__(self, excerpt, tokenizer, max_len):\n        self.excerpt = excerpt\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.excerpt)\n\n    def __getitem__(self, item):\n        text = str(self.excerpt[item])\n        inputs = self.tokenizer(\n            text, \n            max_length=self.max_len, \n            padding=\"max_length\", \n            truncation=True\n        )\n\n        ids = inputs[\"input_ids\"]\n        mask = inputs[\"attention_mask\"]\n\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"attention_mask\": torch.tensor(mask, dtype=torch.long),\n        }","02fefc60":"def generateEmbeddings(data,model_path, max_len = 256):\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n    model = AutoModel.from_pretrained(model_path)\n    tokenizer = AutoTokenizer.from_pretrained(model_path)\n\n    model.to(device)\n    model.eval()\n    \n    dataset = CommonLitDataset(excerpt=data.excerpt.values, tokenizer=tokenizer, max_len=max_len)\n    data_loader = torch.utils.data.DataLoader(\n        dataset, batch_size=32, num_workers=4, pin_memory=True, shuffle=False\n    )\n\n    embeddings = list()\n    \n    with torch.no_grad():\n        for i, inputs in tqdm(enumerate(data_loader)):\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n            outputs = model(**inputs)\n            outputs = outputs[0][:,0].detach().cpu().numpy()\n            embeddings.extend(outputs)\n\n    torch.cuda.empty_cache()\n    return np.array(embeddings)","7b6c864a":"trainEmbeddings1 = generateEmbeddings(train, \"..\/input\/experimental-models-clrp\/CLRPmodel_0_1\")\ntestEmbeddings1 = generateEmbeddings(test, \"..\/input\/experimental-models-clrp\/CLRPmodel_0_1\/\")\n\ntrainEmbeddings2 = generateEmbeddings(train, \"..\/input\/experimental-models-clrp\/CLRPmodel_1_1\/\")\ntestEmbeddings2 = generateEmbeddings(test, \"..\/input\/experimental-models-clrp\/CLRPmodel_1_1\/\")\n\ntrainEmbeddings3 = generateEmbeddings(train, \"..\/input\/experimental-models-clrp\/CLRPmodel_2_1\/\")\ntestEmbeddings3 = generateEmbeddings(test, \"..\/input\/experimental-models-clrp\/CLRPmodel_2_1\/\")\n\ntrainEmbeddings4 = generateEmbeddings(train, \"..\/input\/experimental-models-clrp\/CLRPmodel_3_2\/\")\ntestEmbeddings4 = generateEmbeddings(test, \"..\/input\/experimental-models-clrp\/CLRPmodel_3_2\/\")\n\ntrainEmbeddings5 = generateEmbeddings(train, \"..\/input\/experimental-models-clrp\/CLRPmodel_4_5\/\")\ntestEmbeddings5 = generateEmbeddings(test, \"..\/input\/experimental-models-clrp\/CLRPmodel_4_5\/\")\n\ntrainEmbeddings6 = generateEmbeddings(train, \"..\/input\/experimental-models-clrp\/CLRPmodel_5_4\/\")\ntestEmbeddings6 = generateEmbeddings(test, \"..\/input\/experimental-models-clrp\/CLRPmodel_5_4\/\")\n\ntrainEmbeddings7 = generateEmbeddings(train, \"..\/input\/experimental-models-clrp\/CLRPmodel_6_5\/\")\ntestEmbeddings7 = generateEmbeddings(test, \"..\/input\/experimental-models-clrp\/CLRPmodel_6_5\/\")\n\ntrainEmbeddings8 = generateEmbeddings(train, \"..\/input\/experimental-models-clrp\/CLRPmodel_7_3\/\")\ntestEmbeddings8 = generateEmbeddings(test, \"..\/input\/experimental-models-clrp\/CLRPmodel_7_3\/\")\n\ntrainEmbeddings9 = generateEmbeddings(train, \"..\/input\/experimental-models-clrp\/CLRPmodel_8_4\/\")\ntestEmbeddings9 = generateEmbeddings(test, \"..\/input\/experimental-models-clrp\/CLRPmodel_8_4\/\")\n\ntrainEmbeddings10 = generateEmbeddings(train, \"..\/input\/experimental-models-clrp\/CLRPmodel_9_3\/\")\ntestEmbeddings10 = generateEmbeddings(test, \"..\/input\/experimental-models-clrp\/CLRPmodel_9_3\/\")","3f224573":"def rmse_score(targets,outputs):\n    return np.sqrt(mean_squared_error(targets,outputs))","81a4a905":"import lightgbm as lgb","4afb7db3":"lgbm_params = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': ['RMSE'],\n    'learning_rate': 0.005,\n    \"num_leaves\": 64,  \n    \"max_bin\": 256,\n    \"num_iterations\" : 2000,\n    \"early_stopping_rounds\" : 100,\n    \"force_col_wise\" : True\n#     \"num_threads\" : 16,\n    \n}","2d188320":"def generatePreds(train_embeds, test_embeds, mod = 'lgbm', y_train = y_train, bins=bins, folds=config[\"FOLDS\"]):\n    kFold = kfold = StratifiedKFold(n_splits=folds)\n    rmse = list()\n    preds = np.zeros((test_embeds.shape[0]))\n    for fold , (train_idx,valid_idx) in enumerate(kFold.split(X=train_embeds,y=bins)):\n        train_x,valid_x = train_embeds[train_idx],train_embeds[valid_idx]\n        train_y,valid_y = y_train[train_idx],y_train[valid_idx]\n        \n        if mod == 'lgbm':\n            lgb_train = lgb.Dataset(train_x, train_y)\n            lgb_valid = lgb.Dataset(valid_x, valid_y, reference = lgb_train)\n            model = lgb.train(lgbm_params, lgb_train, valid_sets=[lgb_train, lgb_valid], verbose_eval=100)\n        elif mod == 'svm':\n            model = SVR(C=10,kernel='rbf',gamma='auto')\n            model.fit(train_x,train_y)\n            \n        pred = model.predict(valid_x)\n        score = rmse_score(valid_y, pred)\n        print(f'Fold: {fold} , RMSE : {score}')\n        rmse.append(score)\n        preds += model.predict(test_embeds)\n    \n    print(f'RMSE mean : {np.mean(rmse)}')\n    return np.array(preds) \/ folds","23a90aba":"preds1 = generatePreds(trainEmbeddings1,testEmbeddings1)\npreds2 = generatePreds(trainEmbeddings2,testEmbeddings2)\npreds3 = generatePreds(trainEmbeddings3,testEmbeddings3)\npreds4 = generatePreds(trainEmbeddings4,testEmbeddings4)\npreds5 = generatePreds(trainEmbeddings5,testEmbeddings5)\npreds6 = generatePreds(trainEmbeddings6,testEmbeddings6)\npreds7 = generatePreds(trainEmbeddings7,testEmbeddings7)\npreds8 = generatePreds(trainEmbeddings8,testEmbeddings8)\npreds9 = generatePreds(trainEmbeddings9,testEmbeddings9)\npreds10 = generatePreds(trainEmbeddings10,testEmbeddings10)","847204de":"preds = (preds1 + preds2 + preds3 + preds4 + preds5 + preds6 + preds7 + preds8 + preds9 + preds10) \/ 10","d91c923f":"submission = pd.read_csv(\"..\/input\/commonlitreadabilityprize\/sample_submission.csv\")\nsubmission.target = preds\nsubmission.to_csv(\"submission.csv\", index=False)","d660fe51":"submission","f28aeadc":"# Final Fitting"}}