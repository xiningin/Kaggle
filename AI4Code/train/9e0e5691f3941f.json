{"cell_type":{"b6583026":"code","45f637e5":"code","27390a11":"code","38df0a91":"code","17d009ba":"code","fc66a3c7":"code","6a7cdc2c":"code","a075d2ec":"code","94c7fd74":"code","62872940":"code","3baffedf":"code","e28f5e0f":"code","fd6ae4e0":"code","6b7b4bbc":"markdown","d34c6f3f":"markdown","7d6aab04":"markdown","20b2bc20":"markdown","13067712":"markdown","2c098cf3":"markdown","728e636f":"markdown","4010c220":"markdown","93621116":"markdown","afc5f4d4":"markdown"},"source":{"b6583026":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","45f637e5":"import seaborn as sns\nimport nltk\nnltk.download()","27390a11":"from nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer \nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier","38df0a91":"filename = '\/kaggle\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv'\ndf = pd.read_csv(filename)\ndf.head()","17d009ba":"df['sentiment'].value_counts()","fc66a3c7":"sns.countplot(x = df['sentiment'])","6a7cdc2c":"df['review'][0]","a075d2ec":"ps = PorterStemmer()\nfilter_review = []\nfor sentence in df['review']:\n    filter_sentence = []\n    sentence = sentence .replace('<br \/><br \/>',\" \")\n    sentence = re.sub('[^a-zA-Z]',' ',sentence)\n    sentence = sentence.lower()\n    for word in nltk.word_tokenize(sentence) :\n        if word not in stopwords.words('english'):\n            filter_sentence.append(ps.stem(word))\n    filter_sentence = ' '.join(word for word in filter_sentence)\n    filter_review.append(filter_sentence)","94c7fd74":"#Lets view the transformed text\nfilter_review[1:3]","62872940":"tf = TfidfVectorizer(max_features = 10000)\nX = tf.fit_transform(filter_review).todense()\n","3baffedf":"df['sentiment'] = df['sentiment'].apply(lambda x : 0 if x=='positive' else 1)","e28f5e0f":"X_train,X_test,Y_train,Y_test = train_test_split(X,df['sentiment'],test_size = 0.3,random_state = 90)","fd6ae4e0":"#Logistic Regression\nlm = LogisticRegression()\nlm.fit(X_train,Y_train)\nlm_score = lm.score(X_test,Y_test)\n#RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_train,Y_train)\nrf_score = rf.score(X_test,Y_test)\nprint('LogisticRegression: '+ str(lm_score) +'\\nRandom Forest: '+ str(rf_score))\n","6b7b4bbc":"# Creating Test and Training Data","d34c6f3f":"Now we are done with the text pre processing and we will now proceed for vectorization","7d6aab04":"# Dataset Properties\n* It has 2 columns Review and sentiment.\n* Review has textual data and will be the input to the model.\n* There are 50,000 reviews in the dataset\n* Sentiment has two values positive or negative and will be the output to the model.\n* There are 25,000 positive and negative reviews each.\n* Dataset has a uniform distribution.","20b2bc20":"**Now that we have completed Text preprocessing , we need to perform vectorization as we can't apply models on textual data.\n* We will use TFIDF for vectorization of review column**\n* Convert sentiment column ","13067712":"# Applying Model","2c098cf3":"# Data Preprocessing","728e636f":"*After looking at the text , following tasks to be performed*\n* Everything in lower case\n* Removing punctuation marks.\n* Removing all stopwords\n* Removing break statements\n* Using *PorterStemmer* to convert words back to their root stems.\nI'll first test above on 1 string alone and then loop it over.","4010c220":"# **1)Lets understand the dataset**","93621116":"# IMPORTS","afc5f4d4":"*Since our output is also in text form lets convert it into numerical form*"}}