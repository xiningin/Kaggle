{"cell_type":{"7773416f":"code","96ed1f95":"code","6ca2019c":"code","cf8fa29b":"code","f2b71a8b":"code","a85babaa":"code","7223d61f":"code","65a11375":"code","d2a5bd26":"code","856bf34e":"code","3040e2ba":"code","6b829881":"code","c157ba29":"code","12c54ce4":"code","2accf09e":"markdown","533f82bb":"markdown","31cb1899":"markdown"},"source":{"7773416f":"import sys\nprint(sys.path)","96ed1f95":"import sys\nsys.path.append(\"\/kaggle\/working\/chaii-packages\")","6ca2019c":"%%bash\nmkdir \/kaggle\/working\/chaii-packages\ncd \/kaggle\/working\/chaii-packages\ncp \/kaggle\/input\/external-packages\/* \/kaggle\/working\/chaii-packages\nmv .\/botocore-1.21.17.xyz .\/botocore-1.21.17.tar.gz\nmv .\/jieba-0.42.1.xyz .\/jieba-0.42.1.tar.gz\nmv .\/seqeval-1.2.2.xyz .\/seqeval-1.2.2.tar.gz\n# Copy saved model from training notebook to \/kaggle\/working directory\nmkdir \/kaggle\/working\/saved-model\n# Change this line to the name of your trained model\ncp -r \/kaggle\/input\/local-saved-model\/* \/kaggle\/working\/saved-model","cf8fa29b":"%%bash\n# First, we need to install required dependencies. Instead of running their install_tools.sh, run this cell, which has a few minor modifications. This may take a few minutes to run.\n\ncd \/kaggle\/input\/ # Optional but recommended\ncd modified-xtreme\/\n# Copyright 2020 Google and DeepMind.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nREPO=$PWD\necho $REPO\nLIB=$REPO\/third_party\nmkdir -p $LIB\n\n# install latest transformer\ncd $LIB\ncd transformers\npip install . --no-index --find-links \/kaggle\/working\/chaii-packages\/\ncd $LIB\n\n# pip install seqeval --no-index --find-links \/kaggle\/working\/chaii-packages\/\n# pip install tensorboardx --no-index --find-links \/kaggle\/working\/chaii-packages\/\n# pip install tqdm --no-index --find-links \/kaggle\/working\/chaii-packages\/\n\n# # install XLM tokenizer\n# pip install sacremoses --no-index --find-links \/kaggle\/working\/chaii-packages\/\n# pip install pythainlp --no-index --find-links \/kaggle\/working\/chaii-packages\/\n# pip install jieba --no-index --find-links \/kaggle\/working\/chaii-packages\/\n\n# #git clone https:\/\/github.com\/neubig\/kytea.git && cd kytea\n# #.\/configure --prefix=${CONDA_PREFIX}\n# #make && make install\n# pip install kytea --no-index --find-links \/kaggle\/working\/chaii-packages\/","f2b71a8b":"# Load ChAII dataset\nimport json\nimport random\nimport pandas as pd\nfrom pathlib import Path\n\npd.set_option(\"display.max_rows\", 20, \"display.max_columns\", None)\n\ndata_path = Path(\"\/kaggle\/input\/chaii-hindi-and-tamil-question-answering\/\")\njson_dicts = []\n\ndef get_dataframe(file_path):\n    df = pd.DataFrame()\n    with open(file_path,'r') as f:\n        df = pd.read_csv(f)\n    df = df.astype(str)\n    df = df.apply(lambda x: x.str.strip())\n    return df\n\ntest_data = get_dataframe(data_path \/ \"test.csv\")\ntest_data","a85babaa":"# Convert TyDiQA format to a QA format\ndef convert_to_qa_format_kaggle(row):\n    answer = {}\n    try:\n        answer[\"text\"] = row[\"answer_text\"]\n        answer[\"answer_start\"] = int(row[\"answer_start\"])\n    except:\n        answer[\"text\"] = ''\n        answer[\"answer_start\"] = -1\n    qa_json = {\n        \"title\": \"\",\n        \"paragraphs\": [\n            {\n                \"context\": row[\"context\"],\n                \"qas\": [\n                    {\n                        \"question\": row[\"question\"],\n                        \"id\": row[\"language\"] + '-' + str(row[\"id\"]),\n                        \"answers\": [answer]\n                    }\n                ]\n            }\n        ],\n    }\n    \n    return qa_json\n\n# Process one language at a time\n# Here chaii_data is a pandas dataframe\ndef get_qa_data_from_kaggle_format(chaii_data, language):\n    qa_data = {\"data\":[], \"version\":f\"chaii_{language}\"}\n    for index, row in chaii_data.iterrows():\n        if row[\"language\"] == language:\n            qa_datapoint = convert_to_qa_format_kaggle(row)\n            qa_data[\"data\"].append(qa_datapoint)\n\n    print(\"QA (SQuAD) format:\")\n    print(qa_data[\"data\"][0])\n    return qa_data\n\nhi_test_qa_data = get_qa_data_from_kaggle_format(test_data, 'hindi')\nta_test_qa_data = get_qa_data_from_kaggle_format(test_data, 'tamil')","7223d61f":"# Splitting data into train and dev and saving converted QA formats\ndef split_data(test_qa_data, lang_code):\n    split_data_path = Path(\"\/kaggle\/working\/chaii_data\/\")\n    !mkdir \/kaggle\/working\/chaii_data\n\n    test_qa_data_datapoints = test_qa_data[\"data\"]\n    test_qa_data = {\"data\": test_qa_data_datapoints, \"version\":f\"chaii_{lang_code}_test\"}\n\n    with open(split_data_path \/ f\"test.{lang_code}.qa.jsonl\",'w') as f:\n      json.dump(test_qa_data,f)\n\n    print(f\"{lang_code} Test data size: %d\" % len(test_qa_data_datapoints))\n    \nsplit_data(hi_test_qa_data, 'hi')\nsplit_data(ta_test_qa_data, 'ta')","65a11375":"# If you trained the model on a local machine and want to evaluate you can use this cell\n# predict.sh ${MODEL_PATH} ${TASK} ${DATA_DIR} ${PREDICTIONS_DIR} ${MODEL} ${MODEL_TYPE} ${GPU} ${PREDICT_FILE_NAME}\n# predict_qa.sh ${MODEL} ${MODEL_TYPE} ${MODEL_PATH} ${TGT} ${GPU} ${DATA_DIR} ${PREDICTIONS_DIR} ${PREDICT_FILE_NAME}\n# Predict on train to see performance\n\n!bash \/kaggle\/input\/modified-xtreme\/predict.sh \"\/kaggle\/input\/local-saved-model\/chaii_hi\/bert-base-multilingual-cased_LR3e-5_EPOCH10.0_maxlen384\" \\\n      chaii_hi \"\/kaggle\/working\/chaii_data\/\" \"\/kaggle\/working\/eval_dir\/predictions\/\" \"bert-base-multilingual-cased\" \"bert\" 0 test.hi.qa.jsonl\n","d2a5bd26":"# Tamil Inference\n\n!bash \/kaggle\/input\/modified-xtreme\/predict.sh \"\/kaggle\/input\/local-saved-model\/chaii_ta\/bert-base-multilingual-cased_LR3e-5_EPOCH10.0_maxlen384\" \\\n      chaii_ta \"\/kaggle\/working\/chaii_data\/\" \"\/kaggle\/working\/eval_dir\/predictions\/\" \"bert-base-multilingual-cased\" \"bert\" 0 test.ta.qa.jsonl","856bf34e":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) \/ (len(a) + len(b) - len(c))\n\ndef evaluate(lang_code):\n    # For evaluating the predictions, we will use our custom script which uses jaccard mean \n    import json\n#     with open(f\"\/kaggle\/working\/outputs-temp\/chaii_{lang_code}\/bert-base-multilingual-cased_LR3e-5_EPOCH2.0_maxlen384\/predictions_{lang_code}_.json\") as f:\n#       preds = json.load(f)\n    with open(f\"\/kaggle\/working\/eval_dir\/predictions\/predictions_{lang_code}_.json\") as f:\n        preds = json.load(f)\n\n    with open(f\"\/kaggle\/working\/chaii_data\/test.{lang_code}.qa.jsonl\") as f:\n        dev_data = json.load(f)\n    \n    submission_preds = [{'id':k.split('-')[1], 'PredictionString': v} for k, v in preds.items()]\n    \n    # write submissions file\n    df_ = pd.DataFrame.from_dict(submission_preds)\n    df_.to_csv(f'\/kaggle\/working\/eval_dir\/chaii_{lang_code}_submission.csv', index=False)\n    \n    from pprint import pprint\n    jaccard_mean = 0\n    dev_answer_pair_matches = []\n    for d in dev_data['data']:\n        for para in d['paragraphs']:\n            for qa in para['qas']:\n                sample_jaccard = jaccard(qa['answers'][0]['text'], preds[qa['id']])\n                jaccard_mean += sample_jaccard\n                dev_answer_pair_matches.append({'context':para['context'],'question':qa['question'],'gold_answer':qa['answers'],'mbert_pred':preds[qa['id']],'id':qa['id']})\n\n    jaccard_mean \/= len(dev_answer_pair_matches)\n    print(f\"Jaccard Mean for chaii_{lang_code}: {jaccard_mean}\")\n    \n    return dev_answer_pair_matches\n    \n    \n    \ntest_answer_pair_matches_hi = evaluate(\"hi\")\ntest_answer_pair_matches_ta = evaluate(\"ta\")","3040e2ba":"%%bash\n# Delete existing submission.csv file\nrm \/kaggle\/working\/submission.csv\n# Combine predictions for all languages into a single submission.csv file\ncd \/kaggle\/working\/eval_dir\ncat chaii_hi_submission.csv >> \/kaggle\/working\/submission.csv\ntail -n +2 chaii_ta_submission.csv >> \/kaggle\/working\/submission.csv","6b829881":"!wc -l \/kaggle\/working\/eval_dir\/chaii_hi_submission.csv\n!wc -l \/kaggle\/working\/eval_dir\/chaii_ta_submission.csv\n!wc -l \/kaggle\/working\/submission.csv","c157ba29":"def write_dev_answer_pair_matches(test_answer_pair_matches, lang_code):\n    #Matches in predictions\n    correct_ans = [d for d in test_answer_pair_matches if d['mbert_pred']==d['gold_answer'][0]['text']]\n    with open(f'\/kaggle\/working\/eval_dir\/correct_chaii_{lang_code}_mbert.txt','w',encoding='utf-8') as f:\n      for c in correct_ans:\n        f.write(f\"id:{c['id']}\\n\")\n        f.write(f\"context:{c['context']}\\n\")\n        f.write(f\"question:{c['question']}\\n\")\n        f.write(f\"gold_answer:{c['gold_answer'][0]['text']}\\n\")\n        f.write(f\"mbert_pred:{c['mbert_pred']}\\n\")\n        f.write(\"\\n\\n\")\n        \n    #Mismatches in predictions\n    wrong_ans = [d for d in test_answer_pair_matches if d['mbert_pred']!=d['gold_answer'][0]['text']]\n    with open(f'\/kaggle\/working\/eval_dir\/wrong_chaii_{lang_code}_mbert.txt','w',encoding='utf-8') as f:\n      for c in wrong_ans:\n        f.write(f\"id:{c['id']}\\n\")\n        f.write(f\"context:{c['context']}\\n\")\n        f.write(f\"question:{c['question']}\\n\")\n        f.write(f\"gold_answer:{c['gold_answer'][0]['text']}\\n\")\n        f.write(f\"mbert_pred:{c['mbert_pred']}\\n\")\n        f.write(\"\\n\\n\")\n    \n    return correct_ans, wrong_ans\n        \ncorrect_ans, wrong_ans = write_dev_answer_pair_matches(test_answer_pair_matches_hi, \"hi\")\ncorrect_ans, wrong_ans = write_dev_answer_pair_matches(test_answer_pair_matches_ta, \"ta\")","12c54ce4":"len(correct_ans),len(wrong_ans)","2accf09e":"# ChAII inference notebook\n\nThis notebook is a continuation of the [ChAII-1 Starter Notebook](https:\/\/www.kaggle.com\/deeplearning10\/chaii-1-starter-notebook?scriptVersionId=71032838) and will be used for inference and submitting to the competition.\n\nWe will use the output of the starter notebook, i.e. trained model as an input of this notebook. To do this, click on Add data button, select Notebook Output Files option and upload from ChAII-1 Starter Notebook. \nYou can also upload the model trained locally and use it for inference. ","533f82bb":"## Inference and Evaluation","31cb1899":"## Data preparation"}}