{"cell_type":{"c3ef217d":"code","4ec537f3":"code","62ec416a":"code","655a15c7":"code","dd03770c":"code","55ecfd5a":"code","17b363fb":"code","fe4675b9":"code","b3b3da0f":"code","21cf3a31":"code","93692953":"code","44e0405a":"code","ee91718d":"code","757b1209":"code","c3a1e4e2":"code","ac21557d":"code","a9e92c45":"code","f1b7bde1":"code","1852e048":"code","633fa33d":"code","5b2d0bd8":"code","b0d7e490":"code","c8d3557e":"code","51db57c2":"code","3acad386":"code","c5732197":"code","240f03de":"code","58b9e3ea":"code","9e8e1f32":"code","586b530f":"code","a3f68959":"code","3511441c":"code","ca4bd8fa":"code","dcdb3194":"code","001e9a27":"code","21baf090":"code","a3b888db":"code","320399fa":"code","dc8ab032":"code","a2eb0366":"code","8a5b2f37":"markdown","a63fb477":"markdown","e8464def":"markdown","f81f58b1":"markdown","716f6edf":"markdown","c3924946":"markdown","9fc9b540":"markdown","9e9e9468":"markdown","5e540d7d":"markdown","b0c39902":"markdown","867bc363":"markdown","778a9d73":"markdown","46d35aeb":"markdown","3f71105c":"markdown","16763e3f":"markdown","6a41a58a":"markdown","3777eab5":"markdown","731aac68":"markdown","850a600d":"markdown","4f2d5c72":"markdown","d73c6ba1":"markdown","e388244f":"markdown","c5ec9893":"markdown","f27f179c":"markdown"},"source":{"c3ef217d":"# Common lib\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\n# Utils\nfrom tqdm import tqdm\nimport datetime\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split\n\n# Tensorflow\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.layers import InputLayer\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, Flatten, AveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.metrics import AUC, TruePositives, TrueNegatives, FalsePositives, FalseNegatives\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\nfrom tensorflow.keras.layers.experimental.preprocessing import Resizing, Rescaling\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2","4ec537f3":"# Init variables\ninput_folder = '..\/input\/coronahack-chest-xraydataset'\ntest_img_folder = os.path.join(input_folder, 'Coronahack-Chest-XRay-Dataset', 'Coronahack-Chest-XRay-Dataset', 'test')\ntrain_img_folder = os.path.join(input_folder, 'Coronahack-Chest-XRay-Dataset', 'Coronahack-Chest-XRay-Dataset', 'train')\nmetadata_df = pd.read_csv(os.path.join(input_folder, 'Chest_xray_Corona_Metadata.csv'), index_col=0)","62ec416a":"metadata_df.describe()","655a15c7":"# Split to train & test set\ntrain_df = metadata_df[metadata_df.Dataset_type == 'TRAIN'].reset_index(drop=True)\ntest_df = metadata_df[metadata_df.Dataset_type == 'TEST'].reset_index(drop=True)\n\n# Check train_df size + test_df size == metadata_df size\nassert train_df.size + test_df.size == metadata_df.size\n\nprint(f'Shape of train data: { train_df.shape }')\nprint(f'Shape of test data: { test_df.shape }')\n\ntrain_df.sample(10)","dd03770c":"def count_plot_null_value(dataset, xticks):\n    fig = plt.figure()\n    if dataset == 'train':\n        dataset_df = train_df\n    else:\n        dataset_df = test_df\n    ax = sns.barplot(x=dataset_df.isnull().sum(), \n                     y=dataset_df.columns,\n                     order=['X_ray_image_name', 'Dataset_type', 'Label', 'Label_1_Virus_category', 'Label_2_Virus_category'],\n                     palette=\"Blues\")\n    ax.set_xticks(xticks)\n    ax.set_ylabel('Column')\n    ax.set_xlabel('Count')\n    ax.set_title(f'Number of null values of each column in { dataset } data')\n\n    # Add text to chart\n    for p in ax.patches:\n        ax.annotate(int(p.get_width()),\n                    (p.get_width() + 10, p.get_y() + p.get_height() \/ 2),\n                    va='center',\n                    size=12)\n    plt.show()\n        \ncount_plot_null_value('train', np.arange(0, 7000, 1000))\ncount_plot_null_value('test', np.arange(0, 750, 100))","55ecfd5a":"# fill na\ntrain_df.fillna('unknow', inplace=True)\ntest_df.fillna('unknow', inplace=True)","17b363fb":"def count_plot_value_in_column(column, dataset, ax, order=None):\n    ax = sns.countplot(y=column, \n                       data=dataset, \n                       palette='Blues',\n                       ax=ax,\n                       order=order)\n    return ax\n\ndef add_annotate_to_chart(ax):\n    for p in ax.patches:\n        ax.annotate(int(p.get_width()),\n                    (p.get_width() + 10, p.get_y() + p.get_height() \/ 2),\n                    va='center',\n                    size=12)","fe4675b9":"fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n\n# Train set\nax = count_plot_value_in_column('Label', train_df, axs[0])\nax.set_xticks(np.arange(0, 5000, 500))\nax.set_title('Train set')\nadd_annotate_to_chart(ax)\n\n# Test set\nax = count_plot_value_in_column('Label', test_df, axs[1])\nax.set_xticks(np.arange(0, 500, 50))\nax.set_title('Test set')\nadd_annotate_to_chart(ax)\n\nfig.suptitle('Number of each values in Label column', size=15)\nplt.show()","b3b3da0f":"train_normal = train_df[train_df.Label == 'Normal']\ntest_normal = test_df[test_df.Label == 'Normal']\n\ntrain_normal_with_unknow = train_normal[(train_normal.Label_1_Virus_category == 'unknow') & (train_normal.Label_2_Virus_category == 'unknow')]\ntest_normal_with_unknow = test_normal[(test_normal.Label_1_Virus_category == 'unknow') & (test_normal.Label_2_Virus_category == 'unknow')]\n\ntotal_normal_cases = train_normal.shape[0] + test_normal.shape[0]\ntotal_normal_with_unknow_cases = train_normal_with_unknow.shape[0] + test_normal_with_unknow.shape[0]\n\nprint(f'Label = Normal: { total_normal_cases }')\nprint(f\"Label = Normal & Label_1 = unknow & Label_2 = unknow: { total_normal_with_unknow_cases }\")\n\nassert total_normal_cases + total_normal_with_unknow_cases","21cf3a31":"train_pnemonia = train_df[~train_df.index.isin(train_normal.index)]\ntest_pnemonia = test_df[~test_df.index.isin(test_normal.index)]\n\nassert train_pnemonia.shape[0] + train_normal.shape[0] == train_df.shape[0]\nassert test_pnemonia.shape[0] + test_normal.shape[0] == test_df.shape[0]","93692953":"fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n\n# Train pnemonia\nax = count_plot_value_in_column('Label_1_Virus_category', \n                                train_pnemonia, \n                                axs[0])\nax.set_xticks(np.arange(0, 3500, 500))\nax.set_title('Pnemonia cases in train set')\nadd_annotate_to_chart(ax)\n\n# Test pnemonia\nax = count_plot_value_in_column('Label_1_Virus_category',\n                                test_pnemonia,\n                                axs[1])\nax.set_xticks(np.arange(0, 350, 50))\nax.set_title('Pnemonia cases in test set')\nadd_annotate_to_chart(ax)\n\nfig.suptitle('Number of each values in Label_1_Virus_category', size=15)\n\nplt.show()","44e0405a":"fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n\n# Train pnemonia\nax = count_plot_value_in_column('Label_2_Virus_category', \n                                train_pnemonia, \n                                axs[0])\nax.set_xticks(np.arange(0, 5000, 500))\nax.set_title('Pnemonia cases in train set')\nadd_annotate_to_chart(ax)\n\n# Test pnemonia \nax = count_plot_value_in_column('Label_2_Virus_category', test_pnemonia, axs[1])\nax.set_xticks(np.arange(0, 500, 50))\nax.set_title('Pnemonia cases in test set')\nadd_annotate_to_chart(ax)\n\nfig.suptitle('Number of each values in Label_2_Virus_category', size=15)\n\nplt.show()","ee91718d":"assert os.path.exists(train_img_folder)\nassert os.path.exists(test_img_folder)","757b1209":"random_train_img = train_df.sample(6).reset_index(drop=True)\n\nfig = plt.figure(figsize=(15, 15))\nfor i in range(6):\n    ax = plt.subplot(3, 2, i+1)\n    img_path = os.path.join(train_img_folder, random_train_img.loc[i, 'X_ray_image_name'])\n    label = random_train_img.loc[i, 'Label']\n    img = load_img(img_path)\n    ax.axis('off')\n    ax.set_title(label, size=15)\n    ax.imshow(img)\n    \nplt.show()","c3a1e4e2":"normal_case_img_name = train_df[train_df.Label == 'Normal'].X_ray_image_name[:5]\n\nfig, axs = plt.subplots(5, 2, figsize=(15, 20))\nfor idx, img_name in enumerate(normal_case_img_name):\n    # Plot image\n    img_path = os.path.join(train_img_folder, img_name)\n    img = load_img(img_path)\n    img = img.resize((700, 700))\n    axs[idx, 0].imshow(img)\n    axs[idx, 0].axis('off')\n    # Plot image histogram\n    img_arr = img_to_array(img)\n    axs[idx, 1].hist(img_arr.ravel(), 256)\n    \naxs[0, 0].set_title('Image')    \naxs[0, 1].set_title('Image histogram')\nfig.suptitle('Normal case', size = 15)\nplt.show()","ac21557d":"pnemonia_case_img_name = train_df[train_df.Label == 'Pnemonia'].X_ray_image_name[:5]\n\nfig, axs = plt.subplots(5, 2, figsize=(15, 20))\nfor idx, img_name in enumerate(pnemonia_case_img_name):\n    # Plot image\n    img_path = os.path.join(train_img_folder, img_name)\n    img = load_img(img_path)\n    img = img.resize((700, 700))\n    axs[idx, 0].imshow(img)\n    axs[idx, 0].axis('off')\n    # Plot image histogram\n    img_arr = img_to_array(img)\n    axs[idx, 1].hist(img_arr.ravel(), 256)\n\naxs[0, 0].set_title('Image')\naxs[0, 1].set_title('Image histogram')\nfig.suptitle('Pnemonia cases', size=15)\nplt.show()","a9e92c45":"def load_img_path(quantity, dataset):\n    if dataset == 'train':\n        df = train_df\n        folder = train_img_folder\n    elif dataset == 'test':\n        df = test_df\n        folder = test_img_folder\n    if quantity <= 0:\n        return None\n    img_names = df.X_ray_image_name[:quantity]\n    img_paths = [os.path.join(folder, img_name) for img_name in img_names]\n    return img_paths\n\ndef img_path_to_array(img_paths):\n    img_arr = [img_to_array(load_img(img_path).resize((500, 500))) for img_path in tqdm(img_paths)]\n    img_arr = np.array(img_arr)\n    return img_arr\n\ndef show_img(img):\n    plt.imshow(array_to_img(img))\n    \ndef show_multi_img(img_arr):\n    fig = plt.figure(figsize=(20,10))\n    for i in range(len(img_arr)):\n        plt.subplot(len(img_arr) \/ 4, 4, i+1)\n        show_img(img_arr[i])\n        plt.axis('off')","f1b7bde1":"train_datagen = ImageDataGenerator(rotation_range=10,\n                              brightness_range=(0.1, 1.2),\n                              horizontal_flip=True,\n                              zoom_range=[0.75, 1])\ntest_datagen = ImageDataGenerator()","1852e048":"img_paths = load_img_path(100, 'train')\nimg_arr = img_path_to_array(img_paths)","633fa33d":"aug_imgs = train_datagen.flow(img_arr ,batch_size=8)\nprint(f'Number of batches: { len(aug_imgs) }')","5b2d0bd8":"show_multi_img(aug_imgs[0])","b0d7e490":"train_df, valid_df = train_test_split(train_df, test_size=0.2, shuffle=True, random_state=42)","c8d3557e":"train_batches = train_datagen.flow_from_dataframe(train_df,\n                                             directory=train_img_folder,\n                                             x_col='X_ray_image_name',\n                                             y_col='Label',\n                                             class_mode='binary',\n                                             batch_size=128)\n\nvalid_batches = test_datagen.flow_from_dataframe(valid_df,\n                                             directory=train_img_folder,\n                                             x_col='X_ray_image_name',\n                                             y_col='Label',\n                                             class_mode='binary',\n                                             batch_size=128)\n\ntest_batches = test_datagen.flow_from_dataframe(test_df,\n                                            directory=test_img_folder,\n                                            x_col='X_ray_image_name',\n                                            y_col='Label',\n                                            class_mode='binary',\n                                            batch_size=8,\n                                            shuffle=False)","51db57c2":"print(f'Label encode: { train_batches.class_indices }')","3acad386":"train_batches_series = pd.Series(train_batches.classes)\nvalid_batches_series = pd.Series(valid_batches.classes)\n\nprint(f'Value count in train_batches: \\n{ train_batches_series.value_counts() }')\nprint(f'Value count in valid_batches: \\n{ valid_batches_series.value_counts() }')","c5732197":"def create_dir(dir_path):\n    if not os.path.exists(dir_path):\n        os.mkdir(dir_path)\n        \ncreate_dir('models')","240f03de":"# When export model, these preprocessing layers will be saved along with the rest of model\nresize_and_rescale = Sequential([\n    Resizing(227, 227),\n    Rescaling(1.\/255)\n])","58b9e3ea":"metrics = [TruePositives(name='TP'),\n           TrueNegatives(name='TN'),\n           FalsePositives(name='FP'),\n           FalseNegatives(name='FN'),\n           AUC(curve='PR', name='AUC')]","9e8e1f32":"lamb = 0.9\n\nmodel = Sequential([\n    # Preprocessing layer\n    resize_and_rescale,\n    \n    InputLayer((227, 227, 3)),\n    \n    # 1st layer\n    Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu', kernel_regularizer=l2(lamb), name='conv1'),\n    MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'),\n    BatchNormalization(),\n    \n    # 2nd layer\n    Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(lamb), name='conv2'),\n    MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'),\n    BatchNormalization(),\n    \n    # 3rd layer\n    Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(lamb), name='conv3'),\n    BatchNormalization(),\n    \n    # 4th layer\n    Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(lamb), name='conv4'),\n    BatchNormalization(),\n    \n    # 5th layer\n    Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(lamb), name='conv5'),\n    MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'),\n    BatchNormalization(),\n    \n    # Flatten\n    Flatten(),\n    \n    # 6th layer\n    Dense(units=4096, activation='relu'),\n    Dropout(0.5),\n    \n    # 7th layer\n    Dense(units=4096, activation='relu'),\n    Dropout(0.5),\n    \n    # 8th layer (output)\n    Dense(units=1, activation='sigmoid')\n], name='AlexNet')","586b530f":"#Create folder contains model's files\nmodel_dir = 'models\/alexnet'\nmodel_file = 'best_alexnet.hdf5'\ncreate_dir(model_dir)\n\ncheckpoint = ModelCheckpoint(os.path.join(model_dir, model_file),\n                             monitor='val_loss',\n                             verbose=1,\n                             save_best_only=True,\n                             save_weights_only=False)\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                               patience=30,\n                               verbose=1,\n                               restore_best_weights=True)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), \n                              patience=7, min_delta=1e-3, verbose=1, min_lr=1e-7)","a3f68959":"# Initialize TensorBoard\nlog_dir = 'models\/alexnet\/logs' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)","3511441c":"batch_size = 128\nepochs = 200\nlr = 1e-3\n\nmodel.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr), metrics=metrics)\n\ntraining_time_start = datetime.datetime.now()\n\nhistory = model.fit(train_batches,\n                                epochs=epochs,\n                                verbose=1,\n                                callbacks=[checkpoint, early_stopping, reduce_lr, tensorboard_callback],\n                                validation_data=valid_batches,\n                                steps_per_epoch=len(train_batches),\n                                validation_steps=len(valid_batches))\n\ntraining_time_end = datetime.datetime.now()","ca4bd8fa":"total_training_seconds = (training_time_end - training_time_start).seconds\nprint('Total training time: ', str(datetime.timedelta(seconds=total_training_seconds)))","dcdb3194":"history_df = pd.DataFrame(history.history)","001e9a27":"history_df[['loss', 'val_loss']].plot()\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.show()","21baf090":"history_df[['AUC', 'val_AUC']].plot()\nplt.ylabel('AUC')\nplt.xlabel('Epoch')\nplt.show()","a3b888db":"num_of_epochs = history_df.shape[0]\nhalf_epoch = int(num_of_epochs \/ 2)\n\nfirst_half_history = history_df.loc[:half_epoch]\nfirst_title = f'Loss value at epoch 0 - { half_epoch }'\n\nlast_half_history = history_df.loc[half_epoch:len(history_df)]\nlast_title = f'Loss value at epoch { half_epoch } - { len(history_df) }'\n\nhists = [first_half_history, last_half_history]\ntitles = [first_title, last_title]\n\nfor i in range(2):\n    ax = hists[i][['loss', 'val_loss']].plot()\n    ax.set_xlabel('Epoch')\n    ax.set_ylabel('Loss value')\n    ax.set_title(titles[i])\nplt.show()","320399fa":"first_title = f'AUC value at epoch 0 - { half_epoch }'\nlast_title = f'AUC value at epoch { half_epoch } - { len(history_df) }'\n\ntitles = [first_title, last_title]\n\nfor i in range(2):\n    ax = hists[i][['AUC', 'val_AUC']].plot()\n    ax.set_xlabel('Epoch')\n    ax.set_ylabel('AUC value')\n    ax.set_title(titles[i])\nplt.show()","dc8ab032":"evaluate = model.evaluate(test_batches, verbose=1)","a2eb0366":"loss, tp, fp, tn, fn, auc = evaluate[0], evaluate[1], evaluate[2], evaluate[3], evaluate[4], evaluate[5]\nprint(f'Test loss: { loss }')\nprint(f'True positive: { tp }')\nprint(f'False positive: { fp }')\nprint(f'True negative: { tn }')\nprint(f'False negative: { fn }')\nprint('AUC: %.2f' % auc)","8a5b2f37":"## 6.2 Train AlexNet","a63fb477":"# 4. Data augmentation","e8464def":"**Count value in Label_2_Virus_category column**","f81f58b1":"# 6. Build AlexNet","716f6edf":"## Image histogram\n> An image histogram is a type of histogram that acts as a graphical representation of the tonal distribution in a digital image. It plots the number of pixels for each tonal value. By looking at the histogram for a specific image a viewer will be able to judge the entire tonal distribution at a glance.","c3924946":"## 6.1 AlexNet","9fc9b540":"### **Summary**\n\n* Exploring data\n* Visualizing image\n* Data augmentation\n* Preparing data\n* Training AlexNet to classifies images\n* Result\n---> AUC = 97%","9e9e9468":"**Define metrics used for all models**","5e540d7d":"**Define model architecture**","b0c39902":"# 2. Explore data","867bc363":"**Plot images after augmentation**","778a9d73":"**Make sure that all normal cases go with unknow value in Label_1_Virus_category and Label_2_Virus_category**","46d35aeb":"### Inference from charts\n* We have 2 cases that is Pnemonia and Normal case. \n* Pnemonia cases is much more than Normal cases in both train set and test set.\n* All Normal cases is labeled as unknow\/null in Label_1_Virus_category and Label_2_Virus_category.\n* All Pnemonia cases is labeled as bacteria, virus, stress-smoking and dont have any unknow\/null value in Label_1_Virus_category in both train set and test set. \n* In train set, most of pnemonia case is labeled as unknow\/null value (3875\/3944).\n* In test set, all pnemonia case is labels as unknow\/null value.\n* In Label_1_Virus_category, those value are different to much.\n* In Label_2_Virus_category, if we remove all unknow value then we just have 69 sample.\n* Thus we are going to construct a model which classifies Normal and Pnemonia cases.\n* Cause the difference of Pnemonia and Normal cases so that we should use AUC or F1 score to evaluate the goodness of model.","3f71105c":"**Image histogram of 5 Normal cases**","16763e3f":"**Plot random 6 images in train set**","6a41a58a":"**Count number of null values in train and test dataset**","3777eab5":"## 6.4 Evaluate","731aac68":"## 6.3 Plot learning curve","850a600d":"# 5. Prepare data","4f2d5c72":"**Count value in Label column**","d73c6ba1":"**Preprocessing layers**","e388244f":"# 3. Visualize image","c5ec9893":"**Count value in Label_1_Virus_category column**","f27f179c":"# 1. Import libs"}}