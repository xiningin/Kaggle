{"cell_type":{"08499c30":"code","8d4de0ea":"code","b9a97a7a":"code","6e85b16e":"code","9f747334":"code","d0f70396":"code","c28bad67":"code","c292eac6":"code","74bb9d37":"code","76fb7b7f":"code","328b0aff":"code","0d4b5c8d":"code","64c62d34":"code","92d447b6":"code","02fc2f3c":"code","9095691e":"code","913de19c":"code","7d1e9da5":"code","2ba861c0":"code","5bf8e516":"code","a779532e":"code","27882318":"code","bb2d39aa":"code","1185fe80":"code","f41c691b":"code","7b05c9c1":"code","62e93096":"code","56652a70":"code","aca89265":"code","32317dd8":"code","8c3310ca":"code","71243488":"code","00ec8852":"code","752745cd":"code","4568432e":"code","9839c8ba":"code","29b11f97":"code","55cc3370":"code","691a2318":"code","6450006e":"code","9bce10e7":"code","34c6b81c":"code","1b92a2a0":"markdown","7774008a":"markdown","61098054":"markdown","41f55f8d":"markdown","acdd6c51":"markdown","f0c10f47":"markdown","8705bddb":"markdown","437c3350":"markdown","e9d8aa15":"markdown","a48db39d":"markdown","c344c43e":"markdown","a4cc9a06":"markdown"},"source":{"08499c30":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8d4de0ea":"df1=pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\") #train \nprint(df1.shape)\ndf1.head()","b9a97a7a":"df1.drop_duplicates().shape  #==>Pas de ligne dupliqu\u00e9es ","6e85b16e":"df1.info()","9f747334":"df1.describe()","d0f70396":"df2=pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nprint(df2.shape)\ndf2.head()","c28bad67":"df2.drop_duplicates().shape  #==>Pas de ligne dupliqu\u00e9es","c292eac6":"df2.info()","74bb9d37":"df2.describe()","76fb7b7f":"df3=pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")\ndf3.head()","328b0aff":"newdf=pd.get_dummies(df1['Sex']) #Transfrom sex column to new df according to its values\nnewdf.head()","0d4b5c8d":"df1['female']= newdf['female'].tolist()\ndf1['male']=newdf['male'].tolist()\ndf1.head()","64c62d34":"df1['Embarked'].mode()","92d447b6":"#fillna() ne detecte pas missing values:'Na'\nmissing_values=['','NA',None,np.nan]\nmissing=df1['Embarked'].isin(missing_values)\ndf1['Embarked']=df1['Embarked'].mask(missing,df1['Embarked'].mode())","02fc2f3c":"df1.info()","9095691e":"newdf=pd.get_dummies(df1['Embarked']) #Transfrom Embarked column to new df according to its values\nnewdf.head()","913de19c":"df1=df1.drop(\"Embarked\",axis='columns')","7d1e9da5":"df1['C']= newdf['C'].tolist()\ndf1['Q']=newdf['Q'].tolist()\ndf1['S']=newdf['S'].tolist()\ndf1.head()","2ba861c0":"df1['Age']=df1['Age'].fillna(df1['Age'].mean())\ndf1.info()","5bf8e516":"df1=df1.drop(\"PassengerId\",axis='columns')    #drop PassengerId column\ndf1=df1.drop(\"Name\",axis='columns')         #drop Name column\ndf1=df1.drop(\"Sex\",axis='columns')          #drop Sex column\ndf1=df1.drop(\"Ticket\",axis='columns')       #drop Ticket column\ndf1=df1.drop(\"Cabin\",axis='columns')        #drop Cabin column","a779532e":"df1","27882318":"newdf=pd.get_dummies(df2['Sex']) #Transfrom sex column to new df according to its values\nnewdf.head()","bb2d39aa":"df2['female']= newdf['female'].tolist()\ndf2['male']=newdf['male'].tolist()\ndf2.head()","1185fe80":"newdf=pd.get_dummies(df2['Embarked']) #Transfrom Embarked column to new df according to its values\nnewdf.head()","f41c691b":"df2=df2.drop(\"Embarked\",axis='columns')","7b05c9c1":"df2['C']= newdf['C'].tolist()\ndf2['Q']=newdf['Q'].tolist()\ndf2['S']=newdf['S'].tolist()\ndf2.head()","62e93096":"df2['Age']=df2['Age'].fillna(df1['Age'].mean())\ndf2.info()","56652a70":"df2=df2.drop(\"PassengerId\",axis='columns')    #drop PassengerId column\ndf2=df2.drop(\"Name\",axis='columns')           #drop Name column\ndf2=df2.drop(\"Sex\",axis='columns')            #drop Sex column\ndf2=df2.drop(\"Ticket\",axis='columns')         #drop Ticket column\ndf2=df2.drop(\"Cabin\",axis='columns')          #drop Cabin column","aca89265":"df2","32317dd8":"import xgboost","8c3310ca":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","71243488":"df1.shape","00ec8852":"df1.head()","752745cd":"xtrain=df1.loc[:,'Pclass':]\nxtrain","4568432e":"ytrain=df1.loc[:,:'Survived']\nytrain","9839c8ba":"df2","29b11f97":"seed = 7\n#df1:train\n#df2:test\nX=df1.loc[:,'Pclass':]\nY=df1.loc[:,:'Survived']\ntest_size = 0.33\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)","55cc3370":"# fit model no training data\nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)","691a2318":"print(model)","6450006e":"# make predictions for test data\ny_pred = model.predict(X_test)\npredictions = [round(value) for value in y_pred]","9bce10e7":"# evaluate predictions\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","34c6b81c":"len(predictions)","1b92a2a0":"### colonne embarked","7774008a":"### 2.2.2 fill missing values in Age","61098054":"### 2.2.2 fill missing values in Age","41f55f8d":"## 2-preprocessing df1","acdd6c51":"## 2.2 Embarked column ","f0c10f47":"### 2.2.1 fill missing values in Embarked","8705bddb":"### Train the model","437c3350":"### colonne sex","e9d8aa15":"## 1-Lecture des donn\u00e9es","a48db39d":"## Encoding Embarked_column with get_dummies","c344c43e":"## 2.1 Encoding sex_column with get_dummies","a4cc9a06":"## Preporcessing df2"}}