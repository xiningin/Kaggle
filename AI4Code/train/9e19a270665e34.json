{"cell_type":{"379bde47":"code","68b9f20c":"code","4da6a881":"code","834c6ba4":"code","6c95c31d":"code","4eb827bb":"code","99b17561":"code","ec5da48f":"code","e8c7a55b":"code","4984cb89":"code","a0c9bb09":"code","90c774da":"code","3abc9cc1":"code","22369d62":"code","506704a4":"code","bc1bbc39":"code","f53f2947":"code","fdef7ead":"code","16ec5c68":"code","2afcd2e4":"code","71e546f2":"code","1ddfaf99":"code","d8c7ca75":"code","6b4a3d2f":"code","04469606":"code","6e624f8c":"code","84fae269":"code","842a7aa3":"code","15eacf8e":"code","7887efe6":"code","ea62a259":"code","522daad2":"markdown","a8353e23":"markdown","90423b07":"markdown","6e575d77":"markdown","9ffe2091":"markdown","05ac2617":"markdown","74b0b0c2":"markdown","3427fb55":"markdown","06a6fc65":"markdown","4e3ffdb4":"markdown","891972f2":"markdown","5a6aa37e":"markdown","c171c73c":"markdown","087c1692":"markdown"},"source":{"379bde47":"import pandas as pd\nimport os\nimport shutil\nprint(os.listdir(\"..\/input\/Dataset\"))","68b9f20c":"TRAIN_PATH = \"..\/input\/Dataset\/Train\"\nVAL_PATH = \"..\/input\/Dataset\/Val\"","4da6a881":"import numpy as np\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.layers import *\nfrom keras.models import *\nfrom keras.preprocessing import image","834c6ba4":"model = Sequential()\nmodel.add(Conv2D(32,kernel_size=(3,3),activation=\"relu\",input_shape=(224,224,3)))\n\nmodel.add(Conv2D(64,(3,3),activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64,(3,3),activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128,(3,3),activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128,(3,3),activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(64,activation=\"relu\"))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(1,activation=\"sigmoid\"))\n\nmodel.compile(loss=keras.losses.binary_crossentropy,optimizer = \"adam\",metrics=[\"accuracy\"])\n","6c95c31d":"model.summary()","4eb827bb":"train_datagen = image.ImageDataGenerator(\n    rescale = 1.\/255,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True,\n)\ntest_dataset = image.ImageDataGenerator(rescale = 1.\/255)\n","99b17561":"train_generator = train_datagen.flow_from_directory(\n    '..\/input\/Dataset\/Train',\n    target_size = (224,224),\n    batch_size = 32,\n    class_mode = 'binary'\n)","ec5da48f":"train_generator.class_indices","e8c7a55b":"validation_generator = test_dataset.flow_from_directory(\n    '..\/input\/Dataset\/Val',\n    target_size = (224,224),\n    batch_size = 32,\n    class_mode = 'binary'\n)","4984cb89":"hist = model.fit_generator(\n    train_generator,\n    steps_per_epoch = 8,\n    epochs = 10,\n    validation_data = validation_generator,\n    validation_steps = 2\n)","a0c9bb09":"model.save(\"Detection_Covid_19.h5\")","90c774da":"# model.evaluate_generator(train_generator)","3abc9cc1":"# model.evaluate_generator(validation_generator)","22369d62":"model = load_model(\"Detection_Covid_19.h5\")","506704a4":"import os","bc1bbc39":"train_generator.class_indices","f53f2947":"y_actual = []\ny_test = []","fdef7ead":"for i in os.listdir(\"..\/input\/chest-xray-for-covid19-detection\/Dataset\/Val\/Normal\"):\n  img = image.load_img(\"..\/input\/chest-xray-for-covid19-detection\/Dataset\/Val\/Normal\/\"+i,target_size=(224,224,3))\n  img = image.img_to_array(img)\n  img = np.expand_dims(img,axis=0)\n  p = model.predict_classes(img)\n  y_test.append(p[0,0])\n  y_actual.append(1)","16ec5c68":"for i in os.listdir(\"..\/input\/chest-xray-for-covid19-detection\/Dataset\/Val\/\"):\n  img = image.load_img(\"..\/input\/chest-xray-for-covid19-detection\/Dataset\/Val\/Covid\/\"+i,target_size=(224,224,3))\n  img = image.img_to_array(img)\n  img = np.expand_dims(img,axis=0)\n  p = model.predict_classes(img)\n  y_test.append(p[0,0])\n  y_actual.append(0)","2afcd2e4":"y_actual = np.array(y_actual)\ny_test = np.array(y_test)","71e546f2":"from sklearn.metrics import confusion_matrix","1ddfaf99":"cm = confusion_matrix(y_actual,y_test)","d8c7ca75":"import seaborn as sns","6b4a3d2f":"# sns.heatmap(cm,cmap = \"plasma\" , annot=True)","04469606":"import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nclass_names = [\"Covid-19\",\"Normal\"]\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=\"plasma\"):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","6e624f8c":"plt.figure()\nplot_confusion_matrix(cm, classes=class_names,\n                      title='Confusion matrix for Covid-19 Detection',cmap=\"plasma\")\n","84fae269":"\nhistory = hist\nprint(history.history.keys())","842a7aa3":"\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n","15eacf8e":"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","7887efe6":"import numpy as np\n# from google.colab.patches import cv2_imshow\nimport cv2\nfrom keras.preprocessing import image\nxtest_image = image.load_img('Dataset\/Prediction\/ryct.2020200034.fig5-day7.jpeg', target_size = (224, 224,3))\nxtest_image = image.img_to_array(xtest_image)\nxtest_image = np.expand_dims(xtest_image, axis = 0)\nresults = model.predict_classes(xtest_image)\n# training_set.class_indices\nimggg = cv2.imread('Dataset\/Prediction\/ryct.2020200034.fig5-day7.jpeg')\nprint(\"This Xray Image is of positive covid-19 patient\")\nimggg = np.array(imggg)\nimggg = cv2.resize(imggg,(400,400))\nplt.imshow(imggg)\n# cv2_imshow(imggg)\n# print(results)\nif results[0][0] == 0:\n    prediction = 'Positive For Covid-19'\nelse:\n    prediction = 'Negative for Covid-19'\nprint(\"Prediction Of Our Model : \",prediction)","ea62a259":"import numpy as np\n# from google.colab.patches import cv2_imshow\nfrom keras.preprocessing import image\nxtest_image = image.load_img('..\/input\/chest-xray-for-covid19-detection\/Dataset\/Val\/Covid\/16654_1_1.png', target_size = (224, 224,3))\nxtest_image = image.img_to_array(xtest_image)\nxtest_image = np.expand_dims(xtest_image, axis = 0)\nresults = model.predict_classes(xtest_image)\n# training_set.class_indices\n\nimggg = cv2.imread('..\/input\/chest-xray-for-covid19-detection\/Dataset\/Val\/Covid\/16654_1_1.png')\nprint(\"This Xray Image is of Negative covid-19 patient\")\nimggg = np.array(imggg)\nimggg = cv2.resize(imggg,(400,400))\n\nplt.imshow(imggg)\n# cv2_imshow(imggg)\n# print(results)\nif results[0][0] == 0:\n    prediction = 'Positive For Covid-19'\nelse:\n    prediction = 'Negative for Covid-19'\nprint(\"Prediction Of Our Model : \",prediction)","522daad2":"# **Predictions from X-Ray Images**","a8353e23":"# **Confusion Matrix**","90423b07":"# **Importing Required Libraries**","6e575d77":"# **Summarize history for accuracy**","9ffe2091":"# **Train From Scratch**","05ac2617":"# **Building Architecture**\n","74b0b0c2":"## ***Confusion Matrix***","3427fb55":"# **Test Images**","06a6fc65":"## *Loss is very less and accuracy is on point*","4e3ffdb4":"# Load Datasets","891972f2":"# **Fit The Model**","5a6aa37e":"# **List all data in history**","c171c73c":"# **Summarize history for loss**","087c1692":"## *Data Augmentation*"}}