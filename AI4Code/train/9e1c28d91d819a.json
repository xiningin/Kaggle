{"cell_type":{"0ac68c86":"code","dc5501e5":"code","60593dd7":"code","86a04225":"code","9240bb6d":"code","15339316":"code","c5b980ce":"code","f9aeaa40":"code","9738389f":"code","546a7a9e":"code","63d05d34":"code","56724d71":"code","38ffb343":"code","6bbcdf81":"code","d89dc066":"code","e3c59e7c":"code","d8b28d12":"code","591d0014":"code","612d7f05":"code","ae6781cd":"code","d706b4f0":"code","4ead5f9d":"code","51030680":"code","01232358":"code","38c32ab0":"code","57b8338a":"code","e9da50b9":"code","a99a3b55":"code","e6b1d4d8":"code","8e9169d6":"code","274656c2":"code","6e5fd121":"code","e2bbd91b":"code","c16c40e0":"code","7f8558cc":"code","bdc84001":"markdown","9b26746e":"markdown","36b23185":"markdown","3b00747b":"markdown","32dc3d66":"markdown","07693425":"markdown","8ab87fd3":"markdown","ff790021":"markdown","12a493da":"markdown","35f925e7":"markdown"},"source":{"0ac68c86":"import os\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom operator import itemgetter\nfrom collections import OrderedDict\n\nfrom PIL import Image\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import optim,nn\nimport torch.nn.functional as F\nfrom torchvision import transforms as T,models\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision.utils import make_grid\n\npd.options.plotting.backend = \"plotly\"\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","dc5501e5":"data = pd.read_csv('..\/input\/sample\/sample_labels.csv')\ndata.head()","60593dd7":"data['Patient Gender'].value_counts().plot.bar()","86a04225":"data['Patient Age'].apply(lambda x : int(x[1:3])).plot.hist()","9240bb6d":"data['Patient Age'].apply(lambda x : int(x[1:3])).plot.box()","15339316":"data['View Position'].value_counts().plot.bar()","c5b980ce":"pathology_list = ['Cardiomegaly','Emphysema','Effusion','Hernia','Nodule','Pneumothorax','Atelectasis','Pleural_Thickening','Mass','Edema','Consolidation','Infiltration','Fibrosis','Pneumonia']\n\nfor pathology in pathology_list :\n    data[pathology] = data['Finding Labels'].apply(lambda x: 1 if pathology in x else 0)\n    \ndata['No Findings'] = data['Finding Labels'].apply(lambda x: 1 if 'No Finding' in x else 0)","f9aeaa40":"data = data.drop(list(data.iloc[:,1:11].columns.values),axis = 1)\ndata.iloc[:,1:].sum().plot.barh()","9738389f":"data = data.drop(['No Findings'],axis = 1)\ndata.iloc[:,1:].sum().plot.barh()","546a7a9e":"data.iloc[:,1:].mean().plot.barh()","63d05d34":"def compute_class_freqs(labels):\n\n    labels = np.array(labels)\n    N = labels.shape[0]\n\n    positive_frequencies = np.sum(labels, axis = 0) \/ N\n    negative_frequencies = 1 - positive_frequencies\n\n    return positive_frequencies, negative_frequencies","56724d71":"freq_pos,freq_neg = compute_class_freqs(data.iloc[:,1:])","38ffb343":"df = pd.DataFrame({\"Class\": pathology_list, \"Label\": \"Positive\", \"Value\": freq_pos})\ndf = df.append([{\"Class\": pathology_list[l], \"Label\": \"Negative\", \"Value\": v} for l,v in enumerate(freq_neg)], ignore_index=True)\n\nplt.xticks(rotation=90)\nf = sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=df)","6bbcdf81":"pos_weights = freq_neg\nneg_weights = freq_pos\npos_contribution = freq_pos * pos_weights \nneg_contribution = freq_neg * neg_weights","d89dc066":"df = pd.DataFrame({\"Class\": pathology_list, \"Label\": \"Positive\", \"Value\": pos_contribution})\ndf = df.append([{\"Class\": pathology_list[l], \"Label\": \"Negative\", \"Value\": v} for l,v in enumerate(neg_contribution)], ignore_index=True)\n\nplt.xticks(rotation=90)\nf = sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=df)","e3c59e7c":"def weighted_loss(pos_weights, neg_weights, y_pred, y_true, epsilon=1e-7):\n\n    loss = 0.0\n    for i in range(len(pos_weights)):\n        loss_pos = -1 * torch.mean(pos_weights[i] * y_true[:,i] * torch.log(y_pred[:,i] + epsilon))\n        loss_neg = -1 * torch.mean(neg_weights[i] * (1-y_true[:,i]) * torch.log((1-y_pred[:,i]) + epsilon))\n        loss += loss_pos + loss_neg\n    return loss","d8b28d12":"class NIH_Dataset(Dataset):\n\n    def __init__(self, data, img_dir, transform=None):\n        self.data = data\n        self.img_dir = img_dir \n        self.transform = transform \n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_file = self.img_dir + self.data.iloc[:,0][idx]\n        img = Image.open(img_file).convert('RGB')\n        label = np.array(self.data.iloc[:,1:].iloc[idx])\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img,label","591d0014":"data_transform = T.Compose([\n    T.RandomRotation((-20,+20)),\n    T.Resize((224,224)),\n    T.ToTensor(),\n    T.Normalize(mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225])\n])","612d7f05":"trainds = NIH_Dataset(data,\n                      img_dir = '..\/input\/sample\/sample\/sample\/images\/',\n                      transform = data_transform)","ae6781cd":"def deprocess(img):\n    img = img.permute(1,2,0)\n    img = img * torch.Tensor([0.229, 0.224, 0.225]) + torch.Tensor([0.485, 0.456, 0.406])\n    return img","d706b4f0":"image, label = trainds[0]\nclass_labels = list(np.where(label==1)[0])\nplt.imshow(deprocess(image))\nplt.title(itemgetter(*class_labels)(pathology_list));","4ead5f9d":"trainset, validset, testset = random_split(trainds, [5000,303,303])\n\nprint(\"Length of trainset : {}\".format(len(trainset)))\nprint(\"Length of testset : {}\".format(len(testset)))\nprint(\"Length of validset : {}\".format(len(validset)))","51030680":"trainloader = DataLoader(trainset,\n                         batch_size = 32,\n                         shuffle = True)\n\nvalidloader = DataLoader(validset,\n                         batch_size = 32,\n                         shuffle = False)\n\ntestloader = DataLoader(testset,\n                        batch_size = 32,\n                        shuffle = True)","01232358":"model = models.resnet18()\nmodel.load_state_dict(torch.load('..\/input\/pretrained-model-weights-pytorch\/resnet18-5c106cde.pth'))","38c32ab0":"for param in model.parameters():\n    param.requires_grad = False\n\nmodel.fc = nn.Sequential(\n    nn.Linear(512, 14),\n    nn.Sigmoid()\n)\n\nmodel.to(device)","57b8338a":"optimizer = optim.Adam(model.parameters(),\n                       lr = 0.0001)\nschedular = optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n                                                 factor = 0.1,\n                                                 patience = 4)\nepochs = 15\nvalid_loss_min = np.Inf","e9da50b9":"for i in range(epochs):\n\n    train_loss = 0.0\n    valid_loss = 0.0\n    train_acc = 0.0\n    valid_acc = 0.0 \n\n    model.train()\n    for images,labels in tqdm(trainloader):\n        images = images.to(device)\n        labels = labels.to(device)\n\n        ps = model(images)\n        loss = weighted_loss(pos_weights,neg_weights,ps,labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n    avg_train_loss = train_loss \/ len(trainloader)\n\n    model.eval()\n    with torch.no_grad():\n        for images,labels in tqdm(validloader):\n            images = images.to(device)\n            labels = labels.to(device)\n\n            ps = model(images)\n            loss = weighted_loss(pos_weights,neg_weights,ps,labels)\n            valid_loss += loss.item()\n        avg_valid_loss = valid_loss \/ len(validloader)\n\n    schedular.step(avg_valid_loss)\n\n    if avg_valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).   Saving model ...'.format(valid_loss_min,avg_valid_loss))\n        torch.save({\n            'epoch' : i,\n            'model_state_dict' : model.state_dict(),\n            'optimizer_state_dict' : optimizer.state_dict(),\n            'valid_loss_min' : avg_valid_loss\n        },'Pneumonia_model.pt')\n\n        valid_loss_min = avg_valid_loss\n\n    print(\"Epoch : {} Train Loss : {:.6f} \".format(i+1,avg_train_loss))\n    print(\"Epoch : {} Valid Loss : {:.6f} \".format(i+1,avg_valid_loss))","a99a3b55":"def class_accuracy(dataloader, model):\n\n    per_class_accuracy = [0 for i in range(len(pathology_list))]\n    total = 0.0\n\n    with torch.no_grad():\n        for images,labels in dataloader:\n            ps = model(images.to(device))\n            labels = labels.to(device)\n            ps = (ps >= 0.5).float()\n\n            for i in range(ps.shape[1]):\n                x1 = ps[:,i:i+1]\n                x2 = labels[:,i:i+1]\n                per_class_accuracy[i] += int((x1 == x2).sum())\n\n        per_class_accuracy = [(i\/len(dataloader.dataset))*100.0 for i in per_class_accuracy]\n\n    return per_class_accuracy     \n\n\ndef get_acc_data(class_names,acc_list):\n    df = pd.DataFrame(list(zip(class_names, acc_list)), columns =['Labels', 'Acc']) \n    return df ","e6b1d4d8":"print(\"Train Dataset Accuracy Report\")\nacc_list = class_accuracy(trainloader, model)\nget_acc_data(pathology_list,acc_list)","8e9169d6":"print(\"Test Dataset Accuracy Report\")\nacc_list = class_accuracy(testloader, model)\nget_acc_data(pathology_list,acc_list)","274656c2":"print(\"Valid Dataset Accuracy Report\")\nacc_list = class_accuracy(validloader, model)\nget_acc_data(pathology_list,acc_list)","6e5fd121":"def view_classify(img, ps, label):\n\n    class_name = pathology_list\n    classes = np.array(class_name)\n\n    ps = ps.cpu().data.numpy().squeeze()\n    img = deprocess(img)\n    class_labels = list(np.where(label==1)[0])\n\n    if not class_labels :\n        title = 'No Findings'\n    else : \n        title = itemgetter(*class_labels)(class_name)\n\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(8,12), ncols=2)\n    ax1.imshow(img)\n    ax1.set_title('Ground Truth : {}'.format(title))\n    ax1.axis('off')\n    ax2.barh(classes, ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(classes)\n    ax2.set_yticklabels(classes)\n    ax2.set_title('Predicted Class')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()\n\n    return None","e2bbd91b":"image,label = testset[123]\n\nps = model(image.unsqueeze(0).to(device))\n\nview_classify(image,ps,label)","c16c40e0":"image,label = trainset[999]\n\nps = model(image.unsqueeze(0).to(device))\n\nview_classify(image,ps,label)","7f8558cc":"image,label = validset[234]\n\nps = model(image.unsqueeze(0).to(device))\n\nview_classify(image,ps,label)","bdc84001":"# Plot Results","9b26746e":"# Avoid Data Imbalance using Weighted Loss","36b23185":"# Split Dataset and create dataloaders","3b00747b":"# Each Class Accuracy ","32dc3d66":"# Loading Dataset and Applying Transforms","07693425":"# Hi, Welcome to my Kernel \n\nOutline \n\n- EDA\n- Avoid Data Imbalance using Weighted Loss\n- Loading Dataset and Applying Transforms\n- Define Pre-trained Model\n- Train Model\n- Each label Accuracy \n- Plot results","8ab87fd3":"# Train Model ","ff790021":"* To increase the accuracy, you can train the model for more epoch and can also use other pre-trained model.\n\n# Finally, UPVOTE the notebook if you found it useful, feel free in comments","12a493da":"# Define Pre-trained Model","35f925e7":"# EDA"}}