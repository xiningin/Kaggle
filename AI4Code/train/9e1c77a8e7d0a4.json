{"cell_type":{"198b1c66":"code","522ddd47":"code","a9abbdf3":"code","2cc28771":"code","735bfe71":"code","24219a3b":"code","e42a6c73":"code","d6689ce2":"code","4231801e":"code","2ce1faa4":"code","f53d01fa":"code","2c6bb739":"code","9c5157cd":"code","b59648d5":"code","9c97662b":"code","6fae84ed":"code","6e0d9ec8":"code","b83d1d1b":"code","16f4846a":"code","40090115":"code","84c5a869":"code","4d360ff0":"markdown","9ec240c6":"markdown","df75cd14":"markdown","4eae809f":"markdown","a2ff3fbb":"markdown","b8eb1419":"markdown","dd7200b6":"markdown","4e7d4e6f":"markdown","070c3c1b":"markdown","af12e571":"markdown","56fe6817":"markdown","e3f86c71":"markdown","a72e8d4d":"markdown","99270c8b":"markdown","493a9b3e":"markdown","72ae0ff2":"markdown","946a84fc":"markdown","c5b16803":"markdown","60e90ebb":"markdown","576bc893":"markdown","04529a64":"markdown"},"source":{"198b1c66":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n","522ddd47":"pip install pandas","a9abbdf3":"import pandas as pd","2cc28771":"#data = pd.read_csv(r'C:\\...\\PRECIP_HLY_sample_csv.csv')","735bfe71":"#url= 'https:\/\/www1.ncdc.noaa.gov\/pub\/data\/cdo\/samples\/PRECIP_HLY_sample_csv.csv'\n\n#df= pd.read_csv(url)","24219a3b":"data=pd.read_csv('..\/input\/titanic\/train.csv')","e42a6c73":"data.shape","d6689ce2":"data.head(8)","4231801e":"data[['Age','Fare']].describe()","2ce1faa4":"data.columns","f53d01fa":"data.dtypes","2c6bb739":"np_data=data.to_numpy()\nnp_data","9c5157cd":"data.T","b59648d5":"data[7:15]","9c97662b":"data.iloc[1:3,3:7]","6fae84ed":"data.loc[100:110,['Name','Age']]","6e0d9ec8":"data[data['Age']>70]","b83d1d1b":"data[(data['Age']>60) & (data['Sex']=='female')]","16f4846a":"data.dropna(how='any')","40090115":"data.to_csv('titanic.csv')\n\ndata.to_csv(r'C:\\...\\titanic.csv')","84c5a869":"#data=pd.read_csv(r'C:\\...\\file.csv')\n#data['New_Age']=data['Age']+10\n#data.to_csv(r'C:\\...\\file.csv')","4d360ff0":"Alternatively, you can read CSV files from online resources, such as Kaggle or Github by copying the URL address:","9ec240c6":"To work with pandas, we must install it first:","df75cd14":"'describe' method gives us the statistical information of the columns. In this example, I need the statistical description of the Age and Fare columns:","4eae809f":"Then we have to import pandas using the following code:","a2ff3fbb":"In this example, I'm using the titanic dataset which is already uploaded on the Kaggle:","b8eb1419":"another filtering example which filters the female passengers who are older than 60:","dd7200b6":"# **Missing data**\nDrop the rows where at least one element is missing.","4e7d4e6f":"**CSV (Comma Separated Values)** may be a simple file format accustomed to store tabular data, like a spreadsheet or database. CSV file stores tabular data (numbers and text) in plain text. Each line of the file could be a data record. Each record consists of 1 or more fields, separated by commas, the utilization of the comma as a field separator is that the source of the name for this file format.","070c3c1b":"if you'd like to choose the columns by their name, you can use the loc method:","af12e571":"# **Write a CSV File**\nYou can create the file data.csv in your current working directory or the desired address by the following codes:","56fe6817":"**Reading CSV Files**\n\nOnce your data is saved in a CSV file, you\u2019ll likely want to load and use it from time to time. You can do that with the Pandas read_csv() function. you can read the csv file either from your computer or from online resources:\n\nFirst, reading from your a local address:","e3f86c71":"**Filtering**\n\nI'm interested in the row information that the Age values are larger than 70. The following codes help us with filtering the data:","a72e8d4d":"the 'head' method gives some information about the first rows of the dataframe. for example, by setting the head to 8, pandas shows the information of the first 8 rows:","99270c8b":"we can read the csv file change the dataframe values and then update the csv file values by creating a new column:","493a9b3e":"DataFrame.to_numpy() gives a NumPy representation of the underlying data. When you call DataFrame.to_numpy(), pandas will find the NumPy dtype that can hold all of the dtypes in the DataFrame.","72ae0ff2":"the [ ] helps you slice the rows. for instance, data[7:15] slices the rows from the rows indexed from 7 to 14:","946a84fc":"Also, you can use the dtypes method to get the type of the data. for example, in our example, the type of the Fare column is float64:","c5b16803":"we can get the name of the columns by calling the '.columns' method:","60e90ebb":"you can get the shape of the data by the 'shape method. in this case, or data has 891 rows and 12 columns","576bc893":"if you need the information of certain columns, you can use the 'iloc' method. the following code shows the rows 1 and 2 and the columns 3 to 6.","04529a64":"to transpose your data:"}}