{"cell_type":{"4153b1fb":"code","c722e443":"code","e1e62b7d":"code","cafc2cfc":"code","64f4ccae":"code","4841b555":"code","66813f4f":"code","8448eba6":"code","903dbeda":"markdown"},"source":{"4153b1fb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c722e443":"!ls -lhtr \/kaggle\/input\/ubiquant-market-prediction\/train.csv","e1e62b7d":"!ls -lhtr \/kaggle\/input\/ump-train-picklefile\/train.pkl","cafc2cfc":"%%time \ndf_train = pd.read_pickle(\"\/kaggle\/input\/ump-train-picklefile\/train.pkl\")","64f4ccae":"df_train","4841b555":"#df['col'].astype(np.float16)\nfeatures= [f'f_{i}'for i in range(0,300)]\nfor ifeature in features:  ## this will take a few mins but need not repeat it, so its ok to spend \n    df_train[ifeature]=df_train[ifeature].astype(np.float16)","66813f4f":"df_train.to_pickle('skim.pkl')","8448eba6":"!ls -lhtr ","903dbeda":"## Data Loading \n* the training data size if 18 G, so don't try to load using read_csv, it will not work, \n* Instead try to use other methods to load big datasets https:\/\/www.kaggle.com\/rohanrao\/tutorial-on-reading-large-datasets \n* Or even use the existing pickle file, https:\/\/www.kaggle.com\/columbia2131\/ump-train-picklefile (3 GB)\n* In order to further reduce the memory, use float16 instead of float32 for the features. This helps in saving another 1 GB (2 GB instead of ogirinal 18 GB) "}}