{"cell_type":{"05fd4bed":"code","89231ad7":"code","03375aed":"code","baed2500":"code","d9675b3a":"code","ff1045f3":"code","367f6118":"code","52de0bda":"code","db6f9eeb":"code","28d44e63":"code","5f96e2d6":"code","8796210c":"code","6eed6ab9":"code","cb78a11a":"code","7da7fd8c":"code","fe63dc97":"code","c4f7fdfd":"code","c033a492":"code","7210ee77":"code","e020ec3b":"code","2b107d1c":"code","6b762fc9":"code","79fcb9eb":"code","f972dde9":"code","7938f51b":"code","25ad6f83":"code","c4ce7249":"code","d2c6a706":"code","e0571cf7":"markdown","4c0a1df2":"markdown","e25bf1b2":"markdown","dfacfc5c":"markdown","745048ac":"markdown","d91d7a6a":"markdown","401780c8":"markdown","763a2583":"markdown","8e151fd6":"markdown","47e13e59":"markdown","2cac4bbc":"markdown","cf4f49b5":"markdown","31c93f11":"markdown","6ff70975":"markdown","ea065454":"markdown","f8ad09f9":"markdown","869fb2f7":"markdown"},"source":{"05fd4bed":"import pandas as pd\nfrom sklearn import preprocessing\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import make_scorer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.feature_selection import SelectKBest,mutual_info_classif\nfrom sklearn.model_selection import train_test_split","89231ad7":"df=pd.read_csv('..\/input\/adult-dataset\/adult.csv')\ndf.head()","03375aed":"df.info()","baed2500":"df.nunique()","d9675b3a":"for column in df.columns:\n    if len(df.loc[df[column]=='?'])>0:\n        df[column]=df[column].replace('?',np.nan)\ndf['income']=df['income'].replace('<=50K','0')\ndf['income']=df['income'].replace('>50K','1')\ndf['income']=df['income'].apply(int)\ndf.head()\n","ff1045f3":"df.isna().sum()","367f6118":"df=df[df['workclass'].notnull()]\ndf=df[df['occupation'].notnull()]\ndf=df[df['native-country'].notnull()]\ndf.isna().sum()","52de0bda":"df.info()","db6f9eeb":"df.nunique()","28d44e63":"categorical=[]\nnumerical=[]\nfor col in df.columns:\n    if df[col].dtype=='O' and col!='income':\n        categorical.append(col)\n    elif df[col].dtype=='int64' and col!='income':\n        numerical.append(col)\nprint(categorical)\nprint(numerical)","5f96e2d6":"df.describe()","8796210c":"plt.figure(figsize=(12,8))\ncorrelation=df.corr()\nsns.heatmap(correlation,annot=True)","6eed6ab9":"for col in categorical:\n    \n    fig, ax = plt.subplots(1,3,figsize=(16,7))\n    ax[0].tick_params(axis='x', rotation=90)\n    ax[0].set_title('countplot: '+col)\n    sns.countplot(df[col],ax=ax[0])\n    ax[1].tick_params(axis='x', rotation=90)\n    ax[1].set_title('barplot: '+col)\n    sns.barplot(x=df[col],y=df['income'],ax=ax[1])\n    ax[2].tick_params(axis='x', rotation=90)\n    ax[2].set_title('countplot,hue: '+col)\n    sns.countplot(df[col],hue= df['income'],ax=ax[2])","cb78a11a":"plt.figure(figsize=(16,8))\nplt.title('pointplot')\nsns.pointplot(df['age'],df['hours-per-week'])","7da7fd8c":"for col in numerical:\n    fig, ax = plt.subplots(1,2, figsize=(16,8))\n    ax[0].set_title(col+' Distribution')\n    sns.distplot(df[col],ax=ax[0])\n    ax[1].set_title(col+' Distribution')\n    sns.boxplot(df[col],ax=ax[1])","fe63dc97":"df=df[df['age']<78]\ndf=df[df['age']>18]\ndf=df[df['educational-num']>2]\ndf=df[df['hours-per-week']<60]\ndf=df[df['hours-per-week']>30]","c4f7fdfd":"Q1 = df['fnlwgt']. quantile(0.1)\nQ3 = df['fnlwgt']. quantile(0.9)\ndf=df[df['fnlwgt']<Q3]\ndf=df[df['fnlwgt']>Q1]\n","c033a492":"fig, ax = plt.subplots(1,2, figsize=(16,8))\nax[0].set_title('Distribution')\nsns.distplot(df['fnlwgt'],ax=ax[0])\nax[1].set_title('Distribution')\nsns.boxplot(df['fnlwgt'],ax=ax[1])","7210ee77":"df_new=pd.DataFrame()\nfor col in numerical:\n    df_new[col]=df[col]\ndf_new['income']=df['income']","e020ec3b":"plt.figure(figsize=(12,8))\ncorrelation=df_new.corr()\nsns.heatmap(correlation,annot=True)","2b107d1c":"for col in categorical:\n    dummy = pd.get_dummies(df[col], prefix=col+'_')\n    df = pd.merge(\n        left=df,\n        right=dummy,\n        left_index=True,\n        right_index=True,\n    )\n    del(df[col])\ndf.head()","6b762fc9":"from sklearn.preprocessing import MinMaxScaler\nfor col in df.columns:\n    scaler = MinMaxScaler()\n    df[col]=scaler.fit_transform(df[col].values.reshape(-1,1))","79fcb9eb":"df.head()","f972dde9":"X=df.drop(columns=['income'])\ny=df['income']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\n\n\nr=make_scorer(accuracy_score)\n\nfs = SelectKBest(score_func=mutual_info_classif)\n\nclf=SVC()\n\npipe = Pipeline(steps=[('fs',fs), ('clf', clf)])\nk_range = list(range(75,80))\nparam_grid = {\n    'fs__k':k_range,\n    \n    'clf__kernel': ['rbf','linear']\n    \n}\nsearch = GridSearchCV(pipe, param_grid,n_jobs=1,scoring=r,verbose=10)","7938f51b":"search.fit(X_train,y_train)","25ad6f83":"search.best_params_","c4ce7249":"search.score(X_train,y_train)","d2c6a706":"search.score(X_test,y_test)","e0571cf7":"applying the one hot encoding on the categorical columns ","4c0a1df2":"the parameters that maximise the performance of the classification task are \"78\" for the K parameter and \"linear\" for the kernel parameter","e25bf1b2":"# Outliers","dfacfc5c":"separating categorical and numerical values for the analysis and exploration tasks","745048ac":"# Analysis \/ Exploration","d91d7a6a":"# Preprocessing \/ Feature Engineering","401780c8":"The Dataset infos shows that columns does not contain None Values , but that does not mean there is no missing values in the dataset","763a2583":"we had three columns containing the missing values , and a total of 48842 row , and by removing the rows containing missing values we ve got 45222 , it does not seem like a big deal in this example but it is not a good idea to remove all rows containing missing values , it will be better using Knn imputer for example to estimate those values based on similarity , or also replacing them by the most frequent value , because deleting them completely will cause data exhaustion , but for this example we will go on with this","8e151fd6":"Scaling the data using Min Max Scaler ( other scalers could be tried like Standard \/ Robust Scaler )","47e13e59":" 23 age < high hours rate < 60 age","2cac4bbc":"Categorical Values => Binary values for the label column \" income \" \/ \"?\" => None values to reveal the missing values","cf4f49b5":"that was a quick example for adult incomes classifications based on individuals informations , Any feedback on this work would be very grateful, thank you for your attention ! ","31c93f11":"Handling outliers values using quantiles","6ff70975":"to make it quick we applied the parameter tuning task on few values ( two for svc's kernel and five for the feature selector's \"k\" ) , more values could be used to get better results","ea065454":"# Cleaning \/ handling missing values","f8ad09f9":"for the training phase we will be using the support vector classifier as an algorithm and the gridsearchCv function for the parameter tuning task (the \"K\" parameter for the feature selection function \" selectKbest \"  and the \"kernel\" parameter for the SVC model )","869fb2f7":"those were a set of plots showing the relation between categorical columns and the label column, for example in the relationship column we can notice that husbands are constituting the highest proportion and a large class of them are having a good income ( 50k> )  , for the wifes category we can notice the same thing concerning the good income but with a low proportion"}}