{"cell_type":{"f65d2e74":"code","fffa93af":"code","91f2f32c":"code","2caec312":"code","73c7491f":"code","91a8dbe0":"code","a7e0df27":"code","35d4f900":"code","257c7030":"code","fc23a70e":"code","e5956448":"code","1210f5fb":"code","8cd653ed":"code","e3ed1f2d":"code","f4eaf694":"code","76a8c295":"code","1c0337ba":"code","15c73ec8":"code","9f1553d4":"code","6fb653a7":"code","3ae03e4f":"code","c94fce20":"code","5c4bba7e":"code","24e083e0":"code","cbf1f102":"code","6d2ce7e3":"code","633c5f7b":"code","a6ef93fa":"code","80654002":"code","2128c230":"code","a19a078b":"code","c543be8d":"code","fa506076":"code","99a37d9a":"code","776d5445":"code","a7a070be":"code","67238068":"code","bb4c5869":"code","091fd9dd":"code","74f63013":"code","a1cc04f8":"code","f0fe6914":"code","d96cec10":"markdown","be6bc986":"markdown","6ca96968":"markdown","8544753c":"markdown","1e1609ef":"markdown","4f524fbd":"markdown","95f5660c":"markdown","befc5fad":"markdown","8dc2641c":"markdown","bb11e8d8":"markdown","07cdd806":"markdown","77693255":"markdown","e436661c":"markdown","1423b611":"markdown","f820cc33":"markdown","20406033":"markdown"},"source":{"f65d2e74":"# Import libraries \nimport pandas as pd\nimport numpy as np\nimport time\nimport gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nfrom tqdm import tqdm\n\n# Import libraries \n\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\n\n#Classification\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\n\n# Evaluation\nfrom sklearn.metrics import roc_auc_score, accuracy_score\n\n","fffa93af":"# Read Train data\ndata = pd.read_csv('..\/input\/nida-competition1\/train.csv')\n#Preview Train data\ndisplay(data.head())\ndisplay('There is {} observations with {} features'.format(data.shape[0], data.shape[1]))","91f2f32c":"#Read Test data\ntest = pd.read_csv('..\/input\/nida-competition1\/test.csv')\n#Preview Test data\ndisplay(test.head())\ndisplay('There is {} observations with {} features'.format(test.shape[0], test.shape[1]))","2caec312":"# explore train data\nprint('------This is train dataset------')\ndata.info() ","73c7491f":"#Check statistical data\ndata.describe()","91a8dbe0":"# check train data column\nprint('------This is train dataset------')\ndata.columns ","a7e0df27":"# Jobs\nprint('train','Jobs:\\n', data['job'].unique())","35d4f900":"# Status\nprint('train','Marital:\\n', data['marital'].unique(),'\\n')","257c7030":"# Education\nprint('train','Education:\\n', data['education'].unique(),'\\n')","fc23a70e":"# Other related coulmns\nprint('train','Default:\\n', data['default'].unique(),)\nprint('train','Housing:\\n', data['housing'].unique(),)\nprint('train','Loan:\\n', data['loan'].unique(),)","e5956448":"# Find outlier from age\nprint('-----Train dataset-----')\nprint('Max age: ', data['age'].max())\nprint('Min age: ', data['age'].min())\nprint('Null Values: ', data['age'].isnull().any())\nprint('MEAN:', round(data['age'].mean(), 1))\nprint('STD :', round(data['age'].std(), 1))\nprint('CV  :',round(data['age'].std()*100\/data['age'].mean(), 1), ', High middle dispersion')","1210f5fb":"# Train Plot\nfig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (13, 5))\nsns.boxplot(x = ['age'], data= data, orient = 'v', ax = ax1)\nax1.set_xlabel('People Age', fontsize=15)\nax1.set_ylabel('Age', fontsize=15)\nax1.set_title('Age Distribution', fontsize=15)\nax1.tick_params(labelsize=15)\n\nsns.distplot(data['age'], ax = ax2)\nsns.despine(ax = ax2)\nax2.set_xlabel('Age', fontsize=15)\nax2.set_ylabel('Occurence', fontsize=15)\nax2.set_title('Age x Occurence', fontsize=15)\nax2.tick_params(labelsize=15)\n\nplt.subplots_adjust(wspace=0.5)\nplt.tight_layout()","8cd653ed":"# Calculate the outliers:\n  # Interquartile range, IQR = Q3 - Q1\n  # lower 1.5*IQR whisker = Q1 - 1.5 * IQR \n  # Upper 1.5*IQR whisker = Q3 + 1.5 * IQR\n\nUpper = data['age'].quantile(q = 0.75) + 1.5*(data['age'].quantile(q = 0.75) - data['age'].quantile(q = 0.25))    \n    \nprint('Ages above: ', Upper, 'are outliers')\n\n# Outlier - Train\nprint('Client outlier -train')\nprint('Numerber of outliers: ', data[data['age'] > Upper]['age'].count())\nprint('Number of clients: ', len(data))\n# Outliers in %\nprint('Outliers are:', round(data[data['age'] > Upper]['age'].count()*100\/len(data),2), '%','\\n')","e3ed1f2d":"#jobs clients \nfig, ax = plt.subplots()\nfig.set_size_inches(30, 8)\nsns.countplot(x = 'job', data = data)\nax.set_xlabel('Job', fontsize=15)\nax.set_ylabel('Count', fontsize=15)\nax.set_title('Job Distribution - train', fontsize=15)\nax.tick_params(labelsize=15)\nsns.despine()","f4eaf694":"#marital clients\nfig, ax = plt.subplots()\nfig.set_size_inches(10, 5)\nsns.countplot(x = 'marital', data = data)\nax.set_xlabel('Marital', fontsize=15)\nax.set_ylabel('Count', fontsize=15)\nax.set_title('Marital Distribution - train', fontsize=15)\nax.tick_params(labelsize=15)\nsns.despine()","76a8c295":"#education clients \nfig, ax = plt.subplots()\nfig.set_size_inches(20, 5)\nsns.countplot(x = 'education', data = data)\nax.set_xlabel('Education', fontsize=15)\nax.set_ylabel('Count', fontsize=15)\nax.set_title('Education Distribution - train', fontsize=15)\nax.tick_params(labelsize=15)\nsns.despine()","1c0337ba":"# Default\nfig, (ax1, ax2, ax3) = plt.subplots(nrows = 1, ncols = 3, figsize = (20,8))\nsns.countplot(x = 'default', data = data, ax = ax1, order = ['no', 'unknown', 'yes'])\nax1.set_title('Default', fontsize=15)\nax1.set_xlabel('')\nax1.set_ylabel('Count', fontsize=15)\nax1.tick_params(labelsize=15)\n\n# Housing\nsns.countplot(x = 'housing', data = data, ax = ax2, order = ['no', 'unknown', 'yes'])\nax2.set_title('Housing', fontsize=15)\nax2.set_xlabel('')\nax2.set_ylabel('Count', fontsize=15)\nax2.tick_params(labelsize=15)\n\n# Loan\nsns.countplot(x = 'loan', data = data, ax = ax3, order = ['no', 'unknown', 'yes'])\nax3.set_title('Loan', fontsize=15)\nax3.set_xlabel('')\nax3.set_ylabel('Count', fontsize=15)\nax3.tick_params(labelsize=15)\n\nplt.subplots_adjust(wspace=0.25)","15c73ec8":"print(\"Type of Contact: \\n\", data['contact'].unique())\nprint(\"\\nWhich monthis this campaing work: \\n\", data['month'].unique())\nprint(\"\\nWhich days of week this campaing work: \\n\", data['day_of_week'].unique(),'\\n')","9f1553d4":"# Find strang value from duration\nprint('-----Train dataset-----')\nprint('Max duration: ', data['duration'].max())\nprint('Min duration: ', data['duration'].min())\nprint('Null Values: ', data['duration'].isnull().any())\nprint('MEAN:', round(data['duration'].mean(), 1))\nprint('STD :', round(data['duration'].std(), 1))","6fb653a7":"fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (13, 5))\nsns.boxplot(x = 'duration', data = data, orient = 'v', ax = ax1)\nax1.set_xlabel('Calls', fontsize=10)\nax1.set_ylabel('Duration', fontsize=10)\nax1.set_title('Calls Distribution', fontsize=10)\nax1.tick_params(labelsize=10)\n\nsns.distplot(data['duration'], ax = ax2)\nsns.despine(ax = ax2)\nax2.set_xlabel('Duration Calls', fontsize=10)\nax2.set_ylabel('Occurence', fontsize=10)\nax2.set_title('Duration x Ocucurence', fontsize=10)\nax2.tick_params(labelsize=10)\n\nplt.subplots_adjust(wspace=0.5)\nplt.tight_layout() ","3ae03e4f":"Upper = data['duration'].quantile(q = 0.75) + 1.5*(data['duration'].quantile(q = 0.75) - data['duration'].quantile(q = 0.25))    \n    \nprint('Duration above: ', Upper, 'are outliers')\n\n# Outlier - Train\nprint('Client outlier -train')\nprint('Numerber of outliers: ', data[data['duration'] > Upper]['duration'].count())\nprint('Number of clients: ', len(data))\n# Outliers in %\nprint('Outliers are:', round(data[data['duration'] > Upper]['duration'].count()*100\/len(data),2), '%','\\n')","c94fce20":"\nfig, (ax1, ax2, ax3) = plt.subplots(nrows = 1, ncols = 3, figsize = (15,6))\nsns.countplot(data['contact'], ax = ax1)\nax1.set_xlabel('Contact', fontsize = 10)\nax1.set_ylabel('Count', fontsize = 10)\nax1.set_title('Contact Counts')\nax1.tick_params(labelsize=10)\n\nsns.countplot(data['month'], ax = ax2, order = ['mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'])\nax2.set_xlabel('Months', fontsize = 10)\nax2.set_ylabel('')\nax2.set_title('Months Counts')\nax2.tick_params(labelsize=10)\n\nsns.countplot(data['day_of_week'], ax = ax3)\nax3.set_xlabel('Day of Week', fontsize = 10)\nax3.set_ylabel('')\nax3.set_title('Day of Week Counts')\nax3.tick_params(labelsize=10)\n\nplt.subplots_adjust(wspace=0.25)","5c4bba7e":"# Read Train data\ndata = pd.read_csv('..\/input\/nida-competition1\/train.csv')\n#Preview Train data\ndisplay(data.head())\ndisplay('There is {} observations with {} features'.format(data.shape[0], data.shape[1]))","24e083e0":"# Drop meaningless column\ndata_final = data.drop(['default'], axis=1)\ndata_final = data_final.drop(['pdays'], axis=1)","cbf1f102":"# Label encoder order is alphabetical-train\nlabelencoder_X = LabelEncoder()\ndata_final['job']      = labelencoder_X.fit_transform(data_final['job']) \ndata_final['marital']  = labelencoder_X.fit_transform(data_final['marital']) \ndata_final['education']= labelencoder_X.fit_transform(data_final['education'])  \ndata_final['housing']  = labelencoder_X.fit_transform(data_final['housing']) \ndata_final['loan']     = labelencoder_X.fit_transform(data_final['loan']) \ndata_final['contact']     = labelencoder_X.fit_transform(data_final['contact']) \ndata_final['month']       = labelencoder_X.fit_transform(data_final['month']) \ndata_final['day_of_week'] = labelencoder_X.fit_transform(data_final['day_of_week']) \ndata_final['poutcome'] = labelencoder_X.fit_transform(data_final['poutcome']) ","6d2ce7e3":"display(data_final.head())\ndisplay('There is {} observations with {} features'.format(data_final.shape[0], data_final.shape[1]))","633c5f7b":"# Get target variables\ny = pd.get_dummies(data_final['y'], columns = ['y'], prefix = ['y'], drop_first = True)\n\ndata_final = data_final[['age', 'job', 'marital', 'education', 'housing', 'loan',\n                     'contact', 'month', 'day_of_week', 'duration', 'emp.var.rate', 'cons.price.idx', \n                     'cons.conf.idx', 'euribor3m', 'nr.employed', 'campaign', 'previous', 'poutcome']]\ndata_final.shape","a6ef93fa":"# Split train and test set\nX_train, X_test, y_train, y_test = train_test_split(data_final, y, test_size = 0.2, random_state = 101)\n\n# Define K fold\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","80654002":"X_train.head()","2128c230":"# Logistic regression\nlogmodel = LogisticRegression() \nlogmodel.fit(X_train,y_train)\nlogpred = logmodel.predict_proba(X_test)[:,1]\n\nprint(roc_auc_score(y_test,logpred))\nLOG_auc = (cross_val_score(logmodel, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'roc_auc').mean())\nLOG_acc = (cross_val_score(logmodel, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())","a19a078b":"# Choose number of k\n# Define range of neighbors\nneighbors = np.arange(0,25)\n\n# Create empty list that will hold cv scores\ncv_scores = []\n\n# Perform 10-fold cross validation on training set for odd values of k:\nfor k in neighbors:\n    k_value = k + 1\n    knn = KNeighborsClassifier(n_neighbors = k_value, weights = 'uniform', p = 2, metric = 'euclidean')\n    kfold = KFold(n_splits=10, random_state=123)\n    scores = cross_val_score(knn, X_train, y_train, cv = kfold, scoring = 'roc_auc')\n    cv_scores.append(scores.mean()*100)\n\noptimal_k = neighbors[cv_scores.index(max(cv_scores))]\nprint (\"The optimal number of neighbors is %d with %0.1f%%\" % (optimal_k, cv_scores[optimal_k]))\n\nplt.plot(neighbors, cv_scores)\nplt.xlabel('Number of Neighbors K')\nplt.ylabel('Train auc')\nplt.show()","c543be8d":"# KNN based on optimal k\n\nknn = KNeighborsClassifier(n_neighbors = optimal_k)\nknn.fit(X_train, y_train)\nknnpred = knn.predict_proba(X_test)[:,1]\n\nprint(roc_auc_score(y_test,knnpred))\nKNN_auc = (cross_val_score(knn, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'roc_auc').mean())\nKNN_acc = (cross_val_score(knn, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())","fa506076":"# Decision Tree\n\ndtree = DecisionTreeClassifier(criterion ='gini') # criterion = entopy, gini\ndtree.fit(X_train, y_train)\ndtreepred = dtree.predict_proba(X_test)[:,1]\n\nprint(roc_auc_score(y_test,dtreepred))\nDTREE_auc = (cross_val_score(dtree, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'roc_auc').mean())\nDTREE_acc = (cross_val_score(dtree, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())","99a37d9a":"# Random forest \n\nrfc = RandomForestClassifier(n_estimators = 200) \nrfc.fit(X_train, y_train)\nrfcpred = rfc.predict_proba(X_test)[:,1]\n\nprint(roc_auc_score(y_test,rfcpred))\nRFC_auc = (cross_val_score(rfc, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'roc_auc').mean())\nRFC_acc = (cross_val_score(rfc, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())","776d5445":"# Gradient Boosting Classifier\ngbk = GradientBoostingClassifier()\ngbk.fit(X_train, y_train)\ngbkpred = gbk.predict_proba(X_test)[:,1]\n\nprint(roc_auc_score(y_test,gbkpred))\nGBK_auc = (cross_val_score(gbk, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'roc_auc').mean())\nGBK_acc = (cross_val_score(gbk, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())","a7a070be":"# Summary of CV for all models\n\nmodels = pd.DataFrame({\n                'Models': ['Random Forest Classifier', 'Decision Tree Classifier',\n                           'K-Near Neighbors', 'Logistic Model', 'Gradient Boosting'],\n                'Accuracy':  [RFC_acc, DTREE_acc, KNN_acc, LOG_acc,  GBK_acc],\n                'AUC':  [RFC_auc, DTREE_auc, KNN_auc, LOG_auc,  GBK_auc]})\n\nmodels.sort_values(by='AUC', ascending=False)","67238068":"# learning rate\nlearning_rate_list = np.arange(0.01,0.5,0.05)\nacc_list = []\n\nfor i in learning_rate_list:\n    # Gradient Boosting Classifier\n    gbk = GradientBoostingClassifier(learning_rate = i)\n    gbk.fit(X_train, y_train)\n    gbkpred = gbk.predict(X_test)\n    acc_list.append(accuracy_score(y_test, gbkpred)*100)\n\noptimal_learningrate = learning_rate_list[acc_list.index(max(acc_list))]\nprint(optimal_learningrate)","bb4c5869":"# n estimators\nn_estimators = np.arange(100, 1000, 100)\nacc_list = []\n\nfor i in n_estimators:\n    # Gradient Boosting Classifier\n    gbk = GradientBoostingClassifier(n_estimators = i)\n    gbk.fit(X_train, y_train)\n    gbkpred = gbk.predict(X_test)\n    acc_list.append(accuracy_score(y_test, gbkpred)*100)\n\noptimal_n_estimators = n_estimators[acc_list.index(max(acc_list))]\nprint(optimal_n_estimators)","091fd9dd":"# Read Train data\ntest = pd.read_csv('..\/input\/nida-competition1\/test.csv')\ndisplay(test.head())\ndisplay('There is {} observations with {} features'.format(test.shape[0], test.shape[1]))\n\n# Drop meaningless column\ntest_final = test.drop(['default'], axis=1)\ntest_final = test_final.drop(['pdays'], axis=1)\n\n# Label encoder order is alphabetical-train\nlabelencoder_X = LabelEncoder()\ntest_final['job']      = labelencoder_X.fit_transform(test_final['job']) \ntest_final['marital']  = labelencoder_X.fit_transform(test_final['marital']) \ntest_final['education']= labelencoder_X.fit_transform(test_final['education'])  \ntest_final['housing']  = labelencoder_X.fit_transform(test_final['housing']) \ntest_final['loan']     = labelencoder_X.fit_transform(test_final['loan']) \ntest_final['contact']     = labelencoder_X.fit_transform(test_final['contact']) \ntest_final['month']       = labelencoder_X.fit_transform(test_final['month']) \ntest_final['day_of_week'] = labelencoder_X.fit_transform(test_final['day_of_week']) \ntest_final['poutcome'] = labelencoder_X.fit_transform(test_final['poutcome']) \n\ntest_final = test_final[['age', 'job', 'marital', 'education', 'housing', 'loan',\n                     'contact', 'month', 'day_of_week', 'duration', 'emp.var.rate', 'cons.price.idx', \n                     'cons.conf.idx', 'euribor3m', 'nr.employed', 'campaign', 'previous', 'poutcome']]\n\ndisplay(test_final.head())\ndisplay('There is {} observations with {} features'.format(test_final.shape[0], test_final.shape[1]))","74f63013":"mlr = GradientBoostingClassifier(learning_rate = optimal_learningrate, n_estimators = optimal_n_estimators)\nmlr.fit(data_final, y)\ntest_final['y'] = mlr.predict_proba(test_final)[:,1]","a1cc04f8":"print(test_final['y'].head())","f0fe6914":"# Save to csv files\ntest_final.to_csv('test_Final_JJYPP.csv',index=False)","d96cec10":"#### Job","be6bc986":"#### Age","6ca96968":"#### Contact, month, day of week","8544753c":"# Predict Test Set","1e1609ef":"#### Education","4f524fbd":"# Compare model","95f5660c":"#### Marital","befc5fad":"#Model","8dc2641c":"**Please see file attached for presentation**\n\nMEMBER\n\n6310422093 SCAA \u0e19\u0e32\u0e22\u0e2d\u0e20\u0e34\u0e27\u0e31\u0e12\u0e19\u0e4c\n\n6220422015 BA&I \u0e19.\u0e2a.\u0e27\u0e23\u0e23\u0e13\u0e34\u0e14\n\n6220422020 BA&I \u0e19.\u0e2a.\u0e28\u0e38\u0e20\u0e27\u0e14\u0e35\n\n6220422025 BA&I \u0e19.\u0e2a.\u0e1b\u0e23\u0e34\u0e19\u0e14\u0e32\n","bb11e8d8":"# Data preparation for Train Set","07cdd806":"## Part 1 - Client Data","77693255":"# Data preparation for Test Set","e436661c":"## Part 2 contact details","1423b611":"#### Default Housing Loan","f820cc33":"#### Duration","20406033":"# Model Tuning"}}