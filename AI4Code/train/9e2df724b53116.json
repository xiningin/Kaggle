{"cell_type":{"86e0c0ef":"code","388bdf3a":"code","d7f7020d":"code","b982a45a":"code","50f88a47":"code","8165f014":"code","a8793df4":"code","3448d719":"code","186089b8":"code","f72c82cf":"code","b03e5ca9":"code","4790da02":"code","750d2063":"code","59ffb030":"code","ad23b05a":"code","91287305":"code","8bf7d6f3":"code","a58ec1cd":"code","7eed3743":"code","6d4a9743":"code","a7d1606e":"code","37488710":"code","078c87bc":"code","a3b2a7ad":"code","0d42e92c":"code","04b08625":"code","085f6fb2":"code","5201c579":"code","43042e28":"code","81082eae":"markdown","de9620fb":"markdown","3eea8449":"markdown","307a72c6":"markdown","fbcf3914":"markdown","61b24a74":"markdown","3a2851e8":"markdown"},"source":{"86e0c0ef":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nimport lightgbm as lgb\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","388bdf3a":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv', na_values=[\"n\/a\", \"na\", \"--\"])\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","d7f7020d":"train.head()","b982a45a":"cols = train.select_dtypes(include='object').columns\nfor col in cols:\n    ratio = len(train[col].value_counts()) \/ len(train)\n    if ratio < 0.05:\n        train[col] = train[col].astype('category')","50f88a47":"train.dtypes","8165f014":"# Any missing values?\ntrain.isnull().values.any()","a8793df4":"# Total missing values % for each feature\nnp.round(train.isnull().sum()* 100 \/ len(train))","3448d719":"#Explore Cabin feature\nprint(train['Cabin'].value_counts())","186089b8":"# drop columns with %30 missing values\nthresh = len(train) * 0.7\ntrain.dropna(axis=1, thresh=thresh, inplace=True)","f72c82cf":"# Total missing values for each feature\ntrain.isnull().sum()","b03e5ca9":"#explore age stats\ntrain.Age.describe()","4790da02":"# replace missing age values with median\nage_med = train['Age'].median()\ntrain['Age'].fillna(age_med, inplace=True)\n\n# replace missing Embarked with mode\nimport statistics as st\nemb_mode = st.mode(train['Embarked'])\ntrain['Embarked'].fillna(emb_mode, inplace=True)","750d2063":"# Total missing values for each feature\ntrain.isnull().sum()","59ffb030":"# Summarize Train data\ntrain.describe()","ad23b05a":"#Take a look at the first 5 rows of clean data\ntrain.head()","91287305":"sns.set(rc={'figure.figsize':(12,8)})\nsns.set_palette(\"Paired\", 10)","8bf7d6f3":"train['Alive'] = np.where(train['Survived']==0, \"No\",\"Yes\")\nsns.catplot(x=\"Alive\", kind=\"count\", hue=\"Sex\", data=train);","a58ec1cd":"sns.catplot(x=\"Sex\", kind=\"count\", data=train);","7eed3743":"sns.catplot(x=\"Sex\", y=\"Survived\", hue=\"Pclass\", kind=\"bar\", data=train);","6d4a9743":"sns.catplot(x=\"Sex\", y=\"Survived\", hue=\"Embarked\", kind=\"bar\", data=train);","a7d1606e":"sns.distplot(train['Age']);","37488710":"plt.figure(figsize=(16, 6))\nheatmap = sns.heatmap(train.corr(), vmin=-1, vmax=1, annot=True, cmap='coolwarm')\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':18}, pad=12);\nplt.show();","078c87bc":"features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n\n#Encode categorical features\ntrain['Embarked'] = LabelEncoder().fit_transform(train['Embarked'])\ntrain['Sex']      = LabelEncoder().fit_transform(train['Sex'])\ny_train = train['Survived']\nx_train = train[features]\n\n\n#Encode categorical features\ntest['Embarked'] = LabelEncoder().fit_transform(test['Embarked'])\ntest['Sex'] = LabelEncoder().fit_transform(test['Sex'])\n\n#create x_test\nx_test = test[features]","a3b2a7ad":"#x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)","0d42e92c":"# Feature Scaling\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\n#x_val = sc.transform(x_val)\nx_test = sc.transform(x_test)","04b08625":"print(\"Training set shape: \", x_train.shape)\n#print(\"Validation set shape: \", x_val.shape)\nprint(\"Test set shape: \", x_test.shape)","085f6fb2":"#evaluate model\nmodel = lgb.LGBMClassifier()\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nn_scores = cross_val_score(model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\nprint('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))","5201c579":"# fit the model on the whole dataset\nmodel = lgb.LGBMClassifier()\nmodel.fit(x_train, y_train)\n\npredictions = model.predict(x_test)","43042e28":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","81082eae":"### Prepare Data for Training","de9620fb":"### Data Visualization","3eea8449":"### Import Data","307a72c6":"There is a negative correlation between Survived and Pclass and a somewhat positive correlation with Fare.","fbcf3914":"Highest count per Cabin seems to be 4. Therefore, I will remove this feature as it may be more noise than helpful!","61b24a74":"### Handle Missing Data\n\n","3a2851e8":"### Setup\n\nImport libraries"}}