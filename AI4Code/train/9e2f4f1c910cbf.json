{"cell_type":{"d69b8e38":"code","a7b7d1ff":"code","07ea4ac7":"code","ff426cb3":"code","71789e24":"code","ae16f95d":"code","57e70125":"code","8583799b":"code","d9c89b54":"code","1a780231":"code","22b8c736":"code","60be9450":"code","5ec2fcc8":"code","f70d621e":"code","8664ce3b":"code","dc7ae90d":"code","c501eeed":"code","a553a733":"code","f88a9278":"code","26d58a2e":"code","f8a1087e":"code","e2bd8e6c":"code","df2dc681":"markdown","34f48599":"markdown","4de41253":"markdown","29ad379d":"markdown","c78d93dd":"markdown","e46c04ed":"markdown","559dae93":"markdown","7cc3e0e4":"markdown","6b951089":"markdown","910fd745":"markdown","47f2d746":"markdown","329a0a70":"markdown"},"source":{"d69b8e38":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing as pp\nfrom sklearn.cluster import KMeans\n\nsns.set()\n%matplotlib inline\n\n# Display Options\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = None","a7b7d1ff":"# Import data\ndata = pd.read_csv(\"..\/input\/CC GENERAL.csv\")\ndata.head()","07ea4ac7":"# Overview\ndata.describe()","ff426cb3":"# View missing values (count)\ndata.isna().sum()","71789e24":"# Fill NAs by mean\ndata = data.fillna(data.mean())\n\ndata.isna().sum()","ae16f95d":"# Remove CUST_ID (not usefull)\ndata.drop(\"CUST_ID\", axis=1, inplace=True)","57e70125":"data.dtypes","8583799b":"# Unique values for int64 types\ndata[['CASH_ADVANCE_TRX', 'PURCHASES_TRX', 'TENURE']].nunique()","d9c89b54":"# Correlation plot\nsns.heatmap(data.corr(),\n            xticklabels=data.columns,\n            yticklabels=data.columns\n           )","1a780231":"# Pairplot - dispersion between variables\nsns.pairplot(data)","22b8c736":"# Distribution of int64 variables\nfig, axes = plt.subplots(nrows=3, ncols=1)\nax0, ax1, ax2 = axes.flatten()\n\nax0.hist(data['CASH_ADVANCE_TRX'], 65, histtype='bar', stacked=True)\nax0.set_title('CASH_ADVANCE_TRX')\n\nax1.hist(data['PURCHASES_TRX'], 173, histtype='bar', stacked=True)\nax1.set_title('PURCHASES_TRX')\n\nax2.hist(data['TENURE'], 7, histtype='bar', stacked=True)\nax2.set_title('TENURE')\n\nfig.tight_layout()\nplt.show()","60be9450":"# Create a copy of data\nfeatures = data.copy()\nlist(features)","5ec2fcc8":"# Log-transformation\n\ncols =  ['BALANCE',\n         'PURCHASES',\n         'ONEOFF_PURCHASES',\n         'INSTALLMENTS_PURCHASES',\n         'CASH_ADVANCE',\n         'CASH_ADVANCE_TRX',\n         'PURCHASES_TRX',\n         'CREDIT_LIMIT',\n         'PAYMENTS',\n         'MINIMUM_PAYMENTS',\n        ]\n\n# Note: Adding 1 for each value to avoid inf values\nfeatures[cols] = np.log(1 + features[cols])\n\nfeatures.head()","f70d621e":"features.describe()","8664ce3b":"# Using boxplot for indentify possible outliers values after log-transform\n\nfeatures.boxplot(rot=90, figsize=(30,10))","dc7ae90d":"cols = list(features)\nirq_score = {}\n\nfor c in cols:\n    q1 = features[c].quantile(0.25)\n    q3 = features[c].quantile(0.75)\n    score = q3 - q1\n    outliers = features[(features[c] < q1 - 1.5 * score) | (features[c] > q3 + 1.5 * score)][c]\n    values = features[(features[c] >= q1 - 1.5 * score) | (features[c] <= q3 + 1.5 * score)][c]\n    \n    irq_score[c] = {\n        \"Q1\": q1,\n        \"Q3\": q3,\n        \"IRQ\": score,\n        \"n_outliers\": outliers.count(),\n        \"outliers_avg\": outliers.mean(),\n        \"outliers_stdev\": outliers.std(),\n        \"outliers_median\": outliers.median(),\n        \"values_avg:\": values.mean(),\n        \"values_stdev\": values.std(),\n        \"values_median\": values.median(),\n    }\n    \nirq_score = pd.DataFrame.from_dict(irq_score, orient='index')\n\nirq_score","c501eeed":"# Scale All features\n\nfor col in cols:\n    features[col] = pp.scale(np.array(features[col]))\n\nfeatures.head()","a553a733":"X = np.array(features)\nSum_of_squared_distances = []\nK = range(1, 30)\n\nfor k in K:\n    km = KMeans(n_clusters=k, random_state=0)\n    km = km.fit(X)\n    Sum_of_squared_distances.append(km.inertia_)\n\nplt.plot(K, Sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Sum_of_squared_distances')\nplt.title('Elbow Method For Optimal k')\nplt.show()\n","f88a9278":"# Custumers per cluster\n\nn_clusters = 10\n\nclustering = KMeans(n_clusters=n_clusters,\n                    random_state=0\n                   )\n\ncluster_labels = clustering.fit_predict(X)\n\n# plot cluster sizes\n\nplt.hist(cluster_labels, bins=range(n_clusters+1))\nplt.title('# Customers per Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('# Customers')\nplt.show()\n\n# Assing cluster number to features and original dataframe\nfeatures['cluster_index'] = cluster_labels\ndata['cluster_index'] = cluster_labels","26d58a2e":"# Dispersion between clusterized data\n# Pairplot - dispersion between variables\nsns.pairplot(features, hue='cluster_index')","f8a1087e":"# View Features\nfeatures","e2bd8e6c":"# View results\ndata","df2dc681":"## Credit Card Clustering\n","34f48599":" ## Feature generation\n ### Used technics:\n - Log transformation;\n - Standardization;\n - Statistics for some variables (like mean, median, first and third quartile and mode)","4de41253":"Applying IRQ methodology in our dataset:","29ad379d":"### Preparing data\n- View types;\n- Summarize \/ Overview dataset;\n- Fill NAs","c78d93dd":"## To-Do:\n- [ ] Outlier analysis for any cluster;\n- [ ] Interpretation of clusters","e46c04ed":"## Clustering using K-Means\n\n\nNow we\\`re ready to apply the clustering algorithm, using `KMeans` from `sklearn.cluster`.\n","559dae93":"### Data exploration\n- View types;\n- Data visualization","7cc3e0e4":"#### Outliers\n\n\nAs this is a clustering, I decided to test first without _outlier\\`s_ replacement.  But is important know that information for comparision of clusterized values,  if we\\`ll see outliers inside the clusters.\n\nUsing _IRQ Score_ for identify _outliers_ values in  dataset. \n*_IRQ method_* is used in boxplot to identify possible outliers values. By Wikipedia definition:\n\n> The interquartile range (IQR), also called the midspread or middle 50%, or technically H-spread, is a measure of statistical dispersion, being equal to the difference between 75th and 25th percentiles, or between upper and lower quartiles, IQR = Q3 \u2212 Q1.\nIn other words, the IQR is the first quartile subtracted from the third quartile; these quartiles can be clearly seen on a box plot on the data.\nIt is a measure of the dispersion similar to standard deviation or variance, but is much more robust against outliers.\n\n\n\n**For now, we\\`ll do nothing with outliers because this may harm the clustering.**\n","6b951089":"#### Feature Scaling\nHere we can use `scale` function of `sklearn.preprocessing`.  This function will put all variables at the same scale, with _mean zero_ and _standard deviation equals to one_.","910fd745":"Firstly, using Elbow\\`s method, we can find an adequate number of clusters","47f2d746":"I choose `k = 10` for number of clusters, based in plot above. ","329a0a70":"Observing the table above, we can say that variables  `BALANCE`, `PURCHASES`, `ONEOFF_PURCHASES`, `INSTALLMENTS_PURCHASES`, `CASH_ADVANCE`, `CASH_ADVANCE_TRX`, `PURCHASE_TRX`, `CREDIT_LIMIT`, `PAYMENTS` and `MINIMUM_PAYMENTS` have outliers. Let's treat using log-transformation before standardizing."}}