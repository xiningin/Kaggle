{"cell_type":{"fffe97d5":"code","e740c871":"code","edebd2d4":"code","3faf45de":"code","7107aa5a":"code","32c8f7e4":"code","c5904435":"code","cf311f2e":"code","d17b18dd":"code","dcecf4ea":"code","d2302ccf":"code","32d94565":"code","845dbc6c":"code","0f7540c1":"code","f14dab24":"code","92dc832d":"code","0306f8f8":"code","71261078":"code","9f18fa89":"code","e9f2dc4c":"code","f35579be":"code","0ab0fe30":"code","9be93427":"code","48abd21d":"code","2d40a45b":"code","74c67fe4":"code","90127257":"code","4b338c32":"code","33086052":"code","ebb081d0":"code","e6cc0f77":"code","bc88cdbf":"code","37fe957a":"code","1107e874":"code","7dbc5001":"code","13ad0943":"code","c016e890":"code","303687ba":"code","b809e27f":"code","3dc140bc":"code","85519e5b":"code","8c52e3d6":"code","73572d19":"code","dd040528":"code","5a01f369":"code","5ff5b7f6":"code","130b537d":"code","6b838823":"code","39e2f1e9":"code","2428d520":"code","a02c2797":"code","2131534f":"code","be752559":"code","f1799399":"code","23672d01":"code","d07676dc":"code","c8d03b38":"code","68cbde6e":"code","310707a9":"code","d4ee645a":"code","9e5e8f89":"code","0536d4ad":"code","64a363df":"code","3b50ce12":"code","c06b2363":"code","854422ba":"code","bb6a6437":"markdown","28847edd":"markdown","fc916707":"markdown","275b1ff7":"markdown","9582cc4c":"markdown","440cc220":"markdown","d56b1453":"markdown","8f755375":"markdown","4b6b15b2":"markdown","26f00f89":"markdown","2e82f2f4":"markdown","8d9b8b9e":"markdown","34105da5":"markdown","3745edf9":"markdown","daecbd2f":"markdown","3d7e6e92":"markdown","96f8ddf9":"markdown","6c0eb8f8":"markdown"},"source":{"fffe97d5":"import numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","e740c871":"import warnings\nwarnings.filterwarnings(\"ignore\")","edebd2d4":"import matplotlib as mpl\nmpl.rcParams['font.size']=14\nmpl.rcParams['text.color']='black'","3faf45de":"df=pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')\ndf.head().T","7107aa5a":"# Numerical columns\ndf.describe().T","32c8f7e4":"# Categorical columns\ndf.describe(include='object').T","c5904435":"# Missing Values\ndf.isna().sum()","cf311f2e":"df_copy=df.copy()","d17b18dd":"from sklearn import preprocessing","dcecf4ea":"le=preprocessing.LabelEncoder()\ndf_copy.gender=le.fit_transform(df_copy.gender)\ndf_copy.ever_married=le.fit_transform(df_copy.ever_married)\ndf_copy.work_type=le.fit_transform(df_copy.work_type)\ndf_copy.Residence_type=le.fit_transform(df_copy.Residence_type)\ndf_copy.smoking_status=le.fit_transform(df_copy.smoking_status)","d2302ccf":"df_copy.drop(labels='id',inplace=True,axis=1)","32d94565":"Missing=df_copy[df_copy.bmi.isna()]","845dbc6c":"Temp=df_copy[~df_copy.bmi.isna()]","0f7540c1":"Temp.columns","f14dab24":"X=Temp[['gender', 'age', 'hypertension', 'heart_disease', 'ever_married',\n       'work_type', 'Residence_type', 'avg_glucose_level','smoking_status', 'stroke']]","92dc832d":"y=Temp['bmi']","0306f8f8":"from xgboost import XGBRegressor\nfrom sklearn.model_selection import GridSearchCV","71261078":"xgb = XGBRegressor()\nparameters = { 'objective':['reg:squarederror'],\n              'learning_rate': [.1,.01,.05,.001,.005,.0001], \n              'max_depth': [4, 6, 7,9,10,12],\n              'min_child_weight': [4,5,6],\n              'n_estimators': [500,1000,1500]}\n\nxgb_grid = GridSearchCV(xgb,\n                        parameters,\n                        cv = 3,\n                        n_jobs = -1,\n                        verbose=1)\n\n","9f18fa89":"# xgb_grid.fit(X,y)\n\n# print(xgb_grid.best_score_)\n# print(xgb_grid.best_params_)","e9f2dc4c":"xgb_missing = XGBRegressor(learning_rate=0.005, max_depth=4, min_child_weight= 6, n_estimators= 1000)\nxgb_missing.fit(X,y)\npredicted=xgb_missing.predict(Missing[['gender', 'age', 'hypertension', 'heart_disease', 'ever_married',\n       'work_type', 'Residence_type', 'avg_glucose_level','smoking_status', 'stroke']])\npredicted_bmi=pd.Series(predicted,index=Missing.index)\ndf.loc[Missing.index,'bmi']=predicted_bmi","f35579be":"df.isna().sum()","0ab0fe30":"sizes = df['stroke'].value_counts(sort = True)\nplt.figure(figsize=(7,7),facecolor='white')\n\nplt.pie(sizes, labels=['Not stroke','Stroke'], autopct='%1.2f%%', explode=[0, 0.1],textprops={'fontsize': 14})\nplt.title(\"Stroke Pie Chart\", fontdict={'fontsize': 24,'weight':'bold'})\nplt.text(-1,-1.2, 'Note: Data is highly imbalanced ', {'font':'Serif', 'size':18, 'color':'black', 'weight':'bold'})\nplt.legend()\nplt.show()","9be93427":"plt.figure(figsize = (30,10), dpi = 60)\nplt.subplot(1,3,(1,2))\nstroke_men = len(df.loc[(df[\"stroke\"]==1)&(df['gender']==\"Male\")])\nstroke_women = len(df.loc[(df[\"stroke\"]==1)&(df['gender']==\"Female\")])\nstroke_other = len(df.loc[(df[\"stroke\"]==1)&(df['gender']==\"Other\")])\nhealthy_men = len(df.loc[(df[\"stroke\"]==0)&(df['gender']==\"Male\")])\nhealthy_women = len(df.loc[(df[\"stroke\"]==0)&(df['gender']==\"Female\")])\nhealthy_other = len(df.loc[(df[\"stroke\"]==0)&(df['gender']==\"Other\")])\ntemp=pd.Series([stroke_men,healthy_men,stroke_women,healthy_women,healthy_other],\n               index=['Men with stroke','Healthy men','Women with stroke','Healthy women','Healthy others'])\nplt.pie(temp,labels=['Men with stroke','Healthy men','Women with stroke','Healthy women','Healthy others']\n        ,explode=[0.1, 0.1,0.1,0.1,0.1], autopct='%1.2f%%',textprops={'fontsize': 18})\nplt.title(\"Gender distribution: Pie Chart\", fontdict={'fontsize': 30,'weight':'bold'})\nplt.legend( bbox_to_anchor=(0.75, 0.5, 0.5, 0.5))\n\nplt.subplot(1,3,3)\nax=sns.countplot(data=df,x='gender',hue='stroke',saturation=1,dodge=True)\nplt.legend(['No Stroke','Stroke'])\nplt.xlabel('Gender')\nplt.title('Univariate Analysis')\n\nplt.figure(figsize = (30,4), dpi = 60)\nax=plt.subplot(1,1,1)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.spines['bottom'].set_visible(False)\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)\nmr=df[df['stroke']==1].gender.value_counts(sort=True)['Male']\/df['gender'].value_counts(sort=True)['Male']*100\nfr=df[df['stroke']==1].gender.value_counts(sort=True)['Female']\/df['gender'].value_counts(sort=True)['Female']*100\nplt.text(0., 0.9, 'Observation: ', {'font':'Serif', 'size':30, 'color':'black', 'weight':'bold'})\nplt.text(0., 0.5,'Gender to stroke ratio\\nMale : '+str(round(mr,2))+' %\\nFemale : '+str(round(fr,2))+' %',\n         {'font':'Serif', 'size':20, 'color':'black', 'weight':'normal'}, alpha = 1)\nplt.text(0,0.25,'Stroke chances are nearly equal in male and female \\nOur assumption of Males have more stroke than Females is Wrong',{'font':'Serif', 'size':24, 'color':'black', 'weight':'bold'}, alpha = 1)\n\nplt.show()","48abd21d":"plt.figure(figsize = (30,10), dpi = 60)\nplt.subplot(1,3,(1,2))\nstroke_married = len(df.loc[(df[\"stroke\"]==1)&(df['ever_married']==\"Yes\")])\nstroke_not_married = len(df.loc[(df[\"stroke\"]==1)&(df['ever_married']==\"No\")])\nhealthy_married = len(df.loc[(df[\"stroke\"]==0)&(df['ever_married']==\"Yes\")])\nhealthy_not_married = len(df.loc[(df[\"stroke\"]==0)&(df['ever_married']==\"No\")])\ntemp=pd.Series([healthy_married,healthy_not_married,stroke_not_married,stroke_married],\n               index=['Married and Healthy ','Not married and healthy','Not Married but has stroke','Married and has stroke'])\nplt.pie(temp,labels=['Married and Healthy ','Not married and healthy','Not Married but has stroke','Married and has stroke']\n        ,explode=[0.1, 0.1,0.1,0.1], autopct='%1.2f%%',textprops={'fontsize': 18})\nplt.title(\"Marriage distribution: Pie Chart\", fontdict={'fontsize': 30,'weight':'bold'})\nplt.legend( bbox_to_anchor=(0.75, 0.5, 0.5, 0.5))\n\nplt.subplot(1,3,3)\nax=sns.countplot(data=df,x='ever_married',hue='stroke',saturation=1,dodge=True)\nplt.legend(['No Stroke','Stroke'])\nplt.xlabel('Married')\nplt.title('Univariate Analysis')\n\nplt.figure(figsize = (30,4), dpi = 60)\nax=plt.subplot(1,1,1)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.spines['bottom'].set_visible(False)\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)\nmr=df[df['stroke']==1].ever_married.value_counts(sort=True)['Yes']\/df['ever_married'].value_counts(sort=True)['Yes']*100\nfr=df[df['stroke']==1].ever_married.value_counts(sort=True)['No']\/df['ever_married'].value_counts(sort=True)['No']*100\nplt.text(0., 0.9, 'Observation: ', {'font':'Serif', 'size':30, 'color':'black', 'weight':'bold'})\nplt.text(0., 0.5, 'Married to stroke ratio\\nMarried : '+str(round(mr,2))+' %\\nNot Married : '+str(round(fr,2))+' %',\n         {'font':'Serif', 'size':20, 'color':'black', 'weight':'normal'}, alpha = 1)\nplt.text(0,0.12,'Married people has high chances of stroke as compared to not married \\npeople which makes our assumption right.\\nSo think before getting married' ,{'font':'Serif', 'size':24, 'color':'black', 'weight':'bold'}, alpha = 1)\nplt.show()","2d40a45b":"plt.figure(figsize = (30,10), dpi = 60)\nplt.subplot(1,3,(1,2))\nstroke_Private = len(df.loc[(df[\"stroke\"]==1)&(df['work_type']==\"Private\")])\nstroke_Self_employed = len(df.loc[(df[\"stroke\"]==1)&(df['work_type']==\"Self-employed\")])\nstroke_Govt_job = len(df.loc[(df[\"stroke\"]==1)&(df['work_type']==\"Govt_job\")])\nstroke_children = len(df.loc[(df[\"stroke\"]==1)&(df['work_type']==\"children\")])\nstroke_Never_worked = len(df.loc[(df[\"stroke\"]==1)&(df['work_type']==\"Never_worked\")])\n\nhealthy_Private = len(df.loc[(df[\"stroke\"]==0)&(df['work_type']==\"Private\")])\nhealthy_Self_employed = len(df.loc[(df[\"stroke\"]==0)&(df['work_type']==\"Self-employed\")])\nhealthy_Govt_job = len(df.loc[(df[\"stroke\"]==0)&(df['work_type']==\"Govt_job\")])\nhealthy_children = len(df.loc[(df[\"stroke\"]==0)&(df['work_type']==\"children\")])\nhealthy_Never_worked = len(df.loc[(df[\"stroke\"]==0)&(df['work_type']==\"Never_worked\")])\n\ntemp=pd.Series([stroke_Private,stroke_Self_employed,stroke_Govt_job,stroke_children,stroke_Never_worked,\n               healthy_Private,healthy_Self_employed,healthy_Govt_job,healthy_children,healthy_Never_worked],\n               index=['Private and stroke ','Self employed and stroke','Govt job and stroke','children and stroke','Never worked and stroke'\n                     ,'Private and healthy','Self employed and healthy','Govt job and healthy','children and healthy','Never worked and healthy'])\nplt.pie(temp,labels=['Private and stroke ','Self employed and stroke','Govt job and stroke','children and stroke','Never worked and stroke'\n                     ,'Private and healthy','Self employed and healthy','Govt job and healthy','children and healthy','Never worked and healthy']\n        ,explode=[0.1, 0.1,0.1,0.1,0.1,0.1, 0.1,0.1,0.1,0.1], autopct='%1.2f%%',textprops={'fontsize': 18},pctdistance=0.4,startangle=290\n       ,rotatelabels=True)\nplt.title(\"Worktype distribution: Pie Chart\", fontdict={'fontsize': 30,'weight':'bold'})\nplt.legend( bbox_to_anchor=(1, 0.5, 0.5, 0.5))\n\nplt.subplot(1,3,3)\nax=sns.countplot(data=df,x='work_type',hue='stroke',saturation=1,dodge=True)\nplt.legend(['No Stroke','Stroke'])\nplt.xlabel('Work type')\nplt.title('Univariate Analysis')\nplt.xticks(rotation=30)\n\nplt.figure(figsize = (30,4), dpi = 60)\nax=plt.subplot(1,1,1)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.spines['bottom'].set_visible(False)\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)\n\nprivate_s=df[df['stroke']==1].work_type.value_counts(sort=True)['Private']\/df['work_type'].value_counts(sort=True)['Private']*100\nself_employed_s=df[df['stroke']==1].work_type.value_counts(sort=True)['Self-employed']\/df['work_type'].value_counts(sort=True)['Self-employed']*100\ngovt_job_s=df[df['stroke']==1].work_type.value_counts(sort=True)['Govt_job']\/df['work_type'].value_counts(sort=True)['Govt_job']*100\nchildren_s=df[df['stroke']==1].work_type.value_counts(sort=True)['children']\/df['work_type'].value_counts(sort=True)['children']*100\n\nplt.text(0., 1, 'Observation: ',  {'font':'Serif', 'size':30, 'color':'black', 'weight':'bold'})\nplt.text(0., 0.35, 'Work type to stroke ratio\\nPrivate : '+str(round(private_s,2))+' %\\nSelf employed : '+str(round(self_employed_s,2))+' %'\n         +'\\nGovt job : '+str(round(govt_job_s,2))+' %\\nChildren : '+str(round(children_s,2))+'\\nNever worked : 0 %',\n         {'font':'Serif', 'size':20, 'color':'black', 'weight':'normal'}, alpha = 1)\nplt.text(0,0.1,'Self employed people have high strokes followed by private and govt jobs. Interesting fact is People who have never worked \\nhas no stroke cases. Also our assumption is partially right',{'font':'Serif', 'size':24, 'color':'black', 'weight':'bold'}, alpha = 1)\n\nplt.show()","74c67fe4":"plt.figure(figsize = (30,10), dpi = 60)\nplt.subplot(1,3,(1,2))\nstroke_urban = len(df.loc[(df[\"stroke\"]==1)&(df['Residence_type']==\"Urban\")])\nstroke_rural = len(df.loc[(df[\"stroke\"]==1)&(df['Residence_type']==\"Rural\")])\nhealthy_urban = len(df.loc[(df[\"stroke\"]==0)&(df['Residence_type']==\"Urban\")])\nhealthy_rural = len(df.loc[(df[\"stroke\"]==0)&(df['Residence_type']==\"Rural\")])\ntemp=pd.Series([healthy_rural,healthy_urban,stroke_rural,stroke_urban],\n               index=['Rural and Healthy ','Urban and healthy','Rural and stroke','Healthy and has stroke'])\nplt.pie(temp,labels=['Rural and Healthy ','Urban and healthy','Rural and stroke','Healthy and has stroke']\n        ,explode=[0.1, 0.1,0.1,0.1], autopct='%1.2f%%',textprops={'fontsize': 18},startangle=30)\nplt.title(\"Residence Type distribution: Pie Chart\", fontdict={'fontsize': 30,'weight':'bold'})\nplt.legend( bbox_to_anchor=(0.7, 0.5, 0.5, 0.5))\n\nplt.subplot(1,3,3)\nax=sns.countplot(data=df,x='Residence_type',hue='stroke',saturation=1,dodge=True)\nplt.legend(['No Stroke','Stroke'])\nplt.xlabel('Residential type')\nplt.title('Univariate Analysis')\n\nplt.figure(figsize = (30,4), dpi = 60)\nax=plt.subplot(1,1,1)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.spines['bottom'].set_visible(False)\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)\nur=df[df['stroke']==1].Residence_type.value_counts(sort=True)['Urban']\/df['Residence_type'].value_counts(sort=True)['Urban']*100\nrr=df[df['stroke']==1].Residence_type.value_counts(sort=True)['Rural']\/df['Residence_type'].value_counts(sort=True)['Rural']*100\nplt.text(0., 1, 'Observation: ', {'font':'Serif', 'size':30, 'color':'black', 'weight':'bold'})\nplt.text(0., 0.62, '\\n\\nResidence type to stroke ratio\\nUrban : '+str(round(ur,2))+' %\\nRural : '+str(round(rr,2))+' %',\n         {'font':'Serif', 'size':20, 'color':'black', 'weight':'normal'}, alpha = 1)\nplt.text(0,0.25,'\\nPeople living in rural and urban area have nearby possibilities of having strokes.\\nOur assumption of city people is having more stroke is wrong.\\n\\\nLiving anywhere has same chance of getting stroke.',{'font':'Serif', 'size':24, 'color':'black', 'weight':'bold'}, alpha = 1)\n\nplt.show()","90127257":"plt.figure(figsize = (30,10), dpi = 60)\nplt.subplot(1,3,(1,2))\nstroke_formerly_smoked = len(df.loc[(df[\"stroke\"]==1)&(df['smoking_status']==\"formerly smoked\")])\nstroke_never_smoked = len(df.loc[(df[\"stroke\"]==1)&(df['smoking_status']==\"never smoked\")])\nstroke_smokes = len(df.loc[(df[\"stroke\"]==1)&(df['smoking_status']==\"smokes\")])\nstroke_unknown = len(df.loc[(df[\"stroke\"]==1)&(df['smoking_status']==\"Unknown\")])\n\nhealthy_formerly_smoked = len(df.loc[(df[\"stroke\"]==0)&(df['smoking_status']==\"formerly smoked\")])\nhealthy_never_smoked = len(df.loc[(df[\"stroke\"]==0)&(df['smoking_status']==\"never smoked\")])\nhealthy_smokes = len(df.loc[(df[\"stroke\"]==0)&(df['smoking_status']==\"smokes\")])\nhealthy_unknown = len(df.loc[(df[\"stroke\"]==0)&(df['smoking_status']==\"Unknown\")])\n\ntemp=pd.Series([stroke_formerly_smoked,stroke_never_smoked,stroke_smokes,stroke_unknown,\n               healthy_formerly_smoked,healthy_never_smoked,healthy_smokes,healthy_unknown],\n               index=['Formerly smoke and stroke ','Never smoked and stroke','smokes and stroke','unknown and stroke'\n                     ,'Formerly smoke and healthy ','Never smoked and healthy','smokes and healthy','unknown and healthy'])\nplt.pie(temp,labels=['Formerly smoke and stroke ','Never smoked and stroke','smokes and stroke','unknown and stroke'\n                     ,'Formerly smoke and healthy ','Never smoked and healthy','smokes and healthy','unknown and healthy']\n        ,explode=[0.1, 0.1,0.1,0.1,0.1,0.1, 0.1,0.1], autopct='%1.2f%%',textprops={'fontsize': 18},pctdistance=0.4,startangle=30\n       ,rotatelabels=False)\nplt.title(\"Smokers distribution: Pie Chart\", fontdict={'fontsize': 30,'weight':'bold'})\nplt.legend( bbox_to_anchor=(-0.5, 0.65, 0.5, 0.5))\n\nplt.subplot(1,3,3)\nax=sns.countplot(data=df,x='smoking_status',hue='stroke',saturation=1,dodge=True)\nplt.legend(['No Stroke','Stroke'])\nplt.xlabel('Work type')\nplt.title('Univariate Analysis')\nplt.xticks(rotation=30)\n\nplt.figure(figsize = (30,4), dpi = 60)\nax=plt.subplot(1,1,1)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.spines['bottom'].set_visible(False)\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)\nformerly_smoked_s=df[df['stroke']==1].smoking_status.value_counts(sort=True)['formerly smoked']\/df['smoking_status'].value_counts(sort=True)['formerly smoked']*100\nnever_smoked_s=df[df['stroke']==1].smoking_status.value_counts(sort=True)['never smoked']\/df['smoking_status'].value_counts(sort=True)['never smoked']*100\nsmokes_s=df[df['stroke']==1].smoking_status.value_counts(sort=True)['smokes']\/df['smoking_status'].value_counts(sort=True)['smokes']*100\nunknown_s=df[df['stroke']==1].smoking_status.value_counts(sort=True)['Unknown']\/df['smoking_status'].value_counts(sort=True)['Unknown']*100\n\nplt.text(0., 1, 'Observation: ', {'font':'Serif', 'size':30, 'color':'black', 'weight':'bold'})\nplt.text(0., 0.45, 'Work type to stroke ratio\\nFormerly smoked : '+str(round(formerly_smoked_s,2))+' %\\nNever smoked : '+str(round(never_smoked_s,2))+' %'\n         +'\\nSmokes : '+str(round(smokes_s,2))+' %\\nUnknown : '+str(round(unknown_s,2))+' %',\n         {'font':'Serif', 'size':20, 'color':'black', 'weight':'normal'}, alpha = 1)\nplt.text(0,0.09,'Formerly smoked people have more chances of having stroke followed by people who smokes then people \\nwho never smoked, which makes our assumption incorrect.\\\n \\nAccording to data people who smokes, should not leave smoking as it may cause stroke...Strange but true.',{'font':'Serif', 'size':24, 'color':'black', 'weight':'bold'}, alpha = 1)\nplt.show()","4b338c32":"plt.figure(figsize = (30,10), dpi = 60)\nplt.subplot(1,3,(1,2))\nstroke_hypertension = len(df.loc[(df[\"stroke\"]==1)&(df['hypertension']==1)])\nstroke_not_hypertension = len(df.loc[(df[\"stroke\"]==1)&(df['hypertension']==0)])\nhealthy_hypertension = len(df.loc[(df[\"stroke\"]==0)&(df['hypertension']==1)])\nhealthy_not_hypertension = len(df.loc[(df[\"stroke\"]==0)&(df['hypertension']==0)])\ntemp=pd.Series([stroke_hypertension,stroke_not_hypertension,healthy_hypertension,healthy_not_hypertension],\n               index=['Hypertension and stroke ','No hypertension and stroke','Hypertension and healthy','No hypertension and healthy'])\nplt.pie(temp,labels=['Hypertension and stroke ','No hypertension and stroke','Hypertension and healthy','No hypertension and healthy']\n        ,explode=[0.1, 0.1,0.1,0.1], autopct='%1.2f%%',textprops={'fontsize': 18},startangle=-60)\nplt.title(\"Hypertension distribution: Pie Chart\", fontdict={'fontsize': 30,'weight':'bold'})\nplt.legend( bbox_to_anchor=(0.75, 0.5, 0.5, 0.5))\n\nplt.subplot(1,3,3)\nax=sns.countplot(data=df,x='hypertension',hue='stroke',saturation=1,dodge=True)\nplt.legend(['No Stroke','Stroke'])\nplt.xlabel('Residential type')\nplt.title('Univariate Analysis')\nplt.xticks([1,0],['Hypertension','No hypertension'])\n\nplt.figure(figsize = (30,4), dpi = 60)\nax=plt.subplot(1,1,1)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.spines['bottom'].set_visible(False)\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)\nhyr=df[df['stroke']==1].hypertension.value_counts(sort=True)[1]\/df['hypertension'].value_counts(sort=True)[1]*100\nnhyr=df[df['stroke']==1].hypertension.value_counts(sort=True)[0]\/df['hypertension'].value_counts(sort=True)[0]*100\nplt.text(0., 0.95, 'Observation: ', {'font':'Serif', 'size':30, 'color':'black', 'weight':'bold'})\nplt.text(0., 0.6, '\\n\\nResidence type to stroke ratio\\nHypertension : '+str(round(hyr,2))+' %\\nNot hypertension : '+str(round(nhyr,2))+' %',\n         {'font':'Serif', 'size':20, 'color':'black', 'weight':'normal'}, alpha = 1)\nplt.text(0,0.33,'People having hypertension has high chances of getting stroke.\\\n Our assumption is right.\\nHypertension plays major role in having stroke.',{'font':'Serif', 'size':24, 'color':'black', 'weight':'bold'}, alpha = 1)\n\nplt.show()","33086052":"plt.figure(figsize = (30,10), dpi = 60)\nplt.subplot(1,3,(1,2))\nstroke_heart_disease = len(df.loc[(df[\"stroke\"]==1)&(df['heart_disease']==1)])\nstroke_not_heart_disease = len(df.loc[(df[\"stroke\"]==1)&(df['heart_disease']==0)])\nhealthy_heart_disease = len(df.loc[(df[\"stroke\"]==0)&(df['heart_disease']==1)])\nhealthy_not_heart_disease = len(df.loc[(df[\"stroke\"]==0)&(df['heart_disease']==0)])\ntemp=pd.Series([stroke_heart_disease,stroke_not_heart_disease,healthy_heart_disease,healthy_not_heart_disease],\n               index=['Heart disease and stroke ','No heart disease and stroke','Heart disease and healthy','No heart disease and healthy'])\nplt.pie(temp,labels=['Heart disease and stroke ','No heart disease and stroke','Heart disease and healthy','No heart disease and healthy']\n        ,explode=[0.1, 0.1,0.1,0.1], autopct='%1.2f%%',textprops={'fontsize': 18},startangle=-60)\nplt.title(\"Heart disease distribution: Pie Chart\", fontdict={'fontsize': 30,'weight':'bold'})\nplt.legend( bbox_to_anchor=(0.75, 0.5, 0.5, 0.5))\n\nplt.subplot(1,3,3)\nax=sns.countplot(data=df,x='heart_disease',hue='stroke',saturation=1,dodge=True)\nplt.legend(['No Stroke','Stroke'])\nplt.xlabel('Heart disease')\nplt.title('Univariate Analysis')\nplt.xticks([1,0],['Heart disease','No heart disease'])\n\nplt.figure(figsize = (30,4), dpi = 60)\nax=plt.subplot(1,1,1)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.spines['bottom'].set_visible(False)\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)\nhdr=df[df['stroke']==1].heart_disease.value_counts(sort=True)[1]\/df['heart_disease'].value_counts(sort=True)[1]*100\nnhdr=df[df['stroke']==1].heart_disease.value_counts(sort=True)[0]\/df['heart_disease'].value_counts(sort=True)[0]*100\nplt.text(0., 0.9, 'Observation: ', {'font':'Serif', 'size':30, 'color':'black', 'weight':'bold'})\nplt.text(0., 0.57,'\\n\\nHeart disease to stroke ratio\\nHeart disease : '+str(round(hdr,2))+' %\\nNo Heart disease : '+str(round(nhdr,2))+' %',\n         {'font':'Serif', 'size':20, 'color':'black', 'weight':'normal'}, alpha = 1)\nplt.text(0,0.3,'People having heart disease or previously had heart disease are more prone to having stroke, which makes our assumptions right\\\n\\nBetter not to have heart disease and take care of our health.',{'font':'Serif', 'size':24, 'color':'black', 'weight':'bold'}, alpha = 1)\nplt.show()","ebb081d0":"plt.figure(figsize = (30,15), dpi = 60)\nax=plt.subplot(3,3,1)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.get_yaxis().set_visible(False)\nsns.kdeplot(data=df,x='age',color='#0f4c81',shade=True,alpha=0.8)\nplt.title(\"Distribution of age\",fontdict={'fontweight': 'bold', 'size':18})\nax=plt.subplot(3,3,2)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.get_yaxis().set_visible(False)\nsns.kdeplot(data=df,x='avg_glucose_level',color='#0f4c81',shade=True,alpha=0.8)\nplt.title(\"Distribution of glucose level\",fontdict={'fontweight': 'bold', 'size':18})\nax=plt.subplot(3,3,3)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.get_yaxis().set_visible(False)\nsns.kdeplot(data=df,x='bmi',color='#0f4c81',shade=True,alpha=0.8)\nplt.title(\"Distribution of BMI\",fontdict={'fontweight': 'bold', 'size':18})\nax=plt.subplot(3,3,4)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.spines['bottom'].set_visible(False)\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)\nplt.text(0,0.4,'As age increses chances of having\\nstroke also increases. \\nMid aged and elderly people have \\nhigh chance of stroke.\\nAge is an important factor',{'font':'Serif', 'size':24, 'color':'#0f4c81', 'weight':'bold'}, alpha = 1)\n\nax=plt.subplot(3,3,5)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.spines['bottom'].set_visible(False)\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)\nplt.text(0,0.6,'There is no relation between glucose\\nlevel and stroke. Often common \\nglucose level have led to stroke ',{'font':'Serif', 'size':24, 'color':'#0f4c81', 'weight':'bold'}, alpha = 1)\n\nax=plt.subplot(3,3,6)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.spines['bottom'].set_visible(False)\nax.get_xaxis().set_visible(False)\nax.get_yaxis().set_visible(False)\nplt.text(0,0.6,'Clearly there is no relation between \\nbmi and stroke. Possibilty of having \\nstroke or not is equal occurence',{'font':'Serif', 'size':24, 'color':'#0f4c81', 'weight':'bold'}, alpha = 1)\n\nax=plt.subplot(3,3,7)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.get_yaxis().set_visible(False)\nsns.kdeplot(data=df[df['stroke']==0],x='age',color='#0f4c81', shade=True,legend=False,linewidth=2,alpha=0.8)\nsns.kdeplot(data=df[df['stroke']==1],x='age',color='#ffaa00', shade=True,legend=False,linewidth=2,alpha=0.8)\nplt.title('Distribution of age\\n with respect to stroke',fontdict={'fontweight': 'bold', 'size':18})\nplt.text(0,0.023,'Stroke',{'font':'Serif', 'size':20, 'color':'#ffaa00', 'weight':'bold'}, alpha = 1)\nplt.text(0,0.03,'Healthy',{'font':'Serif', 'size':20, 'color':'#0f4c81', 'weight':'bold'}, alpha = 1)\nax=plt.subplot(3,3,8)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.get_yaxis().set_visible(False)\nsns.kdeplot(data=df[df['stroke']==0],x='avg_glucose_level',color='#0f4c81', shade=True,legend=False,linewidth=2,alpha=0.8)\nsns.kdeplot(data=df[df['stroke']==1],x='avg_glucose_level',color='#ffaa00', shade=True,legend=False,linewidth=2,alpha=0.8)\nplt.title('Distribution of glucose level \\nwith respect to stroke',fontdict={'fontweight': 'bold', 'size':18})\nplt.text(0,0.012,'Stroke',{'font':'Serif', 'size':20, 'color':'#ffaa00', 'weight':'bold'}, alpha = 1)\nplt.text(0,0.015,'Healthy',{'font':'Serif', 'size':20, 'color':'#0f4c81', 'weight':'bold'}, alpha = 1)\nax=plt.subplot(3,3,9)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.get_yaxis().set_visible(False)\nsns.kdeplot(data=df[df['stroke']==0],x='bmi',color='#0f4c81', shade=True,legend=False,linewidth=2,alpha=0.8)\nsns.kdeplot(data=df[df['stroke']==1],x='bmi',color='#ffaa00', shade=True,legend=False,linewidth=2,alpha=0.8)\nplt.title('Distribution of bmi\\n with respect to stroke',fontdict={'fontweight': 'bold', 'size':18})\nplt.text(0,0.055,'Stroke',{'font':'Serif', 'size':20, 'color':'#ffaa00', 'weight':'bold'}, alpha = 1)\nplt.text(0,0.07,'Healthy',{'font':'Serif', 'size':20, 'color':'#0f4c81', 'weight':'bold'}, alpha = 1)\nplt.show()","e6cc0f77":"stroke=df[df['stroke']==1]","bc88cdbf":"cross_tab=pd.crosstab(stroke['work_type'],stroke['gender'])\nsns.heatmap(cross_tab,annot=True)\nplt.show()","37fe957a":"cross_tab=pd.crosstab(stroke['smoking_status'],stroke['gender'],normalize='index')\nsns.heatmap(cross_tab,annot=True,fmt=\"1.0%\")\nplt.show()","1107e874":"cross_tab=pd.crosstab(stroke['heart_disease'],stroke['hypertension'],normalize='index')\nsns.heatmap(cross_tab,annot=True,fmt=\"1.0%\")\nplt.show()","7dbc5001":"df_pipeline=df.copy()","13ad0943":"def ready_pipeline(data):\n    data.gender=data.gender.replace({'Male':0,'Female':1,'Other':-1}).astype(np.uint8)\n    data.ever_married=data.ever_married.apply(lambda x: 1 if x=='Yes' else 0)\n    data.Residence_type=data.Residence_type.apply(lambda x: 1 if x=='Urban' else 0)\n    data=pd.get_dummies(data,columns=['smoking_status','work_type'])\n    data=data.drop(['id'],axis=1)\n    return data","c016e890":"df_pipeline=ready_pipeline(df_pipeline)","303687ba":"df_pipeline.head()","b809e27f":"df_pipeline.columns","3dc140bc":"from sklearn.model_selection import train_test_split","85519e5b":"y=df_pipeline.pop('stroke')\nX=df_pipeline","8c52e3d6":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)","73572d19":"from sklearn.preprocessing import StandardScaler \nsc = StandardScaler()","dd040528":"X_train.age=sc.fit_transform(X_train.age.values.reshape(-1,1))\nX_test.age=sc.transform(X_test.age.values.reshape(-1,1))\nX_train.bmi=sc.fit_transform(X_train.bmi.values.reshape(-1,1))\nX_test.bmi=sc.transform(X_test.bmi.values.reshape(-1,1))\nX_train.avg_glucose_level=sc.fit_transform(X_train.avg_glucose_level.values.reshape(-1,1))\nX_test.avg_glucose_level=sc.transform(X_test.avg_glucose_level.values.reshape(-1,1))","5a01f369":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nimport time","5ff5b7f6":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import roc_auc_score","130b537d":"model_params = [(LogisticRegression(),[{'C':[0.25,0.5,0.75,1],'random_state':[0]}]), \n               (KNeighborsClassifier(),[{'n_neighbors':[4,5,7,8,10], 'metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski']}]), \n               (SVC( probability = True),[{'C':[0.25,0.5,0.75,1],'kernel':['linear', 'rbf'],'random_state':[0]}]), \n               (DecisionTreeClassifier(),[{'criterion':['gini','entropy'],'random_state':[0]}]), \n               (RandomForestClassifier(),[{'n_estimators':[100,150,200],'criterion':['gini','entropy'],'random_state':[0]}]), \n              (XGBClassifier(), [{'learning_rate': [0.01, 0.05, 0.1], 'eval_metric': ['error']}])]","6b838823":"result_record=pd.DataFrame(columns=['Algorithm','Accuracy (train)','Accuracy (test)','Recall','Precision','F1 score','Roc Auc score'])","39e2f1e9":"def run_model(x_train,x_test,y_train, y_test):\n    start_time=time.time()\n    for i,j in model_params:\n        t1=time.time()\n        grid = GridSearchCV(estimator=i,param_grid = j, scoring = 'accuracy',cv = 5)\n        grid.fit(x_train, y_train)\n        predict_y=grid.predict(x_test)\n        predict_probability=grid.predict_proba(x_test)\n        \n        best_param = grid.best_params_\n        train_accuracy = grid.best_score_\n        test_accuracy=accuracy_score(y_test,predict_y)\n        test_f1_score=f1_score(y_test,predict_y, average='micro')\n        test_precision=precision_score(y_test,predict_y, average='micro')\n        test_recall=recall_score(y_test,predict_y, average='micro')\n        test_auc_roc=roc_auc_score(y_test,predict_probability[:,1])\n        \n        print(str(i)+':\\nBest Parameters : ',best_param)\n        print('Train Accuracy : '+str(round(train_accuracy,2)*100)+' % ')\n        print('Test accuracy : '+str(round(test_accuracy,2)*100)+' % ')\n        print('F1 score : '+str(round(test_f1_score,2)*100)+' % ')\n        print('Precision : '+str(round(test_precision,2)*100)+' % ')\n        print('Recall : '+str(round(test_recall,2)*100)+' % ')\n        print('Auc Roc score : '+str(round(test_auc_roc,2)*100)+' % ')\n        \n        result_record.loc[len(result_record.index)]= [i,round(train_accuracy,2)*100,round(test_accuracy,2)*100,round(test_recall,2)*100,round(test_precision,2)*100,round(test_f1_score,2)*100,round(test_auc_roc,2)*100] \n        \n        t2=time.time()-t1\n        print(str(i)+' finished in '+str(t2)+' seconds')\n        print('='*50)\n    final_time=time.time()-start_time\n    print('All operations are finished in '+str(final_time)+' seconds')","2428d520":"run_model(X_train, X_test, y_train, y_test)","a02c2797":"from imblearn.over_sampling import SMOTE","2131534f":"smote=SMOTE()","be752559":"y.value_counts()","f1799399":"x_smote,y_smote=smote.fit_resample(X,y)","23672d01":"y_smote.value_counts()","d07676dc":"X_train, X_test, y_train, y_test = train_test_split(x_smote, y_smote, test_size=0.25)","c8d03b38":"X_train.age=sc.fit_transform(X_train.age.values.reshape(-1,1))\nX_test.age=sc.transform(X_test.age.values.reshape(-1,1))\nX_train.bmi=sc.fit_transform(X_train.bmi.values.reshape(-1,1))\nX_test.bmi=sc.transform(X_test.bmi.values.reshape(-1,1))\nX_train.avg_glucose_level=sc.fit_transform(X_train.avg_glucose_level.values.reshape(-1,1))\nX_test.avg_glucose_level=sc.transform(X_test.avg_glucose_level.values.reshape(-1,1))","68cbde6e":"run_model(X_train, X_test, y_train, y_test)","310707a9":"from imblearn.under_sampling import ClusterCentroids","d4ee645a":"y.value_counts()","9e5e8f89":"cc=ClusterCentroids()\nx_cc,y_cc=cc.fit_resample(X,y)","0536d4ad":"y_cc.value_counts()","64a363df":"X_train, X_test, y_train, y_test = train_test_split(x_cc, y_cc, test_size=0.20)","3b50ce12":"X_train.age=sc.fit_transform(X_train.age.values.reshape(-1,1))\nX_test.age=sc.transform(X_test.age.values.reshape(-1,1))\nX_train.bmi=sc.fit_transform(X_train.bmi.values.reshape(-1,1))\nX_test.bmi=sc.transform(X_test.bmi.values.reshape(-1,1))\nX_train.avg_glucose_level=sc.fit_transform(X_train.avg_glucose_level.values.reshape(-1,1))\nX_test.avg_glucose_level=sc.transform(X_test.avg_glucose_level.values.reshape(-1,1))","c06b2363":"run_model(X_train, X_test, y_train, y_test)","854422ba":"plt.figure(figsize = (25,15), dpi = 60)\nplt.subplot(3,1,1)\nlabels=['LogisticRegression','KNeighborsClassifier','SVC','DecisionTreeClassifier','RandomForestClassifier','XGBClassifier']\nax=sns.heatmap(result_record.iloc[:6,1:],annot=True,yticklabels=labels,fmt='.1f')\nax.xaxis.tick_top()\nplt.title('Unbalanced Data')\nplt.subplot(3,1,2)\nlabels=['LogisticRegression','KNeighborsClassifier','SVC','DecisionTreeClassifier','RandomForestClassifier','XGBClassifier']\nax=sns.heatmap(result_record.iloc[6:12,1:],annot=True,yticklabels=labels,xticklabels=False,fmt='.1f')\n# ax.xaxis.tick_top()\nplt.title('SMOTE (Upsampling)')\nplt.subplot(3,1,3)\nlabels=['LogisticRegression','KNeighborsClassifier','SVC','DecisionTreeClassifier','RandomForestClassifier','XGBClassifier']\nax=sns.heatmap(result_record.iloc[12:,1:],annot=True,yticklabels=labels,xticklabels=False,fmt='.1f')\nax.xaxis.tick_top()\nplt.title('Clustercentroids (Downsampling)')\nplt.show()","bb6a6437":"<h1>We have successfully handled missing value<\/h1>","28847edd":"# Undersampling","fc916707":"<h2>Assumptions:<\/h2>\n1. Is the myth true, Males have more strokes than females<br\/>\n2. Does age has direct impact on stroke?<br\/>\n3. People having hypertension are more prone to stroke<br\/>\n4. Common understanding of heart disease person will suffer heart stroke most of the time?<br\/>\n5. Does married people gets more stroke than unmarried people?<br\/>\n6. Do people working in private sector has more chance of stroke?<br\/>\n7. People living in city are at high risk of stroke?<br\/>\n8. Glucose level or bmi, above\/below some value lead to stroke<br\/>\n9. Common assumption of smoking people has more stroke. Is it True?<br\/>","275b1ff7":"{'learning_rate': 0.005, 'max_depth': 4, 'min_child_weight': 6, 'n_estimators': 1000, 'objective': 'reg:squarederror'}","9582cc4c":"<h3 style=\"letter-spacing:2px\">Hello friends,<br\/>\n    * Today we are going to explore the data of heart stroke<br\/>\n    * Make some assumptions about factors which may lead to stroke or not <br\/>\n    * Selection of right metrics is important as it will define model's true performance<br\/>\n    * Visualizations are made to easily understand representation of data<br\/>\n    <font style=\"font-weight:bold\">Please upvote my work If you like it<\/font>\n    <font style=\"font-weight:bold\">If you have any suggestions, Please do let me know in comments, So i can improve notebook<\/font>\n    <font style=\"font-weight:bold\"><\/font>\n    <\/h3>\n    ","440cc220":"# Selection of Metrics:\nWe are selecting F1 score and Recall as main metrics, as data is highly imbalanced, also any model will give us 95% accuracy easily.","d56b1453":"<h3>Male and Female have highest stroke who work in private organization followed by selfemployed<\/h3>","8f755375":"# Continous numerical feature","4b6b15b2":"<h1>\n    <font style=\"font-weight:bold\">Comment and upvote if you like my work<\/font><br\/>\n    <font style=\"font-weight:bold\">Thank You<\/font>\n<\/h1>","26f00f89":"Data contains 5110 observations with 12 attributes.:\n1) <b>id<\/b>: unique identifier <br\/>\n2) <b>gender<\/b>: Gender of person <br\/>\n3) <b>age<\/b>: Age of person<br\/>\n4) <b>hypertension<\/b>: Person has hypertension or not? <br\/>\n5) <b>heart_disease<\/b>: Person has heart related disease or not?<br\/>\n6) <b>ever_married<\/b>: Marital status<br\/>\n7) <b>work_type<\/b>: Employment type<br\/>\n8) <b>Residence_type<\/b>: Residential category of person<br\/>\n9) <b>avg_glucose_level<\/b>: Average glucose level in blood of person<br\/>\n10) <b>bmi<\/b>: Body mass index of person<br\/>\n11) <b>smoking_status<\/b>: Current\/former status of smoking<br\/>\n12) <b>stroke<\/b>: Did individual suffered stroke or not<br\/>\nlink: https:\/\/www.kaggle.com\/fedesoriano\/stroke-prediction-dataset","2e82f2f4":"<h3>People having no hypertension are mostly getting strokes irrespective of heart disease<\/h3>","8d9b8b9e":"<h3>Females who have never smoked are more prone to stroke<\/h3>","34105da5":"<h1>Bivariate analysis<\/h1>","3745edf9":"<h3>As data(age, glucose level, bmi) is highly skewed, we will handle it in further steps<\\h3>","daecbd2f":"<h1>About Data<\/h1>\n1. Categorical and Numerical features are present\n<ul>\n  <li>Categorical Features: gender, ever_married, work_type, Residence_type,  smoking_status<\/li>\n  <li>Binary Numerical Features: hypertension,heart_disease, stroke<\/li>\n  <li>Continous Numerical Features : age, avg_glucose_level, bmi<\/li>\n<\/ul>\n2. bmi feature has missing values","3d7e6e92":"<h1>Observation:<\/h1>\n<h3>\n<ul>\n    <li>In unbalanced data we have auc score of 84% in Logistic regression algorithm, which is good.<\/li>\n    <li>When data is upsampled to balance data, auc score is 99% , accuracy and f1 score is 96+% which suggest Randomforestclassifier and XGBclassifier is good for upsampled data.<\/li>\n    <li>In downsampling data all algorithms works well, still data is very less to make it interpretable for future unseen data. <\/li> \n    <\/ul>\n<\/h3>","96f8ddf9":"# Smote","6c0eb8f8":"<h1 style = \"font-size:60px; background-color: #FBB002 ; color : #000000; text-align: center; border-radius: 25px 100px;\"> Storytelling with EDA and model selection and prediction of stroke<\/h1>"}}