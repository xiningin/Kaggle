{"cell_type":{"ddbec81b":"code","aaad712e":"code","0ed03cd4":"code","fa2bc8a0":"code","1a9196b9":"code","6b1fa228":"code","70bf2462":"code","4ff57c6e":"code","d6d69bf6":"code","059bdb6c":"code","a92682ed":"code","70b6ba47":"code","987e6d38":"code","48804802":"code","50c00780":"code","7a3549ae":"code","71acaa19":"code","39844ac0":"code","47869b32":"code","8fc94d6c":"code","7a9fd52b":"code","a260d283":"code","c695d00c":"code","8b9d2e9f":"code","a0fdec76":"code","9c700bf0":"code","be5f8985":"code","322b51ac":"code","af696f48":"code","c934f3e7":"code","5151bd6a":"code","c19f5cc9":"code","054ac505":"code","abc9551e":"code","aff6f323":"code","7df29a99":"code","95cf7838":"code","047af6cb":"code","2526394a":"code","7ab8ec2e":"code","7f566824":"code","153b0b51":"code","f1b00b94":"code","ebb13a2e":"code","2c27921c":"code","bce8dfb9":"code","94975093":"code","7f3a9372":"code","20c3d9a4":"code","f112f108":"code","fbc08273":"code","b713b176":"code","701ceb8e":"code","780233e7":"code","0751d7ae":"code","b009d78a":"code","ab3f187c":"code","0a12c113":"code","60d26a68":"code","6d819d25":"code","cfe8f802":"code","85b91ec2":"code","678b7cc0":"code","2e49c95b":"code","e7d5fb6f":"markdown"},"source":{"ddbec81b":"pip install ethnicolr","aaad712e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0ed03cd4":"# data analysis and wrangling\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","fa2bc8a0":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')\ncombine = [train_df, test_df]","1a9196b9":"#check the decoration\ntrain_df.columns.values","6b1fa228":"#preview the data\n#\u6b20\u640d\u5024\u306b\u6ce8\u610f\ntrain_df.head()","70bf2462":"train_df.tail()","4ff57c6e":"#\u30c7\u30fc\u30bf\u306e\u8a73\u7d30\u3092\u898b\u308c\u308b \u30c7\u30fc\u30bf\u306e\u578b\u3068\u304b\ntrain_df.info()","d6d69bf6":"test_df.info()","059bdb6c":"train_df.describe()","a92682ed":"train_df.describe(include=['O'])","70b6ba47":"train_df.describe(include='all')","987e6d38":"train_df[['Pclass', 'Survived']].head()","48804802":"train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by = 'Survived', ascending=False)","50c00780":"train_df[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by = 'Survived', ascending=False)","7a3549ae":"#SibSp\u306f\u914d\u5076\u8005\uff08\u5bb6\u65cf\u306e\u6570\uff1f\uff09\ntrain_df[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by = 'Survived', ascending=False)","71acaa19":"#\u5b50\u4f9b\u306e\u6570\uff1f\ntrain_df[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by = 'Survived', ascending=False)","39844ac0":"#\u5e74\u9f62\u3054\u3068\u306e\u751f\u5b58=1\u30fb\u6b7b\u4ea1=0(bins\u306f\u5e45)\ng = sns.FacetGrid(train_df, col = 'Survived')\ng.map(plt.hist,'Age',bins = 20)","47869b32":"grid = sns.FacetGrid(train_df, col = 'Survived', row = 'Pclass', size = 2.2, aspect=1.6)\ngrid.map(plt.hist,'Age', alpha = .5,bins = 20)\ngrid.add_legend();","8fc94d6c":"grid2 = sns.FacetGrid(train_df, row = 'Embarked', size = 2.2, aspect=1.6)\ngrid2.map(sns.pointplot,'Pclass', 'Survived', 'Sex', palette = 'deep')\ngrid2.add_legend()","7a9fd52b":"grid = sns.FacetGrid(train_df, row = 'Embarked',col = 'Survived', size = 2.2, aspect=1.6)\ngrid.map(sns.barplot,'Sex', 'Fare', alpha=.5, ci = None)\ngrid.add_legend()","a260d283":"print(\"Before\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)\n\n#train_df = train_df.drop([\"Ticket\", \"Cabin\"], axis=1)\n#test_df = test_df.drop([\"Ticket\", \"Cabin\"], axis=1)\ntrain_df = train_df.drop([\"Ticket\"], axis=1)\ntest_df = test_df.drop([\"Ticket\"], axis=1)\ncombine = [train_df, test_df]\n\n\"After\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape","c695d00c":"#\u8ffd\u52a0\u9805\u76ee\nfor dataset in combine:\n    dataset[\"Cabin_initial\"] = dataset.Cabin.str.extract(\"([A-Za-z])\", expand=False)\n\n#train_df[\"Cabin\"].head()\ntrain_df[[\"Cabin_initial\", \"Survived\"]].groupby([\"Cabin_initial\"], as_index=False).mean()","8b9d2e9f":"#\u8ffd\u52a0\u9805\u76ee\ntrain_df[\"Cabin_initial\"].head()","a0fdec76":"#\u8ffd\u52a0\u9805\u76ee\nfor dataset in combine:\n    dataset.loc[ dataset[\"Cabin_initial\"] == \"A\", \"Cabin_initial\"] = 0\n    dataset.loc[ dataset[\"Cabin_initial\"] == \"B\", \"Cabin_initial\"] = 1\n    dataset.loc[ dataset[\"Cabin_initial\"] == \"C\", \"Cabin_initial\"] = 2\n    dataset.loc[ dataset[\"Cabin_initial\"] == \"D\", \"Cabin_initial\"] = 3\n    dataset.loc[ dataset[\"Cabin_initial\"] == \"E\", \"Cabin_initial\"] = 4\n    dataset.loc[ dataset[\"Cabin_initial\"] == \"F\", \"Cabin_initial\"] = 5\n    dataset.loc[ dataset[\"Cabin_initial\"] == \"G\", \"Cabin_initial\"] = 6\n    dataset.loc[ dataset[\"Cabin_initial\"] == \"T\", \"Cabin_initial\"] = 7\n    dataset[\"Cabin_initial\"] = dataset[\"Cabin_initial\"].fillna(8)\ntrain_df.head()","9c700bf0":"#\u8ffd\u52a0\u9805\u76ee\ntrain_df[[\"Cabin_initial\", \"Survived\"]].groupby([\"Cabin_initial\"], as_index=False).mean()","be5f8985":"for dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract('([A-Za-z]+)\\.',expand =False)\n\n#\u30af\u30ed\u30b9\u96c6\u8a08?\npd.crosstab(train_df['Title'], train_df['Sex'])","322b51ac":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady','Countess','Capt','Col','Don', 'Major','Sir','Jonkheer','Dona'],'Rare')\n    \n    dataset['Title'] = dataset['Title'].replace('Mlle','Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms','Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme','Mrs')\n    dataset['Title']= dataset['Title'].replace(['Rev','Dr'] ,'imp')\n\ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index = False).mean()","af696f48":"title_mapping = {\"Mr\":1,\"Miss\":2, \"Mrs\":3,\"Master\":4,\"imp\":5, \"Rare\":6}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    \ntrain_df.head()","c934f3e7":"from ethnicolr import pred_census_ln\n\nextname = train_df.Name.str.extract('\\. ([A-Za-z]+)', expand=False)\nname_df = pd.DataFrame(extname)\ndatas = pred_census_ln(name_df,'Name')\ndatas = datas.fillna('white')\ntrain_df['race'] = datas['race'].map({'api': 0, 'black': 1, 'hispanic': 2,'white': 3}).astype(int)\ntrain_df.head()\n\nextname = test_df.Name.str.extract('\\. ([A-Za-z]+)', expand=False)\nname_df = pd.DataFrame(extname)\ndatas = pred_census_ln(name_df,'Name')\ndatas = datas.fillna('white')\ntest_df['race'] = datas['race'].map({'api': 0, 'black': 1, 'hispanic': 2,'white': 3}).astype(int)\ntest_df.head()","5151bd6a":"train_df = train_df.drop(['Name', 'PassengerId','Cabin'],axis=1)\ntest_df = test_df.drop(['Name','Cabin'],axis = 1)\ncombine = [train_df,test_df]\ntrain_df.shape,test_df.shape","c19f5cc9":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map({'female' : 1, 'male' : 0}).astype(int)\n    \ntrain_df.head()","054ac505":"grid = sns.FacetGrid(train_df, row= 'Pclass',col = 'Sex', size = 2.2, aspect= 1.6)\ngrid.map(plt.hist,'Age', alpha=0.5, bins = 20)\ngrid.add_legend()","abc9551e":"guess_ages = np.zeros((2,3))\n\nfor dataset in combine:\n    for i in range(0,2):\n        for j in range(0,3):\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                              (dataset['Pclass'] == j + 1)]['Age'].dropna()\n            age_guess = guess_df.median()\n            guess_ages[i,j] = int(age_guess\/0.5+0.5) * 0.5\n    for i in range(0,2):\n        for j in range(0,3):\n            dataset.loc[(dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                        'Age'] = guess_ages[i,j]\n        \n    dataset['Age'] = dataset['Age'].astype(int)\ntrain_df.head()\n    \n                                            ","aff6f323":"train_df['AgeBand'] = pd.cut(train_df['Age'], 6)\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index = False).mean().sort_values(by = 'AgeBand',ascending = True)","7df29a99":"# for dataset in combine:\n#     dataset.loc[dataset['Age'] <= 16,'Age'] = 0\n#     dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32),'Age'] = 1\n#     dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48),'Age'] = 2\n#     dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64),'Age'] = 3\n#     dataset.loc[dataset['Age'] > 64,'Age']\n# train_df.head()\n\nfor dataset in combine :\n    dataset.loc[dataset['Age'] <=13 ,'Age'] =0\n    dataset.loc[(dataset['Age'] >13) &(dataset['Age'] <=27) ,'Age'] =1\n    dataset.loc[(dataset['Age'] >27) &(dataset['Age'] <=40) ,'Age'] =2\n    dataset.loc[(dataset['Age'] >40) &(dataset['Age'] <=53) ,'Age'] =3\n    dataset.loc[(dataset['Age'] >53) &(dataset['Age'] <=67) ,'Age'] =4\n    dataset.loc[dataset['Age'] >67 ,'Age'] =5\ntrain_df.head()","95cf7838":"train_df = train_df.drop(['AgeBand'],axis = 1)\ncombine = [train_df,test_df]\ntrain_df.head()","047af6cb":"#\u5b50\u4f9b\u304c\u3044\u308b\u304b\u3044\u306a\u3044\u304b\u306e\u5909\u6570\u3092\u4f5c\u308b \u8ffd\u52a0\u9805\u76ee\n# for dataset in combine:\n#     dataset.loc[ dataset[\"Parch\"] == 0, \"Chill\"] = 0\n#     dataset.loc[ dataset[\"Parch\"] > 0, \"Chill\"] = 1\n#     dataset.loc[dataset[\"Chill\"], \"Chill\"] = dataset.loc[dataset[\"Chill\"], \"Chill\"].astype(int)\n        \n# train_df[train_df[\"Parch\"]>0].head()","2526394a":"# #\u5b50\u4f9b\u304c\u591a\u3044\u304b\u591a\u304f\u306a\u3044\u304b\u306e\u5909\u6570\u3092\u4f5c\u308b\n# for dataset in combine:\n#     dataset.loc[ dataset[\"Parch\"] <= 3, \"Lots\"] = 0\n#     dataset.loc[ dataset[\"Parch\"] >= 4, \"Lots\"] = 1\n#     dataset.loc[dataset[\"Lots\"], \"Lots\"] = dataset.loc[dataset[\"Lots\"], \"Lots\"].astype(int)\n        \n# train_df[train_df[\"Parch\"]>0].head()","7ab8ec2e":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index = False).mean().sort_values(by = 'Survived',ascending = False)","7f566824":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1,'IsAlone'] = 1\n\ntrain_df[['IsAlone', 'Survived']].groupby(['IsAlone'],as_index = False).mean()","153b0b51":"#train_df = train_df.drop([\"Parch\", \"SibSp\", \"FamilySize\"], axis=1)\n#test_df = test_df.drop([\"Parch\", \"SibSp\", \"FamilySize\"], axis=1)\ntrain_df = train_df.drop([\"Parch\", \"SibSp\"], axis=1)\ntest_df = test_df.drop([\"Parch\", \"SibSp\"], axis=1)\ncombine = [train_df, test_df]\n\ntrain_df.head()\n#\u5b50\u4f9b\u304c\u3044\u308b\u304b\u3044\u306a\u3044\u304b\u306e\u5909\u6570\u3092\u4f5c\u308b\u3068\u9ad8\u304f\u306a\u308b\n#\u5909\u6570\u306f\u306a\u308b\u3079\u304f\u6e1b\u3089\u3057\u305f\u3044\u3001\u8981\u7d20\u6570\u3082\u6e1b\u3089\u3057\u305f\u3044","f1b00b94":"# for dataset in combine:\n#     dataset['Age*Class'] = dataset.Age * dataset.Pclass\n    \n# train_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)","ebb13a2e":"# train_df[[\"Age*Class\", \"Survived\"]].groupby([\"Age*Class\"], as_index=False).mean()","2c27921c":"freq_port = train_df.Embarked.dropna().mode()[0]\nfreq_port","bce8dfb9":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n\ntrain_df[['Embarked','Survived']].groupby(['Embarked'],as_index=False).mean().sort_values(by='Survived',ascending = False)","94975093":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map({'S':0,'C':1, 'Q':2}).astype(int)\n    \ntrain_df.head()","7f3a9372":"test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace = True)\ntest_df.head()","20c3d9a4":"# for dataset in combine:\n#     dataset['Age*Fare'] = dataset.Age * dataset.Fare\n    \n# train_df.loc[:, ['Age*Fare', 'Age', 'Fare']].head(10)","f112f108":"# train_df['FareBand'] = pd.qcut(train_df['Fare'],5)\n# train_df[['FareBand','Survived']].groupby(['FareBand'], as_index = False).mean().sort_values(by = 'FareBand',ascending =True)","fbc08273":"# for dataset in combine:\n#     dataset.loc[dataset['Fare'] <= 7.91, 'Fare'] = 0\n#     dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454),'Fare'] = 1\n#     dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31),'Fare'] = 2\n#     dataset.loc[dataset['Fare'] >31, 'Fare'] = 3\n#     dataset['Fare'] = dataset['Fare'].astype(int)\n\n# train_df = train_df.drop(['FareBand'],axis = 1)\n# combine = [train_df, test_df]\n\n# train_df.head(10)\n\n# for dataset in combine :\n#     dataset.loc[dataset['Fare'] <=7.85 ,'Fare'] =0\n#     dataset.loc[(dataset['Fare'] >7.85) &(dataset['Fare'] <=10.5) ,'Fare'] =1\n#     dataset.loc[(dataset['Fare'] >10.5) &(dataset['Fare'] <=21.68) ,'Fare'] =2\n#     dataset.loc[(dataset['Fare'] >21.68) &(dataset['Fare'] <=39.69) ,'Fare'] =3\n#     dataset.loc[dataset['Fare'] >39.69 ,'Fare']=4\n#     dataset['Fare'] =dataset['Fare'].astype(int)\n    \n# train_df = train_df.drop(['FareBand'],axis =1)\n# combine =[train_df , test_df]\n\n# train_df.head(10)","b713b176":"test_df.head(10)","701ceb8e":"#Y\u6210\u5206\u304c\u5fc5\u305a\uff11\u306b\u306a\u3063\u3066\u3044\u308b\u3053\u3068\u3092\u78ba\u8a8d(891,1) 8\u3082\u5408\u3063\u3066\u306a\u304d\u3083\u3044\u3051\u306a\u3044\nX_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test = test_df.drop(\"PassengerId\", axis=1).copy()\nX_train.shape,Y_train.shape,X_test.shape","780233e7":"logreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","0751d7ae":"coeff_df = pd.DataFrame(train_df.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)","b009d78a":"svc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","ab3f187c":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","0a12c113":"gaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","60d26a68":"perceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\nacc_perceptron","6d819d25":"linear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","cfe8f802":"sgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","85b91ec2":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","678b7cc0":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","2e49c95b":"models = pd.DataFrame({\n    'Model' : ['Support Vector Machines','KNN', 'Logistic Regression',\n              'Random Forest', 'Naive Bayes','Perceptron',\n               'Stochastic Gradient Decent','Liner SVC',\n              'Decision Tree'],\n    'Score' : [acc_svc, acc_knn, acc_log,\n              acc_random_forest, acc_gaussian, acc_perceptron,\n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","e7d5fb6f":"\u305d\u308c\u305e\u308c\u306e\u751f\u5b58\u7387"}}