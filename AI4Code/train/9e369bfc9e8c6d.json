{"cell_type":{"3025cbbd":"code","43534abd":"code","77847eb3":"code","f947ab53":"code","51ddd516":"code","50f12bcd":"code","e4772bae":"code","4c570566":"code","5595e355":"code","1509d640":"code","8b3503d6":"code","c72388bd":"code","246837b8":"code","b30f4131":"code","810e2e49":"code","8707493f":"code","364dc8b8":"code","ec463772":"code","33c77fb7":"code","bc0b7437":"code","0c55d4e3":"code","ce3a0ee2":"code","c77d419b":"code","ee75aa48":"code","ddcfa634":"code","44baaded":"code","506b5dac":"code","22068367":"code","03ffef21":"code","270066f0":"code","8c9f399d":"code","3608b198":"code","64d67392":"code","a4235d4c":"code","812e72c2":"code","5fe485e6":"code","55af15b7":"code","d39293d2":"code","6f131c5c":"code","d973ebbf":"code","e59346e1":"code","61ff2b28":"code","9a135f48":"code","00a9fdbd":"code","d50890b7":"code","1a6ca876":"code","22405911":"code","ed32f5a9":"code","41943735":"code","898b0a7a":"code","21d4c24b":"code","99f13b1f":"code","c99d291d":"code","060fc507":"markdown","12b92578":"markdown","f92240ae":"markdown","fef519a4":"markdown","beb38444":"markdown","e06e92dc":"markdown","5c8dbd38":"markdown","bb7069d9":"markdown","be71fcda":"markdown","66a04197":"markdown","13cbf627":"markdown","7abfa4d3":"markdown","3bec3c91":"markdown","b9280213":"markdown","0d971a03":"markdown","e4187abe":"markdown","6854b428":"markdown","96110bcf":"markdown","33ab32e4":"markdown","079a1669":"markdown","65aa5050":"markdown","2a8882a9":"markdown","a6b3c0cf":"markdown","9581f729":"markdown","15c64855":"markdown","9910952a":"markdown","4242c702":"markdown","c205146d":"markdown","8fc40e2f":"markdown","5b6d6ce3":"markdown","74d7b18a":"markdown","b2218c03":"markdown","983a0ef3":"markdown","4e05115d":"markdown","fbde6b55":"markdown","09f127cb":"markdown","2cdc43d6":"markdown","02426a7d":"markdown","48f7b058":"markdown","a3b5bbab":"markdown"},"source":{"3025cbbd":"# load the libraries\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler,OneHotEncoder\nfrom sklearn.model_selection import StratifiedKFold","43534abd":"# read data\nrawdf = pd.read_csv(\"\/kaggle\/input\/health-insurance-cross-sell-prediction\/train.csv\")\ntest  = pd.read_csv(\"\/kaggle\/input\/health-insurance-cross-sell-prediction\/test.csv\")","77847eb3":"#see the head of data\nrawdf.head()","f947ab53":"# get the data types of all features\nrawdf.dtypes","51ddd516":"#get integer data types\nrawdf.dtypes[rawdf.dtypes==\"int64\"]","50f12bcd":"# Driving_License, Previously_Insured,Response is a categorical varriable so we convert it into category\nrawdf[\"Driving_License\"] = rawdf[\"Driving_License\"].astype(\"category\") \nrawdf[\"Previously_Insured\"] = rawdf[\"Previously_Insured\"].astype(\"category\") \nrawdf[\"Driving_License\"] = rawdf[\"Driving_License\"].astype(\"category\") \nrawdf[\"Response\"] = rawdf[\"Response\"].astype(\"category\")","e4772bae":"# get float data types \nrawdf.dtypes[rawdf.dtypes == \"float64\"]","4c570566":"#Region code , Policy Sales Channel are categorical varriables\nrawdf[\"Region_Code\"] = rawdf[\"Region_Code\"].astype(\"category\")\nrawdf[\"Policy_Sales_Channel\"] = rawdf[\"Policy_Sales_Channel\"].astype(\"category\")","5595e355":"#vehicle age and vehicle damage is object varriable\nrawdf.dtypes[rawdf.dtypes==\"object\"]","1509d640":"# gender, vehicle age , vehicle damage are categorical varriables\nrawdf[\"Gender\"] = rawdf[\"Gender\"].astype(\"category\")\nrawdf[\"Vehicle_Age\"] = rawdf[\"Vehicle_Age\"].astype(\"category\")\nrawdf[\"Vehicle_Damage\"] = rawdf[\"Vehicle_Damage\"].astype(\"category\")","8b3503d6":"# check all features data types after conversion\nrawdf.dtypes","c72388bd":"# describe of all numeric values\nrawdf.describe()","246837b8":"def UVA_numeric(data, var_group):\n  ''' \n  Univariate_Analysis_numeric\n  takes a group of variables (INTEGER and FLOAT) and plot\/print all the descriptives and properties along with KDE.\n\n  Runs a loop: calculate all the descriptives of i(th) variable and plot\/print it\n  '''\n\n  size = len(var_group)\n  plt.figure(figsize = (7*size,3), dpi = 100)\n  \n  #looping for each variable\n  for j,i in enumerate(var_group):\n    \n    # calculating descriptives of variable\n    mini = data[i].min()\n    maxi = data[i].max()\n    ran = data[i].max()-data[i].min()\n    mean = data[i].mean()\n    median = data[i].median()\n    st_dev = data[i].std()\n    skew = data[i].skew()\n    kurt = data[i].kurtosis()\n\n    # calculating points of standard deviation\n    points = mean-st_dev, mean+st_dev\n\n    #Plotting the variable with every information\n    plt.subplot(1,size,j+1)\n    sns.kdeplot(data[i], shade=True)\n    sns.lineplot(points, [0,0], color = 'black', label = \"std_dev\")\n    sns.scatterplot([mini,maxi], [0,0], color = 'orange', label = \"min\/max\")\n    sns.scatterplot([mean], [0], color = 'red', label = \"mean\")\n    sns.scatterplot([median], [0], color = 'blue', label = \"median\")\n    plt.xlabel('{}'.format(i), fontsize = 20)\n    plt.ylabel('density')\n    plt.title('std_dev = {}; kurtosis = {};\\nskew = {}; range = {}\\nmean = {}; median = {}'.format((round(points[0],2),round(points[1],2)),\n                                                                                                   round(kurt,2),\n                                                                                                   round(skew,2),\n                                                                                                   (round(mini,2),round(maxi,2),round(ran,2)),\n                                                                                                   round(mean,2),\n                                                                                                   round(median,2)))","b30f4131":"# get numeric varriables\nrawdf.select_dtypes(include=['int64','float64','Int64']).dtypes","810e2e49":"#Segregating varriables into groups\ncustomer_details = [\"Age\",\"Vintage\"]","8707493f":"UVA_numeric(rawdf,customer_details)","364dc8b8":"UVA_numeric(rawdf,[\"Annual_Premium\"])","ec463772":"def UVA_category(data, var_group):\n\n  '''\n  Univariate_Analysis_categorical\n  takes a group of variables (category) and plot\/print all the value_counts and barplot.\n  '''\n  # setting figure_size\n  size = len(var_group)\n  plt.figure(figsize = (7*size,5), dpi = 100)\n\n  # for every variable\n  for j,i in enumerate(var_group):\n    n_uni = data[i].nunique()\n    if n_uni > 20:\n        norm_count1 = data[i].value_counts(normalize = True)\n        norm_count = norm_count1.sort_values().tail(20) \n    else:\n        norm_count = data[i].value_counts(normalize = True)\n    \n\n  #Plotting the variable with every information\n    plt.subplot(1,size,j+1)\n    sns.barplot(norm_count, norm_count.index , order = norm_count.index)\n    plt.xlabel('fraction\/percent', fontsize = 20)\n    plt.ylabel('{}'.format(i), fontsize = 20)\n    plt.title('n_uniques = {} \\n value counts \\n {};'.format(n_uni,norm_count))","33c77fb7":"rawdf.select_dtypes(include=[\"category\"]).dtypes","bc0b7437":"# top 53 region code are taken\nUVA_category(rawdf,[\"Gender\",\"Driving_License\",\"Region_Code\"])","0c55d4e3":"UVA_category(rawdf,[\"Vehicle_Age\",\"Vehicle_Damage\"])","ce3a0ee2":"UVA_category(rawdf,[\"Policy_Sales_Channel\",\"Previously_Insured\"])","c77d419b":"UVA_category(rawdf,[\"Response\"])","ee75aa48":"rawdf.isnull().sum()","ddcfa634":"# custom function for easy outlier analysis\n\ndef UVA_outlier(data, var_group, include_outlier = True):\n  '''\n  Univariate_Analysis_outlier:\n  takes a group of variables (INTEGER and FLOAT) and plot\/print boplot and descriptives\\n\n  Runs a loop: calculate all the descriptives of i(th) variable and plot\/print it \\n\\n\n\n  data : dataframe from which to plot from\\n\n  var_group : {list} type Group of Continuous variables\\n\n  include_outlier : {bool} whether to include outliers or not, default = True\\n\n  '''\n\n  size = len(var_group)\n  plt.figure(figsize = (7*size,4), dpi = 100)\n  \n  #looping for each variable\n  for j,i in enumerate(var_group):\n    \n    # calculating descriptives of variable\n    quant25 = data[i].quantile(0.25)\n    quant75 = data[i].quantile(0.75)\n    IQR = quant75 - quant25\n    med = data[i].median()\n    whis_low = med-(1.5*IQR)\n    whis_high = med+(1.5*IQR)\n\n    # Calculating Number of Outliers\n    outlier_high = len(data[i][data[i]>whis_high])\n    outlier_low = len(data[i][data[i]<whis_low])\n\n    if include_outlier == True:\n      #Plotting the variable with every information\n      plt.subplot(1,size,j+1)\n      sns.boxplot(data[i], orient=\"v\")\n      plt.ylabel('{}'.format(i))\n      plt.title('With Outliers\\nIQR = {}; Median = {} \\n 2nd,3rd  quartile = {};\\n Outlier (low\/high) = {} \\n'.format(\n                                                                                                   round(IQR,2),\n                                                                                                   round(med,2),\n                                                                                                   (round(quant25,2),round(quant75,2)),\n                                                                                                   (outlier_low,outlier_high)\n                                                                                                   ))\n      \n    else:\n      # replacing outliers with max\/min whisker\n      data2 = data[var_group][:]\n      data2[i][data2[i]>whis_high] = whis_high+1\n      data2[i][data2[i]<whis_low] = whis_low-1\n      \n      # plotting without outliers\n      plt.subplot(1,size,j+1)\n      sns.boxplot(data2[i], orient=\"v\")\n      plt.ylabel('{}'.format(i))\n      plt.title('Without Outliers\\nIQR = {}; Median = {} \\n 2nd,3rd  quartile = {};\\n Outlier (low\/high) = {} \\n'.format(\n                                                                                                   round(IQR,2),\n                                                                                                   round(med,2),\n                                                                                                   (round(quant25,2),round(quant75,2)),\n                                                                                                   (outlier_low,outlier_high)\n                                                                                                   ))","44baaded":"UVA_outlier(rawdf,[\"Annual_Premium\",\"Age\",\"Vintage\"] )","506b5dac":"numerical_data = rawdf.select_dtypes(include=[\"int64\",\"Int64\",\"float64\"])\nnumerical_data.corr()","22068367":"# plotting heatmap usill all methods for all transaction variables\nplt.figure(figsize=(36,6), dpi=140)\nfor j,i in enumerate(['pearson']):\n  plt.subplot(1,3,j+1)\n  correlation = numerical_data.dropna().corr(method=i)\n  sns.heatmap(correlation, linewidth = 2)\n  plt.title(i, fontsize=18)","03ffef21":"# scatter plot for all numerical varriables\nplt.figure(dpi=140)\nsns.pairplot(numerical_data)","270066f0":"def TwoSampZ(X1, X2, sigma1, sigma2, N1, N2):\n  '''\n  takes mean, standard deviation, and number of observations and returns p-value calculated for 2-sampled Z-Test\n  '''\n  from numpy import sqrt, abs, round\n  from scipy.stats import norm\n  ovr_sigma = sqrt(sigma1**2\/N1 + sigma2**2\/N2)\n  z = (X1 - X2)\/ovr_sigma\n  pval = 2*(1 - norm.cdf(abs(z)))\n  return pval","8c9f399d":"def TwoSampT(X1, X2, sd1, sd2, n1, n2):\n  '''\n  takes mean, standard deviation, and number of observations and returns p-value calculated for 2-sample T-Test\n  '''\n  from numpy import sqrt, abs, round\n  from scipy.stats import t as t_dist\n  ovr_sd = sqrt(sd1**2\/n1 + sd2**2\/n2)\n  t = (X1 - X2)\/ovr_sd\n  df = n1+n2-2\n  pval = 2*(1 - t_dist.cdf(abs(t),df))\n  return pval","3608b198":"def Bivariate_cont_cat(data, cont, cat, category):\n  #creating 2 samples\n  x1 = data[cont][data[cat]==category][:]\n  x2 = data[cont][~(data[cat]==category)][:]\n  \n  #calculating descriptives\n  n1, n2 = x1.shape[0], x2.shape[0]\n  m1, m2 = x1.mean(), x2.mean()\n  std1, std2 = x1.std(), x2.mean()\n  \n  #calculating p-values\n  t_p_val = TwoSampT(m1, m2, std1, std2, n1, n2)\n  z_p_val = TwoSampZ(m1, m2, std1, std2, n1, n2)\n\n  #table\n  table = pd.pivot_table(data=data, values=cont, columns=cat, aggfunc = np.mean)\n\n  #plotting\n  plt.figure(figsize = (15,6), dpi=140)\n  \n  #barplot\n  plt.subplot(1,2,1)\n  sns.barplot([str(category),'not {}'.format(category)], [m1, m2])\n  plt.ylabel('mean {}'.format(cont))\n  plt.xlabel(cat)\n  plt.title('t-test p-value = {} \\n z-test p-value = {}\\n {}'.format(t_p_val,\n                                                                z_p_val,\n                                                                table))\n\n  # boxplot\n  plt.subplot(1,2,2)\n  sns.boxplot(x=cat, y=cont, data=data)\n  plt.title('categorical boxplot')\n  ","64d67392":"Bivariate_cont_cat(rawdf, 'Vintage', 'Response', 1)","a4235d4c":"Bivariate_cont_cat(rawdf, 'Age', 'Response', 1)","812e72c2":"Bivariate_cont_cat(rawdf, 'Annual_Premium', 'Response', 1)","5fe485e6":"def BVA_categorical_plot(data, tar, cat):\n  '''\n  take data and two categorical variables,\n  calculates the chi2 significance between the two variables \n  and prints the result with countplot & CrossTab\n  '''\n  #isolating the variables\n  data = data[[cat,tar]][:]\n\n  #forming a crosstab\n  table = pd.crosstab(data[tar],data[cat],)\n  f_obs = np.array([table.iloc[0][:].values,\n                    table.iloc[1][:].values])\n\n  #performing chi2 test\n  from scipy.stats import chi2_contingency\n  chi, p, dof, expected = chi2_contingency(f_obs)\n  \n  #checking whether results are significant\n  if p<0.05:\n    sig = True\n  else:\n    sig = False\n\n  #plotting grouped plot\n  sns.countplot(x=cat, hue=tar, data=data)\n  plt.title(\"p-value = {}\\n difference significant? = {}\\n\".format(round(p,8),sig))\n\n  #plotting percent stacked bar plot\n#   sns.catplot(ax, kind='stacked')\n  ax1 = data.groupby(cat)[tar].value_counts(normalize=True).unstack()\n  ax1.plot(kind='bar', stacked='True',title=str(ax1))\n  int_level = data[cat].value_counts()","55af15b7":"BVA_categorical_plot(rawdf, \"Response\",\"Driving_License\")","d39293d2":"BVA_categorical_plot(rawdf, \"Response\",\"Previously_Insured\")","6f131c5c":"BVA_categorical_plot(rawdf, \"Response\",\"Vehicle_Damage\")","d973ebbf":"BVA_categorical_plot(rawdf, \"Response\",\"Vehicle_Age\")","e59346e1":"BVA_categorical_plot(rawdf, \"Response\",\"Gender\")","61ff2b28":"# Sales Channel wise Total Customers Count\npsc_total = rawdf.groupby(\"Policy_Sales_Channel\")[\"Response\"].count()\\\n                          .reset_index(name='count') \\\n                             .sort_values(['count'], ascending=False)\npsc_total","9a135f48":"# filter interested customers count \nFormattedData = rawdf[rawdf[\"Response\"]==1].groupby(\"Policy_Sales_Channel\")[\"Response\"].count()\\\n                          .reset_index(name='count') \\\n                             .sort_values(['count'], ascending=False) \n\nFormattedData[\"total_count\"] = psc_total[\"count\"]\nFormattedData[\"success_rate\"] = (FormattedData[\"count\"]\/FormattedData[\"total_count\"])*100 \nFormattedData[FormattedData[\"total_count\"]>500].sort_values(\"success_rate\",ascending=False).head(50)","00a9fdbd":"# Sales Channel wise Total Customers Count\npsc_total = rawdf.groupby(\"Region_Code\")[\"Response\"].count()\\\n                          .reset_index(name='count') \\\n                             .sort_values(['count'], ascending=False)\npsc_total.head(25)","d50890b7":"# filter interested customers count \nFormattedData = rawdf[rawdf[\"Response\"]==1].groupby(\"Region_Code\")[\"Response\"].count()\\\n                          .reset_index(name='count') \\\n                             .sort_values(['count'], ascending=False) \n\nFormattedData[\"total_count\"] = psc_total[\"count\"]\nFormattedData[\"success_rate\"] = (FormattedData[\"count\"]\/FormattedData[\"total_count\"])*100 \nFormattedData[FormattedData[\"total_count\"]>500].sort_values(\"success_rate\",ascending=False).head(25)","1a6ca876":"FormattedData[FormattedData[\"total_count\"]>10000].sort_values(\"success_rate\",ascending=False)","22405911":"# average success rate is less\nFormattedData[\"success_rate\"].mean()","ed32f5a9":"train = rawdf\ntrainY = rawdf[\"Response\"]","41943735":"train.info()","898b0a7a":"import pandas as pd\nnum_feature = [\"Age\",\"Vintage\",\"Annual_Premium\"]\ncat_feature = [\"Gender\",\"Driving_License\",\"Region_Code\",\"Previously_Insured\",\"Vehicle_Age\",\"Vehicle_Damage\",\"Policy_Sales_Channel\"]\ntrain[\"Age_Cat\"]= pd.cut(train[\"Age\"],bins=[10,20,30,40,50,60,70,80,90,100],labels=[1,2,3,4,5,6,7,8,9])\ntrain[\"Policy_Sales_Channel\"] = train[\"Policy_Sales_Channel\"].astype(\"int\")\ntrain[\"Region_Code\"] = train[\"Region_Code\"].astype(\"int\")\n\nohe = OneHotEncoder(sparse=False)        \ntransformed_train_data = ohe.fit_transform(train[[\"Age_Cat\",\"Gender\",\"Vehicle_Age\",\"Previously_Insured\",\"Driving_License\",\"Vehicle_Damage\"]])\n\n# # the above transformed_data is an array so convert it to dataframe\nencoded_train_data = pd.DataFrame(transformed_train_data, index=train.index)        \ntrain_data = pd.concat([train, encoded_train_data], axis=1)","21d4c24b":"trainX = train_data.drop([\"id\",\"Age\",\"Age_Cat\",\"Gender\",\"Vehicle_Age\",\"Driving_License\",\"Previously_Insured\",\"Vehicle_Damage\",\"Response\"], axis=1)\ntrainX.columns","99f13b1f":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score,confusion_matrix\nlogreg = LogisticRegression(random_state=0)\nmodels = {\n    \"Logistic Regression\":logreg,\n#     \"RandomForestClassifier\":rf\n}\nfeatures = [\"Gender\",\"Driving_License\",\"Previously_Insured\",\"Vehicle_Age\",\"Vehicle_Damage\"]\nskf = StratifiedKFold(n_splits=5, shuffle=True)\nfor model_name,model in models.items():\n    scores = []\n    train_scores = []\n    for train_indx,val_indx in skf.split(X=trainX,y=trainY):\n        #get train and test data     \n        X_train,X_val = trainX.loc[train_indx],trainX.loc[val_indx]\n        Y_train,Y_val = trainY[train_indx],trainY[val_indx]\n        sc = StandardScaler()\n        train_sc = sc.fit_transform(X_train)\n        val_sc  = sc.fit_transform(X_val)\n        #train a model\n        model.fit(train_sc,Y_train)\n        #make a prediction\n        Y_predict = model.predict_proba(val_sc)\n        accuracy = roc_auc_score(Y_val,Y_predict[:,1])\n        Ytrain_predict = model.predict_proba(train_sc)\n        train_accuracy = roc_auc_score(Y_train,Ytrain_predict[:,1])        \n        print(\"train\",train_accuracy)\n        print(\"test\",accuracy)\n        scores.append(accuracy)\n        train_scores.append(train_accuracy)\n    print(\"Mean Accurracy of test {0} is {1}\".format(model_name,np.mean(scores)))\n    print(\"Mean Accurracy of train {0} is {1}\".format(model_name,np.mean(train_scores)))\n    ","c99d291d":"\ntest[\"Age_Cat\"]= pd.cut(test[\"Age\"],bins=[10,20,30,40,50,60,70,80,90,100],labels=[1,2,3,4,5,6,7,8,9])\ntest[\"Policy_Sales_Channel\"] = test[\"Policy_Sales_Channel\"].astype(\"int\")\ntest[\"Region_Code\"] = test[\"Region_Code\"].astype(\"int\")\n\nohe = OneHotEncoder(sparse=False)        \ntransformed_test_data = ohe.fit_transform(test[[\"Age_Cat\",\"Gender\",\"Vehicle_Age\",\"Previously_Insured\",\"Driving_License\",\"Vehicle_Damage\"]])\n\n# # the above transformed_data is an array so convert it to dataframe\nencoded_test_data = pd.DataFrame(transformed_test_data, index=test.index)        \ntest_data = pd.concat([test, encoded_test_data], axis=1)\ntestX = test_data.drop([\"id\",\"Age\",\"Age_Cat\",\"Gender\",\"Vehicle_Age\",\"Previously_Insured\",\"Driving_License\",\"Vehicle_Damage\"],axis=1)\nsc = StandardScaler()\ntestt = sc.fit_transform(testX)\n#predict\npredictions = logreg.predict(testt)\noutput = pd.DataFrame({'id': test.id, 'Response': predictions})\nprint(output[\"Response\"].value_counts())\noutput.to_csv('submission.csv', index=False)","060fc507":"### Are **vintage customers** interested in insurance?","12b92578":"### Bivariate Analysis - Policy_Sales_Channel vs Response","f92240ae":"### summary\n* 95% Vechicle's age \"within 2 years\"\n* Vehicle Damage is equally splitted","fef519a4":"### Inference\n* significant differnece is there.But 99%(univariate analysis) customers has a license, In that only 1 % customers are interested others are not interested  ","beb38444":"# Bivariate Analysis","e06e92dc":"### Float data type","5c8dbd38":"#### summary\n* Most of the customers not interested in insurance\n* 99% customers are licensed  and 87% customers are not interested in insurance. so hyposthesis \" **licensed customer** **interested** in insurance\" is false   \n* Imbalanced target Varriable ","bb7069d9":"### Univariate Analysis Integer","be71fcda":"### Inference\n* Previously Insured customers not interested in insurance","66a04197":"### Are customers with **low annual premium**,   **Interested** in insurance ?","13cbf627":"# Univariate Analysis","7abfa4d3":"### summary\n* Annual premium has a extreme outlier","3bec3c91":"### Inference\n* Vehicle damaged customers has a interest in insurance ","b9280213":"### Object data type","0d971a03":"### Inference\n* Overall vehicle Age 1-2 year category , interested customer's count is high.but\n* In >2 year Age category, Interested customers percentage is high when compared to other category   ","e4187abe":"# Varriable Identification and TypeCasting","6854b428":"### Integer Data type","96110bcf":"## Bivariate Analysis: Continuous-Categorical variables","33ab32e4":"### summary\n* No significant difference in vintage customers . so reject this hypothesis \n* both interested and no interested customers mean vintage is approxiamately same. no significant difference is there.so vintage has no impact on customer interest\n* No outliers ","079a1669":"### ScatterPlot","65aa5050":"### summary\n* Most used ploicy sales channel code(152,26,124,160,156,122,157,154)\n* Previously Insured people was less","2a8882a9":"## *Hypothesis*\n* Are customers with **low annual premium**,   **Interested** in insurance ?  \n* Are **vintage customers** intersted in insurance?\n* Are **Licensed customers** **interested** in insurance\n* Are customers **interested** in insurance  **when vehicle has a damage**\n* Are Customers **interested** in insurance when **vehicle age <1 year(new bike)**\n* Are **previously insured** customers, **not interested** in insurance\n","a6b3c0cf":"### Univariate Analysis - Category","9581f729":"### Are aged customers interested in insurance?","15c64855":"### Bivariate Analysis(Region_code vs Response)","9910952a":"This is My first EDA Notebook , So give a comment if i have done any mistakes in this EDA. \nYour client is an Insurance company that has provided Health Insurance to its customers now they need your help in building a model to predict whether the policyholders (customers) from past year will also be interested in Vehicle Insurance provided by the company.","4242c702":"### Inference\n* Annual premium mean for interested customer is 30419\n* Annual premium mean for not interested customer is 31604\n* Annual Premium makes impact on customer interest\n","c205146d":"### Are licensed customer has a more interest?","8fc40e2f":"### summary\n* Male customers higher than Female\n* 99 % customers has a License\n* Region Code 28 has a high number of customers\n* Region Code 8, 46, 41 has a second high number of customers","5b6d6ce3":"# Univariate - Missing Values and Outlier Analysis","74d7b18a":"#### summary\n* Most of the customers Age between 20 to 30 and 40 to 50 some peak there.\n* vintage is normaly distributed. Average vintage value is 150\n* Annual Premium is Highly skewed and also more kurtosis value so it has a extreme outliers ","b2218c03":"# Exploratory  Data Analysis","983a0ef3":"### summary\n* policy sales channel 155 has high success rate(32%) when compared to other channels.\n* policy sales channel 26 has a more intersted customers. but success rate is 19%\n","4e05115d":"### summary\n*  High total customers and succes rate place code is 28\n*  low success rate and high customers count, places(50,15,30,8,9) \n* Region code affects the customer interest but average success rate of all region is less.","fbde6b55":" ### Inference\n * Interested Customers age between 35 to 52.\n * Uninterested Customers age between 25 to 48.\n * p-value of z and t tests  is 0 , so significant difference there. It indicates age makes a impact on customer interest\n \n ","09f127cb":"### summary\n\n* Features dont have a strong correlation\n\n","2cdc43d6":"# Feature Engineering and Modeling","02426a7d":"### summary\n* In univarite Analysis, Already we have seen Policy sales channel 152 has a more entry","48f7b058":"* Male customers has more interest in insurance. ","a3b5bbab":"## Bivariate Analysis(categorical categorical)"}}