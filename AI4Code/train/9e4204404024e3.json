{"cell_type":{"9dd1752e":"code","994ea8bc":"code","6c0a2c6c":"code","f6ae217d":"code","f13e93c6":"code","90221e66":"code","eade9194":"code","2d693253":"code","aa4e74f3":"code","c21a963d":"code","946a9303":"code","cc997b9c":"code","c763a29b":"code","0ee8a015":"code","a4c8cdf3":"code","1b708edf":"code","ef70cfb8":"code","f53efb14":"code","83de4fd0":"code","2a56e0ff":"code","e59f23d5":"code","a8a55c28":"code","f1a06c96":"code","6d5db0c3":"code","99481771":"markdown","8f2f93af":"markdown","6f5e2133":"markdown","ffa16997":"markdown","4f1243c3":"markdown","282b7dba":"markdown","c41f73f8":"markdown","ae880d98":"markdown","4b422a66":"markdown"},"source":{"9dd1752e":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport re\nimport string\nfrom string import punctuation\n\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download(\"stopwords\")\nfrom nltk import pos_tag\nfrom nltk.tokenize import WhitespaceTokenizer\nfrom nltk.stem import WordNetLemmatizer\nnltk.download('averaged_perceptron_tagger')\nnltk.download('wordnet')\nnltk.download('vader_lexicon')","994ea8bc":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer","6c0a2c6c":"df = pd.read_csv(\"..\/input\/womens-clothing-reviews-csv\/Womens Clothing E-Commerce Reviews.csv\")","f6ae217d":"df = df.drop(['Title', 'Positive Feedback Count', 'Sr. No.'], axis=1)\ndf.dropna(inplace = True)","f13e93c6":"df.head()","90221e66":"sns.set_style('whitegrid')\nsns.countplot(x='Rating', data=df, palette='YlGnBu_r')","eade9194":"#Calculation of Polarity\ndf['Polarity Rating'] = df['Rating'].apply(lambda x: 'Positive' if x > 3 else('Neutral' if x == 3 else 'Negative'))\ndf.head()","2d693253":"#Plotting polarity on a graph - Visualizing data\nsns.set_style('whitegrid')\nsns.countplot(x='Polarity Rating', data=df, palette = 'summer')","aa4e74f3":"from nltk.corpus import wordnet\n\ndef get_wordnet_pos(pos_tag):\n    if pos_tag.startswith('J'):\n        return wordnet.ADJ\n    elif pos_tag.startswith('V'):\n        return wordnet.VERB\n    elif pos_tag.startswith('N'):\n        return wordnet.NOUN\n    elif pos_tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN","c21a963d":"#Data Preprocessing\ndf_positive = df[df['Polarity Rating'] == 'Positive'][0:8000]\ndf_negative = df[df['Polarity Rating'] == 'Negative']\ndf_neutral = df[df['Polarity Rating'] == 'Neutral']","946a9303":"#Sample negative and neutral polarity dataset and create final dataframe\ndf_neutral_final = df_neutral.sample(8000, replace = True)\ndf_negative_final = df_negative.sample(8000, replace = True)\ndf = pd.concat([df_positive, df_negative_final, df_neutral_final], axis=0)","cc997b9c":"def textProcessing(text):\n    text = text.lower()\n    #To remove punctuation\n    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n    #To remove words that contain numbers\n    text = [word for word in text if not any(c.isdigit() for c in word)]\n    #To remove stop words\n    stop = stopwords.words('english')\n    text = [x for x in text if x not in stop]\n    #To remove empty tokens\n    text = [t for t in text if len(t) > 0]\n    #Pos tag text\n    pos_tags = pos_tag(text)\n    #Lemmatize text\n    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n    #To remove words with only one letter\n    text = [t for t in text if len(t) > 1]\n    #Now, joining all \n    text = \" \".join(text)\n    return text","c763a29b":"df['Review'] = df['Review Text'].apply(textProcessing)\ndf.head()","0ee8a015":"from nltk.sentiment.vader import SentimentIntensityAnalyzer","a4c8cdf3":"sid = SentimentIntensityAnalyzer()\ndf['Sentiments'] = df['Review'].apply(lambda x: sid.polarity_scores(x))\ndf = pd.concat([df.drop(['Sentiments'], axis = 1), df['Sentiments'].apply(pd.Series)], axis = 1)\ndf.head()","1b708edf":"df['Number of Characters'] = df['Review'].apply(lambda x: len(x))\ndf['Number of Words'] = df['Review'].apply(lambda x: len(x.split(\" \")))\ndf.head()","ef70cfb8":"from gensim.test.utils import common_texts\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument","f53efb14":"documents = [TaggedDocument(doc,[i]) for i,doc in enumerate(df['Review'].apply(lambda x: x.split(\" \")))]","83de4fd0":"model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n\ndoc2vec_df = df['Review'].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(pd.Series)\ndoc2vec_df.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_df.columns]\ndf = pd.concat([df, doc2vec_df], axis=1)\ndf.head()","2a56e0ff":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(min_df = 6)\ntfidf_result = tfidf.fit_transform(df['Review']).toarray()\ntfidf_df = pd.DataFrame(tfidf_result, columns=tfidf.get_feature_names())\ntfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\ntfidf_df.index = df.index\ndf = pd.concat([df, tfidf_df], axis=1)\ndf.head()","e59f23d5":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(background_color = 'white', max_words = 200, max_font_size = 40, scale = 3,\n                          random_state = 42).generate(str(data))\n    fig = plt.figure(1, figsize=(20,20))\n    plt.axis('off')\n    if title:\n        fig.suptitle(title, fontsize = 20)\n        fig.subplots_adjust(top = 2.3)\n        \n    plt.imshow(wordcloud)\n    plt.show()","a8a55c28":"show_wordcloud(df['Review'])","f1a06c96":"df[df[\"Number of Words\"] >= 5].sort_values(\"pos\", ascending = False)[[\"Review\", \"pos\"]].head(10)\n","6d5db0c3":"df[df[\"Number of Words\"] >= 5].sort_values(\"neg\", ascending = False)[[\"Review\", \"neg\"]].head(10)","99481771":"## Text Cleaning - to remove unnecessary characters from the reviews.","8f2f93af":"## Displaying the top positive and negative reviews","6f5e2133":"## Importing required packages like pandas, numpy, seaborn, etc.","ffa16997":"## Data cleaning","4f1243c3":"## Function to create a word cloud of the most found words in reviews.","282b7dba":"## Using SentimentIntensityAnalyzer to analyze the reviews.","c41f73f8":"## Importing packages for Natural Language Processing ","ae880d98":"## Downloading the dataset from a CSV file using the package pandas.","4b422a66":"## Data Visualization"}}