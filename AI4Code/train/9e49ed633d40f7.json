{"cell_type":{"a10e60cf":"code","d782e2f2":"code","d2f318aa":"code","edc9a8aa":"code","db24e334":"code","7b7abe2c":"code","b1eec16a":"code","c54f21d4":"code","092a0aff":"code","78fce3da":"code","c6b6f14a":"code","23be7854":"code","6565b96d":"code","16ec7988":"code","b1c95acf":"code","6c92534a":"code","05de2661":"code","3b793fb2":"code","dda8bff6":"code","e2ad98d1":"code","6603d642":"code","e9855130":"code","d0b39170":"code","cf233254":"code","95d17624":"code","c0bac678":"code","d90d8c4e":"code","cb0596f8":"code","f520a989":"code","92c2b829":"code","a0fa06f5":"code","2fb34954":"code","6e8395d6":"code","16a6f084":"code","bdd45105":"code","cc96e288":"code","4cf48c16":"code","ba8419a1":"code","a9b7969b":"markdown","327789e1":"markdown","f71d22df":"markdown","5abeeab6":"markdown","210593c4":"markdown","dd32f97b":"markdown","004a2d86":"markdown","8715c4e0":"markdown","592bd6bf":"markdown"},"source":{"a10e60cf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tqdm.auto import tqdm\nfrom bs4 import BeautifulSoup\nfrom collections import defaultdict\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy.stats import rankdata\n\nimport re \nimport scipy\nfrom scipy import sparse\nfrom matplotlib import pyplot as plt \n\nimport time\nimport scipy.optimize as optimize\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.options.display.max_colwidth=300\npd.options.display.max_columns = 100\n\nfrom sklearn.model_selection import train_test_split\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.linear_model import Ridge, Lasso, BayesianRidge\nfrom sklearn.svm import SVR\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d782e2f2":"train = pd.read_csv(\"..\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv\")\n# df_test = pd.read_csv(\"..\/input\/jigsaw-toxic-comment-classification-challenge\/test.csv\")\ncomm_score = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\")","d2f318aa":"train[:2]","edc9a8aa":"train.shape","db24e334":"comm_score[:2]","7b7abe2c":"comm_score.shape","b1eec16a":"\nlabel_score = {'obscene': 0.16, 'toxic': 0.32, 'threat': 1.5, \n            'insult': 0.64, 'severe_toxic': 1.5, 'identity_hate': 1.5}\n\nfor category in label_score:\n    train[category] = train[category] * label_score[category]\n\ntrain['score'] = train.loc[:, 'toxic':'identity_hate'].sum(axis=1)\n\ntrain['y'] = train['score']\n\nmin_len = (train['y'] > 0).sum()  # len of toxic comments\ndf_non_toxic = train[train['y'] == 0].sample(n=min_len, random_state=201)  # take non toxic comments\ntrain_new = pd.concat([train[train['y'] > 0], df_non_toxic])  # make new df\ntrain_new.head(2)","c54f21d4":"train_new.shape","092a0aff":"train_new['y'].value_counts()","78fce3da":"train[:10]","c6b6f14a":"train = train.rename(columns={'comment_text':'comment'})","23be7854":"def text_cleaning(text):\n   \n    \n   \n    template = re.compile(r'https?:\/\/\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text","6565b96d":"tqdm.pandas()\ntrain['comment'] = train['comment'].progress_apply(text_cleaning)","16ec7988":"df = train.copy()","b1c95acf":"df[:5]","6c92534a":"df['y'].value_counts()","05de2661":"df['y'].value_counts(normalize=True)","3b793fb2":"min_len = (df['y'] >= 0.1).sum()\ndf_non_toxic = df[df['y'] == 0].sample(n=min_len * 2, random_state=402)\ndf = pd.concat([df[df['y'] >= 0.1], df_non_toxic])\ndf['y'].value_counts()","dda8bff6":"# vec = TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5))\nvec = TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (2,5),max_features=46000)\nX = vec.fit_transform(df['comment'])\nX\n","e2ad98d1":"model = Ridge(alpha=0.5)\nmodel.fit(X, df['y'])","6603d642":"model_1 = Ridge(alpha=1.)\nmodel_1.fit(X, df['y'])","e9855130":"model_2 = Ridge(alpha=3.)\nmodel_2.fit(X, df['y'])","d0b39170":"val_data = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\")\nval_data[:2]","cf233254":"tqdm.pandas()\nval_data['less_toxic'] = val_data['less_toxic'].progress_apply(text_cleaning)\nval_data['more_toxic'] = val_data['more_toxic'].progress_apply(text_cleaning)","95d17624":"X_less_toxic = vec.transform(val_data['less_toxic'])\nX_more_toxic = vec.transform(val_data['more_toxic'])","c0bac678":"p_less = model.predict(X_less_toxic)\np_more = model.predict(X_more_toxic)","d90d8c4e":"# Validation Accuracy\n(p_less < p_more).mean()","cb0596f8":"p_less_1 = model_1.predict(X_less_toxic)\np_more_1 = model_1.predict(X_more_toxic)\n# Validation Accuracy\n(p_less_1 < p_more_1).mean()","f520a989":"p_less_2 = model_2.predict(X_less_toxic)\np_more_2 = model_2.predict(X_more_toxic)\n# Validation Accuracy\n(p_less_2 < p_more_2).mean()","92c2b829":"tqdm.pandas()\ncomm_score['text'] = comm_score['text'].progress_apply(text_cleaning)","a0fa06f5":"X_test = vec.transform(comm_score['text'])\np_1 = model.predict(X_test)\np_2 = model_1.predict(X_test)\np_3 = model_2.predict(X_test)","2fb34954":"\ncomm_score['score1']=rankdata( p_1, method='ordinal') \ncomm_score[\"score2\"] = rankdata(p_2, method='ordinal')\n\ncomm_score['score3']=rankdata(p_3, method='ordinal')\ncomm_score['score']=comm_score['score3'] + comm_score['score1'] + comm_score['score2']\n# comm_score['score']=rankdata(comm_score['score'] , method='ordinal')","6e8395d6":"# comm_score['score'] = p_1","16a6f084":"# comm_score['score'] = (p_1 + p_2 + p_3) \/ 3.","bdd45105":"comm_score[\"score\"] = rankdata( comm_score[\"score\"], method='ordinal')","cc96e288":"comm_score['score'].count()","4cf48c16":"comm_score[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)","ba8419a1":"comm_score[:3]","a9b7969b":"2","327789e1":"Validation_data","f71d22df":"Ridge Ensemble Modelling ","5abeeab6":"TFIDF","210593c4":"3","dd32f97b":"1st Model","004a2d86":"Read the Dataset\nNote: Here i have used one additional dataset from Kaggle 'jigsaw-toxic-comment-classification' ","8715c4e0":"Create a score that measure how much toxic is a comment","592bd6bf":"Text Cleaning..."}}