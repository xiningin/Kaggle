{"cell_type":{"4febc3a0":"code","b05d1dc5":"code","6471a058":"code","406570a9":"code","2750287b":"code","9a99d44c":"code","0e2fb158":"code","3a963d18":"code","3365a9fe":"code","14fb5c28":"code","a12d92a5":"code","db49e42b":"code","d9bbfe29":"code","083f09d9":"code","9c644a02":"code","0b2af3c0":"code","4c4da905":"code","04714a2e":"code","a971254a":"code","d814e619":"markdown","3a7a0cb7":"markdown"},"source":{"4febc3a0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b05d1dc5":"df = pd.read_csv(\"\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv\")\ndf.head()","6471a058":"df.info()","406570a9":"from_unnamed_2 = df[~df[\"Unnamed: 2\"].isna()][[\"v1\",\"Unnamed: 2\"]]\nfrom_unnamed_3 = df[~df[\"Unnamed: 3\"].isna()][[\"v1\",\"Unnamed: 3\"]]\nfrom_unnamed_4 = df[~df[\"Unnamed: 4\"].isna()][[\"v1\",\"Unnamed: 4\"]]\ncolumn_names = [\"label\", \"text\"]\nfrom_unnamed_2.columns = from_unnamed_3.columns = from_unnamed_4.columns = column_names\nfrom_unnamed_4","2750287b":"df.drop(columns=[\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], inplace=True)\ndf.columns = column_names\ndf.head()","9a99d44c":"df.shape","0e2fb158":"df = df.append([from_unnamed_2, from_unnamed_3, from_unnamed_4], ignore_index=True)\ndf.shape","3a963d18":"df.tail()","3365a9fe":"import seaborn as sns","14fb5c28":"df[\"label\"].value_counts()","a12d92a5":"sns.countplot(x=df[\"label\"])","db49e42b":"import re\nfrom nltk.corpus import stopwords\n\ndef preprocess(text):\n    new_text = re.sub(r\"[^0-9a-zA-Z]\", \" \", text)\n    new_text = re.sub(r\"\\s+\", \" \", text)\n    new_text = [word for word in text.split(\" \") if word not in stopwords.words(\"english\")]\n    new_text = \" \".join(new_text)\n    return new_text","d9bbfe29":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier","083f09d9":"df[\"spam\"] = df[\"label\"].apply(lambda t: 1 if t==\"spam\" else 0)\ndf.head()","9c644a02":"X = df[\"text\"]\ny = df[\"spam\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","0b2af3c0":"pipe = Pipeline([(\"vectorizer\", TfidfVectorizer(preprocessor=preprocess)), (\"classifier\", LinearSVC())])\npipe.fit(X_train, y_train)\npipe.score(X_test, y_test)","4c4da905":"from sklearn.metrics import classification_report, plot_confusion_matrix","04714a2e":"plot_confusion_matrix(estimator=pipe, X=X_test, y_true=y_test)","a971254a":"print(classification_report(y_true=y_test, y_pred=pipe.predict(X_test), target_names=[\"ham\", \"spam\"]))","d814e619":"Classes are imbalanced, must use smart metrics for evaluation!","3a7a0cb7":"# Analyze data and classes a bit"}}