{"cell_type":{"d0c5e25e":"code","81cd47a4":"code","1791eba8":"code","f2317d43":"code","c6ef78af":"code","c437d1b7":"code","e64c3879":"code","d4d9984a":"code","e894e9b9":"code","aa459d7f":"code","f7728723":"code","c2a12c5e":"code","a5fbdaba":"code","66353e67":"code","41082515":"code","a40cf9c6":"code","b85f3a31":"code","88bc055a":"code","f2365e6d":"code","be44344f":"code","d6ef69d2":"code","2e5532e7":"code","3c20acb8":"code","4eaf5b93":"code","2229c82a":"code","4eddc05c":"code","a85b6b16":"code","11b995a6":"code","51cee5ac":"code","9c64d76c":"code","bb42edb5":"code","dec85950":"code","00b98846":"code","c3634a42":"code","f9cb7599":"code","55ae24bf":"code","367e648e":"code","b7e97dd7":"code","f3059ec4":"code","44b82274":"code","830e147a":"code","cae63a87":"code","f0c48400":"code","fde76cb4":"code","0839843c":"code","2d6ee780":"code","dcd73766":"code","10de30a5":"code","35e36b69":"code","b3d85433":"code","6fdc10e1":"code","0eeeaa15":"code","6882bc54":"code","79380b04":"code","b1ed15bd":"code","088b5c01":"code","a6881383":"code","f8b8e38c":"code","be8c0023":"code","147ebb19":"code","e7ce563c":"code","2c985aad":"code","620f8e3c":"code","534662d1":"code","cc9f026c":"code","9a42e304":"code","c7096a69":"code","f6408659":"code","4732dfdf":"code","9f85be27":"code","33d86c76":"code","8593fa92":"code","6db883a2":"code","adc52dba":"code","2479cf0f":"code","f57ae091":"code","8f3d2461":"code","8fc19c7d":"code","1b30009e":"code","55528e23":"code","0a7eedeb":"code","644b9a71":"code","ce3b20b5":"code","1e29b530":"code","c1cac49b":"code","0599cab6":"code","f0e65022":"code","465fe699":"code","7195dea8":"code","7760ff22":"code","64b7fe52":"code","00c7a55e":"code","6e708415":"code","769e1614":"code","1e32244a":"code","26925079":"code","af517790":"code","ef406187":"code","77461585":"code","cb193c2a":"code","03d74fbb":"code","619db55e":"code","29c71da9":"code","33e0e6b8":"code","7813a7c9":"code","1f9048e4":"code","9079445c":"code","a5d6e5c1":"code","345276c3":"code","9f3f7f7e":"code","96fb8f08":"code","86f978a6":"code","bb3322c8":"code","27dbd5d1":"code","ebf7748e":"code","20f631fa":"code","36143bb5":"code","1ef87fe9":"code","a0749589":"code","b41ebc09":"code","339aff0f":"code","75f846df":"code","c33bde2a":"code","c7dd2d63":"code","2dcd1306":"code","193c2e37":"code","0742f526":"code","04e50c66":"code","eb94a263":"code","7ef396e7":"code","f193a40d":"code","5c0c47bd":"code","bc80e92d":"code","39fea811":"code","7f181d52":"code","8100c744":"code","3fa269a0":"code","d99c10e1":"code","a48b5497":"code","fbcebb07":"code","2dbdddf9":"code","5e6d3d08":"code","8da8959f":"code","4205632e":"code","63f2380e":"code","e18108e3":"code","2c1b2ef1":"code","e875baac":"code","9668f1c2":"code","dceda9a4":"code","bdc5f4db":"code","816fa92e":"code","357b0e6e":"code","113786f6":"code","39d300a9":"code","3543f6f5":"code","5acf77b8":"code","2f4cf3dd":"markdown","2b624d66":"markdown","18e08379":"markdown","2045df8e":"markdown","55676a64":"markdown","a79c274e":"markdown","4eb6c051":"markdown","7d9303fe":"markdown","64ef8864":"markdown","b7d2d44e":"markdown","56096d98":"markdown","89680cb0":"markdown","66dddc53":"markdown","4ca9d82a":"markdown","1d1dd52b":"markdown","40d32e84":"markdown","afd4fdf9":"markdown","285c8a48":"markdown","29753810":"markdown","d705a9f0":"markdown","0466c345":"markdown","3dbdec91":"markdown","e18859d8":"markdown","3dc27b4a":"markdown","bb8af5a9":"markdown","80195e2f":"markdown","1780d09f":"markdown","9c22380b":"markdown","0d6839cd":"markdown","96f0c5c0":"markdown","d0f71a80":"markdown","f2a31fd2":"markdown","b7bc49c7":"markdown","32e8f4b6":"markdown","a69687ea":"markdown","efe41754":"markdown","ba5b49c6":"markdown","ccb55b37":"markdown","eaeaec5a":"markdown","7218f738":"markdown","48477104":"markdown","e5ff9e88":"markdown","bfb630c9":"markdown","30a19f1e":"markdown","80b07002":"markdown","7f9d2b3f":"markdown","79011374":"markdown","67c7aff8":"markdown","411d1131":"markdown","06a7315f":"markdown","ee6a44f7":"markdown","585a387c":"markdown","a66b0f60":"markdown","e70eeeb4":"markdown","89d39cd6":"markdown","9998e7c3":"markdown","93ef466c":"markdown","98bd4f4a":"markdown","e9d46169":"markdown","8e4c23ed":"markdown","721b3cae":"markdown","c70d9fe2":"markdown","c2c93c8c":"markdown","b1356bf4":"markdown","95bd61ce":"markdown","a324f07e":"markdown","23a06447":"markdown","3b180216":"markdown","3b52900d":"markdown","4f93f9b4":"markdown","7b3c3904":"markdown","29780ee5":"markdown","8c16b66a":"markdown","2b17b4a8":"markdown","5a5de5e1":"markdown","9d6e6856":"markdown","250483f5":"markdown","a5e498a9":"markdown","98661733":"markdown","7c973667":"markdown","e8a62d87":"markdown"},"source":{"d0c5e25e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","81cd47a4":"# Read Data\nimport numpy as np                     # Linear Algebra (calculate the mean and standard deviation)\nimport pandas as pd                    # manipulate data, data processing, load csv file I\/O (e.g. pd.read_csv)\n\n# Visualization\nimport seaborn as sns                  # Visualization using seaborn\nimport matplotlib.pyplot as plt        # Visualization using matplotlib\n%matplotlib inline\nimport plotly                          # Visualization using Plotly\nimport plotly.express as px\nimport plotly.graph_objs as go\n\n# style\nplt.style.use(\"fivethirtyeight\")       # Set Graphs Background style using matplotlib\nsns.set_style(\"darkgrid\")              # Set Graphs Background style using seaborn\n\n# ML model building; Pre Processing & Evaluation\nfrom sklearn.model_selection import train_test_split                     # split  data into training and testing sets\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge          # Linear Regression, Lasso and Ridge\nfrom sklearn.linear_model import LogisticRegression                      # Logistic Regression\nfrom sklearn.tree import DecisionTreeRegressor                           # Decision tree Regression\nfrom sklearn.ensemble import RandomForestRegressor                       # this will make a Random Forest Regression\nfrom sklearn import svm                                                  # this will make a SVM classificaiton\nfrom sklearn.svm import SVC                                              # import SVC from SVM\nimport xgboost\nfrom sklearn.metrics import confusion_matrix, classification_report      # this creates a confusion matrix\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.metrics import roc_curve,auc                                # ROC\nfrom sklearn.preprocessing import StandardScaler                         # Standard Scalar\nfrom sklearn.model_selection import GridSearchCV                         # this will do cross validation\nfrom sklearn.decomposition import PCA                                    # to perform PCA to plot the data\n\nimport warnings                                                          # Ignore Warnings\nwarnings.filterwarnings(\"ignore\")","1791eba8":"# Import first 5 rows\ntrain = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")","f2317d43":"display(train.head())\ndisplay(test.head())","c6ef78af":"# checking dimension (num of rows and columns) of dataset\nprint(\"Training data shape (Rows, Columns):\",train.shape)\nprint(\"Test data shape (Rows, Columns):\",test.shape)","c437d1b7":"# check dataframe structure like columns and its counts, datatypes & Null Values\ntrain.info()","e64c3879":"train.dtypes.value_counts()","d4d9984a":"# check dataframe structure like columns and its counts, datatypes & Null Values\ntest.info()","e894e9b9":"# descriptive statistics (numerical columns)\ntrain.describe()","aa459d7f":"test.dtypes.value_counts()","f7728723":"# Gives number of data points in each variable\ntrain.count()","c2a12c5e":"# merge the train and test data and inspect the data type\nmerged = pd.concat([train, test], axis=0, sort=True)\ndisplay(merged.dtypes.value_counts())\nprint('Dimensions of data:', merged.shape)","a5fbdaba":"# merge the train and test data and inspect the data type\nmerged = pd.concat([train, test], axis=0, sort=True)\ndisplay(merged.dtypes.value_counts())\nprint('Dimensions of data:', merged.shape)","66353e67":"train['MSZoning'].value_counts()","41082515":"numeric_cols_train = train.select_dtypes(include=[np.number])\ndisplay(numeric_cols_train.head())\nprint('\\n')\nnumeric_cols_train.columns","a40cf9c6":"numeric_cols_train.shape","b85f3a31":"categorical_cols_train = train.select_dtypes(include=[np.object])\ndisplay(categorical_cols_train.head())\nprint('\\n')\ncategorical_cols_train.columns","88bc055a":"numeric_cols_test = test.select_dtypes(exclude='object')\ndisplay(numeric_cols_test.head())\nprint('\\n')\nnumeric_cols_test.columns","f2365e6d":"categorical_cols_test = test.select_dtypes(include=[np.object])\ndisplay(categorical_cols_test.head())\nprint('\\n')\ncategorical_cols_test.columns","be44344f":"# Listing Number of missing values by feature column wise\ntrain_missing = train.isnull().sum().sort_values(ascending=False)\ntrain_missing = train_missing[train_missing > 0]\ntrain_missing","d6ef69d2":"# Listing Number of missing values by feature column wise\ntest_missing = test.isnull().sum().sort_values(ascending=False)\ntest_missing = test_missing[test_missing > 0]\ntest_missing","2e5532e7":"# any() check null values by columns\ntrain.isnull().any()","3c20acb8":"plt.figure(figsize=(17,10))\nsns.heatmap(train.isnull(), yticklabels=False, cbar=False, cmap='viridis')","4eaf5b93":"plt.figure(figsize=(17,10))\nsns.heatmap(test.isnull(), yticklabels=False, cbar=False, cmap='viridis')","2229c82a":"# Percentage of Missing values in train dataset\ntotal = train.isnull().sum().sort_values(ascending=False)\npercent = ((train.isnull().sum()\/train.isnull().count())*100).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, join='outer', keys=['Total Missing Count', '% of Total Observations'])\nmissing_data.index.name =' Numeric cols'\n\nmissing_data.head(20)","4eddc05c":"# Percentage of Missing values in train dataset\ntotal = test.isnull().sum().sort_values(ascending=False)\npercent = ((test.isnull().sum()\/test.isnull().count())*100).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, join='outer', keys=['Total Missing Count', '% of Total Observations'])\nmissing_data.index.name =' Numeric cols'\n\nmissing_data.head(20)","a85b6b16":"for column in train.columns:\n    print(column,train[column].nunique())","11b995a6":"categorical_features = [feature for feature in train.columns if train[feature].dtypes=='O']\ncategorical_features","51cee5ac":"for feature in categorical_features:\n    print('The feature is {} and number of categories are {}'.format(feature,len(train[feature].unique())))","9c64d76c":"fig, axes = plt.subplots(round(len(categorical_cols_train.columns) \/ 3), 3, figsize=(12, 30))\n\nfor i, ax in enumerate(fig.axes):\n    if i < len(categorical_cols_train.columns):\n        ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=90)\n        sns.countplot(x=categorical_cols_train.columns[i], alpha=0.7, data=categorical_cols_train, ax=ax)\n\nfig.tight_layout()","bb42edb5":"# Find out the relationship between categorical variable and dependent varaible\nplt.figure(figsize=(15,70), facecolor='white')\nplotnumber =1\nfor feature in categorical_features:\n    ax = plt.subplot(11,4,plotnumber)\n    data=train.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plotnumber+=1\nplt.show()","dec85950":"numerical_features = train.select_dtypes(exclude='object')\nnumerical_features","00b98846":"discrete_feature=[feature for feature in numerical_features if len(train[feature].unique())<25]\nprint(\"Discrete Variables Count: {}\".format(len(discrete_feature)))","c3634a42":"continuous_features=[feature for feature in numerical_features if feature not in discrete_feature+['target']]\nprint(\"Continuous feature Count {}\".format(len(continuous_features)))","f9cb7599":"continuous_features","55ae24bf":"fig, ax = plt.subplots(5,4, figsize=(16,16))\nsns.distplot(train['LotFrontage'], bins = 20, ax=ax[0,0]) \nsns.distplot(train.LotArea, bins = 20, ax=ax[0,1]) \nsns.distplot(train.YearBuilt, bins = 20, ax=ax[0,2]) \nsns.distplot(train.YearRemodAdd, bins = 20, ax=ax[0,3])\nsns.distplot(train.MasVnrArea, bins = 20, ax=ax[1,0]) \nsns.distplot(train.BsmtFinSF1, bins = 20, ax=ax[1,1]) \nsns.distplot(train.BsmtUnfSF, bins = 20, ax=ax[1,3])\nsns.distplot(train.TotalBsmtSF, bins = 20, ax=ax[2,0])\nsns.distplot(train['1stFlrSF'], bins = 20, ax=ax[2,1])\nsns.distplot(train['2ndFlrSF'], bins = 20, ax=ax[2,2])\nsns.distplot(train.GrLivArea, bins = 20, ax=ax[2,3])\nsns.distplot(train.GarageYrBlt, bins = 20, ax=ax[3,0])\nsns.distplot(train.GarageArea, bins = 20, ax=ax[3,1])\nsns.distplot(train.WoodDeckSF, bins = 20, ax=ax[3,2])\nsns.distplot(train.OpenPorchSF, bins = 20, ax=ax[3,3])\nsns.distplot(train.SalePrice, bins = 20, ax=ax[4,2])\nplt.show()","367e648e":"plt.figure(figsize=(20,60), facecolor='white')\nplotnumber =1\nfor feature in continuous_features:\n    data=train.copy()\n    ax = plt.subplot(12,3,plotnumber)\n    plt.scatter(train[feature],train['SalePrice'])\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plotnumber+=1\nplt.show()","b7e97dd7":"plt.figure(figsize=(20,18))\noutliers = train.drop(['Id', 'SalePrice'], axis=1)\nsns.boxplot(data=outliers, orient='h', palette='Set2');","f3059ec4":"train_IQR = train[['MasVnrArea', 'BsmtFinSF1', 'BsmtUnfSF', '2ndFlrSF', 'GrLivArea', 'YearBuilt', 'GarageYrBlt',\n                   'GarageArea', 'YearRemodAdd']]\nQ1 = train_IQR.quantile(0.25)\nQ3 = train_IQR.quantile(0.75)\nIQR = Q3 - Q1\nIQR","44b82274":"# Here are the outliers\n\ntrain_IQR_clean = train_IQR[~((train_IQR < (Q1 - 1.5*IQR)) | (train_IQR > (Q3 + 1.5*IQR))).any(axis=1)]","830e147a":"# boxplot() showing outlier\nbox = train_IQR_clean\nplt.figure(figsize=(12,10))\nsns.boxplot(data=box)\nplt.show()","cae63a87":"# Pearson Correlation\nplt.figure(figsize=(23,18))\nsns.heatmap(outliers.corr(method='pearson'), cbar=False, annot=True, fmt='.1f', linewidth=0.2, cmap='summer');","f0c48400":"# Spearman Correlation\nplt.figure(figsize=(23,18))\nsns.heatmap(outliers.corr(method='spearman'), cbar=False, annot=True, fmt='.1f', linewidth=0.2, cmap='viridis');","fde76cb4":"fig, ax = plt.subplots(figsize=(16,14))\ncorr = outliers.corr()\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nax.text(-1.1, -0.7, 'Correlation between the Features', fontsize=20, fontweight='bold', fontfamily='serif')\nsns.heatmap(corr, mask=mask, annot=False, fmt='.2f', linewidth=0.2, cbar=True, cmap='coolwarm');","0839843c":"corr = numeric_cols_train.drop('SalePrice', axis=1).corr()\nplt.figure(figsize=(17, 14))\n\nsns.heatmap(corr[(corr >= 0.5) | (corr <= -0.4)], \n            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n            annot=True, annot_kws={\"size\": 8}, square=True);","2d6ee780":"plt.figure(figsize=(14,12))\ncorr = numeric_cols_train.corr()\nk= 11\ncols = corr.nlargest(k,'SalePrice')['SalePrice'].index\nprint(cols)\ncm = np.corrcoef(train[cols].values.T)\nsns.heatmap(cm, cmap='viridis', vmax=.8, annot=True, linewidth=2, linecolor=\"white\", xticklabels = cols.values,\n            yticklabels = cols.values, square=True, annot_kws = {'size':12})","dcd73766":"# kendall\nfig, ax = plt.subplots(1, 3, figsize=(20 , 8))\n\nfeature_lst = ['LotFrontage', 'LotArea', 'YearBuilt','MasVnrArea','OpenPorchSF', 'GarageYrBlt', 'GarageArea', 'OpenPorchSF', 'WoodDeckSF', 'KitchenAbvGr', 'TotRmsAbvGrd']\n\ncorr = train[feature_lst].corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n\nfor idx, method in enumerate(['pearson', 'kendall', 'spearman']):\n    sns.heatmap(train[feature_lst].corr(method=method), ax=ax[idx],\n            square=True, annot=True, fmt='.1f', center=0, linewidth=2,\n            cbar=False, cmap=sns.diverging_palette(240, 10, as_cmap=True),\n            mask=mask\n           ) \n    ax[idx].set_title(f'{method.capitalize()} Correlation', loc='left', fontweight='bold')     \n\nplt.show()","10de30a5":"train.corr()['SalePrice'].sort_values(ascending=False)","35e36b69":"a = train.drop(['SalePrice'], axis=1)\na.corrwith(train['SalePrice']).plot(kind='bar', figsize=(18,14), color=['salmon'])\nplt.title('Correlation b\/n target and Independant features')\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.show()","b3d85433":"train.skew()","6fdc10e1":"test.skew()","0eeeaa15":"# Checking Skewness for feature \"SalePrice\"\nsns.distplot(train['SalePrice'])\nSkew_SalePrice = train['SalePrice'].skew()\nplt.title(\"Skew:\"+str(Skew_SalePrice))","6882bc54":"# SalePrice right skewed; log transform)\nsns.distplot(np.log(train['SalePrice']+1))\nSkew_SalePrice_Log = np.log(train['SalePrice']+1).skew()\nplt.title(\"Skew:\"+str(Skew_SalePrice_Log))","79380b04":"# a) Checking Skewness for feature \"LotArea\"\n# Checking the skewness of \"LotArea\" attributes\ntrain['LotArea'].skew()","b1ed15bd":"# calculating the square for the column df['LotArea'] column\nlog_LotArea_train = np.log(train['LotArea'])\nlog_LotArea_train.skew()","088b5c01":"# b) Checking Skewness for feature \"LowQualFinSF\"\n# Checking the skewness of \"LowQualFinSF\" attributes\ntrain['LowQualFinSF'].skew()","a6881383":"# calculating the square for the column df['LowQualFinSF'] column\nrecipr_LowQualFinSF_train = np.reciprocal(train['LowQualFinSF'])\nrecipr_LowQualFinSF_train.skew()","f8b8e38c":"# c) Checking Skewness for feature \"3SsnPorch\"\n# Checking the skewness of \"3SsnPorch\" attributes\ntrain['3SsnPorch'].skew()","be8c0023":"# performing the log transformation using numpy\nrecipr_3SsnPorch_train = np.reciprocal(train['3SsnPorch'])\nrecipr_3SsnPorch_train.skew()","147ebb19":"# d) Checking Skewness for feature \"PoolArea\"\n# Checking the skewness of \"PoolArea\" attributes\ntrain['PoolArea'].skew()","e7ce563c":"# performing the log transformation using numpy\ncuberoot_PoolArea_train = np.cbrt(train['PoolArea'])\ncuberoot_PoolArea_train.skew()","2c985aad":"# e) Checking Skewness for feature \"MiscVal\"\n# Checking the skewness of \"MiscVal\" attributes\ntrain['MiscVal'].skew()","620f8e3c":"# performing the log transformation using numpy\nrecipr_MiscVal_train = np.reciprocal(train['MiscVal'])\nrecipr_MiscVal_train.skew()","534662d1":"train_skew = pd.concat([log_LotArea_train, recipr_LowQualFinSF_train, recipr_3SsnPorch_train,\n                        recipr_MiscVal_train], axis=1)\ntrain_skew","cc9f026c":"train.head()","9a42e304":"train.shape","c7096a69":"train.drop(['LotArea','LowQualFinSF','3SsnPorch','MiscVal'], inplace=True, axis=1)\ntrain.head()","f6408659":"new_train = pd.concat([train, train_skew], axis=1)\nnew_train.head()","4732dfdf":"new_train.shape","9f85be27":"numeric_cols_test.skew()","33d86c76":"# a) Checking Skewness for feature \"LowQualFinSF\"\n# Checking the skewness of \"LowQualFinSF\" attributes\ntest['LowQualFinSF'].skew()","8593fa92":"# performing the cube root transformation using numpy\ncube_root_LowQualFinSF_test = np.cbrt(test['LowQualFinSF'])\ncube_root_LowQualFinSF_test.skew()","6db883a2":"# b) Checking Skewness for feature \"3SsnPorch\"\n# Checking the skewness of \"3SsnPorch\" attributes\ntest['3SsnPorch'].skew()","adc52dba":"# performing the cube root transformation using numpy\ncube_root_3SsnPorch_test = np.cbrt(test['3SsnPorch'])\ncube_root_3SsnPorch_test.skew()","2479cf0f":"# c) Checking Skewness for feature \"PoolArea\"\n# Checking the skewness of \"PoolArea\" attributes\ntest['PoolArea'].skew()","f57ae091":"# performing the cube root transformation using numpy\nrecipr_PoolArea_test = np.reciprocal(test['PoolArea'])\nrecipr_PoolArea_test.skew()","8f3d2461":"# d) Checking Skewness for feature \"MiscVal\"\n# Checking the skewness of \"MiscVal\" attributes\ntest['MiscVal'].skew()","8fc19c7d":"# performing the cube root transformation using numpy\ncube_root_MiscVal_test = np.cbrt(test['MiscVal'])\ncube_root_MiscVal_test.skew()","1b30009e":"# Histogram for \"SalePrice\"\nplt.figure(figsize=(9,7))\nsns.distplot(train['SalePrice']);","55528e23":"# Histogram for \"Numerical Features in train dataset\"\nnumeric_cols_train.hist(figsize=(16, 20), bins=50, xlabelsize=7, ylabelsize=7);","0a7eedeb":"# Histogram for \"Numerical Features in test dataset\"\nnumeric_cols_test.hist(figsize=(16, 20), bins=50, xlabelsize=7, ylabelsize=7);","644b9a71":"# Line Plot between \"YrSold\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.lineplot(x=train['YrSold'], y=train['SalePrice'])\n\nplt.xlabel('YrSold', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('YrSold Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","ce3b20b5":"# Line Plot between \"YearBuilt\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.lineplot(x=train['YearBuilt'], y=train['SalePrice'])\n\nplt.xlabel('YearBuilt', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('YearBuilt Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","1e29b530":"# Line Plot between \"MoSold\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.lineplot(x=train['MoSold'], y=train['SalePrice'])\n\nplt.xlabel('MoSold', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('MoSold Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","c1cac49b":"train['OverallQual'].value_counts()","0599cab6":"# Line Plot between \"OverallQual\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.lineplot(x=train['OverallQual'], y=train['SalePrice'])\n\nplt.xlabel('OverallQual', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('OverallQual Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","f0e65022":"# Line Plot between \"SaleCondition\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.lineplot(x=train['SaleCondition'], y=train['SalePrice'])\n\nplt.xlabel('SaleCondition', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('SaleCondition Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","465fe699":"# Scatter Plot between \"OverallQual\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.scatterplot(x=train['OverallQual'], y=train['SalePrice'])\n\nplt.xlabel('OverallQual', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('OverallQual Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","7195dea8":"# Scatter Plot between \"GrLivArea\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.scatterplot(train.GrLivArea, train.SalePrice)\n\nplt.xlabel('GrLivArea', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('GrLivArea Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","7760ff22":"# Scatter Plot between \"GarageArea\" and \"target\" variable\nplt.figure(figsize=(7,6))\nsns.scatterplot(train.GarageArea, train.SalePrice)\n\nplt.xlabel('GarageArea', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('GarageArea Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","64b7fe52":"# Scatter Plot between \"TotalBsmtSF\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.scatterplot(train.TotalBsmtSF, train.SalePrice)\n\nplt.xlabel('TotalBsmtSF', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('TotalBsmtSF Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","00c7a55e":"# Scatter Plot between \"1stFlrSF\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.scatterplot(train['1stFlrSF'], train.SalePrice)\n\nplt.xlabel('1stFlrSF', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('1stFlrSF Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","6e708415":"# Scatter Plot between \"MasVnrArea\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.scatterplot(train.MasVnrArea, train.SalePrice)\n\nplt.xlabel('MasVnrArea', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('MasVnrArea Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","769e1614":"# Scatter Plot between \"MasVnrArea\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nsns.scatterplot(np.sqrt(train['MasVnrArea']),np.log(train['SalePrice']))\n\nplt.xlabel('Sqrt_MasVnrArea', fontsize=15, fontweight='bold')\nplt.ylabel('log_SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('Sqrt_MasVnrArea Vs log_SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","1e32244a":"# Scatter Plot between \"MSSubClass\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nplt.scatter(train['MSSubClass'], train['SalePrice'])\n\nplt.xlabel('MSSubClass', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('MSSubClass Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","26925079":"# Scatter Plot between \"LotFrontage\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nplt.scatter(train['LotFrontage'], train['SalePrice'])\n\nplt.xlabel('LotFrontage', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('LotFrontage Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","af517790":"# Scatter Plot between \"TotRmsAbvGrd\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nplt.scatter(train['TotRmsAbvGrd'], train['SalePrice'])\n\nplt.xlabel('TotRmsAbvGrd', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('TotRmsAbvGrd Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","ef406187":"# Scatter Plot between \"CentralAir\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nplt.scatter(train['CentralAir'], train['SalePrice'])\n\nplt.xlabel('CentralAir', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('CentralAir Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","77461585":"# Scatter Plot between \"KitchenAbvGr\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nplt.scatter(train['KitchenAbvGr'], train['SalePrice'])\n\nplt.xlabel('KitchenAbvGr', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('KitchenAbvGr Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","cb193c2a":"# Scatter Plot between \"OpenPorchSF\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nplt.scatter(train['OpenPorchSF'], train['SalePrice'])\n\nplt.xlabel('OpenPorchSF', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('OpenPorchSF Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","03d74fbb":"# Scatter Plot between \"OpenPorchSF\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nplt.scatter(np.log(train['OpenPorchSF']),np.log(train['SalePrice']))\n\nplt.xlabel('log_OpenPorchSF', fontsize=15, fontweight='bold')\nplt.ylabel('log_SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('log_OpenPorchSF Vs log_SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","619db55e":"# Box Plot for \"BsmtExposure\" & \"SalePrice\"\nplt.figure(figsize = (10, 6))\nsns.boxplot(x='BsmtExposure', y='SalePrice', data=train)","29c71da9":"# Box Plot for \"SaleCondition\" & \"SalePrice\"\nplt.figure(figsize = (12, 6))\nsns.boxplot(x='SaleCondition', y='SalePrice', data=train)","33e0e6b8":"# Box Plot for \"Neighborhood\" & \"SalePrice\"\nplt.figure(figsize=(15, 9))\nsns.boxplot(x='Neighborhood', y=\"SalePrice\", data=train)\nplt.xticks(rotation=90)","7813a7c9":"# Count Plot for \"Neighborhood\"\nplt.figure(figsize = (15, 9))\nsns.countplot(x = 'Neighborhood', data = train)\nxt = plt.xticks(rotation=45)","1f9048e4":"num_feat = set(train._get_numeric_data().columns)\nfeat = set(train.columns)\ncat_feat = list(feat-num_feat)\nprint(\"total categoricalfeatures : \"+str(len(cat_feat)))\n\ny='SalePrice'\nfor i,j in enumerate(cat_feat):\n    \n    sns.catplot(x=j, y=y, data=train, alpha=0.5)\n    plt.xticks(rotation=90)","9079445c":"sns.set()\ncolumns = ['SalePrice','OverallQual','TotalBsmtSF','GrLivArea','GarageArea','FullBath','YearBuilt','YearRemodAdd']\nsns.pairplot(train[columns], height = 2, kind ='scatter', diag_kind='kde')","a5d6e5c1":"# Drop columns of train dataset with more than 25% of missing data\n\ntrain.drop(columns=['Id','Alley','FireplaceQu','PoolQC','Fence','MiscFeature'], inplace=True, axis=1)","345276c3":"train.shape","9f3f7f7e":"# Drop columns of test dataset with more than 25% of missing data\n\ntest.drop(columns=['Id','Alley','FireplaceQu','PoolQC','Fence','MiscFeature'], inplace=True, axis=1)","96fb8f08":"test.shape","86f978a6":"df = [train, test]","bb3322c8":"    # train data\n    \n      # Numeric Features\n        \n    train['LotFrontage'] = train['LotFrontage'].fillna(train['LotFrontage'].mean())  # float\n    train['GarageYrBlt'] = train['GarageYrBlt'].fillna(train['GarageYrBlt'].mean())  # float\n    train['MasVnrArea'] = train['MasVnrArea'].fillna(train['MasVnrArea'].mean())     # float\n    \n      # Categorical Features\n        \n    train['GarageCond'] = train['GarageCond'].fillna(train['GarageCond'].mode()[0])\n    train['GarageQual'] = train['GarageQual'].fillna(train['GarageQual'].mode()[0])\n    train['GarageFinish'] = train['GarageFinish'].fillna(train['GarageFinish'].mode()[0])\n    train['GarageType'] = train['GarageType'].fillna(train['GarageType'].mode()[0])\n    train['BsmtFinType2'] = train['BsmtFinType2'].fillna(train['BsmtFinType2'].mode()[0])\n    train['BsmtExposure'] = train['BsmtExposure'].fillna(train['BsmtExposure'].mode()[0])\n    train['BsmtFinType1'] = train['BsmtFinType1'].fillna(train['BsmtFinType1'].mode()[0])\n    train['BsmtQual'] = train['BsmtQual'].fillna(train['BsmtQual'].mode()[0])\n    train['BsmtCond'] = train['BsmtCond'].fillna(train['BsmtCond'].mode()[0])\n    train['MasVnrType'] = train['MasVnrType'].fillna(train['MasVnrType'].mode()[0])\n    train['Electrical'] = train['Electrical'].fillna(train['Electrical'].mode()[0])\n    \n    # test data\n    \n      # Numeric Featurestrain\n        \n    test['LotFrontage'] = test['LotFrontage'].fillna(test['LotFrontage'].mean())  # float\n    test['GarageYrBlt'] = test['GarageYrBlt'].fillna(test['GarageYrBlt'].mean())  # float\n    test['MasVnrArea'] = test['MasVnrArea'].fillna(test['MasVnrArea'].mean())     # float\n    test['BsmtHalfBath'] = test['BsmtHalfBath'].fillna(test['BsmtHalfBath'].mean())\n    test['BsmtFullBath'] = test['BsmtFullBath'].fillna(test['BsmtFullBath'].mean())\n    test['GarageArea'] = test['GarageArea'].fillna(test['GarageArea'].mean())\n    test['BsmtFinSF1'] = test['BsmtFinSF1'].fillna(test['BsmtFinSF1'].mean())\n    test['BsmtFinSF2'] = test['BsmtFinSF2'].fillna(test['BsmtFinSF2'].mean())\n    test['BsmtUnfSF'] = test['BsmtUnfSF'].fillna(test['BsmtUnfSF'].mean())\n    test['TotalBsmtSF'] = test['TotalBsmtSF'].fillna(test['TotalBsmtSF'].mean())\n    test['GarageCars'] = test['GarageCars'].fillna(test['GarageCars'].mean())\n    \n      # Categorical Features\n        \n    test['GarageCond'] = test['GarageCond'].fillna(test['GarageCond'].mode()[0])\n    test['GarageQual'] = test['GarageQual'].fillna(test['GarageQual'].mode()[0])\n    test['GarageFinish'] = test['GarageFinish'].fillna(test['GarageFinish'].mode()[0])\n    test['GarageType'] = test['GarageType'].fillna(test['GarageType'].mode()[0])\n    test['BsmtQual'] = test['BsmtQual'].fillna(test['BsmtQual'].mode()[0])\n    test['BsmtCond'] = test['BsmtCond'].fillna(test['BsmtCond'].mode()[0])\n    test['BsmtFinType2'] = test['BsmtFinType2'].fillna(test['BsmtFinType2'].mode()[0])\n    test['BsmtExposure'] = test['BsmtExposure'].fillna(test['BsmtExposure'].mode()[0])\n    test['BsmtFinType1'] = test['BsmtFinType1'].fillna(test['BsmtFinType1'].mode()[0])\n    test['MasVnrType'] = test['MasVnrType'].fillna(test['MasVnrType'].mode()[0])\n    test['MSZoning'] = test['MSZoning'].fillna(test['MSZoning'].mode()[0])\n    test['Utilities'] = test['Utilities'].fillna(test['Utilities'].mode()[0])\n    test['Functional'] = test['Functional'].fillna(test['Functional'].mode()[0])\n    test['KitchenQual'] = test['KitchenQual'].fillna(test['KitchenQual'].mode()[0])\n    test['SaleType'] = test['SaleType'].fillna(test['SaleType'].mode()[0])\n    test['Exterior2nd'] = test['Exterior2nd'].fillna(test['Exterior2nd'].mode()[0])\n    test['Exterior1st'] = test['Exterior1st'].fillna(test['Exterior1st'].mode()[0])","27dbd5d1":"plt.figure(figsize=(17,10))\nsns.heatmap(train.isnull(), yticklabels=False, cbar=False, cmap='viridis')","ebf7748e":"plt.figure(figsize=(17,10))\nsns.heatmap(test.isnull(), yticklabels=False, cbar=False, cmap='viridis')","20f631fa":"# Transform discrete values to columns with 1 and 0s\ntrain_OHE = pd.get_dummies(train)\n\n# Do the same for competition data\ntest_OHE = pd.get_dummies(test)","36143bb5":"display(train_OHE.head())\ndisplay(test_OHE.head())","1ef87fe9":"plt.figure(figsize=(14,12))\ncorr = numeric_cols_train.corr()\nk= 11\ncols = corr.nlargest(k,'SalePrice')['SalePrice'].index\nprint(cols)\ncm = np.corrcoef(train[cols].values.T)\nsns.heatmap(cm, cmap='viridis', vmax=.8, annot=True, linewidth=2, linecolor=\"white\", xticklabels = cols.values,\n            yticklabels = cols.values, square=True, annot_kws = {'size':12})","a0749589":"print(\"Training Data Shape (Rows,Columns):\",train_OHE.shape)\nprint(\"Competition Data Shape (Rows,Columns):\", test_OHE.shape)","b41ebc09":"# There is a differece between features in the training data set and the test data set\n# We will try dropping the features that are not present in both sets\n\nmissingFeatures_train = list(set(train_OHE.columns.values) - set(test_OHE.columns.values))\ntrain_OHE = train_OHE.drop(missingFeatures_train, axis=1)\n\nmissingFeatures_test = list(set(test_OHE.columns.values) - set(train_OHE.columns.values))\ntest_OHE = test_OHE.drop(missingFeatures_test, axis=1)","339aff0f":"print(\"Training Data Shape (Rows,Columns):\",train_OHE.shape)\nprint(\"Competition Data Shape (Rows,Columns):\", test_OHE.shape)","75f846df":"# Independant variable\nX = train_OHE                     # All rows & columns exclude Target features\n\n# Dependant variable\ny = train['SalePrice']        # Only target feature","c33bde2a":"# split  data into training and testing sets of 80:20 ratio\n# 20% of test size selected\n# random_state is random seed\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=4)","c7dd2d63":"# shape of X & Y test \/ train\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","2dcd1306":"LinReg = LinearRegression()\nLinReg.fit(X_train, y_train)","193c2e37":"# Lasso Regression\nlasso = Lasso()\nlasso.fit(X_train, y_train)","0742f526":"# Ridge Regression\nridge = Ridge()\nridge.fit(X_train, y_train)","04e50c66":"y_pred_LinReg = LinReg.predict(X_test)\ny_pred_lasso = lasso.predict(X_test)\ny_pred_ridge = ridge.predict(X_test)","eb94a263":"y_pred_train_LinReg = LinReg.predict(X_train)","7ef396e7":"print(\"Linear Regression : Train Score {:.2f} & Test Score {:.2f}\".format(LinReg.score(X_train, y_train), LinReg.score(X_test, y_test)))\nprint(\"Lasso Regression : Train Score {:.2f} & Test Score {:.2f}\".format(lasso.score(X_train, y_train), lasso.score(X_test, y_test)))\nprint(\"Ridge Regression : Train Score {:.2f} & Test Score {:.2f}\".format(ridge.score(X_train, y_train), ridge.score(X_test, y_test)))","f193a40d":"print(\"Model\\t\\t\\t RMSE \\t\\t MSE \\t\\t MAE \\t\\t R2\")\n\nprint(\"\"\"LinearRegression \\t {:.2f} \\t\\t {:.2f} \\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n            np.sqrt(mean_squared_error(y_test, y_pred_LinReg)),\n            mean_squared_error(y_test, y_pred_LinReg),\n            mean_absolute_error(y_test, y_pred_LinReg),\n            r2_score(y_test, y_pred_LinReg)))\n\nprint(\"\"\"LassoRegression \\t {:.2f} \\t\\t {:.2f} \\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n            np.sqrt(mean_squared_error(y_test, y_pred_lasso)),\n            mean_squared_error(y_test, y_pred_lasso),\n            mean_absolute_error(y_test, y_pred_lasso),\n            r2_score(y_test, y_pred_lasso)))\n\nprint(\"\"\"RidgeRegression \\t {:.2f} \\t\\t {:.2f} \\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n            np.sqrt(mean_squared_error(y_test, y_pred_ridge)),\n            mean_squared_error(y_test, y_pred_ridge),\n            mean_absolute_error(y_test, y_pred_ridge),\n            r2_score(y_test, y_pred_ridge)))","5c0c47bd":"# Plotting Predictions\nfig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(12,4))\n\nax1.scatter(y_pred_LinReg, y_test, s=20)\nax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\nax1.set_ylabel(\"True\")\nax1.set_xlabel(\"Predicted\")\nax1.set_title(\"Linear Regression\")\n\nax2.scatter(y_pred_lasso, y_test, s=20)\nax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\nax2.set_ylabel(\"True\")\nax2.set_xlabel(\"Predicted\")\nax2.set_title(\"Lasso Regression\")\n\nax3.scatter(y_pred_ridge, y_test, s=20)\nax3.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\nax3.set_ylabel(\"True\")\nax3.set_xlabel(\"Predicted\")\nax3.set_title(\"Ridge Regression\")\nfig.suptitle(\"True vs Predicted\")\nfig.tight_layout(rect=[0, 0.03, 1, 0.95])","bc80e92d":"plt.figure(figsize=(9,8))\n\nplt.scatter(y_pred_train_LinReg, y_train, c = \"blue\",  label = \"Training data\")\nplt.scatter(y_pred_LinReg, y_test, c = \"black\",  label = \"Test data\")\nplt.plot(y_train, y_train, alpha=0.3, c='r')\n\nplt.xlabel(\"Predicted values\")\nplt.ylabel(\"Real values\")\n\nplt.title(\"Linear regression\")\n\nplt.legend(loc = \"upper left\")\n\nplt.show()","39fea811":"plt.figure(figsize=(9,8))\n\nplt.scatter(y_train, y_pred_train_LinReg)\nplt.plot(y_train, y_train, alpha=0.3, c='r')\n\nplt.xlabel(\"Sales\", fontsize=15, fontweight='bold')\nplt.ylabel(\"Predicted Sales\", fontsize=15, fontweight='bold')\n\nplt.title(\"Training Data Fit\", fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","7f181d52":"plt.figure(figsize=(9,8))\nplt.scatter(y_test, y_pred_LinReg)\nplt.plot(y_test, y_test, alpha=0.3, c='r')\n\nplt.xlabel(\"Sales\", fontsize=15, fontweight='bold')\nplt.ylabel(\"Predicted Sales\", fontsize=15, fontweight='bold')\n\nplt.title(\"Test Data Fit\", fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","8100c744":"a = (y_test-y_pred_LinReg)\nsns.distplot(a)","3fa269a0":"plt.scatter(y_train-y_pred_train_LinReg, y_train)\nplt.title(\"Residual Vs  Actual SalePrice for train data\")","d99c10e1":"plt.scatter(y_test-y_pred_LinReg, y_test)\nplt.title(\"Residual Vs  Actual SalePrice for test data\")\nplt.show()","a48b5497":"DTR = DecisionTreeRegressor()\nDTR.fit(X_train, y_train)","fbcebb07":"y_pred_DTR = DTR.predict(X_test)","2dbdddf9":"print(\"Train Score {:.2f} & Test Score {:.2f}\".format(DTR.score(X_train, y_train), DTR.score(X_test, y_test)))","5e6d3d08":"print(\"Model\\t\\t\\t\\t RMSE \\t\\t MSE \\t\\t MAE \\t\\t R2\")\nprint(\"\"\"Decision Tree Regressor \\t {:.2f} \\t\\t {:.2f} \\t\\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n            np.sqrt(mean_squared_error(y_test, y_pred_DTR)),\n            mean_squared_error(y_test, y_pred_DTR),\n            mean_absolute_error(y_test, y_pred_DTR),\n            r2_score(y_test, y_pred_DTR)))\n\nplt.scatter(y_test, y_pred_DTR)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\n\nplt.title(\"Decision Tree Regressor\")\n\nplt.show()","8da8959f":"# Tuning Hyperparameter max_depth & min_sam_split of DecisionTreeRegressor\nmax_d = list(range(1,10))\nmin_sam_split = list(range(10,50,15))\ngridcv = GridSearchCV(DTR, param_grid={'max_depth':max_d, 'min_samples_split':min_sam_split}, n_jobs=-1)\ngridcv.fit(X_train, y_train)","4205632e":"print(\"Parameters :\", gridcv.best_params_)\nprint(\"Train Score {:.2f} & Test Score {:.2f}\".format(gridcv.score(X_train, y_train), gridcv.score(X_test, y_test)))","63f2380e":"rf = RandomForestRegressor()\nrf.fit(X_train,y_train)","e18108e3":"y_pred = rf.predict(X_test)","2c1b2ef1":"print(\"Train Score {:.2f} & Test Score {:.2f}\".format(rf.score(X_train, y_train), rf.score(X_test, y_test)))","e875baac":"LogReg = LogisticRegression()\nLogReg.fit(X_train, y_train)","9668f1c2":"y_pred_test_Log = LogReg.predict(X_test)","dceda9a4":"print(\"Train Score {:.2f} & Test Score {:.2f}\".format(LogReg.score(X_train, y_train), LogReg.score(X_test, y_test)))","bdc5f4db":"import xgboost\nreg_xgb = xgboost.XGBRegressor()\nreg_xgb.fit(X_train,y_train)","816fa92e":"# predicting X_test\ny_pred_xgb = reg_xgb.predict(X_test)","357b0e6e":"print(\"Train Score {:.2f} & Test Score {:.2f}\".format(reg_xgb.score(X_train,y_train),reg_xgb.score(X_test,y_test)))","113786f6":"models = [LinReg, DTR, rf, reg_xgb]\nnames = [\"Linear Regression\", \"Decision Tree Regressor\", \"Random Forest Regressor\", \"XGBoost\"]\nrmses = []\n\nfor model in models:\n    rmses.append(np.sqrt(mean_squared_error(y_test, model.predict(X_test))))\n\nx = np.arange(len(names)) \nwidth = 0.3\n\nfig, ax = plt.subplots(figsize=(10,7))\nrects = ax.bar(x, rmses, width)\nax.set_ylabel('RMSE')\nax.set_xlabel('Models')\n\nax.set_title('RMSE with Different Algorithms')\n\nax.set_xticks(x)\nax.set_xticklabels(names, rotation=45)\n\nfig.tight_layout()","39d300a9":"df = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")","3543f6f5":"y_pred_test_OHE = rf.predict(test_OHE)","5acf77b8":"submission = pd.DataFrame({'Id': df.Id, 'SalePrice': y_pred_test_OHE})\nsubmission.to_csv('Housing_submission.csv', index=False)","2f4cf3dd":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:170%; text-align:left;\"> 6.2) Decision Tree <\/h1>","2b624d66":"#### 4. Explore the Categorical Features","18e08379":"- There is no unwanted column present in given dataset to remove.\n\n     EX: ID","2045df8e":"- All columns have **more than 1 unique value.** No feature found with one value.\n\n\n- There could be chance of only one category in a particular feature. In Categorical features, suppose gender column we have only one value ie male.Then there is no use of that feature in dataset. ","55676a64":"#### GrLivArea Vs SalePrice","a79c274e":"#### 7. Explore the Numerical Features","4eb6c051":"####  1stFlrSF Vs SalePrice","7d9303fe":"#### OverallQual Vs SalePrice","64ef8864":"#### LotArea Vs SalePrice","b7d2d44e":"#### LotFrontage Vs SalePrice","56096d98":"### OneHotEncoding","89680cb0":"#### 11. Relation between Continous numerical Features and Labels","66dddc53":"- With this information we can see that the prices are skewed right and some outliers lies above ~500,000. We will eventually want to get rid of the them to get a normal distribution of the independent variable (SalePrice) for machine learning","4ca9d82a":"#### OverallQual Vs SalePrice","1d1dd52b":"#### MoSold Vs SalePrice","40d32e84":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:180%; text-align:left;\"> 5.3) Multivariate Analysis <\/h1>\n\n- 1. Pair Plot\n    \n    Pair Plot between 'SalePrice' and correlated variables","afd4fdf9":"#### KitchenAbvGr Vs SalePrice","285c8a48":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 6) Model building and Evaluation <\/h1>","29753810":"#### 9. Find Continous Numerical Features","d705a9f0":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:170%; text-align:left;\"> 4.4.1) The correlation between the continuos variables <\/h1>\n\na. Pearson Correlation\n\nb. Spearman Correlation\n\nc. kendall","0466c345":"#### YrSold Vs SalePrice","3dbdec91":"- it seems all continuous features are not normally distributed\n\n- **MasVnrArea, BsmtFinSF1, BsmtUnfSF, 2ndFlrSF, GrLivArea & SalePrice** are **right skewed**\n\n- **YearBuilt,GarageYrBlt,GarageArea,YearRemodAdd** is **left skewed**.","e18859d8":"# Scatter Plot between \"LotArea\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nplt.scatter(np.log(train['LotArea']), np.log(train['SalePrice']))\n\nplt.xlabel('log_LotArea', fontsize=15, fontweight='bold')\nplt.ylabel('log_SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('log_LotArea Vs log_SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","3dc27b4a":"#### SalePrice vs MasVnrArea","bb8af5a9":"- Our dataset features consists of three datatypes\n     1. float\n     2. integer\n     3. object\n- Total numerical features are 38\n- Total categorical features are 43\n- Also we don't have complete data for all of our features","80195e2f":"<h1 style=\"background-color:DeepPink; font-family:newtimeroman; font-size:170%; text-align:left;\"> 4.4) Relation between Features <\/h1>","1780d09f":"- A lot of features seems to be correlated between each other but some of them such as **YearBuild\/GarageYrBlt** may just indicate a price inflation over the years. As for **1stFlrSF\/TotalBsmtSF**, it is normal that the more the 1st floor is large (considering many houses have only 1 floor), the more the total basement will be large.\n\n- There is a strong negative correlation between **BsmtUnfSF and BsmtFinSF2**.","9c22380b":"<h1 style=\"background-color:DeepPink; font-family:newtimeroman; font-size:170%; text-align:left;\"> 4.5) Skewness and Kurtosis <\/h1>","0d6839cd":"#### TotRmsAbvGrd Vs SalePrice","96f0c5c0":"### filling nan values of categorical features by their mode and numeric ones by thier mean.","d0f71a80":"- Our dataset features consists of three datatypes\n     1. float\n     2. integer\n     3. object\n- Total numerical features are 37\n- Total categorical features are 43\n- Also we don't have complete data for all of our features","f2a31fd2":"- for **each feature** it provides below:\n\n     1. count       --->  total no of data points\n     2. statistics  --->  mean, standard deviation\n     3. min & max   --->  values of feature\n     4. percentile  --->  25%, 50%, 75%","b7bc49c7":"<h1 style=\"background-color:DeepPink; font-family:newtimeroman; font-size:170%; text-align:left;\"> 4.1) Find Unwanted Columns <\/h1>","32e8f4b6":"- Skewness tells us about the symmetry in a distribution.\n\n* If the **skewness** is **between -0.5 to +0.5** then we can say data is **fairly symmetrical**.\n  \n* If the **skewness** is **between -1 to -0.5 or 0.5 to 1** then data is **moderately skewed**.\n  \n* If the **skewness** is **less than -1 and greater than +1** then our data is **heavily skewed**.","a69687ea":"#### 6. Relationship between Categorical Features and Label","efe41754":"#### 10. Distribution of Continous Numerical Features","ba5b49c6":"<h1 style=\"background-color:DeepPink; font-family:newtimeroman; font-size:170%; text-align:left;\"> 4.2) Missing Values <\/h1>","ccb55b37":"#### SaleCondition Vs SalePrice","eaeaec5a":"### Test Dataset\n#### a. Numeric Features","7218f738":"#### YearBuilt Vs SalePrice","48477104":"#### TotalBsmtSF Vs SalePrice","e5ff9e88":"#### MSSubClass Vs SalePrice","bfb630c9":"- Observed **Outliers** and **non-linear** relationship","30a19f1e":"#### b. Categorical Features","80b07002":"- Checking missing values by below methods:\n\n     1. df.isnull().sum()\n        - It returns null values for each column\n          \n     2. isnull().any()\n        - It returns True if column have NULL Values\n        - It returns False if column don't have NULL Values\n          \n     3. Heatmap()\n        - Missing value representation using heatmap.\n          \n     4. Percentage of Missing values","7f9d2b3f":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:180%; text-align:left;\"> 5.1) Univariate Analysis <\/h1>","79011374":"### Submission","67c7aff8":"#### 3. Find Features with one value","411d1131":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 2) Load Required Libraries <\/h1>","06a7315f":"# Scatter Plot between \"LotArea\" and \"SalePrice\"\nplt.figure(figsize=(7,6))\nplt.scatter(train['LotArea'], train['SalePrice'])\n\nplt.xlabel('LotArea', fontsize=15, fontweight='bold')\nplt.ylabel('SalePrice', fontsize=15, fontweight='bold')\n\nplt.title('LotArea Vs SalePrice', fontsize=18, fontweight='bold')\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.show()","ee6a44f7":"#### CentralAir Vs SalePrice","585a387c":"### 3. Box Plot","a66b0f60":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:170%; text-align:left;\"> 6.1) Linear Regression \/ Lasso \/ Ridge <\/h1>","e70eeeb4":"- 'GarageCars' and 'GarageArea' are strongly correlated variables. It is because the number of cars that fit into the garage is a consequence of the garage area. 'GarageCars' and 'GarageArea' are like twin brothers. So it is hard to distinguish between the two. Therefore, we just need one of these variables in our analysis (we can keep 'GarageCars' since its correlation with 'SalePrice' is higher).\n\n\n- 'TotRmsAbvGrd' and 'GrLivArea', twins","89d39cd6":"### 1. Histogram","9998e7c3":"#### 8. Find Discrete Numerical Features","93ef466c":"### 2. Scatter Plot","98bd4f4a":"### Checking for Numerical and Categorical features","e9d46169":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 5) Data Visualization <\/h1>\n\n- Used below **visualisation libraries**\n\n     1. Matplotlib\n     2. Seaborn (statistical data visualization)\n     \n### 1. Categorical\n\n- Categorical data :\n\n     1. Numerical Summaries\n     2. Histograms\n     3. Pie Charts\n\n\n### 2. Univariate Analysis\n\n- Univariate Analysis : data consists of **only one variable (only x value)**.\n\n     1. Line Plots \/ Bar Charts\n     2. Histograms\n     3. Box Plots \n     4. Count Plots\n     5. Descriptive Statistics techniques\n     6. Violin Plot","8e4c23ed":"- Observed **Outliers**","721b3cae":"### Train Dataset\n#### a. Numeric Features","c70d9fe2":"- In our above data,\n    1. LotArea\n    2. LowQualFinSF\n    3. 3SsnPorch\n    4. PoolArea\n    5. MiscVal\n- Are highly positively,right skewed.","c2c93c8c":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:170%; text-align:left;\"> 6.3) Random Forest <\/h1>","b1356bf4":"### Steps involved in EDA:\n1. Find Unwanted Columns\n- Find Missing Values\n- Find Features with one value\n- Explore the Categorical Features\n- Find Categorical Feature Distribution\n- Relationship between Categorical Features and Label\n- Explore the Numerical Features\n- Find Discrete Numerical Features\n- Relation between Discrete numerical Features and Labels\n- Find Continous Numerical Features\n- Distribution of Continous Numerical Features\n- Relation between Continous numerical Features and Labels\n- Find Outliers in numerical features\n- Explore the Correlation between numerical features","95bd61ce":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 1) Introduction <\/h1>","a324f07e":"- In our above data,\n    1. LowQualFinSF\n    2. 3SsnPorch\n    3. PoolArea\n    4. MiscVal\n- Are highly positively,right skewed.","23a06447":"### Score Summary :","3b180216":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:180%; text-align:left;\"> 5.2) Bivariate Analysis <\/h1>\n\n- **Bivariate Analysis** : data involves **two different variables**.\n\n     1. Bar Charts\n     2. Scatter Plots\n     3. FacetGrid\n     \n\n-  There are **three** types of bivariate analysis\n\n     1. Numerical & Numerical\n     2. Categorical & Categorical\n     3. Numerical & Categorical","3b52900d":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 3) Read Data <\/h1>","4f93f9b4":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 4) EDA (Exploratory Data Analysis) <\/h1>\n\n- EDA is a way of **Visualizing, Summarizing and interpreting** the information that is **hidden in rows and column** format.","7b3c3904":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:170%; text-align:left;\"> 4.4.2) The correlation between the continuos variables <\/h1>","29780ee5":"#### GarageArea Vs SalePrice","8c16b66a":"### 1. Line Plot","2b17b4a8":"#### 5. Find Categorical Feature Distribution","5a5de5e1":"### 4. Count Plot","9d6e6856":"### Drop Features have more missing values","250483f5":"<h1 style=\"background-color:DeepPink; font-family:newtimeroman; font-size:170%; text-align:left;\"> 4.3) Outliers <\/h1>","a5e498a9":"#### b. Categorical Features","98661733":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:170%; text-align:left;\"> 6.4) Logistic Regression <\/h1>","7c973667":"<h1 style=\"background-color:yellow; font-family:newtimeroman; font-size:170%; text-align:left;\"> 6.5) XGBoost <\/h1>","e8a62d87":"#### OpenPorchSF Vs SalePrice"}}