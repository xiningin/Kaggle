{"cell_type":{"f412ddf1":"code","747ff71f":"code","9848e194":"code","95db1cf8":"code","1b39a1a2":"code","9166d851":"code","7246272d":"code","5a60cb8d":"code","712094f7":"code","34b11942":"code","c8d278ac":"code","08199434":"code","d087d50c":"code","359eb719":"code","09ca1af0":"code","292d5b76":"code","5664055e":"code","0ef60c50":"code","038efcf5":"markdown","3de9a1dc":"markdown","5a42e17a":"markdown","1e2d2579":"markdown","c0473e00":"markdown"},"source":{"f412ddf1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","747ff71f":"import pandas as pd\nimport numpy as np \nimport seaborn as sns \nimport matplotlib","9848e194":"train = pd.read_csv('..\/input\/mobile-price-classification\/train.csv')\ntest = pd.read_csv('..\/input\/mobile-price-classification\/train.csv')","95db1cf8":"print(train.shape)\nprint(test.shape)","1b39a1a2":"train.head()","9166d851":"train.corr()","7246272d":"del train['clock_speed'] \ndel train['m_dep']\ndel train['n_cores']\ndel test['clock_speed'] \ndel test['m_dep']\ndel test['n_cores']","5a60cb8d":"train.head()","712094f7":"print(train.isnull().sum())\nprint(test.isnull().sum())\n","34b11942":"from sklearn.preprocessing import StandardScaler\nsts = StandardScaler()\nfeature_scale = ['battery_power','int_memory','mobile_wt','px_height','px_width','ram']\ntrain[feature_scale] = sts.fit_transform(train[feature_scale])\ntest[feature_scale] = sts.fit_transform(test[feature_scale])","c8d278ac":"train.head()","08199434":"x = train.drop('price_range',axis =1 )\ny = train['price_range']\nntest = test.drop('price_range',axis = 1)","d087d50c":"from sklearn import svm","359eb719":"clf = svm.SVC()","09ca1af0":"clf.fit(x,y)","292d5b76":"answer = clf.predict(ntest)","5664055e":"from sklearn.metrics import r2_score\nr2_score(test['price_range'],answer)","0ef60c50":"result = pd.DataFrame({'PricePredict':answer})\nresult.to_csv('answer.csv',index = False)","038efcf5":"**FEATURE SCALING**","3de9a1dc":"**IMPORTING MODELS**","5a42e17a":"**We need to notice the feature which are very lightly corelated with the price Range**\n***We will remove those feature as they aren't affecting much of the datsets***","1e2d2579":"**clock_speed** **m_dep**  **n_cores**","c0473e00":"**Hence our model prection is of 86 percent**"}}