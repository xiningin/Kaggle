{"cell_type":{"509192b2":"code","90ffbc29":"code","67262728":"code","9276fd49":"code","73e3807e":"code","f581ac41":"code","f195d69b":"code","3da2582b":"code","f48fd8a2":"code","00d34e70":"code","b8bea504":"code","628162d0":"code","8b787307":"markdown","7ece64e9":"markdown","a71120ae":"markdown","af3877a0":"markdown","3a2e4f04":"markdown","05e93131":"markdown","b4f27f14":"markdown","990fa316":"markdown","be87002a":"markdown","cbd24d51":"markdown","be49a430":"markdown"},"source":{"509192b2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport networkx as nx\nfrom networkx.algorithms import community\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport random\nplt.rcParams.update({'figure.max_open_warning': 50})\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n","90ffbc29":"def plot_degree_dist(G):\n    \"\"\" Generates a plot with the degrees of distribution of the connected components. \n    To facilitate the representation it was decided to also use the loglog contained in numpy\n    \n    --------------------------------------------------\n    \n    Input: G---> Graphs\n               A networkx graph\n\n    \n    Output: a list of values of the degree distribution\n        \n        \"\"\"\n    degrees = G.degree()\n    degrees = dict(degrees)\n    values = sorted(set(degrees.values()))\n    histo = [list(degrees.values()).count(x) for x in values]\n    P_k = [x \/ G.order() for x in histo]\n    \n    plt.figure()\n    plt.plot(values, P_k, \"ro-\")\n    plt.xlabel(\"k\")\n    plt.ylabel(\"p(k)\")\n    plt.title(\"Degree Distribution\")\n    plt.show()\n    \n    plt.figure()\n    plt.grid(False)\n    plt.loglog(values, P_k, \"bo-\")\n    plt.xlabel(\"log k\")\n    plt.ylabel(\"log p(k)\")\n    plt.title(\"log Degree Distribution\")\n    plt.show()\n    \n    \"\"\"\"Plot of the histogram degree distribution\"\"\"\n    \n    \n    plt.figure()\n    degrees = [G.degree(n) for n in G.nodes()]\n    counts = dict()\n    for i in degrees:\n        counts[i] = counts.get(i, 0) + 1\n    axes = plt.gca()\n    axes.set_xlim([0,100])\n    axes.set_ylim([0,1000])\n    plt.grid(False)\n    plt.bar(list(counts.keys()), counts.values(), color='r')\n    plt.title(\"Degree Histogram\")\n    plt.ylabel(\"Count\")\n    plt.xlabel(\"Degree\")\n    plt.show()\n    \ndef plot_degree_In(G):\n \n    \"\"\" Generates a plot with the  IN\/OUT degrees of distribution of the connected components. \n    To facilitate the representation it was decided to also use the loglog contained in numpy\n    \n        --------------------------------------------------\n     Parameters\n    \n    \n    Input: G---> Graphs\n    \n           A networkx graph\n\n    \n    Output: a list of values of the degree distribution\n    \n    \"\"\"\n    N = G.order()\n    in_degrees = G.in_degree()  #built-in function to estimate in-degree distribution\n    in_degrees = dict(in_degrees)\n    in_values= sorted(set(in_degrees.values()))\n    in_hist = [list(in_degrees.values()).count(x) for x in in_values]\n    in_P_k = [x \/ N for x in in_hist]\n    out_degrees = G.out_degree()   #built-in function to estimate out-degree distribution\n    out_degrees = dict(out_degrees)\n    out_values = sorted(set(out_degrees.values()))\n    out_hist = [list(out_degrees.values()).count(x) for x in out_values]\n    out_P_k = [x \/ N for x in out_hist]\n    \n    plt.figure()\n    plt.grid(False)\n    plt.plot(in_values ,in_P_k, \"r.\")\n    plt.plot(out_values,out_P_k, \"b.\")\n    plt.legend(['In-degree','Out-degree'])\n    plt.xlabel(\"k\")\n    plt.ylabel(\"p(k)\")\n    plt.title(\"Degree Distribution\")\n    plt.show()\n    \n    plt.figure()\n    plt.grid(False)\n    plt.loglog(in_values ,in_P_k, \"r.\")\n    plt.loglog(out_values,out_P_k, \"b.\")\n    plt.legend(['In-degree','Out-degree'])\n    plt.xlabel(\"log k\")\n    plt.ylabel(\"log p(k)\")\n    plt.title(\"log log Degree Distribution\")\n    plt.show()\n       \ndef plot_clustering_coefficient(G):\n        \"\"\" Generates a plot with the  clustering coefficientof.It is a measure of the degree to which\n        nodes in a graph tend to cluster together. \n    To facilitate the representation it was decided to also use the loglog contained in numpy\n        --------------------------------------------------\n     Parameters\n    Input: G---> Graphs\n    \n    Output: a list of values of the degree distribution\n    \"\"\"\n        clust_coefficients = nx.clustering(G)  #built-in function to estimate clustering coeff  \n        clust_coefficients = dict(clust_coefficients)\n        values1= sorted(set(clust_coefficients.values()))\n        histo1 = [list(clust_coefficients.values()).count(x) for x in values1]\n        \n        plt.figure()\n        plt.grid(False)\n        plt.plot(values1,histo1, \"r.\")\n        plt.xlabel(\"k\")\n        plt.ylabel(\"C (Clustering Coeff)\")\n        plt.title(\"Clustering Coefficients\")\n        plt.show()\n        \n        \n        plt.figure()\n        plt.grid(False)\n        plt.loglog(values1,histo1, \"r.\")\n        plt.xlabel(\"log degree k\")\n        plt.ylabel(\"c (clustering coeff)\")\n        plt.title(\"log log Clustering Coefficients\")\n        plt.show()\n        \n        plt.figure()\n        degrees1 = [nx.clustering(G,n) for n in G.nodes()]\n        plt.hist(degrees1)\n        plt.xlabel(\"log degree k\")\n        plt.ylabel(\"C (Clustering Coeff) hist\")\n        plt.title(\"Clustering Coefficients\")\n        plt.show()\n    \ndef plot_shortest_path_length(G):\n    \n    \"\"\"Plot and Compute shortest paths in the graph.\n\n    Parameters\n    ----------\n    G : NetworkX graph\n\n\n    Returns\n    -------\n    path: list or dictionary\n        All returned paths include both the source and target in the path.\n\n        If the source and target are both specified, return a single list\n        of nodes in a shortest path from the source to the target.\n\n        If only the source is specified, return a dictionary keyed by\n        targets with a list of nodes in a shortest path from the source\n        to one of the targets.\n\n        If only the target is specified, return a dictionary keyed by\n        sources with a list of nodes in a shortest path from one of the\n        sources to the target.\n\n        If neither the source nor target are specified return a dictionary\n        of dictionaries with path[source][target]=[list of nodes in path].\n\"\"\"\n    \n    dist = {}   #inizialize distance dictionary\n    len_pathlengths = 0    #inizialize length path\n    sum_pathlengths = 0    #inizialize sum of length path\n    for n in G.nodes():\n        pathlenghts = []\n        spl = nx.single_source_shortest_path_length(G,n)\n        \n        \"\"\"Compute the shortest path lengths from source to all reachable nodes.\n        Parameters:\n            \u2022G (NetworkX graph) \u2013 \n            \u2022source (node) \u2013 Starting node for path\n            \u2022cutoff (integer, optional) \u2013 Depth to stop the search. Only paths of length <= cutoff are returned.\n        Returns:\n            lengths \u2013 Dictionary of shortest path lengths keyed by target.\n            \n        Return type: dictionary\n \n\n\"\"\"\n        for p in spl:\n            pathlenghts.append(spl[p])\n            len_pathlengths += 1\n            \n        for p in pathlenghts:\n            if p in dist:\n                dist[p] +=1\n            else:\n                dist[p] = 1        \n        sum_pathlengths += sum(pathlenghts)\n            \n    print('')\n    print(\"Average shortest path length %s\" % (sum_pathlengths\/ len_pathlengths))  \n    print(\"diameter: %d\" % nx.diameter(max(nx.connected_component_subgraphs(G), key=len)))  \n    connected_components = [len(c_components) for c_components in sorted(nx.connected_components(G), key = len, reverse  = True)]\n    print(\"connected components: %s\" % connected_components)    \n    \n    print('')\n    print(\"length #paths\")\n          \n    for d in sorted(list(dist.keys())[1:]):  \n        print('%s %d ' % (d, dist[d]))\n    \n    length_path = list (dist.keys())[1:] \n    no_paths = list (dist.values()) [1:]\n    \n    plt.figure()\n    plt.grid(False)\n    plt.plot(length_path, no_paths, 'ro-')\n    plt.xlabel('distance')\n    plt.ylabel('number of paths')\n    plt.title('Length of shortest paths' )\n    plt.show()\n","67262728":"#%%   ---------------------------------------SMALL WORLD UTILITIES-----------------------------------------\n\n    \ndef adjacent_edges(nodes, halfk):    \n\n    n = len(nodes)\n    for i, u in enumerate(nodes):\n        for j in range(i+1, i+halfk+1):\n            v = nodes[j % n]\n            yield u,v\n\n\n       \ndef make_ring_lattice(n,k):\n    \"\"\"Generate a view of lattice graph\"\n            Parameters:\n            \u2022G (NetworkX graph) \u2013 \n            \n            k (node) \u2013 number of adjacent nodes\n        Returns:\n            graphs \u2013 a graph lattice view\n            \n        Return type: networkx graph\n    \"\"\"\n    G = nx.Graph()\n    nodes = range(n)\n    G.add_nodes_from(nodes)\n    G.add_edges_from(adjacent_edges(nodes, k\/\/2))\n    return G\n\ndef flip(p):\n    return np.random.random() < p \n\ndef rewire(G,p):\n    nodes = set(G)\n    for u, v in G.edges():\n        if flip(p): \n            choices = nodes - {u} - set(G[u])\n            new_v = np.random.choice(list(choices))\n            G.remove_edge(u, v)\n            G.add_edge(u, new_v)\n            \ndef small_world(n,k,p):\n    sw = make_ring_lattice(n,k)\n    rewire(sw,p)\n    return sw","9276fd49":"def k_core(G,k,t):\n    \n    \n        \"\"\"Return the core number for each vertex.\n\n    A k-core is a maximal subgraph that contains nodes of degree k or more.\n\n    The core number of a node is the largest value k of a k-core containing\n    that node.\n\n    Parameters\n    ----------\n    G : NetworkX graph\n       A graph or directed graph\n\n    Returns\n    -------\n    core_number : dictionary\n       A dictionary keyed by node to the core number\"\"\"\n       \n        H=G.copy() \n        i=1\n        while (i>0):\n            i=0\n            for node in list(H.nodes()):\n                if H.degree(node)<k:\n                    H.remove_node(node)\n                    i+=1\n        if (H.order()!=0):\n            plt.figure()\n            plt.title(str(k) +'-core decomposition of' + t) \n            nx.draw(H,with_labels=True)\n        return H\n\ndef full_k_core_decomposition(G,t):\n    empty = False\n    k=1\n    while (empty==False):\n        H = k_core(G,k,t)\n        k+=1\n        if (H.order()==0):\n            empty = True\n            ","73e3807e":"graphs = nx.read_edgelist('..\/input\/com-youtube.ungraph.txt',create_using=nx.Graph(), nodetype=int) \n\nsubset = 1000\nedges = graphs.edges()\nedges = list(edges)[:int(subset)]   \nedges = [list(elem) for elem in edges] \n\n\n#%% formatting necessary to allow performing nx.parse_edglist\n\n_newlist = []\n_list = []\n\nfor subsets in edges:\n    for element in subsets:\n        _list.append(element)\n\n_temp= int(len(_list)*0.5)\n\nfor i in range (_temp):\n    _newlist.append(str(_list[2*i]) + \" \" + str(_list[2*i +1]) ) \nprint(_newlist)\ngraphs = nx.parse_edgelist(_newlist, nodetype = int) \n\n#%%\n\"\"\"1 Original Graphs Measures\"\"\"\nN=graphs.order()  \nE = graphs.number_of_edges()  \nAv_deg_undirected = float(2*E)\/N  \n\nprint (\"\\n ORIGINAL GRAPH: \")\nprint(\"The number of nodes is:\", N)\nprint(\"The number of edges is:\", E)\nprint(\"The average degree (undirected graph) is:\", Av_deg_undirected)\n\nplot_degree_dist(graphs) \nplot_clustering_coefficient(graphs)\nplot_shortest_path_length(graphs)\nprint ('The average clustering coefficient is: ' + str(nx.average_clustering(graphs)))","f581ac41":"communities_gen = community.girvan_newman(graphs)\ntop_level_communities = next(communities_gen)\nnext_level_communities = next(communities_gen)\na=sorted(map(sorted,next_level_communities))","f195d69b":"#%% \n\"\"\"GENERATION OF THE SBM GRAPH\"\"\"\n\nsizes = []\nprobs = []\n\n\n\n\nfor com in a:\n  sizes.append(len(com))\n  \n\nnum11 = sizes[0] * (sizes[0]-1)*0.5\nnum12 = sizes[0] * sizes[1]\nnum13 = sizes[0] * sizes[2]\nnum22 = sizes[1] * (sizes[1]-1)*0.5\nnum23 = sizes[1] * sizes[2]\nnum33 = sizes[2] * (sizes[2]-1)*0.5\n\nnum_edges11,num_edges22,num_edges33,num_edges12,num_edges13,num_edges23 = [0,0,0,0,0,0]\nfor g in edges:\n    g[0] = int(g[0])\n    g[1] = int(g[1]) \nfor h in edges:\n  if (h[0] in a[0] and h[1] in a[0]):\n    num_edges11+=1\n  elif (h[0] in a[1] and h[1] in a[1]):\n    num_edges22+=1\n  elif (h[0] in a[2] and h[1] in a[2]):\n    num_edges33+=1    \n  elif ((h[0] in a[0] and h[1] in a[1]) or (h[0] in a[1] and h[1] in a[0])):\n    num_edges12+=1    \n  elif ((h[0] in a[0] and h[1] in a[2]) or (h[0] in a[2] and h[1] in a[0])):\n    num_edges13+=1\n  else:\n      (h[0] in a[1] and h[1] in a[2]) or (h[0] in a[2] and h[1] in a[1])\n      num_edges23+=1    \np11 = float (num_edges11\/num11)\np12 = float (num_edges12\/num12)\np13 = float (num_edges13\/num13)\np22 = float (num_edges22\/num22)\np23 = float (num_edges23\/num23)\np33 = float (num_edges33\/num33)\n\nprobs1 = [p11,p12,p13],[p12,p22,p23],[p13,p23,p33]\n\nprint(probs1)\n#%% It is now possible to generate the SBM and calculate some statistic measures on it\n\nSBM = nx.stochastic_block_model(sizes, probs1, seed=0)\n\n\"\"\"2a STATISTICS ABOUT MEASURES - SBM\"\"\"\nSBM_nodes=SBM.order()\nSBM_Edges = SBM.number_of_edges()\nAv_deg_SBM = float(2*SBM_Edges)\/SBM_nodes\n\nprint (\"\\n SBM GRAPH: \")\nprint(\"The number of nodes is:\", SBM_nodes)\nprint(\"The number of edges is:\", SBM_Edges)\nprint(\"The average degree (undirected graph) is:\", Av_deg_SBM)\n\nplot_degree_dist(SBM) \nplot_clustering_coefficient(SBM)\nplot_shortest_path_length(SBM)\nprint ('The average clustering coefficient is: ' + str(nx.average_clustering(SBM)))","3da2582b":"#%% Generation of Erdos-Renyi random graph\n\n\"\"\"2b STATISTICS ABOUT MEASURES - ERDOS-RENYI\"\"\"\n\nProba = E\/(N*(N-1)\/2)\nErdos_renyi = nx.erdos_renyi_graph (N, Proba)\nNodes_erdos=Erdos_renyi.order()\nEdges_erdos = Erdos_renyi.number_of_edges()\nAv_deg_und_erdos = float(2*Edges_erdos)\/Nodes_erdos  \n\nprint (\"\\n ERDOS-RENYI GRAPH: \")\nprint(\"The number of nodes is:\", Nodes_erdos)\nprint(\"The number of edges is:\", Edges_erdos)\nprint(\"The average degree (undirected graph) is:\", Av_deg_und_erdos)\n\nplot_degree_dist(Erdos_renyi) \nplot_clustering_coefficient(Erdos_renyi)\nplot_shortest_path_length(Erdos_renyi)\nprint ('The average clustering coefficient is: ' + str(nx.average_clustering(Erdos_renyi)))\n","f48fd8a2":"\"\"\"2b STATISTICS ABOUT MEASURES - SMALL WORLD\"\"\"\n\nSmall_World = small_world(N,4,0.2)\nnx.draw_circular(Small_World)\n\nNodes_SW=Small_World.order()\nEdge_SW = Small_World.number_of_edges()\nAv_deg_SW = float(2*Edge_SW)\/Nodes_SW  \nprint (\"\\n SMALL WORLD GRAPH: \")\nprint(\"The number of nodes is:\", Nodes_SW)\nprint(\"The number of edges is:\", Edge_SW)\nprint(\"The average degree (undirected graph) is:\", Av_deg_SW)\n\nplot_degree_dist(Small_World) \nplot_clustering_coefficient(Small_World)\nplot_shortest_path_length(Small_World)\nprint ('The average clustering coefficient is: ' + str(nx.average_clustering(Small_World)))","00d34e70":"\"\"\"4 DIRECTED VERSION WITHOUT 25% OF THE LINKS\"\"\"\n\nk = int(E*0.25)\nDG = graphs.copy()\nDG = DG.to_directed()\nedges_d = DG.edges()\nlist_edges_d = list(edges_d)\nrandom.shuffle(list_edges_d)\n\nfor edgee in list_edges_d:\n    if (DG.degree(edgee[0]) != 1 and DG.degree(edgee[1]) != 1):\n        DG.remove_edge(edgee[0],edgee[1])\n        k-=1\n    if (k==0):\n        break\n\nN4=DG.order()\nE4 = DG.number_of_edges()\nAv_deg_d = float(E)\/N \n\nprint (\"\\n DIRECTED VERSION WITHOUT 25% OF THE LINKS: \")\nprint(\"The number of nodes is:\", N4)\nprint(\"The number of edges is:\", E4)\nprint(\"The average degree (directed graph) is:\", Av_deg_d)\n\nplot_degree_dist(DG)\nplot_degree_In(DG)\nplot_clustering_coefficient(DG)\nDG = DG.to_undirected()\nplot_shortest_path_length(DG)\nprint ('The average clustering coefficient is: ' + str(nx.average_clustering(DG)))\n","b8bea504":"page_rank = nx.pagerank(graphs)\ndict_degree_centrality = nx.degree_centrality(graphs)\ndict_closeness_centrality = nx.closeness_centrality(graphs)\n#dict_eigenvector_centrality = nx.eigenvector_centrality(graphs)   #sometimes doesn't run\ndict_harmonic_centrality = nx.harmonic_centrality(graphs)\ndict_betweeness=nx.betweenness_centrality(graphs)","628162d0":"\"\"\"6 K-CORE DECOMPOSITION\"\"\"   \n_G_CORE = nx.k_core(graphs, 2)\npos = nx.spring_layout(graphs)\nplt.figure()\nplt.title(' networkx 2-core decomposition of Original graph')\nnx.draw_networkx(_G_CORE , pos = pos, node_size = 1, edge_color = \"blue\", alpha = 0.5, with_labels = True)\nOriginal_Graph = full_k_core_decomposition(graphs, ' Original graph')\nSBM_graph = full_k_core_decomposition(SBM, ' Stochastic Block Model graph')\nErdos_Renyi_graph = full_k_core_decomposition(Erdos_renyi, ' Erdos Renyi graph')\nSmal_Word_graph = full_k_core_decomposition(Small_World, ' Small World graph')\nDegraded_Graphs = full_k_core_decomposition(DG, ' degraded graph')\n  ","8b787307":"The most common use for community detection is for the analysis and understanding of network data. The community structure can give us several information about the structure of network like nature and social interactions. Clusters of nodes in a web graph for instance might indicate groups of related web pages. Clusters of nodes in a metabolic network might indicate functional units within the network. The algorithm used for the community detection is: girvan_newman. The Girvan\u2013Newman algorithm detects communities by progressively removing edges from the original network. The connected components of the remaining network are the communities. Instead of trying to construct a measure that tells us which edges are the most central to communities, the Girvan\u2013Newman algorithm focuses on edges that are most likely \"between\" communities. Algorithm removes edge with the highest betweenness centrality at each step.","7ece64e9":"The Clustering Clustering (or Transitivity) is  used as a way measure the degree of connectedness, as well as a way to study the large-scale structure of a network. The clustering coefficient C_iof a vertex i is can be interpreted as the propensity a node has to form triangles. More in detail, it is the frequency of pairs of neighbors of i that are connected by an edge, that is, it is the ratio of the number m_i of pairs of neighbors of i that are connected and the number of possible pairs of neighbors of i, which is k_i (k_i-1)\/2, where k_i  is the degree of i:\nC_i=\u30162m\u3017_i\/(k_i (k_i-1))\nIn other words, C_iis the probability that a pair of neighbors of i are connected. The values of C_iranges from 0 to 1: the lower bound represent the situation where no pairs of neighbors of i are connected, while the upper bound holds when all pairs are linked. In the latter case, the set of neighbors of i extended with i itself forms a clique, that is a graph where each pair of nodes  .\n","a71120ae":"In order to calculate and plot the degree distribution I have implemented a dedicated function.We recall that the degree of a node is the number of directly connected neighbors of the node. For any integer k>=0, the quantity p_k is the fraction of nodes having degree k. This is also the probability that a randomly chosen node in the network has degree k. The quantities p_k, for k =>0, represent the degree distribution of the network.\nDirected networks have two different degree distributions, the in-degree and the out-degree distributions. We might observe, however, that the true degree distribution of a directed network is a joint distribution of in- and out- degrees. That is, for every i,j >= 0, we have a probability p_(i,j) that a randomly chosen node in the graph has i predecessor nodes and j successor nodes. In most real networks, the degree distribution is highly asymmetric (or skewed): most of the nodes (the trivial many) have low degrees while a small but significant fraction of nodes (the vital few) have a high degree. A highly connected node, a node with high degree, is called hub. Since the probability of hubs, although low, is relevant, the degree distribution p_k, when plotted as a function of the degree k, the distribution shows a long tail, which is much fatter than the tail of a Gaussian or exponential model. P(k) of a network is then defined to be the fraction of nodes in the network with degree k. Thus, if there are n nodes in total in a network and nk of them have degree k, we have P(k) = nk\/n. On the x-axis we observe the number of nodes considered and on the y-axis the value of the probability degree of the nodes. \n","af3877a0":"Small World\n\nIn most real network the typical geodesic distance is surprisingly short, in particular when compared with the number of nodes of the network. The small-world effect has a substantial implication for networked systems. Suppose a rumor (or a disease) is spread by a person over a social network, it will reach other people much faster if it is only about six steps away from any person than if it is a hundred steps away. Similarly, the speed with which one gets a response from another computer on the Internet depends on how many hops data packets have to make as they traverse the network. In a regular graph, every node has the same number of neighbors. I will consider two properties of  these graphs: clustering and path length.\nThe small world phenomenon was fist described by Watts and Strogatz. They showed that regular graphs have and high clustering and low path lengths, whereas random graphs with the same size usually have low clustering and low path lengths. One of their objectives was to create a good graph generative model which combines high clustering and short path length. The goal was to create a generative model of a social network. A generative model tries to explain a phenomenon by modelling the process that builds or leads to the phenomenon.\nThe process for building small-world graphs can be summarized as follows:\n\u2022\tStart with regular graphs with n nodes and each node connected to k neighbors\n\u2022\tChoose a subset of the edges and \"rewire\" them by replacing them with random edges.\np is known as the probability that an edge is rewired, and this controls how the graph randomization is performed. With p=0 the graph is regular; with p=1 the graphs it is totally random.\nThe Small-World phenomenon can be replicated in the following steps:\n1.\tBuild a ring lattice, a particular kind of graph\n2.\trewire as Watts and Strogatz did\n3.\tWrite a function to measure the clustering coefficient and use networkx to compute path length\n4.\tcompute path length e degree for a range of value p\n5.\tCompute shortest path.\n\nAdjacent Edges\nA regular graph is a graph where each node has the same number of neighbors; in ring lattice with n nodes, the nodes can be arranged in a circle with each node connected to the k nearest neighbors. \n\nMake Ring lattice\nMake ring lattice uses floor division to compute halfk, so it only corrects if k is even. If k is odd, floor division rounds down, so the result is a ring lattice with k-1 degree.\n\nWatts and Strogatz graphs\n\nTo make a Watts and Strogatz graph, we start with ring lattice and rewire some of its edges. If an edge is rewired, we leave the first node unchanged and choose the second node at random. Self-loops or multiple edges are not allowed, you can\u2019t have an edge from a node to itself, and you can\u2019t have more than one edge between the same two nodes.\n1.\tTo compute the possible choices, we start with nodes, which are a set and subtract the source node u and its neighbors, which avoids self-loops and multiple edges\n2.\tTo choose new_v we use the numpy function\n3.\tWe remove the existing edge from u to v\n4.\tAdd new edge from u to new_v\n","3a2e4f04":"Stochastic Block Model\n\nAs previously stated, we can talk about random graphs and generative models. The stochastic block tends to produce  graphs containing communities, subsets characterized by being connected with one another with particular edge densities\nThe stochastic block model takes the following parameters:\n\tThe number n of vertices;\n\ta partition of the vertex set {1,\u2026,n}  into disjoint subsets {C_1,\u2026 , C_r} called communities;\n\ta symmetric  r matrix and  P of edge probabilities.\nThe edge set is then sampled at random as follows: any two vertices u \u2208 C_i and v \u2208 C_j  are connected by an edge with probability  P_ij  .\n","05e93131":"The ER model is a random generative model, the distributions are normal as can be observed and it is not scale free. The average path is basically long and not in the order of the log so it is not even small world. In fact this is a random network. The nodes considered are 2000, therefore, as mentioned above, log (2000) is about 3 different from the average path which is about 10 on average.","b4f27f14":"Coreness is a measure that can help identify tightly interlinked groups within a network. A k-core is a maximal group of entities, all of which are connected to at least k other entities in the group. K-Core is a measure that can help identify small interlinked core areas on a network. To be included in the K-Core, an entity must be linked to at least k other entities in the group. The linked entities are regardless of how many other entities that they are connected to outside of the group. Maximal in the definition means that we are interested in the largest set of entities with the required minimum number of neighbors within the group. The value of k is sometimes referred to as the coreness of the group. The algorithm for determining the cores hierarchy is based on the following property: If from a given graph G = (V,L) we recursively delete all vertices, and edges incident with them, with degree less than k, the remaining graph is the k-core.\nInput: Graph G = (V,L) represented by lists of neighbors\nOutput: table core with core number for each vertex","990fa316":"Analysis & Considerations\n\nThe values obtained from the small world model are diametrically opposed to those highlighted above. The degree of distribution has the maximum value pk with the intersection k = 4. The histogram of the degrees of distribution shows that the values are in a neighborhood between 0 and 5. The apical point is found in degree 3 with a value of 1000.  SW has a normal distribution, so there are no further observations on the various graphs. You might think of using another type of layout instead of the latex ring to better appreciate the graphic. The average path turns out to be longer than those previously observed.\n","be87002a":"Shortest Path\n\nThe geodesic path between two nodes in a graphs with minimum number of edges is called shortest path. If the graphs is weighted, the path is the minimum sum of edge weights. The geodesic distance is not necessarily unique, but geodesic is well defined since all geodesic paths have the same length. In small world networks  thepath lengths in networks should typically scale as log(n) with n of node networks. The idea behind short distance is that number of nodes one encounters in a breath-first visit of a graph starting from source increase exponentially with the distance to source node, hence the distance increase logarithmically in the number of visited nodes.\nThe diameter is a less useful measure for real networks than the average distance, it really only measures the distance between one pair of vertices at extreme end of the distribution of distance.\n","cbd24d51":"Analysis & Considerations:\n\nThe k-core decomposition on the original network generates graphs that seem to follow a preferential attachment behavior. There are nodes with very high degree and very few with low degree. This is compatible with the starting network, which is a natural. The decomposition of the Random and Small world graphs is not easily observable but surely for ER the subgraphs are random because the original distribution is normal and consequentially the sub graph distribution are normal and thus random. The same evaluation applies to SW.  Degraded graphs also follow how it is possible to observe a power law.\n","be49a430":"The ER graph G(n,p) contains n nodes, and each pair of nodes is connected by an edge with probability p. Generating an ER graph is similar to generating a graph. In an ER graph the probability that the graph is connected is very low when p is small and nearly to 1. Between the region small p and large p there is a rapid transition at a particular p denoted p* Erdos Renyi showed that this critical value is p* = ln(n)\/n, where n is number of nodes A random graph, G(n,p), is unlikely to be connected if p < p\u2217 and very likely to be connected if p > p\u2217."}}