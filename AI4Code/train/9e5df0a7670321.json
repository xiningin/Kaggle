{"cell_type":{"a5f17808":"code","ded875b0":"code","03984de7":"code","3ef1466a":"code","e52d01f6":"code","7a9da26e":"code","5d59ae5c":"code","976c7f29":"code","0d0a8718":"code","79cb569e":"code","382fe73d":"code","65f45228":"code","38a8f030":"code","9a81c15f":"code","bffad578":"code","269c646e":"code","4a1bb803":"code","faed681e":"code","0ad4e8be":"code","81ea8737":"code","0b44ab5b":"code","1a6b61ce":"code","76b2a0c9":"code","c83f82f7":"code","022460aa":"code","6d5f41e9":"code","e2e67112":"code","7539ec80":"code","fa33fec1":"code","55eb8605":"code","58fa684f":"code","1ceb199b":"code","95c40779":"code","fd814977":"code","58bc4ec4":"code","2a00d26a":"code","2c1aaec3":"code","5676ca15":"code","1bcfe65a":"code","7c796b5a":"code","d24fa855":"code","11ff0255":"code","836445a6":"code","982c1559":"code","b254f70f":"code","21b592a9":"code","87bcac1a":"code","0fd75b8f":"code","933743e5":"code","c3c6b4bb":"code","f96dd06d":"code","2e6ec367":"code","ca9ff331":"code","625a170d":"code","85fc7e72":"code","be55f8c0":"markdown","90dfa04d":"markdown","7e4c18bb":"markdown","9a5181fa":"markdown","6e29b8b6":"markdown","bbb3be15":"markdown","0e86fda4":"markdown","31db2c8f":"markdown","a64a245f":"markdown","164e9b1e":"markdown","0286459a":"markdown","7ed15e16":"markdown","0b0a49df":"markdown","391b5782":"markdown","78d574bf":"markdown","49092340":"markdown","f9fac333":"markdown","daf2be3d":"markdown","88a2295d":"markdown","f8731219":"markdown","875874ad":"markdown","8f7e8ad1":"markdown","aaf8aa54":"markdown","e2b901c5":"markdown","39b0676d":"markdown","6c15b073":"markdown","138ad05a":"markdown","9ca0c4ea":"markdown","e9e4721b":"markdown","d84bbd47":"markdown","5046b6bd":"markdown","fb130352":"markdown","41c1a768":"markdown","2c0cf85a":"markdown","da85102b":"markdown","90477c02":"markdown","d94500a9":"markdown","03a43c61":"markdown","88c967d5":"markdown","bb28063a":"markdown","d130ec9a":"markdown","ca77b205":"markdown","6a0e5687":"markdown"},"source":{"a5f17808":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom catboost import CatBoostRegressor\nfrom sklearn.model_selection import GridSearchCV\n%matplotlib inline","ded875b0":"src = r'..\/input\/insurance\/insurance.csv'\ndata = pd.read_csv(src)","03984de7":"data.info()","3ef1466a":"#Getting a handle on the overall data\ndata.describe(include='all')","e52d01f6":"# Transforming categorical features to numerical values\ndata[\"smoker\"] = data[\"smoker\"].replace([\"yes\",\"no\"], [1,0])\ndata[\"sex\"] = data[\"sex\"].replace([\"male\",\"female\"], [1,0])\ndata[\"region_southeast\"] = data[\"region\"].apply(lambda x: 1 if x == \"southeast\" else 0)","7a9da26e":"fig, ax = plt.subplots(figsize=(12,6))\nsns.distplot(x=data.loc[data['sex']==1, 'charges'], label='male', ax=ax)\nsns.distplot(x=data.loc[data['sex']==0, 'charges'], label='female', ax=ax)\nplt.legend()\nplt.show()","5d59ae5c":"fig, ax = plt.subplots(figsize=(12,6))\nsns.distplot(x=data.loc[data['region']=='southwest', 'charges'], label='southwest', ax=ax)\nsns.distplot(x=data.loc[data['region']=='southeast', 'charges'], label='southeast', ax=ax)\nsns.distplot(x=data.loc[data['region']=='northwest', 'charges'], label='northwest', ax=ax)\nsns.distplot(x=data.loc[data['region']=='northeast', 'charges'], label='northeast', ax=ax)\nplt.legend()\nplt.show()","976c7f29":"sns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\nplt.figure(figsize = (10,6))\nsns.scatterplot(x = \"age\", y = \"charges\", data = data)\nplt.xlabel(\"Age\")\nplt.ylabel(\"Charges\")\nplt.title(\"Distribution of charges by age\")","0d0a8718":"sns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\nplt.figure(figsize = (10,6))\nsns.scatterplot(x = \"bmi\", y = \"charges\", data = data)\nplt.xlabel(\"BMI\")\nplt.ylabel(\"Charges\")\nplt.title(\"Distribution of charges by bmi\")","79cb569e":"plt.figure(figsize = (10,5))\nsns.boxplot(x = \"sex\", y = \"charges\", data = data)","382fe73d":"plt.figure(figsize = (10,5))\nsns.boxplot(x = \"region\", y = \"charges\", hue = \"sex\", data = data)","65f45228":"plt.figure(figsize = (10,5))\nsns.boxplot(x = \"region\", y = \"charges\", data = data)","38a8f030":"fig, ax = plt.subplots(figsize=(12,6))\nsns.distplot(x=data.loc[data['children']==0, 'charges'], label='0', ax=ax)\nsns.distplot(x=data.loc[data['children']==1, 'charges'], label='1', ax=ax)\nsns.distplot(x=data.loc[data['children']==2, 'charges'], label='2', ax=ax)\nsns.distplot(x=data.loc[data['children']==3, 'charges'], label='3', ax=ax)\nsns.distplot(x=data.loc[data['children']==4, 'charges'], label='4', ax=ax)\nsns.distplot(x=data.loc[data['children']==5, 'charges'], label='5', ax=ax)\nplt.legend()\nplt.show()","9a81c15f":"plt.figure(figsize = (10,8))\nsns.boxplot(x = \"children\", y = \"charges\",hue = \"smoker\", data = data)\nplt.title(\"Distribution of charges by number of children\")","bffad578":"fig, ax = plt.subplots(figsize=(12,6))\nsns.distplot(x=data.loc[data['smoker']==1, 'charges'], label='smoker', ax=ax)\nsns.distplot(x=data.loc[data['smoker']==0, 'charges'], label='not smoker', ax=ax)\nplt.legend()\nplt.show()","269c646e":"sns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\nplt.figure(figsize = (10,6))\nsns.scatterplot(x = \"age\", y = \"charges\", data = data, hue = \"smoker\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Charges\")\nplt.title(\"Distribution of charges by age and smoker\")","4a1bb803":"clust_by_risk = data[['age', 'charges']]\nclust_by_risk.head()","faed681e":"kmeans = KMeans(n_clusters=3,random_state=19).fit(clust_by_risk)\ndata['risk_cluster'] = kmeans.labels_\ndata.head()","0ad4e8be":"sns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\nplt.figure(figsize = (10,6))\nsns.scatterplot(x = \"age\", y = \"charges\", data = data, hue = \"risk_cluster\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Charges\")\nplt.title(\"Distribution of charges by age and Risk_Cluster\")","81ea8737":"plt.figure(figsize = (10,8))\nsns.boxplot(x = \"risk_cluster\", y = \"charges\",hue = \"smoker\", data = data)\nplt.title(\"Distribution of charges by number of risk_cluster\")","0b44ab5b":"sns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\nplt.figure(figsize = (10,6))\nsns.scatterplot(x = \"bmi\", y = \"charges\", data = data, hue = \"risk_cluster\")\nplt.xlabel(\"bmi\")\nplt.ylabel(\"Charges\")\nplt.title(\"Distribution of charges by bmi and Risk_Cluster\")","1a6b61ce":"data.head()","76b2a0c9":"sns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\nplt.figure(figsize = (10,6))\nsns.boxplot(x = \"smoker\", y = \"charges\", data = data, hue = \"risk_cluster\")\nplt.xlabel(\"Smoker\")\nplt.ylabel(\"Charges\")\nplt.title(\"Distribution of charges by smoker and Risk_Cluster\")","c83f82f7":"data.corr()","022460aa":"sns.heatmap(data.corr(), annot = True)","6d5f41e9":"data.head()","e2e67112":"!pip install pydotplus","7539ec80":"# sklearn\u306etree\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\nfrom sklearn import tree\nfrom IPython.display import Image\nimport pydotplus\nfrom sklearn.tree import DecisionTreeRegressor,plot_tree\nfrom sklearn.metrics import accuracy_score, roc_curve, auc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n","fa33fec1":"src = r'..\/input\/insurance\/insurance.csv'\ndata = pd.read_csv(src)","55eb8605":"# Transforming categorical features to numerical values\ndata[\"smoker\"] = data[\"smoker\"].replace([\"yes\",\"no\"], [1,0])\ndata[\"sex\"] = data[\"sex\"].replace([\"male\",\"female\"], [1,0])\ndata[\"region_southeast\"] = data[\"region\"].apply(lambda x: 1 if x == \"southeast\" else 0)","58fa684f":"clust_by_risk= data[['age', 'charges']]\nclust_by_risk.head()","1ceb199b":"kmeans = KMeans(n_clusters=3,random_state=19).fit(clust_by_risk)\ndata['risk_cluster'] = kmeans.labels_\ndata = data[:1000]\ndata.head()","95c40779":"fig, ax = plt.subplots(figsize=(12,6))\nsns.distplot(x=data.loc[data['risk_cluster']==0, 'charges'], label='A', ax=ax)\nsns.distplot(x=data.loc[data['risk_cluster']==1, 'charges'], label='B', ax=ax)\nsns.distplot(x=data.loc[data['risk_cluster']==2, 'charges'], label='C', ax=ax)\nplt.legend()\nplt.show()","fd814977":"data = data.drop([\"region\"], axis = 1)\ny = data[\"risk_cluster\"]\nx = data.drop([\"charges\",\"risk_cluster\"], axis = 1)\nx_train, x_valid, y_train ,y_valid = train_test_split(x, y, test_size = 0.25, random_state=97)","58bc4ec4":"clf2 = RandomForestClassifier(random_state=0)\nclf2 = clf2.fit(x_train, y_train)","2a00d26a":"pred = clf2.predict(x_valid)\nfpr, tpr, thresholds = roc_curve(y_valid, pred, pos_label=1)\nauc(fpr, tpr)\nscore = accuracy_score(y_valid, pred)\nprint(score)","2c1aaec3":"src = r'..\/input\/insurance\/insurance.csv'\ndata = pd.read_csv(src)\ndata = data[1001:]","5676ca15":"# Transforming categorical features to numerical values\ndata[\"smoker\"] = data[\"smoker\"].replace([\"yes\",\"no\"], [1,0])\ndata[\"sex\"] = data[\"sex\"].replace([\"male\",\"female\"], [1,0])\ndata[\"region_southeast\"] = data[\"region\"].apply(lambda x: 1 if x == \"southeast\" else 0)","1bcfe65a":"y_data = data[\"charges\"]\nx_data = data.drop([\"charges\",\"region\"], axis = 1)\npredicted_rk_cl = clf2.predict(x_data)\nx_data[\"risk_cluster\"] = predicted_rk_cl\nx_data[\"smoker\"] = x_data[\"smoker\"].replace([1,0], [\"yes\",\"no\"])\nx_data[\"sex\"] = x_data[\"sex\"].replace([1,0], [\"male\",\"female\"])\nx_data[\"risk_cluster\"] = x_data[\"risk_cluster\"].replace([0,1,2], [\"A\",\"B\",\"C\"])\nx_data = pd.get_dummies(x_data)","7c796b5a":"x_train, x_test, y_train ,y_test = train_test_split(x_data, y_data, test_size = 0.25,random_state=97)","d24fa855":"##### Model Instantiation\nreg = DecisionTreeRegressor(max_leaf_nodes = 7, random_state=525)\nmodel = reg.fit(x_train, y_train)\nprint(model)","11ff0255":"dot_data = tree.export_graphviz(model,\n                                out_file = None,\n                                feature_names = x_data.columns,\n                                class_names = 'MEDV',\n                                filled = True)\n\n# \u30c0\u30a4\u30a2\u30b0\u30e9\u30e0\u3092\u63cf\u753b\ngraph = pydotplus.graph_from_dot_data(dot_data)\n\n# \u30c0\u30a4\u30a2\u30b0\u30e9\u30e0\u3092\u8868\u793a\nImage(graph.create_png())","836445a6":"YHat = model.predict(x_test)","982c1559":"r2 = r2_score(y_test, YHat)\nprint(\"R^2 = \", r2)","b254f70f":"rg = RandomForestRegressor(n_jobs=-1, random_state=999)\n \nrg.fit(x_train, y_train)\nYHat2 = rg.predict(x_test)\nr2 = r2_score(y_test, YHat2)\nprint(\"R^2 = \", r2)","21b592a9":"model2 = CatBoostRegressor(\n        loss_function='RMSE',random_state=2525)\n\nparam_grid = {'depth': [4, 7, 10],\n         'learning_rate' : [0.01, 0.1, 0.15],\n         'l2_leaf_reg': [1,4,9],\n         'iterations': [300]}\n\ngrid_result = GridSearchCV(estimator = model2,\n                           param_grid = param_grid,\n                           scoring = 'r2',\n                           cv = 4,\n                           verbose=3,\n                           return_train_score = True)\ngrid_result.fit(x_train, y_train)","87bcac1a":"print(grid_result.best_params_)","0fd75b8f":"print(grid_result.best_score_)","933743e5":"best = grid_result.best_estimator_\npred = best.predict(x_test)","c3c6b4bb":"r2 = r2_score(y_test, pred)\nprint(\"R^2 = \", r2)","f96dd06d":"best.feature_importances_","2e6ec367":"FI = pd.DataFrame(best.feature_importances_)\nFI.index = x_train.columns\nFI.columns = ['Feature_Importance']\nFI.plot(kind='bar')","ca9ff331":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error","625a170d":"# Model is trained and then used on test dataset\nmodel1 = LinearRegression()\nmodel1.fit(x_train, y_train)\ny_pred = model1.predict(x_test)\n\n# Coefficients and intercept of linear regression model extracted\nmodel_coef = pd.DataFrame(data = model1.coef_, index = x_test.columns)\nmodel_coef.loc[\"intercept\", 0] = model1.intercept_ \ndisplay(model_coef)\n\n# Model's performance\nmodel_performance = pd.DataFrame(data = [r2_score(y_test, y_pred), np.sqrt(mean_squared_error(y_test, y_pred))],\n                                 index = [\"R2\",\"RMSE\"])\ndisplay(model_performance)","85fc7e72":"residual = y_test - y_pred\n# Positive residual means that the actual charge > predicted charge\n# Negative residual means that the actual charge < predicted charge\nplt.scatter(y_test, residual)\nplt.title(\"Residual vs actual charges\")\nplt.xlabel(\"Actual charges\")\nplt.ylabel(\"Residual\")","be55f8c0":"### You can't differentiate by the number of children in the family\nAs you can see in the figure below, the number of children in a family is not differentiated by the number of children.\nAs you can see in the figure below, having more children is more likely to result in lower smoking rates than in lower payments, However, there is no data to verify this.","90dfa04d":"## Correlation between features","7e4c18bb":"### The relationship between insurance claim amounts and age.","9a5181fa":"Clustering labels are given as A, B, C for convenience, since they occur randomly.","6e29b8b6":"If you look at the breakdown of smoker_cluster, you can see that the risk-layer where there are smoker include cluster 1, where smokers and non-smokers are neatly separated, cluster 0, where there are only non-smokers, and cluster 2, where there is a mixture of the two.","bbb3be15":"## Linear Regression Model","0e86fda4":"Compared to other feature, smoking is a major factor. Just being a smoker can increase your rates by about 25,000 yen, regardless of your age.","31db2c8f":"It is difficult to analyze qualitative data in graphical form, so categorical variables are quantified.","a64a245f":"Male are more at risk than Female.","164e9b1e":"### I'm going to try clustering the three layers of the scatterplot for charges into groups, and using regression to predict the samples that belong to those groups.","0286459a":"## Charges by smoker and number of children\nWhen you have four or more children, both the amount of insurance claims and the smoking rate go down, but this is probably because the smoking rate is going down, so the amount of insurance claims is also going down.","7ed15e16":"As shown in the figure below, we can see that the group of high-risk payers raises the amount of the main payment.\nThe coefficients for the rest of the groups are negative, indicating that improving the health of smokers and high-risk members of the group will reduce the amount of the payment. In this data, the coefficient for women is positive and that for men is negative, which is not true. There may be some bias in the data, but since the value is not important, I will ignore it this time.","0b0a49df":"# Modelling","391b5782":"Trying to predict in earnest. I used CatBoost\nand GridSearchCV to try to find the best model.","78d574bf":"## Charges by smoker and Risk_Cluster","49092340":"Smokers are generally charged much higher rates; rates above 30000 are usually from smokers, and below 15000 are generally non-smokers. Anything in between could be smokers or non-smokers.","f9fac333":"### Plot the relationship of Charges by gender ratio.","daf2be3d":"In terms of gender, males seem to be paying more in all regions.","88a2295d":"If you look at the box-plot, you can see that the clustering of Charges is nicely separated among high-risk and low-risk even in a normal scatter plot.","f8731219":"### Just plotting the relationship between BMI and the amount of insurance claims doesn't seem to correlate with anything.","875874ad":"#### I got the data from this notebook and used it as a reference.\nhttps:\/\/www.kaggle.com\/brandonyongys\/insurance-charges\/data","8f7e8ad1":"### There are no missing values, so we don't need to fill in the missing values, but there are number variables and categorical variables, so we need to encode them to run the regression.","aaf8aa54":"In clustering, smokers, nonsmokers, and in-between are shifted to categorical variables and divided into three characteristically illustrated by seaborn.","e2b901c5":"For now, divide the data into 1000 training data and 336 test data.","39b0676d":"After 1000 cases were used as test data.","6c15b073":"In this case, we clustered smokers, non-smokers, and the middle class, but I feel that we can get good results if we create a classifier that predicts high-risk smokers with positive coefficients in the classification and do feature engineering, as we saw in the linear regression.","138ad05a":"### The figure below shows that there are non-smokers, smokers, and in-between, and the higher the amount of insurance claims, the more smoking.\nAs shown above, there is a three-tiered structure, and I think there is a hidden feature here.\nSpecifically, the smokers' layer, the non-smokers' layer, and the middle layer.","9ca0c4ea":"The is no correlation between the different numerical features. ","e9e4721b":"## Charges by age and smoker","d84bbd47":"There seems to be a fee threshold. Smokers, regardless of the number of children they have, generally charge a minimum of 15,000 yen, while non-smokers charge a maximum of 20,000 yen (generally less than 15,000 yen).\n\nSmokers are definitely an important feature to be aware of when modeling.","5046b6bd":"# Basic data information","fb130352":"# Exploratory Data Analysis","41c1a768":"For now, I used the decision tree to examine the importance. We found that the smokers group had a higher risk and the importance of the indicator was also higher.","2c0cf85a":"### Check the table for regional differences and there are no differences.\nAs the poster mentioned earlier, Southeast seems to have a slightly higher payment, but it's only a small difference.","da85102b":"### The bottom part seems to be not well classified, but let's proceed with this. I used the K-means method this time, and tried DBSCAN, but it didn't cluster well.\n","90477c02":"### I wanted to see the importance, so I used a decision tree to structure the tree first.","d94500a9":"### The tendency is divided by smoking status, but among smokers, there are two varicose veins, which is expected to be a hidden factor.","03a43c61":"## There doesn't seem to be that much of a relationship between BMI and the amount of insurance claims.","88c967d5":"## Pre-processing","bb28063a":"## Charges by region and sex","d130ec9a":"Some of the outliers in the residuals are large, which is worrisome, but most of the samples have residuals near zero, so I feel that data cleansing will yield better results.","ca77b205":"The category variable was made a dummy variable with one-hot encoding.","6a0e5687":"To classify and predict smoker_clusters, I used RandomForestClassifier to test the accuracy. The accuracy was roughly 0.8 to 0.9."}}