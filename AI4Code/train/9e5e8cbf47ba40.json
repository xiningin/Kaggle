{"cell_type":{"53dcf8f0":"code","9a6ceadf":"code","9b5f22e4":"code","28b8f3d0":"code","8433defa":"code","b863af39":"code","6dde02a9":"markdown","5d0c5766":"markdown","dd93cff0":"markdown","61cfa820":"markdown","25753688":"markdown","c34a38c3":"markdown","e290b6cf":"markdown","6c6e2163":"markdown","94dd5fbc":"markdown"},"source":{"53dcf8f0":"import pandas as pd\nimport matplotlib.pyplot  as plt\n \ndef parser(x):\n\treturn pd.datetime.strptime('190'+x, '%Y-%m')\n \nseries = pd.read_csv('..\/input\/shampoo-saled-dataset\/shampoo_sales.csv', \n                     header=0, parse_dates=[0], index_col=0, \n                     squeeze=True, date_parser=parser)\nprint(series.head())\nseries.plot()\nplt.show()","9a6ceadf":"from pandas.plotting import autocorrelation_plot\n\nautocorrelation_plot(series)\nplt.show()","9b5f22e4":"# importing arima library\nfrom statsmodels.tsa.arima_model import ARIMA\n\n\nmodel = ARIMA(series, order=(5,1,0))\nmodel_fit = model.fit(disp=0)\nprint(model_fit.summary())\n\n# plot residual errors\nresiduals = pd.DataFrame(model_fit.resid)\nresiduals.plot()\nplt.title('ARMA Fit Residual Error Line Plot')\nplt.xlabel('Months')\nplt.ylabel('Residual Error')\nplt.show()","28b8f3d0":"residuals.plot(kind='kde')\nplt.title('ARMA Fit Residual Error Density Plot')\nplt.xlabel('Residual Values')\nplt.grid()\nplt.show()\nprint(residuals.describe())","8433defa":"from sklearn.metrics import mean_squared_error\n \n\nX = series.values\nsize = int(len(X) * 0.66)\n\n\ntrain, test = X[0:size], X[size:len(X)]\nhistory = [x for x in train]\npredictions = []\n\n\nfor t in range(len(test)):\n\tmodel = ARIMA(history, order=(5,1,0))\n\tmodel_fit = model.fit(disp=0)\n\toutput = model_fit.forecast()\n\tyhat = output[0]\n\tpredictions.append(yhat)\n\tobs = test[t]\n\thistory.append(obs)\n\tprint('predicted=%f, expected=%f' % (yhat, obs))\n    \n\n\n\n\n# plot\nplt.plot(test, label = 'original sales', marker = '*')\nplt.plot(predictions, color='red', label = 'predicted sales', marker = '*')\nplt.title('Performance Evaluation')\nplt.xlabel('Future Steps')\nplt.ylabel('Sales')\nplt.legend()\nplt.show()","b863af39":"import math\nerror = mean_squared_error(test, predictions)\nprint('Test Root Mean Squared Error: %.3f' % math.sqrt(error))","6dde02a9":"Running the example, we can see that there is a positive correlation with the first 10-to-12 lags that is perhaps significant for the first 5 lags. A good starting point for the AR parameter of the model may be 5.\n\n## ARIMA with Python\nThe statsmodels library provides the capability to fit an ARIMA model. An ARIMA model can be created using the statsmodels library as follows:\n\n- Define the model by calling <font color = \"blue\"> ARIMA() <\/font> and passing in the p, d, and q parameters.\n- The model is prepared on the training data by calling the <font color = \"blue\"> fit()  <\/font>function.\n- Predictions can be made by calling the <font color = \"blue\"> predict()  <\/font> function and specifying the index of the time or times to be predicted.\n\nLet\u2019s start off with something simple. We will fit an ARIMA model to the entire Shampoo Sales dataset and review the residual errors.\n\nFirst, we fit an <font color = \"blue\"> ARIMA(5,1,0) model. <\/font> This sets the lag value to 5 for autoregression, uses a difference order of 1 to make the time series stationary, and uses a moving average model of 0.\n\n**When fitting the model, a lot of debug information is provided about the fit of the linear regression model. We can turn this off by setting the disp argument to 0.**","5d0c5766":"The distribution of the residual errors is displayed above. The results show that indeed there is a bias in the prediction (a non-zero mean in the residuals). Note, that although above we used the entire dataset for time series analysis, ideally we would perform this analysis on just the training dataset when developing a predictive model. \n\nNext, let\u2019s look at how we can use the ARIMA model to make forecasts.","dd93cff0":"### Mean Squared Error (MSE)","61cfa820":"## Rolling Forecast ARIMA Model\nThe ARIMA model can be used to forecast future time steps.\n\nWe can use the <font color=\"blue\"> predict() <\/font> function on the ARIMAResults object to make predictions. It accepts the index of the time steps to make predictions as arguments. These indexes are relative to the start of the training dataset used to make predictions.\n\nIf we used 100 observations in the training dataset to fit the model, then the index of the next time step for making a prediction would be specified to the prediction function as start=101, end=101. This would return an array with one element containing the prediction.\n\nWe also would prefer the forecasted values to be in the original scale, in case we performed any differencing (d>0 when configuring the model). This can be specified by setting the typ argument to the value \u2018levels\u2019: typ=\u2019levels\u2019.\n\nAlternately, we can avoid all of these specifications by using the forecast() function, which performs a one-step forecast using the model.\n\nWe can split the training dataset into train and test sets, use the train set to fit the model, and generate a prediction for each element on the test set.\n\nA rolling forecast is required given the dependence on observations in prior time steps for differencing and the AR model. A crude way to perform this rolling forecast is to re-create the ARIMA model after each new observation is received.\n\nWe manually keep track of all observations in a list called history that is seeded with the training data and to which new observations are appended each iteration.\n\nPutting this all together, below is an example of a rolling forecast with the ARIMA model in Python.","25753688":"In the figure above, we get a line plot of the residual errors, suggesting that there may still be some trend information not captured by the model.\n\nIn the next figure, we get a density plot of the residual error values, suggesting the errors are Gaussian, but may not be centered on zero.","c34a38c3":"## Autoregressive Integrated Moving Average Model\nAn **ARIMA** model is a class of statistical models for analyzing and forecasting time series data. It explicitly caters to a suite of standard structures in time series data, and as such provides a simple yet powerful method for making skillful time series forecasts.\n\nARIMA is an acronym that stands for <font color=\"blue\">**AutoRegressive Integrated Moving Average.**<\/font>  It is a generalization of the simpler AutoRegressive Moving Average and adds the notion of integration.\n\nThis acronym is descriptive, capturing the key aspects of the model itself. Briefly, they are:\n\n- <font color = \"blue\">**AR : Autoregression.**<\/font> A model that uses the dependent relationship between an observation and some number of lagged observations.\n- <font color = \"blue\">**I: Integrated.**<\/font> The use of differencing of raw observations (e.g. subtracting an observation from an observation at the previous time step) in order to make the time series stationary.\n- <font color = \"blue\">**MA: Moving Average.**<\/font> A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.\n\nEach of these components are explicitly specified in the model as a parameter. A standard notation is used of <font color =\"blue\"> ARIMA(p,d,q)<\/font> where the parameters are substituted with integer values to quickly indicate the specific ARIMA model being used. The parameters of the ARIMA model are defined as follows:\n\n- <font color =\"blue\"> p: <\/font> The number of lag observations included in the model, also called the lag order.\n- <font color =\"blue\"> d: <\/font> The number of times that the raw observations are differenced, also called the degree of differencing.\n- <font color =\"blue\"> q: <\/font> The size of the moving average window, also called the order of moving average.\n\nA linear regression model is constructed including the specified number and type of terms, and the data is prepared by a degree of differencing in order to make it stationary, i.e. to remove trend and seasonal structures that negatively affect the regression model. A value of 0 can be used for a parameter, which indicates to not use that element of the model. This way, the ARIMA model can be configured to perform the function of an ARMA model, and even a simple AR, I, or MA model.\n\nAdopting an ARIMA model for a time series assumes that the underlying process that generated the observations is an ARIMA process. This may seem obvious, but helps to motivate the need to confirm the assumptions of the model in the raw observations and in the residual errors of forecasts from the model. Next, let\u2019s take a look at how we can use the ARIMA model in Python. We will start with loading a simple univariate time series.\n\nHow to Create an ARIMA Model for Time Series Forecasting in Python\nby Jason Brownlee on January 9, 2017 in Time Series\nTweet  Share\nLast Updated on August 19, 2020\n\nA popular and widely used statistical method for time series forecasting is the ARIMA model.\n\nARIMA is an acronym that stands for AutoRegressive Integrated Moving Average. It is a class of model that captures a suite of different standard temporal structures in time series data.\n\nIn this tutorial, you will discover how to develop an ARIMA model for time series forecasting in Python.\n\nAfter completing this tutorial, you will know:\n\nAbout the ARIMA model the parameters used and assumptions made by the model.\nHow to fit an ARIMA model to data and use it to make forecasts.\nHow to configure the ARIMA model on your time series problem.\nKick-start your project with my new book Time Series Forecasting With Python, including step-by-step tutorials and the Python source code files for all examples.\n\nLet\u2019s get started.\n\nUpdated Apr\/2019: Updated the link to dataset.\nUpdated Sept\/2019: Updated examples to use latest API.\nAutoregressive Integrated Moving Average Model\nAn ARIMA model is a class of statistical models for analyzing and forecasting time series data.\n\nIt explicitly caters to a suite of standard structures in time series data, and as such provides a simple yet powerful method for making skillful time series forecasts.\n\nARIMA is an acronym that stands for AutoRegressive Integrated Moving Average. It is a generalization of the simpler AutoRegressive Moving Average and adds the notion of integration.\n\nThis acronym is descriptive, capturing the key aspects of the model itself. Briefly, they are:\n\nAR: Autoregression. A model that uses the dependent relationship between an observation and some number of lagged observations.\nI: Integrated. The use of differencing of raw observations (e.g. subtracting an observation from an observation at the previous time step) in order to make the time series stationary.\nMA: Moving Average. A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.\nEach of these components are explicitly specified in the model as a parameter. A standard notation is used of ARIMA(p,d,q) where the parameters are substituted with integer values to quickly indicate the specific ARIMA model being used.\n\nThe parameters of the ARIMA model are defined as follows:\n\np: The number of lag observations included in the model, also called the lag order.\nd: The number of times that the raw observations are differenced, also called the degree of differencing.\nq: The size of the moving average window, also called the order of moving average.\nA linear regression model is constructed including the specified number and type of terms, and the data is prepared by a degree of differencing in order to make it stationary, i.e. to remove trend and seasonal structures that negatively affect the regression model.\n\nA value of 0 can be used for a parameter, which indicates to not use that element of the model. This way, the ARIMA model can be configured to perform the function of an ARMA model, and even a simple AR, I, or MA model.\n\nAdopting an ARIMA model for a time series assumes that the underlying process that generated the observations is an ARIMA process. This may seem obvious, but helps to motivate the need to confirm the assumptions of the model in the raw observations and in the residual errors of forecasts from the model.\n\nNext, let\u2019s take a look at how we can use the ARIMA model in Python. We will start with loading a simple univariate time series.\n\n\n## Shampoo Sales Dataset\nThis dataset describes the monthly number of sales of shampoo over a 3 year period. The units are a sales count and there are 36 observations. The original dataset is credited to Makridakis, Wheelwright, and Hyndman (1998). Below is an example of loading the Shampoo Sales dataset with Pandas with a custom function to parse the date-time field. The dataset is baselined in an arbitrary year, in this case 1900.","e290b6cf":"A popular and widely used statistical method for time series forecasting is the **ARIMA model.** **ARIMA** is an acronym that stands for <font color=\"blue\">**AutoRegressive Integrated Moving Average.**<\/font> It is a class of model that captures a suite of different standard temporal structures in time series data.\n\nIn this notebook, you will discover how to develop an ARIMA model for time series forecasting in Python. After completing this tutorial, you will know:\n* About the ARIMA model the parameters used and assumptions made by the model.\n* How to fit an ARIMA model to data and use it to make forecasts.\n* How to configure the ARIMA model on your time series problem.\n\n\nI you found this notebook help you, please do <font color =\"red\"> UPVOTE. <\/font>","6c6e2163":"## Summary of Configuring an ARIMA Model\nThe classical approach for fitting an ARIMA model is to follow the [Box-Jenkins Methodology.](https:\/\/en.wikipedia.org\/wiki\/Box%E2%80%93Jenkins_method)\n\nThis is a process that uses time series analysis and diagnostics to discover good parameters for the ARIMA model.\n\nIn summary, the steps of this process are as follows:\n\n1. <font color=\"blue\"> Model Identification.<\/font> Use plots and summary statistics to identify trends, seasonality, and autoregression elements to get an idea of the amount of differencing and the size of the lag that will be required.\n2. <font color = \"blue\"> Parameter Estimation. <\/font> Use a fitting procedure to find the coefficients of the regression model.\n3. <font color = \"blue\"> Model Checking.<\/font> Use plots and statistical tests of the residual errors to determine the amount and type of temporal structure not captured by the model.\n\nThe process is repeated until either a desirable level of fit is achieved on the in-sample or out-of-sample observations (e.g. training or test datasets).","94dd5fbc":"We can see that the Shampoo Sales dataset has a clear trend.\n\nThis suggests that the time series is not stationary and will require differencing to make it stationary, at least a difference order of 1. Let\u2019s also take a quick look at an autocorrelation plot of the time series. This is also built-in to Pandas. The example below plots the autocorrelation for a large number of lags in the time series."}}