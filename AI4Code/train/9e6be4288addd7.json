{"cell_type":{"a1d64084":"code","1e4d75fb":"code","19995277":"code","9bcb0e4d":"code","10cc904b":"code","cf52ad83":"code","dc2fca60":"code","6d425c35":"code","627223c2":"code","15966db5":"code","b2c71f9b":"code","aa99068f":"code","6aa104a2":"code","d78ac406":"code","1140eb69":"code","13b4dd02":"code","de30434c":"code","8cb98f09":"code","94be6231":"code","d10bce8d":"code","994d4d72":"code","365cdfe5":"code","7964306e":"code","d06612a2":"code","b2e5143d":"code","3b3574ce":"code","88d9b0f6":"code","5b501149":"code","e73309ce":"code","ee5410ea":"markdown"},"source":{"a1d64084":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","1e4d75fb":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()","19995277":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","9bcb0e4d":"survived_train = train.Survived\ndata = pd.concat([train.drop(['Survived'],axis=1), test])","10cc904b":"#data.describe()\ndata.info()","cf52ad83":"from sklearn.preprocessing import LabelEncoder\ndata['Sex'] = LabelEncoder().fit_transform(data['Sex'])","dc2fca60":"#split titles from names and set it as feature\ndata['Name'] = data['Name'].map(lambda x: x.split(',')[1].split('.')[0].strip())\ntitles = data['Name'].unique()\ntitles","6d425c35":"data['Age'].fillna(-1, inplace=True)\n\nmedians = dict()\nfor title in titles:\n    median = data.Age[(data[\"Age\"] != -1) & (data['Name'] == title)].median()\n    medians[title] = median\n    \nfor index, row in data.iterrows():\n    if row['Age'] == -1:\n        data.loc[index, 'Age'] = medians[row['Name']]\n\ndata.info()","627223c2":"#transform the titles to numeric values, such that the magnitude has some relation with the survival\nreplacement = {\n    'Don': 0,\n    'Rev': 0,\n    'Jonkheer': 0,\n    'Capt': 0,\n    'Mr': 1,\n    'Dr': 2,\n    'Col': 3,\n    'Major': 3,\n    'Master': 4,\n    'Miss': 5,\n    'Mrs': 6,\n    'Mme': 7,\n    'Ms': 7,\n    'Mlle': 7,\n    'Sir': 7,\n    'Lady': 7,\n    'the Countess': 7\n}\n\ndata['Name'] = data['Name'].apply(lambda x: replacement.get(x))\n\nfrom sklearn.preprocessing import StandardScaler\ndata['Name'] = StandardScaler().fit_transform(data['Name'].values.reshape(-1, 1))","15966db5":"data['Age'] = StandardScaler().fit_transform(data['Age'].values.reshape(-1, 1))","b2c71f9b":"# similarly calculate missing fares and fill with median\ndata['Fare'].fillna(-1, inplace=True)\nmedians = dict()\nfor pclass in data['Pclass'].unique():\n    median = data.Fare[(data[\"Fare\"] != -1) & (data['Pclass'] == pclass)].median()\n    medians[pclass] = median\nfor index, row in data.iterrows():\n    if row['Fare'] == -1:\n        data.loc[index, 'Fare'] = medians[row['Pclass']]\ndata['Fare'] = StandardScaler().fit_transform(data['Fare'].values.reshape(-1, 1))","aa99068f":"data['Pclass'] = StandardScaler().fit_transform(data['Pclass'].values.reshape(-1, 1))","6aa104a2":"# replace parch with numeric values for train data\nreplacement = {\n    6: 0,\n    4: 0,\n    5: 1,\n    0: 2,\n    2: 3,\n    1: 4,\n    3: 5\n}\ndata['Parch'] = data['Parch'].apply(lambda x: replacement.get(x))\ndata['Parch'] = StandardScaler().fit_transform(data['Parch'].values.reshape(-1, 1))","d78ac406":"data.drop('Ticket', axis=1, inplace=True)","1140eb69":"data['Embarked'].value_counts()","13b4dd02":"# replace emabrked with numeric values for train data\nreplacement = {\n    'S': 0,\n    'Q': 1,\n    'C': 2\n}\n\ndata['Embarked'] = data['Embarked'].apply(lambda x: replacement.get(x))\ndata['Embarked'] = StandardScaler().fit_transform(data['Embarked'].values.reshape(-1, 1))\ndata.head()['Embarked']","de30434c":"data['SibSp'].unique()","8cb98f09":"replacement = {\n    5: 0,\n    8: 0,\n    4: 1,\n    3: 2,\n    0: 3,\n    2: 4,\n    1: 5\n}\n\ndata['SibSp'] = data['SibSp'].apply(lambda x: replacement.get(x))\ndata['SibSp'] = StandardScaler().fit_transform(data['SibSp'].values.reshape(-1, 1))\ndata.head()['SibSp']","94be6231":"data['Cabin'].fillna('U', inplace=True)\ndata['Cabin'] = data['Cabin'].apply(lambda x: x[0])\ndata['Cabin'].unique()","d10bce8d":"# replace alphabets for cabin with numeric values for train DATA\nreplacement = {\n    'T': 0,\n    'U': 1,\n    'A': 2,\n    'G': 3,\n    'C': 4,\n    'F': 5,\n    'B': 6,\n    'E': 7,\n    'D': 8\n}\n\ndata['Cabin'] = data['Cabin'].apply(lambda x: replacement.get(x))\ndata['Cabin'] = StandardScaler().fit_transform(data['Cabin'].values.reshape(-1, 1))\ndata.head()['Cabin']","994d4d72":"data.head()","365cdfe5":"data.info()","7964306e":"data['Embarked'] = data['Embarked'].fillna(data.Embarked.median())\ndata['Parch'] = data['Parch'].fillna(data.Parch.median())\ndata['Name'] = data['Name'].fillna(data.Name.median())","d06612a2":"data.info()","b2e5143d":"# Split into test.train\ndata_train = data.iloc[:891]\ndata_test = data.iloc[891:]\n\n# Transform into arrays for scikit-learn\nX = data_train.values\ntest = data_test.values\ny = survived_train.values","3b3574ce":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)","88d9b0f6":"from sklearn.ensemble import RandomForestClassifier\nmodels = [\n    RandomForestClassifier(n_estimators=100)\n]\n\nfor model in models:\n    model.fit(X_train, y_train)\n    score = model.score(X_test, y_test)\n    print(score)\n    Y_pred = model.predict(test)\n    ","5b501149":"data_test.info()","e73309ce":"data_test['Survived'] = Y_pred\ndata_test[['PassengerId', 'Survived']].to_csv('usha_titanic_submission4.csv', index=False)","ee5410ea":"## Data Preprocessing"}}