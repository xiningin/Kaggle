{"cell_type":{"5ae7c06a":"code","6afd9d88":"code","de978359":"code","bf514242":"code","d4df09fe":"markdown","6b3c5df1":"markdown","6846654f":"markdown"},"source":{"5ae7c06a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\n\nimport os\nprint(os.listdir(\"..\/input\"))\ninputData=pd.read_csv(r\"..\/input\/BreadBasket_DMS.csv\")","6afd9d88":"mergedDateTime = inputData.Date +' '+inputData.Time\ninputData.index = (pd.to_datetime(mergedDateTime))\ninputData.drop([\"Time\",\"Date\",\"Transaction\"],axis=1,inplace=True)\ninputData.head()","de978359":"\nstartDate,endDate = \"2016-10\",\"2017-02\"\ntrainingData = inputData[startDate:endDate]\n# Group the data on hourly spans\ngroup = pd.DataFrame({\"ItemCount\":trainingData.groupby([trainingData.index.map(lambda t: t.hour),\"Item\"]).size()}).reset_index();\n\n# Now lets find the probabilities\n# Note this is an hourly probability - so we only consider items falling within\n# the hour period\nitemName = \"Coffee\"\ntrainItemProbability = group[group[\"Item\"] == itemName]\ntrainItemProbability.rename(index=int, columns={\"level_0\": \"Hour\"},inplace=True)\ntrainItemProbability.drop([\"Item\"],axis= 1,inplace=True)\ntotal = np.float(trainItemProbability[\"ItemCount\"].sum())  \ntrainItemProbability[\"ItemCount\"]=trainItemProbability[\"ItemCount\"].apply(lambda v:(v \/total))\n\n# Since the item span may not be in the 24 hours range,\n# we add in averages samples. This will ne done to testing data as well\n# Will help us keep sanity during testing\n\nhours = np.arange(0,24,1)\ntrainItemProbability24hrs = pd.DataFrame(0,index=hours,columns=trainItemProbability.columns.values)\ndef expand_to_24_hours(data24hrs,data):\n    for row in range(0,len(data)):\n        oneRow = data.iloc[row,:]\n        data24hrs.iloc[np.int(oneRow.Hour)] = oneRow\n    return data24hrs\ntrainItemProbability = expand_to_24_hours(trainItemProbability24hrs,trainItemProbability)\nx = trainItemProbability[\"Hour\"]\ny = trainItemProbability[\"ItemCount\"]\n\ndel total,group\n\n\ntestingData = inputData[endDate:]  \ngroup = pd.DataFrame({\"ItemCount\":testingData.groupby([testingData.index.map(lambda t: t.hour),\"Item\"]).size()}).reset_index();\n\ntestItemProbability = group[group[\"Item\"] == itemName]\ntestItemProbability.rename(index=int, columns={\"level_0\": \"Hour\"},inplace=True)\ntestItemProbability.drop([\"Item\"],axis= 1,inplace=True)\ntotal = np.float(testItemProbability[\"ItemCount\"].sum())  \ntestItemProbability[\"ItemCount\"]=testItemProbability[\"ItemCount\"].apply(lambda v:(v \/total))\n\n\n\nhours = np.arange(0,24,1) # This will be our new index\ntestItemProbability24hrs = pd.DataFrame(0,index=hours,columns=testItemProbability.columns.values)\ntestItemProbability = expand_to_24_hours(testItemProbability24hrs,testItemProbability)\n\nfig = plt.figure(figsize = (15,5))\nax = fig.gca()\nxTrain = trainItemProbability24hrs[\"Hour\"]\nyTrain = trainItemProbability24hrs[\"ItemCount\"]\nxTest = testItemProbability24hrs[\"Hour\"]\nyTest = testItemProbability24hrs[\"ItemCount\"]\nplt.scatter(xTrain,yTrain,label=\"Train\")\nplt.scatter(xTest,yTest,label=\"Test\")\nplt.legend()\nplt.xlabel('Time span',fontsize=10)\nplt.ylabel('Probability',fontsize=10)\nax.tick_params(labelsize=10)\nplt.title('Probability of {} sold during the day'.format(itemName),fontsize=20)\nplt.grid()\nplt.ioff()\nplt.show()\n\n","bf514242":"# Lets also select particular hour range for our predictions\nstartHour = 3\nendHour = 22\ncondition = np.logical_and((trainItemProbability24hrs.index >= startHour),(trainItemProbability24hrs.index <= endHour))\ntrainSamples = trainItemProbability24hrs[condition]\ncondition = np.logical_and((testItemProbability24hrs.index >= startHour),(testItemProbability24hrs.index <= endHour))\ntestSamples = testItemProbability24hrs[condition]\n# Naive \n\npredicted = trainSamples.copy();\npredicted[\"Naive\"] = trainSamples.ItemCount\nfig = plt.figure(figsize = (15,5))\nax = fig.gca()\nplt.scatter(trainSamples.index,trainSamples.ItemCount,label=\"Train\",c='r',marker='.')\nplt.scatter(testSamples.index,testSamples.ItemCount,label=\"Test\",c='g',marker='+')\nplt.scatter(predicted.index,predicted.ItemCount,label=\"Predicted\",c='b',marker='*')\nplt.legend()\nplt.xlabel('Time span',fontsize=10)\nplt.ylabel('Probability',fontsize=10)\nax.tick_params(labelsize=10)\nplt.title('Naive Forecast',fontsize=20)\nplt.grid()\nplt.ioff()\nplt.show()\n\nrms = sqrt(mean_squared_error(testSamples.ItemCount, predicted.Naive))\nprint(rms)\n\n# Simple Average\n\npredicted[\"Average\"] = trainSamples['ItemCount'].rolling(1).mean()\nfig = plt.figure(figsize = (15,5))\nax = fig.gca()\nplt.scatter(trainSamples.index,trainSamples.ItemCount,label=\"Train\",c='r',marker='.')\nplt.scatter(testSamples.index,testSamples.ItemCount,label=\"Test\",c='g',marker='+')\nplt.scatter(predicted.index,predicted.Average,label=\"Predicted\",c='b',marker='*')\nplt.legend()\nplt.xlabel('Time span',fontsize=10)\nplt.ylabel('Probability',fontsize=10)\nax.tick_params(labelsize=10)\nplt.title('Simple Average Forecast',fontsize=20)\nplt.grid()\nplt.ioff()\nplt.show()\n\nrms = sqrt(mean_squared_error(testSamples.ItemCount, predicted.Average))\nprint(rms)\n\n\n# Moving Average\n\npredicted[\"MAverage\"] = trainSamples['ItemCount'].rolling(4).mean()\n# Find nans and replace. Nans appear as we initialized a DataFrame with zeros\npredicted.fillna(0,inplace=True)\nfig = plt.figure(figsize = (15,5))\nax = fig.gca()\nplt.scatter(trainSamples.index,trainSamples.ItemCount,label=\"Train\",c='r',marker='.')\nplt.scatter(testSamples.index,testSamples.ItemCount,label=\"Test\",c='g',marker='+')\nplt.scatter(predicted.index,predicted.MAverage,label=\"Predicted\",c='b',marker='*')\nplt.legend()\nplt.xlabel('Time span',fontsize=10)\nplt.ylabel('Probability',fontsize=10)\nax.tick_params(labelsize=10)\nplt.title('Moving Average Forecast',fontsize=20)\nplt.grid()\nplt.ioff()\nplt.show()\n\nrms = sqrt(mean_squared_error(testSamples.ItemCount, predicted.MAverage))\nprint(rms)","d4df09fe":"# Probability Forecasting","6b3c5df1":"# Forecasting the probability of an item sold during the 24 span of day","6846654f":"# Group the data into one hourly bunches - Split into test and train sets"}}