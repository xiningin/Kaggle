{"cell_type":{"c94960bb":"code","e1eb3e2a":"code","d05d3da1":"code","08e6bf60":"code","9dce4f2e":"code","149dce2c":"code","7a0c480f":"code","b47883f6":"code","8a521c2e":"code","6fcd7ad4":"code","4f216e30":"code","1aa0748e":"code","8dc7dda4":"code","d9f12af8":"code","af822605":"code","19d2c345":"code","d5c03889":"code","71a01961":"code","c0e78128":"code","37a3eccf":"code","57146e2e":"code","8ba9d530":"code","120eb023":"markdown","1d689f57":"markdown","30a5b302":"markdown","2d29073d":"markdown","065589ef":"markdown"},"source":{"c94960bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e1eb3e2a":"import matplotlib.pyplot as plt\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype\n\ndf = pd.read_csv(\"..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv\")\ndf.head()","d05d3da1":"df.describe()","08e6bf60":"df.info()","9dce4f2e":"df.isnull().sum()","149dce2c":"df.shape","7a0c480f":"# populate list of numerical and categorical variables\nnum_list = []\ncat_list = []\n\nfor column in df:\n    if is_numeric_dtype(df[column]):\n        num_list.append(column)\n    elif is_string_dtype(df[column]):\n        cat_list.append(column)\n        \n\nprint(\"numeric:\", num_list)\nprint(\"categorical:\", cat_list)","b47883f6":"for column in df:\n    plt.figure(column, figsize = (5,5))\n    plt.title(column)\n    if is_numeric_dtype(df[column]):\n        df[column].plot(kind = 'hist')\n    elif is_string_dtype(df[column]):\n        # show only the TOP 10 value count in each categorical data\n        df[column].value_counts()[:10].plot(kind = 'bar')","8a521c2e":"# encoding categorical variable\nfrom sklearn.preprocessing import LabelEncoder\n\ndf['Gender'] = LabelEncoder().fit_transform(df[\"Gender\"])\ndf = df.drop(\"CustomerID\", axis = 1)","6fcd7ad4":"# data transformation - scikit learn scaler\n# note that data transformation model should be trained using train dataset only and then apply to both train and test set\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import RobustScaler\n\n\ndef data_scaler(scaler, var):\n    scaled_var = \"scaled_\" + var\n    model = scaler.fit(df[var].values.reshape(-1,1))\n    df[scaled_var] = model.transform(df[var].values.reshape(-1, 1))\n    \n    plt.figure(figsize = (5,5))\n    plt.title(scaled_var)\n    df[scaled_var].plot(kind = 'hist')\n    \n    plt.figure(figsize = (5,5))\n    plt.title(var)\n    df[var].plot(kind = 'hist')","4f216e30":"# transform data into the standard scale\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\n\nfor var in [\"Age\", \"Annual Income (k$)\",'Spending Score (1-100)']:\n    scaled_var = \"scaled_\" + var\n    model = scaler.fit(df[var].values.reshape(-1,1))\n    df[scaled_var] = model.transform(df[var].values.reshape(-1, 1))\n    \n    plt.figure(figsize = (5,5))\n    plt.title(scaled_var)\n    df[scaled_var].plot(kind = 'hist')","1aa0748e":"print(df.head())","8dc7dda4":"# 2D scatter plot\nimport seaborn as sns\ncolumns = [\"scaled_Age\",\"scaled_Annual Income (k$)\", \"scaled_Spending Score (1-100)\"]\nsns.pairplot(df[columns])","d9f12af8":"# 3D scatter plot\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.pyplot as plt\n\n\naxis_list = [\"scaled_Age\", \"scaled_Annual Income (k$)\",'scaled_Spending Score (1-100)']\nx, y, z = axis_list\n\nfig = plt.figure(figsize = (10,10))\nax = fig.add_subplot(projection = \"3d\")\nsc = ax.scatter(df[x], df[y], df[z], s = 60)\nax.set_xlabel(x)\nax.set_ylabel(y)\nax.set_zlabel(z)","af822605":"# 3D scatter plot with color\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.pyplot as plt\n\nfig = plt.figure(figsize=(16,16))\nvariables_list = [\"Gender\", \"scaled_Age\", \"scaled_Annual Income (k$)\",'scaled_Spending Score (1-100)']\n\nfor i in range(len(variables_list)):\n    axis_list = [\"Gender\", \"scaled_Age\", \"scaled_Annual Income (k$)\",'scaled_Spending Score (1-100)']\n    legend = variables_list[i]\n    axis_list.pop(i)\n    x, y, z = axis_list\n    \n    ax = fig.add_subplot(221 + i, projection='3d') # define the position of the 3D plot\n    sc = ax.scatter(df[x], df[y], df[z], s = 60, c = df[legend], label = variables_list[i])\n    ax.set_xlabel(x)\n    ax.set_ylabel(y)\n    ax.set_zlabel(z)\n    ax.legend()\n    ","19d2c345":"# Spending vs. Age\nX1 = df[[\"scaled_Age\", \"scaled_Spending Score (1-100)\"]].values\n\n# Spending vs. Annual Income\nX2 = df[[\"scaled_Annual Income (k$)\", \"scaled_Spending Score (1-100)\"]].values\n\n# Spending vs. Age vs. Annual Income\nX3 = df[[\"scaled_Age\", \"scaled_Annual Income (k$)\", \"scaled_Spending Score (1-100)\"]].values\n","d5c03889":"# define K means algorithm function that return inertia, label, centroids and silhouetee score\n\nfrom sklearn.cluster import KMeans\nfrom sklearn import metrics\n\ndef KMeans_Algorithm(dataset, n):\n    clustering_KMeans = KMeans(n_clusters= n,init='k-means++', max_iter=300, random_state=0, algorithm = \"elkan\")\n    clustering_KMeans.fit(dataset)\n    \n    # create data frame to store centroids\n    centroids  = clustering_KMeans.cluster_centers_\n    \n    # add cluster label for each data point\n    label = clustering_KMeans.labels_\n    df[\"label\"] = label\n    \n    # evaluation metrics for clustering - inertia and silhouette score\n    inertia = clustering_KMeans.inertia_\n    silhouette_score = metrics.silhouette_score(dataset, label)\n    \n    return inertia, label, centroids, silhouette_score","71a01961":"# Spending Score vs. Age by different numbers of clusters\nX1_inertia_values = []\nX1_silhouette_scores = []\nfig1 = plt.figure(figsize=(20,20))\nfor i in range (2,11):\n    X1_inertia, X1_label, X1_centroids, X1_silhouette = KMeans_Algorithm(X1, i)\n    X1_inertia_values.append(X1_inertia)\n    X1_silhouette_scores.append(X1_silhouette)\n    centroids_df = pd.DataFrame(X1_centroids, columns =['X', 'Y'])\n    \n    sub = fig1.add_subplot(330 + i - 1)\n    sub.scatter(df[\"scaled_Age\"], df[\"scaled_Spending Score (1-100)\"], s = 60, c = df[\"label\"], cmap = \"RdBu\")\n    sub.scatter(centroids_df['X'], centroids_df['Y'], s = 90, marker= \",\", color = \"r\")\n    sub.set_xlabel(\"Age\")\n    sub.set_ylabel(\"Spending Score (1-100)\")\n    \n\n# plot inertia values against number of clusters\nplt.figure(figsize = (10 ,6))\nplt.plot(np.arange(2,11) , X1_inertia_values )\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"Inertia Values\")\n\n# plot silhouette scores against number of clusters\nplt.figure(figsize=(10,6))\nplt.plot(np.arange(2,11), X1_silhouette_scores)\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"Silhouette Score\")\n    ","c0e78128":"# Spending Score vs. Annual Income by different numbers of clusters\nX2_inertia_values = []\nX2_silhouette_scores = []\nfig2 = plt.figure(figsize=(20,20))\nfor i in range (2,11):\n    X2_inertia, X2_label, X2_centroids, X2_silhouette  = KMeans_Algorithm(X2, i)\n    X2_inertia_values.append(X2_inertia)\n    X2_silhouette_scores.append(X2_silhouette)\n    centroids_df = pd.DataFrame(X2_centroids, columns =['X', 'Y'])\n    sub = fig2.add_subplot(330 + i - 1)\n    sub.scatter(df[\"scaled_Annual Income (k$)\"], df[\"scaled_Spending Score (1-100)\"], s = 60, c = df[\"label\"], cmap = \"RdBu\")\n    sub.scatter(centroids_df['X'], centroids_df['Y'], s = 90, marker= \",\", color = \"r\")\n    sub.set_xlabel(\"Annual Income (k$)\")\n    sub.set_ylabel(\"Spending Score (1-100)\")\n    \n\n# plot inertia values against number of clusters\nplt.figure(figsize = (10 ,6))\nplt.plot(np.arange(2, 11) , X2_inertia_values , '-')\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"Inertia Values\")\n\n# plot inertia values against number of clusters\nplt.figure(figsize=(10,6))\nplt.plot(np.arange(2,11) , X2_silhouette_scores, '-')\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"Silhouette Score\")","37a3eccf":"# Spending vs. Age vs. Annual Income by different number of clusters\nX3_inertia_values = []\nX3_silhouette_scores = []\nfig = plt.figure(figsize=(15,15))\nfor i in range (2,11):\n    X3_inertia, X3_label, X3_centroids, X3_silhouette = KMeans_Algorithm(X3, i)\n    X3_inertia_values.append(X3_inertia)\n    X3_silhouette_scores.append(X3_silhouette)\n    centroids_df = pd.DataFrame(X3_centroids, columns =['X', 'Y', 'Z'])\n    ax = fig.add_subplot(330 + i - 1, projection='3d')\n    ax.scatter(df[\"scaled_Age\"],df[\"scaled_Annual Income (k$)\"],df[\"scaled_Spending Score (1-100)\"], s = 30, c = df[\"label\"], cmap = \"RdBu\")\n    ax.scatter(centroids_df['X'], centroids_df['Y'], centroids_df['Z'], s = 90, marker= \",\", color = \"r\")\n    ax.set_xlabel(\"Age\")\n    ax.set_ylabel(\"Annual Income(k$)\")\n    ax.set_zlabel(\"Spending Score (1-100)\")\n    \n# plot inertia values against number of clusters\nplt.figure(11 , figsize = (15 ,6))\nplt.plot(np.arange(2 , 11) , X3_inertia_values , '-')\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"Inertia Values\")\n\n# plot inertia values against number of clusters\nplt.figure(12, figsize=(15,6))\nplt.plot(np.arange(2,11) , X3_silhouette_scores, '-')\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"Silhouette Score\")","57146e2e":"## DBSCAN clustering\n\nfrom sklearn.cluster import DBSCAN\nfrom sklearn import metrics\n\nsilhouette_score_list = []\neps_list = np.arange(0.05, 0.2, 0.02)\nprint(eps_list)\n\nfor i in eps_list:\n    j = i * 100\n    clustering_DBSCAN = DBSCAN(eps=i, min_samples=10).fit(X1)\n    label = clustering_DBSCAN.labels_\n    df[\"label\"] = label\n    score = metrics.silhouette_score(X1, clustering_DBSCAN.labels_)\n    silhouette_score_list.append(score)\n    plt.figure(j, figsize=(5,5))\n    plt.scatter(df[\"scaled_Age\"], df[\"scaled_Spending Score (1-100)\"], s = 60, c = df[\"label\"], cmap = \"RdBu\")\n\nplt.figure(figsize=(10,5))\nplt.plot(eps_list, silhouette_score_list, '-')","8ba9d530":"# Spending vs. Annual Income with original scale - five clusters\n\nX2_inertia, X2_label, X2_centroids, X2_silhouette  = KMeans_Algorithm(X2, 5)\nX2_inertia_values.append(X2_inertia)\nX2_silhouette_scores.append(X2_silhouette)\nplt.figure(figsize = (8,8))\nplt.scatter(df[\"Annual Income (k$)\"], df[\"Spending Score (1-100)\"], s = 60, c = df[\"label\"], cmap = \"RdYlBu\")\nplt.xlabel(\"Annual Income (k$)\")\nplt.ylabel(\"Spending Score (1-100)\")","120eb023":"# Data Preprocessing\n* data transformation through scaling and standardization\n* categorical data encoding","1d689f57":"# DBSCAN Comparison","30a5b302":"# Exploratory Data Analysis","2d29073d":"# K Means Clustering","065589ef":"![Clustering Algorithm Infographics](https:\/\/miro.medium.com\/max\/1400\/1*xCKGM7tUzoR53oFv4yTPWA.png)  \nThis notebook provides a step by step guide to implement Clustering Algorithms for Customer Segmentation. Please visit [Clustering Algorithm for Customer Segmentation](https:\/\/towardsdatascience.com\/clustering-algorithm-for-customer-segmentation-e2d79e28cbc3) for detailed walkthrough."}}