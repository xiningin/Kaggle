{"cell_type":{"d077bd29":"code","42bc7f46":"code","bb2b190f":"code","4cdc0e9a":"code","e8bce16c":"code","7e5f7023":"code","073b2611":"code","184ad1d4":"code","71a06caa":"code","8c3dd41b":"code","09469d67":"code","d72b6a73":"code","fa17fdd2":"code","a6d178cf":"code","b3561007":"code","c997d636":"code","01f50ea3":"code","e62286a8":"code","1f24138e":"code","9bf946e0":"code","19e3ae1f":"code","b30d1b2b":"code","0012f2b9":"code","a764f160":"code","653f3cee":"markdown","15069e21":"markdown","e6d4a148":"markdown","3352fa60":"markdown","8b3fae52":"markdown","7f03b2e8":"markdown","21fa2f59":"markdown","aab2f5a1":"markdown","b39ec16e":"markdown"},"source":{"d077bd29":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\nINPUT_PATH = '\/kaggle\/input'\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","42bc7f46":"import cv2\n# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.datasets import mnist\nimport tensorflow_hub as hub\n\nfrom tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, GlobalAveragePooling2D\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, plot_roc_curve, roc_curve, auc, roc_auc_score\nfrom scipy import interp\nfrom itertools import cycle\nimport matplotlib.pyplot as plt\nimport timeit\n\n%matplotlib inline\n\nimport gc","bb2b190f":"device_name = tf.test.gpu_device_name()\navail_gpu = True\nif \"GPU\" not in device_name:\n    avail_gpu = False\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))\n\ninput_data_path = os.path.join(INPUT_PATH, 'diabetic-retinopathy-resized')\ntest_data = os.path.join(input_data_path, 'resized_train', 'resized_train')\ntest_cropped_data = os.path.join(input_data_path, 'resized_train_cropped','resized_train_cropped')\nprint(test_cropped_data)","4cdc0e9a":"# load pretrained model - deprecated\ndef load_pretrained(weight='imagenet', include_top=False):\n    mobileNetModel = MobileNet(weights=weight, include_top=include_top)\n    model = Sequential()\n    model.add(mobileNetModel)\n    if not include_top:\n        model.add(GlobalAveragePooling2D())\n        model.add(Dense(5, activation='softmax'))\n    model.summary()\n    return model","e8bce16c":"# functions\n\ndef stratified_sampling(data, n_sample=None, stratify=None, random_state=None):\n    if not n_sample or not stratify:\n        return\n    str_sampled_data = data.groupby(stratify, group_keys=False).apply(lambda x: x.sample(int(np.rint(n_sample*len(x)\/len(data))), random_state=random_state)).sample(frac=1).reset_index(drop=True)\n    return str_sampled_data.reset_index(drop=True)\n\ndef data_loader(data, stratify=None, downsampling=False, upsampling=False):\n    if stratify == None:\n        train, test = train_test_split(data, test_size=0.3)\n    else:\n        train, test = train_test_split(data, test_size=0.3, stratify=data[stratify])\n    if downsampling:\n        min_cnt = min(train[stratify].value_counts())\n        train = train.groupby(stratify, group_keys=False).apply(lambda x: x.sample(min_cnt)).sample(frac=1).reset_index(drop=True)\n    if upsampling:\n        max_cnt = max(train[stratify].value_counts())\n        train = train.groupby(stratify, group_keys=False).apply(lambda x: x.sample(max_cnt, replace=True)).sample(frac=1).reset_index(drop=True)\n    train[['level']].hist(figsize=(15, 15))\n    return train, test\n    \ndef micro_f1(y_true, y_pred):\n    y_true = np.array([np.argmax(p) for p in y_true]).reshape(-1, 1)\n    y_pred = np.array([np.argmax(p) for p in y_pred]).reshape(-1, 1)\n    return f1_score(y_true, y_pred, average='micro')\n\ndef get_steps(num_samples, batch_size):\n    if (num_samples % batch_size) > 0:\n        return (num_samples \/\/ batch_size) + 1\n    else:\n        return num_samples \/\/ batch_size\n\ndef img2vec(path, names, image_size = None):\n    vecs = []\n    for name in names:\n        img = cv2.cvtColor(cv2.imread(os.path.join(path, name+'.jpeg')), cv2.COLOR_BGR2RGB)\n        if image_size:\n            img = cv2.resize(img, image_size, interpolation = cv2.INTER_CUBIC)\n        vecs.append(img)\n    return np.array(vecs)\n\ndef stratified_sampling(data, n_sample=None, stratify=None, random_state=None):\n    if not n_sample or not stratify:\n        return\n    tmp_data = data.groupby(stratify, group_keys=False).apply(lambda x: x.sample(int(np.rint(n_sample*len(x)\/len(data))), random_state=random_state)).sample(frac=1).reset_index(drop=True)\n    return tmp_data\n\ndef process(df, path = '..\/input\/diabetic-retinopathy-resized\/resized_train_cropped\/resized_train_cropped', image_size=None):\n    feature_vec = img2vec(path, df['image'].values, image_size=image_size)\n    one_hot = pd.get_dummies(df['level'])\n    return feature_vec, one_hot\n\ndef model_train(model_loader, x_train, x_label, y_test, y_label, optimizer=None, loss=None, epochs=None, n_layer=0):\n    logs= []\n    for opt in optimizer:\n        for l in loss:\n            for e in epochs:\n                for i in range(n_layer):\n                    model = Sequential()\n                    model.add(model_loader(include_top=False))\n                    model.add(GlobalAveragePooling2D())\n                    model.add(Dense(5, activation='softmax'))\n                    for j in range(i+1):\n                        model.layers[j].trainable = True\n                    print(f'optimizer: {opt}, loss_fn:{l}, epochs: {e}, train_layer: {j}')\n                    model.compile(optimizer=opt, loss=l, metrics=['acc'])\n                    model.fit(x_train, x_label, epochs=e)\n                    prediction = model.predict(y_test)\n                    print(f'f1_score: {micro_f1(y_label, prediction)}')\n                    plot_multi_roc_curve(y_label, prediction)\n                    del model\n                    gc.collect()\n                    log = f'optimizer: {opt}, loss_fn:{l}, epochs: {e}, train_layer: {j}, micro_f1_score: {micro_f1(y_label, prediction)}'\n                    logs.append(log)\n    return logs\n\ndef plot_multi_roc_curve(y_true, y_pred):\n    n_classes = y_true.shape[1]\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    for i in range(5):\n        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n    # Compute micro-average ROC curve and ROC area\n    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_pred.ravel())\n    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n    # First aggregate all false positive rates\n    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n    # Then interpolate all ROC curves at this points\n    mean_tpr = np.zeros_like(all_fpr)\n    for i in range(n_classes):\n        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n    # Finally average it and compute AUC\n    mean_tpr \/= n_classes\n\n    fpr[\"macro\"] = all_fpr\n    tpr[\"macro\"] = mean_tpr\n    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n    lw = 5\n    # Plot all ROC curves\n    plt.figure()\n    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n             label='micro-average ROC curve (area = {0:0.2f})'\n                   ''.format(roc_auc[\"micro\"]),\n             color='deeppink', linestyle=':', linewidth=4)\n\n    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n             label='macro-average ROC curve (area = {0:0.2f})'\n                   ''.format(roc_auc[\"macro\"]),\n             color='navy', linestyle=':', linewidth=4)\n\n    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n    for i, color in zip(range(n_classes), colors):\n        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n                 label='ROC curve of class {0} (area = {1:0.2f})'\n                 ''.format(i, roc_auc[i]))\n\n    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Some extension of Receiver operating characteristic to multi-class')\n    plt.legend(loc=\"lower right\")\n    plt.show()","7e5f7023":"# Dataset \uc900\ube44\nlabels = pd.read_csv(os.path.join(input_data_path, 'trainLabels_cropped.csv'))\nlabels = labels.drop(columns=['Unnamed: 0', 'Unnamed: 0.1'])","073b2611":"random_df = stratified_sampling(labels, n_sample=10000, stratify='level', random_state=312)\ntrain, test = data_loader(random_df, stratify='level', downsampling=True)\nx_train, x_label = process(train, path=test_cropped_data, image_size = (224, 224))\ny_test, y_label = process(test, path=test_cropped_data, image_size = (224, 224))","184ad1d4":"model = load_pretrained(include_top=True)\nmodel.summary()","71a06caa":"del model\ngc.collect()","8c3dd41b":"model = load_pretrained()","09469d67":"no_train_prediction = model.predict(y_test)","d72b6a73":"no_train_prediction","fa17fdd2":"y_label.values","a6d178cf":"micro_f1(y_label.values, no_train_prediction)","b3561007":"optimizers = ['adam']\nloss_fn = ['categorical_crossentropy']\nepochs = [5, 30]\nwith tf.device('gpu:0'):\n    logs = model_train(MobileNet, x_train, x_label.values, y_test, y_label.values, optimizer=optimizers, loss=loss_fn, epochs=epochs, n_layer=3)","c997d636":"for log in logs:\n    print(log)","01f50ea3":"optimizers = ['adam']\nloss_fn = ['categorical_crossentropy']\nepochs = [10, 30]\nrandom_df = stratified_sampling(labels, n_sample=2000, stratify='level', random_state=312)\ntrain, test = data_loader(random_df, stratify='level', upsampling=True)\nx_train, x_label = process(train, path=test_cropped_data, image_size = (224, 224))\ny_test, y_label = process(test, path=test_cropped_data, image_size = (224, 224))","e62286a8":"with tf.device('gpu:0'):\n    logs = model_train(MobileNet, x_train, x_label.values, y_test, y_label.values, optimizer=optimizers, loss=loss_fn, epochs=epochs, n_layer=3)","1f24138e":"from tensorflow.keras.applications.inception_v3 import InceptionV3","9bf946e0":"random_df = stratified_sampling(labels, n_sample=10000, stratify='level', random_state=312)\ntrain, test = data_loader(random_df, stratify='level', downsampling=True)\nx_train, x_label = process(train, path=test_cropped_data, image_size = (299, 299))\ny_test, y_label = process(test, path=test_cropped_data, image_size = (299, 299))","19e3ae1f":"with tf.device('gpu:0'):\n    logs = model_train(InceptionV3, x_train, x_label.values, y_test, y_label.values, optimizer=optimizers, loss=loss_fn, epochs=epochs, n_layer=3)","b30d1b2b":"random_df = stratified_sampling(labels, n_sample=2000, stratify='level', random_state=312)\ntrain, test = data_loader(random_df, stratify='level', upsampling=True)\nx_train, x_label = process(train, path=test_cropped_data, image_size = (299, 299))\ny_test, y_label = process(test, path=test_cropped_data, image_size = (299, 299))","0012f2b9":"with tf.device('gpu:0'):\n    logs = model_train(InceptionV3, x_train, x_label.values, y_test, y_label.values, optimizer=optimizers, loss=loss_fn, epochs=epochs, n_layer=3)","a764f160":"print(logs)","653f3cee":"# \uae30\uc874 weight\ub97c \uadf8\ub300\ub85c \uc0ac\uc6a9","15069e21":"## Downsampling","e6d4a148":"# Upsampling","3352fa60":"## MobileNet\uc740 \ucd1d 1,000\uac1c\uc758 class\ub97c \uac00\uc9c0\uace0 \uc788\ub294 classifier\uac00\uc9c0\uace0 \uc788\uae30 \ub54c\ubb38\uc5d0 \n## \uae30\uc874\uc758 classifier\ub97c \ub54c\uc5b4\uc8fc\ub294 \uc791\uc5c5\uc774 \ud544\uc694\ud558\ub2e4.```include_top=False```","8b3fae52":"## Upsampling","7f03b2e8":"# MobileNet Model","21fa2f59":"# InceptionV3","aab2f5a1":"## Layer Trainable","b39ec16e":"## Downsampling"}}