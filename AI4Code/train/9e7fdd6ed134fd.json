{"cell_type":{"173a6233":"code","23b88789":"code","399acfd0":"code","c80c7439":"code","5ca73ffb":"code","6835454e":"code","3f5780b3":"code","48bd537b":"code","ac07d18a":"code","621382f5":"code","efc68d8a":"code","c6e0ef71":"markdown","e9ec8e2d":"markdown","0275aebb":"markdown","ccc57b6d":"markdown","81dbfddb":"markdown","299f71bf":"markdown","c0542394":"markdown","a940ad14":"markdown","322dc00b":"markdown","7d82a479":"markdown"},"source":{"173a6233":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pandas.api.types import is_numeric_dtype\n\nimport os\n\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\n\nimport sklearn\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score\n\nimport seaborn as sns\nimport scikitplot as skplt\nimport matplotlib.pyplot as plt","23b88789":"# Metaparameters\nVERBOSE = 0\nFOLDS = 10\ntest_train_split_SEED = 1971","399acfd0":"def  file_to_dataframe(file):\n    # this file is transposed of what we expect in a pandas dataframe\n    # therefore we import the file and transpose it\n    df = pd.read_csv(file,sep=\"\\t\",dtype=object,header=None, na_values='nd').T\n\n    # now we can set the header\n    header = df.iloc[0] #grab the first row for the header\n    df = df[1:] #take the data less the header row\n    df.columns = header #set the header row as the df header\n\n    return(df)\npd_abundance = file_to_dataframe('..\/input\/metagenomics\/abundance_stoolsubset.txt')","c80c7439":"disease = pd_abundance.loc[:,'disease'] \nd_name = pd_abundance.loc[:,'dataset_name'] \nprint(disease.value_counts())\n\n# list of diseases we want to analyze and predict\ndiseases = ['obesity', 'cirrhosis', 't2d', 'cancer']","5ca73ffb":"cols = pd_abundance.columns.tolist()\nspecies = [x for x in cols if x.startswith('k_')]\nmetadata = [x for x in cols if not x.startswith('k_')]\n\n\npd_abundance_conv = pd_abundance.copy()\npd_abundance_conv = pd_abundance_conv[species].astype('float64')\npd_abundance_conv = pd.concat([pd_abundance[metadata], pd_abundance_conv], axis = 1)\n\n# controls\/healthy samples from Human Microbiome Project coded 'hmp' and 'hmpii'. \n# 't2d' stands for Type 2 Diabetes. We will combine a few studies into single dataset.\ndata_sets = {'control':['hmp', 'hmpii'],'t2d':['WT2D','t2dmeta_long','t2dmeta_short'], 'cirrhosis' : ['Quin_gut_liver_cirrhosis'], \n             'cancer' : ['Zeller_fecal_colorectal_cancer'], 'obesity' : ['Chatelier_gut_obesity']}\n# combine controls from different studies into one\npd_abundance_conv['disease'] = pd_abundance_conv['disease'].apply(lambda x: 'control' if ((x == 'n') or (x == 'nd') or (x == 'leaness')) else x)\n\n# change some metadata variables to numeric\npd_abundance_conv['age'] = pd.to_numeric(pd_abundance_conv.age,  errors='coerce')\npd_abundance_conv['gender'] = pd_abundance_conv['gender'].astype('category').cat.codes\npd_abundance_conv['country'] = pd_abundance_conv['country'].astype('category').cat.codes\n\nfor col in metadata:\n    pd_abundance_conv[col] = pd.to_numeric(pd_abundance_conv[col],  errors='ignore')\n\nnumeric_metadata = [c for c in metadata if is_numeric_dtype(pd_abundance_conv[c]) ]\n\n# also add other features\n\n\n# separate controls and diseases into 2 dataframes\npd_control = pd_abundance_conv.loc[pd_abundance_conv['disease'] == 'control']\npd_disease = pd_abundance_conv.loc[pd_abundance_conv['disease'] != 'control']\n\n# we won't consider diseases from this list\nnot_disease = [d for d in pd_disease.disease.unique().tolist() if d not in diseases] \nfor d in not_disease:\n    pd_disease = pd_disease.drop(pd_disease.loc[pd_disease['disease'] == d].index, axis = 0)     \n\nSEED = 42\nd = 't2d'\nimport warnings\nwarnings.filterwarnings(\"ignore\")","6835454e":"def disease_prediction(d, species):\n    print('-' * 80)\n    print('Disease : %s'%d)\n    \n    skf = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = SEED)\n    oof_preds = []\n    oof_aucs = []\n    oof_scores= []\n    ds_names = data_sets[d]\n    if len(ds_names) == 1:\n        pd_cont = pd_control.loc[pd_control['dataset_name'] == ds_names[0]]\n        pd_dis = pd_disease.loc[pd_disease['dataset_name'] == ds_names[0]]\n    else:\n        pd_cont = pd_control.loc[pd_control['dataset_name'] == ds_names[0]]\n        pd_dis = pd_disease.loc[(pd_disease['disease'] == d) & (pd_disease['dataset_name'] == ds_names[0])]\n        for ds in ds_names[1:]:\n            pd_cont = pd.concat([pd_cont, pd_control.loc[pd_control['dataset_name'] == ds]], axis = 0)\n            pd_dis = pd.concat([pd_dis, pd_disease.loc[(pd_disease['disease'] == d) & (pd_disease['dataset_name'] == ds)]], axis = 0)\n                \n    #     create dataset with all other diseases, target set to 0\n    pd_others = pd_disease.loc[(pd_disease['disease'] != d)]\n    target_others = pd_others['disease'].apply(lambda x: 1 if x == d else 0)\n    \n    #     combine controls and this particular disease back into train dataset\n    pd_train = pd.concat([pd_cont, pd_dis], axis = 0)\n\n    #     adding control data from healthy subject, data by HMP\n    pd_train = pd.concat([pd_train, pd_control.loc[pd_control['dataset_name'] == 'hmp']], axis = 0)\n    pd_train = pd.concat([pd_train, pd_control.loc[pd_control['dataset_name'] == 'hmpii']], axis = 0)\n\n    target = pd_train['disease']\n    #     convert text target into binary\n    binary_target = target.apply(lambda x: 1 if x == d else 0)\n    # binary_target.value_counts()\n    pd_others = pd_others[species] \n    pd_train  = pd_train[species] \n    #     this split provides us with preserved test set\n    disease_train, disease_test, disease_y_train, disease_y_test = train_test_split(pd_train, binary_target, test_size = 0.10, \n#                                                                                     stratify = binary_target,\n                                                                                    random_state = test_train_split_SEED)   \n        \n    #     combining preserved test set with othere diseases samples\n    full_test = pd.concat([disease_test, pd_others])\n    full_y_test = pd.concat([disease_y_test, target_others])\n    \n    disease_y_test.value_counts()\n    disease_y_train.value_counts()\n    preds = np.zeros(disease_y_test.shape[0])\n    full_preds = np.zeros(full_y_test.shape[0])\n\n    for fold, (idxT,idxV) in enumerate(skf.split(disease_train, disease_y_train)):\n\n        X_train = disease_train.iloc[idxT]\n        X_val = disease_train.iloc[idxV]\n        y_train = disease_y_train.iloc[idxT]\n        y_val = disease_y_train.iloc[idxV]\n    \n        XGB_model = XGBClassifier(n_estimators=5000, max_depth=None, \n                            learning_rate=0.05,\n                            objective='binary:logistic', \n                            metric='auc',\n                            verbosity  = VERBOSE,\n                            n_jobs=-1, random_state  = SEED)\n        \n    \n        XGB_model.fit(X_train, y_train,\n                        eval_set = [(X_val, y_val)],\n                        eval_metric=['logloss'],\n                        # eval_metric=['auc','logloss'],\n                        early_stopping_rounds = 100, verbose = VERBOSE )\n            \n        XGB_preds = XGB_model.predict_proba(X_val)\n        XGB_score = metrics.roc_auc_score(y_val, XGB_preds[:,1])\n        XGB_class = XGB_model.predict(X_val)\n        \n        XGB_test = XGB_model.predict_proba(disease_test)\n        XGB_test_score = metrics.roc_auc_score(disease_y_test, XGB_test[:,1])\n        XGB_test_class = XGB_model.predict(disease_test)\n        \n        full_test_preds = XGB_model.predict_proba(full_test)\n        full_test_score = metrics.roc_auc_score(full_y_test, full_test_preds[:,1])\n        full_test_class = XGB_model.predict(full_test)\n              \n        f1s = f1_score(y_val, XGB_class)\n        recall = metrics.recall_score(y_val, XGB_class)\n        precision_score = metrics.precision_score(y_val, XGB_class)\n        \n        f1_test = f1_score(disease_y_test, XGB_test_class)\n        recall_test = metrics.recall_score(disease_y_test, XGB_test_class)\n        precision_score_test = metrics.precision_score(disease_y_test, XGB_test_class)\n        \n        f1_full_test = f1_score(full_y_test, full_test_class)\n        recall_full_test = metrics.recall_score(full_y_test, full_test_class)\n        precision_full_test = metrics.precision_score(full_y_test, full_test_class)\n        \n\n        preds += XGB_test[:,1] \/ FOLDS\n        full_preds += full_test_preds[:,1] \/ FOLDS\n        \n        fold_score = [XGB_score,f1s,recall,precision_score, XGB_test_score,f1_test,recall_test,precision_score_test]\n        oof_scores.append({fold : fold_score})\n    \n    avg_test_score = metrics.roc_auc_score(disease_y_test, preds)\n    avg_class = np.where(preds < 0.5, 0, 1)\n    avg_f1_test = f1_score(disease_y_test, avg_class)\n    avg_recall_test = metrics.recall_score(disease_y_test, avg_class)\n    avg_precision_score_test = metrics.precision_score(disease_y_test, avg_class)\n\n    avg_full_test_score = metrics.roc_auc_score(full_y_test, full_preds)\n    avg_class_full = np.where(full_preds < 0.5, 0, 1)\n    avg_f1_test_full = f1_score(full_y_test, avg_class_full)\n    avg_recall_full_test = metrics.recall_score(full_y_test, avg_class_full)\n    avg_precision_full_test = metrics.precision_score(full_y_test, avg_class_full)\n\n    print('-' * 80)\n    print('Averaged over %i folds ROC AUC score for %s: %.4f'%(FOLDS,d,avg_test_score))\n    print('F1 : %.4f, Recall : %.4f , Precision : %.4f'%(avg_f1_test, avg_recall_test, avg_precision_score_test))\n    print('Confusion matrix for %s averaged across %i folds '%(d,FOLDS))\n    print(confusion_matrix(disease_y_test, avg_class))\n\n    \n    print('Averaged over %i folds ROC AUC score for %s against full set of other diseases: %.4f'%(FOLDS,d,avg_full_test_score))\n    print('F1 : %.4f, Recall : %.4f , Precision : %.4f'%(avg_f1_test_full, avg_recall_full_test, avg_precision_full_test))\n    print('Confusion matrix for %s averaged across %i folds for full set'%(d,FOLDS))\n    print(confusion_matrix(full_y_test, avg_class_full))\n\n    return preds, disease_y_test, full_preds, full_y_test, XGB_model","3f5780b3":"\nd_pred, y_true, full_preds, full_y_test, last_model = disease_prediction(d, species) ","48bd537b":"plt.figure(figsize=(20,10))\nfor f in range(10):\n    plt.subplot(2, 5, f+1)\n    plt.hist(pd_disease[species[f]], bins=20)","ac07d18a":"plt.hist(pd_disease[species].std(), bins=20)","621382f5":"# Select species with abundance whose std is larger than 2\nnew_species = np.array(species)[pd_disease[species].std().values>2]\nd_pred, y_true, full_preds, full_y_test, last_model = disease_prediction(d, new_species) ","efc68d8a":"# add other features\nfeatures = np.hstack([new_species, 'age', 'country', 'gender','birth_year', 'cholesterol', 'fasting_insulin',\n                      'hypertension', 'sepsis', 'creatinine', 'triglycerides'])\n# These features have some missing values but xgboost can handle it\nd_pred, y_true, full_preds, full_y_test, last_model = disease_prediction(d, features)","c6e0ef71":"Import the dataset","e9ec8e2d":"We see that most abundances have all their values close to 0. Let us select the abundances that give the most information, i.e. we use the species whose abundance has high variance. Let us plot the histogram of the stds of the abundances for all the species.","0275aebb":"The result is that we have an increase in AUC and F1 score.","ccc57b6d":"### Next step is to use additional metadata features","81dbfddb":"# Feature selection","299f71bf":"The following cell contain the prediction pipeline from https:\/\/www.kaggle.com\/antaresnyc\/cirrhosis-classification with a few tweaks, use a StratifiedKFold cross-validation scheme to estimate the generalization error for a xgboost model with 5000 trees.","c0542394":"Indeed most of the species have a very small std and hence they don't contain a lot of information. Let us filter them out and use the subset of features as the new features.","a940ad14":"This notebook was inspired by already existing kaggle notebooks on this subject : \n*  https:\/\/www.kaggle.com\/sklasfeld\/starter-metagenomics\n*  https:\/\/www.kaggle.com\/antaresnyc\/cirrhosis-classification\n\nThe goal of this notebook is to predict the disease of a person using the abundance (i.e. population size by species) of microbial inhabitants in human guts. The approach is based on gradient boosting classifiers from xgboost and improve on  https:\/\/www.kaggle.com\/antaresnyc\/cirrhosis-classification.\n\nIn this notebook I apply a basic feature selection scheme that allow me to reduce the dimension and increase the AUC of distinguishing type 2 diabetes versus other disease using microbial inhabitants.\n","322dc00b":"Benchmark: the code from the original notebook.","7d82a479":"### Result\nI go from AUC=0.67 and F1=0.16 obtained by the benchmark to predict diabetes against full set of other diseases to AUC= 0.82 and F1=0.26"}}