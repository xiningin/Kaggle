{"cell_type":{"191443ce":"code","1bf4f53d":"code","2ae9ad32":"code","868e0c83":"code","01ac6097":"code","7dd49938":"code","46c96468":"code","3f11ee28":"code","55cc3136":"code","adea3bd0":"code","266124bd":"code","2329a4ca":"code","476a092e":"code","125b9c8c":"code","8abd53e7":"code","f1473f2d":"code","32b7d544":"code","db1ab933":"code","22c0649f":"code","d07d6262":"code","5e472134":"code","e97fe3cd":"markdown","5a97beca":"markdown"},"source":{"191443ce":"import pandas as pd\nfrom PIL import Image\nimport torch\nimport numpy as np\nimport cv2\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport albumentations as A","1bf4f53d":"train_csv = pd.read_csv(\"..\/input\/cassava-leaf-disease-classification\/train.csv\")","2ae9ad32":"class CassavaDataset(torch.utils.data.Dataset):\n    def __init__(self, img_path, df,transforms=None):\n        self.path = img_path\n        self.df = df\n        self.transforms = transforms\n        \n    def __getitem__(self, index):\n        img_name = self.df.image_id.values[index]\n        img_arr = cv2.imread(self.path+img_name)\n        img_arr_rgb = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n        \n        if self.transforms:\n            sample = {'image':img_arr_rgb}\n            sample = self.transforms(**sample)\n            img_tens = sample['image']\n        else:\n            img_tens = torchvision.transforms.ToTensor()(img_arr_rgb)\n            \n        return img_tens\n    \n    def __len__(self):\n        return len(self.df)","868e0c83":"valid_transform = A.Compose(\n    [A.Resize(256,256),\n     A.Normalize(),\n     ToTensorV2()])","01ac6097":"!pip install timm","7dd49938":"import timm","46c96468":"def create_model_ef():\n    model = timm.create_model(\"tf_efficientnet_b1\", pretrained=False)\n    # five classes only\n    num_classes = 5\n    model.classifier = torch.nn.Linear(model.classifier.in_features, num_classes)\n    return model","3f11ee28":"# create model and load pretrained weights\nmodel = create_model_ef()\nmodel_weights = torch.load(\"..\/input\/cassava-leaf-disease-classification-training\/trained_weights_1\", torch.device('cpu'))\nmodel.load_state_dict(model_weights)","55cc3136":"# \"remove\" last classifier layer by setting it to identity passing the last layer completly through\nmodel.classifier = torch.nn.Identity()","adea3bd0":"train_ds = CassavaDataset(\"..\/input\/cassava-leaf-disease-classification\/train_images\/\", train_csv, transforms=valid_transform)\ntrain_dl = torch.utils.data.DataLoader(train_ds, batch_size=32, num_workers=2)","266124bd":"features = []\nfor images in train_dl:\n    with torch.no_grad():\n        feature = model(images)\n        features.append(feature)","2329a4ca":"# manually checked if its a potatoe\npotatoe = features[1][10]\n\n# the corresponding image we want to check all other similarities to (our input\/identity image)\nImage.open(\"..\/input\/cassava-leaf-disease-classification\/train_images\/\" + train_csv.iloc[42][\"image_id\"])","476a092e":"# flatten the arrays\nfeature_vec = []\nfor x in features:\n    for k in x:\n        feature_vec.append(k)","125b9c8c":"# we will store all relevant indices here\nrelevant = []\n# random threshold score (-> higher is more similar)\nthreshold = 0.65\n\nfor i, feat in enumerate(feature_vec):\n    if float(torch.nn.CosineSimilarity(dim=0)(potatoe,feat)) > threshold:\n        relevant.append(i)","8abd53e7":"# indices of similar images\n# using np.array for easier visuals\nnp.array(relevant)","f1473f2d":"# how many images with a similarity score over 0.65 are in our trainset\nlen(relevant)","32b7d544":"# example 1\n# random sample from the relevant list, you can check them in your notebook \nImage.open(\"..\/input\/cassava-leaf-disease-classification\/train_images\/\" + train_csv.iloc[relevant[22]][\"image_id\"])","db1ab933":"# example 2\n# random sample from the relevant list, you can check them in your notebook \nImage.open(\"..\/input\/cassava-leaf-disease-classification\/train_images\/\" + train_csv.iloc[relevant[50]][\"image_id\"])","22c0649f":"# example 3\n# random sample from the relevant list, you can check them in your notebook \nImage.open(\"..\/input\/cassava-leaf-disease-classification\/train_images\/\" + train_csv.iloc[relevant[0]][\"image_id\"])","d07d6262":"# example 4\n# random sample from the relevant list, you can check them in your notebook \nImage.open(\"..\/input\/cassava-leaf-disease-classification\/train_images\/\" + train_csv.iloc[relevant[140]][\"image_id\"])","5e472134":"# example 5\n# random sample from the relevant list, you can check them in your notebook \nImage.open(\"..\/input\/cassava-leaf-disease-classification\/train_images\/\" + train_csv.iloc[relevant[146]][\"image_id\"])","e97fe3cd":"We have checked the whole trainset and there are **147 images** with a cosine similarity higher than **0.65**, thats around **0.6%** of the whole trainset and should therefore only affect our training a little bit. \n\nKeeping them in our training process should not have a big effect on the model, we also dont know if the testset includes such images or not. \n\nSomeone could try to see if they achieve a higher LB-Score by excluding these images.","5a97beca":"This notebook is a demonstration of how someone could use cosine similarity to find similar images within the trainset. \n\nI have seen a couple of discussions talking about how people were able to find \"potatoes\" within the trainset, which they expected to be filled with leaves only. \n\nIn this notebook we want to identify how many of these \"potatoes\" are within our trainset by using cosine similarity."}}