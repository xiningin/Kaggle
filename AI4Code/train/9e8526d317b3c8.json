{"cell_type":{"69dfc352":"code","af733bc9":"code","f5d405f7":"code","5e4325a2":"code","dc9a6083":"code","49870c54":"code","c69c8a75":"code","b15548f0":"code","84d93b9d":"code","c52ba7e8":"code","c52247c5":"code","da83cf42":"code","80ac6389":"code","60835b10":"code","c444ffcc":"code","eb6a4252":"code","c60a85d6":"code","56526d7c":"code","7e494ae7":"code","3173bebe":"code","af971354":"code","2b038fd0":"code","8ce3ab99":"code","f68b6f32":"code","0c7c1a18":"code","087095b3":"code","937f65bf":"code","42dc5571":"code","cb35c218":"code","2a794701":"code","c043c0e5":"code","89d6c81f":"code","d559d7da":"code","ab944ea5":"code","2d671314":"code","fa217c6a":"code","5a79566f":"code","3fed43ab":"code","d3243cdd":"code","1230c382":"code","8dfde7f7":"code","1e49ae4e":"code","5790263a":"code","84aedfe4":"code","5d7f7f84":"code","149c3a95":"code","4039761f":"code","0af40546":"code","05b27ca3":"code","7d11daa0":"code","eede3fb5":"code","ef4847c7":"code","77f7e628":"code","2f08725e":"code","e1d0da33":"code","68bb2d47":"code","c2c0ba78":"code","a1cf4779":"code","13e29f4b":"code","5c794bf3":"code","d8508bc8":"markdown","4089aa4d":"markdown","3a2bcbf1":"markdown","8d59c378":"markdown","5e9c0c90":"markdown","9f8cba7d":"markdown","32ad98b3":"markdown","585671be":"markdown","cf301da8":"markdown","1804612f":"markdown","8510c45d":"markdown","3bc42d4b":"markdown","3eba3edc":"markdown","99d7b474":"markdown","02a90701":"markdown","b324dd05":"markdown","9289e6a4":"markdown","38cedf6e":"markdown","7fe1135e":"markdown","51c49f77":"markdown","f6fa4e6f":"markdown","c2b780c5":"markdown","b08f3336":"markdown","64b5aeb6":"markdown","6c2aaf83":"markdown","2ea40874":"markdown","10d08077":"markdown","3bf5cdb1":"markdown","15e450f3":"markdown","2f5d234f":"markdown","8e5a2435":"markdown","42797a88":"markdown","3a898295":"markdown","88bd5293":"markdown","43feeda7":"markdown","4a9c59ad":"markdown","37378ad5":"markdown","b975ef2c":"markdown","f866d5e5":"markdown","9f3b757f":"markdown","e718281b":"markdown","5ebec26e":"markdown","b78aa871":"markdown","9a0c39f4":"markdown","858e0d41":"markdown","e6936d9b":"markdown","eb58e98a":"markdown","7cd6fcb7":"markdown","327d971f":"markdown","87bf40c0":"markdown","8126703e":"markdown","9893745f":"markdown","c162a0ae":"markdown","a44b71d9":"markdown","fabea71d":"markdown","b5ee6902":"markdown","f85d4013":"markdown","c3884fc2":"markdown","9be822c1":"markdown","32319778":"markdown","70103a0d":"markdown","8e5dde99":"markdown","26e62695":"markdown"},"source":{"69dfc352":"import warnings\nimport zipfile\nfrom fastai.vision import *\nfrom fastai.metrics import error_rate\nfrom fastai.widgets import *\nimport pandas as pd\nimport base64\nfrom IPython.display import HTML\nimport re\n\nwarnings.filterwarnings('ignore') # Suppress warning messages.\n\n%matplotlib inline","af733bc9":"os.chdir('\/kaggle\/input\/dogs-vs-cats-redux-kernels-edition')\n\nos.listdir()","f5d405f7":"with zipfile.ZipFile('\/kaggle\/input\/dogs-vs-cats-redux-kernels-edition\/train.zip', 'r') as zip_ref:\n    zip_ref.extractall('\/kaggle\/working\/')","5e4325a2":"with zipfile.ZipFile('\/kaggle\/input\/dogs-vs-cats-redux-kernels-edition\/test.zip', 'r') as zip_ref:\n    zip_ref.extractall('\/kaggle\/working\/')","dc9a6083":"os.chdir('\/kaggle\/working\/')\n\nos.listdir()","49870c54":"train_fnames = get_image_files('\/kaggle\/working\/train')\n\nlen(train_fnames)","c69c8a75":"train_fnames[:5]","b15548f0":"labels = [('cat' if 'cat.' in str(fname) else 'dog') for fname in train_fnames]\n\nlabels[:5]","84d93b9d":"np.random.seed(123) # Ensure reproducibility.\ndata = ImageDataBunch.from_lists(\n    path='\/kaggle\/working\/train', \n    fnames=train_fnames, \n    labels=labels, \n    valid_pct=0.2, # Put 20% of the images in the validation set.\n    ds_tfms=get_transforms(flip_vert=False), # Perform data augmentation.\n    size=224, # Resize all images to the same size (224px by 224px).\n    bs=32 # Set the batch size for training.\n).normalize(imagenet_stats) # Normalize all images with ImageNet statistics.","c52ba7e8":"len(data.train_ds), len(data.valid_ds)","c52247c5":"data.classes","da83cf42":"data.show_batch(rows=3, figsize=(12, 12))","80ac6389":"torch.cuda.is_available()","60835b10":"torch.backends.cudnn.enabled","c444ffcc":"# Make sure Internet is on.\nlearner = cnn_learner(data, models.resnet50, metrics=error_rate).to_fp16()","eb6a4252":"learner.lr_find(start_lr=1e-6)","c60a85d6":"learner.recorder.plot()","56526d7c":"max_lr_choice = 5e-4","7e494ae7":"learner.fit_one_cycle(4, max_lr=max_lr_choice)","3173bebe":"learner.recorder.plot_losses()","af971354":"learner.save('imgsize224-stage1')","2b038fd0":"interp = ClassificationInterpretation.from_learner(learner)","8ce3ab99":"interp.plot_confusion_matrix()","f68b6f32":"accuracy = (interp.confusion_matrix()[0, 0] + interp.confusion_matrix()[1, 1]) \/ len(data.valid_ds)\n\naccuracy","0c7c1a18":"interp.plot_top_losses(20, figsize=(16, 16))","087095b3":"data_no_split = ImageDataBunch.from_lists(\n    path='\/kaggle\/working\/train', \n    fnames=train_fnames, \n    labels=labels, \n    valid_pct=0, # Don't put any images in the validation set.\n    ds_tfms=get_transforms(flip_vert=False),\n    size=224,\n    bs=32\n).normalize(imagenet_stats)","937f65bf":"%%capture\nlearner_no_split = cnn_learner(data_no_split, models.resnet50).to_fp16()\nlearner_no_split.load('imgsize224-stage1')","42dc5571":"dataset, file_indices = DatasetFormatter.from_toplosses(learner_no_split)","cb35c218":"# Use in interactive mode only. When committing notebook, cleaning isn't possible.\nImageCleaner(dataset, file_indices, Path('\/kaggle\/working\/train'))","2a794701":"# Use in interactive mode only.\ncleaned = pd.read_csv('\/kaggle\/working\/train\/cleaned.csv')\n\ncleaned.head()","c043c0e5":"# Source: https:\/\/www.kaggle.com\/rtatman\/download-a-csv-file-from-a-kernel\ndef create_download_link(df, title=\"Download CSV file\", filename=\"dogs_vs_cats_cleaned.csv\"):\n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload, title=title, filename=filename)\n    return HTML(html)","89d6c81f":"# Use in interactive mode only.\ncreate_download_link(cleaned)\n\n# See 'Download CSV file' link below.","d559d7da":"# Make sure Internet is on.\ncleaned = pd.read_csv('https:\/\/storage.googleapis.com\/cleaned-data\/dogs_vs_cats_cleaned.csv')\n\ncleaned.head()","ab944ea5":"np.random.seed(123)\ndata_cleaned = ImageDataBunch.from_df(\n    path='\/kaggle\/working\/train', \n    df=cleaned, \n    valid_pct=0.2, # Put 20% of the images in the validation set.\n    ds_tfms=get_transforms(flip_vert=False),\n    size=224,\n    bs=32\n).normalize(imagenet_stats)","2d671314":"learner = cnn_learner(data_cleaned, models.resnet50, metrics=error_rate).to_fp16()","fa217c6a":"learner.lr_find(start_lr=1e-6)","5a79566f":"learner.recorder.plot()","3fed43ab":"max_lr_choice = 5e-4","d3243cdd":"learner.fit_one_cycle(4, max_lr=max_lr_choice)","1230c382":"learner.save('imgsize224-stage2')","8dfde7f7":"np.random.seed(123)\ndata = ImageDataBunch.from_df(\n    path='\/kaggle\/working\/train', \n    df=cleaned, \n    valid_pct=0.2,\n    ds_tfms=get_transforms(flip_vert=False),\n    size=300, # Re-size all images to 300px by 300px.\n    bs=32\n).normalize(imagenet_stats)","1e49ae4e":"%%capture\nlearner = cnn_learner(data, models.resnet50, metrics=error_rate).to_fp16()\nlearner.load('imgsize224-stage2')","5790263a":"learner.lr_find(start_lr=1e-6, end_lr=1e-2, stop_div=False)","84aedfe4":"learner.recorder.plot()","5d7f7f84":"max_lr_choice = 5e-5","149c3a95":"learner.fit_one_cycle(4, max_lr=max_lr_choice)","4039761f":"learner.save('imgsize300-stage1')","0af40546":"learner.unfreeze()\nlearner.lr_find(start_lr=1e-6, end_lr=1e-2, stop_div=False)","05b27ca3":"learner.recorder.plot()","7d11daa0":"learner.fit_one_cycle(4, max_lr=slice(1e-5, 1e-4))","eede3fb5":"learner.save('imgsize300-stage2')","ef4847c7":"learner = learner.to_fp32() # Convert back to default precision for safe export.\nlearner.export()","77f7e628":"test_fnames = get_image_files('\/kaggle\/working\/test')\n\nlen(test_fnames)","2f08725e":"test_fnames[:5]","e1d0da33":"ids = [int(re.findall(r'\\d+', str(fname))[0]) for fname in test_fnames]\n\nids[:5]","68bb2d47":"learner.path # Location of pickle.","c2c0ba78":"learner = load_learner(path=learner.path, test=test_fnames)","a1cf4779":"preds, labels = learner.get_preds(ds_type=DatasetType.Test)\n\npreds[:5]","13e29f4b":"d = {'id': ids, 'label': preds[:, 1]}\nsubmission = pd.DataFrame(data=d)\nsubmission = submission.sort_values(by='id')\n\nsubmission.head()","5c794bf3":"submission.to_csv('submission.csv', index=False)","d8508bc8":"Let's unfreeze our model and run `fastai`'s learning rate finder.","4089aa4d":"We can now download the data frame.","3a2bcbf1":"Let's save our model's weights.","8d59c378":"Now, let's train our model for `4` epochs.","5e9c0c90":"Now, we can use ImageCleaner to:\n\n1. **Re-label:** Mis-labeled images (`'cat'` as `'dog'` or `'dog'` as `'cat'`).\n2. **Delete:**\n    - Images containing both a cat and a dog (since this is not a multi-label classification problem).\n    - Images where it isn't clear whether the animal is a cat or a dog (e.g., due to the animal's posture \/ image blur).\n    - Clip art \/ cartoons.\n    - Irrelevant images (e.g., house pictures, landscapes, company logos, etc.)","9f8cba7d":"There are `12500` files. Let's examine the first `5` filenames.","32ad98b3":"Next, let's change our working directory to `'\/kaggle\/working'` and take a look at its contents.","585671be":"<a id=\"section_5_1\"><\/a>\n## 5.1. Data Cleaning","cf301da8":"As we can see, some of the misclassified images are noisy \/ irrelevant.","1804612f":"Let's create a new learner with `data_cleaned`.","8510c45d":"Let's create our learner by specifying:\n\n- `data` {Training Set + Validation Set}\n- `models.resnet50` (model with ResNet50 architecture pre-trained on ImageNet images)\n- `error_rate` (metric to show during training)\n- `to_fp16()` (mixed precision training)","3bc42d4b":"Let's recreate our `ImageDataBunch` using the `cleaned` data frame.","3eba3edc":"After eyeballing the graph, let's choose a maximum learning rate.","99d7b474":"Finally, let's use a list comprehension to generate the labels.","02a90701":"Let's use a list comprehension to extract the ids.","b324dd05":"Accuracy:","9289e6a4":"A couple of checks:","38cedf6e":"That's a pretty good fit.\n\nPlot of training & validation losses:","7fe1135e":"We shall use `slice(1e-5, 1e-4)` as our sequence of learning rates.\n\nLet's perform *discriminative layer training* for `4` epochs. (This will apply a different learning rate to each *layer group*.)","51c49f77":"---\n\n<a id=\"section_2\"><\/a>\n# 2. {Training Set + Validation Set} Creation","f6fa4e6f":"Now, we'll use `fastai`'s `ImageCleaner` Jupyter widget to re-label \/ delete images which are mislabeled \/ noisy \/ irrelevant.\n\nFirst, let's create a new `ImageDataBunch` without a training, validation split.","c2b780c5":"The first column is the probability of `'cat'` and the second column is the probability of `'dog'`.\n\nLet's create our submission data frame and sort its rows by `id`.","b08f3336":"Let's plot the confusion matrix.","64b5aeb6":"Next, let's load our learner from the exported pickle (specifying the test set this time).","6c2aaf83":"There are `25000` files. Let's examine the first `5` filenames.","2ea40874":"Let's extract the files in `'train.zip'` and `'test.zip'` to the `'\/kaggle\/working\/'` directory.","10d08077":"---\n\n<a id=\"section_3\"><\/a>\n# 3. Mixed Precision Training","3bf5cdb1":"Finally, let's use the `plot_top_losses()` method to examine images which have the biggest losses along with:\n\n- predicted class\n- actual class\n- loss\n- probability assigned by model to actual class","15e450f3":"<a id=\"section_5_3\"><\/a>\n## 5.3. Unfreezing & Discriminative Layer Training","2f5d234f":"After eyeballing the graph, let's choose a *maximum learning rate*.","8e5a2435":"Next, let's run `fastai`'s learning rate finder.","42797a88":"---\n\nThis notebook attempts to replicate a few tricks mentioned by <a href=\"https:\/\/www.kaggle.com\/jhoward\" target=\"_blank\">Jeremy Howard<\/a> in <a href=\"https:\/\/course.fast.ai\/\" target=\"_blank\">Practical Deep Learning for Coders<\/a> to improve the performance of an image classifier.\n\nModule imports and other preliminaries:","3a898295":"Finally, let's export our model as a pickle.","88bd5293":"A new CSV file `'cleaned.csv'` has been created in the `'\/kaggle\/working\/train'` folder. Let's read it in and take a look.","43feeda7":"Now we have a model (`'imgsize224-stage2'`) that is pretty good at classifying dogs vs. cats.\n\n**Trick to create an even better model:** \n\n1. Re-size all images to 300px by 300px and create a new `ImageDataBunch`.\n2. Perform transfer learning on this new `ImageDataBunch` using `'imgsize224-stage2'` as our pre-trained model.\n\nBy using a larger image size, we'll lose most of the overfitting of the previous model, but transfer its 'learning' to the new model.\n\nLet's create the new `ImageDataBunch`.","4a9c59ad":"After eyeballing the graph, let's choose a maximum learning rate.","37378ad5":"<a id=\"section_5_2\"><\/a>\n## 5.2. Progressive Image Re-sizing","b975ef2c":"A random sample of observations:","f866d5e5":"Let's take a look at the competition data files.","9f3b757f":"---\n\n<a id=\"section_6\"><\/a>\n# 6. Test Set Predictions & Submission","e718281b":"Next, let's run `fastai`'s learning rate finder.","5ebec26e":"---\n\n<a id=\"section_1\"><\/a>\n# 1. Data Extraction & Label Generation","b78aa871":"Finally, let's write it to disk.","9a0c39f4":"Now, let's obtain our test set predictions.","858e0d41":"Let's save our model's weights.","e6936d9b":"---\n\n<a id=\"section_5\"><\/a>\n# 5. Improving the Classifier","eb58e98a":"Let's save our model's weights.","7cd6fcb7":"Let's pass in the new learner to `DatasetFormatter.from_toplosses()`. It will return a *formatted* dataset and file indices in descending order of top losses.","327d971f":"Now, let's train our model for `4` epochs.","87bf40c0":"Next, let's download the file, and upload it to a bucket in Google Cloud Storage (or AWS S3 \/ Dropbox \/ other similar service).\n\nAfter the file has been uploaded, we can read it in.","8126703e":"Let's save our model's weights.","9893745f":"Let's create a new learner with the new `ImageDataBunch` and load the previous model's weights.","c162a0ae":"Let's get the filenames in the `'test'` folder.","a44b71d9":"# Table of Contents\n1. [Data Extraction & Label Generation](#section_1)\n2. [{Training Set + Validation Set} Creation](#section_2)\n3. [Mixed Precision Training](#section_3)\n4. [Validation Set Results](#section_4)\n5. [Improving the Classifier](#section_5)\n    1. [Data Cleaning](#section_5_1)\n    2. [Progressive Image Re-sizing](#section_5_2)\n    3. [Unfreezing & Discriminative Layer Training](#section_5_3)\n6. [Test Set Predictions & Submission](#section_6)","fabea71d":"The folders `'train'` and `'test'` contain the images.\n\nLet's get the filenames in `'train'`.","b5ee6902":"**Note:** Since it isn't possible to use the `ImageCleaner` Jupyter widget when committing the notebook, we need to save the `cleaned` data frame to a persistent storage location (e.g., Google Cloud Storage \/ AWS S3 \/ Dropbox). We'll then continue our workflow with this persistent file (instead of the interactive one above).\n\nLet's create a function to download the data frame.","f85d4013":"Now, let's train our model for `4` epochs.","c3884fc2":"---\n\n<a id=\"section_4\"><\/a>\n# 4. Validation Set Results","9be822c1":"The training set contains `20000` images and the validation set contains `5000` images.\n\nClasses:","32319778":"Let's create an `ImageDataBunch` object (containing both the training set and the validation set).","70103a0d":"Let's create a `ClassificationInterpretation` object.","8e5dde99":"Next, let's run `fastai`'s learning rate finder.","26e62695":"Next, let's create a new learner with `data_no_split` and load the `'imgsize224-stage1'` weights."}}