{"cell_type":{"a18a31e7":"code","147cf6d5":"code","9bde8f7d":"code","8d996476":"code","d8f3e951":"code","a324b68f":"code","9ff86170":"code","64c662a3":"code","eeaa8124":"code","e086446f":"code","3ea77c41":"code","423720c8":"code","f41ef394":"code","4c8e4267":"code","475c705c":"code","b2ed3a12":"code","9cdd6672":"code","5a626de7":"code","69f57035":"code","cf485f3b":"code","742d7189":"code","70ad2116":"code","06ec901a":"code","86d05dcc":"code","407ca8bd":"markdown","5ad2943a":"markdown","4beb2e70":"markdown","63af468b":"markdown","19c560c7":"markdown","a8da074d":"markdown","4130f9b7":"markdown","654f1321":"markdown","5b413220":"markdown","b10ce747":"markdown","83583f2c":"markdown","418c8e9e":"markdown","4f6d9164":"markdown","709697e8":"markdown","07eba003":"markdown","76f0bb49":"markdown","1d633e41":"markdown","1ccd6339":"markdown","b88b1a25":"markdown","fe351230":"markdown","de7747d3":"markdown"},"source":{"a18a31e7":"import pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport re\n\nnrows = 1000000\ndf = pd.read_csv('\/kaggle\/input\/Xenophobia.csv', nrows=nrows, encoding='latin1')\n\n# Drop columns not used for modelling\ncols_to_drop = ['status_id', 'created_at', 'location']\ndf.drop(cols_to_drop, axis=1, inplace=True)\n            \n# Convert text to string type\ndf['text'] = df['text'].astype(str)\n\nprint(\"Total number of samples:\", len(df))\n\ndf.head()","147cf6d5":"# Print a random tweet as a sample\nsample_index = 25\nprint(df.iloc[sample_index])","9bde8f7d":"# Helper function to remove unwanted patterns\ndef remove_pattern(input_txt, pattern):\n    r = re.findall(pattern, input_txt)\n    for i in r:\n        input_txt = re.sub(i, '', input_txt)\n    return input_txt\n\n# Remove Twitter handles from the data \ndf['text'] = np.vectorize(remove_pattern)(df['text'], \"@[\\w]*\")\n\n# Remove punctuations, numbers, and special characters\ndf['text'] = df['text'].str.replace(\"[^a-zA-Z#]\", \" \")\n\n# Remove all words below 3 characters\ndf['text'] = df['text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))","8d996476":"# Tokenize the tweets\ntokenized_tweet = df['text'].apply(lambda x: x.split())","d8f3e951":"# Stem the tweets\nfrom nltk.stem.porter import *\nstemmer = PorterStemmer()\ntokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x])","a324b68f":"# Put tokenized tweets back in dataframe\nfor i in range(len(tokenized_tweet)):\n    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\ndf['text'] = tokenized_tweet","9ff86170":"from textblob import TextBlob\n\n# Helper function to match negative tweets\ndef is_tweet_negative(tweet, threshold):\n    testimonial = TextBlob(tweet)\n    polarity = testimonial.sentiment.polarity\n    if polarity < threshold:\n        return True\n    return False\n\n# Helper function to match xenophoic tweets\ndef is_tweet_xenophobic(tweet):\n    for s in search_terms:\n        if s in tweet:\n            return True\n    return False\n\n# Define search terms that appear in xenophic tweets\nsearch_terms = ['alien', 'asian', 'china', 'criminal', 'floater', 'foreigner', 'greenhorn',\n                'illegal', 'intruder', 'invader', 'migrant', 'newcomer', 'odd one out', 'outsider',\n                'refugee', 'send her back', 'send him back', 'send them back', 'settler', 'stranger']\n\n# Find all negative tweets using polarity (< 0)\ndf['Negative'] = df.text.apply(lambda x: is_tweet_negative(x, threshold=0))\n\n# Find all xenophobic tweets looking only at the negative tweets\ndf['Xenophobic'] = df.loc[df['Negative'] == True].apply(lambda x: is_tweet_xenophobic(x.text), axis=1)\ndf[['Xenophobic']] = df[['Xenophobic']].fillna(value=False)","64c662a3":"print(f\"Number of tweets: {len(df)}\")\nprint(f\"Number of positive tweets: {len(df.loc[df['Negative'] == False])}\")\nprint(f\"Number of negative tweets: {len(df.loc[df['Negative'] == True])}\")\nprint(f\"Number of negative tweets, but benign: {len(df.loc[(df['Negative'] == True) & (df['Xenophobic'] == False)])}\")\nprint(f\"Number of xenophobic tweets: {len(df.loc[(df['Negative'] == True) & (df['Xenophobic'] == True)])}\")","eeaa8124":"# Print a xenophobic tweet as a sample\ntweet = df.loc[(df['Negative'] == True) & (df['Xenophobic'] == True)].iloc[20]\nprint(tweet.text)","e086446f":"# Print ratio of target variable\ntarget_ratio = df['Xenophobic'].value_counts()[1]\/df['Xenophobic'].value_counts()[0]\nprint(f\"Ratio of non-xenophobic\/xenophobic: {np.round(target_ratio, 3)}\\n\")\n\nprint('Split before random under-sampling:')\nprint(df.Xenophobic.value_counts())\n\n# Plot the two classes\ndf['Xenophobic'].value_counts().plot(kind='bar', title='Count (Xenophobic) before')","3ea77c41":"# Apply random undersampling to fix the imbalancness in the data\n# Thanks https:\/\/www.kaggle.com\/rafjaa\/resampling-strategies-for-imbalanced-datasets\n\ncount_class_0, count_class_1 = df.Xenophobic.value_counts()\ndf_class_0 = df[df['Xenophobic'] == 0]\ndf_class_1 = df[df['Xenophobic'] == 1]\n\ndf_class_0_under = df_class_0.sample(2*count_class_1)\ndf_undersampled = pd.concat([df_class_0_under, df_class_1], axis=0)\n\ntarget_ratio = df_undersampled['Xenophobic'].value_counts()[1]\/df_undersampled['Xenophobic'].value_counts()[0]\nprint(f\"Ratio of non-xenophobic\/xenophobic: {np.round(target_ratio, 3)}\\n\")\n\nprint('Split after random under-sampling:')\nprint(df_undersampled.Xenophobic.value_counts())\n\ndf_undersampled = df_undersampled.reset_index(drop=True)\ndf_undersampled.Xenophobic.value_counts().plot(kind='bar', title='Count (Xenophobic) after');","423720c8":"# Plot a funnel chart\n\nplt.style.use('seaborn')\nfrom plotly import graph_objs as go\nimport plotly.express as px\n\ntemp = df_undersampled.groupby('Xenophobic').count()['text'].reset_index()\ntemp['label'] = temp['Xenophobic'].apply(lambda x : 'Xenophobic Tweet' if x==1 else 'Non Xenophobic Tweet')\n\nfig = go.Figure(go.Funnelarea(\n    text = temp.label,\n    values = temp.text,\n    title = {\"position\" : \"top center\", \"text\" : \"Funnel Chart for target distribution\"}\n    ))\nfig.show()","f41ef394":"# Plot number of words in tweets\n\nfig,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\ntweet_len=df_undersampled[df_undersampled['Xenophobic']==1]['text'].str.split().map(lambda x: len(x))\nax1.hist(tweet_len,color='red')\nax1.set_title('Xenophobic Tweets')\ntweet_len=df_undersampled[df_undersampled['Xenophobic']==0]['text'].str.split().map(lambda x: len(x))\nax2.hist(tweet_len,color='blue')\nax2.set_title('Non Xenophobic Tweets')\nfig.suptitle('Number of words in tweets')\nplt.show()","4c8e4267":"from collections import Counter\n\ndf_undersampled['temp_list'] = df_undersampled['text'].apply(lambda x:str(x).split())\n\ntop = Counter([item for sublist in df_undersampled['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(25))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","475c705c":"fig = px.bar(temp, x='count',y='Common_words',title='Common words in tweet',orientation='h',width=700,height=700,color='Common_words')\nfig.show()","b2ed3a12":"from wordcloud import WordCloud, STOPWORDS\n\ntext = df_undersampled['text'].values\ncloud = WordCloud(stopwords=STOPWORDS,\n                  background_color='white',\n                  max_words=150,\n                  width=2000,\n                  height=1500).generate(\" \".join(text))\n\nplt.imshow(cloud)\nplt.axis('off')\nplt.show()","9cdd6672":"# Set up variables\ndf_undersampled = df_undersampled.drop(['Negative'], axis=1)\ndf_undersampled = df_undersampled.reset_index(drop=True)\n\nX = df_undersampled\ny = X['Xenophobic']\nX.drop(['Xenophobic'], axis=1, inplace=True)\n\n# Split the data using stratify \nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25)\n\n# Reset the index\nX_train = X_train.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)\nX_test_stats = X_test.copy()","5a626de7":"# Convert the text feature into a vectors of tokens\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ncv = CountVectorizer(strip_accents='ascii', token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b',\n                             lowercase=True, stop_words='english')\nX_train_cv = cv.fit_transform(X_train.text)\nX_test_cv = cv.transform(X_test.text)\n\n# Scale numerical features (followers, retweets etc.)\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ncols = ['favorite_count', 'retweet_count', 'followers_count', 'friends_count', 'statuses_count']\nX_train_sc = scaler.fit_transform(X_train[cols])\nX_test_sc = scaler.transform(X_test[cols])\n\n# Merge the numerical features with our count vectors\nimport scipy.sparse as sp\ntrain_count = sp.csr_matrix(X_train_cv)\ntrain_num = sp.csr_matrix(X_train_sc)\nX_train = sp.hstack([train_count, train_num])\n\ntest_count = sp.csr_matrix(X_test_cv)\ntest_num = sp.csr_matrix(X_test_sc)\nX_test = sp.hstack([test_count, test_num])","69f57035":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix\nn_classes = 2\n\nclf = SGDClassifier(alpha=1e-3, random_state=0)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)","cf485f3b":"# Plot scores and make a confusion matrix for non-xenophobic\/xenophobic predictions\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix\nn_classes = 2\n\ncm = confusion_matrix(y_test, y_pred, labels=range(n_classes))\n\nprint(f'Number of samples to classify: {len(X_test.toarray())}\\n')\nprint(f'Accuracy score: {accuracy_score(y_test, y_pred)}')\nprint(f'Precision score: {precision_score(y_test, y_pred)}')\nprint(f'Recall score: {recall_score(y_test, y_pred)}\\n')\nprint(f'Confusion matrix: \\n{cm}')","742d7189":"# Normalize the confusion matrix and plot it\n\nlabels = ['non-xenophobic', 'xenophobic']\nplt.figure(figsize=(6,6))\ncm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\nsns.heatmap(cm, square=True, annot=True, cbar=False,\n            xticklabels=labels, yticklabels=labels)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')","70ad2116":"# Plot the ROC curve for the SVM classifier\nfrom sklearn.metrics import roc_curve\nfpr, tpr, _ = roc_curve(y_test, y_pred)\nplt.figure(figsize=(8,8))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr, label='SVM')\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.show()","06ec901a":"# Show how the first 50 test tweets were classified and their true label\ntesting_predictions = []\nfor i in range(len(X_test.toarray())):\n    if y_pred[i] == 1:\n        testing_predictions.append('Xenophobic')\n    else:\n        testing_predictions.append('Non-xenophobic')\ncheck_df = pd.DataFrame({'actual_label': list(y_test), 'prediction': testing_predictions, 'text':list(X_test_stats.text)})\ncheck_df.replace(to_replace=0, value='No-Xenophobic', inplace=True)\ncheck_df.replace(to_replace=1, value='Xenophobic', inplace=True)\ncheck_df.iloc[:50]","86d05dcc":"# Show first 10 tweets that were classified as being xenophobic\npd.DataFrame(X_test_stats.text.iloc[y_pred].head(10)).reset_index(drop=True)","407ca8bd":"# Tweet labelling\n\nThe data set is not labeled for us, so we'll have to that ourselves. This procedure is somewhat inspired by \nAbraham Starosta's medium post on the same topic, which you should go and read. He suggests filtering the tweets by a list of searching terms as we only want to run the model on tweets that match the search queries we used to build our tweet dataset. In other words, we traverse the data set and apply a xenophobia label to tweets that contain xenophobic words and otherwise a non-xenophobic tag.\n\nI chose a slightly different approach, since traversing a million tweets in a nested loop takes a considerable amount of time. Instead of labelling all tweets as either xenophobic or not, we'll only be looking at the negative ones, since xenophobia tweets must naturally be a subset of the negative ones. I'll use **TextBlob** for this. So the process is two-fold:\n\n1. Identify all negative tweets by the polarity of the text in the tweet.\n2. Looking at only the negative tweets, classify those that contain xenophobic words (illegal, intruder, send her back etc).\n\nLinks: <br>\nhttps:\/\/medium.com\/sculpt\/xenophobic-tweets-78a9b316635","5ad2943a":"# Text preprocessing\n\nNext step is to do some early preprocesing of the tweets to make them easier to work with and reduce overhead. Initial data cleaning requirements that are common for tweets:\n\n* Remove Twitter handles as they are hardly giving any information about the nature of the tweet.\n* Getting rid of the punctuations, numbers and even special characters since they wouldn\u2019t help in differentiating different kinds of tweets.\n* Most smaller words to not add value. For example, \u2018pdx\u2019, \u2018his\u2019, \u2018all\u2019. So, we will all words less than 3 characters.\n* We want to reduce words to their root word, for example terms like \"loves\", \"loving\", \"lovable\" to just \"love\".\n\nOnce the initial cleaning is done, we can split every tweet into individual words or tokens which is an essential step in any NLP task.","4beb2e70":"The SVM performs well, but again, we kind of customized the data set to its liking by undersampling the non-xenophobic tweets. This way it achieves great results in terms of precision and recall, but since we're missing out on a lot of information about the non-xenophobic tweets, this classifer would struggle to identify true negatives (non-xenophobic). \n\nNext we plot a simple ROC curve that shows the true positive rate vs the false positive rate.","63af468b":"A few remarks on the notation and the scores:\n\nSince we are \"overfeeding\" the classifer with xenophobic tweets with a 2:1 ratio now what the we undersamped the none-xenophobic tweets, the results here are a bit inflated. More work should be done to improve labelling and decrase the undersampling. Below a quick summary though.\n\n**Accuracy score**: Out of all tweets, how many did we label correctly?\n(True positives + true negatives) \/ total observations: (4866 + 64190) \/ 74712\n\n**Precision score**: Out of all hate tweets, how many did we get right?\nTrue positives \/ (true positives + false positives): 4866 \/ (4866 + 1537)\n\n**Recall score**: Out of all true hate tweets, how many did we label correctly?\nTrue positives \/ (true positives + false negatives): 4866 \/ (4866 + 4119)","19c560c7":"# Feature encoding","a8da074d":"The balance is now levelled out about 50-50, however this approach cause a huge data loss, so one should be careful with undersampling. Alternatives are oversampling the minority class or improving the labelling phase by finding more xenophobic tweets or simply","4130f9b7":"# EDA\n\nNow that we have the labels, we can do some simple EDA. We start with a funnel chart to show data distribution. Plots are mostly inspired by: https:\/\/www.kaggle.com\/utcarshagrawal\/nlp-model-the-easiest-way","654f1321":"We'll train a stochastic gradient descent (SGD) classifer to distinguish xenophobic and non-xenophobic tweets. Stochastic means that, at each training iteration, the gradient of the loss (in which direction to move down the slope to minimize the loss) is estimated by a random sampled observations. The model is updated along the way with a decreasing strength schedule (learning rate). By default SGD fits a linear support vector machine (SVM) and uses a hinge loss function.\n\nThe penalty (aka regularization term) defaults to \"l2\", which is the standard regularizer for linear SVM models.\n\nAlpha is set to 0.001 (power of the regularization term) and random_state is zero.\n\nLinks: <br>\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.SGDClassifier.html <br>\nhttps:\/\/towardsdatascience.com\/l1-and-l2-regularization-methods-ce25e7fc831c\n\n","5b413220":"Next we'll compare the number of words in xenophobic\/non xenophobic tweets. Notice that xenophobic tweets tend to be longer in general.","b10ce747":"Now we will tokenize all the cleaned tweets in our dataset. Tokens are individual terms or words, and tokenization is the process of splitting a string of text into tokens.\n\n","83583f2c":"# Modelling using SVM","418c8e9e":"Finally we'll stich the dataframe back together now what we have cleaned the data.","4f6d9164":"We'll print some statistics showing the distribution of the data.","709697e8":"For scaling, the **MinMaxScaler** works well for Naive-Bayes\/SVM models as preserves the shape of the dataset (no distortion). You could opt for **StandardScaler** as well, but that assumes the data distribution is normal. Some investigation could be done here to find  the optimal scaler.\n\nIf you encounter outliers in your data set, go for **RobustScaler**.\n\nScaler should also be used after train\/test split, otherwise data leakage could happen.","07eba003":"Finally let's do a wordcloud of the common words in the data set.","76f0bb49":"Our job here is to transform the text feature (the tweet) into vectors, that a classifier can understand. In this notebook we'll use the stochastic gradient descent SVM classifier. It needs to be able to calculate how many times each word appears in each document and how many times it appears in each category (xenophobic or not). To make this possible, the data needs to look something like this:\n\n[0, 1, 0, \u2026] <br>\n[1, 1, 1, \u2026] <br>\n[0, 2, 0, \u2026]\n\nEach row represents a document, and each column represents a word. The first row might be a document that contains a zero for \u201cdumb,\u201d a one for \u201cthe\u201d and a zero for \u201chate\u201d. That means that the document contains one instance of the word \u201cthe\u201d, but no \u201cdumb\u201d or \u201chate.\u201d\n\nWe'll use Scikit Learn\u2019s CountVectorizer to turn the tweets into count vectors. CountVectorizer creates a vector of word counts for each abstract to form a matrix. Each index corresponds to a word and every word appearing in the texts is represented.\n\nLink: <br>\nhttps:\/\/towardsdatascience.com\/naive-bayes-document-classification-in-python-e33ff50f937e\n\n","1d633e41":"# Resampling\n\nA widely adopted technique for dealing with highly unbalanced datasets is called resampling. It consists of removing samples from the majority class (under-sampling) and \/ or adding more examples from the minority class (over-sampling). The disadvantage with undersampling is that it discards potentially useful data. The main disadvantage with oversampling, from our perspective, is that by making exact copies of existing examples, it makes overfitting likely\n\n![image.png](attachment:image.png)\n\nDespite the advantage of balancing classes, these techniques also have their weaknesses (there is no free lunch). The simplest implementation of over-sampling is to duplicate random records from the minority class, which can cause overfitting. In under-sampling, the simplest technique involves removing random records from the majority class, which can cause loss of information.\n\nWe'll use the Pandas sample() next to undersample the non-xenophobic tweets to balance out the data set.","1ccd6339":"![](https:\/\/i.imgur.com\/DW1QGCQ.jpg)\n\n# Introduction\n\nThe outbreak of the coronavirus COVID-19 has had many side effects. While the World Health Organisation and other agencies are trying to transparently distribute accurate information about the disease, the global conversation has been dominated by mass hysteria and global panic.\n\nTo protect themselves, people are washing their hands like it is the latest fashion trend and have collected stockpiles of hand sanitiser. Conspiracy theories are going viral on the internet. Protective facemasks are flying off the shelves in pharmacies worldwide. Financial markets are crashing and Corona beer sales have declined. The travel industry is devastated, and some news media outlets have succumbed to fearmongering and blatantly misleading headlines. But one of the most devastating side effects has been xenophobic attacks against people of Asian descent. The question is, if this trend can be found in tweets.\n\nIn this notebook, we use NLP tools and a stochastic gradient descent (SGD) classifier to process and train on tweets made during the COVID-19 pandemic. The goal is to classiify tweets containing xenophobia from those that do not. \n\nLinks: <br>\nhttps:\/\/www.euronews.com\/2020\/03\/05\/covid-19-and-xenophobia-why-outbreaks-are-often-accompanied-by-racism <br>\nhttps:\/\/textblob.readthedocs.io\/en\/dev\/quickstart.html <br>\nhttps:\/\/towardsdatascience.com\/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a\n\nWe start by loading the rather large data set and do some initial preprocessing.","b88b1a25":"Next we'll print the top 20 words occuring in all the training tweets.","fe351230":"We'll see that the xenophobic tweets are a minority in the data set and vastly underrepresented (about a 6 per thousand), so'll have to look at some way to balance out the dataset or try to improve our labelling strategy. It may be the case that the tweets do not contain in no way as much xenophobic as we may think. Resampling is an option explored below.","de7747d3":"Stemming is a rule-based process of stripping the suffixes (\u201cing\u201d, \u201cly\u201d, \u201ces\u201d, \u201cs\u201d etc) from a word. For example, For example \u2013 \u201cplay\u201d, \u201cplayer\u201d, \u201cplayed\u201d, \u201cplays\u201d and \u201cplaying\u201d are the different variations of the word \u2013 \u201cplay\u201d. In other words, reducing words to their root."}}