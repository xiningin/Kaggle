{"cell_type":{"dd1bc55d":"code","b280072c":"code","5ac7dd74":"code","20896826":"code","fc3f4521":"code","e53c55d9":"code","722ceeda":"code","8f70b302":"code","b708364a":"code","30fde100":"code","0173175f":"code","c0d22b5d":"code","f7b60276":"code","e1a49544":"code","efe9198e":"code","51ecb27c":"code","dab508f8":"code","3d9c2510":"code","915405c5":"code","7e5d8009":"code","b22aba8c":"code","a33b7d57":"code","8c5f8c11":"code","eb7010ee":"markdown","5265ac29":"markdown","5cc2bb80":"markdown","a3b39d2c":"markdown","2bfd0200":"markdown","c50588e5":"markdown","19e5f48c":"markdown","eda05efe":"markdown","032b5845":"markdown","93d4bdff":"markdown","4e3e8417":"markdown","34cfff72":"markdown","2a00161a":"markdown","860df524":"markdown","6a32a176":"markdown","a2b8fcfc":"markdown","dd75004a":"markdown","025d1222":"markdown","ed589401":"markdown","41bf8220":"markdown","10b51da4":"markdown"},"source":{"dd1bc55d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nplt.style.use(\"classic\")\nfrom scipy import stats\npd.set_option(\"display.max_columns\",None)\npd.set_option(\"display.max_rows\",None)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b280072c":"df = pd.read_csv(\"\/kaggle\/input\/car-price-prediction\/CarPrice_Assignment.csv\")\ndf.head()","5ac7dd74":"df.info()","20896826":"#Checking Null Values\nn = msno.bar(df,color='gold')","fc3f4521":"plt.figure(figsize=(8,6))\nsns.jointplot(x = 'carlength', y = 'price',data= df,kind = 'kde',color='coral')\nplt.show()","e53c55d9":"plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(2,3,figsize=(10,8))\nsns.regplot(x = 'carlength', y = 'price',data= df,color='coral',ax=ax[0][0])\nsns.regplot(x = 'wheelbase', y = 'price',data= df,color='coral',ax=ax[0][1])\nsns.regplot(x = 'enginesize', y = 'price',data= df,color='coral',ax=ax[0][2])\nsns.regplot(x = 'horsepower', y = 'price',data= df,color='coral',ax=ax[1][0])\nsns.countplot(x='fueltype',hue = 'enginetype', data= df,ax=ax[1][1])\nsns.countplot(x='doornumber',hue = 'carbody', data= df,ax=ax[1][2])\n\nplt.tight_layout()\nplt.show()","722ceeda":"plt.figure(figsize=(8,6))\nsns.distplot(df['price'],fit = stats.norm,color='coral')\nplt.show()","8f70b302":"df['price'] = np.log(df['price'].values)\nplt.figure(figsize=(8,6))\nsns.distplot(df['price'],fit = stats.norm,color='coral')\nplt.show()","b708364a":"plt.figure(figsize=(10,9))\nsns.boxplot(data=df,palette='Set3')\nplt.xticks(rotation=90)\nplt.show()","30fde100":"plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(3,3,figsize=(10,8))\nsns.distplot(df['compressionratio'], fit = stats.norm,color='coral',ax=ax[0][0])\nsns.distplot(df['enginesize'], fit = stats.norm,color='coral',ax=ax[0][1])\nsns.distplot(df['horsepower'], fit = stats.norm,color='coral',ax=ax[0][2])\nsns.distplot(df['wheelbase'], fit = stats.norm,color='coral',ax=ax[1][0])\nsns.distplot(df['carwidth'], fit = stats.norm,color='coral',ax=ax[1][1])\nsns.distplot(df['curbweight'], fit = stats.norm,color='coral',ax=ax[1][2])\nsns.distplot(df['citympg'], fit = stats.norm,color='coral',ax=ax[2][0])\nsns.distplot(df['highwaympg'], fit = stats.norm,color='coral',ax=ax[2][1])\nsns.distplot(df['stroke'], fit = stats.norm,color='coral',ax=ax[2][2])\n\nplt.tight_layout()\nplt.show()","0173175f":"plt.rcParams['figure.figsize']=(10,8)\nplt.style.use(\"classic\")\ncolor = ['yellowgreen','gold','lightskyblue','coral','pink','orange']\nexplode = [0,0,0,0.01,0,0.4]\ndf['symboling'].value_counts().plot.pie(y='symboling',explode=explode,colors=color,startangle=50,shadow=True,autopct='%0.1f%%')","c0d22b5d":"plt.rcParams['figure.figsize']=(8,6)\nsns.countplot(x='enginelocation',hue = 'doornumber', data= df)\nplt.show()","f7b60276":"plt.rcParams['figure.figsize'] =(9,8)\nsns.catplot(x=\"carbody\", hue=\"fueltype\", col=\"doornumber\",\n                data=df, kind=\"count\",\n                height=6, aspect=.7,palette='Set3')\nplt.show()","e1a49544":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf['CarName'] = le.fit_transform(df['CarName'])\ndf['fueltype'] = le.fit_transform(df['fueltype'])\ndf['aspiration'] = le.fit_transform(df['aspiration'])\ndf['doornumber'] = le.fit_transform(df['doornumber'])\ndf['carbody'] = le.fit_transform(df['carbody'])\ndf['drivewheel'] = le.fit_transform(df['drivewheel'])\ndf['enginelocation'] = le.fit_transform(df['enginelocation'])\ndf['enginetype'] = le.fit_transform(df['enginetype'])\ndf['cylindernumber'] = le.fit_transform(df['cylindernumber'])\ndf['fuelsystem'] = le.fit_transform(df['fuelsystem'])","efe9198e":"from sklearn.model_selection import train_test_split\nx = df.drop(['car_ID','price'],axis=1)\ny = df['price']\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)","51ecb27c":"from sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom mlxtend import regressor\nfrom sklearn import metrics,linear_model,model_selection\nfrom sklearn.metrics import r2_score,mean_squared_error,mean_squared_log_error\nfrom sklearn.model_selection import cross_val_score","dab508f8":"lg =LGBMRegressor(n_estimators=1500)\nlg.fit(x_train,y_train)","3d9c2510":"y_pred_lg = lg.predict(x_test)\nlgbmetrics = pd.DataFrame({'Model': 'LightGBM',\n                          'r2score':r2_score(y_test,y_pred_lg),\n                          'MSE': metrics.mean_squared_error(y_test,y_pred_lg),\n                           'RMSE': np.sqrt(metrics.mean_squared_error(y_test,y_pred_lg)),\n                           'MSLE': metrics.mean_squared_log_error(y_test,y_pred_lg),\n                           'RMSLE':np.sqrt(metrics.mean_squared_log_error(y_test,y_pred_lg))             \n                          },index=[1])\n\nlgbmetrics","915405c5":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators=15,criterion='mse',random_state=25)\nrf.fit(x_train,y_train)","7e5d8009":"rf_pred = rf.predict(x_test)\nrfMetrics = pd.DataFrame({'Model': 'Random Forest',\n                          'r2score':r2_score(y_test,rf_pred),\n                          'MSE': metrics.mean_squared_error(y_test,rf_pred),\n                           'RMSE': np.sqrt(metrics.mean_squared_error(y_test,rf_pred)),\n                           'MSLE': metrics.mean_squared_log_error(y_test,rf_pred),\n                           'RMSLE':np.sqrt(metrics.mean_squared_log_error(y_test,rf_pred))             \n                          },index=[2])\n\nrfMetrics","b22aba8c":"frames = [lgbmetrics,rfMetrics]\nTrainingResult = pd.concat(frames)\nTrainingResult.style.background_gradient(cmap='Blues')","a33b7d57":"rf_pred = np.exp(rf_pred)\ny_test = np.exp(y_test)\nactualvspredicted = pd.DataFrame({\"Actual\":y_test,\"Predicted\":rf_pred})\nactualvspredicted.head().style.background_gradient(cmap='Blues')","8c5f8c11":"plt.figure(figsize=[8,6])\nsns.regplot(actualvspredicted['Predicted'],actualvspredicted['Actual'],truncate=False)\nplt.title('Actual vs Predicted')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')","eb7010ee":"Machine Learning model can not work with the object type data.So let's encode the object type data into numerical form,by using Label Encoder","5265ac29":">Here in this dataset we don't have any null values.So we don't need to deal with the Null values here","5cc2bb80":">LightGBM","a3b39d2c":">So most of them are normally Distributed","2bfd0200":">Symboling assigned insurance risk rating, A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.So  13.2 % auto are risky & 1.5% cars are preety safe than others ","c50588e5":"### Skewness Check in the Column to be Predicted\n\nWe need to be sure that in order to calculate accurate predictions, our column which is to be predicted should not be skewed. So, checking the distribution of the column SalePrice.","19e5f48c":">Importing necessary libraries & Load the Data","eda05efe":">  <h3>Model Building<\/h3>","032b5845":"><h3>DataSet Information:<\/h3>\t\t\t\t\t\t\n\t\t\t\t\t\t\n1.\tCar_ID:\t\t\tUnique id of each observation (Interger)\t\t\n2.\tSymboling:\t\t\tIts assigned insurance risk rating, A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.(Categorical) \t\t\n3.\tcarCompany:\t\t\tName of car company (Categorical)\t\t\n4.\tfueltype:\t\t\tCar fuel type i.e gas or diesel (Categorical)\t\t\n5.\taspiration:\t\t\tAspiration used in a car (Categorical)\t\t\n6.\tdoornumber:\t\t\tNumber of doors in a car (Categorical)\t\t\n7.\tcarbody:\t\t\tbody of car (Categorical)\t\t\n8.\tdrivewheel:\t\t\ttype of drive wheel (Categorical)\t\t\n9.\tenginelocation:\t\t\tLocation of car engine (Categorical)\t\t\n10.\twheelbase:\t\t\tWeelbase of car (Numeric)\t\t\n11.\tcarlength:\t\t\tLength of car (Numeric)\t\t\n12.\tcarwidth:\t\t\tWidth of car (Numeric)\t\t\n13.\tcarheight:\t\t\theight of car (Numeric)\t\t\n14.\tcurbweight:\t\t\tThe weight of a car without occupants or baggage. (Numeric)\t\t\n15.\tenginetype:\t\t\tType of engine. (Categorical)\t\t\n16.\tcylindernumber:\t\t\tcylinder placed in the car (Categorical)\t\t\n17.\tenginesize:\t\t\tSize of car (Numeric)\t\t\n18.\tfuelsystem:\t\t\tFuel system of car (Categorical)\t\t\n19.\tboreratio:\t\t\tBoreratio of car (Numeric)\t\t\n20.\tstroke:\t\t\tStroke or volume inside the engine (Numeric)\t\t\n21.\tcompressionratio:\t\t\tcompression ratio of car (Numeric)\t\t\n22.\thorsepower:\t\t\tHorsepower (Numeric)\t\t\n23.\tpeakrpm:\t\t\tcar peak rpm (Numeric)\t\t\n24.\tcitympg:\t\t\tMileage in city (Numeric)\t\t\n25.\thighwaympg:\t\t\tMileage on highway (Numeric)\t\t\n26.\tprice(Dependent variable):\t\t\tPrice of car (Numeric)\t\t","93d4bdff":">Random Forest","4e3e8417":"---\n\n<h1 style=\"text-align: center;font-size: 40px;\">Car Price Prediction<\/h1>\n\n---\n\n<center><img src=\"https:\/\/blkdiamondmafia.com\/wp-content\/uploads\/2017\/11\/satin-matte-black-lamborghini-aventador-lp700-4-bronze-gold-wheels-adv1-rims-j.jpg\n\"width=\"500\" height=\"600\"><\/center>\n\n---","34cfff72":">We can see that our data is positively Skewed.In order to bring it to Normal Distribution ,we can apply Log transformation over it","2a00161a":"><h3>Feature Engineering<\/h3>","860df524":">So,Random Forest gives us better accuracy than LightGBM.It gives us 90.5% accuracy with RMSE 0.164","6a32a176":">Data Visualization","a2b8fcfc":">Almost all of the cars have 2 doors & front engine & a small amount of cars have rear engine location & cars with rear engine location have 2 doors","dd75004a":">In order to get the accurate prediction our numerical values should be normally distributed.Let's check our Numerical values are Normally Distributed or not","025d1222":">Splitting data into train & test data","ed589401":"> They have positive relationship with Price,but there  are some outliers,so we need to remove those outliers,Since Outliers create problem to make a good Model","41bf8220":">Now let's compare Actual vs Predicted Value","10b51da4":">Plotting Actual vs Predicted Data"}}