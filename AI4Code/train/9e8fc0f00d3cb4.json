{"cell_type":{"fe366c89":"code","b1ec4276":"code","de01f614":"code","bd6c416e":"code","f5d405d5":"code","ce2ea4e7":"code","4edcd973":"code","34c779f3":"code","33bedbca":"code","0da546bf":"code","834ebbbd":"code","8e8bb8e0":"code","f693c282":"code","7ae82d23":"code","5e5effb9":"markdown","aaa0f39b":"markdown","877be2cd":"markdown","8cfbaa6a":"markdown","041ee0ca":"markdown","e8880a3f":"markdown"},"source":{"fe366c89":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b1ec4276":"from tensorflow.keras import layers, optimizers, models, callbacks, applications\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom shutil import copy2","de01f614":"train_dir = '..\/input\/train\/train\/'\ntest_dir = '..\/input\/test\/test\/'\n\ndf = pd.read_csv('..\/input\/train.csv')\ndf.head()","bd6c416e":"labels = df['has_cactus'].tolist()\nimg_paths = df['id'].tolist()","f5d405d5":"import cv2\n\nindices = np.random.randint(0, 17500, size = 16)\nfig = plt.figure(figsize = (10, 10))\n\nfor i in range(16):\n    image = cv2.imread('..\/input\/train\/train\/{}'.format(img_paths[indices[i]]))\n    plot = fig.add_subplot(4, 4, i + 1)\n    title = 'No' if labels[indices[i]] == 0 else 'Yes'\n    plot.set_title(title)\n    plot.imshow(image)\n    \nplt.show()","ce2ea4e7":"def build_model():\n    \n    model_input = layers.Input(shape = [32, 32, 3])\n    X = applications.densenet.DenseNet121(weights = 'imagenet', include_top = False, classes = 1)(model_input)\n    X = layers.Flatten()(X)\n    model_output = layers.Dense(1, activation = 'sigmoid')(X)\n    \n    return models.Model(model_input, model_output)\n    \n","4edcd973":"model = build_model()\nmodel.compile(loss = 'binary_crossentropy', optimizer = optimizers.Adam(lr = 0.0001), metrics = ['accuracy'])\nmodel.summary()\n","34c779f3":"def split_dataframe(csv_file):\n    df = pd.read_csv(csv_file)\n    \n    train_df = df.iloc[:14000, :]\n    train_df['has_cactus'] = train_df['has_cactus'].apply(str)\n    val_df = df.iloc[14000:, :]\n    val_df['has_cactus'] = val_df['has_cactus'].apply(str)\n    \n    return train_df, val_df\n\ntrain_df, val_df = split_dataframe('..\/input\/train.csv')","33bedbca":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_df, val_df = split_dataframe('..\/input\/train.csv')\n\ntrain_gen = ImageDataGenerator(\n            rescale = 1.\/255,\n            validation_split = 0.15,\n            shear_range = 0.2,\n            zoom_range = 0.2,\n            horizontal_flip = True,\n            vertical_flip = True,\n            rotation_range = 10\n        )\n\ntrain_gen = train_gen.flow_from_dataframe(\n            dataframe = train_df,\n            directory = train_dir,\n            x_col = 'id',\n            y_col = 'has_cactus',\n            target_size = (32, 32),\n            color_mode = 'rgb',\n            class_mode = 'binary',\n            batch_size = 128,\n            shuffle = True,\n        )\n\nval_gen = ImageDataGenerator(rescale = 1.\/255, validation_split = 0.15)\n\nval_gen = val_gen.flow_from_dataframe(\n            dataframe = val_df,\n            directory = train_dir,\n            x_col = 'id',\n            y_col = 'has_cactus',\n            target_size = (32, 32),\n            color_mode = 'rgb',\n            class_mode = 'binary',\n            batch_size = 128,\n            shuffle = True,\n        )","0da546bf":"checkpoint = callbacks.ModelCheckpoint(\n            'model.h5',\n            monitor = 'val_loss',\n            verbose = 0,\n            save_best_only = True,\n            save_weights_only = False,\n            mode = 'auto'\n        )\n\nregulate_lr = callbacks.ReduceLROnPlateau(monitor = 'val_loss', min_lr = 1e-5, patience = 3)\n\nmodel.fit_generator(\n    train_gen,\n    steps_per_epoch = 14000 \/\/ 128,\n    validation_data = val_gen,\n    validation_steps = 14000 \/\/ 128,\n    epochs = 60,\n    callbacks = [checkpoint, regulate_lr]\n)\n","834ebbbd":"# model = models.load_model('.\/models\/' + 'model12.h5')\nmodel = models.load_model('model.h5')\nmodel.evaluate_generator(val_gen, verbose = 1)\n","8e8bb8e0":"img_paths = os.listdir('..\/input\/test\/test\/')\nfinal_model = model\n\nindices = np.random.randint(0, 3500, size = 16)\nfig = plt.figure(figsize = (10, 10))\n\nfor i in range(16):\n    image = cv2.imread('..\/input\/test\/test\/{}'.format(img_paths[indices[i]]))\n    plot = fig.add_subplot(4, 4, i + 1)\n    label = final_model.predict(image.reshape((1, 32, 32, 3)))\n    title = 'No' if labels[indices[i]] == 0 else 'Yes'\n    plot.set_title(title)\n    plot.imshow(image)\n    \nplt.show()\n","f693c282":"from tqdm import tqdm\n\nsubmit = pd.read_csv('..\/input\/sample_submission.csv')\ntest = []\n\nfor image in tqdm(submit['id']):\n    test.append(cv2.imread('..\/input\/test\/test\/' + image))\n\ntest = np.array(test)\nprint(test[0].shape)\n\n# print(submit['id'])\n","7ae82d23":"test = test \/ 255\npreds = final_model.predict(test, verbose = 1)\n\nsubmit['has_cactus'] = preds\nsubmit.head(10)\n\nsubmit.to_csv('sample_submission.csv', index = False)","5e5effb9":"**Visualize images**\n\nHere we plot random images from the dataset with labels set as title","aaa0f39b":"**Create The Model**\n\nAs we are more or less done with the data preparation phase it is high time that we build the model.","877be2cd":"**Initializing the generator**\n\nNow we should prepare the model for training. We take the help of ***ImageDataGenerator*** class over here which will take care of a lot of the hard tasks like prepairing batches, data augmentation, etc. during trainnig of the model. Data augmentation is important and is mostly done to avoid overfitting. Here we also rescale the data, where we transform the pixels into values between 0 and 1.","8cfbaa6a":"**Training the model**\n\nCallbacks are helpful to conduct a meaningful training of the model. Here we use two callbacks.\n\nThe ***checkpoint*** is used to\n\n*   save the model performing best on the validation set (which actually is the measure of the extent of generalizability of the model on unseen data) through each epoch and\n*   save model in each epoch so that we can manually choose, the model performing best on the validation set, for production once the training ends.\n(that is how we choose the model performing best throughout the training)\n\nThe ***reduce_lr*** is used to ensure a connsistent descent of the loss. Here the learning rate is reduced by a specified factor when the curve tends to plateau.\n\nThen we use the ***fit_generator*** function to train the model.\n\n","041ee0ca":"**See performance for real**\n","e8880a3f":"**Compiling Model**\n\nHere we compile the model. As we have only one value as output indicating 0 or 1 *binary_crossentropy* is the loss that should be chosen and we choose *adam* as the optimizer."}}