{"cell_type":{"c74922e9":"code","2d933b94":"code","52437863":"code","e84e522d":"code","1d7b441f":"code","1adb51bf":"code","d4d85315":"code","af8ae384":"code","a6ffad75":"code","756553c1":"code","01388c67":"code","9f216083":"code","455b434e":"code","a9c9cf8a":"code","262c120f":"code","553db393":"code","ae5ecf50":"code","a49a9ed8":"code","8a03d34d":"code","6b136382":"code","c5a00cb5":"code","cac624a2":"code","bca3c0e1":"code","98e1dc34":"code","5fec40a2":"code","e8411a39":"code","ca5f1e28":"markdown"},"source":{"c74922e9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2d933b94":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain.head()","52437863":"test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest.head()","e84e522d":"print(train.info())\nprint(\"-------Missing values--------\")\nprint(train.isnull().sum())\nprint(\"-------Missing percentage--------\")\nprint(train.isnull().sum()\/len(train))","1d7b441f":"col = ['Name','Ticket','Cabin']\ntrain = train.drop(col,axis=1)\ntrain.head(2)","1adb51bf":"#train = train.dropna()\ntrain.columns","d4d85315":"cols = ['Survived','Pclass','Sex','SibSp','Parch','Embarked']\n\nfor col in cols:\n    print(col)\n    print(train[col].value_counts())","af8ae384":"dummies = []\ncols = ['Sex','Embarked','Pclass']\nfor col in cols:\n    dummies.append(pd.get_dummies(train[col]))\n    \ndummies_df = pd.concat(dummies,axis=1)\ndummies_df.head()","a6ffad75":"train = pd.concat((train,dummies_df),axis=1)\ntrain = train.drop(['Sex','Embarked','Pclass'],axis=1)\ntrain.head(2)","756553c1":"train.isnull().sum()","01388c67":"train['Age'] = train['Age'].interpolate()","9f216083":"train.describe()","455b434e":"y = train['Survived']\nX = train.drop(['Survived','PassengerId'],axis=1)","a9c9cf8a":"from sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0)","262c120f":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nmodel = DecisionTreeClassifier(max_depth = 5)\nmodel.fit(X_train,y_train)\ncv = cross_val_score(model,X_train,y_train,cv=10)\nprint(cv)\ny_pred = model.predict(X_test)\naccuracy_score(y_test,y_pred)","553db393":"from sklearn import ensemble\nm1 = ensemble.RandomForestClassifier(n_estimators=100)\nm1.fit (X_train, y_train)\nm1.score (X_test, y_test)\n","ae5ecf50":"import lightgbm as lgb\nm2 = lgb.LGBMClassifier(n_estimators=100)\nm2.fit (X_train, y_train)\nm2.score (X_test, y_test)","a49a9ed8":"m3 = ensemble.GradientBoostingClassifier(n_estimators=50)\nm3.fit (X_train, y_train)\nm3.score (X_test, y_test)\n","8a03d34d":"\"\"\"\nparameters = {\n\n    'application': 'binary',\n    'objective': 'binary',\n    'metric': 'auc',\n    'num_leaves': 31,\n    'feature_fraction': 0.5,\n    'bagging_fraction': 0.5,\n    'bagging_freq': 20,\n    'learning_rate': 0.05,\n    'verbose': 0\n}\n\"\"\"","6b136382":"\"\"\"\nimport lightgbm as lgb\nfrom sklearn import metrics\nmodel = lgb.LGBMClassifier(parameters,num_boost_round=5000,early_stopping_rounds=100)\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\nprint(metrics.classification_report(y_test,y_pred))\nprint(metrics.confusion_matrix(y_test,y_pred))\n#model.score(X_test, y_test)\n\"\"\"","c5a00cb5":"col = ['Name','Ticket','Cabin']\ntest = test.drop(col,axis=1)\ndummies = []\ncols = ['Sex','Embarked','Pclass']\nfor col in cols:\n    dummies.append(pd.get_dummies(test[col]))\n    \ndummies_df = pd.concat(dummies,axis=1)\ntest = pd.concat((test,dummies_df),axis=1)\ntest = test.drop(['Sex','Embarked','Pclass'],axis=1)\ntest.head(2)","cac624a2":"test['Age'] = test['Age'].interpolate()\ntest['Fare'] = test['Fare'] .fillna(test['Fare'].mean())","bca3c0e1":"X_res = test.drop(['PassengerId'],axis=1)","98e1dc34":"y_pred = m3.predict(X_res)","5fec40a2":"sub = pd.DataFrame(test['PassengerId'])\nsub['Survived'] = y_pred","e8411a39":"sub.head()\nsub.to_csv('titanic_results5.csv',index=False)","ca5f1e28":"## **Get 79% score in public LB . Please upvote if helpfull**"}}