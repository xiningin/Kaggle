{"cell_type":{"4228a485":"code","da146bee":"code","d7913095":"code","ef8fe136":"code","eb25cbbf":"code","62e868eb":"code","a651979b":"code","5f82cd45":"code","34a333a7":"code","cd592da2":"code","81fac819":"code","8878163c":"code","fb9fbad6":"code","411306bf":"code","3791f4d9":"code","88db38c2":"code","0f368323":"code","51740427":"code","86ff1d0d":"code","f8c57a69":"code","ef198a61":"code","a36d7235":"markdown","962ff2ee":"markdown","ec904dde":"markdown","ccc06ba8":"markdown","5986201e":"markdown","02dfe269":"markdown"},"source":{"4228a485":"%%time\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\nimport matplotlib.pyplot as  py\nimport cv2\nimport pandas as pd\nfrom fastai.vision import *\nimport os\nimport glob\nimport imageio\nimport warnings\nwarnings.filterwarnings(\"ignore\")","da146bee":"%%time\nHEIGHT = 137\nWIDTH = 236\nSIZE = 128\nstats = (0.0692, 0.2051)\n#check https:\/\/www.kaggle.com\/iafoss\/image-preprocessing-128x128\nTEST = ['\/kaggle\/input\/bengaliai-cv19\/test_image_data_0.parquet',\n        '\/kaggle\/input\/bengaliai-cv19\/test_image_data_1.parquet',\n        '\/kaggle\/input\/bengaliai-cv19\/test_image_data_2.parquet',\n        '\/kaggle\/input\/bengaliai-cv19\/test_image_data_3.parquet']\ndef bbox(img):\n    rows = np.any(img, axis=1)\n    cols = np.any(img, axis=0)\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n    return rmin, rmax, cmin, cmax\n\ndef crop_resize(img0, size=SIZE, pad=16):\n    #crop a box around pixels large than the threshold \n    #some images contain line at the sides\n    ymin,ymax,xmin,xmax = bbox(img0[5:-5,5:-5] > 80)\n    #cropping may cut too much, so we need to add it back\n    xmin = xmin - 13 if (xmin > 13) else 0\n    ymin = ymin - 10 if (ymin > 10) else 0\n    xmax = xmax + 13 if (xmax < WIDTH - 13) else WIDTH\n    ymax = ymax + 10 if (ymax < HEIGHT - 10) else HEIGHT\n    img = img0[ymin:ymax,xmin:xmax]\n    #remove lo intensity pixels as noise\n    img[img < 28] = 0\n    lx, ly = xmax-xmin,ymax-ymin\n    l = max(lx,ly) + pad\n    #make sure that the aspect ratio is kept in rescaling\n    img = np.pad(img, [((l-ly)\/\/2,), ((l-lx)\/\/2,)], mode='constant')\n    return cv2.resize(img,(size,size))\nima=[]\nfor fname in TEST:\n    df = pd.read_parquet(fname)\n        #the input is inverted\n    data = 255 - df.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH).astype(np.uint8)\n    for idx in range(len(df)):\n        #name = df.iloc[idx,0]\n        #normalize each image by its max val\n        img = (data[idx]*(255.0\/data[idx].max())).astype(np.uint8)\n        img = crop_resize(img)\n        ima.append(img)","d7913095":"del TEST\ndel HEIGHT\ndel WIDTH\ndel SIZE\ndel img\ndel data\ndel df\n       ","ef8fe136":"%%time\nim128=np.array(ima)\ndef save_imgs(path:Path, data):\n    path.mkdir(parents=True,exist_ok=True)\n    for i in range(len(data)):\n        imageio.imsave(path\/'{}.png'.format(i),data[i])\n        \nsave_imgs(Path('\/data\/test'),im128)\n","eb25cbbf":"#!cp \/kaggle\/input\/grapheme-imgs-128x128 -r \/data\/train\ndel ima\ndel im128","62e868eb":"%time\nptrain = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/train.csv')\nptrain['Image_path'] = ptrain.apply(lambda row: '\/kaggle\/input\/grapheme-imgs-128x128\/' + row.image_id + '.png', axis = 1)\nptrain['grapheme_root'] = ptrain.apply(lambda row: str(row.grapheme_root), axis = 1)\nptrain['vowel_diacritic'] = ptrain.apply(lambda row: str(row.vowel_diacritic), axis = 1)\nptrain['consonant_diacritic'] = ptrain.apply(lambda row: str(row.consonant_diacritic), axis = 1)\n","a651979b":"%time\nptra=glob.glob('\/kaggle\/input\/grapheme-imgs-128x128\/*')\np1=pd.DataFrame(ptra,columns=['Image_path'])\ndef process(s):\n    return str(s).split('\/')[4]\np1['Image_path']=p1['Image_path'].apply(process)\nptrain['Image_path']=ptrain['Image_path'].apply(process)\np3=p1.merge(ptrain,on='Image_path',)","5f82cd45":"del ptrain\ndel p1\ndel ptra","34a333a7":"%time\ntfms = get_transforms(do_flip=False,)\ndata = ImageDataBunch.from_folder('..\/input', \n                                  train=\"grapheme-imgs-128x128\",\n                                  size=128,bs=128).normalize(stats)\ntest=ImageList.from_folder('\/data\/test')","cd592da2":"data.add_test(test,tfm_y=False)","81fac819":"%%time\ndata_cd = ImageDataBunch.from_df(path='\/kaggle\/input\/',folder='grapheme-imgs-128x128',df=p3,bs=128,size=128,label_col='consonant_diacritic',tfm_y=False).normalize(imagenet_stats)\ndata_gr = ImageDataBunch.from_df(path='\/kaggle\/input\/',folder='grapheme-imgs-128x128',df=p3,bs=128,size=128,label_col='grapheme_root',tfm_y=False).normalize(imagenet_stats)\ndata_vd = ImageDataBunch.from_df(path='\/kaggle\/input\/',folder='grapheme-imgs-128x128',df=p3,bs=128,size=128,label_col='vowel_diacritic',tfm_y=False).normalize(imagenet_stats)","8878163c":"%%time\nif not os.path.exists('\/root\/.cache\/torch\/checkpoints'):\n        os.makedirs('\/root\/.cache\/torch\/checkpoints')\n!cp \/kaggle\/input\/fastai-pretrained-models\/densenet121-a639ec97.pth \/root\/.cache\/torch\/checkpoints\/densenet121-a639ec97.pth\n\nlearn_cd = cnn_learner(data_cd, models.densenet121, metrics=[error_rate, accuracy],model_dir = Path('..\/kaggle\/working'),).to_fp16()\nlearn_vd = cnn_learner(data_vd, models.densenet121, metrics=[error_rate, accuracy],model_dir = Path('..\/kaggle\/working'),).to_fp16()\nlearn_gr = cnn_learner(data_gr, models.densenet121, metrics=[error_rate, accuracy], model_dir = Path('..\/kaggle\/working'),).to_fp16()","fb9fbad6":"del data_cd\ndel data_vd\ndel data_gr","411306bf":"%%capture\nlearn_gr.load('\/kaggle\/input\/modelgr\/best_gr_model')\nlearn_cd.load('\/kaggle\/input\/models\/best_cd_model',)\nlearn_vd.load('\/kaggle\/input\/models\/best_vd_model',)","3791f4d9":"%%capture\nm1_pred1=[]\nm2_pred2=[]\nm3_pred3=[]\nfor i in data.test_ds:\n    y1=learn_cd.predict(i[0])\n    y2=learn_vd.predict(i[0])\n    y3=learn_gr.predict(i[0])\n    m2_pred2.append(y1[1].item())\n    m3_pred3.append(y2[1].item())\n    m1_pred1.append(y3[1].item())\n    del y1\n    del y2\n    del y3","88db38c2":"del learn_gr\ndel learn_vd\ndel learn_cd","0f368323":"# Converting data to submission format\n\n# m1 CD\n# m2 VD\nsample_sub = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/sample_submission.csv')\ncd = 0 \ncd_itr = 0\ngr = 1\ngr_itr = 0\nvd = 2 \nvd_itr = 0\nlength = sample_sub['target'].shape[0]\nfor i in range(length):\n    if(i==gr):\n        sample_sub.at[i,'target'] = m1_pred1[gr_itr]\n        gr_itr+=1\n        gr+=3\n    if(i==cd):\n        sample_sub.at[i,'target'] = m2_pred2[cd_itr]\n        cd_itr+=1\n        cd+=3\n    elif(i==vd):\n        sample_sub.at[i,'target'] = m3_pred3[vd_itr]\n        vd_itr+=1\n        vd+=3\n#print(sample_sub.head())\ndel cd\ndel cd_itr\ndel gr\ndel gr_itr\ndel vd\ndel vd_itr\ndel length","51740427":"# Writing to submission csv file\nsample_sub.to_csv('submission.csv', index=False)","86ff1d0d":"sample_sub.head()","f8c57a69":"del sample_sub","ef198a61":"!ls","a36d7235":"# Prediction","962ff2ee":"# Databunch creation for training images","ec904dde":"# Databunch creation for test images","ccc06ba8":" <h1>Preprocessing to obtain 128x128 images<\/h1>","5986201e":"# Model loading ","02dfe269":"# Saving the images in a directory\n"}}