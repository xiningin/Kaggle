{"cell_type":{"038b22fd":"code","412530c1":"code","d128f238":"code","ea114b12":"code","a7d5e3ec":"code","b4ace279":"code","ed0efb37":"code","3d3ef7c3":"code","7b437735":"code","a0d1b823":"code","faa555fe":"code","8eacc5f4":"code","eb32d723":"code","71e7b574":"code","2602c681":"code","793f4be1":"code","65d44146":"code","316c3e2b":"code","b64b09a9":"code","78480d73":"code","0ae574ef":"code","0a21dc0a":"code","e185fac5":"code","baef2bd8":"code","2a5fbe7a":"code","2ce0f2d8":"code","7306b52a":"code","93a2baa0":"code","8cb29ed7":"code","28adf6ba":"code","1dfa88ed":"code","cfa8e50b":"code","5016fc0c":"code","c6ea683e":"code","51563c57":"code","d43f7aa7":"code","e961d0b1":"code","0bf6365b":"code","603f08d6":"code","96cb4b0a":"code","e2201020":"code","2ef7f51b":"code","7e8a9788":"code","3bdcbc46":"code","89450893":"code","8ab6f185":"code","65370ab2":"code","b856b094":"markdown","2721ce55":"markdown","eeba822e":"markdown"},"source":{"038b22fd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","412530c1":"## Relevant imports\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport re\n\nfrom collections import defaultdict\n\n# Tokenizer imports\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import WordPunctTokenizer\nfrom nltk.tokenize import regexp_tokenize\n\n# NLTK corpus and stemming\/lemmatizer imports\nfrom nltk import pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.corpus import wordnet\nfrom nltk.stem import WordNetLemmatizer\n\n# Scikit-learn packages\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import model_selection, naive_bayes, svm, linear_model\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Gensim imports\nimport gensim","d128f238":"data = pd.read_csv(\"\/kaggle\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv\")","ea114b12":"data.shape","a7d5e3ec":"data.head()","b4ace279":"data.sentiment.unique()","ed0efb37":"data.sentiment.value_counts()","3d3ef7c3":"data.dtypes","7b437735":"data.review.duplicated().sum()","a0d1b823":"data.drop_duplicates(keep = \"first\", inplace = True)\ndata.shape","faa555fe":"data.isna().sum()","8eacc5f4":"# Convert reviews to lowercase\n\ndata.review = data.review.apply(lambda x: str(x).lower())","eb32d723":"data.reset_index(inplace = True)","71e7b574":"data = data.drop(\"index\", axis = 1)","2602c681":"data","793f4be1":"def strip_html(raw_text):\n  find_html = re.compile('<.*?>')\n  clean_text = re.sub(find_html, '', raw_text)\n  return clean_text","65d44146":"data.review = data.review.apply(lambda x: strip_html(x))","316c3e2b":"data","b64b09a9":"# Running WhiteSpace tokenizer \nwpTokenizer = WordPunctTokenizer()\ndata[\"review_tokenized\"] = [wpTokenizer.tokenize(text) for text in data[\"review\"]]","78480d73":"data","0ae574ef":"# Stopwords removal & WordNet lemmatization \n\n# Define POS tags \ntag_map = defaultdict(lambda : wordnet.NOUN)\ntag_map['J'] = wordnet.ADJ\ntag_map['V'] = wordnet.VERB\ntag_map['R'] = wordnet.ADV","0a21dc0a":"for index, text in enumerate(data.review_tokenized):\n    if index % 1000 == 0:\n        print(index)\n#     print(\"-\" * 50)\n    word_list = []\n    wordnet_lemmatizer = WordNetLemmatizer()\n    for word, tag in pos_tag(text):\n        if word not in stopwords.words(\"english\") and word.isalpha():\n            word_processed = wordnet_lemmatizer.lemmatize(word, tag_map[tag[0]])\n            word_list.append(word_processed)\n    data.loc[index, \"review_tokenized_cleaned\"] = str(word_list)","e185fac5":"data","baef2bd8":"data.review_tokenized_cleaned.isna().sum()","2a5fbe7a":"train_X, test_X, train_y, test_y = model_selection.train_test_split(data.review_tokenized_cleaned, data.sentiment, test_size = 0.3, random_state =1)","2ce0f2d8":"print(train_X.shape)\nprint(test_X.shape)\nprint(train_y.shape)\nprint(test_y.shape)","7306b52a":"test_y.value_counts()","93a2baa0":"train_y.value_counts()","8cb29ed7":"label_enc = LabelEncoder()\ntrain_y = label_enc.fit_transform(train_y)\ntest_y = label_enc.transform(test_y)","28adf6ba":"print(np.unique(test_y, return_counts = True))\nprint(np.unique(train_y, return_counts = True))","1dfa88ed":"tfidf_vect = TfidfVectorizer(max_features = 5000)\ntfidf_vect.fit(data.review_tokenized_cleaned)","cfa8e50b":"train_X_tfidf = tfidf_vect.transform(train_X)\ntest_X_tfidf = tfidf_vect.transform(test_X)","5016fc0c":"train_X_tfidf_dense = train_X_tfidf.todense()\ntest_X_tfidf_dense = test_X_tfidf.todense()","c6ea683e":"nb_model = naive_bayes.GaussianNB()\nnb_model.fit(train_X_tfidf_dense, train_y)","51563c57":"preds_nb = nb_model.predict(test_X_tfidf_dense)","d43f7aa7":"preds_nb.shape","e961d0b1":"accuracy_score(preds_nb, test_y)","0bf6365b":"confusion_matrix(test_y, preds_nb)","603f08d6":"print(classification_report(test_y, preds_nb))","96cb4b0a":"svm = svm.SVC(C = 1.0, kernel = \"linear\", degree = 3, gamma = \"auto\")\nsvm.fit(train_X_tfidf, train_y)","e2201020":"preds_svm = svm.predict(test_X_tfidf)\nprint(preds_svm.shape)","2ef7f51b":"accuracy_score(preds_svm, test_y)","7e8a9788":"print(classification_report(test_y, preds_svm))","3bdcbc46":"log_reg = linear_model.LogisticRegression(solver = \"lbfgs\")\nlog_reg.fit(train_X_tfidf, train_y)","89450893":"preds_log_reg = log_reg.predict(test_X_tfidf)\npreds_log_reg.shape","8ab6f185":"accuracy_score(preds_log_reg, test_y)","65370ab2":"print(classification_report(test_y, preds_log_reg))","b856b094":"### Modelling Multinomial Naives Bayes","2721ce55":"### Logistic Regression","eeba822e":"### Support Vector Machine Classifier\n\nTraining can take some time, grab a coffee in the meanwhile :)"}}