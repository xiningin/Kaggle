{"cell_type":{"13960c81":"code","45056c46":"code","2b0ec94c":"code","5b414b16":"code","30a33527":"code","4d5903c2":"code","bd4d1eb9":"code","1f65221f":"code","beb69e49":"code","12fc3d84":"code","2f54624b":"code","b1ccf62f":"code","f36da194":"code","0afa089e":"code","a5df0522":"code","8aac7622":"code","5b3baad2":"markdown","86c1c023":"markdown","33ce8d7b":"markdown","ff156d8d":"markdown","08ed7997":"markdown","b94301d4":"markdown","b2125a9c":"markdown","e9075ed0":"markdown","edf35aed":"markdown"},"source":{"13960c81":"%%time\n### BLOCO DE IMPORTA\u00c7\u00c3O DE BIBLIOTECAS ###\n\n# Importando Bibliotecas b\u00e1sicas\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Importando Bibliotecas do Keras\nimport keras\nfrom keras.models import Input,Model,Sequential,load_model\nfrom keras.layers import Activation,Add,BatchNormalization,Conv2D,Dropout\nfrom keras.layers import Dense,GlobalAveragePooling2D,MaxPooling2D\nfrom keras.optimizers import adam\n# Biblioteca de manipula\u00e7\u00e3o de imagens para Python\nfrom PIL import Image\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Importando Biblioteca de intera\u00e7\u00e3o com o Sistema Operacional\nimport os\nimport zipfile as zip\nimport shutil","45056c46":"%%time\n### BLOCO DE ENTENDIMENTO DA ESTRUTURA ANTIGA DE PASTAS ###\n\n# Listando o conte\u00fado da pasta \"..\/input\/aerial-cactus-identification\"\n#print(os.listdir(\"..\/input\/aerial-cactus-identification\"))\n\n# Listando o conte\u00fado da pasta \"..\/input\/aerial-cactus-identification\/train\"\n#print(os.listdir(\"..\/input\/aerial-cactus-identification\/train\"))\n\n# Listando o conte\u00fado da pasta \"..\/input\/aerial-cactus-identification\/test\"\n#print(os.listdir(\"..\/input\/aerial-cactus-identification\/test\"))\n\n# Listando o primeiro arquivo de imagem da pasta \"..\/input\/aerial-cactus-identification\/train\/train\"\n#print(os.listdir(\"..\/input\/aerial-cactus-identification\/train\/train\")[0])\n\n# Listando o primeiro arquivo de imagem da pasta \"..\/input\/aerial-cactus-identification\/test\/test\"\n#print(os.listdir(\"..\/input\/aerial-cactus-identification\/test\/test\")[0])","2b0ec94c":"%%time\n### BLOCO DE CRIA\u00c7\u00c3O DA NOVA ESTRUTURA DE PASTAS ###\n\n# Listando o conte\u00fado da pasta \"input\"\nprint(os.listdir(\"..\/input\"))\n\n# Listando o conte\u00fado da pasta \"aerial-cactus-identification\"\nprint(os.listdir(\"..\/input\/aerial-cactus-identification\"))\n\n# Extraindo as imagens de treinamento\nwith zip.ZipFile(\"..\/input\/aerial-cactus-identification\/train.zip\", \"r\") as zipObjTrain:\n   # Extraindo todos os arquivos na pasta de trabalho\n   zipObjTrain.extractall()\n\n# Listando o conte\u00fado da pasta \"..\"\nprint(os.listdir(\"..\"))\n\n# Listando o conte\u00fado da pasta \"..working\"\nprint(os.listdir(\"..\/working\"))\n\n# Listando a primeira imagem na pasta \"..working\/train\"\nprint(os.listdir(\"..\/working\/train\")[0])\n\n# Contando a quantidade de imagens existentes na pasta \"..working\/train\"\nprint(len(os.listdir(\"..\/working\/train\")))\n\n# Extraindo as imagens de teste\nwith zip.ZipFile(\"..\/input\/aerial-cactus-identification\/test.zip\", \"r\") as zipObjTest:\n   # Extraindo todos os arquivos na pasta de trabalho\n   zipObjTest.extractall()\n\n# Listando a primeira imagem na pasta \"..working\/test\"\nprint(os.listdir(\"..\/working\/test\")[0])\n\n# Contando a quantidade de imagens existentes na pasta \"..working\/test\"\nprint(len(os.listdir(\"..\/working\/test\")))","5b414b16":"%%time\n### BLOCO DE DEFINI\u00c7\u00c3O DAS PASTAS ONDE SE ENCONTRAM AS IMAGENS\n\n# Pasta das imagens de treinamento\nTRAIN_DATA_PATH = \"..\/working\/train\"\nprint(TRAIN_DATA_PATH)\n\n# Pasta das imagens de teste\nTEST_DATA_PATH = \"..\/working\/test\"\nprint(TEST_DATA_PATH)\n\n# Sele\u00e7\u00e3o da primeira imagem de treinamento a t\u00edtulo de exemplo\nexemplo = TRAIN_DATA_PATH +'\/'+ os.listdir(TRAIN_DATA_PATH)[0]\nprint(exemplo)\n\n# Transforma\u00e7\u00e3o da imagem de exemplo em um array\n# O array resultante corresponde a um array tridimensional, formado por tr\u00eas arrays, sendo:\n#     - posi\u00e7\u00e3o horizontal do pixel;\n#     - posi\u00e7\u00e3o vertical do pixel;\n#     - trinca de valores RGB do pixel;\nnp.array(Image.open(exemplo)).shape","30a33527":"%%time\n### BLOCO DE CARREGAMENTO DOS DADOS DE CONTROLE ###\n\n# Defini\u00e7\u00e3o dos Data Frames\ndf_train = pd.read_csv('..\/input\/aerial-cactus-identification\/train.csv')\ndf_test = pd.read_csv('..\/input\/aerial-cactus-identification\/sample_submission.csv')\n\n# Visualiza\u00e7\u00e3o das 5 primeiras linhas do Data Frame de treinamento\ndf_train.head(5)","4d5903c2":"def plot_roc_auc(truelabel, pred):\n    fpr, tpr, thresholds = sklearn.metrics.roc_curve(truelabel, pred)\n    auc = sklearn.metrics.auc(fpr, tpr)\n    print(auc)\n\n    plt.plot(fpr, tpr, label='ROC curve (auc = %.6f)'%auc)\n    plt.fill_between(x=fpr, y1=tpr,facecolor='yellow', alpha=0.5 )\n    plt.legend()\n    plt.title('ROC curve')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.grid(True)\n    plt.show()\n    return auc","bd4d1eb9":"%%time\n### BLOCO DE VISUALIZA\u00c7\u00c3O DE 32 IMAGENS ###\n\nfig, ax = plt.subplots(4, 8, figsize=(12,6))\nfor i in range(32):\n    ax[i\/\/8][i%8].tick_params(labelbottom=False, labelleft=False, bottom=False, left=False,) \n    target = df_train.iloc[i]['has_cactus']\n    ax[i\/\/8][i%8].set_title(f'{i} -> {target}')\n    ax[i\/\/8][i%8].imshow(np.array(Image.open(TRAIN_DATA_PATH +'\/'+ df_train.iloc[i]['id'])),)\nplt.tight_layout()    ","1f65221f":"%%time\n### BLOCO DE VERIFICA\u00c7\u00c3O DA PROPOR\u00c7\u00c3O DE IMAGENS QUE S\u00c3O CACTOS ###\n\n# Gr\u00e1fico de barras\nsns.countplot(df_train.has_cactus)\n\n# Rela\u00e7\u00e3o num\u00e9rica \"n\u00e3o-cacto \/ cacto\"\nprint ('target 0:1->',len(df_train[df_train.has_cactus==0])\/len(df_train[df_train.has_cactus==1]))","beb69e49":"%%time\n### BLOCO DE DEFINI\u00c7\u00c3O DOS ARRAYS DE VARI\u00c1VEIS E DE TARGETS ###\n# Neste caso o array de vari\u00e1veis cont\u00e9m o array tridimensional de cada imagem, com seus valores divididos por 255\n\n# Data Frame de treinamento\ntmp = []\nfor i in range(len(df_train)):\n    tmp.append(np.array(Image.open(TRAIN_DATA_PATH +'\/'+ df_train.iloc[i]['id'])))\nX_train, y_train = np.array(tmp)\/255, df_train['has_cactus']\n\n# Data Frame de teste\ntmp = [] \nfor i in range(len(df_test)):\n    tmp.append(np.array(Image.open(TEST_DATA_PATH +'\/'+ df_test.iloc[i]['id'])))\nX_test = np.array(tmp)\/255\ndel tmp\n\n# Visualiza\u00e7\u00e3o dos arrays criados\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape)\n# 17.500 observa\u00e7\u00f5es (imagens) no Data Frame de Treinamento e 4.000 no Data Frame de Teste","12fc3d84":"%%time\n### BLOCO DE DEFINI\u00c7\u00c3O DO MODELO DE MACHINE LEARNING ###\n\n# Explica\u00e7\u00e3o do comando: model.add(Conv2D(64,(3,3),padding='same',input_shape=(input_shape)))\n# Conv2D(64 ===> Quantidade de 'features map' que ser\u00e1 utilizada na convolu\u00e7\u00e3o\n# Conv2D(64,(3,3) ===> Tamanho da matriz de filtro\n# padding='same' ===> Em uma convolu\u00e7\u00e3o que utiliza 'pooling' ser\u00e3o produzidas sa\u00edda do mesmo tamanho que as entradas.\n# input_shape=(input_shape) ===> Sempre que esta camada for usada como a primeira camada do modelo, este par\u00e2metro precisa ser informado\n\n# Explica\u00e7\u00e3o do comando: model.add(BatchNormalization(scale=False))\n# Normaliza as ativa\u00e7\u00f5es da camada anterior, por meio da aplica\u00e7\u00e3o de uma transforma\u00e7\u00e3o. Em suma: evitar valores extremos.\n\n# Explica\u00e7\u00e3o do comando: model.add(Dropout(0.5))\n# \u00c9 uma t\u00e9cnica na qual, aleatoriamente, algumas entradas s\u00e3o descartadas \/ ignoradas\n\ndef build_model(input_shape):\n    model =Sequential()\n    model.add(Conv2D(64,(3,3),padding='same',input_shape=(input_shape)))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(scale=False))\n    model.add(Conv2D(64,(3,3),padding='same'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(scale=False))    \n    model.add(Conv2D(64,(3,3),padding='same'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(scale=False))        \n    model.add(MaxPooling2D())\n    model.add(Dropout(0.5))\n    \n    model.add(Conv2D(128,(3,3),padding='same'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(scale=False))\n    model.add(Conv2D(128,(3,3),padding='same'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(scale=False)) \n    model.add(Conv2D(128,(3,3),padding='same'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(scale=False))        \n    model.add(MaxPooling2D())\n    model.add(Dropout(0.5))\n\n    model.add(Conv2D(256,(3,3),padding='same'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(scale=False))\n    model.add(Conv2D(256,(3,3),padding='same'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(scale=False)) \n    model.add(Conv2D(256,(3,3),padding='same'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(scale=False))          \n    \n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(256))\n    model.add(Activation('relu'))    \n    model.add(Dropout(0.5))\n    \n    model.add(Dense(1))\n    model.add(Activation('sigmoid'))\n    model.compile('adam',loss='binary_crossentropy',metrics=['accuracy']) \n#     model.add(Dense(2))\n#     model.add(Activation('softmax'))    \n#     model.compile('adam',loss='categorical_crossentropy',metrics=['accuracy']) \n    \n    return model ","2f54624b":"#data count a:100 b:200 c:300 weights a:3 b:1.5 c:1 \n1.0 \/ len(df_train[df_train.has_cactus==0]) * len(df_train[df_train.has_cactus==1]) ","b1ccf62f":"%%time\nimport sklearn\nfrom sklearn.preprocessing import *\nfrom sklearn.model_selection import train_test_split,KFold,StratifiedKFold\nimport keras.backend as K\nfrom sklearn.metrics import *\nfrom keras.preprocessing.image import ImageDataGenerator\nhistories = []\noof_pred = np.zeros(len(df_train))\nsub_pred = np.zeros(len(df_test))\n\nclass_weights = {} \nweights = [3.010082493125573,#3.01,\n           1.0]\nlen(df_train[df_train.has_cactus==0]) \nfor i in range(2): \n    class_weights[i] = weights[i] \nprint('class_weights:',class_weights)\n\ncheckpoint_name = '\/checkpoint.file'\nskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\nBATCH_SIZE = 64 #128\nEPOCHS = 5 #128\n\nfor fold_id, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):\n    print(f'fold id: {fold_id}')\n    X_tr, y_tr = X_train[train_index], y_train[train_index]\n    X_val, y_val = X_train[val_index], y_train[val_index]\n\n    callbacks=[\n        keras.callbacks.ModelCheckpoint(\n            checkpoint_name, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False),\n        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=5, verbose=1,min_delta=0.00005, ),\n        keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n    ]   \n\n    datagen = ImageDataGenerator(\n#             width_shift_range=0.1,#2,\n            height_shift_range=0.1,\n            horizontal_flip=True\n    )\n    K.clear_session()\n    model = build_model(X_train.shape[1:])   \n    model.summary()    \n    \n    histories.append(\n#         model.fit(X_tr, y_tr, batch_size=16, epochs=128,#64, \n#                   validation_data=(X_val, y_val), \n#                   class_weight=class_weights,verbose=2, callbacks=callbacks)\n        model.fit_generator(\n            datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n            steps_per_epoch=int(np.ceil(len(X_train) \/ BATCH_SIZE)), validation_data=(X_val, y_val), \n            epochs=EPOCHS, class_weight=class_weights, \n            callbacks=callbacks, verbose=2)\n    )\n    \n    model = load_model(checkpoint_name)\n    oof_pred[val_index] = model.predict(X_val).flatten()\n    sub_pred += model.predict(X_test).flatten() \/ skf.n_splits\n    print(roc_auc_score(y_val, oof_pred[val_index]))\n    plot_roc_auc(y_val, oof_pred[val_index])\n    del callbacks\n#plot_roc_auc(y_val, oof_pred[val_index])\nsub_pred = np.clip(sub_pred,0.0,1.0)    ","f36da194":"sub_pred.min(),sub_pred.max()","0afa089e":"plt.hist(sub_pred)\nplt.show()\n\nplt.title('auc count (between 0.80 - 0.20)')\nplt.hist(sub_pred[(sub_pred<0.80) & (sub_pred>0.20)], bins=100)\nplt.show()\n\nplt.title('auc count (between 0.70 - 0.30)')\nplt.hist(sub_pred[(sub_pred<0.70) & (sub_pred>0.30)], bins=100)\nplt.show()\n\nplt.title('auc count (between 0.60 - 0.40)')\nplt.hist(sub_pred[(sub_pred<0.60) & (sub_pred>0.40)], bins=100)\nplt.show()","a5df0522":"print('Ambiguous image index:',np.where((sub_pred<0.80) & (sub_pred>0.20))[:32][0])","8aac7622":"submission = pd.read_csv('..\/input\/aerial-cactus-identification\/sample_submission.csv')\nsubmission['has_cactus'] = sub_pred\nsubmission.to_csv('submission.csv', index=False)\n\nsubmission.head(50)\n\n# Excluindo todo o conte\u00fado e a pr\u00f3pria pasta \"..working\/train\"\nshutil.rmtree(\"..\/working\/train\")\n\n# Excluindo todo o conte\u00fado e a pr\u00f3pria pasta \"..working\/test\"\nshutil.rmtree(\"..\/working\/test\")\n\n# Listando o conte\u00fado da pasta \"..working\"\nprint(os.listdir(\"..\/working\"))","5b3baad2":"# auc range","86c1c023":"# Aerial Cactus Identification\nBras\u00edlia, 16\/12\/2019\n\n&nbsp;\nComponentes:\n* \u00c2ngela Cristina\n* Camilo Bessoni\n* Marcelo Rangel\n* M\u00e1rcio Rodrigues\n* Renato Valadares","33ce8d7b":"# training","ff156d8d":"### Ambiguous image","08ed7997":"# Verificando balanceamento dos dados pelo TARGET","b94301d4":"# weight calcuration","b2125a9c":"# Entendimento dos dados","e9075ed0":"# submission","edf35aed":"# Constru\u00e7\u00e3o do Modelo"}}