{"cell_type":{"c033248b":"code","0e9bb617":"code","861aa984":"code","bb9785b2":"code","1df2dee5":"code","db98c782":"code","40b041c0":"code","6b4848a7":"code","57b97c0c":"code","4a4ebcd7":"code","9fef564a":"code","112a549c":"code","ef1416aa":"code","263548bb":"code","a0fb7649":"code","b1e90cbf":"code","3d711f29":"code","e63a546e":"code","0838b588":"code","779a86b7":"code","473d38bc":"code","8ccaba8d":"code","ff42de19":"code","54e03ccd":"code","f14eaa75":"code","037ac2c0":"code","ebb28924":"code","d44adc76":"markdown","ee305f6c":"markdown","9e45cdb3":"markdown","1a5495fb":"markdown","14ff3720":"markdown","b055e254":"markdown","09a13f7a":"markdown","9ea9070a":"markdown"},"source":{"c033248b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport cv2","0e9bb617":"X = []\ny = []\nIMG_SIZE = 150\n\nDIR = \"\/kaggle\/input\/flowers-recognition\/flowers\/flowers\"\n\nfolders = os.listdir(DIR)\n\n\nfolders","861aa984":"for i, file in enumerate(folders):\n    filename = os.path.join(DIR, file)\n    print(\"Folder {} started\".format(file))\n    try:\n        for img in os.listdir(filename):\n            path = os.path.join(filename, img)\n            img = cv2.imread(path,cv2.IMREAD_COLOR)\n            img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n\n            X.append(np.array(img))\n            y.append(i)\n    except:\n        print(\"File {} not read\".format(path))\n        \n    print(\"Folder {} done\".format(file))\n    print(\"The folder {} is labeled as {}\".format(file, i))","bb9785b2":"np.unique(y, return_counts=True)","1df2dee5":"X = np.array(X)\ny = np.array(y)\n\nprint(\"X shape is {}\".format(X.shape))\nprint(\"y shape is {}\".format(y.shape))","db98c782":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom random import sample\n\nrandom_indexes = sample(range(1, 3500), 16)\nprint(random_indexes)\n\n# Parameters for our graph; we'll output images in a 4x4 configuration\nnrows = 4\nncols = 4\n\n# Index for iterating over images\n\n\n# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols * 4, nrows * 4)\n\n\n\nfor i, img_index in enumerate(random_indexes):\n  # Set up subplot; subplot indices start at 1\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.set_title(folders[y[img_index]])\n  sp.axis('Off') # Don't show axes (or gridlines)\n\n  plt.imshow(X[img_index])\n\n\nplt.show()","40b041c0":"from tensorflow.keras.utils import to_categorical\n\nprint(\"Before the categorical the shape of y is {}\".format(y.shape))\ny = to_categorical(y)\nprint(\"After the categorical the shape of y is {}\".format(y.shape))\n","6b4848a7":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n\nprint(\"There are {} training examples\".format(X_train.shape[0]))\nprint(\"There are {} test examples\".format(X_test.shape[0]))","57b97c0c":"import tensorflow as tf\nimport keras_preprocessing","4a4ebcd7":"training_datagen = keras_preprocessing.image.ImageDataGenerator(\n      rescale = 1.\/255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntraining_datagen.fit(X_train)\n\nvalidation_datagen = keras_preprocessing.image.ImageDataGenerator(\n      rescale = 1.\/255)\n\nvalidation_datagen.fit(X_test)","9fef564a":"model = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    # This is the first convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    # The second convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The third convolution\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The fourth convolution\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(5, activation='softmax')\n])\n\nmodel.summary()\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])","112a549c":"epochs=50\nbatch_size=32\n\nhistory = model.fit_generator(training_datagen.flow(X_train,y_train, batch_size=batch_size),\n                              epochs = 50, validation_data = validation_datagen.flow(X_test, y_test, batch_size=batch_size),\n                              verbose = 1, steps_per_epoch=X_train.shape[0] \/\/ batch_size)","ef1416aa":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","263548bb":"predictions = model.predict(X_test)\nprediction_digits = np.argmax(predictions, axis=1)\n\nlabels_pred = np.unique(prediction_digits, return_counts=True)\nreal_labels = np.argmax(y_test, axis=1)","a0fb7649":"from sklearn.metrics import confusion_matrix\n\nc_m = confusion_matrix(real_labels, prediction_digits)\n\nc_m","b1e90cbf":"import seaborn as sns\nplt.figure(figsize = (10,10))\nsns.heatmap(c_m,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='' , xticklabels = folders , yticklabels = folders)","3d711f29":"from tensorflow.keras.applications import VGG16\n\nbase_model = VGG16(input_shape=(150, 150, 3),\n                  include_top=False,\n                  weights=\"imagenet\")\n\nprint(\"Base Model Loaded\")","e63a546e":"for layer in base_model.layers:\n    layer.trainable=False","0838b588":"base_model.summary()","779a86b7":"last_layer = base_model.get_layer('block5_pool')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output","473d38bc":"\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras import layers, Model\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)                  \n# Add a final sigmoid layer for classification\nx = layers.Dense  (5, activation='softmax')(x)           \n\nmodel = Model( base_model.input, x) \n\nmodel.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'categorical_crossentropy', \n              metrics = ['accuracy'])\n\nmodel.summary()","8ccaba8d":"history = model.fit_generator(training_datagen.flow(X_train,y_train, batch_size=batch_size),\n                              epochs = 50, validation_data = validation_datagen.flow(X_test, y_test, batch_size=batch_size),\n                              verbose = 1, steps_per_epoch=X_train.shape[0] \/\/ batch_size)","ff42de19":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","54e03ccd":"predictions = model.predict(X_test)\nprediction_digits = np.argmax(predictions, axis=1)\n\nlabels_pred = np.unique(prediction_digits, return_counts=True)\nreal_labels = np.argmax(y_test, axis=1)","f14eaa75":"c_m = confusion_matrix(real_labels, prediction_digits)\n\nc_m","037ac2c0":"plt.figure(figsize = (10,10))\nsns.heatmap(c_m,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='' , xticklabels = folders , yticklabels = folders)","ebb28924":"\nnp.unique(real_labels, return_counts=True)","d44adc76":"## Using Transfer Learning","ee305f6c":"Data Augmentation with ImageDataGenerator","9e45cdb3":"## Train the Model (Without Transfer Learning)","1a5495fb":"## Preprocess the Data","14ff3720":"## Image Data Augmentation","b055e254":"We have 3627 image of flowers in 5 different categories","09a13f7a":"The Accuary is better in the Transfer Learning Model. But it seems that, our model is overfitting because, while the training accuracy increases the validation accuracy does not increase.","9ea9070a":"## Get Input Data"}}