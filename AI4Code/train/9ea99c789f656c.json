{"cell_type":{"4fa21d20":"code","4b50cd94":"code","5139c78c":"code","d803c6cb":"code","ed2ba718":"code","b495dfbf":"code","ad21d1a6":"code","8b512f7c":"code","67a15fcf":"code","5d01105f":"code","dcfb57d0":"code","f33a390e":"code","b1c3e039":"code","ca33614e":"markdown","1e107cbb":"markdown","9deaa294":"markdown"},"source":{"4fa21d20":"%matplotlib inline\nfrom scipy.io import loadmat\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom glob import glob\nimport pandas as pd\ntry:\n    from skimage.util.montage import montage2d\nexcept ImportError as e:\n    print('scikit-image is too new',e)\n    from skimage.util import montage as montage2d","4b50cd94":"def read_many_aff(in_paths):\n    img_out, label_out = [], []\n    for c_path in in_paths:\n        a, b = read_affdata(c_path, verbose=False)\n        img_out += [a]\n        label_out += [b]\n    return np.concatenate(img_out, 0), np.concatenate(label_out, 0)\ndef read_affdata(in_path, verbose=True):\n    v = loadmat(in_path)['affNISTdata'][0][0]\n    if verbose:\n        for k in v:\n            print(k.shape)\n    img = v[2].reshape((40, 40, -1)).swapaxes(0, 2).swapaxes(1, 2)\n    label = v[5][0]\n    if verbose:\n        plt.imshow(montage2d(img[:81]), cmap='bone')\n    return img, label","5139c78c":"valid_img_data, valid_img_label = read_affdata('..\/input\/validation.mat')","d803c6cb":"test_img_data, test_img_label = read_affdata('..\/input\/test.mat')","ed2ba718":"c_id = np.random.choice(list(range(valid_img_data.shape[0])))\nplt.matshow(valid_img_data[c_id])\nprint(valid_img_label[c_id])","b495dfbf":"train_img_data, train_img_label = read_many_aff(glob('..\/input\/training_batches\/training_batches\/*.mat'))\nplt.hist(train_img_label)\nprint(train_img_data.shape, train_img_label.shape)","ad21d1a6":"def rebalance_data(in_img, in_label, new_size = None, favor_classes=None, demote_classes=None):\n    base_p = np.ones_like(in_label).astype('float32')\n    if favor_classes is None:\n        favor_classes=[]\n    if demote_classes is None:\n        demote_classes=[]\n    if new_size is None:\n        new_size = in_label.shape[0]\n    \n    for k in favor_classes:\n        base_p[in_label==k] *= 2\n    for k in demote_classes:\n        base_p[in_label==k] \/= 2\n        \n    base_p \/= base_p.sum()\n    new_idx = np.random.choice(np.arange(base_p.shape[0]), size=new_size, replace=True, p=base_p) \n    return in_img[new_idx], in_label[new_idx]","8b512f7c":"trn_img, trn_lab = rebalance_data(train_img_data, \n                                  train_img_label, \n                                  favor_classes=[7], \n                                  demote_classes=[1])\nplt.hist(trn_lab, np.arange(11))","67a15fcf":"fig, ax1 = plt.subplots(1, 1, figsize = (20, 20))\nax1.imshow(montage2d(trn_img[:400]), cmap='bone')\nfig.savefig('full_res.png', dpi=200)","5d01105f":"tst_img, tst_lab = rebalance_data(test_img_data, \n                                  test_img_label, \n                                  favor_classes=[1], \n                                  demote_classes=[7])\nplt.hist(tst_lab, np.arange(11))","dcfb57d0":"def write_to_disk(img_vec, lab_vec, base_name):\n    assert img_vec.shape[0]==lab_vec.shape[0], \"Shapes should match\"\n    idx = np.random.permutation(np.arange(img_vec.shape[0]))\n    np.savez_compressed('{}.npz'.format(base_name),\n                        img = img_vec,\n                        idx = idx\n                       )\n    pd.DataFrame({'idx': idx,\n                  'label': lab_vec\n                 }).to_csv('{}_labels.csv'.format(base_name), index=False)","f33a390e":"write_to_disk(trn_img, trn_lab, 'train')\nwrite_to_disk(valid_img_data, valid_img_label, 'valid')\nwrite_to_disk(tst_img, tst_lab, 'test')\n!ls -lh *.npz\n!ls -lh *.csv","b1c3e039":"test_df = pd.read_csv('test_labels.csv')\ntest_df['label'] = 5 # make every guess 5 \ntest_df.to_csv('sample_submission.csv', index=False)","ca33614e":"# Overview\nThe notebook takes the goofy .mat files and loads them into standard numpy arrays. It then actively unbalances the groups to make for a more exciting machine learning challenge and then saves the data as NPZ and csv files which should be easy to open in a number of different tools.","1e107cbb":"# Make datasets more adverserial\n- Sample training with more 7s than 1s \n- Sample valid normally\n- Sample testing with more 1s than 7s","9deaa294":"# Write everything nicely to disk"}}