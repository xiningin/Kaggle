{"cell_type":{"b36192dd":"code","ea452182":"code","d2bb09db":"code","af21fecf":"code","73297ac0":"code","62592623":"code","3f310169":"code","7a3bb98d":"code","2b7740e0":"code","85b68773":"code","2f782d35":"code","a7f6939e":"code","576e02a8":"code","243c6a8e":"code","0aa5c8e0":"code","2d711916":"code","87afb7fd":"code","aa2ffbed":"code","9ad77b01":"code","2b231a45":"code","f1916a40":"code","da7c5fc9":"code","e38d9c45":"code","9074523a":"code","d618244a":"code","36ce3fa7":"code","7fb83b72":"code","dc07a7cb":"code","5195ba90":"code","4332863d":"code","dc974b45":"code","fd0bb0c1":"code","384e8871":"code","7c2c3155":"code","5d6a5546":"code","afb623cc":"code","63153ae7":"code","04e03cf6":"code","673a447f":"code","0a7c59e2":"code","29aa0d56":"code","afd55a07":"code","f0ad9d3d":"code","3aa7b3e7":"markdown","9417c6bf":"markdown","d09de846":"markdown","bc20d43a":"markdown","f5e101ab":"markdown","a0cdae04":"markdown","2acaa6bc":"markdown","6730be54":"markdown","cb41dc47":"markdown","06dc9aa3":"markdown","c23d5262":"markdown","45fa73af":"markdown","52f174c3":"markdown","78a2e979":"markdown","6c7bacec":"markdown","57fe1903":"markdown","106c01e8":"markdown","90afb7b9":"markdown","eb894326":"markdown","d78fe578":"markdown","db24fdbb":"markdown","1a231961":"markdown"},"source":{"b36192dd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ea452182":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#import missingno as msno\n\n\n%matplotlib inline\n#plt.style.use('seaborn-darkgrid')\n#palette = plt.get_cmap('Set2')","d2bb09db":"from sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nimport sklearn.metrics as metrics\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler","af21fecf":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\n#Creating a copy of the train and test datasets\nc_test  = test.copy()\nc_train  = train.copy()","73297ac0":"train.head(10)","62592623":"test.head(10)","3f310169":"train.info()","7a3bb98d":"test.info()","2b7740e0":"c_train.describe()","85b68773":"c_train.describe(exclude='number')","2f782d35":"c_train['train']  = 1\nc_test['train']  = 0\ndf = pd.concat([c_train, c_test], axis=0,sort=False)        ","a7f6939e":"#correlation matrix\ncorrmat = train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","576e02a8":"SalePrice = pd.DataFrame(corrmat['SalePrice'].sort_values(ascending=False))\nSalePrice","243c6a8e":"#saleprice correlation matrix\nk = 10 #number of variables for heatmap\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(train[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","0aa5c8e0":"df = df.drop(['GarageArea','TotRmsAbvGrd' , '1stFlrSF' ],axis=1)","2d711916":"#scatterplot\nsns.set()\ncols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(train[cols], height = 2.5)\nplt.show();","87afb7fd":"df = df.drop(['Street','LandContour','Utilities','LandSlope','Condition2','RoofMatl','ExterCond','BsmtCond','Heating','CentralAir','Electrical','Functional','GarageQual','GarageCond','PavedDrive','Condition1','SaleType'],axis=1)","aa2ffbed":"#missing data\ntotal = df.isnull().sum().sort_values(ascending=False)\npercent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(25)","9ad77b01":"df =df.drop((missing_data[missing_data['Total'] > 5]).index, axis=1)\nprint(df.isnull().sum().max())","2b231a45":"df.isnull().sum()","f1916a40":"# numeric data\nnumeric_missed = ['BsmtFinSF1',\n                  'BsmtFinSF2',\n                  'BsmtUnfSF',\n                  'TotalBsmtSF',\n                  'BsmtFullBath',\n                  'BsmtHalfBath',\n                  'GarageCars']\n\nfor feature in numeric_missed:\n    df[feature].fillna(0, inplace=True)","da7c5fc9":"# categorical data\ncategorical_missed = ['Exterior1st',\n                  'Exterior2nd',\n                  'MSZoning',\n                  'KitchenQual']\n\nfor feature in categorical_missed:\n    df[feature].fillna(df[feature].mode()[0], inplace=True)","e38d9c45":"df.isnull().sum().max()","9074523a":"plt.figure(figsize=(12, 7))\n\nsns.displot(train['SalePrice']).set(ylabel=None, xlabel=None)\nplt.title('House price distribution histogram', fontsize=18)\nplt.show()","d618244a":"#train['SalePrice'] = np.log1p(train['SalePrice'])","36ce3fa7":"from scipy.stats import skew","7fb83b72":"\n#numeric = df.dtypes[df.dtypes != 'object'].index\n#skewed = df[numeric].apply(lambda col: skew(col)).sort_values(ascending=False)\n#skewed = skewed[abs(skewed) > 0.5]\n\n#for feature in skewed.index:\n    #df[feature] = np.log1p(df[feature])","dc07a7cb":"df = pd.get_dummies(df)\ndf","5195ba90":"df = df.drop(['Id',],axis=1)","4332863d":"#Scaler = StandardScaler()\n#all_scaled = pd.DataFrame(Scaler.fit_transform(df))\n\ndf_train = pd.DataFrame(df[:1460])\ndf_test = pd.DataFrame(df[1460:2920])","dc974b45":"#df_final = df.drop(['Id',],axis=1)\n\n#df_train = df_final[df_final['train'] == 1]\n#df_train = df_train.drop(['train',],axis=1)\n\n\n#df_test = df[~df_train]\n#df_test = df_test.drop(['Id'],axis=1)\n#df_test = df_test.drop(['train',],axis=1)","fd0bb0c1":"target= train['SalePrice']","384e8871":"X_train,X_test,y_train,y_test = train_test_split(df_train,target,test_size=0.33,random_state=0)","7c2c3155":"xgb =XGBRegressor(learning_rate=0.1,n_estimators=100,reg_alpha=0.001,reg_lambda=0.000001,n_jobs=-1,min_child_weight=3,subsample=0.9,max_depth=5,colsample_bytree=0.2)","5d6a5546":"rf = RandomForestRegressor()","afb623cc":"xgb.fit(X_train,y_train) \nrf.fit(X_train,y_train)","63153ae7":"df_tn = pd.DataFrame()\ndf_tn['xgb_pred'] = xgb.predict(X_test)\ndf_tn['rf_pred'] = rf.predict(X_test)","04e03cf6":"df_ts = pd.DataFrame()\ndf_ts['xgb_pred'] = xgb.predict(df_test)\ndf_ts['rf_pred'] = rf.predict(df_test)","673a447f":"from sklearn.linear_model import LinearRegression\n\n# Create linear regression model without the intercept\nlr = LinearRegression(fit_intercept=False)","0a7c59e2":"lr.fit(df_tn[['xgb_pred', 'rf_pred']], y_test)\ndf_ts['stacking'] = lr.predict(df_ts[['xgb_pred', 'rf_pred']])","29aa0d56":"#df_f['blend'] = (df_f['xgb_pred'] + df_f['rf_pred']) \/ 2\n#print(df_f[['xgb_pred', 'rf_pred', 'blend']].head(3))","afd55a07":"print(lr.coef_)","f0ad9d3d":"submission = pd.DataFrame({\n        \"Id\": test[\"Id\"],\n        \"SalePrice\": df_ts['stacking']\n    })\nsubmission.to_csv('submission.csv', index=False)","3aa7b3e7":"**Getting info of data**","9417c6bf":"**There are no more null values**\n**lets check normality of 'SalesPrice'**\n\n","d09de846":"#### Fix The Skewness in the other features","bc20d43a":"**We can safely remove these features as they are not important and do not have a high correlation.**","f5e101ab":"### Scatter plots between 'SalePrice' and correlated variables ","a0cdae04":"## Modeling","2acaa6bc":"* Concat Train and Test datasets","6730be54":"**Let's find and fill in the missing data**","cb41dc47":"**train-test data**","06dc9aa3":"#### for categorical data","c23d5262":"**Submission**","45fa73af":"#### for numerical data","52f174c3":"### Obsevation_1\nSome features have low variance  as majority of data is of 1 category.\nWe will check if these features have significance else we will drop them. \nThese features are : ['Street','LandContour','Utilities','LandSlope','Condition2','RoofMatl','ExterCond','BsmtCond','Heating','CentralAir','Electrical','Functional','GarageQual','GarageCond','PavedDrive','Condition1','SaleType']","78a2e979":"**Import required libraries**","6c7bacec":"**Getting the Data**","57fe1903":"#### At last  dummy variables","106c01e8":"#### Correlation matrix (heatmap style)","90afb7b9":" 'SalePrice' is not normal. It shows 'peakedness', positive skewness\n fix it with  log transformation","eb894326":"* there are some highly correlated feature pairs ,we keep one from each pair \n* #### Saleprice is highly correlated with OverallQual\n* #### GarageArea logically has a great relationship with GarageCars,choose only one,'GarageCars'\n* #### Have the smallest connection YearBuilt and TotRmsAbvGrd\n* #### Also highly correlated 1stFirSF and TotalBsmtSF,as we choose TotalBsmtSF \n* #### TotRmsAbvGrd is highly correlated with GrLivArea","d78fe578":"### Let drop  features we discussed in Observation1 because  they have low variance and are poorly coorelated to salesprice hence provide no valuable info.","db24fdbb":"**Check for any  null values **","1a231961":"# Data preprocessing"}}