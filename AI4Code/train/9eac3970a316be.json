{"cell_type":{"b2afbd10":"code","4cee8aed":"code","39942736":"code","9e4b76e0":"code","f1acdfbb":"code","c96ac7bd":"code","23a5b95d":"code","72d08a63":"code","01d820dc":"code","ef3323c3":"code","426027ee":"code","2c200343":"code","75fa6567":"code","bfc886e5":"code","4c36142f":"code","5faf0e60":"code","9dcd155f":"code","d12a0f73":"code","d9e8b038":"code","cab15e26":"code","a72a9283":"code","b190ed18":"code","bc8badfb":"code","2a3f7e58":"code","2100c4c1":"markdown"},"source":{"b2afbd10":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4cee8aed":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense,SimpleRNN,LSTM,Embedding,Bidirectional","39942736":"df_train = pd.read_csv(\"\/kaggle\/input\/emotions-dataset-for-nlp\/train.txt\",sep=';',header=None)\ndf_train.head()","9e4b76e0":"df_test = pd.read_csv(\"\/kaggle\/input\/emotions-dataset-for-nlp\/test.txt\",sep=';',header=None)\ndf_val = pd.read_csv(\"\/kaggle\/input\/emotions-dataset-for-nlp\/val.txt\",sep=';',header=None)\ndf_test.shape,df_val.shape","f1acdfbb":"df_train.columns = ['text','emotions']\nprint(df_train.columns)\ndf_train.shape","c96ac7bd":"x_train = df_train['text'].values\nprint(len(x_train))\nprint(f'A sample from x train : {x_train[10]}')","23a5b95d":"print(\"unique values : \",df_train.emotions.unique())\ny_train = df_train['emotions'].values\nprint(y_train[:5])\none = OneHotEncoder(sparse = False)\none.fit(y_train.reshape(len(y_train),1))\ny_train = one.transform(y_train.reshape(len(y_train),1))\nprint(y_train[:5])","72d08a63":"df_test.columns = ['text','emotions']\ndf_val.columns = ['text','emotions']\nx_test = df_test['text'].values\nprint(len(x_test))\nx_val = df_val['text'].values\nprint(len(x_val))\n\n\n\ny_test = df_test['emotions'].values\none.fit(y_test.reshape(len(y_test),1))\ny_test = one.transform(y_test.reshape(len(y_test),1))\n\n\ny_val = df_val['emotions'].values\none.fit(y_val.reshape(len(y_val),1))\ny_val = one.transform(y_val.reshape(len(y_val),1))","01d820dc":"vocab_size = 1000\noov = '<OOV>'\nmax_length = 50\ntruc_type ='post'\n","ef3323c3":"tokenizer = Tokenizer(num_words=vocab_size,oov_token='<OOV>')\ntokenizer.fit_on_texts(x_train)\nx_train = tokenizer.texts_to_sequences(x_train)\nprint(f'same sample after tokenizing : {x_train[10]}')","426027ee":"word_index = tokenizer.word_index\n{key: word_index[key] for key in list(word_index)[:10]}","2c200343":"x_train = pad_sequences(x_train,padding='post',maxlen=max_length,truncating = 'post')\nx_train.shape","75fa6567":"x_test = tokenizer.texts_to_sequences(x_test)\nx_test = pad_sequences(x_test,padding='post',maxlen=max_length,truncating = 'post')\nprint(x_test.shape)\n\nx_val = tokenizer.texts_to_sequences(x_val)\nx_val = pad_sequences(x_val,padding='post',maxlen=max_length,truncating = 'post')\nprint(x_val.shape)","bfc886e5":"#creating the RNN model using SimpleRNN\n\nmodel = Sequential()\n#embedding layer to vectorize\nmodel.add(Embedding(vocab_size,output_dim = 64))\n\n#simpleRNN layer\nmodel.add(SimpleRNN(64,activation='relu'))\n\n#dense layer\nmodel.add(Dense(32,activation='relu'))\nmodel.add(Dense(6,activation='softmax'))\nprint(model.summary())\nopt = tf.keras.optimizers.Adam()\n\n#compile\nmodel.compile(optimizer=opt,loss = 'categorical_crossentropy',metrics=['accuracy'])\n","4c36142f":"history = model.fit(x_train,y_train,epochs = 10,validation_data=(x_val,y_val))","5faf0e60":"import matplotlib.pyplot as plt\n\n\ndef plot_graphs(history, string):\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string, 'val_'+string])\n    plt.show()\n    \nplot_graphs(history, 'accuracy')\n\nplot_graphs(history, 'loss')\n\n","9dcd155f":"loss,acc = model.evaluate(x_test,y_test)\nprint(f\"Test accuracy is {acc*100}%\")","d12a0f73":"#creating the RNN model using LSTM\n\nmodel = Sequential()\n#embedding layer to vectorize\nmodel.add(Embedding(vocab_size,output_dim = 64))\n\n#simpleRNN layer\nmodel.add(LSTM(64,activation='relu'))\n\n#dense layer\n\nmodel.add(Dense(32,activation='relu'))\nmodel.add(Dense(6,activation='softmax'))\nprint(model.summary())\nopt = tf.keras.optimizers.Adam()\n\n#compile\nmodel.compile(optimizer=opt,loss = 'categorical_crossentropy',metrics=['accuracy'])\n","d9e8b038":"history = model.fit(x_train,y_train,epochs = 10,validation_data=(x_val,y_val))","cab15e26":"plot_graphs(history, 'accuracy')\nplot_graphs(history, 'loss')","a72a9283":"loss,acc = model.evaluate(x_test,y_test)\nprint(f\"Test accuracy is {acc*100}%\")","b190ed18":"#introducing a  Bidirectional LSTM\nmodel = Sequential()\n#embedding layer to vectorize\nmodel.add(Embedding(vocab_size,output_dim = 64))\n\n#simpleRNN layer\nmodel.add(Bidirectional(LSTM(64,activation='relu')))\n\n#dense layer\n\nmodel.add(Dense(32,activation='relu'))\nmodel.add(Dense(6,activation='softmax'))\nprint(model.summary())\nopt = tf.keras.optimizers.Adam()\n\n#compile\nmodel.compile(optimizer=opt,loss = 'categorical_crossentropy',metrics=['accuracy'])\n","bc8badfb":"history = model.fit(x_train,y_train,epochs = 10,validation_data=(x_val,y_val))\nplot_graphs(history, 'accuracy')\nplot_graphs(history, 'loss')","2a3f7e58":"loss,acc = model.evaluate(x_test,y_test)\nprint(f\"Test accuracy is {acc*100}%\")","2100c4c1":"Getting the input texts ready for the RNN"}}