{"cell_type":{"02f41ade":"code","cd297f14":"code","5bbc2a2d":"code","2799b3d3":"code","e05e96d4":"code","6770ca77":"code","7e712cec":"code","20454a14":"code","80166bf9":"code","e53f0c83":"code","b4f41cf2":"code","3080726c":"code","a6d0486c":"code","6ac0f9ed":"code","3132ab30":"code","3385aa21":"code","cda0b17c":"code","4257f157":"code","7e114b2a":"code","e5ae8a09":"code","0ce1dc5f":"code","6420c126":"code","88799623":"code","fadb8ad6":"code","e975edcb":"code","ebc2a831":"code","49789efb":"code","23e511fc":"code","c69cfb93":"code","fd6d3f37":"code","c70d216c":"code","56977f91":"code","15e94950":"code","ece488be":"code","43e38be3":"code","1893a05c":"code","35903940":"code","57f8b55e":"code","77586aee":"code","30234789":"code","394b7deb":"code","3a785fbf":"code","9f1ddb1f":"code","2dbe4901":"code","0ccbb799":"code","bf92950d":"code","8b3882d1":"code","7e11efdd":"code","2294121c":"code","cec4cfa1":"code","2bfa43b9":"code","b93ff8dc":"code","0788e753":"code","b9de0be3":"code","1ae80255":"code","a4c06bf8":"code","08433aa3":"code","e599f921":"code","f6762b35":"code","bf048ec7":"code","0805af8f":"code","31cc121a":"code","215fb091":"code","fd1f6a33":"code","b23bb0cc":"code","6fbcacda":"code","551fdd7d":"code","178ee923":"code","b993b9fe":"code","7cddc55b":"code","a042b273":"code","f52f03f7":"code","3e6d48dc":"code","4daefa66":"code","69668e05":"code","7f3db04b":"code","862516de":"code","a42a55e5":"code","bdb434dd":"code","b96ea451":"code","02c81aed":"markdown","1e6cfca2":"markdown","e3e2dd40":"markdown","87a29025":"markdown","5bb56f11":"markdown","062cc084":"markdown","fe1b717c":"markdown","0324011d":"markdown","220b42f1":"markdown","7ebce955":"markdown","bf1d2ed6":"markdown","e704716d":"markdown","019eecbc":"markdown","742dfde3":"markdown","92e5c3e1":"markdown"},"source":{"02f41ade":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom scipy.integrate import odeint\n\nfrom plotly.offline import iplot, init_notebook_mode\nimport math\nimport bokeh \nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom urllib.request import urlopen\nimport json\nfrom dateutil import parser\nfrom bokeh.layouts import gridplot\nfrom bokeh.plotting import figure, show, output_file\nfrom bokeh.layouts import row, column\nfrom bokeh.resources import INLINE\nfrom bokeh.io import output_notebook\nfrom bokeh.models import Span\nimport warnings\nwarnings.filterwarnings(\"ignore\")\noutput_notebook(resources=INLINE)","cd297f14":"country_codes = pd.read_csv('https:\/\/raw.githubusercontent.com\/plotly\/datasets\/master\/2014_world_gdp_with_codes.csv')\ncountry_codes = country_codes.drop('GDP (BILLIONS)', 1)\ncountry_codes.rename(columns={'COUNTRY': 'Country', 'CODE': 'Code'}, inplace=True)","5bbc2a2d":"virus_data = pd.read_csv('\/kaggle\/input\/novel-corona-virus-2019-dataset\/covid_19_data.csv')\n\nprev_index = 0\nfirst_time = False\ntmp = 0\n\n\nfor i, row in virus_data.iterrows():\n\n    if(virus_data.loc[i,'SNo'] < 1342 and virus_data.loc[i,'Province\/State']=='Hubei'):\n        if(first_time):\n            tmp = virus_data.loc[i,'Confirmed']\n            prev_index = i\n            virus_data.loc[i,'Confirmed'] = virus_data.loc[i,'Confirmed'] + 593\n            first_time = False\n        else:\n            increment = virus_data.loc[i,'Confirmed'] - tmp\n            tmp = virus_data.loc[i,'Confirmed']\n            virus_data.loc[i,'Confirmed'] = virus_data.loc[prev_index,'Confirmed'] + increment + 593\n            prev_index = i\n    \n\nvirus_data.rename(columns={'Country\/Region': 'Country', 'ObservationDate': 'Date'}, inplace=True)\nvirus_data = virus_data.fillna('unknow')\nvirus_data['Country'] = virus_data['Country'].str.replace('US','United States')\nvirus_data['Country'] = virus_data['Country'].str.replace('UK','United Kingdom') \nvirus_data['Country'] = virus_data['Country'].str.replace('Mainland China','China')\nvirus_data['Country'] = virus_data['Country'].str.replace('South Korea','Korea, South')\nvirus_data['Country'] = virus_data['Country'].str.replace('North Korea','Korea, North')\nvirus_data['Country'] = virus_data['Country'].str.replace('Macau','China')\nvirus_data['Country'] = virus_data['Country'].str.replace('Ivory Coast','Cote d\\'Ivoire')\nvirus_data = pd.merge(virus_data,country_codes,on=['Country'])\n#virus_data.head()\n#print(len(virus_data))","2799b3d3":"top_country = virus_data.loc[virus_data['Date'] == virus_data['Date'].iloc[-1]]\ntop_country = top_country.groupby(['Code','Country'])['Confirmed'].sum().reset_index()\ntop_country = top_country.sort_values('Confirmed', ascending=False)\ntop_country = top_country[:30]\ntop_country_codes = top_country['Country']\ntop_country_codes = list(top_country_codes)\n\n#countries = virus_data.loc[virus_data['Country'] in top_country_codes]\ncountries = virus_data[virus_data['Country'].isin(top_country_codes)]\ncountries_day = countries.groupby(['Date','Code','Country'])['Confirmed','Deaths','Recovered'].sum().reset_index()\n\n\nexponential_line_x = []\nexponential_line_y = []\nfor i in range(16):\n    exponential_line_x.append(i)\n    exponential_line_y.append(i)\n    \n## TOP 30 ##\nchina = countries_day.loc[countries_day['Code']=='CHN']\n\nnew_confirmed_cases_china = []\nnew_confirmed_cases_china.append( list(china['Confirmed'])[0] - list(china['Deaths'])[0] \n                           - list(china['Recovered'])[0] )\n\nfor i in range(1,len(china)):\n\n    new_confirmed_cases_china.append( list(china['Confirmed'])[i] - \n                                     list(china['Deaths'])[i] - \n                                     list(china['Recovered'])[i])\n    \n    \nitaly = countries_day.loc[countries_day['Code']=='ITA']\n\nnew_confirmed_cases_ita = []\nnew_confirmed_cases_ita.append( list(italy['Confirmed'])[0] - list(italy['Deaths'])[0] \n                           - list(italy['Recovered'])[0] )\n\nfor i in range(1,len(italy)):\n    \n    new_confirmed_cases_ita.append( list(italy['Confirmed'])[i] - \n                                  list(italy['Deaths'])[i] - \n                                  list(italy['Recovered'])[i])\n    \n    \nindia = countries_day.loc[countries_day['Code']=='IND']\n\nnew_confirmed_cases_india = []\nnew_confirmed_cases_india.append( list(india['Confirmed'])[0] - list(india['Deaths'])[0] \n                           - list(india['Recovered'])[0] )\n\nfor i in range(1,len(india)):\n    \n    new_confirmed_cases_india.append( list(india['Confirmed'])[i] - \n                                     list(india['Deaths'])[i] - \n                                    list(india['Recovered'])[i])\n    \n\nspain = countries_day.loc[countries_day['Code']=='ESP']\n\nnew_confirmed_cases_spain = []\nnew_confirmed_cases_spain.append( list(spain['Confirmed'])[0] - list(spain['Deaths'])[0] \n                           - list(spain['Recovered'])[0] )\n\nfor i in range(1,len(spain)):\n    \n    new_confirmed_cases_spain.append( list(spain['Confirmed'])[i] - \n                                     list(spain['Deaths'])[i] - \n                                    list(spain['Recovered'])[i])\n    \n\nus = countries_day.loc[countries_day['Code']=='USA']\n\nnew_confirmed_cases_us = []\nnew_confirmed_cases_us.append( list(us['Confirmed'])[0] - list(us['Deaths'])[0] \n                           - list(us['Recovered'])[0] )\n\nfor i in range(1,len(us)):\n    \n    new_confirmed_cases_us.append( list(us['Confirmed'])[i] - \n                                     list(us['Deaths'])[i] - \n                                    list(us['Recovered'])[i])\n    \n    \ngerman = countries_day.loc[countries_day['Code']=='DEU']\n\nnew_confirmed_cases_german = []\nnew_confirmed_cases_german.append( list(german['Confirmed'])[0] - list(german['Deaths'])[0] \n                           - list(german['Recovered'])[0] )\n\nfor i in range(1,len(german)):\n    \n    new_confirmed_cases_german.append( list(german['Confirmed'])[i] - \n                                     list(german['Deaths'])[i] - \n                                    list(german['Recovered'])[i])\n    \n##################################\n    \nsaudi = countries_day.loc[countries_day['Code']=='SAU']\n\nnew_confirmed_cases_saudi = []\nnew_confirmed_cases_saudi.append( list(saudi['Confirmed'])[0] - list(saudi['Deaths'])[0] \n                           - list(saudi['Recovered'])[0] )\n\nfor i in range(1,len(saudi)):\n    \n    new_confirmed_cases_saudi.append( list(saudi['Confirmed'])[i] - \n                                     list(saudi['Deaths'])[i] - \n                                    list(saudi['Recovered'])[i])\n###################################\n    \np1 = figure(plot_width=800, plot_height=550, title=\"Trajectory of Covid-19\")\np1.grid.grid_line_alpha=0.3\np1.ygrid.band_fill_color = \"olive\"\np1.ygrid.band_fill_alpha = 0.1\np1.xaxis.axis_label = 'Total number of detected cases (Log scale)'\np1.yaxis.axis_label = 'New confirmed cases (Log scale)'\n\np1.line(exponential_line_x, exponential_line_y, line_dash=\"4 4\", line_width=0.5)\n\np1.line(np.log(list(china['Confirmed'])), np.log(new_confirmed_cases_china), color='#DBAE23', \n        legend_label='China', line_width=1)\np1.circle(np.log(list(china['Confirmed'])[-1]), np.log(new_confirmed_cases_china[-1]), fill_color=\"white\", size=5)\n\np1.line(np.log(list(italy['Confirmed'])), np.log(new_confirmed_cases_ita), color='#3EC358', \n        legend_label='Italy', line_width=1)\np1.circle(np.log(list(italy['Confirmed'])[-1]), np.log(new_confirmed_cases_ita[-1]), fill_color=\"white\", size=5)\n\n#p1.line(np.log(list(corea_s['Confirmed'])), np.log(new_confirmed_cases_corea), color='#C3893E', \n#       legend_label='South Korea', line_width=1)\n#p1.circle(np.log(list(corea_s['Confirmed'])[-1]), np.log(new_confirmed_cases_corea[-1]), fill_color=\"white\", size=5)\n\n\np1.line(np.log(list(india['Confirmed'])), np.log(new_confirmed_cases_india), color='#3E4CC3', \n        legend_label='India', line_width=1)\np1.circle(np.log(list(india['Confirmed'])[-1]), np.log(new_confirmed_cases_india[-1]), fill_color=\"white\", size=5)\n\np1.line(np.log(list(spain['Confirmed'])), np.log(new_confirmed_cases_spain), color='#F54138', \n        legend_label='Spain', line_width=1)\np1.circle(np.log(list(spain['Confirmed'])[-1]), np.log(new_confirmed_cases_spain[-1]), fill_color=\"white\", size=5)\n\np1.line(np.log(list(us['Confirmed'])), np.log(new_confirmed_cases_us), color='#23BCDB', \n        legend_label='United States', line_width=1)\np1.circle(np.log(list(us['Confirmed'])[-1]), np.log(new_confirmed_cases_us[-1]), fill_color=\"white\", size=5)\n\np1.line(np.log(list(german['Confirmed'])), np.log(new_confirmed_cases_german), color='#010A0C', \n        legend_label='Germany', line_width=1)\np1.circle(np.log(list(german['Confirmed'])[-1]), np.log(new_confirmed_cases_german[-1]), fill_color=\"white\", size=5)\n\n###########################\np1.line(np.log(list(saudi['Confirmed'])), np.log(new_confirmed_cases_saudi), color='#39ff14', \n        legend_label='Saudi Arabia', line_width=1)\np1.circle(np.log(list(saudi['Confirmed'])[-1]), np.log(new_confirmed_cases_saudi[-1]), fill_color=\"white\", size=5)\n\n##############################\np1.legend.location = \"bottom_right\"\n\noutput_file(\"coronavirus.html\", title=\"coronavirus.py\")\n\nshow(p1)","e05e96d4":"countries = virus_data[virus_data['Country'].isin(top_country_codes)]\ncountries_day = countries.groupby(['Date','Code','Country'])['Confirmed','Deaths','Recovered'].sum().reset_index()\n\n\nexponential_line_x = []\nexponential_line_y = []\nfor i in range(16):\n    exponential_line_x.append(i)\n    exponential_line_y.append(i)\n    \nsaudi = countries_day.loc[countries_day['Code']=='SAU']\n\nnew_confirmed_cases_saudi = []\nnew_confirmed_cases_saudi.append( list(saudi['Confirmed'])[0] - list(saudi['Deaths'])[0] \n                           - list(saudi['Recovered'])[0] )\n\nfor i in range(1,len(saudi)):\n    \n    new_confirmed_cases_saudi.append( list(saudi['Confirmed'])[i] - \n                                     list(saudi['Deaths'])[i] - \n                                    list(saudi['Recovered'])[i])\n    \n    \n \np1 = figure(plot_width=800, plot_height=550, title=\"Trajectory of Covid-19 in Saudi Arabia\")\np1.grid.grid_line_alpha=0.3\np1.ygrid.band_fill_color = \"olive\"\np1.ygrid.band_fill_alpha = 0.1\np1.xaxis.axis_label = 'Total number of detected cases (Log scale)'\np1.yaxis.axis_label = 'New confirmed cases (Log scale)'\np = figure(plot_width=400, plot_height=400)\np.outline_line_width = 7\np.outline_line_alpha = 0.3\np.outline_line_color = \"navy\"\n\np1.line(exponential_line_x, exponential_line_y, line_dash=\"4 4\", line_width=0.5)\n\np1.line(np.log(list(saudi['Confirmed'])), np.log(new_confirmed_cases_saudi), color='#39ff14', \n        legend_label='Saudi Arabia', line_width=1)\np1.circle(np.log(list(saudi['Confirmed'])[-1]), np.log(new_confirmed_cases_saudi[-1]), fill_color=\"white\", size=5)\n\np1.legend.location = \"bottom_right\"\n\noutput_file(\"coronavirus_saudi.html\", title=\"Saudi.py\")\n\nshow(p1)","6770ca77":"import plotly as py\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=False)","7e712cec":"corona_data=pd.read_csv('\/kaggle\/input\/novel-corona-virus-2019-dataset\/covid_19_data.csv')\nchoro_map=px.choropleth(corona_data, \n                    locations=\"Country\/Region\", \n                    locationmode = \"country names\",\n                    color=\"Confirmed\", \n                    hover_name=\"Country\/Region\", \n                    animation_frame=\"ObservationDate\"\n                   )\n\nchoro_map.update_layout(\n    title_text = 'Global Spread of Coronavirus',\n    title_x = 0.5,\n    geo=dict(\n        showframe = False,\n        showcoastlines = False,\n    ))\n    \nchoro_map.show()","20454a14":"virus_data[virus_data[\"Country\"]==\"Saudi Arabia\"]","80166bf9":"import pandas as pd\nimport numpy as np\nimport datetime\nimport requests\nimport warnings\n\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\nimport squarify\nimport plotly_express as px\n\n\nfrom IPython.display import Image\nwarnings.filterwarnings('ignore')\n%matplotlib inline","e53f0c83":"confirmed_df = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_confirmed_global.csv')\ndeaths_df = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_deaths_global.csv')\nrecovered_df = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_recovered_global.csv')\nlatest_data = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_daily_reports\/04-04-2020.csv')","b4f41cf2":"dates = list(confirmed_df.columns[4:])\ndates = list(pd.to_datetime(dates))\ndates_saudi = dates[8:]","3080726c":"df1 = confirmed_df.groupby('Country\/Region').sum().reset_index()\ndf2 = deaths_df.groupby('Country\/Region').sum().reset_index()\ndf3 = recovered_df.groupby('Country\/Region').sum().reset_index()\n\nk = df1[df1['Country\/Region']=='Saudi Arabia'].loc[:,'1\/30\/20':]\nsaudi_confirmed = k.values.tolist()[0] \n\nk = df2[df2['Country\/Region']=='Saudi Arabia'].loc[:,'1\/30\/20':]\nsaudi_deaths = k.values.tolist()[0] \n\nk = df3[df3['Country\/Region']=='Saudi Arabia'].loc[:,'1\/30\/20':]\nsaudi_recovered = k.values.tolist()[0] \n\nplt.figure(figsize= (15,10))\nplt.xticks(rotation = 90 ,fontsize = 11)\nplt.yticks(fontsize = 10)\nplt.xlabel(\"Dates\",fontsize = 20)\nplt.ylabel('Total cases',fontsize = 20)\nplt.title(\"Total Confirmed, Active, Death in Saudi Arabia\" , fontsize = 20)\n\nax1 = plt.plot_date(y= saudi_confirmed,x= dates_saudi,label = 'Confirmed',linestyle ='-',color = 'b')\nax2 = plt.plot_date(y= saudi_recovered,x= dates_saudi,label = 'Recovered',linestyle ='-',color = 'g')\nax3 = plt.plot_date(y= saudi_deaths,x= dates_saudi,label = 'Death',linestyle ='-',color = 'r')\nplt.legend();\n\n","a6d0486c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n# Any results you write to the current directory are saved as output.\ntrain=pd.read_csv('\/kaggle\/input\/coronavirus-2019ncov\/covid-19-all.csv')","6ac0f9ed":"train.head(5)","3132ab30":"country_df = train[train['Country\/Region']=='Saudi Arabia'].groupby('Date')['Confirmed','Deaths'].sum()\ncountry_df['day_count'] = list(range(1,len(country_df)+1))\nydata = country_df.Confirmed\nxdata = country_df.day_count\ncountry_df['rate'] = (country_df.Confirmed-country_df.Confirmed.shift(1))\/country_df.Confirmed\ncountry_df['increase'] = (country_df.Confirmed-country_df.Confirmed.shift(1))\n\nplt.plot(xdata, ydata, 'o')\nplt.title(\"Saudi Arabia\")\nplt.ylabel(\"Population infected\")\nplt.xlabel(\"Days\")\nplt.show()","3385aa21":"from scipy.optimize import curve_fit\nimport pylab\n\n\ndef sigmoid(x,c,a,b):\n     y = c*1 \/ (1 + np.exp(-a*(x-b)))\n     return y\n#country_df.ConfirmedCases\n#country_df.day_count\nxdata = np.array([1, 2, 3,4, 5, 6, 7])\nydata = np.array([0, 0, 13, 35, 75, 89, 91])\n\n#([low_a,low_b],[high_a,high_b])\n#low x --> low b\n#high y --> high c\n#a is the sigmoidal shape.\npopt, pcov = curve_fit(sigmoid, xdata, ydata, method='dogbox',bounds=([0.,0., 0.],[100,2, 10.]))\nprint(popt)\n\nx = np.linspace(-1, 10, 50)\ny = sigmoid(x, *popt)\n\npylab.plot(xdata, ydata, 'o', label='data')\npylab.plot(x,y, label='fit')\npylab.ylim(-0.05, 105)\npylab.legend(loc='best')\npylab.show()","cda0b17c":"sa_df = train[train['Country\/Region']=='Saudi Arabia'].groupby('Date')['Confirmed','Deaths','Recovered'].sum().reset_index(False)\nsa_df['Active']=sa_df['Confirmed']-sa_df['Deaths']-sa_df['Recovered']\nsa_df = sa_df[sa_df.Active>=100]","4257f157":"from scipy.optimize import curve_fit\nimport pylab\nfrom datetime import timedelta\n\nsa_df['day_count'] = list(range(1,len(sa_df)+1))\nsa_df['increase'] = (sa_df.Active-sa_df.Active.shift(1))\nsa_df['rate'] = (sa_df.Active-sa_df.Active.shift(1))\/sa_df.Active\n\n\ndef sigmoid(x,c,a,b):\n     y = c*1 \/ (1 + np.exp(-a*(x-b)))\n     return y\n\nxdata = np.array(list(sa_df.day_count)[::2])\nydata = np.array(list(sa_df.Active)[::2])\n\npopulation=1.332*10**9\npopt, pcov = curve_fit(sigmoid, xdata, ydata, method='dogbox',bounds=([0.,0., 0.],[population,6, 100.]))\nprint(popt)","7e114b2a":"est_a = 32589\nest_b = 0.134\nest_c = 45\nx = np.linspace(-1, sa_df.day_count.max()+50, 50)\ny = sigmoid(x,est_a,est_b,est_c)\npylab.plot(xdata, ydata, 'o', label='data')\npylab.plot(x,y, label='fit',alpha = 0.6)\npylab.ylim(-0.05, est_a*1.05)\npylab.xlim(-0.05, est_c*2.05)\npylab.legend(loc='best')\nplt.xlabel('days from day 1')\nplt.ylabel('confirmed cases')\nplt.title('Saudi Arabia')\npylab.show()\n\n\n#print('model start date:',in_df[in_df.day_count==1].index[0])\n#print('model start infection:',int(in_df[in_df.day_count==1].Active[0]))\nprint('model fitted max Active at:',int(est_a))\nprint('model sigmoidal coefficient is:',round(est_b,3))\nprint('model curve stop steepening, start flattening by day:',int(est_c))\nprint('model curve flattens by day:',int(est_c)*2)\ndisplay(sa_df.head(3))\ndisplay(sa_df.tail(3))","e5ae8a09":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport os\nfrom tqdm.notebook import tqdm\nfrom scipy.integrate import solve_ivp\nimport numpy\nimport datetime\nfrom datetime import timedelta","0ce1dc5f":"# Susceptible equation\ndef dS_dt(S, I, R_t, T_inf):\n    return -(R_t \/ T_inf) * I * S\n\n# Exposed equation\ndef dE_dt(S, E, I, R_t, T_inf, T_inc):\n    return (R_t \/ T_inf) * I * S - (T_inc**-1) * E\n\n# Infected equation\ndef dI_dt(I, E, T_inc, T_inf):\n    return (T_inc**-1) * E - (T_inf**-1) * I\n\n# Recovered\/Remove\/deceased equation\ndef dR_dt(I, T_inf):\n    return (T_inf**-1) * I\n\ndef SEIR_model(t, y, R_t, T_inf, T_inc):\n    \n    if callable(R_t):\n        reproduction = R_t(t)\n    else:\n        reproduction = R_t\n        \n    S, E, I, R = y\n    \n    S_out = dS_dt(S, I, reproduction, T_inf)\n    E_out = dE_dt(S, E, I, reproduction, T_inf, T_inc)\n    I_out = dI_dt(I, E, T_inc, T_inf)\n    R_out = dR_dt(I, T_inf)\n    \n    return [S_out, E_out, I_out, R_out]","6420c126":"train1 = pd.read_csv('..\/input\/covid19-global-forecasting-week-4\/train.csv')\n#test = pd.read_csv('..\/input\/covid19-global-forecasting-week-4\/test.csv')\ntrain['Date_datetime'] = train['Date'].apply(lambda x: (datetime.datetime.strptime(x, '%Y-%m-%d')))","88799623":"pop_info = pd.read_csv('\/kaggle\/input\/covid19-population-data\/population_data.csv')\ncountry_pop = pop_info.query('Type == \"Country\/Region\"')\nprovince_pop = pop_info.query('Type == \"Province\/State\"')\ncountry_lookup = dict(zip(country_pop['Name'], country_pop['Population']))\nprovince_lookup = dict(zip(province_pop['Name'], province_pop['Population']))","fadb8ad6":"def plot_model_and_predict(data, pop, solution, title='SEIR model'):\n    sus, exp, inf, rec = solution.y\n    \n    f = plt.figure(figsize=(16,5))\n    ax = f.add_subplot(1,2,1)\n    #ax.plot(sus, 'b', label='Susceptible');\n    ax.plot(exp, 'y', label='Exposed');\n    ax.plot(inf, 'r', label='Infected');\n    ax.plot(rec, 'c', label='Recovered\/deceased');\n    plt.title(title)\n    plt.xlabel(\"Days\", fontsize=10);\n    plt.ylabel(\"Fraction of population\", fontsize=10);\n    plt.legend(loc='best');\n    \n    ax2 = f.add_subplot(1,2,2)\n    preds = np.clip((inf + rec) * pop ,0,np.inf)\n    ax2.plot(range(len(data)),preds[:len(data)],label = 'Predict ConfirmedCases')\n    #ax2.plot(range(len(data)),data['Confirmed'])\n    plt.title('Model predict and data')\n    plt.ylabel(\"Population\", fontsize=10);\n    plt.xlabel(\"Days\", fontsize=10);\n    plt.legend(loc='best');","e975edcb":"train","ebc2a831":"Country = 'Saudi Arabia'\nN = pop_info[pop_info['Name']==Country]['Population'].tolist()[0] # India Population \n\n# Load dataset of Hubei\ntrain_loc = train[train['Country\/Region']==Country].query('Confirmed > 0')\nif len(train_loc)==0:\n    train_loc = train[train['Province\/State']==Country].query('Confirmed > 0')\n\nn_infected = train_loc['Confirmed'].iloc[0] # start from first comfirmedcase on dataset first date\nmax_days = len(train_loc)# how many days want to predict\n\n# Initial stat for SEIR model\ns = (N - n_infected)\/ N\ne = 0.\ni = n_infected \/ N\nr = 0.\n\n# Define all variable of SEIR model \nT_inc = 5.2  # average incubation period\nT_inf = 2.9 # average infectious period\nR_0 = 3.954 # reproduction number\n\n## Solve the SEIR model \nsol = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(R_0, T_inf, T_inc), \n                t_eval=np.arange(max_days))\n\n## Plot result\nplot_model_and_predict(train_loc, N, sol, title = 'SEIR Model (without intervention)')\n","49789efb":"# Define all variable of SEIR model \nT_inc = 5.2  # average incubation period\nT_inf = 2.9  # average infectious period\n\n# Define the intervention parameters (fit result, latter will show how to fit)\nR_0, cfr, k, L=[ 3.95469597 , 0.04593316 , 3.      ,   15.32328881]\n\ndef time_varying_reproduction(t): \n    return R_0 \/ (1 + (t\/L)**k)\n\nsol2 = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(time_varying_reproduction, T_inf, T_inc), \n                t_eval=np.arange(max_days))\n\nplot_model_and_predict(train_loc, N, sol2, title = 'SEIR Model (with intervention)')","23e511fc":"from scipy.optimize import minimize\nfrom sklearn.metrics import mean_squared_log_error, mean_squared_error","c69cfb93":"def cumsum_signal(vec):\n    temp_val = 0\n    vec_new = []\n    for i in vec:\n        if i > temp_val:\n            vec_new.append(i)\n            temp_val = i\n        else:\n            vec_new.append(temp_val)\n    return vec_new","fd6d3f37":"# Use a constant reproduction number\ndef eval_model_const(params, data, population, return_solution=False, forecast_days=0):\n    R_0, cfr = params # Paramaters, R0 and cfr \n    N = population # Population of each country\n    n_infected = data['Confirmed'].iloc[0] # start from first comfirmedcase on dataset first date\n    max_days = len(data) + forecast_days # How many days want to predict\n    s, e, i, r = (N - n_infected)\/ N, 0, n_infected \/ N, 0 #Initial stat for SEIR model\n    \n    # R0 become half after intervention days\n    def time_varying_reproduction(t):\n        if t > 80: # we set intervention days = 80\n            return R_0 * 0.5\n        else:\n            return R_0\n    \n    # Solve the SEIR differential equation.\n    sol = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(time_varying_reproduction, T_inf, T_inc),\n                    t_eval=np.arange(0, max_days))\n    \n    sus, exp, inf, rec = sol.y\n    # Predict confirmedcase\n    y_pred_cases = np.clip((inf + rec) * N ,0,np.inf)\n    y_true_cases = data['Confirmed'].values\n    \n    # Predict Fatalities by remove * fatality rate(cfr)\n    #y_pred_fat = np.clip(rec*N* cfr, 0, np.inf)\n    #y_true_fat = data['Fatalities'].values\n    \n    optim_days = min(20, len(data))  # Days to optimise for\n    weights = 1 \/ np.arange(1, optim_days+1)[::-1]  # Recent data is more heavily weighted\n    \n    # using mean squre log error to evaluate\n    msle_cases = mean_squared_log_error(y_true_cases[-optim_days:], y_pred_cases[-optim_days:], weights)\n    #msle_fat = mean_squared_log_error(y_true_fat[-optim_days:], y_pred_fat[-optim_days:], weights)\n    msle_final = msle_cases\n    \n    if return_solution:\n        return msle_final, sol\n    else:\n        return msle_final","c70d216c":"# Use a Hill decayed reproduction number\ndef eval_model_decay(params, data, population, return_solution=False, forecast_days=0):\n    R_0, cfr, k, L = params # Paramaters, R0 and cfr \n    N = population # Population of each country\n    n_infected = data['Confirmed'].iloc[0] # start from first comfirmedcase on dataset first date\n    max_days = len(data) + forecast_days # How many days want to predict\n    s, e, i, r = (N - n_infected)\/ N, 0, n_infected \/ N, 0 #Initial stat for SEIR model\n    \n    # https:\/\/github.com\/SwissTPH\/openmalaria\/wiki\/ModelDecayFunctions   \n    # Hill decay. Initial values: R_0=2.2, k=2, L=50\n    def time_varying_reproduction(t): \n        return R_0 \/ (1 + (t\/L)**k)\n    \n    # Solve the SEIR differential equation.\n    sol = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(time_varying_reproduction, T_inf, T_inc),\n                    t_eval=np.arange(0, max_days))\n    \n    sus, exp, inf, rec = sol.y\n    # Predict confirmedcase\n    y_pred_cases = np.clip((inf + rec) * N ,0,np.inf)\n    y_true_cases = data['Confirmed'].values\n    \n    # Predict Fatalities by remove * fatality rate(cfr)\n    #y_pred_fat = np.clip(rec*N* cfr, 0, np.inf)\n    #y_true_fat = data['Fatalities'].values\n    \n    optim_days = min(20, len(data))  # Days to optimise for\n    weights = 1 \/ np.arange(1, optim_days+1)[::-1]  # Recent data is more heavily weighted\n    \n    # using mean squre log error to evaluate\n    msle_cases = mean_squared_log_error(y_true_cases[-optim_days:], y_pred_cases[-optim_days:], weights)\n    #msle_fat = mean_squared_log_error(y_true_fat[-optim_days:], y_pred_fat[-optim_days:], weights)\n    msle_final = msle_cases\n    \n    if return_solution:\n        return msle_final, sol\n    else:\n        return msle_final","56977f91":"train.tail()","15e94950":"import plotly.express as px\nfrom matplotlib import dates\nimport plotly.graph_objects as go\n\ndef fit_model_new(data, area_name, initial_guess=[2.2, 0.02, 2, 50], \n              bounds=((1, 20), (0, 0.15), (1, 3), (1, 100)), make_plot=True, decay_mode = None):\n    \n    if area_name in ['France']:# France last data looks weird, remove it\n        train = data.query('Confirmed > 0').copy()[:-1]\n    #elif area_name in ['Virgin Islands']:\n    #    train = data[:-3].query('ConfirmedCases > 0').copy()\n    else:\n        train = data.query('Confirmed > 0').copy()\n    \n    ####### Split Train & Valid #######\n    #valid_data = train[-1:]\n    train_data = train\n    \n    ####### If this country have no ConfirmedCase, return 0 #######\n    if len(train_data) == 0:\n        result_zero = np.zeros((43))\n        return pd.DataFrame({'Confirmed':result_zero,'Fatalities':result_zero}), 0 \n    \n    ####### Load the population of area #######\n    try:\n        #population = province_lookup[area_name]\n        population = pop_info[pop_info['Name']==area_name]['Population'].tolist()[0]\n    except IndexError:\n        print ('country not in population set, '+str(area_name))\n        population = 1000000 \n    \n    \n    if area_name == 'US':\n        population = 327200000\n    if area_name == 'Global':\n        population = 7744240900\n        \n    cases_per_million = train_data['Confirmed'].max() * 10**6 \/ population\n    n_infected = train_data['Confirmed'].iloc[0]\n    \n    ####### Total case\/popuplation below 1, reduce country population #######\n    if cases_per_million < 1:\n        #print ('reduce pop divide by 100')\n        population = population\/100\n        \n    ####### Fit the real data by minimize the MSLE #######\n    res_const = minimize(eval_model_const, [2.2, 0.02], bounds=((1, 20), (0, 0.15)),\n                         args=(train_data, population, False),\n                         method='L-BFGS-B')\n\n    res_decay = minimize(eval_model_decay, initial_guess, bounds=bounds,\n                         args=(train_data, population, False),\n                         method='L-BFGS-B')\n    \n    ####### Align the date information #######\n    test_end = datetime.datetime.strptime('2020-05-14','%Y-%m-%d')\n    test_start = datetime.datetime.strptime('2020-03-26','%Y-%m-%d')\n    train_test = data[data.Date_datetime>=test_start]\n    test_period = (test_end - test_start).days\n    train_max = train_data.Date_datetime.max()\n    train_min = train_data.Date_datetime.min()\n    add_date = 0\n    delta_days =(test_end - train_max).days\n    train_add_time=[]\n\n    if train_min > test_start:\n        add_date = (train_min-test_start).days\n        last = train_min-timedelta(add_date)\n        train_add_time = np.arange(last, train_min, dtype='datetime64[D]').tolist()\n        train_add_time = pd.to_datetime(train_add_time)\n        dates_all = train_add_time.append(pd.to_datetime(np.arange(train_min, test_end+timedelta(1), dtype='datetime64[D]')))\n    else:\n        dates_all = pd.to_datetime(np.arange(train_min, test_end+timedelta(1), dtype='datetime64[D]'))\n\n\n    ####### Auto find the best decay function ####### \n    if decay_mode is None:\n        if res_const.fun < res_decay.fun :\n            msle, sol = eval_model_const(res_const.x, train_data, population, True, delta_days+add_date)\n            res = res_const\n\n        else:\n            msle, sol = eval_model_decay(res_decay.x, train_data, population, True, delta_days+add_date)\n            res = res_decay\n            R_0, cfr, k, L = res.x\n    else:\n        if decay_mode =='day_decay':\n            msle, sol = eval_model_const(res_const.x, train_data, population, True, delta_days+add_date)\n            res = res_const\n        else:\n            msle, sol = eval_model_decay(res_decay.x, train_data, population, True, delta_days+add_date)\n            res = res_decay\n            R_0, cfr, k, L = res.x\n\n    ####### Predict the result by using best fit paramater of SEIR model ####### \n    sus, exp, inf, rec = sol.y\n    \n    y_pred = pd.DataFrame({\n        'Confirmed': cumsum_signal(np.diff((inf + rec) * population, prepend=n_infected).cumsum())\n       # 'ConfirmedCases': [inf[0]*population for i in range(add_date)]+(np.clip((inf + rec) * population,0,np.inf)).tolist(),\n       # 'Fatalities': [rec[0]*population for i in range(add_date)]+(np.clip(rec, 0, np.inf) * population * res.x[1]).tolist()\n    #'Fatalities': cumsum_signal((np.clip(rec * population * res.x[1], 0, np.inf)).tolist())\n    })\n\n    #y_pred_valid = y_pred.iloc[len(train_data):len(train_data)+len(valid_data)]\n    y_pred_valid = y_pred.iloc[:len(train_data)]\n    y_pred_test = pd.concat([train_test[['Confirmed']],y_pred.iloc[-(delta_days):]], ignore_index=True)\n    y_true_valid = train_data[['Confirmed']]\n    #y_true_valid = valid_data[['ConfirmedCases', 'Fatalities']]\n    #print (len(y_pred),train_min)\n    \n    ####### Calculate MSLE ####### \n    valid_msle_cases = mean_squared_log_error(y_true_valid['Confirmed'], y_pred_valid['Confirmed'])\n    #valid_msle_fat = mean_squared_log_error(y_true_valid['Fatalities'], y_pred_valid['Fatalities'])\n    valid_msle = valid_msle_cases\n    \n    ####### Plot the fit result of train data and forecast after 300 days ####### \n    if make_plot:\n        if len(res.x)<=2:\n            print(f'Validation MSLE: {valid_msle:0.5f}, using intervention days decay, Reproduction number(R0) : {res.x[0]:0.5f}, Fatal rate : {res.x[1]:0.5f}')\n        else:\n            print(f'Validation MSLE: {valid_msle:0.5f}, using Hill decay, Reproduction number(R0) : {res.x[0]:0.5f}, Fatal rate : {res.x[1]:0.5f}, K : {res.x[2]:0.5f}, L: {res.x[3]:0.5f}')\n        \n        ####### Plot the fit result of train data dna SEIR model trends #######\n\n        f = plt.figure(figsize=(16,5))\n        ax = f.add_subplot(1,2,1)\n        ax.plot(exp, 'y', label='Exposed');\n        ax.plot(inf, 'r', label='Infected');\n        ax.plot(rec, 'c', label='Recovered\/deceased');\n        plt.title('SEIR Model Trends')\n        plt.xlabel(\"Days\", fontsize=10);\n        plt.ylabel(\"Fraction of population\", fontsize=10);\n        plt.legend(loc='best');\n        #train_date_remove_year = train_data['Date_datetime'].apply(lambda date:'{:%m-%d}'.format(date))\n        ax2 = f.add_subplot(1,2,2)\n        xaxis = train_data['Date_datetime'].tolist()\n        xaxis = dates.date2num(xaxis)\n        hfmt = dates.DateFormatter('%m\\n%d')\n        ax2.xaxis.set_major_formatter(hfmt)\n        ax2.plot(np.array(train_data['Date_datetime'], dtype='datetime64[D]'),train_data['Confirmed'],label='Confirmed Cases (train)', c='g')\n        ax2.plot(np.array(train_data['Date_datetime'], dtype='datetime64[D]'), y_pred['Confirmed'][:len(train_data)],label='Cumulative modeled infections', c='r')\n        #ax2.plot(np.array(valid_data['Date_datetime'], dtype='datetime64[D]'), y_true_valid['ConfirmedCases'],label='Confirmed Cases (valid)', c='b')\n        #ax2.plot(np.array(valid_data['Date_datetime'], dtype='datetime64[D]'),y_pred_valid['ConfirmedCases'],label='Cumulative modeled infections (valid)', c='y')\n        plt.title('Real ConfirmedCase and Predict ConfirmedCase')\n        plt.legend(loc='best');\n        plt.show()\n            \n        ####### Forecast 300 days after by using the best paramater of train data #######\n        if len(res.x)>2:\n            msle, sol = eval_model_decay(res.x, train_data, population, True, 60)\n        else:\n            msle, sol = eval_model_const(res.x, train_data, population, True, 60)\n        \n        sus, exp, inf, rec = sol.y\n        \n        y_pred = pd.DataFrame({\n            'Confirmed': cumsum_signal(np.diff((inf + rec) * population, prepend=n_infected).cumsum()),\n        })\n        \n        ####### Plot 300 days after of each country #######\n        start = train_min\n        end = start + timedelta(len(y_pred))\n        time_array = np.arange(start, end, dtype='datetime64[D]')\n\n        max_day = numpy.where(inf == numpy.amax(inf))[0][0]\n        where_time = time_array[max_day]\n        pred_max_day = y_pred['Confirmed'][max_day]\n        xy_show_max_estimation = (where_time, max_day)\n        \n        con = y_pred['Confirmed']\n        #fat = y_pred['Fatalities']\n        max_day_con = numpy.where(con == numpy.amax(con))[0][0] # Find the max confimed case of each country\n        #max_day_fat = numpy.where(fat == numpy.amax(fat))[0][0]\n        max_con = numpy.amax(con)\n        #max_fat = numpy.amax(fat)\n        where_time_con = time_array[len(time_array)-50]\n        xy_show_max_estimation_confirmed = (where_time_con, max_con)\n        \n        fig = go.Figure()\n        fig.add_trace(go.Scatter(x=time_array, y=y_pred['Confirmed'].astype(int),\n                            mode='lines',\n                            line = dict(color='red'),\n                            name='Estimation Confirmed Case Start from '+ str(start.date())+ ' to ' +str(end.date())))\n        \n        fig.add_trace(go.Scatter(x=time_array[:len(train)], y=train['Confirmed'],\n                            mode='lines',\n                            name='Confirmed case until '+ str(train_max.date()),line = dict(color='green', width=4)))\n    \n        fig.add_annotation(\n            x=where_time_con,\n            y=max_con-(max_con\/30),\n            showarrow=False,\n            text=\"Estimate Max Case around:\" +str(int(max_con)),\n            font=dict(\n                color=\"Blue\",\n                size=15\n            ))\n        fig.add_annotation(\n            x=time_array[len(train)-1],\n            y=train['Confirmed'].tolist()[-1],\n            showarrow=True,\n            text=f\"Real Max ConfirmedCase: \" +str(int(train['Confirmed'].tolist()[-1]))) \n        fig.add_annotation(\n            x=where_time,\n            y=pred_max_day,\n            text='Infect start decrease from: ' + str(where_time))   \n        fig.update_layout(title='Estimate Confirmed Case ,'+area_name+' Total population ='+ str(int(population)), legend_orientation=\"h\")\n        fig.show()\n        ###\n        df = pd.DataFrame({'Values': train_data['Confirmed'].tolist()+y_pred['Confirmed'].tolist(),'Date_datatime':time_array[:len(train_data)].tolist()+time_array.tolist(),\n                   'Real\/Predict': ['ConfirmedCase' for i in range(len(train_data))]+['PredictCase' for i in range(len(y_pred))]})\n        fig = px.line(df, x=\"Date_datatime\", y=\"Values\",color = 'Real\/Predict')\n        fig.show()\n        plt.figure(figsize = (16,7))\n        plt.plot(time_array[:len(train_data)],train_data['Confirmed'],label='Confirmed case until '+ str(train_max.date()),color='g', linewidth=3.0)\n        plt.plot(time_array,y_pred['Confirmed'],label='Estimation Confirmed Case Start from '+ str(start.date())+ ' to ' +str(end.date()),color='r', linewidth=1.0)\n        plt.annotate('Infect start decrease from: ' + str(where_time), xy=xy_show_max_estimation, size=15, color=\"black\")\n        plt.annotate('max Confirmedcase: ' + str(int(max_con)), xy=xy_show_max_estimation_confirmed, size=15, color=\"black\")\n        plt.title('Estimate Confirmed Case '+area_name+' Total population ='+ str(int(population)))\n        plt.legend(loc='lower right')\n        plt.show()\n\n\n    return y_pred_test, valid_msle","ece488be":"country = 'Saudi Arabia'\nif country not in train['Country\/Region'].unique():\n    country_pd_train = train[train['Province\/State']==country]\nelse:\n    country_pd_train = train[train['Country\/Region']==country]\n\na,b = fit_model_new(country_pd_train,country,make_plot=True)","43e38be3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","1893a05c":"df_confirmed=train\n","35903940":"df_confirmed","57f8b55e":"country=\"Saudi Arabia\"\ndf_confirmed1 = df_confirmed[df_confirmed[\"Country\/Region\"] == country]","77586aee":"df_confirmed1","30234789":"## structuring times eries data for confirmed\ndf_all = pd.DataFrame(df_confirmed1.iloc[:,4:7])\ndf_all.index = pd.to_datetime(df_confirmed1.Date_datetime,format='%m\/%d\/%y')\ndf_all=df_all.astype(int)\ndf_all","394b7deb":"df_new= pd.DataFrame(df_all.iloc[:,0])\ndf_new.index = pd.to_datetime(df_confirmed1.Date_datetime,format='%m\/%d\/%y')\ndf_new\n\ntrain=df_new.iloc[:62]\ntest = df_new.iloc[62:]\ntrain","3a785fbf":"##scale or normalize data as the data is too skewed\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(train) #find max value\nscaled_train = scaler.transform(train)#and divide every point by max value\nscaled_test = scaler.transform(test)\nprint(scaled_train[-5:])","9f1ddb1f":"## feed in batches [t1,t2,t3] --> t4\nfrom keras.preprocessing.sequence import TimeseriesGenerator","2dbe4901":"scaled_train.shape","0ccbb799":"## how to decide num of inputs , \nn_input = 5  ## number of steps\nn_features = 1 ## number of features you want to predict (for univariate time series n_features=1)\ngenerator = TimeseriesGenerator(scaled_train,scaled_train,length = n_input,batch_size=1)","bf92950d":"len(generator)","8b3882d1":"x,y = generator[50]","7e11efdd":"(x.shape,y.shape)","2294121c":"(x,y)","cec4cfa1":"y","2bfa43b9":"## above takes 5 inputs and predicts next point in scaled_train\n## smaller batch size leads to better trainig for time series","b93ff8dc":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout, Activation\n\nmodel = Sequential()\nmodel.add(LSTM(150,activation=\"relu\",input_shape=(n_input,n_features)))\nmodel.add(Dense(75, activation='relu'))\nmodel.add(Dense(1))\nmodel.compile(optimizer=\"adam\",loss=\"mse\")","0788e753":"model.summary()","b9de0be3":"validation_set = np.append(scaled_train[55],scaled_test[:5])\nvalidation_set=validation_set.reshape(6,1)\nvalidation_set","1ae80255":"## how to decide num of inputs , \nn_input = 5\nn_features = 1\nvalidation_gen = TimeseriesGenerator(validation_set,validation_set,length=5,batch_size=5)","a4c06bf8":"validation_gen[0][0].shape,validation_gen[0][1].shape","08433aa3":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = EarlyStopping(monitor='loss',patience=30,restore_best_weights=True)","e599f921":"generator","f6762b35":"model.fit_generator(generator,validation_data=validation_gen,epochs=100,callbacks=[early_stop],steps_per_epoch=len(generator))","bf048ec7":"pd.DataFrame(model.history.history).plot(title=\"loss vs epochs curve\")\n","0805af8f":"model.history.history.keys()","31cc121a":"myloss = model.history.history[\"val_loss\"]\nplt.title(\"validation loss vs epochs\")\nplt.plot(range(len(myloss)),myloss)","215fb091":"## holding predictions\ntest_prediction = []\n\n##last n points from training set\nfirst_eval_batch = scaled_train[-n_input:]\ncurrent_batch = first_eval_batch.reshape(1,n_input,n_features)","fd1f6a33":"## how far in future we can predict\nfor i in range(len(test)+57):\n    current_pred = model.predict(current_batch)[0]\n    test_prediction.append(current_pred)\n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)","b23bb0cc":"len(test_prediction)","6fbcacda":"### inverse scaled data\ntrue_prediction = scaler.inverse_transform(test_prediction)\ntrue_prediction[:,0]","551fdd7d":"print(len(true_prediction))","178ee923":"time_series_array = test.index\nfor k in range(0,57):\n    time_series_array = time_series_array.append(time_series_array[-1:] + pd.DateOffset(1))\nlen(time_series_array)","b993b9fe":"df_forecast = pd.DataFrame(columns=[\"confirmed\",\"confirmed_predicted\"],index=time_series_array)\ndf_forecast.loc[:,\"confirmed_predicted\"] = true_prediction[:,0]\ndf_forecast.loc[:,\"confirmed\"] = test[\"Confirmed\"]","7cddc55b":"df_forecast","a042b273":"df_forecast[\"confirmed\"]","f52f03f7":"df_forecast.plot(title=\"Saudi Predictions \")","3e6d48dc":"MAPE = np.mean(np.abs(np.array(df_forecast[\"confirmed\"][:5]) - np.array(df_forecast[\"confirmed_predicted\"][:5]))\/np.array(df_forecast[\"confirmed\"][:5]))\nprint(\"MAPE is \" + str(MAPE*100) + \" %\")","4daefa66":"sum_errs = np.sum((np.array(df_forecast[\"confirmed\"][:5]) - np.array(df_forecast[\"confirmed_predicted\"][:5]))**2)\nsum_errs","69668e05":"stdev = np.sqrt(1\/(5-2) * sum_errs)\nstdev","7f3db04b":"# calculate prediction interval\ninterval = 1.96 * stdev\ninterval","862516de":"df_forecast[\"confirm_min\"] = df_forecast[\"confirmed_predicted\"] - interval\ndf_forecast[\"confirm_max\"] = df_forecast[\"confirmed_predicted\"] + interval\ndf_forecast","a42a55e5":"from datetime import datetime\ndf_forecast[\"Country\"] = country\ndf_forecast[\"Execution date\"] = str(datetime.now()).split()[0]\ndf_forecast","bdb434dd":"from bokeh.layouts import gridplot\nfrom bokeh.plotting import figure, output_file, show\n\np1 = figure(x_axis_type=\"datetime\", title=\"{} - LSTM Results\".format(country),plot_width=1000)\np1.grid.grid_line_alpha=0.5\np1.xaxis.axis_label = 'Date'\np1.yaxis.axis_label = 'Cases'\n\np1.line(df_forecast.index,df_forecast[\"confirmed\"], color='blue', legend_label=\"confirmed\")\np1.line(df_forecast.index,df_forecast[\"confirmed_predicted\"], color='green', legend_label=\"confirmed_predicted\")\np1.line(df_forecast.index,df_forecast[\"confirm_min\"], color='#33A02C', legend_label=\"confirm_min\")\np1.line(df_forecast.index,df_forecast[\"confirm_max\"], color='red', legend_label=\"confirm_max\")\np1.legend.location = \"top_left\"\nshow(p1)","b96ea451":"p1 = figure(x_axis_type=\"datetime\", title=\"{} - LSTM Results\".format(country),plot_width=1000)\np1.grid.grid_line_alpha=1\np1.xaxis.axis_label = 'Date'\np1.yaxis.axis_label = 'Cases'\np1.line(df_forecast.index,df_forecast[\"confirmed\"], color='blue', legend_label=\"confirmed\")\np1.line(df_forecast.index,df_forecast[\"confirmed_predicted\"], color='red',alpha=1, legend_label=\"confirmed_predicted\")\np1.varea(df_forecast.index,df_forecast[\"confirm_min\"],df_forecast[\"confirm_max\"], color='olive',alpha=0.3,legend_label=\"Confidence_Interval\")\np1.legend.location = \"top_left\"\nshow(p1)","02c81aed":"I thought of a sigmoidal function because China's data resembled a sigmoidal shape. Therefore, I try to fit sigmoid functions onto India's. Its just a guess as per the graph about the cases in India.","1e6cfca2":"## forecast","e3e2dd40":"# Global","87a29025":"# Sigmoid model","5bb56f11":"![](http:\/\/www.public.asu.edu\/~hnesse\/classes\/seireqn.png)","062cc084":"# SaudiCOVID19 Forecasting","fe1b717c":"# Time plot ","0324011d":"# Containment Zones in Saudi","220b42f1":"![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/3\/3d\/SEIR.PNG\/800px-SEIR.PNG)","7ebce955":"The SEIR models the flows of people between four states: \nsusceptible (S), \nexposed (E), \ninfected (I), and \nresistant (R). \n\nEach of those variables represents the number of people in those groups. The parameters alpha and beta partially control how fast people move from being susceptible to exposed (beta), from exposed to infected (sigma), and from infected to resistant (gamma). This model has two additional parameters; one is the background mortality (mu) which is unaffected by disease-state, while the other is vaccination (nu). The vaccination moves people from the susceptible to resistant directly, without becoming exposed or infected.\n\nThe SEIR differs from the SIR model in the addition of a latency period. Individuals who are exposed (E) have had contact with an infected person, but are not themselves infectious.\n\nInstructions:\nThe boxes on the right side of the page control the parameters of the model. The page should load with some parameters already in the box. Click \"submit\" to run the model. The parameters can all be modified and the model re-run. The parameters are\nBeta\tThe parameter controlling how often a susceptible-infected contact results in a new exposure.\nGamma\tThe rate an infected recovers and moves into the resistant phase.\nSigma\tThe rate at which an exposed person becomes infective.\nMu\tThe natural mortality rate (this is unrelated to disease). This models a population of a constant size,\nInitial susceptible\tThe number of susceptible individuals at the beginning of the model run.\nInitial exposed\tThe number of exposed individuals at the beginning of the model run.\nInitial infected\tThe number of infected individuals at the beginning of the model run.\nInitial recovered\tThe number of recovered individuals at the beginning of the model run.\nDays\tControls how long the model will run.\nThis program runs on your computer, so some computers may run faster than others. It is probably a good idea not to set the number iterations or the initial populations too high, since it will take longer to run. Note that cookies must be enabled for the algorithm to function.","bf1d2ed6":"# LSTM Model ","e704716d":"# SEIR Model ","019eecbc":"\n****Sigmoid function,\n\nHere is a snap of how I learnt to fit Sigmoid Function - y = c\/(1+np.exp(-a*(x-b))) and 3 coefficients [c, a, b]:\n\n* c - the maximum value (eventual maximum infected people, the sigmoid scales to this value eventually)\n* a - the sigmoidal shape (how the infection progress. The smaller, the softer the sigmoidal shape is)\n* b - the point where sigmoid start to flatten from steepening (the midpoint of sigmoid, when the rate of increase start to slow down)\n\n","742dfde3":"## From this, its seen that in case of Saudi Arabia if the graph goes like that:\n*  **max Active case: 32589**  \u2620\ufe0f\n* \u00a0**curve stop steepening, started flattening by day: 45 ,which is: 28\/04\/2020**\n* \u00a0**curve flattens by day: 90  which is: 11\/06\/2020**","92e5c3e1":"Details:\nThis is an ordinary differential equation model, described by the following equation:\nderivative of S with respect to t equals\nThe simulation uses the fourth-order Runge-Kutta algorithm to solve it numerically, with a step size fixed at 0.01, written in JavaScript. The plotting methods are from the flot module. Both the ode simulation and the script in this page calling it are new, so there may still be some unanticipated bugs (I am also fairly new to the language, so my code may be inefficient or bizarre in places). Internet Explorer may not work since it has not yet adopted the canvas element, which is used in plotting."}}