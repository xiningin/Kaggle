{"cell_type":{"b9d4f7b7":"code","17ee745e":"code","31800db4":"code","7d2519fa":"code","28fdb1f7":"code","e8a56f75":"code","5cba5a0b":"code","c4db2106":"code","e06db2d0":"code","59ade5c7":"code","c6f6e621":"code","3d9ae034":"code","22a86188":"code","768356f3":"code","eb348d6f":"code","d4a12004":"code","98739957":"code","f5982fd8":"code","d740e52e":"code","8ef14b94":"code","3d8d4dd2":"code","a4f24802":"code","7acdd465":"code","44e2eba4":"code","bcf912e2":"code","dd64ac49":"code","24d8e654":"code","93c9362f":"code","6dfdad66":"code","99925775":"code","428f762b":"code","1a2596b6":"code","6dbec180":"code","035e8d26":"code","938b8573":"code","8675d972":"code","2ef151f6":"code","b719810f":"code","5b88360a":"code","76c138b9":"code","80e994a8":"code","01bb533b":"code","628471ae":"code","c1170b10":"code","66c133ba":"code","df751859":"code","a347030f":"code","31712193":"code","3103d316":"code","47126d90":"markdown","47166f8b":"markdown","417dad82":"markdown","226d7615":"markdown","a6fec6fb":"markdown","df4b7cf1":"markdown","d9d37240":"markdown","6f8bfa9b":"markdown","4e825893":"markdown","d1c7b7d6":"markdown","880fca78":"markdown","88dd5b6f":"markdown","ea17d169":"markdown","72ea2585":"markdown","f4f19e00":"markdown","b9b484cc":"markdown","d3ad6377":"markdown","9e08f701":"markdown","d617d544":"markdown","a0c1efd0":"markdown","1fbb7def":"markdown","5a0af529":"markdown","59959f4c":"markdown","23c2623c":"markdown","467468a8":"markdown","37d1cf80":"markdown","cc472aa4":"markdown","81e69221":"markdown","32e59f52":"markdown","a7c3fada":"markdown","0ab41475":"markdown","2575a62c":"markdown"},"source":{"b9d4f7b7":"import pandas as pd\nimport datetime as dt\n","17ee745e":"data = pd.read_table('..\/input\/rfm_xmas19.txt', delimiter = ',')","31800db4":"data.head(10)","7d2519fa":"data.shape","28fdb1f7":"data.info()","e8a56f75":"data[data['customer_id'] == 'FM5295']","5cba5a0b":"data['trans_date'] = pd.to_datetime(data['trans_date'])","c4db2106":"data.info()","e06db2d0":"data['trans_date'].max()","59ade5c7":"cutoff = dt.datetime(2019,9,16)","c6f6e621":"cutoff","3d9ae034":"grouped_object = data.groupby('customer_id')\n\n#separately having a grouped object will come in handy as we continue to add columns\n\ncustomer_grouped = grouped_object['trans_date'].max()","22a86188":"customer_grouped","768356f3":"customer_analysis = pd.DataFrame(customer_grouped)","eb348d6f":"customer_analysis.head()","d4a12004":"customer_analysis['churn'] = 0 ","98739957":"customer_analysis.loc[customer_analysis['trans_date'] <= cutoff, 'churn'] = 1","f5982fd8":"customer_analysis.head(10)","d740e52e":"customer_analysis['num_of_transactions'] = grouped_object.size()","8ef14b94":"customer_analysis.head()","3d8d4dd2":"customer_analysis['total_spend'] = grouped_object['tran_amount'].sum()","a4f24802":"customer_analysis.head()","7acdd465":"churned_customers = customer_analysis[customer_analysis['churn'] == 1]","44e2eba4":"churned_customers.head()","bcf912e2":"churned_customers.shape","dd64ac49":"churned_customers.info()","24d8e654":"churned_customers.tail()","93c9362f":"churned_customers['trans_date'].min()","6dfdad66":"churned_customers.describe()","99925775":"churned_customers['scaled_transactions'] = (churned_customers['num_of_transactions'] - churned_customers['num_of_transactions'].min())\\\n                                           \/(churned_customers['num_of_transactions'].max() - churned_customers['num_of_transactions'].min())","428f762b":"churned_customers.head()","1a2596b6":"churned_customers['scaled_spend'] = (churned_customers['total_spend'] - churned_customers['total_spend'].min()) \\\n                                     \/(churned_customers['total_spend'].max() - churned_customers['total_spend'].min())","6dbec180":"churned_customers.head()","035e8d26":"churned_customers['score'] = ((0.5 * churned_customers['scaled_transactions']) + (0.5 * churned_customers['scaled_spend'])) * 100","938b8573":"churned_customers.head()","8675d972":"cutoff2 = dt.datetime(2019,1,1)\ncutoff2","2ef151f6":"final_cleaned_data = churned_customers[churned_customers['trans_date'] >= cutoff2 ]","b719810f":"final_cleaned_data = final_cleaned_data.sort_values(by = ['trans_date'])","5b88360a":"final_cleaned_data.head()","76c138b9":"final_cleaned_data.drop(columns = ['trans_date','churn','num_of_transactions','total_spend'], inplace = True)","80e994a8":"final_cleaned_data.head()","01bb533b":"final_cleaned_data.sort_values(['score'], ascending = False, inplace = True)","628471ae":"final_cleaned_data.head()","c1170b10":"final_cleaned_data.shape","66c133ba":"coupon_price = data['tran_amount'].mean() * 0.30\ncoupon_price","df751859":"number_of_customers = 1000 \/ 19 \nnumber_of_customers","a347030f":"final_customer_list = final_cleaned_data.head(52)\nfinal_customer_list","31712193":"final_customer_list.drop(columns = ['scaled_transactions','scaled_spend','score'], inplace = True)","3103d316":"final_customer_list","47126d90":"- We have decided that we filter the most recent customers and then use a scoring system to filter further and target those customers with a high score. \n\nYou can research several scoring methods. We will use the weighted sum model. In a nutshell we are assigning both our columns equal weights. So the formula would be ( 1\/2 x number of transactions ) + (1\/2 x total spend).","47166f8b":"Let us now filter our data to only select those customers that are churned. ","417dad82":"Takeaways: \n    \n- There are no missing values \n\n- Transaction date is of object datatype. We would want to convert that to a date type\n\n- There are multiple records from the same customer. We don't have names and addresses but we can provide customer_id's and operations will be able to handle it ","226d7615":"We have multiple rows for each customer. We can group them together and use their latest transaction date as a point of reference. ","a6fec6fb":"We can now send the customer list to our manager along with a brief report on the steps and decisions we made to reach this conclusion. \n\n_______\n_______","df4b7cf1":"**Conclusion**\n\nThere are many other ways to solve this problem. We could have used let's say a clustering model to better segment our customers. My purpose was to show fellow learners like myself, that not all problems require complex solutions. \n\nFeel free to give your feedback on the notebook and I would love to hear the approach you took to solving this problem. ","d9d37240":"Let's add the scoring column and then clean up our dataframe. ","6f8bfa9b":"- We can now filter and choose only those customers who are classified as churned. Let us add more columns to the data first such as number of transactions and total amount spent before filtering. ","4e825893":"Let us create a final clean database.","d1c7b7d6":"So we have the data to work with. It isn't an ideal dataset and sure we would like some more information, but given our time constraint this is what we have to work with. The columns are self explanatory. Let us perform an initial exploration of the data to make sure everything is in order. ","880fca78":"Here is a predicament. There a few steps we can take and the cons associated with them : \n\n- We can filter to choose only those customers that have stopped buying from in the year 2019. Considering the fact that we only have a budget of $1000 dollars, we cannot cater to all of the customers in our dataset. The downside of this approach is that we will filter out customers who might have had a high average cart value in the previous years. We need to ensure maximum return from our advertising spend and customers with a high cart value are better candidates. \n\n- We can sort the results based on total spend or number of transactions. But that leaves us with another question. Is the number of transactions a better indicator of a good customer or total spend?. Think of it this way. A customer can have a high cart value but have a low number of transactions. You can't classify these customers as regulars.\n\n- The third approach can be to assign a scoring system. Taking both spend and number of transactions into consideration and then scoring based on the combination of both columns. This approach by far seems the most reasonable. We have to be careful though and ensure we come up with a scoring system that isn't biased towards one column or the other. ","88dd5b6f":"Note: This step could have actually been avoided completely by simply passing the parse_dates parameter in the read_table function.  \n= read_table(parse_dates = ['trans_date']) ","ea17d169":"Let us now add a churn column that will classify as 1, a customer who is considered as churned or 0 otherwise.","72ea2585":"Let us create a new dataframe that will contain the neccessary columns for our analysis.","f4f19e00":"### Objective","b9b484cc":"\nCan you see how effective communication made it much more clearer what needed to be done. Firms have limited resources and it is out job as data analysts to make sure we are making the optimum use of these resources. If we hadn't communicated and gone with our instinct, we would have ended up making a report on customers in the online space. Probably that have been shopping with us continuously for the past 6 months or so. That excercise would have been futile since that was not the objective the manager had in mind.","d3ad6377":"#### Filtering: ","9e08f701":"Meanwhile you asked your manager to ask the IT team if you can get access to the physical store database. He responds and says it will take too long for the IT department to grant us access. He managed to get data from another team and has already emailed us. Let us look at that dataset. ","d617d544":"The final task is that how do we go about distributing the coupons. Remember our manager asked us to use our discretion to decide what the coupon amount should be and which customers to distribute it to. It is rather tricky to choose the coupon amount. If we choose too high an amount you pretty much end up giving away money and the whole excercise ends up incurring a loss to the firm. Choose a coupon value too low and it might not entice the customers to go online and shop at your website. \n\nWe get in touch with the marketing department and ask them what according to their experienced opinion is the best discount rate. They tell you its 30%. Great, we can now calculate the coupon price.","a0c1efd0":"Now we only have $1000 dollars to spare. To decide the number of customers that can recieve the coupons, we can divide 1000 by the coupon value. ","1fbb7def":"The data didn't require much cleaning and that is expected since it is borrowed from another department that would have done most of the leg work before. So how we go about shortlisting customers whom we can give our coupons to. \n\nLet your data guide you:  \n\n- We want churned customers or customers who stopped shopping. We have a transaction date column for each customer. We can easily shortlist them based on that. Given that most our physical customers buy groceries, any customer who hasn't shopped in over three months in our store can be safely classified as a customer who has churned. \n\nNow since we all will be working with different dates. Let us assume that the max date ( 2019 - 12 - 16 ) is the day we recieved the data. So any customer whose latest transaction date is before October 16, 2019 can be classified as churned. ","5a0af529":"If you didn't notice it earlier, the range for number of transactions is from 4 - 36 while the range for amount spent is 149 - 2513. You can see the problem here. If we didn't normalize our data before going forwards, our weighted sum model would be biased towards the total spend column especially since we are using the same weights for both columns. To normalize we will the use the min-max scaling method. ","59959f4c":"#### Filtering contd.","23c2623c":"Picture a monday morning. Yes I can almost hear you sigh. You are sitting at your desk, absent mindedly sipping on luke warm watered down coffee. Trying to remember the events of the weekend and why is there a reciept in your email thanking you for adopting Jerry, the wild Australian kangaroo. \n\nYour manager walks past you hurriedly and asks you \"Hey, I need a report on who our best customers are\". You are jolted back to reality and take a note of the request and tell your manager you will get to it in a couple of hours. You are a data analyst working for the online department of a retail store. \n\nNow take a moment to think about what the question is. 'Who are our best customers?' Are we talking about our online customers or in store customers? Are we talking about customers who purchase frequently from us or customers that show potential but are not neccessarily paid customers yet? \n\nI am sure you all have read about it in counteless job descriptions and blogs that communication is the key. A good data analyst is a great communicator. The above is a great example of what role communications can play in a successful project. In terms of technical jargon, this is called Fuzzy Logic, using natural language to explain an idea that only superficially explains it. \n\nYou get in touch with your manager after a while and discuss in detail, what the objective of this project is.","467468a8":"### Strategy","37d1cf80":"### The problem","cc472aa4":"So let us break down our strategy. \n\n- Choose only in store customers\n\n- Focus on customers that have been churned. Churned is a fancy way of saying customers that do not partake in business with you anymore","81e69221":"Rounding off we can choose the top 52 customers who will recieve a $19 coupon. ","32e59f52":"### Strategy Contd.","a7c3fada":"While creating complex models and detailed inferences are interesting, I feel like more often than not new data scientists \/ analysts forget the one core purpose. To provide tangible benefit to the organisation we are working for. I can speak from my experience that most often learners like myself when we first step into the field are in awe of sentiment analysis and decision tree models and find all the datasets we can to build these complex models. Not all problems are complex and not all problems require heavily coded, complex algorithms to be solved. \n\nIn this notebook we will look at a real life problem that will shed some light onto what problems a data analyst can expect to encounter in his professional life.\n\nThe dataset has been taken from [Dataquest](https:\/\/www.dataquest.io\/start-here\/?utm_expid=.Iy5DkLTIQMK_9k-duGrR3w.1&utm_referrer=).","0ab41475":"We have $1000 left in our marketing budget and it wont roll over next year. We can use this convert some physical store customers into online. We have to make sure though that we aren't stealing any customers from out brick and mortar store counterparts. We have until today to submit our report. Our manager has asked us to use our judgements and shortcuts where necessary to identify the customers whom we can send coupons to so that they can shop online. ","2575a62c":"### Exploration and Cleaning: "}}