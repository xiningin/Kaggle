{"cell_type":{"d03e4f19":"code","d0796bfb":"code","ae56481c":"code","ee3ea90d":"code","7f54da25":"code","4adfa194":"code","466d65f7":"code","bad26b7f":"code","c0494cbe":"code","1f4837fe":"code","7f39d0f5":"code","74bc2e69":"code","75d3a4fb":"code","f2d282c2":"code","823f4cc4":"code","9c3da86a":"code","5c3d931b":"code","be54144b":"code","2f9f5d29":"code","bf4bae75":"code","ed296553":"code","c696dc19":"code","38889c0f":"code","a3ff7eac":"code","5eb15c98":"code","71a9d3fe":"code","0fae7442":"code","c2c56aaf":"code","35831f07":"code","ef136b7b":"code","ba28816e":"code","80153b08":"code","31400e1a":"code","94900e3b":"code","1255af09":"code","ee4cd78a":"code","a212d780":"code","318d9530":"code","ea07cbb8":"code","20a0fe95":"code","034fa8e6":"code","38dcb340":"code","1daf1525":"code","ad4c52e7":"code","551a2e3a":"code","ed31888a":"code","caf4a131":"code","d065a763":"code","da62ac6f":"code","dfd1c600":"code","c4475b51":"code","f88a63c2":"code","a4e73c80":"code","d0be6981":"code","7bebeb7e":"code","8003455a":"markdown","5148c22e":"markdown","bc40bc76":"markdown","4b149453":"markdown"},"source":{"d03e4f19":"#Importing Libraries\n\nimport numpy as np \nimport pandas as pd \n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.feature_selection import SelectPercentile\nfrom sklearn.feature_selection import f_classif \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score","d0796bfb":"#Reading Data in\n\ndata = pd.read_csv('..\/input\/noshowappointments\/KaggleV2-May-2016.csv')","ae56481c":"data.info()","ee3ea90d":"data.shape","7f54da25":"data.head(10)","4adfa194":"data.tail(10)","466d65f7":"#Renaming columns to have all the headers in lowercase to avoid confusing\n\ndata.rename(columns = lambda x: x.strip().lower().replace(\"-\", \"_\"), inplace=True)","bad26b7f":"#Checking columns new names\n\ndata.head()","c0494cbe":"#Creating a list contains columns names for faster itering over them\n\ncolumns_list = data.columns.to_list()\ncolumns_list","1f4837fe":"#Exploring unique values for each column to understand what we are dealing with\n\nfor column in columns_list:\n    print(data[column].unique())\n    print('')","7f39d0f5":"# Now we'll start manpulating our data to prepare it for further exploring\n\n#Removing unwanted data .. we don't need patientid and appointmentid\n\ndata.drop(['patientid', 'appointmentid'], axis = 1, inplace = True)","74bc2e69":"#Checking modifications\n\ndata.head()","75d3a4fb":"#We will drop rows with ages as '-1'\n\ndata = data[data.age >= 0]","f2d282c2":"#Checking modifications\n\ndata.age.unique()","823f4cc4":"#Now we need to deal with date columns \n\n#First we will convert them to datetime type instead of object\n\ndata['scheduledday'] = pd.to_datetime(data['scheduledday']).astype('datetime64[ns]')\n\ndata['appointmentday'] = pd.to_datetime(data['appointmentday']).astype('datetime64[ns]')","9c3da86a":"#Checking modificatoins\n\ndata.info()","5c3d931b":"data.head()","be54144b":"#We notice from tha data that all appointments time at zero hour\n#So we will remove time component and deal with date and days only\n\ndata['scheduledday'] = data['scheduledday'].dt.date\ndata['appointmentday'] = data['appointmentday'].dt.date","2f9f5d29":"data.head()","bf4bae75":"#Now we will create a new column that calculate the waiting time between scheduled and appointment\n\ndata['waiting_time_days'] = data['appointmentday'] - data['scheduledday']\n\ndata['waiting_time_days'] = data['waiting_time_days'].dt.days","ed296553":"data['waiting_time_days'].unique()","c696dc19":"#Trere are some waiting days vaues in negative and that doesn't make sense\n#We will drop those rows too\n\ndata = data[data.waiting_time_days >= 0]","38889c0f":"#Check the data now\ndata['waiting_time_days'].unique()","a3ff7eac":"data.info()","5eb15c98":"#We notice that the date type turned to object again, so I'll change it back\n\ndata['scheduledday'] = data['scheduledday'].astype('datetime64[ns]')\n\ndata['appointmentday'] = data['appointmentday'].astype('datetime64[ns]')","71a9d3fe":"#Now we will get the weekday for scheduledday to see later if the weekday make a difference or not\n\ndata['scheduled_weekday'] = data['scheduledday'].apply(lambda time: time.dayofweek)","0fae7442":"data.scheduled_weekday.unique()","c2c56aaf":"data.head()","35831f07":"data.shape","ef136b7b":"data.info()","ba28816e":"#We have here three columns (gender, neighbourhood, no_show) with object type that need to e changed to str\n#So we can transform them with label encoder\n\ndata['gender'] = data['gender'].astype(str)\n\ndata['neighbourhood'] = data['neighbourhood'].astype(str)\n\ndata['no_show'] = data['no_show'].astype(str)","80153b08":"#Applying LabelEncoder on the following Features [gender, neighbourhood, no_show]\n\nEncoder = LabelEncoder()\n\ndata['gender'] = Encoder.fit_transform(data['gender'])\n\ndata['neighbourhood'] = Encoder.fit_transform(data['neighbourhood'])\n\ndata['no_show'] = Encoder.fit_transform(data['no_show'])","31400e1a":"#Now I'll drop [scheduledday, appointmentday] features, the give us no valuable info anymore\n\ndata = data.drop(['scheduledday', 'appointmentday'] , axis = 1, inplace = False)","94900e3b":"#Checking the new data shape\ndata.shape","1255af09":"#Now we could proceed to classifications models\n#First we will split features from output\n\n#X Data\nX = data.drop(['no_show'], axis = 1, inplace = False)\n\n#y Data\ny = data['no_show']","ee4cd78a":"#Features shape\n\nX.shape","a212d780":"#We'll try three normalizer to see what fit data the best\n\n#Standard Scaler for Data\n\n#scaler = StandardScaler(copy = True, with_mean = True, with_std = True)\n\n#X = scaler.fit_transform(X)","318d9530":"#MinMaxScaler for Data\n\nscaler = MinMaxScaler(copy = True, feature_range = (0, 1))\n\nX = scaler.fit_transform(X)\n\n#We foumd that min max scaler is the beat scaler to use with my data","ea07cbb8":"#Normalizing Data\n\n#scaler = Normalizer(copy = True, norm = 'l2') \n\n#X = scaler.fit_transform(X)","20a0fe95":"#Feature Selection by Percentile\n\nFeatureSelection = SelectPercentile(score_func = f_classif, percentile = 50)\n\nX = FeatureSelection.fit_transform(X, y)\n","034fa8e6":"#Splitting data (0.75 for train, 0.25 for test)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 44, shuffle = True)","38dcb340":"#Creating an empty list to store models' accurcy for comparison purpose\n\nAccuracy_results = []","1daf1525":"#Applying LogisticRegression Model \n\n\nLogisticRegressionModel = LogisticRegression(penalty = 'l2', solver = 'sag', C = 1.0, random_state = 44)\n\nLogisticRegressionModel.fit(X_train, y_train)\n\n\n#Calculating Prediction\ny_pred = LogisticRegressionModel.predict(X_test)\n\nprint('\\n Logistic Regresiion Model Metrics: \\n')\n\n\n#Calculating Confusion Matrix\nConfusion_matrix = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', Confusion_matrix)\nprint('')\n\n#Calculating Accuracy Score  : ((TP + TN) \/ float(TP + TN + FP + FN))\nAccuracy_score = accuracy_score(y_test, y_pred)\nprint('Accuracy Score is : ', Accuracy_score)\nprint('')\n\n#Calculating Recall Score : (Sensitivity) (TP \/ float(TP + FN))  \nRecall_score = recall_score(y_test, y_pred, average = 'micro')\nprint('Recall Score is : ', Recall_score)\nprint('')\n\n#Calculating Precision Score : (Specificity) #(TP \/ float(TP + FP))  \nPrecision_score = precision_score(y_test, y_pred, average = 'micro') \nprint('Precision Score is : ', Precision_score)\nprint('')\n\n\nAccuracy_results.append({'Logistic Regression Model': np.round(Accuracy_score, 3)})","ad4c52e7":"#Applying SVC Model \n\nSVCModel = SVC(kernel= 'rbf', max_iter = 10000, C = 0.01, gamma = 'auto')\n\nSVCModel.fit(X_train, y_train)\n\n#Calculating Prediction\ny_pred = SVCModel.predict(X_test)\n\nprint('\\n SVC Model Metrics: \\n')\n\n#Calculating Confusion Matrix\nConfusion_matrix = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', Confusion_matrix)\nprint('')\n\n#Calculating Accuracy Score  : ((TP + TN) \/ float(TP + TN + FP + FN))\nAccuracy_score = accuracy_score(y_test, y_pred)\nprint('Accuracy Score is : ', Accuracy_score)\nprint('')\n\n#Calculating Recall Score : (Sensitivity) (TP \/ float(TP + FN))  \nRecall_score = recall_score(y_test, y_pred, average = 'micro')\nprint('Recall Score is : ', Recall_score)\nprint('')\n\n#Calculating Precision Score : (Specificity) #(TP \/ float(TP + FP))  \nPrecision_score = precision_score(y_test, y_pred, average = 'micro') \nprint('Precision Score is : ', Precision_score)\n\n\nAccuracy_results.append({'SVC Model': np.round(Accuracy_score, 3)})\n","551a2e3a":"#Applying DecisionTreeClassifier Model \n\nDecisionTreeClassifierModel = DecisionTreeClassifier(criterion = 'gini', max_depth = 3, random_state = 44) \n\nDecisionTreeClassifierModel.fit(X_train, y_train)\n\n\n#Calculating Prediction\ny_pred = DecisionTreeClassifierModel.predict(X_test)\n\nprint('\\n Decision Tree Classifier Model Metrics: \\n')\n\n#Calculating Confusion Matrix\nConfusion_matrix = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', Confusion_matrix)\nprint('')\n\n#Calculating Accuracy Score  : ((TP + TN) \/ float(TP + TN + FP + FN))\nAccuracy_score = accuracy_score(y_test, y_pred)\nprint('Accuracy Score is : ', Accuracy_score)\nprint('')\n\n#Calculating Recall Score : (Sensitivity) (TP \/ float(TP + FN))  \nRecall_score = recall_score(y_test, y_pred, average = 'micro')\nprint('Recall Score is : ', Recall_score)\nprint('')\n\n#Calculating Precision Score : (Specificity) #(TP \/ float(TP + FP))  \nPrecision_score = precision_score(y_test, y_pred, average = 'micro') \nprint('Precision Score is : ', Precision_score)\n\n\nAccuracy_results.append({'Decision Tree Classifier Model': np.round(Accuracy_score, 3)})","ed31888a":"#Applying RandomForestClassifier Model \n\nRandomForestClassifierModel = RandomForestClassifier(criterion = 'gini', n_estimators = 100,\n                                                     max_depth = 3,random_state = 44) \n\nRandomForestClassifierModel.fit(X_train, y_train)\n\n\n#Calculating Prediction\ny_pred = RandomForestClassifierModel.predict(X_test)\n\nprint('\\n Random Forest Classifier Model Metrics: \\n')\n\n#Calculating Confusion Matrix\nConfusion_matrix = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', Confusion_matrix)\nprint('')\n\n#Calculating Accuracy Score  : ((TP + TN) \/ float(TP + TN + FP + FN))\nAccuracy_score = accuracy_score(y_test, y_pred)\nprint('Accuracy Score is : ', Accuracy_score)\nprint('')\n\n#Calculating Recall Score : (Sensitivity) (TP \/ float(TP + FN))  \nRecall_score = recall_score(y_test, y_pred, average = 'micro')\nprint('Recall Score is : ', Recall_score)\nprint('')\n\n#Calculating Precision Score : (Specificity) #(TP \/ float(TP + FP))  \nPrecision_score = precision_score(y_test, y_pred, average = 'micro') \nprint('Precision Score is : ', Precision_score)\n\nAccuracy_results.append({'Random Forest Classifier Model': np.round(Accuracy_score, 3)})","caf4a131":"#Applying MLPClassifier Model \n\nMLPClassifierModel = MLPClassifier(activation = 'tanh', solver = 'lbfgs', learning_rate = 'constant',\n                                   early_stopping = False,alpha = 0.0001,\n                                   hidden_layer_sizes = (100, 3),random_state = 44)\n\nMLPClassifierModel.fit(X_train, y_train)\n\n#Calculating Prediction\ny_pred = MLPClassifierModel.predict(X_test)\n\nprint('\\n MLPClassifier Model Metrics: \\n')\n\n#Calculating Confusion Matrix\nConfusion_matrix = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', Confusion_matrix)\nprint('')\n\n#Calculating Accuracy Score  : ((TP + TN) \/ float(TP + TN + FP + FN))\nAccuracy_score = accuracy_score(y_test, y_pred)\nprint('Accuracy Score is : ', Accuracy_score)\nprint('')\n\n#Calculating Recall Score : (Sensitivity) (TP \/ float(TP + FN))  \nRecall_score = recall_score(y_test, y_pred, average = 'micro')\nprint('Recall Score is : ', Recall_score)\nprint('')\n\n#Calculating Precision Score : (Specificity) #(TP \/ float(TP + FP))  \nPrecision_score = precision_score(y_test, y_pred, average = 'micro') \nprint('Precision Score is : ', Precision_score)\n\nAccuracy_results.append({'MLP Classifier Model': np.round(Accuracy_score, 3)})","d065a763":"#Applying GradientBoostingClassifier Model \n\nGBCModel = GradientBoostingClassifier(n_estimators = 100, max_depth = 3, random_state = 44)\n\nGBCModel.fit(X_train, y_train)\n\n#Calculating Prediction\ny_pred = GBCModel.predict(X_test)\n\nprint('\\n Gradient BoostingClassifier Model Metrics: \\n')\n\n#Calculating Confusion Matrix\nConfusion_matrix = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', Confusion_matrix)\nprint('')\n\n\n#Calculating Accuracy Score  : ((TP + TN) \/ float(TP + TN + FP + FN))\nAccuracy_score = accuracy_score(y_test, y_pred)\nprint('Accuracy Score is : ', Accuracy_score)\nprint('')\n\n#Calculating Recall Score : (Sensitivity) (TP \/ float(TP + FN))  \nRecall_score = recall_score(y_test, y_pred, average = 'micro')\nprint('Recall Score is : ', Recall_score)\nprint('')\n\n\n#Calculating Precision Score : (Specificity) #(TP \/ float(TP + FP))  \nPrecision_score = precision_score(y_test, y_pred, average = 'micro') \nprint('Precision Score is : ', Precision_score)\n\nAccuracy_results.append({'GBC Model': np.round(Accuracy_score, 3)})","da62ac6f":"Accuracy_results","dfd1c600":"#Applying Grid Searching :  \n'''\nmodel_selection.GridSearchCV(estimator, param_grid, scoring=None,fit_params=None, n_jobs=None, iid=\u2019warn\u2019,\n                             refit=True, cv=\u2019warn\u2019, verbose=0,pre_dispatch=\u20182*n_jobs\u2019, error_score=\n                             \u2019raisedeprecating\u2019,return_train_score=\u2019warn\u2019)\n\n'''\n\nSelectedModel = SVCModel\n\nSelectedParameters = {'C':[0.001, 0.01, 0.1],'kernel':['linear','rbf']}\n\n\nGridSearchModel = GridSearchCV(SelectedModel,SelectedParameters, cv = 2, return_train_score = True)\n\nGridSearchModel.fit(X_train, y_train)\n","c4475b51":"sorted(GridSearchModel.cv_results_.keys())\n\nGridSearchResults = pd.DataFrame(GridSearchModel.cv_results_)[['mean_test_score', 'std_test_score', \n                                                               'params' , 'rank_test_score' , 'mean_fit_time']]\n\n# Showing Results\nprint('Best Score is: ', GridSearchModel.best_score_)\nprint('')\n\nprint('Best Parameters are: ', GridSearchModel.best_params_)\nprint('')\n\nprint('Best Estimator is: ', GridSearchModel.best_estimator_)","f88a63c2":"#Applying SVC Model with GridSearch best parameters\n\nSVCModel = SVC(kernel= 'linear', max_iter = 10000, C = 0.001, gamma = 'auto')\n\nSVCModel.fit(X_train, y_train)\n\n#Calculating Prediction\ny_pred = SVCModel.predict(X_test)\nprint('\\n SVC Model Metrics: \\n')\n\n#Calculating Confusion Matrix\nConfusion_matrix = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', Confusion_matrix)\nprint('')\n\n#Calculating Accuracy Score  : ((TP + TN) \/ float(TP + TN + FP + FN))\nAccuracy_score = accuracy_score(y_test, y_pred)\nprint('Accuracy Score is : ', Accuracy_score)\nprint('')\n\n#Calculating Recall Score : (Sensitivity) (TP \/ float(TP + FN))  \nRecall_score = recall_score(y_test, y_pred, average = 'micro')\nprint('Recall Score is : ', Recall_score)\nprint('')\n\n#Calculating Precision Score : (Specificity) #(TP \/ float(TP + FP))  \nPrecision_score = precision_score(y_test, y_pred, average = 'micro') \nprint('Precision Score is : ', Precision_score)\nprint('')\n\nAccuracy_results.append({'SVCModel': np.round(Accuracy_score, 3)})\n","a4e73c80":"Accuracy_results","d0be6981":"#Calculating Prediction using Gradient Boosting classifer model \n\ny_pred = GBCModel.predict(X_test)\n\nprint(y_test[0:10])\n\nprint('')\n\nprint(y_pred[:10])","7bebeb7e":"#Use Encoder to go back to yes and now values\n\nprint(Encoder.inverse_transform(y_pred[:20]))\n\nprint('')\n\nprint(Encoder.inverse_transform(y_test[:20]))","8003455a":"This a notebook for the Medical No Show Appointments data. We will apply some classification models on it so see if we could predict showing or not showing propability correctly.","5148c22e":"Comments on results:\n\nMaybe we need a larger dataset over a longer period of time to improve our models.","bc40bc76":"So, we find that the accuracy for most models is between 0.79 and 0.80 except for SVC model.\n\nSo, I'll use the Gradient Boosting classifer model to predict the test data.","4b149453":"Fixing age column issues\n\nFrom unique values showing we found ages with 0, -1 values\n\n'0' values may represent babies with only months age but'-1' doesn't make any sense we need to correct that"}}