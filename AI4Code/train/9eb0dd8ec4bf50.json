{"cell_type":{"9aba87e1":"code","6a21939f":"code","cd088c3c":"code","e4368228":"code","f5f3b020":"code","2cd7650e":"code","f9fb430f":"code","8b793a1a":"code","904fb06a":"code","341171e6":"code","b75a7207":"code","98896e7c":"code","a7b7f6d6":"code","f4f6b746":"code","a3a4786b":"code","7b466e59":"code","4eb668b8":"code","80ce5d2c":"code","6028cecf":"code","c53d4b31":"code","f5cb8c1e":"code","6e9a959b":"code","2044f713":"code","a97fc838":"code","275ab896":"code","9eb4af7f":"code","d0cdcab4":"code","92e1d25f":"code","0147249f":"code","9dd86d19":"code","293ca24e":"code","f0b276c1":"code","5fd34874":"code","62dc1bb0":"code","488b979d":"code","77159a6b":"code","f6c531e2":"code","2b04d13d":"code","db5e0920":"code","b7727824":"code","91239c47":"code","d267a069":"code","ca08949e":"code","729b03d5":"code","b36ace04":"code","bfce3264":"code","436706f3":"code","e9556418":"code","41e9eb2f":"code","f2c62894":"code","aa8ae7a7":"code","6c6c5d29":"code","f1cc4f1e":"code","7766214c":"code","762975ef":"code","058e4334":"code","d08f24c2":"code","dc1d4b1f":"code","bbb7cdce":"code","f3d42b43":"code","9615ad62":"code","6b1c42f5":"code","41a46767":"code","b0797ad4":"code","f3f6ff20":"code","5a069b97":"code","1645ce85":"code","1558939b":"code","abac1358":"code","94aca8b9":"code","223d97f5":"code","584255eb":"code","76783e3f":"code","46c09baa":"code","6fd35339":"code","18ecfa7b":"code","f1adf0d1":"code","970b7efd":"code","62314c6b":"code","923c97d4":"code","85fa78da":"code","4dcf291b":"code","0d86c80d":"code","0d5afd06":"code","859e54fc":"code","f0079689":"code","65e1fc36":"code","8423e8b4":"code","0be5a8d0":"code","a7ccaadf":"code","975e35ca":"code","7667d50e":"code","8ad68170":"code","685f8e7c":"code","c2c55876":"code","f5516d36":"code","72bdaf37":"code","28be3c07":"code","73cf7da3":"code","ce3de383":"code","ae082f48":"code","44524934":"code","d853d545":"code","3edeb85d":"code","e738fc3e":"code","431c98e1":"code","ad8a9ae6":"code","b8e8ea87":"code","f1ea0447":"code","9aeb3abf":"code","f420f405":"code","c1502f97":"code","1e3d1a89":"code","94b9fce3":"code","04996690":"code","f4acf6be":"code","b7037d1b":"code","dfcf68e7":"code","f337337e":"code","414363b7":"code","44c0818b":"code","911e93ad":"code","28cbffa1":"code","475cac99":"code","2cd3218d":"code","318fbf04":"markdown","3ee965ac":"markdown","0a77f85f":"markdown","49598270":"markdown","88f62500":"markdown","efb80685":"markdown","add9614f":"markdown","1a8738bd":"markdown","5db50c3d":"markdown","2eaf6ad1":"markdown","03d579f5":"markdown","09686099":"markdown","8282c934":"markdown","5ed8b1c8":"markdown","1dd31108":"markdown","31801d63":"markdown","fb6ddcfc":"markdown","6a6d60f2":"markdown","c810b94a":"markdown","56bc11ab":"markdown","fe70f5d2":"markdown","f63ecb5e":"markdown","759e7944":"markdown","fbcce964":"markdown","8b9a8afa":"markdown","8a14f242":"markdown","231cad4c":"markdown","84aad8b0":"markdown","57f84e95":"markdown","1d87aca0":"markdown","b30ed3ba":"markdown","f2bab6a0":"markdown","5bed86eb":"markdown","1125d3d3":"markdown","3ec18297":"markdown","c7f7ffdf":"markdown","e8f772ea":"markdown","a5e7c092":"markdown","470a6a9e":"markdown","f9ee0c28":"markdown","fc0e5bf8":"markdown","49c1e95e":"markdown","a7e8709f":"markdown","cd32c9c4":"markdown","89b719d5":"markdown","13b9a05d":"markdown","83234239":"markdown","0e0f2714":"markdown","3e33c442":"markdown","c77b0217":"markdown","4de4d588":"markdown"},"source":{"9aba87e1":"# Importing the required libraries for this project\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', 500)","6a21939f":"# Memory saving function credit to https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                #if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                #    df[col] = df[col].astype(np.float16)\n                #el\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        #else:\n            #df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB --> {:.2f} MB (Decreased by {:.1f}%)'.format(\n        start_mem, end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","cd088c3c":"# Loading train and test file and reducing its memeory consumption\n#%%time\ntrain = pd.read_csv('..\/input\/pubg-finish-placement-prediction\/train_V2.csv')\ntrain = reduce_mem_usage(train)\ntest = pd.read_csv('..\/input\/pubg-finish-placement-prediction\/test_V2.csv')\ntest = reduce_mem_usage(test)\nprint(train.shape, test.shape)","e4368228":"# Looking at first five train data\ntrain.head()","f5f3b020":"# Looking at last five train data\ntrain.tail()","2cd7650e":"# Looking at first five test data\ntest.head()","f9fb430f":"# Looking at last five test data\ntest.tail()","8b793a1a":"# To find the datatypes of the columns\ntrain.info()","904fb06a":"# Unique count in column Id, groupId, matchId\nfor i in ['Id', 'groupId', 'matchId']:\n    print(\"Unique values in column '{}' is: {}\".format(i,train[i].nunique()) )","341171e6":"train['matchType'].value_counts()","b75a7207":"mapper = lambda x: 'solo' if ('solo' in x) else 'duo' if ('duo' in x) else 'squad'","98896e7c":"train['matchType'] = train['matchType'].apply(mapper)\nsns.countplot(train['matchType'])\nplt.title('Count of different types of match')\nplt.show()","a7b7f6d6":"corr = train.corr()\nplt.figure(figsize=(20, 15))\nsns.heatmap(train.corr(), annot=True, fmt= '.1f', cmap=\"BrBG\")\nsns.set(font_scale=1.25)\nplt.show()","f4f6b746":"print(\"On an average a person kills {:.4f} players, 99% of people have {} kills or less, while the maximum kills ever recorded is {}.\".format(train['kills'].mean(),train['kills'].quantile(0.99), train['kills'].max()))","a3a4786b":"data = train.copy()\ndata.loc[data['kills'] > data['kills'].quantile(0.99)] = '8+'\nplt.figure(figsize=(15,8))\nsns.countplot(data['kills'].astype(str).sort_values())\nplt.title(\"Kill Count\")\nplt.show()","7b466e59":"data = train.copy()\ndata = data[data['kills']==0]\nplt.figure(figsize=(15,7))\nplt.title(\"Damage Dealt by 0 killers\")\nsns.distplot(data['damageDealt'])\nplt.show()","4eb668b8":"print(\"A total of {} players ({:.4f}%) have won without a single kill!\".format(len(data[data['winPlacePerc']==1]), 100*len(data[data['winPlacePerc']==1])\/len(train)))\ndata1 = train[train['damageDealt'] == 0].copy()\nprint(\"A total of {} players ({:.4f}%) have won without dealing damage!\".format(len(data1[data1['winPlacePerc']==1]), 100*len(data1[data1['winPlacePerc']==1])\/len(train)))","80ce5d2c":"kills = train.copy()\n\nkills['killsCategories'] = pd.cut(kills['kills'], [-1, 0, 2, 5, 10, 60], labels=[\n    '0_kills','1-2_kills', '3-5_kills', '6-10_kills', '10+_kills'])\n\nplt.figure(figsize=(15,8))\nsns.boxplot(x=\"killsCategories\", y=\"winPlacePerc\", data=kills)\nplt.show()","6028cecf":"print(\"{} players ({:.4f}%) walked 0 meters. This means that either they die before even taking a step or they have just joined the game but are away from keyboard (more possible).\".format(len(data[data['walkDistance'] == 0]), 100*len(data1[data1['walkDistance']==0])\/len(train)))","c53d4b31":"data = train.copy()\ndata = data[data['walkDistance'] < train['walkDistance'].quantile(0.99)]\nplt.figure(figsize=(15,7))\nplt.title(\"Walking Distance Distribution\")\nsns.distplot(data['walkDistance'])\nplt.show()","f5cb8c1e":"sns.jointplot(x=\"winPlacePerc\", y=\"walkDistance\",  data=train, height=10, ratio=3)\nplt.show()","6e9a959b":"print(\"An average person drives for {:.1f}m, 99% of people have drived {}m or less, while THE RIDER rode for {}m.\".format(train['rideDistance'].mean(), train['rideDistance'].quantile(0.99), train['rideDistance'].max()))","2044f713":"# Does work in Jupyter\n\"\"\"\ndata = train.copy()\ndata = data[data['rideDistance'] < train['rideDistance'].quantile(0.99)]\nplt.figure(figsize=(15,7))\nplt.title(\"Ride Distance Distribution\")\nsns.distplot(data['rideDistance'])\nplt.show()\n\n\"\"\"","a97fc838":"print(\"{} players ({:.4f}%) drived for 0 meters. This means that they like trekking more than riding.\".format(len(data[data['rideDistance'] == 0]), 100*len(data1[data1['rideDistance']==0])\/len(train)))","275ab896":"sns.jointplot(x=\"winPlacePerc\", y=\"rideDistance\", data=train, height=10, ratio=3)\nplt.show()","9eb4af7f":"plt.figure(figsize =(15,7))\nsns.pointplot(x='vehicleDestroys',y='winPlacePerc',data=data,color='lime',alpha=0.5)\nplt.xlabel('Count of Vehicle Destroys',fontsize = 16,color='blue')\nplt.ylabel('Win Percentage',fontsize = 16,color='blue')\nplt.title('Vehicle Destroyed\/ Win Ratio',fontsize = 20,color='blue')\nplt.grid()\nplt.show()","d0cdcab4":"print(\"In the game on an average a person uses {:.1f} heal items, 99% of people use {} or less, while the maximun used is {}.\".format(train['heals'].mean(), train['heals'].quantile(0.99), train['heals'].max()))\nprint(\"In the game on an average a person uses {:.1f} boost items, 99% of people use {} or less, while the maximun used is {}.\".format(train['boosts'].mean(), train['boosts'].quantile(0.99), train['boosts'].max()))","92e1d25f":"data = train.copy()\ndata = data[data['heals'] < data['heals'].quantile(0.99)]\ndata = data[data['boosts'] < data['boosts'].quantile(0.99)]","0147249f":"f,ax1 = plt.subplots(figsize =(15,7))\nsns.pointplot(x='heals',y='winPlacePerc',data=data,color='lime',alpha=0.8)\nsns.pointplot(x='boosts',y='winPlacePerc',data=data,color='blue',alpha=0.8)\nplt.text(4,0.6,'Heals',color='lime',fontsize = 16,style = 'italic')\nplt.text(4,0.55,'Boosts',color='blue',fontsize = 16,style = 'italic')\nplt.xlabel('Number of heal\/boost items',fontsize = 16,color='blue')\nplt.ylabel('Win Percentage',fontsize = 16,color='blue')\nplt.title('Heals vs Boosts',fontsize = 20,color='blue')\nplt.grid()\nplt.show()","9dd86d19":"sns.jointplot(x=\"winPlacePerc\", y=\"heals\", data=train, height=10, ratio=3, color=\"lime\")\nplt.show()","293ca24e":"sns.jointplot(x=\"winPlacePerc\", y=\"boosts\", data=train, height=10, ratio=3, color=\"blue\")\nplt.show()","f0b276c1":"data = train[train['matchType'] != 'solo']","5fd34874":"sns.jointplot(x=\"winPlacePerc\", y=\"DBNOs\", data=train, height=10, ratio=3)\nplt.show()","62dc1bb0":"sns.jointplot(x=\"winPlacePerc\", y=\"assists\", data=train, height=10, ratio=3)\nplt.show()","488b979d":"sns.jointplot(x=\"winPlacePerc\", y=\"revives\", data=train, height=10, ratio=3)\nplt.show()","77159a6b":"# Checking row with NaN value\ntrain[train['winPlacePerc'].isnull()]","f6c531e2":"train.drop(train[train['winPlacePerc'].isnull()].index, inplace=True)","2b04d13d":"# Engineer a new feature _totalDistance\ntrain['_totalDistance'] = train['rideDistance'] + train['walkDistance'] + train['swimDistance']","db5e0920":"# Engineer _headshot_rate feature --- headshots made per kill\ntrain['_headshot_rate'] = train['headshotKills'] \/ train['kills']\ntrain['_headshot_rate'] = train['_headshot_rate'].fillna(0)","b7727824":"#Defining some functions for plotting graphs\ndef show_countplot(column):\n    plt.figure(figsize=(15,7))\n    sns.countplot(data=train, x=column).set_title(column)\n    plt.show()\n    \ndef show_distplot(column):\n    plt.figure(figsize=(15,7))\n    sns.distplot(train[column],kde=True, bins=50)\n    plt.show()","91239c47":"show_countplot('kills')","d267a069":"# Is it even possible to kill more than 40 people by acquiring more than 55 weapons and maintaining a total distance of less than 100m?\ntrain[(train['kills'] >= 40) & (train['weaponsAcquired'] > 55) & (train['_totalDistance'] < 100.0)]","ca08949e":"# Is it even possible to kill more than 40 people without using any heals?\ntrain[(train['kills'] >= 40) & (train['heals'] == 0)]","729b03d5":"# Drop 'fraudsters' from above df\ntrain.drop(train[(train['kills'] >= 40) & (train['weaponsAcquired'] > 55) & (train['_totalDistance'] < 100.0)].index, inplace=True)\ntrain.drop(train[(train['kills'] >= 40) & (train['heals'] == 0)].index, inplace=True)","b36ace04":"# Plot the distribution of headshot_rate\n# Does work in Jupyter\n# show_distplot('_headshot_rate')","bfce3264":"# List of Hitman who made more than 10 kills and all the kills were done by headshot(perfect kill)\ndisplay(train[(train['_headshot_rate'] == 1) & (train['kills'] >=10)].shape)\ntrain[(train['_headshot_rate'] == 1) & (train['kills'] >= 10)].head(10)","436706f3":"# Create feature killsWithoutMoving\ntrain['_killsWithoutMoving'] = ((train['kills'] > 0) & (train['_totalDistance'] == 0))\n# Check players who kills without moving\ndisplay(train[train['_killsWithoutMoving'] == True].shape)\ntrain[train['_killsWithoutMoving'] == True].head(10)","e9556418":"# Droping kill without moving 'fraudsters'\ntrain.drop(train[train['_killsWithoutMoving'] == True].index, inplace=True)","41e9eb2f":"show_distplot('longestKill')","f2c62894":"# players who took these shots from more than 1km\ntrain[train['longestKill'] >= 1000]","aa8ae7a7":"# Droping these players\ntrain.drop(train[train['longestKill'] >= 1000].index, inplace=True)","6c6c5d29":"# Players who got more than 10 roadKills\ntrain[train['roadKills'] > 10]","f1cc4f1e":"# Drop roadKill 'fraudsters'\ntrain.drop(train[train['roadKills'] > 10].index, inplace=True)","7766214c":"train[['walkDistance', 'rideDistance', 'swimDistance']].describe().T","762975ef":"show_distplot('walkDistance')","058e4334":"# It is not possible for players to play to roam around and explore places without killing anyone \n# and how can they travel 13kms in the game?\ntrain[(train['walkDistance'] >= 13000) & (train['kills'] == 0)]","d08f24c2":"# Drop walking anomalies\ntrain.drop(train[(train['walkDistance'] >= 13000) & (train['kills'] == 0)].index, inplace=True)","dc1d4b1f":"show_distplot('rideDistance')","bbb7cdce":"# It is not possible for players to play to roam around and explore places without killing anyone \n# and how can you ride for 30km?\ntrain[(train['rideDistance'] >= 30000) & (train['kills'] == 0)]","f3d42b43":"# How is it even possible that a player is able to ride and kill without walking even a single meter ?\ntrain[(train['walkDistance'] == 0) & (train['rideDistance'] > 0) & (train['kills'] > 0)]","9615ad62":"# What was the player doing in the game when total distance travelled by him\/her is 0? \ntrain[(train['_totalDistance'] == 0)]","6b1c42f5":"# Drop riding anomalies\ntrain.drop(train[(train['rideDistance'] >= 30000) & (train['kills'] == 0)].index, inplace = True)\ntrain.drop(train[(train['walkDistance'] == 0) & (train['rideDistance'] > 0) & (train['kills'] > 0)].index, inplace = True)\ntrain.drop(train[(train['_totalDistance'] == 0)].index, inplace=True)","41a46767":"# Does work in Jupyter\n# show_distplot('swimDistance')","b0797ad4":"# How can player swim for more than 2 km without breathing?\ntrain[train['swimDistance'] >= 2000]","f3f6ff20":"# Remove outliers\ntrain.drop(train[train['swimDistance'] >= 2000].index, inplace=True)","5a069b97":"show_distplot('weaponsAcquired')","1645ce85":"display(train[train['weaponsAcquired'] >= 80].shape)\ntrain[train['weaponsAcquired'] >= 80].head()","1558939b":"# Remove outliers\ntrain.drop(train[train['weaponsAcquired'] >= 80].index, inplace=True)","abac1358":"show_distplot('heals')","94aca8b9":"# 40 or more healing items used\ndisplay(train[train['heals'] >= 40].shape)\ntrain[train['heals'] >= 40].head(10)","223d97f5":"# Remove outliers\ntrain.drop(train[train['heals'] >= 40].index, inplace=True)","584255eb":"train.shape","76783e3f":"train.to_csv('cleaned_data.csv', index=False)","46c09baa":"cleaned_data = pd.read_csv('cleaned_data.csv')\ncleaned_data = reduce_mem_usage(cleaned_data)","6fd35339":"cleaned_data.head()","18ecfa7b":"cleaned_data['_playersJoined'] = cleaned_data.groupby('matchId')['matchId'].transform('count')\ndata = cleaned_data.copy()\ndata = data[data['_playersJoined']>49]\nplt.figure(figsize=(15,7))\nsns.countplot(data['_playersJoined'])\nplt.title(\"Players Joined\",fontsize=15)\nplt.show()","f1adf0d1":"# Create normalized features\ncleaned_data['_killsNorm'] = cleaned_data['kills']*((100-cleaned_data['_playersJoined'])\/100 + 1)\ncleaned_data['_damageDealtNorm'] = cleaned_data['damageDealt']*((100-cleaned_data['_playersJoined'])\/100 + 1)\ncleaned_data['_maxPlaceNorm'] = cleaned_data['maxPlace']*((100-cleaned_data['_playersJoined'])\/100 + 1)\ncleaned_data['_matchDurationNorm'] = cleaned_data['matchDuration']*((100-cleaned_data['_playersJoined'])\/100 + 1)\n# Compare standard features and normalized features\nto_show = ['Id', 'kills','_killsNorm','damageDealt', '_damageDealtNorm', 'maxPlace', '_maxPlaceNorm', 'matchDuration', '_matchDurationNorm']\ncleaned_data[to_show][0:11]","970b7efd":"match = cleaned_data.groupby('matchId')\ncleaned_data['_killsPerc'] = match['kills'].rank(pct=True).values\ncleaned_data['_killPlacePerc'] = match['killPlace'].rank(pct=True).values\ncleaned_data['_walkDistancePerc'] = match['walkDistance'].rank(pct=True).values\ncleaned_data['_damageDealtPerc'] = match['damageDealt'].rank(pct=True).values\ncleaned_data['_walkPerc_killsPerc'] = cleaned_data['_walkDistancePerc'] \/ cleaned_data['_killsPerc']\ncleaned_data.head()","62314c6b":"corr = cleaned_data[['_killsPerc', '_killPlacePerc','_walkDistancePerc','_damageDealtPerc', '_walkPerc_killsPerc','winPlacePerc']].corr()","923c97d4":"plt.figure(figsize=(15,7))\nsns.heatmap(corr, annot=True,cmap=\"YlGnBu\")\nplt.show()","85fa78da":"agg = cleaned_data.groupby(['groupId']).size().to_frame('players_in_team')\ncleaned_data = cleaned_data.merge(agg, how='left', on=['groupId'])\ncleaned_data['_healthItems'] = cleaned_data['heals'] + cleaned_data['boosts']\ncleaned_data['_headshotKillRate'] = cleaned_data['headshotKills'] \/ cleaned_data['kills']\ncleaned_data['_killPlaceOverMaxPlace'] = cleaned_data['killPlace'] \/ cleaned_data['maxPlace']\ncleaned_data['_killsOverWalkDistance'] = cleaned_data['kills'] \/ cleaned_data['walkDistance']\ncleaned_data['_killsOverDistance'] = cleaned_data['kills'] \/ cleaned_data['_totalDistance']\ncleaned_data['_walkDistancePerSec'] = cleaned_data['walkDistance'] \/ cleaned_data['matchDuration']\ncleaned_data.head()","4dcf291b":"corr = cleaned_data[['killPlace', 'walkDistance','players_in_team','_healthItems', '_headshotKillRate', '_killPlaceOverMaxPlace', '_killsOverWalkDistance', '_killsOverDistance','_walkDistancePerSec','winPlacePerc']].corr()\nplt.figure(figsize=(15,7))\nsns.heatmap(corr, annot=True, cmap=\"BrBG\")\nplt.show()","0d86c80d":"# Less correlated wrt winPlacePerc\ncleaned_data.drop(['_headshotKillRate','_killsOverDistance', '_killsOverWalkDistance', ], axis=1, inplace=True)","0d5afd06":"cleaned_data.head()","859e54fc":"cols_to_fit = [col for col in cleaned_data.columns]\ncorr = cleaned_data[cols_to_fit].corr()\nf,ax = plt.subplots(figsize=(35, 25))\nsns.heatmap(cleaned_data[cols_to_fit].corr(), annot=True, fmt= '.1f',ax=ax, cmap=\"BrBG\")\nsns.set(font_scale=1.25)\nplt.show()","f0079689":"cleaned_data.drop(['killPoints','matchDuration','maxPlace','numGroups','rankPoints','roadKills','teamKills','winPoints',\n                   '_playersJoined', '_maxPlaceNorm', '_matchDurationNorm', '_killsWithoutMoving'], axis=1, inplace=True)","65e1fc36":"len(cleaned_data.columns)","8423e8b4":"corr_matrix = cleaned_data.corr().abs()\n\n# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.95\nto_drop = [column for column in upper.columns if any(upper[column] > 0.85)]","0be5a8d0":"to_drop","a7ccaadf":"# Drop features \ncleaned_data.drop(cleaned_data[to_drop], axis=1,inplace=True)","975e35ca":"cols_to_fit = [col for col in cleaned_data.columns]\ncorr = cleaned_data[cols_to_fit].corr()\nf,ax = plt.subplots(figsize=(30, 20))\nsns.heatmap(corr, annot=True, fmt= '.1f',ax=ax, cmap=\"BrBG\")\nsns.set(font_scale=1.25)\nplt.show()","7667d50e":"#saving highly correlated data\ncleaned_data.to_csv('Highly_correlated_data.csv', index=False)","8ad68170":"highly_corr = pd.read_csv('Highly_correlated_data.csv')\nhighly_corr = reduce_mem_usage(highly_corr)\n\nhighly_corr.shape","685f8e7c":"X_train = highly_corr[highly_corr['winPlacePerc'].notnull()].reset_index(drop=True)\nX_test = highly_corr[highly_corr['winPlacePerc'].isnull()].drop(['winPlacePerc'], axis=1).reset_index(drop=True)\n\n\nY_train = X_train.pop('winPlacePerc')\nX_test_grp = X_test[['matchId','groupId']].copy()\ntrain_matchId = X_train['matchId']\n\n# drop matchId,groupId\nX_train.drop(['matchId','groupId','Id'], axis=1, inplace=True)\nX_test.drop(['matchId','groupId','Id'], axis=1, inplace=True)\n\nprint(X_train.shape, X_test.shape)","c2c55876":"print('There are {} different Match types in the dataset.'.format(highly_corr['matchType'].nunique()))","f5516d36":"# One hot encode matchType\nhighly_corr = pd.get_dummies(highly_corr, columns=['matchType'])\n\n# Take a look at the encoding\nmatchType_encoding = highly_corr.filter(regex='matchType')\nmatchType_encoding.head()","72bdaf37":"# Turn groupId and match Id into categorical types\nhighly_corr['groupId'] = highly_corr['groupId'].astype('category')\nhighly_corr['matchId'] = highly_corr['matchId'].astype('category')\n\n# Get category coding for groupId and matchID\nhighly_corr['groupId_cat'] = highly_corr['groupId'].cat.codes\nhighly_corr['matchId_cat'] = highly_corr['matchId'].cat.codes\n\n# Get rid of old columns\nhighly_corr.drop(columns=['groupId', 'matchId'], inplace=True)\n\n# Lets take a look at our newly created features\nhighly_corr[['groupId_cat', 'matchId_cat']].head()","28be3c07":"# Drop Id column, because it probably won't be useful for our Machine Learning algorithm,\n# because the test set contains different Id's\nhighly_corr.drop(columns = ['Id'], inplace=True)","73cf7da3":"# Take sample for debugging and exploration\nsample = 500000\ndf_sample = highly_corr.sample(sample)","ce3de383":"# Split sample into training data and target variable\nX = df_sample.drop(columns = ['winPlacePerc']) #all columns except target\ny = df_sample['winPlacePerc'] # Only target variable","ae082f48":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.12, random_state=1)","44524934":"print('Sample train shape: ', X_train.shape, \n      'Sample target shape: ', y_train.shape, \n      'Sample validation shape: ', X_test.shape)","d853d545":"# Metric used for the PUBG competition (Mean Absolute Error (MAE))\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Function to print the MAE (Mean Absolute Error) score\n\ndef print_score(m : RandomForestRegressor):\n    res = ['mae train: ', mean_absolute_error(m.predict(X_train), y_train), \n           'mae val: ', mean_absolute_error(m.predict(X_test), y_test)]\n    #Score of the training dataset obtained using an out-of-bag estimate.\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","3edeb85d":"# Train basic model\nm1 = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features='sqrt', n_jobs=-1)\nm1.fit(X_train, y_train)\nprint_score(m1)","e738fc3e":"def rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}).sort_values('imp', ascending=False)","431c98e1":"# What are the most predictive features according to our basic random forest model\nfi = rf_feat_importance(m1, X); fi[:15]","ad8a9ae6":"# Plot a feature importance graph for the 20 most important features\nplot1 = fi[:15].plot('cols', 'imp', figsize=(14,6), legend=False, kind = 'barh')\nplot1","b8e8ea87":"X_train.columns","f1ea0447":"print(X_train.shape, y_train.shape)","9aeb3abf":"# Keep only significant features\nto_keep = fi[fi.imp>0.005].cols\nprint('Significant features: ', len(to_keep))\nto_keep\n\n# Make a DataFrame with only significant features\ndf_keep = X[to_keep].copy()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.12, random_state=1)","f420f405":"# Train model on top features\nm2 = RandomForestRegressor(n_estimators=80, min_samples_leaf=3, max_features='sqrt', n_jobs=-1)\nm2.fit(X_train, y_train)\nprint_score(m2)","c1502f97":"# Get feature importances of our top features\nfi_to_keep = rf_feat_importance(m2, X)\n\nfor i in list(fi_to_keep['cols']):\n    if i not in list(to_keep):\n        fi_to_keep = fi_to_keep[fi_to_keep.cols != i]\n        \nplot2 = fi_to_keep.plot('cols', 'imp', figsize=(14,6), legend=False, kind = 'barh')\nplot2","1e3d1a89":"import scipy\nfrom scipy.cluster import hierarchy as hc\n# Create a Dendrogram to view highly correlated features\ncorr = np.round(scipy.stats.spearmanr(df_keep).correlation, 4)\ncorr_condensed = hc.distance.squareform(1-corr)\nz = hc.linkage(corr_condensed, method='average')\nfig = plt.figure(figsize=(14,10))\ndendrogram = hc.dendrogram(z, labels=df_keep.columns, orientation='left', leaf_font_size=16)\nplt.plot()","94b9fce3":"train = highly_corr.copy()","04996690":"X = train.drop(columns = ['winPlacePerc']) # all columns except target\nX = X[to_keep] # Keep only relevant features\ny = train['winPlacePerc'] # target variable\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)","f4acf6be":"print('Sample train shape: ', X_train.shape, \n      'Sample target shape: ', y_train.shape, \n      'Sample validation shape: ', X_test.shape)","b7037d1b":"# Train final model\n# You should get better results by increasing n_estimators\n# and by playing around with the parameters\nm3 = RandomForestRegressor(n_estimators=50, min_samples_leaf=3, max_features=0.5,\n                          n_jobs=-1)\nm3.fit(X_train, y_train)\nprint_score(m3)","dfcf68e7":"test = pd.read_csv('..\/input\/pubg-finish-placement-prediction\/test_V2.csv')\ntest = reduce_mem_usage(test)","f337337e":"#Adding same features to test data\nagg = test.groupby(['groupId']).size().to_frame('players_in_team')\ntest = test.merge(agg, how='left', on=['groupId'])\ntest['_headshot_rate'] = test['headshotKills'] \/ test['kills']\ntest['_headshot_rate'] = test['_headshot_rate'].fillna(0)\ntest['_totalDistance'] = test['rideDistance'] + test['walkDistance'] + test['swimDistance']\ntest['_playersJoined'] = test.groupby('matchId')['matchId'].transform('count')\ntest['_killsNorm'] = test['kills']*((100-test['_playersJoined'])\/100 + 1)\ntest['_damageDealtNorm'] = test['damageDealt']*((100-test['_playersJoined'])\/100 + 1)\ntest['_damageDealtPerc'] = test['damageDealt'].rank(pct=True).values\ntest['_healthItems'] = test['heals'] + test['boosts']\ntest['killsWithoutMoving'] = ((test['kills'] > 0) & (test['_totalDistance'] == 0))\ntest['_killPlacePerc'] = test['killPlace'].rank(pct=True).values\ntest['_killsPerc'] = test['kills'].rank(pct=True).values\ntest['_walkDistancePerc'] = test['walkDistance'].rank(pct=True).values\ntest['_walkPerc_killsPerc'] = test['_walkDistancePerc'] \/ test['_killsPerc']\ntest['_killPlaceOverMaxPlace'] = test['killPlace'] \/ test['maxPlace']\ntest['_killsPerc'] = test['kills'].rank(pct=True).values\ntest['_walkDistancePerc'] = test['walkDistance'].rank(pct=True).values\ntest['_walkDistancePerSec'] = test['walkDistance'] \/ test['matchDuration']","414363b7":"test.head()","44c0818b":"# Turn groupId and match Id into categorical types\ntest['groupId'] = test['groupId'].astype('category')\ntest['matchId'] = test['matchId'].astype('category')\n\n# Get category coding for groupId and matchID\ntest['groupId_cat'] = test['groupId'].cat.codes\ntest['matchId_cat'] = test['matchId'].cat.codes","911e93ad":"test.columns","28cbffa1":"to_keep","475cac99":"# # Remove irrelevant features from the test set\ntest_pred = test[to_keep].copy()\n\n# Fill NaN with 0 (temporary)\ntest_pred.fillna(0, inplace=True)\ntest_pred.head()","2cd3218d":"predictions = np.clip(a = m3.predict(test_pred), a_min = 0.0, a_max = 1.0)\npred_df = pd.DataFrame({'Id' : test['Id'], 'winPlacePerc' : predictions})\npred_df\n# Create submission file\npred_df.to_csv(\"submission.csv\", index=False)","318fbf04":"#### Longest Kill","3ee965ac":"#### Defining function for calculating Mean Absolute Error (MAE)","0a77f85f":"###### Analysing the Kill","49598270":"- The headshotKills looks OK. So we will not delete these as of now.","88f62500":"For player Id c3e444f7d1289f rode just 5 meters but has killed 14 players in the roadkill. It is highly unlikely. Hence droping it.","efb80685":"### Analyzing Effect of Knocking (DBNO), Assisting or Reviving on Winning Percentage","add9614f":"#### Modifying the test data","1a8738bd":"#### Detecting Anomalies in Riding","5db50c3d":"- There are a few matches with less than 75 players that cannot be displayed here. As you can see most of the matches are nearly packed and have almost 100 players.","2eaf6ad1":"#### Swim Distance","03d579f5":"#### Removing features having 0 correlation with winPlacePerc","09686099":"###### Exploring diffrent match types:","8282c934":"#### Sampling","5ed8b1c8":"#### Dealing with categorical feature","1dd31108":"# PUBG: Battle Royal - Finish Placement Prediction","31801d63":"##### The size of the PUBG dataset is pretty big for a lower\/mid-range laptop so here's a script to make the dataset smaller without losing information.\n\n###### It uses the following approach:\n\n- Iterate over every column\n- Determine if the column is numeric\n- Determine if the column can be represented by an integer\n- Find the min and the max value\n- Determine and apply the smallest datatype that can fit the range of values\n- This reduces the dataset from approx. 900 MB to 466 MB","fb6ddcfc":"##### Effect of Kiiling on Winning percentage","6a6d60f2":"#### Finding Feature Importance using Random Forest","c810b94a":"Creating a new feature 'headshot_rate'. We see that the most players score in the 0 to 10% region. However, there are a few anomalies that have a headshot_rate of 100% percent with more than 9 kills!","56bc11ab":"#### Removing features having high correlation ","fe70f5d2":"#### Road Kills","f63ecb5e":"#### Basic Random Forest","759e7944":"A game in PUBG can have up to 100 players fighting each other. But most of the times a game isn't \"full\". There is no variable that gives us the number of players joined. So lets create one.","fbcce964":"#### Inhumane kills","8b9a8afa":"### Part 3: Feature Engineering","8a14f242":"Most kills are made from a distance of 100 meters or closer. However there are some players (outliers) who make a kill from more than 1km away. These players are probably fraudsters.","231cad4c":"###### Checking correlation of features with Win Percentage:","84aad8b0":"###### Theoretically, if a player is able to destroy the vehicle it indicates the he\/she is skilled. Let's check if this theory is correct.","57f84e95":"### Analysing Healing and Boosting\n","1d87aca0":"#### 100% Headshot Kills","b30ed3ba":"### Analysing Healing and Boosting: Effect of Healing & Boosting on Winning Percentage","f2bab6a0":"### Part 1: Exploratory Data Analysis","5bed86eb":"### Part 4: Final Predition","1125d3d3":"- Both healing and boosts have a high correlation with winning, however boosts matter more.","3ec18297":"#### Killing without Moving","c7f7ffdf":"- Destroying vehicles increases your chances of winning!","e8f772ea":"###### Analysing Walk Distance","a5e7c092":"#### Building a Random Forest Model with top features","470a6a9e":"## Tasks to be performed:\n#### Part 1: Exploratory Data Analysis\n#### Part 2: Data Cleaning: Outlier Detection and Removal - Finding the fraudsters\n#### Part 3: Feature Engineering\n#### Part 4: Final Predition","f9ee0c28":"- There classify the matchType into 3 types: Solo, Duo, Squad","fc0e5bf8":"##### Analysing Riding","49c1e95e":"There are a lot of groupId's and matchId's so one-hot encoding them is computational huge. We will turn them into category codes. That way we can still benefit from correlations between groups and matches in our Random Forest algorithm.","a7e8709f":"### Part 2: Data Cleaning: Outlier Detection and Removal - Finding the fraudsters","cd32c9c4":"- 'kills' has a high correlation with winPlacePerc.","89b719d5":"#### Normalizing the features\nNow that we have a feature '_playersJoined' we can normalize other features based on the amount of players. Features that can be valuable to normalize are:\n\n- kills\n- damageDealt\n- maxPlace\n- matchDuration","13b9a05d":"#### Detecting Anomalies in Walking","83234239":"### Finding anomaly in travelling","0e0f2714":"#### Anomalies detection in Supplies (WeaponAcquired)\n","3e33c442":"#### Modifying the test data","c77b0217":"- Walking has a high correlation with winPlacePerc.","4de4d588":"#### Anomalies in Heals"}}