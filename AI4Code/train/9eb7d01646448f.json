{"cell_type":{"ff1eba4c":"code","1c6e96d6":"code","6dd21d48":"code","12b9daf3":"code","c8de1fa0":"code","19377825":"code","861de675":"code","74c266d3":"code","40483d4d":"code","fb5638c8":"code","a5f8cfb2":"code","a488b764":"code","a848a5be":"code","b55dcc9f":"code","59948c06":"code","2b8ece07":"code","7a7ffb79":"code","bda8391b":"code","c3caf87e":"code","d31d09c3":"code","6e3b3f10":"code","230cec1a":"code","e609aec1":"code","b6ff7d87":"markdown","7649597e":"markdown","ee17ffca":"markdown","ca6affb4":"markdown","5d632fb0":"markdown","de929cfd":"markdown"},"source":{"ff1eba4c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1c6e96d6":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer","6dd21d48":"data = pd.read_csv('..\/input\/disease\/Disease.csv')","12b9daf3":"data.head()","c8de1fa0":"data.info()","19377825":"data.describe()","861de675":"labelencoder = LabelEncoder()\ndata['Disease1'] = labelencoder.fit_transform(data['Disease'])\ndata.head()","74c266d3":"data = data.drop(['Disease'],axis = 1)","40483d4d":"data.Disease1.value_counts()","fb5638c8":"data.info()","a5f8cfb2":"data.Disease1.value_counts().plot(kind=\"bar\", color=[\"Red\", \"Blue\"])","a488b764":"plt.figure(figsize =(10, 4)) \n  \ndata['Age'].hist(bins = 70)","a848a5be":"from sklearn.model_selection import train_test_split\n\nX = data.drop('Disease1', axis=1)\ny = data.Disease1\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","b55dcc9f":"from sklearn.tree import DecisionTreeClassifier\n\n\ntree_clf = DecisionTreeClassifier(random_state=0)\ntree_clf.fit(X_train, y_train)","59948c06":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report","2b8ece07":"test_score = accuracy_score(y_test, tree_clf.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, tree_clf.predict(X_train)) * 100\n\nresults_df = pd.DataFrame(data=[[\"Decision Tree Classifier\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\nresults_df","7a7ffb79":"pred = tree_clf.predict(X_train)\ntree_clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))","bda8391b":"print(classification_report(y_train, pred, labels=[0,1]))","c3caf87e":"from sklearn.model_selection import GridSearchCV","d31d09c3":"params = {\"criterion\":(\"gini\", \"entropy\"), \n          \"splitter\":(\"best\", \"random\"), \n          \"max_depth\":(list(range(1, 20))), \n          \"min_samples_split\":[2, 3, 4], \n          \"min_samples_leaf\":list(range(1, 20))\n          }\n\ntree_clf = DecisionTreeClassifier(random_state=0)\ntree_cv = GridSearchCV(tree_clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=3, iid=True)\ntree_cv.fit(X_train, y_train)\nbest_params = tree_cv.best_params_\nprint(f'Best_params: {best_params}')\n\ntree_clf = DecisionTreeClassifier(**best_params)\ntree_clf.fit(X_train, y_train)","6e3b3f10":"test_score = accuracy_score(y_test, tree_clf.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, tree_clf.predict(X_train)) * 100\n\ntuning_results_df = pd.DataFrame(data=[[\"Decision Tree Classifier\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\ntuning_results_df","230cec1a":"pred = tree_clf.predict(X_train)\ntree_clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))","e609aec1":"print(classification_report(y_train, pred, labels=[0,1]))","b6ff7d87":"#### Using Hyperparameter Tuning to increase Accuracy of the Model","7649597e":"#### The Precision of the Model is 86%","ee17ffca":"#### Using Label Encoder to Quantify the results","ca6affb4":"#### This project is aimed at find whether the Patient has Disease or not using Machine Learning\n#### Decision Tree Classifer model is used for this project. ","5d632fb0":"### Predicting Disease Based on Given Data","de929cfd":"#### Splitting the Dataset into Test and Train"}}