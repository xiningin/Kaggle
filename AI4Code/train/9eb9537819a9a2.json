{"cell_type":{"efd5caf3":"code","e81c4885":"code","e509ec2e":"code","b0d5db3b":"code","5d1d83e6":"code","e645ba77":"code","a5a6f429":"code","2646e319":"code","4977b1db":"code","7d83a81f":"code","78406b27":"code","ecb7334f":"code","7d3ed764":"code","c2dbdf24":"code","0d3b576c":"code","892b20de":"code","1a286b0c":"code","1af4a3f8":"code","bd01a968":"code","845bd2a4":"code","938f1549":"code","c3c4bc9a":"code","4ad9e455":"code","9024a523":"code","5107f2ac":"code","16e5d60f":"code","80ca2897":"code","97ca3987":"code","5b08c3d0":"code","05a2c9cc":"code","f710ac21":"code","e0a543e7":"code","bcd93e12":"code","bb82188f":"code","dc3c7284":"markdown","63fe4551":"markdown","a4bf3b8d":"markdown","82d34741":"markdown","486afbce":"markdown","da63bf63":"markdown","bc7183fc":"markdown","d58dcc11":"markdown","d9ee8c4b":"markdown","4426d252":"markdown","30eee4a2":"markdown","80f31bdd":"markdown","8d180c50":"markdown","9ad931f3":"markdown","56b722e6":"markdown","6f9b7374":"markdown","1f2f8cf1":"markdown"},"source":{"efd5caf3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e81c4885":"#Imports the libraries.\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","e509ec2e":"data = pd.read_csv(\"..\/input\/cyberbullying-classification\/cyberbullying_tweets.csv\")","b0d5db3b":"data.head()","5d1d83e6":"data['cyberbullying_type'].value_counts()","e645ba77":"data.info()","a5a6f429":"data.isnull().sum()","2646e319":"data.shape","4977b1db":"plt.figure(figsize=(14,6))\nsns.countplot(x ='cyberbullying_type',data = data,palette = 'rocket')\nplt.show()","7d83a81f":"def LABEL_ENCODING(c1):\n    from sklearn import preprocessing\n    label_encoder = preprocessing.LabelEncoder()\n    data[c1]= label_encoder.fit_transform(data[c1])\n    data[c1].unique()\nLABEL_ENCODING(\"cyberbullying_type\")\ndata","78406b27":"from wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nfrom wordcloud import ImageColorGenerator\ntext = \" \".join(i for i in data.tweet_text)\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\nplt.figure( figsize=(15,10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","ecb7334f":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\ncorpus = []\nfor i in range(0, len(data)):\n  review = re.sub('[^a-zA-Z]', ' ', data['tweet_text'][i])\n  review = review.lower()\n  review = review.split()\n  ps = PorterStemmer()\n  all_stopwords = stopwords.words('english')\n  all_stopwords.remove('not')\n  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n  review = ' '.join(review)\n  corpus.append(review)","7d3ed764":"corpus[2]","c2dbdf24":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 1500,ngram_range=(1,3))\nX = cv.fit_transform(corpus).toarray()\ny = data.iloc[:, -1].values","0d3b576c":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)","892b20de":"from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)","1a286b0c":"y_pred = classifier.predict(X_test)","1af4a3f8":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","bd01a968":"sns.heatmap(cm,annot =True)\nplt.show()","845bd2a4":"acc1 = accuracy_score(y_test, y_pred)","938f1549":"print(f\"Accuracy of Naive Bayes (Using Bag of words technique): {acc1}\")","c3c4bc9a":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_v=TfidfVectorizer(max_features=5000,ngram_range=(1,3))\nX=tfidf_v.fit_transform(corpus).toarray()","4ad9e455":"y=data['cyberbullying_type']","9024a523":"X.shape","5107f2ac":"from sklearn.model_selection import train_test_split\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","16e5d60f":"print(X1_train.shape)\nprint(X1_test.shape)\nprint(y1_train.shape)\nprint(y1_test.shape)","80ca2897":"count_df = pd.DataFrame(X1_train, columns=tfidf_v.get_feature_names())","97ca3987":"count_df","5b08c3d0":"from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X1_train, y1_train)\nGaussianNB()\ny1_pred = classifier.predict(X1_test)","05a2c9cc":"acc2 = accuracy_score(y1_test, y1_pred)","f710ac21":"print(f\"Accuracy of Naive Bayes (Using TF - IDF technique): {acc2}\")","e0a543e7":"from sklearn.naive_bayes import MultinomialNB\nclassifier=MultinomialNB()\nclassifier.fit(X1_train, y1_train)\npred = classifier.predict(X1_test)\npred = classifier.predict(X1_test)\nscore = accuracy_score(y1_test, pred)","bcd93e12":"score","bb82188f":"mylist=[]\nmylist2=[]\nmylist.append(acc1)\nmylist2.append(\"Naive Bayes(bag of words)\")\nmylist.append(acc2)\nmylist2.append(\"Naive Bayes (Using TF - IDF technique)\")\nmylist.append(score)\nmylist2.append(\"MultinomialNB\")\nplt.rcParams['figure.figsize']=8,6\nsns.set_style(\"darkgrid\")\nax = sns.barplot(x=mylist2, y=mylist, palette = \"rocket\", saturation =1.5)\nplt.xlabel(\"Classification Models\", fontsize = 20 )\nplt.ylabel(\"Accuracy\", fontsize = 20)\nplt.title(\"Accuracy of different Classification Models\", fontsize = 20)\nplt.xticks(fontsize = 11, horizontalalignment = 'center', rotation = 8)\nplt.yticks(fontsize = 13)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{height:.2%}', (x + width\/2, y + height*1.02), ha='center', fontsize = 'x-large')\nplt.show()","dc3c7284":"<h2>DataSet<\/h2>","63fe4551":"* weet_text : Text of the tweet\n* cyberbullying_type : Type of cyberbullying harassment.","a4bf3b8d":"![](https:\/\/i0.wp.com\/lawlex.org\/wp-content\/uploads\/2020\/05\/Cyber-Bullying640.jpg?ssl=1)","82d34741":"![](https:\/\/www.volunteer.ie\/wp-content\/uploads\/2017\/08\/Thank-You-word-cloud-1024x791.jpg)","486afbce":"# Splitting the dataset into the Training set and Test set","da63bf63":"# Creating the Bag of Words model","bc7183fc":"# Word cloud of tweet_text","d58dcc11":"# Naive Bayes (in TF - IDF)","d9ee8c4b":"# Training the Naive Bayes model on the Training set","4426d252":"> As social media usage becomes increasingly prevalent in every age group, a vast majority of citizens rely on this essential medium for day-to-day communication. Social media\u2019s ubiquity means that cyberbullying can effectively impact anyone at any time or anywhere, and the relative anonymity\n> of the internet makes such personal attacks more difficult to stop than traditional bullying.","30eee4a2":"<h3>DataSet Link<\/h3>","80f31bdd":"https:\/\/www.kaggle.com\/andrewmvd\/cyberbullying-classification","8d180c50":"# Using TF - IDF Method.","9ad931f3":"# Splitting the dataset into the Training set and Test set","56b722e6":"# MultinomialNB Algorithm","6f9b7374":"# Confusion matrix","1f2f8cf1":" # Cleaning the  tweet_texts"}}