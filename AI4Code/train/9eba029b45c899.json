{"cell_type":{"606c4837":"code","921e9930":"code","f9234972":"code","3e9260d4":"code","7974f856":"code","c4f39173":"code","69c614f8":"code","d0046b85":"code","01600af7":"code","797a93bf":"code","7925397e":"code","d891b591":"code","44621a77":"code","53103e71":"code","eecb21c2":"code","24359692":"code","b4073481":"code","d03d6075":"code","49d14deb":"code","0b9909fc":"code","c520ddc3":"code","aa53e537":"code","f2bd6871":"code","44ed67bb":"code","ce66208b":"code","5d0aba98":"code","7c8bcd62":"markdown","f65520de":"markdown","b7c9f65c":"markdown","6da830ee":"markdown","c31ed1b5":"markdown","41f25b37":"markdown","c32529e1":"markdown"},"source":{"606c4837":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport re\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom bs4 import BeautifulSoup as bs\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud\nfrom nltk.stem import WordNetLemmatizer\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report","921e9930":"train = pd.read_csv('..\/input\/word2vec-nlp-tutorial\/labeledTrainData.tsv.zip', delimiter = \"\\t\", encoding = 'utf-8')\ntest = pd.read_csv('..\/input\/word2vec-nlp-tutorial\/testData.tsv.zip', delimiter = \"\\t\", encoding = 'utf-8')","f9234972":"sub=pd.read_csv('..\/input\/word2vec-nlp-tutorial\/sampleSubmission.csv')","3e9260d4":"train.head()","7974f856":"# Getting to know data\nprint(train.shape)\nprint(test.shape)","c4f39173":"train['length']=train['review'].apply(len)\ntrain['length'].describe()","69c614f8":"#Sample review\nprint(train['review'][0])","d0046b85":"train_len=train['review'].apply(len)\ntest_len=test['review'].apply(len)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfig=plt.figure(figsize=(15,4))\nfig.add_subplot(1,2,1)\nsns.distplot((train_len),color='red')\n\nfig.add_subplot(1,2,2)\nsns.distplot((test_len),color='blue')","01600af7":"train['word_n'] = train['review'].apply(lambda x : len(x.split(' ')))\ntest['word_n'] = test['review'].apply(lambda x : len(x.split(' ')))\n\nfig=plt.figure(figsize=(15,4))\nfig.add_subplot(1,2,1)\nsns.distplot(train['word_n'],color='red')\n\nfig.add_subplot(1,2,2)\nsns.distplot(test['word_n'],color='blue')","797a93bf":"train['word_n'].describe()","7925397e":"cloud=WordCloud(width=800, height=600).generate(\" \".join(train['review'])) # join function can help merge all words into one string. \" \" means space can be a sep between words.\nplt.figure(figsize=(15,15))\nplt.imshow(cloud)\nplt.axis('off')","d891b591":"fig, axe = plt.subplots(1,3, figsize=(23,5))\nsns.countplot(train['sentiment'], ax=axe[0])\nsns.boxenplot(x=train['sentiment'], y=train['length'], data=train, ax=axe[1])\nsns.boxenplot(x=train['sentiment'], y=train['word_n'], data=train, ax=axe[2])","44621a77":"# English stopwords\n\nstopwords=stopwords.words(\"english\")\nwordnet_lemmatizer = WordNetLemmatizer()","53103e71":"def cleaning(raw_text):\n    # Removing HTML Tags\n    html_removed_text=bs(raw_text).get_text()\n    \n    # Remove any non character\n    character_only_text=re.sub(\"[^a-zA-Z]\",\" \",html_removed_text)\n    \n    # Lowercase and split\n    lower_text=character_only_text.lower().split()\n    \n    # Get STOPWORDS and remove\n    stop_remove_text=[i for i in lower_text if not i in stopwords]\n    \n    # Remove one character words\n    lemma_removed_text=[word for word in stop_remove_text if len(word)>1]\n    \n    #Lemmatization\n    lemma_removed_text=[wordnet_lemmatizer.lemmatize(word,'v') for word in stop_remove_text]\n    \n    \n    return \" \".join(lemma_removed_text)","eecb21c2":"cleaning(train['review'][0])","24359692":"train['cleaned_review']=train['review'].apply(cleaning)","b4073481":"train.head()","d03d6075":"test['review']=test['review'].apply(cleaning)","49d14deb":"# Splitting the data\n\nX=train['cleaned_review'] #Predictors\ny=train['sentiment'] #Target","0b9909fc":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","c520ddc3":"def create_vector(vectorizer,data):\n    '''Pass vectorizer and data'''\n    train_vector=vectorizer.transform(data.tolist())\n    return train_vector.toarray()","aa53e537":"vectorizer = CountVectorizer(analyzer = \"word\",   \n                             tokenizer = None,    \n                             preprocessor = None, \n                             stop_words = None,   \n                             max_features = 20000)\nvectorizer.fit(X_train.tolist())","f2bd6871":"X_train_vector=create_vector(vectorizer,X_train)\nX_test_vector=create_vector(vectorizer,X_test)","44ed67bb":"# RandomForestClassifier\n\nmodel_RMC=RandomForestClassifier(n_estimators=110)\nmodel_RMC.fit(X_train_vector,y_train)\n\n\ny_pred=model_RMC.predict(X_test_vector)","ce66208b":"print(classification_report(y_test,y_pred))","5d0aba98":"# Making a submission\n\ntest_feature_vector=create_vector(vectorizer,test['review'])\ntest_predictions=model_RMC.predict(test_feature_vector)\n\ntest['sentiment']=test_predictions\ntest[['id','sentiment']].to_csv(\"submission.csv\",index=False)","7c8bcd62":"* **Train and test set have a similar distribution of words in one review**\n* **The mean words count is 233 and std is 173 words**","f65520de":"# **Modeling**","b7c9f65c":"* **The distribution of sentiment is almost equal**\n* **Lengh and number of words is similar across review but positive one tends to have more words**","6da830ee":"#  **Exploratory Data Analysis**","c31ed1b5":"* **HTML tag like br should be removed**\n* **words like movie or film are present in every review**","41f25b37":"<h2 style=\"font-weight: bold\">Meets Bags of Popcorn<\/h2>\n\n<h4>This is my first published notebook on Kaggle About NLP, So I decided ofc to take a look at the Bag of Words Meets Bags of Popcorn Compeition \ud83d\ude04\ud83d\ude04<br><br>I will be doing a EDA of review texts, some Visualization and Pre-Processing. and finally modelling <br><\/h4>\n\n* <h5 style=\"font-weight: 700\">Your feedback is very welcome<\/h5>\n* <h5 style=\"font-weight: 700\">If you find this notebook useful, please don't forget to upvote it!<\/h5>","c32529e1":"# **Text Preprocessing**"}}