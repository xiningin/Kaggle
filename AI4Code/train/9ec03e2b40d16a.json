{"cell_type":{"6b9a7242":"code","1307ccd0":"code","ed41fa8b":"code","41888021":"code","2d19dbd5":"code","48a579fb":"code","2f4b1928":"code","d24905b9":"code","d67a9492":"code","4d9c6b9e":"code","f69581bb":"code","5f530c46":"code","fe7ae29f":"code","050a705c":"code","bb298cc1":"code","7364ef65":"code","58f85463":"code","2c01df05":"code","f9b98063":"code","76b6b4d7":"code","c952b8bb":"code","7f8783cb":"code","208ab8fc":"code","7f01eab3":"code","35869fe8":"code","e65556df":"code","da9d5ad7":"code","94660c09":"code","4f7950e0":"code","3ff0cd5c":"code","616c1c58":"code","30598813":"code","58783b9e":"code","13090bd8":"code","d205dd14":"code","af2ff36a":"code","72310241":"code","01fdff1c":"code","a723bddf":"code","d667222a":"code","6a172342":"code","b1bf0cfe":"code","a17695ba":"markdown","a48ebb9d":"markdown","d6b4778f":"markdown","39755c78":"markdown","339da973":"markdown","f1b6e0fd":"markdown","68c08014":"markdown","7d67f242":"markdown","6584c87c":"markdown","054a6e40":"markdown","4542d9bb":"markdown","be004920":"markdown","13c8cf2d":"markdown","c00ac500":"markdown"},"source":{"6b9a7242":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt \nimport math\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1307ccd0":"def calculate_describe(chunks):\n    return chunks.describe().values","ed41fa8b":"from math import radians, cos, sin, asin, sqrt\n\ndef haversine_distance(lat1, long1, lat2, long2,df):\n    data = df\n    phi1 = np.radians(df[lat1])\n    phi2 = np.radians(df[lat2])\n    R = 6371\n    delta_phi = np.radians(df[lat2]-df[lat1])\n    delta_lambda = np.radians(df[long2]-df[long1])\n    \n    #a = sin\u00b2((\u03c6B - \u03c6A)\/2) + cos \u03c6A . cos \u03c6B . sin\u00b2((\u03bbB - \u03bbA)\/2)\n    a = np.sin(delta_phi \/ 2.0) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda \/ 2.0) ** 2\n    \n    #c = 2 * atan2( \u221aa, \u221a(1\u2212a) )\n    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n    \n    #d = R*c\n    d = (R * c) #in kilometers\n    df['Distance'] = d\n    return d","41888021":"def data_cleaning(chunks):\n    chunks.dropna(axis = 0, inplace = True)\n    chunks.fare_amount = pd.to_numeric(chunks.fare_amount, errors='coerce')\n    chunks.passenger_count = pd.to_numeric(chunks.passenger_count, errors='coerce')    \n    chunks.pickup_latitude = pd.to_numeric(chunks.pickup_latitude, errors='coerce')\n    chunks.pickup_longitude = pd.to_numeric(chunks.pickup_longitude, errors='coerce')\n    chunks.dropoff_latitude = pd.to_numeric(chunks.dropoff_latitude, errors='coerce')\n    chunks.dropoff_longitude = pd.to_numeric(chunks.dropoff_longitude, errors='coerce')\n    return chunks","2d19dbd5":"def mapplots(df):\n    import plotly.express as px\n    fig = px.scatter_mapbox(df, lat=\"pickup_latitude\", lon=\"pickup_longitude\", hover_name=\"passenger_count\", hover_data=['passenger_count','fare_amount'],\n                        color_discrete_sequence=[\"black\"], zoom=3, height=300)\n    fig.update_layout(mapbox_style=\"open-street-map\")\n    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n    fig.show()","48a579fb":"def add_new_date_time_features(dataset):\n    dataset['pickup_datetime'] = pd.to_datetime(dataset['pickup_datetime'],format=\"%Y-%m-%d %H:%M:%S UTC\")\n    dataset['hour'] = dataset.pickup_datetime.dt.hour\n    dataset['day'] = dataset.pickup_datetime.dt.day\n    dataset['month'] = dataset.pickup_datetime.dt.month\n    dataset['year'] = dataset.pickup_datetime.dt.year\n    dataset['day_of_week'] = dataset.pickup_datetime.dt.dayofweek\n    \n    return dataset","2f4b1928":" dft=  pd.read_csv('\/kaggle\/input\/iiitb2019nyctaxifare\/TrainTest\/train.csv', nrows=2_500_000)","d24905b9":"dft.head()","d67a9492":"def map_box(dft):\n    dft.drop(index=dft[(dft.pickup_longitude <= -75) \n                         | (dft.pickup_longitude >= -72) \n                         | (dft.dropoff_longitude <= -75) \n                         | (dft.dropoff_longitude >= -72)\n                         | (dft.pickup_latitude <= 39)\n                         | (dft.pickup_latitude >= 42)\n                         | (dft.dropoff_latitude <= 39)\n                         | (dft.dropoff_latitude >= 42)].index, inplace=True)\n    return dft","4d9c6b9e":"haversine_distance('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude',df)\ndf.head(10)","f69581bb":"print(\"old size: %d\" % len(df))\ndf = df[df.fare_amount >=0]\nprint(\"New size: %d\" % len(df))","5f530c46":"df[df.fare_amount>600]","fe7ae29f":"print(\"old size: %d\" % len(df))\ndf = df[df.fare_amount <=600]\nprint(\"New size: %d\" % len(df))","050a705c":"df = df[df.passenger_count<12]","bb298cc1":"from sklearn.ensemble import RandomForestRegressor\n\n\nchunks = pd.read_csv(\"\/kaggle\/input\/iiitb2019nyctaxifare\/TrainTest\/train.csv\", nrows = 5_00,low_memory=False)\nrf = RandomForestRegressor(warm_start=True,n_estimators= 20)\n\nchunks = data_cleaning(chunks)\nchunks = chunks.drop('key',axis=1)\nchunks = chunks[chunks.fare_amount >=0]\nchunks = chunks[chunks.fare_amount <=600]\nchunks = chunks[chunks.passenger_count<12]\nadd_new_date_time_features(chunks)\nchunks = chunks.drop('pickup_datetime',axis=1)\nchunks = map_box(chunks)\nhaversine_distance('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude',chunks)\nX = chunks.iloc[:,chunks.columns!='fare_amount']\ny = chunks['fare_amount'].values  \nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\nrf.fit(X_train, y_train)\npred = rf.predict(X_test)\nmse = mean_squared_error(y_test,pred)\nrmse = math.sqrt(mse)\nprint (rmse)\nprint(chunks.shape)","7364ef65":"from sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",rf.score(X_test,y_test))","58f85463":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nchunks1 = 5_000\ni = 0 \nz = []\nrf = RandomForestRegressor(warm_start=True,n_estimators= 20)\nglobal testP\nglobal pred\nfor chunks in pd.read_csv(\"\/kaggle\/input\/iiitb2019nyctaxifare\/TrainTest\/train.csv\", chunksize = chunks1,low_memory=False):\n    i = i+1\n    chunks = data_cleaning(chunks)\n    chunks = chunks.drop('key',axis=1)\n    chunks = chunks[chunks.fare_amount >=0]\n    chunks = chunks[chunks.fare_amount <=600]\n    chunks = chunks[chunks.passenger_count<12]\n    add_new_date_time_features(chunks)\n    chunks = chunks.drop('pickup_datetime',axis=1)\n    chunks = map_box(chunks)\n    haversine_distance('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude',chunks)\n    X_train = chunks.iloc[:,chunks.columns!='fare_amount']\n    Y_train = chunks['fare_amount'].values    \n    \n    if(i < 10002):\n        rf.fit(X_train, Y_train)\n        rf.n_estimators += 1\n    print(\"iteration no: \"+str(i))    \n\n    if(i==10002):\n        testP = Y_train\n        pred = rf.predict(X_train)\n        break","2c01df05":"from sklearn.metrics import mean_squared_error\nimport math\nmse = mean_squared_error(testP,pred)\nrmse = math.sqrt(mse)\nprint (rmse)","f9b98063":"# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",rf.score(X_train,testP))","76b6b4d7":"chunks = pd.read_csv(\"\/kaggle\/input\/iiitb2019nyctaxifare\/TrainTest\/train.csv\", nrows = 500,low_memory=False)\n\nchunks.head()","c952b8bb":"\ni = 0 \n\nestimators = [ 20 , 60 , 65 ,70 , 75, 80  ]\nchunks = pd.read_csv(\"\/kaggle\/input\/iiitb2019nyctaxifare\/TrainTest\/train.csv\", nrows = 5_0000,low_memory=False)\nchunks = chunks.drop('key',axis=1)\nchunks = data_cleaning(chunks)\nchunks = chunks[chunks.fare_amount >=0]\nchunks = chunks[chunks.fare_amount <=600]\nchunks = chunks[chunks.passenger_count<12]\nadd_new_date_time_features(chunks)\nchunks = chunks.drop('pickup_datetime',axis=1)\nchunks = map_box(chunks)\nhaversine_distance('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude',chunks)\n\ntest_results = []\nfor estimator in estimators:\n    rf = RandomForestRegressor(n_estimators=estimator, n_jobs=-1,warm_start = True)\n    \n    i = i+1\n    X = chunks.iloc[:,chunks.columns!='fare_amount']\n    y = chunks['fare_amount'].values  \n    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n    rf.fit(X_train, y_train)\n    pred = rf.predict(X_test)\n    mse = mean_squared_error(y_test,pred)\n    rmse = math.sqrt(mse)\n    test_results.append(rmse)\n    print(\"iteration no: \"+str(i))    \n    \nax = plt.axes()   \nax.plot(estimators,test_results)\nplt.show()","7f8783cb":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt \nimport math\ni = 0 \n\nmax_features1 = [0.1 , 0.2 , 0.3 , 0.4 , 0.5]\nchunks = pd.read_csv(\"\/kaggle\/input\/iiitb2019nyctaxifare\/TrainTest\/train.csv\", nrows = 5_000_0,low_memory=False)\nchunks = chunks.drop('key',axis=1)\nchunks = data_cleaning(chunks)\nchunks = chunks[chunks.fare_amount >=0]\nchunks = chunks[chunks.fare_amount <=600]\nchunks = chunks[chunks.passenger_count<12]\nadd_new_date_time_features(chunks)\nchunks = chunks.drop('pickup_datetime',axis=1)\nchunks = map_box(chunks)\nhaversine_distance('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude',chunks)\n\ntest_results = []\nfor features in max_features1:\n    rf = RandomForestRegressor(n_estimators= 70, n_jobs=-1,max_features = features)\n    \n    i = i+1\n    X = chunks.iloc[:,chunks.columns!='fare_amount']\n    y = chunks['fare_amount'].values  \n    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n    rf.fit(X_train, y_train)\n    pred = rf.predict(X_test)\n    mse = mean_squared_error(y_test,pred)\n    rmse = math.sqrt(mse)\n    test_results.append(rmse)\n    print(\"iteration no: \"+str(i))    \n    \n","208ab8fc":"ax = plt.axes()   \nax.plot(max_features1,test_results)\nplt.show()","7f01eab3":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt \nimport math\ni = 0 \n\nmin_samples_leaf1 = [1 , 2 ,3 ,10 , 40]\nchunks = pd.read_csv(\"\/kaggle\/input\/iiitb2019nyctaxifare\/TrainTest\/train.csv\", nrows = 5_0,low_memory=False)\nchunks = chunks.drop('key',axis=1)\nchunks = data_cleaning(chunks)\nchunks = chunks[chunks.fare_amount >=0]\nchunks = chunks[chunks.fare_amount <=600]\nchunks = chunks[chunks.passenger_count<12]\nadd_new_date_time_features(chunks)\nchunks = chunks.drop('pickup_datetime',axis=1)\nchunks = map_box(chunks)\nhaversine_distance('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude',chunks)\n\ntest_results = []\nfor leaves in min_samples_leaf1:\n    rf = RandomForestRegressor(n_estimators= 70, n_jobs=-1,max_features = 0.45 , min_samples_leaf = leaves)\n    \n    i = i+1\n    X = chunks.iloc[:,chunks.columns!='fare_amount']\n    y = chunks['fare_amount'].values  \n    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n    rf.fit(X_train, y_train)\n    pred = rf.predict(X_test)\n    mse = mean_squared_error(y_test,pred)\n    rmse = math.sqrt(mse)\n    test_results.append(rmse)\n    print(\"iteration no: \"+str(i))    \n    \nax = plt.axes()   \nax.plot(min_samples_leaf1,test_results)\nplt.show()","35869fe8":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nchunks1 = 50_000\ni = 0 \nz = []\nrf = RandomForestRegressor(n_estimators=80, max_features=0.5, n_jobs=-1, warm_start =True)\nglobal testP\nglobal pred\nfor chunks in pd.read_csv(\"\/kaggle\/input\/iiitb2019nyctaxifare\/TrainTest\/train.csv\", chunksize = chunks1,low_memory=False):\n    i = i+1\n    chunks = data_cleaning(chunks)\n    chunks = chunks.drop('key',axis=1)\n    chunks = chunks[chunks.fare_amount >=0]\n    chunks = chunks[chunks.fare_amount <=600]\n    chunks = chunks[chunks.passenger_count<12]\n    add_new_date_time_features(chunks)\n    chunks = chunks.drop('pickup_datetime',axis=1)\n    chunks = map_box(chunks)\n    haversine_distance('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude',chunks)\n    X_train = chunks.iloc[:,chunks.columns!='fare_amount']\n    Y_train = chunks['fare_amount'].values    \n    \n    if(i < 51):\n        rf.fit(X_train, Y_train)\n        rf.n_estimators += 1\n    print(\"iteration no: \"+str(i))    \n\n    if(i==51):\n        testP = Y_train\n        pred = rf.predict(X_train)\n        break","e65556df":"import lightgbm as lgbm\nparams = {\n        'boosting_type':'gbdt',\n        'objective': 'regression',\n        'nthread': 4,\n        'num_leaves': 35,\n        'learning_rate': 0.05,\n        'max_depth': -1,\n        'subsample': 0.8,\n        'bagging_fraction' : 1,\n        'max_bin' : 5000 ,\n        'bagging_freq': 20,\n        'colsample_bytree': 0.6,\n        'metric': 'rmse',\n        'min_split_gain': 0.5,\n        'min_child_weight': 1,\n        'min_child_samples': 10,\n        'scale_pos_weight':1,\n        'zero_as_missing': True,\n        'seed':0,\n        'num_rounds':50000\n    }\n\n\ndef LGBMmodel(X_train,y_train,params):\n    matrix_train = lgbm.Dataset(X_train, y_train)\n    model=lgbm.train(params=params,\n                    train_set=matrix_train,\n                    num_boost_round=100000, \n                    early_stopping_rounds=500,\n                    verbose_eval=100)\n    return model","da9d5ad7":"import lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n\nparams = {\n    'objective':'regression',\n    'num_leaves':35,\n    'n_estimators':300\n}\n\nchunks1 = 50_000\ni = 0 \nz = []\nglobal testP\nglobal pred\n\nfor chunks in pd.read_csv(\"\/kaggle\/input\/iiitb2019nyctaxifare\/TrainTest\/train.csv\", chunksize = chunks1,low_memory=False):\n    i = i+1\n    chunks = data_cleaning(chunks)\n    chunks = chunks.drop('key',axis=1)\n    chunks = chunks[chunks.fare_amount >=0]\n    chunks = chunks[chunks.fare_amount <=600]\n    chunks = chunks[chunks.passenger_count<12]\n    add_new_date_time_features(chunks)\n    chunks = chunks.drop('pickup_datetime',axis=1)\n    chunks = map_box(chunks)\n    haversine_distance('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude',chunks)\n    X_train = chunks.iloc[:,chunks.columns!='fare_amount']\n    Y_train = chunks['fare_amount'].values    \n    train_data = lgb.Dataset(X_train, Y_train)\n    print('iteration = '+str(i))\n    if(i == 50):\n        testP=X_train\n        pred=Y_train\n        break;\n    if(i == 1):\n        gbm = lgb.train(params, train_data, num_boost_round = 10)\n    else:\n        gbm = lgb.train(params, train_data, num_boost_round = 10,init_model = gbm)\n\n        \ngbm.save_model('model.txt')\ny_pred = gbm.predict(testP, num_iteration=gbm.best_iteration)","94660c09":"gbm\n\n","4f7950e0":"from sklearn.metrics import mean_squared_error\nimport math\n\nmse = mean_squared_error(testP,pred)\nrmse = math.sqrt(mse)\nprint (rmse)","3ff0cd5c":"# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",rf.score(X_train,testP))\n","616c1c58":"from sklearn.externals import joblib\njoblib.dump(rf, 'modrf2.pkl') \n","30598813":"test = pd.read_csv(\"\/kaggle\/input\/iiitb2019nyctaxifare\/TrainTest\/test.csv\")","58783b9e":"import time\nstart_time = time.time() \n\ndef test_box(dft):\n    dft['dropoff_latitude'].fillna(dft['dropoff_latitude'].mean(), inplace = True)\n    dft['dropoff_longitude'].fillna(dft['dropoff_longitude'].mean(), inplace = True)\n    dft['pickup_latitude'].fillna(dft['pickup_latitude'].mean(), inplace = True)\n    dft['pickup_longitude'].fillna(dft['pickup_longitude'].mean(), inplace = True)\n    ind = dft[(dft.pickup_longitude <= -75) | (dft.pickup_longitude >= -72) | (dft.dropoff_longitude <= -75) | (dft.dropoff_longitude >= -72)\n                             | (dft.pickup_latitude <= 39)\n                             | (dft.pickup_latitude >= 42)\n                             | (dft.dropoff_latitude <= 39)\n                             | (dft.dropoff_latitude >= 42)].index\n    print(len(ind))\n    k=0\n    mplat = dft['pickup_latitude'].median()\n    mplon = dft['pickup_longitude'].median()\n    mdlat = dft['dropoff_latitude'].median()\n    mdlon = dft['dropoff_longitude'].median()\n    for i in ind:\n        k=k+1\n        print(k)\n        dft.pickup_longitude.at[i] = mplon;\n        dft.pickup_latitude.at[i] = mplat\n        dft.dropoff_latitude = mdlat\n        dropoff_longitude = mdlon\n    return dft\ntest = test_box(test)\nprint(\"%s seconds\" % (time.time() - start_time))\nhaversine_distance('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude',test)\n\nind = test[test['Distance']<=0].index\nfor i in ind:\n    test.Distance.at[i] = 2.5\n#test.head()","13090bd8":"temp = test['key']\ntemp.to_csv(\"key.csv\", index = False , header = ['key'] )\ntest = test.drop('key',axis=1)","d205dd14":"add_new_date_time_features(test)\ntest = test.drop('pickup_datetime',axis=1)","af2ff36a":"pred = rf.predict(test)\nkey_temp = pd.read_csv(\"key.csv\")\ntest['key'] = key_temp\ntest['fare_amount'] = pred","72310241":"test.head()","01fdff1c":"result.head()","a723bddf":"result = test.loc[:, [ 'key','fare_amount']]\nresult.to_csv(\"submit_2.csv\", index = False )\n","d667222a":"read = pd.read_csv(\"submit_2.csv\")\nread.head(5)","6a172342":"read.shape","b1bf0cfe":"read.shape()","a17695ba":"Function to convert dtypes of pickup date time from objects to datetime format, and dropping the null values ","a48ebb9d":"There are only 33 values in 5_000_000 rows.. so we just drop them\nAlso we convert those string dtypes to float in the data set","d6b4778f":"Function to plot on map","39755c78":"**Modelling**","339da973":"As there are only 8 rows we can drop these values. Since the distance between  is of the garbage value. Better to drop these off","f1b6e0fd":"Checking out the dtypes shows us that there are some string values in the data set","68c08014":"Passenger count cannot be more then 12 considering everyone as kid, still more then 12 is physically impossible ","7d67f242":"Removing the negative values in the fare column ","6584c87c":"Also the fare amount cannot be above 600, it could be because of the incorrect input values ","054a6e40":"tuning hyperparameter a little more","4542d9bb":"Calculating distance between two points, adding this feature as this directly effects the fare amount","be004920":"Now we check for the outliers and other things like mean,SD and min max values for 5_000_000 * 5 rows","13c8cf2d":"Best n estimator is around 70 ","c00ac500":"**Optimisation will happen now**\nThe RMSE for our model is approx around 4.5 to 6 \nNow we need to tune our hyperparameters to get a better model "}}