{"cell_type":{"0135ead1":"code","b808162f":"code","04962a2a":"code","68478549":"code","968d00c1":"code","733ba69a":"code","dc43e6ac":"code","7d0b6418":"code","8e5b0054":"code","053bf885":"code","09003133":"code","fd274e8e":"code","7b7421cb":"code","61d6e040":"code","86e41057":"code","2b9db483":"code","b6b16246":"code","e7446c2f":"code","6a606b5b":"code","fc77c4ec":"code","2018d442":"code","1526e498":"code","8122c927":"code","6f69fe23":"code","9212bd1b":"code","d62dbdd8":"code","066a9c07":"code","7bda7b1f":"code","f42a2e49":"code","68316bfc":"code","2e2320b7":"code","fde5a255":"code","7acae730":"code","7343dba3":"code","fb3b3538":"code","38b6398f":"code","cb28ec53":"markdown","91e59cc0":"markdown","d670c7e6":"markdown","0d494a90":"markdown","05873e79":"markdown","d2b9f47a":"markdown","6f9740e6":"markdown","e2d46b6b":"markdown","76f326ba":"markdown","fee307d0":"markdown","ca1fdef1":"markdown","0d21f5d4":"markdown"},"source":{"0135ead1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b808162f":"df = pd.read_csv('\/kaggle\/input\/supermarket-sales\/supermarket_sales - Sheet1.csv')","04962a2a":"def edaFromData(dfA, allEDA=False, desc='Exploratory Data Analysis'):\n    print('Explorando os dados')\n    print(f'\\nShape:\\n{dfA.shape}')\n    print(f'\\nIs Null:\\n{dfA.isnull().mean().sort_values(ascending=False)}')\n    dup = dfA.duplicated()\n    print(f'\\nDuplicated: \\n{dfA[dup].shape}\\n')\n    try:\n        print(dfA[dfA.duplicated(keep=False)].sample(4))\n    except:\n        pass\n    if allEDA:  # here you put yours prefered analysis that detail more your dataset\n        \n        print(f'\\nDTypes - Numerics')\n        print(dfA.describe(include=[np.number]))\n        print(f'\\nDTypes - Categoricals')\n        print(dfA.describe(include=['object']))\n        \n        #print(df.loc[:, df.dtypes=='object'].columns)\n        print(f'\\nHead dos dados:\\n{dfA.head()}')\n        print(f'\\nSamples dos dados:\\n{dfA.sample(2)}')\n        print(f'\\nTail dos dados:\\n{dfA.tail()}')","68478549":"edaFromData(df)","968d00c1":"df.head(3)","733ba69a":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tabulate import tabulate","dc43e6ac":"def correlation(dfA, varT, minValue=0.5, showGraphic=True, title='Correlation between variables'):\n    corr = dfA.corr()\n    print(f'\\nAnalysing features:\\n'\n          f'Target: {varT}\\n'\n          f'minValue de ref.: {minValue}\\n'\n          f'\\nMain Features:')\n    corrs = corr[varT]\n    features = []\n    for i in range(0, len(corrs)):\n        if corrs[i] > minValue and corrs.index[i] != varT:\n            print(corrs.index[i], f'{corrs[i]:.2f}')\n            features.append(corrs.index[i])\n    if showGraphic:\n        fig = plt.subplots(figsize=(15,8))\n        sns.heatmap(corr,\n                    annot=True, fmt='.2f', vmin=-1, vmax=1, linewidth=0.01,\n                    linecolor='black', cmap='RdBu_r'\n                    )\n        plt.title(title)\n        plt.show()\n    \n    return features","7d0b6418":"varTarget = 'Quantity'\nvarFeatures = correlation(dfA=df, varT=varTarget)","8e5b0054":"def sepColumns(dataset):\n    num = []\n    cat = []\n    for i in dataset.columns:\n        if dataset[i].dtype == 'object':\n            cat.append(i)\n        else:\n            num.append(i)\n    return num, cat","053bf885":"num, cat = sepColumns(df)\nnum, cat","09003133":"for x in cat:\n    df[x] = df[x].str.lower()\ndf[cat].sample(3)","fd274e8e":"branch = df.Branch.unique().tolist()\ncity = df.City.unique().tolist()\ncustomerType = df['Customer type'].unique().tolist()\ngender = df.Gender.unique().tolist()\nproductLine = df['Product line'].unique().tolist()\npayment = df.Payment.unique().tolist()","7b7421cb":"df['year'] = pd.DatetimeIndex(df['Date']).year\ndf['month'] = pd.DatetimeIndex(df['Date']).month","61d6e040":"df['branchNum'] = df['Branch'].apply(lambda x: branch.index(x))\ndf['cityNum'] = df['City'].apply(lambda x: city.index(x))\ndf['customerTypeNum'] = df['Customer type'].apply(lambda x: customerType.index(x))\ndf['genderNum'] = df['Gender'].apply(lambda x: gender.index(x))\ndf['productLineNum'] = df['Product line'].apply(lambda x: productLine.index(x))\ndf['paymentNum'] = df['Payment'].apply(lambda x: payment.index(x))\n","86e41057":"df.sample(3)","2b9db483":"num, cat = sepColumns(df)","b6b16246":"varFeatures = correlation(dfA=df[num], varT=varTarget, minValue=0.5, showGraphic=True)","e7446c2f":"df[varFeatures].describe()","6a606b5b":"def removeOutliers(out, varTarget):\n    print('\\nOutliers\\nRemoving ...', end='')\n    cidgrp = out[varTarget]\n    print('..', end='')\n    # quantiles\n    qtl1 = cidgrp.quantile(.25)  \n    qtl3 = cidgrp.quantile(.75)\n    print('..', end='')\n    # calculating iqr\n    iqr = qtl3 - qtl1\n    print('..', end='')\n\n    # creating limits\n    baixo = qtl1 - 1.5 * iqr\n    alto = qtl3 + 1.5 * iqr\n    print('..', end='')\n\n    # removing outliers\n    novodf = pd.DataFrame()\n    print('..', end='')\n\n    limites = out[varTarget].between(left=baixo, right=alto, inclusive=True)\n    novodf = pd.concat([novodf, out[limites]])\n\n    print('.....Done')\n\n    return novodf","fc77c4ec":"noOut = removeOutliers(df, varTarget)\n# Is there outlier?\nsns.set(style=\"whitegrid\")\n# Two subplots\nfig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True, figsize=(15,5))\nsns.boxplot(x=df[varTarget], ax=ax1).set_title('Original')\nsns.boxplot(x=noOut[varTarget], ax=ax2).set_title('Original No outliers')","2018d442":"print(df[varTarget].describe())\nsns.barplot(x=df[varTarget].describe().index[1:], y=df[varTarget].describe().values[1:])","1526e498":"print(noOut[varTarget].describe())\nsns.barplot(x=noOut[varTarget].describe().index[1:], y=noOut[varTarget].describe().values[1:])","8122c927":"varTarget = 'Total'\nvarFeatures = correlation(noOut, varT=varTarget, minValue=0.1, showGraphic=True)","6f69fe23":"# ML Algorithms sklearn\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, PoissonRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.dummy import DummyRegressor\n\n# ML selecao de dados de treino e teste\nfrom sklearn.model_selection import train_test_split\n# calcular o menor erro medio absoluto entre 2 dados apresentados\nfrom sklearn.metrics import mean_absolute_error","9212bd1b":"regressors = [\n        DecisionTreeRegressor(),\n        RandomForestRegressor(),\n        SVR(),\n        LinearRegression(),\n        GradientBoostingRegressor(),\n        PoissonRegressor(),\n        DummyRegressor(),\n        LogisticRegression(),\n        GaussianNB()\n    ]","d62dbdd8":"X = noOut[varFeatures]\ny = noOut[varTarget]\nXtreino, Xteste, ytreino, yteste = train_test_split(X, y, test_size=0.3, random_state=123)","066a9c07":"reg = []\nmae = []\nsco = []\nfor regressor in regressors:\n    modelo = RandomForestRegressor()\n    modelo.fit(Xtreino, np.array(ytreino))\n    sco.append(modelo.score(Xtreino, ytreino))\n    previsao = modelo.predict(Xteste)\n    mae.append(round(mean_absolute_error(yteste, previsao), 2))\n    reg.append(regressor)","7bda7b1f":"meuMae = pd.DataFrame(columns=['Regressor', 'mae', 'score'])\nmeuMae['Regressor'] = reg\nmeuMae['mae'] = mae\nmeuMae['score'] = sco","f42a2e49":"meuMae = meuMae.sort_values(by='score', ascending=False)\nmeuMae","68316bfc":"f'Best Regressor: {meuMae[\"Regressor\"].values[0]}'","2e2320b7":"noOut.sample(3)","fde5a255":"varFeatures = ['genderNum', 'customerTypeNum']\nvalFeatures = [gender.index('male'), customerType.index('member')]\nvarFeatures, valFeatures","7acae730":"model = meuMae[\"Regressor\"].values[0]\nx = noOut[varFeatures]\ny = noOut[varTarget]\nmodel.fit(x, y)","7343dba3":"predict = float(model.predict([valFeatures]))","fb3b3538":"print(f'Summary:\\n'\n          f'Regs analyzed: {len(noOut)}\\n'\n          f'ML applied: {meuMae[\"Regressor\"].values[0]}\\n'\n          f'Features analyzed:')\n\nfor i in range(0, len(varFeatures)):\n    print(f' - {varFeatures[i]}: {valFeatures[i]}')\n\nprint(f\"Predicted value: US${predict:.2f} \")","38b6398f":"noOut.query(f'genderNum == {valFeatures[0]} and customerTypeNum == {valFeatures[1]}')[['genderNum', 'customerTypeNum', 'Total']].describe()","cb28ec53":"**Sepating numericals and categoricals variables**","91e59cc0":"**Reading data**","d670c7e6":"**Creating lists of unique values of categorical variables**","0d494a90":"**Start EDA - Exploratory Data Analysis**","05873e79":"# Predictions\n\n**Now, we will start a simple forecasting process**","d2b9f47a":"**Analyzing the statistics of the variable features, and having the first impression of how the data profile is**","6f9740e6":"**Datapeople, this is a very simple example, we could do several analyzes such as predicting how much to buy a product given the person's profile. Anyway, the dataset and learning was really cool.\nHugs to everyone.**","e2d46b6b":"**Predicting this sale**\n\nNow, let's predict a possible purchase with the following profile:\n\n* Using best regressor\n* gender = male - genderNum is gender.index('male')\n* member = customer type - customerTypeNum is customerType.index('member')\n\nHow much would be the total value of a purchase with this profile? Let's predict ..","76f326ba":"**Correlation between variables**","fee307d0":"# Removing Outliers\n\n**checking for outliers in the dataset**","ca1fdef1":"# Regressors\n\n**As the volume of data is small, we can check which sklearn algorithm, as a supervised learning method, brings us the best score for our predictions**","0d21f5d4":"**Generating in the dataset, numeric variables with values \u200b\u200bcompatible with the categorical values**"}}