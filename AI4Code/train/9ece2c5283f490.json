{"cell_type":{"5840a696":"code","20385281":"code","40901386":"code","385fee9d":"code","ed28b9de":"code","e6962360":"code","f6a06b2c":"code","fc47a289":"code","9719a05e":"code","a390d93c":"code","666d6478":"code","4698ffd8":"code","64a20091":"code","c0b078d3":"code","e6aad5c0":"code","ccf8a236":"code","8e5e7502":"code","f59f449a":"code","72f202be":"code","4a21278b":"code","358a7608":"code","96e9c058":"code","eb61a5c7":"code","c9c940dc":"code","931f2e51":"code","ae79302e":"code","178a6dd1":"code","5277cefb":"code","857398a2":"code","9be95601":"code","89addf03":"code","c9339a34":"code","00dc15f2":"code","8e1e448c":"code","baf6032e":"code","a8af91fe":"code","679f26ab":"code","d98028e2":"markdown","9b92ee3c":"markdown","4d1143ce":"markdown","d2ec53bf":"markdown","dc5ceef7":"markdown","660cd728":"markdown","2c2c1c3d":"markdown","cd42f8cf":"markdown","8f8eb11a":"markdown","5493b19a":"markdown","3f0e90b5":"markdown","58d4f059":"markdown","5b687ee6":"markdown","a7388652":"markdown","97abff6e":"markdown","195a0dcf":"markdown","f331f143":"markdown","24058a6f":"markdown","4625e997":"markdown","ef0045b2":"markdown","dcc83f36":"markdown","df23e13b":"markdown","b47b4675":"markdown","0ecc2ecd":"markdown","a0d4379d":"markdown","c6f58210":"markdown","542c634c":"markdown","c884eae7":"markdown","e079d22c":"markdown","ee1abfb0":"markdown","f7a52ece":"markdown","a38f6270":"markdown","7d537a11":"markdown","c2f94ef6":"markdown","0c8c145e":"markdown","09198b5d":"markdown","e9b1837b":"markdown","ab545284":"markdown","b3953d16":"markdown","06737943":"markdown","c245ddd3":"markdown","d6f93a31":"markdown"},"source":{"5840a696":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, LabelEncoder\nfrom sklearn.impute import KNNImputer\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier","20385281":"# You don't have to run this code!\n# It's just for clean visualization :)\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\npalette = sns.color_palette(\"bright\")\nsns.set_palette(\"Paired\")","40901386":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\nsub = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\n\nall_data = pd.concat([train, test]).reset_index(drop = True)\nall_data","385fee9d":"sns.countplot(train['Survived']);","ed28b9de":"all_data.nunique().sort_values()","e6962360":"fig, ax = plt.subplots(1, 4, figsize = (12, 4)) # Making Subplots\n\nsns.countplot(train['Survived'], ax=ax[0]);\nsns.countplot(all_data['Sex'], ax=ax[1]);\nsns.countplot(all_data['Pclass'], ax=ax[2]);\nsns.countplot(all_data['Embarked'], ax=ax[3]);\n\nplt.tight_layout() # you can use this function for clear visualization\nplt.show()","f6a06b2c":"sex_survived_rate = all_data.groupby('Sex')['Survived'].mean()\nsex_survived_rate","fc47a289":"sex_survived_rate.plot(kind = 'bar');","9719a05e":"fig, ax = plt.subplots(1, 2, figsize = (10, 5))\n\nsns.distplot(all_data['Age'], ax=ax[0], color='y');\nsns.distplot(all_data['Fare'], ax=ax[1], color='violet');\n\nplt.tight_layout()\nplt.show()","a390d93c":"ss = StandardScaler()\nrb = RobustScaler()\nmm = MinMaxScaler()\n\nfare_standard = ss.fit_transform(all_data['Fare'].values.reshape(-1, 1))\nfare_robust = rb.fit_transform(all_data['Fare'].values.reshape(-1, 1))\nfare_minmax = mm.fit_transform(all_data['Fare'].values.reshape(-1, 1))\n\nfig, ax = plt.subplots(1, 4, figsize=(15, 5))\n\nsns.distplot(fare_standard, color='violet', ax = ax[0]).set_title('StandardScaler');\nsns.distplot(fare_robust, color='y', ax = ax[1]).set_title('RobustScaler');\nsns.distplot(fare_minmax, color='r', ax = ax[2]).set_title('MinMaxScaler');\nsns.distplot(np.log1p(train['Fare']), color='b', ax = ax[3]).set_title('LogScaling');\n\nplt.tight_layout()\nplt.show()","666d6478":"all_data.isna().sum()","4698ffd8":"all_data['missing_counts'] = all_data[all_data.columns[2:]].isna().sum(axis = 1)\nall_data","64a20091":"miss_one_hot = all_data[['Age', 'Cabin', 'Fare', 'Embarked']].isna()\nmiss_one_hot.columns = ['Age_miss', 'Cabin_miss', 'Fare_miss', 'Embarked_miss']\nmiss_one_hot","c0b078d3":"all_data = pd.concat([all_data, miss_one_hot], axis = 1)\nall_data","e6aad5c0":"all_data['Cabin'] = all_data['Cabin'].fillna('nan')\nall_data['Embarked'] = all_data['Embarked'].fillna('nan')\n\nle = LabelEncoder()\n\nall_data['Cabin'] = le.fit_transform(all_data['Cabin'])\nall_data['Sex'] = le.fit_transform(all_data['Sex'])\nall_data['Embarked'] = le.fit_transform(all_data['Embarked'])\nall_data","ccf8a236":"columns = list(all_data.columns)\ncolumns.remove('PassengerId')\ncolumns.remove('Survived')\ncolumns.remove('Ticket')\ncolumns.remove('Name')\ncolumns","8e5e7502":"knn = KNNImputer()\n\nimputed_data = all_data[columns]\nimputed_data = knn.fit_transform(imputed_data)\nimputed_data","f59f449a":"all_data.iloc[:, 5] = imputed_data[:, 2]\nall_data.iloc[:, 9] = imputed_data[:, 5]\nall_data","72f202be":"all_data.isna().sum()","4a21278b":"name=[]\nfor i in range(len(all_data['Name'])):\n    name.append(all_data['Name'].iloc[i].split(',')[1].split('.')[0])\nall_data['Name']=name\nall_data['Name']=all_data['Name'].replace([' Dr',' Mlle',' Rev',' Major',' Col',' Don',' the Countess',' Lady',' Jonkheer',' Sir',' Mme',' Ms',' Capt',' Dona'],'Rare')\nall_data['Name']=all_data['Name'].replace({' Mr':1,' Miss':2,' Mrs':2,' Master':3,'Rare':4})\n\nname=[]\nfor i in range(len(test['Name'])):\n    name.append(test['Name'].iloc[i].split(',')[1].split('.')[0])\ntest['Name']=name\ntest['Name']=test['Name'].replace([' Dr',' Mlle',' Rev',' Major',' Col',' Don',' the Countess',' Lady',' Jonkheer',' Sir',' Mme',' Ms',' Capt',' Dona'],'Rare')\ntest['Name']=test['Name'].replace({' Mr':1,' Miss':2,' Mrs':2,' Master':3,'Rare':4})","358a7608":"ticket_split = all_data['Ticket'].apply(lambda x : x.split(' '))\nticket_split","96e9c058":"ticket_2 = ticket_split[ticket_split.agg(len) == 2]\nticket_2","eb61a5c7":"ticket_2_index = ticket_split[ticket_split.agg(len) == 2].index\nticket_2_index","c9c940dc":"ticket_code_2 = []\n\nfor i in ticket_2.index:\n    ticket_code_2.append(ticket_2[i][0])\n    \nticket_code_2","931f2e51":"ticket_code_2_labeled = le.fit_transform(ticket_code_2)\nticket_code_2_labeled += 1\nticket_code_2_labeled","ae79302e":"ticket_3 = ticket_split[ticket_split.agg(len) == 3]\nticket_3","178a6dd1":"ticket_3_index = ticket_split[ticket_split.agg(len) == 3].index\n\nticket_code_3 = []\n\nfor i in ticket_3.index:\n    ticket_code_3.append(ticket_3[i][0])\n    \nticket_code_3","5277cefb":"ticket_code_3_labeled = le.fit_transform(ticket_code_3)\nticket_code_3_labeled += ticket_code_2_labeled.max()\nticket_code_3_labeled","857398a2":"all_data['ticket_code'] = 0\nall_data","9be95601":"all_data.loc[ticket_2_index, 'ticket_code'] = list(ticket_code_2_labeled)\nall_data.loc[ticket_3_index, 'ticket_code'] = list(ticket_code_3_labeled)\nall_data","89addf03":"all_data2 = all_data.drop(columns = ['Ticket', 'Survived', 'PassengerId'])\nall_data2","c9339a34":"all_data2['Fare'] = np.log1p(all_data2['Fare'])","00dc15f2":"train2 = all_data2[:len(train)]\ntest2 = all_data2[len(train):].reset_index(drop = True)","8e1e448c":"x_train, x_valid, y_train, y_valid = train_test_split(train2, train['Survived'], test_size = 0.2, random_state = 42, stratify = train['Survived'])","baf6032e":"cat = CatBoostClassifier(verbose = 1000,\n                         eval_metric='Accuracy',\n                         early_stopping_rounds=1000,\n                         n_estimators=10000,\n                         learning_rate = 0.025,\n                         max_depth=7)\n\ncat.fit(x_train, y_train, eval_set=[(x_valid, y_valid)])\n\nresult = cat.predict(test2)\n\nsub['Survived'] = result\n\nsub.to_csv('sub_catboost.csv', index = 0)","a8af91fe":"stk = StratifiedKFold(n_splits=5, random_state = 42, shuffle = True)\n\nresult_cat = 0\n\nfor fold, (train_index, valid_index) in enumerate(stk.split(train2, train['Survived'])):\n    x_train, y_train = train2.iloc[train_index], train['Survived'][train_index]\n    x_valid, y_valid = train2.iloc[valid_index], train['Survived'][valid_index]\n    \n    cat = CatBoostClassifier(verbose = 1000,\n                         eval_metric='Accuracy',\n                         early_stopping_rounds=1000,\n                         n_estimators=10000,\n                         learning_rate = 0.02,\n                         max_depth=8)\n    print('----------Fold', fold+1, 'Start!--------')\n    cat.fit(x_train, y_train, eval_set=[(x_valid, y_valid)])\n    print('----------Fold', fold+1, 'Done!--------')\n    result_cat += cat.predict_proba(test2)[:, 1] \/ 5\n\nprint('All Done!')","679f26ab":"sub['Survived'] = result_cat\nsub['Survived'] = sub['Survived'].astype(np.int64)\nsub.to_csv('sub_cat_stratifiedkfold.csv', index = 0)","d98028e2":"# **Modeling**\n\n## There are many **categorical columns!**\n\n### How about using **CatBoost**?","9b92ee3c":"#### **Knn Imputer**","4d1143ce":"#### From the graph below, we can see that despite the large number of male passengers,\n#### the survival rate of male passengers is significantly lower than that of female passengers.\n\n#### Maybe thanks to captain's leadership","d2ec53bf":"#### You can use scalers using function 'fit_transform()'\n\n#### **!! Need to transform your target value using reshape(-1, 1) !!**","dc5ceef7":"# **Titanic Tutorial for Beginner**\n\n<h4>Thank you for visiting my notebook :)<\/h4>\n<h4>This notebook explains easily how to start a competition for beginner!!<\/h4>","660cd728":"*  ## **Now, we need to check Missing Values**\n\n### You can use 'isna().sum()' function to see how many missing values are there","2c2c1c3d":"#### Code presumed to be the type of ticket is included at the beginning of the list (A\/5, STON\/, etc..)","cd42f8cf":"## Scaling","8f8eb11a":"<h4>With above output, we can check top 4 columns are categorical.<\/h4>\n\n#### SibSp & Parch are not categorical columns!! You can visit [here](https:\/\/www.kaggle.com\/c\/titanic\/data) and see the detail explanations about columns","5493b19a":"*****","3f0e90b5":"#### You can choose the scaler that has the highest performance of the model while using all four scalers above\n\n#### **Log Scaling** seems to be attractive \u2192 Because of **skewness**\n\n#### In this notebook, we will use **Log Scaling** :)\n\n*****","58d4f059":"#### **Then, how can we handle those missing values?**\n\n#### Answer is..\n\n* **Fill in the numeric column with -1 and the categorical column with just 'nan'**\n\n* **Fill in the numeric column with each column's mean value**\n\n* **Predict the missing values using ML models** \u2192 **KNN Imputer**","5b687ee6":"## **Ticket?**\n\n#### **At first, we need to split by space**","a7388652":"* ### **distplot**\n\n#### With distplot, you can check the distribution of numeric columns!\n\n#### Below graphs : distribution of Age, Fare","97abff6e":"#### **We checked the distribution of categorical columns!**\n\n#### **Now, aren't you curious about gender and survival rate?**\n\n#### Using **groupby()** function, the relationship between columns can be grasped!","195a0dcf":"* ### **Train_Test_Split**\n\n#### **Using validation data for evaluation**\n\n#### **In case of classification competition, you can use option 'stratify' for seperation balance**","f331f143":"# **Import Library**\n\n\n<h4>In the kaggle notebook environment, you can import most of the libraries you want to use<\/h4>\n\n* pandas \u2192 Python Data Analysis Library\n\n* numpy \u2192 Linear algebra library that performs numerical operations such as vectors and matrices in Python\n\n* matplotlib & seaborn \u2192 Visualization Library","24058a6f":"#### You must use iloc or loc for edit dataframe!","4625e997":"### **Clear!**","ef0045b2":"#### **We can also check the distribution of categorical columns!**\n\n#### **You can use 'nunique()' function to check which column is categorical**","dcc83f36":"* ### **Countplot**\n\n#### Since this competition is a binary classification competition, you can check the balance of the target column using **countplot.**\n\n<h4>With below graph, we can see that Target(Survived) column is unbalanced.<\/h4>\n\n<h4>It's too bad that there are more people who haven't survived.<\/h4>","df23e13b":"# **Load Data**\n\n<h4>Using 'read_csv()' function in Pandas, you can read .csv file easily<\/h4>","b47b4675":"#### **I think that name column is very important**\n\n#### **If the family in the train data survived, other family members in the test data are more likely to survive.**","0ecc2ecd":"#### **EDA is a really important technique in data science**\n\n#### **Many features can be extracted, which plays an important role in improving model performance**","a0d4379d":"#### Fare column looks like be skewed!!\n\n#### Maybe need to use scaler! (ex. StandardScaler, RobustScaler, LogScaling)\n\n#### If we use scaler, our model will be less affected by outliers. Check an image below :)","c6f58210":"#### **How about binning those group??**\n\n#### Using agg(len), we can group those ticket data","542c634c":"## **Thank you so much for reading it until the end**\n## **I'm glad if it helped you!**\n## **If this notebook helped you to learn, please do not forget the Upvote!!**","c884eae7":"#### In this notebook, I'll use knn imputer for numeric columns and fill 'nan' for categorical column\n\n#### For KnnImputer, I think it would be helpful to use the LableEncoder","e079d22c":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 style='color:white; background:#707C4F; border:0' role=\"tab\" aria-controls=\"home\"><center>Contents<\/center><\/h2>\n    \n* **Import Library**\n    \n* **Load Data**\n    \n* **EDA & Preprocessing**\n    \n* **Modeling**\n    \n* **Evaluation**\n    \n* **Submission**","ee1abfb0":"#### Next, making a feature about the presence or absence of missing values","f7a52ece":"#### Need to except Name, PassengerId, Survived, Ticket columns for Imputing","a38f6270":"#### Let's make a feature of **the number of missing values**\n\n* **Excepting PassengerId, Survived columns**","7d537a11":"* ### **Stratified Kfold**\n\n#### You can use the code below for your stratifiedKfold Baseline","c2f94ef6":"* ### **Preprocessing Name, Ticket columns**\n\n#### Thank you for following me all the way here. Please cheer up a little bit more. We're almost there :)","0c8c145e":"#### Making new columns !","09198b5d":"#### So! Let's check about the distribution of those 4 columns using **Countplot**","e9b1837b":"# **EDA & Preprocessing**\n\n<h4>EDA is an abbreviation of Exploratory Data Analysis !<\/h4>\n\n<h4>You can use 'Matplotlib & Seaborn' for Basic EDA :)<\/h4>\n\n<h4>With visualization, we can see the distribution of train, test data's features<\/h4>\n\n#### **Based on the information obtained through the above work, we can preprocess the data**","ab545284":"#### **Done!!!**","b3953d16":"*****","06737943":"#### You can practice with Pclass, Embarked columns!!\n#### Do it youself :)\n\n*****","c245ddd3":"#### You must concat those dataframe using axis = 1 !!","d6f93a31":"#### We can make good features using missing values!\n\n* **The number of missing values**\n* **One-Hot-Encoding - Missing values Y\/N**"}}