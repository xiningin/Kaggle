{"cell_type":{"07c41d80":"code","b5a00be0":"code","0990d0e5":"code","5d430625":"code","7b3b9f53":"code","312305f0":"code","0f484d0e":"code","ef9b87df":"code","c9801931":"code","3adf6036":"code","bf9aa7e7":"code","604c9a06":"code","89d3239d":"code","bc2944dc":"code","0a60242f":"code","c927b45a":"code","e39f90f2":"code","784455bb":"code","dabced1a":"code","9f70b58e":"code","8613c6b2":"code","62bceff9":"code","8df5c32a":"code","ecc512be":"code","c4519628":"code","ed9b53b0":"code","1bf031c1":"code","8979408a":"code","eebf4a09":"code","18389cff":"code","de2ee565":"code","b0012c05":"code","14eed50f":"code","ae9ba880":"code","4f627355":"code","b7448f52":"code","a1b1994b":"code","1125fea8":"code","adeb9d80":"code","0a0dd03d":"code","f0a29a2e":"code","64657f11":"code","967adcab":"code","8cfec949":"code","7fd0147a":"code","e29ae86d":"code","0d76cd70":"code","01bafc09":"code","bbcf24ba":"markdown"},"source":{"07c41d80":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b5a00be0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\nimport gc\nimport sys\n\nfrom pandas.io.json import json_normalize\nfrom datetime import datetime\nfrom sklearn import preprocessing\n\nimport os\nprint(os.listdir(\"..\/input\"))","0990d0e5":"def load_df(csv_path, nr=None):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    #converters = cv\n    #dtype = dt\n    #nrows = nr\n    #column_as_df = cad\n    df = pd.read_csv(csv_path, \n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str'},\n                     nrows=nr)\n    \n    for column in JSON_COLUMNS:\n        cad = json_normalize(df[column])\n        cad.columns = [f\"{column}.{subcolumn}\" for subcolumn in cad.columns]\n        df = df.drop(column, axis=1).merge(cad, right_index=True, left_index=True)\n    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n    return df","5d430625":"%%time\ntrain = load_df('..\/input\/train.csv')\ntest = load_df('..\/input\/test.csv')\n\nprint('train date:', min(train['date']), 'to', max(train['date']))\nprint('test date:', min(test['date']), 'to', max(test['date']))","7b3b9f53":"# only train feature\nfor c in train.columns.values:\n    if c not in test.columns.values: print(c)","312305f0":"# totals, the sub-column transactionRevenue contains the revenue information we are trying to predict\n#train_rev = train_revenue\ntrain_revenue = train[~train['totals.transactionRevenue'].isnull()].copy()\nprint(len(train_revenue))\ntrain_revenue.head()","0f484d0e":"train['totals.transactionRevenue'].fillna(0, inplace=True)\ntrain['totals.transactionRevenue'] = np.log1p(train['totals.transactionRevenue'].astype(float))\nprint(train['totals.transactionRevenue'].describe())","ef9b87df":"ad = train.append(test, sort=False).reset_index(drop=True)","c9801931":"print(ad.info())","3adf6036":"null_cnt = train.isnull().sum().sort_values()\nprint(null_cnt[null_cnt > 0])","bf9aa7e7":"ad['totals.pageviews'].fillna(1, inplace=True)\nad['totals.newVisits'].fillna(0, inplace=True)\nad['totals.bounces'].fillna(0, inplace=True)\nad['totals.pageviews'] = ad['totals.pageviews'].astype(int)\nad['totals.newVisits'] = ad['totals.newVisits'].astype(int)\nad['totals.bounces'] = ad['totals.bounces'].astype(int)\n\nad['trafficSource.isTrueDirect'].fillna(False, inplace=True)","604c9a06":"cc = [col for col in ad.columns if ad[col].nunique() == 1]\n\nprint('drop columns:', cc)\nad.drop(cc, axis=1, inplace=True)","89d3239d":"format_str = '%Y%m%d'\nad['formated_date'] = ad['date'].apply(lambda x: datetime.strptime(str(x), format_str))\nad['_month'] = ad['formated_date'].apply(lambda x:x.month)\nad['_quarterMonth'] = ad['formated_date'].apply(lambda x:x.day\/\/8)\nad['_day'] = ad['formated_date'].apply(lambda x:x.day)\nad['_weekday'] = ad['formated_date'].apply(lambda x:x.weekday())\n\n#ad(['date','formated_date'], axis=1, inplace=True)","bc2944dc":"print(ad['channelGrouping'].value_counts())","0a60242f":"print('train all:', len(train))\nprint('train unique fullVisitorId:', train['fullVisitorId'].nunique())\nprint('train unique visitId:', train['visitId'].nunique())\nprint('-' * 30)\nprint('test all:', len(test))\nprint('test unique fullVisitorId:', test['fullVisitorId'].nunique())\nprint('test unique visitId:', test['visitId'].nunique())\n#print('common fullVisitorId:', len(pd.merge(train, test, how='inner', on='fullVisitorId'))) # 183434","c927b45a":"print(ad['visitNumber'].value_counts()[:5])\nprint('-' * 30)\nprint(ad['totals.newVisits'].value_counts())\nprint('-' * 30)\nprint(ad['totals.bounces'].value_counts())","e39f90f2":"ad['_visitStartHour'] = ad['visitStartTime'].apply(\n    lambda x: str(datetime.fromtimestamp(x).hour))","784455bb":"print('train all sessionId:', len(train['sessionId']))\nprint('train unique sessionId:', train['sessionId'].nunique())","dabced1a":"print('unique browser count:', train['device.browser'].nunique())\nprint('-' * 30)\nprint(ad['device.browser'].value_counts()[:10])","9f70b58e":"pd.crosstab(ad['device.deviceCategory'], ad['device.isMobile'], margins=False)","8613c6b2":"print('unique operatingSystem count:', train['device.operatingSystem'].nunique())\nprint('-' * 30)\nprint(ad['device.operatingSystem'].value_counts()[:10])","62bceff9":"print(ad['geoNetwork.city'].value_counts()[:10])\nprint('-' * 30)\nprint(ad['geoNetwork.region'].value_counts()[:10])\nprint('-' * 30)\nprint(ad['geoNetwork.subContinent'].value_counts()[:10])\nprint('-' * 30)\nprint(ad['geoNetwork.continent'].value_counts())","8df5c32a":"print(ad['geoNetwork.metro'].value_counts()[:10])","ecc512be":"print(ad['geoNetwork.networkDomain'].value_counts()[:10])","c4519628":"print(ad['totals.hits'].value_counts()[:10])\n\nad['totals.hits'] = ad['totals.hits'].astype(int)\nad['_meanHitsPerDay'] = ad.groupby(['_day'])['totals.hits'].transform('mean')\nad['_meanHitsPerWeekday'] = ad.groupby(['_weekday'])['totals.hits'].transform('mean')\nad['_meanHitsPerMonth'] = ad.groupby(['_month'])['totals.hits'].transform('mean')\nad['_sumHitsPerDay'] = ad.groupby(['_day'])['totals.hits'].transform('sum')\nad['_sumHitsPerWeekday'] = ad.groupby(['_weekday'])['totals.hits'].transform('sum')\nad['_sumHitsPerMonth'] = ad.groupby(['_month'])['totals.hits'].transform('sum')","ed9b53b0":"print(ad['totals.pageviews'].value_counts()[:10])\nad['totals.pageviews'] = ad['totals.pageviews'].astype(int)","1bf031c1":"print(ad['trafficSource.adContent'].value_counts()[:10])\nprint('-' * 30)\nprint(train_revenue['trafficSource.adContent'].value_counts())\n\nad['_adContentGMC'] = (ad['trafficSource.adContent'] == 'Google Merchandise Collection').astype(np.uint8)","8979408a":"print(ad['trafficSource.campaign'].value_counts()[:10])\nad['_withCampaign'] = (ad['trafficSource.campaign'] != '(not set)').astype(np.uint8)","eebf4a09":"print(ad['trafficSource.isTrueDirect'].value_counts())","18389cff":"print(ad['trafficSource.keyword'].value_counts()[:10])","de2ee565":"print(ad['trafficSource.medium'].value_counts())\nprint('-' * 30)\nprint(train_revenue['trafficSource.medium'].value_counts())","b0012c05":"print(ad['trafficSource.referralPath'].value_counts()[:10])\n","14eed50f":"print(ad['trafficSource.source'].value_counts()[:10])\nad['_sourceGpmall'] = (ad['trafficSource.source'] == 'mall.googleplex.com').astype(np.uint8)","ae9ba880":"train_revenue = train_revenue.sort_values(['visitStartTime']).reset_index()\ntrain_revenue['_buyCount'] = train_revenue.groupby('fullVisitorId').cumcount() + 1\nad = pd.merge(ad, train_revenue[['_buyCount','fullVisitorId','visitId']], \n                    on=['fullVisitorId','visitId'], how='left')\nfor fvId in train_revenue['fullVisitorId'].unique():\n    visitor_data = ad[ad['fullVisitorId'] == fvId].sort_values(['visitStartTime'])['_buyCount'].reset_index()\n    ad.loc[ad['fullVisitorId'] == fvId, '_buyCount'] = visitor_data['_buyCount'].fillna(method='ffill').values\nad['_buyCount'].fillna(0, inplace=True)\nad['_buyRate'] = ad['_buyCount'] \/ ad['visitNumber']","4f627355":"null_cnt = ad.isnull().sum().sort_values()\nprint(null_cnt[null_cnt > 0])","b7448f52":"ad.info()","a1b1994b":"c = ['fullVisitorId',\n     'visitNumber',\n     'device.deviceCategory',\n     'geoNetwork.subContinent',\n     'totals.transactionRevenue',\n     'totals.newVisits',\n     'totals.hits',\n     'totals.pageviews',\n     '_month',\n     '_quarterMonth',\n     '_weekday',\n     '_visitStartHour',\n     '_adContentGMC',\n     '_withCampaign',\n     '_sourceGpmall',\n     '_buyRate']\nad = ad[c]\n\nfor i, t in ad.loc[:, ad.columns != 'fullVisitorId'].dtypes.iteritems():\n    if t == object:\n        ad = pd.concat([ad, pd.get_dummies(ad[i].astype(str), prefix=i)], axis=1)\n        ad.drop(i, axis=1, inplace=True)","1125fea8":"ad.info()","adeb9d80":"train = ad[ad['totals.transactionRevenue'].notnull()]\ntest = ad[ad['totals.transactionRevenue'].isnull()].drop(['totals.transactionRevenue'], axis=1)","0a0dd03d":"train_id = train['fullVisitorId']\ntest_id = test['fullVisitorId']\n\nY_train_reg = train.pop('totals.transactionRevenue')\nY_train_cls = (Y_train_reg.fillna(0) > 0).astype(np.uint8)\n\nX_train = train.drop(['fullVisitorId'], axis=1)\nX_test  = test.drop(['fullVisitorId'], axis=1)\n\nprint(X_train.shape, X_test.shape)","f0a29a2e":"import sys\nimport gc\n\ndel ad, train, test, train_revenue\ngc.collect()\n\nprint(pd.DataFrame([[val for val in dir()], [sys.getsizeof(eval(val)) for val in dir()]],\n                   index=['name','size']).T.sort_values('size', ascending=False).reset_index(drop=True)[:10])","64657f11":"from sklearn import ensemble, metrics\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.model_selection import GridSearchCV, KFold, GroupKFold\nfrom sklearn.metrics import mean_squared_error, classification_report, roc_auc_score, f1_score, log_loss\n\nimport xgboost as xgb\nimport lightgbm as lgb","967adcab":"if '_revenueProba' in X_train.columns : del X_train['_revenueProba']\nif '_revenueProba' in X_test.columns : del X_test['_revenueProba']","8cfec949":"%%time\nreg = ensemble.GradientBoostingRegressor(n_estimators=500, learning_rate=0.05, max_depth=3, verbose=1, random_state=42)\nreg.fit(X_train, Y_train_cls)\npred_reg = reg.predict(X_test)\n\nprint(len(pred_reg), len(pred_reg[pred_reg > 0.1]))","7fd0147a":"reg = ensemble.GradientBoostingRegressor(n_estimators=1000, learning_rate=0.5, max_depth=3, verbose=1, random_state=42)\nreg.fit(X_train[Y_train_reg > 0], Y_train_reg[Y_train_reg > 0])\n\npred = np.zeros(len(pred_reg))\nfor i in np.arange(len(pred_reg)):\n        pred[i] = reg.predict([X_test.iloc[i]])[0] * pred_reg[i]","e29ae86d":"#submission = sub","0d76cd70":"sub = pd.DataFrame({'fullVisitorId':test_id, 'PredictedLogRevenue':pred})\nsub[\"PredictedLogRevenue\"] = sub[\"PredictedLogRevenue\"].apply(lambda x : 0.0 if x < 0 else x)\nsub[\"PredictedLogRevenue\"] = sub[\"PredictedLogRevenue\"].fillna(0.0)\nsub_sum = sub[['fullVisitorId', 'PredictedLogRevenue']].groupby('fullVisitorId').sum().reset_index()\nsub_sum.to_csv(\"submission.csv\", index=False)\nsub_sum[sub_sum['PredictedLogRevenue'] > 0.0]","01bafc09":"sub_sum['PredictedLogRevenue'].describe()","bbcf24ba":"Importing Libraries"}}