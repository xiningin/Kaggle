{"cell_type":{"37dca4f6":"code","023917df":"code","a18cff4f":"code","e7b58da4":"code","89a104ca":"code","ab2669ef":"code","4557adb7":"code","81311b64":"code","16c6db8b":"code","5b094527":"code","35114efd":"code","b6dfbd1a":"code","25d12d47":"code","927274a4":"code","b4f53017":"code","0f9106a1":"code","e282b6b6":"code","5ee845d7":"code","491199a3":"code","496a0097":"code","cfb49a1f":"code","d2ac511f":"markdown","72288b0f":"markdown","b692fbae":"markdown","20321ca1":"markdown","c2e9647f":"markdown","cb279b7b":"markdown","60109273":"markdown","764224c0":"markdown","aa165187":"markdown","bb463394":"markdown","6b06e3f9":"markdown","f69425c5":"markdown","95643c87":"markdown","dbd4a9f7":"markdown"},"source":{"37dca4f6":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","023917df":"from fastai import *\nfrom fastai.vision import *\n","a18cff4f":"path = Path('\/kaggle\/input\/apparel-dataset\/')\npath.ls()","e7b58da4":"img = ImageList.from_folder(path, recurse = True)","89a104ca":"img.items.shape","ab2669ef":"img.open(img.items[10])","4557adb7":"np.random.seed(33)\nsrc = (img.split_by_rand_pct(0.2).label_from_folder(label_delim = '_'))","81311b64":"tfms = get_transforms()\ndata = (src.transform(tfms, size =128).databunch().normalize(imagenet_stats))","16c6db8b":"data.show_batch(rows = 3, figsize = (15,11))\nprint(f\"\"\" list of classes in the dataset: {data.classes}\\n\n        number of labels in the dataset: {data.c}\\n\n        length of training data: {len(data.train_ds)}\\n\n        length of validation data: {len(data.valid_ds)}\"\"\")","5b094527":"acc_02 = partial(accuracy_thresh, thresh = 0.2)\nlearn = cnn_learner(data, models.resnet34, metrics = acc_02)","35114efd":"learn.model_dir = '\/kaggle\/working\/models'","b6dfbd1a":"learn.lr_find()","25d12d47":"learn.recorder.plot()","927274a4":"lr = 1e-2\nlearn.fit_one_cycle(5,slice(lr))","b4f53017":"learn.save('stage-1-128')","0f9106a1":"learn.unfreeze()","e282b6b6":"learn.lr_find()","5ee845d7":"learn.recorder.plot()","491199a3":"learn.fit_one_cycle(2, max_lr = slice(3e-6, 3e-4))","496a0097":"learn.recorder.plot_losses()","cfb49a1f":"learn.save('stage-2-128')","d2ac511f":"This is an exercise kernel for the fastai lesson 3. I have also visited the \"Multi-label Classification using FastAi Library\" by Kais K in kaggle. You can visit his kernel [*here*](http:\/\/www.kaggle.com\/kaiska\/multi-label-classification-using-fastai-library)\n\n\nI will explain my steps in small sentences for you to get a basic understanding of what am I trying to accomplish, but if you want a detailed explanation of the functions used here, [fastai docs](http:\/\/docs.fast.ai\/) is the best place to learn.","72288b0f":"The accuracy may further increase but may also resultin overfitting, so I have stopped training the learner.","b692fbae":"### Getting started\n\nThis is the kaggle default cell, which helps in listing directories where data is present. Then the necessary packages are downloaded.","20321ca1":"### Creating Training and Validation folders \n\nHere, a training and validation folders are created from the imagelist that we previously created. The labels of the images are taken from the folder name, with a delimiter **'_'**. \n\nrandom seed is set to a fixed number so that we will always get the same training and validation split thereby reproducing the results.","c2e9647f":"An image list is created to read all the images from the path folder by folder. The function \"from_folder\" is important as the labels of the images are the folder names, the labels are created from the name ofthe folder in which the image is in(in the next few steps)","cb279b7b":"### Databunch created\n\nIn fastai library, the training neuralnetwork takes in a object called databunch, which consists of training and validation sets (optionally test set). This databunch will receive images and labels with data augmentations done using the **transform** class. The  images are normalized to imagenet stats as we are using a pretrained imagenet neural network.","60109273":"To see how many files are present in the image list","764224c0":"# **Multilabel classification using Fastai-v1**","aa165187":"We can see that the steepest decrease in the loss is at 1e-2. So, taking this learning rate would be an ideal place to start training the model.","bb463394":"### Finding learning rate\n\n**lr_find()** helps the learner to get the best learning rate for that model with the available data. This function will decrease the number of experimentations and thereby avoids the possibilty of overfitting.","6b06e3f9":"Here, the loss is incresing after 1e-3. So, the ideal learning rate will be 10 times lowerthan that. Since we are interested in training the later parts of the deep neural network more, we can slice the learning rate.","f69425c5":"### Training the model a little further\n\nThough we got a good model with just 5 epochs, this learner is using the pretrained weights of resnet34 which trained on imagenet. To customize this learner for this data, we unfreeze the learner and train the later parts of the learner more to get even more accurate results.","95643c87":"### Initiating the path variable\n\n","dbd4a9f7":"### Creating custom metrics and a learner\n\nHere, we created a custom metric from the accuracy metric as we are dealing with multi-label Classification.\n\nThen a learner is created, which takes the databunch created above and downloads a pretrained model to train that data on."}}