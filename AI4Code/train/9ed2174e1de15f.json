{"cell_type":{"712e7de7":"code","25aba960":"code","fae5b1e6":"code","230e2730":"code","ddbbc2d8":"code","e01e648d":"code","4fd17c09":"code","dadf5c75":"code","876430f0":"code","d72091e5":"code","2bac775c":"code","de6c05c1":"code","61c6307a":"code","b53d6d28":"code","9c2929c9":"code","83ed4e2a":"code","06787cc4":"markdown","ef295615":"markdown"},"source":{"712e7de7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","25aba960":"from sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import GridSearchCV","fae5b1e6":"train_data = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/train.csv', index_col='Id')\ntest_data = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/test.csv', index_col='Id')","230e2730":"y = train_data.SalePrice\nX_full = train_data.copy().drop('SalePrice', axis=1)\nX_test = test_data.copy()","ddbbc2d8":"full_num_cols = [col for col in X_full.columns if X_full[col].dtype in ['int64', 'float64']]\nfull_cat_cols = [col for col in X_full.columns if X_full[col].dtype == 'object']\n\nlow_cardi_cats = [col for col in full_cat_cols if X_full[col].nunique() < 10]\nhigh_cardi_cats = [col for col in full_cat_cols if X_full[col].nunique() > 10]\n\nnums_with_missing = [col for col in full_num_cols if X_full[col].isnull().any()]\ncats_with_missing = [col for col in full_cat_cols if X_full[col].isnull().any()]\n\ncount_num_missing = {col: X_full[col].isnull().sum() for col in nums_with_missing}\ncount_cat_missing = {col: X_full[col].isnull().sum() for col in cats_with_missing}","e01e648d":"high_columns = {c: X_full[c].nunique() for c in high_cardi_cats}\nprint(high_columns)","4fd17c09":"X = X_full.copy()","dadf5c75":"encoder = LabelEncoder()\nfor c in high_cardi_cats:\n    X[c] = encoder.fit_transform(X[c])","876430f0":"num_cols = [col for col in X.columns if X[col].dtype in ['int64', 'float64']]\ncat_cols = [col for col in X.columns if X[col].dtype == 'object']","d72091e5":"num_transformer = SimpleImputer(strategy='mean')\n\nlow_cat_transformer = make_pipeline(SimpleImputer(strategy='constant'),\n                                OneHotEncoder(handle_unknown='ignore'))\n\nhigh_cat_transformer = make_pipeline(SimpleImputer(strategy='constant'),\n                                     OrdinalEncoder(dtype=pd.DataFrame))\n\npreprocessing = ColumnTransformer(\n    transformers=[\n    ('num', num_transformer, num_cols),\n    ('low_cat', low_cat_transformer, low_cardi_cats)\n])","2bac775c":"#Apply new parameters to the pipeline\nmodel = XGBRegressor(n_estimators=300, max_depth=2)\n\npipeline = Pipeline(steps=[\n    ('model', model)\n])","de6c05c1":"imputer = SimpleImputer(strategy='constant')\nX_test[high_cardi_cats] = pd.DataFrame(imputer.fit_transform(X_test[high_cardi_cats]))\n\nfor c in high_cardi_cats:\n    X_test[c] = encoder.fit_transform(X_test[c])","61c6307a":"X_final = pd.DataFrame(preprocessing.fit_transform(X))\nX_test_final = pd.DataFrame(preprocessing.transform(X_test))","b53d6d28":"#Fit\npipeline.fit(X_final,y)","9c2929c9":"preds = pipeline.predict(X_test_final)","83ed4e2a":"#Save predictions to submission\noutput = pd.DataFrame({'Id' : X_test.index, 'SalePrice' : preds})\noutput.to_csv('submission', index=False)","06787cc4":"model = XGBRegressor()\npipeline = Pipeline(steps=[\n    ('prepro', preprocessing),\n    ('model', model)\n])\n\n#Find and print the best combination of parameters in the dict 'parameters'\nparameters = {'model__n_estimators': [i for i in range(100, 600, 100)],\n              'model__max_depth': [2,3,4,5,6]}\n\nsearch = GridSearchCV(pipeline, parameters, scoring='neg_mean_absolute_error').fit(X,y)\n\nprint(search.best_params_)","ef295615":"#Verify score using found parameters\nscores = -1 * cross_val_score(pipeline, X, y, scoring='neg_mean_absolute_error',cv=5)\nprint(scores.mean())"}}