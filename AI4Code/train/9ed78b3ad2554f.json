{"cell_type":{"98dbc1b4":"code","a5f71422":"code","c08f03c7":"code","71138049":"code","ac821b2e":"code","325e33e6":"code","1e3e91bf":"code","2b90615f":"code","4d22457d":"code","5c029f6c":"code","7131e319":"code","61eb5fa0":"code","0d2b7eaf":"code","c54f8191":"code","af56e2d4":"code","3715c650":"code","cdd45a28":"code","82512be4":"code","bfc9ef5d":"code","fb0dd087":"code","0d5ea5ae":"code","0471fa89":"code","36717784":"code","1da46365":"code","e142dd8c":"code","2668c1d8":"code","c97f86f8":"code","bafa7967":"code","1dcc53fd":"code","0211259a":"code","fe55224f":"code","27e29b81":"code","cb46d9a7":"code","b76f11f3":"code","a93a690c":"code","f03097d6":"code","150d6873":"code","078bd952":"code","4136619d":"markdown","71351a4f":"markdown","7954c268":"markdown","6e0cefb7":"markdown","01477ed3":"markdown","4b69f062":"markdown","623a0095":"markdown","ffec627c":"markdown","9354e03e":"markdown","ffe955b4":"markdown","d66ac39c":"markdown","cba4b5db":"markdown","f3d8bfc5":"markdown","e9d8a2fe":"markdown","8032f849":"markdown","e7e831cd":"markdown","33fcc852":"markdown","f5fd835c":"markdown","5cdd14e6":"markdown","aa59edd8":"markdown","2c15ad26":"markdown","9b17b403":"markdown","32c830ce":"markdown","ded80871":"markdown","445a4ae9":"markdown","b5c1c3ff":"markdown","456c2359":"markdown","ff8f46d7":"markdown"},"source":{"98dbc1b4":"!pip install ..\/input\/pytorch-image-models\/timm-0.3.1-py3-none-any.whl","a5f71422":"import numpy as np\nimport os\nimport pandas as pd\nfrom fastai.vision.all import *","c08f03c7":"set_seed(999)","71138049":"dataset_path = Path('..\/input\/cassava-leaf-disease-classification')\nos.listdir(dataset_path)","ac821b2e":"data = pd.read_csv(dataset_path\/'train.csv')\ntrain_df = data[~data['image_id'].isin(['1562043567.jpg', '3551135685.jpg', '2252529694.jpg'])]","325e33e6":"train_df.head()","1e3e91bf":"train_df['path'] = train_df['image_id'].map(lambda x:dataset_path\/'train_images'\/x)\ntrain_df = train_df.drop(columns=['image_id'])\ntrain_df = train_df.sample(frac=1).reset_index(drop=True) #mix dataframe\ntrain_df.head(5)","2b90615f":"len_df = len(train_df)\nprint(f\"Dataset cont\u00e9m {len_df} imagens\")\n","4d22457d":"with open(dataset_path\/\"label_num_to_disease_map.json\") as f:\n    class_names = json.loads(f.read())\nf.close()\n\ntrain_df[\"label_name\"] = train_df['label'].apply(lambda x: class_names[str(x)])\ntrain_df.label = train_df.label.astype(str)\n\nprint(\"Total exemplos de treino: \", len(train_df))\ntrain_df.head(10)","5c029f6c":"count = train_df.label.value_counts().sort_index()\nplt.bar(count.keys(), count)","7131e319":"from PIL import Image\n\nimg_cmd = Image.open(train_df['path'][1])\nwidth, height = img_cmd.size\nprint(width,height) ","61eb5fa0":"img_cmd","0d2b7eaf":"item_tfms = RandomResizedCrop(512, min_scale=0.75, ratio=(1.,1.))\nbatch_tfms = [*aug_transforms(size=224, max_warp=0), Normalize.from_stats(*imagenet_stats)]\nbs=32","c54f8191":"dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n                               valid_pct=0.2, #80-20 train-validation random split\n                               seed=999, #seed\n                               label_col=0, #label is in the first column of the DataFrame\n                               fn_col=1, #filename\/path is in the second column of the DataFrame\n                               bs=bs, #pass in batch size\n                               item_tfms=item_tfms, #pass in item_tfms\n                               batch_tfms=batch_tfms) #pass in batch_tfms","af56e2d4":"dls.show_batch()","3715c650":"# Making pretrained weights work without needing to find the default filename\nif not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n        os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n!cp '..\/input\/timmefficientnet\/tf_efficientnet_b3-e3bd6955.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/tf_efficientnet_b3-e3bd6955.pth'","cdd45a28":"from timm import create_model\nfrom fastai.vision.learner import _update_first_layer\n\ndef create_timm_body(arch:str, pretrained=True, cut=None, n_in=3):\n    \"Creates a body from any model in the `timm` library.\"\n    model = create_model(arch, pretrained=pretrained, num_classes=0, global_pool='')\n    _update_first_layer(model, n_in, pretrained)\n    if cut is None:\n        ll = list(enumerate(model.children()))\n        cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n    if isinstance(cut, int): return nn.Sequential(*list(model.children())[:cut])\n    elif callable(cut): return cut(model)\n    else: raise NamedError(\"cut must be either integer or function\")\n        \ndef create_timm_model(arch:str, n_out, cut=None, pretrained=True, n_in=3, init=nn.init.kaiming_normal_, custom_head=None,\n                     concat_pool=True, **kwargs):\n    \"Create custom architecture using `arch`, `n_in` and `n_out` from the `timm` library\"\n    body = create_timm_body(arch, pretrained, None, n_in)\n    if custom_head is None:\n        nf = num_features_model(nn.Sequential(*body.children())) * (2 if concat_pool else 1)\n        head = create_head(nf, n_out, concat_pool=concat_pool, **kwargs)\n    else: head = custom_head\n    model = nn.Sequential(body, head)\n    if init is not None: apply_init(model[1], init)\n    return model","82512be4":"def timm_learner(dls, arch:str, loss_func=None, pretrained=True, cut=None, splitter=None,\n                y_range=None, config=None, n_out=None, normalize=True, **kwargs):\n    \"Build a convnet style learner from `dls` and `arch` using the `timm` library\"\n    if config is None: config = {}\n    if n_out is None: n_out = get_c(dls)\n    assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n    if y_range is None and 'y_range' in config: y_range = config.pop('y_range')\n    model = create_timm_model(arch, n_out, default_split, pretrained, y_range=y_range, **config)\n    learn = Learner(dls, model, loss_func=loss_func, splitter=default_split, **kwargs)\n    if pretrained: learn.freeze()\n    return learn","bfc9ef5d":"learn = timm_learner(dls, \n                    'tf_efficientnet_b3_ns', \n                     opt_func = ranger,\n                     loss_func=LabelSmoothingCrossEntropy(),\n                     metrics = [accuracy]).to_native_fp16()\n","fb0dd087":"learn.lr_find()","0d5ea5ae":"learn.freeze() \nlearn.fit_flat_cos(1,1e-1, wd=0.5, cbs=[MixUp()])","0471fa89":"learn.save('modelo-1')","36717784":"learn = learn.load('modelo-1')","1da46365":"learn.recorder.plot_loss()","e142dd8c":"learn.unfreeze()\nlearn.lr_find()","2668c1d8":"learn.unfreeze()\n#learn.fit_one_cycle(10, max_lr=slice(0.0001737800776027143, 1.3182567499825382e-06))\nlearn.fit_flat_cos(10,2e-3,pct_start=0,cbs=[MixUp()])","c97f86f8":"learn.recorder.plot_loss()","bafa7967":"learn = learn.to_native_fp32()","1dcc53fd":"learn.save('modelo-2')","0211259a":"learn.export()","fe55224f":"interp = ClassificationInterpretation.from_learner(learn)","27e29b81":"interp.plot_confusion_matrix()","cb46d9a7":"sample_df = pd.read_csv(dataset_path\/'sample_submission.csv')\nsample_df.head()","b76f11f3":"_sample_df = sample_df.copy()\n_sample_df['path'] = _sample_df['image_id'].map(lambda x:dataset_path\/'test_images'\/x)\n_sample_df = _sample_df.drop(columns=['image_id'])\ntest_dl = dls.test_dl(_sample_df)","a93a690c":"test_dl.show_batch()","f03097d6":"preds, _ = learn.tta(dl=test_dl, n=10, beta=0)","150d6873":"sample_df['label'] = preds.argmax(dim=-1).numpy()","078bd952":"sample_df.to_csv('submission.csv',index=False)","4136619d":"## Olhando os dados","71351a4f":"Salavando e exportando o modelo para usar mais tarde, para poss\u00edveis infer\u00eancias:","7954c268":"Executando um processamento r\u00e1pido dos nomes dos arquivos de imagem para facilitar o acesso:","6e0cefb7":"Verificando o que est\u00e1 dispon\u00edvel:","01477ed3":"H\u00e1 um conjunto com com mais de 21k imagens! Com isso \u00e9 poss\u00edvel desenvolver um modelo preditivo, robusto e generaliz\u00e1vel com este conjunto de dados.\n\nAgora, verificando a distribui\u00e7\u00e3o das diferentes classes:","4b69f062":"Vamos treinar um modelo EfficientNet-B3 aa. Usando o pacote [timm](https:\/\/github.com\/rwightman\/pytorch-image-models) de Ross Wightman para definir o modelo. Como esta competi\u00e7\u00e3o n\u00e3o permite acesso \u00e0 Internet, adicionei os pesos pr\u00e9-treinados de timm como um conjunto de dados, e a c\u00e9lula de c\u00f3digo abaixo permitir\u00e1 que timm encontre o arquivo:","623a0095":"\n# Cassava Leaf Disease Classification\n\nNesta competi\u00e7\u00e3o, tenta-se identificar doen\u00e7as comuns em planta\u00e7\u00f5es de mandioca usando ci\u00eancia de dados e aprendizado de m\u00e1quina. M\u00e9todos de detec\u00e7\u00e3o de doen\u00e7as exigem que os agricultores solicitem a ajuda de especialistas agr\u00edcolas financiados pelo governo para inspecionar visualmente e diagnosticar as plantas. Isso sofre por ser muito trabalhoso, com baixo suprimento e caro. Em vez disso, seria prefer\u00edvel se um pipeline automatizado baseado em fotos de qualidade m\u00f3vel das folhas de mandioca pudesse ser desenvolvido.\n\nNesse notebook,  ser\u00e1 utilizado um conjunto de dados dispon\u00edvel em https:\/\/www.kaggle.com\/c\/cassava-leaf-disease-classification\/leaderboard, rotulado por especialistas do National Crops Resources Research Institute (NaCRRI).\n\nNeste kernel, \u00e9 usado um iniciador fastai.","ffec627c":"Preparando submiss\u00e3o","9354e03e":"O `fastai`fornece m\u00e9todos de interpreta\u00e7\u00e3o para modelos de classifica\u00e7\u00e3o, como o [ClassificationInterpretation](https:\/\/docs.fast.ai\/interpret.html), para melhor interpretar as previs\u00f5es de um modelo, e gerar a matriz de confus\u00e3o:\n","ffe955b4":"## Infer\u00eancia\n\nA fun\u00e7\u00e3o `dls.test_dl` permite que voc\u00ea crie um dataloader de teste usando o mesmo pipeline definido anteriormente.","d66ac39c":"Visualizando o `test_dl`","cba4b5db":"Vamos treinar por 10 \u00e9pocas com o modelo descongelado.","f3d8bfc5":"Para as previs\u00f5es, foi aplicada t\u00e9cnica Test-Time Augmentation (15x TTA), conforme [Jason Brownlee](https:\/\/machinelearningmastery.com\/how-to-use-test-time-augmentation-to-improve-model-performance-for-image-classification\/#:~:text=Test%2Dtime%20augmentation%2C%20or%20TTA,an%20ensemble%20of%20those%20predictions).","e9d8a2fe":"Para come\u00e7ar, foi configurado o ambiente, instalando e importando os m\u00f3dulos necess\u00e1rios e definindo uma semente aleat\u00f3ria:","8032f849":"Para confirmar a cria\u00e7\u00e3o bem-sucedida do dataloader, podemos usar o comando `show_batch`, que mostra um subconjunto do lote:","e7e831cd":"Neste caso, temos 5 r\u00f3tulos (4 doen\u00e7as e saud\u00e1vel):\n0. Cassava Bacterial Blight (CBB)\n1. Cassava Brown Streak Disease (CBSD)\n2. Cassava Green Mottle (CGM)\n3. Cassava Mosaic Disease (CMD)\n4. Healthy\n\nNeste caso, o r\u00f3tulo 3 - Cassava Mosaic Disease (CMD) (https:\/\/en.wikipedia.org\/wiki\/Cassava_mosaic_virus) \u00e9 o r\u00f3tulo mais comum. Esse desequil\u00edbrio pode ter que ser tratado com uma fun\u00e7\u00e3o de perda ponderada ou sobreamostragem. E pode-se tentar isso em uma itera\u00e7\u00e3o futura deste kernel ou em um novo kernel.\n\nVerificando uma imagem de exemplo para ver como ela se parece:","33fcc852":"Embora o fastai forne\u00e7a v\u00e1rias maneiras de fazer o carregamento de dados personalizado (at\u00e9 mesmo usando PyTorch DataLoaders simples), os problemas tradicionais de classifica\u00e7\u00e3o de imagens funcionam bem na API de dados de alto n\u00edvel. Aqui, s\u00e3o passadas todas as informa\u00e7\u00f5es necess\u00e1rias para criar um objeto `DataLoaders`","f5fd835c":"## Carregando os dados\n\nDepois de olhar os dados, os dados s\u00e3o carregados no fastai como objetos `DataLoaders`. \n\nPrimeiro, vamos definir as transforma\u00e7\u00f5es de item e em lote. As transforma\u00e7\u00f5es de item realizam um corte bastante grande em cada uma das imagens, enquanto as transforma\u00e7\u00f5es de lote realizam corte redimensionado aleat\u00f3rio para 512 e tamb\u00e9m aplicam outros aumentos padr\u00e3o (em `aug_tranforms`) no n\u00edvel de lote na GPU. O tamanho do lote \u00e9 definido para 32 aqui.","5cdd14e6":"Verificando quantas imagens est\u00e3o dispon\u00edveis no conjunto de dados de treinamento:","aa59edd8":"Tra\u00e7amos a perda `plot_loss`, colocamos o modelo de volta no [fp32](https:\/\/docs.fast.ai\/callback.fp16.html).\n\nA precis\u00e3o anterior era de `fp16` (meia precis\u00e3o)","2c15ad26":"## Treinando o modelo","9b17b403":"\u00c9 fundamental que qualquer prepara\u00e7\u00e3o de dados realizada em um conjunto de dados de treinamento tamb\u00e9m seja realizada em um novo conjunto de dados no futuro.\nIsso pode incluir um conjunto de dados de teste ao avaliar um modelo ou novos dados do dom\u00ednio ao usar um modelo para fazer previs\u00f5es.\nNormalmente, o modelo ajustado no conjunto de dados de treinamento \u00e9 salvo para uso posterior. \n\nA solu\u00e7\u00e3o correta para preparar novos dados para o modelo no futuro \u00e9 tamb\u00e9m salvar quaisquer objetos de prepara\u00e7\u00e3o de dados, como m\u00e9todos de escalonamento de dados, para arquivar junto com o modelo.\n\nEnt\u00e3o salvamos o modelo usando o `save()` \n\nIsso armazena o modelo junto com os dados de treinamento usados para cri\u00e1-lo.\n","32c830ce":"Vamos agora criar nosso objeto `Learner`. Tamb\u00e9m usando t\u00e9cnicas de treinamento de suaviza\u00e7\u00e3o de r\u00f3tulos e otimizador `Ranger`, que s\u00e3o fornecidas no fastai. Tamb\u00e9m  usando a precis\u00e3o mista com muita facilidade:","ded80871":"Agora temos um objeto `Learner` que tem um modelo congelado (apenas os pesos da cabe\u00e7a do modelo podem ser atualizados). Para treinar um modelo, precisamos encontrar a taxa de aprendizagem ideal, o que pode ser feito com o localizador de taxa de aprendizagem do fastai `lr_find()`:","445a4ae9":"Frequentemente, se usa um modelo pr\u00e9-treinado congelado para uma \u00fanica \u00e9poca e, em seguida, treinar todo o modelo pr\u00e9-treinado para v\u00e1rias \u00e9pocas. O otimizador `Ranger` tem melhor desempenho com uma programa\u00e7\u00e3o de taxa de aprendizado de recozimento plana + cosseno. Agora treinaremos o modelo congelado por uma \u00e9poca.\n\nConforme mostrado acima, a taxa de aprendizado ideal para treinar o modelo congelado \u00e9 onde a perda est\u00e1 diminuindo mais rapidamente: cerca de ~ 1e-1. Por seguran\u00e7a, foi usado um peso elevado para ajudar a prevenir o sobreajuste. Tamb\u00e9m usaremos outra t\u00e9cnica comum de treinamento de \u00faltima gera\u00e7\u00e3o: `mixup`.","b5c1c3ff":"Vamos agora descongelar o modelo e encontrar uma boa taxa de aprendizado `lr_find()`:","456c2359":"No fastai, a classe de treinamento \u00e9 o `Learner`, que recebe os dados, modelo, otimizador, fun\u00e7\u00e3o de perda, etc. e permite que voc\u00ea treine modelos, fa\u00e7a previs\u00f5es, etc.\n\nAo treinar modelos CNN comuns como ResNets, normalmente podemos usar a fun\u00e7\u00e3o `cnn_learner` que cria um objeto `Learner` que nos permite treinar um modelo fornecido com os carregadores de dados fornecidos. No entanto, cnn_learner n\u00e3o oferece suporte aos modelos do timm prontos para uso. Zach Mueller (@muellerzr) [has written some simple functions](https:\/\/walkwithfastai.com\/vision.external.timm)  escreveu algumas fun\u00e7\u00f5es simples para tornar muito f\u00e1cil criar objetos Learner para modelos timm.\n\n","ff8f46d7":"Verifica-se que um arquivo csv de treinamento (train.csv) cont\u00e9m os nomes e r\u00f3tulos de imagem. O csv de envio de amostra, com os nomes de imagem de teste e as pastas de imagem de teste e treinamento. Tamb\u00e9m h\u00e1 as imagens no formato tfrecords, que \u00e9 \u00fatil para o carregamento r\u00e1pido de imagens, especialmente para TensorFlow e TPUs. N\u00e3o usado nesse notebook.\n\nVerificando o arquivo csv de treinamento e removendo a imagens duplicadas de acordo com esta [discuss\u00e3o](https:\/\/www.kaggle.com\/c\/cassava-leaf-disease-classification\/discussion\/198202)\n\n'1562043567.jpg' e '3551135685.jpg' (r\u00f3tulo incorreto)\n\n'2252529694.jpg' e '911861181.jpg' (duplicado)"}}