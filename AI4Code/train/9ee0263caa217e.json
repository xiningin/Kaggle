{"cell_type":{"c7bab5af":"code","8789496d":"code","0d01b663":"code","7ea46efe":"code","ee07992b":"code","8f8e1c6e":"code","bf359c0a":"code","e6b7d8b9":"code","09697956":"code","c381cf00":"code","070715d1":"code","fa539221":"code","8f01cef7":"code","4867cc01":"code","c115f2fd":"code","c60e5d7c":"code","55ee8d58":"code","b872cfa3":"code","4f02e685":"code","10c4e8e7":"code","bb2f6190":"code","ab2ba173":"code","95f3340e":"code","f1cd9346":"markdown","481128b4":"markdown","40dee1d9":"markdown","9722ff9e":"markdown","99ff802a":"markdown","7a5607d2":"markdown","1467ed05":"markdown","21740547":"markdown","d5137f1b":"markdown","545051d0":"markdown","68d8e94a":"markdown","c497a26d":"markdown","01b739b6":"markdown","adf39ea7":"markdown"},"source":{"c7bab5af":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nfrom copy import deepcopy\nimport json\nimport os\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.preprocessing import LabelEncoder\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8789496d":"def mcrmse_loss(y_true, y_pred, N=3):\n    \"\"\"\n    Calculates competition eval metric\n    \"\"\"\n    assert len(y_true) == len(y_pred)\n    n = len(y_true)\n    return np.sum(np.sqrt(np.sum((y_true - y_pred)**2, axis=0)\/n)) \/ N","0d01b663":"data_train = [json.loads(line) for line in open('..\/input\/stanford-covid-vaccine\/train.json','r')]\ndata_test = [json.loads(linha) for linha in open('..\/input\/stanford-covid-vaccine\/test.json','r')]\ntest_set = pd.read_csv('..\/input\/stanford-covid-vaccine\/sample_submission.csv')","7ea46efe":"for jason in data_train:\n    jason['step'] = list(range(jason['seq_scored']))\n    jason['sequence'] = list(jason['sequence'])\n    jason['structure'] = list(jason['structure'])\n    jason['predicted_loop_type'] = list(jason['predicted_loop_type'])","ee07992b":"for jason in data_test:\n    jason['step'] = list(range(jason['seq_scored']))\n    jason['sequence'] = list(jason['sequence'])\n    jason['structure'] = list(jason['structure'])\n    jason['predicted_loop_type'] = list(jason['predicted_loop_type'])","8f8e1c6e":"train = pd.json_normalize(data = data_train, \n                            record_path ='reactivity',  \n                            meta =['id','signal_to_noise',\n                                  'SN_filter','seq_length','seq_scored']) \ntrain.rename(columns={0:'reactivity'}, inplace=True)\ntrain['step'] = pd.json_normalize(data = data_train, \n                            record_path ='step'\n                                        )\ntrain['sequence'] = pd.json_normalize(data = data_train, \n                            record_path ='sequence'\n                                        )\ntrain['structure'] = pd.json_normalize(data = data_train, \n                            record_path ='structure'\n                                        )\ntrain['predicted_loop_type'] = pd.json_normalize(data = data_train, \n                            record_path ='predicted_loop_type'\n                                        )\ntrain['reactivity_error'] = pd.json_normalize(data = data_train, \n                            record_path ='reactivity_error'\n                                        )\ntrain['deg_Mg_pH10'] = pd.json_normalize(data = data_train, \n                            record_path ='deg_Mg_pH10'\n                                        )\ntrain['deg_error_Mg_pH10'] = pd.json_normalize(data = data_train, \n                            record_path ='deg_error_Mg_pH10'\n                                        )\ntrain['deg_pH10'] = pd.json_normalize(data = data_train, \n                            record_path ='deg_pH10',\n                                        )\ntrain['deg_error_pH10'] = pd.json_normalize(data = data_train, \n                            record_path ='deg_error_pH10',\n                                        )\ntrain['deg_Mg_50C'] = pd.json_normalize(data = data_train, \n                            record_path ='deg_Mg_50C',\n                                        )\ntrain['deg_error_Mg_50C'] = pd.json_normalize(data = data_train, \n                            record_path ='deg_error_Mg_50C',\n                                        )\ntrain['deg_50C'] = pd.json_normalize(data = data_train, \n                            record_path ='deg_50C',\n                                        )\ntrain['deg_error_50C'] = pd.json_normalize(data = data_train, \n                            record_path ='deg_error_50C',\n                                        )\n\ntrain.set_index(['id','step'], inplace=True)","bf359c0a":"test = pd.json_normalize(data = data_test,\n                         record_path = 'sequence',\n                        meta = ['id','seq_length','seq_scored'])\ntest.rename(columns={0:'sequence'},inplace=True)\ntest['step'] = pd.json_normalize(data = data_test,\n                                record_path = 'step')\ntest['sequence'] = pd.json_normalize(data = data_test,\n                                    record_path = 'sequence')\ntest['structure'] = pd.json_normalize(data = data_test,\n                                     record_path = 'structure')\ntest['predicted_loop_type'] = pd.json_normalize(data = data_test,\n                                               record_path = 'predicted_loop_type')\ntest.set_index(['id','step'], inplace=True)","e6b7d8b9":"train","09697956":"test","c381cf00":"np.random.seed(2020) #Seed the randomness to be deterministic","070715d1":"enc = LabelEncoder()\ncategory_cols_train = [cols for cols in train.columns if train[cols].dtype == 'object']\ncategory_cols_test = [cols for cols in test.columns if test[cols].dtype == 'object']\nprint(category_cols_train)\nprint(category_cols_test)\nX_train_enc = deepcopy(train)\nX_test_enc = deepcopy(test)\nfor cols in category_cols_train:\n    X_train_enc[cols] = enc.fit_transform(X_train_enc[cols])\nfor cols in category_cols_test:\n    X_test_enc[cols] = enc.fit_transform(X_test_enc[cols])","fa539221":"X = X_train_enc.drop(['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C'],axis=1)\ny = X_train_enc.loc[:,['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']]","8f01cef7":"hgbr = MultiOutputRegressor(HistGradientBoostingRegressor(max_iter = 1750, max_depth = 15,early_stopping = True, n_iter_no_change = 10,\n                                                          learning_rate = 0.0025, tol = 1e-6, validation_fraction = 0.2,\n                                                          verbose = 2, max_leaf_nodes = 64),\n                           n_jobs = 4\n)\n\ngbr = MultiOutputRegressor(GradientBoostingRegressor(loss = 'huber', n_estimators = 1000, max_depth = 15,\n                                                     learning_rate = 0.0025, tol = 1e-7, validation_fraction = 0.2,\n                                                     n_iter_no_change = 15, verbose = 2\n    )\n)","4867cc01":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)","c115f2fd":"X_train","c60e5d7c":"hgbr.fit(X_train,y_train)","55ee8d58":"y_pred = hgbr.predict(X_test)","b872cfa3":"print(mean_squared_error(y_test,y_pred,squared=False))","4f02e685":"X_train_enc[X_test_enc.columns]","10c4e8e7":"hgbr.fit(X_train_enc[X_test_enc.columns],y)","bb2f6190":"y_pred_2 = hgbr.predict(X_test_enc)","ab2ba173":"y_pred_2.shape","95f3340e":"submission = pd.DataFrame(np.concatenate([test_set.id_seqpos.values[:,np.newaxis],y_pred_2],axis=1),columns=test_set.columns)\ndisplay(submission.head(10))\nsubmission.to_csv('submission.csv',index=False)","f1cd9346":"## Here we get a insight for what happened to our dataset","481128b4":"# Preprocessing","40dee1d9":"# Results\n\nIt's better than the Gaussin Notebook found here, but i think the top 4, will be better with NN than usual machine learning algorithms.","9722ff9e":"## Train treatment","99ff802a":"# OpenVaccine - Covid-sars-2019\n\nThis notebook has the intend to show a way to expand the list inside th JSONs files and a little\nintrospection with the HistRegressor and a MultiLabel regression task.","7a5607d2":"### **Test**","1467ed05":"# Model Instance\n\n> Here I only used HistBoosting, due to large dataset (n_samples > 100000), the GradientBoostingRegressor take too long too run.","21740547":"### **Train**","d5137f1b":"# Loading the datasets\n\nThe train and test are not load with Pandas library, only submission file is opened to copy the ID's to final submission.","545051d0":"## RMSE","68d8e94a":"This notebook is highly inspired in this notebook:\n\n*[Flatten JSON Data](https:\/\/www.kaggle.com\/arunprathap\/openvaccine-flatten-json-data)\n\nFeel free to comment and upvote \ud83d\ude01","c497a26d":"## Test treatment","01b739b6":"### ~This function is not used~","adf39ea7":"# Cross Validation - train_test_split"}}