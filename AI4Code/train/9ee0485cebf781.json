{"cell_type":{"c4138161":"code","519d2af9":"code","83259458":"code","d7ed2dec":"code","b6f683f5":"code","5a9bd574":"code","f802cb29":"code","133fc6af":"code","c9f5b1da":"code","58c62a35":"code","6928b415":"code","518f34b6":"code","aaa8b6b9":"code","2300b676":"code","11d2782f":"code","7e9408fa":"code","be534125":"code","d8c3c9d0":"code","75d2fc51":"code","d4f78089":"code","0a7510bf":"code","a4ab308b":"code","19fe5701":"code","7d266f88":"code","f8f7bc5d":"code","4409fb13":"code","a93e6793":"code","4d824574":"code","48935d96":"code","c61cce67":"code","7d05e181":"code","86cba6ea":"code","887eb903":"code","638e2236":"code","4814d34e":"markdown","bcf1e686":"markdown","ccf8415f":"markdown","e179c569":"markdown","15941e79":"markdown","4c4dd917":"markdown","625cb15b":"markdown","1d217d4c":"markdown","9916375a":"markdown","badeed0e":"markdown"},"source":{"c4138161":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\n\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, precision_recall_curve, confusion_matrix\n\n# For ensemble modelling\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import VotingClassifier","519d2af9":"df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')","83259458":"df.head()","d7ed2dec":"# Find the shape of dataset\n\ndf.shape","b6f683f5":"# Find the datatype of each attribute\n\ndf.info()","5a9bd574":"# Statistics for numeric attributes\n\ndf.describe()","f802cb29":"# Check for duplicates\n\nduplicate = df[df.duplicated()]\nduplicate","133fc6af":"# Remove duplicate records except the first occurence\n\ndf.drop_duplicates(inplace=True)","c9f5b1da":"# Again check if any duplicate records are left\n\nduplicate = df[df.duplicated()] \nduplicate","58c62a35":"# Find the total number of missing values in each column\n\ndf.isna().sum()","6928b415":"# Checking the shape again\n\ndf.shape","518f34b6":"# PLot Correlation Matrix\n\ncorr = df.corr()\ncorr.style.background_gradient(cmap='PuBu').set_precision(2)","aaa8b6b9":"# Plot class distribution\n\nsns.countplot(data=df, x='Class')","2300b676":"# Splitting the dataset into train and test sets\n\nX = df.iloc[:, :-1].to_numpy()\ny = df['Class'].to_numpy()","11d2782f":"# Generate and plot a synthetic imbalanced classification dataset\n\ncounter = Counter(y)\nprint(counter)\n\n# Scatter plot of 'Class' by class label\nfor label, _ in counter.items():\n    row_ix = np.where(y == label)[0]\n    plt.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\nplt.legend()\nplt.show()","7e9408fa":"# Transform the dataset\n\nsm = SMOTE(random_state=0)\nX, y = sm.fit_resample(X, y)","be534125":"counter = Counter(y)\nprint(counter)\n\n# Scatter plot of 'Class' by class label\nfor label, _ in counter.items():\n    row_ix = np.where(y == label)[0]\n    plt.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\nplt.legend()\nplt.show()","d8c3c9d0":"# Split dataset into train and test sets\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\nprint(\"X_train:\", X_train.shape)\nprint(\"X_test:\", X_test.shape)\nprint(\"y_train:\", y_train.shape)\nprint(\"y_test:\", y_test.shape)","75d2fc51":"dt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)","d4f78089":"print(\"Score of train data:\", dt.score(X_train, y_train))\nprint(\"Score of test data:\", dt.score(X_test, y_test))","0a7510bf":"y_pred = dt.predict(X_test)\ny_pred","a4ab308b":"print(\"Accuracy Score:\", accuracy_score(y_pred, y_test))","19fe5701":"y_pred_prob = dt.predict_proba(X_test)[:,1]\nprecision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\nplt.plot(recall, precision)\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision Recall Curve')","7d266f88":"# Confusion Matrix\n\ncm = confusion_matrix(y_test, y_pred)\n\nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax=ax); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')\nax.set_title('Confusion Matrix')","f8f7bc5d":"import keras\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\n\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV","4409fb13":"# Initialising the ANN\nclassifier = Sequential()\nclassifier.add(Dense(units=30, kernel_initializer='he_uniform', activation='relu', input_dim = 30))\nclassifier.add(Dense(units=50, kernel_initializer='he_uniform', activation='relu'))\nclassifier.add(Dense(units=35, kernel_initializer='he_uniform', activation='relu'))\nclassifier.add(Dense(units=2, activation='softmax'))\n\n# Compiling the ANN\nclassifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","a93e6793":"classifier.summary()","4d824574":"# Fitting the ANN to the Training set\n\nmodel_history = classifier.fit(X_train, y_train, validation_split=0.33, batch_size=250, epochs=30)","48935d96":"# List all data in history\nprint(model_history.history.keys())\n\n# Summarize history for accuracy\nplt.plot(model_history.history['accuracy'])\nplt.plot(model_history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","c61cce67":"# Summarize history for loss\n\nplt.plot(model_history.history['loss'])\nplt.plot(model_history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","7d05e181":"# Calculating score\n\nscore = classifier.evaluate(X_test, y_test)\nscore","86cba6ea":"# Predicting on test data\n\ny_pred = classifier.predict(X_test)\ny_pred = np.argmax(y_pred, axis=1)\ny_pred","887eb903":"# Accuracy\n\naccuracy_score(y_pred, y_test)","638e2236":"# Confusion Matrix\n\ncm = confusion_matrix(y_test, y_pred)\n\nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax=ax); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')\nax.set_title('Confusion Matrix')","4814d34e":"<b>It can be seen that the dataset is highly imbalanced.<\/b>\n\n1 --> Fraud Transactions<br> 0 --> Otherwise","bcf1e686":"## Importing libraries","ccf8415f":"<b>Hence, all duplicate records are removed.<\/b>","e179c569":"<b>After removing duplicate values and checking for missing values there are 2,83,726 records in dataset.<\/b>","15941e79":"### 2. Neural Netowrk","4c4dd917":"## Loading the dataset","625cb15b":"<b>There are no missing values in the dataset.<\/b>","1d217d4c":"## Model","9916375a":"<b> The dataset has 1,081 duplicate records. <\/b>","badeed0e":"### 1. Decision Tree Classifier"}}