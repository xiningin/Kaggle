{"cell_type":{"33021178":"code","da6e3fdf":"code","ed53defa":"code","1f941502":"code","43fddb35":"code","306c6037":"code","0fddaf15":"code","713c81f6":"code","461a39ad":"markdown","7bba4b53":"markdown","8a4cbb2c":"markdown","7cfa968a":"markdown","843b7e08":"markdown","0df78213":"markdown"},"source":{"33021178":"import os\nimport struct\nimport numpy as np\n\n\ndef load_mnist(path, kind = 'train'):\n    \"\"\"MNIST\u30c7\u30fc\u30bf\u3092path\u304b\u3089\u30ed\u30fc\u30c9\"\"\"\n    labels_path = os.path.join(path, '..\/input\/mnistdataset\/%s-labels-idx1-ubyte' % kind)\n    images_path = os.path.join(path, '..\/input\/mnistdataset\/%s-images-idx3-ubyte' % kind)\n    \n    # \u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080:\u5f15\u6570\u306e\u30d5\u30a1\u30a4\u30eb\u3001\u30e2\u30fc\u30c9\u3092\u6307\u5b9a\n    with open(labels_path, 'rb') as lbpath:\n        # \u30d0\u30a4\u30ca\u30ea\u3092\u6587\u5b57\u5217\u306b\u5909\u63db: unpack\u95a2\u6570\u306e\u5f15\u6570\u306b\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u30018\u30d0\u30a4\u30c8\u5206\u306e\n        # \u30d0\u30a4\u30ca\u30ea\u30c7\u30fc\u30bf\u3092\u6307\u5b9a\u3057\u3066\u30de\u30b8\u30c3\u30af\u30ca\u30f3\u30d0\u30fc\u3001\u30a2\u30a4\u30c6\u30e0\u306e\u500b\u6570\u3092\u8aad\u307f\u8fbc\u3080\n        magic, n = struct.unpack('>II', lbpath.read(8))\n        # \u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30e9\u30d9\u30eb\u3092\u8aad\u307f\u8fbc\u307f\u914d\u5217\u3092\u69cb\u7bc9:fromfile\u95a2\u6570\u306e\u5f15\u6570\n        # \u30d5\u30a1\u30a4\u30eb\u3001\u914d\u5217\u306e\u30c7\u30fc\u30bf\u5f62\u5f0f\u3092\u6307\u5b9a\n        labels = np.fromfile(lbpath, dtype = np.uint8)\n        \n    with open(images_path, 'rb') as imgpath:\n        magic, num, rows, cols = struct.unpack(\">IIII\", imgpath.read(16))\n        # \u753b\u50cf\u30d4\u30af\u30bb\u30eb\u60c5\u5831\u306e\u914d\u5217\u306e\u30b5\u30a4\u30ba\u3092\u5909\u66f4\n        images = np.fromfile(imgpath, dtype = np.uint8).reshape(len(labels), 784)\n        # \u753b\u7d20\u5024\u3092-1\u304b\u30891\u306b\u5909\u63db\n        images = ((images \/ 255.) - 0.5) * 2\n    return images, labels\n\n\n\n\nX_train, y_train = load_mnist('', kind = 'train')\nprint('Rows: %d, columns: %d' % (X_train.shape[0], X_train.shape[1]))\nX_test, y_test = load_mnist('', kind = 't10k')\nprint('Rows: %d, columns: %d' % (X_test.shape[0], X_test.shape[1]))","da6e3fdf":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(nrows = 2, ncols = 5, sharex = True, sharey = True)\nax = ax.flatten()\nfor i in range(10):\n    img = X_train[y_train == i][0].reshape(28, 28)\n    ax[i].imshow(img, cmap = 'Greys')\n    \nax[0].set_xticks([])\nax[0].set_yticks([])\nplt.tight_layout()\nplt.savefig(\"output.png\")\nplt.show()","ed53defa":"fig, ax = plt.subplots(nrows = 5, ncols = 5, sharex = True, sharey = True)\nax = ax.flatten()\nfor i in range(25):\n    img = X_train[y_train == 7][i].reshape(28, 28)\n    ax[i].imshow(img, cmap = 'Greys')\nax[0].set_xticks([])\nax[0].set_yticks([])\nplt.tight_layout()\nplt.show()","1f941502":"import numpy as np\nnp.savez_compressed('mnist_scaled.npz',\n                    X_train = X_train,\n                    y_train = y_train,\n                    X_test = X_test,\n                    y_test = y_test)\nmnist = np.load('mnist_scaled.npz')\n\nmnist.files\n\nX_train = mnist['X_train']\n\nX_train, y_train, X_test, y_test = [mnist[f] for f in ['X_train', 'y_train', 'X_test', 'y_test']]\ndel mnist\nX_train.shape","43fddb35":"import numpy as np\nimport sys\n\nclass NeuralNetMLP(object):\n    \"\"\" \u30d5\u30a3\u30fc\u30c9\u30d5\u30a9\u30ef\u30fc\u30c9\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af \/ \u591a\u5c64\u30d1\u30fc\u30bb\u30d7\u30c8\u30ed\u30f3\u5206\u985e\u5668\n    \u30d1\u30e9\u30e1\u30fc\u30bf\n    ----------\n    n_hidden : int (\u30c7\u30d5\u30a9\u30eb\u30c8 30)\n        \u96a0\u308c\u30e6\u30cb\u30c3\u30c8\u306e\u500b\u6570\n    l2 : float (\u30c7\u30d5\u30a9\u30eb\u30c8 : 0.)\n        L2\u6b63\u5247\u5316\u306e\u03bb\u30d1\u30e9\u30e1\u30fc\u30bf\n        l2 = 0\u306e\u5834\u5408\u306f\u6b63\u5247\u5316\u306a\u3057 (default)\n    epochs : int(\u30c7\u30d5\u30a9\u30eb\u30c8: 100)\n        \u8a13\u7df4\u306e\u56de\u6570\n    eta : float(\u30c7\u30d5\u30a9\u30eb\u30c8 : 0.001)\n        \u5b66\u7fd2\u7387\n    shuffle : bool(\u30c7\u30d5\u30a9\u30eb\u30c8 : True)\n        True\u306e\u5834\u5408\u3001\u5faa\u74b0\u3092\u907f\u3051\u308b\u305f\u3081\u306b\u30a8\u30dd\u30c3\u30af\u3054\u3068\u306b\u8a13\u7df4\u30c7\u30fc\u30bf\u3092\u30b7\u30e3\u30c3\u30d5\u30eb\n    minibatch_size : int(\u30c7\u30d5\u30a9\u30eb\u30c8 : 1)\n        \u30df\u30cb\u30d0\u30c3\u30c1\u3042\u305f\u308a\u306e\u8a13\u7df4\u30c7\u30fc\u30bf\u306e\u500b\u6570\n    seed : int(\u30c7\u30d5\u30a9\u30eb\u30c8: None)\n        \u91cd\u307f\u3068\u30b7\u30e3\u30c3\u30d5\u30eb\u3092\u521d\u671f\u5316\u3059\u308b\u305f\u3081\u306e\u30b7\u30fc\u30c9\n    \n    \u5c5e\u6027\n    ----------\n    eval_ : dict\n        \u8a13\u7df4\u306e\u30a8\u30dd\u30c3\u30af\u3054\u3068\u306b\u3001\u3000\u30b3\u30b9\u30c8\u3001\u3000\u8a13\u7df4\u306e\u6b63\u89e3\u7387\u3001\u3000\u691c\u8a3c\u306e\u6b63\u89e3\u7387\u3092\u53ce\u96c6\u3059\u308b\u30c7\u30a3\u30af\u30b7\u30e7\u30ca\u30ea\u30fc\n    \"\"\"\n    \n    def __init__(self, n_hidden = 30, l2 = 0., epochs = 100, eta = 0.001,\n                 shuffle = True, minibatch_size = 1, seed = None):\n        \"\"\"NeuralNetMLP\u306e\u521d\u671f\u5316\"\"\"\n        \n        self.random = np.random.RandomState(seed)\n        self.n_hidden = n_hidden\n        self.l2 = l2\n        self.epochs = epochs\n        self.eta = eta\n        self.shuffle = shuffle\n        self.minibatch_size = minibatch_size\n        \n    def _onehot(self, y, n_classes):\n        \"\"\"\u30e9\u30d9\u30eb\u3092one-hot\u8868\u73fe\u306b\u30a8\u30f3\u30b3\u30fc\u30c9\n        \n        \u30d1\u30e9\u30e1\u30fc\u30bf\n        ----------\n        y : array, shape = [n_examples]\n            \u76ee\u7684\u5909\u6570\u306e\u5024\n        \n        \u623b\u308a\u5024\n        ----------\n        onehot : array, shape = (n_examples, n_labels)\n        \"\"\"\n        \n        onehot = np.zeros((n_classes, y.shape[0]))\n        for idx, val in enumerate(y.astype(int)):\n            onehot[val, idx] = 1.\n            \n        return onehot.T\n    \n    def _sigmoid(self, z):\n        return 1.\/ (1 + np.exp(-np.clip(z, -250, 250)))\n    \n    def _forward(self, X):\n        \"\"\"\u30d5\u30a9\u30ef\u30fc\u30c9\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\u306e\u30b9\u30c6\u30c3\u30d7\u3092\u8a08\u7b97\"\"\"\n        \n        # \u30b9\u30c6\u30c3\u30d71:\u96a0\u308c\u5c64\u306e\u7dcf\u5165\u529b\n        # [n_examples, n_features] dot [n_features, n_hidden]\n        # -> [n_examples, n_hidden]\n        z_h = np.dot(X, self.w_h) + self.b_h\n        \n        # \u30b9\u30c6\u30c3\u30d72:\u96a0\u308c\u5c64\u306e\u6d3b\u6027\u5316\u95a2\u6570\n        a_h = self._sigmoid(z_h)\n        \n        # \u30b9\u30c6\u30c3\u30d73:\u51fa\u529b\u5c64\u306e\u7dcf\u5165\u529b\n        # [n_examples, n_hidden] dot [n_hidden, n_classlabels]\n        # -> [n_examples, n_classlabels]\n        z_out = np.dot(a_h, self.w_out) + self.b_out\n        \n        # \u30b9\u30c6\u30c3\u30d74:\u51fa\u529b\u5c64\u306e\u6d3b\u6027\u5316\u95a2\u6570\n        a_out = self._sigmoid(z_out)\n        \n        return z_h, a_h, z_out, a_out\n        \n    def _compute_cost(self, y_enc, output):\n        \"\"\"\u30b3\u30b9\u30c8\u95a2\u6570\u3092\u8a08\u7b97\n        \n        \u30d1\u30e9\u30e1\u30fc\u30bf\n        ----------\n        y_enc : array, shape = (n_examples, n_labels)\n            one-hot\u8868\u73fe\u306b\u30a8\u30f3\u30b3\u30fc\u30c9\u3055\u308c\u305f\u30af\u30e9\u30b9\u30e9\u30d9\u30eb\n        output : array, shape = [n_examples, n_output_units]\n            \u51fa\u529b\u5c64\u306e\u6d3b\u6027\u5316\u95a2\u6570(\u30d5\u30a9\u30ef\u30fc\u30c9\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3)\n        \n        \u623b\u308a\u5024\n        ----------\n        cost: float\n            \u6b63\u5247\u5316\u3055\u308c\u305f\u30b3\u30b9\u30c8\n        \"\"\"\n        \n        # L2\u6b63\u5247\u5316\n        L2_term = (self.l2 *\n                   (np.sum(self.w_h ** 2.) +\n                    np.sum(self.w_out ** 2.)))\n        term1 = -y_enc * (np.log(output))\n        term2 = (1. - y_enc) * np.log(1. - output)\n        cost = np.sum(term1 - term2) + L2_term\n        \n        return cost\n    \n    def predict(self, X):\n        \"\"\"\u30af\u30e9\u30b9\u30e9\u30d9\u30eb\u3092\u4e88\u6e2c\n        \n        \u30d1\u30e9\u30e1\u30fc\u30bf\n        ----------\n        \n        X:array, shape = [n_examples, n_features]\n            \u5143\u306e\u7279\u5fb4\u91cf\u304c\u8a2d\u5b9a\u3055\u308c\u305f\u5165\u529b\u5c64\n        y_pred: array, shape = [n_examples]\n            \u4e88\u6e2c\u3055\u308c\u305f\u30af\u30e9\u30b9\u30e9\u30d9\u30eb\n        \"\"\"\n        z_h, a_h, z_out, a_out = self._forward(X)\n        y_pred = np.argmax(z_out, axis = 1)\n        \n        return y_pred\n    \n    def fit(self, X_train, y_train, X_valid, y_valid):\n        \"\"\"\u8a13\u7df4\u30c7\u30fc\u30bf\u304b\u3089\u91cd\u307f\u3092\u5b66\u7fd2\n        \n        \u30d1\u30e9\u30e1\u30fc\u30bf\n        ----------\n        X_train : array, shape = [n_examples, n_features]\n            \u5143\u306e\u7279\u5fb4\u91cf\u304c\u8a2d\u5b9a\u3055\u308c\u305f\u5165\u529b\u5c64\n        y_train : array, shape = [n_examples]\n            \u76ee\u7684\u5909\u6570(\u30af\u30e9\u30b9\u30e9\u30d9\u30eb)\n        X_valid : array, shape = [n_examples, n_features]\n            \u8a13\u7df4\u6642\u306e\u691c\u8a3c\u306b\u4f7f\u3046\u30b5\u30f3\u30d7\u30eb\u7279\u5fb4\u91cf\n        y_valid : array, shape = [n_examples]\n        \n        \u623b\u308a\u5024:\n        ----------\n        self\n        \"\"\"\n        \n        \n        # \u30af\u30e9\u30b9\u30e9\u30d9\u30eb\u306e\u500b\u6570\n        n_output = np.unique(y_train).shape[0]\n        n_features = X_train.shape[1]\n        \n        ############\n        # \u91cd\u307f\u306e\u521d\u671f\u5316\n        ############\n        \n        # \u5165\u529b\u5c64 -> \u96a0\u308c\u5c64\u306e\u91cd\u307f\n        self.b_h = np.zeros(self.n_hidden)\n        self.w_h = self.random.normal(loc = 0.0, scale = 0.1,\n                                      size = (n_features, self.n_hidden))\n        \n        # \u96a0\u308c\u5c64 -> \u51fa\u529b\u5c64\u306e\u91cd\u307f\n        self.b_out = np.zeros(n_output)\n        self.w_out = self.random.normal(loc = 0.0, scale = 0.1,\n                                        size = (self.n_hidden, n_output))\n        \n        epoch_strlen = len(str(self.epochs))\n        self.eval_ = {'cost': [], 'train_acc' : [], 'valid_acc' : []}\n        \n        y_train_enc = self._onehot(y_train, n_output)\n        \n        # \u30a8\u30dd\u30c3\u30af\u6570\u3060\u3051\u8a13\u7df4\u3092\u7e70\u308a\u8fd4\u3059\n        \n        for i in range(self.epochs):\n            # \u30df\u30cb\u30d0\u30c3\u30c1\u306e\u53cd\u5fa9\u51e6\u7406(\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3)\n            indices = np.arange(X_train.shape[0])\n            if self.shuffle:\n                self.random.shuffle(indices)\n        \n            for start_idx in range(0, indices.shape[0] - self.minibatch_size + 1,\n                               self.minibatch_size):\n                batch_idx = indices[start_idx:start_idx + self.minibatch_size]\n            \n                # \u30d5\u30a9\u30ef\u30fc\u30c9\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\n                z_h, a_h, z_out, a_out = self._forward(X_train[batch_idx])\n            \n                ###################\n                # \u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\n                ###################\n            \n                # [n_examples, n_classlabels]\n                # \u51fa\u529b\u5c64\u306e\u8aa4\u5dee\u30d9\u30af\u30c8\u30eb(\u5f0f(12.3.13))\n                delta_out = a_out - y_train_enc[batch_idx]\n                \n                # [n_examples, n_hidden]\n                # sigmoid\u95a2\u6570\u306e\u504f\u5fae\u5206\u4fc2\u6570(\u5f0f(12.3.15))\n                sigmoid_derivative_h = a_h * (1. - a_h)\n            \n                # [n_examples, n_classlabels] dot [n_examples, n_hidden]\n                # -> [n_examples, n_hidden]\n                # \u96a0\u308c\u5c64\u306e\u8aa4\u5dee\u30d9\u30af\u30c8\u30eb(\u5f0f(12.3.14))\n                delta_h = (np.dot(delta_out, self.w_out.T) * sigmoid_derivative_h)\n                \n                \n                # [n_features, n_examples] dot [n_examples, n_hidden]\n                # -> [n_features, n_hidden]\n                # \u52fe\u914d\u3092\u8a08\u7b97(\u5f0f(12.3.17),\u5f0f(12.3.18))\n                \n                grad_w_h = np.dot(X_train[batch_idx].T, delta_h)\n                grad_b_h = np.sum(delta_h, axis = 0)\n                \n                grad_w_out = np.dot(a_h.T, delta_out)\n                grad_b_out = np.sum(delta_out, axis = 0)\n                \n                # \u6b63\u5247\u5316\u3068\u91cd\u307f\u306e\u66f4\u65b0\n                # \u5f0f(12.3.19)\n                delta_w_h = (grad_w_h + self.l2 * self.w_h)\n                delta_b_h = grad_b_h # \u30d0\u30a4\u30a2\u30b9\u306f\u6b63\u5247\u5316\u3057\u306a\u3044\n                delta_w_out = (grad_w_out + self.l2 * self.w_out)\n                delta_b_out = grad_b_out # \u30d0\u30a4\u30a2\u30b9\u306f\u6b63\u5247\u5316\u3057\u306a\u3044\n                \n                # \u5f0f(12.3.20)\n                self.w_h -= self.eta * delta_w_h\n                self.b_h -= self.eta * delta_b_h\n                self.w_out -= self.eta * delta_w_out\n                self.b_out -= self.eta * delta_b_out\n            \n            ##########\n            # \u8a55\u4fa1\n            #########\n            \n            # \u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u3054\u3068\u306b\u8a55\u4fa1\u3092\u884c\u3046\n            z_h, a_h, z_out, a_out = self._forward(X_train)\n            cost = self._compute_cost(y_enc = y_train_enc, output = a_out)\n        \n            y_train_pred = self.predict(X_train)\n            y_valid_pred = self.predict(X_valid)\n        \n            train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) \/ X_train.shape[0])\n            valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) \/ X_valid.shape[0])\n        \n\n            sys.stderr.write('\\r%0*d\/%d | Cost: %.2f '\n                   '| Train\/Valid Acc.: %.2f%%\/%.2f%% ' %\n                    (epoch_strlen, i+1, self.epochs, cost,\n                    train_acc*100, valid_acc*100))\n            sys.stderr.flush()\n        \n            self.eval_['cost'].append(cost)\n            self.eval_['train_acc'].append(train_acc)\n            self.eval_['valid_acc'].append(valid_acc)\n        \n        return self","306c6037":"n_epochs = 20\nnn = NeuralNetMLP(n_hidden = 100,\n                  l2 = 0.05,\n                  epochs = n_epochs,\n                  eta = 0.0005,\n                  minibatch_size = 100,\n                  shuffle = True,\n                  seed = 1)\n\nnn.fit(X_train = X_train[:55000],\n       y_train = y_train[:55000],\n       X_valid = X_train[55000:],\n       y_valid = y_train[55000:])\n\nplt.plot(range(nn.epochs), nn.eval_['cost'])\nplt.ylabel('Cost')\nplt.xlabel('Epochs')\nplt.show()\n\n\nplt.plot(range(nn.epochs), nn.eval_['train_acc'], \n         label = 'Training')\nplt.plot(range(nn.epochs), nn.eval_['valid_acc'], \n         label = 'Validation', linestyle='--')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(loc = 'lower right')\n\nplt.show()","0fddaf15":"# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u60f3\ny_test_pred = nn.predict(X_test)\nacc = (np.sum(y_test == y_test_pred).astype(np.float) \/ X_test.shape[0])\nprint('Test accuracy: %.2f%%' % (acc * 100))","713c81f6":"# \u9593\u9055\u3063\u305f\u3068\u304d\u306e\u753b\u50cf\u3068\u6b63\u89e3\u30e9\u30d9\u30eb\u3001\u4e88\u60f3\u30e9\u30d9\u30eb\u3092\u51fa\u529b\nmiscl_img = X_test[y_test != y_test_pred][:25]\ncorrect_lab = y_test[y_test != y_test_pred][:25]\nmiscl_lab = y_test_pred[y_test != y_test_pred][:25]\nfig, ax = plt.subplots(nrows = 5, ncols = 5, sharex = True, sharey = True)\nax = ax.flatten()\nfor i in range(25):\n    img = miscl_img[i].reshape(28,28)\n    ax[i].imshow(img, cmap = 'Greys', interpolation = 'nearest')\n    ax[i].set_title('%d) t: %d p: %d' %(i+1, correct_lab[i], miscl_lab[i]))\n    \nax[0].set_xticks([])\nax[0].set_yticks([])\nplt.tight_layout()\nplt.show()","461a39ad":"## Step:3 \u591a\u5c64\u30d1\u30fc\u30bb\u30d7\u30c8\u30ed\u30f3\u3092\u5b9f\u88c5\u3059\u308b\n\n\u3053\u3053\u3067\u306fMNIST\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u753b\u50cf\u3092\u5206\u985e\u3059\u308b\u591a\u5c64\u30d1\u30fc\u30bb\u30d7\u30c8\u30ed\u30f3\u3092\u5b9f\u88c5\u3059\u308b\uff0e\n\n\u30b3\u30fc\u30c9\u306f\u30b7\u30f3\u30d7\u30eb\u3067\u5165\u529b\u5c64\u3068\u96a0\u308c\u5c64\u3068\u51fa\u529b\u5c64\u306e3\u3064\u306e\u307f\u3067\u3042\u308b\uff0e","7bba4b53":"\u8a66\u3057\u306b\u540c\u3058\u6570\u5b57\u306e\u753b\u50cf\u3092\u3044\u304f\u3064\u304b\u8868\u793a\u3057\u3066\u307f\u3066\uff0c\u9055\u3044\u3092\u78ba\u8a8d\u3059\u308b","8a4cbb2c":"## Step:1 \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\n\nMNIST\u3068\u547c\u3070\u308c\u308b1~9\u306e\u624b\u66f8\u304d\u6570\u5b57\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u8aad\u307f\u8fbc\u3080\n\nMNIST\u306f\u53e4\u304f\u304b\u3089\u6a5f\u68b0\u5b66\u7fd2\u306e\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u3068\u3057\u3066\u3088\u304f\u7528\u3044\u3089\u308c\u308b\n\n![MNIST](.\/output.png)","7cfa968a":"### Step:2 \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u8868\u793a\u3057\u3066\u307f\u308b","843b7e08":"# \u591a\u5c64\u4eba\u5de5\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\n\n\u524d\u56de\u307e\u3067\u306f\u4e3b\u306b\u5358\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306b\u3064\u3044\u3066\u5b66\u3093\u3060\uff0e\n\n\u5358\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3067\u306f\u7dda\u5f62\u5206\u96e2\u4e0d\u53ef\u80fd\u306a\u554f\u984c\u306b\u5bfe\u3057\u3066\u306f\u5b66\u7fd2\u304c\u53ce\u675f\u3057\u306a\u3044\u305f\u3081\u9069\u7528\u304c\u4e0d\u53ef\u80fd\u3067\u3042\u3063\u305f\uff0e\n\n\u3053\u306enotebook\u3067\u306f\u591a\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u6982\u5ff5\u3092\u7406\u89e3\u3057\uff0c\u4f8b\u3068\u3057\u3066\u753b\u50cf\u306e\u5206\u985e\u3092\u884c\u3046\uff0e\n\n* \u591a\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u6982\u5ff5\u3092\u7406\u89e3\u3059\u308b\n\n* \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u8a13\u7df4\u3059\u308b\u305f\u3081\u306e\u57fa\u672c\u7684\u306a\u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u5b9f\u88c5\u3059\u308b\n\n* \u753b\u50cf\u3092\u5206\u985e\u3059\u308b\u305f\u3081\u306e\u57fa\u672c\u7684\u306a\u591a\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u8a13\u7df4\u3059\u308b\n","0df78213":"\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304b\u3089Zip\u30a2\u30fc\u30ab\u30a4\u30d6\u3092\u751f\u6210\u3057\u3066\uff0c\u30c7\u30fc\u30bf\u30d5\u30a1\u30a4\u30eb\u3092.npy\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u683c\u7d0d\u3055\u308c\u305fnpz\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3059\u308b\uff0e\n\n\u3053\u308c\u306b\u3088\u3063\u3066\u6bce\u56de\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304b\u3089\u8aad\u307f\u3053\u3093\u3067\u51e6\u7406\u3059\u308b\u5fc5\u8981\u304c\u306a\u304f\u306a\u308b\uff0e"}}