{"cell_type":{"4088acd3":"code","d2f769e7":"code","5c572dcc":"code","2e8aedbf":"code","ae7c717b":"code","c6887051":"code","15f1048b":"code","9117f018":"code","6c5b3148":"code","c4f0d3ef":"code","31cb7a71":"code","e731b803":"code","78cf3cf7":"code","35d57024":"code","e71c43f5":"code","b132b85f":"code","70f5c245":"code","e12db10e":"code","0fd8ae7d":"code","10c879df":"code","1634c017":"code","729a9483":"code","89f1e0eb":"code","8a0b4f89":"code","99f8a834":"code","5bddaa44":"markdown","aa58be89":"markdown","11002bd1":"markdown","42b57637":"markdown"},"source":{"4088acd3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n# print(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d2f769e7":"import pandas as pd\ndata = pd.read_csv('..\/input\/adult.csv')\n\ndata.describe()\ndata.loc[data['income']=='<=50K', 'income']=-1\ndata.loc[data['income']=='>50K', 'income']=1\ndata.rename(columns={'income':'is_income_more_than_50K'}, inplace=True)","5c572dcc":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%config InlineBackend.figure_format = 'retina'\ndata = data.replace('?', np.nan).dropna()\ndata.head()","2e8aedbf":"# sns.set(rc={'figure.figsize':(13,5)})\n# sns.countplot(x='education.num', data=data)\n# sns.countplot(x='marital.status', data=data)\n# sns.countplot(x='education', data=data)\ncleaned_data= data.copy()\ncleaned_data['capital_profit'] = cleaned_data['capital.gain']- cleaned_data['capital.loss']\ncleaned_data.replace(\n    {'marital.status': \n     {'Married-spouse-absent':7, 'Married-civ-spouse': 6, 'Married-AF-spouse': 5,'Divorced':2,'Never-married':4,'Separated':3,\n      'Widowed':1\n     },\n     'relationship':{'Wife':1,'Own-child':1,'Husband':2, 'Not-in-family':3, 'Other-relative':4, 'Unmarried':5\n     },\n     'workclass':{'Private':3,'Self-emp-not-inc':3,'Self-emp-inc':3,'Federal-gov':2,'Local-gov':2,'State-gov':2,\n                  'Without-pay':1,'Never-worked':1\n    },\n     'sex':{'Female':1,'Male':2\n    },\n\n    }, inplace=True)\n\n# is_complete_family = cleaned_data['marital.status'].isin(['Married-civ-spouse','Married-AF-spous'])\n# cleaned_data.loc[is_complete_family, 'marital.status']=1\n# cleaned_data.loc[~is_complete_family, 'marital.status']=0\n\ncleaned_data.drop(['education','native.country','capital.loss','capital.gain','race','occupation'], axis=1, inplace=True)\ncleaned_data=cleaned_data[['age', 'workclass', 'fnlwgt', 'education.num', 'marital.status',\n       'relationship', 'sex', 'hours.per.week', \n       'capital_profit','is_income_more_than_50K']]","ae7c717b":"# sns.pairplot(data=data, hue ='is_income_more_than_50K')\ncleaned_data.head()","c6887051":"def split_data_to_k_folders(data, k=10):\n    \"\"\"Split data into k folders evenly and throw the remained data\"\"\"\n    ##number of rows of data in every folder\n    unit = len(data)\/\/k\n    data_folders = []\n    for i in range(0,len(data), unit):\n        data_folders.append(data.iloc[i:i+unit])\n    return data_folders[:k]\n\ndef get_stratified_folder(d1, d2):\n    combied_folder = []\n    for i in range(len(d1)):\n        temp = d1[i].append(d2[i])\n        combied_folder.append(temp)\n    return combied_folder\n\ndef split_data_train_test(test_num, combied_folder):\n    temp_folder  = combied_folder.copy()\n    index = test_num-1\n    test_data = temp_folder[index].copy()\n    del temp_folder[index]\n    train_data = temp_folder[0].append(temp_folder[1:])\n    return train_data, test_data\n\n\"\"\"\nNormalize all dataframe\n\"\"\"\ndef get_norm_df(old_df, label):\n    new_df= pd.DataFrame()\n    for col in old_df.columns:\n        if col!=label:\n            new_df[col]=norm(old_df[col].values)\n        else:\n            new_df[col] = old_df[col].values\n    return new_df\n\n\n\"\"\"Normalize one of the col of the dataframe\"\"\"\ndef norm(col_values):\n    col_values =(col_values-min(col_values))\/max(col_values)\n    return col_values\n","15f1048b":"from random import *\n\ndef split_df_by_label(df):\n    neg = df[df['is_income_more_than_50K']==-1]\n    pos = df[df['is_income_more_than_50K']==1]\n    return neg, pos\n\n\ndef train_test_split(f_list,test_i=0, ratio =0.8):\n\n    def get_random_train_index(n,test_index, k):\n        \"\"\"n: the number of random number\n             test_index:the random number should not be the t\u2014index\n             return type: [1,4,5,3,...]\n        \"\"\"\n        all_i = np.arange(k).tolist()\n\n        rand_list =[]\n        while True:\n            if len(rand_list)==n+1:\n                break\n            m=len(all_i)\n            selected_i = randint(0,m-1)\n            rand_list.append(all_i[selected_i])\n            del all_i[selected_i]\n        if test_index in rand_list:\n            rand_list.remove(test_index)\n            return rand_list\n\n        return rand_list[1:]\n    k = len(f_list)\n\n    train_f_num= int(ratio*10)\n    train_i_list = get_random_train_index(train_f_num, test_i,k)\n    print(train_i_list)\n    test_data = f_list[test_i]\n    train_data=f_list[train_i_list[0]]\n    for i in range(1,len(train_i_list)):\n        train_data =train_data.append(f_list[train_i_list[i]])\n    return test_data, train_data\n\ndef stratified_folders(df,k):\n    \"\"\"\n    return the  folder split into k by ratio of -1 and +1\n    \n    \"\"\"\n    neg, pos = split_df_by_label(df)\n\n    neg_folder_list= split_data_to_k_folders(neg, k=k)\n    pos_folder_list = split_data_to_k_folders(pos,k=k)\n\n\n    f_list = get_stratified_folder(neg_folder_list,pos_folder_list)\n#     test_data,train_data=  train_test_split(f_list,test_i, ratio)\n\n    print('There are {} folders and every folder has {} samples'.format(k, len(f_list[0])))\n    return f_list\n\n\n\n","9117f018":"# import numpy as np\n# def get_entropy(df, label):\n#     \"\"\"get the etropy of based on certain dataset(might be split by some node)\"\"\"\n#     p_p_1 = (df[label]==1).sum()\/len(df)\n#     p_n_1= (df[label]==-1).sum()\/len(df)\n#     a = np.array([p_p_1,p_n_1])\n\n#     b = np.log2([1 if p_p_1==0 else p_p_1, 1 if p_n_1==0 else p_n_1])\n    \n    \n\n#     rs = -np.dot(a.T, b)\n#     return -np.dot(a.T, b)\n    \n# def get_i_by_split(df,split_node_name):\n#     n = len(df)\n#     sub_partitions_list = df[split_node_name].unique()\n#     prob_list = []\n#     sub_entroies_list = []\n#     for name in sub_partitions_list:\n#         selected_rows = df[split_node_name]==name\n#         prob_list.append(selected_rows.sum()\/n)\n        \n#         sub_entroies_list.append(get_entropy(df[selected_rows], 'is_income_more_than_50K'))\n\n#     prob_list=np.array(prob_list)\n#     sub_entroies_list = np.array(sub_entroies_list)\n#     rs =np.dot(prob_list.T, sub_entroies_list)\n\n#     return rs\n    \n# def get_info_gain_by_split(node_name):\n#     a = get_entropy(sample,'is_income_more_than_50K')\n#     rs = a - get_i_by_split(sample, node_name) \n#     return rs if not np.isnan(rs) else 0\n# # get_info_gain_by_split('age')\n\n# sample = data.copy()\n# def sort_node_by_infor_gain(node_list):\n#     m = {}\n#     for node in node_list:\n#         m[node] = get_info_gain_by_split(node)\n#     sorted_by_value = sorted(m.items(), key=lambda kv: -kv[1])\n#     for item in sorted_by_value:\n#         print('GAIN({}) = {} '.format(item[0],str(item[1])))\n# a = list(col for col in sample.columns if col!='is_income_more_than_50K')\n# sort_node_by_infor_gain(a)\n\n\n\n\n\n","6c5b3148":"from numpy import *\n\ndef loadDataSet(data):\n    n =len(data[0])\n    dataArr = data[:,:n-1].tolist()\n    labelArr = data[:,-1].tolist()\n    return dataArr,labelArr\n    \n\ndef selectJrand(i,m): \n    j=i\n    while (j==i):\n        j=int(random.uniform(0,m))\n    return j\n\ndef clipAlpha(aj,H,L):  \n    if aj>H:\n        aj=H\n    if L>aj:\n        aj=L\n    return aj\n\ndef kernelTrans(X, A, kTup): \n    m,n = shape(X)\n    K = mat(zeros((m,1)))\n    if kTup[0]=='lin': \n        K = X.dot(A)\n    elif kTup[0]=='rbf': \n        for j in range(m):\n            deltaRow = X[j,:] - A\n            K[j] = deltaRow*deltaRow.T\n        K = exp(K\/(-1*kTup[1]**2)) \n    else:\n        raise NameError('Houston We Have a Problem -- That Kernel is not recognized')\n    return K\n\n\n\n\nclass optStruct:\n    def __init__(self,dataMatIn, classLabels, C, toler, kTup):  \n        self.X = dataMatIn  \n        self.labelMat = classLabels \n        self.C = C \n        self.tol = toler \n        self.m = shape(dataMatIn)[0]\n        self.alphas = mat(zeros((self.m,1)))\n        self.b = 0 \n        self.eCache = mat(zeros((self.m,2))) \n        self.K = mat(zeros((self.m,self.m))) \n        for i in range(self.m):\n            self.K[:,i] = kernelTrans(self.X, self.X[i,:], kTup)\n\n\ndef calcEk(oS, k):\n    fXk = float(multiply(oS.alphas,oS.labelMat).T*oS.K[:,k] + oS.b)\n    Ek = fXk - float(oS.labelMat[k])\n    return Ek\n\ndef selectJ(i, oS, Ei):\n    maxK = -1\n    maxDeltaE = 0\n    Ej = 0\n    oS.eCache[i] = [1,Ei]\n    validEcacheList = nonzero(oS.eCache[:,0].A)[0]  \n    if (len(validEcacheList)) > 1:\n        for k in validEcacheList:\n            if k == i:\n                continue\n            Ek = calcEk(oS, k)\n            deltaE = abs(Ei - Ek)\n            if (deltaE > maxDeltaE): \n                maxK = k\n                maxDeltaE = deltaE\n                Ej = Ek\n        return maxK, Ej\n    else:\n        j = selectJrand(i, oS.m)\n        Ej = calcEk(oS, j)\n    return j, Ej\n\n\ndef updateEk(oS, k): \n    Ek = calcEk(oS, k)\n    oS.eCache[k] = [1,Ek]\n\ndef innerL(i, oS):\n    Ei = calcEk(oS, i) \n    if ((oS.labelMat[i]*Ei < -oS.tol) and (oS.alphas[i] < oS.C)) or ((oS.labelMat[i]*Ei > oS.tol) and (oS.alphas[i] > 0)): #\u68c0\u9a8c\u8fd9\u884c\u6570\u636e\u662f\u5426\u7b26\u5408KKT\u6761\u4ef6 \u53c2\u8003\u300a\u7edf\u8ba1\u5b66\u4e60\u65b9\u6cd5\u300bp128\u516c\u5f0f7.111-113\n        j,Ej = selectJ(i, oS, Ei) \n        alphaIold = oS.alphas[i].copy()\n        alphaJold = oS.alphas[j].copy()\n        if (oS.labelMat[i] != oS.labelMat[j]): \n            L = max(0, oS.alphas[j] - oS.alphas[i])\n            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n        else:\n            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n        if L==H:\n            return 0\n        eta = 2.0 * oS.K[i,j] - oS.K[i,i] - oS.K[j,j]\n        if eta >= 0:\n            return 0\n        oS.alphas[j] -= oS.labelMat[j]*(Ei - Ej)\/eta \n        oS.alphas[j] = clipAlpha(oS.alphas[j],H,L) \n        updateEk(oS, j)\n        if (abs(oS.alphas[j] - alphaJold) < oS.tol): \n            return 0\n        oS.alphas[i] += oS.labelMat[j]*oS.labelMat[i]*(alphaJold - oS.alphas[j])#\u53c2\u8003\u300a\u7edf\u8ba1\u5b66\u4e60\u65b9\u6cd5\u300bp127\u516c\u5f0f7.109\n        updateEk(oS, i)\n        b1 = oS.b - Ei- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,i] - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[i,j]\n        b2 = oS.b - Ej- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,j]- oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[j,j]\n        if (0 < oS.alphas[i]<oS.C):\n            oS.b = b1\n        elif (0 < oS.alphas[j]<oS.C):\n            oS.b = b2\n        else:\n            oS.b = (b1 + b2)\/2.0\n        return 1\n    else:\n        return 0\n\n\ndef smoP(dataMatIn, classLabels, C, toler, maxIter,kTup):\n    oS = optStruct(mat(dataMatIn),mat(classLabels).transpose(),C,toler, kTup)\n    iter = 0\n    entireSet = True\n    alphaPairsChanged = 0\n    while (iter < maxIter) and ((alphaPairsChanged > 0) or (entireSet)):\n        alphaPairsChanged = 0\n        if entireSet:\n            for i in range(oS.m): \n                alphaPairsChanged += innerL(i,oS)\n            iter += 1\n        else:\n            nonBoundIs = nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]\n            for i in nonBoundIs: \n                alphaPairsChanged += innerL(i,oS)\n            iter += 1\n        if entireSet:\n            entireSet = False\n        elif (alphaPairsChanged == 0):\n            entireSet = True\n#         print(\"      iteration number: %d\" % iter)\n    return oS.b,oS.alphas\n\n\n\ndef learning(data_train,C=200, tol=0.0001,max_iter=1000, kTup =('lin', 0)):\n    dataArr,labelArr = loadDataSet(data_train) \n    b,alphas = smoP(dataArr, labelArr, C, tol, max_iter, kTup) \n    datMat=mat(dataArr)\n    labelMat = mat(labelArr).transpose()\n    svInd=nonzero(alphas)[0]  \n    sVs=datMat[svInd] \n    labelSV = labelMat[svInd] \n    return Classifier(alphas,b, sVs,labelSV,svInd,kTup)\n\nclass Classifier:\n    def __init__(self,alphas,b,sVs,labelSV,svInd,kTup):\n        self.alphas= alphas\n        self.b= b\n        self.sVs=sVs\n        self.labelSV =labelSV\n        self.svInd = svInd\n        self.kTup=kTup\n\n    def predict(self, test_data):\n        test_X=test_data[:,:len(test_data[0])-1]\n        test_y = test_data[:,-1]\n#         print('tetex in predictmethod',test_X)\n        \"\"\"must be the np.array type for both x and y\"\"\"\n        m,n = shape(test_X)\n#         print('------', test_y)\n        errorCount = 0\n        predict_y= []\n        for i in range(m):\n            kernelEval = kernelTrans(self.sVs,test_X[i,:],self.kTup) \n            predict=kernelEval.T * multiply(self.labelSV,self.alphas[self.svInd]) + self.b\n            predict_y.append(sign(predict))\n        return PredictRes(predict_y=predict_y, real_y=test_y)\n    \nclass PredictRes:\n    def __init__(self, predict_y, real_y):\n        predict_y=np.array(predict_y).reshape(1,-1)\n        boolean_index = predict_y==real_y\n        self.predict_y =predict_y\n        self.n = self.predict_y[0].size\n        self.real_y = real_y\n        self.number_pos = (real_y==1).sum()\n        self.number_neg = (real_y==-1).sum()\n        self.TP = (predict_y[boolean_index]==1).sum()\n        self.TN= (predict_y[boolean_index]==-1).sum()\n        self.FP =(predict_y[~boolean_index]==1).sum()\n        self.FN =(predict_y[~boolean_index]==-1).sum()\n        self.precision = self.TP \/ (self.TP+self.FP) if (self.TP+self.FP)!=0 else 0\n        self.recall = self.TP\/(self.TP+self.FN) if (self.TP+self.FN)!=0 else 0\n        self.total_accuracy = boolean_index.sum()\/self.n\n        self.f1_score = 2*self.recall*self.precision\/(self.precision+self.recall) if (self.precision+self.recall)!=0 else 0\n        \n    def print_perfance_details(self):\n        print('The test sample size is {} (cotain 70% +1, and 30% -1)'.format(self.n))\n        print(\"Recall   \\t\", self.recall)\n        print(\"Precision\\t\",  self.precision)\n        print(\"F1 Score \\t\",  self.f1_score)\n        print(\"Total Accuracy \\t\",  self.total_accuracy)\n\n        ","c4f0d3ef":"def sub_features(train, test, fl):\n    return train[fl], test[fl]\n\n\ndef helper(features, train_data, test_data):\n    sns.lmplot( x=features[0], y=features[1], data=train_data, fit_reg=False, hue='is_income_more_than_50K', legend=True)\n    train, test = sub_features(train_data, test_data,features)\n\n    return train, test\n\n\ndef c_v_test(folders):\n    \n    res= []\n    for i in range(1,len(folders)+1):\n        s ='Take Folder no.'+str(i)+' as test folder'\n        print(s)\n        train,test = split_data_train_test(i,part_f_list)\n#         train, test = helper(['age','education.num','is_income_more_than_50K'], train_data, test_data)\n        train=train.values\n        test = test.values\n\n        clf = learning(train,C=200, tol=0.0001,max_iter=20, kTup = ('rbf', 1))\n        res_temp = clf.predict(test)\n        res.append(res_temp)\n    \n    print('10 Cross Validation was ended')\n    return res\n\n        \nnorm_df  = get_norm_df(cleaned_data, 'is_income_more_than_50K')\nf_list= stratified_folders(norm_df,1400)\npart_f_list = f_list[10:20]\nprint('Testing size is {}'.format(len(part_f_list[0])))\nprint('Trainging size is {}'.format(len(part_f_list[0])*9))\n\nres = c_v_test(part_f_list)","31cb7a71":"def cal_avg_and_var(pre_res_list):\n    performan_detail = {'precisions':[],\n    'recalls':[],\n    'f1_scores':[],\n    'total_accuracies':[]\n    }\n    for pre_res in pre_res_list:\n        performan_detail['precisions'].append(pre_res.precision)\n        performan_detail['recalls'].append(pre_res.recall)\n        performan_detail['f1_scores'].append(pre_res.f1_score)\n        performan_detail['total_accuracies'].append(pre_res.total_accuracy)\n    def cal(d):\n        avg_performan = {}\n        for key in d:\n            avg_performan[key] = 'The avg( {} )= {}, var( {} )={}.'.format(key,np.average(d[key]) , key, np.var(d[key]))\n\n        return avg_performan\n    avg_performan=cal(performan_detail)\n    return performan_detail,avg_performan ","e731b803":"performan_detail,avg_performan = cal_avg_and_var(res)","78cf3cf7":"avg_performan","35d57024":"class Bagging:\n    def __init__(self,data_folders, test_data, n=15):\n        self.data_folders =data_folders\n        self.num_cls = n #n must be the odd number\n        self.clfs =[]\n        self.test_data=test_data\n        self.random_train_data_folders =[]\n    \n    def bagging_data(self):\n        #Get  10 folders in the all data folders as one trainning sample randomly\n        random_train_data_folders =[]\n        n=self.num_cls\n        for i in range(n):\n            select_no = np.random.randint(len(self.data_folders), size=n)\n            temp = self.data_folders[select_no[0]]\n            for i in range(1,len(select_no)):\n                temp.append(self.data_folders[select_no[i]])\n            random_train_data_folders.append(temp)\n        self.random_train_data_folders = random_train_data_folders\n        \n    def build_clfs(self, C=200, tol=0.0001,max_iter=20, kTup = ('rbf', 1)):\n        if len(self.random_train_data_folders)==0:\n            print('There are no data for trainning, please bagging data first')\n            return \n        clfs =[]\n        i = 1\n        print('Start Building All Classifiers')\n        print(' Trainning Size : ', len(self.random_train_data_folders[0]))\n        print(' Number of classifiers : ',self.num_cls)\n        for sub_train in self.random_train_data_folders:\n            print(\"\\t-Trainning clf no.{}\".format(i))\n            i+=1\n            clf = learning(sub_train.values,C, tol,max_iter, kTup)\n            clfs.append(clf)\n        print('All Classifiers were build successfully')\n        self.clfs = clfs\n\n    def predict_by_multi_clfs(self, test_data):\n        all_pre_res = []\n        real_y = None\n        for clf in self.clfs:\n            obj_res = clf.predict(test_data)\n            all_pre_res.append(obj_res.predict_y)\n            real_y = obj_res.real_y\n        all_pre_res =np.array(all_pre_res)\n        temp = np.sum(all_pre_res, 0)\n        final_res= []\n        for i in range(len(temp)):\n            final_res.append(sign(temp[i]))\n        predict_y = np.array(final_res)\n        return PredictRes(predict_y=predict_y, real_y=real_y)\n    \n        ","e71c43f5":"f_list= stratified_folders(norm_df,1000)\npart_f_list = f_list[20:40]\ntest_data = f_list[1]\nbagging = Bagging(part_f_list,test_data,n=11)","b132b85f":"bagging.bagging_data()\nbagging.build_clfs()\nres = bagging.predict_by_multi_clfs(test_data.values)","70f5c245":"\nres1 = bagging.predict_by_multi_clfs(f_list[25].values)","e12db10e":"\nres1.print_perfance_details()","0fd8ae7d":"res.predict_y","10c879df":"from numpy import *\n\ndef loadDataSet(data): #\u8bfb\u53d6\u6570\u636e\n    n =len(data[0])\n    dataArr = data[:,:n-1].tolist()\n    labelArr = data[:,-1].tolist()\n    return dataArr,labelArr\n    \n\ndef selectJrand(i,m): #\u57280-m\u4e2d\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u4e0d\u662fi\u7684\u6574\u6570\n    j=i\n    while (j==i):\n        j=int(random.uniform(0,m))\n    return j\n\ndef clipAlpha(aj,H,L):  #\u4fdd\u8bc1a\u5728L\u548cH\u8303\u56f4\u5185\uff08L <= a <= H\uff09\n    if aj>H:\n        aj=H\n    if L>aj:\n        aj=L\n    return aj\n\ndef kernelTrans(X, A, kTup): #\u6838\u51fd\u6570\uff0c\u8f93\u5165\u53c2\u6570,X:\u652f\u6301\u5411\u91cf\u7684\u7279\u5f81\u6811\uff1bA\uff1a\u67d0\u4e00\u884c\u7279\u5f81\u6570\u636e\uff1bkTup\uff1a('lin',k1)\u6838\u51fd\u6570\u7684\u7c7b\u578b\u548c\u53c2\u6570\n    m,n = shape(X)\n    K = mat(zeros((m,1)))\n    if kTup[0]=='lin': #\u7ebf\u6027\u51fd\u6570\n        K = X * A.T\n    elif kTup[0]=='rbf': # \u5f84\u5411\u57fa\u51fd\u6570(radial bias function)\n        for j in range(m):\n            deltaRow = X[j,:] - A\n            K[j] = deltaRow*deltaRow.T\n        K = exp(K\/(-1*kTup[1]**2)) #\u8fd4\u56de\u751f\u6210\u7684\u7ed3\u679c\n    else:\n        raise NameError('Houston We Have a Problem -- That Kernel is not recognized')\n    return K\n\n\n#\u5b9a\u4e49\u7c7b\uff0c\u65b9\u4fbf\u5b58\u50a8\u6570\u636e\nclass optStruct:\n    def __init__(self,dataMatIn, classLabels, C, toler, kTup):  # \u5b58\u50a8\u5404\u7c7b\u53c2\u6570\n        self.X = dataMatIn  #\u6570\u636e\u7279\u5f81\n        self.labelMat = classLabels #\u6570\u636e\u7c7b\u522b\n        self.C = C #\u8f6f\u95f4\u9694\u53c2\u6570C\uff0c\u53c2\u6570\u8d8a\u5927\uff0c\u975e\u7ebf\u6027\u62df\u5408\u80fd\u529b\u8d8a\u5f3a\n        self.tol = toler #\u505c\u6b62\u9600\u503c\n        self.m = shape(dataMatIn)[0] #\u6570\u636e\u884c\u6570\n        self.alphas = mat(zeros((self.m,1)))\n        self.b = 0 #\u521d\u59cb\u8bbe\u4e3a0\n        self.eCache = mat(zeros((self.m,2))) #\u7f13\u5b58\n        self.K = mat(zeros((self.m,self.m))) #\u6838\u51fd\u6570\u7684\u8ba1\u7b97\u7ed3\u679c\n        for i in range(self.m):\n            self.K[:,i] = kernelTrans(self.X, self.X[i,:], kTup)\n\n\ndef calcEk(oS, k): #\u8ba1\u7b97Ek\uff08\u53c2\u8003\u300a\u7edf\u8ba1\u5b66\u4e60\u65b9\u6cd5\u300bp127\u516c\u5f0f7.105\uff09\n    fXk = float(multiply(oS.alphas,oS.labelMat).T*oS.K[:,k] + oS.b)\n    Ek = fXk - float(oS.labelMat[k])\n    return Ek\n\n#\u968f\u673a\u9009\u53d6aj\uff0c\u5e76\u8fd4\u56de\u5176E\u503c\ndef selectJ(i, oS, Ei):\n    maxK = -1\n    maxDeltaE = 0\n    Ej = 0\n    oS.eCache[i] = [1,Ei]\n    validEcacheList = nonzero(oS.eCache[:,0].A)[0]  #\u8fd4\u56de\u77e9\u9635\u4e2d\u7684\u975e\u96f6\u4f4d\u7f6e\u7684\u884c\u6570\n    if (len(validEcacheList)) > 1:\n        for k in validEcacheList:\n            if k == i:\n                continue\n            Ek = calcEk(oS, k)\n            deltaE = abs(Ei - Ek)\n            if (deltaE > maxDeltaE): #\u8fd4\u56de\u6b65\u957f\u6700\u5927\u7684aj\n                maxK = k\n                maxDeltaE = deltaE\n                Ej = Ek\n        return maxK, Ej\n    else:\n        j = selectJrand(i, oS.m)\n        Ej = calcEk(oS, j)\n    return j, Ej\n\n\ndef updateEk(oS, k): #\u66f4\u65b0os\u6570\u636e\n    Ek = calcEk(oS, k)\n    oS.eCache[k] = [1,Ek]\n\n#\u9996\u5148\u68c0\u9a8cai\u662f\u5426\u6ee1\u8db3KKT\u6761\u4ef6\uff0c\u5982\u679c\u4e0d\u6ee1\u8db3\uff0c\u968f\u673a\u9009\u62e9aj\u8fdb\u884c\u4f18\u5316\uff0c\u66f4\u65b0ai,aj,b\u503c\ndef innerL(i, oS): #\u8f93\u5165\u53c2\u6570i\u548c\u6240\u6709\u53c2\u6570\u6570\u636e\n    Ei = calcEk(oS, i) #\u8ba1\u7b97E\u503c\n    if ((oS.labelMat[i]*Ei < -oS.tol) and (oS.alphas[i] < oS.C)) or ((oS.labelMat[i]*Ei > oS.tol) and (oS.alphas[i] > 0)): #\u68c0\u9a8c\u8fd9\u884c\u6570\u636e\u662f\u5426\u7b26\u5408KKT\u6761\u4ef6 \u53c2\u8003\u300a\u7edf\u8ba1\u5b66\u4e60\u65b9\u6cd5\u300bp128\u516c\u5f0f7.111-113\n        j,Ej = selectJ(i, oS, Ei) #\u968f\u673a\u9009\u53d6aj\uff0c\u5e76\u8fd4\u56de\u5176E\u503c\n        alphaIold = oS.alphas[i].copy()\n        alphaJold = oS.alphas[j].copy()\n        if (oS.labelMat[i] != oS.labelMat[j]): #\u4ee5\u4e0b\u4ee3\u7801\u7684\u516c\u5f0f\u53c2\u8003\u300a\u7edf\u8ba1\u5b66\u4e60\u65b9\u6cd5\u300bp126\n            L = max(0, oS.alphas[j] - oS.alphas[i])\n            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n        else:\n            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n        if L==H:\n#             print(\"L==H\")\n            return 0\n        eta = 2.0 * oS.K[i,j] - oS.K[i,i] - oS.K[j,j] #\u53c2\u8003\u300a\u7edf\u8ba1\u5b66\u4e60\u65b9\u6cd5\u300bp127\u516c\u5f0f7.107\n        if eta >= 0:\n#             print(\"eta>=0\")\n            return 0\n        oS.alphas[j] -= oS.labelMat[j]*(Ei - Ej)\/eta #\u53c2\u8003\u300a\u7edf\u8ba1\u5b66\u4e60\u65b9\u6cd5\u300bp127\u516c\u5f0f7.106\n        oS.alphas[j] = clipAlpha(oS.alphas[j],H,L) #\u53c2\u8003\u300a\u7edf\u8ba1\u5b66\u4e60\u65b9\u6cd5\u300bp127\u516c\u5f0f7.108\n        updateEk(oS, j)\n        if (abs(oS.alphas[j] - alphaJold) < oS.tol): #alpha\u53d8\u5316\u5927\u5c0f\u9600\u503c\uff08\u81ea\u5df1\u8bbe\u5b9a\uff09\n#             print(\"j not moving enough\")\n            return 0\n        oS.alphas[i] += oS.labelMat[j]*oS.labelMat[i]*(alphaJold - oS.alphas[j])#\u53c2\u8003\u300a\u7edf\u8ba1\u5b66\u4e60\u65b9\u6cd5\u300bp127\u516c\u5f0f7.109\n        updateEk(oS, i) #\u66f4\u65b0\u6570\u636e\n        #\u4ee5\u4e0b\u6c42\u89e3b\u7684\u8fc7\u7a0b\uff0c\u53c2\u8003\u300a\u7edf\u8ba1\u5b66\u4e60\u65b9\u6cd5\u300bp129\u516c\u5f0f7.114-7.116\n        b1 = oS.b - Ei- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,i] - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[i,j]\n        b2 = oS.b - Ej- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,j]- oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[j,j]\n        if (0 < oS.alphas[i]<oS.C):\n            oS.b = b1\n        elif (0 < oS.alphas[j]<oS.C):\n            oS.b = b2\n        else:\n            oS.b = (b1 + b2)\/2.0\n        return 1\n    else:\n        return 0\n\n\n#SMO\u51fd\u6570\uff0c\u7528\u4e8e\u5feb\u901f\u6c42\u89e3\u51faalpha\ndef smoP(dataMatIn, classLabels, C, toler, maxIter,kTup=('lin', 0)): #\u8f93\u5165\u53c2\u6570\uff1a\u6570\u636e\u7279\u5f81\uff0c\u6570\u636e\u7c7b\u522b\uff0c\u53c2\u6570C\uff0c\u9600\u503ctoler\uff0c\u6700\u5927\u8fed\u4ee3\u6b21\u6570\uff0c\u6838\u51fd\u6570\uff08\u9ed8\u8ba4\u7ebf\u6027\u6838\uff09\n    oS = optStruct(mat(dataMatIn),mat(classLabels).transpose(),C,toler, kTup)\n    iter = 0\n    entireSet = True\n    alphaPairsChanged = 0\n    while (iter < maxIter) and ((alphaPairsChanged > 0) or (entireSet)):\n        alphaPairsChanged = 0\n        if entireSet:\n            for i in range(oS.m): #\u904d\u5386\u6240\u6709\u6570\u636e\n                alphaPairsChanged += innerL(i,oS)\n#                 print(\"fullSet, iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged)) #\u663e\u793a\u7b2c\u591a\u5c11\u6b21\u8fed\u4ee3\uff0c\u90a3\u884c\u7279\u5f81\u6570\u636e\u4f7falpha\u53d1\u751f\u4e86\u6539\u53d8\uff0c\u8fd9\u6b21\u6539\u53d8\u4e86\u591a\u5c11\u6b21alpha\n            iter += 1\n        else:\n            nonBoundIs = nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]\n            for i in nonBoundIs: #\u904d\u5386\u975e\u8fb9\u754c\u7684\u6570\u636e\n                alphaPairsChanged += innerL(i,oS)\n#                 print(\"non-bound, iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged))\n            iter += 1\n        if entireSet:\n            entireSet = False\n        elif (alphaPairsChanged == 0):\n            entireSet = True\n        print(\"      iteration number: %d\" % iter)\n    return oS.b,oS.alphas\n\ndef testRbf(data_train,data_test,C=200, tol=0.0001,max_iter=1000, kTup = ('rbf', 1) ):\n    dataArr,labelArr = loadDataSet(data_train) #\u8bfb\u53d6\u8bad\u7ec3\u6570\u636e\n    b,alphas = smoP(dataArr, labelArr, C, tol, max_iter, kTup) #\u901a\u8fc7SMO\u7b97\u6cd5\u5f97\u5230b\u548calpha\n    datMat=mat(dataArr)\n    labelMat = mat(labelArr).transpose()\n    svInd=nonzero(alphas)[0]  #\u9009\u53d6\u4e0d\u4e3a0\u6570\u636e\u7684\u884c\u6570\uff08\u4e5f\u5c31\u662f\u652f\u6301\u5411\u91cf\uff09\n    sVs=datMat[svInd] #\u652f\u6301\u5411\u91cf\u7684\u7279\u5f81\u6570\u636e\n    labelSV = labelMat[svInd] #\u652f\u6301\u5411\u91cf\u7684\u7c7b\u522b\uff081\u6216-1\uff09\n#     print(\"there are %d Support Vectors\" % shape(sVs)[0]) #\u6253\u5370\u51fa\u5171\u6709\u591a\u5c11\u7684\u652f\u6301\u5411\u91cf\n    m,n = shape(datMat) #\u8bad\u7ec3\u6570\u636e\u7684\u884c\u5217\u6570\n    errorCount = 0\n    for i in range(m):\n        kernelEval = kernelTrans(sVs,datMat[i,:],kTup) #\u5c06\u652f\u6301\u5411\u91cf\u8f6c\u5316\u4e3a\u6838\u51fd\u6570\n        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b  #\u8fd9\u4e00\u884c\u7684\u9884\u6d4b\u7ed3\u679c\uff08\u4ee3\u7801\u6765\u6e90\u4e8e\u300a\u7edf\u8ba1\u5b66\u4e60\u65b9\u6cd5\u300bp133\u91cc\u9762\u6700\u540e\u7528\u4e8e\u9884\u6d4b\u7684\u516c\u5f0f\uff09\u6ce8\u610f\u6700\u540e\u786e\u5b9a\u7684\u5206\u79bb\u5e73\u9762\u53ea\u6709\u90a3\u4e9b\u652f\u6301\u5411\u91cf\u51b3\u5b9a\u3002\n        if sign(predict)!=sign(labelArr[i]): #sign\u51fd\u6570 -1 if x < 0, 0 if x==0, 1 if x > 0\n            errorCount += 1\n#     print(\"the training error rate is: %f\" % (float(errorCount)\/m)) #\u6253\u5370\u51fa\u9519\u8bef\u7387\n    train_err = float(errorCount)\/m\n    dataArr_test,labelArr_test = loadDataSet(data_test) #\u8bfb\u53d6\u6d4b\u8bd5\u6570\u636e\n    errorCount_test = 0\n    datMat_test=mat(dataArr_test)\n    labelMat = mat(labelArr_test).transpose()\n    m,n = shape(datMat_test)\n    for i in range(m): #\u5728\u6d4b\u8bd5\u6570\u636e\u4e0a\u68c0\u9a8c\u9519\u8bef\u7387\n        kernelEval = kernelTrans(sVs,datMat_test[i,:],kTup)\n        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b\n        if sign(predict)!=sign(labelArr_test[i]):\n            errorCount_test += 1\n#     print(\"the test error rate is: %f\" % (float(errorCount_test)\/m))\n    test_err = float(errorCount_test)\/m\n    return {'train_err':train_err, 'test_err':test_err}\n\n\n#\u4e3b\u7a0b\u5e8f\n\n\n","1634c017":"def eval_perf(all_error):\n    train_err = all_error[0]\n    test_err = all_error[1]\n    s1 ='avg(test_err) = {}, var(test_err) =  {}'.format(np.average(test_err), np.var(test_err))\n    s2 ='avg(train_err) = {}, var(train_err) =  {}'.format(np.average(train_err), np.var(train_err))\n    print(s1)\n    print(s2)","729a9483":"# age\tworkclass\tfnlwgt\teducation.num\tmarital.status\trelationship\tsex\thours.per.week\tcapital_profit\tis_income_more_than_50K\n\ndef sub_features(train, test, fl):\n    return train[fl], test[fl]\n\n\ndef helper(features, train_data, test_data):\n    sns.lmplot( x=features[0], y=features[1], data=train_data, fit_reg=False, hue='is_income_more_than_50K', legend=True)\n    train, test = sub_features(train_data, test_data,features)\n\n    return train, test\n\n\n        \nnorm_df  = get_norm_df(cleaned_data, 'is_income_more_than_50K')\n\nf_list= stratified_folders(norm_df,600)\npart_f_list = f_list[10:20]\nprint('test size is {}'.format(len(part_f_list[0])))\nprint('test size is {}'.format(len(part_f_list[0])*9))\n\n\ndef c_v_test(folders):\n    all_train_error= []\n    all_test_error= []\n    for i in range(1,len(folders)+1):\n        s ='Test folder no '+str(i)\n        print(s)\n        train,test = split_data_train_test(i,part_f_list)\n#         train, test = helper(['age','education.num','is_income_more_than_50K'], train_data, test_data)\n        train=train.values\n        test = test.values\n        error = testRbf(train,test,C=240, tol=0.0001,max_iter=30, kTup = ('rbf', 1))\n        all_train_error.append(error['train_err'])\n        all_test_error.append(error['test_err'])\n    return all_train_error, all_test_error\n\nall_error = c_v_test(part_f_list)\n","89f1e0eb":"eval_perf(all_error)","8a0b4f89":"\n\n# # test_data =test_data.sample(frac=1)\n# # train_data = train_data.sample(frac=1)\n# # sns.lmplot( x=\"age\", y=\"education.num\", data=test_data_age_and_fnlwgt, fit_reg=False, hue='is_income_more_than_50K', legend=True)\n\n\n\n\n# def split_by_label(data):\n#     \"\"\"\n#     dataset should be numpy format not dataframe\n#     \"\"\"\n#     positive = data[data[:,-1]==1]\n#     negative = data[data[:,-1]==-1]\n#     return positive, negative\n\n# positive, negative = split_by_label(train)\n\n\n# X=train[:,:train[0].size-1]\n\n\n# Y=train[:,-1]#Y\n# C=40\n# sigma=0.1\n# SVMClassifier=SMO(X,Y,C,0.01,5,sigma)\n# title = 'C={}, Sigma ={}'.format(C,sigma)\n# SVMClassifier.visualize(positive,negative,colors=['green', 'blue','black'], xlabel=['age','education.num'],title=title)","99f8a834":"# class CLASSIFIER:\n#     def __init__(self, w,b):\n#         self.w =w\n#         self.b =b\n#     def predit(self, test_X, test_y):\n#         print('test size is ',len(test_y))\n#         \"\"\"Return the accuracy\"\"\"\n#         temp =self.w.T*test_X\n#         temp=np.sum(temp,axis=1)\n#         res = temp+self.b\n#         for i in range(len(res)):\n#             if res[i]>0:\n#                 res[i]=1\n#             else:\n#                 res[i]=-1\n        \n#         return ((res==test_y).sum())\/len(test_y)\n\n\n\n\n    \n# w=  SVMClassifier.get_w()\n# b=SVMClassifier.b\n# classifier = CLASSIFIER(w,b)\n# X=test[:,:test[0].size-1]\n# y= test[:,-1]\n# acc = classifier.predit(X, y)","5bddaa44":"### Obervation from the Information Gain\nThe infomation gain of every split node is how as above. It can observe that features expcet sex and family condition do not contain so much information. Therefore, I will focus these two feature for the futher taining process.","aa58be89":"## Dataset preprocessing and interpretation\n### Clean Data","11002bd1":"### Stratified 10-Fold-Cross Validation","42b57637":"### Calculate Information Gain"}}