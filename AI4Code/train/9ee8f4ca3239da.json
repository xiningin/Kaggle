{"cell_type":{"3496a9a6":"code","9558810c":"code","0099d1b6":"code","8f4f1948":"code","26740763":"code","95757f9f":"code","192d0cdc":"code","9f3d5b51":"code","9eb4a03e":"code","1db5d840":"code","2369e162":"code","4dd93520":"markdown","7020b222":"markdown","25736228":"markdown","4ed96a9c":"markdown","0c2854f7":"markdown","a1caffdd":"markdown","11cb6e5e":"markdown","7a7f8520":"markdown"},"source":{"3496a9a6":"! ls -l \/kaggle\/input\/sartorius-cell-instance-segmentation\n! pip list | grep -E \"lightning|torch|icevision|Pillow\"","9558810c":"# ! pip install -q lightning-flash[image]\n# ! pip install -q 'https:\/\/github.com\/PyTorchLightning\/lightning-flash\/archive\/refs\/heads\/bugfix\/icevision_memory_leak.zip#egg=lightning-flash[image]'\n! pip install -q 'https:\/\/github.com\/gianscarpe\/lightning-flash\/archive\/refs\/heads\/instance_segmentation_papercut.zip#egg=lightning-flash[image]'\n! pip install -q \"icevision[all]>=0.11\" torchvision -U\n# ! pip install -q 'https:\/\/github.com\/Borda\/icevision\/archive\/refs\/heads\/try\/imageio.zip#egg=icevision[all]'\n! pip install -q pandas Pillow -U --force-reinstall\n! pip uninstall -q -y torchtext\n! pip list | grep -E \"lightning|torch|icevision|Pillow\"","0099d1b6":"! mkdir -p \/kaggle\/working\/dataset\/annotations\n! mkdir -p \/kaggle\/working\/dataset\/images\n! cp \/kaggle\/input\/sartorius-cell-instance-segmentation\/LIVECell_dataset_2021\/annotations\/LIVECell\/*.json \/kaggle\/working\/dataset\/annotations\/\n! mkdir \/kaggle\/working\/dataset\/images\/livecell_test_images\/\n! mkdir \/kaggle\/working\/dataset\/images\/livecell_train_val_images\/\n! cp \/kaggle\/input\/sartorius-cell-instance-segmentation\/LIVECell_dataset_2021\/images\/livecell_test_images\/*\/*.tif \/kaggle\/working\/dataset\/images\/livecell_test_images\/\n! cp \/kaggle\/input\/sartorius-cell-instance-segmentation\/LIVECell_dataset_2021\/images\/livecell_train_val_images\/*\/*.tif \/kaggle\/working\/dataset\/images\/livecell_train_val_images\/","8f4f1948":"%reload_ext autoreload\n%autoreload 2\n\nimport os\n\nPATH_PREDICT = \"\/kaggle\/input\/sartorius-cell-instance-segmentation\/test\"\nPATH_DATASET = \"\/kaggle\/input\/sartorius-cell-instance-segmentation\/LIVECell_dataset_2021\"\nLOCAL_DIR_DATASET = \"\/kaggle\/working\/dataset\"\nLOCAL_DIR_ANNOTATIONS = os.path.join(LOCAL_DIR_DATASET, \"annotations\")\nLOCAL_DIR_IMAGES_TRAIN = os.path.join(LOCAL_DIR_DATASET, \"images\", \"livecell_train_val_images\")\nLOCAL_DIR_IMAGES_TEST = os.path.join(LOCAL_DIR_DATASET, \"images\", \"livecell_test_images\")","26740763":"import glob\nimport cv2\nfrom tqdm.auto import tqdm\n\nls_images = glob.glob(f\"{LOCAL_DIR_IMAGES_TRAIN}\/*.tif\") + glob.glob(f\"{LOCAL_DIR_IMAGES_TEST}\/*.tif\")\n\nfor img in tqdm(ls_images):\n  cv2.imwrite(img.replace(\".tif\", \".png\"), cv2.imread(img))","95757f9f":"import os\nimport glob\nimport json\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nNB_ANNOTTAIONS_THR = 900\nannots = glob.glob(os.path.join(LOCAL_DIR_ANNOTATIONS, \"*.json\"))\nddirs = dict(train=LOCAL_DIR_IMAGES_TRAIN, val=LOCAL_DIR_IMAGES_TRAIN, test=LOCAL_DIR_IMAGES_TEST)\n\nfor annot in tqdm(sorted(annots)):\n    with open(annot) as fp:\n        data = json.load(fp)\n    if isinstance(data['annotations'], dict):\n        data['annotations'] = list(data['annotations'].values())\n        \n    for d in data['images']:\n        d['file_name'] = d['file_name'].replace(\".tif\", \".png\")\n        \n#     df_counts = pd.DataFrame(data['annotations']).groupby(['image_id']).size()\n#     too_large = df_counts[df_counts >= NB_ANNOTTAIONS_THR].index.to_list()\n#     df_counts.hist(bins=50, grid=True)\n#     data['annotations'] = [d for d in data['annotations'] if d['image_id'] not in too_large]\n\n#     fname, _ = os.path.splitext(os.path.basename(annot))\n#     img_dir = ddirs[fname.split(\"_\")[-1]]\n#     miss_ = [d for d in data['images'] if not os.path.isfile(os.path.join(img_dir, d['file_name']))]\n#     large_ = [d for d in data['images'] if d['id'] in too_large]\n#     data['images'] = [d for d in data['images'] if os.path.isfile(os.path.join(img_dir, d['file_name'])) and d['id'] not in too_large]\n#     print(f\"{len(data['images'])} (miss {len(miss_)}, large {len(large_)}) images and {len(data['annotations'])} annots in {os.path.basename(annot)}\")\n\n    with open(annot, 'w') as fp:\n        json.dump(data, fp)","192d0cdc":"from flash.image import InstanceSegmentationData\n\ndatamodule = InstanceSegmentationData.from_coco(\n    train_folder=LOCAL_DIR_IMAGES_TRAIN,\n    train_ann_file=os.path.join(LOCAL_DIR_ANNOTATIONS, \"livecell_coco_train.json\"),\n    val_folder=LOCAL_DIR_IMAGES_TRAIN,\n    val_ann_file=os.path.join(LOCAL_DIR_ANNOTATIONS, \"livecell_coco_val.json\"),\n    test_folder=LOCAL_DIR_IMAGES_TEST,\n    test_ann_file=os.path.join(LOCAL_DIR_ANNOTATIONS, \"livecell_coco_test.json\"),\n#     predict_folder=PATH_PREDICT,\n#     data_fetcher: Optional[BaseDataFetcher] = None,\n#     preprocess: Optional[Preprocess] = None,\n    batch_size=16,\n    num_workers=0,\n)","9f3d5b51":"from flash.image import InstanceSegmentation\n\nmodel = InstanceSegmentation(\n    head=\"mask_rcnn\",\n    backbone=\"resnet18_fpn\",\n    num_classes=datamodule.num_classes,\n)","9eb4a03e":"import torch\nimport flash\nfrom pytorch_lightning.loggers import CSVLogger\n\nlogger = CSVLogger(save_dir='logs\/')\ntrainer = flash.Trainer(\n    max_epochs=3,\n    gpus=torch.cuda.device_count(),\n    logger=logger,\n    progress_bar_refresh_rate=1,\n    precision=16,\n    benchmark=True,\n    accumulate_grad_batches=12,\n    #auto_lr_find=True,\n)\n\n# ==============================\n\n# trainer.tune(\n#     model, \n#     datamodule=datamodule, \n#     lr_find_kwargs=dict(min_lr=2e-5, max_lr=1e-2, num_training=25),\n#     # scale_batch_size_kwargs=dict(max_trials=5),\n# )\n# print(f\"Batch size: {datamodule.batch_size}\")\n# print(f\"Learning Rate: {model.learning_rate}\")\n\n# ==============================\n\ntrainer.finetune(model, datamodule=datamodule, strategy=\"freeze\")","1db5d840":"import pandas as pd\nimport seaborn as sns\nsns.set()\n\nmetrics = pd.read_csv(f'{trainer.logger.log_dir}\/metrics.csv')\ndisplay(metrics.head())\nmetrics.set_index(\"step\", inplace=True)\ndel metrics[\"epoch\"]\nsns.relplot(data=metrics, kind=\"line\")","2369e162":"import glob, os\nimport numpy as np\nimport matplotlib.pyplot as plt\n\npredict_imgs = sorted(glob.glob(os.path.join(PATH_PREDICT, \"*.png\")))\n\npredictions = model.predict(predict_imgs)\n\nfor p_img, pred in zip(predict_imgs, predictions):\n    print(p_img, pred.keys())\n    img = plt.imread(p_img)\n    mask = np.zeros(img.shape[:2])\n    for lb, m in enumerate(pred[\"masks\"]):\n        mask[m] = lb + 1\n    fig, axarr = plt.subplots(ncols=2)\n    axarr[0].imshow(img)\n    axarr[1].imshow(mask)","4dd93520":"### Fixing the Coco annotations","7020b222":"## 1. Create the DataModule","25736228":"# \ud83e\udda0 Cell Instance Segmentation with Lightning\u26a1Flash\n\n[Flash](https:\/\/lightning-flash.readthedocs.io\/en\/stable) makes complex AI recipes for over 15 tasks across 7 data domains accessible to all.\n\nIn a nutshell, Flash is the production grade research framework you always dreamed of but didn't have time to build.","4ed96a9c":"# Training with Flash Lightning\n\nSee the instance segm. docs: https:\/\/lightning-flash.readthedocs.io\/en\/stable\/reference\/instance_segmentation.html","0c2854f7":"## 3. Create the trainer and finetune the model","a1caffdd":"## 4. Detect objects in a few images!","11cb6e5e":"## Data preparation\n\nMoving the data to be Coco complient in zero folder depth...","7a7f8520":"## 2. Build the task"}}