{"cell_type":{"d9bf2057":"code","6f6ca6ec":"code","8655c00d":"code","88380933":"code","0768369d":"code","809db9c1":"code","9cefce2e":"code","94f20263":"code","0fe8eef5":"code","caee69fc":"code","441580d6":"code","acc97498":"code","1d0b5381":"code","03cdcab4":"code","e97a1a2c":"code","6c03ebed":"code","e2601bdb":"code","6386fc03":"code","95d47af3":"code","f03b717a":"code","1ae0f3a6":"code","d55da0d5":"code","b5d7cb0b":"code","c8287950":"code","0ffbcc25":"code","ffca2afa":"code","15d31ac4":"code","2af52792":"markdown","0e0b97e8":"markdown"},"source":{"d9bf2057":"!pip install '\/kaggle\/input\/pytorch-170-cuda-toolkit-110221\/torch-1.7.0+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '\/kaggle\/input\/pytorch-170-cuda-toolkit-110221\/torchvision-0.8.1+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '\/kaggle\/input\/pytorch-170-cuda-toolkit-110221\/torchaudio-0.7.0-cp37-cp37m-linux_x86_64.whl' --no-deps","6f6ca6ec":"!pip install '\/kaggle\/input\/mmdetectionv2140\/addict-2.4.0-py3-none-any.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/yapf-0.31.0-py2.py3-none-any.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/terminal-0.4.0-py3-none-any.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/terminaltables-3.1.0-py3-none-any.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/mmcv_full-1_3_8-cu110-torch1_7_0\/mmcv_full-1.3.8-cp37-cp37m-manylinux1_x86_64.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/pycocotools-2.0.2\/pycocotools-2.0.2' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/mmpycocotools-12.0.3\/mmpycocotools-12.0.3' --no-deps\n\n!rm -rf mmdetection\n\n!cp -r ..\/input\/edited-mmdetection \/kaggle\/working\/\n!mv \/kaggle\/working\/edited-mmdetection \/kaggle\/working\/mmdetection\n%cd \/kaggle\/working\/mmdetection\n!pip install -e .","8655c00d":"import cupy as cp\nfrom glob import glob\nimport os\nimport cv2\nfrom tqdm.notebook import tqdm\nimport pickle\nfrom itertools import groupby\nfrom pycocotools import mask as mutils\nfrom pycocotools import _mask as coco_mask\nimport matplotlib.pyplot as plt\nimport os\nimport base64\nimport typing as t\nimport zlib\nimport random\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport sklearn\nimport torchvision\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport cupy as cp\nimport gc\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport PIL\nimport json\nfrom PIL import Image, ImageEnhance\nimport albumentations as A\nimport mmdet\nimport mmcv\nfrom albumentations.pytorch import ToTensorV2\nimport seaborn as sns\nfrom pathlib import Path\nimport pycocotools\nfrom pycocotools import mask\nimport numpy.random\nimport random\nimport re\nimport shutil\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot, set_random_seed\nrandom.seed(0)","88380933":"conf_name = \"\/kaggle\/input\/mmdetectionv2140\/mmdetection-2.14.0\/configs\/cascade_rcnn\/cascade_mask_rcnn_x101_64x4d_fpn_20e_coco.py\"\nmodel_name = '\/kaggle\/input\/scs-mmdet-crcnn\/MMD_CRCNN_2.pth'\nROOT = '\/kaggle\/input\/sartorius-cell-instance-segmentation'\ntrain_or_test = 'test'\nTHR = 0.50\n# Test Data\ndf  = pd.DataFrame(glob(ROOT+f'\/{train_or_test}\/*'), columns=['image_path'])\ndf['id'] = df.image_path.map(lambda x: x.split('\/')[-1].split('.')[0])\ndf= df.sample(frac=20, replace=True)\ndisplay(df.head())","0768369d":"def encode_binary_mask(mask: np.ndarray) -> t.Text:\n    \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n    # check input mask --\n    if mask.dtype != np.bool:\n        raise ValueError(\n            \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n            mask.dtype)\n\n    mask = np.squeeze(mask)\n    if len(mask.shape) != 2:\n        raise ValueError(\n            \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n            mask.shape)\n\n    # convert input mask to expected COCO API input --\n    mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n    mask_to_encode = mask_to_encode.astype(np.uint8)\n    mask_to_encode = np.asfortranarray(mask_to_encode)\n\n    # RLE encode mask --\n    encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n\n    # compress and base64 encoding --\n    binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n    base64_str = base64.b64encode(binary_str)\n    return base64_str.decode()\n\ndef mask2rle(msk):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    msk    = cp.array(msk)\n    pixels = msk.flatten()\n    pad    = cp.array([0])\n    pixels = cp.concatenate([pad, pixels, pad])\n    runs   = cp.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(rle, shape=[520, 704]):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\ndef read_img(image_id, train_or_test='train', image_size=None):\n    filename = f'{ROOT}\/{train_or_test}\/{image_id}.png'\n    assert os.path.exists(filename), f'not found {filename}'\n    img = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n    if image_size is not None:\n        img = cv2.resize(img, (image_size, image_size))\n    if img.dtype == 'uint16':\n        img = (img\/256).astype('uint8')\n    return img\n\ndef load_RGBY_image(image_id, train_or_test='train', image_size=None):\n    img = read_img(image_id, train_or_test, image_size)\n    stacked_images = np.stack([img for _ in range(3)],axis=-1)\n    return stacked_images\n\ndef print_masked_img(image_id, mask):\n    img   = load_RGBY_image(image_id, train_or_test)[...,0]\n    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n    img2  = clahe.apply(img)\n    img3  = cv2.equalizeHist(img)\n    img   = np.stack([img, img2, img3],axis=-1)\n    \n    plt.figure(figsize=(15, 15))\n    plt.subplot(1, 3, 1)\n    plt.imshow(img)\n    plt.title('Image')\n    plt.axis('off')\n    \n    plt.subplot(1, 3, 2)\n    plt.imshow(mask,cmap='inferno')\n    plt.title('Mask')\n    plt.axis('off')\n    \n    plt.subplot(1, 3, 3)\n    plt.imshow(img)\n    plt.imshow(mask, alpha=0.4, cmap='inferno')\n    plt.title('Image + Mask')\n    plt.axis('off')\n    plt.tight_layout()\n    plt.show()","809db9c1":"def rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","9cefce2e":"def rle_encoding(x):\n    dots = np.where(x.flatten() == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return ' '.join(map(str, run_lengths))","94f20263":"IMG_WIDTH = 704\nIMG_HEIGHT = 520","0fe8eef5":"out_image_dir = f'mmdet_{train_or_test}\/'\n!mkdir -p {out_image_dir}\n\nannos = []\nfor idx in tqdm(range(len(df))):\n    image_id = df.iloc[idx]['id']\n    img = load_RGBY_image(image_id, train_or_test)\n    \n    cv2.imwrite(f'{out_image_dir}\/{image_id}.png', img)\n    ann = {\n        'filename': image_id+'.png',\n        'width': img.shape[1],\n        'height': img.shape[0],\n        'ann': {\n            'bboxes': None,\n            'labels': None,\n            'masks': None\n        }\n    }\n    annos.append(ann)\n    \nwith open(f'mmdet_tst.pkl', 'wb') as f:\n    pickle.dump(annos, f)","caee69fc":"def get_img_and_mask(img_path, annotation, width, height):\n    \"\"\" Capture the relevant image array as well as the image mask \"\"\"\n    img_mask = np.zeros((height, width), dtype=np.uint8)\n    for i, annot in enumerate(annotation): \n        img_mask = np.where(rle_decode(annot, (height, width))!=0, i, img_mask)\n    img = cv2.imread(img_path)[..., ::-1]\n    return img[..., 0], img_mask\n\ndef plot_img_and_mask(img, mask, invert_img=True, boost_contrast=True):\n    \"\"\" Function to take an image and the corresponding mask and plot\n    \n    Args:\n        img (np.arr): 1 channel np arr representing the image of cellular structures\n        mask (np.arr): 1 channel np arr representing the instance masks (incrementing by one)\n        invert_img (bool, optional): Whether or not to invert the base image\n        boost_contrast (bool, optional): Whether or not to boost contrast of the base image\n        \n    Returns:\n        None; Plots the two arrays and overlays them to create a merged image\n    \"\"\"\n    plt.figure(figsize=(20,10))\n    \n    plt.subplot(1,3,1)\n    _img = np.tile(np.expand_dims(img, axis=-1), 3)\n    \n    # Flip black-->white ... white-->black\n    if invert_img:\n        _img = _img.max()-_img\n        \n    if boost_contrast:\n        _img = np.asarray(ImageEnhance.Contrast(Image.fromarray(_img)).enhance(16))\n        \n    plt.imshow(_img)\n    plt.axis(False)\n    plt.title(\"Cell Image\", fontweight=\"bold\")\n    \n    plt.subplot(1,3,2)\n    _mask = np.zeros_like(_img)\n    _mask[..., 0] = mask\n    plt.imshow(mask, cmap='rainbow')\n    plt.axis(False)\n    plt.title(\"Instance Segmentation Mask\", fontweight=\"bold\")\n    \n    merged = cv2.addWeighted(_img, 0.75, np.clip(_mask, 0, 1)*255, 0.25, 0.0,)\n    plt.subplot(1,3,3)\n    plt.imshow(merged)\n    plt.axis(False)\n    plt.title(\"Cell Image w\/ Instance Segmentation Mask Overlay\", fontweight=\"bold\")\n    \n    plt.tight_layout()\n    plt.show()","441580d6":"def get_img_and_mask(img_path, annotation, width, height):\n    \"\"\" Capture the relevant image array as well as the image mask \"\"\"\n    img_mask = np.zeros((height, width), dtype=np.uint8)\n    for i, annot in enumerate(annotation): \n        img_mask = np.where(rle_decode(annot, (height, width))!=0, i, img_mask)\n    img = cv2.imread(img_path)[..., ::-1]\n    return img[..., 0], img_mask\n\ndef plot_img_and_mask(img, mask, invert_img=True, boost_contrast=True):\n    \"\"\" Function to take an image and the corresponding mask and plot\n    \n    Args:\n        img (np.arr): 1 channel np arr representing the image of cellular structures\n        mask (np.arr): 1 channel np arr representing the instance masks (incrementing by one)\n        invert_img (bool, optional): Whether or not to invert the base image\n        boost_contrast (bool, optional): Whether or not to boost contrast of the base image\n        \n    Returns:\n        None; Plots the two arrays and overlays them to create a merged image\n    \"\"\"\n    plt.figure(figsize=(20,10))\n    \n    plt.subplot(1,3,1)\n    _img = np.tile(np.expand_dims(img, axis=-1), 3)\n    \n    # Flip black-->white ... white-->black\n    if invert_img:\n        _img = _img.max()-_img\n        \n    if boost_contrast:\n        _img = np.asarray(ImageEnhance.Contrast(Image.fromarray(_img)).enhance(16))\n        \n    plt.imshow(_img)\n    plt.axis(False)\n    plt.title(\"Cell Image\", fontweight=\"bold\")\n    \n    plt.subplot(1,3,2)\n    _mask = np.zeros_like(_img)\n    _mask[..., 0] = mask\n    plt.imshow(mask, cmap='rainbow')\n    plt.axis(False)\n    plt.title(\"Instance Segmentation Mask\", fontweight=\"bold\")\n    \n    merged = cv2.addWeighted(_img, 0.75, np.clip(_mask, 0, 1)*255, 0.25, 0.0,)\n    plt.subplot(1,3,3)\n    plt.imshow(merged)\n    plt.axis(False)\n    plt.title(\"Cell Image w\/ Instance Segmentation Mask Overlay\", fontweight=\"bold\")\n    \n    plt.tight_layout()\n    plt.show()","acc97498":"def does_overlap(mask, other_masks):\n    for other_mask in other_masks:\n        if np.sum(np.logical_and(mask, other_mask)) > 0:\n            return True\n    return False\n\n\ndef remove_overlapping_pixels(mask, other_masks):\n    for other_mask in other_masks:\n        if np.sum(np.logical_and(mask, other_mask)) > 0:\n            print(\"Overlap detected\")\n            mask[np.logical_and(mask, other_mask)] = 0\n    return mask","1d0b5381":"def get_mask_from_result(result):\n    d = {True : 1, False : 0}\n    u,inv = np.unique(result,return_inverse = True)\n    mk = cp.array([d[x] for x in u])[inv].reshape(result.shape)\n#     print(mk.shape)\n    return mk","03cdcab4":"%%writefile labels.txt\nshsy5y\ncort\nastro","e97a1a2c":"from mmcv import Config\n\ncfg = Config.fromfile(conf_name)\ncfg.dataset_type = 'CustomDataset'\ncfg.classes = 'labels.txt'\n\nfor head in cfg.model.roi_head.bbox_head:\n    head.num_classes = 3\n\ncfg.model.roi_head.mask_head.num_classes=3\n\n\ncfg.test_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1280, 1280),\n        flip=True,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip', direction=['horizontal', 'vertical']),\n            dict(\n                type='Normalize',\n                mean=[123.68, 116.779, 103.939],\n                std=[58.393, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\n\ncfg.data.test.pipeline = cfg.test_pipeline\n\n\ncfg.model.test_cfg.rcnn.max_per_img = 300\ncfg.work_dir = 'model_output'\n\ncfg.data.samples_per_gpu = 1\ncfg.data.workers_per_gpu = 1\n\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = range(1)\ncfg.fp16 = dict(loss_scale=512.0)\nmeta = dict()\nmeta['config'] = cfg.pretty_text\n\nprint(f'Config:\\n{cfg.pretty_text}')","6c03ebed":"confidence_thresholds = {0: 0.25, 1: 0.55, 2: 0.35}","e2601bdb":"segms = []\nfiles = []","6386fc03":"model = init_detector(cfg, model_name)\nfor file in sorted(os.listdir('.\/mmdet_test')):\n    img = mmcv.imread('.\/mmdet_test\/' + file)\n    result = inference_detector(model, img)\n    show_result_pyplot(model, img, result)\n    previous_masks = []\n    for i, classe in enumerate(result[0]):\n        if classe.shape != (0, 5):\n            bbs = classe\n            sgs = result[1][i]\n            for bb, sg in zip(bbs,sgs):\n                box = bb[:4]\n                cnf = bb[4]\n                if cnf >= confidence_thresholds[i]:\n                    mask = get_mask_from_result(sg)\n                    mask = remove_overlapping_pixels(mask, previous_masks)\n                    previous_masks.append(mask)\n\n    for mk in previous_masks:\n            rle_mask = rle_encoding(mk)\n            segms.append(rle_mask)\n            files.append(str(file.split('.')[0]))","95d47af3":"indexes = []\nfor i, segm in enumerate(segms):\n    if segm == '':\n        indexes.append(i)","f03b717a":"for element in sorted(indexes, reverse = True):\n    del segms[element]\n    del files[element]","1ae0f3a6":"files = pd.Series(files, name='id')\npreds = pd.Series(segms, name='predicted')","d55da0d5":"preds","b5d7cb0b":"submission_df = pd.concat([files, preds], axis=1)","c8287950":"%cd ..","0ffbcc25":"submission_df.to_csv('\/kaggle\/working\/submission.csv', index=False)","ffca2afa":"submission_df","15d31ac4":"!rm -r .\/mmdetection","2af52792":"# Generate Data for **MMDet**","0e0b97e8":"# Meta Data"}}