{"cell_type":{"fda3c1f8":"code","25432cb4":"code","c04543d2":"code","26e9ba7d":"code","a1a990a6":"code","cfa0a29b":"code","e70aff5d":"code","836bd03b":"code","895f2747":"code","3f05e354":"code","8fa187f0":"code","200856ea":"code","354366e5":"code","79b09b2a":"markdown","a0fc9b22":"markdown","58dea298":"markdown","1cfadbdf":"markdown","24acbca3":"markdown","c496a464":"markdown","819850bd":"markdown"},"source":{"fda3c1f8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","25432cb4":"import time \nimport matplotlib.pyplot as plt\nimport seaborn as sns","c04543d2":"df = pd.read_csv('\/kaggle\/input\/lish-moa\/train_features.csv',index_col = 0)  \ndf","26e9ba7d":"y = pd.read_csv('\/kaggle\/input\/lish-moa\/train_targets_nonscored.csv',index_col = 0 )\ny","a1a990a6":"mode_which_part_to_process = 'full'\nif mode_which_part_to_process == 'full':\n    # consider only gene expression part \n    X = df[[c for c in df.columns if ('c-' in c) or ('g-' in c)]].values\nif mode_which_part_to_process == 'genes':\n    # consider only gene expression part \n    X = df[[c for c in df.columns if 'g-' in c]].values\nif mode_which_part_to_process == 'c':\n    # consider only gene expression part \n    X = df[[c for c in df.columns if 'c-' in c]].values\n\nX_original_save = X.copy()\nprint(X.shape)\n\ny_sum = y.sum(axis = 1)\ndf['y_sum']=y_sum\nprint(y_sum.shape)\ny_sum.value_counts()\n\n","cfa0a29b":"X.shape, df.shape, df.columns[-1]","e70aff5d":"from sklearn import manifold\nimport time \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.decomposition  import PCA\n\npca = PCA()\n# Preliminary reduce X to speed up:\nr = pca.fit_transform(X.copy())\ni_cut = 5000\nr = r[:i_cut,:50]\n\n\nn_neighbors = 10\nn_components = 2\nmethod = manifold.LocallyLinearEmbedding(n_neighbors=n_neighbors, n_components = n_components, \n                                         eigen_solver='auto', method='standard', random_state=1)# , n_jobs=-1)\n\nt0 = time.time()\nr = method.fit_transform(r)\nt1 = time.time()\nprint(\"%s: %.2g sec\" % ('LLE', t1 - t0))\n\nfig = plt.figure(figsize = (15,7) )\nf = 'cp_time'\nc_tmp = df[f].copy().apply(lambda x: str(x)+'_' )# convert to string to avoid sns.scatterplot to interpolate numeric values in legend\nsns.scatterplot(x=r[:,0], y=r[:,1] , hue =c_tmp[:i_cut]) #  df[f][:i_cut].apply(lambda x: str(x) )  )\n#plt.scatter(r[:,0], y=r[:,1] , c=df[f][:i_cut]  )\n#plt.legend()\nplt.title('Colored by '+f)\nplt.show()\n","836bd03b":"# Preliminary reduce X to speed up:\nr = pca.transform(X.copy())\n\nt0 = time.time()\nr = method.transform(r[:,:50])\nt1 = time.time()\nprint(\"%s: %.2g sec\" % ('LLE', t1 - t0))\n\nfig = plt.figure(figsize = (15,7) )\nf = 'cp_time'\nc_tmp = df[f].copy().apply(lambda x: str(x)+'_' )# convert to string to avoid sns.scatterplot to interpolate numeric values in legend\nsns.scatterplot(x=r[:,0], y=r[:,1] , hue =c_tmp) #  df[f][:i_cut].apply(lambda x: str(x) )  )\n#plt.scatter(r[:,0], y=r[:,1] , c=df[f][:i_cut]  )\n#plt.legend()\nplt.title('Colored by '+f)\nplt.show()\n","895f2747":"# Apply transform to full dataset \n\nr = pca.transform(X.copy() )\nr = r[:,:50]\n\nt0 = time.time()\nr = method.transform(r)\nprint(time.time()-t0,'seconds passed')\n\nfig = plt.figure(figsize = (15,7) )\nc = 0\nfor f in ['cp_dose', 'cp_type','cp_time', 'y_sum']:\n    c+=1; fig.add_subplot(1, 4 , c) \n    c_tmp = df[f].copy().apply(lambda x: str(x)+'_' )# convert to string to avoid sns.scatterplot to interpolate numeric values in legend\n    sns.scatterplot(x=r[:,0], y=r[:,1] , hue = c_tmp  )\n    plt.title('Colored by '+f)\nplt.show()\n","3f05e354":"df['cp_type'].value_counts()","8fa187f0":"# Apply transform to full dataset \n\nr = pca.transform(X.copy() )\nr = r[:,:50]\n\nt0 = time.time()\nr = method.transform(r)\nprint(time.time()-t0,'seconds passed')\n\nfig = plt.figure(figsize = (15,7) )\nc = 0\nfor f in ['cp_dose', 'cp_type','cp_time', 'y_sum']:\n    c+=1; fig.add_subplot(1, 4 , c) \n    m = df['cp_type'] == 'ctl_vehicle'\n    c_tmp = df[f].copy().apply(lambda x: str(x)+'_' )# convert to string to avoid sns.scatterplot to interpolate numeric values in legend\n    sns.scatterplot(x=r[:,0][m], y=r[:,1][m] , hue = c_tmp[m]  )\n    plt.title('Colored by '+f)\nplt.show()\n","200856ea":"# Apply transform to full dataset \n\nr = pca.transform(X.copy() )\nr = r[:,:50]\n\nt0 = time.time()\nr = method.transform(r)\nprint(time.time()-t0,'seconds passed')\n\nfig = plt.figure(figsize = (15,7) )\nc = 0\nfor f in ['cp_dose', 'cp_type','cp_time', 'y_sum']:\n    c+=1; fig.add_subplot(1, 4 , c) \n    m = df['y_sum'] > 0 # dfy_sum'] == 0 # cp_type'] == 'trt_cp' #'ctl_vehicle'\n    c_tmp = df[f].copy().apply(lambda x: str(x)+'_' )# convert to string to avoid sns.scatterplot to interpolate numeric values in legend\n    sns.scatterplot(x=r[:,0][m], y=r[:,1][m] , hue = c_tmp[m]  )\n    plt.title('Colored by '+f)\nplt.show()\n","354366e5":"# More things should be checked - please try","79b09b2a":"# Color by target sum and other - observe on control group and targets patterns - see details below","a0fc9b22":"# Load data","58dea298":"# Look at control group - almost all elements - in the leftest \"strip\"","1cfadbdf":"# Two right strips - MoA = ZERO, almost perfectly","24acbca3":"# LLE train LLE with ad hoc found params\n\n1) only first 5000 elements of train taken  (just taken  because otherwise it might run too long)\n\n2) first do pca to 50 dims (standard trick in similar tasks, otherwise it might run too long)\n\n3) random_state = 1 (for  other it also works, but not for all)","c496a464":"# Apply trained transforms to full dataset - again see - rightest \"strip\" is mostly by cp_time =24 (despite cp_time was deleted from X)\n","819850bd":"# What is about ?\n\nLLE - sklearn.manifold.LocallyLinearEmbedding - one out of many dimensional reduction algorithms used to visualize data ( tsne, umap - other popular tools).\n\n**Finding Briefly.** For MoA dataset LLE produce some visually clearly seen clusters - three \"strips\" of lines - which clearly correlate with targets and other features.\n\n**Challenge.** At the moment it looks mysterious - can you somehow explain it and possibly extract some benefits for prediction and more generally for  biological research.\n\n\n**Context** Doing dimensional reduction is stadard for such tasks, in particular some bioinformatitions sometimes prefer LLE because it sometimes produces something like \"trajectories\" (or line-segments). Sometimes they are meaningless - because LLE tends to produce strainght-line looking segments even when there is not such pattern in data, but not in that case. \n\n\n-1) Pay attention - LLE has been performed on data WITHOUT CP_TIME, CP_DOSE, CP_CTL - only genes and viabilities\n\n0) Before reading look at picture below - you will see three \"strips\"\n\n1) The righest strip contains only elements with cp_time = 24 (pay attention: despite cp_time was deleted) \n\n2) TWO right strips have all targets = 0 for almost all points (!) (targets were NOT in data) \n\n3) The control group - placed in the left \"strip\" almost perfectly  (pay attention: despite control group flag was deleted from the data)\n\nIt seem more things can be found. Please try.\n\n\nPS\n\nI have tried to use these LLE as features for my LogReg models - but they did not improve my scores.\n\nOther dimensional reduction plots can be found at my notebook:\nhttps:\/\/www.kaggle.com\/alexandervc\/moa-data-visualization-via-dimensional-reduct\n(LLE plot is also there, but now I decided to attract some attention to it, since it might be valueable not only for competition itself, but for further biological analysis). \n\nPSPS\n\nNice patterns are somewhat fragile - using slighly other settings for preprocessing - they might disapper.\nPreprocessing setting was found ad hoc. \n"}}