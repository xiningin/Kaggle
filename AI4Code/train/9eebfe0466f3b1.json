{"cell_type":{"4c21a55f":"code","765300a6":"code","993c08a3":"code","cd969ff4":"code","0df0f6e2":"code","6b79d99d":"code","ee9bd881":"code","2a1bb726":"code","41859bcb":"code","93abc3b2":"code","f318c4fe":"code","6d0cc517":"code","fa5e005c":"code","5892c499":"code","5bd6ea99":"code","2886fb98":"code","594e3641":"code","5d172a31":"code","86795988":"code","e2f554ef":"code","20be0015":"code","f00c94ec":"code","1979ebd8":"code","1f004878":"code","4f6349e6":"code","33fb1b44":"code","5ced0f84":"code","1edc5eb3":"code","a838ed39":"markdown","df9c19f7":"markdown","36d1eff7":"markdown","0b2450f9":"markdown","742cac48":"markdown","6f61c5b0":"markdown","9b389cf5":"markdown","d492478e":"markdown","4bdd82ee":"markdown","898f802a":"markdown","ba898ca5":"markdown","95bbb57b":"markdown","cad5588c":"markdown","738878e5":"markdown","2fc03951":"markdown","3ede3dc3":"markdown","6e342a7a":"markdown","db808b71":"markdown"},"source":{"4c21a55f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n\n!pip install tensorflow==2.0.0-rc1\nimport tensorflow as tf\nfrom tensorflow import keras\n\n\n\nprint(tf.__version__)\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","765300a6":"imdb = keras.datasets.imdb \n\n(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000) ","993c08a3":"print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))","cd969ff4":"print(train_data[0])","0df0f6e2":"len(train_data[0]), len(train_data[1]) ","6b79d99d":"word_index = imdb.get_word_index()","ee9bd881":"word_index","2a1bb726":"# The first indices are reserved\nword_index = {k:(v+3) for k,v in word_index.items()}\nword_index[\"<PAD>\"] = 0         # PAD words  int = 0   \nword_index[\"<START>\"] = 1       # the start of text  =  int =1 \nword_index[\"<UNK>\"] = 2         # unknown words  int =2 \nword_index[\"<UNUSED>\"] = 3\n\nreverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n\ndef decode_review(text):\n    return ' '.join([reverse_word_index.get(i, '?') for i in text])","41859bcb":"decode_review(train_data[0])","93abc3b2":"train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n                                                        value=word_index[\"<PAD>\"],\n                                                        padding='post',\n                                                        maxlen=256)\n\ntest_data = keras.preprocessing.sequence.pad_sequences(test_data,\n                                                       value=word_index[\"<PAD>\"],\n                                                       padding='post',\n                                                       maxlen=256)","f318c4fe":"len(train_data[0]), len(train_data[1])","6d0cc517":"print(train_data[0])","fa5e005c":"# input shape is the vocabulary count used for the movie reviews (10,000 words)\nvocab_size = 10000\n\nmodel = keras.Sequential()\nmodel.add(keras.layers.Embedding(vocab_size, 16))\nmodel.add(keras.layers.GlobalAveragePooling1D())\nmodel.add(keras.layers.Dense(16, activation=tf.nn.relu))\nmodel.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n\nmodel.summary()","5892c499":"model.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['acc','binary_crossentropy'])","5bd6ea99":"x_val = train_data[:10000]\npartial_x_train = train_data[10000:]\n\ny_val = train_labels[:10000]\npartial_y_train = train_labels[10000:]","2886fb98":"\nhistory = model.fit(partial_x_train,\n                    partial_y_train,\n                    epochs=40,\n                    batch_size=512,\n                    validation_data=(x_val, y_val),\n                    verbose=2)","594e3641":"results = model.evaluate(test_data, test_labels)\n\n","5d172a31":"print(results)","86795988":"history_dict = history.history\nhistory_dict.keys()","e2f554ef":"import matplotlib.pyplot as plt\n\nacc = history_dict['acc']\nval_acc = history_dict['val_acc']\nloss = history_dict['loss']\nval_loss = history_dict['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, 'bo', label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","20be0015":"plt.clf()   # clear figure\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()","f00c94ec":"model_Estop = keras.Sequential()\nmodel_Estop.add(keras.layers.Embedding(vocab_size, 16))\nmodel_Estop.add(keras.layers.GlobalAveragePooling1D())\nmodel_Estop.add(keras.layers.Dense(16, activation=tf.nn.relu))\nmodel_Estop.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n\nmodel_Estop.summary()","1979ebd8":"model_Estop.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['acc','binary_crossentropy'])","1f004878":"callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3) ## activate early stopping\nhistory_Estop = model_Estop.fit(partial_x_train,\n                    partial_y_train,\n                    epochs=40,\n                    batch_size=512,callbacks=[callback],                   ## activate the call back                  \n                    validation_data=(x_val, y_val),\n                    verbose=2)","4f6349e6":"results_Estop = model_Estop.evaluate(test_data, test_labels)\n","33fb1b44":"print(results_Estop)","5ced0f84":"history_Estop = history_Estop.history\nhistory_Estop.keys()","1edc5eb3":"plt.clf()   # clear figure\nacc = history_Estop['acc']\nval_acc = history_Estop['val_acc']\nloss = history_Estop['loss']\nval_loss = history_Estop['val_loss']\n\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()","a838ed39":"# Step 5: Compile ","df9c19f7":"# Step 4: Build the Model","36d1eff7":"# Step 1 : Download and Split data set ","0b2450f9":"# Step 7: Evaluate","742cac48":"##   the model stopped its training when validation accuracy became constant at 30 epochs","6f61c5b0":"### using get_word_index() we can see dictinary from word(key) and its value(integer) ","9b389cf5":"### As you can see below the review is sequence of words have been converted to sequences of integers. ","d492478e":"# Basic Text Classification \nIn this notebook we will use the tensorflow , keras to classify text data set from IMDB reviews.\nwe will use machine learning on reviews  to determine if it's negative or positive ? (Binary Classification).\n","4bdd82ee":"# Step 6: Fit ","898f802a":"## You can see word embedding in text classification in this notebook:\nhttps:\/\/www.kaggle.com\/salahuddinemr\/text-classification-with-word-embedding\n","ba898ca5":" ##  from accuracy plot you can see that the training accuracy stay increase with epochs but the validation accuracy become constant, This is what we call the Overfitting","95bbb57b":"# Early Stopping: \n## to avoid overfitting caused by epochs increasing we use the Early Stopping to stop  learning model at overfitting area","cad5588c":"- for more information about text classification \nhttps:\/\/monkeylearn.com\/text-classification\/","738878e5":"- you can see that the model stoped at 30 epochs ","2fc03951":"# Step 3: Prepare the Data","3ede3dc3":"# Step 2: Explore Data ","6e342a7a":"## At fit model we activate the early stopping in callback  \n### patience : No of epochs after overfitting ","db808b71":"The **IMDB** dataset that contains the text of **50,000** movie reviews from the Internet Movie Database. \n\nThese are split into **25,000** reviews for training and **25,000** reviews for testing. The training and testing sets are balanced, meaning they contain an equal number of positive and negative reviews.\nThe **IMDB** dataset comes **packaged with TensorFlow**. **It has already been preprocessed** such that the reviews (**sequences of words**) have been converted to sequences of integers, where each integer represents a specific word in a dictionary."}}