{"cell_type":{"18e7e6c4":"code","f6dc4c3e":"code","a9166d26":"code","d97710fa":"code","3c8d3fea":"code","5a5b5632":"code","cc2e976d":"code","e9cfa4ad":"code","de78eeb3":"code","43ddd056":"code","45e6beae":"code","bb878f69":"code","9cc511f3":"code","832113df":"code","7d740cfc":"code","306d0a72":"code","33b6a4ad":"code","76e66330":"code","0c19b8ec":"code","8cc4203b":"code","b377617d":"code","87f12190":"code","bcfb7303":"code","8b4cebd6":"code","a2632737":"code","0abbb4ff":"code","ab78e0ad":"code","b527f54d":"code","af6bb7c2":"code","2839a0d4":"code","524258ff":"code","64bd6d0f":"code","e1f4c711":"code","94454e41":"code","77c20855":"code","b5f92476":"code","80e2b7b6":"code","70715fe9":"code","72f2a422":"code","bfd627fc":"code","8666b3cb":"code","dc9ed9b7":"code","2eeeca19":"code","3b1d0e8a":"code","9cd2a422":"code","f33d9182":"code","dcdf9fa4":"code","57c4f4ed":"code","0e174b62":"code","a7eb31d4":"code","53877094":"code","7693c772":"code","e1305e5e":"code","87b71c6b":"code","6ae9a576":"code","8a7ed988":"code","e93984fa":"markdown","4d5f7ea8":"markdown","b8d440b9":"markdown","d874cbc9":"markdown","c2c968ad":"markdown","4e5f69ba":"markdown","6f9eb46d":"markdown","727f1796":"markdown","3e7fa89e":"markdown","959f410b":"markdown","cc9df24c":"markdown","6c8b7bbc":"markdown","62702c8b":"markdown","92e60309":"markdown","1da72bf9":"markdown","cfc0b027":"markdown","a0f4548a":"markdown","f959bd7c":"markdown"},"source":{"18e7e6c4":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\nfrom collections import Counter\nfrom IPython.core.display import display, HTML\nsns.set_style('darkgrid')","f6dc4c3e":"dataset = pd.read_csv('..\/input\/winequality-red.csv')\ndataset.head()","a9166d26":"dataset.isnull().sum()","d97710fa":"bins = (2, 6.5, 8)\nlabels = ['bad', 'good']\ndataset['quality'] = pd.cut(x = dataset['quality'], bins = bins, labels = labels)","3c8d3fea":"dataset['quality'].value_counts()","5a5b5632":"from sklearn.preprocessing import LabelEncoder\nlabelencoder_y = LabelEncoder()\ndataset['quality'] = labelencoder_y.fit_transform(dataset['quality'])","cc2e976d":"dataset.head()","e9cfa4ad":"corr = dataset.corr()\n#Plot figsize\nfig, ax = plt.subplots(figsize=(10, 8))\n#Generate Heat Map, allow annotations and place floats in map\nsns.heatmap(corr, cmap='coolwarm', annot=True, fmt=\".2f\")\n#Apply xticks\nplt.xticks(range(len(corr.columns)), corr.columns);\n#Apply yticks\nplt.yticks(range(len(corr.columns)), corr.columns)\n#show plot\nplt.show()","de78eeb3":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['fixed acidity'], ax = axes[0])\naxes[0].set_xlabel('Fixed Acidity', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'quality', y = 'fixed acidity', data = dataset, hue = 'quality',ax = axes[1])\naxes[1].set_xlabel('Quality', fontsize=14)\naxes[1].set_ylabel('Fixed Acidity', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","43ddd056":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['volatile acidity'], ax = axes[0])\naxes[0].set_xlabel('Volatile Acidity', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'quality', y = 'volatile acidity', data = dataset, hue = 'quality',ax = axes[1])\naxes[1].set_xlabel('Quality', fontsize=14)\naxes[1].set_ylabel('Volatile Acidity', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","45e6beae":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['citric acid'], ax = axes[0])\naxes[0].set_xlabel('Citric Acid', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.boxenplot(x = 'quality', y = 'citric acid', data = dataset, hue = 'quality',ax = axes[1])\naxes[1].set_xlabel('Quality', fontsize=14)\naxes[1].set_ylabel('Citric Acid', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","bb878f69":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['residual sugar'], ax = axes[0])\naxes[0].set_xlabel('Residual Sugar', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'quality', y = 'residual sugar', data = dataset, hue = 'quality',ax = axes[1])\naxes[1].set_xlabel('Quality', fontsize=14)\naxes[1].set_ylabel('Residual Sugar', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","9cc511f3":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['chlorides'], ax = axes[0])\naxes[0].set_xlabel('Chlorides', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'quality', y = 'chlorides', data = dataset, hue = 'quality',ax = axes[1])\naxes[1].set_xlabel('Quality', fontsize=14)\naxes[1].set_ylabel('Chlorides', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","832113df":"f, axes = plt.subplots(2,2,figsize=(14,8))\n\nsns.distplot(dataset['free sulfur dioxide'], ax = axes[0,0])\naxes[0,0].set_xlabel('Free Sulfur Dioxide', fontsize=14)\naxes[0,0].set_ylabel('Count', fontsize=14)\naxes[0,0].yaxis.tick_left()\n\nsns.boxenplot(x = 'quality', y = 'free sulfur dioxide', data = dataset, hue = 'quality',ax = axes[0,1])\naxes[0,1].set_xlabel('Quality', fontsize=14)\naxes[0,1].set_ylabel('Free Sulfur Dioxide', fontsize=14)\naxes[0,1].yaxis.set_label_position(\"right\")\naxes[0,1].yaxis.tick_right()\n\nsns.distplot(dataset['total sulfur dioxide'], ax = axes[1,0])\naxes[1,0].set_xlabel('Total Sulfur Dioxide', fontsize=14)\naxes[1,0].set_ylabel('Count', fontsize=14)\naxes[1,0].yaxis.tick_left()\n\nsns.boxenplot(x = 'quality', y = 'total sulfur dioxide', data = dataset, hue = 'quality',ax = axes[1,1])\naxes[1,1].set_xlabel('Quality', fontsize=14)\naxes[1,1].set_ylabel('Total Sulfur Dioxide', fontsize=14)\naxes[1,1].yaxis.set_label_position(\"right\")\naxes[1,1].yaxis.tick_right()\n\nplt.show()","7d740cfc":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['density'], ax = axes[0])\naxes[0].set_xlabel('Density', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'quality', y = 'density', data = dataset, hue = 'quality',ax = axes[1])\naxes[1].set_xlabel('Quality', fontsize=14)\naxes[1].set_ylabel('Density', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","306d0a72":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['pH'], ax = axes[0])\naxes[0].set_xlabel('pH', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'quality', y = 'pH', data = dataset, hue = 'quality',ax = axes[1])\naxes[1].set_xlabel('Quality', fontsize=14)\naxes[1].set_ylabel('pH', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","33b6a4ad":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['sulphates'], ax = axes[0])\naxes[0].set_xlabel('Sulphates', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'quality', y = 'sulphates', data = dataset, hue = 'quality',ax = axes[1])\naxes[1].set_xlabel('Quality', fontsize=14)\naxes[1].set_ylabel('Sulphates', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","76e66330":"f, axes = plt.subplots(1,2,figsize=(14,4))\n\nsns.distplot(dataset['alcohol'], ax = axes[0])\naxes[0].set_xlabel('Alcohol', fontsize=14)\naxes[0].set_ylabel('Count', fontsize=14)\naxes[0].yaxis.tick_left()\n\nsns.violinplot(x = 'quality', y = 'alcohol', data = dataset, hue = 'quality',ax = axes[1])\naxes[1].set_xlabel('Quality', fontsize=14)\naxes[1].set_ylabel('Alcohol', fontsize=14)\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\n\nplt.show()","0c19b8ec":"dataset['quality'].value_counts()","8cc4203b":"X = dataset.drop('quality', axis = 1).values\ny = dataset['quality'].values.reshape(-1,1)","b377617d":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","87f12190":"print(\"Shape of X_train: \",X_train.shape)\nprint(\"Shape of X_test: \", X_test.shape)\nprint(\"Shape of y_train: \",y_train.shape)\nprint(\"Shape of y_test\",y_test.shape)","bcfb7303":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train_scaled = sc.fit_transform(X_train)\nX_test_scaled = sc.transform(X_test)","8b4cebd6":"# Fitting Logistic Regression to the Training set\nfrom sklearn.linear_model import LogisticRegression\nclassifier_lr = LogisticRegression(C=1, fit_intercept=True, max_iter=1000, penalty = 'l2', solver='liblinear')\nclassifier_lr.fit(X_train_scaled, y_train.ravel())","a2632737":"# Predicting Cross Validation Score\ncv_lr = cross_val_score(estimator = classifier_lr, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_lr.mean())\n\ny_pred_lr_train = classifier_lr.predict(X_train_scaled)\naccuracy_lr_train = accuracy_score(y_train, y_pred_lr_train)\nprint(\"Training set: \", accuracy_lr_train)\n\ny_pred_lr_test = classifier_lr.predict(X_test_scaled)\naccuracy_lr_test = accuracy_score(y_test, y_pred_lr_test)\nprint(\"Test set: \", accuracy_lr_test)","0abbb4ff":"confusion_matrix(y_test, y_pred_lr_test)","ab78e0ad":"tp_lr = confusion_matrix(y_test, y_pred_lr_test)[0,0]\nfp_lr = confusion_matrix(y_test, y_pred_lr_test)[0,1]\ntn_lr = confusion_matrix(y_test, y_pred_lr_test)[1,1]\nfn_lr = confusion_matrix(y_test, y_pred_lr_test)[1,0]","b527f54d":"# Fitting classifier to the Training set\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier_knn = KNeighborsClassifier(leaf_size = 1, metric = 'minkowski', n_neighbors = 32, weights = 'distance')\nclassifier_knn.fit(X_train_scaled, y_train.ravel())","af6bb7c2":"# Predicting Cross Validation Score\ncv_knn = cross_val_score(estimator = classifier_knn, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_knn.mean())\n\ny_pred_knn_train = classifier_knn.predict(X_train_scaled)\naccuracy_knn_train = accuracy_score(y_train, y_pred_knn_train)\nprint(\"Training set: \", accuracy_knn_train)\n\ny_pred_knn_test = classifier_knn.predict(X_test_scaled)\naccuracy_knn_test = accuracy_score(y_test, y_pred_knn_test)\nprint(\"Test set: \", accuracy_knn_test)","2839a0d4":"confusion_matrix(y_test, y_pred_knn_test)","524258ff":"tp_knn = confusion_matrix(y_test, y_pred_knn_test)[0,0]\nfp_knn = confusion_matrix(y_test, y_pred_knn_test)[0,1]\ntn_knn = confusion_matrix(y_test, y_pred_knn_test)[1,1]\nfn_knn = confusion_matrix(y_test, y_pred_knn_test)[1,0]","64bd6d0f":"# Fitting classifier to the Training set\nfrom sklearn.svm import SVC\nclassifier_svm_linear = SVC(kernel = 'linear')\nclassifier_svm_linear.fit(X_train_scaled, y_train.ravel())","e1f4c711":"# Predicting Cross Validation Score\ncv_svm_linear = cross_val_score(estimator = classifier_svm_linear, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_svm_linear.mean())\n\ny_pred_svm_linear_train = classifier_svm_linear.predict(X_train_scaled)\naccuracy_svm_linear_train = accuracy_score(y_train, y_pred_svm_linear_train)\nprint(\"Training set: \", accuracy_svm_linear_train)\n\ny_pred_svm_linear_test = classifier_svm_linear.predict(X_test_scaled)\naccuracy_svm_linear_test = accuracy_score(y_test, y_pred_svm_linear_test)\nprint(\"Test set: \", accuracy_svm_linear_test)","94454e41":"confusion_matrix(y_test, y_pred_svm_linear_test)","77c20855":"tp_svm_linear = confusion_matrix(y_test, y_pred_svm_linear_test)[0,0]\nfp_svm_linear = confusion_matrix(y_test, y_pred_svm_linear_test)[0,1]\ntn_svm_linear = confusion_matrix(y_test, y_pred_svm_linear_test)[1,1]\nfn_svm_linear = confusion_matrix(y_test, y_pred_svm_linear_test)[1,0]","b5f92476":"# Fitting classifier to the Training set\nfrom sklearn.svm import SVC\nclassifier_svm_kernel = SVC(kernel = 'rbf', C = 10, tol = 0.001, gamma = 'scale')\nclassifier_svm_kernel.fit(X_train_scaled, y_train.ravel())","80e2b7b6":"# Predicting Cross Validation Score\ncv_svm_kernel = cross_val_score(estimator = classifier_svm_kernel, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_svm_kernel.mean())\n\ny_pred_svm_kernel_train = classifier_svm_kernel.predict(X_train_scaled)\naccuracy_svm_kernel_train = accuracy_score(y_train, y_pred_svm_kernel_train)\nprint(\"Training set: \", accuracy_svm_kernel_train)\n\ny_pred_svm_kernel_test = classifier_svm_kernel.predict(X_test_scaled)\naccuracy_svm_kernel_test = accuracy_score(y_test, y_pred_svm_kernel_test)\nprint(\"Test set: \", accuracy_svm_kernel_test)","70715fe9":"confusion_matrix(y_test, y_pred_svm_kernel_test)","72f2a422":"tp_svm_kernel = confusion_matrix(y_test, y_pred_svm_kernel_test)[0,0]\nfp_svm_kernel = confusion_matrix(y_test, y_pred_svm_kernel_test)[0,1]\ntn_svm_kernel = confusion_matrix(y_test, y_pred_svm_kernel_test)[1,1]\nfn_svm_kernel = confusion_matrix(y_test, y_pred_svm_kernel_test)[1,0]","bfd627fc":"# Fitting classifier to the Training set\nfrom sklearn.naive_bayes import GaussianNB\nclassifier_nb = GaussianNB()\nclassifier_nb.fit(X_train_scaled, y_train.ravel())","8666b3cb":"# Predicting Cross Validation Score\ncv_nb = cross_val_score(estimator = classifier_nb, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_nb.mean())\n\ny_pred_nb_train = classifier_nb.predict(X_train_scaled)\naccuracy_nb_train = accuracy_score(y_train, y_pred_nb_train)\nprint(\"Training set: \", accuracy_nb_train)\n\ny_pred_nb_test = classifier_nb.predict(X_test_scaled)\naccuracy_nb_test = accuracy_score(y_test, y_pred_nb_test)\nprint(\"Test set: \", accuracy_nb_test)","dc9ed9b7":"confusion_matrix(y_test, y_pred_nb_test)","2eeeca19":"tp_nb = confusion_matrix(y_test, y_pred_nb_test)[0,0]\nfp_nb = confusion_matrix(y_test, y_pred_nb_test)[0,1]\ntn_nb = confusion_matrix(y_test, y_pred_nb_test)[1,1]\nfn_nb = confusion_matrix(y_test, y_pred_nb_test)[1,0]","3b1d0e8a":"# Fitting classifier to the Training set\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier_dt = DecisionTreeClassifier(criterion = 'gini', max_features=6, max_leaf_nodes=400, random_state = 33)\nclassifier_dt.fit(X_train_scaled, y_train.ravel())","9cd2a422":"# Predicting Cross Validation Score\ncv_dt = cross_val_score(estimator = classifier_dt, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_dt.mean())\n\ny_pred_dt_train = classifier_dt.predict(X_train_scaled)\naccuracy_dt_train = accuracy_score(y_train, y_pred_dt_train)\nprint(\"Training set: \", accuracy_dt_train)\n\ny_pred_dt_test = classifier_dt.predict(X_test_scaled)\naccuracy_dt_test = accuracy_score(y_test, y_pred_dt_test)\nprint(\"Test set: \", accuracy_dt_test)","f33d9182":"confusion_matrix(y_test, y_pred_dt_test)","dcdf9fa4":"tp_dt = confusion_matrix(y_test, y_pred_dt_test)[0,0]\nfp_dt = confusion_matrix(y_test, y_pred_dt_test)[0,1]\ntn_dt = confusion_matrix(y_test, y_pred_dt_test)[1,1]\nfn_dt = confusion_matrix(y_test, y_pred_dt_test)[1,0]","57c4f4ed":"# Fitting Random Forest Classification to the Training set\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier_rf = RandomForestClassifier(criterion = 'entropy', max_features = 4, n_estimators = 800, random_state=33)\nclassifier_rf.fit(X_train_scaled, y_train.ravel())","0e174b62":"# Predicting Cross Validation Score\ncv_rf = cross_val_score(estimator = classifier_rf, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_rf.mean())\n\ny_pred_rf_train = classifier_rf.predict(X_train_scaled)\naccuracy_rf_train = accuracy_score(y_train, y_pred_rf_train)\nprint(\"Training set: \", accuracy_rf_train)\n\ny_pred_rf_test = classifier_rf.predict(X_test_scaled)\naccuracy_rf_test = accuracy_score(y_test, y_pred_rf_test)\nprint(\"Test set: \", accuracy_rf_test)","a7eb31d4":"confusion_matrix(y_test, y_pred_rf_test)","53877094":"tp_rf = confusion_matrix(y_test, y_pred_rf_test)[0,0]\nfp_rf = confusion_matrix(y_test, y_pred_rf_test)[0,1]\ntn_rf = confusion_matrix(y_test, y_pred_rf_test)[1,1]\nfn_rf = confusion_matrix(y_test, y_pred_rf_test)[1,0]","7693c772":"models = [('Logistic Regression', tp_lr, fp_lr, tn_lr, fn_lr, accuracy_lr_train, accuracy_lr_test, cv_lr.mean()),\n          ('K-Nearest Neighbors (KNN)', tp_knn, fp_knn, tn_knn, fn_knn, accuracy_knn_train, accuracy_knn_test, cv_knn.mean()),\n          ('SVM (Linear)', tp_svm_linear, fp_svm_linear, tn_svm_linear, fn_svm_linear, accuracy_svm_linear_train, accuracy_svm_linear_test, cv_svm_linear.mean()),\n          ('SVM (Kernel)', tp_svm_kernel, fp_svm_kernel, tn_svm_kernel, fn_svm_kernel, accuracy_svm_kernel_train, accuracy_svm_kernel_test, cv_svm_kernel.mean()),\n          ('Naive Bayes', tp_nb, fp_nb, tn_nb, fn_nb, accuracy_nb_train, accuracy_nb_test, cv_nb.mean()),\n          ('Decision Tree Classification', tp_dt, fp_dt, tn_dt, fn_dt, accuracy_dt_train, accuracy_dt_test, cv_dt.mean()),\n          ('Random Forest Tree Classification', tp_rf, fp_rf, tn_rf, fn_rf, accuracy_rf_train, accuracy_rf_test, cv_rf.mean())\n         ]","e1305e5e":"predict = pd.DataFrame(data = models, columns=['Model', 'True Positive', 'False Positive', 'True Negative',\n                                               'False Negative', 'Accuracy(training)', 'Accuracy(test)',\n                                               'Cross-Validation'])\npredict","87b71c6b":"f, axe = plt.subplots(1,1, figsize=(18,6))\n\npredict.sort_values(by=['Cross-Validation'], ascending=False, inplace=True)\n\nsns.barplot(x='Cross-Validation', y='Model', data = predict, ax = axe)\n#axes[0].set(xlabel='Region', ylabel='Charges')\naxe.set_xlabel('Cross-Validaton Score', size=16)\naxe.set_ylabel('Model')\naxe.set_xlim(0,1.0)\naxe.set_xticks(np.arange(0, 1.1, 0.1))\nplt.show()","6ae9a576":"f, axes = plt.subplots(2,1, figsize=(14,10))\n\npredict.sort_values(by=['Accuracy(training)'], ascending=False, inplace=True)\n\nsns.barplot(x='Accuracy(training)', y='Model', data = predict, palette='Blues_d', ax = axes[0])\n#axes[0].set(xlabel='Region', ylabel='Charges')\naxes[0].set_xlabel('Accuracy (Training)', size=16)\naxes[0].set_ylabel('Model')\naxes[0].set_xlim(0,1.0)\naxes[0].set_xticks(np.arange(0, 1.1, 0.1))\n\npredict.sort_values(by=['Accuracy(test)'], ascending=False, inplace=True)\n\nsns.barplot(x='Accuracy(test)', y='Model', data = predict, palette='Reds_d', ax = axes[1])\n#axes[0].set(xlabel='Region', ylabel='Charges')\naxes[1].set_xlabel('Accuracy (Test)', size=16)\naxes[1].set_ylabel('Model')\naxes[1].set_xlim(0,1.0)\naxes[1].set_xticks(np.arange(0, 1.1, 0.1))\n\nplt.show()","8a7ed988":"predict.sort_values(by=(['Accuracy(test)']), ascending=True, inplace=True)\n\nf, axe = plt.subplots(1,1, figsize=(24,8))\nsns.barplot(x = predict['Model'], y=predict['False Positive'] + predict['False Negative'], ax = axe)\naxe.set_xlabel('Model', size=20)\naxe.set_ylabel('False Observations', size=20)\n\nplt.show()","e93984fa":"### <span id=\"8\"><\/span> ** Support Vector Machine (SVM - Kernel) **","4d5f7ea8":"## <span id=\"4\"><\/span> ** 4. Classification Models **","b8d440b9":"In this kernel, I have built 7 classification models using Red Wine Quality Dataset. These are logistic, k-nn, svm(linear), svm(kernel), naive bayes, decision tree and random forest classification. Then measured and visualized the performance of the models. Please make a comment and let me know how to improve model performance, visualization or something in this kernel. This will also help me on my future analysis.\n\n<b><font color=\"red\">Don't forget to <\/font><\/b> <b><font color=\"green\">UPVOTE <\/font><\/b> if you liked this kernel, thank you. \ud83d\ude42\ud83d\udc4d","d874cbc9":"## <span id=\"12\"><\/span> ** 6. Measuring The Error **","c2c968ad":"### <span id=\"9\"><\/span> ** Naive Bayes **","4e5f69ba":"<hr\/>\n[**Tolgahan Cepel**](https:\/\/www.kaggle.com\/tolgahancepel)\n<hr\/>\n<font color=green>\n1. [Overview](#1)\n1. [Importing Libraries and Reading the Dataset](#2)\n1. [Data Visualization and Preprocessing](#3)\n1. [Classification Models](#4) \n    * [Logistic Regression](#5) \n    * [K-Nearest Neighbors(K-NN)](#6)\n    * [Support Vector Machine (SVM - Linear)](#7)\n    * [Support Vector Machine (SVM - Kernel)](#8)\n    * [Naive Bayes](#9) \n    * [Decision Tree Classification](#10) \n    * [Random Forest Classification](#11) \n1. [Measuring the Error](#12)\n    * [Visualizing Models Performance](#13) \n1. [Conclusion](#14)\n<hr\/>","6f9eb46d":"### <span id=\"6\"><\/span> ** K-Nearest Neighbors (K-NN) **","727f1796":"### <span id=\"11\"><\/span> ** Random Forest Classification **","3e7fa89e":"## <span id=\"1\"><\/span> ** 1. Overview **","959f410b":"Not bad! I mean the result :)","cc9df24c":"### <span id=\"10\"><\/span> ** Decision Tree Classification **","6c8b7bbc":"## <span id=\"2\"><\/span> ** 2. Importing Libraries and Reading the Dataset **","62702c8b":"## <span id=\"3\"><\/span> ** 3. Data Visualization and Preprocessing **","92e60309":"Input Variables:\n- **fixed acidity: ** most acids involved with wine or fixed or nonvolatile\n- **volatile acidity: ** the amount of acetic acid in wine\n- **citric acid: ** found in small quantities, citric acid can add 'freshness' and flavor to wines \n- **residual sugar: ** the amount of sugar remaining after fermentation stops\n- **chlorides: ** the amount of salt in the wine\n- **free sulfur dioxide: ** the free form of SO2 exists in equilibrium between molecular SO2 (as a dissolved gas) and bisulfite ion\n- **total sulfur dioxide: ** amount of free and bound forms of S02\n- **density: ** the density of water is close to that of water depending on the percent alcohol and sugar content\n- **pH: ** describes how acidic or basic a wine is on a scale from 0 (very acidic) to 14 (very basic)\n- **sulphates: ** a wine additive which can contribute to sulfur dioxide gas (S02) levels \n- **alcohol: ** the percent alcohol content of the wine<br>\n\nOutput Variable:\n- **quality: ** output variable (based on sensory data, score between 0 and 10)","1da72bf9":"## <span id=\"14\"><\/span> ** 7. Conclusion **","cfc0b027":"### <span id=\"13\"><\/span> ** Visualizing Models Performance **","a0f4548a":"### <span id=\"7\"><\/span> ** Support Vector Machine (SVM - Linear) **","f959bd7c":"### <span id=\"5\"><\/span> ** Logistic Regression **"}}