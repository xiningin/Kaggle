{"cell_type":{"3c972948":"code","a03f69a2":"code","39476629":"code","bda0821d":"code","ce1f9faf":"code","2998b1bb":"code","dd234847":"code","11df26b1":"code","a76449ee":"code","349e8a64":"code","339219c5":"code","3230b8af":"code","668cdc8b":"markdown","568f84ca":"markdown","03ea722a":"markdown","637287ec":"markdown","443da846":"markdown","e64a0404":"markdown"},"source":{"3c972948":"import pandas as pd\nimport numpy as np\nfrom textblob import TextBlob\n\nimport nltk\nfrom nltk import pos_tag\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import LancasterStemmer, WordNetLemmatizer\nimport re, string, unicodedata\n#import inflect\n\nimport spacy\n#nltk.download('stopwords')\n\nimport nltk.data\n\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.style.use('ggplot')\n#from __future__ import unicode_literals\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","a03f69a2":"Amazon_Meta_Data = pd.read_csv('..\/input\/amazon-reviews-unlocked-mobile-phones\/Amazon_Unlocked_Mobile.csv',nrows=50000, encoding='utf-8')\n\n#------- Counting words in reviews ---------\nword_counts = []\nfor review in Amazon_Meta_Data['Reviews']:\n    count=0\n    for word in str(review).split():\n        count +=1\n    word_counts.append(count)\nAmazon_Meta_Data['words_counts'] = word_counts\n\n# Discarding rows having less then 5 words of review.\nAmazon_Meta_Data=Amazon_Meta_Data.loc[Amazon_Meta_Data['words_counts'] >=5]\n\nAmazon_Meta_Data.head()\n#Amazon_Meta_Data.dtypes","39476629":"def remove_non_ascii(words):\n    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n    new_words = []\n    for word in words:\n        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n        new_words.append(new_word)\n    return new_words\n\ndef to_lowercase(words):\n    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n    new_words = []\n    for word in words:\n        new_word = word.lower()\n        new_words.append(new_word)\n    return new_words\n\ndef remove_punctuation(words):\n    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n    new_words = []\n    for word in words:\n        new_word = re.sub(r'[^\\w\\s]', '', word)\n        if new_word != '':\n            new_words.append(new_word)\n    return new_words\n\ndef replace_numbers(words):\n    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n    p = inflect.engine()\n    new_words = []\n    for word in words:\n        if word.isdigit():\n            new_word = p.number_to_words(word)\n            new_words.append(new_word)\n        else:\n            new_words.append(word)\n    return new_words\n\ndef remove_stopwords(words):\n    \"\"\"Remove stop words from list of tokenized words\"\"\"\n    new_words = []\n    for word in words:\n        if word not in stopwords.words('english'):\n            new_words.append(word)\n    return new_words\n\ndef stem_words(words):\n    \"\"\"Stem words in list of tokenized words\"\"\"\n    stemmer = LancasterStemmer()\n    stems = []\n    for word in words:\n        stem = stemmer.stem(word)\n        stems.append(stem)\n    return stems\n\ndef lemmatize_verbs(words):\n    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n    lemmatizer = WordNetLemmatizer()\n    lemmas = []\n    for word in words:\n        lemma = lemmatizer.lemmatize(word, pos='v')\n        lemmas.append(lemma)\n    return lemmas\n\ndef normalize(words):\n    words = remove_non_ascii(words)\n    words = to_lowercase(words)\n    words = remove_punctuation(words)\n    #words = replace_numbers(words)\n    words = remove_stopwords(words)\n    return words\n\n#Steemming and Lemmatization\ndef stem_and_lemmatize(words):\n    stems = stem_words(words)\n    lemmas = lemmatize_verbs(words)\n    return stems, lemmas\n\n#stems, lemmas = stem_and_lemmatize(words)\n#print('Stemmed:\\n', stems)\n#print('\\nLemmatized:\\n', lemmas)\n\n\n# ---------------   Cleaning   ------------------\ndef clean_text(text):\n    wording = nltk.word_tokenize(text)\n    words = normalize(wording)\n    string_text = ' '.join(words)\n    return string_text\n\n#----------------------  extract Sentences  -------------------------    \ndef sentances(text):\n    sent_detector = nltk.data.load('tokenizers\/punkt\/english.pickle')\n    return sent_detector.tokenize(text.strip())\n\n\n# ---------------   Sentiment   ------------------\ndef get_text_sentiment(text):\n    # create TextBlob object of passed text \n    analysis = TextBlob(clean_text(text)) \n    # set sentiment \n    if analysis.sentiment.polarity > 0: \n        return 'positive'\n    elif analysis.sentiment.polarity == 0: \n        return 'neutral'\n    else: \n        return 'negative'    \n    \n#---------------------- TextBlob Feature Extractions -----------------\n#Function to extract features from text\ndef textBlob_feature_extraction(text): \n        blob = TextBlob(text)\n        return blob.noun_phrases","bda0821d":"sentences = []\nsentiment_sent =[]\nproduct_name =[]\nfor products,reviews in zip(Amazon_Meta_Data[\"Product Name\"], Amazon_Meta_Data[\"Reviews\"]): \n    for sent in sentances(reviews):\n        sentiment_sent.append(get_text_sentiment(sent))\n        sentences.append(sent)\n        product_name.append(products)\n\nall_products_dataset = pd.DataFrame()\nall_products_dataset[\"products\"] = product_name\nall_products_dataset[\"reviews_sentences\"] =  sentences\nall_products_dataset[\"sentiment\"] = sentiment_sent\n\n#Removing Neural sentences\nall_products_dataset = all_products_dataset.loc[(all_products_dataset['sentiment'] != 'neutral')]\n\n# Text Cleaning of sentences\ncleaned_reviews =[]\nfor reviews in all_products_dataset[\"reviews_sentences\"]:\n    cleaned_reviews.append(clean_text(reviews))\n    \n#inserting Cleaned reviews sentences to our dataset\nall_products_dataset.insert(2, 'cleaned_reviews_sentences ', cleaned_reviews)\n\n#Extracting Features From Reviews Sentences\nfeatures = []\nfor reviews in cleaned_reviews:\n    features.append(textBlob_feature_extraction(reviews))\n\nall_products_dataset['texblob_features_extraction']=features","ce1f9faf":"prod_features_counts = {}\nfor prod,feature_list, in zip(all_products_dataset['products'],all_products_dataset['texblob_features_extraction']):\n    for feature in feature_list:\n        if prod in prod_features_counts:\n            if feature in prod_features_counts[prod]:\n                prod_features_counts[prod][feature] += 1\n            else:\n                prod_features_counts[prod][feature] = 1 \n        else:\n            prod_features_counts[prod]={}\n\n#Extracting feature count form feartures\ndist_products =[]\ndist_feature_count= []\nfor key, value in prod_features_counts.items() :\n    dist_products.append(key)\n    dist_feature_count.append(value)\n    \n#----------------- Features Counts Dataset ------------------\nproducts_features_details = pd.DataFrame()\nproducts_features_details['products'] = dist_products\nproducts_features_details['feature with count'] = dist_feature_count\nproducts_features_details.head(10)\n","2998b1bb":"positive_products_dataset = all_products_dataset.loc[(all_products_dataset['sentiment'] == 'positive')]\n\npositive_features_counts = {}\nfor prod,feature_list, in zip(positive_products_dataset['products'],positive_products_dataset['texblob_features_extraction']):\n    for feature in feature_list:\n        if prod in positive_features_counts:\n            if feature in positive_features_counts[prod]:\n                positive_features_counts[prod][feature] += 1\n            else:\n                positive_features_counts[prod][feature] = 1 \n        else:\n            positive_features_counts[prod]={}\n\n#Extracting feature count form feartures\ndist_products =[]\ndist_feature_count= []\nfor key, value in positive_features_counts.items() :\n    dist_products.append(key)\n    dist_feature_count.append(value)\n    \n#----------------- Features Counts Dataset ------------------\npositive_features_details = pd.DataFrame()\npositive_features_details['products'] = dist_products\npositive_features_details['feature with count'] = dist_feature_count\npositive_features_details.head(10)\n","dd234847":"negative_products_dataset = all_products_dataset.loc[(all_products_dataset['sentiment'] == 'negative')]\n\nnegative_features_counts = {}\nfor prod,feature_list, in zip(negative_products_dataset['products'],negative_products_dataset['texblob_features_extraction']):\n    for feature in feature_list:\n        if prod in negative_features_counts:\n            if feature in negative_features_counts[prod]:\n                negative_features_counts[prod][feature] += 1\n            else:\n                negative_features_counts[prod][feature] = 1 \n        else:\n            negative_features_counts[prod]={}\n            \n#Extracting feature count form feartures\ndist_products =[]\ndist_feature_count= []\nfor key, value in negative_features_counts.items() :\n    dist_products.append(key)\n    dist_feature_count.append(value)\n    \n#----------------- Features Counts Dataset ------------------\nnegative_features_details = pd.DataFrame()\nnegative_features_details['products'] = dist_products\nnegative_features_details['feature with count'] = dist_feature_count\nnegative_features_details.head(10)","11df26b1":"#Removing Rows having null features\n#all_products_dataset = all_products_dataset.loc[(all_products_dataset.astype(str)['texblob_features_extraction'] != '[]')]\n#all_products_dataset","a76449ee":"#user_specification = input(\"Search Here\")\nuser_specification = 'good phone with good battery life and affordable price '\nuser_specification_sentiment = get_text_sentiment(user_specification)\nuser_specification_features = textBlob_feature_extraction(user_specification)\nfor feature in user_specification_features:\n    print(feature)\n    \n    \n#Assiging weights to products with max matching \nprod_weight = {}\nif(user_specification_sentiment == 'positive'):\n    for prod in positive_features_counts:\n        for feature in user_specification_features:\n            if prod in prod_weight:\n                if feature in positive_features_counts[prod]:\n                    prod_weight[prod] = prod_weight[prod]+ positive_features_counts[prod][feature]                    \n            else:\n                if feature in positive_features_counts[prod]:\n                    prod_weight[prod] = positive_features_counts[prod][feature]\n\n\ndist_feature =[]\ndist_feature_count= []                    \nfor key, value in prod_weight.items() :\n    dist_feature.append(key)\n    dist_feature_count.append(value)\n    \nrank_products = pd.DataFrame()\nrank_products['product'] =dist_feature\nrank_products['weight'] =dist_feature_count\nrank_products= rank_products.sort_values(by ='weight' , ascending=False)\nrank_products             ","349e8a64":"#user_specification = input(\"Search Here\")\nuser_specification = 'good battery life and affordable price and fast processing'\nuser_specification_sentiment = get_text_sentiment(user_specification)\nuser_specification_features = textBlob_feature_extraction(user_specification)\nfor feature in user_specification_features:\n    print(feature)\n    \n    \n#Assiging weights to products with max matching \nprod_weight = {}\nif(user_specification_sentiment == 'positive'):\n    for prod in positive_features_counts:\n        for feature in user_specification_features:\n            if prod in prod_weight:\n                if feature in positive_features_counts[prod]:\n                    prod_weight[prod] = prod_weight[prod]+ positive_features_counts[prod][feature]                    \n            else:\n                if feature in positive_features_counts[prod]:\n                    prod_weight[prod] = positive_features_counts[prod][feature]\n\n\ndist_feature =[]\ndist_feature_count= []                    \nfor key, value in prod_weight.items() :\n    dist_feature.append(key)\n    dist_feature_count.append(value)\n    \nrank_products = pd.DataFrame()\nrank_products['product'] =dist_feature\nrank_products['weight'] =dist_feature_count\nrank_products= rank_products.sort_values(by ='weight' , ascending=False)\nrank_products             ","339219c5":"#user_specification = input(\"Search Here\")\nuser_specification = 'I need a phone with good price and good camera result '\nuser_specification_sentiment = get_text_sentiment(user_specification)\nuser_specification_features = textBlob_feature_extraction(user_specification)\nfor feature in user_specification_features:\n    print(feature)\n    \n    \n#Assiging weights to products with max matching \nprod_weight = {}\nif(user_specification_sentiment == 'positive'):\n    for prod in positive_features_counts:\n        for feature in user_specification_features:\n            if prod in prod_weight:\n                if feature in positive_features_counts[prod]:\n                    prod_weight[prod] = prod_weight[prod]+ positive_features_counts[prod][feature]                    \n            else:\n                if feature in positive_features_counts[prod]:\n                    prod_weight[prod] = positive_features_counts[prod][feature]\n\n\ndist_feature =[]\ndist_feature_count= []                    \nfor key, value in prod_weight.items() :\n    dist_feature.append(key)\n    dist_feature_count.append(value)\n    \nrank_products = pd.DataFrame()\nrank_products['product'] =dist_feature\nrank_products['weight'] =dist_feature_count\nrank_products= rank_products.sort_values(by ='weight' , ascending=False)\nrank_products             ","3230b8af":"user_specification = input(\"Search Here\")\n#user_specification = 'I need a phone with good price and good camera result '\nuser_specification_sentiment = get_text_sentiment(user_specification)\nuser_specification_features = textBlob_feature_extraction(user_specification)\nfor feature in user_specification_features:\n    print(feature)\n    \n    \n#Assiging weights to products with max matching \nprod_weight = {}\nif(user_specification_sentiment == 'positive'):\n    for prod in positive_features_counts:\n        for feature in user_specification_features:\n            if prod in prod_weight:\n                if feature in positive_features_counts[prod]:\n                    prod_weight[prod] = prod_weight[prod]+ positive_features_counts[prod][feature]                    \n            else:\n                if feature in positive_features_counts[prod]:\n                    prod_weight[prod] = positive_features_counts[prod][feature]\n\n\ndist_feature =[]\ndist_feature_count= []                    \nfor key, value in prod_weight.items() :\n    dist_feature.append(key)\n    dist_feature_count.append(value)\n    \nrank_products = pd.DataFrame()\nrank_products['product'] =dist_feature\nrank_products['weight'] =dist_feature_count\nrank_products= rank_products.sort_values(by ='weight' , ascending=False)\nrank_products             ","668cdc8b":"# Negative reviews products features count","568f84ca":"# Matching and Ranking Products","03ea722a":"# Positive reviews products features count","637287ec":"# Dataset and removing reviews having less then 5 words","443da846":"# Function for preprocessing on data","e64a0404":"# Products features and their counts"}}