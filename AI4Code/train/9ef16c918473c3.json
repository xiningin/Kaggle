{"cell_type":{"4a364f2c":"code","3814a297":"code","c104bd31":"code","7cf9b4fe":"code","4d215856":"code","2d8d11b5":"code","b6b1d6b8":"code","896fb3ba":"code","12b1ba0c":"code","f6d0bb8f":"code","27a2cfd3":"code","2aab13fc":"code","f9660082":"code","364e5a57":"code","734d7b2c":"code","1e55eac3":"code","cfd881b1":"code","95866088":"code","da4ae0d4":"code","eb53bd7b":"code","c67229a6":"code","c3440b0c":"markdown","6606df09":"markdown","3748c584":"markdown","fd6cf02a":"markdown","1bb861fe":"markdown","ec957c4e":"markdown","d653616a":"markdown","7ed4b465":"markdown","1b5bc299":"markdown","a8727c30":"markdown","b11e98f4":"markdown","b666c781":"markdown","a3d5235a":"markdown","0209c470":"markdown","260fe53a":"markdown","df53d112":"markdown","6db9c500":"markdown"},"source":{"4a364f2c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","3814a297":"from keras import layers \nfrom keras import models","c104bd31":"convnet_model = models.Sequential()\nconvnet_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\nconvnet_model.add(layers.MaxPooling2D((2, 2)))\nconvnet_model.add(layers.Conv2D(64, (3, 3), activation='relu')) \nconvnet_model.add(layers.MaxPooling2D((2, 2)))\nconvnet_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","7cf9b4fe":"convnet_model.summary()","4d215856":"convnet_model.add(layers.Flatten())\nconvnet_model.add(layers.Dense(64, activation='relu'))\nconvnet_model.add(layers.Dense(10, activation='softmax'))\n","2d8d11b5":"convnet_model.summary()","b6b1d6b8":"train_path = \"\/kaggle\/input\/digit-recognizer\/train.csv\"\ntest_path = \"\/kaggle\/input\/digit-recognizer\/test.csv\"\n\n# reading data\n\nimport pandas as pd\ntrain = pd.read_csv(train_path)\ntest = pd.read_csv(test_path)","896fb3ba":"print(\"Shape of trainig set :\", train.shape)\nprint(\"Shape of test set :\", test.shape)","12b1ba0c":"train_set = train[:30000]\nvalidation_set = train[30000:]","f6d0bb8f":"# reshaping the datasets to 3D tensors\ntrain_labels = train_set.iloc[:,0]\ntrain_images = train_set.iloc[:,1:]\ntrain_images = train_images.values.reshape((30000, 28, 28, 1))\n\n\ntest_labels = validation_set.iloc[:,0]\ntest_images = validation_set.iloc[:,1:]\ntest_images = test_images.values.reshape((12000, 28, 28, 1))","27a2cfd3":"train_images = train_images.astype('float32') \/ 255\ntest_images = test_images.astype('float32') \/ 255","2aab13fc":"from keras.utils import to_categorical\n\ntrain_labels = to_categorical(train_labels)\ntest_labels = to_categorical(test_labels)\nconvnet_model.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nconvnet_model.fit(train_images, train_labels, epochs=5, batch_size=64)\n","f9660082":"test_loss, test_acc = convnet_model.evaluate(test_images, test_labels)","364e5a57":"test_acc","734d7b2c":"train_labels = train.iloc[:,0]\ntrain_images = train.iloc[:,1:]\ntrain_images = train_images.values.reshape((42000, 28, 28, 1))\ntrain_images = train_images.astype('float32') \/ 255","1e55eac3":"train_labels = to_categorical(train_labels)\nconvnet_model.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nconvnet_model.fit(train_images, train_labels, epochs=5, batch_size=64)","cfd881b1":"test_images = test.values.reshape((28000, 28, 28, 1))\ntest_images = test_images.astype('float32') \/ 255","95866088":"predictions = convnet_model.predict(test_images)\npredictions = np.asarray([np.argmax(prediction) for prediction in predictions])\npredictions.shape","da4ae0d4":"df_predictions = pd.DataFrame(predictions).rename(columns={0: \"Label\"})\ndf_predictions.index.names = ['ImageId']\ndf_predictions.index += 1\ndf_predictions.head()","eb53bd7b":"df_predictions.shape\ndf_predictions.to_csv(\"predictions.csv\")","c67229a6":"from IPython.display import FileLink\nFileLink(r'predictions.csv')","c3440b0c":"After going through this notebook you will be able to understand the components shown in the picture below.\n![image.png](attachment:image.png)","6606df09":"We will build our CNN using sequential convolution layers","3748c584":"Create file for submission.","fd6cf02a":"We dont have validation set to evaluate our model so lets just devide our training date to train and test set.","1bb861fe":"I will use Keras to explain concepts of CNN","ec957c4e":"The input and output height and width can change due to 2 reasons:\n1. Border effect\n2. Strides\n\nIn our example, the size of feature map reduced due to border effect. You can avoid this by using [padding](http:\/\/deepai.org\/machine-learning-glossary-and-terms\/padding).![image.png](attachment:image.png)\n\n","d653616a":"### Max-pooling:\n\n\nMax-pooling downsamples the feature maps by taking maximum value from the patch. You can notice that the size of the feature map halved after max-pooling. Here is an example with 2\\*2 patch size\n\n![image.png](attachment:image.png)","7ed4b465":"# Decoding Convulation NN","1b5bc299":"Its important to understanf how Convnet is differen from the dense (regular) neural network.\n\n1. Dense layers learn global patterns and convulution layers learn local patterns\n    \n    - These patterns are transational invariants: independent of location of pattern\n    - Spatial hierarchies of patterns: they can learn more complex patterns in the subsequent layers\n    \n\n2. It operate on 3D tensors (*feature maps*):\n    1. height\n    2. width\n    3. depth (channel) depth is 1 for b\/w images and 3 for colorful images \n    \n \n Convulation Operation:\n \n Patches from input feature map ---> output feature map (3D tensor)\n \n Output feature map has arbitray height and width and depth axis is called filters that represent specific aspects of input data eg. face in the picture\n \n \n    \n  ","a8727c30":"After setting up layers (convulutions and max-pooling), we feed the resultant to dense layers just like regular neural network. To do this, we need to flatten the 3D tensor to 1D tensor. I used 'relu' function as activation. The final layer takes 1D tensor and use softmax function to provide 10-way probability for each image to be classified as a digit.","b11e98f4":"Inspecting the model","b666c781":"We got good accuracy with the model. Now we are ready to use full training data and get predictions on test set for submission.","a3d5235a":"Lets train the above model","0209c470":"The first layer just takes the input 3D tensor of shape (28,28,1) i.e. (height, width, depth) and it computer 32 filters contain 26\\*26 grid of values (response map) using patch size of 3 \\* 3 ","260fe53a":"## Difference between ConvNets and Dense Neural Network","df53d112":"As a best practice, lets normalize the dataset.","6db9c500":"How CNN works ![image.png](attachment:image.png)"}}