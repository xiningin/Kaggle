{"cell_type":{"82849b03":"code","c07e31f9":"code","d2d2789c":"code","e328dc12":"code","5e36e89f":"code","1b6be681":"code","94525d5f":"code","e1de19d3":"code","a281262b":"code","790c7e27":"code","0f1e5544":"code","2f3bfaa8":"code","ba864c1e":"code","a9cd24a9":"code","7df06d84":"code","c0ce6041":"code","f4589ab4":"code","cec3889c":"code","7d149540":"code","180bc825":"code","bc853f9d":"code","eafb1138":"code","55fb4926":"code","5481724e":"code","f6c45a67":"code","d61c3e62":"code","f7152639":"code","f14a7858":"code","af2ba5ea":"code","e52b992a":"code","b68753cc":"code","e9ccc18a":"code","1bacf068":"code","2b52dc55":"code","8ce29ceb":"code","9b477d53":"code","c75abf57":"markdown","092477da":"markdown","6f9bacbc":"markdown"},"source":{"82849b03":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c07e31f9":"#Code by Jay Lee https:\/\/www.kaggle.com\/jayaos\/basic-nlp-preprocessing-of-corpus-and-zipf-s-law\/notebook\n\nfrom collections import Counter","d2d2789c":"#Code by Jay Lee https:\/\/www.kaggle.com\/jayaos\/basic-nlp-preprocessing-of-corpus-and-zipf-s-law\/notebook\n\ndef read_docu(file):\n    \n    all_words = []\n    \n    with open(file, \"r\", encoding = \"utf-8\") as input_file:\n        for line in input_file:\n            line = line.lower()\n            line = line.strip().split()\n            all_words += line\n        return(all_words)","e328dc12":"#Code by Jay Lee https:\/\/www.kaggle.com\/jayaos\/basic-nlp-preprocessing-of-corpus-and-zipf-s-law\/notebook\n\ndef word_counter(all_words):\n    \n    word_count = Counter()\n    for word in all_words:\n        word_count[word] += 1\n    return(word_count.values())","5e36e89f":"#Code by Jay Lee https:\/\/www.kaggle.com\/jayaos\/basic-nlp-preprocessing-of-corpus-and-zipf-s-law\/notebook\n\ndef draw_zipfian_curve(word_count):\n    plt.plot(sorted(word_count, reverse = True), marker = \"o\")\n    plt.xscale(\"log\")\n    plt.yscale(\"log\")\n    plt.xlabel(\"log(Rank)\")\n    plt.ylabel(\"log(Frequency)\")\n    plt.show()","1b6be681":"#Code by Jay Lee https:\/\/www.kaggle.com\/jayaos\/basic-nlp-preprocessing-of-corpus-and-zipf-s-law\/notebook\n\ndef zipfian_plot(file):\n    word_corpus = read_docu(file)\n    counts = word_counter(word_corpus)\n    draw_zipfian_curve(counts)","94525d5f":"zipfian_plot(\"..\/input\/indic-nlp-library\/test_data\/normalize\/hi.txt\")","e1de19d3":"zipfian_plot(\"..\/input\/indic-nlp-library\/test_data\/normalize\/ta.txt\")","a281262b":"zipfian_plot(\"..\/input\/indic-nlp-library\/test_data\/normalize\/ur.txt\")","790c7e27":"df= pd.read_csv('..\/input\/indic-nlp-library\/test_data\/normalize\/ta.txt', sep='\\t')\ndf.head()","0f1e5544":"df1= pd.read_csv('..\/input\/indic-nlp-library\/test_data\/normalize\/hi.txt', sep='\\t')\ndf1.head()","2f3bfaa8":"#Code by Nain https:\/\/www.kaggle.com\/aakashnain\/chaii-explore-the-data\n\nfrom spacy.lang.ta import Tamil\nfrom spacy.lang.ta import STOP_WORDS as tamil_stopwords\nfrom wordcloud import WordCloud\nfrom collections import Counter","ba864c1e":"# Get the text for Tamil language\ntamil_text = \"\u0baa\u0bc1\u0ba4\u0bcd\u0ba4\u0bc1\u0ba3\u0bb0\u0bcd\u0b9a\u0bcd\u0b9a\u0bbf\u0baf\u0bbe\u0ba9 \u0b9a\u0bc1\u0bb5\u0bbe\u0b9a\u0bae\u0bcd \u0bae\u0bb1\u0bcd\u0bb1\u0bc1\u0bae\u0bcd \u0baa\u0bb3\u0baa\u0bb3\u0baa\u0bcd\u0baa\u0bbe\u0ba9 \u0baa\u0bb1\u0bcd\u0b95\u0bb3\u0bcd \u0ba4\u0b99\u0bcd\u0b95\u0bb3\u0bbf\u0ba9\u0bcd \u0ba4\u0bcb\u0bb1\u0bcd\u0bb1\u0ba4\u0bcd\u0ba4\u0bc8 \u0ba8\u0bbf\u0bb0\u0bcd\u0ba3\u0baf\u0bbf\u0b95\u0bcd\u0b95\u0bbf\u0bb1\u0ba4\u0bc1 .\"","a9cd24a9":"!wget -q http:\/\/www.lipikaar.com\/sites\/www.lipikaar.com\/themes\/million\/images\/support\/fonts\/Tamil.zip","7df06d84":"!unzip -qq Tamil.zip","c0ce6041":"#Code by Nain https:\/\/www.kaggle.com\/aakashnain\/chaii-explore-the-data\n\n# Get the tokens and frequencies for Tamil language\ntamil_nlp = Tamil()\ntamil_doc = tamil_nlp(tamil_text)\ntamil_tokens = set([token.text for token in tamil_doc])\ntamil_tokens_counter = Counter(tamil_tokens)","f4589ab4":"#Code by Nain https:\/\/www.kaggle.com\/aakashnain\/chaii-explore-the-data\n\ndef plot_wordcloud(\n    font_path,\n    frequencies,\n    stopwords,\n    width=500,\n    height=500,\n    background_color=\"black\",\n    collocations=True,\n    min_font_size=5,\n):\n    \"\"\"Generates wordcloud from word frequencies.\"\"\"\n    \n    wordcloud = WordCloud(font_path=font_path,\n                      width=width,\n                      height=height,\n                      background_color=background_color,\n                      stopwords=stopwords,\n                      collocations=collocations,\n                      min_font_size=min_font_size).generate(str(df))\n\n    \n    plt.figure(figsize=(10, 10))\n    plt.imshow(wordcloud)\n    plt.axis(\"off\")\n    plt.title(\"Tamil Text\")\n    plt.show()","cec3889c":"#Code by Nain https:\/\/www.kaggle.com\/aakashnain\/chaii-explore-the-data\n\n# Plot the wordcloud for tamil language\nplot_wordcloud(font_path=\"Tamil\/Lohit-Tamil.ttf\",\n               frequencies=tamil_tokens_counter,\n               stopwords=tamil_stopwords\n              )","7d149540":"df2= pd.read_csv('..\/input\/indic-nlp-library\/test_data\/normalize\/ma.txt', sep='\\t')\ndf2.head()","180bc825":"marathi_text = '\u0d09\u0d28\u0d4d\u0d2e\u0d47\u0d37\u0d2e\u0d41\u0d33\u0d4d\u0d33 \u0d36\u0d4d\u0d35\u0d3e\u0d38\u0d35\u0d41\u0d02 , \u0d24\u0d3f\u0d33\u0d19\u0d4d\u0d19\u0d41\u0d28\u0d4d\u0d28 \u0d2a\u0d32\u0d4d\u0d32\u0d41\u0d15\u0d33\u0d41\u0d02 \u0d24\u0d3e\u0d19\u0d4d\u0d15\u0d33\u0d41\u0d1f\u0d46 \u0d35\u0d4d\u0d2f\u0d15\u0d4d\u0d24\u0d3f\u0d24\u0d4d\u0d35\u0d24\u0d4d\u0d24\u0d46 \u0d36\u0d4b\u0d2d\u0d3f\u0d2a\u0d4d\u0d2a\u0d3f\u0d15\u0d4d\u0d15\u0d41\u0d28\u0d4d\u0d28\u0d41 .'","bc853f9d":"# Download and extract the fonts\n!wget -q http:\/\/www.lipikaar.com\/sites\/www.lipikaar.com\/themes\/million\/images\/support\/fonts\/Devanagari.zip","eafb1138":"!unzip -qq Devanagari.zip","55fb4926":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'lightblue',\n                      font_path=\"Devanagari\/Lohit-Devanagari.ttf\",\n                      colormap='Oranges',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df2))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Marathi Words\")\nplt.show()","5481724e":"!pip install spacy \n!pip install indic-nlp-datasets","f6c45a67":"paragraphs = ['\u0924\u093e\u091c\u093e \u0938\u093e\u0901\u0938\u0947\u0902 \u0914\u0930 \u091a\u092e\u091a\u092e\u093e\u0924\u0947 \u0926\u093e\u0901\u0924 \u0906\u092a\u0915\u0947 \u0935\u094d\u092f\u0915\u094d\u0924\u093f\u0924\u094d\u0935 \u0915\u094b \u0928\u093f\u0916\u093e\u0930\u0924\u0947 \u0939\u0948\u0902 \u0964']","d61c3e62":"text = \" \".join(paragraphs)\nwords = text.split(\" \")","f7152639":"from collections import Counter \ncnt = Counter(words)\n\ncnt.most_common(10)\n# print ","f14a7858":"from spacy.lang.hi import STOP_WORDS as STOP_WORDS_HI","af2ba5ea":"#https:\/\/colab.research.google.com\/github\/rahul1990gupta\/indic-nlp-datasets\/blob\/master\/examples\/Getting_started_with_processing_hindi_text.ipynb#scrollTo=ghnpMGzngcOn\n\n# Let's remove the stop words before printing most common words \n\nfrom spacy.lang.hi import Hindi\n\nnlp = Hindi()\n\ndoc = nlp(text)\n\nnot_stop_words = []\nfor token in doc:\n  if token.is_stop:\n    continue\n  if token.is_punct or token.text ==\"|\":\n    continue \n  not_stop_words.append(token.text)\n\n\nnot_stop_cnt = Counter(not_stop_words)\n\nnot_stop_cnt.most_common(10)","e52b992a":"# Let's render this in wordcloud \n# first import the rquired libraries \nfrom wordcloud import WordCloud\nfrom spacy.lang.hi import STOP_WORDS as STOP_WORS_HI\nimport matplotlib.pyplot as plt","b68753cc":"#https:\/\/colab.research.google.com\/github\/rahul1990gupta\/indic-nlp-datasets\/blob\/master\/examples\/Getting_started_with_processing_hindi_text.ipynb#scrollTo=ghnpMGzngcOn\n\n# That doesn't look right. We need to provide a custom font file to render it correctly. \n# the issue is highlighted here: https:\/\/github.com\/amueller\/word_cloud\/issues\/70\nimport requests\nurl = \"https:\/\/hindityping.info\/download\/assets\/Hindi-Fonts-Unicode\/gargi.ttf\"\n\nr = requests.get(url, allow_redirects=True)\nfont_path=\"gargi.ttf\"\n\nwith open(font_path, \"wb\") as fw:\n  fw.write(r.content)","e9ccc18a":"#https:\/\/colab.research.google.com\/github\/rahul1990gupta\/indic-nlp-datasets\/blob\/master\/examples\/Getting_started_with_processing_hindi_text.ipynb#scrollTo=ghnpMGzngcOn\n\nwordcloud = WordCloud(\n    width=400,\n    height=300,\n    max_font_size=50, \n    max_words=1000,\n    background_color=\"black\",\n    colormap='Set3',\n    stopwords=STOP_WORDS_HI,\n    font_path=font_path\n).generate(text)\nplt.figure(figsize=(10, 10))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","1bacf068":"#Code By Paul Mooney\n\nurdu_file = '..\/input\/indic-nlp-library\/test_data\/normalize\/ur.txt'\nwith open(urdu_file) as f: # The with keyword automatically closes the file when you are done\n    print (f.read(3000))","2b52dc55":"#Code By Paul Mooney\n\ngujarati_file = '..\/input\/indic-nlp-library\/test_data\/normalize\/gu.txt'\nwith open(gujarati_file) as f: # The with keyword automatically closes the file when you are done\n    print (f.read(3000))","8ce29ceb":"#Code By Paul Mooney\n\nbengali_file = '..\/input\/indic-nlp-library\/test_data\/normalize\/bn.txt'\nwith open(bengali_file) as f: # The with keyword automatically closes the file when you are done\n    print (f.read(3000))","9b477d53":"#Code By Paul Mooney\n\nmarathi_file = '..\/input\/indic-nlp-library\/test_data\/normalize\/ma.txt'\nwith open(marathi_file) as f: # The with keyword automatically closes the file when you are done\n    print (f.read(3000))","c75abf57":"Unfortunately, it didn't work with the Marathi, since we don't have Spacy Marathi.","092477da":"![](https:\/\/cdn.analyticsvidhya.com\/wp-content\/uploads\/2020\/01\/States_of_South_Asia.png)analyticsvidhya.com","6f9bacbc":"That's all since I can my WordClouds only in Tamil and Hindi."}}