{"cell_type":{"c422a58c":"code","6d8c3e74":"code","ee816681":"code","5da034fc":"code","98541cd6":"code","dc2da00e":"code","c476e876":"code","7eb93646":"code","c5e58f51":"code","f9b3ae23":"code","bedc3091":"code","1b09ca17":"code","c968ac2f":"code","2e1ce056":"code","76b3b18b":"code","72626ef3":"code","af3a67ef":"code","7e829e37":"code","b75839be":"code","30f4b946":"code","c90902bf":"code","7d20a848":"code","98a0f1c0":"markdown","20a694c2":"markdown","3834d271":"markdown","82496912":"markdown","cac853d6":"markdown","dd390937":"markdown","03410477":"markdown"},"source":{"c422a58c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6d8c3e74":"import torch\nimport fastai\nfrom fastai.tabular.all import *\nfrom fastai.text.all import *\nfrom fastai.vision.all import *\nfrom fastai.medical.imaging import *\nfrom fastai import *\n\nimport time\nfrom datetime import datetime\n\nprint(f'Notebook last run on {datetime.fromtimestamp(time.time()).strftime(\"%Y-%m-%d, %H:%M:%S UTC\")}')\nprint('Using fastai version ',fastai.__version__)\nprint('And torch version ',torch.__version__)","ee816681":"from PIL import Image\n\nimg = Image.open(\"..\/input\/prova\/Prova_Scalata.png\")\nimg","5da034fc":"TensorTypes = (TensorImage,TensorMask,TensorPoint,TensorBBox)","98541cd6":"def _add1(x): return x+1\ndumb_tfm = RandTransform(enc=_add1, p=0.5)\nstart,d1,d2 = 2,False,False\nfor _ in range(40):\n    t = dumb_tfm(start, split_idx=0)\n    if dumb_tfm.do: test_eq(t, start+1); d1=True\n    else:           test_eq(t, start)  ; d2=True\nassert d1 and d2\ndumb_tfm","dc2da00e":"_,axs = subplots(1,2)\nshow_image(img, ctx=axs[0], title='original')\nshow_image(img.flip_lr(), ctx=axs[1], title='flipped');","c476e876":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax,sz in zip(axs.flatten(), [300, 500, 700]):\n    show_image(img.crop_pad(sz), ctx=ax, title=f'Size {sz}');","7eb93646":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax,mode in zip(axs.flatten(), [PadMode.Zeros, PadMode.Border, PadMode.Reflection]):\n    show_image(img.crop_pad((600,700), pad_mode=mode), ctx=ax, title=mode);","c5e58f51":"import cv2 as cv\nimport matplotlib.pyplot as plt\n\nIMG_PATH = \"..\/input\/prova\/Prova_Scalata.png\"\n\nimgArray = cv.imread(IMG_PATH)\n\n\nconvertedArray = cv.cvtColor(imgArray, cv.COLOR_BGR2RGB)\n\nplt.subplots(figsize=(15,10))\nplt.imshow(convertedArray);plt.show()","f9b3ae23":"fig, ((ax1,ax2), (ax3,ax4)) =plt.subplots(2,2,figsize=(14,10))\n\nax1.imshow(convertedArray[:,:,0], cmap=\"Reds_r\"); ax1.set_title(\"R\", size=20) \nax2.imshow(convertedArray[:,:,1], cmap=\"Greens_r\"); ax2.set_title(\"G\", size=20)\nax3.imshow(convertedArray[:,:,2], cmap=\"Blues_r\"); ax3.set_title(\"B\", size=20)\n\nax4.axis(\"off\"); plt.tight_layout(); plt.show()","bedc3091":"fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(15,4))\n\nax1.hist(convertedArray[:,:,0].flatten(), color=\"r\", bins=200); ax1.set_title(\"r\", size=20)\nax2.hist(convertedArray[:,:,1].flatten(), color=\"g\", bins=200); ax1.set_title(\"g\", size=20)\nax3.hist(convertedArray[:,:,2].flatten(), color=\"b\", bins=200); ax1.set_title(\"b\", size=20)\n\nplt.tight_layout();plt.show()","1b09ca17":"type(convertedArray) #numpy.ndarray","c968ac2f":"convertedArray.dtype #dtype('uint8')","2e1ce056":"convertedArray.min() #0\nconvertedArray.max() #255","76b3b18b":"convertedArray.shape  #(256, 196, 3)","72626ef3":"crop1 = convertedArray[:200, :190, :]\ncrop1.shape # (200,190, 3)\nplt.imshow(crop1);plt.show()","af3a67ef":"#In case you want to select from row 230 to 250, column 190 to 195 and all channels:\n\ncrop2 = convertedArray[230:250,190:195,:]\nplt.figure(figsize=(15,8))\nplt.imshow(crop2); plt.show()","7e829e37":"#If you want to crop only one channel (the first one). Just write:\n\nplt.figure(figsize=(15,8))\nplt.imshow(convertedArray[230:250,190:195,0], cmap=\"rainbow\");plt.show()","b75839be":"convertedArray.shape #(256,196,3)\nconvertedArray.shape[0]*convertedArray.shape[1] #50176","30f4b946":"plt.subplots(figsize=(15,10))\nplt.imshow(convertedArray)\nplt.axvline(190, color=\"yellow\")\nplt.axhline(250, color=\"orange\")\n\nplt.show()","c90902bf":"#If you want to extract these two profiles. Proceed this way for the horizontal section at row 200\n\nhorSection = convertedArray[200,:,:]\nplt.figure(figsize=(16,5))\nplt.plot(horSection[:,0], label=\"r\", color=\"#e74c3c\")\nplt.plot(horSection[:,1], label=\"g\", color=\"#16a085\")\nplt.plot(horSection[:,2], label=\"b\", color=\"#3498db\")\n\nplt.xlabel(\"X\"); plt.legend(); plt.show()","7d20a848":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('S\u00ec, l ho fatto, @mpwolke sono stata qui.' )","98a0f1c0":"#Crop","20a694c2":"Above, the tuple tells us that the image has 256 rows, 196 columns and 3 channels (RGB). To crop the image we can simply use numpy indexing methods.\n\nSo, in the next snippets choose numbers below 256 and 196.\n\nTake the first 200 rows and the first 190 columns (of all channels) and write like this below:","3834d271":"#To avoid IndexError: index 600 is out of bounds for axis 0 with size 256.  Change to the right number of Pixels max 256","82496912":"#Dissecting an image\n\nSuppose you want to extract a vertical and a horizontal section from the image.","cac853d6":"#Histograms - Use lower case in \"r\", \"g\", \"b\".","dd390937":"![](https:\/\/www.custorino.it\/content\/files\/2020\/07\/Newsletter-Cus-mese-di-Luglio-2020_page-0002.jpg)custorino.it","03410477":"#Image.Flip"}}