{"cell_type":{"6ed22d87":"code","e1e5a6e6":"code","2c501cc1":"code","4239aca0":"code","481306fb":"code","9b504b7e":"code","3934df7b":"code","72748809":"code","1d5351d5":"code","a7662d8c":"code","4b5abfa3":"code","5702467b":"code","e7f0f834":"code","c2238a89":"code","8357bad2":"code","dc5abde4":"code","d7c7f5d5":"code","1095c869":"code","8764798f":"code","d950d6b8":"code","78b3b252":"code","142ba93f":"code","494736dd":"code","f8c4c1c6":"code","ecb78902":"code","6dd03339":"code","28196ac6":"code","6e416807":"code","20510c05":"code","04f8769f":"code","4d9b85db":"code","bd4c93c6":"code","41de2a17":"code","84cccd08":"code","1b33f529":"code","1b9cdf40":"code","9d13b8e6":"code","5eeb12c4":"markdown"},"source":{"6ed22d87":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib\n\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew\nfrom scipy.stats.stats import pearsonr\n\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error","e1e5a6e6":"train = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")","2c501cc1":"all_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],test.loc[:,'MSSubClass':'SaleCondition']))","4239aca0":"#log transform the target:\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n\n#log transform skewed numeric features:\nnumeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index","481306fb":"skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\nskewed_feats = skewed_feats[skewed_feats > 0.75]\nskewed_feats = skewed_feats.index\nskewed_feats\nall_data[skewed_feats] = np.log1p(all_data[skewed_feats])","9b504b7e":"all_data = pd.get_dummies(all_data)\n#filling NA's with the mean of the column:\nall_data = all_data.fillna(all_data.mean())","3934df7b":"#creating matrices for sklearn:\nX_train = all_data[:train.shape[0]]\nX_test = all_data[train.shape[0]:]\ny = train.SalePrice","72748809":"from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\nfrom sklearn.model_selection import cross_val_score\n\ndef rmse_cv(model):\n    rmse= np.sqrt(-cross_val_score(model, X_train, y, scoring=\"neg_mean_squared_error\", cv = 5))\n    return(rmse)","1d5351d5":"#Trying Lasso\nmodel_ridge = Ridge()","a7662d8c":"alphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]\ncv_ridge = [rmse_cv(Ridge(alpha = alpha)).mean() \n            for alpha in alphas]","4b5abfa3":"cv_ridge = pd.Series(cv_ridge, index = alphas)\ncv_ridge.plot(title = \"Validation - Just Do It\")\nplt.xlabel(\"alpha\")\nplt.ylabel(\"rmse\")","5702467b":"cv_ridge.min()","e7f0f834":"model_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005]).fit(X_train, y)\nrmse_cv(model_lasso).mean()","c2238a89":"coef = pd.Series(model_lasso.coef_, index = X_train.columns)\nprint(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\ncoef","8357bad2":"imp_coef = pd.concat([coef.sort_values().head(10),\n                     coef.sort_values().tail(10)])","dc5abde4":"matplotlib.rcParams['figure.figsize'] = (6.0, 3.0)\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Coefficients in the Lasso Model\")","d7c7f5d5":"#let's look at the residuals as well:\nmatplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n\npreds = pd.DataFrame({\"preds\":model_lasso.predict(X_train), \"true\":y})\npreds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\npreds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")","1095c869":"#Trying XGB\nimport xgboost as xgb","8764798f":"dtrain = xgb.DMatrix(X_train, label = y)\ndtest = xgb.DMatrix(X_test)\n\nparams = {\"max_depth\":2, \"eta\":0.1}\nmodel = xgb.cv(params, dtrain,  num_boost_round=500, early_stopping_rounds=100)","d950d6b8":"model.loc[30:,[\"test-rmse-mean\", \"train-rmse-mean\"]].plot()","78b3b252":"model_xgb = xgb.XGBRegressor(n_estimators=360, max_depth=2, learning_rate=0.1)\nmodel_xgb.fit(X_train, y)","142ba93f":"xgb_preds = np.expm1(model_xgb.predict(X_test))\nlasso_preds = np.expm1(model_lasso.predict(X_test))","494736dd":"predictions = pd.DataFrame({\"xgb\":xgb_preds, \"lasso\":lasso_preds})\npredictions.plot(x = \"xgb\", y = \"lasso\", kind = \"scatter\")","f8c4c1c6":"# trying catboost\nfrom catboost import Pool\nfrom catboost import CatBoostRegressor\nfrom sklearn.model_selection import train_test_split\nimport numpy as np","ecb78902":"X = X_train\ntest_df = X_test\nX.shape, test_df.shape","6dd03339":"float_cols = X.dtypes[X.dtypes == \"float\"].index\nX.loc[:,float_cols] = X[float_cols].astype(str)\n\nX_train.shape, X.shape","28196ac6":"SEED = 1\nX_train.shape,X.shape,y.shape","6e416807":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=SEED)\n\ncat_features = list(range(X.shape[1]))","20510c05":"train_data = Pool(data=X_train,\n                  label=y_train,\n                  cat_features=cat_features\n                 )\n\nvalid_data = Pool(data=X_valid,\n                  label=y_valid,\n                  cat_features=cat_features\n                 )","04f8769f":"%%time\n\nparams = { 'early_stopping_rounds': 100,\n          'verbose': False,\n          'random_seed': SEED,\n          'eval_metric':'RMSE'\n         }\n\ncbc_7 = CatBoostRegressor(**params)\ncbc_7.fit(train_data, \n          eval_set=valid_data, \n          use_best_model=True, \n          plot=True\n         );","4d9b85db":"cbc_7.get_feature_importance(prettified=True)","bd4c93c6":"X_test = test_df\nfloat_cols_test = X_test.dtypes[X_test.dtypes == \"float\"].index\nX_test.loc[:,float_cols_test] = X_test[float_cols_test].astype(str)\n\nX_train.shape, X.shape , X_test.shape","41de2a17":"from sklearn.utils.multiclass import type_of_target\ntype_of_target(y)","84cccd08":"%%time\n\nfrom sklearn.model_selection import StratifiedKFold\n\nn_fold = 3 # amount of data folds\nfolds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=SEED)\n\nparams = {\n          'early_stopping_rounds': 100,\n          'verbose': False,\n          'random_seed': SEED,\n          'eval_metric':'RMSE'\n         }\n\ntest_data = Pool(data=X_test,\n                 cat_features=cat_features)\n\nbins = np.linspace(0, 1, 100) \ny_binned = np.digitize(y, bins)\n\nscores = []\ncatboost_prediction = np.zeros(X_test.shape[0])\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(X, y_binned)):\n    \n    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    \n    train_data = Pool(data=X_train, \n                      label=y_train,\n                      cat_features=cat_features)\n    valid_data = Pool(data=X_valid, \n                      label=y_valid,\n                      cat_features=cat_features)\n    \n    model = CatBoostRegressor(**params)\n    model.fit(train_data,\n              eval_set=valid_data, \n              use_best_model=True\n             )\n    \n    score = model.get_best_score()['validation']['RMSE']\n    scores.append(score)\n\n    y_pred = model.predict(test_data)\n    catboost_prediction += y_pred\n\ncatboost_prediction \/= n_fold\nprint('CV mean: {:.4f}, CV std: {:.4f}'.format(np.mean(scores), np.std(scores)))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_valid, model.predict(X_valid))))","1b33f529":"cb_preds = np.expm1(catboost_prediction)\n\npredictions = pd.DataFrame({\"lasso\":lasso_preds, \"cb\":cb_preds})\npredictions.plot(x = \"lasso\", y = \"cb\", kind = \"scatter\")\n\npredictions = pd.DataFrame({\"xgb\":xgb_preds, \"cb\":cb_preds})\npredictions.plot(x = \"xgb\", y = \"cb\", kind = \"scatter\")\n\npredictions = pd.DataFrame({\"xgb\":xgb_preds, \"lasso\":lasso_preds})\npredictions.plot(x = \"xgb\", y = \"lasso\", kind = \"scatter\")","1b9cdf40":"#I was not able to run and commit below H20 model and I have ran it seperately and used its output here as input dataset. PLease refer to following link for notebook : couldn'thttps:\/\/www.kaggle.com\/shashinkumarsachan\/house-price-prediction-using-h20-automl\n\nh20_preds = pd.read_csv('..\/input\/house-price-predictions-h20-automl-without-tuning\/house_sales_price_pred_full.csv')\n\npredictions = pd.DataFrame({\"h20\":h20_preds['SalePrice'], \"lasso\":lasso_preds})\npredictions.plot(x = \"h20\", y = \"lasso\", kind = \"scatter\")\n\npredictions = pd.DataFrame({\"h20\":h20_preds['SalePrice'], \"cb\":cb_preds})\npredictions.plot(x = \"h20\", y = \"cb\", kind = \"scatter\")\n\npredictions = pd.DataFrame({\"h20\":h20_preds['SalePrice'], \"xgb\":xgb_preds})\npredictions.plot(x = \"h20\", y = \"xgb\", kind = \"scatter\")","9d13b8e6":"# Finally mixing predictions,\n\npreds = 0.57*lasso_preds + 0.0*xgb_preds + 0.0*cb_preds + 0.43*h20_preds['SalePrice']\ncb_solution = pd.DataFrame({\"id\":test.Id, \"SalePrice\":preds})\ncb_solution.to_csv(\"house_price_preds.csv\", index = False)","5eeb12c4":"# ****Applied : Lasso, XGBoost, Catboost, H20****"}}