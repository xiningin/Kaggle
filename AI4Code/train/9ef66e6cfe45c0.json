{"cell_type":{"49ee67cf":"code","33c94f25":"code","89f65d34":"code","fea279a6":"code","56e2b83d":"code","afadb308":"code","69b6c2e3":"code","040dd07c":"code","4c9161ab":"code","5caeaa3b":"code","95a23276":"code","287bfa7b":"code","89812fbf":"code","0b9b8894":"markdown","610ef978":"markdown","2c02d068":"markdown","7d963f75":"markdown","f34279cc":"markdown","1a43b848":"markdown","c0df2cc7":"markdown","df4352e2":"markdown","0a774624":"markdown","48d27a36":"markdown","d4905af7":"markdown","bdfeaee0":"markdown","527bdf88":"markdown","dba571d1":"markdown","1a12cc99":"markdown","9fb1b235":"markdown","5c97a4d6":"markdown","73e9922f":"markdown","8293dc95":"markdown","7aea0390":"markdown","d78c417e":"markdown","1d8508c8":"markdown","29bfb363":"markdown"},"source":{"49ee67cf":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\nimport matplotlib.image as implt\nfrom PIL import Image \nimport seaborn as sns\nimport cv2 as cs2\nimport os\n\nimport warnings\nwarnings.filterwarnings('ignore')","33c94f25":"train_path = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/train\"\ntest_path = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/validation\"\n\ntrain_horses = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/train\/horses\"\ntest_horses = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/validation\/horses\"\n\ntrain_humans = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/train\/humans\"\ntest_humans = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/validation\/humans\"","89f65d34":"category_names = os.listdir(train_path) # output: ['humans', 'horses'] (Makes two categories)\nnb_categories = len(category_names) # output: 2 (Number of categories)\ntrain_images = []\n\nfor category in category_names:\n    folder = train_path + \"\/\" + category\n    train_images.append(len(os.listdir(folder)))","fea279a6":"test_images = []\nfor category in category_names:\n    folder = test_path + \"\/\" + category\n    test_images.append(len(os.listdir(folder)))","56e2b83d":"img1 = implt.imread(train_horses + \"\/horse05-1.png\")\nimg2 = implt.imread(train_humans + \"\/human01-02.png\")\n\nplt.subplot(1, 2, 1)\nplt.title('horse')\nplt.imshow(img1)       \nplt.subplot(1, 2, 2)\nplt.title('human')\nplt.imshow(img2)\nplt.show()","afadb308":"img_size = 50\nhumans_train = []\nhorses_train = []\nlabel = []\n\nfor i in os.listdir(train_humans): # all train human images\n    if os.path.isfile(train_path + \"\/humans\/\" + i): # check image in file\n        humans = Image.open(train_path + \"\/humans\/\" + i).convert(\"L\") # converting grey scale \n        humans = humans.resize((img_size,img_size), Image.ANTIALIAS) # resizing to 50,50\n        humans = np.asarray(humans)\/255 # bit format\n        humans_train.append(humans)\n        label.append(1)\n        \nfor i in os.listdir(train_horses): # all train horse images\n    if os.path.isfile(train_path + \"\/horses\/\" + i): # check image in file\n        horses = Image.open(train_path + \"\/horses\/\" + i).convert(\"L\") # converting grey scale \n        horses = horses.resize((img_size,img_size), Image.ANTIALIAS) # resizing to 50,50\n        horses = np.asarray(horses)\/255 # bit format\n        horses_train.append(horses)\n        label.append(0)","69b6c2e3":"x_train = np.concatenate((humans_train,horses_train),axis=0) # training dataset\nx_train_label = np.asarray(label) # label array containing 0 and 1\nx_train_label = x_train_label.reshape(x_train_label.shape[0],1)\n\nprint(\"humans:\",np.shape(humans_train) , \"horses:\",np.shape(horses_train))\nprint(\"train_dataset:\",np.shape(x_train), \"train_values:\",np.shape(x_train_label))","040dd07c":"img_size = 50\nhumans_test = []\nhorses_test = []\nlabel = []\n\nfor i in os.listdir(test_humans): # all train human images\n    if os.path.isfile(test_path + \"\/humans\/\" + i): # check image in file\n        humans = Image.open(test_path + \"\/humans\/\" + i).convert(\"L\") # converting grey scale \n        humans = humans.resize((img_size,img_size), Image.ANTIALIAS) # resizing to 50,50\n        humans = np.asarray(humans)\/255 # bit format\n        humans_test.append(humans)\n        label.append(1)\n        \nfor i in os.listdir(test_horses): # all train horse images\n    if os.path.isfile(test_path + \"\/horses\/\" + i): # check image in file\n        horses = Image.open(test_path + \"\/horses\/\" + i).convert(\"L\") # converting grey scale \n        horses = horses.resize((img_size,img_size), Image.ANTIALIAS) # resizing to 50,50\n        horses = np.asarray(horses)\/255 # bit format\n        horses_test.append(horses)\n        label.append(0)","4c9161ab":"x_test = np.concatenate((humans_test,horses_test),axis=0) \nx_test_label = np.asarray(label) \nx_test_label = x_test_label.reshape(x_test_label.shape[0],1)\n\nprint(\"humans:\",np.shape(humans_test) , \"horses:\",np.shape(horses_test))\nprint(\"test_dataset:\",np.shape(x_test), \"test_values:\",np.shape(x_test_label))","5caeaa3b":"x = np.concatenate((x_train,x_test),axis=0) # count: 1027+256= 1283  | train_data\n# x.shape: \n#   output = (1283,50,50)\ny = np.concatenate((x_train_label,x_test_label),axis=0) # count: 1027+256= 1283 | test_data\nx = x.reshape(x.shape[0],x.shape[1]*x.shape[2]) # flatten 3D image array to 2D, count: 50*50 = 2500\nprint(\"images:\",np.shape(x), \"labels:\",np.shape(y))","95a23276":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=42)\nnumber_of_train = X_train.shape[0]\nnumber_of_test = X_test.shape[0]\n\nprint(\"Train Number: \", number_of_train)\nprint(\"Test Number: \", number_of_test)","287bfa7b":"x_train = X_train\nx_test = X_test\ny_train = y_train\ny_test = y_test\nprint(\"x train: \",x_train.shape)\nprint(\"x test: \",x_test.shape)\nprint(\"y train: \",y_train.shape)\nprint(\"y test: \",y_test.shape)","89812fbf":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential # initialize neural network library\nfrom keras.layers import Dense # build our layers library\ndef build_classifier():\n    classifier = Sequential() # initialize neural network\n    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return classifier\nclassifier = KerasClassifier(build_fn = build_classifier, epochs = 100)\naccuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\nmean = accuracies.mean()\nvariance = accuracies.std()\nMax = accuracies.max()\nprint(\"Accuracy mean: \"+ str(mean))\nprint(\"Accuracy variance: \"+ str(variance))\nprint(\"Accuracy max: \"+ str(Max))","0b9b8894":"![image.png](attachment:d170c32d-3f1f-4d54-aaa7-a91243cecb69.png)\n* Thats RElu we are usin that","610ef978":"Finally we have usable data","2c02d068":"## Making test data\n * Same things but for test images","7d963f75":"![image.png](attachment:cca7b2ed-a967-4f8c-97cb-a23592bb38f9.png)\n* Thats another activation function for example(tanh function)","f34279cc":"Maked our training dataset","1a43b848":"<a id=\"5\"><\/a> <br>\n## ANN with keras\n **Something about computation graphs**\n   * we have computation graphs\n   * Circles are named \"node\"\n   * Input layers are our data\n   * We will code hidden layers\n   * Output layer:horse or human\n   * W is weight and b is bias if you don't know that you need learn logistic regression first\n   \n  **About code**\n   * We are adding new hidden layers with <u>Classifier.add<\/u>\n   * Building layers <u>Dense<\/u>\n   * Epochs: number of iteration\n   * Metrics: accuracy\n   * Loss:our cost\n   * Units is number of nodes in the one layer\n   * Kernal_initializer is our weights and I prefer uniform weights\n   * cross_val_score:Using cross validation same with machine learning \n   * input_dim: Our input\n   * optimizer: about backward propagation adam is good because needs low memory\n   * activation:activation function, I will explian\n   ","c0df2cc7":"![image.png](attachment:30dc8821-8749-4bee-93a8-9a926002b46c.png)","df4352e2":"![image.png](attachment:f5b0eb92-5004-4f98-9e50-5aeb5ec2cebe.png)","0a774624":"<a id=\"2\"><\/a> <br>\n## Importing\n* That will be short part about importing libraries and variables","48d27a36":"We taked images which in the train images","d4905af7":"![image.png](attachment:b9874fda-8117-4e6e-86fc-6defcfa055ae.png)\n","bdfeaee0":"![image.png](attachment:993005bf-b5d3-42ff-9371-8e4cadcc6622.png)\n* Thats sigmoid function gives a binary value \n* Gives that horse or human in our code","527bdf88":"# Welcome to ANN with Keras\n * Our dataset is images of horses and humans\n * I am going to explain how to do ANN with keras\n * At the end of tutorial you will have basic information of ANN with keras\n * That will be short, basic and I hope useful tutorial\n * I am using keras because keras is basic and useful for me\n \n * [Making data usable](#1)\n     * [Importing libraries and variables](#2)\n     * [Reading images and making categories](#3)\n     * [Processing data](#4)\n * [ANN with keras](#5)\n     *  [Explaining parameters](#6)\n     *  [Conlusion](#7)\n     ","dba571d1":"<a id=\"7\"><\/a> <br>\n# Conclusion\n * First of all thanks for reading my kernel\n * That was a short kernel about ANN with keras\n * I am a newbie and I need your help in the comments\n * I know that my code isn't too good but If you upvote my code that makes me very happy :)","1a12cc99":"## .convert\n  * Turn images to grey scale\n  * And thats easier for ANN\n ","9fb1b235":"We can read images with using matplolib.image","5c97a4d6":"We taked images which in the test images","73e9922f":"## Activation functions\n *  We have some activation functions","8293dc95":"<a id=\"4\"><\/a> <br>\n## Processing data\n * making usable for ANN","7aea0390":"<a id=\"1\"><\/a> <br>\n## Making data usable \n* In this part we will make data science","d78c417e":"![image.png](attachment:73b8b531-2996-4f61-88e1-78132d0dd31f.png)","1d8508c8":"## Image.ANTILIAS\n * makes less pixel in image\n * less pixel means less input and faster ANN","29bfb363":"<a id=\"3\"><\/a> <br>\n## Making categories and reading images\n * Making horse and human categories\n * Reading our images with matplotlib"}}