{"cell_type":{"499420b5":"code","1749ebb3":"code","14f2a6c0":"code","9b9294ac":"code","2aab5cef":"code","89431e26":"code","20d92745":"code","5b9777b2":"code","e59d7d7a":"code","c9e8b16c":"code","945b3025":"code","b56ded75":"code","1d26be4f":"code","e7671d32":"code","b2012e53":"code","7302dc45":"code","f1b893a7":"code","8205cc31":"code","e8558175":"code","12d42af0":"code","af944e0c":"code","66737892":"code","e4333601":"code","02f51728":"code","7643038d":"code","00ef3376":"code","10ca9e55":"code","5cf09f53":"code","927a3fe4":"code","e246ec88":"code","6147e2bc":"code","a2210c96":"code","132f4995":"code","7384bf73":"code","aca79406":"code","c89c6beb":"code","248d52c2":"code","126c6c12":"code","46a2848f":"code","a8d67e6d":"code","9b254c77":"markdown","a9388199":"markdown"},"source":{"499420b5":"!cp -r ..\/input\/brain-tumor-detection-mri\/Brain_Tumor_Detection -d \/Brain_Tumor_Detection\/\n!rm -r \/Brain_Tumor_Detection\/pred\n!ls \/Brain_Tumor_Detection","1749ebb3":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","14f2a6c0":"import pathlib\ndata_dir = \"\/Brain_Tumor_Detection\"\ndata_dir = pathlib.Path(data_dir)","9b9294ac":"image_count = len(list(data_dir.glob('*\/*.jpg')))\nprint(image_count)","2aab5cef":"yes = list(data_dir.glob('yes\/*.jpg'))\nPIL.Image.open(yes[0])","89431e26":"no = list(data_dir.glob('no\/*.jpg'))\nPIL.Image.open(no[0])","20d92745":"BATCH_SIZE = 32\nIMG_HEIGHT = 299\nIMG_WIDTH = 299\nIMG_SIZE = (IMG_HEIGHT, IMG_WIDTH)\n\ntrain_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    batch_size=BATCH_SIZE,\n    image_size=IMG_SIZE,\n    validation_split=0.2,\n    subset='training',\n    seed=123\n)\n\nvalidation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    batch_size=BATCH_SIZE,\n    image_size=IMG_SIZE,\n    validation_split=0.2,\n    subset='validation',\n    seed=123\n)","5b9777b2":"class_names = train_dataset.class_names\nprint(class_names)","e59d7d7a":"plt.figure(figsize=(10, 10))\n\nfor images, labels in train_dataset.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i+1)\n    plt.imshow(images[i].numpy().astype('uint8'))\n    plt.title(class_names[labels[i]])\n    plt.axis('off')","c9e8b16c":"val_batches = tf.data.experimental.cardinality(validation_dataset)\ntest_dataset = validation_dataset.take(val_batches \/\/5)\nvalidation_dataset = validation_dataset.skip(val_batches\/\/5)","945b3025":"print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\nprint('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))","b56ded75":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nvalidation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\ntest_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)","1d26be4f":"data_augmentation = tf.keras.Sequential([\n      tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal',\n                                                            input_shape=(299, 299, 3)),\n      tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n      tf.keras.layers.experimental.preprocessing.RandomZoom(0.2)\n])","e7671d32":"for image, _ in train_dataset.take(1):\n  plt.figure(figsize=(10, 10))\n  first_image = image[0]\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n    plt.imshow(augmented_image[0] \/ 255)\n    plt.axis('off')","b2012e53":"preprocess_input = tf.keras.applications.inception_v3.preprocess_input","7302dc45":"rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1.\/127.5, offset= -1)","f1b893a7":"IMG_SHAPE = IMG_SIZE + (3,)\n\nbase_model = tf.keras.applications.InceptionV3(include_top=False,\n                                               input_shape=IMG_SHAPE,\n                                               weights='imagenet')","8205cc31":"image_batch, label_batch = next(iter(train_dataset))\nfeature_batch = base_model(image_batch)\n\nprint(feature_batch.shape)","e8558175":"base_model.trainable = False","12d42af0":"base_model.summary()","af944e0c":"global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nfeature_batch_average = global_average_layer(feature_batch)\nprint(feature_batch_average.shape)","66737892":"prediction_layer = tf.keras.layers.Dense(1)\nprediction_batch = prediction_layer(feature_batch_average)\nprint(prediction_batch.shape)","e4333601":"inputs = tf.keras.Input(shape=IMG_SHAPE)\nx = data_augmentation(inputs)\nx = preprocess_input(x)\nx = base_model(x, training=False)\nx = global_average_layer(x)\nx = tf.keras.layers.Dropout(0.2)(x)\noutputs = prediction_layer(x)\nmodel = tf.keras.Model(inputs, outputs)","02f51728":"base_learning_rate = 0.0001\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","7643038d":"model.summary()","00ef3376":"len(model.trainable_variables)","10ca9e55":"initial_epochs = 30\n\nloss0, accuracy0 = model.evaluate(validation_dataset)","5cf09f53":"print(\"initial loss: {:.2f}\".format(loss0))\nprint(\"initial accuracy: {:.2f}\".format(accuracy0))","927a3fe4":"history = model.fit(train_dataset,\n                    epochs=initial_epochs,\n                    validation_data=validation_dataset)","e246ec88":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","6147e2bc":"base_model.trainable = True","a2210c96":"# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(base_model.layers))\n\n# Fine-tune from this layer onwards\nfine_tune_at = 250\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable =  False","132f4995":"model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate\/10),\n              metrics=['accuracy'])","7384bf73":"model.summary()","aca79406":"len(model.trainable_variables)","c89c6beb":"fine_tune_epochs = 10\ntotal_epochs =  initial_epochs + fine_tune_epochs\n\nhistory_fine = model.fit(train_dataset,\n                         epochs=total_epochs,\n                         initial_epoch=history.epoch[-1],\n                         validation_data=validation_dataset)","248d52c2":"acc += history_fine.history['accuracy']\nval_acc += history_fine.history['val_accuracy']\n\nloss += history_fine.history['loss']\nval_loss += history_fine.history['val_loss']","126c6c12":"plt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0.8, 1])\nplt.plot([initial_epochs-1,initial_epochs-1],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.ylim([0, 1.0])\nplt.plot([initial_epochs-1,initial_epochs-1],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","46a2848f":"loss, accuracy = model.evaluate(test_dataset)\nprint('Test accuracy :', accuracy)","a8d67e6d":"#Retrieve a batch of images from the test set\nimage_batch, label_batch = test_dataset.as_numpy_iterator().next()\npredictions = model.predict_on_batch(image_batch).flatten()\n\n# Apply a sigmoid since our model returns logits\npredictions = tf.nn.sigmoid(predictions)\npredictions = tf.where(predictions < 0.5, 0, 1)\n\nprint('Predictions:\\n', predictions.numpy())\nprint('Labels:\\n', label_batch)\n\nplt.figure(figsize=(50, 50))\nfor i in range(32):\n  ax = plt.subplot(8, 4, i + 1)\n  plt.imshow(image_batch[i].astype(\"uint8\"))\n\n  if predictions[i] == label_batch[i]:\n    plt.title(\"i: \" + str(i) + \" P: \" + class_names[predictions[i]] + \" L: \" + class_names[label_batch[i]],\n            fontdict = {\n                'fontsize': 20,\n                'color': 'green'\n            })\n  else:\n    plt.title(\"i: \" + str(i) + \" P: \" + class_names[predictions[i]] + \" L: \" + class_names[label_batch[i]],\n            fontdict = {\n                'fontsize': 20,\n                'color': 'red'\n            })\n  plt.axis(\"off\")","9b254c77":"Let's get the data to disk and remove pred folder to make data input pipeline creation easier and efficient.","a9388199":"# **Obtaining Data to Disk and Preprocessing**"}}