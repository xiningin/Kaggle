{"cell_type":{"9eb9bd1f":"code","c534dc46":"code","094765b0":"code","94dd40b5":"code","4236fb34":"code","9c48a6b4":"code","f84e88df":"code","cf2b9bc8":"code","9c379209":"code","6b630bef":"code","b718ceb5":"code","f21f5c7c":"code","d4675345":"code","7145cf78":"code","d3124261":"code","ebab14e4":"code","b99e2c6f":"code","37b17b9e":"code","a1531acb":"code","08234e47":"code","77386fe9":"code","bed64def":"code","8ba2fa73":"code","72972b30":"code","a0c37a63":"code","e50302fd":"code","038c10f1":"code","851d0bfc":"code","85b35147":"code","4651aafa":"code","4e773289":"code","e26f162e":"code","a988ba75":"code","72e1954c":"code","c783c974":"code","d1e4a3d2":"code","5f6a4f9c":"markdown","3723dfd1":"markdown","86f8e541":"markdown","1f19c0ca":"markdown","309eed5c":"markdown","db2839a4":"markdown","7727aa9b":"markdown","4ab126e2":"markdown","8a698c63":"markdown"},"source":{"9eb9bd1f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c534dc46":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntrain.head()","094765b0":"train.isna().sum()","94dd40b5":"len(train)","4236fb34":"test.isna().sum()","9c48a6b4":"train.isna().sum()","f84e88df":"test.isna().sum()","cf2b9bc8":"data = [train, test]\nfor df in data:\n    df[\"Age_na\"] = 0\n    df.loc[df.Age.isna(), \"Age_na\"] = 1\n    df.Age.fillna(value = 28, inplace=True)","9c379209":"# let's add \"Has cabin\"\nfor df in data:\n    df[\"Has_cabin\"] = 1\n    df.loc[df.Cabin.isna(), \"Has_cabin\"] = 0","6b630bef":"# low na columns in train let's drop and in test fill Fare with median\nfor df in data:\n    df.Embarked.dropna(inplace=True)\n    df.Fare.fillna(value=train.Fare.median(), inplace=True)","b718ceb5":"name_title = [\"Master\", \"Mr\", \"Mrs\", \"Miss\"]\n# Name\nfor df in data:\n    df[\"Title\"] = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\n    df.loc[~df[\"Title\"].isin(name_title), \"Title\"] = \"Other\"","f21f5c7c":"# Cabin\nfor df in data:\n    df[\"Cabin\"] = df[\"Cabin\"].str.extract('(^[a-zA-Z])', expand=False)    ","d4675345":"# let's drop and other already used values ticket\nfor df in data:\n    df.drop([\"Ticket\"], axis=1, inplace=True)\n    df.drop([\"Name\"], axis=1, inplace=True)","7145cf78":"# Class, age_na, \nclass_dict = {\n    1:\"First\",\n    2:\"Second\",\n    3:\"Thrid\"\n}\nage_na_dict = {\n    1:\"False\",\n    0:\"True\"\n}\nhas_cabin_dict = {\n    1:\"True\",\n    0:\"False\"\n}\nfor df in data:\n    df[\"Pclass\"] = df[\"Pclass\"].map(class_dict)\n    df[\"Has_cabin\"] = df[\"Has_cabin\"].map(has_cabin_dict)\n    df[\"Age_na\"] = df[\"Age_na\"].map(age_na_dict)","d3124261":"train.Cabin.value_counts()","ebab14e4":"\ntrain","b99e2c6f":"def val_trans(df):\n    df[num_val] = df[num_val].apply(pd.to_numeric)\n    onehot = pd.get_dummies(df[cat_val])\n    df.drop(cat_val, axis=1, inplace=True)\n    return onehot","37b17b9e":"cat_val = ['Pclass', 'Sex','Cabin', 'Embarked','Age_na', 'Has_cabin', 'Title']\nnum_val = ['Age', 'SibSp', 'Parch', 'Fare']\ntrain = train.join(val_trans(train))\ntest = test.join(val_trans(test))\ntrain","a1531acb":"cor_mat = train.corr()\ncor_mat[\"Survived\"].sort_values()","08234e47":"# Split data into train and test\nfrom sklearn.model_selection import train_test_split\nX = train.drop(['PassengerId', \"Survived\"], axis=1)\ny = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","77386fe9":"# SGD Classifier\nfrom sklearn.linear_model import SGDClassifier\nsgd = SGDClassifier()\nsgd.fit(X_train, y_train)\nsgd.score(X_test, y_test)","bed64def":"# Svc Classifier\nfrom sklearn.svm import SVC\nsvc = SVC()\nsvc.fit(X_train, y_train)\nsvc.score(X_test, y_test)","8ba2fa73":"# KNeighbours Classifier\nfrom sklearn.neighbors import KNeighborsClassifier\nknc = KNeighborsClassifier(30)\nknc.fit(X_train, y_train)\nknc.score(X_test, y_test)","72972b30":"# Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)\nrfc.score(X_test, y_test)","a0c37a63":"# Random Forest seems to be the best one, let's tune it\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(rfc, X, y, cv=5)\nscores.mean()","e50302fd":"from scipy.stats import uniform, truncnorm, randint\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.utils.fixes import loguniform\n\nmodel_params = {\n    'n_estimators': randint(250, 320),\n    'max_features': truncnorm(a=0, b=1, loc=0.4, scale=0.1),\n    'min_samples_split': uniform(0.01, 0.199)\n}\nrscv = RandomizedSearchCV(rfc,param_distributions=model_params, n_iter=100, cv=5, random_state=1)\nmodel = rscv.fit(X,y)\nfrom pprint import pprint\npprint(model.best_estimator_.get_params())","038c10f1":"model.score(X_test, y_test)","851d0bfc":"# Let's try to scale the data \nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X.astype(np.float64))\nmodel.fit(X_scaled, y)","85b35147":"pprint(model.best_estimator_.get_params())","4651aafa":"X_test_scaled= scaler.fit_transform(X_test.astype(np.float64))\nX_train_scaled =scaler.fit_transform(X_train.astype(np.float64))\nmodel.score(X_test_scaled, y_test)","4e773289":"rfc.fit(X_train_scaled, y_train)\nrfc.score(X_test_scaled, y_test)","e26f162e":"from scipy.stats import uniform, truncnorm, randint\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.utils.fixes import loguniform\n\nmodel_params = {\n    'n_estimators': randint(250, 320),\n    'max_features': truncnorm(a=0, b=1, loc=0.4, scale=0.1),\n    'min_samples_split': uniform(0.01, 0.199)\n}\nrscv = RandomizedSearchCV(rfc,param_distributions=model_params, n_iter=20, cv=5, random_state=1)\nmodel_last = rscv.fit(X,y)\nfrom pprint import pprint\npprint(model.best_estimator_.get_params())","a988ba75":"model_last.score(X_test, y_test)","72e1954c":"# In test there was no Cabin_T, so we need to add one\ntest.insert(loc=16, column='Cabin_T', value=0)","c783c974":"test_pred = test.drop(\"PassengerId\", axis=1)\nY_pred = model_last.predict(test_pred)\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission","d1e4a3d2":"submission.to_csv('.\/submission.csv', index=False)","5f6a4f9c":"# Now let's transform the data","3723dfd1":"# Now, let's train our model","86f8e541":"# Let's do some visualization with Tableau","1f19c0ca":"# Let's deal with missing values","309eed5c":"If you age is missing, you only have 30% of survival. Almost the same survival rate have the age of 28. So, lets fill missing age with 28 and add column \"Age_na\"","db2839a4":"# Let's dowload our data","7727aa9b":"# Let's see if there any missing data","4ab126e2":"# Let's submit now","8a698c63":"![Dashboard%201.png](attachment:Dashboard%201.png)"}}