{"cell_type":{"5520ccf3":"code","46cb539c":"code","454955f6":"code","21efaa3e":"code","44e5ee40":"code","385fab7e":"code","c360f617":"code","983b31c7":"code","3883ef2f":"code","aa0c643e":"code","3cc36d8e":"code","03fd8ba3":"code","c5a08059":"code","bc4176c8":"code","deb3a9b7":"code","f8139bd2":"code","c9ecc11e":"code","2bb89f48":"code","3ae31455":"code","8f6d118c":"code","159af240":"code","c1ef5f24":"code","9808ea8b":"code","d098b889":"code","a7be4ff9":"code","fc0fea05":"markdown","db33f10f":"markdown","cad7cffe":"markdown"},"source":{"5520ccf3":"# import libraries\nimport os  # just something for kaggle integration\nimport numpy as np  # linear algebra\nimport pandas as pd  # data handling\nimport matplotlib.pyplot as plt  # data visualization\nimport seaborn as sns  # more (better) data visualization","46cb539c":"# get training data\ntrain_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","454955f6":"# show raw train_data\ntrain_data","21efaa3e":"# drop string columns\ntrain_data.drop(['Name', 'Ticket', 'Cabin', 'Embarked'], axis=1, inplace=True)","44e5ee40":"# show statistical information from training data\ntrain_data.describe()","385fab7e":"# show types for each column and the number of non-null values\ntrain_data.info()","c360f617":"# drop rows with null values\ntrain_data = train_data.dropna()","983b31c7":"# show result of cleaning\ntrain_data","3883ef2f":"# convert sex column to binary\n\n# def male(string):\n#     return string == 'male'\n\n# train_data['male'] = train_data['Sex'].apply(male)\n\ntrain_data['male'] = train_data['Sex'].apply(lambda x: x=='male')\ntrain_data = train_data.drop('Sex', axis=1)\n\ntrain_data","aa0c643e":"# plot Fare vs Age\nsns.scatterplot(data=train_data, x='Age', y='Fare')","3cc36d8e":"# importing LinearRegression model\nfrom sklearn.linear_model import LinearRegression\n\n# prepare the data to train\nX = train_data[['Age']]\ny = train_data['Fare'] # target\n\n# instantiate model, train\nlr_model = LinearRegression()\nlr_model.fit(X, y)\n\n# y = mx + b\nprint(lr_model.intercept_)\nprint(lr_model.coef_)\n\n# get predictions\npreds = lr_model.predict(X)","03fd8ba3":"# show prediction line\nplt.scatter(x=train_data['Age'], y=preds)","c5a08059":"train_data.head()","bc4176c8":"# find Fare based on all other columns\n\n# X = train_data.drop(['PassengerId', 'Fare'], axis=1)\nX = train_data[['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'male']]\ny = train_data['Fare']\n\nlr_multi = LinearRegression()\nlr_multi.fit(X, y)\n\nprint('intercept: ', lr_multi.intercept_)\nprint('coefficients: ', lr_multi.coef_)\n\npreds_multi = lr_multi.predict(X)","deb3a9b7":"# compare true values (x-axis) with predictions (y-axis)\nplt.scatter(y, preds_multi)","f8139bd2":"# Make a Logistic Regression model to predict Survived column\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\n# set X and y\nX = train_data.drop(['PassengerId', 'Survived'], axis=1)\ny = train_data['Survived']\n\n# train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=101, test_size=0.2)\n\n# create an instance and train\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)\n\n# generate predictions\nlog_preds = log_reg.predict(X_test)\n\n# check metrics\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nprint('accuracy: ', accuracy_score(y_test, log_preds))\nprint(confusion_matrix(y_test, log_preds))","c9ecc11e":"test_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","2bb89f48":"test_data['male'] = test_data['Sex'].apply(lambda x: x=='male')\ntest_data['Fare'] = test_data['Fare'].fillna(0)","3ae31455":"# Make a Logistic Regression model to predict Survived column\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\n# set X_train and y_train\nX_train = train_data.drop(['PassengerId', 'Survived', 'Age'], axis=1)\ny_train = train_data['Survived']\n\n# set test data\nX_test = test_data[['Pclass', 'SibSp', 'Parch', 'Fare', 'male']]\n\n# create an instance and train\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)\n\n# generate predictions\nlog_preds = log_reg.predict(X_test)","8f6d118c":"test_data['Survived'] = log_preds","159af240":"test_data[['PassengerId', 'Survived']].to_csv('submission.csv', index=False)","c1ef5f24":"X = train_data.drop('Survived', axis=1)\ny = train_data['Survived']\n\nX_columns = X.columns","9808ea8b":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(X)\nX_scaled = scaler.transform(X)\nX_scaled = pd.DataFrame(X_scaled, columns=X_columns)","d098b889":"from sklearn.neighbors import KNeighborsClassifier\n\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y,\n                                                   random_state = 101,\n                                                   test_size=0.2)","a7be4ff9":"k_values = []\n\nfor k in range(1, 46):\n\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n\n    preds = knn.predict(X_test)\n    k_values.append([k, accuracy_score(y_test, preds)])\n    \nk_values = np.array(k_values)\n\nk_values = pd.DataFrame(k_values, columns=['k', 'accuracy'])\n\nsns.scatterplot(data=k_values, x='k', y='accuracy')","fc0fea05":"# Day 3 (7\/19)","db33f10f":"# Day 1 (7\/12)","cad7cffe":"# Day 2 (7\/14)"}}