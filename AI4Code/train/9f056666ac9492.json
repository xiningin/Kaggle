{"cell_type":{"10764be0":"code","9eb1ef2d":"code","0c616576":"code","f03389f5":"code","ebb9b96f":"code","a2e02961":"code","7c372340":"code","ec46c5bb":"code","bfcca2c8":"code","e16f9d28":"code","4b3e2704":"code","57949748":"code","fbddc180":"code","cd91017d":"code","b83f8d86":"code","b7e3e9ce":"code","66e75055":"code","f6ad1ed0":"code","dfda8e71":"code","bc63b019":"code","52efe676":"code","f89959e9":"code","c21063ff":"code","79ebea7a":"code","aa387226":"code","b744110e":"code","44ef3cc4":"code","52177e99":"code","1b62c7e1":"code","6ef1741e":"code","cef3d0e6":"code","01c7357e":"code","796bec8c":"code","e6173420":"code","b65c0023":"markdown","f3a59f90":"markdown","6bb80c5c":"markdown","e39dd026":"markdown","5582da24":"markdown","99b83cf3":"markdown","edff03c4":"markdown","900d62d6":"markdown","b9b7361c":"markdown","325cacf8":"markdown","a09cec0d":"markdown","c90bb551":"markdown","f619bab8":"markdown","dfaac825":"markdown","e8d3aaa3":"markdown","b7b81e55":"markdown","6958f744":"markdown"},"source":{"10764be0":"import os\nimport numpy as np \nimport pandas as pd \nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nimport wandb\nimport squarify\n\nimport folium\nfrom geopy.geocoders import Nominatim\nfrom folium import Choropleth, Circle, Marker\nfrom folium.plugins import HeatMap, MarkerCluster\n\nfrom wordcloud import WordCloud,STOPWORDS\nfrom matplotlib.ticker import FuncFormatter\nfrom palettable.scientific.sequential import Acton_14,Bamako_12,Hawaii_5\nfrom palettable.tableau import Tableau_20\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","9eb1ef2d":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\napi_key = user_secrets.get_secret(\"api_key\")\n\nCONFIG = {'competition': 'kaggle-survey', '_wandb_kernel': 'ruch'}\n\nos.environ[\"WANDB_SILENT\"] = \"true\"\n\n! wandb login $api_key","0c616576":"df = pd.read_csv(\"..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv\")\ndf.head()","f03389f5":"lst = df.columns\nlen(lst)","ebb9b96f":"geolocator = Nominatim(user_agent=\"Ruch\")\n\ndef feature_generation(df):\n    country=[]\n    lat=[]\n    long=[]\n    location_df = pd.DataFrame()\n    for i in df['Q3'].unique(): \n        location = geolocator.geocode(i)\n        try:\n            lat.append(location.latitude)\n            long.append(location.longitude)\n            country.append(i)\n        except:\n            lat.append(np.nan)\n            long.append(np.nan)\n            country.append(np.nan)\n    location_df['Country'] = country\n    location_df['Latitude'] = lat\n    location_df['Longitude'] = long\n    \n    return location_df\n\n# map_data = feature_generation(df)\n# map_data = map_data.dropna()\n\n# df = df.merge(map_data, how='outer', left_on='Q3', right_on='Country')\n# df = df.drop(['Country'], axis = 1)","a2e02961":"# #====== Saving to csv files and creating artifacts ======\n# df.to_csv(\"dataset_lat_long.csv\")\n\n# run = wandb.init(project='kaggle-survey', name='dataset_lat_long',anonymous=\"allow\")\n\n# artifact = wandb.Artifact('dataset_lat_long', type='dataset')\n\n# #====== Add a file to the artifact's contents ======\n# artifact.add_file(\"dataset_lat_long.csv\")\n\n# #====== Save the artifact version to W&B and mark it as the output of this run ======\n# run.log_artifact(artifact)\n\n# run.finish()","7c372340":"run = wandb.init(anonymous=\"allow\")\nartifact = run.use_artifact('ruchi798\/kaggle-survey\/dataset_lat_long:v0', type='dataset')\nartifact_dir = artifact.download()\nrun.finish()\n\npath = os.path.join(artifact_dir,\"dataset_lat_long.csv\")\ndf = pd.read_csv(path)\ndf = df.drop(columns=[\"Unnamed: 0\"])","ec46c5bb":"sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n\ndef map_df(df,col1,col2):\n    \n    df = df.iloc[1:]\n    df = pd.DataFrame(df[[col1, col2, 'Latitude', 'Longitude']]).groupby([col1, col2,'Latitude', 'Longitude']).size().reset_index(name='count')\n    df[col2] = df[col2] + \" : \" + df['count'].astype(str)\n    map_data = pd.DataFrame(df[col2].groupby([df[col1]]).apply(list).reset_index()) \n    map_data = pd.merge(map_data,df[[col1,'Latitude', 'Longitude']],on=col1, how='left')\n    map_data = map_data.drop_duplicates(subset = [col1]).reset_index()\n    \n    world_map= folium.Map(tiles=\"Stamen Watercolor\")\n    mc = MarkerCluster()\n    for idx, row in map_data.iterrows():\n        if not math.isnan(row['Longitude']) and not math.isnan(row['Latitude']):\n            popup = \"\"\"\n            Country : <b>%s<\/b><br>\n            Degree : <b>%s<\/b><br>\n            \"\"\" % (row[col1], row[col2])\n            mc.add_child(Marker([row['Latitude'], row['Longitude']],tooltip=popup))\n        world_map.add_child(mc)\n    \n    return world_map\n\ndef plot_bar(col, palette):\n    title = df[col][0]\n    title = title.replace(\"- Selected Choice\",\"\")\n    plt.figure(figsize=(20,20))\n    plt.yticks(fontsize=16)\n    sns.countplot(y=col,data=df.iloc[1:],order=df.iloc[1:][col].value_counts().index,palette=palette,linewidth=3)\n    plt.title(title,font=\"Serif\", size=20)\n    plt.show()\n    \n#====== Function to plot wandb bar chart ======\ndef plot_wb_bar(df,col1,col2,title): \n    name = col1\n    run = wandb.init(project='kaggle-survey', job_type='image-visualization',name=name)\n    \n    dt = [[label, val] for (label, val) in zip(df[col1], df[col2])]\n    table = wandb.Table(data=dt, columns = [col1,col2])\n    wandb.log({name : wandb.plot.bar(table, col1,col2,title=title)})\n\n    run.finish()\n    \n#====== Function to create a dataframe of value counts ======\ndef count_values(df,col,top=False):\n    df = pd.DataFrame(df[col].value_counts().reset_index().values,columns=[col, \"counts\"])\n    if top==True: df=df[:10]\n    return df","bfcca2c8":"title = df['Q2'][0]\ntitle = title.replace(\"- Selected Choice\",\"\")\nfig, ax  = plt.subplots(figsize=(16, 8))\nfig.suptitle(title, fontsize = 20, font=\"Serif\")\nexplode = (0.05, 0.4, 0.4, 0.5, 0.6)\nlabels = list(df.iloc[1:].Q2.value_counts().index)\nsizes = df.iloc[1:].Q2.value_counts().values\nax.pie(sizes, explode=explode,startangle=60, labels=labels,autopct='%1.0f%%', pctdistance=0.7, colors=[\"#d45d00\",\"#ff9100\",\"#eaaa00\",\"#6d6875\",\"#5e6875\"])\nax.add_artist(plt.Circle((0,0),0.4,fc='white'))\nplt.show()\n\nwmap = map_df(df, 'Q3', 'Q2')\nwmap","e16f9d28":"plot_wb_bar(count_values(df[1:],\"Q2\"),\"Q2\", \"counts\",\"Gender distribution\")","4b3e2704":"plot_bar('Q4',\"Blues\")","57949748":"wmap = map_df(df, 'Q3', 'Q4')\nwmap","fbddc180":"plot_wb_bar(count_values(df[1:],\"Q4\"),\"Q4\", \"counts\",\"Highest level of formal education distribution\")","cd91017d":"plot_bar('Q6',\"Greens\")","b83f8d86":"wmap = map_df(df, 'Q3', 'Q6')\nwmap","b7e3e9ce":"plot_wb_bar(count_values(df[1:],\"Q6\"),\"Q6\", \"counts\",\"Years of experience of writing code distribution\")","66e75055":"# color function for the wordcloud\ndef color_wc(word=None,font_size=None,position=None, orientation=None,font_path=None, random_state=None):\n    h = int(360.0 * 135.0 \/ 255.0)\n    s = int(190.0 * 255.0 \/ 255.0)\n    l = int(100.0 * float(random_state.randint(40, 80)) \/ 255.0)\n    return \"hsl({}, {}%, {}%)\".format(h, s, l)\n\n\nfig = plt.gcf()\nfig.set_size_inches(16, 8)\nwc = WordCloud(stopwords=STOPWORDS,background_color=\"white\", contour_width=2, contour_color='orange',width=1500, height=750,color_func=color_wc,max_words=150, max_font_size=256,random_state=42)\nwc.generate(' '.join(df['Q5']))\nfig = plt.imshow(wc, interpolation=\"bilinear\")\nfig = plt.axis('off')","f6ad1ed0":"wmap = map_df(df, 'Q3', 'Q5')\nwmap","dfda8e71":"plot_wb_bar(count_values(df[1:],\"Q5\"),\"Q5\", \"counts\",\"Job titles distribution\")","bc63b019":"def get_count(question_num, parts):\n    questions = []\n    questions = ['Q'+ str(question_num) +'_Part_'+ str(j) for j in range(1, parts)]\n    questions.append('Q'+ str(question_num) + '_OTHER')\n    \n    categories = []\n    values = []\n    for i in questions:\n        category = df[i].value_counts().index[0]\n        val = df[i].value_counts()[0]\n        \n        categories.append(category)\n        values.append(val)\n       \n    combined_df = pd.DataFrame()\n    combined_df['Category'] = categories\n    combined_df['Value'] = values\n    \n    combined_df = combined_df.sort_values(['Value'],ascending=False)\n    \n    return combined_df\n\ndef plot_donut(data, title, colors):\n    plt.figure(figsize=(16,10))\n    \n    circle = plt.Circle((0,0), 0.7, color='white')\n    plt.rcParams['text.color'] = 'black'\n    \n    plt.pie(data['Value'], labels=data['Category'], colors=colors)\n    \n    p = plt.gcf()\n    p.gca().add_artist(circle)\n    \n    plt.title(title, size=20)\n    plt.show()\n\nprogramming_lang = get_count(7,12)\nplot_donut(programming_lang, 'Programming Languages widely used',Acton_14.hex_colors)","52efe676":"programming_lang = programming_lang.rename(columns={\"Category\": \"Q7\"})\nplot_wb_bar(programming_lang,\"Q7\", \"Value\",\"Programming Languages widely used distribution\")","f89959e9":"plot_bar('Q8',\"Greens\")","c21063ff":"plot_wb_bar(count_values(df[1:],\"Q8\"),\"Q8\", \"counts\",\"Recommended programming language for an aspiring data scientist distribution\")","79ebea7a":"ide = get_count(9,12)\nplot_donut(ide, 'Integrated development environments widely used',Bamako_12.hex_colors)","aa387226":"ide = ide.rename(columns={\"Category\": \"Q9\"})\nplot_wb_bar(ide,\"Q9\", \"Value\",\"Integrated development environments widely used distribution\")","b744110e":"hosted_nb = get_count(10,12)\n\nnorm = matplotlib.colors.Normalize(vmin=min(hosted_nb.Value), vmax=max(hosted_nb.Value))\ncolor = [matplotlib.cm.summer(norm(value)) for value in hosted_nb.Value]\n\nlabels = hosted_nb.Category\nsizes = hosted_nb.Value\n\nfig = plt.gcf()\nax = fig.add_subplot()\nfig.set_size_inches(20, 9)\nsquarify.plot(sizes,color=color, label = labels, pad = True, alpha=.7, text_kwargs={'fontsize':10})\nplt.axis('off')\nplt.show()","44ef3cc4":"hosted_nb = hosted_nb.rename(columns={\"Category\": \"Q10\"})\nplot_wb_bar(hosted_nb,\"Q10\", \"Value\",\"Hosted notebook distribution\")","52177e99":"plot_bar('Q11',\"winter\")","1b62c7e1":"plot_wb_bar(count_values(df[1:],\"Q11\"),\"Q11\", \"counts\",\"Computing platform distribution\")","6ef1741e":"sph = get_count(12,5)\nplot_donut(sph, 'Specialized Hardware',Hawaii_5.hex_colors)","cef3d0e6":"sph = sph.rename(columns={\"Category\": \"Q12\"})\nplot_wb_bar(sph,\"Q12\", \"Value\",\"Specialized Hardware distribution\")","01c7357e":"def visualize_relation(start_slice, end_slice, new_col_names, old_col, new_col, xlabel, title, p1,p2):\n    df_sliced = df.iloc[:,start_slice:end_slice].iloc[1:]\n\n    df_sliced = df_sliced.rename(columns=new_col_names).fillna(0).replace('[^\\\\d]',1, regex=True)\n    df_sliced = df_sliced.join(df[old_col])\n\n    df_sliced_stats = pd.DataFrame()\n    for col in df_sliced.columns[:-1]:\n        df_sliced_stats[col] = df_sliced.groupby(old_col)[col].mean().values\n\n    df_sliced = df_sliced.rename(columns={old_col:new_col})\n    df_sliced_stats.index = df_sliced.groupby(new_col)[list(new_col_names.items())[0][1]].mean().index\n\n    cmap = sns.diverging_palette(p1, p2, as_cmap=True)\n    display(df_sliced_stats.style.background_gradient(cmap, axis=0).format(\"{:.0%}\"))\n\n    df_sliced_stats[new_col] = df_sliced_stats.index\n    fig = plt.figure(figsize=(14, 16))\n    ax = fig.add_subplot(111)\n    for i in range(len(df_sliced_stats.columns[:-1])):\n        color = Tableau_20.hex_colors[i]\n        col = df_sliced_stats.columns[i]\n        df_sliced_stats.plot(kind=\"scatter\", x=col,y=new_col, color=color, label=col,ax=ax, s=100)\n    ax.xaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y))) \n    ax.set_xlabel(xlabel)\n    ax.legend(loc='upper right',bbox_to_anchor=(1.35, 1), frameon=False)\n    ax.set_title(title,font=\"Serif\")\n    plt.show()","796bec8c":"new_col_names ={'Q7_Part_1': 'Python',\n                'Q7_Part_2': 'R',\n                'Q7_Part_3': 'SQL',\n                'Q7_Part_4': 'C',\n                'Q7_Part_5': 'C++',\n                'Q7_Part_6': 'Java',\n                'Q7_Part_7': 'Javascript',\n                'Q7_Part_8': 'Julia',\n                'Q7_Part_9': 'Swift',\n                'Q7_Part_10': 'Bash',\n                'Q7_Part_11': 'MATLAB',\n                'Q7_Part_12': 'None',\n                'Q7_OTHER': 'Other'\n                }\nvisualize_relation(7,20, new_col_names, 'Q5', 'Job Title', \"Usage of Programming Language\", \"Job Title vs Programming Language\", 150, 275)","e6173420":"new_col_names ={'Q12_Part_1': 'NVIDIA GPUs',\n                'Q12_Part_2': 'Google Cloud TPUs',\n                'Q12_Part_3': 'AWS Trainium Chips',\n                'Q12_Part_4': 'AWS Inferentia Chips',\n                'Q12_Part_5': 'None',\n                'Q12_OTHER': 'Other'\n                }\nvisualize_relation(52,58, new_col_names, 'Q5', 'Job Title', \"Adoption of Specialized Hardware\", \"Job Title vs Specialized Hardware\", 50, 175 )","b65c0023":"# Programming language used on a regular basis \ud83e\uddd1\u200d\ud83c\udf73","f3a59f90":"# Highest level of formal education \ud83c\udf93","6bb80c5c":"This is what my [project](https:\/\/wandb.ai\/ruchi798\/kaggle-survey?workspace=user-ruchi798) looks like on the W&B dashboard \u2b07\ufe0f\n![](https:\/\/i.imgur.com\/FDkPPbP.png)","e39dd026":"How many features do we have in store? \ud83c\udf69","5582da24":"# Hosted notebook products \ud83d\udcd3","99b83cf3":"# Job Titles \ud83e\uddd1\u200d\ud83d\udcbc","edff03c4":"# Job Title vs Specialized Hardware \u2699\ufe0f\ud83c\udf36\ufe0f","900d62d6":"<img src=\"https:\/\/camo.githubusercontent.com\/dd842f7b0be57140e68b2ab9cb007992acd131c48284eaf6b1aca758bfea358b\/68747470733a2f2f692e696d6775722e636f6d2f52557469567a482e706e67\">\n\nI will be integrating W&B for visualizations and logging artifacts!\n\n> [Kaggle ML & DS Survey W&B Dashboard](https:\/\/wandb.ai\/ruchi798\/kaggle-survey?workspace=user-ruchi798)\ud83c\udfcb\ufe0f\u200d\u2640\ufe0f\n>\n> - To get the API key, an account is to be created on the [website](https:\/\/wandb.ai\/home) first.\n> - Next, use secrets to use API Keys more securely \ud83e\udd2b","b9b7361c":"# Specialized Hardware \u2699\ufe0f\ud83c\udf36\ufe0f","325cacf8":"# Import libraries \ud83d\udcda","a09cec0d":"![](https:\/\/i.imgur.com\/wcCJf9v.png)","c90bb551":"# Years of Experience of Writing Code \ud83d\udc69\u200d\ud83d\udcbb","f619bab8":"# Gender Distribution \ud83d\udcca","dfaac825":"# Integrated development environments (IDE)","e8d3aaa3":"# Recommended Programming language for an aspiring data scientist\ud83e\uddd1\u200d\ud83c\udfeb","b7b81e55":"# Job Title vs Programming Language \ud83e\uddd1\u200d\ud83c\udf73","6958f744":"# Computing platform \u2699\ufe0f"}}