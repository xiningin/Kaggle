{"cell_type":{"2f7d0cee":"code","3d41d624":"code","9b5283d9":"code","c56c7aed":"code","24e311f8":"code","55ef46dd":"code","0107d55c":"code","120b8135":"code","70d439c6":"code","67543c55":"code","f374e24f":"code","d6c10134":"code","0ac9baf8":"code","7a6d7dd5":"code","660137d3":"code","f1950cf9":"code","c47a9115":"code","bf651a5e":"code","a41b825a":"code","aa7719f0":"code","1429a25c":"code","08edda4b":"markdown","1f410943":"markdown","bb5a9beb":"markdown","9cc7f7bc":"markdown","55f26820":"markdown","1d0be770":"markdown","b63376c8":"markdown","06bc2bb7":"markdown","3b2193a2":"markdown","21e7f5e0":"markdown","d2880b88":"markdown","634be795":"markdown","d1e7ef81":"markdown","1dd10445":"markdown","d881343d":"markdown","6b4c7e86":"markdown","97e48232":"markdown"},"source":{"2f7d0cee":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport xgboost as xgb\nimport sklearn\nfrom sklearn.model_selection import cross_val_score,GridSearchCV\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder\nfrom sklearn.tree import DecisionTreeClassifier,export_graphviz\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression,Perceptron,SGDClassifier\nfrom sklearn.metrics import f1_score,accuracy_score,recall_score,classification_report,make_scorer,roc_curve, auc\nfrom sklearn.model_selection import train_test_split\nfrom category_encoders.one_hot import OneHotEncoder\nimport keras\n\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense","3d41d624":"df = pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\")\ndf.head()","9b5283d9":"numeric_features = ['age','trestbps','thalach','oldpeak','chol']\ncategorical_features = ['sex','cp','fbs','restecg','exang','slope','ca','thal']","c56c7aed":"df[numeric_features].describe()","24e311f8":"numerics = df[numeric_features]\nfig, ax = plt.subplots(5,1,figsize=(22, 30))\nfor i, col in enumerate(numerics):\n    plt.subplot(5,1,i+1)\n    plt.xlabel(col, fontsize=10)\n    sns.distplot(numerics[col].values)\nplt.show() ","55ef46dd":"corr = numerics.corr()\nsns.heatmap(corr,annot=True,fmt='.3f',linewidths=2)\nplt.title('Correlation Matrix')\nplt.gcf().set_size_inches(11,7)\nplt.show()","0107d55c":"categorical = df[categorical_features]\nfig, axes = plt.subplots(round(len(categorical.columns) \/ 4), 3, figsize=(22, 10))\n\nfor i, ax in enumerate(fig.axes):\n    if i < len(categorical.columns):\n        sns.countplot(x=categorical.columns[i], data=categorical, ax=ax)\n\nfig.tight_layout()","120b8135":"pd.crosstab(df.age,df.target).plot(kind=\"bar\",figsize=(18,5))\nplt.title('Heart Disease Frequency for Ages')\nplt.xlabel('Age')\nplt.ylabel('N')\nplt.show()\n\nplt.subplots(figsize=(18, 5))\nplt.title('Heart Disease Distribution for Ages')\nsns.distplot(df[df['target'] == 1]['age'], label=\"Target = 1 \")\nsns.distplot(df[df['target'] == 0]['age'], label=\"Target = 0 \")\nplt.legend()","70d439c6":"sns.set(style=\"ticks\")\nsns.pairplot(df)\nplt.show()","67543c55":"pd.options.mode.chained_assignment = None  # default='warn'\n\nscaler = sklearn.preprocessing.StandardScaler().fit(df[numeric_features])\ndf[numeric_features]= scaler.transform(df[numeric_features])\n\ndf['sex'][df['sex'] == 0] = 'female'\ndf['sex'][df['sex'] == 1] = 'male'\n\ndf['cp'][df['cp'] == 1] = 'typical angina'\ndf['cp'][df['cp'] == 2] = 'atypical angina'\ndf['cp'][df['cp'] == 3] = 'non-anginal pain'\ndf['cp'][df['cp'] == 4] = 'asymptomatic'\n\ndf['fbs'][df['fbs'] == 0] = 'lower than 120mg\/ml'\ndf['fbs'][df['fbs'] == 1] = 'greater than 120mg\/ml'\n\ndf['restecg'][df['restecg'] == 0] = 'normal'\ndf['restecg'][df['restecg'] == 1] = 'ST-T wave abnormality'\ndf['restecg'][df['restecg'] == 2] = 'left ventricular hypertrophy'\n\ndf['exang'][df['exang'] == 0] = 'no'\ndf['exang'][df['exang'] == 1] = 'yes'\n\ndf['slope'][df['slope'] == 1] = 'upsloping'\ndf['slope'][df['slope'] == 2] = 'flat'\ndf['slope'][df['slope'] == 3] = 'downsloping'\n\ndf['thal'][df['thal'] == 1] = 'normal'\ndf['thal'][df['thal'] == 2] = 'fixed defect'\ndf['thal'][df['thal'] == 3] = 'reversable defect'\n\ndf = pd.get_dummies(df, drop_first=True)\ndf_eda = df.copy()\n\ndummies = OneHotEncoder(cols= 'ca',use_cat_names=True)\ndummies.fit(df)\ndf = dummies.transform(df)\ndf.head()","f374e24f":"#Split data in train and test\ny = df[['target']]\nx = df.drop(['target'],axis = 1)\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)","d6c10134":"import os\nfrom IPython.display import SVG\nfrom graphviz import Source\nimport itertools\n\ntree = DecisionTreeClassifier(max_depth=3)\ntree.fit(x,y)\ngraph = Source(export_graphviz(tree\n                               , feature_names=x.columns\n                               , filled = True))\ndisplay(SVG(graph.pipe(format='svg')))","0ac9baf8":"pd.crosstab(df['thal_fixed defect'],df.target).plot(kind=\"bar\",figsize=(18,5))\nplt.title('Thal Fixed defect x Target')\nplt.xlabel('thal_fixed defect')\nplt.ylabel('N')\nplt.show()","7a6d7dd5":"pd.crosstab(df_eda['ca'],df_eda.target).plot(kind=\"bar\",figsize=(18,5))\nplt.title('Ca x Target')\nplt.xlabel('ca')\nplt.ylabel('N')\nplt.show()","660137d3":"lr = LogisticRegression(class_weight = 'balanced', solver = 'liblinear',penalty=\"l2\")\nlr.fit(x_train,y_train)\n\ny_prob = lr.predict_proba(x_test)[:,1] # This will give you positive class prediction probabilities  \ny_pred = np.where(y_prob > 0.5, 1, 0) # This will threshold the probabilities to give class predictions.\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nplt.figure(figsize=(10,8))\nplt.plot(false_positive_rate,true_positive_rate, color='red',label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],linestyle='--')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\n\nprint(\"acc:\",accuracy_score(y_test,y_pred))\nprint(\"recall:\",recall_score(y_test,y_pred))","f1950cf9":"#Transform the data in float and print the number of features\nx_train = x_train.astype(float) \nx_test = x_test.astype(float) \n\n\ny_train = to_categorical(y_train,2) \ny_test =  to_categorical(y_test,2) \n\nx_train.shape, x_test.shape, y_train.shape , y_test.shape","c47a9115":"#Starting Neural network\nmodel = Sequential()\n\n\n#First hidden\nmodel.add(Dense(5 #number of neurals in the first hidden\n                ,activation = 'relu' \n                ,input_shape = (23,) #Number of features that my model will receive\n                ))\n\n\n\n#out hidden\nmodel.add(Dense(2 #number of class\n                ,activation = 'softmax' #its will show me the probrably in the each class\n                ))\n\n\n#summary the model\nmodel.summary()\n","bf651a5e":"#Compile the first Neural Network\nmodel.compile(\n                loss='categorical_crossentropy' \n               ,optimizer='adam' \n               ,metrics=['accuracy'] \n)\n\nhistory = model.fit(x_train,y_train\n         ,epochs=100\n         ,batch_size =32\n         ,verbose = 1\n         ,validation_data=(x_test,y_test)\n         )","a41b825a":"#Predict the x_test\np = model.predict(x_test)\np = (p > 0.5)\nprint('ACC: %.3f%%' % (accuracy_score(y_test, p)*100))\nprint('---------')\nprint(classification_report(y_test, p))","aa7719f0":"plt.subplots(figsize=(13, 8))\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","1429a25c":"plt.subplots(figsize=(13, 8))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","08edda4b":"### 2) Try Neural Network","1f410943":"# Feature Importance using decision tree","bb5a9beb":"### Plotting the frequency of categorical features","9cc7f7bc":"### Plotting Model Loss","55f26820":"### Plotting the frenquency of thal fixed in target","1d0be770":"# Import Data","b63376c8":"# Split in train and test data","06bc2bb7":"# Data Preparation + Feature Enginnering","3b2193a2":"### Plotting the frequency and distribution of age by target","21e7f5e0":"### Correlation between numeric features","d2880b88":"# Modeling","634be795":"Steps:\n\nImport Data\n\nExploratory Data Analysis\n\nData Preparation + Feature Enginnering\n\nSplit data in train and test\n\nFeature importance using decision tree\n\nTry Logistic Regresion\n\nTry Neural Network","d1e7ef81":"### Plotting Model Accurancy","1dd10445":"### Plotting the frenquency of ca in target","d881343d":"### 1) Try logistic Regression","6b4c7e86":"# Exploratory Data Analysis","97e48232":"### Plotting distribution of numeric features"}}