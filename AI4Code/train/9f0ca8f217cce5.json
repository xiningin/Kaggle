{"cell_type":{"9702fef4":"code","bfebb354":"code","f42072a5":"code","04de8476":"code","3950ad3f":"code","fe47c697":"code","1935ae56":"code","4ca88478":"code","34bb7608":"code","8a137c00":"code","f5b266c1":"code","8175f204":"code","e2b6e11c":"code","8a3c6889":"code","9217f40e":"markdown","cce0afa1":"markdown","7c15c63e":"markdown","9972b1f8":"markdown","5705c2f7":"markdown","8544a35f":"markdown","a78d6663":"markdown","d723b435":"markdown"},"source":{"9702fef4":"import pathlib\nimport collections\nimport itertools\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\nfrom sklearn import model_selection, linear_model, metrics\nfrom sklearn.preprocessing import LabelEncoder","bfebb354":"data_folder = pathlib.Path(\"..\/input\/tabular-playground-series-feb-2021\")\nlist(data_folder.iterdir())","f42072a5":"train_filepath = data_folder \/ \"train.csv\"\ntest_filepath = data_folder \/ \"test.csv\"\nsubmission_filepath = data_folder \/ \"sample_submission.csv\"","04de8476":"train_df = pd.read_csv(train_filepath)\ntest_df = pd.read_csv(test_filepath)\n\nprint(f\"Total train feats: {len(train_df.columns)}, Features names: {list(train_df.columns)}\\n\")\nprint(f\"Total test feats: {len(test_df.columns)}, Features names: {list(test_df.columns)}\")","3950ad3f":"train_df.describe()","fe47c697":"fig = plt.figure(figsize=(15, 15))\n\naxes = fig.subplots(7, 4).ravel()\n\nfor i, column in enumerate(train_df.columns):\n    if \"cont\" in column:\n        x_pos = np.linspace(0, 1, 100)\n        kde = stats.gaussian_kde(train_df.loc[:, column].values)(x_pos)\n\n        axis = axes[i]\n        axis.plot(x_pos, kde, color=\"b\", linewidth=1.5)\n        axis.fill_between(x_pos, kde, color=\"b\", alpha=0.5)\n        \n        axis.set_title(f\"Feature: {column}\")\n        axis.set_xlabel(f\"x\")\n        axis.set_ylabel(f\"kde\")\n    if \"cat\" in column:\n        value_counts = train_df.loc[:, column].value_counts().to_dict()\n        labels, count = value_counts.keys(), value_counts.values()\n        \n        axis = axes[i]\n        axis.bar(labels, count)\n        \n        axis.set_xticks(range(len(labels)))\n        axis.set_xticklabels(labels, rotation=-10)\n        axis.set_title(f\"Feature: {column}\")\n        axis.set_xlabel(\"Categories\")\n        axis.set_ylabel(\"count\")\n    \nfig.suptitle(\"Feature distributions\")\nfig.show()\nfig.tight_layout()","1935ae56":"df_corr = train_df.drop([\"id\"], axis=1).corr()\nfor x_idx, y_idx in itertools.product(range(len(df_corr.index)), range(len(df_corr.columns))):\n    if x_idx <= y_idx:\n        df_corr.loc[df_corr.index[x_idx], df_corr.columns[y_idx]] = 0","4ca88478":"fig = plt.figure(figsize=(15, 15))\nax = fig.add_subplot(111)\n\nimg = ax.imshow(df_corr.values, cmap=\"plasma\")\nfig.colorbar(img, ax=ax)\n\nax.set_title(\"Continuous feature correlations\")\nax.set_xlabel(\"continuous features\")\nax.set_ylabel(\"continuous features\")\n\nax.set_xticks(range(len(df_corr.index)))\nax.set_yticks(range(len(df_corr.columns)))\n\nax.set_xticklabels(df_corr.index, rotation=20)\nax.set_yticklabels(df_corr.columns, rotation=20)\n\nfig.tight_layout()\nfig.show()","34bb7608":"def label_encoder(train_df, test_df):\n    \"\"\"\n    Function used for label encoding. Inspiried from: https:\/\/www.kaggle.com\/rizdelhi\/tabular-playground-competition-feb-21#Read-in-the-data-files\n    \"\"\"\n    for column in train_df.columns:\n        if \"cat\" in column:\n            lbl = LabelEncoder()\n            lbl.fit(np.hstack((train_df.loc[:, column].values, test_df.loc[:, column].values)))\n\n            train_df.loc[:, column] = lbl.transform(train_df.loc[:, column].values)\n            test_df.loc[:, column] = lbl.transform(test_df.loc[:, column].values)\n    return train_df, test_df","8a137c00":"train_df, test_df = label_encoder(train_df, test_df)","f5b266c1":"x_train, y_train = train_df.drop([\"id\", \"target\"], axis=1).values, train_df.loc[:, \"target\"].values","8175f204":"reg = linear_model.LinearRegression()\nreg.fit(x_train, y_train)","e2b6e11c":"y_preds = reg.predict(test_df.drop([\"id\"], axis=1))\ndf_submission = pd.read_csv(submission_filepath)\ndf_submission.loc[:, \"target\"] = y_preds","8a3c6889":"submission_filename = submission_filepath.name\ndf_submission.to_csv(submission_filename, index=False)","9217f40e":"There are a lot of under-represented categories in the data. Hopefully, the ML algorithm will learn the difference without us interfering alot.","cce0afa1":"### Train a base linear regressor","7c15c63e":"## Visualise data","9972b1f8":"## Basic aggreagate stats","5705c2f7":"#### Feature distributions","8544a35f":"### Correlation matrix","a78d6663":"Since the data is not highly correlated. We can safely move onto training the regressor, without much feature engineerng dedicated towards reducing the redundancy of data.","d723b435":"## Transform features\/ encode categorical features"}}