{"cell_type":{"6f1c9137":"code","33589095":"code","6de09f0f":"code","e7161a57":"code","bf19a142":"markdown","b47a084f":"markdown","d459ecbb":"markdown","00bd2b54":"markdown","122cae90":"markdown","b5bef48a":"markdown"},"source":{"6f1c9137":"# This Python 3 environment is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# Input data files are available in the \"..\/input\/\" directory.\nimport os\nimport json\nimport os\nfrom collections import defaultdict as dd\nimport pandas as pd\n\ncounter = dd(list)\ncounter_files = 0\ncounter_empty_docs = 0\n\n# run on last version\npath = '\/kaggle\/input\/cord19-expertsystem-mesh\/cord19_expertsystem_mesh_060320'\nfor dirname, _, filenames in os.walk(path):\n    if 'json' in dirname:\n        print(f\"{'\/'.join(dirname.split('\/')[-2:])} has {len(filenames)} files\")\n    for filename in filenames:\n        if not filename.endswith('.json'):\n            continue\n        with open(os.path.join(dirname, filename), 'r') as si:\n            json_data = json.loads(si.read())\n            counter_empty_keys = []\n            counter_files += 1\n            for key in json_data:\n                if json_data[key]:\n                    # we are only interested in knowing if the information is present\n                    if key in ('language', 'cord_uid', 'paper_id'):\n                        counter[key].append(1)\n                    # for other fields, we want to know how many extractions for the current paper\n                    else:\n                        counter[key].append(len(json_data[key]))\n                else:\n                    counter_empty_keys.append(key)\n            if len(counter_empty_keys) >= 4:\n                counter_empty_docs += 1\n                \nprint(f\"Total files: {counter_files}\")","33589095":"from pprint import pprint\npprint(json_data)","6de09f0f":"pprint(json_data.keys())","e7161a57":"data = dd(list)\nheaders = ['field', 'presence in files', 'extractions (sum)', 'extractions (mean)']\nfor field, extractions in counter.items():\n    sum_total_extractions = sum(extractions)\n    total_extractions = len(extractions)\n    mean_extractions = f\"{sum_total_extractions \/ total_extractions:.2f}\"\n    availability = f\"{len(extractions) \/ counter_files * 100:.2f}\"\n\n    contents = [field, availability, sum_total_extractions, mean_extractions]\n    for header, value in zip(headers, contents):\n        data[header].append(value)\n\ndf = pd.DataFrame(dict(data))\ndf['extractions (sum)'] = df.apply(lambda x: \"{:,.0f}\".format(x['extractions (sum)']), axis=1)\nprint(df.head(10))\n        ","bf19a142":"# How to use this dataset\nThe dataset is released as JSON files, mirroring the same folder structure of official CORD-19. \nThe JSON files are named as the original JSONs, making the pairing with CORD-19 JSON files straightforward.\n\nIn particular, the following fields are to be used to match the two datasets and refer to the column fields in CORD-19 metadata.csv:\n\n* **cord_uid**: 8-char alphanumeric string unique to each entry of CORD-19 dataset, persistent across versions;\n* **paper_id**: paper identifier. If the original source is PDF, this corresponds to \"sha\" in metadata.csv, otherwise to \"pmcid\" if PMC xml.","b47a084f":"Let's open one of the files to see what the JSON looks like:","d459ecbb":"For the sake of clarity, the following are the attributes accessible for this JSON file:","00bd2b54":"Stay tuned! More notebooks will follow on how to make better use of the data we've just got accustomed to.","122cae90":"For each file of CORD-19, the dataset we just loaded contains additional metadata. \n\n* MeSH_tax: follows the standard MeSH taxonomy;\n* extractions: relevant concepts found in text with respect to MeSH taxonomy;\n* relations: relations among the entities (diseases, biological processes, drugs, genes, proteins, organizations);\n* organizations, i.e. named entities that identify organizations of any kind somehow relevant for the medical domain;\n* geographical areas, i.e. countries and other locations with MeSH and\/or GeoNames ID;\n* dates, list of all dates found in full text;\n* language, stating the main language found looking at title, abstract and body of the json full texts.\n\nAs one can learn from the following table, MeSH-driven tags and extractions have been found for the vast majority of CORD-19 papers. For each paper, as many as 78 MeSH information and 51 extractions are found, on average. \n\nAs for other fields, each paper has an average of 6 extraction for both health-related organizations and geographic places.\n\nFinally, 3 out of 4 papers show relations between the MeSH entities recognized. ","b5bef48a":"# Intro\nThis notebook shows how to use CORD-19_ExpertSystem_MeSH.\nFirst, let's show the files in the input folder. They refer to [latest CORD-19 release (2020-05-01)]\n(http:\/\/www.kaggle.com\/allen-institute-for-ai\/CORD-19-research-challenge)"}}