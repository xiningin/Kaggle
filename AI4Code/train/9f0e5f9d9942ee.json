{"cell_type":{"ac3934fb":"code","dbd017d7":"code","cd3fe1bf":"code","3fe9eea4":"code","d3a9591b":"code","bf05858c":"code","0b0e9709":"code","e0fd9299":"markdown","a3a0c2d3":"markdown","3a53d1cd":"markdown"},"source":{"ac3934fb":"import os\nprint(os.listdir(\"..\/input\/pokemon-images-dataset\/\"))","dbd017d7":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.optim as optim","cd3fe1bf":"agriculture = \"..\/input\/pokemon-images-dataset\/pokemon\/\"\nprint(agriculture)\ndef imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\n\ndef resize2d(img, size):\n    return (F.adaptive_avg_pool2d(Variable(img, volatile=True), size)).data\n\n# a simple custom collate function, just to show the idea\ndef my_collate(batch):\n    data = torch.stack([item[0] for item in batch])\n    # data = torch.stack([resize2d(item[0], 224) for item in batch])\n    target = [item[1] for item in batch]\n    # AdaptiveAvgPooling\n    target = torch.LongTensor(target)\n    return [data, target]\n\ndef load_dataset(_transform=torchvision.transforms.ToTensor()):\n    # data_path = 'data\/train\/'\n    data_path = agriculture\n    train_dataset = torchvision.datasets.ImageFolder(\n        root=data_path,\n        transform=_transform,\n        # transform=train_transforms\n    )\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=16,\n        num_workers=0,\n        collate_fn=my_collate,  # use custom collate function here\n        shuffle=True\n    )\n    return train_loader\n\ndef show_transformed_images(_transform=torchvision.transforms.ToTensor()):\n    trainloader = load_dataset(_transform)\n    dataiter = iter(trainloader)\n    images, labels = dataiter.next()\n\n    # show images # Let us show some of the training images, for fun.\n    imshow(torchvision.utils.make_grid(images[0:1]))","3fe9eea4":"# this is original images\nshow_transformed_images()","d3a9591b":"# this is ColorJitter images\n# random application of brightness, contrast etc\nshow_transformed_images(_transform=torchvision.transforms.Compose(\n    [transforms.RandomAffine(90, translate=None, scale=(1.41,1.41), shear=None, resample=False, fillcolor=(255,0,0)),\n     transforms.ToTensor()]))","bf05858c":"# Add random affine transformation to \nshow_transformed_images(_transform=torchvision.transforms.Compose(\n    [transforms.RandomAffine(0, translate=None, scale=None, shear=(70,70), resample=False, fillcolor=(255,0,0)),\n     transforms.ToTensor()]))","0b0e9709":"# Add random affine transformation to Images\nx=2\nshow_transformed_images(_transform=torchvision.transforms.Compose(\n    [transforms.RandomAffine((1,90), translate=None, scale=(x,x), shear=(45,45), resample=False, fillcolor=(255,0,0)),\n     transforms.ToTensor()]))","e0fd9299":"* With Any degree of Rotation the image must be multiplied by **\u221a2** in order for the image to still be in the safe area.\n\n* With a shear the image must be enlarged by a","a3a0c2d3":"## Changes","3a53d1cd":"# Original Images"}}