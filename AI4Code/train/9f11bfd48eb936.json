{"cell_type":{"0452db08":"code","824b37c3":"code","a841c124":"code","eaf0b7ea":"code","f7e7f20c":"code","16f0d302":"code","c6063cad":"code","33da7cb8":"code","42be4d48":"code","4da424dc":"code","290cfc97":"code","5435a3c3":"code","c33fe61b":"code","9f575e38":"code","710cc9be":"code","f175ced4":"code","9a39dbe8":"code","9bb1be84":"code","4fb7ff06":"code","bf37d443":"code","d00e7829":"code","146b5f07":"code","e1878c45":"code","244149e7":"code","aa3a21d0":"code","f0f8433c":"code","48256a5a":"code","a5d2003b":"code","db5223a7":"code","8d7ab4ca":"code","28454dcd":"code","921a8261":"code","9dee6d43":"code","b4e03887":"code","16e0966f":"code","eec3688c":"code","704ad5e3":"markdown","948e9a40":"markdown","83286b7e":"markdown","c64fc9ff":"markdown","8c4993eb":"markdown","69d4ed84":"markdown","8fee4dd6":"markdown","d1b953b7":"markdown","4c7fde62":"markdown","d24c1794":"markdown","7ac74c23":"markdown","b5a5eaa0":"markdown","b5c4f65c":"markdown","fe091952":"markdown","a2ab557a":"markdown","3fb4e475":"markdown","d847091a":"markdown","102d6a8d":"markdown","ed0cc16d":"markdown"},"source":{"0452db08":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\n\nroot_path = '\/kaggle\/input\/brazilian-ecommerce\/'\n\ncustomers_df = pd.read_csv(root_path + 'olist_customers_dataset.csv')\nitems_df = pd.read_csv(root_path + 'olist_order_items_dataset.csv')\npayments_df = pd.read_csv(root_path + 'olist_order_payments_dataset.csv')\norders_df = pd.read_csv(root_path + 'olist_orders_dataset.csv')\nproducts_df = pd.read_csv(root_path + 'olist_products_dataset.csv')\nsellers_df = pd.read_csv(root_path + 'olist_sellers_dataset.csv')\ncategories_df = pd.read_csv(root_path + 'product_category_name_translation.csv')","824b37c3":"customers_df.head(2)","a841c124":"items_df.head(2)","eaf0b7ea":"payments_df.head(2)","f7e7f20c":"orders_df.head(2)","16f0d302":"products_df.head(2)","c6063cad":"sellers_df.head(2)","33da7cb8":"categories_df.head(2)","42be4d48":"dataframes = {'customers': customers_df,\n              'items': items_df, \n              'payments': payments_df, \n              'orders': orders_df, \n              'products': products_df, \n              'sellers': sellers_df, \n              'categories': categories_df}\nfor i, j in dataframes.items():\n    print(f'{i:12s} dataframe: {str(len(j)):7s} rows')","4da424dc":"# products_df contains 73 unique categories, while categories_df contains 71: that's why we use left, \n# for missing categories we keep the category name in Portuguese.\nproducts_df = pd.merge(products_df, categories_df, on='product_category_name', how='left')\n# Delete 'product_category_name' column\ndel products_df['product_category_name']\n# Delete  the categories_df dataframe\ndel categories_df\n# Rename the column\nproducts_df.rename(columns={'product_category_name_english': 'product_category'}, inplace=True)","290cfc97":"customers = customers_df['customer_unique_id'].nunique()\norders = orders_df.order_id.nunique()\nprint(\"number of customers:\", customers)\nprint(\"number of orders:   \", orders)\nprint(f\"number of orders per cusotmer: {orders \/ customers:.2f}\")","5435a3c3":"df = pd.merge(orders_df, customers_df, on='customer_id')\ndf = df.merge(items_df, on='order_id')\ndf = df.merge(payments_df, on='order_id')\ndf = df.merge(products_df, on='product_id')\ndf = df.merge(sellers_df, on='seller_id')\ndf.head(3)","c33fe61b":"customer_by_state = df[['customer_unique_id', 'customer_state']].groupby('customer_state').count().reset_index()\ncustomer_by_state = customer_by_state.sort_values(by=['customer_unique_id'])\n\nplt.style.use('seaborn')\nplt.figure(figsize=(15,10))\nplt.bar(customer_by_state['customer_state'], customer_by_state['customer_unique_id'])\nplt.show()","9f575e38":"# We 3 new columns\ndf['order_purchase_year'] = pd.to_datetime(df['order_purchase_timestamp']).dt.year\ndf['order_purchase_month'] = pd.to_datetime(df['order_purchase_timestamp']).dt.month\ndf['order_purchase_day'] = pd.to_datetime(df['order_purchase_timestamp']).dt.day\ndf['order_purchase_hour'] = pd.to_datetime(df['order_purchase_timestamp']).dt.hour\n\norders = df[['order_id', 'order_purchase_year', 'order_purchase_month']]\norders = orders.groupby(['order_purchase_month', 'order_purchase_year']).count().reset_index()\norders = orders.sort_values(by=['order_purchase_year', 'order_purchase_month'])\norders[\"period\"] =  orders[\"order_purchase_month\"].astype(str) + \"\/\" + orders[\"order_purchase_year\"].astype(str)\norders.head(3)","710cc9be":"plt.figure(figsize=(15,10))\nplt.bar(orders['period'], orders['order_id'])\nplt.xticks(rotation=75, fontsize=15, weight='bold')\nplt.yticks(fontsize=15, weight='bold')\nplt.show()","f175ced4":"orders.groupby(['order_purchase_year']).sum()","9a39dbe8":"top_categories = df[['product_category', 'order_item_id']]\ntop_categories = top_categories.groupby(['product_category']).sum().sort_values(by=['order_item_id'], ascending=False).reset_index()\ntop_categories[:10]","9bb1be84":"plt.figure(figsize=(15,10))\nplt.bar(top_categories['product_category'][:10], top_categories['order_item_id'][:10])\nplt.title('Number of products sold per category')\nplt.xticks(rotation=75, fontsize=15, weight='bold')\nplt.yticks(fontsize=15, weight='bold')\nplt.show()","4fb7ff06":"columns = ['order_status', 'customer_state', 'order_item_id', 'price', \n           'freight_value', 'payment_sequential', 'payment_type', 'payment_installments', 'payment_value', \n           'order_purchase_year', 'order_purchase_month', 'order_purchase_day', 'order_purchase_hour']\ndf = df[columns]\ndf.head()","bf37d443":"df.info()","d00e7829":"df.describe()","146b5f07":"df.isnull().any()","e1878c45":"from sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\n\nnum_attributes = ['order_item_id', 'price', 'freight_value', 'payment_sequential', 'payment_installments', \n                  'payment_value', 'order_purchase_year', 'order_purchase_month', 'order_purchase_day', 'order_purchase_hour']\ncat_attributes = ['order_status', 'customer_state', 'payment_type']\n\npipeline = ColumnTransformer([\n        ('num', StandardScaler(), num_attributes),\n        ('cat', OneHotEncoder(), cat_attributes),\n])\ndf_prepared = pipeline.fit_transform(df)\ndf_prepared","244149e7":"df_prepared.shape","aa3a21d0":"df_prepared = df_prepared.toarray()","f0f8433c":"from sklearn.decomposition import PCA\n\n# Preserving 95% of the variance\npca = PCA(n_components=0.95)\ndf_reduced = pca.fit_transform(df_prepared)\ndf_reduced.shape","48256a5a":"from sklearn.cluster import KMeans\n\nk_range = range(2, 15)\nkmeans_per_k = [KMeans(n_clusters=k, random_state=42).fit(df_reduced)\n                for k in k_range]\ninertias = [model.inertia_ for model in kmeans_per_k]","a5d2003b":"plt.figure(figsize=(15, 8))\nplt.plot(k_range, inertias, 'bo-')\nplt.xlabel('K', fontsize=16)\nplt.ylabel('Inertia', fontsize=16)\nplt.show()","db5223a7":"from sklearn.metrics import silhouette_score\n\nsilhouette_scores = [silhouette_score(df_reduced, model.labels_)\n                      for model in kmeans_per_k]","8d7ab4ca":"best_index = np.argmax(silhouette_scores)\nbest_k = k_range[best_index]\nbest_score = silhouette_scores[best_index]\n# Best number of clusters\nbest_k","28454dcd":"plt.figure(figsize=(10, 5))\nplt.plot(range(2, 15), silhouette_scores, \"bo-\")\nplt.xlabel(\"k\", fontsize=14)\nplt.ylabel(\"Silhouette score\", fontsize=14)\nplt.plot(best_k, best_score, 'rs')\nplt.show()","921a8261":"best_model = kmeans_per_k[best_index]\nbest_model","9dee6d43":"y_pred = best_model.fit_predict(df_reduced)","b4e03887":"for i in range(best_k):\n    print(f\"cluster {i + 1} contains: {np.sum(y_pred == i)} customers\")","16e0966f":"from sklearn.manifold import TSNE\n\ntsne = TSNE(n_components=2, random_state=42)\ndf_reduced = tsne.fit_transform(df_prepared)","eec3688c":"plt.figure(figsize=(13,10 ))\nplt.scatter(df_reduced[:, 0], df_reduced[:, 1],c=y_pred, cmap=\"jet\")\nplt.axis('off')\nplt.colorbar()\nplt.show()","704ad5e3":"**Check for null values**","948e9a40":"Almost all customers made only 1 order.\n\n**Merge all other dataframes**","83286b7e":"**Top 10 categories**","c64fc9ff":"# Prepare the Data for the Model\n\nLet's select the attributes that we want to keep:","8c4993eb":"We can see that most customers are from SP (I think this is Sao Paulo)\n\n**Number of orders per year and month**","69d4ed84":"It looks like that the optimal number of cluster on this inertia diagram is somewhere between 5 and 10","8fee4dd6":"## Build a full pipeline for preprocessing numerical and categorical attributes\n\nWe have 3 categorical attributes: order_status, customer_state, and payment_type. We will convert these categories using Scikit-learn's OneHotEncoder class:","d1b953b7":"In this notebook, we are going tu use the [Brazilian E-commerce Dataset](https:\/\/www.kaggle.com\/olistbr\/brazilian-ecommerce) to do a customer segmentation. The dataset contains 100k orders from 2016 to 2018. An order might have mutiple items and each item might be fulfilled by a distinct seller.\n\nThe dataset is divided into 9 files:\n<table>\n  <tr>\n    <th style=\"text-align: left;\">File Name<\/th>\n    <th style=\"text-align: left;\">Description<\/th>\n    <th style=\"text-align: left;\">Number of Columns<\/th>\n  <\/tr>\n  <tr>\n    <td style=\"text-align: left;\">olist_customers_dataset.csv<\/td>\n    <td style=\"text-align: left;\">Contains information about a customer and its location    <\/td>\n    <td style=\"text-align: left;\">5 columns<\/td>\n  <\/tr>\n  <tr>\n    <td style=\"text-align: left;\">olist_geolocation_dataset.csv<\/td>\n    <td style=\"text-align: left;\">Contains Brazilian zip codes (sellers and customers) and its lat\/lang coordinates<\/td>\n    <td style=\"text-align: left;\">5 columns<\/td>\n  <\/tr>\n  <tr>\n    <td style=\"text-align: left;\">olist_order_items_dataset.csv<\/td>\n    <td style=\"text-align: left;\">Contains information about the items purchased within each order  <\/td>\n    <td style=\"text-align: left;\">7 columns<\/td>\n  <\/tr>\n  <tr>\n    <td style=\"text-align: left;\">olist_order_payments_dataset.csv<\/td>\n    <td style=\"text-align: left;\">Contains information about the orders payment options<\/td>\n    <td style=\"text-align: left;\">5 columns<\/td>\n  <\/tr>\n  <tr>\n    <td style=\"text-align: left;\">olist_order_reviews_dataset.csv<\/td>\n    <td style=\"text-align: left;\">Contains information about the reviews made by the customers<\/td>\n    <td style=\"text-align: left;\">7 columns<\/td>\n  <\/tr>\n  <tr>\n    <td style=\"text-align: left;\">olist_orders_dataset.csv<\/td>\n    <td style=\"text-align: left;\">This is the core dataset<\/td>\n    <td style=\"text-align: left;\">8 columns<\/td>\n  <\/tr>\n  <tr>\n    <td style=\"text-align: left;\">olist_products_dataset.csv<\/td>\n    <td style=\"text-align: left ;\">Contains information about the products sold by Olist<\/td>\n    <td style=\"text-align: left;\">9 columns<\/td>\n  <\/tr>\n    <tr>\n    <td style=\"text-align: left;\">olist_sellers_dataset.csv<\/td>\n    <td style=\"text-align: left;\">Contains information about the sellers<\/td>\n    <td style=\"text-align: left;\">4 columns<\/td>\n  <\/tr>\n    <tr>\n    <td style=\"text-align: left;\">product_category_name_translation.csv<\/td>\n    <td style=\"text-align: left;\">Translates the productcategoryname to english <\/td>\n    <td style=\"text-align: left;\">2 columns<\/td>\n  <\/tr>\n<\/table>\n<br><br>\n\n\n\nSince in this project I am only focusing on customer segmentation, I will not use the file **olist_order_reviews_dataset.csv**.","4c7fde62":"We can see that the best number of clusters is 4, let's pick the best model:","d24c1794":"# Data Analysis","7ac74c23":"### Clustring Using KMeans\n\nfirst, we will plot the inertia as a function of the number of clusters to get a quick overview of the optimal number of clusters","b5a5eaa0":"**How many customers, orders, and orders per customer do we have?**","b5c4f65c":"# Import librarires and Load the Datasets","fe091952":"The output is a sparse matrix. This is useful when there are thousands of categories because onehot encoding converts these categories to a matrix full of zeros except for a single 1 per row. storing such a matrix takes to much memory, so instead a sparse matrix only stores the location of the nonzero elements.\n\nIn our case, we need to convert this sparse matrix to a numpy array because we need to perform a dimensionality reduction with PCA (PCA does not support sparse input):","a2ab557a":"Now that we have the clusters, we can get the average depense per cluster, the preferred category of each cluster (I removed the product categories due to the high computational cost) and so on and, for example, do some advertisements or offers specific to each cluster.\n\nFinally, let's try to plot each cluster using TSNE","3fb4e475":"### Dimensionality Reduction","d847091a":"**Merge categories_df and product_df dataframes to use the English names**","102d6a8d":"We can see that the year 2018 was the year with the most orders, let's confirm that:","ed0cc16d":"**Customers by state**"}}