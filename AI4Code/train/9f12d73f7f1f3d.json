{"cell_type":{"75192a43":"code","6e868412":"code","4f3df33e":"code","4eaa0a0c":"code","46fb1be2":"code","2538a813":"code","97b87c93":"code","4073eb96":"code","fe9cc151":"code","591bf1b9":"code","3ce8b478":"code","4d7ffaa1":"code","d7483c26":"code","5b585bf5":"code","603d0387":"code","000ae392":"markdown","359657e8":"markdown","b0d55cf6":"markdown","0fe6d359":"markdown","7ccc5c98":"markdown"},"source":{"75192a43":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier","6e868412":"data = pd.read_csv('..\/input\/loandata\/Loan payments data.csv')","4f3df33e":"data","4eaa0a0c":"data.info()","46fb1be2":"data.isna().sum()","2538a813":"data['loan_status'].unique()","97b87c93":"{column: len(data[column].unique()) for column in data.columns}","4073eb96":"def binary_encode(df, column, positive_value):\n    df = df.copy()\n    df[column] = df[column].apply(lambda x: 1 if x == positive_value else 0)\n    return df\n\ndef ordinal_encode(df, column, ordering):\n    df = df.copy()\n    df[column] = df[column].apply(lambda x: ordering.index(x))\n    return df","fe9cc151":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop Loan_ID column\n    df = df.drop('Loan_ID', axis=1)\n    \n    # Create date\/time columns\n    for column in ['effective_date', 'due_date', 'paid_off_time']:\n        df[column] = pd.to_datetime(df[column])\n    \n    df['effective_day'] = df['effective_date'].apply(lambda x: x.day)\n    \n    df['due_month'] = df['due_date'].apply(lambda x: x.month)\n    df['due_day'] = df['due_date'].apply(lambda x: x.day)\n    \n    df['paid_off_month'] = df['paid_off_time'].apply(lambda x: x.month)\n    df['paid_off_day'] = df['paid_off_time'].apply(lambda x: x.day)\n    df['paid_off_hour'] = df['paid_off_time'].apply(lambda x: x.hour)\n    \n    df = df.drop(['effective_date', 'due_date', 'paid_off_time'], axis=1)\n    \n    # Fill missing values with column means\n    for column in ['past_due_days', 'paid_off_month', 'paid_off_day', 'paid_off_hour']:\n        df[column] = df[column].fillna(df[column].mean())\n    \n    # Binary encode the Gender column\n    df = binary_encode(df, 'Gender', positive_value='male')\n    \n    # Ordinal encode the education column\n    education_ordering = [\n        'High School or Below',\n        'college',\n        'Bechalor',\n        'Master or Above'\n    ]\n    df = ordinal_encode(df, 'education', ordering=education_ordering)\n    \n    # Encode the label (loan_status) column\n    label_mapping = {'COLLECTION': 0, 'PAIDOFF': 1, 'COLLECTION_PAIDOFF': 2}\n    df['loan_status'] = df['loan_status'].replace(label_mapping)\n    \n    # Split df into X and y\n    y = df['loan_status'].copy()\n    X = df.drop('loan_status', axis=1).copy()\n    \n    # Scale X with a standard scaler\n    scaler = StandardScaler()\n    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n    \n    return X, y","591bf1b9":"X, y = preprocess_inputs(data)","3ce8b478":"X","4d7ffaa1":"y","d7483c26":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)","5b585bf5":"models = [\n    LogisticRegression(),\n    SVC(),\n    DecisionTreeClassifier(),\n    MLPClassifier(),\n    RandomForestClassifier(),\n    XGBClassifier()\n]\n\nfor model in models:\n    model.fit(X_train, y_train)","603d0387":"model_names = [\n    \"   Logistic Regression\",\n    \"Support Vector Machine\",\n    \"         Decision Tree\",\n    \"        Neural Network\",\n    \"         Random Forest\",\n    \"               XGBoost\"\n]\n\nfor model, name in zip(models, model_names):\n    print(name + \": {:.4f}%\".format(model.score(X_test, y_test) * 100))","000ae392":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/J3_oKCySC7Y","359657e8":"# Training","b0d55cf6":"# Task for Today  \n\n***\n\n## Loan Payment Prediction  \n\nGiven *data about loans*, let's try to predict whether a given loan will be **paid off** or not.  \n  \nWe will use six different models to make our predictions.","0fe6d359":"# Getting Started","7ccc5c98":"# Preprocessing"}}