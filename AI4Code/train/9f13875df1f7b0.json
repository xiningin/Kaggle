{"cell_type":{"d0625ef8":"code","303ec74c":"code","84f8f07c":"code","1060c053":"code","7a41a6cf":"code","700988d6":"code","c9ce8642":"code","5ea255f7":"code","cfb99bde":"code","111a33d0":"code","b415a22a":"code","b7cc1a72":"code","fa181a6f":"code","d494d417":"code","f1aeb245":"code","8378a279":"code","0d11243a":"code","2fc3d658":"code","9a64a11c":"code","1f04b677":"code","cc3a6521":"code","bf2b99d9":"code","e1e1fb54":"code","a5461c3f":"code","24ebf3dc":"markdown","4c4bb00f":"markdown","242590b4":"markdown","4bcc214d":"markdown","5e4cd011":"markdown","a3cc4390":"markdown","c4810200":"markdown"},"source":{"d0625ef8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","303ec74c":"df1 = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")\ndf1.head()","84f8f07c":"df1.shape","1060c053":"test = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")\ntest.head()","7a41a6cf":"test.shape","700988d6":"import tensorflow as tf\nfrom tensorflow import keras \nimport numpy as np\n","c9ce8642":"x_train = df1.drop([\"label\"], axis =1)\ny_train = df1[\"label\"]\n\nx_test = test.drop([\"label\"], axis = 1)\ny_test = test[\"label\"]","5ea255f7":"x_train = np.array(x_train)\nx_test = np.array(x_test)","cfb99bde":"x_train = x_train\/255\nx_test = x_test\/255","111a33d0":"x_train.shape","b415a22a":"x_train[0].shape","b7cc1a72":"len(x_train)","fa181a6f":"x_train = x_train.reshape(-1,28,28,1)\nx_test = x_test.reshape(-1,28,28,1)\n","d494d417":"from keras.utils import to_categorical\ny_train=to_categorical(y_train,num_classes=len(set(y_train)))\ny_test =to_categorical(y_test,num_classes=len(set(y_test)))","f1aeb245":"y_train.shape","8378a279":"x_train.shape","0d11243a":"def b_model(hp):\n    model = keras.Sequential([\n        keras.layers.Conv2D(filters = hp.Int(\"conv_1_filter\",min_value = 32,max_value = 128,step = 16),\n                           kernel_size = hp.Choice(\"conv_1_kernel\", values = [3,5]),\n                            activation = \"relu\",\n                            input_shape = (28,28,1)\n                           ),\n        keras.layers.Conv2D(filters = hp.Int(\"conv_2_filter\",min_value = 32,max_value = 64,step = 16),\n                           kernel_size = hp.Choice(\"conv_2_kernel\", values = [3,5]),\n                            activation = \"relu\",\n                           ),\n        keras.layers.Flatten(),\n        keras.layers.Dense(\n        units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),\n        activation='relu'),\n        keras.layers.Dense(10, activation='softmax')\n           \n    ])\n    model.compile(optimizer = keras.optimizers.Adam(hp.Choice(\"learning_rate\",values = [1e-2, 1e-3])), \n                  loss =\"categorical_crossentropy\", \n                 metrics = ['accuracy'])\n    return model\n    ","2fc3d658":"from kerastuner import RandomSearch\nfrom kerastuner.engine.hyperparameters import HyperParameters","9a64a11c":"tuner_search = RandomSearch(b_model,objective =\"val_accuracy\",max_trials =5, directory = \"output\", project_name = \"Mnist\" )","1f04b677":"tuner_search.search(x_train,y_train,epochs = 3,validation_split = 0.1)","cc3a6521":"model = tuner_search.get_best_models(num_models = 1)[0]","bf2b99d9":"model.summary()","e1e1fb54":"history = model.fit(x_train,y_train,epochs = 10,validation_split = 0.1,initial_epoch = 3)","a5461c3f":"score = model.evaluate(x_test,y_test)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","24ebf3dc":"# Categoricalizing the TARGET Variable","4c4bb00f":"# We see that the model is showing 91.6% accuracy for the test data. ","242590b4":"# Normalization ","4bcc214d":"# Reshaping the Data","5e4cd011":"# Converting dataset into an array","a3cc4390":"# Splitting Data to train and test","c4810200":"# Model Building and HyperParameter Tuning"}}