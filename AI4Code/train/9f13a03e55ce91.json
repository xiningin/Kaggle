{"cell_type":{"29a65201":"code","c0bf9c1f":"markdown"},"source":{"29a65201":"import numpy as np\nimport pandas as pd\nfrom collections import Counter\nfrom operator import itemgetter\n\nclass KNN:\n    \n    def __init__(self, X, y, K = None, inverse_weighted=False, l2_norm = True):\n        self.X = np.array(X)\n        self.y = y\n        self.K = K\n        if (self.K is None):\n            self.K = int(np.floor(np.sqrt(self.X.shape[0])))\n        self._inverse_weighted = inverse_weighted\n        self.l2_norm = l2_norm\n        \n    def _euclidean(self, x1, x2):\n        return np.sqrt(np.dot(x1 - x2, x1 - x2))\n    \n    def _manhattan(self, x1, x2):\n        return np.sum(np.absolute(x1 - x2))\n    \n    def _distances(self, x):\n        distances = []\n        for index, row in enumerate(self.X):\n            distances.append((index, self._euclidean(x, row) if self.l2_norm else self._manhattan(x, row)))\n        return distances\n\n    def _predict_instance_non_weighted(self, x):\n        distances = self._distances(x)\n        votes = [x[0] for x in sorted(distances, key=lambda y: y[1])][:self.K]\n        cntr = Counter(votes)\n        return y[cntr.most_common(1)[0][0]]\n                          \n    def _predict_instance_weighted(self, new_data):\n        distances = self._distances(new_data)\n        epsilon = 1e-5\n        cw = [(self.y[t[0]], 1\/(t[1] + epsilon)) for t in sorted(distances, key=lambda x: x[1])[:self.K]]\n        vote_dict = {}\n        for c, w in cw:\n            if c in vote_dict:\n                vote_dict[c] += w\n            else:\n                vote_dict[c] = w\n        return max(vote_dict.items(), key=itemgetter(1))[0]\n    \n    def predict(self, new_data):\n        new_data = np.array(new_data)\n        if new_data.ndim == 1:\n            if self._inverse_weighted:\n                return self._predict_instance_weighted(new_data)\n            else:\n                return self._predict_instance_non_weighted(new_data)\n        else:\n            predictions = []\n            for x in new_data:\n                if self._inverse_weighted:\n                    predictions.append(self._predict_instance_weighted(x))\n                else:\n                    predictions.append(self._predict_instance_non_weighted(x))\n            return predictions\n  \n# if __name__ == \"__main__\":\n    \n#     iris = pd.read_csv(\"iris.csv\")\n\n#     X = iris.iloc[:, :4]\n#     y = iris[\"class\"]\n    \n#     knn = KNN(X=X, y=y, inverse_weighted=False, l2_norm=True)\n#     print(\"Automatically calculated K: \", knn.K)\n#     accuracy = sum(knn.predict(X) == y)\/len(y)\n#     print(\"Accuracy on entire dataset: {:.0%}\".format(accuracy))","c0bf9c1f":"# KNN Written from Scratch\n\n-Barrett Duna\n\nThis algorithm classifies new data points based on the K closest neighbors as measured by the euclidean distance. For a prediction, each distance is calculated between the new data point and the data points in the dataset and the K closest data points vote on the class."}}