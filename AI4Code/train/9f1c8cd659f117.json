{"cell_type":{"fd682188":"code","4bac77de":"code","fc37aeef":"code","f8a5815d":"code","8cb00725":"markdown","8c46326b":"markdown","528da52e":"markdown","17ce936f":"markdown"},"source":{"fd682188":"import os\nimport cv2\nimport numpy as np\nfrom time import time\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Input, Dense, Reshape, Flatten\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline","4bac77de":"train_dir = '..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train'\ntest_dir = '..\/input\/asl-alphabet\/asl_alphabet_test\/asl_alphabet_test'\nclasses = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', \n           'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', \n           'W', 'X', 'Y', 'Z', 'nothing', 'space', 'del']\nplt.figure(figsize=(11, 11))\nfor i in range (0,29):\n    plt.subplot(7,7,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    path = train_dir + \"\/{0}\/{0}1.jpg\".format(classes[i])\n    img = plt.imread(path)\n    plt.imshow(img)\n    plt.xlabel(classes[i])","fc37aeef":"def load_data(train_dir):\n    images = []\n    labels = []\n    size = 32,32\n    index = -1\n    for folder in os.listdir(train_dir):\n        index +=1\n        for image in os.listdir(train_dir + \"\/\" + folder):\n            temp_img = cv2.imread(train_dir + '\/' + folder + '\/' + image)\n            temp_img = cv2.resize(temp_img, size)\n            images.append(temp_img)\n            labels.append(index)\n    \n    images = np.array(images)\n    images = images.astype('float32')\/255.0\n    labels = utils.to_categorical(labels)\n    x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.1)\n    \n    print('Loaded', len(x_train),'images for training,','Train data shape =', x_train.shape)\n    print('Loaded', len(x_test),'images for testing','Test data shape =', x_test.shape)\n    \n    return x_train, x_test, y_train, y_test\n\nstart = time()\nx_train, x_test, y_train, y_test = load_data(train_dir)\nprint('Loading:', time() - start)","f8a5815d":"def autoencoder_train(encoder, decoder, data, epochs, batch, learning_rate=0.0001):\n    autoencoder = Sequential([encoder, decoder])\n    adam = Adam(lr=learning_rate)\n    autoencoder.compile(optimizer=adam, loss='mse')\n    start = time()\n    autoencoder.fit(data, data, epochs=epochs, batch_size=batch)\n    train_time = time() - start\n\n    return encoder, data, train_time\n\ndef FCNN(x_train, x_test, y_train, y_test, epochs, batch, neurons, learning_rate=0.001):\n    inp_image = Input(shape = (32, 32, 3))\n    vec_image = Flatten()(inp_image)\n    encoder_res = Dense(neurons, activation='sigmoid')(vec_image)\n\n    inp_decoder = Input(shape=(neurons,))\n    vec_decode = Dense(32*32*3, activation='sigmoid')(inp_decoder)\n    decoder_res = Reshape((32, 32, 3))(vec_decode)\n\n    encoder = Model(inp_image, encoder_res, name=\"encoder\")\n    decoder = Model(inp_decoder, decoder_res, name=\"decoder\")\n    encoder, x_train, ae_train_time = autoencoder_train(encoder, decoder, x_train, epochs, batch)\n\n    model = Sequential()\n    for layer in encoder.layers:\n        model.add(layer)\n\n    model.add(Dense(29, activation='softmax'))\n\n    adam = Adam(lr=learning_rate) \n    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n    model.summary()\n\n    start = time()\n    model.fit(x_train, y_train, epochs=epochs, batch_size=batch, validation_split=0.1, shuffle = True)\n    train_time = time() - start\n    print('\\nAutoencoder train_time: ', ae_train_time)\n    print('\\nFCNN Train time: ', train_time)\n    test_loss, test_acc = model.evaluate(x_test, y_test)\n    print('\\nFCNN Test accuracy: ', test_acc)\n    \nFCNN(x_train, x_test, y_train, y_test, epochs = 25, batch = 128, neurons = 1024)","8cb00725":"# ASL Alphabet Classification with FCNN + Autoencoder","8c46326b":"## The data","528da52e":"## Autoencoder","17ce936f":"## Loading"}}