{"cell_type":{"f201c9d8":"code","c2244100":"code","9418a9cc":"code","e1cb99d9":"code","40dfab7b":"code","f6db06e6":"code","68e801d4":"code","ffd0f801":"code","58efd221":"code","0f6fad2f":"code","593e19f9":"code","831cfe01":"code","57a979fd":"code","e7662e75":"code","25440579":"code","eb240bad":"code","f0161ce2":"code","050cd95e":"code","a2aa7aab":"code","4ca6ed5e":"code","4a883474":"code","c92503b9":"code","07fe3753":"code","cae62f18":"code","c38e60bb":"code","ce15a2e0":"code","c215f80c":"code","7c5a2370":"code","ae24e54e":"code","27d857b6":"code","64540890":"code","6c9c3f6f":"code","28ef6a87":"code","0df11421":"code","e9c8a352":"code","7dd8d80c":"code","5e58ae99":"code","1f221f10":"code","2b803b06":"code","542585a7":"code","b5dd58ac":"code","25a70558":"code","85ef6e66":"code","d4107830":"code","46f6319a":"code","b073f0a9":"code","43e06a4d":"code","5a675a38":"code","9ddbc6d1":"code","e55d499f":"code","a03d642a":"markdown","7b6d881d":"markdown","150ca1bd":"markdown","8c10e9de":"markdown","64f6db99":"markdown","2ae037d2":"markdown"},"source":{"f201c9d8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c2244100":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.layers import Dense,RepeatVector, LSTM, Dropout\nfrom tensorflow.keras.layers import Flatten, Conv1D, MaxPooling1D\nfrom tensorflow.keras.layers import Bidirectional, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.utils import plot_model","9418a9cc":"df = pd.read_csv(\"\/kaggle\/input\/delhi-weather-data\/testset.csv\")","e1cb99d9":"df.head()","40dfab7b":"df[' _conds'].value_counts()","f6db06e6":"plt.figure(figsize=(15,10))\ndf[' _conds'].value_counts().head(15).plot(kind='bar')\n\nplt.title('15 most common weathers in Delhi')\nplt.show()","68e801d4":"plt.figure(figsize=(15, 10))\nplt.title(\"Common wind direction in delhi\")\ndf[' _wdire'].value_counts().plot(kind=\"bar\")\nplt.plot()","ffd0f801":"plt.figure(figsize=(15, 10))\nsns.distplot(df[' _tempm'],bins=[i for i in range(0,61,5)], kde=False)\nplt.title(\"Distribution of Temperatures\")\nplt.grid()\nplt.show()","58efd221":"df['datetime_utc'] = pd.to_datetime(df['datetime_utc'])","0f6fad2f":"df['datetime_utc']","593e19f9":"# imputing the missing value in temperatre feature with mean.\ndf[' _tempm'].fillna(df[' _tempm'].mean(), inplace=True)","831cfe01":"df[' _tempm'].isna().sum()\n# filled all missing values with mean()","57a979fd":"str(df['datetime_utc'][0])","e7662e75":"# a function to extract year part from the whole date\ndef get_year(x):\n  return x[0:4]","25440579":"# a function to extract month part from the whole date\ndef get_month(x):\n  return x[5:7]","eb240bad":"# making two new features year and month\ndf['year'] = df['datetime_utc'].apply(lambda x: get_year(str(x)))\ndf['month'] = df['datetime_utc'].apply(lambda x: get_month(str(x)))","f0161ce2":"df['year']","050cd95e":"temp_year = pd.crosstab(df['year'], df['month'], values=df[' _tempm'], aggfunc='mean')","a2aa7aab":"plt.figure(figsize=(15, 10))\nsns.heatmap(temp_year, cmap='coolwarm', annot=True)\nplt.title(\"Average Tempearture in Delhi from 1996 to 2017\")\nplt.show()","4ca6ed5e":"df[' _hum'].isna().sum()","4a883474":"# imputing missing values in _hum feature with mean\ndf[' _hum'].fillna(df[' _hum'].mean(), inplace=True)","c92503b9":"humidity_year = pd.crosstab(df['year'], df['month'], values=df[' _hum'], aggfunc='mean')","07fe3753":"plt.figure(figsize=(15, 10))\nsns.heatmap(humidity_year, cmap='coolwarm', annot=True)\nplt.title(\"Average Humidity in Delhi from 1996 to 2017\")\nplt.show()","cae62f18":"# taking only temperature feature as values and datetime feature as index in the dataframe for time series forecasting of temperature\ndata = pd.DataFrame(list(df[' _tempm']), index=df['datetime_utc'], columns=['temp'])","c38e60bb":"data","ce15a2e0":"# resampling data with date frequency for time series forecasting\ndata = data.resample('D').mean()","c215f80c":"data.temp.isna().sum()","7c5a2370":"data.fillna(data['temp'].mean(), inplace=True)","ae24e54e":"data.temp.isna().sum()","27d857b6":"data.shape","64540890":"data","6c9c3f6f":"plt.figure(figsize=(25, 7))\nplt.plot(data, linewidth=.5)\nplt.grid()\nplt.title(\"Time Series (Years vs Temp.)\")\nplt.show()","28ef6a87":"# Scaling data to get rid of outliers\nfrom sklearn.preprocessing import MinMaxScaler\nscalar = MinMaxScaler(feature_range=(-1,1))\ndata_scaled = scalar.fit_transform(data)","0df11421":"data_scaled","e9c8a352":"data_scaled.shape","7dd8d80c":"steps = 30\ninp = []\nout = []\nfor i in range(len(data_scaled)- (steps)):\n    inp.append(data_scaled[i:i+steps])\n    out.append(data_scaled[i+steps])","5e58ae99":"inp=np.asanyarray(inp)\nout=np.asanyarray(out)","1f221f10":"x_train = inp[:7300,:,:]\nx_test = inp[7300:,:,:]    \ny_train = out[:7300]    \ny_test= out[7300:]","2b803b06":"inp.shape","542585a7":"x_train.shape","b5dd58ac":"x_test.shape","25a70558":"from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping\nearly_stop = EarlyStopping(monitor = \"loss\", mode = \"min\", patience = 7)\nmodel = Sequential()\nmodel.add(Conv1D(filters=256, kernel_size=2, activation='relu', input_shape=(30,1)))\nmodel.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(RepeatVector(30))\nmodel.add(LSTM(units=100, return_sequences=True, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(units=100, return_sequences=True, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(units=100, return_sequences=True, activation='relu'))\nmodel.add(LSTM(units=100, return_sequences=True, activation='relu'))\nmodel.add(Bidirectional(LSTM(128, activation='relu')))\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(1))\nmodel.compile(loss='mse', optimizer='adam')","85ef6e66":"plot_model(model, to_file='model.png')","d4107830":"history = model.fit(x_train,y_train,epochs=300, verbose=1, callbacks = [early_stop] )","46f6319a":"model.save(\".\/regressor.hdf5\")","b073f0a9":"predict = model.predict(x_test)","43e06a4d":"predict = scalar.inverse_transform(predict)","5a675a38":"Ytesting = scalar.inverse_transform(y_test)","9ddbc6d1":"plt.figure(figsize=(20,9))\nplt.plot(Ytesting , 'blue', linewidth=5)\nplt.plot(predict,'r' , linewidth=4)\nplt.legend(('Test','Predicted'))\nplt.show()","e55d499f":"from sklearn.metrics import mean_squared_error\nmean_squared_error(Ytesting, predict)","a03d642a":"**Haze and Smoke are most common weatehrs conditions in Delhi**","7b6d881d":"# Part 1: A quick analysis of Weather in Delhi","150ca1bd":"**\nNorth and West are the most common wind directions in dehi.**","8c10e9de":"This is a demonstration of using CNN-LSTMs for Time Series Forecasting. We can also improve the model to make better predictions.\nIf you have any suggestion, please comment.","64f6db99":"# Part 2: Time Series Forecasting","2ae037d2":"**Most common temperature scale in Delhi is from 25 to 35 degree.**"}}