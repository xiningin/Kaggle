{"cell_type":{"a3168025":"code","19eb1958":"code","73b823f2":"code","bfbc9d99":"code","52929ebc":"code","742189c7":"code","5a08de59":"code","47bb002b":"code","646f91fb":"code","4f644e0c":"code","c3f651d3":"code","c3443729":"code","e6a55035":"code","41d5df55":"code","e29f9bfd":"code","f64af9f9":"code","951604d0":"code","9f1dba9a":"code","091ccef5":"code","e281410d":"code","81d7b946":"code","ab33eb99":"code","49d4433b":"code","2bb26c2b":"code","6669264e":"code","2244e54a":"code","e4115681":"code","7805bd5c":"code","5ec2c93a":"code","e3929886":"markdown","1f7b4f96":"markdown","be0394d4":"markdown","7f6d3b49":"markdown","42685123":"markdown","8c94b9a6":"markdown","4cc28cd7":"markdown","f00b3060":"markdown","0ef99b4c":"markdown","a8d8174c":"markdown","3701a5d5":"markdown","21c874bc":"markdown","107beca7":"markdown","faf58fa5":"markdown","7eb46bd2":"markdown"},"source":{"a3168025":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport warnings\n#h20\nimport h2o\nfrom h2o.automl import H2OAutoML\nfrom h2o.estimators.gbm import H2OGradientBoostingEstimator\nfrom h2o.grid.grid_search import H2OGridSearch\n\n##Sklearn Imports\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.linear_model import LinearRegression, Lasso, ElasticNet\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#Catboost\nfrom catboost import CatBoostRegressor\n#Xgboost\nfrom xgboost import XGBRegressor\nimport xgboost as xgb\n#lightgbm\nimport lightgbm as lgb\n\n\nimport matplotlib.pyplot as plt\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\nsns.set_theme(style=\"whitegrid\")","19eb1958":"train=pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/train.csv\")\ntest=pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/test.csv\")","73b823f2":"train","bfbc9d99":"train.dtypes","52929ebc":"train.columns.tolist()","742189c7":"train.drop(\"id\",1,inplace=True)\ntest_ids=test[\"id\"].values\ntest.drop(\"id\",1,inplace=True)","5a08de59":"sns.heatmap(train.corr())","47bb002b":"train.corr()[\"loss\"].map(lambda x:abs(x)).sort_values()","646f91fb":"X,y=train.drop(\"loss\",1),train[\"loss\"]\nX_train, X_val, y_train, y_val=train_test_split(X,y,stratify=y,random_state=0)","4f644e0c":"Score_dict={\"scores\":[],\"model_names\":[]}#A dict to score RMSE scores","c3f651d3":"def predict(model,model_name):\n    model.fit(X_train, y_train)\n    y_val_predict = model.predict(X_val)\n    score=mean_squared_error(y_val, y_val_predict,squared=False)\n    print(\"The RMSE for {} is {}\".format(model_name,score))\n    return score # squared= False > returns Root Mean Square Error   ","c3443729":"GBR=GradientBoostingRegressor()\nScore_dict[\"scores\"].append(predict(model=GBR,model_name=\"GBR\"))\nScore_dict[\"model_names\"].append(\"GBR\")","e6a55035":"CBR=CatBoostRegressor(task_type=\"GPU\",\n                           devices='0')\nScore_dict[\"scores\"].append(predict(model=CBR,model_name=\"CBR\"))\nScore_dict[\"model_names\"].append(\"CBR\")","41d5df55":"XGB=XGBRegressor(tree_method='gpu_hist',verbosity=2)\nScore_dict[\"scores\"].append(predict(model=XGB,model_name=\"XGB\"))\nScore_dict[\"model_names\"].append(\"XGB\")","e29f9bfd":"lgbm_regressor= lgb.LGBMRegressor(objective='regression')\nScore_dict[\"scores\"].append(predict(model=lgbm_regressor,model_name=\"lgbm_regressor\"))\nScore_dict[\"model_names\"].append(\"lgbm_regressor\")","f64af9f9":"h2o.init()\n\n# Import a sample binary outcome train\/test set into H2O\ntrain = h2o.import_file(\"..\/input\/tabular-playground-series-aug-2021\/train.csv\")\n\nss =train.split_frame([0.75],seed = 0)\ntrain = ss[0]\nvalid = ss[1]","951604d0":"# Identify predictors and response\nx = train.columns\ny = \"loss\"\nx.remove(y)\nx.remove(\"id\")\n\n\n# Run AutoML for 20 base models (limited to 1 hour max runtime by default)\naml = H2OAutoML(max_models=20, seed=1)\naml.train(x=x, y=y, training_frame=train)","9f1dba9a":"preds = aml.predict(valid)","091ccef5":"preds=h2o.as_list(preds, use_pandas=True).values[:,0]\ny_val_h20=h2o.as_list(valid, use_pandas=True).values[:,0]\nauto_ml_score=mean_squared_error(y_val_h20, preds,squared=False)\nprint(\"The RMSE for Auto ML-h20 is {}\".format(auto_ml_score))\nScore_dict[\"scores\"].append(auto_ml_score)\nScore_dict[\"model_names\"].append(\"auto_ml\")","e281410d":"linear_regression = make_pipeline(LinearRegression())\nScore_dict[\"scores\"].append(predict(model=linear_regression,model_name=\"linear_regression\"))\nScore_dict[\"model_names\"].append(\"linear_regression\")","81d7b946":"lasso = make_pipeline(RobustScaler(), Lasso(alpha=0.0005))\nScore_dict[\"scores\"].append(predict(model=lasso,model_name=\"lasso\"))\nScore_dict[\"model_names\"].append(\"lasso\")","ab33eb99":"elastic_net = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio= .9))\nScore_dict[\"scores\"].append(predict(model=elastic_net,model_name=\"elastic_net\"))\nScore_dict[\"model_names\"].append(\"elastic_net\")","49d4433b":"def bagging_predictions(estimator):\n    regr = BaggingRegressor(base_estimator=estimator,\n                            n_estimators=10,\n                            max_samples=1.0,\n                            bootstrap=True, # Samples are drawn with replacement\n                            n_jobs= -1,\n                            random_state=0).fit(X_train, y_train)\n\n    y_val_predict = regr.predict(X_val)\n    return y_val_predict\n\n\npredictions = np.column_stack((bagging_predictions(linear_regression),\n                              bagging_predictions(lasso),\n                              bagging_predictions(elastic_net)))\nprint(f\"Bagged predictions shape: {predictions.shape}\")\n       \ny_val_predict = np.mean(predictions, axis=1)\nbagging_sr_score=mean_squared_error(y_val, y_val_predict,squared=False)\nprint(\"The RMSE for bagging_sr is {}\".format(bagging_sr_score))\nScore_dict[\"scores\"].append(bagging_sr_score)\nScore_dict[\"model_names\"].append(\"bagging_sr\")","2bb26c2b":"estimators = [ ('elastic_net', elastic_net),('xgb_regressor', XGB),('lgbm_regressor', lgbm_regressor) ,(\"GBR\",GBR)]\nstack = StackingRegressor(estimators=estimators, final_estimator= lasso, cv= 5, n_jobs= -1, passthrough = True)\nScore_dict[\"scores\"].append(predict(model=stack,model_name=\"stack\"))\nScore_dict[\"model_names\"].append(\"stack\")","6669264e":"df=pd.DataFrame(Score_dict)","2244e54a":"df.sort_values(by=\"scores\")","e4115681":"# Fitting Stack on the Entire Data and Creating submission.csv file\ntrain=pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/train.csv\")\ntest=pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/test.csv\")\nX,y=train.drop([\"loss\",\"id\"],1),train[\"loss\"]\n\nestimators = [ ('elastic_net', elastic_net),('xgb_regressor', XGB),('lgbm_regressor', lgbm_regressor) ,(\"GBR\",GBR)]\nstack = StackingRegressor(estimators=estimators, final_estimator= lasso, cv= 5, n_jobs= -1, passthrough = True)\nstack.fit(X,y)\ny_test_pred=stack.predict(test.drop(\"id\",1))","7805bd5c":"submission=pd.DataFrame({\n    \"id\":test[\"id\"],\n    \"loss\":y_test_pred\n    \n})","5ec2c93a":"submission.to_csv(\"submission.csv\",index=False)","e3929886":"## H20 Modelling-AUTO ML","1f7b4f96":"# Boosting Models","be0394d4":"# Bagging of Simple Regression Models","7f6d3b49":"## Gradient Boosting Regression","42685123":"# Final Results","8c94b9a6":"# StackRegressor","4cc28cd7":"# Simple Regression Models Performance","f00b3060":"## Xgboost","0ef99b4c":"# Stack is the Winner","a8d8174c":"### Cat Boost Regressor","3701a5d5":"## ElasticNet Regression","21c874bc":"## Linear Regression ","107beca7":"## LightGBM","faf58fa5":"## Lasso Regression ","7eb46bd2":"# Creating Base Models and Checking their Raw Performance-No Feature Engineering"}}