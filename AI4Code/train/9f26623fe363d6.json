{"cell_type":{"f6fb9eaa":"code","c369d390":"code","68d96e23":"code","ea34791b":"code","d840c41d":"code","c2d91622":"code","26368856":"code","b2c5d881":"code","33221e39":"code","186cc0cc":"code","ef83205b":"code","55ab9334":"code","13507067":"code","371f9a72":"code","6819b919":"code","94fb3662":"code","ea322ed9":"code","f25a8aa0":"code","b6eced92":"code","f4753ccd":"code","316a7353":"code","7031d293":"code","025fd39a":"code","899d4cdc":"code","7c37658b":"code","be968acd":"code","7f5fb1e4":"code","54168b8b":"code","e78b23b9":"code","d5016d14":"code","870cbccb":"code","c706502b":"code","08ca9f86":"code","8277df7d":"code","c4d9884e":"code","6d99c64c":"code","361fe9bc":"code","3cbcfddb":"code","2b649265":"code","1d550fc9":"code","6b5108d6":"code","3455f928":"code","c30aa035":"code","0098f27e":"code","dce4503a":"code","a9a58af7":"code","64264e91":"code","d981862b":"code","6170f6eb":"code","533d0783":"markdown","a25e1137":"markdown","66b05296":"markdown","09f4acda":"markdown","a3d3b610":"markdown","8da4cbbf":"markdown","835fa0c7":"markdown","3c19bd6b":"markdown","94a06b5b":"markdown","f8873481":"markdown","8449f575":"markdown","2172981e":"markdown","57837756":"markdown","6b48f994":"markdown","f049b8ee":"markdown","d3a1d67d":"markdown","3f6b6be4":"markdown","633cce2c":"markdown","f217b22e":"markdown","5a012ed3":"markdown","8b269a3d":"markdown","4ca4e36d":"markdown","4d01fb65":"markdown","a5774f4c":"markdown","d2d18726":"markdown","129e15ea":"markdown","c0955f45":"markdown","7385d226":"markdown","10984d99":"markdown","c98d2ddb":"markdown","e124be09":"markdown","1f5bcfa9":"markdown"},"source":{"f6fb9eaa":"# import modul for data processing\nimport numpy as np\nimport pandas as pd\n\n# import modul for data visualize\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.io as pio\nimport plotly.graph_objects as go\nimport seaborn as sns\nfrom plotly.subplots import make_subplots\n\nfrom IPython.core.interactiveshell import InteractiveShell\nfrom IPython.display import display\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom itertools import cycle, islice\nfrom pandas.plotting import parallel_coordinates\n\n\nimport pickle\nimport os","c369d390":"pd.options.display.max_columns = None\nInteractiveShell.ast_node_interactivity = \"all\"\nMapbox = pickle.load(open('..\/input\/mapbox\/mapbox_credentials.pkl','rb'))\npx.set_mapbox_access_token(Mapbox['Access Token'])\n\nmarket_dataset = pd.read_csv('..\/input\/farmers-markets-in-the-united-states\/farmers_markets_from_usda.csv')\ncounty_dataset = pd.read_csv('..\/input\/farmers-markets-in-the-united-states\/wiki_county_info.csv')\nprint(\"\\n{:^30}\".format('Market Dataframe'))\nprint(\"*\"*120)\ndisplay(market_dataset.head(5))\nprint(\"\\n{:^30}\".format('County Dataframe'))\nprint(\"*\"*120)\ndisplay(county_dataset.head(5))","68d96e23":"# method for change data format\ndef convert_dollar_number(data):\n    if(type(data)==float):\n        return data\n    elif(type(data)==str and '$' in data):\n        return int(\"\".join(data.split('$')[1].split(',')))\n    elif(type(data)==str and '$' not in data):\n        return int(\"\".join(data.split(',')))\n\nfor i in range(3,8):\n    county_dataset[county_dataset.columns[i]] = county_dataset[county_dataset.columns[i]].apply(convert_dollar_number)\nprint(\"\\n{:^30}\".format('Change Data Format'))\nprint(\"*\"*120)","ea34791b":"# This is for knowing any null value on dataframe\ndef graph_missing_value(dataset, name):\n    num_missing_value = dataset.isnull().sum()\n    mean_missing_value = (num_missing_value\/market_dataset.shape[0])*100\n    frame = { 'Name': num_missing_value.index, 'Sum': num_missing_value, 'Percentage':(num_missing_value\/market_dataset.shape[0])*100 } \n    result = pd.DataFrame(frame).reset_index(drop=True)\n\n    fig = px.bar(result, x='Name', y='Sum',\n                 hover_data=['Percentage'], color='Percentage',\n                 labels={'percent':'Persentase'}, height=400)\n\n    fig.update_layout(\n        title='Percentage of Null Value on '+name,\n        xaxis=dict(\n            title='Feature Name',\n            titlefont_size=16,\n            tickfont_size=14,\n        ),\n        yaxis=dict(\n            title='Number of Null Value',\n            titlefont_size=16,\n            tickfont_size=14,\n        )\n    )\n    return fig\n    \ngraph_missing_value(market_dataset, 'Market Dataframe')\ngraph_missing_value(county_dataset, 'County Dataframe')","d840c41d":"# Delete feature 'Website', 'Facebook', 'Twitter', 'Youtube','OtherMedia','Season2Date', 'Season2Time', \n#'Season3Date','Season3Time', 'Season4Date', 'Season4Time','Location','updateTime'\n\nprint('Pre-processing market dataset on progress')\nprint(\"*\"*120)\nmarket_dataset.drop(['Website', 'Facebook', 'Twitter', 'Youtube','OtherMedia','Season2Date', 'Season2Time', \n                     'Season3Date','Season3Time', 'Season4Date', 'Season4Time','Location','updateTime'], axis=1,inplace=True)\n\n# Change null value in feature 'street', 'city', 'County', 'State', 'zip'\n# become Not Defined\nmarket_dataset.update(market_dataset[['street', 'city', 'County', 'State', 'zip']].fillna('Not Reported'))\nmarket_dataset = market_dataset.dropna()\n\n\n# Change all value Y to 1\nmarket_dataset.replace('Y', 1, inplace=True)\n\n# Change all value N to 0\nmarket_dataset.replace('N', 0, inplace=True)\n\n# Change all value - become mode of column on organic columns\nmarket_dataset.replace('-',market_dataset['Organic'].mode()[0],inplace=True)\n# Check null value\ngraph_missing_value(market_dataset, 'Market Dataframe')\n\nprint('Pre-processing county dataset on process')\nprint(\"*\"*120)\n\ncounty_dataset = county_dataset.dropna()\ngraph_missing_value(county_dataset, 'County Dataframe')","c2d91622":"# merging market and county dataset\n# for make sure only county based on available store on market dataset\n\ncounty_dataset = county_dataset.rename(columns={\"county\": \"County\"})\n\nmerge_dataset = market_dataset.copy().merge(county_dataset, how='inner',on=['County','State'])\nmerge_dataset.drop(['number'], axis=1,inplace=True)\nInteractiveShell.ast_node_interactivity = \"last\"","26368856":"print('EDA On Merge Dataframe')\nprint(\"*\"*120)\n\nfig = make_subplots(\n    rows=3,\n    row_heights=[0.6, 0.6, 0.9],\n    specs=[[{\"type\": \"box\",}],\n           [{\"type\": \"box\"}],\n           [{\"type\": \"box\"}]])\n\nfig.add_trace(\n    go.Box(y=merge_dataset['median household income'], \n           x= county_dataset['State'],\n           name='median household income (Hint: point represents county in given state)',\n           boxpoints='outliers', # can also be outliers, or suspectedoutliers, or False\n           jitter=0.3, # add some jitter for a better separation between points\n          )\n        )\n\nfig.add_trace(\n    go.Box(y=merge_dataset['per capita income'], \n           x= merge_dataset['State'],\n           name='per capita income (Hint: point represents county in given state)',\n           boxpoints='outliers', # can also be outliers, or suspectedoutliers, or False\n           jitter=0.3, # add some jitter for a better separation between points\n          )\n        )\n\nfig.add_trace(\n    go.Box(y=merge_dataset['median family income'], \n           x= merge_dataset['State'],\n           name='median family income (Hint: point represents county in given state)',\n           boxpoints='outliers', # can also be outliers, or suspectedoutliers, or False\n           jitter=0.3, # add some jitter for a better separation between points\n          )\n        )\n\nfig.update_layout(\n    title='Merge Dataframe : per capita income & median household income & median family income boxplot', \n    xaxis=({'categoryorder':'category ascending'}),\n    template=\"plotly_dark\",\n    margin=dict(r=10, t=25, b=40, l=60),\n    annotations=[\n        dict(\n            text=\"Source: NOAA\",\n            showarrow=False,\n            xref=\"paper\",\n            yref=\"paper\",\n            x=0,\n            y=0)\n    ],\n    legend=dict(\n        x=0,\n        y=0.1,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    )\n)","b2c5d881":"print('EDA On Merge Dataframe')\nprint(\"*\"*120)\n\nfig = make_subplots(\n    rows=2,\n    row_heights=[0.4, 0.6],\n    specs=[[{\"type\": \"box\",}],\n           [{\"type\": \"box\"}]])\n\nfig.add_trace(\n    go.Box(y=merge_dataset['population'], \n           x= county_dataset['State'],\n           name='population (Hint: point represents county in given state)',\n           boxpoints='outliers', # can also be outliers, or suspectedoutliers, or False\n           jitter=0.3, # add some jitter for a better separation between points\n          )\n        )\n\nfig.add_trace(\n    go.Box(y=merge_dataset['number of households'], \n           x= merge_dataset['State'],\n           name='number of households (Hint: point represents county in given state)',\n           boxpoints='outliers', # can also be outliers, or suspectedoutliers, or False\n           jitter=0.3, # add some jitter for a better separation between points\n          )\n        )\n\nfig.update_layout(\n    title='Merge Dataframe : population & number of households boxplot', \n    xaxis=({'categoryorder':'category ascending'}),\n    template=\"plotly_dark\",\n    margin=dict(r=10, t=25, b=40, l=60),\n    annotations=[\n        dict(\n            text=\"Source: Internet\",\n            showarrow=False,\n            xref=\"paper\",\n            yref=\"paper\",\n            x=0,\n            y=0)\n    ],\n    legend=dict(\n        x=0,\n        y=0.1,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    )\n)","33221e39":"print('Removing Outlier Process')\nprint(\"*\"*120)\n\nQ1 = merge_dataset[merge_dataset.columns[46:]].quantile(0.25)\nQ3 = merge_dataset[merge_dataset.columns[46:]].quantile(0.75)\n\nIQR = Q3 - Q1\n\nmerge_dataset_wout = merge_dataset[~((merge_dataset < (Q1 - 1.5 * IQR)) | (merge_dataset > (Q3 + 1.5 * IQR))).any(axis=1)]\n\nprint('Size of dataframe before outlier removing {}'.format(merge_dataset.shape))\nprint('Size of dataframe after outlier removing {}'.format(merge_dataset_wout.shape))","186cc0cc":"print('Creating New Dataframe for Clustering')\nprint(\"*\"*120)\n\ndf_cluster_1 = merge_dataset_wout.copy()\ndf_cluster_1.drop(['FMID','MarketName','street','city','County','zip','Season1Date','Season1Time','x','y'],axis=1,inplace=True)\nname_state = df_cluster_1['State'].unique()\nname_feature = [\n       'Credit', 'WIC', 'WICcash', 'SFMNP', 'SNAP', 'Organic', 'Bakedgoods',\n       'Cheese', 'Crafts', 'Flowers', 'Eggs', 'Seafood', 'Herbs', 'Vegetables',\n       'Honey', 'Jams', 'Maple', 'Meat', 'Nursery', 'Nuts', 'Plants',\n       'Poultry', 'Prepared', 'Soap', 'Trees', 'Wine', 'Coffee', 'Beans',\n       'Fruits', 'Grains', 'Juices', 'Mushrooms', 'PetFood', 'Tofu',\n       'WildHarvested']\n\ndf_cluster_2 = pd.DataFrame()\nfor i in name_state:\n    new_row = {}\n    new_row['State'] = i\n    for j in name_feature:\n        if 1 in df_cluster_1[df_cluster_1['State']==i][j].value_counts().index:\n            new_row[j+'_'+'1']=df_cluster_1[df_cluster_1['State']==i][j].value_counts()[1]\n        if 0 in df_cluster_1[df_cluster_1['State']==i][j].value_counts().index:\n            new_row[j+'_'+'0']=df_cluster_1[df_cluster_1['State']==i][j].value_counts()[0]\n    df_cluster_2 = df_cluster_2.append(new_row, ignore_index=True)","ef83205b":"print('Cleaning new data frame')\nprint(\"*\"*120)\n\ndf_cluster_2 = df_cluster_2.reset_index()\ndf_cluster_2.drop(['index'],axis=1,inplace=True)\ndf_cluster_2.replace(np.nan, 0, inplace=True)\ndisplay(df_cluster_2.head(5))","55ab9334":"print('Removing useless column and grouping data frame')\nprint(\"*\"*120)\ndf_cluster_1.drop(['Credit', 'WIC', 'WICcash', 'SFMNP', 'SNAP', 'Organic',\n       'Bakedgoods', 'Cheese', 'Crafts', 'Flowers', 'Eggs', 'Seafood', 'Herbs',\n       'Vegetables', 'Honey', 'Jams', 'Maple', 'Meat', 'Nursery', 'Nuts',\n       'Plants', 'Poultry', 'Prepared', 'Soap', 'Trees', 'Wine', 'Coffee',\n       'Beans', 'Fruits', 'Grains', 'Juices', 'Mushrooms', 'PetFood', 'Tofu',\n       'WildHarvested'],axis=1,inplace=True)\n\ndf_cluster_1 = df_cluster_1.groupby('State',as_index = False).agg({'per capita income': 'mean', 'median household income': 'mean',\n                                                             'median family income': 'mean', 'population':'sum',\n                                                             'number of households':'sum'})","13507067":"print('Feature engineering process: To find out how many information from columns')\nprint(\"*\"*120)\n\n\n# Standardize the data to have a mean of ~0 and a variance of 1\nX_std = StandardScaler().fit_transform(df_cluster_1[df_cluster_1.columns[1:]])\n\n\n# conduct dimentionality reduction using pca\npca = PCA()\npca.fit(X_std)\n\npca.explained_variance_ratio_\n\nplt.plot(range(1,6), pca.explained_variance_ratio_.cumsum(), marker='o', linestyle='--')\nplt.title('Explained Variance by Components')\nplt.xlabel('Number of Components')\nplt.ylabel('Cumulative Explained Variance')","371f9a72":"print('Feature engineering process: To find out how many information from columns')\nprint(\"*\"*120)\n\n\nproduct_group = df_cluster_2.columns.values[0:47].tolist()+df_cluster_2.columns.values[51:55].tolist()+ \\\n                    df_cluster_2.columns.values[56:62].tolist()+ \\\n                    df_cluster_2.columns.values[66:].tolist()\n\nnutrition_program = df_cluster_2.columns.values[47:51].tolist()+df_cluster_2.columns.values[62:66].tolist()\n\n# Standardize the data to have a mean of ~0 and a variance of 1\nX_std_2 = StandardScaler().fit_transform(df_cluster_2[nutrition_program])\nX_std_3 = StandardScaler().fit_transform(df_cluster_2[product_group])\n\n\n# conduct dimentionality reduction using pca\npca_2 = PCA()\npca_2.fit(X_std_2)\n\npca_3 = PCA()\npca_3.fit(X_std_3)","6819b919":"print('Feature engineering process: plotting number of information on nutrition program feature')\nprint(\"*\"*120)\n\nplt.plot(range(1,9), pca_2.explained_variance_ratio_.cumsum(), marker='o', linestyle='--')\nplt.title('Explained Variance by Components')\nplt.xlabel('Number of Components')\nplt.ylabel('Cumulative Explained Variance')","94fb3662":"print('Feature engineering process: plotting number of information on product group feature')\nprint(\"*\"*120)\n\nplt.plot(range(1,52), pca_3.explained_variance_ratio_.cumsum(), marker='o', linestyle='--')\nplt.title('Explained Variance by Components')\nplt.xlabel('Number of Components')\nplt.ylabel('Cumulative Explained Variance')","ea322ed9":"print('Feature engineering process:fitting pca with specific number of component & create pca scores for cluster 1')\nprint(\"*\"*120)\n\npca = PCA(n_components = 2)\npca.fit(X_std)\n\npca.transform(X_std)\n\nscores_pca = pca.transform(X_std)","f25a8aa0":"print('Feature engineering process: fitting pca with specific number of component & create pca scores for cluster 2 - nutrition program')\nprint(\"*\"*120)\n\npca_2 = PCA(n_components = 2)\npca_2.fit(X_std_2)\n\npca_2.transform(X_std_2)\n\nscores_pca_2 = pca_2.transform(X_std_2)","b6eced92":"print('Feature engineering process: fitting pca with specific number of component & create pca scores for cluster 3 - product group')\nprint(\"*\"*120)\n\npca_3 = PCA(n_components = 3)\npca_3.fit(X_std_3)\n\npca_3.transform(X_std_3)\n\nscores_pca_3 = pca_3.transform(X_std_3)","f4753ccd":"print('Feature engineering process: find out number of inertia (coherent between clusrter) for cluster 1')\nprint(\"*\"*120)\n\nwcss = []\nfor i in range(1,10):\n    kmeans_pca = KMeans(n_clusters = i, init='k-means++', random_state=42)\n    kmeans_pca.fit(scores_pca)\n    wcss.append(kmeans_pca.inertia_)","316a7353":"print('Feature engineering process: decide how many cluster that we want to create for cluster 1')\nprint(\"*\"*120)\n\nplt.plot(range(1,10), wcss, marker='o', linestyle='--')\nplt.title('K-Means with PCA Clustering')\nplt.xlabel('Number of Clusters')\nplt.ylabel('WCSS')\nplt.show()","7031d293":"print('Feature engineering process: find out number of inertia for cluster 2 - nutrition program')\nprint(\"*\"*120)\n\nwcss_2 = []\nfor i in range(1,10):\n    kmeans_pca_2 = KMeans(n_clusters = i, init='k-means++', random_state=42)\n    kmeans_pca_2.fit(scores_pca_2)\n    wcss_2.append(kmeans_pca_2.inertia_)","025fd39a":"print('Feature engineering process: decide how many cluster that we want to create for cluster 2 - nutrition program')\nprint(\"*\"*120)\n\nplt.plot(range(1,10), wcss_2, marker='o', linestyle='--')\nplt.title('K-Means with PCA Clustering')\nplt.xlabel('Number of Clusters')\nplt.ylabel('WCSS')\nplt.show()","899d4cdc":"print('Feature engineering process: find out number of inertia for cluster 2 - product group')\nprint(\"*\"*120)\n\nwcss_3 = []\nfor i in range(1,10):\n    kmeans_pca_3 = KMeans(n_clusters = i, init='k-means++', random_state=42)\n    kmeans_pca_3.fit(scores_pca_3)\n    wcss_3.append(kmeans_pca_3.inertia_)","7c37658b":"print('Feature engineering process: decide how many cluster that we want to create for cluster 2 - product group')\nprint(\"*\"*120)\n\nplt.plot(range(1,10), wcss_3, marker='o', linestyle='--')\nplt.title('K-Means with PCA Clustering')\nplt.xlabel('Number of Clusters')\nplt.ylabel('WCSS')\nplt.show()","be968acd":"print('Training process: KMeans with 4 clusters for cluster 1')\nprint(\"*\"*120)\n\nkmeans_pca = KMeans(n_clusters=4, init='k-means++',random_state=42)\nkmeans_pca.fit(scores_pca)","7f5fb1e4":"print('Training process: KMeans with 4 clusters for cluster 2 - nutrition program')\nprint(\"*\"*120)\n\nkmeans_pca_2 = KMeans(n_clusters=4, init='k-means++',random_state=42)\nkmeans_pca_2.fit(scores_pca_2)","54168b8b":"print('Training process: KMeans with 4 clusters for cluster 2 - product group')\nprint(\"*\"*120)\n\nkmeans_pca_3 = KMeans(n_clusters=4, init='k-means++',random_state=42)\nkmeans_pca_3.fit(scores_pca_3)","e78b23b9":"print('Create New Feature: Label based on cluster citizen income for dataframe cluster 1')\nprint(\"*\"*120)\n\ndf_cluster_1['Segment Citizen Income'] = kmeans_pca.labels_\ndf_cluster_1['Segment Citizen Income'] = df_cluster_1['Segment Citizen Income'].map({\n    0: 'one',\n    1: 'two',\n    2: 'three',\n    3: 'four'\n})\n","d5016d14":"print('Create New Feature: Label based on cluster nutrition program for dataframe cluster 2')\nprint(\"*\"*120)\n\ndf_cluster_2['Segment Nutrition Program'] = kmeans_pca_2.labels_\ndf_cluster_2['Segment Nutrition Program'] = df_cluster_2['Segment Nutrition Program'].map({\n    0: 'one',\n    1: 'two',\n    2: 'three',\n    3: 'four'\n})\n","870cbccb":"print('Create New Feature: Label based on cluster product group for dataframe cluster 2')\nprint(\"*\"*120)\n\ndf_cluster_2['Segment Product Group'] = kmeans_pca_3.labels_\ndf_cluster_2['Segment Product Group'] = df_cluster_2['Segment Product Group'].map({\n    0: 'one',\n    1: 'two',\n    2: 'three',\n    3: 'four'\n})\n","c706502b":"print('Function for drawing cluster characteristics')\nprint(\"*\"*120)\n\ndef parallel_plot(data, category):\n\tmy_colors = list(islice(cycle(['b', 'r', 'g', 'y', 'k']), None, len(data)))\n\tplt.figure(figsize=(15,15)).gca().axes.set_ylim([-5,+5])\n\tparallel_coordinates(data, category, color = my_colors, marker='o')","08ca9f86":"print('Cluster characteristics for cluster 1')\nprint(\"*\"*120)\n\ndf_analysis_cluster_1 = df_cluster_1.copy()\ndf_analysis_cluster_1.iloc[:,1:6] = X_std\n\ncitizen_income = df_analysis_cluster_1.columns.values[1:8].tolist()\ndf_analysis_cluster_1 = df_analysis_cluster_1[citizen_income].groupby('Segment Citizen Income',\n                                                                        as_index = False).mean()\nparallel_plot(df_analysis_cluster_1, 'Segment Citizen Income')","8277df7d":"print('Cluster characteristics for cluster 2')\nprint(\"*\"*120)\n\ndf_analysis_cluster_2 = df_cluster_2.copy()\ndf_analysis_cluster_2[nutrition_program] = X_std_2\ndf_analysis_cluster_2[product_group] = X_std_3\n\nnutrition_characteristics = nutrition_program + ['Segment Nutrition Program']\nproduct_characteristics_1 = product_group[0:11] + ['Segment Product Group']\nproduct_characteristics_2 = product_group[11:22] + ['Segment Product Group']\nproduct_characteristics_3 = product_group[22:33] + ['Segment Product Group']\nproduct_characteristics_4 = product_group[33:42] + ['Segment Product Group']\nproduct_characteristics_5 = product_group[42:51] + ['Segment Product Group']\nproduct_characteristics_6 = product_group[51:] + ['Segment Product Group']","c4d9884e":"print('Cluster characteristics for cluster 2 based on nutrition program')\nprint(\"*\"*120)\n\ndf_nutrition_program = df_analysis_cluster_2[nutrition_characteristics].groupby('Segment Nutrition Program',\n                                                                        as_index = False).mean()\n\n\nparallel_plot(df_nutrition_program, 'Segment Nutrition Program')","6d99c64c":"print('Cluster characteristics for cluster 2 based on product group')\nprint(\"*\"*120)\n\ndf_pg_1 = df_analysis_cluster_2[product_characteristics_1].groupby('Segment Product Group',\n                                                                        as_index = False).mean()\n\nparallel_plot(df_pg_1, 'Segment Product Group')","361fe9bc":"print('Cluster characteristics for cluster 2 based on product group')\nprint(\"*\"*120)\n\ndf_pg_2 = df_analysis_cluster_2[product_characteristics_2].groupby('Segment Product Group',\n                                                                        as_index = False).mean()\n\nparallel_plot(df_pg_2, 'Segment Product Group')","3cbcfddb":"print('Cluster characteristics for cluster 2 based on product group')\nprint(\"*\"*120)\n\ndf_pg_3 = df_analysis_cluster_2[product_characteristics_3].groupby('Segment Product Group',\n                                                                        as_index = False).mean()\n\nparallel_plot(df_pg_3, 'Segment Product Group')","2b649265":"print('Cluster characteristics for cluster 2 based on product group')\nprint(\"*\"*120)\n\ndf_pg_4 = df_analysis_cluster_2[product_characteristics_4].groupby('Segment Product Group',\n                                                                        as_index = False).mean()\n\nparallel_plot(df_pg_4, 'Segment Product Group')","1d550fc9":"print('Cluster characteristics for cluster 2 based on product group')\nprint(\"*\"*120)\n\ndf_pg_5 = df_analysis_cluster_2[product_characteristics_5].groupby('Segment Product Group',\n                                                                        as_index = False).mean()\n\nparallel_plot(df_pg_5, 'Segment Product Group')","6b5108d6":"print('Cluster characteristics for cluster 2 based on product group')\nprint(\"*\"*120)\n\ndf_pg_6 = df_analysis_cluster_2[product_characteristics_6].groupby('Segment Product Group',\n                                                                        as_index = False).mean()\n\nparallel_plot(df_pg_6, 'Segment Product Group')","3455f928":"from urllib.request import urlopen\nimport json\nwith urlopen('https:\/\/raw.githubusercontent.com\/PublicaMundi\/MappingAPI\/master\/data\/geojson\/us-states.json') as response:\n    counties = json.load(response)","c30aa035":"print('States Cluster Based on Citizen Income')\n\npx.set_mapbox_access_token(Mapbox['Access Token'])\nfig = px.choropleth_mapbox(df_cluster_1, geojson=counties, color=\"Segment Citizen Income\",\n                           locations=\"State\", featureidkey=\"properties.name\",\n                           hover_data = ['per capita income', 'median household income', 'population'],\n                           color_discrete_map={\n                            \"one\": px.colors.sequential.Rainbow[8],\n                            \"two\": px.colors.sequential.Rainbow[6],\n                            \"three\": px.colors.sequential.Rainbow[4],\n                            \"four\": px.colors.sequential.Rainbow[2]\n                        })\nfig.update_layout(mapbox_style=\"carto-positron\",\n                  mapbox_zoom=3, mapbox_center = {\"lat\": 37.0902, \"lon\": -95.7129})\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nfig.show()","0098f27e":"print('States Cluster Based on Nutrition Program')\nfig = px.choropleth_mapbox(df_cluster_2, geojson=counties, color=\"Segment Nutrition Program\",\n                           locations=\"State\", featureidkey=\"properties.name\",\n                           color_discrete_map={\n                            \"one\": px.colors.sequential.Rainbow[8],\n                            \"two\": px.colors.sequential.Rainbow[6],\n                            \"three\": px.colors.sequential.Rainbow[4],\n                            \"four\": px.colors.sequential.Rainbow[2]\n                           }\n                          )\nfig.update_layout(mapbox_style=\"carto-positron\",\n                  mapbox_zoom=3, mapbox_center = {\"lat\": 37.0902, \"lon\": -95.7129})\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nfig.show()","dce4503a":"print('States Cluster Based on Product Group')\nfig = px.choropleth_mapbox(df_cluster_2, geojson=counties, color=\"Segment Product Group\",\n                           locations=\"State\", featureidkey=\"properties.name\",\n                           color_discrete_map={\n                            \"one\": px.colors.sequential.Rainbow[8],\n                            \"two\": px.colors.sequential.Rainbow[6],\n                            \"three\": px.colors.sequential.Rainbow[4],\n                            \"four\": px.colors.sequential.Rainbow[2]\n                           }\n                          )\nfig.update_layout(mapbox_style=\"carto-positron\",\n                  mapbox_zoom=3, mapbox_center = {\"lat\": 37.0902, \"lon\": -95.7129})\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nfig.show()","a9a58af7":"from functools import reduce\nfinal_dataframe  = reduce(lambda x,y: pd.merge(x,y, on=['State'], how='inner'), \n                          [merge_dataset_wout.copy(),\n                           df_cluster_2[['State','Segment Product Group','Segment Nutrition Program']],\n                           df_cluster_1[['State','Segment Citizen Income']]])\nfinal_dataframe['marker size'] = 1","64264e91":"fig = px.scatter_mapbox(final_dataframe, \n                        lat=\"y\", \n                        lon=\"x\", \n                        color=\"Segment Citizen Income\",\n                        size=\"marker size\",\n                        hover_name=\"MarketName\", \n                        hover_data=[\"State\",\"Segment Nutrition Program\",\"Segment Product Group\"],\n                        color_discrete_map={\n                            \"one\": px.colors.sequential.Rainbow[8],\n                            \"two\": px.colors.sequential.Rainbow[6],\n                            \"three\": px.colors.sequential.Rainbow[4],\n                            \"four\": px.colors.sequential.Rainbow[2]\n                           }, \n                        size_max=15, \n                        zoom=3,\n                        mapbox_style='streets',\n                        title='U.S Store cluster Based On Citizen Income')\nfig.show()","d981862b":"fig = px.scatter_mapbox(final_dataframe, \n                        lat=\"y\", \n                        lon=\"x\", \n                        color=\"Segment Nutrition Program\",\n                        size=\"marker size\",\n                        hover_name=\"MarketName\", \n                        hover_data=[\"State\",\"Segment Citizen Income\",\"Segment Product Group\"],\n                        color_discrete_map={\n                            \"one\": px.colors.sequential.Rainbow[8],\n                            \"two\": px.colors.sequential.Rainbow[6],\n                            \"three\": px.colors.sequential.Rainbow[4],\n                            \"four\": px.colors.sequential.Rainbow[2]\n                        }, \n                        size_max=15, \n                        zoom=3,\n                        mapbox_style='streets',\n                        title='U.S Store cluster Based On Nutrition Program')\nfig.show()","6170f6eb":"fig = px.scatter_mapbox(final_dataframe, \n                        lat=\"y\", \n                        lon=\"x\", \n                        color=\"Segment Product Group\",\n                        size=\"marker size\",\n                        hover_name=\"MarketName\", \n                        hover_data=[\"State\",\"Segment Nutrition Program\",\"Segment Citizen Income\"],\n                        color_discrete_map={\n                            \"one\": px.colors.sequential.Rainbow[8],\n                            \"two\": px.colors.sequential.Rainbow[6],\n                            \"three\": px.colors.sequential.Rainbow[4],\n                            \"four\": px.colors.sequential.Rainbow[2]\n                        }, \n                        size_max=15, \n                        zoom=3,\n                        mapbox_style='streets',\n                        title='U.S Store cluster Based On Product Group')\nfig.show()","533d0783":"In code above, I try to drop every feature that really needed on that dataframe. Why? This is because this dataframe created for clustering citizen income. I mean, the feature that really needed on this cluster just **state, per capita income, median household income, median family income, population, and number of household**","a25e1137":"## Availability of Products\n* Average number of stores that serve **Bakedgoods** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Beans** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Cheese** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Coffee** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Crafts** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Credit** (from highest to lowest): two > four > one > three","66b05296":"Based on graph above, number of clusters with lowest different slops is 4 clusters. I meant, if you see each dot, from cluster one until four, slop of dot are very obvious. But, for cluster 5 and greater, it seems like differentiate between dot is more smooth. This principle will be use for next process (decide number of cluster for nutrition program and product availability)","09f4acda":"You just have to see box plot above only, that is final output. Okay, based picture above, We still have quite outlier on our data. Especially on column median household, per capita income and median family income.","a3d3b610":"In code above, I try to create new dataframe that consist of availability product each states in U.S.","8da4cbbf":"# U.S Farmers Markets Exploratory\n\n![Farmer Products](https:\/\/www.morningagclips.com\/wp-content\/uploads\/2020\/05\/6468881225_9e3d16c641_k-720x400.jpg)\n\nThis is notebook that I have created for doing some exploration on U.S Farmer Datasets. There are some facts based on dataset that I want to explain. So lets get started.\n\n## Table of Contents:\n* [Overview](#section-one)\n    - [Problem Question](#subsection-one-one)\n    - [Methodology](#subsection-one-two)\n* [Import Module](#section-two)\n* [Acquire & EDA](#section-three)\n* [Pre-processing](#section-four)\n* [Analyze](#section-five)\n* [Result & Conclusion](#section-six)","835fa0c7":"## Availability of Senior Farmer Market Nutrition Program\nThe Seniors Farmers' Market Nutrition Program (SFMNP) is designed to provide low-income seniors with access to locally grown fruits, vegetables, honey and herbs, increase the domestic consumption of agricultural commodities through farmers' markets, roadside stands, and community supported agricultural programs, and aid in the development of new and additional farmers' markets, roadside stands, and community support agricultural programs.\n* Cluster **four** has highest avarage number of stores that serve SFMNP.\n* Cluster **one** has second highest avarage number of stores that serve SFMNP.\n* Cluster **two** has third highest avarage number of stores that serve SFMNP.\n* Cluster **three** has lowest avarage number of stores that serve SFMNP.\n***\n\n## Availability of Supplemental Nutrition Assistance Program (SNAP)\nThe Supplemental Nutrition Assistance Program (SNAP) provides over **45 million low-income Americans with monthly benefits that can be used to purchase most foods and beverages.**\n***\n* Cluster **four** has highest avarage number of stores that serve SNAP\n* Cluster **one** has second highest avarage number of stores that serve SNAP.\n* Cluster **two** has third highest avarage number of stores that serve SNAP.\n* Cluster **three** has lowest avarage number of stores that serve SNAP.\n***\n\n## Availability of WIC Program\nThe Special Supplemental Nutrition Program for Women, Infants, and Children (WIC) provides federal grants to states for supplemental foods, health care referrals, and nutrition education for low-income pregnant, breastfeeding, and non-breastfeeding postpartum women, and to infants and children up to age five who are found to be at nutritional risk.\n***\n* Cluster **four** has highest avarage number of stores that serve WIC.\n* Cluster **one** has second highest avarage number of stores that serve WIC.\n* Cluster **two** has third highest avarage number of stores that serve WIC.\n* Cluster **three** has lowest avarage number of stores that serve WIC.","3c19bd6b":"If you see feature that have 1 in the end of name, it represents number of store that sell those products each states. And if you see feature that have 0 in the end of name, it represents number of store that dont provide specific products.","94a06b5b":"<a id=\"section-two\"><\/a>\n# Import Module\n***","f8873481":"Based on graph above, we just have creating PCA with 2 component. From 6 feature, we can simplify to only 2 feature. Explainedd variance represents number of useful information per component\/feature. So, with just 2 feature, we have already covered 98% important information.","8449f575":"<a id=\"section-five\"><\/a>\n# Analyze\n***\nWe have already remove outlier from merge dataframe. So, in this step, we will try to analyze clean dataframe to get some insight. After doing some research, I think this problem can addressed by clustering analysis. We can cluster county or state to know characteristics that can answer the problem questions. I will use K-Mean Clustering with PCA. We can compare each stores\/farmer market based on specific criteria. And those criteria can be cluster for our analysis.","2172981e":"In code above, I try to create new feature based on label of kmeans clustering. In clustering 1 (based on citizen income), there are 4 different label, 0, 1,2,3. Until now, we dont have idea what differences between them. I try to rename those label to become one, two, three, four.","57837756":"So, merge dataframe has zero null value. Finally, I will remove outliers from dataframe.","6b48f994":"* Average number of stores that serve **Jams** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Juices** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Maple** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Meat** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Mushroam** (from highest to lowest): two > four > one > three","f049b8ee":"* Average number of stores that serve **Plants** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Poultry** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Prepared** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Seafood** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Soap** (from highest to lowest): two > four > one > three","d3a1d67d":"* Average number of stores that serve **Tofu** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Trees** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Vegetables** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **WildHarvested** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Wine** (from highest to lowest): two > one > four > three","3f6b6be4":"<a id=\"section-three\"><\/a>\n# Acquire & EDA\n***","633cce2c":"***\n<a id=\"subsection-one-two\"><\/a>\n## Methodology\n\nIn order to  answer those question, I do some steps of data analysis which consists of:\n* **Acquire Step**: This step includes finding, accessing, and moving data.\n* **Prepare Step**: `Explore` (Receive data to find out the nature of the data, i.e. the quality and format. It also conducts initial analysis to retrieve data) dan `Pre-process` (after knowing at a glance about the data, then do the pre-process. It involves cleaning data, filtering data, and making data readable by changing to a particular data model or packaging to a specific data form. Finally it integrates data from various sources).\n* **Analyze Step**: covering the selection of analysis techniques used, building data models, and analysis of results.\n* **Report Step**: includes evaluating the results of the analysis, presenting the results to a visual form, and making a report that contains an evaluation of the results of the analysis with the desired criteria.\n\n***\n","f217b22e":"After I cleaning data from null value, I decide to merge **market dataset and county dataset** for better understanding and try to remove outlier.","5a012ed3":"Based on graph above, there are many null value on column **website, twitter, youtube, season 2,3,4, location, and many more**. So, I decided to remove that columns because they dont important for this research. In county dataframe, number of null value is small, so we can easily to remove that.","8b269a3d":"Those graph (above) tell us number of explained variance based on number of components. So, for clustering based on nutrition program, we create PCA with 2 components.","4ca4e36d":"Also, column population and number of households have outliers. I will remove that below","4d01fb65":"In code above, we try to create 2 different PCA, so in total, we create 3 pca. PCA 1 created for cluster based on citizen income. PCA 2 created for cluster based on nutrition program, and the last one is PCA 3 (for cluster based on product group\/availability). ","a5774f4c":"<a id=\"section-six\"><\/a>\n# Result & Conclusion\n***\n\nAfter I conduct intensive analysis, I have get enough information to answer problem question. So, in first section of this notebook, I state that problem question is **Are farmers markets inaccessible to Americans who live in certain parts of the country or are of low socio-economic status. Does the data reflect this criticism?**. Here my answer: **Its true. Critism that states that U.S farmers markets inaccessible to Americans is True. Why?** Because I got some facts, and they are:\n1. The Real example of states that categorized as low socio-economic status based on per capita income, median household income is **puerto rico states**. In this states, they have avarage per capita income USD 15.160 and median household income USD 23.387. That amounts of money enough to make **puerto rico states** categorized as cluster three based on product availability\/group and nutrition program. To recall, cluster three (3) is the lowest access both on nutrition programs (WIC, SFMNP, SNAP) that U.S Government provides and product variety and availability. Another states that similar to puerto rico are idaho, new mexico, montana, etc.\n2. But how is the condition of a prosperous country?. I will tell you about **New York, California, & Massachusetts**. Three of them so rich and have better access both on product availability\/variety and nutrition program. They are on the top rank of all clustering and that is proof for problem question.\n3. Also, I want to tell some anomalies that exists based on cluster above. In **New Hampries, Connecticut,& Hawaii** which is generally known as a prosperous state, both of them dont have better access to farmer product availability and nutrition program. I dont know why, but I think, because they have high per capita income and household income, they are prohibited for accessing nutrition program.\n\nSo, that's my answers. I am open to receive advice & comments from all of you, because I am a beginner in this field. Thanks !!","d2d18726":"* Average number of stores that serve **Eggs** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Flowers** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Fruits** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Grains** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Herbs** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Honey** (from highest to lowest): two > four > one > three","129e15ea":"We have remove every outlier. So, after this, we will continue on analyze step.","c0955f45":"<a id=\"section-one\"><\/a>\n# Overview\n***\n<a id=\"subsection-one-one\"><\/a>\n## Problem Question\n\nProblem question for this task is **One criticism of farmers markets are that they are inaccessible to Americans who live in certain parts of the country or are of low socio-economic status. Does the data reflect this criticism?** ","7385d226":"After I change data format, next I want to know nature of data. In this step, I want to know **column of dataframe, is there any null value, and also which column that has null value**\n***","10984d99":"* Average number of stores that serve **Nursery** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Nuts** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **Organic** (from highest to lowest): two > four > one > three\n* Average number of stores that serve **PetFood** (from highest to lowest): two > four > one > three","c98d2ddb":"Based on graph above, we have to use approximately 3-10 components. But I wan to use just 3 components PCA.","e124be09":"After my code conducts KMeans clustering, I try to representing that to graph. Graph that you can see above is parallel plot of standard value of dataframe cluster 1. To remind you, df_cluster_1 is for clustering based on citizen income. So, there are 4 different cluster:\n* One (Red Area)\n* Two (Yellow Area)\n* Three (Green Area)\n* Four (Blue Area)\n\nI will drill more specific characteristics below\n\n## Cluster One (Red Area)\n***\nI think most of state on U.S fall into this category. In general, statistics tell us that they are: the third highest per capita income, median household income, median family income.\n\n## Cluster Two (Yellow Area)\n***\nAproximately, there are 5 states that fall into this category. Obviously, the unique characteristics of this cluster are huge amount of population and also household. So, I think, this states are metropolitan states with crowder population. In general, statistics tell us that they are: the second highest per capita income, median household income, median family income.\n\n## Cluster Three (Green Area)\n***\nThey have lowest per capita income, median household income, and family income with average population and number of household compared to other cluster. It means that they tend to be **low social economic status**.\n\n## Cluster Four (Blue Area)\n***\nThey have highest per capita income, median household income, and family income with average population and number of household compared to other cluster. It means that they tend to be **richest social economic status**.","1f5bcfa9":"<a id=\"section-four\"><\/a>\n# Pre-processing\n***\nIn this step, I will remove some feature that doesnt important. And then, I will exchange value Y to 1 and N to 0"}}