{"cell_type":{"380a11bc":"code","2a51027a":"code","a8f268a7":"code","46113406":"code","89183856":"code","f3139fa4":"code","e8a4f48f":"code","376e4611":"code","23b5377e":"code","7deea9c3":"code","bb35f648":"code","90b4f191":"code","82a5ec8e":"code","7cc13ba1":"code","968a7af0":"code","e455cb26":"code","fcb2035e":"code","90869e22":"code","a377954e":"code","b2b6a8c5":"code","16409036":"code","e47586f5":"code","d0c73b3b":"code","f9edef82":"code","c5d39eb8":"code","a13a2118":"code","bcd6c3e9":"code","899ac726":"code","10ac21d4":"code","cb7891a6":"code","f9b4747e":"code","bafbccdc":"code","ad20b5bd":"code","2bcf5612":"code","6dd638d4":"code","f113dbd2":"code","9eaf9e23":"code","c5c8c98e":"code","0c7c3933":"code","658613ae":"code","55e3349b":"code","4231ac05":"code","abd0d7d2":"code","c53bc17a":"code","2309c9e2":"code","f4a16f2f":"code","eb373813":"code","adb9aa43":"code","a2c3b96d":"code","80bb2b04":"code","371ac7cb":"code","4c644b2d":"markdown","5f04d06d":"markdown","3b2bd9d5":"markdown","8f46d483":"markdown","c05ddc6d":"markdown","ed5ea1e0":"markdown","1bc7203f":"markdown","d169527d":"markdown"},"source":{"380a11bc":"import time\n\nimport pandas as pd\nimport json\nimport pdb\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport re\nfrom nltk.corpus import wordnet as wn\n\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split,KFold\nfrom sklearn.metrics import accuracy_score\nfrom scipy.sparse import csr_matrix\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix,classification_report\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning) ","2a51027a":"def open_json_file(file):\n    \"\"\"Function to open JSON files\"\"\"\n    json_opened = json.load(open(file))\n    return json_opened","a8f268a7":"#readining in data\ntrain = open_json_file('..\/input\/train.json')\ntest = open_json_file('..\/input\/test.json')","46113406":"print(\"--- sample of training data set ---\")\ntrain[0:1]","89183856":"print(\"--- sample of testing data set ---\")\ntest[0:1]","f3139fa4":"print(\"Training data set size:\",len(train))\nprint(\"Testing data set size:\",len(test))","e8a4f48f":"def pre_process_data(data):\n    \"\"\"This function removes punctuations, special characters letters, and symbols from a list of words\"\"\"\n    new_data = []\n    for recipe in data:\n        new_recipe = []\n        for ingredient in recipe:\n            new_ingredient_list = []\n            for word in ingredient.split():\n                word = re.sub('[^a-zA-Z -]+', '', word) # only keeping the letters, spaces, and hyphens\n                new_ingredient_list.append(wn.morphy(word.lower().strip(\",.!:?;' \")) or word.strip(\",.!:?;' \")) # strip, stem, and append the word\n            new_recipe.append(' '.join(new_ingredient_list))\n        new_data.append(new_recipe)\n    return new_data","376e4611":"#ingredients for training\nx_train = list([train[i]['ingredients'] for i in range(len(train))])\n#labels\/cuisines for training\ny_train_labels = [train[i]['cuisine'] for i in range(len(train))]","23b5377e":"#ingredients for test data\nx_test = list([test[i]['ingredients'] for i in range(len(test))])","7deea9c3":"#pre-process data\nnew_x_train = pre_process_data(x_train)\nnew_x_test = pre_process_data(x_test)","bb35f648":"# prepare X and y\nprint (\"--- Label Encode the Target Variable ---\")\nlb_enc = LabelEncoder()\ny_enc_labels = lb_enc.fit_transform(y_train_labels)\nprint(y_enc_labels)","90b4f191":"# Text Data Features\ndef bag_of_words(data):\n\ttext_data = [' '.join(recipe).lower() for recipe in data] \n\treturn text_data \n\ndef concatenated_words(data):\n\ttext_data = [' '.join(word.replace(\" \",\"_\").lower() for word in recipe) for recipe in data]\n\treturn text_data ","82a5ec8e":"print (\"--- Preparing text data ---\")\n#feature extraction - take #1 \ntrain_text = bag_of_words(x_train)\nsubmission_text = bag_of_words(x_test)\n\n#feature extraction - take #2\n### Here, we are treating every word as a feature\nprep_train_text = bag_of_words(new_x_train)\nprep_submission_text = bag_of_words(new_x_test)\n\n#feature extraction - take #3\n### If an ingredients has multiple words, we will be joining them with an underscore before seperating each ingredient.\nprep_train_text_underscore = concatenated_words(new_x_train)\nprep_submission_text_underscore = concatenated_words(new_x_test)\n\n","7cc13ba1":"# Feature Engineering \ntfidf_enc = TfidfVectorizer()\n\ndef tf_idf_features(text, flag):\n    \"\"\"Fitting TFIDF vectorizer to training data and transforming everything else\"\"\"\n    if flag == \"train\":\n        x = tfidf_enc.fit_transform(text)\n    else:\n        x = tfidf_enc.transform(text)\n    x = x.astype('float16')\n    return x ","968a7af0":"#creating features for each feature engineering approach\ntrain_text_features = tf_idf_features(train_text, flag=\"train\")\nsubmission_text_features = tf_idf_features(submission_text, flag=\"submission\")\n\nprep_train_text_features = tf_idf_features(prep_train_text, flag=\"train\")\nprep_submission_text_features = tf_idf_features(prep_submission_text, flag=\"submission\")\n\nprep_train_text_underscore_features = tf_idf_features(prep_train_text_underscore, flag=\"train\")\nprep_submission_text_underscore_features = tf_idf_features(prep_submission_text_underscore, flag=\"submission\")","e455cb26":"#getting a benchmark\nRANDOM_SEED = 1\nnames = ['DecisionTree','RandomForestClassifier','Logistic_Regression', \"SVC\"]\n\n#declaring the necessary information for each regression model\nregressors = [DecisionTreeClassifier(random_state = RANDOM_SEED),\n    #RandomForestClassifier(n_estimators = 1, random_state = RANDOM_SEED), \n              RandomForestClassifier(n_estimators = 10, random_state = RANDOM_SEED), \n              LogisticRegression(random_state = RANDOM_SEED),\n              SVC(C=10, gamma = 1, decision_function_shape=None, random_state = RANDOM_SEED),\n              ]\n\ndef kfold_cross_validation(X,y, col_names):\n    # In[315]:\n\n    #ten cross-validation employed here\n\n    #shuffling the data\n    #np.random.seed(RANDOM_SEED)\n\n    # specify the k-fold cross-validation design\n    N_FOLDS = 3\n\n    # set up numpy array for storing results\n    cv_results = np.zeros((N_FOLDS, len(names)))\n\n    kf = KFold(n_splits = N_FOLDS, shuffle = False, random_state = RANDOM_SEED)\n\n    index_for_fold = 0 #fold count initialized\n\n    for train_index, test_index in kf.split(X,y):\n        print('\\nFold index:', index_for_fold + 1,\n             '------------------------------------------')\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n        print('\\nShape of input data for this fold:',\n              '\\nData Set: (Observations, Variables)')\n        print('X_train:', X_train.shape)\n        print('X_test:',X_test.shape)\n        print('y_train:', y_train.shape)\n        print('y_test:',y_test.shape)\n\n        index_for_method = 0 #initialize\n        for name, reg_model in zip(names, regressors):\n            print('\\nRegression model evaluation for:', name)\n            print(' Scikit Learn method:', reg_model)\n            reg_model.fit(X_train, y_train) #fit on the train set for this fold\n\n            #evaluate on the test set for this fold\n            y_test_predict = reg_model.predict(X_test)\n\n            fold_method_result = reg_model.score(X_test, y_test)\n\n            cv_results[index_for_fold, index_for_method] = fold_method_result\n            index_for_method += 1\n\n        index_for_fold += 1\n        cv_results_df = pd.DataFrame(cv_results)\n        cv_results_df.columns = col_names\n    return cv_results_df\n","fcb2035e":"import time\nstarttime = time.monotonic()\n\nprint(\"--- Performing 3-fold cross validation ---\\n\")\n\nprint(\"---------Standard Results---------\")\ntrain_text_cv = kfold_cross_validation(train_text_features,\n                                       y_enc_labels, \n                                       col_names = [\"DecisionTree\",\n                                                    \"RandomForest\", \n                                                    \"LogisticRegression\",\n                                                    \"SVM\"])\n\nprint(\"\\n\\n---------Removing Special Characters & Punctuations Results---------\")\nprep_train_text_cv = kfold_cross_validation(prep_train_text_features,\n                                            y_enc_labels,\n                                            col_names = [\"DecisionTree\",\n                                                         \"RandomForest\",\n                                                         \"LogisticRegression\",\n                                                         \"SVM\"])\n\nprint(\"\\n\\n---------Concatenated Words Results---------\")\nprep_train_text_underscore_cv = kfold_cross_validation(prep_train_text_underscore_features,\n                                                       y_enc_labels,\n                                                      col_names = [\"DecisionTree\",\n                                                                   'RandomForest',\n                                                                   'LogisticRegression',\n                                                                   \"SVM\"])\n\nprint(\"\\n\\nThat took \", (time.monotonic()-starttime)\/60, \" minutes\")","90869e22":"print(\"--- Standard Scores ---\")\nprint(train_text_cv.mean())\nprint()\nprint(\"--- Removing Special Characters & Punctuations Scores ---\")\nprint(prep_train_text_cv.mean())\nprint()\nprint(\"--- Concatenated Words Scores ---\")\nprint(prep_train_text_underscore_cv.mean())","a377954e":"#chose the method of removing special characters and punctuations based on performance\nbaseline_models = pd.DataFrame(prep_train_text_cv.mean(),columns=[\"Avg Accuracy\"])\nbaseline_models = baseline_models.reset_index()\nbaseline_models.columns = [\"Model\",\"Baseline Score\"]","b2b6a8c5":"baseline_models","16409036":"def grid_search_function(func_X_train, func_X_test, func_y_train, func_y_test, parameters, model):\n    model = model(random_state=RANDOM_SEED)\n\n    grid_search = GridSearchCV(model, parameters)\n\n    classifier= grid_search.fit(func_X_train,func_y_train)\n\n    #score = classifier.score(func_X_test, func_y_test)\n    return classifier","e47586f5":"def train_test_split_function(X,y, test_size_percent):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_percent, random_state=RANDOM_SEED)\n    return X_train, X_test, y_train, y_test","d0c73b3b":"### RANDOM FOREST CLASSIFIER\nstarttime = time.monotonic()\nparameters = {'n_estimators':[10,100,300]}\nX_train, X_test, y_train, y_test = train_test_split_function(prep_train_text_features, \n                                                             y_enc_labels, \n                                                             test_size_percent = 0.20)\n\nrf_classifier = grid_search_function(X_train, X_test, y_train, y_test, \n                                     parameters, \n                                     model = RandomForestClassifier)\n\nprint(\"\\n\\nThat took \", (time.monotonic()-starttime)\/60, \" minutes\")","f9edef82":"rf_classifier.best_estimator_","c5d39eb8":"def training_info_and_classification_report(X,y,test_size_percent, model):\n    \"\"\"This function retrieves the training and testing score from a model and calculates the\n       classification report. The function will output the training score, testing score,\n       classification report, confusion matrix array, normalized confusion matrix array, and\n       a dataframe of the normalized confusion matrix. This dataframe can then be used to plot\n       a confusion matrix error plot.\"\"\"\n    starttime = time.monotonic()\n    X_train, X_test, y_train, y_test = train_test_split_function(X,y, test_size_percent)\n    print(\"\\n--- Fitting Model ---\")\n    model.fit(X_train, y_train)\n    print(\"\\n--- Predicting Cuisines ---\")\n    y_predict = model.predict(X_test)\n    print(\"\\n--- Scoring Model ---\")\n    model_training_score = model.score(X_train,y_train)\n    \n    model_testing_score = model.score(X_test,y_test)\n    print(\"\\n--- Creating Classification Report ---\")\n    clf_report = classification_report(y_test,\n                          y_predict,\n                          target_names = lb_enc.inverse_transform(model.classes_).tolist())\n    \n    array = confusion_matrix(y_test, y_predict)\n    \n    row_sums = array.sum(axis=1,keepdims=True)\n    norm_conf_mx = array\/row_sums\n\n    error_matrix_df = pd.DataFrame(norm_conf_mx, index = [i for i in lb_enc.inverse_transform(model.classes_).tolist()],\n                  columns = [i for i in lb_enc.inverse_transform(model.classes_).tolist()])\n    \n    print(\"\\n\\nThat took \", (time.monotonic()-starttime)\/60, \" minutes\")\n    \n    return model_training_score, model_testing_score, clf_report, array, norm_conf_mx, error_matrix_df","a13a2118":"training_score_rf,testing_score_rf,rf_classification_report, rf_array, rf_norm_conf_mx, rf_error_matrix_df = training_info_and_classification_report(prep_train_text_features,\n                                                                                                     y_enc_labels,\n                                                                                                     test_size_percent = 0.20,\n                                                                                                     model = rf_classifier.best_estimator_)","bcd6c3e9":"print(\"           Random Forest Classification Report           \")\nprint(rf_classification_report)","899ac726":"plt.figure(figsize = (20,15))\nsns.heatmap(rf_error_matrix_df, annot=False, fmt='g',cmap=\"Greens\")\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.title(\"Confusion Matrix Error Plot\")\nplt.show()","10ac21d4":"starttime = time.monotonic()\nparameters = {'C':[1,5,10,100,1000]}\nX_train, X_test, y_train, y_test = train_test_split_function(prep_train_text_features, \n                                                             y_enc_labels, \n                                                             test_size_percent = 0.20)\n\nlogreg_classifier = grid_search_function(X_train, X_test, y_train, y_test, parameters, model = LogisticRegression)\nprint(\"\\n\\nThat took \", (time.monotonic()-starttime)\/60, \" minutes\")","cb7891a6":"logreg_classifier.best_estimator_","f9b4747e":"training_score_lgr,testing_score_lgr,lgr_classification_report, lgr_array, lgr_norm_conf_mx, lgr_error_matrix_df = training_info_and_classification_report(prep_train_text_features,\n                                                                                                     y_enc_labels,\n                                                                                                     test_size_percent = 0.20,\n                                                                                                     model = logreg_classifier.best_estimator_)","bafbccdc":"print(\"           Logistic Regression Classification Report           \")\nprint(lgr_classification_report)","ad20b5bd":"plt.figure(figsize = (20,15))\nsns.heatmap(rf_error_matrix_df, annot=False, fmt='g',cmap=\"Greens\")\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.title(\"Confusion Matrix Error Plot\")\nplt.show()","2bcf5612":"###Took ~8 Hours to run this GridSearch\n#starttime = time.monotonic()\n#\n#parameters = {'C':(1,10,100,300), 'decision_function_shape':[None], 'gamma': (0.01,1,2,3,'auto'), 'kernel':('rbf','poly','linear') }\n#\n#X_train, X_test, y_train, y_test = train_test_split_function(prep_train_text_features, \n#                                                             y_enc_labels, \n#                                                             test_size_percent = 0.20)\n#\n#all_svm_classifier = grid_search_function(X_train, X_test, y_train, y_test, parameters, model = SVC)\n#\n#print(\"\\n\\nThat took \", (time.monotonic()-starttime)\/60, \" minutes\")\n#\n#all_svm_classifier.best_estimator_\n\n##winning parameters: (C=1, decision_function_shape = None, gamma= 1, kernel='rbf')","6dd638d4":"svm_clf = SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n  max_iter=-1, probability=False, random_state=1, shrinking=True,\n  tol=0.001, verbose=False)\nsvm_ovr = OneVsRestClassifier(svm_clf)","f113dbd2":"def get_training_info(model,full_X_train, full_y_train):\n    \"\"\"Seperate function to run for SVM due to lengthy processing time and conflict when probability = True.\n       This function will retunr the training and testing score of a predefined model\"\"\"\n    X_train, X_test, y_train, y_test = train_test_split_function(full_X_train, \n                                                             full_y_train, \n                                                             test_size_percent = 0.20)\n    print(\"\\n--- Fitting Model ---\")\n    model.fit(X_train, y_train)\n    \n    print(\"\\n--- Scoring Model ---\")\n    model_training_score = model.score(X_train,y_train)\n    model_testing_score = model.score(X_test,y_test)\n    \n    return model_training_score,model_testing_score\n    ","9eaf9e23":"def get_classification_report(X,y,test_size_percent, model):\n    \"\"\"Seperate function to run for SVM due to lengthy processing time and conflict when probability = True.\n       This function will calculate the classification report, classifcation matrix array, normalized classificaiton\n       matrix array, and dataframe for the ormalized classificaiton matrix array.\"\"\"\n    X_train, X_test, y_train, y_test = train_test_split_function(X,y, test_size_percent)\n    \n    model.fit(X_train, y_train)\n    \n    y_predict = model.predict(X_test)\n    \n    clf_report = classification_report(y_test,\n                          y_predict,\n                          target_names = lb_enc.inverse_transform(model.classes_).tolist())\n    \n    array = confusion_matrix(y_test, y_predict)\n    \n    row_sums = array.sum(axis=1,keepdims=True)\n    norm_conf_mx = array\/row_sums\n\n    error_matrix_df = pd.DataFrame(norm_conf_mx, index = [i for i in lb_enc.inverse_transform(model.classes_).tolist()],\n                  columns = [i for i in lb_enc.inverse_transform(model.classes_).tolist()])\n    \n    return clf_report, array, norm_conf_mx, error_matrix_df","c5c8c98e":"training_score_svm, testing_score_svm = get_training_info(svm_ovr,prep_train_text_features,y_enc_labels)     ","0c7c3933":"#need 'probability = True' for OneVsRestClassifier VotingClassifier\np_svm_clf = SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n  max_iter=-1, probability=True, random_state=1, shrinking=True,\n  tol=0.001, verbose=False) ","658613ae":"#svm_ovr = OneVsRestClassifier(all_svm_classifier.best_estimator_)\nsvm_ovr_clf = OneVsRestClassifier(p_svm_clf)\nsvm_classification_report, svm_array, svm_norm_conf_mx, svm_error_matrix_df = get_classification_report(prep_train_text_features,\n                                                                                                     y_enc_labels,\n                                                                                                     test_size_percent = 0.20,\n                                                                                                     model = svm_ovr_clf)","55e3349b":"print(\"           SVM Classification Report           \")\nprint(svm_classification_report)","4231ac05":"plt.figure(figsize = (20,15))\nsns.heatmap(svm_error_matrix_df, annot=False, fmt='g',cmap=\"Greens\")\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.title(\"Confusion Matrix Error Plot\")\nplt.show()","abd0d7d2":"rf_clf = rf_classifier.best_estimator_\nlgr_clf = logreg_classifier.best_estimator_\n#svm_clf = all_svm_classifier.best_estimator_\n\nprint(rf_clf,\"\\n\")\nprint(lgr_clf,\"\\n\")\nprint(svm_clf,\"\\n\")","c53bc17a":"#starttime = time.monotonic()\n#print(\"Getting best model results for Random Forest classifier\")\n#training_score_rf,testing_score_rf=get_training_info(rf_clf,prep_train_text_features,y_enc_labels)\n#print(\"\\nThat took \", (time.monotonic()-starttime)\/60, \" minutes\\n\")\n#\n#starttime = time.monotonic()\n#print(\"Getting best model results for Logistic Regression\")\n#training_score_lgr,testing_score_lgr=get_training_info(lgr_clf,prep_train_text_features,y_enc_labels)\n#print(\"\\nThat took \", (time.monotonic()-starttime)\/60, \" minutes\\n\")\n#\n#starttime = time.monotonic()\n#print(\"Getting best model results for SVM\")\n###Already retrieved##\n##svm_ovr_clf = OneVsRestClassifier(svm_clf)\n##training_score_svm,testing_score_svm=get_training_info(svm_ovr_clf,prep_train_text_features,y_enc_labels)\n#print(\"\\nThat took \", (time.monotonic()-starttime)\/60, \" minutes\\n\")","2309c9e2":"model_names = [\n    \"Random Forest Classifier\",\n    \"Logistic Regression\",\n    \"SVM\",\n    \"VotingClassifier\"]\n\n\nbest_model_testing_score = [\n    testing_score_rf,\n    testing_score_lgr,\n    testing_score_svm,\n    \"-\"\n                   ]\n\nbest_model_training_score = [\n    training_score_rf,\n    training_score_lgr,\n    training_score_svm,\n    \"-\"\n]","f4a16f2f":"def model_to_submission_file(model, full_X_train, full_y_train, full_X_test ,nameOfcsvfile):\n    print(\"\\n--- Fitting Model ---\")\n    starttime = time.monotonic()\n    model_clf = model.fit(full_X_train,full_y_train)\n    \n    print(\"\\n--- Predicting Cuisines ---\")\n    submission_pred = model_clf.predict(full_X_test)\n    test_cuisine = lb_enc.inverse_transform(submission_pred)\n\n    test_id = [recipe['id'] for recipe in test]\n\n    submission_df = pd.DataFrame({'id':test_id, 'cuisine':test_cuisine},columns = ['id','cuisine'])\n\n    submission_df.to_csv('{}'.format(nameOfcsvfile), index= False)\n    print(\"\\n--- Results have been saved ---\")\n    print(\"\\nThat took \", (time.monotonic()-starttime)\/60, \" minutes\")","eb373813":"#model_to_submission_file(model=rf_clf,\n#                         full_X_train=prep_train_text_features,\n#                         full_y_train=y_enc_labels,\n#                         full_X_test=prep_submission_text_features,\n#                         nameOfcsvfile=\"randomforest_model.csv\")\n##0.75663","adb9aa43":"#model_to_submission_file(model=lgr_clf,\n#                         full_X_train=prep_train_text_features,\n#                         full_y_train=y_enc_labels,\n#                         full_X_test=prep_submission_text_features,\n#                         nameOfcsvfile=\"logistic_regression_model.csv\")\n##0.78751","a2c3b96d":"ovr_svm = OneVsRestClassifier(svm_clf, n_jobs = 4)\n\nmodel_to_submission_file(model=ovr_svm,\n                         full_X_train=prep_train_text_features,\n                         full_y_train=y_enc_labels,\n                         full_X_test=prep_submission_text_features,\n                         nameOfcsvfile=\"svm_model.csv\")\n#0.81999","80bb2b04":"#ovr_svm = OneVsRestClassifier(p_svm_clf, n_jobs = 4)\n#vt_clf = VotingClassifier(estimators=[('rf',rf_clf), \n#                                      ('log_reg',lgr_clf),\n#                                      ('SVM+ovr', ovr_svm)],\n#                                      voting = 'soft',\n#                                      weights = [1,2,4])\n#vt_clf.fit(prep_train_text_features,y_enc_labels)\n#\n#submission_pred = vt_clf.predict(prep_submission_text_features)\n#test_cuisine = lb_enc.inverse_transform(submission_pred)\n#\n#test_id = [recipe['id'] for recipe in test]\n#\n#submission_df = pd.DataFrame({'id':test_id, 'cuisine':test_cuisine},columns = ['id','cuisine'])\n#submission_df.to_csv('votingclassifier.csv', index= False)\n##0.81989","371ac7cb":"#submission score\nmodel_testing_score = [0.75663, 0.78751, 0.81999, 0.81989]\n\npd.DataFrame({\"Model\":model_names,\n              \"Training Score\":best_model_training_score,\n              \"Testing Score\": best_model_testing_score,\n              \"Submission Score\": model_testing_score},\n             columns=[\"Model\",\"Training Score\", \"Testing Score\", \"Submission Score\"])","4c644b2d":"_SVM_","5f04d06d":"__Model Creation__","3b2bd9d5":"__Feature Engineering__","8f46d483":"*Best Results for each model*","c05ddc6d":"__Preprocess Steps__","ed5ea1e0":"_Random Forest Classifier_","1bc7203f":"_Logistic Regression_","d169527d":"__Hyper-parameter Tuning__"}}