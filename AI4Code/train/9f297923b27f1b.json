{"cell_type":{"3fc61d3e":"code","7a788d4e":"code","04dfe4dd":"code","e1c9bc88":"code","914b34c1":"code","3386c1b7":"code","c1bc5c15":"code","0c0db036":"code","c9e918f4":"code","2e50cdb3":"code","a3463537":"code","36eb2b40":"code","a5892c60":"code","06b1c141":"markdown","10fd6ab0":"markdown","f8d47294":"markdown","fa526d5c":"markdown","683aed7b":"markdown","64b2cb2d":"markdown","2bd5f613":"markdown","3b134207":"markdown","9b1419b8":"markdown","b4fec3ce":"markdown","dfb23a2a":"markdown","ed183f74":"markdown","8bd59461":"markdown","2a4917e8":"markdown","f42ab933":"markdown"},"source":{"3fc61d3e":"import numpy as np\nimport pandas as pd\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, MaxPool2D, BatchNormalization\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import RMSprop\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nimport xml.etree.ElementTree as ET\nimport sklearn\nimport itertools\nimport cv2\nimport scipy\nimport os\nimport csv\nimport matplotlib.pyplot as plt\n%matplotlib inline","7a788d4e":"dict_characters = {1:'NEUTROPHIL',2:'EOSINOPHIL',3:'MONOCYTE',4:'LYMPHOCYTE'}\n","04dfe4dd":"# Note that the function below is adapted from https:\/\/github.com\/Shenggan\/BCCD_Dataset\nimage = cv2.imread(\"..\/input\/dataset-master\/dataset-master\/JPEGImages\/BloodImage_00022.jpg\")\ntree = ET.parse(\"..\/input\/dataset-master\/dataset-master\/Annotations\/BloodImage_00022.xml\")\nfor elem in tree.iter():\n    if 'object' in elem.tag or 'part' in elem.tag:\n        for attr in list(elem):\n            if 'name' in attr.tag:\n                name = attr.text\n            if 'bndbox' in attr.tag:\n                for dim in list(attr):\n                    if 'xmin' in dim.tag:\n                        xmin = int(round(float(dim.text)))\n                    if 'ymin' in dim.tag:\n                        ymin = int(round(float(dim.text)))\n                    if 'xmax' in dim.tag:\n                        xmax = int(round(float(dim.text)))\n                    if 'ymax' in dim.tag:\n                        ymax = int(round(float(dim.text)))\n                if name[0] == \"R\":\n                    cv2.rectangle(image, (xmin, ymin),\n                                (xmax, ymax), (0, 255, 0), 1)\n                    cv2.putText(image, name, (xmin + 10, ymin + 15),\n                            cv2.FONT_HERSHEY_SIMPLEX, 1e-3 * image.shape[0], (0, 255, 0), 1)\n                if name[0] == \"W\":\n                    cv2.rectangle(image, (xmin, ymin),\n                                (xmax, ymax), (0, 0, 255), 1)\n                    cv2.putText(image, name, (xmin + 10, ymin + 15),\n                            cv2.FONT_HERSHEY_SIMPLEX, 1e-3 * image.shape[0], (0, 0, 255), 1)\n                if name[0] == \"P\":\n                    cv2.rectangle(image, (xmin, ymin),\n                                (xmax, ymax), (255, 0, 0), 1)\n                    cv2.putText(image, name, (xmin + 10, ymin + 15),\n                            cv2.FONT_HERSHEY_SIMPLEX, 1e-3 * image.shape[0], (255, 0, 0), 1)\nplt.figure(figsize=(16,16))\nplt.imshow(image)\nplt.show()","e1c9bc88":"# Plot Image\ndef plotImage(image_location):\n    image = cv2.imread(image_name)\n    plt.imshow(image)\n    return\nimage_name = '..\/input\/dataset2-master\/dataset2-master\/images\/TRAIN\/EOSINOPHIL\/_0_207.jpeg'\nplt.figure(figsize=(16,16))\nplt.subplot(221)\nplt.title('Eosinophil')\nplt.axis('off') \nplotImage(image_name)\nimage_name = '..\/input\/dataset2-master\/dataset2-master\/images\/TRAIN\/LYMPHOCYTE\/_0_204.jpeg'\nplt.subplot(222)\nplt.title('Lymphocyte')\nplt.axis('off') \nplotImage(image_name)\nimage_name = '..\/input\/dataset2-master\/dataset2-master\/images\/TRAIN\/MONOCYTE\/_0_180.jpeg'\nplt.subplot(223)\nplt.title('Monocyte')\nplt.axis('off') \nplotImage(image_name)\nplt.subplot(224)\nimage_name = '..\/input\/dataset2-master\/dataset2-master\/images\/TRAIN\/NEUTROPHIL\/_0_292.jpeg'\nplt.title('Neutrophil')\nplt.axis('off') \nplotImage(image_name)","914b34c1":"reader = csv.reader(open('..\/input\/dataset2-master\/dataset2-master\/labels.csv'))\n# skip the header\nnext(reader)\nX3 = []\ny3 = []\nfor row in reader:\n    label = row[2]\n    if len(label) > 0 and label.find(',') == -1:\n        y3.append(label)\ny3 = np.asarray(y3)\nencoder = LabelEncoder()\nencoder.fit(y3)\nencoded_y = encoder.transform(y3)\ncounts = np.bincount(encoded_y)\nprint(counts)\nfig, ax = plt.subplots()\nplt.bar(list(range(5)), counts)\nax.set_xticklabels(('', 'Basophil', 'Eosinophil', 'Lymphocyte', 'Monocyte', 'Neutrophil'))\nax.set_ylabel('Counts')","3386c1b7":"from tqdm import tqdm\ndef get_data(folder):\n    \"\"\"\n    Load the data and labels from the given folder.\n    \"\"\"\n    X = []\n    y = []\n    z = []\n    for wbc_type in os.listdir(folder):\n        if not wbc_type.startswith('.'):\n            if wbc_type in ['NEUTROPHIL']:\n                label = 1\n                label2 = 1\n            elif wbc_type in ['EOSINOPHIL']:\n                label = 2\n                label2 = 1\n            elif wbc_type in ['MONOCYTE']:\n                label = 3  \n                label2 = 0\n            elif wbc_type in ['LYMPHOCYTE']:\n                label = 4 \n                label2 = 0\n            else:\n                label = 5\n                label2 = 0\n            for image_filename in tqdm(os.listdir(folder + wbc_type)):\n                img_file = cv2.imread(folder + wbc_type + '\/' + image_filename)\n                if img_file is not None:\n                    img_file = scipy.misc.imresize(arr=img_file, size=(60, 80, 3))\n                    img_arr = np.asarray(img_file)\n                    X.append(img_arr)\n                    y.append(label)\n                    z.append(label2)\n    X = np.asarray(X)\n    y = np.asarray(y)\n    z = np.asarray(z)\n    return X,y,z\nX_train, y_train, z_train = get_data('..\/input\/dataset2-master\/dataset2-master\/images\/TRAIN\/')\nX_test, y_test, z_test = get_data('..\/input\/dataset2-master\/dataset2-master\/images\/TEST\/')\n\n# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nfrom keras.utils.np_utils import to_categorical\ny_trainHot = to_categorical(y_train, num_classes = 5)\ny_testHot = to_categorical(y_test, num_classes = 5)\nz_trainHot = to_categorical(z_train, num_classes = 2)\nz_testHot = to_categorical(z_test, num_classes = 2)\nprint(dict_characters)\n","c1bc5c15":"import seaborn as sns\ndf = pd.DataFrame()\ndf[\"labels\"]=y_train\nlab = df['labels']\ndist = lab.value_counts()\nsns.countplot(lab)\nprint(dict_characters)","0c0db036":"def plotHistogram(a):\n    \"\"\"\n    Plot histogram of RGB Pixel Intensities\n    \"\"\"\n    plt.figure(figsize=(10,5))\n    plt.subplot(1,2,1)\n    plt.imshow(a)\n    plt.axis('off')\n    histo = plt.subplot(1,2,2)\n    histo.set_ylabel('Count')\n    histo.set_xlabel('Pixel Intensity')\n    n_bins = 30\n    plt.hist(a[:,:,0].flatten(), bins= n_bins, lw = 0, color='r', alpha=0.5);\n    plt.hist(a[:,:,1].flatten(), bins= n_bins, lw = 0, color='g', alpha=0.5);\n    plt.hist(a[:,:,2].flatten(), bins= n_bins, lw = 0, color='b', alpha=0.5);\nplotHistogram(X_train[1])","c9e918f4":"X_train=np.array(X_train)\nX_train=X_train\/255.0\n\nX_test=np.array(X_test)\nX_test=X_test\/255.0","2e50cdb3":"plotHistogram(X_train[1])","a3463537":"# Helper Functions  Learning Curves and Confusion Matrix\n\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nclass MetricsCheckpoint(Callback):\n    \"\"\"Callback that saves metrics after each epoch\"\"\"\n    def __init__(self, savepath):\n        super(MetricsCheckpoint, self).__init__()\n        self.savepath = savepath\n        self.history = {}\n    def on_epoch_end(self, epoch, logs=None):\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n        np.save(self.savepath, self.history)\n\ndef plotKerasLearningCurve():\n    plt.figure(figsize=(10,5))\n    metrics = np.load('logs.npy')[()]\n    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n        l = np.array(metrics[k])\n        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n        y = l[x]\n        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n    plt.legend(loc=4)\n    plt.axis([0, None, None, None]);\n    plt.grid()\n    plt.xlabel('Number of epochs')\n    plt.ylabel('Accuracy')\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (5,5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\ndef plot_learning_curve(history):\n    plt.figure(figsize=(8,8))\n    plt.subplot(1,2,1)\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('.\/accuracy_curve.png')\n    #plt.clf()\n    # summarize history for loss\n    plt.subplot(1,2,2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('.\/loss_curve.png')","36eb2b40":"import keras\ndict_characters = {1:'NEUTROPHIL',2:'EOSINOPHIL',3:'MONOCYTE',4:'LYMPHOCYTE'}\ndict_characters2 = {0:'Mononuclear',1:'Polynuclear'}\ndef runKerasCNNAugment(a,b,c,d,e):\n    batch_size = 128\n    num_classes = len(b[0])\n    epochs = 10\n#     img_rows, img_cols = a.shape[1],a.shape[2]\n    img_rows,img_cols=60,80\n    input_shape = (img_rows, img_cols, 3)\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=(3, 3),\n                     activation='relu',\n                     input_shape=input_shape,strides=e))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer=keras.optimizers.Adadelta(),\n                  metrics=['accuracy'])\n    datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n    history = model.fit_generator(datagen.flow(a,b, batch_size=32),\n                        steps_per_epoch=len(a) \/ 32, epochs=epochs, validation_data = [c, d],callbacks = [MetricsCheckpoint('logs')])\n    score = model.evaluate(c,d, verbose=0)\n    print('\\nKeras CNN #1C - accuracy:', score[1],'\\n')\n    y_pred = model.predict(c)\n    map_characters = dict_characters\n    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')    \n    Y_pred_classes = np.argmax(y_pred,axis=1) \n    Y_true = np.argmax(d,axis=1)\n    plotKerasLearningCurve()\n    plt.show()  \n    plot_learning_curve(history)\n    plt.show()\n    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n    plot_confusion_matrix(confusion_mtx, classes = list(dict_characters.values())) \n    plt.show()\nrunKerasCNNAugment(X_train,y_trainHot,X_test,y_testHot,1)","a5892c60":"dict_characters = dict_characters2\nrunKerasCNNAugment(X_train,z_trainHot,X_test,z_testHot,2)   \ndict_characters = {1:'NEUTROPHIL',2:'EOSINOPHIL',3:'MONOCYTE',4:'LYMPHOCYTE'}\n","06b1c141":"Automated methods like this can be used to save time and improve efficiency in clinical settings.","10fd6ab0":"*Step Three: Describe Data*","f8d47294":"*Step Eight: Evaluate Classification Models*","fa526d5c":"# Identify Blood Cell Subtypes From Images\n* Basophil vs Eosinophil vs Lymphocyte vs Monocyte vs Neutrophil\n* Mononuclear (Basophil + Lymphocyte vs Monocyte) vs Polynuclear (Neutrophil + Eosinophil)","683aed7b":"*Step Four: Load Augmented Dataset*","64b2cb2d":"An important problem in blood diagnostics is classifying different types of blood cells.  Here we have 410 original images and 12,500 augmented images of blood cells paired with subtype labels (Basophil vs Eosinophil vs Lymphocyte vs Monocyte vs Neutrophil).  We want to automatically classify each image according to the subtype of cells within it.\n\nFor more information about blood cells and blood cell subtypes, see the following links:\nhttps:\/\/www.ncbi.nlm.nih.gov\/books\/NBK2263\/ and https:\/\/www.ncbi.nlm.nih.gov\/books\/NBK2263\/box\/A26\/?report=objectonly","2bd5f613":"*Step Six: Preprocess Data*","3b134207":"To Do: (1) Evaluate InceptionV3 and VGG16 network architectures","9b1419b8":"Here you can see that with the original images we have imbalanced class sizes.  We will use the augmented images instead because they no longer have imbalanced class sizes due to oversampling.","b4fec3ce":"That worked reasonably well, with 95% accuracy for two categories {1:'MONONUCLEAR',2:'POLYNUCLEAR'} as compared to 85% accuracy for four categories {1:'NEUTROPHIL',2:'EOSINOPHIL',3:'MONOCYTE',4:'LYMPHOCYTE'}.  ","dfb23a2a":"*Step One: Import Modules*","ed183f74":"*Step Seven: Define Helper Functions*","8bd59461":"90% accuracy is much better than random chance!  Now let's see if maybe this model will work better for a binary classification task such as determining whether the cell is polynuclear (e.g. neutrophil and eusinophil) or mononuclear (e.g. every other subtype).  ","2a4917e8":"*Step Two: Plot Data*","f42ab933":"*Step Five: Describe Augmented Dataset*"}}