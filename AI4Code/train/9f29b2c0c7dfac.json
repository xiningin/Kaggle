{"cell_type":{"bdce281a":"code","3a95d860":"code","fab2dec0":"code","dc757519":"code","58300692":"code","007ed2d7":"code","05829d1c":"code","149b8cbf":"code","c2945ee4":"code","1157120e":"code","46b590a2":"code","59ee860e":"code","59e98a9c":"markdown"},"source":{"bdce281a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3a95d860":"from fastai.tabular.all import *\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\nfrom sklearn.tree import ExtraTreeClassifier, DecisionTreeClassifier","fab2dec0":"# Load the training dataset\ntrain_df = pd.read_csv('..\/input\/titanic\/train.csv', index_col = 'PassengerId')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv', index_col = 'PassengerId')\ng_sub = pd.read_csv('..\/input\/titanic\/gender_submission.csv', index_col = 'PassengerId')","dc757519":"# Data Processing \/ Feature Engineering\n\n# Ensure all fares have a value\ntrain_df['Fare'] = train_df['Fare'].fillna(train_df['Fare'].mean())\ntest_df['Fare'] = test_df['Fare'].fillna(train_df['Fare'].mean())\n\n# Determine if titled\ndef isTitled(str):\n    if \"Mr.\" not in str and \"Mrs.\" not in str and \"Miss.\" not in str and \"Master.\" not in str:\n        return True\n    else:\n        return False\n    \ntrain_df['Titled'] = train_df['Name'].map(isTitled)\ntest_df['Titled'] = test_df['Name'].map(isTitled)\n\n# Extract title\ndef getTitle(str):\n    if re.search(r'[^ ]*\\.', str) is not None:\n        return re.search(r'[^ ]*\\.', str).group(0)\n    else:\n        return None\n\ntrain_df['Title'] = train_df['Name'].map(getTitle)\ntest_df['Title'] = test_df['Name'].map(getTitle)\n\n# Cut down to last names\ntrain_df['Name'] = train_df['Name'].str.split(',', expand=True)[0]\ntest_df['Name'] = test_df['Name'].str.split(',', expand=True)[0]\n\n# Pull out type of ticket, where applicable\ndef isNumeric(str):\n    if str.isnumeric():\n        return np.nan\n    else:\n        return str.lower()\n    \ntrain_df['Ticket'] = train_df['Ticket'].fillna(-1)\ntrain_df['Ticket Class'] = train_df.Ticket.str.split(expand = True)[0].map(isNumeric)\ntest_df['Ticket'] = test_df['Ticket'].fillna(-1)\ntest_df['Ticket Class'] = test_df.Ticket.str.split(expand = True)[0].map(isNumeric)\n\n# Determine if they're alone on the voyage\ndef isAlone(row):\n    if row['Parch'] == 0 and row['SibSp'] == 0:\n        return True\n    else:\n        return False\n    \ntrain_df['isAlone'] = train_df.apply(func=isAlone, axis=1)\ntest_df['isAlone'] = test_df.apply(func=isAlone, axis=1)\n\ndef familySize(row):\n    return row['Parch'] + row['SibSp']\n\ntrain_df['familySize'] = train_df.apply(func=isAlone, axis=1)\ntest_df['familySize'] = test_df.apply(func=isAlone, axis=1)\n\ndef getFirstLetter(str):\n    if str[0] == '0':\n        return np.nan\n    else:\n        return str[0]\n\ntrain_df['Cabin'] = train_df['Cabin'].fillna('0')\ntrain_df['Cabin Bank'] = train_df['Cabin'].map(getFirstLetter)\n\ntest_df['Cabin'] = test_df['Cabin'].fillna('0')\ntest_df['Cabin Bank'] = test_df['Cabin'].map(getFirstLetter)\n\nto_drop = ['Ticket', 'Cabin']\ntrain_df = train_df.drop(to_drop, axis = 1)\ntest_df = test_df.drop(to_drop, axis = 1)","58300692":"def OHEByName(df, name):\n    OHE = pd.get_dummies(data = df[name], prefix = name)\n    df = df.drop(name, axis = 1)\n    df = df.join(OHE)\n    return df\n\n# OHE for specific columns\nto_OHE = []\nunique_values = train_df.nunique(axis = 0)\nunique_values = unique_values.drop('Survived')\nfor feature in unique_values.index:\n    if feature in to_OHE:\n        train_df = OHEByName(train_df, feature)\n        test_df = OHEByName(test_df, feature)\n        \ntrain_df.columns","007ed2d7":"# Identify categorical & continuous variables\ncont = ['Fare', 'Age', 'Pclass']\n# Form list from everything that's not in cont\ncat = list(train_df.drop(cont, axis = 1).columns)\n# Remove dependent variable, unnecessary OHE columns\ncat.remove('Survived')\n# remove value(s) I don't care about\n# to_remove = ['SibSp', 'Parch', 'Embarked', 'Title', 'Titled', 'Ticket Class', 'isAlone', 'Cabin Bank']\nto_remove = ['SibSp', 'Parch', 'Embarked', 'Title', 'Titled', 'Ticket Class', 'isAlone', 'Cabin Bank']\nfor entry in to_remove:\n    cat.remove(entry)\n    \n# After submitting several times & comparing MSE of validation set score vs. public score,\n# it looks like the 0-300 index is a pretty OK validation set\ntrain_dl = TabularDataLoaders.from_df(df = train_df, y_names = ['Survived'],\n                                     cat_names = cat, cont_names = cont, valid_idx = list(range(0, 300)),\n                                     procs=[Categorify, FillMissing, Normalize])\n\ntest_dl = TabularDataLoaders.from_df(df = test_df, valid_idx = [],\n                                     cat_names = cat, cont_names = cont,\n                                     procs=[Categorify, FillMissing, Normalize])\n\ntrain_dl.xs","05829d1c":"m = RandomForestClassifier()\nparameters = {'max_features': [0.2, 0.4, 0.6, 0.8, 1.0],\n              'min_samples_leaf': [1, 3, 5, 7, 10]}\nGSC = GridSearchCV(m, parameters, n_jobs = -1)\nGSC.fit(train_dl.train.xs, np.ravel(train_dl.train.ys))","149b8cbf":"GSC.score(train_dl.valid.xs, np.ravel(train_dl.valid.ys))\nmax_feat = GSC.best_params_['max_features']\nmin_samp = GSC.best_params_['min_samples_leaf']\nGSC.predict(test_dl.xs)\nprint('Score of {0} achieved by max_features = {1} and min_samples_leaf = {2}'.format(GSC.best_score_, GSC.best_params_['max_features'], GSC.best_params_['min_samples_leaf']))","c2945ee4":"n = RandomForestClassifier(n_jobs = -1, max_features = max_feat, min_samples_leaf = min_samp)\nn.fit(train_dl.train.xs, np.ravel(train_dl.train.ys))\nn.score(train_dl.valid.xs, np.ravel(train_dl.valid.ys))","1157120e":"# plot feature importance\nfeature_names = train_dl.train.xs.columns\nimportances = n.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in n.estimators_], axis=0)\nforest_importances = pd.Series(importances, index=feature_names)\nfig, ax = plt.subplots()\nforest_importances.plot.bar(yerr=std, ax=ax)\nax.set_title(\"Feature importances using MDI\")\nax.set_ylabel(\"Mean decrease in impurity\")\nfig.tight_layout()","46b590a2":"# Dendrogram\nfrom scipy.cluster import hierarchy as hc\ncorr = np.round(scipy.stats.spearmanr(train_dl.train.xs).correlation, 4)\ncorr_condensed = hc.distance.squareform(1-corr)\nz = hc.linkage(corr_condensed, method = 'average')\nfig = plt.figure(figsize = (16, 10))\ndendrogram = hc.dendrogram(z, labels=train_dl.train.xs.columns, orientation='left', leaf_font_size=16)\nplt.show()","59ee860e":"predictions = n.predict(test_dl.xs)\noutput = pd.DataFrame({'PassengerId': test_dl.xs.index, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","59e98a9c":"This notebook is to use the inferences from the notebook I used to analyze relationships to see if I can get a better score than 0.77272"}}