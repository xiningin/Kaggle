{"cell_type":{"1fa9fa9e":"code","7cf9e582":"code","22239589":"code","f1810254":"code","a5505b3f":"code","0275c9a8":"code","3679727b":"code","a46ae894":"code","2fcc8e88":"code","526ad427":"code","dc30a4b3":"code","a37ab2a4":"code","a682f72e":"code","179c8ae3":"code","9497feb7":"code","d57e6238":"code","9f8bed72":"code","b7fa2328":"code","b866b7cd":"code","addd9e8b":"code","8c044c92":"code","920ee309":"code","d029a199":"code","c46fec8d":"code","cc173e2a":"code","ac6948dc":"code","b5ccbcc8":"code","3bbbdb1c":"code","c11f0d60":"code","7b77b3ab":"code","4b07557e":"code","660e43c4":"code","d03fe94b":"code","4632f65e":"code","0784e280":"code","755624b8":"code","81de06cf":"code","6e3971ea":"code","befde01c":"code","f255bc5d":"code","cd81a026":"code","4dbc8a8c":"code","a47e2e2f":"code","65c36ff7":"code","adc7d936":"markdown","1752d635":"markdown","6c136ea4":"markdown","60074cef":"markdown","74a42d66":"markdown","acf4cf14":"markdown","4401b997":"markdown","54b97657":"markdown","b246c026":"markdown","6a7ae43a":"markdown","23d1fc18":"markdown","5af3fe64":"markdown","a9e3cb44":"markdown","9cc312b3":"markdown","3c6feee8":"markdown","1f823b1c":"markdown","eb5e416c":"markdown","498d6272":"markdown","a5069fae":"markdown","2effb193":"markdown","3560de43":"markdown","2d6a36cf":"markdown","70c92775":"markdown","45f325f4":"markdown","395b90d9":"markdown","f6715080":"markdown","720527b5":"markdown","b930a95c":"markdown","7e828afa":"markdown","4a0203da":"markdown","e28adddb":"markdown","3b6b6b06":"markdown","6ee1afb8":"markdown","0dbcc51f":"markdown","d09efbad":"markdown","0bd43b0c":"markdown","4f986d33":"markdown","12f6ef9b":"markdown","855b0c57":"markdown","5e7b1b1a":"markdown","f7c586d2":"markdown","0fcbc415":"markdown","0b3b0f53":"markdown","9f128b99":"markdown","b4014b74":"markdown","eca97f79":"markdown","5b41fee3":"markdown","66abe53d":"markdown"},"source":{"1fa9fa9e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7cf9e582":"train_set=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_set=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","22239589":"train_set.info()","f1810254":"train_set.describe()","a5505b3f":"train_set.describe(include=['object'])","0275c9a8":"train_set.head(5)","3679727b":"train_set.tail(5)","a46ae894":"tot_data_missing= train_set.isnull().sum()\nprint(tot_data_missing)","2fcc8e88":"#checking number of seinor citizens \n(train_set['Age'] >= 60).sum()","526ad427":"import matplotlib.pyplot as plt\nimport seaborn as sns","dc30a4b3":"plt.title('Survived')\nsns.countplot(train_set['Survived'])","a37ab2a4":"print('Percentage of people not be able to survive :',((train_set['Survived']==0).sum()\/train_set.shape[0])*100,'%')\nprint('Percentage of people able to survive :',((train_set['Survived']==1).sum()\/train_set.shape[0])*100,'%')","a682f72e":"women=train_set[train_set['Sex']=='female']\nmen= train_set[train_set['Sex']=='male']","179c8ae3":"ax=[]\nfig=plt.figure(figsize=(15,5))\nax.append(fig.add_subplot(1,2,1))\nax[-1].set_title(\"Female:\")\nsns.countplot(x='Survived',data=women)\nax.append(fig.add_subplot(1,2,2))\nax[-1].set_title(\"Male:\")\nsns.countplot(x='Survived',data=men)","9497feb7":"print('Percentage of women not be able to survive :',((women['Survived']==0).sum()\/train_set.shape[0])*100,'%')\nprint('Percentage of women able to survive :',((women['Survived']==1).sum()\/train_set.shape[0])*100,'%')","d57e6238":"print('Percentage of men not be able to survive :',((men['Survived']==0).sum()\/train_set.shape[0])*100,'%')\nprint('Percentage of men able to survive :',((men['Survived']==1).sum()\/train_set.shape[0])*100,'%')","9f8bed72":"ax=[]\nfig=plt.figure(figsize=(15,5))\nax.append(fig.add_subplot(1,2,1))\nax[-1].set_title(\"Women:\")\nplt.hist(women[women['Survived']==1].Age,label=\"Survived\", bins=18, color=\"silver\")\nplt.hist(women[women['Survived']==0].Age,label=\"Not Survived\", bins=40, color=\"orange\")\nplt.xlabel(\"Age\")\nplt.legend()\nax.append(fig.add_subplot(1,2,2))\nax[-1].set_title(\"Male:\")\nplt.hist(men[men['Survived']==1].Age,label=\"Survived\", bins=18, color=\"silver\")\nplt.hist(men[men['Survived']==0].Age,label=\"Not Survived\", bins=40, color=\"orange\")\nplt.xlabel(\"Age\")\nplt.legend()","b7fa2328":"sns.distplot(train_set['Age'])","b866b7cd":"FacetGrid = sns.FacetGrid(train_set, row='Embarked', height=4.0, aspect=1.6)\nFacetGrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette=None,  order=None, hue_order=None )\nFacetGrid.add_legend()","addd9e8b":"sns.barplot(x='Pclass', y='Survived', data=train_set)","8c044c92":"corr=train_set.corr()\n\ncolormap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr,cmap=colormap,xticklabels=corr.columns,yticklabels=corr.columns,annot=True)","920ee309":"dataset=[train_set,test_set]\nfor data in dataset:\n    data['relation']=data['SibSp']+data['Parch']","d029a199":"train_set=train_set.drop(['PassengerId','Cabin','SibSp','Parch'],axis=1)\ntrain_set.columns.values","c46fec8d":"test_id=test_set['PassengerId']\ntest_set=test_set.drop(['PassengerId','Cabin','SibSp','Parch'],axis=1)","cc173e2a":"dataset=[train_set,test_set]\nfor data in dataset:\n    mean=train_set[\"Age\"].mean()\n    std=train_set[\"Age\"].std()\n    is_null=data[\"Age\"].isnull().sum()\n    random_age=np.random.randint(mean - std, mean + std, size = is_null)\n    age=data[\"Age\"].copy()\n    age[np.isnan(age)]=random_age\n    data[\"Age\"]=age\n    data[\"Age\"]=train_set[\"Age\"].astype(int)    \ntrain_set[\"Age\"].isnull().sum()","ac6948dc":"data = [train_set, test_set]\nfor dataset in data:\n    common_value=dataset['Embarked'].mode()[0]\n    #print(common_value)\n    dataset['Embarked'] = dataset['Embarked'].fillna(common_value)","b5ccbcc8":"mean=test_set['Fare'].mean()\ntest_set['Fare'] = test_set['Fare'].fillna(mean)","3bbbdb1c":"train_set=train_set.drop(['Name','Ticket'],axis=1)\ntest_set=test_set.drop(['Name','Ticket'],axis=1)","c11f0d60":"from sklearn.preprocessing import LabelEncoder","7b77b3ab":"le=LabelEncoder()\ntrain_set['Sex']=le.fit_transform(train_set['Sex'])\ntest_set['Sex']=le.transform(test_set['Sex'])","4b07557e":"le=LabelEncoder()\ntrain_set['Embarked']=le.fit_transform(train_set['Embarked'])\ntest_set['Embarked']=le.transform(test_set['Embarked'])","660e43c4":"train_set.info()","d03fe94b":"test_set.info()","4632f65e":"Y=train_set['Survived']\nX=train_set.drop(['Survived'],axis=1)\ntest=test_set.copy()","0784e280":"from sklearn.model_selection import train_test_split","755624b8":"X_train,X_val,y_train,y_val=train_test_split(X,Y,test_size=0.3,random_state=17)","81de06cf":"from sklearn.linear_model import LogisticRegression","6e3971ea":"lr = LogisticRegression()\nlr.fit(X_train, y_train)","befde01c":"y_pred=lr.predict(X_val)","f255bc5d":"from sklearn import metrics","cd81a026":"mae=metrics.mean_absolute_error(y_val,y_pred)\nacc=metrics.accuracy_score(y_val,y_pred)\nprint(\"Accuracy Score: \",acc)\nprint(\"Mean Absolute Error: \",mae)","4dbc8a8c":"metrics.confusion_matrix(y_val,y_pred)","a47e2e2f":"y_test=lr.predict(test)","65c36ff7":"my_submission = pd.DataFrame({'PassengerId': test_id, 'Survived': y_test})\nmy_submission.to_csv('submission.csv', index=False)","adc7d936":"Let us check the first 5 rows of our training dataset.","1752d635":"We can infer that our target is a bit imbalanced, (details of many people present in this dataset, unfortunately have not survived (~61.61%) !) ","6c136ea4":"Since 'PassengerId' is a unique identification number, therefore, I have dropped it.\nWe know from above that the feature 'Cabin', having many missing values (687), thus, dropping it seems a good idea!","60074cef":"## Model Evaluation","74a42d66":"Now, that our data is finally preprocessing, let's apply a single machine learning algorithm and check how our model predicts!","acf4cf14":"**Remember: Whatever changes made to train data, same to be applied to test**","4401b997":"## Machine Learning (Logistic Regression)","54b97657":"Now, that we have a combined feature of 'SibSp' and 'Parch' ('relation'), we can drop those two also.","b246c026":"Before apply any algorithm, let's split our training dataset into training and validation.","6a7ae43a":"We can see that embarkment is correlated to chance of survival, but also depends on gender.","23d1fc18":"And that's  how the magic happens!","5af3fe64":"``describe()`` function can be used to view some basic statistical details like mean, std (standard deviation), min,max. We can see that the above function returns the details of numeric data type. To include the objects feature also, we can add the **include** parameter as:","a9e3cb44":"That's it for our basic visualizations, time for data preprocessing!","9cc312b3":"From the above heatmap graph, we can observe the Parch and SibSp are cvorrelated( which should be!)","3c6feee8":"## Loading Data","1f823b1c":"For now, we'll be dealing with simple numeric and categorical features. Let's remove the rest!","eb5e416c":"## Missing Values","498d6272":"The first thing we can do by combing the two features ('SibSp' and 'Parch') to combine into one 'relation'. **Why?** because both these features are correlated (according to heatmap above) and 'SibSp', as well as 'Parch' represent the same (relation with the passengers!) ","a5069fae":"## Visualizations","2effb193":"As mentioned earlier, we need to deal with few things before we start applying machine learning model.","3560de43":"We can see that **Embarked** feature has only 2 data missing, that can be easily dealt with. But the problems lies, with the features :\n> * Age and \n> * Cabin. \n\nWe can either provide with some data( like a random value, or most common with a mean, median or mode)  or we can drop it. So, we need to check features that could contribute to a high survival rate. To find better insights, let's visualize the data.","2d6a36cf":"It's a good idea to combine the correlated features into one to reduce the dimensionality. *(Would love to hear your opinion)!*","70c92775":"The training data and test data can be read wih the help of ``read_csv()`` function present in the pandas library.","45f325f4":"The distribution of Age seems to be kind of a Gaussian distribution ( except that small peak).","395b90d9":"It is interesting to check within the people who survived, how many were female and how many were male.\n> \n*As I remember (from the movie), women and childern were given the first priority to go in the rescue boat. Thus, there would be more females who survived*. Let's verify it. ","f6715080":"Let's evaluate how our model works with validation set!","720527b5":"On finally checking the non-null count for both training and test dataset, one value was missing in the 'Fare' faeture of test dataset. Let's fill it with mean!","b930a95c":"Now, all is left to add elements of age. We can just put the mean Age, or we can put a random value between [ mean-std, mean+std], becuase this feature has a bell-shaped (Gaussian) distribution curve.","7e828afa":"## Submission","4a0203da":"Note that, the ``describe()`` function for 'object' data type returns something else instead of what it was in the case of numeric data type.","e28adddb":"Instead of ``head()``, we can use that ``tail()`` function to get the last n rows.","3b6b6b06":"# UPVOTE THE NOTEBOOK IF IT WAS HELP TO YOU!","6ee1afb8":"Almost **52.52%** of men out of all the people were not able to survive! And **26.15%** of women out of all people were able to survive!","0dbcc51f":"As we can see, we have **891** training examples to train. We can observe the following:\n1.  Everyone's age is not available (we have 714 examples instead of 891). Similarly for Cabin (Cabin number) and Embarked (Port of Embarkation). Thus, we have to deal with the missing data here, and\n2. We have 5 features that are int64, 2 that are float64 and rest 5 are objects. Since machine learning models require numeric data, we need to make sure that the all the features that we use should be of numeric format.","d09efbad":"## Data Preprocessing","0bd43b0c":"For classification purposes, we can also check confusion matrix!","4f986d33":"**Points to see:**\n> * mostly women between the age of **15 to 40** have *survived*. Thus, we can say that probabilty of survival of a women between the age of 15 to 40 is high compared to rest. \n> * In case of men, the probability of survival is **very low between the similar age of 15 to 40**. We can also see that (in case for both men and women) , there is **high chance of survival if he\/she is an infant** ( between the age of 0 to 5 years).","12f6ef9b":"Let's check at last, if all the data types have been converted to numeric format and there is no missing value now for both training and test dataset.","855b0c57":"For 'Embarked', we only have 2 missing values. We can either drop or fill it it some value.\nAs we have realized that 'Embarked' is a categorical data type, the best value to fill it is the mode (the most frequently occuring value).","5e7b1b1a":"One more thing, as I mentioned above, not only women but also children were given priority in rescuing. We have **'Age'** feature with us, let's test it out!","f7c586d2":"To get a concise summary of our Dataframe (test_set), we can use to ``info()`` method. This method prints information about a DataFrame including the index dtype and column dtypes, non-null values and memory usage.","0fcbc415":"The first thing is always to check the distribution of our **'target'** data, (here is *'Survived'* feature). Since, this is a binary classification task, thus, we'll be using countplot to show the distribution.","0b3b0f53":"The result came is 0. All the missing values in 'Age' has been dealt with. The only feature with missing value left is 'Embarked'","9f128b99":"At last, after evaluating our model, we can predict the test set and save as '.csv' file as follows:","b4014b74":"Now that we have prepared the training examples, let's fit the model","eca97f79":"Let's import the most common used modules for visualizations, matplotlib and seaborn.","5b41fee3":"We are now left with 2 categorical features having data type 'object', using a simple LabelEncoder() to encode them in numeric format","66abe53d":"From above graph, we can see that rate of survival of Pclass 1 is higher than other 2."}}