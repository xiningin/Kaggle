{"cell_type":{"e0c2df83":"code","26a3ad50":"code","24a3df7c":"code","209394d3":"code","3e813dfa":"code","3a56af38":"code","e784dab3":"code","43a3214f":"code","c50f550a":"code","0e164107":"code","eb55921b":"code","ae0de01b":"code","eee06008":"code","e1b98312":"code","bd6cfa29":"code","306dec6e":"code","abaf16c0":"code","26fbdbe3":"markdown","0877d266":"markdown","0ddc2c69":"markdown","c7d392b9":"markdown","1af97d10":"markdown","73ab351c":"markdown","81372e11":"markdown","8517de7d":"markdown","92d94664":"markdown","9d1b0eb3":"markdown","adabae68":"markdown","eca060f5":"markdown"},"source":{"e0c2df83":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","26a3ad50":"# lets create a text\ntext = \"No woman no cry\"\n\n# length of text ( includes spaces)\nprint(\"length of text :\", len(text))\n\n# split the text\nsplitted_text = text.split()\n\nprint(\"splitted text :\", splitted_text)\n# each word is called token in text maning world.","24a3df7c":"# find specific words with list comprehension method\nspecific_words = [word for word in splitted_text if(len(word)>2)]\nprint(\"Specific words :\", specific_words)\n\n# capitalized words with istitle() method that finds capitalized words\ncapital_words = [word for word in splitted_text if word.istitle()]\nprint(\"Capatal_words :\", capital_words)\n\n\n# words which end with \"o\": endswith() method finds last letter of word\nwords_end_with_o = [word for word in splitted_text if word.endswith('o')]\nprint(\"Word_end_with_o :\", words_end_with_o)\n\n# words which starts with \"w\": startswith() method\nword_start_with_w = [word for word in splitted_text if word.startswith(\"w\")]\nprint(\"Word Start with w\", word_start_with_w)","209394d3":"# unique with set() method\nprint(\"uniquw words :\", set(splitted_text))\n\n# make all letters lowercase with lower() method\nlower_text = [word.lower() for word in splitted_text]\n\n# then find uniques again with set() method\nprint(\"unique lower words :\", lower_text)","3e813dfa":"# chech words includes or not includes particular substring or letter\nprint(\"Is w letter in woman word:\", \"w\" in \"woman\")\n\n# check words are upper case or lower case\nprint(\"Is word uppercase:\", \"WOMAN\".isupper())\nprint(\"Is word lowercase:\", \"cry\".islower())\n\n# check words are made of by digits or not\nprint(\"Is word made of by digits: \",\"12345\".isdigit())\n\n# get rid of from white space characters like spaces and tabs or from unwanted letters with strip() method\nprint(\"00000000No cry: \",\"00000000No cry\".strip(\"0\"))\n\n# find particular letter from front \nprint(\"Find particular letter from back: \",\"No cry no\".find(\"o\"))  # at index 1\n\n# find particular letter from back  rfind = reverse find\nprint(\"Find particular letter from back: \",\"No cry no\".rfind(\"o\"))  # at index 8\n\n# replace letter with letter\nprint(\"Replace o with 3 \", \"No cry no\".replace(\"o\",\"3\"))\n\n# find each letter and store them in list\nprint(\"Each letter: \",list(\"No cry\"))","3a56af38":"# Cleaning text\ntext1 = \"     Be fair and tolerant    \"\nprint(\"Split text1 :\", text1.split(\" \"))\n\n# get rid of from these unnecassary white spaces with strip() method then split\nprint(\"Cleaned text :\", text1.strip().split(\" \"))","e784dab3":"# reading files line by line\nf = open('..\/input\/religious-and-philosophical-texts\/35895-0.txt')\n\n# read first line\nprint(f.readline())\n\n# length of data\ntext3 = f.read()\nprint(\"length of text :\", len(text3))\n\n# Number of lines with splitlines() method\nlines = text3.splitlines()\nprint(\"Number of lines :\", len(lines))","43a3214f":"# read data\ndata = pd.read_csv(\"..\/input\/ben-hamners-tweets\/benhamner.csv\", encoding = \"latin-1\")\ndata.head()","c50f550a":"# find which entries contain the word 'appointment'\nprint(\"In his tweets, the rate of occuring kaggle word is: \", sum(data.text.str.contains('kaggle'))\/len(data))\n\n# text\ntext = data.text[1]\nprint(text)","0e164107":"# find regular expression on text\n# import regular expression package\nimport re\n\n# find callouts that starts with @\ncallouts = [word for word in text.split(\" \") if re.search(\"@[A-Za-z0-9_]+\", word)]\nprint(\"callouts: \", callouts)","eb55921b":"# continue finding regular expressions\n# [A-Za-z0-9_] =\\w\n# We will use \"\\w\" to find callouts and our result will be same because \\w matches with [A-Za-z0-9_]\ncallouts1 = [word for word in text.split(\" \") if re.search(\"@\\w+\", word)]\nprint(\"callouts: \", callouts1)","ae0de01b":"# find specific characters like \"w\"\nprint(re.findall(r\"w\", text))\n\n# \"w\"ith, \"w\"indo\"w\", sho\"w\"ing, s\"w\"itches \n\n# do not find specific character like \"w\". We will use \"^\" symbol\nprint(re.findall(r\"[^w]\", text))","eee06008":"# Regular expressions for Dates\ndate = \"15-10-2000\\n09\/10\/2005\\n15-05-1999\\n05\/05\/99\\n\\n05\/05\/199\\n\\n05\/05\/9\"\nre.findall(r\"\\d{1,2}[\/-]\\d{1,2}[\/-]\\d{1,4}\",date)","e1b98312":"# import natural language tool kit\nimport nltk as nlp\n\n# counting vocabulary of words\ntext = data.text[1]\nsplitted = text.split(\" \")\nprint(\"number of words: \", len(splitted))\n\n# counting unique vocabulary of words\ntext = data.text[1]\nprint(\"number of unique words: \", len(set(splitted)))\n\n# print first five unique words\nprint(\"first 5 unique words: \",list(set(splitted))[:5])\n\n# frequency of words\ndist = nlp.FreqDist(splitted)\nprint(\"frequency of words: \", dist)\n\n# look at keys in dist\nprint(\"words in text: \", dist.keys())\n\n# count how many time a particalar value occurs. Lets look at \"box\"\nprint(\"the word box is occured how many times:\",dist[\"box\"])","bd6cfa29":"# normalization\nword = \"task Tasked tasks tasking\"\nword_list = word.lower().split(\" \")\nprint(\"Normalized words: \", word_list)\n\n# stemming\nporter_stemmer = nlp.PorterStemmer()\nroots = [porter_stemmer.stem(each) for each in word_list]\nprint(\"roots of task Tasked tasks tasking: \", roots)","306dec6e":"# stemming\nstemming_word_list =  [\"Universal\",\"recognition\",\"Become\",\"being\",\"happened\"]\nporter_stemmer = nlp.PorterStemmer()\nroots = [porter_stemmer.stem(each) for each in stemming_word_list]\nprint(\"result of stemming: \",roots)\n\n\n# lemmatization\nlemma = nlp.WordNetLemmatizer()\nlemma_roots = [lemma.lemmatize(each) for each in stemming_word_list]\nprint(\"result of lemmatization: \",lemma_roots)\n      ","abaf16c0":"text_t = \"You\u2019re in the right place!\"\nprint(\"split the sentece: \", text_t.split(\" \"))  # 5 words\n\n# tokenization with nltk\nprint(\"tokenize with nltk: \",nlp.word_tokenize(text_t))","26fbdbe3":"\n\n\nBasic Text Mining Methods\n\n   * Text can be sentences, strings, words, characters and large documents\n   * Now lets create a sentence to understand basics of text mining methods.\n   * Our sentece is \"no woman no cry\" from Bob Marley.\n\n","0877d266":"# Tokenization\n\n* Splitting a sentece into words(tokes)\n* Learn tokenize with nltk","0ddc2c69":"* Natural language is any language that is used by people in everyday like English or Spanish\n* Natural language processing is that any computation and manipulation of natural language to get inside about * how words mean and how sentences are contructed is natural language processing.\n* Natural languages are in change like new words tweets\n* Natural language process tasks are counting words, finding unique words and sentence boundaries, identify   \\ * semantic rules and entities in a sentence\n* We will use natural language tool kit that is open source library in python.\n* It supports most of the NLP tasks\n","c7d392b9":"Lets look at regular expressions for date\n    We will use \"\\d{1,2}[\/-]\\d{1,2}[\/-]\\d{1,4}\" expression to find dates\n        d{1,2}: first number can be 1 or 2 digit\n        [\/-]: between digits there can be \"\/\" or \"-\" symbols\n        d{1,4}: last number can be between 1 and 4\n\n","1af97d10":"# Lemmatization","73ab351c":"# Conclusion","81372e11":"\n\n    Lets look at this @[A-Za-z0-9_]+ expression more detailed\n        @: we say that our searched word start with @\n        [A-Za-z0-9_]: @ is followed by upper or lower case letters, digits or underscore\n        +: there can be more than one @. So with \"+\" sign we say that the words which start with @ can be occured more than one times.\n\n","8517de7d":"# Natural Language Process (NLP)","92d94664":"* It is also stemming but resulting stems are all valid words","9d1b0eb3":"# Normalization and Stemming words","adabae68":"If you like this kernel, don't forget to upvote...!\nThanks in Advance.","eca060f5":"\n* Normalization is different forms of the same word like have and having\n* Stemming is finding a root of the words like having => have\n"}}