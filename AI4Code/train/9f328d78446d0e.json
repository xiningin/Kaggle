{"cell_type":{"80781965":"code","b1f455d5":"code","3218f028":"code","ff2cb0cb":"code","d2962741":"code","3ab5c62c":"code","8b9cddf0":"code","f3d530e3":"code","88c97314":"code","12bd8516":"code","aac91852":"code","8898c25a":"code","d27d1620":"code","8da02bfe":"code","199b1db5":"code","166622af":"code","fbe89253":"code","1431bc61":"code","22e397ff":"code","93063408":"code","a544e666":"code","f3633c5e":"code","1ad2cb4c":"code","563f44d6":"code","1a9bf173":"code","399c455a":"code","0c176edf":"code","a59e9220":"code","ead8bad8":"code","1392542d":"code","7b78d5a0":"code","be357fc4":"code","9ab3c612":"code","d772112f":"code","b34b215c":"code","ac992a37":"code","57687ca3":"code","236f022e":"code","4672288e":"code","433373e1":"code","fa1b3ebd":"code","f9d70d33":"code","87499952":"code","3082d1b7":"code","9c0c15a5":"code","9c83bb43":"code","f1aecf6f":"code","5b20c609":"code","735cacf0":"code","c4840811":"code","56066726":"code","5e0250e3":"code","1ee22c4d":"code","105b13db":"code","bb139bed":"code","88fdd2ae":"code","65a6b96a":"code","2dfe50a9":"code","b473f179":"code","de06602b":"code","68efdf3e":"code","06a07452":"code","e1951738":"code","c7795902":"code","a74f73d2":"code","ab13edb9":"code","a4fbaff5":"code","7d544d69":"code","fc6efcdb":"code","f4a89903":"code","9db8a12c":"code","c7271de5":"code","97aca728":"code","f15cf091":"code","5f545c7c":"code","7eca9b5f":"code","3482ad5a":"code","71665b46":"code","505bd7cd":"code","beb12f50":"code","b29d22a0":"code","4518f574":"code","595b8894":"code","c89acc0e":"code","13107209":"code","732a789a":"code","17cfa1d6":"code","76974640":"code","221bde88":"code","493d8497":"code","ff2c05d9":"code","2451d390":"code","27096018":"markdown","36101f74":"markdown","a2379137":"markdown","fc55d6df":"markdown","558a7490":"markdown","c5c1624a":"markdown","7cf752b7":"markdown","5881d11d":"markdown","bd69a63e":"markdown","5b88f0e9":"markdown","8b481891":"markdown","a61584cf":"markdown","78ec4f4b":"markdown","f63041b5":"markdown","39ba62bd":"markdown","82c49254":"markdown","35cf599b":"markdown","f0893fe7":"markdown","f5acbb53":"markdown","17c727ad":"markdown","58c80afe":"markdown","c50011b3":"markdown","b5549d5c":"markdown","c958af0f":"markdown","270c61ab":"markdown","cbf3e808":"markdown","89c90062":"markdown","53fb051a":"markdown","0b70391a":"markdown","6e1aa766":"markdown","bb3acdf2":"markdown","31d314af":"markdown","b6183c77":"markdown","0a185d88":"markdown","258549e6":"markdown","c05cbe34":"markdown","4cc68840":"markdown","3a40fdce":"markdown","234e4a4b":"markdown","60382dfc":"markdown","8ca6ca4c":"markdown"},"source":{"80781965":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b1f455d5":"## Importe as bilbiotecas##\nimport itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport numpy as np\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\nimport os\nimport seaborn as sns # visualization\nfrom scipy import stats\nfrom scipy.stats import norm \nimport warnings \nfrom sklearn.tree import DecisionTreeClassifier\nwarnings.filterwarnings('ignore') #ignore warnings\n\n%matplotlib inline\nimport gc\n\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols","3218f028":"pwd","ff2cb0cb":"tt=pd.read_csv(\"\/kaggle\/input\/walmart-recruiting-store-sales-forecasting\/train.csv.zip\", parse_dates=[\"Date\"])\ntst=pd.read_csv(\"\/kaggle\/input\/walmart-recruiting-store-sales-forecasting\/test.csv.zip\", parse_dates=[\"Date\"])\nlj=pd.read_csv(\"\/kaggle\/input\/walmart-recruiting-store-sales-forecasting\/stores.csv\")\nfat = pd.read_csv(\"\/kaggle\/input\/walmart-recruiting-store-sales-forecasting\/features.csv.zip\", parse_dates=[\"Date\"])","d2962741":"#viasualiza previamente 5 linha do arquivo 'features.csv'\ntt.head (5)","3ab5c62c":"#Converte date to object do arquivo 'features.csv'# \nfat['Date'] = pd.to_datetime(fat['Date']) #indica o titulo da coluna que quer converter \nfat.head(2)","8b9cddf0":"#viasualiza previamente 5 linha do arquivo 'test.csv'\ntst.head (5)","f3d530e3":"#Converte date to object do arquivo 'test.csv'# \ntst['Date'] = pd.to_datetime(tst['Date']) #indica o titulo da coluna que quer converter \ntst.head(2)","88c97314":"#viasualiza previamente 5 linha do arquivo 'store.csv'\nlj.head (5)","12bd8516":"#viasualiza previamente 5 linha do arquivo 'train.csv'\ntt.head (5)","aac91852":"#Converte date to object do arquivo 'train.csv'# \ntt['Date'] = pd.to_datetime(tt['Date']) #indica o titulo da coluna que quer converter \ntt.head(2)","8898c25a":" fat['IsHoliday'] . value_counts ()","d27d1620":"tt['IsHoliday'] . value_counts ()","8da02bfe":"print(\"A estrutura dos dados de treinamento \u00e9:\", tt.shape)\nprint(\"A estrutura dos dados de treinamento \u00e9:\", tst.shape)\nprint(\"A propor\u00e7\u00e3o entre os dados de treinamento e os dados de teste \u00e9:\", (round(tt.shape[0]*100\/(tt.shape[0]+tst.shape[0])),100-round(tt.shape[0]*100\/(tt.shape[0]+tst.shape[0]))))","199b1db5":"tt=tt.merge(lj, on='Store', how='left')\ntt.head()","166622af":"tt['Ano']=tt['Date'].dt.year\ntt['M\u00eas']=tt['Date'].dt.month\ntt['Semana']=tt['Date'].dt.week\ntt['Dia']=tt['Date'].dt.day\ntt['n_dias']=(tt['Date'].dt.date-tt['Date'].dt.date.min()).apply(lambda x:x.days)","fbe89253":"Ano=pd.Series(tt['Ano'].unique())\nSemana=pd.Series(tt['Semana'].unique())\nM\u00eas=pd.Series(tt['M\u00eas'].unique())\nDia=pd.Series(tt['Dia'].unique())\nn_dias=pd.Series(tt['n_dias'].unique())","1431bc61":"tst['Ano']=tst['Date'].dt.year\ntst['M\u00eas']=tst['Date'].dt.month\ntst['Semana']=tst['Date'].dt.week\ntst['Dia']=tst['Date'].dt.day\ntst['n_dias']=(tst['Date'].dt.date-tst['Date'].dt.date.min()).apply(lambda x:x.days)","22e397ff":"Ano=pd.Series(tst['Ano'].unique())\nSemana=pd.Series(tst['Semana'].unique())\nM\u00eas=pd.Series(tst['M\u00eas'].unique())\nDia=pd.Series(tst['Dia'].unique())\nn_dias=pd.Series(tst['n_dias'].unique())","93063408":"print(\"O formato do conjunto de dados 'store.csv' \u00e9: \", lj.shape)\nprint(\"Os numeros das lojas s\u00e3o: \", lj['Store'].unique())\nprint(\"Os tipos de lojas s\u00e3o:\", lj['Type'].unique())","a544e666":"fat['Ano']=fat['Date'].dt.year\nfat['M\u00eas']=fat['Date'].dt.month\nfat['Semana']=fat['Date'].dt.week\nfat['Dia']=fat['Date'].dt.day\n#tt['n_dias']=(tt['Date'].dt.date-tt['Date'].dt.date.min()).apply(lambda x:x.days)","f3633c5e":"Ano=pd.Series(fat['Ano'].unique())\nSemana=pd.Series(fat['Semana'].unique())\nM\u00eas=pd.Series(fat['M\u00eas'].unique())\nDia=pd.Series(fat['Dia'].unique())\n#n_dias=pd.Series(fat['n_dias'].unique())","1ad2cb4c":"fat.head()","563f44d6":"fat_1 = fat.loc[(fat['Ano'] > 2012)\n                |(fat['M\u00eas'] > 10) & (fat['Ano']== 2012)]\ntfat = fat.drop(fat_1.index)\ntfat.head()","1a9bf173":"tfat.shape","399c455a":"fatext = ['Store','Date', 'Temperature','Fuel_Price','CPI','Unemployment','IsHoliday']\nfat_tt = tfat.filter(items=fatext)\nfat_tt.head()","0c176edf":"fatext = ['Store','Date', 'Temperature','Fuel_Price','CPI','Unemployment','IsHoliday']\nfat_tst = fat_1.filter(items=fatext)\nfat_tst.head()","a59e9220":"fat_tt.shape","ead8bad8":"fatext = ['Store','Date', 'Temperature','Fuel_Price','CPI','Unemployment','IsHoliday']\nfat_2 = tfat.filter(items=fatext)\nfat_2.head()","1392542d":"fat_tst.shape","7b78d5a0":"tfat = tt.groupby(['Store','Date']).agg({'Weekly_Sales': np.mean})\ntfat.index_col=0\ntfat.head()","be357fc4":"tst=tst.merge(lj, on='Store', how='left')\ntst.head()\n","9ab3c612":"tstfat = tst.groupby(['Store','Date']).agg({'Size':np.mean})\ntstfat.index_col=0\ntstfat.head()","d772112f":"tstfat.shape","b34b215c":"tt_1 = tfat.reset_index(level=['Store', 'Date'])\ntst_1 = tstfat.reset_index(level=['Store', 'Date'])\ntt_1.head()","ac992a37":"tst_1.head()","57687ca3":"tt_1['Date'] = pd.to_datetime(tt_1['Date'])\ntst_1['Date'] = pd.to_datetime(tst_1['Date'])","236f022e":"New_fat=pd.merge(fat_tt, tt_1,\n                      on=['Date', 'Store'])\nNew_fat.head()","4672288e":"New_fat_tst=pd.merge(fat_tst, tst_1,\n                      on=['Date', 'Store'])","433373e1":"New_fat_tst.head()","fa1b3ebd":"print(New_fat.describe()['Weekly_Sales'].round(2))","f9d70d33":"print(lj.head())\ngrouped=lj.groupby('Type')\nprint(grouped.describe()['Size'].round(2))","87499952":"print(tt_1.head())\ngrouped=tt_1.groupby('Store')\nprint(grouped.describe()['Weekly_Sales'].round(2))","3082d1b7":"data = pd.concat([lj['Type'], lj['Size']], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\n\nplt.xlabel('Tipo')\nplt.ylabel('Tamanho da loja')\n\nfig = sns.boxplot(x='Type', y='Size', data=data)","9c0c15a5":"data = pd.concat([tt['Type'], tt['Weekly_Sales']], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nplt.xlabel('Tipo')\nplt.ylabel('Venda semanal')\nfig = sns.boxplot(x='Type', y='Weekly_Sales', data=data, showfliers=False)","9c83bb43":"plt.style.use('ggplot')\n\nfig=plt.figure()\nax=fig.add_subplot(111)\nplt.xlabel('Tamanho da loja')\nplt.ylabel('Venda semanal')\nax.scatter(tt['Size'],tt['Weekly_Sales'], alpha=0.5)\n\nplt.show()","f1aecf6f":"types=lj['Type'].unique()\n\nplt.style.use('ggplot')\n\nfig=plt.figure(figsize=(10,5))\nax=fig.add_subplot(111)\n\nfor t in types:\n    x=tt.loc[tt['Type']==t, 'Size']\n    y=tt.loc[tt['Type']==t, 'Weekly_Sales']\n    \n    ax.scatter(x,y,alpha=0.5, label=t)\n\nax.set_title('Gr\u00e1fico de dispers\u00e3o do tamanho da loja volume de venda e tipo de loja')\nax.set_xlabel('Tamanho')\nax.set_ylabel('Venda semanal')\n\nax.legend(loc='higher right',fontsize=12)\nplt.style.use('classic')\n\nplt.show()","5b20c609":"data = pd.concat([tt['Store'], tt['Weekly_Sales'], tt['Type']], axis=1)\nf, ax = plt.subplots(figsize=(20, 8))\nfig = sns.boxplot(x='Store', y='Weekly_Sales', data=data, showfliers=False, hue=\"Type\")","735cacf0":"####### alterar no dataframe Store (str) to Store (int) \n# mod= 'Weekly_Sales ~ C(Store) + C(Type)'\n# lm= ols(mod, data=data).fit()\n# aov_tab = sm.stats.anova_lm(mod, type=2)\n# print (aov_tab)","c4840811":"New_fat.head()","56066726":"##############################     Verificar (gr\u00e1fico ruim)\ndata = pd.concat([New_fat['Temperature'], New_fat['Weekly_Sales'], New_fat['IsHoliday']], axis=1)\nf, ax = plt.subplots(figsize=(30, 8))\nplt.title('Rela\u00e7\u00e3o entre Desemprego e vendas') \nfig = sns.boxplot(x='Temperature', y='Weekly_Sales', data=data, showfliers=False, hue=\"IsHoliday\")","5e0250e3":"data = pd.concat([New_fat['Fuel_Price'], New_fat['Weekly_Sales'], New_fat['IsHoliday']], axis=1)\nf, ax = plt.subplots(figsize=(25, 8))\nplt.title('Rela\u00e7\u00e3o entre Pre\u00e7o da gasolina e vendas') \nfig = sns.boxplot(x='Fuel_Price', y='Weekly_Sales', data=data, showfliers=False, hue=\"IsHoliday\")","1ee22c4d":"data = pd.concat([New_fat['Unemployment'], New_fat['Weekly_Sales'], New_fat['IsHoliday']], axis=1)\nf, ax = plt.subplots(figsize=(27, 8))\nplt.title('Rela\u00e7\u00e3o entre Desemprego e vendas') \nfig = sns.boxplot(x='Unemployment', y='Weekly_Sales', data=data, showfliers=False, hue=\"IsHoliday\")","105b13db":"def plota_bar_dupla_1():\n   grupos = 45\n   HolidayTrue = (tt['IsHoliday==True'])\n   HolidayFalse = (tt['IsHoliday==False'])\n   fig, ax = plt.subplots()\n   indice = np.arange(grupos)\n   bar_larg = 0.4\n   transp = 0.7\n   plt.bar(indice, HolidayTrue, bar_larg, alpha=transp, color=azul, label='Holiday')\n   plt.bar(indice + bar_larg, HolidayFalse, bar_larg, alpha=transp, color=verde, label='No Holiday')\n\nplt.xlabel('Weekly_Sales') \nplt.ylabel('Stores') \nplt.title('Vendas por lojas') \n#plt.xticks(indice + bar_larg) \nplt.legend() \nplt.tight_layout() \nplt.show()","bb139bed":"#Tentar colocar verdadeiro e falso para feriado ao lado e todas as lojas no eixo x\nbins = np.linspace(tt.Weekly_Sales.min(), tt.Weekly_Sales.max(), 10)\ng = sns.FacetGrid(tt, col=\"Store\", hue=\"IsHoliday\", palette=\"Set1\", col_wrap=5)\ng.map(plt.hist, 'Weekly_Sales', bins=bins, ec=\"k\")\n\nplt.title('Volume m\u00e1ximo e minimo das Vendas por lojas') \ng.axes[-1].legend()\nplt.show()","88fdd2ae":"##Correla\u00e7ao\ndef plot_corr(corr):\n    # Cortaremos a metade de cima pois \u00e9 o espelho da metade de baixo\n    mask = np.zeros_like(corr, dtype=np.bool)\n    mask[np.triu_indices_from(mask, 1)] = True\n\n    sns.heatmap(corr, mask=mask, cmap='RdBu', square=True, linewidths=.2)\n\n# Calculando a correla\u00e7\u00e3o\ncorr = tt.corr() \nplt.title('Correla\u00e7\u00e3o entre os dados') \nplot_corr(corr)","65a6b96a":"data = pd.concat([tt['Store'], tt['Weekly_Sales'], tt['IsHoliday']], axis=1)\nf, ax = plt.subplots(figsize=(30, 8))\nfig = sns.boxplot(x='Store', y='Weekly_Sales', data=data, showfliers=False, hue=\"IsHoliday\")\nplt.title('Rela\u00e7\u00e3o entre as lojas, vendas semanais e feriados') ","2dfe50a9":"data = pd.concat([tt['Dept'], tt['Weekly_Sales'], tt['Type']], axis=1)\nf, ax = plt.subplots(figsize=(25, 10))\nplt.title('Rela\u00e7\u00e3o entre as Departamento e vendas semanais') \nfig = sns.boxplot(x='Dept', y='Weekly_Sales', data=data, showfliers=False)","b473f179":"data = pd.concat([tt['Dept'], tt['Weekly_Sales'], tt['Type']], axis=1)\nf, ax = plt.subplots(figsize=(10, 50))\nfig = sns.boxplot(y='Dept', x='Weekly_Sales', data=data, showfliers=False, hue=\"Type\",orient=\"h\") ","de06602b":"data = pd.concat([tt['Dept'], tt['Weekly_Sales'], tt['IsHoliday']], axis=1)\nf, ax = plt.subplots(figsize=(25, 10))\nfig = sns.boxplot(x='Dept', y='Weekly_Sales', data=data, showfliers=False, hue=\"IsHoliday\")","68efdf3e":"plt.style.use('ggplot')\nfig, axes = plt.subplots(1,2, figsize = (20,5))\nfig.subplots_adjust(wspace=1, hspace=1)\nfig.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9)\n\nsales_holiday=tt[['IsHoliday','Weekly_Sales']]\ntarget=[sales_holiday['Weekly_Sales'].loc[sales_holiday['IsHoliday']==True],sales_holiday['Weekly_Sales'].loc[sales_holiday['IsHoliday']==False]]\nlabels=['Holiday','Not Holiday']\n\n#median\nmedianprop={'color':'#2196F3',\n            'linewidth': 2,\n            'linestyle':'-'}\n\n# outliers\n\nflierprop={'color' : '#EC407A',\n          'marker' : 'o',\n          'markerfacecolor': '#2196F3',\n          'markeredgecolor':'white',\n          'markersize' : 3,\n          'linestyle' : 'None',\n          'linewidth' : 0.1}\n\n\n\naxes[0].boxplot(target,labels=labels, patch_artist = 'Patch',\n                  showmeans=True,\n                  flierprops=flierprop,\n                  medianprops=medianprop)\n\nplt.title('Volume de vendas') \n\n\naxes[1].boxplot(target,labels=labels, patch_artist = 'Patch',\n                  showmeans=True,\n                  flierprops=flierprop,\n                  medianprops=medianprop)\n\naxes[1].set_ylim(-6000,80000)\n\nplt.show()","06a07452":"print(tt[tt['IsHoliday']==True]['Weekly_Sales'].describe().round(1))\nprint(tt[tt['IsHoliday']==False]['Weekly_Sales'].describe().round(1))","e1951738":"data = pd.concat([tt['M\u00eas'], tt['Weekly_Sales']], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x='M\u00eas', y=\"Weekly_Sales\", data=data, showfliers=False)\nplt.title('Rela\u00e7\u00e3o vendas semanais por mes') ","c7795902":"data = pd.concat([tt['M\u00eas'], tt['Weekly_Sales'],tt['IsHoliday']], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x='M\u00eas', y=\"Weekly_Sales\", data=data, showfliers=False, hue='IsHoliday')\nplt.title('Rela\u00e7\u00e3o entre vendas semanais, meses e feriados') ","a74f73d2":"data = pd.concat([tt['M\u00eas'], tt['Weekly_Sales'],tt['Type']], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x='M\u00eas', y=\"Weekly_Sales\", data=data, showfliers=False, hue='Type')\nplt.title('Rela\u00e7\u00e3o entre vendas semanais, meses e tipos de lojas')","ab13edb9":"data = pd.concat([tt['Ano'], tt['Weekly_Sales']], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x='Ano', y=\"Weekly_Sales\", data=data, showfliers=False)\nplt.title('Rela\u00e7\u00e3o entre vendas semanais e Anos')","a4fbaff5":"data = pd.concat([tt['Semana'], tt['Weekly_Sales']], axis=1)\nf, ax = plt.subplots(figsize=(20, 6))\nfig = sns.boxplot(x='Semana', y=\"Weekly_Sales\", data=data, showfliers=False)\nplt.title('Rela\u00e7\u00e3o entre vendas semanais, Semanas')","7d544d69":"f, ax = plt.subplots(figsize=(8, 6))\nsns.distplot(tt['Weekly_Sales'])\nplt.title('Distribui\u00e7\u00e3o de vendas semanais')","fc6efcdb":"f, ax = plt.subplots(figsize=(8, 6))\ngrouped=tt.groupby(['Dept','Weekly_Sales','IsHoliday']).mean().round(0).reset_index()\nsns.distplot(grouped)\nplt.title('Distribui\u00e7\u00e3o de vendas semanais por departamentto no feriado')","f4a89903":"print(\"Skewness: \", tt['Weekly_Sales'].skew()) #skewness\nprint(\"Kurtosis: \", tt['Weekly_Sales'].kurt()) #kurtosis\ntt['Weekly_Sales'].min()","9db8a12c":"fig.add_subplot(1,2,1)\nres = stats.probplot(tt.loc[tt['Weekly_Sales']>0,'Weekly_Sales'], plot=plt)\n\nfig.add_subplot(1,2,2)\nres = stats.probplot(np.log1p(tt.loc[tt['Weekly_Sales']>0,'Weekly_Sales']), plot=plt)","c7271de5":"tt.describe()['Weekly_Sales']","97aca728":"tt_over_zero=tt[tt['Weekly_Sales']>0]\ntt_below_zero=tt[tt['Weekly_Sales']<=0]\nsales_over_zero = np.log1p(tt_over_zero['Weekly_Sales'])\n#histogram\nf, ax = plt.subplots(figsize=(8, 6))\nsns.distplot(sales_over_zero)","f15cf091":"print(\"Skewness: \", sales_over_zero.skew()) #skewness\nprint(\"Kurtosis: \", sales_over_zero.kurt()) #kurtosis","5f545c7c":"grouped=tt.groupby(['Dept','Date']).mean().round(0).reset_index()\nprint(grouped.shape)\nprint(grouped.head())\ndata=grouped[['Dept','Date','Weekly_Sales']]\n\n\ndept=tt['Dept'].unique()\ndept.sort()\ndept_1=dept[0:20]\ndept_2=dept[20:40]\ndept_3=dept[40:60]\ndept_4=dept[60:]\n\nfig, ax = plt.subplots(2,2,figsize=(20,10))\nfig.subplots_adjust(wspace=0.5, hspace=0.5)\nfig.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9)\n\nfor i in dept_1 :\n    data_1=data[data['Dept']==i]\n    ax[0,0].plot(data_1['Date'], data_1['Weekly_Sales'],label='Dept_1_mean_sales')\n\nfor i in dept_2 :\n    data_1=data[data['Dept']==i]\n    ax[0,1].plot(data_1['Date'], data_1['Weekly_Sales'],label='Dept_1_mean_sales')\n    \nfor i in dept_3 :\n    data_1=data[data['Dept']==i]\n    ax[1,0].plot(data_1['Date'], data_1['Weekly_Sales'],label='Dept_1_mean_sales')    \n\nfor i in dept_4 :\n    data_1=data[data['Dept']==i]\n    ax[1,1].plot(data_1['Date'], data_1['Weekly_Sales'],label='Dept_1_mean_sales')        \n    \nax[0,0].set_title('Mean sales record by department(0~19)')\nax[0,1].set_title('Mean sales record by department(20~39)')\nax[1,0].set_title('Mean sales record by department(40~59)')\nax[1,1].set_title('Mean sales record by department(60~)')\n\n\nax[0,0].set_ylabel('Mean sales')\nax[0,0].set_xlabel('Date')\nax[0,1].set_ylabel('Mean sales')\nax[0,1].set_xlabel('Date')\nax[1,0].set_ylabel('Mean sales')\nax[1,0].set_xlabel('Date')\nax[1,1].set_ylabel('Mean sales')\nax[1,1].set_xlabel('Date')\n\n\nplt.show()","7eca9b5f":"grouped=tt.groupby(['Store','Date']).mean().round(0).reset_index()\ngrouped.shape\ngrouped.head()\n\ndata=grouped[['Store','Date','Weekly_Sales']]\ntype(data)\n\n\nstore=tt['Store'].unique()\nstore.sort()\nstore_1=store[0:5]\nstore_2=store[5:10]\nstore_3=store[10:15]\nstore_4=store[15:20]\nstore_5=store[20:25]\nstore_6=store[25:30]\nstore_7=store[30:35]\nstore_8=store[35:40]\nstore_9=store[40:]\n\nfig, ax = plt.subplots(5,2,figsize=(20,15))\n\nfig.subplots_adjust(wspace=0.5, hspace=0.5)\nfig.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9)\n\nfor i in store_1 :\n    data_1=data[data['Store']==i]\n    ax[0,0].plot(data_1['Date'], data_1['Weekly_Sales'])\n    \nfor i in store_2 :\n    data_2=data[data['Store']==i]\n    ax[0,1].plot(data_2['Date'], data_2['Weekly_Sales'])\n    \nfor i in store_3 :\n    data_3=data[data['Store']==i]\n    ax[1,0].plot(data_3['Date'], data_3['Weekly_Sales'])\n\nfor i in store_4 :\n    data_4=data[data['Store']==i]\n    ax[1,1].plot(data_4['Date'], data_4['Weekly_Sales'])\n    \nfor i in store_5 :\n    data_5=data[data['Store']==i]\n    ax[2,0].plot(data_5['Date'], data_5['Weekly_Sales'])  \n\nfor i in store_6 :\n    data_6=data[data['Store']==i]\n    ax[2,1].plot(data_6['Date'], data_6['Weekly_Sales'])  \n\nfor i in store_7 :\n    data_7=data[data['Store']==i]\n    ax[3,0].plot(data_7['Date'], data_7['Weekly_Sales'])      \n\nfor i in store_8 :\n    data_8=data[data['Store']==i]\n    ax[3,1].plot(data_8['Date'], data_8['Weekly_Sales'])     \n    \nfor i in store_9 :\n    data_9=data[data['Store']==i]\n    ax[4,0].plot(data_9['Date'], data_9['Weekly_Sales'])     \n\n    \nax[0,0].set_title('Mean sales record by store(0~4)')\nax[0,1].set_title('Mean sales record by store(5~9)')\nax[1,0].set_title('Mean sales record by store(10~14)')\nax[1,1].set_title('Mean sales record by store(15~19)')\nax[2,0].set_title('Mean sales record by store(20~24)')\nax[2,1].set_title('Mean sales record by store(25~29)')\nax[3,0].set_title('Mean sales record by store(30~34)')\nax[3,1].set_title('Mean sales record by store(35~39)')\nax[4,0].set_title('Mean sales record by store(40~)')\n\n\n\nax[0,0].set_ylabel('Mean sales')\nax[0,0].set_xlabel('Date')\nax[0,1].set_ylabel('Mean sales')\nax[0,1].set_xlabel('Date')\nax[1,0].set_ylabel('Mean sales')\nax[1,0].set_xlabel('Date')\nax[1,1].set_ylabel('Mean sales')\nax[1,1].set_xlabel('Date')\nax[2,0].set_ylabel('Mean sales')\nax[2,0].set_xlabel('Date')\nax[2,1].set_ylabel('Mean sales')\nax[2,1].set_xlabel('Date')\nax[3,0].set_ylabel('Mean sales')\nax[3,0].set_xlabel('Date')\nax[3,1].set_ylabel('Mean sales')\nax[3,1].set_xlabel('Date')\nax[4,0].set_ylabel('Mean sales')\nax[4,0].set_xlabel('Date')\n\n\n\nplt.show()","3482ad5a":"grouped=tt.groupby(['Store','Dept'])['Weekly_Sales'].max().reset_index()\ngrouped['Store']=grouped['Store'].astype(str)\ngrouped['Dept']=grouped['Dept'].astype(str)\ngrouped['Weekly_Sales']=grouped['Weekly_Sales'].astype(str)\ngrouped['key']=grouped['Weekly_Sales'] +'_'+ grouped['Store'] +'_'+ grouped['Dept']\n\n\ntt['Store']=tt['Store'].astype(str)\ntt['Dept']=tt['Dept'].astype(str)\ntt['Weekly_Sales_2']=tt['Weekly_Sales'].astype(str)\ntt['key']=tt['Weekly_Sales'].astype(str) +'_'+ tt['Store'].astype(str) +'_'+ tt['Dept'].astype(str)\n\ntrain_2=pd.merge(tt, grouped['key'], how='inner', on='key' )\ntrain_2['Date_2']=train_2['M\u00eas'].astype(str) + '-' + train_2['Dia'].astype(str)\n\ngrouped_2=train_2.groupby(['Date_2','Store','Dept']).count().reset_index()\ngrouped_2.sort_values('Weekly_Sales',ascending=False,inplace=True)","71665b46":"grouped_2['key_2']=grouped_2['Date_2'].astype(str) + grouped_2['Store'].astype(str) + grouped_2['Dept'].astype(str)\ngrouped_2['Count']=grouped_2['Weekly_Sales']\ndata=grouped_2[['key_2','Count']]\n\ntt['Date_2']=tt['M\u00eas'].astype(str) + '-' + tt['Dia'].astype(str)\ntt['key_2']=tt['Date_2'].astype(str) + tt['Store'].astype(str) + tt['Dept'].astype(str)\ntrain=pd.merge(tt, data, how='left', on='key_2' )\ntrain.loc[train['Count'].isnull(),'Count']=0\n\n#grouped_2['proportion']=grouped_2['Weekly_Sales']\/sum(grouped_2['Store'])\n#grouped_2['Count']=grouped_2['Weekly_Sales']\n#data=grouped_2[['Date_2','Count']]\n#print(data.head(100))\n\n#train['Date_2']=train['Month'].astype(str) + '-' + train['Day'].astype(str)\n\n#train=pd.merge(train, data, how='left', on='Date_2' )\n#train.head(150)","505bd7cd":"grouped.head()","beb12f50":"train_2.head()","b29d22a0":"grouped_2.head()","4518f574":"train_2.head()","595b8894":"data = pd.concat([train['Count'], train['Weekly_Sales'], train['Store']], axis=1)\nf, ax = plt.subplots(figsize=(5, 5))\nfig=sns.boxplot(x='Count', y=\"Weekly_Sales\", data=data, showfliers=False)","c89acc0e":"from sklearn import svm \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectPercentile, chi2\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC","13107209":"tt.data = tt[['Store','Dept','Weekly_Sales','Size','Ano','M\u00eas','Semana','Dia','n_dias']]\ntt.targed = tt[['IsHoliday']]\ntst.data = tst[['Store', 'Dept', 'Type','Size','Ano','M\u00eas','Semana','Dia','n_dias']]\ntst.targed = tst[['IsHoliday']]\n#Convertendo features (objct-str) para float\ntt.data['Store']= tt.data['Store'].apply(lambda x:(float(str(x))))\ntt.data['Dept']= tt.data['Dept'].apply(lambda x:(float(str(x))))\ntt.targed = np.where(tt.targed['IsHoliday']==False, 0, 1)\nX_train = tt.data.as_matrix()\nY_train = tt.targed ## Verificar se \u00e9 necess\u00e1rio transformar tudo em matriz\nX_test = tst.data\nY_test = tst.targed","732a789a":"sns.pairplot(tt[['Store','Dept','IsHoliday','Weekly_Sales']], hue='IsHoliday')","17cfa1d6":"model = svm.SVC(kernel='poly')\nmodel.fit(X_train, Y_train)","76974640":"print(X_train)","221bde88":"from matplotlib import style\nstyle.use(\"seaborn-colorblind\")\ntt.data.plot(x='Dept', y='Weekly_Sales', c=tt.targed, kind='scatter',colormap='Accent_r')","493d8497":"type(X_train)","ff2c05d9":"## predict case\nsns.lmplot('X_test', 'Y_test', data=X_train, hue='Types', palette='Set1' )","2451d390":"def acuracia(model,X_train,Y_train):\n    resultados = cross_val_predict(model,X_train,Y_train, cv=5)\n    return metrics.accuracy_score(Y_Train,resultados)\nacuracia","27096018":"A loja pode ser uma das vari\u00e1veis que fornece informa\u00e7\u00f5es sobre vendas. Porem as lojas fornecem muitas informa\u00e7\u00f5es intrisecas, como tipo, tamanho e departamento. \nObservamos tambem que as vari\u00e1veis Pre\u00e7o do combustivel (Fuel_Price) e desemprego (Unemployment) fornecem informa\u00e7\u00f5es sobre o volume de venda. \nJa os dados referentes a temperatura n\u00e3o podemos observar que fornece informa\u00e7\u00f5es sobre o volume de venda semanal ","36101f74":"## Este reposit\u00f3rio trata-se de uma an\u00e1lise do volume de vendas de uma rede de supermercados na semanas que precedem alguns feriados nacionais ##\n\nOs dados para analise correspondem a dados hist\u00f3ricos de vendas de 45 lojas Walmart localizadas em diferentes regi\u00f5es. Cada loja cont\u00e9m v\u00e1rios departamentos\n\nO desafio consiste em prever as vendas em todo o departamento para cada loja por meio de uma modelagem que consiga identificar os efeitos de remarca\u00e7\u00f5es nessas semanas de f\u00e9rias na aus\u00eancia de dados hist\u00f3ricos completos \/ ideais.","a2379137":"Converte Data em objeto","fc55d6df":"Subdividimos a coluna Date em ano\/m\u00eas\/semana\/dia","558a7490":"Vendas em feriados s\u00e3o um pouco mais do que vendas em n\u00e3o feriados","c5c1624a":"<div id=\"pre-processessamento\"> \n    <h2>Pre-Processessamento<\/h2>","7cf752b7":"Como conclus\u00e3o podemos aplicar uma maquina de vetores por meio do m\u00e9todo polinomial, para prever o volume de vendas do departamento 72 em feriados.  ","5881d11d":"Apos as altera\u00e7\u00f5es necess\u00e1rias, as bases de dados sobre:\n    \n    - Influ\u00eancias externas treinamento recebe o nome de  ( fat_tt );\n    - Base de dados de treinamento o nome de  ( tt_1 );\nQue, ap\u00f3s serem acopladas recebe o nome nome  ( New_fat ) ","bd69a63e":"Trabalharemos com 'train.csv', 'test.csv', 'store.csv' e para an\u00e1lises externas usaremos 'features.csv' ","5b88f0e9":"<div id=\"Carregando_Conhecendo o dataset\"> \n    <h2>Carregando e conhecendo o dataset<\/h2>\n    \nOs arquivos podem ser encontrados em https:\/\/www.kaggle.com\/c\/walmart-recruiting-store-sales-forecasting\/data\ne correspondem: \n\n#stores.csv#\nEste arquivo cont\u00e9m informa\u00e7\u00f5es an\u00f4nimas sobre as 45 lojas, indicando o tipo e tamanho da loja.\n\n#train.csv#\nEsses s\u00e3o os dados hist\u00f3ricos do treinamento, que abrangem desde 05-02-2010 a 01\/11\/2012. Dentro deste arquivo, voc\u00ea encontrar\u00e1 os seguintes campos:\n\nLoja - o n\u00famero da loja\nDepartamento - o n\u00famero do departamento\nData - a semana\nWeekly_Sales - vendas para o departamento especificado na loja especificada\nIsHoliday - se a semana \u00e9 uma semana especial de f\u00e9rias\n\n#test.csv#\nEste arquivo \u00e9 id\u00eantico ao train.csv, exceto que retivemos as vendas semanais. Voc\u00ea deve prever as vendas para cada trig\u00eameo de loja, departamento e data neste arquivo.\n\n#features.csv#\nEste arquivo cont\u00e9m dados adicionais relacionados \u00e0 loja, departamento e atividade regional para as datas especificadas. Ele cont\u00e9m os seguintes campos:\n\nLoja - o n\u00famero da loja\nData - a semana\nTemperatura - temperatura m\u00e9dia na regi\u00e3o\nFuel_Price - custo do combust\u00edvel na regi\u00e3o\nMarkDown1-5 - dados anonimizados relacionados a descontos promocionais que o Walmart est\u00e1 executando. Os dados do MarkDown est\u00e3o dispon\u00edveis somente ap\u00f3s novembro de 2011 e n\u00e3o est\u00e3o dispon\u00edveis para todas as lojas o tempo todo. Qualquer valor ausente \u00e9 marcado com um NA.\nCPI - o \u00edndice de pre\u00e7os ao consumidor\nDesemprego - a taxa de desemprego\nIsHoliday - se a semana \u00e9 uma semana especial de f\u00e9rias\nPor conveni\u00eancia, os quatro feriados se enquadram nas semanas seguintes no conjunto de dados (nem todos os feriados est\u00e3o nos dados):\n\nSuper Bowl: 12-fev-10, 11-fev-11, 10-fev-12, 8-fev-13\nDia do Trabalhador: 10-set-10, 9-set-11, 7-set-12, 6-set -13\nA\u00e7\u00e3o de Gra\u00e7as: 26-Nov-10, 25-Nov-11, 23-Nov-12, 29-Nov-13\nNatal: 31-Dez-10, 30-Dez-11, 28-Dez-12, 27-Dez -13","8b481891":"#### Uma breve an\u00e1lise por tipo de loja ####","a61584cf":"A base de dados faetures esta composta com treinamento e teste.\n\nPortanto para realizar uma an\u00e1lise comparativa entre os dados de treinamento (tt) e as influ\u00eancias externas (fat). \u00c9 necess\u00e1rio eliminar do conjunto (fat) as linhas posteriores a 10\/2012\n\nCriamos um var\u00e1vel que receber\u00e1 as linhas que queremos eliminar de (fat)","78ec4f4b":"A correla\u00e7\u00e3o entre os dados nao nos apresenta respostas relevantes. Pode-se observar uma pequena relev\u00e2ncia entre a o volume de vendas da loja e seu tamanho. Porem n\u00e3o ha indica\u00e7\u00f5es relevantes.","f63041b5":"Cada departamento mostra os diferentes n\u00edveis de vendas, podemos inferir que h\u00e1 diferen\u00e7a nas vendas \nDepartamento pode ser a vari\u00e1vel poderosa para prever vendas\nQuando departamento e tipo de loja s\u00e3o considerados juntos, geralmente o departamento do tipo A mostra o maior recorde de vendas\nSuposi\u00e7\u00e3o 4: Tipo e departamento podem ter o efeito de intera\u00e7\u00e3o","39ba62bd":"No arquivo 'features.csv'\n\ntemos 7605 datas e eventos globais que n\u00e3o correspondem a feriados \n\ne 585 eventos globais que correspondem a feriados","82c49254":"Podemos observar que o volume m\u00e1ximo de vendas ocorre em n\u00e3o feriados ","35cf599b":"Feriados e lojas n\u00e3o mostram rela\u00e7\u00f5es significativas.","f0893fe7":"No arquivo 'train.csv'\n\ntemos 391909 datas e faturamentos n\u00e3o corresponder a feriados \ne 29661 datas e eventos correspondem a feriados","f5acbb53":"Count 0 indica a associa\u00e7\u00e3o do dia com venda de maxima, departamento com venda m\u00e1xima e loja com niveis m\u00e1ximos de vendas, em n\u00e3o feirados \n\nJa count 1 indica  a associa\u00e7\u00e3o do dia com venda de maxima, departamento com venda m\u00e1xima e loja com niveis m\u00e1ximos de vendas volume de vendas em feriados.\n\nDeste modo podemos obseervar volume m\u00e1x de vendas este acumudado em feriados para dias especificos e departamentos especificos em lojas especificas.\n\nEsse volume aparenta estar associado ao periodo Natalino. \n                 \n                 \n ","17c727ad":"######################## Explicar melhor esse gggrafico #################################","58c80afe":"Preparando dados ","c50011b3":"Importe as bibliotecas necess\u00e1rias para a analise","b5549d5c":"Apos as altera\u00e7\u00f5es necess\u00e1rias, as bases de dados sobre:\n    \n    - Influ\u00eancias externas recebe o nome de  ( fat_tst );\n    - Base de dados de treinamento o nome de  ( tst_1 );\nQue, ap\u00f3s serem acopladas recebe o nome nome  ( New_fat_tst ) ","c958af0f":"Novamente o departamento 72 apresenta relev\u00e2ncia no volume de vendas nos feriados.","270c61ab":"O gr\u00e1fico confirma o maior volume de vendas ente as lojas do tipo A","cbf3e808":"<div id=\"Visualiza\u00e7\u00e3o previa\"> \n    <h2>Visualiza\u00e7\u00e3o pr\u00e9via e An\u00e1lise da rela\u00e7\u00e3o entre vari\u00e1veis<\/h2>","89c90062":"Embora o resultado n\u00e3o aperente um destin\u00e7ao clara entre o Tipo de loja, tamanho e volume de vendas semanais.\n<br>\n\u00c9 possivel observar um aumento no volume de vendas nas lojas do tipo A e B \n<br>\n<br>\nO gr\u00e1fico a seguir podemos observar o volume de venda de cada loja, bem como o tipo (A,B e C) de cada loja ","53fb051a":"Pelo gr\u00e1fico de linhas, podemos ver os seguintes\n\nO n\u00edvel de vendas \u00e9 diferente por departamento e o n\u00edvel de registro de vendas de um departamento \u00e9 est\u00e1vel\nH\u00e1 alguns pontos altos em janeiro e maio. Portanto, pode haver um evento para altas vendas\nAlguns departamentos est\u00e3o altamente relacionados com esses eventos. Assim, o recorde de vendas sobe acentuadamente em torno de janeiro ou maio\n","0b70391a":"SVM Para Classifica\u00e7\u00e3o vendas por feirado\nindicando se \u00e9 feriado ou n\u00e3o pelo volume de vendas das lojas Se \u00e9 feriado ou n\u00e3o pelo volume vendas por departamento","6e1aa766":"An\u00e1lise visual por tipos de lojas e o tamanho das lojas","bb3acdf2":"#### Uma breve an\u00e1lise dos efeitos externos nas vendas","31d314af":"#### Verificar influ\u00eancia de fatores externos ao volume de vendas das lojas\n\ninicialmente faremos um pr\u00e9-processamento dos dados","b6183c77":"Observamos maior volume de venda nas lojas 2, 38, 40, 72, 90 - 95. ","0a185d88":"Ap\u00f3s realizar o agrupamento entre a janla de datas o departemaneto e a loja (incluindo o tipo)\nIremos plotar a contagem destes elementos associacodos a as vendas semanais. ","258549e6":"Vamos ver quantas de cada classe h\u00e1 em nosso conjunto de dados","c05cbe34":"<h1> \u00cdndice Anal\u00edtico <\/h1>\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <ol>\n        <li><a href=\"#Carregando_Conhecendo o dataset\">Carregando e conhecendo o dataset<\/a><\/li>\n        <li><a href=\"#pre-processessamento\">pre-processessamento<\/a><\/li>\n        <li><a href=\"#Visualiza\u00e7\u00e3o previa\">Visualiza\u00e7\u00e3o pr\u00e9via<\/a><\/li>\n        <li><a href=\"#Inferencias previas\">Infer\u00eancias pr\u00e9vias<\/a><\/li>\n        <li><a href=\"#setting_up_tree\">Configurando a \u00c1rvore de Decis\u00e3o<\/a><\/li>\n        <li><a href=\"#modeling\">Modelagem<\/a><\/li>\n        <li><a href=\"#prediction\">Predi\u00e7\u00e3o<\/a><\/li>\n        <li><a href=\"#evaluation\">Avalia\u00e7\u00e3o<\/a><\/li>\n        <li><a href=\"#visualization\">Visualiza\u00e7\u00e3o Final<\/a><\/li>\n    <\/ol>\n<\/div>\n<br>\n<hr>","4cc68840":"Lendo os dados usando o pandas dataframe:","3a40fdce":"Suposi\u00e7\u00e3o: o maior dia de vendas (por exemplo, Natal) fornecer\u00e1 alto poder de previs\u00e3o\nSuposi\u00e7\u00e3o: o dia mais alto de vendas ser\u00e1 diferente por departamento e loja (por exemplo, alguns departamentos n\u00e3o s\u00e3o sens\u00edveis ao Natal)\nAssim, extraia o dia mais alto e combine esse dia com o conjunto de dados de treinamento","234e4a4b":"# Machine Learning #","60382dfc":"Diferente da rela\u00e7\u00e3o de loja e feriado, departamento e feriado n\u00e3o explicam nenhuma rela\u00e7\u00e3o. \n O departamento 72 mostra o maior aumento nas vendas durante os feriados \nNo entanto, outros n\u00e3o, e ainda mais em alguns departamentos, as vendas fora dos feriados s\u00e3o maiores.\nIsso significa que o car\u00e1ter do produto (departamento) \u00e9 diferente da rela\u00e7\u00e3o com as vendas\n","8ca6ca4c":"As lojas do tipo A s\u00e3o maiores e as do tipo C s\u00e3o menores.\nPodemos observar que a mediana do volume semanal de venda das lojas tipo A \u00e9 a mais alta e do tipo C \u00e9 a mais baixa.\nIsso significa que lojas maiores t\u00eam maior volume de vendas."}}