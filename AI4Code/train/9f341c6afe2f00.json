{"cell_type":{"4ae32761":"code","a9dfaef0":"code","3824d102":"code","99f683c4":"code","b58e3f03":"code","2c867aeb":"code","1b95e9ae":"code","2dbbcea2":"code","588cf7f7":"code","dbdf74a2":"code","7e2fbdd5":"code","30f2f638":"code","8672e867":"code","ec729cb4":"code","8ed9faaa":"code","86996829":"code","46cc12c8":"code","f4887d89":"code","45e2884c":"code","a4b0e9fb":"code","97922ef5":"code","eaf49c00":"code","8b4c1d04":"code","de7ec303":"code","85f4a56f":"code","1e8c8561":"code","dbd31fd5":"code","1b9e1623":"code","c4a85e7c":"code","76a10f5d":"code","8215b060":"code","bb78910f":"code","9e9a68a0":"code","27c51bd6":"code","55d54a60":"code","c7ca4900":"code","da7057df":"code","5b26691f":"code","07af57da":"code","f78af349":"code","9702c9b0":"code","960038a2":"code","67d537c4":"code","8f06e5ef":"code","ec39f060":"code","d673716d":"code","1f976c89":"code","b8871e13":"code","24fab3c1":"code","583dcf3a":"code","880442ef":"code","04f5452d":"markdown","412d003f":"markdown","e4133581":"markdown","c64be7b6":"markdown","d75a7131":"markdown","943951e7":"markdown","8f0a6570":"markdown","678661ee":"markdown","88cb5313":"markdown","311184fd":"markdown"},"source":{"4ae32761":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a9dfaef0":"DATA_PATH='..\/input\/'","3824d102":"df_train = pd.read_csv(DATA_PATH + 'training_set.csv')\ndf_train_meta = pd.read_csv(DATA_PATH + 'training_set_metadata.csv')","99f683c4":"df_train.head()","b58e3f03":"df_train.describe()","2c867aeb":"df_train.info()","1b95e9ae":"df_train_meta.head()","2dbbcea2":"df_train_meta.describe()","588cf7f7":"df_train_meta.info()","dbdf74a2":"f, ax = plt.subplots(figsize=(12, 6))\nsns.distplot(df_train['flux'], ax=ax)\nplt.show()","7e2fbdd5":"df_train.flux.describe()","30f2f638":"f, ax = plt.subplots(figsize=(12, 6))\nsns.distplot(df_train['flux_err'], ax=ax)\nplt.show()","8672e867":"df_train.flux_err.describe()","ec729cb4":"df_train[(df_train.flux> 1000) | (df_train.flux < -1000)].describe()","8ed9faaa":"sns.distplot(df_train[(df_train.flux < 1000) & (df_train.flux > -1000)].flux)","86996829":"sns.countplot(df_train[(df_train.flux < 1000) & (df_train.flux > -1000)].detected)","46cc12c8":"sns.countplot(df_train[(df_train.flux> 250) | (df_train.flux < -250)].detected)","f4887d89":"sns.distplot(df_train[(df_train.flux < 100) & (df_train.flux > -100)].flux)","45e2884c":"sns.countplot(df_train[(df_train.flux_err >= 100) | (df_train.flux_err <= 100)].detected)","a4b0e9fb":"sns.countplot(df_train[(df_train.flux_err > 100) | (df_train.flux_err < -100)].detected)","97922ef5":"sns.heatmap(df_train[['flux', 'flux_err']].corr(), annot=True)","eaf49c00":"passbands = [0, 1,2,3,4,5]\nfig, ax = plt.subplots(nrows=2, ncols=3, figsize=(18,10))\ni = 0\nfor row in ax:\n    for col in row:\n        sns.distplot(df_train[(df_train.passband == passbands[i]) & (df_train.flux < 250) & (df_train.flux > -250)]['flux'], ax=col, axlabel='flux distribution of passband ' + str(i))\n        i += 1\nplt.show()\n        ","8b4c1d04":"sns.countplot(x='detected', data=df_train, hue='passband')\nplt.show()","de7ec303":"df_train.groupby(['passband']).count()","85f4a56f":"ts_lens = df_train.groupby(['object_id', 'passband']).size()\nf, ax = plt.subplots(figsize=(12, 6))\nsns.distplot(ts_lens, ax=ax)\nax.set_title('distribution of time series lengths')\nplt.show()","1e8c8561":"passbands = [0, 1,2,3,4,5]\nfig, ax = plt.subplots(nrows=2, ncols=3, figsize=(18,10))\ni = 0\nfor row in ax:\n    for col in row:\n        sns.distplot(df_train[df_train.passband == i].groupby(['object_id']).size(), ax=col, axlabel='timeseries distribution of passband ' + str(i))\n        i += 1\nplt.show()","dbd31fd5":"f, ax = plt.subplots(figsize=(12, 6))\nsns.distplot(df_train['mjd'], ax=ax, bins=200)\nax.set_title('number of observations made at each time point')\nplt.show()","1b9e1623":"f, ax = plt.subplots(figsize=(12, 6))\nsns.distplot(df_train[df_train['object_id'] == 713]['mjd'], ax=ax, bins=200)\nax.set_title('number of observations made at each time point')\nplt.show()","c4a85e7c":"passbands = [0, 1,2,3,4,5]\nfig, ax = plt.subplots(nrows=2, ncols=3, figsize=(22,10))\ni = 0\nfor row in ax:\n    for col in row:\n        sns.distplot(df_train[(df_train['object_id'] == 713) & (df_train['passband'] == 3)]['mjd'], ax=col, bins=200)\n        col.set_title('number of observations made at each time point by passband ' +  str(i))\n        i += 1\nplt.show()","76a10f5d":"\nf, ax = plt.subplots(figsize=(12, 9))\nax.scatter(x='mjd', y='flux', data=df_train.groupby(['mjd']).mean().reset_index())\nax.scatter(x='mjd', y='flux_err', data=df_train.groupby(['mjd']).mean().reset_index())\nax.legend(['flux', 'flux error'])\nplt.show()","8215b060":"f, ax = plt.subplots(figsize=(12, 9))\nax.scatter(x='mjd', y='flux', data=df_train[df_train.object_id==713].groupby(['mjd']).mean().reset_index())\nax.scatter(x='mjd', y='flux_err', data=df_train[df_train.object_id==713].groupby(['mjd']).mean().reset_index())\nax.legend(['flux', 'flux error'])\nplt.show()","bb78910f":"f, ax = plt.subplots(figsize=(12, 9))\nax.scatter(x='mjd', y='flux', data=df_train[df_train.object_id==615].groupby(['mjd']).mean().reset_index())\nax.scatter(x='mjd', y='flux_err', data=df_train[df_train.object_id==615].groupby(['mjd']).mean().reset_index())\nax.legend(['flux', 'flux error'])\nplt.show()","9e9a68a0":"objects = df_train.object_id.unique()\nrandom_id = np.random.randint(0, len(objects), 12)\nfig, ax = plt.subplots(nrows=4, ncols=3, figsize=(18,10))\ni = 0\nfor row in ax:\n    for col in row:\n        col.scatter(x='mjd', y='flux', data=df_train[df_train.object_id==objects[random_id[i]]].groupby(['mjd']).mean().reset_index())\n        col.scatter(x='mjd', y='flux_err', data=df_train[df_train.object_id==objects[random_id[i]]].groupby(['mjd']).mean().reset_index())\n        col.legend(['flux', 'flux error'])\n        i += 1\nplt.show()","27c51bd6":"sns.heatmap(df_train[['mjd', 'detected']].corr(), annot=True)\nplt.show()","55d54a60":"f, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(df_train_meta[['ra', 'decl', 'gal_l', 'gal_b']].corr(), annot=True, ax=ax)\nplt.show()","c7ca4900":"f, ax = plt.subplots(figsize=(21, 9))\nax.scatter(df_train_meta.object_id, df_train_meta.hostgal_specz)\nax.scatter(df_train_meta.object_id, df_train_meta.hostgal_photoz)\nax.legend(['specz redshift', 'photoz redshift'])\nplt.show()","da7057df":"f, ax = plt.subplots(figsize=(21, 9))\nax.scatter(df_train_meta.object_id, df_train_meta.hostgal_photoz_err)\nax.scatter(df_train_meta.object_id, df_train_meta.hostgal_photoz)\nax.legend(['photoz redshift error', 'photoz redshift'])\nplt.show()","5b26691f":"f, ax = plt.subplots(figsize=(12, 9))\nsns.distplot(df_train_meta.hostgal_photoz)\nsns.distplot(df_train_meta.hostgal_specz)\nax.legend(['photoz redshift', 'specz redshift'])\nplt.show()","07af57da":"f, ax = plt.subplots(figsize=(21, 9))\nsns.distplot(df_train_meta.hostgal_photoz)\nsns.distplot(df_train_meta.hostgal_photoz_err)\nax.legend(['photoz redshift',  'photoz redshift error'])\nplt.show()","f78af349":"f, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(df_train_meta[['hostgal_specz', 'hostgal_photoz', 'hostgal_photoz_err']].corr(), annot=True, ax=ax)\nplt.show()","9702c9b0":"sns.countplot(df_train_meta.target)\nplt.show()","960038a2":"fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,6))\nsns.countplot(df_train_meta[df_train_meta['hostgal_photoz'] == 0].target, ax = ax[0])\nsns.countplot(df_train_meta[df_train_meta['hostgal_photoz'] != 0].target, ax = ax[1])\nplt.show()","67d537c4":"f, ax = plt.subplots(figsize=(12, 9))\nsns.countplot('target', hue='ddf', data=df_train_meta, ax=ax)\nplt.show()","8f06e5ef":"f, ax = plt.subplots(figsize=(12, 6))\nsns.distplot(df_train_meta[df_train_meta.ddf==1].hostgal_photoz)\nsns.distplot(df_train_meta[df_train_meta.ddf==0].hostgal_photoz)\nax.legend(['Redshift on DDF Survey Area',  'Redshift outside DDF survey Area'])\nplt.show()","ec39f060":"f, ax = plt.subplots(figsize=(12, 6))\nsns.distplot(df_train_meta[df_train_meta.ddf==1].hostgal_photoz_err)\nsns.distplot(df_train_meta[df_train_meta.ddf==0].hostgal_photoz_err)\nax.legend(['Redshift error on DDF Survey Area',  'Redshift error outside DDF survey Area'])\nplt.show()","d673716d":"f, ax = plt.subplots(figsize=(12, 6))\nsns.distplot(df_train_meta.hostgal_photoz)\nsns.distplot(df_train_meta.mwebv)\nax.legend(['photoz redshift',  'MWEBV'])\nplt.show()","1f976c89":"f, ax = plt.subplots(figsize=(12, 6))\nsns.distplot(df_train_meta[df_train_meta.hostgal_photoz==0].mwebv)\nsns.distplot(df_train_meta[df_train_meta.hostgal_photoz!=0].mwebv)\nax.legend(['Galactic MWEBV',  'Extragalactic MWEBV'])\nplt.show()","b8871e13":"sns.distplot(df_train_meta.distmod.dropna())\nplt.show()","24fab3c1":"f, ax = plt.subplots(figsize=(12, 6))\nsns.distplot(df_train_meta[df_train_meta.hostgal_photoz == 0].dropna().distmod)\nsns.distplot(df_train_meta[df_train_meta.hostgal_photoz != 0].dropna().distmod)\nax.legend(['Galactic distmod',  'Extragalactic distmod'])\nplt.show()","583dcf3a":"print(df_train_meta[df_train_meta.hostgal_photoz != 0].info())\nprint(df_train_meta[df_train_meta.hostgal_photoz == 0].info())","880442ef":"f, ax = plt.subplots(figsize=(12, 6))\nsns.violinplot(y='distmod', x='target', data=df_train_meta, ax=ax)\nplt.show()","04f5452d":"Since four of them are coordinate it seems that `gal_l` is negatively correlated to `decl` and `ra` is positively correlated to `gal_b`","412d003f":"1. Most of the flux lies between -250 to 250\n2. Majority of the flux greater 250 has detected = True and majority of flux less than 250 has detective = False. Hence detected-target distribution would bee facinating.\n3. Most of the flux lies between -100 to 100","e4133581":" ### Competition Details\nWe've astonomical Time Series data. These simulated time series, or \u2018light curves\u2019, are measurements of\nan object\u2019s brightness as a function of time - by measuring the photon flux in six differ-\nent astronomical filters (commonly referred to as passbands). \n\n**We've to classify each object into 15 classes (14 are in the training set while the 15th one is for *otherwise* category).**\n\nThere is a common error which occurs frequenctly in the observation known as *Redshift* error. Due to this error, the rate of arrival slows down which results in fainter(reddish) light. Redshift can cause either because of the dust in the path of the light or because of the doppler's effect i.e both the entities are moving opposite each other. It is necessary to take *Redshift* in consideration in classification\n\nIn this competition **weighted LogLoss Metrics** is used which means one cannot afford to make wrong predictions with high confidence which makes this problem more interesting. \n\n\n\n","c64be7b6":"1. Time series data is unevenly distributed.\n2. A significant amount of data gaps are present . \n3. Average flux of an object  either have clustered vertical distribution or well-scattered vertical distribution.\n4. Flux Errors are usually clustered and we might use the the distribution of flux and flux_error in later prediction.","d75a7131":"1. Passband 4 and 5 has comparitively wider distribution.\n2. Passband 2 has the most concentrated distribution\n3. Passband 1,3,4 are almost similar\n4. Total count of passbands are different which suggests that there would be data inconsistency in the training set.\n","943951e7":"### Questions and Intutions\n* `flux` and `flux_err` distribution wrt passbands\n* How much passbands have `detected` True.\n* Does `detected` is True for each passband of an object.\n* Find transient and Variable targets.\n* `flux` - `mjd` distribution\n* `flux` and `flux_err` distribution wrt mjd and passbands\n* correlation b\/w `ra`, 'decl` with `gal_l`, `gal_b`\n* Effect of ddf in `hostgal_photoz_err` and `flux_err`\n* correlation between `hostgal_specz`, `MWEBV` and `hostgal_photoz`\n* Checkout frequency of negative flux, distribution of -ve flux and corresponding targets frequncy.\n* Find galactic and extragalctic targets distribution\n* Detected-Target distribution","8f0a6570":"### Let the EDA begins","678661ee":"# EDA","88cb5313":"### Dataset Introduction\n\n**Training data**\n* `object_id` -> the Object ID, unique identifier (given as int32 numbers).\n* `mjd` -> The time in Modified Julian Date (MJD) of the observation.  The MJD is a unit of time introduced by the Smithsonian Astrophysical Observatory in 1957 to record the orbit of Sputnik.\n* `passband` -> The specific LSST passband integer, such that u,g,r,i,z,y = 0, 1, 2, 3, 4, 5 in which it was viewed. \n* `flux` -> the measured flux (brightness) in the passband of observation as listed in the passband column. The flux is corrected for MWEBV, but for large dust extinctions the uncertainty will be much larger in spite of the correction.\n* `flux_err` ->  the uncertainty on the measurement of the flux listed above, given as float32 number..\n* `detected` -> If detected = 1, the object\u2019s brightness is significantly different at the 3\u03c3 level relative to the reference template. This is given as a Boolean flag.\n\n** Training Meta data **\n* `object_id` -> the Object ID, unique identifier\n* `ra` ->  right ascension, sky coordinate:  longitude, units are degrees (given as float32 numbers).\n* `decl` -> declination, sky coordinate: latitude, units are degrees \n* `gal_l` -> Galactic longitude, units are degrees (given as float32 numbers).\n* `gal_b` -> Galactic lattitude, units are degrees (given as float32 numbers).\n* `ddf` -> A Boolean flag to identify the object as coming from the DDF survey area (with value ddf = 1 for the DDF). Note that while the DDF fields are contained within the full WFD survey area, the DDF fields have significantly smaller uncertainties, given that the data are provided as additions of all observations in a given night.\n* `hostgal_specz` -> The spectroscopic redshift of the source.  This is an extremely ac-\ncurate measure of redshift, provided for the training set and a small fraction of the\ntest set.\n* `hostgal_photoz` ->  The photometric redshift of the host galaxy of the astronomical source.  While this is meant to be a proxy for `hostgal_specz`, there can be large differences between the two and `hostgal_photoz` should be regarded as a far less accurate version of `hostgal_specz`.  The `hostgal_photoz` is given as float32 numbers.\n* `hostgal_photoz_err` -> The uncertainty on the `hostgal_photoz` based on LSST survey projections, given as float32 numbers.\n* `distmod` -> The  distance  (modulus)  calculated  from  the `hostgal_photoz` since  this redshift is given for all objects (given as float32 numbers).  Computing the distance modulus requires knowledge of General Relativity, and assumed values of the dark energy and dark matter content of the Universe, as mentioned in the introduction section.\n* `MWEBV` -> is equivaltent to MW E(B-V). this \u2018extinction\u2019 of light is a property of the Milky Way (MW) dust along the line of sight to the astronomical source,  and is thus a function of the sky coordinates of the source `ra`, `decl`.  This is used to determine a passband dependent dimming and reddening of light from astronomical sources as described in subsection 2.1, and is given as float32 numbers.\n* `target` -> The class of the astronomical source. This is provided in the training data.\nCorrectly determining the target (correctly assigning classification probabilities to\nthe objects) is the goal of the classification challenge for the test data.  The\ntarget is given as int8 numbers\n\n** Caveats**\n* Galactic vs extragalactic\n* Data Gaps\n* Negative flux","311184fd":"1. Photoz redhift is more scattered than the specz redshift\n2. Error distribution is pretty concentrated.\n3. There are two types of targets: Galactic(``mwebv = 0``) and extragalcatic.\n4. Redshift outside DDF area are more scattered.\n5. distmod is ``NA`` of extragalactic objects.\n"}}