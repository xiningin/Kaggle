{"cell_type":{"68073f5b":"code","4188fc0b":"code","4c971da1":"code","ef66fda4":"code","bfefeecc":"code","17912afd":"code","8cdc51ae":"code","9959ad69":"code","4e3a594f":"code","80cb2b6c":"code","c862de39":"code","e8f76252":"code","71f59871":"code","3322b6c1":"code","2c8e13d1":"code","a92fc552":"code","486a0e20":"code","3ce41b69":"code","688c9b34":"code","40f41b4d":"code","a8786bdd":"code","a8de18ae":"code","3595e22e":"code","53c7c610":"code","0e20ec14":"code","0fb42f11":"code","41d03a5a":"code","b39e7c46":"code","8414dcae":"code","5e96d7b0":"code","de3f42aa":"code","41484155":"code","50bd6db6":"code","7a8cc4a4":"code","65496e0d":"code","1cd4d4e1":"code","09252e10":"code","ed9d0e2b":"code","1c35c3b0":"code","ab80b0c7":"code","d9a08682":"code","a78d2a8c":"code","35fc7d75":"code","f16900e5":"markdown","0d5c371c":"markdown","00e3dc88":"markdown","b085b959":"markdown","842b9409":"markdown","202ae200":"markdown","45390ae2":"markdown","bdb0bffd":"markdown","420af021":"markdown","7ee1d1d9":"markdown","ee2afd6d":"markdown","11c12127":"markdown"},"source":{"68073f5b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4188fc0b":"df = pd.read_csv(\"\/kaggle\/input\/rossmann-store-sales\/train.csv\")","4c971da1":"df","ef66fda4":"storedf = pd.read_csv(\"\/kaggle\/input\/rossmann-store-sales\/store.csv\")","bfefeecc":"storedf","17912afd":"storedf.info()","8cdc51ae":"storedf.isna().any()","9959ad69":"df.isna().any() # is null","4e3a594f":"df.info()","80cb2b6c":"mergedf = df.merge(storedf,on=[\"Store\"],how=\"inner\")","c862de39":"mergedf","e8f76252":"# Store with maximum sale count\nmergedf[mergedf[\"Sales\"] == mergedf[\"Sales\"].max()]","71f59871":"# PLOT: store sale with maximum sale count \n\ndf_max_store = mergedf[mergedf[\"Store\"] == 909]\n","3322b6c1":"df_max_store[[\"Date\",\"Sales\"]].plot()","2c8e13d1":"import numpy as np\n\nmergedf['Date'] = pd.to_datetime(mergedf['Date'],infer_datetime_format=True)\nmergedf['Month'] = mergedf[\"Date\"].dt.month\nmergedf['Quarter'] = mergedf[\"Date\"].dt.quarter\nmergedf[\"Year\"] = mergedf[\"Date\"].dt.year\n\n\n","a92fc552":"mergedf[\"Day\"] = mergedf[\"Date\"].dt.day\nmergedf[\"Week\"] = mergedf[\"Date\"].dt.week\nmergedf[\"Season\"] = np.where(mergedf[\"Month\"].isin([3,4,5]),\"spring\",\n                            np.where(mergedf[\"Month\"].isin([6,7,8]),\n                                    \"summer\",np.where(mergedf[\"Month\"].isin([9,10,11]),\"fall\",\n                                                     np.where(mergedf[\"Month\"].isin([12,1,2]),\n                                                             \"winter\",\"None\"))))","486a0e20":"print(mergedf[[\"Date\",\"Year\",\"Month\",\"Day\",\"Week\",\"Quarter\",\"Season\"]].head())","3ce41b69":"plt.figure(figsize=(15,8))\nplt.hist(mergedf[\"Sales\"])\nplt.title(\"Histogram for Store Sales\")\nplt.xlabel(\"bins\")\nplt.xlabel(\"Frequency\")\nplt.show()\n","688c9b34":"mergedf.hist(figsize=(20,10))","40f41b4d":"mergedf.isnull().sum()\/mergedf.shape[0] * 100","a8786bdd":"import seaborn as sns \nsns.set(style=\"whitegrid\")\n\nax = sns.barplot(x=\"Season\", y=\"Sales\", data=mergedf)","a8de18ae":"ax = sns.barplot(x=\"Assortment\",y=\"Sales\",data=mergedf)","3595e22e":"ax = sns.barplot(x=\"StoreType\",y=\"Sales\",data=mergedf)","53c7c610":"ax = sns.barplot(x=\"Season\", y=\"Sales\", data=mergedf,estimator=np.size)","0e20ec14":"ax = sns.barplot(x=\"Assortment\", y=\"Sales\", data=mergedf,estimator=np.size)","0fb42f11":"ax = sns.barplot(x=\"StoreType\", y=\"Sales\", data=mergedf,estimator=np.size)","41d03a5a":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\ntarget = [\"Sales\"]\nnumeric_columns = [\"Customers\",\"Open\",\"Promo\",\"Promo2\", \"StateHoliday\",\"SchoolHoliday\",\"CompetitionDistance\"]\ncategorical_columns = [\"DayOfWeek\",\"Quarter\",\"Month\",\"Year\",\"StoreType\",\"Assortment\",\"Season\"]\n\n","b39e7c46":"mergedf.isna().any()","8414dcae":"mergedf[\"CompetitionDistance\"]=mergedf[\"CompetitionDistance\"].fillna(mergedf[\"CompetitionDistance\"].mode()[0])","5e96d7b0":"def one_hot(df,column):\n    \n    uniqueList = df[column].unique()\n    \n    \n    temp = pd.DataFrame()\n    i = 1\n    for item in uniqueList:\n        \n        cname = str(column)+\"_\"+str(i)\n        \n        temp[cname] = [1 if d == True else 0 for d in mergedf[column]==item]\n        \n        \n        i+=1\n        \n    \n    return temp\n\n#mergedf[\"Year\"].unique()","de3f42aa":"ctemp = pd.DataFrame()\nfirst = True\n\nfor c in categorical_columns:\n\n\n    ttdf = one_hot(mergedf[[c]],c)\n    \n    if first == True:\n        ctemp = ttdf.copy()\n        first = False\n    else:\n        ctemp = pd.concat([ctemp,ttdf], axis = 1)","41484155":"ctemp # checking one-hot encoding","50bd6db6":"temp = pd.concat([ctemp,mergedf[numeric_columns]],axis=1)","7a8cc4a4":"#total columns\n\nlen(temp.columns)","65496e0d":"# all columns \n\ntemp.columns","1cd4d4e1":"# making StateHoliday numerical\n\ntemp[\"StateHoliday\"] = [ 1 if a == 'b' else 0 for a in list(temp[\"StateHoliday\"])]","09252e10":"from sklearn.model_selection import train_test_split","ed9d0e2b":"\nx_train, x_test, y_train, y_test = train_test_split(temp,mergedf[target],test_size=0.2,random_state=42)\n","1c35c3b0":"x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,test_size=0.1,random_state=42)\nprint(\"Shape of x_train:\",x_train.shape)\nprint(\"Shape of x_val:\",x_val.shape)\nprint(\"Shape of x_test:\",x_test.shape)\nprint(\"Shape of y_train:\",y_train.shape)\nprint(\"Shape of y_val:\",y_val.shape)\nprint(\"Shape of y_test:\",y_test.shape)","ab80b0c7":"mean_sales = y_train.mean()\nprint(\"Average Sales :\",mean_sales)","d9a08682":"# check if  there are any non-numeric value\n\n\n# i=0\n# for a in x_train[\"StateHoliday\"]:\n#     print(i)\n#     i+=1\n#     print(int(a))\n\n# x_train[x_train[\"StateHoliday\"]=='b'][\"StateHoliday\"] = 1","a78d2a8c":"\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nmodel = Sequential()\nmodel.add(Dense(150,input_dim = 44,activation=\"relu\"))\n\nmodel.add(Dense(1,activation = \"linear\"))\n\nmodel.compile(optimizer='adam',loss=\"mean_absolute_error\",\nmetrics=[\"mean_absolute_error\"])\n\nmodel.fit(x_train.astype(np.float32),y_train.astype(np.float32),epochs=10,batch_size=64)","35fc7d75":"result = model.evaluate(x_test.astype(np.float32),y_test.astype(np.float32))\n\nfor i in range(len(model.metrics_names)):\n    print(\"Metric \",model.metrics_names[i],\":\",str(round(result[i],2)))","f16900e5":"## CREATING MODEL","0d5c371c":"### Statistical Data Visualization\n","00e3dc88":"## Conclusion\n\nWe will try to improve this performance next time. Thanks for reading.","b085b959":"### Merge \nMerging store data frame and sales record dataframe to get flat and single dataframe","842b9409":"## References\n* Learn Keras for Deep Neural Networks By Jojo Moolayil ,2019","202ae200":"## DATA SHAPE","45390ae2":"# DATA PREPARATION","bdb0bffd":"#### Maximum minimum average sale count","420af021":"# EDA","7ee1d1d9":"### DATA TYPE","ee2afd6d":"## ONE HOT ENCODING","11c12127":"## SPLITING TRAIN TEST DATA"}}