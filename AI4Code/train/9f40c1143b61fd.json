{"cell_type":{"062fddc9":"code","7643b3af":"code","6955a369":"code","c5e0d664":"code","f8f4afab":"code","bc72913c":"code","d8005838":"code","84d81dbc":"code","43907706":"markdown","181e1a04":"markdown","a89ac663":"markdown","b53a9f37":"markdown","29c5fa4b":"markdown","31cd0101":"markdown","d52f39c1":"markdown","85ad6b11":"markdown","c6793b0e":"markdown"},"source":{"062fddc9":"import torch\nimport torch.nn as nn                   #for sequence api in torch\nfrom torch.utils.data import DataLoader #for loading images\nimport numpy as np                      #just in case if you need numpy arrays\nimport torchvision.transforms as T      #Used for data preprocessing and converting images to tensors\nimport torchvision.datasets as dset\nimport torch.optim as optim             #For using the desired parameter update\nimport torch.nn.functional as F\n\nUSE_GPU = True\n\nif USE_GPU and torch.cuda.is_available():\n  device = torch.device('cuda')\nelse:\n  device = torch.device('cpu')\n\ndtype = torch.float32\n\nprint(\"Using device: \",device)","7643b3af":"transform = T.Compose([T.RandomHorizontalFlip(),T.ToTensor()])\n#Training \ntrain_data = dset.ImageFolder(\"..\/input\/face-expression-recognition-dataset\/images\/train\",transform=transform)\nloaded_train = DataLoader(train_data,batch_size=64,shuffle=True)\n#Validation\nvalidation_data = dset.ImageFolder(\"..\/input\/face-expression-recognition-dataset\/images\/validation\",transform=transform)\nloaded_validation = DataLoader(validation_data,batch_size=64,shuffle=False)\n\nloss_history = []\nvalidation_acc = []\ntraining_acc = []","6955a369":"%matplotlib inline              \nimport matplotlib.pyplot as plt\nimport random                   #For selecting random element from list\n\ndataiter = iter(loaded_train)   #The iter() function in python represents the iterator similar to c++ iterators\nimages, labels = dataiter.next() #The next() method retrieves the object \nexpression = {0:\"angry\",1:\"disgust\",2:\"fear\",3:\"happy\",4:\"neutral\",5:\"sad\",6:\"surprise\"} #Create a dictionary for mapping accordingly\nrandom_idx = random.sample(range(0,64),1)[0]     #Selects a random single number from 0-64\nprint(\"Target label: \",expression[int(labels[random_idx].numpy())])  #Converting it to numpy from tensor to fetch the label\nplt.imshow(np.transpose(images[random_idx].numpy(), (1, 2, 0)))   ","c5e0d664":"def check_accuracy_part(loader, model):\n    print('Checking accuracy on validation set')\n    num_correct = 0\n    num_samples = 0\n    model.eval()  # set model to evaluation mode\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n            y = y.to(device=device, dtype=torch.long)\n            scores = model(x)\n            _, preds = scores.max(1)\n            num_correct += (preds == y).sum()\n            num_samples += preds.size(0)\n        acc = float(num_correct) \/ num_samples\n        print('Got %d \/ %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))","f8f4afab":"def train_part(model, optimizer, epochs=1):\n    \"\"\"\n    Train a model using the PyTorch Module API.\n    \n    Inputs:\n    - model: A PyTorch Module giving the model to train.\n    - optimizer: An Optimizer object we will use to train the model\n    - epochs: (Optional) A Python integer giving the number of epochs to train for\n    \n    Returns: Nothing, but prints model accuracies during training.\n    \"\"\"\n    model = model.to(device=device)  # move the model parameters to CPU\/GPU\n    for e in range(epochs):\n        print(\"epoch: \",e+1)\n        for t, (x, y) in enumerate(loaded_train):\n            model.train()  # put model to training mode\n            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n            y = y.to(device=device, dtype=torch.long)\n\n            scores = model(x)\n            loss = F.cross_entropy(scores, y)\n\n            # Zero out all of the gradients for the variables which the optimizer\n            # will update.\n            optimizer.zero_grad()\n\n            # This is the backwards pass: compute the gradient of the loss with\n            # respect to each  parameter of the model.\n            loss.backward()\n\n            # Actually update the parameters of the model using the gradients\n            # computed by the backwards pass.\n            optimizer.step()\n\n            if t % 100 == 0:\n                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n                check_accuracy_part(loaded_validation, model)\n                print()","bc72913c":"model = None\noptimizer = None\n\n#First architecture #3,32,32\nconv1 = nn.Sequential(\n    nn.Conv2d(3,512,kernel_size=(3,3),bias=True,padding=1), #512,48,48\n    nn.BatchNorm2d(512),\n    nn.ReLU(),\n    nn.MaxPool2d(kernel_size=(2,2))  #Sampling image to half  512,24,24\n)\nconv2 = nn.Sequential(\n    nn.Conv2d(512,128,kernel_size=(3,3),padding=1,bias=True), #128,24,24\n    nn.BatchNorm2d(128),\n    nn.ReLU(),\n    nn.MaxPool2d(kernel_size=(2,2))         #128,12,12\n)\nconv3 = nn.Sequential(\n    nn.Conv2d(128,64,kernel_size=(3,3),bias=True,padding=1), #64,12,12\n    nn.BatchNorm2d(64),\n    nn.ReLU(),\n    nn.MaxPool2d(kernel_size=(2,2))   #64,6,6\n)\nconv4 = nn.Sequential(\n    nn.Conv2d(64,256,kernel_size=(3,3),bias=True,padding=1), #64,6,6\n    nn.BatchNorm2d(256),\n    nn.ReLU(),\n    nn.MaxPool2d(kernel_size=(2,2))   #256,3,3\n)\nfc = nn.Sequential(\n    nn.Flatten(),\n    nn.Linear(256*3*3,7),\n)\nmodel = nn.Sequential(\n    conv1,\n    conv2,\n    conv3,\n    conv4,\n    fc\n)\nlearning_rate=0.001\noptimizer = optim.Adam(model.parameters(),lr=learning_rate)\ntrain_part(model, optimizer, epochs=10)","d8005838":"#Best model\nbest_model = model\ncheck_accuracy_part(loaded_validation,best_model)","84d81dbc":"def check_accuracy_test(x,y,model):\n  num_samples = 0\n  num_correct = 0\n  loss = None\n  model.eval()    #turning drop-out\/batch norm layer from training to test mode \n  with torch.no_grad():\n    x = x.to(device=device,dtype=dtype)\n    y = y.to(device=device,dtype=torch.long)\n    scores = model(x)\n    _,preds = scores.max(1)\n    return preds\n\nexpression = {0:\"angry\",1:\"fear\",2:\"happy\",3:\"sad\",4:\"surprise\"} #Create a dictionary for mapping accordingly\n\ntransform = T.Compose([T.ToTensor()])\ntest_data = dset.ImageFolder(\"..\/input\/test-images\/test\",transform=transform)\nloaded_test = DataLoader(test_data,batch_size=5,shuffle=False)\n\ndataiter = iter(loaded_test)   #The iter() function in python represents the iterator similar to c++ iterators\nimages, labels = dataiter.next() #The next() method retrieves the object\n\nrandom_idx = random.sample(range(0,5),1)[0] \n\nimage = torch.reshape(images[random_idx],(1,3,48,48))\npredicted_idx = check_accuracy_test(image,labels[random_idx],best_model)\n\nprint(\"Predicted label: \",expression[predicted_idx.item()]) \nprint(\"Correct label: \",expression[int(labels[random_idx].numpy())])  #Converting it to numpy from tensor to fetch the label\nimage = torch.reshape(image,(3,48,48))\nplt.imshow(np.transpose(image.numpy(), (1, 2, 0)))  ","43907706":"## Import the necessary header files required\n\nCheck whether you have GPU availablity since training in CPU is very slow\n\nPrerequisites: \n* Knows intermediate python\n* Classification problems in machine learning\n* How **Forward prop** and **Back prop** works in neural nets\n* Basics of gradient descent (also nice to know kinds of parameter updates)","181e1a04":"## Building our neural network\n\nThis is completely upto your choice you can prefer any kind of structure that you want.\n\n*In torch make sure your conv and pool dimensions are proper* or else the matrices\/tensors can't undergo proper matrix multipilcation.\n\n***Remember to flatten for shifting from convolutional layers to fully connected layers***\n\nThe ReduceLROnPlateau reduces the learning rate whenever our network is stuck at a local minima.\n\n### Important formulas for calculating dimensions\n\n* Output of conv layer would have dimension -> ((H - F + 2P)\/\/s) + 1 *we can't have decimals here*\n\n  *where H - height of input(in our case image) , F - kernel_size(filter size) , P - padding & s - stride (vice versa for width)* \n  \n  \n* If you want the input dimensions (height & width) to remain same then you can use this -> (F - 1)\/2\n\n  *where F - kernel_size(filter size)*","a89ac663":"## Best performance:","b53a9f37":"### If you find this notebook informative please upvote","29c5fa4b":"## Visualizing the image\n\nAs a usual gut check it's recommended to see your image to be sure that image appears properly from DataLoader\n\nHere I've implemented a random way of selecting a expression from the list of images","31cd0101":"## Data loading and preprocessing\n\nHere there isn't much of data preprocessing going on, The RandomHorizontalFlip flips images randomly so our model is more robust\n\nThe DataLoader part in Pytorch takes care of target labels(y, which in our case is the name of the folder) and features(x)","d52f39c1":"## Testing our model with sample images:\n\nHere we'll import random photos from the internet and test how the model predicts","85ad6b11":"## Training the model\n\n* This method trains our model and it's almost similar to the accuracy part.\n* Here we have backward() - takes care of back propagation and the optimizer - takes care of parameter update","c6793b0e":"## Creating a method for predicting validation accuracy\n\n*In Pytorch, we don't have any api like model.fit() in tensorflow, so we have to create our own method.*\n\n* The function calculates the number of correct samples and divides by the number of total samples which ultimately gives us the accuracy.\n* Notice torch.no_grad() part, this is very important as we don't want to back-propagate while predicting."}}