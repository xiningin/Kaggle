{"cell_type":{"33355a5d":"code","18582d60":"code","94d16534":"code","677c767d":"code","091630dc":"code","b53950a9":"code","d25dd6e6":"code","1578d880":"code","072a22b5":"code","87c8427d":"code","65a4eb2e":"code","47810444":"code","4e258cea":"code","8024cee7":"code","ef6a7963":"code","0cec6dec":"code","251bdc09":"code","d71f1f9d":"code","46091e30":"code","1300d0dd":"code","b2d2f3f0":"code","14223287":"code","0bef5318":"code","137ea1d4":"code","951a2855":"code","c53d46b1":"code","4394233b":"code","c7a130d3":"markdown","6f4312d6":"markdown","6879db3f":"markdown"},"source":{"33355a5d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport matplotlib.pyplot as plt #plotting charts\nimport seaborn as sns #plotting charts\n\n","18582d60":"# Read in the data from the 3 reports\nhappy_2015 = pd.read_csv('..\/input\/2015.csv')\nhappy_2016 = pd.read_csv('..\/input\/2016.csv')\nhappy_2017 = pd.read_csv('..\/input\/2017.csv')","94d16534":"happy_2015.head()","677c767d":"happy_2016.head()","091630dc":"happy_2017.head()","b53950a9":"happy_2015.info()","d25dd6e6":"happy_2016.info()","1578d880":"happy_2017.info()","072a22b5":"# Let's find the missing countries between 2015 & 2016 by merging the two tables and \n# creating a new _merge column\n\nmerge1516 = pd.merge(happy_2015,happy_2016,on='Country',how='outer',indicator=True)\n\n# List the countries included in 2015 but not 2016. \nnot16 = merge1516[merge1516['_merge'] == 'left_only']['Country'].tolist()\nnot16","87c8427d":"# List the countries included in 2016 but not 2015\nnot15 = merge1516[merge1516['_merge'] == 'right_only']['Country'].tolist()\nnot15","65a4eb2e":"# Fix \"Somaliland Region\" in 2015 table\n# Remove null value countries from both dataframes\n\nhappy_2015['Country'].replace(to_replace = 'Somaliland region',value='Somaliland Region',inplace=True)\nnot15.remove('Somaliland Region')\nnot16.remove('Somaliland region')\nhappy_2015_clean = happy_2015[~happy_2015['Country'].isin(not16)]\nhappy_2016_clean = happy_2016[~happy_2016['Country'].isin(not15)]\n","47810444":"# Use the same method to compare the 'clean' 2016 table to 2017 table\n\nmerge1617 = pd.merge(happy_2016_clean,happy_2017,on='Country',how='outer',indicator=True)\n\n# Countries in 2016_clean but not in 2017\nnot17 = merge1617[merge1617['_merge'] == 'left_only']['Country'].tolist()\nnot17","4e258cea":"# Countries in 2017 but not in 2016_clean\nnot16_new = merge1617[merge1617['_merge'] == 'right_only']['Country'].tolist()\nnot16_new","8024cee7":"# Make the names for 'Taiwan' and 'Hong Kong' consistent across both happy_2016_clean and \n# happy_2017 tables\n\nhappy_2017['Country'].replace(to_replace = 'Hong Kong S.A.R., China',value = 'Hong Kong',inplace=True)\nhappy_2017['Country'].replace(to_replace = 'Taiwan Province of China',value = 'Taiwan',inplace=True)\nnot17.remove('Taiwan')\nnot17.remove('Hong Kong')\nnot16_new.remove('Taiwan Province of China')\nnot16_new.remove('Hong Kong S.A.R., China')\n\n# Finally, clean up null values from all 3 dataframes\n\nhappy_2015_clean = happy_2015_clean[~happy_2015_clean['Country'].isin(not17)]\nhappy_2016_clean = happy_2016_clean[~happy_2016_clean['Country'].isin(not17)]\nhappy_2017_clean = happy_2017[~happy_2017['Country'].isin(not16_new)]\n","ef6a7963":"happy_2017_clean.head()","0cec6dec":"# rename column headings\nhappy_2017_clean = happy_2017_clean.rename(columns={'Happiness.Rank': 'Happiness Rank 2017'})\nhappy_2015_clean = happy_2015_clean.rename(columns={'Happiness Rank': 'Happiness Rank 2015'})\nhappy_2016_clean = happy_2016_clean.rename(columns={'Happiness Rank': 'Happiness Rank 2016'})\n","251bdc09":"# Create a new dataframe of Country, Region, Happiness Rank from all 3 clean\n# dataframes\n\ncolumn_list_2015 = ['Country','Region','Happiness Rank 2015']\nhappy_2015_clean_final = happy_2015_clean[column_list_2015]\n\ncolumn_list_2016 = ['Country','Region','Happiness Rank 2016']\nhappy_2016_clean_final = happy_2016_clean[column_list_2016]\n\ncolumn_list_2017 = ['Country','Happiness Rank 2017']\nhappy_2017_clean_final = happy_2017_clean[column_list_2017]\n\nhappy_final = happy_2015_clean_final.merge(\n    happy_2016_clean_final,on='Country').merge(\n    happy_2017_clean_final,on='Country')  # merge all 3 data frames on 'Country' column\n\nhappy_final","d71f1f9d":"# Remove 'Region_y' column and rename 'Region_x' to 'Region'\n\nhappy_final.drop('Region_y',axis=1,inplace = True)\nhappy_final.rename(columns={'Region_x':'Region'},inplace = True)\n","46091e30":"happy_final.head(10)","1300d0dd":"# Let's see which countries have increased\/decreased their Happiness Rank the most between 2015\n# and 2017\n\n# Add a new column showing the change in rank between 2017 and 2015\nhappy_final['Change in Rank'] = happy_final['Happiness Rank 2015'] - happy_final['Happiness Rank 2017']\n","b2d2f3f0":"happy_final.head(10)","14223287":"# The top 10 countries that have seen their happiness rank decrease the most between 2015 and 2017\nhappy_final.sort_values(by='Change in Rank',axis=0,ascending=True).head(10)\n","0bef5318":"# Look at the countries in Latin America and Caribbean only\nhappy_latin = happy_final[happy_final['Region'] == 'Latin America and Caribbean']\nhappy_latin.head()","137ea1d4":"# Plot a bar chart of countries in Latin America & Caribbean versus their change in rank\nimport seaborn as sns\nplt.figure(figsize=(14,8))\nsns.set_style(\"whitegrid\")\nsns.barplot(x='Country',y='Change in Rank',\n            data=happy_latin.sort_values(by='Change in Rank',ascending=False),palette='muted')\nplt.xticks(rotation=90)\nplt.grid(b=True,which='major')","951a2855":"# Plot a similar bar chart for those countries in Sub-Saharan Africa\nhappy_sub_saharan = happy_final[happy_final['Region'] == 'Sub-Saharan Africa']\nhappy_sub_saharan_sort = happy_sub_saharan.sort_values(by='Change in Rank', ascending=False)\nplt.figure(figsize=(14,8))\nsns.set_style(\"whitegrid\")\nsns.barplot(x='Country',y='Change in Rank',data=happy_sub_saharan_sort,palette = 'muted')\nplt.xticks(rotation=90)\nplt.grid(b=True,which='major')","c53d46b1":"# Find the countries that have a decrease in rank that is more than 2 times the standard \n# deviation\nhappy_final[happy_final['Change in Rank'] < - happy_final['Change in Rank'].std() *2]","4394233b":"# Let's look at the attributes that contributes the most to the decrease in happiness \n# in the countries Venezuela, Zambia, Liberia and Haiti\n\ncountries = ['Venezuela','Zambia','Liberia','Haiti']\nhappy_2015_copy = happy_2015.copy()\nhappy_2017_copy = happy_2017.copy()\nhappy_2015_copy = happy_2015_copy.set_index('Country')\nhappy_2017_copy = happy_2017_copy.set_index('Country')\n\n# List the attributes (column headings) we are looking at\nattrib_2015 = ['Economy (GDP per Capita)','Family','Health (Life Expectancy)','Freedom'\n              , 'Trust (Government Corruption)', 'Generosity']\nattrib_2017 = ['Economy..GDP.per.Capita.','Family','Health..Life.Expectancy.','Freedom'\n              ,'Trust..Government.Corruption.','Generosity']\n\n# Rename 2017 headings to match those of 2015\nhappy_2017_copy = happy_2017_copy.rename(columns=dict(zip(attrib_2017,attrib_2015)))\n\n# Loop over the 4 countries, list the percentage changes, find the index of the minimum\n# change and print out the relevant attritbute.\nfor country in countries:\n    attrib_pct = []\n    print(country + ':')\n    for i in range(6):\n       my_attrib = (happy_2017_copy.loc[country,attrib_2015[i]] - \n                    happy_2015_copy.loc[country,attrib_2015[i]]) *100 \/ happy_2015_copy.loc[country,attrib_2015[i]]\n       attrib_pct.append(my_attrib)\n    min_index_1 = attrib_pct.index(min(attrib_pct))\n    \n    print(attrib_2015[min_index_1] + \"\\n\" )\n\n\n","c7a130d3":"**INTRODUCTION**\n\nWe will analyse the World Happiness Report for the years 2015, 2016 & 2017. In particular we are interested in finding those countries whose overall 'Happiness Rank' has decreased the most between 2015 and 2017 and the main reason for such a move.\n\nFirst we will read in the necessary dataframes and make sure that the data is consistent with regard to the country names (rows) and column headings. We can then create a new dataframe (happy_final) listing countries with their 'Happiness Rank' for each of the 3 years and a new column 'Change in Rank' showing the change between 2015 and 2017.\n\nWe then visualize these changes in rank by plotting two bar charts for the countries in the regions 'Latin America & Caribbean' and 'Sub-Saharan Africa'.\n\nFinally, we look at the countries with the largest decrease in rank and calculate which attribute from our original dataframes contributes the most to this change.","6f4312d6":"The 2017 dataframe has different heading names from the 2015\/2016 data and there seems to be a mismatch in number of countries between the 3 sets of data, which we can explore and clean up now. Otherwise the data types seem good.","6879db3f":"**Conclusion:**\n\nThe countries that have seen their 'Happiness Rank' decrease the most between 2015 and 2017 seem to be concentrated\nin the Latin America & Caribbean and Sub-Saharan Africa regions with the attributes that contribute the most to this 'change' in happiness being 'Freedom' and 'Trust (Government Corruption)."}}