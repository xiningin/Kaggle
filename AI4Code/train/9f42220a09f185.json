{"cell_type":{"527af93f":"code","3b54a66d":"code","ca6250e9":"code","8d1532db":"code","fd0318aa":"code","98943236":"code","7f4bd2a2":"code","5910e1c4":"code","6b9bc4d7":"code","e7eade78":"code","96b9bf0e":"code","c652f4fa":"code","3192b6a2":"markdown","9f7b4367":"markdown","00c29a4a":"markdown","a7f3e6fe":"markdown","cf3f3a33":"markdown","6eb89889":"markdown","99a60462":"markdown","c3a471d1":"markdown","87b3465a":"markdown","1e9754e5":"markdown","439589f1":"markdown","1e47f39d":"markdown","b638b32e":"markdown","4046adef":"markdown"},"source":{"527af93f":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nplt.style.use(\"seaborn\")","3b54a66d":"data = pd.read_csv(\"..\/input\/linear-regression-dataset\/Linear Regression - Sheet1.csv\")","ca6250e9":"data.info()","8d1532db":"data.head()","fd0318aa":"data.isnull().sum()","98943236":"cmap = sns.diverging_palette(20, 220, as_cmap=True)\nsns.heatmap(data.corr(), cmap=cmap, vmin=-1, vmax=1, annot=True)","7f4bd2a2":"sns.regplot(x=\"X\", y=\"Y\", data=data)","5910e1c4":"lm = LinearRegression()\nx = data[[\"X\"]]\ny = data[[\"Y\"]]\nlm.fit(x, y)\npredict = lm.predict(x)","6b9bc4d7":"print(f\"Intercept of the model: {lm.intercept_}\")\nprint(f\"Slope of the model: {lm.coef_}\")","e7eade78":"ax = sns.distplot(y, hist=False, label=\"Observed Values\")\nsns.distplot(predict, hist=False, label=\"Fitted Values\", ax=ax)\nplt.title(\"Observed vs Fitted Values\")\nplt.xlabel(\"X\")\nplt.ylabel(\"Y\")","96b9bf0e":"sns.residplot(data[\"X\"], data[\"Y\"])","c652f4fa":"print(f\"The R-Squared is: {lm.score(x, y)}\")\nprint(f\"The MSE is: {mean_squared_error(predict, y)}\")","3192b6a2":"**import required libraries**","9f7b4367":"We can visualize the data by using `regplot` function from the `seaborn` library. By this way, we can see the scatter plot of the data along with the regression line.","00c29a4a":"**Check if there is any missing data**","a7f3e6fe":"**Create a linear regression object**\n\n\nSimple linear regression (SLR) helps us to understand the relationship between two variables (X and Y).\n\n\nIn our case,\n* X is the predictor or independent variable\n* Y is the response or dependent variable\n\n\n$\n X: Predictor(Independent) \\ Variables\\\\\n Y: Response(Dependent) \\ Variable\n$\n\n\n**Function:** $Y = b_0 + b_1X$\n\n$b_0$ is known as **intercept** and $b_1$ is known as **slope**.","cf3f3a33":"**Determine the accuracy of the model**\n\n* $R^2\/R-Squared$ (Coefficient of Determination)\n* Mean Squared Error (MSE)","6eb89889":"Since the regression slope is positive, there is a positive correlation between two variables. Data points are not scattered too much around the regression line which is a good indication of variance.","99a60462":"**Information about the dataframe**","c3a471d1":"We can see the strength of association between X and Y by calculating correlation coefficient and visualizing it.","87b3465a":"We can find the intercept and slope by `intercept_` and `coef_` data attributes, respectively.","1e9754e5":"We can see that X is positively correlated with Y","439589f1":"We can compare the observed and fitted values by a distribution plot.","1e47f39d":"This plot shows that most of the data is randomly dispersed and there are two outliers.","b638b32e":"**Create a residual plot**\n\n**Residual** is the difference between the observed value and the predicted value.\n\nResidual plot is a good way to see variance of the data","4046adef":"**Load the data and store in dataframe \"data\"**"}}