{"cell_type":{"7ca85fbd":"code","1c73f85e":"code","7e102902":"code","001925bb":"code","a82dcd22":"code","32354a82":"code","828c38fa":"code","475d59d8":"code","62edebf0":"code","738c3382":"code","957fc2fb":"code","a0918ef4":"code","bf77ab70":"code","2a9f89d5":"code","5f34c9c9":"code","7533c1fc":"code","b9b9b492":"code","b84a5f6c":"code","96cdc589":"code","8dbfb804":"code","127ef305":"code","326f6d6e":"code","9f40c3d2":"code","0c53f361":"code","ee43aad5":"code","32592250":"code","1769f38b":"code","8fa8dc2b":"code","f5b261af":"markdown","78225ee3":"markdown","f37457e8":"markdown","5f2645e6":"markdown","1bf8aab7":"markdown","afec631a":"markdown","8152deed":"markdown","9335a718":"markdown","dc775919":"markdown","7b103abc":"markdown","9e827704":"markdown","945ebfbf":"markdown","9abefdb0":"markdown","d5c10bbb":"markdown","88dd9a2b":"markdown","c6c6b2b1":"markdown","989116b9":"markdown","dbb48890":"markdown","412a9a53":"markdown","fab261b4":"markdown","99ecd98a":"markdown","eecf7f25":"markdown","7aa41078":"markdown","769fa7f8":"markdown","e8753878":"markdown"},"source":{"7ca85fbd":"import numpy as np \nimport pandas as pd \nimport os\nimport re\nfrom sklearn.ensemble import RandomForestClassifier\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1c73f85e":"#Loading in the datasets\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","7e102902":"#Lets first take a look at our data\ntrain_data.head()","001925bb":"#... and therefore have the machine describe it to us\ntrain_data.info()","a82dcd22":"#Lets now identify missing values\ntrain_data.isnull().sum()","32354a82":"#Excluding the 'PassengerId' column from the analysis. \n#We will do this simply by 'dropping' the column using the following command:\ntrain_data = train_data.drop(['PassengerId'], axis=1)","828c38fa":"#Excluding the 'Ticket' column from the analysis. \n#We will do this simply by 'dropping' the column using the following command:\ntrain_data = train_data.drop(['Ticket'], axis=1)\ntest_data = test_data.drop(['Ticket'], axis=1)\n\n#Unlike the Passenger Id we will drop 'Ticket' from both of the datasets because it isn't required for submission","475d59d8":"#Using the following code, we will assign cabins A, B, and C to numeric values such as 1, 2, and 3.\nimport re\ndeck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\ndata = [train_data, test_data]","62edebf0":"#Thereafter we will convert the missing values to zero and create new features\nfor dataset in data:\n    dataset['Cabin'] = dataset['Cabin'].fillna(\"U0\")\n    dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n    dataset['Deck'] = dataset['Deck'].map(deck)\n    dataset['Deck'] = dataset['Deck'].fillna(0)\n    dataset['Deck'] = dataset['Deck'].astype(int)","738c3382":"#Now we can drop the original 'Cabin' column from the original datasets\ntrain_data = train_data.drop(['Cabin'], axis=1)\ntest_data = test_data.drop(['Cabin'], axis=1)\n","957fc2fb":"data = [train_data, test_data]\n\n#We will first find the median age of the passengers on board.\nfor dataset in data:\n    mean = train_data[\"Age\"].mean()\n    std = test_data[\"Age\"].std()\n    is_null = dataset[\"Age\"].isnull().sum()\n    \n#The median age will be used to assign random numbers to the missing values. \n    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n    \n#Now we will fill the missing gaps with the random numbers generated.\n    age_slice = dataset[\"Age\"].copy()\n    age_slice[np.isnan(age_slice)] = rand_age\n    dataset[\"Age\"] = age_slice\n    dataset[\"Age\"] = train_data[\"Age\"].astype(int)\ntrain_data[\"Age\"].isnull().sum()","a0918ef4":"#Filling in the gaps in the 'Embarked' column.\n#We will fill it with the most common value, as described above.\ncommon_value = 'S'\ndata = [train_data, test_data]\n\nfor dataset in data:\n    dataset['Embarked'] = dataset['Embarked'].fillna(common_value)\n","bf77ab70":"#Converting 'Fare'\ndata = [train_data, test_data]\n\nfor dataset in data:\n    dataset['Fare'] = dataset['Fare'].fillna(0)\n    dataset['Fare'] = dataset['Fare'].astype(int)","2a9f89d5":"#Converting 'Sex'\ngenders = {\"male\": 0, \"female\": 1}\ndata = [train_data, test_data]\n\nfor dataset in data:\n    dataset['Sex'] = dataset['Sex'].map(genders)","5f34c9c9":"#Converting 'Embarked'\nports = {\"S\": 0, \"C\": 1, \"Q\": 2}\ndata = [train_data, test_data]\n\nfor dataset in data:\n    dataset['Embarked'] = dataset['Embarked'].map(ports)","7533c1fc":"#First we will convert the common titles to a numeric value\n#We will assign the numeric values to 'titles'\ndata = [train_data, test_data]\ntitles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n\nfor dataset in data:\n#Now we will extract and thereafter replace the more rare titles with some of the common ones\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n#Now we will convert the titles to a number\n    dataset['Title'] = dataset['Title'].map(titles)\n#Lastly we will subscribe the missing values with 0\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_data = train_data.drop(['Name'], axis=1)\ntest_data = test_data.drop(['Name'], axis=1)","b9b9b492":"#The new age group feature will consist of 6 seperate groups.\ndata = [train_data, test_data]\nfor dataset in data:\n    dataset['Age'] = dataset['Age'].astype(int)\n    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1 #Group 1\n    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2 #Group 2\n    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3 #Group 3\n    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4 #Group 4\n    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5 #Group 5\n    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6 #Group 6\n    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6","b84a5f6c":"#Let's take a look at how the passengers is distributed throughout the age groups   \ntrain_data['Age'].value_counts()","96cdc589":"data = [train_data, test_data]\n\nfor dataset in data:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1 #Group 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2 #Group 2\n    dataset.loc[(dataset['Fare'] > 31) & (dataset['Fare'] <= 99), 'Fare']   = 3 #Group 3\n    dataset.loc[(dataset['Fare'] > 99) & (dataset['Fare'] <= 250), 'Fare']   = 4 #Group 4\n    dataset.loc[ dataset['Fare'] > 250, 'Fare'] = 5 #Group 5\n    dataset['Fare'] = dataset['Fare'].astype(int)\n","8dbfb804":"data = [train_data, test_data]\nfor dataset in data:\n    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n    dataset.loc[dataset['relatives'] > 0, 'not_alone'] = 0 #Zero meaning a passenger was traveling alone\n    dataset.loc[dataset['relatives'] == 0, 'not_alone'] = 1#One meaning a passenger was traveling in a party\n    dataset['not_alone'] = dataset['not_alone'].astype(int)\ntrain_data['not_alone'].value_counts()","127ef305":"#Making a fare per person feature\nfor dataset in data:\n    dataset['Fare_Per_Person'] = dataset['Fare']\/(dataset['relatives']+1)\n    dataset['Fare_Per_Person'] = dataset['Fare_Per_Person'].astype(int)","326f6d6e":"#Making an age times class feature\ndata = [train_data, test_data]\nfor dataset in data:\n    dataset['Age_Class']= dataset['Age']* dataset['Pclass']","9f40c3d2":"train_data.head(10)","0c53f361":"#I am dropping the 'Survived' and 'PassengerId' features of the dataset.\n#This is because including the 'Survived'-column would essentially be cheating.\n#... And because the 'PassengerId' shouldn't be count as a variable. \nX_train = train_data.drop(\"Survived\", axis=1)\nY_train = train_data[\"Survived\"]\nX_test  = test_data.drop(\"PassengerId\", axis=1).copy()","ee43aad5":"#Loading and training the Random Forest model.\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\n\nY_prediction = random_forest.predict(X_test)\n\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)","32592250":"acc_random_forest","1769f38b":"#Cross-validating\nfrom sklearn.model_selection import cross_val_score\nrf = RandomForestClassifier(n_estimators=100)\nscores = cross_val_score(rf, X_train, Y_train, cv=10, scoring = \"accuracy\")\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())","8fa8dc2b":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': Y_prediction})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","f5b261af":"**PART 5**\n\nWe will now begin training the models to conclude this assignment. \nBefore doing so, a summary of the above statements and executions is in order. \n\nTo start with, we located the missing data in our datasets. We found that the columns containing information on the passengers' age, cabin, and others had missing data. We used this information to clean the data by either dropping the columns or assigning them new values. \n\nSecond, we created new categories from existing data to help increase the precision of our model. \n\nThirdly, we created new features by combining some of our newly created categories. \n\nBefore going any further, let's first take a look at the dataset we have created. ","78225ee3":"**PART 6 - CROSS VALIDATE AND CONCLUSION**","f37457e8":"Everything seems to be in order.","5f2645e6":"Our model has an average accuracy of 92.7%! \n\nIs this too good to be true? Lets do a cross-validation.","1bf8aab7":"Done!\nLets now test the accuracy of our surival-prediction machine. ","afec631a":"For this next part, I will process the data with the above considerations in mind. Our goal in this chapter will be to make the relevant observations and considerations of which of the data variables we will use in our Random Forest algorithm, and fix missing values. ","8152deed":"As we can see, the majority of people on board fit into age group 4, which ranged from the ages of 27-33\n\nNow we will do the same with the 'Fare' column.\n","9335a718":"Dealing with the 'Cabin' column might prove to be a bit trickier. \nAs stated above, the Random Forest algorithm only works with numeric values. \nTherefore we will have to convert the 'Cabin' column from objects to numeric values. \n\n","dc775919":"We will not simply convert 'Name' to a numeric variable. Because titles of individuals, which can tell us something about their social status, are included in the column, we will instead try to create a new feature out of it. ","7b103abc":"Lastly, a new category from the 'Parch' and 'SibSp' columns will be created. This new category will help us determine whether being alone or in a party on board the Titanic would either have increased or decreased your chances of survival.  ","9e827704":"First of all we will use the 'age' column to divide all the ages into age groups. ","945ebfbf":"**This is my submission to the Kaggle Titanic competition.** \nThe foundation of my submission has been provided by the Kaggle tutorial which used the Random Forest algorithm to predict the passengers' odds of survival. \n\nThe inspiration for the assignment was provided by Niklas Donges\n\nTo improve the accuracy of my Random Forest algorithm, I will try to include other variables not found in the original Kaggle Titanic-train_data. These I will construct by merging new categories into new features. My thought process will be noted throughout the notebook.","9abefdb0":"We have now created thre new categories from 'Age' and 'Fare','Parch' and 'SibSp' and converted them into age- and fare groups. \n\nNext is using these two new categories to create new features for our machine to process. \n\nThe two new features will be\n1. Fare per person\n2. Age times class","d5c10bbb":"It seems that there is a fair amount of missing data in the dataset.\n- The 'Embarked' column only has 2 missing values,\n- The 'Cabin' column has a total of 687 missing values,\n- And we're missing information on 177 of the passengers' age.\n\nWe need to keep this in mind because of the missing data's possible implications on the credibility of the analysis. We might have to work out a solution later, to either exclude the columns with missing data or, instead, fill in the gaps.","88dd9a2b":"**CONCLUSION**\n\nThroughout this notebook, we have created a machine that can predict the odds of survival for passengers on board the Titanic, based on different variables ranging from social class to age to gender. \n\nOur model proved to have been 92.7% successful. However, after doing cross-validation (critical review) of our machine, we found that it had a mean accuracy of 82%.","c6c6b2b1":"**PART 2.**","989116b9":"1. First of all, we can conclude that the 'Passenger Id' should be excluded from the analysis because it doesn't contribute to the passengers' odds of survival. We will also drop the 'Ticket' column; it will be difficult to convert 681 unique valuables to useful data.\n\n2. Second, we have to deal with the 'Cabin' variable because of the missing values, as we saw above. We are not going to exclude 'Cabin' from the dataset because it might indicate where on the ship a passenger might have found themselves. It would be interesting to calculate whether this had affected their chances of survival.\n\n3. Third, we will fill the missing gaps in the 'Age' column. We will do this by filling the missing values with the median age, calculated from the values that we are not missing. The thought process that went into this was as follows: Because we are only missing 177 of the passengers' age out of 891 entries, the chances of the 177 missing values to push the mean age in either direction is fairly narrow. \n\n4. Lastly, we will fill the gaps in the 'Embarked' column. It only has two missing values, which is why we will simply fill them with the average ones. \n","dbb48890":"**PART 3**\n\nIn this part, we will mainly be focusing on converting features from floats and objects to integers. ","412a9a53":"Our data consists of integers, objects and floats. Some of these will have to be converted into numeric variables later in the process.","fab261b4":"This seems a bit more realistic. As we can see, our prediction machine has a mean accuracy of 82%. ","99ecd98a":"Before calculating the Titanic passengers' odds of survival, we first need to process and clean the given data. \n\nThis process aims to identify missing values, different types of data so forth.\nCleaning and understanding the data is a necessary step to prepare the data for the numeric-driven RandomForest algorithm, that doesn't comply well with missing values and things alike.\n","eecf7f25":"**PART 1.**","7aa41078":"**PART 4**\n\nIn this part, we will try to create new categories and features that can help our prediction of the passengers' chance of survival. \n\nMaking new categories out of our data is an important step because it can help us make new features that will contribute a new variable to our machine's prediction.  \n\nWe will create new categories with the columns 'Fare', 'Age', 'Parch', and 'SibSp'\n","769fa7f8":"I will now begin to train my model.","e8753878":"To fix the missing values in the 'Age' column we wil do as follows: "}}