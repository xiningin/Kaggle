{"cell_type":{"dac214e3":"code","1f372806":"code","be50f70c":"code","94f9a04d":"code","2810adbb":"code","69a2761f":"code","17318c20":"code","d71e0389":"code","3adf3426":"code","945bceff":"code","dbfb7245":"code","6fd8dde4":"code","2f90e9fb":"code","9fe135d0":"code","6d03bf05":"code","e20dbdbd":"code","770db310":"code","2c43f066":"code","75ea6ed4":"code","cf951ea5":"code","56730749":"code","fa93a4ac":"code","71026f1f":"markdown","6782c222":"markdown","458407bd":"markdown","6dacfa1e":"markdown","cbececcd":"markdown","464b6411":"markdown","9b7a3ac3":"markdown","112f3fab":"markdown","4f5fcdf3":"markdown","b6d5f94b":"markdown"},"source":{"dac214e3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datetime \nfrom dateutil.relativedelta import relativedelta\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport datetime\nimport statistics\nimport sklearn\nfrom pyproj import Geod\n\n\n# Library to assign missing values\nfrom sklearn.impute import SimpleImputer\n\n# Matplotlib is the main plotting library for python\nimport matplotlib.pyplot as plt\n\n%matplotlib inline \nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1f372806":"# Load data\n\ntripdata_2020_04 = pd.read_csv(\"\/kaggle\/input\/cyclist\/202004-divvy-tripdata.csv\")\ntripdata_2020_05 = pd.read_csv(\"\/kaggle\/input\/cyclist\/202005-divvy-tripdata.csv\")\ntripdata_2020_06 = pd.read_csv(\"\/kaggle\/input\/cyclist\/202006-divvy-tripdata.csv\")\ntripdata_2020_07 = pd.read_csv(\"\/kaggle\/input\/cyclist\/202007-divvy-tripdata.csv\")\ntripdata_2020_08 = pd.read_csv(\"\/kaggle\/input\/cyclist\/202008-divvy-tripdata.csv\")\ntripdata_2020_09 = pd.read_csv(\"\/kaggle\/input\/cyclist\/202009-divvy-tripdata.csv\")\ntripdata_2020_10 = pd.read_csv(\"\/kaggle\/input\/cyclist\/202010-divvy-tripdata.csv\")\ntripdata_2020_11 = pd.read_csv(\"\/kaggle\/input\/cyclist\/202011-divvy-tripdata.csv\")\ntripdata_2020_12 = pd.read_csv(\"\/kaggle\/input\/cyclist\/202012-divvy-tripdata.csv\")\ntripdata_2021_01 = pd.read_csv(\"\/kaggle\/input\/cyclist\/202101-divvy-tripdata.csv\")\ntripdata_2021_02 = pd.read_csv(\"\/kaggle\/input\/cyclist\/202102-divvy-tripdata.csv\")\ntripdata_2021_03 = pd.read_csv(\"\/kaggle\/input\/cyclist\/202103-divvy-tripdata.csv\")","be50f70c":"# Concatenating all the data from 04-2020 to 11-2020\ntripdata_withDoubles = pd.concat([tripdata_2020_04,tripdata_2020_05,tripdata_2020_06,tripdata_2020_07,tripdata_2020_08,tripdata_2020_09,tripdata_2020_10,tripdata_2020_11], ignore_index = True)\n\n# Changing the datatype of start_station_id and end_station_id to match the dataset from 12-2020 to 03-2021\ntripdata_withDoubles.start_station_id = tripdata_withDoubles.start_station_id.astype(object)\ntripdata_withDoubles.end_station_id = tripdata_withDoubles.end_station_id.astype(object)\n\n# Concatenating data from 12-2020 to 03-2021\ntripdata_withChar = pd.concat([tripdata_2020_12,tripdata_2021_01,tripdata_2021_02,tripdata_2021_03], ignore_index=True)\n\n# Concatenating all datasets\ntripdata = pd.concat([tripdata_withDoubles,tripdata_withChar], ignore_index=True)","94f9a04d":"# Exploring Dataset:\ntripdata.head()","2810adbb":"# Exploring Dataset:\ntripdata.describe()","69a2761f":"# Dropping all NA values\ntripdataClean = tripdata.dropna()","17318c20":"print(tripdataClean.isnull().sum())","d71e0389":"# Separating dates into day, month, year and day of the week:\ntripdataClean['date'] = pd.to_datetime(tripdataClean['started_at']).dt.date\ntripdataClean['start_time'] = pd.to_datetime(tripdataClean['started_at']).dt.time\ntripdataClean['end_time'] = pd.to_datetime(tripdataClean['ended_at']).dt.time\ntripdataClean['date'] = pd.to_datetime(tripdataClean['date'])\n\ntripdataClean['year'] = tripdataClean['date'].dt.year\ntripdataClean['month'] = tripdataClean['date'].dt.month\ntripdataClean['day'] = tripdataClean['date'].dt.day","3adf3426":"# Calculating Ride Duration in seconds:\ntripdataClean['started_at'] = pd.to_datetime(tripdataClean['started_at'])\ntripdataClean['ended_at'] = pd.to_datetime(tripdataClean['ended_at'])\n\nrideduration = tripdataClean['ended_at']-tripdataClean['started_at'] \ntripdataClean['ride_duration'] = ((rideduration)\/1000000000).astype(int)","945bceff":"# Calculating distance travelled in km:\nwsg84 = Geod(ellps='WGS84')\n# numpy matrix of the lon \/ lat columns, iterable in column order\nor_and_new = tripdataClean[['start_lng', 'start_lat', 'end_lng', 'end_lat']].to_numpy().T\ntripdataClean['ride_distance'] = wsg84.inv(*or_and_new)[-1] \/ 1000  # as km","dbfb7245":"tripdataClean.dtypes","6fd8dde4":"pd.set_option(\"display.max_columns\", None)\ntripdataClean.head()","2f90e9fb":"tripdataClean['weekday'] = tripdataClean['date'].dt.day_name()","9fe135d0":"tripdataClean.head()","6d03bf05":"# Calculating average time:\nmemberGroup_meanTime = tripdataClean.groupby('member_casual').agg({'ride_duration': ['mean']})\nprint(memberGroup_meanTime)","e20dbdbd":"# Calculating average time:\nmemberGroup_meanDistance = tripdataClean.groupby('member_casual').agg({'ride_distance': ['mean']})\nprint(memberGroup_meanDistance)","770db310":"# Plot the charts using Seaborn's countplot()\n\n# AS 2 separate plots side by side\nfig, ax = plt.subplots(1,2)\nsns.set(rc={'figure.figsize':(25,10)})\nax1 = sns.countplot(data=memberGroup_meanTime, ax=ax[0])\nax2 = sns.countplot(data=memberGroup_meanDistance, ax=ax[1])\n\nax1.set_title(\"Casual\", fontsize=30)\nax1.set_xlabel(\"Days of the Week\", fontsize=40)\nax2.set_title(\"Member\", fontsize=30)\nax2.set_xlabel(\"Days of the Week\", fontsize=40)\nax1.tick_params(axis='both', which='both', labelsize=20) # x\/y axes, minor\/major ticks for ax1\nax2.tick_params(axis='both', which='both', labelsize=20) # x\/y axes, minor\/major ticks for ax2","2c43f066":"member = tripdataClean[tripdataClean['member_casual'] == 'member']\ncasual = tripdataClean[tripdataClean['member_casual'] == 'casual']\n# Plot the charts using Seaborn's countplot()\n\n# AS 2 separate plots side by side\nfig, ax = plt.subplots(1,2)\nsns.set(rc={'figure.figsize':(25,10)})\nax1 = sns.countplot(x=\"weekday\", data=casual, ax=ax[0])\nax2 = sns.countplot(x=\"weekday\", data=member, ax=ax[1])\n\nax1.set_title(\"Casual\", fontsize=30)\nax1.set_xlabel(\"Days of the Week\", fontsize=40)\nax2.set_title(\"Member\", fontsize=30)\nax2.set_xlabel(\"Days of the Week\", fontsize=40)\nax1.tick_params(axis='both', which='both', labelsize=15) # x\/y axes, minor\/major ticks for ax1\nax2.tick_params(axis='both', which='both', labelsize=15) # x\/y axes, minor\/major ticks for ax2","75ea6ed4":"tripdataClean.dtypes","cf951ea5":"classic = tripdataClean[tripdataClean['rideable_type'] == 'classic_bike']\nelectric = tripdataClean[tripdataClean['rideable_type'] == 'electric_bike']","56730749":"# Plot the charts using Seaborn's countplot()\n\n# AS 2 separate plots side by side\nfig, ax = plt.subplots(1,2)\nsns.set(rc={'figure.figsize':(25,10)})\nax1 = sns.countplot(x=\"member_casual\", data=classic, ax=ax[0]) # Retained dataset\nax2 = sns.countplot(x=\"member_casual\", data=electric, ax=ax[1]) # Attrited dataset\n\nax1.set_title(\"classic\", fontsize=30)\nax1.set_xlabel(\"User Type\", fontsize=40)\nax2.set_title(\"electric\", fontsize=30)\nax2.set_xlabel(\"User Type\", fontsize=40)\nax1.tick_params(axis='both', which='both', labelsize=20) # x\/y axes, minor\/major ticks for ax1\nax2.tick_params(axis='both', which='both', labelsize=20) # x\/y axes, minor\/major ticks for ax2","fa93a4ac":"member = tripdataClean[tripdataClean['member_casual'] == 'member']\ncasual = tripdataClean[tripdataClean['member_casual'] == 'casual']\n# Plot the charts using Seaborn's countplot()\n\n# AS 2 separate plots side by side\nfig, ax = plt.subplots(1,2)\nsns.set(rc={'figure.figsize':(25,10)})\nax1 = sns.countplot(x=\"weekday\", data=classic, ax=ax[0])\nax2 = sns.countplot(x=\"weekday\", data=electric, ax=ax[1])\n\nax1.set_title(\"Casual\", fontsize=30)\nax1.set_xlabel(\"Days of the Week\", fontsize=40)\nax2.set_title(\"Member\", fontsize=30)\nax2.set_xlabel(\"Days of the Week\", fontsize=40)\nax1.tick_params(axis='both', which='both', labelsize=15) # x\/y axes, minor\/major ticks for ax1\nax2.tick_params(axis='both', which='both', labelsize=15) # x\/y axes, minor\/major ticks for ax2","71026f1f":"# Exploring Data","6782c222":"## PHASE 4 : Analyze\n\n### Key objectives:\n\n**1.Identify trends and relationships.:**\n\n* We have now a complete data frame with all the info we need to identify the differences in behaviour between the casual and the member users.","458407bd":"## PHASE 2 : Prepare\n\n### Key objectives:\n\n**1.Determine the credibility of the data:**\n\n* The data is public data from a bike sharing company. It starts from the year 2013 until 2021 (three months), there isn't much of a naming convention as the files are sometimes organized by quarter, or month, or the whole year and their names vary a lot. The naming of the columns also changes and there are some columns added and deleted over the years. Nevertheless the data seems to be in good condition and its first hand data collected by the company itself with lots of entries and with lots of useful data.\n\n**2.Sort and filter the data:**\n\n* For this analysis I'm going to focus on the 2020-2021 period as it's the more relevant period to the business task and it has the more complete data with geo-location coordinates, and types of bike used.","6dacfa1e":"# Cleaning Data","cbececcd":"### Analysis:\n\n* It seems that the casual users travel the same average distance than the member users, but they have much longer rides, that would indicate a more leisure oriented usage vs a more \"public transport\" or pragmatic use of the bikes by the annual members.\n\n* This idea is reinforced by the fact that annual users have a very stable use of the service during the week, but the casual users are more of a weekend user. ","464b6411":"## PHASE 3 : Process\n\n### Key objectives:\n\n**1.Clean the data, and prepare the data for analysis:**\n\n* Now that we have all the data in one place we can start to clean the data of possible errors like NA. Also we will make some changes to the data adding useful new columns based on calculations of already existing columns in order to facilitate our analysis and arrive at more insightful conclusions.","9b7a3ac3":"<center><h2>The mission statement<\/h2><\/center> \n\n<center><h4>How do annual members and casual riders use Cyclistic bikes differently? Find out how the two groups of user look at the service and how their user behaviour differ based on different factors.<\/h4><\/center> ","112f3fab":"## PHASE 1 : ASK\n### Key objectives:\n\n**1.Identify the business task:**\n\n* Cyclist has identified that annual customers are more profitable than casual members, and so they want to maximise their profit by turning their casual customers into annual customers by creating a marketing strategy aimed at casual members.\n\n**2.Consider key stakeholders:**\n\n* The main stakeholders here are the director of marketing and my manager Lily Moreno, the rest of the marketing analytics team, and the Cyclistic executive team.\n\n**3.The business task:**\n\nGiven these facts, the business task is defined as searching for differences in the two identified kinds of users in order to make a focused marketing campaign to the \u201ccasual\u201d users in order for them to change to the annual subscription, or resumed in a question:\n\n**What could motivate the \u201ccasual\u201d users to change to an annual subscription based on their behavior**","4f5fcdf3":"### Analysis:\n\n* Here we can see that the annual members use both types of bikes for their rides, but the casual users show a clear preference for the electric bikes, which makes sense given the long duration of their rides.\n\n* On a weekly basis we can see that for the annual members there is a small difference of usage between the start of the week, where they prefer the classic bike and the end of the week, where they use more electric bikes.\n\n* For the casual users we see in general the same pattern of usage from the previous weekly charts, preferring the electric vs the classic bikes and having a weekend usage of the service.","b6d5f94b":"## PHASE 5 : Share\n\n### Key objectives:\n\n**1.Share my conclusions.:**\n\n* Taking in consideration both the business task: **What will encourage the casual members to change to an annual subscription based on their behaviour** and the insights we've learned from the available data we can make some conclusions.\n    \n    1)*The Casual users have leisure, and tourism rides mostly on weekends and using electric bikes*.\n    \n    2)*The Annual users have commute or pragmatic rides, during all week using both electric & classic bikes*\n    \n* I would share this info, the data and my analysis to the marketing team, and I would suggest that in order to convert the casual to the annual users it would be interesting to focus the messages on the leisure aspect of the service, and maybe offer some kind of promotion related to weekends and\/or electric bikes*."}}