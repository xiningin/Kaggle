{"cell_type":{"7e050d74":"code","f33c78d8":"code","501d636c":"code","6037c00b":"code","bc8a7311":"code","4122642e":"code","ba3760fd":"code","8d736649":"code","d41ede05":"code","7c57e196":"code","7a0b9f86":"code","6e21d7a4":"code","1a2b8f7d":"code","542651aa":"code","4eba2782":"code","7d10e6ea":"code","6c528d09":"code","9809caa1":"code","d7b75f7c":"code","08a61b73":"code","d394795c":"code","855ea372":"code","6fcbbf0f":"code","72a6c368":"code","cb0323ac":"code","c9c414d1":"code","2f7b7100":"code","51d78d6e":"markdown","326f5576":"markdown","a4a419cf":"markdown"},"source":{"7e050d74":"import os\nimport cv2\nimport torch\nimport pandas as pd\nimport numpy as np\nimport glob\nimport gc\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset\nfrom albumentations import (Normalize, Resize, Compose)\n#from albumentations.torch import ToTensor\nfrom albumentations.pytorch.transforms import ToTensor\nimport torch.utils.data as data\nimport torchvision.models as models\nimport torch.nn as nn\nfrom torch.nn import functional as F","f33c78d8":"class SteelDataset(Dataset):\n    def __init__(self, df, augment=None):\n\n        \n        df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n        self.fnames = df['ImageId'].unique().tolist()\n        \n\n    def __len__(self):\n        return len(self.fnames)\n\n\n    def __getitem__(self, index):\n        image_id = self.fnames[index]\n        image = cv2.imread(test_data_folder + '\/%s'%(image_id), cv2.IMREAD_COLOR)\n        return image_id, image\n    ","501d636c":"!ls ..\/input","6037c00b":"sample_submission_path = '..\/input\/severstal-steel-defect-detection\/sample_submission.csv'\ntest_data_folder = \"..\/input\/severstal-steel-defect-detection\/test_images\"","bc8a7311":"def null_collate(batch):\n    batch_size = len(batch)\n\n    input = []\n    infor = []\n    for b in range(batch_size):\n        input.append(batch[b][1])\n        infor.append(batch[b][0])\n\n    input = np.stack(input).astype(np.float32)\/255\n    input = input.transpose(0,3,1,2)\n    \n    input = torch.from_numpy(input).float()\n    \n    return infor, input","4122642e":"df = pd.read_csv(sample_submission_path)\ntest_dataset = SteelDataset(df)\n\ntest_loader = DataLoader(\n            test_dataset,\n            batch_size  = 2,\n            drop_last   = False,\n            num_workers = 0,\n            pin_memory  = True,\n            collate_fn  = null_collate\n    )","ba3760fd":"\n#test time augmentation  -----------------------\ndef null_augment   (input): return input\ndef flip_lr_augment(input): return torch.flip(input, dims=[2])\ndef flip_ud_augment(input): return torch.flip(input, dims=[3])\n\ndef null_inverse_augment   (logit): return logit\ndef flip_lr_inverse_augment(logit): return torch.flip(logit, dims=[2])\ndef flip_ud_inverse_augment(logit): return torch.flip(logit, dims=[3])\n\naugment = (\n        (null_augment,   null_inverse_augment   ),\n        (flip_lr_augment,flip_lr_inverse_augment),\n        (flip_ud_augment,flip_ud_inverse_augment),\n    )\n","8d736649":"TEMPERATE=0.5\n######################################################################################\ndef probability_mask_to_probability_label(probability):\n    batch_size,num_class,H,W = probability.shape\n    probability = probability.permute(0, 2, 3, 1).contiguous().view(batch_size,-1, 5)\n    value, index = probability.max(1)\n    probability = value[:,1:]\n    return probability\n\n\ndef remove_small_one(predict, min_size):\n    H,W = predict.shape\n    num_component, component = cv2.connectedComponents(predict.astype(np.uint8))\n    predict = np.zeros((H,W), np.bool)\n    for c in range(1,num_component):\n        p = (component==c)\n        if p.sum()>min_size:\n            predict[p] = True\n    return predict\n\ndef remove_small(predict, min_size):\n    for b in range(len(predict)):\n        for c in range(4):\n            predict[b,c] = remove_small_one(predict[b,c], min_size[c])\n    return predict\n","d41ede05":"def do_evaluate_segmentation(net, test_loader, augment=[]):\n\n    #----\n\n    #def sharpen(p,t=0):\n    def sharpen(p,t=TEMPERATE):\n        if t!=0:\n            return p**t\n        else:\n            return p\n\n\n    test_num  = 0\n    test_id   = []\n    #test_image = []\n    test_probability_label = [] # 8bit\n    test_probability_mask  = [] # 8bit\n    test_truth_label = []\n    test_truth_mask  = []\n\n    #start = timer()\n    for t, (fnames, input) in enumerate(tqdm(test_loader)):\n\n        batch_size,C,H,W = input.shape\n        input = input.cuda()\n\n        with torch.no_grad():\n            net.eval()\n\n            num_augment = 0\n            if 1: #  null\n                logit =  net(input)\n                probability = torch.softmax(logit,1)\n\n                probability_mask = sharpen(probability,0)\n                num_augment+=1\n\n            if 'flip_lr' in augment:\n                logit = net(torch.flip(input,dims=[3]))\n                probability  = torch.softmax(torch.flip(logit,dims=[3]),1)\n\n                probability_mask += sharpen(probability)\n                num_augment+=1\n\n            if 'flip_ud' in augment:\n                logit = net(torch.flip(input,dims=[2]))\n                probability = torch.softmax(torch.flip(logit,dims=[2]),1)\n\n                probability_mask += sharpen(probability)\n                num_augment+=1\n\n            #---\n            probability_mask = probability_mask\/num_augment\n            probability_label = probability_mask_to_probability_label(probability_mask)\n\n        probability_mask = (probability_mask.data.cpu().numpy()*255).astype(np.uint8)\n        probability_label = (probability_label.data.cpu().numpy()*255).astype(np.uint8)\n\n        test_id.extend([i for i in fnames])\n\n        test_probability_mask.append(probability_mask)\n        test_probability_label.append(probability_label)\n        \n    test_probability_mask = np.concatenate(test_probability_mask)\n    test_probability_label = np.concatenate(test_probability_label)\n    \n    \n    return test_probability_label, test_probability_mask, test_id\n","7c57e196":"!ls ..\/input\/henge5","7a0b9f86":"ckpt_file = '..\/input\/henge5\/trace_model_swa.pth'\nnet = torch.jit.load(ckpt_file).cuda()\n","6e21d7a4":"probability_label, probability_mask, image_id = do_evaluate_segmentation(net, test_loader, augment=['null'])","1a2b8f7d":"del net\ngc.collect()","542651aa":"#value = np.max(probability_mask,1,keepdims=True)\n#value = probability_mask*(value==probability_mask)\nprobability_mask = probability_mask[:,1:] #remove background class\n","4eba2782":"#threshold_label      = [ 0.70, 0.8, 0.50, 0.70,]\n#threshold_mask_pixel = [ 0.6, 0.8, 0.5, 0.6,]\n#threshold_mask_size  = [ 1,  1,  1,  1,]\n\nthreshold_label = [0.75, 0.75, 0.5, 0.5]\nthreshold_mask_pixel = [0.4, 0.4, 0.4, 0.4]\nthreshold_mask_size  = [1, 1, 1, 1]","7d10e6ea":"predict_label = probability_label>(np.array(threshold_label)*255).astype(np.uint8).reshape(1,4)\npredict_mask  = probability_mask>(np.array(threshold_mask_pixel)*255).astype(np.uint8).reshape(1,4,1,1)","6c528d09":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","9809caa1":"image_id_class_id = []\nencoded_pixel = []\nfor b in range(len(image_id)):\n    for c in range(4):\n        image_id_class_id.append(image_id[b]+'_%d'%(c+1))\n\n        if predict_label[b,c]==0:\n            rle=''\n        else:\n            rle = mask2rle(predict_mask[b,c])\n        encoded_pixel.append(rle)","d7b75f7c":"df = pd.DataFrame(zip(image_id_class_id, encoded_pixel), columns=['ImageId_ClassId', 'EncodedPixels'])\n#df.to_csv('submission.csv', index=False)","08a61b73":"df.head()","d394795c":"df_mask = df.copy()","855ea372":"submission = pd.read_csv('..\/input\/severstal-steel-defect-detection\/sample_submission.csv')\nsubmission.fillna('',inplace=True)\nsubmission.set_index('ImageId_ClassId', inplace=True)\n\ndf_mask.set_index('ImageId_ClassId', inplace=True)\n\nfor name, row in df_mask.iterrows():\n    submission.loc[name] = row\n\nsubmission.reset_index(inplace=True)\nsubmission.to_csv('submission.csv', index=False)","6fcbbf0f":"submission.head()","72a6c368":"\ndef summarise_submission_csv(df):\n\n\n    text = ''\n    df['Class'] = df['ImageId_ClassId'].str[-1].astype(np.int32)\n    df['Label'] = (df['EncodedPixels']!='').astype(np.int32)\n    num_image = len(df)\/\/4\n    num = len(df)\n\n    pos = (df['Label']==1).sum()\n    neg = num-pos\n\n\n    pos1 = ((df['Class']==1) & (df['Label']==1)).sum()\n    pos2 = ((df['Class']==2) & (df['Label']==1)).sum()\n    pos3 = ((df['Class']==3) & (df['Label']==1)).sum()\n    pos4 = ((df['Class']==4) & (df['Label']==1)).sum()\n\n    neg1 = num_image-pos1\n    neg2 = num_image-pos2\n    neg3 = num_image-pos3\n    neg4 = num_image-pos4\n\n\n    text += 'compare with LB probing ... \\n'\n    text += '\\t\\tnum_image = %5d(1801) \\n'%num_image\n    text += '\\t\\tnum  = %5d(7204) \\n'%num\n    text += '\\n'\n\n    text += '\\t\\tpos1 = %5d( 128)  %0.3f\\n'%(pos1,pos1\/128)\n    text += '\\t\\tpos2 = %5d(  43)  %0.3f\\n'%(pos2,pos2\/43)\n    text += '\\t\\tpos3 = %5d( 741)  %0.3f\\n'%(pos3,pos3\/741)\n    text += '\\t\\tpos4 = %5d( 120)  %0.3f\\n'%(pos4,pos4\/120)\n    text += '\\n'\n\n    text += '\\t\\tneg1 = %5d(1673)  %0.3f  %3d\\n'%(neg1,neg1\/1673, neg1-1673)\n    text += '\\t\\tneg2 = %5d(1758)  %0.3f  %3d\\n'%(neg2,neg2\/1758, neg2-1758)\n    text += '\\t\\tneg3 = %5d(1060)  %0.3f  %3d\\n'%(neg3,neg3\/1060, neg3-1060)\n    text += '\\t\\tneg4 = %5d(1681)  %0.3f  %3d\\n'%(neg4,neg4\/1681, neg4-1681)\n    text += '--------------------------------------------------\\n'\n    text += '\\t\\tneg  = %5d(6172)  %0.3f  %3d \\n'%(neg,neg\/6172, neg-6172)\n    text += '\\n'\n\n    if 1:\n        #compare with reference\n        pass\n\n    return text\n","cb0323ac":"## print statistics ----\ntext = summarise_submission_csv(df)\nprint(text)\n","c9c414d1":" def rle2mask(mask_rle, shape=(1600,256)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T","2f7b7100":"%matplotlib inline\n\ndf = pd.read_csv('submission.csv')[:60]\ndf['Image'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[0])\ndf['Class'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[1])\n\nfor row in df.itertuples():\n    img_path = os.path.join(test_data_folder, row.Image)\n    img = cv2.imread(img_path)\n    mask = rle2mask(row.EncodedPixels, (1600, 256)) \\\n        if isinstance(row.EncodedPixels, str) else np.zeros((256, 1600))\n    if mask.sum() == 0:\n        continue\n    \n    fig, axes = plt.subplots(1, 2, figsize=(20, 60))\n    axes[0].imshow(img\/255)\n    axes[1].imshow(mask*60)\n    axes[0].set_title(row.Image)\n    axes[1].set_title(row.Class)\n    plt.show()","51d78d6e":"The results are extremely sensitive to the thresholds. So play with the thresholds and see the change on LB. You can also try adding Test time Augmentation(TTA) and see if it performs better on LB. Good luck and Happy Kaggling","326f5576":"This is an inference kernel of [this](https:\/\/www.kaggle.com\/c\/severstal-steel-defect-detection\/discussion\/111457#latest-647456) discussion. I followed Heng's steps and tried to replicate his results. I trained the model for around 18 hours and this kernel does the inference of that model. This kernel successfully commits but when I submit I get `Kaggle Error`. See version4 of this kernel.Maybe I am missing something; hopefully you can correct it, which is why I am opensourcing the trained model for you to experiment. The trained model is a traced version, which means you can load it by simply `model = torch.jit.load(ckpt).cuda()`","a4a419cf":"**Difference with the [original kernel](http:\/\/www.kaggle.com\/bibek777\/heng-s-model-unet-efficientnet-b5) is that there is no error with submission file created here.**\n\nAs I stated in the comment section of the version of Bibek's kernel (https:\/\/www.kaggle.com\/bibek777\/heng-s-model-unet-efficientnet-b5) I was able to make a submission of the result in version-2 of this kernel and scored zero on the public LB. \n\nI have changed the thresholds to Heng's values in this version-4 of the kernel."}}