{"cell_type":{"c1ffbd4c":"code","a7d4106c":"code","fa83de9e":"code","b6a10a6b":"code","de1e923c":"code","6caa0fff":"code","59c70ea7":"code","88ddc7d8":"code","2cc587d6":"code","d28005fd":"code","df911ff3":"code","ce739727":"code","652431dd":"code","33e374a8":"code","c0e8b550":"code","bcd5aa0a":"code","da1372cf":"code","d92a4e82":"code","47f74050":"code","53a9d9ef":"code","c608d385":"code","f0fc160e":"code","f40031e7":"code","7066fa57":"code","f8bd39f5":"code","a5455b21":"markdown","f5bef0fa":"markdown","f853d2e1":"markdown","fb5cd0f4":"markdown","73992ea8":"markdown","9c06688c":"markdown","999a9a07":"markdown","a599da3e":"markdown","d8131bda":"markdown","8501246b":"markdown","5bed6128":"markdown","ac10b814":"markdown"},"source":{"c1ffbd4c":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', 25)","a7d4106c":"# Read dataset from csv file. Dropped last two columns and first column which is client number. \n\nheaders=pd.read_csv(\"..\/input\/credit-card-customers\/BankChurners.csv\",nrows=1)\ndf1=pd.read_csv(\"..\/input\/credit-card-customers\/BankChurners.csv\",usecols=headers.iloc[:,1:-2].columns)\ndf1.head()","fa83de9e":"# Checking dtypes and missing values\n\ndf1.info()","b6a10a6b":"# Checking basic descriptive statistics for numeric and categorical variables.\n\ndf1.describe(include=\"all\").T.sort_values(by=[\"unique\"])","de1e923c":"#Creating a Churn feature that depends on Attrition_Flag values  \n#Removed Attrition_Flag feature\n\ndf1.loc[:,'Churn'] = np.where((df1['Attrition_Flag'] == 'Attrited Customer'),\"1\",\"0\")\ndf1.drop(\"Attrition_Flag\",axis=1,inplace=True)\ndf1.head()","6caa0fff":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.style.use(\"tableau-colorblind10\") ","59c70ea7":"# Split the dataset 2 parts that categorical and numerical\n\ncat_col=list(df1.select_dtypes(include=\"object\").columns)\nnum_col=list(df1.select_dtypes(exclude=\"object\").columns)\nprint(\"Categorical Features:\",cat_col,sep=\"\\n\\n\")\nprint(\"\")\nprint(\"Numerical Features:\",num_col,sep=\"\\n\\n\")","88ddc7d8":"def countplot_categorical(cats,data):\n    \n    fig, axes = plt.subplots(2,3, figsize=(22, 16))\n    axes = axes.flatten()\n    fig.suptitle('Categorical Features Distributions',fontsize=30)\n\n    for ax, cat in zip(axes, cats):\n        total = float(len(data[cat]))\n        sns.countplot(data[cat], palette='rocket', ax=ax)\n\n        for p in ax.patches:\n            height = p.get_height()\n            ax.text(p.get_x() + p.get_width() \/ 2.,\n                    height + 10,\n                    '{:1.2f}%'.format((height \/ total) * 100),\n                    ha=\"center\")\n        \n        ax.set_xticklabels(ax.get_xticklabels(),rotation=20)\n        plt.ylabel('Count', fontsize=15, weight='bold')","2cc587d6":" countplot_categorical(cat_col, df1)","d28005fd":"def countplot_churn(cats, data):\n    \n    \n    fig, axes = plt.subplots(2, 3, figsize=(22, 16))\n    axes = axes.flatten()\n    fig.suptitle('Categorical Features Distributions by Churn',fontsize=30)\n    \n    for ax, cat in zip(axes, cats):\n        if cat == 'Churn':\n            sns.countplot(data[cat], palette='rocket', ax=ax)\n\n        else:\n\n            sns.countplot(x=cat,\n                          data=data,\n                          hue='Churn',\n                          palette='rocket',\n                          ax=ax)\n            ax.legend(title='Churn',\n                      loc='upper right',\n                      labels=['No', 'Yes'])\n            \n        ax.set_xticklabels(ax.get_xticklabels(),rotation=20)\n        plt.ylabel('Count', fontsize=15, weight='bold')","df911ff3":"countplot_churn(cat_col, df1)","ce739727":"# Creating a new copy for variable transformations. \n\ndf2 = df1.copy()\n\n# Transform nominal to ordinal\n\ndf2[\"Education_Level_Ord\"]=df2['Education_Level'].replace({\"Unknown\": 0,\n                                                           \"Uneducated\":1,\n                                                           \"High School\":2,\n                                                           \"College\":3,\n                                                           \"Graduate\":4,\n                                                           \"Post-Graduate\":5,\n                                                           \"Doctorate\":6})\n\ndf2[\"Income_Category_Ord\"]=df2['Income_Category'].replace({\"Unknown\": 0,\n                                                           \"Less than $40K\":1,\n                                                           \"$40K - $60K\":2,\n                                                           \"$60K - $80K\":3,\n                                                           \"$80K - $120K\":4,\n                                                           \"$120K +\":5})\n\ndf2.drop([\"Education_Level\",\"Income_Category\"],axis=1,inplace=True)\ndf2[\"Churn\"]=df2[\"Churn\"].astype('int64')","652431dd":"def kdeplot_churn(nums, data):   \n    \n    fig, axes = plt.subplots(7, 2, figsize=(25, 18))\n    axes = axes.flatten()\n    fig.suptitle('Numerical Features Distributions by Churn',fontsize=30)\n    \n    for ax, num in zip(axes, nums):\n        sns.distplot(df2.loc[:, num][(df2[\"Churn\"] == 0)],hist=False,kde=True,color=\"Blue\",ax=ax,label=\"No\")\n        sns.distplot(df2.loc[:, num][(df2[\"Churn\"] == 1) ],hist=False,kde=True,color=\"Red\",ax=ax,label=\"Yes\")\n        ax.legend(title='Churn',loc='upper right')\n        ax.set_xticklabels(ax.get_xticklabels(),rotation=20)","33e374a8":"kdeplot_churn(num_col,df2)","c0e8b550":"def boxplot_churn(nums, data):   \n    \n    fig, axes = plt.subplots(7, 2, figsize=(14,22))\n    axes = axes.flatten()\n    fig.suptitle('Box Plots for Numerical Features',fontsize=30)\n    \n    for ax, num in zip(axes, nums):\n        sns.boxplot(y=num,data=data,ax=ax,color='#e74c3c')","bcd5aa0a":"boxplot_churn(num_col,df2)","da1372cf":"# Creating a new copy for variable transformations. \n\ndf3 = df2.copy()\n\n# Discretization\ndf3[\"Total_Amt_Chng_Q4_Q1_qcut\"]=pd.qcut(df3[\"Total_Amt_Chng_Q4_Q1\"],4)\ndf3[\"Total_Trans_Amt_qcut\"]=pd.qcut(df3[\"Total_Trans_Amt\"],4)\ndf3[\"Total_Ct_Chng_Q4_Q1_qcut\"]=pd.qcut(df3[\"Total_Ct_Chng_Q4_Q1\"],4)\n\n\ndf3.drop([\"Customer_Age\",\"Months_on_book\",\n          \"Credit_Limit\",\"Avg_Open_To_Buy\",\n          \"Total_Amt_Chng_Q4_Q1\",\"Total_Trans_Amt\",\n          \"Total_Ct_Chng_Q4_Q1\"],axis=1,inplace=True)\n","d92a4e82":"df4 = pd.get_dummies(df3)\n\ndf4.head()","47f74050":"fig, ax = plt.subplots(figsize=(10,10))\nfig.suptitle('Correlation between Churn and features',fontsize=20)\nax=sns.heatmap(df4.corr()[[\"Churn\"]].sort_values(\"Churn\"),vmax=1, vmin=-1, cmap=\"YlGnBu\", annot=True, ax=ax);\nax.invert_yaxis()","53a9d9ef":"# Drop some features which have less than 0.01 correlation and greater than -0.01 correlation.\n\ndf5=df4.copy()\nthreshold=0.01\nchurn_corr=df5.corr()[[\"Churn\"]].sort_values(\"Churn\")\ncorr_drop=list(churn_corr[(churn_corr[\"Churn\"]< threshold)& (churn_corr[\"Churn\"]>-threshold)].index)\ndf5.drop(corr_drop,axis=1,inplace=True)\n\ndf5.info()","c608d385":"from sklearn.model_selection import train_test_split,cross_val_predict,StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report,roc_auc_score,roc_curve\nfrom imblearn.pipeline import Pipeline as imbPipe\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.neighbors import KNeighborsClassifier","f0fc160e":"X=df5.drop(\"Churn\",axis=1)\ny=df5[\"Churn\"]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,shuffle=True, stratify = y)","f40031e7":"dct = DecisionTreeClassifier(random_state=42)\nsgd = SGDClassifier(random_state=42)\nlog = LogisticRegression(random_state=42)\nsvm_rbf = SVC(kernel=\"rbf\", random_state=42)\nsvm_lin = LinearSVC(loss=\"hinge\")\nknn=KNeighborsClassifier()\n\nkfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n\n\nVoting_pipeline = imbPipe([\n    \n    (\"scaler\", StandardScaler()),\n    (\"smote\", SMOTE(random_state=42,n_jobs=-1)),\n    (\"voting\", VotingClassifier(estimators=[(\"dct\", dct),\n                                            (\"sgd\", sgd),\n                                            (\"svm_rbf\", svm_rbf),\n                                            (\"smv_lin\", svm_lin),\n                                            (\"knn\",knn),\n                                            (\"log\", log)],voting=\"hard\",n_jobs=-1))\n])\n\n\ny_pred = cross_val_predict(Voting_pipeline, X_train, y_train, cv = kfold)\nprint(classification_report(y_train, y_pred))\n","7066fa57":"Voting_pipeline.fit(X_train, y_train)\ny_pred=Voting_pipeline.predict(X_test)  \nprint(classification_report(y_test, y_pred))","f8bd39f5":"fpr, tpr, thresholds =roc_curve(y_test, y_pred, pos_label=1)\nroc_auc=roc_auc_score(y_test, y_pred)\nplt.figure( figsize=(14,6))\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (AUC = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy',linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC curve')\nplt.legend(loc=\"lower right\")\nplt.show()","a5455b21":"# Feature Engineering for Numerical Variables","f5bef0fa":"# Test Results","f853d2e1":"# Modelling","fb5cd0f4":"> No missing values in dataset. There are 6 categorical and 14 numeric features.","73992ea8":"# Numerical Features","9c06688c":"> Some observations from the charts:\n\n> * Features that have similar distribution for both churn and not churn such as \"Customer age, Months on book etc.\" are removed.\n> * Customers who have lower \"Total_Trans_Ct\" tend to Churn\n> * Customers who have lower \"Total_Trans_Amt\" tend to Churn\n> * Total Relationship Count's churn rate is decreasing after 3.\n> * Total_Amt_Chng_Q4_Q1,Total_Trans_Amt and Total_Ct_Chng_Q4_Q1 features have lots of outliers so i'll transform them to categorical variables using qcut function.(Quantile-based discretization function)","999a9a07":"# Training Hard Voting Classifier","a599da3e":"> **Some observations from the table:**\n> \n> * Majority of clients are married.\n> * Almost all clients have Blue Card (~%93)\n> * Income Category is dominated by \"who has Less than 40K\"\n> * Avg customer age is 46, min age is 26 and max age is 73\n> * Credit card limits are between 1.438 and 34.516\n> * Although min Avg_Open_To_Buy is 3, max value is 34.516. There is a big gap between max and min values. This situation strengthens the presence of outliers.","d8131bda":"# Categorical Features","8501246b":"> Some observations from the charts:\n\n> * Educational Level and Income Category will be transformed to ordinal variables.\n> * Other categorical variables are nominal so i can use \"get_dummies\".\n> * It looks like that churn rate is higher for \"single marital status\" than \"other marital status\".\n> * %16 churn ratio means that the dataset is imbalanced  so i have to use oversampling  or undersampling  methods for better accuracy.","5bed6128":"# Feature Engineering for Categorical Variables","ac10b814":"# Exploratory Data Analysis"}}