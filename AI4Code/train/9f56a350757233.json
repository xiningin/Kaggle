{"cell_type":{"846eba5c":"code","347c33f5":"code","0733bf7d":"code","29c3afce":"code","797e2245":"code","7ce964c6":"code","27db3532":"code","ba83cf34":"code","c5a6b3d3":"code","72ddefe7":"code","f66c4c24":"code","46254fea":"code","4a466dec":"markdown","17474f4d":"markdown","d6104e97":"markdown","acb2d561":"markdown","5c36fe11":"markdown","235d8ae1":"markdown"},"source":{"846eba5c":"# Import Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import linear_model","347c33f5":"# Import Data\ndf = pd.read_csv(\"..\/input\/mushroom-classification\/mushrooms.csv\")\nprint('Shape of dataset= ', df.shape) # Numer of rows and columns\ndf.head(5) # first 5 data","0733bf7d":"# Data type\ndf.info()","29c3afce":"# Missing value check\ndf.isna().sum() # Get number of missing value from each column","797e2245":"# Frequency Tables\nfor col in df.columns:\n    print('-' * 40 + col + '-' * 40 )\n    #print(pd.DataFrame(df[col].value_counts()))\n    print(df[col].value_counts())","7ce964c6":"# Histogram\ndf = df.drop('veil-type', axis=1)\ndf2 = df.melt(value_vars=df.columns)\ng = sns.FacetGrid(df2, col=\"variable\", col_wrap=6)\ng = g.map(sns.countplot, \"value\")","27db3532":"from sklearn.preprocessing import LabelEncoder\ndf3 = pd.DataFrame()\nfor i in df.columns:\n    enc = LabelEncoder()\n    df3[i] = enc.fit_transform(df[i]) \nprint(df3.head(3))","ba83cf34":"#Correlation Matrix - Upper Diagonal\nimport seaborn as sn\ncorrMatrix = df3.corr()\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corrMatrix, dtype=np.bool))\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 20, sep=20,as_cmap=True)\n\nsn.heatmap(corrMatrix, mask=mask, cmap=cmap)\nplt.show()","c5a6b3d3":"#Split dataset & Standardize data\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nX = df3.drop('class', axis=1)\ny = df3['class']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)","72ddefe7":"#Model Selection Using Grid Search\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\npipe = Pipeline([('classifier' , LogisticRegression())])\n\n# Create param grid.\nparam_grid = [\n    {'classifier' : [LogisticRegression()],\n     'classifier__penalty' : ['l1', 'l2'],\n    'classifier__C' : np.logspace(-4, 4, 20),\n    'classifier__solver' : ['liblinear']},\n    {'classifier' : [RandomForestClassifier()],\n    'classifier__n_estimators' : list(range(10,101,10)),\n    'classifier__max_features' : list(range(6,32,5))},\n    {'classifier' : [DecisionTreeClassifier()],\n    'classifier__criterion' : ['gini','entropy'],\n    'classifier__max_depth' : list(range(4,150,20))}\n]\n\n# Create grid search object\nCV = GridSearchCV(pipe, \n                  param_grid = param_grid, \n                  cv = 5, \n                  #scoring=\"neg_mean_squared_error\",\n                  verbose=True, n_jobs=-1)\n\n# Fit on data\nbest_model= CV.fit(X_train, y_train)","f66c4c24":"# View best model\nprint(\"Best parameters found: \", best_model.best_estimator_.get_params()['classifier'])#best parameters and lowest RMSE\nprint(\"Highest Score found: \", round(CV.best_score_,2))","46254fea":"#ROC Curve\nfrom sklearn.metrics import roc_curve, auc\nmodel = RandomForestClassifier(criterion='gini',max_features=6,min_samples_leaf=1, min_samples_split=2,n_estimators=10)\nmodel.fit(X_train,y_train)\nprobs = model.predict_proba(X_test)\ny_prob = probs[:,1]\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nplt.figure(figsize=(7,7))\nplt.title('Receiver Operating Characteristic(ROC) Curve')\nplt.plot(false_positive_rate,true_positive_rate, color='red',label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],linestyle='--')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","4a466dec":"veil-type has only one value p. we can eliminate it.","17474f4d":"The features are all in character type.  ","d6104e97":"![](http:\/\/)Mushroom Classifications\n1. LogisticRegression\n2. Decision Tree\n3. Random Forrest","acb2d561":"Gill-color and bruises features are highly likely to have a relationship with different mushroom types.","5c36fe11":"The best model for the data is random forrest with\n* criterion='gini'\n* max_features=6\n* n_estimators=10","235d8ae1":"The dataset has 22 different features and 8124 data. "}}