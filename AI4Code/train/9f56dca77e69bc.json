{"cell_type":{"177b4ecf":"code","d05be7a6":"code","8cbe4ae1":"code","eddcfb65":"code","cc5e5817":"code","c5f4082d":"code","b0490ac1":"code","3ba5f3b0":"code","daa53581":"code","5950b945":"code","cc657d13":"code","e1adde65":"code","062d5c2a":"code","1cb87aa9":"code","25c83617":"code","0a50acc0":"markdown","489304c6":"markdown","52cc0262":"markdown","5ba9735c":"markdown","866edf3a":"markdown"},"source":{"177b4ecf":"import os\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport matplotlib.pyplot as plt\nfrom kaggle_datasets import KaggleDatasets","d05be7a6":"tf.test.is_gpu_available()","8cbe4ae1":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","eddcfb65":"GCS_DS_PATH = KaggleDatasets().get_gcs_path()\ndataset_base_path = GCS_DS_PATH+\"\/tfrecords-jpeg-224x224\"\ndef get_records(split_name):\n    filenames = tf.io.gfile.glob(dataset_base_path+\"\/\"+ split_name+\"\/\"+ \"*.tfrec\")\n    return tf.data.TFRecordDataset(filenames)","cc5e5817":"train_records = get_records(\"train\")\nval_records = get_records(\"val\")\n\noptions = tf.data.Options()\noptions.experimental_deterministic = False\n\ntest_records = get_records(\"test\").with_options(options)","c5f4082d":"image_feature_description = {\n    'id': tf.io.FixedLenFeature([], tf.string),\n    'class': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n    'image': tf.io.FixedLenFeature([], tf.string),\n}\n\ndef decode_image(image):\n    image = tf.io.decode_image(image)\n    image = tf.cast(image, tf.float32)\n    image = tf.reshape(image, (image_size, image_size, 3))\n    image \/= 255\n    return image\n\ndef parse_image_function(example_proto):\n    example = tf.io.parse_single_example(example_proto, image_feature_description)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int64)\n    id = example['id']\n    return image, label, id\n","b0490ac1":"image_size = 224\n\ntraining_size = sum(1 for record in train_records.map(parse_image_function))\nprint(\"Training Size:\", training_size)\n\ntrain_records\n\nfor image, label, id in train_records.map(parse_image_function):\n    plt.imshow(image)\n    plt.title(label.numpy())\n    break","3ba5f3b0":"batch_size = 32\n\ndef label_data_map(image, label, id):\n    return image, label\n\ndef unlabel_data_map(image, label, id):\n    return image\n\ntraining_batch = train_records.map(parse_image_function).shuffle(training_size\/\/4).map(label_data_map).batch(batch_size).prefetch(1)\nvalidation_batch = val_records.map(parse_image_function).map(label_data_map).batch(batch_size).prefetch(1)\ntest_batch = test_records.map(parse_image_function).map(unlabel_data_map).batch(batch_size).prefetch(1)","daa53581":"num_classes = 104\n\nwith strategy.scope():\n    feature_extractor = tf.keras.applications.MobileNetV2(input_shape=(image_size, image_size, 3), weights='imagenet')\n    feature_extractor.trainable = False\n    \n    model = tf.keras.Sequential([\n        feature_extractor,\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()\n\n","5950b945":"EPOCHS = 50\n\nhistory = model.fit(training_batch, epochs=EPOCHS, validation_data=validation_batch)","cc657d13":"model.evaluate(validation_batch)","e1adde65":"ids = []\nfor img, label, id in test_records.map(parse_image_function):\n    ids.append(id.numpy().decode(\"utf-8\"))","062d5c2a":"probs = model.predict(test_batch)","1cb87aa9":"preds = np.argmax(probs, axis=1)","25c83617":"np.savetxt('submission.csv', np.rec.fromarrays([ids, preds]), fmt=['%s', '%d'], header='id,label', delimiter=',', comments='')","0a50acc0":"## Prediction","489304c6":"## Input Pipeline","52cc0262":"## Validation","5ba9735c":"# Reading TFRecord Files","866edf3a":"# Model"}}