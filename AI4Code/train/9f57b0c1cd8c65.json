{"cell_type":{"b169b66f":"code","c5f623da":"code","f00e24ac":"code","2582ae2e":"code","bcbde0ce":"code","d758626f":"code","a1de9298":"code","2f64e6d4":"code","0a519906":"code","2caaf64a":"code","e6c306f5":"code","15a20aad":"code","38ab3878":"code","efe10096":"code","156a7f71":"code","b3aa4b15":"code","685f5f7e":"code","e21f5e77":"code","bff1da08":"code","622e638b":"code","7061cbc9":"code","3de4d43c":"code","7796dde8":"code","3f77e5fb":"code","ffc7fe25":"code","b7122374":"code","d4485a2c":"code","a3548567":"code","e59fec13":"code","34fa84df":"code","f71c5d09":"code","dfdd43d6":"code","24413ed5":"code","85bbdc78":"code","81c2d130":"markdown","74d7d474":"markdown","dd1c6d3b":"markdown","82dc2fae":"markdown","236b2c63":"markdown","0450ba60":"markdown","38698ac5":"markdown","477c157f":"markdown","24303f07":"markdown","858d6cc9":"markdown","0bfa7b9f":"markdown","e5de4b3d":"markdown","f1d37009":"markdown","d716ac6b":"markdown","6e3445f0":"markdown","bba76d65":"markdown","bd4176ca":"markdown","285f3b32":"markdown","229d519e":"markdown","48e4aa03":"markdown","ff519ab4":"markdown"},"source":{"b169b66f":"import pandas as pd\nimport numpy as np\nimport gc\nimport seaborn as sns","c5f623da":"## Function to reduce the DF size\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","f00e24ac":"#function to fill missing meterological data\ndef site_mean_weather(table):\n    for col in list(table.columns[table.isnull().any()]):\n        imputaion = table.groupby(['site_id','hour','month'])[col].transform('mean')\n        table[col].fillna(imputaion,inplace = True)","2582ae2e":"def prep_func(df):\n    # Drop unnecessary columns\n    df.drop(['floor_count','year_built', 'cloud_coverage','precip_depth_1_hr','sea_level_pressure'],axis=1,inplace=True)\n    gc.collect()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    # Encode meter types\n    df['meter'] = pd.Categorical(df['meter']).rename_categories({0: 'electricity', 1: 'chilledwater', 2: 'steam', 3: 'hotwater'})\n    gc.collect()\n    #Create time related features\n    df['hour'] = df.timestamp.dt.hour\n    df['month'] = df.timestamp.dt.month\n    # Fill missing data\n    site_mean_weather(df)\n    gc.collect()\n    #Create time related features\n    df['day'] = df.timestamp.dt.day\n    df[\"weekday\"] = df.timestamp.dt.weekday \n    gc.collect()\n    #Change column types to category\n    df[['primary_use','hour','month','site_id',\n    'building_id','wind_direction','weekday','day']] = df[['primary_use','hour','month','site_id','building_id','wind_direction','weekday','day']].astype('category')\n    gc.collect()\n    #Sort Data chronologically\n    df['timestamp'].sort_values().reset_index(drop=True)\n    gc.collect()\n    df.drop(['timestamp'],axis = 1, inplace = True)\n    gc.collect()\n    # Create weekend feature\n    df.loc[df['weekday'].isin([5, 6]), 'Weekend'] = 1\n    df['Weekend'].fillna(0,inplace = True)\n    df['Weekend'] = df['Weekend'].astype('bool')\n    gc.collect()\n    \n    df = reduce_mem_usage(df)\n    gc.collect()\n    \n    print('Data is ready')","bcbde0ce":"train = pd.read_csv('..\/input\/ashrae-energy-prediction\/train.csv')\nweather_train = pd.read_csv('..\/input\/ashrae-energy-prediction\/weather_train.csv')\nbuilding = pd.read_csv('..\/input\/ashrae-energy-prediction\/building_metadata.csv')\ndf = pd.merge(train,building, on=\"building_id\", how=\"left\")\ndf = df.merge(weather_train, on=[\"site_id\", \"timestamp\"], how=\"left\")\ndel train, weather_train,building\ngc.collect()\nprint('Data is imported')","d758626f":"prep_func(df)","a1de9298":"df.loc[(df['site_id'] == 0) & (df['meter'] == 'electricity'), 'meter_reading'] = df[(df['site_id'] == 0) & (df['meter'] == 'electricity')]['meter_reading'].apply(lambda x: x* 0.2931 )","2f64e6d4":"df['cons\/sqft'] = df['meter_reading'] \/ df['square_feet']","0a519906":"reduce_mem_usage(df)\ngc.collect()","2caaf64a":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error\nimport lightgbm as lgb\nfrom sklearn.model_selection import TimeSeriesSplit","e6c306f5":"X = df.drop(['meter_reading','cons\/sqft'], axis = 1) #Features\ngc.collect()\ny = df['cons\/sqft'] #target\ngc.collect()","15a20aad":"del df\ngc.collect()","38ab3878":"categorical_columns = ['primary_use','hour','month','site_id','building_id','wind_direction','weekday','day','meter']","efe10096":"params = {\n    \"objective\": \"regression\",\n    \"boosting\": \"gbdt\", # gradient boosting\n    \"learning_rate\": 0.15,\n    \"num_leaves\": 30,\n    \"feature_fraction\": 0.6,\n    \"reg_lambda\": 2,\n    \"metric\": \"rmse\"}","156a7f71":"#Choose number of splits\ntss = TimeSeriesSplit(2)\ntss.split(X) \nfolds = tss.split(X) \nmodels = []\n#Spliting data\nfor train_index, test_index in folds:\n    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index,:]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    #print('TRAIN:', train_index, 'TEST:', test_index)\n#defining train and validation sets\n    lgb_train = lgb.Dataset(X_train, y_train)\n    lgb_valid = lgb.Dataset(X_test, y_test)\n    dftrainLGB = lgb.Dataset(data = X_train, label = y_train, feature_name = list(X_train))\n    del X_test, y_train, y_test\n    gc.collect()\n#model training\n    model = lgb.train(params, train_set=dftrainLGB, num_boost_round=1000, valid_sets=(lgb_train, lgb_valid), \n                      verbose_eval=75, early_stopping_rounds=200,categorical_feature = categorical_columns)\n    models.append(model)\n    del lgb_train, lgb_valid, dftrainLGB\n    gc.collect()","b3aa4b15":"del X, y\ngc.collect()","685f5f7e":"del tss, folds\ngc.collect()","e21f5e77":"for model in models:\n    lgb.plot_importance(model)","bff1da08":"del X_train\ngc.collect()","622e638b":"#cv_results = lgb.cv(params, dftrainLGB, num_boost_round=200, nfold=4, \n                    #verbose_eval=10, early_stopping_rounds=40)","7061cbc9":"test = pd.read_csv('..\/input\/ashrae-energy-prediction\/test.csv')\nweather_test = pd.read_csv('..\/input\/ashrae-energy-prediction\/weather_test.csv')\nbuilding = pd.read_csv('..\/input\/ashrae-energy-prediction\/building_metadata.csv')\ntest = reduce_mem_usage(test)\nweather_test = reduce_mem_usage(weather_test)\nbuilding = reduce_mem_usage(building)","3de4d43c":"test_df = pd.merge(test,building, on=\"building_id\", how=\"left\")\ngc.collect()\ntest_df = test_df.merge(weather_test, on=[\"site_id\", \"timestamp\"], how=\"left\")\ngc.collect()\ndel test, weather_test, building\ngc.collect()","7796dde8":"prep_func(test_df)","3f77e5fb":"gc.collect()","ffc7fe25":"half1 = test_df.iloc[:20848800].drop('row_id',axis=1)\nhalf2 = test_df.iloc[20848800:].drop('row_id',axis=1)","b7122374":"results1 = []\nfor model in models:\n    if  len(results1)== 0:\n        results1 = (model.predict(half1, num_iteration=model.best_iteration)) \/ len(models)\n    else:\n        results1 += (model.predict(half1, num_iteration=model.best_iteration)) \/ len(models)\n    del model\n    gc.collect()","d4485a2c":"results2 = []\nfor model in models:\n    if  len(results2) == 0:\n        results2 = (model.predict(half2, num_iteration=model.best_iteration)) \/ len(models)\n    else:\n        results2 += (model.predict(half2, num_iteration=model.best_iteration)) \/ len(models)\n    del model\n    gc.collect()","a3548567":"del models\ngc.collect()","e59fec13":"results = np.concatenate((results1, results2), axis=0)","34fa84df":"del results1, results2\ngc.collect()","f71c5d09":"test_df['meter_reading'] = results * test_df['square_feet']","dfdd43d6":"test_df.drop(['building_id','primary_use','air_temperature','dew_temperature',\n              'wind_direction','wind_speed','hour','month','day','weekday','Weekend','square_feet'],axis = 1, inplace=True)\ngc.collect()","24413ed5":"test_df.loc[(test_df['site_id'] == 0) & (test_df['meter'] == 'electricity'), 'meter_reading'] = test_df[(test_df['site_id'] == 0) & (test_df['meter'] == 'electricity')]['meter_reading'].apply(lambda x: x \/ 0.2931 )\ngc.collect()","85bbdc78":"output = pd.DataFrame({\"row_id\": test_df['row_id'], \"meter_reading\": test_df['meter_reading']})\ndel test_df\ngc.collect()\noutput.to_csv(\"submission.csv\", index=False)","81c2d130":"#Choose number of splits\nkf = KFold(n_splits=3)\nmodels = []\n#Spliting data\nfor train_index, test_index in  kf.split(X):\n    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index,:]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n#defining train and validation sets\n    lgb_train = lgb.Dataset(X_train, y_train)\n    lgb_valid = lgb.Dataset(X_test, y_test)\n    dftrainLGB = lgb.Dataset(data = X_train, label = y_train, feature_name = list(X_train))\n    del X_test, y_train, y_test\n    gc.collect()\n#model training\n    model = lgb.train(params, train_set=dftrainLGB, num_boost_round=1000, valid_sets=(lgb_train, lgb_valid), \n                      verbose_eval=75, early_stopping_rounds=250,categorical_feature = categorical_columns)\n    models.append(model)\n    del lgb_train, lgb_valid, dftrainLGB\n    gc.collect()","74d7d474":"Run cell to import data.","dd1c6d3b":"Data preparation function.","82dc2fae":"Function to fill missing meterological data","236b2c63":"<a id=\"section-six\"><\/a>\n# 2. Conclusions","0450ba60":"<a id=\"subsection-test\"><\/a>\n## Test Set","38698ac5":"Function for reducing size.","477c157f":"<a id=\"subsection-pred\"><\/a>\n## Testing Model","24303f07":"Run either time series  or kfold model. The predictipn part is same for both","858d6cc9":"<a id=\"subsection-future\"><\/a>\n## Future Work","0bfa7b9f":"<a id=\"subsection-v\"><\/a>\n# Model Validation","e5de4b3d":"<a id=\"section-five\"><\/a>\n# 1. Modeling","f1d37009":"Light Gradient Boosted Machine (LightGBM) model is chosen. \n* Faster training speed and higher efficiency.\n* Lower memory usage.\n* Better accuracy.\n* Support of parallel and GPU learning.\n* Capable of handling large-scale data","d716ac6b":"### Time Series Split Model","6e3445f0":"This notebook is the continuation of [ASHRAE - Energy Prediction1](https:\/\/www.kaggle.com\/fatmanuranl\/ashrae-energy-prediction1). Data is preapred according to EDA on that notebook. Run the cells below to prepare data for modeling.","bba76d65":"Here is a summary table for all things I tried.","bd4176ca":"## Kfold Model","285f3b32":"For all model following parameters are used.","229d519e":"5.  [Modeling](#section-five)\n    - [Model Validation](#subsection-v)\n    - [Test Set](#subsection-test)\n    - [Testing Model](#subsection-pred)\n    \n6. [Conclusion](#section-six)\n    - [Model Validation](#subsection-future)","48e4aa03":"# Data Preparation","ff519ab4":"* Removing outliers\n* Finding feature importance (changing selected features)\n* Changing parameters\n* Using cross validaiton \n* Trying different models for different meter types\n* Running model without divinding meter reading to area\n* Running model after taking log of meter readings\n"}}