{"cell_type":{"adaa0e3b":"code","5c248f6d":"code","4d40869d":"code","0cea822c":"code","632350a6":"code","f5dbe8f7":"code","0a32622d":"code","31dd8eb4":"code","3cf38639":"code","57c51d99":"code","0afaf906":"code","c59071c3":"code","2a9327bd":"code","5e4ba792":"code","eb27442c":"code","3bf782a8":"code","18fb34bf":"code","623d6693":"code","52e9b04d":"code","f391cf31":"code","ed5ed6d5":"code","bb124469":"code","98e5c5f3":"code","1a199250":"code","86e2eb1b":"code","41fa10d6":"code","5231c497":"code","bba0ce47":"code","84873a84":"code","fdfa77c9":"code","b4f3c40f":"code","2a5a693b":"code","50ca4098":"code","52347431":"code","00fa23cd":"code","56f49ee1":"code","7e76e0a1":"markdown","1ea74b99":"markdown","d6c6b47b":"markdown","5a7ed2e0":"markdown"},"source":{"adaa0e3b":"# Let's Get Started by importing libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n\n# Visulation libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","5c248f6d":"# Reading the data\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","4d40869d":"# Checking the data\ntrain.head()","0cea822c":"# Null values are empty data points\n# checking the data for Null values\ntrain.isnull()\n# we do have null values in some columns","632350a6":"# creating heat map based on null values on the data \nfig, ax = plt.subplots(figsize=(12,12)) # Increasing the fig size\n\nsns.heatmap(train.isnull(),cmap='viridis')\n\n# Cabin & Age have most missing values (Null values)\n# and Embarked seem to have some missing values","f5dbe8f7":"# We Will deal with the missing values later\n# Let's checked the survived & not survived population as per gender\n\n# Count plot is the basic measure for such plots\nsns.countplot(x='Survived',data=train, hue='Sex', palette= 'RdBu_r')","0a32622d":"# Count Plot as per Passenger Class\nsns.countplot(x='Survived',data= train, hue='Pclass')","31dd8eb4":"# Age of People on the Titanic \n# simply checking the distribution plot\nsns.distplot(train['Age'].dropna(),bins=30, kde =False)","3cf38639":"# Checking the siblings columns\nsns.countplot(x='SibSp',data = train)\n# Seems like People with no siblings are more","57c51d99":"# Fare Distribution\nsns.distplot(train['Fare'].dropna(),kde=False)\n# High people Fare lies between 0-50","0afaf906":"# More inovative plots can we done with cufflinks\nimport cufflinks as cf\ncf.go_offline()\ntrain['Fare'].iplot(kind='hist',bins = 50)","c59071c3":"# Mean and Median Imputation are the most commonly used imputation tech\n# Rather than just Imputating Mean of Age\n# we will find out Mean of Age as per Passenger class\nplt.figure(figsize=(10,7))\nsns.boxplot(x='Pclass',y=\"Age\",data=train)","2a9327bd":"# Finding out the Mean as Per Passenger class\n#train.groupby('Pclass')['Age'].median()\n# as median takes care of outliers(both are same in our case)\ntrain.groupby('Pclass')['Age'].mean()\n\n# Class 1 Mean : 38\n# Class 2 Mean : 30\n# Class 3 Mean : 25","5e4ba792":"# Writing a function for changing null values as per median\ndef impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        \n        if Pclass == 1:\n            return 37\n        elif Pclass == 2:\n            return 29\n        else:\n            return 24\n        \n    else:\n        return Age","eb27442c":"# Applying above impute on age columns\ntrain['Age'] = train[['Age','Pclass']].apply(impute_age,axis = 1)","3bf782a8":"# Checking if null are imputed or not\nsum(train['Age'].isnull())","18fb34bf":"# Dropping the Cabin as too many null values\ntrain.drop('Cabin', axis = 1, inplace = True)","623d6693":"# checking if Cabin column is dropped or not\ntrain.columns","52e9b04d":"# we can either impute or drop the data row where Embarked is missing\ntrain.dropna(inplace=True)","f391cf31":"# checking the data for missing values\n# creating heat map based on null values on the data \nfig, ax = plt.subplots(figsize=(12,12)) # Increasing the fig size\n\nsns.heatmap(train.isnull(),cmap='viridis')","ed5ed6d5":"sex = pd.get_dummies(train['Sex'],drop_first = True)","bb124469":"embark = pd.get_dummies(train['Embarked'],drop_first = True)","98e5c5f3":"pclass = pd.get_dummies(train['Pclass'],drop_first = True)","1a199250":"# adding the dummies in the data frame\ntrain = pd.concat([train,sex,embark,pclass],axis = 1)","86e2eb1b":"train.head()","41fa10d6":"# Dropping the unnecessary columns\ntrain.drop(['PassengerId','Pclass','Sex','Embarked','Name','Ticket'],axis = 1,inplace =True)","5231c497":"train.head()","bba0ce47":"# splitting the train data for cross validations\nx = train.drop('Survived',axis = 1)\ny= train['Survived']","84873a84":"# Splitting using sklearn\nfrom sklearn.model_selection import train_test_split","fdfa77c9":"# Actual splitting\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3, random_state = 101)","b4f3c40f":"# Model Building\nfrom sklearn.linear_model import LogisticRegression\nlogmodel = LogisticRegression()","2a5a693b":"# Fitting the Logistic Regression on train data \nlogmodel.fit(x_train,y_train)","50ca4098":"# Prediting on the test data using our model\npred = logmodel.predict(x_test)","52347431":"# for classification We can directly have % from\nfrom sklearn.metrics import classification_report","00fa23cd":"# Accuracy is given by\nprint(classification_report (y_test,pred))","56f49ee1":"# Predicting on actual test data\nActual_pred = logmodel.predict(test)","7e76e0a1":"As we have Catogerical Columns like 'Sex'.\nWe need to convert them into numerical Columns, by creating DUMMY VARIABLES.\nSo that our machine learning algorithm can understand the data.","1ea74b99":"# Imputation\nThe assignment of a value to something by inference from the value of the products or processes to which it contributes.\nImputation simply means filling up the null values with logical values\nThere are many Imputation Techniques, But mostly used are:\n* Mean Imputation\n* Median Imputation\n* Creating a Regression model to imputate null values\n","d6c6b47b":"Columns with specific meaning.\nPlease refer to [Titanic Kaggle](http:\/\/https:\/\/www.kaggle.com\/c\/titanic\/overview)","5a7ed2e0":"The competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\n# The Challenge\nIn this challenge, we are ask to build a predictive model that answers the question: \u201cwhat sorts of people were more likely to survive?\u201d using passenger data (ie name, age, gender, socio-economic class, etc).\n\n**What Data Will I Use in This Competition?**\nIn this competition, we\u2019ll gain access to two similar datasets that include passenger information. One dataset is titled `train.csv` and the other is titled `test.csv`.\n\n**Overview**\nThe training set should be used to build your machine learning models. We will also use feature engineering to create new features.\n\nThe test set should be used to see how well our model performs on unseen data. For the test set. It is our job to predict these outcomes. \n\nFor each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n\n**Data Dictionary**\nPlease check the Data Dictionary At [Titanic Kaggle](http:\/\/https:\/\/www.kaggle.com\/c\/titanic\/data)"}}