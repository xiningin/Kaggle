{"cell_type":{"c65c79ae":"code","db88d110":"code","1ec9a410":"code","d2fc4ad4":"code","95314d50":"code","0ef52f75":"code","2a81ba1a":"code","3f05ed38":"code","b1193c8d":"code","e2fc6fa6":"code","484df6f8":"code","8ffe4fce":"code","0dd5c1e3":"code","17ebfe73":"code","610bb0ef":"code","af69a73f":"code","f4780751":"code","679e4036":"code","9bbcdb4e":"code","e51154cd":"code","fe172e91":"code","7df87c6f":"code","52bb64f4":"code","b84c4263":"code","d1809739":"code","0fc04125":"code","035bd76f":"markdown","e9b8b29b":"markdown","5aa197a9":"markdown","b75aed4e":"markdown","dab1d5e9":"markdown","66218d27":"markdown","58888f2a":"markdown","2795d83a":"markdown","ca8798e7":"markdown","8943bfcf":"markdown","0bf40fb2":"markdown","78fecf53":"markdown","4edc885f":"markdown","a2ed4569":"markdown","c7d26a94":"markdown","cce3b33b":"markdown","f801130b":"markdown","719ee36e":"markdown"},"source":{"c65c79ae":"import os\nfrom keras import applications\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.models import Sequential, Model \nfrom keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\nfrom keras import backend as k \nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\nfrom keras.preprocessing import image\nimport numpy as np\nimport math\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score\nimport scikitplot as skplt\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport warnings\nwarnings.filterwarnings('ignore')","db88d110":"train_dir = '..\/input\/seti-data\/primary_small\/train\/'\nvalidation_dir = '..\/input\/seti-data\/primary_small\/valid\/'\ntest_dir = '..\/input\/seti-data\/primary_small\/test\/'\n\nimg_dim  = 197","1ec9a410":"#Generators\ntrain_datagen = ImageDataGenerator(\n  rotation_range = 180,\n  horizontal_flip = True,\n  vertical_flip = True,\n  fill_mode = \"reflect\")\n\n# Note that the validation data shouldn't be augmented!\nvalidation_datagen = ImageDataGenerator()  \ntest_datagen = ImageDataGenerator()  ","d2fc4ad4":"training_batch_size = 64\nvalidation_batch_size = 64\n\ntrain_generator = train_datagen.flow_from_directory(\n  train_dir,                                                  \n  classes = ('noise', 'squiggle', 'narrowband', 'narrowbanddrd', 'squarepulsednarrowband', \n            'squigglesquarepulsednarrowband', 'brightpixel'),\n  target_size = (img_dim, img_dim),            \n  batch_size = training_batch_size,\n  class_mode = \"categorical\",\n  shuffle = True,\n  seed = 123)","95314d50":"validation_generator = validation_datagen.flow_from_directory(\n  validation_dir,\n  classes = ('noise', 'squiggle', 'narrowband', 'narrowbanddrd', 'squarepulsednarrowband', \n            'squigglesquarepulsednarrowband', 'brightpixel'),\n  target_size = (img_dim, img_dim),\n  batch_size = validation_batch_size,\n  class_mode = \"categorical\",\n  shuffle = True,\n  seed = 123)","0ef52f75":"test_size = 700\ntest_batch_size = 1\n\ntest_generator = test_datagen.flow_from_directory(\n  test_dir,\n  classes = ('noise', 'squiggle', 'narrowband', 'narrowbanddrd', 'squarepulsednarrowband', \n            'squigglesquarepulsednarrowband', 'brightpixel'),\n  target_size = (img_dim, img_dim),\n  batch_size = test_batch_size,\n  class_mode = \"categorical\",\n  shuffle = False)","2a81ba1a":"base = InceptionResNetV2(\n  weights = '..\/input\/inceptionresnetv2\/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5',\n  include_top = False,\n  input_shape = (img_dim, img_dim, 3)\n)","3f05ed38":"x = base.output\nx = Flatten(input_shape=base.output_shape[1:])(x)\nx = Dense(img_dim, activation=\"relu\")(x)\nx = Dropout(0.2)(x)\nx = Dense(7, activation=\"softmax\")(x)","b1193c8d":"model = Model(inputs=base.input, outputs=x)","e2fc6fa6":"for layer in model.layers:\n   layer.trainable = True","484df6f8":"model.compile(loss = \"binary_crossentropy\", optimizer = optimizers.rmsprop(lr=1e-4), metrics=[\"accuracy\"])","8ffe4fce":"#Train\n\ntraining_step_size = 64\nvalidation_step_size = 32\n\nhistory = model.fit_generator(\n  train_generator,\n  steps_per_epoch = training_step_size,\n  epochs = 50,\n  validation_data = validation_generator,\n  validation_steps = validation_step_size,\n  verbose = 0,\n)","0dd5c1e3":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","17ebfe73":"predictions = model.predict_generator(test_generator, steps = test_size, verbose = 1)","610bb0ef":"df = pd.DataFrame(predictions)","af69a73f":"df['filename'] = test_generator.filenames","f4780751":"df['truth'] = ''\ndf['truth'] = df['filename'].str.split('\/', 1, expand = True)","679e4036":"df['prediction_index'] = df[[0,1,2,3,4,5,6]].idxmax(axis=1)","9bbcdb4e":"df['prediction'] = ''\ndf['prediction'][df['prediction_index'] == 0] = 'noise'\ndf['prediction'][df['prediction_index'] == 1] = 'squiggle'\ndf['prediction'][df['prediction_index'] == 2] = 'narrowband'\ndf['prediction'][df['prediction_index'] == 3] = 'narrowbanddrd'\ndf['prediction'][df['prediction_index'] == 4] = 'squarepulsednarrowband'\ndf['prediction'][df['prediction_index'] == 5] = 'squigglesquarepulsednarrowband'\ndf['prediction'][df['prediction_index'] == 6] = 'brightpixel'","e51154cd":"df.head()","fe172e91":"cm = confusion_matrix(df['truth'], df['prediction'])\ncm","7df87c6f":"cm_df = pd.DataFrame(cm)","52bb64f4":"cm_df.columns = ['noise', 'squiggle', 'narrowband', 'narrowbanddrd', 'squarepulsednarrowband', \n            'squigglesquarepulsednarrowband', 'brightpixel']","b84c4263":"cm_df['signal'] = ('noise', 'squiggle', 'narrowband', 'narrowbanddrd', 'squarepulsednarrowband', \n            'squigglesquarepulsednarrowband', 'brightpixel')","d1809739":"cm_df","0fc04125":"accuracy = accuracy_score(df['truth'], df['prediction'])\naccuracy","035bd76f":"Create a few constants,","e9b8b29b":"Now, let's use Keras to train the model. The first step is to create some data generators to flow the data into the training process. I'm going to use some **data augmentation** to expand the dataset. Note ... some of the signal types look very similar to each other. For example, 'narrowbanddrd' is basically just a slightly curved version of 'narrowband'. I suspect that some augmentation transformations such as skewing could make one type look like another, so beware!","5aa197a9":"Plot the performance,","b75aed4e":"Then do some basic tidying of the predictions,","dab1d5e9":"If you haven't already, you might want to check out [SETI Simulated Signals - Data Exploration](https:\/\/www.kaggle.com\/tentotheminus9\/seti-simulated-signals-data-exploration) first.","66218d27":"I've played around with **transfer learning** using [ImageNet](http:\/\/image-net.org\/) weights from various depths of the model, but performance wasn't great. Let's just allow the whole thing to be trained,","58888f2a":"# AI, Meet ET","2795d83a":"The next obvious step is to improve this accuracy. More training data will be useful here along with changes to the model and hyperparameters. Deploying the consequent model on real-world SETI data would be then great to see. I hope to add such data soon.","ca8798e7":"### Predict on the test set","8943bfcf":"We can now train the model,","0bf40fb2":"Now, let's merge the 'base' with the custom 'top',","78fecf53":"Finally, here is the overall accuracy,","4edc885f":"SETI have been getting serious about AI [recently](http:\/\/seti.berkeley.edu\/frb-machine\/). After all, what better solution to the problem of too much data?\n\nThis kernel takes a Keras pre-trained model (**InceptionResNetV2**) and trains it on the PNGs produced from the SETI simulated 'primary small' dataset.\n\nLet's start by loading the required modules,","a2ed4569":"Next, load the [InceptionResNetV2 model from keras](https:\/\/keras.io\/applications\/). Note that you have to import the weights as as separate 'dataset' in Kaggle,","c7d26a94":"I need to tweak this model to make predictions for the 7 signal categories. Notice that I didn't include the 'top' in the above step, the 'top' being the output layers in the original model. Below adds a bespoke top. Notice the 7-output **softmax** layer,","cce3b33b":"I held back some files to create a test set. Let's see how well the model does on it. The first step is to run the test set through the model,","f801130b":"Let's compile the model. I've not played around a great deal with the optimiser choice or hyperparameters, but this seems to work reasonable well,","719ee36e":"In order to see how well it's done, we can use a [confusion matrix](https:\/\/en.wikipedia.org\/wiki\/Confusion_matrix),"}}