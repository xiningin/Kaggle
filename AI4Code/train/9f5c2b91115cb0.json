{"cell_type":{"ff8966d6":"code","dcd924a7":"code","332fdab5":"code","48685fec":"code","c77c8d5e":"code","09b39857":"code","f3470257":"code","2dfbdfe2":"code","2ef5351d":"code","c895c802":"code","52f7e6bd":"code","60501f54":"code","087f8648":"code","29f703ea":"code","fd037a32":"code","b5dda6fe":"code","2985fe3f":"code","ed9dea75":"code","540c5abd":"code","47e6fe99":"code","9fb37a5b":"code","65989eb7":"code","5fd3bc41":"code","f14cd111":"code","f1933997":"code","5747e712":"code","a0299ea8":"code","0d7e1e8a":"code","de1e8ee3":"code","7f90fe9a":"code","a5ec7ba5":"code","f1f75955":"code","f8f342a9":"code","5bc445f4":"code","74f9f7cf":"code","70a1d7e7":"code","09c49de7":"code","46ecfe64":"code","0e6bd14d":"code","ec43afa0":"code","b65cb803":"code","aca95654":"code","1a97d7ff":"code","bdf3d5ab":"code","ce363cb5":"code","a9657a79":"markdown","f7f96f2a":"markdown","7bb1e80b":"markdown","16f81d64":"markdown","67a13e4c":"markdown","731d7e09":"markdown","ce54c054":"markdown","1fd52872":"markdown","da70e381":"markdown","6ac447fa":"markdown","a0952db3":"markdown","9697fadd":"markdown","a80ae874":"markdown","24937777":"markdown"},"source":{"ff8966d6":"import pandas as pd\nimport numpy as np\nimport seaborn as sns","dcd924a7":"import matplotlib.pyplot as plt\nimport os\nimport string\nfrom collections import defaultdict\nfrom transformers import AutoTokenizer\nfrom tqdm import tqdm\n","332fdab5":"tokenizer=AutoTokenizer.from_pretrained('..\/input\/bert-base-uncased')","48685fec":"data_text_path ='..\/input\/feedback-prize-2021\/train'\ndata_label_path ='..\/input\/feedback-prize-2021\/train.csv'","c77c8d5e":"df_train_label = pd.read_csv('..\/input\/feedback-prize-2021\/train.csv')","09b39857":"df_train_label.head(2)","f3470257":"def get_tokenized_len(text):\n    return len(tokenizer.encode(text))","2dfbdfe2":"df_train_label['discourse_type'].value_counts()","2ef5351d":"df_train_label['discourse_start'].hist(bins=[0,200,500,1000,2000,3000,4000,5000,6000])","c895c802":"df_train_label['discourse_end'].hist(bins=[0,200,500,1000,2000,3000,4000,5000,6000])","52f7e6bd":"(df_train_label['discourse_end']-df_train_label['discourse_start']).hist(bins=[0,100,200,500,1000,2000])","60501f54":"def get_split_len(textstr):\n    return len(textstr.strip().split())\n\ndf_train_label['predictionstring'].apply(get_split_len).hist(bins=[0,50,100,150,200,500])","087f8648":"df_train_label['discoures_text_len'] = df_train_label['discourse_text'].apply(get_tokenized_len)","29f703ea":"df_train_label.hist(column=['discoures_text_len'])","fd037a32":"df_group = df_train_label.groupby('id')","b5dda6fe":"def f(x):\n    #print(len(x['id']))\n    return pd.Series({    \n                          'discourse_id':x['discourse_id'].values.reshape(-1).tolist(),\n                         'discourse_start':x['discourse_start'].values.reshape(-1).tolist(),\n                         'discourse_end':x['discourse_end'].values.reshape(-1).tolist(),\n                          'discourse_text':x['discourse_text'].values.reshape(-1).tolist(),\n                          'discourse_type':x['discourse_type'].values.reshape(-1).tolist(),\n                         \"predictionstring\":x['predictionstring'].values.reshape(-1).tolist()\n            \n                         }).T\n","2985fe3f":"df_group_recol = df_group.apply(f)","ed9dea75":"#df_group_recol.index ","540c5abd":"df_group_recol.reset_index(level=0, inplace=True)","47e6fe99":"df_group_recol.head()","9fb37a5b":"len(df_group_recol)","65989eb7":"def get_text_from_afile(text_path):\n    with open(os.path.join(\"..\/input\/feedback-prize-2021\/train\",text_path+'.txt'), 'r') as f:\n        return (f.read())","5fd3bc41":"df_group_recol['text'] = df_group_recol['id'].apply(get_text_from_afile)\n    \n    ","f14cd111":"df_group_recol.head()","f1933997":"inequal_count =0 \nfor index, irow in df_group_recol.iterrows():\n    start_list = irow['discourse_start']\n    end_list =irow['discourse_end']\n    discourse_text_list = irow['discourse_text']\n\n    split_text=irow['text'].split()\n\n    for istart, iend,ians in zip(start_list, end_list,discourse_text_list):\n        \n\n        extracted_str = irow['text'][int(istart):int(iend)].strip().strip(string.punctuation)#.strip().strip(string.punctuation).strip()\n        ians_p = ians.strip().strip(string.punctuation)#.strip().strip(string.punctuation).strip()\n        if extracted_str!= ians_p:\n            inequal_count+=1\n            #print('*'*20)\n            #print(irow['text'][int(istart):int(iend)], ians,sep='**')\n","5747e712":"inequal_count","a0299ea8":"inequal_count =0 \nfor index, irow in df_group_recol.iterrows():\n    start_list = irow['discourse_start']\n    end_list =irow['discourse_end']\n    discourse_text_list = irow['discourse_text']\n    predictionstring_list = irow['predictionstring']\n    split_text=irow['text'].split()\n    \n    for ians,predictionstring in zip(discourse_text_list,predictionstring_list):\n        predictionstring_split =predictionstring.strip().split()\n        word_start_index = int(predictionstring_split[0])\n        word_end_idnex = int(predictionstring_split[-1])\n        ans_from_wordidnex = ' '.join(split_text[word_start_index:word_end_idnex+1]).strip().strip(string.punctuation).strip()\n        ians_p = \" \".join(ians.split()).strip().strip(string.punctuation).strip()\n        if ans_from_wordidnex!=ians_p:\n            inequal_count+=1\n            #print('*'*20)\n            #print(ans_from_wordidnex,ians_p,'-pair_end-\\n',sep='*******',)","0d7e1e8a":"inequal_count","de1e8ee3":"inequal_count =0\nfor index, irow in df_group_recol.iterrows():\n    start_list = irow['discourse_start']\n    end_list =irow['discourse_end']\n    discourse_text_list = irow['discourse_text']\n    predictionstring_list = irow['predictionstring']\n    \n    split_text=irow['text'].split()\n\n    wordindex2charindex={}\n    ipos=0\n    new_format_text = \"\"\n    for i_index,iword in enumerate(split_text):\n        wordindex2charindex[i_index]=(ipos,ipos+len(iword)-1)\n        # space\n        ipos= ipos+len(iword)+1\n        new_format_text+=(iword+' ')\n    for ians,predictionstring in zip(discourse_text_list,predictionstring_list):\n        predictionstring_split =predictionstring.strip().split()\n        word_start_index = int(predictionstring_split[0])\n        word_end_idnex = int(predictionstring_split[-1])\n        extracted_str=new_format_text[wordindex2charindex[word_start_index][0]:wordindex2charindex[word_end_idnex][1]+1]\n        if extracted_str.strip().strip(string.punctuation)!= \" \".join(ians.split()).strip().strip(string.punctuation):\n                inequal_count+=1\n","7f90fe9a":"inequal_count","a5ec7ba5":"df_group_recol.head(2)","f1f75955":"\ndf_group_recol['label_count'] =df_group_recol['discourse_type'].apply(len)","f8f342a9":"df_group_recol.hist(column=['label_count'])","5bc445f4":"label_type = list(df_train_label['discourse_type'].value_counts().keys())","74f9f7cf":"def perlabel_count(label_list):\n    dd_dict = defaultdict(lambda:0)\n    for ilabel in label_list:\n        dd_dict[ilabel]+=1\n    return [ dd_dict[il_type] for il_type in label_type]","70a1d7e7":"df_group_recol['perlabel_count'] = df_group_recol['discourse_type'].apply(perlabel_count)","09c49de7":"df_group_recol.head(1)","46ecfe64":"def display_multiple_img(df_list, rows, cols,title):\n    '''\n    ref: https:\/\/stackoverflow.com\/questions\/38082602\/plotting-multiple-different-plots-in-one-figure-using-seaborn\n    \n    '''\n    figure, all_ax = plt.subplots(nrows=rows,ncols=cols,figsize=(16,3))\n    plt.suptitle(title, fontsize=20)\n    for i in range(rows*cols):\n        df_list[i].hist(ax=all_ax.ravel()[i])\n    plt.tight_layout()\n    plt.show()","0e6bd14d":"type_count_array=np.array(df_group_recol['perlabel_count'].values.reshape(-1).tolist())","ec43afa0":"df_list = [pd.DataFrame({itype:type_count_array[:,i_index]}) for i_index, itype in enumerate(label_type)]","b65cb803":"display_multiple_img(df_list, 1, 7,label_type)","aca95654":"df_group_recol['tokenizer_len'] = df_group_recol['text'].apply(get_tokenized_len)","1a97d7ff":"df_group_recol.hist(column=['tokenizer_len'])","bdf3d5ab":"tokenizer.unk_token_id","ce363cb5":"\n\nunktoken_dict={}\nfor text in tqdm(df_group_recol['text']):\n    tokenized_examples =tokenizer(\n            text,  # QA\u7b2c\u4e00\u4e2a\u53e5\u5b50\u7684\u5217\u8868\n            max_length=512,  # \u6700\u5927\u957f\u5ea6\n            stride=0,  # \u662f\u4e0d\u540c\u7a97\u53e3 \u91cd\u53e0\u7684\u957f\u5ea6\uff0c\u4e0d\u662f\u6ed1\u52a8\u7684\u957f\u5ea6\n            return_overflowing_tokens=True,  # \u8fd4\u56de\u6bcf\u4e2aspan \u6837\u4f8b\u5bf9\u5e94\u7684 question-context\u7684\u6837\u672c\u5e8f\u53f7 \u5982[0,0,0,1,1,1]\n            return_offsets_mapping=True,  # \u8fd4\u56detoken\u5bf9\u5e94\u7684char\u7684\u4f4d\u7f6e\n            padding=\"max_length\",  # \u8bbe\u7f6epadding\uff0c\u201cmax_length\u201d\u8868\u793a\u8bbe\u7f6e\u4e3a \u5f53\u524d\u7684max_length\u7684\u503c\uff0cTrue\u8868\u793apaddingg\u5230\u6a21\u578b\u7684\u6700\u957f\u957f\u5ea6\uff0cFalse\u4e0dpadding\n        )\n    for index in range(len(tokenized_examples['input_ids'][0])):\n        if tokenized_examples['input_ids'][0][index] ==tokenizer.unk_token_id:\n            #print(tokenized_examples['offset_mapping'][0][index])\n            \n            span  = str(text[tokenized_examples['offset_mapping'][0][index][0]:tokenized_examples['offset_mapping'][0][index][1]])\n            if span not in unktoken_dict:\n                unktoken_dict[span] =0 \n            try:\n                unktoken_dict[span]+=1\n            except:\n                print(span)\n                pass\n        #print(tokenized_examples['input_ids'])\n        #print(tokenized_examples['offset_mapping'])\n        #print(tokenized_examples.sequence_ids(0))\n    \nprint(len((unktoken_dict)))\nprint(unktoken_dict)","a9657a79":"## ans word len","f7f96f2a":"## label count per doc","7bb1e80b":"## processing","16f81d64":"## ans char len","67a13e4c":"## ans split check","731d7e09":"## ans type","ce54c054":"# Data analysis is all you need firstly!","1fd52872":"## each label type count per doc","da70e381":"## ans predictionstring check","6ac447fa":"## per discoures_text len after tokenized","a0952db3":"## unkown word","9697fadd":"## ans char position check","a80ae874":"## load package","24937777":"## len after tokenied"}}