{"cell_type":{"16a5ee18":"code","8d733858":"code","3525ecd5":"code","eafba5db":"code","05a77d02":"code","9b201427":"code","21435e38":"code","d766e5b6":"code","ceabf7b4":"code","390eee68":"code","74911105":"code","88a1b1af":"code","17e25dd1":"code","02f60d6b":"code","9f3c0a36":"code","25834c4d":"code","f483e466":"code","95ba385b":"code","ca65957b":"code","673ef749":"code","9206f7f1":"code","49a7b2bb":"code","3dd462fd":"code","cf145e06":"code","5974afed":"code","b6350f80":"code","a1fca108":"code","5647110c":"code","88ce89f1":"code","9ac62431":"code","1e7b6e87":"code","0199deae":"code","0a1425a1":"code","3cef4237":"code","3787c49e":"code","6c1a557e":"code","17f5a543":"code","617d4aff":"code","3adf6498":"code","90359fdd":"code","c8e5f1de":"code","0a0731fb":"code","24a15ac9":"code","3e323388":"code","62290c9e":"code","500f68e6":"code","6d8f9b7a":"code","d562c470":"code","d6abdf05":"code","1f3263bc":"code","5c89e03b":"code","52d6bf86":"code","67162762":"code","943d2dcd":"code","2652e253":"code","b57bf5c7":"code","7669b093":"markdown","5d30c9fb":"markdown","92c2dbfd":"markdown","7f6921e6":"markdown","eee49e8e":"markdown","4ae67e92":"markdown","82b6d570":"markdown","40b37f27":"markdown","25949536":"markdown","feef3366":"markdown","c3297a92":"markdown","dc410b53":"markdown","9ca5ea0c":"markdown","4ce2226f":"markdown","4dc38162":"markdown"},"source":{"16a5ee18":"import pandas as pd\nimport numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt","8d733858":"# IGNORE THE CONTENT OF THIS CELL\n# import tensorflow as tf\n# tf.compat.v1.disable_eager_execution()","3525ecd5":"df = pd.read_csv('\/kaggle\/input\/energydata_complete.csv',index_col='date',infer_datetime_format=True)","eafba5db":"df.head()","05a77d02":"df.info()","9b201427":"df['Windspeed'].plot(figsize=(12,8))","21435e38":"df['Appliances'].plot(figsize=(12,8))","d766e5b6":"len(df)","ceabf7b4":"df.head(3)","390eee68":"df.tail(5)","74911105":"df.loc['2016-05-01':]","88a1b1af":"df = df.loc['2016-05-01':]","17e25dd1":"df = df.round(2)","02f60d6b":"len(df)","9f3c0a36":"# How many rows per day? We know its every 10 min\n24*60\/10","25834c4d":"test_days = 2","f483e466":"test_ind = test_days*144","95ba385b":"test_ind","ca65957b":"# Notice the minus sign in our indexing\n\ntrain = df.iloc[:-test_ind]\ntest = df.iloc[-test_ind:]","673ef749":"train","9206f7f1":"test","49a7b2bb":"from sklearn.preprocessing import MinMaxScaler","3dd462fd":"scaler = MinMaxScaler()","cf145e06":"# IGNORE WARNING ITS JUST CONVERTING TO FLOATS\n# WE ONLY FIT TO TRAININ DATA, OTHERWISE WE ARE CHEATING ASSUMING INFO ABOUT TEST SET\nscaler.fit(train)","5974afed":"scaled_train = scaler.transform(train)\nscaled_test = scaler.transform(test)","b6350f80":"from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator","a1fca108":"# scaled_train","5647110c":"# define generator\nlength = 144 # Length of the output sequences (in number of timesteps)\nbatch_size = 1 #Number of timeseries samples in each batch\ngenerator = TimeseriesGenerator(scaled_train, scaled_train, length=length, batch_size=batch_size)","88ce89f1":"len(scaled_train)","9ac62431":"len(generator) ","1e7b6e87":"# scaled_train","0199deae":"# What does the first batch look like?\nX,y = generator[0]","0a1425a1":"print(f'Given the Array: \\n{X.flatten()}')\nprint(f'Predict this y: \\n {y}')","3cef4237":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,LSTM","3787c49e":"scaled_train.shape","6c1a557e":"# define model\nmodel = Sequential()\n\n# Simple RNN layer\nmodel.add(LSTM(100,input_shape=(length,scaled_train.shape[1])))\n\n# Final Prediction (one neuron per feature)\nmodel.add(Dense(scaled_train.shape[1]))\n\nmodel.compile(optimizer='adam', loss='mse')","17f5a543":"model.summary()","617d4aff":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = EarlyStopping(monitor='val_loss',patience=1)\nvalidation_generator = TimeseriesGenerator(scaled_test,scaled_test, \n                                           length=length, batch_size=batch_size)","3adf6498":"model.fit_generator(generator,epochs=10,\n                    validation_data=validation_generator,\n                   callbacks=[early_stop])","90359fdd":"model.history.history.keys()","c8e5f1de":"losses = pd.DataFrame(model.history.history)\nlosses.plot()","0a0731fb":"first_eval_batch = scaled_train[-length:]","24a15ac9":"first_eval_batch","3e323388":"first_eval_batch = first_eval_batch.reshape((1, length, scaled_train.shape[1]))","62290c9e":"model.predict(first_eval_batch)","500f68e6":"scaled_test[0]","6d8f9b7a":"n_features = scaled_train.shape[1]\ntest_predictions = []\n\nfirst_eval_batch = scaled_train[-length:]\ncurrent_batch = first_eval_batch.reshape((1, length, n_features))\n\nfor i in range(len(test)):\n    \n    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])\n    current_pred = model.predict(current_batch)[0]\n    \n    # store prediction\n    test_predictions.append(current_pred) \n    \n    # update batch to now include prediction and drop first value\n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)","d562c470":"test_predictions","d6abdf05":"scaled_test","1f3263bc":"true_predictions = scaler.inverse_transform(test_predictions)","5c89e03b":"true_predictions","52d6bf86":"test","67162762":"true_predictions = pd.DataFrame(data=true_predictions,columns=test.columns)","943d2dcd":"true_predictions","2652e253":"from tensorflow.keras.models import load_model","b57bf5c7":"model.save(\"multivariate.h5\")","7669b093":"## Train Test Split","5d30c9fb":"**NOTE: PAY CLOSE ATTENTION HERE TO WHAT IS BEING OUTPUTED AND IN WHAT DIMENSIONS. ADD YOUR OWN PRINT() STATEMENTS TO SEE WHAT IS TRULY GOING ON!!**","92c2dbfd":"# Time Series Generator\n\nThis class takes in a sequence of data-points gathered at\nequal intervals, along with time series parameters such as\nstride, length of history, etc., to produce batches for\ntraining\/validation.\n\n#### Arguments\n    data: Indexable generator (such as list or Numpy array)\n        containing consecutive data points (timesteps).\n        The data should be at 2D, and axis 0 is expected\n        to be the time dimension.\n    targets: Targets corresponding to timesteps in `data`.\n        It should have same length as `data`.\n    length: Length of the output sequences (in number of timesteps).\n    sampling_rate: Period between successive individual timesteps\n        within sequences. For rate `r`, timesteps\n        `data[i]`, `data[i-r]`, ... `data[i - length]`\n        are used for create a sample sequence.\n    stride: Period between successive output sequences.\n        For stride `s`, consecutive output samples would\n        be centered around `data[i]`, `data[i+s]`, `data[i+2*s]`, etc.\n    start_index: Data points earlier than `start_index` will not be used\n        in the output sequences. This is useful to reserve part of the\n        data for test or validation.\n    end_index: Data points later than `end_index` will not be used\n        in the output sequences. This is useful to reserve part of the\n        data for test or validation.\n    shuffle: Whether to shuffle output samples,\n        or instead draw them in chronological order.\n    reverse: Boolean: if `true`, timesteps in each output sample will be\n        in reverse chronological order.\n    batch_size: Number of timeseries samples in each batch\n        (except maybe the last one).","7f6921e6":"Now let's put this logic in a for loop to predict into the future for the entire test range.\n\n----","eee49e8e":"## Data\n\nLet's read in the data set:","4ae67e92":"Now you will be able to edit the length so that it makes sense for your time series!","82b6d570":"## Scale Data","40b37f27":"### Lets save our model","25949536":"# Multivariate Time Series with RNN","feef3366":"### Create the Model","c3297a92":"## Evaluate on Test Data","dc410b53":"Let's imagine we want to predict just 24 hours into the future, we don't need 3 months of data for that, so let's save some training time and only select the last months data.","9ca5ea0c":"## Inverse Transformations and Compare","4ce2226f":"Let's also round off the data, to one decimal point precision, otherwise this may cause issues with our network (we will also normalize the data anyways, so this level of precision isn't useful to us)","4dc38162":"## EarlyStopping"}}