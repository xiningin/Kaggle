{"cell_type":{"cc19a07f":"code","63156fce":"code","8c645542":"code","2e05cf83":"code","c32f9ae8":"code","5e4f7b5e":"code","7032d628":"code","4acf1d23":"code","0e480417":"code","ce684cb3":"code","1a7be2b3":"code","0cc9c31d":"code","ef82c1b0":"code","c33be638":"code","4afd7610":"code","f3202e70":"code","eb06abe6":"code","4961dd3c":"code","8a629abc":"code","83bcd1fb":"code","f575e69f":"code","9ec6825f":"code","9b07b0a2":"code","f948c4be":"code","c6b4569c":"code","de7aa0c9":"code","3b438ad7":"code","b45fa254":"code","cdbb204b":"markdown","73ccd333":"markdown","6eacb39a":"markdown","8a15e95b":"markdown","98dbd01f":"markdown","8faafca4":"markdown","a0a93f6e":"markdown","43ea6a3e":"markdown","6837f746":"markdown","852cf15d":"markdown","566ba811":"markdown","9e2e3dd9":"markdown","b838f31a":"markdown"},"source":{"cc19a07f":"!conda install -q -y -c dglteam dgl","63156fce":"import dgl\nimport torch\nfrom dgl.data import MiniGCDataset\nimport matplotlib.pyplot as plt\nimport networkx as nx\n\nfrom dgl.nn.pytorch import GraphConv\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport torch.optim as optim\nfrom dgl.dataloading import GraphDataLoader","8c645542":"# A dataset with 80 samples, each graph is\n# of size [10, 20]\ndataset = MiniGCDataset(80, 10, 20)","2e05cf83":"dataset","c32f9ae8":"# dir(dataset)","5e4f7b5e":"len(dataset)","7032d628":"dataset[0]","4acf1d23":"def plot_data(n):\n    print(dataset[n])\n    graph, label = dataset[n]\n    fig, ax = plt.subplots()\n    nx.draw(graph.to_networkx(), ax=ax)\n    ax.set_title('Class: {:d}'.format(label))\n    plt.show()\n    \nplot_data(0)","0e480417":"#10\u756a\u76ee\nplot_data(10)","ce684cb3":"#20\u756a\u76ee\nplot_data(20)","1a7be2b3":"# Create training and test sets.\ntrainset = MiniGCDataset(320, 10, 20)\ntestset = MiniGCDataset(80, 10, 20)","0cc9c31d":"# Use DGL's GraphDataLoader. It by default handles the\n# graph batching operation for every mini-batch.\ndata_loader = GraphDataLoader(trainset, batch_size=32, shuffle=True)","ef82c1b0":"class Classifier(nn.Module):\n    def __init__(self, in_dim, hidden_dim, n_classes):\n        super(Classifier, self).__init__()\n        self.conv1 = GraphConv(in_dim, hidden_dim)\n        self.conv2 = GraphConv(hidden_dim, hidden_dim)\n        self.classify = nn.Linear(hidden_dim, n_classes)\n\n    def forward(self, g):\n        # Use node degree as the initial node feature. For undirected graphs, the in-degree\n        # is the same as the out_degree.\n        h = g.in_degrees().view(-1, 1).float()\n        # Perform graph convolution and activation function.\n        h = F.relu(self.conv1(g, h))\n        h = F.relu(self.conv2(g, h))\n        g.ndata['h'] = h\n        # Calculate graph representation by averaging all the node representations.\n        hg = dgl.mean_nodes(g, 'h')\n        return self.classify(hg)","c33be638":"# Create model\nmodel = Classifier(1, 256, trainset.num_classes)\nloss_func = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nmodel.train()","4afd7610":"epoch_losses = []\nfor epoch in range(80):\n    epoch_loss = 0\n    for iter, (bg, label) in enumerate(data_loader):\n        prediction = model(bg)\n        loss = loss_func(prediction, label)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.detach().item()\n    epoch_loss \/= (iter + 1)\n    print('Epoch {}, loss {:.4f}'.format(epoch, epoch_loss))\n    epoch_losses.append(epoch_loss)","f3202e70":"plt.title('cross entropy averaged over minibatches')\nplt.plot(epoch_losses)\nplt.show()","eb06abe6":"# model\u3092\u63a8\u8ad6\u30e2\u30fc\u30c9\u306b\u5207\u308a\u66ff\u3048\nmodel.eval()","4961dd3c":"# Convert a list of tuples to two lists\ntest_X, test_Y = map(list, zip(*testset))","8a629abc":"# test_X\u306f\u5b66\u7fd2\u306b\u306f\u4f7f\u3063\u3066\u3044\u306a\u3044\u30c6\u30b9\u30c8\u7528\u306e\u30b0\u30e9\u30d5\u304c80\u500b\u5165\u3063\u3066\u3044\u308b\u30ea\u30b9\u30c8\ntest_X","83bcd1fb":"# test_Y\u306f\u6b63\u89e3\u30af\u30e9\u30b9\u304c80\u500b\u5165\u3063\u3066\u3044\u308b\u30ea\u30b9\u30c8\ntest_Y","f575e69f":"# \u30c6\u30b9\u30c8\u7528\u306e\u30b0\u30e9\u30d5\u306e\u30ea\u30b9\u30c8\u3092`dgl.batch`\u3067\u307e\u3068\u3081\u308b\ntest_bg = dgl.batch(test_X)","9ec6825f":"# \u30c6\u30b9\u30c8\u7528\u306e\u6b63\u89e3\u304c\u5165\u3063\u3066\u3044\u308b\u8981\u7d20\u6570=80\u306e\u30ea\u30b9\u30c8\u3092torch.Tensor;size=(80,1)\u306b\u5909\u63db\u3059\u308b\ntest_Y = torch.tensor(test_Y).float().view(-1, 1)\ntest_Y.shape","9b07b0a2":"# \u63a8\u8ad6\u3055\u305b\u308b\u306b\u306f\u30e2\u30c7\u30eb\u306b`dgl.batch`\u3067\u307e\u3068\u3081\u305f\u30b0\u30e9\u30d5\u3092\u5165\u529b\u3059\u308b\npred = model(test_bg)","f948c4be":"# \u5404\u30b0\u30e9\u30d5 x 8\u30af\u30e9\u30b9\u306e\u4e88\u6e2c\u5024\u304c\u8fd4\u308b\npred.shape","c6b4569c":"# softmax\u3067\u5404\u30b0\u30e9\u30d5 x 8\u30af\u30e9\u30b9\u306e\u78ba\u7387\u5206\u5e03\u306b\u5909\u63db\nprobs_Y = torch.softmax(pred, 1)\nprobs_Y.shape","de7aa0c9":"# \u3053\u3053\u308f\u304b\u3093\u306a\u3044\nsampled_Y = torch.multinomial(probs_Y, 1)\n# sampled_Y","3b438ad7":"# \u306a\u305ctorch.argmax\u3058\u3083\u306a\u3044\u3093\u3060\u308d\u3046\nargmax_Y = torch.max(probs_Y, 1)[1].view(-1, 1)\n# argmax_Y","b45fa254":"print('Accuracy of sampled predictions on the test set: {:.4f}%'.format(\n    (test_Y == sampled_Y.float()).sum().item() \/ len(test_Y) * 100))\nprint('Accuracy of argmax predictions on the test set: {:4f}%'.format(\n    (test_Y == argmax_Y.float()).sum().item() \/ len(test_Y) * 100))","cdbb204b":"# Test","73ccd333":"# Import","6eacb39a":"`dgl.data`\u306e\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u306b\u306f\u914d\u5217\u3063\u307d\u3044\u30a2\u30af\u30bb\u30b9\u304c\u3067\u304d\u308b\u69d8\u5b50","8a15e95b":"# Install DGL","98dbd01f":"## \u308f\u304b\u3063\u305f\u3053\u3068\n- \u3053\u306e\u30c7\u30fc\u30bf\u306f8\u7a2e\u985e\u306e\u5f62\u72b6\u304c\u7570\u306a\u308b80\u500b\u306e\u30b0\u30e9\u30d5\u3092\u542b\u3093\u3067\u3044\u308b\u30c7\u30fc\u30bf\n- \u3053\u306e\u30bf\u30b9\u30af\u306f\u305d\u308c\u305e\u308c\u306e\u30b0\u30e9\u30d5\u306e\u7a2e\u985e\u3092\u4e88\u6e2c\u3055\u305b\u308b\u30bf\u30b9\u30af\n- \u5404\u30b0\u30e9\u30d5\u306f\u30ce\u30fc\u30c9\u6570\u3001\u30a8\u30c3\u30b8\u6570\u304c\u7570\u306a\u3063\u3066\u3044\u308b\u30b0\u30e9\u30d5\n- \u304a\u305d\u3089\u304fdataset[9:0]\u306fclass=0, [19:10]\u306fclass=1\u306e\u30c7\u30fc\u30bf\u3068\u3044\u3046\u611f\u3058\u306b\u306a\u3063\u3066\u3044\u308b->\u8981shaffle","8faafca4":"## Quick look at the Dataset","a0a93f6e":"# Model","43ea6a3e":"\uff10\u756a\u76ee\u306e\u30b0\u30e9\u30d5\u3092\u8868\u793a\u3057\u3066\u307f\u308b","6837f746":"- \u6982\u8981\uff1aDGL\u306e\u30b0\u30e9\u30d5\u5206\u985e\u30b5\u30f3\u30d7\u30eb\u306e\u5199\u7d4c\u3002\n- \u76ee\u7684\uff1adgl\u3068dgl.batch\u306e\u4f7f\u3044\u65b9\u3092\u628a\u63e1\u3059\u308b\n- \u308f\u304b\u3063\u305f\u3053\u3068\uff1adgl.batch\u3092\u4f7f\u3046\u3053\u3068\u3067\u30ce\u30fc\u30c9\u6570\u3001\u30a8\u30c3\u30b8\u6570\u306e\u7570\u306a\u308b\u8907\u6570\u306e\u30b0\u30e9\u30d5\u3092\u5165\u529b\u3068\u3057\u305fgraph classification\u304c\u3067\u304d\u308b\n- \u5fdc\u7528\u3057\u305f\u3044\u3053\u3068\uff1a\u30ce\u30fc\u30c9\u6570\u306e\u7570\u306a\u308b\u8907\u6570\u306e\u30b0\u30e9\u30d5\u3092\u5165\u529b\u306b\u5404\u30ce\u30fc\u30c9\u306e\u5c5e\u6027\u3092\u4e88\u6e2c\u3055\u305b\u308bnode classification\n- reference: https:\/\/docs.dgl.ai\/en\/0.6.x\/tutorials\/basics\/4_batch.html\n\n> To train neural networks efficiently, a common practice is to batch multiple samples together to form a mini-batch. Batching fixed-shaped tensor inputs is common. For example, batching two images of size 28 x 28 gives a tensor of shape 2 x 28 x 28. By contrast, batching graph inputs has two challenges:\n> - Graphs are sparse.\n> -Graphs can have various length. For example, number of nodes and edges.\n>\n> To address this, DGL provides a `dgl.batch()` API. It leverages the idea that a batch of graphs can be viewed as a large graph that has many disjointed connected components. Below is a visualization that gives the general idea.","852cf15d":"# Train","566ba811":"\u3053\u306edataset\u306e\u5834\u5408\u3001(\u30b0\u30e9\u30d5 \u30af\u30e9\u30b9)\u306etuple\u304c\u5165\u3063\u3066\u3044\u308b","9e2e3dd9":"# Data loader","b838f31a":"# Load toy dataset\n> In this tutorial, you learn how to perform batched graph classification with DGL. The example task objective is to classify eight types of topologies shown here.\n> \n> https:\/\/data.dgl.ai\/tutorial\/batch\/dataset_overview.png\n> \n> Implement a synthetic dataset data.MiniGCDataset in DGL. The dataset has eight different types of graphs and each class has the same number of graph samples."}}