{"cell_type":{"0519c473":"code","4cbcd752":"code","abd8220f":"code","817af6d3":"code","93f6fe61":"code","5dff4010":"code","aff528f6":"code","5d4abc0c":"code","884796e6":"code","d66a689e":"code","ce803ba8":"code","bed82d15":"code","3a792f85":"code","fe67d1b2":"code","2a07387e":"code","682198eb":"code","8ce23b99":"code","c2c51520":"code","06b40a0d":"code","85387ac2":"code","4430a960":"code","105b0174":"code","a3bbf7d2":"code","4bbb7514":"code","d24f4ddc":"code","d46547e8":"code","a9a9b45a":"code","6b65dd7c":"code","90ab9ac3":"code","ca559e70":"code","f3383b82":"code","9fa60e1a":"code","4d3e756b":"code","f1f92893":"code","c4a4430b":"code","c23eab1a":"code","f336979c":"markdown","fb2a1f82":"markdown","6ccb24da":"markdown","ba162f20":"markdown","493e8d3a":"markdown","83f1c3a8":"markdown","a4eb5838":"markdown","f05f4561":"markdown","7b3e6851":"markdown","95ca8572":"markdown","9fb14da1":"markdown","03529e33":"markdown","6a99ed09":"markdown","e374a253":"markdown","d9f1de65":"markdown","73388a4d":"markdown","98643d95":"markdown","6839f305":"markdown"},"source":{"0519c473":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4cbcd752":"from sklearn.metrics import accuracy_score\n","abd8220f":"# Carregando os dados\ndf = pd.read_csv('\/kaggle\/input\/costa-rican-household-poverty-prediction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/costa-rican-household-poverty-prediction\/test.csv')\n\ndf.shape, test.shape","817af6d3":"# Juntando os dataframes\ndf_all = df.append(test)\n\ndf_all.shape","93f6fe61":"df_all.head().T\n","5dff4010":"# Quais colunas do dataframe s\u00e3o do tipo object\ndf_all.select_dtypes('object').head()","aff528f6":"# Analisando os dados da coluna edjefa\ndf_all['edjefa'].value_counts()","5d4abc0c":"# Analisando os dados da coluna edjefe\ndf_all['edjefe'].value_counts()","884796e6":"# Vamos transformar 'yes' em 1 e 'no' em 0\n# nas colunas edjefa e edjefe\nmapeamento = {'yes': 1, 'no': 0}\n\ndf_all['edjefa'] = df_all['edjefa'].replace(mapeamento).astype(int)\ndf_all['edjefe'] = df_all['edjefe'].replace(mapeamento).astype(int)","d66a689e":"# Quais colunas do dataframe s\u00e3o do tipo object\ndf_all.select_dtypes('object').head()","ce803ba8":"# Olhando a coluna dependency\ndf_all['dependency'].value_counts()","bed82d15":"# Vamos transformar 'yes' em 1 e 'no' em 0\n# na coluna dependency\ndf_all['dependency'] = df_all['dependency'].replace(mapeamento).astype(float)","3a792f85":"# Quais colunas do dataframe s\u00e3o do tipo object\ndf_all.select_dtypes('object').head()","fe67d1b2":"# Verificando os valores nulos\ndf_all.isnull().sum().sort_values()","2a07387e":"#df_all['meaneduc'].fillna(df_all['meaneduc'].mean(), inplace=True) \n#df_all['v2a1'].fillna(df_all['v2a1'].mean(), inplace=True) \n#df_all['rez_esc'].fillna(df_all['rez_esc'].mean(), inplace=True) \n#df_all['v18q1'].fillna(0, inplace=True)\n#df_all['SQBmeaned'].fillna(df_all['SQBmeaned'].mean(), inplace=True)","682198eb":"df_all['meaneduc'].fillna(df_all['meaneduc'].median(), inplace=True) \ndf_all['v2a1'].fillna(df_all['v2a1'].median(), inplace=True) \ndf_all['rez_esc'].fillna(df_all['rez_esc'].median(), inplace=True) \ndf_all['v18q1'].fillna(0, inplace=True)\ndf_all['SQBmeaned'].fillna(df_all['SQBmeaned'].median(), inplace=True)","8ce23b99":"df_all.isnull().sum().sort_values()","c2c51520":"# Prrenchendo com -1 todos os valores nulos\n#df_all['v2a1'].fillna(-1, inplace=True)\n#df_all['meaneduc'].fillna(-1, inplace=True)\n#df_all['rez_esc'].fillna(-1, inplace=True)\n#df_all['SQBmeaned'].fillna(-1, inplace=True)","06b40a0d":"# Prrenchendo com 0 todos os valores nulos\n#df_all['v18q1'].fillna(0, inplace=True)","85387ac2":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target','edjefe', 'edjefa']]\n#'edjefe', 'edjefa'","4430a960":"# Separar os dataframes\ntrain, test = df_all[~df_all['Target'].isnull()], df_all[df_all['Target'].isnull()]\n\ntrain.shape, test.shape","105b0174":"# Instanciando o random forest classifier\n#from sklearn.ensemble import RandomForestClassifier\n\n#rf = RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=42, n_estimators=200)\n#0.36736\n\n\n","a3bbf7d2":"rf.fit(train[feats], train['Target'])","4bbb7514":"accuracy_score(train['Target'], rf.predict(train[feats]))\n","d24f4ddc":"preds_val = rf.predict(train[feats])","d46547e8":"# importando a bilbioteca para plotar o gr\u00e1fico de Matriz de Confus\u00e3o\n#from sklearn.metrics import confusion_matrix\n#confusion_matrix(train, preds_val)\n\n\n# importando a bilbioteca para plotar o gr\u00e1fico de Matriz de Confus\u00e3o\n import scikitplot as skplt\n\n","a9a9b45a":"#from xgboost import XGBClassifier\nrf2 = XGBClassifier(n_estimators=200, learning_rate=0.09, random_state=42)\n# 0.38378\n","6b65dd7c":"rf2.fit(train[feats], train['Target'])\naccuracy_score(train['Target'], rf2.predict(train[feats]))\n","90ab9ac3":"#from sklearn.ensemble import GradientBoostingClassifier\nrf3 = GradientBoostingClassifier(n_estimators=200, learning_rate=1.0, max_depth=1, random_state=42)\n#0.37065","ca559e70":"rf3.fit(train[feats], train['Target'])\naccuracy_score(train['Target'], rf3.predict(train[feats]))","f3383b82":"# Copiando do campe\u00e3o\n\nrf = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=700,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,\n                            verbose=0, class_weight='balanced')","9fa60e1a":"rf.fit(train[feats], train['Target'])\naccuracy_score(train['Target'], rf.predict(train[feats]))","4d3e756b":"# Treinando o modelo\nrf.fit(train[feats], train['Target'])","f1f92893":"# Prever o Target de teste usando o modelo treinado\ntest['Target'] = rf.predict(test[feats]).astype(int)","c4a4430b":"# Vamos verificar as previs\u00f5es\ntest['Target'].value_counts(normalize=True)","c23eab1a":"# Criando o arquivo para submiss\u00e3o\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","f336979c":"# XGBboost","fb2a1f82":"#### ser\u00e1 feito tratamento nos dados 'meaneduc', 'v2a1','v18q1' , 'rez_esc' e 'SQBmeaned'","6ccb24da":"# Relat\u00f3rio\n\n### Foram realizados 4 testes com modelos diferentes e o melhor resultado foi com o random forest balanceado. \nhttps:\/\/www.kaggle.com\/simonesymon\/1931133125\/log?scriptVersionId=42034868\n### Realizei v\u00e1rios testes alterando as variaveis para usar a m\u00e9dia, mediana e moda. Alterei tamb\u00e9m a quest\u00e3o da retirada de variaveis para gerar os modelos de treino e teste. Foram praticamente 2 dias testando.\n### Achei super interessante fazer esse trabalho e cheguei a conclus\u00e3o que preciso estudar mais para ter dom\u00ednio sobre os modelos a serem constru\u00eddos. Tive dificuldades por conta do idioma, meu ingl\u00eas est\u00e1 enferrujado e vou ter que correr atr\u00e1s.\n\n\n\n","ba162f20":"# GBM","493e8d3a":"# Random Foret Classifier ","83f1c3a8":"# Treinando os modelos","a4eb5838":"sera feito um tratamento nos dados no e yes","f05f4561":"coluna com tipo texto que devem ser tratadas.\nid e idhobar n\u00e3o precisam ser tratadas","7b3e6851":"Foi realizado o teste e o melhor score conseguido foi de **0.43480**. Foi feito testes inserindo m\u00e9dia, mediana e moda nos dados missing.","95ca8572":"#### Foi realizado o teste e o melhor score conseguido foi de 0.38378. Foi feito testes inserindo m\u00e9dia, mediana e moda nos dados missing.","9fb14da1":"# Trabalho final\n\nSimone Gomes\n\n1931133125","03529e33":"### Random Forest","6a99ed09":"verificou-se que tem 22075 que n\u00e3o tem escolaridade. Ser\u00e1 feito um tratamento no dado NO e yes","e374a253":"verificou-se que 12818 chefes de fam\u00edlia n\u00e3o tem escolaridade. Ser\u00e1 feito um tratamento no campo NO e yes","d9f1de65":"9557 linhas pra treinar e 23856 linhas pra prever","73388a4d":"## Tratamento nos dados","98643d95":"#### Foi realizado o teste e o melhor score conseguido foi de 0.36736. Foi feito testes inserindo m\u00e9dia, mediana e moda nos dados missing.","6839f305":"Foi realizado o teste e o melhor score conseguido foi de 0.37065. Foi feito testes inserindo m\u00e9dia, mediana e moda nos dados missing."}}