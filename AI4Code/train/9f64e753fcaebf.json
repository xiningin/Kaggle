{"cell_type":{"9a6dc53e":"code","2b2513fa":"code","14d16a45":"code","097a217d":"code","dc5a8451":"code","ab87a6d1":"code","3bb791b6":"code","cc701365":"code","262609ad":"code","c5493cea":"code","d8d2ab2a":"code","0d1e6faa":"code","e97fc987":"code","5f029b15":"code","67e8bbd7":"code","0f1fe43f":"code","e917d8b3":"code","27130424":"code","ab64aadc":"code","7eb985e9":"code","aea9360e":"code","9d624b5d":"markdown","c0a057c3":"markdown","74f70ca3":"markdown","d20614a9":"markdown","5ce30c91":"markdown","442af399":"markdown","ae8632c2":"markdown","7c12e130":"markdown","1f889071":"markdown","6715d21a":"markdown","5123f2b4":"markdown"},"source":{"9a6dc53e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport folium\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt # import matplotlib\n%matplotlib inline\nimport seaborn as sns # seaborn data visualizer\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2b2513fa":"food_waste = pd.read_csv('..\/input\/brooklyn-food-waste\/brooklyn.csv')","14d16a45":"food_waste.head()","097a217d":"# Create dataframe that sums the total approximate dollar value\n# in the dumpster based on geographic loc as well as retailer data\ndf = food_waste.groupby(['collection_lat',\t'collection_long'\t,\n                           'retailer_type',\t'retailer_detail', ])['approximate_dollar_value'].sum()\ndf = df.reset_index()","dc5a8451":"loc_data = pd.DataFrame()\nloc_data['latitude'] = df['collection_lat']\nloc_data['longitude'] = df['collection_long']\nloc_data['retailer_type'] = df['retailer_type']\nloc_data['dollar_value_total'] = df['approximate_dollar_value']","ab87a6d1":"#create a map using latitude and longitude, respectively, of general Brooklyn through a google search\nmap=folium.Map(location=[40.6782,-73.99447], zoom_start=12)\n\n#create a feature group to add to the map\ndumpsters = folium.map.FeatureGroup()\n\n#create loop to add location of dumpsters to the map\nfor lat, lon, in zip(loc_data.latitude, loc_data.longitude):\n    dumpsters.add_child(\n        folium.features.CircleMarker(\n            [lat,lon],\n            radius= 8,\n            color= 'blue',\n            fill= True,\n            fill_color= 'red',\n            fill_opacity=0.7\n        )\n    )\n    \n#adding some text to markers\nlatitudes = list(loc_data.latitude)\nlongitudes = list(loc_data.longitude)\nstore_label = loc_data.retailer_type\ndollar_label= loc_data.dollar_value_total.round(2)\n\nfor lat, lon, label1, label2 in zip(latitudes, longitudes, store_label,dollar_label ):\n    folium.Marker([lat, lon], popup=[label1, label2]).add_to(map)\n\n#add features to map\nmap.add_child(dumpsters)","3bb791b6":"food_waste['label_language'].value_counts()","cc701365":"food_waste['retailer_type'].value_counts()","262609ad":"food_waste[['date_collected','label_date']] = food_waste[['date_collected', 'label_date']]\\\n.apply(pd.to_datetime, format ='%Y-%m-%d', errors='coerce')","c5493cea":"food_waste.head()","d8d2ab2a":"food_waste['label_type'].value_counts()","0d1e6faa":"food_waste['food_type'].value_counts()","e97fc987":"food_waste['time_elapsed'] = food_waste['label_date']-food_waste['date_collected']\nfood_waste.time_elapsed.fillna('0 days', inplace=True)\nfood_waste['time_delta'] = food_waste.time_elapsed\/pd.Timedelta(days=1)\nfood_waste['time_delta'] = food_waste['time_delta'].astype(int)","5f029b15":"food_type_bar = food_waste.groupby('food_type')['time_delta'].mean()","67e8bbd7":"food_type_bar.plot.bar()\n\nplt.show()","0f1fe43f":"plt.figure(dpi=100, figsize=(8, 5))\n\nsns.stripplot(x=food_waste['food_type'], y=food_waste['time_delta'])","e917d8b3":"retailer_type_bar = food_waste.groupby('retailer_type')['time_delta'].mean()\n\nretailer_type_bar.plot.bar()\n\nplt.figure(dpi=100, figsize=(8, 5)).show()","27130424":"plt.figure(dpi=100, figsize=(10, 5))\n\nsns.stripplot(x=food_waste['retailer_type'], y=food_waste['time_delta'])","ab64aadc":"from sklearn.feature_selection import mutual_info_regression\n\n# Define a function to calculate the MI scores of features\ndef make_mi_scores(X, y):\n    mi_scores = mutual_info_regression(X, y)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\n# Define a function to plot the MI scores of features\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")\n","7eb985e9":"X = food_waste.copy()\ny = X.pop('time_delta')\n\nfor colname in X.select_dtypes(\"object\"):\n    X[colname], _ = X[colname].factorize()\n    \nfeatures = ['retailer_type','food_type','collection_lat','collection_long']\nmi_scores = make_mi_scores(X[features],y)","aea9360e":"plt.figure(dpi=100, figsize=(8, 5))\nplot_mi_scores(mi_scores)","9d624b5d":"Below is a bar chart that shows the mean time elapsed (in days) by food type. ","c0a057c3":"I will create a new feature called 'time_elapsed' which measures the difference, in days, between the date on the label and the date that the food waste was collected. If the number of days is positive, then the food was thrown away before the date on the label.","74f70ca3":"We can see that we only have four data points for the \"shelf stable\" food type, so any information about it is less reliable. Entries with shelf stable as a food type also have far more variance in the time elapsed between the label date and the date the food was collected.","d20614a9":"As the plot reveals, larger retailers like drugstores and health food grocer's have a much larger, positive, time between the date on the label and the date the food waste was collected. This suggests that drug stores and health food grocers are more likely to throw food away earlier, but the data collected so far is not decisive enough. \n\nNext, I will employ a statistical technique called mutual information to see if the food type or retailer type actually contains any meaningful information about the time elapsed between the date on the label and the date the food was collected.","5ce30c91":"Let's try to identify some unique values in the 'label_language' column:","442af399":"We can begin by reading in the csv file into a pandas dataframe.","ae8632c2":"# Geographic Data Visualization #\n\nI will use python's folium library to show the total food waste (in US dollars) in each dumpster in Brooklyn. ","7c12e130":"I will examine what the mean time elapsed is for each food type.","1f889071":"Now I will format the 'date_collected' column:","6715d21a":"Stable shelf food appears to be thrown away far earlier than the other food types. We can look at this more deeply with what's called a \"strip plot\", which is essentially a scatter plot that is able to handle categorical data. ","5123f2b4":"# Data Visualization #"}}