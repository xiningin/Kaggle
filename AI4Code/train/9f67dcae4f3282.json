{"cell_type":{"ba08b147":"code","0135e7e4":"code","1d6fa480":"code","8991963f":"code","f618a58f":"code","be8f0db5":"code","5dd3c3ef":"code","2d500b62":"code","ba93da06":"code","e40f36fb":"code","575978a1":"code","ebab94d0":"code","5bab83f3":"code","ee701b4b":"code","94226edc":"code","2a2ee33f":"code","14b9ea92":"code","49dcea90":"code","a815a07e":"code","9c8ca22c":"code","789af98c":"code","01ca870d":"code","e0b484b7":"code","58d67ffc":"code","8011fa7a":"code","d513087d":"code","de18b07a":"code","e7501b66":"code","7c546f02":"code","efc0657e":"code","1fa9db0d":"code","03d3393b":"code","b712a06b":"code","9cd5f2ec":"code","77209fc5":"code","8299a6a3":"markdown","14e03550":"markdown","cbdfa4f4":"markdown","b4c94232":"markdown","6423d50b":"markdown","0347c7a2":"markdown","0dd47d7b":"markdown","8eca8f63":"markdown","3f10b3cb":"markdown"},"source":{"ba08b147":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0135e7e4":"import pandas as pd\nimport numpy as np\nimport random as rnd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","1d6fa480":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest  = pd.read_csv('..\/input\/titanic\/test.csv')","8991963f":"print(train.columns.values)\n","f618a58f":"train.info()","be8f0db5":"train.describe()","5dd3c3ef":"sns.set()\ncols = ['PassengerId', 'Survived', 'Pclass' ,'Name', 'Sex', 'Age' ,'SibSp', 'Parch', 'Ticket' ,'Fare', 'Cabin' ,'Embarked']\nsns.pairplot(train[cols], size = 2.5)\nplt.show();\n","2d500b62":"train.head()","ba93da06":"sns.FacetGrid(train,hue='Survived',height=8).map(sns.distplot,'Age').set_axis_labels('Age',\n'Survived').add_legend()\nplt.show()","e40f36fb":"survived = 'survived'\nnot_survived = 'not survived'\nfig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10, 4))\nwomen = train[train['Sex']=='female']\nmen = train[train['Sex']=='male']\nax = sns.distplot(women[women['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[0], kde =False)\nax = sns.distplot(women[women['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[0], kde =False)\nax.legend()\nax.set_title('Female')\nax = sns.distplot(men[men['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[1], kde = False)\nax = sns.distplot(men[men['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[1], kde = False)\nax.legend()\n_ = ax.set_title('Male')","575978a1":"sns.barplot(x='Pclass', y='Survived', data=train)","ebab94d0":"grid = sns.FacetGrid(train, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","5bab83f3":"sns.barplot(x='Sex', y='Survived', data=train)\n","ee701b4b":"#correlation matrix\ncorrmat = train.corr()\nf, ax = plt.subplots(figsize=(15, 8))\nsns.heatmap(corrmat, vmax=.8, annot=True);","94226edc":"FacetGrid = sns.FacetGrid(train, row='Embarked', size=4.5, aspect=1.6)\nFacetGrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette=None,  order=None, hue_order=None )\nFacetGrid.add_legend()","2a2ee33f":"train.PassengerId[train.Cabin.notnull()].count()","14b9ea92":"train.PassengerId[train.Age.notnull()].count()\n","49dcea90":"train.Age = train.Age.median()","a815a07e":"train[train.Embarked.isnull()]\n","9c8ca22c":"MaxPassEmbarked = train.groupby('Embarked').count()['PassengerId']\ntrain.Embarked[train.Embarked.isnull()] = MaxPassEmbarked[MaxPassEmbarked == MaxPassEmbarked.max()].index[0]\n","789af98c":"train.PassengerId[train.Fare.isnull()]","01ca870d":"train = train.drop(['PassengerId','Name','Ticket','Cabin'],axis=1)\ntrain","e0b484b7":"from sklearn.preprocessing import LabelEncoder\nlabel = LabelEncoder()\ndicts = {}\n\nlabel.fit(train.Sex.drop_duplicates())\ndicts['Sex'] = list(label.classes_)\ntrain.Sex = label.transform(train.Sex)  \n\nlabel.fit(train.Embarked.drop_duplicates())\ndicts['Embarked'] = list(label.classes_)\ntrain.Embarked = label.transform(train.Embarked)","58d67ffc":"train","8011fa7a":"test","d513087d":"test.Age[test.Age.isnull()] = test.Age.mean()\ntest.Fare[test.Fare.isnull()] = test.Fare.median() \nMaxPassEmbarked = test.groupby('Embarked').count()['PassengerId']\ntest.Embarked[test.Embarked.isnull()] = MaxPassEmbarked[MaxPassEmbarked == MaxPassEmbarked.max()].index[0]\nresult = pd.DataFrame(test.PassengerId)\ntest = test.drop(['Name','Ticket','Cabin','PassengerId'],axis=1)\n\nlabel.fit(dicts['Sex'])\ntest.Sex = label.transform(test.Sex)\n\nlabel.fit(dicts['Embarked'])\ntest.Embarked = label.transform(test.Embarked)","de18b07a":"test","e7501b66":"y = train.Survived\ntrain = train.drop(['Survived'], axis=1)","7c546f02":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(train,y,test_size = 0.22,shuffle = True, random_state=0)","efc0657e":"from sklearn.preprocessing import StandardScaler\nscalerModel = StandardScaler(copy=True, with_mean=True, with_std=True)\nX_train = scalerModel.fit_transform(X_train)","1fa9db0d":"X_train","03d3393b":"X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.2) ","b712a06b":"from sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nmodel_rfc = RandomForestClassifier(n_estimators = 70, max_features='auto', criterion='entropy',max_depth=4)\nmodel_knc = KNeighborsClassifier(n_neighbors = 15) \nmodel_lr = LogisticRegression(penalty='l2', tol=0.01) \nmodel_svc = svm.SVC() ","9cd5f2ec":"import pylab as pl\nfrom sklearn.metrics import roc_curve, auc\npl.clf()\nplt.figure(figsize=(8,6))\n#SVC\nmodel_svc.probability = True\nprobas = model_svc.fit(X_train, y_train).predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, probas[:, 1])\nroc_auc  = auc(fpr, tpr)\npl.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % ('SVC', roc_auc))\n#RandomForestClassifier\nprobas = model_rfc.fit(X_train, y_train).predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, probas[:, 1])\nroc_auc  = auc(fpr, tpr)\npl.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % ('RandonForest',roc_auc))\n#KNeighborsClassifier\nprobas = model_knc.fit(X_train, y_train).predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, probas[:, 1])\nroc_auc  = auc(fpr, tpr)\npl.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % ('KNeighborsClassifier',roc_auc))\n#LogisticRegression\nprobas = model_lr.fit(X_train, y_train).predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, probas[:, 1])\nroc_auc  = auc(fpr, tpr)\npl.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % ('LogisticRegression',roc_auc))\npl.plot([0, 1], [0, 1], 'k--')\npl.xlim([0.0, 1.0])\npl.ylim([0.0, 1.0])\npl.xlabel('False Positive Rate')\npl.ylabel('True Positive Rate')\npl.legend(loc=0, fontsize='small')\npl.show()","77209fc5":"model_rfc.fit(train, y)\nresult.insert(1,'Survived', model_rfc.predict(test))\nresult.to_csv('Titanic Disaster_pred.csv', index=False)","8299a6a3":"## Embarked, Pclass and Sex","14e03550":"## Data Preprocessing","cbdfa4f4":"## Data analysis and Viualization","b4c94232":"## Knowing the survivors of this disaster by Pclass","6423d50b":"## Find out how many survivors and who died in total","0347c7a2":"### Missing Values","0dd47d7b":"## Dealing With Categorical Data","8eca8f63":"## Model","3f10b3cb":"## Knowing the survivors of this disaster by age and gender"}}