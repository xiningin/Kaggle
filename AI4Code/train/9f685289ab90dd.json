{"cell_type":{"9784aed3":"code","639c470e":"code","6124994d":"code","330b8dc5":"code","c5cd9daf":"code","e557b328":"code","f983d044":"code","11ee71f3":"code","845e5498":"code","60db8341":"code","bf42719a":"code","860268d0":"code","34051725":"code","694d4d96":"code","4fadb02b":"code","209aca1d":"code","2b72adc9":"code","0eb69900":"markdown","7818587b":"markdown","cba82a22":"markdown","4b7fb80b":"markdown","56f7f837":"markdown","6bdacba8":"markdown","4a580903":"markdown","2651a12a":"markdown","47b4fc82":"markdown","2e638cc6":"markdown","b14d56f5":"markdown","92ce40d8":"markdown","6fde3a3d":"markdown","605868c6":"markdown","19c88e65":"markdown","7da6075e":"markdown","6da98f82":"markdown"},"source":{"9784aed3":"import io\nimport random\nimport string\nimport warnings\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nimport nltk\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.corpus import words\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem import PorterStemmer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.sentiment.util import *\n\n\n# sklearn imports\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import metrics\n\n\n# python imports\nimport re\nimport json\nimport os\nfrom collections import Counter\nimport datetime as dt\n\n\n# Visualization\nfrom matplotlib import pyplot as plt\nfrom matplotlib import ticker\nimport seaborn as sns\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\nfrom wordcloud import WordCloud\nfrom tqdm import tqdm_notebook\n\n\n# Saving models\nimport pickle","639c470e":"data_dir = '..\/input\/covid19tweets\/data'\ntweets = []\nfor file in sorted(os.listdir(data_dir)):\n    tweets.append(pd.read_csv(data_dir + '\/' + file, lineterminator = '\\n'))\n#     print(file)\n\ndf = pd.concat(tweets)\ndf.tail()","6124994d":"fig = plt.figure(figsize=(20,8))\nax = fig.add_subplot(111)\nax.set(title='Temporal tweet frequency worldwide', xlabel='Time', ylabel='Tweet frequency per hour')\nplt.hist(pd.to_datetime(df.created_at), bins = 24*9, color = 'b')\nplt.show()","330b8dc5":"text_en = df['text']","c5cd9daf":"text_en_lr = text_en.apply(lambda x: re.sub(r\"https\\S+\", \"\", str(x)))\ntext_en_lr.head()","e557b328":"text_en_lr_lc = text_en_lr.apply(lambda x: x.lower())\ntext_en_lr_lc.head()","f983d044":"text_en_lr_lc_pr = text_en_lr_lc.apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\ntext_en_lr_lc_pr.head()","11ee71f3":"stop_words = set(stopwords.words('english'))\nstop_words.update(['#coronavirus', '#coronavirusoutbreak', '#coronavirusPandemic', '#covid19', '#covid_19', '#epitwitter', '#ihavecorona', 'amp', 'coronavirus', 'covid19'])\n\ntext_en_lr_lc_pr_sr = text_en_lr_lc_pr.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\ntext_en_lr_lc_pr_sr.head()","845e5498":"word_list = [word for line in text_en_lr_lc_pr_sr for word in line.split()]\nword_list[:5]","60db8341":"sns.set(style=\"darkgrid\")\ncounts = Counter(word_list).most_common(50)\ncounts_df = pd.DataFrame(counts)\ncounts_df\ncounts_df.columns = ['word', 'frequency']\n\nfig, ax = plt.subplots(figsize = (12, 12))\nax = sns.barplot(y=\"word\", x='frequency', ax = ax, data=counts_df)\nplt.savefig('wordcount_bar.png')","bf42719a":"wordcloud = WordCloud(\n    background_color='black',\n    max_words=50,\n    max_font_size=40, \n    scale=5,\n    random_state=1,\n    collocations=False,\n    normalize_plurals=False\n).generate(' '.join(word_list))\n\n\nplt.figure(figsize = (12, 10), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\n\nplt.savefig('wordcloud.png')\n\n","860268d0":"sid = SentimentIntensityAnalyzer()\nsentiment_scores = text_en_lr_lc_pr_sr.apply(lambda x: sid.polarity_scores(x))\nsent_scores_df = pd.DataFrame(list(sentiment_scores))\nsent_scores_df.tail()","34051725":"sent_scores_df['val'] = sent_scores_df['compound'].apply(lambda x: 'neutral' if x == 0 else ('positive' if x > 0 else 'negative'))\nsent_scores_df.head()","694d4d96":"sent_counts = pd.DataFrame.from_dict(Counter(sent_scores_df['val']), orient = 'index').reset_index()\nsent_counts.columns = ['sentiment', 'count']\n\nsns.barplot(y=\"count\", x='sentiment', data=sent_counts)\nplt.savefig('sentiment.png')","4fadb02b":"sentiments_time_df = pd.DataFrame()\nsentiments_time_df['time'] = df['created_at']\nsentiments_time_df['polarity'] = sent_scores_df['compound']\nsentiments_time_df.index = pd.to_datetime(sentiments_time_df['time'])\n\n\not = sentiments_time_df.sample(frac=.001)\not['time'] = pd.to_datetime(ot['time'])\not.index = pd.to_datetime(ot['time'])\not.sort_index(inplace=True)\not['expanding'] = ot['polarity'].expanding().mean()\not['rolling'] = ot['polarity'].rolling('1h').mean()\n\nfig = plt.figure(figsize=(20,5))\nax = fig.add_subplot(111)\nax.scatter(ot['time'],ot['polarity'], label='Tweet Sentiment', s = 10, color = 'y')\nax.plot(ot['time'],ot['rolling'], color ='r', label='Rolling Mean', linewidth = 5)\nax.plot(ot['time'],ot['expanding'], color='b', label='Expanding Mean', linewidth = 5)\nax.set_xlim([dt.date(2020,5,1),dt.date(2020,5,9)])\nax.set(title='Tweet Sentiments over Time', xlabel='Date', ylabel='Sentiment polarity')\nax.legend(loc='best')\nfig.tight_layout()\nplt.savefig('temporal_sentiments.png')\n","209aca1d":"fig = plt.figure(figsize=(10,5))\nax = fig.add_subplot(111)\nax.set(title='Tweet Sentiments distribution', xlabel='polarity', ylabel='frequency')\nsns.distplot(sentiments_time_df['polarity'], bins=30, ax=ax)\n# plt.show()\nplt.savefig('sentiment_distribution.png')","2b72adc9":"polar_tweets_df = pd.DataFrame()\npolar_tweets_df['tweet'] = text_en_lr_lc_pr_sr\npolar_tweets_df['polarity'] = sent_scores_df['val']\n\npositive = polar_tweets_df[polar_tweets_df['polarity'] == 'positive']['tweet']\nnegative = polar_tweets_df[polar_tweets_df['polarity'] == 'negative']['tweet']\nneutral = polar_tweets_df[polar_tweets_df['polarity'] == 'neutral']['tweet']\n\npositive_list = [word for line in positive for word in line.split()]\nnegative_list = [word for line in negative for word in line.split()]\nneutral_list = [word for line in neutral for word in line.split()]\n\npositive_cloud = WordCloud(\n    background_color='black',\n    max_words=50,\n    max_font_size=40, \n    scale=5,\n    random_state=1,\n    collocations=False,\n    normalize_plurals=False\n).generate(' '.join(positive_list))\n\nnegative_cloud = WordCloud(\n    background_color='black',\n    max_words=50,\n    max_font_size=40, \n    scale=5,\n    random_state=1,\n    collocations=False,\n    normalize_plurals=False\n).generate(' '.join(negative_list))\n\nneutral_cloud = WordCloud(\n    background_color='black',\n    max_words=50,\n    max_font_size=40, \n    scale=5,\n    random_state=1,\n    collocations=False,\n    normalize_plurals=False\n).generate(' '.join(neutral_list))\n\n\nfig, axs = plt.subplots(2, 2, figsize = (20, 12))\n# fig.suptitle('Clouds of polar words', fontsize = 30)\nfig.tight_layout(pad = 0)\n\naxs[0, 0].imshow(positive_cloud)\naxs[0, 0].set_title('Words from positive tweets', fontsize = 20)\naxs[0, 0].axis('off')\n# axs[0, 0].tight_layout(pad = 1)\n\naxs[0, 1].imshow(negative_cloud)\naxs[0, 1].set_title('Words from negative tweets', fontsize = 20)\naxs[0, 1].axis('off')\n# axs[0, 1].tight_layout(pad = 1)\n\naxs[1, 0].imshow(neutral_cloud)\naxs[1, 0].set_title('Words from neutral tweets', fontsize = 20)\naxs[1, 0].axis('off')\n# axs[1, 0].tight_layout(pad = 1)\n\naxs[1, 1].imshow(wordcloud)\naxs[1, 1].set_title('Words from all tweets', fontsize = 20)\naxs[1, 1].axis('off')\n# axs[1, 0].tight_layout(pad = 1)\nplt.savefig('joint_cloud.png')\n\n","0eb69900":"### Calculating the Term Frequency","7818587b":"### Word cloud of polar words","cba82a22":"### Reading the tweets","4b7fb80b":"## Sentiment Analysis","56f7f837":"### Plotting the sentiment score counts","6bdacba8":"### Concatenating all the tweets into a list of words","4a580903":"### Classifying the scores based on the compount polarity value","2651a12a":"### Getting the polarity scores for each tweet","47b4fc82":"### Temporal plot of the sentiments","2e638cc6":"### Picking out the tweet texts","b14d56f5":"### Converting all tweets to lowercase","92ce40d8":"### Removing URLs from tweets","6fde3a3d":"### Removing stopwords","605868c6":"### Removing punctuations","19c88e65":"### Temporal frequency of tweets","7da6075e":"### Libraries","6da98f82":"### Sentiment scores distribution"}}