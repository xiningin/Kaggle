{"cell_type":{"094bfc82":"code","94d414fc":"code","cc34ec2c":"code","44541bee":"code","02f8c0f3":"code","3db4af3d":"code","c3cfc4d7":"code","ed7322c9":"code","f46c3fdf":"code","aa691766":"code","14427e4c":"code","cc000bed":"code","4ef0e9d8":"code","bd15ccfa":"code","d17cd2d5":"code","9ef82288":"code","326a8019":"code","bc711783":"code","c7722fec":"code","0113f289":"code","44e780a6":"code","23bb744e":"code","85b4c0ae":"code","6131244e":"code","ef23eee8":"code","7ba4ca82":"code","7c97d07c":"code","2c6e96fd":"code","4ec71c9e":"code","9f512992":"code","322d18a9":"markdown","e5f88b26":"markdown","0afeffe8":"markdown","6de60e50":"markdown","348c1dd9":"markdown","1e3a2c4d":"markdown","074f9be1":"markdown","aceb7480":"markdown","2c5f8813":"markdown","8141e503":"markdown","fcadee12":"markdown","0cd1b082":"markdown","be6a9e12":"markdown","64d28498":"markdown","8cafa6ca":"markdown","e2ee43e5":"markdown","f04ed785":"markdown","e6503c18":"markdown","6a67a256":"markdown"},"source":{"094bfc82":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport warnings\nimport time\n%matplotlib inline\nwarnings.filterwarnings('ignore')","94d414fc":"from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\nclassifier=[]\nimported_as=[]\n\n#MultiLayerPerceptron\nfrom sklearn.neural_network import MLPClassifier\nmlp=MLPClassifier()\nclassifier.append('Multi Layer Perceptron')\nimported_as.append('mlp')\n\n#Bagging\nfrom sklearn.ensemble import BaggingClassifier\nbc = BaggingClassifier()\nclassifier.append('Bagging')\nimported_as.append('bc')\n\n#GBC\nfrom sklearn.ensemble import GradientBoostingClassifier\ngbc = GradientBoostingClassifier()\nclassifier.append('Gradient Boosting')\nimported_as.append('gbc')\n\n#ADA\nfrom sklearn.ensemble import AdaBoostClassifier\nada = AdaBoostClassifier()\nclassifier.append('Ada Boost')\nimported_as.append('ada')\n\n#XGB\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier() \nclassifier.append('XG Boost')\nimported_as.append('xgb')\n\n# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nclassifier.append('Logistic Regression')\nimported_as.append('lr')\n\n#RFC\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\nclassifier.append('Random Forest')\nimported_as.append('rfc')\n\n#KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=1)\nclassifier.append('k Nearest Neighbours')\nimported_as.append('knn')\n\n#SVM\nfrom sklearn.svm import SVC\nsvc = SVC()\nclassifier.append('Support Vector Machine')\nimported_as.append('svc')\n\n#Grid\nfrom sklearn.model_selection import GridSearchCV\nparam_grid = {'C': [0.1,1, 10, 100, 1000,2000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']} \ngrid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\nclassifier.append('SVM tuning grid')\nimported_as.append('grid')\n\n#STcaking\nfrom sklearn.ensemble import StackingClassifier\nestimators=[('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n            ('svr',SVC(random_state=42))]\nstc = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\nclassifier.append('Stacked (RFR & SVM)')\nimported_as.append('stc')\n\nclassifiers = pd.DataFrame({'Classifier':classifier,'Imported as':imported_as})\nprint('All Models Imported\\nModels stored in dataframe called classifiers')","cc34ec2c":"class Modelling:\n    def __init__(self, X_train, Y_train, X_test, Y_test, models):\n        self.X_train = X_train\n        self.X_test = X_test\n        self.Y_train = Y_train\n        self.Y_test = Y_test\n        self.models = models\n    \n    def fit(self):\n        model_acc = []\n        model_time= []\n        for i in self.models:\n            start=time.time()\n            if i == 'knn':\n                accuracy = []\n                for j in range(1,200):    \n                    kn = KNeighborsClassifier(n_neighbors=j)\n                    kn.fit(self.X_train,self.Y_train)\n                    predK = kn.predict(self.X_test)\n                    accuracy.append([accuracy_score(self.Y_test,predK),j])\n                temp = accuracy[0]\n                for m in accuracy:\n                    if temp[0] < m[0]:\n                        temp=m\n                i = KNeighborsClassifier(n_neighbors=temp[1])\n            i.fit(self.X_train,self.Y_train)\n            model_acc.append(accuracy_score(self.Y_test,i.predict(self.X_test)))\n            stop=time.time()\n            model_time.append((stop-start))\n            print(i,'has been fit')\n        self.models_output = pd.DataFrame({'Models':self.models,'Accuracy':model_acc,'Runtime (s)':model_time})\n        \n    def results(self):\n        models=self.models_output\n        models = models.sort_values(by=['Accuracy','Runtime (s)'],ascending=[False,True]).reset_index().drop('index',axis=1)\n        self.best = models['Models'][0]\n        models['Models']=models['Models'].astype(str).str.split(\"(\", n = 2, expand = True)[0]\n        models['Accuracy']=models['Accuracy'].round(5)*100\n        self.models_output_cleaned=models\n        return(models)\n        \n    def best_model(self,type):\n        if type=='model':\n            return(self.best)\n        elif type=='name':\n            return(self.models_output_cleaned['Models'][0])\n    \n    def best_model_accuracy(self):\n        return(self.models_output_cleaned['Accuracy'][0])\n    \n    def best_model_runtime(self):\n        return(round(self.models_output_cleaned['Runtime (s)'][0],3))\n    \n    def best_model_predict(self,X_test):\n        return(self.best.predict(X_test))\n    \n    def best_model_clmatrix(self):\n        return(classification_report(self.Y_test,self.best.predict(self.X_test)))\n    \n    def best_confusion(self):\n        return(confusion_matrix(self.Y_test,self.best.predict(self.X_test)))","44541bee":"data = pd.read_csv('..\/input\/engineering-placements-prediction\/collegePlace.csv')","02f8c0f3":"data.head()","3db4af3d":"sns.set_style('darkgrid')\nsns.set_context('notebook')\nsns.set_palette('rainbow')","c3cfc4d7":"data.info()","ed7322c9":"data.isnull().sum()","f46c3fdf":"sns.countplot(data=data,x='PlacedOrNot')","aa691766":"sns.histplot(data=data,x='Age',kde=True)","14427e4c":"sns.boxplot(data=data,y='CGPA',x='PlacedOrNot')","cc000bed":"plt.figure(figsize=(10,5))\nsns.barplot(data=pd.DataFrame(data.groupby('CGPA').mean()['PlacedOrNot']).reset_index().rename(columns = {'PlacedOrNot':'Placement Possibility'}, inplace = False),\n           x='CGPA',\n           y='Placement Possibility')","4ef0e9d8":"plt.figure(figsize=(5,5))\nsns.barplot(data=pd.DataFrame(data.groupby('Gender').mean()['PlacedOrNot']).reset_index().rename(columns = {'PlacedOrNot':'Placement Possibility'}, inplace = False),\n           x='Gender',\n           y='Placement Possibility')","bd15ccfa":"plt.figure(figsize=(10,5))\nsns.barplot(data=pd.DataFrame(data.groupby('Internships').mean()['PlacedOrNot']).reset_index().rename(columns = {'PlacedOrNot':'Placement Possibility'}, inplace = False),\n           x='Internships',\n           y='Placement Possibility')","d17cd2d5":"plt.figure(figsize=(20,5))\nsns.countplot(data=data[data['PlacedOrNot']==1],\n              x='Stream')\ndisplay(pd.DataFrame(data[data['PlacedOrNot']==1].groupby('Stream').count().rename(columns = {'PlacedOrNot':'Number of Placements'}, inplace = False)['Number of Placements']))","9ef82288":"plt.figure(figsize=(20,5))\nsns.barplot(data=pd.DataFrame(data.groupby('Stream').mean()['PlacedOrNot']).reset_index().rename(columns = {'PlacedOrNot':'Placement Possibility'}, inplace = False),\n           x='Stream',\n           y='Placement Possibility')","326a8019":"display(pd.DataFrame(data.groupby(['HistoryOfBacklogs','PlacedOrNot']).count().rename(columns = {'Internships':'Number of Participants'}, inplace = False)['Number of Participants']))","bc711783":"plt.figure(figsize=(5,5))\nsns.barplot(data=pd.DataFrame(data.groupby('HistoryOfBacklogs').mean()['PlacedOrNot']).reset_index().rename(columns = {'PlacedOrNot':'Placement Possibility'}, inplace = False),\n           x='HistoryOfBacklogs',\n           y='Placement Possibility')","c7722fec":"display(pd.DataFrame(data.groupby(['Hostel']).count().rename(columns = {'Internships':'Number of Participants'}, inplace = False)['Number of Participants']))","0113f289":"plt.figure(figsize=(5,5))\nsns.barplot(data=pd.DataFrame(data.groupby('Hostel').mean()['PlacedOrNot']).reset_index().rename(columns = {'PlacedOrNot':'Placement Possibility'}, inplace = False),\n           x='Hostel',\n           y='Placement Possibility')","44e780a6":"\nfrom sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\ndfs = []\nfor i in ['Stream','Gender']:\n    temp = pd.DataFrame({'Before Encoding':data[i].unique(),'After Encoding':label_encoder.fit_transform(data[i].unique())})\n    dfs.append([temp.sort_values(by=['After Encoding']),i])\n    data[i] = label_encoder.fit_transform(data[i])\nfor i in dfs:\n    print(i[1])\n    display(i[0])\n    print('\\n')","23bb744e":"data.head()","85b4c0ae":"X = data.drop('PlacedOrNot',axis=1)\nY = data['PlacedOrNot']","6131244e":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=100)","ef23eee8":"classifiers","7ba4ca82":"models_to_test = [bc,gbc,ada,xgb,rfc,knn,mlp,svc,lr]","7c97d07c":"classification = Modelling(X_train,Y_train,X_test,Y_test,models_to_test)\nclassification.fit()","2c6e96fd":"classification.results()","4ec71c9e":"print('BestModel is:',  classification.best_model(type='name'))\nprint('Accuracy of model:',classification.best_model_accuracy())\nprint('Training Runtime in seconds',classification.best_model_runtime())\nprint('Classification Matrix:\\n')\nprint(classification.best_model_clmatrix())","9f512992":"cf_matrix = classification.best_confusion()\n\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\n\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cf_matrix.flatten()\/np.sum(cf_matrix)]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_percentages)]\n\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')","322d18a9":"## Role of Backlogs","e5f88b26":"# Data modelling","0afeffe8":"# Data PreProcessing","6de60e50":"# Importing libraries","348c1dd9":"## Role of Internships","1e3a2c4d":"## Role of Hostels","074f9be1":"# EDA","aceb7480":"## Importing and initialising models","2c5f8813":"## Age Group of participants","8141e503":"## Test Train SPlit","fcadee12":"# Engineering Placement prediction","0cd1b082":"## Role of CGPA","be6a9e12":"## Feature and Target split","64d28498":"## Number of placed vs not placed","8cafa6ca":"## Creating class","e2ee43e5":"## Importing data","f04ed785":"## Cardinal Encoding","e6503c18":"## Gender wise placement possibility","6a67a256":"## Role of Stream"}}