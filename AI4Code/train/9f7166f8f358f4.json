{"cell_type":{"9019e3fe":"code","e4406cc0":"code","5782d308":"code","309200ea":"code","8ef236b1":"code","1635d667":"code","ee7a0c2b":"code","40919faf":"code","51c2f014":"code","a9b04798":"code","45b4bcad":"code","ac7ebe78":"code","79b5c491":"code","d70359f6":"code","d7fb16c6":"markdown","cccdbcf9":"markdown","96a57531":"markdown","7ca9e791":"markdown"},"source":{"9019e3fe":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor,RandomForestRegressor,AdaBoostRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb\n\n\n\nsns.set(rc={'figure.figsize':(10,8)})\nsns.set(style='darkgrid', context='notebook', palette='deep')\n\n\nsample_submission = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\ntrain_data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntrain_data['Set'] = 'train'\ntest_data['Set'] = 'test'\ntest_data['SalePrice'] = -1\ndata = train_data.append(test_data)\ndata.reset_index(inplace=True)\nprint('done')","e4406cc0":"data[data.columns[data.isna().sum() > 0]].isna().sum().sort_values().plot.bar();","5782d308":"for col in data.columns:\n    count = sum(data[col].isna())\n    if count > 20:\n        data.drop(col,axis=1, inplace=True)\ndata[data.columns[data.isna().sum() > 0]].isna().sum().sort_values().plot.bar()","309200ea":"data = data.replace(np.nan,0)","8ef236b1":"dummy_data = []\nobj_col = []\nfor col in data.columns:\n    _ = data[col]\n    if _.dtype == 'object' and col != 'Set':\n        obj_col.append(col)\n        dummy_data.append(pd.get_dummies(_,prefix = col))\n        \ndummy_data = pd.concat(dummy_data,axis = 1)\ndata.drop(obj_col,axis = 1, inplace=True)\ndata = pd.concat([data,dummy_data],axis = 1)","1635d667":"train_data = data[data.Set == 'train']\ntest_data = data[data.Set == 'test']\nHouseIds = test_data.Id.to_list()\ntest_data = test_data.drop(['Id','Set',\"SalePrice\",'index'], axis = 1)\ny = train_data.SalePrice\nX = train_data.drop(['SalePrice','Id','Set','index'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 13)\nprint('done')","ee7a0c2b":"%%time\nnp.random.seed(13)\nRF_model = RandomForestRegressor(\n    n_estimators = 1000, \n    n_jobs=-1,max_depth = 6)# .fit(X_train,y_train)\nLGB_model = lgb.LGBMRegressor(\n    objective='regression',num_leaves=5, learning_rate=0.05,\n    n_estimators=720, max_bin = 55, bagging_fraction = 0.8,\n    bagging_freq = 5, feature_fraction = 0.2319, \n    feature_fraction_seed=9, bagging_seed=9,min_data_in_leaf =6, \n    min_sum_hessian_in_leaf = 11)# .fit(X_train,y_train)\n\nXGB_model = xgb.XGBRegressor(\n    objective = 'reg:squarederror', \n    n_estimators = 500,\n    seed = 13, subsample = 0.8,\n    learning_rate = 0.1, \n    reg_alpha=0.01,\n    reg_lambda = 10)# .fit(X_train,y_train)\n\nADA_model = AdaBoostRegressor(\n    base_estimator = DecisionTreeRegressor(max_depth=6),\n    learning_rate = .1, n_estimators = 500,\n    random_state=13)# .fit(X_train,y_train)\n\nGB_model = GradientBoostingRegressor(\n    n_estimators=100, learning_rate=0.05,\n    max_depth=6, max_features='sqrt',\n    min_samples_leaf=15, min_samples_split=10, \n    loss='huber', random_state =13)# .fit(X_train,y_train)","40919faf":"# model_list = [RF_model,LGB_model,XGB_model,ADA_model,GB_model]\n# for m in model_list:\n#     print(\n#     'Train score:',m.score(X_train,y_train),\n#     'Test score:',m.score(X_test,y_test),\n#     'Train RMSE:',np.sqrt(mean_squared_error(np.log(y_train),np.log(m.predict(X_train)))),\n#     'Test RMSE:',np.sqrt(mean_squared_error(np.log(y_test),np.log(m.predict(X_test)))))","51c2f014":"params = {\n    'gamma': [2, 4],\n    'subsample': [0.5],\n    'colsample_bytree': [0.5],\n    'min_child_weight' : [1, 3, 5],\n    'max_depth': [4, 6],\n    'learning_rate' : [0.10]\n}\n# params = {\n#     'max_depth': [6]\n# }\n\nxgb_reg = xgb.XGBRegressor(    \n    objective ='reg:linear',\n    n_estimators = 2000,\n    tree_method = 'gpu_hist')\nkfold = StratifiedKFold(n_splits = 5, shuffle = True,random_state = 123)","a9b04798":"xgb_grid = RandomizedSearchCV(\n    xgb_reg,\n    params,\n    n_jobs = 5,\n    cv = kfold, \n    verbose = 2,\n    refit = True)","45b4bcad":"result = xgb_grid.fit(X,y)","ac7ebe78":"result.best_estimator_","79b5c491":"result.best_score_","d70359f6":"submission =pd.DataFrame()\nsubmission[\"Id\"] = HouseIds\nsubmission[\"SalePrice\"] = result.best_estimator_.predict(test_data)\nsubmission.to_csv('submission.csv',index=None)","d7fb16c6":"## cleaning","cccdbcf9":"## Make dummy variables","96a57531":"## Drop missing columns","7ca9e791":"## Loading"}}