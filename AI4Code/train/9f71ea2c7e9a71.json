{"cell_type":{"fa83efe9":"code","316fbfe9":"code","2e6adf9f":"code","5abf93b0":"code","3819a333":"code","2d19bd00":"code","8f1ad693":"code","401774e5":"code","0535723c":"code","d3619020":"code","ebd0cc01":"code","e46a11da":"code","a9c69809":"code","1e94f9c2":"code","bdd39660":"code","3c0a2315":"markdown","0f8c7880":"markdown"},"source":{"fa83efe9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","316fbfe9":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\n","2e6adf9f":"import glob\nimport cv2\ndataset = []\nlabels=[]\n\nfor filename in glob.glob('..\/input\/flowers-recognition\/flowers\/*\/*'):\n    img=cv2.imread(filename)\n    img=cv2.resize(img,(150,150))\n    img_label=filename.split('\/')[-2]\n    dataset.append(np.array(img)\/255.0)\n    labels.append(str(img_label))\nlen(dataset)\nprint(len(labels))","5abf93b0":"import random\nplt.figure(figsize=(10,10))\n\nfor i in range(9):\n    ax=plt.subplot(3,3,i+1)\n    index=random.randint(0,len(labels))\n    ax.imshow(dataset[index])\n    ax.set_title(labels[index])\nplt.show()","3819a333":"from sklearn import preprocessing\nfrom tensorflow.keras.utils import to_categorical\n\nlabel_encoder = preprocessing.LabelEncoder()\n \nlabels_encoded= label_encoder.fit_transform(labels) \n\nprint(list(set(labels_encoded)))\nlabels_encoded=np.array(labels_encoded)\n","2d19bd00":"from sklearn.utils import shuffle\n\ndataset , labels_encoded = shuffle(dataset,labels_encoded , random_state=0)\nprint(len(dataset),len(labels_encoded))","8f1ad693":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,Y_train,Y_test=train_test_split(dataset,labels_encoded,test_size=0.2,random_state=42)","401774e5":"import tensorflow as tf\nfrom tensorflow import keras\n\nmodel=tf.keras.Sequential([\n      tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)),\n      tf.keras.layers.MaxPooling2D(2,2),\n      tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n      tf.keras.layers.MaxPooling2D(2,2),\n      tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n      tf.keras.layers.MaxPooling2D(2,2),\n      tf.keras.layers.Conv2D(256,(3,3),activation='relu'),\n      tf.keras.layers.MaxPooling2D(2,2),\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(512,activation='relu'),\n      tf.keras.layers.Dense(5,activation='softmax')\n\n])","0535723c":"\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(x_train)\n","d3619020":"model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n","ebd0cc01":"model.summary()","e46a11da":"epochs = 50\nbatch_size = 128\nx_train=np.array(x_train)\nY_train=np.array(Y_train)\n\nx_test=np.array(x_test)\nY_test=np.array(Y_test)\n\n\n\nHistory = model.fit_generator(datagen.flow(x_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (x_test,Y_test),\n                              verbose = 1, steps_per_epoch=x_train.shape[0] \/\/ batch_size)\n# model.fit(x_train,y_train,epochs=epochs,batch_size=batch_size,validation_data = (x_test,y_tes","a9c69809":"plt.plot(History.history['loss'])\nplt.plot(History.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","1e94f9c2":"plt.plot(History.history['accuracy'])\nplt.plot(History.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","bdd39660":"import cv2\ndataset_classes=['daisy','dandelion','rose','sunflower']\n#read the first image\nplt.imshow(x_test[0])\nprint('Actual class of image : ' ,dataset_classes[Y_test[0]])\npredictions =np.argmax((model.predict(x_test))[0])\nprint('Predicted class of image : ',dataset_classes[predictions])","3c0a2315":"### Plotting","0f8c7880":"###  One Hot Encoding"}}