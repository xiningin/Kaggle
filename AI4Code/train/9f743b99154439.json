{"cell_type":{"82ac23ac":"code","744d3f50":"code","968366db":"code","07288fb0":"code","720c0bc0":"code","17dab592":"code","6a293140":"code","2d106cf0":"code","d5c08ebe":"code","870485ef":"code","7c2669e3":"code","5a72d008":"code","54cfa588":"code","5cc7484e":"code","bcaf1b23":"code","f75d6152":"code","9db02e86":"code","08af0ad3":"code","05344b93":"code","a3a854c8":"code","de008054":"code","41ecca6c":"code","6bc89146":"code","dde10eee":"code","ac25b9e1":"code","5dee31a0":"code","3ca455fa":"code","ef8de38b":"code","dc485695":"code","e17b0212":"code","7f197233":"markdown","c0c4e90c":"markdown","604a0214":"markdown","d09d02fe":"markdown","565b32be":"markdown","d08b3ca6":"markdown","d3aa952b":"markdown","9d5dfd42":"markdown","58fb0b8a":"markdown","bb3ba6a1":"markdown","5bf35c2f":"markdown"},"source":{"82ac23ac":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport skimage, os\nfrom skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\nfrom skimage.measure import label,regionprops, perimeter\nfrom keras.models import Model,Sequential\nfrom keras.callbacks import ModelCheckpoint\nfrom skimage.morphology import binary_dilation, binary_opening\nfrom skimage.filters import roberts, sobel\nfrom skimage import measure, feature\nfrom skimage.segmentation import clear_border\nfrom skimage import data\nfrom scipy import ndimage as ndi\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\nimport scipy.misc\nimport numpy as np\nfrom glob import glob\nfrom skimage.io import imread\nBASE_IMG_PATH=os.path.join('..','input')\n%matplotlib inline \ntry:\n    import nibabel as nib #for loading data from NIfTI images\nexcept:\n    raise ImportError('Install NIBABEL')\n","744d3f50":"glob(os.path.join(BASE_IMG_PATH,'3d_images','*'))","968366db":"# show some of the files\nall_images=glob(os.path.join(BASE_IMG_PATH,'3d_images','IMG_*')) \nall_masks = [x.replace('IMG_', 'MASK_') for x in all_images]\nprint(len(all_images),' matching files found:',all_images[0], all_masks[0])\nprint(all_images)","07288fb0":"all_masks_img =[]\nfor mask in all_masks:\n    all_masks_img.append(nib.load(mask).get_data())\n#print(all_masks_img)          \nall_img_img =[]\nfor img in all_images:\n    all_img_img.append(nib.load(img).get_data())\nfor y in all_images:\n    \nimg = nib.load(all_images[0]).get_data()\nimg1 = nib.load(all_images[1]).get_data()\nimg2 = nib.load(all_images[2]).get_data()\nimg3 = nib.load(all_images[3]).get_data()\n#print(img)","720c0bc0":"print(img.shape)\nprint(img1.shape)\nprint(img2.shape)\nprint(img3.shape)","17dab592":"def get_range_value(img_value):\n    return (img_value.shape[0]\/\/27, img_value.shape[1]\/\/27, img_value.shape[2]\/\/27)","6a293140":"for a in range(4):\n    my_range = get_range_value(img)","2d106cf0":"my_range = get_range_value(img)\ndata = np.zeros((my_range[0],my_range[1],my_range[2],1))\nprint(data.shape)\nprint(my_range)\n\nfor i in range(my_range[0]):\n    for j in range(my_range[1]):\n        for k in range(my_range[2]):\n            data[i:,j:,k:,0] = img[i:(i+1)*27,j:(j+1)*27:,k:(k+1)*27]","d5c08ebe":"img_reshape = img.reshape(-1, 512,512,1)\nprint(img_reshape.shape)","870485ef":"m = np.max(img_reshape)\nmi = np.min(img_reshape)","7c2669e3":"m, mi","5a72d008":"img_reshape = (img_reshape - mi) \/ (m - mi)\n","54cfa588":"np.min(img_reshape), np.max(img_reshape)","5cc7484e":"temp = np.zeros([117,515, 515,1])","bcaf1b23":"temp[:,3:,3:,:] = img_reshape","f75d6152":"img_reshape = temp","9db02e86":"from sklearn.model_selection import train_test_split\ntrain_X,valid_X,train_ground,valid_ground = train_test_split(img_reshape,\n                                                             img_reshape,)","08af0ad3":"print(img_reshape.shape)","05344b93":"plt.figure(figsize=[5,5])\n\n# Display the first image in training data\nplt.subplot(121)\ncurr_img = np.reshape(train_X[0], (512,512))\nplt.imshow(curr_img, cmap='gray')\n\n# Display the first image in testing data\nplt.subplot(122)\ncurr_img = np.reshape(valid_X[0], (512,512))\nplt.imshow(curr_img, cmap='gray')","a3a854c8":"batch_size = 128\nepochs = 50\ninChannel = 1","de008054":"fig, (ax1) = plt.subplots(1,4,figsize = (12, 6))\nfor i in range(4):   \n    ax1[i].imshow(all_masks_img[i][all_masks_img[i].shape[0]\/\/2])\n    ax1[i].set_title('Mask')","41ecca6c":"from skimage.util import montage\nfig, ax1 = plt.subplots(1, 1, figsize = (20, 20))\nax1.imshow(montage(all_img_img[0]), cmap ='bone')\nfig.savefig('ct_scan.png')","6bc89146":"117\/\/27","dde10eee":"from keras.layers import Conv3D, MaxPool3D, Flatten, Dense\nfrom keras.layers import Dropout, Input, BatchNormalization\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom plotly.offline import iplot, init_notebook_mode\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import Adadelta\nimport plotly.graph_objs as go\nfrom matplotlib.pyplot import cm\nfrom keras.models import Model\nimport numpy as np\n## input layer\ninput_layer = Input((27, 27, 27, 3))\n## convolutional layers\nconv_layer1 = Conv3D(filters=64, kernel_size=(5, 5, 5), activation='relu')(input_layer)\n## add max pooling to obtain the most imformatic features\npooling_layer1 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer1)\nconv_layer2 = Conv3D(filters=64, kernel_size=(5, 5, 5), activation='relu')(pooling_layer1)\nconv_layer3 = Conv3D(filters=64, kernel_size=(5, 5, 5), activation='relu')(conv_layer2)\n## create an MLP architecture with dense layers : 4096 -> 512 -> 10\n## add dropouts to avoid overfitting \/ perform regularization\ndense_layer1 = Dense(1350, activation='relu')(conv_layer3)\noutput_layer = Dense(160, activation='softmax')(dense_layer1)\n## define the model with input layer and output layer\nmodel = Model(inputs=input_layer, outputs=output_layer)\nprint(model.summary())\n","ac25b9e1":"for i in range(0,117,27):\n    modelll = Model(train_Xtrain_X[i], model_CNN(train_X[i]))","5dee31a0":"modelll = Model(input_img, model_CNN(input_img))\n","3ca455fa":"modelll.summary()","ef8de38b":"modelll.compile(loss='mean_squared_error', optimizer = RMSprop())","dc485695":"model.compile(loss=categorical_crossentropy, optimizer=Adadelta(lr=0.1), metrics=['acc'])\n","e17b0212":"#model.fit(all_img_img,all_img_img, batch_size=8, epochs=50, validation_split=0.2)","7f197233":"The images of the dataset are indeed grayscale images with a dimension of 512 x 512 so before we feed the data into the model it is very important to preprocess it. You'll first convert each 512 x 512 image into a matrix of size 512 x 512 x 1, which you can feed into the network:","c0c4e90c":"-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------","604a0214":"from keras.layers import Conv3D, MaxPool3D, Flatten, Dense\nfrom keras.layers import Dropout, Input, BatchNormalization\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom plotly.offline import iplot, init_notebook_mode\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import Adadelta\nimport plotly.graph_objs as go\nfrom matplotlib.pyplot import cm\nfrom keras.models import Model\nimport numpy as np\nimport keras\nimport h5py","d09d02fe":"Let's verify the minimum and maximum value of the data which should be 0.0 and 1.0 after rescaling it!","565b32be":"Show mask!","d08b3ca6":"Data Genarate ","d3aa952b":"Work with  model","9d5dfd42":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        '..\/input\/3d_images',\n        target_size=(150, 150),\n        batch_size=32,\n        class_mode='binary')\n#model.fit_generator(        train_generator,        steps_per_epoch=2000,        epochs=50)","58fb0b8a":"!mkdir \/kaggle\/output\n!ls \/kaggle\n!cp \/kaggle\/input\/3d_images\/IMG_0031.nii.gz \/kaggle\/output\n!gunzip \/kaggle\/output\/IMG_0031.nii.gz\n!ls \/kaggle\/output\n!ls ..\/input\/3d_images\/","bb3ba6a1":"Here we show how to visualize and examine the 3D Nifti images and lung masks in python","5bf35c2f":"Next, rescale the data with using max-min normalisation technique:"}}