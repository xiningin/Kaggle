{"cell_type":{"36ecba36":"code","32972bda":"code","c75c3d17":"code","fb43dba6":"code","d8434d47":"code","ed200b8d":"code","121d2ee6":"code","93fe20cb":"code","330f614c":"code","0b115dfe":"code","ae49d12a":"code","49915bd7":"code","71a4708e":"code","bdcda9a0":"code","448e3fcb":"code","ceb60aeb":"code","4ef74b80":"markdown","a83e91fc":"markdown","8ddd5050":"markdown","02c4f7aa":"markdown","815da589":"markdown","a4fbc219":"markdown","93c80189":"markdown","0672867b":"markdown","5d3b832b":"markdown","4df2dfac":"markdown","34b27a12":"markdown","7bd659c5":"markdown","13747e19":"markdown","50c0a19f":"markdown","466899ce":"markdown"},"source":{"36ecba36":"import numpy as np # linear algebra\nfrom scipy import stats\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', 222)\n\nimport seaborn as sns\nsns.set()\nimport matplotlib.pyplot as plt \n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\ndf_train = pd.read_csv('\/kaggle\/input\/santander-customer-transaction-prediction\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/santander-customer-transaction-prediction\/test.csv')\ndf_join = pd.concat([df_train, df_test])","32972bda":"print(\"Rows: %s\\nColumns: %s\" % (df_train.shape[0], df_train.shape[1]))\nprint(\"*\" * 30)\nprint(df_train.head())","c75c3d17":"group_types = df_train.columns.to_series().groupby(df_train.dtypes)\nprint(group_types.count())\nprint(\"*\" * 30)\nprint(group_types.groups)","fb43dba6":"df_train.info()","d8434d47":"miss_vals = df_join.isna().sum()\nmiss_vals_percent = 100 * miss_vals \/ len(df_join)\nnull_df = pd.concat([miss_vals, miss_vals_percent], keys=['Missing Values', 'Missing %'], axis=1)\nnull_df.sort_values(by='Missing %', inplace=True, ascending=False)\nprint(null_df)","ed200b8d":"df_train.describe()","121d2ee6":"df_train_feats = df_train.select_dtypes(include=['float64']) # Grab all the usable features since they are only floats\nnormality_results = df_train_feats.apply(lambda x: stats.normaltest(x)[1], axis=0)\n\n# The Probability threshold that the feature is normally distributed\nalpha = 0.05\nnormals = normality_results[normality_results > alpha]\nprint(\"Number of normally distributed features: %s\\nPercentage of Features that are normally distributed: %s\\nFeatures that are normally distrubted: %s\" % (len(normals), len(normals)\/df_train_feats.shape[1], normals.index.values))","93fe20cb":"row = 25\ncol = 8\nfig, ax = plt.subplots(row, col, figsize=(col * 7, row * 5))\n\nidx = 0\nfor r in range(0, row):\n    for c in range(0, col):\n        x = df_train_feats.iloc[:, idx] # grab column\n        sns.distplot(x, axlabel=x.name, ax=ax[r][c])\n        idx += 1\n\nplt.show()","330f614c":"THRESHOLD = 0.8\ncorr = df_train_feats.corr(method='pearson') \nFEATURES_TO_REMOVE = []\n\ni = 0\nfor j in range(0, len(corr)):\n    if i != j:\n        if corr.iloc[i,j] >= THRESHOLD:\n            FEATURES_TO_REMOVE.append(corr.iloc[:, j].name)\n\nprint(\"Features to Remove\\ncount: %s feats: %s\" % (len(FEATURES_TO_REMOVE), FEATURES_TO_REMOVE))","0b115dfe":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\nfrom sklearn.model_selection import GridSearchCV","ae49d12a":"df_train_y = df_train[['target']]\ndf_train_X = df_train.drop(['target', 'ID_code'], axis=1) # only the feature columns are of type float64\n\n\ntrain_X, test_X, train_y, test_y = train_test_split(df_train_X, df_train_y, test_size=0.25, random_state=1)","49915bd7":"classifiers = [\n               'LogisticRegression',\n               'GaussianNB'\n              ]\n\nscaler = StandardScaler()\n\nresults = {\n    'classifiers': classifiers,\n    'auc': [],\n    'acc': [],\n    'f1': []\n}\n\nfor classifier in classifiers:\n    pipe = make_pipeline(scaler, eval(classifier)())\n    pipe.fit(train_X, train_y)\n    pred_y = pipe.predict(test_X)\n    \n    results['auc'].append(roc_auc_score(test_y, pred_y))\n    results['acc'].append(accuracy_score(test_y, pred_y))\n    results['f1'].append(f1_score(test_y, pred_y))\n    \nresults_df = pd.DataFrame(data=results)\nresults_df.sort_values(by='auc', ascending=False, inplace=True)\nprint(results_df)","71a4708e":"selected_classifiers = ['LogisticRegression','GaussianNB']\nparams = {\n    'LogisticRegression': {\n        'logisticregression__penalty': ['l2'],\n        'logisticregression__class_weight': [None, 'balanced'],\n        'logisticregression__solver': ['sag', 'saga'],\n        'logisticregression__max_iter': [25, 100, 125],\n        'logisticregression__tol': [1e-2, 1e-6]\n    },\n    'GaussianNB': {\n        'gaussiannb__var_smoothing': [1e-06, 1e-10, 1e-13]\n    }\n}\ngrid_results = {\n    \"classifiers\": selected_classifiers,\n    \"predict_auc\": [],\n    \"grid_auc\": []\n}\nfinal_models = {}\nscaler = StandardScaler()\n\nfor classifier in selected_classifiers:\n    pipe = make_pipeline(scaler, eval(classifier)())\n    search = GridSearchCV(pipe, params[classifier], scoring = 'roc_auc', n_jobs=2)\n    search.fit(train_X, train_y)\n    \n    grid_results['grid_auc'].append(search.best_score_)\n    pred_y = search.predict(test_X)\n    grid_results['predict_auc'].append(roc_auc_score(test_y, pred_y))\n    \n    final_models[classifier] = search.best_estimator_\n\ndf_search_results = pd.DataFrame(data=grid_results)\ndf_search_results.sort_values(by='predict_auc', ascending=False, inplace=True)\nprint(df_search_results)","bdcda9a0":"id_series = df_test['ID_code']\ndf_test_X = df_test.drop(['ID_code'], axis=1)\n\nbest_estimator = final_models['GaussianNB']\npipe = make_pipeline(StandardScaler(), best_estimator)\npipe.fit(df_train_X, df_train_y)\n\npredict_y = pipe.predict(df_test_X)","448e3fcb":"submission_df = pd.concat([id_series, pd.DataFrame(predict_y, columns=['Target'])], axis=1)\nprint(submission_df.head())","ceb60aeb":"submission_df.to_csv('Transaction_Prediction_1.csv', index=False)","4ef74b80":"It looks like there are no null or empty values the target values that are missing are a part of the test data which is as expected of course.","a83e91fc":"I find it strange that  none of the features are normally distributed given the normality test which uses **D\u2019Agostino's K^2 Normality Test** with a given alpha value of *0.05*. My hunch is that there's something wrong where the normality test are failing or maybe (highly unlikely) that none of the features follow a Guassian distribution. Let's take a visual look. ","8ddd5050":"# EDA","02c4f7aa":"# Modeling","815da589":"Visually it seems that all the features indicate a Gaussian Distribution so it looks like the **normality test** we tried above failed due to the sample size being too large. See this [article](https:\/\/medium.com\/data-design\/large-amount-of-observations-statistical-test-not-so-statistical-3d8ed0e94be) detailing more. We can perform another visual representation to be sure that are assumption is correct such as a Q-Q plot but I think this will suffice. A Gaussian distribution indicates 2 things that 1) we can use a parameteric modeling method to predict here and 2) most models perform\/behave better when data follows a Guassian Distribution which we of course want. ","a4fbc219":"All the feature columns are of type **Float** the prediction target is of type **Int** and the ID columns is of type **Object**.","93c80189":"## Gaussian Distrubtion Check","0672867b":"So it doesn't look like any of the features are correlated to each other so no need to remove any features. ","5d3b832b":"# Submission","4df2dfac":"It looks like the winning model with optimized parameters is the **GaussianNB** estimator. ","34b27a12":"# Preprocessing\nLuckily the data is well prepared and will have to do little to now preprocessing.","7bd659c5":"## Data Visualization","13747e19":"## Parameter Tuning\nThe **GaussianNB** and **LogisticRegressionCV** classifiers perform the best. Let's see if we can improve the scores by parameter tuning. Using the top 2 classifiers, let's run them through the **GridSearch** hyperparameter optimization to see if we can find the optimal parameters to get the best results. ","50c0a19f":"## Overview of the Data","466899ce":"## Feature Selection"}}