{"cell_type":{"56e4ff48":"code","c8b8fbde":"code","c87590b3":"code","f4615e21":"code","50f2c8d2":"code","3f057dd7":"code","bd6d66c2":"code","5cd18c78":"code","08828a2a":"code","e221d24d":"code","b0b5bf28":"code","c2be56de":"code","64a7a5ca":"code","e9249b8a":"code","b1ee9863":"code","b5fe694c":"code","cdb8db5e":"code","5c47024a":"code","0b056347":"code","ab439d10":"code","8142393b":"code","3c21e602":"code","8123551f":"code","a73237d0":"code","ba1b34e0":"code","f5705666":"code","c755c54e":"code","f2feb394":"code","a45647b3":"code","0e5a065f":"code","36114ba5":"markdown","9eb0c67f":"markdown","b49db7ab":"markdown","2e4da946":"markdown","3629785a":"markdown","b8f63be5":"markdown","78300288":"markdown","8ed69894":"markdown","05b9f027":"markdown"},"source":{"56e4ff48":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","c8b8fbde":"df = pd.read_csv(\"..\/input\/train.csv\")","c87590b3":"#Check that the file was read in properly and explore the columns\ndf.head()","f4615e21":"plt.figure(figsize=(12,8))\nsns.heatmap(df.isnull(),cbar=False, yticklabels=False, cmap='viridis')","50f2c8d2":"sns.set_style('darkgrid')","3f057dd7":"sns.countplot(x='Survived', data=df, hue='Pclass')","bd6d66c2":"sns.countplot(x='SibSp', data=df, hue='Survived')","5cd18c78":"df['Fare'].hist(bins=40)","08828a2a":"plt.figure(figsize=(12,6))\nsns.boxplot(x='Pclass', y='Age', data=df)","e221d24d":"def inpute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass == 1:\n            return 37\n        elif Pclass == 2:\n            return 29\n        else: return 24\n    else: return Age","b0b5bf28":"df['Age']=df[['Age','Pclass']].apply(inpute_age, axis=1)","c2be56de":"plt.figure(figsize=(12,8))\nsns.heatmap(df.isnull(),cbar=False, yticklabels=False, cmap='viridis')","64a7a5ca":"df.drop('Cabin', axis=1, inplace=True)","e9249b8a":"plt.figure(figsize=(12,6))\nsns.heatmap(df.isnull(),cbar=False, yticklabels=False, cmap='viridis')","b1ee9863":"df.dropna(inplace=True)","b5fe694c":"plt.figure(figsize=(12,6))\nsns.heatmap(df.isnull(),cbar=False, yticklabels=False, cmap='viridis')","cdb8db5e":"df.info()","5c47024a":"#We make a new 'Male columns because getDummies will drop one the the dummy variables\n#to ensure linear independence.\ndf['Male'] = pd.get_dummies(df['Sex'], drop_first=True)","0b056347":"#The embarked column indicates where the passenger boarded the Titanic.\n#It has three values ['S','C','Q']\nembarked = pd.get_dummies(df['Embarked'], drop_first=True)\ndf = pd.concat([df, embarked], axis=1)","ab439d10":"#These columns do not provide us any information for the following reasons:\n#PassengerID: we consider 'PassengerID' a randomly assigned ID thus not correlated with surviability\n#Name: we are not performing any feature extraction from the name, so we must drop tihs non-numerical column\n#Sex: the 'Male' column already captures all information about the sex of the passenger\n#Ticket: we are not performing any feature extraction, so we must drop this non-numerical column\n#Embarked: we have extracted the dummy values, so those two numerical dummy values encapsulate all the embarked info\n\ndf.drop(['PassengerId', 'Name', 'Sex', 'Ticket', 'Embarked'], axis=1, inplace=True)","8142393b":"#Take a look at our new dataframe\ndf.head()","3c21e602":"df.info()","8123551f":"#Seperate the feature columns from the target column\nX = df.drop('Survived', axis=1)\ny = df['Survived']","a73237d0":"#Split the data into two. I don't think this is necessary since there are two files.\n#I will keep this here for now\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)","ba1b34e0":"from sklearn.linear_model import LogisticRegression\nlogmodel = LogisticRegression()\nlogmodel.fit(X, y)","f5705666":"#Read in the test data\ntest_df = pd.read_csv('..\/input\/test.csv')","c755c54e":"#Clean the test data the same way we did the training data\ntest_df['Age']=test_df[['Age','Pclass']].apply(inpute_age, axis=1)\ntest_df.drop('Cabin', axis=1, inplace=True)\ntest_df.dropna(inplace=True)\ntest_df['Male'] = pd.get_dummies(test_df['Sex'], drop_first=True)\nembarked = pd.get_dummies(test_df['Embarked'], drop_first=True)\ntest_df = pd.concat([test_df, embarked], axis=1)\npass_ids = test_df['PassengerId']\ntest_df.drop(['PassengerId', 'Name', 'Sex', 'Ticket', 'Embarked'], axis=1, inplace=True)","f2feb394":"test_df.tail()","a45647b3":"predictions = logmodel.predict(test_df)","0e5a065f":"submission = pd.DataFrame({\n        \"PassengerId\": pass_ids,\n        \"Survived\": predictions\n    })\nsubmission.to_csv('titanic.csv', index=False)","36114ba5":"##Build and train the model","9eb0c67f":"You can see now the data is cleaner, but we still need to clean the 'Cabin' and 'Embarked' columns. For now, we will simply drop the 'Cabin' column and drop the rows where 'Embarked' is missing.","b49db7ab":"## Data exploration","2e4da946":"We can see that 'Name', 'Sex', 'Ticket', and 'Embarked' are all objects. In this case, they indeed are all strings. We will use Pandas built in getDummies() funciton to convert those to numbers.","3629785a":"Here, we impute the age of those we do not have information on. We use a boxplot to estimate the median age of each class, and impute that into the age for the rows with missing age.","b8f63be5":"We can see here that those who did not survive were predominantly from the 3rd Passenger Class (Pclass).","78300288":"From the heat map, we can see that a lot of the 'Cabin' row information is missing. However, while the age column is also missing some data, we can use imputation to fill in some of the data later. Additionally, the 'Embarked' column has so few rows missing, that we can just delete those.","8ed69894":"## Imports and reading in files","05b9f027":"The data is now clean of null values, but we still need to take care of objects that a machine learning algorithm can't handle, namely strings."}}