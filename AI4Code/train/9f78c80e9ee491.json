{"cell_type":{"2fd95f2e":"code","78736117":"code","bdf3e024":"code","898fdb93":"code","db6c95c9":"code","0c130834":"code","a2d213fd":"code","6075dfc6":"code","2e8a552e":"code","03be13bf":"code","b2ce0ed4":"code","6959ae45":"code","f9788dc9":"code","fd58bcbb":"code","dc95fa50":"code","a01056c3":"code","2f96f828":"code","5ba6c428":"code","9d06309d":"code","8268bbaf":"code","6790f896":"code","72929655":"code","460092c9":"code","18ba7916":"code","01e5f843":"code","1d97ae48":"code","44723ea6":"code","24a1b8e2":"code","8fbdfc11":"code","4898b132":"code","66614ac1":"code","0f62d887":"code","48306b37":"code","904f3c5f":"code","ba5f6c45":"code","2ed6d9fe":"code","0b537860":"code","cf5784e2":"code","1ffa57fd":"code","58d80741":"code","c021f573":"code","fa810e02":"code","4a0bb47a":"code","65d07212":"code","10812d43":"code","c6e67e72":"code","0babc20e":"code","84be9e1d":"code","2531e25c":"code","6a627c22":"code","e183f0d6":"code","90def4aa":"code","49f5f3c8":"code","77d2ca42":"code","d847bb99":"code","2d21ff79":"code","7f617eb4":"code","9c85c6a6":"code","41234b25":"code","7fc40dab":"code","3ad159ac":"code","5a3954d1":"code","bc484c13":"code","b32d8cc6":"code","01e60333":"code","9599adbb":"code","c865415b":"code","9252c19b":"code","4aedccba":"code","53875a34":"code","e52d4789":"code","e902bd44":"code","ed37f4ca":"code","c66e17de":"code","9a181b44":"code","8f125c25":"code","f3fd2153":"code","208977ae":"code","05997a05":"code","af52bdbd":"code","3a6cfaa7":"code","4c5a0941":"code","6cec78e9":"code","d7e5a410":"code","f9708965":"code","c6d6908b":"code","6f0cf55f":"code","2ea0bc52":"code","a920e2b2":"code","83a26415":"code","96275d9a":"code","9b8780b8":"code","80548477":"code","198877a7":"code","bb647f2a":"code","9aa6052a":"code","65617a77":"code","fbf0960d":"code","15426a63":"code","49263255":"code","51d8e798":"code","cb33c1f2":"code","d1a0b74c":"code","364e0ef7":"code","7f6ceaf9":"code","607f4112":"code","611400d7":"code","ae70b4e5":"code","1f990412":"code","107c9069":"code","43fcd8df":"code","f33d58d5":"code","d366f7f9":"code","3bb7712e":"code","a1b413b7":"code","ec7cc950":"code","e141e72b":"code","9b4c4ae5":"code","4e0d6101":"code","6a3468c6":"code","3c21fdc6":"code","da0bf70f":"code","114f908d":"code","6b690c96":"code","b9ae8a39":"code","df6d9a17":"code","149ab19c":"code","26c784dd":"code","16864d4f":"code","d93613aa":"code","85c875b1":"code","ba515293":"code","96dcde07":"code","15505c0d":"code","9a08a729":"code","5791c835":"code","e8d990ec":"code","5b46ad4f":"code","69d416c9":"code","7f4e2ac9":"code","d244bb47":"code","8729d371":"code","2febb7a0":"code","e35840fa":"code","12920657":"code","4ac8d56b":"code","9367f034":"code","f400ddfc":"code","88ba53a1":"code","32afb5ab":"code","c2c08019":"code","0e51e351":"code","d91b8375":"code","983225cd":"code","7a035f3f":"code","d588144f":"code","0099a423":"code","d846201f":"code","93645a77":"code","a3e4ad44":"code","1d67da97":"code","5cdf18c4":"code","6142e3aa":"code","7580953c":"code","455a94d5":"code","56efa0f7":"code","e00f369b":"code","30ab3810":"code","2b2d1dd7":"code","c8dd10ed":"code","30ae00d4":"code","6d128ef0":"code","28467275":"code","30f27fe8":"code","04703759":"code","bd735a68":"code","07acaee2":"code","f99e98ec":"code","3546fff9":"code","9754aef8":"code","bd286410":"code","74f0874a":"code","2cd5ab0f":"code","a36d9ddc":"code","a731bb4e":"code","d105379e":"code","e1e67169":"code","c3e7e727":"code","e7cf2722":"code","3577984d":"code","9608451e":"code","508f1431":"code","28741dbb":"code","4555c0b4":"code","bba6d6d3":"code","14675363":"code","059bae32":"code","bf295a0d":"code","849eb130":"code","2d0faaf6":"code","054f8dfd":"code","09548b76":"code","464e519e":"code","66a49a65":"code","b90d93ca":"code","e1c4f1ea":"code","bb020747":"code","9256303e":"code","c73acec9":"code","8f861f4b":"code","50c17cdf":"code","0eff9363":"code","12501e3c":"code","bcfa881f":"markdown","95105f1b":"markdown","f17954bb":"markdown","9b49b2a7":"markdown","a0130758":"markdown","e11bb1c9":"markdown","7dd0f0bc":"markdown","e84feea1":"markdown","c90ca605":"markdown","a4387ea1":"markdown","94962d0a":"markdown","2ce52adf":"markdown","14ab15b4":"markdown","60c430b6":"markdown","035b20d7":"markdown","e7ad785e":"markdown","0bd5eab9":"markdown","055ff515":"markdown","094a1105":"markdown","fc1afd3b":"markdown","a6ddeeb1":"markdown","f65d605a":"markdown","0d5140ad":"markdown"},"source":{"2fd95f2e":"# supress warnings \nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\n# 'Os' module provides functions for interacting with the operating system \nimport os\n\n# 'Pandas' is used for data manipulation and analysis\nimport pandas as pd \n\n# 'Numpy' is used for mathematical operations on large, multi-dimensional arrays and matrices\nimport numpy as np\n\n# 'Matplotlib' is a data visualization library for 2D and 3D plots, built on numpy\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# 'Seaborn' is based on matplotlib; used for plotting statistical graphics\nimport seaborn as sns\n\n# 'Scikit-learn' (sklearn) emphasizes various regression, classification and clustering algorithms\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import ElasticNet\n\n# 'Statsmodels' is used to build and analyze various statistical models\nimport statsmodels\nimport statsmodels.api as sm\nimport statsmodels.stats.api as sms\nfrom statsmodels.tools.eval_measures import rmse\nfrom statsmodels.compat import lzip\nfrom statsmodels.graphics.gofplots import ProbPlot\n\n# 'SciPy' is used to perform scientific computations\nfrom scipy.stats import f_oneway\nfrom scipy.stats import jarque_bera\nfrom scipy import stats","78736117":"data = pd.read_csv('..\/input\/seoulbikedatacsv\/SeoulBikeData (1).csv',engine='python')","bdf3e024":"data.head(4)","898fdb93":"data.info()","db6c95c9":"data.shape","0c130834":"data[(data['Rented Bike Count']==0)].head()","a2d213fd":"index=data.index[data['Functioning Day']=='No']  # fiding the poisition if non-functioning days","6075dfc6":"data=data.drop(index)","2e8a552e":"data=data.reset_index(drop=True)","03be13bf":"data['Functioning Day'].value_counts()                # checking the count of functioning day","b2ce0ed4":"data['Holiday'].value_counts()                   # checking the count of Holiday","6959ae45":"data.head(1)","f9788dc9":"data.corr() # checking the correlation","fd58bcbb":"num_data=data.select_dtypes(include=np.number)\ncat_data=data.select_dtypes(exclude=np.number)","dc95fa50":"num_data.head(1)","a01056c3":"cat_data.head(1)","2f96f828":"hr=data.groupby(['Seasons','Hour'])['Rented Bike Count'].mean()","5ba6c428":"sr=data.groupby(['Seasons'])['Rented Bike Count'].mean()\nsr","9d06309d":"hr=pd.DataFrame([hr])\nhr.head()","8268bbaf":"\nhr1=hr.T","6790f896":"hr1.head()","72929655":"data['Rented Bike Count'].plot(kind='kde')","460092c9":"num_data.head(1)","18ba7916":"\nnum_data.plot(kind='kde',subplots=True,layout=(4,3),sharex=False,figsize=(15,10))\nplt.show()","01e5f843":"sns.countplot(cat_data['Seasons'])","1d97ae48":"sns.countplot(cat_data['Holiday'])","44723ea6":"plt.hist(data['Rented Bike Count'],bins=10)","24a1b8e2":"sns.distplot(data['Rented Bike Count'])","8fbdfc11":"plt.boxplot(data['Rented Bike Count'],vert=False)","4898b132":"sns.violinplot(data['Rented Bike Count'])","66614ac1":"plt.figure(figsize=(15, 8))           # plotting a heatmap to see correlation\ncorr=num_data.corr()\nsns.heatmap(corr,annot=True,fmt='0.2f',vmax=1,vmin=-1)","0f62d887":"plt.figure(figsize=(15, 8))        # checking the number of bikes plotted every hou\nsns.boxplot(data['Hour'],data['Rented Bike Count']).set_title('Rented Bike Count distribution across hour')","48306b37":"plt.figure(figsize=(15, 8))         #Represntation of the rented bike count based on seasons\nsns.boxplot(data['Seasons'],data['Rented Bike Count'],order=['Autumn','Spring','Summer','Winter']).set_title('Rented Bike Count distribution across Seasons')","904f3c5f":"plt.figure(figsize=(15, 8))\nsns.boxplot(data['Holiday'],data['Rented Bike Count']).set_title('Rented Bike Count distribution across Holidays')","ba5f6c45":"plt.figure(figsize=(15, 8))\nsns.boxplot(x=data['Hour'],y=data['Rented Bike Count'],hue=data['Seasons'],hue_order=['Autumn','Spring','Summer','Winter'])","2ed6d9fe":"plt.figure(figsize=(15, 8))\nsns.countplot(data['Wind speed (m\/s)']) \nplt.xticks(rotation=90)","0b537860":"from scipy.stats import f_oneway\nf_oneway(data['Rented Bike Count'][data['Holiday'] == 'Holiday'], \n             data['Rented Bike Count'][data['Holiday'] == 'No Holiday'])","cf5784e2":"tab=pd.crosstab(data['Holiday'],data['Seasons'])\/data['Seasons'].value_counts()*100","1ffa57fd":"(tab.T).plot(kind='bar',stacked=True,figsize=(10,5))\nplt.legend(framealpha=0.2,bbox_to_anchor=(1,0,0.2,0.5))","58d80741":"cat_data.head(1)","c021f573":"cat_data=cat_data.drop('Date',1)          # dropping date as it is insignificant ","fa810e02":"data1=pd.concat([num_data,cat_data],1)","4a0bb47a":"data1.head(1)","65d07212":"\nplt.figure(figsize=(15, 8))\nplt.title('Box Plot for Numerical Variable')\ndata1.boxplot()","10812d43":"plt.figure(figsize=(15, 8))\nplt.title('Box Plot for Numerical Variable by dropping Rented Bike Count and Visibilty')\ndata1.drop(['Rented Bike Count','Visibility (10m)'],1).boxplot()","c6e67e72":"plt.figure(figsize=(15,8))\nplt.title('Box Plot for Rented Bike Count ')\nsns.boxplot(data1['Rented Bike Count'])","0babc20e":"plt.figure(figsize=(15,8))\nplt.title('Box Plot for visibilty ')\nsns.boxplot(data['Visibility (10m)'])","84be9e1d":"#Capping to remove outliers\nQ1 = data1.quantile(0.25)\nQ3 = data1.quantile(0.75)\n# calculate of interquartile range \nIQR = Q3 - Q1\ndata1=data1[~((data1<(Q1-1.5*IQR))|(data1>(Q3+1.5*IQR))).any(axis=1)]","2531e25c":"data1.shape","6a627c22":"plt.figure(figsize=(15,8))\ndata1.boxplot(column=[  'Temperature(\ufffdC)', 'Humidity(%)',\n       'Wind speed (m\/s)',\n       'Solar Radiation (MJ\/m2)', 'Rainfall(mm)', 'Snowfall (cm)'])\nplt.xticks(rotation=90)","e183f0d6":"plt.figure(figsize=(15,8))\nplt.title('Box Plot for Rented Bike Count after capping')\nsns.boxplot(data1['Rented Bike Count'])","90def4aa":"data1=data1.drop(['Rainfall(mm)', 'Snowfall (cm)'],1)","49f5f3c8":"plt.figure(figsize=(15,8))\ncorr=data1.corr()\ncorr\nsns.heatmap(corr,annot=True,fmt='0.2f',vmax=1,vmin=-1)\n","77d2ca42":"data1.corr()","d847bb99":"data1.head(1)","2d21ff79":"data1.shape\n","7f617eb4":"num_data1=data1.select_dtypes(include=np.number)\ncat_data1=data1.select_dtypes(exclude=np.number)","9c85c6a6":"cat_data1=pd.get_dummies(cat_data1,columns=['Holiday','Seasons'],drop_first=True)  #using one-hot encoding technique","41234b25":"cat_data1=pd.get_dummies(cat_data1,columns=['Functioning Day'])","7fc40dab":"cat_data1.head()","3ad159ac":"num_data1.head(1)","5a3954d1":"data2=pd.concat([num_data1,cat_data1],1)        #combining both categorical and numerical variables\ndata2.head()","bc484c13":"datav1=data2.copy()\ndatav1.head()","b32d8cc6":"out=pd.DataFrame(np.power(datav1['Rented Bike Count'],0.3))","01e60333":"datav1['pow_rbc']=out\ndatav1['pow_rbc'].skew()           # data is slightly left skewed","9599adbb":"data2=pd.concat([num_data1,cat_data1],1)        #combining both categorical and numerical variables\ndata2.head()","c865415b":"datav1=data2.copy()\ndatav1.head()","9252c19b":"out=pd.DataFrame(np.power(datav1['Rented Bike Count'],0.3))","4aedccba":"datav1['pow_rbc']=out\ndatav1['pow_rbc'].skew()           # data is slightly left skewed","53875a34":"data_ols1=datav1.copy()","e52d4789":"from sklearn.preprocessing import StandardScaler       \nsc=StandardScaler()\nnum_two_col_sc=sc.fit_transform(num_data1.drop('Rented Bike Count',1))\nnum_two_col_sc=pd.DataFrame(num_two_col_sc,columns=num_data1.iloc[:,1:].columns)\nnum_two_col_sc.head(2)","e902bd44":"num_sc=num_two_col_sc.reset_index(drop=True)","ed37f4ca":"cat_data1=cat_data1.reset_index(drop=True)","c66e17de":"final_data=pd.concat([num_two_col_sc,cat_data1],axis=1)\nfinal_data.head(2)","9a181b44":"final_data.shape","8f125c25":"##Base model-1 using ols packag","f3fd2153":"#Load the independent and dependent features\ninp=final_data\nout=num_data1['Rented Bike Count']","208977ae":"#Load required libraries\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score,mean_squared_error","05997a05":"#Split the dataset into train and test \nxtrain,xtest,ytrain,ytest= train_test_split(inp,out,test_size=.3,random_state=48)","af52bdbd":"#check the dimensions\nprint('Dimensions of x_train:',xtrain.shape)\nprint('Dimensions of y_train:',ytrain.shape)\nprint('Dimensions of x_test:',xtest.shape)\nprint('Dimensions of y_test:',ytest.shape)","3a6cfaa7":"##Base model-2 using sklearn package","4c5a0941":"score_card = pd.DataFrame(columns=['Model_Name', 'R-Squared', 'Adj. R-Squared', 'RMSE'])\n\nlinreg_full_base_model_using_ols = pd.Series({\n                     'Model_Name': \"LRM_using _OLS\",\n                     'RMSE':ols_rmse,\n                     'R-Squared':ols_r2 ,\n                     'Adj. R-Squared': ols_adj_r2    \n                   })\n\nscore_card = score_card.append(linreg_full_base_model_using_ols , ignore_index=True)\n\n#call scorecard\nscore_card","6cec78e9":"Lr=LinearRegression()\nLr.fit(xtrain,ytrain) \nypred=Lr.predict(xtest)\nprint('predicted values:',ypred,'\\n')\nintercept=Lr.intercept_\nprint('Intercept:',intercept,'\\n')\nCoeff=Lr.coef_\nprint('Coefficents :',Coeff)","d7e5a410":"#find Performance\nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom statsmodels.tools.eval_measures import rmse\n\n#rmse\nlr_rmse=rmse(ytest,ypred)\n#r2_score\nlr_r2=r2_score(ytest,ypred)\n#adj_r2_score\nlr_adj_r2=1-(((1-lr_r2)*(len(xtest)-1))\/(len(xtest)-len(xtest.columns)-1))\n\nprint('rmse:',lr_rmse,'\\n','r2_score:',lr_r2,'\\n','adj_r2:',lr_adj_r2)","f9708965":"#model-3 output transformation model","c6d6908b":"# Build a model with the output transformation\n\n\n#As we know that dependent variable is not normal distributed so transform it\nimport scipy.stats as stats\nbox_out,lam=stats.boxcox(num_data1['Rented Bike Count'])\nbox_out=pd.DataFrame(box_out)\nprint('skewness of price:',box_out.skew()[0])    #equal to zero so normal distributed now\n\n","6f0cf55f":"#split the  input and output variables \nxtrain,xtest,ytrain,ytest= train_test_split(inp,box_out,test_size=.3,random_state=48)\n\n\n#build a model using Sklearn package\nLr=LinearRegression()\nLr.fit(xtrain,ytrain) \nypred=Lr.predict(xtest)\nprint('predicted values:',ypred,'\\n')\nintercept=Lr.intercept_\nprint('Intercept:',intercept,'\\n')\nCoeff=Lr.coef_\nprint('Coefficents :',Coeff)\n#check","2ea0bc52":"#find performance\n#rmse\nlr_box_cox_rmse=rmse(ytest,ypred)\n#r2_score\nlr_box_cox_r2=r2_score(ytest,ypred)\n#adj_r2_score\nlr_box_cox_adj_r2=1-(((1-lr_box_cox_r2)*(len(xtest)-1))\/(len(xtest)-len(xtest.columns)-1))\n\nprint('rmse:',lr_box_cox_rmse,'\\n','r2_score:',lr_box_cox_r2,'\\n','adj_r2:',lr_box_cox_adj_r2)","a920e2b2":"linreg_full_model_with_transformed_Rented_bike_Count = pd.Series({\n                     'Model_Name': \"LRM_full_with_transformed_Rented_bike_Count\",\n                     'RMSE':lr_box_cox_rmse,\n                     'R-Squared':lr_box_cox_r2 ,\n                     'Adj. R-Squared': lr_box_cox_adj_r2     \n                   })\n\nscore_card = score_card.append(linreg_full_model_with_transformed_Rented_bike_Count, ignore_index=True)\n\n#call scorecard\nscore_card","83a26415":" #Assumptions","96275d9a":"#a) Multicolinearity","9b8780b8":"#import library\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif=pd.DataFrame()\nvif['VIF']=[variance_inflation_factor(xtrain.values,i) for i in range(xtrain.shape[1])]          #dataframe to np array\nvif['features']=xtrain.columns\nvif.sort_values('VIF',ascending=False)","80548477":"inpv1=xtrain.drop(['Dew point temperature(\ufffdC)','Holiday_No Holiday'],1)\nvif=pd.DataFrame()\nvif['VIF']=[variance_inflation_factor(inpv1.values,i) for i in range(inpv1.shape[1])]          \nvif['features']=inpv1.columns\nvif.sort_values('VIF',ascending=False)","198877a7":"#model=4 significant features with transformed output# check","bb647f2a":"#inp=inpv1             have only signficant features   (these two are train set)\n#out=ytrain           transformed output","9aa6052a":"#Build a model \nimport statsmodels.api as sm\n\ninpc1=sm.add_constant(inpv1)\nols=sm.OLS(ytrain,inpc1)\nlinear_model_using_ols=ols.fit() \nprint(linear_model_using_ols.summary())","65617a77":"#Autocollinearity","fbf0960d":"#Statistical test to check the linearity\nfrom statsmodels.stats.diagnostic import linear_rainbow \nprint('% of Linearity:',linear_rainbow(res=linear_model_using_ols,frac=0.5)[1]*100)","15426a63":"#Normality","49263255":"#plot the distribution of residual\nsns.distplot(linear_model_using_ols.resid,color='orange')\nplt.show()","51d8e798":"#Check skewness\nprint('Skewness of residual is :',linear_model_using_ols.resid.skew())","cb33c1f2":"#Using qqplot\nfrom statsmodels.graphics.gofplots import qqplot\nqqplot(linear_model_using_ols.resid,line='r')   #r=regression line\n#check","d1a0b74c":"#Find the Homascadasticity\nsns.residplot(linear_model_using_ols.predict(),linear_model_using_ols.resid)\nplt.show()","364e0ef7":"#statsitic test for homascadsticity\nfrom statsmodels.stats.api import het_goldfeldquandt\n\n#H0: model is homascadsticity\nprint('Pvalue is :',het_goldfeldquandt(linear_model_using_ols.resid,linear_model_using_ols.model.exog)[1])","7f6ceaf9":"#Feature selection","607f4112":"inpv1.head(2)","611400d7":"inpv_1=inpv1.copy()","ae70b4e5":"#import library\nfrom mlxtend.feature_selection import SequentialFeatureSelector as sfs","1f990412":"#a) Backward elimination method","107c9069":"lr=LinearRegression()\nlr_back=sfs(estimator=lr,k_features='best',forward=False) #k_features='best' gives significant features among all the features\nsfs_back=lr_back.fit(inpv_1,ytrain)\nback_feat=sfs_back.k_feature_names_\nback_feat=list(back_feat)\nprint('These are the significant features for best model by considering backward_elimin :','\\n',back_feat)","43fcd8df":"#Check score\nprint('Score of backward elimination :',sfs_back.k_score_)","f33d58d5":" #Forward selection method","d366f7f9":"lr=LinearRegression()\nlr_forw=sfs(estimator=lr,k_features='best',forward=True)   \nsfs_forw=lr_forw.fit(inpv_1,ytrain)\nforw_feat=sfs_forw.k_feature_names_\nforw_feat=list(forw_feat)\nprint('These are the significant features for best model by considering forward_selec :','\\n',forw_feat)","3bb7712e":"#Check score\nprint('Score of forward selection :',sfs_forw.k_score_)","a1b413b7":"#RFE-Recursive feature elimination","ec7cc950":"lr=LinearRegression()\nfrom sklearn.feature_selection import RFECV       #its gives possible features so thats why we dont need to write n_features_to_select\nrfe_mod=RFECV(estimator=lr)\nrfe_feat=rfe_mod.fit(inpv_1,ytrain)\n\nrank=pd.DataFrame()\nrank['Rank']=rfe_feat.ranking_\nrank['Feature']=inpv_1.columns\n\nr_feat=rank[rank['Rank']==1]","e141e72b":"#print features\nrfe_featu=r_feat['Feature']\nprint('These are the significant features for best model by considering RFE :','\\n',rfe_featu)","9b4c4ae5":"#Check score\nprint('Score of RFECV method :',np.mean(rfe_feat.grid_scores_))","4e0d6101":"#model-5 model with best features using backward elimination\n","6a3468c6":"import statsmodels.api as sm\n\ninpc2=sm.add_constant(inpv_1[back_feat])\nols=sm.OLS(ytrain,inpc2)\nlinear_model_using_ols_best_feat=ols.fit() \nprint(linear_model_using_ols_best_feat.summary())","3c21fdc6":"#model-6 model with best features using RFE method","da0bf70f":"#Build a model\ninpc3=sm.add_constant(inpv_1[rfe_featu])\nols=sm.OLS(ytrain,inpc3)\nlinear_model_using_ols_best_feat_RFE=ols.fit() \nprint(linear_model_using_ols_best_feat_RFE.summary())","114f908d":"sign_feat=list(inpv_1[rfe_featu].columns)  #bcoz we need to consider only best features obtained from RFE method\n\n\nfrom statsmodels.api import add_constant\nxtest_with_constant=add_constant(xtest[sign_feat],has_constant='add')\nypred_ols=linear_model_using_ols_best_feat_RFE.predict(xtest_with_constant)\nypred_ols.shape","6b690c96":"#find Performance\nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom statsmodels.tools.eval_measures import rmse\n\n#rmse\nols_rmse=np.sqrt(mean_squared_error(ytest,ypred_ols))\n#r2_score\nols_r2=r2_score(ytest,ypred_ols)\n#adj_r2_score\nols_adj_r2=1-(((1-ols_r2)*(len(xtest[sign_feat])-1))\/(len(xtest[sign_feat])-len(xtest[sign_feat].columns)-1))\n\nprint('rmse:',ols_rmse,'\\n','r2_score:',ols_r2,'\\n','adj_r2:',ols_adj_r2)","b9ae8a39":"linreg_model_with_signifi_feat_using_RFECV_method = pd.Series({\n                     'Model_Name': \"LRM_with_signif_feat_using_RFECV\",\n                     'RMSE':ols_rmse,\n                     'R-Squared':ols_r2 ,\n                     'Adj. R-Squared': ols_adj_r2     \n                   })\n\nscore_card = score_card.append(linreg_model_with_signifi_feat_using_RFECV_method , ignore_index=True)\n\n#call scorecard\nscore_card","df6d9a17":"#Interaction effect (Joint effect)","149ab19c":"# Interaction effect with backward elimination","26c784dd":"inpv_1_back=inpv_1[back_feat]\ninpv_1_back.head(2)","16864d4f":"#concatenate ytrain and inpv_1_back[back_feat]\ninpv_1_back=pd.concat([inpv_1_back,ytrain],axis=1)\ninpv_1_back.rename({0: 'Rented Bike Count'}, axis=1, inplace=True)\ninpv_1_back.head(2)\n#check","d93613aa":"#bring to one scale form\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\ninpv_1_back['Rented Bike Count']=sc.fit_transform(inpv_1_back['Rented Bike Count'].values.reshape(-1,1))\ninpv_1_back.head(2)","85c875b1":"inpv_2_back=inpv_1_back.copy()","ba515293":"inpv_2_back['Hour*Temp']=inpv_2_back['Temperature(\ufffdC)']*inpv_2_back['Hour']","96dcde07":"inpv_2_back.head(2)","15505c0d":"inpv_2_back_d=inpv_2_back.drop(['Rented Bike Count'],1)","9a08a729":"inpv_2_back_d.head()","5791c835":"#Build a model \nimport statsmodels.api as sm\n\ninpc4=sm.add_constant(inpv_2_back_d)\nols=sm.OLS(ytrain,inpc4)\nlinear_model_using_ols_best_feat_backward_with_interaction=ols.fit() \nprint(linear_model_using_ols_best_feat_backward_with_interaction.summary())","e8d990ec":"#same we need for test also#check\nxtest[back_feat].head(2)","5b46ad4f":"xtest_backward=pd.concat([xtest[back_feat],ytest],axis=1)\nxtest_backward.rename({0: 'Rented Bike Count'}, axis=1, inplace=True)\nxtest_backward.head(2)\n","69d416c9":"#bring to one scale form\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nxtest_backward['Rented Bike Count']=sc.fit_transform(xtest_backward['Rented Bike Count'].values.reshape(-1,1))\nxtest_backward.head(2)","7f4e2ac9":"xtest_backward_1=xtest_backward.copy()","d244bb47":"xtest_backward_1['Hour*Temp']=xtest_backward['Temperature(\ufffdC)']*xtest_backward['Hour']","8729d371":"xtest_backward_1.head(2)","2febb7a0":"xtest_backward_2=xtest_backward_1.drop('Rented Bike Count',1)","e35840fa":"#find Performance\nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom statsmodels.tools.eval_measures import rmse\n\n#rmse\nols_rmse=np.sqrt(mean_squared_error(ytest,ypred_ols))\n#r2_score\nols_r2=r2_score(ytest,ypred_ols)\n#adj_r2_score\nols_adj_r2=1-(((1-ols_r2)*(len(xtest_backward)-1))\/(len(xtest_backward)-len(xtest_backward.columns)-1))\n\nprint('rmse:',ols_rmse,'\\n','r2_score:',ols_r2,'\\n','adj_r2:',ols_adj_r2)","12920657":"linreg_model_with_signifi_feat_backwrd_interaction = pd.Series({\n                     'Model_Name': \"LRM_with_signif_feat_Backwrd_Intrctn\",\n                     'RMSE':ols_rmse,\n                     'R-Squared':ols_r2 ,\n                     'Adj. R-Squared': ols_adj_r2     \n                   })\n\nscore_card = score_card.append(linreg_model_with_signifi_feat_backwrd_interaction , ignore_index=True)\n\n#call scorecard\nscore_card","4ac8d56b":"#Interaction effect with RFECV method","9367f034":"inpv_1_rfe=inpv_1[rfe_featu]\ninpv_1_rfe.head(2)","f400ddfc":"#concatenate ytrain and inpv_1_rfe[back_feat]\ninpv_1_rfe=pd.concat([inpv_1_rfe,ytrain],axis=1)\ninpv_1_rfe.rename({0: 'Rented Bike Count'}, axis=1, inplace=True)\ninpv_1_rfe.head(2)","88ba53a1":"#bring to one scale form\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\ninpv_1_rfe['Rented Bike Count']=sc.fit_transform(inpv_1_rfe['Rented Bike Count'].values.reshape(-1,1))\ninpv_1_rfe.head(2)","32afb5ab":"inpv_2_rfe=inpv_1_rfe.copy()","c2c08019":"inpv_2_rfe['Hour*Temp']=inpv_2_rfe['Temperature(\ufffdC)']*inpv_2_rfe['Hour']","0e51e351":"inpv_2_rfe=inpv_2_rfe.drop('Rented Bike Count',1)\ninpv_2_rfe.head(2)","d91b8375":"#model-8 interaction effect of price difference with rfe method","983225cd":"#Build a model \nimport statsmodels.api as sm\n\ninpc5=sm.add_constant(inpv_2_rfe)\nols=sm.OLS(ytrain,inpc5)\nlinear_model_using_ols_best_feat_RFECV_with_interaction=ols.fit() \nprint(linear_model_using_ols_best_feat_RFECV_with_interaction.summary())","7a035f3f":"#same we need for test also\nxtest[rfe_featu].head(2)","d588144f":"#concatenate\nxtest_rfe=pd.concat([xtest[rfe_featu],ytest],axis=1)\nxtest_rfe.rename({0: 'Rented Bike Count'}, axis=1, inplace=True)\nxtest_rfe.head(2)","0099a423":"#bring to one scale form\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nxtest_rfe['Rented Bike Count']=sc.fit_transform(xtest_rfe['Rented Bike Count'].values.reshape(-1,1))\nxtest_rfe.head(2)","d846201f":"xtest_rfe_1=xtest_rfe.copy()\nxtest_rfe_1['Hour*Temperature']=xtest_rfe['Hour']*xtest_rfe['Temperature(\ufffdC)']\nxtest_rfe_1=xtest_rfe_1.drop('Rented Bike Count',1)\nxtest_rfe_1.head(2)","93645a77":"from statsmodels.api import add_constant\nxtest_with_constant=add_constant(xtest_rfe_1)\nypred_ols=linear_model_using_ols_best_feat_RFECV_with_interaction.predict(xtest_with_constant)\nypred_ols.shape","a3e4ad44":"#find Performance\nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom statsmodels.tools.eval_measures import rmse\n\n#rmse\nols_rmse=np.sqrt(mean_squared_error(ytest,ypred_ols))\n#r2_score\nols_r2=r2_score(ytest,ypred_ols)\n#adj_r2_score\nols_adj_r2=1-(((1-ols_r2)*(len(xtest_backward)-1))\/(len(xtest_backward)-len(xtest_backward.columns)-1))\n\nprint('rmse:',ols_rmse,'\\n','r2_score:',ols_r2,'\\n','adj_r2:',ols_adj_r2)","1d67da97":"linreg_model_with_signifi_feat_RFECV_interaction = pd.Series({\n                     'Model_Name': \"LRM_with_signif_feat_RFECV_intrctn\",\n                     'RMSE':ols_rmse,\n                     'R-Squared':ols_r2 ,\n                     'Adj. R-Squared': ols_adj_r2     \n                   })\n\nscore_card = score_card.append(linreg_model_with_signifi_feat_RFECV_interaction , ignore_index=True)\n\n#call scorecard\nscore_card","5cdf18c4":"#Optimisation","6142e3aa":"#Cross Validation","7580953c":"inp=final_data\nout=box_out","455a94d5":"#import library\nfrom sklearn.model_selection import cross_val_score,KFold\n\nkf=KFold(n_splits=5,shuffle=True,random_state=48)\n\n\n#use r2 score\nfrom sklearn.linear_model import LinearRegression     #split the dataset into 5 groups\nlr=LinearRegression()\nres=cross_val_score(lr,inp,out,cv=kf,scoring='r2')\nprint('R2 values for 5sets of dataset :',res ) ","56efa0f7":"#bias error\nbe=1-np.mean(res)\n\n#variance error\nve=np.std(res)\n\nprint('Bias error interms of R2:',be)\nprint('Varaince error interms of R2:',ve)      #std(res)=0 model if free of overfitting ","e00f369b":"# Dataset is having overfitting problem... to overcome this we can use regualarization ","30ab3810":" #Regularization with Hyperparameter","2b2d1dd7":"#import hyperparameter library\nfrom sklearn.model_selection import GridSearchCV \n#import regularization library\nfrom sklearn.linear_model import Lasso,Ridge,ElasticNet","c8dd10ed":"#Lasso Regularization","30ae00d4":"loss=Lasso()     #hyper paramater of lasso is alpha\nparam={'alpha':[0.000001,0.00001,0.0001,0.001,0.01,0.1,1,2,5,8,10,50,60,70,90,100]}\n\ngrid=GridSearchCV(loss,param_grid=param,cv=5,scoring='r2') \n\nhyp_rid=grid.fit(inpv_2_rfe,ytrain)\n\nprint('Best hyperparameter is :',hyp_rid.best_params_ )\nprint('Score :',hyp_rid.best_score_ )","6d128ef0":"#Ridge Regularization","28467275":"rid=Ridge()     #hyper paramater of ridge is alpha\nparam={'alpha':[0.000001,0.00001,0.0001,0.001,0.01,0.1,1,2,5,8,10,50,60,70,90,100]}\n\ngrid=GridSearchCV(rid,param_grid=param,cv=5,scoring='r2')\n\nhyp_rid=grid.fit(inpv_2_rfe,ytrain)\n\nprint('Best hyperparameter is :',hyp_rid.best_params_ )\nprint('Score :',hyp_rid.best_score_ )\n","30f27fe8":"#ElasticNet Regularization","04703759":"enet=ElasticNet()     #hyper paramater of elastic  is alpha and l1_ratio\nparam={'alpha':[0.000001,0.00001,0.0001,0.001,0.01,0.1,1,2,5,8,10,50,60,70,90,100],'l1_ratio':[0.1,.2,0.3,0.4,.5,0.6,0.7,0.8,0.9]}\n\ngrid=GridSearchCV(enet,param_grid=param,cv=5,scoring='r2')\n\nhyp_rid=grid.fit(inpv_2_rfe,ytrain)\n\nprint('Best hyperparameter is :',hyp_rid.best_params_ )\nprint('Score :',hyp_rid.best_score_ )","bd735a68":"#model-9  building a model using Ridge regularization","07acaee2":"rid=Ridge(alpha=8)                 \nrid.fit(inpv_2_rfe,ytrain)\n\nypred_train=rid.predict(inpv_2_rfe)\nypred_test=rid.predict(xtest_rfe)\n\nrmse_train=np.sqrt(mean_squared_error(ytrain,ypred_train))\nrmse_test=np.sqrt(mean_squared_error(ytest,ypred_test))\n\nr2_train=r2_score(ytrain,ypred_train)\nr2_test=r2_score(ytest,ypred_test)\n\nadj_r2_train=1-(((1-r2_train)*(len(inpv_2_rfe)-1))\/(len(inpv_2_rfe)-len(inpv_2_rfe.columns)-1))\nadj_r2_test=1-(((1-r2_test)*(len(xtest_rfe)-1))\/(len(xtest_rfe)-len(xtest_rfe.columns)-1))\n\nprint('rmse_train:',rmse_train,'\\n','rmse_test:',rmse_test,'\\n','r2_score_train:',r2_train,'\\n','r2_score_test:',r2_test,'\\n','adj_r2_train:',adj_r2_train,'\\n','adj_r2_test:',adj_r2_test)","f99e98ec":"linreg_model_with_signifi_feat_RFECV_interaction_ridge = pd.Series({\n                     'Model_Name': \"LRM_with_signif_feat_RFECV_interctn_Ridge\",\n                     'RMSE':rmse_test,\n                     'R-Squared':r2_test ,\n                     'Adj. R-Squared': adj_r2_test     \n                   })\n\nscore_card = score_card.append(linreg_model_with_signifi_feat_RFECV_interaction_ridge , ignore_index=True)\n\n#call scorecard\nscore_card","3546fff9":"#Stochastic Gradient Descent","9754aef8":"#import library\nfrom sklearn.linear_model import SGDRegressor","bd286410":"sgd=SGDRegressor()\nsgd.fit(inpv_2_rfe,ytrain)\n\n\nypred_train=sgd.predict(inpv_2_rfe)\nypred_test=sgd.predict(xtest_rfe)\n\nrmse_train=np.sqrt(mean_squared_error(ytrain,ypred_train))\nrmse_test=np.sqrt(mean_squared_error(ytest,ypred_test))\n\nr2_train=r2_score(ytrain,ypred_train)\nr2_test=r2_score(ytest,ypred_test)\n\nadj_r2_train=1-(((1-r2_train)*(len(inpv_2_rfe)-1))\/(len(inpv_2_rfe)-len(inpv_2_rfe.columns)-1))\nadj_r2_test=1-(((1-r2_test)*(len(xtest_rfe)-1))\/(len(xtest_rfe)-len(xtest_rfe.columns)-1))\n\nprint('rmse_train:',rmse_train,'\\n','rmse_test:',rmse_test,'\\n','r2_score_train:',r2_train,'\\n','r2_score_test:',r2_test,'\\n','adj_r2_train:',adj_r2_train,'\\n','adj_r2_test:',adj_r2_test)","74f0874a":"linreg_model_with_signifi_feat_RFECV_interaction_sgd = pd.Series({\n                     'Model_Name': \"LRM_with_signif_feat_RFECV_intrctn_SGD\",\n                     'RMSE':rmse_test,\n                     'R-Squared':r2_test ,\n                     'Adj. R-Squared': adj_r2_test     \n                   })\n\nscore_card = score_card.append(linreg_model_with_signifi_feat_RFECV_interaction_sgd  , ignore_index=True)\n\n#call scorecard\nscore_card","2cd5ab0f":"#SVM Algorithm","a36d9ddc":"from sklearn import svm\nmodel=svm.SVR()\nmodel.fit(inpv_2_rfe,ytrain)\n\n\nypred_train=model.predict(inpv_2_rfe)\nypred_test=model.predict(xtest_rfe)\n\nrmse_train=np.sqrt(mean_squared_error(ytrain,ypred_train))\nrmse_test=np.sqrt(mean_squared_error(ytest,ypred_test))\n\nr2_train=r2_score(ytrain,ypred_train)\nr2_test=r2_score(ytest,ypred_test)\n\nadj_r2_train=1-(((1-r2_train)*(len(inpv_2_rfe)-1))\/(len(inpv_2_rfe)-len(inpv_2_rfe.columns)-1))\nadj_r2_test=1-(((1-r2_test)*(len(xtest_rfe)-1))\/(len(xtest_rfe)-len(xtest_rfe.columns)-1))\n\nprint('rmse_train:',rmse_train,'\\n','rmse_test:',rmse_test,'\\n','r2_score_train:',r2_train,'\\n','r2_score_test:',r2_test,'\\n','adj_r2_train:',adj_r2_train,'\\n','adj_r2_test:',adj_r2_test)\n\n\n","a731bb4e":"linreg_model_with_signifi_feat_RFECV_interaction_SVM = pd.Series({\n                     'Model_Name': \"LRM_with_signif_feat_RFECV_intrctn_SVM\",\n                     'RMSE':rmse_test,\n                     'R-Squared':r2_test ,\n                     'Adj. R-Squared': adj_r2_test     \n                   })\n\nscore_card = score_card.append(linreg_model_with_signifi_feat_RFECV_interaction_SVM  , ignore_index=True)\n\n#call scorecard\nscore_card","d105379e":"#Automatic Relevance Determination Regression (ARD) Algorithm","e1e67169":"from sklearn.linear_model import ARDRegression","c3e7e727":"model=ARDRegression()\nmodel.fit(inpv_2_rfe,ytrain)","e7cf2722":"ypred_train=model.predict(inpv_2_rfe)\nypred_test=model.predict(xtest_rfe)\n\nrmse_train=np.sqrt(mean_squared_error(ytrain,ypred_train))\nrmse_test=np.sqrt(mean_squared_error(ytest,ypred_test))\n\nr2_train=r2_score(ytrain,ypred_train)\nr2_test=r2_score(ytest,ypred_test)\n\nadj_r2_train=1-(((1-r2_train)*(len(inpv_2_rfe)-1))\/(len(inpv_2_rfe)-len(inpv_2_rfe.columns)-1))\nadj_r2_test=1-(((1-r2_test)*(len(xtest_rfe)-1))\/(len(xtest_rfe)-len(xtest_rfe.columns)-1))\n\nprint('rmse_train:',rmse_train,'\\n','rmse_test:',rmse_test,'\\n','r2_score_train:',r2_train,'\\n','r2_score_test:',r2_test,'\\n','adj_r2_train:',adj_r2_train,'\\n','adj_r2_test:',adj_r2_test)","3577984d":"linreg_model_with_signifi_feat_RFECV_interaction_ARD = pd.Series({\n                     'Model_Name': \"LRM_with_signif_feat_RFECV_intrctn_ARD\",\n                     'RMSE':rmse_test,\n                     'R-Squared':r2_test ,\n                     'Adj. R-Squared': adj_r2_test     \n                   })\n\nscore_card = score_card.append(linreg_model_with_signifi_feat_RFECV_interaction_ARD  , ignore_index=True)\n\n#call scorecard\nscore_card","9608451e":"#Bayesian Ridge Regression Algorithm","508f1431":"from sklearn.linear_model import BayesianRidge","28741dbb":"model=BayesianRidge()\nmodel.fit(inpv_2_rfe,ytrain)\n\nypred_train=model.predict(inpv_2_rfe)\nypred_test=model.predict(xtest_rfe)\n\nrmse_train=np.sqrt(mean_squared_error(ytrain,ypred_train))\nrmse_test=np.sqrt(mean_squared_error(ytest,ypred_test))\n\nr2_train=r2_score(ytrain,ypred_train)\nr2_test=r2_score(ytest,ypred_test)\n\nadj_r2_train=1-(((1-r2_train)*(len(inpv_2_rfe)-1))\/(len(inpv_2_rfe)-len(inpv_2_rfe.columns)-1))\nadj_r2_test=1-(((1-r2_test)*(len(xtest_rfe)-1))\/(len(xtest_rfe)-len(xtest_rfe.columns)-1))\n\nprint('rmse_train:',rmse_train,'\\n','rmse_test:',rmse_test,'\\n','r2_score_train:',r2_train,'\\n','r2_score_test:',r2_test,'\\n','adj_r2_train:',adj_r2_train,'\\n','adj_r2_test:',adj_r2_test)","4555c0b4":"linreg_model_with_signifi_feat_RFECV_interaction_BR = pd.Series({\n                     'Model_Name': \"LRM_with_signif_feat_RFECV_intrctn_BR\",\n                     'RMSE':rmse_test,\n                     'R-Squared':r2_test ,\n                     'Adj. R-Squared': adj_r2_test     \n                   })\n\nscore_card = score_card.append(linreg_model_with_signifi_feat_RFECV_interaction_BR  , ignore_index=True)\n\n#call scorecard\nscore_card","bba6d6d3":"#Passive Aggressive Algorithms","14675363":"from sklearn.linear_model import PassiveAggressiveRegressor","059bae32":"model=PassiveAggressiveRegressor()\nmodel.fit(inpv_2_rfe,ytrain)\n\nypred_train=model.predict(inpv_2_rfe)\nypred_test=model.predict(xtest_rfe)\n\nrmse_train=np.sqrt(mean_squared_error(ytrain,ypred_train))\nrmse_test=np.sqrt(mean_squared_error(ytest,ypred_test))\n\nr2_train=r2_score(ytrain,ypred_train)\nr2_test=r2_score(ytest,ypred_test)\n\nadj_r2_train=1-(((1-r2_train)*(len(inpv_2_rfe)-1))\/(len(inpv_2_rfe)-len(inpv_2_rfe.columns)-1))\nadj_r2_test=1-(((1-r2_test)*(len(xtest_rfe)-1))\/(len(xtest_rfe)-len(xtest_rfe.columns)-1))\n\nprint('rmse_train:',rmse_train,'\\n','rmse_test:',rmse_test,'\\n','r2_score_train:',r2_train,'\\n','r2_score_test:',r2_test,'\\n','adj_r2_train:',adj_r2_train,'\\n','adj_r2_test:',adj_r2_test)","bf295a0d":"linreg_model_with_signifi_feat_RFECV_interaction_PAR = pd.Series({\n                     'Model_Name': \"LRM_with_signif_feat_RFECV_intrctn_PAR\",\n                     'RMSE':rmse_test,\n                     'R-Squared':r2_test ,\n                     'Adj. R-Squared': adj_r2_test     \n                   })\n\nscore_card = score_card.append(linreg_model_with_signifi_feat_RFECV_interaction_PAR  , ignore_index=True)\n\n#call scorecard\nscore_card","849eb130":"#Robust Multivariate Regression Algorithms(TheilSenRegressor","2d0faaf6":"from sklearn.linear_model import TheilSenRegressor","054f8dfd":"model=TheilSenRegressor()\nmodel.fit(inpv_2_rfe,ytrain)\n\nypred_train=model.predict(inpv_2_rfe)\nypred_test=model.predict(xtest_rfe)\n\nrmse_train=np.sqrt(mean_squared_error(ytrain,ypred_train))\nrmse_test=np.sqrt(mean_squared_error(ytest,ypred_test))\n\nr2_train=r2_score(ytrain,ypred_train)\nr2_test=r2_score(ytest,ypred_test)\n\nadj_r2_train=1-(((1-r2_train)*(len(inpv_2_rfe)-1))\/(len(inpv_2_rfe)-len(inpv_2_rfe.columns)-1))\nadj_r2_test=1-(((1-r2_test)*(len(xtest_rfe)-1))\/(len(xtest_rfe)-len(xtest_rfe.columns)-1))\n\nprint('rmse_train:',rmse_train,'\\n','rmse_test:',rmse_test,'\\n','r2_score_train:',r2_train,'\\n','r2_score_test:',r2_test,'\\n','adj_r2_train:',adj_r2_train,'\\n','adj_r2_test:',adj_r2_test)","09548b76":"linreg_model_with_signifi_feat_RFECV_interaction_TSR = pd.Series({\n                     'Model_Name': \"LRM_with_signif_feat_RFECV_intrctn_TSR\",\n                     'RMSE':rmse_test,\n                     'R-Squared':r2_test ,\n                     'Adj. R-Squared': adj_r2_test     \n                   })\n\nscore_card = score_card.append(linreg_model_with_signifi_feat_RFECV_interaction_TSR  , ignore_index=True)\n\n#call scorecard\nscore_card","464e519e":"#Random Fprest ","66a49a65":"from sklearn.ensemble import RandomForestRegressor","b90d93ca":"inpv_2_rfe","e1c4f1ea":"regressor=RandomForestRegressor(n_estimators=10,random_state=2)\nregressor.fit(inpv_2_rfe,ytrain)\nypred_train=regressor.predict(inpv_2_rfe)\nypred_test=regressor.predict(xtest_rfe)\n\nrmse_train=np.sqrt(mean_squared_error(ytrain,ypred_train))\nrmse_test=np.sqrt(mean_squared_error(ytest,ypred_test))\n\nr2_train=r2_score(ytrain,ypred_train)\nr2_test=r2_score(ytest,ypred_test)\n\nadj_r2_train=1-(((1-r2_train)*(len(inpv_2_rfe)-1))\/(len(inpv_2_rfe)-len(inpv_2_rfe.columns)-1))\nadj_r2_test=1-(((1-r2_test)*(len(xtest_rfe)-1))\/(len(xtest_rfe)-len(xtest_rfe.columns)-1))\n\nprint('rmse_train:',rmse_train,'\\n','rmse_test:',rmse_test,'\\n','r2_score_train:',r2_train,'\\n','r2_score_test:',r2_test,'\\n','adj_r2_train:',adj_r2_train,'\\n','adj_r2_test:',adj_r2_test)","bb020747":"linreg_model_with_RandomForestRegressor = pd.Series({\n                     'Model_Name': \"LRM_with_RandomForestRegressor\",\n                     'RMSE':rmse_test,\n                     'R-Squared':r2_test ,\n                     'Adj. R-Squared': adj_r2_test     \n                   })\n\nscore_card = score_card.append(linreg_model_with_RandomForestRegressor  , ignore_index=True)\n\n#call scorecard\nscore_card","9256303e":"#Selecting best model","c73acec9":"score_card['RMSE']=score_card['RMSE'].astype('float')","8f861f4b":"score_card.plot(secondary_y=['R-Squared','Adj. R-Squared'])\n\n# display just the plot\nplt.axvline(x=15, color='black',label='BEST model')\nplt.title('Selecting best model',fontsize=20)\nplt.show()","50c17cdf":"xtrain.head(1)","0eff9363":"linreg_model_with_RandomForestRegressor_2 = pd.Series({\n                     'Model_Name': \"LRM_with_RandomForestRegressor_2\",\n                     'RMSE':rmse_test,\n                     'R-Squared':r2_test ,\n                     'Adj. R-Squared': adj_r2_test     \n                   })\n\nscore_card = score_card.append(linreg_model_with_RandomForestRegressor_2  , ignore_index=True)\n\n#call scorecard\nscore_card","12501e3c":"score_card.plot(secondary_y=['R-Squared','Adj. R-Squared'])\n\n# display just the plot\nplt.axvline(x=16, color='black',label='BEST model')\nplt.title('Selecting best model',fontsize=20)\nplt.show()","bcfa881f":"the bike count is comparitively lot more on 'No Holiday' than during a holiday","95105f1b":"Missing Value","f17954bb":"# Graph","9b49b2a7":"Power Transformation","a0130758":"\nAfter dropping now the other variables are clearly visible and we can see that Temperature , Dew point temperature and humidity are significant variables.","e11bb1c9":"# One Way Annova","7dd0f0bc":"The f_statistic =41.75 and the p-value <0.05 which indicates that there is significant difference in the mean of the rented bike count across Holiday. We may consider buliding consider bulliding separat model for each Holiday and No holiday but we go ahead and bulid a single model for both Holiday and No-Holiday.","e84feea1":"so as per the above graph the maximum outliers are present in the Rented bike count and for windspeed,rainfall,snowfall are equal to 0","c90ca605":"No outliers seen in visibility","a4387ea1":"We can see snowfall and rainfall is 0 so we will remove them","94962d0a":"As per the above plot, we can there are 2 peaks one is during the 8 am and the second and the maximum one is during 5pm to 7pm.","2ce52adf":"1)Linear Regression Model","14ab15b4":"based on the above plot we can say that the data is right skewed also maximum values lie between 0 and 1000.","60c430b6":"As per the above boxplot , we can see that more number of bikes have been hired on a working day instead of a holiday.","035b20d7":"1)Linear Regression Model","e7ad785e":"# Outliers Treatment","0bd5eab9":"Power Transformation","055ff515":"Rented bike count is 0 for the above rows when the day is not functioning day","094a1105":"so here we can see that the dew point temperature and the Tempereature have a very high positive correlation.","fc1afd3b":"As per the above plot we can say that winter has maximum holidays(for christmas) and we can see that maximum days are working days.","a6ddeeb1":"Date is unique so we will drop it late","f65d605a":"there are a lot of outliers in the data","0d5140ad":"On grouping the Hour,Seasons and Rented bike count we found the average bikes required every hour."}}