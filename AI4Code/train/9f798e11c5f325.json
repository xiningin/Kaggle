{"cell_type":{"4c3f3c17":"code","0d426acf":"code","2bec9b3c":"code","ac816434":"code","dc0d2263":"code","51db14da":"code","6b9f6809":"code","277ccc92":"code","11fb667d":"code","10979d9e":"code","6a42a276":"code","f69a0cf7":"code","3e9e4bc6":"code","4d6d507f":"code","84ae9ab1":"code","6664aa9a":"code","5ae4007c":"code","b460f6b1":"code","8687e6d3":"code","47879b0d":"markdown","9f1326e8":"markdown","a8d725b2":"markdown","1bc507f8":"markdown","55366682":"markdown","4d5db974":"markdown","bad66cb0":"markdown","c2e96ede":"markdown"},"source":{"4c3f3c17":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","0d426acf":"import pandas as pd ","2bec9b3c":"data = pd.read_csv('..\/input\/BreadBasket_DMS.csv')\ndata.head(5)","ac816434":"# data['Dates'] = data['Date']\n# data = data.drop('Date', axis=1)\n# data.head(5)","dc0d2263":"data.dtypes","51db14da":"data.shape","6b9f6809":"import datetime as dt\ndata['Date'] = pd.to_datetime(data['Date'])\n# data['Date'] = data['Dates'].dt.date\n# data.head(5)","277ccc92":"data['Day'] = data['Date'].dt.day\ndata['Month'] = data['Date'].dt.month\ndata['Hour'] = data['Time'].apply(lambda x:int(str(pd.to_datetime(x).round('H')).split(\" \")[1].split(\":\")[0]))\ndata.head(5)","11fb667d":"import matplotlib.pyplot as plt\nfig, ax = plt.subplots()\ndata['Item'].value_counts().head(10).plot(ax = ax, kind='bar')","10979d9e":"# drop None:\n# Drop row of NONE items\ndata.drop(data[data['Item']=='NONE'].index,inplace=True)","6a42a276":"plt.hist(data['Month'], bins=np.arange(data['Month'].min(), data['Month'].max()+1))","f69a0cf7":"data.groupby('Hour')['Transaction'].nunique().plot(figsize=(8,5))","3e9e4bc6":"data.groupby('Day')['Transaction'].nunique().plot(figsize=(8,5))","4d6d507f":"#Busiest day of week\n#Get total transaction for each date\nbyday=data.groupby('Date')['Transaction'].nunique().reset_index()\n#Create dayofweek column\nbyday['DayofWeek'] = byday['Date'].apply(lambda x:pd.to_datetime(x).weekday())\n\n#Plot average transactions per day\nbyday.groupby('DayofWeek')['Transaction'].mean().plot(figsize=(8,5))\nplt.title(\"Average number of transactions per weekday\")\nplt.ylabel(\"# of Transactions\")\nfig=plt.xticks(np.arange(7),['Mon','Tue','Wed','Thur','Fri','Sat','Sun'])","84ae9ab1":"# get all the items in each transaction \ntransactions = []\nfor i in data['Transaction'].unique():\n    itemlist = list(set(data[data['Transaction']==i]['Item']))\n    if len(itemlist) > 0:\n        transactions.append(itemlist)\ntransactions[:5]\nlen(transactions) == data['Transaction'].nunique()","6664aa9a":"from mlxtend.preprocessing import TransactionEncoder\nfrom mlxtend.frequent_patterns import apriori, association_rules\n\nte = TransactionEncoder()\nte_ary = te.fit(transactions).transform(transactions)\ndf = pd.DataFrame(te_ary, columns=te.columns_)\nfrequent_itemsets = apriori(df, min_support=0.01, use_colnames=True)\nrules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0.5)\nrules.sort_values('confidence', ascending=False).head(10)","5ae4007c":"import random\n\nsupport=rules.as_matrix(columns=['support'])\nconfidence=rules.as_matrix(columns=['confidence'])\n\nfor i in range (len(support)):\n   support[i] = support[i] + 0.0025 * (random.randint(1,10) - 5) \n   confidence[i] = confidence[i] + 0.0025 * (random.randint(1,10) - 5)\n \nplt.scatter(support, confidence,   alpha=0.5, marker=\"*\")\nplt.xlabel('support')\nplt.ylabel('confidence') \nplt.show()\n","b460f6b1":"def draw_graph(rules, rules_to_show):\n  import networkx as nx  \n  G1 = nx.DiGraph()\n   \n  color_map=[]\n  N = 50\n  colors = np.random.rand(N)    \n  strs=['R0', 'R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'R9', 'R10', 'R11']   \n   \n   \n  for i in range (rules_to_show):      \n    G1.add_nodes_from([\"R\"+str(i)])\n    \n     \n    for a in rules.iloc[i]['antecedents']:\n                \n        G1.add_nodes_from([a])\n        \n        G1.add_edge(a, \"R\"+str(i), color=colors[i] , weight = 2)\n       \n    for c in rules.iloc[i]['consequents']:\n             \n            G1.add_nodes_from([c])\n            \n            G1.add_edge(\"R\"+str(i), c, color=colors[i],  weight=2)\n \n  for node in G1:\n       found_a_string = False\n       for item in strs: \n           if node==item:\n                found_a_string = True\n       if found_a_string:\n            color_map.append('yellow')\n       else:\n            color_map.append('green')       \n \n \n   \n  edges = G1.edges()\n  colors = [G1[u][v]['color'] for u,v in edges]\n  weights = [G1[u][v]['weight'] for u,v in edges]\n \n  pos = nx.spring_layout(G1, k=16, scale=1)\n  nx.draw(G1, pos, edges=edges, node_color = color_map, edge_color=colors, width=weights, font_size=16, with_labels=False)            \n   \n  for p in pos:  # raise text positions\n           pos[p][1] += 0.07\n  nx.draw_networkx_labels(G1, pos)\n  plt.show()","8687e6d3":"draw_graph(rules, 20)","47879b0d":"We can see that there are a few points that have moderately high confidence and high support. Those are the ones that we want to take a look into","9f1326e8":" We will do some more discovery to see distribution of sale in term of month,  date of the month, and hour of the day","a8d725b2":"We can see that Saturday is the busiest day of the week for the bakery and Wednesday is the slowest. This is somewhat understandable. ","1bc507f8":"We can see toats and coffee have a highest support, confidence and lift number, which shows that these items are more likely to be bought together.","55366682":"# Market Basket Analysis","4d5db974":"Both of the graphs show  interesting distribution. As we can see, there are no sale going on from May to the end of October. Understanably, the most sale going on time are from 8 - 18, and there are no distrubing trend in term of day of the month sale record. Interestingly, the beginning of the month seems to have the most transaction. From here, I thought it would be interesting to see what date of the week does the bakery has the most transactions.","bad66cb0":"As we can see, there are a lot of 'NONE' recorded item, we could potentially do some investigation on this item. As of right now, since we want to see if there are any correlations between items being bought together, we will drop these NONE item and come back afterwards.","c2e96ede":"# I. Data Discovery"}}