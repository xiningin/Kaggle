{"cell_type":{"88a964ae":"code","1abc5729":"code","b73e3731":"code","41cc2699":"code","3e6004fb":"code","ca5d95b3":"code","6960913f":"code","063b2d78":"code","de85fe56":"code","bfa4c65e":"code","1b9a5939":"code","31f86e0b":"code","2f69f416":"code","fd38a2f9":"code","37cb4ccb":"code","9bddeab5":"code","58f1014a":"code","533f52f5":"code","df39538b":"code","0706080d":"code","a9d7cb84":"code","ad097084":"code","d252b389":"markdown","835bf17f":"markdown","676f9f57":"markdown","12e118ec":"markdown","619644ce":"markdown","bab17d7f":"markdown","be4595a4":"markdown"},"source":{"88a964ae":"import xgboost as xgb\nimport numpy as np\nimport pandas as pd\nimport random\nimport optuna\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nimport seaborn as sns","1abc5729":"train = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/test.csv\")","b73e3731":"train.head()","41cc2699":"Name0=train['loss'].unique()\nName=sorted(Name0)\nprint(Name)","3e6004fb":"target = train['loss']\ndata = train.drop(['loss','id'],axis=1)","ca5d95b3":"fig, ax = plt.subplots(figsize=(16,4))\nsns.histplot(target, label='Train', ax=ax, color='C1',bins=43)\nax.legend()\nax.grid()","6960913f":"columns=data.columns.to_list()\nprint(columns)","063b2d78":"def objective(trial,data=data,target=target):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.2,random_state=42)\n    param = {\n\n        'lambda': trial.suggest_uniform('lambda',0.001,0.1),\n        'alpha': trial.suggest_uniform('alpha',0.1,0.2),\n        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.3,1.0),\n        'subsample': trial.suggest_uniform('subsample', 0.4,0.8),\n        'learning_rate': trial.suggest_uniform('learning_rate', 0.05,0.08),\n        'n_estimators': trial.suggest_int('n_estimators', 1000,4000),\n        'max_depth': trial.suggest_int('max_depth', 3,6),\n        'random_state': trial.suggest_int('random_state', 400,1000),\n        'min_child_weight': trial.suggest_int('min_child_weight', 10,100),\n        'objective': trial.suggest_categorical('objective',['reg:logistic']), \n        'tree_method': trial.suggest_categorical('tree_method',['gpu_hist']),  # 'gpu_hist','hist'       \n        'use_label_encoder': trial.suggest_categorical('use_label_encoder',[False])\n    }\n    model = xgb.XGBClassifier(**param)      \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n    preds = model.predict(test_x)\n    rmse = mean_squared_error(test_y, preds,squared=False)\n    \n    return rmse","de85fe56":"study = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=8)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","bfa4c65e":"study.trials_dataframe()","1b9a5939":"# shows the scores from all trials\noptuna.visualization.plot_optimization_history(study)","31f86e0b":"# interactively visualizes the hyperparameters and scores\noptuna.visualization.plot_parallel_coordinate(study)","2f69f416":"# shows the evolution of the search\noptuna.visualization.plot_slice(study)","fd38a2f9":"# parameter interactions on an interactive chart.\noptuna.visualization.plot_contour(study, params=['alpha','lambda','colsample_bytree'])","37cb4ccb":"# Visualize parameter importances.\noptuna.visualization.plot_param_importances(study)","9bddeab5":"# Visualize empirical distribution function\noptuna.visualization.plot_edf(study)","58f1014a":"Best_trial=study.best_trial.params\nprint(Best_trial)","533f52f5":"sample = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv\")\nprint(sample.shape)","df39538b":"preds = np.zeros((sample.shape[0],len(Name)))\nkf = KFold(n_splits=5,random_state=48,shuffle=True)\nfor trn_idx, test_idx in kf.split(train[columns],target):\n    X_tr,X_val=train[columns].iloc[trn_idx],train[columns].iloc[test_idx]\n    y_tr,y_val=target.iloc[trn_idx],target.iloc[test_idx]\n    model = xgb.XGBClassifier(**Best_trial)\n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False)\n    preds+=model.predict_proba(test[columns])\/kf.n_splits   ###### predict_proba\n    rmse=mean_squared_error(y_val, model.predict(X_val),squared=False)\n    print(rmse)","0706080d":"print(preds.shape)\nprint(preds[0])","a9d7cb84":"subm = sample\nPRED=[]\nfor item in preds:\n    value=np.argmax(item)      \n    PRED+=[value]\nsubm['loss'] = PRED\nsubm.to_csv('submission.csv',index=False)\nsubm","ad097084":"subm['loss'].value_counts()","d252b389":"## Predict","835bf17f":"N=list(range(len(Name)))  \nnormal_mapping=dict(zip(Name,N)) \nreverse_mapping=dict(zip(N,Name)) ","676f9f57":"## Read data","12e118ec":"### Best result of tuning","619644ce":"## Optuna tuning","bab17d7f":"## Target setting","be4595a4":"# XGBoost with Optuna tuning\n* doc: \nhttps:\/\/github.com\/optuna\/optuna"}}