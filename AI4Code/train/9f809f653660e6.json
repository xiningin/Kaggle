{"cell_type":{"34d02ecf":"code","694c1c65":"code","9ddc9f23":"code","f4225cba":"code","0e7e97c3":"code","804066a7":"code","ff670990":"code","800b5205":"code","99492e04":"code","51dfa8ad":"code","4abc4852":"code","4b986044":"code","4ebf3960":"code","bd8d0b3d":"code","5c633c6e":"code","21205d52":"code","419a9cad":"code","90ad7ac5":"code","22ccf60a":"code","218c7137":"code","fcb32fe8":"markdown","d92346c5":"markdown","3340bf55":"markdown","16c738d1":"markdown","b9d17c12":"markdown","fd3cba52":"markdown","54108fe6":"markdown","fcc8863e":"markdown","0845d8b4":"markdown","3a17ba2c":"markdown"},"source":{"34d02ecf":"import tensorflow as tf\nfrom keras.applications import VGG16\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom keras.preprocessing.image import ImageDataGenerator\nimport keras\nimport os\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport cv2\n\nimport glob","694c1c65":"main_path = \"..\/input\/chest-xray-pneumonia\/chest_xray\/\"","9ddc9f23":"train_path = os.path.join(main_path,\"train\")\ntest_path=os.path.join(main_path,\"test\")\nval_path=os.path.join(main_path,\"val\")","f4225cba":"pneumonia_train_images = glob.glob(train_path+\"\/PNEUMONIA\/*.jpeg\")\nnormal_train_images = glob.glob(train_path+\"\/NORMAL\/*.jpeg\")","0e7e97c3":"data = pd.DataFrame(np.concatenate([[0]*len(normal_train_images) , [1] *  len(pneumonia_train_images)]),columns=[\"class\"])","804066a7":"sns.countplot(data['class'],data=data)","ff670990":"# define the type of augmentation techniques we will apply.\ntrain_Datagen = ImageDataGenerator(\n    rescale =1\/255,\n    shear_range=10,\n    zoom_range = 0.2,\n    horizontal_flip = True,\n    width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     rotation_range=20,\n    fill_mode = 'nearest',\n)\nval_datagen = ImageDataGenerator(\n    rescale = 1\/255\n)","800b5205":"conv_base = VGG16(include_top = False,weights='imagenet')\nfor i in conv_base.layers:\n    i.trainable=False\nX = conv_base.output\nX = keras.layers.GlobalAveragePooling2D()(X)\nX = keras.layers.Dense(128,activation='relu')(X)\npredictions = keras.layers.Dense(1,activation='sigmoid')(X)\nmodel= keras.Model(conv_base.input,predictions)\ninitial_learning_rate = 0.1\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=100000,\n    decay_rate=0.96,\n    staircase=True)\nmodel.compile(loss='binary_crossentropy',\n             optimizer=tf.keras.optimizers.RMSprop(lr_schedule),\n             metrics=['accuracy'])","99492e04":"model.summary()","51dfa8ad":"train_generator=train_Datagen.flow_from_directory(\n    train_path,\n    target_size=(150,150),\n    batch_size= 16,\n    class_mode='binary'\n)\nvalidation_generator = val_datagen.flow_from_directory(\n        val_path,\n        target_size=(150,150),\n        batch_size=8,\n        class_mode='binary'\n)\ntest_generator = val_datagen.flow_from_directory(\n    test_path,\n    target_size=(150,150),\n    batch_size=32,\n    class_mode='binary'\n)","4abc4852":"history = model.fit(\n    train_generator,\n    steps_per_epoch = 100,\n    epochs=20,\n    validation_data = validation_generator\n)","4b986044":"accuracy=model.evaluate_generator(test_generator,624)[1]","4ebf3960":"accuracy","bd8d0b3d":"#unfreeze to fine-tune the model and increase the accuracy\nfor i in conv_base.layers:\n    i.trainable = True\n","5c633c6e":"initial_learning_rate = 1e-5\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=100000,\n    decay_rate=0.96,\n    staircase=True)\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(lr_schedule),  # Very slow learning rate\n              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=[keras.metrics.BinaryAccuracy()])","21205d52":"model.fit(\n    train_generator,\n    steps_per_epoch = 50,\n    epochs=100,\n    validation_data = validation_generator\n)","419a9cad":"final_accuracy = model.evaluate_generator(test_generator,624)[1]","90ad7ac5":"final_accuracy","22ccf60a":"accuracy = history.history['accuracy']\nval_accuracy  = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']","218c7137":"plt.figure(figsize=(15,10))\n\nplt.subplot(2, 2, 1)\nplt.plot(accuracy, label = \"Training accuracy\")\nplt.plot(val_accuracy, label=\"Validation accuracy\")\nplt.legend()\nplt.title(\"Training vs validation accuracy\")\n\n\nplt.subplot(2,2,2)\nplt.plot(loss, label = \"Training loss\")\nplt.plot(val_loss, label=\"Validation loss\")\n\nplt.legend()\nplt.title(\"Training vs validation loss\")\n\nplt.show()","fcb32fe8":"# Finetuning the model\nAgain training the model with slower learning rate","d92346c5":"# Saving the model","3340bf55":"### Creating augmented data from the above defined image data generators","16c738d1":"### Clear imbalance between normal and pneumonia class","b9d17c12":"# Defining model\n* Using pre-trained VGG-16 model.\n* Freezing all the layers of model to train.\n* Using RMSProp as optimiser\n* Also  using learning rate decay to optimize the learning process.","fd3cba52":"# Defining Image Generators\n1. Using **ImageDataGenerator** , to augment our images so as to create a larger dataset for our model to train on.\n2. Also to deal with the imbalanced number of data points of the given classes","54108fe6":"# Model Metrics","fcc8863e":"# Visualizing the train and validation accuracy and loss","0845d8b4":"# Unfreezing the layers of model\n","3a17ba2c":"# Importing libraries"}}