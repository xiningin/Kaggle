{"cell_type":{"dbc0efe7":"code","36aed36c":"code","a2a59757":"code","ba219b4d":"code","af704fab":"code","5d84d6a2":"code","1357f64c":"code","f7b5d470":"code","de7b0a79":"code","759d75f8":"code","342d4579":"code","c4cd32e8":"code","3b8a1525":"code","225ce592":"code","aa111faf":"code","2576b75c":"code","c3c0bc92":"code","476ae1b1":"code","41debacb":"code","0f7672e2":"code","e652873c":"code","d784bc4d":"code","a2dac248":"code","052854a5":"code","0c654bdc":"markdown"},"source":{"dbc0efe7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","36aed36c":"import lightgbm as lgb\nimport optuna.integration.lightgbm as oplgb\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nimport category_encoders as ce\nimport seaborn as sns","a2a59757":"df_train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/test.csv\")\ndf_sample = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/sample_submission.csv\")","ba219b4d":"df_train","af704fab":"df_test","5d84d6a2":"train_id = df_train[\"id\"]\ntest_id = df_test[\"id\"]\n\ndf_train.drop(\"id\", axis=1, inplace=True)\ndf_test.drop(\"id\", axis=1, inplace=True)","1357f64c":"cat_features = [f\"cat{i}\" for i in range(9 + 1)]","f7b5d470":"onehot_encoder = ce.one_hot.OneHotEncoder()\nonehot_encoder.fit(pd.concat([df_train[cat_features], df_test[cat_features]], axis=0))\ntrain_ohe = onehot_encoder.transform(df_train[cat_features])\ntest_ohe = onehot_encoder.transform(df_test[cat_features])\ntrain_ohe.columns = [f\"OHE_{col}\" for col in train_ohe]\ntest_ohe.columns = [f\"OHE_{col}\" for col in test_ohe]","de7b0a79":"numerical_features = [f\"cont{i}\" for i in range(13 + 1)]","759d75f8":"train_x = pd.concat([\n    df_train[numerical_features],\n    train_ohe\n], axis=1)","342d4579":"test_x = pd.concat([\n    df_test[numerical_features],\n    test_ohe\n], axis=1)","c4cd32e8":"train_y = df_train[\"target\"]","3b8a1525":"train_x","225ce592":"test_x","aa111faf":"folds = KFold(n_splits=5, shuffle=True, random_state=2021)","2576b75c":"class FoldsAverageLGBM:\n    def __init__(self, folds):\n        self.folds = folds\n        self.models = []\n        \n    def fit(self, lgb_params, train_x, train_y):\n        oof_preds = np.zeros_like(train_y)\n        \n        self.train_x = train_x\n        self.train_y = train_y.values\n        \n        for tr_idx, va_idx in tqdm(folds.split(train_x)):\n            tr_x, va_x = self.train_x.iloc[tr_idx], self.train_x.iloc[va_idx]\n            tr_y, va_y = self.train_y[tr_idx], self.train_y[va_idx]\n            \n            lgb_train_dataset = lgb.Dataset(tr_x, tr_y)\n            lgb_valid_dataset = lgb.Dataset(va_x, va_y)\n            model = lgb.train(lgb_params, lgb_train_dataset, valid_sets=[lgb_valid_dataset], verbose_eval=100)\n            self.models.append(model)\n            \n            oof_pred = model.predict(va_x)\n            oof_preds[va_idx] = oof_pred\n            \n        self.oof_preds = oof_preds\n        \n    def predict(self, test_x):\n        preds = []\n        for model in tqdm(self.models):\n            pred = model.predict(test_x)\n            preds.append(pred)\n        preds = np.mean(preds, axis=0)\n        return preds\n    \n    def get_feature_importance(self, importance_type=\"gain\"):\n        feature_names = self.models[0].feature_name()\n        feature_importances_list = [model.feature_importance(importance_type) for model in self.models]\n        \n        out_df = pd.DataFrame()\n        for i, name in enumerate(feature_names):\n            out_df[name] = [v[i] for v in feature_importances_list]\n        return out_df","c3c0bc92":"def plot_importance(importance_df, max_features=100):\n    feature_order = list(importance_df.mean().sort_values(ascending=False).index[:max_features])\n    target_data = importance_df[feature_order]\n    sns.boxenplot(data=target_data, orient=\"h\", order=feature_order)","476ae1b1":"lgb_params = {\n    'objective': 'regression',\n    'metric': 'rmse',\n    'verbosity': -1,\n    'learning_rate': 0.01,\n    'feature_pre_filter': False,\n    'lambda_l1': 6.271548464074981,\n    'lambda_l2': 6.442666191955093e-05,\n    'num_leaves': 244,\n    'feature_fraction': 0.4,\n    'bagging_fraction': 0.6165715549446614,\n    'bagging_freq': 6,\n    'min_child_samples': 100\n}\nlgb_params[\"learning_rate\"] = 0.001\nlgb_params[\"early_stopping_round\"] = 1000\nlgb_params[\"num_iterations\"] = 20000","41debacb":"folds_average_lgbm = FoldsAverageLGBM(folds)","0f7672e2":"folds_average_lgbm.fit(lgb_params, train_x, train_y)","e652873c":"plt.figure(figsize=(20, 20))\nimportance_df = folds_average_lgbm.get_feature_importance()\nplot_importance(importance_df)","d784bc4d":"np.sqrt(mean_squared_error(df_train.target, folds_average_lgbm.oof_preds))","a2dac248":"y_pred = folds_average_lgbm.predict(test_x)","052854a5":"sub = df_sample.copy()\nsub[\"target\"] = y_pred\n\nsub.to_csv(\"submission_optuna_lgbm_ohe_v2.csv\", index=False)\n\nsub.head()","0c654bdc":"# OneHotEncoder"}}