{"cell_type":{"5831c29b":"code","c42f3593":"code","fd9bac30":"code","971e2125":"code","c42d85e7":"code","5aebdcbf":"code","f4f9f125":"code","4c942eb1":"code","9282d391":"code","5ee65bee":"code","be08d8a6":"code","f7a84f3e":"code","cabeb598":"code","74348998":"code","549c0087":"code","8113474e":"code","21f788d3":"code","829bf8e5":"code","ddf67753":"code","c735348f":"code","1cd62321":"code","b2e15baf":"code","d0b02d61":"code","5a76cdea":"code","3b256935":"code","aa66a3fc":"code","e67d190d":"code","a68d8dcb":"code","f66a90f5":"code","9ccfa749":"code","156ddc1e":"code","22d38a56":"markdown"},"source":{"5831c29b":"# GPU check\n!nvidia-smi","c42f3593":"# Rapids install\n!pip3 install rapids\n!pip3 install cuml","fd9bac30":"# import modlue (Rapids)\nfrom cuml import LinearRegression\nimport cudf, cupy, cuml\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport matplotlib\nimport re","971e2125":"%%time\n# DataFrame (GPU)\ndata = cudf.read_csv(\"\/kaggle\/input\/uk-housing-prices-paid\/price_paid_records.csv\")\ndata.info()","c42d85e7":"# First five data\ndata.head()","5aebdcbf":"# Average price of our homes\ndata['Price'].mean()","f4f9f125":"# I'm removing the unnecessary attribute.\n%time data.drop(['Transaction unique identifier'], axis='columns', inplace=True)","4c942eb1":"# First five data\ndata.head()","9282d391":"# \"Property Type\" visualization\nname = data['Property Type'].factorize()[1].to_arrow()\ndata_pie = []\nc=float(0)\nfor i in name:\n    \n    data_pie.append(cupy.asnumpy(data['Property Type'][data['Property Type'].factorize()[0]==c].count()))\n    c+=1\n\nmatplotlib.pyplot.title(\"Property Type\", fontdict=None, loc='center', pad=None)\nplt.pie(data_pie, labels=name, autopct='%0.f%%', startangle=90)","5ee65bee":"# \"Old\/New\" visualization\nname = data['Old\/New'].factorize()[1].to_arrow()\ndata_pie = []\nc=float(0)\nfor i in name:\n    \n    data_pie.append(cupy.asnumpy(data['Old\/New'][data['Old\/New'].factorize()[0]==c].count()))\n    c+=1\n\nmatplotlib.pyplot.title(\"Old\/New\", fontdict=None, loc='center', pad=None)\nplt.pie(data_pie, labels=name, autopct='%0.f%%', startangle=90)","be08d8a6":"# \"Duration\" visualization\nname = data['Duration'].factorize()[1].to_arrow()\ndata_pie = []\nc=float(0)\nfor i in name:\n    \n    data_pie.append(cupy.asnumpy(data['Duration'][data['Duration'].factorize()[0]==c].count()))\n    c+=1\n\nmatplotlib.pyplot.title(\"Duration\", fontdict=None, loc='center', pad=None)\nplt.pie(data_pie, labels=name, autopct='%0.f%%', startangle=90)","f7a84f3e":"# \"PPDCategory Type\" visualization\nname = data['PPDCategory Type'].factorize()[1].to_arrow()\ndata_pie = []\nc=float(0)\nfor i in name:\n    \n    data_pie.append(cupy.asnumpy(data['PPDCategory Type'][data['PPDCategory Type'].factorize()[0]==c].count()))\n    c+=1\n\nmatplotlib.pyplot.title(\"PPDCategory Type\", fontdict=None, loc='center', pad=None)\nplt.pie(data_pie, labels=name, autopct='%0.f%%', startangle=90)","cabeb598":"# \"Record Status - monthly file only\" visualization\n# I am of the opinion that this column is unnecessary, so I will not buy this column in the train phase.\n\nname = data['Record Status - monthly file only'].factorize()[1].to_arrow()\ndata_pie = []\nc=float(0)\nfor i in name:\n    \n    data_pie.append(cupy.asnumpy(data['Record Status - monthly file only'][data['Record Status - monthly file only'].factorize()[0]==c].count()))\n    c+=1\n\nmatplotlib.pyplot.title(\"Record Status - monthly file only\", fontdict=None, loc='center', pad=None)\nplt.pie(data_pie, labels=name, autopct='%0.f%%', startangle=90)","74348998":"# We translate our column named \"Date of Transfer\" in a way that the model can understand.\n# dt_name is the name of the column that is of type datepart\n\ndef add_datepart(df, dt_name, drop=True, time=False):\n    \"Creates new columns from our datetime column\"\n    \n    \n    dt_column = df[dt_name]\n    column_dtype = dt_column.dtype\n    \n\n    targ_name = re.sub('[Dd]ate$', '', dt_name)\n    \n    # attributes are normally in lower case but we wrote this way because we will use it in columns' name too\n    attr = ['Year', 'Month', 'Day']\n    \n    if time: \n        attr = attr + ['Hour', 'Minute', 'Second']\n        \n    \n    #Sorry curse of dimensionality, maybe another time\n    for a in attr: \n        df[targ_name + a] = getattr(dt_column.dt, a.lower())\n        \n    # how much time passed, we will divide by 10^9 because it is in the nanosecond format\n    df[targ_name + 'Elapsed'] = dt_column.astype(cupy.int64) \/\/ 10 ** 9\n    \n    if drop: \n        df.drop(dt_name, axis=1, inplace=True)","549c0087":"# We convert the column data type to datetime64 [ns] type.\ndata['Date of Transfer']=data['Date of Transfer'].astype('datetime64[ns]')\nadd_datepart(data, 'Date of Transfer', drop=True, time=False)","8113474e":"# new data\ndata.head()","21f788d3":"# We convert data from non-numeric to numeric, because our model cannot infer from string data.\nprint(data['Old\/New'].factorize()[1])\nprint(\"\\n\\n\",data['Old\/New'].factorize()[0])","829bf8e5":"print(data['Town\/City'].factorize()[1])\nprint(\"\\n\\n\",data['Town\/City'].factorize()[0])","ddf67753":"%%time\n# numeric\ndata['Property Type']=data['Property Type'].factorize()[0].astype('float32')\ndata['Old\/New']=data['Old\/New'].factorize()[0].astype('float32')\ndata['Duration']=data['Duration'].factorize()[0].astype('float32')\ndata['Town\/City']=data['Town\/City'].factorize()[0].astype('float32')\ndata['District']=data['District'].factorize()[0].astype('float32')\ndata['County']=data['County'].factorize()[0].astype('float32')\ndata['PPDCategory Type']=data['PPDCategory Type'].factorize()[0].astype('float32')\ndata['Record Status - monthly file only']=data['Record Status - monthly file only'].factorize()[0].astype('float32')\n\ndata['Price'] = data['Price'].astype('float32')","c735348f":"# data info\ndata.info()","1cd62321":"# new data\n# First five data\ndata.head()","b2e15baf":"data.shape","d0b02d61":"# I divide the data into \"test\" and \"train\".\ntempX = data[['Property Type', 'Old\/New', 'Duration', 'Town\/City', 'District', 'County', 'PPDCategory Type', 'Date of TransferYear', 'Date of TransferMonth', 'Date of TransferDay', 'Date of TransferElapsed']]\ntempY = data[['Price']]\n\nx_train, x_test, y_train, y_test  = cuml.train_test_split(tempX, tempY, train_size=0.8)","5a76cdea":"x_train.head()","3b256935":"y_train.head()","aa66a3fc":"# Linear regression on the GPU.\nlr = LinearRegression()\nlr.fit(x_train, y_train)","e67d190d":"# Predict\npred = cudf.DataFrame()\ntemp =lr.predict(x_test)\npred[\"Pred\"] = temp\npred[\"Pred\"] = pred[\"Pred\"].astype('float64')\npred","a68d8dcb":"# Label\ny_test[\"Price\"] = y_test[\"Price\"].astype('float64')\ny_test","f66a90f5":"# MSE\ncuml.metrics.regression.mean_squared_error(y_test, pred)","9ccfa749":"# RMSE\ncuml.metrics.regression.mean_squared_error(y_test, pred, squared=False)","156ddc1e":"# R^2\ncuml.metrics.r2_score(y_test, pred)","22d38a56":"![](https:\/\/miro.medium.com\/max\/4096\/1*dNJ0fhCPqYsrLeSLCjswig.png)\n\nRAPIDS uses optimized **NVIDIA CUDA\u00ae** primitives and high-bandwidth GPU memory to accelerate data preparation and machine learning. The goal of RAPIDS is not only to accelerate the individual parts of the typical data science workflow, but to accelerate the complete end-to-end workflow. \n\nIn this project, after taking and processing 2.9+ GB of data, we will try to make an inference with linear regression."}}