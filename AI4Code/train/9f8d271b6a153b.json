{"cell_type":{"56945365":"code","fe632376":"code","c0f13646":"code","a2b4135c":"code","eecabedf":"code","c8997f83":"code","b5056c0f":"code","7b9c7688":"markdown"},"source":{"56945365":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn.metrics import log_loss, mean_squared_error\nfrom sklearn.impute import SimpleImputer\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression","fe632376":"df = pd.read_csv(\"..\/input\/d\/pasadenian\/titanic\/train_5folds.csv\") # use your own splitted data (5 folds)\ndf_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in ('PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin', 'kfold')]\nobject_cols = ['Pclass', 'Sex', 'Embarked']\nobject_cols_to_impute = ['Embarked']\nnumerical_cols_to_impute = ['Age', 'Fare']\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    \n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    imputer1 = SimpleImputer(strategy='median')\n    xtrain[numerical_cols_to_impute] = imputer1.fit_transform(xtrain[numerical_cols_to_impute])\n    xvalid[numerical_cols_to_impute] = imputer1.transform(xvalid[numerical_cols_to_impute])\n    xtest[numerical_cols_to_impute] = imputer1.transform(xtest[numerical_cols_to_impute])\n    \n    imputer2 = SimpleImputer(strategy='most_frequent')\n    xtrain[object_cols_to_impute] = imputer2.fit_transform(xtrain[object_cols_to_impute])\n    xvalid[object_cols_to_impute] = imputer2.transform(xvalid[object_cols_to_impute])\n    xtest[object_cols_to_impute] = imputer2.transform(xtest[object_cols_to_impute])\n\n    valid_ids = xvalid.PassengerId.values.tolist()\n\n    ytrain = xtrain.Survived\n    yvalid = xvalid.Survived\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    model = XGBClassifier(\n        random_state=fold, \n        use_label_encoder=False, \n        objective='binary:logistic',\n        eval_metric='logloss'\n    )  \n    \n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict_proba(xvalid)\n    preds_valid_binary = model.predict(xvalid)\n    test_preds = model.predict_proba(xtest)\n    final_test_predictions.append([x[1] for x in test_preds])\n    final_valid_predictions.update(dict(zip(valid_ids, [x[1] for x in preds_valid])))\n    loss = log_loss(yvalid, preds_valid_binary)\n    print(fold, loss)\n    scores.append(loss)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"PassengerId\", \"pred_1\"]\nfinal_valid_predictions.to_csv(\"train_pred_1.csv\", index=False)\n\nsample_submission.Survived = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"PassengerId\", \"pred_1\"]\nsample_submission.to_csv(\"test_pred_1.csv\", index=False)","c0f13646":"df = pd.read_csv(\"..\/input\/d\/pasadenian\/titanic\/train_5folds.csv\") # use your own splitted data (5 folds)\ndf_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in ('PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin', 'kfold')]\nobject_cols = ['Pclass', 'Sex', 'Embarked']\nobject_cols_to_impute = ['Embarked']\nnumerical_cols_to_impute = ['Age', 'Fare']\ndf_test = df_test[useful_features]\n\nfor col in object_cols:\n    temp_df = []\n    temp_test_feat = None\n    for fold in range(5):\n        xtrain =  df[df.kfold != fold].reset_index(drop=True)\n        xvalid = df[df.kfold == fold].reset_index(drop=True)\n        xtest = df_test.copy()\n        \n        feat = xtrain.groupby(col)[\"Survived\"].agg(\"mean\")\n        feat = feat.to_dict()\n        \n        imputer1 = SimpleImputer(strategy='median')\n        xtrain[numerical_cols_to_impute] = imputer1.fit_transform(xtrain[numerical_cols_to_impute])\n        xvalid[numerical_cols_to_impute] = imputer1.transform(xvalid[numerical_cols_to_impute])\n        xtest[numerical_cols_to_impute] = imputer1.transform(xtest[numerical_cols_to_impute])\n            \n        imputer2 = SimpleImputer(strategy='most_frequent')\n        xtrain[object_cols_to_impute] = imputer2.fit_transform(xtrain[object_cols_to_impute])\n        xvalid[object_cols_to_impute] = imputer2.transform(xvalid[object_cols_to_impute])\n        xtest[object_cols_to_impute] = imputer2.transform(xtest[object_cols_to_impute])\n    \n        xvalid.loc[:, f\"tar_enc_{col}\"] = xvalid[col].map(feat)\n        temp_df.append(xvalid)\n        if temp_test_feat is None:\n            temp_test_feat = df_test[col].map(feat)\n        else:\n            temp_test_feat += df_test[col].map(feat)\n    \n    temp_test_feat \/= 5\n    df_test.loc[:, f\"tar_enc_{col}\"] = temp_test_feat\n    df = pd.concat(temp_df)\n\n#---\n\nuseful_features = [c for c in df.columns if c not in ('PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin', 'kfold')]\nobject_cols = ['Pclass', 'Sex', 'Embarked']\nobject_cols_to_impute = ['Embarked']\nnumerical_cols_to_impute = ['Age', 'Fare']\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    \n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    imputer1 = SimpleImputer(strategy='median')\n    xtrain[numerical_cols_to_impute] = imputer1.fit_transform(xtrain[numerical_cols_to_impute])\n    xvalid[numerical_cols_to_impute] = imputer1.transform(xvalid[numerical_cols_to_impute])\n    xtest[numerical_cols_to_impute] = imputer1.transform(xtest[numerical_cols_to_impute])\n    \n    imputer2 = SimpleImputer(strategy='most_frequent')\n    xtrain[object_cols_to_impute] = imputer2.fit_transform(xtrain[object_cols_to_impute])\n    xvalid[object_cols_to_impute] = imputer2.transform(xvalid[object_cols_to_impute])\n    xtest[object_cols_to_impute] = imputer2.transform(xtest[object_cols_to_impute])\n\n    valid_ids = xvalid.PassengerId.values.tolist()\n\n    ytrain = xtrain.Survived\n    yvalid = xvalid.Survived\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    model = XGBClassifier(\n        random_state=fold, \n        use_label_encoder=False, \n        objective='binary:logistic',\n        eval_metric='logloss'\n    )  \n    \n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict_proba(xvalid)\n    preds_valid_binary = model.predict(xvalid)\n    test_preds = model.predict_proba(xtest)\n    final_test_predictions.append([x[1] for x in test_preds])\n    final_valid_predictions.update(dict(zip(valid_ids, [x[1] for x in preds_valid])))\n    loss = log_loss(yvalid, preds_valid_binary)\n    print(fold, loss)\n    scores.append(loss)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"PassengerId\", \"pred_2\"]\nfinal_valid_predictions.to_csv(\"train_pred_2.csv\", index=False)\n\nsample_submission.Survived = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"PassengerId\", \"pred_2\"]\nsample_submission.to_csv(\"test_pred_2.csv\", index=False)","a2b4135c":"df = pd.read_csv(\"..\/input\/d\/pasadenian\/titanic\/train_5folds.csv\") # use your own splitted data (5 folds)\ndf_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in ('PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin', 'kfold')]\nobject_cols = ['Pclass', 'Sex', 'Embarked']\nobject_cols_to_impute = ['Embarked']\nnumerical_cols_to_impute = ['Age', 'Fare']\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    \n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    imputer1 = SimpleImputer(strategy='median')\n    xtrain[numerical_cols_to_impute] = imputer1.fit_transform(xtrain[numerical_cols_to_impute])\n    xvalid[numerical_cols_to_impute] = imputer1.transform(xvalid[numerical_cols_to_impute])\n    xtest[numerical_cols_to_impute] = imputer1.transform(xtest[numerical_cols_to_impute])\n    \n    imputer2 = SimpleImputer(strategy='most_frequent')\n    xtrain[object_cols_to_impute] = imputer2.fit_transform(xtrain[object_cols_to_impute])\n    xvalid[object_cols_to_impute] = imputer2.transform(xvalid[object_cols_to_impute])\n    xtest[object_cols_to_impute] = imputer2.transform(xtest[object_cols_to_impute])\n\n    valid_ids = xvalid.PassengerId.values.tolist()\n\n    ytrain = xtrain.Survived\n    yvalid = xvalid.Survived\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ohe = preprocessing.OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n    xtrain_ohe = ohe.fit_transform(xtrain[object_cols])\n    xvalid_ohe = ohe.transform(xvalid[object_cols])\n    xtest_ohe = ohe.transform(xtest[object_cols])\n    \n    xtrain_ohe = pd.DataFrame(xtrain_ohe, columns=[f\"ohe_{i}\" for i in range(xtrain_ohe.shape[1])])\n    xvalid_ohe = pd.DataFrame(xvalid_ohe, columns=[f\"ohe_{i}\" for i in range(xvalid_ohe.shape[1])])\n    xtest_ohe = pd.DataFrame(xtest_ohe, columns=[f\"ohe_{i}\" for i in range(xtest_ohe.shape[1])])\n\n    xtrain = pd.concat([xtrain, xtrain_ohe], axis=1)\n    xvalid = pd.concat([xvalid, xvalid_ohe], axis=1)\n    xtest = pd.concat([xtest, xtest_ohe], axis=1)\n    \n    xtrain = xtrain.drop(object_cols, axis=1)\n    xvalid = xvalid.drop(object_cols, axis=1)\n    xtest = xtest.drop(object_cols, axis=1)\n    \n    model = XGBClassifier(\n        random_state=fold, \n        use_label_encoder=False, \n        objective='binary:logistic',\n        eval_metric='logloss'\n    )  \n    \n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict_proba(xvalid)\n    preds_valid_binary = model.predict(xvalid)\n    test_preds = model.predict_proba(xtest)\n    final_test_predictions.append([x[1] for x in test_preds])\n    final_valid_predictions.update(dict(zip(valid_ids, [x[1] for x in preds_valid])))\n    loss = log_loss(yvalid, preds_valid_binary)\n    print(fold, loss)\n    scores.append(loss)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"PassengerId\", \"pred_3\"]\nfinal_valid_predictions.to_csv(\"train_pred_3.csv\", index=False)\n\nsample_submission.Survived = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"PassengerId\", \"pred_3\"]\nsample_submission.to_csv(\"test_pred_3.csv\", index=False)","eecabedf":"df = pd.read_csv(\"..\/input\/d\/pasadenian\/titanic\/train_5folds.csv\") # use your own splitted data (5 folds)\ndf_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\n\ndf1 = pd.read_csv(\"train_pred_1.csv\")\ndf2 = pd.read_csv(\"train_pred_2.csv\")\ndf3 = pd.read_csv(\"train_pred_3.csv\")\n\ndf_test1 = pd.read_csv(\"test_pred_1.csv\")\ndf_test2 = pd.read_csv(\"test_pred_2.csv\")\ndf_test3 = pd.read_csv(\"test_pred_3.csv\")\n\ndf = df.merge(df1, on=\"PassengerId\", how=\"left\")\ndf = df.merge(df2, on=\"PassengerId\", how=\"left\")\ndf = df.merge(df3, on=\"PassengerId\", how=\"left\")\n\ndf_test = df_test.merge(df_test1, on=\"PassengerId\", how=\"left\")\ndf_test = df_test.merge(df_test2, on=\"PassengerId\", how=\"left\")\ndf_test = df_test.merge(df_test3, on=\"PassengerId\", how=\"left\")\n\ndf.head()","c8997f83":"useful_features = [\"pred_1\", \"pred_2\", \"pred_3\"]\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.Survived\n    yvalid = xvalid.Survived\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    model = LogisticRegression()\n    model.fit(xtrain, ytrain)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict_proba(xtest)\n    final_predictions.append([x[1] for x in test_preds])\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","b5056c0f":"sample_submission.Survived = [int(x>=0.5) for x in np.mean(np.column_stack(final_predictions), axis=1)]\nsample_submission.to_csv(\"submission.csv\", index=False)","7b9c7688":"Inherited from https:\/\/www.kaggle.com\/abhishek\/competition-part-5-blending-101"}}