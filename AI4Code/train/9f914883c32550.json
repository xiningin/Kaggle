{"cell_type":{"d7c04d82":"code","5961cb67":"code","9ea9abd4":"code","bba7ba3a":"code","3fd7bc65":"code","1f4520cd":"code","16859c69":"code","7666f30f":"code","836201a0":"code","4a18d1f7":"code","a00e6cc4":"code","70a61906":"code","d4f1cbb0":"code","ac0a0756":"code","dc8c4f5f":"code","65375e2b":"code","be0dad9d":"code","e1c5c16d":"code","3a238a53":"code","b4338db9":"code","34307d69":"code","e85dd7a3":"code","adcb1435":"code","9d27ce4c":"code","ef03586a":"code","e813366c":"code","aab9420d":"code","42ecb0d0":"code","53eabafc":"code","94db35b3":"code","c42fb365":"code","ca2c926a":"code","e2631e43":"code","e8704384":"code","edfb0491":"code","e64e88ce":"code","e5c5c1af":"code","33083724":"code","a83a3272":"code","3540d698":"code","9a7e7dfc":"code","ca95d3fb":"code","26f203a5":"code","c0b32b2f":"code","d8a83c5f":"markdown","12fde27f":"markdown","c8139faf":"markdown","bb88ad7c":"markdown","ec7418b2":"markdown","0efdb3b7":"markdown","2f812696":"markdown","eb62ac91":"markdown","cadb3c08":"markdown","9f7395ab":"markdown"},"source":{"d7c04d82":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #visualization\nimport seaborn as sns #visualization\nimport missingno as msno #visulaize the distribution of NaN values.\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import VarianceThreshold\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5961cb67":"train_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntrain_df.head()","9ea9abd4":"test_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntest_df.head()","bba7ba3a":"plt.figure(figsize=(20,5))\nsns.distplot(train_df.SalePrice)\nplt.title(\"Sales Price distribution in Train dataset\")\nplt.ylabel(\"Density\")","3fd7bc65":"isna_train = train_df.isnull().sum().sort_values(ascending=False)\nisna_test = test_df.isnull().sum().sort_values(ascending=False)","1f4520cd":"plt.subplot(2,1,1)\nplt_1=isna_train[:30].plot(kind='bar')\nplt.ylabel('Train Data')\nplt.subplot(2,1,2)\nisna_test[:30].plot(kind='bar')\nplt.ylabel('Test Data')\nplt.xlabel('Number of features which are NaNs');","16859c69":"(train_df.isnull().sum()\/len(train_df)).sort_values(ascending=False)[:25]","7666f30f":"missing_percentage=(train_df.isnull().sum()\/len(train_df)).sort_values(ascending=False)[:20]","836201a0":"missing_percentage","4a18d1f7":"train_df=train_df.drop(missing_percentage.index[:5],1)\ntest_df=test_df.drop(missing_percentage.index[:5],1)","a00e6cc4":"#Finding the columns whether they are categorical or numerical\ncols = train_df[missing_percentage.index[5:]].columns\nnum_cols = train_df[missing_percentage.index[5:]]._get_numeric_data().columns\nprint(\"Numerical Columns\",num_cols)\ncat_cols=list(set(cols) - set(num_cols))\nprint(\"Categorical Columns:\",cat_cols)","70a61906":"plt.figure(figsize=[12,10])\nplt.subplot(331)\nsns.distplot(train_df['LotFrontage'].dropna().values)\nplt.xlabel(\"LotFrontage\")\nplt.subplot(332)\nsns.distplot(train_df['GarageYrBlt'].dropna().values)\nplt.xlabel(\"GarageYrBlt\")\nplt.subplot(333)\nsns.distplot(train_df['MasVnrArea'].dropna().values)\nplt.xlabel(\"MasVnrArea\")\nplt.suptitle(\"Distribution of numerical data before Data imputaion\");","d4f1cbb0":"train_df['LotFrontage']= train_df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\ntrain_df['GarageYrBlt']= train_df.groupby('Neighborhood')['GarageYrBlt'].transform(lambda x: x.fillna(x.median()))\ntrain_df['MasVnrArea']= train_df.groupby('Neighborhood')['MasVnrArea'].transform(lambda x: x.fillna(x.median()))\n","ac0a0756":"plt.figure(figsize=[12,10])\nplt.subplot(331)\nsns.distplot(train_df['LotFrontage'].values)\nplt.xlabel(\"LotFrontage\")\nplt.subplot(332)\nsns.distplot(train_df['GarageYrBlt'].values)\nplt.xlabel(\"GarageBlt\")\nplt.subplot(333)\nsns.distplot(train_df['MasVnrArea'].values)\nplt.xlabel('MasVnrArea')\nplt.suptitle('Distribution of data after data imputaion');","dc8c4f5f":"test_df['LotFrontage']= train_df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\ntest_df['GarageYrBlt']= train_df.groupby('Neighborhood')['GarageYrBlt'].transform(lambda x: x.fillna(x.median()))\ntest_df['MasVnrArea']= train_df.groupby('Neighborhood')['MasVnrArea'].transform(lambda x: x.fillna(x.median()))\n","65375e2b":"for column in cat_cols:\n    train_df[column]=train_df.groupby('Neighborhood')[column].transform(lambda x: x.fillna(x.mode()))\n    test_df[column]=test_df.groupby('Neighborhood')[column].transform(lambda x: x.fillna(x.mode()))","be0dad9d":"num_cols = train_df._get_numeric_data().columns\nprint(\"Numerical Columns\",num_cols)\ncat_cols=list(set(cols) - set(num_cols))\nprint(\"Categorical Columns:\",cat_cols)","e1c5c16d":"Neighbor = train_df.groupby(['Neighborhood','YearBuilt'])['SalePrice']\nNeighbor = Neighbor.describe()['mean'].to_frame()\nNeighbor = Neighbor.reset_index(level=[0,1])\nNeighbor = Neighbor.groupby('Neighborhood')","3a238a53":"Neighbor_index = train_df ['Neighborhood'].unique()\nfig = plt.figure(figsize=(50,12))\nfig.suptitle('Yearwise Trend of each Neighborhood')\nfor num in range(1,25):\n    temp = Neighbor.get_group(Neighbor_index[num])\n    ax = fig.add_subplot(6,4,num)\n    ax.plot(temp['YearBuilt'],temp['mean'])\n    ax.set_title(temp['Neighborhood'].unique())\n","b4338db9":"#Finding the columns whether they are categorical or numerical\ncols = train_df.columns\nnum_cols = train_df._get_numeric_data().columns\nprint(\"Numerical Columns\",num_cols)\ncat_cols=list(set(cols) - set(num_cols))\nprint(\"Categorical Columns:\",cat_cols)","34307d69":"from sklearn.preprocessing import LabelEncoder\nfor i in cat_cols:\n    train_df[i]=LabelEncoder().fit_transform(train_df[i].astype(str)) \n    test_df[i]=LabelEncoder().fit_transform(test_df[i].astype(str)) ","e85dd7a3":"fig,ax = plt.subplots(figsize=(10,10))\nsns.heatmap(train_df.corr(),ax=ax,annot= False,linewidth= 0.02,linecolor='black',fmt='.2f',cmap = 'Blues')\nplt.show()","adcb1435":"#price range correlation\ncorr = train_df.corr()\ncorr = corr.sort_values(by=[\"SalePrice\"],ascending=False).iloc[0].sort_values(ascending=False)\nplt.figure(figsize=(15,20))\nsns.barplot(x=corr.values,y=corr.index.values)\nplt.title(\"Correlation Plot\");","9d27ce4c":"#Forming a new dataset that has columns having more than 0.15 correlation\nindex=[]\nTrain=pd.DataFrame()\nY=train_df['SalePrice']\nfor i in range(0,len(corr)):\n    if corr[i] > 0.15 and corr.index[i]!='SalePrice':\n        index.append(corr.index[i])\nX=train_df[index]","ef03586a":"X['cond*qual'] = (train_df['OverallCond'] * train_df['OverallQual']) \/ 100.0\nX['home_age_when_sold'] = train_df['YrSold'] - train_df['YearBuilt']\nX['garage_age_when_sold'] = train_df['YrSold'] - train_df['GarageYrBlt']\nX['TotalSF'] = train_df['TotalBsmtSF'] + train_df['1stFlrSF'] + train_df['2ndFlrSF'] \nX['total_porch_area'] = train_df['WoodDeckSF'] + train_df['OpenPorchSF'] + train_df['EnclosedPorch'] + train_df['3SsnPorch'] + train_df['ScreenPorch'] \nX['Totalsqrfootage'] = (train_df['BsmtFinSF1'] + train_df['BsmtFinSF2'] +train_df['1stFlrSF'] + train_df['2ndFlrSF'])\nX['Total_Bathrooms'] = (train_df['FullBath'] + (0.5 * train_df['HalfBath']) +train_df['BsmtFullBath'] + (0.5 * train_df['BsmtHalfBath']))\n#X['Id'] = train_df['Id']","e813366c":"test_df['cond*qual'] = (test_df['OverallCond'] * test_df['OverallQual']) \/ 100.0\ntest_df['home_age_when_sold'] = test_df['YrSold'] - test_df['YearBuilt']\ntest_df['garage_age_when_sold'] =test_df['YrSold'] - test_df['GarageYrBlt']\ntest_df['TotalSF'] = test_df['TotalBsmtSF'] + test_df['1stFlrSF'] + test_df['2ndFlrSF'] \ntest_df['total_porch_area'] = test_df['WoodDeckSF'] +test_df['OpenPorchSF'] + test_df['EnclosedPorch'] + test_df['3SsnPorch'] + test_df['ScreenPorch'] \ntest_df['Totalsqrfootage'] = (test_df['BsmtFinSF1'] + test_df['BsmtFinSF2'] +test_df['1stFlrSF'] + test_df['2ndFlrSF'])\ntest_df['Total_Bathrooms'] = (test_df['FullBath'] + (0.5 * test_df['HalfBath']) +test_df['BsmtFullBath'] + (0.5 * test_df['BsmtHalfBath']))","aab9420d":"Old_Cols=['OverallCond','OverallQual','YrSold','YearBuilt','YrSold','GarageYrBlt','TotalBsmtSF','1stFlrSF','2ndFlrSF','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','BsmtFinSF1','BsmtFinSF2','1stFlrSF','2ndFlrSF','FullBath','HalfBath','BsmtFullBath','BsmtHalfBath']","42ecb0d0":"Final_cols=[]\nfor i in X.columns:\n    if i not in Old_Cols and i!='SalePrice':\n        Final_cols.append(i)\nX=X[Final_cols]","53eabafc":"fig = plt.figure(figsize=(20,16))\n\nplt.subplot(2, 2, 1)\nplt.scatter(X['home_age_when_sold'],Y)\nplt.title(\"Home Age Vs SalePrice \")\nplt.ylabel(\"SalePrice\")\nplt.xlabel(\"Home Age\")\n\nplt.subplot(2, 2, 2)\nplt.scatter(X['Total_Bathrooms'],Y)\nplt.title(\"Total_Bathrooms Vs SalePrice \")\nplt.ylabel(\"SalePrice\")\nplt.xlabel(\"Total_Bathrooms\")\n\nplt.subplot(2, 2, 3)\nplt.scatter(X['TotalSF'],Y)\nplt.title(\"TotalSF Vs SalePrice \")\nplt.ylabel(\"SalePrice\")\nplt.xlabel('TotalSF')\n\nplt.subplot(2, 2, 4)\nplt.scatter(X[ 'cond*qual'],Y)\nplt.title(\"House Condition Vs SalePrice \")\nplt.ylabel(\"SalePrice\")\nplt.xlabel('cond*qual')\n\nplt.show()","94db35b3":"X.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);","c42fb365":"temp=pd.DataFrame()\ntemp=X\ntemp['SalePrice']=Y","ca2c926a":"for i in range(0, len(temp.columns), 5):\n    sns.pairplot(data=temp,\n                x_vars=temp.columns[i:i+5],\n                y_vars=['SalePrice'])\n","e2631e43":"from sklearn.preprocessing import LabelEncoder\n\n# process columns, apply LabelEncoder to categorical features\nfor c in Old_Cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(train_df[c].values)) \n    train_df[c] = lbl.transform(list(train_df[c].values))\n\n# shape        \nprint('Shape Train_df: {}'.format(train_df.shape))","e8704384":"valid_x=X[Final_cols]\nvalid_y=X['SalePrice']","edfb0491":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n#data = pd.read_csv(\"D:\/\/Blogs\/\/train.csv\")\n#X = data.iloc[:,0:20]  #independent columns\n#y = data.iloc[:,-1]    #target column i.e price range\n#apply SelectKBest class to extract top 10 best features\nbestfeatures = SelectKBest(score_func=chi2, k=10)\nfit = bestfeatures.fit(valid_x,valid_y)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\n#concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Specs','Score']  #naming the dataframe column\n#print(featureScores.nlargest(20,'Score'))  #print 10 best feature\n\nchi2_cols = ['LotArea','Totalsqrfootage','TotalSF','MasVnrArea','BsmtUnfSF','GrLivArea','total_porch_area',\n            'GarageArea','home_age_when_sold','garage_age_when_sold','LotFrontage','Neighborhood','HouseStyle','Fireplaces',\n            'TotRmsAbvGrd','RoofStyle','GarageCars','Foundation','Total_Bathrooms','Electrical']\n\nchi2_cols","e64e88ce":"chi2_X = X[chi2_cols]\nchi2_y = X['SalePrice']","e5c5c1af":"\"\"\"#data imputaion of test dataset\nfor d in Old_Cols:\n    lbld    = LabelEncoder()\n    lbld.fit(list(test_df[d].values))\n    #test_df[d] = lbld.transform(list(test_df[d].values))\n\n#shape\nprint('Shape of test_df: {}'.format(test_df.shape))\"\"\"","33083724":"from sklearn.ensemble import RandomForestRegressor\n\n#pre_col = ['LotArea', 'OverallQual', 'YearBuilt', 'TotRmsAbvGrd']\n\n#train_y = train_df.SalePrice\n#train_x = train_df[pre_col]\n\nmy_model = RandomForestRegressor()\nmy_model.fit(chi2_X,chi2_y)","a83a3272":"\"\"\"from sklearn.linear_model import LinearRegression\nmy_model = LinearRegression()\"\"\"\nmy_model.fit(chi2_X,chi2_y)","3540d698":"test_df['Total_Bathrooms']= test_df.groupby('Neighborhood')['Total_Bathrooms'].transform(lambda x: x.fillna(x.median()))\ntest_df['GarageCars']= test_df.groupby('Neighborhood')['GarageCars'].transform(lambda x: x.fillna(x.median()))\ntest_df['TotalSF']= test_df.groupby('Neighborhood')['TotalSF'].transform(lambda x: x.fillna(x.median()))\ntest_df['GarageArea']= test_df.groupby('Neighborhood')['GarageArea'].transform(lambda x: x.fillna(x.median()))\ntest_df['BsmtUnfSF']= test_df.groupby('Neighborhood')['BsmtUnfSF'].transform(lambda x: x.fillna(x.median()))\ntest_df['Totalsqrfootage']= test_df.groupby('Neighborhood')['Totalsqrfootage'].transform(lambda x: x.fillna(x.median()))\n","9a7e7dfc":"from xgboost import XGBRegressor\nmodel = RandomForestRegressor(n_estimators=100)\nmodel.fit(chi2_X,chi2_y)","ca95d3fb":"test_x = test_df [chi2_cols]\npredicted_prices = my_model.predict(test_x)\nprint(predicted_prices)","26f203a5":"pred = model.predict(test_x)\nprint(pred)","c0b32b2f":"my_submission = pd.DataFrame({\"Id\":test_df[\"Id\"],\"SalePrice\": predicted_prices})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","d8a83c5f":"After data imputation there no much cahnge in the data distribution , so we are using this method to fill in test dataset","12fde27f":"Exploration and analysis","c8139faf":"**Feature Selection**","bb88ad7c":"**Checking the missing values**","ec7418b2":"Percentage of missing values in each features","0efdb3b7":"Numerical distributions before Data imputaion","2f812696":"Still more to come..\n\nHappy Kaggling :)","eb62ac91":"Dropping the columns with highest percentage of missing values","cadb3c08":"Checking the missing data values in both datasets","9f7395ab":"Label Encoding Categorical variables"}}