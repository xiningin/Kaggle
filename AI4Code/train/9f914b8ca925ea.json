{"cell_type":{"72176579":"code","0a9fd5ae":"code","98ca561b":"code","cded7cd6":"code","574e91f7":"code","18642834":"code","31fa73f0":"code","6eb0e010":"code","b30d5014":"code","489a0be9":"code","d6081ea4":"code","f1f87234":"code","e4d6589a":"code","b7838b49":"code","b0b432e3":"code","b6b7331e":"code","a1e8fba0":"code","e3288e6b":"code","7f033994":"code","19276baf":"code","9e6d3c23":"code","94b03a7a":"code","db3dbca6":"code","bb93fffb":"code","8c6fe03d":"code","426268ea":"code","f66a6bb2":"code","4629849d":"code","aac5c004":"code","df4aee9d":"code","7af87d64":"code","18ae58d3":"code","2f418dbd":"code","e4d04311":"code","784b07b0":"markdown","cfd33c26":"markdown"},"source":{"72176579":"\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","0a9fd5ae":"# important libraries\nimport numpy as np # linear algebra\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\n\nfrom kmodes.kprototypes import KPrototypes\nfrom sklearn.metrics import silhouette_score","98ca561b":"train = pd.read_csv('\/kaggle\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv')\n","cded7cd6":"target_col = 'target'\n\nprint('Total number of rows =',train.shape[0])\nprint('Total number of columns =',train.shape[1])\nprint('===================================')\nprint(train.info())\nprint('===================================')\nfor i in train.columns:\n    null_value = train[i].isnull().sum()\n    if null_value > 0 :\n        print(f'This column {i} has = {null_value}')\n        \n# Majority of our data is object type","574e91f7":"# last_new_job \nprint(train.last_new_job.value_counts())\nprint(train.last_new_job.shape)\ntrain.last_new_job.fillna('never',inplace=True)","18642834":"# company_size\nprint(train.company_size.value_counts())\nprint(train.company_size.shape)\nprint('==================================')\n# company_type\nprint(train.company_type.value_counts())\nprint(train.company_type.shape)\n\n\n# we will deal with them together, if both are null values let create our own company\n# with company_size = 100, company_type = other\ntrain.company_size.fillna('0-100',inplace=True)\ntrain.company_type.fillna('Other',inplace=True)","31fa73f0":"# experience\nprint(train.experience.value_counts())\nprint(train.experience.shape)\n\n# Lets fill null values with 0 \ntrain.experience.fillna(0 ,inplace=True)","6eb0e010":"# major_discipline\nprint(train.major_discipline.value_counts())\nprint(train.major_discipline.shape)\n\n# With high school as education level, major discipline has null values \n# lets give another category to them as 'Not_applicable'\ntrain.major_discipline.fillna('Not_applicable',inplace=True)","b30d5014":"# education_level\nprint(train.education_level.value_counts())\nprint(train.education_level.shape)\n# if you notice if education level is null then major too is none, lets drop them as per now\ntrain.dropna(subset=['education_level'], inplace=True)\nprint(train.education_level.shape)","489a0be9":"# enrolled_university\nprint(train.enrolled_university.value_counts())\n# lets assume null values that they have not enrolled\ntrain.enrolled_university.fillna('no_enrollment',inplace=True)","d6081ea4":"# lets impute null values after understanding each column one by one\n# gender\nprint(train.gender.value_counts())\n# as there are 4508 null values, that mean either they forget of mention or they dont want to reveal\n# lets give them with other category only\ntrain.gender.fillna('Other',inplace=True)","f1f87234":"# As we are done with filling null values, Lets do some visualization to understand data\n# our main agenda to find which factor contribute more towards our target col i.e target","e4d6589a":"train.city.value_counts()","b7838b49":"\nfig, axs = plt.subplots(nrows=4,ncols=2, figsize=(15,20))\nsns.countplot(x=\"relevent_experience\",hue='target', data=train, ax=axs[0,0])\nsns.countplot(x=\"enrolled_university\",hue='target', data=train, ax=axs[0,1])\nsns.countplot(x=\"education_level\",hue='target', data=train, ax=axs[1,0])\nsns.countplot(x=\"major_discipline\",hue='target', data=train, ax=axs[1,1])\nsns.countplot(x=\"experience\",hue='target', data=train, ax=axs[2,0])\nsns.countplot(x=\"company_size\",hue='target', data=train, ax=axs[2,1])\nsns.countplot(x=\"company_type\",hue='target', data=train, ax=axs[3,0])\nsns.countplot(x=\"last_new_job\",hue='target', data=train, ax=axs[3,1])","b0b432e3":"cdi = train.sort_values(by='city_development_index', ascending=True)[:1000]\nfigure = plt.figure(figsize=(10,6))\nsns.barplot(y=cdi.city, x=cdi.city_development_index)\nplt.xticks()\nplt.xlabel('city_development_index')\nplt.ylabel('city')\nplt.title('City by city development index')\nplt.show()","b6b7331e":"sns.distplot(train['city_development_index'])","a1e8fba0":"! pip install dython\nfrom dython.model_utils import roc_graph\nfrom dython.nominal import associations\n\n# we will use this for finding corrleation between cateogrical columns","e3288e6b":"train.columns","7f033994":"Cat_data = train[['city_development_index','training_hours',\n                 'city','gender','relevent_experience',\n               'enrolled_university','education_level',\n              'major_discipline','experience','company_size','company_type',\n              'last_new_job','target']]\ndef associations_example():\n    cols = associations(Cat_data,nominal_columns=['city','gender','relevent_experience',\n                                           'enrolled_university','education_level',\n                                          'major_discipline','experience','company_size','company_type',\n                                          'last_new_job','target'])\n    df = pd.DataFrame(cols['corr'])\n    return df\n#     cm = data[cols].corr()\n    \nplt.rcParams[\"figure.figsize\"]=15,10\ndf = associations_example()","19276baf":"# df.tail(1)\ndf = df.sort_values('target', axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last')\ndf[['target']]\n\n# these help us to know how these fators has correlation with target col.\n# as we will be using tree classifier so no need to worry about high correalation","9e6d3c23":"X=train.drop(['target'],axis=1)\nX.corrwith(train['target']).plot.bar(\n        figsize = (10, 5), title = \"Correlation with Target\", fontsize = 10,\n        rot = 50, grid = True)","94b03a7a":"# lets use decsion tree for seeing which col are determining factor\n#first we need to convert categorical column into integer\ncat_cols = ['city','relevent_experience','gender','relevent_experience',\n           'enrolled_university','education_level',\n           'major_discipline','experience','company_size',\n           'company_type','last_new_job']\nfor i in cat_cols:\n    # empty dictionary\n    my_dict = {}\n    u_v = pd.DataFrame(train[i].value_counts())\n    u_v['index'] = u_v.index\n    for p,q in enumerate(u_v.index):\n        my_dict.update({q:p})        \n    train[i] = train[i].replace(my_dict)","db3dbca6":"train = train.drop(columns='enrollee_id')\ntrain.head()","bb93fffb":"X = train.drop(columns='target')\nY = train['target']\nX_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.23, random_state=42, stratify=Y)\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X_train, y_train)\n\n","8c6fe03d":"valuable_cols = pd.DataFrame(clf.feature_importances_)\nvaluable_cols['index'] = X_train.columns\nvaluable_cols = valuable_cols.sort_values(by=0, ascending=False)\nsns.barplot(y='index',x=0,data=valuable_cols)\n\n\n# This tells us feature which will act as deciding factor","426268ea":"#Getting the list of Numerical and Categorical Variables\nnum_cols = train._get_numeric_data().columns\nprint (num_cols)","f66a6bb2":"#Choosing optimal K value\n# cost = []\n# X = train\n# for num_clusters in list(range(2,7)):\n#     kproto = KPrototypes(n_clusters=num_clusters, init='Huang', random_state=42,n_jobs=-2,max_iter=15,n_init=50) \n#     kproto.fit_predict(X, categorical=[0])\n#     cost.append(kproto.cost_)\n\n# plt.plot(cost)\n# plt.xlabel('K')\n# plt.ylabel('cost')\n# plt.show\n\n\n# it came to be 2","4629849d":"# Running K-Prototype clustering\nX = train\nkproto = KPrototypes(n_clusters=2, init='Huang', verbose=0, random_state=42,max_iter=20, n_init=50,n_jobs=-2,gamma=.25) \nclusters = kproto.fit_predict(X, categorical=[0])","aac5c004":"# Calculate Silhoutte Score\n#\nscore = silhouette_score(X, clusters, metric='euclidean')\n#\n# Print the score\n# \nprint('Kprototype Silhouetter Score: %.3f' % score)","df4aee9d":"# We have segregated into two cluster lets analysze it\ncluster_data = train.copy()\ncluster_data['cluster'] = clusters\ncluster_data_0 = cluster_data[cluster_data['cluster']==0].reset_index(drop=True)\ncluster_data_1 = cluster_data[cluster_data['cluster']==1].reset_index(drop=True)\n\n#################################################################\n\n\nfig, axs = plt.subplots(nrows=4,ncols=2, figsize=(15,20))\nsns.countplot(x=\"relevent_experience\",hue='target', data=cluster_data_0, ax=axs[0,0])\nsns.countplot(x=\"relevent_experience\",hue='target', data=cluster_data_1, ax=axs[0,1])\nsns.countplot(x=\"education_level\",hue='target', data=cluster_data_0, ax=axs[1,0])\nsns.countplot(x=\"education_level\",hue='target', data=cluster_data_1, ax=axs[1,1])\nsns.countplot(x=\"experience\",hue='target', data=cluster_data_0, ax=axs[2,0])\nsns.countplot(x=\"experience\",hue='target', data=cluster_data_1, ax=axs[2,1])\nsns.countplot(x=\"company_type\",hue='target', data=cluster_data_0, ax=axs[3,0])\nsns.countplot(x=\"company_type\",hue='target', data=cluster_data_1, ax=axs[3,1])","7af87d64":"feat=train.drop(['target'],axis=1)\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=4)\npca_result = pca.fit_transform(feat.values)","18ae58d3":"components = pd.DataFrame(np.round(pca.components_, 6), columns = list(feat.keys()))\ncomponents","2f418dbd":"ratios = pca.explained_variance_ratio_.reshape(len(pca.components_), 1)\nvariance_ratios = pd.DataFrame(np.round(ratios, 4), columns = ['Explained Variance'])\nvariance_ratios.index = [1,2,3,4]\nvariance_ratios\n\n# In Pca first component explain 88% of the data followed by other components","e4d04311":"fig, ax = plt.subplots(nrows=2,figsize = (15,15))\n\n#  Plot the feature weights as a function of the components\ncomponents.iloc[:,5:].plot(ax = ax[0], kind = 'bar')\ncomponents.iloc[:,:5].plot(ax = ax[1], kind = 'bar')\n\n# we can see training_hours,city, experince, company_size are quite important which is already explained above","784b07b0":"# **If you like my work please upvote**","cfd33c26":" K-Prototype clustering"}}