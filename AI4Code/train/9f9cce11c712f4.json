{"cell_type":{"5dc4ff62":"code","cd8afa50":"code","944596fc":"code","70055435":"code","39005c2d":"code","36a8d06f":"code","8637bdb9":"code","99009a1c":"code","0981746e":"code","c8aa39fc":"code","ff139bd2":"code","7f482512":"code","78460aa6":"code","697a3c1b":"code","af7866ee":"code","96cb7c7b":"code","82162890":"code","54111943":"code","3061e7fd":"code","0faa98d2":"code","e0433611":"code","b3de436e":"code","1cb1825e":"code","a969a2d0":"markdown","fc3ff12d":"markdown"},"source":{"5dc4ff62":"import os\nimport pandas as pd\n\ndata_path = '..\/input\/movielens-20m-dataset'\nmovies_filename = 'movie.csv'\nratings_filename = 'rating.csv'","cd8afa50":"# read data\ndf_movies = pd.read_csv(\n    os.path.join(data_path, movies_filename),\n    usecols=['movieId', 'title'],\n    dtype={'movieId': 'int32', 'title': 'str'})\n\ndf_ratings = pd.read_csv(\n    os.path.join(data_path, ratings_filename),\n    usecols=['userId', 'movieId', 'rating'],\n    dtype={'userId': 'int32', 'movieId': 'int32', 'rating': 'float32'})","944596fc":"df_movies.head()","70055435":"df_movies.shape","39005c2d":"df_ratings.head()","36a8d06f":"# df_ratings.shape\ndf_ratings=df_ratings[:2000000]","8637bdb9":"df_ratings.shape","99009a1c":"num_users = len(df_ratings.userId.unique())\nnum_items = len(df_ratings.movieId.unique())\nprint('There are {} unique users and {} unique movies in this data set'.format(num_users, num_items))","0981746e":"# get count\ndf_ratings_cnt_tmp = pd.DataFrame(df_ratings.groupby('rating').size(), columns=['count'])\ndf_ratings_cnt_tmp","c8aa39fc":"# there are a lot more counts in rating of zero\ntotal_cnt = num_users * num_items\nrating_zero_cnt = total_cnt - df_ratings.shape[0]\n\ndf_ratings_cnt = df_ratings_cnt_tmp.append(\n    pd.DataFrame({'count': rating_zero_cnt}, index=[0.0]),\n    verify_integrity=True,\n).sort_index()\ndf_ratings_cnt","ff139bd2":"#log normalise to make it easier to interpret on a graph\nimport numpy as np\ndf_ratings_cnt['log_count'] = np.log(df_ratings_cnt['count'])\ndf_ratings_cnt","7f482512":"import matplotlib.pyplot as plt\nplt.style.use('ggplot')\n\nget_ipython().run_line_magic('matplotlib', 'inline')\nax = df_ratings_cnt[['count']].reset_index().rename(columns={'index': 'rating score'}).plot(\n    x='rating score',\n    y='count',\n    kind='bar',\n    figsize=(12, 8),\n    title='Count for Each Rating Score (in Log Scale)',\n    logy=True,\n    fontsize=12,\n)\nax.set_xlabel(\"movie rating score\")\nax.set_ylabel(\"number of ratings\")","78460aa6":"# get rating frequency\n# number of ratings each movie got\ndf_movies_cnt = pd.DataFrame(df_ratings.groupby('movieId').size(), columns=['count'])\ndf_movies_cnt.head()","697a3c1b":"# now we need to take only movies that have been rated at least 50 times to get some idea of the reactions of users towards it\npopularity_thres = 50\npopular_movies = list(set(df_movies_cnt.query('count >= @popularity_thres').index))\ndf_ratings_drop_movies = df_ratings[df_ratings.movieId.isin(popular_movies)]\nprint('shape of original ratings data: ', df_ratings.shape)\nprint('shape of ratings data after dropping unpopular movies: ', df_ratings_drop_movies.shape)","af7866ee":"# get number of ratings given by every user\ndf_users_cnt = pd.DataFrame(df_ratings_drop_movies.groupby('userId').size(), columns=['count'])\ndf_users_cnt.head()","96cb7c7b":"# filter data to come to an approximation of user likings.\nratings_thres = 50\nactive_users = list(set(df_users_cnt.query('count >= @ratings_thres').index))\ndf_ratings_drop_users = df_ratings_drop_movies[df_ratings_drop_movies.userId.isin(active_users)]\nprint('shape of original ratings data: ', df_ratings.shape)\nprint('shape of ratings data after dropping both unpopular movies and inactive users: ', df_ratings_drop_users.shape)","82162890":"from scipy.sparse import csr_matrix\n\n# pivot and create movie-user matrix\nmovie_user_mat = df_ratings_drop_users.pivot(index='movieId', columns='userId', values='rating').fillna(0)\n# map movie titles to images\nmovie_to_idx = {\n    movie: i for i, movie in \n    enumerate(list(df_movies.set_index('movieId').loc[movie_user_mat.index].title))\n}\n# transform matrix to scipy sparse matrix\nmovie_user_mat_sparse = csr_matrix(movie_user_mat.values)","54111943":"movie_user_mat_sparse","3061e7fd":"from sklearn.neighbors import NearestNeighbors\n# define model\nmodel_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n# fit\nmodel_knn.fit(movie_user_mat_sparse)","0faa98d2":"from fuzzywuzzy import fuzz\n\ndef fuzzy_matching(mapper, fav_movie, verbose=True):\n    \"\"\"\n    return the closest match via fuzzy ratio. \n    \n    Parameters\n    ----------    \n    mapper: dict, map movie title name to index of the movie in data\n    fav_movie: str, name of user input movie\n    \n    verbose: bool, print log if True\n    Return\n    ------\n    index of the closest match\n    \"\"\"\n    match_tuple = []\n    # get match\n    for title, idx in mapper.items():\n        ratio = fuzz.ratio(title.lower(), fav_movie.lower())\n        if ratio >= 60:\n            match_tuple.append((title, idx, ratio))\n    # sort\n    match_tuple = sorted(match_tuple, key=lambda x: x[2])[::-1]\n    if not match_tuple:\n        print('Oops! No match is found')\n        return\n    if verbose:\n        print('Found possible matches in our database: {0}\\n'.format([x[0] for x in match_tuple]))\n    return match_tuple[0][1]","e0433611":"def make_recommendation(model_knn, data, mapper, fav_movie, n_recommendations):\n    \"\"\"\n    return top n similar movie recommendations based on user's input movie\n    Parameters\n    ----------\n    model_knn: sklearn model, knn model\n    data: movie-user matrix\n    mapper: dict, map movie title name to index of the movie in data\n    fav_movie: str, name of user input movie\n    n_recommendations: int, top n recommendations\n    Return\n    ------\n    list of top n similar movie recommendations\n    \"\"\"\n    # fit\n    model_knn.fit(data)\n    \n    # get input movie index\n    print('You have input movie:', fav_movie)\n    idx = fuzzy_matching(mapper, fav_movie, verbose=True)\n    \n    print('Recommendation system start to make inference')\n    print('......\\n')\n    distances, indices = model_knn.kneighbors(data[idx], n_neighbors=n_recommendations+1)\n    \n    raw_recommends =         sorted(list(zip(indices.squeeze().tolist(), distances.squeeze().tolist())), key=lambda x: x[1])[:0:-1]\n    # get reverse mapper\n    reverse_mapper = {v: k for k, v in mapper.items()}\n    # print recommendations\n    print('Recommendations for {}:'.format(fav_movie))\n    for i, (idx, dist) in enumerate(raw_recommends):\n        print('{0}: {1}, with distance of {2}'.format(i+1, reverse_mapper[idx], dist))","b3de436e":"my_favorite = 'Iron Man'\n\nmake_recommendation(\n    model_knn=model_knn,\n    data=movie_user_mat_sparse,\n    fav_movie=my_favorite,\n    mapper=movie_to_idx,\n    n_recommendations=10)","1cb1825e":"#movie_to_idx","a969a2d0":"modeled after this article: https:\/\/heartbeat.fritz.ai\/recommender-systems-with-python-part-ii-collaborative-filtering-k-nearest-neighbors-algorithm-c8dcd5fd89b2","fc3ff12d":"Issues with KNN-Based Collaborative Filtering\n* popularity bias: The system is biased towards movies that have the most user interaction (i.e. ratings and reviews).\n* item cold-start problem: When a new movie is added to the list, it has a lot less user interaction and thus will rarely occur as a recommendation.\n* scalability issue: The issue of managing a movie-user dataset matrix as the count of users and movies increase, since the matrix that we will deal with will have 90% of the values being 0. Storing such a sparse matrix wastes space when the database accommodates millions of users and movies."}}