{"cell_type":{"98211546":"code","e234997c":"code","2685881f":"code","b2c7c653":"code","4c7820f6":"code","b5c54e54":"code","d333685d":"code","0138a59f":"code","7a5a6cd8":"code","d6ee8f86":"code","5d0b40a3":"code","7710b5de":"code","80fb55fb":"code","b158423a":"code","e1bebd51":"code","9906d82d":"code","c379e816":"code","b6e7bbaa":"code","17ac9b08":"code","125bbcbb":"code","441cb3fa":"code","9b8c4eb2":"code","5d84c49d":"code","e00d84e8":"code","2c570679":"code","e2feb9f9":"code","864e3f00":"code","f6985c18":"code","cd8565ff":"code","26587c3e":"code","f796c610":"code","a39cf63e":"code","83431845":"code","a7689c38":"code","118d3199":"code","3e83a105":"code","06fbfb65":"code","eb1f6e4b":"code","28833749":"code","806205da":"code","29fe9ba1":"code","37536a1e":"markdown","7c4b1b09":"markdown","50d428b1":"markdown","70c57579":"markdown","31dfbb80":"markdown","5d770987":"markdown","844c7a17":"markdown","940ee532":"markdown","994f1d02":"markdown","30366b32":"markdown","aafb7fae":"markdown","546e5f0e":"markdown","b25df2f0":"markdown","24ffb5e6":"markdown","fa0dad9b":"markdown","b18be342":"markdown","c3591616":"markdown","56a3121f":"markdown","80242dfa":"markdown","76f99242":"markdown","c7c7f89c":"markdown","ae76a2f1":"markdown","0f3d51c6":"markdown","e113f4b7":"markdown","901c598d":"markdown","6a9a7d3c":"markdown","679520c5":"markdown"},"source":{"98211546":"%matplotlib inline\nimport pandas as pd\nfrom datetime import datetime\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom sklearn.linear_model import LinearRegression, Ridge,BayesianRidge\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.metrics import mean_squared_error\nfrom math import radians, cos, sin, asin, sqrt\nimport seaborn as sns\nimport matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [16, 10]","e234997c":"test= pd.read_csv('..\/input\/Test.csv')\ntrain=pd.read_csv('..\/input\/Train (2).csv')\n","2685881f":"pd.set_option('display.float_format', lambda x: '%.3f' % x)\ntest.head()","b2c7c653":"pd.set_option('display.float_format', lambda x: '%.3f' % x)\ntrain.head()","4c7820f6":"pd.set_option('display.float_format', lambda x: '%.3f' % x)\ntrain.describe()","b5c54e54":"plt.hist(train['Time from Pickup to Arrival'].values, bins=100)\nplt.xlabel('Time from Pickup to Arrival')\nplt.ylabel('number of train records')\nplt.show()","d333685d":"\nm = np.mean(train['Time from Pickup to Arrival'])\ns = np.std(train['Time from Pickup to Arrival'])\n#train = train[train['Time from Pickup to Arrival'] <= m + 2*s]\n#train2 = train[train['Time from Pickup to Arrival'] >= m - 2*s]\ntrain2 = train[train['Time from Pickup to Arrival'] >= 180]\n","0138a59f":"pd.set_option('display.float_format', lambda x: '%.3f' % x)\ntrain2.describe()","7a5a6cd8":"train2.info()","d6ee8f86":"plt.hist(train2['Time from Pickup to Arrival'].values, bins=100)\nplt.xlabel('Time from Pickup to Arrival')\nplt.ylabel('number of train records')\nplt.show()","5d0b40a3":"train['log_Time from Pickup to Arrival'] = np.log(train['Time from Pickup to Arrival'].values + 1)\nplt.hist(train['log_Time from Pickup to Arrival'].values, bins=100)\nplt.xlabel('log(Time from Pickup to Arrival)')\nplt.ylabel('number of train records')\nplt.show()\nsns.distplot(train[\"log_Time from Pickup to Arrival\"], bins =100)","7710b5de":"plt.plot(train2.groupby('Pickup - Day of Month').count()[['Distance (KM)']], 'o-', label='train')\nplt.plot(test.groupby('Pickup - Day of Month').count()[['Distance (KM)']], 'o-', label='test')\nplt.title('Trips over Time.')\nplt.legend(loc=0)\nplt.ylabel('Trips')\nplt.show()\n","80fb55fb":"plt.plot(train2.groupby('Temperature').mean()[['Time from Pickup to Arrival']], 'o-', label='train')\n\nplt.title('Trips over Time.')\nplt.legend(loc=0)\nplt.ylabel('Trips')\nplt.show()","b158423a":"pc = train2.groupby('Pickup - Day of Month')['Time from Pickup to Arrival'].mean()\nplt.title('Trip duration and Day of Month')\nplt.ylabel('Time in Seconds')\nsns.barplot(pc.index,pc.values)","e1bebd51":"#city_long_border = (-74.03, -73.75)\n#city_lat_border = (40.63, 40.85)\nfig, ax = plt.subplots(ncols=2, sharex=True, sharey=True)\nax[0].scatter(train2['Pickup Long'].values[:100000], train2['Pickup Lat'].values[:100000],\n              color='blue', s=1, label='train', alpha=0.1)\nax[1].scatter(test['Pickup Long'].values[:100000], test['Pickup Lat'].values[:100000],\n              color='green', s=1, label='test', alpha=0.1)\nfig.suptitle('Train and test area overlap.')\nax[0].legend(loc=0)\nax[0].set_ylabel('latitude')\nax[0].set_xlabel('longitude')\nax[1].set_xlabel('longitude')\nax[1].legend(loc=0)\n#plt.ylim(city_lat_border)\n#plt.xlim(city_long_border)\nplt.show()","9906d82d":"vehicle_train = pd.get_dummies(train2['Vehicle Type'], prefix='veh', prefix_sep='_')\nvehicle_test = pd.get_dummies(test['Vehicle Type'], prefix='veh', prefix_sep='_')\npersonal_train = pd.get_dummies(train2['Personal or Business'], prefix='per', prefix_sep='_')\npersonal_test = pd.get_dummies(test['Personal or Business'], prefix='per', prefix_sep='_')","c379e816":"vehicle_train.shape,vehicle_test.shape","b6e7bbaa":"personal_train.shape,personal_test.shape","17ac9b08":"train2 = train2.drop(['Order No','User Id','Vehicle Type','Personal or Business','Placement - Time','Confirmation - Time','Arrival at Pickup - Time','Pickup - Time','Arrival at Destination - Time','Rider Id','Precipitation in millimeters'],axis=1)","125bbcbb":"test = test.drop(['Order No','User Id','Vehicle Type','Personal or Business','Placement - Time','Confirmation - Time','Arrival at Pickup - Time','Pickup - Time','Rider Id','Precipitation in millimeters'],axis=1)","441cb3fa":"train2 = train2.drop(['Arrival at Destination - Day of Month','Arrival at Destination - Weekday (Mo = 1)'],axis=1)","9b8c4eb2":"train2.shape,test.shape","5d84c49d":"Train2= pd.concat([vehicle_train,personal_train,train2],axis=1)","e00d84e8":"Test2= pd.concat([vehicle_test,personal_test,test],axis=1)","2c570679":"Train2.shape,Test2.shape","e2feb9f9":"# Since we have test data, I am not going to split the data\n#train3, test3 = train_test_split(train2, test_size = 0.2)","864e3f00":"y=(Train2['Time from Pickup to Arrival']\/60) #change from seconds to minutes\nTrain2.shape,y.shape,Test2.shape","f6985c18":"#Train2.info(),Test2.info()","cd8565ff":"cols_with_missing = [col for col in Train2.columns \n                                 if Train2[col].isnull().any()]\nreduced_Train2 = Train2.drop(cols_with_missing, axis=1)\nreduced_Test2 = Test2.drop(cols_with_missing, axis=1)\nreduced_Train2.info(),reduced_Test2.info()","26587c3e":"reduced_Train2 = reduced_Train2.drop(['Time from Pickup to Arrival'],axis=1)\nreduced_Train2.info(),reduced_Test2.info()","f796c610":"from sklearn.linear_model import LinearRegression,BayesianRidge,ElasticNet,Lasso,SGDRegressor,Ridge\nlasso = Lasso(alpha = 0.01)\nlasso.fit(reduced_Train2,y)\ny_pred_lasso = lasso.predict(reduced_Test2)","a39cf63e":"FI_lasso = pd.DataFrame({\"Feature Importance\":lasso.coef_}, index=reduced_Train2.columns)\nFI_lasso.sort_values(\"Feature Importance\",ascending=False)","83431845":"FI_lasso[FI_lasso[\"Feature Importance\"]!=0].sort_values(\"Feature Importance\").plot(kind=\"barh\",figsize=(10,15))\nplt.xticks(rotation=90)\nplt.show()","a7689c38":"from sklearn.decomposition import PCA,KernelPCA\npca = PCA(0.95)\n\n#pca = PCA(n_components = 426)\nPCA_reduced_Train2 = pca.fit_transform(reduced_Train2)\n#X_scaled = pca.inverse_transform(lower_dimension_pca)\nvar1 = np.round(pca.explained_variance_ratio_*100, decimals = 1)\nvar1","118d3199":"label =['PC' + str(x) for x in range(1,len(var1)+1)]\nplt.figure(figsize=(15,12))\nplt.bar(x=range(1,len(var1)+1), height = var1 ,tick_label = label)\n\nplt.ylabel(\"Percentage of Explained Variance\")\nplt.xlabel(\"Principle Components\")\nplt.title(\"Principle Component Analysis\")\nplt.show()","3e83a105":"from sklearn.model_selection import cross_val_score,KFold,GridSearchCV,RandomizedSearchCV,StratifiedKFold,train_test_split\n\n# Define Root Mean Square Error \ndef rmse_cv(model,X,y):\n    rmse = np.sqrt(-cross_val_score(model,X,y,scoring=\"neg_mean_squared_error\",cv=5))\n    return rmse","06fbfb65":"from sklearn.ensemble import ExtraTreesRegressor,GradientBoostingRegressor,RandomForestRegressor,VotingClassifier\nfrom sklearn.svm import LinearSVR,SVR\nfrom sklearn.kernel_ridge import KernelRidge\nfrom xgboost import XGBRegressor\n\nmodels = [LinearRegression(),\n             Ridge(),\n             Lasso(alpha=0.01,max_iter=10000),\n             RandomForestRegressor(),\n             GradientBoostingRegressor(),\n             SVR(),\n             LinearSVR(),\n             ElasticNet(alpha = 0.001,max_iter=10000),\n             SGDRegressor(max_iter=1000, tol = 1e-3),\n             BayesianRidge(),\n             KernelRidge(alpha=0.6,kernel='polynomial',degree = 2,coef0=2.5),\n             ExtraTreesRegressor(),\n             XGBRegressor()]\n\nnames = ['LR','Ridge','Lasso','RF','GBR','SVR','LSVR','ENet','SGDR','BayRidge','Kernel','XTreeR','XGBR']","eb1f6e4b":"for model,name in zip(models,names):\n    score = rmse_cv(model,reduced_Train2,y)\n    print(\"{}: {:.6f}, {:4f}\".format(name,score.mean(),score.std()))","28833749":"class grid():\n    def __init__(self,model):\n        self.model = model\n    def grid_get(self,X,y,param_grid):\n        grid_search = GridSearchCV(self.model,param_grid,cv=5,scoring='neg_mean_squared_error')\n        grid_search.fit(X,y)\n        print(grid_search.best_params_,np.sqrt(-grid_search.best_score_))\n        grid_search.cv_results_['mean_test_score'] = np.sqrt(-grid_search.cv_results_['mean_test_score'])\n        print(pd.DataFrame(grid_search.cv_results_)[['params','mean_test_score','std_test_score']])","806205da":"grid(Lasso()).grid_get(reduced_Train2,y,{'alpha':[0.01,0.001,0.0001,0.0002,0.0003,0.0004,0.0005,0.0006,0.0007,0.0009],\n                                       'max_iter':[10000]})","29fe9ba1":"grid(Ridge()).grid_get(reduced_Train2,y,\n                       {'alpha':[10,20,25,30,35,40,45,50,55,57,60,65,70,75,80,100],'max_iter':[10000]})","37536a1e":"Modeling and Evaluation","7c4b1b09":"Let's take a look at what the trip looks like by plotting a timeseries line graph, grouped by the day of month. We can also plot the test data to see if the two datasets follow a similar shape, as well as to see if there are still outliers. \nIt seems that in the beginning of the months there are less trips being taken.","50d428b1":"For Ridge, we have the best combination of parameters identified as {'alpha': 100, 'max_iter': 10000} mean_test_score=12.890 ","70c57579":"## Introduction\n","31dfbb80":"Checking the dummy variables:","5d770987":"Now let's add the indicator variables to our datasets.","844c7a17":"From the patterns of this data, it seems that we can try some data transformations:","940ee532":"Tuning hyperparameters (using GridSearchCV)","994f1d02":"## Data Preparation","30366b32":"I am interested in the time duration from Pickup to Arrival at the last column. Look at the minimum, and the histogram shown below, we should remove some outliers for this column. For the data below the mean, I've decided to exclude data that has less than 2 minute duration.","aafb7fae":"Feature Selection with Lasso Regression","546e5f0e":"GridSearchCV - Lasso","b25df2f0":"First I want to see if there's any trend between temperature and trip duration. It seems to me that in colder (<15 degree) and warmer (>30 degree) the trip duration fluctuate more:","24ffb5e6":"Now I can try to dig into the variables:","fa0dad9b":"## PCA (Principal Component Analysis)","b18be342":"Load the data using the Pandas `read_csv` function:\n","c3591616":"Drop Column (Temperature) with Missing Values","56a3121f":"It seems to me that the day of month has not much impack on the trip duration. ","80242dfa":"## Coordinate Mapping","76f99242":"Dropping some of the catagorical variables:","c7c7f89c":"Crete dummy variables\/hot encoding:","ae76a2f1":"Drop some variables\/columns to match test data:","0f3d51c6":"We can first try and verify that the pickup location data in both sets are fairly similar and representative of one another.","e113f4b7":"We choose 13 models and use 5-folds cross-calidation to evaluate these models.\n\nModels include:\nLinearRegression\nRidge\nLasso\nRandom Forest\nGradient Boosting Tree\nSupport Vector Regression\nLinear Support Vector Regression\nElasticNet\nStochastic Gradient Descent\nBayesianRidge\nKernelRidge\nExtraTreesRegressor\nXgBoost","901c598d":"## Model Prediction","6a9a7d3c":"For Lasso, we have the best combination of parameters identified as {'alpha': 0.01, 'max_iter': 10000}     mean_test_score=12.885 ","679520c5":"## Data summary:"}}