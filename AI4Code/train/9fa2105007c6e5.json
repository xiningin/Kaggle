{"cell_type":{"f8d64647":"code","8353ec80":"code","62108b6c":"code","c46b7add":"code","7702f268":"code","e21c7101":"code","9d905f96":"code","36dfeac8":"code","ad901530":"code","54bdebde":"code","494e7d50":"code","e4fa9eba":"code","5dca9c06":"code","ec9a1406":"code","38229ad1":"code","d6ecc7d5":"code","f8d0a645":"code","f665d3da":"code","f80e3934":"code","64577adb":"code","3f4fad48":"code","a5c0d3e0":"code","7a1326d7":"code","487bd217":"code","000dd0e1":"code","a6471aec":"code","7c0a20d5":"code","d2d773c5":"code","788c324e":"code","209aed3b":"code","480c1a59":"code","ef9fac82":"code","09db9482":"code","5386c9ec":"code","1083fc16":"code","34cdb296":"code","391b4aa3":"code","c10092f9":"code","210f15e1":"code","8fe12dd9":"code","18d9f9e8":"code","e117bbf1":"code","d2883c0c":"code","b338353d":"code","047b94f5":"code","9007dca9":"code","1d51f5d9":"code","6d6c8ec3":"code","f690f34c":"code","9ce76e90":"code","1f2e405c":"code","3617b43e":"code","43a9491e":"code","ac182662":"code","7348854c":"code","227af420":"markdown","fab82382":"markdown","24a3aa63":"markdown","57db45de":"markdown","4cf42f40":"markdown","77bf4b43":"markdown","c1a6b510":"markdown","2272a4fc":"markdown","efd42c56":"markdown","31d79b85":"markdown","7c78f439":"markdown"},"source":{"f8d64647":"# Imports\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","8353ec80":"df = pd.read_csv('..\/input\/tour-travels-customer-churn-prediction\/Customertravel.csv')","62108b6c":"df.head()","c46b7add":"# Checking for missing data\n\ndf.info()","7702f268":"# Double checking just to be sure\n\ndf.isnull().sum()","e21c7101":"# Distribution of Age feature\n\nfig,axes = plt.subplots(nrows=1,ncols=2,figsize=(12,6))\nsns.countplot(data=df,x='Age',ax=axes[0],palette='colorblind')\nsns.countplot(data=df,x='Age',hue='Target',ax=axes[1],palette='colorblind')\nplt.show()\n\n# Interesting to note: There are no 32 year olds who are represented in this dataset.","9d905f96":"# Distribution of Frequent Flyer feature\n\nfig,axes = plt.subplots(nrows=1,ncols=2,figsize=(12,6))\nsns.countplot(data=df,x='FrequentFlyer',ax=axes[0],palette='colorblind')\nsns.countplot(data=df,x='FrequentFlyer',hue='Target',ax=axes[1],palette='colorblind')\nplt.show()","36dfeac8":"# Distribution of Annual Income Class Feature\n\nfig,axes = plt.subplots(nrows=1,ncols=2,figsize=(12,6))\nsns.countplot(data=df,x='AnnualIncomeClass',ax=axes[0],palette='colorblind')\nsns.countplot(data=df,x='AnnualIncomeClass',hue='Target',ax=axes[1],palette='colorblind')\nplt.show()","ad901530":"# Distribution of Services Opted Feature\n\nfig,axes = plt.subplots(nrows=1,ncols=3,figsize=(15,5))\nsns.countplot(data=df,x='ServicesOpted',ax=axes[0],palette='colorblind')\nsns.countplot(data=df,x='ServicesOpted',hue='Target',ax=axes[1],palette='colorblind')\nsns.histplot(data=df,x='ServicesOpted',hue='Target',kde=True,palette='colorblind',ax=axes[2])\nplt.show()","54bdebde":"# Distribution of AccountSyncedToSocialMedia Feature\n\nfig,axes = plt.subplots(nrows=1,ncols=2,figsize=(12,6))\nsns.countplot(data=df,x='AccountSyncedToSocialMedia',ax=axes[0],palette='colorblind')\nsns.countplot(data=df,x='AccountSyncedToSocialMedia',hue='Target',ax=axes[1],palette='colorblind')\nplt.show()","494e7d50":"# Distribution of BookedHotelOrNot feature\nfig,axes = plt.subplots(nrows=1,ncols=2,figsize=(12,6))\nsns.countplot(data=df,x='BookedHotelOrNot',ax=axes[0],palette='colorblind')\nsns.countplot(data=df,x='BookedHotelOrNot',hue='Target',ax=axes[1],palette='colorblind')\nplt.show()","e4fa9eba":"df.describe().transpose()","5dca9c06":"# Creating dummy variables for categorical features so we can create correlation plots, setting drop_first=True to avoid any\n# issues with multicollinearity\n\ndf = pd.get_dummies(df,drop_first=True)\ndf.head()","ec9a1406":"plt.figure(figsize=(9,6))\nsns.heatmap(data=df.corr(),cmap='viridis',annot=True)\nplt.show()","38229ad1":"abs(df.corr()['Target']).sort_values(ascending=False)","d6ecc7d5":"# Checking balance of target label\n\nplt.figure(figsize=(9,6))\nsns.countplot(data=df,x='Target')","f8d0a645":"# Label is pretty unbalanced. we will have to keep this in mind when developing\n# the models\ndf['Target'].value_counts()","f665d3da":"X = df.drop('Target',axis=1)\ny = df['Target']","f80e3934":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=1011)\nscaler = StandardScaler()\nscaled_X_train = scaler.fit_transform(X_train)\nscaled_X_test = scaler.transform(X_test)","64577adb":"from sklearn.neighbors import KNeighborsClassifier\n\n# Preliminary model inpspection using 1 neighbor\nknn_model = KNeighborsClassifier(n_neighbors=1)\nknn_model.fit(scaled_X_train, y_train)\n\nknn_pred = knn_model.predict(scaled_X_test)","3f4fad48":"from sklearn.metrics import confusion_matrix,classification_report,plot_confusion_matrix\n\nconfusion_matrix(y_test,knn_pred)","a5c0d3e0":"print(classification_report(y_test,knn_pred))","7a1326d7":"# Baseline with 1 neighbor performance isn't that great as expected. Going to graph the test error rates to see if the elbow method\n# is appropriate\nfrom sklearn.metrics import accuracy_score","487bd217":"test_error_rates = []\n\nfor k in range(1,30):\n    knn_model = KNeighborsClassifier(n_neighbors=k)\n    knn_model.fit(scaled_X_train,y_train)\n    \n    knn_pred_test = knn_model.predict(scaled_X_test)\n    \n    test_error = 1-accuracy_score(y_test,knn_pred_test)\n    \n    test_error_rates.append(test_error)","000dd0e1":"plt.plot(range(1,30),test_error_rates)\nplt.ylabel('Error Rate')\nplt.xlabel('K Neighbors')\nplt.show()","a6471aec":"# Using a pipeline which we will then use in a Grid Search\n\nscaler = StandardScaler()\nknn = KNeighborsClassifier()","7c0a20d5":"from sklearn.pipeline import Pipeline\n\noperations = [('scaler',scaler),('knn',knn)]\npipe = Pipeline(operations)","d2d773c5":"from sklearn.model_selection import GridSearchCV\n\nk_values = list(range(1,20))\nparam_grid = {'knn__n_neighbors':k_values}\n\nfull_knncv_classifier = GridSearchCV(pipe,param_grid,cv=5,scoring='accuracy')\nfull_knncv_classifier.fit(X_train,y_train)\n\nfull_knn_pred = full_knncv_classifier.predict(X_test)","788c324e":"plot_confusion_matrix(full_knncv_classifier,X_test,y_test)","209aed3b":"print(classification_report(y_test,full_knn_pred))","480c1a59":"from sklearn.metrics import plot_roc_curve","ef9fac82":"fig,ax=plt.subplots(figsize=(12,8))\nplot_roc_curve(full_knncv_classifier,X_test,y_test,\n               ax=ax,name='KNN')\nplt.show()","09db9482":"from sklearn.linear_model import LogisticRegressionCV\n\nlog_model = LogisticRegressionCV(class_weight='Balanced',cv=5,max_iter=10000)\nlog_model.fit(scaled_X_train,y_train)\nlog_pred = log_model.predict(scaled_X_test)","5386c9ec":"log_model.C_","1083fc16":"log_model.coef_","34cdb296":"# Plotting log regression coefficients to see different impacts on model\n\ncoefs = pd.Series(index=X.columns,data=log_model.coef_[0])\ncoefs = coefs.sort_values()\nplt.figure(figsize=(10,6))\nplt.xticks(rotation=70)\nsns.barplot(x=coefs.index,y=coefs.values);","391b4aa3":"plot_confusion_matrix(log_model,scaled_X_test,y_test)","c10092f9":"print(classification_report(y_test,log_pred))","210f15e1":"fig,ax=plt.subplots(figsize=(12,8))\nplot_roc_curve(log_model,scaled_X_test,y_test,ax=ax)\nplt.show()","8fe12dd9":"from sklearn.svm import SVC\n\nsvm = SVC(class_weight='balanced')\nparam_grid = {'C':[1,50,100],'kernel':['linear','rbf'],\n              'gamma':['scale','auto'],'degree':[1,2,3]}","18d9f9e8":"svm_grid = GridSearchCV(svm,param_grid)","e117bbf1":"svm_grid.fit(scaled_X_train,y_train)","d2883c0c":"svm_grid.best_params_","b338353d":"svm_pred = svm_grid.predict(scaled_X_test)","047b94f5":"plot_confusion_matrix(svm_grid,scaled_X_test,y_test)","9007dca9":"fig,ax=plt.subplots(figsize=(12,8))\nplot_roc_curve(svm_grid,scaled_X_test,y_test,ax=ax)\nplt.show()","1d51f5d9":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(random_state=1011,class_weight='balanced')\nparam_grid = {'n_estimators':[64,100,128,200],\n             'max_features':[4,5,6,7,8],\n             'bootstrap':['True','False'],\n             'oob_score':['True','False']}","6d6c8ec3":"rfc_grid = GridSearchCV(rfc,param_grid)","f690f34c":"rfc_grid.fit(X_train,y_train)","9ce76e90":"rfc_grid.best_params_","1f2e405c":"rfc_pred = rfc_grid.predict(X_test)","3617b43e":"fig,ax=plt.subplots(figsize=(12,8))\nplot_roc_curve(rfc_grid,X_test,y_test,ax=ax)\nplt.show()","43a9491e":"print(classification_report(y_test,rfc_pred))","ac182662":"plot_confusion_matrix(rfc_grid,X_test,y_test)\nplt.show()","7348854c":"print(f\"KNN Classification accuracy score is {round(accuracy_score(y_test,knn_pred),5)}\")\nprint(f\"Logistic Regression accuracy score is {round(accuracy_score(y_test,log_pred),5)}\")\nprint(f\"Support Vector Classifier accuracy score is {round(accuracy_score(y_test,svm_pred),5)}\")\nprint(f\"Random Forest Classifier accuracy score is {round(accuracy_score(y_test,rfc_pred),5)}\")","227af420":"Despite KNN performing well in a lot of classification scenarios, I believe that the largely imbalanced classes are affecting the recall of the '1' label. We will see how it performs using logistic regression.","fab82382":"---\n## Exploratory Data Analysis","24a3aa63":"---\n## Logistic Regression","57db45de":"### Conclusion:\n**1**. Frequent Flyer status has the highest correlation to whether or not the customer churns.\n\n**2**. Being a frequent flyer and having high income are the two significant features where Churn exceeds Non-Churn. Intuitively, this makes sense. Someone with more money and who flys a lot is more likely to experiment with different travel companies if they have to travel a lot.\n\n**3**. 27 and 28 year olds churn more than any other age group.\n\n**4**. Overall, it appears that the more services that are opted, the lower the churn rate. It's interesting to explore because the churn rate is minimized at 3 services but starts to grow again after that point. But it seems to plateau and not get much higher.\n\n**5**. People who don't book hotels churn more than those who do, and intuitively this just makes sense.\n\n...","4cf42f40":"---\n## Preprocessing","77bf4b43":"---\n## Random Forest Classifier","c1a6b510":"Support Vector Classifier is performing the best so far.","2272a4fc":"Performing worse than KNN.","efd42c56":"As expected, random forest is performing better than every other classifier at this point in time. Given the fact that the random forest model is the least likely to overfit, I feel it would be most appropriate to deploy this model over the rest.","31d79b85":"## KNN","7c78f439":"---\n## Support Vector Classifier"}}