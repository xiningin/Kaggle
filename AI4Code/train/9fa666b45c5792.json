{"cell_type":{"6ba24567":"code","9453cc05":"code","897d96a3":"code","93886c24":"code","2009cc7f":"code","c7c76c50":"code","419009e2":"code","125a022f":"code","84d3d107":"code","606e5c47":"code","794768ef":"code","828f6c53":"code","116200a0":"code","bf5405cd":"code","9223a183":"code","435b0de6":"code","0129d239":"code","055ebc27":"code","090a4f74":"code","23ba2128":"code","5daed5d1":"code","2ae4b5b4":"code","15316c8b":"code","d134ba3c":"code","41f972e5":"code","b6c2af7c":"code","56e1f667":"code","1f429ef3":"code","1492fab1":"code","b7239eb0":"code","ed0fe428":"code","30604048":"code","5aeefab0":"code","0bd02a35":"code","e4a6c773":"code","6afa39c5":"code","a76147ce":"code","de3c395a":"code","388d881a":"code","8d737aa2":"code","825430c5":"code","5fa2ae23":"markdown","246bcf02":"markdown","b7509a20":"markdown","1711aac5":"markdown","e4b33c23":"markdown","75761ca8":"markdown","5ab7f849":"markdown","43632205":"markdown","d315948e":"markdown","8db5186b":"markdown","df7f98be":"markdown","c7ec60d8":"markdown","9219d23d":"markdown","db3f21c5":"markdown","821713e2":"markdown","2f387368":"markdown","1a0279d7":"markdown","47b810a1":"markdown","267afadf":"markdown","e300f126":"markdown","a3f9e6fe":"markdown","9a1c5e8d":"markdown","36ad0582":"markdown","fbeab557":"markdown"},"source":{"6ba24567":"from collections import defaultdict\nimport os\nfrom pathlib import Path\nimport random\nfrom typing import Dict, List\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (\n    accuracy_score, classification_report, confusion_matrix, \n    ConfusionMatrixDisplay, roc_curve, RocCurveDisplay, \n    precision_recall_curve, PrecisionRecallDisplay\n)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom tqdm.notebook import tqdm ","9453cc05":"plt.rc(\"font\", size=20) #controls default text size\nplt.rc(\"axes\", titlesize=20) #fontsize of the title\nplt.rc(\"axes\", labelsize=20) #fontsize of the x and y labels\nplt.rc(\"xtick\", labelsize=20) #fontsize of the x tick labels\nplt.rc(\"ytick\", labelsize=20) #fontsize of the y tick labels\nplt.rc(\"legend\", fontsize=20) #fontsize of the legend","897d96a3":"data_dir = Path(\"..\/input\/real-world-documents-collections\/docs-sm\")","93886c24":"image_size = 128\ntest_size = 0.2\nrandom_seed = 16","2009cc7f":"random.seed(random_seed)\nnp.random.seed(random_seed)","c7c76c50":"categories = [\"invoice\", \"not_invoice\"]","419009e2":"image_paths = dict(invoice=[], not_invoice=[])\nfor category_path in tqdm(list(data_dir.glob(\"*\"))):\n    category_name = category_path.name\n    if category_name == \"invoice\":\n        image_paths[categories[0]] = random.sample(list(category_path.glob(\"*\")), 50)\n    else:\n        image_paths[categories[1]].extend(random.sample(list(category_path.glob(\"*\")), 10))","125a022f":"fig, ax = plt.subplots(figsize=(10, 10))\nax.bar(categories, [len(image_paths[category]) for category in categories])\nax.set_xlabel(\"Category\")\nax.set_ylabel(\"Count\")\nplt.show()","84d3d107":"Image.open(random.choice([x for y in image_paths.values() for x in y]))","606e5c47":"Image.open(random.choice([x for y in image_paths.values() for x in y]))","794768ef":"def prepare_images(image_paths: Dict[str, List[Path]]) -> Dict[str, List[np.ndarray]]:\n    image_data = dict()\n    for category, image_path_list in tqdm(image_paths.items()):\n        image_array_list = []\n        for image_path in image_path_list:\n            image = cv2.imread(os.fspath(image_path), cv2.IMREAD_GRAYSCALE)\n            image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n            image = cv2.resize(image, (image_size, image_size)).flatten()\n            image_array = np.asarray(image)\n            image_array_list.append(image_array)\n        image_data[category] = image_array_list\n    return image_data","828f6c53":"image_data = prepare_images(image_paths)","116200a0":"fig = plt.figure(figsize=(15, 15))\nax1 = fig.add_subplot(2, 2, 1)\nax2 = fig.add_subplot(2, 2, 2)\nax3 = fig.add_subplot(2, 2, 3)\nax4 = fig.add_subplot(2, 2, 4)\n\ncategory = random.choice(list(image_data.keys()))\nax1.imshow(random.choice(image_data[category]).reshape(image_size, image_size), cmap=\"gray\");\nax1.set_title(category)\nax1.get_xaxis().set_visible(False)\nax1.get_yaxis().set_visible(False)\n\ncategory = random.choice(list(image_data.keys()))\nax2.imshow(random.choice(image_data[category]).reshape(image_size, image_size), cmap=\"gray\");\nax2.set_title(category)\nax2.get_xaxis().set_visible(False)\nax2.get_yaxis().set_visible(False)\n\ncategory = random.choice(list(image_data.keys()))\nax3.imshow(random.choice(image_data[category]).reshape(image_size, image_size), cmap=\"gray\");\nax3.set_title(category)\nax3.get_xaxis().set_visible(False)\nax3.get_yaxis().set_visible(False)\n\ncategory = random.choice(list(image_data.keys()))\nax4.imshow(random.choice(image_data[category]).reshape(image_size, image_size), cmap=\"gray\");\nax4.set_title(category)\nax4.get_xaxis().set_visible(False)\nax4.get_yaxis().set_visible(False)\n\nplt.show()","bf5405cd":"X = np.vstack(image_data[categories[0]] + image_data[categories[1]])\ny = np.array([1] * len(image_data[categories[0]]) + [0] * len(image_data[categories[1]]))","9223a183":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_seed)","435b0de6":"scaler = StandardScaler()","0129d239":"scaler.fit(X_train)","055ebc27":"X_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","090a4f74":"model = LogisticRegression(max_iter=300, random_state=random_seed)","23ba2128":"model.fit(X_train, y_train)","5daed5d1":"y_train_pred = model.predict(X_train)","2ae4b5b4":"print(f\"Accuracy on the training set: {accuracy_score(y_train, y_train_pred)*100}%\")","15316c8b":"print(classification_report(y_train, y_train_pred, labels=[1, 0], target_names=categories))","d134ba3c":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30, 10))\ncm = confusion_matrix(y_train, y_train_pred)\ncm_display = ConfusionMatrixDisplay(cm)\ncm_display.plot(ax=ax1)\ny_train_score = model.decision_function(X_train)\nfpr, tpr, _ = roc_curve(y_train, y_train_score, pos_label=model.classes_[1])\nroc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\nroc_display.plot(ax=ax2)\nx = np.arange(0, 1.1, 0.1)\nax2.plot(x, x, \"--\", label=\"Random Chances\")\nax2.legend(loc=\"lower right\")\nprec, recall, _ = precision_recall_curve(y_train, y_train_score, pos_label=model.classes_[1])\npr_display = PrecisionRecallDisplay(precision=prec, recall=recall)\npr_display.plot(ax=ax3)\nplt.show()","41f972e5":"y_pred = model.predict(X_test)","b6c2af7c":"f\"Accuracy on the test set: {accuracy_score(y_test, y_pred)*100}%\"","56e1f667":"print(classification_report(y_test, y_pred, labels=[1, 0], target_names=categories))","1f429ef3":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30, 10))\ncm = confusion_matrix(y_test, y_pred)\ncm_display = ConfusionMatrixDisplay(cm)\ncm_display.plot(ax=ax1)\ny_score = model.decision_function(X_test)\nfpr, tpr, _ = roc_curve(y_test, y_score, pos_label=model.classes_[1])\nroc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\nroc_display.plot(ax=ax2)\nx = np.arange(0, 1.1, 0.1)\nax2.plot(x, x, \"--\", label=\"Random Chances\")\nax2.legend(loc=\"lower right\")\nprec, recall, _ = precision_recall_curve(y_test, y_score, pos_label=model.classes_[1])\npr_display = PrecisionRecallDisplay(precision=prec, recall=recall)\npr_display.plot(ax=ax3)\nplt.show()","1492fab1":"n_invoice_samples = 150\nn_samples_other_category = 10","b7239eb0":"image_paths = dict(invoice=[], not_invoice=[])\nfor category_path in tqdm(list(data_dir.glob(\"*\"))):\n    category_name = category_path.name\n    if category_name == \"invoice\":\n        image_paths[categories[0]] = random.sample(list(category_path.glob(\"*\")), n_invoice_samples)\n    else:\n        image_paths[categories[1]].extend(random.sample(list(category_path.glob(\"*\")), n_samples_other_category))\n\nimage_data = prepare_images(image_paths)\n\nX = np.vstack(image_data[categories[0]] + image_data[categories[1]])\ny = np.array([1] * len(image_data[categories[0]]) + [0] * len(image_data[categories[1]]))\n# We use stratification for the train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=test_size, random_state=random_seed)","ed0fe428":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\nax1.bar(categories, [np.sum(y_train == 1), np.sum(y_train == 0)])\nax1.set_xlabel(\"Category\")\nax1.set_ylabel(\"Count\")\nax1.set_title(\"Training Data\")\nax2.bar(categories, [np.sum(y_test == 1), np.sum(y_test == 0)])\nax2.set_xlabel(\"Category\")\nax2.set_ylabel(\"Count\")\nax2.set_title(\"Testing Data\")\nplt.show()","30604048":"model = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"lr\", LogisticRegression(max_iter=300, random_state=random_seed))\n])\n\nmodel.fit(X_train, y_train)\ny_train_pred = model.predict(X_train)\ny_pred = model.predict(X_test)","5aeefab0":"print(classification_report(y_train, y_train_pred, labels=[1, 0], target_names=categories))","0bd02a35":"print(classification_report(y_test, y_pred, labels=[1, 0], target_names=categories))","e4a6c773":"from imblearn.over_sampling import ADASYN","6afa39c5":"n_invoice_samples = 50\nn_samples_other_category = 10","a76147ce":"image_paths = dict(invoice=[], not_invoice=[])\nfor category_path in tqdm(list(data_dir.glob(\"*\"))):\n    category_name = category_path.name\n    if category_name == \"invoice\":\n        image_paths[categories[0]] = random.sample(list(category_path.glob(\"*\")), n_invoice_samples)\n    else:\n        image_paths[categories[1]].extend(random.sample(list(category_path.glob(\"*\")), n_samples_other_category))\n\nimage_data = prepare_images(image_paths)\n\nX = np.vstack(image_data[categories[0]] + image_data[categories[1]])\ny = np.array([1] * len(image_data[categories[0]]) + [0] * len(image_data[categories[1]]))\n# We use stratification for the train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=test_size, random_state=random_seed)\n# We oversample the training data\noversampler = ADASYN(random_state=random_seed)\nX_train, y_train = oversampler.fit_resample(X_train, y_train)","de3c395a":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\nax1.bar(categories, [np.sum(y_train == 1), np.sum(y_train == 0)])\nax1.set_xlabel(\"Category\")\nax1.set_ylabel(\"Count\")\nax1.set_title(\"Training Data\")\nax2.bar(categories, [np.sum(y_test == 1), np.sum(y_test == 0)])\nax2.set_xlabel(\"Category\")\nax2.set_ylabel(\"Count\")\nax2.set_title(\"Testing Data\")\nplt.show()","388d881a":"model = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"lr\", LogisticRegression(max_iter=300, random_state=random_seed))\n])\n\nmodel.fit(X_train, y_train)\ny_train_pred = model.predict(X_train)\ny_pred = model.predict(X_test)","8d737aa2":"print(classification_report(y_train, y_train_pred, labels=[1, 0], target_names=categories))","825430c5":"print(classification_report(y_test, y_pred, labels=[1, 0], target_names=categories))","5fa2ae23":"<font size=\"4\">We now evaluate the trained classifier on the test data.<\/font>","246bcf02":"<font size=\"4\">In this demonstration, we will do image classification using what was covered so far in the courses.<\/font>\n\n<font size=\"4\">We will use a simple Logistic Regression model to determine whether a given document image is an invoice or not.<\/font>","b7509a20":"<font size=\"4\">As we can see, not much information remains after shrinking and removing the color information from the images.<\/font>\n\n<font size=\"4\">**Question:** Is it still possible to distinguish between the two kinds of document images? Would a trained model be able to do it?<\/font>","1711aac5":"# **Advanced:** Fixing The Issues","e4b33c23":"# **Libraries**","75761ca8":"# **Data**","5ab7f849":"<font size=\"4\">There are different approaches we can take to fix the issues with our data:<\/font>\n\n* <font size=\"4\">Collect more data<\/font>\n* <font size=\"4\">Select a different metric (Accuracy Paradox)<\/font>\n* <font size=\"4\">Take imbalance into account when doing a Train-Test Split(Stratified Splitting)<\/font>\n* <font size=\"4\">Oversample the minority class and\/or Undersample the majority class<\/font>\n* <font size=\"4\">Generate synthetic data for the minority class<\/font>","43632205":"<font size=\"4\">For this demonstration we will only use part of the data.<\/font>\n\n<font size=\"4\">We will randomly select 50 samples from the **invoice** category and 10 samples from each other category (150)<\/font>","d315948e":"<font size=\"4\">**Questions:**<\/font>\n\n* <font size=\"4\">Are the results good or bad?<\/font>\n* <font size=\"4\">How can we explain this outcome?<\/font>\n* <font size=\"4\">How can we improve the results?<\/font>","8db5186b":"<font size=\"4\">We standardize the data in order to guarantee the conversion of the algorithm used to train the Logistic Regression model.<\/font>","df7f98be":"# **Data Preparation**","c7ec60d8":"<font size=\"4\">**Question:** Why do we fit the scaler only on the training data?<\/font>","9219d23d":"# Useful Resources\n\n* [<font size=\"4\">Precision and Recall: A Tug of War<\/font>](https:\/\/developers.google.com\/machine-learning\/crash-course\/classification\/precision-and-recall)\n* [<font size=\"4\">The Accuracy Paradox<\/font>](https:\/\/en.wikipedia.org\/wiki\/Accuracy_paradox)\n* [<font size=\"4\">Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset\n<\/font>](https:\/\/machinelearningmastery.com\/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset\/)\n* [<font size=\"4\">Imbalanced-learn<\/font>](https:\/\/imbalanced-learn.org\/stable\/)","db3f21c5":"<font size=\"4\">Now that we have finished with data preparation we can split the dataset and proceed with pre-processing and then training<\/font>","821713e2":"## **Oversample the minority class**","2f387368":"## Reminder\n\n* <font size=\"4\">$Precision = \\frac{True\\_Positives}{True\\_Positives + False\\_Positives}$<\/font>\n\n<font size=\"4\">Precision attempts to answer the following question: What proportion of positive identifications was actually correct?<\/font>\n\n\n\n* <font size=\"4\">$Recall =\\frac{True\\_Positives}{True\\_Positives + False\\_Negatives}$<\/font>\n\n<font size=\"4\">Recall attempts to answer the following question: What proportion of actual positives was identified correctly?<\/font>\n\n\n\n* <font size=\"4\">$F1-Score = \\frac{2 * Precision * Recall}{Precision + Recall}$<\/font>","1a0279d7":"<font size=\"4\">**Questions:**<\/font>\n\n* <font size=\"4\">Are the results good or bad?<\/font>\n* <font size=\"4\">How can we explain this outcome?<\/font>","47b810a1":"<font size=\"4\">Before using the images we have to first normalize them and shrink them to the same size<\/font>\n\n<font size=\"4\">For that we will use <\/font>[<font size=\"4\">OpenCV<\/font>](https:\/\/opencv.org\/) <font size=\"4\">(Open Source Computer Vision Library), an open source computer vision and machine learning software library. It was built to provide a common infrastructure for computer vision applications and to accelerate the use of machine perception in commercial products. <\/font>","267afadf":"# **Pre-Processing**","e300f126":"# **Evaluation**","a3f9e6fe":"# **Train-Test Split**","9a1c5e8d":"## **Collect more data**","36ad0582":"# **Constants**","fbeab557":"# **Training**"}}