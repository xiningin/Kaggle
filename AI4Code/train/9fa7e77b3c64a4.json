{"cell_type":{"75b2484e":"code","ef37b065":"code","83539e55":"code","8ef52323":"code","58eae1b8":"code","5b5d8ba7":"code","214708b1":"code","da54a7fb":"code","7526098f":"code","cb677ff8":"code","5c8d3419":"code","54812e81":"code","7441ecf7":"code","b147eb3e":"code","5289765f":"code","e29517bc":"code","0a51103d":"code","37c929ba":"code","15a14919":"code","db7ae509":"code","cefb7dc1":"code","d51999e3":"code","34e825f7":"code","9868cacb":"code","fc472940":"code","1f47ad6b":"code","138b3f69":"code","66f31a6d":"code","46a85993":"code","0365db1b":"code","dabf8a6a":"markdown","02040217":"markdown","411f5441":"markdown","1a59f7ad":"markdown","eb255514":"markdown","3344a22e":"markdown","1fd1b5cd":"markdown","9e782677":"markdown","c143c56a":"markdown","7d46ff46":"markdown","180918a8":"markdown","8af7f712":"markdown","7ce64dce":"markdown","861bd658":"markdown","3c749337":"markdown","28978c7e":"markdown","a029ecb9":"markdown","aac39cc5":"markdown","ce834397":"markdown","bb062a8c":"markdown","70dce098":"markdown","7622ce61":"markdown","f1c29c2e":"markdown"},"source":{"75b2484e":"import time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom prettytable import PrettyTable\nfrom mlxtend.preprocessing import TransactionEncoder\nfrom mlxtend.frequent_patterns import apriori, association_rules, fpgrowth","ef37b065":"# Load the dataset\ngroceries = pd.read_csv(\"..\/input\/groceries-dataset\/Groceries_dataset.csv\")","83539e55":"groceries.shape","8ef52323":"groceries.head()","58eae1b8":"# Get all the transactions as a list of lists\nall_transactions = [transaction[1]['itemDescription'].tolist() for transaction in list(groceries.groupby(['Member_number', 'Date']))]","5b5d8ba7":"# First 21st transactions in the transactional dataset\nlen(all_transactions)","214708b1":"# Look at the 10 first transactions\nall_transactions[0:10]","da54a7fb":"# The following instructions transform the dataset into the required format \ntrans_encoder = TransactionEncoder() # Instanciate the encoder\ntrans_encoder_matrix = trans_encoder.fit(all_transactions).transform(all_transactions)\ntrans_encoder_matrix = pd.DataFrame(trans_encoder_matrix, columns=trans_encoder.columns_)","7526098f":"trans_encoder_matrix.head()","cb677ff8":"def perform_rule_calculation(transact_items_matrix, rule_type=\"fpgrowth\", min_support=0.001):\n    \"\"\"\n    desc: this function performs the association rule calculation \n    @params:\n        - transact_items_matrix: the transaction X Items matrix\n        - rule_type: \n                    - apriori or Growth algorithms (default=\"fpgrowth\")\n                    \n        - min_support: minimum support threshold value (default = 0.001)\n        \n    @returns:\n        - the matrix containing 3 columns:\n            - support: support values for each combination of items\n            - itemsets: the combination of items\n            - number_of_items: the number of items in each combination of items\n            \n        - the excution time for the corresponding algorithm\n        \n    \"\"\"\n    start_time = 0\n    total_execution = 0\n    \n    if(not rule_type==\"fpgrowth\"):\n        start_time = time.time()\n        rule_items = apriori(transact_items_matrix, \n                       min_support=min_support, \n                       use_colnames=True)\n        total_execution = time.time() - start_time\n        print(\"Computed Apriori!\")\n        \n    else:\n        start_time = time.time()\n        rule_items = fpgrowth(transact_items_matrix, \n                       min_support=min_support, \n                       use_colnames=True)\n        total_execution = time.time() - start_time\n        print(\"Computed Fp Growth!\")\n    \n    rule_items['number_of_items'] = rule_items['itemsets'].apply(lambda x: len(x))\n    \n    return rule_items, total_execution\n","5c8d3419":"def compute_association_rule(rule_matrix, metric=\"lift\", min_thresh=1):\n    \"\"\"\n    @desc: Compute the final association rule\n    @params:\n        - rule_matrix: the corresponding algorithms matrix\n        - metric: the metric to be used (default is lift)\n        - min_thresh: the minimum threshold (default is 1)\n        \n    @returns:\n        - rules: all the information for each transaction satisfying the given metric & threshold\n    \"\"\"\n    rules = association_rules(rule_matrix, \n                              metric=metric, \n                              min_threshold=min_thresh)\n    \n    return rules","54812e81":"# Plot Lift Vs Coverage(confidence) \ndef plot_metrics_relationship(rule_matrix, col1, col2):\n    \"\"\"\n    desc: shows the relationship between the two input columns \n    @params:\n        - rule_matrix: the matrix containing the result of a rule (apriori or Fp Growth)\n        - col1: first column\n        - col2: second column\n    \"\"\"\n    fit = np.polyfit(rule_matrix[col1], rule_matrix[col2], 1)\n    fit_funt = np.poly1d(fit)\n    plt.plot(rule_matrix[col1], rule_matrix[col2], 'yo', rule_matrix[col1], \n    fit_funt(rule_matrix[col1]))\n    plt.xlabel(col1)\n    plt.ylabel(col2)\n    plt.title('{} vs {}'.format(col1, col2))","7441ecf7":"def compare_time_exec(algo1=list, alg2=list):\n    \"\"\"\n    @desc: shows the execution time between two algorithms\n    @params:\n        - algo1: list containing the description of first algorithm, where\n            \n        - algo2: list containing the description of second algorithm, where\n    \"\"\"\n    \n    execution_times = [algo1[1], algo2[1]]\n    algo_names = (algo1[0], algo2[0])\n    y=np.arange(len(algo_names))\n    \n    plt.bar(y,execution_times,color=['orange', 'blue'])\n    plt.xticks(y,algo_names)\n    plt.xlabel('Algorithms')\n    plt.ylabel('Time')\n    plt.title(\"Execution Time (seconds) Comparison\")\n    plt.show()","b147eb3e":"val = {'name':12}\nvalue = list(val.items())[0]","5289765f":"value","e29517bc":"fpgrowth_matrix, fp_growth_exec_time = perform_rule_calculation(trans_encoder_matrix) # Run the algorithm\nprint(\"Fp Growth execution took: {} seconds\".format(fp_growth_exec_time))","0a51103d":"fpgrowth_matrix.head()","37c929ba":"fpgrowth_matrix.tail()","15a14919":"fp_growth_rule_lift = compute_association_rule(fpgrowth_matrix)","db7ae509":"fp_growth_rule_lift.head()","cefb7dc1":"plot_metrics_relationship(fp_growth_rule_lift, col1='lift', col2='confidence')","d51999e3":"fp_growth_rule = compute_association_rule(fpgrowth_matrix, metric=\"confidence\", min_thresh=0.2)\nfp_growth_rule.head()","34e825f7":"apriori_matrix, apriori_exec_time = perform_rule_calculation(trans_encoder_matrix, rule_type=\"apriori\")\nprint(\"Apriori Execution took: {} seconds\".format(apriori_exec_time))","9868cacb":"apriori_matrix.head()","fc472940":"apriori_matrix.tail()","1f47ad6b":"apriori_rule_lift = compute_association_rule(apriori_matrix)","138b3f69":"apriori_rule_lift.head()","66f31a6d":"plot_metrics_relationship(apriori_rule_lift, col1='lift', col2='confidence')","46a85993":"apripri_rule = compute_association_rule(apriori_matrix, metric=\"confidence\", min_thresh=0.2)\napripri_rule.head()","0365db1b":"algo1 = ['Fp Growth', fp_growth_exec_time]\nalgo2 = ['Apriori', apriori_exec_time]\n\ncompare_time_exec(algo1, algo2)","dabf8a6a":"This kernel is a comprehensive overview focused on the comparative analysis between Apriori and Frequent Pattern Growth algorithms. In the end, we will have a look at the comparative table between additional algorithms such as: **RAMS, ECLAT, ASPMS.**  These are all association rule algorithms.  \n[I wrote this first kernel](https:\/\/www.kaggle.com\/keitazoumana\/a-simple-way-to-understand-association-rule) to give you more information about how an association rule works.   \nWe will be covering the following topics:   \n\n## Data Preparation for association rules   \n## Association Rules implementation   \n## Comparative Analyzis ","02040217":"![image.png](attachment:image.png)","411f5441":"The Ones and Zeros in the matrix are boolean values, they could also be respectively replaced by True and False, where: \n* **True** means that the item exists in the transaction   \n* **False** means it does not  ","1a59f7ad":"# Comparative Analyzis","eb255514":"![image.png](attachment:image.png)","3344a22e":"Next Time: Another technic such as ASPMS will be included in the comparative analysis phases.   \nhttps:\/\/core.ac.uk\/download\/pdf\/82306393.pdf","1fd1b5cd":"# Data Preparation","9e782677":"### Confidence","c143c56a":"# Sources   \nhttps:\/\/www.researchgate.net\/publication\/272864559_Comparing_the_Performance_of_Frequent_Pattern_Mining_Algorithms   \nhttp:\/\/www.lastnightstudy.com\/Show?id=123\/Difference-Between-Fp-growth-and-Apriori-Algorithm    \nhttps:\/\/core.ac.uk\/download\/pdf\/82306393.pdf","7d46ff46":"### Lift ","180918a8":"We need to transform the data into the following format, which is suitable to perform our association rules.  \n![image.png](attachment:image.png)","8af7f712":"# Deep Dive into Comparative Analysis between Apriori and Frequent Pattern (Fp) Growth algorithms and Brief comparison with RARM, ECLAT and ASPMS   \n![image.png](attachment:image.png)   \n","7ce64dce":"Based on the previous experiences, we can perform the following analyzis    \n## Time execution    ","861bd658":"## Case n\u00b01: Using Fp Growph Algorithm","3c749337":"### Useful Libraries","28978c7e":"# Conclusion     ","a029ecb9":"# Association Rules Implementation","aac39cc5":"* **support** tells how popular an item is based on the proportion of all transactions that are included. The popularity is met if it corresponds to the user-specified support thresold. For instance, a support threshold set to 0.2 (20%) means that the user wants all the items that occur together in at least 20% of all transactions.  \n* A High support thresold does not give much more item combination, so reducing the value might be helpful to see much more item combinations for marketing purpose.","ce834397":"## Case n\u00b02: Using Apriori Algorithm","bb062a8c":"### Confidence","70dce098":"### Helper Functions","7622ce61":"### Lift  ","f1c29c2e":"I hope you enjoyed your journey through this kernel \ud83d\ude00! Feel free to give it an upvote   \nIf you have any question or remark, I will be glad to welcome it for further discussions      \n\nFor further readings do not hesitate to consult the following links:"}}