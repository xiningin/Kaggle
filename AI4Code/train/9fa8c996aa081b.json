{"cell_type":{"1063694c":"code","0e97d4bd":"code","3bf80f9b":"code","afbeae26":"code","eb450db9":"code","3825c0ee":"code","b7e5918f":"code","00d259af":"code","16ec655c":"code","8615dcb0":"code","c11fc2b3":"code","7d401453":"code","997f3e8c":"code","15bdbbc4":"code","a24f8ceb":"code","6396c612":"markdown"},"source":{"1063694c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0e97d4bd":"import matplotlib.pyplot as plt","3bf80f9b":"train_data = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\nprint(train_data.shape)\nprint(test_data.shape)","afbeae26":"train_data","eb450db9":"X_train = train_data.iloc[:,1:].values.reshape(-1, 1, 28, 28)\ny_train = train_data.iloc[:,:1].values.flatten()\nX_test = test_data.values.reshape(-1, 1, 28, 28)","3825c0ee":"plt.imshow(X_train[5].reshape(28, 28, 1));","b7e5918f":"y_train[5]","00d259af":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader","16ec655c":"class MnistData(Dataset):\n    def __init__(self, X, y=None):\n        self.X = X\n        self.y = y\n    \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        if self.y is not None:\n            return self.X[idx], self.y[idx]\n        return self.X[idx]","8615dcb0":"X_train = torch.tensor(X_train, dtype=torch.float32) \/ 255\ny_train = torch.tensor(y_train)\nX_test = torch.tensor(X_test, dtype=torch.float32) \/ 255","c11fc2b3":"train_set = MnistData(X_train, y_train)\ntest_set = MnistData(X_test)","7d401453":"train_loader = DataLoader(train_set, batch_size=128)\ntest_loader = DataLoader(test_set, batch_size=128)","997f3e8c":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.dropout = nn.Dropout(p=0.4)\n        self.fc1 = nn.Linear(1600, 10)\n        \n        self.optimizer = optim.Adam(self.parameters())\n\n    def forward(self, x):\n        x = F.max_pool2d(self.conv1(x), 2)\n        x = F.max_pool2d(self.conv2(x), 2)\n        x = x.flatten(1)\n        x = F.dropout(x, training=self.training)\n        x = self.fc1(x)\n        return F.log_softmax(x, dim=1)\n    \n    # This is not a typical way to create a train function\n    # I like to embed into the model class itself\n    def fit(self, train_loader, epochs=1):\n        # Turn to train mode\n        self.train()\n        for epoch in range(epochs):\n            #\u00a0Get loss and accuracy per epoch\n            total_loss = 0\n            total_acc = 0\n            for batch_idx, (data, target) in enumerate(train_loader):\n                # Zero grad\n                self.optimizer.zero_grad()\n                # Get the output\n                output = self(data)\n                # Calculate the loss (It is average by default)\n                loss = F.nll_loss(output, target)\n                #\u00a0Do gradient math\n                loss.backward()\n                self.optimizer.step()\n                # Calculate accuracy and sum over batches\n                acc = (output.argmax(1) == target).numpy().mean()\n                total_loss += loss.item()\n                total_acc += acc\n            \n            # Averaging over batch or it will be wrong\n            total_loss = total_loss \/ (batch_idx+1)\n            total_acc = total_acc \/ (batch_idx+1)\n            print(f\"Train Epoch: {epoch}\\tLoss: {total_loss:.6f}\\tAccuracy: {total_acc:.6f}\")\n","15bdbbc4":"model = CNN()","a24f8ceb":"model.fit(train_loader, epochs=3)","6396c612":"In torch tensor of images should be (n_channels, dim_1, dim_2)"}}