{"cell_type":{"70585654":"code","64cd3630":"code","8ebf1d98":"code","b22ba002":"code","be0fb9e0":"code","7325176c":"code","2167d179":"code","618730e2":"code","6b102532":"code","80d8a534":"code","4a4a60c6":"code","94f9d43d":"code","b45ea2c0":"code","7129aaf3":"code","4962e8bc":"code","396860e0":"code","ab3797be":"code","5f3b3597":"markdown"},"source":{"70585654":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport seaborn as sn\n\nimport keras\nfrom keras.models import Model\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, Input\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import ModelCheckpoint\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n","64cd3630":"arabic_characters = ['alef', 'beh', 'teh', 'theh', 'jeem', 'hah', 'khah', 'dal', 'thal',\n                    'reh', 'zain', 'seen', 'sheen', 'sad', 'dad', 'tah', 'zah', 'ain',\n                    'ghain', 'feh', 'qaf', 'kaf', 'lam', 'meem', 'noon', 'heh', 'waw', 'yeh']\n","8ebf1d98":"# loading the dataset\n\n\nx_train = pd.read_csv(\"\/kaggle\/input\/ahcd1\/csvTrainImages 13440x1024.csv\",header=None).to_numpy()\ny_train = pd.read_csv(\"\/kaggle\/input\/ahcd1\/csvTrainLabel 13440x1.csv\",header=None).to_numpy()-1 \n\nx_test = pd.read_csv(\"\/kaggle\/input\/ahcd1\/csvTestImages 3360x1024.csv\",header=None).to_numpy()\ny_test = pd.read_csv(\"\/kaggle\/input\/ahcd1\/csvTestLabel 3360x1.csv\",header=None).to_numpy()-1\n\nprint(\"x_train.shape =\", x_train.shape, \"\\ny_train.shape =\", y_train.shape, \"\\nx_test.shape =\", x_test.shape, \"\\ny_test.shape =\", y_test.shape)","b22ba002":"x_train = x_train.reshape(-1,32,32,1)\nx_test = x_test.reshape(-1,32,32,1)\n\nx_train = x_train \/ 255.0\nx_test = x_test \/ 255.0\n\nprint(x_train.shape, x_test.shape)\n\nra = np.random.randint(0, 13440, size=25)\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(x_train[ra[i]].reshape(32,32).T,\"gray\")\n    plt.xlabel(arabic_characters[int(y_train[ra[i]][0])])\nplt.show()\n","be0fb9e0":"# Converting the class vector in integers to binary class matrix\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\nprint(y_train.shape, y_test.shape)\nfor i in zip(y_train[0], arabic_characters):\n    print(i)\n","7325176c":"def get_model():\n    In = Input(shape=(32,32,1))\n    x = Conv2D(32, (5,5), padding=\"same\", activation=\"relu\")(In)\n    x = Conv2D(32, (5,5), activation=\"relu\")(x)\n    x = Conv2D(32, (5,5), activation=\"relu\")(x)\n    x = MaxPooling2D((2,2))(x)\n    x = BatchNormalization()(x)\n    \n    x = Conv2D(64, (5,5), padding=\"same\", activation=\"relu\")(x)\n    x = Conv2D(64, (5,5), activation=\"relu\")(x)\n    x = Conv2D(64, (5,5), activation=\"relu\")(x)\n    x = MaxPooling2D((2,2))(x)\n    x = BatchNormalization()(x)\n    \n    x = Flatten()(x)\n    x = Dense(128, activation=\"relu\")(x)\n    x = Dense(128, activation=\"relu\")(x)\n    x = Dropout(0.4)(x)\n    \n    Out = Dense(28, activation=\"softmax\")(x)\n    \n    model = Model(In, Out)\n    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    return model\n\nmodel = get_model()\nkeras.utils.vis_utils.plot_model(model, show_shapes=True, show_layer_names=True)","2167d179":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n","618730e2":"batch_size = 64\nepochs = 50\n\ntrain_gen = datagen.flow(x_train, y_train, batch_size=batch_size)\ntest_gen = datagen.flow(x_test, y_test, batch_size=batch_size)\n","6b102532":"model_checkpoint_callback = ModelCheckpoint(\n    filepath=\"best.hdf5\",\n    monitor='val_accuracy', \n    verbose=1, \n    save_best_only=True, \n    mode='max')\n\n\nhistory = model.fit_generator(train_gen, \n                              epochs = epochs,\n                              verbose = 0,\n                              steps_per_epoch = x_train.shape[0] \/\/ batch_size,\n                              validation_data = test_gen,\n                              validation_steps = x_test.shape[0] \/\/ batch_size,\n                              callbacks=[model_checkpoint_callback])\n\n\n\n","80d8a534":"# we need to transpose the image for visualization\n# since for training there is no problem we gave the data as it was\nplt.figure()\nplt.subplot(1,2,1)\nplt.imshow(x_test[0].reshape(32,32))\nplt.axis(\"off\")\nplt.title(\"from dataset\")\nplt.subplot(1,2,2)\nplt.imshow(x_test[0].reshape(32,32).T)\nplt.axis(\"off\")\nplt.title(\"with Transpose\")\nplt.show()\n\npred = model.predict([[x_test[0]]])\nplt.imshow(x_test[0].reshape(32,32).T, \"binary\")\nplt.title(arabic_characters[np.argmax(pred)])\nplt.axis(\"OFF\")\nplt.show()","4a4a60c6":"plt.figure(figsize=(10,10))\nplt.plot(history.history[\"accuracy\"])\nplt.plot(history.history[\"val_accuracy\"])\nplt.legend([\"accuracy\",\"val_accuracy\"])\nplt.show()","94f9d43d":"\ny_preds = model.predict(x_test)\ny_pred_classes = np.argmax(y_preds, axis=1)\ny_true = np.argmax(y_test, axis=1)\ncm = confusion_matrix(y_true, y_pred_classes)\n\nplt.figure(figsize=(10,15))\nsn.heatmap(cm, annot=True, fmt=\"d\")","b45ea2c0":"import cv2\ndef get_sides(length):\n    if length%2==0:\n        return length\/\/2,length\/\/2\n    else:\n        return (length-1)\/\/2,1+(length-1)\/\/2\n    \n    \ndef preprocess(character):\n    if len(character.shape)<2:\n        character = cv2.cvtColor(word, cv2.COLOR_BGR2GRAY)\n\n    (wt, ht) = (32,32)\n    (h, w) = character.shape\n    fx = w \/ wt\n    fy = h \/ ht\n    f = max(fx, fy)\n    newSize = (max(min(wt, int(w \/ f)), 1), max(min(ht, int(h \/ f)), 1)) \n    character = cv2.resize(character, newSize)\n\n    if character.shape[0] < 32:\n        add_zeros_up = np.zeros((get_sides(32-character.shape[0])[0], character.shape[1]))\n        add_zeros_down = np.zeros((get_sides(32-character.shape[0])[1], character.shape[1]))\n        character = np.concatenate((add_zeros_up,character))\n        character = np.concatenate((character, add_zeros_down))\n\n    if character.shape[1] < 32:\n        add_zeros_left = np.zeros((32, get_sides(32-character.shape[1])[0]))\n        add_zeros_right = np.zeros((32, get_sides(32-character.shape[1])[1]))\n        \n        character = np.concatenate((add_zeros_left,character), axis=1)\n        character = np.concatenate((character, add_zeros_right), axis=1)\n\n\n    character= character.T\/255.0\n    character = np.expand_dims(character , axis = 2)\n    return character\n\ndef get_characters(img,kv=5):\n    gray = img.copy()\n\n    kernel = np.ones((kv,kv),dtype=np.uint8)\n    if len(img.shape)==3:\n        gray = cv2.cvtColor(gray,cv2.COLOR_BGR2GRAY)\n        \n    _, thresh = cv2.threshold(gray,127,255, cv2.THRESH_BINARY_INV)\n    imgdilation = cv2.dilate(thresh,kernel, iterations=1)\n    ctrs, _= cv2.findContours(imgdilation.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n    sorted_ctrs = sorted(ctrs,key = lambda ctr: cv2.boundingRect(ctr)[0])\n    sorted_ctrs = sorted_ctrs[::-1]\n    characters=[]\n    for ctr in sorted_ctrs:\n        x, y, w, h = cv2.boundingRect(ctr)\n\n        acharacter = 255-np.array(img[y:y+h,x:x+w])\n        acharacter = preprocess(acharacter)\n        characters.append(acharacter)\n    \n    return characters,sorted_ctrs\n\n","7129aaf3":"characters = get_characters(cv2.imread('\/kaggle\/input\/for-detection\/pages\/t2.png',cv2.IMREAD_GRAYSCALE),30)[0]\ncharacters=np.array(characters).reshape(-1,32,32,1)\npreds = model.predict(characters)\nfor img, pred in zip(characters, preds):\n    plt.figure(figsize=(1,1))\n    plt.imshow(img.reshape(32,32).T)\n    plt.title(arabic_characters[pred.argmax()])\n    plt.axis('off')\n    plt.show()","4962e8bc":"page = cv2.imread('\/kaggle\/input\/for-detection\/pages\/t2.png',cv2.IMREAD_GRAYSCALE)\ncharacters = get_characters(page,30)[1]\nfor ctr in characters:\n        x, y, w, h = cv2.boundingRect(ctr)\n\n        acharacter = 255-np.array(page[y:y+h,x:x+w])\n        acharacter = preprocess(acharacter)\n        acharacter = acharacter.reshape(32,32,1)\n        pred = model.predict([[acharacter]])\n        page = cv2.rectangle(page, (x, y), (x + w, y + h), (36,255,12), 1)\n        cv2.putText(page, arabic_characters[np.argmax(pred)], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\nplt.figure(figsize=(10,10))\nplt.imshow(page)\nplt.axis(\"OFF\")\nplt.show()\n","396860e0":"page = cv2.imread('\/kaggle\/input\/for-detection\/pages\/t1.png',cv2.IMREAD_GRAYSCALE)\ncharacters = get_characters(page,30)[1]\nfor ctr in characters:\n        x, y, w, h = cv2.boundingRect(ctr)\n\n        acharacter = 255-np.array(page[y:y+h,x:x+w])\n        acharacter = preprocess(acharacter)\n        acharacter = acharacter.reshape(32,32,1)\n        pred = model.predict([[acharacter]])\n        page = cv2.rectangle(page, (x, y), (x + w, y + h), (36,255,12), 1)\n        cv2.putText(page, arabic_characters[np.argmax(pred)], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\nplt.figure(figsize=(10,10))\nplt.imshow(page)\nplt.axis(\"OFF\")\nplt.show()\n","ab3797be":"model.save(\"model_ewaran.h5\")","5f3b3597":"# Arabic character classification with detection\n\nhere we are Implementing a CNN model for the classification and implementing a detection algorithm at the end."}}