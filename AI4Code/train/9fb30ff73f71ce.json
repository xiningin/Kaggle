{"cell_type":{"32ec5dbc":"code","d3bbe341":"code","c2493dbf":"code","76d9ad56":"code","91573e08":"code","2996532a":"code","3bc27c9c":"code","b53125e0":"code","497534bf":"code","fb794869":"code","bc53e329":"markdown","d4e87369":"markdown","197a873a":"markdown","9fd4bd11":"markdown","6556e70f":"markdown","e0685e02":"markdown","4c7d1f5b":"markdown","0053e463":"markdown","65c5b6de":"markdown","7901813b":"markdown"},"source":{"32ec5dbc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d3bbe341":"#%% Libraries import\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img #preprocessing for image\nfrom keras.models import Sequential #Model olu\u015fturmak\nfrom keras.layers import Dense #Model i\u00e7in\nfrom keras.applications.vgg16 import VGG16 #for transfer learning\nimport matplotlib.pyplot as plt #g\u00f6rsell\u015fetirme\nfrom glob import glob #f o r image import","c2493dbf":"train_path = \"..\/input\/fruits\/fruits-360\/Training\"\ntest_path = \"\/kaggle\/input\/fruits\/fruits-360\/Test\"\n\nimg = load_img('..\/input\/fruits\/fruits-360\/Training\/Avocado\/0_100.jpg')\nplt.imshow(img)\nplt.axis(\"off\")\nplt.show()\n\nx = img_to_array(img)\nprint(x.shape)\n\n\nnumberOfClass = len(glob('..\/input\/fruits\/fruits-360\/Training'+'\/*')) #CLass say\u0131s\u0131n\u0131 klas\u00f6r i\u00e7ine gidip okuyoruz. * koyarak hepsini okumas\u0131n\u0131 sa\u011fl\u0131yoruz. B\u00f6ylece class say\u0131s\u0131 otomatik olarak belirleniyor.","76d9ad56":"vgg = VGG16()","91573e08":"print(vgg.summary())\nprint(type(vgg))\n\nvgg_layer_list = vgg.layers","2996532a":"model = Sequential() \nfor i in range(len(vgg_layer_list)-1): \n    model.add(vgg_layer_list[i]) \nprint(model.summary())","3bc27c9c":"for layers in model.layers: #Burada eklenilen layerlar\u0131n\u0131 train edilebilme \u00f6zelliklerini kapat\u0131yoruz. \u00c7\u00fcnk\u00fc zaten bunlar ileri derecede e\u011fitimli. (Transfer Learning is here!)\n    layers.trainable = False\n\nmodel.add(Dense(numberOfClass, activation=\"softmax\")) #Vgg16'daan \u00e7\u0131kard\u0131\u011f\u0131m\u0131z dense layer\u0131 kendi datam\u0131za uygun olarak ekliyoruz.\n\nprint(model.summary())\n\nmodel.compile(loss = \"categorical_crossentropy\",\n              optimizer = \"rmsprop\",\n              metrics = [\"accuracy\"]) #compliting \n","b53125e0":"\ntrain_data = ImageDataGenerator().flow_from_directory(train_path,target_size = (224,224)) \ntest_data = ImageDataGenerator().flow_from_directory(test_path,target_size = (224,224)) \n\nbatch_size = 32\n\nhist = model.fit_generator(train_data,\n                           steps_per_epoch=1600\/\/batch_size,\n                           epochs= 25,\n                           validation_data=test_data,\n                           validation_steps= 800\/\/batch_size,)","497534bf":"model.save_weights(\".\/weights.h5\")","fb794869":"plt.title('Loss Scores')\nprint(hist.history.keys())\nplt.plot(hist.history[\"loss\"],label = \"training loss\")\nplt.plot(hist.history[\"val_loss\"],label = \"validation loss\")\nplt.legend()\nplt.show()\nplt.figure()\nplt.title('Accuracy Scores')\nplt.plot(hist.history[\"accuracy\"],label = \"training acc\")\nplt.plot(hist.history[\"val_accuracy\"],label = \"validation acc\")\nplt.legend()\nplt.show()\n","bc53e329":"# Adding Vgg16 layers own network except for the final layer","d4e87369":"# Create Dataset Paths & Visualization Sample Data","197a873a":"# If you like this kernel, Please Upvote :) Thanks\n","9fd4bd11":"# Train Section","6556e70f":"# Libraries Import","e0685e02":"# Weights Saving","4c7d1f5b":"# Create VGG16","0053e463":"# Create & Compile the Model","65c5b6de":"# Summary the Network","7901813b":"# Transfer Learning\n\n* Vgg16 Architecture\n\n![image.png](attachment:image.png)"}}