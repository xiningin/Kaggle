{"cell_type":{"fa2b53e9":"code","2d23ab7e":"code","553eaa1f":"code","84dc972d":"code","58906908":"code","a375bc9b":"code","fb29d6be":"code","9fdc59f5":"code","3d6360d4":"code","2f796d81":"code","5f86b6e5":"code","552614a5":"code","e3219ad1":"code","76f3a548":"code","8a63f0cc":"code","ac5f5175":"code","eb20f19f":"code","8525fbbe":"code","0002458f":"code","afc509f2":"code","fe582786":"code","a9dc4bbb":"code","708aa150":"code","a2d940b8":"code","6ee70b42":"code","38ac83b8":"code","a09d54dc":"code","96768dcc":"code","eb47cfc8":"code","cf2f0959":"code","6daede2f":"code","aacf0a02":"code","30de4a5e":"markdown","e3f1262c":"markdown","ec2ea9d3":"markdown","36c34d8b":"markdown","ff177325":"markdown","59be0d2f":"markdown"},"source":{"fa2b53e9":"import os\nimport random\nimport math\nfrom datetime import datetime\nfrom collections import Counter\nimport pandas as pd\nimport numpy as np\n\nimport cv2\nfrom PIL import Image\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\nfrom sklearn.model_selection import train_test_split\nimport xml.etree.ElementTree as ET\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models","2d23ab7e":"images_path = Path('..\/input\/databb\/gambar')\nanno_path = Path('..\/input\/databb\/data xml')\n\n\ndef filelist(root, file_type):\n    \"\"\"\u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u043f\u043e\u043b\u043d\u043e\u0441\u0442\u044c\u044e \u043a\u0432\u0430\u043b\u0438\u0444\u0438\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0439 \u0441\u043f\u0438\u0441\u043e\u043a \u0444\u0430\u0439\u043b\u043e\u0432 \u0432 \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u0438\"\"\"\n    return [os.path.join(directory_path, f) for directory_path, directory_name, \n            files in os.walk(root) for f in files if f.endswith(file_type)]\n\n\ndef generate_train_df (anno_path):\n    annotations = filelist(anno_path, '.xml')\n    anno_list = []\n    for anno_path in annotations:\n        root = ET.parse(anno_path).getroot()\n        anno = {}\n        anno['filename'] = Path(str(images_path) + '\/'+ root.find(\".\/filename\").text)\n        anno['width'] = root.find(\".\/size\/width\").text\n        anno['height'] = root.find(\".\/size\/height\").text\n        anno['class'] = root.find(\".\/object\/name\").text\n        anno['xmin'] = int(root.find(\".\/object\/bndbox\/xmin\").text)\n        anno['ymin'] = int(root.find(\".\/object\/bndbox\/ymin\").text)\n        anno['xmax'] = int(root.find(\".\/object\/bndbox\/xmax\").text)\n        anno['ymax'] = int(root.find(\".\/object\/bndbox\/ymax\").text)\n        anno_list.append(anno)\n    return pd.DataFrame(anno_list)","553eaa1f":"df_train = generate_train_df(anno_path)\ndf_train","84dc972d":"df_train['class'].value_counts()","58906908":"class_dict = {'sarung': 0, 'sarungtangan': 1}\ndf_train['class'] = df_train['class'].apply(lambda x:  class_dict[x])\n\nprint(df_train.shape)\ndf_train.head()","a375bc9b":"def read_image(path):\n    return cv2.cvtColor(cv2.imread(str(path)), cv2.COLOR_BGR2RGB)\n\n\ndef create_mask(bb, x):\n    \"\"\"\u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043c\u0430\u0441\u043a\u0443 \u0434\u043b\u044f bounding box'a \u0442\u0430\u043a\u043e\u0433\u043e \u0436\u0435 \u0448\u0435\u0439\u043f\u0430 \u043a\u0430\u043a \u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435\"\"\"\n    rows,cols,*_ = x.shape\n    Y = np.zeros((rows, cols))\n    bb = bb.astype(np.int)\n    Y[bb[0]:bb[2], bb[1]:bb[3]] = 1.\n    return Y\n\n\ndef mask_to_bb(Y):\n    \"\"\"\u041a\u043e\u043d\u0432\u0435\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u043c\u0430\u0441\u043a\u0443 Y \u0432 bounding box'a, \u043f\u0440\u0438\u043d\u0438\u043c\u0430\u044f 0 \u043a\u0430\u043a \u0444\u043e\u043d\u043e\u0432\u044b\u0439 \u043d\u0435\u043d\u0443\u043b\u0435\u0432\u043e\u0439 \u043e\u0431\u044a\u0435\u043a\u0442 \"\"\"\n    cols, rows = np.nonzero(Y)\n    if len(cols) == 0: \n        return np.zeros(4, dtype=np.float32)\n    top_row = np.min(rows)\n    left_col = np.min(cols)\n    bottom_row = np.max(rows)\n    right_col = np.max(cols)\n    return np.array([left_col, top_row, right_col, bottom_row], dtype=np.float32)\n\n\ndef create_bb_array(x):\n    \"\"\"\u0413\u0435\u043d\u0435\u0440\u0438\u0440\u0443\u0435\u043c \u043c\u0430\u0441\u0441\u0438\u0432 bounding box'a \u0438\u0437 \u0441\u0442\u043e\u043b\u0431\u0446\u0430 train_df\"\"\"\n    return np.array([x[5],x[4],x[7],x[6]])\n\n\ndef resize_image_bb(read_path, write_path, bb, sz):\n    \"\"\"\u0420\u0435\u0441\u0430\u0439\u0437\u0438\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0438 \u0435\u0433\u043e bounding box \u0438 \u0437\u0430\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0432 \u043d\u043e\u0432\u044b\u0439 \u043f\u0443\u0442\u044c\"\"\"\n    im = read_image(read_path)\n    im_resized = cv2.resize(im, (sz, sz))\n    Y_resized = cv2.resize(create_mask(bb, im), (sz, sz))\n    new_path = str(write_path\/read_path.parts[-1])\n    cv2.imwrite(new_path, cv2.cvtColor(im_resized, cv2.COLOR_RGB2BGR))\n    return new_path, mask_to_bb(Y_resized)","fb29d6be":"IM_SIZE = 300","9fdc59f5":"new_paths = []\nnew_bbs = []\ntrain_path_resized = Path('.\/images_resized')\nPath.mkdir(train_path_resized, exist_ok=True)\n\n\nfor index, row in df_train.iterrows():\n    new_path,new_bb = resize_image_bb(row['filename'], train_path_resized, create_bb_array(row.values), IM_SIZE)\n    new_paths.append(new_path)\n    new_bbs.append(new_bb)\n    \n    \ndf_train['new_path'] = new_paths\ndf_train['new_bb'] = new_bbs\n\ndf_train.head()","3d6360d4":"im = cv2.imread(str(df_train.values[58][0]))\nbb = create_bb_array(df_train.values[58])\nprint(im.shape)\n\nY = create_mask(bb, im)\nmask_to_bb(Y)\n\nplt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))","2f796d81":"plt.imshow(Y, cmap='gray')","5f86b6e5":"# example of brighting image augmentation\nfrom numpy import expand_dims\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# \u0412\u044b\u0440\u0435\u0437\u0430\u0435\u043c \u043a\u0443\u0441\u043e\u043a \u0441 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\ndef crop(im, r, c, target_r, target_c): \n    ims =im[r:r+target_r, c:c+target_c]\n    return ims\n\n# \u0426\u0435\u043d\u0442\u0440\u0430\u043b\u044c\u043d\u043e\u0435 \u0432\u044b\u0440\u0435\u0437\u0430\u043d\u0438\u0435 \ndef center_crop(x, r_pix=8):\n    r, c,*_ = x.shape\n    c_pix = round(r_pix*c\/r)\n    cc = crop(x, r_pix, c_pix, r-2*r_pix, c-2*c_pix)\n    return cc\n\ndef rotate_cv(im, deg, y=False, mode=cv2.BORDER_REFLECT):\n  \n    r,c,*_ = im.shape\n    M = cv2.getRotationMatrix2D((c\/2,r\/2),deg,1)\n    if y:\n        return cv2.warpAffine(im, M, (c, r), borderMode=cv2.BORDER_CONSTANT)\n       \n    return cv2.warpAffine(im, M, (c, r), borderMode=mode, flags=cv2.WARP_FILL_OUTLIERS)\n\ndef random_cropXY(x, Y, r_pix=8):\n   \n    r, c,*_ = x.shape\n    c_pix = round(r_pix * c\/r)\n    rand_r = random.uniform(0, 1)\n    rand_c = random.uniform(0, 1)\n    start_r = np.floor(2 * rand_r * r_pix).astype(int)\n    start_c = np.floor(2 * rand_c * c_pix).astype(int)\n    xx = crop(x, start_r, start_c, r - 2*r_pix, c - 2*c_pix)\n    YY = crop(Y, start_r, start_c, r - 2*r_pix, c - 2*c_pix)\n    return xx, YY\n\ndef transformsXY(path, bb, is_transforms):\n    x = cv2.imread(str(path)).astype(np.float32)\n    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB) \/ 255\n    Y = create_mask(bb, x)\n    \n   \n    #print(x.dtype,it.next())\n\n      \n    \n    \n    if is_transforms:\n        rdeg = (np.random.random()-.50) * 20\n        x = rotate_cv(x, rdeg)\n        Y = rotate_cv(Y, rdeg, y=True)\n        \n        ## brigness\n        x1 = x \n        data = img_to_array(x1)\n        samples = expand_dims(data, 0)\n        datagen = ImageDataGenerator(brightness_range=[0.2,1.0])\n        it = datagen.flow(samples, batch_size=1)\n        batch  =it.next()\n        image = batch[0].astype('uint8')\n        x = image\n        x2= image\n        x3 =  rotate_cv(x, rdeg)\n        \n        if np.random.random() > 0.5: \n            x = np.fliplr(x).copy()\n            Y = np.fliplr(Y).copy()\n        x4 =  np.fliplr(x).copy()\n        x, Y = random_cropXY(x, Y)\n        \n        fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n   \n        ax[0].imshow(x1)\n        ax[1].imshow(x2)\n        ax[2].imshow(x3)\n        ax[3].imshow(x4)\n        \n          \n    else:\n        x, Y = center_crop(x), center_crop(Y)\n    return x, mask_to_bb(Y)\n\ndef create_corner_rect(bb, color='red'):\n    bb = np.array(bb, dtype=np.float32)\n    return plt.Rectangle((bb[1], bb[0]), bb[3]-bb[1], bb[2]-bb[0], color=color,\n                         fill=False, lw=3)\n\ndef show_corner_bb(im, bb):\n    plt.imshow(im)\n    plt.gca().add_patch(create_corner_rect(bb))\n    \n","552614a5":"number = 45\nim = cv2.imread(str(df_train['new_path'].values[number]))\nprint(str(df_train.values[number][8]))\nim = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\nshow_corner_bb(im, df_train['new_bb'].values[number])","e3219ad1":"im, bb = transformsXY(str(df_train['new_path'].values[number]),\n                      df_train['new_bb'].values[number],\n                      is_transforms=True)\nshow_corner_bb(im, bb)","76f3a548":"df_train = df_train.reset_index()\nX = df_train[['new_path', 'new_bb']]\nY = df_train['class']\nX_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n\n\ndef normalize(im):\n  \n    imagenet_stats = np.array([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])\n    return (im - imagenet_stats[0]) \/ imagenet_stats[1]\n\n\nclass RoadDataset(Dataset):\n    def __init__(self, paths, bb, y, is_transforms=False):\n        self.is_transforms = is_transforms\n        self.paths = paths.values\n        self.bb = bb.values\n        self.y = y.values\n        \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, idx):\n        path = self.paths[idx]\n        y_class = self.y[idx]\n        x, y_bb = transformsXY(path, self.bb[idx], self.is_transforms)\n        x = normalize(x)\n        x = np.rollaxis(x, 2)\n        return x, y_class, y_bb\n\n    \ntrain_ds = RoadDataset(X_train['new_path'], X_train['new_bb'], y_train, is_transforms=True)\nvalid_ds = RoadDataset(X_val['new_path'], X_val['new_bb'], y_val)","8a63f0cc":"batch_size = 16\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nvalid_dl = DataLoader(valid_ds, batch_size=batch_size)","ac5f5175":"class BB_model(nn.Module):\n    def __init__(self):\n        super(BB_model, self).__init__()\n        resnet = models.resnet34(pretrained=True)\n        layers = list(resnet.children())[:8]\n        self.features = nn.Sequential(*layers)\n        self.classifier = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n        self.bb = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n        \n    def forward(self, x):\n        x = self.features(x)\n        x = F.relu(x)\n        x = nn.AdaptiveAvgPool2d((1,1))(x)\n        x = x.view(x.shape[0], -1)\n        return self.classifier(x), self.bb(x)","eb20f19f":"resnet = models.resnet34(pretrained=True)\nlist(resnet.children())[:8]","8525fbbe":"model = BB_model()#.cuda()\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.Adam(params, lr=0.006)\nepochs = 15\nmodel","0002458f":"import joblib\ndef train():\n    for i in range(epochs):\n\n        model.train()\n        total = 0\n        sum_loss = 0\n\n        for x, y_class, y_bb in train_dl:\n            len_batch = y_class.shape[0]\n            x = x.cpu().float()\n            #x = x.float()\n            #y_class = y_class.cuda()\n            #y_bb = y_bb.cuda().float()\n            y_class = y_class\n            y_bb = y_bb.float()\n            out_class, out_bb = model(x)\n            \n            # losses\n            loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n            loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"sum\")\n            \n            loss = loss_class + loss_bb\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            total += len_batch\n            sum_loss += loss.item()\n        \n        train_loss = sum_loss \/ total\n\n        # Eval\n        model.eval()\n        val_total = 0\n        val_sum_loss = 0\n        correct = 0\n        \n        joblib.dump(model,'modeltes.pkl')\n        \n        for x, y_class, y_bb in valid_dl:\n            len_batch = y_class.shape[0]\n            #x = x.cuda().float()\n            #y_class = y_class.cuda()\n            #y_bb = y_bb.cuda().float()\n            x = x.float()\n            y_class = y_class\n            y_bb = y_bb.float()\n            \n            out_class, out_bb = model(x)\n            \n            loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n            loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"sum\")\n            loss = loss_class + loss_bb\n            \n            _, pred = torch.max(out_class, 1)\n            correct += (pred == y_class).sum().item()\n            \n            val_sum_loss += loss.item()\n            val_total += len_batch\n            \n        val_loss = val_sum_loss \/ val_total\n        val_acc = correct \/ val_total\n\n        print(f\"Epoch [{i+1}\/{epochs}]. train_loss {train_loss:.3f} val_loss {val_loss:.3f} val_acc {val_acc:.3f}\")","afc509f2":"train()","fe582786":"for i, param_group in enumerate(optimizer.param_groups):\n    param_group[\"lr\"] = 0.001","a9dc4bbb":"train()","708aa150":"joblib.load('modeltes.pkl')","a2d940b8":"# resizing test image\n#im = read_image('.\/images_resized\/road789.png')\nPath.mkdir(Path('.\/test'), exist_ok=True)\ncv2.imwrite('.\/test\/frame154.jpg', cv2.cvtColor(im, cv2.COLOR_RGB2BGR))","6ee70b42":"# test Dataset\ntest_ds = RoadDataset(\n    pd.DataFrame([{'path':'.\/test\/frame154.jpg'}])['path'],\n    pd.DataFrame([{'bb':np.array([0,0,0,0])}])['bb'],\n    pd.DataFrame([{'y':[0]}])['y']\n)\nx, y_class, y_bb = test_ds[0]\n\nxx = torch.FloatTensor(x[None,])\nxx.shape","38ac83b8":"cobakm=joblib.load('modeltes.pkl')","a09d54dc":"#out_class, out_bb = cobakm(xx.cuda())\nout_class, out_bb = cobakm(xx)\nout_class, out_bb","96768dcc":"xx.shape","eb47cfc8":"# predicted class\ntorch.max(out_class, 1)","cf2f0959":"class_dict","6daede2f":"bb_hat","aacf0a02":"# predicted bounding box\nbb_hat = out_bb.detach().cpu().numpy()\nbb_hat = bb_hat.astype(int)\nim = cv2.imread(str(df_train['new_path'].values[6]))\nim = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\nplt.subplot(121)\nplt.title(\"prediksi\")\nshow_corner_bb(im, bb_hat[0]*1.3)\nplt.subplot(122)\nplt.title(\"dataasli\")\nshow_corner_bb(im, df_train['new_bb'].values[6])","30de4a5e":"\n# \u0422\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435","e3f1262c":"\u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c \u043d\u0430\u0448\u0438 \u043c\u0435\u0442\u043a\u0438 \u0432 \u043a\u043b\u0430\u0441\u0441\u044b:\n","ec2ea9d3":"\n\u041f\u0440\u0438\u043c\u0435\u043d\u0438\u043c \u0432\u0441\u0435 \u043d\u0430\u0448\u0438 \u043d\u0430\u043f\u0438\u0441\u0430\u043d\u043d\u044b\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438:","36c34d8b":"\n\u0417\u0430\u0433\u0440\u0443\u0437\u0438\u043c \u0432\u0441\u0435 \u044d\u0442\u043e \u0432 \u043d\u0430\u0448 \u0434\u0430\u0442\u0430\u043b\u043e\u0430\u0434\u0435\u0440:\n","ff177325":"\n\u041f\u043e\u0441\u043b\u0435 \u0442\u0440\u0430\u043d\u0441\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438:","59be0d2f":"### \u041f\u0440\u0438\u043c\u0435\u0440 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \n\n\u041e\u0440\u0438\u0433\u0438\u043d\u0430\u043b:\n"}}