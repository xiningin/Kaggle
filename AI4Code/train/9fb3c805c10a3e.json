{"cell_type":{"0f8c2432":"code","909cb794":"code","251c8e50":"code","b6c627f1":"code","50d6d8bf":"code","1386c015":"code","37051105":"code","258d7f2b":"code","16e2321e":"code","1edbaf71":"code","cff631a0":"code","b2c7b7b3":"code","659da095":"code","39757329":"code","661fae88":"code","3d7cbdd4":"code","f914b85e":"code","a33b7b57":"code","dee32c0f":"code","125e64e0":"code","f21241d9":"code","eb868a67":"code","48de9026":"code","b7039e53":"markdown","f5728865":"markdown","25ecb118":"markdown","cb7898c9":"markdown","6807966f":"markdown","a5c2b015":"markdown","730c9216":"markdown","e304a85b":"markdown","fc673785":"markdown","18474516":"markdown","cfb2b13a":"markdown","322337a7":"markdown"},"source":{"0f8c2432":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","909cb794":"bmw_cars_file_path = '\/kaggle\/input\/bmw-used-car-listing\/bmw.csv'\nbmw_data = pd.read_csv(bmw_cars_file_path) \nbmw_data.head()","251c8e50":"# print a summary of the numerical BMW used car data\nbmw_data.describe()","b6c627f1":"categorical_columns = ['model', 'transmission', 'fuelType']\nbmw_data[categorical_columns].describe()","50d6d8bf":"# see what the distinct values are for each of the categorical columns\nbmw_data['model'].unique()","1386c015":"bmw_data['transmission'].unique()","37051105":"bmw_data['fuelType'].unique()","258d7f2b":"numeric_columns = ['year', 'price', 'mileage', 'tax', 'mpg', 'engineSize']\nbmw_num_data = bmw_data[numeric_columns]\nbmw_num_data.head()","16e2321e":"corr = bmw_num_data.corr()\ncorr","1edbaf71":"# Set the width and height of the figure\nplt.figure(figsize=(10, 8))\n\nsns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)","cff631a0":"model_price = bmw_data.groupby('model')['price'].mean().sort_values()\n\nplt.figure(figsize=(14, 8))\nplt.title(\"BMW Average Price for each Model\")\npal = sns.color_palette(\"Greens_d\", len(model_price))\n\nsns.barplot(x=model_price.index, y=model_price.values, palette=pal)\n\nplt.xlabel(\"Model\")\nplt.xticks(rotation=70)\nplt.ylabel(\"Price (Euros)\")\nplt.tight_layout()","b2c7b7b3":"year_price = bmw_data.groupby('year')['price'].mean().sort_values()\n\nplt.figure(figsize=(14, 8))\nplt.title(\"BMW Average Price by Year\")\npal = sns.color_palette(\"Greens_d\", len(year_price))\n\nsns.barplot(x=year_price.index, y=year_price.values, palette=pal)\n\nplt.xlabel(\"Year\")\nplt.ylabel(\"Price (Euros)\")\nplt.tight_layout()","659da095":"plt.figure(figsize=(14,8))\nsns.scatterplot(x=bmw_num_data['year'], y=bmw_num_data['price'])","39757329":"plt.figure(figsize=(14,8))\nsns.scatterplot(x=bmw_num_data['engineSize'], y=bmw_num_data['price'])","661fae88":"plt.figure(figsize=(14,8))\nsns.scatterplot(x=bmw_num_data['mileage'], y=bmw_num_data['price'])","3d7cbdd4":"plt.figure(figsize=(14,8))\nsns.scatterplot(x=bmw_num_data['mpg'], y=bmw_num_data['price'])","f914b85e":"plt.figure(figsize=(14,4))\nbmw_data.groupby('fuelType')['mpg'].mean().plot.barh()","a33b7b57":"engine_0 = bmw_data[bmw_data['engineSize'] == 0.0]\nengine_0","dee32c0f":"plt.figure(figsize=(14,4))\nbmw_data.groupby('transmission')['mpg'].mean().plot.barh()","125e64e0":"from sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Apply ordinal encoder to the model category feature\nordinal_encoder = OrdinalEncoder()\nbmw_data['model'] = ordinal_encoder.fit_transform(bmw_data[['model']])","f21241d9":"# Apply one-hot encoder to transmission and fuelType features\nOH_encoder = OneHotEncoder(sparse=False)\noh_cols = pd.DataFrame(OH_encoder.fit_transform(bmw_data[['transmission', 'fuelType']]))\noh_cols\noh_cols.columns = ['trans_0', 'trans_1', 'trans_2', 'fuel_0', 'fuel_1', 'fuel_2', 'fuel_3', 'fuel_4']\n\n# drop the original columns and add the encoded ones\nbmw_data = bmw_data.drop(['transmission', 'fuelType'], axis=1)\nbmw_data = pd.concat([bmw_data, oh_cols], axis=1)\nbmw_data","eb868a67":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Select the target variable and predictors\ny = bmw_data['price']\nX = bmw_data.drop(['price'], axis=1)\n\n# Divide data into training and validation subsets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=0)\n\nmodel = RandomForestRegressor(n_estimators=10, random_state=0)\nmodel.fit(X_train, y_train)\npreds = model.predict(X_valid)\nmae = mean_absolute_error(y_valid, preds)\nmae","48de9026":"plt.figure(figsize=(14,8))\nsns.scatterplot(x=y_valid, y=preds).set(title='Price vs. Prediction')","b7039e53":"There's very little variation in mpg here compared fuel type, and it is a little surprising that manual transmission cars do not get better mpg than the other two groups. Now let's move on to encoding the categorical features before training a simple model.\n\n### Encoding categorical features","f5728865":"The year and engine size both look positively correlated with price, while the mileage and mpg are both fairly negatively correlated to price. This makes sense, but let's look at a few plots with these features and price, starting with the model and year.","25ecb118":"For an initial model, a mean absolute error of 1,683 Euros is not bad considering the average price is nearly 23,000 Euros. I can see from the plot of the actual prices vs. the predictions that a few very high-priced data points are off by quite a bit, which is going to throw off the average error. Other than that, the prices vs. predictions scatterplot forms a fairly straight line, although it does have a little bit of spread.\n\nThere's a lot of room for improvement, but I'll leave it there for this notebook.","cb7898c9":"Those plots all aggree with the correlations to price we saw. There are a few price outliers, and at least one extreme mileage outlier. There appear to be several mpg outliers, so let's take a closer look at the data for some features. We'll start by looking at the average mpg for each fuel type (a categorical variable, so we'll go back to the original data set).","6807966f":"### Initial data exploration","a5c2b015":"It looks like a few of those peaks in average price are due to only a few (or one) data points for some years. Others are due to a split in lower and higher-priced cars for that year. A few higher-priced cars from 2004 look to be influencing the average for that year, for example.","730c9216":"### Training a simple Random Forest model\nFinally, let's train a simple model to see how good this data set is for predicting the price of a used BMW.","e304a85b":"There are many different models, years, and fuel types in this subset, so it looks like 0.0 was the fill value for missing values in the engine size column. That's a potential source of error in a machine learning model, but we'll leave it alone for now. One last thing I want to look at is the mpg for different types of transmissions.","fc673785":"### BMW Used Car Analysis\n\nAnalyze and predict prices for used BMW automobiles.\n\nThis notebook is based on my earlier notebook, [Audi Used Car Listings](https:\/\/www.kaggle.com\/bcruise\/audi-used-car-listings).\n\nYou may also want to check out these related notebooks:\n- [Mercedes Used Car Analysis](https:\/\/www.kaggle.com\/bcruise\/mercedes-used-car-analysis)\n- [Hyundai Used Car Analysis](https:\/\/www.kaggle.com\/bcruise\/hyundai-used-car-analysis)","18474516":"There are a few interesting peaks and valleys in the prices by year. Let's look at a scatterplot of the same data to see the spread of prices for each year.","cfb2b13a":"It looks like there are no missing values in this data set. If we want to build a model using categorical features, we'll have to encode them. The `transmission` and `fuelType` features only have a few unique values, so we can use one-hot encoding. The `model` has 24 unique values though. It will probably have a lot of predictive value though, so we'll want to keep it. For that feature we'll use ordinal encoding. Before we start building models, let's see how some of the features correlate to each other, and to the price (the ultimate target variable).","322337a7":"Maybe those mpg data points aren't outliers after all. The Hybrid and Other models are very good in mpg, and naturally the Electric vehicle category stands out. Now let's take a closer look at the cars whose engine size is 0."}}