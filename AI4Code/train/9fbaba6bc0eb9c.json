{"cell_type":{"6d170f49":"code","76b09b60":"code","b45a29d0":"code","1f2f581e":"code","9feea069":"code","ef348853":"code","f9bf6940":"code","3eadef02":"code","2acff34c":"code","b0408991":"code","7f6a89e2":"code","55ca1d82":"code","6c1c1cbf":"code","39aff5ad":"code","b79e23f8":"code","6cefb66e":"markdown","bd5be655":"markdown","9a476abf":"markdown","76472528":"markdown","9541b9b9":"markdown","ec9f0793":"markdown","e626a573":"markdown","b8ee812b":"markdown","d285687d":"markdown","9a37b622":"markdown","3cae942f":"markdown","a1c95c3e":"markdown","c54894a2":"markdown","da74d2c3":"markdown","fff430a0":"markdown","6091f11b":"markdown","944d85ad":"markdown","273652c6":"markdown","438b3f60":"markdown"},"source":{"6d170f49":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","76b09b60":"# importing some plotting tools:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# importing tools for preprocessing the data:\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# importing the algorithms needed to predict:\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\n\nfrom keras.losses import mean_absolute_percentage_error as mape","b45a29d0":"data = pd.read_csv(\"..\/input\/graduate-admissions\/Admission_Predict.csv\")\ndata.head()","1f2f581e":"y = data['Chance of Admit ']\n\ndata.drop(['Chance of Admit ', 'Serial No.'], inplace=True, axis=1)\n","9feea069":"plt.figure(figsize=(8,8))\nsns.set_palette(['paleturquoise', 'deepskyblue'])\nsns.set_context(\"poster\", font_scale=0.7)\nsns.scatterplot(data=data, x='GRE Score', y='TOEFL Score', hue='Research')","ef348853":"sns.set_palette(['m'])\nplt.figure(figsize=(8,8))\nsns.distplot(data['University Rating'])","f9bf6940":"sns.set_palette(['mediumpurple'])\nplt.figure(figsize=(8,8))\nsns.distplot(data['SOP'])","3eadef02":"plt.figure(figsize=(8,8))\nsns.violinplot(data['CGPA'])","2acff34c":"xtrain, xtest, ytrain, ytest = train_test_split(data, y, train_size=0.5, test_size=0.5)","b0408991":"RanModel = RandomForestRegressor(n_estimators=500)\n\nRanModel.fit(xtrain, ytrain)","7f6a89e2":"XGModel = XGBRegressor(n_estimators=500)\n\nXGModel.fit(xtrain, ytrain)","55ca1d82":"RanPreds = RanModel.predict(xtest)\n\nmape(ytest, RanPreds)","6c1c1cbf":"XGPreds = XGModel.predict(xtest)\nmape(ytest, XGPreds)","39aff5ad":"for i in range(0, 10):\n    print(RanModel.predict(xtest)[i])","b79e23f8":"print(ytest[0:10])","6cefb66e":"Finding the error percentage for the Random Forest Regressor model:","bd5be655":"# Predicting:","9a476abf":"There are some errors but otherwise the predictions match.","76472528":"Training the data on a XGBoost Regressor model now:","9541b9b9":"# Training models:","ec9f0793":"Plotting the countplot for distribution of university ratings:","e626a573":"Training the data on Random Forest Regressor:","b8ee812b":"Here is a violin plot displaying the distribution of the CGPAs:","d285687d":"Here is the countplot for the SOPs:","9a37b622":"Finally plotting a scatterplot to see the relationship between the scors of GRE Score and TOEFL Score:","3cae942f":"Splitting the data:","a1c95c3e":"What I notice here is that there is a linear and direct relationship between the GRE Scores and TOEFL Scores. The students who score more in one test might also score more or equivalently in the other.","c54894a2":"An accuracy of about 91% or an error percentage of about 9% is seen here.","da74d2c3":"Lets compare the actual values of the predictions to the values predicted by the Random Forest Regressor:","fff430a0":"Finding the error percentage for the XGBRegressor model:","6091f11b":"# Importing Libraries:","944d85ad":"# Plotting:\nReading the data:","273652c6":"Defining the labels:","438b3f60":"An error Perecentage of 8% is decent enough. This also translates into 92% accuracy on the model."}}