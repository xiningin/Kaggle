{"cell_type":{"dceb4cae":"code","cf16243d":"code","ec887ffc":"code","b4615bf9":"code","4b391517":"code","7333cd02":"code","00eefb16":"code","1ae7d2a7":"code","96417335":"code","59447f75":"code","22f9f07e":"code","9c760617":"code","d1ac6623":"code","8f75aca3":"code","688f73f6":"code","d4ec43d5":"code","8b1f962d":"markdown","87693631":"markdown","68851f75":"markdown","a9e79908":"markdown","7dd9a9b7":"markdown","ff991671":"markdown","b7bdd7b9":"markdown","46b37c43":"markdown","1e05b84c":"markdown","27699452":"markdown","b8b4025c":"markdown","9bec3892":"markdown","b2987d72":"markdown","fb22af6c":"markdown","3bc792b7":"markdown","73243646":"markdown","fd8dcf91":"markdown"},"source":{"dceb4cae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir('..\/input\/flowers-recognition\/flowers'))\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cf16243d":"import glob\nfrom pathlib import Path\nflower_dir = Path('..\/input\/flowers-recognition\/flowers\/*\/*')\nflowers = {}\nfor directory in glob.glob(os.path.abspath(flower_dir)):\n    dir_list = []\n    dir_list = directory.split('\/')\n    images = []\n    for files in glob.glob(directory + '\/*.jpg'):\n        images.append(files)\n        flowers.setdefault(dir_list[-1], images)\n    \n","ec887ffc":"label = []\nImage = []\nfor keys, values in flowers.items():\n    for v in values:\n        Image.append(v)\n        label.append(keys)\n\nlen(Image), len(label)","b4615bf9":"from sklearn.utils import shuffle\nimport cv2\nimport matplotlib.pyplot as plt\n\nImage, label = shuffle(Image, label, random_state = 0)\n\nf, ax = plt.subplots(2,5, figsize = (16,8))\nfor i in range(10):\n    img = Image[i]\n    img = cv2.imread(img)\n    img = cv2.resize(img, (224,224))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    ax[i\/\/5, i%5].imshow(img)\n    ax[i\/\/5, i%5].axis('off')\n    ax[i\/\/5, i%5].set_title(label[i])\nplt.show()","4b391517":"data_df = pd.DataFrame(list(zip(Image, label)),columns = ['Image', 'Label'])\ndata_df","7333cd02":"types_of_flowers = ['rose','dandelion', 'daisy', 'tulip', 'sunflower']\nmap = {}\nfor i in range(len(types_of_flowers)):\n    map[types_of_flowers[i]] = i\n\n\nfor x in range(data_df.shape[0]):\n    data_df['Label'][x] = map[data_df['Label'][x]]\ndata_df","00eefb16":"from keras.utils import to_categorical\n\ndef data_generator(data, batch_size):\n    num_samples = len(data)\n    while True:\n        for offset in range(0, num_samples, batch_size):\n            batch_samples = data[offset: offset+batch_size]\n            X = []\n            y = []\n            for ind in batch_samples.index:\n                img = batch_samples['Image'][ind]\n                label = batch_samples['Label'][ind]\n                \n                encoded_label = to_categorical(label, num_classes=5)\n                \n                img = cv2.imread(str(img))\n                img = cv2.resize(img, (224,224))\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                \n                if img.shape[2]==1:\n                    img = np.dstack([img, img, img])\n                img = img.astype(np.float32)\/255    \n                \n                X.append(img)\n                y.append(encoded_label)\n            \n            \n            X = np.asarray(X).astype(np.float32)\n            y = np.asarray(y)\n            \n            yield X, y\n        \n        \n    ","1ae7d2a7":"                                              \nimport tensorflow as tf\nfrom keras.layers import Conv2D, Flatten, Dense, Dropout, Input, MaxPooling2D, GlobalMaxPooling2D, SeparableConv2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.models import Model\nfrom keras.optimizers import Adam, SGD, RMSprop\n\ndef build_model():\n    input_img = Input(shape = (224,224,3), name = 'ImageInput')\n    x = Conv2D(64, (3,3), activation = 'relu', padding = 'same', name = 'Conv1_1' )(input_img)\n    x = Conv2D(63, (3,3), activation = 'relu', padding = 'same', name = 'Conv1_2' )(x)\n    x = MaxPooling2D((2,2), name = 'pool1')(x)\n    \n    x = tf.keras.layers.SeparableConv2D(128, (3,3), activation = 'relu', padding = 'same', name = 'Conv2_1')(x)\n    x = SeparableConv2D(128, (3,3), activation = 'relu', padding = 'same', name = 'Conv2_2')(x)\n    x = MaxPooling2D((2,2), name = 'pool2')(x)\n    \n    x = tf.keras.layers.SeparableConv2D(256, (3,3), activation = 'relu', padding = 'same', name = 'Conv3_1')(x)\n    x = BatchNormalization(name = 'bn1')(x)\n    x = tf.keras.layers.SeparableConv2D(256, (3,3), activation = 'relu', padding = 'same', name = 'Conv3_2')(x)\n    x = BatchNormalization(name = 'bn2')(x)\n    x = tf.keras.layers.SeparableConv2D(256, (3,3), activation = 'relu', padding = 'same', name = 'Conv3_3')(x)\n    x = MaxPooling2D((2,2), name = 'pool3')(x)\n    \n    x = tf.keras.layers.SeparableConv2D(512, (3,3), activation = 'relu', padding = 'same', name = 'Conv4_1')(x)\n    x = BatchNormalization(name = 'bn3')(x)\n    x = tf.keras.layers.SeparableConv2D(512, (3,3), activation = 'relu', padding = 'same', name = 'Conv4_2')(x)\n    x = BatchNormalization(name = 'bn4')(x)\n    x = tf.keras.layers.SeparableConv2D(512, (3,3), activation = 'relu', padding = 'same', name = 'Conv4_3')(x)\n    x = MaxPooling2D((2,2), name = 'pool4')(x)\n    \n    x = Flatten(name = 'flatten')(x)\n    x = Dense(1024,activation = 'relu', name = 'fc1')(x)\n    x = Dropout(0.7, name = 'dropout1')(x)\n    x = Dense(512, activation = 'relu', name = 'fc2')(x)\n    x = Dropout(0.5, name = 'dropout2')(x)\n    x = Dense(5, activation = 'softmax', name = 'fc3')(x)\n    \n    model = Model(inputs = input_img, outputs = x)\n    return model","96417335":"model = build_model()\nmodel.summary()","59447f75":"\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nimport h5py\n\nf = h5py.File('..\/input\/vgg16\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', 'r')\n\nw,b = f['block1_conv1']['block1_conv1_W_1:0'], f['block1_conv1']['block1_conv1_b_1:0']\nmodel.layers[1].set_weights = [w,b]\n\nw,b = f['block1_conv2']['block1_conv2_W_1:0'], f['block1_conv2']['block1_conv2_b_1:0']\nmodel.layers[2].set_weights = [w,b]\n\nw,b = f['block2_conv1']['block2_conv1_W_1:0'], f['block2_conv1']['block2_conv1_b_1:0']\nmodel.layers[4].set_weights = [w,b]\nw,b = f['block2_conv2']['block2_conv2_W_1:0'], f['block2_conv2']['block2_conv2_b_1:0']\nmodel.layers[5].set_weights = [w,b]\n\nf.close()\nmodel.summary()","22f9f07e":"batch_size = 20\nopt = Adam(lr=0.0001, decay=1e-5)\nmodel.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","9c760617":"from sklearn.model_selection import train_test_split\n\nX_train, X_val = train_test_split(data_df, test_size = 0.25, random_state = 30)\n\n\nprint(X_train.shape)\nprint(X_val.shape)\n","d1ac6623":"batch_size = 20\ntrain_data_gen = data_generator(X_train, batch_size)\nval_data_gen = data_generator(X_val, batch_size)","8f75aca3":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nearlyStopping = EarlyStopping(patience = 10)\nlearning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy', patience = 10, verbose =1, factor = 0.5,\n                                           min_lr = 0.0001)\ncallback = [earlyStopping, learning_rate_reduction]\n\nephs = 20\nsteps_per_ephs = X_train.shape[0]\/\/batch_size\nval_steps = X_val.shape[0]\/\/batch_size","688f73f6":"history = model.fit_generator(train_data_gen, epochs = ephs, validation_data = val_data_gen,\n                             validation_steps = val_steps, steps_per_epoch = steps_per_ephs,\n                             callbacks = callback)","d4ec43d5":"f, (ax1, ax2) = plt.subplots(2,1, figsize = (12,12))\nax1.plot(history.history['accuracy'], label = 'Training Accuracy')\nax1.plot(history.history['val_accuracy'], label = 'Validation Accuracy')\nax1.set_title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nax1.legend(['Training Data', 'Validation Data'], loc = 'best')\n\nax2.plot(history.history['loss'], label = 'Training loss')\nax2.plot(history.history['val_loss'], label = 'Validation Loss')\nax2.set_title('Model Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nax2.legend(['Training Data', 'Validation Data'], loc = 'best')","8b1f962d":"**Defining callbacks for the model.** With an simple earlyStopping and Reduce Learning Rate on Plateau class.","87693631":"Here I have trained the model till 20 epochs and further increment in the epochs might increase the accuracy.","68851f75":"**Compiling the model**","a9e79908":"# Building the model.","7dd9a9b7":"Creating a dataframe. Working with a dataframe is way easier for me, so creating a data frame from the list of image names and thier respective labels.","ff991671":"**Calling the data generator function for defining trainng and validation data generator**","b7bdd7b9":"# Data Visualization ","46b37c43":"# **Data Generator**","1e05b84c":"Using a simple data generator which does the data preprocessing and label encodings.","27699452":"Let's see some of the random images and their respective labels.","b8b4025c":"**Chaning the labels (strings) into numbers.**\nSince we have to pass the labels into an encoder later on so this is a very important step.","9bec3892":"This model consists of Convolutional layers and Seperable convolutional layers.","b2987d72":"**Splitting the data into training data and validation data**","fb22af6c":"# Visualizing the model performance ","3bc792b7":"**Importing weigths from VGG16 pre-trained model**","73243646":"# Training the model!","fd8dcf91":"**Please drop an upvote while you are here.** I am a newbie and solemnly welcome critics and comments from you, still have a long way to go.\nThank You!!![l78s3zzpsax21.png](attachment:l78s3zzpsax21.png)"}}