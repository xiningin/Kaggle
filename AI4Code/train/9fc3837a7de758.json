{"cell_type":{"3f03dc1c":"code","01baa1b5":"code","8c3a4c2d":"code","d51fdad6":"code","b7dbb20d":"code","e87d841b":"code","6768db2a":"code","599a5649":"code","b75a77c7":"code","07e39a35":"code","fd9bc77a":"code","1d30c611":"code","66eafd4e":"code","97ee4aae":"code","34559ca7":"code","42dcb38a":"code","b08f0860":"code","1ae31999":"code","4b8745f2":"code","3b1b76cb":"code","15a4a38b":"code","db7fb8b3":"code","20fde499":"code","859039bc":"code","e9a24cfe":"code","24cd655b":"code","a3f4434b":"code","ec2b30c2":"code","45861027":"code","5266e11c":"code","dd51e2e1":"code","083613dc":"code","59efa369":"code","a05634cd":"code","d0c0b1c8":"code","8b1f543c":"code","faff5e0f":"code","a45e205a":"code","8d060eeb":"code","a691eccc":"code","55a613ca":"code","75697c3b":"code","10cd2219":"code","3c8654fb":"code","69c962d8":"code","72100f4b":"code","b1a82852":"code","acaecb38":"code","f1dd5cbc":"code","45597117":"code","eb630664":"code","ee0e373d":"code","4b0eac64":"code","28bfbf80":"code","502d2c98":"code","9f8f5069":"code","81e620bb":"code","1a7c9165":"code","367595d1":"code","4cc7a673":"code","138e432c":"code","e709b773":"code","0797bff0":"markdown","69285785":"markdown","88c6f860":"markdown","61165547":"markdown","f325a48b":"markdown","a45a95ba":"markdown"},"source":{"3f03dc1c":"\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt\n\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer","01baa1b5":"# Suppressing Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","8c3a4c2d":"\n#imporing the data set\nsong_train=pd.read_csv(\"\/kaggle\/input\/song-popularity-prediction\/train.csv\")\nsong_test=pd.read_csv(\"\/kaggle\/input\/song-popularity-prediction\/test.csv\")","d51fdad6":"song_train.head()","b7dbb20d":"song_train.shape","e87d841b":"song_train.info()","6768db2a":"#checking for ouliers\nsong_train.describe(percentiles=[.25, .5, .75, .90, .95, .99])","599a5649":"#finding the null perecentage\nround(100*(song_train.isnull().sum())\/(len(song_train)),2)","b75a77c7":"#numerical featrures\nfeature_num = [\"song_duration_ms\",\"acousticness\",\"danceability\",\"energy\",\"instrumentalness\",\"liveness\",\"loudness\",\"speechiness\",\"tempo\",\"audio_valence\"]\nimpute_tech = SimpleImputer(strategy=\"mean\")\nimputed_set= song_train.copy()\nimputed_set[feature_num] = impute_tech.fit_transform(imputed_set[feature_num])\n#numerical featrures-test set\ntest_tech = SimpleImputer(strategy=\"mean\")\ntest_set= song_test.copy()\ntest_set[feature_num] = test_tech.fit_transform(test_set[feature_num])\n","07e39a35":"imputed_set.isnull().sum()","fd9bc77a":"imputed_set.head()","1d30c611":"imputed_set[\"key\"].value_counts()","66eafd4e":"#categorical featrures\nfeature_cat = [\"key\"]\nimpute_tech = SimpleImputer(strategy=\"most_frequent\")\nimputed_set2= imputed_set.copy()\nimputed_set2[feature_cat] = impute_tech.fit_transform(imputed_set2[feature_cat])\n#categorical featrures\ntest_tech = SimpleImputer(strategy=\"most_frequent\")\ntest_set2= test_set.copy()\ntest_set2[feature_cat] = test_tech.fit_transform(test_set2[feature_cat])","97ee4aae":"imputed_set2.isnull().sum()","34559ca7":"test_set2.isnull().sum()","42dcb38a":"X_train=imputed_set2.drop(['id',\"song_popularity\"], axis=1)\nX_test=test_set2.drop(['id'], axis=1)","b08f0860":"y_train=imputed_set2[\"song_popularity\"]\n","1ae31999":"X_train.head()","4b8745f2":"X_train.describe()","3b1b76cb":"features=[\"song_duration_ms\",\"acousticness\",\"danceability\",\"energy\",\"instrumentalness\",\"liveness\",\"loudness\",\"speechiness\",\"tempo\",\"audio_valence\"]\nscaler = StandardScaler()\nX_train[features] = scaler.fit_transform(X_train[features])\nX_train=round(X_train,2)\nscaler = StandardScaler()\nX_test[features] = scaler.fit_transform(X_test[features])\nX_test=round(X_test,2)\n\n","15a4a38b":"pd.DataFrame(X_train,columns=features)","db7fb8b3":"X_train.info()","20fde499":"y_train.head()","859039bc":"X_train.info()","e9a24cfe":"X_train.head()","24cd655b":"plt.figure(figsize = (20,10))        # Size of the figure\nsns.heatmap(X_train.corr(),annot =True)\nplt.show()","a3f4434b":"import statsmodels.api as sm","ec2b30c2":"# np.asarray(X_train)\n# X_train=X_train.astype(float)","45861027":"# Logistic regression model\nlogm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\nlogm1.fit().summary()","5266e11c":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()","dd51e2e1":"y_train=y_train.astype(float)\nfrom sklearn.feature_selection import RFE\nrfe = RFE(logreg,10)           \nrfe = rfe.fit(X_train,y_train)","083613dc":"rfe.support_","59efa369":"list(zip(X_train.columns, rfe.support_, rfe.ranking_))","a05634cd":"col = X_train.columns[rfe.support_]","d0c0b1c8":"X_train.columns[~rfe.support_]","8b1f543c":"X_train=X_train[col]\nX_train_sm = sm.add_constant(X_train)\nlogm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm2.fit()\nres.summary()","faff5e0f":"X_train=X_train.drop([\"acousticness\"],1)\nX_train_sm = sm.add_constant(X_train)\nlogm3 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm3.fit()\nres.summary()","a45e205a":"X_train=X_train.drop([\"audio_mode\"],1)\nX_train_sm = sm.add_constant(X_train)\nlogm4 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm4.fit()\nres.summary()","8d060eeb":"y_train_pred = res.predict(X_train_sm)\ny_train_pred","a691eccc":"y_train_pred_final = pd.DataFrame({'popular':y_train.values,\"popular_probability\":y_train_pred})\ny_train_pred_final['id']=y_train.index\ny_train_pred_final.head()","55a613ca":"# Creating new column 'predicted' with 1 if song_prob> 0.5 else 0\ny_train_pred_final['predicted'] = y_train_pred_final.popular_probability.map(lambda x: 1 if x > 0.5 else 0)\ny_train_pred_final.head()","75697c3b":"y_train_pred_final[\"predicted\"].value_counts()","10cd2219":"# Confusion matrix \nfrom sklearn import metrics\nconfusion = metrics.confusion_matrix(y_train_pred_final.popular, y_train_pred_final.predicted )\nprint(confusion)","3c8654fb":"# Let's check the overall accuracy.\\\n\nprint(metrics.accuracy_score(y_train_pred_final.popular, y_train_pred_final.predicted))","69c962d8":"# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","72100f4b":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","b1a82852":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","acaecb38":"fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.popular, y_train_pred_final.popular_probability, drop_intermediate = False )","f1dd5cbc":"draw_roc(y_train_pred_final.popular, y_train_pred_final.popular_probability)","45597117":"# Let's create columns with different probability cutoffs \nnumbers = [float(x)\/10 for x in range(10)]\nfor i in numbers:\n    y_train_pred_final[i]= y_train_pred_final.popular_probability.map(lambda x: 1 if x > i else 0)\ny_train_pred_final.head()","eb630664":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = metrics.confusion_matrix(y_train_pred_final.popular, y_train_pred_final[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])\/total1\n    \n    speci = cm1[0,0]\/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","ee0e373d":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\nplt.show()","4b0eac64":"y_train_pred_final['final_predicted'] = y_train_pred_final.popular_probability.map( lambda x: 1 if x > 0.4 else 0)\n\ny_train_pred_final.head()","28bfbf80":"metrics.accuracy_score(y_train_pred_final.popular, y_train_pred_final.final_predicted)","502d2c98":"confusion2 = metrics.confusion_matrix(y_train_pred_final.popular, y_train_pred_final.final_predicted )\nconfusion2","9f8f5069":"test_set2.isnull().sum()\n","81e620bb":"feat=X_train.columns\nfeat","1a7c9165":"X_test_sm = sm.add_constant(test_set2[feat])\ny_test_pred = res.predict(X_test_sm).values.reshape(-1)","367595d1":"y_test_pred_final = pd.DataFrame({'popular_Prob':y_test_pred})\ny_test_pred_final['Id'] = X_test_sm.index\ny_test_pred_final.head()\n\n","4cc7a673":"y_test_pred_final['predicted'] = y_test_pred_final.popular_Prob.map(lambda x: 1 if x > 0.4 else 0)\n\n# Let's see the head\ny_test_pred_final.head()","138e432c":"df=y_test_pred_final.iloc[:,1:]\ndf.to_csv('Submission.csv',index=False,header=True)","e709b773":"pd.read_csv(\"Submission.csv\")","0797bff0":"# train data Feature scaling","69285785":"plotting the ROC curve and finding optimal prob ","88c6f860":"0.4 is the optimal probability","61165547":"Accuracy is 63% considering probability of 0.5","f325a48b":"Treating missing values","a45a95ba":"* Danceability: Describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity.\n* Valence: Describes the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n* Energy: Represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale.\n* Tempo: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece, and derives directly from the average beat duration.\n* Loudness: The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks.\n* Speechiness: This detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value.\n* Instrumentalness: Predicts whether a track contains no vocals. \u201cOoh\u201d and \u201caah\u201d sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \u201cvocal\u201d.\n* Liveness: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live.\n* Acousticness: A confidence measure from 0.0 to 1.0 of whether the track is acoustic.\n* Key: The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C\u266f\/D\u266d, 2 = D, and so on.\n* Mode: Indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n* Duration: The duration of the track in milliseconds.\n* Time Signature: An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).\n"}}