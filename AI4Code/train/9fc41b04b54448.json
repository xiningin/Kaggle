{"cell_type":{"3b89c23d":"code","931f987f":"code","d2768e66":"code","c552f432":"code","65cb4f6a":"code","8e1c18c3":"code","40cf16a6":"markdown","f9b4eeb9":"markdown","6940b180":"markdown","8f654852":"markdown","9cfc5bc0":"markdown","d6f07245":"markdown"},"source":{"3b89c23d":"import os \nfor dirname, _, filenames in os.walk('\/kaggle\/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","931f987f":"import pandas as pd\ncheck_df = pd.read_csv('..\/input\/binance-ethusdt\/ethusdt_kline_1m.csv')\ncheck_df.info()\ncheck_df = check_df.reset_index()\ncols = [\"t\",\"o\",\"h\",\"l\",\"c\",\"v\"]\n# check_df.drop_duplicates(\"t\", inplace=True)\nduplication_df = check_df[check_df.duplicated(subset=cols)].drop_duplicates(cols)[cols]\nduplication_records = pd.merge(duplication_df, check_df, on=cols, how=\"left\")\nprint('\\n\\n =============================duplication records============================= \\n')\nprint(duplication_records)","d2768e66":"import os\nimport pandas as pd\n\ndf = pd.read_csv('..\/input\/binance-ethusdt\/ethusdt_kline_1m.csv')\ndf.t = df.t.apply(lambda x: pd.Timestamp(x, unit='ms'))\ndf.set_index(df['t'], inplace=True)\ndf = df.drop([\"t\"], axis=1)\ndf.to_csv('ethusdt_kline_1m.csv', index=False)\n# default complib zlib\ndf.to_hdf('ethusdt_kline_1m.h5',key=\"kline_\")\n# use blosc mode compression\ndf.to_hdf('ethusdt_kline_1m_compress.h5',key=\"kline_\",complevel=9, complib='blosc:lz4')\n\ndf = df.reset_index()\ndf.to_feather('ethusdt_kline_1m.feather')\n\nfor dirname, _, filenames in os.walk('\/kaggle\/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c552f432":"import time\nimport pandas as pd\n# 1.csv\nstart = time.time()\ndf = pd.read_csv('ethusdt_kline_1m.csv')\n# df.set_index(df['t'], inplace=True)\n# df = df.drop([\"t\"], axis=1)\nprint(df)\nend = time.time()\nprint('CSV Running time:                %s Seconds' % (end-start))\n\n# 2.pandas-feather\nstart = time.time()\ndf = pd.read_feather('ethusdt_kline_1m.feather')\ndf.set_index(df['t'], inplace=True)\ndf = df.drop([\"t\"], axis=1)\nprint(df)\nend = time.time()\nprint('Pd-feather Running time:         %s Seconds' % (end-start))\n\n# 3.pandas-hdf5\nstart = time.time()\ndf = pd.read_hdf('ethusdt_kline_1m.h5', key=\"kline_\")\n# print(df)\nend = time.time()\nprint('Pd-hdf5 Running time:            %s Seconds' % (end-start))\n\n# 4.pandas-hdf5 blosc mode compression \nstart = time.time()\ndf = pd.read_hdf('ethusdt_kline_1m_compress.h5', key=\"kline_\")\n# print(df)\nend = time.time()\nprint('Pd-hdf5 blosc mode Running time: %s Seconds' % (end-start))","65cb4f6a":"import os\n\ndef get_FileSize(filePath):\n    filePath = str(filePath)\n    fsize = os.path.getsize(filePath)\n    fsize = fsize \/ float(1024 * 1024)\n    return round(fsize, 2)\n\nprint(f\"csv file size:             { get_FileSize('ethusdt_kline_1m.csv') } MB\")\nprint(f\"raw feather size:          { get_FileSize('ethusdt_kline_1m.feather') } MB\")\nprint(f\"hdf5 file size:            { get_FileSize('ethusdt_kline_1m.h5') } MB\")\nprint(f\"hdf5 blosc mode file size: { get_FileSize('ethusdt_kline_1m_compress.h5') } MB\")","8e1c18c3":"import pandas as pd\nkline_df = pd.read_hdf('ethusdt_kline_1m_compress.h5', key=\"kline_\")\n\nfreq = '5T'\nkline_1m_df = pd.DataFrame({'o': kline_df.resample(freq, label='right', closed='right').first()['o'],\n                       'h': kline_df.resample(freq, label='right', closed='right').max()['h'],\n                       'l': kline_df.resample(freq, label='right', closed='right').min()['l'],\n                       'c': kline_df.resample(freq, label='right', closed='right').last()['c'],\n                       'v': kline_df.resample(freq, label='right', closed='right').sum()['v'],\n                       })\nprint(kline_1m_df.info())","40cf16a6":"## 1. View files in the working directory","f9b4eeb9":"## 4. Read testing\n> test csv, feather, hdf format","6940b180":"## 5. Calculate file size\uff08MB\uff09","8f654852":"## 2. Checking data duplication\n> The data consists of `484,287` records","9cfc5bc0":"## 3. Format conversion\n> csv conver to feather, hdf","d6f07245":"## 6. Generate kline data\n> 5min 15min 1hour 4hour 1day"}}