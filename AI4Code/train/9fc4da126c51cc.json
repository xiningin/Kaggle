{"cell_type":{"9dbdf612":"code","ff202a27":"code","a1320ae4":"code","14da49f2":"code","93b6b797":"code","7a51509a":"code","ab0a4b8e":"code","e65bce64":"code","eea23a70":"code","593ed334":"code","86e47ed5":"code","fbde2dc0":"code","bc92db6b":"code","a0f8b5c3":"code","3caa597e":"code","bc7cd7b5":"code","15e7dead":"code","f09bbe3b":"code","89df45fa":"code","ea2ca896":"code","7eafa153":"code","75044264":"code","3bd90f6f":"code","bfc86256":"code","7920b51d":"code","20a39923":"code","1d258254":"code","e978fb1d":"code","d7270ae6":"code","f0d263b4":"code","77be2746":"markdown","7da185ef":"markdown","e686412a":"markdown","158145e8":"markdown","d2e4ebd4":"markdown","b40dc95b":"markdown","e2827853":"markdown","e02797f1":"markdown","e0c87c1f":"markdown","6ba3697d":"markdown","2fc50a97":"markdown","0a4a14b7":"markdown","839a94ef":"markdown"},"source":{"9dbdf612":"import pandas as pd\nimport re\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport warnings\nfrom pathlib import Path\nwarnings.filterwarnings('ignore')\nROOT = Path('..\/input\/titanic')","ff202a27":"# Load in the datasets and combain them in one dataset\ntrain = pd.read_csv(ROOT \/ 'train.csv')\ntest = pd.read_csv(ROOT \/ 'test.csv')\nsubmission = pd.read_csv(ROOT \/ 'gender_submission.csv')\ntrain['Dataset'] = 'train'\ntest['Dataset'] = 'test'\nsubmission['Dataset'] = 'submission'\nall_data = train.append(test)\nall_data[all_data.Dataset == 'train'].head()","a1320ae4":"all_data[all_data.Dataset == 'test'].head()","14da49f2":"all_data.Sex[all_data.Sex == 'male'] = 1\nall_data.Sex[all_data.Sex == 'female'] = 0\nall_data.Sex = all_data.Sex.astype(float)\nall_data.head()","93b6b797":"all_data.Age[all_data.Age.isna()] = all_data.Age.mode().iloc[0]\nall_data['AgeCategory'] = pd.qcut(all_data['Age'], 4, labels = list(map(str, range(4))))\nage_category = 0\nfor cat in all_data[['AgeCategory', 'Survived']].groupby('AgeCategory').mean().sort_values('Survived').reset_index().AgeCategory:\n    all_data.Age[all_data.AgeCategory == cat] = age_category\n    age_category += 1\nall_data.drop(columns=\"AgeCategory\", inplace=True)\nall_data.head()","7a51509a":"plt.rcParams['font.size']=20\nall_data[all_data.Dataset=='train'][['Age', 'Survived']]\\\n    .groupby('Age')\\\n    .mean()\\\n    .reset_index()\\\n    .plot.scatter(x='Age', y='Survived', s=100)\nplt.xlabel('Age category')\nplt.ylabel('Survived')\nplt.title('Percent of survived for different age categories')\nplt.grid('both')","ab0a4b8e":"all_data.Pclass = all_data.Pclass.astype(float)\nall_data[['Pclass', 'Survived']].groupby('Pclass').mean().reset_index().plot.scatter(x='Pclass', y='Survived', s=100)\nplt.xlabel('Pclass')\nplt.ylabel('Survived')\nplt.title('Percent of survived for different passenger classes')\nplt.grid('both')","e65bce64":"all_data[['SibSp', 'Survived']].groupby('SibSp').mean().reset_index().plot.scatter(x='SibSp', y='Survived', s=100)\nplt.xlabel('SibSp')\nplt.ylabel('Survived')\nplt.title('Percent of survived for different passenger family status')\nplt.grid('both')","eea23a70":"all_data.SibSp = all_data.SibSp.astype(float)\nall_data.SibSp[all_data.SibSp == 8.] = 5.\nall_data.head()","593ed334":"all_data.SibSp[all_data.SibSp == 0.] = 2.5\nall_data[['SibSp', 'Survived']].groupby('SibSp').mean().reset_index().plot.scatter(x='SibSp', y='Survived', s=100)\nplt.xlabel('SibSp')\nplt.ylabel('Survived')\nplt.title('Percent of survived for different passenger family status')\nplt.grid('both')","86e47ed5":"all_data.head()","fbde2dc0":"all_data['CabinLetter'] = all_data.Cabin.str.slice(start=0, stop=1)","bc92db6b":"all_data.groupby('CabinLetter')['Survived'].mean()","a0f8b5c3":"all_data.groupby('CabinLetter')['Survived'].count()","3caa597e":"all_data.Cabin[all_data.Cabin.notna() & all_data.CabinLetter.isna()]","bc7cd7b5":"all_data.Survived[all_data.Cabin.isna()].mean()","15e7dead":"all_data.Cabin[all_data.Cabin.notna()] = 1\nall_data.Cabin[all_data.Cabin.isna()] = 0\nall_data.Cabin[(all_data.CabinLetter == 'B') & (all_data.CabinLetter == 'D') & (all_data.CabinLetter == 'E')] = 2\nall_data.drop(columns='CabinLetter', inplace=True)\nall_data.Cabin = all_data.Cabin.astype(float)\nall_data.head()","f09bbe3b":"all_data['FareCategory'] = pd.qcut(all_data['Fare'], 7, labels = list(map(str, range(7))))\nall_data['FareCategory'][all_data.FareCategory.isna()] = all_data.FareCategory.mode().iloc[0]","89df45fa":"all_data.groupby('FareCategory').mean().reset_index().plot.scatter(x='FareCategory', y='Survived', s=100)\nplt.grid('both')","ea2ca896":"all_data.Fare = all_data.FareCategory.astype(float)\nall_data.Fare[all_data.Fare == 0] = 1\nall_data.Fare[all_data.Fare == 5] = 4\nall_data.Fare[all_data.Fare == 6] = 5\nall_data.groupby('Fare').mean().reset_index().plot.scatter(x='Fare', y='Survived', s=100)\nplt.grid('both')\nall_data.drop(columns='FareCategory', inplace=True)\nall_data.head()","7eafa153":"feature_columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\ntarget_column = 'Survived'","75044264":"from sklearn.model_selection import (GridSearchCV,\n                                     train_test_split,\n                                     StratifiedKFold\n                                    )\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\n\n# switch of this one because it is too slow\n# from xgboost import XGBClassifier\n\n# \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0431\u0430\u0437\u043e\u0432\u044b\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432\ngbc_params = {'learning_rate': np.arange(0.1, 0.6, 0.1)} # GradientBoostingClassifier\n\nrfc_params = {'n_estimators': range(10, 100, 10), # RandomForestClassifier\n              'min_samples_leaf': range(1, 5)}\n\ndtc_params = {'criterion' : ['gini', 'entropy'], 'min_samples_leaf' : range(1, 20)} #DecisionTreeClassifier\n\nsvc_params = {'kernel': ['linear', 'rbf'], # SVC\n              'C': np.arange(0.1, 1, 0.2)}\n\nlr_params = {'C': 10 ** np.arange(0.0, 0.1, 3.0)}\n\nskf = StratifiedKFold(n_splits=5, random_state=17)","3bd90f6f":"class Blending:\n    def __init__(self, models, meta_alg, test_size, random_state=0):\n        assert 0. < test_size < 1.\n        self.__models = models\n        self.__meta = meta_alg\n        self.__randomseed = random_state\n        self.__test_size = test_size\n  \n    @property\n    def models(self):\n        return self.__models\n\n    @property\n    def meta(self):\n        return self.__meta\n\n    def fit(self, X, y):\n        X_base, X_meta, y_base, y_meta = train_test_split(X, y, random_state=self.__randomseed, test_size=self.__test_size)\n        for model in self.__models:\n            model.fit(X_base, y_base)\n        meta_matrix = np.empty((len(y_meta), len(self.__models)))\n        for i, model in enumerate(self.__models):\n            meta_matrix[:,i] = model.predict(X_meta)\n        self.__meta.fit(meta_matrix, y_meta)\n        return self\n  \n    def predict(self, X):\n        meta_matrix = np.empty((len(X), len(self.__models)))\n        for i, model in enumerate(self.__models):\n            meta_matrix[:,i] = model.predict(X)\n        return self.__meta.predict(meta_matrix)\n\nclass Stacking(Blending):\n    def __init__(self, models, meta_alg, test_size, random_state=0, cv=5):\n        Blending.__init__(self, models, meta_alg, test_size, random_state)\n        self.__cv = cv\n\n    def fit(self, X, y):\n        meta_matrix = np.empty((X.shape[0], len(self.models)))\n        for i, model in enumerate(self.models):\n            meta_matrix[:,i] = cross_val_predict(model, X, y, cv=self.__cv, method='predict')\n            model.fit(X, y)\n        self.meta.fit(meta_matrix, y)\n        return self","bfc86256":"all_data[feature_columns] = StandardScaler().fit_transform(all_data[feature_columns])\nX = all_data[feature_columns][all_data.Dataset == 'train']\ny = all_data[target_column][all_data.Dataset == 'train']\nfor name, estimator in zip(['gbc', 'dtc', 'svc', 'lr'], \n                           [GradientBoostingClassifier(), DecisionTreeClassifier(), SVC(), LogisticRegression()]):\n    globals()[name] = GridSearchCV(cv=skf, estimator=estimator, param_grid=globals()[name + '_params'])\n    globals()[name].fit(X.values, y.values)\n    print(f\"Estimator: {estimator}, Best score: {globals()[name].best_score_}\")","7920b51d":"from sklearn.model_selection import cross_val_predict\nst = Stacking([gbc.best_estimator_, dtc.best_estimator_, svc.best_estimator_, lr.best_estimator_], \n              lr, test_size=.1, random_state=17, cv=5)\nst.fit(X, y)","20a39923":"X.shape","1d258254":"from sklearn.metrics import recall_score\n\ndtc.fit(X, y)\n\nall_data['Predictions'] = st.predict(all_data[feature_columns])","e978fb1d":"recall_score(all_data.Survived[all_data.Dataset == 'train'], all_data.Predictions[all_data.Dataset == 'train'])","d7270ae6":"submission = all_data[['PassengerId', 'Predictions']][all_data.Dataset =='test'].rename(columns={'Predictions' : 'Survived'})\nsubmission.Survived = submission.Survived.astype(int)\nsubmission.head()","f0d263b4":"submission.to_csv('submission.csv', index=False)","77be2746":"## Age\n\nMake age categorical variable","7da185ef":"# Content\n* [Kaggle](#Kaggle)\n* [Feature ingineering](#Feature-ingineering)\n    * [Sex](#Sex)\n    * [Age](#Age)\n    * [Pclass, SibSp, Parch](#Pclass,-SibSp,-Parch)\n    * [Cabin](#Cabin)\n    * [Fare](#Fare)\n   ","e686412a":"### 2.\n1. \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u0442\u0435 \u043e\u0431\u044a\u0435\u043a\u0442 GridSearchCV \u0434\u043b\u044f \u0432\u0441\u0435\u0445 \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u043d\u044b\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430 (\u0432 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430 \u043f\u0440\u0438 \u0435\u0433\u043e \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0438, \u0435\u0441\u043b\u0438 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e, \u0443\u043a\u0430\u0436\u0438\u0442\u0435 random_state=17). \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 cv \u0443\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0439\u0442\u0435 \u0440\u0430\u0432\u043d\u044b\u043c skf.\n\n2. \u041e\u0431\u0443\u0447\u0438\u0442\u0435 \u043a\u0430\u0436\u0434\u044b\u0439 \u0438\u0437 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0438\u0437 1-\u0433\u043e \u043f\u0443\u043d\u043a\u0442\u0430 \u043d\u0430 \u043f\u043e\u043b\u0443\u0447\u0438\u0432\u0448\u0435\u0439\u0441\u044f \u043f\u0440\u0438 \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0438 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435. \u0412\u044b\u0432\u0435\u0434\u0438\u0442\u0435 \u043b\u0443\u0447\u0448\u0435\u0435 \u0441\u043e\u0447\u0435\u0442\u0430\u043d\u0438\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0438\u0437 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432.\n\n3. \u0414\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u043e\u0433\u043e \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430 \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u0435 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u0432\u044b\u0432\u0435\u0434\u0438\u0442\u0435 \u043c\u0435\u0442\u0440\u0438\u043a\u0443 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u0435\u0442 \u043c\u0435\u0442\u0440\u0438\u043a\u0435 \u043e\u0446\u0435\u043d\u043a\u0438 \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u044f.","158145e8":"# Kaggle\n\n\u0412 \u044d\u0442\u043e\u043c \u0434\u043e\u043c\u0430\u0448\u043d\u0435\u043c \u0437\u0430\u0434\u0430\u043d\u0438\u0438 \u0432\u0430\u043c \u043d\u0443\u0436\u043d\u043e \u0431\u0443\u0434\u0435\u0442 \u043f\u043e\u0441\u0442\u0440\u043e\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c \u0434\u043b\u044f \u0434\u0430\u043d\u043d\u044b\u0445 \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u044f [Titanic \u043d\u0430 Kaggle](https:\/\/www.kaggle.com\/c\/titanic\/overview), \u0441\u0444\u043e\u0440\u043c\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0444\u0430\u0439\u043b \u0441 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\u043c\u0438 \u0434\u043b\u044f \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u043e\u0442\u043f\u0440\u0430\u0432\u0438\u0442\u044c \u0435\u0433\u043e \u043d\u0430 \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0443.\n\n\u0412 \u043f\u0440\u0430\u043a\u0442\u0438\u043a\u0435 \u0438\u0437 \u0443\u0440\u043e\u043a\u0430 \u0432\u0430\u0448\u0438\u043c \u0437\u0430\u0434\u0430\u043d\u0438\u0435\u043c \u0431\u044b\u043b\u043e \u0440\u0430\u0437\u043e\u0431\u0440\u0430\u0442\u044c \u043e\u0434\u043d\u043e \u0438\u0437 \u0441\u0430\u043c\u044b\u0445 \u043f\u043e\u043f\u0443\u043b\u044f\u0440\u043d\u044b\u0445 \u044f\u0434\u0435\u0440 \u0434\u043b\u044f \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u044f Titanic \u0438 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u0442\u044c \u0435\u0433\u043e \u0442\u0430\u043a\u0438\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c, \u0447\u0442\u043e\u0431\u044b \u043e\u0441\u0442\u0430\u043b\u0438\u0441\u044c \u0442\u043e\u043b\u044c\u043a\u043e \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u0433\u0440\u0430\u0444\u0438\u043a\u0438.\n\n\u0421\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0435\u043d\u043d\u043e, \u0441\u0435\u0439\u0447\u0430\u0441 \u0432\u0430\u0448\u0435 \u044f\u0434\u0440\u043e \u0434\u043e\u043b\u0436\u043d\u043e \u0432\u044b\u0433\u043b\u044f\u0434\u0435\u0442\u044c \u0442\u0430\u043a\u0438\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c:","d2e4ebd4":"Let set `SibSp` 5 to `SibSp` which equals to 8. It seems they have similar surviving probabilities.","b40dc95b":"## Fare\nThis feature is strongly connected to Pclass. Let categorize it.","e2827853":"Chose feature columns","e02797f1":"Let set 2.5 to `SibSp` which equals to 0, seems, it should be here.","e0c87c1f":"### \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438\n\n### 1.\n\n\u0412\u043e\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435\u0441\u044c \u0432\u0430\u0448\u0438\u043c \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u043c \u0441\u0442\u0435\u043a\u0438\u043d\u0433\u0430 \u0438\u0437 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0435\u0433\u043e \u0434\u043e\u043c\u0430\u0448\u043d\u0435\u0433\u043e \u0437\u0430\u0434\u0430\u043d\u0438\u044f. \u0412 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0431\u0430\u0437\u043e\u0432\u044b\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435 RandomForestClassifier, SVC, GradientBoostingClassifier \u0438 LogisticRegression; \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u043c\u0435\u0442\u0430-\u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430 - XGBoost.\n\n\u0420\u0430\u0437\u0434\u0435\u043b\u0438\u0442\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 train \u043d\u0430 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u0443\u044e \u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u0441 random_state=17 \u0438 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u043c \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f test_size=.3 (\u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 \u0432\u043e\u0437\u044c\u043c\u0438\u0442\u0435 \u0441\u0442\u043e\u043b\u0431\u0435\u0446 Survived, \u0430 \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 - \u0432\u0441\u0435 \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0435 \u0441\u0442\u043e\u043b\u0431\u0446\u044b).\n\n\u041d\u0438\u0436\u0435 \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u044b \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0438\u0437 \u0431\u0430\u0437\u043e\u0432\u044b\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u043d\u0430\u0441\u0442\u0440\u043e\u0438\u0442\u044c \u043d\u0430 5-\u043a\u0440\u0430\u0442\u043d\u043e\u0439 \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e GridSearchCV:","6ba3697d":"## Sex\nMale = 1\nFemale = 0","2fc50a97":"# Feature ingineering","0a4a14b7":"## Pclass, SibSp\n\nConsider all tree features together and note[](http:\/\/) that surviving due to the `Embarked` and `Cabin` can be explained by belonging to one of these categories. Also `Parch` can be connected to `SibSp` and it seems quite unbalanced, because it is mostly equal to 0.","839a94ef":"## Cabin"}}