{"cell_type":{"5593ed47":"code","8dabc956":"code","47c0f0c3":"code","f9987a44":"code","af0a8c2d":"code","4233177f":"code","2e4a1678":"code","d69a2052":"code","ea7fa727":"code","219ce3ed":"code","11f48778":"code","89b69e49":"code","00f73eca":"code","d3c83754":"markdown","b0334c5c":"markdown","cd1a085d":"markdown","f33a53ec":"markdown","8a2c75ef":"markdown","4374dac3":"markdown","5198b5f1":"markdown","9ac9709e":"markdown","3f3637fb":"markdown","4c478ffd":"markdown"},"source":{"5593ed47":"# import the necessary packages\nfrom sklearn.preprocessing import LabelBinarizer, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout\nfrom keras.optimizers import SGD\nfrom keras import regularizers\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))","8dabc956":"# Loading the dataset\ndataset = pd.read_csv('..\/input\/pulsar_stars.csv')","47c0f0c3":"# EDA\nprint(dataset.head())","f9987a44":"# Droping the target and assigning the rest to the data variable\ndata = dataset.drop(['target_class'], axis=1)\n\n# Standardization procedure\nscaler = StandardScaler()\ndata = scaler.fit_transform(data)\n\ntarget = dataset[['target_class']]","af0a8c2d":"# Construct the training and testing splits \ntrainX, testX, trainY, testY = train_test_split(data, target, test_size=0.25)","4233177f":"lb = LabelBinarizer()\ntrainY = lb.fit_transform(trainY)\ntestY = lb.transform(testY)","2e4a1678":"# Defining the model\nmodel = Sequential()\nmodel.add(Dense(4, input_shape=(8,), activation='sigmoid'))\nmodel.add(Dense(2, activation='sigmoid'))\nmodel.add(Dense(1, activation='sigmoid'))","d69a2052":"sgd = SGD(0.12, momentum=0.4)\n\nmodel.compile(loss='binary_crossentropy', optimizer=sgd,\n    metrics=[\"accuracy\"])\n\nclass_weight = {0 : 1., 1 : 2.}\n\nH = model.fit(trainX, trainY, validation_data=(testX, testY), \n              batch_size=128, epochs=200, class_weight=class_weight, verbose=0)\n\nscores = model.evaluate(testX, testY, verbose = 0)","ea7fa727":"predictions = model.predict(testX, batch_size=128)\n\n# apply a step function to threshold the outputs to binary\n# class labels\npredictions[predictions < 0.5] = 0\npredictions[predictions >= 0.5] = 1\n\nreport = classification_report(testY, predictions, \n                               target_names=['Non-pulsar Star', 'Pulsar Star'])\n\nprint('Accuracy = {:.7f}'.format(scores[1]))\nprint(report)","219ce3ed":"conf_matrix = confusion_matrix(testY, predictions)\n\n# Plot the confusion matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt     \n\nplt.figure(figsize=(10,8))\nax = plt.subplot()\nsns.heatmap(conf_matrix, annot=True, ax = ax, fmt='d') #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')\nax.set_title('Confusion Matrix')\nax.xaxis.set_ticklabels(['Non-Pulsar', 'Pulsar'])\nax.yaxis.set_ticklabels(['Non-Pulsar', 'Pulsar'])\n#plt.savefig('confusion_matrix_wcw.png')","11f48778":"# Plotting the curve Epoch vs. Loss\/Accuracy\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, 200), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, 200), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, 200), H.history[\"acc\"], label=\"train_acc\")\nplt.plot(np.arange(0, 200), H.history[\"val_acc\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend()","89b69e49":"fpr_keras, tpr_keras, thresholds_keras = roc_curve(testY, predictions)\n\nauc_keras = auc(fpr_keras, tpr_keras)","00f73eca":"plt.figure(1)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()","d3c83754":"We are going to use the Stochastic Gradient Descent technique as an optimizer, initially with a learning rate = 0.12 and a momentum = 0.4. Furthermore, as this is a binary classification problem, in this case a common loss function to use is the binary cross-entropy. However, as we have imbalanced classes, we need to tell the network that during the training, the positive class is more important than the negative. This has been done through the class weight dictionary, in this case, I am telling the network that during the training data positive points are 2 times more important than the negative ones.","b0334c5c":"With keras, it is possible to define models to our neural network (nn). In this case, we are going to work with a Sequential nn, which is just the nn as we already know, i.e., each layer has as its input the output of the former layer. It is worth mention that our neural network is 8-4-2-1.","cd1a085d":"1. Once the dataset is loaded, let's see some relevant information about the dataset such as column's titles and types, number of records and shape.","f33a53ec":"Machine Learning algorithms works better when integer labels are transformed into vector labels. In order to accomplish this transformation I will instantiate a LabelBinarizer object and apply the transformation methods into our trainY and testY sets.","8a2c75ef":"As we want to classify the class labeled 1 (Pulsar stars), we are especially interessed in obtain a low rate of false negatives. What I mean is, our classes are extremely unbalanced, if we only care about accuracy and obtain high rate of false negatives, it means that our network is not performing well on what it was created for. \n\nWhat I did here was tuning the parameters of the network to obtain the least rate of false negatives while increasing accuracy. The drawback of this approach was that as the false negative occurrencies decreased so increased the occurencies of false positives. In a real worl context, this means that we are better at classifying Pulsar stars, meanwhile our network fails more in classify a Non-pulsar Star as a Pulsar Star (There's no free lunch, you know). Particularly, this behavior is worth because we will be predicting better at what the classifier was meant for. For those who are not acquainted with statistics, the false negative occurrencies are in the bottom -left cell of the confusion matrix and the false positive one are at the top-right cell. ","4374dac3":"Note that the training loss is much higher than the validation loss, why is it?\n\nA Keras model has two modes: training and testing. Regularization mechanisms, such as Dropout and L1\/L2 weight regularization, are turned off at testing time.\n\nBesides, the training loss is the average of the losses over each batch of training data. Because your model is changing over time, the loss over the first batches of an epoch is generally higher than over the last batches. On the other hand, the testing loss for an epoch is computed using the model as it is at the end of the epoch, resulting in a lower loss.\n\nFor more informations, see: http:\/\/blog.datumbox.com\/the-batch-normalization-layer-of-keras-is-broken\/ https:\/\/forums.fast.ai\/t\/validation-loss-lower-than-training-loss\/4581\/2","5198b5f1":"2. Now, let's divide our dataset into two subsets: data and target. In this case, I am doing a Standardization procedure in order obtain zero mean and a standard deviation equals to 1. This preserves Gaussian and Gaussian-like distributions whilst normalizing the central tendencies for each attribute.","9ac9709e":"**ACCURACY = 0.98**\n\nIt is also important to visualize the confusion matrix of our predictions, this can lead us to a more precise visualization and comprehension about where the numbers in our report came from. ","3f3637fb":"At this point we are ready to analyze the results from our neural network. Calling the .predict method on our model will give us the predictions from our testing set. In addition, as the output from our network is given by the sigmoid activation function, the outputs values are real number in the range [0,1], so, we need to apply a step function to threshold the outputs to binary class labels. Lastly, we print a report showing us the performance of the model.","4c478ffd":"Another Important metric for this problem is the Area Under Roc Curve, which can be seen following. Note that the model achieved a very good result, yieling a value greater than 0.93."}}