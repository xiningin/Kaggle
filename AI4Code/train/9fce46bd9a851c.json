{"cell_type":{"a8fce139":"code","88d3f88b":"code","7f40c5a5":"code","e6a7c20d":"code","f481687e":"code","2707b62c":"code","12d6b0f4":"code","607c6f56":"code","bbb8220a":"code","c1d6110f":"code","27bbb901":"code","2bade7be":"code","5fb521e0":"code","45a2f450":"code","7bce2270":"code","14d791cb":"code","8f628465":"code","78618e07":"code","abe3752b":"markdown","b39ad9bb":"markdown","b71c1ceb":"markdown","32c9d3a4":"markdown","c5d9e0b1":"markdown","d40d7513":"markdown","b8b4cb7c":"markdown","94a8ba57":"markdown","42b90f29":"markdown","cde0ee0f":"markdown","bc372119":"markdown","9c4fdf24":"markdown","80a6c4af":"markdown"},"source":{"a8fce139":"%matplotlib notebook\n\n# Linear Algebra\nimport numpy as np\n\n# Data Processing\nimport pandas as pd\n\n# Data Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Algorithms\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.metrics import mean_absolute_error, classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBRegressor\n\n# Stop unnecessary Seaborn warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nsns.set()  # Stylises graphs","88d3f88b":"wine_df = pd.read_csv('..\/input\/winequality-red.csv')","7f40c5a5":"wine_df.info()","e6a7c20d":"wine_df.head()","f481687e":"# Plotting quality of wine\n\nfig = plt.figure(figsize=(40, 8))\nsns.countplot(x='quality', data=wine_df)\nplt.title(\"Barplot of Quality of Wine\")\nplt.xlabel(\"Quality\")\nplt.ylabel(\"Count\")\nplt.show()","2707b62c":"# Heatmap of variables\n\nsns.set(style=\"white\")\n\n# Computer correlation matrix\ncorr = wine_df.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nfig, ax = plt.subplots(figsize=(20, 20))\n\n# Generate a custom diverging colourmap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(\n    corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n    square=True, linewidths=.5, cbar_kws={\"shrink\": .5}\n)\n\nax.set_title('Correlation Heatmap of the Variables of Wine')\n\nplt.show()","12d6b0f4":"fig = plt.figure(figsize = (20,8))\nsns.barplot(x='quality', y ='alcohol', data=wine_df)\nplt.title(\"Quality of Wine with Alcohol\")\nplt.ylabel(\"Alcohol (% of wine)\")\nplt.show()","607c6f56":"# Determining if there are any columns with missing data\n\ncols_with_missing = [col for col in wine_df.columns if wine_df[col].isnull().any()]\nprint(cols_with_missing)","bbb8220a":"# Get list of categorical variables\ns = (X_train.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)","c1d6110f":"# Assigning training and validation data\n\nX = wine_df.copy()\ny = X.quality\nX.drop(['quality'], axis=1, inplace=True)\n\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, random_state=0)","27bbb901":"scores = {}\n\nfor n_estimators in range(10, 510, 10):\n    RF_model = RandomForestClassifier(n_estimators=n_estimators, random_state=0)\n    RF_model.fit(X_train, y_train)\n    RF_predictions = RF_model.predict(X_valid)\n    RF_mae = mean_absolute_error(RF_predictions, y_valid)\n    scores[n_estimators] = RF_mae","2bade7be":"fig_RF, ax_RF = plt.subplots(figsize=(10, 4))\nax_RF.set_title(\"Mean Absolute Error with Number of Estimators of a Random Forest\")\nax_RF.set_xlabel(\"Number of Estimators\")\nax_RF.set_ylabel(\"Mean Absolute Error\")\nplt.plot(scores.keys(), scores.values())","5fb521e0":"best_n_estimators = 0\n\nfor n_estimators, score in scores.items():\n    if score == min(scores.values()):\n        best_n_estimators = n_estimators\n        print(f\"Best Number of Estimators: {n_estimators}\")","45a2f450":"RF_model = RandomForestClassifier(n_estimators=best_n_estimators, random_state=0)\nRF_model.fit(X_train, y_train)\nRF_predictions = RF_model.predict(X_valid)\nRF_mae = mean_absolute_error(RF_predictions, y_valid)\n\nprint(f\"Mean Absolute Error: {RF_mae}\")\nprint(classification_report(y_valid, RF_predictions))","7bce2270":"XGB_model = XGBRegressor(\n    n_estimators=200, learning_rate=0.02,\n    max_depth=10, min_child_weight=1,\n    gamma=0, subsample=0.8,\n    colsample_bytree=0.7,\n    random_state=0, nthread=4\n)\n\nXGB_model.fit(X_train, y_train, early_stopping_rounds=10, verbose=False, eval_set=[(X_valid, y_valid)])\nXGB_predictions = XGB_model.predict(X_valid)\nXGB_mae = mean_absolute_error(XGB_predictions, y_valid)\n\nprint(f\"Mean Absolute Error: {XGB_mae}\")","14d791cb":"base_XGB_model = XGBRegressor(\n    n_estimators=200, learning_rate=0.02,\n    max_depth=10, min_child_weight=1,\n    subsample=0.8, colsample_bytree=0.7,\n    random_state=0, nthread=4\n)\n\nparam_test = {\n 'gamma':[i\/10 for i in range(20)]\n}\n\ngrid_search = GridSearchCV(estimator=base_XGB_model, param_grid=param_test, n_jobs=1, iid=False, cv=5)\ngrid_search.fit(X_train, y_train)","8f628465":"grid_search.cv_results_, grid_search.best_params_, grid_search.best_score_","78618e07":"# Multiply by -1 since sklearn calculates *negative* MAE\nscores = -1 * cross_val_score(RF_model, X, y, cv=10, scoring='neg_mean_absolute_error')\nprint(f\"MAE Scores: {scores}\")\nprint(f\"Average MAE Score: {scores.mean()}\")","abe3752b":"#### Tuning Gamma","b39ad9bb":"There are no columns containing categorical data either.","b71c1ceb":"#### Fix Learning Parameters","32c9d3a4":"#### Cleaning and Prepping Data","c5d9e0b1":"### Applying Cross-Validation\nSince the dataset is smaller, we should use cross-validation ","d40d7513":"## Loading the Data","b8b4cb7c":"## Training a Model","94a8ba57":"#### Determining the Number of Estimators","42b90f29":"## Exploring the Dataset","cde0ee0f":"Looking at the graph above, it seems that there are some correlations that may be worth exploring. There may be a correlation between alcohol and quality... Coincidence, I think not.","bc372119":"### Modelling using XGBoost","9c4fdf24":"### Modelling with Random Forests","80a6c4af":"As we can see, there are no missing bits of data within the dataset - this makes life easiser!"}}