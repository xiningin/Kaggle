{"cell_type":{"52b1acc9":"code","64839a14":"code","ecbeebf7":"code","c6979d84":"code","5ca1f71e":"code","efccdfd3":"code","8dd64793":"code","e2ec73b8":"code","f4561d1b":"code","b7abcabc":"code","b19df31b":"code","c5403436":"markdown","08901d5c":"markdown","7b7bc515":"markdown","9881aafc":"markdown","895455df":"markdown","c10dcad0":"markdown"},"source":{"52b1acc9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","64839a14":"import tensorflow as tf\nfrom tensorflow import keras\n\nimport keras.backend as K\nfrom keras.layers import Input,Dense,Reshape,Flatten,Conv2D,Conv2DTranspose,UpSampling2D,\\\nBatchNormalization,Dropout,Activation,LeakyReLU\nfrom keras.models import Model\nfrom keras.utils import plot_model\nfrom keras.initializers import RandomNormal\nfrom keras.optimizers import Adam,RMSprop\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt","ecbeebf7":"(train_data,train_label),_ = keras.datasets.mnist.load_data()\n\ntrain_data,_,train_label,_ = train_test_split(train_data,train_label,test_size=0.8,shuffle=True)\n\nprint(f\"Train Data shape : {train_data.shape}\")\nprint(f\"Train Label shape : {train_label.shape}\")","c6979d84":"print(f\"Train image max pixel value : {np.max(train_data)}\")\nprint(f\"Train image min pixel value : {np.min(train_data)}\\n\")\n\n# train_data = train_data\/127.5 - 1 ## -1~1\ntrain_data = train_data\/255.0 # 0~1\n\nprint(\"========After Normalizing=======\")\nprint(f\"Train image max pixel value : {np.max(train_data)}\")\nprint(f\"Train image min pixel value : {np.min(train_data)}\")\n\ntrain_data = train_data.reshape(-1,28,28,1).astype(np.float32)\n\nprint(f\"Train Data shape : {train_data.shape}\")","5ca1f71e":"##show 36 samples\n\nrandom_idx = np.random.randint(0,train_data.shape[0],25)\nplt.figure(figsize=(10,10))\nfor i in range(len(random_idx)):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid('off')\n    plt.imshow(train_data[random_idx[i]],cmap='gray')\n    \nplt.tight_layout()\nplt.show()","efccdfd3":"initial_shape = (7,7,64)\n\nclass GAN():\n    def __init__(self,input_dim,D_conv_filters,D_conv_kernel_size,D_conv_strides,D_momentum,\\\n                D_dropout_rate,\\\n                z_dim,G_conv_filters,G_conv_kernel_size,G_conv_strides,G_momentum,\\\n                G_dropout_rate,D_lr=0.0002,G_lr=0.0002,batch_size=128):\n        \n        self.batch_size = batch_size\n        self.input_dim = input_dim\n        \n        self.D_conv_filters = D_conv_filters\n        self.D_conv_kernel_size = D_conv_kernel_size\n        self.D_conv_strides = D_conv_strides\n        self.D_momentum = D_momentum\n        self.D_dropout_rate = D_dropout_rate\n        self.D_lr = D_lr\n        \n        self.z_dim = z_dim\n        \n        self.G_conv_filters = G_conv_filters\n        self.G_conv_kernel_size = G_conv_kernel_size\n        self.G_conv_strides = G_conv_strides\n        self.G_momentum = G_momentum\n        self.G_dropout_rate = G_dropout_rate\n        self.G_lr = G_lr\n        \n        self.G_initial_image_shape = initial_shape\n        self.G_initial_dense_size = np.prod(self.G_initial_image_shape)\n        \n        self._build_D()\n        self._build_G()\n        self._build_Adversarial()\n     \n    ## Freeze or Unfreeze Discriminator ##\n    def _make_trainable(self,network,value):\n        network.trainable = value\n        for layer in network.layers:\n            layer.trainable = value\n        \n    #### Discriminator ####\n    def _build_D(self):\n        D_input = Input(shape=self.input_dim)\n        \n        D_H = D_input\n        for i in range(len(self.D_conv_filters)):\n            D_H = Conv2D(self.D_conv_filters[i],self.D_conv_kernel_size[i],self.D_conv_strides[i],\\\n                        padding='same')(D_H)\n            if i > 0:\n                D_H = BatchNormalization()(D_H)\n            D_H = LeakyReLU(0.2)(D_H)\n            D_H = Dropout(self.D_dropout_rate)(D_H)\n        D_H = Flatten()(D_H)\n        D_H = Dense(128)(D_H)\n        D_output = Dense(1,activation='sigmoid')(D_H)\n        \n        self.D = Model(D_input,D_output)\n    \n    #### Generator ####\n    def _build_G(self):\n        G_input = Input(shape=(self.z_dim,))\n        \n        G_H = Dense(1024)(G_input)\n        G_H = BatchNormalization(momentum=self.G_momentum)(G_H)\n        G_H = LeakyReLU(0.2)(G_H)\n        \n        G_H = Dense(self.G_initial_dense_size)(G_H)\n        G_H = BatchNormalization(momentum=self.G_momentum)(G_H)\n        G_H = LeakyReLU(0.2)(G_H)\n        G_H = Reshape(self.G_initial_image_shape)(G_H)\n        \n        for i in range(len(self.G_conv_filters)):\n            G_H = Conv2DTranspose(self.G_conv_filters[i],self.G_conv_kernel_size[i],self.G_conv_strides[i],padding='same')(G_H)\n            if i != len(self.G_conv_filters)-1:\n                G_H = BatchNormalization(momentum=self.G_momentum)(G_H)\n                G_H = LeakyReLU(0.2)(G_H)\n        G_output = Activation('sigmoid')(G_H)\n        ##G_output = Activation('tanh')(G_H)\n        \n        self.G = Model(G_input,G_output)\n        \n    def _build_Adversarial(self):\n        ## compile D, then freeze D\n        rmsprop1 = RMSprop(learning_rate=self.D_lr)\n        self.D.compile(loss='binary_crossentropy',optimizer=rmsprop1,metrics=['accuracy'])\n        self._make_trainable(self.D,False)\n        \n        adversarial_input = Input(shape=(self.z_dim,))\n        adversarial_output = self.D(self.G(adversarial_input))\n        self.adversarial = Model(adversarial_input,adversarial_output)\n        rmsprop2 = RMSprop(learning_rate=self.G_lr)\n        self.adversarial.compile(loss='binary_crossentropy',optimizer=rmsprop2,metrics=['accuracy'])\n        \n        ## after compiling adversarial model, unfreeze D\n        self._make_trainable(self.D,True)\n        \n    def train_D(self,train_data):\n        ones = tf.ones([self.batch_size,1],dtype=tf.int32)\n        zeros = tf.zeros([self.batch_size,1],dtype=tf.int32)\n        \n        idx = np.random.randint(0,train_data.shape[0],self.batch_size)\n        original_images = train_data[idx]\n        \n        noise = np.random.normal(0,1,(self.batch_size,self.z_dim))\n        generated_images = self.G.predict_on_batch(noise)\n        \n        D_loss_real,D_acc_real = self.D.train_on_batch(original_images,ones)\n        D_loss_fake,D_acc_fake = self.D.train_on_batch(generated_images,zeros)\n        \n        D_loss = 0.5*(D_loss_real+D_loss_fake)\n        D_acc = 0.5*(D_acc_real+D_acc_fake)\n        \n        return D_loss,D_acc\n        \n    def train_G(self):\n        \n        ones = np.ones((self.batch_size,1))\n        noise = np.random.normal(0,1,(self.batch_size,self.z_dim))\n        \n        G_loss,G_acc = self.adversarial.train_on_batch(noise,ones)\n        return G_loss,G_acc","8dd64793":"INPUT_DIM = (28,28,1)\nZ_DIM = 256\n\ngan = GAN(input_dim=INPUT_DIM,D_conv_filters=[16,32,64,128],D_conv_kernel_size=[5,5,5,5],D_conv_strides=[2,2,1,1],\\\n         D_lr=0.0004,D_momentum=None,D_dropout_rate=0.2,z_dim=Z_DIM,\\\n         G_conv_filters=[64,32,16,1],G_conv_kernel_size=[5,5,5,5],G_conv_strides=[2,2,1,1],\\\n         G_momentum=0.9,G_lr=0.0004,G_dropout_rate=None,batch_size=256)","e2ec73b8":"## Visualizing function\n\ndef show_generated_images():\n    plt.figure(figsize=(6,6))\n    random_noise = np.random.normal(0,1,(16,Z_DIM))\n    generated_images = gan.G.predict(random_noise)\n    for i in range(16):\n        plt.subplot(4,4,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(generated_images[i],cmap='gray')\n    plt.tight_layout()\n    plt.show()","f4561d1b":"epochs = 320\nsteps = int(len(train_data)\/gan.batch_size)\n\nfor i in range(epochs):\n    for j in range(steps):\n        ## train D ##\n        D_loss,D_acc = gan.train_D(train_data)\n        \n        ## train combined(adversarial) ##\n        G_loss,G_acc = gan.train_G()\n    print(\"Epoch %d : [D_LOSS : %.8f]  [G_LOSS : (%.8f)] \"%(i+1,D_loss,G_loss))\n    \n    if (i+1) in [5,10,20,40,60,100,160,280,420,510,590]:\n        print(f\"Epochs : {i+1}\")\n        show_generated_images()","b7abcabc":"noise = np.random.normal(0,1,(36,Z_DIM))\ngenerated = gan.G(noise)\n\nplt.figure(figsize=(10,10))\nfor i in range(len(noise)):\n    plt.subplot(6,6,i+1)\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(generated[i],cmap='gray')\n\nplt.tight_layout()\nplt.show()","b19df31b":"noise = np.random.normal(0,1,(16,Z_DIM))\ngenerated = gan.G.predict(noise)\n\nplt.figure(figsize=(8,8))\nfor i in range(len(noise)):\n    plt.subplot(4,4,i+1)\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(generated[i],cmap=plt.cm.binary)\n    \nplt.tight_layout()\nplt.show()","c5403436":"**Load MNIST data & train\/test split**","08901d5c":"**Train GAN (D->G->D->G...)**","7b7bc515":"**Scaling & Reshaping**","9881aafc":"**GAN modeling**","895455df":"**Set HyperParameters**","c10dcad0":"**Generate Images using trained GAN**"}}