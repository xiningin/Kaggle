{"cell_type":{"e91b6aff":"code","9c249023":"code","ff104b82":"code","f21f09e7":"code","e94162af":"code","89ad8c81":"code","f35e9db8":"code","29d9123e":"code","64fd1641":"code","0c2292c7":"code","ba1c9dff":"code","d7c6258a":"code","894385ff":"code","6c79ebcd":"code","a328dafc":"code","14d0dba5":"code","6e17de37":"code","24e86d0b":"code","e9162c18":"code","167dcb14":"code","4a05ae72":"code","59d8a0a9":"code","63bc7164":"code","7ccc7065":"code","1f1d6fc7":"code","99126287":"code","33169134":"code","476f14cf":"code","19e23c7a":"code","d0aaaf24":"code","b8a5496a":"code","5e84558b":"code","7b5f2701":"code","df9d8a1a":"code","c7ef79bc":"code","e1e75541":"code","44a5db29":"code","818e6408":"code","22b400a7":"code","8572cdef":"code","5beaa119":"code","7095ab10":"code","686a71be":"code","cb1fe807":"code","12d13fc2":"code","d351380e":"code","16d64858":"code","90eda079":"code","652ecae7":"markdown","357512fa":"markdown","227a371b":"markdown","23fb8ef2":"markdown","0218913e":"markdown","0c064c32":"markdown","68c472b0":"markdown","fb3d5f0b":"markdown","a3190be5":"markdown","e1ca474b":"markdown","55c97a95":"markdown","c6a31f04":"markdown","b78297eb":"markdown","7388b98e":"markdown","e23fe06b":"markdown","cf4a6324":"markdown","8edcb41d":"markdown","e4f0f454":"markdown","c7debad7":"markdown","35d282c6":"markdown","14b7da9b":"markdown","981a333e":"markdown","fa2e3795":"markdown","8bc0acac":"markdown","4c21a55b":"markdown","822b6e43":"markdown","37af6d01":"markdown","fa43d834":"markdown","6c502874":"markdown","feb88096":"markdown","909d90e1":"markdown","fe265bc7":"markdown","321b7a81":"markdown","a17f81bd":"markdown","d1cbedd4":"markdown","fa215afc":"markdown","16448b8a":"markdown","79b9cf9e":"markdown","32c7ddb3":"markdown","e83a6527":"markdown","ea148b2b":"markdown","0c02341e":"markdown","67ad08f5":"markdown","8d72ef40":"markdown","636b9cb7":"markdown"},"source":{"e91b6aff":"\nimport numpy as np\nimport pandas as pd \nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom collections import Counter\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n\nsample=pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/sample_submission.csv')\ntrain=pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/test.csv')","9c249023":"train.info()","ff104b82":"sexDataset=train.groupby('sex').size().reset_index(name='count')\n\nfig = go.Figure()\n\nfig= px.bar(sexDataset, x='sex', y='count',color='sex')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Distribution of the train dataset by sex',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","f21f09e7":"ageDataset=train.groupby('age_approx').size().reset_index(name='count')\n\nfig = go.Figure()\n\n\n\nfig= px.bar(ageDataset, x='age_approx', y='count',color='count')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Distribution of the train dataset by age',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","e94162af":"train['age_approx'].skew()#Skewness involves the symmetry of the distribution. \n#Skewness is 0 in a normal distribution, so the farther away from 0, the more non-normal the distribution","89ad8c81":"train['patient_id'].nunique()","f35e9db8":"patientsTrain = train.patient_id.value_counts()\n\nfig = go.Figure()\n# Use x instead of y argument for horizontal plot\nfig.add_trace(go.Box(x=patientsTrain,name=\"Images by patient in the train dataset\",marker_color='white'))\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","29d9123e":"anatomDataset=train.groupby('anatom_site_general_challenge').size().reset_index(name='count')\n\nfig= px.pie(anatomDataset, names='anatom_site_general_challenge', values='count',color='count')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Distribution of the train dataset by anatomic areas',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","64fd1641":"BMDataset=train.groupby('benign_malignant').size().reset_index(name='count')\n\nfig= px.pie(BMDataset, names='benign_malignant', values='count',color='count')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Distribution of the train dataset by benign or malignant',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","0c2292c7":"BMDiagnosisDataset=train.groupby(['benign_malignant','diagnosis']).size().reset_index(name='count')\n\nfig= px.bar(BMDiagnosisDataset, y='diagnosis', x='count',color='benign_malignant')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Benign and malignant by diagnosis',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","ba1c9dff":"BMSexDataset=train.groupby(['benign_malignant','sex']).size().reset_index(name='count')\n\nfig= px.bar(BMSexDataset, x='sex', y='count',color='benign_malignant')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Benign and malignant by sex',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","d7c6258a":"\nBMAnatomicDataset=train.groupby(['benign_malignant','anatom_site_general_challenge']).size().reset_index(name='count')\n\nfig= px.bar(BMAnatomicDataset, y='anatom_site_general_challenge', x='count',color='benign_malignant')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Benign and malignant by anatomic site',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","894385ff":"BMAgeDataset=train.groupby(['benign_malignant','age_approx','sex']).size().reset_index(name='count')\n\nfig= px.bar(BMAgeDataset, x='age_approx', y='count',color='benign_malignant',hover_data=['sex'])\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Benign and malignant by age',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","6c79ebcd":"\ntargetDataset=train.groupby(['benign_malignant','target','diagnosis']).size().reset_index(name='count')\n\nfig = go.Figure()\n\nfig = px.bar(targetDataset, y=\"count\", x=\"target\", color='benign_malignant',height=500)\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Benign and malignant by target',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","a328dafc":"fig = go.Figure()\n\nfig = px.bar(targetDataset, x=\"count\", y=\"diagnosis\", color='target',height=300)\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Diagnosis by target',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","14d0dba5":"imagesNameTrain = train.image_name.value_counts()\n\nfig = go.Figure()\n# Use x instead of y argument for horizontal plot\nfig.add_trace(go.Box(x=imagesNameTrain,name=\"Has each image an unique image_name?\",marker_color='white'))\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","6e17de37":"test.info()","24e86d0b":"testSexDataset=test.groupby('sex').size().reset_index(name='count')","e9162c18":"fig = go.Figure()\n\nfig = px.bar(testSexDataset,\n             x='sex',\n             y='count',\n             title='Distribution of the test dataset by sex',\n              color='sex',\n             barmode='stack')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\n    \n\nfig.show()","167dcb14":"testAgeDataset=test.groupby('age_approx').size().reset_index(name='count')\nfig = go.Figure()\n\nfig = px.bar(testAgeDataset,\n             x='age_approx',\n             y='count',\n             title='Distribution of the test dataset by age',\n              color='age_approx',\n             barmode='stack')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\n    \n\nfig.show()","4a05ae72":"test['age_approx'].skew() #Skewness involves the symmetry of the distribution. \n#Skewness is 0 in a normal distribution, so the farther away from 0, the more non-normal the distribution","59d8a0a9":"patientsTest = test.patient_id.value_counts()\nfig = go.Figure()\n# Use x instead of y argument for horizontal plot\nfig.add_trace(go.Box(x=patientsTest,name=\"Images by patient in the test dataset\",marker_color='white'))\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","63bc7164":"testAnatomDataset=test.groupby('anatom_site_general_challenge').size().reset_index(name='count')\n\n\n\nfig= px.bar(testAnatomDataset, y='anatom_site_general_challenge', x='count',color='count')\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Distribution of the test dataset by anatomic areas',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","7ccc7065":"imagesNameTrain = test.image_name.value_counts()\n\nfig = go.Figure()\n# Use x instead of y argument for horizontal plot\nfig.add_trace(go.Box(x=imagesNameTrain,name=\"Has each image an unique image_name?\",marker_color='white'))\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","1f1d6fc7":"pip install -U imbalanced-learn","99126287":"X=train.drop('target',axis=1)\ny=train['target']\nprint('Original dataset shape %s' % Counter(y))","33169134":"from imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(random_state=42)\nX_res, y_res = ros.fit_resample(X, y)\nprint('Resampled dataset shape %s' % Counter(y_res))","476f14cf":"#mix X_res and y_res into train dataset again\nX_res['target']=y_res\ntrain_resampled=X_res","19e23c7a":"targetDatasetResampled=train_resampled.groupby(['benign_malignant','target','diagnosis']).size().reset_index(name='count')\n\nfig = go.Figure()\n\nfig = px.bar(targetDatasetResampled, y=\"count\", x=\"target\", color='benign_malignant',height=500)\n\nfig.update_layout(\n   paper_bgcolor='rgb(0,0,0)',\n   plot_bgcolor='rgb(0,0,0)',\n    font_family=\"Helvetica\",\n    font_color=\"white\",\n    title_font_family=\"Helvetica\",\n    title_font_color=\"white\",\n    legend_title_font_color=\"white\",\n    title_text='Benign and malignant by target',\n    xaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    },\n    yaxis = { \n    'showgrid': False, \n    'zeroline': True, \n    'visible': True,\n    \n    }\n)\n    \n\nfig.show()","d0aaaf24":"import tensorflow as tf\nfrom keras.applications import MobileNet as model\nfrom keras.layers import Dense, GlobalAveragePooling2D,Activation,Flatten\nfrom keras.models import Model\n\nbase_model = model(weights='imagenet',include_top=False)\n\n\n\n\n\n","b8a5496a":"base_model.summary()","5e84558b":"#apply transfer learning to the model\n# add a global spatial average pooling layer\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(1024, activation='relu')(x) # #we add dense layers so that the model can learn more complex functions and classify for better results\nx=Dense(1024,activation='relu')(x) \nx=Dense(512,activation='relu')(x)\n# and a logistic layer -- \npredictions = Dense(2, activation='softmax')(x)","7b5f2701":"# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)","df9d8a1a":"# first: train only the top layers (which were randomly initialized)\n# i.e. freeze all convolutional layers\nfor layer in model.layers:\n    layer.trainable = False","c7ef79bc":"train_data=train_resampled\ntest_data=test\n\ntrain_data['image_name'] = train_data['image_name'].apply(lambda x: x + '.jpg')\ntest_data['image_name'] = test_data['image_name'].apply(lambda x: x + '.jpg')\n\nX2_train, X2_val = train_test_split(train_data, test_size=0.2, random_state=42)\n\n","e1e75541":"train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=360,rescale=1.\/255, horizontal_flip=True)","44a5db29":"\ntrain_generator=train_datagen.flow_from_dataframe(\n    dataframe=X2_train,\n    directory='..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/',\n    x_col=\"image_name\",\n    y_col=\"target\",\n    class_mode=\"raw\",\n    batch_size=8,\n    target_size=(224, 224),\n    color_mode=\"rgb\",\n    \n    \n    )\n\nvalidation_datagen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)\n\nvalid_generator=validation_datagen.flow_from_dataframe(\n    dataframe=X2_val,\n    directory='..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/',\n    x_col=\"image_name\",\n    y_col=\"target\",\n    class_mode=\"raw\", \n    batch_size=8,   \n    target_size=(224, 224),\n    color_mode=\"rgb\",\n    \n    )\n\ntest_datagen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)\n\ntest_generator=test_datagen.flow_from_dataframe(  \n        dataframe=test_data,\n        directory = '..\/input\/siim-isic-melanoma-classification\/jpeg\/test\/',\n        x_col=\"image_name\",\n        batch_size=1,\n        class_mode=None,\n        shuffle=False,\n        target_size=(224, 224),\n        )","818e6408":"model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n\nmodel.fit_generator(generator=train_generator,\n                                    steps_per_epoch=train_generator.n\/\/64,\n                                    validation_data=valid_generator,\n                                    validation_steps=valid_generator.n\/\/64,\n                                    epochs=10,\n                                    \n                       )","22b400a7":"import matplotlib.image as matimage\nimport cv2\n#predict a random image\npathImage=test_generator.filepaths[np.random.random_integers(low=0,high=test_generator.samples)]\nprint(pathImage)\nimg=matimage.imread(pathImage)\nplt.imshow(img)\n\nfrom PIL import Image\nimage=Image.open(pathImage)\nimage=image.convert('RGB')\nimage=image.resize((224,224))\nprobabilities=model.predict(np.expand_dims(image,axis=0))\nprint(probabilities[0][0])\n\n","8572cdef":"dataTestPathPredict='..\/input\/siim-isic-melanoma-classification\/jpeg\/test\/'\ndef make_predictions(image_name):\n    image=Image.open(str(dataTestPathPredict + image_name))\n    image=image.convert('RGB')\n    image=image.resize((224,224))\n    pre = model.predict(np.expand_dims(image,axis=0))\n    return pre[0][0]\n    \n    \n    ","5beaa119":"make_predictions('ISIC_4809071.jpg')","7095ab10":"test_data['model_prediction'] = test_data['image_name'].apply(make_predictions)","686a71be":"test_data.to_csv(\"saveData.csv\")","cb1fe807":"finalpred=test_data['model_prediction']","12d13fc2":"sample=pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/sample_submission.csv')","d351380e":"sample['target']=finalpred","16d64858":"sample.head()","90eda079":"sample.to_csv('FinalSubmission.csv',index=False)","652ecae7":"Yes, the images names are unique.","357512fa":"As you can saw in the EDA before, the train dataset is very unbalaced, so this can lead to overfitting problems. There are many ways to deal with imbalanced data. There are these amazing papers which gives you some ways to solution this problem. \n\n* https:\/\/machinelearningmastery.com\/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset\/\n* https:\/\/medium.com\/analytics-vidhya\/how-to-apply-data-augmentation-to-deal-with-unbalanced-datasets-in-20-lines-of-code-ada8521320c9\n* https:\/\/towardsdatascience.com\/deep-learning-unbalanced-training-data-solve-it-like-this-6c528e9efea6\n* https:\/\/towardsdatascience.com\/handling-imbalanced-datasets-in-deep-learning-f48407a0e758","227a371b":"Yes, the images names are unique. ","23fb8ef2":"* Melanomas in head\/neck: 74\n\n* Melanomas in lower extremity: 124\n\n* Melanomas in oral\/genital: 4\n\n* Melanomas in palms\/soles: 5\n\n* Melanomas in torso: 257\n\n* Melanomas in upper extremity: 111","0218913e":"The distribution is similar to the one of the train dataset. There are a lot of rows with 'No anatomic site known'.","0c064c32":"**A.1. Distribution of the train dataset by sex.**","68c472b0":"There are more older patients in the test dataset.","fb3d5f0b":"The only diagnosis with a value 'malignant' associated is melanoma. The rest of the diagnosis are 'benign'.","a3190be5":"There are more malignant cases between 45 and 80 years old. According to various sources of information (Cancer Research UK, American Cancer Society), melanoma is more common in men, but before age 50\/60 the rates are higher in women.","e1ca474b":"**B.2. Distribution of the test dataset by age.**","55c97a95":"**A.9.Check if a target 0 is always associated with a value 'benign' in the benign_malignant column, and with a value 'melanoma' in the diagnosis column.**","c6a31f04":"# **1-DATA ANALYSIS.**\n<div id=\"intAnalysis\"><\/div>","b78297eb":"In the dataset test there are more males than females, when in the dataset train the quantity of both sexs was similar.","7388b98e":"The most frequent anatomic areas are torso, lower extremity and upper extremity. ","e23fe06b":"I'm going to fix the umbalanced data by doing oversampling using the RandomOverSampler algorithm, by using imbalanced-learn library. For more information about this library, check the link: https:\/\/imbalanced-learn.readthedocs.io\/en\/stable\/index.html","cf4a6324":"There are NaN values in the column 'anatom_site_general_challenge'. ","8edcb41d":"**A.2.Distribution of the train dataset by age.**","e4f0f454":"**B.4.Most common areas where the images are made in the test dataset.**","c7debad7":"A target '0' is always associated with benign. A target '1' is always associated with malignant. The target is very imbalanced.","35d282c6":"In the dataset train there are 2056 patients. ","14b7da9b":"**B.5.Check if the column image_name has unique values for each row .**","981a333e":"# 3-BUILDING A CONVOLUTIONAL NEURAL NETWORK TO PREDICT THE IMAGES.","fa2e3795":"**A.4.Most common areas where the images are made in the train dataset.**","8bc0acac":"**B.3. Images by patient.**","4c21a55b":"# **2-PREPROCESSING THE DATA.**","822b6e43":"# **A-Train dataset**","37af6d01":"I will use MobileNet. It's not the most efficient convolutional neural network but I wanted to obtain the predictions the quickest possible. If you want to check all the Keras' convolutional neural networks and their efficient, check the link: https:\/\/keras.io\/api\/applications\/","fa43d834":"**A.10.Check if the column image_name has unique values for each row .**","6c502874":"This is the whole analysis of the train dataset. ","feb88096":"There are NaN values in the columns 'sex', 'age_approx', 'anatom_site_general_challenge'. We dont' need to handle this NaN values because we are going to classify the images using a convolutional neural network(hence, the only parameters we are going to need are image_name and target). That doesn't mean that we can't extract useful information from the rest of parameters, and we are going to do that in the next analysis. \n\nIf you wanted to do a classic machine learning model with sklearn you'll need to handle the NaN values. ","909d90e1":"**A.8.Distribution in the train dataset by benign and malignant and age.**","fe265bc7":"There are a lot more of benign tumors in the train dataset, it's very imbalanced.","321b7a81":"A diagnosis 'melanoma' is always associated with a target 1.","a17f81bd":"As you can see, the age is normally distributed. ","d1cbedd4":"The patient with the biggest number of images has 115 and the patient with the few number of images has 2. The median of images by patients is 12. The upper fence is 47. There are a few outliers. ","fa215afc":"**A.5.Are tumors mostly benign or malignant in the train dataset?**","16448b8a":"**A.8.Distribution in the dataset by benign and malignant and anatomic area.**","79b9cf9e":"**A.7.Distribution in the dataset by benign and malignant and sex.**","32c7ddb3":"**A.6.Distribution of the dataset by benign and malignant and diagnosis.**","e83a6527":"**B.1. Distribution of the test dataset by sex.**","ea148b2b":"# 4-MAKING THE PREDICTIONS.","0c02341e":"**A.3.Images by patient.**","67ad08f5":"# **B-Test Dataset.**","8d72ef40":"There are slightly more cases of malignant in persons with male sex. ","636b9cb7":"The patient with the biggest number of images has 240 and the patient with the few number of images has 3. The median of images by patients is 10. The upper fence is 43. There are less outliers here than in the train dataset, but there is a huge one: the patient with 240 images. "}}