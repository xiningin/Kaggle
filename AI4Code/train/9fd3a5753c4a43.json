{"cell_type":{"64d7194d":"code","30ae6808":"code","825c5035":"code","a27e56fd":"code","2a909ad7":"code","3b71a210":"code","07f0ec68":"code","6b73004b":"code","d2c6b5ac":"code","df931a00":"code","6cc37bde":"code","2ea6510d":"code","525528e5":"code","4063885c":"code","563b10a8":"code","95ddbb3f":"code","be7ac72f":"code","7a9f9dc8":"code","6895c7da":"code","11dca395":"code","d151ec10":"code","6efcd458":"code","a9144afd":"code","eb5ae359":"code","dbdfcadf":"code","f1753b51":"code","c4494d91":"code","d1723439":"code","56239239":"code","b76f7360":"code","02df43cb":"code","ce8903dc":"code","043a5a64":"code","463d6141":"code","5fe271ed":"code","dc55bec5":"code","df2b41f4":"code","be4069f7":"code","23c313ae":"code","970b6dda":"code","222a518a":"code","f006240b":"code","73f7e27b":"code","79a23f67":"code","52919fff":"code","d780d852":"code","4511a9be":"code","600c3c96":"code","7fab1239":"code","9b46cc8d":"code","58eaf38c":"code","02fa7dce":"code","76040dd2":"code","1a7ed1e9":"code","f7b3edf0":"code","868e3884":"code","8bc052f3":"code","cfd5d3df":"code","0f7e38dd":"code","b85bbd62":"code","e7292f6f":"code","ee3d3620":"code","e0972966":"code","0f7aa878":"code","96d15c7a":"code","5aaa704a":"code","0786029a":"code","efe135b9":"code","f9a21a40":"code","9ec77559":"code","d32eede1":"code","6c8b3bb9":"code","1a3379e7":"code","fb6c35b9":"code","f90c45e0":"code","f1f58d99":"code","1bcd6450":"code","556951ce":"code","15b83535":"markdown","7067598c":"markdown","64a58b72":"markdown","d6771dc0":"markdown","a3f545e7":"markdown","0364b343":"markdown","530cd73a":"markdown","c3e12df8":"markdown","59cb1b09":"markdown","4761a7c8":"markdown","6a0ed162":"markdown","a5e0ea98":"markdown","d8c94ade":"markdown","c2ecf984":"markdown","49dbf4b2":"markdown","e16e1f4f":"markdown","2f31393a":"markdown","49e628a2":"markdown","6b134c01":"markdown","9d0a0b4d":"markdown","f7c1cb42":"markdown","38d205ad":"markdown","59248018":"markdown","5086db27":"markdown","b8945545":"markdown","eb10ff8e":"markdown","ff1d24c5":"markdown"},"source":{"64d7194d":"import numpy as np \nimport pandas as pd \nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import Lasso, Ridge\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nimport matplotlib.gridspec as gridspec\nimport missingno as msno\nimport scipy.stats as stats \nfrom scipy.special import boxcox1p\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings(\"ignore\")","30ae6808":"house_train_data= pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')","825c5035":"# Printing the first five records of data\n\nhouse_train_data.head()","a27e56fd":"#Printing the last five records of data\n\nhouse_train_data.tail()","2a909ad7":"#printing the coloumns in data\n\nhouse_train_data.columns","3b71a210":"#printing the length of data\n\nprint('Length of house_train_data is:    ', len(house_train_data))","07f0ec68":"#Printing the shape of data\n\nhouse_train_data.shape","6b73004b":"#Printing the Dataframe information\n\nhouse_train_data.info()","d2c6b5ac":"#Printing the Data types of all coloumns\n\nhouse_train_data.dtypes","df931a00":"#Counting of missing values in each column\nNANColumns=[]\ni=-1\nfor a in house_train_data.isnull().sum():\n    i+=1\n    if a!=0:\n        print(house_train_data.columns[i],a)\n        NANColumns.append(house_train_data.columns[i])","6cc37bde":"#Is there any missing values?\nhouse_train_data.isnull().values.any()","2ea6510d":"#Counts of missing values in each column\n\nhouse_train_data.isnull().sum()","525528e5":"house_test_data= pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","4063885c":"#Printing the first five records of data\n\nhouse_test_data.head()","563b10a8":"#Prining the last five records of data\n\nhouse_test_data.tail()","95ddbb3f":"#Printing coloumns in data\n\nhouse_test_data.columns","be7ac72f":"#Printing the length of data\n\nprint('Length of house_test_data is:    ', len(house_test_data))","7a9f9dc8":"#Printing the shape of data\n\nhouse_test_data.shape","6895c7da":"#Printing the Dataframe information\n\nhouse_test_data.info()","11dca395":"#Printing the Data types of all coloumns\n\nhouse_test_data.dtypes","d151ec10":"#Counting of missing values in each column\nNANColumns=[]\ni=-1\nfor a in house_test_data.isnull().sum():\n    i+=1\n    if a!=0:\n        print(house_test_data.columns[i],a)\n        NANColumns.append(house_test_data.columns[i])","6efcd458":"#Is there any missing values?\n\nhouse_test_data.isnull().values.any()","a9144afd":"#Counts of missing values in each column\n\nhouse_test_data.isnull().sum()","eb5ae359":"#Hitogram of all columns with their counts\n\nhouse_train_data.hist(figsize=(80,80))\nplt.title(\"Features Distribution with values counts\")\nplt.show()","dbdfcadf":"temporal_features = [feat for feat in house_train_data if \"Year\" in feat or \"Yr\" in feat]\nprint(temporal_features)\nfor feature in temporal_features:\n    sns.scatterplot(x=feature,y=\"SalePrice\",data=house_train_data)\n    plt.title(feature)\n    plt.show()","f1753b51":"#sns.scatterplot(x='GarageYrBlt',y=\"SalePrice\",data=house_train_data)\n#plt.title('GarageYrBlt vs SalePrice')\n#plt.show()","c4494d91":"#sns.scatterplot(x='YrSold',y=\"SalePrice\",data=house_train_data)\n#plt.title('YrSold vs SalePrice')\n#plt.show()","d1723439":"#sns.scatterplot(x='YearBuilt',y=\"SalePrice\",data=house_train_data)\n#plt.title('YearBuilt vs SalePrice')\n#plt.show()","56239239":"#sns.scatterplot(x='YearRemodAdd',y=\"SalePrice\",data=house_train_data)\n#plt.title('YearRemodAdd vs SalePrice')\n#plt.show()","b76f7360":"categorical_features = [feature for feature in house_train_data if house_train_data[feature].nunique() < 22 and feature not in temporal_features]\ncontinuous_features = [feature for feature in house_train_data if feature not in categorical_features and feature not in temporal_features]\n\nprint(\"categorical_features:\\n\",categorical_features)\nprint(\"Continuous_Features:\\n\",continuous_features)","02df43cb":"#Scatter plot of each categorical_Features against Sale price on discrete features\ndef scatterplot(house_train_data,feature,target_feature):\n    plt.figure()\n    sns.scatterplot(house_train_data[feature],house_train_data[target_feature])\n    plt.title(feature)\n    plt.show()\nfor feat in categorical_features:\n    scatterplot(house_train_data,feat,\"SalePrice\")\n","ce8903dc":"#Scatter plot of each Continuous_Features against Sale price on discrete features\ndef scatterplot(train_data,feature,target_feature):\n    plt.figure()\n    sns.scatterplot(train_data[feature],train_data[target_feature])\n    plt.title(feature)\n    plt.show()\n\n    \nfor feat in continuous_features:\n    scatterplot(house_train_data,feat,\"SalePrice\")","043a5a64":"#Looking at the most correlated features with SalePrice\n\ncorr = house_train_data.corr().nlargest(10,\"SalePrice\")[\"SalePrice\"].index\ncmap = np.corrcoef(house_train_data[corr].values.T)\nmask = np.zeros_like(cmap,dtype=bool)\nmask[np.triu_indices_from(mask)] = True\nplt.figure(figsize=(20,10))\nsns.heatmap(cmap,\n            annot=True,\n            fmt=\".3f\",\n            annot_kws = {\"size\":10},\n            cmap=sns.cubehelix_palette(),\n            xticklabels = corr.values,\n            yticklabels = corr.values,\n            mask=mask)","463d6141":"# Extract the SalePrice\n\ny = house_train_data[\"SalePrice\"]","5fe271ed":"# Combining the train and test dataframes\n\ndata_concat = pd.concat([house_train_data,house_test_data],axis=0).reset_index(drop=True)","dc55bec5":"#Function to check missing values\n\ndef missing_value(df):\n    number = df.isnull().sum().sort_values(ascending=False)\n    number = number[number > 0]\n    percentage = df.isnull().sum() *100 \/ df.shape[0]\n    percentage = percentage[percentage > 0].sort_values(ascending=False)\n    return  pd.concat([number,percentage],keys=[\"Total\",\"Percentage\"],axis=1)\nmissing_value(data_concat)\n","df2b41f4":"missing_col = [\"Alley\", \"PoolQC\", \"MiscFeature\",\"Fence\",\n               \"FireplaceQu\",\"GarageType\",\"GarageFinish\",\n               \"GarageQual\",\"GarageCond\",'BsmtQual','BsmtCond',\n               'BsmtExposure','BsmtFinType1','BsmtFinType2',\n               'MasVnrType']\n\nfor col in missing_col:\n    data_concat[col] = data_concat[col].fillna(\"None\") ","be4069f7":"#LotFrontage, Houses in the same neighborhood would have similar lotfrontage area. \n## filling the numerical features with median and mdeidan is the best suited method for numerical based features\ndata_concat[\"LotFrontage\"] = data_concat.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x:x.fillna(x.median()))","23c313ae":"#MasVnrArea, Same apply to the MasVnrArea\n## filling the numerical features with median and mdeidan is the best suited method for numerical based features\ndata_concat[\"MasVnrArea\"] = data_concat.groupby(\"Neighborhood\")[\"MasVnrArea\"].transform(lambda x:x.fillna(x.median()))","970b6dda":"## MSSubClass\n## Imputing the missing values with the Mode because mode fill the values with the most accuring values and best for the categorical features\ndata_concat[\"MSZoning\"] = data_concat.groupby(\"MSSubClass\")[\"MSZoning\"].transform(lambda x: x.fillna(x.mode()[0]))","222a518a":"## GarageYrBlt\ndata_concat.loc[data_concat[\"GarageFinish\"] == \"None\" , \"GarageYrBlt\"] = data_concat[\"YearBuilt\"]","f006240b":"## Check on the missing value\nmissing_value(data_concat)","73f7e27b":"### for the rest of the missing value\n## categorical feature are replaced with the mode value\n## continuous features are replaced with the median value\nmissing_feat = missing_value(data_concat).index","79a23f67":"## getting categorical feature\n\nmissing_cat = [feat for feat in missing_feat if data_concat[feat].dtype == np.object]","52919fff":"## filling the categorical features with mode and mode is the best suited method for categorical based features\nfor feat in missing_cat:\n    data_concat[feat] = data_concat[feat].transform(lambda x: x.fillna(x.mode()[0]))\n\n## numerical feature\nmissing_num = [feat for feat in missing_feat if feat not in missing_cat]","d780d852":"## filling the numerical features with median and mdeidan is the best suited method for numerical based features\nfor feat in missing_num:\n    data_concat[feat] = data_concat[feat].transform(lambda x: x.fillna(x.median()))  \n### Check on the missing value\nmissing_value(data_concat)","4511a9be":"### Months and years should be consider as categorical features\n\ndata_concat[\"MoSold\"] = data_concat[\"MoSold\"].astype(str)\ndata_concat[\"YrSold\"] = data_concat[\"YrSold\"].astype(str)\ndata_concat[\"YearBuilt\"] = data_concat[\"YearBuilt\"].astype(str)","600c3c96":"## Visualisation\nfig = plt.figure(constrained_layout=True, figsize=(12,8))\ngrid = gridspec.GridSpec(ncols=3, nrows=4, figure=fig)\n # Histrogram\nax1 = fig.add_subplot(grid[0,:])\nsns.distplot(y,ax=ax1)\nax1.set_title(\"Histrogram of SalePrice\")\n# QQplot\nax2 = fig.add_subplot(grid[2:,:2])\nstats.probplot(y,plot=ax2)\nax2.set_title(\"QQplot of SalePrice\")\n # Boxplot\nax3 = fig.add_subplot(grid[2:,2])\nsns.boxplot(y,ax=ax3,orient=\"v\")\nax3.set_title(\"Boxplot of SalePrice\")\nplt.show()","7fab1239":"##Check on the kurtosis & the skewness of SalePrice\nprint(\"Kurtosis: {}\".format(y.kurt()))\nprint(\"Skewness: {}\".format(y.skew()))","9b46cc8d":"## Normalise the Dependant Variable(SalePrice)\ny = np.log1p(y)\n\n## Visualise of SalePrice after the normalisation\nfig,(ax1,ax2, ax3) = plt.subplots(3,1,constrained_layout=True,figsize=(12,9))\n\n # Histrogram\nsns.distplot(y,ax=ax1)\nax1.set_title(\"Histrogram of SalePrice\")\n\n# QQplot\nstats.probplot(y,plot=ax2)\nax2.set_title(\"QQplot of SalePrice\")\n\n # Boxplot\nsns.boxplot(y,ax=ax3,orient=\"v\")\nax3.set_title(\"Boxplot of SalePrice\")\n\nplt.show()","58eaf38c":"## Kurtosis and skewness of SalePrice\nprint(\"Kurtosis: {}\".format(y.kurt()))\nprint(\"Skewness: {}\".format(y.skew()))","02fa7dce":"## Check on the skewness and the kurtosis on continuos data only\ncontinuous_feats = [feat for feat in data_concat.columns if data_concat[feat].dtype != np.object]\nskewness = data_concat[continuous_feats].skew().sort_values(ascending=False)\nkurtosis = data_concat[continuous_feats].kurt().sort_values(ascending=False)\n\ndata_concat_norm = pd.concat([skewness,kurtosis],axis=1,keys=[\"Skewness\",\"Kurtosis\"])\n\ndata_concat_norm","76040dd2":"### Features with skewness greater than 1 or lower than -1 are considered highly skewed\nhigh_skew = skewness[abs(skewness) > 1].sort_values(ascending=False)\n\n## Visualisation of TotalBsmtSF\nplt.figure(figsize=(8,6))\nsns.distplot(data_concat[\"TotalBsmtSF\"])\nplt.show()","1a7ed1e9":"## Look at its kurtosis and skewness value\nprint(\"Kurtosis: {}\".format(data_concat[\"TotalBsmtSF\"].kurt()))\nprint(\"Skewness: {}\".format(data_concat[\"TotalBsmtSF\"].skew()))","f7b3edf0":"## import packages\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\n\n## Normalisation of independant variables\nfor feat in high_skew.index:\n    data_concat[feat] = boxcox1p(data_concat[feat], boxcox_normmax(data_concat[feat] + 1))\n## Visualisation of TotalBsmtSF after normalisation\nplt.figure(figsize=(8,6))\nsns.distplot(data_concat[\"TotalBsmtSF\"])\nplt.show()","868e3884":"## Look at its kurtosis and skewness value after the normalisation\nprint(\"Kurtosis: {}\".format(data_concat[\"TotalBsmtSF\"].kurt()))\nprint(\"Skewness: {}\".format(data_concat[\"TotalBsmtSF\"].skew()))","8bc052f3":"## TotalHouseSF: The total Square Foot of the house\ndata_concat[\"TotalHouseSF\"] = data_concat[\"TotalBsmtSF\"] + data_concat[\"1stFlrSF\"] + data_concat[\"2ndFlrSF\"]","cfd5d3df":"## TotalBath: The total number of bathrooms in the house\n## TotalBath: The total number of bathrooms in the house\ndata_concat[\"TotalBath\"] = data_concat[\"BsmtFullBath\"] + data_concat[\"BsmtFullBath\"]*0.5 + data_concat[\"FullBath\"] + data_concat[\"HalfBath\"]*0.5","0f7e38dd":"## TotalPorchSF: The total square foot of porch area of the house\ndata_concat[\"TotalPorchSF\"] = data_concat[\"WoodDeckSF\"] + data_concat[\"OpenPorchSF\"] + data_concat[\"EnclosedPorch\"] +data_concat[\"3SsnPorch\"] + data_concat[\"ScreenPorch\"]","b85bbd62":"## HouseRemodAge: Number of years the house being remodded to the time it was sold\ndata_concat[\"HouseRemodAge\"] = data_concat[\"YrSold\"].astype(int) - data_concat[\"YearRemodAdd\"]\ndata_concat.loc[data_concat[\"HouseRemodAge\"] < 0, \"HouseRemodAge\"] = 0 ","e7292f6f":"## function \npresence = lambda x: 1 if x > 0 else 0\n","ee3d3620":"## HasPool: Presence of pool\ndata_concat[\"HasPool\"] = data_concat[\"PoolArea\"].transform(presence)","e0972966":"## Has2ndFlr: Presence of second floor\ndata_concat[\"Has2ndFlr\"] = data_concat[\"2ndFlrSF\"].transform(presence)","0f7aa878":"## HasGarage: Presence of garage\ndata_concat[\"HasGarage\"] = data_concat[\"GarageArea\"].transform(presence)","96d15c7a":"## HasBsmt: Presence of basement\ndata_concat[\"HasBsmt\"] = data_concat[\"TotalBsmtSF\"].transform(presence)","5aaa704a":"## HasFirePlace: Presence of fireplace\ndata_concat[\"HasFirePlace\"] = data_concat[\"Fireplaces\"].transform(presence)\n","0786029a":"data_concat.describe()","efe135b9":"## Bias feature reducer\nbias_feat = []\nfor feat in data_concat.columns:\n    counts = data_concat[feat].value_counts().iloc[0] ## mode value counts\n    if counts \/ len(data_concat) * 100 > 99.94:\n        bias_feat.append(feat)\n\nbias_feat","f9a21a40":"## Remove the bias feature from the dataset\ndata_concat = data_concat.drop(bias_feat,axis=1)","9ec77559":"data_concat = pd.get_dummies(data_concat).reset_index(drop=True)","d32eede1":"n = len(y)\nhouse_train_data = data_concat[:n]\nhouse_test_data = data_concat[n:]","6c8b3bb9":"X_train, X_test, y_train, y_test =  train_test_split(house_train_data,y,test_size=0.2,random_state=0)\nprint(\"Shapes of data: \", X_train.shape, X_test.shape, y_train.shape, y_test.shape)","1a3379e7":"from sklearn.ensemble import ExtraTreesClassifier\n\n## Create an empty list\npipeline_models = []\n\n# Assign all models into the list\nmodels = [Ridge(),\n          Lasso(),\n          RandomForestRegressor(),\n          ExtraTreesRegressor(),\n          GradientBoostingRegressor(),\n          DecisionTreeRegressor(),\n          KNeighborsRegressor(),\n          ExtraTreesClassifier()\n         \n]\n\nmodel_names = [\"Ridge\",\"Lasso\",\"RFR\",\"ETR\",\"GBoost_Reg\",\"DT_Reg\",\"KNN_Reg\", \"ETC\"]\n\n## Assign each model to a pipeline\nfor name, model in zip(model_names,models):\n    pipeline = (\"Scaled_\"+ name,\n                Pipeline([(\"Scaler\",StandardScaler()),\n                          (name,model)\n                         ]))\n    pipeline_models.append(pipeline)","fb6c35b9":"## Create a dataframe to store all the models' cross validation score\nevaluate = pd.DataFrame(columns=[\"model\",\"cv\",\"std\"])\n\n\n## Encoded dataset\nfor name,model in pipeline_models:\n    kfold = KFold(n_splits=5,shuffle=True,random_state=0)\n    cv = cross_val_score(model, X_train, y_train, cv=kfold, n_jobs=-1, scoring=\"r2\")\n    \n    row = evaluate.shape[0]\n    evaluate.loc[row,\"model\"] = name\n    evaluate.loc[row,\"cv\"] = round(cv.mean(),3)\n    evaluate.loc[row,\"std\"] = \"+\/- {}\".format(round(cv.std(),4))\n    \n    evaluate = evaluate.sort_values(\"cv\",ascending=False)","f90c45e0":"## Visualisation\nfig, ax = plt.subplots(1,1,sharey=False,figsize=(16,9))\n\n## Encoded dataset\nbar = sns.barplot(evaluate[\"model\"], evaluate[\"cv\"],ax=ax,palette = sns.cubehelix_palette(evaluate.shape[0]))\nfor rec in bar.patches:\n    height = rec.get_height()\n    ax.text(rec.get_x() + rec.get_width()\/2, height*1.02,height,ha=\"center\")\nax.set_title(\"Cross Validate Score\")\nax.set_xticklabels(evaluate[\"model\"].to_list(),rotation =50)","f1f58d99":"final_model = GradientBoostingRegressor()\nfinal_model = final_model.fit(X_train,y_train)","1bcd6450":"#submission_results = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\nsubmission_results = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\nsubmission_results.iloc[:,1] = np.floor(np.expm1(final_model.predict(house_test_data)))\nsubmission_results.to_csv('submission_results.csv', index=False)\n","556951ce":"submission_results.head()","15b83535":"#     ","7067598c":"# Now the data is normalised well !!","64a58b72":"# Now the data are normalised :)","d6771dc0":"# Exploring data analysis of train dataframe","a3f545e7":"# Exploring data analysis of test dataframe","0364b343":"# Splitting the Train data into 80% for training and 20% for testing","530cd73a":"## Checking the Missing values","c3e12df8":"# From the insights at the figures, we will use the following *categorical_features:*\n\n# OverallQual, OverallCond, FullBath, TotRmsAbvGrd and GarageCars,  have stong correlation with SalePrice","59cb1b09":"# Importing Python Libraries","4761a7c8":"# Loading dataframes","6a0ed162":"# my insights:\n\n* The SalePrice is right skewed, which indicates that most people are able to afford lower priced house.\n* Easily can notice outliers in SalePrice","a5e0ea98":"<div class=\"alert alert-block alert-success\">  \n<h1><center><strong> Submitting the Regression on test data<\/strong><\/center><\/h1>\n        \n<\/div>","d8c94ade":"# Best Model is Gradient Boosting Regressor","c2ecf984":"# Plotting Hitogram of all columns to check how the values are distributed","49dbf4b2":"# Coverting the categorical features into continous form by applying the get_dummies function","e16e1f4f":"#                                     Data Processing","2f31393a":"# Adding new features from the existing featrures to make the model more distinguished for Sale_price predictions !!","49e628a2":"# From the insights at the figures, we will use the following continuous_features:\n\n# YearBuit, TotalBsmtSF, 1stFlrSF, GrLivArea and GarageArea have stong correlation with SalePrice","6b134c01":"# Deleting the Biased Features","9d0a0b4d":"# Normalising the of Dependant Variable SalePrice","f7c1cb42":"# Droping the SalePrice and Id columns\n\ndata_concat = data_concat.drop(['SalePrice','Id'],axis=1)","38d205ad":"[![General Assembly Logo](https:\/\/camo.githubusercontent.com\/1a91b05b8f4d44b5bbfb83abac2b0996d8e26c92\/687474703a2f2f692e696d6775722e636f6d2f6b6538555354712e706e67)](https:\/\/generalassemb.ly\/education\/web-development-immersive)\n![Misk Logo](https:\/\/i.ibb.co\/KmXhJbm\/Webp-net-resizeimage-1.png)\n\n\n# House prising regression\n**By. Ibrahim Alzahrani**","59248018":"# Looking at the top most correlated features with SalePrice","5086db27":"# plotting columns which represent YEAR","b8945545":"# As indicated in the three charts above, SalePrice is postively-skewed. \n\nSkewness: Defined as the degree of distortion from the symmetrical bell curve or the normal curve.\nKurtosis: Defined as the measuer of the extreme values (also known as outliers) present in the distribution.","eb10ff8e":"# Building the models for training and testing","ff1d24c5":"# Its better now\nNow let's check on the kurtosis and skewness value of SalePrice"}}