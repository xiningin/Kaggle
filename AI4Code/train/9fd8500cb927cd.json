{"cell_type":{"63a7df26":"code","6246463b":"code","64d83bb4":"code","b3dc388a":"code","cb77cfba":"code","4365c959":"code","674bd071":"code","0a6f1ee8":"code","470d498e":"code","95e18211":"code","e65369d8":"code","0b178f61":"code","d38a421e":"code","b3b01e44":"code","0478b472":"code","2a586740":"code","b6f850b0":"code","de3beaf8":"code","85150874":"code","117acb5c":"code","1d612684":"code","6d28e09b":"code","3e6d060f":"code","1533bfe8":"code","735e3651":"code","436da394":"code","ac7c0fbc":"code","64482a6c":"code","71ac30ff":"code","5681b731":"code","3b7b9132":"code","0b529d46":"code","dc1a1c5b":"code","bb1a7336":"code","6d06fe9b":"code","52b03536":"code","cad87038":"code","c2712189":"code","d372badd":"code","27f27353":"code","a2c45b41":"code","e1d846fd":"code","acf03251":"code","e8103e4f":"code","00972d31":"code","f6859e69":"code","3e09ab74":"code","b918871e":"code","7619a7a1":"code","b26ef19c":"code","fdf17779":"code","77d39c20":"code","234d3212":"code","75775218":"code","1cebd057":"markdown","1f0c418c":"markdown","2451736a":"markdown","c3089c98":"markdown","d46f5aea":"markdown","3624251d":"markdown","f1a22b01":"markdown","b407f895":"markdown","5877d087":"markdown","c2a5f478":"markdown","ac1d05f5":"markdown","73c4fb07":"markdown","834965dd":"markdown","9b04202c":"markdown","8ac570e2":"markdown"},"source":{"63a7df26":"# processamento de dados, algebra linear\nimport numpy as np \nimport pandas as pd\n\n# visualiza\u00e7\u00e3o de dados\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# impime os arquivos\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n# carrega o arquivo e exibe 3 amostras\ndf = pd.read_csv('..\/input\/diamonds\/diamonds.csv')\ndf.head(20)\n\n","6246463b":"# exibe as 5 primeiras linhas\ndf.head(5)","64d83bb4":"# Trocando as vari\u00e1veis de texto por num\u00e9ricas\ndf['color'] = df['color'].replace(['J','I','H','G','F','E','D'],[1,2,3,4,5,6,7])\ndf['cut'] = df['cut'].replace(['Fair','Good','Very Good','Premium','Ideal'],[1,2,3,4,5])\ndf['clarity'] = df['clarity'].replace(['I3','I2','I1','SI2','SI1','VS2','VS1','VVS2','VVS1','IF'],[1,2,3,4,5,6,7,8,9,10])","b3dc388a":"# exibe as 5 primeiras linhas dados alfabeticos trocados por n\u00fameros\ndf.head(5)","cb77cfba":"df.info()","4365c959":"# Removendo a coluna Unnamed:0 - Pois aparentemente \u00e9 um contador\ndfn = df.drop(['Unnamed: 0'], axis = 1)\ndfn.head(5)\n","674bd071":"# Exibindo a descri\u00e7\u00e3o da base de dados\ndfn.describe()","0a6f1ee8":"# Verificando a correla\u00e7\u00e3o entre os dados\ncorrelacoes = dfn.corr()\nplt.figure(figsize=(11,8))\nsns.heatmap(correlacoes, annot=True, fmt='.2f', cmap='coolwarm')\nplt.show()","470d498e":"dfn.hist(figsize=(10,8))\nplt.tight_layout()\nplt.show()","95e18211":"plt.figure(figsize=(15,5))\nsns.scatterplot(data=dfn, x=\"carat\", y=\"price\")\nplt.show()","e65369d8":"plt.figure(figsize=(16,8))\nsns.scatterplot(data=dfn, x=\"carat\", y=\"price\", hue=\"color\",size=\"cut\", style=\"clarity\", sizes=(10,250))\nplt.show()","0b178f61":"##sns.set_theme(style=\"ticks\")\nsns.pairplot(data=dfn)\n##plot.show()","d38a421e":"#Verificando cut vs price\nsns.catplot(x=\"cut\", y=\"price\", kind=\"box\", data=df);\n","b3b01e44":"#Verificando color vs price\nsns.catplot(x=\"color\", y=\"price\", kind=\"box\", data=dfn);","0478b472":"#Verificando clarity vs price\nsns.catplot(x=\"clarity\", y=\"price\", kind=\"box\", data=dfn);","2a586740":"#Verificando carat vs price e clarity\nplt.figure(figsize=(15,6))\nsns.lineplot(x=\"carat\", y=\"price\", hue=\"clarity\", palette='coolwarm', data=dfn);\n","b6f850b0":"#Verificando carat vs price \/ clarity  e color \nplt.figure(figsize=(15,6))\nsns.lineplot(x=\"carat\", y=\"price\", hue=\"clarity\", style=\"color\", palette='coolwarm', data=dfn);\n","de3beaf8":"# m\u00e9tricas\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n# vari\u00e1vel de resultado final\n# ser\u00e1 armazenado o resultado de todos experimentos\nexperiment = {}\n# treinamento, test split\nfrom sklearn.model_selection import train_test_split\n","85150874":"# recupera os valores (X), e as classes (Y)\nX = dfn.drop('price', axis=1)\nY = dfn['price']\n","117acb5c":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=6)","1d612684":"print('treinamento:', len(y_train))\nprint('teste      :', len(y_test))","6d28e09b":"# regressor\nfrom sklearn.neighbors import KNeighborsRegressor","3e6d060f":"# model1 \u00e9 o modelo criado pelo regressor KNN\nmodel1 = KNeighborsRegressor(n_neighbors=3,metric='euclidean')\nmodel1.fit(X_train,y_train)\n","1533bfe8":"# ypred \u00e9 o modelo predito\ny_pred = model1.predict(X_test)\n","735e3651":"# Calculando as metricas para o KNN\n# R Square Error\nr2 = r2_score(y_test,y_pred)\n\n# Mean Absolute Error (MAE)\nmae = mean_absolute_error(y_test,y_pred)\n\n# Mean Square Error (MSE)\nmse = mean_squared_error(y_test,y_pred, squared=True)\n\n# Root Mean Square Error (RMSE)\nrmse = mean_squared_error(y_test,y_pred, squared=False)","436da394":"# Imprimindo as metricas e armazenando no vetor experimet\nexperiment['KNN'] = {'R2':r2, 'MAE':mae, 'MSE':mse, 'RMSE':rmse}\n\nprint('R2  :',r2)\nprint('MAE :',mae)\nprint('MSE :',mse)\nprint('RMSE:',rmse)","ac7c0fbc":"# regressor\nfrom sklearn.ensemble import RandomForestRegressor","64482a6c":"# model5 \u00e9 o modelo criado pela Random Forrest\nmodel5 = RandomForestRegressor(n_estimators=10, random_state=26)\nmodel5.fit(X_train, y_train)","71ac30ff":"# Y_pred \u00e9 o modelo predito pelo model5 random forrest\ny_pred = model5.predict(X_test)","5681b731":"# calculo das metricas para o Random Forrest\nr2 = r2_score(y_test,y_pred)\nmae = mean_absolute_error(y_test,y_pred)\nmse = mean_squared_error(y_test,y_pred, squared=True)\nrmse = mean_squared_error(y_test,y_pred, squared=False)","3b7b9132":"# imprimindo as metricas para o Random Forrest e atualizando o vetor experiment\nexperiment['Random Forest'] = {'R2':r2, 'MAE':mae, 'MSE':mse, 'RMSE':rmse}\n\nprint('R2  :',r2)\nprint('MAE :',mae)\nprint('MSE :',mse)\nprint('RMSE:',rmse)","0b529d46":"# imprimindo o resumo dos experimentos\npd.DataFrame(experiment).T","dc1a1c5b":"# escolhendo o primeiro diamante do conjunto de teste\nX_test.head(1)","bb1a7336":"# a resposta do conjunto de teste do primeiro diamante\ny_test.head(1)","6d06fe9b":"## inserindo estes dados no modelo do KNN como um novo diamante\ndata2 = [{\"carat\": 0.53, \"cut\": 3, \"color\": 7, \"clarity\": 5, \"depth\": 61.2, \n          \"table\": 54.0, \"x\": 5.23, \"y\": 5.26, \"z\": 3.21}]\ndfu = pd.DataFrame(data2)\ny_predu = model1.predict(dfu)\nprint(y_predu)\n\n","52b03536":"## inserindo estes dados no modelo do Random Forrest como um novo diamante\ndata2 = [{\"carat\": 0.53, \"cut\": 3, \"color\": 7, \"clarity\": 5, \"depth\": 61.2, \n          \"table\": 54.0, \"x\": 5.23, \"y\": 5.26, \"z\": 3.21}]\ndfu = pd.DataFrame(data2)\ny_predu = model5.predict(dfu)\nprint(y_predu)","cad87038":"# regressor\nfrom sklearn.linear_model import LinearRegression","c2712189":"model2 = LinearRegression()\nmodel2.fit(X_train, y_train)","d372badd":"y_pred = model2.predict(X_test)","27f27353":"r2 = r2_score(y_test,y_pred)\nmae = mean_absolute_error(y_test,y_pred)\nmse = mean_squared_error(y_test,y_pred, squared=True)\nrmse = mean_squared_error(y_test,y_pred, squared=False)","a2c45b41":"experiment['Linear Regression'] = {'R2':r2, 'MAE':mae, 'MSE':mse, 'RMSE':rmse}\n\nprint('R2  :',r2)\nprint('MAE :',mae)\nprint('MSE :',mse)\nprint('RMSE:',rmse)","e1d846fd":"# regressor\nfrom sklearn.svm import SVR\n","acf03251":"model3 = SVR()\nmodel3.fit(X_train, y_train)","e8103e4f":"y_pred = model3.predict(X_test)","00972d31":"r2 = r2_score(y_test,y_pred)\nmae = mean_absolute_error(y_test,y_pred)\nmse = mean_squared_error(y_test,y_pred, squared=True)\nrmse = mean_squared_error(y_test,y_pred, squared=False)","f6859e69":"experiment['SVM'] = {'R2':r2, 'MAE':mae, 'MSE':mse, 'RMSE':rmse}\n\nprint('R2  :',r2)\nprint('MAE :',mae)\nprint('MSE :',mse)\nprint('RMSE:',rmse)","3e09ab74":"# regressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn import tree","b918871e":"model4 = DecisionTreeRegressor(random_state=26)\nmodel4.fit(X_train, y_train)","7619a7a1":"y_pred = model4.predict(X_test)","b26ef19c":"r2 = r2_score(y_test,y_pred)\nmae = mean_absolute_error(y_test,y_pred)\nmse = mean_squared_error(y_test,y_pred, squared=True)\nrmse = mean_squared_error(y_test,y_pred, squared=False)","fdf17779":"experiment['Decision Tree'] = {'R2':r2, 'MAE':mae, 'MSE':mse, 'RMSE':rmse}\n\nprint('R2  :',r2)\nprint('MAE :',mae)\nprint('MSE :',mse)\nprint('RMSE:',rmse)","77d39c20":"text_representation = tree.export_text(model4)\nprint(text_representation)","234d3212":"##fig = plt.figure(figsize=(25,20))\n##_ = tree.plot_tree(model4,filled=True)","75775218":"# imprimindo o resumo dos experimentos\npd.DataFrame(experiment).T","1cebd057":"## Separando os conjuntos X e Y de treino e teste","1f0c418c":"## Regress\u00e3o KNN","2451736a":"# Support Vector Machines (SVM)","c3089c98":"## Regress\u00e3o Random Forest","d46f5aea":"# \u00c1rvore de Decis\u00e3o","3624251d":"# Regrass\u00e3o Linear","f1a22b01":"Procurando por valores nulos e verificando os tipos de dados da base de dados.","b407f895":"Nota-se uma alta correla\u00e7\u00e3o entre o carat e as vari\u00e1veis x,y e z, mas faz sentido pois o carat \u00e9 o \"peso\" do diamante ent\u00e3o justifica.\n\nNota-se uma correla\u00e7\u00e3o forte entre o carat e o pre\u00e7o, que tamb\u00e9m faz sentido.\n\nInvestigando melhor a rela\u00e7\u00e3o entre carat, price e cut,\tcolor, clarity que n\u00e3o aparecem na correla\u00e7\u00e3o\t","5877d087":"De fato o modelo do Random Forrest foi o que mais se aproximou da resposta do conjunto de teste.","c2a5f478":"## Simulando a entrada de dados novos nos modelos de regress\u00e3o","ac1d05f5":"## Separando a coluna \"price\" que ser\u00e1 inferida pelo sistema","73c4fb07":"Importando Bibliotecas\nImpotando o arquivo diamonds.csv","834965dd":"Verificando a correla\u00e7\u00e3o entre os dados","9b04202c":"## Carregando as Metricas","8ac570e2":"## Outras simula\u00e7\u00f5es que n\u00e3o foram para o relat\u00f3rio."}}