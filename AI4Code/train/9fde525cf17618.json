{"cell_type":{"f08d632c":"code","00eea889":"code","a6d6fe92":"code","bef3a277":"code","43309df9":"code","2771c3b5":"code","c4095e91":"code","8852d395":"code","b12119d0":"code","0081dd9d":"code","cca25db8":"code","68702aa8":"code","83d04752":"code","7d4acf91":"code","b6a66f3f":"code","5a5c5617":"code","7330e43a":"code","f16d4de5":"code","d42e751a":"code","5140c775":"code","0f42eb5a":"code","321405f8":"code","894a5a86":"code","efb5c608":"code","d158a5c3":"code","bdbb7733":"code","fca01f0a":"code","d52dbf6b":"code","5d283a34":"code","682b4893":"code","7e12316c":"code","0853d41c":"code","edf82dc0":"code","a9eba872":"code","45046985":"code","98feedbf":"code","352123c3":"code","6569ac18":"code","318885cd":"code","094520da":"code","b91a4750":"code","f12d0807":"code","0bb29da9":"code","e2544712":"code","ddad1c0c":"code","aea2ce20":"code","564b547a":"code","657df885":"code","cac62872":"code","76925f56":"code","d5722f69":"code","cafe9c33":"code","e921f367":"code","a4b04c6e":"code","c708c1e1":"code","eb25ec04":"code","36177c51":"code","4359647b":"markdown","761736b3":"markdown","26e795a8":"markdown","f5bed46a":"markdown","3fe5c286":"markdown","daec91fa":"markdown","0f8cf9bf":"markdown","db60937a":"markdown","f593b2a7":"markdown","fc121e9e":"markdown","7c535e03":"markdown","459b51eb":"markdown","54e8c07e":"markdown"},"source":{"f08d632c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","00eea889":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport category_encoders as ce\nfrom sklearn.preprocessing import OrdinalEncoder, StandardScaler, MinMaxScaler","a6d6fe92":"train_df = pd.read_csv('..\/input\/medical-treatment-dataset\/trainms.csv')\ntest_df = pd.read_csv('..\/input\/medical-treatment-dataset\/testms.csv')\ntarget = pd.read_csv('..\/input\/medical-treatment-dataset\/samplems.csv')\ntrain_df.head(3)","bef3a277":"#dataframe.drop(['<columns\/rows>'], axis = 0\/1, inplace = False\/true)\ntarget.drop(['s.no'], axis = 1, inplace = True)\ntest_df = pd.concat([test_df, target], axis = 1)","43309df9":"test_df.head()","2771c3b5":"print(\"Train data dim : \", train_df.shape, \"\\nTest data dim : \", test_df.shape)","c4095e91":"df = pd.concat([train_df, test_df], sort = True)\ndf.reset_index(drop=True, inplace = True)\ndf","8852d395":"df.drop( 's.no', inplace = True, axis = 1)\ndf.head(3)","b12119d0":"#finding Missing data\n#dataframe.isnull()\nnull_df = df.isnull()\nnull_df.head()","0081dd9d":"for col in null_df.columns:\n    print(null_df[col].value_counts())\n    print(\"_______________________\")","cca25db8":"df.drop(columns = ['Timestamp', 'state'], inplace = True)\ndf.head()","68702aa8":"df['self_employed'].value_counts()","83d04752":"#since 'No' is most common in train_df['self_employed'], we replace NaN with 'No'. \ndf['self_employed'].fillna('No', inplace = True)\ntrain_df.head()","7d4acf91":"df['work_interfere'].value_counts()","b6a66f3f":"df['work_interfere'].fillna('Sometimes', inplace = True)\ndf['work_interfere'].value_counts()","5a5c5617":"def clean_data(result):\n\n    #Gender value cleaning\n    #Male\n    #dataframe.loc[dataframe['<column>'] == '<value>', '<column>'] = <value>\n    result.loc[result['Gender'] == 'M','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'male','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'Mail','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'Mal','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'msle','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'm','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'maile','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'mal','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'Male-ish','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'ostensibly male, unsure what that really means','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'Cis Man','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'something kinda male?','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'make','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'Make','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'cis Man','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'Cis Male','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'cis Male','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'cis male','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'Man','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'man','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'Malr','Gender'] = 'Male'\n    result.loc[result['Gender'] == 'Male ','Gender'] = 'Male'\n\n\n\n\n    #Female\n    result.loc[result['Gender'] == 'F','Gender'] = 'Female'\n    result.loc[result['Gender'] == 'female','Gender'] = 'Female'\n    result.loc[result['Gender'] == 'f','Gender'] = 'Female'\n    result.loc[result['Gender'] == 'Cis Female','Gender'] = 'Female'\n    result.loc[result['Gender'] == 'Femake','Gender'] = 'Female'\n    result.loc[result['Gender'] == 'cis-female\/femme','Gender'] = 'Female'\n    result.loc[result['Gender'] == 'Female (cis)','Gender'] = 'Female'\n    result.loc[result['Gender'] == 'cis female','Gender'] = 'Female'\n    result.loc[result['Gender'] == 'Woman','Gender'] = 'Female'\n    result.loc[result['Gender'] == 'woman','Gender'] = 'Female'\n    result.loc[result['Gender'] == 'femail','Gender'] = 'Female'\n    result.loc[result['Gender'] == 'Female ','Gender'] = 'Female'\n    \n    \n    #Transgender\n    result.loc[result['Gender'] == 'Trans woman','Gender'] = 'Other'\n    result.loc[result['Gender'] == 'Female (trans)','Gender'] = 'Other'\n    result.loc[result['Gender'] == 'Female (trans)','Gender'] = 'Other'\n    result.loc[result['Gender'] == 'Trans-female','Gender'] = 'Other'\n    result.loc[result['Gender'] == 'non-binary','Gender'] = 'Other'\n    result.loc[result['Gender'] == 'Nah','Gender'] = 'Other'\n    result.loc[result['Gender'] == 'Enby','Gender'] = 'Other'\n    result.loc[result['Gender'] == 'fluid','Gender'] = 'Other'\n    result.loc[result['Gender'] == 'Genderqueer','Gender'] = 'Other'\n    result.loc[result['Gender'] == 'Androgyne','Gender'] = 'Other'\n    result.loc[result['Gender'] == 'Agender','Gender'] = 'Other'\n    result.loc[result['Gender'] == 'Guy (-ish) ^_^','Gender'] = 'Other'\n    result.loc[result['Gender'] == 'male leaning androgynous','Gender'] = 'Other'\n    result.loc[result['Gender'] == 'Neuter','Gender'] = 'Other'\n    result.loc[result['Gender'] == 'queer','Gender'] = 'Other'\n    result.loc[result['Gender'] == 'A little about you','Gender'] = 'Other'\n    result.loc[result['Gender'] == 'p','Gender'] = 'Other'","7330e43a":"clean_data(df)\ndf['Gender'].value_counts()","f16d4de5":"sns.boxplot(y = df['Age'])","d42e751a":"df['Age'].describe()","5140c775":"outlierIndex = []\noutlierIndex.append(df.loc[df['Age'] == -1726.000000 ].index.values[0])\noutlierIndex.append(df.loc[df['Age'] == 329.000000 ].index.values[0])","0f42eb5a":"df.drop(outlierIndex, inplace = True)","321405f8":"sns.boxplot(y = df['Age'])","894a5a86":"df['Age'].quantile([.01, .98])","efb5c608":"outlierIndex = []\nfor idx in df.loc[df['Age'] < 18 ].index.values:\n    outlierIndex.append(idx)\nfor idx in df.loc[df['Age'] > 50 ].index.values:\n    outlierIndex.append(idx)\n    \nprint(outlierIndex)","d158a5c3":"df.drop(outlierIndex, inplace = True)\ndf.shape","bdbb7733":"sns.boxplot(y = df['Age'])","fca01f0a":"data = df","d52dbf6b":"y = data['treatment']\ny = pd.DataFrame(y)\ndata.drop(['treatment'], axis = 1, inplace = True)\ndata.head()","5d283a34":"#Encoding target variable\ny.loc[y['treatment'] == 'Yes','treatment'] = 1\ny.loc[y['treatment'] == 'No','treatment'] = 0\ny.head()","682b4893":"data['Country'].unique().shape","7e12316c":"#Target encoding on features ['Country', 'Gender']\nce_df = ce.TargetEncoder(cols = ['Country'])\ndata = ce_df.fit_transform(data, y['treatment'])\ndata.head()","0853d41c":"features = ['self_employed', 'family_history', 'remote_work', 'tech_company', 'obs_consequence']\ndata[features]\n\ndef encodeYesNo(feature):\n    data.loc[data[feature] == 'Yes', feature] = 1\n    data.loc[data[feature] == 'No', feature ] = 0\n    \nfor feature in features:\n    encodeYesNo(feature)\n    \ndata[features].head()","edf82dc0":"data.head()","a9eba872":"ordinal_features = ['Gender', 'work_interfere', 'benefits', 'care_options', 'wellness_program', 'seek_help', 'anonymity', 'leave', 'mental_health_consequence', 'phys_health_consequence', 'coworkers', 'supervisor', 'mental_health_interview', 'phys_health_interview', 'mental_vs_physical']\nce_ord = ce.TargetEncoder(cols = ordinal_features)\ndata = ce_ord.fit_transform(data, y['treatment'])\ndata.head()","45046985":"data['no_employees'].value_counts()","98feedbf":"data.loc[data['no_employees'] == 'More than 1000', 'no_employees'] = '1000-10000'\ndata.head()","352123c3":"lower = []\nupper = []\nfor val in data['no_employees']:\n    values = val.split('-')\n    lower.append(int(values[0]))\n    upper.append(int(values[1]))\n    \n    \ndata['no_employees_lower'] = lower\ndata['no_employees_upper'] = upper\ndata[['no_employees', 'no_employees_lower', 'no_employees_upper']].head()","6569ac18":"data.drop('no_employees', axis = 1, inplace = True)\ndata.head()","318885cd":"data.drop(['comments'], axis = 1, inplace = True)","094520da":"data.head()","b91a4750":"scaled_df = data\n\nminmax_scaler = StandardScaler()\nscaled = minmax_scaler.fit_transform(data[['Age','no_employees_lower', 'no_employees_upper']]) \n\n\nscaled_df['scaled_age'] = scaled[:,0]\nscaled_df['scaled_no_employees_lower'] = scaled[:,1]\nscaled_df['scaled_no_employees_upper'] = scaled[:,2]\nscaled_df.drop(['Age', 'no_employees_lower', 'no_employees_upper'], axis = 1, inplace = True)\nscaled_df.head()","f12d0807":"plt.title(\"Data distribution before scalling\")\nplt.xlim(-6, 6)\n\nfor col in ['scaled_age', 'scaled_no_employees_lower', 'scaled_no_employees_upper']:\n    sns.kdeplot(data[col],)\n\nplt.legend(bbox_to_anchor=(2.2, 1), ncol=2)","0bb29da9":"X = scaled_df\nprint(X.shape, \"\\n\\n\", y.shape)","e2544712":"proccessed_data = scaled_df\nproccessed_data['treatment'] = y['treatment'].values","ddad1c0c":"corr = proccessed_data.corr(method = 'pearson')['treatment']\ncorr","aea2ce20":"plt.figure(figsize=(30, 20))\nsns.heatmap(proccessed_data.corr(method = 'pearson'), annot = proccessed_data.corr(), square = True)","564b547a":"from sklearn.ensemble import ExtraTreesClassifier","657df885":"extraTree = ExtraTreesClassifier()\nextraTree.fit(X, y)\nprint(extraTree.feature_importances_) #use inbuilt class feature_importances of tree based classifiers","cac62872":"#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(extraTree.feature_importances_, index=X.columns)\nfeat_importances.nlargest(15).plot(kind='barh')\nplt.title(\"Top 15 important features\")\nplt.show()","76925f56":"const = np.ones(y.shape)\nX.insert(loc = 0, column = 'x0', value = const)","d5722f69":"imp_features = ['x0']\nfor feature in feat_importances.nlargest(15).keys():\n    if feature != 'treatment':\n        imp_features.append(feature)\n        \nX[imp_features]","cafe9c33":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, f1_score","e921f367":"x_train, x_test, y_train, y_test = train_test_split( X[imp_features], y, test_size=0.2, random_state=42)\nprint(\"x_train : \", x_train.shape)\nprint(\"y_train : \", y_train.shape)\nprint(\"x_test : \", x_test.shape)\nprint(\"y_test : \", y_test.shape)","a4b04c6e":"model = LogisticRegression()\nmodel.fit(x_train, y_train)\nmodel.score(x_train, y_train)","c708c1e1":"yhat = model.predict(x_test)\nyhat","eb25ec04":"confusion_mtx = confusion_matrix(y_test, yhat)\nprint(confusion_mtx)","36177c51":"print(\"Test Accuracy = \", f1_score(y_test, yhat))","4359647b":"# Outlier Detection and Removing","761736b3":"### 5. Scaling numerical Variables\n\n* scaling numerical variables using min-max scaler function","26e795a8":"**From the above list, it is clear that the feature 'state' contain more null values that cannot even filled, since some countries are almost null. So we can drop the column state**","f5bed46a":"# DATA PREPROCCESING","3fe5c286":"### 2. Encoding Categorical variables with Yes\/No values\n\n* The best method to encode categorical variables with values Yes\/No is replacing them with 1\/0\n    * Yes - 1\n    * No - 0","daec91fa":"### 4.Encoding Interval type categorical values.\n\n* one of the good approch for interval type values are split them into lower and upper values.","0f8cf9bf":"# Feature Selection","db60937a":"# Model Development","f593b2a7":"### Logistic regression","fc121e9e":"# Categorical Data Encoding","7c535e03":"### Encoding Categories with a few unique values.\n* Here most of the categorical features are nominal","459b51eb":"### 1. Finding and encoding High Cardinality Features.\n\n* High Cardinality means that, features with lots of unique values","54e8c07e":"* Both features are high cardinality features(k<10k). Hence we cannot apply one-hot encoding since sparse matrix affect the performance of our model.\n\n* The best two options are,\n    * Binary Encoding \n    * Feature Hashing\n    * Target Encoding\n    \n* Binary encoding is most suitable for Ordinal data. Here 'Country' and 'Gender are nominal data. But its worth trying it too.\n\n* Hash encoding may results in Collision, but effect of collision is much less on model prediction.\n\n* Here I continue with target encoding, which I feel more suitable after trying other encodings \n\n[Referance - Categorical encoding ](https:\/\/blog.myyellowroad.com\/using-categorical-data-in-machine-learning-with-python-from-dummy-variables-to-deep-category-66041f734512)\n\n[Reference - Hash Ticking](https:\/\/booking.ai\/dont-be-tricked-by-the-hashing-trick-192a6aae3087)"}}