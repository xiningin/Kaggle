{"cell_type":{"1c316545":"code","ab1bf259":"code","d2b33e61":"code","ab238d9b":"code","73a6ec26":"code","1e5c1574":"code","7974b833":"code","bba5d339":"code","f1cdbc21":"code","b2c617f0":"code","9027bd21":"code","f1ea35a7":"code","1a1bc639":"code","56b73188":"code","41248c7a":"markdown","412d2c7a":"markdown","f63a775f":"markdown","65853dcb":"markdown","6f85dbb1":"markdown","ca7e38bb":"markdown","001919aa":"markdown","c133fa6c":"markdown","15f939a5":"markdown","4f8af9c7":"markdown","9c58a590":"markdown"},"source":{"1c316545":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","ab1bf259":"df = pd.read_csv('..\/input\/new-york-city-airbnb-open-data\/AB_NYC_2019.csv')\ndf.head()","d2b33e61":"\"\"\"\nLook at the price variable. Does it have a long tail?\n\"\"\"\nfig, axes = plt.subplots(1, 2)\n      \naxes[0].hist(df['price'], density= True, bins = 50)\naxes[0].set_title(\"Normal scale Price\")\n\naxes[1].hist(np.log1p(df['price']), density= True, bins = 50)\naxes[1].set_title(\"Logarithmic scale Price\")","ab238d9b":"features  = ['latitude',\n'longitude',\n'price',\n'minimum_nights',\n'number_of_reviews',\n'reviews_per_month',\n'calculated_host_listings_count',\n'availability_365']\n\ndf[features]","73a6ec26":"\"\"\"Checking description of this project's data set\"\"\"\ndf[features].describe()","1e5c1574":"missing_vals = df[features].isnull().sum()\nmissing_vals.to_frame().reset_index().rename({'index': 'Variables', 0: 'Missing Values'}, axis = 1).sort_values(by = 'Missing Values', ascending = False).head(2)","7974b833":"print(\"Median for variable 'minimum_nights': %s\" %(np.median(df[features]['minimum_nights'])))","bba5d339":"def train_test_split(df,test_split = 0.2, val_split = 0.2, random_seed = 42):\n    \"\"\"Shuffling\"\"\"\n    n = len(df)                                                         # Total number of IDs to be generated\n    idx = np.arange(n)                                                  # Generating IDs\n    np.random.seed = random_seed                                        # Setting random Seed to 42\n    np.random.shuffle(idx)                                              # Initial Dataset Ids Shuffled\n\n    \"\"\"Split your data in train\/val\/test sets, with 60%\/20%\/20% distribution.\"\"\"\n    n = len(df)\n    n_val = int(n * val_split)                                           # Number of validation values\n    n_test = int(n * test_split)                                         # Number of Test Set values\n    n_train = n - n_val - n_test                                         # Number of Train set Values\n\n    df_train = df.iloc[idx[:n_train]]                                    # Creating Train set    \n    df_val = df.iloc[idx[n_train:n_train + n_val]]                       # Creating Validation Set\n    df_test = df.iloc[idx[n_train+n_val:]]                               # Creating Test Set\n\n    \"\"\"Dropping indexes now\"\"\"\n    df_train = df_train.reset_index(drop = True)\n    df_val = df_val.reset_index(drop = True)\n    df_test = df_test.reset_index(drop = True)\n\n    \"\"\"Apply the log transformation to the price variable using the np.log1p() function.\"\"\"\n    y_train = np.log1p(df_train['price'].values)\n    y_val = np.log1p(df_val['price'].values)\n    y_test = np.log1p(df_test['price'].values)\n\n    \"\"\"Make sure that the target value ('price') is not in your dataframe.\"\"\"\n    del df_train['price']\n    del df_val['price']\n    del df_test['price']\n    \n    return df_train, df_val, df_test, y_train, y_val, y_test\n\ndf_train, df_val, df_test, y_train, y_val, y_test= train_test_split(df[features])","f1cdbc21":"\"\"\"Imputing Missing values with 0\"\"\"\ndef train_X_imputing_0(df):\n    df = df.fillna(0)\n    X = df.values\n    return X\n\n\"\"\"Imputing Missing values with Mean\"\"\"\ndef train_X_imputing_mean(df):\n    df = df.fillna(0)\n    X = df.values\n    return X","b2c617f0":"\"\"\"Creating a function for Training Linear Regression Model\"\"\"\ndef train_linear_regression_reg(X,y,r = 0.01):\n    \"\"\"\n    Including a biased term\n    \"\"\"\n    ones = np.ones(X.shape[0])\n    X = np.column_stack([ones, X])\n    \n    \"\"\"\n    Gram Matrix\n    \"\"\"\n    XTX = X.T.dot(X)\n    \n    \"\"\"Regularization\"\"\"\n    XTX = XTX + r * np.eye(XTX.shape[0])\n    \n    \n    \"\"\"inverse of Gram Matrix\"\"\"\n    XTX_inv = np.linalg.inv(XTX)\n    w_full = XTX_inv.dot(X.T).dot(y)\n    \n    return w_full[0], w_full[1:] \n\ndef rmse(y, y_pred):\n    error = y - y_pred\n    squared = error ** 2\n    mean_squared = squared.mean()\n    return np.sqrt(mean_squared)","9027bd21":"\"\"\"Model and Prediction with missing value imputation using 0\"\"\"\nX_train = train_X_imputing_0(df_train)\n\nw0,w = train_linear_regression_reg(X_train,y_train,r = 0)\n\n# Predicting on Validation set\ny_pred_train = w0 + X_train.dot(w)\n\n# Predicting on Validation set\nX_val = train_X_imputing_0(df_val)\ny_pred_val = w0 + X_val.dot(w)\n\n# rmse\nprint(\"RMSE_train with 0: %s\" %rmse(y_train, y_pred_train).round(2))\nprint(\"RMSE_valid with 0: %s\" %rmse(y_val, y_pred_val).round(2))\n\n\n\"\"\"Model and Prediction with missing value imputation using mean\"\"\"\nX_train = train_X_imputing_mean(df_train)\n\nw0,w = train_linear_regression_reg(X_train,y_train, r = 0)\n# Predicting on Training set\ny_pred_train = w0 + X_train.dot(w)\n\n# Predicting on Validation set\nX_val = train_X_imputing_mean(df_val)\ny_pred_val = w0 + X_val.dot(w)\n\n# rmse\nprint(\"RMSE_train with mean: %s\" %rmse(y_train, y_pred_train).round(2))\nprint(\"RMSE_valid with mean: %s\" %rmse(y_val, y_pred_val).round(2))","f1ea35a7":"for r in [0.0, 0.000001, 0.0001, 0.001, 0.01, 0.1, 1]:\n    w0,w = train_linear_regression_reg(X_train,y_train,r)\n    \n    \n    # Predicting on Validation set\n    X_val = train_X_imputing_0(df_val)\n    y_pred = w0 + X_val.dot(w)\n    score =  (rmse(y_val, y_pred))\n    # rmse\n    print(\"r: %s, w0: %s, score: %s\" %(r, w0, score))","1a1bc639":"score = []\nfor s in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]:\n    df_train, df_val, df_test, y_train, y_val, y_test= train_test_split(df[features], random_seed = s)\n    \n    \"\"\"Model and Prediction with missing value imputation using 0\"\"\"\n    X_train = train_X_imputing_0(df_train)\n\n    w0,w = train_linear_regression_reg(X_train,y_train,r=0)\n\n    # Predicting on Validation set\n    X_val = train_X_imputing_0(df_val)\n    y_pred = w0 + X_val.dot(w)\n    \n#     RMSE Scores\n    score.append(rmse(y_val, y_pred).round(2))\n    print(\"seed: %s, w0: %s, score: %s\" %(s, w0, score[s]))\nprint(\"Standard Deviation of Scores: %s\" %np.std(score).round(3))","56b73188":"df_train, df_val, df_test, y_train, y_val, y_test= train_test_split(df[features], random_seed = 9)\n\n\n\"\"\"Combining Train and Validation set\"\"\"\ndf_train_full = pd.concat([df_train, df_val])\ndf_train_full = df_train_full.reset_index(drop = True)\n\n\n\n\"\"\"Model and Prediction with missing value imputation using 0\"\"\"\nX_train_full = train_X_imputing_0(df_train_full)\ny_full_train = np.concatenate([y_train, y_val])\n\n\nw0,w = train_linear_regression_reg(X_train,y_train, r = 0.001)\n\n# Predicting on Validation set\nX_test = train_X_imputing_0(df_test)\ny_pred = w0 + X_test.dot(w)\n\n#     RMSE Scores\nscore =rmse(y_test, y_pred)\nprint(\"seed: %s, w0: %s, score: %s\" %(s, w0, score))","41248c7a":"## Features used for this Project","412d2c7a":"## Look at the price variable. Does it have a long tail?","f63a775f":"# This Week 2 Questions\nNotebook is a part of FREE ML course by Glexey Grigorev. [List Of The Questions](https:\/\/github.com\/alexeygrigorev\/mlbookcamp-code\/blob\/master\/course-zoomcamp\/02-regression\/homework.md)","65853dcb":"# Q6.\n        - Split the dataset like previously, use seed 9.\n        - Combine train and validation datasets.\n        - Fill the missing values with 0 and train a model with r=0.001.\n        - What's the RMSE on the test dataset?","6f85dbb1":"# Q2. What's the median (50% percentile) for variable 'minimum_nights'?\n        Split the data\n        - Shuffle the initial dataset, use seed 42.\n        - Split your data in train\/val\/test sets, with 60%\/20%\/20% distribution.\n        - Make sure that the target value ('price') is not in your dataframe.\n        - Apply the log transformation to the price variable using the np.log1p() function.","ca7e38bb":"## Loading and Reading Data ","001919aa":"# Q5.\n        - We used seed 42 for splitting the data. Let's find out how selecting the seed influences our score.\n        - Try different seed values: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9].\n        - For each seed, do the train\/validation\/test split with 60%\/20%\/20% distribution.\n        - Fill the missing values with 0 and train a model without regularization.\n        - For each seed, evaluate the model on the validation dataset and collect the RMSE scores.\n        - What's the standard deviation of all the scores? To compute the standard deviation, use np.std.\n        - Round the result to 3 decimal digits (round(std, 3))\nNote: Standard deviation shows how different the values are. If it's low, then all values are approximately the same. If it's high, the values are different. If standard deviation of scores is low, then our model is stable.","c133fa6c":"# Q3. \n        - We need to deal with missing values for the column from Q1.\n        - We have two options: fill it with 0 or with the mean of this variable.\n        - Try both options. For each, train a linear regression model without regularization using the code from the lessons.\n        - For computing the mean, use the training only!\n        - Use the validation dataset to evaluate the models and compare the RMSE of each option.\n        - Round the RMSE scores to 2 decimal digits using round(score, 2)\n        - Which option gives better RMSE?","15f939a5":"# Q1. Find a feature with missing values. How many missing values does it have?","4f8af9c7":"# Q4. \n        - Now let's train a regularized linear regression.\n        - For this question, fill the NAs with 0.\n        - Try different values of r from this list: [0, 0.000001, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10].\n        - Use RMSE to evaluate the model on the validation dataset.\n        - Round the RMSE scores to 2 decimal digits.\n        - Which r gives the best RMSE?\n        - If there are multiple options, select the smallest r.","9c58a590":"## Importing Libraries"}}