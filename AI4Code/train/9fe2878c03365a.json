{"cell_type":{"0b4f2d65":"code","9e0c72e4":"code","7f0a974c":"code","78e5fdca":"code","cecace7b":"code","43e7fcd6":"code","735b369b":"code","e31c0360":"code","f21a13cd":"code","27530ff6":"code","179e3cf3":"code","dc6106e1":"markdown","0d93185d":"markdown","0a3b0390":"markdown"},"source":{"0b4f2d65":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport bq_helper # It has functions for putting BigQuery results in Pandas DataFrames\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","9e0c72e4":"# create a helper object for our bigquery dataset\nhacker_news = bq_helper.BigQueryHelper(active_project= \"bigquery-public-data\", \n                                       dataset_name = \"hacker_news\")","7f0a974c":"# print a list of all the tables in the hacker_news dataset\nhacker_news.list_tables()","78e5fdca":"# print information on all the columns in the \"full\" table\n# in the hacker_news dataset\nhacker_news.table_schema(\"full\")","cecace7b":"hacker_news.head('full')","43e7fcd6":"# preview the first ten entries in the by column of the full table\nhacker_news.head(\"full\", selected_columns=\"by\", num_rows=10)","735b369b":"# preview the first ten entries in the by column of the full table\nhacker_news.head(\"full\", selected_columns=['by', 'text'], num_rows=10)","e31c0360":"# this query looks in the full table in the hacker_news\n# dataset, then gets the score column from every row where \n# the type column has \"job\" in it.\nquery = \"\"\"SELECT score\n            FROM `bigquery-public-data.hacker_news.full`\n            WHERE type = \"job\" \"\"\"\n\n# check how big this query will be\nhacker_news.estimate_query_size(query)","f21a13cd":"hacker_news.query_to_pandas_safe(query, max_gb_scanned=0.1) # convert 0.1 into 1 for example  ","27530ff6":"# check out the scores of job postings (if the \n# query is smaller than 1 gig)\njob_post_scores = hacker_news.query_to_pandas_safe(query)","179e3cf3":"job_post_scores.score.mean()","dc6106e1":"**What's a query?** \n\nA query is small piece of SQL code that specifies what data would you like to scan from a databases, and how much of that data you would like returned","0d93185d":"Run the Query\n\nNow that we know how to check the size of the query (and make sure we're not scanning several terabytes of data!) we're ready to run our first query. You have two methods available to help you do this:\n\n* BigQueryHelper.query_to_pandas(query): This method takes a query and returns a Pandas dataframe.\n* BigQueryHelper.query_to_pandas_safe(query, max_gb_scanned=1): This method takes a query and returns a Pandas dataframe only if the size of the query is less than the upperSizeLimit (1 gigabyte by default).\nHere's an example of a query that is larger than the specified upper limit.","0a3b0390":"Check the size of your query before you run it"}}