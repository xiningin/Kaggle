{"cell_type":{"50e5937f":"code","b82df240":"code","1053b71c":"code","e5399255":"code","50431273":"code","e691746b":"code","ad87c7c3":"code","231b84ef":"code","2aa7b2e6":"code","533ee47e":"code","aa219c02":"code","389ed499":"code","3e89225f":"code","178a8f87":"code","d8e03bac":"code","8400c854":"code","e38dfeec":"code","8883edee":"code","80a2f759":"code","3e35a8c8":"code","e214a258":"code","93dac28f":"code","4f580bd5":"code","beea6fdf":"code","30cf1eb3":"code","b452f8de":"code","2dc746c5":"code","420d6f57":"code","7880d598":"code","df4dc1eb":"markdown","959c96cd":"markdown"},"source":{"50e5937f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objs as go\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b82df240":"df=pd.read_csv('..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')","1053b71c":"df.head()","e5399255":"df.describe()","50431273":"\nfig,ax=plt.subplots(1,3,figsize=(20,5))\nsns.distplot(df['Age'],ax=ax[0])\nsns.distplot(df['Annual Income (k$)'],ax=ax[1])\nsns.distplot(df['Spending Score (1-100)'],ax=ax[2])","e691746b":"px.violin(df,y='Annual Income (k$)',color='Gender',violinmode='overlay')\n#most of women anuual income is concentrated is  40-80K, whereas men 50_80K","ad87c7c3":"px.box(df,x='Gender',y='Age')","231b84ef":"sns.pairplot(df)","2aa7b2e6":"# we can see that spending score vs annual income there is cluster we can assume it as 5 clusters\npx.scatter(df,x='Annual Income (k$)',y='Spending Score (1-100)',color='Age')\n","533ee47e":"df['Age_bins']=pd.qcut(df['Age'],q=3,labels=['young','middle_age','aged'])\npx.scatter(df,x='Annual Income (k$)',y='Spending Score (1-100)',color='Age_bins')\n","aa219c02":"px.box(df,x='Age_bins',y='Annual Income (k$)')","389ed499":"sns.barplot(df['Age_bins'],df['Spending Score (1-100)'],hue=df['Gender'])\n#young people both men and female have high spending score than other as expected\n","3e89225f":"df['Gender']=df['Gender'].map({'Male':0,'Female':1})\ndf['Age_bins']=df['Age_bins'].map({'young':0,'middle_age':1,'aged':2})\n","178a8f87":"sns.heatmap(df.corr(),annot=True)","d8e03bac":"from  sklearn.cluster import KMeans,hierarchical,DBSCAN\nfrom sklearn.metrics  import silhouette_score\n\nkm_inertia=[]\nX=df[['Age','Spending Score (1-100)','Annual Income (k$)']]\nfor n in range(1,10):\n    km=KMeans(n_clusters=n,init='k-means++')\n    km.fit(X)\n    km_inertia.append(km.inertia_)\n","8400c854":"sns.lineplot(x=np.arange(1,10),y=km_inertia,marker='o')#3 ,4,5 as k value","e38dfeec":"km=KMeans(3)\ndf['k=3']=km.fit_predict(X)\nkm=KMeans(4)\ndf['k=4']=km.fit_predict(X)\nkm=KMeans(5)\ndf['k=5']=km.fit_predict(X)\n","8883edee":"fig,ax=plt.subplots(1,3,figsize=(25,5))\nsns.scatterplot(X['Annual Income (k$)'],X['Spending Score (1-100)'],hue=df['k=3'],ax=ax[0],palette=['red','green','blue'])\nsns.scatterplot(X['Annual Income (k$)'],X['Spending Score (1-100)'],hue=df['k=4'],ax=ax[1],palette=['red','green','blue','yellow'])\nsns.scatterplot(X['Annual Income (k$)'],X['Spending Score (1-100)'],hue=df['k=5'],ax=ax[2],palette=['red','green','blue','yellow','orange'])","80a2f759":"print(silhouette_score(X,labels=df['k=3']))\nprint(silhouette_score(X,labels=df['k=4']))\nprint(silhouette_score(X,labels=df['k=5']))\n","3e35a8c8":"from yellowbrick.cluster import SilhouetteVisualizer\nmodel = KMeans(5, random_state=42)\nvisualizer = SilhouetteVisualizer(model, colors='yellowbrick')\nvisualizer.fit(X)        # Fit the data to the visualizer\nvisualizer.show() ","e214a258":"\nfrom sklearn.preprocessing import normalize\n\nX_scaled=normalize(X)\nX_scaled","93dac28f":"import scipy.cluster.hierarchy as shc\n\n\nplt.figure(figsize=(20, 6))  \nplt.title(\"Dendrograms\")  \ndend = shc.dendrogram(shc.linkage(X, method='ward'))\nplt.ylabel('EuclideanDistance')\nplt.xlabel('Clusters')\n\n#method ward groupsobs by reducing sum of squared distances of each observation from the average observation in a cluster. ","4f580bd5":"from sklearn.cluster import AgglomerativeClustering\n\ncluster=AgglomerativeClustering(n_clusters=5,linkage='ward')\nX['hire_cluster']=cluster.fit_predict(X)","beea6fdf":"fig,ax=plt.subplots(1,2,figsize=(20,5))\nsns.scatterplot(X['Spending Score (1-100)'],X['Annual Income (k$)'],hue=X['hire_cluster'],palette=['green','blue','orange','black','red'],ax=ax[0]).set_title('Hirerachical')\n\nsns.scatterplot(X['Spending Score (1-100)'],X['Annual Income (k$)'],hue=df[\"k=5\"],palette=['green','blue','orange','black','red'],ax=ax[1]).set_title('KMEANs at 5')","30cf1eb3":"print(silhouette_score(X,labels=X['hire_cluster']))#there is slight increase in score","b452f8de":"from sklearn.cluster import DBSCAN\n\nepsilon = np.arange(8,12.75,0.25) # eps values to be investigated\nno_samples = np.arange(3,10)\n\nsil_score=[]\nno_of_cluster=[]\nfor ep in epsilon:\n    for sample in no_samples:\n        db=DBSCAN(eps=ep,min_samples=sample)\n        db.fit(X)\n        no_of_cluster.append(len(np.unique(db.labels_)))\n        print((ep,sample),silhouette_score(X,db.labels_),len(np.unique(db.labels_)))","2dc746c5":"#for 6 cluster the score is high for eps=12.5,min_sample=4\ndb=DBSCAN(eps=12.5,min_samples=4).fit(X)\nX['dbscan']=db.labels_","420d6f57":"fig,ax=plt.subplots(1,3,figsize=(25,5))\n\nsns.scatterplot(y=X['Spending Score (1-100)'],x=X['Annual Income (k$)'],hue=X['hire_cluster'],palette=['green','blue','orange','black','red'],ax=ax[0]).set_title('Hirerachical')\nsns.scatterplot(y=X['Spending Score (1-100)'],x=X['Annual Income (k$)'],hue=df[\"k=5\"],palette=['green','blue','orange','black','red'],ax=ax[1]).set_title('KMEANs at 5')\nsns.scatterplot(y=X['Spending Score (1-100)'],x=X['Annual Income (k$)'],hue=X[\"dbscan\"],palette=['black','green','yellow','blue','orange','red'],ax=ax[2]).set_title('DBSCAN')","7880d598":"----------------Thanks ---------------","df4dc1eb":"#Hirerachical Clustering\nAdditive Clustering is bottom-up approach  ,here each datapoint is treated as seperate cluster in begining,and then twoclusters are merged based on \nthe minimum distance between those  two. it continous till single clusters is left","959c96cd":"Based on Spending score and AnnualIncome  cluster are formed both in hireeachical and Kmean\n1>low annual income(>40) and spending score than 40\n2>annaul  income(>40)and spending score <60\n3>high annual income(<60)and low spending score(>40)\n4>high income and spending score\n5>income between(30,60)and spending score (40,60)\n\nCustomer with high spending score and high income to be considered\n"}}