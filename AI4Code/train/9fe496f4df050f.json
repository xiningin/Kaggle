{"cell_type":{"6ee8e87a":"code","04c426b5":"code","4633260e":"code","2e47f21c":"code","5c1064ef":"code","2d3ff5d1":"code","803b4727":"code","8ab298f7":"code","bf562c7c":"code","cbc572fd":"code","1bc7e172":"code","e450d5ce":"code","86692743":"code","865a11e6":"code","b4afa3f1":"code","9212bb9b":"code","5698c76e":"code","9054cc1f":"code","33fbca33":"code","fcd152e6":"code","0be69c4c":"code","175c0d12":"code","187620f2":"code","2f2c6d67":"code","0fb5d7a0":"code","64719d7b":"code","b1ddacca":"code","4c5e2dde":"code","e8d9d077":"code","39c216a3":"code","8b90ad7b":"code","1807727a":"markdown","58015fb7":"markdown","23d6e877":"markdown","ea4e80e7":"markdown","45505635":"markdown","46dc62fa":"markdown","078dc4af":"markdown","b9187c57":"markdown","e82b1785":"markdown","a3e3a1ab":"markdown","9bb99c87":"markdown","0c36974f":"markdown","2fbc6114":"markdown","c5f3265b":"markdown","1d4c7d0c":"markdown"},"source":{"6ee8e87a":"import pandas as pd\nimport seaborn as sns\nfrom nltk.tokenize import word_tokenize\nimport string\nfrom nltk.corpus import stopwords\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n","04c426b5":"sms = pd.read_csv(\"\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv\", encoding='latin-1')\nsms.head()\n\n#Dataframe poss\u00e8de 5 colonnes","4633260e":"#Surppression des 3 colonnes \"Unnamed\"\n\nsms.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1,inplace=True)\nsms.head()","2e47f21c":"#Renommer la colonne \"v1\" par \"label\" et la colonne \"v2\" par \"message\" et affiche du r\u00e9sultat\n\nsms=sms.rename(columns={\"v1\":\"label\",\"v2\":\"message\"})","5c1064ef":"#Dataframe avec les colonnes renomm\u00e9es\n\nsms.head()","2d3ff5d1":"#Diagramme de la colonne label avec la fonction countplot\n#Affichage de ka quatit\u00e9 de Ham et Spam\n\nsns.countplot(sms.label)","803b4727":"#Afficher la taille de la DataFrame\nsms.shape","8ab298f7":"#R\u00e9duction de la taille de la police en minuscules\nsms['message']=sms['message'].str.lower()","bf562c7c":"#Supprimession des ponctuations\n\ndef remove_punct(text):\n    text_tok = word_tokenize(text)\n    l=[]\n    for word in text_tok: \n        if not word in string.punctuation:\n            l.append(word)\n           \n    resultat=\" \".join(l)  \n    return resultat\n\nsms['message']=sms.message.apply(remove_punct)","cbc572fd":"#Supprimession des Stop words \n\nstop=set(stopwords.words('english'))\n\ndef remove_stopword(text):\n    #On divise le texte en morceau\n    text_tok = word_tokenize(text)\n    #Initialisation liste vide\n    l = []\n    for a in text_tok:\n        if not a in stop:\n            l.append(a)\n            \n    resultat = \" \".join(l)\n    return resultat\n\nsms['message']=sms.message.apply(remove_stopword)","1bc7e172":"#Remplacer les mots par leur forme canonique \n\nlemmatizer=WordNetLemmatizer()\n\ndef lemm(text):\n    text_tok = word_tokenize(text) \n    l=[]\n    for word in text_tok:\n        l.append(lemmatizer.lemmatize(word))\n        \n    resultat = \" \".join(l)\n\n    return resultat\n\nsms.message=sms.message.apply(lemm)","e450d5ce":"# Vectoriser la colonne des messages par la m\u00e9thode Bag of words","86692743":"x#Impirtation de la fonction CoutVectorizer de la biblioth\u00e8que sklearn.feature_extraction.text\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n#Corpus prend la valeur de la colonne message du tableau sms\n\ncorpus=sms['message'].values\nbw_vect = CountVectorizer()\n# tokenize et construire le vocabulaire\nbw_fit=bw_vect.fit(corpus)\n# vectoriser les mots\nbw_corpus = bw_fit.transform(corpus)\nbw_sms=pd.DataFrame(bw_corpus.toarray(),columns=bw_fit.get_feature_names())\nbw_sms","865a11e6":"#Vectoriser la colonne des messages par le m\u00e9thode TF IDF\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n#Initialiser les param\u00e8tres du vectoriseur\ntf_vect = TfidfVectorizer(max_features=500)\n#Apprendre le vocabulaire du vectoriseur bas\u00e9 sur le param\u00e8tre initialis\u00e9\ntfidf_fit=tf_vect.fit(corpus)\n#Vectoriser le corpus\ntfidf_corpus= tfidf_fit.transform(corpus)\ntfidf_sms=pd.DataFrame(tfidf_corpus.toarray(),columns=tfidf_fit.get_feature_names())\ntfidf_sms","b4afa3f1":"from sklearn.model_selection import train_test_split\nXtfidf=tfidf_sms\nY=sms.label\n# Split train \/ test data :\nX_traintfidf, X_testtfidf, Y_train, Y_test = train_test_split(Xtfidf, Y, test_size=0.3, random_state=0)","9212bb9b":"#Importation de la fonction tree de la biblioth\u00e8que sklearn\n\nfrom sklearn import tree\ntree_model = tree.DecisionTreeClassifier()\ntree_model = tree.DecisionTreeClassifier(max_depth = 2)\ntree_model = tree_model.fit(X_traintfidf, Y_train)","5698c76e":"#Importation des librairies matplotlib.pyplot et renommer en plt\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(15,10))\nnames = ['spam', 'non spam']\ntree.plot_tree(tree_model,feature_names = Xtfidf.columns, \n               class_names=names,\n               filled = True)\n\n# Affichage de l'arbre de trie entre les spam et ham","9054cc1f":"#Cr\u00e9ation de la variable de pr\u00e9dilection\n\nY_predicttfidf=tree_model.predict(X_testtfidf)","33fbca33":"# En utilisant l'arbre de d\u00e9cision il faut deviner si chaque message de la variable Y_test est spam ou non\n# Il faut sauvegarder la r\u00e9ponse dans la variable Y_prredicttfidf\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix \nmat = confusion_matrix(Y_predicttfidf, Y_test)\nprint(mat)\n\n#Afficher mat","fcd152e6":"sns.heatmap(mat, annot=True,  xticklabels=names, yticklabels=names)\nplt.xlabel('Test')\nplt.ylabel('Predicted')\n\n#Cr\u00e9ation du tableau permettant de comparer les valeurs pr\u00e9dites avec les valeurs d\u00e9j\u00e0 entr\u00e9es","0be69c4c":"#Importation de la fonction train_test_split de la biblioth\u00e8que sklearn.model_selection\n\nfrom sklearn.model_selection import train_test_split\nXbw=bw_sms\nY=sms.label\n# Split train \/ test data : on r\u00e9cup\u00e8re les sms du tableau et on explique au logiciel ce qu'est un spam \nX_trainbw, X_testbw, Y_train, Y_test = train_test_split(Xbw, Y, test_size=0.3, random_state=0)","175c0d12":"#Importation de la fonction tree de la biblioth\u00e8que sklearn\n\nfrom sklearn import tree\ntree_model = tree.DecisionTreeClassifier()\n\n#Choisir le nombre d'\u00e9tapes de l'arbre, sa profondeur \n\ntree_model = tree.DecisionTreeClassifier(max_depth = 2)\ntree_model = tree_model.fit(X_trainbw, Y_train)","187620f2":"#Importation de la fonction matplotlib.pyplot qui prends le nom de plt\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(15,10))\nnames = ['spam', 'non spam']\ntree.plot_tree(tree_model,feature_names = Xbw.columns, \n               class_names=names,\n               filled = True)\n\n#Cr\u00e9ation et affichage de l'arbre de choix du logicel permettant de dire si les sms sont des spam ou ham","2f2c6d67":"Y_predictbw=tree_model.predict(X_testbw)","0fb5d7a0":"#Importation de la fonction accuracy_score et confusion_matrix de la biblioth\u00e8que sklearn.metrics\nsklearn.metrics import accuracy_score, confusion_matrix\n\n#D\u00e9fintion du tableau mat qui regroupe les avelurs de Y_predict et Y_test\nmat = confusion_matrix(Y_predictbw, Y_test)\nprint(mat)\n\n#Afficher du tableau des valeurs de Y_predict et Y_test","64719d7b":"sns.heatmap(mat, annot=True,  xticklabels=names, yticklabels=names)\nplt.xlabel('Test')\nplt.ylabel('Predicted')\n\n#Affichage du tableau comparant les valeurs pr\u00e9dites avec les valeurs r\u00e9elles","b1ddacca":"#Importation de la fonction GridSearchCV de la biblioth\u00e8que sklearn.model_selection\nfrom sklearn.model_selection import GridSearchCV\n#Importation de la fonction numpy et cette derni\u00e8re prend le nom de np\nimport numpy as np\ndepths = np.arange(10, 40,5)\nparam_grid = [{'max_depth':depths}]\ngrid_tree= GridSearchCV(estimator=tree.DecisionTreeClassifier(),param_grid=param_grid,scoring='accuracy',cv=10)\ngrid_tree.fit(X_traintfidf, Y_train)\nbest_model_tree = grid_tree.best_estimator_\nY_grid=best_model_tree.predict(X_testtfidf)","4c5e2dde":"mat = confusion_matrix(Y_grid, Y_test)\nsns.heatmap(mat, annot=True,  xticklabels=names, yticklabels=names)\nplt.xlabel('Test')\nplt.ylabel('Predicted')","e8d9d077":"from sklearn.ensemble import RandomForestClassifier\nRf_model = RandomForestClassifier()\nRf_model=Rf_model.fit(X_traintfidf, Y_train)\nY_predicttfidf=Rf_model.predict(X_testtfidf)\na_CART = accuracy_score(Y_test,Y_predicttfidf)\nprint(\"L'accuracy score du mod\u00e8le RF est de : \",a_CART)\nmat = confusion_matrix(Y_predicttfidf, Y_test)\nsns.heatmap(mat, annot=True,  xticklabels=names, yticklabels=names)\nplt.xlabel('Test')\nplt.ylabel('Predicted')","39c216a3":"#D\u00e9finition de la fonction reponse\n\ndef reponse(text):\n    text=text.lower()\n    text=text.replace('covid-19','coronavirus')\n    text=remove_punct(text)\n    text=remove_stopword(text)\n    text=lemm(text)\n    tfidf_text=tfidf_fit.transform([text])\n   \n    cm=cosine_similarity(tfidf_text, tfidf_corpus)\n    pos=np.argmax(cm[0])\n    data.answers[pos]\n    return data.answers[pos]","8b90ad7b":"while True:\n    text = str(input(\"Input: \"))\n    if text== \"exit\":\n        print(\"Response: Exiting.....\")\n        break\n    print(\"Response:\",reponse(text))","1807727a":"## Gridsearch\n\nPour d\u00e9terminer la meilleure profondeur entre 10 et 40 pour l'algorithme de l'arbre de d\u00e9cision","58015fb7":"## Vectorisation","23d6e877":"## TF IDF","ea4e80e7":"## 1\u00e8re m\u00e9thode : avec TFIDF","45505635":"## Bag of words","46dc62fa":"## Arbre de d\u00e9cision","078dc4af":"## For\u00eat d'arbres\n\nSi on a un nombre important de variables explicatives (features). on utilise la For\u00eat d'arbres qui fonctionne comme le suivant:\n- on prend des sous ensembles de donn\u00e9es et des sous ensembles de variables explicatives.\n- on applique l'Arbre de d\u00e9cision sur chaque sous ensemble.\n- la pr\u00e9diction de la for\u00eat al\u00e9atoire est alors un simple vote majoritaire des arbes construites.","b9187c57":"## Arbre de d\u00e9cision\n\nArbre de d\u00e9cision est un arbre orient\u00e9 dont les noeuds sont \u00e9tiquet\u00e9s par un test et les ars contiennent mes r\u00e9sultats du test. On choisit de faire un test sur la variable qui disperse le mieux les classes. Pour cela, on calcule le coefficient de Gini qui mesure l'impurit\u00e9 d'un sous ensemble de donn\u00e9e.","e82b1785":"## Code \u00e0 tester","a3e3a1ab":"## Classer\n\nFonction \"classer\" qui prend en entr\u00e9e un texte et retourne comme r\u00e9sultat si ce texte est spam ou non","9bb99c87":"## \u00c9valuation de l'arbre\n\nOn compare les valeurs devin\u00e9es par la machine (Y_predictbw) par rapport aux vraies valeurs (Y_test)","0c36974f":"## Vectorisation","2fbc6114":"## 2\u00e8me m\u00e9thode : avec Bag of words","c5f3265b":"## \u00c9valuation de l'arbre","1d4c7d0c":"## Suite avec la m\u00e9thode TFIDF"}}