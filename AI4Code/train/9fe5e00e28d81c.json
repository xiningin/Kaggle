{"cell_type":{"4d5708bc":"code","1dca939f":"code","85f21fd0":"code","fc6de07d":"code","5031581c":"code","82df4e17":"code","81749bbf":"code","1c8fa8ab":"code","75b95a8e":"code","5c80afa6":"code","ef0db9ae":"code","43057529":"code","88810814":"code","cb625ab3":"code","02a1af0b":"code","f8b2161b":"code","bc7e4180":"code","feeebb16":"code","85905f36":"code","fb5da559":"code","7699221e":"code","77e3449d":"code","c3156cee":"markdown","88121064":"markdown","a7f57fee":"markdown","175b4537":"markdown","2400aca8":"markdown","230bd2f8":"markdown","cfd54a47":"markdown","7e8be9c9":"markdown","2ce77cd4":"markdown","4d1a5a77":"markdown","19224084":"markdown","659a13bb":"markdown"},"source":{"4d5708bc":"%reset -sf\nimport random\nimport collections\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\nfrom tqdm import tqdm\n\nrandom.seed(42)\n!ls \/kaggle\/input\/hashcode-photo-slideshow\/","1dca939f":"# paramters for maximum performance (10 minutes)\nREARRANGE_FOR_MERGE = True\nMERGE_WINDOW = 10000\nARRANGE_WINDOW = 10000\n\n# # paramters for quick compute (2 minutes)\n# REARRANGE_FOR_MERGE = False\n# MERGE_WINDOW = 100\n# ARRANGE_WINDOW = 100","85f21fd0":"filepath = \"\/kaggle\/input\/hashcode-photo-slideshow\/d_pet_pictures.txt\"\nwith open(filepath) as f:\n    pictures = [row.strip().split() for row in f.readlines()][1:]","fc6de07d":"!head -3 \"\/kaggle\/input\/hashcode-photo-slideshow\/d_pet_pictures.txt\"","5031581c":"pic_tags = {}  # maps idx to tags\nhorizontal_photos = []  # horizontal photos only\nvertical_photos = []  # vertical photos only\nfor i,picture in enumerate(pictures):\n    pic_tags[i] = set(picture[2:])\n    if picture[0] == \"H\":\n        horizontal_photos.append(i)\n    elif picture[0] == \"V\":\n        vertical_photos.append(i)\nprint(len(vertical_photos), len(horizontal_photos))","82df4e17":"def calc_tags_pair_score(tags1, tags2):\n    # given two sets of tags, calculate the score\n    return min(len(tags1 & tags2), len(tags1 - tags2), len(tags2 - tags1))\n\ndef calc_idxs_pair_score(idxs1, idxs2):\n    # given two tuples of indices, calculate the score\n    return calc_tags_pair_score(\n        set.union(*[pic_tags[idx] for idx in idxs1]),\n        set.union(*[pic_tags[idx] for idx in idxs2]))\n\ndef calc_idxs_pair_score_max(idxs1, idxs2):\n    # given two tuples of indices, calculate the maximum possible score by tag length\n    return min(len(set.union(*[pic_tags[idx] for idx in idxs1])),\n               len(set.union(*[pic_tags[idx] for idx in idxs2])))\/\/2\n\ndef calc_sequence(idxs_lst):\n    # given the sequence of indices, calculate the score\n    check_validity(idxs_lst)\n    score = 0\n    for before, after in zip(idxs_lst[:-1], idxs_lst[1:]):\n        score += calc_idxs_pair_score(before, after)            \n    return score\n\ndef calc_sequence_max(idxs_lst):\n    # given the sequence of indices, calculate the score\n    check_validity(idxs_lst)\n    score = 0\n    for before, after in zip(idxs_lst[:-1], idxs_lst[1:]):\n        score += calc_idxs_pair_score_max(before, after)            \n    return score\n\ndef check_validity(idxs_lst):\n    all_pics = [idx for idxs in idxs_lst for idx in idxs]\n    if len(all_pics) != len(set(all_pics)):\n        print(\"Duplicates found\")\n    all_verts = [idx for idxs in idxs_lst for idx in idxs if len(idxs) == 2]\n    if (set(all_verts) - set(vertical_photos)):\n        print(\"Horizontal photos found in vertical combinations\")\n    all_horis = [idx for idxs in idxs_lst for idx in idxs if len(idxs) == 1]\n    if (set(all_horis) - set(horizontal_photos)):\n        print(\"Vertical photos found in horizontal arrangement\")","81749bbf":"idxs_list = [(a,b) for a,b in zip(vertical_photos[0::2], vertical_photos[1::2])] \nidxs_list.extend([(a,) for a in horizontal_photos])\ncalc_sequence(idxs_list), calc_sequence_max(idxs_list), len(idxs_list)","1c8fa8ab":"random.shuffle(idxs_list)\nidxs_list.sort(key = lambda idxs: sum([len(pic_tags[idx]) for idx in idxs]))\ncalc_sequence(idxs_list), calc_sequence_max(idxs_list), len(idxs_list)","75b95a8e":"# match vertical photos by tag length\nrandom.shuffle(vertical_photos)\nvertical_photos.sort(key=lambda idx: len(pic_tags[idx]))\nidxs_list = [(a,b) for a,b in zip(vertical_photos[0::2], vertical_photos[1::2])]\nidxs_list.extend([(a,) for a in horizontal_photos])\nidxs_list.sort(key = lambda idxs: sum([len(pic_tags[idx]) for idx in idxs]))\ncalc_sequence(idxs_list), calc_sequence_max(idxs_list), len(idxs_list)","5c80afa6":"vertical_tmp = vertical_photos[::-1]  # start from photo with most tags\nif REARRANGE_FOR_MERGE:  \n    # so we can easily match photos with more tags with photos with less tags\n    vertical_photos[0::2] = vertical_tmp[:30000]\n    vertical_photos[1::2] = vertical_tmp[30000:][::-1]\nvertical_tmp = vertical_photos\nvertical_photos = [vertical_tmp[0]]\nvertical_tmp = vertical_tmp[1:]\n\nfor i in tqdm(range(len(vertical_tmp))):\n    idxs1 = vertical_photos[-1]\n    best = -9999\n    best_next_ptr = 0\n    cnt = 0\n    for j,idxs2 in enumerate(vertical_tmp):\n        if len(vertical_photos)%2 == 0:  # we do not need to consider between pairs\n            break\n        if best == 0:\n            # we have found an optimal match\n            break\n        if cnt > MERGE_WINDOW:\n            # early stopping in the search for a paired photo\n            break\n        score = -len(pic_tags[idxs1] & pic_tags[idxs2])\n        num_tags_if_paired = len(pic_tags[idxs1] | pic_tags[idxs2])\n        if num_tags_if_paired%2 == 1:  \n            # penalise if the total number of tags is odd\n            score = min(score,-0.9)\n        if num_tags_if_paired > 22 and REARRANGE_FOR_MERGE:  \n            # to encourage the total number of tags around 22\n            score = min(score,-0.02*num_tags_if_paired)\n        if score > best:\n            best = score\n            best_next_ptr = j\n        cnt += 1\n    vertical_photos.append(vertical_tmp[best_next_ptr])\n    vertical_tmp = vertical_tmp[:best_next_ptr] + vertical_tmp[best_next_ptr+1:]","ef0db9ae":"# match vertical photos by tag length\nidxs_list = [(a,b) for a,b in zip(vertical_photos[0::2], vertical_photos[1::2])]\nidxs_list.extend([(a,) for a in horizontal_photos])\nidxs_list.sort(key = lambda idxs: sum([len(pic_tags[idx]) for idx in idxs]))\ncalc_sequence(idxs_list), calc_sequence_max(idxs_list), len(idxs_list)","43057529":"idxs_list_tmp = idxs_list\nidxs_list = [idxs_list_tmp[0]]\nidxs_list_tmp = idxs_list_tmp[1:]\n\nfor i in tqdm(range(len(idxs_list_tmp))):\n    idxs1 = idxs_list[-1]\n    best = -1\n    best_next_ptr = -1\n    cnt = 0\n    for j,idxs2 in enumerate(idxs_list_tmp):\n        if cnt > ARRANGE_WINDOW:\n            # early stopping in the greedy search\n            break\n        if best == sum(len(pic_tags[idx]) for idx in idxs2)\/\/2:\n            # if we have reached the maximum possible score for the next neighbour\n            break\n        score = calc_idxs_pair_score(idxs1,idxs2)\n        if score > best:\n            best = score\n            best_next_ptr = j\n        cnt += 1\n    idxs_list.append(idxs_list_tmp[best_next_ptr])\n    idxs_list_tmp = idxs_list_tmp[:best_next_ptr] + idxs_list_tmp[best_next_ptr+1:]","88810814":"calc_sequence(idxs_list), calc_sequence_max(idxs_list), len(idxs_list)","cb625ab3":"plt.figure(figsize=(14,4))\nplt.hist([len(pic_tags[idx1] & pic_tags[idx2]) for idx1,idx2 in \n          zip(vertical_photos[::2], vertical_photos[1::2])], bins=range(20), alpha=0.5,\n         label=\"distribution of number of overlapping tags \" + \n               \"between neighbours of vertical photos sorted by number of tags\")\nfor rect in plt.gca().patches:\n    height = rect.get_height()\n    plt.gca().annotate(f'{int(height)}', xy=(rect.get_x()+rect.get_width()\/2, height), \n                       xytext=(0, 0), textcoords='offset points', \n                       ha='center', va='bottom', fontsize=8)\nplt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\nplt.legend()\nplt.show()","02a1af0b":"plt.figure(figsize=(14,4))\nplt.hist([len(pic_tags[idxs[0]] | pic_tags[idxs[1]])\n          for idxs in zip(vertical_photos[::2], vertical_photos[1::2])], \n         bins=range(36), alpha=0.5,\n         label=\"distribution of number of tags of combined photos\")\nfor rect in plt.gca().patches:\n    height = rect.get_height()\n    plt.gca().annotate(f'{int(height)}', xy=(rect.get_x()+rect.get_width()\/2, height), \n                       xytext=(0, 0), textcoords='offset points', \n                       ha='center', va='bottom', fontsize=8)\nplt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\nplt.legend()\nplt.show()","f8b2161b":"plt.figure(figsize=(14,4))\nplt.plot([calc_idxs_pair_score(idxs1,idxs2) for idxs1,idxs2 in \n          zip(idxs_list[:-1], idxs_list[1:])], alpha=0.5, \n         label=\"score of neighbours in the sequence\")\nplt.plot([calc_idxs_pair_score_max(idxs1,idxs2) for idxs1,idxs2 in \n          zip(idxs_list[:-1], idxs_list[1:])], alpha=0.5,\n         label=\"maximum possible score of neighbours in the sequence\")\nplt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\nplt.legend()\nplt.show()","bc7e4180":"plt.figure(figsize=(14,4))\nplt.hist([[calc_idxs_pair_score_max(idxs1,idxs2) for idxs1,idxs2 in \n          zip(idxs_list[::2], idxs_list[1::2]) if len(idxs1) + len(idxs2) == 4],\n          [calc_idxs_pair_score_max(idxs1,idxs2) for idxs1,idxs2 in \n          zip(idxs_list[::2], idxs_list[1::2]) if len(idxs1) + len(idxs2) == 3],\n          [calc_idxs_pair_score_max(idxs1,idxs2) for idxs1,idxs2 in \n          zip(idxs_list[::2], idxs_list[1::2]) if len(idxs1) + len(idxs2) == 2]],\n         bins=range(20), alpha=0.5,\n         label=[\n        \"maximum possible scores for vertical-vertical neighbours\",\n        \"maximum possible scores for horizontal-vertical neighbours\",\n        \"maximum possible scores for horizontal-horizontal neighbours\"], \n         stacked=True)\nplt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\nplt.legend()\nplt.show()","feeebb16":"plt.figure(figsize=(14,4))\nplt.hist([[calc_idxs_pair_score(idxs1,idxs2) for idxs1,idxs2 in \n          zip(idxs_list[::2], idxs_list[1::2]) if len(idxs1) + len(idxs2) == 4],\n          [calc_idxs_pair_score(idxs1,idxs2) for idxs1,idxs2 in \n          zip(idxs_list[::2], idxs_list[1::2]) if len(idxs1) + len(idxs2) == 3],\n          [calc_idxs_pair_score(idxs1,idxs2) for idxs1,idxs2 in \n          zip(idxs_list[::2], idxs_list[1::2]) if len(idxs1) + len(idxs2) == 2]],\n         bins=range(20), alpha=0.5,\n         label=[\n        \"distribution of scores for vertical-vertical neighbours\",\n        \"distribution of scores for horizontal-vertical neighbours\",\n        \"distribution of scores for horizontal-horizontal neighbours\"], \n         stacked=True)\nplt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\nplt.legend()\nplt.show()","85905f36":"calc_sequence(idxs_list), calc_sequence_max(idxs_list), len(idxs_list)","fb5da559":"submission_lines = []\nsubmission_lines.append(str(len(idxs_list)))\nfor idxs in idxs_list:\n    submission_lines.append(\" \".join([str(idx) for idx in idxs]))","7699221e":"with open(\"submission.txt\", \"w\") as f:\n    f.writelines(\"\\n\".join(submission_lines))","77e3449d":"!head -3 submission.txt","c3156cee":"# Editorial\n\nPlease refer to my [Exploratory Data Analysis](https:\/\/www.kaggle.com\/huikang\/hc-2019q-eda-and-baseline-soln) for my summary of the problem and some insights on the dataset.\n\nFor any approach, the steps can be classified into two stages, both of which should be improved\n- You need to **match** vertical photos into \"combined\" photos.\n- You need to **arrange** the combined\/horizontal photos for maximum score.","88121064":"# Write submission","a7f57fee":"Performance\n- With a running time of 6 minutes from scratch, I have obtained a score of **441088**.\n- The [upper bound of the theoretical maximum](https:\/\/www.kaggle.com\/huikang\/hc-2019q-eda-and-baseline-soln#Theoretical-maximum) is 443406.\n\nCompetition considerations\n- The entire duration of Hash Code qualifiers is 4 hours, including reading the question and submission. A group of up to four people work on the problem.\n- We can reduce K further down to 100. This reduces the computation time to 133 seconds, scoring 412858.\n- The [22nd place](https:\/\/medium.com\/@danieleratti\/how-we-placed-1st-in-italy-and-22nd-in-the-world-google-hashcode-2019-e59e52232b4e)  of the actual qualifiers scored 347793. Some grandmasters on [Codeforces](https:\/\/codeforces.com\/blog\/entry\/65617) do manage to hit 440k for this problem during the qualifiers. [Errichto](https:\/\/codeforces.com\/blog\/entry\/65617?#comment-496761) managed to run the algorithm in 2 minutes during the competition, using C++ bitsets.\n- Realistically, I do not expect teams to come up with the perfect algorithm. The most important part is implementing the greedy search effectively. Algorithms that attempt to conduct the greedy search on all the remaining combined\/horizontal photos will run out of time (estimated 6 hours). It is important to understand that for each node there is a maximum score, and you can stop finding stop once you obtained the score (or close to it).\n- The competition is done in a team. You want to perform better than four people coding individually. There is also a trade-off in collaborating because communication takes up time and effort. This is something your team need to discuss, plan, and practice.","175b4537":"# ARRANGING combined\/horizontal photos <a id='ID_ARRANGED'><\/a>","2400aca8":"Submission format\n```\nnrows\nphoto_id_1v photo_id_2v\nphoto_id_h\n...\n```","230bd2f8":"Input format\n```\nnumber_of_photos\nhorizontal_or_vertical number_of_tags tag1 tag2 tag3 ...\nhorizontal_or_vertical number_of_tags tag1 tag2 tag3 ...\n...\n```","cfd54a47":"# Score calculation","7e8be9c9":"Further improvements\n- As mentioned, we are already very close to the theoretical maximum of 443406.\n- You can try local optimisation on the sequences (as presented in other notebooks). To make this optimisation an effective use of time, you can ignore neighbours that already have an optimum score.\n- You might want to change the way how vertical photos are merged. Currently, vertical photos are usually merged with vertical photos with the same number of tags, or merged such that the combined number of tags is close to 20. You might want to change this distribution.\n- You can consider the frequency of the tags when you arranged during merging. You might want all pairs of vertical photos to share a similar distribution of common tags and less common tags.\n- You can consider the frequency of the tags when you arranged during arranging. For example, in the consideration of the next neighbour, you might want to prefer the intersection tags between adjacent photos (matched-vertical or horizontal) to use the tags that appear less frequently. This way, the remaining neighbours tend to have more common tags, making it easier to find optimium neighbours among themselves.\n- You can also try this algorithm on [other datasets](https:\/\/storage.googleapis.com\/coding-competitions.appspot.com\/HC\/2019\/qualification_round_2019.in.zip) in the competition.","2ce77cd4":"# Parse input","4d1a5a77":"On how the vertical photos are [**matched**](#ID_MATCHED)\n- Conducting a data analysis on the vertical photos, we see that there are signficant overlap in the number of tags between vertical photo pairs.\n- I needed to match the photos in the way that it minimise the amount of overlapping tags.\n- I avoid pairings that result in odd number of tags. This improved the solution my almost a thousand from 440k. This improved the result slightly, but adds 5 minutes to the computation time.\n- I try to pair pictures so that their tags combined is close to 20 (and even), the average. The hypothesis is that with a similar amount of tags, it is easier to find the next neighbour with the optimum score. This also require the increased computation time.\n\nOn how the photos are [**arranged**](#ID_ARRANGED)\n- This is now a travelling salesman problem (TSP). Each node is one combined\/horizontal photo. A score is assigned between each combination of combined\/horizontal pairs, like how a distance is assigned between each location pairs in the traditional TSP. Instead of minimising distance in the traditional TSP, we maximise the score.\n- A greedy approach is used.\n- The greedy search starts from the combined\/horizontal photos with the most number of tags. We do this until no more combined\/horizontal photos are left.\n- We do not search in all the remaining photos. Instead of searching from all the remaining photo, we search among the remaining K=10000 photos.\n- We can also stop when we have obtained the maximum possible score, calculated from the number of tags of the preceding photo. This drastically sped up our computation time from 1 hour with K=10000 to 6 minutes.","19224084":"# Solution analysis","659a13bb":"# MATCHING vertical photos <a id='ID_MATCHED'><\/a>"}}