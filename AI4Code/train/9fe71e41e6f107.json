{"cell_type":{"c72f8d7a":"code","262cbf24":"code","a48f408a":"code","50aac114":"code","04a4255f":"code","1754d2e4":"code","3fd96aa2":"code","eb81a2d9":"code","0e57d435":"code","45136563":"code","af71754a":"code","be948141":"code","ec0820c0":"code","074abc23":"code","bd5719e3":"code","75d8ff67":"code","632902ae":"code","472e3060":"code","d62de745":"code","8cc1589e":"code","e4beac47":"code","b540be40":"code","44114286":"code","978a5252":"code","44ecace0":"code","34fd2620":"code","a2352592":"code","ffcb4990":"code","d84eb1f0":"code","d051e484":"code","4e8e0589":"code","4ba904af":"code","2e201dce":"code","d003d98f":"code","c651b680":"code","62b71bdf":"code","4333e06c":"code","7d1894d9":"code","7d6be242":"code","8bc958d1":"code","73e9ea2d":"code","e09e3077":"code","59b0fa90":"code","edf8487c":"code","8ec178e1":"code","73c4da22":"code","e6024430":"code","e2650263":"code","0a18c15b":"code","070d1e70":"code","0a33f524":"code","491e9320":"code","0607a44e":"code","aff7c7f1":"code","9866dd35":"code","fa0ae633":"code","f2ef85c5":"code","f36ff5ec":"code","0031f032":"code","01205c40":"code","a6404ac2":"code","72d24040":"code","d6758a34":"code","edb240e1":"code","f6f19bcf":"code","7bce0ba5":"code","7bc94894":"code","6f05a02a":"code","c5693080":"code","8a6ffae2":"code","7a8ac6d7":"code","71015e55":"code","4c46ad91":"code","df0cc816":"code","2dc8a5db":"code","e985c23c":"code","d98c59ad":"code","c101b162":"code","9eecc8c2":"code","90b57634":"code","7f2c63d6":"code","bab97293":"code","c5251352":"code","a1f076a5":"code","3f8220af":"code","8e6eda68":"code","0177dad1":"code","fa729771":"code","b1f9de05":"code","de5a5da6":"code","31dd2b33":"code","1637d298":"code","b2ebfe9b":"code","fcae3354":"code","a2e2cae5":"code","0ca0a4eb":"code","ef094b78":"code","003ca6e8":"code","73adeff5":"code","be518a3b":"code","753208ba":"code","6c85036e":"code","429d2db4":"code","92fac5cc":"code","ba478a6b":"code","b6927bec":"code","4d5a2197":"code","86242d28":"code","673e1561":"code","931c4f7f":"code","72b12b99":"code","b13c2d26":"code","35af5f2f":"code","bdad857d":"code","be163348":"code","b427a91b":"code","2a06b144":"code","62db95fd":"code","29d7ccb6":"code","e57d28bc":"markdown","89a69a6d":"markdown","cb675882":"markdown","500b5ef6":"markdown","293df692":"markdown","50ffe90d":"markdown","d33e24cd":"markdown","3b86c0a6":"markdown","c741c2e3":"markdown","9957a8cd":"markdown","5ca2bb1b":"markdown","fc4384a7":"markdown","c48ac81a":"markdown","3c1ce6ae":"markdown","10978e61":"markdown","51da1459":"markdown","5d345475":"markdown","a43be0e2":"markdown","c199a326":"markdown","82ae74b8":"markdown","274a42f0":"markdown","72b4ef81":"markdown","4ec06aff":"markdown","c1940e59":"markdown","46093e70":"markdown","0f0bedc7":"markdown","517fb7a0":"markdown","6cc96734":"markdown","ae8bd8fa":"markdown","84560a2d":"markdown","8647fdf3":"markdown","527edd36":"markdown","caec53a6":"markdown","4ccc1b7b":"markdown","6698e824":"markdown","b3138b6c":"markdown","152202b1":"markdown","e118d74a":"markdown","21491bcf":"markdown","6ed08ee6":"markdown","6cde3c3f":"markdown","379646e1":"markdown","097d1794":"markdown","98e3792c":"markdown","e330bbb5":"markdown","9038ea77":"markdown","cc5b3e99":"markdown","ed1f8fb1":"markdown","d8c5046a":"markdown","039cab32":"markdown","fb1eb46b":"markdown","4e47fd8d":"markdown","82905e0b":"markdown","da85e5b5":"markdown","094db114":"markdown","8cef61b0":"markdown","eae8ef73":"markdown","1fa4d099":"markdown","ad7ad859":"markdown","c70d3a6d":"markdown","af9f4236":"markdown","558d065a":"markdown"},"source":{"c72f8d7a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","262cbf24":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","a48f408a":"leads = pd.read_csv('\/kaggle\/input\/leads-dataset\/Leads.csv')","50aac114":"leads.head()","04a4255f":"leads.head().T","1754d2e4":"len(leads)","3fd96aa2":"leads['Prospect ID'].duplicated().sum()","eb81a2d9":"leads.dtypes","0e57d435":"leads.isna().sum().to_frame(name='Missing Values').sort_values('Missing Values', ascending=False)","45136563":"for i in leads.columns:\n    if leads[i].isna().sum()>3000:\n        leads.drop(i, axis=1, inplace=True)","af71754a":"leads['Lead Source'].value_counts()","be948141":"leads['Lead Source'].fillna('Google', inplace=True)","ec0820c0":"leads['Lead Source'] = leads['Lead Source'].str.replace('google', 'Google')","074abc23":"leads['Lead Source'].unique()","bd5719e3":"leads['Last Activity'].value_counts()","75d8ff67":"leads['Last Activity'].fillna('Other', inplace=True)","632902ae":"leads['City'].value_counts()","472e3060":"leads['City'].fillna('Select', inplace=True)","d62de745":"leads['Specialization'].value_counts()","8cc1589e":"leads['Specialization'].fillna('Select', inplace=True)","e4beac47":"leads['How did you hear about X Education'].value_counts()","b540be40":"leads['How did you hear about X Education'].fillna('Select', inplace=True)","44114286":"leads['Country'].value_counts()","978a5252":"leads[(leads['Country'].isna())&(leads['City'].isna()==False)]['City'].unique()","44ecace0":"leads.loc[(leads['Country'].isna())&(leads['City']=='Mumbai'), 'Country'] = 'India'\nleads.loc[(leads['Country'].isna())&(leads['City']=='Other Cities of Maharashtra'), 'Country'] = 'India'\nleads['Country'].fillna('unknown', inplace=True)","34fd2620":"leads['What is your current occupation'].value_counts()","a2352592":"leads['What is your current occupation'].fillna('Other', inplace=True)","ffcb4990":"leads['Lead Profile'].value_counts()","d84eb1f0":"leads['Lead Profile'].fillna('Select', inplace=True)","d051e484":"leads['What matters most to you in choosing a course'].value_counts()","4e8e0589":"leads['What matters most to you in choosing a course'].fillna('Other', inplace=True)","4ba904af":"leads.describe()","2e201dce":"leads['TotalVisits'].fillna(3, inplace=True)","d003d98f":"leads['Page Views Per Visit'].fillna(2, inplace=True)","c651b680":"leads.columns = leads.columns.str.lower().str.replace(' ','_')\nstring_columns = list(leads.dtypes[leads.dtypes=='Object'].index)\n\nfor col in string_columns:\n    leads[col] = leads[col].str.lower().str.replace(' ', '_')","62b71bdf":"from sklearn.model_selection import train_test_split","4333e06c":"train_full, test_X = train_test_split(leads, test_size=0.2, random_state=1)  ","7d1894d9":"train_X, val_X = train_test_split(train_full, test_size=0.2, random_state=1)","7d6be242":"train_y = train_X['converted'].values.reshape(-1,1)\nval_y = val_X['converted'].values.reshape(-1,1)\ntest_y = test_X['converted'].values.reshape(-1,1)","8bc958d1":"print(f'{len(train_y)}\\n{len(val_y)}\\n{len(test_y)}')","73e9ea2d":"categorical_df = leads.select_dtypes(include='object')\ncategorical_df.drop(['prospect_id'], axis=1, inplace=True)\ncategorical = list(categorical_df.columns)\n\nnumerical_df = leads.select_dtypes(exclude='object')\nnumerical_df.drop(['lead_number', 'converted'], axis=1, inplace=True)\nnumerical = list(numerical_df)","e09e3077":"train_X[categorical].nunique().to_frame('nunique').sort_values('nunique', ascending=False)","59b0fa90":"train_X['converted'].value_counts()","edf8487c":"global_mean = round(train_X['converted'].mean(),3)\nprint(f'Only {global_mean*100}% of leads have been successfully converted.')","8ec178e1":"grouped_train = train_X.groupby('what_is_your_current_occupation').converted.agg(['mean'])\ngrouped_train['diff'] = global_mean - grouped_train['mean']\ngrouped_train['reliability'] = grouped_train['mean']\/global_mean\ngrouped_train","73c4da22":"def converted_stat(column):\n    data_group = train_X.groupby(column).converted.agg(['mean'])\n    data_group['diff'] = data_group['mean'] - global_mean\n    data_group['reliability'] = data_group['mean']\/global_mean\n    return data_group","e6024430":"converted_stat('what_matters_most_to_you_in_choosing_a_course')","e2650263":"converted_stat('a_free_copy_of_mastering_the_interview')","0a18c15b":"converted_stat('city')","070d1e70":"converted_stat('do_not_email')","0a33f524":"converted_stat('lead_origin')","491e9320":"from sklearn.metrics import mutual_info_score\n\ndef calculate_mi(series):\n    return mutual_info_score(series, leads['converted'])\n\ndata_mi = leads[categorical].apply(calculate_mi)\ndata_mi = data_mi.sort_values(ascending=False).to_frame(name='Mi')\ndata_mi","0607a44e":"leads[numerical].corrwith(leads['converted']).to_frame('Correlations')","aff7c7f1":"cat = list(data_mi.iloc[0:9,:].index)","9866dd35":"cat","fa0ae633":"train_dict = train_X[cat+numerical].to_dict(orient='rows')","f2ef85c5":"train_dict[0]","f36ff5ec":"from sklearn.feature_extraction import DictVectorizer\n\ndv = DictVectorizer(sparse=False)\nX_train = dv.fit_transform(train_dict)","0031f032":"len(X_train[0])","01205c40":"dv.get_feature_names()","a6404ac2":"val_dict = val_X[cat+numerical].to_dict(orient='rows')\nX_val = dv.transform(val_dict)","72d24040":"len(X_val[0])","d6758a34":"from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(solver='liblinear', random_state=1)\nmodel.fit(X_train, train_y)","edb240e1":"preds = model.predict_proba(X_val)[:,1]","f6f19bcf":"preds[:5]","7bce0ba5":"pred = (preds>0.5).astype(int).reshape(-1,1)","7bc94894":"pred[:5]","6f05a02a":"(pred==val_y).mean()","c5693080":"from sklearn.metrics import accuracy_score","8a6ffae2":"thresholds = np.linspace(0,1,11)\n\nfor i in thresholds:\n    churn = preds>=i\n    acc = accuracy_score(val_y, churn)\n    print(f'{round(i,1)} {round(acc,3)}')","7a8ac6d7":"thresholds = np.linspace(0,1,21)\naccs = []\n\nfor i in thresholds:\n    churn = preds>=i\n    acc = accuracy_score(val_y, churn)\n    accs.append(acc)","71015e55":"plt.plot(thresholds, accs)\nplt.xlabel('Thresholds')\nplt.ylabel('Accuracy')\nplt.title('Threshold vs Accuracy')\nplt.show()","4c46ad91":"t = 0.4\n\npredict_convert = (preds>=t).reshape(-1,1)\npredict_no_convert = (preds<t).reshape(-1,1)\n\nactual_convert = (val_y==1)\nactual_no_convert = (val_y==0)\n\ntrue_positive = (predict_convert & actual_convert).sum()\ntrue_negative = (predict_no_convert & actual_no_convert).sum()\n\nfalse_positive = (predict_convert & actual_no_convert).sum()\nfalse_negative = (predict_no_convert & actual_convert).sum()","df0cc816":"confussion_table = np.array([[true_negative, false_positive],[false_negative,true_positive]])\nconfussion_table","2dc8a5db":"confussion_table\/confussion_table.sum()","e985c23c":"P = true_positive\/(true_positive+false_positive)\nprint(f'Percent of correct predictions among leads predicted as converted is {round(P,2)*100}%')","d98c59ad":"R = true_positive\/(true_positive+false_negative)\nprint(f'Percent of correct predictions among actual converteds is {round(R,2)*100}%')","c101b162":"tpr = true_positive\/(true_positive+false_negative)\nfpr = false_positive\/(true_negative+false_positive)\nprint(f'The fraction of true positives among all positive examples: {tpr}\\nThe fraction of false positives among all negative examples: {fpr}')","9eecc8c2":"scores = []\n\nthresholds = np.linspace(0,1,101)\n\nfor t in thresholds:\n    tp = ((preds>=t).reshape(-1,1)&(val_y==1)).sum()\n    fp = ((preds>=t).reshape(-1,1)&(val_y==0)).sum()\n    fn = ((preds<t).reshape(-1,1)&(val_y==1)).sum()\n    tn = ((preds<t).reshape(-1,1)&(val_y==0)).sum()\n    scores.append((t,tp,fp,fn,tn))","90b57634":"df_scores = pd.DataFrame(scores)\ndf_scores.columns = ['thresholds','tp','fp','fn','tn']\ndf_scores[::10]","7f2c63d6":"df_scores['tpr'] = df_scores.tp \/ (df_scores.tp+df_scores.fn)\ndf_scores['fpr'] = df_scores.fp \/ (df_scores.fp+df_scores.tn)\ndf_scores[::10]","bab97293":"plt.plot(df_scores.thresholds, df_scores.tpr, label='TPR')\nplt.plot(df_scores.thresholds, df_scores.fpr, label='FPR')\nplt.xlabel('Thresholds')\nplt.title('TPR and FPR')\nplt.legend()\nplt.show()","c5251352":"np.random.seed(1)\ny_rand = np.random.uniform(0,1, size=len(val_y))\ny_rand = y_rand.reshape(-1,1)","a1f076a5":"def tpr_fpr_dataframe(y_val, y_pred):\n    scores = []\n    thresholds = np.linspace(0,1,101)\n    \n    for t in thresholds:\n        tp = ((y_pred>=t)&(y_val==1)).sum()\n        fp = ((y_pred>=t)&(y_val==0)).sum()\n        fn = ((y_pred<t)&(y_val==1)).sum()\n        tn = ((y_pred<t)&(y_val==0)).sum()\n        scores.append((t,tp,fp,fn,tn))\n        \n        df_scores = pd.DataFrame(scores)\n    df_scores.columns = ['thresholds','tp','fp','fn','tn']\n    \n    df_scores['tpr'] = df_scores.tp \/ (df_scores.tp+df_scores.fn)\n    df_scores['fpr'] = df_scores.fp \/ (df_scores.fp+df_scores.tn)\n    \n    return df_scores","3f8220af":"df_rand = tpr_fpr_dataframe(val_y, y_rand)","8e6eda68":"df_rand[::10]","0177dad1":"plt.plot(df_rand.thresholds, df_rand.tpr, label='TPR')\nplt.plot(df_rand.thresholds, df_rand.fpr, label='FPR')\nplt.xlabel('Thresholds')\nplt.title('TPR and FPR for the random model')\nplt.legend()\nplt.show()","fa729771":"num_neg = (val_y==0).sum()\nnum_pos = (val_y==1).sum()\n\ny_ideal = np.repeat([0,1], [num_neg, num_pos])\ny_pred_ideal = np.linspace(0,1, num_neg+num_pos)\n\ndf_ideal = tpr_fpr_dataframe(y_ideal, y_pred_ideal)\ndf_ideal[::10]","b1f9de05":"plt.plot(df_ideal.thresholds, df_ideal.tpr, label='TPR')\nplt.plot(df_ideal.thresholds, df_ideal.fpr, label='FPR')\nplt.xlabel('Thresholds')\nplt.title('TPR and FPR for the ideal model')\nplt.legend()\nplt.show()","de5a5da6":"plt.figure(figsize=(5,5))\n\nplt.plot(df_scores.fpr, df_scores.tpr, label=\"Model\")\nplt.plot(df_rand.fpr, df_rand.tpr,'b--', label=\"Random\")\nplt.plot(df_ideal.fpr, df_ideal.tpr,'y--',label=\"Ideal\")\nplt.legend()\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC curve')\n\nplt.show()","31dd2b33":"from sklearn.metrics import roc_curve","1637d298":"fpr, tpr, thresholds = roc_curve(val_y, preds.reshape(-1,1))","b2ebfe9b":"plt.figure(figsize=(5,5))\nplt.plot(fpr,tpr)\nplt.plot([0,1],[0,1], 'b--')\nplt.show()","fcae3354":"from sklearn.metrics import auc","a2e2cae5":"auc(fpr,tpr)","0ca0a4eb":"from sklearn.metrics import roc_auc_score","ef094b78":"roc_auc_score(y_ideal, y_pred_ideal)","003ca6e8":"roc_auc_score(val_y, y_rand)","73adeff5":"def train(df,y):\n    cate = df[cat+numerical].to_dict(orient='rows')\n    \n    dv = DictVectorizer(sparse=False)\n    dv.fit(cate)\n    \n    X = dv.transform(cate)\n    \n    model = LogisticRegression(solver='liblinear')\n    model.fit(X,y)\n    \n    return dv, model","be518a3b":"def predict(df, dv, model):\n    cate = df[cat+numerical].to_dict(orient='rows')\n    \n    X = dv.transform(cate)\n    y_pred = model.predict_proba(X)[:,1]\n    \n    return y_pred","753208ba":"from sklearn.model_selection import KFold\n\nkfold = KFold(n_splits=10, shuffle=True, random_state=1)\n\naucs = []\n\nfor train_idx, val_idx in kfold.split(train_full):\n    df_train = train_full.iloc[train_idx]\n    df_val = train_full.iloc[val_idx]\n    \n    y_train = df_train['converted'].values.reshape(-1,1)\n    y_val = df_val['converted'].values.reshape(-1,1)\n    \n    dv, model = train(df_train, y_train)\n    y_pred = predict(df_val, dv, model)\n    \n    auc = roc_auc_score(y_val, y_pred)\n    aucs.append(round(auc,3))","6c85036e":"print(aucs)\nprint(f'auc = {np.mean(aucs)} +- {np.std(aucs)}')","429d2db4":"test_dict = test_X[cat+numerical].to_dict(orient='rows')","92fac5cc":"test_dict[0]","ba478a6b":"X_test = dv.transform(test_dict)\nX_test[0]","b6927bec":"dv.get_feature_names()","4d5a2197":"preds_test = model.predict_proba(X_test)","86242d28":"preds_test = preds_test[:,1]","673e1561":"preds_test[:5]","931c4f7f":"pred_test =  (preds_test>0.5).astype(int).reshape(-1,1)","72b12b99":"pred_test[:5]","b13c2d26":"(pred_test==test_y).mean()","35af5f2f":"t = 0.4\n\npredict_convert_t = (preds_test>=t).reshape(-1,1)\npredict_no_convert_t = (preds_test<t).reshape(-1,1)\n\nactual_convert_t = (test_y==1)\nactual_no_convert_t = (test_y==0)\n\ntrue_positive_t = (predict_convert_t & actual_convert_t).sum()\ntrue_negative_t = (predict_no_convert_t & actual_no_convert_t).sum()\n\nfalse_positive_t = (predict_convert_t & actual_no_convert_t).sum()\nfalse_negative_t = (predict_no_convert_t & actual_convert_t).sum()","bdad857d":"confussion_table_t = np.array([[true_negative_t, false_positive_t],[false_negative_t,true_positive_t]])\nprint(f'Confussion Table:\\n{confussion_table_t}')","be163348":"confussion_table_t\/confussion_table_t.sum()","b427a91b":"P_t = true_positive_t\/(true_positive_t+false_positive_t)\nR_t = true_positive_t\/(true_positive_t+false_negative_t)\nprint(f'Precision: {P_t}\\nRecall: {R_t}')","2a06b144":"df_scores_t = tpr_fpr_dataframe(test_y, preds_test.reshape(-1,1))\ndf_scores_t[::10]","62db95fd":"fpr_t, tpr_t, thresholds_t = roc_curve(test_y, preds_test.reshape(-1,1))","29d7ccb6":"plt.figure(figsize=(5,5))\nplt.plot(fpr_t,tpr_t)\nplt.plot([0,1],[0,1], 'b--')\nplt.show()","e57d28bc":"Column names in data frame is key and rows are values.","89a69a6d":"The fraction of true positives among all converted leads: the larger TPR is, the better, The fraction of false positives among all non-converted leads: the smaller the FPR is, the better.","cb675882":"7. What is your current occupation","500b5ef6":"***Dependency between categorical variables and target variable***","293df692":"#### Initial data preparation","50ffe90d":"#### Area under the ROC curve (AUC)","d33e24cd":"Housewife and Working Professional categories are most likely to be converted. There are sharp differences between values.","3b86c0a6":"#### Precision and recall","c741c2e3":"The baseline makes it easier to see how far the ROC curve of our model is from that of a random model. The top-left corner(0,1) is  the \"ideal spot\": the closer our models get to it, the better. ","9957a8cd":"#### Logistic regression","5ca2bb1b":"11. Page Views Per Visit","fc4384a7":"9. What matters most to you in choosing a course","c48ac81a":"And also we check and correct if columns name are not written differently.","3c1ce6ae":"In our data, 2832 leads converted their contract and 4560 leads didn't convert. In order to find convering rate we can divide 2831 by 4560 or use mean() funtion, which will do the same thing.","10978e61":"#### K-fold cross validation","51da1459":"We check what values city column have when Country column's variables are missing.","5d345475":"We see some rows are named \"Select\". Those leads haven'y chosen the How did you hear about X Education, and we also fill missing values with \"Select\".","a43be0e2":"3. City","c199a326":"We vectorized rows into array, to see the column names we can use get_feature_names() funtion.","82ae74b8":"The ROC curve shows the relationship between the FPR and TPR of a model.","274a42f0":"Let's make two lists: categorical, containing names of categorical variables and numerical, containing names of numerical variables","72b4ef81":"#### On test data","4ec06aff":"We want ROC curve to be close to the ideal spot as possible and as far ffrom the random baseline as possible.","c1940e59":"1. Lead Source","46093e70":"2. Last Activity","0f0bedc7":"All columns have the correct dtype.","517fb7a0":"X Education sells online courses to industry professionals. The company markets its courses on several websites and search engines like Google. Once these people land on the website, they might browse the courses or fill up a form for the course or watch some videos. When these people fill up a form providing their email address or phone number, they are classified to be a lead. Moreover, the company also gets leads through past referrals. Once these leads are acquired, employees from the sales team start making calls, writing emails, etc. Through this process, some of the leads get converted while most do not. The typical lead conversion rate at X education is around 30%.","6cc96734":"Let's make all column names follow the same nameing convention","ae8bd8fa":"10. TotalVisits","84560a2d":"An AUC of 0.9 is indicative of a reasonably good model.","8647fdf3":"#### True positive rate and false positive rate","527edd36":"#### Random baseline model","caec53a6":"We see that 82% of prediction is right.","4ccc1b7b":"We choose categorical variables with me score more than 0.01.","6698e824":"In 'Lead Source' column, we fill missing values with the most frequent one","b3138b6c":"## Problem Statement","152202b1":"5. How did you hear about X Education","e118d74a":"The TPR and FPR for our model evaluated at different thresholds.","21491bcf":"Totalvisits and total_time_spent_on_website has positive correlation, the more leads visit website and the more time they spent on website, the more leads are converted. But page_views_per_visit\thas negative correlation, the more number of pages on the website are viewed during the visits, the less they are converted.","6ed08ee6":"Mumbai and Maharashtra are in India, we can fill that missing rows with India. But for rest we will fill with \"unknown\".","6cde3c3f":"#### Confusion Table","379646e1":"If column has missing values more than 3000 it is not an efficient data. We drop that columns.","097d1794":"Here, there is also 84% accuray of our model.","98e3792c":"It's enough data to create our model ","e330bbb5":"4. Specialization","9038ea77":"## Business Goal","cc5b3e99":"Split our data into trian and test datasets","ed1f8fb1":"#### Explotary Data Analysis","d8c5046a":"#### The ideal model","039cab32":"6. Country","fb1eb46b":"8. Lead Profile","4e47fd8d":"We see some rows are named \"Select\". Those leads haven'y chosen the city, and we also fill missing values with \"Select\".","82905e0b":"We check and correct each column.","da85e5b5":"If we choose specific column and find converted mean, we will know converting rate of that group. We can do it by groupby function.\n\nIf difference between global converting rate and that column's converting rate is positive, it means that this group of leads convert their contracts more than general. If it's negative, they convert less than general. And if difference between the rates is the small, the value is not important when predicting converting because this group of leads is not really different from rest of leads.\n\nReliability = global rate \/ group rate. If reliability is lower than 1, the group has lower reliability. And if group reliability is around 1, it's not different from global rate. And if it's above 1, it means that it has more reability that leads will convert their contracts. ","094db114":"***Vectorizing variables***","8cef61b0":"#### ROC Curve","eae8ef73":"To predict leads will be converted or not we will use logistic regression model","1fa4d099":"We see some rows are named \"Select\". Those leads haven'y chosen the specialization, and we also fill missing values with \"Select\".","ad7ad859":"***Correcaltion Coefficient***","c70d3a6d":"X Education needs help in selecting the most promising leads, i.e. the leads that are most likely to convert into paying customers. The company needs a model wherein you a lead score is assigned to each of the leads such that the customers with higher lead score have a higher conversion chance and the customers with lower lead score have a lower conversion chance. The CEO, in particular, has given a ballpark of the target lead conversion rate to be around 80%.","af9f4236":"There're not duplicates, in our data","558d065a":"If we don't have information about last activity of leads, let's simply fill that rows with \"Other\""}}