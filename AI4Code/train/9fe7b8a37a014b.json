{"cell_type":{"1f835594":"code","c775f2de":"code","6a4651b4":"code","b25213b7":"code","e2dc50c9":"markdown","e40e3e83":"markdown","5257f250":"markdown","7eea59a6":"markdown"},"source":{"1f835594":"import numpy as np\nimport json\nimport os\nfrom tqdm import tqdm\ndata_dir = '\/kaggle\/input\/CORD-19-research-challenge'\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport nltk\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\nimport tensorflow_hub as hub\nimport matplotlib.pyplot as plt\nmodule_url = \"https:\/\/tfhub.dev\/google\/universal-sentence-encoder\/1?tf-hub-format=compressed\"\nembed = hub.Module(module_url)\n","c775f2de":"def get_json_data(folder):\n    text  =  \"\"\n    #title = \"\"\n    data = []\n    for txt in os.listdir(folder):\n        if not txt.startswith('.') and txt in ['biorxiv_medrxiv','comm_use_subset','custom_license','noncomm_use_subset']:\n            for filename in tqdm(os.listdir(f\"{folder}\/{txt}\/{txt}\")):\n                if not filename.startswith('.'):\n                    json_data =  json.load(open(f\"{folder}\/{txt}\/{txt}\/{filename}\",'rb'))\n                    for t in json_data['body_text']:            \n                        text += t['text']+'\\n\\n'\n\n    return text\ntxt_data = get_json_data(data_dir)","6a4651b4":"print('sentences containing vaccines or therapeutics ...')\ndoc = \"\"\nfor sentnece in txt_data.split('\\n'):\n    if('vaccines' in sentnece) or ('therapeutics' in sentnece):\n        #word_tokens = word_tokenize(sentnece)\n        doc +=sentnece \n\nprint('Removing stopwords ...')\n\nstop_words = set(stopwords.words('english'))\ntext = \"\"\nfor i in doc.split(' '):\n    if i not in stop_words:\n        text += ' ' + i.lower()\nCorpus = []\nprint('Focusing on short sentences for visualization  ...')\nfor i in text.split(','):\n    if ('vaccines' in i) or ('therapeutics' in i): \n        if len(i.split(' ')) < 15:\n            Corpus.append(i)","b25213b7":"messages2 = Corpus[:10]\nsimilarity_input_placeholder = tf.placeholder(tf.string, shape=(None))\nsimilarity_message_encodings = embed(similarity_input_placeholder)\nwith tf.compat.v1.Session()  as session:\n    session.run(tf.global_variables_initializer())\n    session.run(tf.tables_initializer())\n    message_embeddings_ = session.run(similarity_message_encodings, feed_dict={similarity_input_placeholder: messages2})\n\n    corr = np.inner(message_embeddings_, message_embeddings_)\n    print(corr)\n    def heatmap(x_labels, y_labels, values):\n        fig, ax = plt.subplots()\n        im = ax.imshow(values)\n        # We want to show all ticks...\n        ax.set_xticks(np.arange(len(x_labels)))\n        ax.set_yticks(np.arange(len(y_labels)))\n        # ... and label them with the respective list entries\n        ax.set_xticklabels(x_labels)\n        ax.set_yticklabels(y_labels)\n        # Rotate the tick labels and set their alignment.\n        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=10,\n             rotation_mode=\"anchor\")\n        # Loop over data dimensions and create text annotations.\n        for i in range(len(y_labels)):\n            for j in range(len(x_labels)):\n                text = ax.text(j, i, \"%.2f\"%values[i, j],\n                               ha=\"center\", va=\"center\", color=\"w\", fontsize=6)\n\n        fig.tight_layout()\n        plt.show()\n    heatmap(messages2, messages2, corr)\n","e2dc50c9":"<h4> The goal of this kernal is basicly to scrutinize articles to asses similaries between sentences containing vaccines and\/therapeutics by following steps bellow:<\/h4>\n\n> Import required libraries\n\n> Import universal sentence encoder\n\n> Import the data\n\n> Data cleansing and preprocessing\n\n> Computing sentence similarity-matrix\n\n**Import required libraries and universal sentence encoder**","e40e3e83":"**Import the data**","5257f250":"**Data cleansing and preprocessing**\n\nFor better understanding the data is crisual to make the data clean by removing stopwords and choosing sentences containing vaccines and\/ therapeutics","7eea59a6":"**Computing sentence similarity-matrix**\n\nTo simplify and better visualize the result the first 10 sentences are choosen feel free to increase sentences."}}