{"cell_type":{"132a8211":"code","8e2590a2":"code","c51ae573":"code","c01db048":"code","7529292b":"code","90ece7cd":"code","6c896cc3":"code","9ed3a924":"code","a91b0aad":"code","06ec5618":"code","97488374":"code","1cc183ce":"code","ae3e4e8a":"code","b1abb547":"code","8bc87c89":"code","972a2de4":"code","41a3ccaf":"code","68fc660c":"code","67269b53":"code","53162ec0":"code","c2eddff1":"code","f8dea835":"code","a92a284b":"code","d098ddca":"code","da3c1fa5":"code","d0575396":"code","1416292c":"code","250429ae":"code","b411dbb9":"code","43637d77":"code","1426c94d":"code","db1a6d80":"code","7f362162":"code","1e62ae1a":"code","8a889312":"code","374c40af":"code","858cdafc":"code","3cc2561c":"code","6a9ea19d":"code","97f24fa9":"code","e1e6e7d4":"code","246d79b3":"code","41e94e44":"code","1cae9573":"code","427cad4e":"code","71965b5c":"code","b2ecc860":"code","97d9c215":"code","e2d4fa15":"code","4a315e91":"code","8323631b":"code","86be2005":"code","5a7a14a8":"code","e4408fba":"code","56727fb2":"code","42553a4f":"code","0d523fd5":"code","85592193":"code","bea6109c":"code","2fe03f7c":"code","5e0ae94b":"markdown","ad5dd70f":"markdown","40d8c905":"markdown","fd03577d":"markdown","bd2131ca":"markdown","d349c499":"markdown","4eb0bf99":"markdown","5e421abb":"markdown","1ae73ec6":"markdown","45aaba45":"markdown","4c419370":"markdown","7bfb84ee":"markdown","ebc76b75":"markdown","6282a37f":"markdown","e0f49eba":"markdown","06dac341":"markdown","61ef34bd":"markdown","8a239e5e":"markdown","6909403c":"markdown","5dd2f1a1":"markdown"},"source":{"132a8211":"# Imporing required libraries for project\n\nimport pandas as pd # for data manipluation\nimport numpy as np  # for data calculations and statistical measurement\nimport matplotlib.pyplot as plt #for ineractive visualization charts\nimport seaborn as sns #for ineractive visualization charts\n%matplotlib inline \nimport warnings  # For warnings\nwarnings.filterwarnings(\"ignore\") # To ignore unwanted warnings\n\n\nimport itertools\nimport statsmodels.api as sm # for applying stats model to do forecasting","8e2590a2":"# Reading Dataset and loading into variable\n\ndata = pd.read_csv(\"..\/input\/supermarket-sales\/supermarket_sales - Sheet1.csv\")\n          \ndata.head()\n\n","c51ae573":"# looking at first few rows of data\npd.set_option('display.max_columns', None)\n\ndata.head()","c01db048":"# structer Of data\ndata.shape","7529292b":"# Checking data type and null values for each column\ndata.info()","90ece7cd":"# Checking for null values\ndata.isnull().sum()","6c896cc3":"# Checking five Point Summary For All Numerical Columns\ndata.describe()","9ed3a924":"# Exaploring unqie values of Branch column\ndata['Branch'].value_counts()","a91b0aad":"# Exaploring unqie values of City column\ndata['City'].value_counts()","06ec5618":"# Exaploring unqie values of Gender column\ndata['Gender'].value_counts()","97488374":"# Exaploring unqie values of Customer Type column\ndata['Customer type'].value_counts()","1cc183ce":"# Exaploring unqie values of Product line column\ndata['Product line'].value_counts()","ae3e4e8a":"# Exaploring unqie values of Payment column\ndata['Payment'].value_counts()","b1abb547":"# Converting our date and time column to datetime\ndata['Date'] = pd.to_datetime(data['Date'])\ndata.head(2)","8bc87c89":"# Creating new column by combing date and time column\ndata['DateTime'] = pd.to_datetime(data.Date.astype('str')+' '+data.Time.astype('str'))","972a2de4":"# Cross checking our changes \nprint(data['DateTime'].dtype)","41a3ccaf":"#Pritinng data after making changes\ndata.head()","68fc660c":"data.shape","67269b53":"#Creating a column for Hours\ndata['Hour'] = pd.to_datetime(data['Time'], format ='%H:%M').dt.hour\ndata.head()","53162ec0":"#Getting data only for city yangon\nyangon = data.loc[data['City'] == 'Yangon']","c2eddff1":"#printing head of yangon data\nyangon.head()","f8dea835":"# printing columns for yangon data\nyangon.columns","a92a284b":"# Removing all columns apart from date and total sales \nr_col = ['Invoice ID', 'Branch', 'City', 'Customer type', 'Gender',\n       'Product line', 'Unit price', 'Quantity', 'Tax 5%',\n       'Time', 'Payment', 'cogs', 'gross margin percentage', 'gross income',\n       'Rating', 'DateTime', 'Hour']\n\n\nyangon.drop(r_col, axis =1 , inplace=True)","d098ddca":"# looking at data after dropping columns\nyangon","da3c1fa5":"# changing order of column\nyangon = yangon[[\"Date\",\"Total\"]]\nyangon","d0575396":"# sorting value for by date and seting index\nyangon = yangon.sort_values('Date')","1416292c":"yangon","250429ae":"yangon.set_index('Date', inplace=True)","b411dbb9":"yangon","43637d77":"yangon.columns","1426c94d":"#Resampling the data using Calender Day Frequency and taking their average\n#yangon = yangon['Total'].resample('D').mean()\n# D = Calendar Day frequency","db1a6d80":"yangon.head(4)","7f362162":"yangon.shape","1e62ae1a":"yangon.plot(figsize=(15,6),legend=True)\nplt.ylabel(\"Sales\",fontsize=18)\nplt.xlabel(\"Date\",fontsize=18)\nplt.title(\"Date Vs Sales\",fontsize=20)\nplt.show()","8a889312":"from statsmodels.tsa.stattools import adfuller","374c40af":"test_result = adfuller(yangon['Total'])","858cdafc":"test_result","3cc2561c":"#Resampling the data using Calender Day Frequency and taking their average\nyangon = yangon['Total'].resample('D').mean()\nyangon.head()\n# D = Calendar Day frequency","6a9ea19d":"from pylab import rcParams as rc","97f24fa9":"rc['figure.figsize'] = 10, 14","e1e6e7d4":"decomposition = sm.tsa.seasonal_decompose(yangon,model='additive', freq=30)","246d79b3":"#Finding trend,seasonal,observed and residual values\n\nfig = decomposition.plot()\nplt.show()\n# y(t) = Level + Trend + Seasonality + Noise --> Additive","41e94e44":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf","1cae9573":"fig = sm.graphics.tsa.plot_acf(yangon, lags=40)","427cad4e":"fig = sm.graphics.tsa.plot_pacf(yangon, lags=40)","71965b5c":"p=d=q=range(0,2)","b2ecc860":"p,d,q","97d9c215":"pdq = list(itertools.product(p,d,q))","e2d4fa15":"pdq","4a315e91":"seasonal_pdq = [(x[0],x[1],x[2], 12) for x in pdq]","8323631b":"seasonal_pdq","86be2005":"for param in pdq:\n    for param_seasonal in seasonal_pdq:\n        try:\n            mod = sm.tsa.statespace.SARIMAX(yangon,order = param, seasonal_order = param_seasonal ,\n                                            enforce_stationarity= False , enforce_invertibility= False )\n            results = mod.fit()\n            \n            print('ARIMA{} x {} 12 -- AIC : {}'.format(param, param_seasonal, results.aic))\n            \n        except:\n             continue","5a7a14a8":"mod = sm.tsa.statespace.SARIMAX(yangon,\n                               order=(1,0,1),\n                               seasonal_order= (1,1,1,12),\n                               enforce_stationarity = False,\n                               enforce_invertibility=False)","e4408fba":"results = mod.fit()","56727fb2":"print(results.summary().tables[1])","42553a4f":"results.plot_diagnostics(figsize=(16,8))\nplt.show()","0d523fd5":"pred = results.get_prediction(start = pd.to_datetime('2019-01-01'), dynamic = False)\npred_ci = pred.conf_int()\n\nax = yangon['2019':].plot(label= 'observed')\n\npred.predicted_mean.plot(ax = ax, label = 'One step ahead Forecast',\n                        alpha = 7, figsize= (14,7))\n\nax.fill_between(pred_ci.index,\n               pred_ci.iloc[:,0],\n               pred_ci.iloc[:,1],color = 'k', alpha= 0.2)\n\nax.set_xlabel('Date')\nax.set_ylabel('Total')\nplt.legend()\n\nplt.show()","85592193":"yangon_forecasted = pred.predicted_mean\nyangon_truth = yangon['2019-01-01':]\nmse = ((yangon_forecasted - yangon_truth) ** 2).mean()\n\nprint('MSE of forecast :{}'.format(round(mse,2)))","bea6109c":"pred_uc = results.get_forecast(steps = 10)\npred_ci = pred_uc.conf_int()\n\nax = yangon.plot(label='observed', figsize=(10,8))\npred_uc.predicted_mean.plot(ax=ax, label='Forecast')\nax.fill_between(pred_ci.index,\n               pred_ci.iloc[:,0],\n               pred_ci.iloc[:,1],color='k',alpha=0.6)\nax.set_xlabel('Date')\nax.set_ylabel('Total')\n\nplt.legend()\nplt.show()","2fe03f7c":"pred_uc = results.get_forecast(steps = 60)\npred_ci = pred_uc.conf_int()\n\nax = yangon.plot(label='observed', figsize=(10,8))\npred_uc.predicted_mean.plot(ax=ax, label='Forecast')\nax.fill_between(pred_ci.index,\n               pred_ci.iloc[:,0],\n               pred_ci.iloc[:,1],color='k',alpha=0.6)\nax.set_xlabel('Date')\nax.set_ylabel('Total')\n\nplt.legend()\nplt.show()","5e0ae94b":"**There are three unique values for payment and highest payment mode used is Ewallet.**","ad5dd70f":"# Basic Understanding of Data","40d8c905":"## **Resampling the data**","fd03577d":"#### **We're using Dickey Fuller Test here to test for stationarity. The Dickey Fuller Test gives us 5 values, namely - ADF Test Statitic, p-value, \\#Lags used & Number of Observations used. However, our main focus here is on the p-value.**\n\n#### **We are assuming our H0 as \"Our data is not stationary\" and H1 as \"Our data is stationary\".**\n\n#### From the above 5 values, we see that our p-value is 2.034195712964938e-30 which is 0.000000000000000000000000000002034195712964938 in real numbers. Therefore, we can see that our p-value is less than 0.05 and hence we cannot accept our null hypothesis and that the data is stationary.","bd2131ca":"**We can see that there are no missing values in our dataset, hence we do not need to perform any data handling process for our data.**","d349c499":"#### We have used 10 step forecasting for preidcting the sales for the next 10 days.","4eb0bf99":"**There are a total 5 unique values for product line column and the highest is Fashion and accessories product values are in product line column.**","5e421abb":"**From the above output we can see that most of the column is having proper data type but date column is not in proper format. we will change it to date time before starting our analysis. by combing date and time column and changing it's data type to datetime.**","1ae73ec6":"**We can see that date column datatype is changed to datetime and also newly created column datetime is being added to our main data.**","45aaba45":"**After printing unique values and their counts for Branch and City column it seems that both are same meaning that if you observe then city column has 340 values of  city 'Yangon' and branch column has same 340 values of branch 'A'. The same thing you can notice for other two cities and branches. So, If we use either of the column for analysis it will be same.**","4c419370":"#### Similarly, You can follow the same steps for predicting sales of other two cities.","7bfb84ee":"# Data Description:<hr>\n\nThe data which we are going to use is downloaded from <a herf =\"https:\/\/www.kaggle.com\/aungpyaeap\/supermarket-sales\">Kaggle<\/a>. This data is about supermarket sales, and this data is for three diffrenet brnach over the period of three months between January 2019 to March 2019.","ebc76b75":"# **Sales Forecast For City Yangon**","6282a37f":"Below is brief description of each columns in our data.\n\n\n\n*    Invoice id (Numerical): Computer generated sales slip invoice identification number\n*    Branch (Categorical): Branch of supercenter (3 branches are available identified by   A, B and C).\n*   City (Categorical): Location of supercenters\n*   Customer type (Categorical): Type of customers, recorded by Members for customers using member card and Normal for without member card.\n\n*   Gender (Categorical): Gender type of customer\n*   Product line: General item categorization groups - Electronic accessories, Fashion accessories, Food and beverages, Health and beauty, Home and lifestyle, Sports and travel\n*   Unit price (Numerical): Price of each product in $\n*   Quantity (Numerical): Number of products purchased by customer\n*   Tax (Numerical): 5% tax fee for customer buying\n*   Total (Numerical): Total price including tax\n*   Date (Numerical): Date of purchase (Record available from January 2019 to March 2019)\n*   Time (Numerical): Purchase time (10am to 9pm)\n*   Payment (Categorical): Payment used by customer for purchase (3 methods are available \u2013 Cash, Credit card and Ewallet)\n*   COGS (Numerical): Cost of goods sold\n*   Gross margin percentage (Numerical): Gross margin percentage\n*   Gross income (Numerical): Gross income generated from particular product sold\n*   Rating (Numerical): Customer statification rating on their overall shopping experience (On a scale of 1 to 10)\n\n\n","e0f49eba":"#### In the above graph, we have plotted for the next 50 days or we can also say that we are predicting for the next 2 months.","06dac341":"# **Forecasting with ARIMA**","61ef34bd":"# **Testing for Stationarity**","8a239e5e":"**Form the five point summary of numerical columns we can notice that highest individual total sale noted was 1042.650 and highest individual quantity sold was 10. Overall Average Customer rating is 6.97.**","6909403c":"**There are a total 1000 rows and 17 columns in our data.**","5dd2f1a1":"**There are 501 values for member customer type and 499 values for normal cutomer type.**"}}