{"cell_type":{"c923467a":"code","29315d43":"code","1e5f93d5":"code","0ed082c6":"code","de6c35d4":"code","d8f6581b":"code","f8f72582":"code","4ad1f1fd":"code","ce1f984e":"code","13aa2248":"code","22c26990":"code","fac98272":"code","885fcb2c":"code","fd0f4111":"markdown","8e23545f":"markdown","32ab86f7":"markdown","e48996f7":"markdown","987a3a29":"markdown","3d60f010":"markdown","b00f2598":"markdown"},"source":{"c923467a":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nimport plotly as py\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\npy.offline.init_notebook_mode(connected=True)\nfrom sklearn.cluster import KMeans\nimport warnings\nimport os\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\")\npy.offline.init_notebook_mode(connected = True)","29315d43":"df = pd.read_csv('..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')\ndf.head()","1e5f93d5":"df.info()","0ed082c6":"df.describe().T","de6c35d4":"df.nunique()","d8f6581b":"# Add histogram data\nx1 = df['Age']\nx2 = df['Annual Income (k$)']\nx3 = df['Spending Score (1-100)']\n# Group data together\nhist_data = [x1, x2, x3]\ngroup_labels = ['Age', 'Annual Income (k$)', 'Spending Score (1-100)']\n\nrug_text_one = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j',\n                'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't',\n                'u', 'v', 'w', 'x', 'y', 'z']\nrug_text_two = ['aa', 'bb', 'cc', 'dd', 'ee', 'ff', 'gg', 'hh', 'ii', 'jj',\n                'kk', 'll', 'mm', 'nn', 'oo', 'pp', 'qq', 'rr', 'ss', 'tt',\n                'uu', 'vv', 'ww', 'xx', 'yy', 'zz']\n\nrug_text_three = ['aaa', 'bbb', 'ccc', 'ddd', 'eee', 'fff', 'ggg', 'hhh', 'iii', 'jjj',\n                'kkk', 'lll', 'mmm', 'nnn', 'ooo', 'ppp', 'qqq', 'rrr', 'sss', 'ttt',\n                'uuu', 'vvv', 'www', 'xxx', 'yyy', 'zzz']\n\nrug_text = [rug_text_one, rug_text_two, rug_text_three] # for hover in rug plot\ncolors = ['rgb(0, 0, 100)', 'rgb(0, 200, 200)','rgb(0, 0, 200)']\n\n# Create distplot with custom bin_size\nfig = ff.create_distplot(\n    [x1, x2 ,x3], group_labels, bin_size=3,\n    rug_text=rug_text, colors=colors)\n\nfig.update_layout(title_text='Customized Distplot')\nfig.show()","f8f72582":"# -- 3. data visualization --\n\n# 3.1. Gender ratio:\ndf.Gender = df.Gender.replace({'Female': 1, 'Male': 0})\ngender_counts = df.Gender.value_counts()\nfig = px.pie(gender_counts, title='Gender Ratio', values='Gender', names=['Male', 'Female'], hole=0.5)\nfig.show()","4ad1f1fd":"plt.rcParams['figure.figsize'] = (15, 8)\nsns.countplot(df['Age'], palette = 'hsv')\nplt.title('Distribution of Age', fontsize = 20)\nplt.show()","ce1f984e":"plt.rcParams['figure.figsize'] = (20, 8)\nsns.countplot(df['Annual Income (k$)'], palette = 'rainbow')\nplt.title('Distribution of Annual Income', fontsize = 20)\nplt.show()","13aa2248":"fig = px.scatter_matrix(df,\n    dimensions=['Age', 'Annual Income (k$)', 'Spending Score (1-100)'],\n    color=\"Gender\")\nfig.show()","22c26990":"plt.rcParams['figure.figsize'] = (20, 8)\nsns.countplot(df['Spending Score (1-100)'], palette = 'copper')\nplt.title('Distribution of Spending Score', fontsize = 20)\nplt.show()","fac98272":"kmeans = KMeans(n_clusters = 5, init=\"k-means++\", max_iter = 500, n_init = 10, random_state = 123)\nidentified_clusters = kmeans.fit_predict(X)\n\n\ndata_with_clusters = df.copy()\ndata_with_clusters['Cluster'] = identified_clusters\nfig = px.scatter_3d(data_with_clusters, x = 'Age', y='Annual Income (k$)', z='Spending Score (1-100)',\n              color='Cluster', opacity = 0.8, size='Age', size_max=30)\nfig.show()","885fcb2c":"import scipy.cluster.hierarchy as sch\nX = df.iloc[:,2:4].values\nfig = ff.create_dendrogram(X,\n                           linkagefun = lambda x: sch.linkage(x, \"ward\"),)\n\n# Ward minimizes the variance of the points inside a cluster.\n\nfig.update_layout(title = 'Hierarchical Clustering', xaxis_title='Customers',\n                   yaxis_title='Euclidean Distance', width=700, height=700)\n\nfig.show()","fd0f4111":"1. Compare data points to find most similar data points to each other.\n\n2. Merge these to create a cluster.\n\n3. Compare clusters to find most similar clusters and merge again.\n\n4. Repeat until all data points in a single cluster.","8e23545f":"**Data Visualization**","32ab86f7":"**K-means** clustering is a simple and elegant approach for partitioning a data set into K distinct, non-overlapping clusters. To perform K-means clustering, we must first specify the desired number of clusters K; then the K-means algorithm will assign each observation to exactly one of the K clusters.","e48996f7":"**Hierarchical Clustering Algorithm**\n\nOne potential disadvantage of K-means clustering is that it requires us to pre-specify the number of clusters K. Hierarchical clustering is an alternative approach which does not require that we commit to a particular choice of K. Hierarchical clustering has an added advantage over K-means clustering in that it results in an attractive tree-based representation of the observations, called a dendrogram","987a3a29":"**Read input data**","3d60f010":"Clutsering refers to a very board set of techniques for finding subgroups, or clusters, in a data set. When we cluster the observations of a data set, we seek to partition them into distinct groups so that the observations within each group are quite similar to each other, while observations in different groups are quite different from each other. Of course, to make this concrete, we must define what it means for two or more observations to be similar or different. Indeed, this is often a domain-specific consideration that must be made based on knowledge of the data being studied.","b00f2598":"**Importing Libraries**"}}