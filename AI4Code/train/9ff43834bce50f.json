{"cell_type":{"a22437fd":"code","a1e10b38":"code","faa846c8":"code","d6737ee0":"code","44a613a0":"code","0c11b9d3":"code","f7652ebc":"code","a622d9c0":"code","9338b75c":"code","81b64df6":"code","9017289e":"code","c7bc3520":"markdown","9d583074":"markdown","cd55fcbc":"markdown"},"source":{"a22437fd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a1e10b38":"train = pd.read_csv(\"..\/input\/learn-together\/train.csv\")\ntest = pd.read_csv(\"..\/input\/learn-together\/test.csv\")","faa846c8":"train.dtypes\ntest.dtypes","d6737ee0":"inp = train.iloc[:,15:-2].to_string(header=False, index=False, index_names=False).split('\\n')\nvals = [int(''.join(ele.split()),2) for ele in inp]\ntrain['Soil_Type'] = vals\ntrain.drop(train.iloc[:,15:-2], axis=1, inplace=True)\ninp2 = train.iloc[:,11:15].to_string(header=False, index=False, index_names=False).split('\\n')\nvals2 = [int(''.join(ele.split()),2) for ele in inp2]\ntrain['Wilderness_Area'] = vals2\ntrain.drop(train.iloc[:,11:15], axis=1, inplace=True)\ntrain.head()","44a613a0":"X = train.drop(['Cover_Type'], axis = 1)\ny = train.Cover_Type","0c11b9d3":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier","f7652ebc":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)","a622d9c0":"forest_model = RandomForestClassifier(n_estimators=10)\nforest_model.fit(X_train,y_train)","9338b75c":"from sklearn.metrics import mean_absolute_error\n\nval_predictions = forest_model.predict(X_val)\nval_mae = mean_absolute_error(y_val,val_predictions)\nval_mae","81b64df6":"test['Soil_Type'] = test[test.columns[15:-1]].astype(str).apply(''.join,1).apply(int, base=2)\ntest.drop(test.iloc[:,15:-1], axis=1, inplace=True)\ntest['Wilderness_Area'] = test[test.columns[11:15]].astype(str).apply(''.join,1).apply(int, base=2)\ntest.drop(test.iloc[:,11:15], axis=1, inplace=True)\n\ntest.head()","9017289e":"test_preds = forest_model.predict(test)\noutput = pd.DataFrame({'Id': test.Id, 'Cover_Type': test_preds.astype(int)})\noutput.to_csv('submission.csv', index=False)","c7bc3520":"## A try based on reducing the number of features using basic pandas","9d583074":"### Brute force method to compress 40 columns of Soil_Type into one column ","cd55fcbc":"## This is taking too long."}}