{"cell_type":{"140d816d":"code","b03d0b02":"code","0f491e8c":"code","4d999e03":"code","fae4ddba":"code","562cf926":"code","d4dec65c":"code","2cb5ec7e":"code","a4d87831":"code","2469dd26":"code","1b485037":"code","fa5c047f":"code","4dd4a1ce":"code","99cfcfeb":"code","e89136f3":"code","75fc6231":"code","5b3b807d":"code","ec16ca28":"code","bf1445c3":"code","598e9dd3":"code","3e3c9a01":"code","5e4242fa":"code","4599860b":"code","929cdb20":"code","1ee626a2":"code","e1259897":"code","97af3179":"code","51f8a7f1":"code","b8a845bf":"code","56eab7db":"code","a4ece2ed":"code","3b552dd6":"code","9f25b91f":"code","1bb3d4bc":"code","9354febd":"code","48cb1f30":"code","1006e950":"code","262cd109":"code","6d57e71e":"code","06a10f80":"code","f28950e1":"code","f0fd168b":"code","24fefa08":"code","4576b986":"code","9ee2c48e":"code","3266eb16":"code","d96e8f19":"code","77ebadab":"code","084dd1ed":"code","80040af5":"code","5fbed8ae":"code","aa8bbbb1":"code","a2ac8be8":"code","e3cc8655":"code","76c8d159":"code","ff14480c":"code","be7034aa":"code","2ffd2381":"code","17a329b4":"code","76b89065":"code","9ffc7b8c":"code","e8635398":"code","21829a76":"code","9fb140c5":"code","e56070c7":"code","6f4e41ba":"code","1572cb0b":"code","b09dbf60":"code","4722a299":"code","a486c229":"code","33c26baf":"markdown","3899f93b":"markdown","6a850d39":"markdown","e98c9334":"markdown","a391ad4c":"markdown","a8e8e445":"markdown","48458e18":"markdown","f1afd94a":"markdown","e43e8f66":"markdown","75e1c264":"markdown","b93f9b80":"markdown","32343ef4":"markdown","895c5019":"markdown","d0410456":"markdown","5c317ce3":"markdown","e76744e9":"markdown","c27e8161":"markdown","c4581769":"markdown","522f49ae":"markdown","09849ccb":"markdown","8bef8ee4":"markdown","c8d03607":"markdown","d530212d":"markdown","afce1865":"markdown","ece955ec":"markdown","a7da3a9e":"markdown","e0cd334e":"markdown","f1a55f81":"markdown","ac4975c1":"markdown","4d5850e4":"markdown","f50e9e1f":"markdown","65a33292":"markdown","a20701ab":"markdown","3531beb5":"markdown","5f000ec5":"markdown","fd781db2":"markdown","8f314b07":"markdown","fe4fce63":"markdown","a420279b":"markdown","fdbb5406":"markdown","83000774":"markdown","3bcbe801":"markdown","74362235":"markdown","f89322eb":"markdown","8fa5e250":"markdown","86fd26f3":"markdown","733687d1":"markdown","9ebf0430":"markdown","f6ec1030":"markdown","4b35c540":"markdown","847cdec4":"markdown","20363811":"markdown"},"source":{"140d816d":"##Before anything, set your working directory\n#import os\n#os.chdir(\"C:\/Users\/Ezinne\/Desktop\/Adult Salary\")\n\n#os.getcwd()","b03d0b02":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.patches as mpatches\n\n# Import sys and warnings to ignore warning messages \nimport sys\nimport warnings\n\n%matplotlib inline\n\npd.set_option(\"display.max.columns\", None)\n\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")","0f491e8c":"## We read in the excel data file\n\nSalary = pd.read_csv(\"\/kaggle\/input\/adult-income-dataset\/adult.csv\")\n\nSalary.head(5)","4d999e03":"print(len(Salary))\nprint(Salary.shape)","fae4ddba":"##We investigate further to know the various data types of the respective columns\n\nSalary.info()","562cf926":"##Obtain summary statistics of the data\n\nprint(Salary.describe())\nprint(Salary.describe(include = np.object))\n\n##Or you can use print(Salary.describe(include = 'all')) to list summary statistics of all variables at a go","d4dec65c":"Salary.isnull().sum()","2cb5ec7e":"Salary.columns","a4d87831":"##Noticed earlier the presence of a special character, so we investigate this further\n\nSalary.isin(['?']).sum(axis=0)","2469dd26":"Salary['workclass'] = Salary['workclass'].replace('?', np.nan)\nSalary['occupation'] = Salary['occupation'].replace('?', np.nan)\nSalary['native-country'] = Salary['native-country'].replace('?', np.nan)","1b485037":"Salary.isnull().sum()","fa5c047f":"##drop all the resulting null values\nSalary.dropna(how = 'any', inplace = True)\n\nprint(Salary.shape)","4dd4a1ce":"## For convenience we shall rename some columns\n\nSalary.rename(columns = {'educational-num': 'education rank', 'marital-status': 'marital status',\n                        'capital-gain': 'capital gain', 'capital-loss': 'capital loss', 'hours-per-week': 'HPW',\n                        'native-country': 'country', 'fnlwgt': 'Final Weight'}, inplace = True)","99cfcfeb":"Salary.columns","e89136f3":"##To find out the value count of all the variables in the data we run a loop through the data\n\n#for c in Salary.columns:\n#    print(\"----%s----\" %c)\n#    print(Salary[c].value_counts())","75fc6231":"##First we start with a visualization of all continuous variables in the data\n\nsns.pairplot(Salary)","5b3b807d":"print(Salary['age'].value_counts())\n\nSalary['age'].hist(figsize = (6, 6))","ec16ca28":"Salary['age'].skew()","bf1445c3":"##Next we look at the 'Final Weight' variable\n\nprint(Salary['Final Weight'].value_counts())\n\nSalary['Final Weight'].hist(figsize = (5,5))\nplt.show()","598e9dd3":"print(Salary['workclass'].value_counts( sort = False, normalize = True))\n\nplt.figure(figsize=(8,8))\n\ntotal = float(len(Salary['income']))\n\na = sns.countplot(x='workclass',data = Salary)\n\na.set_xticklabels(a.get_xticklabels(), rotation = 90)\n\nfor f in a.patches:\n    height = f.get_height()\n    a.text(f.get_x() + f.get_width()\/2., height+3, '{:1.2f}'.format((height\/total)*100),ha=\"center\")\n\nplt.title(\"WorlClass Distribution\")\nplt.show()","3e3c9a01":"print(Salary['education'].value_counts(normalize = True))\n\n\nplt.figure(figsize=(20,5))\n\n\ntot = float(len(Salary))\n\na1 = sns.countplot(Salary['education'], palette = 'Set1')\na1.set_xticklabels(a1.get_xticklabels(), rotation = 90)\n\nfor s in a1.patches:\n    height = s.get_height()\n    a1.text(s.get_x()+s.get_width()\/2.,height+3,'{:1.2f}'.format((height\/total)*100),ha='center')\n    \nplt.title(\"Education Level Distribution\")\nplt.show()  ","5e4242fa":"print(Salary['marital status'].value_counts(normalize = True))\n\n\nplt.figure(figsize=(15,5))\n\n\n\ntot = float(len(Salary))\n\nax = sns.countplot(Salary['marital status'], palette = 'Set1')\n\nax.set_xticklabels(ax.get_xticklabels(), rotation = 90)\n\nfor s in ax.patches:\n    height = s.get_height()\n    ax.text(s.get_x() + s.get_width()\/2.,height + 3,'{:1.2f}'.format((height\/total)*100),ha='center')\n    \nplt.title(\"Marital Status Distribution\")\nplt.show()\n","4599860b":"print(Salary['occupation'].value_counts(normalize = True))\n\n\nplt.figure(figsize=(20,5))\n\n\ntot = float(len(Salary))\n\nay = sns.countplot(Salary['occupation'], palette = 'Set2')\nay.set_xticklabels(ay.get_xticklabels(), rotation = 90)\n\nfor s in ay.patches:\n    height = s.get_height()\n    ay.text(s.get_x()+s.get_width()\/2.,height+3,'{:1.2f}'.format((height\/total)*100),ha='center')\n    \nplt.title('Occupation variable Distribution')\nplt.show()\n","929cdb20":"print(Salary['relationship'].value_counts(normalize = True))\n\n\nplt.figure(figsize=(10,8))\n\n\ntot = float(len(Salary))\n\naz = sns.countplot(Salary['relationship'], palette = 'Set1')\n#az.set_xticklabels(az.get_xticklabels(), rotation = 90)\n\nfor s in az.patches:\n    height = s.get_height()\n    az.text(s.get_x()+s.get_width()\/2.,height+3,'{:1.2f}'.format((height\/total)*100),ha='center')\n    \nplt.title('Distribution of \"Relationship\" variable')\nplt.show()\n","1ee626a2":"print(Salary['race'].value_counts(normalize = True))\n\n\nplt.figure(figsize=(10,10))\n\n\ntot = float(len(Salary))\n\naj = sns.countplot(Salary['race'], palette = 'Set1')\n#aj.set_xticklabels(aj.get_xticklabels(), rotation = 90)\n\nfor s in aj.patches:\n    height = s.get_height()\n    aj.text(s.get_x()+s.get_width()\/2.,height+3,'{:1.2f}'.format((height\/total)*100),ha='center')\n    \nplt.title(\"Distribution of the race variable\")\nplt.show()\n","e1259897":"print(Salary['gender'].value_counts(normalize = True))\n\n\nplt.figure(figsize=(6,6))\n\n\ntot = float(len(Salary))\n\nap = sns.countplot(Salary['gender'])\n#ap.set_xticklabels(ap.get_xticklabels(), rotation = 90)\n\nfor s in ap.patches:\n    height = s.get_height()\n    ap.text(s.get_x()+s.get_width()\/2.,height+3,'{:1.2f}'.format((height\/total)*100),ha='center')\n    \nplt.title('Distribution by Gender')\nplt.show()\n","97af3179":"print(Salary['income'].value_counts(normalize = True))\n\n\nplt.figure(figsize=(6,6))\n\n\ntot = float(len([Salary]))\n\nab = sns.countplot(Salary['income'])\n#ab.set_xticklabels(ab.get_xticklabels(), rotation = 90)\n\nfor s in ab.patches:\n    height = s.get_height()\n    ab.text(s.get_x()+s.get_width()\/2.,height+3,'{:1.2f}'.format((height\/total)*100),ha='center')\n    \nplt.title(\"Income Distribution\")\nplt.show()\n","51f8a7f1":"fig = plt.figure(figsize = (6,6))\nsns.boxplot(x = 'income', y = 'age', data = Salary, palette = \"Accent\").set_title(\"Income distribution by Age\")\n","b8a845bf":"##Alternatively we can represent the above plot using a violin plot\n\nsns.violinplot(x = 'income', y = 'age', data = Salary, size = 6)\nplt.title('Violin Plot of Age by Income')","56eab7db":"##Just for confirmation sake, we check the median age across income brackets\n\nprint(Salary.loc[Salary['income'] == '<=50K', 'age'].median())\nprint(Salary.loc[Salary['income'] == '>50K', 'age'].median())","a4ece2ed":"print(pd.crosstab(Salary['income'], Salary['workclass']))\n\nfig = plt.figure(figsize = (12,10))\nad = sns.countplot(x = 'workclass', hue = 'income', data = Salary, palette = \"Spectral\")\n\n#ad.set_xticklabels(ad.get_xticklabels(), rotation = 90)\n\nfor s in ad.patches:\n    height = s.get_height()\n    ad.text(s.get_x()+s.get_width()\/2.,height+3,'{:1.2f}'.format((height\/total)*100),ha='center')\n\nplt.title('Income split by WorkClass')\nplt.show()","3b552dd6":"print(pd.crosstab(Salary['income'], Salary['relationship']))\n\nplt.figure(figsize = (10, 10))\nsns.countplot(x = 'relationship', hue = 'income', data = Salary, palette = \"gist_earth\").set_title('Income by Relationship')","9f25b91f":"plt.figure(figsize = (20, 8))\n\nsns.catplot(y = 'race', hue = 'income', col = 'gender', data = Salary, kind = 'count', palette = 'twilight')\n#plt.title('Income by Race across Gender')","1bb3d4bc":"plt.figure(figsize = (10,10))\n\nsns.catplot(y = 'education', hue = 'income', data = Salary, kind = 'count', col = 'gender', palette = 'pastel')\n","9354febd":"plt.figure(figsize = (8,8))\nsns.catplot(y = 'marital status', hue = 'income', col = 'gender', data = Salary, palette = 'prism', kind = 'count')","48cb1f30":"plt.figure(figsize = (10,10))\nsns.catplot(y = 'occupation', hue = 'income', col = 'gender', kind = 'count', data = Salary, palette = 'Set3_r')","1006e950":"Salary.drop(['education rank', 'country', 'relationship'], axis = 1, inplace = True)\n","262cd109":"Salary.head(5)","6d57e71e":"### We proceed to code the various categorical variables\ned = set(Salary['education'])\nwc = set(Salary['workclass'])\nms = set(Salary['marital status'])\nocc = set(Salary['occupation'])\n#rel = set(Salary['relationship'])\ngen = set(Salary['gender'])\ninc = set(Salary['income'])\nrace = set(Salary['race'])","06a10f80":"print(ed)\n\nSalary['education'] = Salary['education'].map({'Preschool': 0, '1st-4th': 1, '5th-6th': 2, '7th-8th': 3,\n                                              '9th': 4, '10th': 5, '11th': 6, '12th': 7, 'HS-grad': 8,\n                                              'Some-college': 9, 'Assoc-voc': 10, 'Assoc-acdm': 11,\n                                              'Bachelors': 12, 'Masters': 13, 'Doctorate': 14, 'Prof-school': 15}).astype(int)","f28950e1":"print(wc)\n\nSalary['workclass'] = Salary['workclass'].map({'Without-pay': 0, 'Self-emp-not-inc': 1, 'Self-emp-inc': 2,\n                                              'Local-gov': 3, 'State-gov': 4, 'Federal-gov': 5, 'Private': 6}).astype(int)","f0fd168b":"print(ms)\n\nSalary['marital status'] = Salary['marital status'].map({'Never-married': 0, 'Separated': 1, 'Divorced': 2,\n                                                        'Widowed': 3, 'Married-spouse-absent': 4, 'Married-civ-spouse': 5,\n                                                        'Married-AF-spouse': 6}).astype(int)","24fefa08":"print(occ)\n\nSalary['occupation'] = Salary['occupation'].map({'Other-service': 0, 'Craft-repair': 1, 'Priv-house-serv': 2,\n                                                'Handlers-cleaners': 3, 'Farming-fishing': 4, 'Adm-clerical': 5,\n                                                'Transport-moving': 6, 'Machine-op-inspct': 7, 'Sales': 8, 'Armed-Forces': 9,\n                                                'Tech-support': 10, 'Protective-serv': 11, 'Exec-managerial': 12,\n                                                'Prof-specialty': 13}).astype(int)","4576b986":"#print(rel)\n\n#Salary['relationship'] = Salary['relationship'].map({'Not-in-family': 0, 'Other-relative': 1, 'Unmarried': 2,\n#                                                    'Own-child': 3, 'Wife': 4, 'Husband': 5}).astype(int)","9ee2c48e":"print(gen)\n\nSalary['gender'] = Salary['gender'].map({'Female': 0, 'Male': 1}).astype(int)","3266eb16":"print(inc)\n\nSalary['income'] = Salary['income'].map({'<=50K': 0, '>50K': 1}).astype(int)","d96e8f19":"print(race)\n\nSalary['race'] = Salary['race'].map({'Other': 0, 'Amer-Indian-Eskimo': 1, 'Asian-Pac-Islander': 2, 'Black': 3,\n                                    'White': 4}).astype(int)","77ebadab":"Salary.head(5)","084dd1ed":"Salary.tail(5)","80040af5":"##Plot another correlation matrix including our new coded variables\ncorr_matrix = Salary.corr()\n\nf, ax = plt.subplots(figsize = (12,10))\nk = 12 ##The number of variables to be used for the heatmap\ncols = corr_matrix.nlargest(k, 'income')['income'].index ##The 'income' variable is used as index as it is compared against others\ncm = np.corrcoef(Salary[cols].values.T)\nsns.set(font_scale = 1.25)\nhm = sns.heatmap(cm, cbar = True, annot = True, square = True, fmt = '.2f', annot_kws = {'size': 10},\n                yticklabels = cols.values, xticklabels = cols.values) ##annot prints the values inside the matrix\n\nplt.show()","5fbed8ae":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n##Split the data into train and test sets while stratifying our target variable(because its imbalanced)\n\nX = Salary.drop('income', axis = 1)\ny = Salary['income']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 30, stratify = y)\n\nprint(\"Size of the train dataset: \", len(X_train))\nprint(\"Size of the test dataset: \", len(X_test))","aa8bbbb1":"##In fitting our logistic model we take into account that this is an unbalanced dataset,\nlogmodel = LogisticRegression(solver = 'lbfgs', max_iter = 200)\n\nlogmodel.fit(X_train, y_train)","a2ac8be8":"pred = logmodel.predict(X_test)\n\nprint(confusion_matrix(y_test, pred))\n\nprint('Accuracy of Logistic regression classifier on training set: {:.2f}'\n     .format(logmodel.score(X_train, y_train)))\nprint('Accuracy of Logistic regression classifier on test set: {:.2f}'\n     .format(logmodel.score(X_test, y_test)))","e3cc8655":"##Plot the Confusion Matrix\nimport itertools\nmatrix = confusion_matrix(y_test, pred)\n\nplt.gca().xaxis.tick_top()\nplt.gca().xaxis.set_label_position('top')\n\nplt.imshow(matrix, interpolation = 'nearest', cmap = plt.cm.Blues)\nplt.colorbar()\n\nfmt = 'd'\n\nthresh = matrix.max()\/2.\nfor i, j in itertools.product(range(matrix.shape[0]), range(matrix.shape[1])):\n    plt.text(j, i, format(matrix[i, j], fmt), \n            horizontalalignment = 'center', color = 'white' if matrix[i, j] > thresh else 'black')\n    \nclass_names = ['Class-0', 'Class-1']\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names, rotation = 90)\nplt.yticks(tick_marks, class_names)\nplt.tight_layout()\nplt.ylabel('True Label', size = 10)\nplt.xlabel('Predicted Label', size = 10)\nplt.show()","76c8d159":"print(classification_report(pred, y_test))\n","ff14480c":"from sklearn import metrics \n\npred_prob = logmodel.predict_proba(X_test)\n\ny_preds = pred_prob[:, 1]\nfpr, tpr, _ = metrics.roc_curve(y_test, y_preds)\nauc_score = metrics.auc(fpr, tpr)\n#plt.pred_prob()\nplt.figure(figsize = (10,10))\nplt.title('ROC Curve')\nplt.plot(fpr, tpr, label = 'AUC = {:.2f}'.format(auc_score))\nplt.plot([0, 1], [0, 1], 'r--')\n\nplt.xlim(-0.1, 1.1)\nplt.ylim(-0.1, 1.1)\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend(loc = 'lower right')\nplt.show()","be7034aa":"optimal_idx = np.argmax(np.abs(tpr - fpr))\noptimal_threshold = _[optimal_idx]\noptimal_threshold","2ffd2381":"gmeans = np.sqrt(tpr * (1 - fpr))\nix = np.argmax(gmeans)\nprint('Best Threshold = %f, G-mean = %.3f' % (_[ix], gmeans[ix]))","17a329b4":"y_preds = pred_prob[:, 1]\nfpr, tpr, _ = metrics.roc_curve(y_test, y_preds)\n\nix = np.argmax(gmeans)\nprint('Best Threshold = %f, G-mean = %.3f' % (_[ix], gmeans[ix]))\n\n##Plot the roc curve for the model\nplt.figure(figsize = (8, 8))\nplt.plot([0,1], [0,1], linestyle = '--', color = 'red', label = 'No Skill')\nplt.plot(fpr, tpr, marker = '.',color = 'yellow', label = 'Logistic')\nplt.scatter(fpr[ix], tpr[ix], marker = 'o', color = 'black', label = 'Best')\nplt.title('ROC Curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\nplt.show()","76b89065":"##Tune the hyper-parameters by cross validation\nn_splits = 15 ##specify the number of splits\n\nkfold = KFold(n_splits, random_state = 20) ##splits the data set into n folds for evaluation\n\nresult = cross_val_score(logmodel, X, y, cv = kfold, scoring = 'accuracy')\n\n##The accuracy of the k-fold cross-validation can be obtained from the mean of the results\nprint('Accuarcy: %.3f (%.3f)' % (result.mean(), result.std()))","9ffc7b8c":"from sklearn.tree import DecisionTreeClassifier\n\ntree_model = DecisionTreeClassifier(max_depth = 10)\ntree_model.fit(X_train,y_train)","e8635398":"prediction = tree_model.predict(X_test)\n\n\nprint(confusion_matrix(y_test, prediction))\n\nprint('Accuracy of Logistic regression classifier on training set: {:.2f}'\n     .format(tree_model.score(X_train, y_train)))\nprint('Accuracy of Logistic regression classifier on test set: {:.2f}'\n     .format(tree_model.score(X_test, y_test)))","21829a76":"from sklearn import tree\nfeature_names = ['age', 'workclass', 'Final Weight', 'education', 'marital status', 'occupation',\n                'race', 'gender', 'capital gain', 'capital loss', 'HPW']\n\ncn = ['<=50K', '>50K']\n\nfig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (8,8), dpi = 300)\ntree.plot_tree(tree_model, feature_names = feature_names, class_names = cn, filled = True)\nplt.show()","9fb140c5":"print(classification_report(prediction, y_test))","e56070c7":"from sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier(random_state =0, n_jobs = -1, n_estimators = 20, class_weight = 'balanced').fit(X_train, y_train)\n\npred2 = clf.predict(X_test)\n\nprint(confusion_matrix(y_test, pred2))\n\nprint('Accuracy of RandomForest classifier on training set: {:.2f}'\n     .format(clf.score(X_train, y_train)))\nprint('Accuracy of RandomForest classifier on test set: {:.2f}'\n     .format(clf.score(X_test, y_test)))","6f4e41ba":"print(classification_report(pred2, y_test))","1572cb0b":"##Apply kfolds cross_validation\nn_splits = 10\nkfold1 = KFold(n_splits, random_state = 20)\nresult1 = cross_val_score(clf, X, y, cv = kfold1, scoring = 'accuracy')\nprint('Accuarcy: %.3f (%.3f)' % (result1.mean(), result1.std()))","b09dbf60":"important = clf.feature_importances_\n\nfeature_importance = np.array(important)\nfeature_names = np.array(feature_names)\n\ndata = {'feature_names': feature_names, 'feature_importance': important}\ndf = pd.DataFrame(data)\n\ndf.sort_values(by = ['feature_importance'], ascending = False, inplace = True)\n#fig, ax = plt.subplots()\nplt.figure(figsize = (10, 8))\n#plt.bar([x for x in range(len(important))], important)\nsns.barplot(x = df['feature_importance'], y = df['feature_names'], palette = 'twilight')\nplt.ylabel('Feature')\nplt.xlabel('Realtive Importance')\n#ax.set_xticklabels(feature_names, minor = False)\nplt.title(\"Feature Importance in Random Classifier\")\nplt.show()","4722a299":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_class = KNeighborsClassifier(n_neighbors = 16).fit(X_train, y_train)\nknn_pred = knn_class.predict(X_test)\n\nprint(confusion_matrix(knn_pred, y_test))\n\nprint(classification_report(knn_pred, y_test))","a486c229":"accrate = list()\n\nfor i in range(1, 30):\n    knn = KNeighborsClassifier(n_neighbors = i)\n    score = cross_val_score(knn, X, y, cv = 10)\n    accrate.append(score.mean())\n\n\nplt.figure(figsize = (10,10))\nplt.plot(range(1, 30), accrate, color = 'green', linestyle = 'dashed', marker = 'o',\n        markerfacecolor = 'red', markersize = 10)\n\nplt.title('Accuarcy Vs Different K values')\nplt.xlabel('K')\nplt.ylabel('Accuarcy Rate')","33c26baf":"#### Majority of the males earning 50K or less are in the craft and repairs sub-group, while the highest earners are more in the Prof sub-group. Majority of the women who earn 50K or less annually are in the admin\/clerical sub-group, closely followed by those in other-service. Their highest earners are in the Prof sub-group.\n#### Interestingly there are more women earning 50K or less in the Prof group than those who earn above, compared to the men in the same sub-group where the opposite is the case. ","3899f93b":"### Hard coding of categorical variables","6a850d39":"#### With Decison trees (with a maximum depth of 10) the model improved significantly with a prediction accuracy of 86% on the test data","e98c9334":"## Exploratory Data Analysis (EDA)","a391ad4c":"#### The above is a look into the 'realtionship' variable, with Husbands accounting 41.28%, followed by Not-in-family (25.88%), with Other-relative being the least(2.98%)","a8e8e445":"#### The 'education rank' variable is dropped since they correlate with the 'education' variable. Instead we'll recode the variable as integers","48458e18":"### Income by Occupation and Gender","f1afd94a":"## Bivariate Analysis\n\n\n#### Here we look at our different dependent variables and how they affect our target variable (income)","e43e8f66":"#### Craft-repair accounts for 13.31% of the total occupation reported closely by Prof (13.29%), Exec-managerial (13.23%) and Adm-cleric (12.25%) with the smallest group being the armed forces(0.03%)","75e1c264":"### Income Vs Age","b93f9b80":"#### The above result shows that even with KFolds cross_validation, the RandomForest model's accuracy remains constant at 85%. Compared with the decision trees model, the model's accuracy performed marginally less. However the RandomForest model performed better on the train set than the decision trees","32343ef4":"#### In the preceding cell the first line of code outputs the length of the data set which corresponds to the number of rows in the data. The second line gives us the full dimension of the data which is made up of 48842 rows and 15 columns","895c5019":"### Univariate Analysis\n\n#### Univariate analysis means carrying out exploratory analysis, on all or the most important variables","d0410456":"### K-Nearest Neighbor","5c317ce3":"#### Across different relationship sub-category there are more of employees earning less than 50,000 dollars, with 'Not-in-family', 'Husband' and 'Own-child' accounting for the majority, while the Husband sub-category accounts for majority of earners above 50,000","e76744e9":"#### 67.5% of respondents were male while 32.5% were female","c27e8161":"### Income Vs WorkClass","c4581769":"#### The age variable is an assymetric distribution with right skew and ranges from 17 to 90","522f49ae":"### Gender:","09849ccb":"### Occupation Distribution","8bef8ee4":"#### The private sector accounts for the overwhelming number of those that earn below 50,000 dollars (26056), and also accounts for majority of those that earn above 50,000 dollars. Those in the without pay category account for the least across both income brackets.","c8d03607":"#### This is another assymetric right-tailed distribution","d530212d":"#### Most of the variables have correlations ranging from weak positive or negative.  However relationship-marital status stands out with a strong correlation of 0.78. This can be attributed to the values used in coding the categorical variables. In any case the 'relationship' variable had to be dropped from the data (This is the reason for the earlier dropping of the variable)","afce1865":"### Marital Status","ece955ec":"### Correlation Matrix of the new data","a7da3a9e":"#### There is much variability between those who earn less than 50000 dollars and those who earn higher across ages. The median age for those who earn less than 50000 dollars is 34 while the median age of those who earn higher is 43","e0cd334e":"#### The logistic model came out satisfactorily with prediction accuracy of 79%, and evaluation of the algorithm us Kfold cross-validation improved the accuracy marginally (79.4%)\n#### Its is interesting to note that earlier with the 'relationship' still in the data the model performed worse after k-fold cross-validation with an accuracy of 70.5%, however the exclusion of the variable markedly improved the accuracy (79.4%) giving credence to the negative effect  that collinearity on the model.","f1a55f81":"### Random Forests","ac4975c1":"### Income\n\n#### This is our target or dependent variable","4d5850e4":"### Income by Marital Status and Gender","f50e9e1f":"#### The above plot of Accuracy Rate against different K values, from which we can deduce that the k value that mostminimizes the cross validation error is 16, we can now go back to the previous code and run again but this time with the 'n_neighbors' parameter set at 16","65a33292":"#### Majority of respondents (86.03%) were White, followed by Black (9.35%)","a20701ab":"### Income Vs Relationship","3531beb5":"### Realationship variable Distribution","5f000ec5":"### Decision Trees","fd781db2":"### Distribution of Income by Race and Gender","8f314b07":"### Prediction using Logistic Regression","fe4fce63":"### Distribution of Education Level","a420279b":"#### There are 3times more respondents who earn 50000 dollars or less than those who earned above 50000 dollars","fdbb5406":"#### After the null values are dropped, the data is reduced by 3620 rows as those records contain missing values which isnt of much help in our analysis. There are other methods too to solve the problem of missing values but considering the small size of the dropped records we can afford to use this method.","83000774":"### Data Preprocessing","3bcbe801":"#### 32.69% of those that made up this data had graduated High School, followed closely by those got some form of college education(21.89%), while those who had only Preschool education made up the smallest of the group(0.16%)","74362235":"#### As expected Whites account for majority of those earning 50,000 and below, and also above 50,000 across genders. Blacks come a distant second ","f89322eb":"#### High School graduates account for the huge majority of 50,000 or less earners across genders, While the Bachelors Degree holders account for more the above 50,000 earners across genders","8fa5e250":"#### The above is a summary of the data. The first command prints out summary or descriptive statistics of continuous variables in the data while a little tweak of the first code yields summary statistics of categorical (or more precisely, pandas object) data. The summary includes counts, number of unique values, top and frequency of those values.","86fd26f3":"#### For the male gender the Married-civ-spouse account for majority of those who earn 50K and below as well as above 50K,followed by the Never-married sub category. For the female gender The Never-married sub marital category account for the highest number of 50K or below earners, while the Married-civ-spouse account for the highest number of above 50K earners","733687d1":"#### Private sector employees accounted for an overwhelming majority (73.65%) of the data followed by those who are self employed but not yet incorporated their business in distant second (8.39%), and those without any source of income being the smallest group(0.05%)","9ebf0430":"### Income by Occupation and Gender","f6ec1030":"### Race","4b35c540":"#### Those that fell into the 'Married-civ-spouse' category accounted for almost have of the total number of respondents(46.56%), followed by those who were never married (32.28%), 'Divorced' made up the third largest group (13.92%) and the least group were the  'Married-AF-spouse' category (0.07%)","847cdec4":"#### The above shows that there exists in some columns the presence of special characters '?' in the variables 'workclass', 'occupation' and 'native-country'. These we shall replace with the Numpy null or nan value to replace the special character","20363811":"### Distribution of the workclass variable"}}