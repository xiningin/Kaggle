{"cell_type":{"9e7d96fc":"code","a5ff3336":"code","b3ec921a":"code","61550df6":"code","1e7cc0b4":"code","1114c6ed":"code","d85bbcb9":"code","27d08441":"code","319a1f1c":"code","b7ba8497":"code","142d5551":"code","1e343543":"code","45e3b916":"code","bb24ea36":"code","30326bd4":"code","2e26194e":"code","a263f938":"code","f73ba48e":"code","4b70ae86":"code","7dbae188":"code","37121267":"code","cea1a5b5":"code","8c8874f9":"code","fda3b277":"code","b3c18f4b":"code","5a55f586":"code","a8266f60":"code","2e2801ad":"code","85030a4f":"code","6bccda9c":"code","e16c6165":"code","461d6b51":"code","d7f5ee30":"code","a15b199b":"code","78a73be8":"code","53e3358b":"code","b9bbc335":"code","55f7fad4":"code","9e03dab7":"code","d1444f7e":"code","2fb64164":"code","62fb851e":"code","7483d085":"code","854030da":"code","86efeb7e":"code","c91a8e81":"code","ae3f8e83":"code","e0c9bdb1":"code","399b2d02":"code","5fcc9c82":"code","29139375":"code","16f32531":"code","2b05b04c":"code","95ae6a37":"code","0ffc202e":"code","e2a2c1bc":"code","b0a3c4f4":"code","96ee1c0c":"code","f559a3aa":"code","c25a00bf":"code","0c2695a6":"code","c00763c9":"code","c7ab10bc":"code","2af9e185":"code","768a4424":"code","c2cf17a6":"code","db99bef6":"code","deefc06b":"code","77812782":"code","70d31c63":"code","e05dae7a":"code","58635fc8":"code","1ef9c314":"code","df064169":"code","af58085b":"code","4c9b4c49":"code","571fe425":"code","2f825b17":"code","20b6e1bb":"code","a57449cb":"code","9aaaf1d9":"code","648eaa17":"code","fed386c0":"code","ee813ede":"code","f43a2236":"code","7acf2947":"code","4aeb887f":"code","b7459547":"code","d5e4ccb4":"code","c830780c":"code","40792134":"code","b1e03235":"code","054f8d72":"code","64d8c231":"code","f06beb0a":"code","4a3861d4":"code","a2c60ccf":"code","85beb9c0":"code","6d160530":"code","e9f2c2b4":"code","7fef35c2":"code","037edfd3":"code","fb7eeabf":"code","6c387a41":"code","b1decdf5":"code","c997a26f":"code","74331f3f":"code","ffbcbbd9":"code","566c4d30":"code","6b072768":"code","359a1764":"code","c87b5b1a":"code","489cdb38":"code","14d6d92c":"code","b052cdec":"code","ac9ced24":"code","85a4bf98":"code","25c48a55":"code","4da3526e":"code","8ab97fb9":"code","2b9b44c6":"code","865e28c7":"code","5840f1cf":"code","849822d4":"code","4c1cdfe5":"code","62750279":"code","797a060d":"code","1ec1eb6d":"code","e05d67c0":"code","58df75cd":"code","a7697ffb":"code","7b809eea":"code","84b80cbb":"code","0081c546":"code","d6ca2eb6":"code","dccf4abe":"code","bef13059":"markdown","8d611f98":"markdown","0ce6b583":"markdown","cc1a284e":"markdown","c38a959b":"markdown","dc5999e8":"markdown","2629b755":"markdown","40207c8b":"markdown","e4913bfe":"markdown","53f81c89":"markdown","4deedfd2":"markdown","bdffa699":"markdown","61984839":"markdown","46d0e945":"markdown","1afa306c":"markdown","a9ec704b":"markdown"},"source":{"9e7d96fc":"# imported necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split, cross_val_score\n#from sklearn.cross_validation import cross_val_score\nfrom collections import Counter\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import model_selection\n#from sklearn import cross_validation\nfrom scipy.stats import uniform\nfrom sklearn.model_selection import TimeSeriesSplit","a5ff3336":"warnings.filterwarnings(\"ignore\")","b3ec921a":"import sqlite3\ncon = sqlite3.connect('finalassignment.sqlite')","61550df6":"cleaned_data = pd.read_sql_query('select * from Reviews', con)","1e7cc0b4":"cleaned_data.shape","1114c6ed":"# Sort data based on time\ncleaned_data[\"Time\"] = pd.to_datetime(cleaned_data[\"Time\"], unit = \"s\")\ncleaned_data = cleaned_data.sort_values(by = \"Time\")\ncleaned_data.shape","d85bbcb9":"cleaned_data['Score'].value_counts()","27d08441":"# To randomly sample 5k points from both class\n\ndata_p = cleaned_data[cleaned_data['Score'] == 'positive'].sample(n = 5000)\ndata_n = cleaned_data[cleaned_data['Score'] == 'negative'].sample(n = 5000)\nfinal_10k = pd.concat([data_p, data_n])\nfinal_10k.shape","319a1f1c":"# converting scores in 0 and 1\nfinal_10k[\"Score\"] = final_10k[\"Score\"].map(lambda x: 1 if x == \"positive\" else 0)\n#encoded_labels = df['label'].map(lambda x: 1 if x == 'spam' else 0).values","b7ba8497":"# Sorting data based on time\nfinal_10k['Time'] = pd.to_datetime(final_10k['Time'], unit = 's')\nfinal_10k = final_10k.sort_values(by = 'Time')\nfinal_10k.shape","142d5551":"# Grid search\ndef lr_grid_plot(X_train, y_train):\n    tuned_parameters_grid = [{'penalty': ['l1','l2'],'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n    cv = TimeSeriesSplit(n_splits = 3)\n    model_lr_grid = GridSearchCV(LogisticRegression(), param_grid = tuned_parameters_grid, cv = cv)\n    model_lr_grid.fit(X_train, y_train)\n    print(\"\\n**********GridSearchCV**********\\n\")\n    print(\"\\nOptimal C:\", model_lr_grid.best_estimator_.C)\n    print('\\nBest penalty:', model_lr_grid.best_estimator_.get_params()['penalty'])\n    score = model_lr_grid.cv_results_\n    plot_df = pd.DataFrame(score)\n    plt.plot(plot_df[\"param_C\"], 1- plot_df[\"mean_test_score\"], \"-o\")\n    plt.title(\"CV Error vs C\")\n    plt.xlabel(\"C\")\n    plt.ylabel(\"Cross-validation Error\")\n    plt.show()\n    return model_lr_grid.best_estimator_.C","1e343543":"# 10k data which will use to train model after vectorization\nX = final_10k[\"CleanedText\"]\nprint(\"shape of X:\", X.shape)","45e3b916":"# class label\ny = final_10k[\"Score\"]\nprint(\"shape of y:\", y.shape)","bb24ea36":"# split data into train and test where 70% data used to train model and 30% for test\nfrom sklearn.model_selection import train_test_split\nX_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, shuffle = False)\nprint(X_train.shape, y_train.shape, x_test.shape , y_test.shape)","30326bd4":"# Train Vectorizor\nfrom sklearn.feature_extraction.text import CountVectorizer \nbow = CountVectorizer()\nX_train = bow.fit_transform(X_train)\nX_train","2e26194e":"# Standardization \nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler(with_mean = False)\nstd_X_train = scaler.fit_transform(X_train)","a263f938":"# Test Vectorizor\nx_test = bow.transform(x_test)\nx_test.shape","f73ba48e":"scaler = StandardScaler(with_mean = False)\nstd_x_test = scaler.fit_transform(x_test)","4b70ae86":"std_x_test.shape","7dbae188":"# To choose optimal c using cross validation\nfrom sklearn.model_selection import TimeSeriesSplit\noptimal_lambda_bow_grid = lr_grid_plot(std_X_train, y_train)\noptimal_lambda_bow_grid","37121267":"# instantiate learning model \nlr_model =  LogisticRegression(penalty = 'l2', C = optimal_lambda_bow_grid, class_weight = \"balanced\")\n# fitting the model\nlr_model.fit(std_X_train, y_train)\n# predict the response\npred = lr_model.predict(std_x_test)\n# predict probablistic response\npred_prob = lr_model.predict_proba(std_x_test)\n\n# this step use both technique","cea1a5b5":"train_acc_bow_grid = lr_model.score(std_X_train, y_train)\nprint(\"Train accuracy:\",train_acc_bow_grid)","8c8874f9":"test_acc_bow_grid = accuracy_score(y_test, pred) * 100\nprint('\\nThe accuracy of the logistic regression for c = %f is %.2f%%' % (optimal_lambda_bow_grid, test_acc_bow_grid))","fda3b277":"# Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, pred)\ncm","b3c18f4b":"# plot confusion matrix to describe the performance of classifier.\nimport seaborn as sns\nclass_label = [\"negative\", \"positive\"]\ndf_cm = pd.DataFrame(cm, index = class_label, columns = class_label)\nsns.heatmap(df_cm, annot = True, fmt = \"d\")\nplt.title(\"Confusiion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","5a55f586":"# To show main classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, pred))","a8266f60":"# model for knn with bag of word\nmodels = pd.DataFrame({'Model': ['Logistic Regression with Bow'], 'Hyper Parameter(K) for grid search': [optimal_lambda_bow_grid], 'Train Error': [train_acc_bow_grid], 'Test Error': [100 - test_acc_bow_grid], 'Accuracy': [test_acc_bow_grid ], 'Train Accuracy': [train_acc_bow_grid ]}, columns = [\"Model\", \"Hyper Parameter(K) for grid search\", \"Train Error\", \"Test Error\", \"Accuracy\" , \"Train Accuracy\"])\nmodels.sort_values(by='Accuracy', ascending=False)","2e2801ad":"def plot_precision_recall_curve(recall, precision):\n    plt.xlabel(\"Recall\")\n    plt.ylabel(\"Precision\")\n    plt.title(\"Precision_recall_curve\")\n    plt.plot(recall, precision, \"-o\")\n    plt.show()","85030a4f":"# F1-score, auc, precision_recall_curve\nfrom sklearn.metrics import f1_score, auc, precision_recall_curve, average_precision_score\nfrom sklearn.metrics import auc\nf1 = f1_score(y_test, pred)\nprecision, recall, thresholds = precision_recall_curve(y_test, pred_prob[:,1])\nauc = auc(recall, precision)\navg_precision = average_precision_score(y_test, pred_prob[:,1])\nprint(\"Average precision score:\", avg_precision)\nprint(\"F1_score:\", f1)\nprint(\"Auc score:\",auc)\nplot_precision_recall_curve(recall, precision)","6bccda9c":"# Random search\nfrom scipy.stats import uniform\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\ndef lr_random_plot(X_train, y_train):\n    tuned_parameters_random = {'penalty': ['l1','l2'], 'C': uniform(loc = 0, scale = 4)}\n    cv = TimeSeriesSplit(n_splits = 3)\n    model_lr_random = RandomizedSearchCV(LogisticRegression(), tuned_parameters_random, cv = cv, n_iter = 10)\n    model_lr_random.fit(X_train, y_train)\n    print(\"\\n\\n**********RandomizedSearchCV**********\\n\")\n    print(\"\\nOptimal C:\", model_lr_random.best_estimator_.C)\n    print('\\nBest penalty:', model_lr_random.best_estimator_.get_params()['penalty'])\n    score = model_lr_random.cv_results_\n    plot_df = pd.DataFrame(score)\n    plt.plot(plot_df[\"param_C\"], 1 - plot_df[\"mean_test_score\"], \"-o\")\n    plt.title(\"CV Error vs C\")\n    plt.xlabel(\"C\")\n    plt.ylabel(\"Cross-validation Error\")\n    plt.show()\n    return model_lr_random.best_estimator_.C","e16c6165":"optimal_lambda_bow_random = lr_random_plot(std_X_train, y_train)\noptimal_lambda_bow_random","461d6b51":"# instantiate learning model \nlr_model =  LogisticRegression(penalty = 'l2', C = optimal_lambda_bow_grid, class_weight = \"balanced\")\n# fitting the model\nlr_model.fit(std_X_train, y_train)\n# predict the response\npred = lr_model.predict(std_x_test)\n# predict probablistic response\npred_prob = lr_model.predict_proba(std_x_test)\n\n# this step use both technique","d7f5ee30":"train_acc_bow_random = lr_model.score(std_X_train, y_train)\nprint(\"Train accuracy:\",train_acc_bow_random)","a15b199b":"test_acc_bow_random = accuracy_score(y_test, pred) * 100\nprint('\\nThe accuracy of the logistic regression for c = %f is %.2f%%' % (optimal_lambda_bow_random, test_acc_bow_random))","78a73be8":"# Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, pred)\ncm","53e3358b":"# plot confusion matrix to describe the performance of classifier.\nimport seaborn as sns\nclass_label = [\"negative\", \"positive\"]\ndf_cm = pd.DataFrame(cm, index = class_label, columns = class_label)\nsns.heatmap(df_cm, annot = True, fmt = \"d\")\nplt.title(\"Confusiion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","b9bbc335":"# To show main classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, pred))","55f7fad4":"# model for knn with bag of word\nmodelsgrid = pd.DataFrame({'Model': ['Logistic Regression with Bow'], 'Hyper Parameter(K) for random search': [optimal_lambda_bow_random], 'Train Error': [train_acc_bow_random], 'Test Error': [100 - test_acc_bow_random], 'Accuracy': [test_acc_bow_random ], 'Train Accuracy': [train_acc_bow_random ]}, columns = [\"Model\", \"Hyper Parameter(K) for random search\", \"Train Error\", \"Test Error\", \"Accuracy\" , \"Train Accuracy\"])\nmodelsgrid.sort_values(by='Accuracy', ascending=False)\n","9e03dab7":"def plot_precision_recall_curve(recall, precision):\n    plt.xlabel(\"Recall\")\n    plt.ylabel(\"Precision\")\n    plt.title(\"Precision_recall_curve\")\n    plt.plot(recall, precision, \"-o\")\n    plt.show()","d1444f7e":"# F1-score, auc, precision_recall_curve\nfrom sklearn.metrics import f1_score, auc, precision_recall_curve, average_precision_score\nfrom sklearn.metrics import auc\nf1 = f1_score(y_test, pred)\nprecision, recall, thresholds = precision_recall_curve(y_test, pred_prob[:,1])\nauc = auc(recall, precision)\navg_precision = average_precision_score(y_test, pred_prob[:,1])\nprint(\"Average precision score:\", avg_precision)\nprint(\"F1_score:\", f1)\nprint(\"Auc score:\",auc)\nplot_precision_recall_curve(recall, precision)","2fb64164":"# Tried different value of c and finding features weight\n# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C)\nC_param = [10, 1, 0.1]\n\nfor c in C_param:\n    clf = LogisticRegression(penalty='l1', C = c, class_weight = \"balanced\",  solver='liblinear')\n    clf.fit(X_train, y_train)\n    print('\\nC value:', c)\n    print('Coefficient of each feature:', clf.coef_)\n    print('Training accuracy: %0.2f%%' %(clf.score(std_X_train, y_train) * 100))\n    print('Test accuracy: %0.2f%%' %(clf.score(std_x_test, y_test) * 100))\n    print(\"Number of non-zero element: \",np.count_nonzero(clf.coef_))","62fb851e":"clf = LogisticRegression(penalty='l1', C = optimal_lambda_bow_random, class_weight = \"balanced\" ,solver='liblinear')\nclf.fit(std_X_train, y_train)\ny_pred = clf.predict(std_x_test)\nprint(\"Accuracy score: %0.2f%%\" %(accuracy_score(y_test, y_pred) * 100))\nprint(np.count_nonzero(clf.coef_))","7483d085":"std_X_train.shape","854030da":"from scipy.sparse import find\n\n# Before adding noise in data\ncf = clf.coef_[0]\nw_coef1 = cf[np.nonzero(cf)]\nprint(w_coef1[:20])","86efeb7e":"# Generate random normal variable as a noise \nstd_X_train_pert = std_X_train\nnoise = np.random.normal(0, 0.0001, size = (std_X_train_pert[np.nonzero(std_X_train_pert)].size))\n#print(noise.shape)\nnp.nonzero(std_X_train_pert)\nstd_X_train_pert[np.nonzero(std_X_train_pert)] = noise + std_X_train_pert[np.nonzero(std_X_train_pert)]\nstd_X_train_pert.shape","c91a8e81":"clf = LogisticRegression(penalty ='l1', C = optimal_lambda_bow_random, class_weight = \"balanced\", solver='liblinear')\nclf.fit(std_X_train_pert, y_train)\ny_pred = clf.predict(std_x_test)\nprint(\"Accuracy score: %0.2f%%\" %(accuracy_score(y_test, y_pred) * 100))\nprint(np.count_nonzero(clf.coef_))","ae3f8e83":"cf = clf.coef_[0]\nw_coef2 = cf[np.nonzero(cf)]\nprint(w_coef2[:20])","e0c9bdb1":"# Calculate %increase \ncnt = 0\nfor w1, w2 in zip(w_coef1, w_coef2):\n    inc = abs(w1 - w2)\/abs(w1) * 100\n    if inc > 40:\n        cnt += 1\nprint(\"No of weights that changes more than 40% is:\", cnt)","399b2d02":"# Features importance \n\nfeatures = bow.get_feature_names()\ncoef = clf.coef_[0]\ncoeff_df = pd.DataFrame({'Word' : features, 'Coefficient' : coef})\ncoeff_df = coeff_df.sort_values(\"Coefficient\", ascending = False)\nprint('*----------****Top 10 positive*------------------****')\nprint(coeff_df.head(10))\nprint('**-------------***Top 10 negative**---------------***')\nprint(coeff_df.tail(10))","5fcc9c82":"# data\nX = final_10k[\"CleanedText\"]","29139375":"# Target\/class-label\ny = final_10k[\"Score\"]","16f32531":"# Split data\nX_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, shuffle = False)\nprint(X_train.shape, x_test.shape, y_train.shape, y_test.shape)","2b05b04c":"from sklearn.feature_extraction.text import TfidfVectorizer\ntf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\nX_train = tf_idf_vect.fit_transform(X_train)\nX_trn = X_train\nX_train","95ae6a37":"# Standardization \nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler(with_mean = False)\nstd_X_train = scaler.fit_transform(X_train)","0ffc202e":"# Convert test text data to its vectorizor\nx_test = tf_idf_vect.transform(x_test)\nx_tst = x_test\nx_test.shape","e2a2c1bc":"scaler = StandardScaler(with_mean = False)\nstd_x_test = scaler.fit_transform(x_test)","b0a3c4f4":"# To choose optimal_alpha using nested cross validation\noptimal_lambda_tfidf_grid = lr_grid_plot(std_X_train, y_train)\noptimal_lambda_tfidf_grid","96ee1c0c":"# instantiate learning model \nlr_model =  LogisticRegression(penalty = 'l2', C = optimal_lambda_tfidf_grid, class_weight = \"balanced\")\n# fitting the model\nlr_model.fit(std_X_train, y_train)\n# predict the response\npred = lr_model.predict(std_x_test)\n# predict probablistic response\npred_prob = lr_model.predict_proba(std_x_test)","f559a3aa":"# F1-score, auc, precision_recall_curve\nfrom sklearn.metrics import f1_score, auc, precision_recall_curve, average_precision_score\nfrom sklearn.metrics import auc\nf1 = f1_score(y_test, pred)\nprecision, recall, thresholds = precision_recall_curve(y_test, pred_prob[:,1])\nauc = auc(recall, precision)\navg_precision = average_precision_score(y_test, pred_prob[:,1])\nprint(\"Average precision score:\", avg_precision)\nprint(\"F1_score:\", f1)\nprint(\"Auc score:\",auc)\nplot_precision_recall_curve(recall, precision)","c25a00bf":"train_acc_tfidf_grid = lr_model.score(std_X_train, y_train)\nprint(\"Train accuracy:\",train_acc_tfidf_grid)","0c2695a6":"test_acc_tfidf_grid = accuracy_score(y_test, pred) * 100\nprint('\\nThe accuracy of the logistic regression for c = %f is %.2f%%' % (optimal_lambda_tfidf_grid, test_acc_tfidf_grid))","c00763c9":"# Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, pred)\ncm","c7ab10bc":"# plot confusion matrix to describe the performance of classifier.\nimport seaborn as sns\nclass_label = [\"negative\", \"positive\"]\ndf_cm = pd.DataFrame(cm, index = class_label, columns = class_label)\nsns.heatmap(df_cm, annot = True, fmt = \"d\")\nplt.title(\"Confusiion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","2af9e185":"# To show main classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, pred))","768a4424":"# model for knn with bag of word\nmodelsgrid = pd.DataFrame({'Model': ['Logistic Regression with TFIDF'], 'Hyper Parameter(K) for grid search': [optimal_lambda_tfidf_grid], 'Train Error': [train_acc_tfidf_grid], 'Test Error': [100 - test_acc_tfidf_grid], 'Accuracy': [test_acc_tfidf_grid ], 'Train Accuracy': [train_acc_tfidf_grid ]}, columns = [\"Model\", \"Hyper Parameter(K) for grid search\", \"Train Error\", \"Test Error\", \"Accuracy\" , \"Train Accuracy\"])\nmodelsgrid.sort_values(by='Accuracy', ascending=False)\n","c2cf17a6":"optimal_lambda_tfidf_random = lr_random_plot(std_X_train, y_train)\noptimal_lambda_tfidf_random","db99bef6":"# instantiate learning model \nlr_model =  LogisticRegression(penalty = 'l2', C = optimal_lambda_tfidf_random, class_weight = \"balanced\")\n# fitting the model\nlr_model.fit(std_X_train, y_train)\n# predict the response\npred = lr_model.predict(std_x_test)\n# predict probablistic response\npred_prob = lr_model.predict_proba(std_x_test)","deefc06b":"# F1-score, auc, precision_recall_curve\nfrom sklearn.metrics import f1_score, auc, precision_recall_curve, average_precision_score\nfrom sklearn.metrics import auc\nf1 = f1_score(y_test, pred)\nprecision, recall, thresholds = precision_recall_curve(y_test, pred_prob[:,1])\nauc = auc(recall, precision)\navg_precision = average_precision_score(y_test, pred_prob[:,1])\nprint(\"Average precision score:\", avg_precision)\nprint(\"F1_score:\", f1)\nprint(\"Auc score:\",auc)\nplot_precision_recall_curve(recall, precision)","77812782":"train_acc_tfidf_random = lr_model.score(std_X_train, y_train)\nprint(\"Train accuracy %f%%:\" % (train_acc_tfidf_random))","70d31c63":"test_acc_tfidf_random = accuracy_score(y_test, pred) * 100\nprint('\\nThe accuracy of the logistic regression for c = %f is %.2f%%' % (optimal_lambda_tfidf_random, test_acc_tfidf_random))","e05dae7a":"# Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, pred)\ncm","58635fc8":"# plot confusion matrix to describe the performance of classifier.\nimport seaborn as sns\nclass_label = [\"negative\", \"positive\"]\ndf_cm = pd.DataFrame(cm, index = class_label, columns = class_label)\nsns.heatmap(df_cm, annot = True, fmt = \"d\")\nplt.title(\"Confusiion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","1ef9c314":"# To show main classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, pred))","df064169":"# model for knn with bag of word\nmodelsgrid = pd.DataFrame({'Model': ['Logistic Regression with TFIDF'], 'Hyper Parameter(K) for random search': [optimal_lambda_tfidf_random], 'Train Error': [train_acc_tfidf_random], 'Test Error': [100 - test_acc_tfidf_random], 'Accuracy': [test_acc_tfidf_random ], 'Train Accuracy': [train_acc_tfidf_random ]}, columns = [\"Model\", \"Hyper Parameter(K) for random search\", \"Train Error\", \"Test Error\", \"Accuracy\" , \"Train Accuracy\"])\nmodelsgrid.sort_values(by='Accuracy', ascending=False)\n","af58085b":"# Tried different value of c and finding features weight\n# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C)\nC_param = [10, 1, 0.1]\n\nfor c in C_param:\n    clf = LogisticRegression(penalty = 'l2', C = c, class_weight = \"balanced\")\n    clf.fit(X_train, y_train)\n    print('\\nC value:', c)\n    print('Coefficient of each feature:', clf.coef_)\n    print('Training accuracy: %0.3f%%' %(clf.score(std_X_train, y_train) * 100))\n    print('Test accuracy: %0.3f%%' %(clf.score(std_x_test, y_test) * 100))\n    print(\"Number of non-zero element: \",np.count_nonzero(clf.coef_))","4c9b4c49":"clf = LogisticRegression(penalty = 'l1', C = optimal_lambda_tfidf_grid, class_weight = \"balanced\" ,solver='liblinear')\nclf.fit(std_X_train, y_train)\ny_pred = clf.predict(std_x_test)\nprint(\"Accuracy score: %.2f%%\" %(accuracy_score(y_test, y_pred) * 100))\nprint(np.count_nonzero(clf.coef_))","571fe425":"std_X_train.shape","2f825b17":"np.count_nonzero(clf.coef_)","20b6e1bb":"from scipy.sparse import find\n\n# Before adding noise in data\ncf = clf.coef_[0]\nw_coef1 = cf[np.nonzero(cf)]\nprint(w_coef1[:20])","a57449cb":"# Generate random normal variable as a noise \nstd_X_train_pert = std_X_train\nnoise = np.random.normal(0, 0.001, size = (std_X_train_pert[np.nonzero(std_X_train_pert)].size,))\n#print(noise.shape)\nnp.nonzero(std_X_train_pert)\nstd_X_train_pert[np.nonzero(std_X_train_pert)] = noise + std_X_train_pert[np.nonzero(std_X_train_pert)]\nstd_X_train_pert.shape","9aaaf1d9":"std_X_train_pert.shape","648eaa17":"clf = LogisticRegression(penalty = 'l2', C = optimal_lambda_tfidf_grid, class_weight = \"balanced\")\nclf.fit(std_X_train_pert, y_train)\ny_pred = clf.predict(std_x_test)\nprint(\"Accuracy score: %0.2f%%\" %(accuracy_score(y_test, y_pred) * 100))\nprint(np.count_nonzero(clf.coef_))","fed386c0":"np.count_nonzero(clf.coef_)","ee813ede":"cf = clf.coef_[0]\nw_coef2 = cf[np.nonzero(cf)]\nprint(w_coef2[:20])","f43a2236":"# Calculate %increase \ncnt = 0\nfor w1, w2 in zip(w_coef1, w_coef2):\n    inc = abs(w1 - w2)\/abs(w1) * 100\n    if inc > 40:\n        cnt += 1\nprint(\"No of weights that changes more than 40% is:\", cnt)","7acf2947":"# Features importance \n\nfeatures = tf_idf_vect.get_feature_names()\ncoef = clf.coef_[0]\ncoeff_df = pd.DataFrame({'Word' : features, 'Coefficient' : coef})\ncoeff_df = coeff_df.sort_values('Coefficient', ascending = 0)\nprint('*****Top 10 positive*****')\nprint(coeff_df.head(10))\nprint('*****Top 10 negative*****')\nprint(coeff_df.tail(10))","4aeb887f":"# data\nX = final_10k[\"Text\"]\nX.shape","b7459547":"# Target\/class-label\ny = final_10k[\"Score\"]\ny.shape","d5e4ccb4":"# Split data\nX_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, shuffle = False)\nprint(X_train.shape, x_test.shape, y_train.shape, y_test.shape)","c830780c":"import re\ndef cleanhtml(sentence): #function to clean the word of any html-tags\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, ' ', sentence)\n    return cleantext\ndef cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n    cleaned = re.sub(r'[.|,|)|(|\\|\/]',r' ',cleaned)\n    return  cleaned","40792134":"# Train your own Word2Vec model using your own train text corpus\nimport gensim\nlist_of_sent=[]\nfor sent in X_train:\n    filtered_sentence=[]\n    sent=cleanhtml(sent)\n    for w in sent.split():\n        for cleaned_words in cleanpunc(w).split():\n            if(cleaned_words.isalpha()):    \n                filtered_sentence.append(cleaned_words.lower())\n            else:\n                continue \n    list_of_sent.append(filtered_sentence)","b1e03235":"w2v_model_train = gensim.models.Word2Vec(list_of_sent, min_count = 5, size = 50, workers = 4)","054f8d72":"w2v_model_train.wv.most_similar('like')","64d8c231":"w2v_train = w2v_model_train[w2v_model_train.wv.vocab]","f06beb0a":"w2v_train.shape","4a3861d4":"# Train your own Word2Vec model using your own test text corpus\nimport gensim\nlist_of_sent_test = []\nfor sent in x_test:\n    filtered_sentence=[]\n    sent=cleanhtml(sent)\n    for w in sent.split():\n        for cleaned_words in cleanpunc(w).split():\n            if(cleaned_words.isalpha()):    \n                filtered_sentence.append(cleaned_words.lower())\n            else:\n                continue \n    list_of_sent_test.append(filtered_sentence)","a2c60ccf":"w2v_model_test = gensim.models.Word2Vec(list_of_sent_test, min_count = 5, size = 50, workers = 4)","85beb9c0":"w2v_model_test.wv.most_similar('like')","6d160530":"w2v_test = w2v_model_test[w2v_model_test.wv.vocab]","e9f2c2b4":"w2v_test.shape","7fef35c2":"# average Word2Vec\n# compute average word2vec for each review.\nsent_vectors = []; # the avg-w2v for each sentence\/review is stored in this list\nfor sent in list_of_sent: # for each review\/sentence\n    sent_vec = np.zeros(50) # as word vectors are of zero length\n    cnt_words =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        try:\n            vec = w2v_model_train.wv[word]\n            sent_vec += vec\n            cnt_words += 1\n        except:\n            pass\n    sent_vec \/= cnt_words\n    sent_vectors.append(sent_vec)\nprint(len(sent_vectors))\nprint(len(sent_vectors[0]))","037edfd3":"# average Word2Vec\n# compute average word2vec for each review.\nsent_vectors_test = []; # the avg-w2v for each sentence\/review is stored in this list\nfor sent in list_of_sent_test: # for each review\/sentence\n    sent_vec = np.zeros(50) # as word vectors are of zero length\n    cnt_words =0; # num of words with a valid vector in the sentence\/review\n    for word in sent: # for each word in a review\/sentence\n        try:\n            vec = w2v_model_test.wv[word]\n            sent_vec += vec\n            cnt_words += 1\n        except:\n            pass\n    sent_vec \/= cnt_words\n    sent_vectors_test.append(sent_vec)\nprint(len(sent_vectors_test))\nprint(len(sent_vectors_test[0]))","fb7eeabf":"X_train = sent_vectors\n#X_train","6c387a41":"# Standardization \nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler(with_mean = False)\nstd_X_train = scaler.fit_transform(X_train)","b1decdf5":"x_test = sent_vectors_test\n#x_test","c997a26f":"scaler = StandardScaler(with_mean = False)\nstd_x_test = scaler.fit_transform(x_test)","74331f3f":"# To choose optimal_alpha using nested cross validation\n#from sklearn.model_selection import KFold\n#from sklearn.model_selection import KFold\noptimal_lambda_avgw2v_grid = lr_grid_plot(std_X_train, y_train)\noptimal_lambda_avgw2v_grid","ffbcbbd9":"# instantiate learning model \nlr_model =  LogisticRegression(penalty = 'l2', C = optimal_lambda_avgw2v_grid, class_weight = \"balanced\")\n# fitting the model\nlr_model.fit(std_X_train, y_train)\n# predict the response\npred = lr_model.predict(std_x_test)\n# predict probablistic response\npred_prob = lr_model.predict_proba(std_x_test)","566c4d30":"# F1-score, auc, precision_recall_curve\nfrom sklearn.metrics import f1_score, auc, precision_recall_curve, average_precision_score\nfrom sklearn.metrics import auc\nf1 = f1_score(y_test, pred)\nprecision, recall, thresholds = precision_recall_curve(y_test, pred_prob[:,1])\nauc = auc(recall, precision)\navg_precision = average_precision_score(y_test, pred_prob[:,1])\nprint(\"Average precision score:\", avg_precision)\nprint(\"F1_score:\", f1)\nprint(\"Auc score:\",auc)\nplot_precision_recall_curve(recall, precision)","6b072768":"train_acc_avgw2v_grid = lr_model.score(std_X_train, y_train)\nprint(\"Train accuracy:\", train_acc_avgw2v_grid)","359a1764":"test_acc_avgw2v_grid = accuracy_score(y_test, pred) * 100\nprint('\\nThe accuracy of the logistic regression for c = %f is %.2f%%' % (optimal_lambda_avgw2v_grid, test_acc_avgw2v_grid))","c87b5b1a":"# Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, pred)\ncm","489cdb38":"# plot confusion matrix to describe the performance of classifier.\nimport seaborn as sns\nclass_label = [\"negative\", \"positive\"]\ndf_cm = pd.DataFrame(cm, index = class_label, columns = class_label)\nsns.heatmap(df_cm, annot = True, fmt = \"d\")\nplt.title(\"Confusiion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","14d6d92c":"# To show main classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, pred))","b052cdec":"# model for knn with bag of word\nmodelsgrid = pd.DataFrame({'Model': ['Logistic Regression with AvgW2V'], 'Hyper Parameter(K) for random search': [optimal_lambda_avgw2v_grid], 'Train Error': [train_acc_avgw2v_grid], 'Test Error': [100 - test_acc_avgw2v_grid], 'Accuracy': [test_acc_avgw2v_grid ], 'Train Accuracy': [train_acc_avgw2v_grid ]}, columns = [\"Model\", \"Hyper Parameter(K) for grid  search\", \"Train Error\", \"Test Error\", \"Accuracy\" , \"Train Accuracy\"])\nmodelsgrid.sort_values(by='Accuracy', ascending=False)\n","ac9ced24":"optimal_lambda_avgw2v_random = lr_random_plot(std_X_train, y_train)\noptimal_lambda_avgw2v_random","85a4bf98":"# instantiate learning model \nlr_model =  LogisticRegression(penalty = 'l2', C = optimal_lambda_avgw2v_random, class_weight = \"balanced\")\n# fitting the model\nlr_model.fit(std_X_train, y_train)\n# predict the response\npred = lr_model.predict(std_x_test)\n# predict probablistic response\npred_prob = lr_model.predict_proba(std_x_test)","25c48a55":"# F1-score, auc, precision_recall_curve\nfrom sklearn.metrics import f1_score, auc, precision_recall_curve, average_precision_score\nfrom sklearn.metrics import auc\nf1 = f1_score(y_test, pred)\nprecision, recall, thresholds = precision_recall_curve(y_test, pred_prob[:,1])\nauc = auc(recall, precision)\navg_precision = average_precision_score(y_test, pred_prob[:,1])\nprint(\"Average precision score:\", avg_precision)\nprint(\"F1_score:\", f1)\nprint(\"Auc score:\", auc)\nplot_precision_recall_curve(recall, precision)","4da3526e":"# Accuracy on train data\ntrain_acc_avgw2v_random = lr_model.score(std_X_train, y_train)\nprint(\"Train accuracy\", train_acc_avgw2v_random)","8ab97fb9":"test_acc_avgw2v_random = accuracy_score(y_test, pred) * 100\nprint('\\nThe accuracy of the logistic regression for c = %f is %.2f%%' % (optimal_lambda_avgw2v_random, test_acc_avgw2v_random))","2b9b44c6":"# Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, pred)\ncm","865e28c7":"# plot confusion matrix to describe the performance of classifier.\nimport seaborn as sns\nclass_label = [\"negative\", \"positive\"]\ndf_cm = pd.DataFrame(cm, index = class_label, columns = class_label)\nsns.heatmap(df_cm, annot = True, fmt = \"d\")\nplt.title(\"Confusiion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","5840f1cf":"# To show main classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, pred))","849822d4":"# model for knn with bag of word\nmodelsgrid = pd.DataFrame({'Model': ['Logistic Regression with AvgW2V'], 'Hyper Parameter(K) for random search': [optimal_lambda_avgw2v_random], 'Train Error': [train_acc_avgw2v_random], 'Test Error': [100 - test_acc_avgw2v_random], 'Accuracy': [test_acc_avgw2v_random ], 'Train Accuracy': [train_acc_avgw2v_random ]}, columns = [\"Model\", \"Hyper Parameter(K) for random  search\", \"Train Error\", \"Test Error\", \"Accuracy\" , \"Train Accuracy\"])\nmodelsgrid.sort_values(by='Accuracy', ascending=False)\n","4c1cdfe5":"# Tried different value of c and finding features weight\n# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C)\nC_param = [10, 1, 0.1]\n\nfor c in C_param:\n    clf = LogisticRegression(penalty = 'l2', C = c, class_weight = \"balanced\")\n    clf.fit(std_X_train, y_train)\n    print('\\nC value:', c)\n    print('Coefficient of each feature:', clf.coef_)\n    print('Training accuracy: %0.3f%%' %(clf.score(std_X_train, y_train) * 100))\n    print('Test accuracy: %0.3f%%' %(clf.score(std_x_test, y_test) * 100))\n    print(\"Number of non-zero element: \",np.count_nonzero(clf.coef_))","62750279":"clf = LogisticRegression(penalty = 'l2', C = optimal_lambda_avgw2v_random, class_weight = \"balanced\")\nclf.fit(std_X_train, y_train)\ny_pred = clf.predict(std_x_test)\nprint(\"Accuracy score: %0.2f%%\" %(accuracy_score(y_test, y_pred) * 100))\nprint(np.count_nonzero(clf.coef_))","797a060d":"std_X_train.shape","1ec1eb6d":"np.count_nonzero(clf.coef_)","e05d67c0":"from scipy.sparse import find\n\n# Before adding noise in data\ncf = clf.coef_[0]\nw_coef1 = cf[np.nonzero(cf)]\nprint(w_coef1[:50])","58df75cd":"# Generate random normal variable as a noise \nstd_X_train_pert = std_X_train\nnoise = np.random.normal(0, 0.001, size = (std_X_train_pert[np.nonzero(std_X_train_pert)].size,))\n#print(noise.shape)\nnp.nonzero(std_X_train_pert)\nstd_X_train_pert[np.nonzero(std_X_train_pert)] = noise + std_X_train_pert[np.nonzero(std_X_train_pert)]\nstd_X_train_pert.shape","a7697ffb":"std_X_train_pert.shape","7b809eea":"clf = LogisticRegression(penalty = 'l2', C = optimal_lambda_avgw2v_random, class_weight = \"balanced\")\nclf.fit(std_X_train_pert, y_train)\ny_pred = clf.predict(std_x_test)\nprint(\"Accuracy score: %0.2f%%\" %(accuracy_score(y_test, y_pred) * 100))\nprint(np.count_nonzero(clf.coef_))","84b80cbb":"cf = clf.coef_[0]\nw_coef2 = cf[np.nonzero(cf)]\nprint(w_coef2[:50])","0081c546":"# Calculate %increase \ncnt = 0\nfor w1, w2 in zip(w_coef1, w_coef2):\n    inc = (abs(w1 - w2)\/abs(w2)) * 100\n    if inc > 40:\n        cnt += 1\nprint(\"No of weights that changes more than 40% is:\", cnt)","d6ca2eb6":"# model performence table using grid search\n#import itables\nmodels = pd.DataFrame({'Model': ['LogisticRegression with Bow', \"LogisticRegression with TFIDF\", \"LogisticRegression with avgw2v\"], 'Hyper Parameter(lambda)': [optimal_lambda_bow_grid, optimal_lambda_tfidf_grid, optimal_lambda_avgw2v_grid], 'Train Error': [1-train_acc_bow_grid, 1-train_acc_tfidf_grid, 1-train_acc_avgw2v_grid], 'Test Error': [100-test_acc_bow_grid, 100-test_acc_tfidf_grid, 100-test_acc_avgw2v_grid], 'Accuracy': [test_acc_bow_grid, test_acc_tfidf_grid, test_acc_avgw2v_grid]}, columns = [\"Model\", \"Hyper Parameter(lambda)\", \"Train Error\", \"Test Error\", \"Accuracy\"]).sort_values(by='Accuracy', ascending=False)\nmodels.sort_values(by='Accuracy', ascending=False)","dccf4abe":"# model performence table using random search\nmodels = pd.DataFrame({'Model': ['LogisticRegression with Bow', \"LogisticRegression with TFIDF\", \"LogisticRegression with avgw2v\"], 'Hyper Parameter(lambda)': [optimal_lambda_bow_random, optimal_lambda_tfidf_random, optimal_lambda_avgw2v_random], 'Train Error': [1-train_acc_bow_random, 1-train_acc_tfidf_random, 1-train_acc_avgw2v_random], 'Test Error': [100-test_acc_bow_random, 100-test_acc_tfidf_random, 100-test_acc_avgw2v_random], 'Accuracy': [test_acc_bow_random, test_acc_tfidf_random, test_acc_avgw2v_random]}, columns = [\"Model\", \"Hyper Parameter(lambda)\", \"Train Error\", \"Test Error\", \"Accuracy\"]).sort_values(by = \"Accuracy\", ascending = False)\nmodels.sort_values(by='Accuracy', ascending=False)","bef13059":"in this bow technique  we using grid search. In a grid search we using list for find a C like [0.01 , 0.1 , 1 , 10] etc. ","8d611f98":"Now we using grid search for tfidf and plot a graph and find error , accuracy ,f1 score graph etc.. ","0ce6b583":"# Checking for multicollinearity using pertubation test","cc1a284e":"Now we using random search for tfidf and plot a graph and find error , accuracy ,f1 score graph etc.. ","c38a959b":"If You want output ofAmazon Fine Food Review- Using Logisitc Regression kindly check out this website:-\n\n\nhttps:\/\/github.com\/shivambaldha\/Amazon-Fine-Food-Review-Using-Logisitc-Regression","dc5999e8":"# Tf-Idf","2629b755":"now we using random search and plot graph and acc....","40207c8b":"# Checking for multicollinearity using pertubation test","e4913bfe":"# Word2vec","53f81c89":"Now we use random search technique and find best C and in this random search we using interval like[10^-4,10^4] and search best c .","4deedfd2":"now we find f1 score and acc..","bdffa699":"# Amazon Fine Food Review- Using Logisitc Regression","61984839":"this time i don't know what use this step.","46d0e945":"# Checking for multicollinearity using pertubation test","1afa306c":"# Average word2vec","a9ec704b":"# Bag Of Word (BOW)"}}