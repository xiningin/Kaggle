{"cell_type":{"e7c35171":"code","2132c7bd":"code","12a3bf1c":"code","5c8ae978":"code","c97ca539":"code","4a64e6bf":"code","502640c6":"code","b81a077e":"code","56e75060":"code","63d0507d":"code","1843a66c":"code","d3876743":"code","f4ac7187":"code","7f2e002f":"code","600a5092":"code","c738b029":"code","2b59f4a2":"code","e27deda7":"code","4499a6aa":"code","22c315ac":"code","cf619dd4":"code","f72d1f17":"code","133eb0fc":"code","6a11f89d":"code","77c83a84":"code","939336fc":"code","a0774bf1":"code","3fd43d00":"code","ea9cfeb6":"code","de998ea4":"code","9f865e5a":"code","664d2e34":"code","8e52a6da":"code","b791a384":"code","b6a0156a":"code","56962e52":"code","cb86fae8":"code","aaf3ec10":"code","f4b1bcab":"markdown","23f77527":"markdown","ea9daab8":"markdown","e8b1be56":"markdown","4e1892b8":"markdown","35840fdb":"markdown","b0274eae":"markdown","9c48cb02":"markdown","a6289d2e":"markdown","70575819":"markdown","f0d335df":"markdown","610a324e":"markdown","907331ec":"markdown","5d5479b9":"markdown"},"source":{"e7c35171":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# preprocessing\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\nimport pandas_profiling as pp\n\n# models\nfrom sklearn.linear_model import RidgeCV\nimport sklearn.model_selection\nfrom sklearn.model_selection import cross_val_predict as cvp\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb\n\n\n\n# model tuning\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","2132c7bd":"valid_part = 0.3","12a3bf1c":"train0 = pd.read_csv('\/kaggle\/input\/prediction-bod-in-river-water\/train.csv')","5c8ae978":"train0.head(15)","c97ca539":"train0.info()","4a64e6bf":"pp.ProfileReport(train0)","502640c6":"train0 = train0.drop(['Id','5','6','7'], axis = 1)\ntrain0 = train0.dropna()\ntrain0.info()","b81a077e":"train0.head(3)","56e75060":"target_name = 'target'","63d0507d":"# For boosting model\ntrain0b = train0\ntrain_target0b = train0b[target_name]\ntrain0b = train0b.drop([target_name], axis=1)\n# Synthesis valid as test for selection models\ntrainb, testb, targetb, target_testb = train_test_split(train0b, train_target0b, test_size=valid_part, random_state=0)","1843a66c":"train_target0 = train0[target_name]\ntrain0 = train0.drop([target_name], axis=1)","d3876743":"#For models from Sklearn\nscaler = StandardScaler()\ntrain0 = pd.DataFrame(scaler.fit_transform(train0), columns = train0.columns)","f4ac7187":"train0.head(3)","7f2e002f":"len(train0)","600a5092":"# Synthesis valid as test for selection models\ntrain, test, target, target_test = train_test_split(train0, train_target0, test_size=valid_part, random_state=0)","c738b029":"train.head(3)","2b59f4a2":"test.head(3)","e27deda7":"train.info()","4499a6aa":"test.info()","22c315ac":"acc_train_r2 = []\nacc_test_r2 = []\nacc_train_d = []\nacc_test_d = []\nacc_train_rmse = []\nacc_test_rmse = []","cf619dd4":"def acc_d(y_meas, y_pred):\n    # Relative error between predicted y_pred and measured y_meas values\n    return mean_absolute_error(y_meas, y_pred)*len(y_meas)\/sum(abs(y_meas))\n\ndef acc_rmse(y_meas, y_pred):\n    # RMSE between predicted y_pred and measured y_meas values\n    return (mean_squared_error(y_meas, y_pred))**0.5","f72d1f17":"def acc_boosting_model(num,model,train,test,num_iteration=0):\n    # Calculation of accuracy of boosting model by different metrics\n    \n    global acc_train_r2, acc_test_r2, acc_train_d, acc_test_d, acc_train_rmse, acc_test_rmse\n    \n    if num_iteration > 0:\n        ytrain = model.predict(train, num_iteration = num_iteration)  \n        ytest = model.predict(test, num_iteration = num_iteration)\n    else:\n        ytrain = model.predict(train)  \n        ytest = model.predict(test)\n\n    print('target = ', targetb[:5].values)\n    print('ytrain = ', ytrain[:5])\n\n    acc_train_r2_num = round(r2_score(targetb, ytrain) * 100, 2)\n    print('acc(r2_score) for train =', acc_train_r2_num)   \n    acc_train_r2.insert(num, acc_train_r2_num)\n\n    acc_train_d_num = round(acc_d(targetb, ytrain) * 100, 2)\n    print('acc(relative error) for train =', acc_train_d_num)   \n    acc_train_d.insert(num, acc_train_d_num)\n\n    acc_train_rmse_num = round(acc_rmse(targetb, ytrain) * 100, 2)\n    print('acc(rmse) for train =', acc_train_rmse_num)   \n    acc_train_rmse.insert(num, acc_train_rmse_num)\n\n    print('target_test =', target_testb[:5].values)\n    print('ytest =', ytest[:5])\n    \n    acc_test_r2_num = round(r2_score(target_testb, ytest) * 100, 2)\n    print('acc(r2_score) for test =', acc_test_r2_num)\n    acc_test_r2.insert(num, acc_test_r2_num)\n    \n    acc_test_d_num = round(acc_d(target_testb, ytest) * 100, 2)\n    print('acc(relative error) for test =', acc_test_d_num)\n    acc_test_d.insert(num, acc_test_d_num)\n    \n    acc_test_rmse_num = round(acc_rmse(target_testb, ytest) * 100, 2)\n    print('acc(rmse) for test =', acc_test_rmse_num)\n    acc_test_rmse.insert(num, acc_test_rmse_num)","133eb0fc":"def acc_model(num,model,train,test):\n    # Calculation of accuracy of model \u0430\u043a\u0449\u044c Sklearn by different metrics   \n  \n    global acc_train_r2, acc_test_r2, acc_train_d, acc_test_d, acc_train_rmse, acc_test_rmse\n    \n    ytrain = model.predict(train)  \n    ytest = model.predict(test)\n\n    print('target = ', target[:5].values)\n    print('ytrain = ', ytrain[:5])\n\n    acc_train_r2_num = round(r2_score(target, ytrain) * 100, 2)\n    print('acc(r2_score) for train =', acc_train_r2_num)   \n    acc_train_r2.insert(num, acc_train_r2_num)\n\n    acc_train_d_num = round(acc_d(target, ytrain) * 100, 2)\n    print('acc(relative error) for train =', acc_train_d_num)   \n    acc_train_d.insert(num, acc_train_d_num)\n\n    acc_train_rmse_num = round(acc_rmse(target, ytrain) * 100, 2)\n    print('acc(rmse) for train =', acc_train_rmse_num)   \n    acc_train_rmse.insert(num, acc_train_rmse_num)\n\n    print('target_test =', target_test[:5].values)\n    print('ytest =', ytest[:5])\n    \n    acc_test_r2_num = round(r2_score(target_test, ytest) * 100, 2)\n    print('acc(r2_score) for test =', acc_test_r2_num)\n    acc_test_r2.insert(num, acc_test_r2_num)\n    \n    acc_test_d_num = round(acc_d(target_test, ytest) * 100, 2)\n    print('acc(relative error) for test =', acc_test_d_num)\n    acc_test_d.insert(num, acc_test_d_num)\n    \n    acc_test_rmse_num = round(acc_rmse(target_test, ytest) * 100, 2)\n    print('acc(rmse) for test =', acc_test_rmse_num)\n    acc_test_rmse.insert(num, acc_test_rmse_num)","6a11f89d":"xgb_clf = xgb.XGBRegressor({'objective': 'reg:squarederror'}) \nparameters = {'n_estimators': [60, 70, 80, 90, 95, 100, 105, 110, 120, 130, 140], \n              'learning_rate': [0.005, 0.01, 0.05, 0.075, 0.1],\n              'max_depth': [3, 5, 7, 9],\n              'reg_lambda': [0.1, 0.3, 0.5]}\nxgb_reg = GridSearchCV(estimator=xgb_clf, param_grid=parameters, cv=5, n_jobs=-1).fit(trainb, targetb)\nprint(\"Best score: %0.3f\" % xgb_reg.best_score_)\nprint(\"Best parameters set:\", xgb_reg.best_params_)\nacc_boosting_model(7,xgb_reg,trainb,testb)","77c83a84":"#%% split training set to validation set\nXtrain, Xval, Ztrain, Zval = train_test_split(trainb, targetb, test_size=0.2, random_state=0)\ntrain_set = lgb.Dataset(Xtrain, Ztrain, silent=False)\nvalid_set = lgb.Dataset(Xval, Zval, silent=False)","939336fc":"params = {\n        'boosting_type':'gbdt',\n        'objective': 'regression',\n        'num_leaves': 31,\n        'learning_rate': 0.01,\n        'max_depth': -1,\n        'subsample': 0.8,\n        'bagging_fraction' : 1,\n        'max_bin' : 5000 ,\n        'bagging_freq': 20,\n        'colsample_bytree': 0.6,\n        'metric': 'rmse',\n        'min_split_gain': 0.5,\n        'min_child_weight': 1,\n        'min_child_samples': 10,\n        'scale_pos_weight':1,\n        'zero_as_missing': False,\n        'seed':0,        \n    }\nmodelL = lgb.train(params, train_set = train_set, num_boost_round=10000,\n                   early_stopping_rounds=2000,verbose_eval=500, valid_sets=valid_set)","a0774bf1":"acc_boosting_model(8,modelL,trainb,testb,modelL.best_iteration)","3fd43d00":"models = pd.DataFrame({\n    'Model': ['XGB', 'LGBM',],\n    \n    'r2_train': acc_train_r2,\n    'r2_test': acc_test_r2,\n    'd_train': acc_train_d,\n    'd_test': acc_test_d,\n    'rmse_train': acc_train_rmse,\n    'rmse_test': acc_test_rmse\n                     })","ea9cfeb6":"pd.options.display.float_format = '{:,.2f}'.format","de998ea4":"\nmodels.sort_values(by=['r2_test', 'r2_train'], ascending=False)","9f865e5a":"models.sort_values(by=['rmse_test', 'rmse_train'], ascending=True)","664d2e34":"# Plot\nplt.figure(figsize=[25,6])\nxx = models['Model']\nplt.tick_params(labelsize=14)\nplt.plot(xx, models['r2_train'], label = 'r2_train')\nplt.plot(xx, models['r2_test'], label = 'r2_test')\nplt.legend()\nplt.title('graph for XGB and LGBM models for train and test datasets')\nplt.xlabel('Models')\nplt.ylabel('%')\nplt.xticks(xx, rotation='vertical')\nplt.savefig('graph.png')\nplt.show()","8e52a6da":"# Plot\nplt.figure(figsize=[25,6])\nxx = models['Model']\nplt.tick_params(labelsize=14)\nplt.plot(xx, models['d_train'], label = 'd_train')\nplt.plot(xx, models['d_test'], label = 'd_test')\nplt.legend()\nplt.title('Relative errors for XGB and LGBM models for train and test datasets')\nplt.xlabel('Models')\nplt.ylabel('Relative error, %')\nplt.xticks(xx, rotation='vertical')\nplt.savefig('graph.png')\nplt.show()","b791a384":"# Plot\nplt.figure(figsize=[25,6])\nxx = models['Model']\nplt.tick_params(labelsize=14)\nplt.plot(xx, models['rmse_train'], label = 'rmse_train')\nplt.plot(xx, models['rmse_test'], label = 'rmse_test')\nplt.legend()\nplt.title('graph for XGB and LGBM models for train and test datasets')\nplt.xlabel('Models')\nplt.ylabel('%')\nplt.xticks(xx, rotation='vertical')\nplt.savefig('graph.png')\nplt.show()","b6a0156a":"testn = pd.read_csv('\/kaggle\/input\/prediction-bod-in-river-water\/test.csv')\ntestn.info()","56962e52":"testn = testn.drop(['Id','5','6','7'], axis = 1)\ntestn.head(3)","cb86fae8":"#For models from Sklearn\ntestn = pd.DataFrame(scaler.transform(testn), columns = testn.columns)","aaf3ec10":"#XGB model for basic train\nxgb_reg.fit(train0, train_target0)\nxgb_reg.predict(train)[:3]","f4b1bcab":"Thanks to:\n* [Vitalii Mokin](https:\/\/www.kaggle.com\/vbmokin)\n\nThis kernel based on [BOD prediction in river - 15 regression models](http:\/\/www.kaggle.com\/vbmokin\/bod-prediction-in-river-15-regression-models).","23f77527":"[Go to Top](#0)","ea9daab8":"## 3. EDA <a class=\"anchor\" id=\"3\"><\/a>\n\n","e8b1be56":"## 7. Prediction <a class=\"anchor\" id=\"7\"><\/a>\n","4e1892b8":"## 1. Import libraries <a class=\"anchor\" id=\"1\"><\/a>\n\n","35840fdb":"The analysis showed that many values \u200b\u200bare only available in stations 1 and 2, while others have much less data. We propose that at the start code, the BOD5 prediction should be carried out only for data from the first two stations","b0274eae":"## 4. Preparing to modeling <a class=\"anchor\" id=\"4\"><\/a>\n\n","9c48cb02":"## 5. Tuning models and test for all features <a class=\"anchor\" id=\"5\"><\/a>\n\n","a6289d2e":"## 2. Download datasets <a class=\"anchor\" id=\"2\"><\/a>\n","70575819":"## 6. Models comparison <a class=\"anchor\" id=\"6\"><\/a>\n\n","f0d335df":"<a class=\"anchor\" id=\"0\"><\/a>\n\n# BOD prediction in river - XGB & LGBM","610a324e":"This code is based on kernel \"[FE & EDA with Pandas Profiling](https:\/\/www.kaggle.com\/vbmokin\/fe-eda-with-pandas-profiling)\"","907331ec":"### 5.2 LGBM <a class=\"anchor\" id=\"5.9\"><\/a>\n\n","5d5479b9":"### 5.1 XGB<a class=\"anchor\" id=\"5.8\"><\/a>\n\n"}}