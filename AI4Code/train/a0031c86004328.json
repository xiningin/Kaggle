{"cell_type":{"e64a4508":"code","7822bd14":"code","ade491c9":"code","be19f98b":"code","06e2893e":"code","9877337f":"code","668be18e":"code","5214bbd3":"code","ed275675":"code","0506d7fd":"code","44d94b50":"code","484b8eb5":"code","ff0c4c2d":"code","19560594":"code","55804982":"code","ce29a69a":"code","0045cd5b":"code","b2e15133":"code","52762bf2":"code","a0f69404":"code","846f2956":"code","0136b522":"code","c53d6f8f":"code","ddd91d0c":"code","3fc8b1df":"code","6874197c":"code","e763b29b":"code","41bd891e":"code","51fb719c":"code","d2fc1961":"code","8acd276f":"code","372589d6":"code","c9a32ceb":"code","d1dfec46":"code","01a711bf":"markdown","b1719474":"markdown","3fc3943b":"markdown","6c0c8fe0":"markdown","0ee9ca46":"markdown","aaa2bc98":"markdown","f48345fb":"markdown","20a41f85":"markdown","f0dda44c":"markdown","476c4a87":"markdown","5cdbdb63":"markdown","f9981584":"markdown","e3ea6c2a":"markdown","e5cb1bc1":"markdown","702e4fef":"markdown","3c5f7f9a":"markdown","da7f73b9":"markdown","5154dabc":"markdown","a89a74d2":"markdown","68ef8878":"markdown","2f546e43":"markdown","b71fb1b1":"markdown","93a3fa9a":"markdown","4e48848c":"markdown","3668ee96":"markdown","d750f890":"markdown","7687cf63":"markdown","69f99882":"markdown","9c223f14":"markdown","962359b6":"markdown","7d0f62af":"markdown","4737a6af":"markdown","0b70918f":"markdown","5a616560":"markdown","fe1cba6b":"markdown","40bbf4a6":"markdown","e9101085":"markdown","378232ff":"markdown","1c1e8cc8":"markdown","b1f5a026":"markdown","79252e98":"markdown"},"source":{"e64a4508":"#Basic library\nimport numpy as np \nimport pandas as pd \nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n#visualization \nimport seaborn as sns\nimport matplotlib.pyplot as plt \n%matplotlib inline \n\nsns.set_style(\"whitegrid\")\n\ndf= pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndf.tail(5)","7822bd14":"from IPython.display import display\nfrom PIL import Image\npath=\"..\/input\/conclusion\/conclusion.png\"\ndisplay(Image.open(path))","ade491c9":"df.describe()[1:6]","be19f98b":"df.info()","06e2893e":"def finding_zeros (frame):\n    columns = frame.columns[:8]\n    for i in columns:\n        zeros = len(frame.loc[frame[i]==0])\n        print(f'The numbers of 0 values in {i} = {zeros}')\n        \nfinding_zeros(df)","9877337f":"#Finding Missing Values\nNAN_value = (df.isnull().sum() \/ len(df)) * 100\nMissing = NAN_value[NAN_value==0].index.sort_values(ascending=False)\nMissing_data = pd.DataFrame({'Missing Ratio' :NAN_value})\nMissing_data.head()","668be18e":"def finding_zeros (frame):\n    columns = frame.columns[:8]\n    for i in columns:\n        zeros = len(frame.loc[frame[i]==0])\n        print(f'The numbers of 0 values in {i} = {zeros}')\n        \n# Let's Find all those Cells that have 0 Values\ncond1= df[(df['Insulin']==0) & (df['SkinThickness']==0) & (df['Pregnancies']==0) & (df['BloodPressure']==0) & (df['BMI']==0)].index\ncond2 = df[(df['Insulin']==0) & (df['SkinThickness']==0) & (df['Pregnancies']==0) & (df['BloodPressure']==0)].index\nZeros_values = cond2.append(cond1) \ndf.drop(Zeros_values,inplace=True)\n\nfinding_zeros(df)","5214bbd3":"f,ax = plt.subplots(figsize=(15,10))\nmask = np.triu(df.corr())\nsns.heatmap(df.corr(), annot=True, mask=mask,ax=ax,cmap='viridis')\nbottom,top = ax.get_ylim()\nax.set_ylim(bottom+ 0.5, top - 0.5)\nprint(\"variable relationship\")","ed275675":"f,(ax1,ax2,ax3) =plt.subplots(1,3,figsize=(20,5))\ny='Insulin'\nsns.regplot(y=y,x='Glucose',data=df,order = 2,ax=ax1)\nsns.scatterplot(y=y,x='SkinThickness',data=df , ax=ax2,hue='Outcome')\nsns.boxplot(df.Glucose,ax=ax3)\nprint(\"This shows that the Higher Glucose. Higher Insuline\")","0506d7fd":"#Defining Intervals\nlower = np.arange(26,236,5) #ax=ax Glucose we can see the min 20 , max 200\nupper= np.arange(30,205,5)\n\n#Finding the Insuline based on the Glucose\/segmented \ndef find_insuline (name,down,top):\n    result = df.loc[(df['Insulin']>0)&(df['Glucose']>=down)&(df['Glucose']<=top)]['Insulin'].mean()\n    result=np.round(result)\n    Value.append(result)\n    #print(f'the Mean of {name} in range {down}, {top} is :{result}')  \n    \n#Insuline Mean value  \nValue= []\nfor i,j in zip(lower,upper):\n    find_insuline(\"Insulin\",i,j)\n    \nValue[1:9]  # <--- Here we have a lot of value but this way is more visualy friendly","44d94b50":"#Finding Insulines zero value (based on gluose) _index by range\ndef find_insuline_index (name,down,top):\n    Index= df[(df['Insulin']==0) & (df['Glucose']>=down) & (df['Glucose']<=top)].index.values\n    Indexes.append(Index)\n    #print(f'the index in range {down}, {top} is :{Index}')\n    \n#Index\nIndexes =[]\nfor i , j in zip(lower,upper):\n    find_insuline_index(\"Index\",i,j)   \n\nIndexes[10:13] #It will show all the indexes with Insulin == 0","484b8eb5":"#Total\nfor i,j in zip (np.arange(0,36,1),Value):\n    df.loc[Indexes[i],\"Insulin\"]=j\n# Values replace nan for 0    \nfor i in np.arange(0,4,1):\n    df.loc[Indexes[i],\"Insulin\"]=0\n#Interval from 61,65 with 42   \ndf.loc[Indexes[7],\"Insulin\"]=42\n\nfinding_zeros(df)","ff0c4c2d":"f,(ax1,ax2,ax3) =plt.subplots(1,3,figsize=(20,5))\ny='SkinThickness'\nsns.scatterplot(y=y,x='BMI',data=df,ax=ax1)\nsns.scatterplot(y=y,x='Glucose',data=df , ax=ax2,hue='Outcome')\nsns.boxplot(df.BMI,ax=ax3)\nprint(\"This shows that the greater BMI ,the greater SkinThickness (it maskes sense)\")\n","19560594":"# I wont delete the oulier(except zero) because it is not wrong data, according to the Paper they are all girls 21>Age years old\ni_skin = np.arange(15,70,5)\nj_skin = np.arange(20,75,5)\n\n#Finding Value based on BMI\ndef finding_skin (name,down,top):\n    result = df.loc[(df['SkinThickness']>0)&(df['BMI']>=down)&(df['BMI']<=top)]['SkinThickness'].mean()\n    result=np.round(result,2)\n    Skin_values.append(result)\n    #print(f'the Mean of {name} in range {down}, {top} is :{result}')\n    \nSkin_values =[]\nfor i, j in zip (i_skin,j_skin):\n    finding_skin(\"Thickness\",i,j)\n    \nSkin_values","55804982":"def finding_skin_index (name,down,top):\n    Index = df.loc[(df['SkinThickness']==0)&(df['BMI']>=float(down))&(df['BMI']<=float(top))]['SkinThickness'].index.values\n    Skin_Index.append(Index)\n    #print(f'the index in range {down}, {top} is :{Index}')\n    \nSkin_Index = []\nfor i, j in zip (i_skin,j_skin):\n    finding_skin_index(\"Thickness\",i,j)\n    \nSkin_Index[0:2]","ce29a69a":"#replacing Values    \nfor i,j in zip (np.arange(0,10,1),j_skin):\n    df.loc[Skin_Index[i],\"SkinThickness\"]=j\n    \nfinding_zeros(df)","0045cd5b":"SKIN_BMI_ZERO= df[(df['SkinThickness']==0)&(df['BMI']==0)]\nSKIN_BMI_ZERO","b2e15133":"BLOOD_INSULINE_ZERO= df[(df['Glucose']==0)&(df['Insulin']==0)]\nBLOOD_INSULINE_ZERO","52762bf2":"#Index\nBLOOD_INSULINE_ZERO=df[(df['Glucose']==0)&(df['Insulin']==0)].index.values\nSKIN_BMI_ZERO= df[(df['SkinThickness']==0)&(df['BMI']==0)].index.values\n\n#Droping VAlues\ndf.drop(BLOOD_INSULINE_ZERO, inplace=True)\ndf.drop(SKIN_BMI_ZERO ,inplace=True)","a0f69404":"f,(ax1,ax2) =plt.subplots(1,2,figsize=(20,5))\nsns.scatterplot(x='BloodPressure',y='BMI',data=df, ax=ax1)\nsns.scatterplot(x='Age',y='BloodPressure',data=df, ax=ax2) ","846f2956":"df.drop(df[df['BloodPressure']==0].index.values,inplace=True)\n#Finding Missing Values\nNAN_value = (df.isnull().sum() \/ len(df)) * 100\nMissing = NAN_value[NAN_value==0].index.sort_values(ascending=False)\nMissing_data = pd.DataFrame({'Missing Ratio' :NAN_value})\nMissing_data.head()","0136b522":"def boxplot (frame1,frame2,frame3):\n    f,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(20,5))\n    sns.boxplot(frame1,ax=ax1)\n    sns.boxplot(frame2,ax=ax2)\n    sns.boxplot(frame3,ax=ax3)","c53d6f8f":"boxplot(df.Pregnancies,df.Glucose,df.BloodPressure)","ddd91d0c":"boxplot(df.SkinThickness,df.Insulin,df.BMI)","3fc8b1df":"boxplot(df.DiabetesPedigreeFunction,df.Age,df.Outcome)","6874197c":"preg = df.loc[df['Pregnancies']>=15]['Pregnancies'].count()\nglu = df.loc[df['Glucose']<40]['Glucose'].count()\nblood_1 =df[df['BloodPressure']<40]['BloodPressure'].count() \nblood_2 = df[df['BloodPressure']>100]['BloodPressure'].count()\nblood = blood_1 + blood_2\nskin = df[df['SkinThickness']>55]['SkinThickness'].count()\ninsu =df[df['Insulin']>380]['Insulin'].count()\nbmi = df[df['BMI']>50]['BMI'].count()\ndia = df[df['DiabetesPedigreeFunction']>1.2]['DiabetesPedigreeFunction'].count()\nage= df[df['Age']>63]['Age'].count()\noutliers = [preg,glu,blood,skin,insu,bmi,dia,age]\nOutliers = pd.DataFrame(data=outliers, index = df.columns[0:8], columns=['Outliers'])\nOutliers","e763b29b":"preg_i = df.loc[df['Pregnancies']>=15]['Pregnancies'].index.values\nglu_i = df.loc[df['Glucose']<40]['Glucose'].index.values\nblood_1_i =df[df['BloodPressure']<40]['BloodPressure'].index.values \nblood_2_i= df[df['BloodPressure']>100]['BloodPressure'].index.values\nskin = df[df['SkinThickness']>55]['SkinThickness'].index.values\ninsu =df[df['Insulin']>380]['Insulin'].index.values\nbmi = df[df['BMI']>50]['BMI'].index.values\ndia = df[df['DiabetesPedigreeFunction']>1.2]['DiabetesPedigreeFunction'].index.values\nage= df[df['Age']>63]['Age'].index.values\n\nind_out = [preg_i,glu_i,blood_1_i,blood_2_i,skin,insu,bmi,dia,age]\nfor i in ind_out:\n    df_out= df.drop(i)","41bd891e":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report,f1_score\n\nX=df_out.drop('Outcome',axis=1)\ny=df_out['Outcome']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)","51fb719c":"from sklearn.ensemble import RandomForestClassifier\nRFC = RandomForestClassifier(n_estimators=100)\nRFC_model =RFC.fit(X_train,y_train)\ny_pred_RFC= RFC.predict(X_test)\ny_pred_RFC\n\nprint(classification_report(y_test,y_pred_RFC))\nRFC_cm =confusion_matrix(y_test,y_pred_RFC)\nprint(f1_score(y_test,y_pred_RFC))\n#confusion_matrix(y_pred_RFC, y_test)\n","d2fc1961":"from sklearn.preprocessing import StandardScaler\n\nES=StandardScaler()\nES=ES.fit_transform(df_out.drop('Outcome',axis=1))\ndata= pd.DataFrame(ES , columns= df.columns[:-1])\ndata.head(4) # data_p = Data already Processed\n\nX_data=data\ny_data=df_out['Outcome']\n\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33, random_state=101)\ndata.head()","8acd276f":"from sklearn.linear_model import LogisticRegression\nlog=LogisticRegression()\nlog=log.fit(X_train,y_train)\ny_pred_log = log.predict(X_test)\n\nlog_m = confusion_matrix(y_test,y_pred_log )\n                         \nprint(classification_report(y_test,y_pred_log))\n#print(confusion_matrix(y_test,y_pred_log))\nprint(f1_score(y_test,y_pred_log))","372589d6":"from sklearn.neighbors import KNeighborsClassifier\n\nError_Rate = []\nfor i in range (1,50):\n    \n    KNN_Error = KNeighborsClassifier(n_neighbors=i)\n    KNN_Error.fit(X_train,y_train)\n    pred_i = KNN_Error.predict(X_test)\n    Error_Rate.append(np.mean(pred_i != y_test))\n    \nplt.figure(figsize=(10,6))\nplt.plot(range(1,50), Error_Rate , color = 'blue', linestyle = 'dashed', marker = 'o')\nplt.title('Error rate vs K value')\nprint( \" K=3 is the most accurate rate because the error is closest to 0 \")    \n","c9a32ceb":"KNN=KNeighborsClassifier(n_neighbors=3)\nKNN=KNN.fit(X_train,y_train)\ny_pred_KNN= KNN.predict(X_test)\n\nKNN_cm =confusion_matrix(y_test,y_pred_KNN)\nprint(classification_report(y_test,y_pred_KNN))\n#print(confusion_matrix(y_test,y_pred_KNN))\nf1_score(y_test,y_pred_KNN)\n","d1dfec46":"f,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20,5))\nmodel= [log_m,RFC_cm,KNN_cm]\naxes= [ax1,ax2,ax3]\n\nfor i,j in zip (model,axes):\n    group_names = ['True Neg','False Pos','False Neg','True Pos']\n        \n    group_counts = ['{0:0.0f}'.format(value) for value in\n                i.flatten()]\n        \n    group_percentages = ['{0:.2%}'.format(value) for value in\n                     i.flatten()\/np.sum(i)]\n        \n    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n     zip(group_names,group_counts,group_percentages)]\n    labels = np.asarray(labels).reshape(2,2)\n        \n    ax =sns.heatmap(i, annot=labels, fmt='', cmap='plasma',ax=j)","01a711bf":"# 1.Introduction ","b1719474":"## In this section I want to drop all those rows which as 0 Values in all the columns\n1. Because later I want to find some relation between variable but 0 values might affect the final result\n2. I realized I can do this with dropna.(tresh=#), but I will have to create a new Dataframe and applya pd.join\n3. I check other forums and many user mentioned the highest accurancy was 60 % so I thought that the missing values might influence the final result ","3fc3943b":"### 4.3. Replacing Values ","6c0c8fe0":"### 6.3. Dropping Values\n","0ee9ca46":"# \"--------  Section 6 ----------\"","aaa2bc98":"## 10. Applying Machine Learning \n1. ##### Splitting Data","f48345fb":"**Conclusion:** Glucose -  Insulin , Skinthickness - BMI","20a41f85":"## 3.1. Finding the Relation Between Variable to fill out values 0\n1. By using a heatmap, I intended to find a relation between variable (Glucose-Skinthickness-BMI-Insulin), later I will use the relation with stronger coorelation to find the missing values\n2. Instead of using the group mean or Interpolate, I will sort the value by ranks I.e Find all People with Glucose btwn A-B, then extract the mean and use this value to fill the missing one ","f0dda44c":"## 7. Blood Pressure","476c4a87":"# 3. FINDING MISSING VALUES","5cdbdb63":"#### 6.2.Glucose ~ Insulin","f9981584":"### 4.2. Finding Index of Insulin == 0","e3ea6c2a":"# \"--------  Section 5 ----------\"","e5cb1bc1":"##### 4. Applying KNN ","702e4fef":"## 6. Variable related with 0 Values  \n#### 6.1. Skinth Thickness ~ BMI","3c5f7f9a":"## 8. Visualization","da7f73b9":"##### 3. Applying Logistic Regression","5154dabc":"# \"--------  Section 7 ----------\"","a89a74d2":"## 4. Finding Insuline Values\n\n1.  Isuline has 364 \"0\" so I will try to fill them according to Glucose and Skinthickness, but first I will create some graph to have a general view of the data Behav.\n2.  Based on the Graph , We can notice that Insuline - Glucose has a better reationship \"it might seemed a linear regresion\" , the higher A is , B is as well,(please feel free to let any comment on this)\n3. Because Glucose is gonna be my parameter I have to create some Interval to limite the values (I.e People who has glucose btwn A and B and then Extract the mean)","68ef8878":"#### 2. Applying Random Forest Tree","2f546e43":"### 5.3. Finding Skin-Thickness Index\n    \n","b71fb1b1":"# 1.1. Conclusion ","93a3fa9a":"I can apply the same methodology to 'bloodpresurre' but after consulting with doctor (Friend of mine) He claims that blood pressure con not be associate with age , because it varies according several factors and that are not showed in the Data ","4e48848c":"##### Based on the Graph there is a better relation btwn Insulin-Glucose, so now I will fill them segmented by interval = 5","3668ee96":"# \"--------  Section 3 ----------\"","d750f890":"### 4.1. Finding Mean of Insulin","7687cf63":"## 9. Outliers","69f99882":"# \"--------  Section 2 ----------\"\n","9c223f14":"# \"--------  Section 4 ----------\"","962359b6":"                                             **From *LEFT* to *RIGHT***  Logistical Regression - Random Forest - KNN cluster","7d0f62af":"#### **We can easealy notice that there are so many outliers**","4737a6af":"# \"--------  Section 8 ----------\"","0b70918f":"### 5.1. Creating Intervals\n### 5.2. Finding SlkinThickness Values (mean)","5a616560":"## 2. Scrub data** (filtering, extracting , replacing , handle missing values)","fe1cba6b":"## * 5. Finding Skin-Thickness*","40bbf4a6":"    **From *LEFT* to *RIGHT***  BEST = \"Logistical Regression\" - Random Forest - KNN cluster","e9101085":"### In This Kernel I tried to fill those 0 values by using the correalation between variables, I also ask for some comment (doctor) to make sure about the relation between varaiable, these kernel is not that visual friendly because I had to find several intervals\/ each columns , instead of using the mean \/ columns , I checked several kernel with 90% accurancy but i got 61 max, anyway it was a great challenge because it improved my pandas and numpy skills. Feel free to provide some feedback or a better way to find or replace the values ","378232ff":"### 5.4. Replacing Values","1c1e8cc8":"###### The following Interval has Nan values so they will remain with 0 values \n1. The Mean of Insulin in range 31, 35 is :nan\n2. The Mean of Insulin in range 36, 40 is :nan\n3. The Mean of Insulin in range 41, 45 is :nan\n4. The Mean of Insulin in range 46, 50 is :nan\n5. The Mean of Insulin in range 51, 55 is :nan\n\n###### The Interval from 61,65 has nan value, but I can interpolate the value from rank 56-60 and 66-70","b1f5a026":"### Dropping Outliers","79252e98":"### When I was analyzing this data frame I realized that there were many 0 values,then i was checking others kenerls and found out that many people was asking if theses 0 were set in purpose including myself,because I couldnt find any guidance , I decided to fill them out. \n1. I decided to fill out those value that has some kind of relation between variables\n2. I wrote a Funcion to easily chech how many Zeros are lefft to keep tracking "}}