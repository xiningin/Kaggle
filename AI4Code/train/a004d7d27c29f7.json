{"cell_type":{"4a7b825b":"code","d56b14fb":"code","60a9c886":"code","f4e16906":"code","388d4e8c":"code","8c3e3750":"code","dc7869b4":"code","7d8b23fd":"code","5e03e4c2":"code","f469f834":"code","20e5f5c9":"code","d3114f7a":"code","86abfd43":"code","5aa76f82":"code","30d218b4":"code","9d504a7f":"code","c5de7320":"code","be3abf25":"code","6583e8aa":"code","7c3b511e":"code","a9234158":"code","1d10b383":"code","69065b51":"code","bb1baed2":"code","61adc997":"code","d43ed893":"code","4736b1cf":"code","52a8329e":"code","bd282912":"code","098d9943":"code","44cef6de":"code","5105cb7b":"code","b74c73c4":"code","322873dd":"markdown","53266ca4":"markdown","50384ed7":"markdown","8411a205":"markdown","8e2ddd4a":"markdown","3fee6af0":"markdown","6f83e586":"markdown","acf38758":"markdown","954a68cd":"markdown","6d1579df":"markdown","51245519":"markdown","b0034eea":"markdown","7af1c225":"markdown","4241a1e1":"markdown","c5b4651f":"markdown"},"source":{"4a7b825b":"import os\nimport numpy as np \nimport pandas as pd \n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers\n\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\n\n# random seed\nnp.random.seed(42)","d56b14fb":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\n    \nprint('Number of replicas in sync:', strategy.num_replicas_in_sync)","60a9c886":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [224, 224]\nEPOCHS = 25","f4e16906":"# get GCS path of the dataset\nGCS_PATH = KaggleDatasets().get_gcs_path()\nGCS_PATH","388d4e8c":"# get filenames from train and validation data\nimage_files = tf.io.gfile.glob(str(GCS_PATH + '\/chest_xray\/train\/*\/*'))\nimage_files.extend(tf.io.gfile.glob(str(GCS_PATH + '\/chest_xray\/val\/*\/*')))\n\n# split data into train and validation set\ntrain_files, val_files = train_test_split(image_files, \n                                          test_size = 0.2, \n                                          random_state = 42)","8c3e3750":"# count the number of normal and pneumonia images in the training data set\nCOUNT_NORMAL = len([file for file in train_files if 'NORMAL' in file])\nprint(f'Normal images count in training data: {COUNT_NORMAL}')\n\nCOUNT_PNEUMONIA = len([file for file in train_files if 'PNEUMONIA' in file])\nprint(f'Pneumonia images count in training data: {COUNT_PNEUMONIA}')","dc7869b4":"train_ds = tf.data.Dataset.from_tensor_slices(train_files)\nval_ds = tf.data.Dataset.from_tensor_slices(val_files)\n\n# check the number of training and validation images\nTRAIN_IMG_COUNT = tf.data.experimental.cardinality(train_ds).numpy()\nVAL_IMG_COUNT = tf.data.experimental.cardinality(val_ds).numpy()\n\nprint(f'Number of training images: {TRAIN_IMG_COUNT}')\nprint(f'Number of validation images: {VAL_IMG_COUNT}')","7d8b23fd":"# complete path of the training images\nfor path in train_ds.take(5):\n    print(path.numpy())","5e03e4c2":"# class names\nCLASS_NAMES = np.array([str(tf.strings.split(item, os.path.sep)[-1].numpy())[2:-1]\n                        for item in tf.io.gfile.glob(str(GCS_PATH + \"\/chest_xray\/train\/*\"))])\nCLASS_NAMES","f469f834":"def get_label(file_path):\n    # convert the path to a list of path components\n    parts = tf.strings.split(file_path, os.path.sep)\n    # The second to last is the class-directory\n    return parts[-2] == \"PNEUMONIA\"","20e5f5c9":"def decode_img(img):\n  # convert the compressed string to a 3D uint8 tensor\n  img = tf.image.decode_jpeg(img, channels = 3)\n  # Use `convert_image_dtype` to convert to floats in the [0, 1] range\n  img = tf.image.convert_image_dtype(img, tf.float32)\n  # resize the image to the desired size.\n  return tf.image.resize(img, IMAGE_SIZE)","d3114f7a":"def process_path(file_path):\n    label = get_label(file_path)\n    # load the raw data from the file as a string\n    img = tf.io.read_file(file_path)\n    img = decode_img(img)\n    return img, label","86abfd43":"train_ds = train_ds.map(process_path, num_parallel_calls = AUTOTUNE)\nval_ds = val_ds.map(process_path, num_parallel_calls = AUTOTUNE)\n\n# check the shape of images\nfor image, label in train_ds.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())","5aa76f82":"test_ds = tf.data.Dataset.list_files(str(GCS_PATH + '\/chest_xray\/test\/*\/*'))\nTEST_IMAGE_COUNT = tf.data.experimental.cardinality(test_ds).numpy()\ntest_ds = test_ds.map(process_path, num_parallel_calls = AUTOTUNE)\ntest_ds = test_ds.batch(BATCH_SIZE)\n\nTEST_IMAGE_COUNT","30d218b4":"# This is a small dataset, only load it once, and keep it in memory\n# use `.cache(filename)` to cache preprocessing work for datasets that don't\n# fit in memory\ntrain_ds = train_ds.cache().shuffle(buffer_size = 1000)\n\n# Repeat forever\n# `prefetch` lets the dataset fetch batches in the background while the model\n# is training\ntrain_ds = train_ds.repeat().batch(BATCH_SIZE).prefetch(buffer_size = AUTOTUNE)\n\nval_ds = val_ds.cache().shuffle(buffer_size = 1000).repeat().batch(BATCH_SIZE)\nval_ds = val_ds.prefetch(buffer_size = AUTOTUNE)","9d504a7f":"def show_batch(image_batch, label_batch):\n    plt.figure(figsize = (10,10))\n    for n in range(25):\n        ax = plt.subplot(5, 5, n + 1)\n        plt.imshow(image_batch[n])\n        if label_batch[n]:\n            plt.title(\"PNEUMONIA\")\n        else:\n            plt.title(\"NORMAL\")\n        plt.axis(\"off\")","c5de7320":"# call the next batch \nimage_batch, label_batch = next(iter(train_ds))","be3abf25":"# show batch of images\nshow_batch(image_batch.numpy(), label_batch.numpy())","6583e8aa":"def conv_block(filters):\n    block = tf.keras.Sequential([\n        layers.SeparableConv2D(filters, 3, activation = 'relu', padding = 'same'),\n        layers.SeparableConv2D(filters, 3, activation = 'relu', padding = 'same'),\n        layers.BatchNormalization(),\n        layers.MaxPool2D()\n    ])\n    \n    return block","7c3b511e":"def dense_block(units, dropout_rate):\n    block = tf.keras.Sequential([\n        layers.Dense(units, activation = 'relu'),\n        layers.BatchNormalization(),\n        layers.Dropout(dropout_rate)\n    ])\n    \n    return block","a9234158":"def build_model():\n    model = tf.keras.Sequential([\n        layers.Input(shape = (IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n        \n        layers.Conv2D(16, 5, activation = 'relu', padding = 'same'),\n        layers.Conv2D(16, 5, activation = 'relu', padding = 'same'),\n        layers.MaxPool2D(),\n        \n        conv_block(32),\n        conv_block(64),\n        conv_block(128),\n        layers.Dropout(0.2),\n        conv_block(256),\n        layers.Dropout(0.2),\n        \n        layers.Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        \n       layers.Dense(1, activation = 'sigmoid')\n    ])\n    \n    return model","1d10b383":"initial_bias = np.log([COUNT_PNEUMONIA \/ COUNT_NORMAL])\ninitial_bias","69065b51":"weight_for_0 = (1 \/ COUNT_NORMAL) * (TRAIN_IMG_COUNT) \/ 2.0 \nweight_for_1 = (1 \/ COUNT_PNEUMONIA) * (TRAIN_IMG_COUNT) \/ 2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","bb1baed2":"with strategy.scope():\n    model = build_model()\n\n    METRICS = [\n        'accuracy',\n        tf.keras.metrics.Precision(name = 'precision'),\n        tf.keras.metrics.Recall(name = 'recall')\n    ]\n    \n    model.compile(\n        optimizer = 'adam',\n        loss = 'binary_crossentropy',\n        metrics = METRICS\n    )","61adc997":"# train the model\nhistory = model.fit(\n    train_ds,\n    steps_per_epoch = TRAIN_IMG_COUNT \/\/ BATCH_SIZE,\n    epochs = EPOCHS,\n    validation_data = val_ds,\n    validation_steps = VAL_IMG_COUNT \/\/ BATCH_SIZE,\n    class_weight = class_weight,\n)","d43ed893":"# learning rate decay\ndef exponential_decay(lr0, s):\n    def exponential_decay_fn(epoch):\n        return lr0 * 0.1 ** (epoch \/ s)\n    return exponential_decay_fn\n\n\nexponential_decay_fn = exponential_decay(0.01, 20)\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\ncheckpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"xray_model.h5\",\n                                                    save_best_only = True)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience = 10,\n                                                     restore_best_weights = True)","4736b1cf":"history = model.fit(\n    train_ds,\n    steps_per_epoch =TRAIN_IMG_COUNT \/\/ BATCH_SIZE,\n    epochs = 100,\n    validation_data = val_ds,\n    validation_steps = VAL_IMG_COUNT \/\/ BATCH_SIZE,\n    class_weight = class_weight,\n    callbacks = [checkpoint_cb, early_stopping_cb, lr_scheduler]\n)","52a8329e":"with strategy.scope():\n    base_model = tf.keras.applications.InceptionV3(include_top = False, \n                                           weights = 'imagenet', \n                                           input_shape = (224, 224, 3))\n    base_model.trainable = False\n    \n    pool_out = layers.GlobalAveragePooling2D()(base_model.output)\n    pool_out = layers.Dropout(0.3)(pool_out)\n    output = layers.Dense(1, activation = 'sigmoid')(pool_out)\n    \n    inception = tf.keras.Model(base_model.input, output)\n    \n    METRICS = [\n        'accuracy',\n        tf.keras.metrics.Precision(name = 'precision'),\n        tf.keras.metrics.Recall(name = 'recall')\n    ]\n    \n    inception.compile(\n        optimizer = 'adam',\n        loss = 'binary_crossentropy',\n        metrics = METRICS\n    )","bd282912":"# finetune the model\nhistory = inception.fit(\n    train_ds,\n    steps_per_epoch = TRAIN_IMG_COUNT \/\/ BATCH_SIZE,\n    epochs = EPOCHS,\n    validation_data = val_ds,\n    validation_steps = VAL_IMG_COUNT \/\/ BATCH_SIZE,\n    class_weight = class_weight,\n)","098d9943":"# train the top 2 inception blocks (layer after 249)\nfor layer in base_model.layers[:249]:\n    layer.trainable = False\nfor layer in base_model.layers[249:]:\n    layer.trainable = True\n\n# compile the model\ninception.compile(\n        optimizer = tf.keras.optimizers.SGD(lr = 0.0001, momentum = 0.9),\n        loss = 'binary_crossentropy',\n        metrics = METRICS    \n)\n\n# fine tune the model\nhistory = inception.fit(\n    train_ds,\n    steps_per_epoch = TRAIN_IMG_COUNT \/\/ BATCH_SIZE,\n    epochs = 100,\n    validation_data = val_ds,\n    validation_steps = VAL_IMG_COUNT \/\/ BATCH_SIZE,\n    class_weight = class_weight,\n    callbacks = [checkpoint_cb, early_stopping_cb, lr_scheduler]\n)","44cef6de":"fig, ax = plt.subplots(1, 4, figsize = (20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","5105cb7b":"# check the performace of separable CNN model on test data\nloss, acc, prec, rec = model.evaluate(test_ds)","b74c73c4":"# check the performace of inception model on test data\nloss, acc, prec, rec = inception.evaluate(test_ds)","322873dd":"### Read the training, validation and test data","53266ca4":"### Transfer Learning using InceptionV3","50384ed7":"### Create training and validation datasets","8411a205":"### Conclusion\n- From the results on test data it can be seen that Inception model performed better than the separable CNN model and improved the precision.\n- Our recall is greater than our precision, indicating that almost all pneumonia images are correctly identified but some normal images are falsely identified. We should aim to increase our precision.","8e2ddd4a":"### Detect and setup TPU","3fee6af0":"### Model","6f83e586":"### This notebook is inspired from Amy Jang's notebook [here](https:\/\/www.kaggle.com\/amyjang\/tensorflow-pneumonia-classification-on-x-rays). Additionally in this notebook, I have finetuned InceptionV3 and compared its performance to Separable CNN model. InceptionV3 performed better and increased precision, recall as well as accuracy on the test data.","acf38758":"### Prepare data","954a68cd":"- Precision is the number of true positives (TP) over the sum of TP and false positives (FP). It shows what fraction of labeled positives are actually correct.\n\n- Recall is the number of TP over the sum of TP and false negatves (FN). It shows what fraction of actual positives are correct.","6d1579df":"### Finetuning model","51245519":"### Number of images in each class in training data","b0034eea":"- The dataset is imbalanced as the number of normal images are much less than the pneumonia images","7af1c225":"### Prepare test images\n","4241a1e1":"### Display batch of images","c5b4651f":"### Set up some global variables"}}