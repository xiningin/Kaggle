{"cell_type":{"4ed5bb29":"code","59ba5c8b":"code","5c4932f9":"code","4037a5e5":"code","0c74e1e4":"code","650dd51d":"code","3528b1d0":"code","71679eea":"code","c0b78651":"code","1a7f1eab":"code","0ad096ce":"code","190e1364":"code","fba42a5b":"code","5281b958":"code","a85e4012":"code","0c61bb30":"code","76be93bd":"code","062bacd2":"code","9d551352":"code","97299225":"code","25448c47":"code","6a7174ea":"code","cbc7de0d":"code","37ba595b":"code","c518ba5e":"code","0ed9925e":"code","0b717830":"code","deebd11f":"code","8b161b61":"code","4e9a3cb5":"code","1c9ef99d":"code","d547ef49":"code","d6f4ddf8":"code","fd94d21a":"code","236b75fb":"code","56cd4d2c":"code","bd23e8ea":"markdown","eed342a0":"markdown","d81ae297":"markdown","1cdc838f":"markdown","ac1793f1":"markdown","268ae22d":"markdown","cdef194c":"markdown","50433ae1":"markdown","3b26df3f":"markdown","439fc95f":"markdown","754711ce":"markdown"},"source":{"4ed5bb29":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\n\n# from sklearn import datasets # \u00e9ste no hace falta","59ba5c8b":"df = pd.read_csv('..\/input\/compas-scores\/compas-scores.csv')","5c4932f9":"df_reducido = df[['name', 'age', 'sex', 'race', 'compas_screening_date', 'decile_score', 'v_decile_score', 'is_recid', 'r_offense_date', 'is_violent_recid', 'vr_offense_date', 'priors_count' \n ]].copy()","4037a5e5":"df_reducido.head() # vemos que tiene pocas columnas: es m\u00e1s c\u00f3modo trabajar as\u00ed","0c74e1e4":"df_reducido.info()","650dd51d":"df_reducido.nunique()","3528b1d0":"(df_reducido.is_recid == -1).value_counts() # contamos el n\u00famero de elementos (len) donde df.is_recid == -1","71679eea":"# vemos que hay 719 que son -1, lo que coincide con lo que dice la publicaci\u00f3n citada previamente\n# vamos a eliminarlos\n\n#df_reducido = df_reducido[df_reducido.is_recid != -1] # solo conservo los valores del dataframe para los \n# que 'is_recid' es distinto (!=) de -1\n\ndf_reducido.drop(df_reducido[df_reducido.is_recid == -1].index, inplace=True)","c0b78651":"df_reducido.nunique() # para comprobar si lo ha hecho bien","1a7f1eab":"'''\nlo siguiente es comprobar si los valores 'NaT' que aparecen en 'r_offense_date' 'vr_offense_date' se corresponden\nrealmente con 'no reincidentes'. Es decir, cada vez que aparezca un 'NaT', 'is_recid' o 'is_violent_recid' \n(el que corresponda) deben ser cero \n\nPara ello miro los elementos '\u00fanicos' que tiene 'is_recid' cuando 'r_offense_date' es 'NaT', lo que para Python\nes un valor 'null'\n'''\n\ndf_reducido.is_recid[df_reducido.r_offense_date.isnull()].unique()","0ad096ce":"# vemos que 'is_recid' es siempre cero, lo que confirma la hip\u00f3tesis. Hacemos lo mismo para 'is_violent_recid'\n\ndf_reducido.is_violent_recid[df_reducido.vr_offense_date.isnull()].unique()\n","190e1364":"# Perfecto. Parece que los datos no tienen inconsistencias.\n\n# Vamos de todas formas a echarles un nuevo vistazo\n\ndf_reducido.info()","fba42a5b":"df_reducido.nunique()","5281b958":"# el dataframe tiene 11038 filas; pero solo hay 10902 nombres distintos. Esto quiere decir que hay nombres \n# repetidos. A priori, no tiene nada de extra\u00f1o. No obstante, pudiera ocurrir que algunas de esas personas\n# sean, en realidad, la misma. Vamos a echarle un vistazo al tema\n\ndf_reducido[df_reducido.duplicated(['name', 'age'], keep=False)].sort_values(by = 'name')","a85e4012":"# el dataframe tiene 11038 filas; pero solo hay 10902 nombres distintos. Esto quiere decir que hay nombres \n# repetidos. A priori, no tiene nada de extra\u00f1o. No obstante, pudiera ocurrir que algunas de esas personas\n# sean, en realidad, la misma. Vamos a echarle un vistazo al tema\n\ndf_reducido[df_reducido.duplicated(['name', 'age'], keep=False)].sort_values(by = 'name')\n\n# Vemos como resultado que solo hay 5 personas con el mismo nombre y edad. Podr\u00edamos mirar si \n# coincide la fecha de nacimiento en el dataframe original para afinar m\u00e1s; pero creo que no merece la pena\n# hacer nada: solo cinco posibles duplicados de 11038 registros no van a tener incidencia en los resultados\n# del an\u00e1lisis. Opto por no hacer nada con ellos.","0c61bb30":"# Finalmente, llevamos a cabo la conversi\u00f3n de tipos\n\n# Vemos que 'age', 'decile_score' y 'v_decile_score' se tratan como 'int64', es decir, como n\u00fameros. Esto es razonable. \n# \n# 'name' es 'object'. Esta categor\u00eda, aunque correcta, es demasiado general (una especie de caj\u00f3n de sastre en el que cabe todo). Vamos a convertirla en 'string' (texto)\n# \n# Vemos que 'sex', 'race', 'is_recid' y 'is_violent_recid' son 'objects' tambi\u00e9n. Sin embargo, es razonable  convertirlas en 'category' (de hecho, he observado que al ejecutar este programa con otra versi\u00f3n de pandas se convierten a 'category' de forma autom\u00e1tica). Llama la atenci\u00f3n que 'is_violent_recid' toma dos valores: es reincidente o no lo es. Sin embargo, 'is_recid' toma TRES: despu\u00e9s volveremos sobre esto \n# \n# 'compas_screening_date', 'r_offense_date' y 'vr_offense_date' tambi\u00e9n son 'objects'. Tenemos que decirle a Python que, en realidad, se trata de fechas ('datetime')\n# \n# Finalmente, vemos tambi\u00e9n que solo 'r_offense_date' y 'vr_offense_date' tienen valores 'null'. De hecho, a simple vista se aprecia que hay muchos 'NaN'. Esto tiene sentido: si la persona NO es reincidente, 'r_offense_date' y 'vr_offense_date' deben estar vac\u00edos. Hay que comprobar que esto es as\u00ed\n# \n# Hagamos todo eso:\n# \n\n\n# conversi\u00f3n de tipos\ndf_reducido['name'] = df_reducido['name'].astype('string')\ndf_reducido['sex'] = df_reducido['sex'].astype('category')\ndf_reducido['race'] = df_reducido['race'].astype('category')\ndf_reducido['is_recid'] = df_reducido['is_recid'].astype('category')\n#df_reducido['is_violent_recid'] = df_reducido['is_violent_recid'].astype('category')\ndf_reducido['compas_screening_date'] = pd.to_datetime(df_reducido['compas_screening_date'])\ndf_reducido['r_offense_date'] = pd.to_datetime(df_reducido['r_offense_date'])\ndf_reducido['vr_offense_date'] = pd.to_datetime(df_reducido['vr_offense_date'])","76be93bd":"# veamos si lo ha hecho bien\ndf_reducido.info()\ndf_reducido.head()","062bacd2":"# Con esto acabamos el pre-procesado","9d551352":"# Para ver que 'is_recid' predice m\u00e1s bien poco, vamos a hacer una tabla de contingencia en la que comprobaremos \n# si hay coincidencias de is_recid = 1 con decile_score >= 7:\n\ncm = pd.crosstab(df_reducido.is_recid==1, df_reducido.decile_score>=7, rownames=['prediccion'], colnames=['real'])\ncm","97299225":"'''\ncm resulta ser igual a\n\nreal        False  True \nprediccion              \nFalse        5877   1458\nTrue         2200   1503\n\nEsto quiere decir que hay 5877 + 2200 = 8077 individuos con decile_score < 7 (no peligrosos) y 1458 + 1503 = 2961 con decile_score >= 7.  \n\nDe los 8077 'no peligrosos', solo 5877 tienen 'is_recid'= 0. Los 2200 restantes tienen 'is_recid' = 1. Es decir, si nos fijamos \n\u00fanicamente en 'is_recid' estar\u00edamos diciendo err\u00f3neamente que esos 2200 individuos son peligrosos y necesitan medidas de control. \nEs decir, tenemos 2200 falsos positivos.\n\nDe los 2961 'peligrosos', 1458 tienen 'is_recid' = 0. Por ello, si de nuevo nos fijamos \u00fanicamente en 'is_recid' \nresultar\u00eda que estar\u00edamos dejando ninguna supervisi\u00f3n a esos 1458 individuos.\n\nNuestra tasa de acierto, en definitiva, es:\n    (5877 + 1503)\/(5877 + 1503 + 2200 + 1458) = 0.67\nEs decir, si clasificamos como 'peligrosos' a los que tienen 'is_recid' = 1,  acertamos un 67 % de las veces.\n'''\n# Vamos a ver si mejoramos esto con un modelo de regresion. \n# Es decir, vamos a intentar predecir 'decile_score'\n# como una suma ponderada de priors_count, sex, race, is_recid y is_violent_recid\n\nfrom statsmodels.formula.api import ols\n\n#df_reducido = df_reducido[(df_reducido.is_recid == 1) & (df_reducido.decile_score >=  7)]","25448c47":"fit_decile_score = ols('decile_score ~ age + priors_count + C(sex) + C(race) + C(is_recid) + C(is_violent_recid)', data=df_reducido).fit() \n\n# hemos de escribir C() si la variable es categ\u00f3rica\n\nprint(fit_decile_score.summary())","6a7174ea":"'''\nLo importante es:\n\nR-squared: cuanto m\u00e1s cercano a 1, mejor es el modelo. Nos ha salido 0.417. No es para tirar cohetes, pero tampoco est\u00e1 mal del todo.\ncoef: son los coeficientes A, B, C, ... En concreto, est\u00e1 diciendo que\nprediccion_decile_score = 0.2632 * priors_counts -0.0756 * male -1.2429  * asian -0.6781  caucasian + ... + 0.4953  * is_recid + ... + 7.1746 \n\ndonde male, asian, caucasian, ... son variables que valen 1 o 0 y codifican el sexo, la raza, etc. \n'''\n\n# P > |t| : es una medida de la importancia que el modelo concede a la variable asociada. Cuanto mayor sea, peor. \n# En este caso se ve que, para el modelo, 'male' y 'native american' son poco relevantes. \n# Que el sexo ('male') cuenta poco ya se ve en que su coeficiente (-0.0756) es muy peque\u00f1o. Que 'native american' \n# tambi\u00e9n sea poco importante se debe a que hay muy poca gente de esa raza en la base de datos: solo hay 36, \n# como se calcula con el siguiente comando\n\n(df_reducido.race=='Native American').sum()","cbc7de0d":"# La explicaci\u00f3n detallada de c\u00f3mo funciona statsmodel est\u00e1 aqu\u00ed:\n# https:\/\/www.efavdb.com\/interpret-linear-regression","37ba595b":"# con este comando se hace una predicci\u00f3n del valor de decile_score a partir de los que hemos indicado antes.\nprediccion = fit_decile_score.predict(df_reducido) ","c518ba5e":"# generamos la tabla de contingencia, comparando los casos en los que se predice \n# un valor mayor que 7, con aquellos en los que realmente es mayor que 7\ncm = pd.crosstab(prediccion>=7, df_reducido.decile_score>=7, rownames=['prediccion'], colnames=['real'])\ncm","0ed9925e":"'''\nreal        False  True \nprediccion              \nFalse        7931   2306\nTrue          146    655\n\nQuiere decir que en 7931 casos hemos predicho que decile_score era menor que 7\ny, efectivamente, se ha cumplido (verdaderos negativos). En 2306 pens\u00e1bamos que ser\u00eda \nmenor que 7 pero hemos fallado en la predicci\u00f3n (falsos negativos).\n\nPor otra parte, en 655 casos hemos dicho que decile_score ser\u00eda mayor que 7 y \nhemos acertado (verdaderos positivos).  \n\nEn resumen, tenemos:\n    7931 verdaderos negativos (True negatives o TN)\n    655 verdaderos positivos (TP)\n    2306 falsos negativos (False neg. o FN)\n    146 falsos positivos (FP)\n'''\n\nTN = cm[False][False]   \nTP = cm[True][True]\nFN = cm[True][False]\nFP = cm[False][True]\n\nprint('Accuracy: ', (TN+TP)\/(TN+TP+FN+FP))\nprint('PPV: ', TP \/ (TP + FP))\nprint('FPR: ', FP \/ (FP + TN))\nprint('FNR: ', FN \/ (FN + TP))\nprint()","0b717830":"from sklearn.metrics import classification_report\n\nprint(classification_report(df_reducido.decile_score>=7, prediccion>=7))\n","deebd11f":"# Estos n\u00fameros b\u00e1sicamente coinciden con lo ya calculado\n\n# precision True = PPV = 0.82\n# recall False = TN \/ (TN + FP) = 1 - FPR = 0.98\n# precision False = TN \/ (TN + FN) = 0.74\n# recall True = FP \/ (TP + FP) =  1 - TP \/ (TP + FP) = 0.2","8b161b61":"#Se eliminan valores -1 de decile_score y v_decile_score para graficar\ndf_reducido = df_reducido.drop(df_reducido[df_reducido['v_decile_score']==-1].index)\ndf_reducido = df_reducido.drop(df_reducido[df_reducido['decile_score']==-1].index)","4e9a3cb5":"import matplotlib.pyplot as plt\n\n#RACE\ndfgb = df_reducido.groupby(\"race\")\nrace_count = df_reducido.groupby(\"race\")[\"name\"].count()\n\nfig, ax = plt.subplots(3, figsize=(14, 8))\n\nfor (i, race) in enumerate([\"African-American\", \"Caucasian\", \"Hispanic\"]):\n    (\n        (dfgb\n            .get_group(race)\n            .groupby(\"decile_score\")[\"name\"].count() \/ race_count[race]\n        )\n        .plot(kind=\"bar\", ax=ax[i], color=\"#353535\")\n    )\n    ax[i].set_ylabel(race)\n    ax[i].set_xlabel(\"\")\n   \n    ax[i].set_ylim(0, 0.32)\n\nfig.suptitle(\"Score Frequency by Race\")\nplt.show()","1c9ef99d":"# Como se puede ver en el gr\u00e1fico, la distribucion en el decile score de las personas de raza negra se encuentra \n# uniformemente distribuida del 1 al 10, Mientras que para las demas razas, la gran mayor\u00eda de los casos se encuentran \n# en los valores mas bajos del decile_score.","d547ef49":"#Sex\ndfgb = df_reducido.groupby(\"sex\")\nrace_count = df_reducido.groupby(\"sex\")[\"name\"].count()\n\nfig, ax = plt.subplots(2, figsize=(14, 8))\n\nfor (i, sex) in enumerate([\"Male\", \"Female\"]):\n    (\n        (dfgb\n            .get_group(sex)\n            .groupby(\"decile_score\")[\"name\"].count() \n         #\/ race_count[race]\n        )\n        .plot(kind=\"bar\", ax=ax[i], color=\"#353535\")\n    )\n    ax[i].set_ylabel(sex)\n    ax[i].set_xlabel(\"\")\n   \n #   ax[i].set_ylim(0, 0.)\n\nfig.suptitle(\"Score Frequency by Race\")\nplt.show()","d6f4ddf8":"# Para el caso de las diferencias para hombres y mujeres se puede observar en la gr\u00e1fica una tendencia\n# a que menos mujeres estan en lo mas alto del decile_score a diferencia de los hombres.","fd94d21a":"# repetimos lo que hemos hecho antes para decile_score pero para v_decile_score \n\nfit_v_decile_score = ols('v_decile_score ~ age + priors_count + C(sex) + C(race) + C(is_recid) + C(is_violent_recid)', data=df_reducido).fit() \n\n# hemos de escribir C() si la variable es categ\u00f3rica\n\nprint(fit_v_decile_score.summary())","236b75fb":"vprediccion = fit_v_decile_score.predict(df_reducido)\n# con este comando se hace una predicci\u00f3n del valor de decile_score a partir de los que hemos indicado antes.\n\n# generamos la tabla de contingencia, comparando los casos en los que se predice \n# un valor mayor que 7, con aquellos en los que realmente es mayor que 7\ncm = pd.crosstab(vprediccion>=7, df_reducido.v_decile_score>=7, rownames=['prediccion'], colnames=['real'])\n\nTN = cm[False][False]   \nTP = cm[True][True]\nFN = cm[True][False]\nFP = cm[False][True]\n\nprint('Accuracy: ', (TN+TP)\/(TN+TP+FN+FP))\nprint('PPV: ', TP \/ (TP + FP))\nprint('FPR: ', FP \/ (FP + TN))\nprint('FNR: ', FN \/ (FN + TP))\nprint()","56cd4d2c":"# la precisi\u00f3n (accuracy) es ahora del 84.7 %, mejor la que se consigue para los delitos generales\n\nfrom sklearn.metrics import classification_report\n\nprint(classification_report(df_reducido.v_decile_score>=7, vprediccion>=7))","bd23e8ea":"vamos a echarle un vistazo por encima al dataframe:","eed342a0":"## Se pide","d81ae297":"# An\u00e1lisis:\n \n\n\nVamos a echarle un vistazo m\u00e1s despacito a las cosas que llaman la atenci\u00f3n. La primera es que 'is_recid' tome TRES valores 0, 1 y -1. El 0 supongo que significa que no es reincidente y el 1 que s\u00ed lo es; pero el '-1' \u00bfqu\u00e9 significa? En la p\u00e1gina 17 de esta publicaci\u00f3n:\n \nhttps:\/\/arxiv.org\/pdf\/1906.04711.pdf\n \nse dice:\n \n\"Additionally, ProPublica also dropped 719 people who did not appear to have good data. ProPublica could not find case\/arrest information on these people. ProPublica tagged these as \u201cis_recid = -1\u201d in the full dataset.\"\n \nEs decir, 'is_recid = -1' significa que los datos de ese individuo son incompletos o poco fiables. Por esa raz\u00f3n, ProPublica\n \nhttps:\/\/www.propublica.org\n \nlos excluye del an\u00e1lisis y nosotros vamos a hacer lo mismo\n\n","1cdc838f":"Como dice el enunciado que solo se necesitan los campos\n\n\u201ccompas_screening_date\u201d: se refiere a la fecha en la que se realiz\u00f3 la evaluaci\u00f3n\n\n\u201cdecile_score\u201d: es un n\u00famero, de 1 a 10 que indica el riesgo de reincidencia en general (a mayor riesgo, mayor n\u00famero).\n\n\u201cv_decile_score\u201d: es un n\u00famero de 1 a 10, potencialmente distinto del anterior, que indica el riesgo de reincidencia en delitos violentos. Al hacer la evaluaci\u00f3n de un caso en COMPAS, se generan las dos puntuaciones (entre otras cosas).\n\n\u201cis_recid\u201d: indicaci\u00f3n de si la persona es reincidente (en el tiempo en que se recogen datos: no hay informaci\u00f3n de si la persona es reincidente m\u00e1s all\u00e1 de ciertas fechas, y es importante tener esto en cuenta para asegurarse de hacer comparaciones homog\u00e9neas).\n\n\u201cr_offense_date\u201d: fecha en la que se cometi\u00f3 el delito por el que se considera reincidente a la persona.\n\n\u201cis_violent_recid\u201d: indicaci\u00f3n de si la persona es reincidente en un delito con violencia (las mismas consideraciones sobre fechas que para \u201cis_recid\u201d aplican aqu\u00ed)\".\n\n\u201cvr_offense_date\u201d: fecha en la que se cometi\u00f3 el delito violento que da lugar a la consideraci\u00f3n de reincidente.\n\nas\u00ed que eliminaremos el resto, salvo 'name', 'age', 'sex' y 'race', que nos servir\u00e1n para identificar al individuo\n\n\nTambi\u00e9n voy a mantener 'priors_count', que indica el n\u00famero de detenciones previas, y despu\u00e9s veremos que es\nuna variable \u00fatil para predecir el riesgo.","ac1793f1":"## Caso Pr\u00e1ctico \n\nCada d\u00eda es m\u00e1s frecuente la introducci\u00f3n de la ciencia de datos en el \u00e1mbito del derecho y la justicia.\nUn ejemplo bien conocido de ello es el sistema COMPAS (Correctional offender management profiling for\nalternative sanctions) que se usa en varios estados de los Estados Unidos para hacer una evaluaci\u00f3n del riesgo de\nreincidencia de las personas detenidas.\n\nUna breve descripci\u00f3n del sistema puede verse en la p\u00e1gina https:\/\/en.wikipedia.org\/wiki\/COMPAS_(software).\n\nEn este caso, proporciona un conjunto de datos en bruto con informaci\u00f3n de las evaluaciones\n(fichero compas-scores.csv) y la historia legal de unos 11 000 casos en los a\u00f1os 2013 y 2014\n(se trata de uno de los ficheros originales utilizados en un an\u00e1lisis independiente del sistema\nCOMPAS llevado a cabo por ProPublica, disponible en internet).\n\nAunque el conjunto de datos contiene informaci\u00f3n adicional, para resolver las cuestiones planteadas en este caso\nson necesarios (aparte de algunos campos cuyo nombre es autoexplicativo) los siguientes campos:\n\n+ \u201ccompas_screening_date\u201d: se refiere a la fecha en la que se realiz\u00f3 la evaluaci\u00f3n\n\n+ \u201cdecile_score\u201d: es un n\u00famero, de 1 a 10 que indica el riesgo de reincidencia en general (a mayor riesgo, mayor n\u00famero).\n\n+ \u201cv_decile_score\u201d: es un n\u00famero de 1 a 10, potencialmente distinto del anterior, que indica el riesgo de reincidencia en delitos violentos. Al hacer la evaluaci\u00f3n de un caso en COMPAS, se generan las dos puntuaciones (entre otras cosas).\n\n+ \u201cis_recid\u201d: indicaci\u00f3n de si la persona es reincidente (en el tiempo en que se recogen datos: no hay informaci\u00f3n de si la persona es reincidente m\u00e1s all\u00e1 de ciertas fechas, y es importante tener esto en cuenta para asegurarse de hacer comparaciones homog\u00e9neas).\n\n+ \u201cr_offense_date\u201d: fecha en la que se cometi\u00f3 el delito por el que se considera reincidente a la persona.\n\n+ \u201cis_violent_recid\u201d: indicaci\u00f3n de si la persona es reincidente en un delito con violencia (las mismas consideraciones sobre fechas que para \u201cis_recid\u201d aplican aqu\u00ed)\".\n\n+ \u201cvr_offense_date\u201d: fecha en la que se cometi\u00f3 el delito violento que da lugar a la consideraci\u00f3n de reincidente.","268ae22d":"Las estimaciones de riesgo est\u00e1n en 'decile_score' y 'v_decile_score'. A mayor riesgo, mayor valor. Lo que nos preguntan es si conociendo cu\u00e1nto valen 'is_recid'\/'is_violent_recid' podemos predecir el valor que tomar\u00e1n 'decile_score' y 'v_decile_score'. A priori, la hip\u00f3tesis es que NO: si el sujeto NO es reincidente ('is_recid'\/'is_violent_recid' = 0), cabe esperar que el riesgo sea bajo; sin embargo, cuando tenemos un reincidente ('is_recid'\/'is_violent_recid' = 1), supongo que el riesgo puede ser cualquiera y no podemos anticiparlo. Vamos a comprobar si esta intuici\u00f3n es o no correcta","cdef194c":"### 2. \u00bfSon los campos \u201cis_recid\u201d e \u201cis_violent_recid\u201d en este conjunto de datos adecuados para evaluar la precisi\u00f3n de las estimaciones de riesgo generadas por el sistema COMPAS? Si no es as\u00ed, definir y calcular una feature que s\u00ed lo sea.","50433ae1":"### 1. Cargar los datos y realizar un an\u00e1lisis exploratorio y una evaluaci\u00f3n de la calidad de los datos necesarios para el resto del caso. Espec\u00edficamente, evaluar la integridad, validez y actualidad de los datos y proponer estrategias de mitigaci\u00f3n de los posibles problemas encontrados. ","3b26df3f":"### 3. El umbral para establecer medidas preventivas de la reincidencia es de 7 en adelante. Dado este umbral, generar una tabla de contingencia, explicando qu\u00e9 caso se considera como \u201cpositivo\u201d (y, por lo tanto, cu\u00e1les son los errores de tipo I y los errores de tipo II).","439fc95f":"### 5. \u00bfPara qu\u00e9 tipo de riesgos, el de delitos generales o el de delitos violentos, tiene el sistema m\u00e1s capacidad predictiva?","754711ce":"### 4. El sistema asigna, de media, evaluaciones de riesgo m\u00e1s altas a los hombres que a las mujeres, y a las personas de raza afroamericana que a las de raza cauc\u00e1sica. Sin embargo, tambi\u00e9n las tasas de reincidencia son m\u00e1s altas para esos colectivos, aunque no est\u00e1 claro que la asignaci\u00f3n de riesgo sea \u201cjusta\u201d o no. Mostrar estas diferencias mediante representaciones gr\u00e1ficas y utilizarlas para analizar si la asignaci\u00f3n de evaluaciones es justa o no."}}