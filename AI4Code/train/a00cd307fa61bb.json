{"cell_type":{"00a46047":"code","1c9f18f8":"code","dddb69f4":"code","a1cb6bde":"code","9e04e431":"code","42595c8e":"code","8ed3136f":"code","82e0fa5d":"code","1323ba83":"code","3586e11f":"code","2517353e":"code","e6d252e1":"markdown","19fe6f1f":"markdown","3e26fdc3":"markdown","3e73eeb3":"markdown"},"source":{"00a46047":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\nimport PIL\nimport shutil\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nGCS_PATH = KaggleDatasets().get_gcs_path('gan-getting-started')\nprint(GCS_PATH)","1c9f18f8":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n    \nprint(tf.__version__)","dddb69f4":"MONET_FILENAMES = tf.io.gfile.glob(str('..\/input\/finalgan\/*.tfrec'))\nprint('Monet TFRecord Files:', len(MONET_FILENAMES))\n\nPHOTO_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '\/photo_tfrec\/*.tfrec'))\nprint('Photo TFRecord Files:', len(PHOTO_FILENAMES))","a1cb6bde":"IMAGE_SIZE = [256, 256]\n\ndef decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = (tf.cast(image, tf.float32) \/ 127.5) - 1\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\ndef read_tfrecord(example):\n    tfrecord_format = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    return image","9e04e431":"def load_dataset(filenames, labeled=True, ordered=False):\n    dataset = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n    return dataset","42595c8e":"monet_ds = load_dataset(MONET_FILENAMES, labeled=True).batch(1)\nphoto_ds = load_dataset(PHOTO_FILENAMES, labeled=True).batch(1)","8ed3136f":"with strategy.scope():\n    monet_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n    photo_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n\n    monet_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n    photo_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n    \nwith strategy.scope():\n    monet_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n    photo_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n\n    monet_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n    photo_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)","82e0fa5d":"from keras.models import load_model\n\nmonet_generator = keras.models.load_model('..\/input\/finalgan\/monet_generator.h5')\n# photo_generator = keras.models.load_model('..\/input\/model\/photo_generator.h5' )\n# monet_discriminator = keras.models.load_model('..\/input\/model\/monet_discriminator.h5' )\n# photo_discriminator = keras.models.load_model('..\/input\/model\/photo_discriminator.h5' )","1323ba83":"import PIL\n! mkdir ..\/images","3586e11f":"i = 1\nfor img in photo_ds:\n    prediction = monet_generator(img, training=False)[0].numpy()\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n    im = PIL.Image.fromarray(prediction)\n    im.save(\"..\/images\/\" + str(i) + \".jpg\")\n    i += 1\n    print(i)","2517353e":"import shutil\nshutil.make_archive(\"\/kaggle\/working\/images\", 'zip', \"\/kaggle\/images\")","e6d252e1":"# Load Model","19fe6f1f":"# Make Zip File","3e26fdc3":"# Define Model Compilation Arguments","3e73eeb3":"# Generate Output Images And Save Them"}}