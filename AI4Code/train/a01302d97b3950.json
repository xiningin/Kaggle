{"cell_type":{"97735ac5":"code","7f7ddaf8":"code","952f68da":"code","0251443e":"code","7bbe2966":"code","8e62e896":"code","3edeaf76":"code","bd37f387":"code","dcc9431a":"code","751b34b6":"code","4667bc0d":"code","c31f98df":"code","dadb024c":"code","6d8ca0ec":"code","e031f462":"code","83cc94a2":"code","13e35a35":"code","0cffc13b":"code","df40f621":"code","a8d35483":"code","61264330":"code","8cc439fc":"code","72a45831":"code","35f3aa96":"code","95b209b6":"markdown","2e53f73a":"markdown","78618e2c":"markdown","aa60036b":"markdown","fa090943":"markdown","f8665d20":"markdown","d7b9c59b":"markdown","ba898eac":"markdown","ee00f559":"markdown","411fde54":"markdown","13bde61e":"markdown","85e4e6d1":"markdown","9327a1f2":"markdown","074ef663":"markdown","db53afde":"markdown","765e0fc7":"markdown","60ebc865":"markdown","df0b187e":"markdown","c5897ac9":"markdown","037cd44a":"markdown","77f4aeb2":"markdown","b83cf345":"markdown","a302519c":"markdown","25c076ca":"markdown","a9969b9a":"markdown","6091df97":"markdown","2d9f0e21":"markdown","163ea759":"markdown","e96a8f66":"markdown","b313a068":"markdown","40f53fd1":"markdown","ddfd461c":"markdown"},"source":{"97735ac5":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport cufflinks as cf\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","7f7ddaf8":"df=pd.read_csv('..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')","952f68da":"df.head(5)","0251443e":"len(df)","7bbe2966":"df.isnull().sum()","8e62e896":"import missingno as msno\nmsno.matrix(df)","3edeaf76":"df['Gender'].unique()","bd37f387":"print(sum(df.duplicated()))\ndf = df.drop_duplicates()\n","dcc9431a":"ig, axes = plt.subplots(1,2, figsize=(21,6))\nsns.distplot(df['Age'], ax=axes[0])\nsns.distplot(df['Annual Income (k$)'], ax=axes[1])\n\n","751b34b6":"sns.countplot(x='Gender', data=df, palette='viridis')","4667bc0d":"sns.stripplot(x='Gender', y = 'Spending Score (1-100)', data = df)","c31f98df":"sns.boxplot( x= 'Gender', y = 'Annual Income (k$)', data = df )","dadb024c":"x = df['Annual Income (k$)']\ny = df['Age']\nz = df['Spending Score (1-100)']\n\nsns.lineplot(x, y, color = 'blue')\nsns.lineplot(x, z, color = 'pink')\nplt.title('Annual Income vs Age and Spending Score', fontsize = 20)\nplt.show()\n","6d8ca0ec":"df['Gender'].replace({'Male': 0, 'Female': 1},inplace = True) ","e031f462":"df.head(5)","83cc94a2":"df.drop('CustomerID', axis=1, inplace = True)","13e35a35":"df.head(5)","0cffc13b":"sns.heatmap(df.corr(), annot=True)","df40f621":"def impute_age(cols):\n    spend=cols\n    if spend > 55:\n         return 1\n    else:\n         return 0\ndf['Spending Score (1-100)'] = df['Spending Score (1-100)'].apply(impute_age)\ndf.head(5)\n    ","a8d35483":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test= train_test_split(df.drop('Spending Score (1-100)',axis=1), df['Spending Score (1-100)'], test_size=0.30, random_state=101)\nfrom sklearn.linear_model import LogisticRegression\nlog=LogisticRegression()\nlog.fit(X_train,y_train)\npred=log.predict(X_test)\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, pred))\n","61264330":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(df.drop('Spending Score (1-100)',axis=1))\nscaled_features = scaler.transform(df.drop('Spending Score (1-100)',axis=1))\ndf_feat = pd.DataFrame(scaled_features,columns=df.columns[:-1])\ndf_feat.head()\n","8cc439fc":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(scaled_features,df['Spending Score (1-100)'],\n                                                    test_size=0.30)\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\nfrom sklearn.metrics import classification_report,confusion_matrix\nprint(confusion_matrix(y_test,pred))\nprint(classification_report(y_test,pred))","72a45831":"error_rate = []\n\nfor i in range(1,40):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))\n    plt.figure(figsize=(10,6))\nplt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","35f3aa96":"\nknn = KNeighborsClassifier(n_neighbors=3)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=3')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","95b209b6":"We can see from the figure above that at the K interval value of 3, the error rate is low.So now,lets find the classification report with error rate =3.","2e53f73a":"Here we have standardized out data for further processing.","78618e2c":"With interval value=1, we see that our predicitve probability is just 0.68. Lets check which interval value between 1 and 40 gives us the most accurate result.","aa60036b":"Now lets look onto the spending scores of male and female individually","fa090943":"But first we need to check if there are any missing values or not. Turns out our dataset is clean without any null values. So we dont have to worry about filling any missing columns or rows","f8665d20":"Out of 200 people, around 115 were women while 85 were men. The barchart above clearly illustrates the fact that we have more female\ncustomers than male. Perhaps, we have more of household products or may be our stores have more emphasis on items on which female \npopulation is interested","d7b9c59b":"Now lets look at some complex plot","ba898eac":"So we only have two genders listed.\nNow lets do some short codings so that we dont have any duplicate values.","ee00f559":"And there are 200 columns. So this is quite a small dataset with less number of rows and columns. Now lets begin working with all the data that we have","411fde54":"**THANK YOU**","13bde61e":"There are few outliers in the male population on the top. Surprisingly, the females have a little less average income but still our store has more female customers which clearly indicates that females visit our stores regardless of their income. Perhaps, men are more interested in saving than spending. ","85e4e6d1":"**Machine Learning: Logistic Regression**","9327a1f2":"We can see that people with the highest spending score are the ones with annual income of 50k. Perhaps our store is a retail store with only few luxury brands and more of household and daily products. Despite large income, some people appear to have decreasing spending score which is clear onthe right edge of the graph.","074ef663":"Now lets check the Gender Column. There might be two possiblities: either gender is just classified as male and female or there are other classifications that identify LGBTQ community. ","db53afde":"**Machine Learning: K-Means Clustering**","765e0fc7":"**DATA IMPORT AND OBSERVATION**","60ebc865":"Lets see which gender makes up the majority of people visiting our store","df0b187e":"**DATA WRANGLING AND VISUALIZATION**","c5897ac9":"Now lets look onto the distribution of age and income of our customers","037cd44a":"Now lets see if there is any differences in the income of the population in two genders that might explain their spending habit","77f4aeb2":"Since the customer ID are nothing more than unique numbers assigned to each customers, we have removed this column. Lets check","b83cf345":"The figure above indicates that none of the columns we have are strongly correlated to each other. So using machine learning technique of linear regression wont give us an accurate predictive outcome","a302519c":"As you can see we have five columns: Customer ID , Gender, Annual Income and Spending score.","25c076ca":"Now, lets make a fair assumption that people with spending score of more than 55( the topmost chunk in the aforementioned plot)\nare our target customers as they are highly likely to make purchases. Once we can accurately predict these group of customers by looking at their age, gender and income , we cann apply several tactics like sending emails of new offers to increase the number of purchases","a9969b9a":"You can see that our graph shows continuous dark lines without any horizozntal interruptions. This support our previous idea that we dont have any missing values","6091df97":"Now lets try to find if there is any correlation between any of our data.","2d9f0e21":"So with the K-Nearest Neighbour algorithm, we can predict if a customer is our target customer or not with a probability of roughly 8\/10, which is pretty much acceptable. Hope you found this analysis helpful. Feel free to ask if you have any questions with the code above. There are other algorithms that you can apply to find if they are more accurate.","163ea759":"The first figure shows us that the average age of our customers is around 35. The age of our customers is typically between 20 and 70.","e96a8f66":"Now talking about annual income, majority of our customers have an annual income around 80K per annum. The salary ranges from 15k to 135k","b313a068":"Roughly, male and female both have similar spending score. We can see more number of dots on the female side because of \nlarge number of female population compared to male population. We can see both the male and female population have two gaps in their distribution : around 20 and 60. These two gaps divide the population into three chunks: people with score below 20, people with score between 30 and 60 , and people with speding score between 60 and 80. So we conclude that there are three types of customers in both the gender on the basis of their spending habit. We are most interested in the top most group.  ","40f53fd1":"Here we have replaced males with 1 and females with 0. Quantifying the variables will enable us to execute machine learning methods for future predictions. Now lets check if we have succesfully dummied these values or not.\n","ddfd461c":"As we can see the logistic regresion only has a probability of predicting the target customer with a probability of 0.6, which is pretty low, we will apply another machine learning technique( K Nearest Neighbor) to our data."}}