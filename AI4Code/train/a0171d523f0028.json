{"cell_type":{"74f8595f":"code","911e4f40":"code","33908fb1":"code","76d2a71b":"code","f9e1e2da":"code","b57d8e38":"code","12e6ae29":"code","915b6440":"code","e3b772d7":"code","c16dca57":"code","54dda9f6":"code","21f3cecf":"code","383c4f53":"code","2552c186":"code","b27c6c10":"code","154ae63f":"code","75a8ccf3":"code","7dbdd594":"code","26102bb8":"code","584b0044":"code","b5628721":"code","a0ff3d24":"code","6605ac70":"code","b55618e4":"code","2f1dd66b":"code","abcb638b":"code","5f267ea4":"code","3471c8d6":"code","d6ffd6b1":"code","80b3c709":"code","fad33e00":"code","338d19da":"code","968b4f55":"code","92396796":"code","5145851e":"code","4d0549e6":"code","049dc4ab":"code","f1150421":"code","758a4384":"code","64b31fab":"code","09345173":"code","0d8dc1e9":"code","7d4cf3a7":"code","fb590ab7":"code","9dbde014":"code","78c79e92":"markdown","bd95afb5":"markdown","2aab9bf8":"markdown","536e1f80":"markdown","03514d47":"markdown","60238172":"markdown","3196fc52":"markdown","77549967":"markdown","6f071d07":"markdown","6aecdc81":"markdown","6d2ad9f3":"markdown","00f623cf":"markdown","5d8b5c36":"markdown","d162279c":"markdown"},"source":{"74f8595f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import skew","911e4f40":"df = pd.read_csv('..\/input\/titanic\/train.csv')\ndf.head()","33908fb1":"#to get infromation on the dataset like total number of count in dataset and in that how much are non null and what is the datatype of each columns\ndf.info()","76d2a71b":"#replace the missing value with mean\nage = df.Age.mean()\ndf['Age'] = df['Age'].replace(np.nan, age)\n#df['Age'] = df['Age'].astype(int)\ndf['Age']","f9e1e2da":"df.info()","b57d8e38":"# For Cabin more than half of the data isnull so we will drop the column,drop the unwanted columns\ndf = df.drop(['Cabin'],axis=1)\ndf = df.drop(['Name'],axis=1)\ndf = df.drop(['Ticket'],axis=1)","12e6ae29":"#check the unique element \ndf.Embarked.unique()","915b6440":"#get the unique element  count\ndf.groupby('Embarked').size()","e3b772d7":"#replace missing valuw with S\ndf.Embarked.fillna('S',inplace = True)","c16dca57":"df.Embarked.unique()","54dda9f6":"# check for duplicate in data\ndf.duplicated().sum()","21f3cecf":"#change the catergoircal variables to numberic values\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nsex_encoded = le.fit_transform(df['Sex'])\ndf['encoded_sex'] = sex_encoded","383c4f53":"Embarked_encoded = le.fit_transform(df['Embarked'])\ndf['embarked_encoded'] =Embarked_encoded\ndf.head()","2552c186":"#drop the unwanted column\ndf = df.drop(['Sex'],axis=1)\ndf = df.drop(['Embarked'],axis=1)","b27c6c10":"# TO know how much male and female survived \nsns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='encoded_sex',data=df,palette='RdBu_r')","154ae63f":"#get the relationship between the columns\ndf.corr(method='pearson')","75a8ccf3":"# let's see how data is distributed for every column\nplt.figure(figsize=(20,25), facecolor='white')\nplotnumber = 1\nfor column in df:\n    print(column)\n    print(skew(df[column]))\n    if plotnumber<=9 :\n        ax = plt.subplot(3,3,plotnumber)\n        \n        sns.distplot(df[column])\n        plt.xlabel(column,fontsize=20)\n             \n    plotnumber+=1\n\nplt.show()","7dbdd594":"fig, ax = plt.subplots(figsize=(15,10))\nsns.boxplot(data=df, width= 0.5,ax=ax,  fliersize=3)","26102bb8":"Q1 = df.Fare.quantile(0.25)\nQ3 = df.Fare.quantile(0.75)\nQ1, Q3","584b0044":"IQR = Q3 - Q1\nIQR","b5628721":"lower_limit = Q1 - 1.5*IQR\nupper_limit = Q3 + 1.5*IQR\nlower_limit, upper_limit","a0ff3d24":"Q4 = df.Age.quantile(0.25)\nQ5 = df.Age.quantile(0.75)\nQ4, Q5","6605ac70":"IQR = Q5 - Q4\nIQR","b55618e4":"lower_limit = Q4 - 1.5*IQR\nupper_limit = Q5 + 1.5*IQR\nlower_limit, upper_limit","2f1dd66b":"fig, ax = plt.subplots(figsize=(15,10))\nsns.boxplot(data=df, width= 0.5,ax=ax,  fliersize=3)","abcb638b":"# let's see how data is distributed for every column and skewness amount in the data\nplt.figure(figsize=(20,25), facecolor='white')\nplotnumber = 1\nfor column in df:\n    print(column)\n    print(skew(df[column]))\n    if plotnumber<=9 :\n        ax = plt.subplot(3,3,plotnumber)\n        \n        sns.distplot(df[column])\n        plt.xlabel(column,fontsize=20)\n             \n    plotnumber+=1\n\nplt.show()","5f267ea4":"X = df.drop(columns = ['Survived','Pclass','encoded_sex','embarked_encoded'])\ny = df['Survived']","3471c8d6":"from sklearn.preprocessing import StandardScaler \nscalar = StandardScaler()\nX_scaled = scalar.fit_transform(X)","d6ffd6b1":"X_scaled","80b3c709":"#find mutlicollierility\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor \nvif = pd.DataFrame()\nvif[\"vif\"] = [variance_inflation_factor(X_scaled,i) for i in range(X_scaled.shape[1])]\nvif[\"Features\"] = X.columns\nvif","fad33e00":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(X_scaled,y, test_size= 0.25, random_state = 355)","338d19da":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score,confusion_matrix\nlog_classifier=LogisticRegression()\nlog_classifier.fit(x_train, y_train)\nytrain_pred = log_classifier.predict_proba(x_train)\nprint('Logistic train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\nytest_pred = log_classifier.predict_proba(x_test)\nprint('Logistic test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))","968b4f55":"from sklearn.ensemble import RandomForestClassifier\nrf_model = RandomForestClassifier()\nrf_model.fit(x_train, y_train)\nytrain_pred = rf_model.predict_proba(x_train)\nprint('RF train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\nytest_pred = rf_model.predict_proba(x_test)\nprint('RF test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))","92396796":"from sklearn.ensemble import AdaBoostClassifier\nada_classifier=AdaBoostClassifier()\nada_classifier.fit(x_train, y_train)\nytrain_pred = ada_classifier.predict_proba(x_train)\nprint('Adaboost train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\nytest_pred = ada_classifier.predict_proba(x_test)\nprint('Adaboost test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))","5145851e":"from sklearn.neighbors import KNeighborsClassifier\nknn_classifier=KNeighborsClassifier()\nknn_classifier.fit(x_train, y_train)\nytrain_pred = knn_classifier.predict_proba(x_train)\nprint('Adaboost train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\nytest_pred = knn_classifier.predict_proba(x_test)\nprint('Adaboost test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))","4d0549e6":"# I have given minimun but you can try based in your requiremnts\ngrid_param = {\n    \"n_estimators\" : [90,100,],\n    'criterion': ['gini', 'entropy'],\n    'max_depth' : range(2,5,1),\n    'min_samples_leaf' : range(1,5,1),\n    'min_samples_split': range(2,5,1),\n    'max_features' : ['auto','log2']\n}","049dc4ab":"from sklearn.model_selection import train_test_split,GridSearchCV\ngrid_search = GridSearchCV(estimator=rf_model,param_grid=grid_param,cv=5,n_jobs =-1,verbose = 3) #5 folds ","f1150421":"grid_search.fit(x_train,y_train)","758a4384":"grid_search.best_params_","64b31fab":"rand_clf = RandomForestClassifier(criterion= 'gini',\n max_depth = 3,\n max_features = 'auto',\n min_samples_leaf = 3,\n min_samples_split= 4,\n n_estimators = 90,random_state=6)","09345173":"rand_clf.fit(x_train,y_train)","0d8dc1e9":"rand_clf.score(x_test,y_test)","7d4cf3a7":"y_pred = rand_clf.predict(x_test)","fb590ab7":"# Confusion Matrix\nconf_mat = confusion_matrix(y_test,y_pred)\nconf_mat","9dbde014":"rand_clf.predict([[892,35.6,36.7,3,6]]) # changes to get surived","78c79e92":"Variables Description\n\nPassengerID : ID of the Passenger.\nSurvived: Survival (0 = No; 1 = Yes)\nPclass: Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\nName : Name of the Passenger\nSex: Sex of the Passenger (Female \/ Male)\nAge: Age of the Passenger.\nSibsp: Number of siblings\/spouses aboard\nParch: Number of parents\/children aboard\nTicket : Ticket number.\nFare: Passenger fare (British pound)\nCabin: Cabin number\nEmbarked: Port of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n","bd95afb5":"checked with submisssion Data\nPassengerId,Survived\n892,0","2aab9bf8":"df.Fare=df[(df.Fare<lower_limit)|(df.Fare>upper_limit)] #try this above cell when you run local","536e1f80":"df.Age=df[(df.Age<lower_limit)|(df.Age>upper_limit)]","03514d47":" to know what all columns are import or have a relations\n Parch, Fare has more coorelation and PassengerId,SibSp,Age less Negative correlations, Pclass\t,encoded_sex,embarked_encoded has high ngetative correlations","60238172":"**I have imported the required libary in the place where its need**","3196fc52":"**This is my very first code in machine learning, supports me guys with your view\/thoughts in commands, so that I can learn from it  and  if you like this please upvote it willl be encouraging me in my path for data science**","77549967":"Goal\n\nPredict if a passenger survived the sinking of the Titanic or not.","6f071d07":"Steps\n\n* Exploratory Data Analysis \n* Data Preprocessing & Feature Engineering\n* Encoding ( Label Encoding \/ One Hot Encoding \/ Rare Encoding\n* Model Buildind & Performance Metrics\n* Model Validation\n* Summary","6aecdc81":"Outlier removal","6d2ad9f3":"PassengerId- normal distribution,Survived - normal distribution, Pclass- left skewed,Age-normal distribution, SibSp-right skewed,Parch- right skewed,Fare- right skewedencoded_sex- normal distribution,embarked_encoded - left skewed","00f623cf":"will load the data with  skewed check the scores ","5d8b5c36":"df.Fare = df[(df.Fare<lower_limit)]","d162279c":"Now taking this columns PassengerId,Age,SibSp,Parch,Fare for parameter based on Corrections"}}