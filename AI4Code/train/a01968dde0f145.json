{"cell_type":{"73ffc5fc":"code","70c3fb81":"code","4e398068":"code","1774d26e":"code","f950e7c4":"code","e6df8fed":"code","0a8c6391":"code","bfa9cdd5":"code","87f34c17":"code","3f1a1180":"code","b96a4678":"code","c928bd76":"code","48f35c44":"code","43fd878a":"code","de0773ea":"markdown","bad5959e":"markdown","9d2f409c":"markdown","2bb66d38":"markdown","ddd46db8":"markdown","ec78d8d9":"markdown","cd7c3602":"markdown","523d04df":"markdown","bccf3209":"markdown","b4bc8796":"markdown","7ddeefbb":"markdown","52377f9a":"markdown","d89d9f73":"markdown","43b3de57":"markdown"},"source":{"73ffc5fc":"!pip install --no-index \\\n..\/input\/detectron2-download-code-for-offline-install-ii\/detectron2\/detectron2-0.6-cp37-cp37m-linux_x86_64.whl \\\n--find-links=..\/input\/detectron2-download-code-for-offline-install-ii\/detectron2","70c3fb81":"!git clone https:\/\/github.com\/youngwanLEE\/centermask2.git","4e398068":"%cd centermask2\n!wget 'https:\/\/dl.dropbox.com\/s\/dret2ap7djty7mp\/centermask2-lite-V-19-eSE-FPN-ms-4x.pth'","1774d26e":"%%writefile configs\/centermask\/test.yaml\nDATALOADER:\n  ASPECT_RATIO_GROUPING: true\n  FILTER_EMPTY_ANNOTATIONS: true\n  NUM_WORKERS: 2\nMODEL:\n  META_ARCHITECTURE: \"GeneralizedRCNN\"\n  BACKBONE:\n    NAME: \"build_fcos_vovnet_fpn_backbone\"\n    FREEZE_AT: 0\n  VOVNET:\n    OUT_FEATURES: [\"stage3\", \"stage4\", \"stage5\"]\n  FPN:\n    IN_FEATURES: [\"stage3\", \"stage4\", \"stage5\"]\n  PROPOSAL_GENERATOR:\n    NAME: \"FCOS\"  \n  FCOS:\n    POST_NMS_TOPK_TEST: 600 # Max number of detections per image\n    POST_NMS_TOPK_TRAIN: 600\n  # PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n  MASK_ON: True\n  MASKIOU_ON: True\n  ROI_HEADS:\n    NAME: \"CenterROIHeads\"\n    IN_FEATURES: [\"p3\", \"p4\", \"p5\"]\n  ROI_MASK_HEAD:\n    NAME: \"SpatialAttentionMaskHead\"\n    ASSIGN_CRITERION: \"ratio\"\n    NUM_CONV: 4\n    POOLER_RESOLUTION: 14\nDATASETS:\n  TRAIN: (\"train\",) # match with DatasetCatalog.register() call!\n  TEST: (\"test\",)\nSOLVER:\n  CHECKPOINT_PERIOD: 5000\n  IMS_PER_BATCH: 8\n  BASE_LR: 0.01  # Note that RetinaNet uses a different default learning rate\n  STEPS: (60000, 80000)\n  MAX_ITER: 10000 # 16000 = ~9h\nINPUT:\n  MIN_SIZE_TRAIN: (480, 512, 640)\nTEST:\n  AUG:\n    ENABLED: False\n  DETECTIONS_PER_IMAGE: 500\n  EVAL_PERIOD: 600 ","f950e7c4":"# import various libraries\nimport logging\nimport os, re\nfrom collections import OrderedDict\nimport torch\nimport numpy as np\n\nimport detectron2.utils.comm as comm\nfrom detectron2.data import MetadataCatalog\nfrom detectron2.data.datasets import register_coco_instances, load_coco_json\nfrom detectron2.data import DatasetCatalog\nfrom detectron2.engine import DefaultTrainer, DefaultPredictor\nfrom detectron2.engine import default_argument_parser, default_setup, hooks, launch\nfrom detectron2.evaluation import (\n    # CityscapesInstanceEvaluator,\n    # CityscapesSemSegEvaluator,\n    # COCOEvaluator,\n    COCOPanopticEvaluator,\n    DatasetEvaluators,\n    LVISEvaluator,\n    PascalVOCDetectionEvaluator,\n    SemSegEvaluator,\n    verify_results,\n)\nfrom centermask.evaluation import (\n    COCOEvaluator,\n    CityscapesInstanceEvaluator,\n    CityscapesSemSegEvaluator\n)\nfrom detectron2.modeling import GeneralizedRCNNWithTTA\nfrom detectron2.checkpoint import DetectionCheckpointer\nfrom detectron2.utils.visualizer import Visualizer, ColorMode\nfrom centermask.config import get_cfg","e6df8fed":"def get_train_set():\n    return load_coco_json('\/kaggle\/input\/sartorius-create-coco-annotations\/train_fold_0.json', '')\n\ndef get_test_set():\n    return load_coco_json('\/kaggle\/input\/sartorius-create-coco-annotations\/test_fold_0.json', '')\n\n\nclass Trainer(DefaultTrainer):\n    \"\"\"\n    This is the same Trainer except that we rewrite the\n    `build_train_loader` method.\n    \"\"\"\n\n    @classmethod\n    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n        \"\"\"\n        Create evaluator(s) for a given dataset.\n        This uses the special metadata \"evaluator_type\" associated with each builtin dataset.\n        For your own dataset, you can simply create an evaluator manually in your\n        script and do not have to worry about the hacky if-else logic here.\n        \"\"\"\n        if output_folder is None:\n            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n        evaluator_list = []\n        evaluator_list.append(COCOEvaluator(dataset_name, output_dir=output_folder))\n        if len(evaluator_list) == 0:\n            raise NotImplementedError(\n                \"no Evaluator for the dataset {} with the type {}\".format(\n                    dataset_name, evaluator_type\n                )\n            )\n        elif len(evaluator_list) == 1:\n            return evaluator_list[0]\n        return DatasetEvaluators(evaluator_list)\n\n    @classmethod\n    def test_with_TTA(cls, cfg, model):\n        logger = logging.getLogger(\"detectron2.trainer\")\n        # In the end of training, run an evaluation with TTA\n        # Only support some R-CNN models.\n        logger.info(\"Running inference with test-time augmentation ...\")\n        model = GeneralizedRCNNWithTTA(cfg, model)\n        evaluators = [\n            cls.build_evaluator(\n                cfg, name, output_folder=os.path.join(cfg.OUTPUT_DIR, \"inference_TTA\")\n            )\n            for name in cfg.DATASETS.TEST\n        ]\n        res = cls.test(cfg, model, evaluators)\n        res = OrderedDict({k + \"_TTA\": v for k, v in res.items()})\n        return res","0a8c6391":"cfg = get_cfg()\ncfg.merge_from_file(\"configs\/centermask\/test.yaml\")\ncfg.freeze()\ndefault_setup(cfg, 'Namespace(num_gpus=1, opts=[\\'MODEL.WEIGHTS\\', \\'centermask2-lite-V-19-eSE-FPN-ms-4x.pth\\'], resume=False')","bfa9cdd5":"# Dataset registration\nCLASSES = [\"background\", \"shsy5y\", \"astro\", \"cort\"]\nDatasetCatalog.register(\"train\", get_train_set)\nMetadataCatalog.get(\"train\").thing_classes = CLASSES\nMetadataCatalog.get(\"train\").evaluator_type = \"coco\"\nDatasetCatalog.register(\"test\", get_test_set)\nMetadataCatalog.get(\"test\").thing_classes = CLASSES\nMetadataCatalog.get(\"test\").evaluator_type = \"coco\"","87f34c17":"import cv2\nimport matplotlib.pyplot as plt\n\ntest_ds = DatasetCatalog.get('test')\nmeta_ds = MetadataCatalog.get(\"test\")","3f1a1180":"sample = test_ds[9]\n\nimg = cv2.imread(sample[\"file_name\"])\nvisualizer = Visualizer(img[:, :, ::-1], metadata=meta_ds)\nout = visualizer.draw_dataset_dict(sample)\nplt.figure(figsize = (20,15))\nplt.imshow(out.get_image()[:, :, ::-1]);","b96a4678":"trainer = Trainer(cfg)\ntrainer.resume_or_load(resume=False)\nif cfg.TEST.AUG.ENABLED:\n    trainer.register_hooks(\n        [hooks.EvalHook(0, lambda: trainer.test_with_TTA(cfg, trainer.model))]\n    )\ntrainer.train()","c928bd76":"# read log file\nwith open('.\/output\/log.txt', 'r') as f:\n    log = f.read()\n# extract training loss\nlines = re.findall('iter: [0-9]*  total_loss: [.0-9]*', log)\nit, loss = [], []\nfor i in range(len(lines)):\n    res = re.findall(\"[-+]?[.]?[\\d]+(?:,\\d\\d\\d)*[\\.]?\\d*(?:[eE][-+]?\\d+)?\", lines[i])\n    it.append(int(res[0]))\n    loss.append(float(res[1]))\nplt.figure(figsize = (20,10))\nplt.plot(it, loss)\nplt.xlabel('Iteration')\nplt.ylabel('Total loss')\nplt.title('Training loss');","48f35c44":"# Then we do evaluation scores\nraw = re.findall('copypaste: [.,0-9]*', log)\nboxes, segs = [], []\nidx = 0\nfor s in raw:\n    if len(s) > 20:\n        nums = [float(i) for i in s.strip('copypaste: ').split(',')]\n        if idx == 0:\n            boxes.append(nums)\n        else:\n            segs.append(nums)\n        idx = (idx + 1) % 2\nboxes, segs = np.asarray(boxes), np.asarray(segs)\nx = (np.arange(0, len(segs[:,0])) *600) + 600\nplt.figure(figsize = (20,10))\nx = (np.arange(0, len(segs[:,0])) *600) + 600\nplt.plot(x, segs[:,0], label='Mask AP', color='tab:blue')\nplt.plot(x, segs[:,1], label='Mask AP50', color='tab:orange')\nplt.plot(x, segs[:,2], label='Mask AP75', color='tab:red')\nplt.plot(x, boxes[:,0], label='Box AP', linestyle='--', color='tab:blue')\nplt.plot(x, boxes[:,1], label='Box AP50', linestyle='--', color='tab:orange')\nplt.plot(x, boxes[:,2], label='Box AP75', linestyle='--', color='tab:red')\nplt.legend()\nplt.xlabel('Iteration')\nplt.ylabel('Score')\nplt.title('COCO Evaluation scores');","43fd878a":"import random\n\ncfg.defrost()\ncfg.MODEL.WEIGHTS = '.\/output\/model_final.pth'  # path to the model we just trained\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\npredictor = DefaultPredictor(cfg)\ndataset_dicts = DatasetCatalog.get('test')\nouts = []\nfor d in random.sample(dataset_dicts, 3):    \n    im = cv2.imread(d[\"file_name\"])\n    outputs = predictor(im)  # format is documented at https:\/\/detectron2.readthedocs.io\/tutorials\/models.html#model-output-format\n    v = Visualizer(im[:, :, ::-1],\n                   metadata = MetadataCatalog.get('test'), \n                    \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n    )\n    out_pred = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    visualizer = Visualizer(im[:, :, ::-1], metadata=MetadataCatalog.get('test'))\n    out_target = visualizer.draw_dataset_dict(d)\n    outs.append(out_pred)\n    outs.append(out_target)\n_,axs = plt.subplots(len(outs)\/\/2,2,figsize=(40,45))\nfor ax, out in zip(axs.reshape(-1), outs):\n    ax.imshow(out.get_image()[:, :, ::-1])","de0773ea":"Then fetch the [Centermask2](https:\/\/github.com\/youngwanLEE\/centermask2) project:","bad5959e":"Check learning curves. Detectron2 has an event storage module for this, but everything we need is already in the log file:","9d2f409c":"## Model check\n\nCheck a few predictions, code from [Positive score with Detectron 2\/3 - Training](https:\/\/www.kaggle.com\/slawekbiel\/positive-score-with-detectron-2-3-training).","2bb66d38":"Define configuration:","ddd46db8":"# Pretrained model\nThere are several different pretrained models to choose from, below we pick a [lightweight](https:\/\/github.com\/youngwanLEE\/centermask2#centermask-lite) one that actually fits in GPU memory.","ec78d8d9":"Define trainer class:","cd7c3602":"Visulize a few samples for checks:","523d04df":"# Inference\nTime to [make predictions with the trained model](https:\/\/www.kaggle.com\/mistag\/pred-sartorius-detectron2-centermask2). Also see tutorial on how to [run inference with Detectron2 models](https:\/\/colab.research.google.com\/drive\/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5).","bccf3209":"# Training\nThe code below is modified from [train_net.py](https:\/\/github.com\/youngwanLEE\/centermask2\/blob\/master\/train_net.py) that comes with CenterMask2 repository.","b4bc8796":"![logo](https:\/\/raw.githubusercontent.com\/facebookresearch\/detectron2\/main\/.github\/Detectron2-Logo-Horz.svg)","7ddeefbb":"# Train","52377f9a":"Register dataset:","d89d9f73":"# Intro\nIn this notebook we will train an instance segmentation model based on Detectron2 and CenterMask2. \n\nReferences:\n  * [CenterMask2](https:\/\/github.com\/youngwanLEE\/centermask2)\n  * [LIVECell](https:\/\/github.com\/sartorius-research\/LIVECell)\n  * [Create COCO annotations for Sartorius dataset](https:\/\/www.kaggle.com\/mistag\/sartorius-create-coco-annotations)\n  * [Offline Detectron2 installation files](https:\/\/www.kaggle.com\/mistag\/detectron2-download-code-for-offline-installation)\n  \nStart by installing Detectron2:","43b3de57":"Create a configuration file, most importantly define the dataset names to use for train and test. The dataset will be registered later through the Detectron2 [DatasetCatalog](https:\/\/detectron2.readthedocs.io\/en\/latest\/tutorials\/datasets.html) API."}}