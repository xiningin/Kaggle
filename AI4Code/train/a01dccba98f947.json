{"cell_type":{"2daadbf4":"code","0769d6db":"code","02aa2d27":"code","d56028e6":"code","bb0ae1a5":"code","52e55bc3":"code","c55cb82f":"code","38357e81":"code","98ce2322":"code","50a249b8":"code","bf2906c5":"code","bd1ec7db":"code","053f9992":"code","77abd07c":"code","1ced797e":"code","85278bf3":"code","217e9004":"code","b007644a":"code","b767fde9":"code","68d63121":"code","927140b4":"code","a7c4e21d":"code","3068e21e":"code","5dec859f":"code","301f6b65":"code","745aaff8":"code","0b6dc910":"code","c5dcba6c":"code","1d42d69f":"code","f9eb3b13":"code","c5e84462":"code","c0c1622f":"code","deb1c316":"code","5b0834a6":"markdown","e5d1a91f":"markdown","5ac39a57":"markdown","b7c57e94":"markdown","03b30250":"markdown","4410d771":"markdown","4bf5e92c":"markdown","819792f2":"markdown","04eed677":"markdown","10b86161":"markdown","e34c1b64":"markdown","19fe26a8":"markdown","5b664693":"markdown"},"source":{"2daadbf4":"#Import all the necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set_style(\"darkgrid\")\n","0769d6db":"#load the train data\ntrain_data= pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_data=pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain_data.head()\n","02aa2d27":"train_data.info()","d56028e6":"train_data.describe(include=\"all\") # for statistical information which is not for categorical data","bb0ae1a5":"# Lets check for other missing data\ntrain_data.isna().sum()","52e55bc3":"sns.barplot(x='Sex',y='Survived',data=train_data)\nplt.show();","c55cb82f":"sns.barplot(x='Pclass',y='Survived',data=train_data)\nplt.show();","38357e81":"sns.barplot(x='SibSp',y='Survived',data=train_data)\nplt.show();","98ce2322":"sns.barplot(x='Parch',y='Survived',data=train_data)\nplt.show();","50a249b8":"# Age feature\n#sort the ages into logical categories\n\n\nbins = [ 0, 5, 12, 18, 24, 35, 60, np.inf]\nlabels = [ 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ntrain_data['AgeGroup'] = pd.cut(train_data[\"Age\"], bins, labels = labels)\ntest_data['AgeGroup'] = pd.cut(test_data[\"Age\"], bins, labels = labels)\n\n#draw a bar plot of Age vs. survival\nsns.set()\nplt.figure(figsize = (12,6))\nsns.barplot(x=\"AgeGroup\", y=\"Survived\", data=train_data,palette='magma')\nplt.show()","bf2906c5":"#First we will have a loot at test data also\ntest_data.describe(include='all')","bd1ec7db":"# We will start with dropping 'Cabin' column, as a lot of data is missing\ntrain_data.drop(\"Cabin\",axis=1,inplace=True)\ntest_data.drop(\"Cabin\",axis=1,inplace=True)","053f9992":"# Embarked feature\nprint(f'Number of people living in Southampton are(S){train_data[train_data[\"Embarked\"]==\"S\"].shape[0]}')\nprint(f'Number of people living in Cherbourg are(S){train_data[train_data[\"Embarked\"]==\"C\"].shape[0]}')\nprint(f'Number of people living in Queenstown are(S){train_data[train_data[\"Embarked\"]==\"Q\"].shape[0]}')","77abd07c":"# As we can see most of the passengers live in Southampton, so we will the missing data with 'S'\ntrain_data.fillna({\"Embarked\":\"S\"},inplace=True)\n#train_data[train_data.isnull().any(axis = 1)] # to find the rows having missing data, it will return empty df","1ced797e":"# We will drop the name column, as it has no much of significance\ntrain_data.drop(\"Name\",axis=1,inplace=True)\ntest_data.drop(\"Name\",axis=1,inplace=True)\n\n","85278bf3":"#We will drop the row in test data for 'Fare' column\ntest_data['Fare']=test_data[\"Fare\"].fillna(test_data[\"Fare\"].mean())","217e9004":"# Fill the missing value of Age column with mean value.\ntrain_data['Age'] = train_data['Age'].fillna(train_data.groupby('Sex')['Age'].transform('mean'))\n","b007644a":"test_data['Age'] = test_data['Age'].fillna(test_data.groupby('Sex')['Age'].transform('mean'))","b767fde9":"test_data.isna().sum()","68d63121":"#Map the categorical colum 'Sex' with numerical data\nsex_mapping = {\"male\": 0, \"female\": 1}\ntrain_data['Sex'] = train_data['Sex'].map(sex_mapping)\ntest_data['Sex'] = test_data['Sex'].map(sex_mapping)\n\ntrain_data.head()","927140b4":"#Mapping for Embarked feature\nembarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\ntrain_data['Embarked'] = train_data['Embarked'].map(embarked_mapping)\ntest_data['Embarked'] = test_data['Embarked'].map(embarked_mapping)\n\ntrain_data.head()","a7c4e21d":"# Drop the AgeGroup column as it was created for visualization purpose\ntrain_data.drop(\"AgeGroup\",axis=1,inplace=True)\n","3068e21e":"test_data.drop(\"AgeGroup\",axis=1,inplace=True)","5dec859f":"# drop the ticket column\ntrain_data.drop(\"Ticket\",axis=1,inplace=True)","301f6b65":"test_data.drop(\"Ticket\",axis=1,inplace=True)","745aaff8":"train_data.head()","0b6dc910":"test_data.head()","c5dcba6c":"X= train_data.drop([\"PassengerId\",\"Survived\"],axis=1) # Our samples\ny= train_data[\"Survived\"] # Our targets\n\nX.shape,y.shape","1d42d69f":"#Lets split the data\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2)\n","f9eb3b13":"from sklearn.svm import SVC\n\nsvc=SVC()\nsvc.fit(X_train,y_train)\nsvc_preds=svc.predict(X_test)\n\nfrom sklearn.metrics import accuracy_score\n\naccuracy_score(y_test,svc_preds)","c5e84462":"#As accuracy is not good, we can try Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nnp.random.seed(42)\n\nrfc=RandomForestClassifier(n_estimators=100)\nrfc.fit(X_train,y_train)\nrfc_preds= rfc.predict(X_test)\n\naccuracy_score(y_test,rfc_preds)","c0c1622f":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier()\ngbk.fit(X_train, y_train)\ngbk_preds = gbk.predict(X_test)\naccuracy_score(y_test,gbk_preds)","deb1c316":"ids = test_data['PassengerId']\npredictions = rfc.predict(test_data.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission_2.csv', index=False)","5b0834a6":"**Lets Check if our prediction is true or not by visualizing the data**","e5d1a91f":"*Now we have completed the data cleaning part, moving on to Data Splitting in X and Y*","5ac39a57":"**Few Observations**\n* There are total 891 passengers in train_data.\n* Age column has missing data and also its an important column, so we will try to fill the missing data.\n* Cabin column has a lot of missing data, so we will probably drop this column.","b7c57e94":"**Clean the data**","03b30250":"* We have 418 total passengers in test data.\n* 1 entry has been missing from fare.\n* Cabin column has many missing values.","4410d771":"**Creating submission file**\n\nNow its time to create submission file to upload to the Kaggle Competition\n\n","4bf5e92c":"1. Sex vs Survival","819792f2":"**Few predictions**\n1. Sex:-Females have higher probability to survive.\n2. Age:-Children are more likely to survive.\n3. Pclass:-High class people are more likely to survive.\n4. SibSp\/Parch:-People with no siblings or family are more likely to survive.","04eed677":"### What we are going to do \n    1.Understand the data using .info() and .describe()\n    2.Plot the data with histogram , barplot or scatterplot\n    3.Value counts\n    4.Missing data\n    5.Numerical Data\n    6.Select a model\n    7.Train the model\n    8.Test the model\n    9.Evaluate the performance\n    10.Improve the model\n    \n    \n **Understand the data**   ","10b86161":"**Modeling**\n","e34c1b64":"# TITANIC - Survival Prediction\n","19fe26a8":"So our first prediction is true, Females are more likely to survive.\n\n2.Age vs Survival ","5b664693":"**Process Data**"}}