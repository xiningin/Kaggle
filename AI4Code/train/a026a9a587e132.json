{"cell_type":{"9c61c3ed":"code","37815229":"code","42a18ec6":"code","df750a90":"code","9571a221":"code","f784a29d":"code","1ca2f38f":"code","caf7b4c8":"code","7c9d8f1a":"code","2aa4c8af":"code","e4675a4b":"code","2291193b":"code","334cebf2":"code","6d13c3a3":"code","dfca91f5":"code","826f19be":"code","c044f2fd":"code","1249a3ea":"markdown","cb14d692":"markdown","8dc90eb9":"markdown","3c29eaae":"markdown","e798dc88":"markdown","4b8d51eb":"markdown","97077267":"markdown","90778246":"markdown","0a614d40":"markdown"},"source":{"9c61c3ed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","37815229":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.model_selection import train_test_split","42a18ec6":"# Loading dataset\ndata = pd.read_csv(\"..\/input\/did-it-rain-in-seattle-19482017\/seattleWeather_1948-2017.csv\")\ndata.head()","df750a90":"# Data processing\ndata = data.dropna(axis=0)\ndata = data.iloc[:, 1:5]\n","9571a221":"data.head()","f784a29d":"fig = plt.figure(figsize = (10, 7))\nax = plt.axes(projection =\"3d\")\n\nax.set_xlabel(\"TMIN\")\nax.set_ylabel(\"TMAX\")\nax.set_zlabel(\"PRCP\")\nax.scatter3D(xs=data[\"TMIN\"],ys=data[\"TMAX\"],zs=data[\"PRCP\"], c=data[\"RAIN\"])\nplt.show()","1ca2f38f":"# 2. Spliting Dataset\ntrain_set, test_set = train_test_split(data, train_size=0.7, test_size=0.3)","caf7b4c8":"train_set.head()","7c9d8f1a":"test_set.head()","2aa4c8af":"train_data, train_lable = train_set.iloc[:, 0:3], train_set[\"RAIN\"].astype('int')\ntest_data, test_lable = test_set.iloc[:, 0:3], test_set[\"RAIN\"].astype('int')","e4675a4b":"train_data","2291193b":"# KNN classifier\nfrom sklearn.neighbors import KNeighborsClassifier\nKnn_classifiers = []\n\n# k = 1, 3, 5, 7, 9\nfor k in range(1, 10, 2):\n    classifier = KNeighborsClassifier(n_neighbors=k).fit(train_data, train_lable)\n    Knn_classifiers.append(classifier)\n","334cebf2":"# Evaluating 5 classifiers with different k values\nk = 1\nfor classifier in Knn_classifiers:\n    print(\"K =\", k, \", score =\", classifier.score(test_data, test_lable))\n    k += 2","6d13c3a3":"# k = 1\npredictions = Knn_classifiers[0].predict(test_data)\npredictions","dfca91f5":"test_data[\"RAIN\"] = predictions.astype('bool')","826f19be":"test_data.head()","c044f2fd":"fig = plt.figure(figsize = (10, 7))\nax = plt.axes(projection =\"3d\")\n\nax.set_xlabel(\"TMIN\")\nax.set_ylabel(\"TMAX\")\nax.set_zlabel(\"PRCP\")\nax.scatter3D(test_data[\"TMIN\"], test_data[\"TMAX\"],test_data[\"PRCP\"], c=test_data[\"RAIN\"])\nplt.show()","1249a3ea":"# PE04 Assignment using Team Project's dataset\n1. By now, you should have your team project topic finalized. Use the same dataset or a dataset that will help you have a better understanding of the problem you will be dealing with in your team project. ","cb14d692":"4.\tUse the additional 30% of your data as a testing dataset to predict which class they belong to. How does the number of nearest neighbors affect this prediction? ","8dc90eb9":"2.\tChoose 70% of your dataset as the training data for your K-Nearest Neighbor algorithm. ","3c29eaae":"# Plotting All Data Points","e798dc88":"Answer to 5: When k is 1, the predictions results is the most accurate. According to the real world, it might indicate that raining or not raining is determined by the recent few days. I'm not sure about my conclusion because I didn't import the date data in my KNN model.","4b8d51eb":"3.\tUsing the scikit-learn API, apply the K-Nearest Neighbor to your training set for 5 different values of K. ","97077267":"Answer to 4: The lager K value, the lower accuracy of the classifier.\n\n5.\tFind the best results you can achieve using the K-Nearest Neighbor algorithm and interpret the obtained results based on the problem you are trying to solve. ","90778246":"I will drop the date column because it's hard to vectorizing date data","0a614d40":"# Plotting Testing-Predictions\n"}}