{"cell_type":{"40c468a7":"code","3f0e7cdc":"code","82eba100":"code","60d8bcb7":"code","5385c82d":"code","a53e7654":"code","d89de314":"code","e5cb2f46":"code","036c5788":"code","4f59a097":"code","f9fbbe04":"markdown","82b256c5":"markdown","afefc6e7":"markdown","83729144":"markdown","a747a026":"markdown"},"source":{"40c468a7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras.layers import Dense, SimpleRNN, GRU, LSTM, Embedding # Import layers from Keras\nfrom keras.models import Sequential\n\nimport os\nprint(os.listdir(\"..\/input\"))","3f0e7cdc":"raw_data = pd.read_csv('..\/input\/train.csv', encoding='latin-1') # Read the data as a DataFrame using Pandas\nraw_test_data = pd.read_csv('..\/input\/test.csv', encoding='latin-1')\n\nprint(raw_data.shape) # Print the dimensions of train DataFrame\nprint(raw_data.columns) # Print the column names of the DataFrame\nprint('\\n')\nraw_data.head(5) # Print the top few records","82eba100":"# Print the unique classes and their counts\/frequencies\nclasses = np.unique(raw_data['target'], return_counts=True) # np.unique returns a tuple with class names and counts\nprint(classes[0]) #Print the list of unique classes\nprint(classes[1]) #Print the list of frequencies of the above classes02155","60d8bcb7":"max_num_words = 10000\nseq_len = 150\nembedding_size = 100\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\ntokenizer = Tokenizer(num_words=max_num_words) #Tokenizer is used to tokenize text\ntokenizer.fit_on_texts(raw_data.question_text) #Fit this to our corpus\n\nx_train = tokenizer.texts_to_sequences(raw_data.question_text) #'text to sequences converts the text to a list of indices\nx_train = pad_sequences(x_train, maxlen=150) #pad_sequences makes every sequence a fixed size list by padding with 0s \n\n\nx_test = tokenizer.texts_to_sequences(raw_test_data.question_text) \nx_test = pad_sequences(x_test, maxlen=150)\n\nx_train.shape, x_test.shape # Check the dimensions of x_train and x_test  ","5385c82d":"unique_labels = list(raw_data.target.unique())\nprint(unique_labels)","a53e7654":"# Building an LSTM model\nmodel = Sequential() # Call Sequential to initialize a network\nmodel.add(Embedding(input_dim = max_num_words, \n                    input_length = seq_len, \n                    output_dim = embedding_size)) # Add an embedding layer which represents each unique token as a vector\nmodel.add(LSTM(10, return_sequences=False)) # Add an LSTM layer ( will not return output at each step)\nmodel.add(Dense(1, activation='sigmoid')) # Add an ouput layer. Since classification, 3 nodes for 3 classes.","d89de314":"model.summary()","e5cb2f46":"from keras.optimizers import Adam\nadam = Adam(lr=0.001)","036c5788":"# Mention the optimizer, Loss function and metrics to be computed\nmodel.compile(optimizer=adam,                  # 'Adam' is a variant of gradient descent technique\n              loss='binary_crossentropy', # categorical_crossentropy for multi-class classification\n              metrics=['accuracy'])            # These metrics are computed for evaluating and stored in history\ny_train = raw_data['target']\nmodel.fit(x_train, y_train, epochs=1, validation_split=0.25)","4f59a097":"preds = model.predict(x_test)\npred_test_y = (preds>0.35).astype(int)\n\n# Read the submission file\nsubmission=pd.read_csv(\"..\/input\/sample_submission.csv\")\n\n# Fill the is_pass variable with the predictions\nsubmission['prediction']= pd.DataFrame(pred_test_y)\n\n# Converting the submission file to csv format\nsubmission.to_csv('submission.csv', index=False)","f9fbbe04":"### Building and training an LSTM model\n","82b256c5":"### Converting unstructured text to structured numeric form\n\n**This includes:**\n\n1. Tokenizing\n2. Converting sequence of words to sequence of word indeces\n3. Converting varing length sequences to fixed length sequences through padding","afefc6e7":"### Reading the data","83729144":"### Prepare the target vectors for the network","a747a026":"### Check the labels and their frequencies"}}