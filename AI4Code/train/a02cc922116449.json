{"cell_type":{"2062f0d9":"code","7862018e":"code","7e3bb556":"code","e22f58f2":"code","b91a6687":"code","1b8f000b":"code","178bb14b":"code","90c0190e":"code","0340c29f":"code","7bd65c9b":"code","fab860de":"code","cfa8c901":"code","4842b9d3":"code","f2ee8472":"code","c8644a70":"code","819f9818":"code","0f22f462":"code","dc8f2e39":"code","4a2287c7":"code","43672693":"code","91547bf4":"code","60833070":"code","d28dfcd0":"code","8d9741e0":"code","16ee1b50":"code","1df170d5":"code","2456198e":"code","9d6d551a":"code","3619b150":"code","2ed9f0a5":"code","9aeeb12a":"code","2b2c23b7":"code","67f06b10":"code","81a9ee6e":"markdown","6164e153":"markdown","9b00d5ca":"markdown","33fdf546":"markdown","a6b05155":"markdown","141940ec":"markdown","30590871":"markdown","d18136a8":"markdown","3467ea0b":"markdown","37d087d3":"markdown","4144172c":"markdown","a6dcccab":"markdown","2f601c7e":"markdown","d07987d4":"markdown"},"source":{"2062f0d9":"from IPython.display import Image\nImage(filename='\/kaggle\/input\/compare\/img.jpg')","7862018e":"import numpy as np \nimport pandas as pd \nimport plotly.graph_objects as go\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport warnings\nwarnings.filterwarnings('ignore')","7e3bb556":"data = pd.read_csv(\"\/kaggle\/input\/pfizer-vaccine-tweets\/vaccination_tweets.csv\")","e22f58f2":"data.head()","b91a6687":"def basic_eda(df, row_limit=5, list_elements_limit=10):\n    ### rows and columns\n    print('Info : There are {} columns in the dataset'.format(df.shape[1]))\n    print('Info : There are {} rows in the dataset'.format(df.shape[0]))\n    \n    print(\"==================================================\")\n    \n    ## data types\n    print(\"\\nData type information of different columns\")\n    dtypes_df = pd.DataFrame(df.dtypes).reset_index().rename(columns={0:'dtype', 'index':'column_name'})\n    cat_df = dtypes_df[dtypes_df['dtype']=='object']\n    num_df = dtypes_df[dtypes_df['dtype']!='object']\n    print('Info : There are {} categorical columns'.format(len(cat_df)))\n    print('Info : There are {} numerical columns'.format(len(dtypes_df)-len(cat_df)))\n    \n    if list_elements_limit >= len(cat_df):\n        print(\"Categorical columns : \", list(cat_df['column_name']))\n    else:\n        print(\"Categorical columns : \", list(cat_df['column_name'])[:list_elements_limit])\n        \n    if list_elements_limit >= len(num_df):\n        print(\"Numerical columns : \", list(num_df['column_name']))\n    else:\n        print(\"Numerical columns : \", list(num_df['column_name'])[:list_elements_limit])\n    \n    #dtypes_df['dtype'].value_counts().plot.bar()\n    display(dtypes_df.head(row_limit))\n    \n    print(\"==================================================\")\n    print(\"\\nDescription of numerical variables\")\n    \n    #### Describibg numerical columns\n    desc_df_num = df[list(num_df['column_name'])].describe().T.reset_index().rename(columns={'index':'column_name'})\n    display(desc_df_num.head(row_limit))\n    \n    print(\"==================================================\")\n    print(\"\\nDescription of categorical variables\")\n    \n    desc_df_cat = df[list(cat_df['column_name'])].describe().T.reset_index().rename(columns={'index':'column_name'})\n    display(desc_df_cat.head(row_limit))\n    \n    return","1b8f000b":"basic_eda(data)","178bb14b":"from transformers import pipeline\nsentiment_analysis = pipeline('sentiment-analysis')","90c0190e":"transformer_sentiments = data.text.apply(sentiment_analysis)","0340c29f":"labels = []\nscores = []\nfor sentiment in transformer_sentiments:\n    #print(f\"label: {sentiment[0]['label']}, with score: {round(sentiment[0]['score'], 4)}\")\n    labels.append(sentiment[0]['label'])\n    scores.append(round(sentiment[0]['score'], 4))","7bd65c9b":"data['tf-sentiment'] = labels\ndata['tf-score'] = scores","fab860de":"data[['text', 'tf-sentiment', 'tf-score']].head(3)","cfa8c901":"from nltk.sentiment import SentimentIntensityAnalyzer\nsia = SentimentIntensityAnalyzer()","4842b9d3":"def find_sentiment(tweet):\n    if sia.polarity_scores(tweet)[\"compound\"] > 0:\n        return \"POSITIVE\"\n    elif sia.polarity_scores(tweet)[\"compound\"] < 0:\n        return \"NEGATIVE\"\n    else:\n        return \"NEUTRAL\"        ","f2ee8472":"vader_sentiments = data.text.apply(find_sentiment)","c8644a70":"data['vader-sentiment'] = vader_sentiments","819f9818":"data[['text', 'vader-sentiment']].head(3)","0f22f462":"## Make a df just for comparision\ndf = data[['text', 'tf-score', 'tf-sentiment', 'vader-sentiment']]\ndf.head(3)","dc8f2e39":"print(\"Distribution of classes : Optimus Prime\")\ncounts = df['tf-sentiment'].value_counts()\npercent = counts\/sum(counts)\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n\ncounts.plot(kind='bar', ax=ax1)\npercent.plot(kind='bar', ax=ax2)\nax1.set_ylabel('Counts : TF Sentiments', size=12)\nax2.set_ylabel('Percentage : TF Sentiments', size=12)\nplt.tight_layout()\nplt.show()","4a2287c7":"print(\"Distribution of classes : Darth Vader\")\ncounts = df['vader-sentiment'].value_counts()\npercent = counts\/sum(counts)\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n\ncounts.plot(kind='bar', ax=ax1)\npercent.plot(kind='bar', ax=ax2)\nax1.set_ylabel('Counts : VADER Sentiments', size=12)\nax2.set_ylabel('Percentage : VADER Sentiments', size=12)\nplt.tight_layout()\nplt.show()","43672693":"def label_function(val):\n    return f'{val \/ 100 * len(df):.0f}\\n{val:.0f}%'\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(16, 8))\n\ndf.groupby('vader-sentiment').size().plot(kind='pie', autopct=label_function, textprops={'fontsize': 12},\n                                  colors=['tomato', 'gold', 'skyblue'], ax=ax1)\ndf.groupby('tf-sentiment').size().plot(kind='pie', autopct=label_function, textprops={'fontsize': 12},\n                                 colors=['violet', 'lime'], ax=ax2)\nax1.set_ylabel('VADER Sentiments', size=12)\nax2.set_ylabel('Transformer Sentiments', size=12)\nplt.tight_layout()\nplt.show()","91547bf4":"def same_or_diff(x):\n    if x[0]==x[1]:\n        return \"Same\"\n    else:\n        return \"Different\"","60833070":"print(\"Same or Different including the Neutral records\")\ndf['same_or_diff_w_neut'] = df[['tf-sentiment', 'vader-sentiment']].apply(same_or_diff, axis=1)\ndf.head(3)","d28dfcd0":"print(\"Same or Different including the Neutral records : Comparision\")\ncounts = df['same_or_diff_w_neut'].value_counts()\npercent = counts\/sum(counts)\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n\ncounts.plot(kind='bar', ax=ax1)\npercent.plot(kind='bar', ax=ax2)\nax1.set_ylabel('Number of records', size=12)\nax2.set_ylabel('Percentage or records', size=12)\nplt.tight_layout()\nplt.show()","8d9741e0":"print(\"Same or Different after removing the Neutral records\")\ndfwn = df[df['vader-sentiment'] != 'NEUTRAL']\n# Just to ensure\nprint(\"==================================\\n\")\nprint(dfwn['vader-sentiment'].value_counts())\ndfwn['same_or_diff_wo_neut'] = dfwn[['tf-sentiment', 'vader-sentiment']].apply(same_or_diff, axis=1)\ndfwn.head(3)","16ee1b50":"print(\"Same or Different after removing the Neutral records : Comparision\")\ncounts = dfwn['same_or_diff_wo_neut'].value_counts()\npercent = counts\/sum(counts)\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n\ncounts.plot(kind='bar', ax=ax1)\npercent.plot(kind='bar', ax=ax2)\nax1.set_ylabel('Number of records', size=12)\nax2.set_ylabel('Percentage or records', size=12)\nplt.tight_layout()\nplt.show()","1df170d5":"df['color'] = df['same_or_diff_w_neut'].apply(lambda x : \"green\" if x == 'Same' else 'red')\n\nfig = go.Figure(data=[go.Table(\n    columnorder = [1,2,3,4],\n    columnwidth = [400, 100, 100, 120],\n    header=dict(values=['text', 'tf-sentiment', 'vader-sentiment', 'same_or_different'],\n                fill_color='paleturquoise',\n                line_color='black',\n                align='center',\n                height=40),\n    cells=dict(values=[df['text'],df['tf-sentiment'], df['vader-sentiment'], df['same_or_diff_w_neut']],\n               fill_color=[['lavender'], ['lavender'], ['lavender'], list(df.color)],\n               line_color='black',\n               align='left'))\n])\n\nfig.update_layout(height=700,\n                 title=\"Comparision across Transformer and VADER\")\n\nfig.show()","2456198e":"import math\nimport torch\nimport transformers as ppb\nimport warnings\nwarnings.filterwarnings('ignore')","9d6d551a":"## Loading pretrained model\/tokenizer\nmodel_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\ntokenizer = tokenizer_class.from_pretrained(pretrained_weights)\nmodel = model_class.from_pretrained(pretrained_weights)","3619b150":"##### Some utility functions\n# function to find max length\ndef find_max_len(tokenized):\n  max_len = 0\n  for i in tokenized.values:\n      if len(i) > max_len:\n          max_len = len(i)\n  return max_len\n\n\n# function to extract bert features\ndef get_bert_features(df, text_col):\n  tokenized = df[text_col].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n  max_len = find_max_len(tokenized)\n  print(\"Max Len = \",max_len)\n  padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n  attention_mask = np.where(padded != 0, 1, 0)\n\n  input_ids = torch.tensor(padded)  \n  attention_mask = torch.tensor(attention_mask)\n\n  with torch.no_grad():\n    last_hidden_states = model(input_ids, attention_mask=attention_mask)\n\n  features = last_hidden_states[0][:,0,:].numpy()\n\n  return features\n\n\n# Applying above function in batches to avoid RAM issues\ndef extract_features(df, text_col, batch_size=1000):\n    features = []\n    labels = []\n\n    no_of_batches = math.ceil(len(df)\/batch_size)\n    print(\"\\nInitializing...\")\n    print(\"Total no of batches : \",str(no_of_batches))\n    batch_no = 1\n\n#     widgets = ['Generating BERT Embeddings: ', progressbar.AnimatedMarker()] \n#     bar = progressbar.ProgressBar(max_value=len(df), widgets=widgets).start() \n\n    for i in range (0,len(df),batch_size):\n        #time.sleep(0.2)\n        #bar.update(i)\n        print()\n        print(\"\\nGenerating features for batch\",str(batch_no),\"of\",str(no_of_batches))\n        dfn = df[i:i+batch_size]\n        tfeatures = get_bert_features(dfn, text_col)\n        tfeatures = list(tfeatures)\n        features.append(tfeatures)\n        batch_no = batch_no + 1\n\n    print(\"Done\")\n    features = np.concatenate(features)\n\n    return features","2ed9f0a5":"features = extract_features(df=df, text_col = 'text', batch_size=1000)","9aeeb12a":"embeddings = list(features)","2b2c23b7":"df['embedding'] = embeddings\ndf = df[['text', 'embedding']].head(10)","67f06b10":"fig = go.Figure(data=[go.Table(\n    columnorder = [1,2],\n    columnwidth = [300,400],\n    header=dict(values=['text', 'embedding'],\n                fill_color='paleturquoise',\n                line_color='black',\n                align='center',\n                height=40),\n    cells=dict(values=[df['text'],df['embedding']],\n               fill_color=[['lavender'], ['lavender']],\n               line_color='black',\n               align='left'))\n])\n\nfig.update_layout(height=700,\n                 title=\"Embeddings generated using BERT\")\n\nfig.show()","81a9ee6e":"Clearly there is a lot of difference! Let's dig down further!","6164e153":"Interestingly Transformer is clasifying most of the tweets as negative. Let's see about VADER.","9b00d5ca":"### Sentiment Analysis : The Optimus Prime [HuggingFace Transformers]\n\n![HF](https:\/\/raw.githubusercontent.com\/huggingface\/transformers\/master\/docs\/source\/imgs\/transformers_logo_name.png)\n\nTransformers is a library released by [huggingface](https:\/\/huggingface.co\/transformers\/quicktour.html). This library downloads pretrained models for Natural Language Understanding (NLU) tasks, such as analyzing the sentiment of a text, and Natural Language Generation (NLG), such as completing a prompt with new text or translating in another language.\n\nWe'll use the pretrained model find out the sentiment of a tweet in our dataset\n\nPros:\n\n- Good Accuracy\n- Very short and easy to use code\n- No fancy preprocessing needed\n- No finicking around with threshold values\n\nCons:\n\n- Significantly Slower\n- Only works with 2 classes out of the box \n\n","33fdf546":"### Pfizer Vaccine Tweets\n\nThis notebook has two parts. \n\n- Part 1 - Sentiment Analysis of tweets using HuggingFace Transformers (analogical to Optimus Prime!!) and NLTK VADER (Analogical to Darth Vader!!). Ignore the analogies if you aren't a fan of movies.\n- Part 2 - Senternce embedding generation using pretraine BERT.\n\n## Part 1 (Optimus Prime vs Darth Vader!!)","a6b05155":"#### Woah! Are they performing exactly opposite? Let's find out.","141940ec":"We all are familiar with Optimus Prime and Darth Vader. Let's see how good they are.\n\n> Just for for your reference I'm referring HuggingFace Transformer with Optimus Prime and NLTK's VADER with Darth Vader. Interesting Analogy. Isn't it?\n\nWe'll be doing sentiment analysis using both (HuggingFace Transformers and NLTK's VADER) and let's how they perform. And do they contradict each other?","30590871":"### Basic EDA\n\nA generic function for basic EDA","d18136a8":"Interesting! Let's see side by side.","3467ea0b":"### Comparision of Transformer with VADER\n\nNow that we have both the sentiments let's compare the","37d087d3":"#### Let's see at some records !!","4144172c":"#### We can clearly see the differences! ","a6dcccab":"## Part 2 - Sentence embedding generation of tweets using BERT","2f601c7e":"### Sentiment Analysis : The Darth Vader [NLTK VADER]\n\n![nltk](https:\/\/static1.squarespace.com\/static\/538cea80e4b00f1fad490c1b\/54668a77e4b00fb778d22a34\/54668e11e4b00fb778d29051\/1416008768215\/?format=1500w)\n\nNLTK already has a built-in, pretrained sentiment analyzer called VADER (Valence Aware Dictionary and sEntiment Reasoner).\n\nVADER is pretrained, you can get results more quickly than with many other analyzers. However, VADER is best suited for language used in social media, like short sentences with some slang and abbreviations. It\u2019s less accurate when rating longer, structured sentences, but it\u2019s often a good launching point.\n\nPros:\n\n- Very Fast\n- Very short and easy to use code\n- No fancy preprocessing needed\n- Provides three classes\n\nCons:\n\n- Rule based algorithm doesn't consider context\n- less accuarate","d07987d4":"### Thanks for viewing this noteboook. If you found it interesting consider UPVOTING it."}}