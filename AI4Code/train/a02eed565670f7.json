{"cell_type":{"7060c29a":"code","d9da3358":"code","ad89ba8f":"code","a69cbda5":"code","eb6d420b":"code","1d1c925f":"code","6d0324b3":"code","b1bbccfd":"code","ad6f3c0f":"code","29da20bf":"markdown","d2f6c333":"markdown","ad26ca84":"markdown","aa46620b":"markdown","bd2ad76a":"markdown","debdfba0":"markdown","d5dca48f":"markdown","8bbdd654":"markdown","db0539fb":"markdown","5da59643":"markdown"},"source":{"7060c29a":"import numpy as np\nimport tensorflow as tf\nimport keras\nimport cv2\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import img_to_array\nimport os\nfrom tqdm import tqdm\nimport re\nimport matplotlib.pyplot as plt","d9da3358":"# to get the files in proper order\ndef sorted_alphanumeric(data):  \n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n    return sorted(data,key = alphanum_key)\n# defining the size of the image\nSIZE = 256\nhigh_img = []\npath = '..\/input\/image-super-resolution\/dataset\/Raw Data\/high_res'\nfiles = os.listdir(path)\nfiles = sorted_alphanumeric(files)\nfor i in tqdm(files):    \n    if i == '855.jpg':\n        break\n    else:    \n        img = cv2.imread(path + '\/'+i,1)\n        # open cv reads images in BGR format so we have to convert it to RGB\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        #resizing image\n        img = cv2.resize(img, (SIZE, SIZE))\n        img = img.astype('float32') \/ 255.0\n        high_img.append(img_to_array(img))\n\n\nlow_img = []\npath = '..\/input\/image-super-resolution\/dataset\/Raw Data\/low_res'\nfiles = os.listdir(path)\nfiles = sorted_alphanumeric(files)\nfor i in tqdm(files):\n     if i == '855.jpg':\n        break\n     else: \n        img = cv2.imread(path + '\/'+i,1)\n\n        #resizing image\n        img = cv2.resize(img, (SIZE, SIZE))\n        img = img.astype('float32') \/ 255.0\n        low_img.append(img_to_array(img))","ad89ba8f":"for i in range(4):\n    a = np.random.randint(0,855)\n    plt.figure(figsize=(10,10))\n    plt.subplot(1,2,1)\n    plt.title('High Resolution Imge', color = 'green', fontsize = 20)\n    plt.imshow(high_img[a])\n    plt.axis('off')\n    plt.subplot(1,2,2)\n    plt.title('low Resolution Image ', color = 'black', fontsize = 20)\n    plt.imshow(low_img[a])\n    plt.axis('off')","a69cbda5":"train_high_image = high_img[:700]\ntrain_low_image = low_img[:700]\ntrain_high_image = np.reshape(train_high_image,(len(train_high_image),SIZE,SIZE,3))\ntrain_low_image = np.reshape(train_low_image,(len(train_low_image),SIZE,SIZE,3))\n\nvalidation_high_image = high_img[700:830]\nvalidation_low_image = low_img[700:830]\nvalidation_high_image= np.reshape(validation_high_image,(len(validation_high_image),SIZE,SIZE,3))\nvalidation_low_image = np.reshape(validation_low_image,(len(validation_low_image),SIZE,SIZE,3))\n\n\ntest_high_image = high_img[830:]\ntest_low_image = low_img[830:]\ntest_high_image= np.reshape(test_high_image,(len(test_high_image),SIZE,SIZE,3))\ntest_low_image = np.reshape(test_low_image,(len(test_low_image),SIZE,SIZE,3))\n\nprint(\"Shape of training images:\",train_high_image.shape)\nprint(\"Shape of test images:\",test_high_image.shape)\nprint(\"Shape of validation images:\",validation_high_image.shape)\n","eb6d420b":"from keras import layers\ndef down(filters , kernel_size, apply_batch_normalization = True):\n    downsample = tf.keras.models.Sequential()\n    downsample.add(layers.Conv2D(filters,kernel_size,padding = 'same', strides = 2))\n    if apply_batch_normalization:\n        downsample.add(layers.BatchNormalization())\n    downsample.add(keras.layers.LeakyReLU())\n    return downsample\n\n\ndef up(filters, kernel_size, dropout = False):\n    upsample = tf.keras.models.Sequential()\n    upsample.add(layers.Conv2DTranspose(filters, kernel_size,padding = 'same', strides = 2))\n    if dropout:\n        upsample.dropout(0.2)\n    upsample.add(keras.layers.LeakyReLU())\n    return upsample\n\ndef model():\n    inputs = layers.Input(shape= [SIZE,SIZE,3])\n    d1 = down(128,(3,3),False)(inputs)\n    d2 = down(128,(3,3),False)(d1)\n    d3 = down(256,(3,3),True)(d2)\n    d4 = down(512,(3,3),True)(d3)\n    \n    d5 = down(512,(3,3),True)(d4)\n    #upsampling\n    u1 = up(512,(3,3),False)(d5)\n    u1 = layers.concatenate([u1,d4])\n    u2 = up(256,(3,3),False)(u1)\n    u2 = layers.concatenate([u2,d3])\n    u3 = up(128,(3,3),False)(u2)\n    u3 = layers.concatenate([u3,d2])\n    u4 = up(128,(3,3),False)(u3)\n    u4 = layers.concatenate([u4,d1])\n    u5 = up(3,(3,3),False)(u4)\n    u5 = layers.concatenate([u5,inputs])\n    output = layers.Conv2D(3,(2,2),strides = 1, padding = 'same')(u5)\n    return tf.keras.Model(inputs=inputs, outputs=output)\n\nmodel = model()\nmodel.summary()","1d1c925f":"model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mean_absolute_error',\n              metrics = ['acc'])","6d0324b3":"model.fit(train_low_image, train_high_image, epochs = 7, batch_size = 1,\n          validation_data = (validation_low_image,validation_high_image))","b1bbccfd":"def plot_images(high,low,predicted):\n    plt.figure(figsize=(15,15))\n    plt.subplot(1,3,1)\n    plt.title('High Image', color = 'green', fontsize = 20)\n    plt.imshow(high)\n    plt.subplot(1,3,2)\n    plt.title('Low Image ', color = 'black', fontsize = 20)\n    plt.imshow(low)\n    plt.subplot(1,3,3)\n    plt.title('Predicted Image ', color = 'Red', fontsize = 20)\n    plt.imshow(predicted)\n   \n    plt.show()\n\nfor i in range(1,10):\n    \n    predicted = np.clip(model.predict(test_low_image[i].reshape(1,SIZE, SIZE,3)),0.0,1.0).reshape(SIZE, SIZE,3)\n    plot_images(test_high_image[i],test_low_image[i],predicted)","ad6f3c0f":"model.save(\"final_model.h5\")","29da20bf":"# Import Libraires ","d2f6c333":"# Slicing and Reshaping Images","ad26ca84":"# Saving model","aa46620b":"# Defining Model","bd2ad76a":"# Load Data","debdfba0":"# Fitting model","d5dca48f":"# Prediction Visualization","8bbdd654":"## Thank You !!!","db0539fb":"# Compile ","5da59643":"# Data Visualization"}}