{"cell_type":{"4120b70e":"code","f574f800":"code","b6ce2713":"code","79e2d47e":"code","46e856b2":"code","ced56aba":"code","a5f16160":"code","702c1063":"code","63b18c7b":"code","750f3217":"code","ded2a582":"code","44243c0a":"code","e13fb720":"code","075c9d1a":"code","a4605f58":"code","f884ad7b":"code","c3e3bf86":"code","bba0c801":"code","0550af27":"code","273d2f0a":"code","05d2a0d6":"code","27a33a30":"code","926a9fbc":"code","68753ab6":"code","962241b1":"code","668012d9":"code","19c11544":"code","67b08d49":"code","c6bdfb96":"code","5cce856b":"code","5cfa7177":"code","aca41372":"code","b16dab76":"code","cf09be5f":"code","7d709c6a":"code","54175de4":"markdown","42d017a5":"markdown","3ba371c9":"markdown","ca656ec9":"markdown","7724dd6c":"markdown","857bcd8d":"markdown","13eeed12":"markdown","6df8b10f":"markdown","48bd83ba":"markdown"},"source":{"4120b70e":"# Importing essential libraries\nimport numpy as np\nimport pandas as pd","f574f800":"# Loading the dataset\ndf = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')","b6ce2713":"# Returns number of rows and columns of the dataset\ndf.shape","79e2d47e":"# Returns an object with all of the column headers \ndf.columns","46e856b2":"# Returns different datatypes for each columns (float, int, string, bool, etc.)\ndf.dtypes","ced56aba":"# Returns the first x number of rows when head(num). Without a number it returns 5\ndf.head()","a5f16160":"# Returns basic information on all columns\ndf.info()","702c1063":"# Returns basic statistics on numeric columns\ndf.describe().T","63b18c7b":"# Returns true for a column having null values, else false\ndf.isnull().any()","750f3217":"df = df.rename(columns={'DiabetesPedigreeFunction':'DPF'})\ndf.head()","ded2a582":"# Importing essential libraries for visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","44243c0a":"# Plotting the Outcomes based on the number of dataset entries\nplt.figure(figsize=(10,7))\nsns.countplot(x='Outcome', data=df)\n\n# Removing the unwanted spines\nplt.gca().spines['top'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\n\n# Headings\nplt.xlabel('Has Diabetes')\nplt.ylabel('Count')\n\nplt.show()","e13fb720":"# Replacing the 0 values from ['Glucose','BloodPressure','SkinThickness','Insulin','BMI'] by NaN\ndf_copy = df.copy(deep=True)\ndf_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\ndf_copy.isnull().sum()","075c9d1a":"# To fill these Nan values the data distribution needs to be understood\n# Plotting histogram of dataset before replacing NaN values\np = df_copy.hist(figsize = (15,15))","a4605f58":"# Replacing NaN value by mean, median depending upon distribution\ndf_copy['Glucose'].fillna(df_copy['Glucose'].mean(), inplace=True)\ndf_copy['BloodPressure'].fillna(df_copy['BloodPressure'].mean(), inplace=True)\ndf_copy['SkinThickness'].fillna(df_copy['SkinThickness'].median(), inplace=True)\ndf_copy['Insulin'].fillna(df_copy['Insulin'].median(), inplace=True)\ndf_copy['BMI'].fillna(df_copy['BMI'].median(), inplace=True)","f884ad7b":"# Plotting histogram of dataset after replacing NaN values\np = df_copy.hist(figsize=(15,15))","c3e3bf86":"df_copy.isnull().sum()","bba0c801":"from sklearn.model_selection import train_test_split\n\nX = df.drop(columns='Outcome')\ny = df['Outcome']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\nprint('X_train size: {}, X_test size: {}'.format(X_train.shape, X_test.shape))","0550af27":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","273d2f0a":"# Using GridSearchCV to find the best algorithm for this problem\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC","05d2a0d6":"# Creating a function to calculate best model for this problem\ndef find_best_model(X, y):\n    models = {\n        'logistic_regression': {\n            'model': LogisticRegression(solver='lbfgs', multi_class='auto'),\n            'parameters': {\n                'C': [1,5,10]\n               }\n        },\n        \n        'decision_tree': {\n            'model': DecisionTreeClassifier(splitter='best'),\n            'parameters': {\n                'criterion': ['gini', 'entropy'],\n                'max_depth': [5,10]\n            }\n        },\n        \n        'random_forest': {\n            'model': RandomForestClassifier(criterion='gini'),\n            'parameters': {\n                'n_estimators': [10,15,20,50,100,200]\n            }\n        },\n        \n        'svm': {\n            'model': SVC(gamma='auto'),\n            'parameters': {\n                'C': [1,10,20],\n                'kernel': ['rbf','linear']\n            }\n        }\n\n    }\n    \n    scores = [] \n    cv_shuffle = ShuffleSplit(n_splits=5, test_size=0.20, random_state=0)\n        \n    for model_name, model_params in models.items():\n        gs = GridSearchCV(model_params['model'], model_params['parameters'], cv = cv_shuffle, return_train_score=False)\n        gs.fit(X, y)\n        scores.append({\n            'model': model_name,\n            'best_parameters': gs.best_params_,\n            'score': gs.best_score_\n        })\n        \n    return pd.DataFrame(scores, columns=['model','best_parameters','score'])\n\nfind_best_model(X_train, y_train)","27a33a30":"# Using cross_val_score for gaining average accuracy\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(RandomForestClassifier(n_estimators=20, random_state=0), X_train, y_train, cv=5)\nprint('Average Accuracy : {}%'.format(round(sum(scores)*100\/len(scores)), 3))","926a9fbc":"# Creating Random Forest Model\nclassifier = RandomForestClassifier(n_estimators=20, random_state=0)\nclassifier.fit(X_train, y_train)","68753ab6":"# Creating a confusion matrix\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\ncm","962241b1":"# Plotting the confusion matrix\nplt.figure(figsize=(10,7))\np = sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt='g')\nplt.title('Confusion matrix for Random Forest Classifier Model - Test Set')\nplt.xlabel('Predicted Values')\nplt.ylabel('Actual Values')\nplt.show()","668012d9":"# Accuracy Score\nscore = round(accuracy_score(y_test, y_pred),4)*100\nprint(\"Accuracy on test set: {}%\".format(score))","19c11544":"# Classification Report\nprint(classification_report(y_test, y_pred))","67b08d49":"# Creating a confusion matrix for training set\ny_train_pred = classifier.predict(X_train)\ncm = confusion_matrix(y_train, y_train_pred)\ncm","c6bdfb96":"# Plotting the confusion matrix\nplt.figure(figsize=(10,7))\np = sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt='g')\nplt.title('Confusion matrix for Random Forest Classifier Model - Train Set')\nplt.xlabel('Predicted Values')\nplt.ylabel('Actual Values')\nplt.show()","5cce856b":"# Accuracy Score\nscore = round(accuracy_score(y_train, y_train_pred),4)*100\nprint(\"Accuracy on trainning set: {}%\".format(score))","5cfa7177":"# Classification Report\nprint(classification_report(y_train, y_train_pred))","aca41372":"# Creating a function for prediction\ndef predict_diabetes(Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DPF, Age):\n    preg = int(Pregnancies)\n    glucose = float(Glucose)\n    bp = float(BloodPressure)\n    st = float(SkinThickness)\n    insulin = float(Insulin)\n    bmi = float(BMI)\n    dpf = float(DPF)\n    age = int(Age)\n\n    x = [[preg, glucose, bp, st, insulin, bmi, dpf, age]]\n    x = sc.transform(x)\n\n    return classifier.predict(x)","b16dab76":"# Prediction 1\n# Input sequence: Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DPF, Age\nprediction = predict_diabetes(2, 81, 72, 15, 76, 30.1, 0.547, 25)[0]\nif prediction:\n  print('Oops! You have diabetes.')\nelse:\n  print(\"Great! You don't have diabetes.\")","cf09be5f":"# Prediction 2\n# Input sequence: Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DPF, Age\nprediction = predict_diabetes(1, 117, 88, 24, 145, 34.5, 0.403, 40)[0]\nif prediction:\n  print('Oops! You have diabetes.')\nelse:\n  print(\"Great! You don't have diabetes.\")","7d709c6a":"# Prediction 2\n# Input sequence: Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DPF, Age\nprediction = predict_diabetes(5, 120, 92, 10, 81, 26.1, 0.551, 67)[0]\nif prediction:\n  print('Oops! You have diabetes.')\nelse:\n  print(\"Great! You don't have diabetes.\")","54175de4":"# Model Building","42d017a5":"# Predictions","3ba371c9":"# Exploring the dataset","ca656ec9":"# Pima Diabetes Classification & Prediction\n## Predict whether a person has diabetes or not.\n\n![fiji-s-diabetes-epidemic-nation-already-exceeding-who-s-predicted-rate-for-2030\/8258832-1-eng-GB\/Fiji-s-diabetes-epidemic-Nation-already-exceeding-WHO-s-predicted-rate-for-2030_wrbm_large.jpg](https:\/\/cdn-a.william-reed.com\/var\/wrbm_gb_food_pharma\/storage\/images\/publications\/food-beverage-nutrition\/nutraingredients-asia.com\/news\/regulation-policy\/fiji-s-diabetes-epidemic-nation-already-exceeding-who-s-predicted-rate-for-2030\/8258832-1-eng-GB\/Fiji-s-diabetes-epidemic-Nation-already-exceeding-WHO-s-predicted-rate-for-2030_wrbm_large.jpg)\n\n\n","7724dd6c":"# Data Cleaning","857bcd8d":"# Model Evaluation","13eeed12":"# Importing Libraries","6df8b10f":"# Loading the Data","48bd83ba":"*Note: Since the Random Forest algorithm has the highest accuracy, we futher fine tune the model using hyperparameter optimization.*"}}