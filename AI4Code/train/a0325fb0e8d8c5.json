{"cell_type":{"c7299207":"code","08e22a07":"code","2f11cd69":"code","6b08563a":"code","ae2e4c05":"code","f531d68e":"code","1d444a45":"code","94f18a24":"code","ba66bf39":"code","d96e9683":"code","7681a6e3":"code","f0dcc0fe":"code","49622b8c":"code","d0e43db6":"code","1602eae2":"code","a6bf2c58":"code","1a1506fd":"code","4c5e8b9f":"code","f712356d":"code","9af7b8ac":"code","6b85eb07":"code","97d3abbb":"code","a8d54e3f":"code","8d3ae6fd":"code","1f22228a":"code","226c88fc":"code","745783f5":"code","eb270f46":"code","6a06fb7e":"code","2567a944":"code","dea562a2":"code","9c9aef6c":"code","f7737303":"code","0ebea146":"code","93ed6ed3":"code","8a3d79a5":"code","49f45c22":"code","9d0bc8e1":"code","07113691":"code","b4af65fe":"code","931e1460":"code","5e86a4de":"code","be892299":"code","3b7acfba":"code","6a65ad0f":"markdown","e561d09e":"markdown","ce20c1c5":"markdown","a6d528f6":"markdown","9470f918":"markdown","af4b2060":"markdown","0ab478b3":"markdown","f50da64b":"markdown","a5a3d585":"markdown","c1a315fc":"markdown","cedb009e":"markdown","25c47a2d":"markdown","8d340673":"markdown","48092a68":"markdown","de0b2dd7":"markdown"},"source":{"c7299207":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.options.mode.chained_assignment = None  # default='warn'\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","08e22a07":"df = pd.read_csv(\"..\/input\/anime-dataset\/anime.csv\", engine='python')\ndisplay(df.head())\nprint(df.describe())","2f11cd69":"C = df['rating'].mean()\nm = df['votes'].quantile(0.85)\nprint('Mean rating {:.2}, quantite of votes needes to stay {:.0f}'.format(C,m))\n","6b08563a":"df2 = df.loc[df['votes'] >= m]\nprint(df.shape)\nprint(df2.shape)","ae2e4c05":"def weight_rating(x, m=m, C=C):\n    v = x['votes']\n    R = x['rating']\n    \n    return (v\/(v+m) * R) + (m\/(m+v) * C)","f531d68e":"df2['score'] = df2.apply(weight_rating, axis=1)","1d444a45":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.ticker import FuncFormatter\n\n\nplt.figure(figsize=(12, 3), dpi=100)\n\n\ncolor_map = ['#3CB7F1' for _ in range(10)]\ncolor_map[0] = '#5DF13C'\n\n\nbest_score = df2.sort_values(by=['score'], ascending=False)[:10]\n\n\n\ng = plt.bar(best_score[\"title\"], best_score['score'], color=color_map)\nplt.ylabel(\"Score\", color='green')\nplt.xticks(rotation=45, horizontalalignment='right')\nplt.title('Really good animes', fontweight='bold', fontsize=15);\n","94f18a24":"best_rating_not_filter = df.sort_values(by=['rating'], ascending=False)[:10]\n\n\nplt.figure(figsize=(12, 3), dpi=100)\ng = sns.barplot(best_rating_not_filter[\"title\"], best_rating_not_filter['rating'], palette=\"Oranges_r\")\nplt.ylabel(\"Rating\", color='orange', fontweight='bold')\nplt.xlabel(\"\")\ng.set_xticklabels(g.get_xticklabels(), rotation=45,  horizontalalignment='right')\nplt.title('Really good recent rated animes', fontweight='bold', fontsize=15);","ba66bf39":"best_scores = best_score[['score','title','watched', 'studios']].set_index('title')\ndisplay(best_scores)","d96e9683":"dropped = df2.sort_values(by=['dropped', 'score'], ascending=[False, False])\n\nplt.figure(figsize=(12, 3), dpi=100)\n\ncolor_map = ['#f59dd0' for _ in range(5)]\ncolor_map[2] = '#5DF13C'\n\n\nplt.barh(dropped['title'].head(5), dropped['score'].head(5), align='center', color=color_map)\nplt.ylabel('Animes')\nplt.xlabel('Scores')\nplt.title('Most dropped animes');\n\n","7681a6e3":"display(dropped[['score','title','dropped', 'studios']].set_index('title').head(10))\n\n#These are very good animes, but they're also dropped very frequently.","f0dcc0fe":"#use all the data.\n\ndf['description'].head()","49622b8c":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n#create the object vector \ntfidf = TfidfVectorizer(stop_words='english')\n\n#fill nans\ndf['description'] = df['description'].fillna('')\n\n#fit and transform the description in a Term Frequency-Inverse Document Frequency (TF-IDF) matrix\ntfidf_matrix =  tfidf.fit_transform(df['description'])\n\ntfidf_matrix.shape\n\n","d0e43db6":"from sklearn.metrics.pairwise import linear_kernel\n\n#use the tfidf_matrix to pass into a linear kernel and get the cosine similarity matrix \ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n","1602eae2":"#create a index to pass the anime and get the idx\nindice = pd.Series(df.index, index=df['title']).drop_duplicates()\n\ndisplay(indice.head())\nprint(\"A Silent Voice is in index: \", indice['A Silent Voice'])","a6bf2c58":"#define a function to pass the anime and return the recommendations\n\ndef recommendation(title, cosine_sim=cosine_sim):\n    #Get the index of the anime pass\n    idx = indice[title]\n    \n    #make the pairwise similarity score\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    \n    \n    #sort base on similarity\n    sim_scores = sorted(sim_scores, key=lambda x:x[1], reverse =True)\n    \n    #get the 10 most similar\n    sim_scores = sim_scores[1:11]\n    \n    #get the index in df\n    anime_index = [i[0] for i in sim_scores]\n    \n    #return the animes\n    return df['title'].iloc[anime_index]\n    \n    ","1a1506fd":"recommendation('Attack on Titan 3rd Season: Part II')","4c5e8b9f":"recommendation('One-Punch Man')","f712356d":"#create a copy of studios, we'll use this in the future to explore the data\ndf['copy_studios'] = df['studios']\n\nfeatures = ['studios','contentWarn', 'tags']\n\nprint(df[features].isna().sum())","9af7b8ac":"from ast import literal_eval\n\nfor feature in features:\n    df[feature] = df[feature].apply(literal_eval)","6b85eb07":"#make a function to prepare the date\ndef clean_data(x):\n    if isinstance(x, list):\n        return [str.lower(i.replace(\" \",\"\")) for i in x]\n    \n    else:\n        if isinstance(x, str):\n            return str.lower(x.replace(\" \",\"\"))\n        else:\n            return \"\"","97d3abbb":"for feature in features:\n    df[feature] = df[feature].apply(clean_data)","a8d54e3f":"#create a function to put all the words in one 'soup'\ndef soup(x):\n    return \" \".join(x['studios']) + \" \" + \" \".join(x['contentWarn']) + \" \" +\" \".join(x['tags'])\n\ndf['soup'] = df.apply(soup, axis=1)\n    ","8d3ae6fd":"print(df['soup'][10])","1f22228a":"from sklearn.feature_extraction.text import CountVectorizer\n\ncount = CountVectorizer(stop_words='english')\n\ncount_matrix = count.fit_transform(df['soup'])\n","226c88fc":"from sklearn.metrics.pairwise import cosine_similarity\n\n# Compute the Cosine Similarity matrix based on the count_matrix,\n#the count matrix don't down-weight the number of times a tag appears,\n#in this case this is better\n\n\ncosine_2 = cosine_similarity(count_matrix, count_matrix)","745783f5":"#create a index Serie to pass the anime\ndf = df.reset_index()\nindice_2 = pd.Series(df.index, index=df['title'])","eb270f46":"#get the recommendation \nrecommendation('One-Punch Man', cosine_2)","6a06fb7e":"recommendation('Paprika', cosine_2)","2567a944":"display(df[['title', 'mediaType', 'eps', 'duration', 'studios', 'tags', 'contentWarn', 'rating']].loc[df['title'] == 'Paprika'])\ndisplay(df[['title', 'mediaType', 'eps', 'duration', 'studios', 'tags', 'contentWarn', 'rating']].iloc[[5453, 6113, 3394, 3877]])","dea562a2":"#get rid of the animes that hasn't been released \ndf = df.loc[df['startYr'] <= 2020]","9c9aef6c":"#make bins and labels for decades\nbins = [i for i in range(1910,2021,10)]\nlabels = [str(i)+str(\"-\")+str(i+10) for i in range(1910,2020,10)]\n\ndf['decade_of_released'] = pd.cut(df['startYr'], bins=bins, labels=labels)\n","f7737303":"tv_data = df.loc[df['mediaType'] == 'TV']\ntv_data = tv_data.groupby('decade_of_released').count()['title']\n","0ebea146":"\n#plot\n\nplt.figure(figsize=(12, 4), dpi=120)\nsns.set_style(\"ticks\")\n\nsplot = sns.countplot(x='decade_of_released', hue='mediaType', data=df)\n\nfor p in splot.patches:\n    if p.get_height() in tv_data.values:\n        splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                       ha = 'right', va = 'center', xytext = (0, 4), textcoords = 'offset points', color='blue')\n        \nplt.ylabel(\"Amount\", color='orange', fontweight='bold')\nplt.xlabel(\"Decade of Released\", color='orange', fontweight='bold', labelpad=15)\nplt.legend(loc='upper left', facecolor='#42d3ff', framealpha=1)\nsns.despine()\nplt.show();","93ed6ed3":"plt.figure(figsize=(12, 4), dpi=120)\nscatter = sns.violinplot(data=df, x='decade_of_released', y='rating')\n\nplt.ylabel(\"Rating\", color='orange', fontweight='bold')\nplt.xlabel(\"Decade of Released\", color='orange', fontweight='bold', labelpad=15)\nplt.title('Decade and ratings', fontweight='bold');","8a3d79a5":"plt.figure(figsize=(12, 4), dpi=120)\nscatter = sns.violinplot(data=df, x='mediaType', y='rating')\nplt.ylabel(\"Rating\", color='orange', fontweight='bold')\nplt.xlabel(\"Media Type\", color='orange', fontweight='bold', labelpad=15)\nplt.title('Media Type', fontweight='bold');","49f45c22":"plt.figure(figsize=(18, 4), dpi=120)\nsns.violinplot(data=df, x='decade_of_released', y='rating', color=\"white\")\nsns.stripplot(data=df, x='decade_of_released', y='rating', hue='mediaType', jitter=True,\n                   dodge=True, \n                   marker='o', \n                   alpha=0.2)\n\n\n\nplt.ylabel(\"Rating\", color='orange', fontweight='bold')\nplt.xlabel(\"Decade of Released\", color='orange', fontweight='bold', labelpad=15)\nplt.title('Decade, Ratings and Media Type', fontweight='bold');","9d0bc8e1":"#fill the NaN with zeros\ndf['rating'] = df['rating'].fillna(0)\n","07113691":"#The Copy Studios is not a list, but a string, so we need to clean that.\ndf['copy_studios'] = df['copy_studios'].str.replace('[', '')\ndf['copy_studios'] = df['copy_studios'].str.replace(']', '')\ndf['copy_studios'] = df['copy_studios'].str.replace(\"'\", \"\")\ndf['copy_studios'] = df['copy_studios'].str.split(\",\")\n","b4af65fe":"#create a dict with each studio\ncnt = {}\n\nfor idx, row in df.iterrows():\n    rating = row['rating']\n    studios = row['copy_studios']\n    for studio in studios:      \n        if not studio in cnt:\n            cnt[studio] = {}\n            cnt[studio].setdefault('productions', 1)\n            score = float(rating) \n            cnt[studio]['rating'] = []\n            cnt[studio]['rating'].append(score)\n        else:\n            score = float(rating)\n            cnt[studio]['productions'] += 1\n            cnt[studio]['rating'].append(score)\n            \n\n","931e1460":"import numpy as np\n#get the mean rating of the studios\nfor studio in cnt:\n    cnt[studio]['rating'] = round(np.mean(cnt[studio]['rating']),2)\n    ","5e86a4de":"#make the dict a data frame\nstudios = pd.DataFrame.from_dict(cnt, orient='index')\n","be892299":"#let's see the most prolific studios\n\nmore_productive_st = studios.sort_values(by=['productions', 'rating'], ascending = [False, False])[:20]\nmore_productive_st","3b7acfba":"#plot the results\n\nmore_productive_st['studios'] = more_productive_st.index\n\nsns.set_style(style=\"whitegrid\")\nplt.figure(figsize=(12, 6), dpi=100)\n\n\ngx2 = sns.scatterplot(x='studios', y=\"productions\",data= more_productive_st[1:], size='rating', sizes=(20, 200), color=\"skyblue\")\n\n\nplt.xticks(rotation=45, horizontalalignment='right')\nplt.xlabel('Studios', fontweight='bold', labelpad=10, color='green')\nplt.ylabel('Productions 1917-2020', fontweight='bold', labelpad=5, color='green')\nplt.title('Studios, Productions and Ratings', fontweight='bold', color='darkblue', fontsize=13)\n\n\nplt.show()","6a65ad0f":"But, maybe, your friend hasn't watched too much anime, and also he doesn't want to take a look at your list, so he could just end up watching and anime and dropping it. Let's make a plot with the most dropped animes to (if possible) avoid at the beginning of his anime career.","e561d09e":"It's been a long way since 1910 to 2020, starting with just a few movies to end up with a really good amount of material to watch. Take a look how Web was just 2 little dots in 1990-2000 to be a large a tick line en 2000-2010, and it hasn't \"eat\" the other types, because there's still Movies, Tv Specials, OVA's, and DVD","ce20c1c5":"Good, but this system get the similar words and structure in the review. That's why we get all the anime from the franchise in first place and also why we get animes from the Saitama Prefecture in the case of One-Punch Man. It's not a bad idea to watch everything that the anime has for you, but we are more sophisticated and want to get similar animes from the studio, the content warning and tags.","a6d528f6":"# Recommendation System","9470f918":"Just to check, let's do the same but with all the ratings in the original data.","af4b2060":"![](http:\/\/)Base on this type of rating the number of anime decreased a lot, but the main idea is to keep the rating equally as possible to (first) recommend the best animes.","0ab478b3":"**So, if a friend tells you \"*hey, I wanna watch a anime, any recommendations?*\" You could say, yes:**","f50da64b":"31.384 words were used to describe the 14.578 animes. Next, compute the [Cosine Similarity](https:\/\/en.wikipedia.org\/wiki\/Cosine_similarity)\n","a5a3d585":"# Data Analysis\nNow, let's take a look at the studios.","c1a315fc":"# Recommendation System Part.2","cedb009e":"Now you need a recommendation system for people who have already watched anime. First we are going to use the review of each anime to make a matrix that will compute the Term Frequency-Inverse Document Frequency (TF-IDF).","25c47a2d":"# **Pretty goods animes to watch, if you like Paprika. Now we can extract some info from the data.**","8d340673":"Make a function to obtain the score of each anime","48092a68":"**That's all. If you any recommendation to improve the notebook, please comment and\n*Thanks!!***","de0b2dd7":"I'll be using IMDB's weighted rating (wr):\n\n![](https:\/\/image.ibb.co\/jYWZp9\/wr.png)\n\n* v is the number of votes for the movie;\n* m is the minimum votes required to be listed in the chart;\n* R is the average rating of the movie; And\n* C is the mean vote across the whole report\n\nThis is a good way to avoid weight more the animes that has been recently released and have more stars and less votes.\n   "}}