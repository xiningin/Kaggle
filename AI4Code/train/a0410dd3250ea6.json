{"cell_type":{"436ab4aa":"code","b981c056":"code","1d3efd9f":"code","3b484acc":"code","909329a7":"code","87a6b93b":"code","34918323":"code","8a29e5dd":"code","6a5d86f4":"code","18263283":"code","b82aef6f":"code","6c43a82a":"code","3c95649f":"code","bbb993b4":"code","8f42f4a9":"code","66191c15":"code","7adc3faa":"code","138f0c10":"code","78828d35":"code","19195941":"code","0a151744":"code","30731ddc":"code","f588fd45":"code","c5a57f34":"code","1b458351":"code","9215b32e":"code","e1b378a1":"code","27c5f76b":"code","9eb193d4":"code","0e9e0321":"code","1f93a74e":"code","e6865a52":"code","04f3c894":"code","3c853345":"code","ede6a3d4":"code","16d47141":"code","32ee4188":"code","851d4644":"code","e55ec97b":"code","88d24db8":"code","bcfdc0fa":"code","92c2624d":"code","5118d005":"code","1cae559e":"code","a94dd2b3":"code","98f242dc":"code","4773dcb4":"code","e46d6d25":"code","69ede120":"code","098d8f29":"code","a23914ac":"code","d39542fc":"code","b658ebfa":"code","bdd68bdb":"code","cefa1e69":"code","571cca49":"code","343c3747":"code","22d055dc":"code","68c04779":"code","d1d82eb8":"code","a0a2cdac":"code","32757ba1":"code","eb7a8842":"code","b90ff6f9":"code","801f75ae":"markdown","c2a8e4ef":"markdown","c63aff4f":"markdown","4cbd32fc":"markdown","e77b164d":"markdown","74557e71":"markdown","efd0cdca":"markdown","b21c822a":"markdown","1ab562b8":"markdown","c60b10ab":"markdown","aa6ce6f9":"markdown","7a33d884":"markdown","8c93da42":"markdown","5eabf256":"markdown","88161d69":"markdown","cd6b91a0":"markdown","06baf24f":"markdown","3c749fd2":"markdown","43d1ef86":"markdown"},"source":{"436ab4aa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b981c056":"# importing Data Analysis tools\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","1d3efd9f":"df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf.head()\ndf_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndf_test.head()","3b484acc":"df_test.info()","909329a7":"# verify the data shape\ndf.shape","87a6b93b":"# check the content missing value\ndf.isna().sum()","34918323":"# verify the data mean, median, average and the other mathmatical values\ndf.describe()","8a29e5dd":"# check the datasets datatype\ndf.info()","6a5d86f4":"pd.crosstab(df['Age'][df['Survived'] == 1], df['Survived'][df['Survived'] == 1]).plot(linestyle='-', legend=False)\nplt.ylabel('Number of passenger')\nplt.title('Relation between the Age and Survival');","18263283":"pd.crosstab(df['Sex'], df['Survived']).plot(kind='bar', cmap='tab20c')\nplt.ylabel('Number of passengers')\nplt.title('Relation between the Sex and the Survived Passenger');","b82aef6f":"pd.DataFrame(df['Pclass'].value_counts()).plot(kind='bar')\nplt.xlabel('Ticket Class')\nplt.ylabel('Number of passenger')\nplt.title('Number of passenger in each class');","6c43a82a":"pd.crosstab(df['Pclass'], df['Survived']).plot(kind='bar', cmap='tab20c');","3c95649f":"corr_matrix = df.corr()\nsns.heatmap(corr_matrix, annot=True, cmap='Blues', cbar=False);","bbb993b4":"pd.crosstab(df['Fare'][df['Survived'] == 1], df['Survived'][df['Survived'] == 1]).plot()","8f42f4a9":"# verify the data missing value\ndf.isna().sum()","66191c15":"copy_df = df.copy()","7adc3faa":"copy_df['Age_Bins'] = pd.cut(df.Age, bins=10)","138f0c10":"copy_df.groupby('Age_Bins')['Fare'].mean().plot(kind='bar', figsize=(10, 5));","78828d35":"copy_df.groupby('Parch')['Survived'].value_counts().plot(kind='bar');","19195941":"copy_df.groupby('SibSp')['Parch'].sum().plot(kind='bar');","0a151744":"copy_df.groupby('Parch')['Fare'].median().sort_values().plot(kind='barh');","30731ddc":"copy_df.groupby('SibSp')['Pclass'].value_counts().plot(kind='bar');","f588fd45":"test_df = pd.read_csv('..\/input\/titanic\/test.csv')\ntest_df.head()","c5a57f34":"y = copy_df['Survived']\ncopy_df.drop('Survived', axis=1, inplace=True)\n\ncopy_df['Source'] = \"Train\"\ntest_df['Age_Bins'] = pd.cut(test_df.Age, bins=10)\ntest_df['Source'] = \"Test\"","1b458351":"combine_df = pd.concat([copy_df, test_df], axis=0)\ncombine_df.shape","9215b32e":"combine_df.isna().sum()","e1b378a1":"combine_df.Age.sort_values().unique()[:10]","27c5f76b":"combine_df.head()","9eb193d4":"data = []\nnum = []\nfor values in combine_df.Ticket:\n    if len(values.split(' ')) > 1:\n        data.append(values.strip().split(' ')[0])\n        num.append(values.strip().split(' ')[1])\n    else:\n        data.append('X')\n        num.append(values)\ncombine_df['Ticket_Category'] = data\ncombine_df['Ticket_Update'] = num\ncombine_df.head()","0e9e0321":"combine_df.Cabin.fillna('X', inplace=True)\ncombine_df['Cabin_Category'] = combine_df.Cabin.apply(lambda x: x[0])\ncombine_df.head()","1f93a74e":"combine_df['Cabin_Num'] = combine_df.Cabin.apply(lambda x: x[1:] if len(x) > 1 else 'n')\ncombine_df.head()","e6865a52":"combine_df.isna().sum()","04f3c894":"combine_df.drop('Age_Bins', axis=1, inplace=True)","3c853345":"combine_df.Embarked.fillna(combine_df.Embarked.mode()[0], inplace=True)\n","ede6a3d4":"from sklearn.preprocessing import LabelEncoder","16d47141":"label_encoder = LabelEncoder()\ncombine_df.Embarked = label_encoder.fit_transform(combine_df.Embarked)\ncombine_df.Sex = label_encoder.fit_transform(combine_df.Sex)\ncombine_df.Cabin_Num = label_encoder.fit_transform(combine_df.Cabin_Num)\ncombine_df.Cabin_Category = label_encoder.fit_transform(combine_df.Cabin_Category)\ncombine_df.Ticket_Category = label_encoder.fit_transform(combine_df.Ticket_Category)\ncombine_df.Ticket_Update = label_encoder.fit_transform(combine_df.Ticket_Update)","32ee4188":"combine_df.head()","851d4644":"combine_df.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)","e55ec97b":"combine_df.Age.fillna(combine_df.Age.median(), inplace=True)","88d24db8":"df_train, df_test = combine_df[combine_df.Source == 'Train'], combine_df[combine_df.Source == 'Test']","bcfdc0fa":"df_train.drop('Source', axis=1, inplace=True)\ndf_test.drop('Source', axis=1, inplace=True)","92c2624d":"df_train.isna().sum()","5118d005":"# import all the sklearn libraries\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import LinearSVC","1cae559e":"len(X_train), len(y_train)","a94dd2b3":"decision_model = DecisionTreeClassifier()\ndecision_model.fit(df_train, df.Survived)\nplt.barh(df_train.columns, decision_model.feature_importances_);","98f242dc":"X_train.drop(['Cabin_Category', 'Embarked', 'Parch', 'Ticket_Category'], axis=1, inplace=True)\nX_val.drop(['Cabin_Category', 'Embarked', 'Parch', 'Ticket_Category'], axis=1, inplace=True)","4773dcb4":"# create the object of the machine learning model\nlg_model = LogisticRegression()\nk_neighbor_model = KNeighborsClassifier()\nrf_model = RandomForestClassifier()\nd_model = DecisionTreeClassifier()\nsvc_model = LinearSVC()\nada_model = AdaBoostClassifier()","e46d6d25":"estimators = [lg_model, rf_model, svc_model, ada_model]\nscore_history = {}\n\nfor i in range(0, 101, 2):\n    final_evaluation = []\n    for model in estimators:\n        np.random.seed(i)\n        X_train, X_val, y_train, y_val = train_test_split(df_train, df.Survived, test_size=0.2)\n        model.fit(X_train, y_train)\n        score = model.score(X_val, y_val)\n        final_evaluation.append({model: score})\n    score_history[i] = final_evaluation\n    ","69ede120":"plt.figure(figsize=(20, 8))\nfor i in range(0, 101, 2):\n    plt.bar(i, score_history.get(i)[0].values(), color='red')\n    plt.grid()\n    plt.xlabel('Random Seed')\n    plt.ylabel('Accuracy')\n    plt.title('Logistic Regression', fontsize=24, fontweight='bold')","098d8f29":"plt.figure(figsize=(20, 8))\nfor i in range(0, 101, 2):\n    plt.bar(i, score_history.get(i)[1].values(), color='green')\n    plt.grid()\n    plt.xlabel('Random Seed')\n    plt.ylabel('Accuracy')\n    plt.title('RandomForest Classifier', fontsize=24, fontweight='bold')","a23914ac":"plt.figure(figsize=(20, 8))\nfor i in range(0, 101, 2):\n    plt.bar(i, score_history.get(i)[2].values(), color='orange')\n    plt.grid()\n    plt.xlabel('Random Seed')\n    plt.ylabel('Accuracy')\n    plt.title('LinearSVC', fontsize=24, fontweight='bold')","d39542fc":"plt.figure(figsize=(20, 8))\nfor i in range(0, 101, 2):\n    plt.bar(i, score_history.get(i)[3].values(), color='purple')\n    plt.grid()\n    plt.xlabel('Random Seed')\n    plt.ylabel('Accuracy')\n    plt.title('AdaBoost Classifier', fontsize=24, fontweight='bold')","b658ebfa":"np.random.seed(46)\nX_train, X_val, y_train, y_val = train_test_split(df_train, df.Survived, test_size=0.2)\nrf_model.fit(X_train, y_train)\nrf_model.score(X_val, y_val)","bdd68bdb":"np.random.seed(8)\nX_train, X_val, y_train, y_val = train_test_split(df_train, df.Survived, test_size=0.2)\nlg_model.fit(X_train, y_train)\nlg_model.score(X_val, y_val)","cefa1e69":"np.random.seed(6)\nX_train, X_val, y_train, y_val = train_test_split(df_train, df.Survived, test_size=0.2)\nsvc_model.fit(X_train, y_train)\nsvc_model.score(X_val, y_val)","571cca49":"np.random.seed(24)\nX_train, X_val, y_train, y_val = train_test_split(df_train, df.Survived, test_size=0.2)\nada_model.fit(X_train, y_train)\nada_model.score(X_val, y_val)","343c3747":"df_test.Fare.fillna(df_test.Fare.median(), inplace=True)","22d055dc":"df_test.isna().sum()","68c04779":"for i in range(10, 101, 10):\n    rf_model = RandomForestClassifier(n_estimators=i)\n    rf_model.fit(X_train, y_train)\n    print(f\"Estimators {i}: {rf_model.score(X_val, y_val)}\")","d1d82eb8":"rf_model = RandomForestClassifier(n_estimators=20)\nrf_model.fit(X_train, y_train)\nrf_model.score(X_val, y_val)","a0a2cdac":"from sklearn.model_selection import cross_val_score\nscore = cross_val_score(cat_model, df_train, df.Survived, cv=10)\nscore.mean()","32757ba1":"from catboost import CatBoostClassifier\ncat_model = CatBoostClassifier(learning_rate=0.1)\ncat_model.fit(X_train, y_train)\ncat_model.score(X_val, y_val)","eb7a8842":"y_preds = cat_model.predict(df_test)","b90ff6f9":"# create the submission csv file\npreds = pd.DataFrame(y_preds, columns=['Survived'], index=np.arange(892, 1310))\npreds.index.name = 'PassengerId'\npreds.to_csv('submission7.csv')","801f75ae":"## Feature Data\n\nLets perform some feature enginnering to manipulate the datatypes and fill the missing value in our datasets if any.","c2a8e4ef":"From the correlation matrix we see that fare is contributing the maximum ratio for the survival of the passenger.\n\nLets see the relation between the fare and the survival.","c63aff4f":"We see from the above correlation matrix that:\n* Fare and Age have a high posistive correlation.\n* Parch have a high positive correlation with the target variable.\n* Sibsp and Parch have high positive correlation.\n* Parch and Fare have a high positive correlation.\n* Pclass and SibSp have a high positive correlation.","4cbd32fc":"So, from the above graph we can predict that the passenger of age age around 25 years died in the shipwrek and the teenagers of age around 8-10 years died minimum in the shipwrek.\n\nLet's found the relation between the male and the female effect on the survival rate in the shipwrek.","e77b164d":"Let's make this dataframe visual to understand it more deeper inside the datasets.","74557e71":"The graph above show that 1st class passenger give the priorty to live in the shipwrek and 3rd class passenger doestnot survived much as out of around 500 3rd class passenger only around 120 passenger survived.  \n\nLets create a correlation matrix between all the labels and dependent variable to check out the all the relation at once","efd0cdca":"### Data Evaluation\n\n#### Exploratory Data Analysis (EDA)\nLet's perform some Data Analysis to understand the data and find the relation between the depenedent variable and the independent variable.","b21c822a":"## Modeling\nSo, we perform the feature operation and convert the object datatype into numeric and fill the missing values. So its time to model the machine learning model and perform the experimentation to improve the model using hyperparameter tuning.\n\nSince, we dealing up with the binary data. So, we use Classification model for modelling the datasets. For this problem we are using:\n1. Logistic Regression\n2. K-Neighbor Classifier\n3. RandomForest Classification","1ab562b8":"Lets prepare the datasets into X and y labels","c60b10ab":"Loading up the train and the test data and verify the datasets","aa6ce6f9":"## Data Aggregation","7a33d884":"## Transformation\nWe extract the information from the columns and create the separate columns which containes the central tedency over different columns.\n\n* Fare and Age have a high posistive correlation. (sum)\n* Sibsp and Parch have high positive correlation. (\n* Parch and Fare have a high positive correlation.\n* Pclass and SibSp have a high positive correlation.","8c93da42":"## Load our Tools for Analysis and Machine Learning Modeling","5eabf256":"* Linear Regression: 8\n* RandomForest Classifier: 46\n* LinearSVC: 6\n* AdaBoost Classifier: 24","88161d69":"We see from the above correlation matrix that:\n* Fare and Age have a high posistive correlation.\n* Parch have a high positive correlation with the target variable.\n* Sibsp and Parch have high positive correlation.\n* Parch and Fare have a high positive correlation.\n* Pclass and SibSp have a high positive correlation.","cd6b91a0":"Now find the relation between the different variables and the correlation matrix between the dependent variable and the independent variable.\n\nLet's create a relation between the age and the survived labels and understand what factors affects the age on the survived.","06baf24f":"We got the best score using the RandomForest Classifier. So we move on with the model and firstly perform the manual hyperparameter tuning and increase the accuracy of the model.","3c749fd2":"So, from this graph we conclude that maximum female survived in the shipwrek.\n\nNow, lets find the relation between the ```pclass``` and the survived rate","43d1ef86":"# Titanic - Machine Learning Competition\n> The goal of this competition is create Machine Learning Model to predict which passenger survived in the Titanic shipwrek.\n\nSo, we achieve our goal by following steps:\n1. Problem Defination\n2. Make the Data Ready\n3. Data Evaluation\n4. Feature Data\n5. Data Modeling\n6. Experimentation\n\n## 1. Problem Defination\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: \u201cwhat sorts of people were more likely to survive?\u201d using passenger data (ie name, age, gender, socio-economic class, etc).\n\n### Data Dictonary\n* survival: Survival (0 = No, 1 = Yes)\n* pclass: Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)\n* sex: Sex\t\n* Age: Age (in years)\t\n* sibsp: of siblings\/spouses aboard the Titanic\t\n* parch: of parents\/children aboard the Titanic\t\n* ticket: Ticket number\t\n* fare: Passenger fare\t\n* cabin: Cabin number\t\n* embarked: Port of Embarkation"}}