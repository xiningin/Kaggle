{"cell_type":{"15aba89b":"code","1d0661dc":"code","ca23ece4":"code","4c50ab71":"code","7de81a55":"code","1f08489e":"code","8b253de9":"code","20810e9e":"code","4317791e":"code","75a28b5a":"code","e8dddc59":"code","140827eb":"code","f3bb4842":"code","630b3c19":"code","3efe78f3":"code","1c37a072":"code","981cac77":"code","2231a3e5":"code","6a341f2f":"code","3fcb260c":"code","5b16a5ab":"code","936d77c4":"code","a11672c8":"code","89b87f94":"code","0dd6bce9":"code","ab9c6532":"code","678d4ec3":"code","f80f5676":"code","a7a93927":"code","a73786c2":"code","952d2168":"code","8a74b23b":"code","f44f6e89":"code","5cdc0fe6":"code","52cf55fc":"code","c7061a33":"code","25f49f2f":"code","f7385df0":"markdown","aba407ad":"markdown","7f53bf81":"markdown","b5d0ca0c":"markdown","400cb573":"markdown","127c1215":"markdown","ba8c82c6":"markdown","29a79c43":"markdown","59a1da35":"markdown","9e3f4c39":"markdown","5da1a6b4":"markdown","b15066b3":"markdown","4216f5b5":"markdown","42397cb2":"markdown","8cbe1c9d":"markdown","a33eb062":"markdown","9704303b":"markdown","900b732f":"markdown","4bca7954":"markdown","e3142cc7":"markdown","9e69c7f9":"markdown","44ef7a6f":"markdown","c864c0e8":"markdown","97679495":"markdown","87a96903":"markdown","251d753b":"markdown","eb71acbe":"markdown","acfd5d47":"markdown","825f40b3":"markdown","1f7f1aca":"markdown","4d190d5a":"markdown","2bdcf815":"markdown","8270dee9":"markdown","91d9cea3":"markdown","17b6398d":"markdown","ca09a558":"markdown"},"source":{"15aba89b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","1d0661dc":"import pandas_datareader.data as web","ca23ece4":"import statsmodels\nstatsmodels.__version__","4c50ab71":"import datetime as dt\n\nend = dt.datetime.now() #today's date\nend","7de81a55":"#example:\n\nprint(end.year)\nprint(end.month)\nprint(end.day)","1f08489e":"start = end - dt.timedelta(days=2600) # start from 26\/11\/2014\nstart","8b253de9":"#BTC-USD\n\ncompany = 'BTC-USD'\nsource = 'yahoo'","20810e9e":"# Retrieving the historical values of the BTC price \ndf = web.DataReader(company,\n                    source,\n                    start = start,\n                    end = end)[['Close']].reset_index() #only Close Price\n\n# Making sure we are dealing with Datetime\ndf['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n\n# Resetting the dates as indexes\ndf.set_index(['Date'], inplace=True)\n\n# On a Daily Basis\ndf = df.asfreq('d')\n\n# Chronological sorting\ndf.sort_index(inplace=True)\n\n# Showing the df we are going to work with\ndf     #last datapoint is yesterdays close","4317791e":"#checking for missing values\n\ndf.isnull().sum() #Everything's OK!","75a28b5a":"import plotly.express as px\n\nfig = px.line(df, x=df.index, y=\"Close\")\n\nfig.update_layout(title='BTC\/USD Price',\n                   xaxis_title='Years',\n                   yaxis_title='Price')\n\nfig.show()","e8dddc59":"log_df = np.log(df) #log df\n\nfig = px.line(log_df, x=log_df.index, y=\"Close\")\n\nfig.update_layout(title='BTC\/USD Log Price Representation',\n                   xaxis_title='Years',\n                   yaxis_title='LOG Price')\n\nfig.show()","140827eb":"# Let's difference this and look at the ACFs\nfig, axes = plt.subplots(1, 3,figsize=(15,4))\n\nplt.style.use('seaborn-deep')\n\naxes[0].plot(log_df);\naxes[0].set_title('Linearized Series')\n             \n# 1st Differencing\ny_diff = log_df.diff().dropna()\naxes[1].plot(y_diff); \naxes[1].set_title('1st Order Differencing')\n\n# 2nd Differencing\ny_diff_diff = log_df.diff().diff().dropna()\naxes[2].plot(y_diff_diff); \naxes[2].set_title('2nd Order Differencing')","f3bb4842":"from statsmodels.tsa.stattools import adfuller","630b3c19":"adfuller(log_df)","3efe78f3":"# check with ADF Test for stationarity\n\ny_diff= log_df.diff().dropna()\ny_diff_diff= log_df.diff().diff().dropna()\n\nprint('p-value zero-diff: ', adfuller(log_df)[1])\nprint('p-value first-diff: ', adfuller(y_diff)[1])\nprint('p-value second-diff: ', adfuller(y_diff_diff)[1])","1c37a072":"pip install pmdarima","981cac77":"#check for the best number of diffs to apply (using ndiffs):\n\nfrom pmdarima.arima.utils import ndiffs\n\nd = ndiffs(log_df)\nd #1 diff will be enough!","2231a3e5":"from statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\n\n#figure setup\nfig = plt.figure(figsize=(20,10))\nax1 = fig.add_subplot(2,1,1)\nax1.set_title('1st Order Differencing')\nax2 = fig.add_subplot(2,2,3)\nax3 = fig.add_subplot(2,2,4)\n\n#plots\nax1.plot(y_diff)\nplot_acf(y_diff, lags=20, ax=ax2);\nplot_pacf(y_diff, lags=20, ax=ax3, color='r', method='ywm')\nplt.show()","6a341f2f":"q = 1\np = 1","3fcb260c":"#from statsmodels.tsa.arima_model import ARIMA #statsmodels 0.11\nfrom statsmodels.tsa.arima.model import ARIMA #statsmodels >=0.12\n\ny= log_df.Close #just to be precise\n\narima = ARIMA(y, order=(p,d,q)) #1,1,1\n#arima = arima.fit(disp = 0 )\narima = arima.fit()\narima.summary()","5b16a5ab":"import pmdarima as pm\nsmodel = pm.auto_arima(y,\n                       start_p =0, max_p = 5,\n                       start_d = 0, max_d = 5,\n                       start_q = 0, max_q = 5,\n                       seasonal = False,\n                       trace = True)","936d77c4":"train_size=0.7 #70% of data\n\nindex = round(train_size*log_df.shape[0])\n\ny_train = log_df.iloc[:index] #first 70% rows for training set\ny_test = log_df.iloc[index:] #last 30% rows for test set\nn_train=len(y_train)\n\n#results from autoarima\nbest_order = smodel.order # best (p,d,q)","a11672c8":"y_train.shape, y_test.shape","89b87f94":"y_train","0dd6bce9":"n_train","ab9c6532":"plt.figure(figsize=(14,6))\nplt.plot(ARIMA(y_train,order=best_order).fit().get_forecast(10).predicted_mean)\nplt.plot(ARIMA(y_train,order=best_order).fit().get_forecast(10).conf_int())","678d4ec3":"arima_df = ARIMA(y_train,order=best_order).fit().get_forecast(10).conf_int()\narima_df['pred'] = ARIMA(y_train,order=best_order).fit().get_forecast(10).predicted_mean\narima_df","f80f5676":"def walk_forward_validation(n_train, test):\n    # create dataframe to store the outcome\n    result = pd.DataFrame(columns=['forecast', 'lower_interval', 'upper_interval'])\n    # predict one point at a time\n    for i in range(len(test)):\n        # define train set\n        train_ = log_df.iloc[:n_train+i, :].copy()\n        # train the model\n        arima = ARIMA(endog = train_, order=best_order).fit(method_kwargs={\"warn_convergence\": False})\n        # get the forecast\n        results = arima.get_forecast(1, alpha=0.05)\n        # central\n        result.loc[i, 'forecast'] = results.predicted_mean[0]\n        # lower interval\n        result.loc[i, 'lower_interval'] = results.conf_int().iloc[0, 0]\n        # upper interval\n        result.loc[i, 'upper_interval'] = results.conf_int().iloc[0, 1]\n    # join with test dataframe\n    result.index=test.index\n    result = result.apply(pd.to_numeric)\n    return test.join(result)\n\nresult = walk_forward_validation(n_train, y_test)","a7a93927":"result","a73786c2":"# baseline = tomorrows prediction is todays price\nresult['base'] = result['Close'].shift()\nresult['base'].iloc[0] = y_train.Close[-1]\nresult.apply(lambda x: np.exp(x).astype('float16')).tail(5) #exp for visualization only","952d2168":"# We define here a \"Plot forecast vs. real\", which also shows historical train set\n\ndef plot_forecast(fc, train, test, upper=None, lower=None):\n    is_confidence_int = isinstance(upper, np.ndarray) and isinstance(lower, np.ndarray)\n    # Prepare plot series\n    fc_series = pd.Series(fc, index=test.index)\n    lower_series = pd.Series(upper, index=test.index) if is_confidence_int else None\n    upper_series = pd.Series(lower, index=test.index) if is_confidence_int else None\n\n    # Plot\n    plt.figure(figsize=(10,4), dpi=100)\n    plt.plot(train, label='training', color='black')\n    plt.plot(test, label='actual', color='black', ls='--')\n    plt.plot(fc_series, label='forecast', color='orange')\n    if is_confidence_int:\n        plt.fill_between(lower_series.index, lower_series, upper_series, color='k', alpha=.15)\n    plt.title('Forecast vs Actuals')\n    plt.legend(loc='upper left', fontsize=8);","8a74b23b":"plot_forecast(result.forecast, y_train, y_test, np.array(result.upper_interval), np.array(result.lower_interval))","f44f6e89":"#https:\/\/en.wikipedia.org\/wiki\/Mean_absolute_scaled_error","5cdc0fe6":"# define a function to get MAPE using y_pred, y_true\ndef get_mape(y_true, y_pred):\n    '''takes y_true, y_pred (pandas series)\n    returns mean absolute percentage error'''\n    mape = 100*((y_true - y_pred)\/y_true).abs().mean()\n    return round(mape, 2)\n\n# define a function to get MASE using y_pred, y_true\ndef get_mase(y_true, y_pred, y_train):\n    '''takes y_true, y_pred (pandas series)\n    returns mean absolute scaled error'''\n    mae_test = (y_true - y_pred).abs().mean()\n    y_t = y_train\n    y_t_1 = y_train.shift(-1)\n    mae_train = (y_t - y_t_1).abs().mean()\n    return round(mae_test\/mae_train, 2)","52cf55fc":"# MAPE and MASE \nprint('mape model:', get_mape(result.Close, result.forecast))\nprint('mape baseline:', get_mape(result.Close, result.base))\nprint('')\nprint('mase model:', get_mase(result.Close, result.forecast, y_train.Close))\nprint('mase baseline', get_mase(result.Close, result.base, y_train.Close))","c7061a33":"forecast_recons = np.exp(result.forecast)\ntrain_recons = np.exp(y_train)\ntest_recons = np.exp(y_test)\nlower_recons = np.array(np.exp(result.lower_interval))\nupper_recons = np.array(np.exp(result.upper_interval))\n\n# plt \nplot_forecast(forecast_recons, train_recons, test_recons, upper_recons, lower_recons)","25f49f2f":"print(np.exp(ARIMA(log_df,order=best_order).fit().get_forecast(1).predicted_mean))","f7385df0":"# We get a Straight line! Not good. \u274c","aba407ad":"## BEST PREDICTION FOR TOMORROW'S PRICE: \ud83d\udcb8","7f53bf81":"# What have we learned\u2753","b5d0ca0c":"\ud83d\udca1 When TS have exponential growth, it is generally a good idea to use the logarithm to make the plot look more linear.","400cb573":"\ud83d\udcb8 Let's try to predict the future price of Bitcoin (BTC\/USD) using ARIMA.","127c1215":"We use the **PACF** plot to calculate the value for **p** \n\nWe use the **ACF** plot to calculate the value for **q**","ba8c82c6":"## Let's evaluate using performace metrics...","29a79c43":"## Transformation : Linearization (Logarithm)","59a1da35":"# Re-compose back to initial Time Series","9e3f4c39":"\ud83d\udc49 Check for stationarity using the Augmented Dickey-Fuller test:\n\n    \u274c Null hypothesis: Stationarity **does not** exist in the series.\n\n     \u2757 Alternative Hypothesis: Stationarity **does** exist in the series.\n     \n[Statsmodel Documentation: Adfuller](https:\/\/www.statsmodels.org\/dev\/generated\/statsmodels.tsa.stattools.adfuller.html)","5da1a6b4":"\ud83d\udc49 A stationary time series is one whose properties do not depend on the time at which the series is observed.","b15066b3":"# ARIMA","4216f5b5":"<div>\n<img src=\"https:\/\/loghi-famosi.com\/wp-content\/uploads\/2020\/08\/Bitcoin-Logo.png\"  width=\"200\"\/>\n<\/div>","42397cb2":"### Temporal Split and Forecast","8cbe1c9d":"## Financial Data (Yahoo Finance)","a33eb062":"\ud83d\udcda The `pandas_datareader` is a Python library that you can use to import financial data from Yahoo, the OECD, WorldBank,\n[etc.......](https:\/\/pandas-datareader.readthedocs.io\/en\/latest\/remote_data.html)","9704303b":"## Crypto Market:","900b732f":"\ud83d\udc49 Choose a starting date","4bca7954":"## Training the ARIMA","e3142cc7":"### Step 1: Setting up the TS","9e69c7f9":"# \ud83c\udfc1","44ef7a6f":"# We also need a quick baseline model...\n\n## ... Best prediction for the price tomorrow is the price today. \ud83d\ude25\ud83e\udd76","c864c0e8":"#### Visualisation","97679495":"# BITCOIN - TIME SERIES ARIMA PREDICTION: \ud83c\udfc6","87a96903":"\ud83d\udcc6  What day is it today ? ","251d753b":"## Stationarisation","eb71acbe":"## Visualisation, Transformation and  Decomposition:","acfd5d47":"\ud83d\udcc8 How does my TS look like ?","825f40b3":"# Model fit","1f7f1aca":"## GridSearching with `auto_arima`","4d190d5a":"**Reminder:** \n- A small p-value (<0.05) suggests  strong evidence against H0, so you **reject the null hypothesis**. \ud83d\udc49 Stationary\n- A large p-value (> 0.05) indicates weak evidence against H0, so you **fail to reject the null hypothesis**. \ud83d\udc49 Non-stationary","2bdcf815":"# Model Validation \ud83e\uddd0","8270dee9":"\u2611\ufe0f TimeSeries Models work better with Stationary TS !\n\n\ud83d\udc49 Let's try to differentiate the linearized version of the TS.","91d9cea3":"#### Let's find the Hyperparameters _p_ and _q_","17b6398d":"**What ARIMA stands for?:** ARIMA is short for \u2018AutoRegressive Integrated Moving Average\u2019, is a forecasting algorithm based on the idea that the information in the past values of the time series can alone be used to predict the future values. Maybe this assumption is not good enough for precise stock price predictions \ud83e\udd14\n\n**Last words**: This 'investigation' found that the price follows a random walk approach \u27a1 past price action can not be used to determine future price action.\n\n[More information can be found here.](https:\/\/www.investopedia.com\/terms\/r\/randomwalktheory.asp) **[Random Walk Theory]**","ca09a558":"## Is it really possible? Let's find out together!"}}