{"cell_type":{"be311028":"code","4807a7f3":"code","75047689":"code","532903cb":"code","e35aac19":"code","5ff243a8":"code","ade15851":"code","fcf98809":"code","fdc7d411":"code","f21195d6":"code","cb1da2ce":"code","b0a8a70a":"code","4e8313ea":"code","ce76b8b5":"code","255512d9":"code","1508299c":"code","7d490bb6":"code","b98ebfaf":"code","2ff79199":"code","b7e20d14":"code","3bdcfc16":"code","9848ce53":"markdown","b30ba68d":"markdown","68413932":"markdown","a4cdea1e":"markdown","e4ad811e":"markdown","7fbbc85e":"markdown","8446c114":"markdown","0844cb3f":"markdown","d79ad3f4":"markdown","1e8f21dd":"markdown","5a1360af":"markdown","2e6e7651":"markdown","53f13a9b":"markdown","50010ff1":"markdown","9dbfb1c1":"markdown","b8a64193":"markdown","1ad2d5c5":"markdown","101c95b3":"markdown"},"source":{"be311028":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport nltk\nimport re\n\nimport glob\nimport io\n# Any results you write to the current directory are saved as output.\n\nimport seaborn as sns\nfrom decimal import Decimal\nimport locale\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer","4807a7f3":"job_titles = pd.read_csv(\"..\/input\/cityofla\/CityofLA\/Additional data\/job_titles.csv\", header = None)\njob_titles.head()","75047689":"sample_job_export = pd.read_csv('..\/input\/cityofla\/CityofLA\/Additional data\/sample job class export template.csv')\nsample_job_export","532903cb":"kaggle_data_dictionary = pd.read_csv('..\/input\/cityofla\/CityofLA\/Additional data\/kaggle_data_dictionary.csv')\nkaggle_data_dictionary","e35aac19":"code = r'Class\\s{1,2}Code:\\s*(\\d*)'\nopen_d = r'Open Date:\\s*(\\d\\d-\\d\\d-\\d\\d)'\nsal = r'(\\$(\\d+,\\d+))((\\s(to|and|-)\\s)(\\$\\d+,\\d+))?' # Taken from kaggle kernel\nsal_dwp = r'Power\\sis\\s((\\$(\\d+,\\d+))((\\s(to|and|-)\\s)(\\$\\d+,\\d+))?)'\ndut = r'DUTIES\\W+(.*\\n)' # Duties\nreq = r'REQUIREMENT(S)?(\/MINIMUM\\sQUALIFICATION)?\\W+(.*\\n)' #Requirements\nend_d = r'(MONDAY|TUESDAY|WEDNESDAY|THURSDAY|FRIDAY|SATURDAY|SUNDAY)\\W+(JANUARY|FEBRUARY|MARCH|APRIL|MAY|JUNE|JULY|AUGUST|SEPTEMBER|OCTOBER|NOVEMBER|DECEMBER)(.*\\d)'\nexp_len = r'(one|two|three|four|five|six|seven|eight|nine)\\s(?=(year|years|month|months)\\sof\\s(?=(full-time|part-time)))' \nsch_typ = r'(college|university|high school|apprentice)' # School Type\nedu_y = r'(\\b\\w+(-year))(?=\\D+(college|university))' #Education Year\nedu_major = r'(college or university|college|university|apprentice)\\D+(in|as a)\\s(\\D+);' # Education Major\ncourse_l = r'(\\d+\\ssemester.+quarter(\\sunits)?)'\n#open_d = r'Open Date: (.*)\\n' ","5ff243a8":"def doextraction(glob_text):\n    col = ['FILE_NAME', 'JOB_CLASS_TITLE', 'JOB_CLASS_NO', 'REQUIREMENT_SET_ID', 'REQUIREMENT_SUBSET_ID', 'JOB_DUTIES',\\\n           'EDUCATION_YEARS', 'SCHOOL_TYPE', 'EDUCATION_MAJOR', 'EXPERIENCE_LENGTH', 'FULL_TIME_PART_TIME', \\\n           'EXP_JOB_CLASS_TITLE', 'EXP_JOB_CLASS_ALT_RESP', 'EXP_JOB_CLASS_FUNCTION', 'COURSE_COUNT', 'COURSE_LENGTH',\\\n           'COURSE_SUBJECT', 'MISC_COURSE_DETAILS', 'DRIVERS_LICENSE_REQ', 'DRIV_LIC_TYPE', 'ADDTL_LIC', 'EXAM_TYPE', \\\n           'SALARY_START', 'SALARY_END', 'ENTRY_SALARY_DWP', 'REQUIREMENTS', 'APPLICATION_DEADLINE', 'OPEN_DATE']\n    \n    df = pd.DataFrame(columns = col) # Initializing a data frame with all the column names mentioned above.\n    \"\"\"Get all the files from the given glob and pass them to the extractor.\"\"\"\n    for thefile in glob.glob(glob_text)[:200]:\n        with io.open(thefile, 'r', errors = 'replace') as fyl:\n            text = fyl.read()\n            df = get_features(text, thefile, df)\n            \n    return df ","ade15851":"with open('..\/input\/cityofla\/CityofLA\/Job Bulletins\/ADVANCE PRACTICE PROVIDER CORRECTIONAL CARE 2325 020808 REV 111214.txt', encoding = 'utf-8') as f:\n    print(f.read())","fcf98809":"def get_headings(text): # Returns all the headings in the text file as a list \n    headings_list = []\n    for line in text.split('\\n'):\n        if line.isupper():\n            headings_list.append(line.strip())\n    \n    return headings_list","fdc7d411":"def get_job_class(text): \n    # This function returns the title and the class code of the job. \n    job_title = text.strip().splitlines()[0].strip()\n    class_code = re.findall(code, text)[0]\n    \n    return job_title, class_code ","f21195d6":"def get_open_date(text):\n    try:\n        open_date = re.findall(open_d, text)[0]\n    except:\n        open_date = np.NaN\n        \n    return open_date","cb1da2ce":"def get_salary(text):\n    salary_range = re.search(sal, text)\n    \n    try:\n        salary_start = salary_range.group(1)\n    except:\n        salary_start = np.NaN\n        \n    try:\n        salary_end = salary_range.group(6)\n    except:\n        salary_end = np.NaN\n        \n    salary_dwp = re.search(sal_dwp, text).group(1) if re.search(sal_dwp, text) is not None else np.NaN\n    \n    return salary_start, salary_end, salary_dwp","b0a8a70a":"def get_requirement(headings, text):\n    # All the text mentioned in the requirement section is returned.\n    x = headings.index([elm for elm in headings if elm.startswith('REQUIREMENT')][0])\n    m = re.search(headings[x], text).end()\n    n = re.search(headings[x+1], text).start()\n    requirement = text[m:n].strip()\n    \n    return requirement","4e8313ea":"def get_duties(headings, text):\n    try:\n        x = headings.index([elm for elm in headings if elm.startswith('DUT')][0])\n        m = re.search(headings[x], text).end()\n        n = re.search(headings[x+1], text).start()\n        duties = text[m:n].strip()\n    except:\n        duties = np.NaN\n        \n    return duties","ce76b8b5":"def get_req_id(requirement):\n    # This function returns requirement_set_id and requirement_subset_id.\n    req_id = re.search('(\\d)\\.', requirement.strip()[:2]).group(1) if re.search('(\\d\\.)', requirement.strip()[:2]) is \\\n            not None else np.NaN\n    req_sub_id = re.search('\\n(a)\\.', requirement).group(1) if re.search('\\n(a)\\.', requirement) is not None \\\n            else np.NaN\n    \n    return req_id, req_sub_id","255512d9":"def get_exp_job(requirement):\n    exp_id = re.findall(r'(?<=Los Angeles as a )(\\w+\\s\\w+)', requirement)\n    if len(exp_id) == 1:\n        k1 = exp_id[0]\n        k1b = np.NaN\n    elif len(exp_id) > 1:\n        k1 = exp_id[0]\n        k1b = exp_id[1]\n    else:\n        k1 = k1b = np.NaN\n    \n    k2 = re.search('(?<=experience)(.+)(;|\\.|or)', requirement).group(1).strip() if re.search('(?<=experience)(.+)(;|\\.|or)', requirement)\\\n            is not None else np.NaN\n    \n    return k1, k1b, k2","1508299c":"def get_exam_type(headings):\n    heads_text = ' '.join(headings)\n\n    if re.search('\\sINTERDEPART\\w+ PROMOT', heads_text) and re.search('\\sOPEN COMPETIT', heads_text):\n        e_type ='OPEN_INT_PROM'\n    elif re.search('\\sINTERDEPART\\w+ PROMOT', heads_text):\n        e_type = 'INT_DEPT_PROM'\n    elif re.search('\\sDEPARTMENT\\w+ PROMOT', heads_text):\n        e_type = 'T_PROM'\n    else:\n        e_type = 'OPEN'\n        \n    return e_type","7d490bb6":"def get_features(text, filename, df):\n    filename = filename.replace('..\/input\/cityofla\/CityofLA\/Job Bulletins\/', '')\n    headings = get_headings(text)\n    \n    job_title, class_code = get_job_class(text)\n    \n    open_date = get_open_date(text)\n    \n    salary_start, salary_end, salary_dwp = get_salary(text)\n    \n    requirement = get_requirement(headings, text)\n    \n    req_id, req_sub_id = get_req_id(requirement)\n    \n    duties = get_duties(headings, text)\n    \n    # e1 is the conjunction used in the requirements\n    e1 = requirement.splitlines()[0][-3:].strip() if len(requirement.splitlines()) >1 else np.NaN\n    if e1 != 'and' and e1 != 'or':\n        e1 = np.NaN\n        \n    k1, k1b, k2 =  get_exp_job(requirement)   \n    \n    # p1 and p2 are 'DRIVERS_LICENSE_REQ' and 'DRIV_LIC_TYPE'\n    if re.search('(positions may require a valid California driver\\'s license)', text, re.I) is not None:\n        p1 = 'P'\n        \n    elif re.search('(driver\\'s license is required)', text, re.I) is not None:\n        p1 = 'R' \n        \n    else:\n        p1 = np.NaN\n    \n    p2 = re.search(\"((?<=Class)\\s\\w\\s)(?=\\D+driver's)\", text, re.I).group(0).strip() if \\\n            re.search(\"((?<=Class)\\s\\w\\s)(?=\\D+driver's)\", text, re.I) is not None else np.NaN\n    \n    try:\n        x = re.findall(end_d, text)[0]\n        deadline = ''.join(x).strip()\n    except:\n        deadline = np.NaN\n     \n    exam_type = get_exam_type(headings)\n    \n    df = df.append({'FILE_NAME': filename, 'JOB_CLASS_TITLE': job_title, 'JOB_CLASS_NO': class_code,\\\n                   'REQUIREMENT_SET_ID': req_id, 'REQUIREMENT_SUBSET_ID': req_sub_id, 'JOB_DUTIES': duties,\\\n                   'EXP_JOB_CLASS_TITLE': k1, 'EXP_JOB_CLASS_ALT_RESP': k1b, 'EXP_JOB_CLASS_FUNCTION': k2, \\\n                    'DRIVERS_LICENSE_REQ': p1, 'DRIV_LIC_TYPE': p2, 'EXAM_TYPE': exam_type, 'SALARY_START': salary_start, 'SALARY_END': salary_end, \\\n                    'ENTRY_SALARY_DWP': salary_dwp, 'REQUIREMENTS': requirement, 'APPLICATION_DEADLINE': deadline, \\\n                    'OPEN_DATE': open_date}, ignore_index = True)\n    \n    # Append the features extracted from each text file.\n    return df","b98ebfaf":"data_df = doextraction('..\/input\/cityofla\/CityofLA\/Job Bulletins\/*.txt')","2ff79199":"def get_extra_features(data_df):\n    data_df['EXPERIENCE_LENGTH'] = data_df.REQUIREMENTS.apply(lambda x: re.search(exp_len,x, re.IGNORECASE).group(1)+ ' ' + re.search(exp_len,x, re.IGNORECASE).group(2) \\\n                                                              if re.search(exp_len,x, re.IGNORECASE) is not None else np.NaN)\n    data_df['FULL_TIME_PART_TIME'] = data_df.REQUIREMENTS.apply(lambda x: re.search(exp_len,x,re.I).group(3) if re.search(exp_len,x,re.I) is not None else np.NaN)\n    data_df['SCHOOL_TYPE'] = data_df.REQUIREMENTS.apply(lambda x: re.search(sch_typ, x, re.I).group(1)\\\n                                                        if re.search(sch_typ, x, re.I) is not None else np.NaN)\n\n    data_df['EDUCATION_YEARS'] = data_df.REQUIREMENTS.apply(lambda x: re.search(edu_y, x, re.I).group(1)\\\n                                                           if re.search(edu_y, x, re.I) is not None else np.NaN)\n\n\n    data_df['EDUCATION_MAJOR'] = data_df.REQUIREMENTS.apply(lambda x: re.search(edu_major, x).group(3)\\\n                                                           if re.search(edu_major, x) is not None else np.NaN)\n    \n    \n    data_df.COURSE_LENGTH = data_df.REQUIREMENTS.apply(lambda x: re.search(course_l, x, re.I).group(0) if re.search(course_l, x, re.I)\\\n                                                  is not None else np.NaN)\n    return data_df","b7e20d14":"data_df = get_extra_features(data_df)\ndata_df.head(15)","3bdcfc16":"percent_missing = data_df.isna().mean().round(4) * 100\nmissing_value_df = pd.DataFrame({'percent_missing': percent_missing})\nmissing_value_df.sort_values('percent_missing', ascending=False, inplace=True)\nmissing_value_df.head(15)","9848ce53":"Requirements mentioned in the text are extracted by finding the character position after the Requirement heading and the position previous to next heading. After finding the characters range, requirements are extracted from string.","b30ba68d":"In the above function text is taken as input and finds the lower and upper limit of the salary mentioned. Also, the first DWP-specific salary range is found.\nIf the salary is flat-rated then the one amount is returned.","68413932":"Let us check the percentage of missing values in each column. Five columns are completely misssing as they are not given any values.","a4cdea1e":"The information for the exam type is extracted in the headings list as this whole line is UpperCase letters. In this the exam type is categorized based on the description given in kaggle_data_dictionary.CSV file for exam type. Firstly, we are checking for the interdepartmental promotion and open competition followed by Interdedartmental promotion, departmental promotion and open type exam. These are labeled as described inthe description of CSV file.","e4ad811e":"If you like my kernel or think it's helpful, please upvote. Thank You.","7fbbc85e":"In this function k1 is the job title of the job one must hold to satisfy the requirement. In this case I am taking only first two letters of the job title.\nk1b is the alternate class of k1 and k2 is the field in which experience is required to satisfy this job requirements.","8446c114":"# Looking into CSV files\nAdditional data folder contains 3 CSV files:\n    1. job_titles.CSV : This file contains Job class titles of the available jobs.\n    2. sample job class export template.CSV : This file contains sample submission of csv.\n    3. kaggle_data_dictionary.CSV: This file contains the name and details of the columns to include in the exported csv file.","0844cb3f":"# Importing the required packages","d79ad3f4":"The above section containd some of the regex used to extract features. These Regular Expressions are used to extract various details needed to be included in the columns. \nThe regex for salary (sal) is taken from kernel https:\/\/www.kaggle.com\/shahules\/discovering-opportunities-at-la","1e8f21dd":"The Duties mentioned in the Bulletin are extracted finding the range of the characters similar to the requirements","5a1360af":"From the above output we can see the general pattern of the text files.","2e6e7651":"# Feature Extraction","53f13a9b":"# More to be added soon","50010ff1":"In the above function get_extra_features I am adding the features that can be extracted from requirements.","9dbfb1c1":"get_features function takes in each text file at a time and extract features from that and appends the extracted features to a data frame.\nAlso, in the above function whether driver's license required or not and the class of divers license required are extracted from text.","b8a64193":"In this section sevaral functions are defined to get various featueres. Major features are extracted from each file and appended to the data frame, while some additional features are extracted after the data frame is made with few features.","1ad2d5c5":"In the doextraction function a dataFrame is initialized with all the column names. This function takes in path for the text files, read each file and send it to the get_features function. The dataframe with details from the text is updated after reading each file. ","101c95b3":"In the pattern of the text files one can observe that the headings in the file are UpperCase letters. So, Using above function I am extracting headings. Also, it is observed that the first heading is the job title."}}