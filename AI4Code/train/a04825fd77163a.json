{"cell_type":{"05560ab1":"code","4111e13c":"code","af842f9a":"code","1e15010b":"code","e8651fed":"code","ae000a85":"code","0c62180e":"code","893d8fa8":"code","5271d3c6":"code","667faf91":"code","2705d7eb":"code","6c8f5010":"code","3dbd202e":"code","98a15095":"code","38803eb9":"code","7ce42151":"code","08c54d07":"code","d641e4aa":"markdown","ade75b50":"markdown","6fb241c4":"markdown","f391e5fd":"markdown","d079f461":"markdown","8f47c3e0":"markdown","089fa188":"markdown","71b60115":"markdown","c131430e":"markdown","f0cdbc1f":"markdown","461d5033":"markdown","48dc8117":"markdown","c686982c":"markdown","baffb178":"markdown"},"source":{"05560ab1":"import numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten\nfrom keras.optimizers import Adam, RMSprop, SGD\nfrom keras import regularizers\nfrom keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau\nimport datetime\nimport matplotlib.pyplot as plt\nfrom keras.utils import plot_model","4111e13c":"train_dir = '..\/input\/fer2013\/train\/'\ntest_dir = '..\/input\/fer2013\/test\/'\n\nrow, col = 48, 48\nclasses = 7\n\ndef count_exp(path, set_):\n    dict_ = {}\n    for expression in os.listdir(path):\n        dir_ = path + expression\n        dict_[expression] = len(os.listdir(dir_))\n    df = pd.DataFrame(dict_, index=[set_])\n    return df\ntrain_count = count_exp(train_dir, 'train')\ntest_count = count_exp(test_dir, 'test')\nprint(train_count)\nprint(test_count)","af842f9a":"train_count.transpose().plot(kind='bar')","1e15010b":"test_count.transpose().plot(kind='bar')","e8651fed":"plt.figure(figsize=(14,22))\ni = 1\nfor expression in os.listdir(train_dir):\n    img = load_img((train_dir + expression +'\/'+ os.listdir(train_dir + expression)[1]))\n    plt.subplot(1,7,i)\n    plt.imshow(img)\n    plt.title(expression)\n    plt.axis('off')\n    i += 1\nplt.show()","ae000a85":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   zoom_range=0.3,\n                                   horizontal_flip=True)\n\ntraining_set = train_datagen.flow_from_directory(train_dir,\n                                                batch_size=64,\n                                                target_size=(48,48),\n                                                shuffle=True,\n                                                color_mode='grayscale',\n                                                class_mode='categorical')\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_set = test_datagen.flow_from_directory(test_dir,\n                                                batch_size=64,\n                                                target_size=(48,48),\n                                                shuffle=True,\n                                                color_mode='grayscale',\n                                                class_mode='categorical')","0c62180e":"training_set.class_indices","893d8fa8":"def get_model(input_size, classes=7):\n     #Initialising the CNN\n    model = tf.keras.models.Sequential()   \n\n    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape =input_size))\n    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(2, 2))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n    model.add(Dense(1024, activation='relu'))\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(classes, activation='softmax'))\n\n    #Compliling the model\n    model.compile(optimizer=Adam(lr=0.0001, decay=1e-6), \n                  loss='categorical_crossentropy', \n                  metrics=['accuracy'])\n    return model","5271d3c6":"fernet = get_model((row,col,1), classes)\nfernet.summary()","667faf91":"plot_model(fernet, to_file='fernet.png', show_shapes=True, show_layer_names=True)","2705d7eb":"chk_path = 'ferNet.h5'\nlog_dir = \"checkpoint\/logs\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\ncheckpoint = ModelCheckpoint(filepath=chk_path,\n                             save_best_only=True,\n                             verbose=1,\n                             mode='min',\n                             moniter='val_loss')\n\nearlystop = EarlyStopping(monitor='val_loss', \n                          min_delta=0, \n                          patience=3, \n                          verbose=1, \n                          restore_best_weights=True)\n                        \nreduce_lr = ReduceLROnPlateau(monitor='val_loss', \n                              factor=0.2, \n                              patience=6, \n                              verbose=1, \n                              min_delta=0.0001)\n\n\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\ncsv_logger = CSVLogger('training.log')\n\ncallbacks = [checkpoint, reduce_lr, csv_logger]","6c8f5010":"steps_per_epoch = training_set.n \/\/ training_set.batch_size\nvalidation_steps = test_set.n \/\/ test_set.batch_size\n\nhist = fernet.fit(x=training_set,\n                 validation_data=test_set,\n                 epochs=60,\n                 callbacks=callbacks,\n                 steps_per_epoch=steps_per_epoch,\n                 validation_steps=validation_steps)","3dbd202e":"plt.figure(figsize=(14,5))\nplt.subplot(1,2,2)\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['train', 'test'], loc='upper left')\n\nplt.subplot(1,2,1)\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","98a15095":"train_loss, train_accu = fernet.evaluate(training_set)\ntest_loss, test_accu = fernet.evaluate(test_set)\nprint(\"final train accuracy = {:.2f} , validation accuracy = {:.2f}\".format(train_accu*100, test_accu*100))","38803eb9":"fernet.save_weights('fernet_bestweight.h5')","7ce42151":"y_pred = fernet.predict(training_set)\ny_pred = np.argmax(y_pred, axis=1)\nclass_labels = test_set.class_indices\nclass_labels = {v:k for k,v in class_labels.items()}\n\nfrom sklearn.metrics import classification_report, confusion_matrix\ncm_train = confusion_matrix(training_set.classes, y_pred)\nprint('Confusion Matrix')\nprint(cm_train)\nprint('Classification Report')\ntarget_names = list(class_labels.values())\nprint(classification_report(training_set.classes, y_pred, target_names=target_names))\n\nplt.figure(figsize=(8,8))\nplt.imshow(cm_train, interpolation='nearest')\nplt.colorbar()\ntick_mark = np.arange(len(target_names))\n_ = plt.xticks(tick_mark, target_names, rotation=90)\n_ = plt.yticks(tick_mark, target_names)","08c54d07":"y_pred = fernet.predict(test_set)\ny_pred = np.argmax(y_pred, axis=1)\nclass_labels = test_set.class_indices\nclass_labels = {v:k for k,v in class_labels.items()}\n\n#from sklearn.metrics import classification_report, confusion_matrix\ncm_test = confusion_matrix(test_set.classes, y_pred)\nprint('Confusion Matrix')\nprint(cm_test)\nprint('Classification Report')\ntarget_names = list(class_labels.values())\nprint(classification_report(test_set.classes, y_pred, target_names=target_names))\n\nplt.figure(figsize=(8,8))\nplt.imshow(cm_test, interpolation='nearest')\nplt.colorbar()\ntick_mark = np.arange(len(target_names))\n_ = plt.xticks(tick_mark, target_names, rotation=90)\n_ = plt.yticks(tick_mark, target_names)","d641e4aa":"### Confusion Matrix and Classification on training set","ade75b50":"## importing libraries","6fb241c4":"high accracy is achieved on training set but accuracy on validation set is stuck at 66% also no overfitting can se seen in the dataset hence is can be concluded that the inefficiency may be due to the unbalanced dataset","f391e5fd":"### Model evaluation","d079f461":"## Creating Training and test sets","8f47c3e0":"### Confusion Matrix and Classification on test set","089fa188":"## Loss and Accuracy plot","71b60115":"### PLot of number of images in test set","c131430e":"## Training Model","f0cdbc1f":"### Callbacks Function","461d5033":"## Defining Model","48dc8117":"# Facial Emotion Recogination","c686982c":"### PLot of number of images in training set","baffb178":"## Importing Dataset"}}