{"cell_type":{"4b8bc22b":"code","468f5468":"code","db790067":"code","6c9569be":"code","fbd022a2":"code","a9891177":"code","702f0ea8":"code","2eecbb35":"code","ea7ca14f":"code","b13a2027":"code","5324e3ae":"code","a15196f0":"code","32ded711":"code","d1bda8bf":"code","85af3c2b":"code","3fa77b01":"code","add8f18e":"code","bd18f813":"code","3f4003cd":"code","93a22eeb":"code","47207219":"code","8f7d2bcf":"code","22d00cd6":"markdown","08de7c8a":"markdown","f8058873":"markdown","4a350df6":"markdown","ec9173df":"markdown","77936b72":"markdown","8288741c":"markdown","9bdb930f":"markdown","90468e38":"markdown","6686b4f6":"markdown","5730c698":"markdown","722ea2a2":"markdown","daaca486":"markdown","dae583a9":"markdown","6880e04f":"markdown","ca553068":"markdown","665d2c60":"markdown","614f24bb":"markdown","1cf50881":"markdown","9ed1bf1f":"markdown","f3fab14a":"markdown","d410bed1":"markdown"},"source":{"4b8bc22b":"import numpy as np \nimport pandas as pd \nfrom sklearn.model_selection import train_test_split \nfrom matplotlib import pyplot as plt \n\n#It makes directly below the code cell that produced it. \n%matplotlib inline \n\n#Take a look at a iceberg\nimport plotly.offline as py \nimport plotly.graph_objs as go \nfrom plotly import tools \n\n#Ignore warnings\nimport warnings \nwarnings.filterwarnings('ignore')\n\npy.init_notebook_mode(connected=True)","468f5468":"!pip install py7zr\nimport py7zr\nimport os\n\nif not os.path.exists('\/kaggle\/train\/') :\n    os.makedirs('\/kaggle\/train\/')\n\nif not os.path.exists('\/kaggle\/test\/') :\n    os.makedirs('\/kaggle\/test\/')\n\nwith py7zr.SevenZipFile(\"\/kaggle\/input\/statoil-iceberg-classifier-challenge\/train.json.7z\", 'r') as archive:\n    archive.extractall(path=\"\/kaggle\/train\")\n\nwith py7zr.SevenZipFile(\"\/kaggle\/input\/statoil-iceberg-classifier-challenge\/test.json.7z\", 'r') as archive:\n    archive.extractall(path=\"\/kaggle\/test\")\n\nfor dirname, _, filenames in os.walk('\/kaggle'): \n    for filename in filenames: \n        print(os.path.join(dirname, filename))","db790067":"train = pd.read_json('\/kaggle\/train\/data\/processed\/train.json')\ntest = pd.read_json('\/kaggle\/test\/data\/processed\/test.json')","6c9569be":"train.head()","fbd022a2":"train['inc_angle'].value_counts()","a9891177":"#na -> 0\ntrain.inc_angle = train.inc_angle.replace('na',0)","702f0ea8":"#Check out the length\nlen(train.loc[0,'band_1'])","2eecbb35":"#Generate the training data \n#Create 3 bands having HH, HV, avg of both \nX_band_1 = np.array([np.array(band).astype(np.float32).reshape(75,75) for band in train['band_1']])\nX_band_2 = np.array([np.array(band).astype(np.float32).reshape(75,75) for band in train['band_2']])\n#Use 'np.concatenate' to make a new channel for a color image \nX_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],((X_band_1+X_band_2)\/2)[:, :, :, np.newaxis]], axis=-1)\n\nX_band_test_1 = np.array([np.array(band).astype(np.float32).reshape(75,75) for band in test['band_1']])\nX_band_test_2 = np.array([np.array(band).astype(np.float32).reshape(75,75) for band in test['band_2']])\n\nX_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis],\n                         X_band_test_2[:, :, :, np.newaxis],\n                         ((X_band_test_1+X_band_test_2)\/2)[:, :, :, np.newaxis]], axis=-1)","ea7ca14f":"#For example, let's see 14 sample\ntrain.loc[14, 'is_iceberg']","b13a2027":"#We can see that even if the pic is same, but different depend on band1,2\nband1 = X_band_1[14,:,:]\nband2 = X_band_2[14,:,:]\n#We use 'from plotly import tools'-> import tools\nfig = tools.make_subplots(rows=1,cols=2, specs=[[{'is_3d': True}, {'is_3d':True}]])\ndata = go.Surface(z=band1, colorscale='RdBu_r', scene='scene1', showscale=True)\ndata1 = go.Surface(z=band2, colorscale='RdBu_r', scene='scene2', showscale=True)\n\nfig['layout'].update(title='3D surface plot for example14 ', titlefont=dict(size=30), height=600, width=800)\n\nfig.append_trace(data,1,1)\nfig.append_trace(data1,1,2)\npy.iplot(fig)","5324e3ae":"#This picture is only viewed from above without considering the z axis.\nplt.imshow(band1)\nplt.show()","a15196f0":"#Make 3D surface plot \nlabel = 'ship'\n\nfig = tools.make_subplots(rows=1, cols=2,  specs=[[{'is_3d': True}, {'is_3d': True}]])\nfig.append_trace(dict(type='surface', z=band1, colorscale='RdBu_r', scene='scene1', showscale=False), 1, 1)\nfig.append_trace(dict(type='surface', z=band2, colorscale='RdBu_r', scene='scene2', showscale=False), 1, 2)\n\n#The bottom part is setting size and the title of fig\nfig['layout'].update(title='3D surface plot for \"{}\" (left is from band1, right is from band2)'.format(label), titlefont=dict(size=30), height=600, width=800)\n\npy.iplot(fig)","32ded711":"#Use 'def' function to make it \ndef plot_contour_2d(band1, band2, label):\n    fig = tools.make_subplots(rows=1, cols=2, specs=[[{'is_3d': True}, {'is_3d':True}]])\n    fig.append_trace(dict(type='surface', z=band1, colorscale='RdBu_r', scene='scene1', showscale=False), 1, 1)\n    fig.append_trace(dict(type='surface', z=band2, colorscale='RdBu_r', scene='scene2', showscale=False), 1, 2)\n    \n    fig['layout'].update(title='3D surface plot for \"{}\" (left is from band1, right is from band2)'.format(label), titlefont=dict(size=30), height=600, width=800)\n    \n    py.iplot(fig)\n    \n#The bottom part here is now a code that shows the top view without the z axis.   \n    fig, ax = plt.subplots(1,2,figsize=(16,10))\n    ax[0].imshow(X_band_1[num,:,:])\n    ax[0].set_title('Image from band_1', fontsize=15)\n    ax[1].imshow(X_band_2[num,:,:])\n    ax[1].set_title('Image from band_2', fontsize=15)\n    plt.show()","d1bda8bf":"num = 0\nlabel = 'iceberg' if (train['is_iceberg'].values[num] == 1) else'ship'\nplot_contour_2d(X_band_1[num,:,:], X_band_2[num,:,:], label)","85af3c2b":"#Check out num 100\nnum =100 \nlabel = 'iceberg' if (train['is_iceberg'].values[num] == 1) else 'ship'\nplot_contour_2d(X_band_2[num,:,:], X_band_2[num,:,:], label)","3fa77b01":"#Import Keras \nfrom matplotlib import pyplot \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom keras import initializers\nfrom keras.optimizers import Adam\n#Stop learning if the loss does not decrease further through keras.callbacks.\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping","add8f18e":"#define our model\ndef getModel():\n    #Buildin the model\n    gmodel = Sequential()\n    #Conv Layer1\n    gmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu', input_shape=(75,75,3)))\n    gmodel.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n    gmodel.add(Dropout(0.2))\n    \n    #Conv Layer2\n    gmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n    gmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n    gmodel.add(Dropout(0.2))\n    \n    #Conv Layer3\n    gmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n    gmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n    gmodel.add(Dropout(0.2))\n    \n    #Conv Layer4\n    gmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n    gmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n    gmodel.add(Dropout(0.2))\n    \n    #Flatten the data for upcoming dense layers\n    gmodel.add(Flatten())\n    \n    #Dense Layers\n    gmodel.add(Dense(512))\n    gmodel.add(Activation('relu'))\n    gmodel.add(Dropout(0.2))\n    \n    #Sigmoid Layer\n    #Adam makes model Optimization\n    gmodel.add(Dense(1))\n    gmodel.add(Activation('sigmoid'))\n    \n    mypotim=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n    gmodel.compile(loss='binary_crossentropy', optimizer=mypotim, metrics=['accuracy'])\n    gmodel.summary()\n    return gmodel\n\ndef get_callbacks(filepath, patience=2):\n    es = EarlyStopping('val_loss', patience=patience, mode='min')\n    msave = ModelCheckpoint(filepath, save_best_only=True)\n    return [es, msave]\nfile_path = '.model_weights.hdf5'\ncallbacks = get_callbacks(filepath=file_path, patience=5)","bd18f813":"target_train = train['is_iceberg']\nX_train, X_valid, y_train, y_valid = train_test_split(X_train,\n                                                      target_train,\n                                                      random_state=1,\n                                                      train_size = 0.8)","3f4003cd":"#Without denoising, core features\ngmodel = getModel()\ngmodel.fit(X_train, y_train,\n           batch_size=24,\n           epochs=10,\n           verbose=1,\n           validation_data=(X_valid, y_valid),\n           callbacks=callbacks)","93a22eeb":"#Recall saved weight \ngmodel.load_weights(filepath = file_path)\nscore = gmodel.evaluate(X_valid, y_valid, verbose=1)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","47207219":"#X_test = concatenate X_band_test1 and test2\npredicted_test = gmodel.predict_proba(X_test, verbose=1)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","8f7d2bcf":"submission = pd.DataFrame()\nsubmission['id']=test['id']\nsubmission['is_iceberg']=predicted_test.reshape((predicted_test.shape[0]))\nsubmission.to_csv('sub.csv', index=False)","22d00cd6":"The red peak represents the shape of the ship, and depending on HH and HV, the direction seen by the radar varies slightly, but it can be seen that it eventually represents the same thing.","08de7c8a":"In conclusion, this is the code that gets an image of three channels by changing it like this. Both train data and test data were performed.","f8058873":"The images say that the radar shot from the satellite meets a specific object and bounced back, which was saved as an image.\n\nThe more solid objects (land, islands, sea ice, icebergs, ships) are said to reflect stronger rader energy, resulting in brighter images. This is called backscatter.\n\n**\"backscatter\"** is heavily influenced by the surrounding environment, and the stronger the wind around it, the brighter the image, the weaker the wind, the darker it is already, and I think the kinetic energy of many molecules in the strong wind is reflected and put on the radar.\n\nStraightening this image is a lateral surveillance radar that takes images from a certain angle. inc_angle means an angle that looks at **band_1.band_2**.\n\nIn general, the higher the **incidence angle**, the better the ocean background is.\n\n**Band_1, band_2** can be thought of as an image.","4a350df6":"* They are 5625 long and change the size to 75x75 to make images (**75x75 = 5625**) easier to learn in order to learn them, and to have [N, height, width, channel] dimensions for 2D. \n* np.newaxis makes it easy to use.","ec9173df":"# Overall workflow\n![image.png](attachment:image.png)","77936b72":"## Better way to make 3D subplot\n* Fist we make an 'plot_contour_2d' function\n* Next, choose the value in the setted function to confirm the num that we want to see ","8288741c":"### Reference\nThank you for his best lecture ever!! I made more detailed by listening his lecture! It will be really helpful for starter.\n\nCheck out 'You Han Lee' youtube and his kaggle.\nhttps:\/\/www.kaggle.com\/youhanlee\n\nhttps:\/\/www.youtube.com\/watch?v=uVoagNbaSwo&t=3s","9bdb930f":"* **batch_size** = Set how many samples to update the weight.\n\nFor example, if the batch size is 10, every 10 pieces of data is compared to the actual label value, so even if you initially predict incorrectly, you are more likely to update the weights and then fit them.Smaller batch sizes will make the learning dense, but it will take a long time throughout the process of continuing to compare with labels and updating weights.\n\n* **epochs** = Set how many iterations of the entire dataset you want to learn.\n\nRepeated learning can improve the performance of your model. However, too much repetitive learning can lead to overfitting, which increases performance for the learning set, but decreases performance for the unobserved test set. Therefore, if overfitting is likely to occur, end the learning.\n![image.png](attachment:image.png)\n\n* **Verbose** = Sets the phrase that is output during learning.\n- 0 : Outputs nothing.\n- 1: Show progress bar showing progress of training.\n- 2: Output loss information for each mini-batch.","90468e38":"* The data are given in the form of json, which is read as pd.read_json rather than as a pd.read_csv.\n* Also, this file is in 7z format so that you can open it with the code.","6686b4f6":"If you look at the shape of the data,\n\n* **id**\n* **feature**: band_1, band_2, inc_angle\n* **target**: is_iceberg -> iceberg = 1, ship = 0","5730c698":"## Model Evaluation\n* Instead of testing it right away for a better model, we evaluate the model first by dividing the existing train set into trains and valids.\n* Sklearn built-in function train_test_split makes it easy.","722ea2a2":"* This composition is a composition that builds machine learning and deep learning models that distinguish ships from glaciers with satellite images provided by them.\n* IMAGE CLASSIFICATION- BINARY CLASSIFICATION\n* You can learn a 2-D convolutional neural network (CNN) using keras.\n* keras is a famous deep learning framework that builds deep learning models easily and quickly.\n* Plotly is a library that enables interactive visulization.","daaca486":"If you look at it, there is **'na'** at the top, and you can think of it as a miss value. So I'm going to change this 'na' -> '0'\n","dae583a9":"You can now enter a number in the num section below to see what we want.\n","6880e04f":"## Make 3D surface plot ","ca553068":"Next, Recall the saved weight again to check the loss and accuracy for the validation set. (recall -> **file_path**)","665d2c60":"## Import library ","614f24bb":"## Example of image Visualization\nWe can find that the visualized shape varies depending on the **angle of incidence**. Even if it was a same picture. \n","1cf50881":"It's a little different from num = 0, but you can see other glaciers besides the peak.","9ed1bf1f":"## CNN\n![image.png](attachment:image.png)\nConvolutional Neural Networks (CNNs) learn images directly from data and classify images using patterns as useful algorithms to find patterns to analyze images. \n\nA key concept of CNN is that it can be learned while maintaining spatial information in images. Because CNN receives data in matrix form to preserve the shape of the image, it can prevent information loss that occurs in the process of vectoring the image. In other words, the underlying concept is \"let each element of a filter expressed in a row be automatically learned to suit data processing.\"\n\n","f3fab14a":"### 1. Conv2D\n : A method used a lot in image processing because it is mainly specialized in image processing.\n\ngmodel.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n\n* First factor: 64 -> The number of convolutional filters(= number of neurons connected)\n* Second factor: kernel_size = (3,3) -> (row, column) of the convolutional kernel\n* Number three factor: activation='relu' -> activation function setting, rectifier function, mainly used in the beneficial layer\n* +relu: A function that returns 0 if the value is less than 0 and returns the value if the value is greater than 0.\n* Number 4 factor: input_shpae (75, 75, 3) -> size 75\u00d775 and color photo (RGB), so channel 3, channel 1 if black and white\n\n**Relu**\n![image.png](attachment:image.png)\n* x>0 is a straight line with a slope of 1, and x<0 is a function value of 0.\n* Learning is much faster when compared to the sigmoid and tanh functions.\n* The computational cost is not significant, and the implementation is very simple.\n* For values with x <0, there is a disadvantage that neurons can die because the slope is zero.\n\n**Input Shape**\n:75 x 75, 3 = because it is a color image\n\n### 2. MaxPooling2D\ngoal->\n* Input size is reduced: the convolution layer is repeated several times, and all data that is not needed is not analyzed. By drawing out the characteristics, you're learning.\n* Overfitting: A decrease in input size can be thought of as a decrease in the number of useless parameters. Overfitting, which exhibits high performance only for training data, can be reduced.\n* Pulling out features well : When pooling, it can recognize certain shapes better.\n\n**pool_size**:Tuples of integers or two integers, reduced arguments (horizontal and vertical). (2, 2) reduces the input in half for two spatial dimensions. If only one integer is specified, the same window length applies for both dimensions.\n\n**strides**: Integer, Tuple of 2 integers, or None. The stride value. If None, the default value is pool_size.\n\n### 3. Dropout\n: Dropout is a way to solve Overfitting, one of the problems in deep learning learning. In summary, some units in the hidden layer are prevented from being overfitted by preventing them from operating.\n![image.png](attachment:image.png)\nWe can easily think dropout is a proess to making the model less intelligent.","d410bed1":"## Start Deep Learning\n* Let's start deep learning now! The dataset is ready, so you can design a neural network model.\n* Since it's an image, do it with a 2D CNN. Keras has several layers built into it that are used for deep learning, so we just need to stack them like blocks."}}