{"cell_type":{"019df708":"code","3d5de69f":"code","2b6d36f1":"code","ab2aac59":"code","9391edd1":"code","5094d564":"code","928c5e3a":"code","55c4ee77":"markdown","0dfa15be":"markdown"},"source":{"019df708":"import pickle\n\nimport pylab as pl\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nfrom random import randrange, sample","3d5de69f":"train_path = \"..\/input\/utds-cifar-10\/train\/\"\n\nBATCH_SIZE = 128\nEPOCHS = 100","2b6d36f1":"def unpickle(f):\n    with open(f, 'rb') as fo:\n        d = pickle.load(fo, encoding='bytes')\n    return d\n\ndef preprocess(image):\n    image = tf.stack([image[:1024], image[1024:2048], image[2048:3072]], axis=-1)\n    image = tf.reshape(image, (32, 32, 3))\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    \n    return image","ab2aac59":"all_images = []\nall_labels = []\n\nfor i in range(1, 6):\n    data = unpickle(train_path+f\"batch_{i}\")\n    all_images.append(data[b'data'])\n    all_labels += data[b'labels']\n    \nall_images = np.concatenate(all_images, axis=0)\nall_labels = np.reshape(all_labels, (len(all_labels), 1))\n\n# Select a portion of the training data to use for validation\nvalidation_size = int(0.2 * all_images.shape[0])\nvalidation_indices = sample(range(all_images.shape[0]), validation_size)\ntrain_indices = [i for i in range(all_images.shape[0]) if i not in validation_indices]\n\nvalidation_images = all_images[validation_indices]\nvalidation_labels = all_labels[validation_indices]\n\ntrain_images = all_images[train_indices]\ntrain_labels = all_labels[train_indices]\n\ntrain_image_count = train_images.shape[0]\n\n# Data goes in as shape (3072,), is mapped through the preprocess function, and comes out as shape (32, 32, 3)\ntrain_images = tf.data.Dataset.from_tensor_slices(train_images).map(preprocess).batch(BATCH_SIZE)\ntrain_labels = tf.data.Dataset.from_tensor_slices(train_labels).batch(BATCH_SIZE)\n\nvalidation_images = tf.data.Dataset.from_tensor_slices(validation_images).map(preprocess).batch(BATCH_SIZE)\nvalidation_labels = tf.data.Dataset.from_tensor_slices(validation_labels).batch(BATCH_SIZE)\n\ntrain_dataset = tf.data.Dataset.zip((train_images, train_labels)).repeat()\nvalidation_dataset = tf.data.Dataset.zip((validation_images, validation_labels))","9391edd1":"def get_model():\n    inp = tf.keras.Input((32, 32, 3))\n    backbone = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(32, 3, padding='same', activation='swish'),\n        tf.keras.layers.AveragePooling2D(),\n        tf.keras.layers.Conv2D(64, 3, padding='same', activation='swish'),\n        tf.keras.layers.AveragePooling2D(),\n        tf.keras.layers.Conv2D(128, 3, padding='same', activation='swish'),\n        tf.keras.layers.AveragePooling2D(),\n        tf.keras.layers.Conv2D(256, 3, padding='same', activation='swish')\n    ])\n    \n    x = backbone(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(10, activation='softmax')(x)\n    \n    return tf.keras.Model(inp, x)\n\nmodel = get_model()\nmodel.summary()","5094d564":"model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n\nmodel.fit(train_dataset, validation_data=validation_dataset, epochs=EPOCHS, steps_per_epoch=train_image_count\/\/BATCH_SIZE)","928c5e3a":"test_data = unpickle(\"..\/input\/utds-cifar-10\/test\/test_batch\")\n\ntest_images = test_data[b'data']\ntest_images = tf.data.Dataset.from_tensor_slices(test_images).map(preprocess).batch(1024)\n\npredictions = model.predict(test_images)\npredictions = tf.math.argmax(predictions, axis=1).numpy()\n\nsubmission = pd.DataFrame.from_dict({ 'Id': list(range(test_data[b'data'].shape[0])), 'Predicted': list(predictions) })\nsubmission.to_csv(\"submission.csv\", index=False)\n\nprint(submission)","55c4ee77":"# Dataset and preprocessing\n\nFrom the CIFAR-10 page:\n\n> Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image. \n\nMeaning that an unpickled data object will have shape 10000x3072, with 10000 images of 3072 pixels (32x32x3 == 3072)","0dfa15be":"# Model Definition\n\nIn this notebook we're using a basic sequential CNN and the Keras Functional API."}}