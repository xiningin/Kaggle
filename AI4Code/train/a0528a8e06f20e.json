{"cell_type":{"ebd379ed":"code","ed9d38b7":"code","1c24210d":"code","66306066":"code","cb338259":"code","0f89ed6f":"code","291d6a29":"code","849cb819":"code","68612ece":"code","fbb2497a":"code","6f671a7b":"code","776bbc21":"code","ed4e882b":"code","fc1e8602":"code","8d122a66":"code","6ef5a99d":"code","03011932":"code","6cd9e54f":"code","a311f735":"code","421da54b":"code","313aa39e":"code","1d60d658":"code","6e415ee1":"code","64ee807c":"code","7e5f2a24":"code","9f85f824":"code","4914d43c":"code","66341500":"code","419c005e":"code","42e3bd4c":"code","af006a47":"code","11f5d678":"code","b36bc35b":"code","344e947f":"code","f5b53800":"code","86e77fea":"code","3ae4b27f":"code","1c1c56fd":"code","52190136":"code","1fd94790":"code","2d48cdc7":"code","7371e05b":"code","db17ec73":"code","f034320c":"code","59757049":"code","59f3eaba":"code","17641d34":"code","d1ea764d":"code","36e67397":"code","79ea34b5":"code","975df5a8":"code","5ed98bda":"code","d7f383ef":"code","49ac1046":"code","f2c64850":"code","30039848":"code","5e00df31":"code","692bfe66":"code","bbf31439":"code","a098f1e2":"code","9d083b69":"code","822496a0":"code","7e2efcd6":"code","6f35ecd5":"code","1c37f8b2":"code","588e3801":"code","a5614fbb":"code","dd53eee1":"code","aea0014d":"code","3a9bf26b":"code","7eadabfb":"code","39b5091c":"code","fdc420b8":"code","aec7a1f2":"code","1fb7b2b1":"code","33814ced":"code","2464a173":"code","61a4214b":"code","5cc27a3b":"code","36025a79":"code","917c453a":"code","db923b3b":"code","30b82276":"code","895be941":"code","d7355b81":"code","e52b5a2b":"code","2d7e1d5e":"code","4f1f0089":"code","746ca63c":"code","de255e8b":"code","423d0a9c":"code","0188aff0":"code","5d051ba1":"code","6aec701c":"code","8795211b":"code","e18d0ac6":"code","3f222e1f":"code","61263086":"code","52a0247c":"code","d71c93dd":"code","0b544b58":"code","d142188b":"code","1638acc1":"code","338c16b8":"code","6b43c4d6":"code","0ab9048c":"code","356d1c9a":"code","5186826f":"code","fc5ea5a7":"code","c8263a8b":"code","ca010c21":"code","ca90eb3a":"code","c3607f62":"code","8555bbb5":"code","eb91ad36":"code","8447b9b4":"code","cd4495e3":"code","cba7001f":"code","dc55fcbe":"code","de7eb489":"code","3d3e07df":"code","7e0d37b4":"code","a89fd66f":"code","69847cc6":"code","44c792bf":"code","8420450a":"code","493b2984":"code","cf1d4995":"code","d4098d6e":"code","00e94ad5":"code","9098b539":"code","68fbd714":"code","4d4fe662":"code","cd017607":"code","b9fe68c6":"code","00aee396":"code","1d196c79":"code","ce5824b7":"code","aa6f2daf":"code","40f88097":"code","2493f3cd":"code","56553366":"code","7f1b9d02":"code","0cc83a58":"code","4ebc406d":"code","2a1e876b":"code","3fa5c9e2":"code","ad690680":"code","78e40978":"code","c2aa73ff":"code","27626671":"code","d0755b81":"code","cf40a276":"code","018dbb86":"code","6bfe3d0a":"code","b124af0a":"code","71646355":"code","52ffb947":"code","6c9ad485":"code","cc14664c":"code","deb69833":"code","a11b1865":"code","8eda5f84":"code","c431c5d4":"code","f8561855":"code","0c3cbcf3":"code","4d0a67e9":"code","acbcbe62":"code","f6864680":"code","d4d238d6":"code","9a8a7c4d":"code","4ea4d466":"code","bff531c5":"code","ffa06244":"code","575483d5":"code","b3c78d98":"code","32d3785b":"code","7ff40040":"code","f2429762":"code","b1dfa1dc":"code","627a8865":"code","0b026274":"code","e68ac011":"code","65a9ec40":"code","4cfb5716":"code","8da82000":"code","78f04899":"code","aaca2ea7":"code","c3eddb74":"code","00d4f4e2":"code","a5b47dad":"code","5a5ebc21":"code","5d71735b":"code","5b7b37df":"code","25809750":"code","aa11f7a4":"code","04d819f3":"code","5064a2e7":"code","4296acd3":"code","cf42f29e":"code","db649fdc":"code","9f7418aa":"code","5ce6b105":"code","73b78d98":"code","6850f07c":"code","74e303de":"code","0a8b10dd":"code","e63a1f77":"code","d293ac02":"code","b05df829":"code","9782d254":"code","fad8feda":"code","2ca55334":"code","01eb7eb1":"code","61aa59c7":"code","b9a35ca0":"code","7f02ba76":"code","d16ca6bf":"code","a9c4f21f":"code","db04ea24":"code","87705251":"code","44158838":"code","0dc18520":"code","96ac5436":"code","07f84406":"code","874acc54":"code","fc45edba":"code","37d63154":"code","53e36e46":"code","fbc6bf28":"code","b0f21075":"code","ca1e836c":"code","228c657a":"code","07c37ef0":"code","8d125005":"code","f17fe444":"code","3d229425":"code","84ca1a9f":"code","c7c92ea6":"markdown","4f6165a9":"markdown","4693ba2d":"markdown","7d2c09ad":"markdown","58535b66":"markdown","6423a137":"markdown","a26e1728":"markdown","0fa15365":"markdown","786d257f":"markdown","60b1a6a1":"markdown","5d9d865e":"markdown","bf72275b":"markdown","5fe5bd31":"markdown","4adeb23b":"markdown","c03a53b5":"markdown","4eccdb5d":"markdown","2cee9a61":"markdown","3e1236b5":"markdown","70fd1c9d":"markdown","dfd0a335":"markdown","22e57c1f":"markdown","6ef51f39":"markdown","7a83504c":"markdown","da5423af":"markdown","525ef734":"markdown","4a46ffe8":"markdown","e5bef3f2":"markdown","e364e72c":"markdown","0637d4ab":"markdown","2bc8ef48":"markdown","a943a1eb":"markdown","6bcd5fe4":"markdown","cd97e90a":"markdown","c0fad23e":"markdown","c85b0599":"markdown","c6a7dbf0":"markdown","0ec89faa":"markdown","2e24f987":"markdown","3413f368":"markdown","91be52ff":"markdown","eb1e638b":"markdown","03032427":"markdown","01b94b43":"markdown","87edbdb9":"markdown"},"source":{"ebd379ed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport json\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ed9d38b7":"# Membaca data bisnis\nbiz=pd.read_csv('\/kaggle\/input\/yelpversion6\/yelp_business.csv')\nbiz.head()","1c24210d":"biz.shape","66306066":"#memisahkan masing-masing kategori ke kolom berbeda\ndf_category_split = biz['categories'].str.split(';', expand=True)[[0,1,2]]\n\n# nama kolom yang baru\ndf_category_split.columns = ['category_1', 'category_2', 'category_3']\nbiz = pd.concat([biz, df_category_split], axis=1)\n\n# menghapus kolom lama 'categories'\nbiz = biz.drop(['categories'], axis=1)","cb338259":"biz.head()","0f89ed6f":"# Filter dataset, 'kategori: Restaurants, 'state': PA, dan 'is_open' : 1\nresto = biz.loc[(biz['category_1'] == 'Restaurants') | (biz['category_2'] == 'Restaurants') | (biz['category_3'] == 'Restaurants')]\nresto = resto.loc[(resto['state'] == 'PA')]\nresto = resto.loc[(resto['is_open'] == 1)]\nprint(resto.shape)\n","291d6a29":"#menghapus variabel yang tidak digunakan dan garbage collection\ndel biz\n\nimport gc\ngc.collect()\n","849cb819":"resto.head()","68612ece":"#menghapus kolom yang tidak digunakan\nresto=resto.drop(['name', 'neighborhood', 'address', 'city', 'state',\n       'postal_code', 'latitude', 'longitude','is_open', 'category_1', 'category_2', 'category_3'],axis=1)\nresto.reset_index(drop=True, inplace=True)","fbb2497a":"print(resto.info())\nresto.head()","6f671a7b":"# Membaca data user\nuser=pd.read_csv('\/kaggle\/input\/yelpversion6\/yelp_user.csv')\nuser.head()\n","776bbc21":"print(user.shape)","ed4e882b":"## Filter dataset\n\n# Menghapus kolom 'name'\nuser=user.drop('name',axis=1)\n\n# Memilih data user yang review_count nya >0\nuser = user.loc[(user['review_count'] > 0)]\nprint(user.shape)","fc1e8602":"print(user.info())\nuser.head()","8d122a66":"# Membaca data review\nreviews=pd.read_csv('yelp_review.csv')\nreviews.head()","6ef5a99d":"print(reviews.shape)\nreviews.columns","03011932":"reviews=reviews.drop('text',axis=1)","6cd9e54f":"#join resto dan reviews\nyelp_join=pd.merge(resto,reviews,on='business_id',how='inner')\n\n#join resto, reviews dengan user\nyelp_join=pd.merge(yelp_join,user,on='user_id',how='inner')\nprint(yelp_join.shape)\nyelp_join.head()","a311f735":"#menghapus variabel yang tidak digunakan dan garbage collection\ndel resto\ndel reviews\ndel user\n\nimport gc\ngc.collect()\n","421da54b":"yelp_join.head()","313aa39e":"print(yelp_join.dtypes)\n\n#tipe data datetime\nyelp_join['date']=pd.to_datetime(yelp_join['date'])\nyelp_join['yelping_since']=pd.to_datetime(yelp_join['yelping_since'])","1d60d658":"#indexing id to number for simplicity\nbizID = pd.Categorical((pd.factorize(yelp_join.business_id)[0] + 1))\nuserID = pd.Categorical((pd.factorize(yelp_join.user_id)[0] + 1))\nreviewID = pd.Categorical((pd.factorize(yelp_join.review_id)[0] + 1))\n\nbizID=bizID.astype(int)\nuserID=userID.astype(int)\nreviewID=reviewID.astype(int)\n\nyelp_join['business_id']=bizID\nyelp_join['user_id']=userID\nyelp_join['review_id']=reviewID","6e415ee1":"## Filter dataset\n# Menghapus  incosistency: review date < yelping since\nyelp_join = yelp_join.loc[((yelp_join['date'] > yelp_join['yelping_since']) == True)]\nprint(yelp_join.shape)","64ee807c":"print(yelp_join.shape)\nyelp_join.head()","7e5f2a24":"print(yelp_join.business_id.nunique())\nprint(yelp_join.user_id.nunique())","9f85f824":"yelp_join['user_id'].value_counts()","4914d43c":"yelp_join['business_id'].value_counts()","66341500":"min_resto_ratings = 1\nfilter_resto = yelp_join['business_id'].value_counts() > 1\nfilter_resto = filter_resto[filter_resto].index.tolist()\n\nmin_user_ratings = 1\nfilter_users = df_new['user_id'].value_counts() > min_user_ratings\nfilter_users = filter_users[filter_users].index.tolist()\n","419c005e":"df_new = yelp_join[(yelp_join['business_id'].isin(filter_resto)) & (yelp_join['user_id'].isin(filter_users))]\nprint('The original data frame shape:\\t{}'.format(yelp_join.shape))\nprint('The new data frame shape:\\t{}'.format(df_new.shape))","42e3bd4c":"print(yelp_join.business_id.nunique())\nprint(yelp_join.user_id.nunique())","af006a47":"yelp_join.head()","11f5d678":"cf=yelp_join","b36bc35b":"print(yelp_join.shape)\nyelp_join.columns","344e947f":"#drop unused columns\n#cf = cf.drop(['business_id'], axis=1)\ncf = cf.drop(['stars_x'], axis=1)\ncf = cf.drop(['review_count_x'], axis=1)\n#cf = cf.drop(['review_id'], axis=1)\n#cf = cf.drop(['user_id'], axis=1)\ncf = cf.drop(['date'], axis=1)\ncf = cf.drop(['useful_x'], axis=1)\ncf = cf.drop(['funny_x'], axis=1)\ncf = cf.drop(['cool_x'], axis=1)\ncf = cf.drop(['review_count_y'], axis=1)\ncf = cf.drop(['yelping_since'], axis=1)\ncf = cf.drop(['friends'], axis=1)\ncf = cf.drop(['cool_y'], axis=1)\ncf = cf.drop(['useful_y'], axis=1)\ncf = cf.drop(['funny_y'], axis=1)\ncf = cf.drop(['fans'], axis=1)\ncf = cf.drop(['elite'], axis=1)\ncf = cf.drop(['average_stars'], axis=1)\ncf = cf.drop(['compliment_hot'], axis=1)\ncf = cf.drop(['compliment_more'], axis=1)\ncf = cf.drop(['compliment_profile'], axis=1)\ncf = cf.drop(['compliment_cute'], axis=1)\ncf = cf.drop(['compliment_list'], axis=1)\ncf = cf.drop(['compliment_note'], axis=1)\ncf = cf.drop(['compliment_plain'], axis=1)\ncf = cf.drop(['compliment_cool'], axis=1)\ncf = cf.drop(['compliment_funny'], axis=1)\ncf = cf.drop(['compliment_writer'], axis=1)\ncf = cf.drop(['compliment_photos'], axis=1)\ncf.columns","f5b53800":"cf.to_csv('collaborative.csv')","86e77fea":"import matplotlib.pyplot as plt","3ae4b27f":"print(yelp_join.shape)\nyelp_join.head()\nyelp_join.dtypes","1c1c56fd":"yelp_join=predictor","52190136":"stars=yelp_join['rating'].value_counts()\nstars=stars.to_frame().reset_index()\nstars.columns=['rating','count']\nprint(stars)\nstars.sort_values(by=['rating'],ascending=True).plot.bar(x='rating',y='count')","1fd94790":"yr=yelp_join.groupby('yelping_since')[['user_id']].count()\nyr","2d48cdc7":"# df is defined in the previous example\n\n# step 1: create a 'year' column\nyelp_join['year_of_yelping'] = yelp_join['yelping_since'].map(lambda x: x.strftime('%Y'))\n\n# step 2: group by the created columns\ngrouped_df = yelp_join.groupby('year_of_yelping')[['user_id']].count()\n\ngrouped_df\n","7371e05b":"yr=grouped_df.reset_index()\nyr","db17ec73":"yr.plot.bar(x='year_of_yelping',y='user_id')","f034320c":"yr=yelp_join.groupby('date')[['review_id']].count()\nyr","59757049":"# df is defined in the previous example\n\n# step 1: create a 'year' column\nyelp_join['year_of_review'] = yelp_join['date'].map(lambda x: x.strftime('%Y'))\n\n# step 2: group by the created columns\ngrouped_df = yelp_join.groupby('year_of_review')[['review_id']].count()\n\ngrouped_df\n","59f3eaba":"yr=grouped_df.reset_index()\nyr","17641d34":"yr.plot.bar(x='year_of_review',y='review_id')","d1ea764d":"us=yelp_join.groupby('user_id')[['business_id']].count()\nus","36e67397":"us=yelp_join.groupby('user_id')[['review_id']].count()\nus","79ea34b5":"yelp_join.shape","975df5a8":"# Only the last 3 years\n#yelp_join=yelp_join.loc[(yelp_join['date'] >= '2005-10-01')]\nsdfsd=yelp_join.loc[(yelp_join['date'] >= '2005-10-01')]\n#yelp_join.shape","5ed98bda":"#x=yelp_join.loc[(yelp_join['date'] >= '2015-01-01')]\n#x=x.loc[(x['yelping_since'] <'2015-02-01')]\nprint(sdfsd['date'].sort_values(ascending=True))","d7f383ef":"yelp_join=yelp_join.loc[(yelp_join['date'] < '2015-01-01')]\nyelp_join.shape","49ac1046":"yelp_join.shape","f2c64850":"print(yelp_join.business_id.nunique())\nprint(yelp_join.user_id.nunique())","30039848":"#x=yelp_join.loc[(yelp_join['yelping_since'] >= '2015-01-01')]\nx=yelp_join.loc[(yelp_join['yelping_since'] <'2015-01-01')]\nprint(x['yelping_since'].sort_values(ascending=True))\nprint(x.shape)","5e00df31":"yelp_join=yelp_join.loc[(yelp_join['yelping_since'] < '2015-02-01')]\nyelp_join.shape","692bfe66":"print(yelp_join['yelping_since'].sort_values(ascending=False))","bbf31439":"yelp_join['no_friends']=0\nyelp_join.loc[yelp_join['friends'] == 'None', ['no_friends']] = 1","a098f1e2":"yelp_join","9d083b69":"yelp_join.shape","822496a0":"yelp_join['year_of_yelping']=yelp_join['year_of_yelping'].astype(int)\nyelp_join['year_of_review']=yelp_join['year_of_review'].astype(int)\nyelp_join.dtypes","7e2efcd6":"#Check check\n\n#check recent date\nprint(yelp_join[['date','yelping_since','review_id']].sort_values(by='date',ascending=False).head())\n#print(yelp_join['date'].loc[yelp_join['index']==29524])","6f35ecd5":"from datetime import datetime\n\nd_base = datetime(2015, 1, 1)\nprint(d_base)","1c37f8b2":"print(yelp_join['date'].loc[yelp_join['review_id']==53024])\ndays=(d_base-(yelp_join['date'].loc[yelp_join['review_id']==53024]))\nprint(days)","588e3801":"yelp_join.shape","a5614fbb":"yelp_join.columns","dd53eee1":"#derive columns\ndf = pd.DataFrame([])\nfor index, row in yelp_join.iterrows():\n    #total friends\n    number=row['friends'].count(\",\")+1\n    #days been yelping since\n    days=(d_base-row['yelping_since']).days\n    #total compliments\n    compnum=row['compliment_hot']+row['compliment_more']+row['compliment_cute']+row['compliment_note']+row['compliment_cool']+row['compliment_funny']+row['compliment_writer']+row['compliment_photos']\n    #total votes per user\n    votes=row['funny_y']+row['useful_y']+row['cool_y']\n    #review age\n    age=(d_base-row['date']).days\n    print(days)\n    df = df.append(pd.Series([row['review_id'],row['no_friends'],number,compnum,days,age,votes]),ignore_index=True)\n    \ndf.columns=['review_id','no_friends','total_friends','total_compliments','days_since','review_age','total_votes']\ndf.shape\n","aea0014d":"df.head()","3a9bf26b":"df.shape","7eadabfb":"df.loc[df['no_friends'] == 1, ['total_friends']] = 0\ndf = df.drop(['no_friends'], axis=1)","39b5091c":"yelp_join=pd.merge(yelp_join,df,on='review_id',how='inner')\nyelp_join.shape","fdc420b8":"yelp_join.head()","aec7a1f2":"print(yelp_join[['date','review_age','review_id']].sort_values(by='date',ascending=False).head())\nprint(yelp_join[['yelping_since','days_since','review_id']].sort_values(by='yelping_since',ascending=False).head())","1fb7b2b1":"yelp_join=yelp_join.rename(columns={\"stars_x\": \"biz_avg_rating\",\n                          \"review_count_x\": \"biz_total_rvw\",\n                          \"stars_y\": \"rating\",\n                          \"useful_x\": \"review_useful\",\n                          \"funny_x\": \"review_funny\",\n                          \"cool_x\": \"review_cool\",\n                          \"review_count_y\": \"user_total_rvw\",\n                          \"average_stars\" : \"user_avg_rating\",\n                         })","33814ced":"yelp_join['elite']","2464a173":"z=yelp_join.describe()\nz\nz.to_csv('descriptive-stats.csv')\n#2019-07-27 17:36","61a4214b":"skew=yelp_join.skew(axis=0,numeric_only=True)\nskew.to_csv('skew.csv')\n#2019-07-27 17:36","5cc27a3b":"#export data to master file\nyelp_join.to_csv('yelp_join_added_columns.csv')\n#2019-07-27 17:36","36025a79":"yelp_join.head()","917c453a":"#Read data from file\nyelp_join=pd.read_csv('yelp_join_added_columns.csv',index_col=0)\nyelp_join.head()","db923b3b":"yelp_join.business_id.nunique()","30b82276":"#for recent-ness column of item\nbizpopularity=yelp_join.groupby('business_id')[['review_age']].mean()\nbizpopularity","895be941":"yelp_join=pd.merge(yelp_join,bizpopularity,on='business_id',how='inner')\nyelp_join.head()\nyelp_join.shape","d7355b81":"yelp_join.columns","e52b5a2b":"#review metadata columns for user feature\nuserreview=yelp_join[['review_id','user_id','review_useful','review_funny','review_cool','user_total_rvw']]\n#c=userreview.groupby('user_id')[['cool_y','funny_y','useful_y','review_count_y']].mean()","2d7e1d5e":"userreview.sort_values(by='user_id')","4f1f0089":"yelp_join.business_id.nunique()","746ca63c":"c=userreview.groupby('user_id').agg({'review_useful' : 'sum','review_funny' : 'sum','review_cool' : 'sum'})\nc","de255e8b":"yelp_join=pd.merge(yelp_join,c,on='user_id',how='inner')\nyelp_join.head()\nyelp_join.shape","423d0a9c":"yelp_join.columns\nyelp_join.shape","0188aff0":"yelp_join.columns","5d051ba1":"print(yelp_join.shape)\nprint(yelp_join.business_id.nunique())\nprint(yelp_join.user_id.nunique())","6aec701c":"yelp_join.groupby(['business_id','user_id']).size()\n","8795211b":"#export\nyelp_join.to_csv('resto_full.csv')\n#2019-07-27 18:36","e18d0ac6":"#import\nimport pandas as pd\nyelp_join=pd.read_csv('resto_full.csv',index_col=0)","3f222e1f":"yelp_join.columns","61263086":"yelp_join.shape","52a0247c":"z=yelp_join.groupby('user_id').agg({'review_id' : 'count'})\nz=z.sort_values(by='review_id',ascending=True)\nz","d71c93dd":"z.to_csv('user-review-count.csv')","0b544b58":"z.describe()","d142188b":"##Split test user, top 10%\nfrom sklearn.model_selection import train_test_split\nuser_train, user_test = train_test_split(z,test_size=0.1,shuffle=False)","1638acc1":"user_test=user_test.reset_index()","338c16b8":"user_test.sort_values(by='user_id',ascending=True)","6b43c4d6":"yelp_join.shape","0ab9048c":"forsample = yelp_join[(yelp_join['user_id'].isin(user_test['user_id']))]\nforsample.shape","356d1c9a":"forsample.head()","5186826f":"#get 20% from the whole dataset\ntrain, test = train_test_split(forsample,test_size=0.425,shuffle=True)","fc5ea5a7":"test","c8263a8b":"test.to_csv('test_dataset.csv')","ca010c21":"yelp_join.shape","ca90eb3a":"print(yelp_join.user_id.nunique())\nprint(yelp_join.business_id.nunique())","c3607f62":"train = yelp_join[(~yelp_join['review_id'].isin(test['review_id']))]\ntrain","8555bbb5":"#for training the neural network model\ntrain.to_csv('train_dataset.csv')","eb91ad36":"yelp_join.business_id.nunique()","8447b9b4":"print(yelp_join.user_id.nunique())\nprint(yelp_join.business_id.nunique())","cd4495e3":"print(train.user_id.nunique())\nprint(train.business_id.nunique())","cba7001f":"#import\nimport pandas as pd\nyelp_join=pd.read_csv('resto_full.csv',index_col=0)\ntrain=pd.read_csv('train_dataset.csv',index_col=0)\ntest=pd.read_csv('test_dataset.csv',index_col=0)","dc55fcbe":"train.shape","de7eb489":"train.sha","3d3e07df":"train['rating'].hist()","7e0d37b4":"test.shape","a89fd66f":"test['rating'].hist()","69847cc6":"print(yelp_join.shape)\nprint(train.shape)\nprint(test.shape)","44c792bf":"yelp_join.user_id.nunique()","8420450a":"nuser=yelp_join.user_id.unique()\nnuser","493b2984":"userset = pd.DataFrame({'user_id':nuser[:]})","cf1d4995":"userset","d4098d6e":"nbiz=yelp_join.business_id.unique()\nnbiz","00e94ad5":"bizset = pd.DataFrame({'business_id':nbiz[:]})","9098b539":"bizset","68fbd714":"userset['key'] = 0\nbizset['key'] = 0\n\ndf_cartesian = userset.merge(bizset,on='key',how='outer')\ndf_cartesian = df_cartesian.drop(columns=['key'])\ndf_cartesian","4d4fe662":"iddata=train[['user_id','business_id']]\niddata","cd017607":"df_1_2 = df_cartesian.merge(iddata,on=['user_id','business_id'], how='left',indicator=True)\ndf_1_not_2 = df_1_2[df_1_2[\"_merge\"] == \"left_only\"].drop(columns=[\"_merge\"])\ndf_1_not_2","b9fe68c6":"iddata=test[['user_id','business_id']]\niddata","00aee396":"df_1_2 = df_1_not_2.merge(iddata,on=['user_id','business_id'], how='left',indicator=True)\ndf_final = df_1_2[df_1_2[\"_merge\"] == \"left_only\"].drop(columns=[\"_merge\"])\ndf_final","1d196c79":"bizf=yelp_join[['business_id','biz_avg_rating','biz_total_rvw','review_age_y']]\nbizf.sort_values(by='business_id')\nbizf=bizf.drop_duplicates()\nbizf","ce5824b7":"df_final= df_final.merge(bizf,on='business_id', how='left')\ndf_final","aa6f2daf":"userf=yelp_join[['user_id','fans','user_total_rvw','user_avg_rating','days_since','total_friends','total_compliments','total_votes','review_useful_y', 'review_funny_y', 'review_cool_y']]\nuserf.sort_values(by='user_id')\nuserf=userf.drop_duplicates()\nuserf","40f88097":"df_final= df_final.merge(userf,on='user_id', how='left')\ndf_final.head()","2493f3cd":"df_final.sort_values(by='user_id')","56553366":"df_final.to_csv('full-mat-predict.csv')","7f1b9d02":"import pandas as pd","0cc83a58":"df_final=pd.read_csv('full-mat-predict.csv')","4ebc406d":"df_final.shape","2a1e876b":"df_final=df_final.drop('Unnamed: 0',axis=1)","3fa5c9e2":"df_final.head()","ad690680":"yelp_join.columns","78e40978":"predictor=yelp_join[['rating','biz_avg_rating', 'biz_total_rvw',\n       'review_age_y', 'fans', 'user_total_rvw', 'user_avg_rating',\n       'days_since', 'total_friends', 'total_compliments', 'total_votes',\n       'review_useful_y', 'review_funny_y', 'review_cool_y']]\npredictor.shape","c2aa73ff":"predictor.columns","27626671":"predictor.shape","d0755b81":"import pandas as pd\nimport numpy as np\n\nrs = np.random.RandomState(0)\ncorr = predictor.corr()\ncorr.style.background_gradient(cmap='coolwarm')\n# 'RdBu_r' & 'BrBG' are other good diverging colormaps","cf40a276":"import pandas as pd\nimport numpy as np\n\nrs = np.random.RandomState(0)\ncorr = predictor.corr()\ncorr.style.background_gradient(cmap='coolwarm')\n# 'RdBu_r' & 'BrBG' are other good diverging colormaps","018dbb86":"descdata=predictor.describe()\ndescdata.to_csv('predictor-descriptive.csv')","6bfe3d0a":"rating=predictor['rating']\npred = predictor.drop(['rating'], axis=1)\n\n#export\npred.to_csv('predictor-new.csv')\nrating.to_csv('target-new.csv',header=False)","b124af0a":"import pandas as pd","71646355":"#import\nx=pd.read_csv('predictor-new.csv',index_col=0)\ny=pd.read_csv('target-new.csv',index_col=0,header=None)","52ffb947":"print(x.shape)\nx.head()","6c9ad485":"print(y.shape)\ny.head()","cc14664c":"df_final.columns","deb69833":"df_final.shape","a11b1865":"x","8eda5f84":"fullmatpred=df_final[['biz_avg_rating', 'biz_total_rvw',\n       'review_age_y', 'fans', 'user_total_rvw', 'user_avg_rating',\n       'days_since', 'total_friends', 'total_compliments', 'total_votes',\n       'review_useful_y', 'review_funny_y', 'review_cool_y']]","c431c5d4":"test=test[['biz_avg_rating', 'biz_total_rvw',\n       'review_age_y', 'fans', 'user_total_rvw', 'user_avg_rating',\n       'days_since', 'total_friends', 'total_compliments', 'total_votes',\n       'review_useful_y', 'review_funny_y', 'review_cool_y','rating']]","f8561855":"test","0c3cbcf3":"x_test=test[['biz_avg_rating', 'biz_total_rvw', 'review_age_y', 'fans',\n       'user_total_rvw', 'user_avg_rating', 'days_since', 'total_friends',\n       'total_compliments', 'total_votes', 'review_useful_y', 'review_funny_y',\n       'review_cool_y']]","4d0a67e9":"y_test=test[['rating']]","acbcbe62":"x_test","f6864680":"print(train.shape)\nprint(test.shape)","d4d238d6":"train.describe().to_csv('train-describe.csv')","9a8a7c4d":"test.describe().to_csv('test-describe.csv')","4ea4d466":"#encode target to 5 columns\n# import preprocessing from sklearn\nfrom sklearn import preprocessing\nfrom tensorflow.python import keras\nenc = preprocessing.LabelEncoder()\n\n# 2. FIT\nenc.fit(y)\n\n# 3. Transform\nlabels = enc.transform(y)\nlabels.shape\ny=keras.utils.to_categorical(labels)\n# as you can see, you've the same number of rows 891\n# but now you've so many more columns due to how we changed all the categorical data into numerical data\n\n","bff531c5":"#encode target to 5 columns\n# import preprocessing from sklearn\nfrom sklearn import preprocessing\nfrom tensorflow.python import keras\nenc = preprocessing.LabelEncoder()\n\n# 2. FIT\nenc.fit(y_test)\n\n# 3. Transform\nlabels = enc.transform(y_test)\nlabels.shape\ny_test=keras.utils.to_categorical(labels)\n# as you can see, you've the same number of rows 891\n# but now you've so many more columns due to how we changed all the categorical data into numerical data\n\n","ffa06244":"y.shape","575483d5":"y_test.shape","b3c78d98":"x.shape","32d3785b":"##handling outliers\nimport numpy as np\nimport numpy.ma as ma\nfrom scipy.stats import mstats\n\nlow = .05\nhigh = .95\nquant_df = x.quantile([low, high])\nprint(quant_df)","7ff40040":"quant_df.head()","f2429762":"##handling outliers\n\n# Winsorizing\nx['biz_avg_rating']=mstats.winsorize(x['biz_avg_rating'], limits=[0.05, 0.05])\nx['biz_total_rvw']=mstats.winsorize(x['biz_total_rvw'], limits=[0.05, 0.05])\nx['review_age_y']=mstats.winsorize(x['review_age_y'], limits=[0.05, 0.05])\nx['fans']=mstats.winsorize(x['fans'], limits=[0.05, 0.05])\nx['user_total_rvw']=mstats.winsorize(x['user_total_rvw'], limits=[0.05, 0.05])\nx['user_avg_rating']=mstats.winsorize(x['user_avg_rating'], limits=[0.05, 0.05])\nx['days_since']=mstats.winsorize(x['days_since'], limits=[0.05, 0.05])\nx['total_friends']=mstats.winsorize(x['total_friends'], limits=[0.05, 0.05])\nx['total_compliments']=mstats.winsorize(x['total_compliments'], limits=[0.05, 0.05])\nx['total_votes']=mstats.winsorize(x['total_votes'], limits=[0.05, 0.05])\nx['review_useful_y']=mstats.winsorize(x['review_useful_y'], limits=[0.05, 0.05])\nx['review_funny_y']=mstats.winsorize(x['review_funny_y'], limits=[0.05, 0.05])\nx['review_cool_y']=mstats.winsorize(x['review_cool_y'], limits=[0.05, 0.05])","b1dfa1dc":"quant_df.head()","627a8865":"fullmatpred.loc[fullmatpred['biz_avg_rating'] < 2.5, 'biz_avg_rating'] = 2.5\nfullmatpred.loc[fullmatpred['biz_avg_rating'] > 4.5, 'biz_avg_rating'] = 4.5\nfullmatpred.loc[fullmatpred['biz_total_rvw'] < 15, 'biz_total_rvw'] = 15\nfullmatpred.loc[fullmatpred['biz_total_rvw'] > 561, 'biz_total_rvw'] = 561\nfullmatpred.loc[fullmatpred['review_age_y'] < 255, 'review_age_y'] = 255\nfullmatpred.loc[fullmatpred['review_age_y'] > 1177, 'review_age_y'] = 1178\nfullmatpred.loc[fullmatpred['fans'] < 0, 'fans'] = 0\nfullmatpred.loc[fullmatpred['fans'] > 76, 'fans'] = 76\nfullmatpred.loc[fullmatpred['user_total_rvw'] < 6, 'user_total_rvw'] = 6\nfullmatpred.loc[fullmatpred['user_total_rvw'] > 862, 'user_total_rvw'] = 862\nfullmatpred.loc[fullmatpred['user_avg_rating'] < 2.88, 'user_avg_rating'] = 2.88\nfullmatpred.loc[fullmatpred['user_avg_rating'] > 4.43, 'user_avg_rating'] = 4.43\nfullmatpred.loc[fullmatpred['days_since'] < 281, 'days_since'] = 281\nfullmatpred.loc[fullmatpred['days_since'] > 2667, 'days_since'] = 2667\nfullmatpred.loc[fullmatpred['total_friends'] < 0 , 'total_friends'] = 0\nfullmatpred.loc[fullmatpred['total_friends'] > 589 , 'total_friends'] = 589\nfullmatpred.loc[fullmatpred['total_compliments'] < 0 , 'total_compliments'] = 0\nfullmatpred.loc[fullmatpred['total_compliments'] > 966 , 'total_compliments'] = 676\nfullmatpred.loc[fullmatpred['total_votes'] < 0 , 'total_votes'] = 0\nfullmatpred.loc[fullmatpred['total_votes'] > 4728 , 'total_votes'] = 4728\nfullmatpred.loc[fullmatpred['review_useful_y'] > 201 , 'review_useful_y'] = 201\nfullmatpred.loc[fullmatpred['review_funny_y'] > 78 , 'review_funny_y'] = 78\nfullmatpred.loc[fullmatpred['review_cool_y'] > 78 , 'review_cool_y'] = 78\n","0b026274":"x_test.loc[x_test['biz_avg_rating'] < 2.5, 'biz_avg_rating'] = 2.5\nx_test.loc[x_test['biz_avg_rating'] > 4.5, 'biz_avg_rating'] = 4.5\nx_test.loc[x_test['biz_total_rvw'] < 15, 'biz_total_rvw'] = 15\nx_test.loc[x_test['biz_total_rvw'] > 561, 'biz_total_rvw'] = 561\nx_test.loc[x_test['review_age_y'] < 255, 'review_age_y'] = 255\nx_test.loc[x_test['review_age_y'] > 1177, 'review_age_y'] = 1178\nx_test.loc[x_test['fans'] < 0, 'fans'] = 0\nx_test.loc[x_test['fans'] > 76, 'fans'] = 76\nx_test.loc[x_test['user_total_rvw'] < 6, 'user_total_rvw'] = 6\nx_test.loc[x_test['user_total_rvw'] > 862, 'user_total_rvw'] = 862\nx_test.loc[x_test['user_avg_rating'] < 2.88, 'user_avg_rating'] = 2.88\nx_test.loc[x_test['user_avg_rating'] > 4.43, 'user_avg_rating'] = 4.43\nx_test.loc[x_test['days_since'] < 281, 'days_since'] = 281\nx_test.loc[x_test['days_since'] > 2667, 'days_since'] = 2667\nx_test.loc[x_test['total_friends'] < 0 , 'total_friends'] = 0\nx_test.loc[x_test['total_friends'] > 589 , 'total_friends'] = 589\nx_test.loc[x_test['total_compliments'] < 0 , 'total_compliments'] = 0\nx_test.loc[x_test['total_compliments'] > 966 , 'total_compliments'] = 676\nx_test.loc[x_test['total_votes'] < 0 , 'total_votes'] = 0\nx_test.loc[x_test['total_votes'] > 4728 , 'total_votes'] = 4728\nx_test.loc[x_test['review_useful_y'] > 201 , 'review_useful_y'] = 201\nx_test.loc[x_test['review_funny_y'] > 78 , 'review_funny_y'] = 78\nx_test.loc[x_test['review_cool_y'] > 78 , 'review_cool_y'] = 78\n","e68ac011":"x.shape","65a9ec40":"fullmatpred.shape","4cfb5716":"#Normalization\nfrom sklearn.preprocessing import MinMaxScaler\n#Normalize data\nscaler = MinMaxScaler()\n# Fit only to the training data\nx = scaler.fit_transform(x)\n# Now apply the transformations to the data:\n#x_test= scaler.transform(x_test)","8da82000":"fullmatpred","78f04899":"fullmatpred= scaler.transform(fullmatpred)","aaca2ea7":"x_test= scaler.transform(x_test)","c3eddb74":"test.columns","00d4f4e2":"##Split training and test set\nfrom sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(x,y,test_size=0.2,stratify=y)","a5b47dad":"x_test.shape","5a5ebc21":"x_val.shape","5d71735b":"x_test[6]","5b7b37df":"import os\nos.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n \n# The GPU id to use, usually either \"0\" or \"1\";\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";  \n \n# Do other imports now...","25809750":"from __future__ import absolute_import, division, print_function, unicode_literals\n\n# TensorFlow and tf.keras\nimport tensorflow as tf\nfrom tensorflow.python import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation\nfrom tensorflow.keras.optimizers import SGD,Adam\nfrom tensorflow.keras import regularizers, initializers\nfrom tensorflow.keras.callbacks import CSVLogger,EarlyStopping,ModelCheckpoint\nfrom sklearn.metrics import log_loss, confusion_matrix\n\n# Helper libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(tf.__version__)\nprint(keras.__version__)","aa11f7a4":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\nprint(\"GPU Available: \", tf.test.is_gpu_available())","04d819f3":"csv_logger = CSVLogger('log-final-2.csv', append=True, separator=';')\nfrom sklearn import metrics\nfrom sklearn.metrics import log_loss, confusion_matrix","5064a2e7":"model = Sequential()\nmodel.add(Dense(4,input_dim=13, activation='tanh',use_bias=True, kernel_regularizer=regularizers.l2(0.0001), bias_regularizer=regularizers.l2(0.01)))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(4, activation='tanh',use_bias=True, kernel_regularizer=regularizers.l2(0.0001), bias_regularizer=regularizers.l2(0.01)))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(8, activation='tanh',use_bias=True, kernel_regularizer=regularizers.l2(0.0001), bias_regularizer=regularizers.l2(0.01)))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(5, activation='softmax'))\nsgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9)","4296acd3":"model.compile(loss='categorical_crossentropy',\n              optimizer=sgd,\n              metrics=['accuracy'])\n# simple early stopping\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=50,restore_best_weights=True)\n#checkpoint\n# checkpoint\nfilepath=\"weights.best.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\nhistory=model.fit(x_train, y_train,\n          epochs=3000,batch_size=200,validation_data=(x_val, y_val),callbacks=[csv_logger,es,checkpoint]\n          )\n\ny_pred=model.predict(x_test)\nmatrix = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\npd.DataFrame(matrix).to_csv(\"result-final-2.csv\",header=False,index=False)\n\nfrom tensorflow.keras.models import model_from_json\n# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"model-final-2.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"model-final-2.h5\")\nprint(\"Saved model to disk\")\n \n# later...","cf42f29e":"# load weights\nmodel.load_weights(\"weights.best.hdf5\")\n# Compile model (required to make predictions)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=sgd,\n              metrics=['accuracy'])\nprint(\"Created model and loaded weights from file\")","db649fdc":"y_pred_val=model.predict(x_val)","9f7418aa":"acc=metrics.accuracy_score(y_val.argmax(axis=1), y_pred_val.argmax(axis=1))\nacc","5ce6b105":"matrix","73b78d98":"len(history.history['loss'])","6850f07c":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","74e303de":"import matplotlib.pyplot as plt\n# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","0a8b10dd":"# load json and create model\nfrom tensorflow.keras.models import model_from_json\n\njson_file = open('model-final-2.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model.load_weights(\"model-final-2.h5\")\nprint(\"Loaded model from disk\")\n \n# evaluate loaded model on test data\nloaded_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\nscore = loaded_model.evaluate(x_test, y_test, verbose=0)\nprint(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))","e63a1f77":"y_pred=loaded_model.predict(x_test)","d293ac02":"y_pred","b05df829":"test.rating.value_counts()","9782d254":"y_test.shape","fad8feda":"from sklearn.metrics import mean_squared_error,mean_absolute_error\nfrom math import sqrt\n\nrms = sqrt(mean_squared_error(y_test.argmax(axis=1), y_pred.argmax(axis=1)))\nprint(rms)\nmae = mean_absolute_error(y_test.argmax(axis=1), y_pred.argmax(axis=1))\nprint(mae)\nconf=metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\nprint(conf)","2ca55334":"df_final.shape","01eb7eb1":"fmpred=loaded_model.predict(fullmatpred)","61aa59c7":"fmpredrating=fmpred.argmax(axis=1)\nfmpredrating.min()","b9a35ca0":"fmpredratingdf=pd.DataFrame({'col1':fmpred[:,0],'col2':fmpred[:,1],'col3':fmpred[:,2],'col4':fmpred[:,3],'col5':fmpred[:,4]})\nfmpredratingdf","7f02ba76":"fmpredratingdf[\"rating\"] = fmpredratingdf[[\"col1\",\"col2\",\"col3\",\"col4\",\"col5\"]].max(axis=1)","d16ca6bf":"fmpredratingdf","a9c4f21f":"def get_status(df):\n    if df['rating'] == df['col1']:\n        return 1\n    elif df['rating'] == df['col2']:\n        return 2\n    elif df['rating'] == df['col3']:\n        return 3\n    elif df['rating'] == df['col4']:\n        return 4\n    else:\n        return 5\n\nfmpredratingdf['star'] = fmpredratingdf.apply(get_status, axis = 1)","db04ea24":"fmpredratingdf","87705251":"full_matrix_id=df_final[['user_id','business_id']]\nfull_matrix_id","44158838":"rat=fmpredratingdf[['star']]\nrat=rat.rename({'star':'rating'},axis=1)\nrat","0dc18520":"fullpreddata=pd.concat([full_matrix_id, rat], axis=1)","96ac5436":"fullpreddata","07f84406":"fullpreddata.to_csv('cf-predicted.csv',header=False,index=None)","874acc54":"train=pd.read_csv('train_dataset.csv',index_col=0)\ntrain.head()","fc45edba":"train_cf=train[['user_id','business_id','rating']]\ntrain_cf.shape","37d63154":"fullpreddata.head()","53e36e46":"test=pd.read_csv('test_dataset.csv',index_col=0)\ntest.head()","fbc6bf28":"test_cf=test[['user_id','business_id','rating']]\ntest_cf.shape","b0f21075":"full_total=fullpreddata.append(train_cf,sort=False)\nfull_total\nfull_total.to_csv('cf-full.csv',header=False,index=None)","ca1e836c":"full_total","228c657a":"##Import library\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import log_loss, confusion_matrix, accuracy_score\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.tree import DecisionTreeClassifier","07c37ef0":"#model=MLPClassifier(hidden_layer_sizes=(4,4,8),max_iter=3000,solver='sgd',activation='tanh',alpha=0.01,learning_rate_init=0.0001,verbose=True)\n#model=MLPClassifier(hidden_layer_sizes=(8,8,8),max_iter=3000,solver='adam',activation='tanh',verbose=True)\n#model=KNeighborsClassifier(n_neighbors=1000)\n#model=LogisticRegression(multi_class='auto',solver='sag')\n#model=DecisionTreeClassifier()\nmodel=MLPClassifier(hidden_layer_sizes=(100,100),max_iter=3000,verbose=True,activation='tanh')","8d125005":"model.fit(x_train,y_train)\n#Test the model\ny_pred = model.predict(x_test)\n#Print final result\nprint(confusion_matrix(y_test,y_pred))","f17fe444":"model.n_layers_","3d229425":"accuracy = model.score(x_test,y_test)\nprint(accuracy*100,'%')","84ca1a9f":"accuracy = metrics.accuracy_score(y_test, y_pred)\naccuracy","c7c92ea6":"Ketiga *dataframe* ini yaitu **resto, user, dan review** perlu digabung menjadi satu *dataframe*. Hal ini dilakukan dengan *inner join* atau *merge* yang akan menghubungkan ketiga data tersebut berdasarkan id nya","4f6165a9":"### Review Date","4693ba2d":"### User","7d2c09ad":"## Train data: except test data","58535b66":"### Review Date","6423a137":"## Reviews Data","a26e1728":"# -------------------- ","0fa15365":"# Separate Users","786d257f":"# Business Understanding\n\nSistem rekomendasi menjadi salah satu *tool* untuk menyajikan informasi yang sesuai dengan preferensi pengguna. Pada use case kali ini, akan dilakukan rekomendasi terhadap restoran. Rekomendasi akan dilakukan dengan memanfaatkan data historis review\/ulasan serta penilaian pengguna yang telah dilakukan sebelumnya. Dari data ini, dapat diprediksi bagaimana preferensi pengguna terhadap restoran-restoran lain yang terdapat pada platform tersebut. Restoran yang diprediksi memiliki *rating* yang tinggi akan disajikan sebagai rekomendasi terhadap user terkait","60b1a6a1":"kemudian, kita akan memilih kolom-kolom yang akan digunakan. Disini kita akan memanfaatkan 3 kolom saja, yaitu **business_id, review_count, stars** ","5d9d865e":"## Filtering Dataset","bf72275b":"terdapat 174.567 data bisnis dengan 13 atribut","5fe5bd31":"# Data Understanding\n\nData yang akan dimanfaatkan yaitu data informasi terkait bisnis, pengguna, serta data ulasan terkait.\n\nPertama kita mulai dengan membaca dan menyimpan data-data tersebut ke *dataframe* pandas","4adeb23b":"### Yelping Since","c03a53b5":"# Data Preparation\n\nSelanjutnya kita masuk ke tahap data preparation, yaitu menyiapkan data sehingga sesuai dengan kebutuhan model\n\nPertama, perlu dilakukan beberapa penyesuaian terhadap tipe data","4eccdb5d":"Setelah membagi kategori ke masing-masing kolom, kita akan melakukan *filter* pada data, disini kita akan memilih data **Restaurants** di *state* **PA (Pennsylvania)** dengan status *is_open* **True \/ 1**","2cee9a61":"### Memilih sebagian data \n\nkali ini kita akan mencoba  membangun rekomendasi hanya untuk bisnis **restoran**, sehingga data yang ada perlu di-*filter* dulu.\n\nkarena kolom kategori terdiri dari beberapa jenis, kita akan membaginya (split) menjadi satu kolom per kategori ","3e1236b5":"## Predictor","70fd1c9d":"## Finally!","dfd0a335":"### Yelping Since","22e57c1f":"## Exporting data for collaborative filtering (PENDING)","6ef51f39":"### Memilih sebagian data \n\nSama dengan sebelumnya, kali ini kita akan mem-*filter* data user. kolom *name* tidak akan digunakan. Selain itu ada baris yang akan kita buang, yaitu data **user yang tidak pernah melakukan review** (review_count=0) ","7a83504c":"untuk meminimalisir memori, kita bisa menghapus data biz awal yang sudah tidak lagi digunakan","da5423af":"## 13 features final","525ef734":"# Modelling","4a46ffe8":"## Final","e5bef3f2":"Disini kita tidak memanfaatkan informasi 'text', sehingga kolom tersebut akan dihapus","e364e72c":"## Additional","0637d4ab":"## Dataset to be predicted: to make full rating","2bc8ef48":"## Joined Data","a943a1eb":"## Derived Columns","6bcd5fe4":"## Test data","cd97e90a":"## Alternatively: using sklearn","c0fad23e":"## Filtering data : >1 user reviewing and >1 business reviewed","c85b0599":"Setelah itu dilakukan penyaringan untuk data yang tidak valid atau tidak sesuai dengan kebutuhan model. Diantaranya yaitu:\n1. Data dengan tanggal review **(date)** lebih awal dibandingkan tanggal mendaftar **(yelping_since)** dianggap tidak valid, sehingga tidak disertakan dalam observasi\n2. ","c6a7dbf0":"## Business Data","0ec89faa":"## Data Exploration","2e24f987":"### Rating Distribution","3413f368":"Data resto final yang kita gunakan adalah data di atas ","91be52ff":"## Users Data","eb1e638b":"# Pre-processing data","03032427":"Untuk masing-masing id yang bertipe string, akan dilakukan perubahan (index) menjadi id bertipe integer, yang dilakukan untuk penyederhanaan serta minimalisir memori ","01b94b43":"# Overview\n\n>P.S. I decided to write this in Bahasa since there already exist many resources using English, but just very few ones in Bahasa. Hopefully by using Bahasa, local people (especially newbies like me) can understand it better and faster :) \n\n\nDi notebook ini saya akan berbagi pengalaman\/proyek saya terkait pembangunan sistem rekomendasi menggunakan beberapa teknik. Asumsi saya, pembaca sudah memahami sedikit mengenai konsep sistem rekomendasi. \n\nSistem rekomendasi bisa dikategorikan sebagai *Supervised Learning* karena memiliki target kelas yang akan diprediksi. Pendekatan yang saya gunakan pada pembangunan sistem rekomendasi kali ini yaitu *multi-class prediction*, dimana untuk masing-masing pasangan *item*-pengguna akan diprediksi berapa *rating* yang akan diberikan, dengan *range* 1 - 5.\n\nData yang saya gunakan yaitu data [Yelp Academic dataset version 6](https:\/\/www.kaggle.com\/yelp-dataset\/yelp-dataset\/version\/6), disediakan oleh Yelp yang merupakan platform review berbagai bisnis di Amerika Serikat. Untuk versi terbaru (version 9) juga sudah tersedia, namun karena keterbatasan *resources* pada Kaggle, pada notebook ini saya masih menggunakan versi 6 dengan data yang lebih sedikit.","87edbdb9":"# Clean data"}}