{"cell_type":{"9b21852b":"code","c7a8e02f":"code","60f48e3b":"code","598c260c":"code","155bd65c":"code","a6a09214":"code","75096099":"code","583efda4":"code","cd180b18":"code","09203454":"code","ead0926a":"code","7fa16301":"code","1cb6b967":"code","ad27c125":"code","811a697c":"code","f4feeec9":"code","43a7a1c2":"code","070be1f6":"code","5f6efc84":"code","18ecaa88":"code","748a29a6":"code","31f70c02":"markdown","551d13b9":"markdown","35c118f3":"markdown","b2c46289":"markdown","40176a26":"markdown","cd1b3a1d":"markdown","a33ba12c":"markdown","aa3f5059":"markdown","61a9b509":"markdown","482bb583":"markdown","e5c0228d":"markdown","61faea0b":"markdown","629a4b62":"markdown","35a458de":"markdown","adcf160a":"markdown","517bc6fa":"markdown"},"source":{"9b21852b":"# Install dependencies\n! [ -e \/content ] && pip install -Uqq fastai  # upgrade fastai on colab\nfrom fastai.vision.all import *","c7a8e02f":"# Save current working directory as pathlib.Path object\npath = Path(\"..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\")\npath","60f48e3b":"# List all files in path\npath.ls()","598c260c":"# Grab file names recursively\nfnames = get_image_files(path)\nfnames","155bd65c":"# Function for binary labelling\ndef label_func(fname):\n    if parent_label(fname)==\"Lung_Opacity\":\n        return 0\n    if parent_label(fname)==\"Normal\":\n        return 0\n    if parent_label(fname)==\"Viral Pneumonia\":\n        return 0\n    else:\n        return 1","a6a09214":"# Construct the DataLoaders object\ndbl = DataBlock(blocks    = (ImageBlock, CategoryBlock),\n                get_y     = label_func,\n                splitter  = RandomSplitter(valid_pct=0.2, seed=42),\n                item_tfms = Resize(128))\n\ndls = dbl.dataloaders(fnames)\ndls.show_batch()","75096099":"# Show size of training and validation set \nlen(dls.train_ds), len(dls.valid_ds)","583efda4":"# To make the metric calculation reproducible a seed is set\nimport random\nset_seed(123)\n\nlearn = cnn_learner(dls, resnet18, metrics=[error_rate,accuracy])\nlearn.fine_tune(6)","cd180b18":"learn.loss_func","09203454":"learn.opt_func","ead0926a":"# Interprete the model\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","7fa16301":"losses,idxs = interp.top_losses()\nlen(dls.valid_ds)==len(losses)==len(idxs)","1cb6b967":"# Assign variables to each quadrant of the confusion matrix\nupp, low = interp.confusion_matrix()\ntn, fp = upp[0], upp[1]\nfn, tp = low[0], low[1]\nprint(tn, fp, fn, tp)","ad27c125":"sensitivity = tp\/(tp + fn)\nsensitivity","811a697c":"specificity = tn\/(tn + fp)\nspecificity","f4feeec9":"ppv = tp\/(tp+fp)\nppv","43a7a1c2":"npv = tn\/(tn+fn)\nnpv","070be1f6":"# Plot images with the highest loss \ninterp = Interpretation.from_learner(learn)\ninterp.plot_top_losses(20)","5f6efc84":"# Print filenames of top losses\nlosses, idxs = interp.top_losses(20)\nl = 0\nfor i in idxs:\n    print(f\"Loss: {round(float(losses[l]),2)}\\tFilename: {dls.valid_ds.items[i]}\")\n    l += 1","18ecaa88":"# Load exported model for deployment \nlearn_inf = load_learner(\"..\/input\/covidmodel\/binary_model.pkl\") ","748a29a6":"# Predict COVID on \"test\" images\n#pos\nprint(learn_inf.predict('..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\/COVID\/COVID-1011.png'))\n#pos\n#print(learn_inf.predict('..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\/COVID\/COVID-1012.png'))\n#neg\n#print(learn_inf.predict('..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\/Normal\/Normal-10.png'))\n#neg\n#print(learn_inf.predict('..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\/Lung_Opacity\/Lung_Opacity-1004.png'))\n#neg\n#print(learn_inf.predict('..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\/Viral Pneumonia\/Viral Pneumonia-1000.png'))","31f70c02":"# Interpretation of the model\n- Show images where the model failed.\n- what does the average \u201cpositive example\u201d look like vs the average \u201cnegative example\u201d\n- Is it possible to discern these differences visually? mathematically?","551d13b9":"# Result evaluation of the model\nThe resnet18 model trained for 6 epochs only, already achieves more than 99% accuracy. However, accuracy is not the only measure that should be considered for model evaluation. Other metrics that will be analysed here are:\n\n## False Positive & False Negative\n- **False Positive** the test is positive but the patient actually is COVID-negative.\n- **False Negative** the test is negative but the patient actually is COVID-positive","35c118f3":"It seems like most of the images with a high loss are COVID-possitive or Lung_Opacity. Reasons for that could be that Lung_Opacity images look a lot like COVID-positive images.","b2c46289":"# Test the model\nTo perform some manual sanity checks, the model will be tested on some (hopefully) unseen CXRs. Futhermore, it will be tested on unrelated images that are not CXRs.","40176a26":"# Train a model\nThe `cnn_learner` function is used to initiate the training.","cd1b3a1d":"We can do the same for the optimization function.","a33ba12c":"The dataset contains four different folders: COVID, Lung_Opacity, Normal, Viral Pneumonia. But we want to create a **binary** classifier and therefore we will refer to every image that is not in the COVID folder as a 0 and every image in the COVID folder as a 1. ","aa3f5059":"The model has a specificity (true negative rate) of ~99.66% which means almost all COVID-negative patients will be be correctly classified as negative. Also known as **Type I error**.","61a9b509":"We didn't specify a loss function, therefore fastai will try to choose the best selection for the task. Let's check which one it was.","482bb583":"## Sensitivity & Specificity\n- **Sensitivity** or **True Positive Rate**: The test is positive given that the patient actually is positive. Sensitivity measures the avoidance of false negatives.\n- **Specificity** or **True Negative Rate**: The test is negative given that the patient actually is negative. Specificity measure the avoidance of false positives.\n- Example: A new test for COVID-19 was tested on 20,000 patients, 10,000 of which are known to have the disease. \n    - If this test correctly classified 9000 patients as positive (true positive) but classifies 1000 as negative (false negative), the test would have a sensitivity of 90% (true positive rate).\n    - $Sensitivity = TP\/(TP+FN) = 9000\/(9000+1000) = 9000\/10,000 = 0.90$\n    - If this test correctly classified 8000 patients as negative (true negative) but classifies 2000 as positive (false positive), the test would have a specificity of 80% (true negative rate).\n    - $Specificity = TN\/(TN+FP) = 8000\/(8000+2000) = 8000\/10,000 = 0.80$\n    \nWhich metric is more meaningful when trying to detect a disease?\nA COVID-test should foremost have a high sensitivity. In other words, the test should detect as much positive patients as possible. On the other hand, a diagnostic tool with a low specificity will be useless as it will falsely classify too many patients as positive even though they are not. ","e5c0228d":"The model has a sensitivity (true positive rate) of ~97.25. This means that it is capable of correctly detecting 97.25% true positives (patient has COVID and is detected) and will miss 2.75% of false negatives (patient has COVID but is *not* detected). Also known as **Type II error**.","61faea0b":"# Create a DataLoaders object\n\nA **DataLoader** is an iterator that provides a stream of mini-batches. Each mini-batch is a tuple of an independent variables batch and a dependent variables batch. The **DataLoaders** object contains a training DataLoader and a validation DataLoader.","629a4b62":"# Jason's Part\nROC curve etc.","35a458de":"The PPV is slightly lower than the NPV which means that it is better at detecting COVID-positive patients than COVID-negative. This could be because the training dataset contains fewer positive than negative images. However, the metrics should be considered very good. ","adcf160a":"## Positive Predictive Value (Precision) & Negative Predictive Value (Recall)\nDiagnostic tests are often evaluated via PPV (Positive Predictive Value) or NPV (Negative Predictive Value).\n- **PPV**: If the model predicts a patient has a condition what is the probability that the patient actually has the condition\n- **NPV**: If the model predicts a patient does not have a condition what is the probability that the patient actually does not have the condition\n\nThe ideal value of the PPV, with a perfect test, is 1 (100%), and the worst possible value would be zero.\n\nThe ideal value of the NPV, with a perfect test, is 1 (100%), and the worst possible value would be zero.","517bc6fa":"# Binary classification of chest x-rays to detect COVID-19\n\n# Introduction\nThis notebook is part of a coding bootcamp project called \"chestX\" hosted by TechLabs Berlin. ChestX is a webapp that detect COVID-19 from chest x-ray images (CXR) with the help of a computer vision model. For more information please refer to our GitHub: https:\/\/github.com\/TechLabs-Berlin\/st21-chestX\n\n### Interpreting CXRs\n- X-ray images are grayscale with values ranging from 0 (black) to 255 (white) \n- The values correlate to the density of the body's area:\n    - black: air \n    - dark grey: subcutaneous tissues or fat\n    - light grey: soft tissues like the heart and blood vessels \n    - off white: bones such as the ribs\n    - bright white: metallic objects such as pacemakers or necklace \n- If something happens in the lungs, such as pneumonia, the air-dense lungs change into water-dense lungs. This causes the demarcation lines to fade since the pixel densities start closing in on the grayscale bar.\n- About 20% of patients infected with COVID-19 develop pulmonary infiltrates and some develop very serious abnormalities. \n\n### Why CXRs?\n- Portable chest X-rays are likely to be one of the most common modalities for the identification and follow-up of COVID-19 lung abnormalities.\n- CT rooms are more difficult to decontaminate and they are not as available in different parts of the world as x-ray machines\n- Deep Learning techniques have proven to be beneficial in both classifying abnormalities from lung x-ray images and aiding the radiologists to accurately predict COVID-19 cases in a reduced time frame.\n\nSource: https:\/\/link.springer.com\/article\/10.1007\/s42979-021-00496-w\n\n### The dataset\nThe dataset used: https:\/\/www.kaggle.com\/tawsifurrahman\/covid19-radiography-database \n\nWhich is a collection from the following resources:\n- [1]https:\/\/bimcv.cipf.es\/bimcv-projects\/bimcv-covid19\/#1590858128006-9e640421-6711\n- [2]https:\/\/github.com\/ml-workgroup\/covid-19-image-repository\/tree\/master\/png\n- [3]https:\/\/sirm.org\/category\/senza-categoria\/covid-19\/\n- [4]https:\/\/eurorad.org\n- [5]https:\/\/github.com\/ieee8023\/covid-chestxray-dataset\n- [6]https:\/\/figshare.com\/articles\/COVID-19_Chest_X-Ray_Image_Repository\/12580328\n- [7]https:\/\/github.com\/armiro\/COVID-CXNet\n- [8]https:\/\/www.kaggle.com\/c\/rsna-pneumonia-detection-challenge\/data\n- [9] https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia\n\n### Data composition\nThe dataset contains 3616 COVID-19 positive cases, 10192 Normal, 6012 Lung Opacity (Non-COVID lung infection), and 1345 Viral Pneumonia images. In total, that makes 17549 COVID-19 negative and 3616 positive images and therefore a quite biased dataset (A positive to negative ratio of 20.61%.)."}}