{"cell_type":{"39b34c9d":"code","0af0a212":"code","aec6a4f4":"code","f1725832":"code","a40466ce":"code","e6219177":"code","115ead51":"code","968171c6":"code","6b03c12b":"code","2bb13a07":"code","f1c6594a":"code","62dae55d":"code","43141d62":"code","6141e5c9":"code","f9718adb":"code","17be1fa8":"code","ff5ea180":"code","1a07b617":"code","4b262a02":"code","ef20aa40":"code","38f07e7e":"code","34ad1918":"code","9412cf61":"code","c5e6404a":"code","d5f615a6":"code","c7f7f54e":"code","5e7a3288":"code","830116c2":"code","69d3fd84":"code","c1d867a4":"code","3a0ae6a8":"code","49362449":"code","484ee7b0":"code","ad415d99":"code","ccd96b34":"code","05cdf059":"code","706ebdb6":"code","5911f4c0":"code","3a219cb4":"code","fe3f43f5":"code","09f67438":"code","1944cc4b":"code","e0797ce1":"code","d24145a8":"markdown","646aed2f":"markdown","2bac90da":"markdown","6888cfd2":"markdown","9900080a":"markdown","c8264962":"markdown","17c2b156":"markdown","16c22e80":"markdown","fe9d6564":"markdown","7a961b1e":"markdown","7f8b52f7":"markdown","ca10d559":"markdown","82215ca9":"markdown"},"source":{"39b34c9d":"import math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\npd.set_option('display.max_columns', None)\nimport warnings\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nfrom plotly import tools\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import datasets, linear_model\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import LinearSVR\nfrom sklearn.svm import SVR\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.tree import export_graphviz\n\nwarnings.filterwarnings('ignore')\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 9999\npd.options.display.float_format = '{:20,.2f}'.format\nfrom IPython.display import Image\nfrom IPython.core.display import HTML ","0af0a212":"#Loading mathematic data set\ndata_mat = pd.read_csv('..\/input\/student-mat.csv')\n#Loading Portuguese data set\ndata_por = pd.read_csv('..\/input\/student-por.csv')\ndata_mat.info()","aec6a4f4":"data_mat.head()","f1725832":"data_por.head()","a40466ce":"#Validate nulls on mathematic dataset\ndata_mat.isnull().any()","e6219177":"#Validate nulls on Portuguese dataset\ndata_por.isnull().any()","115ead51":"#Display number of students study mathematic according to gender\nsns.catplot(x=\"sex\", kind=\"count\",palette=\"magma\", data=data_mat, height = 6)\nplt.title(\"Gender of students : F - female,M - male\")","968171c6":"#Display number of students study Portuguese according to gender.\nsns.catplot(x=\"sex\", kind=\"count\",palette=\"magma\", data=data_por, height = 6)\nplt.title(\"Gender of students : F - female,M - male\")","6b03c12b":"#Display distribution of math students according to age.\nages_mat = data_mat[\"age\"].value_counts()\nlabels_mat = (np.array(ages_mat.index))\nsizes_mat = (np.array((ages_mat \/ ages_mat.sum())*100))\n\nages_por = data_por[\"age\"].value_counts()\nlabels_por = (np.array(ages_por.index))\nsizes_por = (np.array((ages_por \/ ages_por.sum())*100))\n\ntrace = go.Pie(labels=labels_mat, values=sizes_mat)\nlayout = go.Layout(title=\"\u0410ge of students\")\ndat = [trace]\nfig = go.Figure(data=dat, layout=layout)\npy.iplot(fig, filename=\"age\")\n","2bb13a07":"#Display distribution of Portuguese students according to age.\ntrace = go.Pie(labels=labels_por, values=labels_por)\nlayout = go.Layout(title=\"\u0410ge of students\")\ndat = [trace]\nfig = go.Figure(data=dat, layout=layout)\npy.iplot(fig, filename=\"age\")","f1c6594a":"#Display how many hours per week math students spend on their studies.\ndata_mat['st_time'] = np.nan\ndf = [data_mat]\n\nfor col in df:\n    col.loc[col['studytime'] == 1 , 'st_time'] = '< 2 hours'\n    col.loc[col['studytime'] == 2 , 'st_time'] = '2 to 5 hours'\n    col.loc[col['studytime'] == 3, 'st_time'] = '5 to 10 hours'\n    col.loc[col['studytime'] == 4, 'st_time'] = '> 10 hours'  \n \nlabels = data_mat[\"st_time\"].unique().tolist()\namount = data_mat[\"st_time\"].value_counts().tolist()\n\ncolors = [\"red\", \"blue\", \"grey\", \"yellow\"]\n\ntrace = go.Pie(labels=labels, values=amount,\n               hoverinfo='label+percent', textinfo='value', \n               textfont=dict(size=20),\n               marker=dict(colors=colors, \n                           line=dict(color='#000000', width=2)))\ndt = [trace]\nlayout = go.Layout(title=\"Study time -Math \")\n\nfig = go.Figure(data=dt, layout=layout)\niplot(fig, filename='pie')","62dae55d":"#Display how many hours per week Portugese students spend on their studies.\ndata_por['st_time'] = np.nan\ndf = [data_por]\n\nfor col in df:\n    col.loc[col['studytime'] == 1 , 'st_time'] = '< 2 hours'\n    col.loc[col['studytime'] == 2 , 'st_time'] = '2 to 5 hours'\n    col.loc[col['studytime'] == 3, 'st_time'] = '5 to 10 hours'\n    col.loc[col['studytime'] == 4, 'st_time'] = '> 10 hours'  \n \nlabels = data_por[\"st_time\"].unique().tolist()\namount = data_por[\"st_time\"].value_counts().tolist()\n\ncolors = [\"red\", \"blue\", \"grey\", \"yellow\"]\n\ntrace = go.Pie(labels=labels, values=amount, hoverinfo='label+percent', textinfo='value', \n               textfont=dict(size=20), marker=dict(colors=colors, line=dict(color='#000000', width=2)))\n\ndt = [trace]\nlayout = go.Layout(title=\"Study time - Portugese\")\n\nfig = go.Figure(data=dt, layout=layout)\niplot(fig, filename='pie')","43141d62":"#Display math students travling time urban vs rural.\nsns.catplot(x=\"address\", kind=\"count\",hue = \"traveltime\",palette=\"brg\", data=data_mat, height = 6)\nplt.title(\"Students address for Mathematics courses: U - urban City, R - rural non City\")\n\n#Display Portugese students travling time urban vs rural.\nsns.catplot(x=\"address\", kind=\"count\",hue = \"traveltime\",palette=\"brg\", data=data_por, height = 6)\nplt.title(\"Students address for Portugese courses: U - urban City, R - rural non City\")","6141e5c9":"#Categories math & Portuguese students according to their grade.\n# 15-20 \tExcellent\n# 10-15 \tGood\n# 0-9       Poor   \n\ndata_mat['Category_Grade'] = 'na'\ndata_mat.loc[(data_mat.G3  >= 15) & (data_mat.G3 <= 20), 'Category_Grade'] = 'Excellent' \ndata_mat.loc[(data_mat.G3  >= 10) & (data_mat.G3 <= 14), 'Category_Grade'] = 'GOOD' \ndata_mat.loc[(data_mat.G3  >= 0) & (data_mat.G3 <= 9), 'Category_Grade'] = 'POOR'\n\ndata_por['Category_Grade'] = 'na'\ndata_por.loc[(data_por.G3  >= 15) & (data_por.G3 <= 20), 'Category_Grade'] = 'Excellent' \ndata_por.loc[(data_por.G3  >= 10) & (data_por.G3 <= 14), 'Category_Grade'] = 'GOOD' \ndata_por.loc[(data_por.G3  >= 0) & (data_por.G3 <= 9), 'Category_Grade'] = 'POOR' \n\n\ndata_mat.head(5)","f9718adb":"#Display final grade category in math and Portuguese according to category\nplt.figure(figsize=(8,6))\nsns.countplot(data_mat.Category_Grade, order=[\"POOR\",\"GOOD\",\"Excellent\"], palette='Set1')\nplt.title('Final Grade - Mathematics',fontsize=20)\nplt.xlabel('Final Grade', fontsize=16)\nplt.ylabel('Number of Student', fontsize=16)\n\nplt.figure(figsize=(8,6))\nsns.countplot(data_por.Category_Grade, order=[\"POOR\",\"GOOD\",\"Excellent\"], palette='Set1')\nplt.title('Final Grade - Portuguese',fontsize=20)\nplt.xlabel('Final Grade', fontsize=16)\nplt.ylabel('Number of Student', fontsize=16)","17be1fa8":"# Display crrelation between features for math and Portugase students\nplt.figure(figsize=(10,10))\nsns.heatmap(data_mat.corr(),annot = True,fmt = \".2f\",cbar = True)\nplt.title('Crrelation - Mathematics',fontsize=20)\nplt.xticks(rotation=90)\nplt.yticks(rotation = 0)\n\nplt.figure(figsize=(10,10))\nsns.heatmap(data_por.corr(),annot = True,fmt = \".2f\",cbar = True)\nplt.title('Crrelation - Portuguese',fontsize=20)\nplt.xticks(rotation=90)\nplt.yticks(rotation = 0)","ff5ea180":"# Display grade distibution for math and Portuguese according G1,G2 & G3 semesters.\nfig = plt.figure(figsize=(14,5))\nplt.style.use('seaborn-white')\nax1 = plt.subplot(121)\nplt.hist([data_mat['G1'], data_mat['G2'], data_mat['G3']], label=['G1', 'G2', 'G3'], color=['#48D1CC', '#FF7F50', '#778899' ], alpha=0.8)\nplt.legend(fontsize=14)\nplt.xlabel('Grade', fontsize=18)\nplt.ylabel('Frequency', fontsize=18)\nplt.title('Mathematics Grades', fontsize=20)\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\nplt.ylim(0,220)\n\nax2 = plt.subplot(122)\nplt.hist([data_por['G1'], data_por['G2'], data_por['G3']], label=['G1', 'G2', 'G3'], color=['#48D1CC', '#FF7F50', '#778899' ], alpha=0.8)\nplt.legend(fontsize=14)\nplt.xlabel('Grade', fontsize=18)\nplt.ylabel('Frequency', fontsize=18)\nplt.title('Portuguese Grades', fontsize=20)\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\nplt.ylim(0,220)\n\nplt.show()","1a07b617":"# Display distribution of math and Portuguese students absences\nfig = plt.figure(figsize=(14,10))\n\nax1 = plt.subplot(221)\nsns.countplot(data_mat['absences'], color='#48D1CC')\nplt.title('Absences count in Math', fontsize=14)\nplt.xlabel('number of absences', fontsize=12)\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\nplt.xlim((0,32))\n\nax2 = plt.subplot(222)\nsns.countplot(data_por['absences'], color='#FF7F50')\nplt.title('Absences count in Portuguese', fontsize=14)\nplt.xlabel('number of absences', fontsize=12)\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\nplt.xlim((0,32))\n\nax3 = plt.subplot(223)\nsns.regplot(data_mat['absences'], data_mat['G3'], x_estimator=np.mean, color='#48D1CC')\nplt.title('Math: G3 vs absences', fontsize=14)\nplt.xlabel('Absences: number of absences', fontsize=12)\nax3.spines['top'].set_visible(False)\nax3.spines['right'].set_visible(False)\nplt.xlim((0,32))\n\nax4 = plt.subplot(224)\nsns.regplot(data_por['absences'], data_por['G3'], x_estimator=np.mean, color='#FF7F50')\nplt.title('Portuguese: G3 vs absences', fontsize=14)\nplt.xlabel('Absences: number of absences', fontsize=12)\nax4.spines['top'].set_visible(False)\nax4.spines['right'].set_visible(False)\nplt.xlim((0,32))\n\nplt.tight_layout()","4b262a02":"# Preprocessing final data while columns that contain Yes\/No values will be converted into binary values and categories columns \n# will be enumerated.\n\nmath_final = data_mat.copy()\nmath_final = math_final.drop(['G1', 'G2','st_time','Category_Grade'], axis=1)\n# Convert dummy variables values into 0\/1.\nmath_final.school = math_final['school'].replace(['GP', 'MS'], [1,0])\nmath_final.sex = math_final['sex'].replace(['F','M'],[1,0])\nmath_final.address = math_final['address'].replace(['U','R'], [1,0])\nmath_final.famsize = math_final['famsize'].replace(['LE3','GT3'], [1,0])\nmath_final.Pstatus = math_final['Pstatus'].replace(['T','A'], [1,0])\nmath_final.schoolsup = math_final['schoolsup'].replace(['yes','no'],[1,0])\nmath_final.famsup = math_final['famsup'].replace(['yes','no'],[1,0])\nmath_final.activities = math_final['activities'].replace(['yes','no'],[1,0])\nmath_final.nursery = math_final['nursery'].replace(['yes','no'],[1,0])\nmath_final.higher = math_final['higher'].replace(['yes','no'],[1,0])\nmath_final.internet = math_final['internet'].replace(['yes','no'],[1,0])\nmath_final.romantic = math_final['romantic'].replace(['yes','no'],[1,0])\nmath_final.paid = math_final['paid'].replace(['yes','no'],[1,0])\n\nnorminal_vars = ['Fjob', 'Mjob', 'reason','guardian','Medu','Fedu','traveltime','studytime']\nmath_final = pd.get_dummies(math_final, columns= norminal_vars, drop_first=True)\nmath_final.head()","ef20aa40":"# Split data into train and test.\nX = math_final.drop(['G3'], axis=1)\ny = math_final['G3']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","38f07e7e":"#Run cross val score on the fpllowing chosen models:\n#    1.) LinearRegression\n#    2.) DecisionTreeRegressor\n#    3.) linear_model.Lasso\n#    4.) GradientBoostingRegressor\n#    5.) RandomForestRegressor\n#    6.) SVR\n#    7.) XGBRegressor\n\n\n#Create the model according to give model name    \ndef bulid_model(model_name):\n        model = model_name()\n        return model\n\n#Run the given model and prints the score and std\ndef run_cross_val_score(model, X, y, cv):\n    #Running the scoring with negative mean squared error \n    cv_scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_squared_error')\n    cv_scores = np.sqrt(abs(cv_scores)) # Convert the given score into RMSE\n    print(\"CV Score cv =\", cv, cv_scores, \"\\n\\nMean of cv scores: \", np.mean(cv_scores),\"\\n\")\n    print(\"STD =\", cv_scores.std())\n            \n#Loop through models and run cross val score        \nfor model_name in [LinearRegression, DecisionTreeRegressor, linear_model.Lasso, GradientBoostingRegressor, RandomForestRegressor, SVR, XGBRegressor]:\n    model = bulid_model(model_name)\n    print(\"\\n=====================================================================\")\n    print(model_name,\"\\n\")\n    run_cross_val_score(model, X_train, y_train, 5)    ","34ad1918":"print(\"The chosen models are: \\n\\t 1.) DecisionTreeRegressor \\n\\t 2.) SVR \\n\\t 3.) XGBRegressor \\n\\t 4.) RandomForestRegressor  \\n\\t 5.) LinearRegression\")","9412cf61":"# criterion (default='mse') - The function to measure the quality : 'mse', 'friedman_mse','mae'\n#        1.) mse - mean squared error.\n#        2.) friedman_mse - mean squared error : uses mean squared error with Friedman\u2019s improvement score for potential splits.\n#        3.) mse - mean squared error : mean absolute error.\n\n# splitter (default='best') - The strategy used to choose the split at each node\n#        1.) best - to choose the best split.\n#        2.) random -  to choose the best random split.\n\n# max_depth (default='None') - The maximum depth of the tree.\n\n# min_samples_split (default=2) - The minimum number of samples required to split an internal node.\n\n# max_features (default='None') - The number of features to consider when looking for the best split.          \n#        int value = then consider max_features features at each split.\n#        \"auto\u201d = then max_features=n_features.\n#        \u201csqrt\u201d = then max_features=sqrt(n_features).\n#        \u201clog2\u201d = then max_features=log2(n_features)\n\n# presort (default=False) - Whether to presort the data to speed up the finding of best splits in fitting\n\n\ndef get_parameters_tuning (model, X_train, y_train, X_test, y_test, cv, params_grid):\n    grid = GridSearchCV(model, params_grid, cv=cv, scoring='neg_mean_squared_error')\n    grid.fit(X_train, y_train)\n    print('Best cross validation score: {:.2f}'.format(np.sqrt(abs(grid.best_score_))))\n    print('Best parameters:', grid.best_params_)\n    print('Test score:', np.sqrt(abs(grid.score(X_test, y_test))))\n\nparams_grid = {'criterion':['mse','friedman_mse','mae'], 'splitter':['best','random'], 'max_depth':[10,100,1000], \n               'min_samples_split':[5,10,20,40,80,160], 'min_samples_leaf':[1,2,3,4,5,10], \n               'max_features':['auto','sqrt','log2'], 'presort':[True,False] }\n\nget_parameters_tuning(DecisionTreeRegressor(), X_train, y_train, X_test, y_test, 5, params_grid)","c5e6404a":"decision_tree_regressor_model = DecisionTreeRegressor(max_depth=10, min_samples_leaf=10, min_samples_split=40, presort=True)\ndecision_tree_regressor_model.fit(X_train, y_train)","d5f615a6":"dt_predictions = decision_tree_regressor_model.predict(X_train)","c7f7f54e":"def print_rmse(orig_values, predict_values):\n    rmse = np.sqrt(MSE(orig_values, predict_values))\n    print(\"RMSE = {:.2f}\".format(rmse))","5e7a3288":"#DecisionTreeRegressor RMSE for train data\nprint('Predict RMSE with floting prediction : ')\nprint_rmse(y_train, dt_predictions)","830116c2":"#Display the Difference Between Predicted G3 and Actual G3\nplt.figure(figsize=(15,7))\nplt.plot(y_train-dt_predictions, '.b', markersize=4)\nplt.xlabel('Data')\nplt.ylabel('Actual Difference')\nplt.title('Display the Difference Between Predicted G3 and Actual G3')","69d3fd84":"#DecisionTreeRegressor RMSE for test data\ndt_test_predictions = decision_tree_regressor_model.predict(X_test)\nprint('Predict RMSE with floting prediction : ')\nprint_rmse(y_test, dt_test_predictions)","c1d867a4":"export_graphviz(decision_tree_regressor_model, out_file ='tree.dot')  \nImage(url= \"tree.jpg\")","3a0ae6a8":"#SVR\nparams_grid = {'gamma': [1e-3,1e-1,1e0,1e1,1e10,1e50], 'C':[1e-3,1e-1,1e0,1e1,1e10,1e50]}\nget_parameters_tuning(SVR(), X_train, y_train, X_test, y_test, 5, params_grid)","49362449":"svr_model = SVR(C=10.0, gamma=0.001)\nsvr_model.fit(X_train, y_train)\nsvr_predictions = svr_model.predict(X_train)\n\n#SVR RMSE for train data\nprint('Predict RMSE with floting prediction for SVR model : ')\nprint_rmse(y_train, svr_predictions)","484ee7b0":"plt.figure(figsize=(15,7))\nplt.plot(y_train-svr_predictions, '.b', markersize=4)\nplt.xlabel('Data')\nplt.ylabel('Actual Difference')\nplt.title('SVR - Display the Difference Between Predicted G3 and Actual G3')","ad415d99":"#SVR RMSE for test data\nsvr_test_predictions = svr_model.predict(X_test)\nprint('Predict RMSE with floting prediction (SVR-test) : ')\nprint_rmse(y_test, svr_test_predictions)","ccd96b34":"#XGBRegressor\ngrid_params = {'max_depth':[2,3,5,7], 'learning_rate':[0.001,0.01,0.1], 'n_estimators':[50,100,200]}\nget_parameters_tuning(XGBRegressor(), X_train, y_train, X_test, y_test, 5, grid_params)","05cdf059":"model_XGBRegressor = XGBRegressor(max_depth=2,learning_rate=0.1, n_estimators=50)\nmodel_XGBRegressor.fit(X_train,y_train)\nxgbregressor_train_predictions = model_XGBRegressor.predict(X_train)\n\n#XGBRegressor RMSE for train data\nprint('Predict RMSE with floting prediction for XGBRegressor model : ')\nprint_rmse(y_train, xgbregressor_train_predictions)","706ebdb6":"plt.figure(figsize=(15,7))\nplt.plot(y_train-xgbregressor_train_predictions, '.b', markersize=4)\nplt.xlabel('Data')\nplt.ylabel('Actual Difference')\nplt.title('XGBRegressor - Display the Difference Between Predicted G3 and Actual G3')","5911f4c0":"#XGBRegressor RMSE for test data\nxgbregressor_test_predictions = model_XGBRegressor.predict(X_test)\nprint('Predict RMSE with floting prediction (XGBRegressor-test) : ')\nprint_rmse(y_test, xgbregressor_test_predictions)","3a219cb4":"#RandomForestRegressor\nparams_grid = {'n_estimators':[5,10,50,100,500],'max_depth':[1,3,5,7],'min_samples_leaf':[5]}\nget_parameters_tuning(RandomForestRegressor(), X_train, y_train, X_test, y_test, 5, params_grid)","fe3f43f5":"best_RFR = RandomForestRegressor(n_estimators=500, max_depth=7, min_samples_leaf=5)\nbest_RFR.fit(X_train, y_train)\n\nrandomforest_train_predictions = best_RFR.predict(X_train)\nprint('Predict RMSE with floting prediction (RandomForestRegressor-train) : ')\nprint_rmse(y_train, randomforest_train_predictions)\n\nrandomforest_test_predictions = best_RFR.predict(X_test)\nprint('\\nPredict RMSE with floting prediction (RandomForestRegressor-test) : ')\nprint_rmse(y_test, randomforest_test_predictions)\n","09f67438":"params_grid = {'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True, False]}\nget_parameters_tuning(LinearRegression(), X_train, y_train, X_test, y_test, 5, params_grid)","1944cc4b":"linear_regression_model = LinearRegression()\nlinear_regression_model.fit(X_train,y_train)\nlinear_regression_predictions = linear_regression_model.predict(X_train)\n\nprint('Predict RMSE with floting prediction (LinearRegression-train) : ')\nprint_rmse(y_train, linear_regression_predictions)\n\n\nlinear_regression_test_predictions = linear_regression_model.predict(X_test)\nprint('\\nPredict RMSE with floting prediction (LinearRegression-test) : ')\nprint_rmse(y_test, linear_regression_test_predictions)\n","e0797ce1":"#Model ensemble\nmodel_ensemble_df = pd.DataFrame(randomforest_test_predictions,columns=['RF'])\nmodel_ensemble_df['XGB'] = xgbregressor_test_predictions\nmodel_ensemble_df['SVR'] = svr_test_predictions\nmodel_ensemble_df['AVG'] = model_ensemble_df.median(axis=1)\n\nprint_rmse(y_test, model_ensemble_df['AVG'])","d24145a8":"# Features Description","646aed2f":"### RandomForestRegressor","2bac90da":"### SVR","6888cfd2":"### DecisionTreeRegressor","9900080a":"### Model evaluation: quantifying the quality of predictions\nWe have chosen to use the \"Mean Squared Error\" method to evaluate the quality of the model.  \nOur regression labels are in range of 0 - 20 with a semmi normal distribution and we have no need to use log.  \n\"Mean Squared Error\" was preferred over \"Mean Absolute Error\", as we wanted the model to \"punish\" larger errors, and over R^2 because we wanted the units to be understandable.","c8264962":"### XGBRegressor","17c2b156":"### Problem Definition: \n\nEstimate final grade in mathematic according to given features, while most features are social features. \nIn addition, EDA is done on mathematic and Portuguese datasets, but prediction is done only on mathematic data set.  \n","16c22e80":"### LinearRegression","fe9d6564":"### Project Stages:\nThe following are the project stages applied:\n1.\tProblem definition.\n2.\tData collection and preprocessing.\n3.\tEDA.\n4.\tExamination of seven models for mathematic dataset, while selecting some of them for further examination with different parameters.\n5.\tExamine selected models on test data.\n6.\tConclusion.\n","7a961b1e":"There are 33 features in this data. What they represent is given below.\n\nschool : Student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)\n\nsex : Student's sex (binary: 'F' - female or 'M' - male)\n\nage : Student's age (numeric: from 15 to 22)\n\naddress : Student's home address type (binary: 'U' - urban or 'R' - rural)\n\nfamsize : Family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)\n\nPstatus : Parent's cohabitation status (binary: 'T' - living together or 'A' - living apart)\n\nMedu : Mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education, or 4 - higher education)\n\nFedu : Father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education, or 4 - higher education)\n\nMjob : Mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n\nFjob : Father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n\nreason : Reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')\n\nguardian : Student's guardian (nominal: 'mother', 'father' or 'other')\n\ntraveltime : Home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n\nstudytime : Weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n\nfailures : Number of past class failures (numeric: n if 1<=n<3, else 4)\n\nschoolsup : Extra educational support (binary: yes or no)\n\nfamsup : Family educational support (binary: yes or no)\n\npaid : Extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n\nactivities : Extra-curricular activities (binary: yes or no)\n\nnursery : Attended nursery school (binary: yes or no)\n\nhigher : Wants to take higher education (binary: yes or no)\n\ninternet : Internet access at home (binary: yes or no)\n\nromantic : With a romantic relationship (binary: yes or no)\n\nfamrel : Quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n\nfreetime : Free time after school (numeric: from 1 - very low to 5 - very high)\n\ngoout : Going out with friends (numeric: from 1 - very low to 5 - very high)\n\nDalc : Workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n\nWalc : Weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n\nhealth : Current health status (numeric: from 1 - very bad to 5 - very good)\n\nabsences : Number of school absences (numeric: from 0 to 93)\n\nG1 : First period grade (numeric: from 0 to 20)\n\nG2 : Second period grade (numeric: from 0 to 20)\n\nG3 : Final grade (numeric: from 0 to 20, output target)","7f8b52f7":"### Conclusion:\n   ","ca10d559":"### Model Ensemble","82215ca9":"#### The following are the final tests results:\n#####    1.) RandomForestRegressor: 3.97\n#####    2.) XGBRegressor: 4.08\n#####    3.) SVR: 4.15\n#####    4.) LinearRegression: 4.31\n#####    5.) DecisionTreeRegressor: 4.43    \n"}}