{"cell_type":{"bc273d0c":"code","889fbe39":"code","f1dc99cf":"code","28b108f5":"code","43cc49b8":"code","02626c68":"code","7f89ec0a":"code","3eeaa509":"code","06731a97":"code","19f327f5":"code","d814a84c":"code","756d87ee":"code","18c9540a":"code","7916d23b":"code","a450385c":"code","80cd1799":"code","3f365295":"code","a2bae177":"code","a4b1096f":"code","677514bc":"code","b65c4721":"code","2cc880a5":"code","9ad086a8":"code","8765b5d9":"code","e790dc56":"code","fadc888f":"code","66ed51b8":"code","55297252":"markdown","dc3fe029":"markdown","ad511787":"markdown","c9cb5ae9":"markdown","654103e7":"markdown","39f4bfd1":"markdown","e291be38":"markdown","aa421c50":"markdown","4b0e3cb8":"markdown"},"source":{"bc273d0c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O\nimport math, time\n\n#Plotting\nimport matplotlib.pyplot as plt\n#import seaborn as sns\n#%matplotlib inline\n\n# Scikit learn libraries\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n#from sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\n#from sklearn.svm import LinearSVC\n#from sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport eli5\n#import datetime\n\n#from scipy import stats\n#from scipy.sparse import hstack, csr_matrix\n\nfrom wordcloud import WordCloud\n#from collections import Counter\n\nfrom nltk.tokenize import TweetTokenizer\n#from nltk.corpus import stopwords\nfrom nltk.util import ngrams\n\npd.set_option('max_colwidth',400) # show only part of the API request for nicer presentation\nimport msgpack","889fbe39":"info = pd.read_csv('..\/input\/train_info.csv')","f1dc99cf":"with open('..\/input\/train.msgpack', 'rb') as data_file:\n    train = msgpack.unpack(data_file)\nwith open('..\/input\/test.msgpack', 'rb') as data_file:\n    test = msgpack.unpack(data_file)","28b108f5":"train = pd.DataFrame(train)\ntest = pd.DataFrame(test)\ntrain.columns = ['id', 'content']\ntest.columns = ['id', 'content']","43cc49b8":"info.head()","02626c68":"info.injection.value_counts()","7f89ec0a":"print(train.shape)","3eeaa509":"train.head()","06731a97":"train.tail()","19f327f5":"# Guarantee that the content is in the form of str\ntrain['content'] = train['content'].astype(str)\ntest['content'] = test['content'].astype(str)","d814a84c":"print(train.dtypes)","756d87ee":"wordcloud = WordCloud().generate(train['content'].values[6])\n\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","18c9540a":"vectorizer = TfidfVectorizer(ngram_range=(1, 3), analyzer='char')\nfull_text = list(train['content'].values) + list(test['content'].values)\nvectorizer.fit(full_text)\ntrain_vectorized = vectorizer.transform(train['content'])\ntest_vectorized = vectorizer.transform(test['content'])","7916d23b":"train_info = pd.merge(train, info, on='id') # map each id's content to its maliciousness","a450385c":"y = np.array([1 if i == True else 0 for i in train_info.injection.values]) # the maliciousness is converted from boolean to integer","80cd1799":"logreg = LogisticRegression(solver='liblinear')\n\nparam_grid = {'C':[1,5,10]} \n\ngscv = GridSearchCV(logreg,param_grid,cv=5,scoring='roc_auc')\n#gscv.fit(train_vectorized,y)\n#print(\"Best C value: {}\".format(gscv.best_params_['C']))\n#print(\"Roc_Auc Score: {0:.2f}%\".format(gscv.best_score_) * 100)","3f365295":"logreg = LogisticRegression(solver='liblinear',C=1)","a2bae177":"scores = cross_val_score(logreg, train_vectorized, y, scoring='roc_auc', n_jobs=-1, cv=5)\nprint('Cross-validation mean auc {0:.2f}%, std {1:.2f}.'.format(np.mean(scores) * 100, np.std(scores) * 100))","a4b1096f":"logreg.fit(train_vectorized, y)","677514bc":"eli5.show_weights(logreg, vec=vectorizer,  targets=[0, 1])","b65c4721":"eli5.show_prediction(logreg, doc=train['content'].values[6], vec=vectorizer)","2cc880a5":"rdge = Ridge()\n\nparam_grid = {'alpha':np.logspace(-1,1,3)} \n\ngscv = GridSearchCV(rdge,param_grid,cv=5, scoring='roc_auc')\n#gscv.fit(train_vectorized,y)\n#print(\"Best alpha value: {}\".format(gscv.best_params_['alpha']))\n#print(\"Roc_Auc Score: {0:.2f}%\".format(gscv.best_score_) * 100)","9ad086a8":"rdge = Ridge(alpha=10)","8765b5d9":"scores = cross_val_score(rdge, train_vectorized, y, scoring='roc_auc', n_jobs=-1, cv=5)\nprint('Cross-validation mean auc {0:.2f}%, std {1:.2f}.'.format(np.mean(scores) * 100, np.std(scores) * 100))","e790dc56":"rfc=RandomForestClassifier(random_state=42)\n\nparam_grid = {\n    'n_estimators': [100, 200, 500]\n}\n\ngscv = GridSearchCV(rfc,param_grid,cv=5,scoring='roc_auc')\n#gscv.fiit(train_vectorized,y)\n#print(\"Best n_estimator value: {}\".format(gscv.best_params_['n_estimators']))\n#print(\"Roc_Auc Score: {0:.2f}%\".format(gscv.best_score_) * 100)","fadc888f":"rfc = RandomForestClassifier(random_state=40,n_estimators=100)","66ed51b8":"scores = cross_val_score(logreg, train_vectorized, y, scoring='roc_auc', n_jobs=-1, cv=5)\nprint('Cross-validation mean auc {0:.2f}%, std {1:.2f}.'.format(np.mean(scores) * 100, np.std(scores) * 100))","55297252":"### Importing Libraries","dc3fe029":"### Random Forest Classifier\nRandom forests are bagged decision tree models that split on a subset of features on each split. It has high performance, is robust to outliers and non-linear data, and has low bias and moderate variance. However, they have a tendency of overfitting and are not interpretable.","ad511787":"### Machine Learning in Networking\n\nTeam members: Bohan, Kerk, Yi Tian, Issac\n\nObjective: Given the API request, determine if the request is malicious (ie injecting).\n\nMachine learning category: It is clear that this is a classification problem since the API request can only be malicious or not. Supervised learning classification algorithm should be used as the dataset indicates if the request was malicious or not.\n\nRelevant algorithms would be Logistic Regression, Ridge Regression, Random Forest Classification etc.","c9cb5ae9":"### Preprocessing\nNormally for Natural Language Processing, preprocessing would include removing stop words, lowercasing, stemming, normalization etc.\nHowever, as this is code, and most of the API request's contents are obfuscated, as shown from train.head() in the data exploration, most of such preprocessing would be useless and perhaps detrimental, as it is difficult to identify stop words and stemming for words used in code, while lowercasing and normalization might affect the meaning of the code itself. Noise removal is also highly challenging as it is difficult to distinguish between noise and the signals that the API request is malicious.\n\nHence the only preprocessing done is to convert the content of the API's into vectors such that it is approachable to machine learning. This is done by vectorizing the text\nBoth countvectorizer and tfidfvectorizer was considered. Countvectorizer counts the number of occurences of the words in the API request, while, tfidfvectorizer assign a score for each word proportional to how often the words appear in the API request, while being inversely proportional to how often it appears in different API request, hence it gives more weight to words that are uniquely salient to the API request, which are more likely to predict if it is malicious or not. Hence, tfidvectorizer was selected.\n\nDue to the nature of the content of the API request, it should be vectorized by characters. ngrams is chosen to range from 1-4 so that small groups of malicious characters can be identified.","654103e7":"### Logistic Regression\n\nLogistic Regression is chosen as it is simple to implement, while there is no obvious outliers in the data, while the predictors do not appear to have any significant correlation. (the given API's content vary widely) However, it may not detect \n\nHyper parameter tuning is done with grid search CV, which is to test various tuning of the important parameters of the given algorithm and select the parameter that is most successful.\n\nCross-validation is used instead of train-test splits as it allow the model to train on multiple train-test splits, giving a better indication of how well the model will perform on unseen data.\n\nThe scoring algorithm is chosen as roc_auc because we care equally about true positive and true negative rates, while our data is well balanced, with 49% true and 51% false. roc_auc  is even more useful as it tells us how good the model is at ranking predictions, giving the probability that a randomly chosen positive instance is ranked higher than a randomly chosen negative instance.\nAccuracy is also used, as it place equal importance on true positive and true negative rates, and our data is well balanced, hence it will also give a good idea of how well the algorithm performs.\nOther scoring algorithm such as f1_score, which was rejected as it does not consider true negative rates.","39f4bfd1":"### Loading data\nThe data is given in msgpack and is read as bytes.","e291be38":"From the data visualization, we can observe that info contain ID and whether the API request was malicious, while train contains ID and the contents of the API request. Below is a tag cloud showing the terms used.","aa421c50":"### Ridge Regression\nRidge Regression aim to regularize the terms, and it uses L2 regularization, which is a minimizing a loss function with a regularization term in it compared to logistic regression. Hence, it is less likely to cause overfitting, hence it should possibly inprove the score. This comes at the cost of lower performance.","4b0e3cb8":"### Data Exploration\n\nUnfortunately, the dataset is given as a chunk of text for each API request, and there is little to visualize graphically."}}