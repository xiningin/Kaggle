{"cell_type":{"392c2769":"code","74322076":"code","a444c766":"code","6135264a":"code","63ccda03":"code","d3328542":"code","72495947":"code","78088cd2":"code","5eaf518d":"code","090636ec":"code","652160bd":"code","5cd4b6b2":"code","3593914a":"markdown","f69b5ab9":"markdown","bcd4bed4":"markdown","b5360cd0":"markdown","4ab0b392":"markdown","4887505c":"markdown","4ebb59ae":"markdown","a5576fd3":"markdown","782035d9":"markdown","598f415e":"markdown"},"source":{"392c2769":"import os.path\n\nimport numpy as np\nimport pandas as pd\nfrom keras.layers import Dense, Input, Dropout\nfrom keras.models import Model, load_model\nfrom keras import optimizers\nfrom keras import regularizers\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","74322076":"base_path = '\/kaggle\/input\/titanic\/'\nmodel_file = 'mod.h5'\nperformance_file = base_path + 'perf.csv'\ntrainset = base_path + 'train.csv'\nepochs = 3200\nnp.random.seed(1244)\n","a444c766":"def process_X(df):\n    X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n    X['Sex'] = X['Sex'].map({\"male\": 0, \"female\":1}) \n    # fill Embarked with the most common value\n    X['Embarked'].fillna(\"S\", inplace=True)\n    X['Embarked'] = X['Embarked'].map({'S': 0, 'C':1, 'Q': 2})\n    # Fill age with the negative value\n    X['Age'].fillna(-1, inplace=True)\n    # Extract title\n    dataset_title = pd.Series([i.split(\",\")[1].split(\".\")[0].strip() for i in df[\"Name\"]])\n    le = preprocessing.LabelEncoder()\n    le.fit(dataset_title)\n    X[\"Title\"] = le.transform(dataset_title)\n    X['Title'].fillna(-1, inplace=True)\n    \n    X = (X - X.mean()) \/ X.std()\n    return X\n","6135264a":"def read_dataset(filename):\n    df = pd.read_csv(filename, low_memory=False)\n    msk = np.random.rand(len(df)) < 0.85\n    dev = df[~msk]\n    train = df[msk]\n\n    X_train = process_X(df)\n    Y_train = df['Survived'].values\n\n    return X_train, Y_train\n","63ccda03":"X_train, Y_train = read_dataset(trainset)\nprint(X_train.columns)","d3328542":"def gen_model(input_shape):\n\n    biasl1=0\n    kernell1=0\n    biasl2=0.03\n    kernell2=0.03\n\n    X_input = Input(shape=input_shape)\n\n    X = Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=kernell1, l2=kernell2) ,bias_regularizer=regularizers.l1_l2(l1=biasl1, l2=biasl2))(X_input)\n    X = Dense(32, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=kernell1, l2=kernell2) ,bias_regularizer=regularizers.l1_l2(l1=biasl1, l2=biasl2))(X)\n    X = Dense(16, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=kernell1, l2=kernell2) ,bias_regularizer=regularizers.l1_l2(l1=biasl1, l2=biasl2))(X)\n    X = Dense(16, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=kernell1, l2=kernell2) ,bias_regularizer=regularizers.l1_l2(l1=biasl1, l2=biasl2))(X)\n    X = Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l1_l2(l1=kernell1, l2=kernell2) ,bias_regularizer=regularizers.l1_l2(l1=biasl1, l2=biasl2))(X)\n\n    m = Model(inputs=X_input, outputs=X)\n    m.summary()\n    opt = optimizers.Adam(learning_rate=0.0001, decay=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n    m.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n\n    return m\n","72495947":"model = None\nif os.path.exists(model_file):\n    print(\"Going to load model\")\n    model = load_model(model_file)\nelse:\n    print(\"Going to generate a new model\")\n    model = gen_model(input_shape=(X_train.shape[1],))\n","78088cd2":"model_result = model.fit(X_train, Y_train, batch_size=64, epochs=2500, validation_split=0.2, shuffle=True, verbose=2)\n","5eaf518d":"plt.figure(figsize=(30, 10))\n\nplt.subplot(1, 2, 1)\nplt.plot(model_result.history[\"loss\"], label=\"training\")\nplt.plot(model_result.history[\"val_loss\"], label=\"validation\")\nplt.axhline(0.55, c=\"red\", linestyle=\"--\")\nplt.axhline(0.35, c=\"yellow\", linestyle=\"--\")\nplt.axhline(0.15, c=\"green\", linestyle=\"--\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(model_result.history[\"accuracy\"], label=\"training\")\nplt.plot(model_result.history[\"val_accuracy\"], label=\"validation\")\nplt.axhline(0.75, c=\"red\", linestyle=\"--\")\nplt.axhline(0.80, c=\"green\", linestyle=\"--\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\n\nplt.show()","090636ec":"def generateSubmission(m):\n    df = pd.read_csv(base_path + 'test.csv', low_memory=False)\n    X_test = process_X(df)\n    Y = m.predict(X_test)\n    ids = range(892, 1310)\n\n    submission = open(\"submission.csv\", \"w+\")\n    submission.write(\"PassengerId,Survived\\n\")\n\n    for i in range(0, len(ids)):\n        id = ids[i]\n        if Y[i] > 0.5:\n            survived = 1\n        else:\n            survived = 0\n        submission.write(str(id) + ',' + str(survived) + '\\n')\n","652160bd":"generateSubmission(model)","5cd4b6b2":"model.save(\"mod.h5\")","3593914a":"Define input features processing:\n1. Replace missing values by constants (-99)\n2. Normalize all inputs","f69b5ab9":"Import libraries","bcd4bed4":"Plot graphs","b5360cd0":"Train model","4ab0b392":"Prepare submission file","4887505c":"Read data from input file and split it to train\/dev set","4ebb59ae":"Prepare global constants","a5576fd3":"Read input data","782035d9":"Create a simple Keras model","598f415e":"Save model"}}