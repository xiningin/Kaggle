{"cell_type":{"9b06d704":"code","f38c3434":"code","a08e6c64":"code","47e4f663":"code","e484cc03":"code","3e24f9fd":"code","2e617213":"code","41a5f4b0":"code","42648d74":"code","87b05af1":"code","f36e033e":"code","5eb4f004":"code","eb848eb6":"code","661c2646":"code","866971d1":"code","919cd250":"code","d984c507":"code","1d78de30":"code","4e2e472a":"code","12d8cfcd":"code","7cc806ea":"code","bbbc4a6b":"code","4b82dfcd":"code","6b5502b6":"code","d3ce025b":"code","7f768813":"code","efc89a79":"code","793ff2d8":"code","1435beef":"code","54b774c6":"code","6696be28":"code","1ccb90bf":"code","d64e49b3":"code","2308c995":"code","9a7f32e1":"code","40dce261":"code","93a1ab15":"code","84b4056a":"code","a547b8a6":"code","2b30767a":"code","5101cca4":"code","2f779f8a":"code","b7bc148f":"code","2df579aa":"code","136cca5e":"code","3e4e8491":"code","6053ffed":"code","20f569ee":"code","af9e0225":"code","b37a602c":"code","c0c81c25":"code","fbbfadd8":"code","9ad6817f":"code","bee22f62":"code","bc54a508":"code","dcf02312":"code","4b1c7351":"markdown","522702c1":"markdown","60c7125e":"markdown","ad483f6b":"markdown","33361022":"markdown","9cae0058":"markdown","51d99ccc":"markdown","9d3b0eea":"markdown","f305ba63":"markdown","96f9448a":"markdown","02ed863b":"markdown","0f86dd6d":"markdown","c7aa05da":"markdown","e4abb3df":"markdown","947b1507":"markdown","84e90556":"markdown","0ce13f40":"markdown","807185bc":"markdown","b15637eb":"markdown","5bbfc7a8":"markdown","d17b7635":"markdown","769f1f9e":"markdown","25722730":"markdown"},"source":{"9b06d704":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport requests\nimport seaborn as sns\nimport scipy.stats as ss\nimport sklearn.linear_model as lm\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor as vif\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","f38c3434":"df = pd.read_csv('\/kaggle\/input\/airline\/airline.csv')","a08e6c64":"df.columns","47e4f663":"df = df.drop('Unnamed: 0',axis=1)","e484cc03":"df.describe()","3e24f9fd":"df.info()","2e617213":"df.select_dtypes(include=['object']).nunique()","41a5f4b0":"#No null values in the dataset\ndf.isnull().values.any()","42648d74":"plt.figure(figsize=(20,8))\n\nplt.subplot(1,2,1)\nplt.title('Market Share')\nsns.distplot(df['market share'])\n\nplt.subplot(1,2,2)\nplt.title('Market Share.1')\nsns.boxplot(y=df['market share'])\n\nplt.show()","87b05af1":"plt.figure(figsize=(20,8))\n\nplt.subplot(1,2,1)\nplt.title('Market Share')\nsns.distplot(df['market share.1'])\n\nplt.subplot(1,2,2)\nplt.title('Market Share.1')\nsns.boxplot(y=df['market share.1'])\n\nplt.show()","f36e033e":"print(df['market share.1'].describe(percentiles = [0.25,0.50,0.75,0.85,0.90,1]))","5eb4f004":"plt.figure(figsize=(20,8))\n\nplt.subplot(1,2,1)\nplt.title('Average fare_1')\nsns.distplot(df['Average Fare'])\n\nplt.subplot(1,2,2)\nplt.title('Average fare_1')\nsns.boxplot(y=df['Average Fare'])\n\nplt.show()","eb848eb6":"#Average fare of\nplt.figure(figsize=(20,8))\n\nplt.subplot(1,2,1)\nplt.title('Average fare')\nsns.distplot(df['Average fare'])\n\nplt.subplot(1,2,2)\nplt.title('Average fare_2')\nsns.boxplot(y=df['Average fare'])\n\nplt.show()","661c2646":"plt.figure(figsize=(50, 20))\n\nplt.subplot(1,2,2)\nplt1 = df['City1'].value_counts().plot('bar')\nplt.title('City1 Histogram')\nplt1.set(xlabel = 'City1', ylabel='Frequency of City1')\n\nplt.show()","866971d1":"plt.subplot(1,1,1)\nplt3 = df['market leading airline'].value_counts().plot('bar')\nplt.title('market leading airline Histogram')\nplt3.set(xlabel = 'market leading airline', ylabel='Frequency of market leading airline')","919cd250":"plt.subplot(1,1,1)\nplt4 = df['Low price airline'].value_counts().plot('bar')\nplt.title('Low price airline Histogram')\nplt4.set(xlabel = 'Low price airline', ylabel='Frequency of Low price airline')","d984c507":"from IPython.display import display\n\nwith pd.option_context('precision', 2):\n    display(df.groupby(['City1'])['Average Fare'].describe()[['count', 'mean']])","1d78de30":"cats = ['City1','City2','market leading airline','Low price airline']","4e2e472a":"city = df['City1'].append(df['City2'])\nairlines = df['market leading airline'].append(df['Low price airline'])","12d8cfcd":"print('unique locations: {} | unique airlines: {}'.format(city.nunique(), airlines.nunique()))","7cc806ea":"df[cats] = df[cats].astype('category')","bbbc4a6b":"df_1 = df.apply(lambda x: x.cat.codes if x.dtype.name == 'category' else x)","4b82dfcd":"sns.pairplot(df);","6b5502b6":"fig,ax = plt.subplots(figsize=(8,6))\nsns.heatmap(df_1.corr(),vmin=-0.8, annot=True, cmap='coolwarm',ax=ax);","d3ce025b":"def scatter(x,fig):\n    plt.subplot(5,2,fig)\n    plt.scatter(df_1[x],df_1['price'])\n    plt.title(x+' vs Price')\n    plt.ylabel('Price')\n    plt.xlabel(x)\n\nplt.figure(figsize=(10,20))\n\nscatter('Average Fare', 1)\nscatter('Average fare', 2)\n\nplt.tight_layout()","7f768813":"def pp(x,y,z):\n    sns.pairplot(df_1, x_vars=[x,y,z], y_vars='price',size=4, aspect=1, kind='scatter')\n    plt.show()\n\npp('market leading airline', 'Average fare', 'market share')\n\npp('Low price airline', 'Average weekly passengers', 'market share.1')","efc89a79":"from sklearn.model_selection import train_test_split\n\nnp.random.seed(0)\ndf_train, df_test = train_test_split(df_1, train_size = 0.7, test_size = 0.3, random_state = 100)","793ff2d8":"#Dividing data into X and y variables\ny_train = df_train.pop('Average Fare')\nX_train = df_train","1435beef":"lm = LinearRegression()\nlm.fit(X_train,y_train)\nrfe = RFE(lm, 10)\nrfe = rfe.fit(X_train, y_train)","54b774c6":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","6696be28":"X_train.columns[rfe.support_]","1ccb90bf":"X_train_rfe = X_train[X_train.columns[rfe.support_]]\nX_train_rfe.head()","d64e49b3":"def build_model(X,y):\n    X = sm.add_constant(X) #Adding the constant\n    lm = sm.OLS(y,X).fit() # fitting the model\n    print(lm.summary()) # model summary\n    return X\n    \ndef checkVIF(X):\n    vif = pd.DataFrame()\n    vif['Features'] = X.columns\n    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    return(vif)","2308c995":"X_train_new = build_model(X_train_rfe,y_train)","9a7f32e1":"X_train_new = X_train_rfe.drop([\"City2\"], axis = 1)","40dce261":"X_train_new = build_model(X_train_new,y_train)","93a1ab15":"X_train_new = X_train_new.drop([\"City1\"], axis = 1)","84b4056a":"X_train_new = build_model(X_train_new,y_train)","a547b8a6":"#Calculating the Variance Inflation Factor\ncheckVIF(X_train_new)","2b30767a":"X_train_new = X_train_new.drop([\"Average fare\"], axis = 1)","5101cca4":"X_train_new = build_model(X_train_new,y_train)","2f779f8a":"checkVIF(X_train_new)","b7bc148f":"X_train_new = X_train_new.drop([\"Distance\"], axis = 1)","2df579aa":"X_train_new","136cca5e":"X_train_new = build_model(X_train_new,y_train)","3e4e8491":"X_train_new = X_train_new.drop([\"Average weekly passengers\"], axis = 1)","6053ffed":"X_train_new = build_model(X_train_new,y_train)","20f569ee":"checkVIF(X_train_new)","af9e0225":"lm = sm.OLS(y_train,X_train_new).fit()\ny_train_price = lm.predict(X_train_new)","b37a602c":"# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_price), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18)   ","c0c81c25":"#Dividing into X and y\ny_test = df_test.pop('Average Fare')\nX_test = df_test","fbbfadd8":"# Now let's use our model to make predictions.\nX_train_new = X_train_new.drop('const',axis=1)\n# Creating X_test_new dataframe by dropping variables from X_test\nX_test_new = X_test[X_train_new.columns]\n\n# Adding a constant variable \nX_test_new = sm.add_constant(X_test_new)","9ad6817f":"# Making predictions\ny_pred = lm.predict(X_test_new)","bee22f62":"from sklearn.metrics import r2_score \nr2_score(y_test, y_pred)","bc54a508":"#EVALUATION OF THE MODEL\n# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure()\nplt.scatter(y_test,y_pred)\nfig.suptitle('y_test vs y_pred', fontsize=20)              # Plot heading \nplt.xlabel('y_test', fontsize=18)                          # X-label\nplt.ylabel('y_pred', fontsize=16) ","dcf02312":"print(lm.summary())","4b1c7351":"# Conclusion","522702c1":"Model-6","60c7125e":"Model-5","ad483f6b":"Inference:\n    \n- 19 Unique Airlines and For locations, however, a set of 104 would quickly clutter the model interpretability and fare prediction\n\n- To overcome the above problem, instead of treating them as category,convert City1, City2 and all airlines to Integers for a better learning in linear regression which can find relation with Average Fare(target variable)\n\n- This comes as no surprise as quite often, the leading airline controls such a large portion of the market share that they effectively set the price.","33361022":"Model-4","9cae0058":"dropping Average fare because of high VIF value. (we have already seen this high multicollinearity in above scatterplot)","51d99ccc":"Inference :\n    \n-The plot seemed to be right-skewed, meaning that the most market share in the dataset are low(Below 40).\n\n-There is a significant difference between the mean and the median of the market share distribution.\n\n-The data points are far spread out from the mean, which indicates a high variance in the share prices.\n\n-On the other hand 'Average Fare' as dependent variable as a quite similarity between my 'Average fare' Independent variable\n","9d3b0eea":"Model-2","f305ba63":"# Model Building","96f9448a":"Residual Analysis of Model","02ed863b":"1.R-sqaured and Adjusted R-squared (extent of fit) - 0.843 and 0.843 - 84% variance explained.\n\n2.F-stats and Prob(F-stats) (overall model fit) - 744.0 and 9.63e-276(approx. 0.0) - Model fit is significant and explained 84% variance is just not by chance.\n\n3.p-values - p-values for all the coefficients seem to be less than the significance level of 0.05. - meaning that all the predictors are statistically significant.\n\n4.The most important features from the above analysis are market leading airline,low price airline and their market share with actual fare in each itiniary becuase from the interpretation made in EDA, it is as clearly visible that top-3 market leading airlines are same as low price airline i.e they have a great hold on market. \n\n5.However, feature set has to encapsulate more information like day, timing and booking details.The most important feature in the flight pricing prediction is the the day is a holiday or not, the day is weekday or weekend and the difference between the days.\n\n6.Gradient boosting can be a better optimized model here with the theoritic aspect. The loss function is a measure indicating how good are model\u2019s coefficients are at fitting the underlying data. A logical understanding of loss function would depend on what we are trying to optimise. For example, if we are trying to predict the average prices by using a regression, then the loss function would be based off the error between true and predicted average prices. One of the biggest motivations of using gradient boosting is that it allows one to optimise a user specified cost function, instead of a loss function that usually offers less control and does not essentially correspond with real world applications.\n","0f86dd6d":"# Import Librararies","c7aa05da":"Model-1","e4abb3df":"\u2022 Find the most important features of this dataset to predict the average fair.\n\n\u2022 Figure out what other model can be applied to improve the model performance.\n\n\u2022 What are other ways this data can be improved which will help in improving the Prediction.","947b1507":"p-vale of City2 seems to be higher than the significance value of 0.05, hence dropping it as it is insignificant in presence of other variables.\n","84e90556":"# Prediction and Evaluation","0ce13f40":"# EDA","807185bc":"# Problem Statement\n","b15637eb":"Inference:\n\n-There is a good deal of overlap between the two city columns and two airline columns. ","5bbfc7a8":"Model-3","d17b7635":"dropping Distance because of high VIF value.","769f1f9e":"p-vale of City1 seems to be higher than the significance value of 0.05, hence dropping it as it is insignificant in presence of other variables.","25722730":"#Visualising Categorical Data\n"}}