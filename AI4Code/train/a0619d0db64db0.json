{"cell_type":{"fb77aedb":"code","3a1cac34":"code","ea9975e3":"code","eb80cf74":"code","0100f784":"code","82d0aeb9":"code","8ee4f053":"code","0df55210":"code","008577a0":"code","00725cdc":"code","66927f57":"code","7381c6a4":"code","a91c1dde":"code","5a1f42f2":"code","af23ce0e":"code","ddf722c9":"code","55599c38":"code","787034a4":"code","3a057ae3":"code","247c545f":"code","87ccc290":"code","3f5a869c":"code","50e01271":"code","b5a75b22":"code","7cbabbf8":"code","45fb9d11":"code","02aa2325":"code","1d142141":"code","80ca16b8":"code","cd9506b3":"code","fc9075f6":"code","00e1ee7a":"code","8f9a9654":"code","959deb24":"code","fc4f1290":"code","cf8e616e":"code","369874da":"code","a9fe2b86":"code","e6eb823a":"code","5dd9e661":"code","c4e84f80":"code","5bfc7ca1":"code","6b8918c8":"code","3b080e65":"code","25a21cb6":"code","f720e70a":"code","5b63e6cc":"code","be27a058":"code","9b83b6dc":"code","fcc4ba4b":"code","d64be6cb":"code","7e0c4e7c":"code","65c95db5":"code","97c20642":"code","5d18a089":"code","3509788d":"code","1027b940":"code","df508fb6":"code","9f5664b4":"code","e50e412d":"code","0fb60d82":"code","e8a0f8eb":"code","1f2438c7":"code","c46b33ed":"code","9b1accbb":"code","4cb4816b":"code","d2c62755":"code","3b6f27aa":"code","097f2755":"code","05905938":"code","4973424c":"markdown","13be408c":"markdown","1dcc3979":"markdown","137ae770":"markdown","33ba8e38":"markdown","06577c37":"markdown","222bccb7":"markdown","c1975d3b":"markdown","f9df18f4":"markdown","5c32f563":"markdown","012fa74f":"markdown","4a282c84":"markdown","c8d7d5f4":"markdown","ee0b939a":"markdown","4dfe427c":"markdown","ffb943ee":"markdown","7b658f34":"markdown","c8d4a53a":"markdown","e8226a29":"markdown","5eeee6ba":"markdown","6b7573b7":"markdown","4d483e07":"markdown"},"source":{"fb77aedb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set a few plotting defaults\n%matplotlib inline\nplt.style.use('fivethirtyeight')\nplt.rcParams['font.size'] = 18\nplt.rcParams['patch.edgecolor'] = 'k'","3a1cac34":"def plotar(variaveis,eixoX,titulo):\n    eixoY = []\n    for v in variaveis: \n        eixoY.append(df[v].value_counts()[1])\n    \n    plt.figure(figsize=(20,5))\n    sns.barplot(x = eixoX,y = eixoY).set_title(titulo)\n    plt.show()","ea9975e3":"#Carregar os dados dos datasets\ndf = pd.read_csv('\/kaggle\/input\/costa-rican-household-poverty-prediction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/costa-rican-household-poverty-prediction\/test.csv')\n\ndf.shape, test.shape","eb80cf74":"# Chefes de fam\u00edlia\nheads = df.loc[df['parentesco1'] == 1].copy()\n\n\n\n# Vari\u00e1veis para treinamento\ntrain_campos = df.loc[(df['Target'].notnull()) & (df['parentesco1'] == 1), ['Target', 'idhogar']]\n\n# Quantidade de chefes conforme a calissifica\u00e7\u00e3o\nl_counts = train_campos['Target'].value_counts().sort_index()\n\nl_counts\n","0100f784":"Parentes = 'Parentesco'\nvariaveis = 'parentesco1','parentesco2','parentesco3','parentesco4','parentesco5','parentesco6','parentesco7','parentesco8','parentesco9','parentesco10','parentesco11','parentesco12'\neixoX = ['Chefe de fam\u00edlia','C\u00f4njugue','Filho','Divorciado','Genro\/Nora','Neto','Pai','Sogro','Irm\u00e3o','Cunhada','Outro Familiar','Outro N\u00e3o Familiar']\nplotar(variaveis,eixoX,Parentes)","82d0aeb9":"# Verifica\u00e7\u00e3o de fam\u00edlias onde os indiv\u00edduos no mesmo domic\u00edlio t\u00eam um n\u00edvel de pobreza diferente na base de treino\n# Agrupa as fam\u00edlias para verificar os valores \u00fanicos\nall_equal = df.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\n\n# Fam\u00edlias onde as metas n\u00e3o s\u00e3o todas iguais\nnot_equal = all_equal[all_equal != True]\nprint('Encontramos {} Individuos na mesma familia no mesmo dom\u00edcilio que possuem um n\u00edvel de probreza diferente e precisamos corrigir.'.format(len(not_equal)))","8ee4f053":"# Itera\u00e7\u00e3o com cada familia\nfor household in not_equal.index:\n    # Localizar a classifica\u00e7\u00e3o correta do chefe para cada familia\n    true_target = int(df[(df['idhogar'] == household) & (df['parentesco1'] == 1.0)]['Target'])\n    \n    # Definindo a target correta para todos os membros da fam\u00edlia\n    df.loc[df['idhogar'] == household, 'Target'] = true_target\n    \n    \n# Agrupando a fam\u00edliapara decobrir o n\u00famero de valores \u00fanicos\nall_equal = df.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\n\n# Fam\u00edlias onde as metas n\u00e3o s\u00e3o todas iguais\nnot_equal = all_equal[all_equal != True]\nprint('Encontramos {} familias no mesmo dom\u00edcilio que possuem um n\u00edvel de probreza diferente.'.format(len(not_equal)))","0df55210":"households_leader = df.groupby('idhogar')['parentesco1'].sum()\n\n# verifica\u00e7\u00e3o de familias sem chefe\nhouseholds_no_head = df.loc[df['idhogar'].isin(households_leader[households_leader == 0].index), :]\n\nprint('There are {} households without a head.'.format(households_no_head['idhogar'].nunique()))\n\n\n\n","008577a0":"# Verifica\u00e7\u00e3o das fam\u00edlias sem chefe e com classifica\u00e7\u00e3o diferente\nhouseholds_no_head_equal = households_no_head.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\nprint('{} Households with no head have different labels.'.format(sum(households_no_head_equal == False)))","00725cdc":"df_all = df.append(test)\n\ndf_all.shape","66927f57":"df_all.drop('area2', axis = 1, inplace = True)","7381c6a4":"# Criando a vari\u00e1vel com as caracteristicas das paredes da casa\ndf_all['walls'] = np.argmax(np.array(df_all[['epared1', 'epared2', 'epared3']]),\n                           axis = 1)\ndf_all = df_all.drop(columns = ['epared1', 'epared2', 'epared3'])\n","a91c1dde":"df_all['walls'].value_counts()","5a1f42f2":"# Roof ordinal variable\n#df_all['roof'] = np.argmax(np.array(df_all[['etecho1', 'etecho2', 'etecho3']]),\n#                           axis = 1)\n#df_all = df_all.drop(columns = ['etecho1', 'etecho2', 'etecho3'])","af23ce0e":"#df_all['roof'].value_counts()","ddf722c9":"# Floor ordinal variable\n#df_all['floor'] = np.argmax(np.array(df_all[['eviv1', 'eviv2', 'eviv3']]),\n #                          axis = 1)\n#df_all = df_all.drop(columns = ['eviv1', 'eviv2', 'eviv3'])","55599c38":"#df_all['floor'].value_counts()","787034a4":"# Create new feature\n#df_all['walls+roof+floor'] = df_all['walls'] + df_all['roof'] + df_all['floor']","3a057ae3":"#df_all['walls+roof+floor'].value_counts()","247c545f":"# Verificando os valores nulos\ndf_all.isnull().sum().sort_values()","87ccc290":"df_all.select_dtypes('object').head()","3f5a869c":"# Analisando os dados da coluna edjefa\ndf_all['edjefa'].value_counts()","50e01271":"# Analisando os dados da coluna edjefe\ndf_all['edjefe'].value_counts()","b5a75b22":"mapeamento = {'yes': 1, 'no': 0}\n\ndf_all['edjefa'] = df_all['edjefa'].replace(mapeamento).astype(int)\ndf_all['edjefe'] = df_all['edjefe'].replace(mapeamento).astype(int)","7cbabbf8":"# Verificando a sobreposi\u00e7\u00e3o dos dados para o masculino\ndf_all['edjefe'].value_counts()","45fb9d11":"# Verificando a sobreposi\u00e7\u00e3o dos dados para o Feminino\ndf_all['edjefa'].value_counts()","02aa2325":"# COntinua\u00e7\u00e3o da verifica\u00e7\u00e3o das variaveis que s\u00e3o do tipo Object\ndf_all.select_dtypes('object').head()","1d142141":"# Verificando a coluna dependence\ndf_all['dependency'].value_counts().sort_values()","80ca16b8":"# Sobrepondo os dados da coluna dependency conforme o mapeamento e tranformando em tipo float\ndf_all['dependency'] = df_all['dependency'].replace(mapeamento).astype(float)","cd9506b3":"df_all['dependency'].value_counts()","fc9075f6":"df_all['dependency'].isnull().sum()","00e1ee7a":"# COntinua\u00e7\u00e3o da verifica\u00e7\u00e3o das variaveis que s\u00e3o do tipo Object\ndf_all.select_dtypes('object').head()","8f9a9654":"# verificando as informa\u00e7\u00f5es do data set\ndf_all.info()","959deb24":"# Verificando os valores nulos\ndf_all.isnull().sum().sort_values()","fc4f1290":"df_all['Target'].value_counts()","cf8e616e":"# Verificando os valores de aluguel (v2a1) para os chefes de familia (parentesco = 1)\ndf_all[df_all['parentesco1'] == 1]['v2a1'].isnull().sum()","369874da":"# Verificando os dados de  v2a1 - pagamento do valor de aluguel\ndf_all['v2a1'].value_counts()","a9fe2b86":"df_all['v2a1'].isnull().sum()","e6eb823a":"# Verificando os dados de v18q\ndf_all['v18q'].value_counts()","5dd9e661":"df_all['v18q'].isnull().sum()","c4e84f80":"# Verificando os dados de v18q1 \ndf_all['v18q1'].value_counts()","5bfc7ca1":"df_all['v18q1'].isnull().sum()","6b8918c8":"# Prenchendo com -1 os valores nulos de v2a1\ndf_all['v2a1'].fillna(-1, inplace=True)","3b080e65":"# Prenchendo com 0 os valores nulos de v18q1\ndf_all['v18q1'].fillna(0, inplace=True)","25a21cb6":"# Prenchendo com -1 os valores nulos de SQBmeaned, meaneduc e rez_esc\ndf_all['SQBmeaned'].fillna(-1, inplace=True)\ndf_all['meaneduc'].fillna(-1, inplace=True)\ndf_all['rez_esc'].fillna(-1, inplace=True)","f720e70a":"df_all.isnull().sum().sort_values()","5b63e6cc":"# Feature Engineering\n\n# Vamos criar novas colunas para valores percapita\ndf_all['phone-pc'] = df_all['qmobilephone'] \/ df_all['tamviv']\ndf_all['tablets-pc'] = df_all['v18q1'] \/ df_all['tamviv']\ndf_all['rooms-pc'] = df_all['rooms'] \/ df_all['tamviv']\ndf_all['rent-pc'] = df_all['v2a1'] \/ df_all['tamviv']","be27a058":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]\n\n","9b83b6dc":"# Separar os dataframes\ntrain, test = df_all[~df_all['Target'].isnull()], df_all[df_all['Target'].isnull()]\n\ntrain.shape, test.shape","fcc4ba4b":"# Instanciando o random forest classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_jobs=-1, n_estimators=200, random_state=42)","d64be6cb":"# Treinando o modelo\nrf.fit(train[feats], train['Target'])\n","7e0c4e7c":"df_all['Target'].value_counts().sort_values()","65c95db5":"# Prever o Target de teste usando o modelo treinado\ntest['Target'] = rf.predict(test[feats]).astype(int)","97c20642":"# Vamos verificar as previs\u00f5es\ntest['Target'].value_counts(normalize=True)","5d18a089":"# Trabalhando com AdaBoost\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score\nabc = AdaBoostClassifier(n_estimators=200, learning_rate=1.0, random_state=42)\nabc.fit(train[feats], train['Target'])\naccuracy_score(test['Target'], abc.predict(test[feats]))","3509788d":"# Trabalhando com GBM\nfrom sklearn.ensemble import GradientBoostingClassifier\ngbm = GradientBoostingClassifier(n_estimators=200, learning_rate=1.0, max_depth=1, random_state=42)\ngbm.fit(train[feats], train['Target'])\naccuracy_score(test['Target'], gbm.predict(test[feats]))","1027b940":"# Criando o arquivo para submiss\u00e3o\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","df508fb6":"#Avaliando a importancia de cada coluna\nimport matplotlib.pyplot as plt\nfig=plt.figure(figsize=(25,30))\n    \npd.Series(rf.feature_importances_, index=feats).sort_values().plot.barh()","9f5664b4":"# Limitando o treinamento ao chefe da familia\n\n# Criando um novo dataframe para treinar\nheads = train[train['parentesco1'] == 1]","e50e412d":"# Feature Engineering\n\n# Vamos criar novas colunas para valores percapita\nheads['hsize-pc'] = heads['hhsize'] \/ heads['tamviv']\nheads['phone-pc'] = heads['qmobilephone'] \/ heads['tamviv']\nheads['tablets-pc'] = heads['v18q1'] \/ heads['tamviv']\nheads['rooms-pc'] = heads['rooms'] \/ heads['tamviv']\nheads['rent-pc'] = heads['v2a1'] \/ heads['tamviv']","0fb60d82":"# Criando um novo modelo\nrf2 = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=700,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,\n                            verbose=0, class_weight='balanced')","e8a0f8eb":"# Treinando o modelo\nrf2.fit(heads[feats], heads['Target'])","1f2438c7":"# Prever o Target de teste usando o modelo treinado\ntest['Target'] = rf2.predict(test[feats]).astype(int)","c46b33ed":"# Vamos verificar as previs\u00f5es\ntest['Target'].value_counts(normalize=True)","9b1accbb":"# Trabalhando com AdaBoost\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score\nabc = AdaBoostClassifier(n_estimators=200, learning_rate=1.0, random_state=42)\nabc.fit(heads[feats], heads['Target'])\naccuracy_score(test['Target'], abc.predict(test[feats]))","4cb4816b":"# Trabalhando com GBM\nfrom sklearn.ensemble import GradientBoostingClassifier\ngbm = GradientBoostingClassifier(n_estimators=200, learning_rate=1.0, max_depth=1, random_state=42)\ngbm.fit(heads[feats], heads['Target'])\naccuracy_score(test['Target'], gbm.predict(test[feats]))","d2c62755":"# Criando o arquivo para submiss\u00e3o\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","3b6f27aa":"#Avaliando a importancia de cada coluna\nimport matplotlib.pyplot as plt\nfig=plt.figure(figsize=(25,30))\n    \npd.Series(rf2.feature_importances_, index=feats).sort_values().plot.barh()","097f2755":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\n\n# Imprimir a matriz de confus\u00e3o no modelo de test\nprint(classification_report(Id, Target))\n\n\ncmat = confusion_matrix(Id, Target)\n\n\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.4) # for label size\nsns.heatmap(cmat, annot=True, fmt=\"d\") # font size\n\n\nprint('Verdade Negativo {}'.format(cmat[0,0]))\nprint('Falso Positivo {}'.format(cmat[0,1]))\nprint('Falso Negativo {}'.format(cmat[1,0]))\nprint('Verdadeiro Positivo {}'.format(cmat[1,1]))\nprint('Acur\u00e1cia: {}'.format(np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))))\nprint('Classifica\u00e7\u00e3o: {}'.format(np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))))\n\nerror_rate = []\nacc = []\n\nfor i in range(1,40):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(Id, Target)\n\n    acc.append(knn.score(Id, Target))\n\n    # Plotando o erro\n\nplt.figure(figsize=(10,4))\nplt.plot(range(1,40), acc, color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\nplt.title('Accuracia vs. K-Valores')\nplt.xlabel('K-Valores')\nplt.ylabel('Accuracia')\nplt.show()","05905938":"cm = confusion_matrix('Target', test['prediction'])","4973424c":"Este trabaho teve como objetivo submeter ao Kaggle um valor melhor para a competi\u00e7\u00e3o, mas somente os chefes de fam\u00edlia s\u00e3o usados na pontua\u00e7\u00e3o, o que significa que queremos prever a pobreza em uma base familiar. O valor como parametro foi 0.43719. Ap\u00f3s v\u00e1rias tentativas de melhorar o modelo, conseguimos atingir o melhor valor de 0.43768, atingindo o objetivo de melhoria da pontua\u00e7\u00e3o.\n\nAs an\u00e1lises foram iniciadas a partir do dicionario de dados para o entendimento das caracteristicas das variaveis. O foco inicial foi verificar as fam\u00edlias onde os indiv\u00edduos no mesmo domic\u00edlio tinham um n\u00edvel de pobreza diferente na base de treino, constamos 85 individuos da mesma familia que est\u00e3o em situa\u00e7\u00e3 de probreza diferente. Ao identificar ajustamos os dados para normalizar a classifica\u00e7\u00e3o dos individuos da mesma familia com a mesma situa\u00e7\u00e3o de pobreza.\n\nCom foco no chefe de familia, foi realizada  a verifica\u00e7\u00e3o das familias que n\u00e3o possuiam chefes. Encontramos 15 familias sem chefes e ajustamos.\n\n\n\n\n\n","13be408c":"Explica\u00e7\u00e3o do problema e dos dados: \nOs dados para esta competi\u00e7\u00e3o s\u00e3o fornecidos em dois arquivos: train.csve test.csv. O conjunto de treinamento tem 9557 linhas e 143 colunas, enquanto o conjunto de teste tem 23856 linhas e 142 colunas. Cada linha representa um indiv\u00edduo e cada coluna \u00e9 um recurso, exclusivo para o indiv\u00edduo ou para a fam\u00edlia do indiv\u00edduo . O conjunto de treinamento tem uma coluna adicional Target, que representa o n\u00edvel de pobreza em uma escala de 1 a 4 e \u00e9 o r\u00f3tulo da competi\u00e7\u00e3o. Um valor de 1 \u00e9 a pobreza mais extrema.\n\nEste \u00e9 um problema de aprendizado de m\u00e1quina de classifica\u00e7\u00e3o multi-classe supervisionado :\n\nSupervisionado : fornecido com os r\u00f3tulos dos dados de treinamento\nClassifica\u00e7\u00e3o multiclasse: os r\u00f3tulos s\u00e3o valores discretos com 4 classes\nObjetivo\nO objetivo \u00e9 prever a pobreza ao n\u00edvel do agregado familiar . Recebemos dados em n\u00edvel individual com cada indiv\u00edduo tendo caracter\u00edsticas \u00fanicas, mas tamb\u00e9m informa\u00e7\u00f5es sobre sua fam\u00edlia. Para criar um conjunto de dados para a tarefa, teremos que realizar algumas agrega\u00e7\u00f5es dos dados individuais para cada fam\u00edlia. Al\u00e9m disso, temos que fazer uma previs\u00e3o para cada indiv\u00edduo no conjunto de teste, mas \"SOMENTE os chefes de fam\u00edlia s\u00e3o usados \u200b\u200bna pontua\u00e7\u00e3o\", o que significa que queremos prever a pobreza em uma base familiar.\n\nObserva\u00e7\u00e3o importante: embora todos os membros de uma fam\u00edlia devam ter o mesmo r\u00f3tulo nos dados de treinamento, existem erros onde os indiv\u00edduos na mesma casa t\u00eam r\u00f3tulos diferentes. Nestes casos, somos orientados a usar a etiqueta do chefe de cada fam\u00edlia, que pode ser identificada pelas linhas onde parentesco1 == 1.0. Abordaremos como corrigir isso no caderno (para mais informa\u00e7\u00f5es, d\u00ea uma olhada na discuss\u00e3o principal da competi\u00e7\u00e3o ).\n\nOs Targetvalores representam os n\u00edveis de pobreza da seguinte forma:\n\n1 = Extrema pobreza \n2 = Pobreza moderada\n3 = Fam\u00edlias vulner\u00e1veis \n4 = Fam\u00edlias n\u00e3o vulner\u00e1veis","1dcc3979":"O resultado gerado mostra 143 vari\u00e1veis (considerado muitas vari\u00e1veis).","137ae770":"Verificando os registros da chefe de fam\u00edlia (feminino), conforme a quantidade de anos de escolaridade. Nesse resultado verificamos a quantidade de 22075 mulheres sem escolaridade, o dado est\u00e1 como \"no\" e \"yes\" que \u00e9 igual a 1 a quantidade de 214, vamos tratar os dados adiante., vamos tratar os dados adiante.","33ba8e38":"Vers\u00e3o 10 - verificamos que houve melhoria na pontua\u00e7\u00e3o ap\u00f3s a entrega da vers\u00e3o e da utiliza\u00e7\u00e3o da vari\u00e1ve","06577c37":"Verificando as colunas que s\u00e3o do tipo object (que cont\u00e9m texto), pois o modelo trabalha somente com colunas numericas.","222bccb7":"A base de treino possui 9557 linhas e 143 colunas e a de teste 23856 linhas e 142 colunas. O treino ser\u00e1 realizado com 9557 linhas e a previs\u00e3o ser\u00e1 com as 23856 linhas. As linhas que n\u00e3o possuirem a informa\u00e7\u00e3o de chefe de fam\u00edlia ser\u00e3o desconsideradas pelo Kaggle no resultado final.","c1975d3b":"Unindo os data sets de treino e de teste para verifica\u00e7\u00e3o das caracter\u00edsticas dos dados. Na sequencia dos tratamentos dos dados , as bases de treino e de teste ser\u00e3o separados novamente. Na uni\u00e3o temos 33413 linhas e 143 colunas. Foi criada uma coluna target no data ser de teste.","f9df18f4":"Podemos verificar no resultado acima que n\u00e3o temos mais nenhuma vari\u00e1vel que utilizaremos como object. as vari\u00e1veis ID e idhogar n\u00e3o ser\u00e3o utilizadas.","5c32f563":"C\u00e9lula padr\u00e3o da cria\u00e7\u00e3o de um novo notebook - importando o numpy e o pandas e processa o diret\u00f3rio para mostrar quais arquivos possui.","012fa74f":"Vars\u00e3o 12","4a282c84":"Verificando os registros do chefe de fam\u00edlia (masculino), conforme a quantidade de anos de escolaridade. Nesse resultado verificamos a quantidade de 12818 homens sem escolaridade, o dado est\u00e1 como \"no\" e \"yes\" que \u00e9 igual a 1 a quantidade de 416, vamos tratar os dados adiante.","c8d7d5f4":"Demonstra\u00e7\u00e3o das vari\u00e1veis mais importantes para o modelo","ee0b939a":"Vers\u00e3o 15","4dfe427c":"Pelo resultado e ap\u00f3s sobrescrever como yes e no para 1 e 0 para as vari\u00e1veis edjefa e edjfe, verificamos que essas vari\u00e1veis n\u00e3o retornaram como object, logo se tornaram numericas. A coluna dependency restou para ser tratada.","ffb943ee":"Mediante o resultado, vemos que temos a seguinte quantidade de dados: yes = 7580 e no = 6036. Vamos tratar esses dados para que se tornem como ponto flutuante, assim como os demais da coluna.","7b658f34":"Vers\u00e3o 11","c8d4a53a":"Sobrescrevendo os dados que est\u00e3o como yes e no para 1 e 0 para as vari\u00e1veis edjefa e edjfe","e8226a29":"Demonstra\u00e7\u00e3o das vari\u00e1veis mais importantes para o modelo 2","5eeee6ba":"Vars\u00e3o 13","6b7573b7":"Gr\u00e1fico para verifica\u00e7\u00e3o da quantidade de individuos e parentesco","4d483e07":"Verifica\u00e7\u00e3o das familias que n\u00e3o possuiam chefes"}}