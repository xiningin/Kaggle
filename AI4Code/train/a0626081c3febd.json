{"cell_type":{"7039844a":"code","a5ce6c02":"code","8124e9ff":"code","a73bce2c":"code","4720e359":"code","ce5e64b6":"code","4d868e06":"code","29a7719e":"code","7b75502a":"code","3ef122d6":"code","fa91dbf1":"code","b00d566d":"code","440313e6":"code","aad198dd":"code","b47e26b9":"code","c6e28298":"code","07e8accb":"code","ef3c8d57":"code","942a5031":"code","16fdddef":"code","108ff714":"code","00524d50":"code","e2eb8ba1":"code","1f257644":"code","3465ec4c":"code","04003b09":"code","793e27a2":"code","a3c08ce4":"code","483239f6":"code","c2422db0":"code","49708e2c":"code","d34590e0":"code","4dd53603":"code","c9834638":"code","7c3fd4a7":"code","6f00c921":"code","389407c3":"code","4e7b274a":"code","72d58483":"code","78df3e2d":"code","290632d1":"code","09743ee8":"code","0a1b1726":"code","91e0fde0":"code","82211d27":"code","80aa010b":"code","d7a2ea72":"code","c01cee89":"markdown","99d7e8dd":"markdown","4c79607a":"markdown","661a93d1":"markdown","53b00fa5":"markdown","92408212":"markdown","73936087":"markdown","1a8b8822":"markdown","b5a84438":"markdown","33cc7108":"markdown","74517137":"markdown","6f405b01":"markdown","60ec8c1c":"markdown","63778bdf":"markdown","349ecc4c":"markdown"},"source":{"7039844a":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,classification_report,auc,f1_score,precision_recall_curve,confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV,KFold\nfrom sklearn.preprocessing import normalize\nimport tensorflow as tf\nsns.set_style('darkgrid')\n%matplotlib inline\nimport re\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score, roc_curve\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a5ce6c02":"dataset_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndataset_train.head()","8124e9ff":"dataset_train.Ticket.dtype","a73bce2c":"dataset_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ndataset_test.head()","4720e359":"gender = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\ngender.head()","ce5e64b6":"dataset_train.describe()","4d868e06":"dataset_train.isnull().sum()","29a7719e":"dataset_test.describe()","7b75502a":"dataset_test.isnull().sum()","3ef122d6":"gender.describe()","fa91dbf1":"dataset_train['Age'] = dataset_train['Age'].fillna(dataset_train['Age'].mean())\nmean_train = int(dataset_train['Age'].mean())\nmean_test = int(dataset_test['Age'].mean())\n#dataset_train['Age'] = dataset_train['Age'].fillna(np.random.choice([i for i in range(mean_train - 10, mean_train + 10)]))\ndataset_train['Embarked'] = dataset_train['Embarked'].fillna(np.random.choice(['C','Q','S']))\ndataset_test['Age'] = dataset_test['Age'].fillna(dataset_test['Age'].mean())\n#dataset_test['Age'] = dataset_test['Age'].fillna(np.random.choice([i for i in range(mean_test - 10, mean_test + 10)]))\ndataset_test['Fare'] = dataset_test['Fare'].fillna(dataset_test['Fare'].mean())","b00d566d":"train_corr = dataset_train.corr()\nplt.figure(figsize = (8,6))\nsns.heatmap(train_corr)","440313e6":"test_corr = dataset_test.corr()\nplt.figure(figsize = (8,6))\nsns.heatmap(test_corr)","aad198dd":"fig, axes = plt.subplots(2,4,figsize = (16,10), sharex = False, sharey = False)\n\nsns.countplot(x = 'Sex', data = dataset_train, ax = axes[0,0],edgecolor = 'black')\nsns.countplot(x = 'Survived', data = dataset_train, ax = axes[0,1],edgecolor = 'black')\nsns.countplot(x = 'Parch', data = dataset_train, ax = axes[0,2],edgecolor = 'black')\nsns.countplot(x = 'SibSp', data = dataset_train, ax = axes[0,3],edgecolor = 'black')\nsns.distplot(dataset_train['Fare'],ax = axes[1,0])\nsns.countplot(x = 'Embarked', data = dataset_train, ax = axes[1,1],edgecolor = 'black')\nsns.distplot(dataset_train['Age'], ax = axes[1,2])  #dropped all the NaN values and plotted the remaining float value\nsns.countplot(x = 'Pclass', data = dataset_train,ax = axes[1,3],edgecolor = 'black')\nplt.show()","b47e26b9":"sns.pairplot(dataset_train, kind = 'scatter', hue = 'Sex',plot_kws=dict(s=80, edgecolor=\"white\", linewidth=0.5))\nplt.show()","c6e28298":"#PIE chart visualization for Male-Female Percentage\nplt.figure(figsize = (8,8))\nplt.title('Percent Male-Female',fontsize = 30)\nx_sex,y_sex = dataset_train.Sex.value_counts(normalize = True)*100\nprint(dataset_train.Sex.value_counts(normalize = True)*100)\nwedges= plt.pie([x_sex,y_sex], labels = ['Male','Female'], colors = ['green','blue'], autopct='%.2f%%', \n        textprops = {'color':'Black','size':20}, wedgeprops={'linewidth':1, 'edgecolor':'black'})\nplt.show()","07e8accb":"#PIE chart visualization for Survived-Not Survived Percentage\nplt.figure(figsize = (8,8))\nplt.title('Percent Survived-Not Survived', fontsize = 30)\nx_surv, y_surv = dataset_train.Survived.value_counts(normalize = True)*100\nprint(dataset_train.Survived.value_counts(normalize = True)*100)\nplt.pie([x_surv,y_surv], labels = ['Survived','Not Survived'], colors = ['green','blue'],  autopct='%.2f%%', \n        textprops = {'color':'Black','size':20}, wedgeprops={'linewidth':1, 'edgecolor':'black'})\nplt.show()","ef3c8d57":"# BAR distributions of Survived and Pclass to look for std deviation\nplt.figure(figsize = (10,7))\nplt.hist(dataset_train['Fare'], bins = 20, histtype = 'bar', edgecolor = 'Black')\nplt.title('Range of Fare value values VS Count', fontsize = 20)\nplt.xlabel('Range(Fare)', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)\nplt.show()","942a5031":"plt.figure(figsize = (10,7))\nplt.hist(dataset_train['Age'], bins = 30, histtype = 'bar',edgecolor = 'Black')\nplt.title('Range of Age values VS Count(No of persons)', fontsize = 20)\nplt.xlabel('Range(AGE)', fontsize = 12)\nplt.ylabel('Count', fontsize = 12)\nplt.show()","16fdddef":"def get_title(string):\n    if '.' in string:\n        return string.split(',')[1].split('.')[0].strip()\n    else:\n        return 'N.F'\ndef replace_titles(x):\n    title = x['Title']\n    if title in ['Capt', 'Col', 'Dona', 'Don', 'Jonkheer', 'Major', 'Rev', 'Sir']:\n        return 'Mr'\n    elif title in ['the Countess', 'Mme', 'Lady']:\n        return 'Mrs'\n    elif title in ['Mlle', 'Ms']:\n        return 'Miss'\n    elif title =='Dr':\n        if x['Sex']=='male':\n            return 'Mr'\n        else:\n            return 'Mrs'\n    else:\n        return title\n    \n    \ndataset_train['Title'] = dataset_train['Name'].apply(get_title)\ntemp_title = dataset_train.apply(replace_titles, axis = 1)\ntemp_title.value_counts()\ndata_sur = dataset_train[dataset_train['Survived'] == 1]\nsurvived_title = data_sur.apply(replace_titles, axis = 1)\nsurvived_title.value_counts()\n","108ff714":"temp_title.value_counts()","00524d50":"fig,axes = plt.subplots(1,2, figsize = (17,7))\na = axes[0].bar(temp_title.value_counts().index, height=temp_title.value_counts().values, color=['red','green','yellow','blue'],\n       edgecolor = 'Black')\naxes[0].set_xlabel('Title', fontdict={'fontsize':15})\naxes[0].set_ylabel('Count', fontdict={'fontsize':15})\naxes[0].set_title('Title(Survived and Not Survived) vs Count', fontdict={'fontsize':19})\naxes[0].tick_params(labelsize = 13)\naxes[0].set_yticks(range(0,800,100))\nfor ax in a.patches:\n    axes[0].text(ax.get_x() + 0.25, ax.get_height() + 5, str(round(ax.get_height(), 2)), fontdict={'fontsize':14})\n    \nb = axes[1].bar(survived_title.value_counts().index, height=survived_title.value_counts().values, color=['red','green','yellow','blue'],\n       edgecolor = 'Black')\naxes[1].set_xlabel('Title', fontdict={'fontsize':15})\naxes[1].set_ylabel('Count', fontdict={'fontsize':15})\naxes[1].set_title('Title(Suvived) vs Count', fontdict={'fontsize':19})\naxes[1].tick_params(labelsize = 13)\naxes[1].set_yticks(range(0,300,20))\nfor ax in b.patches:\n    axes[1].text(ax.get_x() + 0.25, ax.get_height() + 2, str(round(ax.get_height(), 2)), fontdict={'fontsize':14})\n","e2eb8ba1":"data_sur_fare = dataset_train.groupby('Sex').Fare.mean()\nprint(data_sur_fare)\nax_sur_fare = data_sur_fare.plot.bar(edgecolor = 'Black',fontsize = 12, figsize =(10,7), color = ['Red', 'Green'])\nplt.title('Averge Fare for Males and Females', fontsize = 20)\nplt.xlabel('Sex', fontdict = {'fontsize':17})\nplt.ylabel('Avergae Fare', fontdict={'fontsize':17})\nplt.yticks(range(0,70,10))\nplt.xticks(rotation = 45)\nplt.tick_params(labelsize = 14)\nfor i in ax_sur_fare.patches:\n    ax_sur_fare.text(i.get_x()+0.19, i.get_height() + 0.4, str(round(i.get_height(),2)) , fontsize = 15 , color = 'Black')","1f257644":"plt.figure(figsize = (10,7))\nsns.violinplot(dataset_train['Survived'], dataset_train['SibSp'], )\nplt.tick_params(labelsize = 13)\nplt.xlabel('Survived', fontdict={'fontsize':17})\nplt.ylabel('SibSp', fontdict = {'fontsize':17})\nplt.title('Survived VS SibSp', fontdict={'fontsize':20})\nplt.show()","3465ec4c":"plt.figure(figsize = (13,8))\naxes= sns.barplot(x = sorted(dataset_train['SibSp'].unique()), y = 'Age', data = dataset_train[['Age', 'SibSp']].groupby('SibSp').mean(),\n                 linewidth = 1, edgecolor = 'black')\nfor ax in axes.patches:\n    plt.text(ax.get_x() + 0.25, ax.get_height() + 0.3, str(round(ax.get_height(), 2)), fontsize = 15)\nplt.xlabel('SibSp', fontdict = {'fontsize':15})\nplt.ylabel('Average Age', fontdict = {'fontsize':15})\nplt.yticks(range(0,45,5))\nplt.tick_params(labelsize = 13)\nplt.title('Average Age VS SibSp', fontdict = {'fontsize':20})\nplt.show()","04003b09":"fare_cabin = dataset_train[['Cabin', 'Fare']].groupby(by = 'Cabin').mean()\nfare_cabin = fare_cabin.sort_values(by = 'Fare', ascending = False)\nfare_cabin = fare_cabin[:16][:]\nfare_cabin = fare_cabin.reset_index()\nfare_cabin = fare_cabin.sort_values(by = 'Cabin', ascending = True)\ndef label_encoder(string):\n    num = re.findall('\\d+', string)\n    alpha = string[0]\n    if len(num)>1:\n        label = label = alpha + '(' + '-'.join(num) + ')'\n    else:\n        label = alpha + '-'.join(num)\n    return label\n\nfare_cabin['Cabin'] = fare_cabin['Cabin'].apply(label_encoder)","793e27a2":"plt.figure(figsize = (20,8))\nplt.plot(fare_cabin['Cabin'], fare_cabin['Fare'], color = 'Green')\nplt.plot(fare_cabin['Cabin'], fare_cabin['Fare'], '*', color = 'red', markersize = 20)\nplt.ylabel('Average Fare', fontdict = {'fontsize':17})\nplt.xlabel('Cabin Number', fontdict= {'fontsize':17})\nplt.xticks(rotation = 45)\nplt.tick_params(labelsize = 13)\nplt.title('Average fare for top 10 most popular Cabins according to data', fontdict={'fontsize':20})\nplt.show()","a3c08ce4":"dataset_train['Ticket'] = dataset_train['Ticket'].apply(lambda x: len(x))\ndataset_train['Title'] = dataset_train['Name'].apply(get_title)\ndataset_train['Title'] = dataset_train.apply(replace_titles, axis = 1)\ndrop_cols = ['PassengerId','Name','Cabin', 'Title']\nencode_cols = ['Sex','Embarked', 'Title']\nencode_after = pd.get_dummies(dataset_train[encode_cols])\nfin_data = dataset_train.copy()\nfin_data = fin_data.drop(drop_cols, axis = 1)\nfin_data = pd.concat([fin_data, encode_after], axis = 1)\nprint(fin_data.columns)\nfin_data.drop(['Sex', 'Embarked'], axis = 1, inplace = True)","483239f6":"dataset_test['Title'] = dataset_test['Name'].apply(get_title)\ndataset_test['Ticket'] = dataset_test['Ticket'].apply(lambda x: str(x))\ndataset_test['Ticket'] = dataset_test['Ticket'].apply(lambda x: len(x))\ndataset_test['Title'] = dataset_test.apply(replace_titles, axis = 1)\nencode_cols_teset = pd.get_dummies(dataset_test[encode_cols])\nfin_data_test = dataset_test.copy()\nfin_data_test = fin_data_test.drop(['PassengerId','Name','Cabin', 'Embarked','Sex'],axis =1)\nfin_data_test = pd.concat([fin_data_test, encode_cols_teset], axis = 1)\nfin_data_test = fin_data_test[[ 'Pclass', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare',\n        'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q',\n       'Embarked_S', 'Title_Master', 'Title_Miss', 'Title_Mr',\n       'Title_Mrs']]","c2422db0":"fin_data.head()","49708e2c":"fin_data_test.head()","d34590e0":"X_train = fin_data.values[:,1:]\nY_train = fin_data.values[:,0]\nX_test = fin_data_test.values[:,:]\nY_test = gender.values[:,1:]","4dd53603":"params = {'penalty':['l1','l2'], 'C':[0.01,0.1,1,10,100]}\nlr = LogisticRegression(solver = 'liblinear')\ngrid = GridSearchCV(lr, param_grid=params, scoring ='f1', cv = 10, n_jobs=-1)\ngrid.fit(X_train, Y_train)\ngrid.best_params_","c9834638":"lr = LogisticRegression(C = 1, penalty='l2', solver='liblinear')\nlr.fit(X_train, Y_train)\npredict_lr = lr.predict(X_test)","7c3fd4a7":"print(\"Accuracy = {0}%\".format(round(accuracy_score(Y_test, predict_lr)*100, 2)))\nprint(classification_report(Y_test, predict_lr))\nprint(\"Score = {0}\".format(f1_score(Y_test, predict_lr)))\nprint(confusion_matrix(Y_test, predict_lr))","6f00c921":"auc_score_lr = roc_auc_score(Y_test, predict_lr)\nprint('AUROC Score : {0}'.format(round(auc_score_lr, 4)))\nfpr, tpr, threshold = roc_curve(Y_test, predict_lr)\nplt.figure(figsize = (12,7))\nplt.plot([0,1], [0,1], '--')\nplt.plot(fpr, tpr, '-*', color = 'Orange', label = 'ROC curve area : {0}'.format(round(auc_score_lr, 4)))\nplt.xlabel('False Postitive Rate', fontdict = {'fontsize':15})\nplt.ylabel('True Postitive Rate', fontdict = {'fontsize':15})\nplt.title('ROC-AUC Curve Logistic Regression', fontdict = {'fontsize':20})\nplt.legend()\nplt.show()","389407c3":"rf = RandomForestClassifier()\nparams_rf = {'n_estimators':list(range(1,20)), 'max_depth':list(range(1,10)), 'criterion':['gini', 'entropy']} #'max_features':['auto', 'log2', 'sqrt'],\n            #'bootstrap':[True, False]\ngrid_rf = GridSearchCV(rf, param_grid=params_rf, cv = 5, scoring='accuracy', n_jobs = -1)\ngrid_rf.fit(X_train,Y_train)\nprint('HyperParameter optimization')\ngrid_rf.best_params_","4e7b274a":"rf = RandomForestClassifier(criterion = 'entropy', max_depth = 7, n_estimators = 16, bootstrap=False) #4,13\nrf.fit(X_train, Y_train)\npredict_rf = rf.predict(X_test)\nprint(\"Accuracy Score = {} %\".format(rf.score(X_test, Y_test)*100))\nprint(classification_report(Y_test, predict_rf))\nprint('F1 Score = {}'.format(f1_score(Y_test, predict_rf)))","72d58483":"auc_score_rf = roc_auc_score(Y_test, predict_rf)\nprint('AUROC Score : {0}'.format(round(auc_score_rf, 4)))\nfpr, tpr, threshold = roc_curve(Y_test, predict_rf)\nplt.figure(figsize = (12,7))\nplt.plot([0,1], [0,1], '--')\nplt.plot(fpr, tpr, '-*', color = 'Orange', label = 'ROC curve area : {0}'.format(round(auc_score_rf, 4)))\nplt.xlabel('False Postitive Rate', fontdict = {'fontsize':15})\nplt.ylabel('True Postitive Rate', fontdict = {'fontsize':15})\nplt.title('ROC-AUC Curve Random Forest', fontdict = {'fontsize':20})\nplt.legend()\nplt.show()","78df3e2d":"def model():\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(120, activation = tf.nn.relu, kernel_initializer = 'normal'))\n    model.add(tf.keras.layers.Dense(120, activation = tf.nn.relu, kernel_initializer = 'normal'))\n    model.add(tf.keras.layers.Dense(120, activation = tf.nn.relu, kernel_initializer = 'normal'))\n    #model.add(tf.keras.layers.Dense(120, activation = tf.nn.relu, kernel_initializer = 'normal'))\n    model.add(tf.keras.layers.Dense(1, activation = tf.nn.sigmoid))\n    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n    return model","290632d1":"model = model()\nmodel.fit(X_train, Y_train, epochs = 500, verbose = 0)","09743ee8":"val_loss, val_acc = model.evaluate(X_train, Y_train)","0a1b1726":"val_loss, val_acc = model.evaluate(X_test, Y_test)","91e0fde0":"predict_nn = model.predict([X_test])\npredict_nn_fin = []\nfor i in range(len(predict_nn)):\n    if predict_nn[i]>=0.7:\n        predict_nn_fin.append(1)\n    else:\n        predict_nn_fin.append(0)","82211d27":"print(\"Accuracy = {0}%\".format(round(accuracy_score(Y_test, predict_nn_fin)*100, 2)))\nprint(classification_report(Y_test, predict_nn_fin))\nprint(\"Score = {0}\".format(f1_score(Y_test, predict_nn_fin)))\nprint(confusion_matrix(Y_test, predict_nn_fin))","80aa010b":"auc_score_nn = roc_auc_score(Y_test, predict_nn_fin)\nprint('AUROC Score : {0}'.format(round(auc_score_nn, 4)))\nfpr, tpr, threshold = roc_curve(Y_test, predict_nn_fin)\nplt.figure(figsize = (12,7))\nplt.plot([0,1], [0,1], '--')\nplt.plot(fpr, tpr, '-*', color = 'Orange', label = 'ROC curve area : {0}'.format(round(auc_score_nn, 4)))\nplt.xlabel('False Postitive Rate', fontdict = {'fontsize':15})\nplt.ylabel('True Postitive Rate', fontdict = {'fontsize':15})\nplt.title('ROC-AUC Curve Random Forest', fontdict = {'fontsize':20})\nplt.legend()\nplt.show()","d7a2ea72":"'''submission = pd.DataFrame({\n        \"PassengerId\": gender['PassengerId'],\n        \"Survived\": predict_rf\n    })\n\nsubmission.PassengerId = submission.PassengerId.astype(int)\nsubmission.Survived = submission.Survived.astype(int)\n\nsubmission.to_csv(\"titanic1_submission.csv\", index=False)'''","c01cee89":"**MODEL 2 : RANDOM FOREST**\n1. FIRST BLOCK IS USED TO FIND THE BEST POSSIBLE PARAMETERS\n2. SECOND BLOCK IS USED TO PREDICT ON THE DATASET\n3. GridSearchCV was used to find the best optimal parameters but were not little modified to get the current target result.","99d7e8dd":"> TEST SET CREATION","4c79607a":"**FILLING IN MISSING VALUES**\n> From the above isnull().sum() command we can see that the amount of data that is missing has a good amount. If we were to drop these values then the dataset_train will be reduced from 891 to 204 rows and sililar for the test set through which we will not be able to make good visualization and good model. So to overcome this challenge we will fill the missing values in the AGE columns with the respective mean of the data available in dataset_train['Age'] and dataset_test['Age'] and the EMBARKED columsn is filled with random values choosen from the unique values occuring in the column 'EMBARKED'.","661a93d1":"> THE TRAIN SET NOW HAS 16 DISTINCT feature some of which were created using pd.get_dummies. ","53b00fa5":"> THE TEST SET NOW HAS 15 DISTINCT feature some of which were created using pd.get_dummies. ","92408212":"DETAILS ON THE NEUARAL NETWORK USED\n> 1. FULLY CONNECT 4 LAYER NEURAL NETWORK \n> 2. EACH LAYER USES 120 NEURAON EACH WITH ACTIVATION FUNCTION 'relu'\n> 3. OPTIMIZER:- 'adam', LOSS_FXN:- 'binary_crossentropy'\n> 4. EPOCHES RUN : - 500","73936087":"**VISUALIZATION**\n> Lets start with the basic visualization \nI HAVE USED VARIOUS PLOTS FROM SEABORN AND MATPLOTLIB TO VISUALIZE WHAT I FOUND IMPORTANT FROM THE DATASET. I MAY HAVE MISSED SOME THING ON THE WAY, PLEASE CONVEY THEM IN THE COMMENTS.","1a8b8822":"**MODEL 1 : LOGISTIC REGRESSION**\n1. FIRST BLOCK IS USED TO FIND THE BEST POSSIBLE PARAMETERS\n2. SECOND BLOCK IS USED TO PREDICT ON THE DATASET\n3. GridSearchCV was used to find the best optimal parameters but were not little modified to get the current target result.","b5a84438":"> IN THIS I HAVE CREATED THE DUMMY COLUMNS FOR 'SEX' AND 'EMBARKED' COLUMNS AND DROPPED THE COLUMNS LIKE 'PassengerId','Name','Ticket','Cabin','Title' AS I FOUND THEM TO BE NOT WORTHY FOR THE MODEL.","33cc7108":"**MODEL IMPLEMENTATION**\nHERE I HAVE IMPLEMENT 3 MODELS THAT I FOUND MOST INTERESTING\n1. LOGISTIC REGRESSION\n2. RANDOM FOREST MODEL\n3. NEUARAL NETWORK MODEL","74517137":"> TRAIN SET CREATION","6f405b01":"**DATA PREPROCESSING**","60ec8c1c":"**FINALLY CREATED DATA**","63778bdf":"> TITLE ENCODING AND LABELLING","349ecc4c":"**MODEL 3 : NEUARAL NETWORK**\n> FIRST BLOCK IS USED TO FIND THE BEST POSSIBLE PARAMETERS\n> SECOND BLOCK IS USED TO PREDICT ON THE DATASET"}}