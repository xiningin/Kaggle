{"cell_type":{"2ea37924":"code","c9dea120":"code","4c82049a":"code","1b2de3a6":"code","a5294a01":"code","82bb9e7b":"code","2d5b5b23":"code","9329300f":"code","c648d28e":"code","10efda7b":"code","61b30017":"code","2ca29df1":"code","221b3144":"code","9a269bd7":"code","2c283661":"code","4d90f438":"code","961af58e":"code","08c5daf6":"code","dcb1f5b5":"code","94a062b5":"code","dd74136e":"code","eee456e6":"code","3bbf77c3":"code","a9cd1cc2":"markdown","22340d15":"markdown","02b6640d":"markdown","3a7d87a8":"markdown","3b482388":"markdown","4a7b2444":"markdown","849e3390":"markdown","641533aa":"markdown","200aab5f":"markdown"},"source":{"2ea37924":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport matplotlib.pyplot as plt       \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.linear_model import LinearRegression\n\n        \ninput_path = Path('\/kaggle\/input\/tabular-playground-series-jan-2021\/')","c9dea120":"train = pd.read_csv(input_path \/ 'train.csv', index_col='id')\nprint('Train df')\ndisplay(train.head())\nprint('Test df')\ntest = pd.read_csv(input_path \/ 'test.csv', index_col='id')\ndisplay(test.head())\nprint('Sample submission')\nsubmission = pd.read_csv(input_path \/ 'sample_submission.csv', index_col='id')\ndisplay(submission.head())","4c82049a":"%matplotlib inline\ntrain.hist(bins=100,figsize=(20,15))","1b2de3a6":"train.plot(figsize=(12,6))\nplt.show()","a5294a01":"# box plot\ntrain.boxplot(figsize=(12,6))\nplt.show()","82bb9e7b":"# drop outliers in target\ntrain=train.drop(train[train.target < 4.4].index)","2d5b5b23":"corr_matrix=train.corr()\ncorr_matrix['target'].sort_values(ascending = False)\n","9329300f":"\nfrom pandas.plotting import scatter_matrix\nattributes = ['cont7', 'cont2', 'cont3', 'cont11', 'cont12']\nscatter_matrix(train[attributes], figsize = (12,8))","c648d28e":"target = train.pop('target')\nX_train, X_test, y_train, y_test = train_test_split(train, target, train_size=0.80)","10efda7b":"X=train\ny=target","61b30017":"X.plot()\nplt.show()","2ca29df1":"y.plot()\nplt.show()","221b3144":"xgbreg=XGBRegressor()\n\nxgbreg.fit(X_train, y_train)\ny_pred = xgbreg.predict(X_test)\nscore = mean_squared_error(y_test, y_pred, squared=False)\nprint('XGBRegressor default parameters - mean squared error: ', score)","9a269bd7":"\nxgbreg_mod = XGBRegressor(n_estimators=100, learning_rate=0.1, n_jobs=4)\nxgbreg_mod.fit(X_train, y_train)\ny_pred=xgbreg.predict(X_test)\nscore = mean_squared_error(y_test, y_pred, squared=False)\nprint('Mean squared error: ', score)","2c283661":"#SGDRegressor\nsgd_reg = SGDRegressor(max_iter=100, penalty=None, eta0=0.05)\nsgd_reg.fit(X_train, y_train.ravel())\ny_pred_sgd=sgd_reg.predict(X_test)\nscore = mean_squared_error(y_test, y_pred_sgd, squared=False)\nprint('SGDRegressor Mean squared error: ', score)","4d90f438":"# Polynomial regression\nfrom sklearn.preprocessing import PolynomialFeatures\npoly_features = PolynomialFeatures(degree=2, include_bias=False)\nX_poly = poly_features.fit_transform(X_train)\nX_poly_test = poly_features.fit_transform(X_test)\nprint(X_train.head())\nprint(X_poly)\n","961af58e":"\nlin_reg = LinearRegression()\nlin_reg.fit(X_poly, y_train)\n\ny_pred_lin_reg=lin_reg.predict(X_poly_test)\nscore = mean_squared_error(y_test, y_pred_lin_reg, squared=False)\nprint('LinearRegression with poly - mean squared error: ', score)","08c5daf6":"sgd_reg = SGDRegressor(max_iter=50, penalty=None, eta0=0.1)\nsgd_reg.fit(X_poly, y_train.ravel())\ny_pred_sgd=sgd_reg.predict(X_poly_test)\nscore = mean_squared_error(y_test, y_pred_sgd, squared=False)\nprint('SGDRegressor with polynominal transform mean squared error: ', score)","dcb1f5b5":"xgb_poly = XGBRegressor(n_estimators=100, learning_rate=0.1)\nxgb_poly.fit(X_poly, y_train)","94a062b5":"y_pred_xgb_poly=lin_reg.predict(X_poly_test)\nscore = mean_squared_error(y_test, y_pred_xgb_poly, squared=False)\nprint('Mean squared error: ', score)","dd74136e":"my_model=xgb_poly","eee456e6":"my_y_pred =my_model.predict(X_poly_test)\nscore = mean_squared_error(y_test, my_y_pred, squared=False)\nprint(score)","3bbf77c3":"poly_test = poly_features.fit_transform(test)\nsubmission['target'] = my_model.predict(poly_test)\nsubmission.to_csv('poly_xgb_regressor.csv')","a9cd1cc2":"## Make submissions","22340d15":"# Choosing model","02b6640d":"Plots for attributes with the biggest correlation","3a7d87a8":"## Pull out the target, and make a validation split","3b482388":"Parameters choosing","4a7b2444":"Build model with default parameters.","849e3390":"Best model","641533aa":"# Read in the data files","200aab5f":"\n# XGB Regressor\n"}}