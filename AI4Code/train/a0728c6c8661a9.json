{"cell_type":{"29fa4207":"code","34c3898a":"code","b13591ab":"code","44f944f4":"code","28d45a7a":"code","d0c59ead":"code","b4286f90":"code","76748136":"code","69211731":"code","e270c9fa":"code","19e93e41":"code","592cae18":"code","bc19bb0b":"code","dd811713":"code","1c42cb5a":"code","19fb8088":"code","2ef902e1":"code","c101ed57":"code","61da78a1":"code","38d851a2":"code","7ef8f033":"markdown","9c4cfc0b":"markdown","8a9169e1":"markdown","1134f3f7":"markdown","39292ecf":"markdown","27d65b5e":"markdown","a3f63224":"markdown","2a9229bd":"markdown","dc95e323":"markdown","10723482":"markdown","f46f66b2":"markdown","b8f65256":"markdown","23fba5f2":"markdown","bef0906d":"markdown","dc9f4579":"markdown"},"source":{"29fa4207":"# import the tools we need\nimport os \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder\nimport torch\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nfrom pytorch_lightning import metrics\nfrom sklearn.preprocessing impbort LabelEncoder\nfrom sklearn.model_selection import train_test_splitb","34c3898a":"# Read the csv files\ncomp_df = pd.read_csv('..\/input\/dog-breed-identification\/labels.csv')\ntest_df = pd.read_csv('..\/input\/dog-breed-identification\/sample_submission.csv')\n\n# How many number of images in Training set and test set?\nprint('Training set: {}, Test set: {}'.format(comp_df.shape[0],test_df.shape[0]))","b13591ab":"# how may dog breed in training set? \ncomp_df.breed.value_counts()","44f944f4":"# Encode the breed into digits\ncomp_df['label'] = LabelEncoder().fit_transform(comp_df.breed)\n\n# Create a breed-2-index dictionary\ndict_df = comp_df[['label','breed']].copy()\ndict_df.drop_duplicates(inplace=True)\ndict_df.set_index('label',drop=True,inplace=True)\nindex_to_breed = dict_df.to_dict()['breed']","28d45a7a":"# Change the id to full file path\ntrain_dir = '..\/input\/dog-breed-identification\/train'\ncomp_df.id = comp_df.id.apply(lambda x: x+'.jpg')\ncomp_df.id = comp_df.id.apply(lambda x:train_dir+'\/'+x)\n\n# Drop the breed column\ncomp_df.pop('breed')","d0c59ead":"def show_images(df,img_num):\n    sample = df.sample(img_num)\n    paths = sample.id.tolist()\n    for path in paths:\n        plt.figure(figsize=(3,3))\n        img = plt.imread(path)\n        plt.imshow(img)\n        plt.axis('off')\n        plt.show()","b4286f90":"show_images(comp_df,4)","76748136":"class img_dataset(Dataset):\n    def __init__(self,dataframe,transform=None,test=False):\n        self.dataframe = dataframe\n        self.transform = transform\n        self.test = test\n        \n    def __getitem__(self,index):\n        x = Image.open(self.dataframe.iloc[index,0])\n        if self.transform:\n            x = self.transform(x)\n        if self.test:\n            return x\n        else:\n            y = self.dataframe.iloc[index,1]\n            return x,y\n        \n    def __len__(self):\n        return self.dataframe.shape[0]","69211731":"# Creat transfomers\ntrain_transformer = transforms.Compose([transforms.RandomResizedCrop(224),\n                                        transforms.RandomRotation(15),\n                                        transforms.RandomHorizontalFlip(),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\nval_transformer = transforms.Compose([transforms.Resize(256),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])","e270c9fa":"# Print the result of 1 epoch\ndef print_epoch_result(train_loss,train_acc,val_loss,val_acc):\n    print('loss: {:.3f}, acc: {:.3f}, val_loss: {:.3f}, val_acc: {:.3f}'.format(train_loss,\n                                                                              train_acc,\n                                                                              val_loss,\n                                                                              val_acc))\n# Main Training function\ndef train_model(model, cost_function, optimizer,num_epochs=5):\n    train_losses = []\n    val_losses = []\n    train_acc = []\n    val_acc = []\n    \n    # Metrics object\n    train_acc_object = metrics.Accuracy(compute_on_step=False)\n    val_acc_object = metrics.Accuracy(compute_on_step=False)\n    \n    for epoch in range(num_epochs):\n        \"\"\"\n        On epoch start\n        \"\"\"\n        print('-'*15)\n        print('Start training {}\/{}'.format(epoch+1, num_epochs))\n        print('-'*15)\n        \n        # Training\n        train_sub_losses = []\n        model.train()\n        for x,y in train_loader:\n            optimizer.zero_grad()\n            x,y = x.to(device),y.to(device)\n            y_hat = model(x)\n            loss = cost_function(y_hat,y)\n            loss.backward()\n            optimizer.step()\n            #lr_scheduler.step()\n            # update loss sublist\n            train_sub_losses.append(loss.item())\n            # update accuracy object\n            train_acc_object(y_hat.cpu(),y.cpu())\n            \n        # Validation\n        val_sub_losses = []\n        model.eval()\n        for x,y in val_loader:\n            x,y = x.to(device),y.to(device)\n            y_hat = model(x)\n            loss = cost_function(y_hat,y)\n            val_sub_losses.append(loss.item())\n            val_acc_object(y_hat.cpu(),y.cpu())\n            \n        \"\"\"\n        On epoch end\n        \"\"\"\n        # Update the loss list\n        train_losses.append(np.mean(train_sub_losses))\n        val_losses.append(np.mean(val_sub_losses))\n        \n        # Update the accuracy list and reset the metrics object \n        train_epoch_acc = train_acc_object.compute()\n        val_epoch_acc = val_acc_object.compute()\n        train_acc.append(train_epoch_acc)\n        val_acc.append(val_epoch_acc)\n        train_acc_object.reset()\n        val_acc_object.reset()\n        \n        # print the result of epoch\n        print_epoch_result(np.mean(train_sub_losses),train_epoch_acc,np.mean(val_sub_losses),val_epoch_acc)\n        \n    print('Finish Training.')\n    return train_losses, train_acc, val_losses, val_acc","19e93e41":"# Setting up gpu\ndevice = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')","592cae18":"# Parameters for dataset\ntraining_samples = comp_df.shape[0] # Use small number first to test whether the model is doing well, then change back to full dataset\ntest_size=0.05\nbatch_size = 64\n\n# Reduce the number of samples\nsample_df = comp_df.sample(training_samples)\n\n# Split the comp_df into training set and validation set\nx_train,x_val,_,_ = train_test_split(sample_df,sample_df,test_size=test_size)\n\n# Create dataloaders form datasets\ntrain_set = img_dataset(x_train, transform=train_transformer)\nval_set = img_dataset(x_val, transform=val_transformer)\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_set , batch_size=batch_size, shuffle=True)\n\n# How many images in training set and val set?\nprint('Training set: {}, Validation set: {}'.format(x_train.shape[0],x_val.shape[0]))","bc19bb0b":"# Use resnet-50 as a base model\nclass net(torch.nn.Module):\n    def __init__(self, base_model, base_out_features, num_classes):\n        super(net,self).__init__()\n        self.base_model=base_model\n        self.linear1 = torch.nn.Linear(base_out_features, 512)\n        self.output = torch.nn.Linear(512,num_classes)\n    def forward(self,x):\n        x = F.relu(self.base_model(x))\n        x = F.relu(self.linear1(x))\n        x = self.output(x)\n        return x\n\nres = torchvision.models.resnet50(pretrained=True)\nfor param in res.parameters():\n    param.requires_grad=False\n\nmodel_final = net(base_model=res, base_out_features=res.fc.out_features, num_classes=120)\nmodel_final = model_final.to(device)","dd811713":"# Cost function and optimzier\ncost_function = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam([param for param in model_final.parameters() if param.requires_grad], lr=0.0003)\n\n# Learning rate scheduler\n#lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.1)\n\n# Epoch \nEPOCHS = 30","1c42cb5a":"# Start Training\ntrain_losses, train_acc, val_losses, val_acc = train_model(model=model_final, \n                                                           cost_function=cost_function, \n                                                           optimizer=optimizer,\n                                                           num_epochs=EPOCHS)","19fb8088":"def plot_result(train_loss,val_loss,train_acc,val_acc):\n    plt.style.use('ggplot')\n    fig, (ax1,ax2) = plt.subplots(2,1,figsize=(10,8))\n    ax1.plot(train_loss,label='loss')\n    ax1.plot(val_loss,label='val_loss')\n    ax1.legend()\n    ax1.set_xlabel('epoch')\n    ax1.set_xticks(range(0,EPOCHS+1))\n    ax2.plot(train_acc, label='acc')\n    ax2.plot(val_acc,label='val_acc')\n    ax2.legend()\n    ax2.set_xlabel('epoch')\n    ax2.set_xticks(range(0,EPOCHS+1))\n    plt.show()\nplot_result(train_losses,val_losses, train_acc,  val_acc)","2ef902e1":"# Prepare for test data dataframe\n#test_df = pd.read_csv('..\/input\/dog-breed-identification\/sample_submission.csv')\ntest_dir = '..\/input\/dog-breed-identification\/test'\ntest_df = test_df[['id']]\ntest_df.id = test_df.id.apply(lambda x: x+'.jpg')\ntest_df.id = test_df.id.apply(lambda x : test_dir+'\/'+x)\ntest_set = img_dataset(test_df,transform=val_transformer, test=True)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)","c101ed57":"model_final.eval()\npredictions = torch.tensor([])\nprint('Start predicting....')\nfor x in test_loader:\n    x = x.to(device)\n    y_hat = model_final(x)\n    predictions = torch.cat([predictions, y_hat.cpu()])\nprint('Finish prediction.')","61da78a1":"predictions = F.softmax(predictions,dim=1).detach().numpy()","38d851a2":"answer_id = pd.read_csv('..\/input\/dog-breed-identification\/sample_submission.csv').id.tolist()\npredictions_df = pd.DataFrame(predictions, index=answer_id)\npredictions_df.columns = predictions_df.columns.map(index_to_breed)\npredictions_df.rename_axis('id', inplace=True)\npredictions_df.to_csv('submission.csv')","7ef8f033":"Start doing prediction\n- Since the submission require us to provide the softmax probabilities, I will use nn.softmax for the outputs.","9c4cfc0b":"# Prepare dataframe for training set\n\n- Prepare dataframe with two columns: complete file path and labels (transferd to index)\n- Create a index-2-breed dictionary","8a9169e1":"# Main Training function","1134f3f7":"- From the graph, it is known that both accuarcy and loss are still improving, training with more epochs (around 40~50) would be better.","39292ecf":"# Dog breed classification using Pytorch\n\n- Transfer learning using Resnet-50","27d65b5e":"# Plot the result","a3f63224":"# Create CSV file for submission","2a9229bd":"# Do prediction on test data","dc95e323":"Create model\n- I will use resnet-50 as a base model (with parameters freezed)\n- Two dense layers added at the end.","10723482":"Transfer all result to softmax probabilities","f46f66b2":"Now the main training function is finished, lets preprare the model, dataset, cost function and optimizer.","b8f65256":"# Have a look on the images","23fba5f2":"Thank you very much.","bef0906d":"Prepare the test loader first","dc9f4579":"# Create Custom Dataset class and transformers"}}