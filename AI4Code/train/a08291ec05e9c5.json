{"cell_type":{"6d9c1db6":"code","64d080e1":"code","4d95844a":"code","8ceae8de":"code","e9998c6b":"code","24766bc7":"code","56a87e37":"code","cb60e597":"code","cf170f72":"code","adc91c4c":"code","62b3dd93":"code","fc10c393":"code","5d93fbfb":"code","bedc6525":"code","f6ea1faf":"code","d8fe79ab":"code","8673bfc7":"code","02050097":"code","b6a1200f":"code","fa4a4d91":"code","8e72b60e":"code","1fcb38b3":"code","548a6735":"code","d62d1d23":"code","d612e2a9":"code","9cd4a74d":"code","2012bd0a":"code","2f46d4ef":"markdown","333eebe3":"markdown","a0fc58f6":"markdown","4c97514a":"markdown","f53ddc6a":"markdown","2c5373e1":"markdown","32e48923":"markdown","6881fa1b":"markdown","4f49389e":"markdown","8087ade5":"markdown","c9f79d02":"markdown","297f3bf7":"markdown","28c77c39":"markdown","1a8c9184":"markdown","d3acf9b4":"markdown","63c1dc5b":"markdown","b854aae7":"markdown"},"source":{"6d9c1db6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","64d080e1":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","4d95844a":"raw_data=pd.read_csv(\"\/kaggle\/input\/autompg-dataset\/auto-mpg.csv\")\nraw_data.describe(include='all')","8ceae8de":"raw_data.isnull().sum()","e9998c6b":"raw_data_mod=raw_data.drop(['car name'],axis=1)","24766bc7":"raw_data_mod[raw_data_mod.horsepower.values=='?']","56a87e37":"model_data=raw_data_mod.copy()\nmodel_data['horsepower']=model_data.horsepower.replace({'?':None})\n","cb60e597":"model_data.isnull().sum()","cf170f72":"from sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\n\ny=model_data['mpg']\nx=model_data.drop(['mpg'],axis=1)\nX_train,X_valid,y_train,y_valid=train_test_split(x,y,random_state=1)\nmy_imp=SimpleImputer()\nmy_imp_1=SimpleImputer()\nimputed_X_train=pd.DataFrame(my_imp.fit_transform(X_train))\nimputed_X_valid=pd.DataFrame(my_imp.transform(X_valid))\nimputed_mod_data=pd.DataFrame(my_imp_1.fit_transform(model_data))\n\n\nimputed_X_train.columns=X_train.columns\nimputed_mod_data.columns=model_data.columns\nimputed_X_valid.columns=X_valid.columns\n","adc91c4c":"plt.subplots_adjust(right=2.0,wspace=0.7,hspace=0.8)\nplt.subplot(2,4,1)\nmpg=sns.distplot(imputed_mod_data['mpg'])\nplt.subplot(2,4,2)\ncyn=sns.distplot(imputed_mod_data['cylinders'])\nplt.subplot(2,4,3)\ndis=sns.distplot(imputed_mod_data['displacement'])\nplt.subplot(2,4,4)\nwgt=sns.distplot(imputed_mod_data['weight'])\nplt.subplot(2,4,5)\nacc=sns.distplot(imputed_mod_data['acceleration'])\nplt.subplot(2,4,6)\nmyr=sns.distplot(imputed_mod_data['model year'])\nplt.subplot(2,4,7)\norg=sns.distplot(imputed_mod_data['origin'])\nplt.subplot(2,4,8)\nhrs=sns.distplot(imputed_mod_data['horsepower'])\n\nplt.show()","62b3dd93":"imp_X_tr=imputed_X_train.drop(['displacement'],axis=1)\nimp_X_ts=imputed_X_valid.drop(['displacement'],axis=1)\nimp_mod_data=imputed_mod_data.drop(['displacement'],axis=1)","fc10c393":"f,(ax1,ax2,ax3,ax4)=plt.subplots(4,1,sharey=True,figsize=(8,25))\n\nax1.scatter(np.log(imputed_mod_data['displacement']),imputed_mod_data['mpg'])\nax1.set_title('displacement and mpg')\nax2.scatter(np.log(imputed_mod_data['horsepower']),imputed_mod_data['mpg'])\nax2.set_title('horsepower and mpg')\nax3.scatter(1\/(model_data['acceleration']),imputed_mod_data['mpg'])\nax3.set_title('acceleration and mpg')\nax4.scatter(np.log(imputed_mod_data['weight']),imputed_mod_data['mpg'])\nax4.set_title('weight and mpg')\n\nplt.show()\n","5d93fbfb":"imp_X_tr.horsepower=np.log(imp_X_tr.horsepower)\nimp_X_tr.weight=np.log(imp_X_tr.weight)\nimp_X_ts.horsepower=np.log(imp_X_ts.horsepower)\nimp_X_ts.weight=np.log(imp_X_ts.weight)\n\nimp_X_tr.acceleration=1\/(imp_X_tr.acceleration)\nimp_X_ts.acceleration=1\/(imp_X_ts.acceleration)\n\nimp_mod_data.horsepower=np.log(imp_mod_data.horsepower)\nimp_mod_data.weight=np.log(imp_mod_data.weight)\n\nimp_mod_data.acceleration=1\/(imp_mod_data.acceleration)\n","bedc6525":"from sklearn.preprocessing import LabelEncoder\n\nlabel_encoder=LabelEncoder()\n\nlabel_X_train=imp_X_tr.copy()\nlabel_X_valid=imp_X_ts.copy()\n\nlabel_X_train['cylinders']=label_encoder.fit_transform(label_X_train['cylinders'])\nlabel_X_valid['cylinders']=label_encoder.transform(label_X_valid['cylinders'])\nimp_mod_data['cylinders']=label_encoder.fit_transform(imp_mod_data['cylinders'])\n\n","f6ea1faf":"from sklearn.preprocessing import OneHotEncoder\n\noh_enc=OneHotEncoder(handle_unknown='ignore',sparse=False)\n\noh_X_train=label_X_train.copy()\noh_X_valid=label_X_valid.copy()\n\noh_X_tr=pd.DataFrame(oh_enc.fit_transform(np.array(oh_X_train['origin']).reshape([-1,1])))\noh_X_va=pd.DataFrame(oh_enc.transform(np.array(oh_X_valid['origin']).reshape([-1,1])))\nimp_mod_data_tr=pd.DataFrame(oh_enc.fit_transform(np.array(imp_mod_data['origin']).reshape([-1,1])))\noh_X_tr.index=oh_X_train.index\noh_X_va.index=oh_X_valid.index\nimp_mod_data_tr.index=imp_mod_data.index\n\noh_X_train.drop(['origin'],axis=1,inplace=True)\noh_X_valid.drop(['origin'],axis=1,inplace=True)\nimp_mod_data.drop(['origin'],axis=1,inplace=True)\n\n#dropping the '0' column produced by one-hot encoding as it was adding up to multi-collinearity.\noh_X_tr.drop([0],axis=1,inplace=True)\noh_X_va.drop([0],axis=1,inplace=True)\nimp_mod_data_tr.drop([0],axis=1,inplace=True)\n\n\noh_X_train=pd.concat([oh_X_train,oh_X_tr],axis=1)\noh_X_valid=pd.concat([oh_X_valid,oh_X_va],axis=1)\nimp_mod_data=pd.concat([imp_mod_data,imp_mod_data_tr],axis=1)\n\n\n","d8fe79ab":"imp_mod_data","8673bfc7":"oh_X_train","02050097":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nscaler_1=StandardScaler()\n#scaler.var_=np.ones((1,4))\n#scaler.fit(oh_X_train[['displacement','horsepower','weight','model year']])\nscaler.fit(oh_X_train[['acceleration']])\nscaler_1.fit(imp_mod_data[['acceleration']])\n\noh_x_tr_sca=scaler.transform(oh_X_train[['acceleration']])\noh_x_vl_sca=scaler.transform(oh_X_valid[['acceleration']])\nimp_mod_data_sca=scaler_1.transform(imp_mod_data[['acceleration']])\n\noh_x_tr_sca=pd.DataFrame(oh_x_tr_sca)\noh_x_vl_sca=pd.DataFrame(oh_x_vl_sca)\nimp_mod_data_sca=pd.DataFrame(imp_mod_data_sca)\n\noh_x_tr_sca.columns=oh_X_train[['acceleration']].columns\noh_x_vl_sca.columns=oh_X_valid[['acceleration']].columns\nimp_mod_data_sca.columns=imp_mod_data[['acceleration']].columns","b6a1200f":"oh_tr_r=oh_X_train.drop(['acceleration'],axis=1)\noh_tv_r=oh_X_valid.drop(['acceleration'],axis=1)\nmod_data_r=imp_mod_data.drop(['acceleration'],axis=1)\n\noh_X_train=pd.concat([oh_tr_r,pd.DataFrame(oh_x_tr_sca)],axis=1)\noh_X_valid=pd.concat([oh_tv_r,pd.DataFrame(oh_x_vl_sca)],axis=1)\nimp_mod_data=pd.concat([mod_data_r,pd.DataFrame(imp_mod_data_sca)],axis=1)","fa4a4d91":"for col in oh_X_train[['horsepower','model year','weight']].columns:\n    oh_X_train[col]=oh_X_train[col]-oh_X_train.mean(axis=0)[col]\n    oh_X_valid[col]=oh_X_valid[col]-oh_X_valid.mean(axis=0)[col]\n    imp_mod_data[col]=imp_mod_data[col]-imp_mod_data.mean(axis=0)[col]","8e72b60e":"y_tr_log=pd.DataFrame(np.log(y_train))\ny_tr_log","1fcb38b3":"from sklearn.linear_model import LinearRegression\nreg=LinearRegression()\nreg.fit(oh_X_train,y_tr_log)","548a6735":"from sklearn.model_selection import cross_val_score\n\nscores = -1 * cross_val_score(reg,oh_X_train, y_tr_log,\n                              cv=5,\n                              scoring='neg_mean_absolute_error')\nprint(\"Average MAE score (across experiments):{}\".format(scores.mean()))\n\n\n","d62d1d23":"reg.score(oh_X_train,y_tr_log)","d612e2a9":"plt.scatter(np.exp(reg.predict(oh_X_valid)),y_valid)","9cd4a74d":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvariables = oh_X_train\nvif = pd.DataFrame()\nvif[\"VIF\"] = [variance_inflation_factor(variables.values, i) for i in range(variables.shape[1])]\nvif[\"features\"] = variables.columns","2012bd0a":"vif","2f46d4ef":"* replacing missing values with the column's mean.","333eebe3":"a.)Linearity","a0fc58f6":"# Encoding Categorical variables.","4c97514a":"# Checking for Multi-collinearity.","f53ddc6a":"* Hello Everyone,this is my first ever notebook on kaggle in which i tried building a linear regression model on the MPG dataset.I have tried my best at it,if you have any suggestions,i would be more than happy to hear from you.","2c5373e1":"* Dropping Displacement feature as it was adding up to multi-collinearity in the model.[](http:\/\/)","32e48923":"* here for 'cylinders' feature ...label encoding was used as the feature is an ordinal variable.","6881fa1b":"the reason we didn't find any missing value above because all the missing values in the horsepower column are being replaced by '?'.This is also one of the reasons why the dtype of horsepower column is 'object'.","4f49389e":"# Checking for Homoscedasticity.","8087ade5":"> * here i only did standardization for the 'acceleration' feature as it was following a uniform distribution.while for the rest of the features,mean-normalization(without dividing by std. deviation) was done.","c9f79d02":"as the car name feature wouldn't have any predictive power hence dropping it.","297f3bf7":"* adding the required non-linearities so that linearity assumption is not violated.","28c77c39":"# Checking for missing values.","1a8c9184":"# Checking Linearity asumptions.","d3acf9b4":"# **Feature Description:**\n* **MPG** is a continuous valued variable which indicates the miles consumed per gallon(fuel economy).\n* **cylinders** is a categorical variable which indicate the no.of cylinders present in the vehicle.It is the power unit of the engine.More no. of cylinders indicate more power is generated by the engine which leads to higher fuel consumption.Thus vehicles with fewer cylinder give better fuel economy(higher mpg) while vehicles with more cylinders give poor fuel economy(lower mpg).\n* **displacement** is a continuous valued variable which indicates the total volume of all the cylinders in the engine.It is usually expressed in litres(L) or cubic centi-meters(cc).Thus higher displacement indicates more no.of cylinders and eventually lower fuel economy.\n* **horsepower** is a continuous valued variable which measures the power an engine develops.High horsepower leads to more fuel consumption which lowers fuel economy.\n* **weight** is a self-explanatory continuous variable.\n* **acceleration** is also a self-explanatory continuous variable and is usually calculated by measuring the time it takes for the vehicle to go from 0-60mph in US&UK while 0-100mph is used in the rest of the world.\n* **model** year is also a categorical variable which denotes the year the vehicle got manufactured in.\n* **origin** is also a categorical variable which represents the country the car is made in.1 stands for America,2 stands for Europe,3 stands for Asia. \n* **car name** is a self-explanatory categorical variable.\n","63c1dc5b":"* here for 'origin' feature we use one-hot encoding as the feature doesn't follow any hirerachical order.","b854aae7":"# Data Visualization."}}