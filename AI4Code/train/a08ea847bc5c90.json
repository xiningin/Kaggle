{"cell_type":{"815261b1":"code","a4e6393c":"code","f51f8684":"code","c23ff2a1":"code","50cb9361":"code","5db42057":"code","fb6c08c6":"code","e3c71f49":"code","c975705d":"code","27551c81":"code","a7c3ab66":"code","626b167f":"code","9d819030":"code","e7aea87f":"code","b57f0f06":"code","547d3e86":"code","89243d47":"code","08c30c67":"code","851d5ae8":"code","0cb71e92":"code","d70d3f06":"markdown","84b1faa9":"markdown","d0ef44d0":"markdown","143c2f7a":"markdown","6ff1bd69":"markdown","5f5687b5":"markdown","03d5f252":"markdown","0905edda":"markdown","bbd2f210":"markdown","d41a1be5":"markdown","18132e08":"markdown","fe5c7ee0":"markdown","226b02f6":"markdown","2fa534f4":"markdown","034d8038":"markdown","d6da21d4":"markdown","9dfdf49e":"markdown"},"source":{"815261b1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a4e6393c":"import warnings\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom scipy.stats import *\nfrom scipy.special import boxcox1p\n\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n\nfrom sklearn.preprocessing import *\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_predict, cross_val_score\nfrom sklearn.feature_selection import SelectFromModel\n\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import f1_score, recall_score\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\n\n#Options\nrandom_state = 100\npd.options.display.max_rows = 999\npd.options.display.max_columns = 999\nwarnings.filterwarnings(\"ignore\")\n\n\n\n\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import roc_curve\n\nfrom xgboost import XGBClassifier","f51f8684":"#\u0414\u043e\u0431\u0430\u0432\u0438\u043c \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438\n\n#\u0420\u0430\u0441\u0447\u0435\u0442 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044f Gini  \u0438 AUC\ndef model_score(y_test, y_pred_prob, return_str=False):\n    gini = 2*roc_auc_score(y_test, y_pred_prob[:,1:])-1\n    auc = roc_auc_score(y_test, y_pred_prob[:,1:])\n    if return_str:\n        return \"Gini: {0:.4} | AUC: {1:.4}\".format(gini, auc)\n    else:\n        return gini, auc\n\n#\u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0433\u0435\u043d\u0435\u0440\u0438\u0440\u0443\u0435\u0442 \u043e\u0442\u0440\u0435\u0437\u043a\u0438 \u0434\u043b\u044f \u0437\u0430\u0434\u0430\u043d\u0438\u044f \u0438\u043d\u0442\u0435\u0440\u0432\u0430\u043b\u043e\u0432. \u0420\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u0432 \u043f\u0430\u0440\u0435 \u0441 \u043f\u043e\u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0439 \u0444\u0443\u043d\u043a\u0446\u0438\u0435\u0439.\ndef make_groups(ser, num):\n    desc = ser.describe()\n    return(np.linspace(desc[\"min\"], desc[\"max\"]+1, num+1))\n    \n#\u0424\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u0440\u0438\u0441\u0432\u0430\u0438\u0432\u0430\u0435\u0442 \u043d\u043e\u043c\u0435\u0440 \u0433\u0440\u0443\u043f\u043f\u044b (\u043e\u0442\u0440\u0435\u0437\u043a\u0430) \u043f\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044e.\ndef set_groups(x, groups):\n    for i in range(len(groups)-1):\n        if (x >= groups[i])&(x < groups[i+1]):\n            return i\n    #return -1\n    raise ValueError(\"Value not in group\")\n\n\ndef feat_types(df):\n    data_describe = df.describe(include=\"all\")\n    num_cols = [c for c in df.columns if df[c].dtype.name != 'object']\n    cat_cols = [c for c in df.columns if df[c].dtype.name == 'object']\n    bin_cols = [c for c in cat_cols if data_describe[c]['unique'] == 2]\n    nonbin_cols = [c for c in cat_cols if data_describe[c]['unique'] > 2]\n    \n    return num_cols, cat_cols, bin_cols, nonbin_cols\n\n\ndef validate_model(models):\n    fig, ax = plt.subplots(figsize=(7,6))\n    ax.plot([0, 1], [0, 1], color='grey', linestyle='--')\n    ax.set_xlim([0.0, 1.0])\n    ax.set_ylim([0.0, 1.008])\n    ax.set_xlabel('False Positive Rate')\n    ax.set_ylabel('True Positive Rate')\n    \n    for model in models:\n        score = cross_val_predict(model, X, y, cv=5, method='predict_proba')\n        gini, roc_auc = model_score(y, score)\n        fpr, tpr, _ = roc_curve(y,  score[:,1:])\n        ax.plot(fpr,tpr, label=\"{0} \\n{1}\".format(type(model).__name__, model_score(y, score, return_str=True)))\n    \n    ax.legend(loc=\"lower right\")\n    ax.set_title(\"ROC\")","c23ff2a1":"#data = pd.read_excel(\"Test case - Regression.xlsx\", header=1)\ndata = pd.read_excel(\"\/kaggle\/input\/testcatse-kasko-sber\/Test case - Regression.xlsx\", header=1)\ndata.drop(\"Unnamed: 0\", axis=1, inplace=True)\n\n#\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0434\u0430\u043d\u043d\u044b\u0435 \u0438 \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\ndisplay(data.head())\ndisplay(data.info())\n\n#\u0411\u0438\u043d\u0430\u0440\u0438\u0437\u0443\u0435\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a \u043f\u043e\u043b\u0430\nmap_Sex = {'Male': 1, 'Female':0}\ndata.replace({\"Gender\": map_Sex}, inplace=True)","50cb9361":"#\u0420\u0430\u0437\u043e\u0431\u044c\u0435\u043c \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \u043d\u0430 \u0433\u0440\u0443\u043f\u043f\u044b \u043f\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u0445 \u0432\u043e\u0437\u0440\u0430\u0441\u0442\u0430 \u0438 \u0434\u043e\u0445\u043e\u0434\u0430\nn_groups = 6\ngr = make_groups(data[\"Age\"], n_groups)\ndata[\"Age_gr\"] = data[\"Age\"].apply(set_groups, args=[gr])\n\n#Add Income groups\ngr = make_groups(data[\"Income\"], n_groups)\ndata[\"Income_gr\"] = data[\"Income\"].apply(set_groups, args=[gr])\n\ndata.head(3)","5db42057":"#\u041e\u0446\u0435\u043d\u0438\u043c \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043c\u0443\u0436\u0447\u0438\u043d \u0438 \u0436\u0435\u043d\u0449\u0438\u043d\nct = pd.crosstab(data[\"Gender\"], data[\"KASKO_flg\"])\ndisplay(ct)","fb6c08c6":"#\u041e\u0446\u0435\u043d\u043a\u0430 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u0434\u043e\u0445\u043e\u0434\u0430 \u043f\u043e \u0432\u043e\u0437\u0440\u0430\u0441\u0442\u043d\u044b\u043c \u0433\u0440\u0443\u043f\u043f\u0430\u043c \u0432 \u0440\u0430\u0437\u0440\u0435\u0437\u0435 \u043c\u0443\u0436\u0447\u0438\u043d \u0438 \u0436\u0435\u043d\u0449\u0438\u043d.\ngroups = np.unique(data[\"Age_gr\"])\nfig, ax = plt.subplots(figsize=(15,4), ncols=2)\nplt.suptitle(\"Income distribution per Age groups\")\nfor g in [0,1]:\n    ax[g].set_title(\"Gender: {}\".format(g))\n    for gr in groups:\n        sns.distplot(data.loc[(data[\"Age_gr\"]==gr)&(data[\"Gender\"]==g), \"Income\"], hist=False, ax=ax[g], label=\"Age_gr_{}\".format(gr))\n    ax[g].grid()","e3c71f49":"fig, ax = plt.subplots(figsize=(24,5), ncols=2)\n\ngrouped = data.groupby([\"Age_gr\", \"Gender\"]).agg({\"KASKO_flg\":\"mean\"})\ngrouped = grouped.unstack(level=-1)\ngrouped.columns = [col[0]+\"_\"+str(col[1]) for col in grouped.columns]\n\nax[0].set_title(\"Age groups vs KASKO prob\")\nax[0].grid()\nax[0] = sns.lineplot(grouped.index, grouped[\"KASKO_flg_0\"], ax=ax[0], label=\"Female\")\nax[0] = sns.lineplot(grouped.index, grouped[\"KASKO_flg_1\"], ax=ax[0], label=\"Male\")\n\ngrouped = data.groupby([\"Income_gr\", \"Gender\"]).agg({\"KASKO_flg\":\"mean\"})\ngrouped = grouped.unstack(level=-1)\ngrouped.columns = [col[0]+\"_\"+str(col[1]) for col in grouped.columns]\n\nax[1].set_title(\"Income groups vs KASKO prob\")\nax[1].grid()\nax[1] = sns.lineplot(grouped.index, grouped[\"KASKO_flg_0\"], ax=ax[1], label=\"Female\")\nax[1] = sns.lineplot(grouped.index, grouped[\"KASKO_flg_1\"], ax=ax[1], label=\"Male\")","c975705d":"fig, ax = plt.subplots(figsize=(24,5), ncols=2)\nplt.suptitle(\"Age groups\")\nfor g in [0,1]:\n    grouped = data[data[\"Gender\"]==g].groupby([\"Age_gr\", \"Income_gr\"]).agg({\"KASKO_flg\":\"mean\"})\n    grouped = grouped.unstack()\n    grouped.columns = [\"Income_gr_\"+str(col[1]) for col in grouped.columns]\n    sns.lineplot(data=grouped, ax=ax[g])\n    ax[g].set_title(\"Gender: {}\".format(g))\n    ax[g].grid()","27551c81":"fig, ax = plt.subplots(figsize=(24,5), ncols=2)\nplt.suptitle(\"Income groups\")\nfor g in [0,1]:\n    grouped = data[data[\"Gender\"]==g].groupby([\"Income_gr\", \"Age_gr\"]).agg({\"KASKO_flg\":\"mean\"})\n    grouped = grouped.unstack()\n    grouped.columns = [\"Age_group_\"+str(col[1]) for col in grouped.columns]\n    sns.lineplot(data=grouped, ax=ax[g])\n    ax[g].set_title(\"Gender: {}\".format(g))\n    ax[g].grid()\n    ","a7c3ab66":"data2 = data.copy()","626b167f":"data = data2.copy()\ndata[\"Gender\"] = data[\"Gender\"].astype(object)\ndata.drop([\"Age_gr\", \"Income_gr\"], axis=1, inplace=True)\ndisplay(data.head(3))","9d819030":"X = data.drop([\"KASKO_flg\"], axis=1)\ny = data['KASKO_flg']\n\nnum_cols, cat_cols, bin_cols, nonbin_cols = feat_types(X)\n\nX_cat=None\nif len(nonbin_cols):\n    X_cat = pd.get_dummies(X[nonbin_cols])\n#X = pd.get_dummies(X, columns=nonbin_cols)\n\npoly = PolynomialFeatures(interaction_only=True, include_bias=True)\nX_poly = poly.fit_transform(X[bin_cols + num_cols])\n#X = pd.DataFrame(poly.fit_transform(X), index=X.index)\n\nscaler = StandardScaler()\nscaler = MinMaxScaler()\n#scaler = RobustScaler()\n\nX_poly = pd.DataFrame(scaler.fit_transform(X_poly), index=X.index)\n#X = pd.DataFrame(scaler.fit_transform(X), index=X.index)\n\nX = pd.concat([X_poly, X_cat], axis=1)\nX.head(5)","e7aea87f":"clf = LogisticRegression(random_state=random_state)\nvalidate_model([clf])","b57f0f06":"clf = XGBClassifier(seed=random_state)\nvalidate_model([clf])","547d3e86":"clf = RandomForestClassifier(random_state=random_state)\nvalidate_model([clf])","89243d47":"def hyperopt_gini(X_, y_, params):\n    try:\n        Model = globals()[params.pop(\"model\")]\n        model = Model(**params)\n        score = cross_val_predict(model, X_, y_, cv=5, method='predict_proba')\n        return -model_score(y_, score)[0]\n    \n    except Exception as ex :\n        #print(ex)\n        return np.inf\n\ndef f_model(params):\n    global best\n    global best_params\n    global best_ext_params\n    acc = hyperopt_gini(X, y, params.copy())\n    if (acc < best):\n        best = acc\n        best_params = params\n        print(\"new best: {0:.4} {1}\".format(best, params))\n    return {'loss': acc, 'status': STATUS_OK}\n\n\ndef model_tune(space, X, y, random_state=random_state, iters=10):\n    print(space[\"model\"])\n    global best\n    global best_params\n    best, best_params = np.inf, None \n    res = fmin(f_model, space, algo=tpe.suggest, max_evals=iters, rstate=np.random.RandomState(random_state))\n    \n    Model = globals()[best_params.pop(\"model\")]\n    print(\"\\nBest_params: \\n\", best_params)\n    \n    model = Model(random_state=random_state, **best_params)\n        \n    print(\"--------------------------------------------------\")\n    return model","08c30c67":"space_lr = {\n    'model': 'LogisticRegression',\n    'penalty': hp.choice('penalty',[\"l1\", \"l2\"]),\n    'C': hp.uniform('C', 0.00001,5),\n    'tol': hp.uniform('tol', 0.0001, 0.1),\n    'solver': hp.choice('solver',[\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"])\n}\n\nspace_xgbc = {\n        'model': 'XGBClassifier',\n        'lambda' : hp.uniform('lambda', 0.0001, 1),\n\n        'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n        'max_depth':        hp.choice('max_depth',        np.arange(2, 5, 1, dtype=int)),\n        'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n        'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n        'subsample':        hp.uniform('subsample', 0.6, 1),\n        'n_estimators':     130,\n        'eval_metric': 'auc',\n        'objective': 'binary:logistic',\n        'nthread': 4,\n        'early_stopping_rounds': 10,\n}\n\nspace_rf = {\n        'model': 'RandomForestClassifier',\n    \n        'n_estimators':     hp.choice('n_estimators',    np.arange(20, 200, 10)),\n        'max_depth':        hp.choice('max_depth',        np.arange(2, 5, 1, dtype=int)),\n        'min_samples_split':hp.choice('min_samples_split',  np.arange(2, 5, 1, dtype=int)),\n        'min_samples_leaf':hp.choice('min_samples_leaf',  np.arange(1, 5, 1, dtype=int)),\n        'n_jobs': 4\n\n}","851d5ae8":"model_rf = model_tune(space_rf, X, y, iters=20)\n\nvalidate_model([model_rf])","0cb71e92":"fitted = []\nfitted.append(model_tune(space_lr, X, y, iters=20))\nfitted.append(model_tune(space_xgbc, X, y, iters=20))\nfitted.append(model_tune(space_rf, X, y, iters=20))\n\nvalidate_model(fitted)","d70d3f06":"\u041f\u043b\u0430\u043d\u0438\u0440\u043e\u0432\u0430\u043b \u0443\u0432\u0438\u0434\u0435\u0442\u044c \u0440\u043e\u0441\u0442 \u0434\u043e\u0445\u043e\u0434\u043e\u0432 \u0441 \u0432\u043e\u0437\u0440\u0430\u0441\u0442\u043e\u043c \u0438 \u0441\u0435\u0433\u043c\u0435\u043d\u0442\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043a\u043b\u0438\u0435\u043d\u0442\u043e\u0432 \u0432\u043d\u0443\u0442\u0440\u0438 \u0433\u0440\u0443\u043f\u043f (\u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0439 \u0434\u043e\u0445\u043e\u0434 \u0432 \u0433\u0440\u0443\u043f\u043f\u0435), \u043d\u043e \u043d\u0435 \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u043e\u0441\u044c - \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u0435\u0442 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u0434\u043e\u0445\u043e\u0434\u0430. \n\u0422\u0430\u043a\u0430\u044f \u0436\u0435 \u043a\u0430\u0440\u0442\u0438\u043d\u0430 \u0432 \u0440\u0430\u0437\u0440\u0435\u0437\u0435 \u0433\u0440\u0443\u043f\u043f \u0434\u043e\u0445\u043e\u0434\u0430 (\u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u043f\u0440\u0438\u0432\u043e\u0434\u0438\u0442\u044c \u043d\u0435 \u0441\u0442\u0430\u043b).","84b1faa9":"## 5.3 RandomForestClassifier","d0ef44d0":"\u0418\u0437\u0443\u0447\u0435\u043d\u0438\u0435 \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u0432 \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 \u043d\u0430\u043c \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0435 \u0432\u044b\u0432\u043e\u0434\u044b:\n - \u041f\u043e\u0432\u0435\u0434\u0435\u043d\u0438\u0435 \u043c\u0443\u0436\u0447\u0438\u043d \u0438 \u0436\u0435\u043d\u0449\u0438\u043d \u0438\u043c\u0435\u0435\u0442 \u043a\u0430\u0440\u0434\u0438\u043d\u0430\u043b\u044c\u043d\u044b\u0435 \u043e\u0442\u043b\u0438\u0447\u0438\u044f:\n     - \u0412\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0438\u043e\u0431\u0440\u0435\u0442\u0435\u043d\u0438\u044f \u043f\u043e\u043b\u0438\u0441\u0430 \u041a\u0410\u0421\u041a\u041e \u0443 \u043c\u043e\u043b\u043e\u0434\u044b\u0445 \u043c\u0443\u0436\u0447\u0438\u043d \u0438\u043c\u0435\u0435\u0442 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435. \u0412 \u0441\u0432\u043e\u044e \u043e\u0447\u0435\u0440\u0435\u0434\u044c, \u0441\u0442\u0430\u0440\u0448\u0438\u0435 \u043f\u043e\u043a\u043e\u043b\u0435\u043d\u0438\u044f \u0441\u043a\u043b\u043e\u043d\u043d\u044b \u0438\u0437\u0431\u0435\u0433\u0430\u0442\u044c \u043f\u043e\u0434\u043e\u0431\u043d\u044b\u0445 \u0442\u0440\u0430\u0442. \n     - \u0416\u0435\u043d\u0449\u0438\u043d\u044b \u0438\u043c\u0435\u044e\u0442 \u043c\u0435\u043d\u0435\u0435 \u0432\u044b\u0440\u0430\u0436\u0435\u043d\u043d\u044b\u0439 \u0442\u0440\u0435\u043d\u0434, \u043d\u043e \u0432 \u043e\u0431\u0440\u0430\u0442\u043d\u043e\u043c \u043d\u0430\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0438 - \u0441 \u0432\u043e\u0437\u0440\u0430\u0441\u0442\u043e\u043c \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0438\u043e\u0431\u0440\u0435\u0442\u0435\u043d\u0438\u044f \u0441\u0442\u0440\u0430\u0445\u043e\u0432\u043a\u0438 \u043f\u043e\u0432\u044b\u0448\u0430\u0435\u0442\u0441\u044f. \n - \u0418 \u0434\u043b\u044f \u043c\u0443\u0436\u0447\u0438\u043d, \u0438 \u0434\u043b\u044f \u0436\u0435\u043d\u0449\u0438\u043d \u0443\u0440\u043e\u0432\u0435\u043d\u044c \u0434\u043e\u0445\u043e\u0434\u0430 \u0438\u043c\u0435\u0435\u0442 \u0441\u0445\u043e\u0436\u0435\u0435 \u0432\u043b\u0438\u044f\u043d\u0438\u0435 \u043d\u0430 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0438\u043e\u0431\u0440\u0435\u0442\u0435\u043d\u0438\u044f \u043f\u043e\u043b\u0438\u0441\u0430 \u041a\u0410\u0421\u041a\u041e \n - \u0412 \u0433\u0440\u0443\u043f\u043f\u0435 \u0441 \u043d\u0430\u0438\u043c\u0435\u043d\u044c\u0448\u0438\u043c \u0434\u043e\u0445\u043e\u0434\u043e\u043c \u043d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u0442\u0441\u044f \u0438\u0437\u043b\u043e\u043c \u0438 \u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0435 \u0441\u043d\u0438\u0436\u0435\u043d\u0438\u0435 \u043f\u043e\u0443\u043f\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0439 \u0441\u043f\u043e\u0441\u043e\u0431\u043d\u043e\u0441\u0442\u0438 \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0434\u0440\u0443\u0433\u0438\u0445 \u0433\u0440\u0443\u043f\u043f.","143c2f7a":"# 5. Model","6ff1bd69":"## 3.2 \u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445\n### \u0420\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0434\u043e\u0445\u043e\u0434\u0430 (Income) \u043f\u043e \u0432\u043e\u0437\u0440\u0430\u0441\u0442\u043d\u044b\u043c \u0433\u0440\u0443\u043f\u043f\u0430\u043c","5f5687b5":"## 5.1 \u041b\u043e\u0433\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0430\u044f \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f","03d5f252":"## 5.2 xgBoost","0905edda":"# 4. \u0414\u0430\u0442\u0430\u0441\u0435\u0442","bbd2f210":"### \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u0440\u0430\u0437\u0440\u0435\u0437\u0435 \u0433\u0440\u0443\u043f\u043f","d41a1be5":"# 3. \u0418\u0437\u0443\u0447\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445","18132e08":"# 1. \u0418\u043c\u043f\u043e\u0440\u0442\u044b \u0438 \u043f\u043e\u043b\u0435\u0437\u043d\u044b\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438","fe5c7ee0":"- \u041c\u0443\u0436\u0447\u0438\u043d\u044b\n    - \u0413\u0440\u0430\u0444\u0438\u043a\u0438 \u043f\u043e \u043c\u0443\u0436\u0447\u0438\u043d\u0430\u043c \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u044e\u0442 \u0441\u0438\u043d\u0445\u0440\u043e\u043d\u043d\u044b\u0439 \u0442\u0440\u0435\u043d\u0434 \u0432 \u0440\u0430\u0437\u043d\u044b\u0445 \u0433\u0440\u0443\u043f\u043f\u0430\u0445, \u043d\u0435\u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e \u043e\u0442 \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f - \u043f\u043e \u0432\u043e\u0437\u0440\u0430\u0441\u0442\u0443 \u0438\u043b\u0438 \u043f\u043e \u0434\u043e\u0445\u043e\u0434\u0443.\n    - \u041c\u043e\u0436\u043d\u043e \u043e\u0442\u043c\u0435\u0442\u0438\u0442\u044c \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u0443\u044e \u043d\u0435\u043b\u0438\u043d\u0435\u0439\u043d\u043e\u0441\u0442\u044c \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0442\u0438 \u043f\u0440\u0438\u043e\u0431\u0440\u0435\u0442\u0435\u043d\u0438\u044f \u043f\u043e\u043b\u0438\u0441\u0430 \u041a\u0410\u0421\u041a\u041e \u0432 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 \u043e\u0442 \u0432\u043e\u0437\u0440\u0430\u0441\u0442\u0430 (\u0438\u043b\u0438 \u043d\u0430\u043b\u0438\u0447\u0438\u0435 \u0438\u0437\u043b\u043e\u043c\u0430 \u043c\u0435\u0436\u0434\u0443 2 \u0438 3 \u0432\u043e\u0437\u0440\u0430\u0441\u0442\u043d\u044b\u043c\u0438 \u0433\u0440\u0443\u043f\u043f\u0430\u043c\u0438)\n- \u0416\u0435\u043d\u0449\u0438\u043d\u044b\n    - \u0420\u0435\u0437\u043a\u043e\u0435 \u0441\u043d\u0438\u0436\u0435\u043d\u0438\u0435 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0438 \u043f\u0440\u0438\u043e\u0431\u0440\u0435\u0442\u0435\u043d\u0438\u044f \u043f\u043e\u043b\u0438\u0441\u0430 \u041a\u0410\u0421\u041a\u041e \u0432 \u0433\u0440\u0443\u043f\u043f\u0435 \u043c\u043e\u043b\u043e\u0434\u044b\u0445 \u0436\u0435\u043d\u0449\u0438\u043d (\u0433\u0440\u0443\u043f\u043f\u044b 0-2).\n    - \u0412 \u0446\u0435\u043b\u043e\u043c \u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u0432\u044b\u0433\u043b\u044f\u0434\u044f\u0442 \u043c\u0435\u043d\u0435\u0435 \u043b\u0438\u043d\u0435\u0439\u043d\u043e \u0438 \u0441 \u0431\u043e\u043b\u044c\u0448\u0438\u043c \u0447\u0438\u0441\u043b\u043e\u043c \u0438\u0437\u043b\u043e\u043c\u043e\u0432 \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043c\u0443\u0436\u0447\u0438\u043d.\n- \u0413\u0440\u0430\u0444\u0438\u043a\u0438 \u043f\u043e\u0434\u0442\u0432\u0435\u0440\u0436\u0434\u0430\u044e\u0442 \u0440\u0435\u0437\u043a\u043e\u0435 \u0441\u043d\u0438\u0436\u0435\u043d\u0438\u0435 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0438 \u043f\u0440\u0438\u043e\u0431\u0440\u0435\u0442\u0435\u043d\u0438\u044f \u0441\u0442\u0440\u0430\u0445\u043e\u0432\u043a\u0438 \u0432 \u0441\u0435\u0433\u043c\u0435\u043d\u0442\u0435 \u0441 \u043d\u0430\u0438\u043c\u0435\u043d\u044c\u0448\u0438\u043c \u0443\u0440\u043e\u0432\u043d\u0435\u043c \u0434\u043e\u0445\u043e\u0434\u0430, \u043a\u0430\u043a \u0434\u043b\u044f \u043c\u0443\u0436\u0447\u0438\u043d, \u0442\u0430\u043a \u0438 \u0434\u043b\u044f \u0436\u0435\u043d\u0449\u0438\u043d.\n\n","226b02f6":"### \u0412\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0438\u043e\u0431\u0440\u0435\u0442\u0435\u043d\u0438\u044f \u043f\u043e\u043b\u0438\u0441\u0430 \u041a\u0410\u0421\u041a\u041e \u0432 \u0440\u0430\u0437\u0440\u0435\u0437\u0435 \u0433\u0440\u0443\u043f\u043f (Age, Income) \u0434\u043b\u044f \u043c\u0443\u0436\u0447\u0438\u043d \u0438 \u0436\u0435\u043d\u0449\u0438\u043d","2fa534f4":"## 3.1 \u0424\u0438\u0447\u0438","034d8038":"# 2. \u0427\u0442\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445","d6da21d4":"## 5.3 \u0422\u044e\u043d\u0438\u043d\u0433 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432","9dfdf49e":"\u041d\u0443\u0436\u043d\u043e \u043f\u043e\u0441\u0442\u0440\u043e\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c \u043e\u0442\u043a\u043b\u0438\u043a\u0430 \u043d\u0430 \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u0438\u0435 \u043f\u043e\u043a\u0443\u043f\u043a\u0438 \u043f\u043e\u043b\u0438\u0441\u0430 \u041a\u0410\u0421\u041a\u041e \u2013 \u043e\u0431\u0443\u0447\u0438\u0442\u044c \u043b\u043e\u0433\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0443\u044e \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044e, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0431\u0443\u0434\u0435\u0442 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0442\u044c \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c \u043f\u043e\u043a\u0443\u043f\u043a\u0438.\n\n\u041a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u0440\u0435\u0448\u0435\u043d\u0438\u044f \u0431\u0443\u0434\u0435\u0442 \u043e\u0446\u0435\u043d\u0438\u0432\u0430\u0442\u044c\u0441\u044f \u043f\u043e \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u0435 Gini (\u0432\u043d\u0438\u043c\u0430\u0442\u0435\u043b\u044c\u043d\u0435\u0435 \u043a \u0434\u0430\u043d\u043d\u044b\u043c, \u0438\u043c\u0435\u0435\u0442 \u0441\u043c\u044b\u0441\u043b \u0438\u0445 \u043f\u0440\u0435\u0434\u0432\u0430\u0440\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0438\u0437\u0443\u0447\u0438\u0442\u044c) \u0438 \u043e\u0431\u0449\u0435\u0439 \u0430\u043a\u043a\u0443\u0440\u0430\u0442\u043d\u043e\u0441\u0442\u0438 \u043e\u0444\u043e\u0440\u043c\u043b\u0435\u043d\u0438\u044f. \u041c\u043e\u0434\u0435\u043b\u044c \u0434\u043e\u043b\u0436\u043d\u0430 \u0431\u044b\u0442\u044c \u0432\u0430\u043b\u0438\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u0430 \u0438 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u0434\u043e\u043b\u0436\u043d\u044b \u0431\u044b\u0442\u044c \u043f\u043e\u043a\u0430\u0437\u0430\u043d\u044b \u0432 \u0440\u0435\u0448\u0435\u043d\u0438\u0438. \u041f\u043e\u0447\u0435\u043c\u0443 \u0438\u043c\u0435\u043d\u043d\u043e \u043b\u043e\u0433\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0430\u044f \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f \u2013 1) \u044d\u0442\u043e \u043d\u0430\u0438\u0431\u043e\u043b\u0435\u0435 \u043f\u0440\u043e\u0441\u0442\u043e\u0439 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c, 2) \u043e\u043d \u043f\u043e\u0437\u0432\u043e\u043b\u0438\u0442 \u043e\u0446\u0435\u043d\u0438\u0442\u044c \u043b\u043e\u0433\u0438\u043a\u0443 \u0440\u0435\u0448\u0435\u043d\u0438\u044f, \u0430 \u043d\u0435 \u0442\u043e\u043b\u044c\u043a\u043e \u0442\u0435\u0445\u043d\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u043d\u0430\u0432\u044b\u043a.\n\n\n\u0414\u0430\u043d\u043d\u044b\u0435 \u043b\u0435\u0436\u0430\u0442 \u043d\u0430 \u044f\u043d\u0434\u0435\u043a\u0441.\u0434\u0438\u0441\u043a\u0435: https:\/\/yadi.sk\/d\/M0eQmmy83Tinsg"}}