{"cell_type":{"6d8c2c8f":"code","905e14e0":"code","259700bb":"code","59f58438":"code","b7f59fa5":"code","14245250":"code","58967baf":"code","4fc9276a":"code","0d6d6394":"code","2b3a3101":"code","cc265809":"code","f27c30bd":"code","2e525079":"code","56a6757b":"markdown","f06bb242":"markdown"},"source":{"6d8c2c8f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","905e14e0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport re\nfrom tqdm.notebook import tqdm\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import Ridge, LinearRegression\nfrom sklearn.metrics import mean_squared_error\n","259700bb":"training_file = pd.read_csv(\"..\/input\/commonlitreadabilityprize\/train.csv\")\ntest_file = pd.read_csv(\"..\/input\/commonlitreadabilityprize\/test.csv\")\nsubmission = pd.read_csv(\"..\/input\/commonlitreadabilityprize\/sample_submission.csv\")\n","59f58438":"training_file.head()","b7f59fa5":"training_file.shape","14245250":"data = training_file[['excerpt', 'target']]\ndata = data.sample(frac=1).reset_index(drop=True)\nexcerpt, targets = training_file['excerpt'].values, training_file['target'].values\n\nt_X, v_X = excerpt[:2750], excerpt[2750:]\nt_Y, v_Y = targets[:2750], targets[2750:]\n\nprint(t_X.shape, v_X.shape)\nprint(t_Y.shape, v_Y.shape)\n","58967baf":"from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor","4fc9276a":"models={\"LR\":LinearRegression(),\n        \"rdg\":Ridge(),\n        \"rf\":RandomForestRegressor(n_estimators=100),\n        \"Adb\":AdaBoostRegressor(n_estimators=120)\n        }","0d6d6394":"def train(model,vec):\n    model_pipeline=make_pipeline(\n    vec,\n    model\n    )\n    model_pipeline.fit(t_X, t_Y)\n\n    preds = model_pipeline.predict(v_X)\n    mse_loss = mean_squared_error(v_Y, preds)\n\n    print(f\"MSE Loss using {name} model is: {mse_loss}\")\n","2b3a3101":"for name,model in zip(models.keys(),models.values()):\n        train(model,vec=CountVectorizer(binary=True))","cc265809":"for name,model in zip(models.keys(),models.values()):\n        train(model, vec=TfidfVectorizer(binary=True, ngram_range=(1, 1)))","f27c30bd":"#From above we can see that ridge regression has minimum loss\nfinal_model=make_pipeline(\n                TfidfVectorizer(binary=True, ngram_range=(1, 1)),\n                models['rdg'])\nfinal_model.fit(t_X, t_Y)","2e525079":"test = test_file[['id', 'excerpt']]\ntest_ids = test['id'].tolist()\ntest_text = test['excerpt'].values\n\ntest_preds_linear = final_model.predict(test_text)\n\nsubmission = pd.DataFrame()\nsubmission['id'] = test_ids\nsubmission['target']=test_preds_linear\nsubmission.to_csv(\"submission.csv\", index=None)","56a6757b":"<h2>Using Countvectorizer","f06bb242":"<h2>Using TfidfVectorizer "}}