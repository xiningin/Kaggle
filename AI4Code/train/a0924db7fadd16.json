{"cell_type":{"a0e477bd":"code","7aa9fc15":"code","f2970290":"code","adf18f0c":"code","1bb4b901":"code","2d609672":"code","34907b92":"code","dda2e2a0":"code","944dd109":"code","5c6a9075":"code","fbe8df30":"code","2f8a35a3":"code","0b4aa5be":"code","fc0aada0":"code","ee92f161":"code","7b193d93":"code","6b780d75":"code","1703d085":"code","cc29b15d":"code","8eb2c464":"code","61a08f39":"code","d27f96e6":"code","579d4ea2":"code","fb0c86fa":"code","1c2472b5":"code","a5b8e697":"markdown","e7bde816":"markdown","0c7ca578":"markdown","cf288001":"markdown","390bafe9":"markdown","586e897f":"markdown","7659663c":"markdown","8d37750f":"markdown","a8cfc406":"markdown","0a176064":"markdown","71fc7b21":"markdown","6988de06":"markdown","049ad519":"markdown","3bc7f9af":"markdown","39e800a1":"markdown","6faeee66":"markdown","941b640f":"markdown","28c41d64":"markdown","b5e6535f":"markdown","89b66d8f":"markdown","e4a82e7f":"markdown"},"source":{"a0e477bd":"# Data Analysis\nimport pandas as pd\nfrom collections import Counter\n\n# Data Cleaning \nimport re # Regular Expressions\nimport string \nimport nltk\nfrom nltk.tokenize import word_tokenize \nfrom nltk.stem.porter import PorterStemmer # Stemmer\n#nltk.download()\n\n# Preprocessing\nfrom sklearn.model_selection import train_test_split\n\n# Modeling\nfrom sklearn.naive_bayes import MultinomialNB\n\n#Validation\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix","7aa9fc15":"data = pd.read_csv('..\/input\/fraudulent-e-mails-spam-or-ham\/kg_train.csv\/kg_train.csv')\ntest = pd.read_csv('..\/input\/fraudulent-e-mails-spam-or-ham\/kg_test.csv\/kg_test.csv')\n\ndata.head(10)","f2970290":"# I'll store the data into the variable data_copy\ndata_copy = data.copy()\ntest_copy = test.copy()","adf18f0c":"data_copy.loc[97]","1bb4b901":"def len_raw_text(dataset):\n    dataset[\"text_length_t\"] = 0\n    for i,text in enumerate(dataset.text):\n        dataset[\"text_length_t\"][i] = len(text)\n    \nlen_raw_text(data_copy)\nlen_raw_text(test_copy)\n\nprint(\"Ham emails average text length: \", (sum(data_copy.text_length_t[data_copy.label == 0]))\/(data_copy[data_copy.label == 0].shape[0]))\nprint(\"Spam emails average text length: \", (sum(data_copy.text_length_t[data_copy.label == 1]))\/(data_copy[data_copy.label == 1].shape[0]))","2d609672":"data_copy.loc[[9,236,429,7]].text","34907b92":"def find_match(pattern, string):\n    ''' This function looks for a specific pattern in a text, if it finds the pattern returns 1 and if not 0. '''\n    match = re.search(pattern, string)\n    if match:\n        return 1\n    else:\n        return 0\n\ndef HTML_Clean(dataset):\n\n    # patterns is a list that contains all the patterns related with html documentation.\n    patterns_HTML = [re.compile(r'(?is)<(script|style).*?>.*?(<\/\\1>)'),\n    re.compile(r'(?s)<!--(.*?)-->[\\n]?'),\n    re.compile(r'(?s)<.*?>'),\n    ]\n\n    # More patterns that I'm looking for. I'm creating these patterns outside the patterns list because it makes it easier to detect and store them.\n    patterns_CSS = re.compile(r'(?s)[Pp]{.*}(body)') # CSS pattern\n    patterns_ERROR = re.compile(r'(?s)^[Ee]rr:\\d{3}') # Error pattern\n    patterns_Email = re.compile(r'.+@[A-Za-z]*\\.[A-Za-z]{3}') # Email pattern\n\n\n    # Create the variables to store the information related with the removed elements.\n    dataset[\"HTML_True\"] = 0 \n    dataset[\"CSS_True\"] = 0\n    dataset[\"ERROR_True\"] = 0\n    dataset[\"EMAIL_True\"] = 0\n\n    # The following code finds the presence of the elements and fill the variables.\n    for i,doc in enumerate(dataset.text):\n        for pattern in patterns_HTML:\n            aux = find_match(pattern, doc)\n            if aux == 1:\n                dataset.HTML_True[i] = 1\n        if find_match(patterns_CSS,doc):\n            dataset.CSS_True[i] = 1\n        if find_match(patterns_ERROR,doc):\n            dataset.ERROR_True[i] = 1\n        if find_match(patterns_Email,doc):\n            dataset.EMAIL_True[i] = 1\n        \n        # Once the information is stored in variables, we can clean it. I won't clean the emails from the text because I've seen that this makes the model more inaccurate.\n\n        if ((dataset.HTML_True[i] == 1) or (dataset.CSS_True[i] == 1) or (dataset.ERROR_True[i] == 1)):\n            # First we remove inline JavaScript\/CSS:\n            cleaned = re.sub(r\"(?is)<(script|style).*?>.*?(<\/\\1>)\", \"\", dataset.text[i].strip())\n    \n            # Then we remove html comments. This has to be done before removing regular\n            # tags since comments can contain '>' characters.\n            cleaned = re.sub(r\"(?s)<!--(.*?)-->[\\n]?\", \"\", cleaned)\n    \n            # Next we can remove the remaining tags:\n            cleaned = re.sub(r\"(?s)<.*?>\", \" \", cleaned)\n\n            # Style elements (CSS)\n            cleaned = re.sub(r'(?s)[Pp]{.*}(body)', \" \", cleaned)\n\n            # Error\n            cleaned = re.sub(r\"(?s)^[Ee]rr:\\d{3}\", \"\", cleaned)\n    \n            # Finally, we deal with whitespace\n            cleaned = re.sub(r\"&nbsp;\", \" \", cleaned)\n            cleaned = re.sub(r\"  \", \" \", cleaned)\n            cleaned = re.sub(r\"  \", \" \", cleaned)\n    \n            # Replace the original text for the cleaned one\n            dataset.text[i] = cleaned.strip()\n\nHTML_Clean(data_copy)\nHTML_Clean(test_copy)","dda2e2a0":"print(\"HTML elements in ham emails: {:.2%}\".format(data_copy.groupby(\"label\").HTML_True.value_counts()[0][1]\/(data_copy.groupby(\"label\").HTML_True.value_counts()[0][1]+data_copy.groupby(\"label\").HTML_True.value_counts()[0][0])))\nprint(\"HTML elements in spam emails: {:.2%}\".format(data_copy.groupby(\"label\").HTML_True.value_counts()[1][1]\/(data_copy.groupby(\"label\").HTML_True.value_counts()[1][1]+data_copy.groupby(\"label\").HTML_True.value_counts()[1][0])))\nprint(\"\\nCSS elements in ham emails: {:.0%}\".format(0\/(0+data_copy.groupby(\"label\").CSS_True.value_counts()[0][0])))\nprint(\"CSS elements in spam emails: {:.2%}\".format(data_copy.groupby(\"label\").CSS_True.value_counts()[1][1]\/(data_copy.groupby(\"label\").CSS_True.value_counts()[1][1]+data_copy.groupby(\"label\").CSS_True.value_counts()[1][0])))\nprint(\"\\nERROR elements in ham emails: {:.0%}\".format(0\/(0+data_copy.groupby(\"label\").ERROR_True.value_counts()[0][0])))\nprint(\"ERROR elements in spam emails: {:.2%}\".format(data_copy.groupby(\"label\").ERROR_True.value_counts()[1][1]\/(data_copy.groupby(\"label\").ERROR_True.value_counts()[1][1]+data_copy.groupby(\"label\").ERROR_True.value_counts()[1][0])))\nprint(\"\\nEMAIL elements in ham emails: {:.2%}\".format(data_copy.groupby(\"label\").EMAIL_True.value_counts()[0][1]\/(data_copy.groupby(\"label\").EMAIL_True.value_counts()[0][1]+data_copy.groupby(\"label\").EMAIL_True.value_counts()[0][0])))\nprint(\"EMAIL elements in spam emails: {:.2%}\".format(data_copy.groupby(\"label\").EMAIL_True.value_counts()[1][1]\/(data_copy.groupby(\"label\").EMAIL_True.value_counts()[1][1]+data_copy.groupby(\"label\").EMAIL_True.value_counts()[1][0])))","944dd109":"data_copy.groupby([\"HTML_True\", \"EMAIL_True\", \"label\"]).label.count()","5c6a9075":"print(\"Spam emails with EMAIL elements and WITHOUT HTML elements: {:.2%}\".format(data_copy.groupby([\"HTML_True\", \"EMAIL_True\", \"label\"]).label.count()[0][1][1]\/(data_copy.groupby([\"HTML_True\", \"EMAIL_True\", \"label\"]).label.count()[0][1][1] + data_copy.groupby([\"HTML_True\", \"EMAIL_True\", \"label\"]).label.count()[0][1][0])))\nprint(\"Spam emails with HTML elements and WITHOUT EMAIL elements: {:.2%}\".format(data_copy.groupby([\"HTML_True\", \"EMAIL_True\", \"label\"]).label.count()[1][0][1]\/(data_copy.groupby([\"HTML_True\", \"EMAIL_True\", \"label\"]).label.count()[1][0][1] + data_copy.groupby([\"HTML_True\", \"EMAIL_True\", \"label\"]).label.count()[1][0][0])))\nprint(\"\\nHam emails WITH HTML and EMAIL elements: {:.2%}\".format(data_copy.groupby([\"HTML_True\", \"EMAIL_True\", \"label\"]).label.count()[1][1][0]\/(data_copy.groupby([\"HTML_True\", \"EMAIL_True\", \"label\"]).label.count()[1][1][1] + data_copy.groupby([\"HTML_True\", \"EMAIL_True\", \"label\"]).label.count()[1][1][0])))\n","fbe8df30":"def HTML_EMAIL_new(dataset):\n    dataset[\"HTML0_EMAIL1\"] = 0\n    dataset[\"HTML1_EMAIL1\"] = 0\n    for i in range(len(dataset)):\n        if dataset.HTML_True[i] == 1:\n            if dataset.EMAIL_True[i] == 0:\n                dataset[\"HTML0_EMAIL1\"][i] = 1\n        if dataset.HTML_True[i] == 0:\n            if dataset.EMAIL_True[i] == 1:\n                dataset[\"HTML0_EMAIL1\"][i] = 1\n        if dataset.HTML_True[i] == 1:\n            if dataset.EMAIL_True[i] == 1:\n                dataset[\"HTML1_EMAIL1\"][i] = 1\n\nHTML_EMAIL_new(data_copy)\nHTML_EMAIL_new(test_copy)","2f8a35a3":"re.escape(string.punctuation)","0b4aa5be":"# The main idea for this function is the same as the one I did before, clean the text keeping the information removed in binary variables.\n\ndef punctuation_and_substrings(dataset):\n\n    # I'll first define the variable that I want to create, one for punctuation and the others for the length of the substrings. I will explain later why I'm creating this variables.\n\n    dataset[\"punctuation\"] = 0\n    dataset[\"substring_+50_1\"] = 0\n    dataset[\"substring_+50_2\"] = 0\n    dataset[\"all_substring_1\"] = 0\n    dataset[\"all_substring_2\"] = 0\n    dataset[\"len_substring\"] = 0\n\n    # The following code only look for the presence of the element on the text and fill the variables\n\n    regex = re.compile('[%s]' % re.escape(string.punctuation))\n\n    for i,text in enumerate(dataset.text):\n        dataset.punctuation[i] = len(re.findall(regex, text))\n        ss = re.findall(r'.', text) # store every character of the text in a vector\n        find_space = False # find_space looks if the emails have at least one space, if not, we are facing an email which is formed by one long substring\n        aux_1 = 0 # aux_1 stores the position of the blank spaces\n        for j in range(len(ss)): \n            if ss[j] == \" \":\n                find_space = True\n                if ((j - aux_1) >= 50):\n                    dataset[\"len_substring\"][i] = j-aux_1\n                    if dataset[\"len_substring\"][i] > 100:\n                        dataset[\"substring_+50_2\"][i] = 1\n                    else:\n                        dataset[\"substring_+50_1\"][i] = 1\n                    aux_1 = j+1\n                else:\n                    aux_1 = j+1\n            if j == (len(ss)-1) and find_space == False:\n                dataset[\"len_substring\"][i] = len(ss)\n                if dataset[\"len_substring\"][i] >= 100:\n                    dataset[\"all_substring_1\"][i] = 1\n                else:\n                    dataset[\"all_substring_2\"][i] = 1\n\npunctuation_and_substrings(data_copy)\npunctuation_and_substrings(test_copy)\n\n# Before cleaning the elements, I'll store the following elements from the raw text: Capital letters and equal signs (spam emails are more likely to have this elements)\n\ndef Capital_Letters(dataset):\n    dataset[\"Capital_Letters\"] = 0\n    dataset[\"equal_sign\"] = 0\n\n    for i,text in enumerate(dataset.text):\n        if len(text)-len(re.findall(r' ', text)) > 0:\n            if (len(re.findall(r'[A-Z]', text)) \/ (len(text)-len(re.findall(r' ', text)))) > 0.5:\n                dataset.Capital_Letters[i] = 1\n        if re.search(r'=', text):\n            dataset.equal_sign[i] = 1\n\nCapital_Letters(data_copy)\nCapital_Letters(test_copy)\n\n# The following function is going to deal with capital letters (converting all the text in lowercase), punctuation (by removing it, but we'll create a veriable to store and quantify the presence of that problem), single characters (by removing it) and doble spaces (it will replace doble space with one space) and long substrings. The cleaned text is going to be store in a new variable in the dataset called preprocessed_text.\n\ndef clean_text(text):\n\n    # remove all single characters\n    processed_feature= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', str(text))\n\n    # remove punctuation\n    processed_feature= re.sub('[%s]' % re.escape(string.punctuation), ' ', processed_feature)\n\n    # Remove single characters from the start\n    processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature) \n\n    # Substituting multiple spaces with single space\n    processed_feature = re.sub(r'\\s+', ' ', processed_feature, flags=re.I)\n\n    # Converting to Lowercase\n    processed_feature = processed_feature.lower()\n\n    # Remove large substrings (more than 50 chars)\n    substring = re.findall(r'.', processed_feature)\n    to_remove = []\n    find_space = False\n    aux_1 = 0\n    for i in range(len(substring)):\n        if substring[i] == \" \":\n            find_space = True\n            if (i - aux_1) >= 100:\n                to_remove.append([aux_1,i])\n                aux_1 = i+1\n            else:\n                aux_1 = i+1\n        if (i == (len(substring)-1)) and (find_space == False) and (len(substring) >= 50):\n            to_remove.append([0,len(substring)])\n    for substring_index in to_remove:\n        processed_feature = re.sub(processed_feature[substring_index[0]:substring_index[1]], \"\", processed_feature)\n\n    \n    return processed_feature\n\ndata_copy[\"preprocessed_text\"] = 0\ndata_copy.loc[:, \"preprocessed_text\"] = data_copy[\"text\"].apply(clean_text)\ntest_copy[\"preprocessed_text\"] = 0\ntest_copy.loc[:, \"preprocessed_text\"] = test_copy[\"text\"].apply(clean_text)\n\n# Once the text is cleaned, I'll also keep the length of it:\n\ndef length_and_punctuation(dataset):\n\n    # Creating the variable \"text_length\" to store the length of a specific text\n    dataset[\"text_length_pt\"] = 0\n    dataset[\"len_text_0\"] = 0\n\n    for i,text in enumerate(dataset.preprocessed_text):\n        dataset.text_length_pt[i] = len(text)\n        if dataset.text_length_pt[i] == 0:\n            dataset[\"len_text_0\"][i] = 0\n\nlength_and_punctuation(data_copy)\nlength_and_punctuation(test_copy)","fc0aada0":"data_copy","ee92f161":"data_copy.groupby(\"label\").punctuation.mean()","7b193d93":"train_tokenized = [word_tokenize(doc) for doc in data_copy.preprocessed_text]\ntest_tokenized = [word_tokenize(doc) for doc in test_copy.preprocessed_text]\n\ntrain_tokenized[1], test_tokenized[2]","6b780d75":"def stemmer(dataset_token):\n    porter = PorterStemmer()\n\n    final_doc = []\n\n    for i,doc in enumerate(dataset_token):\n        final_doc.append([])\n        for word in doc:\n            final_doc[i].append(porter.stem(word))\n        \n    return final_doc\n\nfinal_doc = stemmer(train_tokenized)\nfinal_doc_validation = stemmer(test_tokenized)\n\nfinal_doc[1], final_doc_validation[2]","1703d085":"def normalize_text(dataset, doc):\n    dataset[\"normalized_text\"] = \"\"\n\n    for i in range(len(dataset)):\n        sentence = \"\"\n        for word in doc[i]:\n            sentence = sentence + \" \" + word\n        dataset.normalized_text[i] = sentence\n\nnormalize_text(data_copy, final_doc)\nnormalize_text(test_copy, final_doc_validation)","cc29b15d":"data_copy","8eb2c464":"def MinMaxScaler(data, feature):\n    \"\"\" This function takes a list of numerical features and normalize them by using the MinMax Scaler \"\"\"\n    maximum = data[feature].max()\n    minimum = data[feature].min()\n    for i,f in enumerate(data[feature]):\n        data.loc[i, feature] = (data.loc[i, feature] - minimum) \/ (maximum - minimum)\n\ndef MultinomialModel(data, drop_features, numerical_features):\n    \"\"\" This function takes a dataset (data), a list of features to drop (drop_features), like the text, and a list of numerical features to normalize (numerical_features). The function will return the indexes for the observations I'm failing to classify.\"\"\"\n\n    train_final = data.drop(drop_features, axis=1)\n\n    X = train_final.drop(\"label\", axis=1)\n    y = train_final[\"label\"]\n\n    for feature in numerical_features:\n        MinMaxScaler(X, feature)\n\n    wrong_predictions_index = []\n    f1 = []\n    p_s = []\n    r_s = []\n\n    # The following part of the function tries to simulate some kind of cross-validation score, this will definitely help to give more precision in the accuracy scores and to get a deeper understanding of the emails I'm failing to identify.\n\n    for i in range(10):\n        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state = i)\n\n        model = MultinomialNB()\n        model.fit(X_train,y_train)\n        \n        y_pred = model.predict(X_val)\n\n        f1.append(f1_score(y_pred, y_val))\n        p_s.append(precision_score(y_pred, y_val))\n        r_s.append(recall_score(y_pred, y_val))\n\n        for i,j in enumerate(y_val.index):\n            if y_pred[i] != y_val[j]:\n                if j not in wrong_predictions_index:\n                    wrong_predictions_index.append(j)\n\n    print(\"F1 Score: \", sum(f1)\/len(f1), \" Precision Score: \", sum(p_s)\/len(p_s), \" Recall Score: \",sum(r_s)\/len(r_s))\n\n    return wrong_predictions_index\n\nwrong_predictions_index = MultinomialModel(data_copy, [\"text\", \"preprocessed_text\", \"normalized_text\"], [\"len_substring\", \"text_length_t\", \"text_length_pt\", \"punctuation\"])\n","61a08f39":"def add_words(dataset, final_doc, different_words, common_words):\n    \"\"\" This function takes a specific dataset (dataset), its lemmatized text (final_doc), and two lists of words (different_words, common_words). For different words I'll just look for the presence of the word in a specific text and, for different words I'll look for the number of times that the words appear in the text. I'll also normalizate the common_words variables \"\"\"\n \n    for word in different_words:\n        dataset[word] = 0\n        for i in range(len(dataset)):\n            if word in dataset.normalized_text[i]:\n                dataset[word][i] = 1\n\n    for word in common_words:\n        dataset[word] = 0\n        for i in range(len(dataset)):\n            for word_1 in final_doc[i]:\n                if word == word_1:\n                    dataset[word][i] += 1\n    MinMaxScaler(dataset, common_words)\n\ndef find_words(dataset, dataset_1, final_doc, final_doc_validation, ham_data_index, spam_data_index, ham_words_number, spam_words_number, limit, frequency_restriction):\n    \"\"\" This function takes two datasets (dataset, dataset_1), its lemmatized text (final_doc, final_doc_validation), the emails in which the algorithm has to look for the words (ham_data_index, spam_data_index), the number of words to look for (ham_words_number, spam_words_number), a limit (limit, I'll explain that in the following cell), and a frequency restriction for different words (frequency_restriction)\"\"\"\n\n    # The following loop looks for common words in ham emails\n    list_ham_words_repeated = []\n    list_ham_words = []\n    for i in ham_data_index:\n        repeated_words = []\n        for item in final_doc[i]: \n            if item not in repeated_words:\n                list_ham_words.append(item)\n                list_ham_words_repeated.append(item)\n                repeated_words.append(item)\n            else:\n                list_ham_words_repeated.append(item)\n\n    # The following loop looks for common words in spam emails\n    list_spam_words_repeated = []\n    list_spam_words = []\n    for j in spam_data_index:\n        repited_words = []\n        for item in final_doc[j]: \n            if item not in repeated_words:\n                list_spam_words.append(item)\n                list_spam_words_repeated.append(item)\n                repited_words.append(item)\n            else:\n                list_spam_words_repeated.append(item)\n\n    # Now I want to storage the words in dataframes to easily manipulate them         \n    c_ham_repeated  = Counter(list_ham_words_repeated)\n    c_spam_repeated = Counter(list_spam_words_repeated)\n    c_ham = Counter(list_ham_words)\n    c_spam = Counter(list_spam_words)\n    df_hamwords  = pd.DataFrame(c_ham.most_common(ham_words_number),  columns=['word', 'count'])\n    df_spamwords = pd.DataFrame(c_spam.most_common(spam_words_number), columns=['word', 'count'])\n    df_hamwords_repeated  = pd.DataFrame(c_ham_repeated.most_common(ham_words_number),  columns=['word', 'count'])\n    df_spamwords_repeated = pd.DataFrame(c_spam_repeated.most_common(spam_words_number), columns=['word', 'count'])\n\n    # Now I have common words for spam and ham emails. The following peace of code will look for which common words for spam emails are also common for ham emails and which are different.\n\n    common_words = []\n    different_words = []\n\n    for i in range(len(df_hamwords)):\n        find_word = False\n        for j in range(len(df_spamwords)):\n            if df_hamwords.loc[i][0] == df_spamwords.loc[j][0]:\n                common_words.append(df_hamwords.loc[i][0])\n                find_word = True\n        if find_word == False:\n            different_words.append(df_hamwords.loc[i][0])\n\n    for i in range(len(df_spamwords)):\n        find_word = False\n        for j in range(len(df_hamwords)):\n            if df_spamwords.loc[i][0] == df_hamwords.loc[j][0]:\n                find_word = True\n        if find_word == False:\n            different_words.append(df_spamwords.loc[i][0])\n\n    # For the words which are common in both types of emails, we'll keep the words with a significant frequency difference\n\n    common_words_frequency = []\n\n    for i,word in enumerate(common_words):\n        common_words_frequency.append([word])\n        for j,word_1 in enumerate(df_hamwords_repeated[\"word\"]):\n            if word_1 == word:\n                common_words_frequency[i].append(float(df_hamwords_repeated[\"count\"][j]\/len(ham_data_index)))\n        for k,word_2 in enumerate(df_spamwords_repeated[\"word\"]):\n            if word_2 == word:\n                common_words_frequency[i].append(float(df_spamwords_repeated[\"count\"][k]\/len(spam_data_index)))\n\n    sum_1 = 0\n    sum_2 = 0\n\n    for i in range(len(common_words_frequency)):\n        if len(common_words_frequency[i]) == 3:\n            sum_1 += abs(float(common_words_frequency[i][1])-float(common_words_frequency[i][2]))\n        else:\n            sum_2 += 1\n\n    final_common_words = []\n\n    for i in range(len(common_words_frequency)):\n        if len(common_words_frequency[i]) == 3:\n            if abs(float(common_words_frequency[i][1])-float(common_words_frequency[i][2])) >= frequency_restriction:\n                final_common_words.append(common_words_frequency[i][0])\n                \n    # Once I have the two lists, common_words and different_words, I'll add this features to the different datasets\n\n    add_words(dataset, final_doc, different_words[0:limit], final_common_words[0:limit])\n    add_words(dataset_1, final_doc_validation, different_words[0:limit], final_common_words[0:limit])","d27f96e6":"find_words(data_copy, test_copy, final_doc, final_doc_validation, data_copy[data_copy.label == 0].index, data_copy[data_copy.label == 1].index, 500, 500, 350, 0.8)\n\nindexes = MultinomialModel(data_copy, [\"text\", \"preprocessed_text\",\"normalized_text\"], [\"len_substring\"])","579d4ea2":"data_copy.loc[indexes]","fb0c86fa":"model = MultinomialNB()\nX = data_copy.drop([\"text\", \"preprocessed_text\",\"normalized_text\", \"len_substring\", \"label\"], axis=1)\ny = data_copy[\"label\"]\nmodel.fit(X,y)\nX_val = test_copy.drop([\"text\", \"preprocessed_text\",\"normalized_text\", \"len_substring\"], axis=1)\ny_pred_validation = model.predict(X_val)\n\ny_pred_validation","1c2472b5":"# my_submission = pd.DataFrame({'Id': test_copy.index, 'Category': y_pred_validation})\n# # #  you could use any filename. We choose submission here\n# my_submission.to_csv('final_submission_1.csv', index=False)","a5b8e697":"Before starting with the cleaning task, I will keep the original length of the emails. I have decided to store the length of the \"raw\" text because, as I will analyze later, the length of the emails is significantly different from the ham and spam emails. Spam emails tend to be larger than ham emails. If I just keep the length of the cleaned text I will have some issues with a specific kind of spam email, the ones that are only a large substring. I will print an example in the following cell: ","e7bde816":"Much better, let's create binnary variables to store the following relations:\n\n- HTML(1)-EMAIL(0) and HTML(0)-EMAIL(1)\n\n- HTML(1)-EMAIL(1)","0c7ca578":"This type of emails are problematic because I won't have features to identify them due to the lack of words in them. Large substrings are a distinctive element for spam emails but are also unable to normalize, so I'll clean them. This means that some spam emails will be reduced to a text length of zero, and this could result in wrong predictions.\n\nIn this notebook I'll frequently work with functions, this allows me to not repeat the code for the *test dataset*.","cf288001":"## 4. Featuring\n\nIn the previous section, I've focused on making the email's text more generic and easy to use. In this section I'll transform the data from unstructured to structured. \n\nTo do this I'll look for common words in both, *spam* and *ham* emails. Once I get this information, I'll look for common words in spam emails which are also common in ham emails and for words which are different. For the words which are different, I'll create a binnary variable to store which texts contain this words and which doesn't. Finally, for common words in both type of emails, I'll look for the frequency of this words in the emails and, for those words with a high difference in frequency between spam and ham emails, I'll create a variable to count the number of times this words appear in the emails.\n\n### 4.1. Model\n\nFirst of all, I'll define the model I'll be using to classify the text (MultinomialNB). In the following cell I've created a function to get the accuracy for a specific model and, another function to normalize numerical data.","390bafe9":"In the cell below I have printed the elements that will be cleaned in this subsection: HTML element (<...>), CSS elements (P{...}body), Error emails (Err:...) and emails. All of these elements do not fit a normalization task.","586e897f":"## 3. Data Cleaning\n\nThe main focus for this section is to clean the text from the emails to apply some kind of normalization to it (using a Stemmer\/Lemmatizer). Once the text is normalized, I'll look for common\/different words in spam and ham emails. I'll use this information to build features to predict whether an email is ham or spam.\n\nClean text means to remove elements. Punctuation, large substrings, HTML\/CSS elements as many others. It's important to clean the text from the emails to get a better performance in the normalization task but, it's also important to take care when removing elements because some of them could be important to detect the typology of an email. For example, one of the elements that will be removed from the text is punctuation (!?,.:;), as we will see later, there is a strong relationship between the number of punctuation elements and the email typology. **What I mean by this is that the text has to be cleaned without losing information**. It's extremely important to save this information in variables.\n\nThe first thing I'll do is to create a copy of the dataset to avoid making changes to the original. This allows me to apply changes to the copy without worrying about making mistakes because I can always go back to the original dataset and make another copy.","7659663c":"One thing that it's important to notice is the relation between the number of punctuation elements and the typology of the email, *spam emails* tend to have more puctuation elements than *ham emails* (68 elements of difference).","8d37750f":"### 3.1. Clean HTML\/CSS documentation","a8cfc406":"Now that I have cleaned the text from HTML\/CSS elements as well as emails and errors, It's time to see if there is a relation between these elements and the typology of the email.","0a176064":"We can look to the observation we have been unable to identify by using the *indexes* returned by the function **find_words**:","71fc7b21":"Well, the first thing we may notice here is that ERROR elements and CSS elements are only present in *spam emails*. Due to that reason, variables *CSS_True* and *ERROR_True* should be enough to detect this kind of spam emails. Apart from this, the relation is not that clear between EMAIL and HTML elements. Emails with this kind of element are indeed more likely to be *spam emails*, but the difference is slight. Let's see if there is a more clear relation between these variables and the typology of the emails.","6988de06":"### 3.3.2. Stemmer\n\nWe can now apply the stemmer to normalize linguistics.","049ad519":"### 3.3. Stemming (a way of normalization for liguistics)\n\nStemming and Lematizing are linguistic techinques that allows us to normalize the language. It'll help us to make the emails look more generic. How it works? Well, it takes us to the basic term meaning of the word (playing\/plays\/played --> play).\n\nIf we want to apply one of these techinques, we have to split out text emails into words. To do this we'll use the word_tokenize function from the *nltk.tokenize* library.","3bc7f9af":"### 3.2. Clean single elements, long substrings, punctuation, doble spaces and convert to lowercase\n\nThe next group of elements that will be removed from the text are punctuation, long substrings, capital letters and doble spaces. For humans it's easy to identify that \"ok\", \"Ok\" and \"ok!\" is the same word, but machines are not as intuitive as we are, so we'll need to build some rules to avoid this mistakes.","39e800a1":"## 1. Libraries","6faeee66":"## 2. Read the database\n\nOnce the files are downloaded from the Kaggle website (https:\/\/www.kaggle.com\/c\/fraudulent-e-mails-spam-or-ham\/overview\/evaluation), the first step is to read the dataset and analyze it, this is going to be helpful to build a correct data cleaning process.","941b640f":"Well, the function below is large an tough to understand. At least, I would like to think that the idea of what these function does its clear. Here I'll explain the arguments that this function takes an how to use them. Let's start by classifing the arguments:\n\n- 1. datasets\n- 2. stemmer\n- 3. ranges\n- 4. word numeber\n- 5. limit\n- 6. frequency restriction\n\n### 1.datasets (dataset, dataset_1)\n\nI'm passing two datasets to the fuction because I want to look for common and different words in the training dataset and look for these words in both datasets, train and test. If you only want to test with different types of combinations, I recomend you to make two copies of the train dataseta dn passing these copies to the function.\n\ndata_copy_1 = data_copy.copy()\n\ndata_copy_2 = data_copy.copy()\n\nfind_words(data_copy_1, data_copy_2, ...)\n\n### 2.stemmer (final_doc, final_doc_validation)\n\nThis second argument is the stemmed text of the emails. This is going to be used in the *add_words* function to look for specific words. Two arguments are needed here, the stemmed vector for the test dataset and the stemmed vector for the test dataset.\n\n### 3.ranges (ham_data_index, spam_data_index)\n\nWhen I was doing the firsts steps in this dataset, I came up with the idea of looking for words (common and different) for different ranges of emails, not only for *ham* and *spam* emails. I explain myself, I noticed that by just using variables related to the length of the text and the punctuation I was getting scores from about 90% accuracy and, wrong predictions were related to long ham emails with a huge amount of punctuation elements and short spam emails with few punctuation elements. So, I tried to look for words in short and large emails. Unfortunately, I didn't figure out the way to do it and gain accuracy.\n\n### 4.Word number (ham_words_number, spam_words_number)\n\nThe number of words to look for.\n\n### 5.Limit (limit)\n\nThis variable is closely related to the previous one. I could be the situation in which I want a huge list of words (Word number) because I want to make sure that different words are truly different (that's why I specify a limit). Let's imagine that I tell the algorithm to pick 100 words on each list (common and different), what could happen is that some words are classified as different but they are not. It could be the case in which we have the word *travel* in position 90 of the ham most common words, but this word is also in position 101 of the spam most common words, this word will be classified as different when it's common.\n\n### 6.Frequency restriction (frequency_restriction)\n\nThis variable words as a restriction for common words, we've to tell the algorithm which common words to pick and which don't.","28c41d64":"If we take a look at the first ten rows of the dataset (stored in the variable **data**), we notice that we only have two variables: \"text\" and \"label\". The variable *text* store a specific email while the variable *label* shows us if the email is listed as a *ham* (0) or *spam* (1) email. If we focus on the variable *text*, it's easy to see that this is full of HTML tags, emails, punctuation, and other problems related to unstructured data.","b5e6535f":"# Submission","89b66d8f":"# Fraudulent E-mails: Spam or Ham?\n\nIn this notebook, I'll cover the *Fraudulent E-mails* competition on Kaggle as a part of the text analysis theory at the postgraduate course on Data Science by the University of Barcelona. The main focus of this exercise is to have a better understood of the data cleaning techniques for unstructured data (usually text data). Due to that reason, I won't get deep into the modeling part of the project (it's compulsory to use the MultinomialNB model).\n\n## Index\n\n1. **Libraries**\n\n2. **Read the database**\n\n3. **Data Cleaning**\n\n    3.1. Clean HTML documentation\n    \n    3.2. Clean single elements, doble spaces and convert to lowercase\n\n    3.3. Stemming (a way of normalization for liguistics)\n    \n    \u00b7 3.3.1. Count and Remove punctuation\n    \n    \u00b7 3.3.2. Stemmer\n\n4. **Featuring**\n\n    4.1. Model\n\n    4.2. Word Research\n\n5. **Conclusions** (not wrote yet)","e4a82e7f":"### 4.2. Word Research\n\nOnce I have the function to evaluate the accuracy of the different models I'll be testing, it's time to search for common and different words in emails."}}