{"cell_type":{"9b5894df":"code","0cde4e65":"code","745eeb98":"code","eab1e438":"code","a61146da":"code","ad687481":"code","f1d1424a":"code","e0f94901":"code","326bd375":"code","be48fa31":"code","e30cc2ba":"code","8b00b3a9":"code","87c4e260":"markdown","78c938e1":"markdown","cad31c09":"markdown","63dbf40f":"markdown","c2793a62":"markdown","eb7951b2":"markdown","fb6f3397":"markdown","ff21c338":"markdown","70cad1d5":"markdown"},"source":{"9b5894df":"import pandas as pd\n\nreviews = pd.read_csv(\"..\/input\/wine-reviews\/winemag-data-130k-v2.csv\", index_col=0)\n\nfrom learntools.core import binder; binder.bind(globals())\nfrom learntools.pandas.renaming_and_combining import *\nprint(\"Setup complete.\")","0cde4e65":"reviews.head()","745eeb98":"# Your code here\nrenamed = ____\n\nq1.check()","eab1e438":"#q1.hint()\n#q1.solution()","a61146da":"reindexed = ____\n\nq2.check()","ad687481":"#q2.hint()\n#q2.solution()","f1d1424a":"gaming_products = pd.read_csv(\"..\/input\/things-on-reddit\/top-things\/top-things\/reddits\/g\/gaming.csv\")\ngaming_products['subreddit'] = \"r\/gaming\"\nmovie_products = pd.read_csv(\"..\/input\/things-on-reddit\/top-things\/top-things\/reddits\/m\/movies.csv\")\nmovie_products['subreddit'] = \"r\/movies\"","e0f94901":"combined_products = ____\n\nq3.check()","326bd375":"#q3.hint()\n#q3.solution()","be48fa31":"powerlifting_meets = pd.read_csv(\"..\/input\/powerlifting-database\/meets.csv\")\npowerlifting_competitors = pd.read_csv(\"..\/input\/powerlifting-database\/openpowerlifting.csv\")","e30cc2ba":"powerlifting_combined = ____\n\nq4.check()","8b00b3a9":"#q4.hint()\n#q4.solution()","87c4e260":"Create a `DataFrame` of products mentioned on *either* subreddit.","78c938e1":"Both tables include references to a `MeetID`, a unique key for each meet (competition) included in the database. Using this, generate a dataset combining the two tables into one.","cad31c09":"## 3.\nThe [Things on Reddit](https:\/\/www.kaggle.com\/residentmario\/things-on-reddit\/data) dataset includes product links from a selection of top-ranked forums (\"subreddits\") on reddit.com. Run the cell below to load a dataframe of products mentioned on the *\/r\/gaming* subreddit and another dataframe for products mentioned on the *r\/\/movies* subreddit.","63dbf40f":"# Congratulations\n\nYou've finished the Pandas track.  Many data scientist feel efficiency with Pandas is the most useful and practical skill they have, because it allows you to progress quickly in any project you have.\n\nYou can take advantage of your Pandas skills by entering a [Kaggle Competition](https:\/\/www.kaggle.com\/competitions) or answering a question you find interesting using [Kaggle Datasets](https:\/\/www.kaggle.com\/datasets).","c2793a62":"## 4.\nThe [Powerlifting Database](https:\/\/www.kaggle.com\/open-powerlifting\/powerlifting-database) dataset on Kaggle includes one CSV table for powerlifting meets and a separate one for powerlifting competitors. Run the cell below to load these datasets into dataframes:","eb7951b2":"## 1.\n`region_1` and `region_2` are pretty uninformative names for locale columns in the dataset. Create a copy of `reviews` with these columns renamed to `region` and `locale`, respectively.","fb6f3397":"## 2.\nSet the index name in the dataset to `wines`.","ff21c338":"# Exercises\n\nView the first several lines of your data by running the cell below:","70cad1d5":"# Renaming and combining workbook\n\n## Introduction\n\nThis is the workbook part of the \"Renaming and combining\" section of the Advanced Pandas tutorial. For the reference section, click [here](https:\/\/www.kaggle.com\/residentmario\/renaming-and-combining-reference).\n\nRenaming is covered in its own section in the [\"Essential Basic Functionality\"](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/basics.html#renaming-mapping-labels) section of the extensive official documentation. Combining is covered by the [\"Merge, join, concatenate\"](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/merging.html) section there."}}