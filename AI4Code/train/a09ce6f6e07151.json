{"cell_type":{"37eaacb1":"code","0ab66da5":"code","b66fae17":"code","f4ecd0d5":"code","bd15f091":"code","a3aa0504":"code","7c71e464":"code","2f2f5670":"code","494acf87":"code","47d0786d":"code","50809560":"code","d0a1e366":"code","23f19f81":"code","377291f3":"code","2a74d5c9":"code","8a02b5ee":"code","05adfa5d":"code","9b12c4f1":"code","eb25973f":"code","eb020af4":"code","7442fb6a":"code","464dcc45":"code","793ac79d":"code","e7e2c641":"markdown","62f2ed41":"markdown","3e26422f":"markdown","ac625c21":"markdown","676a7578":"markdown","c19eef9c":"markdown","41efb0e3":"markdown","0683446e":"markdown","77a7f6e7":"markdown","8b5bf070":"markdown","0c442c27":"markdown","2b84ca1e":"markdown","dda22003":"markdown","ae456066":"markdown","a1d84029":"markdown","73c20891":"markdown","38f75d69":"markdown","cbb846e3":"markdown","fa261311":"markdown","19d71e2a":"markdown","2dd6c64c":"markdown"},"source":{"37eaacb1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2 as cv\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0ab66da5":"right = cv2.imread('..\/input\/directions\/Direction\/Right\/764.jpg', cv2.IMREAD_COLOR)\nleft = cv2.imread('..\/input\/directions\/Direction\/Left\/105.jpg', cv2.IMREAD_COLOR)\nup = cv2.imread('..\/input\/directions\/Direction\/Up\/102.jpg', cv2.IMREAD_COLOR)\ndown = cv2.imread('..\/input\/directions\/Direction\/Down\/104.jpg', cv2.IMREAD_COLOR)\n#industry = cv2.imread('..\/input\/cv-images\/industry-min.png', cv2.IMREAD_COLOR)\n#finance = cv2.imread('..\/input\/cv-images\/finance-min.jpg', cv2.IMREAD_COLOR)\n\nplt.figure(figsize=(40, 30))\nplt.subplot(2, 2, 1).set_title('Right', fontsize = 65); plt.axis('off')   \nplt.imshow(cv2.cvtColor(right, cv2.COLOR_BGR2RGB))\nplt.subplot(2, 2, 2).set_title('Left', fontsize = 65); plt.axis('off')   \nplt.imshow(cv2.cvtColor(left, cv2.COLOR_BGR2RGB))\nplt.subplot(2, 2, 3).set_title('Up', fontsize = 65); plt.axis('off')   \nplt.imshow(cv2.cvtColor(up, cv2.COLOR_BGR2RGB))\nplt.subplot(2, 2, 4).set_title('Down', fontsize = 65); plt.axis('off')   \nplt.imshow(cv2.cvtColor(down, cv2.COLOR_BGR2RGB))\n#plt.subplot(3, 2, 5).set_title('Industry', fontsize = 65); plt.axis('off')   \n#plt.imshow(cv2.cvtColor(industry, cv2.COLOR_BGR2RGB))\n#plt.subplot(3, 2, 6).set_title('Finance', fontsize = 65); plt.axis('off')   \n#plt.imshow(cv2.cvtColor(finance, cv2.COLOR_BGR2RGB))\nplt.suptitle('Applications of Computer Vision', fontsize = 60)\nplt.show()","b66fae17":"height = 224\nwidth = 224\nfont_size = 20\npaths = ['..\/input\/directions\/Direction\/Down\/104.jpg', '..\/input\/directions\/Direction\/Left\/105.jpg']","f4ecd0d5":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook \nplt.figure(figsize=(15, 8))\nfor i, path in enumerate(paths):\n    \n    name = os.path.split(path)[-1]\n    img = cv2.imread(path, cv2.IMREAD_COLOR)\n    resized_img = cv2.resize(img, (height, width))\n    \n    plt.subplot(1, 2, i+1).set_title(name[ : -4], fontsize = font_size); plt.axis('off')\n    plt.imshow(cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB))\nplt.show()","bd15f091":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook \nplt.figure(figsize=(15, 8))\nfor i, path in enumerate(paths):\n    \n    name = os.path.split(path)[-1]\n    img = cv2.imread(path, 0)\n    resized_img = cv2.resize(img, (height, width))\n    \n    plt.subplot(1, 2, i + 1).set_title(f'Grayscale {name[ : -4]} Image', fontsize = font_size); plt.axis('off')\n    plt.imshow(resized_img, cmap='gray')\nplt.show()","a3aa0504":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook \nfor i, path in enumerate(paths):\n    \n    name = os.path.split(path)[-1]\n    img = cv2.imread(path, cv2.IMREAD_COLOR)\n    resized_img = cv2.resize(img, (height, width))\n    \n    denoised_img = cv2.medianBlur(resized_img, 5)\n    \n    plt.figure(figsize=(15, 8))\n    plt.subplot(1, 2, 1).set_title(f'Original {name[ : -4]} Image', fontsize = font_size); plt.axis('off')\n    plt.imshow(cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB))\n    plt.subplot(1, 2, 2).set_title(f'After Median Filtering of {name[ : -4]} Image', fontsize = font_size); plt.axis('off')\n    plt.imshow(cv2.cvtColor(denoised_img, cv2.COLOR_BGR2RGB))\n    plt.show()","7c71e464":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook \nfor i, path in enumerate(paths):\n    \n    name = os.path.split(path)[-1]\n    img = cv2.imread(path, 0)\n    resized_img = cv2.resize(img, (height, width))\n    denoised_img = cv2.medianBlur(resized_img, 5)\n    \n    th = cv2.adaptiveThreshold(denoised_img, maxValue = 255, adaptiveMethod = cv2.ADAPTIVE_THRESH_GAUSSIAN_C, thresholdType = cv2.THRESH_BINARY, blockSize = 11, C = 2)\n    \n    plt.figure(figsize=(15, 8))\n    plt.subplot(1, 2, 1).set_title(f'Grayscale {name[ : -4]} Image', fontsize = font_size); plt.axis('off')\n    plt.imshow(resized_img, cmap = 'gray')\n    plt.subplot(1, 2, 2).set_title(f'After Adaptative Thresholding of {name[ : -4]} Image', fontsize = font_size); plt.axis('off')\n    plt.imshow(cv2.cvtColor(th, cv2.COLOR_BGR2RGB))\n    plt.show()","2f2f5670":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook \nfor i, path in enumerate(paths):\n    \n    name = os.path.split(path)[-1]\n    img = cv2.imread(path, 0)\n    resized_img = cv2.resize(img, (height, width))\n    laplacian = cv2.Laplacian(resized_img, cv2.CV_64F)\n    \n    plt.figure(figsize=(15, 8))\n    plt.subplot(1, 2, 1).set_title(f'Grayscale {name[ : -4]} Image', fontsize = font_size); plt.axis('off')\n    plt.imshow(resized_img, cmap = 'gray')\n    plt.subplot(1, 2, 2).set_title(f'After finding Laplacian Derivatives of {name[ : -4]} Image', fontsize = font_size); plt.axis('off')\n    plt.imshow(cv2.cvtColor(laplacian.astype('float32'), cv2.COLOR_BGR2RGB))\n    plt.show()","494acf87":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook \n\nfor i, path in enumerate(paths):\n    \n    name = os.path.split(path)[-1]\n    img = cv2.imread(path, 0)\n    resized_img = cv2.resize(img, (height, width))\n    edges = cv2.Canny(resized_img, threshold1 = 100, threshold2 = 200)\n    \n    plt.figure(figsize=(15, 8))\n    plt.subplot(1, 2, 1).set_title(f'Grayscale {name[ : -4]} Image', fontsize = font_size); plt.axis('off')\n    plt.imshow(resized_img, cmap = 'gray')\n    plt.subplot(1, 2, 2).set_title(f'After Canny Edge Detection of {name[ : -4]} Image', fontsize = font_size); plt.axis('off')\n    plt.imshow(cv2.cvtColor(edges, cv2.COLOR_BGR2RGB))\n    plt.show()","47d0786d":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook \n\nfor i, path in enumerate(paths):\n    \n    name = os.path.split(path)[-1]\n    img = cv2.imread(path, 0)\n    resized_img = cv2.resize(img, (height, width))\n    \n    freq = np.fft.fft2(resized_img)\n    \n    freq_shift = np.fft.fftshift(freq)\n    \n    magnitude_spectrum = 20 * np.log(np.abs(freq_shift))\n\n    plt.figure(figsize=(15, 8))\n    plt.subplot(1, 2, 1).set_title(f'Grayscale {name[ : -4]} Image', fontsize = font_size); plt.axis('off')   \n    plt.imshow(cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB))\n    plt.subplot(1, 2, 2).set_title(f'Magnitude Spectrum of {name[ : -4]} Image', fontsize = font_size); plt.axis('off')   \n    plt.imshow(magnitude_spectrum, cmap = 'gray')\n    plt.show()","50809560":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook\n\nmin_line_length = 100\nmax_line_gap = 10\n\nimg = cv2.imread('..\/input\/directions\/Direction\/Up\/102.jpg')\nresized_img = cv2.resize(img, (height, width))\nimg_copy = resized_img.copy()\n\nedges = cv2.Canny(resized_img, threshold1 = 50, threshold2 = 150)\n\nlines = cv2.HoughLinesP(edges, rho = 1, theta = np.pi \/ 180, threshold = 100, minLineLength = min_line_length, maxLineGap = max_line_gap)\n\nfor line in lines:\n    for x1, y1, x2, y2 in line:\n        hough_lines_img = cv2.line(resized_img ,(x1,y1),(x2,y2),color = (0,255,0), thickness = 2)\n\nplt.figure(figsize=(15, 8))\nplt.subplot(1, 2, 1).set_title('Original Image', fontsize = font_size); plt.axis('off')   \nplt.imshow(cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB))\nplt.subplot(1, 2, 2).set_title('After Hough Line Transformation', fontsize = font_size); plt.axis('off')   \nplt.imshow(cv2.cvtColor(hough_lines_img, cv2.COLOR_BGR2RGB))\nplt.show()","d0a1e366":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook\n\nimg = cv2.imread('..\/input\/directions\/Direction\/Up\/102.jpg')\nresized_img = cv2.resize(img, (height, width))\nimg_copy = resized_img.copy()\ngray = cv2.cvtColor(resized_img,cv2.COLOR_BGR2GRAY)\n\ngray = np.float32(gray)\ncorners = cv2.cornerHarris(gray, blockSize = 2, ksize = 3, k = 0.04)\n\ncorners = cv2.dilate(corners, None)\nresized_img[corners > 0.0001 * corners.max()] = [0, 0, 255]\n\nplt.figure(figsize=(15, 8))\nplt.subplot(1, 2, 1).set_title('Original Image', fontsize = font_size); plt.axis('off')   \nplt.imshow(cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB))\nplt.subplot(1, 2, 2).set_title('After Harris Corner Detection', fontsize = font_size); plt.axis('off')   \nplt.imshow(cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB))\nplt.show()","23f19f81":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook\n\nkernel = np.ones((5,5), np.uint8)\n\nplt.figure(figsize=(15, 8))\n\nimg = cv2.imread('..\/input\/directions\/Direction\/Left\/105.jpg', cv2.IMREAD_COLOR)\nresized_img = cv2.resize(img, (height, width))\n\nmorph_open = cv2.morphologyEx(resized_img, cv2.MORPH_OPEN, kernel)\nmorph_close = cv2.morphologyEx(morph_open, cv2.MORPH_CLOSE, kernel)\n    \nplt.subplot(1,2,1).set_title('Original Digit - 7 Image', fontsize = font_size); plt.axis('off')   \nplt.imshow(cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB))\nplt.subplot(1,2,2).set_title('After Morphological Opening and Closing of Digit - 7 Image', fontsize = font_size); plt.axis('off')   \nplt.imshow(cv2.cvtColor(morph_close, cv2.COLOR_BGR2RGB))\nplt.show()","377291f3":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook\n\npts1 = np.float32([[1550, 1170],[2850, 1370],[50, 2600],[1850, 3450]])\npts2 = np.float32([[0,0],[4160,0],[0,3120],[4160,3120]])\n\nimg = cv2.imread('..\/input\/directions\/Direction\/Up\/102.jpg', cv2.IMREAD_COLOR)\n\ntransformation_matrix = cv2.getPerspectiveTransform(pts1, pts2)\n\nfinal_img = cv2.warpPerspective(img, M = transformation_matrix, dsize = (4160, 3120))\n\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg = cv2.resize(img, (256, 256))\nfinal_img = cv2.cvtColor(final_img, cv2.COLOR_BGR2RGB)\nfinal_img = cv2.resize(final_img, (256, 256))\n \nplt.figure(figsize=(15, 8))    \nplt.subplot(1,2,1).set_title('Original Book Image', fontsize = font_size); plt.axis('off')   \nplt.imshow(img)\nplt.subplot(1,2,2).set_title('After Perspective Transformation of Book Image', fontsize = font_size); plt.axis('off')   \nplt.imshow(final_img)\nplt.show()","2a74d5c9":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook\n\nplt.figure(figsize=(15, 8))\n\nimg = cv2.imread('..\/input\/directions\/Direction\/Up\/102.jpg', cv2.IMREAD_COLOR)\nresized_img = cv2.resize(img, (height, width))\ncontours_img = resized_img.copy()\nimg_gray = cv2.cvtColor(resized_img,cv2.COLOR_BGR2GRAY)\n\nret,thresh = cv2.threshold(img_gray, thresh = 127, maxval = 255, type = cv2.THRESH_BINARY)\n\ncontours, hierarchy = cv2.findContours(thresh, mode = cv2.RETR_TREE, method = cv2.CHAIN_APPROX_NONE)\n\ncv2.drawContours(contours_img, contours, contourIdx = -1, color = (0, 255, 0), thickness = 2)\n\nplt.subplot(1,2,1).set_title('Original Image', fontsize = font_size); plt.axis('off')   \nplt.imshow(resized_img)\nplt.subplot(1,2,2).set_title('After Finding Contours', fontsize = font_size); plt.axis('off')   \nplt.imshow(contours_img)\nplt.show()","8a02b5ee":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook\n\nR = cv2.imread('..\/input\/directions\/Direction\/Up\/102.jpg', cv2.IMREAD_COLOR)\nR = cv2.resize(R, (224, 224))\nH = cv2.imread('..\/input\/directions\/Direction\/Left\/105.jpg', cv2.IMREAD_COLOR)\nH = cv2.resize(H, (224, 224))\n\nG = R.copy()\nguassian_pyramid_c = [G]\nfor i in range(6):\n    G = cv2.pyrDown(G)\n    guassian_pyramid_c.append(G)\n \n     \nG = H.copy()\nguassian_pyramid_d = [G]\nfor i in range(6):\n    G = cv2.pyrDown(G)\n    guassian_pyramid_d.append(G)\n\nlaplacian_pyramid_c = [guassian_pyramid_c[5]]\nfor i in range(5, 0, -1):\n    GE = cv2.pyrUp(guassian_pyramid_c[i])\n    L = cv2.subtract(guassian_pyramid_c[i-1], GE)\n    laplacian_pyramid_c.append(L)\n\nlaplacian_pyramid_d = [guassian_pyramid_d[5]]\nfor i in range(5,0,-1):\n    guassian_expanded = cv2.pyrUp(guassian_pyramid_d[i])\n    L = cv2.subtract(guassian_pyramid_d[i-1], guassian_expanded)\n    laplacian_pyramid_d.append(L)\n\nlaplacian_joined = []\nfor lc,ld in zip(laplacian_pyramid_c, laplacian_pyramid_d):\n    r, c, d = lc.shape\n    lj = np.hstack((lc[:, 0 : int(c \/ 2)], ld[:, int(c \/ 2) :]))\n    laplacian_joined.append(lj)\n\nlaplacian_reconstructed = laplacian_joined[0]\nfor i in range(1,6):\n    laplacian_reconstructed = cv2.pyrUp(laplacian_reconstructed)\n    laplacian_reconstructed = cv2.add(laplacian_reconstructed, laplacian_joined[i])\n\ndirect = np.hstack((R[ : , : int(c \/ 2)], H[ : , int(c \/ 2) : ]))\n\nplt.figure(figsize=(30, 20))\nplt.subplot(2,2,1).set_title('Up Direction', fontsize = 35); plt.axis('off')   \nplt.imshow(cv2.cvtColor(R, cv2.COLOR_BGR2RGB))\nplt.subplot(2,2,2).set_title('Left Direction', fontsize = 35); plt.axis('off')   \nplt.imshow(cv2.cvtColor(H, cv2.COLOR_BGR2RGB))\nplt.subplot(2,2,3).set_title('Direct Joining', fontsize = 35); plt.axis('off')   \nplt.imshow(cv2.cvtColor(direct, cv2.COLOR_BGR2RGB))\nplt.subplot(2,2,4).set_title('Pyramid Blending', fontsize = 35); plt.axis('off')   \nplt.imshow(cv2.cvtColor(laplacian_reconstructed, cv2.COLOR_BGR2RGB))\nplt.show()","05adfa5d":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook\n\nlower_white = np.array([0, 0, 150])\nupper_white = np.array([255, 255, 255])\n\nimg = cv2.imread('..\/input\/directions\/Direction\/Left\/105.jpg', cv2.IMREAD_COLOR)\nimg = cv2.resize(img, (height, width))\n\nbackground = cv2.imread(\"..\/input\/directions\/Direction\/Up\/102.jpg\", cv2.IMREAD_COLOR)\nbackground = cv2.resize(background, (height, width))\n\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nhsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\nmask = cv2.inRange(hsv_img, lowerb = lower_white, upperb = upper_white)\n\nfinal_img = cv2.bitwise_and(img, img, mask = mask)\nfinal_img = np.where(final_img == 0, background, final_img)\n\nplt.figure(figsize=(15, 8))\nplt.subplot(1,2,1).set_title('Original Left Direction', fontsize = font_size); plt.axis('off')   \nplt.imshow(img)\nplt.subplot(1,2,2).set_title('After Object Tracking using Color-space Conversion of Left Direction', fontsize = font_size); plt.axis('off')   \nplt.imshow(final_img)\nplt.show()","9b12c4f1":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook\n\nimg = cv2.imread('..\/input\/directions\/Direction\/Up\/102.jpg', cv2.IMREAD_COLOR)\nimg = cv2.resize(img, (height, width))\nimg_copy = img.copy()\nmask = np.zeros(img.shape[ : 2], np.uint8)\n\nbackground_model = np.zeros((1,65),np.float64)\nforeground_model = np.zeros((1,65),np.float64)\n\nrect = (10, 10, 224, 224)\n\ncv2.grabCut(img, mask = mask, rect = rect, bgdModel = background_model, fgdModel = foreground_model, iterCount = 5, mode = cv2.GC_INIT_WITH_RECT)\n\nnew_mask = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\nimg = img * new_mask[:, :, np.newaxis]\n\nplt.figure(figsize=(15, 8))\nplt.subplot(1,2,1).set_title('Original Up Direction Image', fontsize = font_size); plt.axis('off')   \nplt.imshow(cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB))\nplt.subplot(1,2,2).set_title('After Interactive Foreground Extraction of Up Direction Image', fontsize = font_size); plt.axis('off')   \nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nplt.show()","eb25973f":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook\n\nkernel = np.ones((3 , 3), np.uint8)\n\nimg = cv2.imread('..\/input\/directions\/Direction\/Up\/102.jpg', cv2.IMREAD_COLOR)\nresized_img = cv2.resize(img, (height, width))\nimg_copy = resized_img.copy()\n\ngray = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)\nret, thresh = cv2.threshold(gray, thresh = 0, maxval = 255, type = cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n\nopening = cv2.morphologyEx(thresh, op = cv2.MORPH_OPEN, kernel = kernel, iterations = 2)\nbackground = cv2.dilate(opening, kernel = kernel, iterations = 5)\n\ndist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\nret, foreground = cv2.threshold(dist_transform, thresh = 0.2  * dist_transform.max(), maxval = 255, type = cv2.THRESH_BINARY)\n\nforeground = np.uint8(foreground)\nunknown = cv2.subtract(background, foreground)\n\nret, markers = cv2.connectedComponents(foreground)\n\nmarkers = markers + 1\nmarkers[unknown == 255] = 0\n\nmarkers = cv2.watershed(resized_img, markers)\nresized_img[markers == -1] = [0, 0, 255]\n\nplt.figure(figsize=(15, 8))\nplt.subplot(1, 2, 1).set_title('Up Direction Image', fontsize = font_size); plt.axis('off')   \nplt.imshow(cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB))\nplt.subplot(1, 2, 2).set_title('After Watershed Algorithm', fontsize = font_size); plt.axis('off')   \nplt.imshow(cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB))\nplt.show()","eb020af4":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook\n\nmask = cv2.imread('..\/input\/directions\/Direction\/Up\/102.jpg',0)\nmask = cv2.resize(mask, (height, width))\n\nfor i, path in enumerate(paths):\n    \n    name = os.path.split(path)[-1]\n    img = cv2.imread(path, cv2.IMREAD_COLOR)\n    resized_img = cv2.resize(img, (height, width))\n    \n    ret, th = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n    inverted_mask = cv2.bitwise_not(th)\n    damaged_img = cv2.bitwise_and(resized_img, resized_img, mask = inverted_mask)\n    \n    result = cv2.inpaint(resized_img, mask, inpaintRadius = 3, flags = cv2.INPAINT_TELEA)\n\n\n    plt.figure(figsize=(15, 8))\n    plt.subplot(1, 2, 1).set_title(f'Damaged Image of {name[ : -4]}', fontsize = font_size); plt.axis('off')   \n    plt.imshow(cv2.cvtColor(damaged_img, cv2.COLOR_BGR2RGB))\n    plt.subplot(1, 2, 2).set_title(f'After Image Inpainting of {name[ : -4]}', fontsize = font_size); plt.axis('off')   \n    plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n    plt.show()","7442fb6a":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook\n\nimg = cv2.imread('..\/input\/directions\/Direction\/Up\/102.jpg', cv2.IMREAD_COLOR)\nimg_copy = img.copy()\ntemplate = cv2.imread('..\/input\/directions\/Direction\/Left\/105.jpg', cv2.IMREAD_COLOR)\nw, h, c = template.shape\n\nmethod = eval('cv2.TM_CCOEFF')\n\nresult = cv2.matchTemplate(img, templ = template, method = method)\nmin_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n\ntop_left = max_loc\n\nbottom_right = (top_left[0] + w, top_left[1] + h)\n\ncv2.rectangle(img, top_left, bottom_right, color = (255, 0, 0), thickness = 3)\n\nplt.figure(figsize=(30, 20))\nplt.subplot(2, 2, 1).set_title('Image of Up and Left Direction', fontsize = 35); plt.axis('off')\nplt.imshow(cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB))\nplt.subplot(2, 2, 2).set_title('Face Template of Directions', fontsize = 35); plt.axis('off')\nplt.imshow(cv2.cvtColor(template, cv2.COLOR_BGR2RGB))\nplt.subplot(2, 2, 3).set_title('Matching Result', fontsize = 35); plt.axis('off')\nplt.imshow(result, cmap = 'gray')\nplt.subplot(2, 2, 4).set_title('Detected Direction', fontsize = 35); plt.axis('off')\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nplt.show()","464dcc45":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook\n\nface_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\neye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n\nimg = cv2.imread('..\/input\/directions\/Direction\/Up\/102.jpg')\nimg = cv2.resize(img, (height, width))\nimg_copy = img.copy()\n\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nfaces = face_cascade.detectMultiScale(gray, scaleFactor = 1.3, minNeighbors = 5)\n\nfor (fx, fy, fw, fh) in faces:\n    img = cv2.rectangle(img, (fx, fy), (fx + fw, fy + fh), (255, 0, 0), 2)\n\n    roi_gray = gray[fy:fy+fh, fx:fx+fw]\n    roi_color = img[fy:fy+fh, fx:fx+fw]\n    \n    eyes = eye_cascade.detectMultiScale(roi_gray)\n    \n    for (ex, ey, ew, eh) in eyes:\n        cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n        \nplt.figure(figsize=(15, 8))\nplt.subplot(1, 2, 1).set_title('No Eyes', fontsize = font_size); plt.axis('off')   \nplt.imshow(cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB))\nplt.subplot(1, 2, 2).set_title('After Face and Eyes Detections', fontsize = font_size); plt.axis('off')   \nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nplt.show()  ","793ac79d":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Thank you Asha Gutlapalli @ashagutlapalli for the script.' )","e7e2c641":"#IMAGE SEGMENTATION","62f2ed41":"#IMAGE GRADIENTS\n\nGradients are the slope of the tangent of the graph of the function.","3e26422f":"#Denoising","ac625c21":"#FACE AND EYE DETECTION\n\nSaving for next work since we have No Eyes in this Dataset.","676a7578":"#Different snippets to be repeated:\n\nFACE AND EYE DETECTION, TEMPLATE MATCHING (need 2 persons), IMAGE INPAINTING and Segmentation, Pyramids, Contours and GEOMETRIC TRANSFORMATION OF IMAGE (basic the last ones).","c19eef9c":"#GEOMETRIC TRANSFORMATION OF IMAGE","41efb0e3":"#Code by Asha Gutlapalli https:\/\/www.kaggle.com\/ashagutlapalli\/computer-vision-101-with-opencv\/notebook ","0683446e":"#Grayscale","77a7f6e7":"#TEMPLATE MATCHING","8b5bf070":"#EDGE DETECTION","0c442c27":"#IMAGE INPAINTING","2b84ca1e":"#COLORSPACE CONVERSION AND OBJECT TRACKING","dda22003":"#MORPHOLOGICAL TRANSFORMATION OF IMAGE","ae456066":"#LINE TRANSFORM","a1d84029":"#IMAGE PYRAMIDS\n\nGradient Pyramids\n\nLaplacian Pyramids","73c20891":"#Contours","38f75d69":"#INTERACTIVE FOREGROUND EXTRACTION","cbb846e3":"#THRESHOLDING","fa261311":"#FOURIER TRANSFORM ON IMAGE","19d71e2a":"#CORNER DETECTION","2dd6c64c":"#IMAGE AND RESIZING"}}