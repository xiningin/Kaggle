{"cell_type":{"196bc6c6":"code","73236dcc":"code","efb6176e":"code","2d20f443":"code","e73c2e96":"code","1a3b854e":"code","c07daacc":"code","aeedca28":"code","98ffac0d":"code","0e4f3617":"code","48da4a14":"code","a921cc1a":"code","5f8224ec":"code","9ef4a35c":"code","598c48a8":"code","ae77ead1":"code","a9914590":"code","fa28b09a":"code","b10b7da9":"code","9a17115e":"code","6911a3d7":"code","eed6e46d":"code","14fe5f2c":"code","8f6ddfda":"code","32e11812":"code","8d33bc20":"code","88c75cfc":"code","e87c5833":"code","d9c0bcca":"code","6593312a":"code","3b8aa3b2":"code","83dc5fa6":"code","19492bcb":"code","9a710954":"code","88415bd0":"code","2903729a":"code","b20db8f3":"code","913b82a8":"code","f3983f05":"code","550bf55e":"code","4d308713":"markdown","57ae7bcc":"markdown","b7f2a20f":"markdown","c84623db":"markdown","fcaa5b29":"markdown"},"source":{"196bc6c6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","73236dcc":"bankdata = pd.read_csv(\"..\/input\/Churn_Modelling.csv\")","efb6176e":"bankdata.head(10)","2d20f443":"bankdata.isna().sum()","e73c2e96":"bankdata.CustomerId.unique().size","1a3b854e":"bankdata.info()","c07daacc":"import matplotlib.pyplot as plt\n%matplotlib inline\nbankdata.Exited.value_counts()\nplt.title = \"Exited Class Histogram\"\nplt.xlabel = \"Exited\"\nplt.ylabel = \"Frequency\"\npd.value_counts(bankdata['Exited']).plot.bar()","aeedca28":"import matplotlib.pyplot as plt\n%matplotlib inline\nbankdata.Geography.value_counts()\nplt.title = \"Exited Class Histogram\"\nplt.xlabel = \"Geography\"\nplt.ylabel = \"Frequency\"\npd.value_counts(bankdata['Geography']).plot.bar()","98ffac0d":"import matplotlib.pyplot as plt\n%matplotlib inline\nbankdata.Gender.value_counts()\nplt.title = \"Gender Class Histogram\"\nplt.xlabel = \"Gender\"\nplt.ylabel = \"Frequency\"\npd.value_counts(bankdata['Gender']).plot.bar()","0e4f3617":"import matplotlib.pyplot as plt\n%matplotlib inline\nbankdata.IsActiveMember.value_counts()\nplt.title = \"IsActiveMember Class Histogram\"\nplt.xlabel = \"IsActiveMember\"\nplt.ylabel = \"Frequency\"\npd.value_counts(bankdata['IsActiveMember']).plot.bar()","48da4a14":"import matplotlib.pyplot as plt\n%matplotlib inline\nbankdata.HasCrCard.value_counts()\nplt.title = \"HasCrCard Histogram\"\nplt.xlabel = \"HasCrCard\"\nplt.ylabel = \"Frequency\"\npd.value_counts(bankdata['HasCrCard']).plot.bar()","a921cc1a":"import matplotlib.pyplot as plt\n%matplotlib inline\nbankdata.Surname.value_counts()\nplt.title = \"Surname Histogram\"\nplt.xlabel = \"Surname\"\nplt.ylabel = \"Frequency\"\npd.value_counts(bankdata['Surname']).plot.bar()","5f8224ec":"bankdata.describe()","9ef4a35c":"bankdata.corr()","598c48a8":"import seaborn as sn\ncorrelationmat = bankdata.corr(method='pearson')\nf, ax = plt.subplots(figsize = (10,10))\nsn.heatmap(correlationmat, vmax=0.8, square=True, annot=True)","ae77ead1":"bankdata.drop(columns=['RowNumber','CustomerId', 'Surname'], axis= 1, inplace= True)\nbankdata.IsActiveMember.value_counts()","a9914590":"plot_data = bankdata[['CreditScore', 'Age', 'Tenure',\n                     'Balance','NumOfProducts','EstimatedSalary']]\ngrid = sn.pairplot(data = plot_data, size = 3)","fa28b09a":"# box and whisker plots to check outliers\nbankdata.plot(kind='box', subplots=True, layout=(4,4), fontsize=8, figsize=(14,14))\nplt.show()","b10b7da9":"print(\"Before\",bankdata.shape)\ndef outlier(col): \n            q3 = bankdata[col].quantile(0.75) \n            q1 = bankdata[col].quantile(0.25) \n            iqr = q3 - q1 \n            lowval = q1 - 1.5* iqr \n            highval = q3 + 1.5 * iqr \n            loc_ret = bankdata.loc[(bankdata[col] > lowval) & (bankdata[col] < highval)] \n            return loc_ret      \nnumeric_subset = bankdata.select_dtypes('number') \n\nbankdata = outlier('Age')\nbankdata = outlier('CreditScore')\nbankdata = outlier('NumOfProducts')\nprint(\"After\",bankdata.shape)","9a17115e":"bankdata.head(5)","6911a3d7":"Y=bankdata[['Exited']]\nX= bankdata.drop('Exited', axis=1)","eed6e46d":"from sklearn.preprocessing import LabelEncoder\nlencoder = LabelEncoder()\nfor i in range(0,X.shape[1]):\n    if X.dtypes[i]=='object':\n        X[X.columns[i]] = lencoder.fit_transform(X[X.columns[i]])","14fe5f2c":"from sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nScaled_X= pd.DataFrame(ss.fit_transform(X), columns=X.columns)","8f6ddfda":"Scaled_X.head(5)","32e11812":"from imblearn.over_sampling import SMOTE\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(Scaled_X, Y, test_size=0.2, random_state=0)\n\nprint(\"Number transactions X_train dataset: \", X_train.shape)\nprint(\"Number transactions y_train dataset: \", y_train.shape)\nprint(\"Number transactions X_test dataset: \", X_test.shape)\nprint(\"Number transactions y_test dataset: \", y_test.shape)","8d33bc20":"#print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train[:1]==1)))\n#print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n\nsm = SMOTE(random_state=2)\nX_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n\nprint('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))","88c75cfc":"#y_train_res1.shape\nX_train_res1 = pd.DataFrame(X_train_res)\ny_train_res1 = pd.DataFrame(y_train_res)","e87c5833":"y_train_res1.head(5)","d9c0bcca":"import keras \nmodel = keras.models.Sequential()\nmodel.add(keras.layers.Dense(5, input_dim=10, activation='relu'))\nmodel.add(keras.layers.Dense(5, activation='relu'))\nmodel.add(keras.layers.Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","6593312a":"model.fit(X_train_res1, y_train_res1, epochs=20, batch_size=10)","3b8aa3b2":"predict = model.predict(X_test)\npredict = predict> 0.5","83dc5fa6":"from sklearn.metrics import confusion_matrix\nmatrix1 =confusion_matrix(y_test, predict)","19492bcb":"matrix1","9a710954":"accuracy = (matrix1[0,0]+ matrix1[1,1])\/(matrix1[0,0]+ matrix1[1,1] + matrix1[0,1]+ matrix1[1,0])\naccuracy","88415bd0":"from keras.optimizers import SGD\nmodel2 = keras.models.Sequential()\nmodel2.add(keras.layers.Dense(5, input_dim=10, activation='relu'))\nmodel2.add(keras.layers.BatchNormalization())\nmodel2.add(keras.layers.Dense(10, activation='relu'))\nmodel2.add(keras.layers.BatchNormalization())\nmodel2.add(keras.layers.Dense(1, activation='sigmoid'))\nsgd = SGD(lr=0.01, decay=1e-6, momentum = 0.9)\nmodel2.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])","2903729a":"model2.fit(X_train_res1, y_train_res1, epochs=10, batch_size=10)","b20db8f3":"predict1 = model2.predict(X_test)\npredict1 = predict1> 0.5","913b82a8":"from sklearn.metrics import confusion_matrix\nmatrix2 =confusion_matrix(y_test, predict1)","f3983f05":"matrix2","550bf55e":"accuracy = (matrix2[0,0]+ matrix2[1,1])\/(matrix2[0,0]+ matrix2[1,1] + matrix2[0,1]+ matrix2[1,0])\naccuracy","4d308713":"There is no correlation between features and target","57ae7bcc":"Divide the data set into Train and test sets, Apply smote to resolve the issue of class imbalnce","b7f2a20f":" Normalize the train and test data (2.5 points)","c84623db":"        Data Looks clean, but there is a class imbalance. ","fcaa5b29":" Initialize & build the model (10 points)"}}