{"cell_type":{"bfb75c69":"code","eb0e7c29":"code","ee2e443f":"code","fd1473d0":"code","c9c199e1":"code","0e0ec834":"code","7d3cae61":"code","946aec81":"code","26d1748b":"code","c23bc2a8":"code","c97edbc2":"code","a9df7804":"code","dd7df4c9":"code","f0fbed43":"code","ec1cfebe":"code","de95a375":"code","77be3b47":"code","9eaa5e8d":"code","48ddcf3e":"code","7ffb2548":"code","ec479d3f":"code","58ecbdd4":"code","265b4092":"code","adc094d8":"code","dbebf0d9":"code","61185be2":"code","a1067fd9":"code","3815d209":"code","e617e815":"code","bd1f0684":"code","4a426ca2":"code","041dda23":"code","87a69654":"code","44abbee1":"code","cc132e0b":"code","3937db4c":"code","b1f27723":"code","6d84c45d":"code","49767ef0":"code","fe91ac55":"code","39cbb856":"code","6e903aa2":"code","b21ef5fc":"code","12aed8f7":"code","d5edc005":"code","55dcfce9":"code","f1e7d58d":"code","2a310622":"code","0668176b":"code","826efdf9":"code","b88814d8":"code","b0cf0976":"code","aed0122a":"code","a9bf4ed5":"code","b70cbc17":"code","fd471752":"markdown","c8a4dd43":"markdown","8984d64b":"markdown"},"source":{"bfb75c69":"!pip install console_progressbar","eb0e7c29":"# This preprocessing portion of the code is provided by foamliu on his github repo\n# https:\/\/github.com\/foamliu\/Car-Recognition\/blob\/master\/pre-process.py\n\nimport tarfile\nimport scipy.io\nimport numpy as np\nimport os\nimport cv2 as cv\nimport shutil\nimport random\nfrom console_progressbar import ProgressBar","ee2e443f":"def ensure_folder(folder):\n    if not os.path.exists(folder):\n        os.makedirs(folder)\n        \ndef save_train_data(fnames, labels, bboxes):\n    src_folder ='..\/input\/stanford-cars-dataset\/cars_train\/cars_train\/'\n    num_samples = len(fnames)\n\n    train_split = 0.8\n    num_train = int(round(num_samples * train_split))\n    train_indexes = random.sample(range(num_samples), num_train)\n\n    pb = ProgressBar(total=100, prefix='Save train data', suffix='', decimals=3, length=50, fill='=')\n\n    for i in range(num_samples):\n        fname = fnames[i]\n        label = labels[i]\n        (x1, y1, x2, y2) = bboxes[i]\n\n        src_path = os.path.join(src_folder, fname)\n        src_image = cv.imread(src_path)\n        height, width = src_image.shape[:2]\n        # margins of 16 pixels\n        margin = 16\n        x1 = max(0, x1 - margin)\n        y1 = max(0, y1 - margin)\n        x2 = min(x2 + margin, width)\n        y2 = min(y2 + margin, height)\n        # print(\"{} -> {}\".format(fname, label))\n        pb.print_progress_bar((i + 1) * 100 \/ num_samples)\n\n        if i in train_indexes:\n            dst_folder = '\/kaggle\/working\/data\/train\/'\n        else:\n            dst_folder = '\/kaggle\/working\/data\/valid\/'\n\n        dst_path = os.path.join(dst_folder, label)\n        if not os.path.exists(dst_path):\n            os.makedirs(dst_path)\n        dst_path = os.path.join(dst_path, fname)\n\n        crop_image = src_image[y1:y2, x1:x2]\n        dst_img = cv.resize(src=crop_image, dsize=(img_height, img_width))\n        cv.imwrite(dst_path, dst_img)","fd1473d0":"def save_test_data(fnames, bboxes):\n    src_folder = '..\/input\/stanford-cars-dataset\/cars_test\/cars_test\/'\n    dst_folder = '\/kaggle\/working\/data\/test\/'\n    num_samples = len(fnames)\n\n    pb = ProgressBar(total=100, prefix='Save test data', suffix='', decimals=3, length=50, fill='=')\n\n    for i in range(num_samples):\n        fname = fnames[i]\n        (x1, y1, x2, y2) = bboxes[i]\n        src_path = os.path.join(src_folder, fname)\n        src_image = cv.imread(src_path)\n        height, width = src_image.shape[:2]\n        # margins of 16 pixels\n        margin = 16\n        x1 = max(0, x1 - margin)\n        y1 = max(0, y1 - margin)\n        x2 = min(x2 + margin, width)\n        y2 = min(y2 + margin, height)\n        # print(fname)\n        pb.print_progress_bar((i + 1) * 100 \/ num_samples)\n\n        dst_path = os.path.join(dst_folder, fname)\n        crop_image = src_image[y1:y2, x1:x2]\n        dst_img = cv.resize(src=crop_image, dsize=(img_height, img_width))\n        cv.imwrite(dst_path, dst_img)","c9c199e1":"def process_train_data():\n    print(\"Processing train data...\")\n    cars_annos = scipy.io.loadmat('..\/input\/cars-devkit\/cars_train_annos.mat')\n    annotations = cars_annos['annotations']\n    annotations = np.transpose(annotations)\n\n    fnames = []\n    class_ids = []\n    bboxes = []\n    labels = []\n\n    for annotation in annotations:\n        bbox_x1 = annotation[0][0][0][0]\n        bbox_y1 = annotation[0][1][0][0]\n        bbox_x2 = annotation[0][2][0][0]\n        bbox_y2 = annotation[0][3][0][0]\n        class_id = annotation[0][4][0][0]\n        labels.append('%04d' % (class_id,))\n        fname = annotation[0][5][0]\n        bboxes.append((bbox_x1, bbox_y1, bbox_x2, bbox_y2))\n        class_ids.append(class_id)\n        fnames.append(fname)\n\n    labels_count = np.unique(class_ids).shape[0]\n    print(np.unique(class_ids))\n    print('The number of different cars is %d' % labels_count)\n\n    save_train_data(fnames, labels, bboxes)","0e0ec834":"def process_test_data():\n    print(\"Processing test data...\")\n    cars_annos = scipy.io.loadmat('..\/input\/cars-devkit\/cars_test_annos.mat')\n    annotations = cars_annos['annotations']\n    annotations = np.transpose(annotations)\n\n    fnames = []\n    bboxes = []\n\n    for annotation in annotations:\n        bbox_x1 = annotation[0][0][0][0]\n        bbox_y1 = annotation[0][1][0][0]\n        bbox_x2 = annotation[0][2][0][0]\n        bbox_y2 = annotation[0][3][0][0]\n        fname = annotation[0][4][0]\n        bboxes.append((bbox_x1, bbox_y1, bbox_x2, bbox_y2))\n        fnames.append(fname)\n\n    save_test_data(fnames, bboxes)","7d3cae61":"img_width, img_height = 224, 224\n\ncars_meta = scipy.io.loadmat('..\/input\/cars-devkit\/cars_meta.mat')\nclass_names = cars_meta['class_names']  # shape=(1, 196)\nclass_names = np.transpose(class_names)\nprint('class_names.shape: ' + str(class_names.shape))\nprint('Sample class_name: [{}]'.format(class_names[8][0][0]))\n\nensure_folder('\/kaggle\/working\/data\/train')\nensure_folder('\/kaggle\/working\/data\/valid')\nensure_folder('\/kaggle\/working\/data\/test')\n\nprocess_train_data()\nprocess_test_data()","946aec81":"import torchvision\nfrom fastai.vision import *\nfrom fastai.metrics import error_rate\nfrom fastai import *\nimport cv2 as cv\nimport numpy as np\nimport pandas as pd\nimport scipy.io as sio","26d1748b":"tfms = get_transforms(do_flip=True, flip_vert=False, max_lighting=0.1, max_zoom=1.05,\n                      max_warp=0.,\n                      xtra_tfms=[rand_crop(), rand_zoom(1, 1.5),\n                                 symmetric_warp(magnitude=(-0.2, 0.2))])\n\ndata = ImageDataBunch.from_folder('data\/','train','valid',\n                                  ds_tfms=tfms\n                                  ,size=128,bs=64).normalize(imagenet_stats)","c23bc2a8":"data.show_batch(rows=3, figsize=(12,9))","c97edbc2":"# class names and number of classes\n# print(data.classes)\nlen(data.classes),data.c","a9df7804":"!pip install pretrainedmodels\nimport pretrainedmodels","dd7df4c9":"from torch import nn\nimport torch.nn.functional as F\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1., gamma=2.):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, inputs, targets, **kwargs):\n        CE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n        pt = torch.exp(-CE_loss)\n        F_loss = self.alpha * ((1-pt)**self.gamma) * CE_loss\n        return F_loss.mean()","f0fbed43":"def resnext50_32x4d(pretrained=False):\n    pretrained = 'imagenet' if pretrained else None\n    model = pretrainedmodels.se_resnext50_32x4d(pretrained=pretrained)\n    return nn.Sequential(*list(model.children()))","ec1cfebe":"learn = cnn_learner(data, resnext50_32x4d, pretrained=True, cut=-2,\n                    split_on=lambda m: (m[0][3], m[1]), \n                    metrics=[accuracy])\nlearn.loss_fn = FocalLoss()","de95a375":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","77be3b47":"learn.fit_one_cycle(32, max_lr=slice(2e-2), wd=1e-5)","9eaa5e8d":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","48ddcf3e":"learn.save('resnext50_32x4d_1');\nlearn.unfreeze();\nlearn = learn.clip_grad();","7ffb2548":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","ec479d3f":"learn.load('resnext50_32x4d_1');\nlearn.unfreeze();\nlearn = learn.clip_grad();","58ecbdd4":"lr = [3e-3\/100, 3e-3\/20, 3e-3\/10]\nlearn.fit_one_cycle(36, lr, wd=1e-7)\n","265b4092":"learn.save('resnext50_32x4d_2');","adc094d8":"SZ = 224\ncutout_frac = 0.20\np_cutout = 0.75\ncutout_sz = round(SZ*cutout_frac)\ncutout_tfm = cutout(n_holes=(1,1), length=(cutout_sz, cutout_sz), p=p_cutout)\n\ntfms = get_transforms(do_flip=True, max_rotate=15, flip_vert=False, max_lighting=0.1,\n                      max_zoom=1.05, max_warp=0.,\n                      xtra_tfms=[rand_crop(), rand_zoom(1, 1.5),\n                                 symmetric_warp(magnitude=(-0.2, 0.2)), cutout_tfm])","dbebf0d9":"data = ImageDataBunch.from_folder('data\/','train','valid',\n                                  ds_tfms=tfms\n                                  ,size=224,bs=32).normalize(imagenet_stats)\n\nlearn.data = data\ndata.train_ds[0][0].shape","61185be2":"learn.load('resnext50_32x4d_2');\nlearn.freeze();\nlearn = learn.clip_grad();","a1067fd9":"learn.loss_func = FocalLoss()","3815d209":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","e617e815":"learn.fit_one_cycle(24, slice(3e-3), wd=5e-6)","bd1f0684":"learn.save('resnext50_32x4d_3');\nlearn.load('resnext50_32x4d_3');","4a426ca2":"learn.unfreeze();\nlearn = learn.clip_grad();","041dda23":"lr = [1e-3\/200, 1e-3\/20, 1e-3\/10]\nlearn.fit_one_cycle(32, lr)","87a69654":"learn.save('resnext50_32x4d_4');\nlearn.load('resnext50_32x4d_4');","44abbee1":"SZ = 299\ncutout_frac = 0.20\np_cutout = 0.75\ncutout_sz = round(SZ*cutout_frac)\ncutout_tfm = cutout(n_holes=(1,1), length=(cutout_sz, cutout_sz), p=p_cutout)","cc132e0b":"tfms = get_transforms(do_flip=True, max_rotate=15, flip_vert=False, max_lighting=0.1,\n                      max_zoom=1.05, max_warp=0.,\n                      xtra_tfms=[rand_crop(),\n                                 symmetric_warp(magnitude=(-0.2, 0.2)), cutout_tfm])","3937db4c":"data = ImageDataBunch.from_folder('data\/','train','valid',\n                                  ds_tfms=tfms\n                                  ,size=SZ,bs=24).normalize(imagenet_stats)\n\nlearn.data = data","b1f27723":"learn.load('resnext50_32x4d_4');\nlearn.freeze();\nlearn = learn.clip_grad();\nlearn.mixup();","6d84c45d":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","49767ef0":"learn.fit_one_cycle(32, slice(1e-2))","fe91ac55":"learn.save('resnext50_32x4d_5');","39cbb856":"learn.load('resnext50_32x4d_5');","6e903aa2":"learn.unfreeze();\nlearn = learn.clip_grad();\n# learn.mixup();","b21ef5fc":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","12aed8f7":"lr = [2e-5, 2e-4, 2e-3]\nlearn.fit_one_cycle(64, lr)","d5edc005":"learn.export('\/kaggle\/working\/fastai_resnet.pkl');","55dcfce9":"labels = sio.loadmat('..\/input\/cars-devkit\/cars_test_annos_withlabels.mat')","f1e7d58d":"x = []\nfor i in range(8041):\n    x.append(np.transpose(np.array(labels['annotations']['fname']))[i][0][0])","2a310622":"df=pd.DataFrame(data=np.transpose(np.array(labels['annotations']['class'],dtype=np.int)),\n                  index=x)\n\ndf.to_csv('\/kaggle\/working\/data\/test_labels.csv')","0668176b":"learn = load_learner('\/kaggle\/working\/','fastai_resnet.pkl', test= \n                     ImageList.from_csv('\/kaggle\/working\/data','test_labels.csv',folder='test'))\npreds,y = learn.TTA(ds_type=DatasetType.Test)","826efdf9":"a=preds;a.shape","b88814d8":"b=np.array(labels['annotations']['class'],dtype=np.int)-1;b.shape \nb = torch.from_numpy(b)","b0cf0976":"acc=accuracy(a,b);acc","aed0122a":"pd.DataFrame(preds.cpu().numpy()).to_csv('test_probs.csv',index=False)","a9bf4ed5":"labelled_preds = torch.argmax(preds,1).cpu().numpy()\nout = open('result.txt', 'a')\nfor val in labelled_preds:\n    out.write('{}\\n'.format(str(val+1)))\nout.close()","b70cbc17":"!rm -rf data\/","fd471752":"# Size 299","c8a4dd43":"# Size 224","8984d64b":"# Predicting on the test set"}}