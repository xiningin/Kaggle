{"cell_type":{"8b69d0c7":"code","c509caed":"code","8e0f9ec1":"code","4efcd63b":"code","0d73edbe":"code","59af5117":"code","fabab06e":"code","c9e059e2":"code","453a7690":"code","d275cf06":"code","1bd961c9":"code","4a574697":"code","a23c1ad9":"code","f1a925c8":"code","d7b00c94":"code","a9649dd6":"code","c090677b":"code","0d4dd14d":"code","274fb906":"code","a6f1557b":"code","079d8dd9":"markdown","efe32c53":"markdown","4356cefa":"markdown","e1ad5e2c":"markdown","52df3bb8":"markdown","c9719c1c":"markdown","622448dc":"markdown","6623712e":"markdown","fd7b07be":"markdown","e4d7f70f":"markdown","90a7765b":"markdown","6866454a":"markdown","2c02d5dd":"markdown","1807cf8b":"markdown","c51ba274":"markdown","3dde68c3":"markdown","48ae95a4":"markdown","6258c30b":"markdown","1db05adf":"markdown","e34e0210":"markdown"},"source":{"8b69d0c7":"import os\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nimport zlib\nimport itertools\nimport sklearn\nimport itertools\nimport scipy\nimport skimage\nfrom skimage.transform import resize\nimport csv\nfrom tqdm import tqdm\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, learning_curve,KFold,cross_val_score,StratifiedKFold\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import confusion_matrix\nimport keras\nimport tensorflow as tf\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, MaxPool2D, BatchNormalization\nfrom keras.utils import np_utils\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import models, layers, optimizers\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.utils import class_weight\nfrom keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\nfrom keras.models import Sequential, model_from_json\nfrom keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D,MaxPooling2D,AveragePooling2D, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras import backend as K\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.applications.inception_v3 import InceptionV3\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.applications import Xception\n\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","c509caed":"train_dir = \".\/chest_xray\/train\/\"\ntest_dir =  \".\/chest_xray\/test\/\"\ndef get_data(folder):\n    X = []\n    y = []\n    for folderName in os.listdir(folder):\n        if not folderName.startswith('.'):\n            if folderName in ['NORMAL']:\n                label = 0\n            elif folderName in ['PNEUMONIA']:\n                label = 1\n            else:\n                label = 2\n            for image_filename in tqdm(os.listdir(folder + folderName)):\n                img_file = cv2.imread(folder + folderName + '\/' + image_filename)\n                if img_file is not None:\n                    img_file = skimage.transform.resize(img_file, (200,200,3))\n                    img_arr = np.asarray(img_file)\n                    X.append(img_arr)\n                    y.append(label)\n    X = np.asarray(X)\n    y = np.asarray(y)\n    return X,y\nX_train, y_train = get_data(train_dir)\nX_test, y_test= get_data(test_dir)\n\n# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nfrom keras.utils.np_utils import to_categorical\ny_trainHot = to_categorical(y_train, num_classes = 2)\ny_testHot = to_categorical(y_test, num_classes = 2)","8e0f9ec1":"def plotHistogram(a):\n    \"\"\"\n    Plot histogram of RGB Pixel Intensities\n    \"\"\"\n    plt.figure(figsize=(10,5))\n    plt.subplot(1,2,1)\n    plt.imshow(a)\n    plt.axis('off')\n    histo = plt.subplot(1,2,2)\n    histo.set_ylabel('Count')\n    histo.set_xlabel('Pixel Intensity')\n    n_bins = 30\n    plt.hist(a[:,:,0].flatten(), bins= n_bins, lw = 0, color='r', alpha=0.5);\n    plt.hist(a[:,:,1].flatten(), bins= n_bins, lw = 0, color='g', alpha=0.5);\n    plt.hist(a[:,:,2].flatten(), bins= n_bins, lw = 0, color='b', alpha=0.5);\nplotHistogram(X_train[1])","4efcd63b":"print(\"20 images from Normal Category\")\nmultipleImages = glob('.\/chest_xray\/train\/NORMAL\/**')\ni_ = 0\nplt.rcParams['figure.figsize'] = (12.0, 12.0)\nplt.subplots_adjust(wspace=0, hspace=0)\nfor l in multipleImages[:25]:\n    im = cv2.imread(l)\n    im = cv2.resize(im, (128, 128)) \n    plt.subplot(5, 5, i_+1) #.set_title(l)\n    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    i_ += 1","0d73edbe":"print(\"20 images Pneumonia Category\")\nmultipleImages = glob('.\/chest_xray\/train\/PNEUMONIA\/**')\ni_ = 0\nplt.rcParams['figure.figsize'] = (12.0, 12.0)\nplt.subplots_adjust(wspace=0, hspace=0)\nfor l in multipleImages[:25]:\n    im = cv2.imread(l)\n    im = cv2.resize(im, (128, 128)) \n    plt.subplot(5, 5, i_+1) #.set_title(l)\n    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    i_ += 1","59af5117":"map_characters = {0: 'No Pneumonia', 1: 'Yes Pneumonia'}\ndict_characters=map_characters\nimport seaborn as sns\ndf = pd.DataFrame()\ndf[\"labels\"]=y_train\nlab = df['labels']\ndist = lab.value_counts()\nsns.countplot(lab)\nprint(dict_characters)","fabab06e":"# Helper Functions  Learning Curves and Confusion Matrix\n\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nclass MetricsCheckpoint(Callback):\n    \"\"\"Callback that saves metrics after each epoch\"\"\"\n    def __init__(self, savepath):\n        super(MetricsCheckpoint, self).__init__()\n        self.savepath = savepath\n        self.history = {}\n    def on_epoch_end(self, epoch, logs=None):\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n        np.save(self.savepath, self.history)\n\ndef plotKerasLearningCurve():\n    plt.figure(figsize=(10,5))\n    metrics = np.load('logs.npy')[()]\n    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n        l = np.array(metrics[k])\n        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n        y = l[x]\n        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n    plt.legend(loc=4)\n    plt.axis([0, None, None, None]);\n    plt.grid()\n    plt.xlabel('Number of epochs')\n    plt.ylabel('Accuracy')\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (5,5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\ndef plot_learning_curve(history):\n    plt.figure(figsize=(8,8))\n    plt.subplot(1,2,1)\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('.\/accuracy_curve.png')\n    plt.subplot(1,2,2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('.\/loss_curve.png')","c9e059e2":"map_characters1 = {0: 'No Pneumonia', 1: 'Yes Pneumonia'}\nclass_weight1 = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\nweight_path1 = '.\/imagenet_models\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\nweight_path2 = '.\/imagenet_models\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\nweight_path3 = '.\/imagenet_models\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nweight_path4 = '.\/imagenet_models\/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\nweight_path5 = '.\/imagenet_models\/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\npretrained_model_1 = VGG16(weights = weight_path1, include_top=False, input_shape=(200, 200, 3))\npretrained_model_2 = InceptionV3(weights = weight_path2, include_top=False, input_shape=(200, 200, 3))\npretrained_model_3 = ResNet50(weights = weight_path3, include_top=False, input_shape=(200, 200, 3))\npretrained_model_4 = InceptionResNetV2(weights = weight_path4, include_top=False, input_shape=(200, 200, 3))\npretrained_model_5 = Xception(weights = weight_path5, include_top=False, input_shape=(200, 200, 3))\noptimizer1 = keras.optimizers.Adam(lr=0.0001)\ndef pretrainedNetwork(xtrain,ytrain,xtest,ytest,pretrainedmodel,pretrainedweights,classweight,numclasses,numepochs,optimizer,labels):\n    base_model = pretrained_model_1 # Topless\n    # Add top layer\n    x = base_model.output\n    x = Flatten()(x)\n    predictions = Dense(numclasses, activation='relu')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n    # Train top layer\n    for layer in base_model.layers:\n        layer.trainable = False\n    model.compile(loss='categorical_crossentropy', \n                  optimizer=optimizer, \n                  metrics=['accuracy'])\n    callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n    model.summary()\n    # Fit model\n    history = model.fit(xtrain,ytrain, epochs=numepochs, class_weight=classweight, validation_data=(xtest,ytest), verbose=1,callbacks = [MetricsCheckpoint('logs')])\n    # Evaluate model\n    score = model.evaluate(xtest,ytest, verbose=0)\n    print('\\nKeras CNN - accuracy:', score[1], '\\n')\n    y_pred = model.predict(xtest)\n    print('\\n', sklearn.metrics.classification_report(np.where(ytest > 0)[1], np.argmax(y_pred, axis=1), target_names=list(labels.values())), sep='') \n    Y_pred_classes = np.argmax(y_pred,axis = 1) \n    Y_true = np.argmax(ytest,axis = 1) \n    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n    plot_learning_curve(history)\n    plt.show()\n    plot_confusion_matrix(confusion_mtx, classes = list(labels.values()))\n    plt.show()\n    return model\n","453a7690":"# Deal with imbalanced class sizes below\n# Make Data 1D for compatability upsampling methods\nX_trainShape = X_train.shape[1]*X_train.shape[2]*X_train.shape[3]\nX_testShape = X_test.shape[1]*X_test.shape[2]*X_test.shape[3]\nX_trainFlat = X_train.reshape(X_train.shape[0], X_trainShape)\nX_testFlat = X_test.reshape(X_test.shape[0], X_testShape)\nY_train = y_train\nY_test = y_test\nros = RandomUnderSampler(ratio='auto')\nX_trainRos, Y_trainRos = ros.fit_sample(X_trainFlat, Y_train)\nX_testRos, Y_testRos = ros.fit_sample(X_testFlat, Y_test)\nY_trainRosHot = to_categorical(Y_trainRos, num_classes = 2)\nY_testRosHot = to_categorical(Y_testRos, num_classes = 2)\n# Make Data 2D again\nfor i in range(len(X_trainRos)):\n    height, width, channels = 200,200,3\n    X_trainRosReshaped = X_trainRos.reshape(len(X_trainRos),height,width,channels)\nfor i in range(len(X_testRos)):\n    height, width, channels = 200,200,3\n    X_testRosReshaped = X_testRos.reshape(len(X_testRos),height,width,channels)\n# Plot Label Distribution\ndfRos = pd.DataFrame()\ndfRos[\"labels\"]=Y_trainRos\nlabRos = dfRos['labels']\ndistRos = lab.value_counts()\nsns.countplot(labRos)\nprint(dict_characters)","d275cf06":"class_weight1 = class_weight.compute_class_weight('balanced', np.unique(Y_train), Y_train)\nprint(\"Old Class Weights: \",class_weight1)\nclass_weight2 = class_weight.compute_class_weight('balanced', np.unique(Y_trainRos), Y_trainRos)\nprint(\"New Class Weights: \",class_weight2)","1bd961c9":"pretrainedNetwork(X_trainRosReshaped, Y_trainRosHot, X_testRosReshaped, Y_testRosHot,pretrained_model_1,weight_path1,class_weight2,2,6,optimizer1,map_characters1)","4a574697":"plotKerasLearningCurve()\nplt.show()\n","a23c1ad9":"pretrainedNetwork(X_trainRosReshaped, Y_trainRosHot, X_testRosReshaped, Y_testRosHot,pretrained_model_2,weight_path2,class_weight2,2,6,optimizer1,map_characters1)","f1a925c8":"plotKerasLearningCurve()\nplt.show()","d7b00c94":"pretrainedNetwork(X_trainRosReshaped, Y_trainRosHot, X_testRosReshaped, Y_testRosHot,pretrained_model_3,weight_path3,class_weight2,2,6,optimizer1,map_characters1)","a9649dd6":"plotKerasLearningCurve()\nplt.show()","c090677b":"pretrainedNetwork(X_trainRosReshaped, Y_trainRosHot, X_testRosReshaped, Y_testRosHot,pretrained_model_4,weight_path4,class_weight2,2,6,optimizer1,map_characters1)","0d4dd14d":"plotKerasLearningCurve()\nplt.show()","274fb906":"pretrainedNetwork(X_trainRosReshaped, Y_trainRosHot, X_testRosReshaped, Y_testRosHot,pretrained_model_5,weight_path5,class_weight2,2,6,optimizer1,map_characters1)","a6f1557b":"plotKerasLearningCurve()\nplt.show()","079d8dd9":"### Loading Data and scaling values to 0(Normal) and 1(Pneumonia)","efe32c53":"**The goal is to get rid of the class imbalance issues.  Oversampling with data augmentation (e.g. [SMOTE](http:\/\/contrib.scikit-learn.org\/imbalanced-learn\/stable\/over_sampling.html)) would be preferable to undersampling but undersampling is faster.**","4356cefa":"![](https:\/\/i.imgur.com\/jZqpV51.png)\n\n","e1ad5e2c":"## Evaluate Classification Models","52df3bb8":"### Evaluate Undersampling Strategy","c9719c1c":"### Transfer learning w\/ VGG16 Convolutional Network","622448dc":"### Transfer learning w\/ Xception Convolutional Network ","6623712e":"### Transfer learning w\/ VGG16, InceptionResNetV2, Inception V3, ResNet50 and Xception Convolutional Network","fd7b07be":"### Transfer learning w\/ InceptionResNetV2 Convolutional Network","e4d7f70f":"\n<tr>\n    <th>Model<\/th>\n    <th>Accuracy(Test Data)<\/th> \n  \n  <tr>\n    <td>VGG16<\/td>\n    <td>88.89<\/td>\n  <\/tr>\n  \n  <tr>\n    <td>InceptionV3<\/td>\n    <td>86.11<\/td>\n   <\/tr>\n    \n   <tr>\n    <td>ResNet50<\/td>\n    <td>50%<\/td>\n   <\/tr>\n   \n   <tr>\n    <td>InceptionResNetV2<\/td>\n    <td>51.71%<\/td>\n   <\/tr>\n   \n   <tr>\n    <td>Xception<\/td>\n    <td>50%<\/td>\n   <\/tr>\n   \n<\/tr>\n  ","90a7765b":"## Exploratory Data Analysis","6866454a":"## Problem Formulation","2c02d5dd":"### Note : VGG16 model have best accuracy of 88.90%.\n### InceptionV3 model performed as good as VGG16 with accuracy of 86.11 %.\n### All other models do not perform well except VGG16 and InceptionV3.","1807cf8b":"### Transfer learning w\/ InceptionV3 Convolutional Network","c51ba274":"**Using Adam Optimizer with learning rate = 0.0001, loss = categorical_crossentropy, ReLU activation and accuracy as metrics**","3dde68c3":"### Define Helper Functions","48ae95a4":"# Detecting Pneumonia in X-Ray Images","6258c30b":"### Visualizing Data","1db05adf":"Detecting penumonia from X-ray images using Deep Learning\n\n**Dataset source: https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia**<br>\nThe dataset is organized into 3 folders (train, test, val) and contains subfolders for each image category (Pneumonia\/Normal). There are 5,863 X-Ray images (JPEG) and 2 categories (Pneumonia\/Normal). Its a binary classification dataset. The two classes are Normal and Pneumonia.","e34e0210":"### Transfer learning w\/ ResNet50 Convolutional Network"}}