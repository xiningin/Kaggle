{"cell_type":{"cd117670":"code","3d69a145":"code","38d3959d":"code","8af40079":"code","4c858780":"code","2c6894f3":"code","081217df":"code","b42347e7":"code","d4454e85":"code","d70811ca":"code","132cbd1c":"code","bab1e6e9":"code","699bdab0":"code","f9f86156":"markdown","9ab804a6":"markdown","35d202b2":"markdown"},"source":{"cd117670":"import os\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\n","3d69a145":"\n#IMAGE_DIR = \"..\/input\/celeba-dataset\/img_align_celeba\/img_align_celeba\"\nIMG_HEIGHT = 128 \nIMG_WIDTH =  128\nBATCH_SIZE = 32\nAUTO = tf.data.experimental.AUTOTUNE\n\n","38d3959d":"#The following functions can be used to convert a value to a type compatible\n# with tf.Example.\n\ndef _bytes_feature(value):\n\n  if isinstance(value, type(tf.constant(0))):\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n   return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n","8af40079":"def serialize_example(image_string):\n  \"\"\"\n  Creates a tf.Example message ready to be written to a file.\n  \"\"\"\n  image_shape = tf.image.decode_jpeg(image_string).shape\n  feature = {\n\n      'image': _bytes_feature(image_string),\n  }\n\n  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n  return example_proto.SerializeToString()","4c858780":"def process_img(img):\n    \n  # convert the compressed string to a 3D uint8 tensor\n  img = tf.image.decode_jpeg(img, channels=3)\n\n  # crop image  \n  #credit: https:\/\/www.kaggle.com\/tobirohrer\/gan-with-tensorflow-and-tf-dataset\n  img = tf.image.central_crop(img, 0.7)\n  img = tf.image.crop_to_bounding_box(img, \n                                    offset_height = 30, \n                                    offset_width = 10, \n                                    target_height = 115, \n                                    target_width = 115\n                                     )\n\n  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n  img = tf.image.convert_image_dtype(img, tf.float32)\n  # resize the image to the desired size.    \n  return tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n\n","2c6894f3":"#function to create tfrecord\ndef create_tfrecord(file_dir,name='celeba'):\n    \n    #tfrecord filename\n    filename = name + '.tfrecord'\n\n    with tf.io.TFRecordWriter(filename) as writer:\n\n        for image in tqdm(os.listdir(file_dir)):\n                \n            img_string = open(os.path.join(file_dir,image), 'rb').read()\n            #img = process_img(img)\n            #img_string = base64.b64encode(img)\n                            \n            example = serialize_example(img_string)\n            writer.write(example)\n","081217df":"#process the image an save it to new directory in .jpg format\nfrom PIL import Image\n\ndef process_and_save():\n    \n    for image_name in tqdm(os.listdir(IMAGE_DIR)):\n        \n        img_string = open(os.path.join(IMAGE_DIR,image_name), 'rb').read()\n        img = process_img(img_string)\n        img = Image.fromarray((img.numpy() * 255).astype(np.uint8))\n        img = img.save('celeba-new\/'+image_name)\n\n\n                ","b42347e7":"#save image\nprocess_and_save()","d4454e85":"#create tfrecord\ncreate_tfrecord(file_dir='celeba-new')","d70811ca":"\n# Create a dictionary describing the features.\nimage_feature_description = {\n    'image': tf.io.FixedLenFeature([], tf.string),\n}\n\ndef _parse_image_function(example_proto):\n  # Parse the input tf.Example proto using the dictionary above.\n  parsed_example = tf.io.parse_single_example(example_proto, image_feature_description)\n  image = decode_image(parsed_example['image'])\n\n  return image\n\ndef decode_image(image_data):\n    #decode image \n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0  # convert image to floats in [0, 1] range\n    image = tf.image.resize(image,[IMG_HEIGHT,IMG_WIDTH])\n    return image","132cbd1c":"#function to plot images\ndef view_image(ds):\n    images = next(iter(ds)) # extract 1 batch from the dataset\n    images = images.numpy()\n\n    fig = plt.figure(figsize=(20, 20))\n    for i in range(20):\n        ax = fig.add_subplot(4, 5, i+1, xticks=[], yticks=[])\n        ax.imshow(images[i])\n","bab1e6e9":"#create tfdataset from tfrecord\nTFRECORD_FILE = '..\/input\/celeba-tfrecord\/celeba.tfrecord'\ndef create_dataset():\n\n    dataset = tf.data.TFRecordDataset(TFRECORD_FILE)\n\n    dataset = dataset.map(_parse_image_function, num_parallel_calls=AUTO)\n    dataset = dataset.repeat().shuffle(1024).batch(BATCH_SIZE).prefetch(AUTO)\n    \n    return dataset","699bdab0":"#create ds and view\nds = create_dataset()\nview_image(ds)","f9f86156":"# Create A Tfrecord for CelebA Dataset","9ab804a6":"### **If you already have a tfrecod file than call the function bellow**","35d202b2":"### **If you want to create a tfrecord from Celeba Dataset and then call the functions below.The reason to process and save the image separately is to avoid creating a large tfrecord file.I couldn't find the way to create tfrecord and process the data simultaneously without creating a large tfrecord file**"}}