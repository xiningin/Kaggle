{"cell_type":{"633b15b9":"code","02635de7":"code","86fbcb87":"code","0d03dcc9":"code","406d1ce9":"code","3d9f3d1b":"code","e0c23684":"code","e7ee5f23":"code","31d73593":"code","d3fd2883":"code","7cc88660":"code","2676ac1c":"code","dd62fd98":"code","fd1ff4a1":"code","2f32c39a":"code","26a86dc7":"code","5b31f903":"code","63c10494":"code","52102c88":"code","eb73b1a7":"code","93e538fd":"code","ce24128c":"code","3dae5a1e":"code","d485c02a":"code","3ee77f90":"code","c8303d76":"code","a0445a26":"code","9f57821f":"code","07fec57a":"markdown","4e97e3f9":"markdown","e128e450":"markdown","b30adaf7":"markdown","d5a2dee0":"markdown","964521b2":"markdown","a8553eab":"markdown","55d531fe":"markdown","fecf964d":"markdown","cf215832":"markdown","a49b8548":"markdown","500b0e51":"markdown","1c92d16f":"markdown","5d77f009":"markdown","a82217c5":"markdown","d92c7808":"markdown","16241c3a":"markdown","aa10246f":"markdown","0165213d":"markdown","f2e1d85c":"markdown","d42b603d":"markdown","bd3d505d":"markdown","9eaaf271":"markdown"},"source":{"633b15b9":"!pip install fastbook","02635de7":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom fastbook import *\nfrom fastai.vision.all import *\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","86fbcb87":"data = pd.read_csv('\/kaggle\/input\/10-monkey-species\/monkey_labels.txt', header=None, skiprows=1)\ndata.columns = ['Label', 'Latin Name', 'Common Name','Train Images','Validation Images']\ndata[\"Latin Name\"] = data[\"Latin Name\"].replace(\"\\t\",\"\", regex=True).apply(lambda x: x.strip())\ndata.head(10)","0d03dcc9":"print(\"No of Classes :\" +str(data[\"Label\"].nunique()))\nprint(\"No of Training Images :\" + str(data[\"Train Images\"].sum()))\nprint(\"No of Validation Images :\" +str(data[\"Validation Images\"].sum()))","406d1ce9":"## Following way we can create a Dictionay which can be useful to get Latin name from label simillary can create for Common Name\n\n#data[\"Latin Name\"] = data[\"Latin Name\"].replace(\"\\t\",\"\", regex=True).apply(lambda x: x.strip())\n#dictdata = dict(zip(data[\"Label\"],data[\"Latin Name\"].replace(\"\\t\",\" \")))","3d9f3d1b":"#Creating the path object passing the path\npath = Path(\"\/kaggle\/input\/10-monkey-species\/training\/training\")","e0c23684":"fns = get_image_files(path)","e7ee5f23":"failed = verify_images(fns)\nfailed","31d73593":"#This unlinks any files from the path which can not be opened\nfailed.map(Path.unlink);","d3fd2883":"monkeys = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, # the data will be fetched using get_image_files method\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),# Randomsplitter will divide the data into 80% training and 20 % validation set\n    get_y=parent_label,# parent_label method will help to take output label which  will be taken as the name of parent folder of images  \n    item_tfms=Resize(128),# Resize image  \n    batch_tfms=[*aug_transforms(size=224, max_warp=0.), Normalize.from_stats(*imagenet_stats)]) #Augumentation and Normalization","7cc88660":"dls = monkeys.dataloaders(path)","2676ac1c":"len(dls.train_ds)\nprint(\"No of Training Images :\" + str(len(dls.train_ds)))\nprint(\"No of Validation Images :\" +str(len(dls.valid_ds)))","dd62fd98":"temp = dls.train_ds[0]\nprint(temp)","fd1ff4a1":"dls.train.show_batch(max_n=10, nrows=2)","2f32c39a":"dls.valid.show_batch(max_n=10, nrows=2)","26a86dc7":"learn = cnn_learner(dls, resnet50, metrics=[error_rate,accuracy])\n","5b31f903":"learn.fine_tune(4,base_lr=0.001) #- fine tune method can also used to fine tune the model","63c10494":"#cutmix = CutMix(1.)\n#learn.fit_one_cycle(4, cbs=cutmix)","52102c88":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","eb73b1a7":"interp.plot_top_losses(5, nrows=1)","93e538fd":"learn.export()","ce24128c":"path = Path()\npath.ls(file_exts='.pkl')","3dae5a1e":"learn_inf = load_learner(path\/'export.pkl')","d485c02a":"learn_inf.dls.vocab","3ee77f90":"predict = []\nactual = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/10-monkey-species\/validation\/validation\/'):\n    for filename in filenames:\n        actual.append(dirname[-2:])\n        predict.append(learn_inf.predict(os.path.join(dirname, filename))[0])\n       ","c8303d76":"print(\"no of entries for validation set\"+str(len(predict)))","a0445a26":"\n\nconfusion_matrix(actual, predict)","9f57821f":"\nprint(classification_report(actual, predict))\nprint(\"accuracy : \",accuracy_score(actual, predict))","07fec57a":"**Please Upvote and comment if you Like my work .**","4e97e3f9":"<a id=\"10\"><\/a> <br>\n# Predicting ValidationSet\n\n\nlets predict the validation set data and see our model performance on unseen data","e128e450":"<a id=\"6\"><\/a> <br>\n# Train\/Fine Tune model\n\nHere we are Fine Tuning the pretrained resnet model to classify our categories\n\nCutMix- In CutMix augmentation we cut and paste random patches between the training images. \nfit_one_cycle - it is used to fine tune the model per cycle\n","b30adaf7":"<a id=\"11\"><\/a> <br>\n# Analysing Validation Result\n\nUsing confusion matrix and classification report  lets check the performance","d5a2dee0":"<a id=\"8\"><\/a> <br>\n# Exporting Model\n\nWe can export the model if we want to create a webservice .using below code and save in file ","964521b2":"It looks this is good result where acurracy more than 98%  while fine tuning and 97.42 % accuaracy on un seen validation set. ","a8553eab":"<a id=\"7\"><\/a> <br>\n# Analysing Result  \n\nLets Analyse over result using confusion matrix","55d531fe":"<a id=\"1\"><\/a> <br>\n# Install Libraries\n\nfastbook  helps us to setup notebook with required fastai packages","fecf964d":"We can see that just two iteration and only using few data we are getting a good model with more than 98 % accuracy","cf215832":"Using this we can see Images which are not predicted correctly also . Also data cleanup can be done in case the image itself is faulty ,","a49b8548":"* Data Look pretty balanced \n* Also we can use Common name\/Latin Name of monkey in place of Label to represent our prediction","500b0e51":"the sum of the two set doesn't match with  training data mentioned in the text\n\n","1c92d16f":"It matches with the Validation data entries in text file","5d77f009":"Lets see how the data looks in this train and validation set","a82217c5":"<a id=\"3\"><\/a> <br>\n# Read Data\nSo Lets by start reading the images from the training folder \n\nPath - it is class from python to which we have passed the training path and create a path object.\n\nget_image_files- it is method from fastai which  get image files in `path` recursively, only in `folders`, if specified\n\nverify_images - it is method from fastai which Find images in `fns` that can't be opened\n","d92c7808":" <a id=\"5\"><\/a> <br>\n # Create Model\n \n we have used  cnn_learner to create model where we are passing over dataset , pretrained model resnet50 and the metrics to check the performance","16241c3a":"<a id=\"2\"><\/a> <br>\n# Import Libraries\n\nBelow we have imported some library required for the project\nwe can see to import fastai we have added * which can be seen as bad practice but as claimed by fastai team that they will import only the specific required thing we can use this .","aa10246f":"<a id=\"9\"><\/a> <br>\n# Import Model\n\nUsing below code we can import the model","0165213d":"**Data Loader**\n\nUsing the Datablock we will create a DataLoader which will hold all the data from the training folder with specific size augumentaion, ","f2e1d85c":"<a id=\"4\"><\/a> <br>\n# Create Datablock\n\nDatablock : Generic container to quickly build `Datasets` and `DataLoaders`\n\nImageBlock: As we are providing Input as Images\n\nCategoryBlock : As we are providing output as Category\n\nRandomSplitter: Use to split the dataset in train and test\n\nResize : Resize the data \n","d42b603d":"# Introduction\n\nThis notebook is in inspiration to the tutorial shared by Jeremy Howard on fastai\n\n[link](https:\/\/www.youtube.com\/watch?v=_QUEXsHfsA0&list=PLfYUBJiXbdtRL3FMB3GoWHRI8ieU6FhfM) \n\n* **FASTAI** :\n    fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. [Link](https:\/\/github.com\/fastai\/fastai)\n    \n    \n* **DataSet** : The dataset consists of two files, training and validation. Each folder contains 10 subforders labeled as n0~n9, each corresponding a species form Wikipedia's monkey cladogram. Images are 400x300 px or larger and JPEG format (almost 1400 images). Images were downloaded with help of the googliser open source code.\n\n\n* **Label mapping** :\n    1. n0, alouattapalliata \n    2. n1, erythrocebuspatas\n    3. n2, cacajaocalvus \n    4. n3, macacafuscata\n    5. n4, cebuellapygmea \n    6. n5, cebuscapucinus\n    7. n6, micoargentatus \n    8. n7, saimirisciureus\n    9. n8, aotusnigriceps \n    10. n9, trachypithecusjohnii    \n    \n**Content**\n* [Install Libraries](#1)\n* [Import Libraries](#2)\n* [Read Data](#3)\n* [Create Datablock](#4)\n* [Create Model](#5)\n* [Train\/Fine Tune model](#6)\n* [Analysing Result](#7)\n* [Exporting Model](#8)\n* [Import Model](#9)\n* [Predicting ValidationSet](#10)\n* [Analysing Validation Result](#11)","bd3d505d":"From this we can see as we have provided Image Block and CategoryBlock . we have tuple with PILImage and Category as TesorCategory","9eaaf271":"**Import Text Data File**"}}