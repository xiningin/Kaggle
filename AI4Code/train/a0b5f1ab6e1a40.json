{"cell_type":{"9f516c3a":"code","0d6917ec":"code","9ef6e3a9":"code","ecca97dc":"code","c7276518":"code","a4fb80a9":"code","c340a88c":"code","cf8ee78d":"code","a03e527d":"code","9ae273f1":"code","7f0b3069":"code","874e34f9":"code","7421756a":"code","c26abe94":"code","5f88b489":"code","451ef649":"code","dda33f56":"code","a0155d8f":"code","ced39af2":"code","fa0c004b":"code","ef957161":"code","7e76376c":"code","c3ddf9d1":"code","bf94d3bf":"code","cf1ab9c4":"code","ca377fab":"code","f7a15841":"code","57b47c14":"code","fda0d8f7":"markdown","82cc6b37":"markdown","42051048":"markdown","a6402d1d":"markdown","4956f8d2":"markdown"},"source":{"9f516c3a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nimport os\nfrom IPython.display import clear_output","0d6917ec":"CATEGORIES = os.listdir(\"\/kaggle\/input\/plant-seedlings-classification\/train\")\nCATEGORIES","9ef6e3a9":"X=[]\nY=[]\nIMG_S1,IMG_S2 = 140,140        #size of the image we will use...feel free to change it and observe model behaviour\ndef createTrainingData():\n    \"\"\"\n    To create training data from the dataset:\n        Steps performed by this function:\n            a. get the COLORED image\n            b. resize image to required size\n            c. convert the colours(this step does not affect the model)\n                >> cv2 reads image in the format BGR. we change the color format so that we can view the image with original colors.\n                >> Having different format won't change the performance of the model.\n                >> You can assume that we still have all the data just kinda shuffled if we dont convert it.\n            d. add image to the training set and its corresponding class\n            e. flip image upside down and mirror it -> add this image also to the training set with its label\n                >> This step is used to increase the amount of data we have,cosider a seedling flipped will still be a seedling.\n    \n    \"\"\"\n    a=0\n    pathh = \"\/kaggle\/input\/plant-seedlings-classification\/\"\n    types = [\"train\"]\n    for typ in types:\n        datadir = os.path.join(pathh,typ)\n        for ele in CATEGORIES:\n            PATH = os.path.join(datadir,ele)\n            class_num = CATEGORIES.index(ele)\n            for img in os.listdir(PATH):\n                image = os.path.join(PATH, img)\n                image = cv2.imread(image, cv2.IMREAD_ANYCOLOR)\n                image = cv2.resize(image , (IMG_S1, IMG_S2))\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                X.append(image)\n                X.append(cv2.flip(image,-1))\n                Y.append(class_num)\n                Y.append(class_num)\n                a+=1\n        clear_output()\n        print(a)\n        ","ecca97dc":"createTrainingData() #create the set","c7276518":"X = np.array(X)\/255.\nY = np.array(Y)\nX.shape","a4fb80a9":"def one_hottie(labels,C):\n    \"\"\"\n    One hot Encoding is used in multi-class classification problems to encode every label as a vector of binary values\n        eg. if there are 3 class as 0,1,2\n            one hot vector for class 0 could be : [1,0,0]\n                           then class 1: [0,1,0]\n                           and class 2: [0,0,1]\n    We need this encoding in out labels for the model learns to predict in a similar way.\n    \n    Without it,if only integer values are used in labels,it could affect model in different ways,\n        such as predicting a class that does not exist.\n        \n    \"\"\"\n    One_hot_matrix = tf.one_hot(labels,C)\n    return tf.keras.backend.eval(One_hot_matrix)\nY = one_hottie(Y, 12)\nprint (\"Y shape: \" + str(Y.shape))","c340a88c":"\nplt.imshow(X[7])","cf8ee78d":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 8)   #split the data in\ndel X\ndel Y","a03e527d":"# Implements the forward propagation for the model:\n# CONV2D -> Leaky RELU -> MAXPOOL -> CONV2D -> Leaky RELU -> MAXPOOL -> CONV2D -> Leaky RELU -> MAXPOOL -> CONV2D -> Leaky RELU -> MAXPOOL-> \n# -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n#SOME DROPout layers for regularization\n# Batch normalization helps compute faster\n# regularizers for regularization\n# Feel free to try different values\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(64, 1, activation=None,kernel_regularizer=tf.keras.regularizers.l2(0.1), input_shape=(140,140,3)),\n    tf.keras.layers.BatchNormalization(axis=3),\n    tf.keras.layers.LeakyReLU(0.1),\n    tf.keras.layers.MaxPool2D(strides=2),\n    \n    tf.keras.layers.Conv2D(128, 3, activation=None,padding=\"same\",kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n    tf.keras.layers.BatchNormalization(axis=3),\n    tf.keras.layers.LeakyReLU(0.1),\n    tf.keras.layers.MaxPool2D(strides=2),\n    \n    tf.keras.layers.Dropout(0.4),\n    \n    tf.keras.layers.Conv2D(256, 5, activation=None,kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n    tf.keras.layers.BatchNormalization(axis=3),\n    tf.keras.layers.LeakyReLU(0.1),\n    tf.keras.layers.MaxPool2D(strides=2),\n    \n    tf.keras.layers.Conv2D(64, 5, activation=None,padding=\"same\",kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n    tf.keras.layers.BatchNormalization(axis=3),\n    tf.keras.layers.LeakyReLU(0.1),\n    tf.keras.layers.MaxPool2D(strides=2),\n    \n    tf.keras.layers.Dropout(0.4),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(100,kernel_regularizer=tf.keras.regularizers.l2(0.01), activation=None),\n    tf.keras.layers.BatchNormalization(axis=1),\n    tf.keras.layers.ReLU(),\n    \n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(50,kernel_regularizer=tf.keras.regularizers.l2(0.01), activation=None),\n    tf.keras.layers.BatchNormalization(axis=1),\n    tf.keras.layers.ReLU(),\n    \n    tf.keras.layers.Dense(12, kernel_regularizer=tf.keras.regularizers.l2(0.01) ,activation='softmax')\n])\n","9ae273f1":"initial_learning_rate = 0.001 #initial rate\n# Rate decay with exponential decay\n# new rate = initial_learning_rate * decay_rate ^ (step \/ decay_steps)\n\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=800,\n    decay_rate=0.5,\n    staircase=True)","7f0b3069":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])","874e34f9":"Y_train.shape","7421756a":"result = model.fit(x=X_train,y=Y_train,batch_size=64,epochs=120,verbose=1,shuffle=False,initial_epoch=0,\n                   validation_split=0.2)","c26abe94":"result.history.keys()","5f88b489":"plt.plot(result.history['accuracy'], label='train')\nplt.plot(result.history['val_accuracy'], label='valid')\nplt.legend(loc='upper left')\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()\nplt.plot(result.history['loss'], label='train')\nplt.plot(result.history['val_loss'], label='test')\nplt.legend(loc='upper right')\nplt.title('Model Cost')\nplt.ylabel('Cost')\nplt.xlabel('Epoch')\nplt.show()","451ef649":"valid = model.evaluate(X_test,Y_test,verbose=2)","dda33f56":"Records = []","a0155d8f":"Records.append(valid)","ced39af2":"Records","fa0c004b":"X=[]\nfile = []\ndef createTestData():\n    a=0\n    pathh = \"\/kaggle\/input\/plant-seedlings-classification\/\"\n    types = [\"test\"]\n    for typ in types:\n        PATH = os.path.join(pathh,typ)\n        for img in os.listdir(PATH):\n            file.append(img)\n            image = os.path.join(PATH, img)\n            image = cv2.imread(image, cv2.IMREAD_ANYCOLOR)\n            image = cv2.resize(image , (IMG_S1, IMG_S2))\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            X.append(image)\n            a+=1\n    print(a)","ef957161":"createTestData()\nX = np.array(X)\/255. #normalize the data ","7e76376c":"file","c3ddf9d1":"X.shape","bf94d3bf":"species = model.predict_classes(X)\nprint(species.shape)\nprint(species)","cf1ab9c4":"ans = pd.DataFrame(file,columns = [\"file\"])","ca377fab":"ans = ans.join(pd.DataFrame(species,columns=[\"species\"]))\nans[\"species\"] = ans[\"species\"].apply(lambda x: CATEGORIES[int(x)])\nans.head(20)","f7a15841":"ans.to_csv(\"answers.csv\",index=False)","57b47c14":"model.save(\"saved_model\")","fda0d8f7":"**Output**","82cc6b37":"Check out some plots","42051048":"**Making Predictions**","a6402d1d":"**Evaluation on test set**","4956f8d2":"**First We create the data for the training**"}}