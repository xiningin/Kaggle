{"cell_type":{"12e05f44":"code","d27b9894":"code","ae0eb42d":"code","4ee32ee6":"code","ab795e64":"code","ab7ade90":"code","e6cc3709":"code","98e6abf1":"code","6505fa1e":"code","a24569dd":"code","e238e2e0":"code","6179ff36":"code","172151ae":"code","1a7849f6":"code","cf944668":"code","eac3d7ca":"code","9185b25b":"code","ccac9987":"code","fd9b3b09":"markdown","2df6d30d":"markdown"},"source":{"12e05f44":"import numpy as np, pandas as pd, os, gc\nimport matplotlib.pyplot as plt, time\nfrom PIL import Image \nimport warnings\nwarnings.filterwarnings(\"ignore\")\npath = '..\/input\/severstal-steel-defect-detection'\n\ntrain = pd.read_csv('..\/input\/steel-defect-detection\/Severstal Steel Defect Detection.csv')\n\n# RESTRUCTURE TRAIN DATAFRAME\ntrain2 = pd.DataFrame({'ImageId':train['ImageId'][::4]})\ntrain2['e1'] = train['EncodedPixels'][::4].values\ntrain2['e2'] = train['EncodedPixels'][1::4].values\ntrain2['e3'] = train['EncodedPixels'][2::4].values\ntrain2['e4'] = train['EncodedPixels'][3::4].values\ntrain2.reset_index(inplace=True,drop=True)\ntrain2.fillna('',inplace=True); \ntrain2['count'] = np.sum(train2.iloc[:,1:]!='',axis=1).values\ntrain2.head()","d27b9894":"# https:\/\/www.kaggle.com\/ateplyuk\/pytorch-starter-u-net-resnet\n# https:\/\/stanford.edu\/~shervine\/blog\/keras-how-to-generate-data-on-the-fly\nimport keras\n\nclass DataGenerator(keras.utils.Sequence):\n    def __init__(self, df, batch_size = 16, subset=\"train\", shuffle=False, \n                 info={}):\n        super().__init__()\n        self.df = df\n        self.shuffle = shuffle\n        self.subset = subset\n        self.batch_size = batch_size\n        #self.preprocess = preprocess\n        self.info = info\n        \n        if self.subset == \"train\":\n            self.data_path = '..\/input\/severstal-steel-defect-detection\/train_images\/'\n        elif self.subset == \"test\":\n            self.data_path = '..\/input\/severstal-steel-defect-detection\/test_images\/'\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.df) \/ self.batch_size))\n    \n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.df))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    def __getitem__(self, index): \n        X = np.empty((self.batch_size,128,800,3),dtype=np.float32)\n        y = np.empty((self.batch_size,128,800,4),dtype=np.int8)\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        for i,f in enumerate(self.df['ImageId'].iloc[indexes]):\n            self.info[index*self.batch_size+i]=f\n            X[i,] = Image.open(self.data_path + f).resize((800,128))\n            if self.subset == 'train': \n                for j in range(4):\n                    y[i,:,:,j] = rle2maskResize(self.df['e'+str(j+1)].iloc[indexes[i]])\n        #if self.preprocess!=None: X = self.preprocess(X)\n        if self.subset == 'train': return X, y\n        else: return X","ae0eb42d":"# https:\/\/www.kaggle.com\/titericz\/building-and-visualizing-masks\ndef rle2maskResize(rle):\n    # CONVERT RLE TO MASK \n    if (pd.isnull(rle))|(rle==''): \n        return np.zeros((128,800) ,dtype=np.uint8)\n    \n    height= 256\n    width = 1600\n    mask= np.zeros( width*height ,dtype=np.uint8)\n\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]-1\n    lengths = array[1::2]    \n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n    \n    return mask.reshape( (height,width), order='F' )[::2,::2]\n\ndef mask2contour(mask, width=3):\n    # CONVERT MASK TO ITS CONTOUR\n    w = mask.shape[1]\n    h = mask.shape[0]\n    mask2 = np.concatenate([mask[:,width:],np.zeros((h,width))],axis=1)\n    mask2 = np.logical_xor(mask,mask2)\n    mask3 = np.concatenate([mask[width:,:],np.zeros((width,w))],axis=0)\n    mask3 = np.logical_xor(mask,mask3)\n    return np.logical_or(mask2,mask3) \n\ndef mask2pad(mask, pad=2):\n    # ENLARGE MASK TO INCLUDE MORE SPACE AROUND DEFECT\n    w = mask.shape[1]\n    h = mask.shape[0]\n    \n    # MASK UP\n    for k in range(1,pad,2):\n        temp = np.concatenate([mask[k:,:],np.zeros((k,w))],axis=0)\n        mask = np.logical_or(mask,temp)\n    # MASK DOWN\n    for k in range(1,pad,2):\n        temp = np.concatenate([np.zeros((k,w)),mask[:-k,:]],axis=0)\n        mask = np.logical_or(mask,temp)\n    # MASK LEFT\n    for k in range(1,pad,2):\n        temp = np.concatenate([mask[:,k:],np.zeros((h,k))],axis=1)\n        mask = np.logical_or(mask,temp)\n    # MASK RIGHT\n    for k in range(1,pad,2):\n        temp = np.concatenate([np.zeros((h,k)),mask[:,:-k]],axis=1)\n        mask = np.logical_or(mask,temp)\n    \n    return mask ","4ee32ee6":"! pip install segmentation-models","ab795e64":"from keras import backend as K\n# https:\/\/www.kaggle.com\/xhlulu\/severstal-simple-keras-u-net-boilerplate\nfrom keras.losses import binary_crossentropy\nfrom segmentation_models.losses import bce_jaccard_loss\n# COMPETITION METRIC\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","ab7ade90":"import tensorflow as tf\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n\ndef iou_coef(y_true, y_pred, smooth=1):\n  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n  union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n  iou = K.mean((intersection + smooth) \/ (union + smooth), axis=0)\n  return iou\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(tf.cast(y_true, tf.float32), y_pred) + 0.5 * dice_loss(tf.cast(y_true, tf.float32), y_pred)","e6cc3709":"def recall(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    \n    recall = true_positives \/ (possible_positives + K.epsilon())\n    return recall\n\ndef precision(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    \n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    return precision\n\ndef f1(y_true, y_pred):\n    pre=precision(y_true, y_pred)\n    rec=recall(y_true, y_pred)\n    return 2 * ((pre * rec) \/ (pre + rec))","98e6abf1":"from segmentation_models import Unet\nfrom segmentation_models.utils import set_trainable\n\n\nmodel = Unet('efficientnetb0', input_shape=(128, 800, 3), classes=4, activation='sigmoid',encoder_weights='imagenet')\nmodel.compile(optimizer='adam', loss=binary_crossentropy, metrics=[dice_coef,iou_coef,'accuracy',precision,recall]) #bce_dice_loss binary_crossentropy\nmodel.summary()","6505fa1e":"# TRAIN AND VALIDATE MODEL\nidx = int(0.8*len(train2)); print()\ntrain_batches = DataGenerator(train2.iloc[:idx],shuffle=True)\nvalid_batches = DataGenerator(train2.iloc[idx:])","a24569dd":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n \ndef rle2mask(mask_rle, shape=(800,128)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T","e238e2e0":"\n# LOAD MODEL\nfrom keras.models import load_model\nmodel.load_weights('..\/input\/unetrasin-effb\/model.h5')\n","6179ff36":"filenames = {}\nval_set = train2.iloc[idx:];\n#defects = []\ndefects = list(val_set[val_set['e1']!=''].sample(0).index)\ndefects += list(val_set[val_set['e2']!=''].sample(0).index)\ndefects += list(val_set[val_set['e3']!=''].sample(7).index)\ndefects += list(val_set[val_set['e4']!=''].sample(9).index)\n\n","172151ae":"defects","1a7849f6":"#10884,","cf944668":"defects=[11993,11725,12352,11433,\n 12264,\n 11496,\n 12423,\n 10344,\n 12318,\n 10786,\n 11578,\n 10066,\n 11581,\n 10570,\n 11558,\n 11088]","eac3d7ca":"valid_batches = DataGenerator(val_set[val_set.index.isin(defects)])\nprint('Images and masks from our Data Generator')\nprint('KEY: yellow=defect1, green=defect2, blue=defect3, magenta=defect4')\n\n# DISPLAY IMAGES WITH DEFECTS\nfor i,batch in enumerate(valid_batches):\n    plt.figure(figsize=(14,50)) #20,18\n    for k in range(16):\n        plt.subplot(16,1,k+1)\n        img = batch[0][k,]\n        img = Image.fromarray(img.astype('uint8'))\n        img = np.array(img)\n        extra = '  has defect'\n        for j in range(4):\n            msk = batch[1][k,:,:,j]\n            msk = mask2pad(msk,pad=0)\n            msk = mask2contour(msk,width=0)\n            if np.sum(msk)!=0: extra += ' '+str(j+1)\n            if j==0: # yellow\n                img[msk==1,0] = 235 \n                img[msk==1,1] = 235\n            elif j==1: img[msk==1,1] = 210 # green\n            elif j==2: img[msk==1,2] = 255 # blue\n            elif j==3: # magenta\n                img[msk==1,0] = 255\n                img[msk==1,2] = 255\n        #plt.title(filenames[16*i+k]+extra)\n        plt.axis('off') \n        plt.imshow(img)\n    plt.subplots_adjust(wspace=0.05)\n    plt.show()","9185b25b":"train2.iloc[defects]","ccac9987":"# PLOT PREDICTIONS\n#valid_batches = DataGenerator(val_set[val_set.index.isin(defects)])\npreds = model.predict_generator(valid_batches,verbose=1)\n\nprint('Plotting predictions...')\nprint('KEY: yellow=defect1, green=defect2, blue=defect3, magenta=defect4')\n\nfor i,batch in enumerate(valid_batches):\n    plt.figure(figsize=(20,36))\n    for k in range(16):\n        plt.subplot(16,2,2*k+1)\n        img = batch[0][k,]\n        img = Image.fromarray(img.astype('uint8'))\n        img = np.array(img)\n        dft = 0\n        extra = '  has defect '\n        for j in range(4):\n            msk = batch[1][k,:,:,j]\n            if np.sum(msk)!=0: \n                dft=j+1\n                extra += ' '+str(j+1)\n            msk = mask2pad(msk,pad=0)\n            msk = mask2contour(msk,width=2)\n            if j==0: # yellow\n                img[msk==1,0] = 235 \n                img[msk==1,1] = 235\n            elif j==1: img[msk==1,1] = 210 # green\n            elif j==2: img[msk==1,2] = 255 # blue\n            elif j==3: # magenta\n                img[msk==1,0] = 255\n                img[msk==1,2] = 255\n        if extra=='  has defect ': extra =''\n        plt.title('Train '+train2.iloc[i+k,0]+extra)\n        plt.axis('off') \n        plt.imshow(img)\n        plt.subplot(16,2,2*k+2) \n        if dft!=0:\n            msk = preds[16*i+k,:,:,dft-1]\n            plt.imshow(msk)\n        else:\n            plt.imshow(np.zeros((256,1600)))#ss\n        plt.axis('off')\n        mx = np.round(np.max(msk),3)\n        plt.title('Predict Defect '+str(dft)+'  (max pixel = '+str(mx)+')')\n    plt.subplots_adjust(wspace=0.05)\n    plt.show()","fd9b3b09":"# Utility Functions\nNext we'll need some utility functions. The first converts rle to mask. The second converts a mask to its contour. The third enlarges a mask. The second and third together put blank space between defect and mask contour for better visualization.","2df6d30d":"# Train EDA\nLet's confirm our Data Generator works and view some training images. We will only show examples with defects. Note that all mask contours are plotted with a little blank space around the defect to aid visualization. Below we show examples of each type but note that in the training set only 7.1%, 2.0%, 41.0%, 6.4% of images have defects 1, 2, 3, 4 respectively."}}