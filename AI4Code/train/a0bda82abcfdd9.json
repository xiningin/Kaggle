{"cell_type":{"af3e0d78":"code","e632939e":"code","ade1bd0c":"code","ecd0919c":"code","7e4126ef":"code","dc252d7a":"code","864e400e":"code","0b6bae73":"code","3222642f":"code","35418580":"code","175e3817":"code","f56408cf":"code","38e94bc0":"code","5afa01fc":"code","7a70f48b":"code","0f3fe355":"code","4381752e":"code","47f1d851":"code","2c00c595":"code","862ea016":"code","51fc7d90":"code","5eb630da":"code","0c218975":"code","3e5fc029":"code","c70d19bf":"code","5b60b82d":"code","d81b8a35":"code","c9c50258":"code","90cd498b":"code","f2a8a192":"code","e983c86a":"code","e8a926ff":"code","10f99ca2":"code","4059c084":"markdown","09a3a285":"markdown","3db7b415":"markdown","133fe5d1":"markdown","325bbb4f":"markdown","aa4f1b0c":"markdown","da0f02d9":"markdown","d084725d":"markdown","13ed0f9e":"markdown","def971b3":"markdown","9f417878":"markdown","e9159493":"markdown","e229f01c":"markdown","072140ad":"markdown","072024c9":"markdown","436cfc9d":"markdown","5c70cbc0":"markdown","df9fdf6f":"markdown"},"source":{"af3e0d78":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e632939e":"# Importation of more libraries for formatting and visualizations\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")","ade1bd0c":"bank_data = pd.read_csv('\/kaggle\/input\/customer-segmentation\/customer_segmentation.csv')","ecd0919c":"bank_data.shape","7e4126ef":"bank_data.head()","dc252d7a":"#lets drop the unnamed column from the data since it's not informative and it's very similar to the customer Id\nbank_data.drop('Unnamed: 0', inplace = True,axis=1)","864e400e":"bank_data.head()","0b6bae73":"#detailed check on the data \nbank_data.info()","3222642f":"#brief summary on the numerical attributes\nbank_data.describe()","35418580":"#Lets fill in the missing values in the defaulted column with the median\nbank_data['Defaulted'] = bank_data.Defaulted.fillna(value=bank_data.Defaulted.median)","175e3817":"#code shows no more missing values.\nbank_data.Defaulted.isnull().any()","f56408cf":"num_features =['Age','Edu','Years Employed','Income','Card Debt','DebtIncomeRatio']","38e94bc0":"num_data = bank_data[num_features]","5afa01fc":"# Plotting histograms plots for the variables\nnum_data.hist(bins=30, color = 'blue',figsize=(12,12))\nplt.show()","7a70f48b":"# Plotting Histogram  for the Other debt variable\nbank_data['Other Debt'].hist(bins=30, color = 'blue',figsize=(6,4))\nplt.show()","0f3fe355":"#feature engineering \n#lets create a new feature Total_Debt from Card Debt and Other Debt\nbank_data['Total_Debt'] = bank_data['Card Debt'] + bank_data['Other Debt']","4381752e":"#snap shot of the data\nbank_data.head()","47f1d851":"bank_data.skew()","2c00c595":"bank_data['Total_Debt_log'] = np.log(bank_data['Total_Debt'])\nbank_data['Income_log'] = np.log(bank_data['Income'])\nbank_data['Age_log'] = np.log(bank_data['Age'])","862ea016":"#snapshot of the new dataset.\nbank_data.head(2)","51fc7d90":"cluster_cols = ['Age_log','Total_Debt_log','Income_log']\ncluster_data = bank_data[cluster_cols]","5eb630da":"#standizing our data to create  mean centered version of our dataset\nfrom sklearn import preprocessing\nscaler = preprocessing.StandardScaler()\ncluster_scaled = scaler.fit_transform(cluster_data)","0c218975":"#Cluster generation\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nimport matplotlib.cm as cm\n\nX = cluster_scaled\n\ncluster_centers = dict()\n\nfor n_clusters_K in range(3,5):\n    fig, ax1 = plt.subplots(figsize=(8,5))\n    \n    ax1.set_xlim([-0.1, 1])\n    ax1.set_ylim([0, len(X) + (n_clusters_K + 1) * 10])\n\n    cluster_obj = KMeans(n_clusters=n_clusters_K, random_state=10)\n    cluster_labels = cluster_obj.fit_predict(X)\n\n    silhouette_avg = silhouette_score(X, cluster_labels)\n    cluster_centers.update({n_clusters_K :{\n                                        'cluster_center':cluster_obj.cluster_centers_,\n                                        'silhouette_score':silhouette_avg,\n                                        'labels':cluster_labels}\n                           })\n\n    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n    y_lower = 10\n    for i in range(n_clusters_K):\n        ith_cluster_silhouette_values = \\\n            sample_silhouette_values[cluster_labels == i]\n\n        ith_cluster_silhouette_values.sort()\n\n        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n        y_upper = y_lower + size_cluster_i\n        \n        color = cm.nipy_spectral(float(i) \/ n_clusters_K)\n        \n        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n                          0, ith_cluster_silhouette_values,\n                          facecolor=color, edgecolor=color, alpha=0.7)\n\n        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n        y_lower = y_upper + 10  # 10 for the 0 samples\n\n    ax1.set_title(\"The silhouette plot for the various cluster values of K.\")\n    ax1.set_xlabel(\"The silhouette coefficient values\")\n    ax1.set_ylabel(\"Cluster label\")\n    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n    ax1.set_yticks([])\n    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n    \n    plt.show()\n        ","3e5fc029":"#recomputing cluster lables with various values of clusters_k\nValues_of_K = range(3,15)\nresults =[]\nfor k in Values_of_K:\n    cluster_obj2 = KMeans(n_clusters=k, random_state=1)\n    cluster_labels2 = cluster_obj2.fit_predict(X)\n    silhouette_avg2 = silhouette_score(X, cluster_labels2)\n    results.append([k,silhouette_avg2])\n\nresult = pd.DataFrame(results, columns=[\"n_clusters_K\", \"silhouette_score\"])","c70d19bf":"result.head(10)","5b60b82d":"plt.figure(figsize = (10,8))\nplt.plot(result.n_clusters_K,result.silhouette_score,marker = 'o')\nplt.title('Plot that shows the variation of silhouette_score with various values of k')\nplt.xlabel('Values of Clusters K')\nplt.ylabel('Values of silhouette_score')","d81b8a35":"for i in range(3,5):\n    print(f\"for a {i} numbered  cluster\")\n    original_data = scaler.inverse_transform(cluster_centers[i]['cluster_center'])\n    print(pd.DataFrame(np.exp(original_data),columns = cluster_cols))\n    print(\"Silhouette score for cluster {} is {:.3f}\".format(i,cluster_centers[i]['silhouette_score']))\n    print()","c9c50258":"#Lets Assign Cluster labels to the clusters\nlabels = cluster_centers[3]['labels']   \ncluster_data['3cluster_labels'] = labels\nlabels = cluster_centers[4]['labels']\ncluster_data['4cluster_labels'] = labels","90cd498b":"cluster_data.head()","f2a8a192":"import plotly as py\nimport plotly.io as pio\npio.renderers.default='notebook'\nimport plotly.graph_objs as go\npy.offline.init_notebook_mode()\n\nx_data = ['Cluster 1','Cluster 2','Cluster 3']\ncutoff_quantile = 70 # Used to avoid extrem outliers that may interfere in making of good observations due to noise\nfield_to_plot = 'Age_log'\n\ny0 = cluster_data[cluster_data['3cluster_labels']==0][field_to_plot].values\ny0 = y0[y0<np.percentile(y0, cutoff_quantile)]\ny1 = cluster_data[cluster_data['3cluster_labels']==1][field_to_plot].values\ny1 = y1[y1<np.percentile(y1, cutoff_quantile)]\ny2 = cluster_data[cluster_data['3cluster_labels']==2][field_to_plot].values\ny2 = y2[y2<np.percentile(y2, cutoff_quantile)]\n\ny_data = [y0,y1,y2]\n\ncolors = ['red','blue','green']\ntraces = []\n\nfor xd, yd, cls in zip(x_data, y_data, colors):\n        traces.append(go.Box(\n            y=yd,\n            name=xd,\n            boxpoints=False,\n            jitter=0.5,\n            whiskerwidth=0.2,\n            fillcolor=cls,\n            marker=dict(\n                size=2,\n            ),\n            line=dict(width=1),\n        ))\n\nlayout = go.Layout(\n    title=(f'Difference in {field_to_plot} from cluster to cluster'),\n    yaxis=dict(\n        autorange=True,\n        showgrid=True,\n        zeroline=True,\n        dtick=50,\n        gridcolor='black',\n        gridwidth=0.1,\n        zerolinecolor='rgb(255, 255, 255)',\n        zerolinewidth=2,\n    ),\n    margin=dict(\n        l=40,\n        r=30,\n        b=80,\n        t=100,\n    ),\n    paper_bgcolor='white',\n    plot_bgcolor='white',\n    showlegend=False\n)\nfig = go.Figure(data=traces, layout=layout)\npy.offline.iplot(fig)","e983c86a":"import plotly as py\nimport plotly.io as pio\npio.renderers.default='notebook'\nimport plotly.graph_objs as go\npy.offline.init_notebook_mode()\n\nx_data = ['Cluster 1','Cluster 2','Cluster 3']\ncutoff_quantile = 70 # Used to avoid extrem outliers that may interfere in making of good observations due to noise\nfield_to_plot = 'Total_Debt_log'\n\ny0 = cluster_data[cluster_data['3cluster_labels']==0][field_to_plot].values\ny0 = y0[y0<np.percentile(y0, cutoff_quantile)]\ny1 = cluster_data[cluster_data['3cluster_labels']==1][field_to_plot].values\ny1 = y1[y1<np.percentile(y1, cutoff_quantile)]\ny2 = cluster_data[cluster_data['3cluster_labels']==2][field_to_plot].values\ny2 = y2[y2<np.percentile(y2, cutoff_quantile)]\n\ny_data = [y0,y1,y2]\n\ncolors = ['red','blue','green']\ntraces = []\n\nfor xd, yd, cls in zip(x_data, y_data, colors):\n        traces.append(go.Box(\n            y=yd,\n            name=xd,\n            boxpoints=False,\n            jitter=0.5,\n            whiskerwidth=0.2,\n            fillcolor=cls,\n            marker=dict(\n                size=2,\n            ),\n            line=dict(width=1),\n        ))\n\nlayout = go.Layout(\n    title=(f'Difference in {field_to_plot} from cluster to cluster'),\n    yaxis=dict(\n        autorange=True,\n        showgrid=True,\n        zeroline=True,\n        dtick=50,\n        gridcolor='black',\n        gridwidth=0.1,\n        zerolinecolor='rgb(255, 255, 255)',\n        zerolinewidth=2,\n    ),\n    margin=dict(\n        l=40,\n        r=30,\n        b=80,\n        t=100,\n    ),\n    paper_bgcolor='white',\n    plot_bgcolor='white',\n    showlegend=False\n)\nfig = go.Figure(data=traces, layout=layout)\npy.offline.iplot(fig)","e8a926ff":"import plotly as py\nimport plotly.io as pio\npio.renderers.default='notebook'\nimport plotly.graph_objs as go\npy.offline.init_notebook_mode()\n\nx_data = ['Cluster 1','Cluster 2','Cluster 3','Cluster 4']\ncutoff_quantile = 70 # Used to avoid extrem outliers that may interfere in making of good observations due to noise\nfield_to_plot = 'Age_log'\n\ny0 = cluster_data[cluster_data['4cluster_labels']==0][field_to_plot].values\ny0 = y0[y0<np.percentile(y0, cutoff_quantile)]\ny1 = cluster_data[cluster_data['4cluster_labels']==1][field_to_plot].values\ny1 = y1[y1<np.percentile(y1, cutoff_quantile)]\ny2 = cluster_data[cluster_data['4cluster_labels']==2][field_to_plot].values\ny2 = y2[y2<np.percentile(y2, cutoff_quantile)]\ny3 = cluster_data[cluster_data['4cluster_labels']==3][field_to_plot].values\ny3 = y3[y3<np.percentile(y3, cutoff_quantile)]\n\ny_data = [y0,y1,y2,y3]\n\ncolors = ['red','blue','green','cyan']\ntraces = []\n\nfor xd, yd, cls in zip(x_data, y_data, colors):\n        traces.append(go.Box(\n            y=yd,\n            name=xd,\n            boxpoints=False,\n            jitter=0.5,\n            whiskerwidth=0.2,\n            fillcolor=cls,\n            marker=dict(\n                size=2,\n            ),\n            line=dict(width=1),\n        ))\n\nlayout = go.Layout(\n    title=(f'Difference in {field_to_plot} from cluster to cluster'),\n    yaxis=dict(\n        autorange=True,\n        showgrid=True,\n        zeroline=True,\n        dtick=50,\n        gridcolor='black',\n        gridwidth=0.1,\n        zerolinecolor='rgb(255, 255, 255)',\n        zerolinewidth=2,\n    ),\n    margin=dict(\n        l=40,\n        r=30,\n        b=80,\n        t=100,\n    ),\n    paper_bgcolor='white',\n    plot_bgcolor='white',\n    showlegend=False\n)\nfig = go.Figure(data=traces, layout=layout)\npy.offline.iplot(fig)\n","10f99ca2":"import plotly as py\nimport plotly.io as pio\npio.renderers.default='notebook'\nimport plotly.graph_objs as go\npy.offline.init_notebook_mode()\n\n\nx_data = ['Cluster 1','Cluster 2','Cluster 3','Cluster 4']\ncutoff_quantile = 70 # Used to avoid extrem outliers that may interfere in making of good observations due to noise\nfield_to_plot = 'Total_Debt_log'\n\ny0 = cluster_data[cluster_data['4cluster_labels']==0][field_to_plot].values\ny0 = y0[y0<np.percentile(y0, cutoff_quantile)]\ny1 = cluster_data[cluster_data['4cluster_labels']==1][field_to_plot].values\ny1 = y1[y1<np.percentile(y1, cutoff_quantile)]\ny2 = cluster_data[cluster_data['4cluster_labels']==2][field_to_plot].values\ny2 = y2[y2<np.percentile(y2, cutoff_quantile)]\ny3 = cluster_data[cluster_data['4cluster_labels']==3][field_to_plot].values\ny3 = y3[y3<np.percentile(y3, cutoff_quantile)]\n\ny_data = [y0,y1,y2,y3]\n\ncolors = ['red','blue','green','cyan']\ntraces = []\n\nfor xd, yd, cls in zip(x_data, y_data, colors):\n        traces.append(go.Box(\n            y=yd,\n            name=xd,\n            boxpoints=False,\n            jitter=0.5,\n            whiskerwidth=0.2,\n            fillcolor=cls,\n            marker=dict(\n                size=2,\n            ),\n            line=dict(width=1),\n        ))\n\nlayout = go.Layout(\n    title=(f'Difference in {field_to_plot} from cluster to cluster'),\n    yaxis=dict(\n        autorange=True,\n        showgrid=True,\n        zeroline=True,\n        dtick=50,\n        gridcolor='black',\n        gridwidth=0.1,\n        zerolinecolor='rgb(255, 255, 255)',\n        zerolinewidth=2,\n    ),\n    margin=dict(\n        l=40,\n        r=30,\n        b=80,\n        t=100,\n    ),\n    paper_bgcolor='white',\n    plot_bgcolor='white',\n    showlegend=False\n)\nfig = go.Figure(data=traces, layout=layout)\npy.offline.iplot(fig)\n","4059c084":"**From the snapshot of the data above, we can see that there are some missing values in the defaulted column. we can also note that we only have numerical variables**","09a3a285":"**When we look at the results of the clustering process, we can infer some insights**\n\n**Lets consider the 3 cluster segment**\n\n**We can see 3 clusters with a  noticable difference in age groups of cluster 0 and 2 while  slight difference in age group between cluster 0 and 1**\n\n**Generally older people tend to have a higher total debt probably because of high income that they have and the reverse is true with the younger population**\n\n**We can also see the same trend being replicated in 4 clustered configuration.**","3db7b415":"**EXPLORATORY DATA ANALYSIS.**","133fe5d1":"**As seen previously cluster 1 and 4 have  the highest average age hence having clients w earning the most income as well has having the most total debt.\nThe difference in other clusters is minimum though follows the same trend**","325bbb4f":"**Content**\n\n**Customer segmentation is one of those important aspects that a business has to carefully consider before formulating products or services to it's customer base Pitching the right message to the right customer and at the right time has been the objective for all banks.Banks look at customer segmentation to gain insight, on how to decide on specific offers, improve customer service, and understand customer behaviour & more. The success or failure of a marketing campaign depends on how customers are segmented. Based on the customer segmentation, banks unleash product recommendations like saving plans, loans, wealth management, etc. on target customer groups.**\n\n**OBJECTIVE:** \n**To segment and analyze bank customers using Kmeans model so as to understand the kind of clients a bank has which can then be used in developing profitable products that can generate more revenue to the bank.\nThis is a small sample Dataset that summarizes the usage behavior of about nearly 1000 active credit card holders during the last 6 months.\nThe Unit for the income is in thausands of dollars.**","aa4f1b0c":"**From the code above, we can see some columns which are more skewed than others. we are going to reduce skewness in the Total debt, income  and Age  columns since they are the features that we are going to use for clustering . **","da0f02d9":"**Plot above shows that the other debt variable is skewed to the right.we will remove the skewness from the variable before clustering.**","d084725d":"**CLUSTER GENERATION**","13ed0f9e":"**Our goal is to Segment our customers into favourable clusters\nWe are going to make use of  variables; Age, Income and Total Debt\nWe shall make use of the Kmeans clustering model to perform the segmentation.\nFor better performance of the model,we shall need to scale and standardize the data of the columns of  interest**","def971b3":"**As seen previously, cluster 1 and 3 have the highest median Total debt which must be corresponding to those more older clients with a higher income range in thousands of dollars. Median Total debt of clusters 2 and 4 are similar which could be merged to one cluster.**","9f417878":"**One of the noticable columns is one for income, there is some bit of skewness in this column. we shall need to address this at some point.We can see that the dataset is mostly made up of medium aged young people of average age about 35 years.**","e9159493":"**As seen previously cluster 2 and 3 have  the highest average age hence having clients w earning the most income as well has having the most total debt.\nThe difference in other clusters is minimum though follows the same trend**","e229f01c":"**From the look at the histograms, there are some columns that are skewed.**","072140ad":"**CLUSTER ANALYSIS**","072024c9":"**Our segmentation is going to majorly focus on some numerical variables of our interest.\nLets perform some data visualization for some  numerical variables of interest**","436cfc9d":"**From the silhouette plots above, we can see that the 3 clustered segments has the highest  silhouette_score than the 4 clustered segments \nas seen in the visualizations above, Secondly the 3 clustered segments generaly do not have overlaps between it's clusters unlike those of cluster 4 which have overlaps between it's segments. Therefore we will consider the three clustered segment.**","5c70cbc0":"All feedback is welcome. you can also upvote this notebook. cheers.","df9fdf6f":"**DATA CLEANING,FORMATTING AND INSPECTION**"}}