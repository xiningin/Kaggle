{"cell_type":{"8dcf3706":"code","37591f08":"code","4c8d4e37":"code","df03f7e8":"code","97d2351c":"code","bd599b56":"code","0ebd3dd3":"code","3be6b990":"code","af355279":"code","7c244763":"code","e178d442":"code","e33f979e":"code","ee712597":"code","76b0e632":"code","3ed67668":"code","d98ca94e":"code","526c0ef8":"code","4a88362a":"code","22924770":"code","115a3a71":"code","cfdf426c":"code","15f2a179":"markdown","9de4668e":"markdown","1de1d184":"markdown","48cea86c":"markdown","048fbc5b":"markdown","b6ced963":"markdown","d08ff622":"markdown","b6ce8555":"markdown","b306f4d8":"markdown","5c54d7ea":"markdown","75780347":"markdown","3f36f57e":"markdown","2aab93c1":"markdown","27ad1348":"markdown","d48e56a2":"markdown"},"source":{"8dcf3706":"#Author : Jun \n#Date: 17\/02\/2020\nimport pandas as pd \nfrom sklearn.model_selection import train_test_split \nfrom sklearn import metrics\nfrom sklearn import tree\nimport matplotlib.pyplot as plt \nfrom sklearn.cluster import KMeans\nimport seaborn as sns","37591f08":"survey = pd.read_csv(\"..\/input\/developer-survey-2020\/survey_results_public.csv\")  # read data\nsurvey.info() # data information","4c8d4e37":"countries = survey['Country'].value_counts()\ncountries.head(5)","df03f7e8":"import plotly.graph_objects as go\nfig = go.Figure(data=go.Choropleth(\n    locations = countries.index, \n    z = countries,\n    locationmode = 'country names', \n    colorscale = 'Reds',    \n))\nfig.show()","97d2351c":"columns = ['EdLevel','Country','ConvertedComp'] # use two features. ConvertedComp is the target variable: salary\ndf = pd.DataFrame(survey, columns=columns) \ndf.head(10)","bd599b56":"df['EdLevel'].value_counts().plot(kind = 'pie', title = 'Education Level', autopct='%1.1f%%') # EDA ","0ebd3dd3":"# bad EDA. How to improve it?\ndf['Country'].value_counts().plot(kind = 'pie', title = 'Country', autopct='%1.1f%%') ","3be6b990":"df.dropna(inplace=True) # drop all NaN values. Improvement: handle missing values\ndf.head(10)","af355279":"df['EdLevel']  = df['EdLevel'].astype(str) #shorten description\ndf['EdLevel'] = df['EdLevel'].apply(lambda x: x[0:4])","7c244763":"grouped = df.groupby('EdLevel')   #EDA\ngrouped['ConvertedComp'].median().plot.barh();","e178d442":"salary_median = df['ConvertedComp'].median() #create the target variable y\ny = df['ConvertedComp'].apply(lambda x:0 if x <= salary_median else 1) #1 for high, 0 for low\ndf['Income'] = y # income is a categorical variable\ndf.head(10)","e33f979e":"columns = ['EdLevel','Country'] #create the feature set X\nX = pd.DataFrame(df, columns=columns) \nX.head(5)","ee712597":"X = pd.get_dummies(X) #Improvement: OneHot encoding for nominal data. Ordinal encoder for ordinal data\nX.head(10)","76b0e632":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) #split data into training and test data. Improvement: usually need validation data for hyperparameter tuning","3ed67668":"dt = tree.DecisionTreeClassifier(criterion='entropy', max_depth = 10, random_state=1) #decision tree for classification\ndt = dt.fit(X_train, y_train)\ny_pred = dt.predict(X_test)\nprint (\"Accuracy: {0:.3f}\".format(metrics.accuracy_score(y_test, y_pred)),\"\\n\") #print accuracy\n","d98ca94e":"grouped = df.groupby('Income')  #group data into low and high incomes\ndf2 = pd.DataFrame(grouped.get_group(0), columns=df.columns) # 0 for low income\ndf2.head(5)","526c0ef8":"X2 = df2.drop(['ConvertedComp','Income'], axis=1)\nX2 = pd.get_dummies(X2) #OneHot Encoding. Improvement: Edlevel belongs to ordinal data\nkm = KMeans(n_clusters=2) # 2 clusters for low income group \ny2 = km.fit_predict(X2) # labels of sample","4a88362a":"df2['Cluster']=y2\nchurn_crosstab = pd.crosstab(df2['Cluster'],df2[\"EdLevel\"],  normalize=True)\nchurn_crosstab.plot(kind = 'bar', grid=True) \nplt.show() ","22924770":"# bad EDA. How to improve it?\nchurn_crosstab = pd.crosstab(df2['Cluster'],df2['Country'],  normalize=True)\nchurn_crosstab.plot(kind = 'bar', grid=True) \nplt.show() ","115a3a71":"def select_countries(x):\n    if x ==\"United States\":\n        x = \"USA\"\n    elif x == \"United Kingdom\":\n        x = \"UK\" \n    elif x == \"India\":\n        x = \"India\" \n    elif x == \"Germany\":\n        x = \"Germany\" \n    else:\n        x = \"Others\"\n    return x\n    \ndf2['Country']  = df2['Country'].astype(str)\ndf2['Country'] = df2['Country'].apply(lambda x: select_countries(x))\ndf2.head(5)","cfdf426c":"churn_crosstab = pd.crosstab(df2['Cluster'],df2['Country'],  normalize=True)\nchurn_crosstab.plot(kind = 'bar', grid=True) \nplt.show() ","15f2a179":"create target class","9de4668e":"handle missing values","1de1d184":"EDA for cluster results","48cea86c":"load data","048fbc5b":"encode","b6ced963":"selec two features","d08ff622":"This demo notebook aims to help analyze data of Stack Overflow Developer Survey 2020.","b6ce8555":"EDA","b306f4d8":"create features","5c54d7ea":"EDA","75780347":"create decision tree","3f36f57e":"* Cluster analysis of low income class and EDA with crosstab in Lecture 04","2aab93c1":"split into training and test data","27ad1348":"respondents in each country","d48e56a2":"* cluster 1: bach degree; more India developers\n* cluster 0: other degree; more other countries"}}