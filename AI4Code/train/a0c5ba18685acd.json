{"cell_type":{"50121e76":"code","4a801670":"code","570763fe":"code","e37b61ce":"code","92bb8ab8":"code","420dcf33":"code","0709b236":"code","9882a80c":"code","7cfc95b7":"code","c139c15d":"code","c5ab877e":"code","9152d112":"code","57e1d184":"code","42127e96":"code","8f0020a8":"code","c088ac7b":"code","61d71886":"code","ece48033":"code","d59cbb9b":"code","a9d91f2a":"code","bcd30205":"code","45117ac7":"code","482c01b1":"code","35acead6":"code","15b39f7e":"code","41a71f79":"code","87a67b0b":"code","5b560fd5":"code","334625e9":"code","4095bc56":"code","30ef867b":"code","4dc4bbf8":"code","3b24364c":"code","ba252d64":"code","65e33bd6":"code","8031f8ec":"code","835bbc45":"code","3a2f1749":"code","bd989017":"code","548ec225":"code","0c62b978":"code","8f7f62b3":"code","68815cdf":"code","c417fc5f":"code","2741e73f":"code","3461196e":"code","789aac3a":"code","5b93ec37":"code","e6d8ad7c":"markdown","ec52acaf":"markdown"},"source":{"50121e76":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport os","4a801670":"from matplotlib.image import imread","570763fe":"pwd","e37b61ce":"my_data_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/'","92bb8ab8":"os.listdir(my_data_dir)","420dcf33":"train_path = my_data_dir + \"train\"\ntest_path = my_data_dir + \"test\"\nval_path = my_data_dir + \"val\"","0709b236":"os.listdir(train_path)","9882a80c":"os.listdir(test_path)","7cfc95b7":"os.listdir(val_path)","c139c15d":"##os.listdir(train_path+\"NORMAL\")[0]","c5ab877e":"#norm_1 = imread(train_path+\"\\\\NORMAL\"+\"\\\\IM-0115-0001.jpeg\")","9152d112":"#plt.imshow(norm_1,cmap='gray')","57e1d184":"#os.listdir(train_path+\"\\\\PNEUMONIA\")[0]","42127e96":"#pne_1 = imread(train_path+\"\\\\PNEUMONIA\"+'\\\\person1000_bacteria_2931.jpeg')","8f0020a8":"#plt.imshow(pne_1,cmap='gray')","c088ac7b":"#norm_1.shape","61d71886":"#pne_1.shape","ece48033":"#type(pne_1)","d59cbb9b":"img_shape = (150,150,3)","a9d91f2a":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","bcd30205":"image_gen = ImageDataGenerator(rotation_range=20, width_shift_range=0.10, height_shift_range=0.10, \n                               rescale=1\/255, shear_range=0.1, zoom_range=0.1, horizontal_flip=True, fill_mode='nearest' )","45117ac7":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D","482c01b1":"model = Sequential()\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=img_shape, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=img_shape, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=img_shape, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128,activation='relu'))\n\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","35acead6":"model.summary()","15b39f7e":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = EarlyStopping(monitor='val_loss',patience=20,restore_best_weights=True)","41a71f79":"batch_size = 16","87a67b0b":"train_image_gen = image_gen.flow_from_directory(train_path,target_size=img_shape[:2],color_mode='rgb', batch_size=batch_size,\n                                               class_mode='binary', shuffle=True)","5b560fd5":"val_image_gen = image_gen.flow_from_directory(val_path,target_size=img_shape[:2],color_mode='rgb',batch_size=batch_size,\n                                               class_mode='binary',shuffle=False)","334625e9":"test_image_gen = image_gen.flow_from_directory(test_path,target_size=img_shape[:2],batch_size=batch_size,\n                                               class_mode='binary',shuffle=False)","4095bc56":"train_image_gen.class_indices","30ef867b":"results = model.fit_generator(train_image_gen,epochs=100, validation_data=val_image_gen,callbacks=[early_stop])","4dc4bbf8":"model.save('cxr_model_3.h5')","3b24364c":"model_df = pd.DataFrame(model.history.history)","ba252d64":"model_df","65e33bd6":"cnn_pred = model.predict_generator(test_image_gen)","8031f8ec":"#cnn_pred","835bbc45":"predictions = cnn_pred > 0.5 ","3a2f1749":"from sklearn.metrics import confusion_matrix,classification_report, accuracy_score","bd989017":"print(classification_report(test_image_gen.classes , predictions))","548ec225":"print(confusion_matrix(test_image_gen.classes,predictions))","0c62b978":"x = np.arange(0,1,0.01)","8f7f62b3":"d = []\nfor i in x:\n    prediction = cnn_pred > i\n    d.append(accuracy_score(test_image_gen.classes,prediction))","68815cdf":"the_df = pd.DataFrame({'threshold':list(x) , 'accuracy': d})","c417fc5f":"the_df[the_df['accuracy']==the_df['accuracy'].max()]","2741e73f":"threshold = 0.94","3461196e":"prediction = cnn_pred > threshold","789aac3a":"print(confusion_matrix(test_image_gen.classes,predictions))\nprint('\\n')\nprint(classification_report(test_image_gen.classes,predictions))","5b93ec37":"x = accuracy_score(test_image_gen.classes,predictions)\nprint(f\"the accuracy is on test dataset is {x}\")","e6d8ad7c":"# hence the threshold should be 0.94","ec52acaf":"# Reducing target image shape to smaller value to save time and memory while training the model. "}}