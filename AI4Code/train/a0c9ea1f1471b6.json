{"cell_type":{"d2c6182d":"code","43b949b0":"code","00ac359f":"code","4227d780":"code","e1a5e548":"code","90904700":"code","ed2cbe7f":"code","a6455c53":"code","064c67ae":"code","dc10fc72":"code","d1d80a94":"code","f7b8f560":"code","fda8b3e6":"code","190091d8":"code","e71012c5":"code","5c04c2a6":"code","8cea9d83":"code","85b8c7cf":"code","2bc6063e":"code","0c91a037":"code","6572b184":"code","feafba83":"code","1fdea769":"code","e12a12cd":"code","e74e1b45":"code","dbd9bcf3":"code","e4a8e809":"code","4d77f770":"code","54106f45":"code","6c3955ff":"code","45facbe0":"code","68e42490":"code","ca57a114":"code","fc1ac5ab":"code","668a8526":"code","2842f1c4":"code","75c061f9":"code","c93c6b3f":"code","aee50f0c":"code","6a2ec7ec":"code","bcd7ac6e":"code","2b61ada7":"code","424a45cf":"code","1908c489":"code","f8c2e91e":"code","60e8305f":"code","008704d9":"code","34e67f6c":"code","a1ec56a0":"code","adfba917":"code","daa3e9a4":"code","aab0c3e8":"code","db7ee5d8":"code","cf6de252":"code","5de71549":"code","19e79743":"code","fc18f514":"markdown","b9ec0bc0":"markdown","260ff68a":"markdown","b71e1f2e":"markdown","450258a6":"markdown","39257bd7":"markdown","a43512ee":"markdown","ef9b4d01":"markdown","7cc81bb8":"markdown","20de75a2":"markdown","8621b9ec":"markdown","0cbfaaa4":"markdown","0de54bed":"markdown","d7618656":"markdown","d9bde324":"markdown","b6652002":"markdown","3dae18f6":"markdown"},"source":{"d2c6182d":"import copy\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nimport pandas_profiling as pp\n\n# models\nfrom sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier \nfrom sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, VotingClassifier \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\n# NN models\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras import optimizers\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# model tuning\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval\n\nfrom sklearn import preprocessing\n\nfrom sklearn.linear_model import LinearRegression,LogisticRegression, SGDRegressor, RidgeCV\n\n# import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)","43b949b0":"data = pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\")","00ac359f":"data = data[data['age'] < 80]","4227d780":"data.head(3)","e1a5e548":"data.info()","90904700":"pp.ProfileReport(data)","ed2cbe7f":"# Thanks to: https:\/\/www.kaggle.com\/ahmadjaved097\/classifying-heart-disease-patients\nplt.figure(figsize=(14,8))\nsns.heatmap(data.corr(), annot = True, cmap='coolwarm',linewidths=.1)\nplt.show()","a6455c53":"#Thanks to: https:\/\/www.kaggle.com\/littleraj30\/eda-model-building-in-depth-on-heart-disease\nfig,ax=plt.subplots(1,2,figsize=(14,5))\nsns.countplot(x='fbs',data=data,hue='target',palette='Set3',ax=ax[0])\nax[0].set_xlabel(\"0-> fps <120 , 1-> fps>120\",size=12)\ndata.fbs.value_counts().plot.pie(ax=ax[1],autopct='%1.1f%%',shadow=True, explode=[0.1,0],cmap='Blues')\nax[1].set_title(\"0 -> fps <120 , 1 -> fps>120\",size=12)","064c67ae":"#Thanks to: https:\/\/www.kaggle.com\/littleraj30\/eda-model-building-in-depth-on-heart-disease\nfig,ax=plt.subplots(1,2,figsize=(14,5))\nsns.countplot(x='restecg',data=data,hue='target',palette='Set3',ax=ax[0])\nax[0].set_xlabel(\"resting electrocardiographic\",size=12)\ndata.restecg.value_counts().plot.pie(ax=ax[1],autopct='%1.1f%%',shadow=True,\n                                     explode=[0.005,0.05,0.05],cmap='Oranges')\nax[1].set_title(\"resting electrocardiographic\",size=12)","dc10fc72":"#Thanks to: https:\/\/www.kaggle.com\/littleraj30\/eda-model-building-in-depth-on-heart-disease\nfig,ax=plt.subplots(1,2,figsize=(14,5))\nsns.countplot(x='slope',data=data,hue='target',palette='Set1',ax=ax[0])\nax[0].set_xlabel(\"peak exercise ST segment\",size=12)\ndata.slope.value_counts().plot.pie(ax=ax[1],autopct='%1.1f%%',shadow=True,explode=[0.005,0.05,0.05],cmap='Reds')\n\nax[1].set_title(\"peak exercise ST segment \",size=12)","d1d80a94":"#Thanks to: https:\/\/www.kaggle.com\/littleraj30\/eda-model-building-in-depth-on-heart-disease\nfig,ax=plt.subplots(1,2,figsize=(14,5))\nsns.countplot(x='ca',data=data,hue='target',palette='Set2',ax=ax[0])\nax[0].set_xlabel(\"number of major vessels colored by flourosopy\",size=12)\ndata.ca.value_counts().plot.pie(ax=ax[1],autopct='%1.1f%%',shadow=True,cmap='Oranges')\nax[1].set_title(\"number of major vessels colored by flourosopy\",size=12)","f7b8f560":"#Thanks to: https:\/\/www.kaggle.com\/littleraj30\/eda-model-building-in-depth-on-heart-disease\nfig,ax=plt.subplots(1,2,figsize=(14,5))\nsns.countplot(x='thal',data=data,hue='target',palette='Set2',ax=ax[0])\nax[0].set_xlabel(\"number of major vessels colored by flourosopy\",size=12)\ndata.thal.value_counts().plot.pie(ax=ax[1],autopct='%1.1f%%',shadow=True,cmap='Greens')\nax[1].set_title(\"number of major vessels colored by flourosopy\",size=12)","fda8b3e6":"# Thanks to: https:\/\/www.kaggle.com\/ahmadjaved097\/classifying-heart-disease-patients\nmale =len(data[data['sex'] == 1])\nfemale = len(data[data['sex']== 0])\n\nplt.figure(figsize=(8,6))\n\n# Data to plot\nlabels = 'Male','Female'\nsizes = [male,female]\ncolors = ['pink', 'darkgreen']\nexplode = (0, 0)  # explode 1st slice\n \n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=90)\n \nplt.axis('equal')\nplt.show()","190091d8":"# Thanks to: https:\/\/www.kaggle.com\/ahmadjaved097\/classifying-heart-disease-patients\nplt.figure(figsize=(8,6))\n\n# Data to plot\nlabels = 'Chest Pain Type:0','Chest Pain Type:1','Chest Pain Type:2','Chest Pain Type:3'\nsizes = [len(data[data['cp'] == 0]),len(data[data['cp'] == 1]),\n         len(data[data['cp'] == 2]),\n         len(data[data['cp'] == 3])]\ncolors = ['pink', 'yellowgreen','purple','gold']\nexplode = (0, 0,0,0)  # explode 1st slice\n \n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=180)\n \nplt.axis('equal')\nplt.show()","e71012c5":"# Thanks to: https:\/\/www.kaggle.com\/ahmadjaved097\/classifying-heart-disease-patients\nplt.figure(figsize=(8,6))\n\n# Data to plot\nlabels = 'fasting blood sugar < 120 mg\/dl','fasting blood sugar > 120 mg\/dl'\nsizes = [len(data[data['fbs'] == 0]),len(data[data['cp'] == 1])]\ncolors = ['grey', 'yellowgreen','orange','gold']\nexplode = (0.1, 0)  # explode 1st slice\n \n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=180)\n \nplt.axis('equal')\nplt.show()","5c04c2a6":"# Thanks to: https:\/\/www.kaggle.com\/ahmadjaved097\/classifying-heart-disease-patients\nplt.figure(figsize=(15,6))\nsns.countplot(x='age',data = data, hue = 'target',palette='GnBu')\nplt.show()","8cea9d83":"# Clone data for FE \ntrain_fe = copy.deepcopy(data)\ntarget_fe = train_fe['target']\ndel train_fe['target']","85b8c7cf":"# Thanks to: https:\/\/www.kaggle.com\/vbmokin\/used-cars-fe-eda-with-3d\nX = train_fe\nz = target_fe","2bc6063e":"# Thanks to: https:\/\/www.kaggle.com\/vbmokin\/used-cars-fe-eda-with-3d\n#%% split training set to validation set\nXtrain, Xval, Ztrain, Zval = train_test_split(X, z, test_size=0.2, random_state=0)\ntrain_set = lgb.Dataset(Xtrain, Ztrain, silent=False)\nvalid_set = lgb.Dataset(Xval, Zval, silent=False)","0c91a037":"# Thanks to: https:\/\/www.kaggle.com\/vbmokin\/used-cars-fe-eda-with-3d\nparams = {\n        'boosting_type':'gbdt',\n        'objective': 'regression',\n        'num_leaves': 31,\n        'learning_rate': 0.05,\n        'max_depth': -1,\n        'subsample': 0.8,\n        'bagging_fraction' : 1,\n        'max_bin' : 5000 ,\n        'bagging_freq': 20,\n        'colsample_bytree': 0.6,\n        'metric': 'rmse',\n        'min_split_gain': 0.5,\n        'min_child_weight': 1,\n        'min_child_samples': 10,\n        'scale_pos_weight':1,\n        'zero_as_missing': True,\n        'seed':0,        \n    }\n\nmodelL = lgb.train(params, train_set = train_set, num_boost_round=1000,\n                   early_stopping_rounds=50,verbose_eval=10, valid_sets=valid_set)","6572b184":"# Thanks to: https:\/\/www.kaggle.com\/vbmokin\/used-cars-fe-eda-with-3d\nfig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nlgb.plot_importance(modelL,ax = axes,height = 0.5)\nplt.show();plt.close()","feafba83":"# Thanks to: https:\/\/www.kaggle.com\/vbmokin\/used-cars-fe-eda-with-3d\nfeature_score = pd.DataFrame(train_fe.columns, columns = ['feature']) \nfeature_score['score_lgb'] = modelL.feature_importance()","1fdea769":"# Thanks to: https:\/\/www.kaggle.com\/vbmokin\/used-cars-fe-eda-with-3d\n#%% split training set to validation set \ndata_tr  = xgb.DMatrix(Xtrain, label=Ztrain)\ndata_cv  = xgb.DMatrix(Xval   , label=Zval)\nevallist = [(data_tr, 'train'), (data_cv, 'valid')]","e12a12cd":"# Thanks to: https:\/\/www.kaggle.com\/vbmokin\/used-cars-fe-eda-with-3d\nparms = {'max_depth':8, #maximum depth of a tree\n         'objective':'reg:squarederror',\n         'eta'      :0.3,\n         'subsample':0.8,#SGD will use this percentage of data\n         'lambda '  :4, #L2 regularization term,>1 more conservative \n         'colsample_bytree ':0.9,\n         'colsample_bylevel':1,\n         'min_child_weight': 10}\nmodelx = xgb.train(parms, data_tr, num_boost_round=200, evals = evallist,\n                  early_stopping_rounds=30, maximize=False, \n                  verbose_eval=10)\n\nprint('score = %1.5f, n_boost_round =%d.'%(modelx.best_score,modelx.best_iteration))","e74e1b45":"# Thanks to: https:\/\/www.kaggle.com\/vbmokin\/used-cars-fe-eda-with-3d\nfig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nxgb.plot_importance(modelx,ax = axes,height = 0.5)\nplt.show();plt.close()","dbd9bcf3":"# Thanks to: https:\/\/www.kaggle.com\/vbmokin\/used-cars-fe-eda-with-3d\nfeature_score['score_xgb'] = feature_score['feature'].map(modelx.get_score(importance_type='weight'))\nfeature_score","e4a8e809":"# Thanks to: https:\/\/www.kaggle.com\/vbmokin\/used-cars-fe-eda-with-3d\n# Standardization for regression model\ntrain_fe = pd.DataFrame(\n    preprocessing.MinMaxScaler().fit_transform(train_fe),\n    columns=train_fe.columns,\n    index=train_fe.index\n)","4d77f770":"# Thanks to: https:\/\/www.kaggle.com\/vbmokin\/used-cars-fe-eda-with-3d\n# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(train_fe, target_fe)\ncoeff_logreg = pd.DataFrame(train_fe.columns.delete(0))\ncoeff_logreg.columns = ['feature']\ncoeff_logreg[\"score_logreg\"] = pd.Series(logreg.coef_[0])\ncoeff_logreg.sort_values(by='score_logreg', ascending=False)","54106f45":"# Thanks to: https:\/\/www.kaggle.com\/vbmokin\/used-cars-fe-eda-with-3d\n# the level of importance of features is not associated with the sign\ncoeff_logreg[\"score_logreg\"] = coeff_logreg[\"score_logreg\"].abs()\nfeature_score = pd.merge(feature_score, coeff_logreg, on='feature')","6c3955ff":"# Thanks to: https:\/\/www.kaggle.com\/vbmokin\/used-cars-fe-eda-with-3d\n# Linear Regression\n\nlinreg = LinearRegression()\nlinreg.fit(train_fe, target_fe)\ncoeff_linreg = pd.DataFrame(train_fe.columns.delete(0))\ncoeff_linreg.columns = ['feature']\ncoeff_linreg[\"score_linreg\"] = pd.Series(linreg.coef_)\ncoeff_linreg.sort_values(by='score_linreg', ascending=False)","45facbe0":"# Thanks to: https:\/\/www.kaggle.com\/vbmokin\/used-cars-fe-eda-with-3d\ncoeff_linreg[\"score_linreg\"] = coeff_linreg[\"score_linreg\"].abs()\nfeature_score = pd.merge(feature_score, coeff_linreg, on='feature')\nfeature_score = feature_score.fillna(0)\nfeature_score = feature_score.set_index('feature')\nfeature_score","68e42490":"# Thanks to: https:\/\/www.kaggle.com\/vbmokin\/feature-importance-xgb-lgbm-logreg-linreg\n# Thanks to: https:\/\/www.kaggle.com\/nanomathias\/feature-engineering-importance-testing\n# MinMax scale all importances\nfeature_score = pd.DataFrame(\n    preprocessing.MinMaxScaler().fit_transform(feature_score),\n    columns=feature_score.columns,\n    index=feature_score.index\n)\n\n# Create mean column\nfeature_score['mean'] = feature_score.mean(axis=1)\n\n# Plot the feature importances\nfeature_score.sort_values('mean', ascending=False).plot(kind='bar', figsize=(20, 10))","ca57a114":"feature_score.sort_values('mean', ascending=False)","fc1ac5ab":"# Thanks to: Thanks to: https:\/\/www.kaggle.com\/vbmokin\/feature-importance-xgb-lgbm-logreg-linreg\n# Create total column with different weights\nfeature_score['total'] = 0.5*feature_score['score_lgb'] + 0.3*feature_score['score_xgb'] \\\n                       + 0.1*feature_score['score_logreg'] + 0.1*feature_score['score_linreg']\n\n# Plot the feature importances\nfeature_score.sort_values('total', ascending=False).plot(kind='bar', figsize=(20, 10))","668a8526":"feature_score.sort_values('total', ascending=False)","2842f1c4":"target_name = 'target'\ndata_target = data[target_name]\ndata = data.drop([target_name], axis=1)","75c061f9":"train, test, target, target_test = train_test_split(data, data_target, test_size=0.2, random_state=0)","c93c6b3f":"train.head(3)","aee50f0c":"test.head(3)","6a2ec7ec":"train.info()","bcd7ac6e":"test.info()","2b61ada7":"#%% split training set to validation set\nXtrain, Xval, Ztrain, Zval = train_test_split(train, target, test_size=0.2, random_state=0)","424a45cf":"# Decision Tree Classifier\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(train, target)\nacc_decision_tree = round(decision_tree.score(train, target) * 100, 2)\nacc_decision_tree","1908c489":"acc_test_decision_tree = round(decision_tree.score(test, target_test) * 100, 2)\nacc_test_decision_tree","f8c2e91e":"def hyperopt_xgb_score(params):\n    clf = XGBClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=10).mean()\n    print(current_score, params)\n    return current_score \n \nspace_xgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'eta': hp.quniform('eta', 0.025, 0.5, 0.005),\n            'max_depth':  hp.choice('max_depth', np.arange(2, 12, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'subsample': hp.quniform('subsample', 0.5, 1, 0.005),\n            'gamma': hp.quniform('gamma', 0.5, 1, 0.005),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'eval_metric': 'auc',\n            'objective': 'binary:logistic',\n            'booster': 'gbtree',\n            'tree_method': 'exact',\n            'silent': 1,\n            'missing': None\n        }\n \nbest = fmin(fn=hyperopt_xgb_score, space=space_xgb, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best)","60e8305f":"params = space_eval(space_xgb, best)\nparams","008704d9":"XGB_Classifier = XGBClassifier(**params)\nXGB_Classifier.fit(train, target)\nacc_XGB_Classifier = round(XGB_Classifier.score(train, target) * 100, 2)\nacc_XGB_Classifier","34e67f6c":"acc_test_XGB_Classifier = round(XGB_Classifier.score(test, target_test) * 100, 2)\nacc_test_XGB_Classifier","a1ec56a0":"fig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nxgb.plot_importance(XGB_Classifier,ax = axes,height =0.5)\nplt.show();\nplt.close()","adfba917":"svc = SVC()\nsvc.fit(train, target)\nacc_svc = round(svc.score(train, target) * 100, 2)\nacc_svc","daa3e9a4":"acc_test_svc = round(svc.score(test, target_test) * 100, 2)\nacc_test_svc","aab0c3e8":"models = pd.DataFrame({\n    'Model': ['Decision Tree Classifier','XGBClassifier', 'Support Vector Machines'],\n    \n    'Score_train': [acc_decision_tree, acc_XGB_Classifier, acc_svc],\n    'Score_test': [acc_test_decision_tree, acc_test_XGB_Classifier, acc_test_svc]\n                    })","db7ee5d8":"models.sort_values(by=['Score_train', 'Score_test'], ascending=False)","cf6de252":"models.sort_values(by=['Score_test', 'Score_train'], ascending=False)","5de71549":"models['Score_diff'] = abs(models['Score_train'] - models['Score_test'])\nmodels.sort_values(by=['Score_diff'], ascending=True)","19e79743":"# Plot\nplt.figure(figsize=[25,6])\nxx = models['Model']\nplt.tick_params(labelsize=14)\nplt.plot(xx, models['Score_train'], label = 'Score_train')\nplt.plot(xx, models['Score_test'], label = 'Score_test')\nplt.legend()\nplt.title('Score of 20 popular models for train and test datasets')\nplt.xlabel('Models')\nplt.ylabel('Score, %')\nplt.xticks(xx, rotation='vertical')\nplt.savefig('graph.png')\nplt.show()","fc18f514":"### 7.1 Decition Tree Classifiter <a class=\"anchor\" id=\"7.1\"><\/a>\n\n[Back to Table of Contents](#0.1)","b9ec0bc0":"## 8. Models evaluation <a class=\"anchor\" id=\"8\"><\/a>\n\n[Back to Table of Contents](#0.1)","260ff68a":"<a class=\"anchor\" id=\"4.4\"><\/a>\n### 4.4 Linear Regression\n##### [Back to Table of Contents](#0.1)","b71e1f2e":" ## 6. Preparing to modeling <a class=\"anchor\" id=\"6\"><\/a>\n\n[Back to Table of Contents](#0.1)","450258a6":"<a class=\"anchor\" id=\"5\"><\/a>\n## 5. Comparison of the all feature importance diagrams \n##### [Back to Table of Contents](#0.1)","39257bd7":"## 2. Download datasets <a class=\"anchor\" id=\"2\"><\/a>\n\n[Back to Table of Contents](#0.1)","a43512ee":"## 1. Import libraries <a class=\"anchor\" id=\"1\"><\/a>\n\n[Back to Table of Contents](#0.1)","ef9b4d01":" ## 4. FE: building the feature importance diagrams <a class=\"anchor\" id=\"4\"><\/a>\n\n[Back to Table of Contents](#0.1)","7cc81bb8":"<a class=\"anchor\" id=\"4.3\"><\/a>\n### 4.3 Logistic Regression\n[Back to Table of Contents](#0.1)","20de75a2":"### 7.2 XGB Classifier <a class=\"anchor\" id=\"7.2\"><\/a>\n\n[Back to Table of Contents](#0.1)","8621b9ec":"<a class=\"anchor\" id=\"4.1\"><\/a>\n### 4.1 LGBM \n[Back to Table of Contents](#0.1)","0cbfaaa4":"<a class=\"anchor\" id=\"4.2\"><\/a>\n### 4.2 XGB\n[Back to Table of Contents](#0.1)","0de54bed":"## 3. EDA <a class=\"anchor\" id=\"3\"><\/a>\n\n[Back to Table of Contents](#0.1)","d7618656":"<a class=\"anchor\" id=\"0.1\"><\/a>\n\n## Table of Contents\n\n1. [Import libraries](#1)\n1. [Download datasets](#2)\n1. [EDA](#3)\n1. [FE: building the feature importance diagrams](#4)\n    -  [4.1 LGBM](#4.1)\n    -  [4.2 XGB](#4.2) \n    -  [4.3 Logistic Regression](#4.3) \n    -  [4.4 Linear Regression](#4.4)\n1. [Comparison of the all feature importance diagrams ](#5)\n1. [Preparing to modeling](#6)  \n1. [Tuning models and test for all features](#7)\n    -  [Decition Tree Classifiter](#7.1)\n    -  [XGB Classifier](#7.2)\n    -  [Support Vector Machines](#7.3) \n1. [Models evaluation](#8)","d9bde324":"### 7.3 Support Vector Machines \n<a class=\"anchor\" id=\"7.3\"><\/a>\n\n[Back to Table of Contents](#0.1)","b6652002":"## 7. Tuning models and test for all features <a class=\"anchor\" id=\"7\"><\/a>\n\n[Back to Table of Contents](#0.1)","3dae18f6":"## Acknowledgements\n#### This kernel uses such good kernels\n   - https:\/\/www.kaggle.com\/vbmokin\/used-cars-fe-eda-with-3d\n   - https:\/\/www.kaggle.com\/vbmokin\/feature-importance-xgb-lgbm-logreg-linreg\n   - https:\/\/www.kaggle.com\/nanomathias\/feature-engineering-importance-testing\n   - https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions\n   - https:\/\/www.kaggle.com\/kabure\/titanic-eda-model-pipeline-keras-nn\n   - https:\/\/www.kaggle.com\/vbmokin\/used-cars-price-prediction-by-15-models\n   - https:\/\/www.kaggle.com\/vbmokin\/feature-importance-xgb-lgbm-logreg-linreg\\\n   - https:\/\/www.kaggle.com\/littleraj30\/eda-model-building-in-depth-on-heart-disease\n   - https:\/\/www.kaggle.com\/ahmadjaved097\/classifying-heart-disease-patients"}}