{"cell_type":{"4517aaf7":"code","1d567c17":"code","ceb2ac9d":"code","d58703c4":"code","d5d42ec7":"code","10858051":"code","dbe3a71d":"code","77c992f0":"code","6a4c89a5":"code","8fd5049b":"code","376c1078":"code","4b14c98c":"code","34afe28b":"code","6b22fe61":"code","f44e4019":"code","32e27a4c":"code","4ada3cd8":"code","97eb3e13":"code","f2e47193":"code","f8d3ca84":"code","af09f47c":"code","84beb447":"code","d704f6df":"code","ac79d485":"code","7c05ec16":"code","60f267e0":"code","d2f95b84":"code","9c8ecc03":"code","25f79273":"code","7f6e14d5":"code","2858f08f":"code","68780937":"markdown","e0a8c465":"markdown","0a87aaee":"markdown","378fce90":"markdown","3ee6ff07":"markdown","3aa6a11d":"markdown","2b89f449":"markdown","fee375d2":"markdown","722a3f63":"markdown","fc24fc6b":"markdown","ea2e95b1":"markdown","279312ef":"markdown","3478567e":"markdown","48ec3dcd":"markdown","4d323a5f":"markdown","45b391c9":"markdown","0b14f4cd":"markdown","471a8306":"markdown","b544007b":"markdown","c14ebbaa":"markdown","97d2b296":"markdown","57c53e46":"markdown","14f334df":"markdown","44096738":"markdown","bc84e5b7":"markdown","d18731d1":"markdown","c630acf1":"markdown","c7d5e3f4":"markdown","e55d5e1a":"markdown"},"source":{"4517aaf7":"# Importing needed library\nimport numpy as np\nimport pickle\nimport matplotlib.pyplot as plt\nfrom math import sqrt, ceil\nimport cv2\nfrom timeit import default_timer as timer\n","1d567c17":"\"\"\"\nDefining function for Naive Forward Pass for Convolutional Layer.\n\nInput consists of following:\n\n    x of shape (N, C, H, W) - input, where N is number of input images \n        and every of them with C channels, with height H and with width W.\n    w of shape (F, C, HH, WW) - filters, with the help of which we convolve every input image \n        with F different filters, where every filter spans all C channels and every filter \n        has height HH and width WW.\n    b of shape (F, ) - biases for every filter F.\n    cnn_params - dictionary with parameters for convolution, where key stride is a step for sliding, \n        and key pad is a zero-pad frame around input image.\n\nFunction returns a tuple of (feature_maps, cache):\n\n    feature_maps - received feature maps with shape (N, F, H', W'), where:\n        N - number of received batches of feature maps for every input image \n            and is the same with number of input images.\n        F - number of received feature maps for every input image \n            and is the same with number of filters for convolution.\n        H' - height of received feature map that is calculated by following equation: \n            H' = 1 + (H + 2 * pad - HH) \/ stride\n        W' - width of received feature map that is calculated by following equation:\n            W' = 1 + (W + 2 * pad - WW) \/ stride\n        cache - tuple of shape (x, w, b, cnn_params), that is needed in backward pass.\n\"\"\"\n\n\n# Defining function for Naive Forward Pass for Convolutional Layer\ndef cnn_forward_naive(x, w, b, cnn_params):\n    # Preparing parameters for convolution operation\n    stride = cnn_params['stride']\n    pad = cnn_params['pad']\n    N, C, H, W = x.shape\n    F, _, HH, WW = w.shape\n\n    # Preparing cache for output\n    cache = (x, w, b, cnn_params)\n\n    # Applying to the input volume of images zero valued pad frame for all channels with function 'np.pad'\n    # Applying this zero valued pad frame only for height and width\n    # That's why we leave first two tuples as '(0, 0), (0, 0)'\n    # And two last tuples with pad parameter as '(pad, pad), (pad, pad)'\n    # In this way we implement zero valued pad only to H and to W of N inputs with C channels\n    x_padded = np.pad(x, ((0, 0), (0, 0), (pad, pad), (pad, pad)), mode='constant', constant_values=0)\n\n    # Calculating spatial sizes of output feature maps\n    height_out = int(1 + (H + 2 * pad - HH) \/ stride)\n    width_out = int(1 + (W + 2 * pad - WW) \/ stride)\n\n    # Defining zero valued volume for output feature maps\n    # N is a number of received batches of feature maps for every input image\n    # (is the same with number of input images)\n    # F is a number of received feature maps for every input image\n    # (is the same with number of filters for convolution)\n    feature_maps = np.zeros((N, F, height_out, width_out))\n\n    # Implementing convolution through N input images, every with F filters and with respect to C channels\n    # For every image\n    for n in range(N):\n        # For every filter\n        for f in range(F):\n            # Defining variable for indexing height in output feature map\n            # (because our step might not be equal to 1)\n            height_index = 0\n            # Convolving every channel of the image with every channel of the current filter\n            # Result is summed up\n            # Going through all input image (2D convolution) through all channels\n            for i in range(0, H, stride):\n                # Defining variable for indexing width in output feature map\n                # (because our step might not be equal to 1)\n                width_index = 0\n                for j in range(0, W, stride):\n                    feature_maps[n, f, height_index, width_index] = \\\n                        np.sum(x_padded[n, :, i:i+HH, j:j+WW] * w[f, :, :, :]) + b[f]\n                    # Increasing index for width\n                    width_index += 1\n                # Increasing index for height\n                height_index += 1\n\n    # Returning resulted volume of feature maps and cache\n    return feature_maps, cache\n","ceb2ac9d":"# Defining function for calculating absolute error\n# Absolute error shows deviation between received value y and true value x\n# Difference should be very small, less then 1e-7\ndef absolute_error(x, y):\n    return np.sum(np.abs(x - y))\n\n\n# Defining shapes for input data, weights and biases\nx_shape = (1, 3, 4, 4)  # (N, C, H, W) - N data, C channels, H height, W width\nw_shape = (3, 3, 4, 4)  # (F, C, HH, WW) - F different filters, C channels, HH height, WW width\nb_shape = (3, )\n\n# Generating data\n# Defining input, weights and biases by filling them with 'linspase' function\n# By using 'prod' we calculate and specify number of elements in the array\n# By using 'reshape' we reshaping defined array from one dimentional to needed shape\nx = np.linspace(0, 255, num=np.prod(x_shape), dtype='uint8').reshape(x_shape)\nw = np.linspace(-1.0, 1.0, num=np.prod(w_shape), dtype='float64').reshape(w_shape)\nb = np.linspace(-1.0, 1.0, num=np.prod(b_shape), dtype='float64').reshape(b_shape)\n\n# # Check point\n# print(x.shape)  # (1, 3, 4, 4)\n# print(w.shape)  # (3, 3, 4, 4)\n# print(b.shape)  # (3,)\n\n# Defining parameters for convolution operation\n# Dictionary with following keys:\n# 'stride' - step for sliding\n# 'pad' - zero-pad frame around input\ncnn_params = {'stride': 2, 'pad': 1}\n\n# Calculating output with function for naive forward pass\nout, _ = cnn_forward_naive(x, w, b, cnn_params)\n\n# Check point\nprint(out.shape)  # (1, 3, 2, 2)\nprint()\nprint(out)\n# [[[[-1577.82517483 -1715.03496503]\n#    [-2154.29370629 -2308.0979021 ]]\n\n#   [[  480.12587413   440.25874126]\n#    [  296.38461538   240.59440559]]\n\n#   [[ 2538.07692308  2595.55244755]\n#    [ 2747.06293706  2789.28671329]]]]\n\n# Defining true output that we know in advance\ncorrect_out = np.array([[[[-1577.82517483, -1715.03496503],\n   [-2154.29370629, -2308.0979021 ]],\n\n  [[  480.12587413,   440.25874126],\n   [  296.38461538,   240.59440559]],\n\n  [[ 2538.07692308,  2595.55244755],\n   [ 2747.06293706,  2789.28671329]]]])\n\n# Calculating difference\nprint()\nprint(absolute_error(correct_out, out))  # 4.1748563717192155e-08\n","d58703c4":"\"\"\"\nDefining function for Naive Backward Pass for Convolutional Layer.\n\nInput consists of following:\n\n    derivatives_out - upstream derivatives.\n    cache - tuple of shape (x, w, b, cnn_params), where:\n        x of shape (N, C, H, W) - input, where N is number of input images \n            and every of them with C channels, with height H and with width W.\n        w of shape (F, C, HH, WW) - filters, with the help of which we convolve every input image \n            with F different filters, where every filter spans all C channels and every filter \n            has height HH and width WW.\n        b of shape (F, ) - biases for every filter F.\n        cnn_params - dictionary with parameters for convolution, where key stride is a step for sliding, \n            and key pad is a zero-pad frame around input image.\n        \nFunction returns a tuple of (dx, dw, db):\n\n    dx - gradient with respect to x.\n    dw - gradient with respect to w.\n    db - gradient with respect to b.\n\"\"\"\n\n\n# Defining function for Naive Backward Pass for Convolutional Layer\ndef cnn_backward_naive(derivative_out, cache):\n    # Preparing variables for input, weights, biases, cnn parameters from cache\n    x, w, b, cnn_params = cache\n\n    # Preparing variables with appropriate shapes\n    N, C, H, W = x.shape  # For input\n    F, _, HH, WW = w.shape  # For weights\n    _, _, height_out, weight_out = derivative_out.shape  # For output feature maps\n\n    # Preparing variables with parameters\n    stride = cnn_params['stride']\n    pad = cnn_params['pad']\n\n    # Preparing gradients for output\n    dx = np.zeros_like(x)\n    dw = np.zeros_like(w)\n    db = np.zeros_like(b)\n\n    # It is important to remember that cache has original non-padded input x.\n    # Applying to the input volume of images zero valued pad frame for all channels with function 'np.pad'\n    # Applying zero valued pad frame only for height and width\n    # That's why we leave first two tuples as '(0, 0), (0, 0)'\n    # And two last tuples with pad parameter as '(pad, pad), (pad, pad)'\n    # In this way we implement zero valued pad only to H and to W of N inputs with C channels\n    x_padded = np.pad(x, ((0, 0), (0, 0), (pad, pad), (pad, pad)), mode='constant', constant_values=0)\n    # Also, we apply padding for dx\n    dx_padded = np.pad(dx, ((0, 0), (0, 0), (pad, pad), (pad, pad)), mode='constant', constant_values=0)\n\n    # Implementing backward pass through N input images, every with F filters and with respect to C channels\n    # And calculating gradients\n    # For every image\n    for n in range(N):\n        # For every filter\n        for f in range(F):\n            # Going through all input image through all channels\n            for i in range(0, H, stride):\n                for j in range(0, W, stride):\n                    # Calculating gradients\n                    dx_padded[n, :, i:i+HH, j:j+WW] += w[f, :, :, :] * derivative_out[n, f, i, j]\n                    dw[f, :, :, :] += x_padded[n, :, i:i+HH, j:j+WW] * derivative_out[n, f, i, j]\n                    db[f] += derivative_out[n, f, i, j]\n\n    # Reassigning dx by slicing dx_padded\n    dx = dx_padded[:, :, 1:-1, 1:-1]\n\n    # Returning calculated gradients\n    return dx, dw, db\n","d5d42ec7":"\"\"\"\nDefining function for Naive Forward Pass for Max Pooling Layer.\n\nInput consists of following:\n\n    x of shape (N, F, H, W) - input, where N is number of input images \n        and every of them with F channels (number of feature maps after Convolutional Layer), \n        with height H and with width W.\n    pooling_params - dictionary with following keys:\n        pooling_height - height of pooling region.\n        pooling_width - width of pooling region.\n        stride - step (distance) between pooling regions.\n    \nFunction returns a tuple of (pooled_output, cache):\n\n    pooled_output - output resulted data with shape (N, F, H', W'), where:\n        N - number of received batches of feature maps for every input image \n            and is the same with number of input images.\n        F - number of channels (number of feature maps after Convolutional Layer) for every input image.\n        H' - height of received pooled data that is calculated by following equation: \n            H' = 1 + (H + pooling_height) \/ stride\n        W' - width of received pooled data that is calculated by following equation: \n            W' = 1 + (W + pooling_width) \/ stride\n    cache - tuple of shape (x, pooling_params), that is needed in backward pass.\n\"\"\"\n\n\n# Defining function for Naive Forward Pass for Max Pooling Layer\ndef max_pooling_forward_naive(x, pooling_params):\n    # Preparing variables with appropriate shapes\n    N, F, H, W = x.shape  # For input\n\n    # Preparing variables with parameters\n    pooling_height = pooling_params['pooling_height']\n    pooling_width = pooling_params['pooling_width']\n    stride = pooling_params['stride']\n\n    # Cache for output\n    cache = (x, pooling_params)\n\n    # Defining spatial size of output image volume after pooling layer\n    height_pooled_out = int(1 + (H - pooling_height) \/ stride)\n    width_polled_out = int(1 + (W - pooling_width) \/ stride)\n    # Depth of output volume is number of channels which is F (number of feature maps)\n    # And number of input images N remains the same - it is number of output image volumes now\n\n    # Creating zero valued volume for output image volume after pooling layer\n    pooled_output = np.zeros((N, F, height_pooled_out, width_polled_out))\n\n    # Implementing forward naive pooling pass through N input images,\n    # every with F channels (number of feature maps)\n    # And calculating output pooled image volume\n    # For every image\n    for n in range(N):\n        # Going through all input image through all channels\n        for i in range(height_pooled_out):\n            for j in range(width_polled_out):\n                # Preparing height and width for current pooling region\n                ii = i * stride\n                jj = j * stride\n                # Getting current pooling region with all channels F\n                current_pooling_region = x[n, :, ii:ii+pooling_height, jj:jj+pooling_width]\n                # Finding maximum value for all channels and filling output pooled image\n                # Reshaping current pooling region from (3, 2, 2) - 3 channels and 2 by 2\n                # To (3, 4) in order to utilize np.max function\n                # Specifying 'axis=1' as parameter for choosing maximum value\n                # out of 4 numbers along 3 channels\n                pooled_output[n, :, i, j] = \\\n                    np.max(current_pooling_region.reshape((F, pooling_height * pooling_width)), axis=1)\n\n    # Returning output resulted data\n    return pooled_output, cache\n","10858051":"# Defining function for calculating absolute error\n# Absolute error shows deviation between received value y and true value x\n# Difference should be very small, less then 1e-7\ndef absolute_error(x, y):\n    return np.sum(np.abs(x - y))\n\n\n# Defining shape for input image volume\nx_shape = (2, 1, 4, 4)  # (N, F, H, W) - N data, F channels, H height, W width\n\n# Generating data\n# Defining input by filling it with 'linspase' function\n# By using 'prod' we calculate and specify number of elements in the array\n# By using 'reshape' we reshaping defined array from one dimentional to needed shape\nx = np.linspace(0, 255, num=np.prod(x_shape), dtype='float64').reshape(x_shape)\n\n# # Check point\n# print(x.shape)  # (2, 1, 2, 2)\n# print(x)\n# [[[[  0.           8.22580645  16.4516129   24.67741935]\n#    [ 32.90322581  41.12903226  49.35483871  57.58064516]\n#    [ 65.80645161  74.03225806  82.25806452  90.48387097]\n#    [ 98.70967742 106.93548387 115.16129032 123.38709677]]]\n#\n#  [[[131.61290323 139.83870968 148.06451613 156.29032258]\n#    [164.51612903 172.74193548 180.96774194 189.19354839]\n#    [197.41935484 205.64516129 213.87096774 222.09677419]\n#    [230.32258065 238.5483871  246.77419355 255.        ]]]]\n\n# Defining parameters for pooling operation\n# Dictionary with following keys:\n#    'pooling_height' - height of pooling region\n#    'pooling_width' - width of pooling region\n#    'stride' - step (distance) between pooling regions\npooling_params = {'pooling_height': 2, 'pooling_width': 2, 'stride': 2}\n\n# Calculating output with function for naive forward pass for pooling layer\nout, _ = max_pooling_forward_naive(x, pooling_params)\n\n# Check point\nprint(out.shape)  # (2, 1, 2, 2)\nprint()\nprint(out)\n# [[[[ 41.12903226  57.58064516]\n#    [106.93548387 123.38709677]]]\n#\n#  [[[172.74193548 189.19354839]\n#    [238.5483871  255.        ]]]]\n\n# Defining true output that we know in advance\ncorrect_out = np.array([[[[ 41.12903226,  57.58064516],\n   [106.93548387, 123.38709677]]],\n\n [[[172.74193548, 189.19354839],\n   [238.5483871,  255.        ]]]])\n\n# Calculating difference\nprint()\nprint(absolute_error(correct_out, out))  # 1.8387098066341423e-08\n","dbe3a71d":"\"\"\"\nDefining function for Naive Backward Pass for MAX Pooling Layer.\n\nInput consists of following:\n\n    derivatives_out - upstream derivatives.\n    cache - tuple of (x, pooling_params), where:\n        x of shape (N, F, H, W) - input, where N is number of input images \n            and every of them with F channels (number of feature maps after Convolutional Layer), \n            with height H and with width W.\n        pooling_params - dictionary with following keys:\n            pooling_height - height of pooling region.\n            pooling_width - width of pooling region.\n            stride - step (distance) between pooling regions.\n\nFunction returns derivatives calculated with Gradient Descent method:\n\n    dx - gradient with respect to x.\n\"\"\"\n\n\n# Defining function for Naive Backward Pass for MAX Pooling Layer.\ndef max_pooling_backward_naive(derivatives_out, cache):\n    # Preparing variables with appropriate shapes\n    x, pooling_params = cache\n    N, F, H, W = x.shape\n\n    # Preparing variables with parameters\n    pooling_height = pooling_params['pooling_height']\n    pooling_width = pooling_params['pooling_width']\n    stride = pooling_params['stride']\n\n    # Defining spatial size of output image volume after pooling layer\n    height_pooled_out = int(1 + (H - pooling_height) \/ stride)\n    width_polled_out = int(1 + (W - pooling_width) \/ stride)\n    # Depth of output volume is number of channels which is F (or number of feature maps)\n    # And number of input images N remains the same - it is number of output image volumes now\n\n    # Creating zero valued volume for output gradient after backward pass of pooling layer\n    # The shape is the same with x.shape\n    dx = np.zeros((N, F, H, W))\n\n    # Implementing backward naive pooling pass through N input images,\n    # every with F channels (number of feature maps)\n    # And calculating output pooled image volume\n    # For every image\n    for n in range(N):\n        # For every channel\n        for f in range(F):\n            # Going through all pooled image by height and width\n            for i in range(height_pooled_out):\n                for j in range(width_polled_out):\n                    # Preparing height and width for current pooling region\n                    ii = i * stride\n                    jj = j * stride\n                    # Getting current pooling region\n                    current_pooling_region = x[n, f, ii:ii+pooling_height, jj:jj+pooling_width]\n                    # Finding maximum value for current pooling region\n                    current_maximum = np.max(current_pooling_region)\n                    # Creating array with the same shape as 'current_pooling_region'\n                    # Filling with 'True' and 'False' according to the condition '==' to 'current_maximum'\n                    temp = current_pooling_region == current_maximum\n                    # Calculating output gradient\n                    dx[n, f, ii:ii+pooling_height, jj:jj+pooling_width] += \\\n                        derivatives_out[n, f, i, j] * temp\n\n                    # Backward pass for pooling layer will return gradient with respect to x\n                    # Every pooling region will be filled with '0'\n                    # or derivative if that value was maximum for forward pass\n                    # print(x[0, 0, 0:2, 0:2])\n                    # print()\n                    # print(dx[0, 0, 0:2, 0:2])\n\n                    # [[ 0.57775955 -0.03546282]\n                    #  [-1.03050044 -1.23398021]]\n\n                    # [[-0.93262122  0.        ]\n                    #  [ 0.          0.        ]]\n\n    # Returning gradient with respect to x\n    return dx\n","77c992f0":"# Defining shape for input image volume and output derivatives volume\nx_shape = (1, 1, 8, 8)  # (N, F, H, W) - N data, F channels, H height, W width\nderivatives_out_shape = (1, 1, 4, 4)  # (N, F, H, W) - N data, F channels, H height, W width\n\n# Generating data\n# Defining input by filling it with 'linspase' function\n# By using 'prod' we calculate and specify number of elements in the array\n# By using 'reshape' we reshaping defined array from one dimentional to needed shape\nx = np.linspace(0, 255, num=np.prod(x_shape), dtype='uint8').reshape(x_shape)\nderivatives_out = np.random.randn(*derivatives_out_shape)\n# We use here mark '*' to unpack shape and pass it to the function\n# Also, we can use function 'np.random.random_sample' and pass shape there\n\n# # Check point\n# print(x.shape)  # (1, 1, 8, 8)\n# print(x)\n# [[[[  0   4   8  12  16  20  24  28]\n#    [ 32  36  40  44  48  52  56  60]\n#    [ 64  68  72  76  80  85  89  93]\n#    [ 97 101 105 109 113 117 121 125]\n#    [129 133 137 141 145 149 153 157]\n#    [161 165 170 174 178 182 186 190]\n#    [194 198 202 206 210 214 218 222]\n#    [226 230 234 238 242 246 250 255]]]]\n\n# # Check point\n# print(derivatives_out.shape)  # (1, 1, 4, 4)\n\n# Defining parameters for pooling operation\n# Dictionary with following keys:\n#    'pooling_height' - height of pooling region\n#    'pooling_width' - width of pooling region\n#    'stride' - step (distance) between pooling regions\npooling_params = {'pooling_height': 2, 'pooling_width': 2, 'stride': 2}\n\n# Calculating output with function for naive forward pass for pooling layer\nout, cache = max_pooling_forward_naive(x, pooling_params)\n# Calculating output gradients with function for naive backward pass for pooling layer\ndx = max_pooling_backward_naive(derivatives_out, cache)\n\n# Backward pass for pooling layer will return gradient with respect to x\n# Every pooling region will be filled with '0' or derivative if that value was maximum for forward pass\nprint(x[0, 0, 0:2, 0:2])\nprint()\nprint(dx[0, 0, 0:2, 0:2])\n\n# [[ 0  4]\n#  [32 36]]\n\n# [[0.         0.        ]\n#  [0.         1.09264091]]\n","6a4c89a5":"\"\"\"\nDefining function for Naive Forward Pass for Fully-Connected Layer (also known as Affine Layer).\n\nInput consists of following:\n\n    x of shape (N, d1, ..., dk) - input data, where input x contains N batches and \n        each batch x[i] has shape (d1, ..., dk).\n    w of shape (D, M) - weights.\n    b of shape (M,) - biases.\n    We will reshape each input batch x[i] into vector of dimension D = d1 * ... * dk.\n    As a result, input will be in form of matrix with shape (N, D).\n    It is needed for calculation product of input matrix over weights.\n    As weights' matrix has shape (D, M), then output resulted matrix will have shape (N, M).\n\nFunction returns a tuple of (fc_output, cache):\n\n    fc_output - output data of shape (N, M).\n    cache - tuple of shape (x, w, b, cnn_params), that is needed in backward pass.\n\"\"\"\n\n\n# Defining function for Naive Forward Pass for Fully-Connected Layer.\ndef fc_forward(x, w, b):\n    # Cache for output\n    cache = (x, w, b)\n\n    # Reshaping input data with N batches into matrix with N rows\n    N = x.shape[0]\n    x_reshaped = x.reshape(N, -1)\n    # By using '-1' we say that number of column is unknown, but number of rows N is known\n    # Resulted matrix will be with N rows and D columns\n    # Example:\n    # x = np.random.randint(0, 9, (2, 3, 3))\n    # print(x.shape)  # (2, 3, 3)\n    # print(x)\n    #             [[[3 6 5]\n    #               [6 3 2]\n    #               [1 0 0]]\n    #\n    #              [[8 5 8]\n    #               [7 5 2]\n    #               [2 1 6]]]\n    #\n    # x = x.reshape(2, -1)\n    # print(x.shape)  # (2, 9)\n    # print(x)\n    #             [[3 6 5 6 3 2 1 0 0]\n    #              [8 5 8 7 5 2 2 1 6]]\n\n    # Implementing Affine Forward Pass.\n    # Calculating product of input data over weights\n    fc_output = np.dot(x_reshaped, w) + b\n\n    # Returning resulted matrix with shape of (N, M)\n    return fc_output, cache\n","8fd5049b":"\"\"\"\nDefining function for Naive Backward Pass for Fully-Connected Layer (also known as Affine Layer).\n\nInput consists of following:\n\n    derivatives_out - upstream derivatives of shape (N, M).\n    cache - tuple of (x, w, b), where:\n        x of shape (N, d1, ..., dk) - input data.\n        w of shape (D, M) - weights.\n        b of shape (M,) - biases.\n\nFunction returns a tuple of (dx, dw, db):\n\n    dx - gradient with respect to x of shape (N, d1, ..., dk).\n    dw - gradient with respect to w of shape (D, M).\n    db - gradient with respect to b of shape (M,).\n\"\"\"\n\n\n# Defining function for Naive Backward Pass for Fully-Connected Layer.\ndef fc_backward(derivatives_out, cache):\n    # Preparing variables for input, weights and biases from cache\n    x, w, b = cache\n\n    # Implementing backward pass for Affine Layer\n    # Calculating gradient with respect to x and reshaping to make shape as in x\n    dx = np.dot(derivatives_out, w.T).reshape(x.shape)\n    # Calculating gradient with respect to w\n    # Reshaping input data with N batches into matrix with N rows and D columns\n    N = x.shape[0]\n    x = x.reshape(N, -1)\n    dw = np.dot(x.T, derivatives_out)\n    # Calculating gradient with respect to b\n    db = np.dot(np.ones(dx.shape[0]), derivatives_out)\n\n    # Returning calculated gradients\n    return dx, dw, db\n","376c1078":"\"\"\"\nDefining function for Naive Forward Pass for ReLU activation.\nReLU is the abbreviation for Rectified Linear Unit.\n\nInput consists of following:\n\n    x of any shape - input data.\n\nFunction returns a tuple of (relu_output, cache):\n\n    relu_output - output data of the same shape as x.\n    cache - is x, that is needed in backward pass.\n\"\"\"\n\n\n# Defining function for Naive Forward Pass for ReLU activation.\ndef relu_forward(x):\n    # Cache for output\n    cache = x\n\n    # Implementing ReLU forward pass\n    # Numbers that are less than zero will be changed to 0\n    relu_output = np.maximum(0, x)\n\n    # Returning calculated ReLU output\n    return relu_output, cache\n","4b14c98c":"# Defining shape for input data x\nx_shape = (2, 9)\n\n# Generating data from -9 to 9 and with x_shape\nx = np.random.randint(-9, 9, x_shape)\n\n# Implementing ReLU activation\nresult, cache = relu_forward(x)\n\n# Showing results\nprint(cache)\nprint(result)\n","34afe28b":"\"\"\"\nDefining function for Naive Backward Pass for ReLU activation.\n\nInput consists of following:\n\n    derivatives_out - upstream derivatives of any shape.\n    cache - is x, of the same shape as derivatives_out.\n\nFunction returns a tuple of (relu_output, cache):\n\n    dx - gradient with respect to x.\n\"\"\"\n\n\ndef relu_backward(derivatives_out, cache):\n    # Preparing variable for input from cache\n    x = cache\n\n    # Implementing ReLU backward pass\n    # Defining array with the same shape as x\n    # Filling with 'True' and 'False' according to the condition 'x > 0'\n    temp = x > 0\n    # Calculating gradient with respect to x\n    dx = temp * derivatives_out\n\n    # ReLU backward pass will return gradient with respect to x\n    # Each element of the array will be filled with '0'\n    # or derivative if that value in x was more than 0\n\n    # Returning calculated ReLU output\n    return dx\n","6b22fe61":"# Defining shape for input data x and upstream derivatives\nx_shape = (2, 9)\nderivatives_out_shape = (2, 9)\n\n# Generating data from -9 to 9 and with x_shape and derivatives_out_shape\nx = np.random.randint(-9, 9, x_shape)\nderivatives_out = np.random.randint(-9, 9, derivatives_out_shape)\n\n# Implementing ReLU Forward Pass\nresult, cache = relu_forward(x)\n\n# Implementing ReLU Backward Pass\ndx = relu_backward(derivatives_out, cache)\n\n# ReLU backward pass will return gradient with respect to x\n# Each element of the array will be filled with '0'\n# or derivative if that value in x was more than 0\n\n# Showing results\nprint('Input x:\\n', cache)\nprint('\\nUpstream derivatives:\\n', derivatives_out)\nprint('\\nGradient with respect to x:\\n', dx)\n","f44e4019":"\"\"\"\nDefining function for Softmax Classification Loss.\n\nInput consists of following:\n\n    x of shape (N, C) - input data, where x[i, j] is score for the j-th class for the i-th input.\n    y of shape (N, ) - vector of labels, where y[i] is the label for x[i] and 0 <= y[i] < C.\n\nFunction returns a tuple of (loss, dx):\n\n    loss - scalar giving the Logarithmic Loss.\n    dx - gradient of loss with respect to x.\n\"\"\"\n\n\ndef softmax_loss(x, y):\n    # Calculating probabilities\n    shifted_logits = x - np.max(x, axis=1, keepdims=True)\n    z = np.sum(np.exp(shifted_logits), axis=1, keepdims=True)\n    log_probabilities = shifted_logits - np.log(z)\n    probabilities = np.exp(log_probabilities)\n\n    # Getting number of samples\n    N = x.shape[0]\n\n    # Calculating Logarithmic Loss\n    loss = -np.sum(log_probabilities[np.arange(N), y]) \/ N\n\n    # Calculating gradient\n    dx = probabilities\n    dx[np.arange(N), y] -= 1\n    dx \/= N\n\n    # Returning tuple of Logarithmic loss and gradient\n    return loss, dx\n","32e27a4c":"\"\"\"\"\"\"\"\"\"\nInitializing ConvNet1 will be done with following architecture:\nInput --> Conv --> ReLU --> Pool --> FC --> ReLU --> FC --> Softmax\n\nCNN will operate with mini-batches of Input data with shape (N, C, H, W),\nwhere N is number of images, each with C channels, height H and width W.\n\"\"\"\n\n\n# Creating class for ConvNet1\nclass ConvNet1(object):\n\n    \"\"\"\"\"\"\"\"\"\n    Initializing new Network\n    Input consists of following:\n        input_dimension of shape (C, H, W) - dimension of input data, \n                                             where C channels, with height H and with width W.\n        number_of_filters - number of filters to use in Convolutional Layer.\n        size_of_filter - size of filter to use in Convolutional Layer.\n        hidden_dimension - number of neurons to use in Fully-Connected Hidden Layer.\n        number_of_classes - number of scores to produce from the final Fully-Connected Layer.\n        weight_scale - scalar giving standard deviation for random initialization of weights.\n        regularization - scala giving L2 regularization strength.\n        dtype - numpy datatype to use for computation.\n    \"\"\"\n\n    def __init__(self, input_dimension=(3, 32, 32), number_of_filters=32, size_of_filter=7,\n                 hidden_dimension=100, number_of_classes=10, weight_scale=1e-3, regularization=0.0,\n                 dtype=np.float32):\n\n        # Defining dictionary to store all weights and biases\n        self.params = {}\n        # Defining variable for regularization\n        self.regularization = regularization\n        # Defining datatype for computation\n        self.dtype = dtype\n        # Getting input dimension C - channels, H - height, W - width\n        C, H, W = input_dimension\n        # Getting filter size which is squared\n        HH = WW = size_of_filter\n        # Getting number of filters\n        F = number_of_filters\n        # Getting number of neurons in Hidden Fully-Connected Layer\n        Hh = hidden_dimension\n        # Getting number of classes in Output Fully-Connected Layer\n        Hclass = number_of_classes\n\n        # Initializing weights and biases for Convolutional Layer (which is only one here)\n        # Weights are the volume of shape (F, C, HH, WW),\n        # where F is number of filters, each with C channels, height HH and width WW\n        # Biases initialized with 0 and shape (F,)\n        self.params['w1'] = weight_scale * np.random.rand(F, C, HH, WW)\n        self.params['b1'] = np.zeros(F)\n\n        \"\"\"\n        Defining parameters for Convolutional Layer (which is only one here):\n            'cnn_params' is a dictionary with following keys:\n                'stride' - step for sliding,\n                'pad' - zero-pad frame around input that is calculated by following formula:\n                    pad = (size_of_filter - 1) \/ 2\n        \n        Calculating spatial size of output image volume (feature maps) by following formulas:\n            feature_maps - output data of feature maps of shape (N, F, Hc, Wc) where:\n                Hc = 1 + (H + 2 * pad - HH) \/ stride\n                Wc = 1 + (W + 2 * pad - WW) \/ stride\n                    where,\n                    N here is the same as we have it as number of input images,\n                    F here is as number of channels of each N (that are now as feature maps),\n                    HH and WW are height and width of filter.\n        \n        Input for CNN Layer has shape of (N, C, H, W)\n        Output from CNN Layer has shape of (N, F, Hc, Wc)\n        \"\"\"\n\n        self.cnn_params = {'stride': 1, 'pad': int((size_of_filter - 1) \/ 2)}\n        Hc = int(1 + (H + 2 * self.cnn_params['pad'] - HH) \/ self.cnn_params['stride'])\n        Wc = int(1 + (W + 2 * self.cnn_params['pad'] - WW) \/ self.cnn_params['stride'])\n\n        \"\"\"\n        Defining parameters for Max Pooling Layer:\n            'pooling_params' is a dictionary with following keys:\n                'pooling_height' - height of pooling region,\n                'pooling_width' - width of pooling region,\n                'stride' - step (distance) between pooling regions.\n    \n        Calculating spatial size of output image volume after Max Pooling Layer\n        by following formulas:\n            output resulted data of shape (N, C, Hp, Wp) where:\n                Hp = 1 + (Hc - pooling_height) \/ stride\n                Wp = 1 + (Wc - pooling_width) \/ stride\n                    where,\n                    N here is the same as we have it as number of filters,\n                    C here is as number of channels of each N,\n                    Hc and Wc are height and width of output feature maps\n                    from Convolutional layer.\n                    \n        Input for Max Pooling Layer has shape of (N, F, Hc, Wc)\n        Output from Max Pooling Layer has shape of (N, F, Hp, Wp)\n        \"\"\"\n\n        self.pooling_params = {'pooling_height': 2, 'pooling_width': 2, 'stride': 2}\n        Hp = int(1 + (Hc - self.pooling_params['pooling_height']) \/ self.pooling_params['stride'])\n        Wp = int(1 + (Wc - self.pooling_params['pooling_width']) \/ self.pooling_params['stride'])\n\n        \"\"\"\n        Input for hidden Fully-Connected Layer has shape of (N, F * Hp * Wp)\n        Output from hidden Fully-Connected Layer has shape of (N, Hh)\n        \"\"\"\n\n        # Initializing weights and biases for Fully-Connected Layer\n        # Weights are the volume of shape (F * Hp * Wp, Hh)\n        # Where F * Hp * Wp performs full connections\n        # from Max Pooling layer to Hidden Fully-Connected Layer\n        # Hh is number of neurons\n        # Biases initialized with 0 and shape (Hh,)\n        self.params['w2'] = weight_scale * np.random.rand(F * Hp * Wp, Hh)\n        self.params['b2'] = np.zeros(Hh)\n\n        \"\"\"\n        Input for output Fully-Connected Layer has shape of (N, Hh)\n        Output from output Fully-Connected Layer has shape of (N, Hclass)\n        \"\"\"\n\n        # Initializing weights and biases for output Fully-Connected Layer\n        # Weights are the volume of shape (Hh, Hclass)\n        # Weights perform full connections from Hidden to Output Layer\n        # Hclass is number of neurons\n        # Biases initialized with 0 and shape (Hh,)\n        self.params['w3'] = weight_scale * np.random.rand(Hh, Hclass)\n        self.params['b3'] = np.zeros(Hclass)\n\n        # After initialization of Neural Network is done it is needed to set values as 'dtype'\n        # Going through all keys from dictionary\n        # Setting to all values needed 'dtype'\n        for d_key, d_value in self.params.items():\n            self.params[d_key] = d_value.astype(dtype)\n\n    \"\"\"\n    Evaluating loss for training ConvNet1.\n    \n    Input consists of following:\n    \n        x of shape (N, C, H, W) - input data, \n            where N is number of images and every of them with C channels, \n            with height H and with width W.\n        y of shape (N, ) - vector of labels, where y[i] is the label for x[i].\n    \n    Function returns a tuple of (loss, gradients):\n    \n        loss - scalar giving the Logarithmic Loss.\n        gradients - dictionary with the same keys as self.params, \n            mapping parameter names to gradients of loss with respect to those parameters.\n    \"\"\"\n\n    # Defining function for evaluating Loss.\n    def loss_for_training(self, x, y):\n        # Getting weights and biases\n        w1, b1 = self.params['w1'], self.params['b1']\n        w2, b2 = self.params['w2'], self.params['b2']\n        w3, b3 = self.params['w3'], self.params['b3']\n\n        # Implementing forward pass for ConvNet1 and computing scores for every input\n        # Forward pass:\n        # Input --> Conv --> ReLU --> Pool --> FC --> ReLU --> FC --> Softmax\n        cnn_output, cache_cnn = cnn_forward_naive(x, w1, b1, self.cnn_params)\n        relu_output_1, cache_relu_1 = relu_forward(cnn_output)\n        pooling_output, cache_pooling = max_pooling_forward_naive(relu_output_1, self.pooling_params)\n        fc_hidden, cache_fc_hidden = fc_forward(pooling_output, w2, b2)\n        relu_output_2, cache_relu_2 = relu_forward(fc_hidden)\n        scores, cache_fc_output = fc_forward(relu_output_2, w3, b3)\n\n        # Computing loss and gradients\n        loss, d_scores = softmax_loss(scores, y)\n\n        # Adding L2 regularization\n        loss += 0.5 * self.regularization * np.sum(np.square(w1))\n        loss += 0.5 * self.regularization * np.sum(np.square(w2))\n        loss += 0.5 * self.regularization * np.sum(np.square(w3))\n\n        # Implementing backward pass for ConvNet1\n        # Backward pass through FC output\n        dx3, dw3, db3 = fc_backward(d_scores, cache_fc_output)\n        # Adding L2 regularization\n        dw3 += self.regularization * w3\n\n        # Backward pass through ReLU and FC Hidden\n        d_relu_2 = relu_backward(dx3, cache_relu_2)\n        dx2, dw2, db2 = fc_backward(d_relu_2, cache_fc_hidden)\n        # Adding L2 regularization\n        dw2 += self.regularization * w2\n\n        # Backward pass through Pool, ReLU and Conv\n        d_pooling = max_pooling_backward_naive(dx2, cache_pooling)\n        d_relu_1 = relu_backward(d_pooling, cache_relu_1)\n        dx1, dw1, db1 = cnn_backward_naive(d_relu_1, cache_cnn)\n        # Adding L2 regularization\n        dw1 += self.regularization * w1\n\n        # Putting resulted derivatives into gradient dictionary\n        gradients = dict()\n        gradients['w1'] = dw1\n        gradients['b1'] = db1\n        gradients['w2'] = dw2\n        gradients['b2'] = db2\n        gradients['w3'] = dw3\n        gradients['b3'] = db3\n\n        # Returning loss and gradients\n        return loss, gradients\n\n    \"\"\"\n    Calculating Scores for Predicting.\n    \n    Input consists of following:\n    \n        x of shape (N, C, H, W) - input data, \n            where N is number of images and every of them with C channels, \n            with height H and with width W.\n    \n    Function returns:\n    \n        scores of shape (N, C) - classification scores, \n            where score [i, C] is the classification score for x[i] and class C.\n    \"\"\"\n\n    # Defining function for calculating Scores for Predicting.\n    def scores_for_predicting(self, x):\n        # Getting weights and biases\n        w1, b1 = self.params['w1'], self.params['b1']\n        w2, b2 = self.params['w2'], self.params['b2']\n        w3, b3 = self.params['w3'], self.params['b3']\n\n        # Implementing forward pass for ConvNet1 and computing scores for every input\n        # Forward pass:\n        # Input --> Conv --> ReLU --> Pool --> FC --> ReLU --> FC --> Softmax\n        cnn_output, _ = cnn_forward_naive(x, w1, b1, self.cnn_params)\n        relu_output_1, _ = relu_forward(cnn_output)\n        pooling_output, _ = max_pooling_forward_naive(relu_output_1, self.pooling_params)\n        affine_hidden, _ = fc_forward(pooling_output, w2, b2)\n        relu_output_2, _ = relu_forward(affine_hidden)\n        scores, _ = fc_forward(relu_output_2, w3, b3)\n\n        # Returning scores for every input\n        return scores\n","4ada3cd8":"# After CNN was built we can Initialize new Model and chek dimensions of the weights for every Layer\n\n# Creating instance of class and Initializing new Model\nmodel = ConvNet1(hidden_dimension=500)\n\n# Generating data\nN = 5\nx = np.random.randn(N, 3, 32, 32)  # Input images\ny = np.random.randint(10, size=N)  # Coresponding labels\n\n# Calculating loss and gradients\nloss, gradients = model.loss_for_training(x, y)\n\n# Going through all parameters after Initialization and after calculating gradients with Backward Pass\n# Checking if dimensions are correct\nfor param_name in model.params:\n    print(param_name, model.params[param_name].shape)  # After Initialization\n    print(param_name, gradients[param_name].shape)  # After Backward Pass\n    print()\n","97eb3e13":"# Creating function for updating parameters based on Adam method\ndef adam(w, dw, config=None):\n    # Checking if any configuration was not passed\n    # Then, creating config as dictionary\n    if config is None:\n        config = {}\n\n    # Assigning values by default\n    # If values were passed in config dictionary, then this will not influence\n    config.setdefault('learning_rate', 1e-3)\n    config.setdefault('beta1', 0.9)\n    config.setdefault('beta2', 0.999)\n    config.setdefault('epsilon', 1e-8)\n    config.setdefault('m', np.zeros_like(w))\n    config.setdefault('v', np.zeros_like(w))\n    config.setdefault('t', 0)\n\n    config['t'] += 1\n    config['m'] = config['beta1'] * config['m'] + (1 - config['beta1']) * dw\n    config['v'] = config['beta2'] * config['v'] + (1 - config['beta2']) * (dw**2)\n\n    mt = config['m'] \/ (1 - config['beta1']**config['t'])\n    vt = config['v'] \/ (1 - config['beta2']**config['t'])\n\n    # Implementing updating\n    next_w = w - config['learning_rate'] * mt \/ (np.sqrt(vt) + config['epsilon'])\n\n    # Returning updated parameter and configuration\n    return next_w, config\n ","f2e47193":"\"\"\"\nIt encapsulates all the logic necessary for training classification model.\nIt performs Stochastic Gradient Descent using Vanilla SGD updating rule\n\nClass accepts both training and validation data and labels.\nConsequently, it can periodically check classification accuracy on both\ntraining and validation data to watch out for overfitting.\n\nFirstly, for training, instance of Class will be constructed with model of classifier,\ndatasets, and other options like learning rate, batch size, etc.\nAfter that, method 'run()' will be called to run optimization procedure and train the model.\n\nClass works on model object that have to contain following:\n    model.params has to be a dictionary mapping string parameters names\n    to numpy arrays with values.\n\n    model.loss_for_training(x, y) has to be a functions that computes loss and gradients.\n    Loss will be a scalar and gradients will be a dictionary with the same keys\n    as in model.params mapping parameters names to gradients with respect to those parameters.\n\n    model.scores_for_predicting(x) has to be a function that computes classification scores.\n    Scores will be an array of shape (N, C) giving classification scores for x,\n    where scores[i, c] gives the score of class c for x[i].\n\n\n\"\"\"\n\n\n# Creating class for training\nclass Train(object):\n\n    \"\"\"\"\"\"\"\"\"\n    Initializing new Train class\n    Input consists of following required and Optional arguments.\n    \n    Required arguments consist of following:\n        model - a modal object conforming parameters as described above,\n        data - a dictionary with training and validating data.\n    \n    Optional arguments (**kwargs) consist of following:\n        update_rule - a string giving the name of an update rule in optimize_rules.py,\n        optimization_config - a dictionary containing hyperparameters that will be passed \n                              to the chosen update rule. Each update rule requires different\n                              parameters, but all update rules require a 'learning_rate' parameter.\n        learning_rate_decay - a scalar for learning rate decay. After each epoch the 'learning_rate'\n                              is multiplied by this value,\n        batch_size - size of minibatches used to compute loss and gradients during training,\n        number_of_epochs - the number of epoch to run for during training,\n        print_every - integer number that corresponds to printing loss every 'print_every' iterations,\n        verbose_mode - boolean that corresponds to condition whether to print details or not. \n\n    \"\"\"\n\n    def __init__(self, model, data, **kwargs):\n        # Preparing required arguments\n        self.model = model\n        self.x_train = data['x_train']\n        self.y_train = data['y_train']\n        self.x_validation = data['x_validation']\n        self.y_validation = data['y_validation']\n\n        # Preparing optional arguments\n        # Unpacking keywords of arguments\n        # Using 'pop' method and setting at the same time default value\n        self.optimization_config = kwargs.pop('optimization_config', {})  # Default is '{}'\n        self.learning_rate_decay = kwargs.pop('learning_rate_decay', 1.0)  # Default is '1.0'\n        self.batch_size = kwargs.pop('batch_size', 100)  # Default is '100'\n        self.number_of_epochs = kwargs.pop('number_of_epochs', 10)  # Default is '10'\n        self.print_every = kwargs.pop('print_every', 10)  # Default is '10'\n        self.verbose_mode = kwargs.pop('verbose_mode', True)  # Default is 'True'\n\n        # Checking if there are extra keyword arguments and raising an error\n        if len(kwargs) > 0:\n            extra = ', '.join(k for k in kwargs.keys())\n            raise ValueError('Extra argument:', extra)\n\n        # Assigning to 'self.update_rule' with the real function\n        self.update_rule = adam\n\n        # Implementing '_reset' function\n        self._reset()\n\n    # Creating 'reset' function for defining variables for optimization\n    def _reset(self):\n        # Setting up variables\n        self.current_epoch = 0\n        self.best_validation_accuracy = 0\n        self.best_params = {}\n        self.loss_history = []\n        self.train_accuracy_history = []\n        self.validation_accuracy_history = []\n\n        # Making deep copy of 'optimization_config' for every parameter at every layer\n        # It means that at least learning rate will be for every parameter at every layer\n        self.optimization_configurations = {}\n        for p in self.model.params:\n            d = {k: v for k, v in self.optimization_config.items()}\n            self.optimization_configurations[p] = d\n\n    # Creating function 'step' for making single gradient update\n    def _step(self):\n        # Making minibatch from training data\n        # Getting total number of training images\n        number_of_training_images = self.x_train.shape[0]\n        # Getting random batch of 'batch_size' size from total number of training images\n        batch_mask = np.random.choice(number_of_training_images, self.batch_size)\n        # Getting training dataset according to the 'batch_mask'\n        x_batch = self.x_train[batch_mask]\n        y_batch = self.y_train[batch_mask]\n\n        # Calculating loss and gradient for current minibatch\n        loss, gradient = self.model.loss_for_training(x_batch, y_batch)\n\n        # Adding calculated loss to the history\n        self.loss_history.append(loss)\n\n        # Implementing updating for all parameters (weights and biases)\n        # Going through all parameters\n        for p, v in self.model.params.items():\n            # Taking current value of derivative for current parameter\n            dw = gradient[p]\n            # Defining configuration for current parameter\n            config_for_current_p = self.optimization_configurations[p]\n            # Implementing updating and getting next values\n            next_w, next_configuration = self.update_rule(v, dw, config_for_current_p)\n            # Updating value in 'params'\n            self.model.params[p] = next_w\n            # Updating value in 'optimization_configurations'\n            self.optimization_configurations[p] = next_configuration\n\n    # Creating function for checking accuracy of the model on the current provided data\n    # Accuracy will be used in 'train' function for both training dataset and for testing dataset\n    # Depending on which input into the model will be provided\n    def check_accuracy(self, x, y, number_of_samples=None, batch_size=100):\n\n        \"\"\"\"\"\"\"\"\"\n        Input consists of following:\n            x of shape (N, C, H, W) - N data, each with C channels, height H and width W,\n            y - vector of labels of shape (N,),\n            number_of_samples - subsample data and test model only on this number of data,\n            batch_size - split x and y into batches of this size to avoid using too much memory.\n\n        Function returns:\n            accuracy - scalar number giving percentage of images \n                       that were correctly classified by model.\n        \"\"\"\n\n        # Getting number of input images\n        N = x.shape[0]\n\n        # Subsample data if 'number_of_samples' is not None\n        # and number of input images is more than 'number_of_samples'\n        if number_of_samples is not None and N > number_of_samples:\n            # Getting random batch of 'number_of_samples' size from total number of input images\n            batch_mask = np.random.choice(N, number_of_samples)\n            # Reassigning (decreasing) N to 'number_of_samples'\n            N = number_of_samples\n            # Getting dataset for checking accuracy according to the 'batch_mask'\n            x = x[batch_mask]\n            y = y[batch_mask]\n\n        # Defining and calculating number of batches\n        # Also, making it as integer with 'int()'\n        number_of_batches = int(N \/ batch_size)\n        # Increasing number of batches if there is no exact match of input images over 'batch_size'\n        if N % batch_size != 0:\n            number_of_batches += 1\n\n        # Defining variable for storing predicted class for appropriate input image\n        y_predicted = []\n\n        # Computing predictions in batches\n        # Going through all batches defined by 'number_of_batches'\n        for i in range(number_of_batches):\n            # Defining start index and end index for current batch of images\n            s = i * batch_size\n            e = (i + 1) * batch_size\n            # Getting scores by calling function 'loss_for predicting' from model\n            scores = self.model.scores_for_predicting(x[s:e])\n            # Appending result to the list 'y_predicted'\n            # Scores is given for each image with 10 numbers of predictions for each class\n            # Getting only one class for each image with maximum value\n            y_predicted.append(np.argmax(scores, axis=1))\n            # Example\n            #\n            # a = np.arange(6).reshape(2, 3)\n            # print(a)\n            #    ([[0, 1, 2],\n            #     [3, 4, 5]])\n            #\n            # print(np.argmax(a))\n            # 5\n            #\n            # np.argmax(a, axis=0)\n            #     ([1, 1, 1])\n            #\n            # np.argmax(a, axis=1)\n            #     ([2, 2])\n            #\n            # Now we have each image with its only one predicted class (index of each row)\n            # but not with 10 numbers for each class\n\n        # Concatenating list of lists and making it as numpy array\n        y_predicted = np.hstack(y_predicted)\n\n        # Finally, we compare predicted class with correct class for all input images\n        # And calculating mean value among all values of following numpy array\n        # By saying 'y_predicted == y' we create numpy array with True and False values\n        # 'np.mean' function will return average of the array elements\n        # The average is taken over the flattened array by default\n        accuracy = np.mean(y_predicted == y)\n\n        # Returning accuracy\n        return accuracy\n\n    # Creating function for training the model\n    def run(self):\n        # Getting total number of training images\n        number_of_training_images = self.x_train.shape[0]\n        # Calculating number of iterations per one epoch\n        # If 'number_of_training_images' is less than 'self.batch_size' then we chose '1'\n        iterations_per_one_epoch = int(max(number_of_training_images \/ self.batch_size, 1))\n        # Calculating total number of iterations for all process of training\n        # Also, making it as integer with 'int()'\n        iterations_total = int(self.number_of_epochs * iterations_per_one_epoch)\n\n        # Running training process in the loop for total number of iterations\n        for t in range(iterations_total):\n            # Making single step for updating all parameters\n            self._step()\n\n            # Checking if training loss has to be print every 'print_every' iteration\n            if self.verbose_mode and t % self.print_every == 0:\n                # Printing current iteration and showing total number of iterations\n                # Printing currently saved loss from loss history\n                print('Iteration: ' + str(t + 1) + '\/' + str(iterations_total) + ',',\n                      'loss =', self.loss_history[-1])\n\n            # Defining variable for checking end of current epoch\n            end_of_current_epoch = (t + 1) % iterations_per_one_epoch == 0\n\n            # Checking if it is the end of current epoch\n            if end_of_current_epoch:\n                # Incrementing epoch counter\n                self.current_epoch += 1\n                # Decaying learning rate for every parameter at every layer\n                for k in self.optimization_configurations:\n                    self.optimization_configurations[k]['learning_rate'] *= self.learning_rate_decay\n\n            # Defining variables for first and last iterations\n            first_iteration = (t == 0)\n            last_iteration = (t == iterations_total - 1)\n\n            # Checking training and validation accuracy\n            # At the first iteration, the last iteration, and at the end of every epoch\n            if first_iteration or last_iteration or end_of_current_epoch:\n                # Checking training accuracy with 1000 samples\n                training_accuracy = self.check_accuracy(self.x_train, self.y_train,\n                                                        number_of_samples=1000)\n\n                # Checking validation accuracy\n                # We don't specify number of samples as it has only 1000 images itself\n                validation_accuracy = self.check_accuracy(self.x_validation, self.y_validation)\n\n                # Adding calculated accuracy to the history\n                self.train_accuracy_history.append(training_accuracy)\n                self.validation_accuracy_history.append(validation_accuracy)\n\n                # Checking if the 'verbose_mode' is 'True' then printing details\n                if self.verbose_mode:\n                    # Printing current epoch over total amount of epochs\n                    # And training and validation accuracy\n                    print('Epoch: ' + str(self.current_epoch) + '\/' + str(self.number_of_epochs) + ',',\n                          'Training accuracy = ' + str(training_accuracy) + ',',\n                          'Validation accuracy = ' + str(validation_accuracy))\n\n                # Tracking the best model parameters by comparing validation accuracy\n                if validation_accuracy > self.best_validation_accuracy:\n                    # Assigning current validation accuracy to the best validation accuracy\n                    self.best_validation_accuracy = validation_accuracy\n                    # Reset 'self.best_params' dictionary\n                    self.best_params = {}\n                    # Assigning current parameters to the best parameters variable\n                    for k, v in self.model.params.items():\n                        self.best_params[k] = v\n\n        # At the end of training process swapping best parameters to the model\n        self.model.params = self.best_params\n\n        # Saving trained model parameters into 'pickle' file\n        with open('model_params_ConvNet1.pickle', 'wb') as f:\n            pickle.dump(self.model.params, f)\n\n        # Saving loss, training accuracy and validation accuracy histories into 'pickle' file\n        history_dictionary = {'loss_history': self.loss_history,\n                              'train_accuracy_history': self.train_accuracy_history,\n                              'validation_history': self.validation_accuracy_history}\n        with open('model_histories_ConvNet1.pickle', 'wb') as f:\n            pickle.dump(history_dictionary, f)\n","f8d3ca84":"# Opening file for reading in binary mode\nwith open('..\/input\/cifar10-preprocessed\/data.pickle', 'rb') as f:\n    d = pickle.load(f, encoding='latin1')  # dictionary type\n\n# Showing loaded data from file\nfor i, j in d.items():\n    print(i + ':', j.shape)\n\n# x_test: (1000, 3, 32, 32)\n# y_test: (1000,)\n# x_validation: (1000, 3, 32, 32)\n# y_validation: (1000,)\n# y_train: (49000,)\n# x_train: (49000, 3, 32, 32)\n","af09f47c":"# # Defining number of training examples\n# number_of_training_data = 10\n\n# # Preparing data by slicing in 'data' dictionary appropriate array\n# small_data = {\n#     'x_train':d['x_train'][:number_of_training_data],\n#     'y_train':d['y_train'][:number_of_training_data],\n#     'x_validation':d['x_validation'],\n#     'y_validation':d['y_validation']\n# }\n\n# # Creating instance of class for 'ConvNet1' and initializing model\n# model = ConvNet1(weight_scale=1e-2, hidden_dimension=100)\n\n# # Creating instance of class for 'Train' and initializing model\n# train = Train(model,\n#                 small_data,\n#                 optimization_config={'learning_rate':1e-3},\n#                 learning_rate_decay=1.0,\n#                 batch_size=50,\n#                 number_of_epochs=40,\n#                 print_every=1,\n#                 verbose_mode=True\n#                )\n\n# # Running training process\n# train.run()\n\n# # Iteration: 1\/40, loss = 2.304156330660657\n# # Epoch: 1\/40, Training accuracy = 0.2, Validation accuracy = 0.104\n# # Iteration: 2\/40, loss = 1.9239178674475683\n# # Epoch: 2\/40, Training accuracy = 0.2, Validation accuracy = 0.104\n# # Iteration: 3\/40, loss = 1.961843083593952\n# # Epoch: 3\/40, Training accuracy = 0.3, Validation accuracy = 0.114\n# # Iteration: 4\/40, loss = 1.7088626381520096\n# # Epoch: 4\/40, Training accuracy = 0.3, Validation accuracy = 0.112\n# # Iteration: 5\/40, loss = 1.790893648450029\n# # Epoch: 5\/40, Training accuracy = 0.3, Validation accuracy = 0.113\n# # Iteration: 6\/40, loss = 1.553063320728389\n# # Epoch: 6\/40, Training accuracy = 0.4, Validation accuracy = 0.118\n# # Iteration: 7\/40, loss = 1.504731016906359\n# # Epoch: 7\/40, Training accuracy = 0.6, Validation accuracy = 0.127\n# # Iteration: 8\/40, loss = 1.3778760651924922\n# # Epoch: 8\/40, Training accuracy = 0.7, Validation accuracy = 0.128\n# # Iteration: 9\/40, loss = 1.2700900299913496\n# # Epoch: 9\/40, Training accuracy = 0.7, Validation accuracy = 0.126\n# # Iteration: 10\/40, loss = 0.8992967041177883\n# # Epoch: 10\/40, Training accuracy = 0.7, Validation accuracy = 0.124\n# # Iteration: 11\/40, loss = 0.9165220925946536\n# # Epoch: 11\/40, Training accuracy = 0.8, Validation accuracy = 0.128\n# # Iteration: 12\/40, loss = 0.9491060479837771\n# # Epoch: 12\/40, Training accuracy = 0.8, Validation accuracy = 0.127\n# # Iteration: 13\/40, loss = 0.7976666358424253\n# # Epoch: 13\/40, Training accuracy = 0.8, Validation accuracy = 0.13\n# # Iteration: 14\/40, loss = 0.8548372424907567\n# # Epoch: 14\/40, Training accuracy = 0.8, Validation accuracy = 0.13\n# # Iteration: 15\/40, loss = 0.5813599067303247\n# # Epoch: 15\/40, Training accuracy = 0.8, Validation accuracy = 0.125\n# # Iteration: 16\/40, loss = 0.6966588606603552\n# # Epoch: 16\/40, Training accuracy = 0.8, Validation accuracy = 0.118\n# # Iteration: 17\/40, loss = 0.5626237198809396\n# # Epoch: 17\/40, Training accuracy = 0.8, Validation accuracy = 0.119\n# # Iteration: 18\/40, loss = 0.26339598914163065\n# # Epoch: 18\/40, Training accuracy = 0.9, Validation accuracy = 0.118\n# # Iteration: 19\/40, loss = 0.29878547180592546\n# # Epoch: 19\/40, Training accuracy = 0.9, Validation accuracy = 0.115\n# # Iteration: 20\/40, loss = 0.4843359893296553\n# # Epoch: 20\/40, Training accuracy = 0.9, Validation accuracy = 0.11\n# # Iteration: 21\/40, loss = 0.35380002193269516\n# # Epoch: 21\/40, Training accuracy = 0.9, Validation accuracy = 0.109\n# # Iteration: 22\/40, loss = 0.3064678618569846\n# # Epoch: 22\/40, Training accuracy = 0.9, Validation accuracy = 0.107\n# # Iteration: 23\/40, loss = 0.268992005060759\n# # Epoch: 23\/40, Training accuracy = 1.0, Validation accuracy = 0.104\n# # Iteration: 24\/40, loss = 0.1008331286872808\n# # Epoch: 24\/40, Training accuracy = 1.0, Validation accuracy = 0.105\n# # Iteration: 25\/40, loss = 0.10162442788513885\n# # Epoch: 25\/40, Training accuracy = 1.0, Validation accuracy = 0.114\n# # Iteration: 26\/40, loss = 0.0904764151684745\n# # Epoch: 26\/40, Training accuracy = 1.0, Validation accuracy = 0.118\n# # Iteration: 27\/40, loss = 0.05986395317667737\n# # Epoch: 27\/40, Training accuracy = 1.0, Validation accuracy = 0.118\n# # Iteration: 28\/40, loss = 0.06656748416668198\n# # Epoch: 28\/40, Training accuracy = 1.0, Validation accuracy = 0.121\n# # Iteration: 29\/40, loss = 0.03516100235003429\n# # Epoch: 29\/40, Training accuracy = 1.0, Validation accuracy = 0.119\n# # Iteration: 30\/40, loss = 0.025043994149305148\n# # Epoch: 30\/40, Training accuracy = 1.0, Validation accuracy = 0.12\n# # Iteration: 31\/40, loss = 0.011630922092309436\n# # Epoch: 31\/40, Training accuracy = 1.0, Validation accuracy = 0.122\n# # Iteration: 32\/40, loss = 0.008378605154116384\n# # Epoch: 32\/40, Training accuracy = 1.0, Validation accuracy = 0.123\n# # Iteration: 33\/40, loss = 0.009034204059119416\n# # Epoch: 33\/40, Training accuracy = 1.0, Validation accuracy = 0.124\n# # Iteration: 34\/40, loss = 0.003657528897951924\n# # Epoch: 34\/40, Training accuracy = 1.0, Validation accuracy = 0.126\n# # Iteration: 35\/40, loss = 0.0029452484012359426\n# # Epoch: 35\/40, Training accuracy = 1.0, Validation accuracy = 0.132\n# # Iteration: 36\/40, loss = 0.007884038654341882\n# # Epoch: 36\/40, Training accuracy = 1.0, Validation accuracy = 0.131\n# # Iteration: 37\/40, loss = 0.005848302135786235\n# # Epoch: 37\/40, Training accuracy = 1.0, Validation accuracy = 0.129\n# # Iteration: 38\/40, loss = 0.00551834462304681\n# # Epoch: 38\/40, Training accuracy = 1.0, Validation accuracy = 0.131\n# # Iteration: 39\/40, loss = 0.0012599165138640512\n# # Epoch: 39\/40, Training accuracy = 1.0, Validation accuracy = 0.133\n# # Iteration: 40\/40, loss = 0.0009190822228068787\n# # Epoch: 40\/40, Training accuracy = 1.0, Validation accuracy = 0.134","84beb447":"# # Saving trained model parameters locally without commiting\n# from IPython.display import FileLink\n\n# FileLink('model_params_ConvNet1.pickle')\n","d704f6df":"# # Saving loss, training accuracy and validation accuracy histories locally without commiting\n# from IPython.display import FileLink\n\n# FileLink('model_histories_ConvNet1.pickle')\n","ac79d485":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (10.0, 8.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'\n\n\n# Opening file with history for reading in binary mode\nwith open('..\/input\/cifar10-preprocessed\/model_histories_ConvNet1_Overfitting.pickle', 'rb') as f:\n    history_dictionary = pickle.load(f, encoding='latin1')  # dictionary type, we use 'latin1' for python3\n\n    \n# Plotting history\nfig = plt.figure()\nplt.subplot(2, 1, 1)\nplt.plot(history_dictionary['loss_history'], '-o')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Overfitting small data', fontsize=20)\n\nplt.subplot(2, 1, 2)\nplt.plot(history_dictionary['train_accuracy_history'], '-o')\nplt.plot(history_dictionary['validation_history'], '-o')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\n\nplt.show()\n\n# Saving plot\nfig.savefig('Overfitting_Process.png')\nplt.close()\n","7c05ec16":"# # Creating instance of class for 'ConvNet1' and initializing model\n# model = ConvNet1(weight_scale=1e-3, hidden_dimension=500, regularization=1e-3)\n\n# # Creating instance of class for training and initializing model\n# train = Train(model,\n#                 d,\n#                 optimization_config={'learning_rate':1e-3},\n#                 learning_rate_decay=1.0,\n#                 batch_size=50,\n#                 number_of_epochs=10,\n#                 print_every=20,\n#                 verbose_mode=True\n#                )\n\n# # Running training process\n# train.run()","60f267e0":"# # Saving trained model parameters locally without commiting\n# from IPython.display import FileLink\n\n# FileLink('model_params_ConvNet1.pickle')\n","d2f95b84":"# # Saving loss, training accuracy and validation accuracy histories locally without commiting\n# from IPython.display import FileLink\n\n# FileLink('model_histories_ConvNet1.pickle')\n","9c8ecc03":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (10.0, 8.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'\n\n\n# Opening file with history for reading in binary mode\nwith open('..\/input\/cifar10-preprocessed\/model_histories_ConvNet1_Training.pickle', 'rb') as f:\n    history_dictionary = pickle.load(f, encoding='latin1')  # dictionary type, we use 'latin1' for python3\n\n    \n# Plotting history\nfig = plt.figure()\nplt.subplot(2, 1, 1)\nplt.plot(history_dictionary['loss_history'], '-o')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Training of Model', fontsize=20)\n\nplt.subplot(2, 1, 2)\nplt.plot(history_dictionary['train_accuracy_history'], '-o')\nplt.plot(history_dictionary['validation_history'], '-o')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\n\nplt.show()\n# Saving plot\nfig.savefig('Training_Process.png')\nplt.close()\n","25f79273":"# Opening file for reading in binary mode\nwith open('..\/input\/cifar10-preprocessed\/model_params_ConvNet1.pickle', 'rb') as f:\n    d_trained = pickle.load(f, encoding='latin1')  # dictionary type, we use 'latin1' for python3\n\n# Showing loaded data from file\nfor i, j in d_trained.items():\n    print(i + ':', j.shape)\n\n\n# Creating instance of class and initializing model\nmodel_1 = ConvNet1()\n\n# Assigning to the new model loaded parameters from 'pickle' file\nmodel_1.params = d_trained\n\n# Showing assigned parameters\nprint()\nfor i, j in model_1.params.items():\n    print(i + ':', j.shape)\n\n\n# Preparing function for ploting set of filters\n# As input it will take 4D tensor and convert it to the grid\n# Values will be scaled to the range [0, 255]\ndef convert_to_grid(x_input):\n    N, H, W, C = x_input.shape\n    grid_size = int(ceil(sqrt(N)))\n    grid_height = H * grid_size + 1 * (grid_size - 1)\n    grid_width = W * grid_size + 1 * (grid_size - 1)\n    grid = np.zeros((grid_height, grid_width, C)) + 255\n    next_idx = 0\n    y0, y1 = 0, H\n    for y in range(grid_size):\n        x0, x1 = 0, W\n        for x in range(grid_size):\n            if next_idx < N:\n                img = x_input[next_idx]\n                low, high = np.min(img), np.max(img)\n                grid[y0:y1, x0:x1] = 255.0 * (img - low) \/ (high - low)\n                next_idx += 1\n            x0 += W + 1\n            x1 += W + 1\n        y0 += H + 1\n        y1 += H + 1\n\n    return grid\n\n\n# Visualizing trained filters\n# Transposing filters to make channels come at the end\nd_trained['w1'] = d_trained['w1'].transpose(0, 2, 3, 1)\n# print(d_trained['w1'].shape)  # (32, 7, 7, 3)\n\n# Plotting\nfig = plt.figure()\ngrid = convert_to_grid(d_trained['w1'])\nplt.imshow(grid.astype('uint8'))\nplt.axis('off')\nplt.gcf().set_size_inches(5, 5)\nplt.title('Trained filters', fontsize=20)\nplt.show()\n# Saving plot\nfig.savefig('Trained_filters.png')\nplt.close()\n\n\n# Visualizing initialized filters\n# Creating instance of class and initializing model\nmodel = ConvNet1()\n\n# Transposing filters to make channels come at the end\nmodel.params['w1'] = model.params['w1'].transpose(0, 2, 3, 1)\n# print(model.params['w1'].shape)   # (32, 7, 7, 3)\n\n# Plotting\nfig = plt.figure()\ngrid = convert_to_grid(model.params['w1'])\nplt.imshow(grid.astype('uint8'))\nplt.axis('off')\nplt.gcf().set_size_inches(5, 5)\nplt.title('Initialized filters', fontsize=20)\nplt.show()\n# Saving plot\nfig.savefig('Initialized_filters.png')\nplt.close()\n","7f6e14d5":"# Opening file for reading in binary mode\nwith open('..\/input\/cifar10-preprocessed\/model_params_ConvNet1.pickle', 'rb') as f:\n    d_trained = pickle.load(f, encoding='latin1')  # dictionary type, we use 'latin1' for python3\n\n# Showing loaded data from file\nfor i, j in d_trained.items():\n    print(i + ':', j.shape)\n\n\n# Creating instance of class and initializing model\nmodel_1 = ConvNet1()\n\n# Assigning to the new model loaded parameters from 'pickle' file\nmodel_1.params = d_trained\n\n# Showing assigned parameters\nprint()\nfor i, j in model_1.params.items():\n    print(i + ':', j.shape)\n\n\n# CIFAR-10 has 10 classes from 0 to 9\nlabels = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n\n\n# Preparing data for predicting from test dataset\nx_input = d['x_test'][:1]\ny_input = d['y_test'][:1]\n# True label\nprint()\nprint('True label:', labels[y_input[0]])\n\n# Getting scores from forward pass of input image\nscores = model_1.scores_for_predicting(x_input)\n\n# Scores is given for each image with 10 numbers of predictions for each class\n# Getting only one class for each image with maximum value\nprint('Predicted label:', labels[np.argmax(scores, axis=1)[0]])\n# Now we have each image with its only one predicted class (index of each row)\n# but not with 10 numbers for each class\n\n# Printing all scores\nprint()\nprint('All scores', scores)\n\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (10.0, 8.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'\n\n# Plotting scores\nfig = plt.figure()\nx_positions = np.arange(len(labels))\nbarlist = plt.bar(x_positions, scores[0], align='center', alpha=0.6)\nbarlist[np.argmax(scores)].set_color('red')\nplt.xticks(x_positions, labels, fontsize=15)\nplt.ylabel('Value', fontsize=15)\nplt.title('Classification of input image', fontsize=20)\n\nplt.show()\n# Saving plot\nfig.savefig('Classification_of_input_image.png')\nplt.close()\n","2858f08f":"# Loading input image from file\n# Our image initially is in RGB format\n# But now we open it in BGR format as function 'cv2.imread' opens it so\nx_input = cv2.imread('..\/input\/images-for-testing\/horse.jpg')\n\n# Getting image shape\nprint(x_input.shape)  # (1050, 1680, 3)\n\n# Getting blob from input image\n# The 'cv2.dnn.blobFromImage' function returns 4-dimensional blob\n# from input image after normalizing, and RB channels swapping\n# Resulted shape has number of images, number of channels, width and height\n# E.G.: blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size, swapRB=True)\nblob = cv2.dnn.blobFromImage(x_input, 1 \/ 255.0, (32, 32), swapRB=True, crop=False)\n\n# Getting blob's shape\nprint(blob.shape)  # (1, 3, 32, 32)\n\n\n# Preprocessing image in the same way as it was done for training data\n# Normalizing by 255.0 we already did in blob, now we need subtract mean image and divide by std image\n\n# Opening file for reading in binary mode\nwith open('..\/input\/cifar10-preprocessed\/mean_and_std.pickle', 'rb') as f:\n    mean_and_std = pickle.load(f, encoding='latin1')  # dictionary type, we use 'latin1' for python3\n\n# Getting mean image and std from dictionary\nmean_image = mean_and_std['mean_image']\nstd = mean_and_std['std']\n\n# Getting shape\nprint(mean_image.shape)  # (32, 32, 3)\nprint(std.shape)  # (32, 32, 3)\n\n# Transposing mean and std to make channels come first as we have it now in blob image\nmean_image = mean_image.transpose(2, 0, 1)\nstd = std.transpose(2, 0, 1)\n\n# Getting shape\nprint(mean_image.shape)  # (3, 32, 32)\nprint(std.shape)  # (3, 32, 32)\nprint()\n\n# Subtracting mean image from blob\nblob[0] -= mean_image\n# Dividing by standard deviation\nblob[0] \/= std\n\n\n# CIFAR-10 has 10 classes from 0 to 9\nlabels = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n\n# Opening file for reading in binary mode\nwith open('..\/input\/cifar10-preprocessed\/model_params_ConvNet1.pickle', 'rb') as f:\n    d_trained = pickle.load(f, encoding='latin1')  # dictionary type, we use 'latin1' for python3\n\n# Creating instance of class and initializing model\nmodel = ConvNet1()\n\n# Assigning to the new model loaded parameters from 'pickle' file\nmodel.params = d_trained\n\n# Showing assigned parameters\nfor i, j in model.params.items():\n    print(i + ':', j.shape)\nprint()\n    \n# Getting scores from forward pass of input image\n# Measuring at the same time execution time\nstart = timer()\nscores = model.scores_for_predicting(blob)\nend = timer()\n\n# Scores is given for each image with 10 numbers of predictions for each class\n# Getting only one class for each image with maximum value\nprint('Predicted label is', labels[np.argmax(scores, axis=1)[0]])\nprint('Time spent for pedicting: {} seconds'.format(round(end - start, 5)))\nprint()\n# Now we have each image with its only one predicted class (index of each row)\n# but not with 10 numbers for each class\n\n# Printing all scores\nprint(scores)\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (10.0, 8.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'\n\n# Plotting scores\nfig = plt.figure()\nx_positions = np.arange(len(labels))\nbarlist = plt.bar(x_positions, scores[0], align='center', alpha=0.6)\nbarlist[np.argmax(scores)].set_color('red')\nplt.xticks(x_positions, labels, fontsize=15)\nplt.ylabel('Value', fontsize=15)\nplt.title('Classification of user\\'s image', fontsize=20)\n\nplt.show()\n# Saving plot\nfig.savefig('Classification_of_users_image.png')\nplt.close()\n\n\n# Showing image with predicted label\n# Resizing image\nx_input = cv2.resize(x_input, (400, 300), interpolation=cv2.INTER_AREA)\n\n# Preparing text with label and score\ntext = 'Label: {}'.format(labels[np.argmax(scores, axis=1)[0]])\n\n# Preparing colour\ncolour = [0, 255, 0]\n\n# Putting text with label and confidence on the original image\ncv2.putText(x_input, text, (10, 25), cv2.FONT_HERSHEY_TRIPLEX, 0.8, colour, 1)\n\n# Showing resulted image\nfig = plt.figure()\nplt.imshow(cv2.cvtColor(x_input, cv2.COLOR_BGR2RGB))\nplt.axis('off')\nplt.show()\n# Saving plot\nfig.savefig('Users_image_with_label.png')\nplt.close()\n","68780937":"# Predicting with image from test dataset","e0a8c465":"## Using `pure` numpy library and CIFAR10 dataset","0a87aaee":"# Naive Backward Pass for ReLU activation","378fce90":"# Naive Backward Pass for Convolutional Layer","3ee6ff07":"# Naive Forward Pass for Max Pooling Layer","3aa6a11d":"# Naive Backward Pass for MAX Pooling Layer","2b89f449":"# Softmax Classification Loss","fee375d2":"# Plotting history results for Overfitted small data","722a3f63":"# Initializing new Model and checking dimensions of weights for every Layer","fc24fc6b":"# Overfitting small data","ea2e95b1":"# Convolutional Neural Network for Image Classification","279312ef":"# Training Network","3478567e":"# Naive Forward Pass for Convolutional Layer","48ec3dcd":"# Adam updating method","4d323a5f":"# Visualizing Filters of Convolutional Layer\n## After CNN was trained, it is possible to visualize filters and compare them with initialized ones","45b391c9":"# Predicting with user's image\n## Uploading user's image, than preprocessing it and feeding to the network","0b14f4cd":"# Preparing helper functions for CNN","471a8306":"# Naive Forward Pass for Fully-Connected Layer","b544007b":"# Naive Backward Pass for Fully-Connected Layer","c14ebbaa":"# Loading prepared and preprocessed data from file","97d2b296":"# Naive Forward Pass for ReLU activation","57c53e46":"# Checking Naive Forward Pass for Convolutional Layer","14f334df":"# Checking Naive Backward Pass for ReLU activation","44096738":"# Checking Naive Forward Pass for ReLU activation","bc84e5b7":"# Checking Naive Backward Pass for Max Pooling Layer","d18731d1":"# Creating Convolutional Neural Network Model","c630acf1":"# Plotting history results for Trained CNN","c7d5e3f4":"# Checking Naive Forward Pass for Max Pooling Layer","e55d5e1a":"# Creating Train class for training classification model"}}