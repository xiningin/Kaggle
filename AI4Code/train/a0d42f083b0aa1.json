{"cell_type":{"e7ccd490":"code","d706d5ce":"code","daa60df1":"code","c0c1a49e":"code","39b99d16":"code","edc0ea36":"code","d6a1527d":"code","9a66cb2b":"code","3fd40def":"code","b296d1d3":"code","5a6b92d5":"code","05dd34db":"code","bc28402c":"code","42d9a2fe":"code","af6b749a":"code","dce06d39":"code","6611dde5":"code","1be47a90":"code","35b4526b":"code","4ee28842":"code","093e7199":"code","969a284a":"code","f17c4653":"code","79bc5083":"code","4b9b3566":"code","85598600":"code","a9441166":"code","374a94f8":"code","1bc0b426":"code","cc5dbee8":"code","d04f94ba":"code","0a3c9a0c":"code","339f08ca":"code","8df915cd":"code","f4d9ad1e":"code","d183547d":"code","32357543":"code","dd1df095":"code","7520305b":"markdown","a1eec3ce":"markdown","faebeefc":"markdown"},"source":{"e7ccd490":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d706d5ce":"# Id - \uac01 \ud589\uc758 \uace0\uc720 \uc2dd\ubcc4\uc790\uc785\ub2c8\ub2e4.\n# \ubaa9\ud45c - \ubaa9\ud45c\ub294 \uc18c\ub4dd \uc218\uc900 \uadf8\ub8f9\uc744 \ub098\ud0c0\ub0b4\ub294 \uc11c\uc218 \ubcc0\uc218\uc785\ub2c8\ub2e4.\n# 1 = \uadf9\uc2ec\ud55c \ube48\uace4\n# 2 = \uc911\uac04 \ube48\uace4\n# 3 = \ucde8\uc57d \uac00\uad6c\n# 4 = \ucde8\uc57d\ud558\uc9c0 \uc54a\uc740 \uac00\uad6c\n# idhogar - \uac01 \uac00\uad6c\uc758 \uace0\uc720 \uc2dd\ubcc4\uc790\uc785\ub2c8\ub2e4. \uc774\uac83\uc740 \uac00\uad6c \uc804\uccb4 \uae30\ub2a5 \ub4f1\uc744 \ub9cc\ub4dc\ub294 \ub370 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc9c0\uc815\ub41c \uac00\uad6c\uc758 \ubaa8\ub4e0 \ud589\uc740 \uc774 \uc2dd\ubcc4\uc790\uc5d0 \ub300\ud574 \uc77c\uce58\ud558\ub294 \uac12\uc744 \uac16\uc2b5\ub2c8\ub2e4.\n# parentesco1 - \uc774 \uc0ac\ub78c\uc774 \uac00\uc7a5\uc778\uc9c0 \uc5ec\ubd80\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.","daa60df1":"import numpy as np # linear algebra\nimport pandas as pd \nimport joblib\n\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.metrics import f1_score\n\nfrom joblib import Parallel, delayed\nfrom sklearn.base import clone\nfrom sklearn.ensemble import VotingClassifier, ExtraTreesClassifier, RandomForestClassifier\nfrom sklearn.utils import class_weight\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","c0c1a49e":"from sklearn.preprocessing import LabelEncoder\n\n# this only transforms the idhogar field, the other things this function used to do are done elsewhere\ndef encode_data(df):\n    df['idhogar'] = LabelEncoder().fit_transform(df['idhogar'])\n\n# plot feature importance for sklearn decision trees    \ndef feature_importance(forest, X_train, display_results=True):\n    ranked_list = []\n    zero_features = []\n    \n    importances = forest.feature_importances_\n\n    indices = np.argsort(importances)[::-1]\n    \n    if display_results:\n        # Print the feature ranking\n        print(\"Feature ranking:\")\n\n    for f in range(X_train.shape[1]):\n        if display_results:\n            print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]) + \" - \" + X_train.columns[indices[f]])\n        \n        ranked_list.append(X_train.columns[indices[f]])\n        \n        if importances[indices[f]] == 0.0:\n            zero_features.append(X_train.columns[indices[f]])\n            \n    return ranked_list, zero_features","39b99d16":"def do_features(df):\n    feats_div = [('children_fraction', 'r4t1', 'r4t3'), \n                 ('working_man_fraction', 'r4h2', 'r4t3'),\n                 ('all_man_fraction', 'r4h3', 'r4t3'),\n                 ('human_density', 'tamviv', 'rooms'),\n                 ('human_bed_density', 'tamviv', 'bedrooms'),\n                 ('rent_per_person', 'v2a1', 'r4t3'),\n                 ('rent_per_room', 'v2a1', 'rooms'),\n                 ('mobile_density', 'qmobilephone', 'r4t3'),\n                 ('tablet_density', 'v18q1', 'r4t3'),\n                 ('mobile_adult_density', 'qmobilephone', 'r4t2'),\n                 ('tablet_adult_density', 'v18q1', 'r4t2'),\n                ]\n    \n    feats_sub = [('people_not_living', 'tamhog', 'tamviv'),\n                 ('people_weird_stat', 'tamhog', 'r4t3')]\n\n    for f_new, f1, f2 in feats_div:\n        df['fe_' + f_new] = (df[f1] \/ df[f2]).astype(np.float32)       \n    for f_new, f1, f2 in feats_sub:\n        df['fe_' + f_new] = (df[f1] - df[f2]).astype(np.float32)\n    \n    # aggregation rules over household\n    aggs_num = {'age': ['min', 'max', 'mean'],\n                'escolari': ['min', 'max', 'mean']\n               }\n    \n    aggs_cat = {'dis': ['mean']}\n    for s_ in ['estadocivil', 'parentesco', 'instlevel']:\n        for f_ in [f_ for f_ in df.columns if f_.startswith(s_)]:\n            aggs_cat[f_] = ['mean', 'count']\n\n    # aggregation over household\n    for name_, df_ in [('18', df.query('age >= 18'))]:\n        df_agg = df_.groupby('idhogar').agg({**aggs_num, **aggs_cat}).astype(np.float32)\n        df_agg.columns = pd.Index(['agg' + name_ + '_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n        df = df.join(df_agg, how='left', on='idhogar')\n        del df_agg\n\n    # Drop id's\n    df.drop(['Id'], axis=1, inplace=True)\n    \n    return df","edc0ea36":"# convert one hot encoded fields to label encoding\ndef convert_OHE2LE(df):\n    tmp_df = df.copy(deep=True)\n    for s_ in ['pared', 'piso', 'techo', 'abastagua', 'sanitario', 'energcocinar', 'elimbasu', \n               'epared', 'etecho', 'eviv', 'estadocivil', 'parentesco', \n               'instlevel', 'lugar', 'tipovivi',\n               'manual_elec']:\n        if 'manual_' not in s_:\n            cols_s_ = [f_ for f_ in df.columns if f_.startswith(s_)]\n        elif 'elec' in s_:\n            cols_s_ = ['public', 'planpri', 'noelec', 'coopele']\n        sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n        #deal with those OHE, where there is a sum over columns == 0\n        if 0 in sum_ohe:\n            print('The OHE in {} is incomplete. A new column will be added before label encoding'\n                  .format(s_))\n            # dummy colmn name to be added\n            col_dummy = s_+'_dummy'\n            # add the column to the dataframe\n            tmp_df[col_dummy] = (tmp_df[cols_s_].sum(axis=1) == 0).astype(np.int8)\n            # add the name to the list of columns to be label-encoded\n            cols_s_.append(col_dummy)\n            # proof-check, that now the category is complete\n            sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n            if 0 in sum_ohe:\n                 print(\"The category completion did not work\")\n        tmp_cat = tmp_df[cols_s_].idxmax(axis=1)\n        tmp_df[s_ + '_LE'] = LabelEncoder().fit_transform(tmp_cat).astype(np.int16)\n        if 'parentesco1' in cols_s_:\n            cols_s_.remove('parentesco1')\n        tmp_df.drop(cols_s_, axis=1, inplace=True)\n    return tmp_df","d6a1527d":"train = pd.read_csv('..\/input\/costa-rican-household-poverty-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/costa-rican-household-poverty-prediction\/test.csv')\n\ntest_ids = test.Id","9a66cb2b":"def process_df(df_):\n    # encode the idhogar\n    encode_data(df_)\n    \n    # create aggregate features\n    return do_features(df_)\n\ntrain = process_df(train)\ntest = process_df(test)","3fd40def":"# some dependencies are Na, fill those with the square root of the square\ntrain['dependency'] = np.sqrt(train['SQBdependency'])\ntest['dependency'] = np.sqrt(test['SQBdependency'])\n\n# fill \"no\"s for education with 0s\ntrain.loc[train['edjefa'] == \"no\", \"edjefa\"] = 0\ntrain.loc[train['edjefe'] == \"no\", \"edjefe\"] = 0\ntest.loc[test['edjefa'] == \"no\", \"edjefa\"] = 0\ntest.loc[test['edjefe'] == \"no\", \"edjefe\"] = 0\n\n# if education is \"yes\" and person is head of household, fill with escolari\ntrain.loc[(train['edjefa'] == \"yes\") & (train['parentesco1'] == 1), \"edjefa\"] = train.loc[(train['edjefa'] == \"yes\") & (train['parentesco1'] == 1), \"escolari\"]\ntrain.loc[(train['edjefe'] == \"yes\") & (train['parentesco1'] == 1), \"edjefe\"] = train.loc[(train['edjefe'] == \"yes\") & (train['parentesco1'] == 1), \"escolari\"]\n\ntest.loc[(test['edjefa'] == \"yes\") & (test['parentesco1'] == 1), \"edjefa\"] = test.loc[(test['edjefa'] == \"yes\") & (test['parentesco1'] == 1), \"escolari\"]\ntest.loc[(test['edjefe'] == \"yes\") & (test['parentesco1'] == 1), \"edjefe\"] = test.loc[(test['edjefe'] == \"yes\") & (test['parentesco1'] == 1), \"escolari\"]\n\n# this field is supposed to be interaction between gender and escolari, but it isn't clear what \"yes\" means, let's fill it with 4\ntrain.loc[train['edjefa'] == \"yes\", \"edjefa\"] = 4\ntrain.loc[train['edjefe'] == \"yes\", \"edjefe\"] = 4\n\ntest.loc[test['edjefa'] == \"yes\", \"edjefa\"] = 4\ntest.loc[test['edjefe'] == \"yes\", \"edjefe\"] = 4\n\n# convert to int for our models\ntrain['edjefe'] = train['edjefe'].astype(\"int\")\ntrain['edjefa'] = train['edjefa'].astype(\"int\")\ntest['edjefe'] = test['edjefe'].astype(\"int\")\ntest['edjefa'] = test['edjefa'].astype(\"int\")\n\n# create feature with max education of either head of household\ntrain['edjef'] = np.max(train[['edjefa','edjefe']], axis=1)\ntest['edjef'] = np.max(test[['edjefa','edjefe']], axis=1)\n\n# fill some nas\ntrain['v2a1']=train['v2a1'].fillna(0)\ntest['v2a1']=test['v2a1'].fillna(0)\n\ntest['v18q1']=test['v18q1'].fillna(0)\ntrain['v18q1']=train['v18q1'].fillna(0)\n\ntrain['rez_esc']=train['rez_esc'].fillna(0)\ntest['rez_esc']=test['rez_esc'].fillna(0)\n\ntrain.loc[train.meaneduc.isnull(), \"meaneduc\"] = 0\ntrain.loc[train.SQBmeaned.isnull(), \"SQBmeaned\"] = 0\n\ntest.loc[test.meaneduc.isnull(), \"meaneduc\"] = 0\ntest.loc[test.SQBmeaned.isnull(), \"SQBmeaned\"] = 0\n\n# fix some inconsistencies in the data - some rows indicate both that the household does and does not have a toilet, \n# if there is no water we'll assume they do not\ntrain.loc[(train.v14a ==  1) & (train.sanitario1 ==  1) & (train.abastaguano == 0), \"v14a\"] = 0\ntrain.loc[(train.v14a ==  1) & (train.sanitario1 ==  1) & (train.abastaguano == 0), \"sanitario1\"] = 0\n\ntest.loc[(test.v14a ==  1) & (test.sanitario1 ==  1) & (test.abastaguano == 0), \"v14a\"] = 0\ntest.loc[(test.v14a ==  1) & (test.sanitario1 ==  1) & (test.abastaguano == 0), \"sanitario1\"] = 0","b296d1d3":"def train_test_apply_func(train_, test_, func_):\n    test_['Target'] = 0\n    xx = pd.concat([train_, test_])\n\n    xx_func = func_(xx)\n    train_ = xx_func.iloc[:train_.shape[0], :]\n    test_  = xx_func.iloc[train_.shape[0]:, :].drop('Target', axis=1)\n\n    del xx, xx_func\n    return train_, test_","5a6b92d5":"# convert the one hot fields into label encoded\ntrain, test = train_test_apply_func(train, test, convert_OHE2LE)","05dd34db":"cols_2_ohe = ['eviv_LE', 'etecho_LE', 'epared_LE', 'elimbasu_LE', \n              'energcocinar_LE', 'sanitario_LE', 'manual_elec_LE',\n              'pared_LE']\ncols_nums = ['age', 'meaneduc', 'dependency', \n             'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total',\n             'bedrooms', 'overcrowding']\n\ndef convert_geo2aggs(df_):\n    tmp_df = pd.concat([df_[(['lugar_LE', 'idhogar']+cols_nums)],\n                        pd.get_dummies(df_[cols_2_ohe], \n                                       columns=cols_2_ohe)],axis=1)\n\n    geo_agg = tmp_df.groupby(['lugar_LE','idhogar']).mean().groupby('lugar_LE').mean().astype(np.float32)\n    geo_agg.columns = pd.Index(['geo_' + e for e in geo_agg.columns.tolist()])\n    \n    del tmp_df\n    return df_.join(geo_agg, how='left', on='lugar_LE')\n\n# add some aggregates by geography\ntrain, test = train_test_apply_func(train, test, convert_geo2aggs)","bc28402c":"# add the number of people over 18 in each household\ntrain['num_over_18'] = 0\ntrain['num_over_18'] = train[train.age >= 18].groupby('idhogar').transform(\"count\")\ntrain['num_over_18'] = train.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\ntrain['num_over_18'] = train['num_over_18'].fillna(0)\n\ntest['num_over_18'] = 0\ntest['num_over_18'] = test[test.age >= 18].groupby('idhogar').transform(\"count\")\ntest['num_over_18'] = test.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\ntest['num_over_18'] = test['num_over_18'].fillna(0)\n\n# add some extra features, these were taken from another kernel\ndef extract_features(df):\n    df['bedrooms_to_rooms'] = df['bedrooms']\/df['rooms']\n    df['rent_to_rooms'] = df['v2a1']\/df['rooms']\n    df['tamhog_to_rooms'] = df['tamhog']\/df['rooms'] # tamhog - size of the household\n    df['r4t3_to_tamhog'] = df['r4t3']\/df['tamhog'] # r4t3 - Total persons in the household\n    df['r4t3_to_rooms'] = df['r4t3']\/df['rooms'] # r4t3 - Total persons in the household\n    df['v2a1_to_r4t3'] = df['v2a1']\/df['r4t3'] # rent to people in household\n    df['v2a1_to_r4t3'] = df['v2a1']\/(df['r4t3'] - df['r4t1']) # rent to people under age 12\n    df['hhsize_to_rooms'] = df['hhsize']\/df['rooms'] # rooms per person\n    df['rent_to_hhsize'] = df['v2a1']\/df['hhsize'] # rent to household size\n    df['rent_to_over_18'] = df['v2a1']\/df['num_over_18']\n    # some households have no one over 18, use the total rent for those\n    df.loc[df.num_over_18 == 0, \"rent_to_over_18\"] = df[df.num_over_18 == 0].v2a1\n    \nextract_features(train)    \nextract_features(test) ","42d9a2fe":"# drop duplicated columns\nneedless_cols = ['r4t3', 'tamhog', 'tamviv', 'hhsize', 'v18q', 'v14a', 'agesq',\n                 'mobilephone', 'female', ]\n\ninstlevel_cols = [s for s in train.columns.tolist() if 'instlevel' in s]\n\nneedless_cols.extend(instlevel_cols)\n\ntrain = train.drop(needless_cols, axis=1)\ntest = test.drop(needless_cols, axis=1)","af6b749a":"### Split the data\n\ndef split_data(train, y, sample_weight=None, households=None, test_percentage=0.20, seed=None):\n    # uncomment for extra randomness\n#     np.random.seed(seed=seed)\n    \n    train2 = train.copy()\n    \n    # pick some random households to use for the test data\n    cv_hhs = np.random.choice(households, size=int(len(households) * test_percentage), replace=False)\n    \n    # select households which are in the random selection\n    cv_idx = np.isin(households, cv_hhs)\n    X_test = train2[cv_idx]\n    y_test = y[cv_idx]\n\n    X_train = train2[~cv_idx]\n    y_train = y[~cv_idx]\n    \n    if sample_weight is not None:\n        y_train_weights = sample_weight[~cv_idx]\n        return X_train, y_train, X_test, y_test, y_train_weights\n    \n    return X_train, y_train, X_test, y_test","dce06d39":"X = train.query('parentesco1==1')\n# X = train.copy()\n\n# pull out and drop the target variable\ny = X['Target'] - 1\nX = X.drop(['Target'], axis=1)\n\nnp.random.seed(seed=None)\n\ntrain2 = X.copy()\n\ntrain_hhs = train2.idhogar\n\nhouseholds = train2.idhogar.unique()\ncv_hhs = np.random.choice(households, size=int(len(households) * 0.15), replace=False)\n\ncv_idx = np.isin(train2.idhogar, cv_hhs)\n\nX_test = train2[cv_idx]\ny_test = y[cv_idx]\n\nX_train = train2[~cv_idx]\ny_train = y[~cv_idx]\n\n# train on entire dataset\nX_train = train2\ny_train = y\n\ntrain_households = X_train.idhogar","6611dde5":"# figure out the class weights for training with unbalanced classes\n\n# \ubd88\uade0\ud615\ud55c \ub370\uc774\ud130 \uac00\uc911\uce58\ny_train_weights = class_weight.compute_sample_weight('balanced', y_train, indices=None)","1be47a90":"# drop some features which aren't used by the LGBM or have very low importance\n# \uc911\uc694\ub3c4 \ub0ae\uc740 \ubcc0\uc218 drop\nextra_drop_features = [\n 'agg18_estadocivil1_MEAN',\n 'agg18_estadocivil6_COUNT',\n 'agg18_estadocivil7_COUNT',\n 'agg18_parentesco10_COUNT',\n 'agg18_parentesco11_COUNT',\n 'agg18_parentesco12_COUNT',\n 'agg18_parentesco1_COUNT',\n 'agg18_parentesco2_COUNT',\n 'agg18_parentesco3_COUNT',\n 'agg18_parentesco4_COUNT',\n 'agg18_parentesco5_COUNT',\n 'agg18_parentesco6_COUNT',\n 'agg18_parentesco7_COUNT',\n 'agg18_parentesco8_COUNT',\n 'agg18_parentesco9_COUNT',\n 'geo_elimbasu_LE_4',\n 'geo_energcocinar_LE_1',\n 'geo_energcocinar_LE_2',\n 'geo_epared_LE_0',\n 'geo_hogar_mayor',\n 'geo_manual_elec_LE_2',\n 'geo_pared_LE_3',\n 'geo_pared_LE_4',\n 'geo_pared_LE_5',\n 'geo_pared_LE_6',\n 'num_over_18',\n 'parentesco_LE',\n 'rez_esc']","35b4526b":"xgb_drop_cols = extra_drop_features + [\"idhogar\",  'parentesco1']","4ee28842":"### Fit a voting classifier\n# 4\nopt_parameters = {'max_depth':35, 'eta':0.1, 'silent':0, 'objective':'multi:softmax', 'min_child_weight': 1, 'num_class': 4, 'gamma': 2.0, 'colsample_bylevel': 0.9, 'subsample': 0.84, 'colsample_bytree': 0.88, 'reg_lambda': 0.40 }\n# 5\nopt_parameters = {'max_depth':35, 'eta':0.15, 'silent':1, 'objective':'multi:softmax', 'min_child_weight': 2, 'num_class': 4, 'gamma': 2.5, 'colsample_bylevel': 1, 'subsample': 0.95, 'colsample_bytree': 0.85, 'reg_lambda': 0.35 }\n# 6\n# opt_parameters = {'max_depth':35, 'eta':0.15, 'silent':0, 'objective':'multi:softmax', 'min_child_weight': 2, 'num_class': 4, 'gamma': 2.75, 'colsample_bylevel': 0.95, 'subsample': 0.95, 'colsample_bytree': 0.85, 'reg_lambda': 0.35 }\n# # 7\n# opt_parameters = {'max_depth':35, 'eta':0.12, 'silent':0, 'objective':'multi:softmax', 'min_child_weight': 2, 'num_class': 4, 'gamma': 3.25, 'colsample_bylevel': 0.95, 'subsample': 0.88, 'colsample_bytree': 0.88, 'reg_lambda': 0.35 }\n\ndef evaluate_macroF1_lgb(predictions, truth):  \n    # this follows the discussion in https:\/\/github.com\/Microsoft\/LightGBM\/issues\/1483\n    pred_labels = predictions.argmax(axis=1)\n    truth = truth.get_label()\n    f1 = f1_score(truth, pred_labels, average='macro')\n    return ('macroF1', 1-f1) \n\nfit_params={\"early_stopping_rounds\":500,\n            \"eval_metric\" : evaluate_macroF1_lgb, \n            \"eval_set\" : [(X_train,y_train), (X_test,y_test)],\n            'verbose': False,\n           }\n\ndef learning_rate_power_0997(current_iter):\n    base_learning_rate = 0.1\n    min_learning_rate = 0.02\n    lr = base_learning_rate  * np.power(.995, current_iter)\n    return max(lr, min_learning_rate)\n\nfit_params['verbose'] = 50","093e7199":"np.random.seed(100)\n\ndef _parallel_fit_estimator(estimator1, X, y, sample_weight=None, threshold=True, **fit_params):\n    estimator = clone(estimator1)\n    \n    # randomly split the data so we have a test set for early stopping\n    if sample_weight is not None:\n        X_train, y_train, X_test, y_test, y_train_weight = split_data(X, y, sample_weight, households=train_households)\n    else:\n        X_train, y_train, X_test, y_test = split_data(X, y, None, households=train_households)\n        \n    # update the fit params with our new split\n    fit_params[\"eval_set\"] = [(X_test,y_test)]\n    \n    # fit the estimator\n    if sample_weight is not None:\n        if isinstance(estimator1, ExtraTreesClassifier) or isinstance(estimator1, RandomForestClassifier):\n            estimator.fit(X_train, y_train)\n        else:\n            _ = estimator.fit(X_train, y_train, sample_weight=y_train_weight, **fit_params)\n    else:\n        if isinstance(estimator1, ExtraTreesClassifier) or isinstance(estimator1, RandomForestClassifier):\n            estimator.fit(X_train, y_train)\n        else:\n            _ = estimator.fit(X_train, y_train, **fit_params)\n    \n    if not isinstance(estimator1, ExtraTreesClassifier) and not isinstance(estimator1, RandomForestClassifier) and not isinstance(estimator1, xgb.XGBClassifier):\n        best_cv_round = np.argmax(estimator.evals_result_['validation_0']['mlogloss'])\n        best_cv = np.max(estimator.evals_result_['validation_0']['mlogloss'])\n        best_train = estimator.evals_result_['train']['macroF1'][best_cv_round]\n    else:\n        best_train = f1_score(y_train, estimator.predict(X_train), average=\"macro\")\n        best_cv = f1_score(y_test, estimator.predict(X_test), average=\"macro\")\n        print(\"Train F1:\", best_train)\n        print(\"Test F1:\", best_cv)\n        \n    # reject some estimators based on their performance on train and test sets\n    if threshold:\n        # if the valid score is very high we'll allow a little more leeway with the train scores\n        if ((best_cv > 0.37) and (best_train > 0.75)) or ((best_cv > 0.44) and (best_train > 0.65)):\n            return estimator\n\n        # else recurse until we get a better one\n        else:\n            print(\"Unacceptable!!! Trying again...\")\n            return _parallel_fit_estimator(estimator1, X, y, sample_weight=sample_weight, **fit_params)\n    \n    else:\n        return estimator\n    \nclass VotingClassifierLGBM(VotingClassifier):\n    '''\n    This implements the fit method of the VotingClassifier propagating fit_params\n    '''\n    def fit(self, X, y, sample_weight=None, threshold=True, **fit_params):\n        \n        if isinstance(y, np.ndarray) and len(y.shape) > 1 and y.shape[1] > 1:\n            raise NotImplementedError('Multilabel and multi-output'\n                                      ' classification is not supported.')\n\n        if self.voting not in ('soft', 'hard'):\n            raise ValueError(\"Voting must be 'soft' or 'hard'; got (voting=%r)\"\n                             % self.voting)\n\n        if self.estimators is None or len(self.estimators) == 0:\n            raise AttributeError('Invalid `estimators` attribute, `estimators`'\n                                 ' should be a list of (string, estimator)'\n                                 ' tuples')\n\n        if (self.weights is not None and\n                len(self.weights) != len(self.estimators)):\n            raise ValueError('Number of classifiers and weights must be equal'\n                             '; got %d weights, %d estimators'\n                             % (len(self.weights), len(self.estimators)))\n\n        names, clfs = zip(*self.estimators)\n        self._validate_names(names)\n\n        n_isnone = np.sum([clf is None for _, clf in self.estimators])\n        if n_isnone == len(self.estimators):\n            raise ValueError('All estimators are None. At least one is '\n                             'required to be a classifier!')\n\n        self.le_ = LabelEncoder().fit(y)\n        self.classes_ = self.le_.classes_\n        self.estimators_ = []\n\n        transformed_y = self.le_.transform(y)\n\n        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n                delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n                                                 sample_weight=sample_weight, threshold=threshold, **fit_params)\n                for clf in clfs if clf is not None)\n\n        return self","969a284a":"## voting classifiers\ub294 '\ub2e4\uc218\uacb0 \ubd84\ub958'\n\n## 1. Hard Voting Classifier : \uc5ec\ub7ec \ubaa8\ub378\uc744 \uc0dd\uc131\ud558\uace0 \uadf8 \uc131\uacfc(\uacb0\uacfc)\ub97c \ube44\uad50\ud569\ub2c8\ub2e4\n## \uc774 \ub54c classifier\uc758 \uacb0\uacfc\ub4e4\uc744 \uc9d1\uacc4\ud558\uc5ec \uac00\uc7a5 \ub9ce\uc740 \ud45c\ub97c \uc5bb\ub294 \ud074\ub798\uc2a4\ub97c \ucd5c\uc885 \uc608\uce21\uac12\uc73c\ub85c \uc815\ud558\ub294 \uac83\uc744 Hard Voting Classifier\n## \uc608\ub97c \ub4e4\uc5b4, \ucd5c\uc885\uacb0\uacfc\ub97c 1\ub85c \uc608\uce21\ud55c \ubaa8\ub378\uc774 3\uac1c, 2\ub85c \uc608\uce21\ud55c \ubaa8\ub378\uc774 1\uac1c\uc774\uba74 Hard Voting Classifier\uc758 \ucd5c\uc885 \uacb0\uacfc(\uc608\uce21)\uc740 1\uc774 \ub428\n\n\n\n## 2. Soft Voting Classifier\n## \uc559\uc0c1\ube14\uc5d0 \uc0ac\uc6a9\ub418\ub294 \ubaa8\ub4e0 \ubd84\ub958\uae30\uac00 \ud074\ub798\uc2a4\uc758 \ud655\ub960\uc744 \uc608\uce21\ud560 \uc218 \uc788\uc744 \ub54c \uc0ac\uc6a9\n## \uac01 \ubd84\ub958\uae30\uc758 \uc608\uce21\uc744 \ud3c9\uade0 \ub0b4\uc5b4 \ud655\ub960\uc774 \uac00\uc7a5 \ub192\uc740 \ud074\ub798\uc2a4\ub85c \uc608\uce21 (\uac00\uc911\uce58 \ud22c\ud45c)","f17c4653":"clfs = []\nfor i in range(15):\n    clf = xgb.XGBClassifier(random_state=217+i, n_estimators=300, learning_rate=0.15, n_jobs=4, **opt_parameters)\n    \n    clfs.append(('xgb{}'.format(i), clf))\n    \nvc = VotingClassifierLGBM(clfs, voting='soft')\ndel(clfs)\n\n#Train the final model with learning rate decay\n_ = vc.fit(X_train.drop(xgb_drop_cols, axis=1), y_train, sample_weight=y_train_weights, threshold=False, **fit_params)\n\nclf_final = vc.estimators_[0]","79bc5083":"# params 4 - 400 early stop - 15 estimators - l1 used features - weighted\nglobal_score = f1_score(y_test, clf_final.predict(X_test.drop(xgb_drop_cols, axis=1)), average='macro')\nvc.voting = 'soft'\nglobal_score_soft = f1_score(y_test, vc.predict(X_test.drop(xgb_drop_cols, axis=1)), average='macro')\nvc.voting = 'hard'\nglobal_score_hard = f1_score(y_test, vc.predict(X_test.drop(xgb_drop_cols, axis=1)), average='macro')\n\nprint('Validation score of a single LGBM Classifier: {:.4f}'.format(global_score))\nprint('Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_score_soft))\nprint('Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: {:.4f}'.format(global_score_hard))","4b9b3566":"# see which features are not used by ANY models\nuseless_features = []\ndrop_features = set()\ncounter = 0\nfor est in vc.estimators_:\n    ranked_features, unused_features = feature_importance(est, X_train.drop(xgb_drop_cols, axis=1), display_results=False)\n    useless_features.append(unused_features)\n    if counter == 0:\n        drop_features = set(unused_features)\n    else:\n        drop_features = drop_features.intersection(set(unused_features))\n    counter += 1\n    \ndrop_features","85598600":"ranked_features = feature_importance(clf_final, X_train.drop(xgb_drop_cols, axis=1))","a9441166":"## Random Forest\net_drop_cols = ['agg18_age_MAX', 'agg18_age_MEAN', 'agg18_age_MIN', 'agg18_dis_MEAN',\n       'agg18_escolari_MAX', 'agg18_escolari_MEAN', 'agg18_escolari_MIN',\n       'agg18_estadocivil1_COUNT', 'agg18_estadocivil1_MEAN',\n       'agg18_estadocivil2_COUNT', 'agg18_estadocivil2_MEAN',\n       'agg18_estadocivil3_COUNT', 'agg18_estadocivil3_MEAN',\n       'agg18_estadocivil4_COUNT', 'agg18_estadocivil4_MEAN',\n       'agg18_estadocivil5_COUNT', 'agg18_estadocivil5_MEAN',\n       'agg18_estadocivil6_COUNT', 'agg18_estadocivil6_MEAN',\n       'agg18_estadocivil7_COUNT', 'agg18_estadocivil7_MEAN',\n       'agg18_parentesco10_COUNT', 'agg18_parentesco10_MEAN',\n       'agg18_parentesco11_COUNT', 'agg18_parentesco11_MEAN',\n       'agg18_parentesco12_COUNT', 'agg18_parentesco12_MEAN',\n       'agg18_parentesco1_COUNT', 'agg18_parentesco1_MEAN',\n       'agg18_parentesco2_COUNT', 'agg18_parentesco2_MEAN',\n       'agg18_parentesco3_COUNT', 'agg18_parentesco3_MEAN',\n       'agg18_parentesco4_COUNT', 'agg18_parentesco4_MEAN',\n       'agg18_parentesco5_COUNT', 'agg18_parentesco5_MEAN',\n       'agg18_parentesco6_COUNT', 'agg18_parentesco6_MEAN',\n       'agg18_parentesco7_COUNT', 'agg18_parentesco7_MEAN',\n       'agg18_parentesco8_COUNT', 'agg18_parentesco8_MEAN',\n       'agg18_parentesco9_COUNT', 'agg18_parentesco9_MEAN'] #+ ['parentesco_LE', 'rez_esc']\n\net_drop_cols.extend([\"idhogar\", \"parentesco1\", 'fe_rent_per_person', 'fe_rent_per_room',\n       'fe_tablet_adult_density', 'fe_tablet_density'])","374a94f8":"# do the same thing for some extra trees classifiers\nets = []    \nfor i in range(10):\n    rf = RandomForestClassifier(max_depth=None, random_state=217+i, n_jobs=4, n_estimators=700, min_impurity_decrease=1e-3, min_samples_leaf=2, verbose=0, class_weight=\"balanced\")\n    ets.append(('rf{}'.format(i), rf))   \n\nvc2 = VotingClassifierLGBM(ets, voting='soft')    \n_ = vc2.fit(X_train.drop(et_drop_cols, axis=1), y_train, threshold=False)  ","1bc0b426":"# w\/ threshold, extra drop cols\nvc2.voting = 'soft'\nglobal_rf_score_soft = f1_score(y_test, vc2.predict(X_test.drop(et_drop_cols, axis=1)), average='macro')\nvc2.voting = 'hard'\nglobal_rf_score_hard = f1_score(y_test, vc2.predict(X_test.drop(et_drop_cols, axis=1)), average='macro')\n\nprint('Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_rf_score_soft))\nprint('Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: {:.4f}'.format(global_rf_score_hard))","cc5dbee8":"# w\/o threshold, extra drop cols\nvc2.voting = 'soft'\nglobal_rf_score_soft = f1_score(y_test, vc2.predict(X_test.drop(et_drop_cols, axis=1)), average='macro')\nvc2.voting = 'hard'\nglobal_rf_score_hard = f1_score(y_test, vc2.predict(X_test.drop(et_drop_cols, axis=1)), average='macro')\n\nprint('Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_rf_score_soft))\nprint('Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: {:.4f}'.format(global_rf_score_hard))","d04f94ba":"# see which features are not used by ANY models\nuseless_features = []\ndrop_features = set()\ncounter = 0\nfor est in vc2.estimators_:\n    ranked_features, unused_features = feature_importance(est, X_train.drop(et_drop_cols, axis=1), display_results=False)\n    useless_features.append(unused_features)\n    if counter == 0:\n        drop_features = set(unused_features)\n    else:\n        drop_features = drop_features.intersection(set(unused_features))\n    counter += 1\n    \ndrop_features","0a3c9a0c":"def combine_voters(data, weights=[0.5, 0.5]):\n    # do soft voting with both classifiers\n    vc.voting=\"soft\"\n    vc1_probs = vc.predict_proba(data.drop(xgb_drop_cols, axis=1))\n    vc2.voting=\"soft\"\n    vc2_probs = vc2.predict_proba(data.drop(et_drop_cols, axis=1))\n    \n    final_vote = (vc1_probs * weights[0]) + (vc2_probs * weights[1])\n    predictions = np.argmax(final_vote, axis=1)\n    \n    return predictions","339f08ca":"combo_preds = combine_voters(X_test, weights=[0.5, 0.5])\nglobal_combo_score_soft = f1_score(y_test, combo_preds, average='macro')\nglobal_combo_score_soft","8df915cd":"combo_preds = combine_voters(X_test, weights=[0.4, 0.6])\nglobal_combo_score_soft= f1_score(y_test, combo_preds, average='macro')\nglobal_combo_score_soft","f4d9ad1e":"combo_preds = combine_voters(X_test, weights=[0.6, 0.4])\nglobal_combo_score_soft = f1_score(y_test, combo_preds, average='macro')\nglobal_combo_score_soft","d183547d":"y_subm = pd.DataFrame()\ny_subm['Id'] = test_ids","32357543":"vc.voting = 'soft'\ny_subm_lgb = y_subm.copy(deep=True)\ny_subm_lgb['Target'] = vc.predict(test.drop(xgb_drop_cols, axis=1)) + 1\n\nvc2.voting = 'soft'\ny_subm_rf = y_subm.copy(deep=True)\ny_subm_rf['Target'] = vc2.predict(test.drop(et_drop_cols, axis=1)) + 1\n\ny_subm_ens = y_subm.copy(deep=True)\ny_subm_ens['Target'] = combine_voters(test) + 1","dd1df095":"from datetime import datetime\nnow = datetime.now()\n\nsub_file_lgb = 'submission_soft_XGB_{:.4f}_{}.csv'.format(global_score_soft, str(now.strftime('%Y-%m-%d-%H-%M')))\nsub_file_rf = 'submission_soft_RF_{:.4f}_{}.csv'.format(global_rf_score_soft, str(now.strftime('%Y-%m-%d-%H-%M')))\nsub_file_ens = 'submission_ens_{:.4f}_{}.csv'.format(global_combo_score_soft, str(now.strftime('%Y-%m-%d-%H-%M')))\n\ny_subm_lgb.to_csv(sub_file_lgb, index=False)\ny_subm_rf.to_csv(sub_file_rf, index=False)\ny_subm_ens.to_csv(sub_file_ens, index=False)","7520305b":"## Read in the data and clean it up","a1eec3ce":"## Prepare Submission","faebeefc":"### Geo aggregates\n\n"}}