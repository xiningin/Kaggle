{"cell_type":{"b85cf05b":"code","a03f8e1f":"code","40093faa":"code","e6c7845f":"code","26f720fb":"code","45b20114":"code","f6f7f442":"code","abf36ea1":"markdown"},"source":{"b85cf05b":"import numpy as np \nimport pandas as pd\nimport os","a03f8e1f":"import tensorflow as tf\nfrom tensorflow.keras.layers import (Input, MaxPooling2D, BatchNormalization,\n                                    GlobalAveragePooling2D, Dense, Conv2D,\n                                    Dropout, Flatten, Activation, ZeroPadding2D,\n                                    Add)\nfrom tensorflow.keras import activations\nfrom tensorflow.keras.models import Model","40093faa":"def res_identity(x, filters): \n    x_skip = x # this will be used for addition with the residual block \n    f1, f2 = filters\n\n  #first block \n    x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n    x = BatchNormalization()(x)\n    x = Activation(activations.relu)(x)\n\n  #second block # bottleneck (but size kept same with padding)\n    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='SAME')(x)\n    x = BatchNormalization()(x)\n    x = Activation(activations.relu)(x)\n\n  # third block activation used after adding the input\n    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n    x = BatchNormalization()(x)\n  # x = Activation(activations.relu)(x)\n\n  # add the input \n    x = Add()([x, x_skip])\n    x = Activation(activations.relu)(x)\n    \n    return x","e6c7845f":"def res_conv(x, s, filters):\n    x_skip = x\n    f1, f2 = filters\n\n  # first block\n  \n    x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n      # second block\n    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='SAME')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n  #third block\n    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n    x = BatchNormalization()(x)\n\n  # shortcut \n    x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid')(x_skip)\n    x_skip = BatchNormalization()(x_skip)\n\n  # add \n    x = Add()([x, x_skip])\n    x = Activation(activations.relu)(x)\n        \n    return x","26f720fb":"def squeeze_and_excite(tensor):\n    x = GlobalAveragePooling2D()(tensor)\n    x2 = Dense(x.shape[1]\/\/8, activation='relu')(x)\n    x2 = Dense(x.shape[1], activation='sigmoid')(x2)\n    x2 = tf.keras.layers.Reshape((1,1,x.shape[1]), input_shape=(x.shape[1],))(x2)\n    x = tf.keras.layers.multiply((x2,tensor))\n    \n    return x","45b20114":"inputs = Input(shape=(224,224,3))\nx = ZeroPadding2D(padding=(3, 3))(inputs)\nx = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D((3, 3), strides=(2, 2))(x)\n\nx = res_conv(x, s=1, filters=(64, 256))\nx = res_identity(x, filters=(64, 256))\nx = res_identity(x, filters=(64, 256))\n\nx = squeeze_and_excite(x)\n\nx = res_conv(x, s=2, filters=(128, 512))\nx = res_identity(x, filters=(128, 512))\nx = res_identity(x, filters=(128, 512))\nx = res_identity(x, filters=(128, 512))\n\nx = squeeze_and_excite(x)\n\nx = res_conv(x, s=2, filters=(256, 1024))\nx = res_identity(x, filters=(256, 1024))\nx = res_identity(x, filters=(256, 1024))\nx = res_identity(x, filters=(256, 1024))\nx = res_identity(x, filters=(256, 1024))\nx = res_identity(x, filters=(256, 1024))\n\nx = squeeze_and_excite(x)\n\nx = res_conv(x, s=2, filters=(512, 2048))\nx = res_identity(x, filters=(512, 2048))\nx = res_identity(x, filters=(512, 2048))\n\nx = GlobalAveragePooling2D()(x)\noutputs = Dense(11, activation='sigmoid')(x) #multi-class\n\nmodel = Model(inputs=inputs, outputs=outputs, name='Resnet50')\n\nmodel.summary()","f6f7f442":"pretrained = tf.keras.applications.ResNet50(include_top=False, weights='imagenet')(inputs)\nx = GlobalAveragePooling2D()(pretrained)\noutputs = Dense(11, activation='sigmoid')(x) \nresnet50 = Model(inputs=inputs, outputs=outputs, name='Resnet50_Keras' )\nresnet50.summary()","abf36ea1":"# Here is the pre-trained ResNet50 from Keras"}}