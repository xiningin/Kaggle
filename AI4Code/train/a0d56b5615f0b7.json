{"cell_type":{"722f34fb":"code","b6425157":"code","2cf9e4f1":"code","6be766d4":"code","a3643e84":"code","9d81416f":"code","02f1da98":"code","12dfc5a9":"code","457886d0":"code","b89ab13d":"code","01390fe5":"code","790a0baf":"code","ffdc00d8":"code","4b8945c6":"code","eb2abc58":"code","6df9623d":"code","d609531b":"code","1819d973":"code","c2a6ba86":"markdown","66070f8f":"markdown","b5dd0e41":"markdown","e631ab99":"markdown","16ccc41b":"markdown","2145c8c0":"markdown","1a0047f5":"markdown","2ec34adb":"markdown","314dfe70":"markdown","36752a43":"markdown","318278a3":"markdown"},"source":{"722f34fb":"import matplotlib.pyplot as plt\nimport os,shutil,math,scipy,cv2\nfrom tensorflow import keras\nimport tensorflow as tf\nimport seaborn as sns\nimport pandas as pd\nimport random as rn\nimport numpy as np\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\n\nfrom PIL import Image\nfrom PIL import Image as pil_image\nfrom PIL import ImageDraw\n\nfrom tqdm import tqdm\nfrom skimage.io import imread\nfrom IPython.display import SVG\n\nfrom scipy import misc,ndimage\nfrom scipy.ndimage.interpolation import zoom\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras import layers\nfrom keras.applications.vgg16 import VGG16,preprocess_input\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Dense,Flatten,Dropout,Concatenate,GlobalAveragePooling2D,Lambda,ZeroPadding2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam,SGD","b6425157":"#Direcci\u00f3n de los ficheros\nlabels = pd.read_csv('\/kaggle\/input\/dog-breed-identification\/labels.csv')\ntrain_dir = '\/kaggle\/input\/dog-breed-identification\/train'\ntest_dir = '\/kaggle\/input\/dog-breed-identification\/test'","2cf9e4f1":"#Razas de perros\ndogs_breeds = ['scottish_deerhound','maltese_dog','entlebucher','pomeranian','labrador_retriever','basenji','airedale','leonberg','blenheim_spaniel','siberian_husky']\nD = []\nZ = []\nimgsize = 150   \ndef label_assignment(img):\n    img = img.rsplit( \".\", 1 )[ 0 ]\n    label = \"\".join(labels[labels.id == img].breed.unique())\n    return label\n\ndef resize_dataset(data_dir):\n    for img in tqdm(os.listdir(data_dir)):\n        label = label_assignment(img)\n        if label in dogs_breeds:\n            path = os.path.join(data_dir,img)\n            img = cv2.imread(path,cv2.IMREAD_COLOR)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img,(imgsize,imgsize))\n            D.append(np.array(img))\n            Z.append(str(label))\n\n        \nresize_dataset(train_dir)\nresize_dataset(test_dir)","6be766d4":"df = pd.DataFrame()\ndf['breed'] = Z\nprint(df['breed'].value_counts())\nprint('\\n#Total Load Image:   '+str(len(df.breed)))","a3643e84":"#function to show bar length\ndef barw(ax): \n    for p in ax.patches:\n        val = p.get_width() #height of the bar\n        x = p.get_x() + p.get_width() # x-position \n        y = p.get_y() + p.get_height()\/2 #y-position\n        ax.annotate(round(val,2),(x,y))\n        \n#finding top dog brands\nplt.figure(figsize = (15, 4))\nlab = labels[labels['breed'].isin(dogs_breeds)].breed\nax0 = sns.countplot(y=lab,order=lab.value_counts().index)\nbarw(ax0)\nplt.show()","9d81416f":"#Se crean dos diccionarios para pasar las clases de forma numerica a texto.\nclass_dogs_breeds = {'scottish_deerhound': 0,'maltese_dog': 1,'entlebucher': 2,'pomeranian': 3,'labrador_retriever': 4,'basenji': 5,'airedale': 6,'leonberg': 7,'blenheim_spaniel': 8,'siberian_husky': 9}\nclass_dogs_breeds2 = {0:'scottish_deerhound',1:'maltese_dog',2:'entlebucher',3:'pomeranian',4:'labrador_retriever',5:'basenji',6:'airedale',7:'leonberg',8:'blenheim_spaniel',9:'siberian_husky'}\n\nT = [class_dogs_breeds[item] for item in Z]\nY = to_categorical(T,10)\nX = np.array(D)\nX = X\/255\n\nx_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=42)","02f1da98":"fig,ax=plt.subplots(5,2)\nfig.set_size_inches(20,20)\nfor i in range(5):\n    for j in range (2):\n        l=rn.randint(0,len(Z))\n        ax[i,j].imshow(X[l])\n        ax[i,j].set_title('Dog: '+Z[l])\n        \nplt.tight_layout()","12dfc5a9":"base_model = VGG16(include_top=False,\n                  input_shape = (imgsize,imgsize,3),\n                  weights = 'imagenet')\n\nfor layer in base_model.layers:\n    layer.trainable = False\n    \nfor layer in base_model.layers:\n    print(layer,layer.trainable)\n\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10,activation='softmax'))\nmodel.summary()","457886d0":"path = os.path.join('..\/input\/dog-breed-identification\/test\/00102ee9d8eb90812350685311fe5890.jpg')\nimg = cv2.imread(path,cv2.IMREAD_COLOR)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg = cv2.resize(img,(imgsize,imgsize))\nx = img_to_array(img)\nx = x.reshape((1,) + x.shape)\ndatagen1 = ImageDataGenerator(rotation_range=30, fill_mode='nearest')\ndatagen2 = ImageDataGenerator(width_shift_range=0.2, height_shift_range=0.2)\ndatagen3 = ImageDataGenerator(horizontal_flip=True, vertical_flip=False)\ndatagen4 = ImageDataGenerator(zoom_range=0.3)\ndatagen5 = ImageDataGenerator(\n        rotation_range=10,  \n        zoom_range = 0.1, \n        width_shift_range=0.2,  \n        height_shift_range=0.2, \n        horizontal_flip=True,  \n        vertical_flip=False) \n\naug_iter1 = datagen1.flow(x, batch_size=1)\naug_iter2 = datagen2.flow(x, batch_size=1)\naug_iter3 = datagen3.flow(x, batch_size=1)\naug_iter4 = datagen4.flow(x, batch_size=1)\naug_iter5 = datagen5.flow(x, batch_size=1)\n\nimage1 = next(aug_iter1)[0].astype('uint8')\nimage2 = next(aug_iter2)[0].astype('uint8')\nimage3 = next(aug_iter3)[0].astype('uint8')\nimage4 = next(aug_iter4)[0].astype('uint8')\nimage5 = next(aug_iter5)[0].astype('uint8')\n\n# plot image\nfig,ax=plt.subplots(2,3)\nfig.set_size_inches(10,10)\nax[0,0].imshow(img)\nax[0,1].imshow(image5)\nax[0,2].imshow(image1)\nax[1,0].imshow(image2)\nax[1,1].imshow(image3)\nax[1,2].imshow(image4)\nax[0,0].set_title('ORIGINAL IMAGE')\nax[0,1].set_title('DISTORTED')\nax[0,2].set_title('ROTATION')\nax[1,0].set_title('WIDTH AND HEIGHT SHIFT')\nax[1,1].set_title('HORIZONTAL FLIP')\nax[1,2].set_title('ZOOM RANGE')\n        \nplt.tight_layout()\n","b89ab13d":"model.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\nhistory = model.fit_generator(\n    augs_gen.flow(x_train,y_train, batch_size=16),\n    validation_data  = (x_test,y_test),\n    epochs = 20\n)","01390fe5":"plt.plot(history.history['accuracy'], linestyle='-.', color='g')\nplt.plot(history.history['val_accuracy'], linestyle='--', color='y')\nplt.title('ACCURACY MODEL')\nplt.ylabel('ACCURACY')\nplt.xlabel('EPOCH')\nplt.legend(['TEST', 'TRAIN'], loc='upper left')\n\nplt.show()\n\nplt.plot(history.history['loss'], linestyle='-.', color='g')\nplt.plot(history.history['val_loss'], linestyle='--', color='y')\nplt.title('LOSS MODEL')\nplt.ylabel('LOSS')\nplt.xlabel('EPOCH')\nplt.legend(['TEST', 'TRAIN'], loc='upper left')\n\nplt.show()","790a0baf":"list_img = np.random.randint(0,x_test.shape[0]-1,size=10)\nfor i,img_test in enumerate(x_test[list_img]):\n    x = np.expand_dims(img_test, axis=0)\n    predictions = model.predict(x)\n\n    print(\"valor predicho:\",  np.argmax(predictions))\n    print('raza predicha: ', class_dogs_breeds2[np.argmax(predictions)])\n    print(\"max prob: \", np.max(predictions))\n    print(\"ground truth: \", np.argmax(y_test[list_img[i]]))\n    print('raza ground truth: ', class_dogs_breeds2[np.argmax(y_test[list_img[i]])])\n    plt.imshow(img_test)\n    plt.show()","ffdc00d8":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import *\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nX1 = [X[i].flatten() for i in range(X.shape[0])]","4b8945c6":"s = cross_val_score(GaussianNB(), X1, T, cv=KFold(5, shuffle=True), scoring=make_scorer(accuracy_score))\nprint(\"accuracy %.3f (+\/- %.5f)\"%(np.mean(s), np.std(s))) ","eb2abc58":"s = cross_val_score(RandomForestClassifier(), X1, T, cv=KFold(5, shuffle=True), scoring=make_scorer(accuracy_score))\nprint( \"accuracy %.3f (+\/- %.5f)\"%(np.mean(s), np.std(s)))","6df9623d":"p = Pipeline(((\"pca\", PCA(n_components=70)), (\"classifier\", SVC(kernel='rbf')) ))\ns = cross_val_score(p, X1, T, cv=KFold(5, shuffle=True), scoring=make_scorer(accuracy_score))\nprint( \"accuracy %.3f (+\/- %.5f)\"%(np.mean(s), np.std(s)))","d609531b":"p = Pipeline(((\"pca\", PCA(n_components=80)), (\"classifier\", RandomForestClassifier() )))\ns = cross_val_score(p, X1, T, cv=KFold(5, shuffle=True), scoring=make_scorer(accuracy_score))\nprint( \"accuracy %.3f (+\/- %.5f)\"%(np.mean(s), np.std(s)))","1819d973":"p = Pipeline(((\"pca\", PCA(n_components=40)), (\"classifier\", DecisionTreeClassifier(max_depth = 10) )))\ns = cross_val_score(p, X1, T, cv=KFold(5, shuffle=True), scoring=make_scorer(accuracy_score))\nprint( \"accuracy %.3f (+\/- %.5f)\"%(np.mean(s), np.std(s)))","c2a6ba86":"# CLASIFICACI\u00d3N DE RAZAS DE PERROS","66070f8f":"# Cantidad de Imagenes de Cada Raza Seleccionada\n\n- scottish_deerhound\n- maltese_dog\n- entlebucher\n- pomeranian\n- labrador_retriever\n- basenji\n- airedale\n- leonberg\n- blenheim_spaniel\n- siberian_husky ","b5dd0e41":"# **Librer\u00edas a importar**","e631ab99":"# Imagenes Aleatoria de las Razas de Perros","16ccc41b":"# Contexto\nEl conjunto de datos de Stanford Dogs contiene im\u00e1genes de 120 razas de perros de todo el mundo. Este conjunto de datos se ha creado utilizando im\u00e1genes y anotaciones de ImageNet para la tarea de categorizaci\u00f3n detallada de im\u00e1genes. Originalmente se recopil\u00f3 para la categorizaci\u00f3n de im\u00e1genes de grano fino, un problema desafiante ya que ciertas razas de perros tienen caracter\u00edsticas casi id\u00e9nticas o difieren en color y edad.\n\n# Contenido\nN\u00famero de categor\u00edas: 120\nN\u00famero de im\u00e1genes: 20.580\nAnotaciones: etiquetas de clase, cuadros delimitadores\n\n# Agradecimientos\nLa fuente de datos original se encuentra en http:\/\/vision.stanford.edu\/aditya86\/ImageNetDogs\/ y contiene informaci\u00f3n adicional sobre las divisiones de entrenamiento \/ prueba y los resultados de referencia.\n\n# DATASET Usado\nSe uso la versi\u00f3n del dataset publicado por Dog-breed-identification en la plataforma de Kaggle.","2145c8c0":"# **DATASET**","1a0047f5":"![](https:\/\/img2.rtve.es\/i\/?w=1600&i=1493315930816.jpg)* ","2ec34adb":"# MODELO VGG16 (RED NEURONAL)","314dfe70":"# **Integrantes:**\n\n1. Hollman Esteban Gonz\u00e1lez Su\u00e1rez 2172002\n2. Kevin Alonso Luna Bustos 2172022\n3. Jhoann Sebastian Martinez Oviedo 2171995","36752a43":"![](https:\/\/mlux9brz2apw.i.optimole.com\/y1pDtVQ-TuEH2CPN\/w:600\/h:344\/q:auto\/https:\/\/kgptalkie.com\/wp-content\/uploads\/2020\/09\/image-102.png)","318278a3":"![](https:\/\/qph.fs.quoracdn.net\/main-qimg-e657c195fc2696c7d5fc0b1e3682fde6)* "}}