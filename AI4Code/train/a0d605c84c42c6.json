{"cell_type":{"1c7c17b6":"code","60ba0ebd":"code","e44e03a7":"code","5f705bea":"code","b9c6f827":"code","937df7bc":"code","2f803214":"code","fc893e63":"code","ec9d256f":"code","b00e91e9":"code","5ced3d8c":"code","833435fc":"code","282135fe":"code","008868ec":"code","d6e9f14e":"markdown","2791d796":"markdown","7297c275":"markdown","138a8902":"markdown","98c23f1e":"markdown","86b670c7":"markdown","15f5734a":"markdown","644c58f6":"markdown","380ca875":"markdown","d6d17eb3":"markdown"},"source":{"1c7c17b6":"import os, random\nimport shutil\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom skimage.transform import resize\n\nfrom collections import defaultdict\nimport h5py\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom ipywidgets import interact, interactive\nimport nibabel as nib\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv3D, Dropout, MaxPooling3D, UpSampling3D, Activation, BatchNormalization, PReLU, Conv3DTranspose, concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n#tf.enable_eager_execution()\n\n# force channels-last ordering\ntf.keras.backend.set_image_data_format('channels_last')\nprint(tf.keras.backend.image_data_format())\n\n","60ba0ebd":"def dice_coefficient_loss(y_true, y_pred,eps=1e-9):\n    intersect = 2*(K.sum(y_true * y_pred))\n    union = K.sum(y_pred) + K.sum(y_true) \n    dice_score=(intersect + eps) \/ (union+eps)\n    return 1.0 - dice_score\n\ndef BCEDiceLoss(y_true, y_pred,eps=1e-9):\n    intersect = 2*(K.sum(y_true * y_pred))\n    union = K.sum(y_pred) + K.sum(y_true) \n    dice_score=(intersect + eps) \/ (union+eps)\n    dice_loss=1.0 - dice_score\n    bce = tf.keras.losses.BinaryCrossentropy()\n    BCE =  bce(y_true, y_pred)\n    return dice_loss + BCE","e44e03a7":"def zer_one(img,threshold=0.5):\n    ones = K.ones_like(img)    \n    zeros = K.zeros_like(img)\n    output = K.switch(K.greater(img,threshold), ones, img)\n    output = K.switch(K.less_equal(output,threshold), zeros, output)\n    return output\n\ndef confusion_matrix_calc(targets,inputs):\n    inputs= tf.math.argmax(inputs, axis=-1)\n    inputs=tf.expand_dims(inputs, -1, name=None)\n    inputs=tf.cast(inputs, dtype=tf.float32, name=None)\n    tn = K.sum(inputs * targets) #K.sum(inputs+targets-(inputs * targets))\n    tp = K.sum((inputs * targets))\n    fp = K.sum(((1-targets) * inputs))\n    fn = K.sum((targets * (1-inputs)))\n    return tn,fp,fn,tp\n\nBETA=0.5\nALPHA=1.5\nthreshold=0.5\n \n#@tf.function\ndef TPR(targets, inputs, alpha=ALPHA, beta=BETA, smooth=1e-6):\n    tn, fp, fn, tp=confusion_matrix_calc(targets,inputs)\n    TPR = (tp +smooth)\/(tp+fn+smooth)\n    return TPR\n#@tf.function\ndef FPR(targets, inputs, alpha=ALPHA, beta=BETA, smooth=1e-6):\n    tn, fp, fn, tp=confusion_matrix_calc(targets,inputs)\n    FPR = (fp +smooth)\/(fp+tp+ smooth) \n    return FPR\n#@tf.function \ndef FNR(targets, inputs, alpha=ALPHA, beta=BETA, smooth=1e-6):\n    tn, fp, fn, tp=confusion_matrix_calc(targets,inputs)\n    FNR = (fn+smooth)\/(tp+fn+smooth)\n    return FNR\n      \ndef Tversky(targets, inputs, alpha=ALPHA, beta=BETA, smooth=1e-6):\n    tn, fp, fn, tp=confusion_matrix_calc(targets,inputs)\n        \n    #tn, fp, fn, tp=confusion_matrix_calc(targets,inputs).ravel()\n    Tversky = (tp + smooth) \/ (tp + alpha*fp + beta*fn + smooth) \n    return Tversky\n\ndef dice_coefficient(y_true, y_pred, smooth=1.,eps: float = 1e-9):\n    y_true=zer_one(y_true)\n    y_pred=zer_one(y_pred)\n    batch_num=y_true.shape[0]\n    #print(\"batch_num\",batch_num)\n\n    #print(\"y_true\",y_true.shape,\"y_pred\",y_pred.shape)\n    intersec = K.sum(y_true * y_pred,axis=[1,2,3,4])\n    union = K.sum(y_pred ,axis=[1,2,3,4]) + K.sum(y_true,axis=[1,2,3,4]) \n    #print(\"intersec\",intersec,\"union\",union)\n    dice_coefficient=(2*intersec + eps) \/ (union+eps)\n    dice_coefficient_arr=dice_coefficient.numpy()\n    #print(\"dice_coefficient_arr shape\",dice_coefficient_arr.shape)\n    for i in range(len(dice_coefficient_arr)):\n        if K.sum(y_true)==0 and K.sum(y_pred)==0:\n            dice_coefficient_arr[i]=1\n    dice_coefficient=tf.convert_to_tensor(dice_coefficient_arr)\n    return K.mean(dice_coefficient )","5f705bea":"from shutil import copyfile\ncopyfile('..\/input\/isbi-data-processing\/train_data.csv', '.\/train_data.csv')","b9c6f827":"df=pd.read_csv('.\/train_data.csv')\ndf.columns","937df7bc":"df['path']=df['path'].str.replace('.\/','..\/input\/isbi-data-processing\/',1)\ndf['mask1_path']=df['mask1_path'].str.replace('.\/','..\/input\/isbi-data-processing\/',1)\ndf['mask2_path']=df['mask2_path'].str.replace('.\/','..\/input\/isbi-data-processing\/',1)\ndf['mask2_path'][0]\ndf.to_csv('.\/train_data.csv',index=False)","2f803214":"class GlobalConfig:\n    #data pathes config\n    root_dir = '..\/input\/isbi-data-processing\/'\n    train_root_dir = root_dir+'training'\n    test_root_dir = root_dir+'testing'\n    train_csv_path = '.\/train_data.csv'\n    test_csv_path = root_dir+'test_data.csv'    \n    patch_index_csv_path = root_dir+'patch_index.csv'\n\n\n    train_logs_path = '.\/model\/train_log.csv'\n    ae_pretrained_model_path = '.\/model\/autoencoder_best_model.pth'    \n    \n    #preprocess data config\n    modalities = ['flair_pp.nii','mprage_pp.nii','pd_pp.nii','t2_pp.nii']\n    seed = 55  \n    k_fold=4\n    \n    #model config\n    channels=len(modalities)\n    out_channels=1\n    input_shape = (32, 32, 32, channels)\n    depth = 4 # depth of layers for V\/Unet\n    n_base_filters = 32\n    pooling_kernel = (2, 2, 2)  # pool size for the max pooling operations\n    deconvolution = True  # if False, will use upsampling instead of deconvolution\n    \n    #model train config\n    #where the model weights initialization so each time begin with the same weight to compare between different models\n    initial_weights_path=root_dir+'initial_weights.hdf5'\n    #Where to save the model weights during train\n    #metrics=['mse']\n    metrics=['mse',TPR,FPR,FNR,Tversky,dice_coefficient]\n    weights_file_path = 'weight\/'\n    patience = 5  # learning rate will be reduced after this many epochs if the validation loss is not improving\n    early_stop = 20  # training will be stopped after this many epochs without the validation loss improving\n    initial_learning_rate = 1e-3\n    learning_rate_drop = 0.1  # factor by which the learning rate will be reduced\n    n_epochs = 50\n\n    run_eagerly=True\n    train_history_path='history.csv'\n    \n    batch_size=20\n    #len(config[\"modality\"])\n\ndef seed_everything(seed: int):\n    np.random.seed(seed)\n    #torch.manual_seed(seed)\n    #if torch.cuda.is_available():\n    #    torch.cuda.manual_seed(seed)\n    \nconfig = GlobalConfig()\nseed_everything(config.seed)","fc893e63":"class ISBIDataset(tf.keras.utils.Sequence):\n    def __init__(self, df: pd.DataFrame,patch_index_df,modalities, phase: str=\"test\", \n                 is_resize: bool=False,batch_size=10):\n        self.df = df\n        self.phase = phase\n        #self.augmentations = get_augmentations(phase)\n        self.data_types = modalities\n        self.is_resize = is_resize\n        self.patch_gap=16\n        self.patch_df=patch_index_df \n        self.index=0\n        self.batch_size=batch_size\n    def __len__(self):\n        return int((self.df.shape[0] * self.patch_df.shape[0])\/self.batch_size)\n    \n    def __getitem__(self, batch_index):\n        #batch start index\n        #batch size choosen to make the batch in the same image\n        index=batch_index* self.batch_size\n        idx=int(index\/self.patch_df.shape[0])\n        patient_id,study =self.df.loc[idx,['patient_id','study']]\n        root_path=self.df.loc[(self.df['patient_id'] == patient_id) & (self.df['study'] == study),'path'].values[0]\n        # load all modalities\n        images = []\n        for data_type in self.data_types:\n            img_path = root_path+patient_id+\"_\"+study+data_type\n            img = self.load_img(img_path)\n            if self.is_resize:\n                img = self.resize(img)\n            img=np.pad(img, ((5,6), (3,4), (5,6)), 'constant')\n            img = self.normalize(img)\n            images.append(img)\n            \n        img = np.stack(images)\n        #shape (x,y,z,channel)\n        img=np.moveaxis(img,(0,1,2,3),(3,0,1,2))\n        \n        if self.phase != \"test\":\n            mask_path =  self.df.loc[(self.df['patient_id'] == patient_id)&(self.df['study'] == study),'mask1_path'].values[0]\n            mask = self.load_img(mask_path)\n            mask=np.pad(mask, ((5,6), (3,4), (5,6)), 'constant')\n \n            if self.is_resize:\n                mask = self.resize(mask)\n                mask = np.clip(mask.astype(np.uint8), 0, 1).astype(np.float32)\n                mask = np.clip(mask, 0, 1)\n            mask = np.clip(mask.astype(np.uint8), 0, 1).astype(np.float32)\n            mask = np.clip(mask, 0, 1)\n            #shape(x,y,z,channel=1)\n            mask=np.moveaxis(np.expand_dims(mask,0),(0,1,2,3),(3,0,1,2))\n            #augmented = self.augmentations(image=img.astype(np.float32), \n            #                              mask=mask.astype(np.float32))\n            \n            #img = augmented['image']\n            #mask = augmented['mask']\n            '''\n            return {\n                \"Id\": id_,\n                \"image\": img,\n                \"mask\": mask,\n            }\n            '''\n            '''\n            for i,row in self.patch_df.iterrows():\n                self.index+=1\n                print('index=',self.index)\n            '''\n            # batches\n            patch_images=[]\n            patch_masks=[]\n            for b in range(self.batch_size):\n                row=self.patch_df.loc[(index+b)%self.patch_df.shape[0]]\n                size=32\n                patch_img=img[row[0]:row[0]+size, row[1]:row[1]+size, row[2]:row[2]+size,:]\n                patch_mask=mask[row[0]:row[0]+size,row[1]:row[1]+size,row[2]:row[2]+size,:]\n                patch_images.append(patch_img)\n                \n                patch_masks.append(patch_mask)\n                \n            patch_images=np.stack(patch_images)\n            patch_masks=np.stack(patch_masks)\n            #return np.moveaxis(np.expand_dims(img,axis=-1), (0, 1, 2, 3,4), ( 4, 1, 2,3,0)),  np.expand_dims(np.expand_dims(mask,axis=-1),0)\n            #return np.moveaxis(np.expand_dims(patch_img,axis=-1), (0, 1, 2, 3,4), ( 4, 1, 2,3,0)),  np.expand_dims(np.expand_dims(patch_mask,axis=-1),0)\n            return patch_images,patch_masks\n        '''\n        return {\n            \"Id\": id_,\n            \"image\": img,\n        }\n        '''\n        \n        return np.moveaxis(np.expand_dims(mask,axis=-1), (0, 1, 2, 3,4), ( 4, 1, 2,3,0))\n    \n    def load_img(self, file_path):\n        data = nib.load(file_path)\n        data = np.asarray(data.dataobj)\n        return data\n    \n    def normalize(self, data: np.ndarray):\n        data_min = np.min(data)\n        return (data - data_min) \/ (np.max(data) - data_min)\n    \n    def resize(self, data: np.ndarray):\n        data = resize(data, (64, 120, 120), preserve_range=True)\n        return data","ec9d256f":"class U_Net_Model(tf.keras.Model):\n    '''\n    conv block\n        - convolution layer\n        - activation\n        - batch normalization layer, instance normalization layer\n        - drop out\n        - convolution layer\n        - activation\n        - max pooling layer, average pooling layer\n\n    '''\n    def __init__(self, model_input_shape,\n                 out_channel=1, \n                 pooling_kernel=(2, 2, 2),\n                 drop_out=False,\n                 drop_rate=0.1,\n                 initial_learning_rate=0.00001,\n                 deconvolution=False, \n                 depth=4, \n                 n_base_filters=32,\n                 kernel=(3,3,3),\n                 padding='same',\n                 strides=(1,1,1),\n                 up_strides=(2,2,2),\n                 up_kernel=(2,2,2),\n                 max_pooling=False,\n                 batch_normalization=False,\n                 instance_normalization=False,\n                 activation=\"sigmoid\"):\n        super().__init__()\n        self.model_input_shape = model_input_shape\n        self.out_channel=out_channel\n        self.pooling_kernel = pooling_kernel\n        self.drop_out=drop_out\n        self.drop_rate=drop_rate\n        self.initial_learning_rate = initial_learning_rate\n        self.deconvolution = deconvolution\n        self.depth = depth\n        self.n_base_filters = n_base_filters\n        self.kernel=kernel\n        self.padding=padding\n        self.strides=strides\n        self.up_strides=up_strides\n        self.up_kernel=up_kernel\n        self.max_pooling=max_pooling\n        self.batch_normalization = batch_normalization\n        self.instance_normalization=instance_normalization\n        self.activation = activation\n\n        self.unet_model = self.unet_model_3d(\n            input_shape=self.model_input_shape ,\n            out_channel=self.out_channel,\n            pooling_kernel=self.pooling_kernel ,\n            drop_out=self.drop_out,\n            drop_rate=self.drop_rate,\n            initial_learning_rate=self.initial_learning_rate ,\n            deconvolution=self.deconvolution ,\n            depth=self.depth ,\n            n_base_filters=self.n_base_filters ,\n            kernel=self.kernel,\n            padding=self.padding,\n            strides=self.strides,\n            up_strides=self.up_strides,\n            up_kernel=self.up_kernel,\n            max_pooling=self.max_pooling,\n            batch_normalization=self.batch_normalization ,\n            instance_normalization=self.instance_normalization,\n            activation=self.activation )\n        \n    def call(self, inputs):\n        return self.unet_model(inputs)\n\n    \n    def train_step22(self, data):\n        # Unpack the data. Its structure depends on your model and\n        # on what you pass to `fit()`.\n        x, y = data\n        #print(\"x\",x)\n        #print(\"x\",K.int_shape(x),\"y\",K.int_shape(y))\n        with tf.GradientTape() as tape:\n            y_pred = self(x, training=True)  # Forward pass\n            # Compute the loss value\n            # (the loss function is configured in `compile()`)\n            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n\n        # Compute gradients\n        trainable_vars = self.trainable_variables\n        gradients = tape.gradient(loss, trainable_vars)\n        # Update weights\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n        # Update metrics (includes the metric that tracks the loss)\n        self.compiled_metrics.update_state(y, y_pred)\n        # Return a dict mapping metric names to current value\n        return {m.name: m.result() for m in self.metrics}\n    \n    def create_convolution_block(self,input_layer, \n                                 n_filters, \n                                 batch_normalization,\n                                 drop_out,\n                                 drop_rate,\n                                 kernel, \n                                 padding, \n                                 strides,\n                                 max_pooling, \n                                 pooling_kernel, \n                                 instance_normalization,\n                                activation=None):\n        \"\"\"\n        :param input_layer:\n        :param n_filters:\n        :param batch_normalization:\n        :param kernel:\n        :param activation: Keras activation layer to use. (default is 'relu')\n        :param padding:\n        :return:\n        \"\"\"\n        # conv layer\n        layer = Conv3D(n_filters, kernel, padding=padding, strides=strides)(input_layer)\n\n        # activation layer\n        if activation is None:\n            layer= Activation('relu')(layer)\n        else:\n            layer= activation()(layer)\n\n        # batch normalization or instance normalization layer\n        if batch_normalization:\n            layer = BatchNormalization(axis=1)(layer)\n        elif instance_normalization:\n            try:\n                from keras_contrib.layers.normalization import InstanceNormalization\n            except ImportError:\n                raise ImportError(\"Install keras_contrib in order to use instance normalization.\"\n                                  \"\\nTry: pip install git+https:\/\/www.github.com\/farizrahman4u\/keras-contrib.git\")\n            layer = InstanceNormalization(axis=1)(layer)\n\n        # drop out layer\n        if drop_out:\n            layer=Dropout(drop_rate)(layer)\n\n        # conv layer\n        layer = Conv3D(n_filters, kernel, padding=padding, strides=strides)(layer)\n\n        # activation layer\n        if activation is None:\n            layer= Activation('relu')(layer)\n        else:\n            layer= activation()(layer)\n\n        '''\n        \n        # max pooling layer\n        if max_pooling:\n            layer= MaxPooling3D(pooling_kernel)(layer)\n        '''\n        return layer\n        \n    \n    def get_up_convolution(self, n_filters, \n                           pooling_kernel, \n                           kernel, \n                           strides, \n                           deconvolution):\n        if deconvolution:\n            return Conv3DTranspose(filters=n_filters, kernel_size=kernel, strides=strides)\n        else:\n            return UpSampling3D(size=pooling_kernel)\n\n    # metrics=dice_coefficient\n    def unet_model_3d(self, input_shape,\n                      out_channel=3, \n                      pooling_kernel=(2, 2, 2),\n                      drop_out=False,\n                      drop_rate=0.1,\n                      initial_learning_rate=0.00001,\n                      deconvolution=False, \n                      depth=4, \n                      n_base_filters=32,\n                      kernel=(3,3,3),\n                      padding='same',\n                      strides=(1, 1, 1),\n                      up_strides=(2,2,2),\n                      up_kernel=(2,2,2),\n                      max_pooling=False,\n                      batch_normalization=False, \n                      instance_normalization=False,\n                      activation=\"sigmoid\"):\n        \n        \"\"\"\n        Builds the 3D UNet Keras model.f\n        :param metrics: List metrics to be calculated during model training (default is dice coefficient).\n        :param n_base_filters: The number of filters that the first layer in the convolution network will have. Following\n        layers will contain a multiple of this number. Lowering this number will likely reduce the amount of memory required\n        to train the model.\n        :param depth: indicates the depth of the U-shape for the model. The greater the depth, the more max pooling\n        layers will be added to the model. Lowering the depth may reduce the amount of memory required for training.\n        :param input_shape: Shape of the input data (n_chanels, x_size, y_size, z_size). The x, y, and z sizes must be\n        divisible by the pool size to the power of the depth of the UNet, that is pooling_kernel^depth.\n        :param pooling_kernel: Pool size for the max pooling operations.\n        :param n_labels: Number of binary labels that the model is learning.\n        :param initial_learning_rate: Initial learning rate for the model. This will be decayed during training.\n        :param deconvolution: If set to True, will use transpose convolution(deconvolution) instead of up-sampling. This\n        increases the amount memory required during training.\n        :return: Untrained 3D UNet Model\n        \"\"\"\n        inputs = Input(input_shape)\n        current_layer = inputs\n        levels = []\n        print(f'input shape {inputs.shape}')\n        # add levels with max pooling\n        for layer_depth in range(depth):\n            layer1 = self.create_convolution_block(input_layer=current_layer, \n                                                   n_filters=n_base_filters*(2**layer_depth),\n                                                   batch_normalization=batch_normalization,\n                                                   drop_out=drop_out,\n                                                   drop_rate=drop_rate,\n                                                   kernel=kernel,\n                                                   \n                                                   padding=padding,\n                                                   strides=strides,\n                                                   max_pooling=max_pooling,\n                                                   pooling_kernel=pooling_kernel,\n                                                   instance_normalization=instance_normalization,\n                                                  activation=None)\n            \n            if layer_depth < depth - 1:\n                current_layer = MaxPooling3D(pool_size=pooling_kernel)(layer1)\n                levels.append([layer1, current_layer])\n            else:\n                current_layer = layer1\n                levels.append([layer1])\n        # add levels with up-convolution or up-sampling\n        for layer_depth in range(depth-2, -1, -1):\n            \n            up_convolution = self.get_up_convolution(n_filters=current_layer.shape[1],\n                                                     pooling_kernel=pooling_kernel, \n                                                     kernel=up_kernel,\n                                                     strides=up_strides,\n                                                     deconvolution=deconvolution)(current_layer)\n            concat = concatenate([up_convolution, levels[layer_depth][0]], axis=4)\n            current_layer = self.create_convolution_block(input_layer=concat, \n                                                   n_filters=levels[layer_depth][0].shape[-1],\n                                                   batch_normalization=batch_normalization,\n                                                   drop_out=drop_out,\n                                                   drop_rate=drop_rate,\n                                                   kernel=kernel,\n                                                   \n                                                   padding=padding,\n                                                   strides=strides,\n                                                   max_pooling=max_pooling,\n                                                   pooling_kernel=pooling_kernel,\n                                                   instance_normalization=instance_normalization,\n                                                         activation=None)\n\n        # number of labels: 1\n        final_convolution = Conv3D(out_channel, (1, 1, 1))(current_layer)\n        act = Activation(activation)(final_convolution)\n        model = Model(inputs=inputs, outputs=act)\n\n        #model.summary()\n        return model\n    \n    def get_callbacks(self,weights_file_path, fold, initial_learning_rate=0.0001, learning_rate_drop=0.5,\n                      learning_rate_patience=50, verbosity=1, early_stopping_patience=None):\n\n        check_point = ModelCheckpoint(weights_file_path+'fold_' + fold + '_weights-{epoch:02d}-{val_loss:.2f}.hdf5', save_best_only=True)\n        csv_log = CSVLogger(weights_file_path+'training-log.csv', append=True)\n\n        # potential problem of recude learning rate: https:\/\/github.com\/keras-team\/keras\/issues\/10924\n        reduce = ReduceLROnPlateau(factor=learning_rate_drop, patience=learning_rate_patience, verbose=verbosity)\n        if early_stopping_patience:\n            early_stop = EarlyStopping(verbose=verbosity, patience=early_stopping_patience)\n            return [check_point, csv_log, reduce, early_stop]\n        else:\n            return [check_point, csv_log, reduce]\n        ","b00e91e9":"df = pd.read_csv(config.train_csv_path)\npatch_df=pd.read_csv(config.patch_index_csv_path)\nlosses={\"BCEDiceLoss\":BCEDiceLoss,\"dice_coefficient_loss\":dice_coefficient_loss}\n\nfor k in losses.keys():\n    for fold in range(config.k_fold):\n        config.weights_file_path=\".\/\"+k+\"\/\"\n        os.makedirs(config.weights_file_path, exist_ok=True)\n\n        train_df = df.loc[df['fold'] != fold].reset_index(drop=True)\n        val_df = df.loc[df['fold'] == fold].reset_index(drop=True)\n        train_generator=ISBIDataset(train_df,patch_df,modalities=config.modalities, \n                                    phase=\"train\", is_resize=False,batch_size=config.batch_size)\n        valid_generator=ISBIDataset(val_df, patch_df,modalities=config.modalities, \n                                    phase=\"valid\", is_resize=False,batch_size=config.batch_size)\n\n        print ('-'*100)\n        print (\"Fold:\", fold)\n\n        # create model\n        model=U_Net_Model(config.input_shape,\n                              config.out_channels,\n                              depth=config.depth, \n                              initial_learning_rate=config.initial_learning_rate,\n                              deconvolution=config.deconvolution)\n        model.build((None ,*config.input_shape))\n        model.load_weights(config.initial_weights_path)\n        #model.summary()\n        if not isinstance(config.metrics, list):\n            config.metrics = [config.metrics]\n        model.compile(optimizer=Adam(lr=config.initial_learning_rate), \n                      loss=losses[k], metrics=config.metrics,run_eagerly=config.run_eagerly)\n        callbacks = model.get_callbacks(config.weights_file_path, str(fold),\n                                initial_learning_rate=config.initial_learning_rate,\n                                learning_rate_drop=config.learning_rate_drop,\n                                learning_rate_patience=config.patience,\n                                early_stopping_patience=config.early_stop)\n        \n        history=model.fit(x=train_generator,\n                  batch_size=config.batch_size,\n                  epochs=config.n_epochs,\n                  verbose=1,\n                  callbacks=callbacks,\n                  validation_data=valid_generator,\n                  validation_batch_size=config.batch_size,\n                  workers=4)\n        #history.history is dict can be saved to dataframe\n        history_dict=history.history\n        history_df = pd.DataFrame.from_dict(history_dict) \n        history_df.to_csv(config.weights_file_path+config.train_history_path, index=False)\n        break \n        ","5ced3d8c":"import numpy as np\nimport nibabel as nib\nimport h5py\n\nclass Reconstruct:\n    def __init__(self, ind, shape, patch_size, to_weight):\n        # find its original image: d.data[str(shape)][ind][0]\n        # find its target image: d.data[str(shape)][ind][1]\n        self.ind = ind\n        self.shape = shape\n        self.patch_size = patch_size\n        # weight the patch before merging or not\n        self.to_weight = to_weight\n        \n        self.data = np.zeros(shape)\n        self.image = np.zeros(shape)\n        self.target = np.zeros(shape)\n        self.count = np.zeros(shape, dtype=np.float32)\n        \n#         construct softmax map for distance from the boundary\n\n        if self.to_weight is False:\n            self.dist_map = np.ones(patch_size)\n        else:\n            self.dist_map = np.zeros(patch_size)\n            mini = 0\n            minj = 0\n            mink = 0\n            for i in range(patch_size[0]):\n                mini = min(i+1, patch_size[0]-i)\n                for j in range(patch_size[1]):\n                    minj = min(j+1, patch_size[1]-j)\n                    for k in range(patch_size[2]):\n                        mink = min(k+1, patch_size[2]-k)\n    #                     print(i, j, k, mini, minj, mink)\n                        self.dist_map[i, j, k] = min(mini, minj, mink)\n    #         print(self.dist_map)\n            self.dist_map = np.exp(self.dist_map)\/np.sum(np.exp(self.dist_map))\n    \n#             self.dist_map = np.zeros(patch_size)\n#             center = (np.array(patch_size)-1) \/ 2\n#             center_dist = np.linalg.norm(center)\n#             for i in range(patch_size[0]):\n#                 for j in range(patch_size[1]):\n#                     for k in range(patch_size[2]):\n#     #                     print([i, j, k], np.array([i, j, k]) - center)\n#                         self.dist_map[i, j, k] = center_dist - np.linalg.norm(np.array([i, j, k]) - center)\n#     #         print(self.dist_map)\n#             self.dist_map[self.dist_map < 0] = 0\n#             self.dist_map = np.exp(self.dist_map)\/np.sum(np.exp(self.dist_map))\n#     #         print(self.dist_map)\n\n        \n    def add(self, patch, index):\n        patch = patch * self.dist_map\n        # get patch data\n        patch_index = np.zeros(self.shape, dtype=np.bool)\n        \n        patch_index[...,\n                    index[0]:index[0]+patch.shape[0],\n                    index[1]:index[1]+patch.shape[1],\n                    index[2]:index[2]+patch.shape[2]] = True\n        \n        patch_data = np.zeros(self.shape)\n        patch_data[patch_index] = patch.flatten()\n        \n        # store patch data in self.data\n        new_data_index = np.logical_and(patch_index, np.logical_not(self.count > 0))\n        self.data[new_data_index] = patch_data[new_data_index]\n        \n        # average overlapped region\n        averaged_data_index = np.logical_and(patch_index, self.count > 0)\n        if np.any(averaged_data_index):\n            self.data[averaged_data_index] = (self.data[averaged_data_index] * self.count[averaged_data_index] + \n                                              patch_data[averaged_data_index]) \/ (self.count[averaged_data_index] + 1)\n#         self.count[patch_index] += 1\n#         print(self.count[patch_index].shape, self.dist_map.shape)\n        self.count[ index[0]:index[0]+patch.shape[-3],\n                    index[1]:index[1]+patch.shape[-2],\n                    index[2]:index[2]+patch.shape[-1]] += 1\n        \n    def store(self, name):\n        \n        with h5py.File( name + \".h5\", 'w') as f:\n            f.create_dataset(\"index\", data=self.ind)\n            f.create_dataset(\"shape\", data=self.shape)\n            f.create_dataset(\"data\", data=self.data)\n        nib.save(nib.Nifti1Image(self.data, np.eye(4)),  name + \".nii.gz\")","833435fc":"\n\n\n# weight_path = ['\/model\/weight\/spring2019\/fold0_all_patch_weights-05-0.40.hdf5',\n#                '\/model\/weight\/spring2019\/fold0_weights-03-0.39.hdf5',\n#                '\/model\/weight\/spring2019\/fold_binary0weights-05-0.06.hdf5',\n#               ]\n# weight_name = ['all',\n#                'normal',\n#                'binary',\n#               ]\ndef load_img(file_path):\n    data = nib.load(file_path)\n    data = np.asarray(data.dataobj)\n    return data\n    \ndef normalize(data: np.ndarray):\n    data_min = np.min(data)\n    return (data - data_min) \/ (np.max(data) - data_min)\n\nweight_path = ['.\/dice_coefficient_loss\/fold_0_weights-01-0.48.hdf5',\n              ]\nweight_name = ['dice',\n              ]\nfold=0\ndata_types = ['flair_pp.nii','mprage_pp.nii','pd_pp.nii','t2_pp.nii']\ndf=pd.read_csv('.\/train_data.csv')\n#df['path']=df['path'].str.replace('.', '..\/input\/isbi-dataset-ms-lesion-segmentation',1)\n#df['mask1_path']=df['mask1_path'].str.replace('.', '..\/input\/isbi-dataset-ms-lesion-segmentation',1)\n\n\ntrain_df = df.loc[df['fold'] != fold].reset_index(drop=True)\nval_df = df.loc[df['fold'] == fold].reset_index(drop=True)\npatch_index_df=pd.read_csv('..\/input\/isbi-data-processing\/patch_index.csv')\n# set up valid index\n\nfor i_weight in range(len(weight_path)):\n    print(\"loading weight: \", weight_name[i_weight])\n    model=U_Net_Model(config.input_shape,\n                          config.out_channels,\n                          depth=config.depth, \n                          initial_learning_rate=config.initial_learning_rate,\n                          deconvolution=config.deconvolution)\n    model.build((None ,*config.input_shape))\n    model.load_weights('.\/dice_coefficient_loss\/fold_0_weights-01-0.48.hdf5') \n    \n\n    fold_index = 0\n    for i,row in val_df.iterrows():\n        patient_id,study,root_path,mask_path = row['patient_id'],row['study'],row['path'],row['mask1_path']\n        # load all modalities\n        images = []\n        for data_type in data_types:\n            img_path = root_path+patient_id+\"_\"+study+data_type\n            img = load_img(img_path)\n\n            img=np.pad(img, ((5,6), (3,4), (5,6)), 'constant')\n            img = normalize(img)\n            images.append(img)\n            \n        img = np.stack(images)\n        #shape (x,y,z,channel)\n        img=np.moveaxis(img,(0,1,2,3),(3,0,1,2))\n\n        mask = load_img(mask_path)\n        mask=np.pad(mask, ((5,6), (3,4), (5,6)), 'constant')\n\n        mask = np.clip(mask.astype(np.uint8), 0, 1).astype(np.float32)\n        mask = np.clip(mask, 0, 1)\n        shape=mask.shape\n        #shape(x,y,z,channel=1)\n        mask=np.moveaxis(np.expand_dims(mask,0),(0,1,2,3),(3,0,1,2))\n        size=32\n        patch_size=(32,32,32)\n        predict  = Reconstruct(i, shape, patch_size, False)\n        truth = Reconstruct(i, shape, patch_size, False)\n\n        for b in range(patch_index_df.shape[0]):\n            patch_index_row=patch_index_df.loc[b]\n            \n            patch_img=img[patch_index_row[0]:patch_index_row[0]+size, \n                          patch_index_row[1]:patch_index_row[1]+size, \n                          patch_index_row[2]:patch_index_row[2]+size,:]\n            patch_mask=mask[patch_index_row[0]:patch_index_row[0]+size,\n                            patch_index_row[1]:patch_index_row[1]+size,\n                            patch_index_row[2]:patch_index_row[2]+size,0]\n            patch_img=np.expand_dims(patch_img,axis=0)\n            #patch_mask=np.expand_dims(patch_mask,axis=0)\n            result = model.predict(patch_img)\n            result=K.argmax(result,axis=-1)\n            result=np.squeeze(result,axis=0)\n            #print(patch_img.shape,patch_mask.shape,result.shape,patch_index_row)\n            predict.add(result, patch_index_row)\n            truth.add(patch_mask, patch_index_row)\n\n        dir_name = '.\/model\/h5df_data\/recon\/' + weight_name[i_weight] + '\/'\n        os.makedirs(os.path.dirname(dir_name), exist_ok=True)\n        file_name = dir_name+ patient_id+\"_\"+study\n        predict.store(file_name + \"_predict\")\n        truth.store(file_name + \"_target\")\n        print('reconstruct',patient_id+\"_\"+study)\nprint(\"finish reconstructing image\")","282135fe":"def show_image(images):\n    # show image with [None, None, : ,: ,:] dimension\n    def show_frame(id):\n        length = len(images)\n        for i in range(length):\n            ax = plt.subplot(1, length, i+1)\n            if (i == 0):\n                ax.set_title(\"Input\")\n            if (i == 1):\n                ax.set_title(\"Target\")\n            if (i == 2):\n                ax.set_title(\"Output\")\n            plt.imshow(images[i][id, :, :], cmap='gray')\n    interact(show_frame, \n             id=widgets.IntSlider(min=0, max=images[0].shape[0]-1, step=1, value=images[0].shape[0]\/2))","008868ec":"'''\n#flair_image=load_img('\/content\/training\/training05\/preprocessed\/training05_01_flair_pp.nii')\ntarget=load_img('.\/model\/h5df_data\/recon\/dice\/training01_01__target.nii.gz')\npredict=load_img('.\/model\/h5df_data\/recon\/dice\/training01_01__predict.nii.gz')\nshow_image([predict,target])\n'''\n","d6e9f14e":"# loss functions","2791d796":"# Config","7297c275":"# Imports","138a8902":"# Reconstruct","98c23f1e":"# Train","86b670c7":"# Generator","15f5734a":"# Visualize","644c58f6":"# Show Image","380ca875":"# Model","d6d17eb3":"# Metric functions"}}