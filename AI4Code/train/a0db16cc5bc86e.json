{"cell_type":{"9f2ee614":"code","597b2ce0":"code","9dda7988":"code","d867fcb5":"code","718386cf":"code","3dcf1631":"code","624f2846":"code","a5846bb9":"code","a12fd510":"code","365576bb":"code","4e9357c3":"code","4e13d4d0":"code","78be9d74":"code","8a84e82c":"code","c21a006d":"code","8aeb5bf8":"code","e8fea3a4":"code","7f7ca4c1":"code","5e99f9ee":"code","d9d961ca":"code","cc0649d6":"code","44dff141":"code","a60c44c5":"code","d5565864":"code","c549862d":"code","d25e7826":"code","c81063bf":"code","9726e94c":"code","b97b6a2f":"code","8b547392":"code","34f16a91":"markdown","0e98a77b":"markdown"},"source":{"9f2ee614":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","597b2ce0":"from PIL import Image\nimport numpy as np\nimport os\nimport shutil\n#from tqdm import tqdm\nfrom tqdm.notebook import trange, tqdm\nimport imageio\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom random import shuffle\nimport random\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\n\"\"\"\nimport keras\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.utils import to_categorical\nfrom keras.regularizers import l2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras import optimizers\n\nfrom keras.layers import Activation, Dense, Dropout, Flatten\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D # to add convolutional layers\nfrom keras.layers.convolutional import MaxPooling2D # to add pooling layers\nfrom keras.layers.advanced_activations import LeakyReLU,ThresholdedReLU\n\n\"\"\"\nimport tensorflow as tf\n#tf.logging.set_verbosity(tf.logging.ERROR)\nimport cv2\n","9dda7988":"def plot_loss_accuracy(history):\n    historydf = pd.DataFrame(history.history, index = history.epoch)\n    plt.figure(figsize=(8, 6))\n    historydf.plot(ylim=(0, max(1, historydf.values.max())))\n    loss = history.history['val_loss'][-1]\n    acc = history.history['val_accuracy'][-1]\n    plt.title('Validation Loss: %.3f, Validation Accuracy: %.3f' % (loss, acc))","d867fcb5":"train_categories = pd.read_csv('\/kaggle\/input\/train.csv')\ntrain_categories['Image'] =  train_categories['Image'].apply(lambda x: int(x.split('.')[0]))\ntrain_images = train_categories.Image.values.tolist()\nlocation = '\/kaggle\/input\/identify_dance_form\/'\ntrainLabels = {}\nf = open(\"\/kaggle\/input\/train.csv\", \"r\")\ndances = f.read()\ndances = dances.split('\\n')\n\nfor i in tqdm(range(len(dances) - 1)):\n    dances[i] = dances[i].split(',')\n    trainLabels[dances[i][0]] = dances[i][1]\ndel trainLabels['Image']\n\ntest_images = pd.read_csv('\/kaggle\/input\/test.csv')\ntestImages = test_images.Image.values.tolist()","718386cf":"Dances = trainLabels.values()\ntrainSet = set(Dances)\nitr_set = {}\nfor i in trainSet:\n    itr_set[i] = 0","3dcf1631":"if not os.path.exists(location + str('\/train_labelled')):\n    os.makedirs(location + str('\/train_labelled'))\n    os.makedirs(location + str('\/test_labelled'))\n    \n    # Combine labels and images and move to labelled train folder\n    for img in tqdm(os.listdir(location + '\/train')):\n        if not int(img.split('.')[0]) in train_images:\n            continue\n        imgName = img.split('.')[0]\n        label = trainLabels[str(imgName) + '.jpg']\n        itr_set[label] += 1\n        path = os.path.join(location + '\/train\/', img)\n        saveName = location + '\/train_labelled\/' + label + '-' + str(itr_set[label]) + '.jpg'\n        image_data = np.array(Image.open(path))\n        imageio.imwrite(saveName, image_data)\n        \n    # Move 20% of labelled data to validation folder for testing\n    validation_data = os.listdir(location + '\/train_labelled')\n    random.Random(22).shuffle(validation_data)\n    for i in itr_set:\n        itr_set[i] = int(itr_set[i]*0.2)\n    for i in tqdm(itr_set):\n        for j in validation_data:\n            if j.split('-')[0] == i:\n                if itr_set[i] > 0:\n                    shutil.move(location + '\/train_labelled\/' + str(j), location + str('\/test_labelled'))\n                    itr_set[i] -= 1\n\n# Move unlabelled data for classification to test folder\nif not os.path.exists(location + str('\/test_images')):\n    os.makedirs(location + str('\/test_images'))\n    for image in tqdm(testImages):\n        shutil.move(location + '\/test\/' + str(image), location + str('\/test_images'))","624f2846":"def label_img(name):\n    word_label = name.split('-')[0]\n    if word_label == 'kathak' : return np.array([1,0,0,0,0,0,0,0])\n    elif word_label == 'mohiniyattam' : return np.array([0,1,0,0,0,0,0,0])\n    elif word_label == 'kuchipudi' : return np.array([0,0,1,0,0,0,0,0])\n    elif word_label == 'kathakali' : return np.array([0,0,0,1,0,0,0,0])\n    elif word_label == 'bharatanatyam' : return np.array([0,0,0,0,1,0,0,0])\n    elif word_label == 'odissi' : return np.array([0,0,0,0,0,1,0,0])\n    elif word_label == 'sattriya' : return np.array([0,0,0,0,0,0,1,0])\n    elif word_label == 'manipuri' : return np.array([0,0,0,0,0,0,0,1])","a5846bb9":"def get_size_statistics(DIR):\n    heights = []\n    widths = []\n    for img in tqdm(os.listdir(DIR)): \n        path = os.path.join(DIR, img)\n        data = np.array(Image.open(path)) #PIL Image library\n        heights.append(data.shape[0])\n        widths.append(data.shape[1])\n    avg_height = sum(heights) \/ len(heights)\n    avg_width = sum(widths) \/ len(widths)\n    print(\"Average Height: \" + str(avg_height))\n    print(\"Max Height: \" + str(max(heights)))\n    print(\"Min Height: \" + str(min(heights)))\n    print(\"Average Width: \" + str(avg_width))\n    print(\"Max Width: \" + str(max(widths)))\n    print(\"Min Width: \" + str(min(widths)))","a12fd510":"get_size_statistics(location + '\/train_labelled')","365576bb":"IMG_SIZE_H = 300\nIMG_SIZE_W = 300\n\ndef load_training_data(DIR):\n    train_data = []\n    for img in tqdm(os.listdir(DIR)):\n        label = label_img(img)\n        path = os.path.join(DIR, img)\n        img = cv2.imread(path)\n        img = cv2.resize(img, (IMG_SIZE_W, IMG_SIZE_H), interpolation = cv2.INTER_CUBIC)\n        train_data.append([np.array(img), label])\n    shuffle(train_data)\n    return train_data\n\ndef load_validation_data(DIR):\n    val_data = []\n    for img in tqdm(os.listdir(DIR)):\n        label = label_img(img)\n        path = os.path.join(DIR, img)\n        img = cv2.imread(path)\n        img = cv2.resize(img, (IMG_SIZE_W, IMG_SIZE_H), interpolation = cv2.INTER_CUBIC)\n        val_data.append([np.array(img), label])\n    shuffle(val_data)\n    return val_data\n\ndef load_testing_data(DIR):\n    test_data = []\n    for Img in tqdm(os.listdir(DIR)):\n        path = os.path.join(DIR, Img)\n        img = cv2.imread(path)\n        img = cv2.resize(img, (IMG_SIZE_W, IMG_SIZE_W), interpolation = cv2.INTER_CUBIC)\n        test_data.append([np.array(img), Img])\n    return test_data","4e9357c3":"train_data = load_training_data(location + '\/train_labelled')\nval_data = load_validation_data(location + '\/test_labelled')\nX_train = np.array([i[0] for i in train_data])#.reshape(-1, IMG_SIZE_H, IMG_SIZE_W, 3)\nX_train = X_train \/ 255 # normalize training data\ny_train = np.array([i[1] for i in train_data])\n#y_train = y_train \/ 255 # normalize training data\nX_test = np.array([i[0] for i in val_data])#.reshape(-1, IMG_SIZE_H, IMG_SIZE_W, 3)\nX_test = X_test \/ 255 # normalize test data\ny_test = np.array([i[1] for i in val_data])\n#y_test = y_test \/ 255 # normalize training data","4e13d4d0":"plt.imshow(train_data[120][0], #cmap = 'gist_gray'\n          )\nplt.show()","78be9d74":"vggmodel = VGG16(weights = 'imagenet', include_top = False, input_shape = (IMG_SIZE_H, IMG_SIZE_W, 3), pooling = 'max')","8a84e82c":" # Print the model summary\nvggmodel.summary()","c21a006d":"from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, GlobalAveragePooling2D, GlobalMaxPooling2D, BatchNormalization\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.models import Sequential\n\nADAMAX = optimizers.Adamax(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)\n\nvggmodel.trainable = False\nmodel = tf.keras.Sequential([vggmodel, \n                    Dense(1024, activation = 'relu'), Dropout(0.15),\n                    Dense(256, activation = 'relu'), Dropout(0.15),\n                    Dense(8, activation = 'softmax'),\n                   ])\nmodel.compile(optimizer = ADAMAX, loss = 'categorical_crossentropy',  metrics = ['accuracy'])","8aeb5bf8":"# Use annelar to gradually decrese the learning rate to improve generalization\n\nreduce_lr = ReduceLROnPlateau(monitor = 'loss', patience = 5, verbose = 1, factor = 0.2, min_lr = 0.00002,\n                                            mode = 'auto', cooldown = 1)","e8fea3a4":"gen = ImageDataGenerator(rotation_range = 40, width_shift_range = 0.1,\n                         height_shift_range = 0.1, zoom_range = 0.20, horizontal_flip = True,\n                         vertical_flip = False, featurewise_center = False,\n                         samplewise_center = False, featurewise_std_normalization = False,\n                         samplewise_std_normalization = False)\ntest_gen = ImageDataGenerator()\n\n# Create batches to  train models faster\ntrain_generator = gen.flow(X_train, y_train, batch_size = 16)\ntest_generator = test_gen.flow(X_test, y_test, batch_size = 16)","7f7ca4c1":"epochs = 100\n\nhistory = model.fit_generator(train_generator, steps_per_epoch = 16, epochs = epochs, \n                              validation_data = test_generator, validation_steps = 16, verbose = 1,\n                              callbacks=[reduce_lr])\n\n# evaluate the model\n\nscores = model.evaluate(X_test, y_test, verbose = 1)\nprint(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100 - scores[1]*100))","5e99f9ee":"plot_loss_accuracy(history)","d9d961ca":"test_data = load_testing_data(location + '\/test_images')\ntest = np.array([i[0] for i in test_data])#.reshape(-1, IMG_SIZE_H, IMG_SIZE_W, 1)\ntest_labels = np.array([i[1] for i in test_data])\ntest = test \/ 255 # normalize test data\nY_pred = np.round(model.predict(test), 0)\nY_pred = np.argmax(Y_pred, axis = 1)\nY_pred = pd.Series(Y_pred, name = \"label\")","cc0649d6":"def dance_label(word_label):\n    if word_label == 0: return 'kathak'\n    elif word_label == 1: return 'mohiniyattam'\n    elif word_label == 2: return 'kuchipudi'\n    elif word_label == 3: return 'kathakali'\n    elif word_label == 4: return 'bharatanatyam'\n    elif word_label == 5: return 'odissi'\n    elif word_label == 6: return 'sattriya'\n    elif word_label == 7: return 'manipuri'","44dff141":"submission_df = pd.DataFrame({\n                  \"Image\": pd.Series(test_labels),\n                  \"target\": pd.Series(Y_pred)})\nsubmission_df['target'] = submission_df['target'].apply(lambda x: dance_label(x))\nsubmission_df.to_csv('submission_vgg_v1.csv', index = False)","a60c44c5":"LR = 0.002\nmodel_name = 'classify_dances-{}-{}.model'.format(LR, 'vgg_v1')\nmodel.save(model_name)","d5565864":"inception_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape = (IMG_SIZE_H, IMG_SIZE_W, 3))","c549862d":"inception_model.trainable = False","d25e7826":"model = tf.keras.Sequential([inception_model, GlobalAveragePooling2D(),\n                    Dense(1024, activation = 'relu'), Dropout(0.10),\n                    Dense(512, activation = 'relu'), Dropout(0.10),\n                    Dense(8, activation = 'softmax'),\n                   ])\nmodel.compile(optimizer = ADAMAX, loss = 'categorical_crossentropy',  metrics = ['accuracy'])\nmodel.summary()","c81063bf":"epochs = 100\n\nhistory = model.fit_generator(train_generator, steps_per_epoch = 16, epochs = epochs, \n                              validation_data = test_generator, validation_steps = 16, verbose = 1,\n                              callbacks=[reduce_lr])\n\n# evaluate the model\n\nscores = model.evaluate(X_test, y_test, verbose = 1)\nprint(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100 - scores[1]*100))","9726e94c":"Y_pred = np.round(model.predict(test), 0)\nY_pred = np.argmax(Y_pred, axis = 1)\nY_pred = pd.Series(Y_pred, name = \"label\")","b97b6a2f":"submission_df = pd.DataFrame({\n                  \"Image\": pd.Series(test_labels),\n                  \"target\": pd.Series(Y_pred)})\nsubmission_df['target'] = submission_df['target'].apply(lambda x: dance_label(x))\nsubmission_df.to_csv('submission_IV3_v1.csv', index = False)","8b547392":"LR = 0.002\nmodel_name = 'classify_dances-{}-{}.model'.format(LR, 'inception_v1')\nmodel.save(model_name)","34f16a91":"## InceptionV3 model","0e98a77b":"## Transfer Learning - VGG Model"}}