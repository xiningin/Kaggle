{"cell_type":{"958189ae":"code","5ba7ce07":"code","61168553":"code","82010cc9":"code","98e7c33c":"code","09f61505":"code","4b43a61a":"code","64239309":"code","18e68f06":"code","6ec43246":"code","8f7a188c":"code","a49758c6":"code","04bc445d":"code","5361abc9":"code","660adc7c":"code","e5379034":"code","33be2270":"code","d130e7b1":"code","a98503c5":"code","cbbb9870":"code","8b2c425e":"code","fb310523":"code","3001816d":"code","be1a1240":"code","c2ac240a":"code","b8663c4e":"code","0cf8d498":"code","a6c9fbc4":"markdown","a82ff0dd":"markdown","a9b95c5d":"markdown","e7756f45":"markdown","3e1da6b5":"markdown","ddcfc7b8":"markdown"},"source":{"958189ae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# Yo`u can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5ba7ce07":"import matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Input, Dense, Flatten\nfrom tensorflow.keras.models import Model, Sequential, load_model\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom sklearn.metrics import confusion_matrix,accuracy_score\n","61168553":"trainPath='..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train'\nvalidPath='..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid'\n# os.listdir('..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train')","82010cc9":"train_datagen=ImageDataGenerator(rescale=1.\/255,\n                                 shear_range=0.2,\n                                 zoom_range=0.2,\n                                 brightness_range=[1,1.3],\n                                 horizontal_flip=True)\n\nvalid_datagen=ImageDataGenerator(rescale=1.\/255)","98e7c33c":"trainData=train_datagen.flow_from_directory(trainPath,\n                                            target_size=(224, 224),\n                                            shuffle=True,\n                                            batch_size=16,\n                                            class_mode='categorical')","09f61505":"validData=valid_datagen.flow_from_directory(validPath,\n                                            target_size=(224, 224),\n                                            shuffle=True,\n                                            batch_size=16,\n                                            class_mode='categorical')","4b43a61a":"len(trainData.class_indices)","64239309":"class_di","18e68f06":"import tensorflow as tf\n# from tensorflow.keras.applications.resnet50 import ResNet50\n\n# resnet = ResNet50(input_shape = (224, 224, 3), weights='imagenet', include_top=False)\n\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\n\n# from tensorflow.keras.applications.vgg19 import VGG19\n\nINV3 = InceptionV3(input_shape = (224, 224, 3), weights='imagenet', include_top=False)","6ec43246":"for layer in INV3.layers:\n    layer.trainable=False","8f7a188c":"x=Flatten()(INV3.output)\n# x=Dense(100,activation='relu')(x)\nprediction=Dense(len(trainData.class_indices),activation='softmax')(x)\n\nmodel=Model(inputs=INV3.input, outputs=prediction)","a49758c6":"tf.keras.utils.plot_model(\n    model, to_file='INV3-summary.png', show_shapes=True, show_dtype=True,\n    show_layer_names=True, rankdir='TB', expand_nested=True, dpi=96,\n    layer_range=None\n)","04bc445d":"model.summary()","5361abc9":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","660adc7c":"history=model.fit_generator(trainData,\n                          epochs=60,\n                          validation_data=validData,\n                          steps_per_epoch=len(trainData),\n                          validation_steps=len(validData)\n                         )","e5379034":"model.save('INV3.h5')","33be2270":"model_file=load_model('..\/input\/model-files\/vgg19.h5')","d130e7b1":"plt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Val Loss')\nplt.legend()\nplt.grid()\nplt.title('Train and validation loss of tuned model')\nplt.savefig('Loss-INV3')\nplt.show()\n","a98503c5":"plt.grid()\nplt.plot(history.history['accuracy'], label='Train accuracy')\nplt.plot(history.history['val_accuracy'], label='Val accuracy')\nplt.legend()\nplt.title('Train and validation Accuracy of tuned model')\nplt.savefig('accuracy-INV3')\nplt.show()\n","cbbb9870":"pred=np.argmax(model_file.predict(validData), axis=1)\npred","8b2c425e":"class_dict=validData.class_indices\nclass_dict","fb310523":"import cv2\nimport tensorflow as tf\ndef prepare(filepath):\n    img_array = cv2.imread(filepath, cv2.IMREAD_COLOR)\n    img_array = img_array \/ 255\n    new_array = cv2.resize(img_array, (224, 224))\n    return new_array.reshape(-1, 224, 224, 3)","3001816d":"def prediction(img):\n    pred_result=np.argmax(model_file.predict(img))\n    disease_category=list(class_dict)\n    return disease_category[pred_result]","be1a1240":"img=prepare('..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid\/Tomato___Leaf_Mold\/09240d05-a928-4491-9f13-ee42b693e2bd___Crnl_L.Mold 6610_180deg.JPG')\nprediction(img)","c2ac240a":"import random","b8663c4e":"disease_list=[]\nsample_image=[]\ndisease_name=[]\nfor i in os.listdir(validPath):\n    disease_list.append(i)\n# print(disease)\n\nfor i in disease_list:\n    x=random.sample(os.listdir(validPath+'\/'+i),1)\n    path=os.path.join(validPath+ '\/'+ i+'\/'+str(x[0]))\n    sample_image.append(path)\n    disease_name.append(i)","0cf8d498":"plt.figure(figsize=(20,15))\nplt.grid()\n\ni=0\nfor filepath in sample_image:\n    img_read = cv2.imread(filepath, cv2.IMREAD_COLOR)\n    img_array = img_read \/ 255\n    new_array = cv2.resize(img_array, (224, 224))\n    reshape_arr=new_array.reshape(-1, 224, 224, 3)\n    result=np.argmax(model_file.predict(reshape_arr))\n    predicted=list(validData.class_indices)[result]\n\n    plt.subplot(5,2,i+1)\n    plt.axis(\"off\")\n    plt.title(f\"Actual: {disease_name[i]},\\n Predicted: {predicted}\")\n    plt.imshow(img_read)\n    \n    i=i+1\n","a6c9fbc4":"## Save model","a82ff0dd":"## Test With single Image","a9b95c5d":"## Load Model","e7756f45":"## Test with random 1 images from each class","3e1da6b5":"## Evaluate this model","ddcfc7b8":"## Predict Valid Data classes"}}