{"cell_type":{"922837b9":"code","fcf2b80b":"code","2c061862":"code","bc03af59":"code","f5e15a9f":"code","4d4b0803":"code","dfd6da5c":"code","9b54967a":"code","140097b5":"code","d0187a22":"code","9be4e869":"code","b77be3f8":"code","28715731":"code","8edf21cb":"code","14adfb15":"code","8c1138e4":"code","9ccc2536":"code","21d003aa":"code","f42d068d":"code","2ba13b17":"code","e6711e32":"code","51906e56":"code","00abd813":"code","fa3ce030":"code","41bac134":"code","9ac25904":"markdown","baefe5dd":"markdown","46c79759":"markdown","036494ce":"markdown","b6ae93df":"markdown","0ed85c36":"markdown","8ce19cc7":"markdown","b6f84c8f":"markdown","4aa97773":"markdown","17aae5f4":"markdown","4c4a8aed":"markdown","e48acbb4":"markdown","4de78829":"markdown","69f1c138":"markdown","7e92a85e":"markdown","cbf4f591":"markdown","4fb4dd10":"markdown","71517f4f":"markdown","e9411af7":"markdown","78965547":"markdown","fd1d9732":"markdown","ef2b36bb":"markdown","5bcda672":"markdown","d1ffb54b":"markdown","748cfc3c":"markdown","670ae534":"markdown","81f036ea":"markdown","b04d2519":"markdown","f6cf70a3":"markdown","8804f606":"markdown","6718be76":"markdown","3297d2ce":"markdown","076a9ea0":"markdown","02ec18f1":"markdown"},"source":{"922837b9":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split","fcf2b80b":"data = pd.read_csv('..\/input\/logistic-regression\/Social_Network_Ads.csv')","2c061862":"data.head(10)","bc03af59":"data.info()","f5e15a9f":"data.isnull().sum()","4d4b0803":"data['Purchased'].unique()","dfd6da5c":"dummies = pd.get_dummies(data['Gender'])\nmerged = pd.concat([data,dummies], axis='columns')\nfinal_data = merged.drop(['Gender'], axis='columns')\nfinal_data","9b54967a":"final_data.info()","140097b5":"final_data.groupby(['Purchased']).count()","d0187a22":"plt.figure(figsize=(12,10))\ncorr = final_data.corr()\nsns.heatmap(corr, annot=True, linewidths=1, cmap='coolwarm')","9be4e869":"sns.set_style('darkgrid')\np = sns.regplot(x='Age', y='Purchased', data=final_data, logistic=True, scatter_kws={\"color\": \"black\"}, line_kws={\"color\": \"red\"})\np.figure.set_size_inches(12,8)","b77be3f8":"final_data.shape","28715731":"x_train, x_test, y_train, y_test = train_test_split(final_data[['Age']], final_data.Purchased, train_size = 0.75, random_state = 0)","8edf21cb":"x_train.shape","14adfb15":"x_test.shape","8c1138e4":"model = LogisticRegression(solver='liblinear') ## For small datasets, \u2018liblinear\u2019 is a good choice\nmodel.fit(x_train,y_train)","9ccc2536":"y_predicted = model.predict(x_test)\nprint('The Predicted values are: ', y_predicted)","21d003aa":"print('The probability estimates are: \\n', model.predict_proba(x_test))  ## Those with probability>0.5 are classified as '0' otherwise '1'","f42d068d":"from sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\ncnf_matrix = metrics.confusion_matrix(y_test, y_predicted)\ncnf_matrix","2ba13b17":"plt.figure(figsize = (8,6))\nsns.heatmap(cnf_matrix, annot=True,cmap='Oranges')\nplt.xlabel('Predicted label')\nplt.ylabel('Actual label')","e6711e32":"from sklearn.metrics import accuracy_score\naccuracy = metrics.accuracy_score(y_test, y_predicted)\naccuracy_percentage = accuracy * 100\nprint('The percentage of correct predictions for the test data: ', accuracy_percentage)","51906e56":"from sklearn.metrics import recall_score\nrecall = metrics.recall_score(y_test,y_predicted).round(2)\nprint('Recall score: ', recall)","00abd813":"from sklearn.metrics import precision_score\nprecision = metrics.precision_score(y_test,y_predicted).round(2)\nprint('Precision Score: ', precision)","fa3ce030":"from sklearn.metrics import f1_score\nf1_score = metrics.f1_score(y_test,y_predicted).round(2)\nprint('F1 score: ', f1_score)","41bac134":"from sklearn.metrics import classification_report\ncl_report = metrics.classification_report(y_test,y_predicted)\nprint('Classification Report: \\n', cl_report)","9ac25904":"#### *From the above, we found that our classes are not of equal size or we have a class imbalance.*","baefe5dd":"#### *There is no multicollinearity among the predictor variables as the correlation coefficients are very low.*\n#### *The only predictor variable having correlation coefficient>0.5 with target variable is 'Age'. So, the only feature we select is 'Age'.*","46c79759":"# PROBLEM STATEMENT: Predicting whether user is going to buy a product displayed on a social networking site by clicking the ad on the site","036494ce":"> ##### *It can be defined as 'Out of all the items that are truly positive, how many were correctly classified as positive'.*\n> ##### *Or simply, how many positive items were 'recalled' from the dataset.*\n> ##### The formula for Recall Score is TP\/(TP+FN).","b6ae93df":"## 13.6 Classification Report","0ed85c36":"> **As we are getting high precision, recall and F1 score, we conclude that the performance of our logistic regression model is good.**","8ce19cc7":"# 2. Load the Dataset","b6f84c8f":"#### *True Negatives(TN) = 66, True Positives(TP) = 23, False Negatives(FN) = 9, False Positives(FP) = 2*","4aa97773":"> ##### *It is defined as the harmonic mean between precision and recall.*\n> ##### *An F1 score reaches its best value at 1 and worst value at 0. A low F1 score is an indication of both poor precision and poor recall.*\n> ##### *The formula for F1 Score is TP \/ (TP + 0.5 x (FP + FN))*","17aae5f4":"## 13.2 Classification Accuracy","4c4a8aed":"#### *When we have a class imbalance, accuracy can become an unreliable metric for measuring our performance. Hence we need other metrics.*","e48acbb4":"# 13. Model Evaluation","4de78829":"> ##### *It is a summary of prediction results on a classification problem.*\n> ##### *The number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix.*\n> ##### *It gives you insight not only into the errors being made by your classifier but more importantly the types of errors that are being made.*\n> ##### *It is this breakdown that overcomes the limitation of using classification accuracy alone.*","69f1c138":"> ##### *It can be defined as 'number of items in a class labeled correctly out of all items in that class'.*\n> ##### *The formula for Classification accuracy is (TP+TN)\/(TP+TN+FP+FN)*","7e92a85e":"## 13.5 F1 Score","cbf4f591":"# 14. Conclusion","4fb4dd10":"# 10. Split the dataset into train and test data","71517f4f":"# 5. Check unique values in the target variable","e9411af7":"## 13.3 Recall Score","78965547":"# 1. Import the Relevant Libraries","fd1d9732":"# 9. Logistic Regression Plot","ef2b36bb":"# 12. Predictions","5bcda672":"## 13.1 Confusion Matrix for a binary classifier","d1ffb54b":"> ##### *Finally, using the classification_report, we can find the values of various metrics of our confusion matrix.*","748cfc3c":"# 6. Convert the categorical variable to numeric\n\n#### *The variable 'Purchased' has categorical data. So we will convert into numeric type.*","670ae534":"# 11. Model Initialization","81f036ea":"# 8. Feature Selection using Correlation Matrix","b04d2519":"## 13.4 Precision Score","f6cf70a3":"#### *There are no missing values.*","8804f606":"# 4. Check for Missing Values","6718be76":"# 7. Size of the Classes","3297d2ce":"Reference for Confusion Matrix: \n1. https:\/\/machinelearningmastery.com\/confusion-matrix-machine-learning\/\n2. https:\/\/www.kdnuggets.com\/2020\/05\/model-evaluation-metrics-machine-learning.html","076a9ea0":"> ##### *It can be defined as 'Out of all the items labeled as positive, how many truly belong to the positive class'.*\n> ##### *The formula for Precision Score is TP\/(TP+FP)*","02ec18f1":"# 3. Explore the Dataset"}}