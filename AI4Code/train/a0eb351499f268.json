{"cell_type":{"ccf83a8b":"code","da210475":"code","d5297897":"code","d2f6234d":"code","f12e3c7a":"code","05a20fa0":"code","9c037bcf":"code","513daf7d":"code","86f3de7b":"code","3b2ab6c4":"code","2cdfcd23":"code","cc767cfb":"code","16729b44":"code","23d7d699":"code","c7bf1ef2":"code","fc8f5fb8":"code","cdd22ba1":"code","d806ecb8":"code","c26659ef":"code","a27986f8":"code","706617b6":"code","e54e9ef1":"code","f090e1a5":"code","a2dbb761":"code","657ed360":"code","71604e9d":"code","0b26290b":"code","7faa4683":"code","08c3099f":"code","85d7fcec":"code","6a0583ec":"code","96f77c66":"code","94420810":"code","8b40e3b3":"code","7bd4f957":"code","403553fd":"code","149f930f":"code","8826b4c8":"code","26c2e2a4":"code","e0aa4498":"code","e33024cc":"code","7e61e013":"code","7f4f8c1c":"code","dd9b9298":"markdown","541a489d":"markdown","9de96f27":"markdown","4033809f":"markdown","828293ab":"markdown","f66c0dc5":"markdown","2d11f1ec":"markdown","c1e6a9f4":"markdown","4272dbc9":"markdown","45f3e6b7":"markdown","1c1f2653":"markdown","281e92dd":"markdown","410bf650":"markdown","5c111446":"markdown","8772a40e":"markdown","fadf0732":"markdown","5aa825cf":"markdown","93c64e2c":"markdown","a220d353":"markdown","de569faf":"markdown","90f5a4bc":"markdown","24947806":"markdown","80c10bb4":"markdown","023734b2":"markdown","ffee4855":"markdown","bb10bbe6":"markdown","43cfea49":"markdown","9c544cc4":"markdown","0fbe3899":"markdown","09edfd27":"markdown"},"source":{"ccf83a8b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","da210475":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n%matplotlib inline\nsns.set_style('whitegrid')\n\ntrain_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")","d5297897":"train_data.head()","d2f6234d":"train_data.info()","f12e3c7a":"train_data.describe()","05a20fa0":"sns.heatmap(train_data.isnull())","9c037bcf":"sns.countplot(x='Survived', data=train_data)","513daf7d":"f, axes = plt.subplots(1, 2, figsize=(15,7))\nsns.countplot(x='Survived',hue='Sex', data=train_data, color=\"b\", ax=axes[0])\nsns.countplot(x='Survived',hue='Pclass', data=train_data, color=\"r\", ax=axes[1])","86f3de7b":"sns.distplot(train_data['Age'].dropna())","3b2ab6c4":"train_data['Fare'].hist(bins=30)\n","2cdfcd23":"train_data['SibSp'].hist(bins=30)","cc767cfb":"train_data['Parch'].hist(bins=30)","16729b44":"sns.pairplot(train_data)","23d7d699":"train_data['Age']= train_data[['Age']].fillna(value=train_data['Age'].mean())","c7bf1ef2":"sns.heatmap(train_data.isnull())","fc8f5fb8":"train_data= train_data.drop(['Cabin','PassengerId','Name','Ticket'], axis=1)","cdd22ba1":"sex=pd.get_dummies(train_data['Sex'], drop_first=True)\nembarked= pd.get_dummies(train_data['Embarked'], drop_first=True)","d806ecb8":"train_data.drop(['Sex','Embarked'], axis=1,inplace=True)","c26659ef":"train_data=pd.concat([train_data,sex,embarked], axis=1)","a27986f8":"train_data.head()","706617b6":"from sklearn.model_selection import train_test_split\nX=train_data.drop(['Survived'], axis=1)\ny=train_data['Survived']\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30,random_state=501)","e54e9ef1":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()\nlr.fit(X_train,y_train)","f090e1a5":"predict_with_lr=lr.predict(X_test)","a2dbb761":"from sklearn.metrics import classification_report, confusion_matrix\nreport_lr=classification_report(y_test,predict_with_lr,output_dict=True)\nprint (\"Logistic Regression model \\n\", classification_report(y_test,predict_with_lr))\nprint('\\n')\nprint (\"Logistic Regression model \\n\",confusion_matrix(y_test,predict_with_lr))\nacc_matrix=pd.DataFrame({'Model' : ['Logistic Regression'],\n                        'Accuracy':[report_lr['accuracy']]})\n","657ed360":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train,y_train)\npredict_with_knn=knn.predict(X_test)","71604e9d":"report_knn=classification_report(y_test,predict_with_knn, output_dict=True)\ndict={'Model' : 'K Nearest Neighbors',\n                        'Accuracy':report_knn['accuracy']}\nacc_matrix=acc_matrix.append(dict, ignore_index=True)\nprint (\"K Nearest Neighbors \\n\", classification_report(y_test,predict_with_knn))\nprint('\\n')\nprint (\"K Nearest Neighbors \\n\",confusion_matrix(y_test,predict_with_knn))\n","0b26290b":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=800)\nrf.fit(X_train,y_train)\npredict_with_rf=rf.predict(X_test)","7faa4683":"report_rf=classification_report(y_test,predict_with_rf, output_dict=True)\ndict={'Model' : 'Random Forest',\n                        'Accuracy':report_rf['accuracy']}\nacc_matrix=acc_matrix.append(dict, ignore_index=True)\nprint (\"Random Forest \\n\", classification_report(y_test,predict_with_rf))\nprint('\\n')\nprint (\"Random Forest \\n\",confusion_matrix(y_test,predict_with_rf))","08c3099f":"from sklearn.svm import SVC\nsvc=SVC()\nsvc.fit(X_train,y_train)\npredict_with_svc=svc.predict(X_test)","85d7fcec":"report_svm=classification_report(y_test,predict_with_svc, output_dict=True)\ndict={'Model' : 'SVM Classifier',\n                        'Accuracy':report_svm['accuracy']}\nacc_matrix=acc_matrix.append(dict, ignore_index=True)\nprint (\"SVM Classification \\n\", classification_report(y_test,predict_with_svc))\nprint('\\n')\nprint (\"SVM Classification \\n\",confusion_matrix(y_test,predict_with_svc))","6a0583ec":"from sklearn.model_selection import GridSearchCV\nparam_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']}\ngrid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\ngrid.fit(X_train,y_train)","96f77c66":"grid.best_params_","94420810":"grid.best_estimator_","8b40e3b3":"predict_with_svc_grid=grid.predict(X_test)\nreport_svm_gs=classification_report(y_test,predict_with_svc_grid, output_dict=True)\ndict={'Model' : 'SVM Classifier after Grid search',\n                        'Accuracy':report_svm_gs['accuracy']}\nacc_matrix=acc_matrix.append(dict, ignore_index=True)\nprint (\"SVM Classification with Grid \\n\", classification_report(y_test,predict_with_svc_grid))\nprint('\\n')\nprint (\"SVM Classification with Grid\\n\",confusion_matrix(y_test,predict_with_svc_grid))","7bd4f957":"acc_matrix","403553fd":"test_data.head()","149f930f":"sns.heatmap(test_data.isnull())","8826b4c8":"filter_test_data=test_data.drop(['Cabin','PassengerId','Name','Ticket'], axis=1)","26c2e2a4":"filter_test_data['Age']=filter_test_data[['Age']].fillna(value=filter_test_data['Age'].mean())\nsex_test=pd.get_dummies(filter_test_data['Sex'], drop_first=True)\nembarked_test= pd.get_dummies(filter_test_data['Embarked'], drop_first=True)\nfilter_test_data.drop(['Sex','Embarked'], axis=1,inplace=True)\nfilter_test_data=pd.concat([filter_test_data,sex_test,embarked_test], axis=1)","e0aa4498":"filter_test_data.isnull().sum()","e33024cc":"filter_test_data['Fare']=filter_test_data[['Fare']].fillna(value=filter_test_data['Age'].mean())","7e61e013":"final_pred=rf.predict(filter_test_data)","7f4f8c1c":"submission= pd.DataFrame({ \n    'PassengerId': test_data['PassengerId'],\n    'Survived': final_pred })\nsubmission.to_csv(\"Submission.csv\", index=False)","dd9b9298":"## Model Selection\n","541a489d":"#### Interesting. We can see the servival rate of female is high. Also most interesting count we got from pclass graph. 3 category class people mostly died. This 2 cols are important for our data set. \n\nLets explore the age cols. We will start with the distribution plot. As age has some missing val we will use dropna function to get a accurate distribution plot. \n","9de96f27":"We will use Random Forest for test data. Let have a look into the test data.\n\n","4033809f":"## Lets have the accuracy summary","828293ab":"Lets apply grid search to find the best parameter for SVC.\n","f66c0dc5":"Its a kind of normal distribution.\n\nLets work on the Fare, SibSp, Parch cols for hist plots. ","2d11f1ec":"**We have the target col which is Survived. **\n\n**Data Dictionary for Key cols**\n\n**Survival**\n0 = No, 1 = Yes\n\n**embarked**\nC = Cherbourg, Q = Queenstown, S = Southampton\n\n**pclass**\n1 = 1st, 2 = 2nd, 3 = 3rd\n\nLets describe the data and info of it.\n","c1e6a9f4":"Now the accuracy is 85%","4272dbc9":"## Conclusion\n We did a binary classification and select the model with higher accuracy. **Please upvote if you like.** ","45f3e6b7":"Lets have classification report and Confusion matrix.","1c1f2653":"## 1. Logistic Regression model","281e92dd":"Accuracy is 71%","410bf650":"Now we have 2 categorical col. Lets get dummy variable and prepare the final set of data.","5c111446":" ## 3. Random Forest ","8772a40e":"Lets normalize the test data to fit in our model.\n","fadf0732":"## Exploratory Data Analysis\nLets explore the data with interactive graphs","5aa825cf":"## 4. SVM Classification\n","93c64e2c":"It is clear that Cabin and and age has missing value. As the cabin has lots of missing value , we can drop it from out data set. Now lets check the count of our target **\"Survived\"** col. ","a220d353":"Lets remove the following cols :\n* Cabin : It has too much missing value.\n* PassengerId : This is just a sequence number. Not related to our model.\n* Name\n* Ticket : It should be related to the pclass and does not contain any meaningfull info. \n","de569faf":"Accuracy is 83%. lets try other classification model to improve accuracy. ","90f5a4bc":" ## 2.  K Nearest Neighbors","24947806":"It will only return the numeric cols. ","80c10bb4":"Death count is high based on the graph. Lets do some plot based on sex and pclass, so that we can have a clear relation. I will be using seaborn subplots and use **\"Sex\" and \"pclass\"** category. \n","023734b2":"> ## Data and Library Load.","ffee4855":"Removing Sex and Embarked col and contact the dummy variable in the training set.\n","bb10bbe6":"Lets take a look of the final Data.","43cfea49":"So max people travleing alone. From the fare graph , we can see lost cost ticket has major count. \nNow we have a good visual of data. Lets do a quick pair plot to relete the cols with our target col and start data cleaning.","9c544cc4":"## Missing data from data set\nChecking the missing data from dataset through heat map.","0fbe3899":"## Data Correction\n\nLet start with age col. Lets put avg age for missing data. ","09edfd27":"Lets split the data into train test split."}}