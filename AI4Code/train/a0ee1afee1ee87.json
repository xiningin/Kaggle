{"cell_type":{"1ce5203f":"code","1cc9708e":"code","489d9b71":"code","d20f1517":"code","c06fbdfa":"code","35dc9e39":"code","37c13b76":"code","d8b27a92":"code","4305e149":"code","5aed087d":"code","e9bcd3ff":"code","f24307a0":"code","5edc18f2":"code","5b51d73a":"code","2327a61d":"code","24dbf8d3":"code","6e399206":"code","40ed7766":"code","509453f4":"code","6e275bd3":"code","f80cb680":"code","400dc77d":"code","f5b80f05":"code","38993b90":"code","8b5ca21a":"code","3e33257c":"code","25ba416b":"code","0e399c56":"code","c8ce59fd":"markdown","fac76dfa":"markdown","32cf6a4c":"markdown","eb8a206b":"markdown","49f43f08":"markdown","6591fb1c":"markdown","1aaf6dd6":"markdown","17a58766":"markdown","53d12750":"markdown","36d97a4d":"markdown","a7595ac1":"markdown","7a17db4c":"markdown","ecfe326f":"markdown","dafdbef9":"markdown","3fcf80dc":"markdown","4be131c5":"markdown","fc65ca74":"markdown","cfc3aa2d":"markdown","25c56bae":"markdown","92d1550d":"markdown","c3a6b962":"markdown","0ae808dc":"markdown","d39607e6":"markdown","459a6b63":"markdown","d4b6ea8a":"markdown","81b52121":"markdown","c21c35ac":"markdown"},"source":{"1ce5203f":"#\nimport numpy as np\nimport pandas as pd\nimport random\n\n# image\nfrom PIL import Image\n\n# folder\nimport os\nimport glob\n\n# visu\nimport matplotlib.pyplot as plt\nplt.rc('image', cmap='gray')\n\n# sklearn\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n#tensorflow\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import to_categorical","1cc9708e":"categories = [\"circle\", \"square\", \"star\", \"triangle\"]","489d9b71":"im_width = 100\nim_height = 100","d20f1517":"%%time\n\ndata = []\ntarget = []\n\nfor cat in categories:\n    filelist = glob.glob('\/kaggle\/input\/four-shapes\/shapes\/' + cat + '\/*.png')\n    target.extend([cat for _ in filelist])\n    data.extend([np.array(Image.open(fname).resize((im_width, im_height))) for fname in filelist])\n#\ndata_array = np.stack(data, axis=0)","c06fbdfa":"data_array.shape","35dc9e39":"fig = plt.figure(figsize=(20,15))\ngs = fig.add_gridspec(4, 4)\n#\nfor line in range(0, 3):\n    for row in range(0, 3):\n        num_image = random.randint(0, data_array.shape[0])\n        ax = fig.add_subplot(gs[line, row])\n        ax.axis('off');\n        ax.set_title(target[num_image])\n        ax.imshow(data_array[num_image]);","37c13b76":"pd.DataFrame(target).value_counts()\/len(target)","d8b27a92":"X_train, X_test, y_train, y_test = train_test_split(data_array, np.array(target), test_size=0.2, stratify=target)","4305e149":"pd.DataFrame(y_train).value_counts()\/len(y_train)","5aed087d":"pd.DataFrame(y_test).value_counts()\/len(y_test)","e9bcd3ff":"print(X_train.max())\nprint(X_train.min())","f24307a0":"X_test_norm = np.round((X_test\/255), 3).copy()\nX_train_norm = np.round((X_train\/255), 3).copy()","5edc18f2":"print(X_train_norm.max())\nprint(X_train_norm.min())","5b51d73a":"fig = plt.figure(figsize=(20,15))\ngs = fig.add_gridspec(4, 4)\n#\nfor line in range(0, 3):\n    for row in range(0, 3):\n        num_image = random.randint(0, X_train_norm.shape[0])\n        ax = fig.add_subplot(gs[line, row])\n        ax.axis('off');\n        ax.set_title(y_train[num_image])\n        ax.imshow(X_train_norm[num_image]);","2327a61d":"display(np.array(y_train).shape)\ndisplay(np.unique(y_train))\ndisplay(np.array(y_test).shape)\ndisplay(np.unique(y_test))","24dbf8d3":"encoder = LabelEncoder().fit(y_train)","6e399206":"y_train_cat = encoder.transform(y_train)\ny_test_cat = encoder.transform(y_test)","40ed7766":"y_train_oh = to_categorical(y_train_cat)\ny_test_oh = to_categorical(y_test_cat)","509453f4":"pd.DataFrame(y_test_oh).head()","6e275bd3":"X_train_norm = X_train_norm.reshape(-1, 100, 100, 1)\nX_test_norm = X_test_norm.reshape(-1, 100, 100, 1)\nX_train_norm.shape","f80cb680":"def initialize_model():\n    model = Sequential()\n    model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(im_height, im_width, 1), padding='same'))\n    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n    model.add(layers.Conv2D(64, (3, 3), activation=\"relu\", padding='same'))\n    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n    model.add(layers.Conv2D(128, (3, 3), activation=\"relu\", padding='same'))\n    model.add(layers.MaxPool2D(pool_size=(3, 3)))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(120, activation='relu'))\n    model.add(layers.Dense(60, activation='relu'))\n    model.add(layers.Dropout(rate=0.2))\n    model.add(layers.Dense(4, activation='softmax'))\n\n    return model","400dc77d":"model = initialize_model()\nmodel.summary()","f5b80f05":"def compile_model(model):\n    model.compile(optimizer='adam',\n                  loss='categorical_crossentropy',\n                  metrics=\"accuracy\")\n    return model","38993b90":"model = initialize_model()\nmodel = compile_model(model)\nes = EarlyStopping(patience=5, monitor='val_accuracy', restore_best_weights=True)\n\nhistory = model.fit(X_train_norm, y_train_oh,\n                    batch_size=16,\n                    epochs=1000,\n                    validation_split=0.3,\n                    callbacks=[es])","8b5ca21a":"def plot_history(history, title='', axs=None, exp_name=\"\"):\n    if axs is not None:\n        ax1, ax2 = axs\n    else:\n        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n    \n    if len(exp_name) > 0 and exp_name[0] != '_':\n        exp_name = '_' + exp_name\n    ax1.plot(history.history['loss'], label='train' + exp_name)\n    ax1.plot(history.history['val_loss'], label='val' + exp_name)\n    ax1.set_ylim(-0.1, 0.1)\n    ax1.set_title('loss')\n    ax1.legend()\n\n    ax2.plot(history.history['accuracy'], label='train accuracy'  + exp_name)\n    ax2.plot(history.history['val_accuracy'], label='val accuracy'  + exp_name)\n    ax2.set_ylim(0.9, 1.1)\n    ax2.set_title('Accuracy')\n    ax2.legend()\n    return (ax1, ax2)\n\nplot_history(history, title='', axs=None, exp_name=\"\");","3e33257c":"model.evaluate(X_test_norm, y_test_oh, verbose=0)","25ba416b":"predictions = model.predict(X_test_norm)","0e399c56":"fig = plt.figure(figsize=(20,15))\ngs = fig.add_gridspec(4, 4)\n#\nfor line in range(0, 3):\n    for row in range(0, 3):\n        num_image = random.randint(0, X_test_norm.shape[0])\n        ax = fig.add_subplot(gs[line, row])\n        ax.axis('off');\n        ax.set_title(\"Predicted: \" + categories[list(np.round(predictions[num_image])).index(1)])\n        ax.imshow(X_test_norm[num_image]);\nfig.suptitle(\"Predicted label for the displayed shapes\", fontsize=25, x=0.42);","c8ce59fd":"# 2. Loading images","fac76dfa":"Let's have a look at several random shape images and associated label of our dataset:","32cf6a4c":"# 3. Train test split\n<b> Let's split the dataset in a train set to train model and a test set for evaluation.<\/b> We will build the train set with 80% of the dataset and the test set with the 20% remaining. We keep the class repartition by setting the parameter `stratify` to `target` (which is the list containing the labels).","eb8a206b":"Here I set an early stopping after 5 epochs and set the parameter `restore_best_weights` to `True` so that the weights of best score on monitored metric - here `val_accuracy` (accuracy on test set) - are restored when training stops. This way the model has the best accuracy possible on unseen data.","49f43f08":"<b>And make predictions on test set to show, for random images of the test set, that the predicted label for each images is the good one:<\/b>","6591fb1c":"<b>We can check the accuracy:<\/b>","1aaf6dd6":"# 1. Imports","17a58766":"Applying on both train and test set:","53d12750":"# 6. Results","36d97a4d":"Fitting the encoder on train set:","a7595ac1":"All images are of size 200 x 200. Because of memory limitation in Kaggle, keeping 200 x 200 is not possible. Let's divide the height and width by two.","7a17db4c":"<b>The deep learning model needs a 4 dimensions tensor to work with. Here we have grayscale pictures with no channel. It means the matrices of our black and white pictures are of shape 3. We need to add an extra dimension so algorithm can accept it.<\/b>","ecfe326f":"Here we convert targets. First, from string to numerical values, each category becoming an integer, from 0 to 3 (as there are four different shape categories):","dafdbef9":"There are four shape categories. The images are loaded in a numpy array as matrix and associated categories are loaded in an independent array.","3fcf80dc":"Now, let's define the Convolutional Neural Network.\n\n<b>The CNN that is composed of:<\/b>\n\n* a Conv2D layer with 32 filters, a kernel size of (3, 3), the relu activation function, a padding equal to same and the correct input_shape\n* a MaxPooling2D layer with a pool size of (2, 2)\n* a Conv2D layer with 64 filters, a kernel size of (3, 3), the relu activation function, and a padding equal to same\n* a MaxPooling2D layer with a pool size of (2, 2)\n* a Conv2D layer with 128 filters, a kernel size of (3, 3), the relu activation function, and a padding equal to same\n* a MaxPooling2D layer with a pool size of (3, 3)\n* a Flatten layer\n* a dense function with 120 neurons with the relu activation function\n* a dense function with 60 neurons with the relu activation function\n* a dropout layer (with a rate of 0.5), to regularize the network\n* a dense function related to the task: multiclassification of 4 classes","4be131c5":"And now, we convert the result to one-hot encoded target so that they can be used to train a classification neural network. We use `to_categorical` from tensorflow library:","fc65ca74":"## Target encoding","cfc3aa2d":"# 5. Convolutionnal neural network","25c56bae":"# 4. Preparing the data","92d1550d":"<b>Thank you for reading \ud83d\ude4f\ud83c\udffb If you like please upvote. If you have any suggestion of improvment or if you notice some mistakes please feel free to comment<\/b><br><br>\n<b style=\"color:royalblue\">V. Bonnet<\/b>","c3a6b962":"<div style=\"display: block; height: 500px; overflow:hidden; text-align:center\">\n     <img src=\"https:\/\/imgur.com\/dhGIBOt.jpg\" style=\"top: 0px;border-radius: 20px; \">\n<\/div>","0ae808dc":"To ease the convergence of the algorithm, it is usefull to normalize the data. See here what are the maximum and minimum values in the data, and normalize it accordingly (the resulting image intensities should be between 0 and 1).","d39607e6":"Here again, we can check the normalised pictures randomly:","459a6b63":"## Expanding dimension for the correct model intput dim","d4b6ea8a":"<b>So we have a wonderful 100% accuracy for this shape recognition algorithm!<span style=\"font-size:50pt\">\ud83d\udd25\ud83d\ude80<\/span><\/b>","81b52121":"So we have 14970 tensor images of width 100 and height 100, each pixel being defined by Black (0) or white (255):","c21c35ac":"## Normalization"}}