{"cell_type":{"691cfe3a":"code","ad72a715":"code","16d39332":"code","d873290a":"code","c17502ba":"code","82c3c92a":"code","3017d355":"code","452d4cdc":"code","9b7253a2":"code","ce550d02":"code","12a7ff56":"code","c08cb466":"code","a23ba6fb":"code","efa9d658":"code","b5c3187e":"code","e6d343cc":"code","2ee3ad3c":"code","ccef6d61":"code","72acc879":"code","c9868621":"code","916149dd":"code","59886ba9":"code","91b5444e":"code","123be251":"code","734d0ebf":"code","616528b5":"code","e6e9d2f5":"code","8a6e514e":"code","36817ba4":"code","95467131":"code","ae2e4113":"code","747f8c83":"code","353a7702":"code","a0544e3f":"code","bf173b50":"code","bd040b29":"code","490d4206":"code","3367efca":"code","c71f460e":"code","2aab6f47":"code","f3e7a176":"code","8af269e7":"code","e9d4d5a1":"code","88e52413":"code","d29354b7":"code","d521faf7":"code","86e2ebbc":"code","2e1a25c9":"code","d3dde960":"code","95b1aeb2":"code","bb03515c":"code","ef9b4cfc":"code","187253b6":"code","78de6d72":"code","ce5d09f1":"code","32f20eeb":"code","c63273af":"code","29989fa3":"code","8ba79a7c":"code","a8cff8f3":"code","5726e51c":"code","26488e05":"code","b31606db":"code","ce450a93":"code","4f95efcb":"code","1ae464da":"code","7ab42ef1":"code","1e7c27b3":"code","fa0470e9":"code","39ca92bd":"code","421f8eb4":"code","f84cb551":"code","8d2be9b5":"code","58915d44":"code","6d095054":"code","3be70255":"code","acbc81ee":"code","708d436a":"code","b6e88858":"code","9c3f21c8":"code","d4a4afee":"code","dbe8604f":"code","83c72330":"code","80dd9c97":"code","4425ac69":"code","2a681d87":"code","9fd3c6c7":"code","7f194ecb":"code","ebdb88cc":"code","587e792f":"code","cfa8435e":"code","77c6b648":"code","d99ef3d3":"code","6dc2e0b9":"code","39d08238":"code","a1d9d0e2":"code","029c681e":"code","3d49b10d":"code","64ef4e47":"code","4ebc20f8":"code","2a3fc933":"code","a239e31b":"code","175fe53b":"code","24e32146":"code","1b6634c3":"markdown","596096ad":"markdown","c2000717":"markdown","c2b1d1eb":"markdown","b8d85157":"markdown","0c9ea7e2":"markdown"},"source":{"691cfe3a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\n# Any results you write to the current directory are saved as output.","ad72a715":"df_train = pd.read_csv(\"..\/input\/train.csv\")\ndf_test=pd.read_csv(\"..\/\/input\/test.csv\")\n\n\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\nprint(train['RoofMatl'].unique())\nprint(test['RoofMatl'].unique())","16d39332":"df_test.shape\n#df_train.shape[1]","d873290a":"df_train.shape","c17502ba":"\ndf_train = df_train.drop(df_train[(df_train['GrLivArea']>4000) & (df_train['SalePrice']<300000)].index)\n\ndf_all=df_train.drop(['SalePrice'],axis=1).append(df_test)","82c3c92a":"df_train.drop(['SalePrice'],axis=1).append(df_test)[:1458].head()","3017d355":"#data_input=df_train.drop(['Id','SalePrice'],axis=1)\n#df.drop(['B', 'C'], axis=1)\n#data_output=df_train['SalePrice']\ndf_train.head()\ndf_test.head()\n\n#df_train.drop(['SalePrice'],axis=1).append(df_test)","452d4cdc":"df_all.head()","9b7253a2":"total=df_all.isnull().sum()\/df_all.isnull().count()\nsum=df_all.isnull().sum()\n#total.head\n#sum.head\nmissing=pd.concat([total,sum],axis=1,keys=['Perc','Sum']).sort_values(by='Perc',ascending=False)\n#missing.keys=['Percentage','Sum']\ncolstodrop=missing[missing['Sum']>0].index\n#colstodrop\nmissing[missing['Sum']>0]\n \n#data_input=data_input.drop(colstodrop,axis=1)\n#data_test=df_test.drop(colstodrop,axis=1)\n#data_input.head(5)\n","ce550d02":"df_all['MiscFeature']=df_all['MiscFeature'].fillna(\"None\")\ndf_all['Alley']=df_all['Alley'].fillna(\"None\")\ndf_all['Fence']=df_all['Fence'].fillna(\"None\")\ndf_all['FireplaceQu']=df_all['FireplaceQu'].fillna(\"None\")\ndf_all['GarageFinish']=df_all['GarageFinish'].fillna(\"None\")\ndf_all['GarageQual']=df_all['GarageFinish'].fillna(\"None\")\ndf_all['GarageType']=df_all['GarageType'].fillna(\"None\")\ndf_all['BsmtCond']=df_all['BsmtCond'].fillna(\"None\")\ndf_all['BsmtExposure']=df_all['BsmtExposure'].fillna(\"Nobase\")\ndf_all['BsmtQual']=df_all['BsmtQual'].fillna(\"None\")\ndf_all['BsmtFinType2']=df_all['BsmtFinType2'].fillna(\"None\")\ndf_all['BsmtFinType1']=df_all['BsmtFinType1'].fillna(\"None\")\ndf_all['GarageCond']=df_all['GarageCond'].fillna(\"None\")\ndf_all['PoolQC']=df_all['PoolQC'].fillna(\"None\")\ndf_all['MasVnrType']=df_all['MasVnrType'].fillna(\"None\")\ndf_all['MasVnrArea']=df_all['MasVnrArea'].fillna(0)\ndf_all['Functional']=df_all['Functional'].fillna(\"Typ\")\n#df_all['Utilities']=df_all['Utilities'].fillna(\"AllPub\")\ndf_all=df_all.drop(['Utilities'],axis=1)\ndf_all['MSZoning']=df_all['MSZoning'].fillna(df_all['MSZoning'].mode()[0])\ndf_all['Electrical']=df_all['Electrical'].fillna(df_all['Electrical'].mode()[0])\ndf_all[\"LotFrontage\"] = df_all.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))\nfor col in ['GarageYrBlt','GarageArea','GarageCars']:\n    df_all[col]=df_all[col].fillna(0)\n    \nfor col in ['BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath']:\n    df_all[col]=df_all[col].fillna(0)\n    \nfor col in ['SaleType','Exterior1st','Exterior2nd','KitchenQual']:\n    df_all[col]=df_all[col].fillna(df_all[col].mode()[0])\n    \n    \n#Introduce some new fields\n\n\ndf_all['Total_sqr_footage'] = (df_all['BsmtFinSF1'] + df_all['BsmtFinSF2'] +\n                                 df_all['1stFlrSF'] + df_all['2ndFlrSF'])\n\ndf_all['Total_Bathrooms'] = (df_all['FullBath'] + (0.5 * df_all['HalfBath']) +\n                               df_all['BsmtFullBath'] + (0.5 * df_all['BsmtHalfBath']))\n\ndf_all['Total_porch_sf'] = (df_all['OpenPorchSF'] + df_all['3SsnPorch'] +\n                              df_all['EnclosedPorch'] + df_all['ScreenPorch'] +\n                              df_all['WoodDeckSF'])\n","12a7ff56":"#df_all['Exterior1st'].mode()[0]","c08cb466":"#test piece for doing qa on missing values\n#df_all['Utilities'].mode()[0]\ndf_all.isna().sum().sort_values(ascending=False)","a23ba6fb":"df_all.head()","efa9d658":"df_all['BsmtFinSF1']","b5c3187e":"colstodrop","e6d343cc":"df_all.columns","2ee3ad3c":"# df_all['YrSold']=df_all['YrSold'].apply(str)\n# df_all['MoSold']=df_all['MoSold'].apply(str)\n# df_all['OverallQual']=df_all['OverallQual'].apply(str)\n# df_all['OverallCond']=df_all['OverallCond'].apply(str)\n# df_all['MSSubClass']=df_all['MSSubClass'].apply(str)\n# df_all['YearBuilt']=df_all['YearBuilt'].apply(str)\n#df_all['YearRemodAdd']=df_all['YearRemodAdd'].apply(str)\n# df_all['GarageYrBlt']=df_all['GarageYrBlt'].apply(str)\ndf_all=df_all.drop(['Id'],axis=1)\ndf_all['Totalarea']=df_all['TotalBsmtSF'] + df_all['1stFlrSF'] + df_all['2ndFlrSF']","ccef6d61":"numericcols=df_all.dtypes[df_all.dtypes != object]\ncategorcols=df_all.dtypes[df_all.dtypes == object]","72acc879":"numericcols.index","c9868621":"categorcols.index","916149dd":"catcols=('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond',\n         'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir',  'OverallCond', 'OverallQual',\n        #'YrSold',  'GarageYrBlt','YearRemodAdd',\n        'YrSold', 'MoSold','MSSubClass')\n#'MSSubClass',\ncatcols\n# these columns are used for label encoding","59886ba9":"df_all.shape\n\n\n","91b5444e":"df_all.dtypes[df_all.dtypes == \"object\"].index","123be251":"print(df_all.dtypes.unique())\nprint(df_all['MSSubClass'].dtypes)\n\ndf_all['MSSubClass']","734d0ebf":"\ndf_all.shape\n#df_all['MSSubClass'].dtype\n#print(numeric_feats)\n#df_all['MSSubClass']=str(df_all['MSSubClass'])\ndf_all['MSSubClass']=df_all['MSSubClass'].apply(str)","616528b5":"df_all['MSSubClass']","e6e9d2f5":"\nfrom scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\n\ndf_all.dtypes\n\n#df_all=df_all.drop('SalePrice',axis=1)\nnumeric_feats = df_all.dtypes[df_all.dtypes != \"object\"].index\n\n# Check the skew of all numerical features\nskewed_feats = df_all[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkew in numerical features: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(10)\nskewness=skewness[abs(skewness['Skew'])>0.20]\nskewness\nprint(df_all.shape)","8a6e514e":"numeric_feats","36817ba4":"df_all['MiscVal'].skew()","95467131":"#skewness=skewness[abs(skewness)>1.25]\n#skewness.count()\n\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax \nskewed_features = skewness.index\n\nlam = 0.15\nfor feat in skewed_features:\n    #df_all[feat] = boxcox1p(df_all[feat], lam)\n    df_all[feat] = boxcox1p(df_all[feat], boxcox_normmax(df_all[feat] + 1))\n    #df_all[feat] = np.log1p(df_all[feat])\n    \n #   df_all[feat] += 1\n  #df_all[feat] = np.log1p(df_all[feat])\n#for feat in skewed_features:\n#    df_all[feat]=np.log1p(df_all[feat])","ae2e4113":"#df_all['3SsnPorch']\nnumeric_feats = df_all.dtypes[df_all.dtypes != \"object\"].index\nnumeric_feats\n\nskewed_feats = df_all[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew' :skewed_feats}) \n#skewness=skewness[abs(skewness['Skew'])>1]\nskewness","747f8c83":"# from sklearn.preprocessing import LabelEncoder\n# for c in catcols:\n#     lbl = LabelEncoder() \n#     lbl.fit(list(df_all[c].values)) \n#     d=c+\"_e\"\n#     #print(d)\n#     df_all[d] = lbl.transform(list(df_all[c].values)) \n#    #df_all[c]=np.log1p(df_all[c])","353a7702":"df_all.shape","a0544e3f":"def encode(frame, feature):\n    ordering = pd.DataFrame()\n    ordering['val'] = df_all[feature].unique()\n    ordering.index = ordering.val\n    ordering['spmean'] = frame[[feature, 'SalePrice']].groupby(feature).mean()['SalePrice']\n    ordering = ordering.sort_values('spmean')\n    ordering['ordering'] = range(1, ordering.shape[0]+1)\n    ordering = ordering['ordering'].to_dict()\n    \n    for cat, o in ordering.items():\n        df_all.loc[df_all[feature] == cat, feature+'_E'] = str(o)\n    \nqual_encoded = []\nfor q in catcols:  \n    encode(df_train, q)\n    #df_train.append(q+'_E')\nprint(qual_encoded)\n","bf173b50":"#df_train.SalePrice\n#df_all['MSSubClass']\ndf_all.shape","bd040b29":"# def encode2(frame, feature):\n#     ordering = pd.DataFrame()\n#     ordering['val'] = df_all[feature].unique()\n#     ordering.index = ordering.val\n#     ordering['spmean'] = frame[[feature, 'SalePrice']].groupby(feature).mean()['SalePrice']\n#     ordering = ordering.sort_values('spmean')\n#     ordering['ordering'] = range(1, ordering.shape[0]+1)\n#     #print(ordering)\n#     ordering = ordering['ordering'].to_dict()\n#     #print(ordering.items())\n#     #print(ordering)\n    \n#     for cat, o in ordering.items():\n#         #df_all.loc[df_all[feature] == cat, feature+'_E'] = o\n#         print(feature,o,cat)\n#         #print(o)\n        \n\n# for q in catcols:  \n#     encode2(df_train, q)\n#     #df_train.append(q+'_E')\n    \n    \n# for c in catcols:\n#     lbl = LabelEncoder() \n#     lbl.fit(list(df_all[c].values)) \n#     df_all[c] = lbl.transform(list(df_all[c].values))\n","490d4206":"df_all.head()","3367efca":"df_train[['MSZoning','SalePrice']].groupby('MSZoning').mean()\n#frame[[feature, 'SalePrice']].groupby(feature).mean()['SalePrice']","c71f460e":"df_all.isna().sum().sort_values(ascending=False)\n#df_all[df_all['GarageQual_E'].isna()].head()#['GarageQual']\n#df_all[df_all['GarageQual_E'].isna().GarageQual].head()#['GarageQual']","2aab6f47":"#df_train.iloc[:,81:]","f3e7a176":"skewed_feats","8af269e7":"df_all.shape","e9d4d5a1":"df_all['haspool'] = df_all['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\ndf_all['has2ndfloor'] = df_all['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\ndf_all['hasgarage'] = df_all['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\ndf_all['hasbsmt'] = df_all['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\ndf_all['hasfireplace'] = df_all['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)","88e52413":"df_all=pd.get_dummies(df_all).reset_index(drop=True)\ndf_all.shape","d29354b7":"skewed_features","d521faf7":"df_all.shape","86e2ebbc":"df_all.columns","2e1a25c9":"from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC,LassoCV\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\n#from sklearn.linear_model import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb","d3dde960":"from sklearn.linear_model import LinearRegression","95b1aeb2":"linreg = LinearRegression()","bb03515c":"for cat in df_all.columns:\n    print(cat)\n\nprint(df_train['RoofMatl'].unique())\nprint(df_train['RoofMatl'].unique())","ef9b4cfc":"df_all","187253b6":"data_input=df_all[:1458]\ndata_test=df_all[1458:]\ndata_output=np.log1p(df_train['SalePrice']).values\ndata_output.shape","78de6d72":"data_test.shape\ndata_output","ce5d09f1":"data_input.shape","32f20eeb":"data_test.shape","c63273af":"# for col in data_test.columns:\n#     if data_test[col].sum() == 0:\n#         data_input=data_input.drop(col,axis=1)\n#         data_test =data_test.drop(col,axis=1)\n","29989fa3":"print(data_input.shape)\nprint(data_test.shape)\nprint(data_output.shape)","8ba79a7c":"\n#data_test=df_test.drop(['Id'],axis=1)\n#data_test=pd.get_dummies(data_test)\n\n#data_output=np.log1p(df_train['SalePrice'])\n#data_input=df_train.drop(['Id','SalePrice'],axis=1)\n#data_input=df_train.drop(colstodrop,axis=1)\n#data_input=pd.get_dummies(data_input)\n#data_=pd.get_dummies(data_input)\n#\n","a8cff8f3":"#traincols=data_test.columns\n#testcols=data_input.columns\n#traincols\n\n#def common_member(a, b): \n#    a_set = set(a) \n#    b_set = set(b) \n#    if (a_set & b_set): \n#        return list(a_set & b_set) \n#    else: \n#        print(\"No common elements\")  \n           \n#modelcols=common_member(traincols, testcols) \n","5726e51c":"#data_input=data_input[modelcols]\n#modelcols\n#data_input\nprint(data_input.shape)\nprint(data_output.shape)","26488e05":"#Validation function\nn_folds = 5\n\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(data_input.values)\n    rmse= np.sqrt(-cross_val_score(model, data_input.values, data_output, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)","b31606db":"data_output","ce450a93":"linreg.fit(data_input, data_output)\n#linreg_output=linreg.predict(data_input)\nrmsle_cv(linreg).mean()","4f95efcb":"fig,ax=plt.subplots()\nax.scatter(x=data_output,y=linreg.predict(data_input))","1ae464da":"linreg_output=linreg.predict(data_test)","7ab42ef1":"linreg_output[abs(linreg_output)>15]","1e7c27b3":"data_input.shape\ntype(data_input)","fa0470e9":"data_input.iloc[120:290]","39ca92bd":"# data_input.shape\n\n# kf=KFold(5)\n# kf.split(data_input,data_output)\n# k=list(range(100))\n# for x,y in kf.split(data_input,data_output):\n#     print (x,y)\n#     x=list(x)\n#     print(data_input[x])\n#     print(type(x))","421f8eb4":"# #i=0\n# #j=np.zeros(20)\n# #for i in range(0,20):\n#     #print(i)\n# #    j[i]=i\n# #    i+=1\n    \n# kf=KFold(5)\n# #print(j)\n# #print(j.shape)\n# lasso = Lasso(alpha =0.0005, random_state=1)\n# ENet =  ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=1)\n\n# #print(da)\n# print(data_input.shape[0])\n# print(data_output.shape[0])\n# predictions=np.zeros((data_input.shape[0],2))\n\n# i=0\n# for x,y in kf.split(data_input,data_output):\n#     lasso.fit(data_input.iloc[x],data_output.iloc[x])\n#     ENet.fit(data_input,data_output)\n# #     print(i)\n# #     i+=1\n# #     if(data_input.loc[x].isna()):\n#     #print(x)\n#     #output=data_input.loc[x]\n#     #print(data_input.loc[x].isna().sum())\n#     #data_input[data_input.isnull().any(axis=1)]\n#     #print(data_output.loc[x].shape)\n#     #print(y)\n#     predictions[y,0]=lasso.predict(data_input.iloc[y])\n#     predictions[y,1]=ENet.predict(data_input.iloc[y])\n#     #predictions[y,1]=lasso.predict(data_input.loc[y])\n#     #print(data_output.loc[x])\n#     #data_input.loc[x] \n# #print(predictions)\n# #xgb_output=model_xgb.predict(data_test)\n# #rmsle_cv(model_xgb).mean()\n# model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n#                              learning_rate=0.05, max_depth=3, \n#                              min_child_weight=1.7817, n_estimators=2200,\n#                              reg_alpha=0.4640, reg_lambda=0.8571,\n#                              subsample=0.5213, silent=1,\n#                              random_state =7, nthread = -1)\n# #model_xgb.fit(data_input,data_output)\n# model_xgb.fit(predictions,data_output)\n# print(rmsle_cv(model_xgb).mean())\n# print(rmsle_cv(model_xgb).std())\n# predictions.shape    \n# print(predictions)","f84cb551":"# data_input.loc[data_input['1stFlrSF'].isnull()]\n# output.isnull().sum()\n# output[output['MSSubClass'].isnull()]\n# data_input.iloc[523,:]","8d2be9b5":"# data_input.shape\n# data_output.shape\n\n# #data_output.loc[290]\n# print(predictions.shape)\n\n# #predictions=np.zeros(df_train.shape[0])\n# print(predictions.shape)\n# print(data_output.shape)\n# print(predictions)\n\n\n#predictions=np.zeros((df_train.shape[0],1))","58915d44":"# data_input.head()\n# data_output.head()\ndf_all.shape","6d095054":"#lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n\n\n\nalphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\nkfolds = KFold(n_splits=10, shuffle=True, random_state=42)\nlasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds))\n#lasso = Lasso(alpha =0.0005, random_state=1)\nlasso.fit(data_input,data_output)\n\nlasso_output_train=lasso.predict(data_input)\nlasso_output=lasso.predict(data_test)\nprint(rmsle_cv(lasso).mean())\nprint(rmsle_cv(lasso).std())","3be70255":"resid=abs(lasso_output_train-data_output)\nout_mean=abs(lasso_output_train-data_output).mean()\nout_std=abs(lasso_output_train-data_output).std()\nz=(resid-out_mean)\/out_std\n#out_border\nz=np.array(z)\n#outliers=\noutliers=np.where(abs(z)>1.3*abs(z).std())[0]\noutliers","acbc81ee":"#detect outliers\n\n#np.where(resid > out_mean+3*out_std  )\n#data_input=data_input.drop([outliers],axis=0)\n#data_input\n# data_input_drop_out=data_input.drop([30,   66,   88,  142,  185,  277,  308,  328,  410,  431,  462,\n#         479,  495,  559,  580,  587,  627,  631,  657,  665,  680,  687,\n#         709,  710,  713,  727,  773,  811,  873,  897,  967,  969, 1021,\n#        1061, 1121, 1138, 1180, 1210, 1211, 1322, 1381, 1430, 1451])\n# data_output_drop_out=np.delete(data_output,[30,   66,   88,  142,  185,  277,  308,  328,  410,  431,  462,\n#         479,  495,  559,  580,  587,  627,  631,  657,  665,  680,  687,\n#         709,  710,  713,  727,  773,  811,  873,  897,  967,  969, 1021,\n#        1061, 1121, 1138, 1180, 1210, 1211, 1322, 1381, 1430, 1451],0)\n# type(data_input)\n# type(data_output)\n\n# data_input_drop_out=data_input.drop([   3,    4,   13,   17,   22,   24,   30,   35,   38,   48,   59,\n#          66,   70,   76,   88,   97,  107,  142,  154,  157,  169,  175,\n#         181,  185,  193,  198,  216,  217,  218,  223,  225,  238,  242,\n#         250,  251,  261,  268,  270,  275,  277,  286,  291,  308,  318,\n#         328,  329,  330,  335,  347,  348,  358,  365,  371,  377,  378,\n#         393,  397,  401,  410,  418,  431,  439,  441,  445,  451,  457,\n#         462,  473,  479,  488,  495,  503,  507,  512,  528,  534,  543,\n#         544,  545,  557,  558,  559,  580,  587,  588,  606,  607,  625,\n#         627,  629,  631,  638,  651,  657,  661,  665,  668,  679,  680,\n#         687,  704,  706,  709,  710,  713,  714,  715,  716,  725,  727,\n#         737,  739,  743,  746,  770,  771,  773,  788,  795,  796,  802,\n#         807,  808,  811,  854,  863,  873,  884,  895,  897,  901,  914,\n#         915,  922,  934,  939,  941,  944,  962,  967,  969,  971,  972,\n#         989,  999, 1021, 1025, 1029, 1045, 1048, 1055, 1061, 1064, 1067,\n#        1074, 1079, 1091, 1121, 1130, 1138, 1142, 1144, 1149, 1162, 1167,\n#        1177, 1178, 1180, 1182, 1183, 1184, 1199, 1201, 1204, 1210, 1211,\n#        1214, 1215, 1218, 1224, 1243, 1246, 1251, 1261, 1266, 1275, 1281,\n#        1302, 1320, 1322, 1323, 1335, 1336, 1342, 1343, 1348, 1357, 1376,\n#        1378, 1380, 1381, 1384, 1413, 1421, 1425, 1430, 1441, 1451])\n\n# data_output_drop_out=np.delete(data_output,[   3,    4,   13,   17,   22,   24,   30,   35,   38,   48,   59,\n#          66,   70,   76,   88,   97,  107,  142,  154,  157,  169,  175,\n#         181,  185,  193,  198,  216,  217,  218,  223,  225,  238,  242,\n#         250,  251,  261,  268,  270,  275,  277,  286,  291,  308,  318,\n#         328,  329,  330,  335,  347,  348,  358,  365,  371,  377,  378,\n#         393,  397,  401,  410,  418,  431,  439,  441,  445,  451,  457,\n#         462,  473,  479,  488,  495,  503,  507,  512,  528,  534,  543,\n#         544,  545,  557,  558,  559,  580,  587,  588,  606,  607,  625,\n#         627,  629,  631,  638,  651,  657,  661,  665,  668,  679,  680,\n#         687,  704,  706,  709,  710,  713,  714,  715,  716,  725,  727,\n#         737,  739,  743,  746,  770,  771,  773,  788,  795,  796,  802,\n#         807,  808,  811,  854,  863,  873,  884,  895,  897,  901,  914,\n#         915,  922,  934,  939,  941,  944,  962,  967,  969,  971,  972,\n#         989,  999, 1021, 1025, 1029, 1045, 1048, 1055, 1061, 1064, 1067,\n#        1074, 1079, 1091, 1121, 1130, 1138, 1142, 1144, 1149, 1162, 1167,\n#        1177, 1178, 1180, 1182, 1183, 1184, 1199, 1201, 1204, 1210, 1211,\n#        1214, 1215, 1218, 1224, 1243, 1246, 1251, 1261, 1266, 1275, 1281,\n#        1302, 1320, 1322, 1323, 1335, 1336, 1342, 1343, 1348, 1357, 1376,\n#        1378, 1380, 1381, 1384, 1413, 1421, 1425, 1430, 1441, 1451],0)\n\n\ndata_input_drop_out=data_input.drop([   3,    4,   13,   17,   30,   38,   48,   66,   70,   76,   88,\n         97,  107,  142,  154,  175,  181,  185,  193,  198,  217,  218,\n        223,  225,  238,  242,  251,  261,  268,  275,  277,  286,  291,\n        308,  318,  328,  329,  330,  347,  348,  358,  365,  371,  377,\n        378,  380,  393,  397,  401,  410,  418,  431,  439,  441,  445,\n        451,  454,  457,  462,  473,  479,  488,  495,  512,  528,  534,\n        543,  545,  557,  558,  559,  580,  587,  588,  606,  607,  625,\n        627,  631,  657,  661,  665,  668,  679,  680,  687,  704,  706,\n        709,  710,  713,  714,  715,  725,  727,  737,  739,  743,  746,\n        770,  771,  773,  788,  796,  802,  807,  808,  811,  854,  863,\n        873,  884,  895,  897,  915,  934,  939,  941,  943,  944,  962,\n        967,  969,  971,  972,  989,  999, 1021, 1029, 1045, 1048, 1055,\n       1061, 1064, 1067, 1074, 1079, 1091, 1121, 1130, 1138, 1142, 1162,\n       1167, 1177, 1180, 1182, 1183, 1184, 1199, 1201, 1210, 1211, 1214,\n       1215, 1243, 1246, 1251, 1261, 1266, 1302, 1320, 1322, 1323, 1335,\n       1342, 1343, 1357, 1376, 1378, 1381, 1384, 1413, 1421, 1430, 1441,\n       1451])\n\ndata_output_drop_out=np.delete(data_output,[   3,    4,   13,   17,   30,   38,   48,   66,   70,   76,   88,\n         97,  107,  142,  154,  175,  181,  185,  193,  198,  217,  218,\n        223,  225,  238,  242,  251,  261,  268,  275,  277,  286,  291,\n        308,  318,  328,  329,  330,  347,  348,  358,  365,  371,  377,\n        378,  380,  393,  397,  401,  410,  418,  431,  439,  441,  445,\n        451,  454,  457,  462,  473,  479,  488,  495,  512,  528,  534,\n        543,  545,  557,  558,  559,  580,  587,  588,  606,  607,  625,\n        627,  631,  657,  661,  665,  668,  679,  680,  687,  704,  706,\n        709,  710,  713,  714,  715,  725,  727,  737,  739,  743,  746,\n        770,  771,  773,  788,  796,  802,  807,  808,  811,  854,  863,\n        873,  884,  895,  897,  915,  934,  939,  941,  943,  944,  962,\n        967,  969,  971,  972,  989,  999, 1021, 1029, 1045, 1048, 1055,\n       1061, 1064, 1067, 1074, 1079, 1091, 1121, 1130, 1138, 1142, 1162,\n       1167, 1177, 1180, 1182, 1183, 1184, 1199, 1201, 1210, 1211, 1214,\n       1215, 1243, 1246, 1251, 1261, 1266, 1302, 1320, 1322, 1323, 1335,\n       1342, 1343, 1357, 1376, 1378, 1381, 1384, 1413, 1421, 1430, 1441,\n       1451],0)\n","708d436a":"\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\ndata_input_drop_out.describe()\n#data_input.SaleType_Oth\n#data_input_drop_out.GarageYrBlt","b6e88858":"print(data_output_drop_out.shape)\nprint(data_input_drop_out.shape)","9c3f21c8":"#lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n\n\n\nalphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\nkfolds = KFold(n_splits=10, shuffle=True, random_state=42)\nlasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds))\n#lasso = Lasso(alpha =0.0005, random_state=1)\nlasso.fit(data_input_drop_out,data_output_drop_out)\n\n#lasso_output_train=lasso.predict(data_input_drop_out)\nlasso_output=lasso.predict(data_test)\n#print(rmsle_cv(lasso).mean())\n#print(rmsle_cv(lasso).std())\n\nprint(np.sqrt(-cross_val_score(lasso, data_input_drop_out, data_output_drop_out, cv=5, scoring=\"neg_mean_squared_error\")).mean())\n\nprint(np.sqrt(-cross_val_score(lasso, data_input, data_output, cv=5, scoring=\"neg_mean_squared_error\")).mean())\n\n#0.06322291922 - This is the neg sq error before\n#0.06282314846491026 - with yr sold as numeric\n#0.06283893683984203 - year sold as categorical\n#0.061950377776641655 - yr sold as categorical ,plus new removals for outliers\n#V51 - 0.0622346286049821 added quality","d4a4afee":"# xgb_output=model_xgb.predict(lasso_output.reshape(-1,1))\nprint(df_all.shape)","dbe8604f":"# xgb_output","83c72330":"# df_all.shape","80dd9c97":"# data_test.shape","4425ac69":"# model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n#                              learning_rate=0.05, max_depth=3, \n#                              min_child_weight=1.7817, n_estimators=2200,\n#                              reg_alpha=0.4640, reg_lambda=0.8571,\n#                              subsample=0.5213, silent=1,\n#                              random_state =7, nthread = -1)\n# model_xgb.fit(data_input_drop_out,data_output_drop_out)\n# xgb_output_train=model_xgb.predict(data_input)\n# xgb_output=model_xgb.predict(data_test)\n# print(np.sqrt(-cross_val_score(model_xgb, data_input_drop_out, data_output_drop_out, cv=5, scoring=\"neg_mean_squared_error\")).mean())\n\n#rmsle_cv(model_xgb).mean()","2a681d87":"\n\nfrom sklearn.linear_model import Ridge\n\nrr = Ridge(alpha=13)\nrr.fit(data_input_drop_out, data_output_drop_out)\nnp.sqrt(-cross_val_score(rr, data_input_drop_out, data_output_drop_out, cv=5, scoring=\"neg_mean_squared_error\")).mean()","9fd3c6c7":"\n# from sklearn.ensemble import RandomForestRegressor\n\n# regr = RandomForestRegressor(max_depth=2, random_state=0,\n#                               n_estimators=100)\n# regr.fit(data_input_drop_out,data_output_drop_out)\n# print(np.sqrt(-cross_val_score(regr, data_input_drop_out, data_output_drop_out, cv=5, scoring=\"neg_mean_squared_error\")).mean())\n","7f194ecb":"# ENet =  ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=1)\n# ENet.fit(data_input_drop_out,data_output_drop_out)\n# ENet_output_train=ENet.predict(data_input)\n# ENet_output=ENet.predict(data_test)\n\n# print(np.sqrt(-cross_val_score(ENet, data_input_drop_out, data_output_drop_out, cv=5, scoring=\"neg_mean_squared_error\")).mean())\n\n#rmsle_cv(ENet).mean()","ebdb88cc":"#averaged_models = AveragingModels(models = (ENet,   lasso))","587e792f":"\n# stk_inp_train=np.column_stack([lasso_output_train,ENet_output_train,xgb_output_train])\n# GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n#                                    max_depth=4, max_features='sqrt',\n#                                    min_samples_leaf=15, min_samples_split=10, \n#                                    loss='huber', random_state =5)\n# GBoost.fit(stk_inp_train, data_output)\n\n\n# rmsle_cv(GBoost).mean()\n# #linreg_output=linreg.predict(data_input)\n# #stk_inp_test.shape\n","cfa8435e":"#df_all.Id\n# stk_inp_train=np.column_stack([lasso_output_train,ENet_output_train])","77c6b648":"# linreg.fit(stk_inp_train,data_output)\n# print(linreg.coef_)\n#rmsle_cv(linreg).mean()\n# #linreg.predict(stk_inp_test)[abs(linreg.predict(stk_inp_test))>15]","d99ef3d3":"# linreg.predict(stk_inp_train)","6dc2e0b9":"# data_test.isnull().sum().sort_values(ascending = False).head(5)","39d08238":" testids=df_test['Id']\n# print(testids.shape)\n# print(data_test.shape) \n# print(data_test.columns)\n\n# i=0\n\n#dat_test[data_test.groupby('MSSubClass').sum() == 0","a1d9d0e2":"# print(testcolsnoval)","029c681e":"lasso_output =lasso.predict(data_test)\n# ENet_output=ENet.predict(data_test)\n# xgb_output=model_xgb.predict(data_test)\n#xgb_output=model_xgb.predict(stk_inp_test))\n# stk_inp_test=np.column_stack([lasso_output,ENet_output,xgb_output])\n#test_output=GBoost.predict(stk_inp_test) # commenting out to submit lasso\ntest_output=lasso_output\n#test_output=xgb_output","3d49b10d":"#test_output=0.33*lasso_output+0.33*ENet_output+0.34*xgb_output\n#test_output=xgb_output\n#test_output=lasso_output\n#lasso_output.shape\n\n#test_output=GBoost.predict(stk_inp_test)","64ef4e47":"results=pd.concat([testids,pd.Series(np.expm1(test_output))],axis=1,keys=['Id','SalePrice'])","4ebc20f8":"results.head(5)","2a3fc933":"results.to_csv('..\/working\/submissionslassooutlierremoval6.csv',index=False)\n","a239e31b":"\nprint(os.listdir(\"..\/working\"))","175fe53b":"df_train.head()","24e32146":"data_test.head()","1b6634c3":"**THanks to this Kernel.\n\nI have used Kernel by this individual to learn a lot.**\n\nhttps:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard\n\nPlease excuse me for the unformatted version, I will format it soon,But you can take necessary techniques available here.If you did find this kernel helpful in anyway, a mention would be appreciated :).\n\n\nThis code has been developed with the help of lot of kernels available public in this competition. Thanks you all for the contributions.","596096ad":"    Label Encoding","c2000717":"data_test=pd.get_dummies(data_test)\ndata_input=pd.get_dummies(data_input)","c2b1d1eb":"PoolQC\t0.996574\t2909\nMiscFeature\t0.964029\t2814\nAlley\t0.932169\t2721\nFence\t0.804385\t2348\nFireplaceQu\t0.486468\t1420\nLotFrontage\t0.166495\t486\nGarageYrBlt\t0.054471\t159\nGarageFinish\t0.054471\t159\nGarageQual\t0.054471\t159\nGarageCond\t0.054471\t159\nGarageType\t0.053786\t157\nBsmtExposure\t0.028092\t82\nBsmtCond\t0.028092\t82\nBsmtQual\t0.027749\t81\nBsmtFinType2\t0.027407\t80\nBsmtFinType1\t0.027064\t79\nMasVnrType\t0.008222\t24\nMasVnrArea\t0.007879\t23\nMSZoning\t0.001370\t4\nFunctional\t0.000685\t2\nBsmtHalfBath\t0.000685\t2\nBsmtFullBath\t0.000685\t2\nUtilities\t0.000685\t2","b8d85157":"data_test=data_test.drop(['Id'],axis=1)\ndata_test.shape","0c9ea7e2":"> "}}