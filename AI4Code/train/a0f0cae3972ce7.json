{"cell_type":{"be8fd029":"code","1d370414":"code","127afaa7":"code","81636462":"code","1be6569e":"code","673e0536":"code","a03341e8":"code","a4e88be1":"code","fd532049":"code","d1848159":"code","465b4c9e":"code","d7a880b1":"code","512992f1":"code","b43abd1d":"code","93bc6c1a":"code","dd2e138b":"code","415acf6a":"markdown","712bc080":"markdown","377b6501":"markdown","7e526dd5":"markdown","e147eb15":"markdown","906bc019":"markdown"},"source":{"be8fd029":"import pandas as pd\n\n# Import country diabetes data\ndataset = pd.read_excel('..\/input\/country-summary\/country_summary.xlsx')\n\n# Remove unnecessary columns\ndataset = dataset.drop(labels=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4','Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9','Unnamed: 11', 'Unnamed: 12','Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17','Unnamed: 19', 'Unnamed: 20','Unnamed: 22','Unnamed: 24', 'Unnamed: 25','Unnamed: 27'],axis=1)\n\n# Remove values within parantheses\ndataset['Number of adults 20\u201379 years with diabetes in 1,000s (95% confidence interval)'] = dataset['Number of adults 20\u201379 years with diabetes in 1,000s (95% confidence interval)'].str.replace(r\"\\(.*\\)\",\"\")\n\ndataset['Number of adults 20\u201379 years with undiagnosed diabetes in 1,000s (95% confidence interval)'] = dataset['Number of adults 20\u201379 years with undiagnosed diabetes in 1,000s (95% confidence interval)'].str.replace(r\"\\(.*\\)\",\"\")\n\n# Create new dataset comparing country\/territory with select columns\ndataset = dataset[['Country or territory', 'Number of adults 20\u201379 years with diabetes in 1,000s (95% confidence interval)', 'Number of adults 20\u201379 years with undiagnosed diabetes in 1,000s (95% confidence interval)']]\n\n# Rename columns\ndiab_country = dataset.rename(columns={'Number of adults 20\u201379 years with diabetes in 1,000s (95% confidence interval)': '# 20-79 yr Old Adults w\/ Diabetes (1000s)', 'Number of adults 20\u201379 years with undiagnosed diabetes in 1,000s (95% confidence interval)': '# 20-79 yr Old Adults w\/ Undiagnosed Diabetes (1000s)'})\n\n# Turn values from strings with commas and unecessary spaces into floating pt. numbers\ndiab_country['# 20-79 yr Old Adults w\/ Diabetes (1000s)'] = diab_country['# 20-79 yr Old Adults w\/ Diabetes (1000s)'].str.replace(',', '').str.replace(' ', '').astype(float)\n\ndiab_country['# 20-79 yr Old Adults w\/ Undiagnosed Diabetes (1000s)'] = diab_country['# 20-79 yr Old Adults w\/ Undiagnosed Diabetes (1000s)'].str.replace(',', '').str.replace(' ', '').astype(float)\n\ndiab_country","1d370414":"import pandas as pd\n\n# Import GDP per capita data\ngdp_capita = pd.read_csv('..\/input\/gdp-per-capita\/API_NY.GDP.PCAP.CD_DS2_en_csv_v2_1217696.csv')\n\n# We only need 2019 data, so all other columns can be removed\n# Additionally, all NaN terms and repeated data points are removed\n# Right column is renamed\n\ngdp_capita = (gdp_capita[['Country Name','2019']].rename(columns = {'2019':'GDP\/Capita 2019'})).dropna().drop_duplicates()\n\ngdp_capita","127afaa7":"# Turn GDP\/capita values into a dictionary, so GDP\/capita can be easily fetched given a country\/territory name\ngdp_capita_np = gdp_capita.to_numpy() # turn to numpy array to extract data easily\ngdp_capita_dict = {} # new empty dictionary to be filled\n\nfor n in range(len(gdp_capita_np)):\n    gdp_capita_dict[gdp_capita_np[n][0]] = gdp_capita_np[n][1]\n","81636462":"import numpy as np\n# Turn each column into an individual numpy array\ncountry_col = diab_country['Country or territory'].to_numpy()\ncol_1 = diab_country['# 20-79 yr Old Adults w\/ Diabetes (1000s)'].to_numpy()\ncol_2 = diab_country['# 20-79 yr Old Adults w\/ Undiagnosed Diabetes (1000s)'].to_numpy()\n\n# Use GDP\/Capita dictionary to turn country\/territory names to GDP values\nfor i in range(len(country_col)):\n    if country_col[i] in gdp_capita_dict:\n        country_col[i] = gdp_capita_dict[country_col[i]]\n        \n# Not all countries\/territories are present in GDP\/Capita dictionary, so the remaining will be discarded\n# GDPs will be appended to new array\n\ndiscarded_countries = [] # Type: str\ndiscarded_country_indices = [] # Array type: contains individual numpy arrays with indices\nGDPs = [] # Array type: float\n\nfor i in country_col:\n    if type(i) == str:\n        discarded_countries.append(i)\n        discarded_country_indices.append(np.where(country_col==i))\n    else:\n        GDPs.append(i)\n        \nGDPs = np.array(GDPs)\nplace_holder = []\n\nfor u in range(len(discarded_country_indices)):\n    place_holder.append(discarded_country_indices[u][0][0])\ndiscarded_country_indices = place_holder # Array type: int, contains indices of all countries without corresponding GDP\/capita values\n\n# The following code removes the diabetes data from countries without GDP\/capita data from col_1 and col_2 (discarded_country_indices tells which indices to remove)\n\ncol_1 = np.delete(col_1,discarded_country_indices)\ncol_2 = np.delete(col_2,discarded_country_indices)\n\nprint(\"GDP Numpy Array Shape (Ind. variable): \",np.shape(GDPs))\nprint(\"Col 1 & 2 Shape (Dep. variables): \",np.shape(col_1),np.shape(col_2))\n\n# Data is all in the correct form and shape and ready to be plotted.","1be6569e":"import matplotlib.pyplot as plt\n\n# Col_1 contains data on the # of 20-79 yr old adults w\/ Diabetes\n# Following plot compares Col_1 values to country GDP\/capita\n\nplt.scatter(GDPs,col_1)\nplt.xlabel('GDP Per Capita')\nplt.ylabel('# 20-79 yr Old Adults w\/ Diabetes (1000s)')\nplt.suptitle('Instances of Diabetes vs. Country GDP\/Capita')\n\nplt.show() ","673e0536":"# Visual inspection of the data indicates that there are two outlier countries with low GDP\/Capita values and very high numbers of individuals with diabetes. For appropriate interpretation, these values will be excluded.\n\nplt.scatter(GDPs,col_1)\nplt.xlim(0,9e4)\nplt.ylim(0,3e3)\nplt.xlabel('GDP Per Capita')\nplt.ylabel('# 20-79 yr Old Adults w\/ Diabetes (1000s)')\nplt.suptitle('Instances of Diabetes vs. Country GDP\/Capita')\nplt.show()\n\n# General trend indicates that, with larger GDP per capita values, number of individuals with diabetes decreases","a03341e8":"# Col_2 contains data on the # of 20-79 yr old adults that remain undiagnosed\n# Following plot compares Col_2 values to country GDP\/capita\n\nplt.scatter(GDPs,col_2)\nplt.xlabel('GDP Per Capita')\nplt.ylabel('# 20-79 yr Old Adults w\/ Undiagnosed Diabetes (1000s)')\nplt.suptitle('Instances of Undiagnosed Diabetes vs. Country GDP\/Capita')\n\nplt.show()","a4e88be1":"# Similarly, the two points out of 155 countries in Col_2 will influence the analysis. For robust and appropriate interpretation, the two points will be removed from Col_2.\n\n# A formal statistical test for the influence of those two points could be conducted in the future. However, that would be outside the scope of this analysis. A visual inspection was sufficient for now.\n\nremoved_indices = []\nfor value in col_2:\n    if value > 4e4:\n        removed_indices.append(np.where(col_2==value))\nremoved_indices = [removed_indices[0][0][0],removed_indices[1][0][0]]\n\nGDPs = np.delete(GDPs,removed_indices)\ncol_2 = np.delete(col_2,removed_indices)\n\n# Data ready to be plotted","fd532049":"from scipy import stats\n\nplt.scatter(GDPs,col_2)\nplt.xlabel('GDP Per Capita')\nplt.ylabel('# 20-79 yr Old Adults w\/ Undiagnosed Diabetes (1000s)')\nplt.suptitle('Instances of Undiagnosed Diabetes vs. Country GDP\/Capita')\n\n# Add regression line:\n\nm,b,r,p,std_err = stats.linregress(GDPs,col_2)\nplt.plot(GDPs,GDPs*m+b)\n\n# Calculate r-squared value:\n\nr_squared = r**2\n\n# Plot of Individuals with Undiagnosed Diabetes vs. GDP\/Capita excluding two outlier points.\n\nprint(\"Slope: \",m,',',\"Y-intercept: \",b)\nprint('R-squared: ',r_squared)\nplt.show()","d1848159":"# Change window to (0,2000):\nplt.scatter(GDPs,col_2)\nplt.xlabel('GDP Per Capita')\nplt.ylabel('# 20-79 yr Old Adults w\/ Undiagnosed Diabetes (1000s)')\nplt.suptitle('Instances of Undiagnosed Diabetes vs. Country GDP\/Capita')\n\nplt.plot(GDPs,GDPs*m+b)\nplt.ylim(0,2e3)\n\nprint(\"Slope: \",m,',',\"Y-intercept: \",b)\nprint('R-squared: ',r_squared)\nprint()\nprint(\"Decrease in number of individuals with undiagnosed diabetes with a $20,000 increase in GDP\/Capita (1000s): \",abs(m*2e4))\n\nplt.show()","465b4c9e":"# Split Col_2 values into Lower & Upper:\n\nLower,Upper = col_2,col_2\n\nsplit = 4e3\nindices_to_remove_for_lower = []\nfor value in GDPs:\n    if value >= split:\n        indices_to_remove_for_lower.append(np.where(GDPs==value))\n\nindices_to_remove_for_upper = []\nfor value in GDPs:\n    if value < split:\n        indices_to_remove_for_upper.append(np.where(GDPs==value))\n\nplace_holder = []\nfor b in range(len(indices_to_remove_for_lower)):\n    place_holder.append(indices_to_remove_for_lower[b][0][0])\nindices_to_remove_for_lower = place_holder\n\nplace_holder = []\nfor b in range(len(indices_to_remove_for_upper)):\n    place_holder.append(indices_to_remove_for_upper[b][0][0])\nindices_to_remove_for_upper = place_holder\n\nLower = np.delete(Lower,indices_to_remove_for_lower)\nUpper = np.delete(Upper,indices_to_remove_for_upper)\n\n# Col_2 now split into the 2 categories above.\n\n# Lower is the group containing # of individuals with undiagnosed diabetes from countries with LOW GDP\/Capitas\n\n# Upper is the group containing # of individuals with undiagnosed diabetes from countries with HIGH GDP\/Capitas\n\nprint('n_lower: ',len(Lower),',','n_upper: ',len(Upper))\nprint()\n\n#t-test\nt_stat,pvalue = stats.ttest_ind(Lower,Upper,equal_var=False)\nprint('t-statistic: ',t_stat)\nprint('p-value: ',pvalue)","d7a880b1":"# Import data:\n\nimport pandas as pd\ndf_pima = pd.read_csv('..\/input\/pimadiabetes\/diabetes.csv')\ndf_pima.head()","512992f1":"# Split data\nfrom sklearn.model_selection import train_test_split\n\nX = df_pima.drop(labels='Outcome',axis=1).to_numpy()\ny = df_pima['Outcome'].to_numpy()\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.8)\ny_test,y_train = y_test.reshape(-1),y_train.reshape(-1)\n\nprint(\"Train shape: \",np.shape(X_train),np.shape(y_train))\nprint(\"Test shape: \",np.shape(X_test),np.shape(y_test))\n\n# We are now ready to proceed to the first algorithm: SVM","b43abd1d":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\n\n# Perform Hyperparamter Optimization:\n# Optimization was run locally, so only code and output will be shown.\n\n# Create a dictionary with all possible combinations of important hyperparamters for GridSearch to test\n\"\"\"\nparams_to_test_svm = {'C':[0.01,0.1,1,10,100],'kernel':['linear','rbf','sigmoid'],'gamma':[0.001,0.01,0.1,1,10,100]}\n\ngrid = GridSearchCV(SVC(), params_to_test_svm, verbose=10, n_jobs=-1)\ngrid.fit(X_train,y_train)\n\nprint(\"best score: \", grid.best_score_)\nprint(\"best estimator: \", grid.best_estimator_)\nprint(\"best params: \", grid.best_params_)\n\"\"\"\n# Time elapsed: 35.1 minutes \n\n# best score:  0.768418308831196\n\n# best estimator:  SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)\n\n# best params:  {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}\n\n# Using the parameters found, performance is measured on test data:\n\nmodel = SVC(C=10, gamma=0.001, kernel='linear')\nmodel.fit(X_train,y_train)\n\n# Find number of True Positives (tp), True Negatives (tn), False Positives (fp), and False Negatives (fn)\n\npredicted = model.predict(X_test)\ntp,tn,fp,fn=0,0,0,0\n\nfor value in range(len(predicted)):\n    if predicted[value] == 0:\n        if y_test[value] == predicted[value]:\n            tn += 1\n        else:\n            fn += 1\n    else:\n        if y_test[value] == predicted[value]:\n            tp += 1\n        else:\n            fp += 1\n          \nprint(\"SVM Performance Summary:\")\nprint()\nprint(\"# True Positives: \",tp)\nprint(\"# True Negatives: \",tn)\nprint(\"# False Positives: \",fp)\nprint(\"# False Negatives: \",fn)\nprint(\"Total: \",sum([tp,tn,fp,fn]))\nprint()\n\nprecision, recall, accuracy = tp\/(tp+fp), tp\/(tp+fn), (tp+tn)\/(tp+tn+fn+fp)\nf1 = 2*precision*recall\/(precision+recall)\nprint(\"Precision Score: \",precision)\nprint(\"Recall Score: \",recall)\nprint(\"F1: \",f1)\nprint(\"Accuracy Score: \",accuracy)\n\n# This array will be used to compare against against scores from other classifiers\nsvm_array = [precision,recall,f1,accuracy]","93bc6c1a":"from sklearn.ensemble import RandomForestClassifier\n\n\"\"\"\nparams_to_test_rf = {'n_estimators':[100,250,500,1000],'criterion':['gini','entropy'],'max_features':['auto','sqrt','log2']}\ngrid = GridSearchCV(RandomForestClassifier(),params_to_test_rf,n_jobs=-1)\n\nprint(\"best score: \", grid.best_score_)\nprint(\"best estimator: \", grid.best_estimator_)\nprint(\"best params: \", grid.best_params_)\n\"\"\"\n# Time elapsed: 1.2 minutes\n\n# best score:  0.7703185392509663\n\n# best estimator:  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,criterion='entropy', max_depth=None, max_features='sqrt', max_leaf_nodes=None, max_samples=None,min_impurity_decrease=0.0, min_impurity_split=None,min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None, oob_score=False, random_state=None, verbose=0, warm_start=False)\n\n# best params:  {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 500}\n\nmodel = RandomForestClassifier(criterion='entropy',max_features='sqrt',n_estimators=500,n_jobs=-1)\nmodel.fit(X_train,y_train)\n\npredicted = model.predict(X_test)\ntp,tn,fp,fn=0,0,0,0\n\n\nfor value in range(len(predicted)):\n    if predicted[value] == 0:\n        if y_test[value] == predicted[value]:\n            tn += 1\n        else:\n            fn += 1\n    else:\n        if y_test[value] == predicted[value]:\n            tp += 1\n        else:\n            fp += 1\n          \nprint(\"RF Performance Summary:\")\nprint()\nprint(\"# True Positives: \",tp)\nprint(\"# True Negatives: \",tn)\nprint(\"# False Positives: \",fp)\nprint(\"# False Negatives: \",fn)\nprint(\"Total: \",sum([tp,tn,fp,fn]))\nprint()\n\nprecision, recall, accuracy = tp\/(tp+fp), tp\/(tp+fn), (tp+tn)\/(tp+tn+fn+fp)\nf1 = 2*precision*recall\/(precision+recall)\nprint(\"Precision Score: \",precision)\nprint(\"Recall Score: \",recall)\nprint(\"F1: \",f1)\nprint(\"Accuracy Score: \",accuracy)\n\nrf_array = [precision,recall,f1,accuracy]","dd2e138b":"from sklearn.ensemble import GradientBoostingClassifier\n\n\"\"\"\nparams_to_test_gbt = {'loss':['deviance'],'learning_rate':[0.01,0.05,0.1,0.2,0.3],'n_estimators':[100,300,500,1000],'criterion':['friedman_mse','mse','mae'],'min_samples_split':[2,5,10],'min_impurity_decrease':[0,0.01],'max_depth':[2,3,5,7]}\n\ngrid = GridSearchCV(GradientBoostingClassifier(),params_to_test_gbt,verbose=1,n_jobs=-1)\ngrid.fit(X_train,y_train)\n\nprint(\"best score: \", grid.best_score_)\nprint(\"best estimator: \", grid.best_estimator_)\nprint(\"best params: \", grid.best_params_)\n\"\"\"\n\n# best score: 0.7833799813407969\n\n# best estimator: GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,learning_rate=0.1, loss='deviance', max_depth=3,max_features=None, max_leaf_nodes=None,min_impurity_decrease=0, min_impurity_split=None,min_samples_leaf=1, min_samples_split=10,min_weight_fraction_leaf=0.0, n_estimators=100,n_iter_no_change=None, presort='deprecated',random_state=None, subsample=1.0, tol=0.0001,validation_fraction=0.1, verbose=0,warm_start=False)\n\n# best params:  {'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3, 'min_impurity_decrease': 0, 'min_samples_split': 10, 'n_estimators': 100}\n\nmodel = GradientBoostingClassifier(criterion='friedman_mse',learning_rate=0.1,loss='deviance',max_depth=3,min_impurity_decrease=0,min_samples_split=10,n_estimators=100)\nmodel.fit(X_train,y_train)\n\npredicted = model.predict(X_test)\ntp,tn,fp,fn=0,0,0,0\n\nfor value in range(len(predicted)):\n    if predicted[value] == 0:\n        if y_test[value] == predicted[value]:\n            tn += 1\n        else:\n            fn += 1\n    else:\n        if y_test[value] == predicted[value]:\n            tp += 1\n        else:\n            fp += 1\n            \nprint(\"GBT Performance Summary:\")\nprint()\nprint(\"# True Positives: \",tp)\nprint(\"# True Negatives: \",tn)\nprint(\"# False Positives: \",fp)\nprint(\"# False Negatives: \",fn)\nprint(\"Total: \",sum([tp,tn,fp,fn]))\nprint()\n\nprecision, recall, accuracy = tp\/(tp+fp), tp\/(tp+fn), (tp+tn)\/(tp+tn+fn+fp)\nf1 = 2*precision*recall\/(precision+recall)\nprint(\"Precision Score: \",precision)\nprint(\"Recall Score: \",recall)\nprint(\"F1: \",f1)\nprint(\"Accuracy Score: \",accuracy)\n\nrf_array = [precision,recall,f1,accuracy]","415acf6a":"*How does SVM work?*\n\nStandard-vector machines classify objects by attempting to draw a distinct line of separation between groups of data points. By taking in a dataset with N features, the SVM model plots each training data point in an N+1 dimensional grid and attempts to fit a hyperplane between the different clusters of points. If the model must choose between two outcomes,the hyperplane is placed so that it maximizes the distance between each of the two clusters, thus providing a clean separation between the two. In the event where more than two outcomes are possible, SVM can draw several hyperplanes. If a linear hyperplane cannot be appropriately placed between the two clusters, then the data will undergo some form of transformation or scaling to make the clusters more distinct. This is the job of the \"kernel\" parameter.\n\nSeveral parameters have an effect on the way that the hyperplane is placed in the grid. Two of the most important are parameters called \"C\" and \"gamma\", and both are tested below. C is the parameter that controls how closely the hyperplane will be fit to the training data. If fit very closely, then a low training error is achieved. However, this low training error is often correlated with a phenomenon called overfitting, in which the algorithm struggles to classify  test data that it is unfamilar with. This indicates the presence of a tradeoff between a model's ability to closely-fit the training data and generalize it for unseen data. The regularization term C quantifies this tradeoff. Different values are needed for different datasets, so it is important to optimize it for the specific dataset in use.\n\nThe parameter gamma quantifies how valuable a single data point is to the general model. In a dataset with mislabled points and\/or significant outliers, it is not preferable for every data point to have an equal say in the placement of the hyperplane. The data points that deviate notably should have less influence than those that follow the general trend. Large gamma values lead to high bias (meaning greater generalization and simplification) and low gamma values indicate high variance (meaning it abides closely by the training data i.e. overfitting).","712bc080":"*How do Gradient Boosted algorithms work in classification problems?*\n\nLike the Random Forest algorithm, Gradient Boosted Trees are a collection of trees that contribute towards a larger answer. However, instead of the individual independent decision trees present in RF, GBTs wield a collection of \"ensembles\", each containing several weak decision trees that are added together to make a more refined model. At the end, the most popular decision from the ensembles is the answer presented by the cumulative model.\n\nEach ensemble (*E_n*) is a collection of decision trees. The first tree (*T_n1*)is built from the entire training dataset, and records all the training elements it could not classify. The second tree (*T_n2*) is based on this data that the first tree had trouble with. Similarly, the third tree (*T_n3*) in the ensemble is based on the data that the second tree failed to classify, and so on until a specified stopping point *m*. The failures of each tree is recorded by a \"loss function\", which provides a form of measurement of the deviation of a prediction from the true value. This means that the decision reached by the nth ensemble is:\n\n*E_n = T_n1 + T_n2 + T_n3 + ... + T_nm*\n\nThe most popular decision of the collection of ensembles allows GBTs to reach a final decision.","377b6501":"*How do Random Forests work in classification problems?*\n\nThe core of the RF algorithm is based on the idea of popular-vote. It is called a \"Forest\" because it tallies up the individual decisions of a population of decision trees, and it outputs the most popular decision. The Forest is \"Random\" because it contains distinct uncorrelated trees. The trees are \"uncorrelated\" and unique because each is built from different sub-datasets of the original training data. That means that each tree grabs different attributes out of its specific sub-dataset, making the cumulative model robust against individual outlier points in some of its sub-datasets. This also means that each tree comes to its own decision, independent of those made by any of its peers.\n\nThe term \"sub-dataset\" may be misleading because each sub-dataset does not necessarily contain any less data than is in the entire training dataset. Instead, each tree takes in the full training dataset, changes some of the data values, and calls the new dataset a sub-dataset. Fabricating data sounds counter-intuitive, but it is the way that the decision reached by each tree can remain uninfluenced by those reached by its peers. Keep in mind, any errors made by an individual tree based on its sub-dataset are nearly irrelevant compared to the many other trees in the forest.\n\nThe parameters tested in the following code are the number of estimators (or trees), the \"criterion\", or the way to measure the quality of a split in a decision tree, and the maximum number of features, or the number of columns in the training data that each tree can base its decisions on.","7e526dd5":"As shown by the r-squared value of 0.00241, there appears to be a very weak linear relationship between the number of undiagnosed individuals and the GDP\/Capita of the country in which they live. This is due to the number of countries with both low GDP per Capita values and low numbers of individuals with undiagnosed diabetes. However, with a slope of -0.003346, the regression line indicates a negative relationship. An increase of $20,000 in a country's GDP\/Capita correlates with about 66,900 fewer instances of undiagnosed diabetes.\n\nTo further investigate this finding, I will perform a comparision of the number of individuals with undiagnosed diabetes from poor versus wealthy nations by creating two categories, split by a global understanding of low versus high GDP\/Capita values.\n\nBased on WorldBank classifications of Low income, Lower-middle income, Upper-middle income, and High income based on GNI\/Capita as of July 2019, the GDP\/Capita binary threshold used for this analysis will be $4000\/person. From the data in Col_2, two groups will be made around this split: Lower & Upper. A t-test will be conducted to see if there is a significant difference in the means of the two groups.\n\nNull: \u03bc_lower = \u03bc_upper","e147eb15":"The high p-value of 0.8245 indicates that there is insufficient evidence to claim the null hypothesis as false. That is, the mean values of the number of individuals with undiagnosed diabetes from poor and wealthy countries are not significantly different from each other. However, although the majority of undiagnosed values are small for countries with less GDP\/Capita (which accounts for the large p-value), there are still many instances in which some of these countries have large numbers of undiagnosed diabetic people. It is clear through visual inspection that there are no wealthy countries with equivalently high rates of undiagnosed people.\n\nFor these countries in particular, the importance of quicker and readily-available diagnoses opens up the potential for Machine Learning models to help.\n\nIf ML techniques are to be used to decrease the number of undiagnosed patients in poorer countries, which algorithms would provide the most accurate diagnoses based on patient characteristics? In the following analysis, three algorithms will be tested: Support-Vector Machines (SVM), Random Forest (RF), and Gradient Boosted Trees (GBTs). After hyperparameter optimization, several performance measures from each algorithm will be compared to discover the best of the tested algorithms. Each learning algorithm will be given the Pima Indian Diabetes dataset, containing several important patient characteristics along with their diagnoses, shown below. Performance will be evaluated on a test set.","906bc019":"From 1980 to 2014, the number of individuals with diabetes worldwide has risen from 108 million to 422 million, marking an astounding 290% increase. As of 2016, it is the 7th leading cause of death in the world, with 1.6 million deaths directly linked to diabetes that year alone (World Health Organization).\n\nThe amount of undiagnosed cases is also exceedingly high. In the United States, an estimated 7.3 million people remain undiagnosed as of 2018 (Diabetes Research Institute). It is expected that, in poorer countries with larger populations and less access to medical care, this number increases significantly. This deficiency could potentially leave room for a machine learning algorithm that could help in the diagnoses of these individuals, so they could then take the necessary steps to treat the disease. Which ML model would provide the most accurate prediction of diabetes in an individual given his\/her medical details?\n\nTo find out, it would first be necessary to show how the number of undiagnosed individuals compares to the care to which they may have access. A good way to represent this is through the GDP per capita of the individual's country, which provides a strong indication of the person's standard of living.\n\nThe diabetes data below is from the International Diabetes Federation, and the GDP\/Capita data is from the World Bank Group."}}