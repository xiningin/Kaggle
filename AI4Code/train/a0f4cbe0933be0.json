{"cell_type":{"9451f878":"code","762b8542":"code","af33c11a":"code","4b2fcb6b":"code","e6dc675e":"code","982a6559":"code","3f3f5d9d":"code","f5086a78":"code","06591798":"code","1ed0536c":"code","371c25d5":"code","88f2c0ea":"code","f6d932f0":"code","04f07db6":"code","7fcad380":"code","e98f0679":"code","4fb38c30":"code","f9857acc":"code","643f2101":"code","50a0d1b6":"code","92acedc7":"code","53426aec":"code","e4681c13":"code","0a684c9d":"code","3d89dc81":"code","90314541":"code","ec841548":"code","4d75aa5a":"code","dbf0729d":"code","9dcee58a":"code","206ff287":"code","29201e74":"code","0bf04106":"code","80100ee5":"code","cdd033b4":"code","9e2a49bf":"code","16518628":"code","703b79c0":"code","a75627e1":"code","7775dd72":"code","7bc782f9":"markdown","f06f9f13":"markdown","772f17e6":"markdown","3e2778e6":"markdown","c7833028":"markdown","31131194":"markdown","052b1d01":"markdown","e20167bc":"markdown","91b43387":"markdown","37b95936":"markdown","b4221553":"markdown","afee1c60":"markdown","610cbf1d":"markdown","0a8dde1e":"markdown","1d0d40b1":"markdown","91d6c4ae":"markdown","863562ee":"markdown","f4fa1c43":"markdown","56c91364":"markdown","f450dcd0":"markdown","06f30069":"markdown","6e606857":"markdown","1a76228f":"markdown","aecab7d3":"markdown","0fb18b8a":"markdown","5efe6182":"markdown"},"source":{"9451f878":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\ndata = pd.read_csv('\/kaggle\/input\/time-series-starter-dataset\/Month_Value_1.csv')\ndata.head()\ndata.dropna(inplace=True)\ndata","762b8542":"data.info()","af33c11a":"data['Period'].astype('datetime64[ns]')","4b2fcb6b":"data['Period'] = pd.to_datetime(data['Period'],format='%d.%m.%Y')","e6dc675e":"data.info()","982a6559":"data['year']=data['Period'].dt.year \ndata['month']=data['Period'].dt.month \ndata['day']=data['Period'].dt.day\n\ndata['dayofweek_num']=data['Period'].dt.dayofweek  \n\n\ndata.head(18)","3f3f5d9d":"import matplotlib.pyplot as plt\nplt.rcParams.update({'figure.figsize':(15,5)})\nimport seaborn as sns\n\n# plt.figure(figsize=(15,5))\n# sns.distplot(data['Sales_quantity'])\nplt.plot(data.Sales_quantity)","f5086a78":"data['rolling_mean'] = data.Sales_quantity.rolling( window=2).mean()\ndata['rolling_mean6'] = data.Sales_quantity.rolling( window=6).mean()\nplt.plot(data.Sales_quantity, label='original')\nplt.plot(data.rolling_mean, label = 'window =2')\nplt.plot(data.rolling_mean6, label = 'window =6')\nplt.legend(loc='best')\n","06591798":"data.head(17)","1ed0536c":"data.index = data.Period","371c25d5":"from statsmodels.tsa.stattools import adfuller\ndftest = adfuller(data.Sales_quantity, autolag='AIC')","88f2c0ea":"dftest","f6d932f0":"dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\nfor key,value in dftest[4].items():\n   dfoutput['Critical Value (%s)'%key] = value\nprint (dfoutput)","04f07db6":"data","7fcad380":"# To remove Trend\ndata['#Sales_quantity'] = data['Sales_quantity'] - data['Sales_quantity'].shift(1)\ndata['#Sales_quantity'].dropna(inplace=True)\ndata['#Sales_quantity'].dropna().plot()","e98f0679":"dftest = adfuller(data['#Sales_quantity'], autolag='AIC')\ndfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\nfor key,value in dftest[4].items():\n   dfoutput['Critical Value (%s)'%key] = np.round(value, 1)\nprint (dfoutput)\n\ndftest[1].round(4)","4fb38c30":"# To remove Seasonality\ndata['#Sales_quantity_sea'] = data['Sales_quantity'] - data['Sales_quantity'].shift(12)\ndata['#Sales_quantity_sea'].dropna(inplace=True)\ndata['#Sales_quantity_sea'].dropna().plot()","f9857acc":"dftest = adfuller(data['#Sales_quantity_sea'], autolag='AIC')\ndfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\nfor key,value in dftest[4].items():\n   dfoutput['Critical Value (%s)'%key] = value\nprint (dfoutput)","643f2101":"# Log Transformation\ndata['log'] = np.log(data.Sales_quantity)","50a0d1b6":"dftest = adfuller(data['log'], autolag='AIC')\ndfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\nfor key,value in dftest[4].items():\n   dfoutput['Critical Value (%s)'%key] = value\nprint (dfoutput)","92acedc7":"import statsmodels.api as sm\n# multiplicative\nres = sm.tsa.seasonal_decompose(data.Sales_quantity,period=12,model=\"multiplicative\")\n#plt.figure(figsize=(16,12))\nfig = res.plot()\n#fig.show()","53426aec":"res = sm.tsa.seasonal_decompose(data.Sales_quantity,period=12,model=\"additive\")\n#plt.figure(figsize=(16,12))\nfig = res.plot()\n#fig.show()","e4681c13":"import statsmodels.api as sm\nsm.graphics.tsa.plot_pacf(data['log'], lags=12, method='ols')\nplt.show()","0a684c9d":"#ACF and PACF plots:\nfrom statsmodels.tsa.stattools import acf, pacf\nlag_acf = acf(data['log'], nlags=12)\nlag_pacf = pacf(data['log'], nlags=12, method='ols')\n\n\nplt.plot(lag_pacf)\nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96\/np.sqrt(len(data['log'])),linestyle='--',color='gray')\nplt.axhline(y=1.96\/np.sqrt(len(data['log'])),linestyle='--',color='gray')\nplt.title('Partial Autocorrelation Function')","3d89dc81":"import statsmodels.api as sm\nsm.graphics.tsa.plot_acf(data['log'], lags=12)\nplt.show()","90314541":"\nplt.plot(lag_acf)\nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96\/np.sqrt(len(data['log'])),linestyle='--',color='gray')\nplt.axhline(y=1.96\/np.sqrt(len(data['log'])),linestyle='--',color='gray')\nplt.title('Autocorrelation Function')","ec841548":"from statsmodels.tsa.arima_model import ARIMA","4d75aa5a":"model = ARIMA(data['log'], order=(2,2, 2))  \nresults_AR = model.fit(disp=1)  \n","dbf0729d":"results_AR.fittedvalues","9dcee58a":"predictions_ARIMA_diff = pd.Series(results_AR.fittedvalues, copy=True)\npredictions_ARIMA_diff.head()\n(predictions_ARIMA_diff)","206ff287":"# predictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()\n# predictions_ARIMA_diff_cumsum.head()\n# (predictions_ARIMA_diff_cumsum)","29201e74":"predictions_ARIMA_log = pd.Series(data['log'].iloc[0], index=data.index)\npredictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum,fill_value=0)\npredictions_ARIMA_log.head(49)","0bf04106":"predictions_ARIMA = np.exp(predictions_ARIMA_log)\nplt.plot(data['Sales_quantity'])\nplt.plot(predictions_ARIMA)\nplt.title('RMSE: %.4f'% np.sqrt(sum((predictions_ARIMA-data['Sales_quantity'])**2)\/len(data['Sales_quantity'])))","80100ee5":"x = results_AR.forecast(steps=10)","cdd033b4":"x = np.exp(x[0])\nx","9e2a49bf":"rng = pd.date_range('2020-04-01', periods=10, freq='M')","16518628":"rng = pd.DataFrame(rng, columns=['Dates'])","703b79c0":"rng","a75627e1":"rng['future'] = x\nrng.index = rng.Dates","7775dd72":"plt.plot(data['Sales_quantity'], label='original')\nplt.plot(predictions_ARIMA, label='fitted Values')\nplt.plot(rng['future'], label='Future Values')\nplt.legend(loc='best')\n","7bc782f9":"# What Is Time Series?\n\n* Variable \u2014 anything that changes over time\n* Time periods \u2014 Can be daily, weekly, monthly, yearly etc\n* Variable Behaviour \u2014 Quantifiable value\n\n## Past Is Important\n**Most time series data is dependent on its past values. Recent past values are good indicators of a variable\u2019s behaviour.**\n\n#### Now let\u2019s consider the effect of Friday\u2019s price on Sunday\u2019s price\n![image.png](attachment:image.png)","f06f9f13":"## p \u2013 The lag value where the PACF chart crosses the upper confidence interval for the first time. If you notice closely, in this case p=2.","772f17e6":"# Linear Vs Non-Linear Time Series\n![image.png](attachment:image.png)","3e2778e6":"### Role Of Lag Operator\n**Lag operator enables models to quantify how past, present and future values are linked to each other.**\n\n\n**For example, let\u2019s assume we are recording London\u2019s daily temperature and want to build a model that forecasts temperature. There is higher probability that the temperature tomorrow will be similar to what it is today. It is unlikely to snow tomorrow if it is melting hot today.**","c7833028":"## Past data can be a good indicator of future data","31131194":"### Differencing\nIn this method, we compute the difference of consecutive terms in the series. Differencing is typically performed to get rid of the varying mean. Mathematically, differencing can be written as:\n\nyt\u2018 = yt \u2013 y(t-1)","052b1d01":"![image.png](attachment:image.png)","e20167bc":"## ARIMA is a very popular statistical method for time series forecasting. ARIMA stands for Auto-Regressive Integrated Moving Averages. ARIMA models work on the following assumptions \u2013\n\n### The data series is stationary, which means that the mean and variance should not vary with time. A series can be made stationary by using log transformation or differencing the series.\n#### The data provided as input must be a univariate series, since arima uses the past values to predict the future values.\n#### ARIMA has three components \u2013 AR (autoregressive term), I (differencing term) and MA (moving average term). Let us understand each of these components \u2013\n\n# AR term refers to the past values used for forecasting the next value. The AR term is defined by the parameter \u2018p\u2019 in arima. The value of \u2018p\u2019 is determined using the PACF plot.\n\n# MA term is used to defines number of past forecast errors used to predict the future values. The parameter \u2018q\u2019 in arima represents the MA term. ACF plot is used to identify the correct \u2018q\u2019 value.\n\n# Order of differencing  specifies the number of times the differencing operation is performed on series to make it stationary. Test like ADF and KPSS can be used to determine whether the series is stationary and help in identifying the d value.","91b43387":"# AR   PACF  'P'  value","37b95936":"### Auto Regressive (AR)\n### Auto Regressive (AR) model is a specific type of regression model where, the dependent variable depends on past values of itself.","b4221553":"## Moving Average (MA)\n#### Moving Average (MA) model works by analysing how wrong you were in predicting values for the previous time-periods to make a better estimate for the current time-period.","afee1c60":"## q \u2013 The lag value where the ACF chart crosses the upper confidence interval for the first time. If you notice closely, in this case p=2.","610cbf1d":"# Trend\n![image.png](attachment:image.png)","0a8dde1e":"#### Deterministic Vs Non-Deterministic Time Series\n**Time series can be deterministic or non-deterministic in nature.\nDeterministic time series always behave in an expected manner where as non-deterministic time series is stochastic or random in nature.**","1d0d40b1":"![image.png](attachment:image.png)","91d6c4ae":"# Basic Structure of ARIMA Model","863562ee":"## Rolling Window","f4fa1c43":"## If a time series mean, variance and covariance with past and future values do not change over time then the model is known to be covariance stationary.\n\n## What makes Time series Stationary\n\n1. Constant Mean\n2. Constant Variance\n3. Constant Covariance\n\n\nCovariance is calculated by multiplying Correlation of assets to the Standard Deviation of assets.","56c91364":"# Seasonality\n![image.png](attachment:image.png)","f450dcd0":"# If it is a time series you are to analyze, the traditional components are the trend, the seasonal component, the cyclical movement and the irregular component. If seasonality tends to be constant over time, the additive model is suggestive. If however the seasonality seems to increase with time then the multiplicative model is suggestive. Use addition or subtraction in an additive model where multiplication or division, respectively, is applicable in a multiplicative model. That is the difference.","06f30069":"# Autocorrelation\n\n#### Informally, autocorrelation is the similarity between observations as a function of the time lag between them.\n\n![image.png](attachment:image.png)\n\n\n### Above is an example of an autocorrelation plot. Looking closely, you realize that the first value and the 24th value have a high autocorrelation. Similarly, the 12th and 36th observations are highly correlated. This means that we will find a very similar value at every 24 unit of time.","6e606857":"# Predicting Time Series ? Predicting Future","1a76228f":"### ADF (Augmented Dickey Fuller) Test  ","aecab7d3":"![image.png](attachment:image.png)","0fb18b8a":"![image.png](attachment:image.png)","5efe6182":"# MA ACF 'Q' value"}}