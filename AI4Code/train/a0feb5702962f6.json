{"cell_type":{"b77d5664":"code","22d440ad":"code","9bd2b9f3":"code","c5f9269f":"code","511d3823":"code","7cb5062d":"code","acde2f5b":"code","f577b447":"markdown","f2470547":"markdown","80410eea":"markdown","06290c3d":"markdown"},"source":{"b77d5664":"#================================================================\n# K-Means Looper\n# DataRanch.info X Jarrett Devereaux\n#================================================================\n\n#%%\n#sklearn imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport os","22d440ad":"%matplotlib inline","9bd2b9f3":"#%%\n#Update csv here\ncsv_name = 'combined_upworkers.csv'\ndrop_col = 'ciphertext'","c5f9269f":"#%%\n#read in data + drop duplicates\ndf = pd.read_csv(f'\/kaggle\/input\/upworkers-2021\/{csv_name}', low_memory=False)\ndf = df.drop_duplicates(drop_col)","511d3823":"#%%\ndef complete_kmeans(optimal_clusters, X, col1, col2, csv_name):\n    kmeans = KMeans(n_clusters=optimal_clusters)\n    kmeans.fit(X)\n    y_kmeans = kmeans.predict(X)\n    plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n    centers = kmeans.cluster_centers_\n    plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)\n    plt.xlabel(col1)\n    plt.ylabel(col2)\n    plt.show()\n    #make a directory with csv_name if one doesn't exist\n    csv_name = csv_name.split('.')[0]\n    try:\n        os.mkdir(f'\/kaggle\/working\/data_pics')\n    except Exception as e:\n        pass\n    #output plt to file\n    #plt.savefig(f'data_pics\/{csv_name}_{col1}_{col2}_kmeans.png')\n    #clear plots for the next iteration in the loop\n    #plt.clf()\n    #plt.cla()\n    #plt.close()","7cb5062d":"#%%\n#function that takes in two column names and processes the columns for k-means\ndef produce_kmeans(df, col1, col2, csv_name):\n    df[col1] = df[col1].astype(float)\n    df[col2] = df[col2].astype(float)\n    df[col1] = df[col1].fillna(0)\n    df[col2] = df[col2].fillna(0)\n    x_list = df[col1]\n    y_list = df[col2]\n    zipped_list = list(zip(x_list, y_list))\n    X = np.array(zipped_list)\n    #scale data\n    scaler = StandardScaler()\n    X = scaler.fit_transform(X)\n\n    #Uncomment to use the elbow method\n    #K-Means elbow method to determine the optimal number of clusters\n    #================================================================\n    dist_df = []\n    for num_clusters in range(1, 11):\n        kmeans = KMeans(n_clusters=num_clusters)\n        kmeans.fit(X)\n        wcss = kmeans.inertia_\n        dist_df.append([num_clusters, wcss])\n    dist_df = pd.DataFrame(dist_df, columns=['num_clusters', 'wcss'])\n    dist_df.plot(x='num_clusters', y='wcss', kind='line')\n    plt.show()\n    #plt.scatter(x_list, y_list, s=50)\n    #plt.show()\n    #================================================================\n    \n    try:\n        #uncomment to edit the number of clusters you want to use\n        #================================================================\n        #optimal_clusters = int(input('How many clusters would you like?'))\n        #================================================================\n        optimal_clusters = 3\n    except:\n        optimal_clusters = 3\n    complete_kmeans(optimal_clusters, X, col1, col2, csv_name)","acde2f5b":"#%%\n# Driver (edit the column name here)\n#====================================================\n#run produce_kmeans on every column in df vs price\nfor col in df.columns:\n    try:\n        produce_kmeans(df, 'combinedTotalEarnings', col, csv_name)\n    except:\n        continue\n#====================================================","f577b447":"# **Standardize Data and Use Elbow Method**","f2470547":"The special column in this case is \"combinedTotalEarnings\". This will represented on the x-axis","80410eea":"# **Read data**","06290c3d":"# **K-Means Visualization on each column vs a pivot column**"}}