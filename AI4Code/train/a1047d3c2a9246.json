{"cell_type":{"b0baedc0":"code","578b43ac":"code","fd242664":"code","9dfd1cc6":"code","adeb9b3f":"code","ced00646":"code","fcc100d9":"code","7f367df7":"code","4e3fe0bf":"code","f3753a1d":"code","db2c9776":"code","6703a798":"code","9955235f":"code","aef7af42":"code","b2430a5a":"code","a132d763":"code","5d8e4b92":"code","053625be":"code","efc48674":"code","663330bc":"code","735c08f2":"code","01b4958f":"code","1eee4d39":"code","c0ddf1a8":"code","73dff310":"code","55217486":"code","f04df5dd":"code","9e01a68b":"code","e15e09fa":"code","d494137f":"code","faaa9a40":"code","98c03345":"code","fee75d75":"code","1c3819f5":"code","71613112":"code","e6b85c7d":"code","362304a1":"code","ae35f04f":"markdown","8e6ce6b0":"markdown","c9098747":"markdown","0cb68133":"markdown","34b98571":"markdown","cef7d142":"markdown","15049562":"markdown","71d8b4ee":"markdown","fcef6c49":"markdown","0acf06e6":"markdown","168e63f1":"markdown","5d59e525":"markdown","dacb9b8d":"markdown","f4efe1d5":"markdown","8efaef1f":"markdown","533ada68":"markdown","71bdd54b":"markdown"},"source":{"b0baedc0":"import numpy as np\nimport pandas as pd\nimport os\nimport zipfile\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nimport time\nfrom IPython.display import Image","578b43ac":"from torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as T","fd242664":"image_size = 64\nbatch_size = 128\nstats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)","9dfd1cc6":"train_ds = ImageFolder(IMG_DIR, transform = T.Compose([\n    T.Resize(image_size),\n    T.CenterCrop(image_size),\n    T.ToTensor(),\n    T.Normalize(*stats)\n]))\n\ntrain_dl = DataLoader(train_ds, batch_size, shuffle = True, num_workers = 3, pin_memory = True)","adeb9b3f":"train_ds","ced00646":"import torch\nfrom torchvision.utils import make_grid","fcc100d9":"# denormalize\ndef denormalize(img_tensors):\n    return img_tensors * stats[1][0] + stats[0][0]\n\n# to show the images\ndef show_images(images, n_max = 64):\n    fig, ax = plt.subplots(figsize = (12,8))\n    ax.set_xticks([]); ax.set_yticks([])\n    ax.imshow(make_grid(denormalize(images.detach()[:n_max]), nrow = 8).permute(1,2,0))\n    \ndef show_batch(dl, n_max = 64):\n    for images, _ in dl:\n        show_images(images,n_max)\n        break","7f367df7":"show_batch(train_dl)","4e3fe0bf":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","f3753a1d":"device = get_default_device()\ndevice","db2c9776":"train_dl = DeviceDataLoader(train_dl,device)","6703a798":"import torch.nn as nn\nimport torch.nn.functional as F","9955235f":"discriminator = nn.Sequential(\n    # in 3*64*64\n    nn.Conv2d(3,64, kernel_size = 4, stride = 2, padding = 1, bias = False),\n    nn.BatchNorm2d(64),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out 64*32*32\n    \n    nn.Conv2d(64,128, kernel_size = 4, stride = 2, padding = 1, bias = False),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out 128*16*16\n    \n    nn.Conv2d(128,256, kernel_size = 4, stride = 2, padding = 1, bias = False),\n    nn.BatchNorm2d(256),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out 256*8*8\n    \n    nn.Conv2d(256,512, kernel_size = 4, stride = 2, padding = 1, bias = False),\n    nn.BatchNorm2d(512),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out 512*4*4\n    \n    nn.Conv2d(512, 1, kernel_size = 4, stride = 1, padding = 0, bias = False),\n    # 1*1*1\n    \n    nn.Flatten(),\n    nn.Sigmoid()\n)\n\ndiscriminator","aef7af42":"discriminator = to_device(discriminator, device)","b2430a5a":"latent_size = 128\n\ngenerator = nn.Sequential(\n    # in latent_size*1*1\n    nn.ConvTranspose2d(latent_size, 512, kernel_size = 4, stride = 1, padding = 0, bias = False),\n    nn.BatchNorm2d(512),\n    nn.ReLU(True),\n    # 512*4*4\n    \n    nn.ConvTranspose2d(512, 256, kernel_size = 4, stride = 2, padding = 1, bias = False),\n    nn.BatchNorm2d(256),\n    nn.ReLU(True),\n    # 256*8*8\n    \n    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.ReLU(True),\n    # out: 128 x 16 x 16\n\n    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(64),\n    nn.ReLU(True),\n    # out: 64 x 32 x 32\n\n    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.Tanh()\n    # out: 3 x 64 x 64\n)\n\ngenerator","a132d763":"xb = torch.randn(batch_size, latent_size, 1, 1) # random latent tensors\nfake_images = generator(xb)\nprint(fake_images.shape)\nshow_images(fake_images)","5d8e4b92":"generator = to_device(generator,device)","053625be":"def train_discriminator(real_images, opt_d):\n    # clear discrimimnator gradients\n    opt_d.zero_grad()\n    \n    # pass real images through discriminator\n    real_preds = discriminator(real_images)\n    real_targets = torch.ones(real_images.size(0), 1, device = device)\n    real_loss = F.binary_cross_entropy(real_preds, real_targets)\n    real_score = torch.mean(real_preds).item()\n    \n    # generate fake images\n    latent = torch.randn(batch_size, latent_size, 1, 1, device = device)\n    fake_images = generator(latent)\n    \n    # passing fake images through discriminator\n    fake_targets = torch.zeros(fake_images.size(0), 1, device = device)\n    fake_preds = discriminator(fake_images)\n    fake_loss = F.binary_cross_entropy(fake_preds,fake_targets)\n    fake_score = torch.mean(fake_preds).item()\n    \n    # update discriminator weights\n    loss = real_loss + fake_loss\n    loss.backward()\n    opt_d.step()\n    \n    return loss.item(), real_score, fake_score","efc48674":"def train_generator(opt_g):\n    # clear generator gradients\n    opt_g.zero_grad()\n    \n    # generate fake images\n    latent = torch.randn(batch_size, latent_size, 1, 1, device = device)\n    fake_images = generator(latent)\n    \n    # try to fool the discriminator\n    preds = discriminator(fake_images)\n    targets = torch.ones(batch_size, 1, device = device)\n    loss = F.binary_cross_entropy(preds, targets)\n    \n    # update generator weights\n    loss.backward()\n    opt_g.step()\n    \n    return loss.item()","663330bc":"!mkdir Generated\nsample_dir = \".\/Generated\"","735c08f2":"from torchvision.utils import save_image","01b4958f":"def save_samples(index, latent_tensors, show = True):\n    fake_images = generator(latent_tensors)\n    fake_fname = \"gen-image-{0:0=4d}.jpg\".format(index)\n    save_image(denormalize(fake_images), os.path.join(sample_dir, fake_fname), nrow = 8)\n    print('Saving .. ', fake_fname)\n    \n    if show:\n        fig,ax = plt.subplots(figsize = (8,8))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(fake_images.cpu().detach(), nrow = 8).permute(1,2,0))","1eee4d39":"fixed_latent = torch.randn(64, latent_size, 1,1, device = device)","c0ddf1a8":"save_samples(0,fixed_latent)","73dff310":"from tqdm.notebook import tqdm\nimport torch.nn.functional as F","55217486":"def fit(epochs, lr, start_index = 1):\n    torch.cuda.empty_cache()\n    \n    # losses and scores\n    losses_g = []\n    losses_d = []\n    real_scores = []\n    fake_scores = []\n    \n    # create optimizers\n    opt_d = torch.optim.Adam(discriminator.parameters(), lr = lr, betas = (0.5, 0.999))\n    opt_g = torch.optim.Adam(generator.parameters(), lr = lr, betas = (0.5, 0.999))\n    \n    for epoch in range(epochs):\n        for real_images, _ in tqdm(train_dl):\n            \n            # train discriminator\n            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n            \n            # train generator\n            loss_g = train_generator(opt_g)\n            \n        # record losses and scores\n        losses_g.append(loss_g)\n        losses_d.append(loss_d)\n        real_scores.append(real_score)\n        fake_scores.append(fake_score)\n        \n        # log losses and score (last batch)\n        print(f\"Epoch [{epoch+1}\/{epochs}], loss_g : {loss_g:.4f}, loss_d : {loss_d:.4f}, real_score : {real_score:.4f}, fake_score : {fake_score:.4f}\")\n        \n        # save generated images\n        save_samples(epoch+start_index, fixed_latent, show = False)\n        \n    return losses_g, losses_d, real_scores, fake_scores","f04df5dd":"lr = 0.0002\nepochs = 25","9e01a68b":"start = time.time()\n\nhistory = fit(epochs, lr)\n\nend = time.time()\n\nprint(f\"Finished in {(end-start):.4f} seconds.\")","e15e09fa":"losses_g, losses_d, real_scores, fake_scores = history","d494137f":"# Save the model checkpoints \ntorch.save(generator.state_dict(), 'G.pth')\ntorch.save(discriminator.state_dict(), 'D.pth')","faaa9a40":"# Image 2\nImage(\".\/Generated\/gen-image-0002.jpg\")","98c03345":"# Image 8\nImage(\".\/Generated\/gen-image-0015.jpg\")","fee75d75":"# Image 20\nImage(\".\/Generated\/gen-image-0020.jpg\")","1c3819f5":"# Image 25\nImage(\".\/Generated\/gen-image-0025.jpg\")\n","71613112":"# saving the progress to a video\n\nvid_fname = 'gans_training.avi'\n\nfiles = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'gen' in f]\nfiles.sort()\n\nout = cv.VideoWriter(vid_fname,cv.VideoWriter_fourcc(*'MP4V'), 1, (530,530))\n[out.write(cv.imread(fname)) for fname in files]\nout.release()","e6b85c7d":"plt.plot(losses_d, '-')\nplt.plot(losses_g, '-')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['Discriminator', 'Generator'])\nplt.title('Losses');","362304a1":"plt.plot(real_scores, '-')\nplt.plot(fake_scores, '-')\nplt.xlabel('epoch')\nplt.ylabel('score')\nplt.legend(['Real', 'Fake'])\nplt.title('Scores');","ae35f04f":"## 7.Generator Training","8e6ce6b0":"## 0.Libraries","c9098747":"## 2.Show a batch of images","0cb68133":"# Generative Adverserial Networks\n\nDeep neural networks are used mainly for supervised learning: classification or regression. Generative Adverserial Networks or GANs, however, use neural networks for a very different purpose: Generative modeling\n\nWhile there are many approaches used for generative modeling, a Generative Adverserial Network takes the following approach: \n\n![GAN Flowchart](https:\/\/i.imgur.com\/6NMdO9u.png)","34b98571":"## 8.Full Training Loop","cef7d142":"### References\n- Gif at https:\/\/www.kaggle.com\/anshalsingh\/gif-gan-anime-face-dataste?select=improvement.gif\n- https:\/\/jovian.ai\/learn\/deep-learning-with-pytorch-zero-to-gans","15049562":"\n\n<img src=\"https:\/\/i.imgur.com\/6NMdO9u.png\" style=\"max-width:420px; margin-bottom:32px\"\/>\n\n","71d8b4ee":"## 1.Image Loader and Transforms","fcef6c49":"### **Train the model.**","0acf06e6":"### Discriminator Network\n\nThe discriminator takes an image as input, and tries to classify it as \"real\" or \"generated\". In this sense, it's like any other neural network. We'll use a convolutional neural networks (CNN) which outputs a single number output for every image. We'll use stride of 2 to progressively reduce the size of the output feature map.\n\n![](https:\/\/github.com\/vdumoulin\/conv_arithmetic\/raw\/master\/gif\/padding_strides_odd.gif)","168e63f1":"## 9.Result Visualizations","5d59e525":"### Generator Network\n\nThe input to the generator is typically a vector or a matrix of random numbers (referred to as a latent tensor) which is used as a seed for generating an image. The generator will convert a latent tensor of shape `(128, 1, 1)` into an image tensor of shape `3 x 28 x 28`. To achive this, we'll use the `ConvTranspose2d` layer from PyTorch, which is performs to as a *transposed convolution* (also referred to as a *deconvolution*). [Learn more](https:\/\/github.com\/vdumoulin\/conv_arithmetic\/blob\/master\/README.md#transposed-convolution-animations)\n\n![](https:\/\/i.imgur.com\/DRvK546.gif)","dacb9b8d":"## 3.Using a GPU","f4efe1d5":"## 4.Discriminator Network","8efaef1f":"- **Let's create a directory to store generated images.**","533ada68":"## 6.Discriminator Training","71bdd54b":"## 5.Generator Network"}}