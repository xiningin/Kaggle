{"cell_type":{"6f330e2a":"code","6301c22b":"code","6345e2e5":"code","abe3e1e7":"code","f0e93758":"code","1307c1b2":"code","ef1287b2":"code","fa9517b6":"code","4017679a":"code","70dc4178":"code","074ae704":"code","aa47656b":"code","047a5fd8":"code","e72dba38":"code","a2b44d89":"code","d05554ba":"code","25bdf631":"markdown","c47fb6ad":"markdown","c1b285b9":"markdown","8d7f4670":"markdown","3b514abe":"markdown","f6f23225":"markdown","7c2f6eae":"markdown","4a40e6ce":"markdown","fd5d5bd4":"markdown","7df3778c":"markdown","c4a1229b":"markdown","fd8bcff5":"markdown","5e55ecdd":"markdown","6f9bb50b":"markdown","315e9248":"markdown","15e7dbee":"markdown","4a5e547b":"markdown","da329582":"markdown"},"source":{"6f330e2a":"%%capture\n# pywaffle for pictograms\n!pip install pywaffle","6301c22b":"%%capture\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n\nfrom pywaffle import Waffle\n\nimport plotly.graph_objects as go\nimport plotly.graph_objs as gobj\nimport plotly\nimport plotly.express as px\nimport plotly.io as pio\nfrom plotly.subplots import make_subplots\n\npio.templates.default = \"ggplot2\"\n\npd.options.display.max_columns=999\npd.options.display.max_rows=50\npd.options.display.max_colwidth = 500\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6345e2e5":"maindf = pd.read_csv('\/kaggle\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv', low_memory=False)","abe3e1e7":"### DATA PREPROCESSING IN THIS CELL\n\n# Group genders under one umbrella to lower cardinality.\nmaindf.loc[maindf['Q2'].isin(['Prefer to self-describe','Nonbinary']),'Q2'] = 'Other'\n\n# Shorten answers where possible to prevent overlapping tick labels.\nmaindf.loc[maindf['Q3']=='United Kingdom of Great Britain and Northern Ireland','Q3'] = 'UK'\nmaindf.loc[maindf['Q3']=='United States of America','Q3'] = 'USA'\nmaindf.loc[maindf['Q3']=='Iran, Islamic Republic of...','Q3'] = 'Iran'\nmaindf.loc[maindf['Q3']=='United Arab Emirates','Q3'] = 'UAE'\nmaindf.loc[maindf['Q3']=='Republic of Korea','Q3'] = 'South Korea'\n\n# Shorten answers where possible to prevent overlapping tick labels. Group certain education levels to lower cardinality.\nmaindf.loc[maindf['Q4']=='Some college\/university study without earning a bachelor\u2019s degree','Q4'] = 'Other'\nmaindf.loc[maindf['Q4']=='No formal education past high school','Q4'] = 'Other'\nmaindf.loc[maindf['Q4']=='I prefer not to answer','Q4'] = 'No Answer Provided'\nmaindf.loc[maindf['Q4']=='Professional degree','Q4'] = 'Other'\nmaindf.loc[maindf['Q4']=='Doctoral degree','Q4'] = 'Doctoral'\nmaindf.loc[maindf['Q4']==\"Bachelor\u2019s degree\",'Q4'] = 'Bachelor\u2019s'\nmaindf.loc[maindf['Q4']==\"Master\u2019s degree\",'Q4'] = 'Master\u2019s'\n\n# Shorten answers where possible to prevent overlapping tick labels. Reformatting to wrap long names.\nmaindf.loc[maindf['Q5']=='Data Analyst','Q5'] = 'Data\/Biz.<br>Analyst'\nmaindf.loc[maindf['Q5']=='Business Analyst','Q5'] = 'Data\/Biz.<br>Analyst'\nmaindf.loc[maindf['Q5']=='Software Engineer','Q5'] = 'Software<br>Engineer'\nmaindf.loc[maindf['Q5']=='Data Engineer','Q5'] = 'Data<br>Engineer'\nmaindf.loc[maindf['Q5']=='DBA\/Database Engineer','Q5'] = 'Data<br>Engineer'\nmaindf.loc[maindf['Q5']=='Machine Learning Engineer','Q5'] = 'ML<br>Engineer'\nmaindf.loc[maindf['Q5']=='Research Scientist','Q5'] = 'Research<br>Scientist'\nmaindf.loc[maindf['Q5']=='Data Scientist','Q5'] = 'Data<br>Scientist'\nmaindf.loc[maindf['Q5']=='Product\/Project Manager','Q5'] = 'Product\/Project<br>Manager'\n\n# Establish a new column to identify employment status. \nmaindf['Employment'] = maindf['Q5']\nmaindf.loc[~maindf['Q5'].isin(['Student','Currently not employed']),['Employment']] = 'Employed'\nmaindf.loc[maindf['Employment']=='Currently not employed','Employment'] = 'Not employed'\n\n# Shorten answers where possible to prevent overlapping tick labels. Group certain answers to lower cardinality.\nmaindf.loc[maindf['Q15']=='I do not use machine learning methods','Q15'] = 'I don\\'t use ML'\nmaindf.loc[maindf['Q15']=='Under 1 year','Q15'] = '< 1 years'\nmaindf.loc[maindf['Q15']=='5-10 years','Q15'] = '5+ years'\nmaindf.loc[maindf['Q15']=='10-20 years','Q15'] = '5+ years'\nmaindf.loc[maindf['Q15']=='20 or more years','Q15'] = '5+ years'\n\n# Shorten answers where possible to prevent overlapping tick labels. Group certain answers to lower cardinality.\nmaindf.loc[maindf['Q6']=='I have never written code','Q6'] = 'No coding<br>experience'\nmaindf.loc[maindf['Q6']=='10-20 years','Q6'] = '10+ years'\nmaindf.loc[maindf['Q6']=='20+ years','Q6'] = '10+ years'\n\n\n# only interested in these titles\nselect_titles = [\n    'Data<br>Scientist',\n    'Research<br>Scientist',\n    'ML<br>Engineer', \n    'Data<br>Engineer', \n    'Data\/Biz.<br>Analyst',\n    'Statistician'\n]\n\n\n# Filter to keep only relevant titles' answers\nmaindf[1:] = maindf[1:][maindf['Q5'].isin(select_titles)]","f0e93758":"colorlist = px.colors.qualitative.Vivid\ntitlecolor=\"#0D2A63\"\nmcolor1 = colorlist[6] # yellow\nmcolor2 = colorlist[5] # green\nmcolor3 = colorlist[7] # turq\n\ntick_font = dict(dict(size=14,family='Soleil'))\ntitle_font = dict(dict(size=20,color=titlecolor,family='Poynter Gothic Text'))\nannot_font = dict(dict(size=14, family='Soleil',color=\"#0D2A63\"))","1307c1b2":"# Extract all the answers except missing records\nvizdata=maindf.loc[1:, \"Q1\"].dropna()\n\n# Obtain percentage of each answer\npercentages = vizdata.value_counts(normalize=True).sort_index()\n# Obtain raw counts of each answer\ncounts = vizdata.value_counts(normalize=False).sort_index()\n\n# Combine all into one df\nvizdata = pd.DataFrame(\n    np.hstack([percentages.values.reshape(-1, 1), counts.values.reshape(-1, 1)]),\n    index=percentages.index,\n    columns=[\"Percent\", \"Count\"],\n).reset_index()\n\nfig = px.bar(vizdata, x=\"index\", y=\"Count\", text=\"Percent\",range_y=[0,2200])\n\n# Create color list so that multiple colors are used for emphasis \ncolors = [colorlist[10],]*11\ncolors[:4] = [colorlist[5]]*4\n\nfig.update_traces(\n    hovertemplate=\"Age: %{x}<br>Count: %{y:,.0f}\",\n    marker_color=colors,\n    marker_opacity=0.8,\n    texttemplate=\"%{text:.0%}\",\n    textposition='inside'\n)\n\nfig.update_layout(\n    xaxis=dict(\n        showgrid=False,\n        title_text=\"Age Groups\", \n        tickfont=tick_font\n    ),\n    yaxis=dict(\n        showticklabels=True,\n        title_text=\"Number of Respondents\"),\n    hoverlabel=dict(\n        bgcolor=\"white\",\n        font_size=14,\n    ),\n    margin=dict(pad=5),\n    height=500,\n    width=800,\n    title=dict(\n        text=\"Age Distribution of Data Science Professionals\",\n        y=1,\n        x=0,\n        xref=\"paper\",\n        xanchor= 'left',\n        yanchor= 'top',\n        font=title_font\n))\n# line that separates first 4 bars and the rest\nfig.add_shape(\n    type=\"line\",\n    y0=0, x0=3.5, \n    y1=1, x1=3.5,\n    xref='x',\n    yref='paper',\n    line=dict(\n        color=\"black\",\n        width=1,\n        dash=\"dashdot\",\n    ))\n\n# vertical gray rectangle to highlight first 4 bars\nfig.add_vrect(\n    x0=-0.5, x1=3.5,\n    y0=0,y1=1,\n    fillcolor=\"darkgray\", opacity=0.2,\n    layer=\"below\", line_width=0,\n),\n\n# Annotation to highlight percent of top 4\nfig.add_annotation(\n    y=2100,\n    x=3,\n    xref='x',yref='y',\n    text='<i>\u224563% are below 35 yrs old<\/i>',\n    textangle=0,\n    showarrow=True,\n    arrowhead=7,\n    arrowsize=1,\n    arrowwidth=1.5,\n    ax=150,\n    ay=-10,\n    font=annot_font,\n)\n\nfig.show()","ef1287b2":"vizdata = maindf.loc[1:, \"Q3\"].dropna()\n\npercentages = vizdata.value_counts(normalize=True).sort_values()\ncounts = vizdata.value_counts(normalize=False).sort_values()\n\nvizdata = pd.DataFrame(\n    np.hstack([percentages.values.reshape(-1, 1), counts.values.reshape(-1, 1)]),\n    index=percentages.index,\n    columns=[\"Percent\", \"Count\"],\n).reset_index()\n\nvizdata = vizdata[vizdata['index']!='Other'].tail(10)\n\n# Obtain list of top 10 countries to be used in the following cell\ntop10list = vizdata['index']\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Bar(\n        x=vizdata[\"Count\"], \n        y=vizdata[\"index\"],\n        text=vizdata[\"Percent\"],\n        orientation=\"h\",name=''))\n\ncolors = [colorlist[10],]*10\ncolors[-2:] = [colorlist[5]]*2\n\nfig.update_traces(\n    hovertemplate=\"Country: %{y}<br>Count: %{x:,.0f}\",\n    marker_color=colors,\n    marker_opacity=0.8,\n    texttemplate=\"%{text:.0%}\",\n    textposition='inside'\n)\n\nfig.update_layout(\n    xaxis=dict(\n        showticklabels=True,\n        showgrid=True,\n        title=\"Number of Respondents\"\n    ),\n    yaxis=dict(\n        showgrid=False,\n        tickfont=tick_font,\n        title=\"Country of Residence\"\n        \n    ),    \n    hoverlabel=dict(\n        bgcolor=\"white\",\n        font_size=14,\n    ),\n    margin=dict(pad=5),\n    height=600,\n    width=800,\n    title=dict(\n        text='10 Countries with the Most Data Science Professionals',\n        y=0.94,\n        x=0,\n        xref=\"paper\",\n        xanchor= 'left',\n        yanchor= 'top',\n        font=title_font                  \n    )\n)\n\nfig.add_shape(\n    type=\"line\",\n    y0=0.8, x0=0, \n    y1=0.8, x1=1,\n    xref='paper',\n    yref='paper',\n    line=dict(\n        color=\"black\",\n        width=1,\n        dash=\"dashdot\",\n    ))\n\nfig.add_vrect(\n    x0=0, x1=1800,\n    y0=0.8,y1=1,\n    xref='paper',\n    yref='paper',\n    fillcolor=\"darkgray\", opacity=0.2,\n    layer=\"below\", line_width=0,\n),\n\n\nfig.add_annotation(\n    y=0.85,\n    x=0.8,\n    xref='paper',yref='paper',\n    text='<i>34% reside in India and the US<\/i>',\n    textangle=0,\n    showarrow=True,\n    arrowhead=7,\n    arrowsize=1,\n    arrowwidth=1.5,\n    ax=10,\n    ay=50,\n    font=annot_font,\n)\n\n\n\n\nfig.show()","fa9517b6":"vizdata = maindf.loc[1:, [\"Q2\"]].dropna()\n\nvizdata = pd.DataFrame(vizdata.value_counts(normalize=True)).reset_index()\n\n# Create a dict of labels and values(percents) as Pywaffle uses dict as input\nvizdata_dict = dict(zip(vizdata['Q2'],vizdata[0]*100))\n\n# Create value labels to rounded percentages that are consistent (unlike how Pywaffe rounds them up - sometimes sum of all exceed 100%)\nlabels = ['{} {:.1f}%'.format(k, v) for k, v in vizdata_dict.items()]\n\nfig = plt.figure(\n    FigureClass=Waffle,\n    rows=6,\n    title=dict(label='Overall Gender Distribution of DS Professionals',loc='left',size=4.5, color=titlecolor),\n    figsize=(3,2),\n    values=vizdata_dict,\n    labels=labels,\n    legend = {\n        'loc': 'lower left',\n        'bbox_to_anchor': (0, -0.4),\n        'ncol': 4,\n        'framealpha': 0,\n        'fontsize': 3.5\n    },\n    icons='user', \n    icon_size=7,\n    icon_legend=True,\n    dpi=250,\n    block_arranging_style='new-line',\n    interval_ratio_y=0.1,\n)\n\nfig.show()","4017679a":"vizdata = maindf.loc[1:,[\"Q2\", \"Q3\"]].dropna()\n\ncountry_sum = vizdata.groupby([\"Q3\"]).size()\nvizdata = vizdata.groupby([\"Q2\", \"Q3\"], as_index=False).size()\n\nvizdata[\"Country Sum\"] = vizdata[\"Q3\"].map(country_sum)\nvizdata[\"Percent\"] = vizdata[\"size\"] \/ vizdata[\"Country Sum\"]\n\nvizdata = vizdata[vizdata['Q3']!='Other']\n\n# Sort countries by rate of male respondents, ascending\nsort_cats = (\n    vizdata.loc[vizdata[\"Q2\"] == \"Man\"]\n    .sort_values(by=[\"Percent\"])[\"Q3\"]\n    .values\n)[::-1]\n\nfig = go.Figure(\n    px.bar(\n        data_frame=vizdata,\n        x=\"Percent\",\n        y=\"Q3\",\n        text='Percent',\n        color=\"Q2\",\n        orientation=\"h\",\n        color_discrete_sequence=[colorlist[5],colorlist[0],colorlist[10],colorlist[9]]\n    )\n)\n\nfig.update_traces(\n    hovertemplate=\"%{y}<br>%{x:.0%}\",\n    texttemplate='%{text:.0%}',\n    marker_opacity=0.7\n)\n\nfig.update_layout(\n    margin=dict(pad=5, t=80),\n    legend=dict(\n        bgcolor=\"rgba(0,0,0,0)\",\n        orientation=\"h\",\n        title_text=\"\",\n        font=dict(size=12,color=\"#0D2A63\"),\n        yanchor=\"bottom\",\n        y=1,\n        xanchor=\"left\",\n        x=0,\n    ),\n    hoverlabel=dict(\n        bgcolor=\"white\",\n        font_size=14,\n    ),\n    height=1800,\n    width=800,\n    xaxis=dict(visible=False),\n    yaxis=dict(\n        categoryorder= \"array\", \n        categoryarray= sort_cats,\n        tickfont=tick_font, \n        tickmode=\"linear\", \n        title=\"\"),\n    title=dict(\n        text='Gender-Diversity by Country',\n        y=0.99,\n        x=0,\n        xref=\"paper\",\n        xanchor= 'left',\n        yanchor= 'top',\n        font=title_font                \n    )\n)\n\nfig.show()","70dc4178":"vizdata = maindf[maindf['Q4']!='No Answer Provided'].loc[1:, \"Q4\"].dropna()\n\norder_ = ['Doctoral','Master\u2019s','Bachelor\u2019s','Other']\nvizdata = vizdata.value_counts(normalize=True).reindex(order_).reset_index()\n\nvizdata_dict = dict(zip(vizdata['index'],vizdata['Q4']*100))\nlabels = ['{} {:.1f}%'.format(k, v) for k, v in vizdata_dict.items()]\n\nfig = plt.figure(\n    FigureClass=Waffle,\n    rows=6,\n    title=dict(label='Educational Backgrounds of Data Scientists',loc='left',size=5, color=titlecolor),\n    figsize=(3,2),\n    values=vizdata_dict,\n    labels=labels,\n    legend = {\n        'loc': 'lower left',\n        'bbox_to_anchor': (0, -0.4),\n        'ncol': 4,\n        'framealpha': 0,\n        'fontsize': 3.5\n    },\n    icons=['university','university','university','laptop-code'],\n    icon_size=7, \n    icon_legend=True,\n    dpi=250,\n    block_arranging_style='new-line',\n    interval_ratio_y=0.1,\n)\n\nfig.show()","074ae704":"colrange = list(range(110, 118))\nvizdata = maindf.iloc[1:, colrange].dropna(how=\"all\")\n\n# trim out the unneccessary part of the answers \nvizdata.columns = maindf.iloc[0, colrange].apply(lambda x: x.split(\"-\")[-1].strip()).values\n\n# reduce the length of the answers to prevent overlapping labels\nvizdata.rename(\n    columns={\n        \"Analyze and understand data to influence product or business decisions\": \n        \"Analyze data for<br>business decisions\",\n        \n        \"Build and\/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data\": \n        \"Manage business<br>data infrastructure\",\n        \n        \"Build prototypes to explore applying machine learning to new areas\": \n        \"Prototype ML to<br>apply to new areas\",\n        \n        \"Build and\/or run a machine learning service that operationally improves my product or workflows\": \n        \"Manage ML for<br>product\/business\",\n        \n        \"Experimentation and iteration to improve existing ML models\": \n        \"Improve existing<br>ML models\",\n        \n        \"Do research that advances the state of the art of machine learning\": \n        \"Research to<br>advance state of<br>the art of ML\",\n        \n        \"None of these activities are an important part of my role at work\": \n        \"None of these\",\n    },\n    inplace=True,\n)\n\n# omit \"Other\" and \"None of these\" answers as they don't provie any insight for this question\nvizdata = vizdata.drop(columns=['Other','None of these']).notna()\n\n# add title column\nvizdata[\"Title\"] = maindf.loc[vizdata.index, \"Q5\"]\n\ntitles_size = vizdata.groupby([\"Title\"]).size()\nvizdata = vizdata.groupby(\"Title\").sum()\nvizdata = vizdata.stack().reset_index()\nvizdata[\"Title Size\"] = vizdata[\"Title\"].map(titles_size)\nvizdata[\"Percent\"] = round(vizdata[0] \/ vizdata[\"Title Size\"], 2)\n\n# marker and text colors to highlight the largest percentage of each group\nmcolors = [[colorlist[10]]*vizdata['level_1'].nunique() for _ in range(len(select_titles))]\ntcolors = [[\"rgb(136,136,136)\"]*vizdata['level_1'].nunique() for _ in range(len(select_titles))]\n\nfig = make_subplots(cols=len(select_titles), rows=1, vertical_spacing=0.01,shared_yaxes=True)\n\nfor n, jobtitle in enumerate(select_titles):\n    subset_data = vizdata[vizdata['Title']==jobtitle].reset_index(drop=True)\n    indexmax = subset_data['Percent'].idxmax()\n    mcolors[n][indexmax] = colorlist[5]\n    tcolors[n][indexmax] = \"black\"\n    fig.append_trace(trace=go.Bar(\n        name=jobtitle,\n        y=subset_data[\"level_1\"],\n        x=subset_data[\"Percent\"],\n        text=subset_data[\"Percent\"], \n        orientation='h',\n        hoverinfo=\"skip\",\n        textposition='outside',\n        texttemplate=\"%{text:.0%}\",\n        textfont_color=tcolors[n],\n        marker_color=mcolors[n],\n        marker_opacity=0.8),\n                     col=n+1,row=1)\n    fig.add_annotation(dict(\n        x=0.5,y=5.8,\n        showarrow=False,\n        font=tick_font,\n        text=jobtitle,\n        xref=f\"x{n+1}\",\n        yref=f\"y{n+1}\"\n    ))\n\n\nfig.update_xaxes(\n    range = [0,2.5],\n    visible=False\n)\n\nfig.update_yaxes(\n    tickfont=tick_font,\n    ticklen=0,\n    showgrid=False,\n    title=\"\",\n)\n\n\nfig.update_layout(\n    paper_bgcolor='#EDEDED',\n    plot_bgcolor='#EDEDED',\n    margin=dict(pad=10),\n    showlegend=False,\n    height=700,\n    width=700,\n    title=dict(\n        text=\"Regular Work Activities per Job Title\",\n        y=0.95,\n        x=0,\n        xref=\"paper\",\n        xanchor= 'left',\n        yanchor= 'top', \n        font=title_font),  \n    hoverlabel=dict(\n        bgcolor=\"white\",\n        font_size=14,\n    ),\n)\n\nfor i in range(5):\n    fig.add_shape(type=\"line\",\n        x0=-0.2, y0=0.5+i, x1=1, y1=0.5+i,\n        xref = 'paper',\n        line=dict(\n            color=\"black\",\n            width=0.8,\n            dash=\"dot\",\n        )\n    )\n\nfig.show()","aa47656b":"vizdata = maindf.loc[1:, [\"Q5\",\"Q6\"]].dropna()\n\ntitlesize = vizdata.groupby('Q5').size()\ntitle_exp_size = vizdata.groupby(by=['Q5','Q6']).size()\n\nvizdata = vizdata.drop_duplicates(inplace=False).copy()\n\nvizdata['TitleSize'] = vizdata.set_index('Q5').index.map(titlesize)\nvizdata['TitleExpSize'] = vizdata.set_index(['Q5','Q6']).index.map(title_exp_size)\nvizdata['Percent'] = vizdata['TitleExpSize']\/vizdata['TitleSize']\n\nsort_exp=[\n    \"No coding<br>experience\",\n    '< 1 years',\n    '1-2 years',\n    '3-5 years',\n    '5-10 years',\n    '10+ years'\n]\n\nmcolors = [[colorlist[10]]*vizdata['Q6'].nunique() for _ in range(len(select_titles))]\ntcolors = [[\"rgb(136,136,136)\"]*vizdata['Q6'].nunique() for _ in range(len(select_titles))]\n\nfig = make_subplots(cols=len(select_titles), rows=1, vertical_spacing=0.01,shared_yaxes=True)\n\nfor n, jobtitle in enumerate(select_titles):\n    subset_data = vizdata[vizdata['Q5']==jobtitle].reset_index(drop=True)\n    indexmax = subset_data['Percent'].idxmax()\n    mcolors[n][indexmax] = colorlist[5]\n    tcolors[n][indexmax] = \"black\"\n    fig.append_trace(trace=go.Bar(\n        name=jobtitle,\n        y=subset_data[\"Q6\"],\n        x=subset_data[\"Percent\"],\n        text=subset_data[\"Percent\"], \n        orientation='h',\n        hoverinfo=\"skip\",\n        textposition='outside',\n        texttemplate=\"%{text:.0%}\",\n        textfont_color=tcolors[n],\n        marker_color=mcolors[n],\n        marker_opacity=0.8),\n                     col=n+1,row=1)\n    fig.add_annotation(dict(\n        x=0.5,y=6,\n        showarrow=False,\n        font=tick_font,\n        text=jobtitle,\n        xref=f\"x{n+1}\",\n        yref=f\"y{n+1}\"\n    ))\n\n\nfig.update_xaxes(\n    range = [0,1.5],\n    visible=False\n)\n\nfig.update_yaxes(\n    tickfont=tick_font,\n    showgrid=False,\n    title=\"\",\n    ticklen=0,\n    categoryorder= \"array\",\n    categoryarray= sort_exp,\n)\n\n\nfig.update_layout(\n    paper_bgcolor='#EDEDED',\n    plot_bgcolor='#EDEDED',\n    margin=dict(pad=10),\n    showlegend=False,\n    height=700,\n    width=700,\n    title=dict(\n        text=\"Coding Experience per Job Title\", \n        y=0.95,\n        x=0,\n        xref=\"paper\",\n        xanchor= 'left',\n        yanchor= 'top', \n        font=title_font),  \n        hoverlabel=dict(\n        bgcolor=\"white\",\n        font_size=14,\n    ),\n)\n\n\nfor i in range(5):\n    fig.add_shape(type=\"line\",\n        x0=-0.15, y0=0.5+i, x1=1, y1=0.5+i,\n        xref = 'paper',\n        line=dict(\n            color=\"black\",\n            width=0.8,\n            dash=\"dot\",\n        )\n    )\n\nfig.show()","047a5fd8":"vizdata = maindf.loc[1:, [\"Q5\",\"Q15\"]].dropna()\n\ntitlesize = vizdata.groupby('Q5').size()\ntitle_exp_size = vizdata.groupby(by=['Q5','Q15']).size()\n\nvizdata = vizdata.drop_duplicates(inplace=False).copy()\n\nvizdata['TitleSize'] = vizdata.set_index('Q5').index.map(titlesize)\nvizdata['TitleExpSize'] = vizdata.set_index(['Q5','Q15']).index.map(title_exp_size)\nvizdata['Percent'] = vizdata['TitleExpSize']\/vizdata['TitleSize']\n\nsort_exp=[\n    \"I don't use ML\",\n    '< 1 years',\n    '1-2 years',\n    '2-3 years',\n    '3-4 years',\n    '4-5 years',\n    '5+ years'\n]\n\nmcolors = [[colorlist[10]]*vizdata['Q15'].nunique() for _ in range(len(select_titles))]\ntcolors = [[\"rgb(136,136,136)\"]*vizdata['Q15'].nunique() for _ in range(len(select_titles))]\n\nfig = make_subplots(cols=len(select_titles), rows=1, vertical_spacing=0.01,shared_yaxes=True)\n\nfor n, jobtitle in enumerate(select_titles):\n    subset_data = vizdata[vizdata['Q5']==jobtitle].reset_index(drop=True)\n    indexmax = subset_data['Percent'].idxmax()\n    mcolors[n][indexmax] = colorlist[5]\n    tcolors[n][indexmax] = \"black\"\n    fig.append_trace(trace=go.Bar(\n        name=jobtitle,\n        y=subset_data[\"Q15\"],\n        x=subset_data[\"Percent\"],\n        text=subset_data[\"Percent\"], \n        orientation='h',\n        hoverinfo=\"skip\",\n        textposition='outside',\n        texttemplate=\"%{text:.0%}\",\n        textfont_color=tcolors[n],\n        marker_color=mcolors[n],\n        marker_opacity=0.8),\n                     col=n+1,row=1)\n    fig.add_annotation(dict(\n        x=0.5,y=7,\n        showarrow=False,\n        font=tick_font,\n        text=jobtitle,\n        xref=f\"x{n+1}\",\n        yref=f\"y{n+1}\"\n    ))\n\n\nfig.update_xaxes(\n    range = [0,1.5],\n    visible=False\n)\n\nfig.update_yaxes(\n    tickfont=tick_font,\n    showgrid=False,\n    title=\"\",\n    ticklen=0,\n    categoryorder= \"array\",\n    categoryarray= sort_exp,\n)\n\n\nfig.update_layout(\n    paper_bgcolor='#EDEDED',\n    plot_bgcolor='#EDEDED',\n    margin=dict(pad=10),\n    showlegend=False,\n    height=700,\n    width=700,\n    title=dict(\n        text=\"Machine Learning Experience per Job Title\", \n        y=0.95,\n        x=0,\n        xref=\"paper\",\n        xanchor= 'left',\n        yanchor= 'top', \n        font=title_font),  \n        hoverlabel=dict(\n        bgcolor=\"white\",\n        font_size=14,\n    ),\n)\n\n\nfor i in range(6):\n    fig.add_shape(type=\"line\",\n        x0=-0.15, y0=0.5+i, x1=1, y1=0.5+i,\n        xref = 'paper',\n        line=dict(\n            color=\"black\",\n            width=0.8,\n            dash=\"dot\",\n        )\n    )\n\nfig.show()","e72dba38":"colrange = list(range(82, 95))\nvizdata = maindf.iloc[1:, colrange].dropna(how=\"all\")\n\nvizdata.columns = maindf.iloc[0, colrange].apply(lambda x: x.split(\" - \")[-1].strip()).values\n\nvizdata.rename(\n    columns={\n        \"Convolutional Neural Networks\": \n        \"CNNs\",\n        \n        \"Bayesian Approaches\": \n        \"Bayesian<br>Methods\",\n        \n        \"Gradient Boosting Machines (xgboost, lightgbm, etc)\": \n        \"GBMs\",\n        \n        \"Decision Trees or Random Forests\": \n        \"Dec Trees\/<br>Rand Forests\",\n        \n        \"Linear or Logistic Regression\": \n        \"Lin\/Log<br>Regression\",\n    },\n    inplace=True,\n)\n\n\nvizdata = vizdata.notna()\n\nvizdata[\"Title\"] = maindf.loc[vizdata.index, \"Q5\"]\n\ntitles_size = vizdata.groupby([\"Title\"]).size()\nvizdata = vizdata.groupby(\"Title\").sum()\nvizdata = vizdata.stack().reset_index()\nvizdata[\"Title Size\"] = vizdata[\"Title\"].map(titles_size)\nvizdata[\"Percent\"] = round(vizdata[0] \/ vizdata[\"Title Size\"], 2)\n\ntop5 = vizdata[vizdata['Title'].isin(select_titles)].groupby('level_1')['Percent'].mean().nlargest(5).index\nvizdata = vizdata[vizdata['level_1'].isin(top5)]\n\nmcolors = [[colorlist[10]]*vizdata['level_1'].nunique() for _ in range(len(select_titles))]\ntcolors = [[\"rgb(136,136,136)\"]*vizdata['level_1'].nunique() for _ in range(len(select_titles))]\n\nfig = make_subplots(cols=len(select_titles), rows=1, vertical_spacing=0.01,shared_yaxes=True)\n\nfor n, jobtitle in enumerate(select_titles):\n    subset_data = vizdata[vizdata['Title']==jobtitle].reset_index(drop=True)\n    indexmax = subset_data['Percent'].idxmax()\n    mcolors[n][indexmax] = colorlist[5]\n    tcolors[n][indexmax] = \"black\"\n    fig.append_trace(trace=go.Bar(\n        name=jobtitle,\n        y=subset_data[\"level_1\"],\n        x=subset_data[\"Percent\"],\n        text=subset_data[\"Percent\"], \n        orientation='h',\n        hoverinfo=\"skip\",\n        textposition='outside',\n        texttemplate=\"%{text:.0%}\",\n        textfont_color = tcolors[n],\n        marker_color=mcolors[n],\n        marker_opacity=0.8),\n                     col=n+1,row=1)\n    fig.add_annotation(dict(\n        x=0.5,y=4.8,\n        showarrow=False,\n        font=tick_font,\n        text=jobtitle,\n        xref=f\"x{n+1}\",\n        yref=f\"y{n+1}\"\n    ))\n\n\nfig.update_xaxes(\n    range = [0,2.5],\n    visible=False\n)\n\nfig.update_yaxes(\n    tickfont=tick_font,\n    ticklen=0,\n    showgrid=False,\n    title=\"\",\n)\n\n\nfig.update_layout(\n    paper_bgcolor='#EDEDED',\n    plot_bgcolor='#EDEDED',\n    margin=dict(pad=10),\n    showlegend=False,\n    height=650,\n    width=650,\n    title=dict(\n        text=\"5 Most Regularly Utilized ML Algorithms\",\n        y=0.95,\n        x=0,\n        xref=\"paper\",\n        xanchor= 'left',\n        yanchor= 'top',  \n        font=title_font),  \n    hoverlabel=dict(\n        bgcolor=\"white\",\n        font_size=14,\n    ),\n)\n\nfor i in range(4):\n    fig.add_shape(type=\"line\",\n        x0=-0.2, y0=0.5+i, x1=1, y1=0.5+i,\n        xref = 'paper',\n        line=dict(\n            color=\"black\",\n            width=0.8,\n            dash=\"dot\",\n        )\n    )\n\nfig.show()","a2b44d89":"vizdata = maindf.loc[1:, [\"Q3\",\"Q24\"]].dropna()\nvizdata = vizdata[vizdata['Q3']!='Other']\n\nvizdata[\"Q24\"] = vizdata[\"Q24\"].map(lambda x: x.replace(\",\", \"\")).map(lambda x: x.replace(\"$\", \"\"))\nvizdata[\"Q24\"] = vizdata[\"Q24\"].map(\n    lambda x: 500000 if \">\" in x\n    else 0.5 * (int(x.split(\"-\")[0]) + int(x.split(\"-\")[1]))\n)\n\nvizdata = vizdata.groupby(by=[\"Q3\"])[\"Q24\"].agg(['median']).reset_index()\n\nvizdata = vizdata.sort_values(by='median').tail(10)\n\ntop10mostpaying = vizdata['Q3'].values\n\nvizdata['median'] = vizdata['median']\/1000\n\nfig = px.bar(vizdata, \n             x=\"median\", \n             y=\"Q3\", \n             text=\"median\",\n             orientation=\"h\",\n            )\n\ncolors = [colorlist[10],]*10\ncolors[-2:] = [colorlist[5]]*2\n\nfig.update_traces(\n    hoverinfo=\"skip\",\n    hovertemplate=None,\n    marker_color=colors,\n    marker_opacity=0.8,\n    textangle=0,\n    texttemplate=\"$ %{text:,.0f}K\",\n    textposition='inside'\n)\n\nfig.update_layout(\n    xaxis=dict(\n        visible=True,\n        title_text=\"Annual Median Salary in USD\",\n        showticklabels=False,\n        ticklen=0\n    ),\n    yaxis=dict(\n        title_text=\"\", \n        tickfont=tick_font,\n        \n    ),    \n    hoverlabel=dict(\n        bgcolor=\"white\",\n        font_size=14,\n    ),\n    margin=dict(pad=5),\n    height=600,\n    width=800,\n    title=dict(\n        text='10 Countries with the Highest Median Salaries',        \n        y=1,\n        x=0,\n        xref=\"paper\",\n        xanchor= 'left',\n        yanchor= 'top', \n        font=title_font,\n))\n\n\nfig.show()","d05554ba":"expensedf = pd.read_csv('..\/input\/householdexpenditure\/householdexpenditure.csv')\nexpensedf['Country'] = expensedf['Country'].apply(lambda x: x.strip())\nexpensedict = dict(zip(expensedf['Country'],expensedf['HouseholdExpenditurePerCapita']))\n\n\nvizdata = maindf.loc[1:, [\"Q3\",\"Q24\"]].dropna()\nvizdata[\"Q24\"] = vizdata[\"Q24\"].map(lambda x: x.replace(\",\", \"\")).map(lambda x: x.replace(\"$\", \"\"))\nvizdata[\"Q24\"] = vizdata[\"Q24\"].map(\n    lambda x: 500000 if \">\" in x\n    else 0.5 * (int(x.split(\"-\")[0]) + int(x.split(\"-\")[1]))\n)\nvizdata = vizdata[vizdata['Q3']!='Other']\nvizdata = vizdata.groupby(by=[\"Q3\"])[\"Q24\"].agg(['median']).reset_index()\n\nvizdata['HouseHoldExp'] = vizdata['Q3'].map(expensedict)\nvizdata['Salary\/Expenses'] = vizdata['median']\/vizdata['HouseHoldExp']\n\nvizdata['median'] = vizdata['median']\/1000\nvizdata['HouseHoldExp'] = vizdata['HouseHoldExp']\/1000\n\nvizdata = vizdata.sort_values(by='Salary\/Expenses').tail(10)\n\n\nfig = make_subplots(rows=1, \n                    cols=2, \n                    specs=[[{}, {}]], \n                    shared_xaxes=False,\n                    shared_yaxes=False, \n                    horizontal_spacing=0.001\n                   )\n\nfig.add_trace(go.Scatter(\n                    x=vizdata['Salary\/Expenses'], \n                    y=vizdata['Q3'],\n                    mode='lines+markers+text',\n                    text=vizdata['Salary\/Expenses'],\n                    line_color=colorlist[7],\n                    name='Salary \/ Expense Rate'), row=1, col=1)\n\n\nfig.add_trace(go.Bar(x=vizdata['median'], \n                     y=vizdata['Q3'],\n                     text=vizdata['median'], \n                     orientation='h',\n                     marker_color=colorlist[5],\n                     marker_opacity=0.8,\n                     name='Annual Salary'), row=1, col=2)\n\nfig.add_trace(go.Bar(x=vizdata['HouseHoldExp'], \n                     y=vizdata['Q3'],\n                     text=vizdata['HouseHoldExp'], \n                     orientation='h',\n                     marker_color=\"#800000\",\n                     marker_opacity=0.8,\n                     name='Household Expenditure per Capita'), row=1, col=2)\n\n\n\n\nfig.update_traces(\n    hoverinfo=\"skip\",\n    hovertemplate=None,\n    texttemplate=\"%{text:,.2f}\",\n    textposition=\"bottom right\",\n    row=1,col=1\n)\nfig.update_traces(\n    hoverinfo=\"skip\",\n    hovertemplate=None,\n    textangle=0,\n    texttemplate=\"$%{text:,.0f}K\",\n    textposition='inside',\n    row=1,col=2\n)\n\n\nfig.update_layout(\n    legend=dict(\n        bgcolor=\"rgba(0,0,0,0)\",\n        orientation=\"h\",\n        title_text=\"\",\n        yanchor=\"bottom\",\n        y=1.015,\n        xanchor=\"left\",\n        x=0,\n    ),\n    barmode='overlay',\n    xaxis1=dict(\n        visible=True,\n        showgrid=False,\n        range=[2,6],\n        ticklen=0,\n        showticklabels=False,\n        title='Salary\/Expense Ratio'\n    ),\n    xaxis2=dict(\n        visible=True,\n        showgrid=False,\n        ticklen=0,\n        showticklabels=False,\n        title='Annual Median Salary in USD'\n    ),\n    yaxis1=dict(\n        showline=False,\n        linewidth=1,\n        showticklabels=True,\n        ticklen=0\n        \n    ), \n    yaxis2=dict(\n        title_text=\"\", \n        tickfont=tick_font,\n        showline=True,\n        linecolor='rgba(102, 102, 102, 0.8)',\n        showticklabels=False,\n        linewidth=1,\n        ticklen=0        \n    ),\n\n    margin=dict(pad=10,t=120),\n    height=700,\n    width=800,\n    title=dict(\n        text='10 Countries with the Highest Salary\/Expense Ratio',\n        y=0.95,\n        x=0,\n        xref=\"paper\",\n        xanchor= 'left',\n        yanchor= 'top', \n        font=title_font\n    )\n)\n\n\nfig.show()","25bdf631":"Majority of the data science professionals who responded to the survey are **below 35 years old**. 1 in 4 data science professionals are in their late twenties. \n\nThe upcoming graph will show the **top 10 countries** with **most DS professionals**.","c47fb6ad":"There are obviously many other questions that could help us analyze survey results further. However, for the sake of keeping this notebook \"digestible\", I tried to keep this list relatively short and sweet. I hope that this notebook has been helpful to you, and feel free to let me know below if you have any questions\/comments.","c1b285b9":"# Comparing various Job Titles within Data Science\n<div id=\"jobtitles\"><\/div>\n\n\nWe know that the Data Science attracts professionals with varying backgrounds. In the upcoming sections, we'll compare these varying professions\/job titles to see how the **work activities**, **machine learning experiences**, **coding experiences** differ from one to another. We will also review which Machine Learning Algorithms are utilized (and at what rate) by these professions.\n\nLet's start with work activities to see who does what. In this question the users were able to pick more than one activity provided, so the answers (activities) are not mutually exclusive.","8d7f4670":"# Education Levels\n\n<div id=\"education\"><\/div>\n\nRespondents are divided into four groups from Education levels perspective: **Doctoral** degree holders, **Master's** degree holders, **Bachelor's** degree holders, and those who pursued **other means of education**. \n\nOther means of education consists of professional degree holders, high school grads, and those who received some college\/university study without earning a degree.","3b514abe":"# References\n\nEF English Proficiency Index \nhttps:\/\/en.wikipedia.org\/wiki\/EF_English_Proficiency_Index\n\nList of countries by household final consumption expenditure per capita\nhttps:\/\/en.wikipedia.org\/wiki\/List_of_countries_by_household_final_consumption_expenditure_per_capita","f6f23225":"**Statisticians** mostly employ Regression Algorithms, Decision Trees\/Random Forests and Bayesian Methods. <br>\nMore than half of **Research Scientists** and **Machine Learning Engineers** use Convolutional Neural Networks regularly. <br>\n**Data Scientists** utilize GBM's more than any other group of professionals.\n\n\nOverall, Linear and Logistic Regression methods are the clear winners from utilization rate perspective. On an average, **78%** of the above respondents reported that they use these two algorithms on a regular basis.\n\nGradient Boosting Methods, the winning algorithms for a lot of the Kaggle competitions, are utilized by only **39%** of participants regularly. This is most likely due to the explainability of these algorithms; explainability and simplicity are highly important factors in business. GBM's tend to be much more complex and difficult to explain compared to Regression algorithms.","7c2f6eae":"After a **very** rough calculation, on average: \n* Research Scientists have **6.1**,\n* Data Engineers have **5.9**\n* Data Scientists have **5.3**,\n* Statisticians have **4.7**,\n* Machine Learning Engineers have **4.6**,\n* Business\/Data Analysts have **3.3**\nyears of Coding\/Programming experience...","4a40e6ce":"Kagglers residing in India and in the U.S. alone make up to 34% of respondents; while the ones from the top 10 countries make up to 53%.\n\nLet's look at the gender distributions.","fd5d5bd4":"Analyzing data is the most common activity across all job titles. On average, **62%** of the respondents reported that they analyze data on a regular basis. \n\nNearly the **50% of Research Scientists** work towards advancing the state of the art of Machine Learning.\n\nData Engineers have two main responsibilities: management of business data infrastructure and analysis of the data. I assume that the type of analysis Data Engineers conduct is different than Business\/Data Analysts analyses. Analysts are more interested in **the story and key insights** that's extracted from the data, while Data Engineers analyze the data from **format\/frequency\/quality** perspective. \n\nBack when I started learning about Data Science, one of the main things I was unclear about was the difference in roles and responsibilities of different job titles. A graph like the one above would have been helpful.\n\nIn the upcoming graphs, we'll compare these job titles from **Coding and Machine Learning Experience** perspectives.","7df3778c":"Having lived in many countries myself, I know that it's crucial to take living expenses into account when doing salary comparison. Making 100k USD in  San Francisco, U.S. isn't the same thing as making 100k USD in D\u00fcsseldorf, Germany. For this reason, keeping average household expenditure[[2]](https:\/\/en.wikipedia.org\/wiki\/Household_final_consumption_expenditure) in mind may provide some guidance with salary analysis. \n\nIn the next graph, we'll see the top 10 countries with the **highest median salary\/expense rate**. The country with the best rate will be at the very top.","c4a1229b":"After a similar calculation, on average: \n* Data Scientists have **2.7**,\n* Research Scientists have **2.5**,\n* Machine Learning Engineers have **2.3**,\n* Statisticians have **1.9**,\n* Data Engineers have **1.4**\n* Business\/Data Analysts have **1.2**\nyears of Machine Learning experience...\n\nBoth the years of ML and Coding experience averages are very rough estimates and are prone to error, so take these averages with a **large grain of salt**. That being said, it makes intuitive sense to me that Scientists are the most experienced group and that Analysts tend to have the least experience. \n\nOne thing that stood out to me was that on average Statisticians show slightly more coding experience compared to Machine Learning Engineers. This may be due to the margin of error of calculations, or the fact that the sample of survey respondents who are Statisticians happen to be a highly experienced bunch. A third probable reason is that Machine Learning Engineer position is relatively new, and Statisticians have been around for quite some time... \n\nLet's see the **top 5 Machine Learning algorithms** utilized regularly by these groups of professionals.","fd8bcff5":"The **largest cluster** of data science professionals are the ones with a **Master's** degree - **47%**. \nRespondents with a **Bachelor's** degree are **26%** of these professionals; and a **19%** hold **Doctoral** degree. \n**8%** of the respondents got into the field without earning a form of University degree.\n\nThe demand for skilled data science professionals is high, and the attention the field is getting has grown substantially over the recent years. It's an open discussion, whether a university\/masters\/doctoral degree is necessary to get into Data Science. The alternatives to the traditional education methods are growing rapidly, especially since the beginning of the covid pandemic. It will be interesting to see the next years survey results and see how these percentages change.","5e55ecdd":"**US** and **Switzerland** are the highest paying countries. \n\n**Israel**, a country known to invest heavily in R&D and technology, follows them closely.<br>\n\nI see that majority of the top 10 countries are either mostly **English speaking**, or are very high in English proficiency [[1]](https:\/\/en.wikipedia.org\/wiki\/EF_English_Proficiency_Index)","6f9bb50b":"# 2020 Kaggle ML & DS Survey Results\n\n\n\nThis year, as in 2017, 2018, and 2019 Kaggle set out to conduct an industry-wide survey that presents a truly comprehensive view of the state of data science and machine learning. The survey was live for 3.5 weeks in October, and after cleaning the data, it was finalized with 20,036 responses!\n\nI'll be analyzing the dataset that's made of survey participants' answers. My aim is to provide an accurate and easy to understand visual overview of state of the data science community.\n\nFirst, let's review the survey methodology notes from Kaggle.\n\n* An invitation to participate in the survey was sent to the entire Kaggle community.\n* The survey accommodated participants located in 171 different countries and territories.\n* Respondents that were flagged by the survey system as \u201cSpam\u201d were excluded.\n* Respondents with the most experience were asked the most questions.  For example, students and unemployed persons were not asked questions about their employer.  Likewise, respondents that do not write code were not asked questions about writing code.\n\nThis notebook focuses on the answers of participants with the following job titles: **Data Scientist, Research Scientist, Statistician, Machine Learning Engineer, Data Engineer, Data\/Business Analyst**. Therefore, the answers of students, unemployed participans and of those with a different current job title than what's listed above are excluded from the analysis. <br>\n\nThe notebook covers 5 main topics:\n* [Overall Age, Location, Gender Distribution](#overview)\n* [Gender-diversity by Country](#gencountry)\n* [Education Levels](#education)\n* [Comparing various Job Titles within Data Science](#jobtitles)\n* [Compensation Analysis - Median Salary by Country](#compensation)\n\nThe code driving visualizations have been hidden in order to clear up visual space; you have the option to unhide by clicking \"show hidden code\" throughout the notebook.","315e9248":"There's an overwhelming imbalance when we look at the distribution of genders. On average, 8 out of 10 respondents are men. I believe that diversity in any form (gender-wise, racial, cultural etc.) is highly beneficial as it tends to bring different, unique perspectives\/ideas into the picture. I am hoping that in the upcoming years we will see a more balanced and rich distribution from gender-diversity perspective.\n\n<div id=\"gencountry\"><\/div>\n\nWe will now dive a bit deeper to look at the **gender distribution by country**. Since the field is dominated by men, measuring male to non-male ratio is a good way to understand level of gender-diversity for each country. \n\nThe countries with the lower male\/non-male rate **(more gender-diverse) are at the top**, and the countries with the higher male\/non-male rate **(less gender-diverse) are at the bottom**.","15e7dbee":"# Compensation Analysis\n\n<div id=\"compensation\"><\/div>\n\nIn the survey users were asked to pick one of the provided salary ranges representing their annual salary(e.g. 5,000-10,000; 10,000-15,000...).<br>\nTo make an easier and simpler numerical analysis, (similar to the years of experience calculations above) I assumed a uniform distribution within each range, and replaced each salary range with the **average of** its **min** and **max values**.<br>\nFor example, if the salary range is **5,000 - 10,000**, I used **7,500** as a median salary. The only exception is **>500,000**, which I replaced with itself, **500,000**.\n<br>\nKeeping this in mind, let's look at the median salaries from top 10 countries with the highest salaries.","4a5e547b":"Some of the top 10 Countries, and the ranking amongst them are different compared to the previous chart.<br> Israel is offering the best deal by providing a median salary of 95K USD and an average household expenditure per Capita is 18K USD. The Salary\/Expense rate in Israel is **5.22**.\n\nSwitzerland follows Israel with a Salary\/Expense rate of **3.97**, while offering a median salary of 112K USD.\n\nUSA, the country that pays the most, is 8th on the list when we consider living expenses alongside the salaries. The salary\/expense rate in the U.S. is **2.97**.","da329582":"# A General Overview\n\n<div id=\"overview\"><\/div>\n\nLet's start with the basics and visualize the **overall age, gender and location distribution** of the survey respondents."}}