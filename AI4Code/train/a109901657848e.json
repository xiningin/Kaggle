{"cell_type":{"b92bcc47":"code","24251868":"code","8f0b9831":"code","89fed32d":"code","6ab3479b":"code","8dff2dd5":"code","77e448fd":"code","2503eaaf":"code","67110d5e":"code","d7494529":"code","2c2fb802":"code","1bf19629":"code","aaad60cd":"code","0b1d978e":"code","651be6c3":"code","ea9e3ed8":"code","56131def":"code","4a017f8a":"code","6c8c49cc":"code","9245748f":"code","feb0cb2b":"markdown","9afaa485":"markdown","62e9882b":"markdown","a5a4db9c":"markdown","e41f7519":"markdown","f93b2ccf":"markdown"},"source":{"b92bcc47":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn import metrics\nfrom xgboost import XGBClassifier","24251868":"df = pd.read_csv('..\/input\/heart-disease-health-indicators-dataset\/heart_disease_health_indicators_BRFSS2015.csv')","8f0b9831":"df.sample(5)","89fed32d":"df.info()","6ab3479b":"df.isnull().sum()","8dff2dd5":"df.columns","77e448fd":"Age, MentHlth, PhysHlth, BMI","2503eaaf":"catcol = ['', 'HighBP', 'HighChol', 'CholCheck',\n       'Smoker', 'Stroke', 'Diabetes', 'PhysActivity', 'Fruits', 'Veggies',\n       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n       'DiffWalk', 'Sex', 'Education',\n       'Income']","67110d5e":"plt.figure(figsize=(15,40))\nfor i,column in enumerate(catcol):\n    plt.subplot(len(catcol), 2, i+1)\n    plt.suptitle(\"Plot Value Count\", fontsize=20, x=0.5, y=1)\n    sns.countplot(data=df, x=column)\n    plt.title(f\"{column}\")\n    plt.tight_layout()","d7494529":"plt.figure(figsize=(15,40))\nfor i,column in enumerate(catcol):\n    plt.subplot(len(catcol), 2, i+1)\n    plt.suptitle(\"Plot Value Proportion\", fontsize=20, x=0.5, y=1)\n    plt.pie(x=df[column].value_counts(), labels=df[column].unique(), autopct='%.0f%%')\n    plt.title(f\"{column}\")\n    plt.tight_layout()","2c2fb802":"distcol = ['Age', 'MentHlth', 'PhysHlth', 'BMI']\nfig, axes = plt.subplots(2, 2, figsize=(18, 10))\nsns.histplot(ax=axes[0,0], data=df, x=distcol[0])\nsns.histplot(ax=axes[0,1], data=df, x=distcol[1])\nsns.histplot(ax=axes[1,0], data=df, x=distcol[2])\nsns.histplot(ax=axes[1,1], data=df, x=distcol[3])","1bf19629":"plt.figure(figsize=(15,50))\nfor i,column in enumerate(catcol[1:]):\n    plt.subplot(len(catcol), 2, i+1)\n    plt.suptitle(\"Plot Value Count VS HeartAttack\", fontsize=20, x=0.5, y=1)\n    sns.countplot(data=df, x=column, hue='HeartDiseaseorAttack')\n    plt.title(f\"{column}\")\n    plt.tight_layout()","aaad60cd":"bincol = ['HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'Diabetes', 'PhysActivity', 'Fruits', 'Veggies',\n         'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk', 'Sex']","0b1d978e":"plt.figure(figsize=(15,50))\nfor i,column in enumerate(bincol[1:]):\n    plt.subplot(len(catcol), 2, i+1)\n    plt.suptitle(\"Plot Value Count VS Education\", fontsize=20, x=0.5, y=1)\n    sns.countplot(data=df, x=column, hue='Education')\n    plt.title(f\"{column}\")\n    plt.tight_layout()","651be6c3":"plt.figure(figsize=(15,50))\nfor i,column in enumerate(bincol[1:]):\n    plt.subplot(len(catcol), 2, i+1)\n    plt.suptitle(\"Plot Value Count VS Income\", fontsize=20, x=0.5, y=1)\n    sns.countplot(data=df, x=column, hue='Income')\n    plt.title(f\"{column}\")\n    plt.tight_layout()","ea9e3ed8":"# MinMaxScaler\nfor feature in ['BMI', 'MentHlth', 'PhysHlth']: \n    df[feature] = df[feature].astype('int64')\n    df[feature] = MinMaxScaler(feature_range=(0, 1)).fit_transform(df[[feature]])","56131def":"# Split column to Feature(X) and Target(Y)\nX = df.drop(columns='HeartDiseaseorAttack')\nY = df['HeartDiseaseorAttack']","4a017f8a":"# Split data to train and test\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=48)","6c8c49cc":"# I will try some classifier algorithm and not tune the parameter, let it default\nalgorithm = [\n#     LogisticRegression(),\n    KNeighborsClassifier(),\n    RandomForestClassifier(),\n    XGBClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n]","9245748f":"# Data without resample\nlog_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\nlog = pd.DataFrame(columns = log_cols)\n\nfor cla in algorithm:\n    cla.fit(X_train, Y_train)\n    name = cla.__class__.__name__\n    print(\"=\" * 30)\n    print(name)\n    print('****Results****')\n    \n    train_predictions = cla.predict(X_test)\n    acc = accuracy_score(Y_test, train_predictions)\n    print(\"Accuracy: {:.4%}\".format(acc))\n    \n    train_predictions = cla.predict(X_test)\n    ll = log_loss(Y_test, train_predictions)\n    print(\"Log Loss: {}\".format(ll))\n    print(\"\\n\")\n    \n    log_entry = pd.DataFrame([[name, acc * 100, ll]], columns = log_cols)\n    log = log.append(log_entry)\n    \nprint(\"=\" * 30)","feb0cb2b":"<h1 style='background:#CCE2CB; border:0; color:black'><center> Preprocessing <\/center><\/h1> ","9afaa485":"<h1 style='background:#CCE2CB; border:0; color:black'><center> EDA <\/center><\/h1> ","62e9882b":"<h1 style='background:#CCE2CB; border:0; color:black'><center> Importing Libraries <\/center><\/h1> ","a5a4db9c":"<h1 style='background:#CCE2CB; border:0; color:black'><center> Preprocessing <\/center><\/h1> ","e41f7519":"<h1 style='background:#CCE2CB; border:0; color:black'><center> Feature Engineering <\/center><\/h1> ","f93b2ccf":"<h1 style='background:#CCE2CB; border:0; color:black'><center> Loading Data <\/center><\/h1> "}}