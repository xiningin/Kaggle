{"cell_type":{"048f191a":"code","4cacb024":"code","cdd28125":"code","69c8c45c":"code","9d7a77d5":"code","a5a7224c":"code","bed0ff5e":"code","1b4756db":"code","493d8929":"code","a3a5effc":"code","8f35659d":"code","b4f8335b":"code","750a73ba":"code","3b68a961":"code","441dc4f6":"code","3b192cb6":"code","32deb89c":"code","1e94b57c":"code","cf6c3e7a":"code","a66f9782":"code","fa9ecd34":"code","86bab3f3":"code","47fd5086":"code","751a25f4":"code","30cbbbe9":"code","a6e8f335":"code","25d3fbd5":"code","89f74d09":"code","f93cc3d4":"code","29ab5aec":"code","282a216e":"code","2f49fd7f":"code","cdea09e3":"code","6e323d6d":"code","a7720718":"code","8641b764":"code","dd45eed7":"code","8a6b7f55":"code","e26c1d9c":"markdown","f76ff6c4":"markdown","7e46b887":"markdown","1121a928":"markdown","07ff8878":"markdown","c6471b7d":"markdown","261a62c5":"markdown","42d3c00b":"markdown"},"source":{"048f191a":"!nvidia-smi","4cacb024":"!pip install transformers\n!pip install text_hammer ","cdd28125":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport re\nimport text_hammer as th\n\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.initializers import TruncatedNormal\nfrom tensorflow.keras.losses import CategoricalCrossentropy,BinaryCrossentropy\nfrom tensorflow.keras.metrics import CategoricalAccuracy,BinaryAccuracy\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.utils import plot_model","69c8c45c":"train=pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntest=pd.read_csv('..\/input\/nlp-getting-started\/test.csv')","9d7a77d5":"train.head()","a5a7224c":"train.shape","bed0ff5e":"test.shape","1b4756db":"train.isnull().sum()","493d8929":"train=train.fillna(\" \")","a3a5effc":"train.isnull().sum()","8f35659d":"train.target.value_counts()","b4f8335b":"sns.countplot(train.target)","750a73ba":"# drop duplicate values\ntrain=train.drop_duplicates('text',keep='last')","3b68a961":"train.shape","441dc4f6":"plt.figure(figsize=(15,100))\nsns.countplot(data=train, y='keyword' , hue='target')","3b192cb6":"def preprocess(text):\n  text=str(text).lower()\n  text=th.remove_urls(text)\n  text=th.cont_exp(text)\n  text=th.remove_emails(text)\n  text=th.remove_html_tags(text)\n  text=th.remove_special_chars(text)\n  text=th.remove_accented_chars(text)\n  text = str(text).lower().replace('\\\\', '').replace('_', ' ')\n  return text","32deb89c":"# train prerocessing\ntrain.text=train.text.apply(preprocess)\ntrain.keyword=train.keyword.apply(preprocess)","1e94b57c":"# test preprocessing\ntest.text=test.text.apply(preprocess)","cf6c3e7a":"# train.text=train.text+\" \"+train.keyword","a66f9782":"y_train = train.target.values","fa9ecd34":"train.text[0]","86bab3f3":"from transformers import AutoTokenizer,TFBertModel\ntokenizer = AutoTokenizer.from_pretrained('bert-large-uncased')\nbert = TFBertModel.from_pretrained('bert-large-uncased')","47fd5086":"tokenizer(train.text[5])","751a25f4":"train.text[1]","30cbbbe9":"print(\"max len of tweets\",max([len(x.split()) for x in train.text]))\nmax_length = 40","a6e8f335":"x_train = tokenizer(\n    text=train.text.tolist(),\n    add_special_tokens=True,\n    max_length=40,\n    truncation=True,\n    padding=True, \n    return_tensors='tf',\n    return_token_type_ids = False,\n    return_attention_mask = True,\n    verbose = True)","25d3fbd5":"x_train['input_ids'].shape","89f74d09":"max_len = 40\n\n\ninput_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\ninput_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n\n\nembeddings = bert(input_ids,attention_mask = input_mask)[1]\nout=tf.keras.layers.Dropout(0.07)(embeddings)\nout = Dense(128, activation='relu')(embeddings)\nout = tf.keras.layers.Dropout(0.1)(out)\nout = Dense(32,activation = 'relu')(out)\n\ny = Dense(1,activation = 'sigmoid')(out)\n\nmodel = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\nmodel.layers[2].trainable = True","f93cc3d4":"model.summary()","29ab5aec":"optimizer = Adam(\n    learning_rate=3e-5,\n    epsilon=1e-08,\n    decay=0.01,\n    clipnorm=1.0)\n\n# Set loss and metrics\nloss = BinaryCrossentropy(from_logits = True)\nmetric = BinaryAccuracy('accuracy'),\n\n# Compile the model\nmodel.compile(\n    optimizer = optimizer,\n    loss = loss, \n    metrics = metric)","282a216e":"plot_model(model, show_shapes = True)","2f49fd7f":"import tensorflow as tf\ntf.config.experimental.list_physical_devices('GPU')","cdea09e3":"train_history = model.fit(\n    x ={'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']} ,\n    y = y_train,\n  epochs=2,\n    batch_size=32\n)","6e323d6d":"test = tokenizer(\n    text=test.text.tolist(),\n    add_special_tokens=True,\n    max_length=40,\n    truncation=True,\n    padding=True, \n    return_tensors='tf',\n    return_token_type_ids = False,\n    return_attention_mask = True,\n    verbose = True)","a7720718":"pred = model.predict({'input_ids':test['input_ids'],'attention_mask':test['attention_mask']}) ","8641b764":"y_predicted = np.where(pred>0.5,1,0)","dd45eed7":"y_predicted = y_predicted.reshape((1,3263))[0]\ny_predicted","8a6b7f55":"submission=pd.read_csv('..\/input\/nlp-getting-started\/sample_submission.csv')\nsubmission[\"target\"]=y_predicted\nsubmission.to_csv('submission.csv', index=False, header=True)","e26c1d9c":"# Text Preprocessing","f76ff6c4":"# MODEL","7e46b887":"# Importing data","1121a928":"# Model training","07ff8878":"# Submission","c6471b7d":"# Installing dependencies","261a62c5":"# Importing libraries","42d3c00b":"# Prediction"}}