{"cell_type":{"bfe1f20c":"code","1bc5ac5f":"code","dbb4bd0d":"code","c4cb1dad":"code","acc73c80":"code","4bae634a":"code","ff831998":"code","94850767":"code","48ba0d6d":"code","256869c7":"code","60f303d3":"code","fb9e6465":"code","ecb5b59a":"code","66518fb5":"code","703d0479":"code","e93a6b82":"code","b7aece68":"code","b6cc84dc":"code","74c0ed29":"code","8b766651":"code","69207a7a":"code","9fda7ef4":"code","48ad92cb":"code","6584689f":"code","d4b5c1f4":"code","31dce326":"code","47fd5cef":"code","11ce7ea2":"code","4f914859":"code","668a325a":"code","7a72f211":"code","11ca71f5":"code","f7be3a67":"code","c5797547":"code","fb2797da":"code","e2e19372":"code","421d1b95":"code","7f678cf2":"code","63a593d0":"code","81037e09":"code","d6895daa":"code","35c5e4bc":"code","3fa369bf":"code","96e791e3":"code","440972c1":"code","ba00a83e":"code","4300ff27":"code","d1cd6e05":"code","f42851f6":"code","b5b459ec":"code","63d50d98":"code","c5626113":"code","1ce8db71":"code","f7d98bef":"code","51ab8e60":"code","a7bc1452":"code","88caccce":"code","ff8e7e63":"code","3f610610":"code","631a450f":"code","269a8f14":"markdown","12ef9868":"markdown","151c024d":"markdown","3604c6b5":"markdown","01fcf3db":"markdown","e9d0cd84":"markdown","b5e9bb12":"markdown","85d9224c":"markdown","ecc00173":"markdown","d92bfb1c":"markdown","ee003f46":"markdown","11750741":"markdown","ce72eba1":"markdown","4b1b9745":"markdown","859eea63":"markdown","1c3cdafd":"markdown","249bdc5c":"markdown","8c723fec":"markdown","2a037564":"markdown","6584fb87":"markdown","b0fcc153":"markdown","0f47653a":"markdown","ac16e531":"markdown","a7ee973d":"markdown","0b3db15e":"markdown","233190b3":"markdown","2317bf2e":"markdown","14f02186":"markdown","b4a82dd1":"markdown","b5ed917d":"markdown","fc9ef450":"markdown","12fbe872":"markdown","4851c4f8":"markdown","efff8602":"markdown","7050050d":"markdown","72f116af":"markdown","51952f10":"markdown","31bd2714":"markdown","20e6c96c":"markdown","4c34ee1b":"markdown","46df3e75":"markdown","324dd3d2":"markdown","544245a8":"markdown","dc55f683":"markdown","4d110fcb":"markdown","05ade9ac":"markdown","949cbedd":"markdown","c9c482d4":"markdown","e542a2b4":"markdown","354d5749":"markdown","c29079ec":"markdown"},"source":{"bfe1f20c":"### This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1bc5ac5f":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score,make_scorer,classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score,adjusted_rand_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import plot_roc_curve\nimport scikitplot as skplt","dbb4bd0d":"df = pd.read_csv('..\/input\/prediction-of-music-genre\/music_genre.csv')","c4cb1dad":"df.head(10)","acc73c80":"discr_feat = ['instance_id', 'artist_name', 'track_name', 'popularity','key', 'mode','obtained_date','music_genre','tempo']\ncont_feat = ['popularity','acousticness','duration_ms', 'energy','instrumentalness','liveness','loudness','speechiness','valence']","4bae634a":"df.info()","ff831998":"df.shape","94850767":"df.describe()","48ba0d6d":"print(df.isnull().sum())\n","256869c7":"df.index[df.isnull().any(axis=1)]","60f303d3":"for i in df.index[df.isnull().any(axis=1)]:\n    print(\"la ligne n\u00b0\",i)\n    print(    df.iloc[i        ,:]  )","fb9e6465":"for i in df.index[df.isnull().any(axis=1)]:\n    df=df.drop(i)","ecb5b59a":"print(df.isnull().sum())","66518fb5":"df.music_genre.value_counts()","703d0479":"for col in cont_feat :\n    plt.figure(figsize=[10,5])\n    sns.histplot(df[col])","e93a6b82":"# Create subplots net.\nfig, axes = plt.subplots(len(cont_feat), 1, figsize=(20, 105))\n\n# Fill subplots.\nfor idx, feature in enumerate(cont_feat):\n    g = sns.violinplot(ax=axes[idx], x='music_genre', y=feature, data=df)\n    g.set_title(feature)\n    plt.sca(axes[idx])\n    plt.xticks(rotation=30)\n    sns.set(font_scale=2)","b7aece68":"plt.figure(figsize=(10,6))\n\nplt.scatter(df.acousticness[df.music_genre=='Hip-Hop'],\n           df.loudness[df.music_genre=='Hip-Hop'],\n           c=\"salmon\")\n\nplt.scatter(df.acousticness[df.music_genre=='Classical'],\n           df.loudness[df.music_genre=='Classical'],\n           c=\"lightblue\")\n\nplt.scatter(df.acousticness[df.music_genre=='Electronic'],\n           df.loudness[df.music_genre=='Electronic'],\n           c=\"yellow\")\n\nplt.scatter(df.acousticness[df.music_genre=='Country'],\n           df.loudness[df.music_genre=='Country'],\n           c=\"brown\")\n\nplt.scatter(df.acousticness[df.music_genre=='Rap'],\n           df.loudness[df.music_genre=='Rap'],\n           c=\"purple\")\n\nplt.scatter(df.acousticness[df.music_genre=='Blues'],\n           df.loudness[df.music_genre=='Blues'],\n           c=\"darkblue\")\n\nplt.title(\" \")\nplt.xlabel(\" \")\nplt.legend([\" \",\" \"])\nplt.ylabel(\" \");","b6cc84dc":"for feature in cont_feat:\n    fig = sns.FacetGrid(df, hue=\"music_genre\", aspect=3, palette=\"Set2\") # aspect=3 permet d'allonger le graphique\n    fig.map(sns.kdeplot, feature, shade=True)\n    fig.add_legend()","74c0ed29":"corr_matrix=df.corr()\nplt.figure(figsize=(15,10))\nsns.heatmap(corr_matrix,\n           annot=True,\n           linewidths=0.5,\n           fmt=\".2f\",\n           cmap=\"YlGnBu\")","8b766651":"sns.scatterplot(x='loudness', y='energy', data=df, hue='music_genre')\nplt.legend(loc=4, prop={'size': 6})\nplt.tight_layout()","69207a7a":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","9fda7ef4":"df_music_genre = df.drop(['instance_id', 'artist_name', 'track_name', 'key', 'mode','obtained_date','tempo'], axis=1)","48ad92cb":"data_train = df_music_genre.sample(frac=0.8, random_state=1)          # 80% des donn\u00e9es avec frac=0.8\ndata_test = df_music_genre.drop(data_train.index)     # le reste des donn\u00e9es pour le test","6584689f":"X_train = data_train.drop(['music_genre'], axis=1)\ny_train = data_train['music_genre']\nX_test = data_test.drop(['music_genre'], axis=1)\ny_test = data_test['music_genre']","d4b5c1f4":"plt.figure(figsize=(9,9))\n\nlogistique = lambda x: np.exp(x)\/(1+np.exp(x))   \n\nx_range = np.linspace(-10,10,50)       \ny_values = logistique(x_range)\n\nplt.plot(x_range, y_values, color=\"red\")","31dce326":"from sklearn.linear_model import LogisticRegression","47fd5cef":"lr = LogisticRegression()\nlr.fit(X_train,y_train)","11ce7ea2":"y_lr = lr.predict(X_test)","4f914859":"lr_score = accuracy_score(y_test, y_lr)\nprint(lr_score)","668a325a":"from sklearn import ensemble\n\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","7a72f211":"print(classification_report(y_test, y_rf))","11ca71f5":"rf_score = accuracy_score(y_test, y_rf)\nprint(rf_score)","f7be3a67":"cm = confusion_matrix(y_test, y_rf)\nprint(cm)","c5797547":"importances = rf.feature_importances_\nindices = np.argsort(importances)","fb2797da":"plt.figure(figsize=(12,8))\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), df_music_genre.columns[indices])\nplt.title('Importance des caracteristiques')","e2e19372":"!pip install xgboost","421d1b95":"from optuna import *\nimport xgboost as XGB\nxgb  = XGB.XGBClassifier()\nxgb.fit(X_train, y_train)\ny_xgb = xgb.predict(X_test)\ncm = confusion_matrix(y_test, y_xgb)\nprint(cm)\nprint(classification_report(y_test, y_xgb))","7f678cf2":"music_features = df_music_genre.drop(\"music_genre\", axis = 1)","63a593d0":"music_labels = df_music_genre[\"music_genre\"]","81037e09":"scaler = StandardScaler()","d6895daa":"music_features_scaled = scaler.fit_transform(music_features)","35c5e4bc":"music_features_scaled.mean(), music_features_scaled.std()","3fa369bf":"tr_val_f, test_features, tr_val_l, test_labels = train_test_split(\n    music_features_scaled, music_labels, test_size = 0.1, stratify = music_labels)","96e791e3":"train_features, val_features, train_labels, val_labels = train_test_split(\n    tr_val_f, tr_val_l, test_size = len(test_labels), stratify = tr_val_l)","440972c1":"train_features.shape, train_labels.shape, val_features.shape, val_labels.shape, test_features.shape,   test_labels.shape","ba00a83e":"f1 = make_scorer(f1_score, average = \"weighted\")","4300ff27":"model = RandomForestClassifier(n_estimators = 35, max_depth = 15, min_samples_leaf = 4)","d1cd6e05":"def classification_task(estimator, features, labels):\n    \"\"\"\n    Peforms classification by training (\"fit\", \"predict\") and evaluation (\"score\") of a modelling alogirthm.\n    \n    Arguments: \n        Estimator, features (X) and labels (y).\n    \n    Returns: \n        Model's performance measured in terms of accuracy and f1_score.\n        \n        Le F1-score est une m\u00e9trique pour \u00e9valuer la performance des mod\u00e8les de classification \u00e0 2 classes ou plus.\n    \"\"\"\n    estimator.fit(features, labels)\n    predictions = estimator.predict(features)\n    \n    print(f\"Accuracy: {accuracy_score(labels, predictions)}\")\n    print(f\"F1 score: {f1_score(labels, predictions, average = 'weighted')}\")","f42851f6":"classification_task(model, train_features, train_labels)","b5b459ec":"classification_task(model, val_features, val_labels)","63d50d98":"classification_task(model, test_features, test_labels)","c5626113":"predicted_labels = model.predict_proba(test_features)","1ce8db71":"skplt.metrics.plot_roc(test_labels, predicted_labels)\nplt.legend(loc=4, prop={'size': 6})\nplt.show()","f7d98bef":"df_music_genre['music_genre'] = df['music_genre'].map({\"Electronic\":0, \"Anime\":1,\"Jazz\":2, \"Alternative\":3,\"Country\":4, \"Rap\":5,\"Blues\":6, \"Rock\":7, \"Classical\":8,\"Hip-Hop\":9})","51ab8e60":"df_music_genre.dtypes\n","a7bc1452":"y = df_music_genre['music_genre'].values\nX = df_music_genre.drop(['music_genre'], axis=1).values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","88caccce":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout","ff8e7e63":"# define the model\nmodel = Sequential()\n#model.add(Dense(512, input_dim=(X_train.shape[1]), activation=\"relu\"))\n#model.add(Dropout(0.2))\nmodel.add(Dense(256, input_dim=10, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation=\"softmax\"))\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n\n ","3f610610":"train = model.fit(X_train , y_train , validation_data=(X_test,y_test), batch_size=128,epochs=100, verbose=1)","631a450f":"### array = np.array([0.09, 0.56, 0.53, 0.87, 0.14])\ndf = pd.DataFrame(columns = ['Logistic Regression', 'XGBoost', 'Random Forest', 'Estimator','RN']) \nmodel_scores = df.append({'Logistic Regression' : 0.09, 'XGBoost' :0.56, 'Random Forest' : 0.53, 'Estimator':0.87, 'RN':0.14},  \n                ignore_index = True) \nmodel_compare = pd.DataFrame(model_scores)\nmodel_compare.T.plot.bar();","269a8f14":"Random Forest fonctionne gr\u00e2ce \u00e0 l'association de plusieurs arbres de d\u00e9cision.","12ef9868":"## Deep Learning","151c024d":"#### importance des caract\u00e9ristiques","3604c6b5":"La meilleure performance peut \u00eatre observ\u00e9e dans la musique classique, suivie par les genres anime et \u00e9lectronique. Ces genres ont des caract\u00e9ristiques uniques. Par exemple, la dur\u00e9e de la musique classique est tr\u00e8s longue et l'acoustique est extr\u00eamement faible par rapport aux autres genres.\n\nLes performances les plus faibles sont celles du rap et de la musique alternative. Le rap n'est unique que par sa popularit\u00e9, avec un l\u00e9ger avantage sur le rock. La musique alternative est au sommet de l'intensit\u00e9 sonore, le rap ayant une valeur presque similaire. Les deux genres les moins performants, le rap et la musique alternative, partagent plusieurs caract\u00e9ristiques, telles que l'acousticness et la liveness, avec des valeurs exceptionnellement proches qui pourraient entra\u00eener une erreur de classification entre les deux.","01fcf3db":"D'apr\u00e8s ce graphique les genres musicaux semblent se diff\u00e9rencier de par leur popularit\u00e9 principalement.","e9d0cd84":"*Informations g\u00e9n\u00e9rales concernant le dataset:*","b5e9bb12":"## classification","85d9224c":"*Taille de notre Dataset :*","ecc00173":"Et la matrice de confusion :","d92bfb1c":"L'accuracy est de 0,54 ce qui n'est pas beaucoup, cela n'est pas \u00e9tonnant au vu du nombre de classes que nous avons(10). ","ee003f46":"On peut voir qu'il y a une tendance au niveau de la diagonale, mais au vu de la pr\u00e9cision qui reste faible, trop de donn\u00e9es figure de part et d'autre.","11750741":"La mesure de pertinence compte le nombre de fois o\u00f9 l'algorithme a fait une bonne pr\u00e9diction (en pourcentage) :","ce72eba1":"La taille de notre Dataset a ainsi chang\u00e9 et comporte maintenant 50000 lignes pour toujours 18 colonnes.","4b1b9745":"## r\u00e9gression logistique","859eea63":"L'attribut featureimportances renvoie un tableau du poids de chaque caract\u00e9ristique dans la d\u00e9cision :","1c3cdafd":"On \u00e9tudie la distribution de chaque genre musical pour chaque features: ","249bdc5c":"## Random Forest","8c723fec":"On a les informations suivantes :\n\n1. instance_id  \n2. artist_name : nom de l'artiste\n3. track_name : nom du titre\n4. popularity : taux de populatit\u00e9\n5. acousticness : degr\u00e9 d'acoustique. 1.0 = chanson acoustique\n6. danceability: adaptabilit\u00e9 \u00e0 la danse. 0 = la moins dansante; 1 = la plus dansante  \n7. duration_ms : dur\u00e9e du titre en ms \n8. energy: d\u00e9crit l'intensit\u00e9     \n9. instrumentalness : quantit\u00e9 de voix. 1.0 = chanson instrumentale\n10. key  \n11. liveness : probabilit\u00e9 que la chanson ait \u00e9t\u00e9 enregistr\u00e9e en live. Sup\u00e9rieure \u00e0 0,8 = morceau en live\n12. loudness : intensit\u00e9\n13. mode : le mode (Minor, Major)\n14. speechiness : pr\u00e9sence de mots parl\u00e9s. Sup\u00e9rieur \u00e0 0,66 = compos\u00e9 de mots parl\u00e9s; entre 0,33 et 0,66 = contenient de la musique et des mots; inf\u00e9rieur \u00e0 0,33 = pas de paroles.\n15. tempo : tempo\n16. obtained_date : date  \n17. valence : d\u00e9crit la positivit\u00e9 musicale du morceauu. 0 = n\u00e9gatif; 1 = positif \n18. music_genre : genre musical","2a037564":"On peut pr\u00e9dire les valeurs sur l'ensemble de test avec le mod\u00e8le entra\u00een\u00e9 :","6584fb87":"# Machine Learning","b0fcc153":"Nous avons donc d\u00e9cid\u00e9 d'\u00e9tudier plut\u00f4t la distribution de tous les genre musicaux pour chaque features en m\u00eame temps:","0f47653a":"Affichage des distributions des valeurs continues :","ac16e531":"La m\u00e9thode XGBoost est d\u00e9riv\u00e9e des arbres de d\u00e9cision, et tr\u00e8s efficace, en particulier pour de grandes quantit\u00e9s de donn\u00e9es.","a7ee973d":"A partir de ces graphiques, on peut dire que les features popularit\u00e9, loudness, energy et acousticness semblent \u00eatre les features qui changent le plus selon les genres.","0b3db15e":"*Affichage des 10 premi\u00e8res lignes :*","233190b3":"## Comparaison des diff\u00e9rents algorithmes:","2317bf2e":"On remarque qu\u2019il y a une forte corr\u00e9lation entre l\u2019\u00e9nergie du morceau et son intensit\u00e9 (corr\u00e9lation positive 0,84).\nD\u2019autres param\u00e8tres ont une forte corr\u00e9lation n\u00e9gative, c\u2019est le cas de : \nl\u2019\u00e9nergie et l\u2019acoustique\nl\u2019acoustique et l\u2019intensit\u00e9\n","14f02186":"La r\u00e9gression logistique consiste \u00e0 trouver une fonction lin\u00e9aire C(X) qui permette d'estimer la probabilit\u00e9 de  Y=1  connaissant  X  :\np(Y=1|X)=eC(X)1+eC(X)\n \nAutrement dit, cela revient \u00e0 trouver une s\u00e9paration lin\u00e9aire des caract\u00e9ristiques qui minimise un crit\u00e8re d'erreur.","b4a82dd1":"*Importation des donn\u00e9es :*","b5ed917d":"On entra\u00eene le mod\u00e8le Random Forest avec fit :","fc9ef450":"## XGBoost","12fbe872":"On entra\u00eene le mod\u00e8le de r\u00e9gression logistique avec fit :","4851c4f8":"V\u00e9rifions si nous avons des donn\u00e9es manquantes:","efff8602":"## Pr\u00e9sentation du dataset\n","7050050d":"## Conclusion","72f116af":"Comme perspective d'am\u00e9lioration nous avons deux id\u00e9es:\n- Etudier moins de genres de musique \u00e0 la fois et\/ou fusionner les genres similaires.\n\n- Etudier les noms des chansons gr\u00e2ce \u00e0 du NLP par exemple.","51952f10":"### import des librairies","31bd2714":"## Analyse exploratoire des donn\u00e9es","20e6c96c":"# Prediction de genre musicaux\nLe dataset que nous avons choisi est une classification des musiques selon le genre musical. Ce dataset est issu de Spotify et comporte 10 genres musicaux ('Electronic','Anime','Jazz','Alternative','Country','Rap','Blues','Rock','Classical','Hip-Hop').\nOn y trouve \u00e9galement 18 colonnes : 11 d\u00e9cimales, 6 cha\u00eenes de caract\u00e8res et 1 format date.","4c34ee1b":"On veut maintenant pr\u00e9dire le genre musical \u00e0 partir de toutes les caract\u00e9ristiques, et \u00e9valuer la qualit\u00e9 de cette pr\u00e9diction en utilisant la r\u00e9gression logistique d\u00e9finie dans la librairie sklearn :","46df3e75":"On peut visualiser ces degr\u00e9s d'importance avec un graphique \u00e0 barres :","324dd3d2":"*Notre dataset comporte 50005 lignes et 18 colonnes.*","544245a8":"L'accuracy est de 0,54 ce qui n'est pas beaucoup, cela n'est pas \u00e9tonnant au vu du nombre de classes que nous avons(10) et de la similirait\u00e9 des genres entre eux. (Lorsque nous avons voulu exporter le document en PDF, cette erreur est apparue)","dc55f683":"Obtenir une \"pr\u00e9cision\" et un \"f1_score\" de pr\u00e8s de 80 % sur les donn\u00e9es d'entrainement et de pr\u00e8s de 90 % sur les \u00e9chantillons de validation et de test n'est pas un si mauvais r\u00e9sultat. Habituellement, les scores de validation sont l\u00e9g\u00e8rement inf\u00e9rieurs \u00e0 ceux des \u00e9chantillons de formation, car le mod\u00e8le pr\u00e9dit des classes pour des donn\u00e9es qu'il n'avait pas vues auparavant. Cependant, dans ce cas, il semble que les \u00e9chantillons de validation et de test soient assez faciles pour le mod\u00e8le, et qu'il puisse facilement deviner leurs classes. De plus, ces r\u00e9sultats montrent que le mod\u00e8le ne sous-estime ni ne surestime les \u00e9chantillons d'entra\u00eenement.","4d110fcb":"R\u00e9gression logistique : La r\u00e9gression logistique peut traiter le type de donn\u00e9es utilis\u00e9es dans ce projet. N\u00e9anmoins, la d\u00e9cision finale de classification est ambigu\u00eb lorsque les valeurs des caract\u00e9ristiques de diff\u00e9rents genres musicaux sont similaires.  \n\nRandomForest \/ XGBoost \/ Deep Learning : Les mod\u00e8le n'ont pas une pr\u00e9cision assez importante. Les donn\u00e9es serr\u00e9es de diff\u00e9rentes classes ont surement cr\u00e9\u00e9 de l'ambiguit\u00e9.\n\nLa classification en utilisant Estimator fournit des r\u00e9sultats qui sont bons pour un probl\u00e8me poss\u00e9dant 10 classes.\n\n\n","05ade9ac":"Comme nous pouvons le voir il est compliqu\u00e9 de repr\u00e9senter point par point nos donn\u00e9es dans un graphique proprement:","949cbedd":"L'accuracy est de 0,09 ce qui n'est pas satisfaisant.","c9c482d4":"*D\u00e9finition des valeurs discr\u00e8tes et continues:*","e542a2b4":"On remarque que nous avons seulement 5 lignes comportant des donn\u00e9es manquantes (les lignes 10000 \u00e0 10004). \nC'est anecdotiques en comparaison \u00e0 la taille de notre dataset, mais on peut tout de m\u00eame les supprimer.","354d5749":"On a une AUC proche de 1 ce qui est bon r\u00e9sultat. Cela montre que la plupart des \u00e9chantillons ont \u00e9t\u00e9 correctement pr\u00e9dits.","c29079ec":"Nous avons essay\u00e9 de rajouter diff\u00e9rentes couches de neurones, mais les r\u00e9sultats ne sont pas satisfaisant nous ne d\u00e9passons pas les 0.2 d'accuracy."}}