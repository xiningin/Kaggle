{"cell_type":{"a711981f":"code","d909abd7":"code","9a314353":"code","5b59585b":"code","82f35ddf":"code","e0a14515":"code","3f57448d":"code","7b904c57":"code","a2bd3f8a":"code","7f4b276c":"code","68c2d93c":"code","06f66481":"code","8cf536ac":"code","58b4e6a2":"code","a02be10e":"code","ee80a930":"code","5f6ec12d":"code","7b8a21c6":"code","adf64932":"code","0241c4ef":"code","4bd7aa56":"code","dfb3b6d3":"code","661c70f6":"code","0b17b926":"code","c5a94a8e":"code","1ec18fbd":"code","a71f4160":"code","789dd38a":"code","99908a85":"code","ad0d27f8":"code","03b0ec91":"code","d8f96916":"code","c1def7da":"code","13617639":"code","692e10af":"code","b7ab13dc":"code","5bb62c47":"code","b70fc63e":"code","76663815":"code","07a4d8aa":"code","8666e227":"code","23f499c3":"code","a5360250":"code","57608c6d":"code","30192522":"code","8c783c17":"code","cdb136ac":"code","8dababe6":"code","fe18f7c8":"markdown","7d261047":"markdown","fe47da86":"markdown","4083d37a":"markdown","6471e0d2":"markdown","ed049f32":"markdown","a1be9368":"markdown","2c78b25d":"markdown","10c599c6":"markdown","85106508":"markdown","108f895d":"markdown","10a20249":"markdown","dd8fcb53":"markdown"},"source":{"a711981f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d909abd7":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport scipy.stats as st \nimport os\nfrom tqdm import tqdm\n","9a314353":"df1=pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/train.csv')\ndf2=pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/test.csv')","5b59585b":"df=pd.concat([df1,df2],sort=False)","82f35ddf":"df.describe(include='object')","e0a14515":"#df.info()","3f57448d":"na=df.isnull().sum()","7b904c57":"na=na[na>0]","a2bd3f8a":"na_cols=list(na.index)","7f4b276c":"na=df[na_cols].copy()","68c2d93c":"#na.info()","06f66481":"dummy_cols=['PoolQC','MiscFeature','Alley']\nnan_na= ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','GarageType','GarageYrBlt','Fence',\n 'GarageFinish', 'GarageQual', 'GarageCond','GarageCars','GarageArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','FireplaceQu']\nna=na.drop(dummy_cols+['SalePrice'],axis=1)","8cf536ac":"na_mod={}\nfor i in tqdm(na.columns):\n    if i not in nan_na: \n        if na[i].dtype=='O':\n            mx=df1[i].value_counts()[df1[i].value_counts()==df1[i].value_counts().max()].index[0]\n            na[i]=na[i].replace(np.nan,mx)\n            na_mod[i]=mx\n\n        elif na[i].dtype=='float64':\n            mx=df1[i].median()\n            na[i]=na[i].replace(np.nan,mx)\n        ","58b4e6a2":"#na.info()\n    ","a02be10e":"na_mod   ","ee80a930":"for i in tqdm(nan_na):\n     \n    if na[i].dtype=='O':\n        mx='NA'\n        na[i]=na[i].replace(np.nan,mx)\n        na_mod[i]=mx\n\n    elif na[i].dtype=='float64':\n        mx=0.0\n        na[i]=na[i].replace(np.nan,mx)\n        ","5f6ec12d":"for i in na.columns:\n    df[i]=na[i]\n","7b8a21c6":"for i in dummy_cols:\n    df[i+'_present']=(~df[i].isnull()).astype(int)\n    df=df.drop(i,axis=1)","adf64932":"df.info()","0241c4ef":"df['MSSubClass']=df['MSSubClass'].astype(str)\nobjs=[]\nfor i in df.columns:\n    if df[i].dtype=='O':\n        objs.append(i)","4bd7aa56":"for i in objs:\n    print('\\n')\n    print(df[i].value_counts())","dfb3b6d3":"drop_cols=['Street','LandContour','Utilities','LandSlope','BldgType',\n          'Heating','Electrical',\n           'GarageArea','PoolArea','LotShape','HouseStyle']\nqual=['ExterQual','ExterCond','BsmtQual','BsmtCond','HeatingQC',\n      'KitchenQual','GarageQual','GarageCond']\nbasement=['BsmtFinType1','BsmtFinType2']\nlen(drop_cols)\n","661c70f6":"d=df\nd['total_bathroom']=d['BsmtFullBath']+d['BsmtHalfBath']*0.5+ \\\n                    d['FullBath']+d['HalfBath']*0.5\nd=d.drop(['BsmtFullBath','BsmtHalfBath','FullBath','HalfBath'],axis=1)","0b17b926":"d[basement]=df[basement]\nfor i in basement:\n    d[i]=d[i].map({'GLQ':6,'ALQ':5,'BLQ':4,'Rec':3,'LwQ':2,'Unf':1,'NA':0})\nd['BsmtFinType1'].value_counts()","c5a94a8e":"#df2['Condition_isnorm']=df2['Condition1'].apply(lambda x:0 if x=='Norm' else 1)\n#df2=df2.drop('Condition1',axis=1)","1ec18fbd":"d[qual]=df[qual]\nfor i in qual:\n    d[i]=d[i].map({'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1,'NA':0})","a71f4160":"d.info()","789dd38a":"d=d.drop(drop_cols,axis=1)","99908a85":"d['total_porchSF']=0\nd['total_porchSF']=d['OpenPorchSF']+d['EnclosedPorch']+d['3SsnPorch']\\\n+d['ScreenPorch']+d['WoodDeckSF']\nd=d.drop(['EnclosedPorch','OpenPorchSF','3SsnPorch','WoodDeckSF','ScreenPorch'],axis=1)","ad0d27f8":"d['BsmtExposure']=d['BsmtExposure'].map({'Gd':4,'Av':3,'Mn':2,'No':1,'NA':0})","03b0ec91":"drop_num=['GarageYrBlt','MoSold','MiscFeature_present',\n          'Alley_present']\nd=d.drop(drop_num,axis=1)","d8f96916":"d.corr().loc['SalePrice',]","c1def7da":"for i in d.columns:\n    if d[i].dtype=='O':\n        sns.boxplot(x=d[i],y=d['SalePrice'])\n        plt.show()","13617639":"plt.figure(figsize=(20,10))\nsns.boxplot(data=d,x='YrSold',y='SalePrice')","692e10af":"plt.figure(figsize=(30,20))\nsns.boxplot(data=d,x='YearBuilt',y='SalePrice')","b7ab13dc":"def yr_blt(x):\n    if x<1901:\n        return '1800s'\n    elif x<1950:\n        return '1900-50s'\n    elif x<1960:\n        return '1950s'\n    elif x<1970:\n        return '1960s'\n    elif x<1980:\n        return '1970s'\n    elif x<1990:\n        return '1980s'\n    elif x<2000:\n        return '1990s'\n    elif x<2020:\n        return '2000s'\nd['year_built']=d['YearBuilt'].apply(yr_blt)\nd['year_built'].value_counts()","5bb62c47":"plt.figure(figsize=(20,10))\nsns.boxplot(data=d,x='year_built',y='SalePrice')","b70fc63e":"for i in d.columns:\n    if d[i].dtype!='O':\n        sns.regplot(x=d[i],y=d['SalePrice'])\n        plt.show()","76663815":"d['yr_remod']=d['YearRemodAdd'].apply(yr_blt)\nplt.figure(figsize=(20,10))\nsns.boxplot(data=d,x='yr_remod',y='SalePrice')\nplt.xticks(rotation=90)\nd=d.drop('YearRemodAdd',axis=1)","07a4d8aa":"#sns.regplot(x=np.log(d['GrLivArea']),y=d['SalePrice'])\nd=d.drop('KitchenAbvGr',axis=1)\n","8666e227":"d=d.drop('PoolQC_present',axis=1)","23f499c3":"#d=d.drop(['ext1+ext2','cond1+cond2'],axis=1)\nd['YrSold']=d['YrSold'].astype(str)\nobj=[i for i in d.columns if d[i].dtype=='O']\n\nd_final=pd.get_dummies(d,columns=obj,drop_first=True)\nd_final.shape","a5360250":"train=d_final[d_final.SalePrice.isnull()==False].drop('Id',axis=1)\ntest=d_final[d_final.SalePrice.isnull()==True].drop(['Id','SalePrice'],axis=1)\ntest_id=d_final[d_final.SalePrice.isnull()==True]['Id']","57608c6d":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression,Lasso,Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\nfrom sklearn.model_selection import train_test_split,RandomizedSearchCV,GridSearchCV\nfrom statsmodels.api import OLS,add_constant","30192522":"x=train.drop('SalePrice',axis=1)\ny=train['SalePrice']\nlr=LinearRegression()\nlgb=LGBMRegressor()\nlasso=Lasso(alpha=0.3,max_iter=10e6)\nrf=RandomForestRegressor()","8c783c17":"x_tr,x_ts,y_tr,y_ts=train_test_split(x,y,test_size=0.3,random_state=6969)\nmodels={'Linear Regression':lr,'Random Forest':rf,'Light GBM':lgb,'Lasso':lasso}\nmod1={}\nfor i in models:\n    print('\\n',i)\n    a=models[i].fit(x_tr,y_tr)\n    pred_ts=a.predict(x_ts)\n    pred_tr=a.predict(x_tr)\n    print('\\nTrain Scores')\n    tr_r2=r2_score(y_tr,pred_tr)\n    tr_mae=mean_absolute_error(y_tr,pred_tr)\n    tr_mse=mean_squared_error(y_tr,pred_tr)\n    print('R2:',tr_r2)\n    print('MAE:',tr_mae)\n    print('MSE:',tr_mse)\n    print('\\nTest Scores')\n    ts_r2=r2_score(y_ts,pred_ts)\n    ts_mae=mean_absolute_error(y_ts,pred_ts)\n    ts_mse=mean_squared_error(y_ts,pred_ts)\n    print('R2:',ts_r2)\n    print('MAE:',ts_mae)\n    print('MSE:',ts_mse)\n    mod1[i]=a","cdb136ac":"x3_tr,x3_ts,y3_tr,y3_ts=train_test_split(x,np.log(y),test_size=0.3,random_state=6969)\nmodels={'Linear Regression':lr,'Random Forest':rf,'Light GBM':lgb,'Lasso':lasso}\nmod3={}\nfor i in models:\n    print('\\n',i)\n    a=models[i].fit(x3_tr,y3_tr)\n    pred_ts=a.predict(x3_ts)\n    pred_tr=a.predict(x3_tr)\n    print('\\nTrain Scores')\n    tr_r2=r2_score(y3_tr,pred_tr)\n    tr_mae=mean_absolute_error(y3_tr,pred_tr)\n    tr_mse=mean_squared_error(y3_tr,pred_tr)\n    print('R2:',tr_r2)\n    print('MAE:',tr_mae)\n    print('MSE:',tr_mse)\n    print('\\nTest Scores')\n    ts_r2=r2_score(y3_ts,pred_ts)\n    ts_mae=mean_absolute_error(y3_ts,pred_ts)\n    ts_mse=mean_squared_error(y3_ts,pred_ts)\n    print('R2:',ts_r2)\n    print('MAE:',ts_mae)\n    print('MSE:',ts_mse)\n    mod3[i]=a","8dababe6":"fm=lgb.fit(x,np.log(y))\npred=fm.predict(test)\np=np.exp(pred)\nresult=pd.DataFrame({'SalePrice':p},index=test_id)\nresult.to_csv('result2_lgb.csv')\n","fe18f7c8":"# Data Cleaning\n\nlet us combine test and train to clean the data and make it machine usable and plit the data later on ","7d261047":"Month of sale has no correlation to the price.\nGarageYrBlt is highly correlated to YearBuilt","fe47da86":"Since Light GBM with log transform gives the best result we will use that model and predict on test data and save it to a csv file","4083d37a":"Some of the missing values are supposed to be marked as 'N.A' if categorical and 0 if numerical. The rest can be imputed by mode or median. We must figure this out by checking the data description.\n\nFor example if a value is missing in garage condition it means there is no garage and the corresponding garage area will be 0. Hence it is important to notice these variables and impute the right values ","6471e0d2":"Year ofsale doesnt seem to affect the sale price much. We can see that houses sold in 2007 is not more expensive than one sold in 2006. Hence we can treat this as a categorical variable. It also has an added benifit that if recession and other factors connect to year are affecting the prices it can easily be identified if we make it categorical and use one hot encoding.\n","ed049f32":"Now we try to understand the variables and their distribution to draw insights which will help us in further feature engineering\n","a1be9368":"From the above visualization we can see how each categorical variable affects the sale price of the house\n    ","2c78b25d":"All null values have been filled. Now we can focus on feature engineering, feature selection and encoding","10c599c6":"Because MSsubclass is actually categorical we convet it to object inspite of it being int. This variable should be one-hot encoded.\nWe can drop variable street,utilities,LandSlope,LandContour,heating,electrical,PoolArea as it has very few variation.BldgType and HouseStyle are covered in the MSsubclass column.\n","85106508":"Since columns such as 'PoolQC','MiscFeature','Alley' have very few values, the model will not have enough samples for each class to learn. Hence we will create a dummy column which has value 1 if any of these features are present and 0 if it is not present","108f895d":"We will check model performance once on the original target and then on target with log transformation as it is highly right skewed. Based on its performance on the test data we can choose the model","10a20249":"# Model Building\n\nNow we will prepare the data, fit and tune algorithms and choose one based on its performance","dd8fcb53":"The YearBuilt variable also doesnt behave like a numerical variable as it doesnt exactly hold any numeric meaning. We can see that a house built in 2000 is not greater than 1800. It doesnt make sense in a numeric sense. Hence we convert it into categoricalvariable "}}