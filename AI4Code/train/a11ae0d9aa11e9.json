{"cell_type":{"f7f29d04":"code","8fd9050a":"code","1c232b8c":"code","d795e88d":"code","9c8a6756":"code","8d81d3ad":"code","44a55b98":"code","c2d2cdd1":"code","842b17b0":"code","91dc9be5":"code","5112ea64":"code","33e548cf":"code","d4264a52":"code","9885c291":"code","ce58631b":"code","e633d567":"markdown","b3c12954":"markdown","a8ed3d08":"markdown","9ce35a04":"markdown","32b006d8":"markdown","cbbdfd57":"markdown","51bc7341":"markdown"},"source":{"f7f29d04":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\n\n\nfrom collections import defaultdict\n\n\nfrom sklearn import datasets\nfrom sklearn.datasets import make_blobs\n\n# ignoring warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nimport os, cv2, json\n\n\nnp.random.seed(42)","8fd9050a":"iris=datasets.load_iris()","1c232b8c":"iris","d795e88d":"X=pd.DataFrame(iris.data,columns=['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width'])\ny=pd.DataFrame(iris.target,columns=['Classes'])\n\nX","9c8a6756":"X['species'] = pd.Series(np.random.randn(150), index=X.index)\nX['species'][y['Classes']==0]='Setosa'\nX['species'][y['Classes']==1]='versicolor'\nX['species'][y['Classes']==2]='virginica'","8d81d3ad":"X","44a55b98":"X.shape","c2d2cdd1":"clusters=len(np.unique(y))","842b17b0":"def euclidean_dis(x1, x2):\n    return np.sqrt(np.sum((x1 - x2)**2))","91dc9be5":"from collections import defaultdict\n\n\nclass KMeans:\n    \n    def __init__(self,data,k,max_ite):\n        self.data=data\n        self.k=k\n        self.max_ite=max_ite\n        \n    def predict(self):\n\n        centroids = defaultdict(int)\n        \n        K=self.k\n        max_iter=self.max_ite\n        \n        for i in range(K):\n            centroids[i] = self.data[i]\n\n\n\n        r=0\n\n\n        for i in range(max_iter):\n            r=r+1\n            classes=defaultdict(list)\n            \n            for key in range(K):\n                classes[key]=[]\n            for datapoint in self.data:\n                distance=[]\n                for j in range(K):\n\n                    dis=euclidean_dis(datapoint,centroids[j])\n\n                    distance.append(dis)\n                mindis=min(distance)\n\n                index=distance.index(mindis)\n                classes[index].append(datapoint)\n                old_centroid=dict(centroids)\n\n            for t in range(K):\n                class_=classes[t]\n\n\n                new_centroid=np.mean(class_,axis=0)\n                centroids[t]=new_centroid\n            flg=1\n            for t in range(K):\n\n                a=centroids[t]\n                b=old_centroid[t]\n                if np.sum((a - b)\/b * 100) > 0.001:\n                    flg = 0\n\n\n\n            if flg==1:\n                break\n\n\n        return classes,centroids","5112ea64":"kmeans=KMeans(iris.data[:,:4],clusters,10000)\n\nclasses,centroids=kmeans.predict()\n\n\nfor i in range(0,3):\n    classes[i]=np.array(classes[i]).tolist()\n    \nfor i in range(0,3):\n    print(len(classes[i]))\nprint(centroids)\n","33e548cf":"class0=[]\nclass1=[]\nclass2=[]\n\nfor i in range(len(iris.target)):\n    if iris.target[i]==0:\n        class0.append(iris.data[i])\n    elif iris.target[i]==1:\n        class1.append(iris.data[i])\n    elif iris.target[i]==2:\n        class2.append(iris.data[i])\n\n\nclass0=np.array(class0).tolist()\nclass1=np.array(class1).tolist()\nclass2=np.array(class2).tolist()\n\n\n# utility function\n\ndef subset(array1,array2):\n    flg=0\n    for i in range(len(array1)):\n        if(array2==array1[i]):\n            flg=1\n            break\n    if(flg==1):\n        return True\n    else:\n        return False\n    \n\n# confusion matrix\n    \ndef confusion_matrix(a,b,c,classes,):\n    \n    cm=[[0 for i in range(y.Classes.nunique())] for i in range(y.Classes.nunique())]\n\n    for element in a:\n\n        if subset(classes[2],element):\n            cm[0][0]=cm[0][0]+1\n        elif subset(classes[1],element):\n            cm[0][1]=cm[0][1]+1\n        elif subset(classes[0],element):\n            cm[0][2]=cm[0][2]+1\n\n    for element in b:\n\n        if subset(classes[2],element):\n            cm[1][0]=cm[1][0]+1\n        elif subset(classes[1],element):\n            cm[1][1]=cm[1][1]+1\n        elif subset(classes[0],element):\n            cm[1][2]=cm[1][2]+1\n\n    for element in c:\n\n        if subset(classes[2],element):\n\n            cm[2][0]=cm[2][0]+1\n        elif subset(classes[1],element):\n\n            cm[2][1]=cm[2][1]+1\n        elif subset(classes[0],element):\n\n            cm[2][2]=cm[2][2]+1\n            \n    return cm\n\n\n# performance metrics\n            \nclass Metrics:\n    \n    def __init__(self,confusion_m):\n        self.confusion_m=confusion_m\n        self.total=np.sum(confusion_m)\n        self.diagonal=np.sum(np.diag(confusion_m))\n    \n    def accuracy(self):\n        accuracy=(self.diagonal\/self.total)\n        return accuracy\n    \n    def recall(self):\n        recall=np.diag(self.confusion_m)\/np.sum(self.confusion_m,axis=1)\n        recall=np.mean(recall)\n        return recall\n    \n    def precision(self):\n        precision=np.diag(self.confusion_m)\/np.sum(self.confusion_m,axis=0)\n        precision=np.mean(precision)\n        return precision\n    \n    def f1_score(self,precision,recall):\n        f1_score=(2*precision*recall)\/(precision+recall)\n        \n        return f1_score\n","d4264a52":"\nmatrix=confusion_matrix(class0,class1,class2,classes)\nperformance=Metrics(matrix)\n\naccuracy=performance.accuracy()\nrecall=performance.recall()\nprecision=performance.precision()\nf1_score=performance.f1_score(precision,recall)\n\nprint('confusion matrix is:',end='\\n')\nprint(np.array(matrix),end='\\n')\n\nprint(\"Accuracy of the model is {}\".format(accuracy*100))\nprint(\"Recall of the model is {}\".format(recall*100))\nprint(\"Precision of the model is {}\".format(precision*100))\nprint(\"F1-Score of the model is {}\".format(f1_score*100))","9885c291":"from sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters = 3, init = 'k-means++', random_state = 42)\ny_k = kmeans.fit_predict(iris.data)","ce58631b":"y_k","e633d567":"#  Kmeans Implementation from scratch on Iris dataset","b3c12954":"# KMeans Implementation","a8ed3d08":"# Performance metrics","9ce35a04":"# prediction","32b006d8":"# Function to calculate euclidean distance","cbbdfd57":"# kmeans using inbuilt library","51bc7341":"> # load the dataset"}}