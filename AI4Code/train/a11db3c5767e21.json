{"cell_type":{"28c21ae4":"code","2b750069":"code","2939e69a":"code","63184895":"code","99e8ebde":"code","9daacd49":"code","a4f953ea":"code","74290592":"code","88d3f437":"code","026b664c":"code","f5fef45e":"code","ae5f34f7":"code","ec896c76":"code","0b162092":"code","521c60c3":"code","af7f4350":"code","cad506e7":"code","dd4eadb3":"code","48fdbbec":"code","21ef3e83":"code","a76a782a":"code","4dd91454":"code","db0c24ac":"code","b9acc9d9":"code","2bbab761":"code","3d0c1858":"code","89fad617":"code","1d641c17":"code","d686fce4":"code","bbb98432":"code","128a83a1":"code","7df58b0a":"code","7cc17f09":"markdown"},"source":{"28c21ae4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2b750069":"import tensorflow as tf\nfrom tensorflow.keras import models, layers\nimport matplotlib.pyplot as plt\n","2939e69a":"#constant\nIMAGE_SIZE = 128  # reduced the size because notebook was crashing. Did trial and error with batch_size, CNN features, multiple layers etc. \nBATCH_SIZE = 32\nCHANNELS = 3\nEPOCHS = 50","63184895":"dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/tomatodataplantvillage\/\",\n    shuffle=True,\n    image_size =(IMAGE_SIZE, IMAGE_SIZE),\n    batch_size = BATCH_SIZE\n)","99e8ebde":"class_names = dataset.class_names\nprint(class_names)\nprint(len(class_names))","9daacd49":"len(dataset)","a4f953ea":"for image_batch, label_batch in dataset.take(1):\n    print(image_batch.shape)\n    print(label_batch.numpy())","74290592":"for image_batch, label_batch in dataset.take(1):\n    print(image_batch[0].shape)","88d3f437":"plt.figure(figsize =(20,20))\nfor image_batch, label_batch in dataset.take(1): # taking 1 batch of 32 images\n    for i in range(4):\n        ax = plt.subplot(2,2,i+1)\n        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[label_batch[i]])\n        plt.axis(\"off\")","026b664c":"len(dataset)\nprint ( len(dataset) * BATCH_SIZE)  # actual images (last batch is less than BATCH_SIZE though)","f5fef45e":"print(\"Total Dataset:\", len(dataset), \"with each item has images of batch\", BATCH_SIZE)\ntrain_size = 0.8\nTRAIN_SET_SIZE = int(len(dataset) * train_size)\ntrain_ds = dataset.take(TRAIN_SET_SIZE)\ntest_ds = dataset.skip(TRAIN_SET_SIZE)\nprint(\"Train:\", len(train_ds), \", Temp test:\", len(test_ds))\n\nvalidation_size = 0.1\nVALID_SET_SIZE = int(len(dataset) * validation_size)\nvalid_ds = test_ds.take(VALID_SET_SIZE)\ntest_ds = test_ds.skip(VALID_SET_SIZE)\nprint(\"Validation:\", len(valid_ds), \", Test:\", len(test_ds))","ae5f34f7":"def get_dataset_partitions_tf(ds, train_split=0.8, val_split = 0.1, test_split=0.1, shuffle=True, shuffle_size = 10000):\n    ds_size = len(ds)\n    \n    if shuffle:\n        ds = ds.shuffle(shuffle_size, seed = 12)\n        \n    train_size = int(train_split * ds_size)    \n    val_size = int(val_split * ds_size)\n    \n    train_ds = ds.take(train_size)\n    \n    val_ds = ds.skip(train_size).take(val_size)\n    test_ds = ds.skip(train_size).skip(val_size)\n\n    return train_ds, val_ds, test_ds","ec896c76":"train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)","0b162092":"# train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n# val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n# test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n\ntrain_ds = train_ds.shuffle(1000)\nval_ds = val_ds.shuffle(1000)\ntest_ds = test_ds.shuffle(1000)","521c60c3":"resize_and_rescale = tf.keras.Sequential([\n    layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n    layers.experimental.preprocessing.Rescaling(1.0\/255)    \n])\n\ndata_augmentation = tf.keras.Sequential([\n    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n    layers.experimental.preprocessing.RandomRotation(0.2),\n])","af7f4350":"# https:\/\/stackoverflow.com\/questions\/47324571\/keras-valueerror-negative-dimension-size-caused-by-subtracting-5-from-1\n# getting error\n\ninput_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\nn_classes = len(class_names)\nmodel = models.Sequential([\n    resize_and_rescale,\n    data_augmentation,\n    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape = input_shape),  # 32 features \/ layers \/ features, (3,3) is filter size\n    layers.MaxPooling2D((2,2)),\n    \n    layers.Conv2D(64, (3,3), activation='relu'), \n    layers.MaxPooling2D((2,2)),\n    \n    layers.Conv2D(64, (3,3), activation='relu'), \n    layers.MaxPooling2D((2,2)),    \n    \n#     layers.Conv2D(64, (3,3), activation='relu'), \n#     layers.MaxPooling2D((2,2)),   \n    \n#     layers.Conv2D(64, (3,3), activation='relu'), \n#     layers.MaxPooling2D((2,2)),    \n    \n#     layers.Conv2D(64, (3,3), activation='relu'), \n#     layers.MaxPooling2D((2,2)),   \n    \n    layers.Flatten(),\n    \n    layers.Dense(64, activation = 'relu'),\n    layers.Dense(n_classes, activation = 'softmax')\n])\n\nmodel.build(input_shape = input_shape)","cad506e7":"model.summary()","dd4eadb3":"model.compile(\n    optimizer = 'adam',\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n    metrics=['accuracy']\n)","48fdbbec":"history = model.fit(\n    train_ds,\n    epochs=EPOCHS,\n    batch_size = BATCH_SIZE,\n    verbose=1,\n    validation_data=val_ds\n)","21ef3e83":"scores = model.evaluate(test_ds)","a76a782a":"scores","4dd91454":"history.params","db0c24ac":"print(history.history.keys())","b9acc9d9":"history.history['accuracy']","2bbab761":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n","3d0c1858":"plt.figure(figsize=(8,8))\n\nplt.subplot(1,2,1)\nplt.plot(range(EPOCHS), acc, label = 'Training Accuracy')\nplt.plot(range(EPOCHS), val_acc, label = 'Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1,2,2)\nplt.plot(range(EPOCHS), loss, label = 'Training Loss')\nplt.plot(range(EPOCHS), val_loss, label = 'Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')","89fad617":"for images_batch, labels_batch in test_ds.take(1):\n    \n    # for first image in a batch below code\n    #print(images_batch[0].numpy().astype('uint8')) # 3-d array\n    plt.imshow(images_batch[0].numpy().astype('uint8')) # show image","1d641c17":"import numpy as np","d686fce4":"for images_batch, labels_batch in test_ds.take(1):\n    # working on a first image in a batch of 32 (BATCH_SIZE)\n    first_image = images_batch[0].numpy().astype('uint8')\n    first_label = labels_batch[0].numpy()\n    \n    print(\"first image to predict\")\n    plt.imshow(first_image)\n    print(\"actual label:\", class_names[first_label])\n    \n    batch_predictions = model.predict(images_batch)  # predict all images\n    print(\"predictions:\", class_names[np.argmax(batch_predictions[0])]) # first image\n\n    \n    \n    ","bbb98432":"def predict(model, img):\n    img_array = tf.keras.preprocessing.image.img_to_array(img.numpy())\n    \n    img_array = tf.expand_dims(img_array, 0) # creates a batch for an image\n    predictions = model.predict(img_array)\n    \n    predicted_class = class_names[np.argmax(predictions[0])]\n    confidence = round(100 * (np.max(predictions[0])), 2)\n    return predicted_class, confidence\n    ","128a83a1":"plt.figure(figsize=(15,15))\nfor images, labels in test_ds.take(1):\n    for i in range(4):\n        ax = plt.subplot(3,3,i+1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        \n        predicted_class, confidence = predict(model, images[i])\n        actual_class = class_names[labels[i]]\n        \n        plt.title(f\"Actual: {actual_class}\\n Predicted: {predicted_class}\\n Confidence: {confidence}%\")\n        \n        plt.axis(\"off\")\n        \n        \n        ","7df58b0a":"model_version = 1  # increment it manually to have different versions\nmodel.save(f\".\/models\/{model_version}\")","7cc17f09":"Code is from: \n\n* https:\/\/www.youtube.com\/watch?v=dGtDTjYs3xc\n* https:\/\/www.youtube.com\/watch?v=bns5ELvbzVk \n* https:\/\/www.youtube.com\/watch?v=ZN6P_GEJ7lk\n\n* YouTube Channel - codebasics\n\nwith minor changes here and there."}}