{"cell_type":{"bf0dbb5f":"code","575f21a4":"code","520c03e5":"code","55bd5db1":"code","c1494e5e":"code","ad628a0d":"code","6c7f74aa":"code","6dc3adcd":"code","eba6a906":"code","c18a8915":"code","4f514282":"code","16f1d9d4":"code","db9ddd35":"code","1e28258d":"code","c4d8d46c":"code","a1a6162b":"code","ad6094ad":"code","81064eb2":"code","5145fa64":"code","6cc8753c":"code","09dd975e":"code","b5bd61c5":"code","75e15187":"markdown","73795e8c":"markdown","a58bc20d":"markdown","1e03fb20":"markdown","2c49a3c1":"markdown","e6eabb9e":"markdown","e227e173":"markdown","23dd3b1b":"markdown"},"source":{"bf0dbb5f":"import optuna\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import log_loss\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE","575f21a4":"train = pd.read_csv(\"..\/input\/tabular-playground-series-may-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-may-2021\/test.csv\")","520c03e5":"cols = []\nfor col in train.columns[1:-1]:\n    cols.append(col)","55bd5db1":"le = LabelEncoder()\nencoded = le.fit_transform(train.target)\ntrain = train.assign(target=encoded)\napple = train['target'].values\napple","c1494e5e":"train[cols].values","ad628a0d":"plt.figure(figsize=(16,16),dpi=80)\ncorr=train.corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\nsns.heatmap(corr, mask=mask, cmap='PuBu', robust=True, center=0,\n            square=True, linewidths=.5)\nplt.title('Correlation', fontsize=15)\nplt.show()","6c7f74aa":"X = train.drop([\"target\"],axis=1)\ny = train[\"target\"]\nX.shape,y.shape","6dc3adcd":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test  = train_test_split(X,y,train_size=0.8,random_state=42)\ncolumns = train.drop(['id','target'],axis=1).columns\nX_test = test.drop(['id'],axis=1)","eba6a906":"xgb_params = {\n    'learning_rate':0.746463,\n    'max_depth':1,\n    'lambda':25.46112,\n    'random_state':21,\n    'objective':'multi:softprob',\n    'eval_metric':'mlogloss',\n} ","c18a8915":"preds_1 = np.zeros((X_test.shape[0],4))\nkf = StratifiedKFold(n_splits = 10 , random_state = 13 , shuffle = True)\nll =[]\nn=0\n\nfor tr_idx, test_idx in kf.split(train[columns], train['target']):\n    \n    X_tr, X_val = train[columns].iloc[tr_idx], train[columns].iloc[test_idx]\n    y_tr, y_val = train['target'].iloc[tr_idx], train['target'].iloc[test_idx]\n    \n    model = XGBClassifier(**xgb_params)\n    \n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=200,verbose=False)\n    \n    preds_1+=model.predict_proba(X_test)\/kf.n_splits\n    ll.append(log_loss(y_val, model.predict_proba(X_val)))\n    print(n+1,ll[n])\n    n+=1","4f514282":"df_kfold_xgb = pd.DataFrame(preds_1,columns=['Class_1','Class_2','Class_3','Class_4'])\ndf_kfold_xgb['id']  = test['id']\ndf_kfold_xgb = df_kfold_xgb[['id','Class_1','Class_2','Class_3','Class_4']]","16f1d9d4":"params_lgbm = {\n    'learning_rate': 0.08602375,\n    'max_depth': 1,\n    'min_child_samples':61,\n    'min_child_weight' : 0.2569581,\n    'metric': 'multi_logloss', \n    'random_state': 42,\n    'n_estimators': 10000,\n    'objective': 'multiclass',      \n}","db9ddd35":"preds_2 = np.zeros((X_test.shape[0],4))\nskf = StratifiedKFold(n_splits = 10 , random_state = 13 , shuffle = True)\nll =[]\nn=0\n\nfor tr_idx, test_idx in skf.split(train[columns], train['target']):\n    \n    X_tr, X_val = train[columns].iloc[tr_idx], train[columns].iloc[test_idx]\n    y_tr, y_val = train['target'].iloc[tr_idx], train['target'].iloc[test_idx]\n    \n    model = LGBMClassifier(**params_lgbm)\n    \n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=200,verbose=False)\n    \n    preds_2+=model.predict_proba(X_test)\/kf.n_splits\n    ll.append(log_loss(y_val, model.predict_proba(X_val)))\n    print(n+1,ll[n])\n    n+=1","1e28258d":"df_kfold_lgbm = pd.DataFrame(preds_2,columns=['Class_1','Class_2','Class_3','Class_4'])\ndf_kfold_lgbm['id']  = test['id']\ndf_kfold_lgbm = df_kfold_lgbm[['id','Class_1','Class_2','Class_3','Class_4']]","c4d8d46c":"params_cb = {\n    'loss_function': 'MultiClass',\n    'eval_metric': 'MultiClass',\n    'learning_rate' : 0.0765847,\n    'reg_lambda': 18.7924786,\n    'subsample': 0.537623 ,\n    'depth': 5,\n    'min_data_in_leaf': 19,\n    'verbose':False,\n    'bootstrap_type': 'Bernoulli',\n    'random_state' :42,\n    'leaf_estimation_method':'Newton',\n}","a1a6162b":"preds_3 = np.zeros((X_test.shape[0],4))\nkf = StratifiedKFold(n_splits = 10 , random_state = 13 , shuffle = True)\nll =[]\nn=0\n\nfor tr_idx, test_idx in kf.split(train[columns], train['target']):\n    \n    X_tr, X_val = train[columns].iloc[tr_idx], train[columns].iloc[test_idx]\n    y_tr, y_val = train['target'].iloc[tr_idx], train['target'].iloc[test_idx]\n    \n    model = CatBoostClassifier(**params_cb)\n    \n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=200,verbose=False)\n    \n    preds_3+=model.predict_proba(X_test)\/kf.n_splits\n    ll.append(log_loss(y_val, model.predict_proba(X_val)))\n    print(n+1,ll[n])\n    n+=1","ad6094ad":"df_kfold = pd.DataFrame(preds_3,columns=['Class_1','Class_2','Class_3','Class_4'])\ndf_kfold['id']  = test['id']\ndf_kfold = df_kfold[['id','Class_1','Class_2','Class_3','Class_4']]","81064eb2":"output_3 = df_kfold.to_csv('submit_3.csv',index=False)","5145fa64":"estimators = [('lgbm',LGBMClassifier(**params_lgbm)),('cb',CatBoostClassifier(**params_cb)),('xgb',XGBClassifier(**xgb_params))]\nclf = StackingClassifier(estimators=estimators, final_estimator=LGBMClassifier(), stack_method='predict_proba', n_jobs=-1)","6cc8753c":"preds_4 = np.zeros((X_test.shape[0],4))\nkf = StratifiedKFold(n_splits = 5 , random_state = 42 , shuffle = True)\nl1 =[]\nn=0\n\nfor tr_idx, test_idx in kf.split(train[columns], train['target']):\n    \n    X_tr, X_val = train[columns].iloc[tr_idx], train[columns].iloc[test_idx]\n    y_tr, y_val = train['target'].iloc[tr_idx], train['target'].iloc[test_idx]\n    \n    model = clf\n    \n    model.fit(X_tr,y_tr)\n    \n    preds_4+=model.predict_proba(X_test)\/kf.n_splits\n    ll.append(log_loss(y_val, model.predict_proba(X_val)))\n    print(n+1,ll[n])\n    n+=1","09dd975e":"df_kfold_stk = pd.DataFrame(preds_4,columns=['Class_1','Class_2','Class_3','Class_4'])\ndf_kfold_stk['id']  = test['id']\ndf_kfold_stk = df_kfold_stk[['id','Class_1','Class_2','Class_3','Class_4']]","b5bd61c5":"output_4 = df_kfold_stk.to_csv('submit_4.csv',index=False)","75e15187":"****XGBOOST CLASSIFIER****","73795e8c":"****Label Encoding****","a58bc20d":"****Catboost classifier****","1e03fb20":"****Stacking Classifier****","2c49a3c1":"****Loading the datasets****","e6eabb9e":"****LGBM Classifier****","e227e173":"****Correlation Heatmap****","23dd3b1b":"****Dimension Reduction****"}}