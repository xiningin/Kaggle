{"cell_type":{"87e7bcde":"code","a06b10e1":"code","eb34b91b":"code","7bc96d8a":"code","4260070f":"code","93c14a99":"code","87136e0e":"code","d9177fb1":"code","d999a66c":"code","ad019468":"code","d67e0f82":"code","913ebb93":"code","94374163":"code","eb6990e3":"code","a700fcd7":"code","7818f8f9":"code","2034acf6":"code","a15193a4":"code","25a87555":"markdown","8ebfd9ce":"markdown","aeadc250":"markdown","859c0b8d":"markdown","f4b57f98":"markdown","dd67ee05":"markdown","5feb13a6":"markdown","1bd8ce70":"markdown","1be21f16":"markdown"},"source":{"87e7bcde":"from keras.models import Model\nfrom keras.layers import Input, Dense, Conv2D, BatchNormalization, LeakyReLU, Reshape, Conv2DTranspose\nfrom keras.layers.core import Activation","a06b10e1":"class Generator(object):\n    def __init__(self, input_dim, image_shape):\n        INITIAL_CHANNELS = 256\n        INITIAL_SIZE = 64\n\n        inputs = Input((input_dim,))\n        fc1 = Dense(input_dim=input_dim, units=INITIAL_CHANNELS * INITIAL_SIZE * INITIAL_SIZE)(inputs)\n        fc1 = BatchNormalization()(fc1)\n        fc1 = LeakyReLU(0.2)(fc1)\n        fc2 = Reshape((INITIAL_SIZE, INITIAL_SIZE, INITIAL_CHANNELS), input_shape=(INITIAL_CHANNELS * INITIAL_SIZE * INITIAL_SIZE,))(fc1)\n        up1 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(fc2)\n        conv1 = Conv2D(64, (3, 3), padding='same')(up1)\n        conv1 = BatchNormalization()(conv1)\n        conv1 = Activation('relu')(conv1)\n        up2 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv1)\n        conv2 = Conv2D(image_shape[2], (5, 5), padding='same')(up2)\n        outputs = Activation('tanh')(conv2)\n\n        self.model = Model(inputs=[inputs], outputs=[outputs])\n\n    def get_model(self):\n        return self.model","eb34b91b":"from keras.models import Model\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, LeakyReLU, Flatten\nfrom keras.layers.core import Activation\n\nclass Discriminator(object):\n    def __init__(self, input_shape):\n        inputs = Input(input_shape)\n        conv1 = Conv2D(64, (5, 5), padding='same')(inputs)\n        conv1 = LeakyReLU(0.2)(conv1)\n        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n        conv2 = Conv2D(128, (5, 5), padding='same')(pool1)\n        conv2 = LeakyReLU(0.2)(conv2)\n        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n        fc1 = Flatten()(pool2)\n        fc1 = Dense(1)(fc1)\n        outputs = Activation('sigmoid')(fc1)\n\n        self.model = Model(inputs=[inputs], outputs=[outputs])\n\n    def get_model(self):\n        return self.model","7bc96d8a":"import math, cv2\nimport numpy as np\n\nfrom keras.models import Model, Sequential\nfrom keras.utils. generic_utils import Progbar\n\nclass DCGAN(object):\n    def __init__(self, input_dim, image_shape):\n        self.input_dim = input_dim\n        self.d = Discriminator(image_shape).get_model()\n        self.g = Generator(input_dim, image_shape).get_model()\n\n    def compile(self, g_optim, d_optim):\n        self.d.trainable = False\n        self.dcgan = Sequential([self.g, self.d])\n        self.dcgan.compile(loss='binary_crossentropy', optimizer=g_optim)\n        self.d.trainable = True\n        self.d.compile(loss='binary_crossentropy', optimizer=d_optim)\n\n    def train(self, epochs, batch_size, X_train):\n        g_losses = []\n        d_losses = []\n        for epoch in range(epochs):\n            np.random.shuffle(X_train)\n            n_iter = X_train.shape[0] \/\/ batch_size\n            progress_bar = Progbar(target=n_iter)\n            for index in range(n_iter):\n                # create random noise -> N latent vectors\n                noise = np.random.uniform(-1, 1, size=(batch_size, self.input_dim))\n\n                # load real data & generate fake data\n                image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n                for i in range(batch_size):\n                    if np.random.random() > 0.5:\n                        image_batch[i] = np.fliplr(image_batch[i])\n                    if np.random.random() > 0.5:\n                        image_batch[i] = np.flipud(image_batch[i])\n                generated_images = self.g.predict(noise, verbose=0)\n\n                # attach label for training discriminator\n                X = np.concatenate((image_batch, generated_images))\n                y = np.array([1] * batch_size + [0] * batch_size)\n\n                # training discriminator\n                d_loss = self.d.train_on_batch(X, y)\n\n                # training generator\n                g_loss = self.dcgan.train_on_batch(noise, np.array([1] * batch_size))\n\n                progress_bar.update(index, values=[('g', g_loss), ('d', d_loss)])\n            g_losses.append(g_loss)\n            d_losses.append(d_loss)\n            if (epoch+1)%10 == 0:\n                image = self.combine_images(generated_images)\n                #image = (image + 1) \/ 2.0 * 255.0\n                cv2.imwrite('.\/result\/' + str(epoch) + \".png\", image)\n            print('\\nEpoch' + str(epoch) + \" end\")\n\n            # save weights for each epoch\n            if (epoch+1)%5 == 0:\n                self.g.save_weights('.\/generator_' + str(epoch) + '.h5', True)\n                self.d.save_weights('.\/discriminator_' + str(epoch) + '.h5', True)\n        return g_losses, d_losses\n\n    def load_weights(self, g_weight, d_weight):\n        self.g.load_weights(g_weight)\n        self.d.load_weights(d_weight)\n\n    def combine_images(self, generated_images):\n        num = generated_images.shape[0]\n        width = int(math.sqrt(num))\n        height = int(math.ceil(float(num) \/ width))\n        shape = generated_images.shape[1:4]\n        image = np.zeros((height * shape[0], width * shape[1], shape[2]),\n                         dtype=generated_images.dtype)\n        for index, img in enumerate(generated_images):\n            i = int(index \/ width)\n            j = index % width\n            image[i * shape[0]:(i + 1) * shape[0], j * shape[1]:(j + 1) * shape[1], :] = img[:, :, :]\n        return image","4260070f":"ComputeLB = False\n\nimport os, gc, zipfile\nimport numpy as np, pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport librosa \nimport cv2\n\nPATH='..\/input\/hah-data-science-challenge\/'","93c14a99":"# change wave data to mel-stft\ndef calculate_melsp(x, n_fft=1024, hop_length=128):\n    stft = np.abs(librosa.stft(x, n_fft=n_fft, hop_length=hop_length))**2\n    log_stft = librosa.power_to_db(stft)\n    melsp = librosa.feature.melspectrogram(S=log_stft,n_mels=128)\n    return melsp","87136e0e":"train = pd.read_csv(\"..\/input\/hah-data-science-challenge\/train.csv\")\nsmpl_sub = pd.read_csv(\"..\/input\/hah-data-science-challenge\/test.csv\")","d9177fb1":"train = train[train.Target==0]\ntrain['Target']=train['Target'].astype('int64')\ntrain=train.reset_index()","d999a66c":"# CREATE RANDOMLY CROPPED IMAGES\nx_train=np.zeros([len(train),256,256,1])\nfor i in range(len(train)):\n    y, sr = librosa.core.load(PATH+'\/train\/train\/'+train[\"\u30d5\u30a1\u30a4\u30eb\"].values[i],sr=None)\n    y = librosa.util.normalize(y)\n    melsp = calculate_melsp(y)\n    img = melsp\n    img = cv2.resize(img,(256,256))\n    img = img.reshape(256,256,1)\n    img = (img-img.min())\/(img.max()-img.min())\n    x_train[i] = img","ad019468":"from keras.optimizers import Adam\n\nbatch_size = 16\nepochs = 100\ninput_dim = 30\ng_optim = Adam(lr=0.0001, beta_1=0.5, beta_2=0.9)\nd_optim = Adam(lr=0.0001, beta_1=0.5, beta_2=0.9)\n\n### 0. prepare data\ninput_shape = x_train[0].shape\n\n### 1. train generator & discriminator\ndcgan = DCGAN(input_dim, input_shape)\ndcgan.compile(g_optim, d_optim)\ng_losses, d_losses = dcgan.train(epochs, batch_size, x_train)\nwith open('loss.csv', 'w') as f:\n    for g_loss, d_loss in zip(g_losses, d_losses):\n        f.write(str(g_loss) + ',' + str(d_loss) + '\\n')","d67e0f82":"import numpy as np\nfrom keras.models import Model\nfrom keras.layers import Input, Dense\nimport keras.backend as K\n\ndef sum_of_residual(y_true, y_pred):\n    return K.sum(K.abs(y_true - y_pred))\n\nclass ANOGAN(object):\n    def __init__(self, input_dim, g):\n        self.input_dim = input_dim\n        self.g = g\n        g.trainable = False\n        # Input layer cann't be trained. Add new layer as same size & same distribution\n        anogan_in = Input(shape=(input_dim,))\n        g_in = Dense((input_dim), activation='tanh', trainable=True)(anogan_in)\n        g_out = g(g_in)\n        self.model = Model(inputs=anogan_in, outputs=g_out)\n        self.model_weight = None\n\n    def compile(self, optim):\n        self.model.compile(loss=sum_of_residual, optimizer=optim)\n        K.set_learning_phase(0)\n\n    def compute_anomaly_score(self, x, iterations=300):\n        z = np.random.uniform(-1, 1, size=(1, self.input_dim))\n\n        # learning for changing latent\n        loss = self.model.fit(z, x, batch_size=1, epochs=iterations, verbose=0)\n        loss = loss.history['loss'][-1]\n        similar_data = self.model.predict_on_batch(z)\n\n        return loss, similar_data","913ebb93":"iterations = 100\ninput_dim = 30\nanogan_optim = Adam(lr=0.001, amsgrad=True)\n\n    ### 0. prepare data\ninput_shape = x_train[0].shape\n\n### 1. train generator & discriminator\ndcgan = DCGAN(input_dim, input_shape)\ndcgan.load_weights('.\/generator_44.h5', '.\/discriminator_44.h5')\n\nimg_ge = np.zeros([len(x_train),256,256,1])\nanomaly_score_log = np.zeros(len(x_train))\nfor i, test_img in enumerate(x_train):\n    test_img = test_img[np.newaxis,:,:,:]\n    anogan = ANOGAN(input_dim, dcgan.g)\n    anogan.compile(anogan_optim)\n    anomaly_score, generated_img = anogan.compute_anomaly_score(test_img, iterations)\n    #generated_img = denormalize(generated_img)\n    img_ge[i] = generated_img\n    anomaly_score_log[i] = anomaly_score\n    #imgs = np.concatenate((test_img[0], generated_img[0]), axis=1)\n    #cv2.imwrite('.\/predict' + os.sep + str(int(anomaly_score)) + '_' + str(i) + '.png', imgs)\n    #print(str(i) + ' %.2f'%anomaly_score)\n    with open('scores.txt', 'a') as f:\n        f.write(str(anomaly_score) + '\\n')","94374163":"for i in range(10):\n    plt.figure(figsize=(10,10))\n    plt.subplot(1,2,1)\n    plt.imshow(x_train[i,:,:,0])\n    plt.title('original_image')\n    plt.subplot(1,2,2)\n    plt.imshow(img_ge[i,:,:,0])\n    plt.title('generate_image')\n    plt.show()","eb6990e3":"plt.figure(figsize=(5,5))\nplt.hist(anomaly_score_log)\nplt.title('anomaly_score')\nplt.show()","a700fcd7":"train = pd.read_csv(\"..\/input\/hah-data-science-challenge\/train.csv\")\n\ntrain = train[train.Target==1]\ntrain['Target']=train['Target'].astype('int64')\ntrain=train.reset_index()\n\n# CREATE RANDOMLY CROPPED IMAGES\nx_train=np.zeros([len(train),256,256,1])\nfor i in range(len(train)):\n    y, sr = librosa.core.load(PATH+'\/train\/train\/'+train[\"\u30d5\u30a1\u30a4\u30eb\"].values[i],sr=None)\n    y = librosa.util.normalize(y)\n    melsp = calculate_melsp(y)\n    img = melsp\n    img = cv2.resize(img,(256,256))\n    img = img.reshape(256,256,1)\n    img = (img-img.min())\/(img.max()-img.min())\n    x_train[i] = img\n\niterations = 100\ninput_dim = 30\nanogan_optim = Adam(lr=0.001, amsgrad=True)\n\n    ### 0. prepare data\ninput_shape = x_train[0].shape\n\n### 1. train generator & discriminator\ndcgan = DCGAN(input_dim, input_shape)\ndcgan.load_weights('.\/generator_44.h5', '.\/discriminator_44.h5')\n\nimg_ge = np.zeros([len(x_train),256,256,1])\nanomaly_score_log2 = np.zeros(len(x_train))\nfor i, test_img in enumerate(x_train):\n    test_img = test_img[np.newaxis,:,:,:]\n    anogan = ANOGAN(input_dim, dcgan.g)\n    anogan.compile(anogan_optim)\n    anomaly_score, generated_img = anogan.compute_anomaly_score(test_img, iterations)\n    #generated_img = denormalize(generated_img)\n    img_ge[i] = generated_img\n    anomaly_score_log2[i] = anomaly_score\n    #imgs = np.concatenate((test_img[0], generated_img[0]), axis=1)\n    #cv2.imwrite('.\/predict' + os.sep + str(int(anomaly_score)) + '_' + str(i) + '.png', imgs)\n    #print(str(i) + ' %.2f'%anomaly_score)\n    with open('scores.txt', 'a') as f:\n        f.write(str(anomaly_score) + '\\n')","7818f8f9":"for i in range(2):\n    plt.figure(figsize=(10,10))\n    plt.subplot(1,2,1)\n    plt.imshow(x_train[i,:,:,0])\n    plt.title('original_image')\n    plt.subplot(1,2,2)\n    plt.imshow(img_ge[i,:,:,0])\n    plt.title('generate_image')\n    plt.show()","2034acf6":"plt.figure(figsize=(5,5))\nplt.hist(anomaly_score_log2)\nplt.title('anomaly_score')\nplt.show()","a15193a4":"plt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nplt.hist(anomaly_score_log,color='red')\nplt.title('anomaly_score_Target=0')\nplt.subplot(1,2,2)\nplt.hist(anomaly_score_log2,color='blue')\nplt.title('anomaly_score_Target=1')\nplt.show()","25a87555":"\u7570\u5e38\u5024\u30b9\u30b3\u30a2\u306e\u983b\u5ea6\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002","8ebfd9ce":"Target=0\u306e\u307f\u3092\u5b66\u7fd2\u3055\u305b\u307e\u3059\uff01","aeadc250":"DCGAN\u3092\u4f7f\u3063\u3066\u5b66\u7fd2\u3055\u305b\u307e\u3059\u3002","859c0b8d":"**AnoGan\u3092\u8a66\u3057\u3066\u307f\u307e\u3057\u305f\u3002**\n\n**\u7686\u69d8\u306e\u3054\u53c2\u8003\u306b\u306a\u308c\u308c\u3070\u5e78\u3044\u3067\u3059\u3002**","f4b57f98":"\u97f3\u58f0\u30c7\u30fc\u30bf\u3092\u30e1\u30eb\u30b9\u30da\u30af\u30c8\u30b0\u30e9\u30e0\u306b\u5909\u63db\u3057\u307e\u3059\u3002","dd67ee05":"**\u6240\u611f**\n\n\u30fbGan\u306e\u5b66\u7fd2\u304c\u96e3\u3057\u3044\u305b\u3044\u304b\u3001Target=0\u3067\u3055\u3048\u3082\u4e0a\u624b\u304f\u753b\u50cf\u304c\u751f\u6210\u3067\u304d\u3066\u3044\u306a\u3044\u3088\u3046\u306b\u611f\u3058\u307e\u3059\u3002\n\n\u30fb\u7570\u5e38\u5024\u30b9\u30b3\u30a2\u3092\u7b97\u51fa\u3057\u305f\u304c\u3001\u73fe\u72b6\u3067\u306fTarget=0\u3068Target=1\u306e\u533a\u5225\u304c\u96e3\u3057\u3044\u3067\u3059\u3002\uff08\u4f55\u304b\u5de5\u592b\u304c\u5fc5\u8981\uff1f\uff09\n","5feb13a6":"AnoGan\u3092\u4f7f\u3044\u3001\u7570\u5e38\u5024\u30b9\u30b3\u30a2\u3092\u7b97\u51fa\u3057\u307e\u3059\u3002","1bd8ce70":"\u53ef\u8996\u5316\u3057\u3066\u307f\u307e\u3059\uff01","1be21f16":"\u6b21\u306bTarget=1\u3092\u78ba\u8a8d\u3057\u3066\u3044\u304d\u307e\u3059\u3002"}}