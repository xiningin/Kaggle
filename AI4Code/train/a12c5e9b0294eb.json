{"cell_type":{"fc4c5584":"code","cd2ed136":"code","683ec489":"code","d881a035":"code","154aeb8c":"code","5e4e509e":"code","f1278bf8":"code","93c6e804":"code","63ed3183":"code","835d4fb8":"code","9cc9830c":"code","7dfe6eaf":"code","9f39b5f7":"code","556bc3cb":"code","3fba430b":"code","5b8543cf":"markdown","74a1c808":"markdown","29c410b8":"markdown","53cfda6a":"markdown","fa2109db":"markdown","51735d4b":"markdown","a863c0cd":"markdown","e5856bb4":"markdown","06a3e65b":"markdown","326126df":"markdown","44ca610d":"markdown","791a896a":"markdown","56ccc4d3":"markdown","9053854e":"markdown","65f9d9cd":"markdown","764b2b6e":"markdown","5cf29da4":"markdown"},"source":{"fc4c5584":"# Importing necessary libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport missingno as msno\nfrom datetime import date\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\n\n# Necessary display settings\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\npd.set_option('display.width', 500)\n\n# Importing dataset\n\ndf_ = pd.read_csv('..\/input\/churn-prediction\/Churn.csv')\ndf = df_.copy()\n\n# Setting column names with full upper letters:\n\ndf.columns = [col.upper() for col in df.columns]\n\n# Quick check:\n\ndef check_df(dataframe):\n    print(\"##################### Head #####################\")\n    print(dataframe.head(5))\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n    print(\"##################### Info #####################\")\n    print(dataframe.info())\n    print(\"####################### NA ######################\")\n    print(dataframe.isnull().sum())\n    print(\"################### Quantiles ###################\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n\ncheck_df(df)","cd2ed136":"df['TOTALCHARGES'].replace([' '], '0.0', inplace=True)\ndf[\"TOTALCHARGES\"] = df[\"TOTALCHARGES\"].astype(float)\n\ndf[\"CHURN\"].replace([\"Yes\"], \"1\", inplace=True)\ndf[\"CHURN\"].replace([\"No\"], \"0\", inplace=True)\ndf[\"CHURN\"] = df[\"CHURN\"].astype(int)","683ec489":"def grab_col_names(dataframe, cat_th=10, car_th=20):\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n    return cat_cols, num_cols, cat_but_car\n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)","d881a035":"def cat_summary(dataframe, col_name, plot=False):\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() \/ len(dataframe)}))\n    print(\"##########################################\")\n    if plot:\n        sns.countplot(x=dataframe[col_name], data=dataframe)\n        plt.show()\n\nfor col in cat_cols:\n    cat_summary(df, col, True)","154aeb8c":"def num_summary(dataframe, numerical_col, histogram=False, boxplot=False):\n    quantiles = [0.05, 0.10, 0.50, 0.95, 0.99]\n    print(dataframe[numerical_col].describe(quantiles).T)\n\n    if histogram:\n        dataframe[numerical_col].hist(bins=20)\n        plt.xlabel(numerical_col)\n        plt.ylabel(\"frequency\")\n        plt.title(numerical_col)\n        plt.show()\n\n    if boxplot:\n        sns.boxplot(x=dataframe[numerical_col])\n        plt.xlabel(numerical_col)\n        plt.show()\n\nfor col in num_cols:\n    num_summary(df, col, True, True)","5e4e509e":"def one_hot_encoder(dataframe, categorical_cols, drop_first=True):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n    return dataframe\n\ndf = one_hot_encoder(df, cat_cols)\ndf.rename(columns = {\"CHURN_1\": \"CHURN\"}, inplace=True)","f1278bf8":"# Getting only float and int columns:\ndff = df.select_dtypes(include=['float', 'int'])\n\n# Setting neighbor status as 20 - default:\nclf = LocalOutlierFactor(n_neighbors=20)\nclf.fit_predict(dff)\n\n# Saving scores of neighbor scales:\ndff_scores = clf.negative_outlier_factor_\nscores = pd.DataFrame(np.sort(dff_scores))\n\n# Getting the plot of hidden outliers scale:\nscores.plot(stacked=True, xlim=[0, 100], style='.-')\nplt.show()\n\n# I have decided to select the hidden outliers below 11th value:\nth = np.sort(dff_scores)[11]\nclf_index = df[dff_scores < th].index\n\n# Controlling which are these values:\ndf.iloc[(clf_index)]\n\n# Deleting them from dataset:\ndf.drop(index=clf_index, inplace=True)","93c6e804":"df.loc[(df[\"MULTIPLELINES_No phone service\"] == 0) & (df[\"MULTIPLELINES_Yes\"] == 0), \"NEW_MUTLIPLELINES\"] = 0\ndf.loc[(df[\"MULTIPLELINES_No phone service\"] == 0) & (df[\"MULTIPLELINES_Yes\"] == 1), \"NEW_MUTLIPLELINES\"] = 1\ndf.loc[(df[\"MULTIPLELINES_No phone service\"] == 1) & (df[\"MULTIPLELINES_Yes\"] == 0), \"NEW_MUTLIPLELINES\"] = 0\n\ndf.loc[(df[\"ONLINESECURITY_No internet service\"] == 0) & (df[\"ONLINESECURITY_Yes\"] == 0), \"NEW_ONLINESECURITY\"] = 0\ndf.loc[(df[\"ONLINESECURITY_No internet service\"] == 0) & (df[\"ONLINESECURITY_Yes\"] == 1), \"NEW_ONLINESECURITY\"] = 1\ndf.loc[(df[\"ONLINESECURITY_No internet service\"] == 1) & (df[\"ONLINESECURITY_Yes\"] == 0), \"NEW_ONLINESECURITY\"] = 0\n\ndf.loc[(df[\"ONLINEBACKUP_No internet service\"] == 0) & (df[\"ONLINEBACKUP_Yes\"] == 0), \"NEW_ONLINEBACKUP\"] = 0\ndf.loc[(df[\"ONLINEBACKUP_No internet service\"] == 0) & (df[\"ONLINEBACKUP_Yes\"] == 1), \"NEW_ONLINEBACKUP\"] = 1\ndf.loc[(df[\"ONLINEBACKUP_No internet service\"] == 1) & (df[\"ONLINEBACKUP_Yes\"] == 0), \"NEW_ONLINEBACKUP\"] = 0\n\ndf.loc[(df[\"DEVICEPROTECTION_No internet service\"] == 0) & (df[\"DEVICEPROTECTION_Yes\"] == 0), \"NEW_DEVICEPROTECTION\"] = 0\ndf.loc[(df[\"DEVICEPROTECTION_No internet service\"] == 0) & (df[\"DEVICEPROTECTION_Yes\"] == 1), \"NEW_DEVICEPROTECTION\"] = 1\ndf.loc[(df[\"DEVICEPROTECTION_No internet service\"] == 1) & (df[\"DEVICEPROTECTION_Yes\"] == 0), \"NEW_DEVICEPROTECTION\"] = 0\n\ndf.loc[(df[\"TECHSUPPORT_No internet service\"] == 0) & (df[\"TECHSUPPORT_Yes\"] == 0), \"NEW_TECHSUPPORT\"] = 0\ndf.loc[(df[\"TECHSUPPORT_No internet service\"] == 0) & (df[\"TECHSUPPORT_Yes\"] == 1), \"NEW_TECHSUPPORT\"] = 1\ndf.loc[(df[\"TECHSUPPORT_No internet service\"] == 1) & (df[\"TECHSUPPORT_Yes\"] == 0), \"NEW_TECHSUPPORT\"] = 0\n\ndf.loc[(df[\"STREAMINGTV_No internet service\"] == 0) & (df[\"STREAMINGTV_Yes\"] == 0), \"NEW_STREAMINGTV\"] = 0\ndf.loc[(df[\"STREAMINGTV_No internet service\"] == 0) & (df[\"STREAMINGTV_Yes\"] == 1), \"NEW_STREAMINGTV\"] = 1\ndf.loc[(df[\"STREAMINGTV_No internet service\"] == 1) & (df[\"STREAMINGTV_Yes\"] == 0), \"NEW_STREAMINGTV\"] = 0\n\ndf.loc[(df[\"STREAMINGMOVIES_No internet service\"] == 0) & (df[\"STREAMINGMOVIES_Yes\"] == 0), \"NEW_STREAMINGMOVIES\"] = 0\ndf.loc[(df[\"STREAMINGMOVIES_No internet service\"] == 0) & (df[\"STREAMINGMOVIES_Yes\"] == 1), \"NEW_STREAMINGMOVIES\"] = 1\ndf.loc[(df[\"STREAMINGMOVIES_No internet service\"] == 1) & (df[\"STREAMINGMOVIES_Yes\"] == 0), \"NEW_STREAMINGMOVIES\"] = 0\n\n# TOTAL SERVICE NUMBER:\ndf[\"TOTAL_SERVICE\"] = df[\"NEW_MUTLIPLELINES\"] + df[\"NEW_ONLINESECURITY\"] + df[\"NEW_ONLINEBACKUP\"] \\\n                      + df[\"NEW_DEVICEPROTECTION\"] + df[\"NEW_TECHSUPPORT\"] \\\n                      + df[\"NEW_STREAMINGTV\"] + df[\"NEW_STREAMINGMOVIES\"] + df[\"PHONESERVICE_Yes\"]\n\nlist = df[[\"NEW_MUTLIPLELINES\", \"NEW_ONLINESECURITY\", \"NEW_ONLINEBACKUP\", \"NEW_DEVICEPROTECTION\",\n           \"NEW_TECHSUPPORT\", \"NEW_STREAMINGTV\", \"NEW_STREAMINGMOVIES\"]]\n\ndf = df.drop(list, axis=1)","63ed3183":"df[\"TOTALCHARGES_PER_SERVICE\"] = df[\"TOTALCHARGES\"] \/ df[\"TOTAL_SERVICE\"]\n\ndf[\"TOTALCHARGES_PER_SERVICE\"].replace(np.inf, 0, inplace=True)\n\nlow_mean = df[(df[\"TOTALCHARGES_PER_SERVICE\"] == 0) & (df[\"PARTNER_Yes\"] == 0)][\"TOTALCHARGES\"].mean()\nhigh_mean = df[(df[\"TOTALCHARGES_PER_SERVICE\"] == 0) & (df[\"PARTNER_Yes\"] == 1)][\"TOTALCHARGES\"].mean()\n\ndf.loc[(df[\"TOTALCHARGES_PER_SERVICE\"] == 0) & (df[\"PARTNER_Yes\"] == 0), \"TOTALCHARGES_PER_SERVICE\"] = low_mean\ndf.loc[(df[\"TOTALCHARGES_PER_SERVICE\"] == 0) & (df[\"PARTNER_Yes\"] == 1), \"TOTALCHARGES_PER_SERVICE\"] = high_mean\n","835d4fb8":"df[\"MONTHLYCHARGES_PER_SERVICE\"] = df[\"MONTHLYCHARGES\"] \/ df[\"TOTAL_SERVICE\"]\ndf[\"MONTHLYCHARGES_PER_SERVICE\"].replace(np.inf, 0, inplace=True)\n\nlow_mean = df[(df[\"MONTHLYCHARGES_PER_SERVICE\"] == 0) & (df[\"PARTNER_Yes\"] == 0)][\"MONTHLYCHARGES\"].mean()\nhigh_mean = df[(df[\"MONTHLYCHARGES_PER_SERVICE\"] == 0) & (df[\"PARTNER_Yes\"] == 1)][\"MONTHLYCHARGES\"].mean()\n\ndf.loc[(df[\"MONTHLYCHARGES_PER_SERVICE\"] == 0) & (df[\"PARTNER_Yes\"] == 0), \"MONTHLYCHARGES_PER_SERVICE\"] = low_mean\ndf.loc[(df[\"MONTHLYCHARGES_PER_SERVICE\"] == 0) & (df[\"PARTNER_Yes\"] == 1), \"MONTHLYCHARGES_PER_SERVICE\"] = high_mean","9cc9830c":"zero_mean = df.loc[(df[\"CONTRACT_One year\"] == 0) & (df[\"CONTRACT_Two year\"] == 0)][\"TOTALCHARGES\"].mean()\ntwo_mean = df.loc[(df[\"CONTRACT_One year\"] == 0) & (df[\"CONTRACT_Two year\"] == 1)][\"TOTALCHARGES\"].mean()\none_mean = df.loc[(df[\"CONTRACT_One year\"] == 1) & (df[\"CONTRACT_Two year\"] == 0)][\"TOTALCHARGES\"].mean()\n\n\ndf.loc[(df[\"CONTRACT_One year\"] == 0) & (df[\"CONTRACT_Two year\"] == 0), \"CONTRACT_TYPE\"] = 1\ndf.loc[(df[\"CONTRACT_One year\"] == 0) & (df[\"CONTRACT_Two year\"] == 1), \"CONTRACT_TYPE\"] = two_mean\ndf.loc[(df[\"CONTRACT_One year\"] == 1) & (df[\"CONTRACT_Two year\"] == 0), \"CONTRACT_TYPE\"] = one_mean\n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)\n","7dfe6eaf":"df.shape","9f39b5f7":"rs = RobustScaler()\ndf[num_cols] = rs.fit_transform(df[num_cols])","556bc3cb":"from sklearn.ensemble import RandomForestClassifier\n\ny = df[\"CHURN\"]\nX = df.drop([\"CUSTOMERID\", \"CHURN\"], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=32)\nrf_model = RandomForestClassifier(random_state=18).fit(X_train, y_train)\ny_pred = rf_model.predict(X_test)\naccuracy_score(y_pred, y_test)","3fba430b":"def plot_importance(model, features, num=len(X), save=False):\n    feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': features.columns})\n    plt.figure(figsize=(10, 10))\n    sns.set(font_scale=1)\n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\",\n                                                                      ascending=False)[0:num])\n    plt.title('Features')\n    plt.tight_layout()\n    plt.show()\n    if save:\n        plt.savefig('importances.png')\n\nplot_importance(rf_model, X_train)","5b8543cf":"**Let\u2019s start with the dataset:**\n\nTelco is a fantastic California-based telecommunication company. They provided us with a dataset of 19 different feature of 7043 customers. Telco wants to be provided with a model which is able to predict the probability of a customer to be churn(leave the company).\n\n\n**Dataset variables:**\n\nCustomerId \u2014 Customer ID\n\nGender \u2014 Customer Gender(male\/female)\n\nSeniorCitizen \u2014 Old or not customer(1, 2)\n\nPartner \u2014 Customer having a co-user(Yes, No)\n\nDependents \u2014 Customer having to look after anyone(Yes, No)\n\nTenure \u2014 Customer using company services (month)\n\nPhoneService \u2014 Customer having or not phone service(Yes, No)\n\nMultipleLines \u2014 Customer having more than one phone line(Yes, No, No phone service)\n\nInternetService \u2014 Customer having internet service (DSL, Fiber optic, No)\n\nOnlineSecurity \u2014 Customer having online security or not(Yes, No, No internet service)\n\nOnlineBackup \u2014 Customer having online backup service or not(Yes, No, No internet service)\n\nDeviceProtection \u2014 Customer having device protection service or not(Yes, No, No internet service)\n\nTechSupport \u2014 Customer requesting tech support anytime(Yes, No, No internet service)\n\nStreamingTV \u2014 Customer having TV stream service(Yes, No, No internet service)\n\nStreamingMovies \u2014 Customer having movie stream service(Yes, No, No internet service)\n\nContract \u2014 The type\/length of contract(Monthly, One year, Two year)\n\nPaperlessBilling \u2014 Customer having paperless billing(Yes, No)\n\nPaymentMethod \u2014 Customer payment method(Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic)\n\nMonthlyCharges \u2014 The amount customer paid monthly\n\nTotalCharges \u2014 The total amount customer paid to company\n\nChurn \u2014 Customer being churn or not(Yes, No)\n\nThe target variable is \u201cChurn\u201d.\n\n**Let's start by importing the dataset and quick check it:**","74a1c808":"**Feature Engineering**\n\nMathematics, Statistics, Econometrics, Know-How, Business Information and many others\u2026are fields you should be familiar to for a better data analysis. But don\u2019t get blue! The greatest journeys all start with a single step!\n\nThis story is about engineering new features from the dataset. We separate dataset into particles, multiply, divide and generate new features which explain us lot more than the dataset itself does. This is called feature engineering and by this we are able to build a better model which actually predict the outcome\/result of the dataset variables (i.e. works\/doesn\u2019t work, No\/Yes, Sick\/Healthy, etc.).\n\nThe are many valuable models which are used in this field. The analysis below is based on Random Forrest Classifier model.","29c410b8":"After creating the new variables, categoric and numeric columns are defined again with grab_col_names function.\n\nLet\u2019s see what is the shape of our dataset now:","53cfda6a":"As far as we can see from the categorical and numerical columns, dataset does not contain outlier values. Boxplot provide us with enough visual information which can also be provided with functions.\n\nAlthough we decide to move on and encode our variables. Label Encoding is necessary to code variables with binary results such as Yes\/No, Good\/Bad, Strong\/Weak, etc; and One-Hot encoding our variables help us avoid the dummy variable trap. I decided to encode my variables with One-Hot encoding:","fa2109db":"So before continuing to feature engineering we need to sum up here. In the latest function one-hot encoding has been done. Because of one-hot encoding, new categorical columns has been created, so this is why we need to define categoric and numeric columns again.\n\nAttention please. In that phase we should do the analyze and find columns which have low explanatory impact of dataset values. But since summarized categoric columns and saw none of the classes are significantly low, rare column analysis may not be done.\n\nUntil now, we have been working on categorical columns. Haven\u2019t found any outlier and numerical columns aren\u2019t scaled yet. So the first step that should be taken now is to get rid of \u201chidden outliers\u201d.\n\nHidden outliers are the ones that cannot be found by analyzing the columns within it\u2019s borders, but can be found when rows are compared to each other. With this, we can find what it is named \u201chidden outliers\u201d. For this example a hidden outlier would be a customer which hasn\u2019t bought any service but have a monthly and total charge higher than zero. Also a hidden outlier could be a customer who has a monthly charge higher than zero, but total charge seem to be zero.\n\n**Please find below the steps to find out the hidden outliers:**","51735d4b":"**Creating CONTRACT_TYPE variable:**","a863c0cd":"**Creating MONTHLYCHARGES_PER_SERVICE variable:**","e5856bb4":"Now it\u2019s time for Feature Engineering. Basically we should create new variables which have strong explanatory force for dataset values. The aim is to create a model with less variables which ones are strong enough to predict the dataset with the highest accuracy.\n\nSo these variables should be created with very high difficulty in that way we don\u2019t create noise inside the dataset and the variable isn\u2019t the duplicate of any other variable already in dataset. Latter on we\u2019ll be sorting the variables by their force of explanatory force of dataset.\n\n**Below I have created:**\n\n*TOTAL_SERVICE*\n\n*TOTALCHARGES_PER_SERVICE*\n\n*MONTHLYCHARGES_PER_SERVICE*\n\n*CONTRACT_TYPE*\n\n\n**Creating TOTAL_SERVICE variable:**","06a3e65b":"And below is the summary function for numerical columns and the result for histogram=True and boxplot=True:","326126df":"We have started this story with 7043 rows and 21 columns. Now we have deleted 11 rows as hidden outliers and created 15 new columns as variables to explain the result \u201cCHURN\u201d with higher probability.\n\nNow, before testing our dataset with Random Forest Classifier model, we have to scale also our numerical columns. This can be done by Standard Scaler which uses the mean and standard error. But this parameters are outlier-effected parameters, so to avoid that problem (even if we deleted the hidden outliers from our dataset) we will be using Robust Scaler which as parameter to scale numerical columns is using median and IQR.","44ca610d":"Please play the code above!\n\nAs we can see, TOTALCHARGES_PER_SERVICE & MONTHLYCHARGES_PER_SERVICE features that we created have the highest importance to explain the model pattern.\n\nThank you for reading!\n\nHope this will help you understand better the importance of modelling the dataset and generating specific features which will explain the dataset\u2019s pattern with significant importance.\n\nThis work has been done with the support of [VBO](https:\/\/www.veribilimiokulu.com\/), [Vahit Keskin](https:\/\/www.linkedin.com\/in\/vahitkeskin\/), [O\u011fuz Erdo\u011fan](https:\/\/www.linkedin.com\/in\/oguzerdo\/), [Hande K\u00fc\u00e7\u00fckbulut](https:\/\/www.linkedin.com\/in\/hande-kucukbulut\/), [Mehmet Tuzcu](https:\/\/www.linkedin.com\/in\/mehmettuzcu\/) & [Burak Do\u011frul](https:\/\/www.linkedin.com\/in\/burakdogrul\/).","791a896a":"Please find below the function of the summary of category columns and the result of plot analysis:","56ccc4d3":"Now the dataset is ready to be categorized into new groups by dataset variable types.\n\nSo please find below the special function to grab columns by their type set within our function.\n\ncat_cols - categoric columns which values have less than 10 unique levels\n\nnum_cols - numerical columns which values have more than 20 unique levels and aren't object type\n\ncat_but_car - columns seems categoric but with higher unique levels than 20\n","9053854e":"Finally it\u2019s time to model our dataset and get the results:","65f9d9cd":"To implement Random Forest model we need to import RandomForestClassifier from sklearn.ensemble. Thereafter \u201cy\u201d set as dataframe\u2019s target variable and \u201cX\u201d set as dataframe without target variable and other variables not necessarily needed to occur the prediction.\n\nThe dataset split to test and train parts with 25\u201375 ratio. And accuracy measured by random-states set for you to get the same result as me, 0.8054.\n\nNow let\u2019s check the importance of the features already been in dataset and the features we have created from dataset:","764b2b6e":"As far as we can see the shape of dataset is 7043 rows and 21 columns(18 of which are object type, 1 is float64 and 2 are int64). There is no null values in dataset, and the quantiles of numeric columns are not signing for any outlier.\n\nNow is time to grab columns by their type and save categorically. But while we check the dataset, we saw that \u201cCHURN\u201d variable is object type, so further analysis will be unable due to variable type. Also \u201cTOTALCHARGES\u201d variable has some blank (\u201c \u201c) spaces which we are going to replace with zero.","5cf29da4":"**Creating TOTALCHARGES_PER_SERVICE variable:**"}}