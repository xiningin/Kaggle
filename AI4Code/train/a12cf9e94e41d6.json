{"cell_type":{"5e1221a6":"code","6cffc3e6":"code","2eab921c":"code","3e372c28":"code","52bae64c":"code","c09456e6":"code","97156ea0":"code","5296568b":"code","d84a06e6":"code","f5089d8c":"code","97908979":"code","1bcfa404":"code","79c006ff":"code","5e55f741":"code","aa8d7bf2":"code","6abfaaad":"markdown","8fcec815":"markdown","5eeb91ad":"markdown","6719fd43":"markdown","c305f10d":"markdown","2e54822a":"markdown","f80461f1":"markdown","ba4d8f40":"markdown","153a103b":"markdown"},"source":{"5e1221a6":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\n\nsns.set_style(\"darkgrid\")","6cffc3e6":"df = pd.read_csv(\"\/kaggle\/input\/foreign-exchange-rates-per-dollar-20002019\/Foreign_Exchange_Rates.csv\")\n\ndf = df.drop(columns=[\"Unnamed: 0\"])\nnewColumnsNames = list(map(lambda c: c.split(\" - \")[0] if \"-\" in c else \"DATE\", df.columns))\nnewColumnsNames\ndf.columns = newColumnsNames","2eab921c":"# Fill ND values with previous and next values\n\ndf = df.replace(\"ND\", np.nan)\ndf = df.bfill().ffill() \n\n# Make date wise indexing \n\ndf = df.set_index(\"DATE\")\ndf.index = pd.to_datetime(df.index)\ndf = df.astype(float)","3e372c28":"print(\"Total number of records\", len(df))\nprint(\"Total number of days between {} and {} are {}\".format(df.index.min().date(), df.index.max().date(), (df.index.max() - df.index.min()).days+1))","52bae64c":"# Prepare a full dataframe\nnum_records = 7303\ndata = {}\ndata[\"DATE\"] = pd.date_range(\"2000-01-03\", \"2019-12-31\", freq=\"D\")\n\ncomplete = pd.DataFrame(data=data)\ncomplete = complete.set_index(\"DATE\")\ncomplete = complete.merge(df, left_index=True, right_index=True, how=\"left\")\ncomplete = complete.bfill().ffill()","c09456e6":"complete.head()","97156ea0":"toInspect = [\"INDIA\", \"CHINA\", \"EURO AREA\"]\nrows, cols = 3, 2\nfig, ax = plt.subplots(rows, cols, figsize=(20,rows*5))\n\nfor row in range(rows):\n    sns.lineplot(data=df[[toInspect[row]]], ax=ax[row][0])\n    sns.lineplot(data=complete[[toInspect[row]]], ax=ax[row][1])","5296568b":"sampled2d = complete.resample(\"2D\").mean()","d84a06e6":"# Data Conversion Utility\n\ndef getTimeSeriesData(A, window=7):\n    X, y = list(), list()\n    for i in range(len(A)):\n        end_ix = i + window\n        if end_ix > len(A) - 1:\n            break\n        seq_x, seq_y = A[i:end_ix], A[end_ix]\n        X.append(seq_x)\n        y.append(seq_y)\n    return np.array(X), np.array(y)","f5089d8c":"window = 2\nnum_features = 1\n\nX, y = getTimeSeriesData(list(sampled2d[\"INDIA\"]), window=window)\nprint(\"X:\", X.shape)\nprint(\"Y:\", y.shape)\n\n# We need to add one more dimension to X, i.e Num of features in 1 sample of time step. as we are doing a univariate prediction which means number of features are 1 only\nX = X.reshape((X.shape[0], X.shape[1], num_features))  # For LSTM\nprint(\"-----------\")\nprint(\"X:\", X.shape)\nprint(\"Y:\", y.shape)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\nprint(\"-----------\")\nprint(\"X train:\", X_train.shape)\nprint(\"y train:\", y_train.shape)\nprint(\"X test:\", X_test.shape)\nprint(\"y test:\", y_test.shape)","97908979":"# Define Model\nmodel = Sequential()\nmodel.add(LSTM(7, activation='relu', input_shape=(window, num_features)))\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam', loss='mse')\nhistory = model.fit(X_train, y_train, epochs=5, verbose=1)","1bcfa404":"plt.plot(history.history[\"loss\"])\n# plt.plot(history.history[\"val_loss\"])\nplt.title(\"Model Loss\")\nplt.ylabel('Loss')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.show()","79c006ff":"yPred = model.predict(X_test, verbose=0)\nyPred.shape = yPred.shape[0]","5e55f741":"plt.figure(figsize=(30,5))\nsns.set(rc={\"lines.linewidth\": 8})\nsns.lineplot(x=np.arange(y_test.shape[0]), y=y_test, color=\"green\")\nsns.set(rc={\"lines.linewidth\": 3})\nsns.lineplot(x=np.arange(y_test.shape[0]), y=yPred, color=\"coral\")\nplt.margins(x=0, y=0.5)\nplt.legend([\"Original\", \"Predicted\"])","aa8d7bf2":"points = 200\nplt.figure(figsize=(30,5))\nsns.set(rc={\"lines.linewidth\": 8})\nsns.lineplot(x=np.arange(points), y=y_test[:points], color=\"green\")\nsns.set(rc={\"lines.linewidth\": 3})\nsns.lineplot(x=np.arange(points), y=yPred[:points], color=\"coral\")\nplt.margins(x=0, y=0.5)\nplt.legend([\"Original\", \"Predicted\"])","6abfaaad":"### Compare initial records with complete records","8fcec815":"## Data Preprocessing","5eeb91ad":"### Interpolate missing data","6719fd43":"### Lets see how well we did it","c305f10d":"### Well its working pretty great in univariate itself in just 5 epochs\n\n## Please upvote if you Like\n","2e54822a":"So far so good, we have created a full series data which is almost same as original one. \n\n\n#### Why we created a complete time series data ?\n\n1. It enables us to resample the data, and now we can try to see seasonality pattern(In any) in the data on different time scale.\n2. Resampling data on a larger scale will reduce the amount of error induced by inputing values using `bfill and ffill`\n3. We can create different models on different sampled data and compare their accuracy","f80461f1":"## Now Lets create a Task\n\n### We want to predict stock exchange value of INR (INDIAN curreny) \n1. Using only values of Indian stock (Univariate)\n2. Using other countries stock values as well (Multivariate)","ba4d8f40":"##### lets zoom it a bit","153a103b":"Before proceding further we need to convert the data into a proper time steps data from which a ML model can learn something(A pattern or seasonality)\n\nFor example: If we keep a time window of 3 steps, then data A will be converted to X and Y\n\n`A = [1, 2, 3, 4, 5, 6, 7, 8]`\n\n\n`X = [[1, 2, 3],\n     [2, 3, 4],\n     [3, 4, 5],\n     [4, 5, 6],\n     [5, 6, 7]]`\n     \n     \n`Y = [4,\n      5,\n      6,\n      7,\n      8]`\n\n`\nX.shape = (5, 3)\nY.shape = (5,)`"}}