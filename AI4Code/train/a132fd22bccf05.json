{"cell_type":{"2c8707c3":"code","d6f38f4b":"code","976b08e0":"code","48ea706e":"code","eff234d5":"code","65661135":"code","fe5d3903":"code","db62842c":"code","2002dab0":"code","9bde1560":"code","b8f22908":"code","f4c68dbe":"code","4aecf325":"code","ae7cf416":"code","34455b07":"code","6e1e3068":"code","1bc549f4":"code","a5ecd511":"code","b2d1b6a4":"code","f954a187":"code","dfd6c490":"code","825d1e11":"code","54119fde":"code","17a2cabf":"code","85d2585c":"code","917f3a6c":"code","1e4211f7":"code","80e790fb":"code","4ef56447":"code","12191fcb":"code","e0f91315":"code","40fe6682":"code","e33060f5":"code","2d1ef950":"code","8570b00b":"code","bc2c4f64":"code","82f51350":"code","cd85009c":"code","9c4caf1f":"code","5c2fc375":"code","5732fb6c":"code","b105ecfe":"code","bc9bbf91":"code","90733c3a":"code","38d96e46":"code","15634e6a":"code","f6b253ab":"code","b31d39b5":"code","0b5a4b44":"code","f3d10f2b":"code","ec0943f4":"code","c855a5d7":"code","3dec6383":"code","1fbc69e3":"code","311e2c58":"code","928edb54":"code","dcc4ee61":"code","5a408ff0":"code","2532314a":"code","ff840fff":"code","8d5578b3":"code","eeb491f2":"code","a1c3ea2f":"code","0b484bb1":"code","8215b482":"code","ad41201d":"code","701ab808":"code","6166397c":"code","41a715fc":"code","3d4cd75e":"code","8adf86ed":"code","f7ed6497":"code","4b8305a0":"code","a76b0788":"code","8b04dc3a":"code","a432db6c":"code","aed97714":"code","72d88311":"code","19616cca":"code","35503dd9":"code","b3ab9e30":"code","28aa3c04":"code","73b89fda":"code","2db655e4":"code","e0a97bdc":"code","676c077d":"code","0074c22a":"code","e2823f5b":"code","85f87c12":"code","aa202e7f":"code","686319fc":"code","1c5dc0a0":"code","dcfe9849":"code","6d9b2886":"code","d554df19":"code","657ce4ff":"code","684c8568":"code","ff8a625c":"code","fe024b5e":"code","7e96d06a":"code","aea0026e":"code","e757e77f":"code","70caed57":"code","d76b2c55":"code","3959549b":"code","f1f1bfa8":"code","d198ac23":"code","c36a5b87":"code","9ea19a1d":"code","5052cfe4":"code","75c538fa":"code","5c4deafd":"code","edfc1515":"code","e92edebc":"code","99162e56":"code","3c3bd0e9":"code","afff9dfa":"code","0535b374":"code","d4e0acaf":"code","52ab17fb":"code","bb4251f2":"code","c7d711d9":"code","31b1602b":"code","7925f069":"code","9170e0a6":"code","19ef1b6e":"code","8341c0bd":"code","50af9648":"code","21eb6269":"code","3c980950":"code","17dc4af8":"code","ec354172":"markdown","0eb3772c":"markdown","4ce477c0":"markdown","ad54358a":"markdown","52b14841":"markdown","ed91d1e7":"markdown","5df67b11":"markdown","1953c1b4":"markdown","6f4d718a":"markdown","47509746":"markdown","6587c5d8":"markdown","f3690f8d":"markdown","03586fe8":"markdown","8094d73f":"markdown","690c0580":"markdown","547c9789":"markdown","6938a5f6":"markdown","4d6e8aa4":"markdown","98096c53":"markdown"},"source":{"2c8707c3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import r2_score\nfrom sklearn.feature_selection import RFE\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import precision_recall_curve\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nimport statsmodels.api as sm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns',500)\npd.set_option('display.max_rows',500)","d6f38f4b":"train = pd.read_csv('..\/input\/titanic\/train.csv')\n# train = pd.read_csv('train.csv')","976b08e0":"train.head()","48ea706e":"train.shape","eff234d5":"train.info()","65661135":"train.describe(percentiles=[0.25,0.50,0.75,0.95,0.99])","fe5d3903":"train.isnull().sum()\/len(train)","db62842c":"#We will check the percentile, mean and mode of the age\n#Mode\n\ntrain.Age.value_counts(normalize=True)","2002dab0":"#Percentiles\ntrain.Age.describe(percentiles=[0.25,0.50,0.75,0.95,0.99])","9bde1560":"#mean\ntrain.Age.mean()","b8f22908":"#filling na values with the 50 percentile\/median\ntrain['Age'] = train.Age.fillna(train.Age.median())","f4c68dbe":"#age after treating missing values\ntrain.Age.value_counts(ascending=False)","4aecf325":"train.Age.describe()","ae7cf416":"#Binning age into groups\n\ndef agegroup(x):\n    if x < 20:\n        return 'Kids'\n    elif x >= 20 and x <35:\n        return 'Adults'\n    elif x >= 35 and x <60:\n        return 'Middle Age'\n    else:\n        return 'Senior Citizen'\n","34455b07":"# Here we have created the age group column based on above parameters\n\ntrain['Age_Group'] = train['Age'].apply(agegroup)\ntrain.head()","6e1e3068":"#since 'Cabin' has missing values of 0.77, we will create a new category 'NA'\n\ntrain.Cabin.fillna('NA',inplace=True)","1bc549f4":"#Unique Values for 'Cabin'\ntrain.Cabin.unique()","a5ecd511":"#As the cabin represents wheater it is first class, second class or third class; we will create a new column as 'Cabin_class'\n\nlist_a = []\nlist_b = []\nlist_c = []\nlist_d = []\nlist_e = []\nlist_f = []\n\nfor i in train['Cabin']:\n    if i.startswith('A'):\n        list_a.append(i)\n    if i.startswith('B'):\n        list_b.append(i)\n    if i.startswith('C'):\n        list_c.append(i)\n    if i.startswith('D'):\n        list_d.append(i)\n    if i.startswith('E'):\n        list_e.append(i)\n    if i.startswith('F'):\n        list_f.append(i)","b2d1b6a4":"train['Cabin_class'] = train['Cabin'].replace(list_a,'A Deck').replace(list_b,'B Deck').replace(list_c,'C Deck').replace(list_d,'D Deck').replace(list_e,'E Deck').replace(list_f,'F Deck').replace('G6','G Deck').replace('T','Boat Deck')","f954a187":"train.Cabin_class.unique()","dfd6c490":"#Checking mode for 'Embarked'\n\ntrain.Embarked.mode()","825d1e11":"#filling na with the mode\n\ntrain['Embarked'] = train.Embarked.fillna(train.Embarked.mode()[0])","54119fde":"train.Embarked.value_counts()","17a2cabf":"#let's recheck the missing values\ntrain.isnull().sum()","85d2585c":"train.head()","917f3a6c":"train.info()","1e4211f7":"#unique values for 'Sex'\n\ntrain.Sex.unique()","80e790fb":"#unique values for 'Embarked'\n\ntrain.Embarked.unique()","4ef56447":"#dividing columns into categorical and numerical\n\nnum = train.describe(percentiles=[0.25,0.50,0.75,0.95,0.99]).columns.to_list()\nnum = num[2:]\ncat = train.select_dtypes('object').columns.to_list()","12191fcb":"\nnum","e0f91315":"#checking the outliers for numerical columns\n\nfor i in num:\n    sns.boxplot(train[i])\n    plt.title(i)\n    plt.tight_layout()\n    plt.show()","40fe6682":"#let's check the percentile again for the numericals\n\ntrain.describe(percentiles=[0.25,0.50,0.75,0.95,0.99])","e33060f5":"#filtering the outliers for age - less than equal to 99 percentile\ntrain = train[train['Age'] <= train['Age'].quantile(0.99)]","2d1ef950":"#filtering the outliers for SibSp - less than equal to 99 percentile\ntrain = train[train['SibSp'] <= train['SibSp'].quantile(0.99)]","8570b00b":"#filtering the outliers for Fare - less than equal to 99 percentile\ntrain = train[train['Fare'] <= train['Fare'].quantile(0.99)]","bc2c4f64":"#structure of train dataset after missing values and outliers treatment\n\ntrain.shape","82f51350":"#let's check the numericals after the outlier treatment\n\n#Fare\n\nplt.figure(figsize=(10,5))\n\nsns.violinplot(data=train, x='Survived', y='Fare')\n\nplt.xlabel(\"Survived\", fontsize=10)\nplt.ylabel(\"Fare\", fontsize=10)\nplt.title(\"Fare vs Survival\")\n\nplt.show()","cd85009c":"#Age\n\nplt.figure(figsize=(10,5))\n\nsns.violinplot(data=train, x='Survived', y='Age')\n\nplt.xlabel(\"Survived\", fontsize=10)\nplt.ylabel(\"Age\", fontsize=10)\nplt.title(\"Age vs Survival\")\n\nplt.show()","9c4caf1f":"#SibSp\n\nplt.figure(figsize=(10,5))\n\nsns.violinplot(data=train, x='Survived', y='SibSp')\n\nplt.xlabel(\"Survived\", fontsize=10)\nplt.ylabel(\"SibSp\", fontsize=10)\nplt.title(\"SibSp vs Survival\")\n\nplt.show()","5c2fc375":"#Parch\n\nplt.figure(figsize=(10,5))\n\nsns.violinplot(data=train, x='Survived', y='Parch')\n\nplt.xlabel(\"Survived\", fontsize=10)\nplt.ylabel(\"Parch\", fontsize=10)\nplt.title(\"Parch vs Survival\")\n\nplt.show()","5732fb6c":"#Removing the Name from the cat as they are not relevent for our analysis\ncat.remove('Name')","b105ecfe":"#Removing the Cabin from the cat as they are not relevent for our analysis\ncat.remove('Cabin')","bc9bbf91":"#Removing the Ticket from the cat as they are not relevent for our analysis\ncat.remove('Ticket')","90733c3a":"#Sex\n\nsns.countplot(train.Sex,hue=train.Survived)\n\nplt.show()","38d96e46":"#Age_Group\n\nsns.countplot(train.Age_Group,hue=train.Survived)\n\nplt.show()","15634e6a":"#Cabin_class\n\nsns.countplot(train.Cabin_class,hue=train.Survived)\n\nplt.xticks(rotation=75)\n\nplt.show()","f6b253ab":"#Embarked\n\nsns.countplot(train.Embarked,hue=train.Survived)\n\nplt.show()","b31d39b5":"sns.pairplot(train, vars=train[num],hue='Survived',palette='terrain')\n\nplt.show()","0b5a4b44":"#correlations within numerical variables\n\nplt.figure(figsize=[6,7])\nsns.heatmap(train.corr(),annot=True,fmt='.2f',cmap='YlOrBr')\nplt.show()","f3d10f2b":"#Sex and Age_Group\n\n# plt.figure(figsize=[12,12])\n\nsns.heatmap(pd.pivot_table(data=train , columns= 'Sex' , index='Age_Group' ,values = 'Survived')  , annot=True, cmap = 'Blues')\n\nplt.show()","ec0943f4":"#Embarked and Age_Group\n\n# plt.figure(figsize=[12,12])\n\nsns.heatmap(pd.pivot_table(data=train , columns= 'Embarked' , index='Age_Group' ,values = 'Survived')  , annot=True, cmap = 'Greens')\n\nplt.show()","c855a5d7":"#Embarked and Sex\n\n# plt.figure(figsize=[12,12])\n\nsns.heatmap(pd.pivot_table(data=train , columns= 'Embarked' , index='Sex' ,values = 'Survived')  , annot=True, cmap = 'Reds')\n\nplt.show()","3dec6383":"#Cabin_class and Age_Group \n\n# plt.figure(figsize=[12,12])\n\nsns.heatmap(pd.pivot_table(data=train , index= 'Cabin_class' , columns='Age_Group' ,values = 'Survived')  , annot=True, cmap = 'PuRd')\n\nplt.show()","1fbc69e3":"#Sex vs Fare\n\nfig, (axes) = plt.subplots(2, figsize=(7,10))\n\nsns.boxplot(data=train,x='Sex',y='Fare',ax=axes[0])\n\nsns.barplot(data=train,x='Sex',y='Survived',ax=axes[1])\n\nplt.show()","311e2c58":"#Embarked vs Fare\n\nfig, (axes) = plt.subplots(2,figsize=(7,10))\n\nsns.boxplot(data=train,x='Embarked',y='Fare',ax=axes[0])\n\nsns.barplot(data=train,x='Embarked',y='Survived',ax=axes[1])\n\nplt.show()","928edb54":"#Age_Group vs Fare\n\nfig, (axes) = plt.subplots(2,figsize=(7,10))\n\nsns.boxplot(data=train,x='Age_Group',y='Fare',ax=axes[0])\n\nsns.barplot(data=train,x='Age_Group',y='Survived',ax=axes[1])\n\n \nplt.show()","dcc4ee61":"#Embarked vs Age\n\nfig, (axes) = plt.subplots(2,figsize=(7,10))\n\nsns.boxplot(data=train,x='Embarked',y='Age',ax=axes[0])\n\nsns.barplot(data=train,x='Embarked',y='Survived',ax=axes[1])\n\n \nplt.show()","5a408ff0":"#Sex vs Age\n\nfig, (axes) = plt.subplots(2,figsize=(7,10))\n\nsns.boxplot(data=train,x='Sex',y='Age',ax=axes[0])\n\nsns.barplot(data=train,x='Sex',y='Survived',ax=axes[1])\n\n \nplt.show()","2532314a":"lis = ['No', 'Yes']\nbinCol = []\nfor c in cat:\n    if train[c].unique().tolist()[0] in lis:\n        binCol.append(c)\nbinCol","ff840fff":"# Defining the map function\ndef binary_map(x):\n    return x.map({'Yes': 1, \"No\": 0})\n\n# Applying the function to the list\ntrain[binCol] = train[binCol].apply(binary_map)","8d5578b3":"cols = []\nfor c in cat:\n    if c not in binCol:\n        cols.append(c)\ncols","eeb491f2":"#unwanted columns\nno_list = ['Name', 'Cabin', 'Ticket']","a1c3ea2f":"cols = [e for e in cols if e not in no_list]","0b484bb1":"cols","8215b482":"dummy = pd.get_dummies(train[cols],drop_first=True)\ndummy","ad41201d":"new_train = pd.concat([train, dummy], axis=1)","701ab808":"new_train.head()","6166397c":"new_train.shape","41a715fc":"new_train.drop(cols,inplace=True, axis =1)","3d4cd75e":"dropList = []\nfor c in new_train.columns.to_list():\n    if 'NA' in c:\n        dropList.append(c)\ndropList","8adf86ed":"new_train.drop(dropList,inplace=True, axis =1)","f7ed6497":"new_train.shape","4b8305a0":"new_train.head()","a76b0788":"X = new_train.drop(['Name', 'Ticket','Cabin','Survived','PassengerId'], axis=1)\nX.head()","8b04dc3a":"# Checking the correlation \n\nplt.figure(figsize=[15,15])\n\nsns.heatmap(X.corr(),annot=True,fmt='.2f')\n\nplt.show()","a432db6c":"y = new_train['Survived']","aed97714":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)","72d88311":"X_train.shape","19616cca":"X_test.shape","35503dd9":"y_train.shape","b3ab9e30":"y_test.shape","28aa3c04":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier(max_depth=5)\ndt.fit(X_train, y_train)","73b89fda":" !pip install pydotplus","2db655e4":"# Importing required packages for visualization\n\nfrom IPython.display import Image  \nfrom six import StringIO\nfrom sklearn.tree import export_graphviz\nfrom sklearn.tree import export_graphviz\nimport pydotplus, graphviz","e0a97bdc":"# plotting tree with max_depth=3\ndot_data = StringIO()  \n\nexport_graphviz(dt, out_file=dot_data, filled=True, rounded=True,\n                feature_names=X.columns, \n                class_names=['Not Survived', \"Survived\"])\n\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())\nImage(graph.create_png())","676c077d":"y_train_pred = dt.predict(X_train)\ny_test_pred = dt.predict(X_test)","0074c22a":"from sklearn.metrics import confusion_matrix, accuracy_score","e2823f5b":"# Confusion matrix \nprint(accuracy_score(y_train, y_train_pred))\nconfusion_matrix(y_train, y_train_pred)","85f87c12":"print(accuracy_score(y_test, y_test_pred))\nconfusion_matrix(y_test, y_test_pred)","aa202e7f":"test = pd.read_csv('..\/input\/titanic\/test.csv')\n# test = pd.read_csv('test.csv')","686319fc":"test.head()","1c5dc0a0":"test.info()","dcfe9849":"test.describe()","6d9b2886":"test.shape","d554df19":"test.isnull().sum()","657ce4ff":"#We will check the percentile, mean and mode of the age\n#Mode\n\ntest.Age.value_counts(normalize=True)","684c8568":"#Percentiles\ntest.Age.describe(percentiles=[0.25,0.50,0.75,0.95,0.99])","ff8a625c":"#mean\ntest.Age.mean()","fe024b5e":"#filling na values with the 50 percentile\/median\ntest['Age'] = test.Age.fillna(test.Age.median())","7e96d06a":"#age after treating missing values\ntest.Age.value_counts(ascending=False)","aea0026e":"test.shape","e757e77f":"#Percentiles\ntest.Fare.describe(percentiles=[0.25,0.50,0.75,0.95,0.99])","70caed57":"#mean\ntest.Fare.mean()","d76b2c55":"#filling na values with the 50 percentile\/median\ntest['Fare'] = test.Fare.fillna(test.Fare.median())","3959549b":"#since 'Cabin' has missing values more than 300, we will create a new category 'NA'\n\ntest.Cabin.fillna('NA',inplace=True)","f1f1bfa8":"#Unique Values for 'Cabin'\ntest.Cabin.unique()","d198ac23":"#As the cabin represents wheater it is first class, second class or third class; we will create a new column as 'Cabin_class'\n\nlist_a = []\nlist_b = []\nlist_c = []\nlist_d = []\nlist_e = []\nlist_f = []\n\nfor i in test['Cabin']:\n    if i.startswith('A'):\n        list_a.append(i)\n    if i.startswith('B'):\n        list_b.append(i)\n    if i.startswith('C'):\n        list_c.append(i)\n    if i.startswith('D'):\n        list_d.append(i)\n    if i.startswith('E'):\n        list_e.append(i)\n    if i.startswith('F'):\n        list_f.append(i)","c36a5b87":"test['Cabin_class'] = test['Cabin'].replace(list_a,'A Deck').replace(list_b,'B Deck').replace(list_c,'C Deck').replace(list_d,'D Deck').replace(list_e,'E Deck').replace(list_f,'F Deck').replace('G6','G Deck').replace('T','Boat Deck')","9ea19a1d":"test.isnull().sum()","5052cfe4":"#dividing columns into categorical and numerical\n\nnum = test.describe(percentiles=[0.25,0.50,0.75,0.95,0.99]).columns.to_list()\nnum = num[1:]\ncat = test.select_dtypes('object').columns.to_list()","75c538fa":"print('Categorical',cat)\nprint('Numerical',num)","5c4deafd":"#checking the outliers for numerical columns\n\nfor i in num:\n    sns.boxplot(test[i])\n    plt.title(i)\n    plt.tight_layout()\n    plt.show()","edfc1515":"#structure of train dataset after missing values and outliers treatment\n\ntest.shape","e92edebc":"lis = ['No', 'Yes']\nbinCol = []\nfor c in cat:\n    if test[c].unique().tolist()[0] in lis:\n        binCol.append(c)\nbinCol","99162e56":"# Defining the map function\ndef binary_map(x):\n    return x.map({'Yes': 1, \"No\": 0})\n\n# Applying the function to the list\ntest[binCol] = test[binCol].apply(binary_map)","3c3bd0e9":"cols = []\nfor c in cat:\n    if c not in binCol:\n        cols.append(c)\ncols","afff9dfa":"#unwanted columns\nno_list = ['Name', 'Cabin', 'Ticket']","0535b374":"cols = [e for e in cols if e not in no_list]","d4e0acaf":"cols","52ab17fb":"dummy = pd.get_dummies(test[cols],drop_first=True)\ndummy.head()","bb4251f2":"new_test = pd.concat([test, dummy], axis=1)","c7d711d9":"new_test.head()","31b1602b":"new_test.shape","7925f069":"new_test.drop(cols,inplace=True, axis =1)","9170e0a6":"dropList = []\nfor c in new_test.columns.to_list():\n    if 'NA' in c:\n        dropList.append(c)\ndropList","19ef1b6e":"dropList.append('Cabin')","8341c0bd":"dropList.append('PassengerId')","50af9648":"new_test.drop(dropList,inplace=True, axis =1)","21eb6269":"new_test = new_test.drop('Name',axis=1)","3c980950":"new_test.shape","17dc4af8":"y = new_train[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex_male\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(new_train[features])\nX_test = pd.get_dummies(new_test[features])\n\ndt.fit(X, y)\npredictions = dt.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","ec354172":"#### Test-Train Split","0eb3772c":"#### Creating Dummy Variables :","4ce477c0":"#### Data Preparation\n\n##### Converting Binary Variables into 0-1","ad54358a":"###### Categorical Analysis","52b14841":"#### Importing Train and Test dataset","ed91d1e7":"#### Data Cleaning ","5df67b11":"###### Categorical vs Numerical Analysis","1953c1b4":"#### Calculating Different Metrics for Model Evaluation :","6f4d718a":"#### Outliers check","47509746":"### The Challenge\n\n\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\n\nOn April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\n\nIn this challenge, we ask you to build a predictive model that answers the question: \u201cwhat sorts of people were more likely to survive?\u201d using passenger data (ie name, age, gender, socio-economic class, etc).\n\n\n\n#### Importing the libraries","6587c5d8":"#### Bivariate Analysis\n\n###### Numerical Analysis","f3690f8d":"#### Checking the structure","03586fe8":"###### Categorical Analysis","8094d73f":"#### Checking the unique values for the categorical data","690c0580":"#### Creating Dummy Variables :","547c9789":"#### Outliers check","6938a5f6":"#### Univariate Analysis\n\n###### Numerical Analysis","4d6e8aa4":"### Importing the test data set","98096c53":"#### Data Preparation\n\n##### Converting Binary Variables into 0-1"}}