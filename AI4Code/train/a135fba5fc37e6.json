{"cell_type":{"f5792a84":"code","cb36d4f1":"code","bb82eae7":"code","5e16d77b":"code","c7ecaa66":"code","cec0ffdf":"code","8c2686c6":"code","1b94d907":"code","cd9f66e7":"code","e887f1e9":"code","01fd1e34":"code","4b3dee02":"code","02c1ae39":"code","d901b328":"code","02d164fb":"code","5d880c8d":"code","b14442bc":"code","b2975158":"code","fc9980e1":"markdown","c3203a27":"markdown","a6e70c37":"markdown","ad75a602":"markdown","6f8e2a7a":"markdown","434f1f67":"markdown","47c0ee69":"markdown"},"source":{"f5792a84":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cb36d4f1":"import numpy as np\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.models import Model, load_model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nfrom keras.initializers import glorot_uniform\nimport scipy.misc\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\n%matplotlib inline\n\nimport keras.backend as K\nK.set_image_data_format('channels_last')\nK.set_learning_phase(1)","bb82eae7":"X_orig = np.load(\"..\/input\/sign-language-digits-dataset\/X.npy\")\nY_orig = np.load(\"..\/input\/sign-language-digits-dataset\/Y.npy\")","5e16d77b":"print(X_orig.shape)\nprint(Y_orig.shape)","c7ecaa66":"#reshape X_orig\nX_orig = X_orig.reshape(-1,64,64,1)\nX_orig.shape","cec0ffdf":"plt.figure(figsize=(20,6))\n\nfor i,j in enumerate([0,205,411,617,823,1030,1237,1444,1650,1858]):\n    plt.subplot(2,5,i+1)\n    plt.imshow(X_orig[j].reshape(64,64))\n    plt.title(np.argmax(Y_orig[j]))\n    plt.axis(\"off\")","8c2686c6":"label_y = []\n\nlabel_y = [np.where(i==1)[0][0] for i in Y_orig]\ncount = pd.Series(label_y).value_counts()\nprint(count)","1b94d907":"#lets reorganize\n\nX_organized = np.concatenate((X_orig[204:409,:],\n                              X_orig[822:1028,:],\n                              X_orig[1649:1855,:],\n                              X_orig[1443:1649,:],\n                              X_orig[1236:1443,:],\n                              X_orig[1855:2062,:],\n                              X_orig[615:822,:],\n                              X_orig[409:615,:],\n                              X_orig[1028:1236,:],\n                              X_orig[0:204,:]),axis = 0)","cd9f66e7":"plt.figure(figsize=(20,6))\n\nfor i,j in enumerate([0,205,411,617,823,1030,1237,1444,1650,1858]):\n    plt.subplot(2,5,i+1)\n    plt.imshow(X_organized[j].reshape(64,64))\n    plt.title(np.argmax(Y_orig[j]))\n    plt.axis(\"off\")","e887f1e9":"from sklearn.model_selection import train_test_split\n\ntrain_x,test_x,train_y,test_y = train_test_split(X_orig,Y_orig,test_size=0.2)\nprint(train_x.shape)\nprint(train_y.shape)\nprint(test_x.shape)\nprint(test_y.shape)","01fd1e34":"def identity_block(X, f, filters):\n    \"\"\"\n    Arguments:\n    X -- input shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- shape of the middle CONV's window for the main path\n    filters -- number of filters in the CONV layers of the main path\n    Returns:\n    X -- output of shape (n_H, n_W, n_C)\n    \"\"\"\n    \n    # Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value. \n    X_shortcut = X\n    \n    # First component\n    X = Conv2D(filters = F1, kernel_size =(1,1), strides = (1,1), padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X)\n    X = Activation('relu')(X)\n        \n    # Second component\n    X = Conv2D(filters= F2, kernel_size=(f,f), strides=(1,1),padding='same',kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3)(X)\n    X = Activation('relu')(X)\n\n    # Third component\n    X = Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding='valid',kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3)(X)\n\n    # Final step\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X","4b3dee02":"def convolutional_block(X, f, filters,s = 2):\n    \"\"\"\n    X -- input shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- shape of the middle CONV's window for the main path\n    filters --number of filters\n    s -- stride\n    Returns:\n    X -- output of the convolutional block shape (n_H, n_W, n_C)\n    \"\"\"\n    #Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n    # First component\n    X = Conv2D(F1, (1,1), strides = (s,s), padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X)\n    X = Activation('relu')(X)\n\n    # Second component\n    X = Conv2D(F2, (f,f), strides = (1,1),padding='same',kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X)\n    X = Activation('relu')(X)\n\n    # Third component\n    X = Conv2D(F3, (1,1), strides = (1,1), padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X)\n\n    #SHORTCUT PATH\n    X_shortcut = Conv2D(F3, (1,1),strides = (s,s),padding='valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis =3)(X_shortcut)\n\n    # Final step\n    X = Add()([X,X_shortcut])\n    X = Activation('relu')(X)  \n    return X","02c1ae39":"def ResNet50(input_shape = (64, 64, 1), classes = 10):\n    \"\"\"\n    input_shape -- shape of the images of the dataset\n    classes -- integer, number of classes\n\n    Returns:\n    model\n    \"\"\"\n    \n    # Define the input with shape input_shape\n    X_input = Input(input_shape)\n\n    \n    # Zero-Padding\n    X = ZeroPadding2D((3, 3))(X_input)\n    \n    # Stage 1\n    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    # Stage 2\n    X = convolutional_block(X, f = 3, filters = [64, 64, 256],s = 1)\n    X = identity_block(X, 3, [64, 64, 256])\n    X = identity_block(X, 3, [64, 64, 256])\n\n    # Stage 3\n    X = convolutional_block(X,f=3,filters=[128,128,512],s=2)\n    X = identity_block(X,3,[128,128,512])\n    X = identity_block(X,3,[128,128,512])\n    X = identity_block(X,3,[128,128,512])\n    \n    # Stage 4\n    X = convolutional_block(X,f=3,filters=[256,256,1024],s=2)\n    X = identity_block(X,3,[256,256,1024])\n    X = identity_block(X,3,[256,256,1024])\n    X = identity_block(X,3,[256,256,1024])\n    X = identity_block(X,3,[256,256,1024])\n    X = identity_block(X,3,[256,256,1024])\n\n    # Stage 5\n    X = convolutional_block(X,f=3,filters=[512,512,2048],s=2)\n    X = identity_block(X,3,[512,512,2048])\n    X = identity_block(X,3,[512,512,2048])\n\n    # AVGPOOL\n    X = AveragePooling2D((2,2),name=\"avg_pool\")(X)\n\n    # output layer\n    X = Flatten()(X)\n    X = Dense(classes, activation='softmax',kernel_initializer = glorot_uniform(seed=0))(X)\n    \n    # Create model\n    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n\n    return model","d901b328":"model = ResNet50(input_shape=(64,64,1),classes=10)","02d164fb":"#Compile\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","5d880c8d":"#fit the training set\nmodel.fit(train_x, train_y, epochs = 20, batch_size = 32)","b14442bc":"evals = model.evaluate(test_x,test_y)\nprint(\"loss\" +str(evals[0]))\nprint(\"accuracy\" +str(evals[1]))","b2975158":"model.summary()","fc9980e1":"### ResNet","c3203a27":"#### Now labels and images are matching with each other... Lets split the data into train and test","a6e70c37":"##### The ResNet \"convolutional block\" is the second block type. You can use this type of block when the input and output dimensions don't match up. The difference with the identity block is that there is a CONV2D layer in the shortcut path","ad75a602":"### Implementation of ResNet","6f8e2a7a":"### Identity Block\n\n##### The identity block is the standard block used in ResNets, and corresponds to the case where the input activation has the same dimension as the output activation ","434f1f67":"### Convolutional Block","47c0ee69":"#### here we can see that the label and the images don not match correctly so lets re-organize them"}}