{"cell_type":{"05e96f96":"code","3333cd8b":"code","ec119541":"code","4329454f":"code","b0409c51":"code","96b6701f":"code","b7134175":"code","4d033529":"code","359b5901":"code","8dc7cc2c":"code","6d175f3f":"code","d7354669":"code","d9d5959e":"code","4d82853b":"code","d38ebcd7":"code","d515f051":"code","fa08d377":"markdown","e02cb18e":"markdown"},"source":{"05e96f96":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3333cd8b":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split","ec119541":"df=pd.read_csv('..\/input\/imdb-dataset-sentiment-analysis-in-csv-format\/Train.csv')\ndf.head()","4329454f":"#shuffling data\ndf = df.sample(frac=1, axis=1).reset_index(drop=True)","b0409c51":"df.groupby('label').count()","96b6701f":"import seaborn as sns\nsns.countplot(df['label'])","b7134175":"\nx_train,x_test,y_train,y_test= train_test_split(df['text'],df['label'],test_size=0.2)","4d033529":"vocab_size=600\noov_tok='<OOV>'","359b5901":"token=Tokenizer(num_words=vocab_size,oov_token=oov_tok)\ntoken.fit_on_texts(x_train)","8dc7cc2c":"wordIndex=token.word_index\nsequences=token.texts_to_sequences(x_train)\ntrain_padded_seq=pad_sequences(sequences,maxlen=60,padding='post',truncating='post')","6d175f3f":"#testing data\ntest_sequences=token.texts_to_sequences(x_test)\ntest_padded_seq=pad_sequences(test_sequences,maxlen=60,padding='post',truncating='post')","d7354669":"#model\nmodel=tf.keras.models.Sequential([tf.keras.layers.Embedding(vocab_size,16,input_length=60),\n                                  tf.keras.layers.GlobalAveragePooling1D(),\n                                  tf.keras.layers.Dense(32,activation='relu'),\n                                  tf.keras.layers.Dropout(0.4),\n                                  tf.keras.layers.Dense(64,activation='relu'),\n                                  tf.keras.layers.Dropout(0.3),\n                                  tf.keras.layers.Dense(1,activation='sigmoid')\n                                  \n                                  \n    \n])","d9d5959e":"model.summary()","4d82853b":"model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),metrics=['accuracy'],optimizer='adam')","d38ebcd7":"earlyStop=tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=2)\nhistory=model.fit(train_padded_seq,y_train,validation_data=(test_padded_seq,y_test),epochs=10\n                  ,callbacks=[earlyStop])","d515f051":"model.evaluate(test_padded_seq, y_test)","fa08d377":"check dataset is balanced or not","e02cb18e":"This notebook is about the sentiment analysis using Tensorflow and embedding layer.. Do upvote"}}