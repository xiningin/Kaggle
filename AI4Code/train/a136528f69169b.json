{"cell_type":{"25ddea8e":"code","71b10477":"code","45623f2f":"code","e49ed80c":"code","8e9833ae":"code","70f55c2a":"code","44b215a7":"code","cbcbed84":"code","e14ffcf1":"code","c8ab7505":"code","fe4b39f8":"code","2c4461da":"code","ab3e17e8":"code","20a13b23":"code","793b038f":"code","175b959b":"code","9d130af4":"code","e5fd22f7":"code","a1b56a57":"code","5f0d50b2":"code","0bafcbc2":"code","663ecc4e":"code","5de82921":"code","6b909976":"code","677e9dc3":"code","d861a1aa":"code","35dc098f":"code","2bf824e6":"code","968037e8":"code","bab5b146":"code","42c3c139":"code","7a851239":"code","69ae7c68":"code","bf136dcf":"code","c9c31a89":"code","80e469e0":"code","cd3e612c":"code","4113531c":"code","04db9912":"code","d0187569":"code","fa4c5ade":"code","79563cdf":"code","aa5e0e48":"code","503e2b79":"code","15c84c8b":"code","94c645c5":"code","7f28ee21":"code","0ac6dca3":"code","e06e6356":"code","4d80fa06":"code","af3d630e":"code","423d5adb":"code","7e280ed1":"code","e51f7419":"code","dac7014c":"code","d1bdda29":"code","445627bf":"code","67d1b2be":"code","329556a4":"code","992e6e2c":"markdown","77dfebbe":"markdown","e56f116c":"markdown","68cbd657":"markdown"},"source":{"25ddea8e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","71b10477":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt","45623f2f":"dataset_directory = \"\/kaggle\/input\/nyse\/\"","e49ed80c":"df = pd.read_csv(dataset_directory+\"prices.csv\", header=0)\ndf.head()","8e9833ae":"df.shape","70f55c2a":"df.info()","44b215a7":"df.describe()","cbcbed84":"df.duplicated().sum()","e14ffcf1":"df.isnull().sum()","c8ab7505":"df.symbol.unique()","fe4b39f8":"len(df.symbol.values)","2c4461da":"df.date.unique()","ab3e17e8":"comp_info = pd.read_csv(dataset_directory+\"securities.csv\")\ncomp_info.head()","20a13b23":"comp_info.shape","793b038f":"comp_info.info()","175b959b":"comp_info.describe()","9d130af4":"comp_info.isnull().sum()","e5fd22f7":"comp_info.duplicated().sum()","a1b56a57":"comp_info[\"Ticker symbol\"].unique()","5f0d50b2":"comp_info[\"Ticker symbol\"].nunique()","0bafcbc2":"comp_info.loc[comp_info.Security.str.startswith(\"Mic\"), :]","663ecc4e":"def combine_company_df(list_comp_name, col_name):\n    query_str = \"\"\n    for i in range(0, len(list_comp_name)):   \n        query_str += f'Security.str.startswith(\"{list_comp_name[i]}\")'\n        if i != len(list_comp_name)-1:\n            query_str += \" or \"\n            \n    return comp_info.query(query_str, engine='python')[col_name]","5de82921":"comp_plot = comp_info.loc[(comp_info.Security.str.startswith(\"Yahoo Inc.\")) | \n                          (comp_info.Security.str.startswith(\"Microsoft Corp.\"))|\n                          (comp_info.Security.str.startswith(\"Adobe Systems Inc\")) |\n                          (comp_info.Security.str.startswith(\"Facebook\")) | \n                          (comp_info.Security.str.startswith(\"Xerox Corp.\")) |\n                          (comp_info.Security.str.startswith(\"Goldman Sachs Group\")),\n                          [\"Ticker symbol\"]][\"Ticker symbol\"]\n\nprint(comp_plot)","6b909976":"list_comp_name = [\"Yahoo Inc.\", \"Microsoft Corp.\", \"Adobe Systems Inc\", \"Facebook\", \"Xerox Corp.\", \"Goldman Sachs Group\"]\ncomp_plot = combine_company_df(list_comp_name, \"Ticker symbol\")\ncomp_plot","677e9dc3":"def get_company_stock(comp_symbol):\n    company = df[df['symbol'] == comp_symbol]\n    return company","d861a1aa":"def plotter(comp_symbol, company):\n    figure, axes = plt.subplots(1,2,figsize=(16,8))\n    \n    plt.subplot(121)\n    plt.plot(company[\"date\"], company[\"open\"], 'g')\n    plt.xticks(rotation=90)\n    plt.xlabel('Time')\n    plt.ylabel(comp_symbol + \" open stock prices\")\n    plt.title('prices Vs Time')\n\n    plt.subplot(122)\n    plt.plot(company[\"date\"], company[\"close\"], 'r')\n    plt.xlabel('Time')\n    plt.xticks(rotation=90)\n    plt.ylabel(comp_symbol + \" close stock prices\")\n    plt.title('Prices Vs Time')\n    \n    plt.show()","35dc098f":"for comp_symbol in comp_plot:\n    company = get_company_stock(comp_symbol)\n    plotter(comp_symbol, company.tail(30))","2bf824e6":"company_symbol = \"YHOO\"\ncompany_state = \"close\"\n\nstock = get_company_stock(company_symbol)[company_state].values","968037e8":"stock = stock.reshape(len(stock) , 1)\nstock","bab5b146":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0,1))\nstock = scaler.fit_transform(stock)","42c3c139":"train_len = int(len(stock) * 0.80)\ntest_len = len(stock) - train_len","7a851239":"train = stock[0:train_len]\ntrain","69ae7c68":"test = stock[len(train):]\ntest","bf136dcf":"train = train.reshape(len(train), 1)\ntest = test.reshape(len(test), 1)\n\nprint(train.shape , test.shape)","c9c31a89":"def split_sequence(sequence, n_steps_in, n_steps_out):\n    data_x, data_y = list(), list()\n    for i in range(len(sequence)):\n        end_ix = i + n_steps_in\n        out_end_ix = end_ix + n_steps_out\n  \n        if out_end_ix > len(sequence):\n            break\n        \n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n        data_x.append(seq_x)\n        data_y.append(seq_y)\n    return np.array(data_x), np.array(data_y)","80e469e0":"n_steps_in, n_steps_out = 5, 1\nn_features = 1\n\ntrain_x, train_y = split_sequence(train, n_steps_in, n_steps_out)\ntest_x, test_y = split_sequence(test, n_steps_in, n_steps_out)","cd3e612c":"print(train_x.shape , train_y.shape)\nprint(test_x.shape , test_y.shape)","4113531c":"from sklearn.model_selection import GridSearchCV\nfrom sklearn import svm\n\n%time\nparam_grid = { \"kernel\": [\"poly\", \"rbf\"],\n               \"degree\": [3,4,5] }\n\ngrid = GridSearchCV(svm.SVR(), param_grid, refit=True, verbose=1)","04db9912":"train_x = train_x.reshape(len(train_x), n_steps_in)\ntrain_y = train_y.reshape(len(train_y), n_steps_out)\n\nprint(train_x.shape , train_y.shape)\n\ngrid.fit(train_x, train_y.ravel())\n\nprint(grid.best_params_)\nprint(grid.best_estimator_)","d0187569":"import joblib\n\nSVR_model_file = \"SVR_model.pkl\"\njoblib.dump(grid.best_estimator_, SVR_model_file, compress = 1)","fa4c5ade":"grid = joblib.load(SVR_model_file)","79563cdf":"test_y = test_y.reshape(test_y.shape[0] , 1)\ntest_y = scaler.inverse_transform(test_y)\ntest_y[:10]","aa5e0e48":"test_x = test_x.reshape(len(test_x), n_steps_in)\ntest_y = test_y.reshape(len(test_y), n_steps_out)\n\nprint(test_x.shape , test_y.shape)\n\npred = grid.predict(test_x)\npred = [[val] for val in pred] \npred = scaler.inverse_transform(pred)\npred[:10]","503e2b79":"from sklearn.metrics import mean_squared_error\n\nprint(\"MSE: \",mean_squared_error(test_y, pred))","15c84c8b":"print(\"Red - Predicted Stock Prices  ,  Blue - Actual Stock Prices\")\nplt.rcParams[\"figure.figsize\"] = (15,7)\nplt.plot(test_y, 'b')\nplt.plot(pred , 'r')\nplt.xlabel('Time')\nplt.ylabel('Stock Prices')\nplt.title('Check the accuracy of the model with time')\nplt.grid(True)\nplt.show()\n","94c645c5":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.layers import LSTM , GRU\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping","7f28ee21":"model_wieght_file = \"NYstock_wieght.hdf5\"\n\nlr_reduce = ReduceLROnPlateau(monitor=\"val_loss\", factor=0, min_delta=0.001, patience=1, verbose=1)\n\ncheckpoint = ModelCheckpoint(model_wieght_file, monitor=\"val_loss\", verbose=1, save_best_only=True, mode=\"max\")\n\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)","0ac6dca3":"model = Sequential()\n\nmodel.add(GRU(256 , input_shape = (n_steps_in , n_features) , return_sequences=True))\nmodel.add(Dropout(0.4))\nmodel.add(LSTM(256))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(64 ,  activation = 'relu'))\nmodel.add(Dense(1))\n\nmodel.summary()","e06e6356":"model.compile(loss=\"mean_squared_error\", \n              optimizer=Adam(lr=0.0005), \n              metrics=[\"mean_squared_error\"])","4d80fa06":"n_steps_in, n_steps_out = 5, 1\nn_features = 1\n\ntrain_x, train_y = split_sequence(train, n_steps_in, n_steps_out)\ntest_x, test_y = split_sequence(test, n_steps_in, n_steps_out)","af3d630e":"print(train_x.shape , train_y.shape)\nprint(test_x.shape , test_y.shape)","423d5adb":"history = model.fit(train_x, \n                    train_y, \n                    epochs=100 , \n                    callbacks = [checkpoint , lr_reduce, es], \n                    validation_data = (test_x,test_y))","7e280ed1":"plt.plot(history.history[\"mean_squared_error\"])\nplt.plot(history.history[\"val_mean_squared_error\"])\nplt.title(\"Mean Squared Error\")\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","e51f7419":"plt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"val_loss\"])\nplt.title('Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","dac7014c":"import math\n\ndef model_score(model, train_x, train_y, test_x, test_y):\n    train_score = model.evaluate(train_x, train_y, verbose=1)\n    print(\"Train score: %0.5f MSE(%.2f RMSE)\" % (train_score[0], math.sqrt(train_score[0])))\n    \n    test_score = model.evaluate(test_x, test_y, verbose=1)\n    print('Test Score: %.5f MSE (%.2f RMSE)' % (test_score[0], math.sqrt(test_score[0])))\n    ","d1bdda29":"model_score(model, train_x, train_y, test_x, test_y)","445627bf":"pred = model.predict(test_x)\npred = scaler.inverse_transform(pred)\npred[:10]","67d1b2be":"test_y = test_y.reshape(test_y.shape[0] , 1)\ntest_y = scaler.inverse_transform(test_y)\ntest_y[:10]","329556a4":"print(\"Red - Predicted Stock Prices  ,  Blue - Actual Stock Prices\")\nplt.rcParams[\"figure.figsize\"] = (15,7)\nplt.plot(test_y, 'b')\nplt.plot(pred , 'r')\nplt.xlabel('Time')\nplt.ylabel('Stock Prices')\nplt.title('Check the accuracy of the model with time')\nplt.grid(True)\nplt.show()\n\n","992e6e2c":"### Securities Dataset","77dfebbe":"### Dataset Directory","e56f116c":"### Prices Dataset","68cbd657":"## New York Stock Exchange"}}