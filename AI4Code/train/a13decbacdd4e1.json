{"cell_type":{"89494d76":"code","20948910":"code","4b17224e":"code","5c347748":"code","1bd6ca48":"code","12bed795":"code","8358f8e7":"code","480f95e2":"code","e503b8de":"code","bc609e7c":"markdown","ec761244":"markdown","35a3bf67":"markdown"},"source":{"89494d76":"from keras.models import load_model\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nimport keras.optimizers\nfrom ipywidgets import interact_manual\nfrom ipywidgets import widgets\nimport pickle\nimport numpy as np\nimport re","20948910":"import os\nprint(os.listdir(\"..\/input\"))","4b17224e":"def define_alphabet():\n    base_en = 'abcdefghijklmnopqrstuvwxyz'\n    special_chars = ' !?\u00bf\u00a1'\n    german = '\u00e4\u00f6\u00fc\u00df'\n    italian = '\u00e0\u00e8\u00e9\u00ec\u00ed\u00f2\u00f3\u00f9\u00fa'\n    french = '\u00e0\u00e2\u00e6\u00e7\u00e9\u00e8\u00ea\u00ea\u00ee\u00ef\u00f4\u0153\u00f9\u00fb\u00fc\u00ff'\n    spanish = '\u00e1\u00e9\u00ed\u00f3\u00fa\u00fc\u00f1'\n    czech = '\u00e1\u010d\u010f\u00e9\u011b\u00edj\u0148\u00f3\u0159\u0161\u0165\u00fa\u016f\u00fd\u017e'\n    slovak = '\u00e1\u00e4\u010d\u010fdzd\u017e\u00e9\u00ed\u013a\u013e\u0148\u00f3\u00f4\u0155\u0161\u0165\u00fa\u00fd\u017e'\n    all_lang_chars = base_en + german +  italian + french + spanish + czech + slovak\n    small_chars = list(set(list(all_lang_chars)))\n    small_chars.sort() \n    big_chars = list(set(list(all_lang_chars.upper())))\n    big_chars.sort()\n    small_chars += special_chars\n    letters_string = ''\n    letters = small_chars + big_chars\n    for letter in letters:\n        letters_string += letter\n    return small_chars,big_chars,letters_string","5c347748":"def get_sample_text(file_content,start_index,sample_size):\n\n    while not (file_content[start_index].isspace()):\n        start_index += 1\n    while file_content[start_index].isspace():\n        start_index += 1\n    end_index = start_index+sample_size \n    while not (file_content[end_index].isspace()):\n        end_index -= 1\n    return file_content[start_index:end_index]","1bd6ca48":"def get_input_row(content,start_index,sample_size, alphabet):\n    sample_text = get_sample_text(content,start_index,sample_size)\n    counted_chars_all = count_chars(sample_text.lower(), alphabet[0])\n    counted_chars_big = count_chars(sample_text, alphabet[1])\n    all_parts = counted_chars_all + counted_chars_big\n    return all_parts","12bed795":"def remove_xml(text):\n    return re.sub(r'<[^<]+?>', '', text)\n\ndef remove_newlines(text):\n    return text.replace('\\n', ' ') \n    \n\ndef remove_manyspaces(text):\n    return re.sub(r'\\s+', ' ', text)\n\ndef clean_text(text):\n    text = remove_xml(text)\n    text = remove_newlines(text)\n    text = remove_manyspaces(text)\n    return text","8358f8e7":"def count_chars(text, alphabet):\n    alphabet_counts = []\n    for letter in alphabet:\n        count = text.count(letter)\n        alphabet_counts.append(count)\n    return alphabet_counts","480f95e2":"# Load the Alphabet\nalphabet = define_alphabet()\nLANGUAGES_DICT = {'en':0,'fr':1,'es':2,'it':3,'de':4,'sk':5,'cs':6}\nLABELS =  list(LANGUAGES_DICT.keys())\n# Length of cleaned text used for training and prediction - 140 chars\nMAX_LEN = 140\n\n# number of language samples per language that we will extract from source files\nNUM_SAMPLES = 250000\n\n\nwith open(\"..\/input\/input_size.sav\", \"rb\") as file_obj:\n    input_size = pickle.load(file_obj)\n\nwith open(\"..\/input\/standard_scaler.sav\", \"rb\") as file_obj:\n    standard_scaler = pickle.load(file_obj)\n    \ndef get_prediction(TEXT):\n    #if len(TEXT) < MAX_LEN:\n    #    print(\"Text has to be at least {} chars long, but it is {}\/{}\".format(MAX_LEN, len(TEXT), MAX_LEN))\n    #    return(-1)\n    # Data cleaning\n    cleaned_text = clean_text(TEXT)\n    temp_text=cleaned_text.split(' ')\n    if len(temp_text)<MAX_LEN:\n        count=MAX_LEN-len(temp_text)\n        for i in range(0,count):\n            temp_text.append(\" unk \")\n        cleaned_text=' '.join(temp_text)\n    \n    # Get the MAX_LEN char\n    input_row = get_input_row(cleaned_text, 0, MAX_LEN, alphabet)\n    \n    # Data preprocessing (Standardization)\n    test_array = standard_scaler.transform([input_row])\n    \n    raw_score = model.predict(test_array)\n    pred_idx= np.argmax(raw_score, axis=1)[0]\n    score = raw_score[0][pred_idx]*100\n    \n    # Prediction\n    prediction = LABELS[model.predict_classes(test_array)[0]]\n    print('TEXT:', TEXT, '\\nPREDICTION:', prediction.upper(), '\\nSCORE:', score)\n\n\n\nmodel = Sequential()\n# Note: glorot_uniform is the Xavier uniform initializer.\n\nmodel.add(Dense(500,input_dim=input_size, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(300, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(100, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(len(LANGUAGES_DICT), kernel_initializer=\"glorot_uniform\", activation=\"softmax\"))\nmodel_optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=model_optimizer,\n              metrics=['accuracy'])\n\nmodel.summary()\nmodel.load_weights('..\/input\/lang_identification_weights.h5')\n\n\n","e503b8de":"print(get_prediction(\"This is a sample text in English\"))\nprint(get_prediction(\"Ceci est un exemple de texte en anglais\"))\nprint(get_prediction(\"Dies ist ein Beispieltext in Englisch\"))\n","bc609e7c":"***This Python Notebook detects following languages form a short description of text***\n* **ISO-CODE**     \n* en --> English\t            \n* fr --> French\t            \n* es --> Spanish\t\t             \n* it --> Italian\t             \n* de --> German\t            \n* cz --> Czech\t           \n* sk --> Slovakian\t             ","ec761244":"The Below Code have following files\n\n**input_size.sav and standard_sacaler are pre-trained pickle files**","35a3bf67":"**Lets predict the diffrent lanaguges form sample of text**"}}