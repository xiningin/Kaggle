{"cell_type":{"bd273bd2":"code","4fe00224":"code","ec42beac":"code","a37b1d34":"code","3bd07d78":"code","7a47d4d5":"code","ffe061f4":"code","75209e84":"code","cf285c0a":"code","3409d035":"code","2d1e79f3":"code","b8a6f959":"code","0c94f125":"code","75a8fd10":"code","a43a767e":"code","b79c59ee":"markdown","32e0793d":"markdown","54762aa2":"markdown","8ea51b46":"markdown","29e0210c":"markdown","7f54c61e":"markdown","e5f1f3e0":"markdown","2f664e65":"markdown","9ec212fa":"markdown","ea2b476c":"markdown"},"source":{"bd273bd2":"import os \nprint(os.listdir('..\/input'))","4fe00224":"import numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate\n\nimport matplotlib.pyplot as plt","ec42beac":"# take 50 history points (~2 months)\nhistory_points = 50","a37b1d34":"csv_path = '..\/input\/stocks\/GOOGL_daily.csv'","3bd07d78":"# Read Dataset & Normalise it\ndef csv_to_dataset(csv_path):\n    data = pd.read_csv(csv_path)\n    data = data.drop('date', axis=1)\n    ## reverse index because .csv top column is most recent price \n    data = data[::-1]\n    data = data.reset_index()\n    data = data.drop('index', axis=1)\n    print(data)\n\n    # normaliser\n    data_normaliser = preprocessing.MinMaxScaler()\n    data_normalised = data_normaliser.fit_transform(data) \n    # using the last {history_points} open high low close volume data points, predict the next open value\n    ohlcv_histories_normalised =      np.array([data_normalised[i  : i + history_points].copy() for i in range(len(data_normalised) - history_points)])\n    print(ohlcv_histories_normalised.shape)    \n    next_day_open_values_normalised = np.array([data_normalised[:,0][i + history_points].copy() for i in range(len(data_normalised) - history_points)])   \n\n    next_day_open_values_normalised = np.expand_dims(next_day_open_values_normalised, -1)\n\n    next_day_open_values = np.array([data.loc[:,\"1. open\"][i + history_points].copy() for i in range(len(data) - history_points)])\n    next_day_open_values = np.expand_dims(next_day_open_values, -1)\n    \n    y_normaliser = preprocessing.MinMaxScaler()\n    y_normaliser.fit(next_day_open_values)\n\n    # add MACD\n    def calc_ema(values, time_period):\n        # https:\/\/www.investopedia.com\/ask\/answers\/122314\/what-exponential-moving-average-ema-formula-and-how-ema-calculated.asp\n        sma = np.mean(values[:,3])\n        ema_values = [sma]\n        k = 2 \/ (1 + time_period)\n        for i in range(len(his) - time_period, len(his)):\n            close = his[i][3]\n            ema_values.append(close * k + ema_values[-1] * (1 - k))\n        return ema_values[-1]\n    \n    # add technical indicators \n    technical_indicators = []\n    for his in ohlcv_histories_normalised:\n        # since we are using his[3] we are taking the SMA of the closing price\n        sma = np.mean(his[:,3])                            # add SMA\n        macd = calc_ema(his, 12) - calc_ema(his, 26)       # add MACD    \n        technical_indicators.append(np.array([sma,macd,])) # add MACD\n\n    technical_indicators = np.array(technical_indicators)\n\n    tech_ind_scaler = preprocessing.MinMaxScaler()\n    technical_indicators_normalised = tech_ind_scaler.fit_transform(technical_indicators)\n\n    assert ohlcv_histories_normalised.shape[0] == next_day_open_values_normalised.shape[0]\n    return ohlcv_histories_normalised, technical_indicators_normalised, next_day_open_values_normalised, next_day_open_values, y_normaliser","7a47d4d5":"ohlcv_histories, technical_indicators, next_day_open_values, unscaled_y, y_scaler = csv_to_dataset(csv_path)","ffe061f4":"# splitting the dataset up into train and test sets\ntest_split = 0.9 # 90% stock-history for training, most-recent 10% stock-history for testing\nn = int(ohlcv_histories.shape[0] * test_split)\n\nohlcv_train = ohlcv_histories[:n]\ntech_ind_train = technical_indicators[:n] # add technical indicator\ny_train = next_day_open_values[:n]\n\nohlcv_test = ohlcv_histories[n:]\ntech_ind_test = technical_indicators[n:] # add technical indicator\ny_test = next_day_open_values[n:]\n\nunscaled_y_test = unscaled_y[n:]\n\nprint(ohlcv_train.shape)","75209e84":"# Build Model\nlstm_input = Input(shape=(history_points, 5), name='lstm_input')\ndense_input = Input(shape=(technical_indicators.shape[1],), name='tech_input') # 2nd input for technical indicator\n\nx = LSTM(50, name='lstm_0')(lstm_input)\nx = Dropout(0.2, name='lstm_dropout_0')(x)\n\n# the second branch opreates on the second input\nlstm_branch = Model(inputs=lstm_input, outputs=x)\ny = Dense(25, name='tech_dense_0')(dense_input)\ny = Activation(\"relu\", name='tech_relu_0')(y)\ny = Dropout(0.2, name='tech_dropout_0')(y)\ntechnical_indicators_branch = Model(inputs=dense_input, outputs=y)\n# combine the output of the two branches\ncombined = concatenate([lstm_branch.output, technical_indicators_branch.output], name='concatenate')\n \nz = Dense(50, activation=\"sigmoid\", name='dense_pooling')(combined)\nz = Dense(1, activation=\"linear\", name='dense_out')(z)\n \n# this model will accept the inputs of the two branches and then output a single value\nmodel = Model(inputs=[lstm_branch.input, technical_indicators_branch.input], outputs=z)\n\nmodel.summary()","cf285c0a":"# Compile Model\nadam = Adam(lr=0.0005)\nmodel.compile(optimizer=adam, loss='mse')","3409d035":"# Train Model\nnum_epochs = 100\nbatch_size = 32\nmodel.fit(x=[ohlcv_train, tech_ind_train], y=y_train, batch_size=batch_size, epochs=num_epochs, shuffle=True, validation_split=0.1)","2d1e79f3":"# Evaluate Model\nevaluation = model.evaluate([ohlcv_test, tech_ind_test], y_test)\nprint(evaluation)","b8a6f959":"y_test_predicted = model.predict([ohlcv_test, tech_ind_test])\n\n# model.predict returns normalised values, now we scale them back up using the y_scaler from before\ny_test_predicted = y_scaler.inverse_transform(y_test_predicted)\n\n# also getting predictions for the entire dataset, just to see how it performs\ny_predicted = model.predict([ohlcv_histories,technical_indicators])\ny_predicted = y_scaler.inverse_transform(y_predicted)\n\nassert unscaled_y_test.shape == y_test_predicted.shape\nreal_mse = np.mean(np.square(unscaled_y_test - y_test_predicted))\nscaled_mse = real_mse \/ (np.max(unscaled_y_test) - np.min(unscaled_y_test)) * 100\nprint(scaled_mse)","0c94f125":"# Plot stock prediction\nplt.gcf().set_size_inches(22, 15, forward=True)\nstart = 0\nend = -1\nreal = plt.plot(unscaled_y_test[start:end], label='real')\npred = plt.plot(y_test_predicted[start:end], label='predicted')\nplt.title('symbol = GOOGL')\nplt.legend(['Real', 'Predicted'])\nplt.show()","75a8fd10":"buys = []\nsells = []\nthresh = 0.2\n\nx = 0\nfor ohlcv, ind in zip(ohlcv_test, tech_ind_test):\n    normalised_price_today = ohlcv[-1][0]\n    normalised_price_today = np.array([[normalised_price_today]])\n    \n    price_today = y_scaler.inverse_transform(normalised_price_today)\n    \n    predicted = np.squeeze(y_scaler.inverse_transform( model.predict( [np.array([ohlcv]), np.array([ind]) ]) ))\n                           \n    \n    delta = predicted - price_today\n    # print(delta)\n    if delta > thresh:\n        buys.append((x, price_today[0][0]))\n    elif delta < -thresh:\n        sells.append((x, price_today[0][0]))\n    x += 1\nprint(buys)\nprint(sells)","a43a767e":"plt.gcf().set_size_inches(22, 15, forward=True)\n\nstart = 0\nend = -1\n\nreal = plt.plot(unscaled_y_test[start:end], label='real')\npred = plt.plot(y_test_predicted[start:end], label='predicted')\n\nplt.scatter(list(list(zip(*buys))[0]), list(list(zip(*buys))[1]), c= '#00ff00')   # buy points in green\nplt.scatter(list(list(zip(*sells))[0]), list(list(zip(*sells))[1]), c= '#ff0000') # sell points in red\n\n# real = plt.plot(unscaled_y[start:end], label='real')\n# pred = plt.plot(y_predicted[start:end], label='predicted')\n\nplt.legend(['Real', 'Predicted'])\n\nplt.show()","b79c59ee":"### *Test data is the most recent 10% stock history*","32e0793d":"![](https:\/\/miro.medium.com\/max\/1269\/0*dcNNGSOyOpE6Pby2.png)","54762aa2":"## Plot Stock Prediction","8ea51b46":"## Evaluate Model","29e0210c":"## Train Model","7f54c61e":"# Stock LSTM with MACD + Buy\/Sell Strategy\n## *add technical indicator = Moving Average Convergence Divergence*","e5f1f3e0":"## Plot Buy & Sell timing","2f664e65":"## Build Model","9ec212fa":"## Read Dataset","ea2b476c":"## **Buy\/Sell Strategy**"}}