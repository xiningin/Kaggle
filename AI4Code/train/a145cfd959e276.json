{"cell_type":{"d378c004":"code","2d424424":"code","d4a84031":"code","f3899cc6":"code","62cc8787":"code","000c74e1":"code","9c6b0493":"code","b24da7c6":"code","41748b52":"code","21d20952":"code","4d9ca433":"code","ba2e8e37":"code","46f493d8":"code","d662319a":"code","23685131":"code","82c0a9a5":"code","c04629f7":"code","0123d5e5":"code","9ab7ba28":"code","f5d44814":"code","c72cdbf1":"code","5765544d":"code","1af958da":"code","68324263":"code","6c8af9c5":"code","250c4c45":"code","13a98918":"code","1ba62cf2":"code","de24b2a8":"code","59c3a5e0":"code","008bc55e":"code","4b47fa6e":"code","1764391b":"code","25fbbd0e":"code","155e1b95":"code","874b43af":"code","a64b04b6":"code","95df0013":"code","6faadc33":"code","c178afad":"code","e28d5af2":"code","833ef1a2":"code","54cc6841":"code","3ecc137d":"code","7d8be95f":"code","6b5618c7":"code","adaeaab5":"code","6300cd12":"code","41987b1e":"code","e982ab07":"code","2df47070":"code","f7ec723e":"code","97160493":"code","cbe38d11":"code","b287e3a9":"code","f0b693de":"code","b2857d1b":"code","c4dfd986":"code","96a15709":"code","228155bd":"code","fc03bd90":"code","ee52178c":"code","fb0cbeac":"code","4735c28b":"code","1b9b79b0":"code","08bd978f":"code","2344c7ec":"code","5f7294b2":"code","ff64fae5":"code","ca2b8f4c":"code","f7300306":"code","c06b8191":"code","afe95c91":"markdown","c822eb0d":"markdown","3d67f3f0":"markdown","e4a197a7":"markdown","6355129b":"markdown","9827edf0":"markdown","738bf2e1":"markdown","de6fcffb":"markdown","faa65d45":"markdown","deae9204":"markdown","bbb9ea11":"markdown","ba82c689":"markdown","cd11f0d2":"markdown","d93336a0":"markdown","ec819a4b":"markdown","4660f604":"markdown","258f8dbc":"markdown","9219b06a":"markdown","64f95a51":"markdown","6cfcacdb":"markdown","53809676":"markdown","35ffdf05":"markdown","ae8ceeb7":"markdown","76e50efd":"markdown","c305bc80":"markdown","ca2e52a3":"markdown","bf2d4e5d":"markdown","7a660dcc":"markdown","d24080fe":"markdown","c1da926c":"markdown","a9bea274":"markdown","45bd9b8f":"markdown","82a331f1":"markdown","47bc58d9":"markdown","9dba1a7f":"markdown","24ec206a":"markdown","4a77aa2e":"markdown","bcee9b7a":"markdown","389b8d96":"markdown","68ebdbe7":"markdown","a89adb05":"markdown","fb61fa28":"markdown","e2399d23":"markdown"},"source":{"d378c004":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n#from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB2\n\nimport os\n#from tensorflow.python.keras.applications.nasnet import preprocess_input\nfrom tqdm import tqdm","2d424424":"dir_root = '..\/input\/lyme-clean-and-dirty\/Lyme_ver03\/'\ndir_original = dir_root + 'data\/'\ndir_augmented = dir_root + 'augmented_dataset\/'\ntest_df = pd.read_csv(dir_root + 'test_data.csv')\ntrain_df = pd.read_csv(dir_root + 'training_data.csv')\naugmented_df = pd.read_csv(dir_root + 'data_augmented.csv')","d4a84031":"\"\"\"\ndir_root = '\/data1\/LYME\/ver_03\/'\ndir_original = dir_root + 'data\/'\ndir_augmented = dir_root + 'augmented_dataset\/'\ntest_df = pd.read_csv(dir_root + 'test_data.csv')\ntrain_df = pd.read_csv(dir_root + 'training_data.csv')\naugmented_df = pd.read_csv(dir_root + 'data_augmented.csv')\n\"\"\"","f3899cc6":"%%time\n\ndata = {}\n\ntarget_size = (224, 224)\n\n\nfor i in range(len(test_df['image'])):\n    image_name = dir_original + test_df['image'][i]\n    image=tf.keras.preprocessing.image.load_img(image_name, color_mode='rgb', target_size = target_size)\n    image=np.array(image)\n    data.update({test_df['image'][i]: image})\n    \n\nfor i in range(len(train_df['image'])):\n    image_name = dir_original + train_df['image'][i]\n    image=tf.keras.preprocessing.image.load_img(image_name, color_mode='rgb', target_size = target_size)\n    image=np.array(image)\n    data.update({train_df['image'][i]: image})\n\n\nfor i in range(len(augmented_df['image'])):\n    image_name = dir_augmented + augmented_df['image'][i]\n    image=tf.keras.preprocessing.image.load_img(image_name, color_mode='rgb', target_size = target_size)\n    image=np.array(image)\n    data.update({augmented_df['image'][i]: image})\n\n\n","62cc8787":"print('train_df size: ',len(train_df))\nprint('test_df size: ',len(test_df))\n#data_df = pd.concat([test_df, train_df])\ndata_df = train_df\n\ndata_df.reset_index(drop=True, inplace=True)\ndata_df = data_df.sample(frac=1, random_state=123)\ndata_df.reset_index(drop=True, inplace=True)\n\nprint('data_original_df size: ',len(data_df))","000c74e1":"def show_model_results(acc_per_fold, loss_per_fold, auc_per_fold):\n    # == Provide average scores ==\n    print('------------------------------------------------------------------------')\n    print('Score per fold')\n    for i in range(0, len(acc_per_fold)):\n      print('------------------------------------------------------------------------')\n      print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - AUC: {auc_per_fold[i]}')\n    print('------------------------------------------------------------------------')\n    print('Average scores for all folds:')\n    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n    print(f'> AUC: {np.mean(auc_per_fold)} (+- {np.std(auc_per_fold)})')\n    print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')","9c6b0493":"def plot_mean_std(label, line_color, fill_color, epoch_list, mean_list, std_list, ax):\n  \n  ax.plot(\n    epoch_list,\n    mean_list,\n    color=line_color,\n    label=label, \n    lw=2,\n    alpha=0.8,\n  )\n\n  upper = (mean_list + std_list)\n  lower = (mean_list - std_list)\n\n  ax.fill_between(\n    epoch_list,\n    lower,\n    upper,\n    color=fill_color,\n    alpha=0.5,\n    label=r\"$\\pm$ 1 std. dev.\",\n  )\n\n\ndef plot_train_val_mean_std(metric_label, legend_location, metric_ylim, history_train_list_means, history_train_list_stds, history_val_list_means, history_val_list_stds, ax):\n\n\n  epochs_list = range(EPOCHS)\n\n  plot_mean_std('train', 'r', \"lightcoral\", epochs_list, history_train_list_means, history_train_list_stds, ax)\n  plot_mean_std('val', 'b', \"lightsteelblue\", epochs_list, history_val_list_means, history_val_list_stds, ax)\n\n  ax.set(\n    xlim = [0, EPOCHS-1],\n    ylim = metric_ylim,\n    title = metric_label + \" - History\",\n  )\n\n  ax.legend(loc=legend_location, ncol=2)\n\n  model_name = model_prefix + '_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name    \n  figures_dir = '.\/OUTPUT\/' + model_prefix + '\/' + model_name + '\/'\n  os.makedirs(figures_dir, exist_ok=True)    \n  fig_filename = model_name + '_' + metric_label + '_history_' + add_title + '.png'\n  fig_file_path = os.path.join(figures_dir, fig_filename)\n  plt.savefig(fig_file_path, dpi=300)\n\n  plt.show()  \n","b24da7c6":"class Base_Model(tf.keras.Model):\n\n  def __init__(self, target_size):\n    super().__init__()\n    self.target_size = target_size\n    self.base_model = EfficientNetB2(\n    #self.base_model = MobileNetV2(\n        include_top=False,\n        pooling='max', \n        weights=WEIGHTS, \n        input_shape = self.target_size)\n    \n    print(target_size)\n\n    # make the weights and biases of the base model non-trainable\n    # by \"freezing\" each layer of the BASE network\n    for layer in self.layers:\n        print(layer.name)\n        layer.trainable = TRAINABLE    \n    \n    self.flat_layer = tf.keras.layers.Flatten()\n    self.dense1_layer = tf.keras.layers.Dense(512, activation='relu')\n    self.dense2_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n\n  def call(self, inputs, training=False):\n    x = self.base_model(inputs)\n    x = self.flat_layer(x)\n    x = self.dense1_layer(x)\n\n\n    return self.dense2_layer(x)\n    ","41748b52":"class Complex_Model():\n\n  def __init__(self, result_data, result_label, test_data, test_label, \n               save_dir, save_best_model_path, epoch_num, \n               target_size = (224, 224, 3), num_folds = 5):\n    \n    self.X = result_data\n    self.Y = result_label\n    self.x = test_data\n    self.y = test_label\n\n    self.target_size = target_size\n    self.save_dir = save_dir\n    self.save_best_model_path = save_best_model_path\n    self.epoch_num = epoch_num\n    self.num_folds = num_folds\n\n    self.acc_per_fold = []\n    self.loss_per_fold = []\n    self.auc_per_fold = []\n\n    self.history_acc_list = []\n    self.history_loss_list = []\n    self.history_auc_list = []\n    self.history_val_acc_list = []\n    self.history_val_loss_list = []\n    self.history_val_auc_list = []\n\n\n\n  def run(self):\n\n    kfold = StratifiedKFold(n_splits = self.num_folds)\n  \n\n    from tqdm import tqdm\n    for train, test in tqdm(kfold.split(self.X, self.Y)):\n\n      model = Base_Model(self.target_size)\n      #model = create_model()\n\n      #model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001), \n      model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001), \n                  loss = 'binary_crossentropy', \n                  metrics = [tf.keras.metrics.AUC(name='auc'),'acc'])\n\n\n      if DA == True:  \n        train_data_aug = ImageDataGenerator(\n          rescale=1.\/255,\n          featurewise_center=True, \n          samplewise_center=True, featurewise_std_normalization=True, samplewise_std_normalization=True,\n          zca_whitening=True, zca_epsilon=1e-06, rotation_range=90, \n          width_shift_range=1.0, height_shift_range=1.0, brightness_range=[0.5, 1.5], \n          shear_range=90.0, zoom_range=1.0, channel_shift_range=0.0, \n          fill_mode='nearest', horizontal_flip=False, vertical_flip=False\n        ).flow(self.X[train], self.Y[train])\n      else:\n        train_data_aug = ImageDataGenerator(rescale=1.\/255).flow(self.X[train], self.Y[train])\n    \n      test_data_aug = ImageDataGenerator(rescale=1.\/255).flow(self.X[test], self.Y[test])\n\n      checkpoint_AUC = ModelCheckpoint(save_dir, monitor='val_auc', verbose=2, save_best_only=True, \n                                      mode='max', save_weights_only=True)\n      \n      history = model.fit(\n        train_data_aug,\n        batch_size=BATCH_SIZE,\n        epochs=self.epoch_num,\n        verbose=2,\n        callbacks = [checkpoint_AUC],\n        validation_data=test_data_aug)\n        \n      model.summary()        \n      \n      model.load_weights(save_dir)\n      \n      scores = model.evaluate(test_data_aug, verbose=0)\n\n      self.loss_per_fold.append(scores[0])\n      self.auc_per_fold.append(scores[1])\n      self.acc_per_fold.append(scores[2])\n\n      \n      self.history_acc_list.append(history.history['acc'])\n      self.history_loss_list.append(history.history['loss'])\n      self.history_auc_list.append(history.history['auc'])\n      self.history_val_acc_list.append(history.history['val_acc'])\n      self.history_val_loss_list.append(history.history['val_loss'])\n      self.history_val_auc_list.append(history.history['val_auc'])\n\n\n  def run_full(self):\n    model = Base_Model(self.target_size)\n    #model = create_model()\n    \n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001), \n                  loss = 'binary_crossentropy', \n                  metrics = [tf.keras.metrics.AUC(name='auc'),'acc'])\n\n    if DA == True:  \n        train_data_aug = ImageDataGenerator(\n          rescale=1.\/255,\n          featurewise_center=True, \n          samplewise_center=True, featurewise_std_normalization=True, samplewise_std_normalization=True,\n          zca_whitening=True, zca_epsilon=1e-06, rotation_range=90, \n          width_shift_range=1.0, height_shift_range=1.0, brightness_range=[0.5, 1.5], \n          shear_range=90.0, zoom_range=1.0, channel_shift_range=0.0, \n          fill_mode='nearest', horizontal_flip=False, vertical_flip=False\n        ).flow(self.X, self.Y)\n    else:\n        train_data_aug = ImageDataGenerator(rescale=1.\/255).flow(self.X, self.Y)\n    \n    test_data_aug = ImageDataGenerator(rescale=1.\/255).flow(self.x, self.y)\n\n    checkpoint_AUC = ModelCheckpoint(save_dir, monitor='val_auc', verbose=2, save_best_only=True, \n                                      mode='max', save_weights_only=True)\n      \n    history = model.fit(\n        train_data_aug,\n        batch_size=BATCH_SIZE,\n        epochs=self.epoch_num,\n        verbose=2,\n        callbacks = [checkpoint_AUC],\n        validation_data=test_data_aug)\n        \n    model.summary()        \n      \n    model.load_weights(save_dir)\n      \n    scores = model.evaluate(test_data_aug, verbose=0)\n\n    print('**** Test BEST model ****')\n    Accuracy_string = 'Acc{acc_best:.3f}'.format(acc_best=scores[2])\n    print('Accuracy = {acc_best:.4f}'.format(acc_best=scores[2]))\n    AUC_string = 'AUC{AUC_best:.3f}'.format(AUC_best=scores[1])\n    print('AUC= {AUC_best:.4f}'.format(AUC_best=scores[1]))\n    Loss_string = 'Loss{Loss_best:.3f}'.format(Loss_best=scores[0])\n    print('Loss = {Loss_best:.4f}'.format(Loss_best=scores[0]))\n    \n    best_model_metrics_filename = self.save_best_model_path + '_' + Loss_string + '_' + Accuracy_string + '_' + AUC_string  + '_best.h5'\n    model.save_weights(best_model_metrics_filename) \n    \n    return model, best_model_metrics_filename, self.x, self.y\n    \n    \n  def show_results(self):\n    show_model_results(self.acc_per_fold, self.loss_per_fold, self.auc_per_fold)\n\n\n  def history_stat_metrics(self, history_list):\n    history_list_means = np.mean(np.asarray(history_list),axis=0)\n    history_list_stds = np.std(np.asarray(history_list),axis=0)\n    return(history_list_means, history_list_stds)\n\n\n  def plot_accuracy(self):\n\n    train_acc_list_means, train_acc_list_stds = self.history_stat_metrics(self.history_acc_list)\n    val_acc_list_means, val_acc_list_stds = self.history_stat_metrics(self.history_val_acc_list)\n\n    fig, ax = plt.subplots()\n\n    plot_train_val_mean_std('Accuracy', \"lower center\", [0.01, 1.05], train_acc_list_means, \n                        train_acc_list_stds, val_acc_list_means, val_acc_list_stds, ax)\n    \n   \n  def plot_auc(self):\n\n    train_auc_list_means, train_auc_list_stds = self.history_stat_metrics(self.history_auc_list)\n    val_auc_list_means, val_auc_list_stds = self.history_stat_metrics(self.history_val_auc_list)\n\n    fig, ax = plt.subplots()\n\n    plot_train_val_mean_std('AUC', \"lower center\", [0.01, 1.05], train_auc_list_means, train_auc_list_stds, \n                        val_auc_list_means, val_auc_list_stds, ax)\n\n\n\n  def plot_loss(self):\n\n    train_loss_list_means, train_loss_list_stds = self.history_stat_metrics(self.history_loss_list)\n    val_loss_list_means, val_loss_list_stds = self.history_stat_metrics(self.history_val_loss_list)\n\n    fig, ax = plt.subplots()\n\n    plot_train_val_mean_std('Loss', \"upper center\", [0.01, 6], train_loss_list_means, train_loss_list_stds, \n                        val_loss_list_means, val_loss_list_stds, ax) \n\n\n  def folds_mean_max_auc(self):\n    return np.mean(self.acc_per_fold), np.std(self.acc_per_fold), np.mean(self.auc_per_fold), np.std(self.auc_per_fold), np.mean(self.loss_per_fold), np.std(self.loss_per_fold)  ","21d20952":"def prepare_data_growing(data_df, noisy_part, limit):\n    result_label = []\n    result_data = []\n\n    dirty_pos_lyme_count = 0\n    dirty_no_lyme_count = 0\n\n    clean_pos_lyme_count = 0\n    clean_no_lyme_count = 0\n\n    clean_count = 0\n    dirty_count = 0\n    \n    dirty_limit = limit * noisy_part\n    print('dirty_limit: ', dirty_limit)\n    clean_limit = limit - dirty_limit\n    print('clean_limit: ', clean_limit)\n    \n    num_images = len(data_df['image'])\n    print('**************************')\n    print('Subset (images): ', num_images)\n    for i in range(num_images):\n        if (data_df['clean'][i] == 1) and (data_df['lyme_positive'][i] == 1) and (clean_pos_lyme_count < clean_limit):\n            result_label.append(data_df['lyme_positive'][i])\n            result_data.append(data[data_df['image'][i]])\n            clean_pos_lyme_count += 1\n            clean_count += 1\n\n        if (data_df['clean'][i] == 1) and (data_df['lyme_positive'][i] == 0) and (clean_no_lyme_count < clean_limit):\n            result_label.append(data_df['lyme_positive'][i])\n            result_data.append(data[data_df['image'][i]])\n            clean_no_lyme_count += 1\n            clean_count += 1\n       \n        if (data_df['clean'][i] == 0) and (data_df['lyme_positive'][i] == 1) and (dirty_pos_lyme_count < dirty_limit):\n            result_label.append(data_df['lyme_positive'][i])\n            result_data.append(data[data_df['image'][i]])\n            dirty_pos_lyme_count += 1\n            dirty_count += 1\n\n        if (data_df['clean'][i] == 0) and (data_df['lyme_positive'][i] == 0) and (dirty_no_lyme_count < dirty_limit):\n            result_label.append(data_df['lyme_positive'][i])\n            result_data.append(data[data_df['image'][i]])\n            dirty_no_lyme_count += 1       \n            dirty_count += 1       \n\n    print('dirty_pos_lyme_count:', dirty_pos_lyme_count)            \n    print('dirty_no_lyme_count:', dirty_no_lyme_count)\n    print('dirty_count:', dirty_count)\n\n    print('clean_pos_lyme_count:', clean_pos_lyme_count)            \n    print('clean_no_lyme_count:', clean_no_lyme_count)    \n    print('clean_count:', clean_count)\n  \n    result_data = np.asarray(result_data).astype(np.float32)\n    result_label = np.asarray(result_label).astype(np.float32)\n\n    print('**************************')\n    print('Final state of subset ...')\n    print('pos_lyme_count: ', dirty_pos_lyme_count + clean_pos_lyme_count)\n    print('no_lyme_count: ', dirty_no_lyme_count + clean_no_lyme_count)\n    print('Noise ratio: ', dirty_count\/(dirty_count + clean_count))\n    print('Growing subset (data) size: ',len(result_data))\n    print('Growing subset (label) size: ',len(result_label))\n    print('**************************')\n\n    return result_data, result_label","4d9ca433":"def plot_noise_vs(x, y, x_label, y_label, plot_title):\n  plt.plot(x, y)\n  #plt.xticks(x)\n  plt.xlabel(x_label)\n  plt.ylabel(y_label)\n  plt.title(plot_title)\n\n  model_name = model_prefix + '_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name    \n  figures_dir = '.\/OUTPUT\/' + model_prefix + '\/' + model_name + '\/'\n  os.makedirs(figures_dir, exist_ok=True)    \n  fig_filename = model_name + '_' + plot_title + '.png'\n  fig_file_path = os.path.join(figures_dir, fig_filename)\n  plt.savefig(fig_file_path, dpi=300)\n\n  plt.show()","ba2e8e37":"def plot_noise_mean_std(metric_label, legend_location, metric_ylim, x_list, list_means, list_stds, ax):\n\n    plot_mean_std('Mean', 'b', \"lightsteelblue\", x_list, list_means, list_stds, ax)\n\n    ax.set(\n        xlim = [0, len(x_list)+5],\n        ylim = metric_ylim,\n        title = metric_label + \" vs \" + x_label,\n        xlabel = x_label,\n        ylabel = metric_label\n    )\n\n    ax.legend(loc=legend_location, ncol=2)\n\n    model_name = model_prefix + '_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name    \n    figures_dir = '.\/OUTPUT\/' + model_prefix + '\/' + model_name + '\/'\n    os.makedirs(figures_dir, exist_ok=True)    \n    fig_filename = model_name + '_' + metric_label + \"_vs_\" + x_label_filename + '_FILL.png'\n    fig_file_path = os.path.join(figures_dir, fig_filename)\n    plt.savefig(fig_file_path, dpi=300)\n\n    plt.show()  ","46f493d8":"def run_kfold():  \n    #save_dir = '.\/MODELS\/best'\n    #save_dir = os.path.dirname(checkpoint_path)\n    #os.makedirs(save_dir, exist_ok=True)\n    \n    model_name = model_prefix + '_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name\n    save_model_filename = '.\/MODELS\/' + model_name\n    figures_dir = '.\/OUTPUT\/' + model_prefix + '\/' + model_name + '\/'\n    os.makedirs(figures_dir, exist_ok=True)\n    \n    #num_list = [15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65]\n    num_list = list(range(5,46,1))\n\n    metrics_list = []\n    for n in tqdm(num_list):\n        result_data, result_label = prepare_data_growing(train_df, NOISE_PART, n)\n        add_title = 'noise' + str(NOISE_PART) + '_num' + str(n)\n        model = Complex_Model(result_data=result_data, result_label=result_label, \n                              test_data=[], test_label=[],\n                              save_dir=save_dir, save_best_model_path=save_model_filename, epoch_num = EPOCHS)\n    \n        model.run()\n        model.show_results()\n        model.plot_accuracy()\n        model.plot_loss()\n        model.plot_auc()\n    \n        metrics = model.folds_mean_max_auc()\n        metrics_list.append(metrics)   \n\n    acc_mean_list = []\n    acc_std_list = []\n    auc_mean_list = []\n    auc_std_list = []\n    loss_mean_list = []\n    loss_std_list = []\n    for n in range(len(num_list)):\n        acc_mean_list.append(metrics_list[n][0])\n        acc_std_list.append(metrics_list[n][1])\n        auc_mean_list.append(metrics_list[n][2])\n        auc_std_list.append(metrics_list[n][3])\n        loss_mean_list.append(metrics_list[n][4])\n        loss_std_list.append(metrics_list[n][5])    \n        \n    # Summary\n    summary = np.column_stack((np.array(num_list),acc_mean_list,acc_std_list,auc_mean_list,auc_std_list,loss_mean_list,loss_std_list))\n    summary_df = pd.DataFrame(summary)\n    summary_df.columns = ['num', 'acc_mean', 'acc_std', 'auc_mean', 'auc_std', 'loss_mean', 'loss_std']\n    summary_df.head()\n    summary_filename = model_name + '_summary.txt'\n    summary_file_path = os.path.join(figures_dir, summary_filename)\n    summary_df.to_csv(summary_file_path, index=False)\n        \n    plot_noise_vs(num_list, acc_mean_list, x_label, 'Accuracy (mean)', 'Accuracy_mean_vs_' + x_label_filename)\n    plot_noise_vs(num_list, acc_std_list, x_label, 'Accuracy (std)', 'Accuracy_std_vs_' + x_label_filename)\n    plot_noise_vs(num_list, auc_mean_list, x_label, 'AUC (mean)', 'AUC_mean_vs_' + x_label_filename)\n    plot_noise_vs(num_list, auc_std_list, x_label, 'AUC (std)', 'AUC_std_vs_' + x_label_filename)\n    plot_noise_vs(num_list, loss_mean_list, x_label, 'Loss (mean)', 'Loss_mean_vs_' + x_label_filename)\n    plot_noise_vs(num_list, loss_std_list, x_label, 'Loss (std)', 'Loss_std_vs_' + x_label_filename)\n    \n    fig, ax = plt.subplots()\n    plot_noise_mean_std('Accuracy', \"lower center\", [0.3, 0.9], num_list, np.array(acc_mean_list), np.array(acc_std_list), ax)   \n    fig, ax = plt.subplots()\n    plot_noise_mean_std('AUC', \"upper center\", [0.5, 1.1], num_list, np.array(auc_mean_list), np.array(auc_std_list), ax)    \n    fig, ax = plt.subplots()\n    plot_noise_mean_std('Loss', \"upper center\", [-0.2, 3.6], num_list, np.array(loss_mean_list), np.array(loss_std_list), ax)    ","d662319a":"def run_final(test_data, test_label):  \n    \n    model_name = model_prefix + '_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name\n    save_model_filename = '.\/MODELS\/' + model_prefix + '\/' + model_name\n    figures_dir = '.\/OUTPUT\/' + model_prefix + '\/' + model_name + '\/'\n    os.makedirs(figures_dir, exist_ok=True)\n    \n    print('**************************')\n    print('Training subset ...')\n    train_data, train_label = prepare_data_growing(train_df, NOISE_PART, 45)\n    print('**************************')    \n    print('Testing subset ...')\n    print('For all testing procedures use the same: test_data, test_label')    \n    #test_data, test_label = prepare_data_growing(test_df, NOISE_PART, 20)\n    \n    add_title = 'noise' + str(NOISE_PART) + '_num' + str(45)\n    model = Complex_Model(result_data=train_data, result_label=train_label, \n                          test_data=test_data, test_label=test_label,\n                          save_dir=save_dir, save_best_model_path=save_model_filename, \n                          epoch_num = EPOCHS)\n    \n    model, best_model_metrics_filename, test_data, test_label = model.run_full()\n        \n    return model, best_model_metrics_filename","23685131":"import itertools\ndef plot_confusion_matrix(cm, \n                          #cm_std, # for k-fold only\n                          classes,\n                          normalize=False,\n                          title='Means',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm_sum = cm.sum(axis=1)[:, np.newaxis]\n        cm = cm.astype('float') \/ cm_sum\n#        cm_std = cm_std.astype('float') \/ cm_sum # for k-fold only\n        print(\"Confusion matrix, NORMALIZED\")\n    else:\n        print('Confusion matrix, WITHOUT normalization')\n\n    print('Mean values:')\n    print(cm)\n\n#    print('Standard deviation values:') # for k-fold only\n#    print(cm_std)\n\n    plt.title(title)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45, fontsize = 8)\n    plt.yticks(tick_marks, classes, fontsize = 8)\n\n    fmt = '.2f' if normalize else '.0f' # 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 #+ \"\\n\" + r'$\\pm$' + format(cm_std[i, j], fmt), # for k-fold only\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\", fontsize = 7)\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n    # Check folders\n    model_name = model_prefix + '_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name\n    print('model_name: ', model_name)\n    figures_dir = '.\/OUTPUT\/' + model_prefix + '\/' + model_name + '\/'\n    os.makedirs(figures_dir, exist_ok=True)\n    print('figures_dir: ', figures_dir)    \n    \n    plt.title('')     \n    fig_filename = title + '_ConfusionMatrix.eps'\n    fig_file_path = os.path.join(figures_dir, fig_filename)\n    plt.savefig(fig_file_path, bbox_inches='tight', dpi=300)\n    \n    plt.title(title)\n    fig_filename = title + '_ConfusionMatrix.png'\n    fig_file_path = os.path.join(figures_dir, fig_filename)\n    plt.savefig(fig_file_path, bbox_inches='tight', dpi=300)","82c0a9a5":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\ndef test_model(model, best_model_metrics_filename, test_data, test_label):\n#def test_model(model, best_model_metrics_filename, test_data_aug, test_label):\n    \n    model.load_weights(best_model_metrics_filename)\n    \n    test_data_aug = ImageDataGenerator(rescale=1.\/255).flow(test_data, test_label)\n    scores = model.evaluate(test_data_aug, verbose=1)\n    \n    print('**** EXTENDED TEST *****')\n    print(' Scores for TEST subset:')\n    Loss_string = 'Loss{Loss_best:.3f}'.format(Loss_best=scores[0])\n    print('Loss = {Loss_best:.4f}'.format(Loss_best=scores[0]))\n    AUC_string = 'AUC{AUC_best:.3f}'.format(AUC_best=scores[1])\n    print('AUC= {AUC_best:.4f}'.format(AUC_best=scores[1]))\n    Accuracy_string = 'Acc{acc_best:.3f}'.format(acc_best=scores[2])\n    print('Accuracy = {acc_best:.4f}'.format(acc_best=scores[2]))    \n\n    # CM\n    print('**** CONFUSION MATRIX *****')\n    #x_test, y_test = test_data, test_label\n\n    #score = model.evaluate(x_test, y_test)\n    #print('score:', score)\n    #predicted_probs = model.predict(x_test)\n    #print('predicted_probs:', predicted_probs)\n    \n    #samples = test_data_aug.samples\n    #nb_samples = len(samples)\n    #predicted_probs = model.predict_generator(test_data_aug, steps = np.ceil(nb_samples\/32))\n    predicted_probs = model.predict(test_data\/255)\n    #print('predicted_probs:',predicted_probs)\n\n    df = pd.DataFrame(predicted_probs)\n    predicted_probs = df[0].values.tolist()\n    predicted = [round(x) for x in predicted_probs]\n    #predicted = predicted_probs #.argmax(axis=-1)\n    #print('predicted:', predicted)\n\n    expected = test_label\n    #expected = y_test\n    #expected = y_test.argmax(axis=-1)\n    #print('expected:', expected)\n\n    # Print test of confusion matrix\n    conf_matrix = confusion_matrix(expected, predicted)\n    print(conf_matrix)      \n    \n    # Check folders\n    model_name = model_prefix + '_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name\n    print('model_name: ', model_name)\n    figures_dir = '.\/OUTPUT\/' + model_prefix + '\/' + model_name + '\/'\n    os.makedirs(figures_dir, exist_ok=True)\n    print('figures_dir: ', figures_dir)\n    title = model_name\n    print('title: ', title)\n\n    BINARY = True\n\n    #class_names = ['AZU','ONU', 'IZU', 'MYSLITE']\n    #class_names = subfolder_names\n    class_names = ['Lyme','NO']\n\n    # Compute confusion matrix\n    #cnf_matrix = confusion_matrix(expected, predicted)\n    np.set_printoptions(precision=4)\n\n    print('**************************')\n    # Plot non-normalized confusion matrix\n    if BINARY == True:\n        fig, ax = plt.subplots(dpi=300, figsize=(6, 3)) \n    else: \n        fig, ax = plt.subplots(dpi=300, figsize=(15, 15))\n    \n    plot_confusion_matrix(conf_matrix, \n                      #confusion_matrix_stds, # for k-fold only\n                      classes=class_names, normalize=False,\n                      #title = MODEL_NAME + '_' + TRAIN_TITLE + '_' + DA_TYPE + '_' + SAVED_MODEL + '_NOT_normalized')\n                      title = title + '_NOT_normalized')\n\n    print('**************************')\n    # Plot normalized confusion matrix\n    if BINARY == True:\n        fig, ax = plt.subplots(dpi=300, figsize=(6, 3)) \n    else: \n        fig, ax = plt.subplots(dpi=300, figsize=(15, 15))\n    plot_confusion_matrix(conf_matrix, \n                      #confusion_matrix_stds, # for k-fold only\n                      classes=class_names, normalize=True,\n                      #title = MODEL_NAME + '_' + TRAIN_TITLE + '_' + DA_TYPE + '_' + SAVED_MODEL + '_normalized')\n                      title = title + '_normalized')\n\n    plt.show()   \n    \n    TP = conf_matrix[0][0]\n    #print(TP)\n    FN = conf_matrix[0][1]\n    FP = conf_matrix[1][0]\n    TN = conf_matrix[1][1]    \n    \n    # ROC\n    from sklearn.metrics import roc_curve, auc\n\n    #fpr = dict()\n    #tpr = dict()\n    #roc_auc = dict()\n\n    fpr, tpr, _ = roc_curve(expected, predicted_probs)\n    roc_auc = auc(fpr, tpr)\n    #roc_auc_1 = roc_auc_score(expected, predicted_probs)\n\n    fig, ax = plt.subplots(figsize=(5, 5)) \n\n    ax.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Random, 0.5\", alpha=0.8)\n    ax.plot(fpr, tpr,\n         #label = \"AUC, %0.4f; , %0.4f\" % (roc_auc,roc_auc_1),\n         label = \"AUC, %0.4f\" % (roc_auc),\n         color='navy', linestyle='-', linewidth=4)\n\n    ax.legend(loc=\"lower right\", title = 'AUC')\n\n    plt.title('')     \n    fig_filename = title + '_ROC.eps'\n    fig_file_path = os.path.join(figures_dir, fig_filename)\n    plt.savefig(fig_file_path, bbox_inches='tight', dpi=300)\n    \n    plt.title(title)\n    fig_filename = title + '_ROC.png'\n    fig_file_path = os.path.join(figures_dir, fig_filename)\n    plt.savefig(fig_file_path, bbox_inches='tight', dpi=300)\n\n    plt.show()   \n    \n    # Save TEST results\n    \n    # Check folders\n    model_name = model_prefix + '_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name\n    print('model_name: ', model_name)\n    figures_dir = '.\/OUTPUT\/' + model_prefix + '\/' + model_name + '\/'\n    os.makedirs(figures_dir, exist_ok=True)\n    print('figures_dir: ', figures_dir)\n\n    test_CM_AUC_filename = model_name + '_CM_AUC.csv'\n    print('test_CM_AUC_filename: ', test_CM_AUC_filename)\n    test_CM_AUC_file_path = os.path.join(figures_dir, test_CM_AUC_filename)\n\n    test_ROC_filename = model_name + '_ROC.csv'\n    print('test_results_filename: ', test_ROC_filename)\n    test_ROC_file_path = os.path.join(figures_dir, test_ROC_filename)\n\n    roc_df = pd.DataFrame(fpr.T, columns=['fpr'])\n    roc_df['tpr'] = pd.DataFrame(tpr)\n    roc_df.head()\n    roc_df.to_csv(test_ROC_file_path)\n\n    cm_auc_df = pd.DataFrame(columns=['Loss', 'AUC', 'Accuracy', 'ROC_AUC', 'TP', 'FN', 'FP', 'TN'], \n                         data=[[scores[0], scores[1], scores[2], roc_auc, TP, FN, FP, TN]])\n    cm_auc_df.head()\n    cm_auc_df.to_csv(test_CM_AUC_file_path)    ","c04629f7":"def model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name):\n    # Check folders\n    model_name = model_prefix + '_' + data_quality + '_' + TL_name + '_E' + str(EPOCHS) + '_' + WEIGHTS_name + '_' + DA_name\n    print('model_name: ', model_name)\n    figures_dir = '.\/OUTPUT\/' + model_prefix + '\/' + model_name + '\/'\n    os.makedirs(figures_dir, exist_ok=True)\n    print('figures_dir: ', figures_dir)\n    return model_name, figures_dir","0123d5e5":"# For mean-std measurements -> KFOLD = True\n# For model final testing -> KFOLD = False\nKFOLD = False","9ab7ba28":"# For all testing procedures: use the same test_data, test_label\nprint('Testing subset ...')\nNOISE_PART = 0.5\ntest_data, test_label = prepare_data_growing(test_df, NOISE_PART, 20)\ntest_data_aug = ImageDataGenerator(rescale=1.\/255).flow(test_data, test_label)","f5d44814":"model_prefix = 'EfficientNetB2'\nBATCH_SIZE = 32\n\nEPOCHS = 30\nEPOCHS_KFOLD = 30\nEPOCHS_TEST = 1000\n\n# Train from ImageNet-trainable Weights\nWEIGHTS = 'imagenet'\nWEIGHTS_name = 'imagenet'\n# Train from scratch\n#WEIGHTS = None\n#WEIGHTS_name = 'Scratch'\n\nadd_title = ''\nx_label = 'Number of images'\nx_label_filename = 'Num'    \n\n#save_dir = ''\nsave_dir = '.\/MODELS\/' + model_prefix + '\/'\nmodel_name = ''\nsave_model_filename = ''\nfigures_dir = ''","c72cdbf1":"# Clean dataset \nNOISE_PART = 0.0\ndata_quality = 'CLEAN'\n\n# Dirty dataset \n#NOISE_PART = 1.0\n#data_quality = 'DIRTY'\n\n# Dirty & Clean dataset \n#NOISE_PART = 0.5\n#data_quality = 'DIRTY_CLEAN'","5765544d":"# Train from ImageNet-trainable Weights Learning (IWL) -> True\n#TRAINABLE = True\n#TL_name = 'NOTL'\n# Transfer Learning (TL) -> False\nTRAINABLE = False\nTL_name = 'TL'","1af958da":"%%time\n# With Data Augmentation -> True\n#DA = True\n#DA_name = 'DA' \n# Without Data Augmentation -> False\nDA = False\nDA_name = 'NODA' \n\nEPOCHS = EPOCHS_KFOLD\nmodel_name, figures_dir = model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name)\nif KFOLD: run_kfold()","68324263":"%%time\nEPOCHS = EPOCHS_TEST\nmodel, best_model_metrics_filename = run_final(test_data, test_label)\ntest_model(model, best_model_metrics_filename, test_data, test_label)","6c8af9c5":"%%time\n\n# With Data Augmentation -> True\nDA = True\nDA_name = 'DA' \n# Without Data Augmentation -> False\n#DA = False\n#DA_name = 'NODA' \n\nEPOCHS = EPOCHS_KFOLD\nmodel_name, figures_dir = model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name)\nif KFOLD: run_kfold()","250c4c45":"%%time\nEPOCHS = EPOCHS_TEST\nmodel, best_model_metrics_filename = run_final(test_data, test_label)\ntest_model(model, best_model_metrics_filename, test_data, test_label)","13a98918":"# Train from ImageNet-trainable Weights Learning (IWL) -> True\nTRAINABLE = True\nTL_name = 'NOTL'\n# Transfer Learning (TL) -> False\n#TRAINABLE = False\n#TL_name = 'TL'","1ba62cf2":"%%time\n# With Data Augmentation -> True\n#DA = True\n#DA_name = 'DA' \n# Without Data Augmentation -> False\nDA = False\nDA_name = 'NODA' \n\nEPOCHS = EPOCHS_KFOLD\nmodel_name, figures_dir = model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name)\nif KFOLD: run_kfold()","de24b2a8":"%%time\nEPOCHS = EPOCHS_TEST\nmodel, best_model_metrics_filename = run_final(test_data, test_label)\ntest_model(model, best_model_metrics_filename, test_data, test_label)","59c3a5e0":"%%time\n# With Data Augmentation -> True\nDA = True\nDA_name = 'DA' \n# Without Data Augmentation -> False\n#DA = False\n#DA_name = 'NODA' \n\nEPOCHS = EPOCHS_KFOLD\nmodel_name, figures_dir = model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name)\nif KFOLD: run_kfold()","008bc55e":"%%time\nEPOCHS = EPOCHS_TEST\nmodel, best_model_metrics_filename = run_final(test_data, test_label)\ntest_model(model, best_model_metrics_filename, test_data, test_label)","4b47fa6e":"# Clean dataset \n#NOISE_PART = 0.0\n#data_quality = 'CLEAN'\n\n# Dirty dataset \nNOISE_PART = 1.0\ndata_quality = 'DIRTY'\n\n# Dirty & Clean dataset \n#NOISE_PART = 0.5\n#data_quality = 'DIRTY_CLEAN'","1764391b":"# Train from ImageNet-trainable Weights Learning (IWL) -> True\n#TRAINABLE = True\n#TL_name = 'NOTL'\n# Transfer Learning (TL) -> False\nTRAINABLE = False\nTL_name = 'TL'","25fbbd0e":"%%time\n# With Data Augmentation -> True\n#DA = True\n#DA_name = 'DA' \n# Without Data Augmentation -> False\nDA = False\nDA_name = 'NODA' \n\nEPOCHS = EPOCHS_KFOLD\nmodel_name, figures_dir = model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name)\nif KFOLD: run_kfold()","155e1b95":"%%time\nEPOCHS = EPOCHS_TEST\nmodel, best_model_metrics_filename = run_final(test_data, test_label)\ntest_model(model, best_model_metrics_filename, test_data, test_label)","874b43af":"%%time\n# With Data Augmentation -> True\nDA = True\nDA_name = 'DA' \n# Without Data Augmentation -> False\n#DA = False\n#DA_name = 'NODA' \n\nEPOCHS = EPOCHS_KFOLD\nmodel_name, figures_dir = model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name)\nif KFOLD: run_kfold()","a64b04b6":"%%time\nEPOCHS = EPOCHS_TEST\nmodel, best_model_metrics_filename = run_final(test_data, test_label)\ntest_model(model, best_model_metrics_filename, test_data, test_label)","95df0013":"# Train from ImageNet-trainable Weights Learning (IWL) -> True\nTRAINABLE = True\nTL_name = 'NOTL'\n# Transfer Learning (TL) -> False\n#TRAINABLE = False\n#TL_name = 'TL'","6faadc33":"# With Data Augmentation -> True\n#DA = True\n#DA_name = 'DA' \n# Without Data Augmentation -> False\nDA = False\nDA_name = 'NODA' \n\nEPOCHS = EPOCHS_KFOLD\nmodel_name, figures_dir = model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name)\nif KFOLD: run_kfold()","c178afad":"%%time\nEPOCHS = EPOCHS_TEST\nmodel, best_model_metrics_filename = run_final(test_data, test_label)\ntest_model(model, best_model_metrics_filename, test_data, test_label)","e28d5af2":"# With Data Augmentation -> True\nDA = True\nDA_name = 'DA' \n# Without Data Augmentation -> False\n#DA = False\n#DA_name = 'NODA' \n\nEPOCHS = EPOCHS_KFOLD\nmodel_name, figures_dir = model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name)\nif KFOLD: run_kfold()","833ef1a2":"%%time\nEPOCHS = EPOCHS_TEST\nmodel, best_model_metrics_filename = run_final(test_data, test_label)\ntest_model(model, best_model_metrics_filename, test_data, test_label)","54cc6841":"# Clean dataset \n#NOISE_PART = 0.0\n#data_quality = 'CLEAN'\n\n# Dirty dataset \n#NOISE_PART = 1.0\n#data_quality = 'DIRTY'\n\n# Dirty & Clean dataset \nNOISE_PART = 0.5\ndata_quality = 'DIRTY_CLEAN'","3ecc137d":"# Train from ImageNet-trainable Weights Learning (IWL) -> True\n#TRAINABLE = True\n#TL_name = 'NOTL'\n# Transfer Learning (TL) -> False\nTRAINABLE = False\nTL_name = 'TL'","7d8be95f":"# With Data Augmentation -> True\n#DA = True\n#DA_name = 'DA' \n# Without Data Augmentation -> False\nDA = False\nDA_name = 'NODA' \n\nEPOCHS = EPOCHS_KFOLD\nmodel_name, figures_dir = model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name)\nif KFOLD: run_kfold()","6b5618c7":"%%time\nEPOCHS = EPOCHS_TEST\nmodel, best_model_metrics_filename = run_final(test_data, test_label)\ntest_model(model, best_model_metrics_filename, test_data, test_label)","adaeaab5":"# With Data Augmentation -> True\nDA = True\nDA_name = 'DA' \n# Without Data Augmentation -> False\n#DA = False\n#DA_name = 'NODA' \n\nEPOCHS = EPOCHS_KFOLD\nmodel_name, figures_dir = model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name)\nif KFOLD: run_kfold()","6300cd12":"%%time\nEPOCHS = EPOCHS_TEST\nmodel, best_model_metrics_filename = run_final(test_data, test_label)\ntest_model(model, best_model_metrics_filename, test_data, test_label)","41987b1e":"# Train from ImageNet-trainable Weights Learning (IWL) -> True\nTRAINABLE = True\nTL_name = 'NOTL'\n# Transfer Learning (TL) -> False\n#TRAINABLE = False\n#TL_name = 'TL'","e982ab07":"# With Data Augmentation -> True\n#DA = True\n#DA_name = 'DA' \n# Without Data Augmentation -> False\nDA = False\nDA_name = 'NODA' \n\nEPOCHS = EPOCHS_KFOLD\nmodel_name, figures_dir = model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name)\nif KFOLD: run_kfold()","2df47070":"%%time\nEPOCHS = EPOCHS_TEST\nmodel, best_model_metrics_filename = run_final(test_data, test_label)\ntest_model(model, best_model_metrics_filename, test_data, test_label)","f7ec723e":"# With Data Augmentation -> True\nDA = True\nDA_name = 'DA' \n# Without Data Augmentation -> False\n#DA = False\n#DA_name = 'NODA' \n\nEPOCHS = EPOCHS_KFOLD\nmodel_name, figures_dir = model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name)\nif KFOLD: run_kfold()","97160493":"%%time\nEPOCHS = EPOCHS_TEST\nmodel, best_model_metrics_filename = run_final(test_data, test_label)\ntest_model(model, best_model_metrics_filename, test_data, test_label)","cbe38d11":"# Train from ImageNet-trainable Weights\n#WEIGHTS = 'imagenet'\n#WEIGHTS_name = 'imagenet'\n# Train from scratch\nWEIGHTS = None\nWEIGHTS_name = 'random'","b287e3a9":"# Clean dataset \nNOISE_PART = 0.0\ndata_quality = 'CLEAN'\n\n# Dirty dataset \n#NOISE_PART = 1.0\n#data_quality = 'DIRTY'\n\n# Dirty & Clean dataset \n#NOISE_PART = 0.5\n#data_quality = 'DIRTY_CLEAN'","f0b693de":"# Train from ImageNet-trainable Weights Learning (IWL) -> True\nTRAINABLE = True\nTL_name = 'NOTL'\n# Transfer Learning (TL) -> False\n#TRAINABLE = False\n#TL_name = 'TL'","b2857d1b":"# With Data Augmentation -> True\n#DA = True\n#DA_name = 'DA' \n# Without Data Augmentation -> False\nDA = False\nDA_name = 'NODA' \n\nEPOCHS = EPOCHS_KFOLD\nmodel_name, figures_dir = model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name)\nif KFOLD: run_kfold()","c4dfd986":"%%time\nEPOCHS = EPOCHS_TEST\nmodel, best_model_metrics_filename = run_final(test_data, test_label)\ntest_model(model, best_model_metrics_filename, test_data, test_label)","96a15709":"# With Data Augmentation -> True\nDA = True\nDA_name = 'DA' \n# Without Data Augmentation -> False\n#DA = False\n#DA_name = 'NODA' \n\nEPOCHS = EPOCHS_KFOLD\nmodel_name, figures_dir = model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name)\nif KFOLD: run_kfold()","228155bd":"%%time\nEPOCHS = EPOCHS_TEST\nmodel, best_model_metrics_filename = run_final(test_data, test_label)\ntest_model(model, best_model_metrics_filename, test_data, test_label)","fc03bd90":"# Clean dataset \n#NOISE_PART = 0.0\n#data_quality = 'CLEAN'\n\n# Dirty dataset \nNOISE_PART = 1.0\ndata_quality = 'DIRTY'\n\n# Dirty & Clean dataset \n#NOISE_PART = 0.5\n#data_quality = 'DIRTY_CLEAN'","ee52178c":"# Train from ImageNet-trainable Weights Learning (IWL) -> True\nTRAINABLE = True\nTL_name = 'NOTL'\n# Transfer Learning (TL) -> False\n#TRAINABLE = False\n#TL_name = 'TL'","fb0cbeac":"# With Data Augmentation -> True\n#DA = True\n#DA_name = 'DA' \n# Without Data Augmentation -> False\nDA = False\nDA_name = 'NODA' \n\nEPOCHS = EPOCHS_KFOLD\nmodel_name, figures_dir = model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name)\nif KFOLD: run_kfold()","4735c28b":"%%time\nEPOCHS = EPOCHS_TEST\nmodel, best_model_metrics_filename = run_final(test_data, test_label)\ntest_model(model, best_model_metrics_filename, test_data, test_label)","1b9b79b0":"# With Data Augmentation -> True\nDA = True\nDA_name = 'DA' \n# Without Data Augmentation -> False\n#DA = False\n#DA_name = 'NODA' \n\nEPOCHS = EPOCHS_KFOLD\nmodel_name, figures_dir = model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name)\nif KFOLD: run_kfold()","08bd978f":"%%time\nEPOCHS = EPOCHS_TEST\nmodel, best_model_metrics_filename = run_final(test_data, test_label)\ntest_model(model, best_model_metrics_filename, test_data, test_label)","2344c7ec":"# Clean dataset \n#NOISE_PART = 0.0\n#data_quality = 'CLEAN'\n\n# Dirty dataset \n#NOISE_PART = 1.0\n#data_quality = 'DIRTY'\n\n# Dirty & Clean dataset \nNOISE_PART = 0.5\ndata_quality = 'DIRTY_CLEAN'","5f7294b2":"# Train from ImageNet-trainable Weights Learning (IWL) -> True\nTRAINABLE = True\nTL_name = 'NOTL'\n# Transfer Learning (TL) -> False\n#TRAINABLE = False\n#TL_name = 'TL'","ff64fae5":"# With Data Augmentation -> True\n#DA = True\n#DA_name = 'DA' \n# Without Data Augmentation -> False\nDA = False\nDA_name = 'NODA' \n\nEPOCHS = EPOCHS_KFOLD\nmodel_name, figures_dir = model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name)\nif KFOLD: run_kfold()","ca2b8f4c":"%%time\nEPOCHS = EPOCHS_TEST\nmodel, best_model_metrics_filename = run_final(test_data, test_label)\ntest_model(model, best_model_metrics_filename, test_data, test_label)","f7300306":"# With Data Augmentation -> True\nDA = True\nDA_name = 'DA' \n# Without Data Augmentation -> False\n#DA = False\n#DA_name = 'NODA' \n\nEPOCHS = EPOCHS_KFOLD\nmodel_name, figures_dir = model_version_folders(model_prefix, data_quality, TL_name, EPOCHS, WEIGHTS_name, DA_name)\nif KFOLD: run_kfold()","c06b8191":"%%time\nEPOCHS = EPOCHS_TEST\nmodel, best_model_metrics_filename = run_final(test_data, test_label)\ntest_model(model, best_model_metrics_filename, test_data, test_label)","afe95c91":"#### Regime = DIRTY + NOTL + NODA","c822eb0d":"# Model_class","3d67f3f0":"#### Regime = DIRTY + CLEAN + TL + NODA","e4a197a7":"### Regime = CLEAN + NOTL","6355129b":"#### Regime = DIRTY + NOTL + DA","9827edf0":"### Regime = DIRTY + CLEAN + NOTL","738bf2e1":"#### Regime = CLEAN + TL + NODA","de6fcffb":"# Plot functions","faa65d45":"#### Regime = CLEAN + NOTL + DA","deae9204":"#### Regime = DIRTY + CLEAN + NOTL + NODA","bbb9ea11":"### Regime = DIRTY + CLEAN + NOTL","ba82c689":"## Regime = DIRTY","cd11f0d2":"#### Regime = DIRTY + TL + NODA","d93336a0":"#### Regime = DIRTY + CLEAN + NOTL + DA","ec819a4b":"## Regime = DIRTY + CLEAN","4660f604":"#### Regime = DIRTY + CLEAN + TL + DA","258f8dbc":"### Regime = DIRTY + CLEAN + TL","9219b06a":"## Data PreProcessing ","64f95a51":"#### Regime = DIRTY + CLEAN + NOTL + DA","6cfcacdb":"### Regime = CLEAN + TL","53809676":"#### Regime = CLEAN + NOTL + NODA","35ffdf05":"#### Regime = DIRTY + NOTL + DA","ae8ceeb7":"## Regime = CLEAN","76e50efd":"# Prepare data","c305bc80":"### Regime = DIRTY + TL","ca2e52a3":"### Regime = DIRTY + NOTL","bf2d4e5d":"### Regime = DIRTY + NOTL","7a660dcc":"#### TEST -> model","d24080fe":"## Load from Local Storage","c1da926c":"# From random weights","a9bea274":"#### Regime = DIRTY + CLEAN + NOTL + NODA","45bd9b8f":"#### Regime = DIRTY + NOTL + NODA","82a331f1":"# Different number of images","47bc58d9":"## Regime = DIRTY + CLEAN","9dba1a7f":"## Regime = DIRTY","24ec206a":"### Regime = CLEAN + NOTL","4a77aa2e":"# Regime = CLEAN","bcee9b7a":"#### Regime = CLEAN + TL + DA","389b8d96":"## Load from Kaggle","68ebdbe7":"#### Regime = CLEAN + NOTL + DA","a89adb05":"# Regimes","fb61fa28":"#### Regime = DIRTY + TL + DA","e2399d23":"#### Regime = CLEAN + NOTL + NODA"}}