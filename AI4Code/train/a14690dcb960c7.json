{"cell_type":{"d97383a9":"code","e94daf07":"code","4b256c85":"code","ab9984f5":"code","06103ffe":"code","a67edbe0":"code","5eebcc91":"code","5602bf54":"code","262f8f5e":"code","8e144939":"code","6d132c86":"code","35a3fcbf":"code","e41f8dcf":"code","17b5a79e":"code","ec015c7e":"code","c53770f7":"code","69337aba":"code","bb0d5588":"code","b92e9a42":"code","6abd8ae3":"code","c5af96bb":"code","48f60b73":"code","21aa905c":"code","308d1924":"code","118a89fc":"code","495597b9":"code","62b51007":"code","fb746538":"code","63bdd90e":"code","02318925":"markdown","a1de55c5":"markdown","be1c9d9a":"markdown","810fa50d":"markdown","317f3563":"markdown","3bfb22d0":"markdown","30ad2625":"markdown","2ced3a74":"markdown","b8d74fbc":"markdown","dd5e02fe":"markdown","0f4e3e9b":"markdown","8b3746bc":"markdown","122b4582":"markdown","2f81b745":"markdown"},"source":{"d97383a9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","e94daf07":"column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\nhousing_df = pd.read_csv(\"..\/input\/boston-house-prices\/housing.csv\", header=None, delimiter=r\"\\s+\", names=column_names)\nhousing_df.head(10)","4b256c85":"housing_df.describe()","ab9984f5":"housing_df.info()","06103ffe":"import matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\nimport plotly.express as px","a67edbe0":"housing_df.corr()","5eebcc91":"sns.set_style('darkgrid')\nmatplotlib.rcParams['font.size'] = 14\nmatplotlib.rcParams['figure.figsize'] = (10, 6)\nmatplotlib.rcParams['figure.facecolor'] = '#00000000'","5602bf54":"plt.figure(figsize = (20 ,10))\nsns.boxplot(data=housing_df.drop('MEDV' , axis=1))","262f8f5e":"sns.scatterplot(x='LSTAT',y=\"MEDV\" , data=housing_df);","8e144939":"sns.pairplot(housing_df)","6d132c86":"from sklearn.preprocessing import StandardScaler","35a3fcbf":"inputs = housing_df.drop('MEDV', axis=1)\nscaler = StandardScaler().fit(inputs)","e41f8dcf":"scaled_inputs = scaler.transform(inputs)","17b5a79e":"print(pd.DataFrame(scaled_inputs).describe())\nscaled_inputs","ec015c7e":"sns.boxplot(data=pd.DataFrame(scaled_inputs))","c53770f7":"targets= housing_df['MEDV']","69337aba":"from sklearn.model_selection import train_test_split","bb0d5588":"inputs_train , inputs_test , targets_train , targets_test = train_test_split(scaled_inputs , targets , test_size=0.25,random_state=4)","b92e9a42":"pd.DataFrame(inputs_test)[[0 , 5 , 12]].to_numpy().shape","6abd8ae3":"nw_input_train , nw_input_test = pd.DataFrame(inputs_train)[[0 , 5 , 12]].to_numpy() , pd.DataFrame(inputs_test)[[0 , 5 , 12]].to_numpy()","c5af96bb":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import explained_variance_score\nfrom sklearn.metrics import mean_squared_error","48f60b73":"#instantiate the model\nmodel = LinearRegression()\n\n#fit the model on trianing data\nmodel.fit(nw_input_train , targets_train)\n\n#predictions\npreds = model.predict(nw_input_test)\n# loss\nvar = explained_variance_score(targets_test , preds)\nloss = np.sqrt(mean_squared_error(targets_test , preds))\nprint('Variance Score : ' , var)\nprint('RMSE loss: ', loss)","21aa905c":"#instantiate the model\nmodel = LinearRegression()\n\n#fit the model on trianing data\nmodel.fit(inputs_train , targets_train)\n\n#predictions\npreds = model.predict(inputs_test)\n# loss\nvar = explained_variance_score(targets_test , preds)\nloss = np.sqrt(mean_squared_error(targets_test , preds))\nprint('Variance Score : ' , var)\nprint('RMSE loss: ', loss)","308d1924":"from sklearn.linear_model import SGDRegressor","118a89fc":"#instantiate the model\nmodel = SGDRegressor()\n\n#fit the model on trianing data\nmodel.fit(nw_input_train , targets_train)\n\n#predictions\npreds = model.predict(nw_input_test)\n# loss\nvar = explained_variance_score(targets_test , preds)\nloss = np.sqrt(mean_squared_error(targets_test , preds))\nprint('Variance Score : ' , var)\nprint('RMSE loss: ', loss)","495597b9":"#instantiate the model\nmodel = SGDRegressor()\n\n#fit the model on trianing data\nmodel.fit(inputs_train , targets_train)\n\n#predictions\npreds = model.predict(inputs_test)\n# loss\nvar = explained_variance_score(targets_test , preds)\nloss = np.sqrt(mean_squared_error(targets_test , preds))\nprint('Variance Score : ' , var)\nprint('RMSE loss: ', loss)","62b51007":"from sklearn.linear_model import Ridge","fb746538":"#instantiate the model\nmodel = Ridge()\n\n#fit the model on trianing data\nmodel.fit(nw_input_train , targets_train)\n\n#predictions\npreds = model.predict(nw_input_test)\n# loss\nvar = explained_variance_score(targets_test , preds)\nloss = np.sqrt(mean_squared_error(targets_test , preds))\nprint('Variance Score : ' , var)\nprint('RMSE loss: ', loss)","63bdd90e":"#instantiate the model\nmodel = Ridge()\n\n#fit the model on trianing data\nmodel.fit(inputs_train , targets_train)\n\n#predictions\npreds = model.predict(inputs_test)\n# loss\nvar = explained_variance_score(targets_test , preds)\nloss = np.sqrt(mean_squared_error(targets_test , preds))\nprint('Variance Score : ' , var)\nprint('RMSE loss: ', loss)","02318925":"# Approach\nSince there are only numerical columns we won't need to use encoders. So the basic approach is as follows:\n- Exploratory Data Analysis\n- Get The inputs & targets\n- Scale the inputs\n- Train\/Test Split \n- Model Selection ( we'll using linear regression and sochastic gradient descent)\n- Train the Model \n- Make Predictions \n- Use the test set for Validation","a1de55c5":"# Scaling The Columns","be1c9d9a":"# Summary\nThe Dateset is too small so the model is not realistic and the most of the features and with low correlations. \nWe've tried the 3 basic linear regressors and out of them Linear Regressor has the least RMSE error.","810fa50d":"Let's also create an array with CRIM, RM, LSTAT columns as features.","317f3563":"# Train\/Test Split","3bfb22d0":"#### Linear Model With All Features","30ad2625":"# Stochastic Gradient Descent Model","2ced3a74":"### Creating Input\/Target arrays","b8d74fbc":"The loss in the model with all features is higher, which should be quite obvious, but as a ML engineer it's your job to verify the obvious too.","dd5e02fe":"## Important Columns\nWe see that CRIM, RM, LSTAT are columns which have a high correlation or rather they seem to have a polynomial relation.\nSo let's try to build a model on these columns first rather than taking the whole dataset.","0f4e3e9b":"#### Model With Only Important Columns","8b3746bc":"# Ridge Model","122b4582":"# DataSet\nEach record in the database describes a Boston suburb or town. The data was drawn from the Boston Standard Metropolitan Statistical Area (SMSA) in 1970. The attributes are de\ufb01ned as follows (taken from the UCI Machine Learning Repository1): CRIM: per capita crime rate by town\n\n1. ZN: proportion of residential land zoned for lots over 25,000 sq.ft.  \n2. INDUS: proportion of non-retail business acres per town  \n3. CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)  \n4. NOX: nitric oxides concentration (parts per 10 million)  \n5. RM: average number of rooms per dwelling  \n6. AGE: proportion of owner-occupied units built prior to 1940  \n7. DIS: weighted distances to \ufb01ve Boston employment centers  \n8. RAD: index of accessibility to radial highways  \n9. TAX: full-value property-tax rate per \\$10K   \n10. PTRATIO: pupil-teacher ratio by town  \n11. B: 1000(Bk\u22120.63)2 where Bk is the proportion of blacks by town   \n12. LSTAT: % lower status of the population  \n13. MEDV: Median value of owner-occupied homes in $1000s  \n","2f81b745":"# Linear Regression Model"}}