{"cell_type":{"4f063bc3":"code","95047cc0":"code","97d9c53a":"code","9a6eebe4":"code","48dd832d":"code","2baa2ee6":"code","be84c25f":"code","8452130f":"code","5a6635f5":"code","e751efe3":"code","0a668c9c":"code","2991c794":"code","b4fa9060":"code","c9d3cb22":"code","2751f208":"code","9f9a5d84":"code","a41ade98":"code","91ee8c74":"code","70428062":"code","52414cff":"code","e663f0d7":"code","822732ef":"code","19f8a8f9":"code","81279806":"code","441c5d41":"code","34dff4fd":"code","af6038b4":"code","cc8c844c":"code","a8358769":"code","ed9a9670":"code","24807a75":"code","bb7cf276":"code","146e05cf":"code","b6e9326a":"code","315e6fb1":"code","402e8df0":"markdown","04bde7db":"markdown","987faec7":"markdown","3621b061":"markdown","0558f4e3":"markdown","4d483fa8":"markdown","dd9064a1":"markdown","e5d1a390":"markdown","6ad6aa97":"markdown","d4c51c8a":"markdown","1ac9d5f7":"markdown","1ba1bd0a":"markdown","ef57ea10":"markdown","a9c2188a":"markdown","fca50a0c":"markdown"},"source":{"4f063bc3":"import numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn import covariance\nfrom sklearn import compose\nfrom sklearn import model_selection\nfrom sklearn import pipeline\nfrom sklearn import linear_model\nfrom sklearn import metrics\nfrom sklearn import decomposition\nfrom sklearn.svm import LinearSVC","95047cc0":"df = pd.read_csv(\"\/kaggle\/input\/dataset-of-songs-in-spotify\/genres_v2.csv\")\nprint(df.shape)\ndf.head()","97d9c53a":"df.info()","9a6eebe4":"#drop unneeded columns\ndf.drop(columns=['type', 'id', 'uri', 'track_href', 'analysis_url', 'song_name', 'Unnamed: 0', 'title'], inplace=True)\nprint(df.shape)\ndf.head()","48dd832d":"df.describe()","2baa2ee6":"#is there empty values\ndf.isna().sum()","be84c25f":"df.info()","8452130f":"df['genre'].value_counts()","5a6635f5":"df['time_signature'].value_counts()","e751efe3":"histograms = df.hist(figsize=(10,10))\nplt.show()","0a668c9c":"for col in df.select_dtypes(include=np.number).columns.tolist():\n  fig = px.box(df, \n        color = \"genre\",\n        y = col, \n        title = col\n       )\n  fig.show()","2991c794":"# scater matrix drawing fnc\ndef scatterMatrix(df):\n  df_2_charts = df.copy();\n  \n  kolumny = pd.Index(df.columns).tolist()\n  wykres = px.scatter_matrix(df_2_charts, dimensions=kolumny[:-1], color=\"genre\")\n  wykres.update_layout(autosize=True, width=2000, height=2000)\n  wykres.show()","b4fa9060":"scatterMatrix(df)","c9d3cb22":"### outlayers - IQR\ndef IQR_outliers(data, outlayers):\n  Q1, Q3 = np.percentile(data, [25, 75])\n  IQR = Q3 - Q1\n\n  u_band  = Q3 + (1.5 * IQR)\n  l_band  = Q1 - (1.5 * IQR)\n  idx = np.where((data > u_band) | (data < l_band))\n  outlayers[idx] = True\n  \n  return outlayers\n\n#outlayers array, by default row is treated as non outlayer\noutlayers = np.full(shape=df.shape[0], fill_value=False)\n\ncols = df.select_dtypes(include=np.number).columns.tolist()\n#for each feature - mark outlayers\nfor col in cols[:-1]:\n  outlayers = IQR_outliers(df[col], outlayers)\n\n\noutIdx = [i for i,x in enumerate(outlayers) if x == True]\ndf_nonoutlayers_by_iqr = df.drop(outIdx)\ndf_nonoutlayers_by_iqr.head(10)\ndf_nonoutlayers_by_iqr.shape","2751f208":"### Outlayers - elipticEnvelope\n\n\ndetector = covariance.EllipticEnvelope(contamination=0.1, support_fraction=1)\n\ntoOutlayers = df.drop(columns=\"genre\")\ndetector.fit(toOutlayers)\n\nol_flag = detector.predict(toOutlayers)\n\noutIdx = [i for i,x in enumerate(ol_flag) if x == -1]\n\ndf_nonoutlayers_by_envelope = df.drop(outIdx)\ndf_nonoutlayers_by_envelope.head(10)\ndf_nonoutlayers_by_envelope.shape ","9f9a5d84":"#Select dataframe for further processing\n\n#original with all rows\ndf_pre_model = df.copy()\n\n#without rows detected by elipticEnvelope\n#df_pre_model = df_nonoutlayers_by_envelope.copy()\n\n#without rows detected by IQR\n#df_pre_model = df_nonoutlayers_by_iqr.copy()\ndf_pre_model.shape","a41ade98":"df_pre_model.var()","91ee8c74":"#low voarince features\n\n\nlow_var = df_pre_model.var()\nlow_var = low_var[low_var < 0.02 ]\n\nlow_var_cols = low_var.index.tolist()\nprint(low_var_cols)","70428062":"#remove low varaince features\n\n#be carful - when dropping outlayers variance differ\n#this suits well using all rows\n\n \ndf_pre_model.drop(columns=low_var_cols, inplace=True);","52414cff":"#There is no highly correlated values - do not drop any features\ndf2Corr = df_pre_model.copy();\ndf2Corr['genre'] = preprocessing.LabelEncoder().fit_transform(df2Corr['genre'])\ncorrMx = df2Corr.corr()\ncorrMx.style.background_gradient(cmap = \"RdBu_r\")","e663f0d7":"#treat a time_signature as as category value\n\n#be carful - dropping low variance features may drop also time_signature\n\ndf_category = pd.get_dummies(df_pre_model, columns=['time_signature'], prefix_sep='_')\n\ndf_category.shape","822732ef":"def buildModel(algo, X_train, X_test, y_train, y_test):\n  \n  # train model\n  algo.fit(X_train, y_train)\n\n  predict = algo.predict(X_test)\n\n  # accuracy\n  accuracy = algo.score(X_test, y_test)\n  \n  return {\n      \"predict\": predict,\n      \"accuracy\": accuracy\n  }","19f8a8f9":"def modelCrossValidation(X, Y, algo):\n\n  validation = model_selection.KFold(\n      n_splits=5, shuffle=True, random_state=1\n  )\n  statsNames = ['accuracy', 'balanced_accuracy', 'f1_weighted', 'f1_macro']\n\n  res = {}\n  for sname in statsNames:\n    res[sname] =  round(model_selection.cross_val_score(algo, \n                                                    X,\n                                                    Y,\n                                                    cv=validation,\n                                                    scoring=sname,\n                                                    n_jobs=-1).mean(), 2)\n  return res","81279806":"X1 = df_category.drop(columns=['genre'])\nY1 = df_category[\"genre\"]\nX1.head()","441c5d41":"from imblearn.over_sampling import SMOTE\n\nX1_std = preprocessing.StandardScaler().fit_transform(X1)\n\n\nsmote = SMOTE()\nX1, Y1 = smote.fit_resample(X1_std, Y1)\n\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X1, \n                                                                    Y1, \n                                                                    test_size=.2, \n                                                                    random_state=1,\n                                                                    shuffle=True\n                                                                    )\n\nscoring = [['model name','accuracy']]","34dff4fd":"##LogisticRegression;\n\nalgLR = linear_model.LogisticRegression(max_iter=1000);\nresLR = buildModel(algLR, X_train, X_test, y_train, y_test)\n\nscoring.append([\n      'LogisticRegression', \n      resLR[\"accuracy\"]\n])\nprint(scoring)","af6038b4":"## LinearSVC\n\nalgLSVC = LinearSVC(random_state=1, max_iter=5000)\nresLSVC = buildModel(algLSVC, X_train, X_test, y_train, y_test)\n\nscoring.append([\n   'LinearSVC', \n   resLSVC[\"accuracy\"]\n])\n  \nprint(scoring)","cc8c844c":"from sklearn.neighbors import KNeighborsClassifier\n\n## KNeighborsClassifier\n\nalgKNC = KNeighborsClassifier(n_neighbors=5)\nresKNC = buildModel(algKNC, X_train, X_test, y_train, y_test)\n\nscoring.append([\n                  'KNeighborsClassifier', \n                  resKNC[\"accuracy\"]\n                ])\nprint(scoring)","a8358769":"from sklearn.ensemble import RandomForestClassifier\n\n# RandomForestClassifier\n\nalgRFC = RandomForestClassifier(random_state  = 1, max_depth = 10  )\nresRFC = buildModel(algRFC, X_train, X_test, y_train, y_test)\n\nscoring.append([\n                  'RandomForestClassifier', \n                  resRFC[\"accuracy\"]\n                ])\nprint(scoring)\n","ed9a9670":"from sklearn.ensemble import BaggingClassifier\n\n# BaggingClassifier\n\nalgBag = BaggingClassifier()\nresBag = buildModel(algBag, X_train, X_test, y_train, y_test)\n\nscoring.append([\n                  'BaggingClassifier', \n                  resBag[\"accuracy\"]\n                ])\nprint(scoring)","24807a75":"#draw chart to compare algorithms\n\ntoChart = pd.DataFrame(scoring, columns =['algorithm', 'accuracy']) \ntoChart.drop(0, inplace=True)\n\npx.bar(toChart, x=\"algorithm\", y=\"accuracy\")","bb7cf276":"#best alg\nbestAlg = algKNC;\n\nvres = modelCrossValidation(X_train, y_train, bestAlg)\nprint(vres)","146e05cf":"#print metrics\nprint(metrics.classification_report(y_test, resKNC['predict']))","b6e9326a":"print(\"Confusion matrix: \");\nprint(metrics.confusion_matrix(y_test, resKNC['predict'], labels=np.unique(y_test)), sep=\"\\n\")","315e6fb1":"\nfig, ax = plt.subplots(figsize=(15, 15))\nmetrics.plot_confusion_matrix(bestAlg, X_test, y_test, ax=ax)","402e8df0":"## Select data for further processing","04bde7db":"## Correlation analysys ","987faec7":"\nI used some ideas found here:\n* 1. https:\/\/www.kaggle.com\/giorgosdiamantis\/song-genre-classification\n* https:\/\/www.kaggle.com\/jubsadeghi\/spotify\n* https:\/\/www.kaggle.com\/botirrakhimov\/genre-prediction-using-sklearn-classification\n","3621b061":"## Helper functions ","0558f4e3":"# Bulding models","4d483fa8":"# Data description","dd9064a1":"## Models","e5d1a390":"# Comapre models results","6ad6aa97":"## Outlayers - eliptic envelope","d4c51c8a":"## Outlayers - IQR","1ac9d5f7":"## Category coding","1ba1bd0a":"# Data preparation","ef57ea10":"# Best model validation","a9c2188a":"## Variance analysys","fca50a0c":"## Split test and train data"}}