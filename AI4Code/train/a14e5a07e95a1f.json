{"cell_type":{"eb29109c":"code","75ad35ad":"code","bd523347":"code","8984e723":"code","8477d87c":"code","fb5cecf0":"code","a71d052d":"code","10ce6656":"code","93640c42":"code","62243321":"code","4f83da93":"code","43210a6b":"code","e423a9fd":"code","d1c2a2ca":"code","d56e1f4a":"code","4840ff37":"code","8b2a047e":"code","ce1c8000":"code","d80ce64a":"code","d52b1a6a":"code","8b55adfb":"code","051a79c6":"code","3105dea8":"code","ccee6092":"code","45d3dd34":"code","da5e70e1":"code","2e3770b3":"code","b3cf8018":"code","9103ad4f":"code","fd358563":"code","7fd9be9d":"code","b92384d8":"code","8fba7036":"code","482dfce7":"code","faac9a72":"code","df0f8f1c":"code","36a7f423":"code","bbadf6e7":"code","4dc1cdc0":"markdown","92da4638":"markdown","c4929254":"markdown","f4a2119a":"markdown","827a4485":"markdown","6e290adb":"markdown","9cb7d871":"markdown","ab3325b6":"markdown","c9e68fa1":"markdown","da5f84ab":"markdown","f6138c8f":"markdown","f8972eff":"markdown","ecf917ed":"markdown","2f59a54c":"markdown","f7e989b1":"markdown"},"source":{"eb29109c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","75ad35ad":"df = pd.read_csv('..\/input\/real-estate-price-prediction\/Real estate.csv')","bd523347":"df.head()","8984e723":"df.info()","8477d87c":"sns.pairplot(data = df,\n             x_vars = [\"X1 transaction date\" ,\n                      \"X2 house age\" ,\n                      \"X3 distance to the nearest MRT station\",\n                      \"X4 number of convenience stores\" ,\n                      \"X5 latitude\" ,\n                      \"X6 longitude\" ,\n                      \"Y house price of unit area\"],\n             y_vars = [\"X1 transaction date\" ,\n                      \"X2 house age\" ,\n                      \"X3 distance to the nearest MRT station\",\n                      \"X4 number of convenience stores\" ,\n                      \"X5 latitude\" ,\n                      \"X6 longitude\" ,\n                      \"Y house price of unit area\"]\n            )","fb5cecf0":"# Features:\nX = df.drop(['Y house price of unit area'  , 'No'] , axis = 1)\n# Label:\ny = df['Y house price of unit area']","a71d052d":"from sklearn.preprocessing import PolynomialFeatures","10ce6656":"polynomial_converter= PolynomialFeatures(degree=3, include_bias=False)\npoly_features= polynomial_converter.fit_transform(X)\npoly_features.shape","93640c42":"from sklearn.model_selection import train_test_split","62243321":"X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=101)","4f83da93":"from sklearn.preprocessing import StandardScaler","43210a6b":"scaler= StandardScaler()\nscaler.fit(X_train)","e423a9fd":"X_train= scaler.transform(X_train)\nX_test= scaler.transform(X_test)","d1c2a2ca":"from sklearn.linear_model import Ridge","d56e1f4a":"ridge_model= Ridge(alpha=10)\nridge_model.fit(X_train, y_train)","4840ff37":"#predict Test Data\ny_pred = ridge_model.predict(X_test)","8b2a047e":"#Evaluating the Model\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\nMAE= mean_absolute_error(y_test, y_pred)\nMSE= mean_squared_error(y_test, y_pred)\nRMSE= np.sqrt(MSE)","ce1c8000":"pd.DataFrame([MAE, MSE, RMSE], index=['MAE', 'MSE', 'RMSE'], columns=['metrics'])","d80ce64a":"#Train the Model\nfrom sklearn.linear_model import RidgeCV","d52b1a6a":"ridge_cv_model=RidgeCV(alphas=(0.1, 1.0, 10.0), scoring='neg_mean_absolute_error')","8b55adfb":"ridge_cv_model.fit(X_train, y_train)","051a79c6":"ridge_cv_model.alpha_","3105dea8":"#Predicting Test Data\ny_pred_ridge= ridge_cv_model.predict(X_test)","ccee6092":"MAE_ridge= mean_absolute_error(y_test, y_pred_ridge)\nMSE_ridge= mean_squared_error(y_test, y_pred_ridge)\nRMSE_ridge= np.sqrt(MSE_ridge)","45d3dd34":"pd.DataFrame([MAE_ridge, MSE_ridge, RMSE_ridge], index=['MAE', 'MSE', 'RMSE'], columns=['Ridge Metrics'])","da5e70e1":"ridge_cv_model.coef_","2e3770b3":"from sklearn.linear_model import LassoCV","b3cf8018":"lasso_cv_model= LassoCV(eps=0.01, n_alphas=100, cv=5)\nlasso_cv_model.fit(X_train, y_train)","9103ad4f":"lasso_cv_model.alpha_","fd358563":"y_pred_lasso= lasso_cv_model.predict(X_test)","7fd9be9d":"MAE_Lasso= mean_absolute_error(y_test, y_pred_lasso)\nMSE_Lasso= mean_squared_error(y_test, y_pred_lasso)\nRMSE_Lasso= np.sqrt(MSE_Lasso)\npd.DataFrame([MAE_Lasso, MSE_Lasso, RMSE_Lasso], index=['MAE', 'MSE', 'RMSE'], columns=['Lasso Metrics'])","b92384d8":"lasso_cv_model.coef_","8fba7036":"from sklearn.linear_model import ElasticNetCV","482dfce7":"elastic_model= ElasticNetCV(l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1],cv=5, max_iter=100000)\nelastic_model.fit(X_train, y_train)","faac9a72":"elastic_model.l1_ratio_","df0f8f1c":"y_pred_elastic=elastic_model.predict(X_test)","36a7f423":"MAE_Elastic= mean_absolute_error(y_test, y_pred_elastic)\nMSE_Elastic= mean_squared_error(y_test, y_pred_elastic)\nRMSE_Elastic= np.sqrt(MSE_Elastic)\npd.DataFrame([MAE_Elastic, MSE_Elastic, RMSE_Elastic], index=['MAE', 'MSE', 'RMSE'], columns=['Elastic Metrics'])","bbadf6e7":"elastic_model.coef_","4dc1cdc0":"#### Ridge Regression (Coosing an alpha value with Cross-Validation)","92da4638":"#### EDA:","c4929254":"#### Split the Data to Train & Test","f4a2119a":"#### 2- Lasso Regression","827a4485":"#### 3- Elastic Net","6e290adb":"#### Scaling the Data","9cb7d871":"## Introduction\nOne of the major aspects of training your machine learning model is avoiding overfitting. The model will have a low accuracy if it is overfitting. This happens because your model is trying too hard to capture the noise in your training dataset. By noise we mean the data points that don\u2019t really represent the true properties of your data, but random chance. Learning such data points, makes your model more flexible, at the risk of overfitting.\n\nThe concept of balancing bias and variance, is helpful in understanding the phenomenon of overfitting.\n\nOne of the ways of avoiding overfitting is using cross-validation, that helps in estimating the error over test set, and in deciding what parameters work best for your model.\n\n## Regularization\nThis is a form of regression, that constrains\/ regularizes or shrinks the coefficient estimates towards zero. In other words, this technique discourages learning a more complex or flexible model, so as to avoid the risk of overfitting.\n\nRead full article about Regularization method [here](https:\/\/towardsdatascience.com\/regularization-in-machine-learning-76441ddcf99a).","ab3325b6":"#### Preprocessing (Polynomial Conversion)","c9e68fa1":"### Regularization","da5f84ab":"#### Take a look at dataset","f6138c8f":"#### Determine the Features & Target Variable (Lable)","f8972eff":"#### Import all Necessary Libraries","ecf917ed":"#### 1- Ridge Regression","2f59a54c":"# Regression Regularization: Real estate price\n\nIn this notebook i'm going to apply Regression Regularization on [Real estate price prediction\n](https:\/\/www.kaggle.com\/quantbruce\/real-estate-price-prediction).\n\nThis dataset has 8 columns. The values of X1 to X6 columns affect the price per unit area of the house in the \"Y house price of unit area\" column.","f7e989b1":"#### Import the Data"}}