{"cell_type":{"2c0a1329":"code","35cb04bf":"code","ff3a0e05":"code","6e062df9":"code","fdd1846a":"code","6cfff8c9":"code","2520b85c":"code","e0af31fd":"code","bf49c5ce":"code","1fe35e06":"code","2787e81c":"markdown","57faa1bd":"markdown","a8c39917":"markdown","139c4189":"markdown","81f9741d":"markdown","52ddf15e":"markdown","6beddd07":"markdown","abfd00ae":"markdown","6b19d279":"markdown","0bdac024":"markdown","34733c3a":"markdown","5adedd0c":"markdown","2a82d640":"markdown","34d36a64":"markdown","2500d6db":"markdown","443b09f8":"markdown"},"source":{"2c0a1329":"import pandas as pd\n\ntrain_df = pd.read_csv('..\/input\/title-generation\/train.csv')\ntest_df = pd.read_csv('..\/input\/title-generation\/test.csv')","35cb04bf":"print(len(train_df))\ntrain_df.drop_duplicates(inplace=True)\nprint(len(train_df))","ff3a0e05":"test_samples_from_train = set(train_df['abstract']).intersection(set(test_df['abstract']))\nwtf_df = train_df[train_df['abstract'].isin(test_samples_from_train)]\nwtf_df.describe()","6e062df9":"bugged_title = wtf_df.abstract.mode()[0]\n# https:\/\/arxiv.org\/pdf\/1410.0163.pdf\nwtf_df[wtf_df['abstract'] == bugged_title]","fdd1846a":"wtf_df = wtf_df[wtf_df['abstract'] != bugged_title]\nuncertain_title = wtf_df.abstract.mode()[0]\nwtf_df[wtf_df['abstract'] == uncertain_title]","6cfff8c9":"wtf_df = wtf_df[wtf_df['abstract'] != uncertain_title].reset_index(drop=True)","2520b85c":"import numpy as np\nimport collections\n\nwords = [st.split() for st in train_df['title'].values]\nwords = [w for ttl in words for w in ttl]\n\nmean_title_length = np.mean(np.asarray([len(st.split()) for st in train_df['title'].values]))\nprint('Mean title length is', mean_title_length)\n\nmost_frequently_words = collections.Counter(words).most_common()[:round(mean_title_length)]\nnan_fill_value = ' '.join([el[0] for el in most_frequently_words])\nprint('BEST TITLE EVER:')\nnan_fill_value","e0af31fd":"submission_df = pd.merge(test_df, wtf_df, on='abstract', how='left').fillna(nan_fill_value)","bf49c5ce":"! wget -q https:\/\/raw.githubusercontent.com\/Samsung-IT-Academy\/stepik-dl-nlp\/master\/task11_kaggle\/create_submission.py","1fe35e06":"from create_submission import generate_csv\n\nsubmission_df.to_csv('predicted_titles.csv', index=False)\ngenerate_csv('predicted_titles.csv', 'kaggle_pred.csv', '..\/input\/title-generation\/vocs.pkl')","2787e81c":"Submit your prediciton.","57faa1bd":"As [kashnitsky mentioned](https:\/\/www.kaggle.com\/kashnitsky\/arxiv-title-generation-dumb-baseline) there is large intersection between train and test data. Let's see how bad it is.","a8c39917":"As we can see, 43% of test data was taken from train.","139c4189":"To max F1-score let's count average title length and fill it with most frequently words.","81f9741d":"Download python script.","52ddf15e":"Get rid of both of them.","6beddd07":"P.S. Now you can train your BERT trying to beat this score :)","abfd00ae":"So we have 43% perfectly labeled test. 57% left to do.","6b19d279":"***YOU ARE AWESOME!!!111***","0bdac024":"Make train\/test dataframes.","34733c3a":"One has uncertainty.","5adedd0c":"Remove duplicates from train. There is one duplicate in test data too, but we should predict all of test samples anyway, so let's just clean train.","2a82d640":"Generate serialized .csv","34d36a64":"**Simple EDA baseline.**","2500d6db":"Fill NaN values after tables merging.","443b09f8":" One sample has messed up abstract\/title pair."}}