{"cell_type":{"3ae79dd2":"code","9aec6e8e":"code","dc9f0477":"code","aaf50dce":"code","e4775956":"code","57c15540":"code","80e94ffb":"code","6ea846e1":"code","a372ca66":"code","61df758c":"code","5e5c1dc0":"code","de062e91":"code","d82be7a9":"code","11460320":"code","db62668b":"code","affa64e8":"code","a9d9421f":"code","baea0d40":"code","bd52923a":"code","5e8569ae":"code","994db8f7":"code","303401a6":"code","e47e2cd2":"code","bbc0f4f3":"code","6c79287f":"code","5ef7847f":"code","63920c55":"code","cbd8da48":"code","b091366b":"code","636423df":"code","60c134a5":"code","c195817a":"code","d7c1b70b":"code","b22a581a":"code","35751784":"code","d3c19bf7":"markdown","05130f66":"markdown","d28ac919":"markdown","c0a1f543":"markdown","a9690e35":"markdown","303ebbdb":"markdown","f8f51d34":"markdown","32756e98":"markdown","496591cb":"markdown","cf956f09":"markdown","58b97041":"markdown","8647def9":"markdown","5cd67e6c":"markdown","22140d1d":"markdown","78f3b5b9":"markdown","fdd9e60c":"markdown","d9c7d08e":"markdown","61a52230":"markdown","2386efcc":"markdown","b943a2c3":"markdown","2bafa9f8":"markdown","d74548b7":"markdown","6c2ad403":"markdown","19a31b47":"markdown","211c4bb1":"markdown"},"source":{"3ae79dd2":"# making all imports \n%matplotlib inline\n# %config InlineBackend.figure_format = 'retina'\nimport os\nimport glob\nimport json\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\n\nimport tensorflow as tf\nimport keras\n\nimport cv2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport logging\nlogger = tf.get_logger()\nlogger.setLevel(logging.ERROR)","9aec6e8e":"main_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/\"\ntrain_data_dir = main_dir + \"train\/\"\nvalidation_data_dir = main_dir + \"val\/\"\ntest_data_dir = main_dir + \"test\/\"\n\n\nprint(\"Working Directory Contents:\", os.listdir(main_dir))\n\n# creating path is really important when we deal with multiple folder and files ","dc9f0477":"train_n = train_data_dir+'NORMAL\/'\ntrain_p = train_data_dir+'PNEUMONIA\/'\n\nprint(\"length of cases in training set:\",len(os.listdir(train_p)) + len(os.listdir(train_n)))\nprint(\"length of pneumonia cases in training set:\",len(os.listdir(train_p)))\nprint(\"length of normal cases in training set:\",len(os.listdir(train_n)))","aaf50dce":"# Quick look to the images \nclahe = cv2.createCLAHE(clipLimit = 5)\n\n\nimg_name = 'IM-0115-0001.jpeg'\nimg_normal = cv2.imread('..\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\/' + img_name)\nimg_normal = cv2.resize(img_normal, (500,500))\nimg_normal = cv2.cvtColor(img_normal, cv2.COLOR_BGR2GRAY)\nimg_normal_clahe = clahe.apply(img_normal) + 30\n\n\n\nimg_name_1 = 'person1000_virus_1681.jpeg'\nimg_pneumonia = cv2.imread('..\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\/' + img_name_1)\nimg_pneumonia = cv2.resize(img_pneumonia, (500,500))\nimg_pneumonia = cv2.cvtColor(img_pneumonia, cv2.COLOR_BGR2GRAY)\nimg_pneumonia_clahe = clahe.apply(img_pneumonia) + 30\n\n\n#-----------------------------------------------------------------------------------------#\n\n\nfig, axs = plt.subplots(2,2,figsize=(10,6))\naxs[0,0].imshow(img_normal)\naxs[0,0].set_title(\"NORMAL\")\naxs[0,1].imshow(img_normal_clahe)\naxs[0,1].set_title(\"NORMAL_CLAHE\")\naxs[1,0].imshow(img_pneumonia)\naxs[1,0].set_title(\"PNEUMONIA\")\naxs[1,1].imshow(img_pneumonia_clahe)\naxs[1,1].set_title(\"PNEUMNIA_CLAHE\");\n","e4775956":"### here we will apply image augumentation only on the training images not on testing or validation \nimg_width , img_height = [224,224]\nbatch_size = 16\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    brightness_range=[0.2,1.0],\n    horizontal_flip=True)\n\n\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)\nval_datagen = ImageDataGenerator(rescale=1. \/ 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary',\n    shuffle = True)\n\nvalidation_generator = val_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary')\n\ntest_generator = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary')","57c15540":"\nimage_batch, label_batch = next(iter(train_generator))\n\ndef show_batch(image_batch, label_batch):\n    plt.figure(figsize=(10, 10))\n    for n in range(15):\n        ax = plt.subplot(5, 5, n + 1)\n        plt.imshow(image_batch[n])\n        if label_batch[n]:\n            plt.title(\"PNEUMONIA\")\n        else:\n            plt.title(\"NORMAL\")\n        plt.axis(\"off\")\n\nshow_batch(image_batch, label_batch)","80e94ffb":"nb_train_samples = 5216 # number of training samples\nnb_validation_samples = 16 # number of validation samples\nnb_test_samples = 624 # number of training samples\nepochs = 20  # number of epochs we gonna run\nbatch_size  = 16 # batch size ( at every iteration it will take 16 batches for training)","6ea846e1":"from tensorflow.keras.applications.densenet import DenseNet169\nfrom tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n\nbase = DenseNet169(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\ntf.keras.backend.clear_session()\n\nfor layer in base.layers:\n    layer.trainable =  False # freezing densenet layers \n\ndensenet_model = Sequential()\ndensenet_model.add(base)\ndensenet_model.add(GlobalAveragePooling2D())\ndensenet_model.add(BatchNormalization())\ndensenet_model.add(Dense(256, activation='relu'))\ndensenet_model.add(Dropout(0.5))\ndensenet_model.add(BatchNormalization())\ndensenet_model.add(Dense(128, activation='relu'))\ndensenet_model.add(Dropout(0.5))\ndensenet_model.add(Dense(1, activation='sigmoid'))\n\ndensenet_model.summary()","a372ca66":"# defined optimizer\noptm = Adam(lr=0.0001)\ndensenet_model.compile(loss='binary_crossentropy', optimizer=optm, \n                  metrics=['accuracy'])\n\n# defining callbacks \n\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau\nEarlyStopping = EarlyStopping(monitor='val_accuracy',\n                              min_delta=.01,\n                              patience=7,\n                              verbose=1,\n                              mode='max',\n                              baseline=None,\n                              restore_best_weights=True)\n\nrlr = ReduceLROnPlateau( monitor=\"val_accuracy\",\n                            factor=0.01,\n                            patience=3,\n                            verbose=0,\n                            mode=\"max\",\n                            min_delta=0.01)\n\nmodel_save = ModelCheckpoint('.\/densenet169.h5',\n                             save_best_only = True,\n                             save_weights_only = False,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\n\n\n","61df758c":"### Training our model\ndense_history = densenet_model.fit(train_generator,\n                              steps_per_epoch = nb_train_samples \/\/ batch_size,\n                              epochs = 20,\n                              validation_data = test_generator,\n                           \n                              callbacks=[EarlyStopping, model_save,rlr])","5e5c1dc0":"# its always a good practice to load the model after saving with the best epochs \ndensenet_model = keras.models.load_model('.\/densenet169.h5')","de062e91":"# for plotting learning curve \ndef plot(history):\n\n    training_accuracy = history.history['accuracy']\n    validation_accuracy = history.history['val_accuracy']\n\n    training_loss = history.history['loss']\n    validation_loss = history.history['val_loss']\n\n    epochs_range=range(len(training_accuracy))\n\n    plt.figure(figsize=(8, 8))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, training_accuracy, label='Training Accuracy')\n    plt.plot(epochs_range, validation_accuracy, label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.title('Training and Validation Accuracy')\n\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, training_loss, label='Training Loss')\n    plt.plot(epochs_range, validation_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.title('Training and Validation Loss')\n    plt.show()","d82be7a9":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nfrom PIL import Image\ndef predict(image_path, model):\n    im = cv2.imread(image_path)\n    test_image = np.asarray(im)\n    processed_test_image = process_image(test_image)\n    processed_test_image = np.expand_dims(processed_test_image, axis = 0)\n    \n    ps = model.predict(processed_test_image)\n    return ps\n    \ndef process_image(image):\n    image = image\/255\n    image = cv2.resize(image, (224,224))\n    return image\n\n\ndef testing(model, test_df):\n    \"\"\" the passed data must be the img_path columns and label column\"\"\"\n    base_pred =[]\n    for image in test_df.img_path:\n        base_pred.append(predict(image , model)[0][0])\n    \n    final_base_pred  = np.where(np.array(base_pred)>0.5,1,0)\n    actual_label = test_df['label']\n    # print(final_base_pred)\n\n    print(classification_report(actual_label, final_base_pred))\n    matrix=confusion_matrix(actual_label, final_base_pred)\n    sns.heatmap(matrix,square=True, annot=True, fmt='d', cbar=False,\n            xticklabels=['0', '1'],\n            yticklabels=['0', '1'])\n    plt.xlabel('Predicted label')\n    plt.ylabel('True label')","11460320":"# for evaluation point of view i have created a dataframe of test directory \ntest_data = []\ntest_normal_path = test_data_dir + '\/NORMAL'\ntest_pneumonia_path = test_data_dir + '\/PNEUMONIA'\nfor filename in os.listdir(test_normal_path):\n    test_data.append((os.path.join(test_normal_path,filename),0))\nfor filename in os.listdir(test_pneumonia_path):\n    test_data.append((os.path.join(test_pneumonia_path,filename),1))    \n    \n    \n    \n    \ntest_df = pd.DataFrame(test_data, columns = ['img_path','label'], index = None)\n# this test_df must contain the img_path and label column in order to run the function    ","db62668b":"\nplot(dense_history)","affa64e8":"densenet_model = keras.models.load_model('.\/densenet169.h5')","a9d9421f":"testing(densenet_model, test_df)","baea0d40":"from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n\nbase = MobileNetV2(weights = 'imagenet', include_top = False, input_shape= (224, 224, 3))\ntf.keras.backend.clear_session()\n    \nfor layer in base.layers:\n    layer.trainable =  False\n\nmobilenet_model = Sequential()\nmobilenet_model.add(base)\nmobilenet_model.add(GlobalAveragePooling2D())\nmobilenet_model.add(BatchNormalization())\nmobilenet_model.add(Dense(256, activation='relu'))\nmobilenet_model.add(Dropout(0.5))\nmobilenet_model.add(BatchNormalization())\nmobilenet_model.add(Dense(128, activation='relu'))\nmobilenet_model.add(Dropout(0.5))\nmobilenet_model.add(Dense(1, activation='sigmoid'))\n\nmobilenet_model.summary()","bd52923a":"# defined optimizer\noptm = Adam(lr=0.0001)\nmobilenet_model.compile(loss='binary_crossentropy', optimizer=optm, \n                  metrics=['accuracy'])\n\n# defining callbacks \n\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau\nEarlyStopping = EarlyStopping(monitor='val_accuracy',\n                              min_delta=.001,\n                              patience=6,\n                              verbose=1,\n                              mode='auto',\n                              baseline=None,\n                              restore_best_weights=True)\n\nrlr = ReduceLROnPlateau( monitor=\"val_accuracy\",\n                            factor=0.01,\n                            patience=4,\n                            verbose=0,\n                            mode=\"max\",\n                            min_delta=0.01)\n\nmodel_save = ModelCheckpoint('.\/mobilenet.h5',\n                             save_best_only = True,\n                             save_weights_only = False,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\n\n\n### Training our model\nmobilenet_history = mobilenet_model.fit(train_generator,\n                              steps_per_epoch = nb_train_samples \/\/ batch_size,\n                              epochs = 20,\n                              validation_data = test_generator,\n                           \n                              callbacks=[EarlyStopping, model_save,rlr])","5e8569ae":"plot(mobilenet_history)","994db8f7":"mobilenet_model = keras.models.load_model('.\/mobilenet.h5')","303401a6":"testing(mobilenet_model, test_df)","e47e2cd2":"from keras.layers.merge import concatenate\nfrom keras.layers import Input\nimport tensorflow as tf\n\ninput_shape = (224,224,3)\ninput_layer = Input(shape = (224, 224, 3))\n\n#first model\nbase_mobilenet = MobileNetV2(weights = 'imagenet', include_top = False, input_shape = input_shape)\nbase_densenet = DenseNet169(weights = 'imagenet', include_top = False, input_shape = input_shape)\n\nfor layer in base_mobilenet.layers:\n    layer.trainable =  False\nfor layer in base_densenet.layers:\n    layer.trainable = False\n    \nmodel_mobilenet = base_mobilenet(input_layer)\nmodel_mobilenet = GlobalAveragePooling2D()(model_mobilenet)\noutput_mobilenet = Flatten()(model_mobilenet)\n\nmodel_densenet = base_densenet(input_layer)\nmodel_densenet = GlobalAveragePooling2D()(model_densenet)\noutput_densenet = Flatten()(model_densenet)\n\nmerged = tf.keras.layers.Concatenate()([output_mobilenet, output_densenet]) \n\nx = BatchNormalization()(merged)\nx = Dense(256,activation = 'relu')(x)\nx = Dropout(0.5)(x)\nx = BatchNormalization()(x)\nx = Dense(128,activation = 'relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(1, activation = 'sigmoid')(x)\nstacked_model = tf.keras.models.Model(inputs = input_layer, outputs = x)\n\n\n\n\n","bbc0f4f3":"stacked_model.summary()","6c79287f":"# defined optimizer\noptm = Adam(lr=0.0001)\nstacked_model.compile(loss='binary_crossentropy', optimizer=optm, \n                  metrics=['accuracy'])\n\n# defining callbacks \n\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau\nEarlyStopping = EarlyStopping(monitor='val_accuracy',\n                              min_delta=.01,\n                              patience=6,\n                              verbose=1,\n                              mode='auto',\n                              baseline=None,\n                              restore_best_weights=True)\n\nrlr = ReduceLROnPlateau( monitor=\"val_accuracy\",\n                            factor=0.01,\n                            patience=6,\n                            verbose=0,\n                            mode=\"max\",\n                            min_delta=0.01)\n\nmodel_save = ModelCheckpoint('.\/stacked_model.h5',\n                             save_best_only = True,\n                             save_weights_only = False,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\n\n\n### Training our model\nstacked_history = stacked_model.fit(train_generator,\n                              steps_per_epoch = nb_train_samples \/\/ batch_size,\n                              epochs = 20,\n                              validation_data = test_generator,\n                           \n                              callbacks=[EarlyStopping, model_save,rlr])","5ef7847f":"stacked_model = keras.models.load_model('.\/stacked_model.h5')","63920c55":"testing(stacked_model,test_df)","cbd8da48":"#### Lets do some prediction on our validation data \n# for evaluation point of view i have created a dataframe of test directory \nvalidation_data = []\nvalidation_normal_path = validation_data_dir + '\/NORMAL'\nvalidation_pneumonia_path = validation_data_dir + '\/PNEUMONIA'\nfor filename in os.listdir(validation_normal_path):\n    validation_data.append((os.path.join(validation_normal_path,filename),0))\nfor filename in os.listdir(validation_pneumonia_path):\n    validation_data.append((os.path.join(validation_pneumonia_path,filename),1))    ","b091366b":"validation_df = pd.DataFrame(validation_data, columns = ['img_path','label'], index = None)\nvalidation_df = validation_df.sample(frac=1).reset_index(drop=True)\n","636423df":"validation_df.head()","60c134a5":"testing(stacked_model, validation_df)","c195817a":"testing(mobilenet_model, validation_df)","d7c1b70b":"testing(densenet_model, validation_df)","b22a581a":"def predict_image(validation_df, model):\n    plt.figure(figsize=(6,6))\n    for index , data in validation_df[:10].iterrows():\n        img_name = data['img_path']\n        label = data['label']\n    \n        label_predicted = np.where((predict(img_name , model)[0][0])>0.5,'pneumonia','normal')\n        plt.imshow(load_img(img_name, target_size = (120,120)))\n        if label == 1:\n            plt.xlabel(f\"True:Pneumonia, Predicted:{label_predicted}\", fontsize = 15)\n        if label == 0:\n            plt.xlabel(f\"True:Normal, Predicted:{label_predicted}\", fontsize = 15)\n            \n        plt.tight_layout()\n        plt.show()\n    ","35751784":"predict_image(validation_df, stacked_model)","d3c19bf7":"### Defining some function for plotting and Testing","05130f66":"## Stacked Model (MobilenetV2, Densenet169)","d28ac919":"#### STEP-2 (creating the path )","c0a1f543":"#### Some image processing can help us to understand the xray \n\nfor image processing we create a function and put in lambda layer in our model , \n\nfor Xray-classification i have found out the CLAHE and image normalization helps up to get better result","a9690e35":"#### Testing all models on validation data","303ebbdb":"#### i will be using pretrained mobilenet, densenet169 and stacked model of (mobilenet and densenet169)","f8f51d34":"#### STEP-3( Creating the generator for fitting to the model)\nwe need generator because training big amount of images can take us to memory insufficient error\n\nhere generator will do all our image processing task for training ","32756e98":"#### About Dataset\n* The dataset consists of training data, validation data, and testing data.\n* The training data consists of 5,216 chest x-ray images with 3,875 images shown to have pneumonia and 1,341 images shown to be normal.\n* The validation data is relatively small with only 16 images with 8 cases of pneumonia and 8 normal cases.\n* The testing data consists of 624 images split between 390 pneumonia cases and 234 normal cases.\n\n\n#### What is Pneumonia?\n<img src = 'https:\/\/i.ibb.co\/tqCHdDV\/pneumonia.png'>\n* Pneumonia is an infection in one or both lungs. Bacteria, viruses, and fungi cause it. The infection causes inflammation in the air sacs in your lungs, which are called alveoli. The alveoli fill with fluid or pus, making it difficult to breathe.\n\n","496591cb":"#### defining a function for plotting history object","cf956f09":"#### here we will classify pneumonia vs normal looking xray using CNN and pretrained model \n<img src = 'https:\/\/i.ibb.co\/Sw52m0T\/model.png'>\n\n","58b97041":"#### Testing on our DATA","8647def9":"### Lets test our validation _df ","5cd67e6c":"#### STEP-1 (importing libraries)","22140d1d":"##### The function we have created for testing takes a dataframe ","78f3b5b9":"#### Before Further do i wanna share some result of my reasearch on this project to save your time and efforts\n<img src = 'https:\/\/i.ibb.co\/c2NtHN6\/evaluation-1.png'  width = 800 height = 1700>\n<img src = 'https:\/\/i.ibb.co\/6w2d343\/evaluation2.png' width = 800 height = 1700>\nthis result will help us to choose models and building stacked model ","fdd9e60c":"##### here we can draw some batch to see how our image looks like after data augmentation\nits a good practice to see our data after augumentation ","d9c7d08e":"#### Takeaway:\n* as we can see that our stacked model has the lowest loss in 20 epochs and highest validation accuracy \n* further for model improvement we can apply preprocessing (CLAHE and normalization) for better model\n* we can stack more model and can try to improve our model","61a52230":"### STEP-4 (Defining the model) \n\n#### Here we are going to use Pretrained models for better accuracy since our Custom CNN didn't give good results","2386efcc":"## MobilenetV2","b943a2c3":"#### 1- DenseNet169 ","2bafa9f8":"#### **if you liked my notebook give a upvote and help me to get my first ever bronze \ud83d\ude4f**\nfeel free to put up questions in comment box \n* follow me on youtube for tutorial videos @https:\/\/www.youtube.com\/c\/AbhishekJaiswal24","d74548b7":"#### **as we can see that our stacked model classified all 16 chestx-ray correctly**","6c2ad403":"### After looking these result lets build our own model for greater accuracy","19a31b47":"#### for testing purpose we created a function\n","211c4bb1":"as we can see that the maximum val_accuracy is 94% and loss is .18 the minimum loss \n* we can further stack more model and can try to improve val_accuracy and val_loss"}}