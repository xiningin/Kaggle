{"cell_type":{"301f7d92":"code","82121617":"code","5be3a621":"code","0fb3e75f":"code","b8cf478b":"code","f0743d9a":"code","e5a3688d":"code","e31a036e":"code","5a0f8ad8":"code","a9eb82d5":"code","7b10982a":"code","193219fb":"code","d8d4df24":"code","8cf358f2":"code","df8d4f8b":"code","4541ac12":"markdown","8cf67183":"markdown","2d285ecc":"markdown","2ca7905c":"markdown","7beef7e0":"markdown","3d268632":"markdown","5d698526":"markdown","35044d59":"markdown","b4c07c00":"markdown","d9fc1f9a":"markdown","38b454c2":"markdown","c99517c3":"markdown","8b53dcde":"markdown","9d58c2cf":"markdown","b1ef5446":"markdown"},"source":{"301f7d92":"# Import numpy and pandas\nimport numpy as np \nimport pandas as pd\n\n# We'll use this later for splitting our data up into training and validation sets\nfrom sklearn.model_selection import train_test_split\n\n# Import matplotlib and sns \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n# Get everything we need from Keras\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, Dropout\nfrom keras.models import Model\nfrom keras.initializers import glorot_uniform\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nimport keras.backend as K\nK.set_image_data_format('channels_last')","82121617":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","5be3a621":"train.head(5)","0fb3e75f":"# Get number of training examples\nprint('Number of training examples: ' + str(train.shape[0]))\n\n# Plot the number of examples per class in our training set\nsns.countplot(train['label'])","b8cf478b":"# Get a list of 25 random examples\nexample_ids = np.random.randint(28000, size = 25)\n\n# Set up your figure\ncnt = 1\nfig = plt.figure()\ntitle = fig.suptitle('MNIST Handwritten Digit Examples', fontsize = 20)\ntitle.set_position([.5, .92])\nfig.set_figheight(12)\nfig.set_figwidth(10)\nfor id in example_ids:\n    # Get the data associated with each example\n    example_data = train.iloc[[id]]\n    \n    # Get the label associated with each example\n    example_truth = example_data['label'].unique()[0]\n    \n    # Drop the label so we are only left with the image data\n    example_data = example_data.drop(['label'], axis = 1)\n    \n    # Convert the data to a numpy array so that it's compatible with imshow\n    example_data = np.array(example_data)\n    \n    # Reshape the example to a 28 x 28 array\n    example_data = np.reshape(example_data, [28, 28])\n    \n    # Plot that array in a subplot\n    plt.subplot(5, 5, cnt)\n    plt.title('Label = ' + str(np.array(example_truth)))\n    plt.axis('off')\n    plt.imshow(example_data)\n    cnt += 1","f0743d9a":"def digit_conv_net(input_shape, num_classes):\n    \n    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n    X_input = Input(input_shape)\n\n    # Zero-Padding: pads the border of X_input with zeroes\n    X = ZeroPadding2D((2, 2))(X_input)\n\n    # CONV -> BN -> RELU Block applied to X\n    X = Conv2D(32, (5, 5), strides = (1, 1), name = 'conv0', padding = 'same', kernel_initializer = glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n    X = Activation('relu')(X)\n    \n    # CONV -> BN -> RELU Block applied to X\n    X = Conv2D(32, (5, 5), strides = (1, 1), name = 'conv1', padding = 'same', kernel_initializer = glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn1')(X)\n    X = Activation('relu')(X)\n\n    # MAXPOOL\n    X = MaxPooling2D(pool_size = (2, 2), name = 'max_pool0')(X)\n    \n    # Add dropout to regularize\n    X = Dropout(0.25)(X)\n    \n    # CONV -> BN -> RELU Block applied to X\n    X = Conv2D(64, (5, 5), strides = (1, 1), name = 'conv2', padding = 'same', kernel_initializer = glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n    X = Activation('relu')(X)\n    \n    # CONV -> BN -> RELU Block applied to X\n    X = Conv2D(64, (5, 5), strides = (1, 1), name = 'conv3', padding = 'same', kernel_initializer = glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn3')(X)\n    X = Activation('relu')(X)\n\n    # MAXPOOL\n    X = MaxPooling2D(pool_size = (2, 2), name = 'max_pool1')(X)\n    \n    # Add dropout to regularize\n    X = Dropout(0.25)(X)\n    \n    # FLATTEN X -> FULLY CONNECTED\n    X = Flatten()(X)\n    X = Dense(128, activation = 'relu', name = 'fc0')(X)\n    X = Dropout(0.25)(X)\n    X = Dense(128, activation = 'relu', name = 'fc1')(X)\n    X = Dropout(0.25)(X)\n    X = Dense(num_classes, activation = 'softmax', name = 'fc2')(X)\n\n    # Create model. This creates your Keras model instance, you'll use this instance to train\/test the model.\n    model = Model(inputs = X_input, outputs = X, name = 'LeNet5')\n\n    return model","e5a3688d":"# Initialize model with input size and number of classes\nDigitModel = digit_conv_net([28, 28, 1], 10)\n\n# Complie the model. Use Adam optimizer.\nDigitModel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","e31a036e":"DigitModel.summary()","5a0f8ad8":"train_labels = train['label']\ntrain_labels = pd.get_dummies(train_labels)\ntrain_features = train.drop(['label'], axis = 1)\nX_train, X_val, y_train, y_val = train_test_split(train_features,\n                                                   train_labels,\n                                                   train_size = 0.98,\n                                                   test_size = 0.02,\n                                                   random_state = 0)\nX_train = np.array(X_train)\nX_train = np.reshape(X_train, [X_train.shape[0], 28, 28, 1]) \/ 255.\n\nX_val = np.array(X_val)\nX_val = np.reshape(X_val, [X_val.shape[0], 28, 28, 1]) \/ 255.\n\ntest = np.array(test)\ntest = np.reshape(test, [test.shape[0], 28, 28, 1]) \/ 255.","a9eb82d5":"ReduceLearningRate = ReduceLROnPlateau(monitor = 'val_acc', \n                                       factor = 0.5, \n                                       patience = 3, \n                                       min_lr = 0.00001)","7b10982a":"DataGenerator = ImageDataGenerator(rotation_range = 10,\n                                   zoom_range = 0.1,\n                                   width_shift_range = 0.1,\n                                   height_shift_range = 0.1)\n\n# Fits the model on batches with real-time data augmentation\nDataGenerator.fit(X_train)","193219fb":"# Store this in a variable called mdl which we will use later to visualize the model performance\nmdl = DigitModel.fit_generator(DataGenerator.flow(X_train, y_train, batch_size = 32), \n                               epochs = 15,\n                               validation_data = (X_val, y_val),\n                               callbacks = [ReduceLearningRate])","d8d4df24":"fig = plt.figure()\ntitle = fig.suptitle('Model Accuracy\/Loss Summary', fontsize = 16)\ntitle.set_position([.5, 1.0])\nfig.set_figheight(5)\nfig.set_figwidth(10)\n\n# Summarize history for accuracy\nplt.subplot(1, 2, 1)\nplt.plot(mdl.history['acc'])\nplt.plot(mdl.history['val_acc'])\nplt.title('Model Accuracy', fontsize = 10)\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='lower right')\n\n# Summarize history for loss\nplt.subplot(1, 2, 2)\nplt.plot(mdl.history['loss'])\nplt.plot(mdl.history['val_loss'])\nplt.title('Model Loss', fontsize = 10)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper right')","8cf358f2":"# predict results\nresults = DigitModel.predict(test)\n\n# select the index with the maximum probability\nresults = np.argmax(results, axis = 1)\nresults = pd.Series(results, name = \"Label\")","df8d4f8b":"my_submission = pd.concat([pd.Series(range(1,28001), name = \"ImageId\"), results], axis = 1)\nmy_submission.to_csv(\"my_submission.csv\", index = False)","4541ac12":"## 3. Setting up our CNN\nNow for the fun part! Let's go ahead and set up the CNN that we will be using to perform image classification. Our CNN will have the following structure:\n\nINPUT - > CONV -> BN -> RELU -> CONV -> BN -> RELU -> MAXPOOL ->  DROPOUT -> CONV -> BN -> RELU -> CONV -> BN -> RELU -> MAXPOOL -> DROPOUT -> FULLY CONNECTED -> DROPOUT -> FULLY CONNECTED -> DROPOUT -> SOFTMAX\n\nIf you are unfamiliar with concepts such as convolutional layers, batch normalization, relu, and pooling, I would recommend taking the following course on CNNs.\n\n* References:\n    * Convolutional Neural Networks: https:\/\/www.coursera.org\/learn\/convolutional-neural-networks","8cf67183":"### 3.1. Preprocessing our data\n\nOur model has now been initialized and compiled. Now we need to set up our data so that we can feed it into the model. Do do this we separate our labels from our pixel intensity values. Our labels will become our target (stored as y) and our intensity values will be reshaped into 28 x 28 images. Before that happens, however, we will use the 'train_test_split' function to break our data into a training set and a validation set. Finally, we divide our pixel intensities by 255 to normalize them. This last step scales the data so that every pixel value is between 0 and 1. This speeds up optimization.\n\n* References:\n    * train_test_split: http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html","2d285ecc":"## 5. Checking our work\n\nOur model is fully trained and we are ready to run our test data through it. However, before we do that, we can use the block of code below to check for any underfitting or overfitting. Earlier we split the data up into a training and validation sets. Below you have two plots. One shows training and validation accuracy vs epochs, and the other shows training and validation loss vs epochs. Ideally you want to see your training and validation accuracy go up AND remain close to each other. Similarly, you want to see your training and validation loss go down AND remain close to each other. This lets you know that your model is generalizing well to data that it's never seen before.\n","2ca7905c":"## 1. Setting up our environment\n\nLet's get started by setting up our environment. We will be using the Keras environment to set up our convolutional neural network (CNN). In addition to Keras we will be using numpy and pandas to help us manipulate and set up our data for our model. Finally, we will be using matplotlib and seaborn for plotting and visualization If you are unfamiliar with any of these, please take advantage of the links below.\n\n* References:\n    * Keras: https:\/\/keras.io\/\n    * Numpy: https:\/\/docs.scipy.org\/doc\/\n    * Pandas: http:\/\/pandas.pydata.org\/pandas-docs\/stable\/\n    * Matplotlib: https:\/\/matplotlib.org\/index.html\n    * Seaborn: https:\/\/seaborn.pydata.org\/","7beef7e0":"Next on the adgenda is to see how many examples of each class we have. For this we use the 'countplot' function available through Seaborn. Go ahead and run the code below. We can see that we have roughly the same amount of training examples for each class. This is good! When training a model you want to have a uniform amount of examples from each class. If this is not the case, then you have a class imbalance problem. There are several methods available for fixing that issue. See the link below for more on that.\n\n* References:\n    * Countplot: https:\/\/seaborn.pydata.org\/generated\/seaborn.countplot.html?highlight=countplot#seaborn.countplot\n    * Class imbalance problem: https:\/\/towardsdatascience.com\/dealing-with-imbalanced-classes-in-machine-learning-d43d6fa19d2\n\n","3d268632":"We have our data loaded and we know that it is evenly distributed among our different classes, but what does each example actually look like? Let's find out! The code below generates a set of 25 random examples, reshapes those examples from a 1 x 748 array to a 28 x 28 array, and then displays that array using matplotlib's 'imshow' function. \n\n* References:\n    * np.reshape: https:\/\/docs.scipy.org\/doc\/numpy\/reference\/generated\/numpy.reshape.html\n    * imshow: https:\/\/matplotlib.org\/api\/_as_gen\/matplotlib.pyplot.imshow.html","5d698526":"## 6. Submit your work!\n\nYou can see above that our model is doing very well! Both the loss and and accuracy for our training and validation sets are similar. Feel free to use this code or play around with it even more. Hope this helps, and please feel free to leave any questions in the comments section.","35044d59":"Our data is now stored as a pandas 'DataFrame'. We can take advantage of the 'head' attribute to get a glimpse at what our raw data looks like.","b4c07c00":"Data augmentation is the process of applying small changes to our existing data set to generate more data. Take the kitten example below. From the original image, we can change the height and width, rotate, crop, and flip it to generate more training examples. Keras has a function called 'ImageDataGenerator' that applies these transformations for us in real time. These new examples are fed into our model during training. I would highly recommend going to the link below to see what options are available on Keras.\n\n* References:\n    * ImageDataGenerator: https:\/\/keras.io\/preprocessing\/image\/\n\n![](https:\/\/cdn-images-1.medium.com\/max\/1600\/1*C8hNiOqur4OJyEZmC7OnzQ.png)\n\nImage source: https:\/\/medium.com\/nanonets\/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced","d9fc1f9a":"We've defined the basic structure of our CNN. Now let's initilize it with the input size and number of classes. Once that is done, we complie the model.\n\n* References\n    * Compile: https:\/\/keras.io\/models\/model\/","38b454c2":"You can use the 'summary' attribute to see the structure of your model and get the number of parameters you will be training.\n\n* References:\n    * Summary: https:\/\/keras.io\/models\/about-keras-models\/#about-keras-models","c99517c3":"# Welcome!\nIn this kernel I will walk you through some basic exploratory data analysis (EDA) and how to set up a simple convolutional neural network to perform image classification. Hope you find this helpful. Please feel free to comment below if you have any questions.","8b53dcde":"## 4. Fire it all up!\n\nNow we are ready to go. We've defined our model, precprocessed our data, defined a callback to monitor the progress of our model, and we've set our model up with data augmentation. Run the block of code below and enjoy the show. For better performance, increase the number of epochs (25-30 epochs should do the trick).","9d58c2cf":"## 2. Loading our data and exploring it\nSo now that we have our environment set up, let's load our data and start exploring it. First we use pandas to read in the data. The data provided here is stored in the form of a CSV file. Each row consists of a label (0, 1, 2, 3, 5, ..., 9) and 748 pixel intensity values. Run the code in the cell below this to load the data.","b1ef5446":"### 3.2. Some finishing touches...callbacks and data augmentation\n\nAt this point, our data and our model are ready to go. However, before we go any further, I'd like to showcase two particularly nice features in Keras: Callbacks and real-time data augmentation. A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training. Here we use the 'ReduceLROnPlateau callback. In a nutshell, this monitors a parameter of our choice (i.e. the validation accuracy) and reduces the learning rate for our optimizer if our parameter starts to plateau. In this instance, the following inputs are given:\n\n* monitor - What parameter our model will monitor\n* factor - What we multiply the learning rate by in the event of a plateau\n* patience - How many epochs we are willing to wait before we reduce the learning rate\n* min_lr - How low we are willing to let the learning rate go. Do not set this too low. It will slow down your optimizer.\n\n* Refernces:\n    * Callbacks: https:\/\/keras.io\/callbacks\/"}}