{"cell_type":{"84e29468":"code","354939bb":"code","86a852b2":"code","7b24dc06":"code","2e660fd3":"code","5024b09f":"code","eabddf03":"code","170972ad":"code","1dbdb333":"code","7f87a691":"code","3ac4d573":"code","f0079925":"code","fc5b990f":"code","a742b5bd":"code","540e95ff":"code","0708f132":"code","f14f21ed":"code","a8817baa":"code","6f8d1f96":"code","f4a05b8b":"code","0fb2cb02":"code","999d0c11":"markdown","6a89c45a":"markdown","e7d2cb94":"markdown","f99e06a6":"markdown","d5dab90f":"markdown","e6900313":"markdown","afe9610a":"markdown","199ddd5f":"markdown","3bf6c324":"markdown","4d69aaa2":"markdown","6e40eac1":"markdown","7c293284":"markdown"},"source":{"84e29468":"!pip install -q nnAudio\n!pip install -q ttach","354939bb":"!curl https:\/\/raw.githubusercontent.com\/pytorch\/xla\/master\/contrib\/scripts\/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --version 1.8\n#!curl https:\/\/raw.githubusercontent.com\/pytorch\/xla\/master\/contrib\/scripts\/env-setup.py -o pytorch-xla-env-setup.py\n#!python pytorch-xla-env-setup.py --version \"nightly\"","86a852b2":"import os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","7b24dc06":"train = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/training_labels.csv')\ntest = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/sample_submission.csv')\n\ndef get_train_file_path(image_id):\n    return \"..\/input\/g2net-gravitational-wave-detection\/train\/{}\/{}\/{}\/{}.npy\".format(\n        image_id[0], image_id[1], image_id[2], image_id)\n\ndef get_test_file_path(image_id):\n    return \"..\/input\/g2net-gravitational-wave-detection\/test\/{}\/{}\/{}\/{}.npy\".format(\n        image_id[0], image_id[1], image_id[2], image_id)\n\ntrain['file_path'] = train['id'].apply(get_train_file_path)\ntest['file_path'] = test['id'].apply(get_test_file_path)\n\ndisplay(train.head())\ndisplay(test.head())","2e660fd3":"import torch\nfrom nnAudio.Spectrogram import CQT1992v2\n\ndef apply_qtransform(waves, transform=CQT1992v2(sr=2048, fmin=20, fmax=1024, hop_length=64)):\n    waves = np.hstack(waves)\n    waves = waves \/ np.max(waves)\n    waves = torch.from_numpy(waves).float()\n    image = transform(waves)\n    return image\n\nfor i in range(5):\n    waves = np.load(train.loc[i, 'file_path'])\n    image = apply_qtransform(waves)\n    target = train.loc[i, 'target']\n    plt.imshow(image[0])\n    plt.title(f\"target: {target}\")\n    plt.show()","5024b09f":"train['target'].hist()","eabddf03":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = '.\/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","170972ad":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    apex=True\n    debug=True\n    num_workers=4\n    model_name='tf_efficientnet_b4_ns'\n    scheduler='CosineAnnealingLR' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n    epochs=8\n    #factor=0.2 # ReduceLROnPlateau\n    #patience=4 # ReduceLROnPlateau\n    #eps=1e-6 # ReduceLROnPlateau\n    T_max=3 # CosineAnnealingLR\n    #T_0=3 # CosineAnnealingWarmRestarts\n    lr=1e-4\n    min_lr=1e-6\n    batch_size=48\n    weight_decay=1e-6\n    gradient_accumulation_steps=1\n    max_grad_norm=1000\n    qtransform_params={\"sr\": 2048, \"fmin\": 20, \"fmax\": 1024, \"hop_length\": 32, \"bins_per_octave\": 8, \"verbose\": False}\n    seed=2021\n    target_size=1\n    target_col='target'\n    n_fold=5\n    trn_fold=[0] # [0, 1, 2, 3, 4]\n    train=True\n    \nif CFG.debug:\n    CFG.epochs = 3\n    train = train.sample(n=10000, random_state=CFG.seed).reset_index(drop=True)","1dbdb333":"# ====================================================\n# Library\n# ====================================================\nimport sys\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nimport torch_xla\nimport torch_xla.debug.metrics as met\nimport torch_xla.distributed.data_parallel as dp\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.utils.utils as xu\nimport torch_xla.core.xla_model as xm\nimport torch_xla.utils.serialization as xser\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.test.test_utils as test_utils\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nimport timm\n\nfrom torch.cuda.amp import autocast, GradScaler\n\nimport warnings\nwarnings.filterwarnings('ignore')","7f87a691":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    score = roc_auc_score(y_true, y_pred)\n    return score\n\n\ndef init_logger(log_file=OUTPUT_DIR+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()\n\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","3ac4d573":"Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\nfor n, (train_index, val_index) in enumerate(Fold.split(train, train[CFG.target_col])):\n    train.loc[val_index, 'fold'] = int(n)\ntrain['fold'] = train['fold'].astype(int)\ndisplay(train.groupby(['fold', 'target']).size())","f0079925":"# ====================================================\n# Dataset\n# ====================================================\nclass TrainDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.labels = df[CFG.target_col].values\n        self.wave_transform = CQT1992v2(**CFG.qtransform_params)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def apply_qtransform(self, waves, transform):\n        waves = np.hstack(waves)\n        waves = waves \/ np.max(waves)\n        waves = torch.from_numpy(waves).float()\n        image = transform(waves)\n        return image\n\n    def __getitem__(self, idx):\n        file_path = self.file_names[idx]\n        waves = np.load(file_path)\n        image = self.apply_qtransform(waves, self.wave_transform)\n        image = image.squeeze().numpy()\n        if self.transform:\n            image = self.transform(image=image)['image']\n        label = torch.tensor(self.labels[idx]).float()\n        return image, label","fc5b990f":"# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    \n    if data == 'train':\n        return A.Compose([\n            ToTensorV2(),\n        ])\n\n    elif data == 'valid':\n        return A.Compose([\n            ToTensorV2(),\n        ])","a742b5bd":"train_dataset = TrainDataset(train, transform=get_transforms(data='train'))\n\nfor i in range(5):\n    plt.figure(figsize=(16,12))\n    image, label = train_dataset[i]\n    plt.imshow(image[0])\n    plt.title(f'label: {label}')\n    plt.show() ","540e95ff":"# ====================================================\n# MODEL\n# ====================================================\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        self.model = timm.create_model(self.cfg.model_name, pretrained=pretrained, in_chans=1)\n        self.n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(self.n_features, self.cfg.target_size)\n\n    def forward(self, x):\n        output = self.model(x)\n        return output\n\nMX = xmp.MpModelWrapper(CustomModel(CFG, pretrained=True))\n","0708f132":"# ====================================================\n# Helper functions\n# ====================================================\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s \/ 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s \/ (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\ndef loss_fn(outputs, targets):\n        return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n\ndef train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    if CFG.apex:\n        scaler = GradScaler()\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to train mode\n    model.train()\n    start = end = time.time()\n    global_step = 0\n    for step, (images, labels) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        if CFG.apex:\n            with autocast():\n                y_preds = model(images)\n                loss = loss_fn(y_preds, labels)\n        else:\n            y_preds = model(images)\n            loss = criterion(y_preds.view(-1), labels)\n        # record loss\n        losses.update(loss.item(), batch_size)\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss \/ CFG.gradient_accumulation_steps\n        #if CFG.apex:\n        #    scaler.scale(loss).backward()\n        #else:\n        #    loss.backward()\n        loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n            if CFG.apex:\n                # scaler.step(optimizer)\n                xm.optimizer_step(optimizer)\n                scaler.update()\n            else:\n                optimizer.step()\n            optimizer.zero_grad()\n            global_step += 1\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n    return losses.avg\n\n\ndef valid_fn(valid_loader, model, criterion, device):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to evaluation mode\n    model.eval()\n    preds = []\n    start = end = time.time()\n    valid_labels = []\n    for step, (images, labels) in enumerate(valid_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        # compute loss\n        with torch.no_grad():\n            y_preds = model(images)\n        xm.mark_step()\n        loss = loss_fn(y_preds, labels)\n        losses.update(loss.item(), batch_size)\n        # record accuracy\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n        valid_labels.append(labels.to('cpu').numpy())\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss \/ CFG.gradient_accumulation_steps\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n    preds = np.concatenate(preds)\n    valid_labels = np.concatenate(valid_labels)\n    score = get_score(valid_labels, preds)\n    return losses.avg, preds, score","f14f21ed":"MX = xmp.MpModelWrapper(CustomModel(CFG, pretrained=True))","a8817baa":"def epoch_update_gamma(y_true,y_pred, epoch=-1,delta=1):\n        \"\"\"\n        Calculate gamma from last epoch's targets and predictions.\n        Gamma is updated at the end of each epoch.\n        y_true: `Tensor`. Targets (labels).  Float either 0.0 or 1.0 .\n        y_pred: `Tensor` . Predictions.\n        \"\"\"\n        DELTA = delta+1\n        SUB_SAMPLE_SIZE = 2000.0\n        pos = y_pred[y_true==1]\n        neg = y_pred[y_true==0] # yo pytorch, no boolean tensors or operators?  Wassap?\n        # subsample the training set for performance\n        cap_pos = pos.shape[0]\n        cap_neg = neg.shape[0]\n        pos = pos[torch.rand_like(pos) < SUB_SAMPLE_SIZE\/cap_pos]\n        neg = neg[torch.rand_like(neg) < SUB_SAMPLE_SIZE\/cap_neg]\n        ln_pos = pos.shape[0]\n        ln_neg = neg.shape[0]\n        pos_expand = pos.view(-1,1).expand(-1,ln_neg).reshape(-1)\n        neg_expand = neg.repeat(ln_pos)\n        diff = neg_expand - pos_expand\n        ln_All = diff.shape[0]\n        Lp = diff[diff>0] # because we're taking positive diffs, we got pos and neg flipped.\n        ln_Lp = Lp.shape[0]-1\n        diff_neg = -1.0 * diff[diff<0]\n        diff_neg = diff_neg.sort()[0]\n        ln_neg = diff_neg.shape[0]-1\n        ln_neg = max([ln_neg, 0])\n        left_wing = int(ln_Lp*DELTA)\n        left_wing = max([0,left_wing])\n        left_wing = min([ln_neg,left_wing])\n        default_gamma=torch.tensor(0.2, dtype=torch.float).cuda()\n        if diff_neg.shape[0] > 0 :\n           gamma = diff_neg[left_wing]\n        else:\n           gamma = default_gamma # default=torch.tensor(0.2, dtype=torch.float).cuda() #zoink\n        L1 = diff[diff>-1.0*gamma]\n        ln_L1 = L1.shape[0]\n        if epoch > -1 :\n            return gamma\n        else :\n            return default_gamma\n\n\n\ndef roc_star_loss( _y_true, y_pred, gamma, _epoch_true, epoch_pred):\n        \"\"\"\n        Nearly direct loss function for AUC.\n        See article,\n        C. Reiss, \"Roc-star : An objective function for ROC-AUC that actually works.\"\n        https:\/\/github.com\/iridiumblue\/articles\/blob\/master\/roc_star.md\n            _y_true: `Tensor`. Targets (labels).  Float either 0.0 or 1.0 .\n            y_pred: `Tensor` . Predictions.\n            gamma  : `Float` Gamma, as derived from last epoch.\n            _epoch_true: `Tensor`.  Targets (labels) from last epoch.\n            epoch_pred : `Tensor`.  Predicions from last epoch.\n        \"\"\"\n        #convert labels to boolean\n        y_true = (_y_true>=0.50)\n        epoch_true = (_epoch_true>=0.50)\n\n        # if batch is either all true or false return small random stub value.\n        if torch.sum(y_true)==0 or torch.sum(y_true) == y_true.shape[0]: return torch.sum(y_pred)*1e-8\n\n        pos = y_pred[y_true]\n        neg = y_pred[~y_true]\n\n        epoch_pos = epoch_pred[epoch_true]\n        epoch_neg = epoch_pred[~epoch_true]\n\n        # Take random subsamples of the training set, both positive and negative.\n        max_pos = 1000 # Max number of positive training samples\n        max_neg = 1000 # Max number of positive training samples\n        cap_pos = epoch_pos.shape[0]\n        cap_neg = epoch_neg.shape[0]\n        epoch_pos = epoch_pos[torch.rand_like(epoch_pos) < max_pos\/cap_pos]\n        epoch_neg = epoch_neg[torch.rand_like(epoch_neg) < max_neg\/cap_pos]\n\n        ln_pos = pos.shape[0]\n        ln_neg = neg.shape[0]\n\n        # sum positive batch elements agaionst (subsampled) negative elements\n        if ln_pos>0 :\n            pos_expand = pos.view(-1,1).expand(-1,epoch_neg.shape[0]).reshape(-1)\n            neg_expand = epoch_neg.repeat(ln_pos)\n\n            diff2 = neg_expand - pos_expand + gamma\n            l2 = diff2[diff2>0]\n            m2 = l2 * l2\n            len2 = l2.shape[0]\n        else:\n            m2 = torch.tensor([0], dtype=torch.float).cuda()\n            len2 = 0\n\n        # Similarly, compare negative batch elements against (subsampled) positive elements\n        if ln_neg>0 :\n            pos_expand = epoch_pos.view(-1,1).expand(-1, ln_neg).reshape(-1)\n            neg_expand = neg.repeat(epoch_pos.shape[0])\n\n            diff3 = neg_expand - pos_expand + gamma\n            l3 = diff3[diff3>0]\n            m3 = l3*l3\n            len3 = l3.shape[0]\n        else:\n            m3 = torch.tensor([0], dtype=torch.float).cuda()\n            len3=0\n\n        if (torch.sum(m2)+torch.sum(m3))!=0 :\n           res2 = torch.sum(m2)\/max_pos+torch.sum(m3)\/max_neg\n           #code.interact(local=dict(globals(), **locals()))\n        else:\n           res2 = torch.sum(m2)+torch.sum(m3)\n\n        res2 = torch.where(torch.isnan(res2), torch.zeros_like(res2), res2)\n\n        return res2\n    \nclass ROC_Star(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n    def forward(self, y_pred,_y_true,i):    #_epoch_true, epoch_pred):\n        return roc_star_loss( _y_true, y_pred, CFG.gamma, torch.from_numpy(CFG.last_epoch_true[i]).cuda(), torch.from_numpy(CFG.last_epoch_pred[i]).cuda())","6f8d1f96":"# ====================================================\n# Train loop\n# ====================================================\ndef train_loop():\n    # ====================================================\n    # loader\n    # ====================================================\n    global FLAGS\n    fold, folds = FLAGS[\"fold\"], FLAGS[\"train\"]\n    device = xm.xla_device()\n\n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n\n    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n    valid_labels = valid_folds[CFG.target_col].values\n\n    train_dataset = TrainDataset(train_folds, transform=get_transforms(data='train'))\n    valid_dataset = TrainDataset(valid_folds, transform=get_transforms(data='train'))\n\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n        train_dataset,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=True)\n\n\n    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n        valid_dataset,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=False,\n        )\n\n    train_loader = DataLoader(train_dataset,\n                              batch_size=CFG.batch_size,\n                              sampler=train_sampler,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, \n                              batch_size=CFG.batch_size,\n                              sampler=valid_sampler,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    \n    # ====================================================\n    # scheduler \n    # ====================================================\n    def get_scheduler(optimizer):\n        if CFG.scheduler=='ReduceLROnPlateau':\n            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n        elif CFG.scheduler=='CosineAnnealingLR':\n            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n        return scheduler\n\n    # ====================================================\n    # model & optimizer\n    # ====================================================\n    model = MX.to(device)\n\n    optimizer = Adam(model.parameters(), lr=CFG.lr*xm.xrt_world_size(), weight_decay=CFG.weight_decay, amsgrad=False)\n    scheduler = get_scheduler(optimizer)\n\n    \n    # ====================================================\n    # loop\n    # ====================================================\n    criterion = ROC_Star()\n    best_score = 0.\n    best_loss = np.inf\n    \n    for epoch in range(CFG.epochs):\n        xm.master_print(f\"Epoch :{epoch}\")\n        start_time = time.time()\n        \n        # train\n        para_loader = pl.ParallelLoader(train_loader, [device])\n        avg_loss = train_fn(fold, para_loader.per_device_loader(device), model, criterion, optimizer, epoch, scheduler, device)\n        xm.master_print(f\"Train Loss:{avg_loss:.4f}\")\n        # eval\n        para_loader = pl.ParallelLoader(valid_loader, [device])\n        avg_val_loss, preds, score = valid_fn(para_loader.per_device_loader(device), model, criterion, device)        \n        xm.master_print(f\"Val Loss:{avg_val_loss:.4f} Val Score:{score:.4f}\")\n        \n        if isinstance(scheduler, ReduceLROnPlateau):\n            scheduler.step(avg_val_loss)\n        elif isinstance(scheduler, CosineAnnealingLR):\n            scheduler.step()\n        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n            scheduler.step()\n\n        elapsed = time.time() - start_time\n        \n        xm.master_print(elapsed)\n        xm.rendezvous(\"epoch complete\")\n        if score > best_score:\n            best_score = score\n            xm.save(model.state_dict(), OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth')\n        \n        if avg_val_loss < best_loss:\n            best_loss = avg_val_loss\n            xm.save(model.state_dict(), OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth')\n    \n    xm.master_print('='*20)\n    xm.master_print(f'best_loss: {best_loss:.4f}')\n    xm.master_print(f'Score: {best_score:.4f}')\n    xm.master_print('='*20)\n\n    return best_score, best_loss","f4a05b8b":"def _mp_fn(rank, flags):\n    torch.set_default_tensor_type('torch.FloatTensor')\n    a = train_loop()","0fb2cb02":"for fold in range(CFG.n_fold):\n    if fold in CFG.trn_fold:\n        FLAGS={\"fold\": fold, \"train\": train}\n        xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')","999d0c11":"# Utils","6a89c45a":"# Library","e7d2cb94":"# CFG","f99e06a6":"# Dataset","d5dab90f":"# MODEL","e6900313":"# Train loop","afe9610a":"# Transforms","199ddd5f":"# CV split","3bf6c324":"# Helper functions","4d69aaa2":"# Directory settings","6e40eac1":"# Data Loading","7c293284":"# Quick EDA"}}