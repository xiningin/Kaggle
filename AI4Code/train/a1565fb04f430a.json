{"cell_type":{"98fa966e":"code","2c509ba1":"code","fa2296a4":"code","d48461fa":"code","0fee42ea":"code","8838bbdf":"code","1df6aff4":"code","3fc4380d":"code","f6280af5":"code","c296f114":"code","171bb220":"code","31faf3ed":"markdown","83facf92":"markdown","78f409da":"markdown","2714045a":"markdown","404f0655":"markdown","8938c6b4":"markdown","5e956b93":"markdown","da28db76":"markdown","72f8c9e0":"markdown"},"source":{"98fa966e":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models","2c509ba1":"# Define a transform to normalize the data\ntransform = transforms.Compose([transforms.ToTensor(),\n                                transforms.Normalize((0.5,), (0.5,)),\n                              ])\n# Download and load the training and testing data\ntrainset = datasets.MNIST('~\/.pytorch\/MNIST_data\/', download=True, train=True, transform=transform)\ntestset = datasets.MNIST('~\/.pytorch\/MNIST_data\/', download=True, train=False, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=64)","fa2296a4":"len(trainset), len(testset) # validation if its loaded correctly","d48461fa":"# obtain one batch of training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\nimages = images.numpy()\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20\/2, idx+1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n    # print out the correct label for each image\n    # .item() gets the value contained in a Tensor\n    ax.set_title(str(labels[idx].item()))","0fee42ea":"#view image in more detail\nimg = np.squeeze(images[1])\n\nfig = plt.figure(figsize = (12,12)) \nax = fig.add_subplot(111)\nax.imshow(img, cmap='gray')\nwidth, height = img.shape\nthresh = img.max()\/2.5\nfor x in range(width):\n    for y in range(height):\n        val = round(img[x][y],2) if img[x][y] !=0 else 0\n        ax.annotate(str(val), xy=(y,x),\n                    horizontalalignment='center',\n                    verticalalignment='center',\n                    color='white' if img[x][y]<thresh else 'black')","8838bbdf":"# define where to run model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.cuda.is_available()","1df6aff4":"# define model\nclass Classifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(784, 256)\n        self.fc2 = nn.Linear(256, 256)\n        self.fc3 = nn.Linear(256, 64)\n        self.fc4 = nn.Linear(64, 10)\n\n        # Dropout module with 0.2 drop probability\n        self.dropout = nn.Dropout(p=0.2)\n\n    def forward(self, x):\n        # make sure input tensor is flattened\n        x = x.view(x.shape[0], -1)\n\n        # Now with dropout\n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.dropout(F.relu(self.fc2(x)))\n        x = self.dropout(F.relu(self.fc3(x)))\n\n        # output so no dropout here\n        x = F.log_softmax(self.fc4(x), dim=1)\n\n        return x","3fc4380d":"model = Classifier()\n\n#set loss and optimizer criterion\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n#put model on gpu\nmodel.to(device)","f6280af5":"# train model\n\n#choose epochs\nepochs = 10\nsteps = 0\nepoch = 0\n#print_every = 10\n#for plot\ntrain_losses, test_losses = [], []\n\n#train model\nfor e in range(epochs):\n    epoch +=1\n    #set running loss to 0\n    running_loss = 0\n    for images, labels in trainloader:\n        steps +=1\n\n        #move inputs to device\n        images, labels = images.to(device), labels.to(device)\n\n        #set trained weights to 0 for new batch\n        optimizer.zero_grad()\n\n        #training part incl. backpropagation\n        log_ps = model(images)\n        loss = criterion(log_ps, labels)\n        loss.backward()\n        optimizer.step()\n\n        #track the loss change\n        running_loss += loss.item()\n\n    else: #if steps % print_every == 0:\n\n        #set test loss and accuracy to 0 for current epoch\n        test_loss = 0\n        accuracy = 0 \n\n        with torch.no_grad():\n            #remove dropout for testing phase\n            model.eval()\n            for images, labels in testloader:\n\n                #move inputs to device\n                images, labels = images.to(device), labels.to(device)\n\n                #testing \n                log_ps = model(images)\n                loss = criterion(log_ps, labels)\n                test_loss += loss.item()\n\n                #see probabilities (-> LOGsoftmax used)\n                ps = torch.exp(log_ps)\n\n                #get the top probabilities against the classes (colums)\n                top_p, top_class = ps.topk(1, dim=1)\n\n                #check for fit and calculate accuracy\n                equals = top_class == labels.view(*top_class.shape)\n                accuracy += torch.mean(equals.type(torch.FloatTensor))\n        \n        #reset to training mode to add dropouts again\n        model.train()\n\n        #for plotting\n        train_losses.append(running_loss\/len(trainloader))\n        #for plotting\n        test_losses.append(test_loss\/len(testloader))\n\n        print(\"Epochs : {}, Steps: {}\".format(epoch, steps))\n        print('Accuracy: {:.3f}'.format(accuracy\/len(testloader)))\n        print('Train loss: {:.3f}'.format(running_loss\/len(trainloader)))\n        print('Test loss: {:.3f}'.format(test_loss\/len(testloader)))","c296f114":"plt.plot(train_losses, label=\"Train Loss\")\nplt.plot(test_losses, label=\"Test Loss\")\nplt.legend(frameon=False)","171bb220":"# obtain one batch of test images\ndataiter = iter(testloader)\nimages, labels = dataiter.next()\n\n# get sample outputs\noutput = model(images)\n# convert output probabilities to predicted class\n_, preds = torch.max(output, 1)\n# prep images for display\nimages = images.numpy()\n\n# plot the images in the batch, along with predicted and true labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20\/2, idx+1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n    ax.set_title(\"{} ({})\".format(str(preds[idx].item()), str(labels[idx].item())),\n                 color=(\"green\" if preds[idx]==labels[idx] else \"red\"))","31faf3ed":"Let's have a look at the dataset. I take 20 images from one batch and plot them with their label","83facf92":"97.5% accuracy. nice. well, it's an easy and clean dataset","78f409da":"# Training on MNIST Dataset\n\nHere I will write a full NN to train on the MNIST dataset:","2714045a":"sadly, no cuda yet on my device, so I get a cup of coffe while my NN is training\nLet's first define how my classifier will look like","404f0655":"now looking at my images again with test label and actual label","8938c6b4":"To get a better impression, I use the code from my course to plot a close-up of one of the images","5e956b93":"now also define the loss criterion and optimizer for the backpropagation","da28db76":"# Training NN Model\nNow I will define my model and train it","72f8c9e0":"First we need to get the data. I load them from the torchvision package"}}