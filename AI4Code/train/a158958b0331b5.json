{"cell_type":{"bd244281":"code","3b4f9b86":"code","cf9c8ec2":"code","94bf53d2":"code","93260333":"code","32c623b7":"code","05cfd385":"code","930d1838":"code","38955a7f":"code","cb6bcdc1":"code","0cee6a29":"code","1412721b":"code","0038b201":"code","37e01ba6":"code","d48323cc":"code","53752653":"code","9220db3f":"code","725c9593":"code","0740c9ca":"code","e9451942":"code","da49bf6e":"code","145dd30d":"code","ae1ac581":"code","cb9d585e":"code","3018dd69":"code","5f0d3cd6":"code","792ee820":"code","8f07394b":"code","184b15c1":"markdown","ec48ae52":"markdown","e4651d25":"markdown","2404cb99":"markdown","16b98110":"markdown","518bc82a":"markdown","5199add0":"markdown","5d960c22":"markdown","3afeba6a":"markdown","caf0314e":"markdown","e7343d2e":"markdown","1f4d0207":"markdown","4cfd088e":"markdown","4094c2fc":"markdown","4101f2d2":"markdown","f9152c00":"markdown","0e65f444":"markdown","12807bf9":"markdown","5bbc7f35":"markdown","ba3971a5":"markdown"},"source":{"bd244281":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport sklearn\nfrom sklearn import metrics\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nimport numpy as np\nimport keras_tuner as kt\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt","3b4f9b86":"train = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\n\ntest = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\n","cf9c8ec2":"def evaluate(model, x_val, y_val):\n    y_pred = model.predict(x_val).reshape(y_val.shape)\n    r2 = metrics.r2_score(y_val, y_pred)\n    mse = metrics.mean_squared_error(y_val, y_pred)\n    mae = metrics.mean_absolute_error(y_val, y_pred)\n    msle = metrics.mean_squared_log_error(y_val, y_pred)\n    mape = np.mean(keras.metrics.mean_absolute_percentage_error(y_val, y_pred).numpy())\n    rmse = np.sqrt(mse)\n    rmlse_score = rmlse(y_val, y_pred).numpy()\n    print(\"R2 Score:\", r2)\n    print(\"MSE:\", mse)\n    print(\"MAE:\", mae)\n    print(\"MSLE:\", msle)\n    print(\"MAPE\", mape)\n    print(\"RMSE:\", rmse)\n    print(\"RMLSE\", rmlse_score)\n    return {\"r2\": r2, \"mse\": mse, \"mae\": mae, \"msle\": msle, \"mape\": mape, \"rmse\": rmse, \"rmlse\": rmlse_score}","94bf53d2":"def rmlse(y_true, y_pred):\n    return tf.sqrt(tf.reduce_mean(tf.square(tf.math.log(y_pred + 1) - tf.math.log(y_true + 1))))","93260333":"def submit(model, X, ids, file_path):\n    SalePrice = model.predict(X)\n    submission = pd.DataFrame({\"Id\": ids, \"SalePrice\": SalePrice.reshape(-1)})\n    submission.to_csv(file_path, index=False)","32c623b7":"train.head()","05cfd385":"train.shape","930d1838":"train.info()","38955a7f":"train.describe()","cb6bcdc1":"correlation_scores = train.corr()\ncorrelation_scores","0cee6a29":"train.corr()[\"SalePrice\"].sort_values(key = lambda x: abs(x), ascending=False)","1412721b":"for data in [train, test]:\n    null_counts = data.isnull().sum()\n    null_counts[null_counts > 0]\n    null_columns = list(pd.DataFrame(null_counts[null_counts > 0]).index)\n    for column in null_columns:\n        if data[column].dtype == object:\n            data[column] = data[[column]].replace(np.NAN, \"Unknown\")\n        else:\n            data[column] = data[column].replace(np.NAN, data[column].mean())","0038b201":"train_test = pd.get_dummies(pd.concat([train, test]))","37e01ba6":"train_test.head()","d48323cc":"mean_value = train_test.mean()\nstd_value = train_test.std()\nmean_value.pop(\"SalePrice\")\nstd_value.pop(\"SalePrice\")\nprint(mean_value)\nprint(std_value)","53752653":"train_features = train_test.iloc[0: len(train)]\ntest_features = train_test.iloc[len(train):]\n_ = train_features.pop(\"Id\")\n_ = test_features.pop(\"SalePrice\")\ntest_ids = test_features.pop(\"Id\")","9220db3f":"train_features, val_features = train_test_split(train_features, test_size=0.2, random_state=np.random.randint(1000))","725c9593":"train_features.corr()","0740c9ca":"thresold = 0.05\ncorrelated_scores = train_features.corr()[\"SalePrice\"]\ncorrelated_scores = correlated_scores[correlated_scores.abs() >= thresold]\ncorrelated_columns = list(correlated_scores.index)\ncorrelated_columns.remove(\"SalePrice\")\nprint(correlated_columns)","e9451942":"train_targets = train_features.pop(\"SalePrice\")\nval_targets = val_features.pop(\"SalePrice\")","da49bf6e":"categorical_columns = set(train.dtypes[train.dtypes==object].index)","145dd30d":"scale_strategies = [\"none\", \"standard_scale\", \"standard_scale_exclude_categorcial_features\"]\nscale_strategy = scale_strategies[2]\nif scale_strategy == scale_strategies[1]:\n    train_features = (train_features - mean_value) \/ std_value\n    val_features = (val_features - mean_value) \/ std_value\n    test_features = (test_features - mean_value) \/ std_value\nif scale_strategy == scale_strategies[2]:\n    for column in train_features.columns:\n        is_categorical_feature = False\n        components = column.split(\"_\")\n        if len(components) == 2 and components[0] in categorical_columns:\n            is_categorical_feature = True\n        if is_categorical_feature == False:\n            for features in [train_features, val_features, test_features]:\n                features.loc[:, column] = (features.loc[:, column] - mean_value[column]) \/ std_value[column]","ae1ac581":"train_features.head()","cb9d585e":"use_correlated_columns = True\nif use_correlated_columns:\n    train_features = train_features[correlated_columns]\n    val_features = val_features[correlated_columns]\n    test_features = test_features[correlated_columns]","3018dd69":"def build_model(hp):\n    model = keras.Sequential()\n    model.add(keras.Input((train_features.shape[1])))\n    for depth in range(hp.Choice('depth', [3, 4, 5, 6, 7])):\n        model.add(keras.layers.Dense(hp.Choice('width', [4, 8, 16, 32, 64]), activation=hp.Choice('activation', [\"relu\", \"elu\", \"tanh\", \"selu\", \"sigmoid\"]), kernel_regularizer=keras.regularizers.l2()))\n    model.add(keras.layers.Dense(1))\n    adam = keras.optimizers.Adam(learning_rate=hp.Choice(\"learing_rate\", [1e-3, 5e-3, 1e-4, 5e-4, 1e-5]))\n    model.compile(loss='mse', optimizer=adam, metrics=[\"mae\", rmlse])\n    return model","5f0d3cd6":"tuner = kt.RandomSearch(\n    build_model,\n    objective=kt.Objective(\"val_rmlse\", direction=\"min\"),\n    max_trials=100)\ntuner.search(train_features, train_targets, epochs=10, validation_data=(val_features, val_targets))\nbest_model = tuner.get_best_models()[0]\nkeras.utils.plot_model(best_model, show_shapes=True)","792ee820":"early_stop = keras.callbacks.EarlyStopping(patience=10)\nreduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\nmodel_checkpoint_path = \"model.h5\"\nmodel_checkpoint = keras.callbacks.ModelCheckpoint(model_checkpoint_path, save_best_model=True)\nhistory = best_model.fit(train_features, train_targets, epochs=300, validation_data=(val_features, val_targets), callbacks=[early_stop, model_checkpoint, reduce_lr])\nfor metric in [\"loss\", \"mae\", \"rmlse\"]:\n    pd.DataFrame(history.history, columns=[metric, \"val_\" + metric]).plot()\n    plt.show()","8f07394b":"SalePrice = best_model.predict(test_features).reshape(-1)\nsubmission = pd.DataFrame({\"Id\": test_ids, \"SalePrice\": SalePrice})\nsubmission.to_csv(\"submission.csv\", index=False)","184b15c1":"## Build the Model","ec48ae52":"### Train Validation Split","e4651d25":"## House Price Regression with KerasTuner\n## Table of Contents\n- Summary\n- Import Packages\n- Import Datasets\n- Common Functions\n- Exploratory Data Analysis & Data Preprocessing\n    - Statistic infos\n    - Missing Value Imputation\n    - Convert Categorical Features to Numerical Features\n    - Train Validation Split\n    - Calculate Correlated Features\n    - Feature Scaling\n- Model Development\n- Submission\n\n\n## Summary\nIn this notebook, I will demonstrate using Keras Tuner to do hyper parameter tuning in House Price Prediction Problems.","2404cb99":"## Import Datasets","16b98110":"**Evaluation Function**","518bc82a":"## Submission","5199add0":"## Model Development and Evaluation","5d960c22":"\n## If you found my work useful, please give me an upvote, thanks.","3afeba6a":"## Common Functions","caf0314e":"**Root Mean Squared Logarithmic Error**","e7343d2e":"**Correlation scores**","1f4d0207":"**Statistic infos**","4cfd088e":"**Submission**","4094c2fc":"## Import Packages","4101f2d2":"### Missing Value Imputation\n\nI will use following strategies to apply imputation to missing values. \n- For numerical columns, I will replace missing value with their mean value.\n- For categorical columns, I will replace missing value with unknown category.","f9152c00":"### Convert Categorical Features to Numerical Features","0e65f444":"### Calculate Correlated Features","12807bf9":"## Exploratory Data Analysis & Data Preprocessing","5bbc7f35":"**Factors that impact house price most**","ba3971a5":"### Feature Scaling"}}