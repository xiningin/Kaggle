{"cell_type":{"a41feb86":"code","332a60fd":"code","e03a0a19":"code","f6ca0d3c":"code","7bc590ce":"code","dbc1b45e":"code","168d6aac":"code","e44b83c4":"code","a0dcbbc5":"code","3b665000":"code","ac54356f":"code","cdf228c8":"code","e1c211b5":"code","a3e7344d":"code","0981c78d":"code","32d9aa77":"code","d57b24d1":"code","0a13cae4":"code","ad360388":"code","2dc3d8de":"code","df5ff3b9":"markdown","e5db1aee":"markdown","f90d3d3f":"markdown","60b99201":"markdown","d7ff9296":"markdown","7f6d2c26":"markdown","d1e7b49d":"markdown","e5bb91cd":"markdown","5194789b":"markdown","7df70d13":"markdown","7fa7d9ca":"markdown"},"source":{"a41feb86":"import nltk\nnltk.download('punkt') #if in case tokenize sentences in words\nfrom nltk.stem.lancaster import  LancasterStemmer\nstemmer = LancasterStemmer()","332a60fd":"!pip install tflearn","e03a0a19":"import numpy as np\nimport tensorflow as tf\nimport tflearn\nimport random\nimport json\nimport pandas as pd","f6ca0d3c":"intents = pd.read_json('..\/input\/intent-chatbot\/intents.json')\nintents.head()","7bc590ce":"words = []\nclasses = []\ndocuments = []\nignore = ['?']\n#loop through each sentence in the intent's patterns\nfor intent in intents['intents']:\n  for pattern in intent['patterns']:\n    w = nltk.word_tokenize(pattern)\n    words.extend(w)\n    documents.append((w, intent['tag']))\n    if intent['tag'] not in classes:\n      classes.append(intent['tag'])","dbc1b45e":"words = [stemmer.stem(w.lower()) for w in words if w not in ignore]\nwords = sorted(list(set(words)))\nclasses = sorted(list(set(classes)))\n\nprint(len(documents),\"documents\")\nprint(len(classes), \"classes\", classes)\nprint(len(words), \"unique stemmed words\", words)","168d6aac":"training = []\noutput = []\noutput_empty = [0] * len(classes)\n\nfor doc in documents: \n  bag = []\n  pattern_words = doc[0]\n  pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n  for w in words:\n    bag.append(1) if w in pattern_words else bag.append(0)\n\n  output_row = list(output_empty)\n  output_row[classes.index(doc[1])] = 1\n  training.append([bag,output_row])\n\nrandom.shuffle(training)\ntraining = np.array(training)\n\ntrain_x = list(training[:,0])\ntrain_y = list(training[:,1])","e44b83c4":"tf.compat.v1.reset_default_graph()","a0dcbbc5":"net = tflearn.input_data(shape=[None, len(train_x[0])])\nnet = tflearn.fully_connected(net, 10)\nnet = tflearn.fully_connected(net, 10)\nnet = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\nnet = tflearn.regression(net)","3b665000":"model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')","ac54356f":"model.fit(train_x, train_y, n_epoch = 1000, batch_size=8, show_metric=True)","cdf228c8":"model.save('model.tflearn')","e1c211b5":"import pickle\npickle.dump({'words' : words, 'classes':classes, 'train_x': train_x, 'train_y' : train_y}, open(\"training_data\", \"wb\"))","a3e7344d":"data = pickle.load(open('training_data','rb'))\nwords = data['words']\nclasses = data['classes']\ntrain_x = data['train_x']\ntrain_y = data['train_y']","0981c78d":"model.load('.\/model.tflearn')","32d9aa77":"def clean_up_sentence(sentence):\n  sentence_words = nltk.word_tokenize(sentence)\n  sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n  return sentence_words","d57b24d1":"def bow(sentence, words, show_details = False):\n  sentence_words = clean_up_sentence(sentence)\n  bag = [0]*len(words)\n  for s in sentence_words:\n    for i,w in enumerate(words):\n      if w==s:\n        bag[i] = 1\n        if show_details:\n          print('found in bag: %s' % w)\n  return (np.array(bag))","0a13cae4":"context = {}\n\nERROR_THRESHOLD = 0.25\ndef classify(sentence):\n    # generate probabilities from the model\n    results = model.predict([bow(sentence, words)])[0]\n    # filter out predictions below a threshold\n    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n    # sort by strength of probability\n    results.sort(key=lambda x: x[1], reverse=True)\n    return_list = []\n    for r in results:\n        return_list.append((classes[r[0]], r[1]))\n    # return tuple of intent and probability\n    return return_list\n\ndef response(sentence, userID='123', show_details=False):\n    results = classify(sentence)\n    # if we have a classification then find the matching intent tag\n    if results:\n        # loop as long as there are matches to process\n        while results:\n            for i in intents['intents']:\n                # find a tag matching the first result\n                if i['tag'] == results[0][0]:\n                    # set context for this intent if necessary\n                    if 'context_set' in i:\n                        if show_details: print ('context:', i['context_set'])\n                        context[userID] = i['context_set']\n\n                    # check if this intent is contextual and applies to this user's conversation\n                    if not 'context_filter' in i or \\\n                        (userID in context and 'context_filter' in i and i['context_filter'] == context[userID]):\n                        if show_details: print ('tag:', i['tag'])\n                        # a random response from the intent\n                        return print(random.choice(i['responses']))\n\n            results.pop(0)","ad360388":"response('Can you please let me know the delivery options?')","2dc3d8de":"response('Menu today?')","df5ff3b9":"## Testing Chatbot","e5db1aee":"# Creating Model & Training","f90d3d3f":"# Importing Libraries","60b99201":"# Importing Dataset","d7ff9296":"# Stemming","7f6d2c26":"# Introduction","d1e7b49d":"## Creating methods for calling chatbot","e5bb91cd":"In this notebook, I will be building a contextual chatbot, using tflearn. The chatbot will be trained on a small .json file, named intent.json. I hope, this will be fun. If you want to make the chatbot robust, all you need to do is to edit the intent.json file with more entries and the chatbot will be able to become more efficient. This notebook is inspired from **The AI University channel's** **\"How to Build a contextual Chatbot using Tensorflow\"** playlist. To learn more about this chatbot, you can have a look at [this playlist](https:\/\/www.youtube.com\/playlist?list=PLlH6o4fAIji5JmlmEs-MYe1tYBwuwW5ah).\n\n![Chatbot](https:\/\/www.userlike.com\/api\/proxy\/resize\/do-i-need-a-chatbot\/header-chat-box.png?height=720)","5194789b":"# Chatbot Testing","7df70d13":"# Creating Training Data","7fa7d9ca":"# Tokenizing Words"}}