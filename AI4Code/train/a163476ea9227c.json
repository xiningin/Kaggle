{"cell_type":{"b0fde182":"code","42c6c040":"code","5b438b56":"code","c6495e24":"code","c9e9c7e1":"code","7bab46a7":"code","a5cf3fe7":"code","0dcf4024":"code","e89e20a9":"code","baf15636":"code","ec937b2a":"code","b6a10e47":"code","ea178494":"code","d45e99ed":"code","d0013407":"code","fbdd44a4":"code","1c485a3a":"code","80594977":"code","2853cfe3":"code","1e67f77f":"code","cc69ca72":"code","e81eff77":"code","ee3b0cf4":"code","04e06db0":"code","c0aa6a78":"code","f97b5af6":"code","8ed26543":"code","61e83907":"code","1ea2535c":"code","e68342fa":"code","24a56181":"code","0d424b64":"code","33bf303e":"code","ca847419":"code","989b6d4d":"code","2e521440":"code","49efc983":"code","2bdb15dd":"code","ae582f49":"code","29a60d58":"code","0715185e":"code","56827eca":"code","06cb70e0":"code","0cda4595":"code","8c4cf371":"code","efaf0094":"code","d6de65ce":"code","f65734a7":"code","488b18f7":"code","5bc4064f":"code","be4cd042":"code","5a6cec2a":"code","3d295ce4":"code","dfc3b019":"code","aefa4614":"code","ea53a1de":"code","df614149":"code","d6158976":"code","fa21da45":"code","342330e9":"code","1862af7d":"code","ca859681":"code","087bb6fc":"code","2d8bc4dc":"code","e76f37ac":"code","fb100bf3":"code","99b87281":"code","ac645a73":"code","ebb00a87":"code","03516ba0":"code","1652287e":"code","e5f93db8":"code","4a0ff537":"code","f5194b14":"code","41b95ad3":"code","efdb0d49":"code","9409e2ee":"code","f1f7350e":"code","abafc7e8":"code","c8f298c1":"code","61e46765":"code","28b4a16e":"code","ce1da948":"code","790f8aff":"code","9045cc60":"code","64c285b7":"code","aedba724":"code","a593e835":"code","70c86f39":"markdown","566df928":"markdown","a1588a80":"markdown","4df03b4a":"markdown","7743fa59":"markdown","2ccdac98":"markdown","1b1fc842":"markdown","40e7310b":"markdown","62893a9c":"markdown","d14483bc":"markdown","755b2ec6":"markdown","934acb73":"markdown","58563c50":"markdown","e966cdd3":"markdown","126eb86d":"markdown","fcc53b57":"markdown","f424feba":"markdown","bb0482a8":"markdown","d032de8b":"markdown","0d7cd396":"markdown","45ea4c6d":"markdown","391e2bbf":"markdown","8965850a":"markdown","2d0b4fc6":"markdown","13b514a1":"markdown","f44b8fe5":"markdown","4641e787":"markdown","03da80e8":"markdown","0a41ecf5":"markdown","019ffdb4":"markdown","5294115e":"markdown","d9af773b":"markdown","b95d002b":"markdown","1ea2e4aa":"markdown","80332acf":"markdown","9f62bfdc":"markdown","880b200d":"markdown","31c45d47":"markdown","45322fff":"markdown","0b9cb2ad":"markdown","c84d2c21":"markdown","e480a71a":"markdown","f6cef4d0":"markdown","5a8a545d":"markdown","47cb5c83":"markdown","0384201a":"markdown","7e7d899c":"markdown","797fc0b9":"markdown","8fa3e320":"markdown","b884edbc":"markdown","240f1621":"markdown","e8c6a3b1":"markdown","193e44fa":"markdown","619e647f":"markdown","ec234240":"markdown","1f04a09a":"markdown","abc48fbb":"markdown","0f97389a":"markdown","491fae57":"markdown","7f61608f":"markdown","3c2fb607":"markdown","b555a658":"markdown","5d0ac5e0":"markdown","81ddaae9":"markdown","59471a17":"markdown","d0be1191":"markdown","a421cc89":"markdown","3c84006d":"markdown","697fcb23":"markdown","c29485fe":"markdown","537b24b6":"markdown","76da9bbc":"markdown","bd15be67":"markdown","2cc5c0ec":"markdown"},"source":{"b0fde182":"# standard libraries\nimport pandas as pd\nimport numpy as np\n\n# plotting libraries\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import rcParams\nfrom wordcloud import WordCloud\nimport seaborn as sns\n%matplotlib inline\nrcParams['figure.figsize'] = 10,8\nsns.set(style='white')\n\n# text analysis libraries\nimport re\nimport spacy\nimport string\nimport emoji\n\n# model building and valuation libraries\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import f1_score, recall_score, precision_score, make_scorer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Sampling \nfrom sklearn.utils import resample, shuffle\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\n\n# Machine Learning models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import MultinomialNB, ComplementNB\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Ensemble models\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier\n\n# Neural Networks\n# from tensorflow.keras.metrics import Precision, Recall\n# from tensorflow.keras import Sequential\n# from tensorflow.keras.layers import Dense, Dropout, LSTM\n# from tensorflow.keras.callbacks import EarlyStopping\n\n# other libraries\nimport warnings\nwarnings.filterwarnings('ignore')","42c6c040":"# Loading a spacy English dictionary for NLP\nnlp = spacy.load('en_core_web_sm')","5b438b56":"df = pd.read_csv('..\/input\/climate-change-belief-analysis\/train.csv')\ndf_test = pd.read_csv('..\/input\/climate-change-belief-analysis\/test.csv')","c6495e24":"# Check the first five rows of the dataframe\ndf.head()","c9e9c7e1":"df.info()","7bab46a7":"print(f'The dataframe consists of {len(df)} twitter messages.')","a5cf3fe7":"# Check for NaN entries\ndf.isnull().sum()","0dcf4024":"# Sometimes empty strings can be regarded as not being null, therefore there has to be a check for empty strings message column.\nblanks = []\nfor index, sentiment, message, tweetid in df.itertuples():\n    if message.isspace():\n        blanks.append(index)","e89e20a9":"blanks","baf15636":"# Original length of dataset \noriginal_len = len(df)","ec937b2a":"original_len","b6a10e47":"all_duplicates = df[df.duplicated(['message'])]","ea178494":"all_duplicates.head(10)","d45e99ed":"len(all_duplicates)","d0013407":"duplicates = df[df.duplicated(['sentiment','message'])]","fbdd44a4":"len(duplicates)","1c485a3a":"print(f\"Therefore {len(all_duplicates) - len(duplicates)} of the rows are duplicate messages but not sharing the\\\n same sentiment, therefore they will all be dropped.\")","80594977":"# Creating a list of the indexes of duplicated messages not sharing the same sentiment.\nnot_matching = [index for index in all_duplicates.index if index not in duplicates.index]\nnot_matching","2853cfe3":"# Creating a list of the not_matching indexes and their counterpart \nremoval_list = []\nfor index in not_matching:\n    remove = df[df.loc[:,'message'] == df.loc[index, 'message']].index.to_list()\n    removal_list += remove","1e67f77f":"print(\"These is a list of indexes that have a tweet message duplicated but not sharing the same sentiment.\")\nremoval_list","cc69ca72":"# View of these messages\ndf.loc[removal_list, :]","e81eff77":"# Percentage split of the data\nplt.figure(figsize=(6,6))\nsns.set(font_scale=1.1)\ndf['sentiment'].value_counts().plot(kind='pie', autopct='%.1f', labels=['Pro','News','Neutral','Anti']);","ee3b0cf4":"df_copy = df.copy()","04e06db0":"# Check for presence of urls\ndef url_extractor(text):\n    \"\"\"\n    Returns a binary output identifying the presence of a referenced\n    url in a message\n    \n    Parameters\n    -----------\n    text: str\n        A text message\n        \n    Returns\n    --------\n    int\n        1 if a url is present in the text and 0 if there is no url\n    \"\"\"\n    \n    pattern = r'https?\\W+\\S+' # Search for a website in text\n    \n    if re.search(pattern, text):\n        return 1\n    else:\n        return 0","c0aa6a78":"df_copy['url'] = df_copy['message'].apply(url_extractor)","f97b5af6":"df_copy.head()","8ed26543":"plt.figure(figsize=(10, 5))\ndf_copy.groupby('sentiment')['url'].mean().sort_values(ascending=False).plot(kind='bar')\nplt.ylabel('ratio')\nplt.title('Ratio of tweet messages with url within each sentiment group');","61e83907":"# Remove retweets\ndef retweet_removal(text):\n    \"\"\"\n    Returns a retweet message without the RT\n    \n    Parameters\n    -----------\n    text: str\n        A text message\n    \n    Returns\n    --------\n    str\n        A tweet message without the retweet acronym\n    \"\"\"\n    if re.match(r\"RT\\s+\", text): # i.e. if text message starts with RT\n        text = re.sub(r\"RT\\s+\",\"\", text)\n\n    return text","1ea2535c":"df_copy['message'] = df_copy['message'].apply(retweet_removal)","e68342fa":"# Remove symbols and urls from tweets\ndef clean_tweets(text):\n    \"\"\"\n    Returns a tweet text without the twitter handle, hashtags and urls\n    \n    Parameters\n    -----------\n    text: str\n        A tweet message\n    \n    Returns\n    --------\n    str\n        A tweet without a website url, '@' and \"#\" symbols\n    \"\"\"\n    \n    pattern = r'@|#|https?\\W*\\S+'\n    \n    clean_text = re.sub(pattern, \"\", text).strip()\n    \n    return clean_text","24a56181":"df_copy['message'] = df_copy['message'].apply(clean_tweets)","0d424b64":"def wordcount(data):\n    \"\"\"\n    Returns a graph showing distribution of word count for each sentiment group.\n\n    Parameters\n    -----------\n    data: DataFrame\n        Dataframe consisting of tweet messages abd their respective sentiment\n        group.\n    \n    Returns\n    --------\n    ax : matplotlib Axes\n        Axes object with A Catplot showing the distribution of wordcounts in each \n        sentiment group\n    \"\"\"\n    \n    word_count=data['message'].apply(lambda x: len(x.split()))\n    wordcount_sentiment=pd.concat([pd.DataFrame(word_count),data['sentiment']],axis=1)\n    ax = sns.catplot(x=\"sentiment\", y=\"message\",kind='boxen', data=wordcount_sentiment)\n    plt.ylabel('Word count', fontsize=12);","33bf303e":"wordcount(df_copy)","ca847419":"# Chracter length distribution\ndef character_length(data):\n    \"\"\"\n    Returns a graph showing distribution of character length on each sentiment\n\n    Parameters\n    -----------\n    data: DataFrame\n        Dataframe consisting of tweet messages abd their respective sentiment\n        group.\n    \n    Returns\n    --------\n    ax : matplotlib Axes\n        Axes object with a line plot showing the distribution of charcater \n        lengths in each sentiment group.\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(8, 7))\n    charlen=data['message'].str.len()\n    charlen_sentiment=pd.concat([pd.DataFrame(charlen),data['sentiment']],axis=1)\n    sns.kdeplot(charlen_sentiment['message'][charlen_sentiment['sentiment'] == -1],label='anti')\n    sns.kdeplot(charlen_sentiment['message'][charlen_sentiment['sentiment'] == 0],label='neutral')\n    sns.kdeplot(charlen_sentiment['message'][charlen_sentiment['sentiment'] == 1],label='pro')\n    sns.kdeplot(charlen_sentiment['message'][charlen_sentiment['sentiment'] == 2],label='news')","989b6d4d":"character_length(df_copy)","2e521440":"# Create a visualization of the number of tagged twitter handles, and hashtags per sentiment groups\ndef tweet_occurence_graph(dataframe, sentiment, top_n=5, color='darkblue'):\n    \"\"\"\n    Returns a subplot of two horizontal bar graphs of the top most tagged person or organization,\n    and top most active topic of interest as identified by hashtags, in a specified sentiment group.\n    \n    Parameters\n    -----------\n    dataframe: DataFrame\n        Dataframe consisting of tweet messages and their respective sentiment group.\n    sentiment: int, str\n        A sentiment value based on category\n    top_n: int, default=5\n        The top n occurence of twitter handle and hashtag.\n    color: matplotlib colormap name or object, default='darkblue'\n         \n    Returns\n    --------\n    ax : matplotlib Axes\n        Axes object with subplots of two horizontal bar graphs\n    \"\"\"\n    \n    # I.D twitter handle and hashtags patterns\n    twitter_handle_pattern = r'(?<=^|(?<=[^a-zA-Z0-9-_\\.]))(@[A-Za-z]+[A-Za-z0-9-_]+)' # Disregards emails\n    hashtag_pattern = r'(#[A-Za-z]+[A-Za-z0-9-_]+)'\n    \n    # Filter the dataframe according to the sentiment group\n    df_filtered = dataframe[dataframe['sentiment'] == sentiment]\n    \n    # Create a dictionary of twitter handles and hashtags, and \n    # the corresponding number of occurances per sentiment group\n    twitter_handle_frequency = {}\n    hashtag_frequency = {}\n    \n    for tweet in df_filtered['message']:\n        \n        # Match all the twitter handles in a message\n        identified_handle_patterns = re.findall(twitter_handle_pattern, tweet)\n        # Match all the hashtags in a message\n        identified_hashtag_patterns = re.findall(hashtag_pattern, tweet)\n        \n        # TWITTER HANDLE\n        for item in identified_handle_patterns:\n            \n            if item in twitter_handle_frequency.keys():\n                twitter_handle_frequency[item] += 1\n            else:\n                twitter_handle_frequency[item] = 1\n            \n        # HASHTAGS\n        for item in identified_hashtag_patterns:\n            \n            if item in hashtag_frequency.keys():\n                hashtag_frequency[item] += 1\n            else:\n                hashtag_frequency[item] = 1\n        \n    # Create a temporary dataframes to host the frequency dictionaries \n    # TWITTER HANDLE\n    handle_df = pd.DataFrame(\n        data=twitter_handle_frequency.values(), \n        index=twitter_handle_frequency.keys(), \n        columns=['Occurences']\n    )\n    handle_df.sort_values(by='Occurences', ascending=False, inplace=True)\n    handle_df = handle_df[:top_n]\n    \n    # HASHTAGS\n    hashtag_df = pd.DataFrame(\n        data=hashtag_frequency.values(), \n        index=hashtag_frequency.keys(), \n        columns=['Occurences']\n    )\n    hashtag_df.sort_values(by='Occurences', ascending=False, inplace=True)\n    hashtag_df = hashtag_df[:top_n]\n    \n    # Sentiment groups\n    target = {2:'News', 1:'Pro', 0:'Neutral', -1:'Anti'}\n    \n    fig, ax = plt.subplots(ncols=2, figsize=(14, 8))\n    fig.tight_layout(pad=7.0)\n    sns.barplot(x='Occurences', y=handle_df.index, color=color, data=handle_df, ax=ax[0]) # Twitter handle\n    sns.barplot(x='Occurences', y=hashtag_df.index, color=color, data=hashtag_df, ax=ax[1]) # Hashtags\n    ax[0].set_title(f'Top {top_n} Twitter handles for {target[sentiment]} category')\n    ax[1].set_title(f'Top {top_n} Hashtags for {target[sentiment]} category')","49efc983":"tweet_occurence_graph(df, sentiment=-1, top_n=10, color='cadetblue')","2bdb15dd":"def plot_wordcloud(data, sentiment):\n    \"\"\"\n    Returns Wordcloud plot of top 100 words in our tweets.\n    \n    Parameters\n    -----------\n    data: DataFrame \n        A dataframe column that containing tweets.\n    sentiment: int, str\n        A sentiment group\n     \n    Returns\n    --------\n    ax : matplotlib Axes\n        A WordCloud showing the common words used used in that sentiment group\n    \"\"\"\n    \n    # Filter dataframe to reflect the specified sentiment group\n    filtered_data = data[data['sentiment'] == sentiment]['message']\n    plt.figure(figsize = (15,8))\n    plt.imshow(WordCloud(max_words=100 , width=1000 ,height=600).generate(\" \".join(filtered_data)), \n               interpolation = 'bilinear')","ae582f49":"plot_wordcloud(df_copy, -1)","29a60d58":"tweet_occurence_graph(df, sentiment=0, top_n=10, color='cadetblue')","0715185e":"plot_wordcloud(df_copy, 0)","56827eca":"tweet_occurence_graph(df, sentiment=1, top_n=10, color='cadetblue')","06cb70e0":"plot_wordcloud(df_copy, 1)","0cda4595":"tweet_occurence_graph(df, sentiment=2, top_n=10, color='cadetblue')","8c4cf371":"plot_wordcloud(df_copy, 2)","efaf0094":"def retweet_removal(text):\n    \"\"\"\n    Returns a retweet message without the RT\n    \n    Parameters\n    -----------\n    text: str\n        A sentence to be examined\n    \n    Returns\n    --------\n    string\n        A tweet message without the retweet acronym\n    \"\"\"\n    if re.match(r\"RT\\s+\", text): # i.e. if text message starts with RT\n        text = re.sub(r\"RT\\s+\",\"\", text)\n\n    return text","d6de65ce":"df['message'] = df['message'] .apply(lambda tweet: retweet_removal(tweet))\ndf_test['message'] = df_test['message'] .apply(lambda tweet: retweet_removal(tweet))","f65734a7":"def symbol_removal(text):\n    \"\"\"\n    Returns a tweet message without the @ and # symbol\n    \n    Parameters\n    -----------\n    text: str\n       A text message \n    \"\"\"\n    \n    edited_text = re.sub(r\"[@#]\", \"\", text)\n    \n    return edited_text","488b18f7":"df['message'] = df['message'] .apply(lambda tweet: symbol_removal(tweet))\ndf_test['message'] = df_test['message'] .apply(lambda tweet: symbol_removal(tweet))","5bc4064f":"df_test.head()","be4cd042":"X=df['message']\nX_test=df_test['message']\ny=df['sentiment']","5a6cec2a":"vectorizer = TfidfVectorizer(sublinear_tf=True)\nX = vectorizer.fit_transform(X)\nX_test = vectorizer.transform(X_test)","3d295ce4":"X_train, X_validate, y_train, y_validate = train_test_split(X, y,test_size = 0.3333, random_state = 27)","dfc3b019":"def scoring_metrics(actual, predicted):\n    \"\"\"\n    Returns a plot of a confusion matrix plotted on a heatmap as well as \n    a classification report.\n    \n    Parameters\n    -----------\n    actual: list\n        list of actual sentiment\n    predicted: list\n        list of predicted sentiment\n    \n    Results\n    --------\n    ax : matplotlib Axes\n        A heatmap showing percentages for each category on a heatmap\n    \"\"\"\n    \n    cm = confusion_matrix(actual, predicted)\n    perc_cm = np.empty(shape=cm.shape) # Confusion matrix for storing percentages\n    \n    totals = np.sum(cm, axis=1)\n    \n    # Calculate ratios row wise\n    for row in range(cm.shape[0]):\n        for col in range(cm.shape[1]):\n            perc_cm[row, col] = cm[row, col] \/ totals[row]\n    \n    print('Classification Report')\n    print(classification_report(actual, predicted))\n    print('\\n')\n    print('Confusion Matrix')\n    fig, ax = plt.subplots(ncols=2,figsize=(14,6), sharey=True)\n    labels = [-1, 0, 1, 2]\n    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', cbar=False, yticklabels=labels, xticklabels=labels, ax=ax[0])\n    sns.heatmap(perc_cm, annot=True, fmt='.2%', cmap='Blues', cbar=False, yticklabels=labels, xticklabels=labels, ax=ax[1])\n    fig.tight_layout(pad=7.0)\n    ax[0].set_ylabel(\"Actual\")\n    ax[0].set_xlabel(\"Predicted\")\n    ax[1].set_xlabel(\"Predicted\")\n    ax[0].set_title(\"Actual count\")\n    ax[1].set_title(\"Percentage of row wise actual\");","aefa4614":"# Storing the F1, precision and recall values\ndef valuations(actual, predicted):\n    \"\"\"\n    Returns the F1, precision and recall of the predicted values\n    against actual\n    \n    Parameters\n    -----------\n    actual: list\n        list of actual sentiment\n    predicted: list\n        list of predicted sentiment\n        \n    Returns\n    --------\n    dict:\n        Dictionary containing the f1, precision, and recall score         \n    \"\"\"\n    \n    f1 = f1_score(actual, predicted, average='weighted')\n    precision = precision_score(actual, predicted, average='weighted')\n    recall = recall_score(actual, predicted, average='weighted')\n    \n    return {'f1': f1, 'precision': precision, 'recall': recall} ","ea53a1de":"# Create a base model for the machine learning models\ndef base_model(X_train, y_train, X_test, model):\n    \"\"\"\n    Returns the predicted values of the feature being predicted.\n    \n    Parameters\n    -----------\n    X_train: DataFrame, pd.Series, np.array\n        Training data to train the model\n    y_train: list, np.array, DataFrame, pd.Series\n        Training labels to train the model\n    X_test: DataFrame, pd.Series, np.array\n        Testing data having same features as X_train \n        used to generate predictions\n    model: \n        Machine Learning model\n    \n    Returns\n    --------\n    list:\n        Predictions of the target variable\n    \"\"\"\n    \n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    \n    return predictions","df614149":"logreg = LogisticRegression()","d6158976":"y_pred_logreg = base_model(X_train, y_train, X_validate, logreg)","fa21da45":"scoring_metrics(y_validate, y_pred_logreg)","342330e9":"logreg_metrics = valuations(y_validate, y_pred_logreg)","1862af7d":"#### LinearSVC","ca859681":"linsvc = LinearSVC()","087bb6fc":"y_pred_linsvc = base_model(X_train, y_train, X_validate, linsvc)","2d8bc4dc":"scoring_metrics(y_validate, y_pred_linsvc)","e76f37ac":"linsvc_metrics = valuations(y_validate, y_pred_logreg)","fb100bf3":"svc = SVC()","99b87281":"y_pred_svc = base_model(X_train, y_train, X_validate, svc)","ac645a73":"scoring_metrics(y_validate, y_pred_svc)","ebb00a87":"linsvc_metrics = valuations(y_validate, y_pred_svc)","03516ba0":"mltnb = MultinomialNB() ","1652287e":"y_pred_mltnb = base_model(X_train, y_train, X_validate, mltnb)","e5f93db8":"scoring_metrics(y_validate, y_pred_mltnb)","4a0ff537":"mltnb_metrics = valuations(y_validate, y_pred_mltnb)","f5194b14":"cmpnb = ComplementNB()","41b95ad3":"y_pred_cmpnb = base_model(X_train, y_train, X_validate, cmpnb)","efdb0d49":"scoring_metrics(y_validate, y_pred_cmpnb)","9409e2ee":"cmpnb_metrics = valuations(y_validate, y_pred_cmpnb)","f1f7350e":"dt = DecisionTreeClassifier()","abafc7e8":"y_pred_dt = base_model(X_train, y_train, X_validate, dt)","c8f298c1":"scoring_metrics(y_validate, y_pred_dt)","61e46765":"dt_metrics = valuations(y_validate, y_pred_dt)","28b4a16e":"rf = RandomForestClassifier()","ce1da948":"y_pred_rf = base_model(X_train, y_train, X_validate, rf)","790f8aff":"scoring_metrics(y_validate, y_pred_rf)","9045cc60":"param_grid = {\n    'C': [0.1, 0.3, 0.5, 0.7, 0.8, 1]\n}","64c285b7":"linsvc = LinearSVC()\ngrid_svc = GridSearchCV(\n    estimator=linsvc,\n    param_grid=param_grid,\n    scoring='accuracy',\n    cv=3,\n    n_jobs=-1\n)\ngrid_svc.fit(X_train, y_train)\nbest_model = grid_svc.best_estimator_\nY_pred_grid=best_model.predict(X_validate)\nprint(classification_report(y_validate, Y_pred_grid))","aedba724":"Y_pred_grid_test=best_model.predict(X_test)","a593e835":"results = pd.DataFrame({\"tweetid\":df_test['tweetid'],\"sentiment\": Y_pred_grid_test})\nresults.to_csv(\"output.csv\", index=False)","70c86f39":"There are 1590 messages which are duplicated amongst each other in terms of the message column only.","566df928":"## GridSearch","a1588a80":"Trump once said \u201cNobody really knows if it climate change is real as we can see in our anti class graph he is number one in trends.This has proved to be untrue according to a survey, over 97% of scientists say that climate change was mostly if not all man made.The president of the U.S went as far as branding it\u2019s former president Mr Obama\u2019s climate change legacy as \u201cstupid\u201d.The Obama rule was devised to shut down hundreds of heavily polluting coal-fired power plants and freeze construction of new coal plants, while replacing them with vast wind and solar farms. Which sounded like a great idea to me.These series of tweets lands him on our highest trend on our anti graph.","4df03b4a":"For the news category we have 2 sides basically we have news channels that are for the notion of man made climate change and we have channels that are neutral, these channels tend to focus mostly on facts and the political stance towards climate change thats why words like Trump, scientist, report, republlican , china and business occur the most.","7743fa59":"EDSA has tasked the group in creating a Machine Learning model that is able to identify the sentiment group each person belongs to based on their tweet message. Accurate predictions from this model will enable companies to familiarize themselves with the overall sentiment of a broader population hence enabling access to insights and developing marketing strategies.\n\nThe overall analytical framework that was followed is that data was presented to us which contained tweets about climate change collected from 27 April 2015 till 21 Feb 2018. Data was split into train and test data and the machine learning model was trained using only train data and was tested with the test data. Various models were tested to determine the best performing model, the models ranged from Linear Support Vector Machines, Complement Naive Bayes, ensemble models such as Voting Classifier, and Bagging Classifier, and Neural Networks.","2ccdac98":"**Splitting the data to test and validation set**","1b1fc842":"The performance of the model was based on how well the model generalizes between different sentiment groups, this was clearly captured by using the F1-score as the valuation metric.\n\n$$F1 = \\frac{2 \\times Precision \\times Recall}{Precision + Recall}$$\n\nwhereby:\n\n$$Precision = \\frac{TP}{TP + FP}$$ <br>\n\n$$Recall = \\frac{TP}{TP + FN}$$ <br>\n\n$TP$ - True Positives <br>\n\n$FP$ - False Positives <br>\n\n$FN$ - False Negatives","40e7310b":"Based on the pie chart above, 53.9% of the tweets supports the belief of man-made climate change **(Pro)**, 23% are based on factual news about climate change **(News)**, 14.9% of the tweets are rather neutral on the subject **(Neutral)**, and 8.2% do not believe in man-made climate change **(Anti)**. Looking at this distribution of the dataset based on sentiment classes, it appears that the data is unbalanced. Having an unbalanced dataset introduces bias within the data, depending on the application of the model and how critical the classification, we can either keep the data as is or use data balancing methods like upsampling, down sampling and Smote.","62893a9c":"#### Multinomial Naive Bayes","d14483bc":"The presence of a url in a tweet is marked by the number 1, whereas if the tweet does not have url, it is marked by zero. Below is the ratio of the presence of urls in each sentiment group.  ","755b2ec6":"## Background\n\nOrganizations around the world are focused on reducing the amount of environmental impact that is caused by the products they produce. These organizations have taken the responsibility to reduce their carbon footprint. However, there are some people who believe that it is not their responsibility to follow suit, and that climate change is a hoax. They argue that the environmental changes which are happening are natural.","934acb73":"As observed in the the graphs above the most mentioned twitter account is that of the United States President Donald Trump and the most discussed topic is climate and climate change.","58563c50":"#### SVC","e966cdd3":"In the quest to find out what makes each sentiment class unique, an exploration of the topics each group mentions the most is conducted. This is achieved by extracting the hashtags from the tweets and creating plots of the most mentioned hashtags for each sentiment group. Furthermore, finding out who or what entity is being tagged the most in each sentiment group by extracting the mentioned twitter handles from the tweets could help in identifying the uniqueness of each sentiment group.\n\nThe regular expression library is utilized to extract the twitter handles and hashtags, and plot the top most frequent topics and twitter accounts. ","126eb86d":"# Modeling","fcc53b57":"DISCUSSION OF RESULTS","f424feba":"## Data Prepocessing","bb0482a8":"### Support Vector Machines","d032de8b":"# Exploratory Data Analysis","0d7cd396":"DISCUSSION ABOUT THE RESULTS\nIn our case we have the class \"Pro\" with the most data points this might potentially mean that our model would be biased towards the class \"Pro\", meaning that our model will be very good at predicting that text belongs to the class \"Pro\" and very bad at predicting other classes.","45ea4c6d":"## Overview","391e2bbf":"**Exporting the best performing which is linear SVC**","8965850a":"To avoid any data leakage to the test data when performing a train test split, a copy of the dataframe is created to ensure that the removal of retweets (RT) and urls (https..) does not affect the original database. The reason being that the this process will be part of the data cleaning pipeline when cleaning the X_train database. Cleaning a copy of the database will only help in doing word cloud visualizations. ","2d0b4fc6":"There are 1586 messages which are duplicated both in sentiment and message.","13b514a1":"<a href=\"https:\/\/colab.research.google.com\/github\/Maredipinkydimakatso\/jhb-ss3-classification-Repo\/blob\/master\/Classification_submission_file.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","f44b8fe5":"### Anti","4641e787":"Similarly, there appears to be no empty strings in the dataset.","03da80e8":"The figure above shows the word cloud for the sentiment group that bellieves  in the notion of cllimate change. In the word coud we can observe words and phrases like \"Beieve\", \"change denier\", \"change hoax\", \"watch BeforetheFlood\", \"science\", \"threat\", \"Husband Beieve\". These words indicates that this group is advocating for man made climate change and most importantly that the want to change the minds of those who do not believe by suggesting that the watch Before the flood.","0a41ecf5":"This makes it clear tha the News class puts url's in their message to strengthen the message that they are sending through.","019ffdb4":"Model not suited for imbalanced data","5294115e":"### RandomForestClassifier","d9af773b":"The above are the duplicates in our data and removing them might impact the score accuracy, so for now we will keep them","b95d002b":"## Visualizations","1ea2e4aa":"Millions of messages are sent everyday through different digital platforms. These messages (e.g tweets) are essentially data, which could be used to gain insights and make data-driven decisions. Using the technique of classification, machine learning models can be taught how to group new text data into categories. In order to do this, however, these models need to be trained rigorously so that they can accurately categorise new data.\nThus, the aim of this project is to build a classification model that can predict which category a tweet falls into. Since seeing that this project is focused on climate change, the categories are Pro (i.e. supports the belief in man-made climate change), Anti (does not support the belief in man-made climate change), Neutral (is neither for or against the belief in climate change) and Factual news.\nThe objectives of this project are to:\n\n- Understand the training data\n- Use this understanding along with machine learning techniques to develop a model that accurately classify climate change tweets into different categories","80332acf":"### Distribution","9f62bfdc":"### Logistic Regression","880b200d":"## Missing values","31c45d47":"### Naive Bayes","45322fff":"# Introduction","0b9cb2ad":"The performance of the models is based on the weighted F1-score, this will be identified using the classification report. The confusion matrix will also be displayed in order to identify where the model is performing poorly.","c84d2c21":"### Decision Tree","e480a71a":"In the possitive class where 53% of our data lies if the data represents a sample population it woulld mean that most peoplle in general believe in the notion of man made climate change. We can also see similarly to the other groups that the President is also on the most mentioned twitter handle.\n\nThe most mentioned twitter acount belongs to @StephenSchlegel, @senSanders was also the second most mentioned. Bernard Sanders is an American politician who has served as the junior United States Senator from Vermont since 2007 and as U.S, he strongly supports the notion of man made climate change.\n\nThe top topic that this sentiment group is mostly discussing is #climate and #BeforeTheFlood, \"Before the flood\" is a National Geographic doicumentary that stars Leonardo Dicaprio and it aims to educate people about the effects of global warming, which explains why Leonardo Dicaprios handle is also part of the top 10 most mentioned tweet.\n\n","f6cef4d0":"In order for text messages to serve as input to the Machine Learning models, the text messages have to be converted to numbers using the Term Frequency Inverse Document Frequency Vectorizer.","5a8a545d":"## Valuation","47cb5c83":"## Overview","0384201a":"## Ensemble models","7e7d899c":"## Machine Learning ","797fc0b9":"### Pro","8fa3e320":"In this section we will take a closer look at our data to check for obvious and hidden underlying clues and relationships that exist within our differrent classes. Our problem is a multiclass classification problem with only 4 classes so in order for us to distinguish between the classes we need to figure out what makes each classs unique.","b884edbc":"# Libraries","240f1621":"DISCUSSION OF RESULTS","e8c6a3b1":"In the Neutral category we see words like \"maybe\", \"look\", \"change real\" , \"right\", \"thinK\", \"cause\" all these words somewhat represent a form or element of uncertainty which indicates that this particular sentiment group is not really sure where they stand.","193e44fa":"The word cloud above representing people who do not believe in climate man made climate change shows us interesting insights about this particular group. From the word cloud we observe words like \"hoax\", \"fraud\" , \"evidence\",\"fake\" , \"Scam\" and \"Myth\" being used which indicates that they feel like the notion of man made global barming is a Scam, a fraud, a myth and it's fake. This highlights the groups negetive sentiment towards man made global warming.","619e647f":"Based on the categorical plots above, it appears that based on the median values (solid line), the Anti and Pro regularly express their sentiment in more words as compared to the News and Neutral group. This might be indicative of a strong persona that is in Anti and Pro group, that they feel that they need to say more to get their point across. The News group has the lowest median for the word count which is due to the high number of url extensions that are in that sentiment group as seen in the previous graph on ratio of presence of urls in the tweets. The News group uses website links, articles and past stories to further make their point across, hence their overall lower usage of words. ","ec234240":"The data frame consists of three columns, sentiment which is an interger value refering to the tweet class.\n\n| **Class** | **Description** |\n| :----------: | :------------- |\n| 2 | **News:** the tweet links to factual news about climate change |\n| 1 | **Pro:** the tweet supports the belief of man-made climate change |\n| 0 | **Neutral:** the tweet neither supports nor refutes the belief of man-made climate change |\n| -1 | **Anti:** the tweet does not believe in man-made climate change |\n\nsource: https:\/\/www.kaggle.com\/c\/climate-change-belief-analysis\/data\n\nThe message column is in text format for tweets collected from April 2015 to February 2018 on people expressing the belief \nabout man-made climate change. The tweetid is a unique integer value corresponding to the tweet message.","1f04a09a":"To avoid any data leakage, the dataset has been split into a training dataset to train the machine learning model and the testing dataset to test the performance of the model.","abc48fbb":"The approach followed in valuating the performance of the models is based on testing the performance of the base machine learning model, that is, without any parameters being adjusted and comparing the results will all the other models.","0f97389a":"# Conclusion","491fae57":"## Framework","7f61608f":"The graph above represent the top 10 most occuring twitter handles within the sentiment group that is Anti [against the notion of] man made climate change. The graph shows that the handle @SteveSGoddord appears the most followed by the handle of U.S President, Donald Trump and then a handle called @PrisonPlanet.\n\nThe twitter handle @SteveSGoddard was owned by a man called Tony Heller who describes himself as a whiste blower and an independant thinker who believes that the notion of man made climate change is not entirely true he believes that we are not the primary cause of climate change and that infact that our contribution to it is miniscule.\n\nThe president of the United States of America on the other hand has publicly labelled climate change as a hoax.\n\n","3c2fb607":"## Duplicates","b555a658":"Better performer as compared to MultiNonmial NB","5d0ac5e0":"### Writing Characteristics","81ddaae9":"There are currently no missing values in the dataset.","59471a17":"The earth climates is changing very fast and differently nowadays climate changes in our earth are affecting our lives psychologically, physically and emotionally. some see it as a natural occurrence and others see it as a man made catastrophe, the fact is simple that the world climate is changing What is climate change? Climate change is the seasonal changes for a long period of time in the world. The climate patterns effect our economies and ecosystems For example, the changes in climate can affect how people, plants and animal live, such as food production and health risks.\n\nThe Earth\u2019s climate is very broad and always changing causing a good deal concern for us as humans.However, what are the causes and effects of climate changes that affecting our lives and environment?\n\nThere are two main causes of climate changes \u2013 natural causes and human activities. Natural causes have influenced the earth\u2019s climates such as volcanic eruptions, ocean current, the earth\u2019s orbital changes and solar variations.\n\nAll the causes are giving a great impact for climate changes in our earth.the consequences We can see that there are three main effects on climate changes in our environment. Firstly, climate change in the world affects human health. There are so many past researches showed that climate change will leads to human health and producing diseases. Secondly, climate changes will also affect the biodiversity. Biodiversity is very important for the plants and animals to maintain their habitat and ecosystem. The climate changes have impacted the loss of biodiversity.\n\nWhen we have a look at our Neutral occurrence sentiment graph each of these topics are becoming more and more relevant each day and rightfully so.This has made the \u201c#climate\u201d thee most talked about topic on the news and social media","d0be1191":"<a href=\"https:\/\/colab.research.google.com\/github\/Maredipinkydimakatso\/jhb-ss3-classification-Repo\/blob\/master\/Classification_submission_file.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","a421cc89":"### Neutral","3c84006d":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Background\" data-toc-modified-id=\"Background-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;<\/span>Background<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Introduction<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Problem-Statement\" data-toc-modified-id=\"Problem-Statement-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;<\/span>Problem Statement<\/a><\/span><\/li><li><span><a href=\"#Framework\" data-toc-modified-id=\"Framework-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;<\/span>Framework<\/a><\/span><\/li><li><span><a href=\"#Valuation\" data-toc-modified-id=\"Valuation-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;<\/span>Valuation<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Libraries\" data-toc-modified-id=\"Libraries-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Libraries<\/a><\/span><\/li><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>Data<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;<\/span>Overview<\/a><\/span><\/li><li><span><a href=\"#Missing-values\" data-toc-modified-id=\"Missing-values-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;<\/span>Missing values<\/a><\/span><\/li><li><span><a href=\"#Duplicates\" data-toc-modified-id=\"Duplicates-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;<\/span>Duplicates<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Exploratory-Data-Analysis\" data-toc-modified-id=\"Exploratory-Data-Analysis-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>Exploratory Data Analysis<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;<\/span>Overview<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Distribution\" data-toc-modified-id=\"Distribution-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;<\/span>Distribution<\/a><\/span><\/li><li><span><a href=\"#Writing-Characteristics\" data-toc-modified-id=\"Writing-Characteristics-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;<\/span>Writing Characteristics<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Visualizations\" data-toc-modified-id=\"Visualizations-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;<\/span>Visualizations<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Anti\" data-toc-modified-id=\"Anti-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;<\/span>Anti<\/a><\/span><\/li><li><span><a href=\"#Neutral\" data-toc-modified-id=\"Neutral-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;<\/span>Neutral<\/a><\/span><\/li><li><span><a href=\"#Pro\" data-toc-modified-id=\"Pro-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;<\/span>Pro<\/a><\/span><\/li><li><span><a href=\"#News\" data-toc-modified-id=\"News-4.2.4\"><span class=\"toc-item-num\">4.2.4&nbsp;&nbsp;<\/span>News<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;<\/span>Feature Engineering<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;<\/span>Modeling<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Data-Prepocessing\" data-toc-modified-id=\"Data-Prepocessing-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;<\/span>Data Prepocessing<\/a><\/span><\/li><li><span><a href=\"#Machine-Learning\" data-toc-modified-id=\"Machine-Learning-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;<\/span>Machine Learning<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;<\/span>Logistic Regression<\/a><\/span><\/li><li><span><a href=\"#Support-Vector-Machines\" data-toc-modified-id=\"Support-Vector-Machines-5.2.2\"><span class=\"toc-item-num\">5.2.2&nbsp;&nbsp;<\/span>Support Vector Machines<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#SVC\" data-toc-modified-id=\"SVC-5.2.2.1\"><span class=\"toc-item-num\">5.2.2.1&nbsp;&nbsp;<\/span>SVC<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#KNearest-Neighbors\" data-toc-modified-id=\"KNearest-Neighbors-5.2.3\"><span class=\"toc-item-num\">5.2.3&nbsp;&nbsp;<\/span>KNearest Neighbors<\/a><\/span><\/li><li><span><a href=\"#Naive-Bayes\" data-toc-modified-id=\"Naive-Bayes-5.2.4\"><span class=\"toc-item-num\">5.2.4&nbsp;&nbsp;<\/span>Naive Bayes<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Multinomial-Naive-Bayes\" data-toc-modified-id=\"Multinomial-Naive-Bayes-5.2.4.1\"><span class=\"toc-item-num\">5.2.4.1&nbsp;&nbsp;<\/span>Multinomial Naive Bayes<\/a><\/span><\/li><li><span><a href=\"#Complement-Naive-Bayes\" data-toc-modified-id=\"Complement-Naive-Bayes-5.2.4.2\"><span class=\"toc-item-num\">5.2.4.2&nbsp;&nbsp;<\/span>Complement Naive Bayes<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Decision-Tree\" data-toc-modified-id=\"Decision-Tree-5.2.5\"><span class=\"toc-item-num\">5.2.5&nbsp;&nbsp;<\/span>Decision Tree<\/a><\/span><\/li><li><span><a href=\"#Neural-Networks\" data-toc-modified-id=\"Neural-Networks-5.2.6\"><span class=\"toc-item-num\">5.2.6&nbsp;&nbsp;<\/span>Neural Networks<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Ensemble-models\" data-toc-modified-id=\"Ensemble-models-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;<\/span>Ensemble models<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#RandomForestClassifier\" data-toc-modified-id=\"RandomForestClassifier-5.3.1\"><span class=\"toc-item-num\">5.3.1&nbsp;&nbsp;<\/span>RandomForestClassifier<\/a><\/span><\/li><li><span><a href=\"#VotingClassifier\" data-toc-modified-id=\"VotingClassifier-5.3.2\"><span class=\"toc-item-num\">5.3.2&nbsp;&nbsp;<\/span>VotingClassifier<\/a><\/span><\/li><li><span><a href=\"#BaggingClassifier\" data-toc-modified-id=\"BaggingClassifier-5.3.3\"><span class=\"toc-item-num\">5.3.3&nbsp;&nbsp;<\/span>BaggingClassifier<\/a><\/span><\/li><\/ul><\/li><\/ul><\/li><li><span><a href=\"#Balancing-the-data\" data-toc-modified-id=\"Balancing-the-data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;<\/span>Balancing the data<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Downsampling\" data-toc-modified-id=\"Downsampling-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;<\/span>Downsampling<\/a><\/span><\/li><li><span><a href=\"#Upsampling\" data-toc-modified-id=\"Upsampling-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;<\/span>Upsampling<\/a><\/span><\/li><li><span><a href=\"#SMOTE\" data-toc-modified-id=\"SMOTE-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;<\/span>SMOTE<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;<\/span>Results<\/a><\/span><\/li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;<\/span>Conclusion<\/a><\/span><\/li><\/ul><\/div>","697fcb23":"### News","c29485fe":"## Problem Statement","537b24b6":"DISCUSSION OF RESULTS","76da9bbc":"# Data","bd15be67":"In the neautral class it has been observed that Donald Trump is one of the most mentioned handles followed by the news chanels CNN and fox news respectfully. What we can say is that the neutral group is more interested in factual news and the political view as well.","2cc5c0ec":"#### Complement Naive Bayes"}}