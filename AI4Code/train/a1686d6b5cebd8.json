{"cell_type":{"d0a5a16b":"code","a08508fa":"code","3df920c5":"code","0c69fcd7":"code","88c4af09":"code","cac53d38":"code","d65e27c7":"code","9a5367b3":"code","9eedfb36":"code","9d69c97d":"code","2e5630f7":"code","795b02af":"code","00c4a0c9":"code","068a74a7":"code","ad95b993":"markdown","75a0ddc7":"markdown","ac8af44e":"markdown","de88ea53":"markdown"},"source":{"d0a5a16b":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n\nimport os\nprint(os.listdir(\"..\/input\/dataset\"))\n","a08508fa":"from keras import layers\nfrom keras import models\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation = 'relu',\n                       input_shape = (150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D(2, 2))\nmodel.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D(2, 2))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation = 'relu'))\nmodel.add(layers.Dense(1, activation = 'sigmoid'))","3df920c5":"model.summary()","0c69fcd7":"from keras import optimizers\n\nmodel.compile(loss = 'binary_crossentropy',\n             optimizer=optimizers.RMSprop(lr=1e-4),\n             metrics = ['acc'])","88c4af09":"from keras.preprocessing.image import ImageDataGenerator\ntrain_dir=(\"..\/input\/dataset\/train\")\nvalidation_dir=(\"..\/input\/dataset\/valudation\")\ntest_dir=(\"..\/input\/dataset\/test\")\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n                    train_dir,\n                    target_size = (150, 150),\n                    batch_size = 20,\n                    class_mode = 'binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n                        validation_dir,\n                        target_size = (150, 150),\n                        batch_size = 20,\n                        class_mode = 'binary')","cac53d38":"for data_batch, labels_batch in train_generator:\n    print('data batch shape:', data_batch.shape)\n    print('labels batch shape:', labels_batch.shape)\n    break","d65e27c7":"history = model.fit_generator(\n                train_generator,\n                steps_per_epoch = 40,\n                epochs = 20,\n                validation_data = validation_generator,\n                validation_steps = 40)","9a5367b3":"import matplotlib.pyplot as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label = 'Training acc')\nplt.plot(epochs, val_acc, 'b', label = 'Validation acc')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label = 'Training loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\nplt.show()","9eedfb36":"datagen = ImageDataGenerator(\n                            rotation_range=40,\n                            width_shift_range=0.2,\n                            height_shift_range=0.2,\n                            shear_range=0.2,\n                            zoom_range=0.2,\n                            horizontal_flip=True,\n                            fill_mode='nearest')","9d69c97d":"model = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(512, activation = 'relu'))\nmodel.add(layers.Dense(1, activation = 'sigmoid'))\n\nmodel.compile(loss = 'binary_crossentropy',\n             optimizer=optimizers.RMSprop(lr=1e-4),\n             metrics=['acc'])","2e5630f7":"\ntrain_datagen = ImageDataGenerator(\n                rescale = 1.\/255,\n                rotation_range=40,\n                width_shift_range=0.2,\n                height_shift_range=0.2,\n                shear_range=0.2,\n                zoom_range=0.2,\n                horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n                                train_dir,\n                                target_size = (150, 150),\n                                batch_size = 32,\n                                class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n                                validation_dir,\n                                target_size = (150, 150),\n                                batch_size = 32,\n                                class_mode = 'binary')\n\nhistory = model.fit_generator(\n                            train_generator,\n                            steps_per_epoch = 5,\n                            epochs = 5,\n                            validation_data = validation_generator,\n                            validation_steps = 5)","795b02af":"acc = history.history['acc']\nval_acc = history.history['val_acc']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'b', label = 'Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label = 'Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\n\nplt.show()","00c4a0c9":"train_datagen = ImageDataGenerator(\n                rescale = 1.\/255,\n                rotation_range=40,\n                width_shift_range=0.2,\n                height_shift_range=0.2,\n                shear_range=0.2,\n                zoom_range=0.2,\n                horizontal_flip=True)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n                                train_dir,\n                                target_size = (150, 150),\n                                batch_size = 32,\n                                class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n                                validation_dir,\n                                target_size = (150, 150),\n                                batch_size = 32,\n                                class_mode = 'binary')\n\nhistory = model.fit_generator(\n                            train_generator,\n                            steps_per_epoch = 40,\n                            epochs = 10,\n                            validation_data = validation_generator,\n                            validation_steps = 20)","068a74a7":"acc = history.history['acc']\nval_acc = history.history['val_acc']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'b', label = 'Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label = 'Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\n\nplt.show()","ad95b993":"**epochu kestik**","75a0ddc7":"**Ahmet KAYKISIZ 162803046 II. \u00d6\u011fretim**\nhttps:\/\/www.dropbox.com\/sh\/copgx9u7fto5sv8\/AADXpFpV4srRu0X1HvYqKxK0a?dl=0\n","ac8af44e":" augment drop","de88ea53":"epoch kesince grafik"}}