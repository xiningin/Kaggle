{"cell_type":{"23182cd9":"code","c06ab8df":"code","76e7d29c":"code","3a5752c6":"code","a636f3eb":"code","d0beb9cf":"code","0e988ab3":"code","3f173701":"code","54cf3d35":"code","b4cb15ae":"code","b844704a":"code","fa76f871":"code","2b87bf77":"markdown"},"source":{"23182cd9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # numeric library\nimport pandas as pd # data structure library\n\nimport matplotlib.pyplot as plt # plot library","c06ab8df":"# reading the dataset\npath = \"..\/input\/tensorflow-great-barrier-reef\/\"\ntrain = pd.read_csv(path+\"train.csv\")\ntest = pd.read_csv(path+\"test.csv\")\n\n# dataset shape\nprint('Train Images: {}'.format(train.shape[0]))\nprint('Test Images: {}'.format(test.shape[0]))\n\n# how many images contain the starfish and how many does not\nprint('Train Images without Starfish: {} and Train Images with Starfish: {}'.format(train[train['annotations']=='[]'].shape[0], train[train['annotations']!='[]'].shape[0]))\nprint('Percentage of Images with Starfish: {:.2f}%'.format(train[train['annotations']!='[]'].shape[0]\/train.shape[0]*100))","76e7d29c":"# Add images path to dataframe\ntrain[\"image_path\"] = \"..\/input\/tensorflow-great-barrier-reef\/train_images\/video_\"+train[\"video_id\"].astype(str)+\"\/\"+train[\"image_id\"].apply(lambda x: x.split(\"-\")[1])+\".jpg\"\n\n# eval annotations\ntrain[\"annotations\"] = train[\"annotations\"].apply(eval)\n\n# viewing some sample rows of the dataframe\ntrain.head()","3a5752c6":"from collections import OrderedDict\ndef draw_bar_graph(ax, x, y, div_factor, *args):\n    d = dict(zip(x, y)) # creating a dictionary using the argument (x, y): x=key, y=value\n    d = OrderedDict(sorted(d.items())) # sorting the dictionary w.r.t. keys\n\n    width = 0.75 # the width of the bars \n\n    ax.bar(list(d.keys()), list(d.values()), width=width, align='center', edgecolor='darkblue', facecolor='lightblue')\n    ax.set_xticks(list(d.keys()), list(d.keys()))\n\n    # this draws the labels\n    for i, v in d.items():\n        ax.text(i-width\/div_factor, v+10, str(v), color='black', fontweight='bold')\n        \n    if len(args) == 3:\n        ax.set_title('{}: {}'.format(args[2], np.dot(list(d.values()), list(d.keys()))))\n     \n    ax.set_xlabel(args[0])\n    ax.set_ylabel(args[1])\n    return ax","a636f3eb":"fig, axes = plt.subplots(1, 2, figsize=(12.5, 5))\nimage_count = train['video_id'].value_counts()\naxes[0] = draw_bar_graph(axes[0], image_count.index, image_count.values, 10, 'Video Id', 'Number of Images')\n\n# count of images with\/without starfish\ntemp_series1 = train[train['annotations'].str.len()==0].groupby('video_id').count()['annotations']\ntemp_series2 = train[train['annotations'].str.len()!=0].groupby('video_id').count()['annotations']\n\n# creating a dataframe\ntemp_df = pd.DataFrame({ 'Starfish (without)': temp_series1, 'Starfish (with)': temp_series2 })\n\nvideo_id = [0,1,2]\n\n# From raw value to percentage\ntotals = [i+j for i,j in zip(temp_df['Starfish (without)'], temp_df['Starfish (with)'])]\ngreenBars = [i \/ j * 100 for i,j in zip(temp_df['Starfish (without)'], totals)]\norangeBars = [i \/ j * 100 for i,j in zip(temp_df['Starfish (with)'], totals)]\n \n# plot\nwidth = 0.75\n# Create green Bars\naxes[1].bar(video_id, greenBars, color='#119999', edgecolor='white', width=width, label='Starfish (without)')\n# Create orange Bars\naxes[1].bar(video_id, orangeBars, bottom=greenBars, color='#f9bc86', edgecolor='white', width=width, label='Starfish (with)')\n\nfor i in video_id:\n    axes[1].text(i-width\/5, greenBars[i]-50, '{:.2f}%'.format(greenBars[i]), color='black', fontweight='bold')\n    axes[1].text(i-width\/5, greenBars[i]+3, '{:.2f}%'.format(orangeBars[i]), color='black', fontweight='bold')\n    \n# Custom x axis\naxes[1].set_xticks(video_id, video_id)\naxes[1].set_xlabel(\"Video id\")\naxes[1].set_ylabel(\"Percentage of Images\")\n\n# Add a legend\n#axes[1].legend(loc='upper left', bbox_to_anchor=(1,1), ncol=1)\naxes[1].legend(loc='lower right')\n\nplt.tight_layout()\nplt.show()\nplt.close() # doesn't hold the image in memory anymore","d0beb9cf":"fig, ax = plt.subplots(figsize=(10, 7.5))\n    \nstarfish_count = train[train.annotations.str.len()!=0].annotations.str.len().value_counts()\ndraw_bar_graph(ax, starfish_count.index, starfish_count.values, 3, 'Number of Starfish per Image', 'Number of Images', 'Distribution of starfish numbers across images\\nTotal starfish in all images')\n\nplt.tight_layout()\nplt.show()\nplt.close() # doesn't hold the image in memory anymore","0e988ab3":"# creating a new dataframe temp_df just separating the bounding box information\n# this is to just create the histogram of bounding box sizes\nout = {}\nfor i, (k, v) in enumerate(train[train['annotations'].str.len()!=0]['annotations'].items()):\n    temp_df = pd.DataFrame(v)\n    if temp_df.empty:\n        out[(i, k)] = pd.DataFrame(index=[0], columns=['Id'])\n    else:\n        out[(i, k)] = temp_df\ntemp_df = pd.concat(out, sort=True).reset_index(level=[0,2], drop=True)\n# temp_df will contain all the 11898 starfish bounding box details\ntemp_df['area'] = temp_df['height'] * temp_df['width']\ntemp_df['aspect_ratio'] = temp_df['width'] \/ temp_df['height']\nprint('Number of bounding boxes (which is also the number of starfish): {}'.format(temp_df.shape[0]))\ntemp_df.head()","3f173701":"fig, axes = plt.subplots(2,2, figsize=(15, 10))\n\n# drawing histograms by dividing into different bounding box area ranges\n# gives an idea how big\/small starfish objects are within the images\ntemp_df[temp_df['area']<=1600]['area'].hist(ax = axes[0, 0]) # number of bounding boxes where area < 1600 pixel^2\ntemp_df[(temp_df['area']>1600)&(temp_df['area']<=5000)]['area'].hist(ax = axes[0, 1]) # number of bounding boxes where area > 1600 pixel^2 and <= 5000 pixel^2\ntemp_df[(temp_df['area']>5000)&(temp_df['area']<=10000)]['area'].hist(ax = axes[1, 0]) # ...\ntemp_df[(temp_df['area']>10000)]['area'].hist(ax = axes[1, 1]) # ...\n\n# setting x and y labels of the figures\nfor i in range(2):\n    for j in range(2):\n        axes[i, j].set_xlabel('Bounding box area, (pixel)$^2$')\n        axes[i, j].set_ylabel('Frequency')\n        \nplt.tight_layout()\nplt.show()\nplt.close()","54cf3d35":"# looking at the various aspect ratios of the bounding boxes containing starfish object\nfig, axes = plt.subplots(1,2, sharey=True, figsize=(12.5, 5))\n\ntemp_df[temp_df['aspect_ratio'] < 1.0]['aspect_ratio'].hist(ax=axes[0])\ntemp_df[temp_df['aspect_ratio'] >= 1.0]['aspect_ratio'].hist(ax=axes[1])\n\naxes[0].set_xlabel('Aspect Ratio')\naxes[1].set_xlabel('Aspect Ratio')\naxes[0].set_ylabel('Frequency')\nplt.tight_layout()\nplt.show()\nplt.close()","b4cb15ae":"print('The image ID with the largest bounding box area: {}'.format(temp_df['area'].idxmax()))\n# we have seen an image can contain upto 18 starfish(es): finding one such image id\nprint('The image ID with the highest number of starfish: {}'.format(train['annotations'].str.len().idxmax()))","b844704a":"from PIL import Image, ImageDraw\n\n# draw an image with bounding boxes: argument is the dataframe and image id\ndef img_viz(df, id):\n    image = df['image_path'][id]\n    img = Image.open(image)\n    \n    for box in df['annotations'][id]:\n        shape = [box['x'], box['y'], box['x']+box['width'], box['y']+box['height']]\n        ImageDraw.Draw(img).rectangle(shape, outline =\"red\", width=3)\n    return img\n\n# in this part, we draw a few images to get an idea of the image quality, surroundings, shapes of starfish inside it, etc.\nfig, axes = plt.subplots(2,2, figsize=(15, 10))\n\n# draw an image with starfish\nimg1 = img_viz(train, id=5474)\naxes[0, 0].set_title('An image with starfish')\naxes[0, 0].imshow(img1)\n\n# draw an image with the largest bounding box containing starfish\nimg2 = img_viz(train, id=7336)\naxes[0, 1].set_title('The image with the largest bounding box containing starfish')\naxes[0, 1].imshow(img2)\n\n# draw an image with the highest number of starfish\nimg3 = img_viz(train, id=12679)\naxes[1, 0].set_title('One of three images with the highest number (18) of starfish')\naxes[1, 0].imshow(img3)\n\n# draw an image without a starfish as well\nimg4 = img_viz(train, id=1)\naxes[1, 1].set_title('An image with no starfish')\naxes[1, 1].imshow(img4)\n\nplt.tight_layout()\nplt.show()\nplt.close() # doesn't hold the image in memory anymore","fa76f871":"# in this part, we draw a few images to get an idea of the image quality, surroundings, shapes of starfish inside it, etc.\nfig, axes = plt.subplots(1,1, figsize=(15, 10))\n\n# draw an image with starfish\nimg1 = img_viz(train, id=7336)\naxes.set_title('An image with starfish')\naxes.imshow(img1)\n\nplt.tight_layout()\nplt.show()\nplt.close()","2b87bf77":"<h2>Summary<\/h2>\n<ul>\n    <li>The images vary in quality (e.g., clarity). The background colour seems to be affected as well (not always sea blue?). <\/li>\n    <li>The surroudnings should definitely be considered in terms of choosing the object (starfish) detection algorithm - also if applying 'transfer learning' (pre-built model for object detection) too.<\/li>\n    <li>There are different bounding box sizes within the image. Some of them are very hard to identify with naked eye. Is there a need to apply 'image augmentation' techniques especially for starfish bounding boxes (the larger ones?) that are not abundant in quantity?<\/li>\n    <li>Semantic segmenation algorighms for only learning the 'semantic' inforamtion of the starfish. In other words, no need to differentiate between multiple starfish. As long as, a starfish object can be detected and localised within the image correctly, the task will be achieved.<\/li>\n    <li>The projection angle of the scene seems to be important too, e.g., the bigger starfish will be easier to identify than the distant ones. Is there a way to differentiate between different projections, e.g., presence of prodominant blue gives a notion of whether the image is taken from farther away (or difficult angle) than images where there is absence of blue as a predominant colour?<\/li>\n    <li>The initial choice of algorithm: Mask R-CNN algorithm?<\/li>\n<\/ul>"}}